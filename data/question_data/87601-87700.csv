,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Local convexity of the topology of weak convergence of probability measures,Local convexity of the topology of weak convergence of probability measures,,"Let $X$ be a Polish or standard Borel space, and $\mathcal P(X)$ be the space of all Borel probability measures on $X$ endowed with the topology of weak convergence. I am thinking of using Choquet-Bishop-de Leeuw theorem which requires working on locally convex topological spaces. I thus wonder whether $\mathcal P(X)$ can be considered as a subspace of a locally convex topological space, or shall I instead work with compact subsets of $\mathcal P(X)$ in some norm topology?","Let $X$ be a Polish or standard Borel space, and $\mathcal P(X)$ be the space of all Borel probability measures on $X$ endowed with the topology of weak convergence. I am thinking of using Choquet-Bishop-de Leeuw theorem which requires working on locally convex topological spaces. I thus wonder whether $\mathcal P(X)$ can be considered as a subspace of a locally convex topological space, or shall I instead work with compact subsets of $\mathcal P(X)$ in some norm topology?",,"['functional-analysis', 'measure-theory', 'probability-theory', 'convex-analysis', 'locally-convex-spaces']"
1,Does Strong Convergence in $L^1$ Imply Weak Convergence in $L^2$?,Does Strong Convergence in  Imply Weak Convergence in ?,L^1 L^2,"If I have $f_n \to f$ in $L^1(D)$, where $D \subset \mathbb{R}$ is compact, is it accurate to say $f_n \rightharpoonup f$ in $L^2(D)$? The argument is as follows: consider a simple function $\phi = \sum_i a_i \chi_{D_i}$. Then \begin{align*} \lim_{n\to \infty} \int_D \phi f_n & = \lim_{n\to\infty} \sum_i a_i \int_{D_i} f_n \\ & = \sum_i a_i \int_{D_i} f \\ & = \sum_i \int_{D_i} a_i f \\ & = \int_D \phi f  \end{align*} Then weak convergence would follow from density of simple functions in $L^2$. This seems to make sense, but I couldn't find this result anywhere else - seems surprising for a result that appears so elementary.","If I have $f_n \to f$ in $L^1(D)$, where $D \subset \mathbb{R}$ is compact, is it accurate to say $f_n \rightharpoonup f$ in $L^2(D)$? The argument is as follows: consider a simple function $\phi = \sum_i a_i \chi_{D_i}$. Then \begin{align*} \lim_{n\to \infty} \int_D \phi f_n & = \lim_{n\to\infty} \sum_i a_i \int_{D_i} f_n \\ & = \sum_i a_i \int_{D_i} f \\ & = \sum_i \int_{D_i} a_i f \\ & = \int_D \phi f  \end{align*} Then weak convergence would follow from density of simple functions in $L^2$. This seems to make sense, but I couldn't find this result anywhere else - seems surprising for a result that appears so elementary.",,"['real-analysis', 'functional-analysis', 'lp-spaces', 'weak-convergence']"
2,No trace on $B(H)$ if $H$ is infinite dimensional,No trace on  if  is infinite dimensional,B(H) H,"Let $H$ be an infinite dimensional Hilbert space and $B(H)$ the bounded linear operators on $H$. Then thre is no ultra weakly continous non-zero positve trace $tr:B(H)\rightarrow \mathbb{C}$. I talked to my professor about it and he showed me how he would do it. But he used without further clarifcation that $tr$ is SOT-contionous, which I don't see right now.","Let $H$ be an infinite dimensional Hilbert space and $B(H)$ the bounded linear operators on $H$. Then thre is no ultra weakly continous non-zero positve trace $tr:B(H)\rightarrow \mathbb{C}$. I talked to my professor about it and he showed me how he would do it. But he used without further clarifcation that $tr$ is SOT-contionous, which I don't see right now.",,"['functional-analysis', 'hilbert-spaces', 'operator-algebras', 'von-neumann-algebras']"
3,Surjection of norms,Surjection of norms,,"Let $V$ be an infinite dimensional $\mathbb{C}$ (or $\mathbb{R}$) vector space. Suppose there exists two norms on $V$ such that \begin{equation*} \| \cdot\|_1 \leq \| \cdot \|_2. \end{equation*} Is it true that there always exists a surjection between the two different completions of $V$? That is, does there always exist a continuous $\mathbb{C}$-linear surjection ($\mathbb{R}$-linear surjection) \begin{equation*} \overline{V}^{\|\cdot \|_2} \twoheadrightarrow \overline{V}^{\|\cdot \|_1} \, ? \end{equation*} The particular example I have in mind is when $G$ is an infinite discrete countable group and $V = \mathbb{C}[G]$, the complex valued functions on $G$ with finite support. Then there is a surjection from the maxmial group $C^*$-algebra and the reduced $C^*$-algebra.","Let $V$ be an infinite dimensional $\mathbb{C}$ (or $\mathbb{R}$) vector space. Suppose there exists two norms on $V$ such that \begin{equation*} \| \cdot\|_1 \leq \| \cdot \|_2. \end{equation*} Is it true that there always exists a surjection between the two different completions of $V$? That is, does there always exist a continuous $\mathbb{C}$-linear surjection ($\mathbb{R}$-linear surjection) \begin{equation*} \overline{V}^{\|\cdot \|_2} \twoheadrightarrow \overline{V}^{\|\cdot \|_1} \, ? \end{equation*} The particular example I have in mind is when $G$ is an infinite discrete countable group and $V = \mathbb{C}[G]$, the complex valued functions on $G$ with finite support. Then there is a surjection from the maxmial group $C^*$-algebra and the reduced $C^*$-algebra.",,"['functional-analysis', 'vector-spaces', 'metric-spaces', 'operator-theory', 'normed-spaces']"
4,What is a predual of the Banach space of compact operators on $\ell^2$?,What is a predual of the Banach space of compact operators on ?,\ell^2,I am wondering if the space $K(\ell^2)$ of compact operators on $\ell^2$ can have a predual. Thank you in advance for your help.,I am wondering if the space $K(\ell^2)$ of compact operators on $\ell^2$ can have a predual. Thank you in advance for your help.,,"['functional-analysis', 'operator-theory', 'compact-operators']"
5,Prove that this space is not Banach,Prove that this space is not Banach,,"Let $\Omega\subset\mathbb{R}^n$ be an open, bounded set with boundary $\partial\Omega$ of class $C^1$. $$\mathcal{A}:=\{u\in C^2(\bar\Omega):u=0\text{ on }\partial\Omega \}$$ endowed with the scalar product $$(u,v)_{\mathcal{A}}:=\int_{\Omega}(\nabla u,\nabla v)_{\mathbb{R}^n}\,dx.$$ I have to prove that $\mathcal{A}$ equipped with the induced norm is a normed space, but it is not a Banach space. I can't find a proper counterexample. Any help?","Let $\Omega\subset\mathbb{R}^n$ be an open, bounded set with boundary $\partial\Omega$ of class $C^1$. $$\mathcal{A}:=\{u\in C^2(\bar\Omega):u=0\text{ on }\partial\Omega \}$$ endowed with the scalar product $$(u,v)_{\mathcal{A}}:=\int_{\Omega}(\nabla u,\nabla v)_{\mathbb{R}^n}\,dx.$$ I have to prove that $\mathcal{A}$ equipped with the induced norm is a normed space, but it is not a Banach space. I can't find a proper counterexample. Any help?",,"['analysis', 'functional-analysis', 'hilbert-spaces', 'banach-spaces']"
6,Inverse of identity operator not continuous,Inverse of identity operator not continuous,,"Let $\mathbb 1: (C^1([0,1]), \|f\|:=\|f\|_\infty + \|f'\|_\infty)\to (C^1([0,1]),\|\cdot\|_\infty)$ denote the identity mapping between $C^1([0,1])$ with different norms. Then $f$ is linear, continuous and one-to-one, but the inverse Operator $\mathbb 1^{-1}$ is not continuous. I am trying to convince myself that the inverse operator is indeed not continuous, but I don't know how. I tried to show that it is not bounded, but I didn't really know how to proceed after writing down the definition of the operator norm for $\mathbb 1^{-1}$. How can I show that $\mathbb 1^{-1}$ is not continuous? Thanks.","Let $\mathbb 1: (C^1([0,1]), \|f\|:=\|f\|_\infty + \|f'\|_\infty)\to (C^1([0,1]),\|\cdot\|_\infty)$ denote the identity mapping between $C^1([0,1])$ with different norms. Then $f$ is linear, continuous and one-to-one, but the inverse Operator $\mathbb 1^{-1}$ is not continuous. I am trying to convince myself that the inverse operator is indeed not continuous, but I don't know how. I tried to show that it is not bounded, but I didn't really know how to proceed after writing down the definition of the operator norm for $\mathbb 1^{-1}$. How can I show that $\mathbb 1^{-1}$ is not continuous? Thanks.",,['functional-analysis']
7,"Is the sequence $(f_n)$ convergent? weakly convergent? in $(C[0,1])'$",Is the sequence  convergent? weakly convergent? in,"(f_n) (C[0,1])'","Is the sequence $(f_n)$ convergent in $(C[0,1])'$? Weakly convergent? $$f_n(x)=n \int^{1/n}_0 x(t)dt , n\in \mathbb{N}.$$ Attempt: First I tried to show: $f_n\rightarrow f(x):=x(0)$ Then, I tried to find $g_n,g\in BV[0,1]:f_n(x)=\int^{1/n}_0 x(t)dg_n(t)$, $f(x)=\int^{1/n}_0 x(t)dg(t)$. Next, let $h\in(C[0,1])''$ such that $h(g)=g(0+)-g(0)$. Then how to show $h(g_n) \rightarrow h(g)$ does not hold.","Is the sequence $(f_n)$ convergent in $(C[0,1])'$? Weakly convergent? $$f_n(x)=n \int^{1/n}_0 x(t)dt , n\in \mathbb{N}.$$ Attempt: First I tried to show: $f_n\rightarrow f(x):=x(0)$ Then, I tried to find $g_n,g\in BV[0,1]:f_n(x)=\int^{1/n}_0 x(t)dg_n(t)$, $f(x)=\int^{1/n}_0 x(t)dg(t)$. Next, let $h\in(C[0,1])''$ such that $h(g)=g(0+)-g(0)$. Then how to show $h(g_n) \rightarrow h(g)$ does not hold.",,"['real-analysis', 'functional-analysis', 'weak-convergence']"
8,Want to show that $\{e^{i2\pi nx}:n\in\mathbb Z\}$ form an orthonormal basis for 1-periodic $L^2$ functions.,Want to show that  form an orthonormal basis for 1-periodic  functions.,\{e^{i2\pi nx}:n\in\mathbb Z\} L^2,"So here is my problem, I would like to prove that $\{e^{i2\pi nx}:n\in\mathbb Z\}$ form an orthonormal basis for 1- periodic $L^2([0,1])$ functions with respect to, $$\langle f,g\rangle:=\int_{[0,1]}f(x)\overline{g(x)}dx$$ An easy computations shows that, $$\langle e^{i2\pi nx},e^{i2\pi mx}\rangle=\delta_{n,m}$$ hence $\{e^{i2\pi nx}:n\in\mathbb Z\}$ is an orthormal system of vectors. So it is left to show that $\{e^{i2\pi nx}:n\in\mathbb Z\}$ is indeed maximal i.e a basis. For that I wanted to show that if for $f\in L^2[(0,1)]$ 1-periodic we have, $$\langle f,e^{i2\pi nx}\rangle=0\;\forall n\in \mathbb Z$$ then it follows $f\equiv0$ and hence the system is maximal. But I am failing to show that... Can someone help me? Thanks!","So here is my problem, I would like to prove that $\{e^{i2\pi nx}:n\in\mathbb Z\}$ form an orthonormal basis for 1- periodic $L^2([0,1])$ functions with respect to, $$\langle f,g\rangle:=\int_{[0,1]}f(x)\overline{g(x)}dx$$ An easy computations shows that, $$\langle e^{i2\pi nx},e^{i2\pi mx}\rangle=\delta_{n,m}$$ hence $\{e^{i2\pi nx}:n\in\mathbb Z\}$ is an orthormal system of vectors. So it is left to show that $\{e^{i2\pi nx}:n\in\mathbb Z\}$ is indeed maximal i.e a basis. For that I wanted to show that if for $f\in L^2[(0,1)]$ 1-periodic we have, $$\langle f,e^{i2\pi nx}\rangle=0\;\forall n\in \mathbb Z$$ then it follows $f\equiv0$ and hence the system is maximal. But I am failing to show that... Can someone help me? Thanks!",,"['functional-analysis', 'hilbert-spaces', 'orthonormal']"
9,Strictly convex unit balls in $L^p$,Strictly convex unit balls in,L^p,"I need to show that if $1<p<\infty$, then the unit ball is strictly convex in $L^p$, that is, $||\lambda x+(1-\lambda)y|| < 1$ whenever $||f|| = ||g||=1$ and $\lambda \in (0,1)$. I tried Minkwoski's inequality, but that only yields convexity, not strict. I also never used the fact that $p$ cannot be $1$ or $\infty$. Speaking of which, why is it not true for those values (unless the spaces are singletons of course)? EDIT: I know this is a duplicate, but the other post contains 2 incorrect answers only.","I need to show that if $1<p<\infty$, then the unit ball is strictly convex in $L^p$, that is, $||\lambda x+(1-\lambda)y|| < 1$ whenever $||f|| = ||g||=1$ and $\lambda \in (0,1)$. I tried Minkwoski's inequality, but that only yields convexity, not strict. I also never used the fact that $p$ cannot be $1$ or $\infty$. Speaking of which, why is it not true for those values (unless the spaces are singletons of course)? EDIT: I know this is a duplicate, but the other post contains 2 incorrect answers only.",,"['real-analysis', 'functional-analysis', 'measure-theory', 'convex-analysis']"
10,there is a measurable function $f$ on $X$ such that $|{f(x)}|=1$ for a.a $x \in X$ and $\nu(E)=\int_Efd|{\nu}|$ for any $E \in \mathfrak{M}$,there is a measurable function  on  such that  for a.a  and  for any,f X |{f(x)}|=1 x \in X \nu(E)=\int_Efd|{\nu}| E \in \mathfrak{M},"any hints on this problem:   Let $\nu$ be a finite signed measure on a measure space $(X, \mathfrak{M})$ and let $|{\nu}|$ be its total variation, prove that there is a measurable function $f$ on $X$ such that $|{f(x)}|=1$ for a.a $x \in X$ and $\nu(E)=\int_Efd|{\nu}|$ for any $E \in \mathfrak{M}$ I know that we need to use the Radon-Nikodym theorem, but I don't know how to start! Any help is greatly appreciated. Thanx in advance.","any hints on this problem:   Let $\nu$ be a finite signed measure on a measure space $(X, \mathfrak{M})$ and let $|{\nu}|$ be its total variation, prove that there is a measurable function $f$ on $X$ such that $|{f(x)}|=1$ for a.a $x \in X$ and $\nu(E)=\int_Efd|{\nu}|$ for any $E \in \mathfrak{M}$ I know that we need to use the Radon-Nikodym theorem, but I don't know how to start! Any help is greatly appreciated. Thanx in advance.",,['real-analysis']
11,Equivalent definitions for strictly positive elements,Equivalent definitions for strictly positive elements,,"We have two usual definitions for strictly positive elements in C*-algebras: Let $A$ be a C*-algebra Definition (a) [MURPHY, C$^*$-algebras and Operator Theory ] An element $a\in A_+$ is said to be strictly positive if $\overline{aAa}=A$, that is, the hereditary subalgebra generated by $a$ is dense in $A$. One can easily show that the following equivalence holds: $$\overline{aA}=A\iff\overline{Aa}=A\iff\overline{aAa}$$ Definition (b) [TAKESAKI, Theory of Operator Algebras I ] An element $a\in A$ is said to be strictly positive if $\tau(a)>0$ for every state $\tau\in A^*$. Equivalently, $a$ is strictly positive if $\tau(a)>0$ for every nonzero positive lineaer functional $\tau$ on $A$. In his book Operator Algebras , Blackadar says that it can be shown that these two definitions are equivalent, using Hahn-Banach and the usual results about extension of positive functionals. I've already shown that $(a)\Rightarrow (b)$, so the other implication is the problem. Any help is appreciated. Thank you.","We have two usual definitions for strictly positive elements in C*-algebras: Let $A$ be a C*-algebra Definition (a) [MURPHY, C$^*$-algebras and Operator Theory ] An element $a\in A_+$ is said to be strictly positive if $\overline{aAa}=A$, that is, the hereditary subalgebra generated by $a$ is dense in $A$. One can easily show that the following equivalence holds: $$\overline{aA}=A\iff\overline{Aa}=A\iff\overline{aAa}$$ Definition (b) [TAKESAKI, Theory of Operator Algebras I ] An element $a\in A$ is said to be strictly positive if $\tau(a)>0$ for every state $\tau\in A^*$. Equivalently, $a$ is strictly positive if $\tau(a)>0$ for every nonzero positive lineaer functional $\tau$ on $A$. In his book Operator Algebras , Blackadar says that it can be shown that these two definitions are equivalent, using Hahn-Banach and the usual results about extension of positive functionals. I've already shown that $(a)\Rightarrow (b)$, so the other implication is the problem. Any help is appreciated. Thank you.",,"['functional-analysis', 'definition', 'operator-algebras', 'c-star-algebras']"
12,"Normed linear space with two norms that are not equivalent, one is complete, what about the other?","Normed linear space with two norms that are not equivalent, one is complete, what about the other?",,"I have been searching for an answer to the following question: Given a normed linear space $V$ and two norms that are not equivalent, but $\exists K\in\mathbf{R}$ such that $\|v\|_1\leq K\|v\|_2$ for all $v\in V$. We know that $(V,\|\cdot\|_2)$ is complete, i.e. a Banach space. Is $(V,\|\cdot\|_1)$ also complete? Some related questions posted so far are: (i) Example of two norms on same space, non-equivalent, with one dominating the other (ii) If two normed spaces are Lipschitz equivalent, then one if complete iff the other is In (i) there is a good example from julien, but I am unable to relate it to Cauchy sequences. Could someone please shine some light on this, please?","I have been searching for an answer to the following question: Given a normed linear space $V$ and two norms that are not equivalent, but $\exists K\in\mathbf{R}$ such that $\|v\|_1\leq K\|v\|_2$ for all $v\in V$. We know that $(V,\|\cdot\|_2)$ is complete, i.e. a Banach space. Is $(V,\|\cdot\|_1)$ also complete? Some related questions posted so far are: (i) Example of two norms on same space, non-equivalent, with one dominating the other (ii) If two normed spaces are Lipschitz equivalent, then one if complete iff the other is In (i) there is a good example from julien, but I am unable to relate it to Cauchy sequences. Could someone please shine some light on this, please?",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
13,Does $f(x)\in L^1$ imply that $f'(x) \in L^1$?,Does  imply that ?,f(x)\in L^1 f'(x) \in L^1,"Let $f(x)$ be defined for all real numbers differentiable function of one variable.We know that: $$\int_{-\infty }^{+\infty } |f(x)| \, dx\neq +\infty$$ Problem is to resolve if it is possible or not that: $$\int_{-\infty }^{+\infty } |f'(x)| \, dx= +\infty$$","Let $f(x)$ be defined for all real numbers differentiable function of one variable.We know that: $$\int_{-\infty }^{+\infty } |f(x)| \, dx\neq +\infty$$ Problem is to resolve if it is possible or not that: $$\int_{-\infty }^{+\infty } |f'(x)| \, dx= +\infty$$",,"['real-analysis', 'functional-analysis', 'measure-theory']"
14,$T_n \rightarrow T$ then we have $||T|| \le \liminf(||T_n||)$,then we have,T_n \rightarrow T ||T|| \le \liminf(||T_n||),"I know how to show that a cauchy sequence of linear continuous operators $T_n:X \rightarrow Y$ has a limit that is also such an operator(if Y is a Banach space), but I found this relation here too $||T|| \le \liminf(||T_n||)$ and I just don't know where this liminf comes into play. Does anybody here know?","I know how to show that a cauchy sequence of linear continuous operators has a limit that is also such an operator(if Y is a Banach space), but I found this relation here too and I just don't know where this liminf comes into play. Does anybody here know?",T_n:X \rightarrow Y ||T|| \le \liminf(||T_n||),"['calculus', 'real-analysis']"
15,Calculating square roots of operators using power series for $\sqrt{1 - z}$,Calculating square roots of operators using power series for,\sqrt{1 - z},"The following is a theorem from Reed & Simon's Methods of Modern Mathematical Physics, Volume I . Here, we are working in a complex Hilbert space $(\mathcal{H}, (\cdot, \cdot))$, and $\mathscr{L}(\mathcal{H})$ is the space of bounded linear operators $\mathcal{H} \to \mathcal{H}$. Statement of theorem: Let $A \in \mathscr{L}(\mathcal{H})$ be positive (i.e., $(x, Ax) \ge 0$, all $x \in \mathcal{H}$). Then there is a unique positive $B \in \mathscr{L}(\mathcal{H})$ such that $B^2 = A.$ The proof in the text begins as follows: ""It is sufficient to consider the case where $||A|| \le 1$. First observe that $$||I- A|| = \operatorname{sup}_{||\phi|| = 1}|((I-A)\phi, \phi)| \le 1.$$ Next we use that fact that $\sqrt{1-z} = 1 + \sum_{k=1}^\infty c_kz^k$ converges absolutely for complex $z$ satisfying $|z| \le 1$, where the constants $c_k$ are known explicitly. This fact implies that the series $1 + \sum_{k=1}^\infty c_k(I- A)^k$ converges in norm to an operator $B$. Since the convergence is absolute, we can square the series and rearrange terms, which proves that $B^2 = A \dots$ I am able to verify most of the statements in this passage. However: My question is, how does one successfully work out the calculation for squaring the series? I have been trying for awhile to do the formal multiplication  $$(1 + c_1(I - A) + c_2(I-A)^2 + \cdots )(1 + c_1(I - A) + c_2(I-A)^2 + \cdots ),$$ using the fact that $0 = 1 + \sum_{k=1}^\infty c_k$. But I am just getting a bunch of messy terms. Is there a good trick to use, or an easier way to realize that $B^2 = A$? Hints or solutions are greatly appreciated.","The following is a theorem from Reed & Simon's Methods of Modern Mathematical Physics, Volume I . Here, we are working in a complex Hilbert space $(\mathcal{H}, (\cdot, \cdot))$, and $\mathscr{L}(\mathcal{H})$ is the space of bounded linear operators $\mathcal{H} \to \mathcal{H}$. Statement of theorem: Let $A \in \mathscr{L}(\mathcal{H})$ be positive (i.e., $(x, Ax) \ge 0$, all $x \in \mathcal{H}$). Then there is a unique positive $B \in \mathscr{L}(\mathcal{H})$ such that $B^2 = A.$ The proof in the text begins as follows: ""It is sufficient to consider the case where $||A|| \le 1$. First observe that $$||I- A|| = \operatorname{sup}_{||\phi|| = 1}|((I-A)\phi, \phi)| \le 1.$$ Next we use that fact that $\sqrt{1-z} = 1 + \sum_{k=1}^\infty c_kz^k$ converges absolutely for complex $z$ satisfying $|z| \le 1$, where the constants $c_k$ are known explicitly. This fact implies that the series $1 + \sum_{k=1}^\infty c_k(I- A)^k$ converges in norm to an operator $B$. Since the convergence is absolute, we can square the series and rearrange terms, which proves that $B^2 = A \dots$ I am able to verify most of the statements in this passage. However: My question is, how does one successfully work out the calculation for squaring the series? I have been trying for awhile to do the formal multiplication  $$(1 + c_1(I - A) + c_2(I-A)^2 + \cdots )(1 + c_1(I - A) + c_2(I-A)^2 + \cdots ),$$ using the fact that $0 = 1 + \sum_{k=1}^\infty c_k$. But I am just getting a bunch of messy terms. Is there a good trick to use, or an easier way to realize that $B^2 = A$? Hints or solutions are greatly appreciated.",,['functional-analysis']
16,Corollary of Banach Steinhaus theorem,Corollary of Banach Steinhaus theorem,,"If $\{M_n\}_{n∈\mathbb{N}}$ is a family of continuous operators for $X$ Banach to $Y$ normed, such that $M_n(x)$ converges to $M(x)$ for all $x ∈ X$, then $M$ is a linear bounded operator and $||M||_{L(X,Y)}≤\liminf_{n→∞}||M_n||_{L(X,Y)}$. I cant understand of which set is taken the inf?","If $\{M_n\}_{n∈\mathbb{N}}$ is a family of continuous operators for $X$ Banach to $Y$ normed, such that $M_n(x)$ converges to $M(x)$ for all $x ∈ X$, then $M$ is a linear bounded operator and $||M||_{L(X,Y)}≤\liminf_{n→∞}||M_n||_{L(X,Y)}$. I cant understand of which set is taken the inf?",,"['functional-analysis', 'operator-theory', 'limsup-and-liminf']"
17,Is the classical derivative the weak derivative on any domain?,Is the classical derivative the weak derivative on any domain?,,"I was looking at the following definition of the weak derivative: Let $\Omega$ be a domain (ie an open connected subset of $\mathbb{R}^n$). Suppose $u,v \in L_{1,loc}(\Omega)$ and \begin{equation} \int_{\Omega}u(x)\partial^{\alpha}\eta(x)dx = (-1)^{|\alpha|}\int_{\Omega}v(x)\eta(x)dx, \forall \eta \in C^{\infty}_c(\Omega) \end{equation} where $\alpha$ is a multiindex. Then $v$ is called the weak partial derivative of $u$ in $\Omega$, and is denoted by $\partial^{\alpha}u$. Now suppose the classical derivative $\partial^{\alpha}u$ exists and is continuous on some domain $\Omega$. Is the classical derivative the weak derivative on $\Omega$? I suppose this reduces to the integration by parts formula (ie the Guass-Green Theorem). But I'm having trouble justifying its use since for any particular $\eta \in C^{\infty}_c(\Omega)$ I seem to require a subdomain $\Omega' \subset \Omega$ such that $\text{supp} \eta \subset \Omega'$ and $\partial\Omega'$ is $C^{|\alpha|}$. Is there a standard construction, or do I need to have stronger restrictions on the domain $\Omega?$ Edit: The $\partial^{\alpha}u$ exists and is continuous on all of $\Omega$, not all of $\mathbb{R}^n$ as initially stated.","I was looking at the following definition of the weak derivative: Let $\Omega$ be a domain (ie an open connected subset of $\mathbb{R}^n$). Suppose $u,v \in L_{1,loc}(\Omega)$ and \begin{equation} \int_{\Omega}u(x)\partial^{\alpha}\eta(x)dx = (-1)^{|\alpha|}\int_{\Omega}v(x)\eta(x)dx, \forall \eta \in C^{\infty}_c(\Omega) \end{equation} where $\alpha$ is a multiindex. Then $v$ is called the weak partial derivative of $u$ in $\Omega$, and is denoted by $\partial^{\alpha}u$. Now suppose the classical derivative $\partial^{\alpha}u$ exists and is continuous on some domain $\Omega$. Is the classical derivative the weak derivative on $\Omega$? I suppose this reduces to the integration by parts formula (ie the Guass-Green Theorem). But I'm having trouble justifying its use since for any particular $\eta \in C^{\infty}_c(\Omega)$ I seem to require a subdomain $\Omega' \subset \Omega$ such that $\text{supp} \eta \subset \Omega'$ and $\partial\Omega'$ is $C^{|\alpha|}$. Is there a standard construction, or do I need to have stronger restrictions on the domain $\Omega?$ Edit: The $\partial^{\alpha}u$ exists and is continuous on all of $\Omega$, not all of $\mathbb{R}^n$ as initially stated.",,"['real-analysis', 'analysis', 'functional-analysis', 'partial-differential-equations', 'differential-topology']"
18,"uniform convergence on compact subsets of the linear,continuous and uniformly bounded operators.","uniform convergence on compact subsets of the linear,continuous and uniformly bounded operators.",,"Let $X,Y$ be normed spaces. Let $T_j : X\to Y$ be a sequence of linear and continuous functions, such that $\lVert T_j\rVert\lt K$  $\forall j$. If $T_j$ converges pointwise to $T$, prove that $T$ is also linear and continuous, and the convergence is uniform on compact subsets of $X$. I proved everything except for the uniform convergence on compact subsets. Please help me )=!","Let $X,Y$ be normed spaces. Let $T_j : X\to Y$ be a sequence of linear and continuous functions, such that $\lVert T_j\rVert\lt K$  $\forall j$. If $T_j$ converges pointwise to $T$, prove that $T$ is also linear and continuous, and the convergence is uniform on compact subsets of $X$. I proved everything except for the uniform convergence on compact subsets. Please help me )=!",,"['functional-analysis', 'operator-theory', 'normed-spaces', 'uniform-convergence']"
19,Approximation in Sobolev Spaces,Approximation in Sobolev Spaces,,"Consider the following proof in Lawrence Evans book 'Partial Differential Equations': How does it follows that $v^{\epsilon} \in C^{\infty}(\bar{V})$? I could see how $v^{\epsilon} \in C^{\infty}(V)$ by using the translations, but I'm having difficulty seeing how it extends to $\bar{V}$, since it says that $u_{\epsilon}(x) := u(x^{\epsilon}) \text{ for } x \text{ in } V$, we are mollifying on $V$. Do you have any idea of how this follows? Thanks for any assistance. How do we show that the convergent sequence $(v_m)_m$ which is stated in the Theorem statement converges uniformly to $u$?(Its actually called $(u_{m})_{m}$ in the proof stament but I will use $(v_{m})_{m}$). We use the fact that the convergence is uniform in a proof of a Theorem later in the book, so it is established as being uniformly convergent. The idea that I am proposing: In the proof we have that $v := \sum_{i=0}^{N}\zeta_{i}v_{i}$ is a member of $(v_{m})_{m}$.  I think the idea is that we form a sequence  $(v_m)_m$ by letting say $\epsilon = (\frac{1}{m})$ and then by choosing a small enough $\epsilon$ such that we have the same $\epsilon$ for all the translations on each $V_{i}$ for $i=1,...N$ and $V_{0}$ and therefore we have $v_{m} := \sum_{i=0}^{N}\zeta_{i}v_{i}$ which allows us to write $||D^{\alpha}v_{m} - D^{\alpha}u||_{L^{P}(U)} \leq CN\delta$ for small enough $\epsilon$ and all $\epsilon$ smaller, so for some $N \in \mathbb{N}$ and for all $m \geq N$ we have $||v_{m} - u||_{L^{P}(U)} \leq CN\delta$. From this we have the uniform convergence from the usual definition. Does this make sense? Is it necessary to do this or is the uniform continuity more apparent? Let me know if anything is unclear, thanks.","Consider the following proof in Lawrence Evans book 'Partial Differential Equations': How does it follows that $v^{\epsilon} \in C^{\infty}(\bar{V})$? I could see how $v^{\epsilon} \in C^{\infty}(V)$ by using the translations, but I'm having difficulty seeing how it extends to $\bar{V}$, since it says that $u_{\epsilon}(x) := u(x^{\epsilon}) \text{ for } x \text{ in } V$, we are mollifying on $V$. Do you have any idea of how this follows? Thanks for any assistance. How do we show that the convergent sequence $(v_m)_m$ which is stated in the Theorem statement converges uniformly to $u$?(Its actually called $(u_{m})_{m}$ in the proof stament but I will use $(v_{m})_{m}$). We use the fact that the convergence is uniform in a proof of a Theorem later in the book, so it is established as being uniformly convergent. The idea that I am proposing: In the proof we have that $v := \sum_{i=0}^{N}\zeta_{i}v_{i}$ is a member of $(v_{m})_{m}$.  I think the idea is that we form a sequence  $(v_m)_m$ by letting say $\epsilon = (\frac{1}{m})$ and then by choosing a small enough $\epsilon$ such that we have the same $\epsilon$ for all the translations on each $V_{i}$ for $i=1,...N$ and $V_{0}$ and therefore we have $v_{m} := \sum_{i=0}^{N}\zeta_{i}v_{i}$ which allows us to write $||D^{\alpha}v_{m} - D^{\alpha}u||_{L^{P}(U)} \leq CN\delta$ for small enough $\epsilon$ and all $\epsilon$ smaller, so for some $N \in \mathbb{N}$ and for all $m \geq N$ we have $||v_{m} - u||_{L^{P}(U)} \leq CN\delta$. From this we have the uniform convergence from the usual definition. Does this make sense? Is it necessary to do this or is the uniform continuity more apparent? Let me know if anything is unclear, thanks.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'convolution', 'regularization']"
20,Counterexample using counting measure,Counterexample using counting measure,,"While proving that the norm of the mulplicative operator from $L^2(X) \to L^2(X)$ is the essential supremum of $|g|$ where $g \in L^\infty(X)$, I found that I need the $\sigma$-finiteness of the measure on $X$. Can someone give me an example of a non $\sigma$-finite measure space and $g \in L^\infty(X)$ such that the norm of the multiplication operator is strictly less than the essential supremum of $|g|$? I was trying with the counting measure on $\mathbb R$, but to no avail, so it would be nice if someone can give me the example using the counting measure,but other counterexamples are also welcome. If somebody has any problem with the definition of a multiplicative operator, please refer to this . Thanks for any help.","While proving that the norm of the mulplicative operator from $L^2(X) \to L^2(X)$ is the essential supremum of $|g|$ where $g \in L^\infty(X)$, I found that I need the $\sigma$-finiteness of the measure on $X$. Can someone give me an example of a non $\sigma$-finite measure space and $g \in L^\infty(X)$ such that the norm of the multiplication operator is strictly less than the essential supremum of $|g|$? I was trying with the counting measure on $\mathbb R$, but to no avail, so it would be nice if someone can give me the example using the counting measure,but other counterexamples are also welcome. If somebody has any problem with the definition of a multiplicative operator, please refer to this . Thanks for any help.",,"['functional-analysis', 'measure-theory', 'operator-theory', 'normed-spaces']"
21,How to prove this? (convergence in the weak*-topology),How to prove this? (convergence in the weak*-topology),,"I want to prove the following theorem, but I'm not skilled in deal with weak and weak*-topologies: Theorem. Let $X$ be a Banach space and $\sigma(X',X)$ the weak*-topology of $X'$ [$X'$ is the dual of $X$]. Then $f_n \overset{\star}{\rightharpoonup} f$ in $\sigma(X',X)$ iff $\langle f_n, x \rangle \overset{n \to \infty}{\longrightarrow} \langle f,x \rangle$ for all $x \in X$. if I well understood, this is a relation between the convergence in the weak*-topology and the strong convergence in $X'$. For reference, this is for example Proposition 3.13 in Brezis's book on functional analysis (he doesn't prove it; only suggests that the reader should copy the proof of the ""dual"" theorem about the weak topology - that, anyway, is not carried out explicitly.). May anyone post a detailed proof, in order to show me how to handle with such objects? EDIT - I add the definition of weak*-topology I'm using. Definition. Let $X$ be a Banach space, $X'$ the dual of $X$, $\mathcal F \subset X''$ defined by $\mathcal F := \{f \to \langle f,x \rangle, x \in X\}$, $\mathcal F : X' \to \mathbb K^X$, $\mathbb K^X$ endowed with the product topology $\tau$. Then $\sigma( X', X) := \mathcal F^{-1}\tau$ is the weak*-topology of $X'$.","I want to prove the following theorem, but I'm not skilled in deal with weak and weak*-topologies: Theorem. Let $X$ be a Banach space and $\sigma(X',X)$ the weak*-topology of $X'$ [$X'$ is the dual of $X$]. Then $f_n \overset{\star}{\rightharpoonup} f$ in $\sigma(X',X)$ iff $\langle f_n, x \rangle \overset{n \to \infty}{\longrightarrow} \langle f,x \rangle$ for all $x \in X$. if I well understood, this is a relation between the convergence in the weak*-topology and the strong convergence in $X'$. For reference, this is for example Proposition 3.13 in Brezis's book on functional analysis (he doesn't prove it; only suggests that the reader should copy the proof of the ""dual"" theorem about the weak topology - that, anyway, is not carried out explicitly.). May anyone post a detailed proof, in order to show me how to handle with such objects? EDIT - I add the definition of weak*-topology I'm using. Definition. Let $X$ be a Banach space, $X'$ the dual of $X$, $\mathcal F \subset X''$ defined by $\mathcal F := \{f \to \langle f,x \rangle, x \in X\}$, $\mathcal F : X' \to \mathbb K^X$, $\mathbb K^X$ endowed with the product topology $\tau$. Then $\sigma( X', X) := \mathcal F^{-1}\tau$ is the weak*-topology of $X'$.",,"['functional-analysis', 'weak-convergence']"
22,Dual of an isometry,Dual of an isometry,,"Let $T : X \to Y$ be a linear isometry between normed spaces $X,Y$. Must the dual map $T^* : Y^* \to X^*$ be an isometry?","Let $T : X \to Y$ be a linear isometry between normed spaces $X,Y$. Must the dual map $T^* : Y^* \to X^*$ be an isometry?",,['functional-analysis']
23,Sobolev embeddings,Sobolev embeddings,,"I'm doing some reading on embeddings of Sobolev spaces and at the moment I am trying to understand why $H^1(0,1)\subset C(0,1)$. The proof I found basically shows that for any $u\in H^1(0,1)$ the inequality $$||u||_\infty \leq c ||u||_{H^1(0,1)}$$ holds for some constant $c>0$, but I don't understand yet why this proves the subset statement.","I'm doing some reading on embeddings of Sobolev spaces and at the moment I am trying to understand why $H^1(0,1)\subset C(0,1)$. The proof I found basically shows that for any $u\in H^1(0,1)$ the inequality $$||u||_\infty \leq c ||u||_{H^1(0,1)}$$ holds for some constant $c>0$, but I don't understand yet why this proves the subset statement.",,"['functional-analysis', 'sobolev-spaces']"
24,"How can we pick $f \in C(0,T;H)$ with $f(T) =0$ and $f(0) = h$, where $h$ is arbitrary?","How can we pick  with  and , where  is arbitrary?","f \in C(0,T;H) f(T) =0 f(0) = h h","Let $C(0,T;H)$ be the space of continuous functions $f:[0,T]\to H$ where $H$ is Hilbert. For every $h \in H$, why is it possible to pick a function $f \in C(0,T;H)$ such that $f(0) = h$ and $f(T) = 0$? When $H = \mathbb{R}$, OK, I guess it's possible to do this as i can visualise a graph. But not sure about the general case. How to prove it? I ask because I see in the proof to parabolic PDE existence, one gets $$(u_0-u(0),v(0))_H=0$$ for all $v \in C(0,T;H)$ with $v(T)=0$, and from this everybody says that $u(0) = u_0$ since $v(0)$ is arbitrary. So this is why I ask the question.","Let $C(0,T;H)$ be the space of continuous functions $f:[0,T]\to H$ where $H$ is Hilbert. For every $h \in H$, why is it possible to pick a function $f \in C(0,T;H)$ such that $f(0) = h$ and $f(T) = 0$? When $H = \mathbb{R}$, OK, I guess it's possible to do this as i can visualise a graph. But not sure about the general case. How to prove it? I ask because I see in the proof to parabolic PDE existence, one gets $$(u_0-u(0),v(0))_H=0$$ for all $v \in C(0,T;H)$ with $v(T)=0$, and from this everybody says that $u(0) = u_0$ since $v(0)$ is arbitrary. So this is why I ask the question.",,"['functional-analysis', 'partial-differential-equations', 'hilbert-spaces']"
25,"Thin Plate Spline interpolation of scattered $z(x,y)$ data",Thin Plate Spline interpolation of scattered  data,"z(x,y)","I am trying to understand Thin Plate Spline interpolation of scattered data. As I understand it TPS is just a special case of Radial Basis Function interpolation: $$ z(x,y) = p(x,y) + \sum_i l_i\phi(r)$$ where p(x,y) is a polynomial and $\ \phi $ is a RBF. In the case of TPS: $\ \phi = r^2\ln(r) $ Should not the RBF decrease with r? In the case of inverse distance weighted interpolation the weight of each point goes from +infinity at r = 0 to 0 at r = + infinity. Which order of polynomial should I use? I understand that p(x,y) should compensate for offset and maybe a linear trend, so that would indicate: p(x,y) = ax+by+c. But why stop there? The TPS is required to go exactly trough each point: $$ z_i = p(x_i,y_i) + \sum_j l_j\phi(r_i) $$ This can be written as a matrix equation: $$ [\Phi, X, Y, 1]*[L, a, b, c]'=Z$$ where $\ \Phi $ is a nxn matrix, X, Y, L and Z are nx1 vectors. This is underdetermined: there are n + 3 unknowns and n equations. Therefore one have to impose some additional requirements. One requires: $$ \sum_i x_i*l_i = 0$$ $$ \sum_i y_i*l_i = 0$$ $$ \sum_i 1*l_i = 0$$ and calls this orthogonality. But what does this mean? I am used to orthogonal function expansions and understand that $\ <x,b(x,y)> = 0$ for some basis function,b, would mean that x and b(x,y) are orthogonal and that would be a good thing since it makes it easy to find the coefficients of b by simply taking the inner product of b and the function to be expanded. But in this context? And why is the coefficents of the RBFs that are in the orthogonality requirement and not the RBFs themselves? However this means that we now have n equations for n unknows. Introducing $\ P=[X,Y,1] $ and $\ C = [a,b,c]' $ our first matrix equation can be written as: $$ [\Phi | P][L|C]'=Z $$ and the orthogonality requirements becomes a vertical concatenation to this: $$ [P' | 0]*[L | C]' = 0 $$ Which method would you recommend to solve this equation? Which functions does this correspond to in Lapack? If the number of samples, n, is large this computation becomes heavy. Is there some easy and sensible way to improve upon this? I was considering introducing a cut-off radius and any points further away than this would get the $\ \phi $ = 0 value. This would lead to a sparse matrix equation. However this stumbles on my first question: why does not the RBF decay to 0 as r goes to infinity?","I am trying to understand Thin Plate Spline interpolation of scattered data. As I understand it TPS is just a special case of Radial Basis Function interpolation: $$ z(x,y) = p(x,y) + \sum_i l_i\phi(r)$$ where p(x,y) is a polynomial and $\ \phi $ is a RBF. In the case of TPS: $\ \phi = r^2\ln(r) $ Should not the RBF decrease with r? In the case of inverse distance weighted interpolation the weight of each point goes from +infinity at r = 0 to 0 at r = + infinity. Which order of polynomial should I use? I understand that p(x,y) should compensate for offset and maybe a linear trend, so that would indicate: p(x,y) = ax+by+c. But why stop there? The TPS is required to go exactly trough each point: $$ z_i = p(x_i,y_i) + \sum_j l_j\phi(r_i) $$ This can be written as a matrix equation: $$ [\Phi, X, Y, 1]*[L, a, b, c]'=Z$$ where $\ \Phi $ is a nxn matrix, X, Y, L and Z are nx1 vectors. This is underdetermined: there are n + 3 unknowns and n equations. Therefore one have to impose some additional requirements. One requires: $$ \sum_i x_i*l_i = 0$$ $$ \sum_i y_i*l_i = 0$$ $$ \sum_i 1*l_i = 0$$ and calls this orthogonality. But what does this mean? I am used to orthogonal function expansions and understand that $\ <x,b(x,y)> = 0$ for some basis function,b, would mean that x and b(x,y) are orthogonal and that would be a good thing since it makes it easy to find the coefficients of b by simply taking the inner product of b and the function to be expanded. But in this context? And why is the coefficents of the RBFs that are in the orthogonality requirement and not the RBFs themselves? However this means that we now have n equations for n unknows. Introducing $\ P=[X,Y,1] $ and $\ C = [a,b,c]' $ our first matrix equation can be written as: $$ [\Phi | P][L|C]'=Z $$ and the orthogonality requirements becomes a vertical concatenation to this: $$ [P' | 0]*[L | C]' = 0 $$ Which method would you recommend to solve this equation? Which functions does this correspond to in Lapack? If the number of samples, n, is large this computation becomes heavy. Is there some easy and sensible way to improve upon this? I was considering introducing a cut-off radius and any points further away than this would get the $\ \phi $ = 0 value. This would lead to a sparse matrix equation. However this stumbles on my first question: why does not the RBF decay to 0 as r goes to infinity?",,"['linear-algebra', 'functional-analysis', 'interpolation']"
26,"$L^2$-lower semicontinuity of an integral operator on $G(x,\nabla w(x))$",-lower semicontinuity of an integral operator on,"L^2 G(x,\nabla w(x))","In the paper "" A posteriori error estimates for variable time-step discretizations of nonlinear evolution equations "" by Nochetto, Savaré, Verdi we find the following claim in Example 2.4: Let $\mathcal H:=L^2(\Omega),\ p>1$   $$ \phi(w):=\int_\Omega G(x,\nabla w(x))dx,\quad D(\phi):=L^2(\Omega)\cap W_0^{1,p}(\Omega)$$   If $G(x,\xi):\Omega\times\mathbb R^d\rightarrow\mathbb R$ is a Carathéodory function convex and continuously differentiable in $\xi$ for a.e. $x\in\Omega$ such that   $$ G(x,\xi)\geqslant\alpha_0|\xi|^p-\alpha_1,\quad|\nabla_\xi G(x,\xi)|\leqslant\alpha_2 (1+|\xi|^{p-1}), \quad\forall\xi\in\mathbb R^m,a.e. x\in\Omega$$   with some positive constants $\alpha_i$, then $\phi$ is convex and lower semicontinuous in $\mathcal H=L^2(\Omega)$. Note that l.s.c. is stated in $L^2$. (At least for $p=2$) I am interested in either a reference to such a result with proof or a hint of how to prove this. I have dificulties to relate this to classical results like the theorem of Serrin and generalizations as they yield  $${\lim \inf}_{n\rightarrow\infty} \phi(u_n)\geqslant\phi(u)$$ only for sequences $u_n\rightarrow u$ wrt the $L^1$ norm where the $u_n$ and $u$ are in $W^{1,1}(\Omega)$ while assumptions are usually weaker. whether or not such a result carries over to the vector-valued case, i.e. $\mathcal H=L^2(\Omega,\mathbb R^N)$. NB: I'm a numerics guy with little practice in analysis...","In the paper "" A posteriori error estimates for variable time-step discretizations of nonlinear evolution equations "" by Nochetto, Savaré, Verdi we find the following claim in Example 2.4: Let $\mathcal H:=L^2(\Omega),\ p>1$   $$ \phi(w):=\int_\Omega G(x,\nabla w(x))dx,\quad D(\phi):=L^2(\Omega)\cap W_0^{1,p}(\Omega)$$   If $G(x,\xi):\Omega\times\mathbb R^d\rightarrow\mathbb R$ is a Carathéodory function convex and continuously differentiable in $\xi$ for a.e. $x\in\Omega$ such that   $$ G(x,\xi)\geqslant\alpha_0|\xi|^p-\alpha_1,\quad|\nabla_\xi G(x,\xi)|\leqslant\alpha_2 (1+|\xi|^{p-1}), \quad\forall\xi\in\mathbb R^m,a.e. x\in\Omega$$   with some positive constants $\alpha_i$, then $\phi$ is convex and lower semicontinuous in $\mathcal H=L^2(\Omega)$. Note that l.s.c. is stated in $L^2$. (At least for $p=2$) I am interested in either a reference to such a result with proof or a hint of how to prove this. I have dificulties to relate this to classical results like the theorem of Serrin and generalizations as they yield  $${\lim \inf}_{n\rightarrow\infty} \phi(u_n)\geqslant\phi(u)$$ only for sequences $u_n\rightarrow u$ wrt the $L^1$ norm where the $u_n$ and $u$ are in $W^{1,1}(\Omega)$ while assumptions are usually weaker. whether or not such a result carries over to the vector-valued case, i.e. $\mathcal H=L^2(\Omega,\mathbb R^N)$. NB: I'm a numerics guy with little practice in analysis...",,['functional-analysis']
27,"An operator between $\mathcal{L}(X, Y)$ and $\mathcal{L}(Y, X)$",An operator between  and,"\mathcal{L}(X, Y) \mathcal{L}(Y, X)","Please, I need help with this problem. Let $X$, $Y$ be two vector normed spaces. Let $A_0\in\mathcal{L}(X, Y)$ such that $A^{-1}_0\in\mathcal{L}(Y,X)$. Show that there's an operator $\mathcal{T}_0\in\mathcal{L}(\mathcal{L}(X, Y), \mathcal{L}(Y, X))$ such that $\mathcal{T}_0A_0 = A_0^{-1}$ and $\|\mathcal{T}_0\| = \|A^{-1}_0\| / \|A_0\|$. Thanks in advance.","Please, I need help with this problem. Let $X$, $Y$ be two vector normed spaces. Let $A_0\in\mathcal{L}(X, Y)$ such that $A^{-1}_0\in\mathcal{L}(Y,X)$. Show that there's an operator $\mathcal{T}_0\in\mathcal{L}(\mathcal{L}(X, Y), \mathcal{L}(Y, X))$ such that $\mathcal{T}_0A_0 = A_0^{-1}$ and $\|\mathcal{T}_0\| = \|A^{-1}_0\| / \|A_0\|$. Thanks in advance.",,"['functional-analysis', 'operator-theory']"
28,Use Lax-Milgram theorem to prove the existence of weak solution for an elliptic equation,Use Lax-Milgram theorem to prove the existence of weak solution for an elliptic equation,,"Let $\Omega$ an open bounded and regular domain to $\mathbb{R^n}$ and let $\{\overline{\Omega_1},\overline{\Omega_2}\}$ a partition of $\Omega.$  $\bar{\Omega} = \bar{\Omega_1} \cup \bar{\Omega_2}.$ We put $\Gamma = \partial \Omega_1 \cap \partial \Omega_2$ the interface between $\Omega_1$ and $\Omega_2$ such that $\Gamma \subset  \Omega.$ We put $u_1 = u/\Omega_1$ (restriction $u$ to $\Omega_1$) and we condider the problem: $$-k_i \Delta u_i = f , x \in \Omega_1 , i=1,2$$ $$u_1=0 , x \in \partial \Omega$$ $$u_1 = u_2 , x \in \Gamma$$ $$k_1 \nabla u_1 n = k_2 \nabla u_2 n , x \in \Gamma$$ $k(x)$ is an piecewise constant , with $k(x) = k_i > 0, i = 1,2$  and $f \in L^2(\Omega)$ My questions are, how: 1-prouve that this problem admit a unique solution in an adequat Hilbert space $V.$ 2- Prouve that $\exists c > 0, ||u||_V \leq c$ and prouve that $u$ verfies the minimum of energy.","Let $\Omega$ an open bounded and regular domain to $\mathbb{R^n}$ and let $\{\overline{\Omega_1},\overline{\Omega_2}\}$ a partition of $\Omega.$  $\bar{\Omega} = \bar{\Omega_1} \cup \bar{\Omega_2}.$ We put $\Gamma = \partial \Omega_1 \cap \partial \Omega_2$ the interface between $\Omega_1$ and $\Omega_2$ such that $\Gamma \subset  \Omega.$ We put $u_1 = u/\Omega_1$ (restriction $u$ to $\Omega_1$) and we condider the problem: $$-k_i \Delta u_i = f , x \in \Omega_1 , i=1,2$$ $$u_1=0 , x \in \partial \Omega$$ $$u_1 = u_2 , x \in \Gamma$$ $$k_1 \nabla u_1 n = k_2 \nabla u_2 n , x \in \Gamma$$ $k(x)$ is an piecewise constant , with $k(x) = k_i > 0, i = 1,2$  and $f \in L^2(\Omega)$ My questions are, how: 1-prouve that this problem admit a unique solution in an adequat Hilbert space $V.$ 2- Prouve that $\exists c > 0, ||u||_V \leq c$ and prouve that $u$ verfies the minimum of energy.",,"['functional-analysis', 'partial-differential-equations']"
29,On Absolutely Continuous Functions,On Absolutely Continuous Functions,,"I would like to know if we can extend the concept of absolute continuity to functions $f:[a,b]\to X$, where $X$ is a topological vector space. I browsed some books on Topological Vector Spaces but can't find the definition of absolutely continuous functions defined on $[a,b]$ and take values on $X$. I would be greatful if someone can provide me a definition (if possible) of absolute continuous function $f:[a,b]\to X$. Thanks in advance...","I would like to know if we can extend the concept of absolute continuity to functions $f:[a,b]\to X$, where $X$ is a topological vector space. I browsed some books on Topological Vector Spaces but can't find the definition of absolutely continuous functions defined on $[a,b]$ and take values on $X$. I would be greatful if someone can provide me a definition (if possible) of absolute continuous function $f:[a,b]\to X$. Thanks in advance...",,"['functional-analysis', 'topological-vector-spaces']"
30,Is it possible to write any bounded continuous function as a uniform limit of smooth functions,Is it possible to write any bounded continuous function as a uniform limit of smooth functions,,Is $C^\infty(\mathbb{R})\subset C_b(\mathbb{R})$ dense? I.e. is any continuous bounded function $f:\mathbb{R}\to\mathbb{R}$ the uniform limit of smooth functions? On any bounded interval this is true since by Stone-Weierstrass polynomials are smooth and dense in the continuous functions. I guess the result is still true for $\mathbb{R}$ but I don't know how to prove it. Since I don't have any integrability conditions on $f$ the technique of convoluting with mollifiers is probably not applicable.,Is $C^\infty(\mathbb{R})\subset C_b(\mathbb{R})$ dense? I.e. is any continuous bounded function $f:\mathbb{R}\to\mathbb{R}$ the uniform limit of smooth functions? On any bounded interval this is true since by Stone-Weierstrass polynomials are smooth and dense in the continuous functions. I guess the result is still true for $\mathbb{R}$ but I don't know how to prove it. Since I don't have any integrability conditions on $f$ the technique of convoluting with mollifiers is probably not applicable.,,"['real-analysis', 'functional-analysis']"
31,When is the quotient algebra of a unital C* algebra helpful?,When is the quotient algebra of a unital C* algebra helpful?,,"Let $\mathcal A$ be a unital C* algebra. Which properties does $\mathcal B \subset \mathcal A$ has to have for it to make sense to form the quotient algebra $\mathcal A / \mathcal B$? In cases where this construction makes sense, does $\mathcal A / \mathcal B$ have any special structure/properties that are helpful? Put differently, for what kind of standard questions does it help to consider $\mathcal A / \mathcal B$ because it has desired properties?","Let $\mathcal A$ be a unital C* algebra. Which properties does $\mathcal B \subset \mathcal A$ has to have for it to make sense to form the quotient algebra $\mathcal A / \mathcal B$? In cases where this construction makes sense, does $\mathcal A / \mathcal B$ have any special structure/properties that are helpful? Put differently, for what kind of standard questions does it help to consider $\mathcal A / \mathcal B$ because it has desired properties?",,"['abstract-algebra', 'functional-analysis', 'c-star-algebras']"
32,When can you integrate a derivative?,When can you integrate a derivative?,,Let us say I have an expression $$\frac{d}{dt}f = g$$ where the derivative is taken in a weak sense (of distributions). Can I integrate this from $0$ to $t_0$ and get $$f(t_0) - f(0) = \int_0^{t_0}g?$$ Does the derivative need to be a classical one to do that?,Let us say I have an expression $$\frac{d}{dt}f = g$$ where the derivative is taken in a weak sense (of distributions). Can I integrate this from $0$ to $t_0$ and get $$f(t_0) - f(0) = \int_0^{t_0}g?$$ Does the derivative need to be a classical one to do that?,,"['functional-analysis', 'distribution-theory']"
33,Banach spaces and quotient space,Banach spaces and quotient space,,"Let $X$ be a normed vector space, $M$ a closed subspace of $X$ such that $M$ and $X/M$ are Banach spaces. Any hint to prove that $X$ must be a Banach space?","Let $X$ be a normed vector space, $M$ a closed subspace of $X$ such that $M$ and $X/M$ are Banach spaces. Any hint to prove that $X$ must be a Banach space?",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
34,Interchanging closed operators and integrals,Interchanging closed operators and integrals,,"I am dealing with a problem in Evans PDE without measure theory knowledge... We have contraction semigroup $\{S_t\}_{t \geq 0}$ on real Banach space $X$, i.e family of bounded linear operators from $ X \to X $ which satisfy: 1) $S(0)u = u$ $\text{ }$ for all $u \in X$ 2) $S(t+s)=S(t)S(s)u = S(s)S(t)u $ $\quad$($ t,s \geq 0$, $u \in X $) 3) mapping  $t \mapsto S(t)u $ $\text{ }$ is continuous from $ [0,\infty) $ into $X$ 4) $||S(t)|| \leq 1$ We have infinitesimal generator A of the contraction semigroup $\{S_t\}_{t \geq 0}$, $$ A: D(A) \to X $$ $$  Au:= \lim_{t \to 0+} \frac{S(t)u-u}{t} $$ where $$D(A)= \{ u \in X; \lim_{t \to 0+} \frac{S(t)u-u}{t} \text{ exists in } X \}. $$ I have to prove $$ A \int_0^{\infty} e^{-\lambda t}S(t)u dt = \int_0^{\infty} e^{-\lambda t}S(t)Au dt$$ for all $u \in D(A).$ From theory i know $ S(t)u \in D(A)$, $AS(t)u = S(t)Au$, $D(A)$ is dense in $X$ and $A$ is closed. The hint in the book is to approximate the integral by a Riemann sum. Edit:  I tried as it was suggested to me: $$ I:=\int_0^{\infty}e^{-\lambda t}S(t)udt \quad \text{and} \quad J:=\int_0^{\infty}e^{-\lambda t}S(t)Audt. $$  I have to prove $A(I)=J$. I define $$ I_n = \int_0^{n}e^{-\lambda t}S(t)udt \quad \text{and} \quad  J_n=\int_0^{n}e^{-\lambda t}S(t)Audt. $$ Therefore $I_n \to I$ and $J_n \to J$. I approximate $I_n$ and $J_n$ with the help of Riemann sums. Divide the interval $[0,n]$ in $k$ parts of length $\frac{n}{k}$. Function $e^{-\lambda t}$ is monotonically decreasing and thus reaches its maximum on the interval $[\frac{i}{n},\frac{i+1}{n}]$ at $\frac{i}{n}$. The approximation with upper Riemann sum for integral $I_n$ is  $$ I_n = \int_0^{n}e^{-\lambda t}S(t)udt \leq \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)u $$ and for integral $J_n$ is $$ J_n = \int_0^{n}e^{-\lambda t}S(t)Audt \leq \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)Au $$ Is this OK? Then i define sequences $\{ I_{n,k} \}_k = I_{n,1},I_{n,2},\dots$ and $\{ J_{n,k} \}_k = J_{n,1},J_{n,2},\dots$ where  $$ I_{n,k} = \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)u $$ and $$ J_{n,k} = \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)Au $$ Then $I_{n,k} \to I_{n}$ when $k \to \infty$ and $J_{n,k} \to J_{n}$ when $k \to \infty$. Here i also struggle...Is the following true? $$ A(I_{n,k}) = A(\sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)u) = \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}AS(t)u $$ I know $A$ is linear ($Au=\lim_{t\to 0+} \frac{S(t)u-u}{t}$) but what can i do with the $\max$? I then use a proven fact in the book, $AS(t)u = S(t)Au$ to get $A(I_{n,k}) = J_{n,k}$. I have $A(I_{n,k}) \to J_n$ and since $A$ is closed i have $A(I_n) = J_n$. Therefore $A(I_n) \to J$. Using again closedness of $A$ i conclude $A(I)=J$.","I am dealing with a problem in Evans PDE without measure theory knowledge... We have contraction semigroup $\{S_t\}_{t \geq 0}$ on real Banach space $X$, i.e family of bounded linear operators from $ X \to X $ which satisfy: 1) $S(0)u = u$ $\text{ }$ for all $u \in X$ 2) $S(t+s)=S(t)S(s)u = S(s)S(t)u $ $\quad$($ t,s \geq 0$, $u \in X $) 3) mapping  $t \mapsto S(t)u $ $\text{ }$ is continuous from $ [0,\infty) $ into $X$ 4) $||S(t)|| \leq 1$ We have infinitesimal generator A of the contraction semigroup $\{S_t\}_{t \geq 0}$, $$ A: D(A) \to X $$ $$  Au:= \lim_{t \to 0+} \frac{S(t)u-u}{t} $$ where $$D(A)= \{ u \in X; \lim_{t \to 0+} \frac{S(t)u-u}{t} \text{ exists in } X \}. $$ I have to prove $$ A \int_0^{\infty} e^{-\lambda t}S(t)u dt = \int_0^{\infty} e^{-\lambda t}S(t)Au dt$$ for all $u \in D(A).$ From theory i know $ S(t)u \in D(A)$, $AS(t)u = S(t)Au$, $D(A)$ is dense in $X$ and $A$ is closed. The hint in the book is to approximate the integral by a Riemann sum. Edit:  I tried as it was suggested to me: $$ I:=\int_0^{\infty}e^{-\lambda t}S(t)udt \quad \text{and} \quad J:=\int_0^{\infty}e^{-\lambda t}S(t)Audt. $$  I have to prove $A(I)=J$. I define $$ I_n = \int_0^{n}e^{-\lambda t}S(t)udt \quad \text{and} \quad  J_n=\int_0^{n}e^{-\lambda t}S(t)Audt. $$ Therefore $I_n \to I$ and $J_n \to J$. I approximate $I_n$ and $J_n$ with the help of Riemann sums. Divide the interval $[0,n]$ in $k$ parts of length $\frac{n}{k}$. Function $e^{-\lambda t}$ is monotonically decreasing and thus reaches its maximum on the interval $[\frac{i}{n},\frac{i+1}{n}]$ at $\frac{i}{n}$. The approximation with upper Riemann sum for integral $I_n$ is  $$ I_n = \int_0^{n}e^{-\lambda t}S(t)udt \leq \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)u $$ and for integral $J_n$ is $$ J_n = \int_0^{n}e^{-\lambda t}S(t)Audt \leq \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)Au $$ Is this OK? Then i define sequences $\{ I_{n,k} \}_k = I_{n,1},I_{n,2},\dots$ and $\{ J_{n,k} \}_k = J_{n,1},J_{n,2},\dots$ where  $$ I_{n,k} = \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)u $$ and $$ J_{n,k} = \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)Au $$ Then $I_{n,k} \to I_{n}$ when $k \to \infty$ and $J_{n,k} \to J_{n}$ when $k \to \infty$. Here i also struggle...Is the following true? $$ A(I_{n,k}) = A(\sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}S(t)u) = \sum_{i=1}^k \frac{n}{k} e^{-\lambda(i-1)\frac{n}{k}}\max_{t \in [(i-1)\frac{n}{k},i\frac{n}{k}]}AS(t)u $$ I know $A$ is linear ($Au=\lim_{t\to 0+} \frac{S(t)u-u}{t}$) but what can i do with the $\max$? I then use a proven fact in the book, $AS(t)u = S(t)Au$ to get $A(I_{n,k}) = J_{n,k}$. I have $A(I_{n,k}) \to J_n$ and since $A$ is closed i have $A(I_n) = J_n$. Therefore $A(I_n) \to J$. Using again closedness of $A$ i conclude $A(I)=J$.",,"['calculus', 'functional-analysis', 'measure-theory', 'operator-theory']"
35,Quotients of the maximal tensor product,Quotients of the maximal tensor product,,"Let $A$ and $B$ be C*-algebras and let $\gamma$ be any C*-norm on the algebraic tensor product $A\odot B$. Why is $A\otimes_\gamma B$ a quotient of $A\otimes_{{\rm max}}B$, where $\otimes_{{\rm max}}$ stands for the maximal tensor product of C*-algebras? How does this quotient map look like?","Let $A$ and $B$ be C*-algebras and let $\gamma$ be any C*-norm on the algebraic tensor product $A\odot B$. Why is $A\otimes_\gamma B$ a quotient of $A\otimes_{{\rm max}}B$, where $\otimes_{{\rm max}}$ stands for the maximal tensor product of C*-algebras? How does this quotient map look like?",,"['functional-analysis', 'tensor-products', 'operator-algebras', 'c-star-algebras']"
36,"Proving $\,f$ is constant.",Proving  is constant.,"\,f","Let $\,f:[a,b] \rightarrow  \Bbb R $ be  continuous  and  $\int_a^b f(x)g(x)\,dx=0$, whenever $g:[a,b] \rightarrow  \Bbb R $ is  continuous and $\int_a^b g(x)\,dx=0$. Show that $f$ is a constant function. I tried a bunch of things including the mid-point integral theorem(?) but to no avail. I'd appreciate an explanation of a solution because I really don't see where to go with this one..","Let $\,f:[a,b] \rightarrow  \Bbb R $ be  continuous  and  $\int_a^b f(x)g(x)\,dx=0$, whenever $g:[a,b] \rightarrow  \Bbb R $ is  continuous and $\int_a^b g(x)\,dx=0$. Show that $f$ is a constant function. I tried a bunch of things including the mid-point integral theorem(?) but to no avail. I'd appreciate an explanation of a solution because I really don't see where to go with this one..",,"['calculus', 'real-analysis', 'integration', 'analysis', 'functional-analysis']"
37,Monotonicity of $\mathcal{l^p}$ spaces using only Hoelder inequality,Monotonicity of  spaces using only Hoelder inequality,\mathcal{l^p},"For $p > 0$, let $\ell^p$ be the space of sequences for which  $$\sum_{i=1}^{\infty} |a_i|^p$$  is finite ($a_i \in \mathbb{R}$). It is well-known that, for $q > p$, $$\ell^p \subset \ell^q.$$ Can this be shown only using the Hoelder inequality for such sequence spaces (which I know/can prove, so it can be assumed)? I remember the Jensen Inequality proof for the similar statement for the monotonicity for $\mathcal{L_p}$ spaces, but there should be a clever way of just using Hoelder - I think -, and I am blanking on how to do it.","For $p > 0$, let $\ell^p$ be the space of sequences for which  $$\sum_{i=1}^{\infty} |a_i|^p$$  is finite ($a_i \in \mathbb{R}$). It is well-known that, for $q > p$, $$\ell^p \subset \ell^q.$$ Can this be shown only using the Hoelder inequality for such sequence spaces (which I know/can prove, so it can be assumed)? I remember the Jensen Inequality proof for the similar statement for the monotonicity for $\mathcal{L_p}$ spaces, but there should be a clever way of just using Hoelder - I think -, and I am blanking on how to do it.",,"['functional-analysis', 'lp-spaces']"
38,"Examples of $f \in L^p$ iff $p_0 < p < p_1$, $p_0 \le p \le p_1$ or $p = p_0$","Examples of  iff ,  or",f \in L^p p_0 < p < p_1 p_0 \le p \le p_1 p = p_0,"Suppose $0 < p_0 < p_1 \leq \infty$. Find examples of functions $f$ on $(0,\infty)$ with Lebesgue measure such that $f \in L^p$ if and only if (a) $p_0 < p < p_1$ (b) $p_0 \leq p \leq p_1$ (c) $p=p_0$ The hint says consider functions of the form $f(x) = x^{-a}|\log x|^b$ but the hint does not help since integral is divergent for any choice of $a$ and $b$ Thank you for your time!","Suppose $0 < p_0 < p_1 \leq \infty$. Find examples of functions $f$ on $(0,\infty)$ with Lebesgue measure such that $f \in L^p$ if and only if (a) $p_0 < p < p_1$ (b) $p_0 \leq p \leq p_1$ (c) $p=p_0$ The hint says consider functions of the form $f(x) = x^{-a}|\log x|^b$ but the hint does not help since integral is divergent for any choice of $a$ and $b$ Thank you for your time!",,"['real-analysis', 'analysis', 'functional-analysis', 'lp-spaces']"
39,SOT limit of Self-adjoint operators is self-adjoint?,SOT limit of Self-adjoint operators is self-adjoint?,,"Say $T_n$ is a sequence of self-adjoint operators on a Hilbert space and converges in the strong operator topology to $\mathcal{T}$, must $\mathcal{T}$ be self-adjoint? Since $T_nx$ converges to $\mathcal{T}x$ in norm, it converges weakly, and so I figured that $\langle\mathcal{T}x,x\rangle-\langle x,\mathcal{T}x\rangle=\lim_{n\to \infty}\langle T_nx, x\rangle-\langle x, T_nx\rangle=0,$ which does the job, but there's a chance that my limit operators aren't justified. Thanks.","Say $T_n$ is a sequence of self-adjoint operators on a Hilbert space and converges in the strong operator topology to $\mathcal{T}$, must $\mathcal{T}$ be self-adjoint? Since $T_nx$ converges to $\mathcal{T}x$ in norm, it converges weakly, and so I figured that $\langle\mathcal{T}x,x\rangle-\langle x,\mathcal{T}x\rangle=\lim_{n\to \infty}\langle T_nx, x\rangle-\langle x, T_nx\rangle=0,$ which does the job, but there's a chance that my limit operators aren't justified. Thanks.",,['functional-analysis']
40,Banach contraction theorem for partially defined maps,Banach contraction theorem for partially defined maps,,"Let $(X,d)$ be a metric space and let $(f,D(f))$ be a partially defined map on $X$, i.e. $D(f)\subset X$ and $$   f:D(f)\to X. $$ Suppose that $f$ is a contraction, i.e. $$   d(f(x),f(y))\leq \rho\cdot d(x,y),\quad \text{for any }x,y\in D(f) $$ for some $\rho \in [0,1)$ and that there exists a point $x\in D(f)$ such that $f^n(x)\in D(f)$ for any $n=0,1,2,\dots$ Is that true, that the solution of $z = f(z)$ need to exist and be unique? If yes, is it possible to approximate this solution in terms of $f^n(x)$ and $\rho$? If not, are there any additional assumptions that can guarantee the uniqueness and existence? Any hints are appreciated.","Let $(X,d)$ be a metric space and let $(f,D(f))$ be a partially defined map on $X$, i.e. $D(f)\subset X$ and $$   f:D(f)\to X. $$ Suppose that $f$ is a contraction, i.e. $$   d(f(x),f(y))\leq \rho\cdot d(x,y),\quad \text{for any }x,y\in D(f) $$ for some $\rho \in [0,1)$ and that there exists a point $x\in D(f)$ such that $f^n(x)\in D(f)$ for any $n=0,1,2,\dots$ Is that true, that the solution of $z = f(z)$ need to exist and be unique? If yes, is it possible to approximate this solution in terms of $f^n(x)$ and $\rho$? If not, are there any additional assumptions that can guarantee the uniqueness and existence? Any hints are appreciated.",,"['real-analysis', 'functional-analysis']"
41,Lebesgue integrability of continuous function in closed interval,Lebesgue integrability of continuous function in closed interval,,"I'm trying to show that a continuous function $f$ in $[a,b]$ is Lebesgue integrable, using approximation through step functions. It is pretty trivial to show using the connection between Riemann integral and Lebesgue integral. But I have to show it only using step functions approximation. Using the definition of Lebesgue integral which uses step functions approximation seemed to be easy but I'm confused. Thanks for any help","I'm trying to show that a continuous function $f$ in $[a,b]$ is Lebesgue integrable, using approximation through step functions. It is pretty trivial to show using the connection between Riemann integral and Lebesgue integral. But I have to show it only using step functions approximation. Using the definition of Lebesgue integral which uses step functions approximation seemed to be easy but I'm confused. Thanks for any help",,"['functional-analysis', 'lebesgue-integral']"
42,using uniform boundedness principle,using uniform boundedness principle,,I have a sequence of numbers $x_n$ that satisfy that for every $y_n \in c_0$ (when $c_0$ is a Banach space  of all the complex sequences that satisfy $\lim_{n\rightarrow \infty }{a_n} =0$ ) the series $\sum_1^\infty{x_ny_n} $ convergence .How do I show that $x_n \in l^1 $ ? Maybe using uniform boundedness principle will help me ? Thanks for your help.,I have a sequence of numbers $x_n$ that satisfy that for every $y_n \in c_0$ (when $c_0$ is a Banach space  of all the complex sequences that satisfy $\lim_{n\rightarrow \infty }{a_n} =0$ ) the series $\sum_1^\infty{x_ny_n} $ convergence .How do I show that $x_n \in l^1 $ ? Maybe using uniform boundedness principle will help me ? Thanks for your help.,,"['functional-analysis', 'banach-spaces']"
43,Normed linear space and linear functional,Normed linear space and linear functional,,"Let $X$ be the normed linear spaceof sequences of reals that have only finitely many non-zero terms. Given $x = \{x_n\} \in X$, define $$f(x) = \displaystyle \sum_{n=1}^{\infty} x_n$$ I think that it is quite easy to prove that $f$ is linear (please correct me if you think otherwise). My question is whether $f$ is continuous if we give $X$ the topology induced by the $l^{\infty}$ norm. Thank you very much in advance!","Let $X$ be the normed linear spaceof sequences of reals that have only finitely many non-zero terms. Given $x = \{x_n\} \in X$, define $$f(x) = \displaystyle \sum_{n=1}^{\infty} x_n$$ I think that it is quite easy to prove that $f$ is linear (please correct me if you think otherwise). My question is whether $f$ is continuous if we give $X$ the topology induced by the $l^{\infty}$ norm. Thank you very much in advance!",,"['analysis', 'functional-analysis']"
44,Estimate on the norm of a self-adjoint operator,Estimate on the norm of a self-adjoint operator,,"EDIT: thks to Martin's comment I realize the previous version was wrong. Here is the correct version of what I need to show: I am trying to show that if $A$ is a self - adjoint operator in a Hilbert space $H$ then  $$ \|A\| \le \sup_{\|x\| = 1}   |\langle x, Ax \rangle| $$ I am given the fact that whenever $\|x\| = \|y\| = 1$ we have $$ |\langle x,Ay\rangle| \le \sup_{\|x\| = 1} \langle x,Ax \rangle. $$  I am really stuck with this one, any bhint would be highly appreciated, many thanks !!","EDIT: thks to Martin's comment I realize the previous version was wrong. Here is the correct version of what I need to show: I am trying to show that if $A$ is a self - adjoint operator in a Hilbert space $H$ then  $$ \|A\| \le \sup_{\|x\| = 1}   |\langle x, Ax \rangle| $$ I am given the fact that whenever $\|x\| = \|y\| = 1$ we have $$ |\langle x,Ay\rangle| \le \sup_{\|x\| = 1} \langle x,Ax \rangle. $$  I am really stuck with this one, any bhint would be highly appreciated, many thanks !!",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
45,What is the domain of $\vert \Delta\vert^{1/2}$?,What is the domain of ?,\vert \Delta\vert^{1/2},"Assume $U$ is a bounded open subset of $\mathbb{R}^N$. Furthermore $\Delta: H^2(U) \subset L^2(U) \to L^2(U)$ is the Laplace operator. My question is: What is the domain of $\vert \Delta\vert^{1/2}$? I've seen this notation a lot recently and still don't know what to make of it. First of all the Laplace operator is not a positive operator. I guess, that is what the $\vert \cdot \vert$ is for. Here is a definition of the root of $-\Delta$, which suggests that the domain could be $L^1 (U)$. It would be perfect for my cause, if the domain could be taken as $H^2(U)$ again.","Assume $U$ is a bounded open subset of $\mathbb{R}^N$. Furthermore $\Delta: H^2(U) \subset L^2(U) \to L^2(U)$ is the Laplace operator. My question is: What is the domain of $\vert \Delta\vert^{1/2}$? I've seen this notation a lot recently and still don't know what to make of it. First of all the Laplace operator is not a positive operator. I guess, that is what the $\vert \cdot \vert$ is for. Here is a definition of the root of $-\Delta$, which suggests that the domain could be $L^1 (U)$. It would be perfect for my cause, if the domain could be taken as $H^2(U)$ again.",,"['functional-analysis', 'operator-theory']"
46,"If $f\in L^1[0,1]\cap L^2[0,1]$, then $\|f\|_1 \le \|f\|_2$.","If , then .","f\in L^1[0,1]\cap L^2[0,1] \|f\|_1 \le \|f\|_2","This problem has two parts: (a) If $f\in L^1[0,1]\cap L^2[0,1]$, then $\|f\|_1 \le \|f\|_2$. (b) Use (a) to deduce that $L^2[0,1]$ is a subset of $L^1[0,1]$. Without using part (a), let $f$$\in$$L^2[0,1]$. Since the constant function $1$ $\in$ $L^2[0,1]$, by Holder inequality, we can conclude that $\|f\|_1$$\le$$\|f\|_2\|1\|_2$$=\|f\|_2$. But how can you deduce part (b) from part (a)? Also, how do you prove the claim in part (a)?","This problem has two parts: (a) If $f\in L^1[0,1]\cap L^2[0,1]$, then $\|f\|_1 \le \|f\|_2$. (b) Use (a) to deduce that $L^2[0,1]$ is a subset of $L^1[0,1]$. Without using part (a), let $f$$\in$$L^2[0,1]$. Since the constant function $1$ $\in$ $L^2[0,1]$, by Holder inequality, we can conclude that $\|f\|_1$$\le$$\|f\|_2\|1\|_2$$=\|f\|_2$. But how can you deduce part (b) from part (a)? Also, how do you prove the claim in part (a)?",,['functional-analysis']
47,Gateaux Differentiation in Infinite Dimensional Space,Gateaux Differentiation in Infinite Dimensional Space,,"Let $X, Y$ be Banach spaces. A mapping $F: X\rightarrow Y$ is said to be Gateaux differentiable at $x_0\in X$ iff there exists a continuous linear mapping $A: X\rightarrow Y$ such that $$ \textbf{(*)} \quad \lim_{t\downarrow 0}\frac{F(x_0+th)-F(x_0)}{t}=A(h) \quad \forall h\in X. $$ I would like to construct a nonlinear mapping $F: X\rightarrow Y$ that is not Gateaux differentiable at  $x_0\in X$ but there exists a discontinuous linear mapping $A: X\rightarrow Y$ such that (*) is satisfied. Thank you for all comments and helping.","Let $X, Y$ be Banach spaces. A mapping $F: X\rightarrow Y$ is said to be Gateaux differentiable at $x_0\in X$ iff there exists a continuous linear mapping $A: X\rightarrow Y$ such that $$ \textbf{(*)} \quad \lim_{t\downarrow 0}\frac{F(x_0+th)-F(x_0)}{t}=A(h) \quad \forall h\in X. $$ I would like to construct a nonlinear mapping $F: X\rightarrow Y$ that is not Gateaux differentiable at  $x_0\in X$ but there exists a discontinuous linear mapping $A: X\rightarrow Y$ such that (*) is satisfied. Thank you for all comments and helping.",,"['functional-analysis', 'banach-spaces', 'gateaux-derivative']"
48,Representation of linear functionals,Representation of linear functionals,,"I have always seen the linear functionals in $R^n$ expressed at $\ell(x) = \sum_{i=0}^n a_ix_i$ And in an countable metric space $\ell(x) = \sum_{i=0}^{\infty} a_ix_i$. I guess that this follows directly from http://en.wikipedia.org/wiki/Riesz_representation_theorem , for Hilbert spaces. But what if we are not in an Hilbert space or if the space is uncountable. If X was a 1 dimensional space I would get $f(x) = f(1)x$ by continuity and linearity (by derivation and integration) and by partial derivation it would look like $f(x) = \sum_{i=0}^n f(1)x_i$ for the n dimensional case","I have always seen the linear functionals in $R^n$ expressed at $\ell(x) = \sum_{i=0}^n a_ix_i$ And in an countable metric space $\ell(x) = \sum_{i=0}^{\infty} a_ix_i$. I guess that this follows directly from http://en.wikipedia.org/wiki/Riesz_representation_theorem , for Hilbert spaces. But what if we are not in an Hilbert space or if the space is uncountable. If X was a 1 dimensional space I would get $f(x) = f(1)x$ by continuity and linearity (by derivation and integration) and by partial derivation it would look like $f(x) = \sum_{i=0}^n f(1)x_i$ for the n dimensional case",,['functional-analysis']
49,Linear extension and Hahn Banach Theorem. Am I missing some detail in this exercise?,Linear extension and Hahn Banach Theorem. Am I missing some detail in this exercise?,,"This is an exercise problem from a course in functional analysis. However, it is not a homework problem. I think I got it figured out, however my teacher said something during the lecture that I didn't understand, and was lagging behind with taking notes, so I thought I'd think about it at home rather than ask during lecture. Now I can't make sense out of what she said, and I'd rather not wait until the next lecture to ask her. Here's where you guys come in :) Exercise: Show that there exists a non-zero linear functional $F \in (L^\infty[a, b])^\ast$ such that for any $f \in C[a, b]$, $F(f) = f((a + b)/2)$ My Solution: In $L^\infty[a, b]$ we identify all functions that are equal almost everywhere. In each such equivalence class there exist a continuous function and we let that function represent the equivalence class. Therefore we can conclude that $C[a,b] \subseteq L^\infty[a, b]$. Note that $\| \cdot \|_\infty$ is a norm on $L^\infty[a, b]$ (Hahn-Banach requires only semi-norm). Now define $F(f) = f((a + b)/2)$ on C[a,b]. This is linear and bounded functional, $$F(\lambda f + \mu g) = (\lambda f + \mu g)\left(\frac{a + b}{2}\right) = \lambda f\left(\frac{a + b}{2}\right) + \mu g\left(\frac{a + b}{2}\right) = \lambda F(f) + \mu F(g)$$ $$|F(f)| = \left| f\left(\frac{a + b}{2}\right) \right| \leq \| f \|_\infty $$ By Hahn-Banach Theorem we can extend $F$ to $L^\infty[a, b]$ with the same norm such that $F(f) \leq \| f \|_\infty$, $\forall f \in L^\infty[a, b]$. Hence $F \in (L^\infty[a, b])^\ast$ Is this a complete solution? My teacher pointed something out, that I couldn't really grasp because I was behind on taking notes. But this is what she said basically: Teacher's comment: You can try to show that this $F$ does not come from $f \in L^1[a, b]$ i.e. $F \neq \phi_f$ where $$ \phi_f(g) = \int_a^b fg dx.$$ Does this make any sense? Why is this relevant? I can't see how, but at the same time I am afraid of missing some detail here. Thank you very much in advance!","This is an exercise problem from a course in functional analysis. However, it is not a homework problem. I think I got it figured out, however my teacher said something during the lecture that I didn't understand, and was lagging behind with taking notes, so I thought I'd think about it at home rather than ask during lecture. Now I can't make sense out of what she said, and I'd rather not wait until the next lecture to ask her. Here's where you guys come in :) Exercise: Show that there exists a non-zero linear functional $F \in (L^\infty[a, b])^\ast$ such that for any $f \in C[a, b]$, $F(f) = f((a + b)/2)$ My Solution: In $L^\infty[a, b]$ we identify all functions that are equal almost everywhere. In each such equivalence class there exist a continuous function and we let that function represent the equivalence class. Therefore we can conclude that $C[a,b] \subseteq L^\infty[a, b]$. Note that $\| \cdot \|_\infty$ is a norm on $L^\infty[a, b]$ (Hahn-Banach requires only semi-norm). Now define $F(f) = f((a + b)/2)$ on C[a,b]. This is linear and bounded functional, $$F(\lambda f + \mu g) = (\lambda f + \mu g)\left(\frac{a + b}{2}\right) = \lambda f\left(\frac{a + b}{2}\right) + \mu g\left(\frac{a + b}{2}\right) = \lambda F(f) + \mu F(g)$$ $$|F(f)| = \left| f\left(\frac{a + b}{2}\right) \right| \leq \| f \|_\infty $$ By Hahn-Banach Theorem we can extend $F$ to $L^\infty[a, b]$ with the same norm such that $F(f) \leq \| f \|_\infty$, $\forall f \in L^\infty[a, b]$. Hence $F \in (L^\infty[a, b])^\ast$ Is this a complete solution? My teacher pointed something out, that I couldn't really grasp because I was behind on taking notes. But this is what she said basically: Teacher's comment: You can try to show that this $F$ does not come from $f \in L^1[a, b]$ i.e. $F \neq \phi_f$ where $$ \phi_f(g) = \int_a^b fg dx.$$ Does this make any sense? Why is this relevant? I can't see how, but at the same time I am afraid of missing some detail here. Thank you very much in advance!",,['functional-analysis']
50,Proof that certain operators are compact,Proof that certain operators are compact,,"I want to examine which of the following operators $T \colon C[0,1] \to C[0,1]$. are compact, by some I think I got the argument, but others I have no idea. a) $Tx(t) = x(t^2)$ Guess it is compact, but I have no idea how to proof this? b) $Tx(t) = x(0) + tx(1)$ Here the range of $T$ consist of lines, i.e. the set $\{ n + m \cdot x : n,m \in \mathbb{R} \}$, this set is finite-dimensional because $\{ \mathbb{1}, \operatorname{id} \}$ are a base ($1$ denotes the constant function $1(x) = 1$ for all $x$). c) $Tx(t) = \int_0^1 e^{st} x(s) \mathrm{d}s$ This is compact according to example A.2 from Appendix A: Compact Operators d) $Tx(t) = \sum_{k=1}^{\infty} x(\frac{1}{k}) \frac{t^k}{k!}$ Guess here I could use arguments similar to those How to prove that an operator is compact? Proof that operator is compact because $x(\frac{1}{x})$ is bounded on $[0,1]$ and the series $\sum_{k=1}^{\infty} \frac{t^k}{k!}$ converges to $e^t - 1$. e) $Tx(t) = \sum_{k=0}^{\infty} \frac{x(t^k)}{k!}$. Here I have no idea how to proof or disproof compactness of $T$? f) $Tx(t) = \int_0^t x(s) \mathrm{d} s$ Here I have no glue too....","I want to examine which of the following operators $T \colon C[0,1] \to C[0,1]$. are compact, by some I think I got the argument, but others I have no idea. a) $Tx(t) = x(t^2)$ Guess it is compact, but I have no idea how to proof this? b) $Tx(t) = x(0) + tx(1)$ Here the range of $T$ consist of lines, i.e. the set $\{ n + m \cdot x : n,m \in \mathbb{R} \}$, this set is finite-dimensional because $\{ \mathbb{1}, \operatorname{id} \}$ are a base ($1$ denotes the constant function $1(x) = 1$ for all $x$). c) $Tx(t) = \int_0^1 e^{st} x(s) \mathrm{d}s$ This is compact according to example A.2 from Appendix A: Compact Operators d) $Tx(t) = \sum_{k=1}^{\infty} x(\frac{1}{k}) \frac{t^k}{k!}$ Guess here I could use arguments similar to those How to prove that an operator is compact? Proof that operator is compact because $x(\frac{1}{x})$ is bounded on $[0,1]$ and the series $\sum_{k=1}^{\infty} \frac{t^k}{k!}$ converges to $e^t - 1$. e) $Tx(t) = \sum_{k=0}^{\infty} \frac{x(t^k)}{k!}$. Here I have no idea how to proof or disproof compactness of $T$? f) $Tx(t) = \int_0^t x(s) \mathrm{d} s$ Here I have no glue too....",,"['analysis', 'functional-analysis', 'operator-theory', 'compact-operators']"
51,Weak derivative of a Lipschitz function,Weak derivative of a Lipschitz function,,"Let $f \in C^\infty_c(\mathbb{R})^*$ be a distribution. How can I show the following: $$f \in C^{0,1}(\mathbb{R}) \Leftrightarrow f \in L^\infty(\mathbb{R}) \text{ and } f' \in L^\infty(\mathbb{R}) \text{.}$$ Here $C^{0,1}(\mathbb{R})$ is the space of bounded Lipschitz functions on $\mathbb{R}$ and $f'$ is the distributional derivative of $f$.","Let $f \in C^\infty_c(\mathbb{R})^*$ be a distribution. How can I show the following: $$f \in C^{0,1}(\mathbb{R}) \Leftrightarrow f \in L^\infty(\mathbb{R}) \text{ and } f' \in L^\infty(\mathbb{R}) \text{.}$$ Here $C^{0,1}(\mathbb{R})$ is the space of bounded Lipschitz functions on $\mathbb{R}$ and $f'$ is the distributional derivative of $f$.",,['functional-analysis']
52,Proof of an inequality of $L^p$ norms,Proof of an inequality of  norms,L^p,"For a general measure space, we define : $\|f\|_p= \left(\int\vert f\vert^p du\right)^{1/p}$.  Let $0 < a < b < c < \infty$ and prove the following: $$ \|f\|_b \leqslant \max\{\|f\|_a, \|f\|_c\}. $$ Any help is appreciated because I dont understand the solution underneath","For a general measure space, we define : $\|f\|_p= \left(\int\vert f\vert^p du\right)^{1/p}$.  Let $0 < a < b < c < \infty$ and prove the following: $$ \|f\|_b \leqslant \max\{\|f\|_a, \|f\|_c\}. $$ Any help is appreciated because I dont understand the solution underneath",,"['functional-analysis', 'inequality', 'normed-spaces', 'lp-spaces']"
53,"Closed subspace of $L^1[0,1]$",Closed subspace of,"L^1[0,1]","The statement I need to prove is following.  Let $S$ be a closed subspace of Lebesgue space $L^1[0,1].$ Assume that for every $f\in S$ there exists a number $p(f)>1$ such that $f\in L^{p(f)}[0,1].$ Then there exists a number $p>1$ such that $S\subset L^p[0,1].$ As far as I understand, this problem is related to Baire theorem. Hence, I write $S=\bigcup^{\infty}_{n=1}( S\cap L^{1+1/n} [0,1])$ and conclude that for some $n$  closure of $S\cap L^{1+1/n} [0,1]$ has nonempty interior. But how can I proceed further to show that it lies in some $L^{1+1/m}$?","The statement I need to prove is following.  Let $S$ be a closed subspace of Lebesgue space $L^1[0,1].$ Assume that for every $f\in S$ there exists a number $p(f)>1$ such that $f\in L^{p(f)}[0,1].$ Then there exists a number $p>1$ such that $S\subset L^p[0,1].$ As far as I understand, this problem is related to Baire theorem. Hence, I write $S=\bigcup^{\infty}_{n=1}( S\cap L^{1+1/n} [0,1])$ and conclude that for some $n$  closure of $S\cap L^{1+1/n} [0,1]$ has nonempty interior. But how can I proceed further to show that it lies in some $L^{1+1/m}$?",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
54,Finding the norm of the operators,Finding the norm of the operators,,"How do I find the norm of the following operator i.e. how to find $\lVert T_z\rVert$ and $\lVert l\rVert$? 1) Let $z\in \ell^\infty$ and $T_z\colon \ell^p\to\ell^p$ with $$(T_zx)(n)=z(n)\cdot x(n).$$ What my thoughts were to use Banach-Steinhaus theorem but it seems straight forward and I don't know if I am right. $\lVert T_z\rVert _p \leqslant\lVert z\lVert \cdot n\cdot\lVert x\rVert_p n=n^2\lVert x\rVert _p$ so if I choose $x=1$ then I get $\lVert T_z\rVert =n^2$. 2) Let $0\leqslant t_1\leqslant\cdots\leqslant t_n=1$ and $\alpha_1,\dots,\alpha_n \in K$ , $l\colon C([0,1])\to K$ with $l(x)=\sum_{i=1}^n \alpha_i x(t_i)$. How to I find operator norm in this case as well?  I am quite sure I am not right. I would be glad if I could get some help.  Definitely some hints would be great! Thanks in advance.","How do I find the norm of the following operator i.e. how to find $\lVert T_z\rVert$ and $\lVert l\rVert$? 1) Let $z\in \ell^\infty$ and $T_z\colon \ell^p\to\ell^p$ with $$(T_zx)(n)=z(n)\cdot x(n).$$ What my thoughts were to use Banach-Steinhaus theorem but it seems straight forward and I don't know if I am right. $\lVert T_z\rVert _p \leqslant\lVert z\lVert \cdot n\cdot\lVert x\rVert_p n=n^2\lVert x\rVert _p$ so if I choose $x=1$ then I get $\lVert T_z\rVert =n^2$. 2) Let $0\leqslant t_1\leqslant\cdots\leqslant t_n=1$ and $\alpha_1,\dots,\alpha_n \in K$ , $l\colon C([0,1])\to K$ with $l(x)=\sum_{i=1}^n \alpha_i x(t_i)$. How to I find operator norm in this case as well?  I am quite sure I am not right. I would be glad if I could get some help.  Definitely some hints would be great! Thanks in advance.",,"['functional-analysis', 'operator-theory', 'normed-spaces']"
55,Does $(x_n)$ Cauchy in $\ell^1$ implies $(\|x_n\|_1)$ is Cauchy in $\mathbb F$,Does  Cauchy in  implies  is Cauchy in,(x_n) \ell^1 (\|x_n\|_1) \mathbb F,"Define $\ell^1=\{x\colon\mathbb N\to\mathbb F: \|x\|_1~\mbox{is finite}\}$ where $\mathbb F$ is either $\mathbb R$ or $\mathbb C$. If $(x_n)$ is a Cauchy sequence in $\ell^1$, does that mean that $(\|x_n\|)$ is Cauchy in $\mathbb F?$","Define $\ell^1=\{x\colon\mathbb N\to\mathbb F: \|x\|_1~\mbox{is finite}\}$ where $\mathbb F$ is either $\mathbb R$ or $\mathbb C$. If $(x_n)$ is a Cauchy sequence in $\ell^1$, does that mean that $(\|x_n\|)$ is Cauchy in $\mathbb F?$",,"['functional-analysis', 'metric-spaces', 'banach-spaces']"
56,Functional Analysis - Banach-Steinhaus theorem,Functional Analysis - Banach-Steinhaus theorem,,"How can I use the Banach-Steinhaus' Uniform boundedness principle in order to prove the following claim: If $x_n$ is a sequence of complex numbers such that the series $\sum_1^\infty x_n \chi_n$  converges for every sequence $ \chi_n \in l_p $ ($1 \leq p < \infty $ ) , then $x_n \in l_q $  where $ \frac{1}{p} + \frac{1}{q} = 1 $ . Thanks in advance!","How can I use the Banach-Steinhaus' Uniform boundedness principle in order to prove the following claim: If $x_n$ is a sequence of complex numbers such that the series $\sum_1^\infty x_n \chi_n$  converges for every sequence $ \chi_n \in l_p $ ($1 \leq p < \infty $ ) , then $x_n \in l_q $  where $ \frac{1}{p} + \frac{1}{q} = 1 $ . Thanks in advance!",,['functional-analysis']
57,Map bounded if composition is bounded,Map bounded if composition is bounded,,"Let $X,Y,Z$ Banach spaces and $A:X\rightarrow Y$ and $B:Y\rightarrow Z$ linear maps with $B$ bounded and injective and $BA$ bounded. Prove that $A$ is bounded as well. If I knew that $B(Y)$ is closed I'd have a bounded linear map $B^{-1}:B(Y)\rightarrow Y$ by the bounded inverse theorem. Therefore $A=B^{-1}BA$ is bounded. How to prove the claim if $B(Y)$ is not closed.","Let $X,Y,Z$ Banach spaces and $A:X\rightarrow Y$ and $B:Y\rightarrow Z$ linear maps with $B$ bounded and injective and $BA$ bounded. Prove that $A$ is bounded as well. If I knew that $B(Y)$ is closed I'd have a bounded linear map $B^{-1}:B(Y)\rightarrow Y$ by the bounded inverse theorem. Therefore $A=B^{-1}BA$ is bounded. How to prove the claim if $B(Y)$ is not closed.",,"['real-analysis', 'functional-analysis', 'banach-spaces']"
58,"Is it possible to 'approximate' compact, convex sets in $\ell^2$ by the Hilbert cube","Is it possible to 'approximate' compact, convex sets in  by the Hilbert cube",\ell^2,"Define $H=\{(x_n)_n\in\ell^2:|x_n|\le \frac1n, n\in\mathbf N\}\subset\ell^2$. This set is known as the Hilbert cube and it is well-known that $H$ is compact, convex and non-empty. Let $\overline{\mathrm{conv}}(C)$ denote the closure of the convex hull of a subset $C\subset\ell^2$. Suppose $S$ is a non-empty, compact, convex subset of $\ell^2$, is it possible to write$$S=\overline{\mathrm{conv}}\left(\bigcup_{n=1}^\infty[ S\cap(n\cdot H)]\right),$$ where (for $n\in\mathbf N$ fixed) $n\cdot H=\{n\cdot x:x\in H\}$. I think it is possible (since the Hilbert cube keeps getting 'thinner' in each coordinate), but I do not know how to prove it.","Define $H=\{(x_n)_n\in\ell^2:|x_n|\le \frac1n, n\in\mathbf N\}\subset\ell^2$. This set is known as the Hilbert cube and it is well-known that $H$ is compact, convex and non-empty. Let $\overline{\mathrm{conv}}(C)$ denote the closure of the convex hull of a subset $C\subset\ell^2$. Suppose $S$ is a non-empty, compact, convex subset of $\ell^2$, is it possible to write$$S=\overline{\mathrm{conv}}\left(\bigcup_{n=1}^\infty[ S\cap(n\cdot H)]\right),$$ where (for $n\in\mathbf N$ fixed) $n\cdot H=\{n\cdot x:x\in H\}$. I think it is possible (since the Hilbert cube keeps getting 'thinner' in each coordinate), but I do not know how to prove it.",,"['functional-analysis', 'hilbert-spaces', 'convex-analysis', 'compactness']"
59,Differentiation continuous iff domain is finite dimensional,Differentiation continuous iff domain is finite dimensional,,"Let $A\subset C([0,1])$ a closed linear subspace with respect to the usual supremum norm satisfying $A\subset C^1([0,1])$. Is $D\colon A\rightarrow C([0,1]), \ f\rightarrow f'$ continuous iff $A$ is finite dimensional? If $A$ is finite dimensional $D$ is continuous of course. But is the other implication true at all? Wouldn't something like $A:=\overline{\text{span}\{\sin{\left(t+\frac{1}{n}\right)} \ | \ n\in\mathbb{N}\}}$ be a counterexample?","Let $A\subset C([0,1])$ a closed linear subspace with respect to the usual supremum norm satisfying $A\subset C^1([0,1])$. Is $D\colon A\rightarrow C([0,1]), \ f\rightarrow f'$ continuous iff $A$ is finite dimensional? If $A$ is finite dimensional $D$ is continuous of course. But is the other implication true at all? Wouldn't something like $A:=\overline{\text{span}\{\sin{\left(t+\frac{1}{n}\right)} \ | \ n\in\mathbb{N}\}}$ be a counterexample?",,"['real-analysis', 'functional-analysis', 'vector-spaces']"
60,Fourier Transform of a derivative + Bochner's theorem about positive definite functions,Fourier Transform of a derivative + Bochner's theorem about positive definite functions,,"I've been reading about Bochner's Theorem lately, but when I apply it to the derivative of a function, I seem to get a contradiction with the theorem. ""Bochner's theorem states that a   positive definite function is the   Fourier transform of a finite Borel   measure. As well, an easy converse of   this is that a Fourier transform must   be positive definite. "" - source So consider $f(x) \in L^1 (\mathbb{R})$ where $f(x) = \tfrac{1}{2} x^2$ if $-1 \leq x \leq 1$ and $0$ otherwise. Also consider $g(x) \in L^1 (\mathbb{R})$ where $g(x) = 1$ if $-1\leq x \leq 1$ and $0$ otherwise. Now Bochner's theorem states that the Fourier transform of each of these functions should be positive definite. One well known property of Positive Definite functions $h(\xi)$ is that: $h(0) \geq |h(x)|$ for all $x\in \mathbb{R}$. Now consider $\bar{g}$ and $\bar{f}$ the Fourier transforms of $g$ and $f$ respectively.  Since $g(x)=f''(x)$ (a.e.) then $\bar{g}(\xi) = \xi^2 \bar{f}(\xi)$ implying  $\bar{g}(0)=0$ By Bochner's Theorem we know $\bar{g}$ is positive definite, but then this implies that $\bar{g}$ is zero for all $\xi$. But one can see by the Fourier inversion theorem this would imply $g$ is zero a.e. Obviously this is a contradiction. I've been banging my head on this for days, can you let me know where the error in the reasoning is? I am wondering if there is a mistake in the statement '$\bar{g}(\xi) = \xi^2 \bar{f}(\xi)$' or in my understanding of positive definite functions or in my use of Bochner's theorem. Thanks in advance! Note, I know my examples of f and g are discontinuous. If this is the problem, it isn't actually a problem in my situation, so if it helps, consider a smooth mollification of g and let f be the anti-derivative of its antiderivative. Thanks!","I've been reading about Bochner's Theorem lately, but when I apply it to the derivative of a function, I seem to get a contradiction with the theorem. ""Bochner's theorem states that a   positive definite function is the   Fourier transform of a finite Borel   measure. As well, an easy converse of   this is that a Fourier transform must   be positive definite. "" - source So consider $f(x) \in L^1 (\mathbb{R})$ where $f(x) = \tfrac{1}{2} x^2$ if $-1 \leq x \leq 1$ and $0$ otherwise. Also consider $g(x) \in L^1 (\mathbb{R})$ where $g(x) = 1$ if $-1\leq x \leq 1$ and $0$ otherwise. Now Bochner's theorem states that the Fourier transform of each of these functions should be positive definite. One well known property of Positive Definite functions $h(\xi)$ is that: $h(0) \geq |h(x)|$ for all $x\in \mathbb{R}$. Now consider $\bar{g}$ and $\bar{f}$ the Fourier transforms of $g$ and $f$ respectively.  Since $g(x)=f''(x)$ (a.e.) then $\bar{g}(\xi) = \xi^2 \bar{f}(\xi)$ implying  $\bar{g}(0)=0$ By Bochner's Theorem we know $\bar{g}$ is positive definite, but then this implies that $\bar{g}$ is zero for all $\xi$. But one can see by the Fourier inversion theorem this would imply $g$ is zero a.e. Obviously this is a contradiction. I've been banging my head on this for days, can you let me know where the error in the reasoning is? I am wondering if there is a mistake in the statement '$\bar{g}(\xi) = \xi^2 \bar{f}(\xi)$' or in my understanding of positive definite functions or in my use of Bochner's theorem. Thanks in advance! Note, I know my examples of f and g are discontinuous. If this is the problem, it isn't actually a problem in my situation, so if it helps, consider a smooth mollification of g and let f be the anti-derivative of its antiderivative. Thanks!",,"['real-analysis', 'complex-analysis', 'functional-analysis', 'fourier-analysis']"
61,$C_0(X)$ is a closed subspace of $C_b(X)$,is a closed subspace of,C_0(X) C_b(X),"Can you tell me if my proof is correct? Thank you! Claim: $C_0(X)$ is a closed subspace of $C_b(X)$ Proof: We have to show that $C_0(X)$ contains all of its limit points. Let $f(x)$ be a limit point of it, then we have a sequence $f_n$ converging to it (in $\|\cdot\|_\infty$) hence $f_n$ is a Cauchy sequence (with respect to $\|\cdot\|_\infty$). Of course, $f$ is continuous since it's the uniform limit of a sequence of continuous functions. So we only have to show that $f(x)$ vanishes at $\pm \infty$ (apparently, $X \subset \mathbb R$? See here for a definition of $C_0(X)$. I'd have thought it's more general but then what does $x \to \infty$ mean in a general topological space?) Let $\varepsilon>0$. Let $N$ be such that $m,n \geq N$ implies $\|f_n - f_N\|_\infty \leq \varepsilon/2$. Then $$ |f(x)| \leq |f(x) - f_N(x)| + |f_N(x)| \leq \varepsilon$$ for $x \in X \setminus K_N$ where $|f_N(x)| \leq \varepsilon/2$ outside some $K_N$, $K_N$ compact. Also, for all $x$, $|f(x) - f_N(x)| = \lim_{m \to \infty} |f_m(x) - f_N(x)| \leq \varepsilon/2$ since $|f_m(x) - f_N(x)| \leq \|f_m - f_N\|_\infty \leq \varepsilon / 2$ for all $m > N$.","Can you tell me if my proof is correct? Thank you! Claim: $C_0(X)$ is a closed subspace of $C_b(X)$ Proof: We have to show that $C_0(X)$ contains all of its limit points. Let $f(x)$ be a limit point of it, then we have a sequence $f_n$ converging to it (in $\|\cdot\|_\infty$) hence $f_n$ is a Cauchy sequence (with respect to $\|\cdot\|_\infty$). Of course, $f$ is continuous since it's the uniform limit of a sequence of continuous functions. So we only have to show that $f(x)$ vanishes at $\pm \infty$ (apparently, $X \subset \mathbb R$? See here for a definition of $C_0(X)$. I'd have thought it's more general but then what does $x \to \infty$ mean in a general topological space?) Let $\varepsilon>0$. Let $N$ be such that $m,n \geq N$ implies $\|f_n - f_N\|_\infty \leq \varepsilon/2$. Then $$ |f(x)| \leq |f(x) - f_N(x)| + |f_N(x)| \leq \varepsilon$$ for $x \in X \setminus K_N$ where $|f_N(x)| \leq \varepsilon/2$ outside some $K_N$, $K_N$ compact. Also, for all $x$, $|f(x) - f_N(x)| = \lim_{m \to \infty} |f_m(x) - f_N(x)| \leq \varepsilon/2$ since $|f_m(x) - f_N(x)| \leq \|f_m - f_N\|_\infty \leq \varepsilon / 2$ for all $m > N$.",,"['functional-analysis', 'normed-spaces']"
62,Cauchy in Norm and Weakly converge Implies Norm convergent,Cauchy in Norm and Weakly converge Implies Norm convergent,,"Let $X$ be a normed space and $(x_n)$ is a Cauchy sequence in the norm sense. Also assume the $x_n \rightarrow x_0 $ weakly. Then $x_n \rightarrow x_0 $ in norm. What I did:Take $ \varepsilon >0 $ since $x_n$ is cauchy there a $n_0$ such that $ |\!| x_n-x_m |\!|< \epsilon$ $\forall n,m \geq n_0$ From Hahn Banach there are $x^{*} _n\, \in X^{*}$ such that $|\!| x_n-x_0 |\!| = | x^{*}_n (x_n-x_0)|$ and $|\!| x^{*}_n |\!|=1$. Hence  \begin{align} |\!| x_n-x_0 |\!| &= | x^{*}_n (x_n-x_0)|\\ &=| x^{*}_n (x_n-x_m+x_m-x_0)| \\ &\leq | x^{*}_n (x_n-x_m)|+| x^{*}_n (x_m-x_0)|\\ &\leq \varepsilon+| x^{*}_n (x_m-x_0)|. \end{align} Since the last inequality hold $\forall m \geq n_0$ we can take the limit in respect of $m$ and then we get $|\!| x_n-x_0 |\!| \leq \epsilon $ (Since   $x_n \rightarrow x_0 $  weakly). And then by definition we are done. Where I saw this exercise there was a hint. Hint Observe that $x_n \in x_m +\varepsilon B_X$ and $x_m+\varepsilon B_X$ is weakly closed. How do we proceed from there?","Let $X$ be a normed space and $(x_n)$ is a Cauchy sequence in the norm sense. Also assume the $x_n \rightarrow x_0 $ weakly. Then $x_n \rightarrow x_0 $ in norm. What I did:Take $ \varepsilon >0 $ since $x_n$ is cauchy there a $n_0$ such that $ |\!| x_n-x_m |\!|< \epsilon$ $\forall n,m \geq n_0$ From Hahn Banach there are $x^{*} _n\, \in X^{*}$ such that $|\!| x_n-x_0 |\!| = | x^{*}_n (x_n-x_0)|$ and $|\!| x^{*}_n |\!|=1$. Hence  \begin{align} |\!| x_n-x_0 |\!| &= | x^{*}_n (x_n-x_0)|\\ &=| x^{*}_n (x_n-x_m+x_m-x_0)| \\ &\leq | x^{*}_n (x_n-x_m)|+| x^{*}_n (x_m-x_0)|\\ &\leq \varepsilon+| x^{*}_n (x_m-x_0)|. \end{align} Since the last inequality hold $\forall m \geq n_0$ we can take the limit in respect of $m$ and then we get $|\!| x_n-x_0 |\!| \leq \epsilon $ (Since   $x_n \rightarrow x_0 $  weakly). And then by definition we are done. Where I saw this exercise there was a hint. Hint Observe that $x_n \in x_m +\varepsilon B_X$ and $x_m+\varepsilon B_X$ is weakly closed. How do we proceed from there?",,"['functional-analysis', 'convergence-divergence', 'normed-spaces']"
63,Show that a functional is a distribution,Show that a functional is a distribution,,"Consider the following functional $$   \langle u , \phi \rangle = \int_0^{\infty} \phi(t) \frac{\mathrm{d}t}{t^{\alpha}} $$ I want to show that it is a functional in $\mathcal{D'}{(\mathbb{R})}$. Because of the compact support of $\phi$, the indefinite integral could be made definite by an upper bound $C$. $$   \langle u , \phi \rangle = \int_0^{C} \phi(t) \frac{\mathrm{d}t}{t^{\alpha}} $$ So, first linearity is clear because of this property from the integral. $$  \langle u , a \phi + b \psi \rangle   =  \int_0^{C} (a \phi(t) + b \psi) \frac{\mathrm{d}t}{t^{\alpha}}   =  a \int_0^{C} \phi(t)\frac{\mathrm{d}t}{t^{\alpha}} + b \int_0^{C} \psi(t)\frac{\mathrm{d}t}{t^{\alpha}}   =  a\langle u ,  \phi \rangle + b\langle u, b\psi \rangle $$  For continuity i have to consider a sequence $\phi_k \to \phi$, but thats were i stuck, i have no idea how to show that $\langle u, \phi_k \rangle \to \langle u, \phi \rangle$? Do you have any hints for me ?","Consider the following functional $$   \langle u , \phi \rangle = \int_0^{\infty} \phi(t) \frac{\mathrm{d}t}{t^{\alpha}} $$ I want to show that it is a functional in $\mathcal{D'}{(\mathbb{R})}$. Because of the compact support of $\phi$, the indefinite integral could be made definite by an upper bound $C$. $$   \langle u , \phi \rangle = \int_0^{C} \phi(t) \frac{\mathrm{d}t}{t^{\alpha}} $$ So, first linearity is clear because of this property from the integral. $$  \langle u , a \phi + b \psi \rangle   =  \int_0^{C} (a \phi(t) + b \psi) \frac{\mathrm{d}t}{t^{\alpha}}   =  a \int_0^{C} \phi(t)\frac{\mathrm{d}t}{t^{\alpha}} + b \int_0^{C} \psi(t)\frac{\mathrm{d}t}{t^{\alpha}}   =  a\langle u ,  \phi \rangle + b\langle u, b\psi \rangle $$  For continuity i have to consider a sequence $\phi_k \to \phi$, but thats were i stuck, i have no idea how to show that $\langle u, \phi_k \rangle \to \langle u, \phi \rangle$? Do you have any hints for me ?",,"['calculus', 'functional-analysis', 'distribution-theory']"
64,Operator norm is not induced by a scalar product,Operator norm is not induced by a scalar product,,"Definition of the problem Let $\mathcal{H}$ be a Hilbert space, $\dim\mathcal{H}\geq2$. Prove that the operator norm on $L\left(\mathcal{H}\right)$ is not induced by a scalar product. We are hinted to prove that the orthogonal projection onto $span\left\{ \varphi\right\} $ for $\varphi\in\mathcal{H},\quad\left\Vert \varphi\right\Vert =1$, is given by $P_{\varphi}x=\left\langle x,\varphi\right\rangle \varphi,\quad x\in\mathcal{H}$. We have now to consider $P_{\varphi}$ and $P_{\psi}$, where $\varphi\perp\psi$ and $\left\Vert \varphi\right\Vert =\left\Vert \psi\right\Vert =1$. My effort I did prove the above citted statement. My idea I should use the parallelogram equality to show that the equality does not hold:  $$ \left\Vert P_{\varphi}+P_{\psi}\right\Vert ^{2}+\left\Vert P_{\varphi}-P_{\psi}\right\Vert ^{2}=2\cdot\left\Vert P_{\varphi}\right\Vert ^{2}+2\cdot\left\Vert P_{\psi}\right\Vert ^{2}. $$ Further efforts I did try to compute the first operator norm, and I get the following by using Pythagoreus Theorem and Cauchy-Schwarz, and since $\varphi\perp\psi$:  $$ \begin{eqnarray*} \left\Vert P_{\varphi}+P_{\psi}\right\Vert ^{2}+\left\Vert P_{\varphi}-P_{\psi}\right\Vert ^{2} & = & \sup_{\left\Vert x\right\Vert =1}\left(\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert P_{\psi}x\right\Vert ^{2}+\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert -P_{\psi}x\right\Vert ^{2}\right)\\  & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert P_{\psi}x\right\Vert ^{2}\right)\\  & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert \left\langle x,\varphi\right\rangle \varphi\right\Vert ^{2}+\left\Vert \left\langle x,\psi\right\rangle \psi\right\Vert ^{2}\right)\\  & \leq & 2\sup_{\left\Vert x\right\Vert =1}\left(\left|\left\langle x,\varphi\right\rangle \right|^{2}\left\Vert \varphi\right\Vert ^{2}+\left|\left\langle x,\psi\right\rangle \right|^{2}\left\Vert \psi\right\Vert ^{2}\right)\\  & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left|\left\langle x,\varphi\right\rangle \right|^{2}+\left|\left\langle x,\psi\right\rangle \right|^{2}\right)\\  & \leq & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert x\right\Vert ^{2}\left\Vert \varphi\right\Vert ^{2}+\left\Vert x\right\Vert ^{2}\left\Vert \psi\right\Vert ^{2}\right)\\  & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert x\right\Vert ^{2}+\left\Vert x\right\Vert ^{2}\right)\\  & = & 2\cdot\left(1+1\right)\\  & = & 4. \end{eqnarray*} $$ On the other side, by almost the same computations, we have:  \begin{eqnarray*} 2\cdot\left\Vert P_{\varphi}\right\Vert ^{2}+2\cdot\left\Vert P_{\psi}\right\Vert ^{2} & = & \sup_{\left\Vert x\right\Vert =1}\left(2\left\Vert P_{\varphi}x\right\Vert ^{2}+2\left\Vert P_{\psi}x\right\Vert ^{2}\right)\\  & = & ...\\  & \leq & 4. \end{eqnarray*} And I guess that would with difficulties prove my statement.. My Question How would you go to solve the problem? Could you give me a few steps so I could go any further? Do you see any mistakes in what I did so far? Thank you for your help, Franck.","Definition of the problem Let $\mathcal{H}$ be a Hilbert space, $\dim\mathcal{H}\geq2$. Prove that the operator norm on $L\left(\mathcal{H}\right)$ is not induced by a scalar product. We are hinted to prove that the orthogonal projection onto $span\left\{ \varphi\right\} $ for $\varphi\in\mathcal{H},\quad\left\Vert \varphi\right\Vert =1$, is given by $P_{\varphi}x=\left\langle x,\varphi\right\rangle \varphi,\quad x\in\mathcal{H}$. We have now to consider $P_{\varphi}$ and $P_{\psi}$, where $\varphi\perp\psi$ and $\left\Vert \varphi\right\Vert =\left\Vert \psi\right\Vert =1$. My effort I did prove the above citted statement. My idea I should use the parallelogram equality to show that the equality does not hold:  $$ \left\Vert P_{\varphi}+P_{\psi}\right\Vert ^{2}+\left\Vert P_{\varphi}-P_{\psi}\right\Vert ^{2}=2\cdot\left\Vert P_{\varphi}\right\Vert ^{2}+2\cdot\left\Vert P_{\psi}\right\Vert ^{2}. $$ Further efforts I did try to compute the first operator norm, and I get the following by using Pythagoreus Theorem and Cauchy-Schwarz, and since $\varphi\perp\psi$:  $$ \begin{eqnarray*} \left\Vert P_{\varphi}+P_{\psi}\right\Vert ^{2}+\left\Vert P_{\varphi}-P_{\psi}\right\Vert ^{2} & = & \sup_{\left\Vert x\right\Vert =1}\left(\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert P_{\psi}x\right\Vert ^{2}+\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert -P_{\psi}x\right\Vert ^{2}\right)\\  & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert P_{\varphi}x\right\Vert ^{2}+\left\Vert P_{\psi}x\right\Vert ^{2}\right)\\  & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert \left\langle x,\varphi\right\rangle \varphi\right\Vert ^{2}+\left\Vert \left\langle x,\psi\right\rangle \psi\right\Vert ^{2}\right)\\  & \leq & 2\sup_{\left\Vert x\right\Vert =1}\left(\left|\left\langle x,\varphi\right\rangle \right|^{2}\left\Vert \varphi\right\Vert ^{2}+\left|\left\langle x,\psi\right\rangle \right|^{2}\left\Vert \psi\right\Vert ^{2}\right)\\  & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left|\left\langle x,\varphi\right\rangle \right|^{2}+\left|\left\langle x,\psi\right\rangle \right|^{2}\right)\\  & \leq & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert x\right\Vert ^{2}\left\Vert \varphi\right\Vert ^{2}+\left\Vert x\right\Vert ^{2}\left\Vert \psi\right\Vert ^{2}\right)\\  & = & 2\sup_{\left\Vert x\right\Vert =1}\left(\left\Vert x\right\Vert ^{2}+\left\Vert x\right\Vert ^{2}\right)\\  & = & 2\cdot\left(1+1\right)\\  & = & 4. \end{eqnarray*} $$ On the other side, by almost the same computations, we have:  \begin{eqnarray*} 2\cdot\left\Vert P_{\varphi}\right\Vert ^{2}+2\cdot\left\Vert P_{\psi}\right\Vert ^{2} & = & \sup_{\left\Vert x\right\Vert =1}\left(2\left\Vert P_{\varphi}x\right\Vert ^{2}+2\left\Vert P_{\psi}x\right\Vert ^{2}\right)\\  & = & ...\\  & \leq & 4. \end{eqnarray*} And I guess that would with difficulties prove my statement.. My Question How would you go to solve the problem? Could you give me a few steps so I could go any further? Do you see any mistakes in what I did so far? Thank you for your help, Franck.",,"['linear-algebra', 'functional-analysis', 'hilbert-spaces']"
65,Basis functions for a Schauder-Faber-Basis,Basis functions for a Schauder-Faber-Basis,,"I am working through two proofs that there exists a Schauder Basis for $C([0,1])$ . One proof defines a basis $(f_n)_{n=0}^{\infty}$ with $$  f_0(x) = 1 \qquad f_1(x) = x $$ for $2^{k-1} < n \le 2^{k}$ , where $k \ge 1$ , we define $$  f_n(x) = \left\{ \begin{array}{ll}                     2^k ( x - (2^{-k}(2n - 2) - 1)) & \mathrm{if} ~ x \in I_n \\                     1 - 2^k ( x - (2^{-k}(2n - 1) - 1)) & \mathrm{if} ~ x \in J_n \\                     0 & \mathrm{otherwise}                   \end{array} \right. $$ where $$  I_n = [2^{-k}(2n-2), 2^{-k}(2n-1)) \qquad  J_n = [2^{-k}(2n-1), 2^{-k}2n). $$ The graphs of these functions form a sequence of ""tents"" of height one and width $2^{-k+1}$ that sweep across the interval $[0,1]$ . This proof is from this notes page 94. Another proof I found on the internet goes like this, define the ""triangle function"" $$  \Delta(x) = \begin{cases}                 2x & \mathrm{if } \hspace{2mm} x \in \left[0, \frac{1}{2}\right] \\ \\                 2(1-x)  & \mathrm{if } \hspace{2mm} x \in \left(\frac{1}{2},1\right] \\ \\                 0 & \mathrm{otherwise}.              \end{cases}$$ Then consider for $n > 0$ $$  \Delta_n(x) = \Delta(2^j x - k) \quad \mathrm{for } \qquad n = 2^j + k, \quad j \ge 0,\quad 0 \le k < 2^j $$ and $\Delta_{-1}(x) = 1, \Delta_0(x) = x$ . Then the sequence $\Delta_{-1}, \Delta_0, \Delta_1, \Delta_2, \ldots$ forms a Schauder basis for the Banach space of continuous functions on $[0,1]$ . I found this proof here and here . Now here's my question. I tried to prove that both, the $\Delta_n$ and the $f_n$ 's, define the same functions, but I am not able to convert the definitions to each other. Do you know how can I proof that these two functions are essentially the same ""tent""-functions?","I am working through two proofs that there exists a Schauder Basis for . One proof defines a basis with for , where , we define where The graphs of these functions form a sequence of ""tents"" of height one and width that sweep across the interval . This proof is from this notes page 94. Another proof I found on the internet goes like this, define the ""triangle function"" Then consider for and . Then the sequence forms a Schauder basis for the Banach space of continuous functions on . I found this proof here and here . Now here's my question. I tried to prove that both, the and the 's, define the same functions, but I am not able to convert the definitions to each other. Do you know how can I proof that these two functions are essentially the same ""tent""-functions?","C([0,1]) (f_n)_{n=0}^{\infty} 
 f_0(x) = 1 \qquad f_1(x) = x
 2^{k-1} < n \le 2^{k} k \ge 1 
 f_n(x) = \left\{ \begin{array}{ll}
                    2^k ( x - (2^{-k}(2n - 2) - 1)) & \mathrm{if} ~ x \in I_n \\
                    1 - 2^k ( x - (2^{-k}(2n - 1) - 1)) & \mathrm{if} ~ x \in J_n \\
                    0 & \mathrm{otherwise}
                  \end{array} \right.
 
 I_n = [2^{-k}(2n-2), 2^{-k}(2n-1)) \qquad
 J_n = [2^{-k}(2n-1), 2^{-k}2n).
 2^{-k+1} [0,1] 
 \Delta(x) = \begin{cases}
                2x & \mathrm{if } \hspace{2mm} x \in \left[0, \frac{1}{2}\right] \\
\\
                2(1-x)  & \mathrm{if } \hspace{2mm} x \in \left(\frac{1}{2},1\right] \\
\\
                0 & \mathrm{otherwise}.
             \end{cases} n > 0 
 \Delta_n(x) = \Delta(2^j x - k) \quad \mathrm{for } \qquad n = 2^j + k, \quad j \ge 0,\quad 0 \le k < 2^j
 \Delta_{-1}(x) = 1, \Delta_0(x) = x \Delta_{-1}, \Delta_0, \Delta_1, \Delta_2, \ldots [0,1] \Delta_n f_n","['analysis', 'functional-analysis']"
66,"Prove that this property holds for any $f\in L^\infty([0,1])$.",Prove that this property holds for any .,"f\in L^\infty([0,1])","I recently came across this problem, namely we are given a continuous function $f:\mathbb R\to\mathbb R$ such that $$\int_0^1f(u(x))\mathrm dx=0,\;\forall u\in C^0([0,1]):\int_0^1u(x)\mathrm d x=0.$$ I am asked to prove that the same property holds for any $u\in L^\infty([0,1])$ such that  $$\int_0^1 u(x)\mathrm dx=0.$$ My attempt is to exploit Lusin Theorem because my first thought is that an essentially bounded measurable function is nearly a continuous one and then use the property given for continuous function. However I' still having problems in figuring out the reasoning. Is my path correct or not? and how should I approach the problem? Thank you. Edit This is a further thought that came to my mind. Is such an $f$ necessarily a linear map? Because of course linear maps do the jobs, but what about the converse? The thought came by noticing that if $u$ is a continuous function satisfying the hypothesis given, then so does $\lambda u$, and if $v$ is another such function, then $u+v$ is fine as well. I didn't want to ask another question because it descends from the original problem i proposed. Hope it is ok to ask here. Bye.","I recently came across this problem, namely we are given a continuous function $f:\mathbb R\to\mathbb R$ such that $$\int_0^1f(u(x))\mathrm dx=0,\;\forall u\in C^0([0,1]):\int_0^1u(x)\mathrm d x=0.$$ I am asked to prove that the same property holds for any $u\in L^\infty([0,1])$ such that  $$\int_0^1 u(x)\mathrm dx=0.$$ My attempt is to exploit Lusin Theorem because my first thought is that an essentially bounded measurable function is nearly a continuous one and then use the property given for continuous function. However I' still having problems in figuring out the reasoning. Is my path correct or not? and how should I approach the problem? Thank you. Edit This is a further thought that came to my mind. Is such an $f$ necessarily a linear map? Because of course linear maps do the jobs, but what about the converse? The thought came by noticing that if $u$ is a continuous function satisfying the hypothesis given, then so does $\lambda u$, and if $v$ is another such function, then $u+v$ is fine as well. I didn't want to ask another question because it descends from the original problem i proposed. Hope it is ok to ask here. Bye.",,"['real-analysis', 'measure-theory', 'functional-analysis']"
67,How to prove that there is a subspace $W \subset C(X)$ so that $C(X)$ is isomorphic?,How to prove that there is a subspace  so that  is isomorphic?,W \subset C(X) C(X),"Let $X$ be a compact metric space and let $F$ be a closed subset of $X$. Assume that there exists a bounded extension operator $T:C(F) \rightarrow C(X)$, i.e., $T \in B(C(F),C(X))$ and for all $g\in C(F)$, $T(g)|_{F} =g$. How to prove that there is a subspace $W \subset C(X)$ so that $C(X)$ is isomorphic (as a vector space) to $W \bigoplus Z$, where $Z=\{f \in C(X) : f|_F =0 \}$? Equip $W \bigoplus Z$ with the norm $\||(w,z)|\| = \|w\|+\|z\|$. The above isomorphism is an isomorphism of Banach spaces? Let $X=[0,1]$ and let $F$ be a closed subset of $X$. How to prove there is a bounded extension operator $T$ from $C(F)$ to $C([0,1])$? Thank you so much for your help.","Let $X$ be a compact metric space and let $F$ be a closed subset of $X$. Assume that there exists a bounded extension operator $T:C(F) \rightarrow C(X)$, i.e., $T \in B(C(F),C(X))$ and for all $g\in C(F)$, $T(g)|_{F} =g$. How to prove that there is a subspace $W \subset C(X)$ so that $C(X)$ is isomorphic (as a vector space) to $W \bigoplus Z$, where $Z=\{f \in C(X) : f|_F =0 \}$? Equip $W \bigoplus Z$ with the norm $\||(w,z)|\| = \|w\|+\|z\|$. The above isomorphism is an isomorphism of Banach spaces? Let $X=[0,1]$ and let $F$ be a closed subset of $X$. How to prove there is a bounded extension operator $T$ from $C(F)$ to $C([0,1])$? Thank you so much for your help.",,"['functional-analysis', 'banach-spaces']"
68,$T(V)$ is a closed subspace of $V$?,is a closed subspace of ?,T(V) V,Let $V$ be a normed vector space (not necessarily a Banach space) and let $S$ and $T$ be continuous linear transformations from $V$ to $V$. If we assume that $T=T \circ S \circ T$. Then how to show that $T(V)$ is a closed subspace of $V$? Thank you for your help!,Let $V$ be a normed vector space (not necessarily a Banach space) and let $S$ and $T$ be continuous linear transformations from $V$ to $V$. If we assume that $T=T \circ S \circ T$. Then how to show that $T(V)$ is a closed subspace of $V$? Thank you for your help!,,"['functional-analysis', 'operator-theory', 'normed-spaces']"
69,Characterizations of the form domain for unbounded selfadjoint operators,Characterizations of the form domain for unbounded selfadjoint operators,,"This question follows from this one and especially from Willie Wong's answer: link . In Reed & Simon's book Methods of modern mathematical physics , vol. I, pag.277, the form domain of a self-adjoint operator $(A, D(A))$ on a Hilbert space $H$ is defined by passing to a spectral representation , that is by taking a unitary isomorphism $$U \colon H \to \bigoplus_{j=1}^N L^2(\mathbb{R}, d\mu_j), $$ (where $N\in \{1, 2 \ldots +\infty\}$ and $\mu_j$ are finite Borel measures) such that $(UA)\varphi=(x\psi_j(x))_{j=1}^N$ [ $A$ is unitarily equivalent to multiplication by $x$ ]. The sought domain is then said to be $$Q(q)=\left\{ (\psi_j)_{j=1}^N \ :\  \sum_{j=1}^N \int_{-\infty}^\infty \lvert x \rvert \lvert \psi_j(x)\rvert^2\, d\mu_j <+\infty \right\}.$$ Question . Let $$D(\lvert A\rvert^{1/2})=\left\{ \varphi \in H\ :\ \int_{-\infty}^\infty \lvert \lambda \rvert\, d\big(E_A(\lambda)\varphi, \varphi\big)<+\infty\right\},$$ where $\{E_A(\lambda)\}_{\lambda \in \mathbb{R}}$ is the spectral family of $A$ (cfr. Reed & Simon vol. I Theorem VIII.6). Is it true that $Q(q)=D(\lvert A\rvert^{1/2})$? I believe the answer to be affirmative. This should make for a characterization of the form domain a bit more transparent than the one based on spectral representations. For example, it is not immediately clear that the latter is independent on the particular representation chosen.","This question follows from this one and especially from Willie Wong's answer: link . In Reed & Simon's book Methods of modern mathematical physics , vol. I, pag.277, the form domain of a self-adjoint operator $(A, D(A))$ on a Hilbert space $H$ is defined by passing to a spectral representation , that is by taking a unitary isomorphism $$U \colon H \to \bigoplus_{j=1}^N L^2(\mathbb{R}, d\mu_j), $$ (where $N\in \{1, 2 \ldots +\infty\}$ and $\mu_j$ are finite Borel measures) such that $(UA)\varphi=(x\psi_j(x))_{j=1}^N$ [ $A$ is unitarily equivalent to multiplication by $x$ ]. The sought domain is then said to be $$Q(q)=\left\{ (\psi_j)_{j=1}^N \ :\  \sum_{j=1}^N \int_{-\infty}^\infty \lvert x \rvert \lvert \psi_j(x)\rvert^2\, d\mu_j <+\infty \right\}.$$ Question . Let $$D(\lvert A\rvert^{1/2})=\left\{ \varphi \in H\ :\ \int_{-\infty}^\infty \lvert \lambda \rvert\, d\big(E_A(\lambda)\varphi, \varphi\big)<+\infty\right\},$$ where $\{E_A(\lambda)\}_{\lambda \in \mathbb{R}}$ is the spectral family of $A$ (cfr. Reed & Simon vol. I Theorem VIII.6). Is it true that $Q(q)=D(\lvert A\rvert^{1/2})$? I believe the answer to be affirmative. This should make for a characterization of the form domain a bit more transparent than the one based on spectral representations. For example, it is not immediately clear that the latter is independent on the particular representation chosen.",,"['functional-analysis', 'hilbert-spaces', 'operator-theory', 'spectral-theory']"
70,Equivalence of norms in Sobolev space,Equivalence of norms in Sobolev space,,"I am trying to prove an equivalence between two norms in the Sobolev space $H^1(\Omega)$ over a bounded Lipschitz domain $\Omega$, namely the standard norm $$||u||_{H^1(\Omega)}^2=\int_{\Omega} u^2 \,dx + \int_{\Omega} |\nabla u|^2\,dx$$ and the norm $$||u||_{\partial}^2= \int_{\partial \Omega} u_{|\partial \Omega}^2 \,d\sigma + \int_{\Omega} |\nabla u|^2\,dx$$ The second sumands are the same in both cases, so since in the first one we integrate the positve function $u^2$ over a larger domain, it is clear that $||u||_{\partial} \leq ||u||_{H^1(\Omega)}$, so it now suffices to find a positive constant $C$ such that $C||u||_{H^1(\Omega)}\leq ||u||_{\partial}$. Now we can use the following projection theorem: given a Hilbert space $H$ and a closed subspace $V\subset H$, for every $X\in H$ there exists a unique $P_Vx\in V$ such that $$||x-P_vx||=\inf_{v\in V} \{||v-x||\}$$ and besides $x-P_Vx\in V^{\perp}$. In our case, this yields a decomposition $$u=u_0+E(u_{|\partial \Omega})$$ where $E(u_{|\partial \Omega})$ is an extension to $\Omega$ of the restriction $u_{|\partial \Omega}$ and $u_0\in H_0^1(\Omega)$ and therefore $$||u||_{H^1(\Omega)}^2=||u_0||_{H^1(\Omega)}^2+||E(u_{|\partial \Omega})||_{H^1(\Omega)}^2$$ Note that by the projection theorem we have that $$||E(u_{|\partial \Omega})||_{H^1(\Omega)}^2=\inf\{||v||_{H^1(\Omega)}: v\in H^1(\Omega), v_{|\partial \Omega}=u_{|\partial \Omega}\} \stackrel{def}{=} ||u_{|\partial \Omega}||_{H^{1/2}(\partial \Omega)}$$ Does this lead towards our purpose? Thanks in advance for any insight.","I am trying to prove an equivalence between two norms in the Sobolev space $H^1(\Omega)$ over a bounded Lipschitz domain $\Omega$, namely the standard norm $$||u||_{H^1(\Omega)}^2=\int_{\Omega} u^2 \,dx + \int_{\Omega} |\nabla u|^2\,dx$$ and the norm $$||u||_{\partial}^2= \int_{\partial \Omega} u_{|\partial \Omega}^2 \,d\sigma + \int_{\Omega} |\nabla u|^2\,dx$$ The second sumands are the same in both cases, so since in the first one we integrate the positve function $u^2$ over a larger domain, it is clear that $||u||_{\partial} \leq ||u||_{H^1(\Omega)}$, so it now suffices to find a positive constant $C$ such that $C||u||_{H^1(\Omega)}\leq ||u||_{\partial}$. Now we can use the following projection theorem: given a Hilbert space $H$ and a closed subspace $V\subset H$, for every $X\in H$ there exists a unique $P_Vx\in V$ such that $$||x-P_vx||=\inf_{v\in V} \{||v-x||\}$$ and besides $x-P_Vx\in V^{\perp}$. In our case, this yields a decomposition $$u=u_0+E(u_{|\partial \Omega})$$ where $E(u_{|\partial \Omega})$ is an extension to $\Omega$ of the restriction $u_{|\partial \Omega}$ and $u_0\in H_0^1(\Omega)$ and therefore $$||u||_{H^1(\Omega)}^2=||u_0||_{H^1(\Omega)}^2+||E(u_{|\partial \Omega})||_{H^1(\Omega)}^2$$ Note that by the projection theorem we have that $$||E(u_{|\partial \Omega})||_{H^1(\Omega)}^2=\inf\{||v||_{H^1(\Omega)}: v\in H^1(\Omega), v_{|\partial \Omega}=u_{|\partial \Omega}\} \stackrel{def}{=} ||u_{|\partial \Omega}||_{H^{1/2}(\partial \Omega)}$$ Does this lead towards our purpose? Thanks in advance for any insight.",,['functional-analysis']
71,"Looking for a proof of the completeness of $C^{n}[0,1]$.",Looking for a proof of the completeness of .,"C^{n}[0,1]","Can someone refer me to a verification of the completeness of $C^{n}[0,1]$ under the norm $\|f\|_{C^{n}} = \sum_{k=0}^{n}\|f^{(k)}\|_{\infty}$? I tried to follow the same approach as the standard proof the $C[0,1]$ is complete under the supremum norm, but I run into the problem that the limits I end up with do not necessarily define a function in $C^n[0,1]$.","Can someone refer me to a verification of the completeness of $C^{n}[0,1]$ under the norm $\|f\|_{C^{n}} = \sum_{k=0}^{n}\|f^{(k)}\|_{\infty}$? I tried to follow the same approach as the standard proof the $C[0,1]$ is complete under the supremum norm, but I run into the problem that the limits I end up with do not necessarily define a function in $C^n[0,1]$.",,"['functional-analysis', 'banach-spaces']"
72,The union of cyclic subspace is also a cyclic space,The union of cyclic subspace is also a cyclic space,,"Given a separable Hilbert space $H$, $U$ is a unitary operator. A cyclic subspace, denoted as $Z(x)$ for some $x\in H$, is defined as the closure of linear span of $U^nx$, where $n\in \Bbb Z$ is any integer number. Now we have a sequence of cyclic subspaces, namely, $Z(x_1)\subset Z(x_2)\subset \cdots$. Then the closure of its union, $\overline{\bigcup_iZ(x_i)}$, is also a cyclic subspace.","Given a separable Hilbert space $H$, $U$ is a unitary operator. A cyclic subspace, denoted as $Z(x)$ for some $x\in H$, is defined as the closure of linear span of $U^nx$, where $n\in \Bbb Z$ is any integer number. Now we have a sequence of cyclic subspaces, namely, $Z(x_1)\subset Z(x_2)\subset \cdots$. Then the closure of its union, $\overline{\bigcup_iZ(x_i)}$, is also a cyclic subspace.",,"['functional-analysis', 'hilbert-spaces', 'operator-theory']"
73,Minimization problem in Sobolev spaces,Minimization problem in Sobolev spaces,,"This is a homework problem and I don't know how to solve it: Consider the following minimization problem on the real-valued sobolev space $H^{1,2}(\Omega)$ with dimension $n=1$ and $\Omega=(0,1)$: $$F(u) = \int_0^1 \left(u^2+ \text{min}\left\{(u'-1)^2, (u'+1)^2\right\}\right) \ \mathrm{d}x \ \to\ \min$$ ($u'$ denotes the derivative of $u$). a) How to prove, that $F\colon H^{1,2}(\Omega) \to \mathbb R$ is continuous? b) How to prove, that $\displaystyle\inf_{u\in H^{1,2}(\Omega)} F(u) = 0$, but there is no $u \in H^{1,2}(\Omega)$ with $F(u)=0$ ? I think, $F$ is not linear mapping (because of quadratic terms in the integral). So it is maybe not the right way to show that the operator norm is bounded. Do I have to prove the continuity of $F$ by the definition (with $\varepsilon$ and $\delta$) or is there another possibility? And I don't know how to determine the infimum.","This is a homework problem and I don't know how to solve it: Consider the following minimization problem on the real-valued sobolev space $H^{1,2}(\Omega)$ with dimension $n=1$ and $\Omega=(0,1)$: $$F(u) = \int_0^1 \left(u^2+ \text{min}\left\{(u'-1)^2, (u'+1)^2\right\}\right) \ \mathrm{d}x \ \to\ \min$$ ($u'$ denotes the derivative of $u$). a) How to prove, that $F\colon H^{1,2}(\Omega) \to \mathbb R$ is continuous? b) How to prove, that $\displaystyle\inf_{u\in H^{1,2}(\Omega)} F(u) = 0$, but there is no $u \in H^{1,2}(\Omega)$ with $F(u)=0$ ? I think, $F$ is not linear mapping (because of quadratic terms in the integral). So it is maybe not the right way to show that the operator norm is bounded. Do I have to prove the continuity of $F$ by the definition (with $\varepsilon$ and $\delta$) or is there another possibility? And I don't know how to determine the infimum.",,"['functional-analysis', 'hilbert-spaces', 'sobolev-spaces']"
74,Powers of a densely-defined bounded linear operator,Powers of a densely-defined bounded linear operator,,"This is a question I was thinking of some time ago. Suppose $\mathbf{X} \equiv (X, \|\cdot\|_X)$ is a (real or complex) Banach space, $U$ is a dense subspace of $\mathbf{X}$, and $\phi$ is a bounded linear operator $(U,\|\cdot\|_X) \to \mathbf{X}$. We know from the B.L.T. theorem that $\phi$ can be uniquely extended to a bounded linear operator $\Phi: \mathbf{X} \to \mathbf{X}$. Question. Provided $x \in X$, does there exist a sequence, $\{x_n\}_{n=1}^\infty$, in $U$ such that $\lim_n x_n = x$ in $\mathbf{X}$ and, for each $n \in \mathbb{N}^+$, $\{\Phi^k(x_n)\}_{k=1}^n \subseteq \phi(U)$?","This is a question I was thinking of some time ago. Suppose $\mathbf{X} \equiv (X, \|\cdot\|_X)$ is a (real or complex) Banach space, $U$ is a dense subspace of $\mathbf{X}$, and $\phi$ is a bounded linear operator $(U,\|\cdot\|_X) \to \mathbf{X}$. We know from the B.L.T. theorem that $\phi$ can be uniquely extended to a bounded linear operator $\Phi: \mathbf{X} \to \mathbf{X}$. Question. Provided $x \in X$, does there exist a sequence, $\{x_n\}_{n=1}^\infty$, in $U$ such that $\lim_n x_n = x$ in $\mathbf{X}$ and, for each $n \in \mathbb{N}^+$, $\{\Phi^k(x_n)\}_{k=1}^n \subseteq \phi(U)$?",,"['functional-analysis', 'operator-theory']"
75,Interpolating between the $L^{p}$ norm and the Hölder semi-norm,Interpolating between the  norm and the Hölder semi-norm,L^{p},"Set-up. For a bounded continuous function $u \colon \mathbb{R}^n \to \mathbb{R}$, the $\gamma$-Hölder semi-norm of $u$ is  $$ \begin{eqnarray} [u]_{C^\gamma}  &=&  \sup \left\{\frac{|u(x) - u(y)|}{|x-y|^\gamma} : x,y \in U, x \neq y \right\}  \\ &=& \inf \left\{ C \geq 0 : |u(x) - u(y)| \leq C |x-y|^{\gamma} \text{ for all } x,y \in U \right\}. \end{eqnarray} $$ The Problem Fix $1 \leq p < \infty$, $0 < \gamma \leq 1$, and $0 < \lambda < 1$ such that $$ 0 = \frac{\lambda}{p} - (1-\lambda)\frac{\gamma}{n}. $$ I am trying to prove that there is a constant $C$ such that $$ \|u\|_{L^\infty} \leq C \|u\|_{L^p}^{\lambda} [u]_{C^\gamma}^{1-\lambda} $$ for every compactly supported $C^{1}(\mathbb{R}^n)$ function $u$. My Strategy My plan is to use the interpolation result for Lebesgue spaces:  For every $q,r$ satisfying $p < q < r \leq \infty$ and  $$ \frac{1}{q} = \frac{\lambda}{p} + \frac{1-\lambda}{r}, $$ we have $$ \|u\|_{L^q} \leq \|u\|_{L^{p}}^{\lambda} \|u\|_{L^r}^{1-\lambda} $$ for every $u \in L^p \cap L^r$. Solving for $1/r$ in terms of $q$ and using the relationship between $p$, $\gamma$, and $n$, we find $$ \frac{1}{r} = \frac{1/q - \lambda/p}{1-\lambda} = \frac{1/q}{1-\lambda} - \frac{\gamma}{n} $$ So, by letting $q \to \infty$, we have $r \to -n / \gamma$, and $$ \frac{1}{q} = \frac{\lambda}{p} + \frac{1-\lambda}{r}, $$ goes to $$ 0 = \frac{\lambda}{p} - (1-\lambda)\frac{\gamma}{n}. $$ Meanwhile, for $u \in L^{\infty}$ (which certainly holds when $u$ is compactly supported and $C^1$), we have that $\lim_{q \to \infty} \|u\|_{L^q} =\|u\|_{L^\infty}$. So if I could prove that $\|u\|_r \to [u]_{C^{\gamma}}$ as $q \to \infty$ (i.e., as $r \to -n / \gamma$), I'd be done. The problem is that I don't know how to prove this.  Moreover, I'm not sure if this is even the right approach to prove the desired inequality. Can someone please help me out?","Set-up. For a bounded continuous function $u \colon \mathbb{R}^n \to \mathbb{R}$, the $\gamma$-Hölder semi-norm of $u$ is  $$ \begin{eqnarray} [u]_{C^\gamma}  &=&  \sup \left\{\frac{|u(x) - u(y)|}{|x-y|^\gamma} : x,y \in U, x \neq y \right\}  \\ &=& \inf \left\{ C \geq 0 : |u(x) - u(y)| \leq C |x-y|^{\gamma} \text{ for all } x,y \in U \right\}. \end{eqnarray} $$ The Problem Fix $1 \leq p < \infty$, $0 < \gamma \leq 1$, and $0 < \lambda < 1$ such that $$ 0 = \frac{\lambda}{p} - (1-\lambda)\frac{\gamma}{n}. $$ I am trying to prove that there is a constant $C$ such that $$ \|u\|_{L^\infty} \leq C \|u\|_{L^p}^{\lambda} [u]_{C^\gamma}^{1-\lambda} $$ for every compactly supported $C^{1}(\mathbb{R}^n)$ function $u$. My Strategy My plan is to use the interpolation result for Lebesgue spaces:  For every $q,r$ satisfying $p < q < r \leq \infty$ and  $$ \frac{1}{q} = \frac{\lambda}{p} + \frac{1-\lambda}{r}, $$ we have $$ \|u\|_{L^q} \leq \|u\|_{L^{p}}^{\lambda} \|u\|_{L^r}^{1-\lambda} $$ for every $u \in L^p \cap L^r$. Solving for $1/r$ in terms of $q$ and using the relationship between $p$, $\gamma$, and $n$, we find $$ \frac{1}{r} = \frac{1/q - \lambda/p}{1-\lambda} = \frac{1/q}{1-\lambda} - \frac{\gamma}{n} $$ So, by letting $q \to \infty$, we have $r \to -n / \gamma$, and $$ \frac{1}{q} = \frac{\lambda}{p} + \frac{1-\lambda}{r}, $$ goes to $$ 0 = \frac{\lambda}{p} - (1-\lambda)\frac{\gamma}{n}. $$ Meanwhile, for $u \in L^{\infty}$ (which certainly holds when $u$ is compactly supported and $C^1$), we have that $\lim_{q \to \infty} \|u\|_{L^q} =\|u\|_{L^\infty}$. So if I could prove that $\|u\|_r \to [u]_{C^{\gamma}}$ as $q \to \infty$ (i.e., as $r \to -n / \gamma$), I'd be done. The problem is that I don't know how to prove this.  Moreover, I'm not sure if this is even the right approach to prove the desired inequality. Can someone please help me out?",,"['real-analysis', 'analysis', 'functional-analysis']"
76,Bidual of a WSC space,Bidual of a WSC space,,"Let $E$ be a Banach space which is weakly sequentially complete (i.e. each weak Cauchy sequence converges weakly). Must $E^{**}$ be weakly sequentially complete either? Of course, this question is interesting only for non-reflexive spaces.","Let $E$ be a Banach space which is weakly sequentially complete (i.e. each weak Cauchy sequence converges weakly). Must $E^{**}$ be weakly sequentially complete either? Of course, this question is interesting only for non-reflexive spaces.",,"['functional-analysis', 'reference-request', 'banach-spaces', 'examples-counterexamples']"
77,This map $f$ is not continuous with respect to sup norm,This map  is not continuous with respect to sup norm,f,"Question: On the space $\ell^1$ for $x=(\alpha_1,\alpha_2,\ldots)\in{\ell^1}$, define $$f(x)=\sum\limits_{n=1}^\infty \alpha_n$$ Prove that $f$ is not continuous with respect to $\|x\|_\infty =\sup_n|\alpha_n|$. This is my proof: Since $f$ is a linear map, $f$ is continuous iff $f$ is bounded. Assume for the sake of contradiction that $f$ is bounded. This implies that there exist $k\gt 0$.  such that $$\|f(x)\|\le k\|x\|_\infty \text{ for all } x\in \ell^1$$ In particular, $k$ may be $1$. Now, let $x=(\alpha_1,\alpha_2,\ldots)\in \ell^1$ where $\alpha_i \ge 0$ for all $i$. $$\|f(x)\|=\|\sum\limits_{n=1}^{\infty}\alpha_{n}\|$$ Since for each $i$ $\alpha_{i}\gt 0$, $$=\sum\limits_{n=1}^\infty |\alpha_n| \gt\sup_n|\alpha_n|=\|x\|_\infty$$ This implies $$\|f(x)\|\gt\|x\|_\infty$$ Contradicting my first line of proof. Hence $f$ is not bounded, i.e. $f$ is not continuous. My problem here is that I failed to believe myself, I think something is wrong in the proof. can anyone help me out?","Question: On the space $\ell^1$ for $x=(\alpha_1,\alpha_2,\ldots)\in{\ell^1}$, define $$f(x)=\sum\limits_{n=1}^\infty \alpha_n$$ Prove that $f$ is not continuous with respect to $\|x\|_\infty =\sup_n|\alpha_n|$. This is my proof: Since $f$ is a linear map, $f$ is continuous iff $f$ is bounded. Assume for the sake of contradiction that $f$ is bounded. This implies that there exist $k\gt 0$.  such that $$\|f(x)\|\le k\|x\|_\infty \text{ for all } x\in \ell^1$$ In particular, $k$ may be $1$. Now, let $x=(\alpha_1,\alpha_2,\ldots)\in \ell^1$ where $\alpha_i \ge 0$ for all $i$. $$\|f(x)\|=\|\sum\limits_{n=1}^{\infty}\alpha_{n}\|$$ Since for each $i$ $\alpha_{i}\gt 0$, $$=\sum\limits_{n=1}^\infty |\alpha_n| \gt\sup_n|\alpha_n|=\|x\|_\infty$$ This implies $$\|f(x)\|\gt\|x\|_\infty$$ Contradicting my first line of proof. Hence $f$ is not bounded, i.e. $f$ is not continuous. My problem here is that I failed to believe myself, I think something is wrong in the proof. can anyone help me out?",,['functional-analysis']
78,Fourier transform,Fourier transform,,"Suppose $1< p<\infty$. Let $f$ be a continuous function with compact support defined on $\mathbb{R}$. Does it exist a function $g \in L^p(\mathbb{T})$ such that:  $$ \widehat{f}|_{\mathbb{Z}}=\widehat{g} $$  where $\widehat{f}$ denote the Fourier transform on $\mathbb{R}$ and $\widehat{g}$ the Fourier transform on $\mathbb{T}$ ?","Suppose $1< p<\infty$. Let $f$ be a continuous function with compact support defined on $\mathbb{R}$. Does it exist a function $g \in L^p(\mathbb{T})$ such that:  $$ \widehat{f}|_{\mathbb{Z}}=\widehat{g} $$  where $\widehat{f}$ denote the Fourier transform on $\mathbb{R}$ and $\widehat{g}$ the Fourier transform on $\mathbb{T}$ ?",,"['reference-request', 'functional-analysis', 'fourier-analysis']"
79,Example of an infinite dimensional vector space that is not isomorphic to its dual [duplicate],Example of an infinite dimensional vector space that is not isomorphic to its dual [duplicate],,This question already has answers here : Closed 12 years ago . Possible Duplicates: Why are vector spaces not isomorphic to their duals? Dual space question Can someone give an (as easy as possible) example (together with a proof) of an infinite dimensional vector space that is not isomorphic to its dual ?,This question already has answers here : Closed 12 years ago . Possible Duplicates: Why are vector spaces not isomorphic to their duals? Dual space question Can someone give an (as easy as possible) example (together with a proof) of an infinite dimensional vector space that is not isomorphic to its dual ?,,"['linear-algebra', 'functional-analysis']"
80,Laplace inverse transform formula and Cauchy's integral formula,Laplace inverse transform formula and Cauchy's integral formula,,The question is about Laplace Transform and the inverse transform formula. Can the inverse  transform formula be proved using Cauchy's integral formula?,The question is about Laplace Transform and the inverse transform formula. Can the inverse  transform formula be proved using Cauchy's integral formula?,,"['complex-analysis', 'functional-analysis']"
81,Hardy Spaces on the unit disk and $\mathbb R^n$,Hardy Spaces on the unit disk and,\mathbb R^n,"Is there a connection between the Hardy Spaces on the unit disk and on $\mathbb R^n$?. If so, can we use results from the Hardy Spaces on the unit disk to prove $(H^1)^* = \text{BMO}$? Further, what is the most fruitful way to define $H^1$ on $\mathbb R^n$ but avoiding (bounded) distributions? I was writing something for a project and this would be the only point where I would use them. Of course, I could take the completion of the $C_c^\infty$ functions in the $H^1$-norm, but is this workable enough?","Is there a connection between the Hardy Spaces on the unit disk and on $\mathbb R^n$?. If so, can we use results from the Hardy Spaces on the unit disk to prove $(H^1)^* = \text{BMO}$? Further, what is the most fruitful way to define $H^1$ on $\mathbb R^n$ but avoiding (bounded) distributions? I was writing something for a project and this would be the only point where I would use them. Of course, I could take the completion of the $C_c^\infty$ functions in the $H^1$-norm, but is this workable enough?",,"['soft-question', 'functional-analysis']"
82,Thoughts about measurable functions,Thoughts about measurable functions,,"I've recently been studying the functional analysis and I think I need some help with one exercise in the book. We have the Lusin's theorem, which is stated the following way: Given some measurable $E$ where $\mu(E)<\infty$ and some function $f$, which is measurable and finite almost everywhere in $E$, the following statement is true: $\forall \epsilon>0 : \space  \exists  F_\epsilon \subset E$, that ($F_\epsilon$ has to be closed): 1) $\mu(E \setminus F_\epsilon) < \epsilon$ 2) $f$ is continuous on $F_\epsilon$ Now - the exercise is to tell if the inverse theorem is correct (and give the proof if it is) - so that if there exists that $F_\epsilon$, on which our function is continuous (and I assume finite almost everywhere) , then it's also measurable on the corresponding set $E$. I assume this statement is correct, but unfortunately I can't come up with a proper proof. Proof of the Lusin's theorem doesn't help here, because we have to prove the continuity -> measurableness on the corresponding sets and the Egorov's theorem is no help in that case. Could someone share the proof please or give me some clues on accomplishing it.","I've recently been studying the functional analysis and I think I need some help with one exercise in the book. We have the Lusin's theorem, which is stated the following way: Given some measurable $E$ where $\mu(E)<\infty$ and some function $f$, which is measurable and finite almost everywhere in $E$, the following statement is true: $\forall \epsilon>0 : \space  \exists  F_\epsilon \subset E$, that ($F_\epsilon$ has to be closed): 1) $\mu(E \setminus F_\epsilon) < \epsilon$ 2) $f$ is continuous on $F_\epsilon$ Now - the exercise is to tell if the inverse theorem is correct (and give the proof if it is) - so that if there exists that $F_\epsilon$, on which our function is continuous (and I assume finite almost everywhere) , then it's also measurable on the corresponding set $E$. I assume this statement is correct, but unfortunately I can't come up with a proper proof. Proof of the Lusin's theorem doesn't help here, because we have to prove the continuity -> measurableness on the corresponding sets and the Egorov's theorem is no help in that case. Could someone share the proof please or give me some clues on accomplishing it.",,"['measure-theory', 'functional-analysis']"
83,Limit point of basic sequence in Banach space,Limit point of basic sequence in Banach space,,This question is about Schauder bases in Banach spaces. Suppose $(x_n)$ is a basic sequence in a Banach space $E$. Prove that $0$ is the only possible weak limit point of $\{x_n \in E \;\vert\; n \in \mathbb{N}\}$.,This question is about Schauder bases in Banach spaces. Suppose $(x_n)$ is a basic sequence in a Banach space $E$. Prove that $0$ is the only possible weak limit point of $\{x_n \in E \;\vert\; n \in \mathbb{N}\}$.,,"['functional-analysis', 'banach-spaces']"
84,Number of continuous $[0; 1] \to [0; 1]$ functions for given arc length,Number of continuous  functions for given arc length,[0; 1] \to [0; 1],"Just out of pure curiosity ... Suppose I want to connect the two points $(0,0)$ and $(1,1)$ with the graph of some continuous and differentiable function $$f : [0; 1] \to [0; 1]$$ and let $s$ be the arc length of that function in $[0; 1]$. Of course, the function with minimum $s$ that satisfies the above conditions is $f(x) = x$ with $s = \sqrt 2$. So for $s = \sqrt 2$, exactly one matching function can be found. But what happens to the number of these functions if $s$ increases? Surely, more functions can be found to match the given arc length - uncountably many more I suppose due to the nature of the real numbers. But intuitively, I'd think that the number of such functions grows even more the greater $s$ gets , since there is more ""space"" the graph can use. So, despite continuum cardinality, are there any means of measuring the number of such functions against $s$ or is it all the same once that minimal way of $f(x) = x$ as been taken? And would this change if we limited the ways of constructing such functions to e.g. some elementary ones?","Just out of pure curiosity ... Suppose I want to connect the two points $(0,0)$ and $(1,1)$ with the graph of some continuous and differentiable function $$f : [0; 1] \to [0; 1]$$ and let $s$ be the arc length of that function in $[0; 1]$. Of course, the function with minimum $s$ that satisfies the above conditions is $f(x) = x$ with $s = \sqrt 2$. So for $s = \sqrt 2$, exactly one matching function can be found. But what happens to the number of these functions if $s$ increases? Surely, more functions can be found to match the given arc length - uncountably many more I suppose due to the nature of the real numbers. But intuitively, I'd think that the number of such functions grows even more the greater $s$ gets , since there is more ""space"" the graph can use. So, despite continuum cardinality, are there any means of measuring the number of such functions against $s$ or is it all the same once that minimal way of $f(x) = x$ as been taken? And would this change if we limited the ways of constructing such functions to e.g. some elementary ones?",,"['functional-analysis', 'functions', 'cardinals']"
85,"If $g_1, g_2\in\mathscr{L}^{\infty}(X,\mathscr{A},\mu)$ are equal locally $\mu$-almost everywhere, then $T_{g_1}=T_{g_2}$.","If  are equal locally -almost everywhere, then .","g_1, g_2\in\mathscr{L}^{\infty}(X,\mathscr{A},\mu) \mu T_{g_1}=T_{g_2}","Background Suppose that $(X,\mathscr{A},\mu)$ is an arbitrary measure space, that $p$ satisfies $1\leq p<+\infty$ , and that $q$ is defined by $\frac{1}{p}+\frac{1}{q}=1$ . Let $g$ belong to $\mathscr{L}^q(X,\mathscr{A},\mu)$ . Then $fg$ is integrable whenever $f$ belongs to $\mathscr{L}^p(X,\mathscr{A},\mu)$ (by Hölder's inequality), and so the formula \begin{align*}     T_g(f) = \int fgd\mu \end{align*} defines a linear functional $T_g$ on $\mathscr{L}^p(X,\mathscr{A},\mu)$ . Denote $T$ the map from $\mathscr{L}^q(X,\mathscr{A},\mu)$ to $\left(L^p(X,\mathscr{A},\mu)\right)^*$ that takes the function $g$ to the functional $T_g$ defined above. My Question Now, it is clear that if $g_1$ and $g_2$ are equal almost everywhere, then $T_{g_1}=T_{g_2}$ . However, the book I am reading pointed out that, in case $q=+\infty$ , we have if $g_1$ and $g_2$ are equal locally almost everywhere then $T_{g_1}=T_{g_2}$ . I want to prove this claim, but got stuck. My Attempt So Far I want to consider first the case when $fg_1$ and $fg_2$ are nonnegative. Let $A=\{x\in X:(fg_1)(x) \neq (fg_2)(x)\}$ . Let $h$ be the function defined by \begin{align*} h(x)= \begin{cases} +\infty\quad &\text{if $x\in A$},\\ 0\quad &\text{if $x\neq A$}. \end{cases} \end{align*} Define $\{h_n\}$ by $h_n=n\chi_{A}$ . Then $h(x)=\lim_{n\to\infty}h_n(x)$ for all $x\in X$ . So $\int hd\mu = \lim_{n\to\infty}\int h_nd\mu$ I got stuck here. What I wanted to do (but failed so far) is to show that $\int hd\mu=0$ . Then in view of $fg_1\leq fg_2+h$ , this would imply that $\int fg_1d\mu\leq\int fg_2d\mu + \int hd\mu = \int fg_2d\mu$ . Then analogously, $\int fg_2d\mu\leq\int fg_1d\mu$ , and we would have been done. Could someone please help me out? Thank you very much in advance! A property holds locally $\mu$ -almost everywhere if the set of points at which it fails to hold is locally $\mu$ -null. A set $N$ is called locally $\mu$ -null if for each set $A$ that belongs to $\mathscr{A}$ and satisfies $\mu(A)<+\infty$ the set $A\bigcap N$ is $\mu$ -null.","Background Suppose that is an arbitrary measure space, that satisfies , and that is defined by . Let belong to . Then is integrable whenever belongs to (by Hölder's inequality), and so the formula defines a linear functional on . Denote the map from to that takes the function to the functional defined above. My Question Now, it is clear that if and are equal almost everywhere, then . However, the book I am reading pointed out that, in case , we have if and are equal locally almost everywhere then . I want to prove this claim, but got stuck. My Attempt So Far I want to consider first the case when and are nonnegative. Let . Let be the function defined by Define by . Then for all . So I got stuck here. What I wanted to do (but failed so far) is to show that . Then in view of , this would imply that . Then analogously, , and we would have been done. Could someone please help me out? Thank you very much in advance! A property holds locally -almost everywhere if the set of points at which it fails to hold is locally -null. A set is called locally -null if for each set that belongs to and satisfies the set is -null.","(X,\mathscr{A},\mu) p 1\leq p<+\infty q \frac{1}{p}+\frac{1}{q}=1 g \mathscr{L}^q(X,\mathscr{A},\mu) fg f \mathscr{L}^p(X,\mathscr{A},\mu) \begin{align*}
    T_g(f) = \int fgd\mu
\end{align*} T_g \mathscr{L}^p(X,\mathscr{A},\mu) T \mathscr{L}^q(X,\mathscr{A},\mu) \left(L^p(X,\mathscr{A},\mu)\right)^* g T_g g_1 g_2 T_{g_1}=T_{g_2} q=+\infty g_1 g_2 T_{g_1}=T_{g_2} fg_1 fg_2 A=\{x\in X:(fg_1)(x) \neq (fg_2)(x)\} h \begin{align*}
h(x)=
\begin{cases}
+\infty\quad &\text{if x\in A},\\
0\quad &\text{if x\neq A}.
\end{cases}
\end{align*} \{h_n\} h_n=n\chi_{A} h(x)=\lim_{n\to\infty}h_n(x) x\in X \int hd\mu = \lim_{n\to\infty}\int h_nd\mu \int hd\mu=0 fg_1\leq fg_2+h \int fg_1d\mu\leq\int fg_2d\mu + \int hd\mu = \int fg_2d\mu \int fg_2d\mu\leq\int fg_1d\mu \mu \mu N \mu A \mathscr{A} \mu(A)<+\infty A\bigcap N \mu","['real-analysis', 'integration', 'functional-analysis', 'analysis', 'measure-theory']"
86,Solve an integral equation using functional analysis,Solve an integral equation using functional analysis,,"I'm trying to solve the following equation: Is there a continuous function $f: [0,1] \rightarrow \mathbb{R}$ that satisfies $$f(x) + \int_0^x e^{x \cos(t)}f(t) \ dt = x^2 + 1, x \in [0,1]$$ if so, check if it is unique. We were also given the hint to check if -1 is in the spectre of the operator. I tried several approaches; I tried using $x^2+1$ as $f$ , but it didn't work. My next approach was to show that the norm of the operator is less than 1, which would imply that -1 is not in the spectre, but that didn't work either. Could you please give me a hint as to which approach I should use here. Thank you.","I'm trying to solve the following equation: Is there a continuous function that satisfies if so, check if it is unique. We were also given the hint to check if -1 is in the spectre of the operator. I tried several approaches; I tried using as , but it didn't work. My next approach was to show that the norm of the operator is less than 1, which would imply that -1 is not in the spectre, but that didn't work either. Could you please give me a hint as to which approach I should use here. Thank you.","f: [0,1] \rightarrow \mathbb{R} f(x) + \int_0^x e^{x \cos(t)}f(t) \ dt = x^2 + 1, x \in [0,1] x^2+1 f","['functional-analysis', 'integral-equations']"
87,A Hölder bound on an integral involving the complex exponential.,A Hölder bound on an integral involving the complex exponential.,,"I want to show that if $\gamma \in (0,1)$ we have: $$\int_{\mathbb R^n}\frac{|e^{i x \cdot \xi}-e^{iy\cdot \xi}|^2}{|\xi|^{n+2\gamma}}\,\mathrm d \xi \le C_{n , \gamma} |x-y|^{2 \gamma}$$ for some $C_{n,\gamma}>0$ only dependent on $n, \gamma$ . Some ideas: We can use the fact $f(z)=e^{iz}$ has complex derivative of modulus $\le 1$ and Cauchy-Schwarz to bound the numerator. Hölder/Cauchy Schwarz inequalities in the relevant $L^p$ spaces come to mind, as does splitting up the integral into a near $0$ and tail term and bounding contributions. None of these seem to give bounds of the right form from what I have tried however.","I want to show that if we have: for some only dependent on . Some ideas: We can use the fact has complex derivative of modulus and Cauchy-Schwarz to bound the numerator. Hölder/Cauchy Schwarz inequalities in the relevant spaces come to mind, as does splitting up the integral into a near and tail term and bounding contributions. None of these seem to give bounds of the right form from what I have tried however.","\gamma \in (0,1) \int_{\mathbb R^n}\frac{|e^{i x \cdot \xi}-e^{iy\cdot \xi}|^2}{|\xi|^{n+2\gamma}}\,\mathrm d \xi \le C_{n , \gamma} |x-y|^{2 \gamma} C_{n,\gamma}>0 n, \gamma f(z)=e^{iz} \le 1 L^p 0","['functional-analysis', 'analysis', 'functional-inequalities']"
88,Does improvement on regularity implies compactness?,Does improvement on regularity implies compactness?,,"Let $M$ be a compact metric space and $\mathcal C^0(M)=\{f:M\to\mathbb R; f\ \text{is continous}\}$ . Let $T:\mathcal C^0(M)\to \mathcal C^0(M)$ be a bounded linear transformation. Suppose that for every $f\in\mathcal C^0(M)$ we have that $Tf$ is $1/2$ -Hölder. Does this imply that $T$ is compact? It is clear that if $ | T f | _ {\mathcal C^{1/2} (M)}\leq K$ for some $ K> 0$ for every $\| f\|_{\mathcal C^0(M)}\leq 1$ , then Arzela-Ascoli implies the result. However, I believe that this is not generally true. Also, I am not able to imply that $T(B(0,1))$ is equicontinuous.","Let be a compact metric space and . Let be a bounded linear transformation. Suppose that for every we have that is -Hölder. Does this imply that is compact? It is clear that if for some for every , then Arzela-Ascoli implies the result. However, I believe that this is not generally true. Also, I am not able to imply that is equicontinuous.","M \mathcal C^0(M)=\{f:M\to\mathbb R; f\ \text{is continous}\} T:\mathcal C^0(M)\to \mathcal C^0(M) f\in\mathcal C^0(M) Tf 1/2 T  | T f | _ {\mathcal C^{1/2} (M)}\leq K  K> 0 \| f\|_{\mathcal C^0(M)}\leq 1 T(B(0,1))","['real-analysis', 'functional-analysis']"
89,Action of exponential of multiplication operator on $L^2$,Action of exponential of multiplication operator on,L^2,"Let $X: L^2(\mathbb{R}) \rightarrow L^2(\mathbb{R})$ be a multiplication operator, i.e. $f(x) \mapsto xf(x)$ for $f \in L^2$ . Multiplication operators are known to be self-adjoint on some dense subset of $L^2$ , and so by Stone's theorem on one-parameter unitary groups $X$ is the infinitesimal generator of some one-parameter group of operators $U(t)$ such that $U(t) = e^{itX}$ . I am interested in explicitly finding the action of $e^{itX}$ on an $L^2$ function $f$ . In an analogy with the heat semigroup, I think this can be determined by thinking of $e^{itX}$ as the solution to the differential equation $$\partial_t f = ixf$$ but I don't think this would make sense since $f$ is only assumed to be a function of $x$ . How can one find and/or describe how $e^{itX}$ acts on $L^2$ functions? Can anything be said about $e^{tx}$ ?","Let be a multiplication operator, i.e. for . Multiplication operators are known to be self-adjoint on some dense subset of , and so by Stone's theorem on one-parameter unitary groups is the infinitesimal generator of some one-parameter group of operators such that . I am interested in explicitly finding the action of on an function . In an analogy with the heat semigroup, I think this can be determined by thinking of as the solution to the differential equation but I don't think this would make sense since is only assumed to be a function of . How can one find and/or describe how acts on functions? Can anything be said about ?",X: L^2(\mathbb{R}) \rightarrow L^2(\mathbb{R}) f(x) \mapsto xf(x) f \in L^2 L^2 X U(t) U(t) = e^{itX} e^{itX} L^2 f e^{itX} \partial_t f = ixf f x e^{itX} L^2 e^{tx},"['functional-analysis', 'operator-theory', 'semigroup-of-operators']"
90,Why Applying A Continuous Linear Elliptic Differential Operator Gives A Functional and Clarifying Dual Space Definition,Why Applying A Continuous Linear Elliptic Differential Operator Gives A Functional and Clarifying Dual Space Definition,,"I'm reading a paper on Multiscale FEM Methods and I just need a bit of help better visualizing how to interpret the dual space in the PDE setup. We are given a continuous, linear, elliptic differential operator $O: [H^1(\Omega)]^k \to X_0^*$ for $k=1 ,2 ,3$ . We are considering the problem $$ Ou=f\quad\text{ in }X^*_0 $$ where $X^* _0$ is defined as the dual space of $X_0$ , defined as $$ X_0 = \{ x \in [H^1(\Omega)]^k : x=0 \text{ on the Dirichlet boundary, $x = 0$ on the Multiscale FEM border} \}. $$ We take $u \in X = \{ x \in [H^1(\Omega)]^k : x=0 \mbox { on the Dirichlet boundary} \}$ . In order to visualize this I took $k=1$ and the operator $O$ to be the Laplacian: furthermore I took $u = \sin(\pi x)$ on $\Omega = [0,2]$ . Then we know that $u$ is zero on the boundaries and $u \in H^1(\Omega)$ since $$ \|u\|_{H^1(\Omega)} = 1+\pi^2 < \infty. $$ However, when we apply the differential operator I get $$ f = \pi^2 \sin(\pi x). $$ This function does map input values to the field of real numbers but it is not a linear function. this goes against my understanding of what it means to be an element of the dual space. So my questions are: Am I misunderstanding something about the definition of a dual space? (I thought you just had to map elements from the space to a field via a linear function). Am I misunderstanding something else fundamental to the setup of this problem? Sorry if this is a silly question and thank you very much for any insights.","I'm reading a paper on Multiscale FEM Methods and I just need a bit of help better visualizing how to interpret the dual space in the PDE setup. We are given a continuous, linear, elliptic differential operator for . We are considering the problem where is defined as the dual space of , defined as We take . In order to visualize this I took and the operator to be the Laplacian: furthermore I took on . Then we know that is zero on the boundaries and since However, when we apply the differential operator I get This function does map input values to the field of real numbers but it is not a linear function. this goes against my understanding of what it means to be an element of the dual space. So my questions are: Am I misunderstanding something about the definition of a dual space? (I thought you just had to map elements from the space to a field via a linear function). Am I misunderstanding something else fundamental to the setup of this problem? Sorry if this is a silly question and thank you very much for any insights.","O: [H^1(\Omega)]^k \to X_0^* k=1 ,2 ,3 
Ou=f\quad\text{ in }X^*_0
 X^* _0 X_0 
X_0 = \{ x \in [H^1(\Omega)]^k : x=0 \text{ on the Dirichlet boundary, x = 0 on the Multiscale FEM border} \}.
 u \in X = \{ x \in [H^1(\Omega)]^k : x=0 \mbox { on the Dirichlet boundary} \} k=1 O u = \sin(\pi x) \Omega = [0,2] u u \in H^1(\Omega) 
\|u\|_{H^1(\Omega)} = 1+\pi^2 < \infty.
 
f = \pi^2 \sin(\pi x).
","['functional-analysis', 'partial-differential-equations', 'dual-spaces', 'finite-element-method']"
91,Surjectivity of $T: l_2 \to l_2$ defined as $(x_n)_{n=1}^\infty \mapsto (x_n+x_{n+1})_{n=1}^\infty$,Surjectivity of  defined as,T: l_2 \to l_2 (x_n)_{n=1}^\infty \mapsto (x_n+x_{n+1})_{n=1}^\infty,"\begin{aligned} T: l_{2}(\mathbb{C}) &\longrightarrow l_{2}(\mathbb{C}) \\ \left(x_{n}\right)_{n=1}^{\infty} &\longmapsto\left(x_{n}+x_{n+1}\right)_{n=1}^{\infty} \end{aligned} Any element of $l_2$ can be uniquely expressed in the basis $\{e_n\}_{n=1}^{\infty}$ : $$ \left(x_{n}\right)_{n=1}^{\infty}=\lim _{k \rightarrow \infty} \sum_{n=1}^{k} x_{n} e_{n}, \quad e_{n}=\left(\delta_{n_{j}}\right)_{j=1}^{\infty} \\ $$ I found these $e_n$ in Im $(T)$ : \begin{aligned} v_{1} & =(1,0,0,0, \ldots) & \longmapsto & &(1,0,0,0, \ldots) \\ v_{2} & =(-1,1,0,0, \ldots) & \longmapsto & &(0,1,0,0, \cdots) \\ v_{3} & =(1,-1,1,0, \ldots) & \longmapsto & &(0,0,1,0, \cdots) \\ \vdots\\ v_{n} & =\left((-1)^{n+1},(-1)^{n+2}, \ldots,(-1)^{n+n}, 0, \ldots\right) & \longmapsto & &(0, \ldots, 0,1,0, \ldots) \\ \vdots \end{aligned} Now, for any $\left(y_{n}\right)_{n=1}^{\infty} \in l_2$ , $$ \sum_{n=1}^{\infty} y_{n} e_{n}=\sum_{n=1}^{\infty} y_{n} T\left(v_{n}\right)=T\left(\sum_{n=1}^{\infty} y_{n} v_{n}\right). $$ However, the limit \begin{equation} \lim _{k \rightarrow \infty} \sum_{n=1}^{k} y_{n} v_{n}=\left(y_{n}^{\prime}\right)_{n=1}^{\infty} \end{equation} would have to exist, every element $y_{n}^{\prime}$ of the sequence, \begin{equation} \begin{aligned} y_{1}^{\prime} & =y_{1}-y_{2}+y_{3}-y_{4} \cdots \\ y_{2}^{\prime} & =y_{2}-y_{3}+y_{4}-y_{5} \cdots \\ \vdots\\ \end{aligned} \end{equation} would have to converge and, finally, that \begin{equation} ||\left(y_{n}^{\prime}\right)_{n=1}^{\infty}||=\sum_{n=1}^{\infty}\left|y_{n}^\prime\right|^{2}<\infty \end{equation} I have arrived to the conclusion that $T$ is not surjective, but I am afraid I could be wrong. Also, as $T$ is inyective,there is an inverse that is again defined, for every element of the transformed sequence, with another alternating series of elements of the input sequence... Thank you; I hope you find it enjoyable!","Any element of can be uniquely expressed in the basis : I found these in Im : Now, for any , However, the limit would have to exist, every element of the sequence, would have to converge and, finally, that I have arrived to the conclusion that is not surjective, but I am afraid I could be wrong. Also, as is inyective,there is an inverse that is again defined, for every element of the transformed sequence, with another alternating series of elements of the input sequence... Thank you; I hope you find it enjoyable!","\begin{aligned}
T: l_{2}(\mathbb{C}) &\longrightarrow l_{2}(\mathbb{C}) \\
\left(x_{n}\right)_{n=1}^{\infty} &\longmapsto\left(x_{n}+x_{n+1}\right)_{n=1}^{\infty}
\end{aligned} l_2 \{e_n\}_{n=1}^{\infty} 
\left(x_{n}\right)_{n=1}^{\infty}=\lim _{k \rightarrow \infty} \sum_{n=1}^{k} x_{n} e_{n}, \quad e_{n}=\left(\delta_{n_{j}}\right)_{j=1}^{\infty} \\
 e_n (T) \begin{aligned}
v_{1} & =(1,0,0,0, \ldots) & \longmapsto & &(1,0,0,0, \ldots) \\
v_{2} & =(-1,1,0,0, \ldots) & \longmapsto & &(0,1,0,0, \cdots) \\
v_{3} & =(1,-1,1,0, \ldots) & \longmapsto & &(0,0,1,0, \cdots) \\
\vdots\\
v_{n} & =\left((-1)^{n+1},(-1)^{n+2}, \ldots,(-1)^{n+n}, 0, \ldots\right) & \longmapsto & &(0, \ldots, 0,1,0, \ldots) \\
\vdots
\end{aligned} \left(y_{n}\right)_{n=1}^{\infty} \in l_2 
\sum_{n=1}^{\infty} y_{n} e_{n}=\sum_{n=1}^{\infty} y_{n} T\left(v_{n}\right)=T\left(\sum_{n=1}^{\infty} y_{n} v_{n}\right).
 \begin{equation}
\lim _{k \rightarrow \infty} \sum_{n=1}^{k} y_{n} v_{n}=\left(y_{n}^{\prime}\right)_{n=1}^{\infty}
\end{equation} y_{n}^{\prime} \begin{equation}
\begin{aligned}
y_{1}^{\prime} & =y_{1}-y_{2}+y_{3}-y_{4} \cdots \\
y_{2}^{\prime} & =y_{2}-y_{3}+y_{4}-y_{5} \cdots \\
\vdots\\
\end{aligned}
\end{equation} \begin{equation}
||\left(y_{n}^{\prime}\right)_{n=1}^{\infty}||=\sum_{n=1}^{\infty}\left|y_{n}^\prime\right|^{2}<\infty
\end{equation} T T","['functional-analysis', 'hilbert-spaces']"
92,"How to compute this ""differential sequence"" of functions?","How to compute this ""differential sequence"" of functions?",,"Given a real function $f$ , define the following sequences of functions: $f_0(x) = f(x)$ ; $f_{i+1}'(x) = [f_i(x+1)-f_i(x-1)]/2$ . Some simple examples are: If $f(x)=x$ , then $f_i(x)=x$ for all $i\geq 0$ (up to an additive constant; note that adding a constant to $f_i$ does not affect $f_{i+1}$ ). Similarly, if $f(x)=x^2$ , then $f_i(x)=x^2$ for all $i\geq 0$ . The ""pattern"" breaks at 3: if $f(x)=x^3$ , then $f_i(x) = x^3 + i\cdot x$ . But for some functions, computing $f_i$ is much harder. I am particualrly interested in $f(x)=1/x$ . I get $f_1(x) = (\ln(x+1)-\ln(x-1))/2$ , but from this point on, the sequence becomes much harder to compute. QUESTIONS: Is there a simple algorithm to compute $f_i(x)$ for a general $f$ ? If not, is there a simple expression for $f_i(x)$ for the case when $f(x)=1/x$ , or at least an expression that approximates $f_i(x)$ ? Does this sequence I made up have a known name?","Given a real function , define the following sequences of functions: ; . Some simple examples are: If , then for all (up to an additive constant; note that adding a constant to does not affect ). Similarly, if , then for all . The ""pattern"" breaks at 3: if , then . But for some functions, computing is much harder. I am particualrly interested in . I get , but from this point on, the sequence becomes much harder to compute. QUESTIONS: Is there a simple algorithm to compute for a general ? If not, is there a simple expression for for the case when , or at least an expression that approximates ? Does this sequence I made up have a known name?",f f_0(x) = f(x) f_{i+1}'(x) = [f_i(x+1)-f_i(x-1)]/2 f(x)=x f_i(x)=x i\geq 0 f_i f_{i+1} f(x)=x^2 f_i(x)=x^2 i\geq 0 f(x)=x^3 f_i(x) = x^3 + i\cdot x f_i f(x)=1/x f_1(x) = (\ln(x+1)-\ln(x-1))/2 f_i(x) f f_i(x) f(x)=1/x f_i(x),"['real-analysis', 'functional-analysis', 'ordinary-differential-equations', 'derivatives', 'delay-differential-equations']"
93,Brezis' exercise 8.30.8: how to find the eigenvalues of this self-adjoint compact operator?,Brezis' exercise 8.30.8: how to find the eigenvalues of this self-adjoint compact operator?,,"Let $I$ be the open interval $(0, 1)$ . Let $k \in \mathbb R \setminus \{1\}$ . We consider the space $$ V := \{v \in H^1 (I) : v(0) = kv(1)\}, $$ and the symmetric bilinear form $a$ defined on $V$ by $$ a(u, v) = \int_I [ u'v' + uv ]  - \left ( \int_I u \right) \left ( \int_I v \right). $$ I am trying to solve a problem in Brezis' Functional Analysis Exercise 8.30 Check that $V$ is a closed subspace of $H^1 (I)$ . In what follows, $V$ is equipped with the Hilbert structure induced by the $H^1$ inner product. Prove that $a$ is a continuous and coercive bilinear form on $V$ . Deduce that for every $f \in L^2 (I)$ there exists a unique solution of the problem $$ (1) \quad u \in V \quad \text{and} \quad a(u, v)=\int_I f v \quad \forall v \in V. $$ Show that the solution $u$ of $(1)$ belongs to $H^2 (I)$ and satisfies $$ (2) \quad \begin{cases} -u'' + u-\int_I u = f \quad \text {on} \quad I, \\ u(0)=k u(1) \text { and } u'(1)=k u'(0). \end{cases} $$ Conversely, prove that any function $u \in H^2(I)$ satisfying $(2)$ is a solution of $(1)$ . Let $k_n \in \mathbb{R} \setminus \{1\}$ for all $n$ . Assume $k_n \xrightarrow{n \to \infty} k \neq 1$ . Set $$ V_n = \{v \in H^1(I) : v(0)=k_n v(1)\} . $$ Given $f \in L^2 (I)$ , let $u_n$ be the solution of $$ (1_n) \quad u_n \in V_n \quad \text { and } \quad a(u_n, v) = \int_I f v \quad \forall v \in V_n . $$ Prove that $u_n \to u$ in $H^1 (I)$ , where $u$ is the solution of $(1)$ . Deduce that $u_n \to u$ in $H^2 (I)$ . What happens to the sequence $\left(u_n\right)$ if $k_n$ converges to $1$ ? Consider the operator $T: L^2 (I) \rightarrow L^2 (I)$ defined by $T f=u$ , where $u$ is the solution of $(1)$ . Show that $T$ is self-adjoint and compact. Study the set $E V(T)$ of eigenvalues of $T$ . I am trying to solve (8.) In below attempt, I come up with a system of $4$ linear equations to solve for $(A, B, C, \beta)$ . Unfortunately, I don't know how to tackle this system. Could you elaborate on how to solve (8.) efficiently? Clearly, $T$ is injective, so $0 \notin EV (T)$ . Let $\frac{1}{\lambda}$ be an eigenvalue and $u$ the corresponding eigenfunction. Then $$ (3) \quad \begin{cases} -u'' - \alpha u = \beta \quad \text {on} \quad I, \\ u(0)=k u(1) \\ u'(1)=k u'(0), \\ \alpha = \lambda-1, \\ \beta = \int_I u. \end{cases} $$ We consider three cases. $\alpha < 0$ . Then $u$ has the form $$ u(x) =  A e^{\sqrt{-\alpha} x} + B e^{-\sqrt{-\alpha} x} +C, $$ for some $A,B, C \in \mathbb R$ to be chosen. We have $$ \begin{align*} u'(x) &= A \sqrt{-\alpha} e^{\sqrt{-\alpha} x} - B \sqrt{-\alpha} e^{-\sqrt{-\alpha} x}, \\ u''(x) &= -A \alpha e^{\sqrt{-\alpha} x} - B \alpha e^{-\sqrt{-\alpha} x}. \end{align*} $$ Then $$ \begin{align*} u (0) &= A+B+C, \\ u (1) &= A e^{\sqrt{-\alpha}} + B e^{-\sqrt{-\alpha}} +C, \\ u' (0) &= A \sqrt{-\alpha} - B \sqrt{-\alpha} , \\ u' (1) &= A \sqrt{-\alpha} e^{\sqrt{-\alpha}} - B \sqrt{-\alpha} e^{-\sqrt{-\alpha}}. \end{align*} $$ We have $-u'' - \alpha u = \beta$ implies $-C\alpha = \beta$ . We have $u'(1)=k u'(0)$ implies $A e^{\sqrt{-\alpha}} - B e^{-\sqrt{-\alpha}} = k(A-B)$ . We have $u(0)=k u(1)$ implies $A+B+C = k (A e^{\sqrt{-\alpha}} + B e^{-\sqrt{-\alpha}} +C)$ . We have $\beta = \int_I u$ implies $\frac{A e^{\sqrt{-\alpha}} - B e^{-\sqrt{-\alpha}}}{\sqrt{-\alpha}} + \frac{B-A}{\sqrt{-\alpha}} = \beta -C$ . So we have the system $$ (4) \quad \begin{cases} \alpha C + \beta &=0 , \\ ( e^{\sqrt{-\alpha}} - k ) A + ( k - e^{-\sqrt{-\alpha}} ) B &=0, \\ ( e^{\sqrt{-\alpha}} - 1 ) A + ( 1 - e^{-\sqrt{-\alpha}} ) B + \sqrt{-\alpha} C - \sqrt{-\alpha} \beta &=0, \\ ( ke^{\sqrt{-\alpha}} - 1 ) A + ( ke^{-\sqrt{-\alpha}} -1 ) B + (k-1) C &=0, \end{cases} $$ to solve for $(A, B, C, \beta)$ .","Let be the open interval . Let . We consider the space and the symmetric bilinear form defined on by I am trying to solve a problem in Brezis' Functional Analysis Exercise 8.30 Check that is a closed subspace of . In what follows, is equipped with the Hilbert structure induced by the inner product. Prove that is a continuous and coercive bilinear form on . Deduce that for every there exists a unique solution of the problem Show that the solution of belongs to and satisfies Conversely, prove that any function satisfying is a solution of . Let for all . Assume . Set Given , let be the solution of Prove that in , where is the solution of . Deduce that in . What happens to the sequence if converges to ? Consider the operator defined by , where is the solution of . Show that is self-adjoint and compact. Study the set of eigenvalues of . I am trying to solve (8.) In below attempt, I come up with a system of linear equations to solve for . Unfortunately, I don't know how to tackle this system. Could you elaborate on how to solve (8.) efficiently? Clearly, is injective, so . Let be an eigenvalue and the corresponding eigenfunction. Then We consider three cases. . Then has the form for some to be chosen. We have Then We have implies . We have implies . We have implies . We have implies . So we have the system to solve for .","I (0, 1) k \in \mathbb R \setminus \{1\} 
V := \{v \in H^1 (I) : v(0) = kv(1)\},
 a V 
a(u, v) = \int_I [ u'v' + uv ]  - \left ( \int_I u \right) \left ( \int_I v \right).
 V H^1 (I) V H^1 a V f \in L^2 (I) 
(1) \quad
u \in V
\quad \text{and} \quad
a(u, v)=\int_I f v
\quad \forall v \in V.
 u (1) H^2 (I) 
(2) \quad
\begin{cases}
-u'' + u-\int_I u = f \quad \text {on} \quad I, \\
u(0)=k u(1) \text { and } u'(1)=k u'(0).
\end{cases}
 u \in H^2(I) (2) (1) k_n \in \mathbb{R} \setminus \{1\} n k_n \xrightarrow{n \to \infty} k \neq 1 
V_n = \{v \in H^1(I) : v(0)=k_n v(1)\} .
 f \in L^2 (I) u_n 
(1_n) \quad
u_n \in V_n
\quad \text { and } \quad
a(u_n, v) = \int_I f v
\quad \forall v \in V_n .
 u_n \to u H^1 (I) u (1) u_n \to u H^2 (I) \left(u_n\right) k_n 1 T: L^2 (I) \rightarrow L^2 (I) T f=u u (1) T E V(T) T 4 (A, B, C, \beta) T 0 \notin EV (T) \frac{1}{\lambda} u 
(3) \quad
\begin{cases}
-u'' - \alpha u = \beta \quad \text {on} \quad I, \\
u(0)=k u(1) \\
u'(1)=k u'(0), \\
\alpha = \lambda-1, \\
\beta = \int_I u.
\end{cases}
 \alpha < 0 u 
u(x) =  A e^{\sqrt{-\alpha} x} + B e^{-\sqrt{-\alpha} x} +C,
 A,B, C \in \mathbb R 
\begin{align*}
u'(x) &= A \sqrt{-\alpha} e^{\sqrt{-\alpha} x} - B \sqrt{-\alpha} e^{-\sqrt{-\alpha} x}, \\
u''(x) &= -A \alpha e^{\sqrt{-\alpha} x} - B \alpha e^{-\sqrt{-\alpha} x}.
\end{align*}
 
\begin{align*}
u (0) &= A+B+C, \\
u (1) &= A e^{\sqrt{-\alpha}} + B e^{-\sqrt{-\alpha}} +C, \\
u' (0) &= A \sqrt{-\alpha} - B \sqrt{-\alpha} , \\
u' (1) &= A \sqrt{-\alpha} e^{\sqrt{-\alpha}} - B \sqrt{-\alpha} e^{-\sqrt{-\alpha}}.
\end{align*}
 -u'' - \alpha u = \beta -C\alpha = \beta u'(1)=k u'(0) A e^{\sqrt{-\alpha}} - B e^{-\sqrt{-\alpha}} = k(A-B) u(0)=k u(1) A+B+C = k (A e^{\sqrt{-\alpha}} + B e^{-\sqrt{-\alpha}} +C) \beta = \int_I u \frac{A e^{\sqrt{-\alpha}} - B e^{-\sqrt{-\alpha}}}{\sqrt{-\alpha}} + \frac{B-A}{\sqrt{-\alpha}} = \beta -C 
(4) \quad
\begin{cases}
\alpha C + \beta &=0 , \\
( e^{\sqrt{-\alpha}} - k ) A + ( k - e^{-\sqrt{-\alpha}} ) B &=0, \\
( e^{\sqrt{-\alpha}} - 1 ) A + ( 1 - e^{-\sqrt{-\alpha}} ) B + \sqrt{-\alpha} C - \sqrt{-\alpha} \beta &=0, \\
( ke^{\sqrt{-\alpha}} - 1 ) A + ( ke^{-\sqrt{-\alpha}} -1 ) B + (k-1) C &=0,
\end{cases}
 (A, B, C, \beta)","['functional-analysis', 'ordinary-differential-equations', 'sobolev-spaces', 'spectral-theory', 'eigenfunctions']"
94,Intersection of weak topologies,Intersection of weak topologies,,"Let $X$ be a real vector space, let $X^\star$ be its algebraic dual, and fix two vector subspaces $\mathscr{A}, \mathscr{B}\subseteq X^\star$ such that $\mathscr{C}:=\mathscr{A}\cap \mathscr{B} \neq \{0\}$ . Question. Is it true that a convex subset $S\subseteq X$ is closed in the both the weak topologies generated by $\mathscr{A}$ and $\mathscr{B}$ (that is, $S$ is closed in $(X,\sigma(X,\mathscr{A})$ and $(X,\sigma(X,\mathscr{B}))$ ) if and only if $S$ is closed in $(X,\sigma(X,\mathscr{C}))$ ? The ""if"" part should be trivial by the fact that $\mathscr{C}\subseteq \mathscr{A}$ and $\mathscr{C}\subseteq \mathscr{B}$ , so that $\sigma(X,\mathscr{C})\subseteq \sigma(X,\mathscr{A})$ and $\sigma(X,\mathscr{C})\subseteq \sigma(X,\mathscr{B})$ (without the hypothesis that $S$ is convex). What about the converse? Ps. Here, the weak topology $\sigma(X,\mathscr{A})$ is the coarser topology on $X$ such that each function in $\mathscr{A}$ is continuous.","Let be a real vector space, let be its algebraic dual, and fix two vector subspaces such that . Question. Is it true that a convex subset is closed in the both the weak topologies generated by and (that is, is closed in and ) if and only if is closed in ? The ""if"" part should be trivial by the fact that and , so that and (without the hypothesis that is convex). What about the converse? Ps. Here, the weak topology is the coarser topology on such that each function in is continuous.","X X^\star \mathscr{A}, \mathscr{B}\subseteq X^\star \mathscr{C}:=\mathscr{A}\cap \mathscr{B} \neq \{0\} S\subseteq X \mathscr{A} \mathscr{B} S (X,\sigma(X,\mathscr{A}) (X,\sigma(X,\mathscr{B})) S (X,\sigma(X,\mathscr{C})) \mathscr{C}\subseteq \mathscr{A} \mathscr{C}\subseteq \mathscr{B} \sigma(X,\mathscr{C})\subseteq \sigma(X,\mathscr{A}) \sigma(X,\mathscr{C})\subseteq \sigma(X,\mathscr{B}) S \sigma(X,\mathscr{A}) X \mathscr{A}","['functional-analysis', 'weak-topology']"
95,Pointwise a.e. approximation by a sequence of smooth functions with supremum bound,Pointwise a.e. approximation by a sequence of smooth functions with supremum bound,,"There are many well known results on approximations by regular functions. Here are some of them. If $f : \mathbb R \to \mathbb R$ is (Lebesgue) measurable, then there exists a sequence of continuous functions $f_n : \mathbb R \to \mathbb R$ such that $f_n \to f$ pointwise a.e. (see here for a proof). If $f \in C(\mathbb R)$ is a continuous function then there exists a sequence of functions $f_n \in C^{\infty}(\mathbb R)$ such that $f_n \to f$ uniformly on every compact subset of $\mathbb R$ . Furthermore, if $f \in C^K(\mathbb R)$ then the convergence can be ensured to uniformly hold on every compact set for all derivatives up to order $K$ . The set $C_c^{\infty}(\mathbb R^d)$ is dense in each of the spaces $L^p(\mathbb R^d), 1 \leq p < \infty$ in their norms. I am aware that pointwise a.e. convergence is a very weak form of convergence to ask for. A tool like Lusin's theorem with an approximation argument is enough to guarantee a convergence result. Keeping this in mind, I'm thinking that a slightly stronger version of this convergence, which I require, should also be true. The key difference with this problem is that I require a uniform bound on the approximating functions in question. Suppose that $g : \mathbb R \to \mathbb R$ is a Borel measurable function such that $|g|$ is essentially bounded above by $1$ . Then, does there exist a sequence of functions $\{f_n\}_{n \geq 1}$ , such that each $f_n$ is twice differentiable with bounded and continuous derivatives, $|f_n| \leq 1$ on $\mathbb R^d$ for all $n$ , and $f_n \to g$ pointwise a.e.? Now, without the condition $|f_n| \leq 1$ on $\mathbb R^d$ , there is no problem at all. We may consider a sequence of continuous functions $h_n$ which approach $g$ pointwise a.e., and for each $h_n$ we can consider a sequence of smooth functions $h_{ni} \to h_n$ pointwise a.e. We'll be done by a diagonal argument. However, it's not possible to place a restriction on $|h_{ni}|$ , it seems, in any particular way. That insight is what I'm looking for here.","There are many well known results on approximations by regular functions. Here are some of them. If is (Lebesgue) measurable, then there exists a sequence of continuous functions such that pointwise a.e. (see here for a proof). If is a continuous function then there exists a sequence of functions such that uniformly on every compact subset of . Furthermore, if then the convergence can be ensured to uniformly hold on every compact set for all derivatives up to order . The set is dense in each of the spaces in their norms. I am aware that pointwise a.e. convergence is a very weak form of convergence to ask for. A tool like Lusin's theorem with an approximation argument is enough to guarantee a convergence result. Keeping this in mind, I'm thinking that a slightly stronger version of this convergence, which I require, should also be true. The key difference with this problem is that I require a uniform bound on the approximating functions in question. Suppose that is a Borel measurable function such that is essentially bounded above by . Then, does there exist a sequence of functions , such that each is twice differentiable with bounded and continuous derivatives, on for all , and pointwise a.e.? Now, without the condition on , there is no problem at all. We may consider a sequence of continuous functions which approach pointwise a.e., and for each we can consider a sequence of smooth functions pointwise a.e. We'll be done by a diagonal argument. However, it's not possible to place a restriction on , it seems, in any particular way. That insight is what I'm looking for here.","f : \mathbb R \to \mathbb R f_n : \mathbb R \to \mathbb R f_n \to f f \in C(\mathbb R) f_n \in C^{\infty}(\mathbb R) f_n \to f \mathbb R f \in C^K(\mathbb R) K C_c^{\infty}(\mathbb R^d) L^p(\mathbb R^d), 1 \leq p < \infty g : \mathbb R \to \mathbb R |g| 1 \{f_n\}_{n \geq 1} f_n |f_n| \leq 1 \mathbb R^d n f_n \to g |f_n| \leq 1 \mathbb R^d h_n g h_n h_{ni} \to h_n |h_{ni}|","['functional-analysis', 'measure-theory', 'lebesgue-measure', 'smooth-functions']"
96,Riesz-Markov theorem and positive linear functionals on real-valued continuous functions,Riesz-Markov theorem and positive linear functionals on real-valued continuous functions,,"Riesz-Markov theorem : Let $X$ be a locally compact Hausdorff space. For any continuous linear functional $\Psi$ on $C_0(X)$ , there is a unique regular countably additive complex Borel measure $\mu$ on $X$ that $$ \forall f \in C_0(X): \Psi(f)=\int_X f(x)d\mu(x). $$ The norm of $\Psi$ as a linear functional is $||\Psi||=|\mu|(X)$ . Finally, $\Psi$ is positive if and only if the measure $\mu$ is non-negative. The different versions I have found of the Riesz-Markov theorem do not specify if the set of continuous functions on X which vanish at infinity are real or complex valued functions. I want to say that if I have a positive linear functional defined on $C^\mathbb{R}_0(X)$ where $X$ is a compact Hausdorff space, and $||\Psi||=1$ , then the measure given by the theorem is a probability measure. Any help on this topic? Thanks.","Riesz-Markov theorem : Let be a locally compact Hausdorff space. For any continuous linear functional on , there is a unique regular countably additive complex Borel measure on that The norm of as a linear functional is . Finally, is positive if and only if the measure is non-negative. The different versions I have found of the Riesz-Markov theorem do not specify if the set of continuous functions on X which vanish at infinity are real or complex valued functions. I want to say that if I have a positive linear functional defined on where is a compact Hausdorff space, and , then the measure given by the theorem is a probability measure. Any help on this topic? Thanks.",X \Psi C_0(X) \mu X  \forall f \in C_0(X): \Psi(f)=\int_X f(x)d\mu(x).  \Psi ||\Psi||=|\mu|(X) \Psi \mu C^\mathbb{R}_0(X) X ||\Psi||=1,"['real-analysis', 'functional-analysis', 'measure-theory', 'borel-measures', 'riesz-representation-theorem']"
97,A doubt on Theorem 2.6 from Pazy's book,A doubt on Theorem 2.6 from Pazy's book,,"I have been very confused about an argument on Theorem 2.6 from Pazy, Semigroups of Linear Operators and Applications to Partial Differential Equations. Here is the theorem and part of the proof: I just can not prove that red part from the picture just using that the semigroups are $C_0$ . Remember that a semigroup $\{T_t\}_{t \geq 0}$ of bounded linear operators on a Banach space is $C_0$ if $\lim_{t \rightarrow 0^+} T(t)x = x,$ for all $x \in X.$ Here there's another discussion about the same doubt, which I still didn't understand. Here is my attempt : Fixed $t > 0$ , consider the function $\varphi(r) = T(t - r)(S(r)x),$ with $r \leq t$ . So, for a $s \geq 0$ , we want to describe $\frac{d \varphi}{d r}(s)$ . Notice that \begin{align} \frac{\varphi(s + h) - \varphi(s)}{h} & = \frac{1}{h}[T(t - (s + h))(S(s + h)x) - T(t - s)(S(s)x)] \\ & = \frac{1}{h}[T(t - (s + h))(S(s + h)x) - T(t - s)(S(s)x) - T(t - (s+h))(S(s)x) + T(t - (s+h))(S(s)x)] \\ & = \frac{1}{h} [T(t - (s + h))(S(s + h)x) - T(t - (s + h))(S(s)x)] + \frac{1}{h}[T(t - (s+h))(S(s)x) - T(t - s)(S(s)x)  ] \\ &  \end{align} Lets conclude something about the second quotient above. For $\tilde{h} = - h$ , we deduce \begin{align} \frac{1}{h}[T(t - (s+h))(S(s)x) - T(t - s)(S(s)x)] & = -\frac{1}{\tilde{h}}[T(\tilde{h} + (t - s))(S(s)x) - T(t - s)(S(s)x)] \\ & = -\frac{1}{\tilde{h}}[T(\tilde{h})( T(t - s)(S(s)x)) - T(t - s)(S(s)x)], \end{align} which converges to $-A(T(t-s)(S(s)x))$ . For me the problem is in the first quotient. Notice that \begin{align} \frac{1}{h} [T(t - (s + h))(S(s + h)x) - T(t - (s + h))(S(s)x)] & = T(t - (s+h)) \frac{(S(s+h)x - S(s)x)}{h} \\ & = T(t - (s+h)) \frac{(S(h)(S(s)x) - S(s)x)}{h}. \end{align} Somehow, I think that this should converge to $T(t-s)(B(S(s)x))$ as $h \rightarrow 0^+$ . However, I was not able to obtain this just using that $\{T(t)\}$ is a $C_0$ semigroup. All I know it is $$ \lim_{h \rightarrow 0^+} \frac{(S(h)(S(s)x) - S(s)x)}{h} = B(S(s)x). $$ Any help is very welcome.","I have been very confused about an argument on Theorem 2.6 from Pazy, Semigroups of Linear Operators and Applications to Partial Differential Equations. Here is the theorem and part of the proof: I just can not prove that red part from the picture just using that the semigroups are . Remember that a semigroup of bounded linear operators on a Banach space is if for all Here there's another discussion about the same doubt, which I still didn't understand. Here is my attempt : Fixed , consider the function with . So, for a , we want to describe . Notice that Lets conclude something about the second quotient above. For , we deduce which converges to . For me the problem is in the first quotient. Notice that Somehow, I think that this should converge to as . However, I was not able to obtain this just using that is a semigroup. All I know it is Any help is very welcome.","C_0 \{T_t\}_{t \geq 0} C_0 \lim_{t \rightarrow 0^+} T(t)x = x, x \in X. t > 0 \varphi(r) = T(t - r)(S(r)x), r \leq t s \geq 0 \frac{d \varphi}{d r}(s) \begin{align}
\frac{\varphi(s + h) - \varphi(s)}{h} & = \frac{1}{h}[T(t - (s + h))(S(s + h)x) - T(t - s)(S(s)x)] \\
& = \frac{1}{h}[T(t - (s + h))(S(s + h)x) - T(t - s)(S(s)x) - T(t - (s+h))(S(s)x) + T(t - (s+h))(S(s)x)] \\
& = \frac{1}{h} [T(t - (s + h))(S(s + h)x) - T(t - (s + h))(S(s)x)] + \frac{1}{h}[T(t - (s+h))(S(s)x) - T(t - s)(S(s)x)  ] \\
& 
\end{align} \tilde{h} = - h \begin{align}
\frac{1}{h}[T(t - (s+h))(S(s)x) - T(t - s)(S(s)x)] & = -\frac{1}{\tilde{h}}[T(\tilde{h} + (t - s))(S(s)x) - T(t - s)(S(s)x)] \\
& = -\frac{1}{\tilde{h}}[T(\tilde{h})( T(t - s)(S(s)x)) - T(t - s)(S(s)x)],
\end{align} -A(T(t-s)(S(s)x)) \begin{align}
\frac{1}{h} [T(t - (s + h))(S(s + h)x) - T(t - (s + h))(S(s)x)] & = T(t - (s+h)) \frac{(S(s+h)x - S(s)x)}{h} \\
& = T(t - (s+h)) \frac{(S(h)(S(s)x) - S(s)x)}{h}.
\end{align} T(t-s)(B(S(s)x)) h \rightarrow 0^+ \{T(t)\} C_0 
\lim_{h \rightarrow 0^+} \frac{(S(h)(S(s)x) - S(s)x)}{h} = B(S(s)x).
","['functional-analysis', 'partial-differential-equations', 'semigroup-of-operators', 'hyperbolic-equations', 'parabolic-pde']"
98,Coercivity and spectral gap: understanding the equivalence,Coercivity and spectral gap: understanding the equivalence,,"I am referring to this paper , p. 21. First, there is the following definition of coercivity : Let $L$ be an unbounded operator on a Hilbert space $\mathcal{H}$ with kernel $\mathcal{K}$ and let $\tilde{\mathcal{H}}$ be another Hilbert space continuously and densely embedded in $\mathcal{K}^\perp$ , endowed with a scalar product $\langle\cdot,\cdot\rangle_{\tilde{\mathcal{H}}}$ and a Hilbertian norm $\Vert\cdot\Vert_{\tilde{\mathcal{H}}}$ . The operator $L$ is said to be $\lambda$ -coercive on $\tilde{\mathcal{H}}$ if $$ \forall h\in\mathcal{K}^\perp\cap D(L),\quad\Re\langle Lh,h\rangle_{\tilde{\mathcal{H}}}\geq\lambda\Vert h\Vert^2_{\tilde{\mathcal{H}}}, $$ where $\Re$ stands for the real part. The operator $L$ is said to be coercive on $\tilde{\mathcal{H}}$ if it is $\lambda$ -coercive on $\tilde{\mathcal{H}}$ for some $\lambda>0$ . Afterwards, it is said that [..] the most standard situation is when $\tilde{\mathcal{H}}=\mathcal{K}^\perp\simeq \mathcal{H}/\mathcal{K}$ . Moreover, in this particular case, it is said that [..] it is equivalent to say that $L$ is coercive on $\mathcal{K}^\perp$ , or that the symmetric part of $L$ admits a spectral gap . Could you please explain to me why this equivalence holds? As far as I understand, spectral gap means that there exists some $c>0$ such that $$ \sigma(L)\subset\{0\}\cup [c,\infty) $$ However, from this, I can neither conclude that $L$ is coercive on $\mathcal{K}^\perp$ (nor vice versa). My ""feeling"" is that this has something to do with the relationship between the spectrum of $L$ and its numerical range (but I only know this for self-adjoint bounded operators and this seems to be another situation here).","I am referring to this paper , p. 21. First, there is the following definition of coercivity : Let be an unbounded operator on a Hilbert space with kernel and let be another Hilbert space continuously and densely embedded in , endowed with a scalar product and a Hilbertian norm . The operator is said to be -coercive on if where stands for the real part. The operator is said to be coercive on if it is -coercive on for some . Afterwards, it is said that [..] the most standard situation is when . Moreover, in this particular case, it is said that [..] it is equivalent to say that is coercive on , or that the symmetric part of admits a spectral gap . Could you please explain to me why this equivalence holds? As far as I understand, spectral gap means that there exists some such that However, from this, I can neither conclude that is coercive on (nor vice versa). My ""feeling"" is that this has something to do with the relationship between the spectrum of and its numerical range (but I only know this for self-adjoint bounded operators and this seems to be another situation here).","L \mathcal{H} \mathcal{K} \tilde{\mathcal{H}} \mathcal{K}^\perp \langle\cdot,\cdot\rangle_{\tilde{\mathcal{H}}} \Vert\cdot\Vert_{\tilde{\mathcal{H}}} L \lambda \tilde{\mathcal{H}} 
\forall h\in\mathcal{K}^\perp\cap D(L),\quad\Re\langle Lh,h\rangle_{\tilde{\mathcal{H}}}\geq\lambda\Vert h\Vert^2_{\tilde{\mathcal{H}}},
 \Re L \tilde{\mathcal{H}} \lambda \tilde{\mathcal{H}} \lambda>0 \tilde{\mathcal{H}}=\mathcal{K}^\perp\simeq \mathcal{H}/\mathcal{K} L \mathcal{K}^\perp L c>0 
\sigma(L)\subset\{0\}\cup [c,\infty)
 L \mathcal{K}^\perp L","['functional-analysis', 'operator-theory', 'spectral-theory', 'kinematics', 'coercive']"
99,If translation of function is smooth then function is smooth,If translation of function is smooth then function is smooth,,Let $\varphi \in L^2(\mathbb{R}^n)$ . Recall that we write $\tau_t\varphi(x) = \varphi(x-t)$ . I want to show that if $t\mapsto\tau_t\varphi\in L^2(\mathbb{R}^n)$ is a smooth map then $\varphi$ is smooth. I tried to use mollifier but I don't see how it can be useful.,Let . Recall that we write . I want to show that if is a smooth map then is smooth. I tried to use mollifier but I don't see how it can be useful.,\varphi \in L^2(\mathbb{R}^n) \tau_t\varphi(x) = \varphi(x-t) t\mapsto\tau_t\varphi\in L^2(\mathbb{R}^n) \varphi,"['real-analysis', 'functional-analysis']"
