,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How can we determine the number of terms which we have to take in a series to get a particular accurate?,How can we determine the number of terms which we have to take in a series to get a particular accurate?,,"As I remember , two days ago , there was a question ( here ) asks for calculating this limit $\displaystyle \lim \limits_{x\rightarrow \infty } \frac{x^3}{e^x}$ and the question was answered . of course this is an easy limit , we can calculate it using l'hopital rule . Now ,  if I expressed $\displaystyle e^x = 1+x+\frac{x^2}{2!} + \frac{x^3}{3!} + \ldots  = \sum\limits_{i=0}^{\infty}\frac{x^i}{i!}$ and substitute back an approximation for $e^x$. If we approximated $e^x$ for 3 terms then the limit is $\infty$ , if we approximated it for 4 terms then the limit is 6 but if we approximated for 5 terms then we get the right answer which is 0 . Now , How can we know that approximation for 5 terms will work while approximation for 4 or 3 terms would fail ? Is there any test or analytical method to determine this ? I used the geometric approach to see the reason behind that . here is the sketch for those approximations and the original function which illustrate and show why approximation for  3 and 4 terms fail . but I ask for Analytical approach as using the sketch of approximations is not rigorous and practical in general .","As I remember , two days ago , there was a question ( here ) asks for calculating this limit $\displaystyle \lim \limits_{x\rightarrow \infty } \frac{x^3}{e^x}$ and the question was answered . of course this is an easy limit , we can calculate it using l'hopital rule . Now ,  if I expressed $\displaystyle e^x = 1+x+\frac{x^2}{2!} + \frac{x^3}{3!} + \ldots  = \sum\limits_{i=0}^{\infty}\frac{x^i}{i!}$ and substitute back an approximation for $e^x$. If we approximated $e^x$ for 3 terms then the limit is $\infty$ , if we approximated it for 4 terms then the limit is 6 but if we approximated for 5 terms then we get the right answer which is 0 . Now , How can we know that approximation for 5 terms will work while approximation for 4 or 3 terms would fail ? Is there any test or analytical method to determine this ? I used the geometric approach to see the reason behind that . here is the sketch for those approximations and the original function which illustrate and show why approximation for  3 and 4 terms fail . but I ask for Analytical approach as using the sketch of approximations is not rigorous and practical in general .",,"['calculus', 'sequences-and-series', 'limits', 'taylor-expansion']"
1,problem about uniform continuity,problem about uniform continuity,,"Problem: ""Show that if $f:\left[a,+\infty\right] \rightarrow \mathbb R$ is continuous and if $\lim_{x \rightarrow + \infty} f(x)$ exists, then $f$ is uniformly continuous"". I have a question about this problem. My partial solution: $\lim_{x\rightarrow +\infty}f(x) = L \Rightarrow \forall \varepsilon>0, \exists M>0$ such that $x \geq M \Rightarrow  |f(x)-L|<\frac{\varepsilon}{2}$. Given $x_1$,$x_2$ $\in$$[M, \infty)$$\Rightarrow |f(x_1)-L|<\frac{\varepsilon}{2}$ and $|f(x_2)-L|<\frac{\varepsilon}{2}$ $\Rightarrow |f(x_1)-L|<\frac{\varepsilon}{2}$ and $|L-f(x_2)|<\frac{\varepsilon}{2}$ $\Rightarrow |f(x_1)-L+L-f(x_2)|\leq |f(x_1)-L|+|L-f(x_2)|< \varepsilon$ $\Rightarrow |f(x_1) - f(x_2)|<\varepsilon$ $\Rightarrow$ $f$ is uniformly continuous on $[M, +\infty)$. How can I extend this result towards $f$ uniformly continuous on $[a, +\infty]$?","Problem: ""Show that if $f:\left[a,+\infty\right] \rightarrow \mathbb R$ is continuous and if $\lim_{x \rightarrow + \infty} f(x)$ exists, then $f$ is uniformly continuous"". I have a question about this problem. My partial solution: $\lim_{x\rightarrow +\infty}f(x) = L \Rightarrow \forall \varepsilon>0, \exists M>0$ such that $x \geq M \Rightarrow  |f(x)-L|<\frac{\varepsilon}{2}$. Given $x_1$,$x_2$ $\in$$[M, \infty)$$\Rightarrow |f(x_1)-L|<\frac{\varepsilon}{2}$ and $|f(x_2)-L|<\frac{\varepsilon}{2}$ $\Rightarrow |f(x_1)-L|<\frac{\varepsilon}{2}$ and $|L-f(x_2)|<\frac{\varepsilon}{2}$ $\Rightarrow |f(x_1)-L+L-f(x_2)|\leq |f(x_1)-L|+|L-f(x_2)|< \varepsilon$ $\Rightarrow |f(x_1) - f(x_2)|<\varepsilon$ $\Rightarrow$ $f$ is uniformly continuous on $[M, +\infty)$. How can I extend this result towards $f$ uniformly continuous on $[a, +\infty]$?",,"['real-analysis', 'limits', 'uniform-continuity']"
2,"Limit of two variables, proposed solution check: $\lim_{(x,y)\to(0,0)}\frac{xy}{\sqrt{x^2+y^2}}$","Limit of two variables, proposed solution check:","\lim_{(x,y)\to(0,0)}\frac{xy}{\sqrt{x^2+y^2}}","Does this solution make sense, The limit in question: $$ \lim_{(x,y)\to(0,0)}\frac{xy}{\sqrt{x^2+y^2}} $$ My solution is this: Suppose, $$ \sqrt{x^2+y^2} < \delta $$ therefore $$xy<\delta^2$$ So by the Squeeze Theorem the limit exists since $$\frac{xy}{\sqrt{x^2+y^2}}<\frac{\delta^2}{\delta}=\delta$$ Is this sufficient?","Does this solution make sense, The limit in question: $$ \lim_{(x,y)\to(0,0)}\frac{xy}{\sqrt{x^2+y^2}} $$ My solution is this: Suppose, $$ \sqrt{x^2+y^2} < \delta $$ therefore $$xy<\delta^2$$ So by the Squeeze Theorem the limit exists since $$\frac{xy}{\sqrt{x^2+y^2}}<\frac{\delta^2}{\delta}=\delta$$ Is this sufficient?",,"['limits', 'multivariable-calculus', 'solution-verification']"
3,"Show that as $N \to \infty$, $\sum_{i=N}^\infty{1} \to 0?$","Show that as ,",N \to \infty \sum_{i=N}^\infty{1} \to 0?,"How do I show that as $N \to \infty$, that $$\sum_{i=N}^\infty{1} \to 0?$$ Don't know how to even start. Thanks.. Apparently this is wrong. But my teacher said that if $P_n f = \sum_{j=0}^n(f,w_j)w_j$, where $w_j$ is orthonormal basis of $L^2$, then $|P_n f- f|_{L^2} \to 0$. How can that be then? Because I thought $$|P_nf - f| = |\sum_{j=0}^n(f,w_j)w_j - \sum_{j=0}^\infty(f,w_j)w_j| = |\sum_{j={n+1}}^\infty(f,w_j)w_j| \leq \sum_{j={n+1}}^\infty|f|$$ where the last equality is by Cauchy Schwarz.","How do I show that as $N \to \infty$, that $$\sum_{i=N}^\infty{1} \to 0?$$ Don't know how to even start. Thanks.. Apparently this is wrong. But my teacher said that if $P_n f = \sum_{j=0}^n(f,w_j)w_j$, where $w_j$ is orthonormal basis of $L^2$, then $|P_n f- f|_{L^2} \to 0$. How can that be then? Because I thought $$|P_nf - f| = |\sum_{j=0}^n(f,w_j)w_j - \sum_{j=0}^\infty(f,w_j)w_j| = |\sum_{j={n+1}}^\infty(f,w_j)w_j| \leq \sum_{j={n+1}}^\infty|f|$$ where the last equality is by Cauchy Schwarz.",,['limits']
4,Limits question math help?,Limits question math help?,,"Question : Find $$\lim_{x\to\pi}\frac{\sin(3x)}{\sin(2x)}$$ If I divide by $x$ in the denominator and the numerator, I still get no result. Should I replace $x-\pi=0$? By the way,I shouldnt use L'hopital...","Question : Find $$\lim_{x\to\pi}\frac{\sin(3x)}{\sin(2x)}$$ If I divide by $x$ in the denominator and the numerator, I still get no result. Should I replace $x-\pi=0$? By the way,I shouldnt use L'hopital...",,['limits']
5,$\lim_{t\to 0} \frac{(1+t)^{1/2} - (1-t)^{1/2}}{t}$,,\lim_{t\to 0} \frac{(1+t)^{1/2} - (1-t)^{1/2}}{t},"How can I find the limit of this? Should I use the conjugate pair? It doesn't seem logical that this has a limit, I started by trying to simplifying the function but I don't think you can simplify this any further. $$     \lim_{t\to 0}   \frac{(1+t)^{1/2} - (1-t)^{1/2}}{t} $$","How can I find the limit of this? Should I use the conjugate pair? It doesn't seem logical that this has a limit, I started by trying to simplifying the function but I don't think you can simplify this any further. $$     \lim_{t\to 0}   \frac{(1+t)^{1/2} - (1-t)^{1/2}}{t} $$",,"['calculus', 'limits']"
6,How to find the limit of this sequence?,How to find the limit of this sequence?,,"How to find the limit $\displaystyle\lim_{n \to + \infty}{S_n}$ where $$S_n= \dfrac{1}{2} + \dfrac{1}{2\cdot 4} + \dfrac{1}{2\cdot 4 \cdot 6} +  \dfrac{1}{2\cdot 4 \cdot 6\cdots 2n}? $$ I know that $\dfrac{1}{2}<S_n<1. $ With Maple, I guess the answer $.6487212707$, but I can not explain.","How to find the limit $\displaystyle\lim_{n \to + \infty}{S_n}$ where $$S_n= \dfrac{1}{2} + \dfrac{1}{2\cdot 4} + \dfrac{1}{2\cdot 4 \cdot 6} +  \dfrac{1}{2\cdot 4 \cdot 6\cdots 2n}? $$ I know that $\dfrac{1}{2}<S_n<1. $ With Maple, I guess the answer $.6487212707$, but I can not explain.",,['limits']
7,Convergence of the series,Convergence of the series,,"Im trying to resolve the next exercise: $$\sum_{n=1}^\infty\ e^{an}n^2   \text{  ,  }a\in R $$ I dont know in which ranges I should separe the a value for resolving the limit and finding out the convergence.","Im trying to resolve the next exercise: $$\sum_{n=1}^\infty\ e^{an}n^2   \text{  ,  }a\in R $$ I dont know in which ranges I should separe the a value for resolving the limit and finding out the convergence.",,"['calculus', 'sequences-and-series', 'limits', 'summation']"
8,Prove the convergence,Prove the convergence,,"My task is to prove, that if this both conditions hold$$\lim_{n\rightarrow\infty}(a_{n+1}-a_n)=0$$ $$\forall{\varepsilon >0} \exists{N\in\mathbb{N}}\forall{n,m>N}: |a_{3m}-a_{3n}|\leq\varepsilon$$then $a_{n}$ converges, and show examples, that none of above is alone sufficient for $a_{n}$ to converge. I am afraid I don't understand second condition good enough to do anything. It seems similiar to Cauchy's condition of limit, but if it is so, then $a_{3n}$ is a kind of limit for $a_{3m}$. But what does it mean that subseries are bounded by themselves? What about examples? I would greatly appreciate any help and I look forward to it. Thank you  in advance","My task is to prove, that if this both conditions hold$$\lim_{n\rightarrow\infty}(a_{n+1}-a_n)=0$$ $$\forall{\varepsilon >0} \exists{N\in\mathbb{N}}\forall{n,m>N}: |a_{3m}-a_{3n}|\leq\varepsilon$$then $a_{n}$ converges, and show examples, that none of above is alone sufficient for $a_{n}$ to converge. I am afraid I don't understand second condition good enough to do anything. It seems similiar to Cauchy's condition of limit, but if it is so, then $a_{3n}$ is a kind of limit for $a_{3m}$. But what does it mean that subseries are bounded by themselves? What about examples? I would greatly appreciate any help and I look forward to it. Thank you  in advance",,"['real-analysis', 'limits']"
9,Limit of a continuous function,Limit of a continuous function,,"Suppose that $f$ is a continuous and real function on $[0,\infty]$. How can we show that if $\lim_{n\rightarrow\infty}(f(na))=0$ for all $a>0$ then $\lim_{x\rightarrow+\infty} f(x)=0$?","Suppose that $f$ is a continuous and real function on $[0,\infty]$. How can we show that if $\lim_{n\rightarrow\infty}(f(na))=0$ for all $a>0$ then $\lim_{x\rightarrow+\infty} f(x)=0$?",,"['calculus', 'limits']"
10,A Problem about Limits of Sequence,A Problem about Limits of Sequence,,"$\newcommand{\set}[1]{\left\{#1\right\}}$ I have been asked to solve the following problem: Let $\set{x_n}_{n=1}^\infty$ be a real sequence defined by $$x_{n+1}=\frac{C}{2}+\frac{x_n^2}{2},$$ with $x_1=\frac{C}{2}$, where $C$ is a constant. Try to show that If $C>1$, then $\set{x_n}_{n=1}^\infty$ is divergent; If $0< C\leq 1$, then $\set{x_n}_{n=1}^\infty$ is convergent; If $-3\leq C < 0$, then $\set{x_n}_{n=1}^\infty$ is convergent; For the case of $C< -3$, when is $\set{x_n}_{n=1}^\infty$ divergent? the original link were here: A Problem about Limits of Sequence","$\newcommand{\set}[1]{\left\{#1\right\}}$ I have been asked to solve the following problem: Let $\set{x_n}_{n=1}^\infty$ be a real sequence defined by $$x_{n+1}=\frac{C}{2}+\frac{x_n^2}{2},$$ with $x_1=\frac{C}{2}$, where $C$ is a constant. Try to show that If $C>1$, then $\set{x_n}_{n=1}^\infty$ is divergent; If $0< C\leq 1$, then $\set{x_n}_{n=1}^\infty$ is convergent; If $-3\leq C < 0$, then $\set{x_n}_{n=1}^\infty$ is convergent; For the case of $C< -3$, when is $\set{x_n}_{n=1}^\infty$ divergent? the original link were here: A Problem about Limits of Sequence",,"['sequences-and-series', 'limits']"
11,Prove $\lim_{x\to0}\sqrt{4-x}=2$ using the precise definition of limits. (Epsilon-Delta),Prove  using the precise definition of limits. (Epsilon-Delta),\lim_{x\to0}\sqrt{4-x}=2,"Prove $$\lim_{x\to0}\sqrt{4-x}=2$$ using the precise definition of limits. (Epsilon-Delta) I am not sure how to link $0<\left |x  \right |<\delta$ with $\left |\sqrt{4-x}-2\right |<\epsilon$ . EDIT (Trying it out now) I worked till here, then I basically got stuck.","Prove $$\lim_{x\to0}\sqrt{4-x}=2$$ using the precise definition of limits. (Epsilon-Delta) I am not sure how to link $0<\left |x  \right |<\delta$ with $\left |\sqrt{4-x}-2\right |<\epsilon$ . EDIT (Trying it out now) I worked till here, then I basically got stuck.",,"['calculus', 'limits', 'radicals', 'epsilon-delta']"
12,Finding the values of the real constants such that the limit exists,Finding the values of the real constants such that the limit exists,,Find the values of the real constants $c$ and $d$ such that $$\lim_{x\to 0}\frac{\sqrt{c+dx}-\sqrt{3}}{x}=\sqrt{3}$$ I really have no clue how to even get started.,Find the values of the real constants $c$ and $d$ such that $$\lim_{x\to 0}\frac{\sqrt{c+dx}-\sqrt{3}}{x}=\sqrt{3}$$ I really have no clue how to even get started.,,"['calculus', 'limits']"
13,a property in some real number $\alpha=2+\sqrt{2}$ and $\beta=2-\sqrt{2}$,a property in some real number  and,\alpha=2+\sqrt{2} \beta=2-\sqrt{2},let $\alpha=2+\sqrt{2}$ and $\beta=2-\sqrt{2}$ i want to show for $n\in\Bbb N$ $$ \alpha^{n}+\beta^{n}\in \Bbb N$$ and $$\lim\limits_{n\rightarrow\infty}\alpha^{n}+\beta^{n}=[\alpha^{n}]+1$$ thanks for any help.,let $\alpha=2+\sqrt{2}$ and $\beta=2-\sqrt{2}$ i want to show for $n\in\Bbb N$ $$ \alpha^{n}+\beta^{n}\in \Bbb N$$ and $$\lim\limits_{n\rightarrow\infty}\alpha^{n}+\beta^{n}=[\alpha^{n}]+1$$ thanks for any help.,,"['analysis', 'limits']"
14,Calculating $\lim_{n\to \infty} \left(1+\frac{x}{\sqrt{n}}\right)^n\exp(-x\sqrt{n})$,Calculating,\lim_{n\to \infty} \left(1+\frac{x}{\sqrt{n}}\right)^n\exp(-x\sqrt{n}),"I've encountered the following limit while verifying the Central Limit Theorem for the sum of several exponential random variables:     $$\lim_{n\to \infty} \left(1+\frac{x}{\sqrt{n}}\right)^n\exp(-x\sqrt{n})$$   I know the answer, which is $\exp(-x^2/2)$. Can anyone help in computing the limit?","I've encountered the following limit while verifying the Central Limit Theorem for the sum of several exponential random variables:     $$\lim_{n\to \infty} \left(1+\frac{x}{\sqrt{n}}\right)^n\exp(-x\sqrt{n})$$   I know the answer, which is $\exp(-x^2/2)$. Can anyone help in computing the limit?",,['limits']
15,Another limit related to pi number,Another limit related to pi number,,Find the value of the limit: $$\lim_{n\to\infty} \sum_{k=0}^n \frac{{k!}^{2} {2}^{k}}{(2k+1)!}$$ I'm trying to find out if this limit can be computed only by using high school  knowledge for solving limits. Thanks.,Find the value of the limit: $$\lim_{n\to\infty} \sum_{k=0}^n \frac{{k!}^{2} {2}^{k}}{(2k+1)!}$$ I'm trying to find out if this limit can be computed only by using high school  knowledge for solving limits. Thanks.,,"['real-analysis', 'limits']"
16,Numerical Computation and limits of a function,Numerical Computation and limits of a function,,"There's numerical differentiation and numerical integration, but is there numerical methods for calculating limits? Or is it only via symbolic computations? I've seen limit calculators like this . But,in general, is there a need to compute limits of functions in real life computer programming?","There's numerical differentiation and numerical integration, but is there numerical methods for calculating limits? Or is it only via symbolic computations? I've seen limit calculators like this . But,in general, is there a need to compute limits of functions in real life computer programming?",,"['limits', 'numerical-methods']"
17,Yet Another Question On Using Basics Limit Arithmetics,Yet Another Question On Using Basics Limit Arithmetics,,"Is this claim true? Given $\lim \limits_{n\to \infty}\ a_n=\frac{1}{2}$ Then $\lim \limits_{n\to \infty}\ (a_n - [a_n])=\frac{1}{2}$ I think it's true, but probably I just didn't find the right example to disprove it. Thanks a lot.","Is this claim true? Given $\lim \limits_{n\to \infty}\ a_n=\frac{1}{2}$ Then $\lim \limits_{n\to \infty}\ (a_n - [a_n])=\frac{1}{2}$ I think it's true, but probably I just didn't find the right example to disprove it. Thanks a lot.",,"['real-analysis', 'limits']"
18,how to prove that a solution of the equation is,how to prove that a solution of the equation is,,"consider the equation $ x^n - 4 x^{n-1} - 4 x^{n-2} - 4 x^{n-3} - \cdots-4x-4=0$ for $n = 1$ :: solution is : $x = 4$ for $n =  2$, ($x^2 - 4 x - 4  = 0$) :: solution is : $x = 4.8$ for $n = 3$, ($x^3 - 4x^2 - 4 x - 4 =0 $) :: solution is : x = $4.96$ how to prove that as $n \to\infty$  (what ever it means) the solution is $x = 5$.","consider the equation $ x^n - 4 x^{n-1} - 4 x^{n-2} - 4 x^{n-3} - \cdots-4x-4=0$ for $n = 1$ :: solution is : $x = 4$ for $n =  2$, ($x^2 - 4 x - 4  = 0$) :: solution is : $x = 4.8$ for $n = 3$, ($x^3 - 4x^2 - 4 x - 4 =0 $) :: solution is : x = $4.96$ how to prove that as $n \to\infty$  (what ever it means) the solution is $x = 5$.",,"['polynomials', 'limits']"
19,Limits: dividing by the highest power does not work in this case,Limits: dividing by the highest power does not work in this case,,"I believe to solve expressions like: $$\lim_{x\to \infty} (2x^2 + 1)$$ we need to divide each term in the numerator and denominator by the highest power. In the previous case, the highest power is $x^2$, so we get $$\lim_{x \to \infty} \left(2 + \frac{1}{x^2} \right) = 2+0=2$$ Now for: $$\lim_{n \to \infty} \frac{-1}{\sqrt{n} + 2}$$ The answer given is $\frac{-1}{\infty}=0$ On the other hand, what I did was $$\lim_{x \to \infty} \frac{-1}{1 + \frac{2}{\sqrt{n}}}=\frac{-1}{1}=-1$$ What's wrong?","I believe to solve expressions like: $$\lim_{x\to \infty} (2x^2 + 1)$$ we need to divide each term in the numerator and denominator by the highest power. In the previous case, the highest power is $x^2$, so we get $$\lim_{x \to \infty} \left(2 + \frac{1}{x^2} \right) = 2+0=2$$ Now for: $$\lim_{n \to \infty} \frac{-1}{\sqrt{n} + 2}$$ The answer given is $\frac{-1}{\infty}=0$ On the other hand, what I did was $$\lim_{x \to \infty} \frac{-1}{1 + \frac{2}{\sqrt{n}}}=\frac{-1}{1}=-1$$ What's wrong?",,['limits']
20,Finding a limit of a series,Finding a limit of a series,,"How would you calculate this limit it just blew me off on my midterms i seem to have calculated the limit correctly but my process is bougus < what my friend said. $$ \lim_{n\to\infty}\frac{n \sqrt{n} +n}{\sqrt{n^3}+2} $$ How i calculated the limit: $$ \lim_{n\to\infty}\frac{n \sqrt{n^2  \frac{n}{n^2}{}} +n}{\sqrt{n^4  n^{-1}}+2} = \lim_{n\to\infty}\frac{n^2 \sqrt{\frac{n}{n^2}{}} +n}{n^2\sqrt{n^2 n^{-1}}+2} = \lim_{n\to\infty}\frac{n^2 \sqrt{\frac{n}{n^2}{}} +n}{n^2\sqrt{n^2 n^{-1}}+2}\\  \frac{n^2 \sqrt{\frac{1}{n}{}} +n}{n^2\sqrt{n^2 n^{-1}}+2}= \frac{\frac{n^2\sqrt{0}}{n^2\sqrt{0}}+\frac{n}{n^2\sqrt{0}}}{\frac{n^2\sqrt{0}}{n^2\sqrt{0}}+\frac{2}{n^2\sqrt{0}}}= \frac{1}{1}=1 $$ I followed a book where an example was given where it said you can transform a expression like so: $$ \frac{1}{n} \sqrt{n^2 + 2} = \sqrt{\frac{1}{n^2} (n^2+2)} $$ or $$ \sqrt{n^2+1} = n \sqrt{1+\frac{1}{n^2}} $$","How would you calculate this limit it just blew me off on my midterms i seem to have calculated the limit correctly but my process is bougus < what my friend said. $$ \lim_{n\to\infty}\frac{n \sqrt{n} +n}{\sqrt{n^3}+2} $$ How i calculated the limit: $$ \lim_{n\to\infty}\frac{n \sqrt{n^2  \frac{n}{n^2}{}} +n}{\sqrt{n^4  n^{-1}}+2} = \lim_{n\to\infty}\frac{n^2 \sqrt{\frac{n}{n^2}{}} +n}{n^2\sqrt{n^2 n^{-1}}+2} = \lim_{n\to\infty}\frac{n^2 \sqrt{\frac{n}{n^2}{}} +n}{n^2\sqrt{n^2 n^{-1}}+2}\\  \frac{n^2 \sqrt{\frac{1}{n}{}} +n}{n^2\sqrt{n^2 n^{-1}}+2}= \frac{\frac{n^2\sqrt{0}}{n^2\sqrt{0}}+\frac{n}{n^2\sqrt{0}}}{\frac{n^2\sqrt{0}}{n^2\sqrt{0}}+\frac{2}{n^2\sqrt{0}}}= \frac{1}{1}=1 $$ I followed a book where an example was given where it said you can transform a expression like so: $$ \frac{1}{n} \sqrt{n^2 + 2} = \sqrt{\frac{1}{n^2} (n^2+2)} $$ or $$ \sqrt{n^2+1} = n \sqrt{1+\frac{1}{n^2}} $$",,"['calculus', 'sequences-and-series', 'limits']"
21,Can a limit exist if there are paths to the limit point where the function is not defined?,Can a limit exist if there are paths to the limit point where the function is not defined?,,"For example, does the limit of $f(x,y) = \frac{bxy}{xy}$ for any constant $b$ exist for $(x,y) \to (0,0)$? Does the fact that for $x=0$ and $y=0$ you have a problem with deviding by zero imply that there is no limit? Or could you extend the definition of a limit with ""for all $x$ and $y$ in the domain of $f$...""? In fact, this question arose from the following question: For which constants $a$, $b$ and $c$ does the limit $(x,y) \to (0,0)$ exist for $f(x,y) = \frac{ax^2+bxy+cy^2}{xy}$? When approaching $(0,0)$ through lines $y=mx$, it turns out that the limit depends on $m$ if not both $a$ and $c$ are $0$. So the first condition for the existing of a limit is that both $a$ and $c$ are $0$. That leaves the question for which $b$ the limit $(x,y) \to (0,0)$ exist for $f(x,y) = \frac{bxy}{xy}$. And this is where we started doubting the solution. We found 3 approaches, which we don't know is the right one. Can you simply say: Hey, $f(x,y) = \frac{bxy}{xy}$ simply results to $b$, so the limit exists for every $b$ (and equals $b$)? Or should you say: $f(x,y) = b$ for $x \ne 0$ and $y \ne 0$, and $f(x,y)$ is undefined for $x = 0$ or $y = 0$. And this makes the limit nonexistent, because for pairs $(x,y)$, even though close to $(0,0)$, you cannot guarantee anything about $|f(x,y)-b|$ because if either $x = 0$ or $y = 0$ the function isn't even defined properly.  Or is it the case that: $f(x,y) = b$ for $x \ne 0$ and $y \ne 0$, and $f(x,y)$ is undefined for $x = 0$ or $y = 0$. And this is no problem, the limit still exists for every $b$ (and is $b$)?","For example, does the limit of $f(x,y) = \frac{bxy}{xy}$ for any constant $b$ exist for $(x,y) \to (0,0)$? Does the fact that for $x=0$ and $y=0$ you have a problem with deviding by zero imply that there is no limit? Or could you extend the definition of a limit with ""for all $x$ and $y$ in the domain of $f$...""? In fact, this question arose from the following question: For which constants $a$, $b$ and $c$ does the limit $(x,y) \to (0,0)$ exist for $f(x,y) = \frac{ax^2+bxy+cy^2}{xy}$? When approaching $(0,0)$ through lines $y=mx$, it turns out that the limit depends on $m$ if not both $a$ and $c$ are $0$. So the first condition for the existing of a limit is that both $a$ and $c$ are $0$. That leaves the question for which $b$ the limit $(x,y) \to (0,0)$ exist for $f(x,y) = \frac{bxy}{xy}$. And this is where we started doubting the solution. We found 3 approaches, which we don't know is the right one. Can you simply say: Hey, $f(x,y) = \frac{bxy}{xy}$ simply results to $b$, so the limit exists for every $b$ (and equals $b$)? Or should you say: $f(x,y) = b$ for $x \ne 0$ and $y \ne 0$, and $f(x,y)$ is undefined for $x = 0$ or $y = 0$. And this makes the limit nonexistent, because for pairs $(x,y)$, even though close to $(0,0)$, you cannot guarantee anything about $|f(x,y)-b|$ because if either $x = 0$ or $y = 0$ the function isn't even defined properly.  Or is it the case that: $f(x,y) = b$ for $x \ne 0$ and $y \ne 0$, and $f(x,y)$ is undefined for $x = 0$ or $y = 0$. And this is no problem, the limit still exists for every $b$ (and is $b$)?",,['limits']
22,Limit with prime sequence and inverse logintegral,Limit with prime sequence and inverse logintegral,,I found formula below$$\lim_{n\to\infty}\frac{\operatorname{li^{-1}}(n)}{p_n}=1$$ where $\operatorname{li^{-1}}(n)$ is inverse logintegral function and $p_n$ is prime number sequence. Can anyone prove this formula?,I found formula below$$\lim_{n\to\infty}\frac{\operatorname{li^{-1}}(n)}{p_n}=1$$ where $\operatorname{li^{-1}}(n)$ is inverse logintegral function and $p_n$ is prime number sequence. Can anyone prove this formula?,,"['prime-numbers', 'limits', 'logarithms']"
23,"Prove that $\lim_{(x,y) \to (0,0)}(\frac{xy}{x^2 + y^2})^{x^2}$ does not exist",Prove that  does not exist,"\lim_{(x,y) \to (0,0)}(\frac{xy}{x^2 + y^2})^{x^2}","Which sequences should one choose to effectively prove that $$\lim_{(x,y) \to (0,0)}\left(\frac{xy}{x^2 + y^2}\right)^{x^2}$$ does not exist? Obviously, we deal with $$\lim_{(x,y) \to (0,0)}x^2*ln\left(\frac{xy}{x^2+y^2}\right).$$ I tried to substitute $x=y=\frac{1}{n}$ and $x=\frac{1}{n}$ , $y=\frac{1}{n^2}$ ( $n$ approaches infinity), but in both cases $x^2$ seems to drag the whole thing to zero? Thanks!","Which sequences should one choose to effectively prove that does not exist? Obviously, we deal with I tried to substitute and , ( approaches infinity), but in both cases seems to drag the whole thing to zero? Thanks!","\lim_{(x,y) \to (0,0)}\left(\frac{xy}{x^2 + y^2}\right)^{x^2} \lim_{(x,y) \to (0,0)}x^2*ln\left(\frac{xy}{x^2+y^2}\right). x=y=\frac{1}{n} x=\frac{1}{n} y=\frac{1}{n^2} n x^2",['limits']
24,"Without using L'Hopitals rule, how do you get $\lim_{x \to 0} \frac{1 - \cos 5x}{\sin 3x}$?","Without using L'Hopitals rule, how do you get ?",\lim_{x \to 0} \frac{1 - \cos 5x}{\sin 3x},"Without using L'Hopitals rule, how do you get the limit $$\lim_{x \to 0} \frac{1 - \cos 5x}{\sin 3x}$$ Using L'Hopital's, I can just take the derivative of the numerator $5 \sin 5x$ and denominator $3 \cos 3x$ which goes to $0/1$ or zero. But how do you show this without using derivatives? Is there a trigonometric trick so that the denominator $\sin 3x$ is transformed so the term does not become $0/0$ ? Any lead would be appreciated. Thanks","Without using L'Hopitals rule, how do you get the limit Using L'Hopital's, I can just take the derivative of the numerator and denominator which goes to or zero. But how do you show this without using derivatives? Is there a trigonometric trick so that the denominator is transformed so the term does not become ? Any lead would be appreciated. Thanks",\lim_{x \to 0} \frac{1 - \cos 5x}{\sin 3x} 5 \sin 5x 3 \cos 3x 0/1 \sin 3x 0/0,"['limits', 'derivatives', 'limits-without-lhopital']"
25,Using L'hospitals rule when right hand limit and left hand limit are different,Using L'hospitals rule when right hand limit and left hand limit are different,,Is it possible to use L'hospital rule for a function whose left hand limit and right hand limit are different. For example in the question $\lim_{x\rightarrow0} \frac{e^{1/x}-1}{e^{1/x}+1}$ The Left hand limit is equal to -1 while the right hand limit is equal to 1. However using l'hospitals rule gives $$\lim_{x\rightarrow0} \frac{e^{1/x}-1}{e^{1/x}+1}=\lim_{x\rightarrow0} \frac{-e^{1/x}/x²}{-e^{1/x}/x²}=1$$ Why does the rule gives the value of the right hand limit and not of the left hand limit. Is there any utility in using the l'hospitals rule for a evaluating a limit that does not exist (left hand limit and right hand limit are different),Is it possible to use L'hospital rule for a function whose left hand limit and right hand limit are different. For example in the question The Left hand limit is equal to -1 while the right hand limit is equal to 1. However using l'hospitals rule gives Why does the rule gives the value of the right hand limit and not of the left hand limit. Is there any utility in using the l'hospitals rule for a evaluating a limit that does not exist (left hand limit and right hand limit are different),\lim_{x\rightarrow0} \frac{e^{1/x}-1}{e^{1/x}+1} \lim_{x\rightarrow0} \frac{e^{1/x}-1}{e^{1/x}+1}=\lim_{x\rightarrow0} \frac{-e^{1/x}/x²}{-e^{1/x}/x²}=1,"['calculus', 'limits', 'derivatives']"
26,"Confusion about ""$:=$"" notation in pointwise convergence definition","Confusion about """" notation in pointwise convergence definition",:=,"My instructor's lecture notes state: Let $\{f_n:E\rightarrow\mathbb{R}\}_{n\in\mathbb{N}}$ be a sequence of functions defined on nonempty $E\subset\mathbb{R}$ . We say that the sequence converges pointwisely to $f$ on $E$ if $\forall x\in E,\forall \epsilon>0,\exists N\in \mathbb{N}:\forall n\geq N, |f_n(x)-f(x)|\leq \epsilon $ . In this case, $f(x):=\lim_{n\rightarrow \infty}f_n(x)$ . Why was $f$ defined in the last sentence? Doesn't the definition of pointwise convergence in the previous sentences imply that $f(x)=\lim_{n\rightarrow \infty}f_n(x)$ for all $x\in E$ when pointwise convergence holds? I assumed that the notation "" $:=$ "" is used to define $f$ .","My instructor's lecture notes state: Let be a sequence of functions defined on nonempty . We say that the sequence converges pointwisely to on if . In this case, . Why was defined in the last sentence? Doesn't the definition of pointwise convergence in the previous sentences imply that for all when pointwise convergence holds? I assumed that the notation "" "" is used to define .","\{f_n:E\rightarrow\mathbb{R}\}_{n\in\mathbb{N}} E\subset\mathbb{R} f E \forall x\in E,\forall \epsilon>0,\exists N\in \mathbb{N}:\forall n\geq N, |f_n(x)-f(x)|\leq \epsilon  f(x):=\lim_{n\rightarrow \infty}f_n(x) f f(x)=\lim_{n\rightarrow \infty}f_n(x) x\in E := f","['real-analysis', 'limits', 'soft-question', 'definition', 'pointwise-convergence']"
27,"How to evaluate the limit: $\lim_{t \to \infty} \int_0^1 \frac{e^{it^2(1+y^2)}}{1+y^2} \, dy$",How to evaluate the limit:,"\lim_{t \to \infty} \int_0^1 \frac{e^{it^2(1+y^2)}}{1+y^2} \, dy","I was evaluating the Fresnel integral: $$ \int_{-\infty}^{\infty} e^{ix^2}dx $$ After some calculations, I successfully evaluated it correctly. However, there is one problem that I don't know how to evaluate strictly and not just logically. I want to evaluate this limit: $$ \lim_{{t \to \infty}} \int_{0}^{1} \frac{e^{it^2(1+y^2)}}{1+y^2} \, dy $$ So, I have done this: Let $y={x\over t}$ , then our limit will become: $$ \lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2 \left(1+\frac{x^2}{t^2}\right)}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx $$ Now, let's do something like this: $$ \begin{align*} &\lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2(1+\frac{x^2}{t^2})}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx \\ &= \lim_{{t \to \infty}} \left(\int_{0}^{t} \frac{\cos(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx + \int_{0}^{t} \frac{i\sin(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx\right) \end{align*} $$ Now, let's look at the first member and evaluate the limit for it: $$ \lim_{{t \to \infty}} \int_{0}^{t} \frac{\cos(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx $$ Instead of this integral, let's evaluate this kind of integral: $$ \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx $$ Now, let's use the Dominated Convergence Theorem: $$ \left| \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq \int_{0}^{t} \frac{1}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx $$ As we evaluate the integral on the right side, it will give us: $$ \int_{0}^{t} \frac{1}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx = \frac{\pi+2}{8t} $$ So, we have: $$ \left| \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq \frac{\pi+2}{8t} $$ Now, let's take the limit on both sides, and we will get: $$ \left| \lim_{{t \to \infty}} \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq 0 $$ And from this: $$ \lim_{{t \to \infty}} \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx = 0 $$ And from this: $$ \lim_{{t \to \infty}} \int_{{0}}^{{t}} \frac{{\cos(t^2(1+\frac{x^2}{t^2}))}}{{1+\frac{x^2}{t^2}}} \cdot \frac{1}{t} \, dx = 0 $$ With the same logic, the second member is also $0$ . Therefore: $$ \lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2(1+\frac{x^2}{t^2})}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx = 0 $$ But I can't properly explain why it was right to say if the limit of the integral from the square of the integrand function is $0$ , then the limit of the integral from the integrand function (without the square) is also $0$ . Can someone please explain this to me mathematically and not just logically? I know the first equation, which we desire to evaluate, oscillates very fast and therefore is zero, but I want to show all this mathematically, and I don't want to use the Gamma function. Basically, we said that if: $$ \lim_{{t \to \infty}} \int_{{0}}^{{t}} \left(f(x;t)\right)^2 \, dx = 0 $$ then: $$ \lim_{{t \to \infty}} \int_{{0}}^{{t}} f(x;t) \, dx = 0 $$ But it isn't true for every function. Then, what makes it work in this case? Thanks to everyone in advance who will try it.","I was evaluating the Fresnel integral: After some calculations, I successfully evaluated it correctly. However, there is one problem that I don't know how to evaluate strictly and not just logically. I want to evaluate this limit: So, I have done this: Let , then our limit will become: Now, let's do something like this: Now, let's look at the first member and evaluate the limit for it: Instead of this integral, let's evaluate this kind of integral: Now, let's use the Dominated Convergence Theorem: As we evaluate the integral on the right side, it will give us: So, we have: Now, let's take the limit on both sides, and we will get: And from this: And from this: With the same logic, the second member is also . Therefore: But I can't properly explain why it was right to say if the limit of the integral from the square of the integrand function is , then the limit of the integral from the integrand function (without the square) is also . Can someone please explain this to me mathematically and not just logically? I know the first equation, which we desire to evaluate, oscillates very fast and therefore is zero, but I want to show all this mathematically, and I don't want to use the Gamma function. Basically, we said that if: then: But it isn't true for every function. Then, what makes it work in this case? Thanks to everyone in advance who will try it.","
\int_{-\infty}^{\infty} e^{ix^2}dx
 
\lim_{{t \to \infty}} \int_{0}^{1} \frac{e^{it^2(1+y^2)}}{1+y^2} \, dy
 y={x\over t} 
\lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2 \left(1+\frac{x^2}{t^2}\right)}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx
 
\begin{align*}
&\lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2(1+\frac{x^2}{t^2})}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx \\
&= \lim_{{t \to \infty}} \left(\int_{0}^{t} \frac{\cos(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx + \int_{0}^{t} \frac{i\sin(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx\right)
\end{align*}
 
\lim_{{t \to \infty}} \int_{0}^{t} \frac{\cos(t^2(1+\frac{x^2}{t^2}))}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx
 
\int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx
 
\left| \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq \int_{0}^{t} \frac{1}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx
 
\int_{0}^{t} \frac{1}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx = \frac{\pi+2}{8t}
 
\left| \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq \frac{\pi+2}{8t}
 
\left| \lim_{{t \to \infty}} \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx \right| \leq 0
 
\lim_{{t \to \infty}} \int_{0}^{t} \frac{\left(\cos(t^2(1+\frac{x^2}{t^2}))\right)^2}{(1+\frac{x^2}{t^2})^2} \frac{1}{t^2} \, dx = 0
 
\lim_{{t \to \infty}} \int_{{0}}^{{t}} \frac{{\cos(t^2(1+\frac{x^2}{t^2}))}}{{1+\frac{x^2}{t^2}}} \cdot \frac{1}{t} \, dx = 0
 0 
\lim_{{t \to \infty}} \int_{0}^{t} \frac{e^{it^2(1+\frac{x^2}{t^2})}}{1+\frac{x^2}{t^2}} \frac{1}{t} \, dx = 0
 0 0 
\lim_{{t \to \infty}} \int_{{0}}^{{t}} \left(f(x;t)\right)^2 \, dx = 0
 
\lim_{{t \to \infty}} \int_{{0}}^{{t}} f(x;t) \, dx = 0
","['limits', 'analysis', 'solution-verification', 'parametric', 'fresnel-integrals']"
28,If $|f'(x)-e^{2x}|\leq 3$ for all $x\in\mathbb{R}$. Then evaluate the limit $\lim_{x\to +\infty}\frac{f(x)}{e^{2x}}$,If  for all . Then evaluate the limit,|f'(x)-e^{2x}|\leq 3 x\in\mathbb{R} \lim_{x\to +\infty}\frac{f(x)}{e^{2x}},Let $f:\mathbb{R}\to\mathbb{R}$ be a differentiable function such that $f'$ is continuous and satisfies $|f'(x)-e^{2x}|\leq 3$ for all $x\in\mathbb{R}$ . Then evaluate the limit $$\lim_{x\to +\infty}\frac{f(x)}{e^{2x}}$$ . My Attempt: From the given inequality we have $$|f'(x)e^{-2x}-1|\leq 3e^{-2x}$$ $$\lim_{x\to+\infty}|f'(x)e^{-2x}-1|\leq\lim_{x\to+\infty} 3e^{-2x}$$ $$\lim_{x\to+\infty}|f'(x)e^{-2x}-1|\leq 0$$ $$\lim_{x\to+\infty}|f'(x)e^{-2x}-1|= 0$$ $$\lim_{x\to+\infty}\left(f'(x)e^{-2x}-1\right)= 0$$ $$\lim_{x\to+\infty}f'(x)e^{-2x}=1$$ Now to evaluate $\lim_{x\to +\infty}\frac{f(x)}{e^{2x}}$ it is very tempting to use the L'Hopital Rule and then using $\lim_{x\to+\infty}f'(x)e^{-2x}=1$ we get the answer as $\frac{1}{2}$ But how do we show that $\lim_{x\to+\infty}f(x)=\infty$ since condition to use L'Hopital rule is that the limit must be of form $\frac{0}{0}$ or $\frac{\infty}{\infty}$,Let be a differentiable function such that is continuous and satisfies for all . Then evaluate the limit . My Attempt: From the given inequality we have Now to evaluate it is very tempting to use the L'Hopital Rule and then using we get the answer as But how do we show that since condition to use L'Hopital rule is that the limit must be of form or,f:\mathbb{R}\to\mathbb{R} f' |f'(x)-e^{2x}|\leq 3 x\in\mathbb{R} \lim_{x\to +\infty}\frac{f(x)}{e^{2x}} |f'(x)e^{-2x}-1|\leq 3e^{-2x} \lim_{x\to+\infty}|f'(x)e^{-2x}-1|\leq\lim_{x\to+\infty} 3e^{-2x} \lim_{x\to+\infty}|f'(x)e^{-2x}-1|\leq 0 \lim_{x\to+\infty}|f'(x)e^{-2x}-1|= 0 \lim_{x\to+\infty}\left(f'(x)e^{-2x}-1\right)= 0 \lim_{x\to+\infty}f'(x)e^{-2x}=1 \lim_{x\to +\infty}\frac{f(x)}{e^{2x}} \lim_{x\to+\infty}f'(x)e^{-2x}=1 \frac{1}{2} \lim_{x\to+\infty}f(x)=\infty \frac{0}{0} \frac{\infty}{\infty},"['real-analysis', 'calculus', 'limits', 'limits-without-lhopital']"
29,Electric Field Due to uniformly charged infinitely long wire,Electric Field Due to uniformly charged infinitely long wire,,"Calculate the field at a point P at distance r from infinitely long wire with charge density $\lambda$ Generally the electric field in this case at point P, distance r from the wire is derived using : $$ \vec E . 2 \pi r l = \frac{\lambda l}{\epsilon _○}$$ I tried to do the same but using Coulombs law As force between two point charges is given by:(field is force per unit charge) $$\vec F = \frac{1}{4 \pi \epsilon_○}×\frac{Q_1 Q_2}{r^2}(\hat r)= \frac{kQ_1Q_2}{r^2}(\hat r)$$ And Vertical components get cancelled out I defined the following integral: $$\int^\infty _{-\infty} \frac{k}{r^2+x^2}\cos \theta \ dQ$$ $$=\int^\infty _{-\infty} \frac{k}{r^2+x^2}×\frac{r}{\sqrt{r^2+x^2}} \ \lambda \ dx$$ It finally evaluates to $$\frac{k \lambda}{r} × \left[\frac {x}{\sqrt{x^2+r^2}}\right]^{\infty}_{-\infty}$$ Is my process correct? How do I further evaluate to obtain the expression by putting the limits? I proceeded without knowing what to do and got $$\frac{k\lambda}{r}×\left[ \frac{\infty}{\infty}- \frac{- \infty}{\infty} \right]$$ $$ = \frac{k \lambda}{r}× \frac{2×\infty}{\infty}=\frac{2k\lambda}{r}$$ The doubt is:  Since in this case the answer comes out correct. Does it it mean we can treat indeterminate forms by cancelling infinity with infinity as equal to 1/1 like in this case? I know it is wrong mathematically but does it generally give the correct answer treated this way? (in similar cases maybe)","Calculate the field at a point P at distance r from infinitely long wire with charge density Generally the electric field in this case at point P, distance r from the wire is derived using : I tried to do the same but using Coulombs law As force between two point charges is given by:(field is force per unit charge) And Vertical components get cancelled out I defined the following integral: It finally evaluates to Is my process correct? How do I further evaluate to obtain the expression by putting the limits? I proceeded without knowing what to do and got The doubt is:  Since in this case the answer comes out correct. Does it it mean we can treat indeterminate forms by cancelling infinity with infinity as equal to 1/1 like in this case? I know it is wrong mathematically but does it generally give the correct answer treated this way? (in similar cases maybe)",\lambda  \vec E . 2 \pi r l = \frac{\lambda l}{\epsilon _○} \vec F = \frac{1}{4 \pi \epsilon_○}×\frac{Q_1 Q_2}{r^2}(\hat r)= \frac{kQ_1Q_2}{r^2}(\hat r) \int^\infty _{-\infty} \frac{k}{r^2+x^2}\cos \theta \ dQ =\int^\infty _{-\infty} \frac{k}{r^2+x^2}×\frac{r}{\sqrt{r^2+x^2}} \ \lambda \ dx \frac{k \lambda}{r} × \left[\frac {x}{\sqrt{x^2+r^2}}\right]^{\infty}_{-\infty} \frac{k\lambda}{r}×\left[ \frac{\infty}{\infty}- \frac{- \infty}{\infty} \right]  = \frac{k \lambda}{r}× \frac{2×\infty}{\infty}=\frac{2k\lambda}{r},"['integration', 'limits', 'definite-integrals', 'indeterminate-forms']"
30,How to calculate the limit $\lim_{x\rightarrow 0}k^2\operatorname{csch}^2(kx)-\frac{1}{4}\operatorname{csch}^2\left(\frac{x}{2}\right)$？,How to calculate the limit ？,\lim_{x\rightarrow 0}k^2\operatorname{csch}^2(kx)-\frac{1}{4}\operatorname{csch}^2\left(\frac{x}{2}\right),"I have just learnt the hyperbolic function and I meet a problem goes like follows: $$\lim_{x\rightarrow 0}k^2\operatorname{csch}^2(kx)-\frac{1}{4}\operatorname{csch}^2\left(\frac{x}{2}\right)$$ I have tried refomulating it as a form of fraction and applying the L'Hopital's Law but it seems that it just leads the problem to a much more messy land, because multiple differentiations is required. I wonder if there exists any easy way to solve it? Any comments will be appreciated.","I have just learnt the hyperbolic function and I meet a problem goes like follows: I have tried refomulating it as a form of fraction and applying the L'Hopital's Law but it seems that it just leads the problem to a much more messy land, because multiple differentiations is required. I wonder if there exists any easy way to solve it? Any comments will be appreciated.",\lim_{x\rightarrow 0}k^2\operatorname{csch}^2(kx)-\frac{1}{4}\operatorname{csch}^2\left(\frac{x}{2}\right),"['limits', 'hyperbolic-functions']"
31,I can't comprehend Stewart's explanation for the precise definition of limit and it's driving me nuts,I can't comprehend Stewart's explanation for the precise definition of limit and it's driving me nuts,,"I'm going through a Calculus class for the third time, and I understand everything very basically. I'm able to solve simple limits, derivatives, and integrals, but I can never really comprehend what I'm doing and the logic behind it. I'm on my third Calculus book, and I chose Stewart because I heard it's simpler. I couldn't get past the properties of numbers in the previous ones. I can (now) understand the entire logic that's going on here. However, I can't understand why he makes some assumptions that allow the logic to happen (not sure if that's the right way to put it). They're not really assumptions, I just don't know why these things appear. For example, he writes: Notice that if $0 < |x - 3| < \frac{0.1}{2} = 0.05$ , then $|f(x) - 5| = |(2x - 1) - 5| = |2x - 6| = 2|x - 3| < 2(0.05) = 0.1$ How did he know delta is 0.05? How does that prove anything about that bunch of equations and inequalities? When I first read this paragraph I though it meant something like Notice that if (I assume that delta is half of epsilon) then (this string of equations and inequalities is true) But a friend explained to me that said string is actually how you arrive at delta. As in, it's a proof of the previous assumption. She rewrote it to me like this and it made sense: $$|f(x) - 5| < 0.1$$ $$|f(x) - 5| = |2x - 1 - 5| = |2x - 6| = 2|x - 3|$$ $$2|x - 3| < 0.1$$ $$|x - 3| < \frac{0.1}{2} = 0.05$$ Now I'm reading Stewart's statement as Notice that if (I assume that delta is half of epsilon) then (this string of equations and inequalities proves that I magically made the correct assumption) I don't know if I'm right to think this statement is contrived. My friend wasn't able to help me past here because she doesn't understand what I'm asking anymore :( Then I got another question, which is how $|x - 3| < \delta$ and $|x - 3| < 0.05$ being true prove that $\delta = 0.05$ . It feels like that merely puts a roof on delta, as if it could be anything below 0.05. What if it's actually 0.005? I believe it's justified by saying that we obtained that number from $\varepsilon = 0.1$ , so their relation are proven enough that for $\delta = 0.05$ it'll never result in an out of bounds epsilon. I just can't make the synapses to visualize that.","I'm going through a Calculus class for the third time, and I understand everything very basically. I'm able to solve simple limits, derivatives, and integrals, but I can never really comprehend what I'm doing and the logic behind it. I'm on my third Calculus book, and I chose Stewart because I heard it's simpler. I couldn't get past the properties of numbers in the previous ones. I can (now) understand the entire logic that's going on here. However, I can't understand why he makes some assumptions that allow the logic to happen (not sure if that's the right way to put it). They're not really assumptions, I just don't know why these things appear. For example, he writes: Notice that if , then How did he know delta is 0.05? How does that prove anything about that bunch of equations and inequalities? When I first read this paragraph I though it meant something like Notice that if (I assume that delta is half of epsilon) then (this string of equations and inequalities is true) But a friend explained to me that said string is actually how you arrive at delta. As in, it's a proof of the previous assumption. She rewrote it to me like this and it made sense: Now I'm reading Stewart's statement as Notice that if (I assume that delta is half of epsilon) then (this string of equations and inequalities proves that I magically made the correct assumption) I don't know if I'm right to think this statement is contrived. My friend wasn't able to help me past here because she doesn't understand what I'm asking anymore :( Then I got another question, which is how and being true prove that . It feels like that merely puts a roof on delta, as if it could be anything below 0.05. What if it's actually 0.005? I believe it's justified by saying that we obtained that number from , so their relation are proven enough that for it'll never result in an out of bounds epsilon. I just can't make the synapses to visualize that.",0 < |x - 3| < \frac{0.1}{2} = 0.05 |f(x) - 5| = |(2x - 1) - 5| = |2x - 6| = 2|x - 3| < 2(0.05) = 0.1 |f(x) - 5| < 0.1 |f(x) - 5| = |2x - 1 - 5| = |2x - 6| = 2|x - 3| 2|x - 3| < 0.1 |x - 3| < \frac{0.1}{2} = 0.05 |x - 3| < \delta |x - 3| < 0.05 \delta = 0.05 \varepsilon = 0.1 \delta = 0.05,['calculus']
32,Can we use series expansion to evaluate $\lim_{x\to\infty}\frac{\cos x+\sin x}{x^2}?$,Can we use series expansion to evaluate,\lim_{x\to\infty}\frac{\cos x+\sin x}{x^2}?,"Evaluate $\lim_{x\to\infty}\frac{\cos x+\sin x}{x^2}$ Method $1$ : Numerator is small. Denominator is much bigger. So, limit is zero. Method $2$ : Using series expansion, $\lim_{x\to\infty}\frac{\left(1-\frac{x^2}{2!}+\frac{x^4}{4!}+...\right)+\left(x-\frac{x^3}{3!}+\frac{x^6}{6!}+...\right)}{x^2}$ Now, the numerator is a polynomial. And its degree is higher than that of denominator. So, the answer is $\infty?$ What's wrong in this method? I first thought the series expansion can be used only when $x$ tends to zero. But perhaps this is not the case. These expansions are valid for all $x?$ Or, maybe the numerator can be manipulated in some way so that the final answer is zero?","Evaluate Method : Numerator is small. Denominator is much bigger. So, limit is zero. Method : Using series expansion, Now, the numerator is a polynomial. And its degree is higher than that of denominator. So, the answer is What's wrong in this method? I first thought the series expansion can be used only when tends to zero. But perhaps this is not the case. These expansions are valid for all Or, maybe the numerator can be manipulated in some way so that the final answer is zero?",\lim_{x\to\infty}\frac{\cos x+\sin x}{x^2} 1 2 \lim_{x\to\infty}\frac{\left(1-\frac{x^2}{2!}+\frac{x^4}{4!}+...\right)+\left(x-\frac{x^3}{3!}+\frac{x^6}{6!}+...\right)}{x^2} \infty? x x?,"['calculus', 'limits', 'solution-verification', 'contest-math', 'limits-without-lhopital']"
33,Limit of the summation,Limit of the summation,,"I have recently been trying out the following limit $$\lim _{a \rightarrow \infty}\left(2 \sqrt{a}-\frac{2 a^{3 / 2}}{3}+\frac{a^{5 / 2}}{5}+\sum_{n=3}^{\infty} \frac{2(-1)^n a^{1 / 2(2 n+1)}}{(2 n+1) n !}\right)$$ . While it seems that we cannot evaluate it through some standard methods, Wolfram gives $\sqrt{\pi}$ to be the answer. I tried evaluating it as the limit of a partial sum, but still not getting it. Any help would be appreciated. Thank you!","I have recently been trying out the following limit . While it seems that we cannot evaluate it through some standard methods, Wolfram gives to be the answer. I tried evaluating it as the limit of a partial sum, but still not getting it. Any help would be appreciated. Thank you!",\lim _{a \rightarrow \infty}\left(2 \sqrt{a}-\frac{2 a^{3 / 2}}{3}+\frac{a^{5 / 2}}{5}+\sum_{n=3}^{\infty} \frac{2(-1)^n a^{1 / 2(2 n+1)}}{(2 n+1) n !}\right) \sqrt{\pi},"['sequences-and-series', 'limits']"
34,Does this mean that Euler's constant diverges?,Does this mean that Euler's constant diverges?,,"I was playing around with the Euler-Mascheroni constant and the constant $\gamma$ is defined as the limit below. $$ \gamma = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log{n} $$ It can also be expressed as this other sum which is basically the same thing but rewritten. It sums up the individual differences rather than the entire difference. $$ \gamma = \lim_{n\to\infty} \sum_{k=1}^n \left( \frac{1}{k} - \log\left(\frac{k+1}{k} \right) \right) $$ This was where I was playing around and my work is right below. $$ \gamma = \lim_{n\to\infty} \sum_{k=1}^n \left( \frac{1}{k} - \log\left(\frac{k+1}{k} \right) \right) = \lim_{n\to\infty} \sum_{k=1}^n \left( \frac{1}{k} - \log\left(1+\frac{1}{k} \right) \right) \\ =\lim_{n\to\infty} \left[ \sum_{k=1}^n \left( \frac{1}{k} \right) -\sum_{k=1}^n \left( \log\left( 1+\frac{1}{k} \right) \right) \right] $$ And using the properties of logarithms (specifically $\log{ab}=\log{a}+\log{b}$ ) we can rewrite the left sum as a product. $$ \lim_{n\to\infty} \left[ \sum_{k=1}^n \left( \frac{1}{k} \right) -  \log\left( \prod_{k=1}^n   \left(1+\frac{1}{k} \right) \right)  \right] $$ Actually, while I'm writing this I don't even know why I rewrote the fraction that way because it does nothing but it turns out that that product is equal to $n+1$ (this is easily provable using factorials). So it follows that the limit is equal to $$ \lim_{n\to\infty} \left[ \sum_{k=1}^n \left( \frac{1}{k} \right) -  \log(n+1)  \right]  $$ And in the beginning, $\gamma$ was defined as $$ \gamma = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log{n} $$ So $$ \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log{n} = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log(n+1) $$ This can be tested by plugging in some numbers on a calculator like desmos . And this is where things start to break, assuming that my proof is correct. Since this formula holds true for any $n$ at infinity, surely this must be true for $n+2$ . And for $n+3$ , and $n+l$ , where $l$ is a positive integer. And the same thing backward must be true, that is, it's also true for $n-1$ and $n-l$ . So what if $l=n-1$ ? Then the formula yields $$ \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log({n-l}) = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log({n-(n-1)}) = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log({1}) \\ = \sum_{k=1}^n \frac{1}{k} = \infty $$ Does this mean that $\gamma$ isn't even a constant and goes to infinity? I don't think so but I can't really find a mistake in my logic. I don't even know enough calculus to do a test (but I've heard of it) to check if the series converges.","I was playing around with the Euler-Mascheroni constant and the constant is defined as the limit below. It can also be expressed as this other sum which is basically the same thing but rewritten. It sums up the individual differences rather than the entire difference. This was where I was playing around and my work is right below. And using the properties of logarithms (specifically ) we can rewrite the left sum as a product. Actually, while I'm writing this I don't even know why I rewrote the fraction that way because it does nothing but it turns out that that product is equal to (this is easily provable using factorials). So it follows that the limit is equal to And in the beginning, was defined as So This can be tested by plugging in some numbers on a calculator like desmos . And this is where things start to break, assuming that my proof is correct. Since this formula holds true for any at infinity, surely this must be true for . And for , and , where is a positive integer. And the same thing backward must be true, that is, it's also true for and . So what if ? Then the formula yields Does this mean that isn't even a constant and goes to infinity? I don't think so but I can't really find a mistake in my logic. I don't even know enough calculus to do a test (but I've heard of it) to check if the series converges.","\gamma 
\gamma = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log{n}
 
\gamma = \lim_{n\to\infty} \sum_{k=1}^n \left( \frac{1}{k} - \log\left(\frac{k+1}{k} \right) \right)
 
\gamma = \lim_{n\to\infty} \sum_{k=1}^n \left( \frac{1}{k} - \log\left(\frac{k+1}{k} \right) \right) = \lim_{n\to\infty} \sum_{k=1}^n \left( \frac{1}{k} - \log\left(1+\frac{1}{k} \right) \right) \\
=\lim_{n\to\infty} \left[ \sum_{k=1}^n \left( \frac{1}{k} \right) -\sum_{k=1}^n \left( \log\left( 1+\frac{1}{k} \right) \right) \right]
 \log{ab}=\log{a}+\log{b} 
\lim_{n\to\infty} \left[ \sum_{k=1}^n \left( \frac{1}{k} \right) -  \log\left( \prod_{k=1}^n 
 \left(1+\frac{1}{k} \right) \right)  \right]
 n+1 
\lim_{n\to\infty} \left[ \sum_{k=1}^n \left( \frac{1}{k} \right) -  \log(n+1)  \right] 
 \gamma 
\gamma = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log{n}
 
\lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log{n} = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log(n+1)
 n n+2 n+3 n+l l n-1 n-l l=n-1 
\lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log({n-l}) = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log({n-(n-1)}) = \lim_{n\to\infty} \sum_{k=1}^n \left(\frac{1}{k}\right) - \log({1}) \\
= \sum_{k=1}^n \frac{1}{k} = \infty
 \gamma","['calculus', 'limits', 'logarithms', 'euler-mascheroni-constant']"
35,Confusion about having limit value an given point,Confusion about having limit value an given point,,"Today , me and my friend discussed on a question which is about whether there is limit in a given point.To answer this , we assumed that let $f$ be a function such that $f:{1} \rightarrow {4} ,f(1)=4$ ,i.e, its domain is only $1$ and image is only $4$ , but these values are isolated. Thanks to this function , we write the point $(1,4)$ in cartesian coordinate system. I said that because of our $x$ value is an isolated number ,i.e $1$ , we cannot close to $1$ because we do not have $f(x)$ values for those values. However , my friend said that we have a limit here and the limit value is $1$ by using $\epsilon - \delta$ definition. After this discussion ,we went to our professors , one of them firstly said that there is no limit of a point , but after that she hesitated about it and wanted some time for thinking. The other professor said that we can find limit value for the given point using epsilon-delta. I am confused here , because i learned that limit is the behavior of a function in given x value when we get close to (but not equal) this point. Here , our function has domain $1$ , so we cannot talk about $1.000000...1 $ or $0.9999..$ . Briefly , what do you think about whether a given point has a limit value there ? If it has limit value can you prove it using epsilon delta and for point $(1,4) $ ? Addentum: By formal definition ; For the function f(x) defined on an interval that contains $x =a$ . Then we say that, $\lim_{x \to a}f(x) = L$ If for every number epsilon( $∈$ ) which greater than zero, there is some positive number delta $\delta$ such that, $| f(x) – L | < ∈$ where $0 < |x – a| < \delta$ Source : https://www.geeksforgeeks.org/formal-definition-of-limits/ So , we see that to be able to use epsilon-delta , we must have a defined interval , but we do not have any defined interval except for $x=1$ isolated point. Then how dare can you use epsilon delta ?","Today , me and my friend discussed on a question which is about whether there is limit in a given point.To answer this , we assumed that let be a function such that ,i.e, its domain is only and image is only , but these values are isolated. Thanks to this function , we write the point in cartesian coordinate system. I said that because of our value is an isolated number ,i.e , we cannot close to because we do not have values for those values. However , my friend said that we have a limit here and the limit value is by using definition. After this discussion ,we went to our professors , one of them firstly said that there is no limit of a point , but after that she hesitated about it and wanted some time for thinking. The other professor said that we can find limit value for the given point using epsilon-delta. I am confused here , because i learned that limit is the behavior of a function in given x value when we get close to (but not equal) this point. Here , our function has domain , so we cannot talk about or . Briefly , what do you think about whether a given point has a limit value there ? If it has limit value can you prove it using epsilon delta and for point ? Addentum: By formal definition ; For the function f(x) defined on an interval that contains . Then we say that, If for every number epsilon( ) which greater than zero, there is some positive number delta such that, where Source : https://www.geeksforgeeks.org/formal-definition-of-limits/ So , we see that to be able to use epsilon-delta , we must have a defined interval , but we do not have any defined interval except for isolated point. Then how dare can you use epsilon delta ?","f f:{1} \rightarrow {4} ,f(1)=4 1 4 (1,4) x 1 1 f(x) 1 \epsilon - \delta 1 1.000000...1  0.9999.. (1,4)  x =a \lim_{x \to a}f(x) = L ∈ \delta | f(x) – L | < ∈ 0 < |x – a| < \delta x=1","['real-analysis', 'calculus']"
36,L'Hopital's Rule for nested exponential function,L'Hopital's Rule for nested exponential function,,"I am trying to look for the following limit: $$\lim_{x\to\infty} (xe^{1/x} - x)^x$$ I re-wrote the limit in the following way $$\exp\left( \lim_{x\to\infty} x\ln \left[ x(e^{1/x} -1) \right]  \right)$$ and I look for the limit of the exponent using L'Hopital's rule (beforehand, I changed the $x$ term adjacent to the $\ln$ term so that it becomes $1/x$ ). However, I only end up with more complicated expressions as I repeatedly use L'Hopital's rule (I checked first if the resulting function after applying L'Hopital's is of the form $0/0$ or $\infty/\infty$ ). Is there more efficient way to solve this?","I am trying to look for the following limit: I re-wrote the limit in the following way and I look for the limit of the exponent using L'Hopital's rule (beforehand, I changed the term adjacent to the term so that it becomes ). However, I only end up with more complicated expressions as I repeatedly use L'Hopital's rule (I checked first if the resulting function after applying L'Hopital's is of the form or ). Is there more efficient way to solve this?",\lim_{x\to\infty} (xe^{1/x} - x)^x \exp\left( \lim_{x\to\infty} x\ln \left[ x(e^{1/x} -1) \right]  \right) x \ln 1/x 0/0 \infty/\infty,"['limits', 'analysis', 'exponential-function', 'infinity']"
37,Why can they use continuity to compute this limit?,Why can they use continuity to compute this limit?,,"(a) Use l'Hôpital's rule to find $\displaystyle\lim_{x\to0}\ln[(1+x)^{1/x}]$ . Solution: Since $\ln x$ is continuous, $$\lim_{x\to0}\ln\left((1+x)^{1/x}\right)=\ln\left(\lim_{x\to0}(1+x)^{1/x}\right)=1.$$ Therefore, $\displaystyle\lim_{x\to0}(1+x)^{1/x}=e$ . In the solution above, they've reasoned that because "" $\ln(x)$ "" is continuous, they are able to use limit laws to directly take the limit of the inner function. However, $\ln x$ is undefined and has a vertical asymptote at $x=0$ , so how are they able to still use continuity (and thus direct substitution) to compute this limit? If I were not allowed to use graphing software and had no idea how the graph of $\ln\left[(1+x)^{1/x}\right]$ looked like, how would I know that I can use continuity?","(a) Use l'Hôpital's rule to find . Solution: Since is continuous, Therefore, . In the solution above, they've reasoned that because "" "" is continuous, they are able to use limit laws to directly take the limit of the inner function. However, is undefined and has a vertical asymptote at , so how are they able to still use continuity (and thus direct substitution) to compute this limit? If I were not allowed to use graphing software and had no idea how the graph of looked like, how would I know that I can use continuity?",\displaystyle\lim_{x\to0}\ln[(1+x)^{1/x}] \ln x \lim_{x\to0}\ln\left((1+x)^{1/x}\right)=\ln\left(\lim_{x\to0}(1+x)^{1/x}\right)=1. \displaystyle\lim_{x\to0}(1+x)^{1/x}=e \ln(x) \ln x x=0 \ln\left[(1+x)^{1/x}\right],"['calculus', 'limits', 'continuity']"
38,intuition for $\lim_{n \to \infty} f_n'(x) \ne f'(x)$ (Tom Apostol's exercise $11.7.18$),intuition for  (Tom Apostol's exercise ),\lim_{n \to \infty} f_n'(x) \ne f'(x) 11.7.18,"Let $f_n(x) = \frac{\sin nx}{n}$ and $f(x) = \lim_{n \to \infty} f_n(x)$ . Therefore, for all fixed $x$ , $f(x) = 0$ The derivatives are then (for all fixed $x$ ): $f_n'(x) = \cos nx$ and $f'(x) = 0$ . I understand that numerically $\lim_{n \to \infty} f_n'(0) = 1 \ne 0 = f'(0)$ , but I don't know how to understand that intuitively. I guess the simplest thing to say is that information about $n$ is lost in $f(x)$ , so it cannot cancel out in the derivative, like it did in the $f_n'(x)$ . Or even simpler, to just say that the two are simply two different functions. I'm looking forward to get a better explanation. Clarification, after seeing Jyrki's answer: $f_n'(0)=1$ always. If $f_n$ for higher $n$ becomes flatter at 0, why is $f_n'(0)$ also not approaching $0$ as $n \to \infty$ ? If $f_n(0)$ does not become flat with higher $n$ s (e.g. but it just oscillates with a higher frequency), then why is $f'(0)$ also not different from $0$ ?","Let and . Therefore, for all fixed , The derivatives are then (for all fixed ): and . I understand that numerically , but I don't know how to understand that intuitively. I guess the simplest thing to say is that information about is lost in , so it cannot cancel out in the derivative, like it did in the . Or even simpler, to just say that the two are simply two different functions. I'm looking forward to get a better explanation. Clarification, after seeing Jyrki's answer: always. If for higher becomes flatter at 0, why is also not approaching as ? If does not become flat with higher s (e.g. but it just oscillates with a higher frequency), then why is also not different from ?",f_n(x) = \frac{\sin nx}{n} f(x) = \lim_{n \to \infty} f_n(x) x f(x) = 0 x f_n'(x) = \cos nx f'(x) = 0 \lim_{n \to \infty} f_n'(0) = 1 \ne 0 = f'(0) n f(x) f_n'(x) f_n'(0)=1 f_n n f_n'(0) 0 n \to \infty f_n(0) n f'(0) 0,"['limits', 'convergence-divergence', 'pointwise-convergence']"
39,Why doesn't limit of a double/multivariable function needn't exist given that it exists along all straight line?,Why doesn't limit of a double/multivariable function needn't exist given that it exists along all straight line?,,"I am studying multivariable calculus as of now. I have been told by my mentor that if limit exists along all straight lines, it doesn't mean that limit exists. I got the same information from Wikipidea.org as well as Thomas Calculus. However, I doubt this. I think that I have got something (at least for double variable functions), which can be called as a proof. What I know about limits is that there is a function say $f$ and for calculating limiting value at a point, we evaluate the function for points present in the point's close neighborhood. If all these values are approaching some number, we say that the number being approached is the limiting value. For example let's say that $f(x, y)$ is a function and we want its limiting value at $(0, 0)$ . According to what I have mentioned above about limits, we need to plug in several points in origin's close neighborhood to get the limiting value. If my interpretation of limit is correct, this should give us the correct answer. Let's say I evaluate the limit by approaching origin via lines $y = mx$ . I have full control over m and I can manipulate it as I wish. So, by doing this substitution, we can get any $(x, y)$ given both $x$ and $y$ are in close neighborhood of origin by manipulating value of m (Except for x = 0 for which the limiting value can be calculated separately). So, this method is same as the first method mentioned in the paragraph. But since, from three sources I was getting the same information, I feel that I am wrong. I request to please correct me by telling my mistake. All the three sources refer the following example as a proof: Quoting from en.wikipidea.org A study of limits and continuity in multivariable calculus yields many counterintuitive results not demonstrated by single-variable functions. For example, there are scalar functions of two variables with points in their domain which give different limits when approached along different paths. E.g., the function. $$f(x,y) = \frac{x^2y}{x^4+y^2}$$ approaches zero whenever the point $(0,0)$ is approached along lines through the origin $({\displaystyle y=kx})$ . However, when the origin is approached along a parabola ${\displaystyle y=\pm x^{2}}$ , the function value has a limit of ${\displaystyle \pm 1/2}a$ . Since taking different paths toward the same point yields different limit values, a general limit does not exist there. I believe that limit doesn't exists along all lines in this case. Lets say $x_{0}$ is a non-zero x-coordinate of a point in close neighborhood of origin. Let us evaluate limit along a line $y = mx\space where\space m = x_0$ . Doing the substitution in the above function, we get, $$\lim\limits_{x \to 0}\frac{mx^3}{x^4 + m^2x^2}$$ This can be rewritten as $$\lim\limits_{x \to 0}\frac{\frac{m}{x}}{1 + (\frac{m}{x})^2}$$ Out of the several values in close neighborhood of origin, one will $(x_0, y)$ . If we plug in this point in our above function with $m=x_0$ , for this point, $f$ becomes $\frac{1}{3}$ . If I plug in $x = \frac {x_0} {2}$ , I get $\frac{2}{5}$ . Therefore limit doesn't exists along all the lines. However, Wikipedia, Thomas Calculus, my mentor all say that limit exists along all lines. My questions : Why, if limit exists along all lines, limit needn't exist along every other path. What is wrong in my attempt trying to contradict the example given on wikipidea. Sorry for my poor english. Thank you so much.","I am studying multivariable calculus as of now. I have been told by my mentor that if limit exists along all straight lines, it doesn't mean that limit exists. I got the same information from Wikipidea.org as well as Thomas Calculus. However, I doubt this. I think that I have got something (at least for double variable functions), which can be called as a proof. What I know about limits is that there is a function say and for calculating limiting value at a point, we evaluate the function for points present in the point's close neighborhood. If all these values are approaching some number, we say that the number being approached is the limiting value. For example let's say that is a function and we want its limiting value at . According to what I have mentioned above about limits, we need to plug in several points in origin's close neighborhood to get the limiting value. If my interpretation of limit is correct, this should give us the correct answer. Let's say I evaluate the limit by approaching origin via lines . I have full control over m and I can manipulate it as I wish. So, by doing this substitution, we can get any given both and are in close neighborhood of origin by manipulating value of m (Except for x = 0 for which the limiting value can be calculated separately). So, this method is same as the first method mentioned in the paragraph. But since, from three sources I was getting the same information, I feel that I am wrong. I request to please correct me by telling my mistake. All the three sources refer the following example as a proof: Quoting from en.wikipidea.org A study of limits and continuity in multivariable calculus yields many counterintuitive results not demonstrated by single-variable functions. For example, there are scalar functions of two variables with points in their domain which give different limits when approached along different paths. E.g., the function. approaches zero whenever the point is approached along lines through the origin . However, when the origin is approached along a parabola , the function value has a limit of . Since taking different paths toward the same point yields different limit values, a general limit does not exist there. I believe that limit doesn't exists along all lines in this case. Lets say is a non-zero x-coordinate of a point in close neighborhood of origin. Let us evaluate limit along a line . Doing the substitution in the above function, we get, This can be rewritten as Out of the several values in close neighborhood of origin, one will . If we plug in this point in our above function with , for this point, becomes . If I plug in , I get . Therefore limit doesn't exists along all the lines. However, Wikipedia, Thomas Calculus, my mentor all say that limit exists along all lines. My questions : Why, if limit exists along all lines, limit needn't exist along every other path. What is wrong in my attempt trying to contradict the example given on wikipidea. Sorry for my poor english. Thank you so much.","f f(x, y) (0, 0) y = mx (x, y) x y f(x,y) = \frac{x^2y}{x^4+y^2} (0,0) ({\displaystyle y=kx}) {\displaystyle y=\pm x^{2}} {\displaystyle \pm 1/2}a x_{0} y = mx\space where\space m = x_0 \lim\limits_{x \to 0}\frac{mx^3}{x^4 + m^2x^2} \lim\limits_{x \to 0}\frac{\frac{m}{x}}{1 + (\frac{m}{x})^2} (x_0, y) m=x_0 f \frac{1}{3} x = \frac {x_0} {2} \frac{2}{5}","['calculus', 'limits', 'multivariable-calculus']"
40,How to find the limit of $\sqrt[^n]{n+1}$ as n approaches $\infty$?,How to find the limit of  as n approaches ?,\sqrt[^n]{n+1} \infty,"How to find the limit of $\sqrt[^n]{n+1}$ as n approaches $\infty$ ? My teacher hasn't taught L'Hopital's Rule yet, so I am only able to solve this using some standard limits. The similar standard limit I can think of is $\lim_{n\to\infty} (1+\frac{a}{n})^n = e^a$ . What I have done so far: $\lim_{n\to\infty} \sqrt[^n]{n+1}$ $ = \lim_{n\to\infty} (n+1)^{\frac{1}{n}}$ Let $ m = \frac{1}{n} \therefore n = \frac{1}{m}$ . Since $n\rightarrow\infty$ , $m\rightarrow0$ . $\lim_{m\to0} (1+\frac{1}{m})^m$ But I'm stuck in this step because I don't know how to work out the answer. If I just substitute $0$ in m, $1+\frac{1}{m}$ is undefined. If I rewrite this as $e^{log((1+\frac{1}{m})^m)}$ , it's also undefined. I know the limit is $1$ by looking at the graph. I'm wondering how I'm able to solve it in a more rigorous way.","How to find the limit of as n approaches ? My teacher hasn't taught L'Hopital's Rule yet, so I am only able to solve this using some standard limits. The similar standard limit I can think of is . What I have done so far: Let . Since , . But I'm stuck in this step because I don't know how to work out the answer. If I just substitute in m, is undefined. If I rewrite this as , it's also undefined. I know the limit is by looking at the graph. I'm wondering how I'm able to solve it in a more rigorous way.",\sqrt[^n]{n+1} \infty \lim_{n\to\infty} (1+\frac{a}{n})^n = e^a \lim_{n\to\infty} \sqrt[^n]{n+1}  = \lim_{n\to\infty} (n+1)^{\frac{1}{n}}  m = \frac{1}{n} \therefore n = \frac{1}{m} n\rightarrow\infty m\rightarrow0 \lim_{m\to0} (1+\frac{1}{m})^m 0 1+\frac{1}{m} e^{log((1+\frac{1}{m})^m)} 1,"['limits', 'limits-without-lhopital']"
41,Evaluating limits without the usage of graph,Evaluating limits without the usage of graph,,"$\lim_{x \to 1} {\frac{x^3-1}{x^2-1}}$ Is there a way to evaluate this limit when $x$ Approaches 1 without using a graph? From graph, its easy to see, that as its $\frac{3}{2}$ but how do we simplify and break the fraction down because if I substitute $x=1$ to the expression I get $\frac{0}{0}$","Is there a way to evaluate this limit when Approaches 1 without using a graph? From graph, its easy to see, that as its but how do we simplify and break the fraction down because if I substitute to the expression I get",\lim_{x \to 1} {\frac{x^3-1}{x^2-1}} x \frac{3}{2} x=1 \frac{0}{0},['limits']
42,Can't understand why cosh(1/x) changes the result for this limit,Can't understand why cosh(1/x) changes the result for this limit,,"I have this limit: $$\lim_{x \to -\infty} x^2\left({(x^2+1)\cosh{\frac 1x}\over x^2}-1\right)$$ If I solve this limit by hand, I get 1 $\require{cancel}$ $$\lim_{x \to -\infty} x^2\left({(x^2+1)\cosh{\cancelto{0}{\frac 1x}}\over x^2}-1\right)=$$ $$\lim_{x \to -\infty} x^2\left({(x^2+1)\cancelto{1}{\cosh{0}}\over x^2}-1\right)=$$ $$\lim_{x \to -\infty} \cancel{x^2}\left({\cancel{x^2}+1\cancel{-x^2}\over \cancel{x^2}}\right)=1$$ However, both Wolfram Alpha and the exercise say the correct result is ${\frac 32}$ $$\lim_{x \to -\infty} x^2\left({(x^2+1)\cosh{\frac 1x}\over x^2}-1\right) = \frac 32$$ However, if I remove $\cosh{\frac 1x}$ , which for ${x \to -\infty}$ tends to $1$ , suddenly Wolfram Alpha says the result is 1: $$\lim_{x \to -\infty} x^2\left({(x^2+1)\over x^2}-1\right) = 1$$ I'm at a complete loss. Wolfram Alpha uses L'Hopital's rule to solve the first limit, so it doesn't help me undersand the discrepancy","I have this limit: If I solve this limit by hand, I get 1 However, both Wolfram Alpha and the exercise say the correct result is However, if I remove , which for tends to , suddenly Wolfram Alpha says the result is 1: I'm at a complete loss. Wolfram Alpha uses L'Hopital's rule to solve the first limit, so it doesn't help me undersand the discrepancy",\lim_{x \to -\infty} x^2\left({(x^2+1)\cosh{\frac 1x}\over x^2}-1\right) \require{cancel} \lim_{x \to -\infty} x^2\left({(x^2+1)\cosh{\cancelto{0}{\frac 1x}}\over x^2}-1\right)= \lim_{x \to -\infty} x^2\left({(x^2+1)\cancelto{1}{\cosh{0}}\over x^2}-1\right)= \lim_{x \to -\infty} \cancel{x^2}\left({\cancel{x^2}+1\cancel{-x^2}\over \cancel{x^2}}\right)=1 {\frac 32} \lim_{x \to -\infty} x^2\left({(x^2+1)\cosh{\frac 1x}\over x^2}-1\right) = \frac 32 \cosh{\frac 1x} {x \to -\infty} 1 \lim_{x \to -\infty} x^2\left({(x^2+1)\over x^2}-1\right) = 1,"['calculus', 'limits', 'limits-without-lhopital', 'hyperbolic-functions']"
43,Function unbounded on a neighbourhood then limit doesn't exist,Function unbounded on a neighbourhood then limit doesn't exist,,"I came across a corollary which goes as follows: Let $D \subset \mathbb R $ . If $f:D \rightarrow \mathbb R$ is not bounded on $N(c,\delta)\, \cap \, D$ for some $\delta$ - neighbourhood $N(c,\delta)$ of c, then $\lim_{x \to c} f(x)$ does not exist on $\mathbb R$ . My question is, in this corollary shouldn't this condition of unboundedness apply on every $\delta$ - neighbourhood $N(c,\delta)$ of c. For example if f(x) = tan(x), and c = $\pi/4$ , D = $ [0,\pi/2) \cup (\pi/2,3\pi/2) $ , then for a $\pi/2$ -neigbourhood of $\pi/4$ , $N(\pi/4,\pi/2) $ . f is not bounded on the interval $ N(\pi/4,\pi/2)\, \cap \, D = [0,\pi/2) \cup(\pi/2,3\pi/4) $ , which would imply that $\lim_{x \to \pi/4} tan(x)$ doesn't exist. Which is not true Also, in this corollary how would it be affected if we consider a deleted neighbourhood?","I came across a corollary which goes as follows: Let . If is not bounded on for some - neighbourhood of c, then does not exist on . My question is, in this corollary shouldn't this condition of unboundedness apply on every - neighbourhood of c. For example if f(x) = tan(x), and c = , D = , then for a -neigbourhood of , . f is not bounded on the interval , which would imply that doesn't exist. Which is not true Also, in this corollary how would it be affected if we consider a deleted neighbourhood?","D \subset \mathbb R  f:D \rightarrow \mathbb R N(c,\delta)\, \cap \, D \delta N(c,\delta) \lim_{x \to c} f(x) \mathbb R \delta N(c,\delta) \pi/4  [0,\pi/2) \cup (\pi/2,3\pi/2)  \pi/2 \pi/4 N(\pi/4,\pi/2)   N(\pi/4,\pi/2)\, \cap \, D = [0,\pi/2) \cup(\pi/2,3\pi/4)  \lim_{x \to \pi/4} tan(x)","['real-analysis', 'limits', 'analysis']"
44,Interpreting the ratio test for $\lim_{n\to\infty} \sum_{k=1}^n \frac{n}{n^2+k} $,Interpreting the ratio test for,\lim_{n\to\infty} \sum_{k=1}^n \frac{n}{n^2+k} ,"We want to find the limit of this. $$\lim_{n\to\infty} \sum_{k=1}^n \frac{n}{n^2+k} $$ I would have done it as follows: $$\lim_{n \to \infty} \bigg| \frac{a_{n+1}}{a_n}\bigg| = \lim_{n\to\infty}\frac{\frac{n+1}{(n+1)^2+n}}{\frac{n}{n^2+n}} =\lim_{n\to\infty} \frac{n+1}{(n+1)^2+n} \cdot \frac{n^2+n}{n} = \lim_{n\to\infty}\frac{n^3+2n^2+n}{n^3+3n^2+n} \\ =\lim_{n\to\infty} \frac{n^3 \cdot \bigl(1+\frac{2}{n} + \frac{1}{n^2} \bigr)}{n^3\cdot\big(1+\frac{3}{n} + \frac{1}{n^2} \bigr)} = \frac{1}{1} = 1$$ According to the ratio test, the series converges if $\lim_{n \to \infty} \bigg| \frac{a_{n+1}}{a_n}\bigg| <1$ and it diverges if it's $> 1$ . But since we get $1$ here, the series converges towards that value, no? But according to the ratio test, we can't make a statement about the series of the limit of $\lim_{n \to \infty} \bigg| \frac{a_{n+1}}{a_n}\bigg| = 1$ What am I misunderstanding here?","We want to find the limit of this. I would have done it as follows: According to the ratio test, the series converges if and it diverges if it's . But since we get here, the series converges towards that value, no? But according to the ratio test, we can't make a statement about the series of the limit of What am I misunderstanding here?","\lim_{n\to\infty} \sum_{k=1}^n \frac{n}{n^2+k}  \lim_{n \to \infty} \bigg| \frac{a_{n+1}}{a_n}\bigg| = \lim_{n\to\infty}\frac{\frac{n+1}{(n+1)^2+n}}{\frac{n}{n^2+n}} =\lim_{n\to\infty} \frac{n+1}{(n+1)^2+n} \cdot \frac{n^2+n}{n} = \lim_{n\to\infty}\frac{n^3+2n^2+n}{n^3+3n^2+n} \\
=\lim_{n\to\infty} \frac{n^3 \cdot \bigl(1+\frac{2}{n} + \frac{1}{n^2} \bigr)}{n^3\cdot\big(1+\frac{3}{n} + \frac{1}{n^2} \bigr)} = \frac{1}{1} = 1 \lim_{n \to \infty} \bigg| \frac{a_{n+1}}{a_n}\bigg| <1 > 1 1 \lim_{n \to \infty} \bigg| \frac{a_{n+1}}{a_n}\bigg| = 1","['calculus', 'sequences-and-series', 'limits']"
45,Give an example of a set which has exactly 3 limit points and the set is closed.,Give an example of a set which has exactly 3 limit points and the set is closed.,,"So the question is, Give an example of a set of real numbers which has exactly 3 limit points and the set is closed. I have been trying to solve it by myself, and I know one potential set can be $A$ , such that, $A = \{k + \frac{1}{n}\ : n \in \mathbb{N} \}$ Where $K$ is the limit point of $A$ . The problem with this set is, this set is not closed, by the definition of a closed set, the set also need to contain it's limit points, but $k \notin A$","So the question is, Give an example of a set of real numbers which has exactly 3 limit points and the set is closed. I have been trying to solve it by myself, and I know one potential set can be , such that, Where is the limit point of . The problem with this set is, this set is not closed, by the definition of a closed set, the set also need to contain it's limit points, but",A A = \{k + \frac{1}{n}\ : n \in \mathbb{N} \} K A k \notin A,"['real-analysis', 'limits', 'set-theory']"
46,"Show that $(1 + x^2 y^2)^{-\frac{1}{x^2 + y^2}}$ is $1$ as $(x,y) \to(0,0)$",Show that  is  as,"(1 + x^2 y^2)^{-\frac{1}{x^2 + y^2}} 1 (x,y) \to(0,0)","I want to show that: $$\lim_{(x,y)\to(0,0)} (1 + x^2 y^2)^{-\frac{1}{x^2 + y^2}} = 1$$ Direct substitution doesn't work, because of the denominator of $\frac{1}{x^2 + y^2}$ . Usually these problems are solved by bounding the following expression: $$\left|(1 + x^2 y^2)^{-\frac{1}{x^2 + y^2}} -1 \right| = \left| \frac{1 - (1 + x^2 y^2)^{\frac{1}{x^2 + y^2}} }{ (1 + x^2 y^2)^{\frac{1}{x^2 + y^2}}} \right|$$ I don't know how to continue.","I want to show that: Direct substitution doesn't work, because of the denominator of . Usually these problems are solved by bounding the following expression: I don't know how to continue.","\lim_{(x,y)\to(0,0)} (1 + x^2 y^2)^{-\frac{1}{x^2 + y^2}} = 1 \frac{1}{x^2 + y^2} \left|(1 + x^2 y^2)^{-\frac{1}{x^2 + y^2}} -1 \right| = \left| \frac{1 - (1 + x^2 y^2)^{\frac{1}{x^2 + y^2}} }{ (1 + x^2 y^2)^{\frac{1}{x^2 + y^2}}} \right|","['real-analysis', 'limits', 'multivariable-calculus']"
47,Prove that if $\lim_{x\to a^+}f'(x)$ exists then $\lim_{x\to a^+}f(x)$ exists.,Prove that if  exists then  exists.,\lim_{x\to a^+}f'(x) \lim_{x\to a^+}f(x),"Prove that if $\lim_{x\to a^+}f'(x)$ exists then $\lim_{x\to a^+}f(x)$ exists. I am a high school math teacher, not a professional mathematician. I just thought of this question, in the context of trying to show that if $f''(a)>0$ then the curve does not necessarily have a U-shape around $x=a$ , but that is not important here and I am not inviting discussion of that; I just mentioned that to add context. I have searched for this question, here at MSE and also approachzero, but haven't found anything helpful. The statement I'm trying to prove here seems intuitively obvious to me but difficult to prove. I have tried using the formal definition of limit, and differentiation from first principles, to no avail. (I just asked a related question which turned out to be a flawed question, because what I was asking to be proved, is not true. Responders there said that the case with one-sided limits is true, so assuming that is correct, I am asking about that here. In that related question, I showed my flawed attempt at the proof.) Feel free to let me know if there's anything I can do to improve this question.","Prove that if exists then exists. I am a high school math teacher, not a professional mathematician. I just thought of this question, in the context of trying to show that if then the curve does not necessarily have a U-shape around , but that is not important here and I am not inviting discussion of that; I just mentioned that to add context. I have searched for this question, here at MSE and also approachzero, but haven't found anything helpful. The statement I'm trying to prove here seems intuitively obvious to me but difficult to prove. I have tried using the formal definition of limit, and differentiation from first principles, to no avail. (I just asked a related question which turned out to be a flawed question, because what I was asking to be proved, is not true. Responders there said that the case with one-sided limits is true, so assuming that is correct, I am asking about that here. In that related question, I showed my flawed attempt at the proof.) Feel free to let me know if there's anything I can do to improve this question.",\lim_{x\to a^+}f'(x) \lim_{x\to a^+}f(x) f''(a)>0 x=a,"['real-analysis', 'calculus', 'limits', 'derivatives']"
48,"For a non-negative integer $k$, $\lim_{x\to \infty} \frac{f(x+1)-f(x)}{x^k}=l\implies \lim_{x\to \infty}\frac{f(x)}{x^{k+1}}=\frac l{k+1}$","For a non-negative integer ,",k \lim_{x\to \infty} \frac{f(x+1)-f(x)}{x^k}=l\implies \lim_{x\to \infty}\frac{f(x)}{x^{k+1}}=\frac l{k+1},"Suppose that $f$ defined on $(a,\infty)$ is bounded on each finite interval $(a,b),a>b$ . For a non-negative integer $k$ , it is to be shown that $\lim_{x\to \infty} \frac{f(x+1)-f(x)}{x^k}=l\implies \lim_{x\to \infty}\frac{f(x)}{x^{k+1}}=\frac l{k+1}$ Given an $\displaystyle \epsilon  >0,$ there exists an integer $\displaystyle N$ such that $$\displaystyle  x \geq N \Longrightarrow \ \left| \frac{f( x+1) -f( x)}{x^{k}}  -l \right| < \epsilon $$ Noting that \begin{align*} f( x) & =\sum _{i=1}^{[ x]} f( x-[ x] +i) -f( x-[ x] +i-1) +\color{red}{f( x-[ x])} \end{align*} it follows that \begin{align*} f( x) & =\sum _{i=1}^{N}\overbrace{( f( x-[ x] +i) -f( x-[ x] +i-1))}^{h( i)} +\sum _{i=N+1}^{[ x]}( f( x-[ x] +i) -f( x-[ x] +i-1)) +\color{red}{( \ )} \end{align*} It follows that \begin{align*} |\frac{f( x)}{x^{k+1}} -\frac{l}{k+1} | & \leq \sum _{i=1}^{N} |\frac{h( i)}{x^{k+1}} -\frac{l}{[ x]( k+1)} |+\sum _{i=N+1}^{[ x]} |\frac{h( i)}{x^{k+1}} -\frac{l}{[x](k+1)} |+\color{red}{( )x^{-k-1}}\\  & \leq {\textstyle \frac{\overbrace{M}^{\sup _{1\leq i\leq N} h( i)}}{x^{k+1}} +\frac{N|l|}{[ x]( k+1)} +\frac{\epsilon ([ x] -N)}{x} +|\frac{l}{x} -\frac{l}{[ x]( k+1)} |([ x] -N) +\color{red}{\overbrace{\color{red}{\sup _{t\in [ 0,1)}f(t)}}^{M'} x^{-k-1}}}\\  & =\frac{M+M'}{x^{k+1}} +{\textstyle \frac{N|l|}{[ x]( k+1)} +\color{purple}{|\frac{l[ x]}{x} -\frac{l}{( k+1)} |} -N|\frac{l}{x} -\frac{l}{[ x]( k+1)} |+\frac{\epsilon ([ x] -N)}{x}} \tag 1 \end{align*} In $(1)$ , except the purple term every other term can be made arbitrarily small. How do I take care of the purple term so that I can conlude the desired result by limit definition.","Suppose that defined on is bounded on each finite interval . For a non-negative integer , it is to be shown that Given an there exists an integer such that Noting that it follows that It follows that In , except the purple term every other term can be made arbitrarily small. How do I take care of the purple term so that I can conlude the desired result by limit definition.","f (a,\infty) (a,b),a>b k \lim_{x\to \infty} \frac{f(x+1)-f(x)}{x^k}=l\implies \lim_{x\to \infty}\frac{f(x)}{x^{k+1}}=\frac l{k+1} \displaystyle \epsilon  >0, \displaystyle N \displaystyle 
x \geq N \Longrightarrow \ \left| \frac{f( x+1) -f( x)}{x^{k}}
 -l \right| < \epsilon  \begin{align*}
f( x) & =\sum _{i=1}^{[ x]} f( x-[ x] +i) -f( x-[ x] +i-1) +\color{red}{f( x-[ x])}
\end{align*} \begin{align*}
f( x) & =\sum _{i=1}^{N}\overbrace{( f( x-[ x] +i) -f( x-[ x] +i-1))}^{h( i)} +\sum _{i=N+1}^{[ x]}( f( x-[ x] +i) -f( x-[ x] +i-1)) +\color{red}{( \ )}
\end{align*} \begin{align*}
|\frac{f( x)}{x^{k+1}} -\frac{l}{k+1} | & \leq \sum _{i=1}^{N} |\frac{h( i)}{x^{k+1}} -\frac{l}{[ x]( k+1)} |+\sum _{i=N+1}^{[ x]} |\frac{h( i)}{x^{k+1}} -\frac{l}{[x](k+1)} |+\color{red}{( )x^{-k-1}}\\
 & \leq {\textstyle \frac{\overbrace{M}^{\sup _{1\leq i\leq N} h( i)}}{x^{k+1}} +\frac{N|l|}{[ x]( k+1)} +\frac{\epsilon ([ x] -N)}{x} +|\frac{l}{x} -\frac{l}{[ x]( k+1)} |([ x] -N) +\color{red}{\overbrace{\color{red}{\sup _{t\in [ 0,1)}f(t)}}^{M'} x^{-k-1}}}\\
 & =\frac{M+M'}{x^{k+1}} +{\textstyle \frac{N|l|}{[ x]( k+1)} +\color{purple}{|\frac{l[ x]}{x} -\frac{l}{( k+1)} |} -N|\frac{l}{x} -\frac{l}{[ x]( k+1)} |+\frac{\epsilon ([ x] -N)}{x}} \tag 1
\end{align*} (1)","['real-analysis', 'calculus', 'limits']"
49,Prove/disprove: $f^2+f+1$ is not continuous at $x_0$,Prove/disprove:  is not continuous at,f^2+f+1 x_0,"Prove or Disprove: Let $x_0\in\mathbb R$ and let $f$ be a function that is defined on a neighborhood of $x_0$ . If $f$ is not continuous at $x_0$ and $f^3$ is continuous at $x_0$ , then $f^2+f+1$ is not continuous at $x_0$ . I am struggling with this proof (or disproof), because in my mind if we have that $f^3$ is continuous at $x_0$ , then $lim_{x\to x_0} f^3(x)=f^3(x_0)\implies lim_{x\to x_0}f(x)=\sqrt[\leftroot{-2}\uproot{2}3]{lim_{x\to x_0} f^3(x)}=\sqrt[\leftroot{-2}\uproot{2}3]{f^3(x_0)}=f(x_0)$ which just implies that $f$ is continuous at $x_0$ and then this is vacuously a proof. Am I missing something?","Prove or Disprove: Let and let be a function that is defined on a neighborhood of . If is not continuous at and is continuous at , then is not continuous at . I am struggling with this proof (or disproof), because in my mind if we have that is continuous at , then which just implies that is continuous at and then this is vacuously a proof. Am I missing something?",x_0\in\mathbb R f x_0 f x_0 f^3 x_0 f^2+f+1 x_0 f^3 x_0 lim_{x\to x_0} f^3(x)=f^3(x_0)\implies lim_{x\to x_0}f(x)=\sqrt[\leftroot{-2}\uproot{2}3]{lim_{x\to x_0} f^3(x)}=\sqrt[\leftroot{-2}\uproot{2}3]{f^3(x_0)}=f(x_0) f x_0,"['real-analysis', 'calculus', 'limits', 'continuity']"
50,Does every continuous function have an order of vanishing?,Does every continuous function have an order of vanishing?,,"I am trying to understand in what ways we can characterise growth of continuous functions around a point. One particular way to do so is by comparing a functions growth to a power of $x$ as follows. For a continuous function $f:[0,\infty) \to \mathbb{R}$ define its order of vanishing (at $x=0$ ) to be the number $0\leq \alpha \leq \infty$ such that $$\lim_{x \to 0} \left(\frac{f(x)}{x^\alpha}\right) =\gamma \neq \cases{0 \\ \pm \infty} $$ i.e. the $\alpha$ so the above limit is defined, finite and non-zero. In the case for a function $f(x)$ where $\frac{f(x)}{x^n} \to 0 \quad \forall n \in[0,\infty)$ define the order of vanishing of $f(x)$ , namely $\alpha$ , to be $\infty$ . For example with these definitions $\alpha=\infty$ when $f(x)=\exp \left(-\frac{1}{x}\right)$ as then $f(x)$ would grow slower than any power of $x$ around $x=0$ . My question is : Does the order of vanishing always exist for each continuous function $f$ on $[0,\infty)$ ? i.e. is this quantity well defined? If not then are there extra conditions should I stipulate on $f$ to guarantee existence? My thoughts on the matter as are follows, If such an $\alpha$ exists it is necessarily unique, for if $\beta<\alpha$ then $$\frac{f(x)}{x^\beta}=\frac{f(x)}{x^\alpha}\cdot x^{\alpha-\beta} \to 0$$ since by assumption the limit of $\frac{f(x)}{x^\alpha}$ is finite and non-zero. Hence $\beta$ cannot be an order of vanishing for $f$ . Similarly if $\beta>\alpha$ then $$\frac{f(x)}{x^\beta}=\frac{f(x)}{x^\alpha}\cdot \frac{1}{x^{\beta-\alpha}} \to \pm \infty$$ again, $\beta$ cannot be an order of vanishing of $f$ . Therefore if $\alpha$ exists it is unique. We cannot have $\frac{f(x)}{x^n}\to \pm \infty \quad \forall n \in [0,\infty)$ Since for $n=0$ this would imply $f(0)$ non finite. I suspect the existence of such an $\alpha$ may have a topological proof, maybe we can partition the domain of $\alpha \in [0,\infty)$ up into parts $S$ and $L$ , i.e. $[0,\infty)=S \cup L$ where $$S:=\bigg\{ \alpha \in [0,\infty) \bigg | \frac{f(x)}{x^\alpha} \to \pm \infty \text{ as } x \to 0 \bigg \}$$ $$L:=\bigg\{ \alpha \in [0,\infty) \bigg | \frac{f(x)}{x^\alpha} \to 0 \text{ as } x \to 0 \bigg \}$$ Maybe this violates the connectivity of $[0,\infty)$ ?","I am trying to understand in what ways we can characterise growth of continuous functions around a point. One particular way to do so is by comparing a functions growth to a power of as follows. For a continuous function define its order of vanishing (at ) to be the number such that i.e. the so the above limit is defined, finite and non-zero. In the case for a function where define the order of vanishing of , namely , to be . For example with these definitions when as then would grow slower than any power of around . My question is : Does the order of vanishing always exist for each continuous function on ? i.e. is this quantity well defined? If not then are there extra conditions should I stipulate on to guarantee existence? My thoughts on the matter as are follows, If such an exists it is necessarily unique, for if then since by assumption the limit of is finite and non-zero. Hence cannot be an order of vanishing for . Similarly if then again, cannot be an order of vanishing of . Therefore if exists it is unique. We cannot have Since for this would imply non finite. I suspect the existence of such an may have a topological proof, maybe we can partition the domain of up into parts and , i.e. where Maybe this violates the connectivity of ?","x f:[0,\infty) \to \mathbb{R} x=0 0\leq \alpha \leq \infty \lim_{x \to 0} \left(\frac{f(x)}{x^\alpha}\right) =\gamma \neq \cases{0 \\ \pm \infty}  \alpha f(x) \frac{f(x)}{x^n} \to 0 \quad \forall n \in[0,\infty) f(x) \alpha \infty \alpha=\infty f(x)=\exp \left(-\frac{1}{x}\right) f(x) x x=0 f [0,\infty) f \alpha \beta<\alpha \frac{f(x)}{x^\beta}=\frac{f(x)}{x^\alpha}\cdot x^{\alpha-\beta} \to 0 \frac{f(x)}{x^\alpha} \beta f \beta>\alpha \frac{f(x)}{x^\beta}=\frac{f(x)}{x^\alpha}\cdot \frac{1}{x^{\beta-\alpha}} \to \pm \infty \beta f \alpha \frac{f(x)}{x^n}\to \pm \infty \quad \forall n \in [0,\infty) n=0 f(0) \alpha \alpha \in [0,\infty) S L [0,\infty)=S \cup L S:=\bigg\{ \alpha \in [0,\infty) \bigg | \frac{f(x)}{x^\alpha} \to \pm \infty \text{ as } x \to 0 \bigg \} L:=\bigg\{ \alpha \in [0,\infty) \bigg | \frac{f(x)}{x^\alpha} \to 0 \text{ as } x \to 0 \bigg \} [0,\infty)","['real-analysis', 'general-topology', 'limits', 'continuity', 'asymptotics']"
51,Compute $\lim _{x\to 0}\left(\frac{\sqrt[3]{x}}{x}\right)$,Compute,\lim _{x\to 0}\left(\frac{\sqrt[3]{x}}{x}\right),I want to compute $\displaystyle \lim _{x\to 0}\left(\frac{\sqrt[3]{x}}{x}\right)$ $\displaystyle \lim _{x\to 0^{+}}\left(\frac{\sqrt[3]{x}}{x}\right)$ \begin{align*}  \lim _{x\to 0^{+}}\left(\frac{\sqrt[3]{x}}{x}\right)&= \lim _{x\to 0^{+}}\left(\frac{\sqrt[3]{x}}{\sqrt[3]{x}^{3}}\right)\\ &=\lim _{x\to 0^{+}}\left(\sqrt[3]{\frac{x}{x^3}}\right)\\ &=\lim _{x\to 0^{+}}\left(\sqrt[3]{\frac{1}{x^2}}\right)\\ &=\lim _{x\to 0^{+}}\left(\sqrt[3]{\frac{1}{(0^{+})^2}}\right)=+\infty\\ \lim _{x\to 0^{+}}\left(\frac{\sqrt[3]{x}}{x}\right)&=+\infty \end{align*} $\displaystyle \lim _{x\to 0^{-}}\left(\frac{\sqrt[3]{x}}{x}\right)$ $x\to 0^{-}\implies x<0 \implies (-x)>0\implies (-x)^{3}>0 \implies (-x)=\sqrt[3]{(-x)^3}   $ \begin{align*}  \lim _{x\to 0^{-}}\left(\frac{\sqrt[3]{x}}{x}\right)&=  \lim _{x\to 0^{-}}\left(\frac{-\sqrt[3]{x}}{-x}\right)\\ &=\lim _{x\to 0^{-}}\left(\frac{-\sqrt[3]{x}}{\sqrt[3]{(-x)^3}}\right)\\ \end{align*} I'm stuck here; please correct me if am wrong Thanks in advance,I want to compute I'm stuck here; please correct me if am wrong Thanks in advance,"\displaystyle \lim _{x\to 0}\left(\frac{\sqrt[3]{x}}{x}\right) \displaystyle \lim _{x\to 0^{+}}\left(\frac{\sqrt[3]{x}}{x}\right) \begin{align*}
 \lim _{x\to 0^{+}}\left(\frac{\sqrt[3]{x}}{x}\right)&= \lim _{x\to 0^{+}}\left(\frac{\sqrt[3]{x}}{\sqrt[3]{x}^{3}}\right)\\
&=\lim _{x\to 0^{+}}\left(\sqrt[3]{\frac{x}{x^3}}\right)\\
&=\lim _{x\to 0^{+}}\left(\sqrt[3]{\frac{1}{x^2}}\right)\\
&=\lim _{x\to 0^{+}}\left(\sqrt[3]{\frac{1}{(0^{+})^2}}\right)=+\infty\\
\lim _{x\to 0^{+}}\left(\frac{\sqrt[3]{x}}{x}\right)&=+\infty
\end{align*} \displaystyle \lim _{x\to 0^{-}}\left(\frac{\sqrt[3]{x}}{x}\right) x\to 0^{-}\implies x<0 \implies (-x)>0\implies (-x)^{3}>0 \implies (-x)=\sqrt[3]{(-x)^3}    \begin{align*}
 \lim _{x\to 0^{-}}\left(\frac{\sqrt[3]{x}}{x}\right)&=  \lim _{x\to 0^{-}}\left(\frac{-\sqrt[3]{x}}{-x}\right)\\
&=\lim _{x\to 0^{-}}\left(\frac{-\sqrt[3]{x}}{\sqrt[3]{(-x)^3}}\right)\\
\end{align*}","['real-analysis', 'calculus', 'limits', 'limits-without-lhopital']"
52,Evaluate $\lim_{x \to -2} \frac{x + 2}{\sin(\frac{\pi x}{2})}$ using continuity (without L'Hospital),Evaluate  using continuity (without L'Hospital),\lim_{x \to -2} \frac{x + 2}{\sin(\frac{\pi x}{2})},"A little background: I am TAing for a Calculus I class (mostly non-math majors), and this problem showed up on the worksheet for tomorrow. We have fully developed limits, including the squeeze theorem, and continuity, but we have not covered L'Hospital's rule yet. I am not sure how the students are supposed to approach this one. Perhaps I am missing something. Here is the problem: Use continuity to evaluate the limit. Explain your answer (especially why you can use continuity). $$ \lim_{x \to -2} \frac{x + 2}{\sin\big(\frac{\pi x}{2}\big)}. $$ We see that this function is not continuous (has a hole) at $-2$ and, for that matter, at all values of $x$ that make $\sin\big(\frac{\pi x}{2}\big) = 0$ . We will get $\frac{0}{0}$ if we do all the steps to get down to the point at which we can just plug in $-2$ . We cannot use L'Hospital's rule. The best direction I see is something like this: \begin{align*} \lim_{x \to -2} \frac{x + 2}{\sin\big(\frac{\pi x}{2}\big)} &= \lim_{x \to -2} \frac{x}{\sin\big(\frac{\pi x}{2}\big)} + \lim_{x \to -2} \frac{2}{\sin\big(\frac{\pi x}{2}\big)}\\ &= \frac{2}{\pi}\lim_{x \to -2} \frac{\frac{\pi x}{2}}{\sin\big(\frac{\pi x}{2}\big)} + 2\lim_{x \to -2} \frac{1}{\sin\big(\frac{\pi x}{2}\big)} \end{align*} From there, we might be able to do some $\frac{\sin(x)}{x}$ -type thing with the left term, but I am not quite sure what to do with the right term.","A little background: I am TAing for a Calculus I class (mostly non-math majors), and this problem showed up on the worksheet for tomorrow. We have fully developed limits, including the squeeze theorem, and continuity, but we have not covered L'Hospital's rule yet. I am not sure how the students are supposed to approach this one. Perhaps I am missing something. Here is the problem: Use continuity to evaluate the limit. Explain your answer (especially why you can use continuity). We see that this function is not continuous (has a hole) at and, for that matter, at all values of that make . We will get if we do all the steps to get down to the point at which we can just plug in . We cannot use L'Hospital's rule. The best direction I see is something like this: From there, we might be able to do some -type thing with the left term, but I am not quite sure what to do with the right term.","
\lim_{x \to -2} \frac{x + 2}{\sin\big(\frac{\pi x}{2}\big)}.
 -2 x \sin\big(\frac{\pi x}{2}\big) = 0 \frac{0}{0} -2 \begin{align*}
\lim_{x \to -2} \frac{x + 2}{\sin\big(\frac{\pi x}{2}\big)} &= \lim_{x \to -2} \frac{x}{\sin\big(\frac{\pi x}{2}\big)} + \lim_{x \to -2} \frac{2}{\sin\big(\frac{\pi x}{2}\big)}\\
&= \frac{2}{\pi}\lim_{x \to -2} \frac{\frac{\pi x}{2}}{\sin\big(\frac{\pi x}{2}\big)} + 2\lim_{x \to -2} \frac{1}{\sin\big(\frac{\pi x}{2}\big)}
\end{align*} \frac{\sin(x)}{x}","['calculus', 'limits', 'continuity', 'limits-without-lhopital']"
53,Evaluating $\lim_{k\to \infty} \frac{\sum_{n=0}^{k}x^{\frac{n}{k}}}{k+1}$ for all $x$,Evaluating  for all,\lim_{k\to \infty} \frac{\sum_{n=0}^{k}x^{\frac{n}{k}}}{k+1} x,"So I was really bored in my math class (I'm a high school sophomore taking precalculus in school) and my mind wandered to this expression: $$\lim_{k\to \infty} \frac{\sum_{n=0}^{k}x^{\frac{n}{k}}}{k+1}$$ I have no idea how to even begin to evaluate this. I did some playing around with it on Desmos and it looks something like this for large values of $k$ , which I don't recognize the shape of at all. I do notice that the graph should have the points $(0,0)$ and $(1,1)$ , and it seems like if $j>k$ then $\frac{\sum_{n=0}^{k}x^{\frac{n}{k}}}{k+1}\ge\frac{\sum_{n=0}^{j}x^{\frac{n}{j}}}{j+1}$ for all $x$ with equality at $x=1$ . Also, please feel free to add any suitable tags---I didn't really know which ones to add. (If you're wondering how I derived this expression, I was thinking about expressions like $\frac{x^0+x^1}{2}$ , $\frac{x^0+x^{\frac{1}{2}}+x^1}{3}$ , $\frac{x^0+x^{\frac{1}{3}}+x^{\frac{2}{3}}+x^1}{4}$ , and then I thought about what would happen if we added more and more terms...)","So I was really bored in my math class (I'm a high school sophomore taking precalculus in school) and my mind wandered to this expression: I have no idea how to even begin to evaluate this. I did some playing around with it on Desmos and it looks something like this for large values of , which I don't recognize the shape of at all. I do notice that the graph should have the points and , and it seems like if then for all with equality at . Also, please feel free to add any suitable tags---I didn't really know which ones to add. (If you're wondering how I derived this expression, I was thinking about expressions like , , , and then I thought about what would happen if we added more and more terms...)","\lim_{k\to \infty} \frac{\sum_{n=0}^{k}x^{\frac{n}{k}}}{k+1} k (0,0) (1,1) j>k \frac{\sum_{n=0}^{k}x^{\frac{n}{k}}}{k+1}\ge\frac{\sum_{n=0}^{j}x^{\frac{n}{j}}}{j+1} x x=1 \frac{x^0+x^1}{2} \frac{x^0+x^{\frac{1}{2}}+x^1}{3} \frac{x^0+x^{\frac{1}{3}}+x^{\frac{2}{3}}+x^1}{4}","['limits', 'summation']"
54,"Limit problem, how to show algebraically this limit doesn't exist?","Limit problem, how to show algebraically this limit doesn't exist?",,"I believe that the following limit does not exist: $$\lim\limits_{x \rightarrow \infty} \dfrac{\ln(1+\sin x)}{x} $$ A graphing tool suggests that there are vertical asymptotes at ""multiples"" of 3 $\pi$ /2. But I am not sure how to show this algebraically. It doesn't qualify for L'Hospital's Rule and series didn't get me very far either. Any suggestions are welcome. EDIT: I tried a u-sub by setting $1+sinx=t$ . The expression becomes $\frac{\ln t}{\arcsin(t-1)}$ where $t$ is in the interval $[0,2]$ . Now for all $t$ in the interval $(0,2]$ , the limit exists (including $t=1$ which is just a basic L'Hospital Rule). For $t=0+$ , it is clear the limit does not exist. That would be my best answer. EDIT 2: There is a problem with my answer. $1+sinx=t$ is not equivalent to $x=arcsin(t-1)$ because the arcsine gives a restricted outcome for $x$ . It is not possible for $x$ to go to infinity assuming the expression $x=arcsin(t-1)$ in the expression's denominator.","I believe that the following limit does not exist: A graphing tool suggests that there are vertical asymptotes at ""multiples"" of 3 /2. But I am not sure how to show this algebraically. It doesn't qualify for L'Hospital's Rule and series didn't get me very far either. Any suggestions are welcome. EDIT: I tried a u-sub by setting . The expression becomes where is in the interval . Now for all in the interval , the limit exists (including which is just a basic L'Hospital Rule). For , it is clear the limit does not exist. That would be my best answer. EDIT 2: There is a problem with my answer. is not equivalent to because the arcsine gives a restricted outcome for . It is not possible for to go to infinity assuming the expression in the expression's denominator.","\lim\limits_{x \rightarrow \infty} \dfrac{\ln(1+\sin x)}{x}  \pi 1+sinx=t \frac{\ln t}{\arcsin(t-1)} t [0,2] t (0,2] t=1 t=0+ 1+sinx=t x=arcsin(t-1) x x x=arcsin(t-1)",['limits']
55,Interversion of limit and summation of double-indexed sequence [closed],Interversion of limit and summation of double-indexed sequence [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Assume we have a sequence $(a_{m,n}) \in [0,1]^{\mathbb{N}\times \mathbb{N}}$ such that $a_{m,n} \rightarrow a_n\in [0,1]$ when $m \rightarrow \infty$ . Are there any known conditions under which $\sum_{n=0}^{\infty} a_{m,n} \rightarrow \sum_{n=0}^{\infty} a_n$ when $m \rightarrow \infty$ ? Assume it is known that both series converge.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question Assume we have a sequence such that when . Are there any known conditions under which when ? Assume it is known that both series converge.","(a_{m,n}) \in [0,1]^{\mathbb{N}\times \mathbb{N}} a_{m,n} \rightarrow a_n\in [0,1] m \rightarrow \infty \sum_{n=0}^{\infty} a_{m,n} \rightarrow \sum_{n=0}^{\infty} a_n m \rightarrow \infty","['real-analysis', 'calculus', 'sequences-and-series', 'limits']"
56,Asymptotic Difference of Binomial Expansions,Asymptotic Difference of Binomial Expansions,,"Given $x\rightarrow\infty$ , I know that $(1-\frac{2\ln2}{x})^{x-2}-(1-\frac{\ln2}{x})^{2(x-1)}$ goes to zero because \begin{align*} \Big(1-\frac{2\ln2}{x}\Big)^{x-2}-\Big(1-\frac{\ln2}{x}\Big)^{2(x-1)} &\sim\exp\Big(-\frac{2\ln2}{x}\cdot x\Big)-\exp\Big(-\frac{\ln2}{x}\cdot 2x\Big) \\ &=0, \end{align*} where I used $\sim$ to mean asymptotic equivalence. How can I find the specific scaling (i.e., the rate of convergence) of the difference? From the plots I made, it seems to me that it should be something like $O(\frac{1}{x})$ , which can be further verified with Wolfram alpha's Big-O domination calculator -- the result is \begin{align*} \Big(1-\frac{2\ln2}{x}\Big)^{x-2}-\Big(1-\frac{\ln2}{x}\Big)^{2(x-1)} &=\frac{\ln4-\ln^22}{4x}-O\Big(\frac{1}{x^2}\Big) \\ &=O\Big(\frac{1}{x}\Big). \end{align*} I tried using Binomial expansions and Taylor expansions but had trouble simplifying. Is there a simpler way to do this (without having to resort to Laurent series which Wolfram claims)?","Given , I know that goes to zero because where I used to mean asymptotic equivalence. How can I find the specific scaling (i.e., the rate of convergence) of the difference? From the plots I made, it seems to me that it should be something like , which can be further verified with Wolfram alpha's Big-O domination calculator -- the result is I tried using Binomial expansions and Taylor expansions but had trouble simplifying. Is there a simpler way to do this (without having to resort to Laurent series which Wolfram claims)?","x\rightarrow\infty (1-\frac{2\ln2}{x})^{x-2}-(1-\frac{\ln2}{x})^{2(x-1)} \begin{align*}
\Big(1-\frac{2\ln2}{x}\Big)^{x-2}-\Big(1-\frac{\ln2}{x}\Big)^{2(x-1)}
&\sim\exp\Big(-\frac{2\ln2}{x}\cdot x\Big)-\exp\Big(-\frac{\ln2}{x}\cdot 2x\Big) \\
&=0,
\end{align*} \sim O(\frac{1}{x}) \begin{align*}
\Big(1-\frac{2\ln2}{x}\Big)^{x-2}-\Big(1-\frac{\ln2}{x}\Big)^{2(x-1)}
&=\frac{\ln4-\ln^22}{4x}-O\Big(\frac{1}{x^2}\Big) \\
&=O\Big(\frac{1}{x}\Big).
\end{align*}","['limits', 'asymptotics', 'binomial-theorem']"
57,What is the derivative of Cantor function on Cantor set?,What is the derivative of Cantor function on Cantor set?,,"Although on Cantor set $C$ , the Cantor function $f|_C$ is non-differentiable, but I wonder for $x,y\in C$ , the limit: $$\lim_{y\to x}\frac{f(y)-f(x)}{y-x}=$$ $$\begin{cases} =+\infty\\\mathrm{or}\\\text{does not exist?} \end{cases}$$ I have tried to use the property that $f=\lim\limits_{n\to \infty} F_n$ and $\lim\limits_{n\to\infty}\frac{F_n(y)-F_n(x)}{y-x}=+\infty$ ,but since $\phi_n(y)= \frac{F_n(y)-F_n(x)}{y-x}$ is not uniformly convergent, we cannot say: $$\lim\limits_{y\to x} \lim\limits_{n\to \infty }\phi_n(y)=\lim\limits_{n\to \infty}\lim\limits_{y\to x}\phi_n(y)$$ so I do not know – is there any ways to research the property of the derivative of $f|_C$ .","Although on Cantor set , the Cantor function is non-differentiable, but I wonder for , the limit: I have tried to use the property that and ,but since is not uniformly convergent, we cannot say: so I do not know – is there any ways to research the property of the derivative of .","C f|_C x,y\in C \lim_{y\to x}\frac{f(y)-f(x)}{y-x}= \begin{cases}
=+\infty\\\mathrm{or}\\\text{does not exist?}
\end{cases} f=\lim\limits_{n\to \infty} F_n \lim\limits_{n\to\infty}\frac{F_n(y)-F_n(x)}{y-x}=+\infty \phi_n(y)= \frac{F_n(y)-F_n(x)}{y-x} \lim\limits_{y\to x} \lim\limits_{n\to \infty }\phi_n(y)=\lim\limits_{n\to \infty}\lim\limits_{y\to x}\phi_n(y) f|_C","['real-analysis', 'limits', 'derivatives', 'cantor-set']"
58,"Evaluate $\lim_{n\to\infty}\dfrac{[1^2x]+[2^2x]+[3^2x]+...[n^2x]}{n^3}$, where $[.]$ denotes the greatest integer function $x\in R$","Evaluate , where  denotes the greatest integer function",\lim_{n\to\infty}\dfrac{[1^2x]+[2^2x]+[3^2x]+...[n^2x]}{n^3} [.] x\in R,"Evaluate $\lim_{n\to\infty}\dfrac{[1^2x]+[2^2x]+[3^2x]+...[n^2x]}{n^3}$ , where $[.]$ denotes the greatest integer function $x\in R$ $\lim_{n\to\infty}\dfrac{[1^2x]+[2^2x]+[3^2x]+...[n^2x]}{n^3}=\lim_{n\to\infty}\dfrac{\sum_{r=1}^n[r^2x]}{n^3}$ Without $[.]$ , I could have written $\sum r^2=\dfrac{n(n+1)(2n+1)}6$ . Not sure how to approach now. If we try to convert it into integration, we have $\dfrac1n$ which could be written as $dx$ , we need $\dfrac rn$ to be written as varibale (maybe $y$ here, since $x$ is already given), but we have $r^2$ in $[.]$ , I don't think we can take $n^2$ inside. Can the squeeze theorem be applicable here? But now sure how.","Evaluate , where denotes the greatest integer function Without , I could have written . Not sure how to approach now. If we try to convert it into integration, we have which could be written as , we need to be written as varibale (maybe here, since is already given), but we have in , I don't think we can take inside. Can the squeeze theorem be applicable here? But now sure how.",\lim_{n\to\infty}\dfrac{[1^2x]+[2^2x]+[3^2x]+...[n^2x]}{n^3} [.] x\in R \lim_{n\to\infty}\dfrac{[1^2x]+[2^2x]+[3^2x]+...[n^2x]}{n^3}=\lim_{n\to\infty}\dfrac{\sum_{r=1}^n[r^2x]}{n^3} [.] \sum r^2=\dfrac{n(n+1)(2n+1)}6 \dfrac1n dx \dfrac rn y x r^2 [.] n^2,"['integration', 'limits', 'definite-integrals', 'summation']"
59,How to find functions in order to apply Squeeze Rule for continuous functions,How to find functions in order to apply Squeeze Rule for continuous functions,,"In our course we were introduced to the the Squeeze Rule for continuous functions. An example was given where the Squeeze Rule was used to prove that the following function is continuous at point $0$ . $$ f(x) = \begin{cases}        x^2 \sin(1/x) & x \not = 0 \\       0             & x = 0     \end{cases} $$ Looking at a graph of $f(x)$ , $g(x) = x^2$ and $h(x) = -x^2$ makes it pretty obvious that we could use $g, h$ together with the Squeeze Rule. But in a test they won't be so nice as to provide us with visual aids, also the use of a graphing calculator is forbidden. Are there any common techniques/clues we can apply if we are only given $f$ and it's graph (this they will provide in an examination) to find $g, h$ to apply the Squeeze Rule, proving continuity of $f$ ? Based on the definition of $f$ above alone I doubt I would have thought of $g(x) = x^2$ and $h(x) = -x^2$ straight away.","In our course we were introduced to the the Squeeze Rule for continuous functions. An example was given where the Squeeze Rule was used to prove that the following function is continuous at point . Looking at a graph of , and makes it pretty obvious that we could use together with the Squeeze Rule. But in a test they won't be so nice as to provide us with visual aids, also the use of a graphing calculator is forbidden. Are there any common techniques/clues we can apply if we are only given and it's graph (this they will provide in an examination) to find to apply the Squeeze Rule, proving continuity of ? Based on the definition of above alone I doubt I would have thought of and straight away.","0 
f(x) = \begin{cases} 
      x^2 \sin(1/x) & x \not = 0 \\
      0             & x = 0 
   \end{cases}
 f(x) g(x) = x^2 h(x) = -x^2 g, h f g, h f f g(x) = x^2 h(x) = -x^2","['real-analysis', 'calculus', 'limits', 'inequality', 'graphing-functions']"
60,Calculate limit of $\Gamma$ function for special values.,Calculate limit of  function for special values.,\Gamma,"I would like to calculate the limit without any software but have no idea how to do it. $$f(n) = \lim_{c \rightarrow 0} \frac{\Gamma(-n + c) + \Gamma(-n - c))}{2}$$ $$n = 0, 1, 2, ...$$ Wolfram in some way claculates it, for example: $$f(0) = - \gamma$$ $$f(1) = \gamma - 1$$ $$f(2) = \frac{3 - 2 \gamma}{4}$$ $$f(3) = \frac{6 \gamma - 11}{36}$$ $$(...)$$ It seems that the solutions will be somethink like that: $$f(n) = \frac{(a - \gamma)(-1)^{n}}{b}$$","I would like to calculate the limit without any software but have no idea how to do it. Wolfram in some way claculates it, for example: It seems that the solutions will be somethink like that:","f(n) = \lim_{c \rightarrow 0} \frac{\Gamma(-n + c) + \Gamma(-n - c))}{2} n = 0, 1, 2, ... f(0) = - \gamma f(1) = \gamma - 1 f(2) = \frac{3 - 2 \gamma}{4} f(3) = \frac{6 \gamma - 11}{36} (...) f(n) = \frac{(a - \gamma)(-1)^{n}}{b}","['limits', 'convergence-divergence', 'gamma-function']"
61,$\lim_{n \rightarrow \infty}\left(1+\dfrac{2}{n}\right)^{n^2}e^{-2n}$ [duplicate],[duplicate],\lim_{n \rightarrow \infty}\left(1+\dfrac{2}{n}\right)^{n^2}e^{-2n},This question already has answers here : $\lim_{n\to\infty} \left(1+\frac{2}{n}\right)^{n^2} e^{-2n}$ (2 answers) Closed 3 years ago . $\lim_{n \rightarrow \infty}\left(1+\dfrac{2}{n}\right)^{n^2}e^{-2n}$ $\lim_{n \rightarrow \infty}\left(e^{-2}\left(1+\dfrac{2}{n}\right)^n\right)^{n}$ It is indeterminate form $1^{\infty}$ I solve this like this $e^{\lim_{n \rightarrow \infty}}\frac{\ln(e^{-2}(1+\frac{2}{n})^n)}{\frac{1}{n}}$ I can't apply L'Hôpital's rule now how can I solve this problem quickly?,This question already has answers here : $\lim_{n\to\infty} \left(1+\frac{2}{n}\right)^{n^2} e^{-2n}$ (2 answers) Closed 3 years ago . It is indeterminate form I solve this like this I can't apply L'Hôpital's rule now how can I solve this problem quickly?,\lim_{n \rightarrow \infty}\left(1+\dfrac{2}{n}\right)^{n^2}e^{-2n} \lim_{n \rightarrow \infty}\left(e^{-2}\left(1+\dfrac{2}{n}\right)^n\right)^{n} 1^{\infty} e^{\lim_{n \rightarrow \infty}}\frac{\ln(e^{-2}(1+\frac{2}{n})^n)}{\frac{1}{n}},['limits']
62,$\lim_{x\to 0} \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2} $,,\lim_{x\to 0} \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2} ,"I have to find for which values of $a \in \Bbb N, a \ne 0$ the following limit exists and it is finite: $$\lim_{x\to 0} \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2}  $$ Applying L'Hôpital's rule: $$\frac{1-\cos (ax)}{x^2}\sim \frac{\sin (ax) \cdot a}{2x}\sim \frac{a^2}{2}$$ Then $$ \frac{\cos (\pi \cdot \frac{1-\cos (ax)}{x^2})}{x^2}  \sim   \frac{\cos (\pi \cdot \frac{a^2}{2})}{x^2}.$$ $$\cos (\pi \cdot \frac{a^2}{2})=0 \implies a^2=1+2k, \quad k \in \Bbb N$$ and in this case the limit is $0$ . In the book the suggested solution is $a^2=1+2k$ for which the limit is $$ \frac{(-1)^k \cdot (2k+1)^2\cdot\pi}{24}$$ but I don't understand this solution. Trying to solve the limit with $a^2=1+2k$ : $$ \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2} \sim \frac{-\sin (\pi \cdot \frac{1-\cos ax}{x^2}) \cdot \pi \cdot  \frac{\sin (ax)  a  x^2 - (1-\cos (ax))  2x}{x^4}}{2x} $$ $$ =  \sin \left( \frac{\pi}{2}+k \pi\right) \cdot \pi \cdot \frac{(1-\cos(ax))2- \sin(ax) ax}{2 \cdot x^4}$$ $$= (-1)^k \cdot \pi \cdot \frac{(1-\cos(ax))2- \sin(ax) ax}{2 \cdot x^4} $$",I have to find for which values of the following limit exists and it is finite: Applying L'Hôpital's rule: Then and in this case the limit is . In the book the suggested solution is for which the limit is but I don't understand this solution. Trying to solve the limit with :,"a \in \Bbb N, a \ne 0 \lim_{x\to 0} \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2}   \frac{1-\cos (ax)}{x^2}\sim \frac{\sin (ax) \cdot a}{2x}\sim \frac{a^2}{2}  \frac{\cos (\pi \cdot \frac{1-\cos (ax)}{x^2})}{x^2}  \sim   \frac{\cos (\pi \cdot \frac{a^2}{2})}{x^2}. \cos (\pi \cdot \frac{a^2}{2})=0 \implies a^2=1+2k, \quad k \in \Bbb N 0 a^2=1+2k  \frac{(-1)^k \cdot (2k+1)^2\cdot\pi}{24} a^2=1+2k  \frac{\cos \left(\pi \cdot \frac{1-\cos (ax)}{x^2}\right)}{x^2} \sim \frac{-\sin (\pi \cdot \frac{1-\cos ax}{x^2}) \cdot \pi \cdot  \frac{\sin (ax)  a  x^2 - (1-\cos (ax))  2x}{x^4}}{2x}   =  \sin \left( \frac{\pi}{2}+k \pi\right) \cdot \pi \cdot \frac{(1-\cos(ax))2- \sin(ax) ax}{2 \cdot x^4} = (-1)^k \cdot \pi \cdot \frac{(1-\cos(ax))2- \sin(ax) ax}{2 \cdot x^4} ","['real-analysis', 'limits']"
63,$\lim\limits_{n\to\infty}n\big(\sum_{k=1}^n\frac{k^2}{n^3+kn}-\frac{1}{3}\big)$?,?,\lim\limits_{n\to\infty}n\big(\sum_{k=1}^n\frac{k^2}{n^3+kn}-\frac{1}{3}\big),"calculate $$\lim\limits_{n\to\infty}n\left(\sum\limits_{k=1}^n\dfrac{k^2}{n^3+kn}-\dfrac{1}{3}\right).$$ I got it $$\lim\limits_{n\to\infty}\sum\limits_{k=1}^n\dfrac{k^2}{n^3+kn}=\lim\limits_{n\to\infty}\dfrac{1}{n}\sum\limits_{k=1}^n\dfrac{(\frac{k}{n})^2}{1+\frac{k}{n^2}}.$$ Use Squeeze theorem we have $$\frac{1}{n+1}\sum\limits_{k=1}^n(\frac{k}{n})^2<\dfrac{1}{n}\sum\limits_{k=1}^n\dfrac{(\frac{k}{n})^2}{1+\frac{k}{n^2}}<\dfrac{1}{n}\sum\limits_{k=1}^n(\frac{k}{n})^2$$ So $$\lim\limits_{n\to\infty}\sum\limits_{k=1}^n\dfrac{k^2}{n^3+kn}=\int_0^1x^2\mathrm{d}x=\frac{1}{3}.$$ Use $$\lim\limits_{n\to\infty}n\left(\int_0^1f(x)\mathrm{d}x-\frac{1}{n}\sum\limits_{k=1}^{n}f\left(\frac{k}{n}\right)\right)=\frac{f(0)-f(1)}{2}.$$ Hence $$\lim\limits_{n\to\infty}n\left(\sum\limits_{k=1}^n\dfrac{k^2}{n^3+kn}-\dfrac{1}{3}\right)=\frac{1}{2}.$$ If our method is correct, is there any other way to solve this problem? Thank you","calculate I got it Use Squeeze theorem we have So Use Hence If our method is correct, is there any other way to solve this problem? Thank you",\lim\limits_{n\to\infty}n\left(\sum\limits_{k=1}^n\dfrac{k^2}{n^3+kn}-\dfrac{1}{3}\right). \lim\limits_{n\to\infty}\sum\limits_{k=1}^n\dfrac{k^2}{n^3+kn}=\lim\limits_{n\to\infty}\dfrac{1}{n}\sum\limits_{k=1}^n\dfrac{(\frac{k}{n})^2}{1+\frac{k}{n^2}}. \frac{1}{n+1}\sum\limits_{k=1}^n(\frac{k}{n})^2<\dfrac{1}{n}\sum\limits_{k=1}^n\dfrac{(\frac{k}{n})^2}{1+\frac{k}{n^2}}<\dfrac{1}{n}\sum\limits_{k=1}^n(\frac{k}{n})^2 \lim\limits_{n\to\infty}\sum\limits_{k=1}^n\dfrac{k^2}{n^3+kn}=\int_0^1x^2\mathrm{d}x=\frac{1}{3}. \lim\limits_{n\to\infty}n\left(\int_0^1f(x)\mathrm{d}x-\frac{1}{n}\sum\limits_{k=1}^{n}f\left(\frac{k}{n}\right)\right)=\frac{f(0)-f(1)}{2}. \lim\limits_{n\to\infty}n\left(\sum\limits_{k=1}^n\dfrac{k^2}{n^3+kn}-\dfrac{1}{3}\right)=\frac{1}{2}.,"['real-analysis', 'integration', 'limits', 'solution-verification']"
64,L'Hospital's rule doesn't converge for a function with square root,L'Hospital's rule doesn't converge for a function with square root,,"I was trying to find the limit of a function of the form $\frac{x}{\sqrt{(x+a)(x+b)}}$ . When I apply L'Hospital's rule and differentiate the numerator and denominator, after simplification I end up with the same form as I started with: $$L = \lim_{x \to \infty} \frac{x}{\sqrt{(x+a)(x+b)}} \\ = \lim_{x \to \infty} \frac{1}{\frac{1}{2} \frac{(2x+a+b)}{\sqrt{(x+a)(x+b)}}} = \frac{2\sqrt{(x+a)(x+b)}}{2x+a+b} = \frac{\frac{2x+a+b}{\sqrt{(x+a)(x+b)}}}{2} \\ = \lim_{x \to \infty} \frac{x}{\sqrt{(x+a)(x+b)}} \textrm{(because $\lim_{x \to \infty} \frac{a+b}{\sqrt{...}}$ is zero)}$$ I noticed if I solve it by computing the limit of the squared value, the solution is easy: $$L^2 = \lim_{x \to \infty} \frac{x^2}{(x+a)(x+b)} \\ L^2 = \lim_{x \to \infty} \frac{2x}{2x+b+c} = 1 \\ L = \sqrt{1} = 1$$ Before I found this solution, I was searching online for different ways of evaluating limits and applying L'Hospital's rule, but none of the resources I came across seem to cover this case. Am I missing another straightforward way of solving this (whether using L'Hospital's or not)? When does L'Hospital's rule fail to converge, and what does it mean when it does?","I was trying to find the limit of a function of the form . When I apply L'Hospital's rule and differentiate the numerator and denominator, after simplification I end up with the same form as I started with: I noticed if I solve it by computing the limit of the squared value, the solution is easy: Before I found this solution, I was searching online for different ways of evaluating limits and applying L'Hospital's rule, but none of the resources I came across seem to cover this case. Am I missing another straightforward way of solving this (whether using L'Hospital's or not)? When does L'Hospital's rule fail to converge, and what does it mean when it does?","\frac{x}{\sqrt{(x+a)(x+b)}} L = \lim_{x \to \infty} \frac{x}{\sqrt{(x+a)(x+b)}} \\
= \lim_{x \to \infty} \frac{1}{\frac{1}{2} \frac{(2x+a+b)}{\sqrt{(x+a)(x+b)}}} = \frac{2\sqrt{(x+a)(x+b)}}{2x+a+b} = \frac{\frac{2x+a+b}{\sqrt{(x+a)(x+b)}}}{2} \\
= \lim_{x \to \infty} \frac{x}{\sqrt{(x+a)(x+b)}} \textrm{(because \lim_{x \to \infty} \frac{a+b}{\sqrt{...}} is zero)} L^2 = \lim_{x \to \infty} \frac{x^2}{(x+a)(x+b)} \\
L^2 = \lim_{x \to \infty} \frac{2x}{2x+b+c} = 1 \\
L = \sqrt{1} = 1","['limits', 'derivatives']"
65,$\lim f'(x) = l$,,\lim f'(x) = l,"Let $f : \left]0, +\infty\right[ \to \mathbb R$ a differentiable and bounded function such that $$\lim_{x \to +\infty} f'(x) = l$$ Show that $l = 0$ . My attempt is the following : Suppose that $l>0$ , then $\forall \epsilon > 0, \exists x_0 > 0, \text{ such that } \forall x>x_0, \lvert f'(x) - l \rvert \leq \epsilon $ . Taking $\epsilon = \frac{l}{2}$ , we have that $\frac{l}{2} \leq f'(x)$ $\forall x > x_0$ . Then by the mean value theorem, we can say that $\forall x > x_0, f(x) \geq \frac{l}{2}(x-x_0) + f(x_0)$ . Hence, $\lim_{x \to +\infty}f(x)= +\infty$ . I guess we can do the same for $l < 0$ and deduce that $\lim_{x \to +\infty}f(x)= -\infty$ . So if $f$ is bounded then $l=0$ . Is it correct ? Is there any direct proof ?","Let a differentiable and bounded function such that Show that . My attempt is the following : Suppose that , then . Taking , we have that . Then by the mean value theorem, we can say that . Hence, . I guess we can do the same for and deduce that . So if is bounded then . Is it correct ? Is there any direct proof ?","f : \left]0, +\infty\right[ \to \mathbb R \lim_{x \to +\infty} f'(x) = l l = 0 l>0 \forall \epsilon > 0, \exists x_0 > 0, \text{ such that } \forall x>x_0, \lvert f'(x) - l \rvert \leq \epsilon  \epsilon = \frac{l}{2} \frac{l}{2} \leq f'(x) \forall x > x_0 \forall x > x_0, f(x) \geq \frac{l}{2}(x-x_0) + f(x_0) \lim_{x \to +\infty}f(x)= +\infty l < 0 \lim_{x \to +\infty}f(x)= -\infty f l=0","['real-analysis', 'limits', 'derivatives', 'solution-verification']"
66,$\lim_{x \to 0}{\frac{\sinh(x)-\sin(x)}{x(\cosh(x)-\cos(x))}}$,,\lim_{x \to 0}{\frac{\sinh(x)-\sin(x)}{x(\cosh(x)-\cos(x))}},"As stated in the title. My attempt, begin with L'Hopital: $$L=\lim_{x \to 0}{\frac{\sinh(x)-\sin(x)}{x(\cosh(x)-\cos(x))}}=\lim_{x \to 0}{\frac{\cosh(x)-\cos(x)}{(\cosh(x)-\cos(x))+x(\sinh(x)+\sin(x))}}$$ Dividing by the numerator $$\lim_{x \to 0}\frac{1}{1+\left(\frac{x\left(\sinh(x)+\sin(x)\right)}{\cosh(x)-\cos(x)}\right)}=\frac{1}{1+\lim_{x \to 0}{\left(\frac{x\left(\sinh(x)+\sin(x)\right)}{\cosh(x)-\cos(x)}\right)}}$$ L'Hopital again $$\frac{1}{1+\lim_{x \to 0}{\left(\frac{x(\cosh(x)+\cos(x))+(\sinh(x)+\sin(x))}{\sinh(x)+\sin(x)}\right)}}$$ Diving through $$\frac{1}{1+\lim_{x \to 0}{\left(1+\frac{\cosh(x)+\cos(x)}{\left(\frac{\sinh(x)}{x}+\frac{\sin(x)}{x} \right)}\right)}}=\frac{1}{1+(1+\frac{1+1}{1+1})}=\frac{1}{3}$$ Is this correct, and is there a more elegant way of doing it?","As stated in the title. My attempt, begin with L'Hopital: Dividing by the numerator L'Hopital again Diving through Is this correct, and is there a more elegant way of doing it?",L=\lim_{x \to 0}{\frac{\sinh(x)-\sin(x)}{x(\cosh(x)-\cos(x))}}=\lim_{x \to 0}{\frac{\cosh(x)-\cos(x)}{(\cosh(x)-\cos(x))+x(\sinh(x)+\sin(x))}} \lim_{x \to 0}\frac{1}{1+\left(\frac{x\left(\sinh(x)+\sin(x)\right)}{\cosh(x)-\cos(x)}\right)}=\frac{1}{1+\lim_{x \to 0}{\left(\frac{x\left(\sinh(x)+\sin(x)\right)}{\cosh(x)-\cos(x)}\right)}} \frac{1}{1+\lim_{x \to 0}{\left(\frac{x(\cosh(x)+\cos(x))+(\sinh(x)+\sin(x))}{\sinh(x)+\sin(x)}\right)}} \frac{1}{1+\lim_{x \to 0}{\left(1+\frac{\cosh(x)+\cos(x)}{\left(\frac{\sinh(x)}{x}+\frac{\sin(x)}{x} \right)}\right)}}=\frac{1}{1+(1+\frac{1+1}{1+1})}=\frac{1}{3},"['calculus', 'limits', 'derivatives', 'trigonometry']"
67,Evaluate $\underset{n\to \infty }{\text{lim}}\left(\sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}\right)$,Evaluate,\underset{n\to \infty }{\text{lim}}\left(\sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}\right),"Evaluate the limit $$ \underset{n\to \infty }{\text{lim}}\left(\sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}\right) $$ I got stuked when trying to evaluate it and I even don't know where to begin. Mathematica tells me that $$ \sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}=\frac{2^{1/n} \left(-\left(2^{1/n}\right)^n \Phi \left(2^{1/n},1,n+1+\frac{1}{n}\right)+\left(2^{1/n}\right)^{n+1} \Phi \left(2^{1/n},1,n+1+\frac{1}{n}\right)-2^{1/n} \Phi \left(2^{1/n},1,1+\frac{1}{n}\right)+\Phi \left(2^{1/n},1,1+\frac{1}{n}\right)+n \left(2^{1/n}\right)^n-n\right)}{\left(2^{1/n}-1\right) n^2} $$ However it doesn't give the result of the limit either. And I tried $n=10000$ numerically, the answer is $1.44274..$ . So how to calculate the limit ?","Evaluate the limit I got stuked when trying to evaluate it and I even don't know where to begin. Mathematica tells me that However it doesn't give the result of the limit either. And I tried numerically, the answer is . So how to calculate the limit ?","
\underset{n\to \infty }{\text{lim}}\left(\sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}\right)
 
\sum _{k=1}^n \frac{2^{k/n}}{\frac{1}{k}+n}=\frac{2^{1/n} \left(-\left(2^{1/n}\right)^n \Phi \left(2^{1/n},1,n+1+\frac{1}{n}\right)+\left(2^{1/n}\right)^{n+1} \Phi \left(2^{1/n},1,n+1+\frac{1}{n}\right)-2^{1/n} \Phi \left(2^{1/n},1,1+\frac{1}{n}\right)+\Phi \left(2^{1/n},1,1+\frac{1}{n}\right)+n \left(2^{1/n}\right)^n-n\right)}{\left(2^{1/n}-1\right) n^2}
 n=10000 1.44274..","['limits', 'summation', 'special-functions']"
68,How to show that $a_{n+2}=\frac{a_{n+1} ^2 -1}{a_n}$ . is bounded?,How to show that  . is bounded?,a_{n+2}=\frac{a_{n+1} ^2 -1}{a_n},"Let $a_{n+2}=\frac{a_{n+1} ^2  -1}{a_n}$ be a sequence of real numbers where $a_n>0$ for all $n \in \mathbb{Z}_{+}$ . It is given that $a_1=1 , a_2=b>0$ . It is given that $1<b<2$ .Is it possible to show that $a_n$ is bounded from this given information?",Let be a sequence of real numbers where for all . It is given that . It is given that .Is it possible to show that is bounded from this given information?,"a_{n+2}=\frac{a_{n+1} ^2  -1}{a_n} a_n>0 n \in \mathbb{Z}_{+} a_1=1 , a_2=b>0 1<b<2 a_n","['real-analysis', 'sequences-and-series', 'limits', 'cauchy-sequences']"
69,Proof using formal definition of limit that $ \lim_{x\to0} (x^2\sin(x^2+2x)+2)=2 $,Proof using formal definition of limit that, \lim_{x\to0} (x^2\sin(x^2+2x)+2)=2 ,"I'm having a hard time trying to understand how to prove the following, using the formal definition of limits: $$ \lim_{x\to0} (x^2\sin(x^2+2x)+2)=2 $$ I already did the following the steps but I'm not sure if my thinking is correct: $$ |x^2\sin(x^2+2x)+2-2|<\epsilon \implies  |x^2\sin(x^2+2x)|<\epsilon \implies |x^2||\sin(x^2+2x)|<\epsilon $$ and assuming that $x\in{R}$ then $x^2|\sin(x^2+2x)|<\epsilon$ Now I also know that $-1<\sin(x)<1$ however I'm struggling to understand how to best apply this to the proof. I'm not looking for a full solution to the problem, rather I'm interested in confirming if my thinking up until now is correct and maybe some hints to unblock the next steps.","I'm having a hard time trying to understand how to prove the following, using the formal definition of limits: I already did the following the steps but I'm not sure if my thinking is correct: and assuming that then Now I also know that however I'm struggling to understand how to best apply this to the proof. I'm not looking for a full solution to the problem, rather I'm interested in confirming if my thinking up until now is correct and maybe some hints to unblock the next steps.","
\lim_{x\to0} (x^2\sin(x^2+2x)+2)=2
 
|x^2\sin(x^2+2x)+2-2|<\epsilon \implies  |x^2\sin(x^2+2x)|<\epsilon \implies |x^2||\sin(x^2+2x)|<\epsilon
 x\in{R} x^2|\sin(x^2+2x)|<\epsilon -1<\sin(x)<1","['limits', 'epsilon-delta']"
70,Evaluate $\lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{k}{k^2+n^2}$,Evaluate,\lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{k}{k^2+n^2},"$$\lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{k}{k^2+n^2}$$ I got asked this question in a group, and solved it the following way: $$\lim\limits_{n\to\infty}\left( \int\limits_1^{n+1}\frac{x}{x^2+n^2}\space dx\leq \sum\limits_{k=1}^{n}\frac{k}{k^2+n^2}\leq \int\limits_1^n \frac{x}{x^2+n^2}\space dx + f(1)\right) $$ $$\frac{\ln2}{2}\leq \lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{k}{k^2+n^2}\leq\frac{\ln2}{2}$$ Therefore: $$\lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{k}{k^2+n^2} = \frac{\ln2}{2}$$ The guy who asked me the question said that the answer key said $\frac{\ln\left(\frac{5}{2}\right)}{2}$ but also said that it might be incorrect, so I don't have the answer. What I want to ask is that how come this sum is not equal to $0$ ? We were able to use the squeeze theorem because the limit for $f(1)$ goes to zero. Every other value after $f(1)$ also goes to $0$ (even faster?) and that had me thinking about how this summation can be equal to such a value. Can anyone please explain how this happens? And it would be great if you could also verify or correct my solution.","I got asked this question in a group, and solved it the following way: Therefore: The guy who asked me the question said that the answer key said but also said that it might be incorrect, so I don't have the answer. What I want to ask is that how come this sum is not equal to ? We were able to use the squeeze theorem because the limit for goes to zero. Every other value after also goes to (even faster?) and that had me thinking about how this summation can be equal to such a value. Can anyone please explain how this happens? And it would be great if you could also verify or correct my solution.","\lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{k}{k^2+n^2} \lim\limits_{n\to\infty}\left(
\int\limits_1^{n+1}\frac{x}{x^2+n^2}\space dx\leq \sum\limits_{k=1}^{n}\frac{k}{k^2+n^2}\leq \int\limits_1^n \frac{x}{x^2+n^2}\space dx + f(1)\right)
 \frac{\ln2}{2}\leq \lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{k}{k^2+n^2}\leq\frac{\ln2}{2} \lim\limits_{n\to\infty}\sum\limits_{k=1}^{n}\frac{k}{k^2+n^2} = \frac{\ln2}{2} \frac{\ln\left(\frac{5}{2}\right)}{2} 0 f(1) f(1) 0","['calculus', 'sequences-and-series', 'limits', 'convergence-divergence']"
71,Solution verification of $\lim_{n\to\infty}\left(1+\left(\sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)\right)^{-1}\right)^{n}$,Solution verification of,\lim_{n\to\infty}\left(1+\left(\sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)\right)^{-1}\right)^{n},"$$\lim_{n\to\infty}\left(1+\left(\sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)\right)^{-1}\right)^{n}$$ Source: Romanian Mathematical Magazine Spring edition 2022, problem UP. 354 . I work out in following manner. Clearly, $\displaystyle \frac{k\pi}{n}>0$ for all $k\in[ 1, n-1]$ so due to    Taylor series around $x=0$ we have $\sin x \leq x$ for all $ x>0$ . Choose $\displaystyle x=\frac{k\pi}{n}$ we have then $$\sin\left(\frac{k\pi }{n}\right)\leq \frac{k\pi}{n}\Rightarrow S(n)= \sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)\leq \pi\sum_{k=1}^{n-1}\frac{k^2}{n^2}=\frac{\pi}{6}\left[\frac{(n-1)(2n-1)}{n}\right]\cdots(1)$$ Since  the partial sum of the later sum diverges as $n\to \infty$ so $S(n)\to \infty$ (due to comparison test). Therefore, $$L=\lim_{n\to \infty} \left(1+\left(S(n)\right)^{-1}\right)^{n}=1^{\infty}$$ and hence we have $$L= \lim_{n\to\infty}\exp\left(\left(S(n)\right)^{-1}\right)=\exp\left(\lim_{n\to \infty}n\left(\sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)\right)^{-1}\right)$$ since latter expression is Riemann integrable function on $[0,1]$ so the limit reduces to $$L= \exp\left(\int_0^1 x\sin(\pi x) dx\right)^{-1} \underbrace {=}_{IBP}e^{\left(\pi^{-1}\right)^{-1}}=e^{\pi}$$ The reason of $(1)$ in above is to show that for large value  of $n$ the original sum is divergent so that its reciprocal is $0$ giving us $1^{\infty}$ form. Question: Is my work and inequality $(1)$ supports the valid proof? I manage  to find the limit of problem  in other way by showing that $$\sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)=\frac{1}{2}\cot\left(\frac{\pi}{2n}\right)$$ giving us $e^{\pi}$ .","Source: Romanian Mathematical Magazine Spring edition 2022, problem UP. 354 . I work out in following manner. Clearly, for all so due to    Taylor series around we have for all . Choose we have then Since  the partial sum of the later sum diverges as so (due to comparison test). Therefore, and hence we have since latter expression is Riemann integrable function on so the limit reduces to The reason of in above is to show that for large value  of the original sum is divergent so that its reciprocal is giving us form. Question: Is my work and inequality supports the valid proof? I manage  to find the limit of problem  in other way by showing that giving us .","\lim_{n\to\infty}\left(1+\left(\sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)\right)^{-1}\right)^{n} \displaystyle \frac{k\pi}{n}>0 k\in[ 1, n-1] x=0 \sin x \leq x  x>0 \displaystyle x=\frac{k\pi}{n} \sin\left(\frac{k\pi }{n}\right)\leq \frac{k\pi}{n}\Rightarrow S(n)= \sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)\leq \pi\sum_{k=1}^{n-1}\frac{k^2}{n^2}=\frac{\pi}{6}\left[\frac{(n-1)(2n-1)}{n}\right]\cdots(1) n\to \infty S(n)\to \infty L=\lim_{n\to \infty} \left(1+\left(S(n)\right)^{-1}\right)^{n}=1^{\infty} L= \lim_{n\to\infty}\exp\left(\left(S(n)\right)^{-1}\right)=\exp\left(\lim_{n\to \infty}n\left(\sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)\right)^{-1}\right) [0,1] L= \exp\left(\int_0^1 x\sin(\pi x) dx\right)^{-1} \underbrace {=}_{IBP}e^{\left(\pi^{-1}\right)^{-1}}=e^{\pi} (1) n 0 1^{\infty} (1) \sum_{k=1}^{n-1}\frac{k}{n}\sin\left(\frac{k\pi}{n}\right)=\frac{1}{2}\cot\left(\frac{\pi}{2n}\right) e^{\pi}","['real-analysis', 'sequences-and-series', 'limits', 'solution-verification']"
72,A graph satisfying $\lim_{x \to 0} f(x) = 0$ and $\lim_{x \to 0} f(f(x)) = 1$,A graph satisfying  and,\lim_{x \to 0} f(x) = 0 \lim_{x \to 0} f(f(x)) = 1,I am wondering how $\lim_{x \to 0} f(x) = 0$ but $\lim_{x \to 0} f(f(x)) = 1$ is possible. Since $\lim_{x \to 0} f(f(x))$ = $f(\lim_{x \to 0} f(x)) = \lim_{x \to 0} f(x) = 0$ but not $1$ . I think this has something to do with discontinuity at $0$ but I am not able to sketch a graph satisfying this.,I am wondering how but is possible. Since = but not . I think this has something to do with discontinuity at but I am not able to sketch a graph satisfying this.,\lim_{x \to 0} f(x) = 0 \lim_{x \to 0} f(f(x)) = 1 \lim_{x \to 0} f(f(x)) f(\lim_{x \to 0} f(x)) = \lim_{x \to 0} f(x) = 0 1 0,"['limits', 'limits-without-lhopital']"
73,Limit of $f(x)=x/|x|$ as $x\to 0$,Limit of  as,f(x)=x/|x| x\to 0,"Consider the function $f$ defined in $\mathbb{R}\setminus\{0\}$ by $f(x)=\frac{x}{|x|}$ . Show that $\displaystyle\lim_{x\to 0}f(x)$ doesn't exist. My attempt: Note that $f(x)=1$ for $x>0$ and $f(x)=-1$ for $x<0$ . Suppose that $\displaystyle\lim_{x\to 0}f(x)=L$ exists. Applying the definition with $\varepsilon =1$ , there should be $\delta>0$ such that $$0<|x-0|<\delta\implies |f(x)-L|<1.$$ Taking $x=\delta/2$ , implies $|1-L|<1$ , then $-1<-1-L<1$ , which implies $1-L<1\iff 0<L$ Now, taking $x=-\delta/2$ implies $|-1-L|<1,$ then $-1<-1-L<1,$ which implies $-1<-1-L\iff L<0$ . (Contradiction) Is this correct?","Consider the function defined in by . Show that doesn't exist. My attempt: Note that for and for . Suppose that exists. Applying the definition with , there should be such that Taking , implies , then , which implies Now, taking implies then which implies . (Contradiction) Is this correct?","f \mathbb{R}\setminus\{0\} f(x)=\frac{x}{|x|} \displaystyle\lim_{x\to 0}f(x) f(x)=1 x>0 f(x)=-1 x<0 \displaystyle\lim_{x\to 0}f(x)=L \varepsilon =1 \delta>0 0<|x-0|<\delta\implies |f(x)-L|<1. x=\delta/2 |1-L|<1 -1<-1-L<1 1-L<1\iff 0<L x=-\delta/2 |-1-L|<1, -1<-1-L<1, -1<-1-L\iff L<0","['real-analysis', 'calculus', 'limits', 'solution-verification', 'epsilon-delta']"
74,Does this recursive sequence converge (non monotonic)?,Does this recursive sequence converge (non monotonic)?,,"Let $\{a_n\}$ be a sequence such that $a_1=4$ and $a_{n+1}=\dfrac{5 a_n -6}{a_n -2},\, \forall n\geq 2$ . Show that it converges and find its limit. The only thing that I managed to show is that if it is convergent, the limit is either 1 or 6. I used Mathematica to see the behavior of the sequence, and I noticed that it converges to 6 and also that it is not monotonic. I have come across some recursive sequences like this in various posts here in math.SE, but all of them where bounded and monotonic.","Let be a sequence such that and . Show that it converges and find its limit. The only thing that I managed to show is that if it is convergent, the limit is either 1 or 6. I used Mathematica to see the behavior of the sequence, and I noticed that it converges to 6 and also that it is not monotonic. I have come across some recursive sequences like this in various posts here in math.SE, but all of them where bounded and monotonic.","\{a_n\} a_1=4 a_{n+1}=\dfrac{5 a_n -6}{a_n -2},\, \forall n\geq 2","['real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence', 'recursion']"
75,"Can I solve $\lim_{(x,y)\to\ (0,0)} \frac{x^2y^2}{x^2+x^2y^2+y^2}$ by converting to polar coordinates?",Can I solve  by converting to polar coordinates?,"\lim_{(x,y)\to\ (0,0)} \frac{x^2y^2}{x^2+x^2y^2+y^2}","Is it correct to solve this problem like this? $$\lim_{(x,y)\to\ (0,0)} \frac{x^2y^2}{x^2+x^2y^2+y^2} $$ $$\lim_{(x,y)\to\ (0,0)} \frac{1}{1+\frac{x^2+y^2}{x^2y^2}}$$ $$\frac{x^2+y^2}{x^2y^2}=\lim_{r\to\ 0} \frac{1}{r^2\cos^2\theta\sin^2\theta}=\infty\implies \lim_{(x,y)\to\ (0,0)} \frac{1}{1+\frac{x^2+y^2}{x^2y^2}}=0$$",Is it correct to solve this problem like this?,"\lim_{(x,y)\to\ (0,0)} \frac{x^2y^2}{x^2+x^2y^2+y^2}  \lim_{(x,y)\to\ (0,0)} \frac{1}{1+\frac{x^2+y^2}{x^2y^2}} \frac{x^2+y^2}{x^2y^2}=\lim_{r\to\ 0} \frac{1}{r^2\cos^2\theta\sin^2\theta}=\infty\implies \lim_{(x,y)\to\ (0,0)} \frac{1}{1+\frac{x^2+y^2}{x^2y^2}}=0","['limits', 'multivariable-calculus', 'polar-coordinates', 'limits-without-lhopital']"
76,Rate of convergence for a sequence (Preferably without Taylor series),Rate of convergence for a sequence (Preferably without Taylor series),,"I am trying to solve the following problem: Knowing that the sequence $(a_{n})$ with: $$a_{n+1}=\frac{1}{2}(a_{n}+\frac{3}{a_{n}})$$ converges to $\sqrt{3}$ , find it's rate of convergence. After doing some searching, I found this formula from wikipedia : $$\lim\limits_{n \to \infty} \frac{|a_{n+1}-L|}{|a_{n}-L|} = μ$$ And I think that our L is $\sqrt{3}$ . Do I need to find the value of $a_{n}$ to find the rate of convergence (μ)? And how do I find $a_{n}$ ? UPDATE: I can simply use the formula above but I need to make my limit approach to $\sqrt{3}$ because we have $a_{n} \to \sqrt{3}$ : $$\lim\limits_{x \to \sqrt{3}} \frac{|\frac{1}{2}(x+\frac{3}{x})-\sqrt{3}|}{|x-\sqrt{3}|}$$ But my problem is that this limit is resulting in a indeterminate form because of $\frac{0}{0}$ How can I solve this limit without expanding series? UPDATE 2 - ANSWER: Using @ user 's approach we can write our limit as: $$\lim\limits_{x \to \sqrt{3}} \frac{\frac{1}{2}(x+\frac{3}{x})-\sqrt{3}}{x-\sqrt{3}}=\frac{x^2-2\sqrt 3x+3}{2x(x-\sqrt{3})}=\frac{(x-\sqrt{3})^2}{2x(x-\sqrt{3})}=\frac{x-\sqrt{3}}{2x}\to 0$$ and then the sequence converges Q-superlinearly to $\sqrt 3$ . Look at here .","I am trying to solve the following problem: Knowing that the sequence with: converges to , find it's rate of convergence. After doing some searching, I found this formula from wikipedia : And I think that our L is . Do I need to find the value of to find the rate of convergence (μ)? And how do I find ? UPDATE: I can simply use the formula above but I need to make my limit approach to because we have : But my problem is that this limit is resulting in a indeterminate form because of How can I solve this limit without expanding series? UPDATE 2 - ANSWER: Using @ user 's approach we can write our limit as: and then the sequence converges Q-superlinearly to . Look at here .",(a_{n}) a_{n+1}=\frac{1}{2}(a_{n}+\frac{3}{a_{n}}) \sqrt{3} \lim\limits_{n \to \infty} \frac{|a_{n+1}-L|}{|a_{n}-L|} = μ \sqrt{3} a_{n} a_{n} \sqrt{3} a_{n} \to \sqrt{3} \lim\limits_{x \to \sqrt{3}} \frac{|\frac{1}{2}(x+\frac{3}{x})-\sqrt{3}|}{|x-\sqrt{3}|} \frac{0}{0} \lim\limits_{x \to \sqrt{3}} \frac{\frac{1}{2}(x+\frac{3}{x})-\sqrt{3}}{x-\sqrt{3}}=\frac{x^2-2\sqrt 3x+3}{2x(x-\sqrt{3})}=\frac{(x-\sqrt{3})^2}{2x(x-\sqrt{3})}=\frac{x-\sqrt{3}}{2x}\to 0 \sqrt 3,"['sequences-and-series', 'limits', 'convergence-divergence']"
77,$	\lim_{x \to 0}x \tan (xa+ \arctan \frac{b}{x})$,,	\lim_{x \to 0}x \tan (xa+ \arctan \frac{b}{x}),I have to evaluate the following limit $$	\lim_{x \to  0}x \tan (xa+ \arctan \frac{b}{x})$$ I tried to divide tan in $\frac{sin}{cos}$ or with Hopital but I can't understand where I'm making mistakes. The final result is: $\frac{b}{1-ab}$ if $ab \ne 1$ $- \infty$ if $ab=1$ and $a>0$ $+ \infty$ if $ab=1$ and $a<0$,I have to evaluate the following limit I tried to divide tan in or with Hopital but I can't understand where I'm making mistakes. The final result is: if if and if and,	\lim_{x \to  0}x \tan (xa+ \arctan \frac{b}{x}) \frac{sin}{cos} \frac{b}{1-ab} ab \ne 1 - \infty ab=1 a>0 + \infty ab=1 a<0,['limits']
78,Finding the limit: $\lim_{x\to \infty}\frac{1}{2}x\sin {\frac{180(x-2)}{x}}$,Finding the limit:,\lim_{x\to \infty}\frac{1}{2}x\sin {\frac{180(x-2)}{x}},"While investigating a problem, I came across a function: $$f(x) = \frac{1}{2}x\sin {\frac{180(x-2)}{x}}$$ When looking at the function in Desmos (I was checking my proof), I discovered that $$\lim_{x\to \infty}\frac{1}{2}x\sin {\frac{180(x-2)}{x}} = \pi$$ I double-checked Wolframalpha, and this limit is true. The only issue is that I can't seem to prove it by hand, and I'm really interested as to how $\pi$ pops out of nowhere. Please note I am working in degrees, so it is not 180 radians in the sin function. I would really appreciate it if someone could explain a solution.","While investigating a problem, I came across a function: When looking at the function in Desmos (I was checking my proof), I discovered that I double-checked Wolframalpha, and this limit is true. The only issue is that I can't seem to prove it by hand, and I'm really interested as to how pops out of nowhere. Please note I am working in degrees, so it is not 180 radians in the sin function. I would really appreciate it if someone could explain a solution.",f(x) = \frac{1}{2}x\sin {\frac{180(x-2)}{x}} \lim_{x\to \infty}\frac{1}{2}x\sin {\frac{180(x-2)}{x}} = \pi \pi,"['calculus', 'limits', 'limits-without-lhopital', 'pi']"
79,"Evaluating Multivariable Limit $\lim\limits_{(x,y) \to (0,2)} \frac{\sin(xy)}{x}$",Evaluating Multivariable Limit,"\lim\limits_{(x,y) \to (0,2)} \frac{\sin(xy)}{x}","Question : Evaluate the limit $$\lim\limits_{(x,y) \to (0,2)} \frac{\sin(xy)}{x}$$ My first thought is that the limit looks a lot like the single variable $\lim\limits_{x \to 0} \frac{\sin(x)}{x} = 1$ . Regardless of what $y$ is (as long as it is real) $xy \to 0$ . Hence I am wrongly concluding that the entire limit evaluates to $1$ . I guess the ratio of the convergence is not the same as in the single variable case, hence it may not be 1. However, I am unsure how to evaluate it properly.","Question : Evaluate the limit My first thought is that the limit looks a lot like the single variable . Regardless of what is (as long as it is real) . Hence I am wrongly concluding that the entire limit evaluates to . I guess the ratio of the convergence is not the same as in the single variable case, hence it may not be 1. However, I am unsure how to evaluate it properly.","\lim\limits_{(x,y) \to (0,2)} \frac{\sin(xy)}{x} \lim\limits_{x \to 0} \frac{\sin(x)}{x} = 1 y xy \to 0 1","['limits', 'multivariable-calculus']"
80,Calculating a limit with exponent and trig function,Calculating a limit with exponent and trig function,,"I got this limit to calculate: $$ \lim_{x\to\frac{\pi}{2}}(\tan x)^\frac{1}{x-\frac{\pi}{2}} $$ I'm trying to solve it with De L'Hopitals rule and the first step should be this, I guess: $$ \lim_{x\to\frac{\pi}{2}}e^\frac{\ln(\tan x)}{x-\frac{\pi}{2}} $$ Then I'm trying to solve the limit of the exponent: $$ \lim_{x\to\frac{\pi}{2}}\frac{\ln(\tan x)}{x - \frac{\pi}{2}} $$ In the last step I inversed the function in the denominator of the exponent. Next I do: $$ \lim_{x\to\frac{\pi}{2}}\frac{\frac{1}{\tan x}*\frac{1}{\cos^2x}}{1} = \lim_{x\to\frac{\pi}{2}}\frac{1}{\tan x\cos^2x}= \lim_{x\to\frac{\pi}{2}}=... $$ Skipping a few calculations, in the end I get $$ \lim_{x\to\frac{\pi}{2}}\frac{1}{2\cos x\sin^3x} $$ Which would mean the limit of the exponent = infinity, but the answer sheet says it's 2. I have a strong feeling I did something wrong in one of the first steps, however I'm unable to find out what exactly...","I got this limit to calculate: I'm trying to solve it with De L'Hopitals rule and the first step should be this, I guess: Then I'm trying to solve the limit of the exponent: In the last step I inversed the function in the denominator of the exponent. Next I do: Skipping a few calculations, in the end I get Which would mean the limit of the exponent = infinity, but the answer sheet says it's 2. I have a strong feeling I did something wrong in one of the first steps, however I'm unable to find out what exactly...","
\lim_{x\to\frac{\pi}{2}}(\tan x)^\frac{1}{x-\frac{\pi}{2}}
 
\lim_{x\to\frac{\pi}{2}}e^\frac{\ln(\tan x)}{x-\frac{\pi}{2}}
 
\lim_{x\to\frac{\pi}{2}}\frac{\ln(\tan x)}{x - \frac{\pi}{2}}
 
\lim_{x\to\frac{\pi}{2}}\frac{\frac{1}{\tan x}*\frac{1}{\cos^2x}}{1} = \lim_{x\to\frac{\pi}{2}}\frac{1}{\tan x\cos^2x}= \lim_{x\to\frac{\pi}{2}}=...
 
\lim_{x\to\frac{\pi}{2}}\frac{1}{2\cos x\sin^3x}
","['limits', 'derivatives']"
81,"Find the value of $\lim _{a \to \infty} \frac{1}{a} \int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} \cdot \tan ^{-1}\left(\frac{1}{x}\right) \,d x $",Find the value of,"\lim _{a \to \infty} \frac{1}{a} \int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} \cdot \tan ^{-1}\left(\frac{1}{x}\right) \,d x ","Find the value of : $$ \lim _{a \rightarrow \infty} \frac{1}{a} \int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} \cdot \tan ^{-1}\left(\frac{1}{x}\right) \,d x $$ I have tried to evaluate this integral by L'Hospitals rule, by separately diffrentiating the numerator and the denominator in the following steps: $$\int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} d x\cdot\dfrac{\pi}{2} (\text{by taking x=1/t and adding the integrands)} $$ I end up converting the above integral in the form $(\text{by Leibnitz's integral rule})$ $$ \dfrac{\pi}{2} \left(\int_{0}^{\infty} \frac{x}{1+x^{4}} d x\right) $$ please provide an approach to this problem after this step.","Find the value of : I have tried to evaluate this integral by L'Hospitals rule, by separately diffrentiating the numerator and the denominator in the following steps: I end up converting the above integral in the form please provide an approach to this problem after this step.","
\lim _{a \rightarrow \infty} \frac{1}{a} \int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} \cdot \tan ^{-1}\left(\frac{1}{x}\right) \,d x
 \int_{0}^{\infty} \frac{x^{2}+a x+1}{1+x^{4}} d x\cdot\dfrac{\pi}{2} (\text{by taking x=1/t and adding the integrands)}
 (\text{by Leibnitz's integral rule})  \dfrac{\pi}{2}
\left(\int_{0}^{\infty} \frac{x}{1+x^{4}} d x\right)
","['calculus', 'integration', 'limits', 'leibniz-integral-rule']"
82,Evaluating $\lim\limits_{n \to \infty}\frac{2^{2n}(n!)^2}{(2n+1)!}$,Evaluating,\lim\limits_{n \to \infty}\frac{2^{2n}(n!)^2}{(2n+1)!},"Can you help me find this limit: $$\lim_{n \rightarrow \infty} \dfrac{2^{2n}(n!)^2}{(2n+1)!}$$ I tried to use $$ \lim_{n \rightarrow \infty} \dfrac{2^{2n}(n!)^2}{(2n+1)!} = \ln\left(\exp\left( \lim_{n \rightarrow \infty} \dfrac{2^{2n}(n!)^2}{(2n+1)!} \right)\right)$$ but it didn't work out so well. This problem came up when I was trying to find the radius of convergence of the sum $$\sum_{n=0}^{\infty}(-1)^n\left[\dfrac{2^{n}(n!)^2}{(2n+1)!}\right]^p.x^n$$ Thanks! (Anyway I omitted the exponential $p$ in the limit because it just a constant). (*Edited. Is there any others way instead of using Stirling approximation(1) or the Center Binomial Coefficient(2)? I just stated learning Analysis and this limit is only a part of the finding the radius of convergence problems,though. It take way too long and hard to prove (1) and (2)). Sorry for not  ask clearly the first time.","Can you help me find this limit: I tried to use but it didn't work out so well. This problem came up when I was trying to find the radius of convergence of the sum Thanks! (Anyway I omitted the exponential in the limit because it just a constant). (*Edited. Is there any others way instead of using Stirling approximation(1) or the Center Binomial Coefficient(2)? I just stated learning Analysis and this limit is only a part of the finding the radius of convergence problems,though. It take way too long and hard to prove (1) and (2)). Sorry for not  ask clearly the first time.",\lim_{n \rightarrow \infty} \dfrac{2^{2n}(n!)^2}{(2n+1)!}  \lim_{n \rightarrow \infty} \dfrac{2^{2n}(n!)^2}{(2n+1)!} = \ln\left(\exp\left( \lim_{n \rightarrow \infty} \dfrac{2^{2n}(n!)^2}{(2n+1)!} \right)\right) \sum_{n=0}^{\infty}(-1)^n\left[\dfrac{2^{n}(n!)^2}{(2n+1)!}\right]^p.x^n p,"['real-analysis', 'sequences-and-series', 'limits']"
83,"Book: Ron Larson, Calculus, Find the Limit if it exists?","Book: Ron Larson, Calculus, Find the Limit if it exists?",,"I answered a question to determine whether a particular limit of a function exists and I got the right answer that it didn’t exist but for a different reason to what the book states. Question. Find the limit (if it exists) and if it does not exist explain why. $$\lim_{x\to-3^-}\left(\frac{x}{\sqrt{x^2-9}}\right)$$ My answer. The domain is restricted to the closed interval $[-3 , 3]$ . The limit does not exist because the function is only continuous on the right-hand side of $x=3$ . Books Solution. The limit does not exist. The function decreases without bound as $x$ approaches $-3$ from the left. Can someone please explain if my solution would suffice and also what the book means by this, since I thought that the function was undefinded for values of $x<-3$ ?","I answered a question to determine whether a particular limit of a function exists and I got the right answer that it didn’t exist but for a different reason to what the book states. Question. Find the limit (if it exists) and if it does not exist explain why. My answer. The domain is restricted to the closed interval . The limit does not exist because the function is only continuous on the right-hand side of . Books Solution. The limit does not exist. The function decreases without bound as approaches from the left. Can someone please explain if my solution would suffice and also what the book means by this, since I thought that the function was undefinded for values of ?","\lim_{x\to-3^-}\left(\frac{x}{\sqrt{x^2-9}}\right) [-3 , 3] x=3 x -3 x<-3",['calculus']
84,Find the values of $a$ and $b$ if $\lim_{x\to -\infty}$ $\sqrt{x^2-x+1} + ax - b = 0$?,Find the values of  and  if  ?,a b \lim_{x\to -\infty} \sqrt{x^2-x+1} + ax - b = 0,"I took out x from the square root and reached the following expression, $$\lim_{x\to -\infty} x\sqrt{1-\frac{1}{x}+\frac{1}{x^2}} + ax - b = 0$$ then I separated the part of the expression which contains x from b and tried evaluating its limit, giving me the following expression, $$\lim_{x\to -\infty} \frac{\sqrt{1-\frac{1}{x}+\frac{1}{x^2}}+a}{\frac{1}{x}} $$ Now, the problem is that I am unable to proceed from here. What I have read and learnt till now tells me that since the denominator of this expression tends to 0 the numerator must also tend to 0 for the limit to exist as a finite number, but I don't understand why only 0? Can't it be something else? Can someone please explain me the approach to solving such questions and the reason behind why it works? And it would be great if you could tell me the values of a and b in this case. Note : Assuming that the numerator must also tend to 0 for the limit to be finite, and then applying L'Hopital's rule I got the values of a and b as -1 and -1/2 respectively. The only thing is that I don't have the answer of this question with me, so it would be great if you could tell me what I am getting is right or wrong.","I took out x from the square root and reached the following expression, then I separated the part of the expression which contains x from b and tried evaluating its limit, giving me the following expression, Now, the problem is that I am unable to proceed from here. What I have read and learnt till now tells me that since the denominator of this expression tends to 0 the numerator must also tend to 0 for the limit to exist as a finite number, but I don't understand why only 0? Can't it be something else? Can someone please explain me the approach to solving such questions and the reason behind why it works? And it would be great if you could tell me the values of a and b in this case. Note : Assuming that the numerator must also tend to 0 for the limit to be finite, and then applying L'Hopital's rule I got the values of a and b as -1 and -1/2 respectively. The only thing is that I don't have the answer of this question with me, so it would be great if you could tell me what I am getting is right or wrong.",\lim_{x\to -\infty} x\sqrt{1-\frac{1}{x}+\frac{1}{x^2}} + ax - b = 0 \lim_{x\to -\infty} \frac{\sqrt{1-\frac{1}{x}+\frac{1}{x^2}}+a}{\frac{1}{x}} ,"['calculus', 'limits', 'indeterminate-forms']"
85,Evaluating $\lim\limits_{n \to \infty} \sqrt[n]{\frac{n!}{\sum\limits_{m=1}^n m^m}}$,Evaluating,\lim\limits_{n \to \infty} \sqrt[n]{\frac{n!}{\sum\limits_{m=1}^n m^m}},"Evaluate: $$\lim_{n \to \infty} \sqrt[n]{\frac{n!}{\sum_{m=1}^n m^m}}$$ In case it's hard to read, that is the n-th root.  I don't know how to evaluate this limit or know what the first step is...  I believe that: $$\sum_{m=1}^n m^m$$ doesn't have a closed form so I suppose there must be some identity or theorem that must be applied to this limit.  According to the answer key, the limit evaluates to $\frac{1}{e}$ .","Evaluate: In case it's hard to read, that is the n-th root.  I don't know how to evaluate this limit or know what the first step is...  I believe that: doesn't have a closed form so I suppose there must be some identity or theorem that must be applied to this limit.  According to the answer key, the limit evaluates to .",\lim_{n \to \infty} \sqrt[n]{\frac{n!}{\sum_{m=1}^n m^m}} \sum_{m=1}^n m^m \frac{1}{e},"['real-analysis', 'calculus', 'sequences-and-series', 'limits', 'summation']"
86,Finding $\lim_{n\to\infty} \left(\frac{\sqrt{n^2+n}-1}{n}\right)^{2\sqrt{n^2+n}-1}$,Finding,\lim_{n\to\infty} \left(\frac{\sqrt{n^2+n}-1}{n}\right)^{2\sqrt{n^2+n}-1},"Find the following limit without using the L'Hopital rule: $$\lim_{n\to\infty} \left(\dfrac{\sqrt{n^2+n}-1}{n}\right)^{2\sqrt{n^2+n}-1}$$ Answer: $e^{-1}$ My attempt: Since the limit is of the form $1^{\infty}$ , I decided to use the standard formula: $$\lim_{x\to a} f^g = e^{\lim_\limits{x\to a}(f-1)g}$$ (See link ) Let $l=(f-1)g$ . We have, $$l=\left(\dfrac{\sqrt{n^2+n}-(1+n)}{n}\right)(2\sqrt{n^2+n}-1)$$ This on solving boils down to $$l=2n+3-\sqrt{1+\frac 1n}(2n+3)+\frac 1n$$ Now if I tend $n$ towards infinity, then $l\to 0$ and the limit i.e. $e^l$ , is equal to $1$ , which contradicts the given answer. Please help. Thanks! Edit:  A proof for the ""standard formula"" I have used. Edit 2: just noticed a typo in the power which I have now fixed.","Find the following limit without using the L'Hopital rule: Answer: My attempt: Since the limit is of the form , I decided to use the standard formula: (See link ) Let . We have, This on solving boils down to Now if I tend towards infinity, then and the limit i.e. , is equal to , which contradicts the given answer. Please help. Thanks! Edit:  A proof for the ""standard formula"" I have used. Edit 2: just noticed a typo in the power which I have now fixed.",\lim_{n\to\infty} \left(\dfrac{\sqrt{n^2+n}-1}{n}\right)^{2\sqrt{n^2+n}-1} e^{-1} 1^{\infty} \lim_{x\to a} f^g = e^{\lim_\limits{x\to a}(f-1)g} l=(f-1)g l=\left(\dfrac{\sqrt{n^2+n}-(1+n)}{n}\right)(2\sqrt{n^2+n}-1) l=2n+3-\sqrt{1+\frac 1n}(2n+3)+\frac 1n n l\to 0 e^l 1,"['calculus', 'limits', 'limits-without-lhopital']"
87,determine whether or not infinite series $ \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{\left(-1\right)^{n}+n} $ converge,determine whether or not infinite series  converge, \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{\left(-1\right)^{n}+n} ,"I want to determine if the series $ \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{\left(-1\right)^{n}+n} $ converge/diverge. the sequence in the denominator is not monotinic, so I cant use Dirichlet's or Abel's tests. My intuition is that this series converge, becuase its looks close to $ \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{n} $ but im not sure how to prove. Any ideas will help, thanks.","I want to determine if the series converge/diverge. the sequence in the denominator is not monotinic, so I cant use Dirichlet's or Abel's tests. My intuition is that this series converge, becuase its looks close to but im not sure how to prove. Any ideas will help, thanks.", \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{\left(-1\right)^{n}+n}   \sum_{n=2}^{\infty}\frac{\left(-1\right)^{n}}{n} ,"['calculus', 'sequences-and-series', 'limits']"
88,how to structure an example of a sequence,how to structure an example of a sequence,,I need to find an example of a sequence that on the one hand is divergent and on the other hand has two subsequences that $$\lim_{n\to \infty} \mathit{a}_{3n} = \lim_{n\to \infty} \mathit{a}_{5n}.$$ Thanks a lot.,I need to find an example of a sequence that on the one hand is divergent and on the other hand has two subsequences that Thanks a lot.,\lim_{n\to \infty} \mathit{a}_{3n} = \lim_{n\to \infty} \mathit{a}_{5n}.,"['calculus', 'sequences-and-series', 'limits']"
89,Limit of $\frac{n + (-1)^n n}{n+2}$,Limit of,\frac{n + (-1)^n n}{n+2},"I'm taking a university real analysis course and I was tasked with demonstarting a proof on regaurding the limit (or lack there of) of $\frac{n + (-1)^n n}{n+2}$ . Here's my attempt at a proof that no limit exists. First use algerbra of limits to seperate $\frac{n + (-1)^n n}{n+2}$ $\implies$ $\frac{1}{1+\frac{2}{n}} + \frac{(-1)^n}{1 + \frac{2}{n}}$ Limit of $\frac{1}{1+\frac{2}{n}}$ as $n \rightarrow \infty$ is simply 1. Using the squeeze prinicible. Assuming $\frac{(-1)^n}{1 + \frac{2}{n}}$ does have a limit $y$ then sequences $x_n,y_n,z_n$ such that $x_n \leq y_n \leq z_n$ all sequences must converge on $y$ . Take... $x_n = \frac{-1}{1+\frac{2}{n}}$ $ y_n = \frac{(-1)^n}{1 + \frac{2}{n}}$ $z_n = \frac{1}{1+\frac{2}{n}}$ There is no possible $x_n$ or $z_n$ that converge to similar limits and obeys $x_n \leq y_n \leq z_n$ . Therefore there is no limit $y$ . Since $x_n = \frac{(-1)^n}{1+\frac{2}{n}}$ has no limit, by the algebra of limits neither does $\frac{n + (-1)^n n}{n+2}$ . Any feedback would be much appreciated!","I'm taking a university real analysis course and I was tasked with demonstarting a proof on regaurding the limit (or lack there of) of . Here's my attempt at a proof that no limit exists. First use algerbra of limits to seperate Limit of as is simply 1. Using the squeeze prinicible. Assuming does have a limit then sequences such that all sequences must converge on . Take... There is no possible or that converge to similar limits and obeys . Therefore there is no limit . Since has no limit, by the algebra of limits neither does . Any feedback would be much appreciated!","\frac{n + (-1)^n n}{n+2} \frac{n + (-1)^n n}{n+2} \implies \frac{1}{1+\frac{2}{n}} + \frac{(-1)^n}{1 + \frac{2}{n}} \frac{1}{1+\frac{2}{n}} n \rightarrow \infty \frac{(-1)^n}{1 + \frac{2}{n}} y x_n,y_n,z_n x_n \leq y_n \leq z_n y x_n = \frac{-1}{1+\frac{2}{n}}  y_n = \frac{(-1)^n}{1 + \frac{2}{n}} z_n = \frac{1}{1+\frac{2}{n}} x_n z_n x_n \leq y_n \leq z_n y x_n = \frac{(-1)^n}{1+\frac{2}{n}} \frac{n + (-1)^n n}{n+2}","['real-analysis', 'sequences-and-series', 'limits', 'solution-verification']"
90,Evaluating $\lim_{x\to 0}\frac{x\sin x-2+2\cos x}{x\ln(1+x)-x^2}$ using L'Hôpital,Evaluating  using L'Hôpital,\lim_{x\to 0}\frac{x\sin x-2+2\cos x}{x\ln(1+x)-x^2},"Considering this limit, assigned to my high school students, $$\lim_{x\to 0}\frac{x\sin x-2+2\cos x}{x\ln \left(1+x\right)-x^2}=\left(\frac00\right)=\lim_{x\to 0}\frac{\frac{d}{dx}\left(x\sin \left(x\right)-2+2\cos \left(x\right)\right)}{\frac{d}{dx}\left(x\ln \left(1+x\right)-x^2\right)} \tag 1$$ After some steps, using L'Hôpital, I find: $$\lim_{x\to 0}\frac{\left(x\cos \left(x\right)-\sin \left(x\right)\right)\left(1+x\right)}{-2x^2-x+x\ln \left(x+1\right)+\ln \left(x+1\right)}=\left(\frac00\right)$$ Should I continue to apply L'Hôpital? :-(","Considering this limit, assigned to my high school students, After some steps, using L'Hôpital, I find: Should I continue to apply L'Hôpital? :-(",\lim_{x\to 0}\frac{x\sin x-2+2\cos x}{x\ln \left(1+x\right)-x^2}=\left(\frac00\right)=\lim_{x\to 0}\frac{\frac{d}{dx}\left(x\sin \left(x\right)-2+2\cos \left(x\right)\right)}{\frac{d}{dx}\left(x\ln \left(1+x\right)-x^2\right)} \tag 1 \lim_{x\to 0}\frac{\left(x\cos \left(x\right)-\sin \left(x\right)\right)\left(1+x\right)}{-2x^2-x+x\ln \left(x+1\right)+\ln \left(x+1\right)}=\left(\frac00\right),"['limits', 'limits-without-lhopital']"
91,$\displaystyle \sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)=2$,,\displaystyle \sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)=2,"How to prove that $$\sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)=2$$ I know that $\displaystyle  \sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)\leq 2$ . I also know that the supremum is not reached on some number $t_0$ , otherwise we would have $\sqrt 2 \in \mathbb{Q}$ .","How to prove that I know that . I also know that the supremum is not reached on some number , otherwise we would have .",\sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)=2 \displaystyle  \sup_{t\in \mathbb{R}}\left(\sin(\sqrt 2 \ t)+\sin(t)\right)\leq 2 t_0 \sqrt 2 \in \mathbb{Q},"['real-analysis', 'number-theory', 'limits', 'supremum-and-infimum']"
92,Limits with $a_n+\log a_n = 1+\frac{1}{n}$,Limits with,a_n+\log a_n = 1+\frac{1}{n},"If $a_n+\log a_n = 1+\dfrac{1}{n}$ , compute: $\lim_\limits{n\to \infty}a_n$ $\lim_\limits{n\to \infty} n(a_n-1)$ If $a_n$ is convergent to $l$ , then passing to limit $l+\log l = 1$ . But $f(x)=x+\log x$ is increasing, so unique solution is $l = 1$ . But I don't know how to prove $a_n$ is bounded and monotonic.","If , compute: If is convergent to , then passing to limit . But is increasing, so unique solution is . But I don't know how to prove is bounded and monotonic.",a_n+\log a_n = 1+\dfrac{1}{n} \lim_\limits{n\to \infty}a_n \lim_\limits{n\to \infty} n(a_n-1) a_n l l+\log l = 1 f(x)=x+\log x l = 1 a_n,[]
93,Evaluating the limit $ \lim_{x \to 0} \frac{x}{p} \lfloor \frac{q}{x} \rfloor$ [duplicate],Evaluating the limit  [duplicate], \lim_{x \to 0} \frac{x}{p} \lfloor \frac{q}{x} \rfloor,This question already has answers here : what is the limit of $\displaystyle \lim_{x\to 0} \frac{x}{a}\cdot \lfloor{\frac{b}{x}\rfloor}$ (2 answers) Closed 4 years ago . $$\lim_{x \to 0} \frac{x}{p} \left\lfloor \frac{q}{x} \right\rfloor =\;\;\; ?$$ My attempt: $\frac{q}{x}-1 < \lfloor \frac{q}{x} \rfloor \le \frac {q}{x} $ . Then I consider four cases. In case 1 I took x and p both positive and then I multiplied above by $\frac{x}{p} $ and took limit and applied squeeze theorem. In other cases I did the same. My answer is $ \frac{q}{p} $ . Is the solution correct?,This question already has answers here : what is the limit of $\displaystyle \lim_{x\to 0} \frac{x}{a}\cdot \lfloor{\frac{b}{x}\rfloor}$ (2 answers) Closed 4 years ago . My attempt: . Then I consider four cases. In case 1 I took x and p both positive and then I multiplied above by and took limit and applied squeeze theorem. In other cases I did the same. My answer is . Is the solution correct?,\lim_{x \to 0} \frac{x}{p} \left\lfloor \frac{q}{x} \right\rfloor =\;\;\; ? \frac{q}{x}-1 < \lfloor \frac{q}{x} \rfloor \le \frac {q}{x}  \frac{x}{p}   \frac{q}{p} ,"['real-analysis', 'calculus', 'limits', 'analysis', 'solution-verification']"
94,Discontinuity of a derivative,Discontinuity of a derivative,,"We know that if $f'(x)$ is discontinuous at $x_{0}$ , then $x_{0}$ is a fundamental essential discontinuity of $f'(x)$ (because derivatives can't have removable discontinuity or a jump discontinuity). So why derivative of absolute value has jump discontinuity in $x=0$ ?","We know that if is discontinuous at , then is a fundamental essential discontinuity of (because derivatives can't have removable discontinuity or a jump discontinuity). So why derivative of absolute value has jump discontinuity in ?",f'(x) x_{0} x_{0} f'(x) x=0,"['limits', 'derivatives', 'absolute-value', 'continuity']"
95,"Prove that limit $a_n^{b_n} = 0$ when $\lim_{n\to\infty} a_n = 0$, $\lim_{n\to\infty} b_n = \infty$","Prove that limit  when ,",a_n^{b_n} = 0 \lim_{n\to\infty} a_n = 0 \lim_{n\to\infty} b_n = \infty,"As $n$ goes to infinity: $\lim_{n\to\infty} a_n = 0$ , $\lim_{n\to\infty}b_n = \infty$ I need to prove that $\lim_{n\to\infty}a_n^{b_n} = 0$ . Is it enough to say that from a curtain point $|a_n| < 1$ and thus $lim_{a_n^{b_n}} = 0$ because $b_n$ is greater than $1$ from a curtain point?","As goes to infinity: , I need to prove that . Is it enough to say that from a curtain point and thus because is greater than from a curtain point?",n \lim_{n\to\infty} a_n = 0 \lim_{n\to\infty}b_n = \infty \lim_{n\to\infty}a_n^{b_n} = 0 |a_n| < 1 lim_{a_n^{b_n}} = 0 b_n 1,['limits']
96,Solve without L'Hopital's rule: $\lim_{x\to0}\frac{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\tan(2x)}$,Solve without L'Hopital's rule:,\lim_{x\to0}\frac{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\tan(2x)},"Solve without L'Hopital's rule: $$\displaystyle\lim_{x\to0}{\frac{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\tan(2x)}}$$ My work: $\displaystyle\lim_{x\to0}{\frac{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\tan(2x)}}=\displaystyle\lim_{x\to0}{\frac{\cos{(2x)}\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\sin{(2x)}}}$ $\displaystyle\lim_{x\to0}{\frac{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\sin{2x}}}=\displaystyle\lim_{x\to0}{\frac{\cosh(3x^2)\cdot e^{8x^3}-1}{x^2\sin{(2x)}}}\cdot\displaystyle\lim_{x\to0}{\frac{1}{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}+1}}$ All of my attempts failed. $$\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}+1\;\;\text{is continuous &decreasing }$$ Source: Matematička analiza 1, 2. kolokvij","Solve without L'Hopital's rule: My work: All of my attempts failed. Source: Matematička analiza 1, 2. kolokvij",\displaystyle\lim_{x\to0}{\frac{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\tan(2x)}} \displaystyle\lim_{x\to0}{\frac{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\tan(2x)}}=\displaystyle\lim_{x\to0}{\frac{\cos{(2x)}\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\sin{(2x)}}} \displaystyle\lim_{x\to0}{\frac{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}-1}{x^2\sin{2x}}}=\displaystyle\lim_{x\to0}{\frac{\cosh(3x^2)\cdot e^{8x^3}-1}{x^2\sin{(2x)}}}\cdot\displaystyle\lim_{x\to0}{\frac{1}{\sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}+1}} \sqrt{\cosh{(3x^2)}}\cdot e^{4x^3}+1\;\;\text{is continuous &decreasing },"['real-analysis', 'calculus', 'limits', 'limits-without-lhopital']"
97,"Show function is continuous at $(0,0)$",Show function is continuous at,"(0,0)","Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ be a function with $$\space f(x, y) = \begin{equation} \begin{cases} \dfrac{y^2\log(1+x^2y^2)}{\sqrt{x^4+y^4}}, & (x, y) \neq (0, 0)\\ 0, & (x, y) = 0  \end{cases}\end{equation}$$ Show that f is continious. I've already shown that f is continous for $(x, y) \neq (0,0)$ but I am having trouble with finding a proof for $(0, 0)$ using epsilon-delta or limits of sequences. Can anyone help?  This is how far I got with simplifying for epsilon delta $$ \Bigg{|}\frac{y^2\log(1+x^2y^2)}{\sqrt{x^4+y^4}}\Bigg{|} \\  \Leftrightarrow \Bigg{|}\frac{y^2\log(1+x^2y^2)}{\sqrt{y^4*(\frac{x^4}{y^4}+1)}}\Bigg{|} \\ \Leftrightarrow \Bigg{|}\frac{y^2\log(1+x^2y^2)}{y^2\sqrt{(\frac{x^4}{y^4}+1)}}\Bigg{|} \\ \Leftrightarrow \Bigg{|}\frac{\log(1+x^2y^2)}{\sqrt{(\frac{x^4}{y^4}+1)}}\Bigg{|} \\ \leq \big{|}\log(1+x^2y^2)\big{|} $$ But now I am clueless on how to connect $$ \big{|}log(1+x^2y^2)\big{|} < \epsilon \\ $$ and $$ \sqrt{x^2+y^2} < \delta $$",Let be a function with Show that f is continious. I've already shown that f is continous for but I am having trouble with finding a proof for using epsilon-delta or limits of sequences. Can anyone help?  This is how far I got with simplifying for epsilon delta But now I am clueless on how to connect and,"f: \mathbb{R}^2 \rightarrow \mathbb{R} \space f(x, y) = \begin{equation}
\begin{cases}
\dfrac{y^2\log(1+x^2y^2)}{\sqrt{x^4+y^4}}, & (x, y) \neq (0, 0)\\
0, & (x, y) = 0 
\end{cases}\end{equation} (x, y) \neq (0,0) (0, 0) 
\Bigg{|}\frac{y^2\log(1+x^2y^2)}{\sqrt{x^4+y^4}}\Bigg{|} \\ 
\Leftrightarrow \Bigg{|}\frac{y^2\log(1+x^2y^2)}{\sqrt{y^4*(\frac{x^4}{y^4}+1)}}\Bigg{|} \\
\Leftrightarrow \Bigg{|}\frac{y^2\log(1+x^2y^2)}{y^2\sqrt{(\frac{x^4}{y^4}+1)}}\Bigg{|} \\
\Leftrightarrow \Bigg{|}\frac{\log(1+x^2y^2)}{\sqrt{(\frac{x^4}{y^4}+1)}}\Bigg{|} \\
\leq \big{|}\log(1+x^2y^2)\big{|}
 
\big{|}log(1+x^2y^2)\big{|} < \epsilon \\
 
\sqrt{x^2+y^2} < \delta
","['real-analysis', 'limits', 'multivariable-calculus']"
98,prove derivative of dot product of A(u) and B(u) with respect to u.,prove derivative of dot product of A(u) and B(u) with respect to u.,,"Suppose $\vec{A}$ and $\vec{B}$ are differentiable  functions of a scalar u. Prove: $\Large \frac{d}{du}(\vec{A} \cdot \vec{B}) = \vec{A} \cdot \frac{d\vec{B}}{du} + \frac{d\vec{A}}{du} \cdot \vec{B}$ ok so i start with definition of derivative: $\Large \frac{df(x)}{dx} = \lim \limits_{\Delta x \to \infty} \frac{f(x+\Delta x) - f(x)}{\Delta x}$ and apply it to the dot product of $\vec{A}$ and $\vec{B}$ : $\Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{(\vec{A}+\Delta\vec{A}) \cdot (\vec{B}+\Delta\vec{B}) -\vec{A}\cdot\vec{B}}{\Delta u}$ appying ""foil"" method to expand dot produt in numerator: $\Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{\vec{A}\cdot\Delta B ~+~ \Delta \vec{A} \cdot \vec{B} ~+~ \Delta A \cdot \Delta B}{\Delta u}$ $\Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{\vec{A}\cdot\Delta B}{\Delta u} + \lim \limits_{\Delta u \to \infty} \frac{\Delta \vec{A} \cdot \vec{B}}{\Delta u} + \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u}$ $\Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \vec{A} \cdot \frac{d\vec{B}}{du} + \frac{d\vec{A}}{du} \cdot \vec{B}  + \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u}$ now for the part that I don't understand..why does this piece goto zero: $\Large \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u} = 0?$","Suppose and are differentiable  functions of a scalar u. Prove: ok so i start with definition of derivative: and apply it to the dot product of and : appying ""foil"" method to expand dot produt in numerator: now for the part that I don't understand..why does this piece goto zero:",\vec{A} \vec{B} \Large \frac{d}{du}(\vec{A} \cdot \vec{B}) = \vec{A} \cdot \frac{d\vec{B}}{du} + \frac{d\vec{A}}{du} \cdot \vec{B} \Large \frac{df(x)}{dx} = \lim \limits_{\Delta x \to \infty} \frac{f(x+\Delta x) - f(x)}{\Delta x} \vec{A} \vec{B} \Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{(\vec{A}+\Delta\vec{A}) \cdot (\vec{B}+\Delta\vec{B}) -\vec{A}\cdot\vec{B}}{\Delta u} \Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{\vec{A}\cdot\Delta B ~+~ \Delta \vec{A} \cdot \vec{B} ~+~ \Delta A \cdot \Delta B}{\Delta u} \Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \lim \limits_{\Delta u \to \infty} \frac{\vec{A}\cdot\Delta B}{\Delta u} + \lim \limits_{\Delta u \to \infty} \frac{\Delta \vec{A} \cdot \vec{B}}{\Delta u} + \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u} \Large \frac{d}{du} (\vec{A} \cdot \vec{B}) = \vec{A} \cdot \frac{d\vec{B}}{du} + \frac{d\vec{A}}{du} \cdot \vec{B}  + \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u} \Large \lim \limits_{\Delta u \to \infty} \frac{\Delta A \cdot \Delta B}{\Delta u} = 0?,"['calculus', 'limits', 'vector-analysis']"
99,Limit of the series $\lim_{n \to \infty} \frac{1}{n^2} \sum_{k=1}^{n-1} \csc\left(\frac{k\pi}{n}\right)$.,Limit of the series .,\lim_{n \to \infty} \frac{1}{n^2} \sum_{k=1}^{n-1} \csc\left(\frac{k\pi}{n}\right),Does the following limit exist? $$\lim_{n \to \infty} \frac{1}{n^2} \sum_{k=1}^{n-1} \csc\left(\frac{k\pi}{n}\right)$$ I've computed the value for a few $n$ and it seems that the limit is zero. Any idea on how to prove this rigorously? The problem arises from electrostatics when computing the forces on point charges arranged in a ring.,Does the following limit exist? I've computed the value for a few and it seems that the limit is zero. Any idea on how to prove this rigorously? The problem arises from electrostatics when computing the forces on point charges arranged in a ring.,\lim_{n \to \infty} \frac{1}{n^2} \sum_{k=1}^{n-1} \csc\left(\frac{k\pi}{n}\right) n,"['real-analysis', 'calculus', 'sequences-and-series', 'limits']"
