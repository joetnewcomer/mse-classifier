,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Probability that a string has a rotation that is ""similar"" to a target string","Probability that a string has a rotation that is ""similar"" to a target string",,"I came up with the following problem: Suppose that you have a string s1 of length N with an alphabet with 4 letters. That is, each character in a string has only 4 possible choices. A string s2 is considered similar to s1 if there exists a rotation of s2 such that the hamming distance between the rotation of s2 and s1 is 3 or less. A rotation is defined as a cyclic shuffling of words. For example, rotations of ABCD are BCDA. CDAB, DABC, ABCD. Note that ABCD isa considered a rotation of itself. What's the probability that a random string s2 is similar to s1? My initial thought process was to enumerate the number of strings that had valid rotations as so: for each allowed number of differences $i \in$ [0 to 3], you can choose $i$ characters to be different in a string of size $N$ . Each of those characters has 3 different possible characters that they can take on, since they are differing from s1. Each of those strings has $N$ valid rotations, so we multiply each by $N$ . There are 4^N possible strings of length $N$ . This yields: $$\frac{N\sum_{i=0}^{3} \binom{N}{i} 3^i}{4^N} $$ However, it's clear to see that this over-counts by quite a bit. Removing the $N$ from the numerator gives much better results but doesn't match up to what I see experimentally. Does anybody have any hints as to what I'm doing wrong? I also attached my brute-force tester: import random from math import comb  def similarDNA(reference, candidates):     N = len(reference)      reference += reference      num_similar = 0      for candidate in candidates:         if len(candidate) != N:             continue         for i in range(N):             num_diffs = 0             for j in range(N):                 if reference[i+j] != candidate[j]:                     num_diffs += 1                 if num_diffs > 3:                     break             if num_diffs <= 3:                 num_similar += 1                 break      return num_similar  def random_string(N = 1000):     return ''.join(random.choices(""ATGC"", k = N))  def calc_probability(N):     denom = 4**N     numer = 0     for i in range(4):         numer += comb(N, i) * 3**i     return numer / denom  num_candidates = 100000 num_trials = 1000  for num_digits in range(1, 20):     num_similar = 0     candidates = set([random_string(num_digits) for i in range(num_candidates)])     for _ in range(num_trials):         reference = random_string(num_digits)         num_similar += similarDNA(reference, candidates)      print(num_digits, num_similar/(num_trials*len(candidates)), calc_probability(num_digits))","I came up with the following problem: Suppose that you have a string s1 of length N with an alphabet with 4 letters. That is, each character in a string has only 4 possible choices. A string s2 is considered similar to s1 if there exists a rotation of s2 such that the hamming distance between the rotation of s2 and s1 is 3 or less. A rotation is defined as a cyclic shuffling of words. For example, rotations of ABCD are BCDA. CDAB, DABC, ABCD. Note that ABCD isa considered a rotation of itself. What's the probability that a random string s2 is similar to s1? My initial thought process was to enumerate the number of strings that had valid rotations as so: for each allowed number of differences [0 to 3], you can choose characters to be different in a string of size . Each of those characters has 3 different possible characters that they can take on, since they are differing from s1. Each of those strings has valid rotations, so we multiply each by . There are 4^N possible strings of length . This yields: However, it's clear to see that this over-counts by quite a bit. Removing the from the numerator gives much better results but doesn't match up to what I see experimentally. Does anybody have any hints as to what I'm doing wrong? I also attached my brute-force tester: import random from math import comb  def similarDNA(reference, candidates):     N = len(reference)      reference += reference      num_similar = 0      for candidate in candidates:         if len(candidate) != N:             continue         for i in range(N):             num_diffs = 0             for j in range(N):                 if reference[i+j] != candidate[j]:                     num_diffs += 1                 if num_diffs > 3:                     break             if num_diffs <= 3:                 num_similar += 1                 break      return num_similar  def random_string(N = 1000):     return ''.join(random.choices(""ATGC"", k = N))  def calc_probability(N):     denom = 4**N     numer = 0     for i in range(4):         numer += comb(N, i) * 3**i     return numer / denom  num_candidates = 100000 num_trials = 1000  for num_digits in range(1, 20):     num_similar = 0     candidates = set([random_string(num_digits) for i in range(num_candidates)])     for _ in range(num_trials):         reference = random_string(num_digits)         num_similar += similarDNA(reference, candidates)      print(num_digits, num_similar/(num_trials*len(candidates)), calc_probability(num_digits))",i \in i N N N N \frac{N\sum_{i=0}^{3} \binom{N}{i} 3^i}{4^N}  N,"['probability', 'combinatorics', 'permutations']"
1,Composite of uniform distributions,Composite of uniform distributions,,"If $X_1$ is uniform $(0,1)$ and $X_2$ is uniform $(0, X_1+1)$ , what is $X_3$ , which is characterized as uniform $(0, X_2+1)$ ? I simulated $X_3$ and got the following graph but found it hard to compute the precise distribution:","If is uniform and is uniform , what is , which is characterized as uniform ? I simulated and got the following graph but found it hard to compute the precise distribution:","X_1 (0,1) X_2 (0, X_1+1) X_3 (0, X_2+1) X_3","['probability', 'probability-distributions', 'uniform-distribution']"
2,Statistics for the number of empty vessels for large systems,Statistics for the number of empty vessels for large systems,,"Consider randomly (iid) dropping $b$ balls into $n$ vessels. I am interested in the statistics of $e$ , the number of empty vessels. I've seen elsewhere on stackexchange that this can be written down in terms of Stirling numbers of the second kind, but I don't have a good sense of how to extract useful information from those expressions. I'm most interested in the following information: Can we find the probability distribution for $e$ in the large- $n$ limit, at least in some regimes for $k$ ? Can we say that the empty fraction $e/n$ is a function of the average number of balls per vessel $b/n$ in this limit? Can we find the mean and variance of $e$ , again in the large-system limit? I've tried a few things already. I started off by simply calculating the odds that no balls fell within $e$ specific vessels and then the odds that none fell within $e+1$ specific vessels. But of course it's wrong to say that the difference between these two numbers is proportional to the probability of exactly $e$ empty vessels. Next, I tried to write down a recursion relationship, in which $P(e,b+1)$ , the probability of $e$ empties given $b+1$ balls is (Edited to fix error) $$P(e,b+1) = P(e,b)(1-e/n) + P(e+1,b)((e+1)/n).$$ That one still seems to me to be correct, and I wanted to rewrite it in terms of $b/n$ and $e/n$ and then do a Taylor expansion. That gives me a PDE, but when I try to solve it I get nonsensical answers.","Consider randomly (iid) dropping balls into vessels. I am interested in the statistics of , the number of empty vessels. I've seen elsewhere on stackexchange that this can be written down in terms of Stirling numbers of the second kind, but I don't have a good sense of how to extract useful information from those expressions. I'm most interested in the following information: Can we find the probability distribution for in the large- limit, at least in some regimes for ? Can we say that the empty fraction is a function of the average number of balls per vessel in this limit? Can we find the mean and variance of , again in the large-system limit? I've tried a few things already. I started off by simply calculating the odds that no balls fell within specific vessels and then the odds that none fell within specific vessels. But of course it's wrong to say that the difference between these two numbers is proportional to the probability of exactly empty vessels. Next, I tried to write down a recursion relationship, in which , the probability of empties given balls is (Edited to fix error) That one still seems to me to be correct, and I wanted to rewrite it in terms of and and then do a Taylor expansion. That gives me a PDE, but when I try to solve it I get nonsensical answers.","b n e e n k e/n b/n e e e+1 e P(e,b+1) e b+1 P(e,b+1) = P(e,b)(1-e/n) + P(e+1,b)((e+1)/n). b/n e/n","['probability', 'combinatorics', 'variance']"
3,Gambler's Ruin with unfair coin,Gambler's Ruin with unfair coin,,"I was solving this famous problem which reads: You start with N Dollars. Each turn, you toss a coin for each dollar you have and you double it if you win, otherwise, you lose it. You go on like this. What is the probability of losing all of your money? You solve the problem in the following way: You notice that, $$P(\text{Ruin having N dollars}) = (P(\text{ruin having 1 dollar}))^N$$ calling $ e:= P(\text{ruin having 1 dollar}) $ you set the recursive expression $$ e = p_l + p_w e^2  $$ in which $p_l$ is the probability of losing and $p_w$ is the probability of winning (so that, you have now two coins and you have to lose both of them). Setting $p_l = p_w = 1/2$ one has $e = 1$ , which means that if you play this game forever you will lose eventually. This is a standard problem and it is pretty famous. I wanted to generalize the problem for unfair coins. In particular, I wanted to find the value of $p_w$ for which the probability $e$ is not zero. So, I solved the equation for general $p_w$ and $p_l = 1 - p_w$ and what you get is that you always have two solutions, namely: $$ e_1 = \frac{p_l}{p_w};  \quad e_2 = 1 $$ When $p_w <1/2$ , $e_1$ is larger than $1$ : we can exclude this solution because it is not in $(0,1)$ , the valid range for probability. We still have $1$ as a solution, which implies that we will always lose for all of our money. But when $p_w > 1/2$ , $e_1$ is in (0,1), meaning that it is an acceptable solution. In fact, for $p_w=1$ you got $e_1=0$ , according with the intuition. The trouble is that $e_2$ is still a valid solution. Is this correct? And should we interpret the fact that we have two valid solutions in that regime, one of which leads to certain ruin?","I was solving this famous problem which reads: You start with N Dollars. Each turn, you toss a coin for each dollar you have and you double it if you win, otherwise, you lose it. You go on like this. What is the probability of losing all of your money? You solve the problem in the following way: You notice that, calling you set the recursive expression in which is the probability of losing and is the probability of winning (so that, you have now two coins and you have to lose both of them). Setting one has , which means that if you play this game forever you will lose eventually. This is a standard problem and it is pretty famous. I wanted to generalize the problem for unfair coins. In particular, I wanted to find the value of for which the probability is not zero. So, I solved the equation for general and and what you get is that you always have two solutions, namely: When , is larger than : we can exclude this solution because it is not in , the valid range for probability. We still have as a solution, which implies that we will always lose for all of our money. But when , is in (0,1), meaning that it is an acceptable solution. In fact, for you got , according with the intuition. The trouble is that is still a valid solution. Is this correct? And should we interpret the fact that we have two valid solutions in that regime, one of which leads to certain ruin?","P(\text{Ruin having N dollars}) = (P(\text{ruin having 1 dollar}))^N  e:= P(\text{ruin having 1 dollar})  
e = p_l + p_w e^2 
 p_l p_w p_l = p_w = 1/2 e = 1 p_w e p_w p_l = 1 - p_w 
e_1 = \frac{p_l}{p_w};  \quad e_2 = 1
 p_w <1/2 e_1 1 (0,1) 1 p_w > 1/2 e_1 p_w=1 e_1=0 e_2","['probability', 'probability-theory', 'stochastic-processes']"
4,The triangle inequality holds... $50\%$ of the time? Or is this problem asking for something else?,The triangle inequality holds...  of the time? Or is this problem asking for something else?,50\%,"Here's a question from my probability textbook: If three numbers be named at random it is just as likely as not that every two of them will be greater than the third. I don't understand what this problem is even asking, it's not clear what this means. Could anyone help? One interpretation is just if I randomly select three numbers $a > b > c$ , we want to show that the probability that $b + c > a$ is ${1\over2}$ . I guess that's true, but I'm not sure since infinities are weird. EDIT: Using Mike Earnest's answer of ${1\over2} + {1\over{2n^2}}$ to my previous question here : Three different persons have each to name an integer not greater than $n$ . Find the chance that the integers named will be such that every two are together greater than the third. We take the limit as $n \to \infty$ , and get ${1\over2}$ . Does that work? EDIT 2: This textbook was written in the 19th century, maybe explaining the lack of rigorous formulation on its part.","Here's a question from my probability textbook: If three numbers be named at random it is just as likely as not that every two of them will be greater than the third. I don't understand what this problem is even asking, it's not clear what this means. Could anyone help? One interpretation is just if I randomly select three numbers , we want to show that the probability that is . I guess that's true, but I'm not sure since infinities are weird. EDIT: Using Mike Earnest's answer of to my previous question here : Three different persons have each to name an integer not greater than . Find the chance that the integers named will be such that every two are together greater than the third. We take the limit as , and get . Does that work? EDIT 2: This textbook was written in the 19th century, maybe explaining the lack of rigorous formulation on its part.",a > b > c b + c > a {1\over2} {1\over2} + {1\over{2n^2}} n n \to \infty {1\over2},['probability']
5,Distribution of this strange combination of two random variables,Distribution of this strange combination of two random variables,,"We have two independent random variables $\gamma_1$ and $\gamma_2$ and we know their CDFs, given by $F_{\gamma_1}(x)$ and $F_{\gamma_2}(x)$ . We select a threshold $\gamma_T$ and then we define a random variable $Z$ as follows: If $\gamma_2 < \gamma_T$ , then $Z = \max(\gamma_1, \gamma_2)$ . If $\gamma_2 \geq \gamma_T$ , then $Z = \gamma_2$ . I am trying to calculate the CDF of $Z$ , $F_Z(x)$ . For the first case ( $\gamma_2 < \gamma_T$ ) I know that $F_Z(x) = F_{\gamma_1}(x) \cdot F_{\gamma_2}(x)$ , however I am unable to calculate the CDF for the second case ( $\gamma_2 \geq \gamma_T$ ). For the second case I have tried $F_Z(x) = F_{\gamma_1}(\gamma_T) \cdot F_{\gamma_2}(\gamma_T) + F_{\gamma_2}(x) - F_{\gamma_2}(\gamma_T)$ but comparing to simulations it doesn't seem to be the correct solution. I have also checked Example 6-17 in page 193 of the book of Papoulis (4th edition), which I think is related, but I'm not sure how to do the calculation. Any ideas?","We have two independent random variables and and we know their CDFs, given by and . We select a threshold and then we define a random variable as follows: If , then . If , then . I am trying to calculate the CDF of , . For the first case ( ) I know that , however I am unable to calculate the CDF for the second case ( ). For the second case I have tried but comparing to simulations it doesn't seem to be the correct solution. I have also checked Example 6-17 in page 193 of the book of Papoulis (4th edition), which I think is related, but I'm not sure how to do the calculation. Any ideas?","\gamma_1 \gamma_2 F_{\gamma_1}(x) F_{\gamma_2}(x) \gamma_T Z \gamma_2 < \gamma_T Z = \max(\gamma_1, \gamma_2) \gamma_2 \geq \gamma_T Z = \gamma_2 Z F_Z(x) \gamma_2 < \gamma_T F_Z(x) = F_{\gamma_1}(x) \cdot F_{\gamma_2}(x) \gamma_2 \geq \gamma_T F_Z(x) = F_{\gamma_1}(\gamma_T) \cdot F_{\gamma_2}(\gamma_T) + F_{\gamma_2}(x) - F_{\gamma_2}(\gamma_T)","['probability', 'probability-theory', 'probability-distributions']"
6,Proof of Sampling/Importance Resampling (Weighted Bootstrap) technique,Proof of Sampling/Importance Resampling (Weighted Bootstrap) technique,,"From Casella Berger exercise 5.65: Let us have $X \sim f$ . Then, assume we produce $m$ i.i.d. random variables $Y_1,...,Y_m$ from another distribution $g$ . Let us have $$q_i = \frac{\frac{f(Y_i)}{g(Y_i)}}{\sum_{j = 1}^{m}\frac{f(Y_j)}{g(Y_j)}}$$ Now, we generate random variables $X^\star$ from the discrete distribution of $P(X^\star = Y_i) = q_i$ . This technique seems to be called ""Sampling/Importance Resampling (SIR) / weighted bootstrap"". I need to show that $X_1^\star, X_2^\star, ..., X_r^\star,..$ are approximately a sample from $f$ . The textbook hint given says: ""Show that $P(X^\star \leq x) = \sum_{i = 1}^m q_iI(Y_i \leq x)$ . From there use WLLN."" The hint itself seems wrong - we are not supposed to have indicator random variables $I(Y_i \leq x)$ in the definition of $P(X^\star \leq x)$ . The solution manual on the internet is wrong. The issue in my reasoning: $$P(X^\star \leq x) = \sum_{i = 1}^m P(X^\star \leq x | X^\star = Y_i)P(X^\star = Y_i) = \sum_{i = 1}^m P(Y_i \leq x)q_i = P(Y_i \leq x)\sum_{i = 1}^m q_i$$ This does not look anything like the required equality in the hint. We arrived at the conclusion that $F_{X^\star}(x) = G_Y(x)$ . Which is back to the definition... How can this be shown, preferably using WLLN?","From Casella Berger exercise 5.65: Let us have . Then, assume we produce i.i.d. random variables from another distribution . Let us have Now, we generate random variables from the discrete distribution of . This technique seems to be called ""Sampling/Importance Resampling (SIR) / weighted bootstrap"". I need to show that are approximately a sample from . The textbook hint given says: ""Show that . From there use WLLN."" The hint itself seems wrong - we are not supposed to have indicator random variables in the definition of . The solution manual on the internet is wrong. The issue in my reasoning: This does not look anything like the required equality in the hint. We arrived at the conclusion that . Which is back to the definition... How can this be shown, preferably using WLLN?","X \sim f m Y_1,...,Y_m g q_i = \frac{\frac{f(Y_i)}{g(Y_i)}}{\sum_{j = 1}^{m}\frac{f(Y_j)}{g(Y_j)}} X^\star P(X^\star = Y_i) = q_i X_1^\star, X_2^\star, ..., X_r^\star,.. f P(X^\star \leq x) = \sum_{i = 1}^m q_iI(Y_i \leq x) I(Y_i \leq x) P(X^\star \leq x) P(X^\star \leq x) = \sum_{i = 1}^m P(X^\star \leq x | X^\star = Y_i)P(X^\star = Y_i) = \sum_{i = 1}^m P(Y_i \leq x)q_i = P(Y_i \leq x)\sum_{i = 1}^m q_i F_{X^\star}(x) = G_Y(x)","['probability', 'probability-theory', 'sampling', 'bootstrap-sampling']"
7,6 Robberies happen in a city with 6 Districts what is the probability that a district has more than 1 robbery?,6 Robberies happen in a city with 6 Districts what is the probability that a district has more than 1 robbery?,,"That's the from stat110 book, problem 23 A city with 6 districts has 6 robberies in a particular week. Assume the robberies are located randomly, with all possibilities for which robbery occurred where equally likely. What is the probability that some district had more than 1 robbery? I have found several threads with different solutions here, but none with mine. My solution: Strategy: using the complement, $1-$ what is the probability that all robberies happen in different district? The first robbery can happen in any district out of the six. The next robbery can happen in any of the $5$ other districts, then there are $4$ , $3$ , $2$ , $1$ districts. which translated to me into a probability of $$1 - \frac{5}{6}\frac{4}{6}\frac{3}{6}\frac{2}{6}\frac{1}{6}$$ or $$1 - \frac{5!}{6^5}$$ the solution is $$1 - \frac{6!}{6^6}$$ Where did my reasoning fail? thank you very much for explaining!","That's the from stat110 book, problem 23 A city with 6 districts has 6 robberies in a particular week. Assume the robberies are located randomly, with all possibilities for which robbery occurred where equally likely. What is the probability that some district had more than 1 robbery? I have found several threads with different solutions here, but none with mine. My solution: Strategy: using the complement, what is the probability that all robberies happen in different district? The first robbery can happen in any district out of the six. The next robbery can happen in any of the other districts, then there are , , , districts. which translated to me into a probability of or the solution is Where did my reasoning fail? thank you very much for explaining!",1- 5 4 3 2 1 1 - \frac{5}{6}\frac{4}{6}\frac{3}{6}\frac{2}{6}\frac{1}{6} 1 - \frac{5!}{6^5} 1 - \frac{6!}{6^6},"['probability', 'combinatorics', 'statistics']"
8,Asymptotics for the probability that two $n$-cycles generate $S_n$ (or $A_n$).,Asymptotics for the probability that two -cycles generate  (or ).,n S_n A_n,"Is there a known asymptotic formula for the probability that two $n$ -cycles generate $S_n$ (or $A_n$ in the event that $n$ is odd)? There seems to be a lot of published research on this question for two arbitrary permutations. This is more a reference request -- no proof necessary. (In fact, I am only interested in the case when $n = p$ is prime, if that is somehow easier or known.)","Is there a known asymptotic formula for the probability that two -cycles generate (or in the event that is odd)? There seems to be a lot of published research on this question for two arbitrary permutations. This is more a reference request -- no proof necessary. (In fact, I am only interested in the case when is prime, if that is somehow easier or known.)",n S_n A_n n n = p,"['probability', 'group-theory', 'reference-request', 'asymptotics', 'symmetric-groups']"
9,What does multiplying a pdf mean?,What does multiplying a pdf mean?,,"Suppose I have two (independent) continuous random variables $X$ and $Y$ with pdfs $f(x)$ and $g(x)$ respectively.  It is well-known that $f(x)g(x)$ is not the pdf of $XY$ ; in fact, $f(x)g(x)$ may not be a pdf at all (see Appendix). On the other hand, (assuming $X$ and $Y$ have common support — h/t Thomas Andrews) it's easy enough to make $f(x)g(x)$ a pdf: just rescale by $\left(\int{f(x)g(x)\,dx}\right)^{-1}$ .  Then we have the following interesting facts: If $f(x)=g(x)=1[0\leq x\leq 1]$ (uniform distribution), then $f(x)g(x)$ is also the pdf of the uniform distribution. If $f(x)=\lambda_fe^{-\lambda_fx}\cdot1[0\leq x]$ , $g(x)=\lambda_ge^{-\lambda_gx}\cdot1[0\leq x]$ (exponential distribution), then $f(x)g(x)\propto(\lambda_f+\lambda_g)e^{-(\lambda_f+\lambda_g)x}\cdot1[0\leq x]$ , also the pdf of the exponential distribution. Same for two normal distributions. Multiplying a normal and an exponential gives a normal. If $X$ is as in the appendix ( $2x1[0\leq x\leq 1]$ ) and $Y$ is supported on $[0,1]$ with standard deviation $\sigma$ , then $f(x)g(x)$ after rescaling has mean $2\sigma^2$ . So clearly there's something going on here. Is there a probabilistic interpretation for $f(x)g(x)$ ? Appendix For example, let $$f(x)=g(x)=2x\cdot 1[0\leq x\leq1]$$ (where $1[A]$ is the indicator function of $A$ ).  Then $$\int_{\mathbb{R}}{f(x)g(x)\,dx}=\int_0^1{4x^2\,dx}=\frac{4}{3}\neq1$$ Thus $f(x)g(x)$ isn't even a pdf. For completeness, the law of $XY$ is as follows: \begin{align*} \mathbb{P}[XY\leq x]&=\int_{\mathbb{R}}{f(s)\mathbb{P}\left[Y\leq\frac{x}{s}\right]\,ds} \\ &=\int_0^1{2s\min{(1,(x/s)^2)}\,ds} \\ &=\int_0^x{2s\,ds}+\int_x^1{2x/s\,ds} \\ &=x^2-2x\ln{(x)} \end{align*} To get the pdf, differentiate; the result is precisely $2(x-\ln{(x)}-1)1[0\leq x\leq1]$ .","Suppose I have two (independent) continuous random variables and with pdfs and respectively.  It is well-known that is not the pdf of ; in fact, may not be a pdf at all (see Appendix). On the other hand, (assuming and have common support — h/t Thomas Andrews) it's easy enough to make a pdf: just rescale by .  Then we have the following interesting facts: If (uniform distribution), then is also the pdf of the uniform distribution. If , (exponential distribution), then , also the pdf of the exponential distribution. Same for two normal distributions. Multiplying a normal and an exponential gives a normal. If is as in the appendix ( ) and is supported on with standard deviation , then after rescaling has mean . So clearly there's something going on here. Is there a probabilistic interpretation for ? Appendix For example, let (where is the indicator function of ).  Then Thus isn't even a pdf. For completeness, the law of is as follows: To get the pdf, differentiate; the result is precisely .","X Y f(x) g(x) f(x)g(x) XY f(x)g(x) X Y f(x)g(x) \left(\int{f(x)g(x)\,dx}\right)^{-1} f(x)=g(x)=1[0\leq x\leq 1] f(x)g(x) f(x)=\lambda_fe^{-\lambda_fx}\cdot1[0\leq x] g(x)=\lambda_ge^{-\lambda_gx}\cdot1[0\leq x] f(x)g(x)\propto(\lambda_f+\lambda_g)e^{-(\lambda_f+\lambda_g)x}\cdot1[0\leq x] X 2x1[0\leq x\leq 1] Y [0,1] \sigma f(x)g(x) 2\sigma^2 f(x)g(x) f(x)=g(x)=2x\cdot 1[0\leq x\leq1] 1[A] A \int_{\mathbb{R}}{f(x)g(x)\,dx}=\int_0^1{4x^2\,dx}=\frac{4}{3}\neq1 f(x)g(x) XY \begin{align*}
\mathbb{P}[XY\leq x]&=\int_{\mathbb{R}}{f(s)\mathbb{P}\left[Y\leq\frac{x}{s}\right]\,ds} \\
&=\int_0^1{2s\min{(1,(x/s)^2)}\,ds} \\
&=\int_0^x{2s\,ds}+\int_x^1{2x/s\,ds} \\
&=x^2-2x\ln{(x)}
\end{align*} 2(x-\ln{(x)}-1)1[0\leq x\leq1]","['probability', 'probability-distributions']"
10,"Simple probability: $m$ balls are placed independently in container A with probability $a$, and B otherwise. Probability A has fewer than x balls?","Simple probability:  balls are placed independently in container A with probability , and B otherwise. Probability A has fewer than x balls?",m a,"Each of $m$ balls is placed independently into a container A with probability $0 <a<1$ , or in container B otherwise. What is the probability that container A will have fewer than $x$ balls, where $0<x\leq m$ ? Now immediately to me this looks like a binomial setup. So I would be tempted to say that the probability is $$P = \sum_{i=0}^{x-1} {m \choose i} a^i (1-a)^{m-1}$$ This seems correct from everything I know about the binomial distribution. Nevertheless I am uncomfortable with it because it seems to be summing up the probabilities of each of the events ""this specific set of $i<x$ balls is in A, and all other balls are in B$."" This makes me uncomfortable because the events are of course dependent in general. If you take one set of size $i>2$ containing ball number one, and another different set of size $i$ containing ball number one, then the events that the first set is the set of balls in A, is not independent from the event that the second set is the set in A. If someone could help to clarify where I am not understanding that would be much appreciated.","Each of balls is placed independently into a container A with probability , or in container B otherwise. What is the probability that container A will have fewer than balls, where ? Now immediately to me this looks like a binomial setup. So I would be tempted to say that the probability is This seems correct from everything I know about the binomial distribution. Nevertheless I am uncomfortable with it because it seems to be summing up the probabilities of each of the events ""this specific set of balls is in A, and all other balls are in B$."" This makes me uncomfortable because the events are of course dependent in general. If you take one set of size containing ball number one, and another different set of size containing ball number one, then the events that the first set is the set of balls in A, is not independent from the event that the second set is the set in A. If someone could help to clarify where I am not understanding that would be much appreciated.",m 0 <a<1 x 0<x\leq m P = \sum_{i=0}^{x-1} {m \choose i} a^i (1-a)^{m-1} i<x i>2 i,"['probability', 'binomial-distribution']"
11,"How do we explain the ""Bad Luck"" in probability?","How do we explain the ""Bad Luck"" in probability?",,"Say, in the game of Pokemon Go, the probability of catching a shiny Pokemon is $\frac{1}{450} \approx 0.22222\%$ . Some players consider that ""lucky"". And by the Law of Large Numbers, we can say, if we catch 450 Pokemon per day, then over the long term, we get about 1 shiny Pokemon per day (assuming all Pokemon has a chance of being shiny, for simplicity, because in reality not all Pokemon has its shiny form released yet). by probability, we can also say that, the probability of getting one or more shiny Pokemon per day is $$ 1 - \left(\frac{449}{450}\right) ^ {450} \approx 0.6325 = 63.25 \% $$ So how do we explain the difference between the ""long term"" $100\%$ vs the short term $63.25\%$ ?  How do we explain this ""lucky everyday"" vs ""not as lucky everyday at $63.25\%$ ? Where did that remaining $36.75\%$ go? P.S. I think I know the answer and how the math relates to the philosophy of everyday life... but I will put the answer here 3 - 7 days later.","Say, in the game of Pokemon Go, the probability of catching a shiny Pokemon is . Some players consider that ""lucky"". And by the Law of Large Numbers, we can say, if we catch 450 Pokemon per day, then over the long term, we get about 1 shiny Pokemon per day (assuming all Pokemon has a chance of being shiny, for simplicity, because in reality not all Pokemon has its shiny form released yet). by probability, we can also say that, the probability of getting one or more shiny Pokemon per day is So how do we explain the difference between the ""long term"" vs the short term ?  How do we explain this ""lucky everyday"" vs ""not as lucky everyday at ? Where did that remaining go? P.S. I think I know the answer and how the math relates to the philosophy of everyday life... but I will put the answer here 3 - 7 days later.",\frac{1}{450} \approx 0.22222\%  1 - \left(\frac{449}{450}\right) ^ {450} \approx 0.6325 = 63.25 \%  100\% 63.25\% 63.25\% 36.75\%,['probability']
12,"Given a randomly generated binary matrix with fixed row and column weights, what is the probability that columns have ones at different rows?","Given a randomly generated binary matrix with fixed row and column weights, what is the probability that columns have ones at different rows?",,"Setup: Given $a,b\in\mathbb{N}$ , and $b\geq a$ such that $b/a\in\mathbb{N}$ , I generate (i.e., uniformly sample amongst all possible matrices) a random matrix $\mathbf{A}\in\{0,1\}^{a,b}$ , where $a$ is the number of rows and $b$ is the number of columns, such that each column of $\mathbf{A}$ contains exactly one entry 1 (i.e., weight of one), and each row of $\mathbf{A}$ contains exactly $b/a$ entries of 1 (i.e., weight of $b/a$ ). This implies that any individual column is uniformly distributed among all length- $a$ columns of weight one (in total there are only $a$ such columns), and any individual row is uniformly distributed among all length- $b$ columns of weight $b/a$ . Question: Assuming $x<a$ and $x<b$ , looking at just $x$ specific columns (e.g., the first $x$ columns), what is the probability that all $x$ columns have a one in a different row? Attempt: I think of counting the number of such matrices. More specifically I count the number of ways to choose the rows of the matrix sequentially. This gives \begin{align} \underbrace{{b-x\choose b/a-1}\dots{b-x-(x-1)(b/a-1)\choose b/a-1}} _{\text{#ways to choose rows with entry 1 in the $x$ columns}} \underbrace{{b-x(b/a)\choose b/a}\dots{b-(a-1)b/a\choose b/a}} _{\text{#ways to choose remaining rows}} \end{align} and the number of ways to choose the matrix without the imposed restrictions is \begin{align} {b\choose b/a}\dots{b-(a-1)b/a\choose b/a}. \end{align} Dividing the final terms of the two equations give us our probability. Did I under/over-count the number of possibilities? Do I also need to include the number of rows each of the $x$ columns can have their one entry in? This would result in a further multiplication of $a(a-1)\dots(a-x+1)$ .","Setup: Given , and such that , I generate (i.e., uniformly sample amongst all possible matrices) a random matrix , where is the number of rows and is the number of columns, such that each column of contains exactly one entry 1 (i.e., weight of one), and each row of contains exactly entries of 1 (i.e., weight of ). This implies that any individual column is uniformly distributed among all length- columns of weight one (in total there are only such columns), and any individual row is uniformly distributed among all length- columns of weight . Question: Assuming and , looking at just specific columns (e.g., the first columns), what is the probability that all columns have a one in a different row? Attempt: I think of counting the number of such matrices. More specifically I count the number of ways to choose the rows of the matrix sequentially. This gives and the number of ways to choose the matrix without the imposed restrictions is Dividing the final terms of the two equations give us our probability. Did I under/over-count the number of possibilities? Do I also need to include the number of rows each of the columns can have their one entry in? This would result in a further multiplication of .","a,b\in\mathbb{N} b\geq a b/a\in\mathbb{N} \mathbf{A}\in\{0,1\}^{a,b} a b \mathbf{A} \mathbf{A} b/a b/a a a b b/a x<a x<b x x x \begin{align}
\underbrace{{b-x\choose b/a-1}\dots{b-x-(x-1)(b/a-1)\choose b/a-1}}
_{\text{#ways to choose rows with entry 1 in the x columns}}
\underbrace{{b-x(b/a)\choose b/a}\dots{b-(a-1)b/a\choose b/a}}
_{\text{#ways to choose remaining rows}}
\end{align} \begin{align}
{b\choose b/a}\dots{b-(a-1)b/a\choose b/a}.
\end{align} x a(a-1)\dots(a-x+1)","['probability', 'combinatorics']"
13,"New to Bayesian statistics, getting confused with the definitions and sub-understanding of how it works","New to Bayesian statistics, getting confused with the definitions and sub-understanding of how it works",,"I'm sorry if these seem like rudimentary questions, but I'm self taught trying to grasp an understanding that seems a but beyond me right now. Here's my situation. A meteorologist is interested in predicting temperature extremes for a location in the southern United States. From daily temperature records for this location she extracts the annual maximum temperature over a 10 year period. The mean of the observations is $98.2~.$ She assumes that each observation is independently distributed as $N(\mu, 3^2).$ A historical study suggests that $\mu \sim N(90, 102).$ This was the scenario I was given, I was then asked to derive the $95\%$ posterior Highest Density Interval for $\mu$ with posterior $N(98.1,0.94^2)$ which I managed to do. What I am confused about is this : The meteorologist says: “There is a probability of $0.95$ that $\mu$ lies between $a$ and $b.$ ” Is her claim correct? I assume not because of the differences of historical data which may skew the results. I also have no clue how to describe why a Bayesian analysis mught be preferable to a frequentist analysis of these annual temperature data.","I'm sorry if these seem like rudimentary questions, but I'm self taught trying to grasp an understanding that seems a but beyond me right now. Here's my situation. A meteorologist is interested in predicting temperature extremes for a location in the southern United States. From daily temperature records for this location she extracts the annual maximum temperature over a 10 year period. The mean of the observations is She assumes that each observation is independently distributed as A historical study suggests that This was the scenario I was given, I was then asked to derive the posterior Highest Density Interval for with posterior which I managed to do. What I am confused about is this : The meteorologist says: “There is a probability of that lies between and ” Is her claim correct? I assume not because of the differences of historical data which may skew the results. I also have no clue how to describe why a Bayesian analysis mught be preferable to a frequentist analysis of these annual temperature data.","98.2~. N(\mu, 3^2). \mu \sim N(90, 102). 95\% \mu N(98.1,0.94^2) 0.95 \mu a b.","['probability', 'statistics']"
14,Why can we not artifically change the state space of this Markov chain?,Why can we not artifically change the state space of this Markov chain?,,"I am slightly confused about the solution to Exercise 11 in Chapter 4 of Introduction to Probability Models , by Sheldon M. Ross. Context: On any given day Gary is either cheerful (C), so-so (S), or glum (G). If he is cheerful today, then he will be C, S, or G tomorrow with respective probabilities 0.5, 0.4, 0.1. If he is feeling so-so today, then he will be C, S, or G tomorrow with probabilities 0.3, 0.4, 0.3. If he is glum today, then he will be C, S, or G tomorrow with probabilities 0.2, 0.3, 0.5. Letting $X_n$ denote Gary’s mood on the nth day, then $\{X_n, n \geq 0$ } is a three-state Markov chain (state 0 = C, state 1 = S, state 2 = G) with transition probability matrix $$P = \begin{pmatrix} 0.5 & 0.4 & 0.1 \\ 0.3 & 0.4 & 0.3 \\ 0.2 & 0.3 & .5 \end{pmatrix}. $$ The question: In Example 4.3, Gary was in a glum mood four days ago. Given that he hasn’t felt cheerful in a week, what is the probability he is feeling glum today? According to the solution manual, the answer is $\frac{P_{2,2}^4}{1-P_{2,0}^4}$ , with $$P = \begin{pmatrix} 1 & 0 & 0 \\ 0.3 & 0.4 & 0.3 \\ 0.2 & 0.3 & .5 \end{pmatrix}.$$ However, my initial approach had been to  form a new, reduced transition probability matrix $$P = \begin{pmatrix} \frac{4}{7} & \frac{3}{7} \\ \frac{3}{8} & \frac{5}{8} \end{pmatrix},$$ where I just completely neglect the possibility of going into state 0, and simply report $P_{1,1}^4$ as the answer. Why is this approach wrong? To be clear, I fully understand the logic behind the correct answer, and I know something is not right with the way I tried to solve the problem, but I would appreciate a clear explanation as to why it doesn't work.","I am slightly confused about the solution to Exercise 11 in Chapter 4 of Introduction to Probability Models , by Sheldon M. Ross. Context: On any given day Gary is either cheerful (C), so-so (S), or glum (G). If he is cheerful today, then he will be C, S, or G tomorrow with respective probabilities 0.5, 0.4, 0.1. If he is feeling so-so today, then he will be C, S, or G tomorrow with probabilities 0.3, 0.4, 0.3. If he is glum today, then he will be C, S, or G tomorrow with probabilities 0.2, 0.3, 0.5. Letting denote Gary’s mood on the nth day, then } is a three-state Markov chain (state 0 = C, state 1 = S, state 2 = G) with transition probability matrix The question: In Example 4.3, Gary was in a glum mood four days ago. Given that he hasn’t felt cheerful in a week, what is the probability he is feeling glum today? According to the solution manual, the answer is , with However, my initial approach had been to  form a new, reduced transition probability matrix where I just completely neglect the possibility of going into state 0, and simply report as the answer. Why is this approach wrong? To be clear, I fully understand the logic behind the correct answer, and I know something is not right with the way I tried to solve the problem, but I would appreciate a clear explanation as to why it doesn't work.","X_n \{X_n, n \geq 0 P = \begin{pmatrix} 0.5 & 0.4 & 0.1 \\ 0.3 & 0.4 & 0.3 \\ 0.2 & 0.3 & .5 \end{pmatrix}.  \frac{P_{2,2}^4}{1-P_{2,0}^4} P = \begin{pmatrix} 1 & 0 & 0 \\ 0.3 & 0.4 & 0.3 \\ 0.2 & 0.3 & .5 \end{pmatrix}. P = \begin{pmatrix} \frac{4}{7} & \frac{3}{7} \\ \frac{3}{8} & \frac{5}{8} \end{pmatrix}, P_{1,1}^4","['probability', 'stochastic-processes', 'markov-chains']"
15,Substring of a bit string probability [closed],Substring of a bit string probability [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Given a fixed bit string $A$ of length $k$ and a randomly generated bit string $B$ of length $n > k$ , meaning each bit of $B$ has probability $1/2$ to be  zero or one respectively, how can one determine the probability that $A$ is a substring of $B$ , meaning that the sequence of bits of $A$ appears somewhere in $B$ (contiguously)? Unfortunately, I don't really have any approaches to this problem...","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Given a fixed bit string of length and a randomly generated bit string of length , meaning each bit of has probability to be  zero or one respectively, how can one determine the probability that is a substring of , meaning that the sequence of bits of appears somewhere in (contiguously)? Unfortunately, I don't really have any approaches to this problem...",A k B n > k B 1/2 A B A B,"['probability', 'bit-strings']"
16,"Central Limit Theorem in a win, lose or stay the same scenario","Central Limit Theorem in a win, lose or stay the same scenario",,"So, I have this problem: Robert bets on a casino game where he estimates that he has a 0.45 probability of winning, a 0.5 probability of losing, and a 0.05 probability of being left with no profit or loss. In each game she bets \$10, which implies that she can win \$10, lose \$10 or stay as he was, with the odds described. If Robert plays this game 100 times independently. What is the approximate probability that he ends up with more money than he started (assuming she has enough money for the first 100 plays)? My attempt: Let $X_i$ be the money he gains or losses in each round. And let $Y=X_1+...X_{100}$ . Then I have $$E(X_i)=10(.45)+(-10)(.5)+0(.05)=-.5$$ $$E(X_i^2)=10^2(.45)+(-10)^2(.5)+0^2(.05)=95$$ $$Var(X_i)=E(X_i^2)-E(X_i)^2=95-(-.5)^2=94.75$$ Then $$E(Y)=100E(X_i)=-50$$ $$Var(Y)=100Var(X_i)=9475$$ Now, if I want to calculate the  probability that he ends up with more money than he started I have to calculate $P(Y>1000)$ . My problem is when I apply the CLT because $P(Y>1000)=1-P(Y\leq1000)=1-P(\frac{Y+50}{\sqrt{9475}}\leq\frac{1000+50}{\sqrt{9475}})=1-\phi(10.78)$ And using a Standard Normal Table that is impossible. So, any help, suggestion or ideas are welcomed and appreciated.","So, I have this problem: Robert bets on a casino game where he estimates that he has a 0.45 probability of winning, a 0.5 probability of losing, and a 0.05 probability of being left with no profit or loss. In each game she bets \$10, which implies that she can win \$10, lose \$10 or stay as he was, with the odds described. If Robert plays this game 100 times independently. What is the approximate probability that he ends up with more money than he started (assuming she has enough money for the first 100 plays)? My attempt: Let be the money he gains or losses in each round. And let . Then I have Then Now, if I want to calculate the  probability that he ends up with more money than he started I have to calculate . My problem is when I apply the CLT because And using a Standard Normal Table that is impossible. So, any help, suggestion or ideas are welcomed and appreciated.",X_i Y=X_1+...X_{100} E(X_i)=10(.45)+(-10)(.5)+0(.05)=-.5 E(X_i^2)=10^2(.45)+(-10)^2(.5)+0^2(.05)=95 Var(X_i)=E(X_i^2)-E(X_i)^2=95-(-.5)^2=94.75 E(Y)=100E(X_i)=-50 Var(Y)=100Var(X_i)=9475 P(Y>1000) P(Y>1000)=1-P(Y\leq1000)=1-P(\frac{Y+50}{\sqrt{9475}}\leq\frac{1000+50}{\sqrt{9475}})=1-\phi(10.78),"['probability', 'probability-theory', 'central-limit-theorem']"
17,Random Walk Markov Process -- Probability of Return to the Origin,Random Walk Markov Process -- Probability of Return to the Origin,,"I'm struggling with a problem I was asked by a friend a few days ago. It goes as follows: You start at the origin. On the first iteration you walk right with probability $p$ and left with probability $q = 1 - p$ . On each subsequent iteration you walk in the same direction as the previous iteration with probability $p$ and in the opposite direction with probability $q$ . What is the probability that you return to the origin in $n$ steps or fewer? The issue is that it's difficult to account for the Markov process in the calculation. Since I want something that works for arbitrary $n$ , I can't use matrices. Say $X_i$ is the the random variable such that on the $i$ -th step $$ X_i = \begin{cases} 1 &\text{if}\ i = 0\ \text{and went right}\\ -1 &\text{if}\ i = 0\ \text{and went left}\\ 1 &\text{if}\ i > 0\ \text{and went in same direction}\\  -1 &\text{if}\ i > 0\ \text{and went in opposite direction.}\end{cases} $$ Then the probability of returning to the origin is \begin{align*} P(\text{return})  &= q P(\text{return}|X_0 = -1) + p P(\text{return}|X_0 = 1)\\ &= P(\text{return}|X_0 = 1)\\ &= q + p P(\text{return}|X_1 = 1). \end{align*} I don't know where to go from here. When constructing a Monte Carlo simulation, I first simulate $\left(X_i\right)_{i = 0}^{n-1}$ . Then the cumulative product tells you whether you went left or right on the $i$ -th step. From there, you can take the cumulative sum to find position. If that's ever 0, then you add to the count. It's not clear to me how one would map this onto a mathematically rigorous calculation. This is my Python code. import numpy as np  # Define n n = 4  # Define p p = 0.75  # Calculate q q = 1 - p  # X can be either 1 or -1 vals = [1, -1]  # How many Monte Carlo simulations sims = 10**6  # Whether same or opposite X = np.random.choice(vals, size = (sims, n), replace = True, p = [p, q])  # Whether left or right move = np.cumprod(X, axis = 1)  # Sum change to calculate position position = np.cumsum(move, axis = 1)  # Which rows go through the origin success = np.sum(position == 0, axis = 1) > 0  # Calculate fraction that go through the origin solution = np.mean(success)  solution","I'm struggling with a problem I was asked by a friend a few days ago. It goes as follows: You start at the origin. On the first iteration you walk right with probability and left with probability . On each subsequent iteration you walk in the same direction as the previous iteration with probability and in the opposite direction with probability . What is the probability that you return to the origin in steps or fewer? The issue is that it's difficult to account for the Markov process in the calculation. Since I want something that works for arbitrary , I can't use matrices. Say is the the random variable such that on the -th step Then the probability of returning to the origin is I don't know where to go from here. When constructing a Monte Carlo simulation, I first simulate . Then the cumulative product tells you whether you went left or right on the -th step. From there, you can take the cumulative sum to find position. If that's ever 0, then you add to the count. It's not clear to me how one would map this onto a mathematically rigorous calculation. This is my Python code. import numpy as np  # Define n n = 4  # Define p p = 0.75  # Calculate q q = 1 - p  # X can be either 1 or -1 vals = [1, -1]  # How many Monte Carlo simulations sims = 10**6  # Whether same or opposite X = np.random.choice(vals, size = (sims, n), replace = True, p = [p, q])  # Whether left or right move = np.cumprod(X, axis = 1)  # Sum change to calculate position position = np.cumsum(move, axis = 1)  # Which rows go through the origin success = np.sum(position == 0, axis = 1) > 0  # Calculate fraction that go through the origin solution = np.mean(success)  solution","p q = 1 - p p q n n X_i i 
X_i = \begin{cases} 1 &\text{if}\ i = 0\ \text{and went right}\\
-1 &\text{if}\ i = 0\ \text{and went left}\\
1 &\text{if}\ i > 0\ \text{and went in same direction}\\ 
-1 &\text{if}\ i > 0\ \text{and went in opposite direction.}\end{cases}
 \begin{align*}
P(\text{return}) 
&= q P(\text{return}|X_0 = -1) + p P(\text{return}|X_0 = 1)\\
&= P(\text{return}|X_0 = 1)\\
&= q + p P(\text{return}|X_1 = 1).
\end{align*} \left(X_i\right)_{i = 0}^{n-1} i","['probability', 'markov-process', 'random-walk']"
18,Properties of the stochastic integral $\int_0^t\frac{|B_s|}{s}\Bbb dB_s$,Properties of the stochastic integral,\int_0^t\frac{|B_s|}{s}\Bbb dB_s,"For a Brownian motion $(B_t)_{t\geq0}$ we define the process $$I_t:=\int_0^t\frac{|B_s|}{s}\Bbb dB_s,\qquad (t>0).$$ But what can we say about this process? Is it even possible to define this process? If yes, it is for sure a local martingale, but is it also a (true) martingale? As $$\Bbb E[I]_t=\Bbb E\int_0^t\frac{B_s^2}{s^2}\Bbb ds=\int_0^t\frac{1}{s}\Bbb ds=\infty, $$ where $[.]_t$ denotes the quadratic variation, the second moment can't exist if it is a martingale. Also, what can we say about the limit $$I_0:=\lim\limits_{t\searrow0}I_t,$$ does it exist in any sense? I thought about scaling property, Hölder continuity and the law of the iterated logarithm, but notthing helped. As the limit $$\lim\limits_{t\searrow0}\frac{B_t^2}{t}$$ doesn't exist, I can't just use the Itô formula. All hints about which properties this process possesses are welcome.","For a Brownian motion we define the process But what can we say about this process? Is it even possible to define this process? If yes, it is for sure a local martingale, but is it also a (true) martingale? As where denotes the quadratic variation, the second moment can't exist if it is a martingale. Also, what can we say about the limit does it exist in any sense? I thought about scaling property, Hölder continuity and the law of the iterated logarithm, but notthing helped. As the limit doesn't exist, I can't just use the Itô formula. All hints about which properties this process possesses are welcome.","(B_t)_{t\geq0} I_t:=\int_0^t\frac{|B_s|}{s}\Bbb dB_s,\qquad (t>0). \Bbb E[I]_t=\Bbb E\int_0^t\frac{B_s^2}{s^2}\Bbb ds=\int_0^t\frac{1}{s}\Bbb ds=\infty,
 [.]_t I_0:=\lim\limits_{t\searrow0}I_t, \lim\limits_{t\searrow0}\frac{B_t^2}{t}","['probability', 'stochastic-processes', 'martingales', 'stochastic-integrals']"
19,"Uniform integrability of $\sqrt{n} Y_n$ for $Y_n \sim \mathcal{N}(0, \frac{\sigma^2}{n})$",Uniform integrability of  for,"\sqrt{n} Y_n Y_n \sim \mathcal{N}(0, \frac{\sigma^2}{n})","Let $Y_n \sim \mathcal{N}(0, \frac{\sigma^2}{n})$ . Then the set $\{\sqrt{n} Y_n\}_{n \ge 1}$ is uniformly integrable since $$ \sqrt{n} Y_n \sim \sqrt{n}\mathcal{N}\bigg(0, \frac{\sigma^2}{n}\bigg) = \mathcal{N}(0, \sigma^2), $$ is a normal distribution that is not dependent on $n$ . Now suppose instead $Y_n$ is not normally distributed, but it is asymptotically normally distributed, i.e., $Y_n \stackrel{a}{\sim} \mathcal{N}(0, \frac{\sigma^2}{n})$ . For example $Y_n$ could be the sample mean for $n$ iid observations. Once again, consider the set $\{\sqrt{n} Y_n\}_{n \ge 1}$ . Is it still uniformly integrable now that $Y_n$ is only asymptotically distributed as $\mathcal{N}(0, \frac{\sigma^2}{n})$ ? If it isn't, are there additional assumptions that can be placed on $Y_n$ so that $\{\sqrt{n} Y_n\}_{n \ge 1}$ becomes uniformly integrable?","Let . Then the set is uniformly integrable since is a normal distribution that is not dependent on . Now suppose instead is not normally distributed, but it is asymptotically normally distributed, i.e., . For example could be the sample mean for iid observations. Once again, consider the set . Is it still uniformly integrable now that is only asymptotically distributed as ? If it isn't, are there additional assumptions that can be placed on so that becomes uniformly integrable?","Y_n \sim \mathcal{N}(0, \frac{\sigma^2}{n}) \{\sqrt{n} Y_n\}_{n \ge 1} 
\sqrt{n} Y_n \sim \sqrt{n}\mathcal{N}\bigg(0, \frac{\sigma^2}{n}\bigg) = \mathcal{N}(0, \sigma^2),
 n Y_n Y_n \stackrel{a}{\sim} \mathcal{N}(0, \frac{\sigma^2}{n}) Y_n n \{\sqrt{n} Y_n\}_{n \ge 1} Y_n \mathcal{N}(0, \frac{\sigma^2}{n}) Y_n \{\sqrt{n} Y_n\}_{n \ge 1}","['probability', 'probability-theory', 'measure-theory', 'probability-limit-theorems', 'uniform-integrability']"
20,"Mean of $Y=\cos(X)$ where $X\sim\mathcal N(0,1)$",Mean of  where,"Y=\cos(X) X\sim\mathcal N(0,1)","Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space and $X,Y:\Omega\rightarrow\mathbb{R}$ be two random variables. If $X\sim\mathcal N(0,1)$ and $Y=\cos(X)$ , what is $\mathbb{E}[Y]$ (i.e. the mean of $Y$ )? Using the definition of the mean, \begin{align} \mathbb{E}[Y]&=\mathbb{E}[\cos(X)] \\ &=\int_\mathbb{R} \cos(x)f_X(x) \ dx \\ &=\frac{1}{\sqrt{2\pi}}\int_\mathbb{R} \cos(x)\exp\left(-\frac{x^2}{2}\right) \ dx \\ &=\frac{1}{\sqrt{e}}. \end{align} However, according to my textbook $\mathbb{E}[Y]=0$ . Is there an error in my logic?","Let be a probability space and be two random variables. If and , what is (i.e. the mean of )? Using the definition of the mean, However, according to my textbook . Is there an error in my logic?","(\Omega,\mathcal{F},\mathbb{P}) X,Y:\Omega\rightarrow\mathbb{R} X\sim\mathcal N(0,1) Y=\cos(X) \mathbb{E}[Y] Y \begin{align}
\mathbb{E}[Y]&=\mathbb{E}[\cos(X)] \\
&=\int_\mathbb{R} \cos(x)f_X(x) \ dx \\
&=\frac{1}{\sqrt{2\pi}}\int_\mathbb{R} \cos(x)\exp\left(-\frac{x^2}{2}\right) \ dx \\
&=\frac{1}{\sqrt{e}}.
\end{align} \mathbb{E}[Y]=0","['probability', 'solution-verification']"
21,Number of attempts to fully color a disk coloring half of it at a time [closed],Number of attempts to fully color a disk coloring half of it at a time [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Mark precisely one half of the disk by a line that goes through its center. The angle of the line has a uniform distribution, meaning there is no preferable direction. You color one half of the disk and keep on with the same coloring scheme. What is the average number of attempts that you need to color the entire disk?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 3 years ago . Improve this question Mark precisely one half of the disk by a line that goes through its center. The angle of the line has a uniform distribution, meaning there is no preferable direction. You color one half of the disk and keep on with the same coloring scheme. What is the average number of attempts that you need to color the entire disk?",,"['probability', 'expected-value']"
22,A conditional probability problem where the next day depends on the last 3 days,A conditional probability problem where the next day depends on the last 3 days,,"For many years, Meteorologists have spent long visits (5 days) at the Bigtown. They have observed that, for three consecutive days, if there are EXACTLY two sunny days, the next day is a sunny day*, while half of all the cloudy days are followed by another cloudy day. Assuming days are either cloudy or sunny, estimate how many days have been cloudy in their last ten visits. Visits are not necessarily following each other. ''half of all the cloudy days are followed by another cloudy day'' so $P(C\mid C)=50\%$ Is this possible? If not why not? *i.e. SSC -> S SCS -> S CSS -> S where -> means followed by","For many years, Meteorologists have spent long visits (5 days) at the Bigtown. They have observed that, for three consecutive days, if there are EXACTLY two sunny days, the next day is a sunny day*, while half of all the cloudy days are followed by another cloudy day. Assuming days are either cloudy or sunny, estimate how many days have been cloudy in their last ten visits. Visits are not necessarily following each other. ''half of all the cloudy days are followed by another cloudy day'' so Is this possible? If not why not? *i.e. SSC -> S SCS -> S CSS -> S where -> means followed by",P(C\mid C)=50\%,['probability']
23,Extreme random variable sequence independence,Extreme random variable sequence independence,,"During solution of probability problem I came across following: Let $X_n$ - be a sequence of i.i.d (independent, identically distributed) random variables, uniformly distributed over $[0;1]$ . Then is it true that random variables $m_n$ , determined as $m_n=min\{X_1, ..., X_n\}$ are also independent or not? If not, do you have any ideas of proving that such 𝑚𝑛 approaches 0 almost surely then? I was trying to proof this via fact mentioned above, and do not have anymore ideas.. Do you have any ideas about this one? This is very crucial for my solution, would appreciate any help!","During solution of probability problem I came across following: Let - be a sequence of i.i.d (independent, identically distributed) random variables, uniformly distributed over . Then is it true that random variables , determined as are also independent or not? If not, do you have any ideas of proving that such 𝑚𝑛 approaches 0 almost surely then? I was trying to proof this via fact mentioned above, and do not have anymore ideas.. Do you have any ideas about this one? This is very crucial for my solution, would appreciate any help!","X_n [0;1] m_n m_n=min\{X_1, ..., X_n\}","['probability', 'probability-distributions', 'random-variables', 'independence']"
24,Probability to be infected in series of meetings,Probability to be infected in series of meetings,,"I have difficulty interpreting a simple probabilistic calculation and would be happy to help. We are in the midst of the Covid-19 epidemic and I am trying to assess someone's probability to be infected in a time window. For simplicity, I guess the probability of getting infected during a single session depends on its duration alone. In math terms: The probability to be infected in a given meeting is $P(t) = t\cdot\Theta$ , where $t$ is meeting duration and $\Theta$ is only a calibration parameter of the virus (and keep the probability under 1). Hence, the probability to be infected in a series of meetings is the complementary event to be not-infected in any meeting: $P(t_1...t_N) =  1-\prod_{k=1}^N(1-t_k\cdot\Theta)\tag{*}$ Does this inference sound reasonable? It seems to me that this is the material of a basic course in probability. Surprisingly and incomprehensibly to me, I saw in an article a calculation that actually reaches the following result for the same question (and the same assumptions): $P(t_1...t_N) = 1- \exp(-\Theta\sum_{k=1}^{N}t_{k})\tag{**}$ I do not understand what the relationship is between $(*)$ and $(**)$ and how in the calculation of a complementary event they arrived at the equation $(**)$ ? Thanks a lot!","I have difficulty interpreting a simple probabilistic calculation and would be happy to help. We are in the midst of the Covid-19 epidemic and I am trying to assess someone's probability to be infected in a time window. For simplicity, I guess the probability of getting infected during a single session depends on its duration alone. In math terms: The probability to be infected in a given meeting is , where is meeting duration and is only a calibration parameter of the virus (and keep the probability under 1). Hence, the probability to be infected in a series of meetings is the complementary event to be not-infected in any meeting: Does this inference sound reasonable? It seems to me that this is the material of a basic course in probability. Surprisingly and incomprehensibly to me, I saw in an article a calculation that actually reaches the following result for the same question (and the same assumptions): I do not understand what the relationship is between and and how in the calculation of a complementary event they arrived at the equation ? Thanks a lot!",P(t) = t\cdot\Theta t \Theta P(t_1...t_N) =  1-\prod_{k=1}^N(1-t_k\cdot\Theta)\tag{*} P(t_1...t_N) = 1- \exp(-\Theta\sum_{k=1}^{N}t_{k})\tag{**} (*) (**) (**),"['probability', 'exponential-function', 'problem-solving']"
25,The probabilty of the a 6-letter word is a palindrome,The probabilty of the a 6-letter word is a palindrome,,"a cat is walking on the keyboard. Given that the cat walked just on letters (with an equal chance for each letter A-Z) and wrote a 6-letter word, what is the probability that this word is a palindrome.","a cat is walking on the keyboard. Given that the cat walked just on letters (with an equal chance for each letter A-Z) and wrote a 6-letter word, what is the probability that this word is a palindrome.",,['probability']
26,Probability Game Optimal Strategy,Probability Game Optimal Strategy,,"You're playing a game where you have a .45 probability of winning and .55 probability of losing. You start out with 2000 chips and the winning condition is that if you bet a cumulative total of 10000 chips, then you win. Otherwise if you run out of chips, you lose. For example, if you bet 20 chips, no matter the outcome, that will contribute 20 to the total. And you'll be left with either 1980 or 2020 current chips. The min bet size is 1$ and max is as much as you currently have. What is the best strategy to maximize your probability of winning? What I said was, you'd want to use a strategy akin to betting as much as possible at each round. Since otherwise, from LLN, you are losing in general and just prolonging with small bets will make you lose more in the long run. I said you'd be able to maybe calculate the exact strategy using dynamic programming, with f(s,t) representing what you should bet at each combination of (current money, total cumulative so far). However I do not know if this is correct nor did I have time to fully solve it. Thank you!","You're playing a game where you have a .45 probability of winning and .55 probability of losing. You start out with 2000 chips and the winning condition is that if you bet a cumulative total of 10000 chips, then you win. Otherwise if you run out of chips, you lose. For example, if you bet 20 chips, no matter the outcome, that will contribute 20 to the total. And you'll be left with either 1980 or 2020 current chips. The min bet size is 1$ and max is as much as you currently have. What is the best strategy to maximize your probability of winning? What I said was, you'd want to use a strategy akin to betting as much as possible at each round. Since otherwise, from LLN, you are losing in general and just prolonging with small bets will make you lose more in the long run. I said you'd be able to maybe calculate the exact strategy using dynamic programming, with f(s,t) representing what you should bet at each combination of (current money, total cumulative so far). However I do not know if this is correct nor did I have time to fully solve it. Thank you!",,"['probability', 'expected-value', 'game-theory', 'gambling']"
27,Conditional Probability Problem with Dice,Conditional Probability Problem with Dice,,"Three distinct fair dice are thrown. The probability that $4$ appears on two dice given that $5$ occurs on atleast one dice. I counted the number of total cases when atleast one five occurs. This can be counted as (exactly 1+ exactly 2+exactly 3) = $ 75+15+1$ . The favourable cases are $3$ . So probability should be $3/91$ according to me. However, the answer that is given in the source from where the question has been taken is something else. So, I just wanted to confirm whether my method is correct.","Three distinct fair dice are thrown. The probability that appears on two dice given that occurs on atleast one dice. I counted the number of total cases when atleast one five occurs. This can be counted as (exactly 1+ exactly 2+exactly 3) = . The favourable cases are . So probability should be according to me. However, the answer that is given in the source from where the question has been taken is something else. So, I just wanted to confirm whether my method is correct.",4 5  75+15+1 3 3/91,"['probability', 'conditional-probability', 'dice']"
28,Some probabilistic reasoning in graphs.,Some probabilistic reasoning in graphs.,,"I’m reading the following scenario: $\bullet$ Let $G$ be an $n$ -vertex graph. $\bullet$ Sample $s$ vertices from $V(G)$ independently, with repetition. Let $S$ be the set of vertices selected. $\bullet$ Let $B = \{v \in V(G): \forall s \in S, \{v,s\} \in E(G)\}$ $\bullet$ Let $T$ be a set of $t$ vertices with at most $m$ common neighbours. $\bullet$ To have $T \subset B$ , need to select $S$ from these common neighbours. $\bullet \Rightarrow \mathbb{P}(T \subset B) \leq \left( \frac{m}{n} \right)^s$ The way the last statement comes about, from my understanding, is that, given the set of common neighbours of size $m$ , any vertex in the graph has at most $\frac{m}{n}$ a chance of being in this set. $S$ has $s$ members, hence the number $\left( \frac{m}{n} \right)^s$ . But how about this line of reasoning? We have $\mathbb{P}(T \subset B) = \mathbb{P}(\text{ the $m$ given vertices} \in S)$ . Each of those $m$ vertices has at most $\frac{s}{n}$ a chance to be in $S$ . The set has $m$ members, hence $\left(\frac{s}{n}\right)^m$ . Is this equivalent to the above? If not, why? Also please correct me if any of the above sentences doesn’t make sense.","I’m reading the following scenario: Let be an -vertex graph. Sample vertices from independently, with repetition. Let be the set of vertices selected. Let Let be a set of vertices with at most common neighbours. To have , need to select from these common neighbours. The way the last statement comes about, from my understanding, is that, given the set of common neighbours of size , any vertex in the graph has at most a chance of being in this set. has members, hence the number . But how about this line of reasoning? We have . Each of those vertices has at most a chance to be in . The set has members, hence . Is this equivalent to the above? If not, why? Also please correct me if any of the above sentences doesn’t make sense.","\bullet G n \bullet s V(G) S \bullet B = \{v \in V(G): \forall s \in S, \{v,s\} \in E(G)\} \bullet T t m \bullet T \subset B S \bullet \Rightarrow \mathbb{P}(T \subset B) \leq \left( \frac{m}{n} \right)^s m \frac{m}{n} S s \left( \frac{m}{n} \right)^s \mathbb{P}(T \subset B) = \mathbb{P}(\text{ the m given vertices} \in S) m \frac{s}{n} S m \left(\frac{s}{n}\right)^m","['probability', 'graph-theory', 'solution-verification', 'probabilistic-method']"
29,Combinatoric problem: Contest winner problem,Combinatoric problem: Contest winner problem,,"I have this problem to solve where: There is a contest between $m$ competitors. Each competitor draws a number between $1$ to $N$ separately, and the winner is the one who drew the highest number. The problem I'm having is to find out the probability that the contest fails. The contest fails when there isn't a single winner - two or more competitors drew the same number and that number was the highest from all the other numbers that were drawn. Generally, to draw the same number is not a problem as long that there is a competitor who drew higher. I calculated the probability that two or more competitors drew the same number using the complement probability: $$ \begin{multline} 1 - P(\text{all m contestants drew different number})  = 1 - \frac{N!}{(N-m)!} \frac{1}{N^m}  \end{multline} $$ Am I right?  I'm missing the part where the number that was drawn was the highest. Appreciate your help, thank you in advance.","I have this problem to solve where: There is a contest between competitors. Each competitor draws a number between to separately, and the winner is the one who drew the highest number. The problem I'm having is to find out the probability that the contest fails. The contest fails when there isn't a single winner - two or more competitors drew the same number and that number was the highest from all the other numbers that were drawn. Generally, to draw the same number is not a problem as long that there is a competitor who drew higher. I calculated the probability that two or more competitors drew the same number using the complement probability: Am I right?  I'm missing the part where the number that was drawn was the highest. Appreciate your help, thank you in advance.","m 1 N 
\begin{multline}
1 - P(\text{all m contestants drew different number})  = 1 - \frac{N!}{(N-m)!} \frac{1}{N^m} 
\end{multline}
","['probability', 'combinatorics']"
30,Expected value of game when flipping a coin,Expected value of game when flipping a coin,,"You start off with \$ $10,000$ . You flip a fair coin. If you get heads, you get paid \$ $1$ . If you get tails, you pay your friend half your current money. What is the expected amount of money you have after $n$ rounds ?. So let's define the initial amount as $x_{0} = 10000$ . Then in round 1, we expect $$ x_{1} = {1 \over 2}\left({x \over 2} + x + 1\right) $$ Note in round $1$ , we could have $2$ possible values for $x_{1}$ . $5000$ and $10,001$ . So in round $2$ , we could have $4$ possible values. So clearly at round $n$ , we have $2^{n}$ possible values, all with equal probability. Now this is one of the parts that I think I'm doing correctly, but don't know how to justify. To simplify things, I am claiming that instead of having $2^{n}$ possible values in round $n$ , we have a single value, which is the average of the $2^{n}$ values. So, for example, I can collapse the $2$ values for round $1$ into $\left(10001 + 5000\right)/2 = 7500.5$ . Then by doing so, it becomes clear that our recursion is $$ x_{n} = {1 \over 2}\left({x_{n - 1} \over 2} + x_{n - 1} + 1\right) $$ My first question is: how can I justify the ""collapsing"" ?. If you write out a few terms, you'll see that $$ x_{n} = 0.75^{n}\, x_{0} + \sum_{i = 0}^{n - 1}0.75^{i} \times 0.5 $$ My second question is, am I done here, or do I need to prove that the simplified $x_{n}$ that depends only on $x_{0}$ holds by induction ?. I found this formula by writing out a few items, and eyeballing/inducing things because there's a very clear pattern, so I feel like that's enough proof ?.","You start off with \$ . You flip a fair coin. If you get heads, you get paid \$ . If you get tails, you pay your friend half your current money. What is the expected amount of money you have after rounds ?. So let's define the initial amount as . Then in round 1, we expect Note in round , we could have possible values for . and . So in round , we could have possible values. So clearly at round , we have possible values, all with equal probability. Now this is one of the parts that I think I'm doing correctly, but don't know how to justify. To simplify things, I am claiming that instead of having possible values in round , we have a single value, which is the average of the values. So, for example, I can collapse the values for round into . Then by doing so, it becomes clear that our recursion is My first question is: how can I justify the ""collapsing"" ?. If you write out a few terms, you'll see that My second question is, am I done here, or do I need to prove that the simplified that depends only on holds by induction ?. I found this formula by writing out a few items, and eyeballing/inducing things because there's a very clear pattern, so I feel like that's enough proof ?.","10,000 1 n x_{0} = 10000 
x_{1} = {1 \over 2}\left({x \over 2} + x + 1\right)
 1 2 x_{1} 5000 10,001 2 4 n 2^{n} 2^{n} n 2^{n} 2 1 \left(10001 + 5000\right)/2 = 7500.5 
x_{n} = {1 \over 2}\left({x_{n - 1} \over 2} + x_{n - 1} + 1\right)
 
x_{n} = 0.75^{n}\, x_{0} + \sum_{i = 0}^{n - 1}0.75^{i} \times 0.5
 x_{n} x_{0}","['probability', 'induction', 'expected-value', 'gambling']"
31,probability group students to maximize expectation,probability group students to maximize expectation,,"Given $3n$ people that the $i^{\text{th}}$ person can pass a test with probability $p_i$ , now you are required to divide them to $n$ groups that each group has $3$ people. The score of one group equals $1$ if at least two people pass the test, $0$ otherwise. In order to maximize the expectation of total score, how do you group them? I've thought about this problem for a bit, and I think intuitively it makes sense to group two large $p_i$ with a small $p_i$ . Also, I've thought about in the optimal arrangement, swapping any two $p_i$ from different groups should lower the expectation. I can write out mathematically the difference in expectation when swapping two of the students, but it doesn't seem to give any obvious result. I've hit a wall.","Given people that the person can pass a test with probability , now you are required to divide them to groups that each group has people. The score of one group equals if at least two people pass the test, otherwise. In order to maximize the expectation of total score, how do you group them? I've thought about this problem for a bit, and I think intuitively it makes sense to group two large with a small . Also, I've thought about in the optimal arrangement, swapping any two from different groups should lower the expectation. I can write out mathematically the difference in expectation when swapping two of the students, but it doesn't seem to give any obvious result. I've hit a wall.",3n i^{\text{th}} p_i n 3 1 0 p_i p_i p_i,"['probability', 'optimization', 'algorithms']"
32,Fair gambler's ruin tail probability,Fair gambler's ruin tail probability,,"I'm looking at the following variant of the fair gambler's ruin problem: The gambler starts with 1 dollar. They repeatedly flip a fair coin. Heads, +1 dollar; Tails -1 dollar. The game stops when the gambler reaches 0 dollars. It is well known that the game ends with probability 1, and that the mean time for the game to end is infinite. I am interested in the following question: What is the (asymptotic) probability that the game is not yet over after $n$ flips? From a heuristic argument, I'm fairly certain that the answer is $\theta(1/\sqrt{n})$ . From simulation, it appears that the answer is about $0.8/\sqrt{n}$ . I'd like to know the exact answer, and I'd like to know how to derive it analytically. At least, I'd like to know how to prove that the probability is $\theta(1/\sqrt{n})$ . I'm guessing the proof involves a martingale, but I can't find it myself.","I'm looking at the following variant of the fair gambler's ruin problem: The gambler starts with 1 dollar. They repeatedly flip a fair coin. Heads, +1 dollar; Tails -1 dollar. The game stops when the gambler reaches 0 dollars. It is well known that the game ends with probability 1, and that the mean time for the game to end is infinite. I am interested in the following question: What is the (asymptotic) probability that the game is not yet over after flips? From a heuristic argument, I'm fairly certain that the answer is . From simulation, it appears that the answer is about . I'd like to know the exact answer, and I'd like to know how to derive it analytically. At least, I'd like to know how to prove that the probability is . I'm guessing the proof involves a martingale, but I can't find it myself.",n \theta(1/\sqrt{n}) 0.8/\sqrt{n} \theta(1/\sqrt{n}),"['probability', 'markov-chains', 'martingales', 'random-walk']"
33,A different approach to a common question,A different approach to a common question,,"A unit stick is randomly broken into 3 pieces, it is given that these three pieces can make a triangle, what is the expected length of the medium-sized piece? This a question we are all familiar with and anyone who has seen it anywhere/solved it knows that the expected length of the medium piece is $\frac{5}{18}$ , we reach this conclusion by using $E(L+M+S) = 1$ , and we know we can calculate $E(L)$ and $E(S)$ , so we just use $E(M) = 1-E(L)-E(S)$ to get our answer, is there any way we can solely calculate the $E(M)$ without calculating the other two values? $L$ : Length of the longest part $S$ : Length of the smallest part $M$ : Length of the medium part Thank you :)","A unit stick is randomly broken into 3 pieces, it is given that these three pieces can make a triangle, what is the expected length of the medium-sized piece? This a question we are all familiar with and anyone who has seen it anywhere/solved it knows that the expected length of the medium piece is , we reach this conclusion by using , and we know we can calculate and , so we just use to get our answer, is there any way we can solely calculate the without calculating the other two values? : Length of the longest part : Length of the smallest part : Length of the medium part Thank you :)",\frac{5}{18} E(L+M+S) = 1 E(L) E(S) E(M) = 1-E(L)-E(S) E(M) L S M,"['probability', 'geometric-probability']"
34,Estimating number of people in a group based on knowing the number of birthdays for today,Estimating number of people in a group based on knowing the number of birthdays for today,,"Lets say there is a group of people and we don't know how big is this group. Lets say that we are told that 3 people had a birthday today. For simplicity we can assume that birthdays are uniformly distributed and there is 365 days in a year. Can I, based on this information only, estimate the number of people in this group? Putting it other way I would like to answer the questions: Given that 3 people had a birthday today what is the probability that the group has 100 people?  Given that 3 people had a birthday today what is the probability that the group has 251 people? So lets X be a random variable representing a number of people in a group then P(X = x | number_of_people_who_had_birthday_today = n) is a probability of a group being of size x given number of the people having birthday today is n. It is obvious that: P(X = 0 | number_of_people_who_had_birthday_today = 3) = 0 P(X = 1 | number_of_people_who_had_birthday_today = 3) = 0 P(X = 2 | number_of_people_who_had_birthday_today = 3) = 0 since because 3 people had a birthday there must be at least 3 people in this  group. I would like to find formula for P. But, I struggle to put my head around it. If I would somehow be able to model the initial number of people in a room as some distribution with a given mean \mu. Lets say I would be coming back on some number of consecutive days and asking how many people had birthday today. Lets say that after 5 days I would get a list of answers [2,3,2,3,4]. I believe that I could use my initial distribution and the above list to somehow update my initial believe using Bayes theorem. But for that I would need P(N | x)(if I am not mistaken) but I don't know what it is.","Lets say there is a group of people and we don't know how big is this group. Lets say that we are told that 3 people had a birthday today. For simplicity we can assume that birthdays are uniformly distributed and there is 365 days in a year. Can I, based on this information only, estimate the number of people in this group? Putting it other way I would like to answer the questions: Given that 3 people had a birthday today what is the probability that the group has 100 people?  Given that 3 people had a birthday today what is the probability that the group has 251 people? So lets X be a random variable representing a number of people in a group then P(X = x | number_of_people_who_had_birthday_today = n) is a probability of a group being of size x given number of the people having birthday today is n. It is obvious that: P(X = 0 | number_of_people_who_had_birthday_today = 3) = 0 P(X = 1 | number_of_people_who_had_birthday_today = 3) = 0 P(X = 2 | number_of_people_who_had_birthday_today = 3) = 0 since because 3 people had a birthday there must be at least 3 people in this  group. I would like to find formula for P. But, I struggle to put my head around it. If I would somehow be able to model the initial number of people in a room as some distribution with a given mean \mu. Lets say I would be coming back on some number of consecutive days and asking how many people had birthday today. Lets say that after 5 days I would get a list of answers [2,3,2,3,4]. I believe that I could use my initial distribution and the above list to somehow update my initial believe using Bayes theorem. But for that I would need P(N | x)(if I am not mistaken) but I don't know what it is.",,"['probability', 'birthday']"
35,How to understand the difference between independent events and independent random variables?,How to understand the difference between independent events and independent random variables?,,"I'm trying to learn probability on my own and have recently been studying random variables. The book I'm using provides an explanation of why the criterion for event independence is different than the criterion for random variable independence but I just can't get my head around it. ""Definition 3.8.2 (Independence of many r.v.s). Random variables $X_1 , \ldots , X_n$ are independent if \begin{align} & P (X_1 \leq x_1 , \ldots , X_n \leq x_n ) \\[6pt] = {} & P (X_1 \leq x_1 ) \cdots P (X_n \leq x_n ), \text{ for all } x_1 , \ldots , x_n \in\mathbb R.\end{align} For infinitely many r.v.s, we say that they are independent if every finite subset of the r.v.s is independent. Comparing this to the criteria for independence of $n$ events, it may seem strange that the independence of $X_1 , \ldots , X_n$ requires just one equality, whereas for events we needed to verify pairwise independence for all $\binom{n}{2}$ pairs, three-way independence for all $\binom{n}{3}$ triplets, and so on. However, upon closer examination of the definition, we see that independence of r.v.s requires the equality to hold for all possible $x_1 , \ldots , x_n$ -- infinitely many conditions!"" So somehow, the criteria that each r.v. being tested for independence can take on any value and have the equality still hold allows us to infer that there is tuple-wise independence between each r.v. being tested as well, unlike the criteria for events. Can someone help illuminate this for me?","I'm trying to learn probability on my own and have recently been studying random variables. The book I'm using provides an explanation of why the criterion for event independence is different than the criterion for random variable independence but I just can't get my head around it. ""Definition 3.8.2 (Independence of many r.v.s). Random variables are independent if For infinitely many r.v.s, we say that they are independent if every finite subset of the r.v.s is independent. Comparing this to the criteria for independence of events, it may seem strange that the independence of requires just one equality, whereas for events we needed to verify pairwise independence for all pairs, three-way independence for all triplets, and so on. However, upon closer examination of the definition, we see that independence of r.v.s requires the equality to hold for all possible -- infinitely many conditions!"" So somehow, the criteria that each r.v. being tested for independence can take on any value and have the equality still hold allows us to infer that there is tuple-wise independence between each r.v. being tested as well, unlike the criteria for events. Can someone help illuminate this for me?","X_1 , \ldots , X_n \begin{align}
& P (X_1 \leq x_1 , \ldots , X_n \leq x_n ) \\[6pt]
= {} & P (X_1 \leq x_1 ) \cdots P (X_n \leq x_n ), \text{ for all } x_1 , \ldots , x_n \in\mathbb R.\end{align} n X_1 , \ldots , X_n \binom{n}{2} \binom{n}{3} x_1 , \ldots , x_n","['probability', 'random-variables', 'independence']"
36,Expected value of sum of a random variable where the upper limit is a random variable.,Expected value of sum of a random variable where the upper limit is a random variable.,,"Consider $X_i$ to denote the numerical value for the i-th event. Assume it is IID. Say we want to compute $$ c = E\left[\sum_{i=1}^NX_i\right] $$ $N$ is a random variable. You can think of it as represent the number of events needed to get some constant sum $c$ . My question is, can the above be simplified in the following manner? $$ c = \sum_{i=1}^NE[X_i] \\ = NE[X_i] $$","Consider to denote the numerical value for the i-th event. Assume it is IID. Say we want to compute is a random variable. You can think of it as represent the number of events needed to get some constant sum . My question is, can the above be simplified in the following manner?","X_i 
c = E\left[\sum_{i=1}^NX_i\right]
 N c 
c = \sum_{i=1}^NE[X_i] \\
= NE[X_i]
","['probability', 'random-variables', 'expected-value']"
37,"Expected number of fair coin tosses until 2 consequitive heads, a non-recurseive solution","Expected number of fair coin tosses until 2 consequitive heads, a non-recurseive solution",,"Trying to find the expected number of fair coin tosses until 2 consequitive heads fall, I didn't come up with the recursive solution initially and used a more 'iterative' or 'brute-force' approach, which lead me to a different answer, without any hints where I might be wrong. I couldn't find a similar solution on the Internet, to which I could compare mine, so I'd love if someone could point me to the flaw in my logic. Here is my attempt: Let $X$ be the random variable for which I'm searching the expected value $\text{E}X$ . I'm building a series $\sum_0^\infty n \cdot P(X=n)$ , and my goal is to find the probabiity that a game lasts $n$ tosses - $P(X = n)$ , for all $n \in \mathbb N$ . The general form of a single play is as follows: $$ \underbrace{\dots 0\,1\,0 \dots 0\,1\,0\dots0}_{n \,\text{tosses}}\;1\,1 $$ i.e. a bunch of heads, surrounded by tails, and two heads at the end. Denote the number of tosses before the final two heads with $n$ . It is clear there are at least 2 tosses in a single (successful) run, and $n \ge 0$ . For convenience I use $n$ for the tosses before the final two heads, and not for the length of the whole run. Now I need to count the possible plays for any given length (starting from 2), and the answer is then: $$\text{E}X := \sum_{t=0}^\infty t \cdot P(X=t) = \sum_{n=0}^\infty (n+2) \cdot \frac{\text{No. of valid non-final parts of length } n}{2^{n+2}}$$ (The second sum in fact skips runs of length 0 and 1 as they contribute nothing to the expected value.) The number of valid plays of length $n$ I find by looking at all possible cases for the number of heads in the non-final part of the string - let's call that $k$ . For a given $n$ , the number of non-final heads can be at most half of $n$ , since each head must be followed by a tail. Let's fix an $n \in \mathbb N$ and a number of heads $k \in [0,\lfloor \frac{n}{2}\rfloor]$ . The picture in my head is like this: $$ \|\,(10)\,\|\,(10)\,\|\,\dots\,\|\,(10)\,\| \; 1\, 1 $$ where "" $\|$ ""s represent the $k + 1$ placeholders for the $n-2k$ tails I must arrange around the $k$ head-tail pairs in a $(n + 2)$ -toss-long play. The total number of positions to ""put stuff"" (tails and head-tails pairs) is $(k + 1) + (n-2k) = n - k + 1$ . Moreover, every configuration is uniquely described by the positions of the $k$ head-tail pairs, and all possible positions of $k$ head-tail pairs make up a valid toss sequence. Therefore, given $n$ and $k$ , the number of valid runs with $k$ non-final tails of length $n+2$ is $\binom{n-k+1}{k}$ . (These 2-3 lines were a part I suspected for some time that it could be wrong, but I cannot see any mistakes here.) Letting $k$ range over $[0, \lfloor \frac{n}{2} \rfloor]$ , the probability that a play lasts $n + 2$ tosses is: $$P(X = n+2) = \frac{\sum_{k=0}^{ \lfloor n / 2 \rfloor} \binom{n-k+1}{k}}{2^{n+2}}$$ And finally, the series for the expected value: $$\text{E}X = \sum_{n=0}^\infty n \cdot P(X=n) = \sum_{n=0}^\infty \left(\frac{n+2}{2^{n+2}}\cdot\sum_{k=0}^{ \lfloor n / 2 \rfloor} \binom{n-k+1}{k}\right)$$ Giving this to Wolfram Mathematica, I see that it quickly converges to $8.888...$ . After 2 or 3 random attempts to ""make it work"" I found that removing the ""+ 1"" part in the binomial coefficient produces the correct answer (6), so I thought this part could be wrong. There should definitely be a $+1$ in it, though (for the reasons I explained above), and I think it's just a coincidence that I get the correct answer this way. As much as I hope that is not the case, it's possible that only my code is wrong, here's it for reference: https://pastebin.com/iuPW7f8H (I couldn't make it compute the actual limit so I checked the result for some sample points). (I use the words 'run' and 'play' interchangably for a single sequence of tosses in a valid experiment as said in the problem, please let me know if there's a more standard term for this.)","Trying to find the expected number of fair coin tosses until 2 consequitive heads fall, I didn't come up with the recursive solution initially and used a more 'iterative' or 'brute-force' approach, which lead me to a different answer, without any hints where I might be wrong. I couldn't find a similar solution on the Internet, to which I could compare mine, so I'd love if someone could point me to the flaw in my logic. Here is my attempt: Let be the random variable for which I'm searching the expected value . I'm building a series , and my goal is to find the probabiity that a game lasts tosses - , for all . The general form of a single play is as follows: i.e. a bunch of heads, surrounded by tails, and two heads at the end. Denote the number of tosses before the final two heads with . It is clear there are at least 2 tosses in a single (successful) run, and . For convenience I use for the tosses before the final two heads, and not for the length of the whole run. Now I need to count the possible plays for any given length (starting from 2), and the answer is then: (The second sum in fact skips runs of length 0 and 1 as they contribute nothing to the expected value.) The number of valid plays of length I find by looking at all possible cases for the number of heads in the non-final part of the string - let's call that . For a given , the number of non-final heads can be at most half of , since each head must be followed by a tail. Let's fix an and a number of heads . The picture in my head is like this: where "" ""s represent the placeholders for the tails I must arrange around the head-tail pairs in a -toss-long play. The total number of positions to ""put stuff"" (tails and head-tails pairs) is . Moreover, every configuration is uniquely described by the positions of the head-tail pairs, and all possible positions of head-tail pairs make up a valid toss sequence. Therefore, given and , the number of valid runs with non-final tails of length is . (These 2-3 lines were a part I suspected for some time that it could be wrong, but I cannot see any mistakes here.) Letting range over , the probability that a play lasts tosses is: And finally, the series for the expected value: Giving this to Wolfram Mathematica, I see that it quickly converges to . After 2 or 3 random attempts to ""make it work"" I found that removing the ""+ 1"" part in the binomial coefficient produces the correct answer (6), so I thought this part could be wrong. There should definitely be a in it, though (for the reasons I explained above), and I think it's just a coincidence that I get the correct answer this way. As much as I hope that is not the case, it's possible that only my code is wrong, here's it for reference: https://pastebin.com/iuPW7f8H (I couldn't make it compute the actual limit so I checked the result for some sample points). (I use the words 'run' and 'play' interchangably for a single sequence of tosses in a valid experiment as said in the problem, please let me know if there's a more standard term for this.)","X \text{E}X \sum_0^\infty n \cdot P(X=n) n P(X = n) n \in \mathbb N  \underbrace{\dots 0\,1\,0 \dots 0\,1\,0\dots0}_{n \,\text{tosses}}\;1\,1  n n \ge 0 n \text{E}X := \sum_{t=0}^\infty t \cdot P(X=t) = \sum_{n=0}^\infty (n+2) \cdot \frac{\text{No. of valid non-final parts of length } n}{2^{n+2}} n k n n n \in \mathbb N k \in [0,\lfloor \frac{n}{2}\rfloor]  \|\,(10)\,\|\,(10)\,\|\,\dots\,\|\,(10)\,\| \; 1\, 1  \| k + 1 n-2k k (n + 2) (k + 1) + (n-2k) = n - k + 1 k k n k k n+2 \binom{n-k+1}{k} k [0, \lfloor \frac{n}{2} \rfloor] n + 2 P(X = n+2) = \frac{\sum_{k=0}^{ \lfloor n / 2 \rfloor} \binom{n-k+1}{k}}{2^{n+2}} \text{E}X = \sum_{n=0}^\infty n \cdot P(X=n) = \sum_{n=0}^\infty \left(\frac{n+2}{2^{n+2}}\cdot\sum_{k=0}^{ \lfloor n / 2 \rfloor} \binom{n-k+1}{k}\right) 8.888... +1","['probability', 'combinatorics']"
38,What is the jacobian factor?,What is the jacobian factor?,,"The excercise from the book I am solving problem 1.4 of the famous book Pattern recognition and machine learning of Bishop. The idea of the exercise is that in a simple function $f(x)$ the maximum is the same if we apply a transformation $x = g(y)$ . However, in the case of a probability density, this does not hold anymore. I have solved the exercise, but Bishop says this happens because of the Jacobian factor and I do not understand what this means. Could someone help me with this concept?","The excercise from the book I am solving problem 1.4 of the famous book Pattern recognition and machine learning of Bishop. The idea of the exercise is that in a simple function the maximum is the same if we apply a transformation . However, in the case of a probability density, this does not hold anymore. I have solved the exercise, but Bishop says this happens because of the Jacobian factor and I do not understand what this means. Could someone help me with this concept?",f(x) x = g(y),"['probability', 'machine-learning', 'density-function', 'jacobian', 'pattern-recognition']"
39,Method of Indicators Random Variables Problem and the Hiring Problem,Method of Indicators Random Variables Problem and the Hiring Problem,,"I'm trying to do the following problem from The Probability Tutoring Book by Carol Ash. Pick numbers at random between $0$ and $1$ . The $i^{th}$ number sets a ""record"" if it's larger than all of it's predecessors. For example, the sequence $.1, .04, .3, .12, .6, .5$ has $3$ record setters $(.1, .3, .6)$ . We always take the first number to be a record setter. Find the expected number of record setters. This problem reminded me of the hiring problem which is set up like so: Each day a new candidate comes to interview for a job. We hire the $i^{\text{th}}$ person if that person is more qualified than everyone who came before. We interview for $n$ days. What is the expected number of people we hire? We can proceed to do the problem by reasoning like so: Let $X$ be the number of people we hire. $$X = X_1 + X_2 + ... + X_n$$ where $X_i = 1$ if we hire that person and $X_i = 0$ otherwise. Well the probability that the best person is on the $i^{th}$ day is $\frac {1}{i}$ since all of the people have the same potential to be the most qualified candidate. Now this becomes a simple exercise in linearity of expectation : $$E[X] = \sum_i {E[X_i]} = \sum_i {\frac{1}{i}} = O(\log(n))$$ At first I thought this reasoning would easily apply to my ""record setting"" problem (which according to the solutions at the end of the book it does). However, something rubs me the wrong. Why doesn't the probability that $i^{th}$ number is the highest so far depend on what values the previous numbers are? For example, $$P(2^{\text{nd}}\ \text{number highest}) = 1 - n_1 $$ where $n_1$ is the first number we choose and $$P(i^{\text{th}}\ \text{number highest}) = 1 - \max(n_1, n_2, n_3, ..., n_{i-1}) $$ . Suddenly my reasoning for the hiring problem, ""all of the people have the same potential to be the most qualified candidate"" doesn't hold up. Can someone see where my logic went wrong? Any help would be helpful. :)","I'm trying to do the following problem from The Probability Tutoring Book by Carol Ash. Pick numbers at random between and . The number sets a ""record"" if it's larger than all of it's predecessors. For example, the sequence has record setters . We always take the first number to be a record setter. Find the expected number of record setters. This problem reminded me of the hiring problem which is set up like so: Each day a new candidate comes to interview for a job. We hire the person if that person is more qualified than everyone who came before. We interview for days. What is the expected number of people we hire? We can proceed to do the problem by reasoning like so: Let be the number of people we hire. where if we hire that person and otherwise. Well the probability that the best person is on the day is since all of the people have the same potential to be the most qualified candidate. Now this becomes a simple exercise in linearity of expectation : At first I thought this reasoning would easily apply to my ""record setting"" problem (which according to the solutions at the end of the book it does). However, something rubs me the wrong. Why doesn't the probability that number is the highest so far depend on what values the previous numbers are? For example, where is the first number we choose and . Suddenly my reasoning for the hiring problem, ""all of the people have the same potential to be the most qualified candidate"" doesn't hold up. Can someone see where my logic went wrong? Any help would be helpful. :)","0 1 i^{th} .1, .04, .3, .12, .6, .5 3 (.1, .3, .6) i^{\text{th}} n X X = X_1 + X_2 + ... + X_n X_i = 1 X_i = 0 i^{th} \frac {1}{i} E[X] = \sum_i {E[X_i]} = \sum_i {\frac{1}{i}} = O(\log(n)) i^{th} P(2^{\text{nd}}\ \text{number highest}) = 1 - n_1  n_1 P(i^{\text{th}}\ \text{number highest}) = 1 - \max(n_1, n_2, n_3, ..., n_{i-1}) ","['probability', 'discrete-mathematics', 'algorithms', 'random-variables']"
40,Ito process and martingale.,Ito process and martingale.,,"Suppose $X$ is an Ito process with $K=0$ . Prove or disprove $X_t^2 - \langle X\rangle_t$ is a martingale. My attempt is: $X_t = X_0 + \int_0^t K_s ds + \int_0^t H_s dW_s$ this is Ito process. And so, If X is Ito process, with K=0, then $X_t = X_0 + \int^t_0 H_s dW_s$ or $dX_t = H_t dW_t$ And also $X_t^2 - \langle X\rangle_t =X_t^2 - dX_t dX_t = X_t^2 - H_t^2 d t$ Well I o order to be martingale, I need to show that $E[  X_t^2 - H_t^2 d t | F_s] =  X_s^2 - H_s^2 d s$ for $s\le t $ . But I cannot show this martingale part. Please help me to do this part. Thanks a lot.","Suppose is an Ito process with . Prove or disprove is a martingale. My attempt is: this is Ito process. And so, If X is Ito process, with K=0, then or And also Well I o order to be martingale, I need to show that for . But I cannot show this martingale part. Please help me to do this part. Thanks a lot.",X K=0 X_t^2 - \langle X\rangle_t X_t = X_0 + \int_0^t K_s ds + \int_0^t H_s dW_s X_t = X_0 + \int^t_0 H_s dW_s dX_t = H_t dW_t X_t^2 - \langle X\rangle_t =X_t^2 - dX_t dX_t = X_t^2 - H_t^2 d t E[  X_t^2 - H_t^2 d t | F_s] =  X_s^2 - H_s^2 d s s\le t ,"['calculus', 'probability', 'stochastic-processes', 'stochastic-calculus', 'self-learning']"
41,Expected number of matching pairs from a random list,Expected number of matching pairs from a random list,,"Question A random list of length $n$ (even number) consists of $n_1$ stars $\star$ and $n_2$ squares $\square$ . Suppose we randomly put these shapes into $n/2$ pairs, denote: $X_1$ to be the number of matching pairs of $\star$ $X_2$ to be the number of matching pairs of $\square$ What is the expected number of $X_1$ and $X_2$ ? Example For example, if $n=10$ , $n_1=7, n_2=3$ , suppose we have a random pattern of 5 pairs \begin{align*} \star ~\square \\ \star ~\star \\ \square ~\square \\ \star ~\star \\ \star ~\star \end{align*} Because there are 3 matching pairs for $\star$ and 1 matching pair for $\square$ , we have $X_1=3, X_2=1$ . If we repeat this process many times, we should have different patterns of pairs, and produce different values of $X_1$ and $X_2$ . I'm wondering how to calculate their expected values $E[X_1]$ and $E[X_2]$ , which should be functions on $n_1$ and $n_2$ . The problem comes from my research project. Thank you in advance.","Question A random list of length (even number) consists of stars and squares . Suppose we randomly put these shapes into pairs, denote: to be the number of matching pairs of to be the number of matching pairs of What is the expected number of and ? Example For example, if , , suppose we have a random pattern of 5 pairs Because there are 3 matching pairs for and 1 matching pair for , we have . If we repeat this process many times, we should have different patterns of pairs, and produce different values of and . I'm wondering how to calculate their expected values and , which should be functions on and . The problem comes from my research project. Thank you in advance.","n n_1 \star n_2 \square n/2 X_1 \star X_2 \square X_1 X_2 n=10 n_1=7, n_2=3 \begin{align*}
\star ~\square \\
\star ~\star \\
\square ~\square \\
\star ~\star \\
\star ~\star
\end{align*} \star \square X_1=3, X_2=1 X_1 X_2 E[X_1] E[X_2] n_1 n_2","['probability', 'combinatorics', 'expected-value']"
42,Convergence of integral of function of Brownian Motion,Convergence of integral of function of Brownian Motion,,"Let $B$ be a Brownian motion in $\mathbb{R}^2$ and $f$ be a continuous bounded probablity density function in $\mathbb{R}^2$ . Define $$ A_t = \int_0^t f(B_s) ds $$ Show that: i) $\mathbb{E} [\frac{A_t}{t}] \to 0$ as $t \to \infty$ ; ii) $A_t \to \infty$ as $t \to \infty$ . I tried to exploit neighbourhood recurrence and the strong markov propertyf or part (ii) but couldn't conclude, while I'm completely lost on (i). Any help/hint?","Let be a Brownian motion in and be a continuous bounded probablity density function in . Define Show that: i) as ; ii) as . I tried to exploit neighbourhood recurrence and the strong markov propertyf or part (ii) but couldn't conclude, while I'm completely lost on (i). Any help/hint?","B \mathbb{R}^2 f \mathbb{R}^2 
A_t = \int_0^t f(B_s) ds
 \mathbb{E} [\frac{A_t}{t}] \to 0 t \to \infty A_t \to \infty t \to \infty","['probability', 'probability-theory', 'stochastic-processes', 'brownian-motion']"
43,"However, how long will it take to randomly generate an $n$-universal word?","However, how long will it take to randomly generate an -universal word?",n,"Suppose $A$ is a finite alphabet, $|A| = m$ . Let's call a word $w \in A^*$ $n$ -universal iff it contains every word from $A^n$ as a subword. Now, suppose we generate a random $n$ -universal word in a following way: we start with the empty word and each step add to the right of it a symbol that we generate independently under uniform distribution. That lasts until we our word becomes $n$ -universal (in the long run we will almost surely get it due to the infinite monkey theorem). However, how long will it take? Let's denote the expected length of the word generated that way/expected number of turns to generate it as $Eu(n, m)$ . I would like to know the value of $Eu(n, m)$ (or at least its asymptotic for large $n$ and $m$ ). For $m = 1$ : as there is only one word of length $n$ , thus we are guaranteed to get it at $n$ -th turn. Thus $Eu(n, 1) = n$ . For $n = 1$ ,  we will generate an arbitrary symbol, then wait till a symbol that was not generated before is generated. Repeat this until the set of symbols is exhausted. Thus $Eu(1, m) = m(\sum_{i = 1}^{m} \frac{1}{i}) = m(ln(m) + \gamma) + O(1)$ For $n = m = 2$ , we first generate two symbols. If they are the same, we will wait till the other symbol is generated and then wait what comes after it. If it is the same then we only have to  wait till the initial symbol appears again.  Otherwise, we need to wait till that other symbol appears again twice in a row. If two initial symbols are different, we will generate an additional one. If it the same as the previous one, we will wait till two first symbols come it a row. Otherwise we will wait till two second symbols come in a row. Thus $Eu(2, 2) = 2 + \frac{1}{2}(2 + \frac{1}{2}6 + \frac{1}{2}2) + \frac{1}{2}(\frac{1}{2} + 6) = \frac{33}{4}$ However, I do not know how to calculate it for different $(n, m)$ .","Suppose is a finite alphabet, . Let's call a word -universal iff it contains every word from as a subword. Now, suppose we generate a random -universal word in a following way: we start with the empty word and each step add to the right of it a symbol that we generate independently under uniform distribution. That lasts until we our word becomes -universal (in the long run we will almost surely get it due to the infinite monkey theorem). However, how long will it take? Let's denote the expected length of the word generated that way/expected number of turns to generate it as . I would like to know the value of (or at least its asymptotic for large and ). For : as there is only one word of length , thus we are guaranteed to get it at -th turn. Thus . For ,  we will generate an arbitrary symbol, then wait till a symbol that was not generated before is generated. Repeat this until the set of symbols is exhausted. Thus For , we first generate two symbols. If they are the same, we will wait till the other symbol is generated and then wait what comes after it. If it is the same then we only have to  wait till the initial symbol appears again.  Otherwise, we need to wait till that other symbol appears again twice in a row. If two initial symbols are different, we will generate an additional one. If it the same as the previous one, we will wait till two first symbols come it a row. Otherwise we will wait till two second symbols come in a row. Thus However, I do not know how to calculate it for different .","A |A| = m w \in A^* n A^n n n Eu(n, m) Eu(n, m) n m m = 1 n n Eu(n, 1) = n n = 1 Eu(1, m) = m(\sum_{i = 1}^{m} \frac{1}{i}) = m(ln(m) + \gamma) + O(1) n = m = 2 Eu(2, 2) = 2 + \frac{1}{2}(2 + \frac{1}{2}6 + \frac{1}{2}2) + \frac{1}{2}(\frac{1}{2} + 6) = \frac{33}{4} (n, m)","['probability', 'combinatorics', 'stochastic-processes', 'coupon-collector', 'combinatorics-on-words']"
44,Expected value of squared uniform distribution,Expected value of squared uniform distribution,,Let $X \sim \text{Unif}(\sqrt n S^{n-1})$ where $S^{n-1}$ is the unit Sphere in $\mathbb{R}^n$ . I'm trying to prove that $\mathbb{E}(\left \| X \right \|^2)=n$ . An interesting fact here is the rotational invariance of the distribution of $X$ . I have used it to prove that $\mathbb{E}( X_i^2)$ is a constant $\alpha$ but I didn't find an argument that helps me determine the constant factor $\alpha$ . Does anyone have a hint or an idea?,Let where is the unit Sphere in . I'm trying to prove that . An interesting fact here is the rotational invariance of the distribution of . I have used it to prove that is a constant but I didn't find an argument that helps me determine the constant factor . Does anyone have a hint or an idea?,X \sim \text{Unif}(\sqrt n S^{n-1}) S^{n-1} \mathbb{R}^n \mathbb{E}(\left \| X \right \|^2)=n X \mathbb{E}( X_i^2) \alpha \alpha,"['probability', 'probability-theory', 'probability-distributions']"
45,Using Law of Iterated Logarithm to calculate limits,Using Law of Iterated Logarithm to calculate limits,,"Suppose $X_i$ are i.i.d., $\mathbb{E}X_1 = 0$ , $\mathbb{E}X^2_1<\infty$ and $S_n = \sum_{i=1}^n X_i$ I am to calculate three following limits: $\liminf_{n \to \infty} \frac{S_n}{ \sqrt{n \ln ( \ln(n))}}$ $\lim_{n \to \infty} \frac{S_n}{n^{\alpha}}$ where $\alpha > \frac{1}{2}$ $\lim_{n \to \infty} \frac{-S_n}{\sqrt{n}lnn}$ The first one was relatively easy, and I got $-\sqrt{2 \mathbb{E}X^2_1}$ as result (using symmetry and LIL Hartman's-Winter). I got stuck on the next two however. What can be done here?","Suppose are i.i.d., , and I am to calculate three following limits: where The first one was relatively easy, and I got as result (using symmetry and LIL Hartman's-Winter). I got stuck on the next two however. What can be done here?",X_i \mathbb{E}X_1 = 0 \mathbb{E}X^2_1<\infty S_n = \sum_{i=1}^n X_i \liminf_{n \to \infty} \frac{S_n}{ \sqrt{n \ln ( \ln(n))}} \lim_{n \to \infty} \frac{S_n}{n^{\alpha}} \alpha > \frac{1}{2} \lim_{n \to \infty} \frac{-S_n}{\sqrt{n}lnn} -\sqrt{2 \mathbb{E}X^2_1},"['probability', 'probability-theory', 'random-walk']"
46,Monotonicity of a fraction combined with series (related to probability distributions),Monotonicity of a fraction combined with series (related to probability distributions),,"Let $(p_n)_{n \geq 0}$ be a probability distribution on $\mathbb{N}_0$ with finite expectation, thus $\sum_{n = 0}^\infty p_n = 1$ and $\sum_{n=0}^\infty n \, p_n < \infty$ . I want to show that for all $0 \leq s \leq t < 1$ $$ \frac{\sum_{n=1}^{\infty} (1-s^n)\,  n \, p_n}{\sum_{n=1}^{\infty} (1-s^n)\, p_n} \leq \frac{\sum_{n=1}^{\infty} (1-t^n)\,  n \, p_n}{\sum_{n=1}^{\infty} (1-t^n)\, p_n}. $$ It is actually a little bit surprising to me that this is true as I thought that the $n$ in the numerator increases the weight of the bigger choice of $t$ compared to the denominator, but I plotted the function for some choices of $(p_n)$ and found that it is indeed increasing. Any ideas for formal proofs or arguments are appreciated.","Let be a probability distribution on with finite expectation, thus and . I want to show that for all It is actually a little bit surprising to me that this is true as I thought that the in the numerator increases the weight of the bigger choice of compared to the denominator, but I plotted the function for some choices of and found that it is indeed increasing. Any ideas for formal proofs or arguments are appreciated.","(p_n)_{n \geq 0} \mathbb{N}_0 \sum_{n = 0}^\infty p_n = 1 \sum_{n=0}^\infty n \, p_n < \infty 0 \leq s \leq t < 1  \frac{\sum_{n=1}^{\infty} (1-s^n)\,  n \, p_n}{\sum_{n=1}^{\infty} (1-s^n)\, p_n} \leq \frac{\sum_{n=1}^{\infty} (1-t^n)\,  n \, p_n}{\sum_{n=1}^{\infty} (1-t^n)\, p_n}.  n t (p_n)","['probability', 'sequences-and-series', 'inequality', 'monotone-functions']"
47,Probability distribution vs. probability function,Probability distribution vs. probability function,,"Is there a difference between the expressions ""probability distribution"" and ""probability function"" or are they just synonyms?","Is there a difference between the expressions ""probability distribution"" and ""probability function"" or are they just synonyms?",,"['probability', 'terminology']"
48,"Prokhorov's Theorem : The Statement. Precompact, Sequentially Compact, Relatively Compact : Definitions.","Prokhorov's Theorem : The Statement. Precompact, Sequentially Compact, Relatively Compact : Definitions.",,"Let $S$ be a Polish space (a complete separable metric space), Let $\mathcal{P}(S)$ be the space of Borel probability measures on $S$ (the Borel sets are induced by the metric on the space $S$ ). Next I give the statement of Prokhorov's Theorem as I know it. $\textbf{Prokhorov's Theorem :}$ $\textbf{ (Bilingsley Convergence of Probability Measures page 37)  }$ A subset $\mathcal{M}\subset \mathcal{P}(S)$ is tight if and only if it is relatively compact. Now some definitions : $\textbf{Definition 1. : (Bilingsley page 35)} $ A subset $\mathcal{M}\subset\mathcal{P}(S)$ is $\textit{relatively compact}$ if every sequence has a weakly convergent sub-sequence. That is for $\{\mu_k\}\subset \mathcal{M}$ , there exists $\{\mu_{k_{m}}\}\subset \mathcal{M}$ such that $\mu_{k_{m}}\overset{weakly}{\longrightarrow}\mu \in \mathcal{P}(S)$ . $\textbf{Definition 2. : (Wikipedia Webpage Sequentially Compact) } $ A topological space $X$ is $\textit{Sequentially Compact}$ if every sequence in $X$ has a subsequence converging in $X$ . (Notice the convergence is w.r.t the topology, not necessarily the weak topology. $\textbf{Definition 3. : (Wikipedia Webpage Precompact) } $ A subset $Y$ of a topological space $X$ is precompact (relatively compact) if its closure is compact. $\textbf{Question 1:}$ The definitions 1. and 3. both use the term 'relatively compact' to mean different things, are either of them 'correct'?. $\textbf{Question 2:}$ I have seen Prokhorov's Theorem stated slightly differently in some places : for example if a subset $\mathcal{M}\subset \mathcal{P}(S)$ is tight : Wikipedia says $\mathcal{M}$ is sequentially compact. In other places I have seen it said that $\mathcal{M}$ is precompact. Or we have that $\mathcal{M}$ is relatively compact, as I stated before. Which of these is correct, are they in fact the same?","Let be a Polish space (a complete separable metric space), Let be the space of Borel probability measures on (the Borel sets are induced by the metric on the space ). Next I give the statement of Prokhorov's Theorem as I know it. A subset is tight if and only if it is relatively compact. Now some definitions : A subset is if every sequence has a weakly convergent sub-sequence. That is for , there exists such that . A topological space is if every sequence in has a subsequence converging in . (Notice the convergence is w.r.t the topology, not necessarily the weak topology. A subset of a topological space is precompact (relatively compact) if its closure is compact. The definitions 1. and 3. both use the term 'relatively compact' to mean different things, are either of them 'correct'?. I have seen Prokhorov's Theorem stated slightly differently in some places : for example if a subset is tight : Wikipedia says is sequentially compact. In other places I have seen it said that is precompact. Or we have that is relatively compact, as I stated before. Which of these is correct, are they in fact the same?",S \mathcal{P}(S) S S \textbf{Prokhorov's Theorem :} \textbf{ (Bilingsley Convergence of Probability Measures page 37)  } \mathcal{M}\subset \mathcal{P}(S) \textbf{Definition 1. : (Bilingsley page 35)}  \mathcal{M}\subset\mathcal{P}(S) \textit{relatively compact} \{\mu_k\}\subset \mathcal{M} \{\mu_{k_{m}}\}\subset \mathcal{M} \mu_{k_{m}}\overset{weakly}{\longrightarrow}\mu \in \mathcal{P}(S) \textbf{Definition 2. : (Wikipedia Webpage Sequentially Compact) }  X \textit{Sequentially Compact} X X \textbf{Definition 3. : (Wikipedia Webpage Precompact) }  Y X \textbf{Question 1:} \textbf{Question 2:} \mathcal{M}\subset \mathcal{P}(S) \mathcal{M} \mathcal{M} \mathcal{M},"['probability', 'general-topology', 'probability-theory', 'metric-spaces', 'compactness']"
49,The probability that a continuous random variable equals a certain value is 0: Does that apply to finding even/odd values??,The probability that a continuous random variable equals a certain value is 0: Does that apply to finding even/odd values??,,"I understand that the probability for any X to equal a certain value is 0 (X is a continuous random variable with a given probability density function (pdf)). However, does that apply to finding the probability that X is even, or that X is odd? For example, the way I see it, it would be like P(X is odd) = P(X = 1 or 3 etc. from the interval a to b). Which means that the probability here is 0 by the rule above. Am I looking at this wrong? Should I be looking at it as the total number of odd x's by using 'and', not 'or', however that still would not be a range to find an integral? (x is an integer on the graph). I am working with a uniform distribution. To clarify, I want to find P(X is odd) on my range of values, and X is a continuous random variable with a pdf.","I understand that the probability for any X to equal a certain value is 0 (X is a continuous random variable with a given probability density function (pdf)). However, does that apply to finding the probability that X is even, or that X is odd? For example, the way I see it, it would be like P(X is odd) = P(X = 1 or 3 etc. from the interval a to b). Which means that the probability here is 0 by the rule above. Am I looking at this wrong? Should I be looking at it as the total number of odd x's by using 'and', not 'or', however that still would not be a range to find an integral? (x is an integer on the graph). I am working with a uniform distribution. To clarify, I want to find P(X is odd) on my range of values, and X is a continuous random variable with a pdf.",,"['probability', 'probability-distributions', 'random-variables']"
50,Representation and expected value of a certain simple r.v.,Representation and expected value of a certain simple r.v.,,"Let $(\Omega,\mathcal{F},P)$ denote the probability space on which all of the following random variables are defined and $\omega\in\Omega$ . Let $X$ denote a non-negative random variable and $X_n,n\geq 1$ a random variable which is defined as follows: $$X_n (\omega) = \sum_{k=1}^{n2^n} \frac{k - 1}{2^n}\cdot\mathbf{1}_{X (\omega)\in\left[\frac{k - 1}{2^n}, \frac{k}{2^n}\right)} + n\cdot\mathbf{1}_{X (\omega)\in \left[n,\infty\right)}.\tag{$\ast$}$$ I see that $X_n$ is simple. I want to find its expected value. In Billingsley (1995): Probability and Measure it says on p. 68 (Equation (5.2)) that a simple random variable $Y$ has the form $$Y (\omega) = \sum_i y_i \mathbf{1}_{\omega\in A_i},\tag{$\ast\ast$}$$ where the $y_i$ are the values taken by $Y$ and the $A_i$ form a partition of $\Omega$ . On p. 76 (Equation (5.15)) the expected value of a simple random variable in the form $(\ast\ast)$ is given by $$E\left[Y\right] = \sum_i y_i P(A_i).$$ My understanding is that $(\ast)$ is not in the form $(\ast\ast)$ because of $X (\omega)$ instead of $\omega$ as argument of the indicator functions. Is that correct? How can I obtain $(\ast)$ in the form $(\ast\ast)$ ? Or is that not a path to the expected value of $(\ast)$ ?",Let denote the probability space on which all of the following random variables are defined and . Let denote a non-negative random variable and a random variable which is defined as follows: I see that is simple. I want to find its expected value. In Billingsley (1995): Probability and Measure it says on p. 68 (Equation (5.2)) that a simple random variable has the form where the are the values taken by and the form a partition of . On p. 76 (Equation (5.15)) the expected value of a simple random variable in the form is given by My understanding is that is not in the form because of instead of as argument of the indicator functions. Is that correct? How can I obtain in the form ? Or is that not a path to the expected value of ?,"(\Omega,\mathcal{F},P) \omega\in\Omega X X_n,n\geq 1 X_n (\omega) = \sum_{k=1}^{n2^n} \frac{k - 1}{2^n}\cdot\mathbf{1}_{X (\omega)\in\left[\frac{k - 1}{2^n}, \frac{k}{2^n}\right)} + n\cdot\mathbf{1}_{X (\omega)\in \left[n,\infty\right)}.\tag{\ast} X_n Y Y (\omega) = \sum_i y_i \mathbf{1}_{\omega\in A_i},\tag{\ast\ast} y_i Y A_i \Omega (\ast\ast) E\left[Y\right] = \sum_i y_i P(A_i). (\ast) (\ast\ast) X (\omega) \omega (\ast) (\ast\ast) (\ast)","['probability', 'probability-theory', 'random-variables']"
51,"Calculate $\mathbb{E}(X-Y\mid 2X+Y).$ if $X\sim N(0,a)$ and $Y\sim N(0,b)$",Calculate  if  and,"\mathbb{E}(X-Y\mid 2X+Y). X\sim N(0,a) Y\sim N(0,b)","Question: Given that $X$ and $Y$ are two random variables  satisfying $X\sim N(0,a)$ and $Y\sim N(0,b)$ for some $a,b>0$ . Assume that $X$ and $Y$ have correlation $\rho.$ Calculate $$\mathbb{E}(X-Y \mid 2X+Y).$$ I tried to use the fact that if $A$ and $B$ are independent, then $\mathbb{E}(A\mid B) = \mathbb{E}(A)$ and uncorrelated implies independence in jointly normal distribution. So, I attempted to express $X-Y$ as a linear combination of $2X+Y$ and $Z$ where $\operatorname{Cov}(2X+Y,Z) = 0.$ But I am not able to do so. Any hint is appreciated.","Question: Given that and are two random variables  satisfying and for some . Assume that and have correlation Calculate I tried to use the fact that if and are independent, then and uncorrelated implies independence in jointly normal distribution. So, I attempted to express as a linear combination of and where But I am not able to do so. Any hint is appreciated.","X Y X\sim N(0,a) Y\sim N(0,b) a,b>0 X Y \rho. \mathbb{E}(X-Y \mid 2X+Y). A B \mathbb{E}(A\mid B) = \mathbb{E}(A) X-Y 2X+Y Z \operatorname{Cov}(2X+Y,Z) = 0.","['probability', 'normal-distribution', 'conditional-expectation', 'expected-value']"
52,Candies drawn from both bowls,Candies drawn from both bowls,,"Bowl $1$ contains $N_1$ candies, all different from each other. Bowl $2$ contains $N_2$ candies, all different from each other. However there are $p$ candies identical across the two bowls. In other words, the first bowl contains $p$ candies identical to as many candies in the second bowl and $N_1 - p$ candies that have no equivalent in the second bowl. Similarly, the second bowl contains $p$ candies that are identical to as many candies in the first bowl, and $N_2 - p$ candies that have no equivalent in the first bowl. Now suppose I draw $m_1$ random candies from the first bowl and $m_2$ from the second one. What is the mean number of candy pairs that I will be drawing? In other words, how many of those $m_1$ candies I draw will be identical to some candies I'm drawing from the second bowl? Or equivalently, how many of the $m_2$ candies I have drawn from the second bowl will be identical to some of the $m_1$ candies I have drawn from the first bowl?","Bowl contains candies, all different from each other. Bowl contains candies, all different from each other. However there are candies identical across the two bowls. In other words, the first bowl contains candies identical to as many candies in the second bowl and candies that have no equivalent in the second bowl. Similarly, the second bowl contains candies that are identical to as many candies in the first bowl, and candies that have no equivalent in the first bowl. Now suppose I draw random candies from the first bowl and from the second one. What is the mean number of candy pairs that I will be drawing? In other words, how many of those candies I draw will be identical to some candies I'm drawing from the second bowl? Or equivalently, how many of the candies I have drawn from the second bowl will be identical to some of the candies I have drawn from the first bowl?",1 N_1 2 N_2 p p N_1 - p p N_2 - p m_1 m_2 m_1 m_2 m_1,"['probability', 'combinatorics', 'expected-value']"
53,About uniform distribution and marginal PDF.,About uniform distribution and marginal PDF.,,"Let S be the shadowed region: Suppose (X,Y) have a uniform distribution over S, their joint PDF is given by $f_{X,Y}(x,y)=\frac{1}{16}, (x,y) \in S$ . Problem 1: find the marginal PDF $f_X(x)$ of X. Question 1: I know f_X(x) is the integral of Y=y but how do I represent this in this diagram? $f_X(x)= \int_0^4 \frac{1}{16} dy$ ?","Let S be the shadowed region: Suppose (X,Y) have a uniform distribution over S, their joint PDF is given by . Problem 1: find the marginal PDF of X. Question 1: I know f_X(x) is the integral of Y=y but how do I represent this in this diagram? ?","f_{X,Y}(x,y)=\frac{1}{16}, (x,y) \in S f_X(x) f_X(x)= \int_0^4 \frac{1}{16} dy","['probability', 'probability-distributions']"
54,Multinomial Distribution -- How to calculate percentiles?,Multinomial Distribution -- How to calculate percentiles?,,"I've read the rules and searched but I do not even know what I'm looking for. Here is my problem: Suppose I have a bag containing three different marbles: red, green, and blue. I am drawing a single marble from the bag each time with replacement. I would like to know how many times, on average, do I need to draw marbles from the bag until I have drawn $25$ of each type of marble. I would like to plot this distribution and be able to calculate percentiles on this distribution. After some research I think this is a multinomial distribution. I can calculate the probability that I have exactly $25$ of each marble after $75$ draws by the following: $$\frac{75!}{25!\times25!\times25!}\times\left(\frac13\right)^{25}\times \left(\frac13\right)^{25} \times\left(\frac13\right)^{25}$$ which works out to about $1.06\%$ . However, I don't know how to proceed with turning this into a distribution so I can calculate percentiles. Please advise on how to proceed.","I've read the rules and searched but I do not even know what I'm looking for. Here is my problem: Suppose I have a bag containing three different marbles: red, green, and blue. I am drawing a single marble from the bag each time with replacement. I would like to know how many times, on average, do I need to draw marbles from the bag until I have drawn of each type of marble. I would like to plot this distribution and be able to calculate percentiles on this distribution. After some research I think this is a multinomial distribution. I can calculate the probability that I have exactly of each marble after draws by the following: which works out to about . However, I don't know how to proceed with turning this into a distribution so I can calculate percentiles. Please advise on how to proceed.",25 25 75 \frac{75!}{25!\times25!\times25!}\times\left(\frac13\right)^{25}\times \left(\frac13\right)^{25} \times\left(\frac13\right)^{25} 1.06\%,"['probability', 'probability-distributions', 'multinomial-coefficients', 'coupon-collector', 'multinomial-distribution']"
55,Using convolution formula to find PMF and then to show negative binomial distribution,Using convolution formula to find PMF and then to show negative binomial distribution,,"Let $X$ and $Y$ be independent random variables taking only integer values. Let $Z=X+Y$ , which also takes only integer values. Its PMF can be computed by the convolution formula: for any integer $z$ , \begin{align} \ P_Z(z) & = P(Z=z) =P(X+Y=z) \\  & = \sum_{x=-\infty}^{\infty} P(X=x,X+Y=z)\\   & = \sum_{x=-\infty}^{\infty} P(X=x,Y=z-x) \\  & = \sum_{x=-\infty}^{\infty} P(X=x)P(Y=z-x) \\   & = \sum_{x=-\infty}^{\infty} P_X(x) P_Y(z-x) \end{align} Question: Let $X$ and $Y$ be independent and have geometric distribution with parameter $p$ . By computing the PMF, show $X+Y$ has a negative binomial distribution with parameters $r=2$ and $p$ . Geometric distribution is given by $f(x)=(1-p)^{x-1} p$ and negative binomial distribution is $P(X=x|r,p)={x-1 \choose r-1}p^r (1-p)^y$ . I would like to know how to calculate the convolution formula for PMF. Any help is appreciated.","Let and be independent random variables taking only integer values. Let , which also takes only integer values. Its PMF can be computed by the convolution formula: for any integer , Question: Let and be independent and have geometric distribution with parameter . By computing the PMF, show has a negative binomial distribution with parameters and . Geometric distribution is given by and negative binomial distribution is . I would like to know how to calculate the convolution formula for PMF. Any help is appreciated.","X Y Z=X+Y z \begin{align}
\ P_Z(z) & = P(Z=z) =P(X+Y=z) \\
 & = \sum_{x=-\infty}^{\infty} P(X=x,X+Y=z)\\ 
 & = \sum_{x=-\infty}^{\infty} P(X=x,Y=z-x) \\
 & = \sum_{x=-\infty}^{\infty} P(X=x)P(Y=z-x) \\ 
 & = \sum_{x=-\infty}^{\infty} P_X(x) P_Y(z-x)
\end{align} X Y p X+Y r=2 p f(x)=(1-p)^{x-1} p P(X=x|r,p)={x-1 \choose r-1}p^r (1-p)^y","['probability', 'statistics', 'probability-distributions']"
56,Independence of a random variable and a sigma algebra,Independence of a random variable and a sigma algebra,,"Let $(\Omega,\mathcal{F},P)$ be a probability space and $X$ be a random variable on it. Consider a sub $\sigma$ -algebra $\mathcal{G}$ . $X$ is said to be independent of $\mathcal{G}$ if $\sigma(X)$ and $\mathcal{G}$ are independent as $\sigma$ -algebras. I already know the fact that independence of $X$ and $\mathcal{G}$ implies $\mathbb{E}[X|\mathcal{G}]=\mathbb{E}[X]$ but not necessarily the other way round. However, if $X$ satisfies the equality $\mathbb{E}[e^{itX}|\mathcal{G}]=\mathbb{E}[e^{itX}]$ , for all $t\in\mathbb{R}$ , then can we conclude that $X$ and $\mathcal{G}$ are independent?","Let be a probability space and be a random variable on it. Consider a sub -algebra . is said to be independent of if and are independent as -algebras. I already know the fact that independence of and implies but not necessarily the other way round. However, if satisfies the equality , for all , then can we conclude that and are independent?","(\Omega,\mathcal{F},P) X \sigma \mathcal{G} X \mathcal{G} \sigma(X) \mathcal{G} \sigma X \mathcal{G} \mathbb{E}[X|\mathcal{G}]=\mathbb{E}[X] X \mathbb{E}[e^{itX}|\mathcal{G}]=\mathbb{E}[e^{itX}] t\in\mathbb{R} X \mathcal{G}","['probability', 'probability-theory', 'conditional-expectation', 'conditional-probability']"
57,Lower bound on tail probability for maximum of independent random variables,Lower bound on tail probability for maximum of independent random variables,,"I'm having difficulty solving a problem from van der Vaart & Wellner (1996). Problem 2.3.2 on page 120 asks the reader to prove: For independent random variables $\xi_1, \ldots, \xi_n$ , $$ P\left(\max_i |\xi_i| >x\right) \ge \frac{\sum_i P(|\xi_i|>x)}{1 + \sum_i P(|\xi_i|>x)}. $$ There is a hint: For $x\ge 0$ , one has $1-x\le \exp(-x)$ and $1-e^{-x}\ge x/(1+x)$ . I'm not sure how to start with proving this statement. Clearly the form $x/(1+x)$ in the hint is the same as the form on the rhs of the inequality, however I'm not sure how to get the $1-e^{-x}$ in there. Any hints / suggestions as to how to attack this problem would be appreciated.","I'm having difficulty solving a problem from van der Vaart & Wellner (1996). Problem 2.3.2 on page 120 asks the reader to prove: For independent random variables , There is a hint: For , one has and . I'm not sure how to start with proving this statement. Clearly the form in the hint is the same as the form on the rhs of the inequality, however I'm not sure how to get the in there. Any hints / suggestions as to how to attack this problem would be appreciated.","\xi_1, \ldots, \xi_n 
P\left(\max_i |\xi_i| >x\right) \ge \frac{\sum_i P(|\xi_i|>x)}{1 + \sum_i P(|\xi_i|>x)}.
 x\ge 0 1-x\le \exp(-x) 1-e^{-x}\ge x/(1+x) x/(1+x) 1-e^{-x}","['probability', 'probability-theory', 'inequality']"
58,Determining the limit of a sequence of sets?,Determining the limit of a sequence of sets?,,"(a) Let $\Omega = \mathfrak{R}$ . Define $A_n = \big{[}0, \frac{n}{n+1}\big{)}$ . Determine if $\lim_{n \to \infty} A_n$ exists. If yes, what is it? (b) Show that $\lim_{n \to \infty} \big{[}0, 1 + \frac{1}{n} \big{)} = [0, 1]$ Definitions : $$\inf_{k \geq n}A_k = \bigcap_{k = n}^{\infty} A_k$$ $$\sup_{k \geq n}A_k = \bigcup_{k = n}^{\infty} A_k$$ $$\lim_{n \to \infty}\inf A_n = \bigcup_{n = 1}^{\infty}\bigcap_{k = n}^{\infty} A_k$$ $$\lim_{n \to \infty}\sup A_n = \bigcap_{n = 1}^{\infty}\bigcup_{k = n}^{\infty} A_k$$ The sequence of sets $\{A_n\}$ is said to converge to its limit A if: $$\lim_{n \to \infty}\inf A_n = \lim_{n \to \infty}\sup A_n = A$$ Question : Just looking at the sets in (a) and (b) and 'plugging' in $\infty$ I can obtain an answer, but I do not think that is the correct way to approach this problem. Is there a simple way to evaluate the infimum and supremum of a set? I understand the infimum is the greatest element that is less than or equal to all elements of a set $S$ whereas the supremum is the least element that is greater than or equal to all elements of $S$","(a) Let . Define . Determine if exists. If yes, what is it? (b) Show that Definitions : The sequence of sets is said to converge to its limit A if: Question : Just looking at the sets in (a) and (b) and 'plugging' in I can obtain an answer, but I do not think that is the correct way to approach this problem. Is there a simple way to evaluate the infimum and supremum of a set? I understand the infimum is the greatest element that is less than or equal to all elements of a set whereas the supremum is the least element that is greater than or equal to all elements of","\Omega = \mathfrak{R} A_n = \big{[}0, \frac{n}{n+1}\big{)} \lim_{n \to \infty} A_n \lim_{n \to \infty} \big{[}0, 1 + \frac{1}{n} \big{)} = [0, 1] \inf_{k \geq n}A_k = \bigcap_{k = n}^{\infty} A_k \sup_{k \geq n}A_k = \bigcup_{k = n}^{\infty} A_k \lim_{n \to \infty}\inf A_n = \bigcup_{n = 1}^{\infty}\bigcap_{k = n}^{\infty} A_k \lim_{n \to \infty}\sup A_n = \bigcap_{n = 1}^{\infty}\bigcup_{k = n}^{\infty} A_k \{A_n\} \lim_{n \to \infty}\inf A_n = \lim_{n \to \infty}\sup A_n = A \infty S S","['probability', 'limits', 'probability-theory', 'measure-theory']"
59,How to compute the expected minimum Hamming distance with 3 strings,How to compute the expected minimum Hamming distance with 3 strings,,"If we sample $3$ binary strings of length $n$ , uniformly and independently, what is the expected minimum Hamming distance between the closest pair? Numerically, it seems to be asymptotic to $n/2$ but it would be great to know if there is an exact formula.","If we sample binary strings of length , uniformly and independently, what is the expected minimum Hamming distance between the closest pair? Numerically, it seems to be asymptotic to but it would be great to know if there is an exact formula.",3 n n/2,[]
60,"Equal in distribution, linear combination of random variables","Equal in distribution, linear combination of random variables",,"I have a problem that I am working on, and I am trying to figure out if there is more information I can say about it. I have that $X, Y, Z$ are iid and that $\frac{X + Y+ Z}{\sqrt{3}} \overset{d}{=} X$ , and $E(X^2) = 1$ . I need to find the distribution of X. It seems clear that $$\frac{X + Y+ Z}{\sqrt{3}} \overset{d}{=} X$$ $$\Rightarrow X + Y+ Z \overset{d}{=} \sqrt{3}X$$ Hence, for expected value we have $$E(X) = \mu = E(Y) = E(Z)$$ $$E(X+Y+Z) = \sqrt{3} E(X)$$ $$3\mu= \sqrt{3} \mu \Rightarrow \mu = 0$$ And for the Variance of X we can see that $$Var(X) = E(X^2) - (E(X))^2$$ $$Var(X) = 1 - \mu^2 = 1$$ $$Var(X) = Var(Y) = Var(Z) = 1$$ $$Var(\frac{X+Y+Z}{\sqrt{3}}) = \frac{1+1+1}{3} = 1$$ Therefore $E(X) = 0,$ and $Var(X) = 1.$ It seems like $X$ could be a standard normal distribution, but clearly we do not know that for sure.  Is there anything else that I can say about it?","I have a problem that I am working on, and I am trying to figure out if there is more information I can say about it. I have that are iid and that , and . I need to find the distribution of X. It seems clear that Hence, for expected value we have And for the Variance of X we can see that Therefore and It seems like could be a standard normal distribution, but clearly we do not know that for sure.  Is there anything else that I can say about it?","X, Y, Z \frac{X + Y+ Z}{\sqrt{3}} \overset{d}{=} X E(X^2) = 1 \frac{X + Y+ Z}{\sqrt{3}} \overset{d}{=} X \Rightarrow X + Y+ Z \overset{d}{=} \sqrt{3}X E(X) = \mu = E(Y) = E(Z) E(X+Y+Z) = \sqrt{3} E(X) 3\mu= \sqrt{3} \mu \Rightarrow \mu = 0 Var(X) = E(X^2) - (E(X))^2 Var(X) = 1 - \mu^2 = 1 Var(X) = Var(Y) = Var(Z) = 1 Var(\frac{X+Y+Z}{\sqrt{3}}) = \frac{1+1+1}{3} = 1 E(X) = 0, Var(X) = 1. X","['probability', 'probability-distributions', 'normal-distribution']"
61,Expected number of collisions while distributing balls in boxes,Expected number of collisions while distributing balls in boxes,,"Suppose we have n balls $b_1, b_2,\cdots , b_n$ and n boxes. Each ball is placed into a box chosen independently and uniformly randomly. A colliding pair is defined as $(b_i,b_j)$ , where $i<j$ and $b_i$ and $b_j$ are placed in the same box. We are asked to evaluate the expected number of colliding pairs. What I did - Clearly, for any $k$ -set of balls in some box, there are $\binom{k}{2}$ colliding pairs in that box. Next if $C$ is the total number of colliding pairs after randomly placing all the balls in boxes, $E[C] = E[C_1+C_2+\cdots+C_n]=\displaystyle\sum_{i=1}^{n}E[C_i]=nE[C_k]$ where $C_k$ is the number of colliding pairs in box $k$ and $E[C_k] = E[C_1]=E[C_2]=\cdots$ . Now as each box will have $\binom{i}{2} = i(i-1)/2$ colliding pairs if the box contains $i$ balls, we can calculate the expected value as follows - $\begin{align} nE[C_k] &= n\left(\displaystyle\sum_{i=2}^{n}\binom{i}{2}\text{Pr}\left[i(i-1)\text{ colliding pairs in box k}\right]\right) \\&= n\left(\displaystyle\sum_{i=2}^{n}\binom{n}{i}\dfrac{i(i-1)}{2}\left(\dfrac{1}{n}\right)^i\left(\dfrac{n-1}{n}\right)^{n-i}\right)\end{align}$ This can be calculated using various tricks like differentiating the $(1+x)^n$ binomial expansion and so on. But, the answer $E[C] = \dfrac{n-1}{2}$ . Given that the answer is so simple, is there a much simpler/slicker/quicker way to see it?","Suppose we have n balls and n boxes. Each ball is placed into a box chosen independently and uniformly randomly. A colliding pair is defined as , where and and are placed in the same box. We are asked to evaluate the expected number of colliding pairs. What I did - Clearly, for any -set of balls in some box, there are colliding pairs in that box. Next if is the total number of colliding pairs after randomly placing all the balls in boxes, where is the number of colliding pairs in box and . Now as each box will have colliding pairs if the box contains balls, we can calculate the expected value as follows - This can be calculated using various tricks like differentiating the binomial expansion and so on. But, the answer . Given that the answer is so simple, is there a much simpler/slicker/quicker way to see it?","b_1, b_2,\cdots , b_n (b_i,b_j) i<j b_i b_j k \binom{k}{2} C E[C] = E[C_1+C_2+\cdots+C_n]=\displaystyle\sum_{i=1}^{n}E[C_i]=nE[C_k] C_k k E[C_k] = E[C_1]=E[C_2]=\cdots \binom{i}{2} = i(i-1)/2 i \begin{align}
nE[C_k] &= n\left(\displaystyle\sum_{i=2}^{n}\binom{i}{2}\text{Pr}\left[i(i-1)\text{ colliding pairs in box k}\right]\right) \\&= n\left(\displaystyle\sum_{i=2}^{n}\binom{n}{i}\dfrac{i(i-1)}{2}\left(\dfrac{1}{n}\right)^i\left(\dfrac{n-1}{n}\right)^{n-i}\right)\end{align} (1+x)^n E[C] = \dfrac{n-1}{2}","['probability', 'combinatorics', 'expected-value']"
62,How to use Concentration Inequalitites to bound this probability from above?,How to use Concentration Inequalitites to bound this probability from above?,,"I'm attempting a problem in Rohatgi & Saleh's Intro to Probability and Statistics, from the Concentration inequalities section. It's actually the first exercise in the section, so the fact that I can't get it means I'm missing something obvious: We have a random variable X with PDF: $f(x;\lambda) = \frac{e^{-x} x^\lambda}{\lambda !}, x>0$ for some $\lambda \geq 0$ an integer. They ask that I show that $P\{0<X<2(\lambda + 1)\} > \frac{\lambda}{\lambda + 1}$ . I'd like to use the concentration/Markov/Chebyshev inequalities to for this but all the inequalities are in the wrong direction. Is there a nifty way I'm not thinking of to get them to mirror this result? Hints are greatly appreciated. Also please don't go easy on me if this is something obvious. I need to start being better at probability. Also here are the concentration inequalities I've been referring to: $$\text{If $E[h(X)]$ exists,  } \quad  P[h(X)\geq M] \leq \frac{E[h(X)]}{M} \quad \text{for any } M>0,\\ \text{If $E[|X|^k]$ exists,  } \quad  P[|X|\geq M] \leq \frac{E[|X|^k]}{M^k} \quad \text{for any } M>0,$$","I'm attempting a problem in Rohatgi & Saleh's Intro to Probability and Statistics, from the Concentration inequalities section. It's actually the first exercise in the section, so the fact that I can't get it means I'm missing something obvious: We have a random variable X with PDF: for some an integer. They ask that I show that . I'd like to use the concentration/Markov/Chebyshev inequalities to for this but all the inequalities are in the wrong direction. Is there a nifty way I'm not thinking of to get them to mirror this result? Hints are greatly appreciated. Also please don't go easy on me if this is something obvious. I need to start being better at probability. Also here are the concentration inequalities I've been referring to:","f(x;\lambda) = \frac{e^{-x} x^\lambda}{\lambda !}, x>0 \lambda \geq 0 P\{0<X<2(\lambda + 1)\} > \frac{\lambda}{\lambda + 1} \text{If E[h(X)] exists,  } \quad  P[h(X)\geq M] \leq \frac{E[h(X)]}{M} \quad \text{for any } M>0,\\
\text{If E[|X|^k] exists,  } \quad  P[|X|\geq M] \leq \frac{E[|X|^k]}{M^k} \quad \text{for any } M>0,","['probability', 'probability-theory']"
63,What is the distribution of $X\vert Y$ where $Y$ is Bernoulli R.V?,What is the distribution of  where  is Bernoulli R.V?,X\vert Y Y,"On good days customers arrive at an infinite server queue   according to a Poission process with rate $12$ per hour, whereas on other days   they arrive according to a Poisson process with rate $4$ per hour. The service times,   on all days, are exponentially distributed with rate $1$ per hour. Every day at time $10$ hours the system is shut down and all those presently in service are forced to leave   without completing service. Suppose that each day is, independently, a good day   with probability $0.5$ and that we want to use simulation to estimate $\theta$ , the mean   number of customers per day that do not have their services completed. My question regards only in finding $\mathbb{E}[X|Y]$ where $X$ denotes the number of costumers that do not have their services completed on any day and $Y$ denotes whether the day is good or ordinary. Therefore $Y$ is Bernoulli. (The hint given is that $X|Y$ follows a Poisson). I was not able to find an explicit form for the distribution of $X$ given $Y$ , but my reasoning in finding an approximate value of such goes as follows: The average number of people that arrive per hour on a good day is $12$ and they stay in the system approximately $1$ hour each. On average $108$ people visit the server. Suppose now that we allow people in the server at time $10$ , as soon as they walk in the server closes. But the average of people that walk is at $t=10$ is $12$ , therefore $$\mathbb{E}\left[X|Y=0\right]\approx12$$ and by the same reasoning $$\mathbb{E}\left[X|Y=1\right]\approx4$$ where $Y=0$ denotes that the day is gonna be good with probability $1/2$ and $Y=1$ denotes that it is going to be bad with probability $1/2$ . My question is, how would I find the exact value of such expectations? Is it possible without any prior knowledge of stochastic processes? UDATE: After some research I found that $$\mathbb{E}\left[X\vert Y=0\right]=12\left(1-e^{-10}\right)$$ and $$\mathbb{E}\left[X\vert Y=1\right]=4\left(1-e^{-10}\right)$$ Which indeed agrees with my approximation. I am wondering how this answers was derived, as the source I found it on does not give any motivation.","On good days customers arrive at an infinite server queue   according to a Poission process with rate per hour, whereas on other days   they arrive according to a Poisson process with rate per hour. The service times,   on all days, are exponentially distributed with rate per hour. Every day at time hours the system is shut down and all those presently in service are forced to leave   without completing service. Suppose that each day is, independently, a good day   with probability and that we want to use simulation to estimate , the mean   number of customers per day that do not have their services completed. My question regards only in finding where denotes the number of costumers that do not have their services completed on any day and denotes whether the day is good or ordinary. Therefore is Bernoulli. (The hint given is that follows a Poisson). I was not able to find an explicit form for the distribution of given , but my reasoning in finding an approximate value of such goes as follows: The average number of people that arrive per hour on a good day is and they stay in the system approximately hour each. On average people visit the server. Suppose now that we allow people in the server at time , as soon as they walk in the server closes. But the average of people that walk is at is , therefore and by the same reasoning where denotes that the day is gonna be good with probability and denotes that it is going to be bad with probability . My question is, how would I find the exact value of such expectations? Is it possible without any prior knowledge of stochastic processes? UDATE: After some research I found that and Which indeed agrees with my approximation. I am wondering how this answers was derived, as the source I found it on does not give any motivation.",12 4 1 10 0.5 \theta \mathbb{E}[X|Y] X Y Y X|Y X Y 12 1 108 10 t=10 12 \mathbb{E}\left[X|Y=0\right]\approx12 \mathbb{E}\left[X|Y=1\right]\approx4 Y=0 1/2 Y=1 1/2 \mathbb{E}\left[X\vert Y=0\right]=12\left(1-e^{-10}\right) \mathbb{E}\left[X\vert Y=1\right]=4\left(1-e^{-10}\right),"['probability', 'probability-theory', 'probability-distributions', 'conditional-probability']"
64,Alice and Bob card game - a different version,Alice and Bob card game - a different version,,"Alice chooses with uniform distribution two real numbers between 0 and 100 and write them down, each on a card. Then, Alice decides which card Bob will see. Bob looks at the card and then decides which of the cards he wants. If he get the higher number he wins, otherwise he loses. As not as the version in the question Alice and Bob card game , here Alice can play a strategy such that Bob won't be able to guarantee winning strictly more than half the time. The question is how Alice can do that. I tried to reflect the strategy that Bob uses in the original question, for example, decide that if both numbers are greater than 50, Bob will get the lower number to see, etc. In all these variation, the original strategy of Bob still guarantees to win strictly more than half the time. Any other ideas?","Alice chooses with uniform distribution two real numbers between 0 and 100 and write them down, each on a card. Then, Alice decides which card Bob will see. Bob looks at the card and then decides which of the cards he wants. If he get the higher number he wins, otherwise he loses. As not as the version in the question Alice and Bob card game , here Alice can play a strategy such that Bob won't be able to guarantee winning strictly more than half the time. The question is how Alice can do that. I tried to reflect the strategy that Bob uses in the original question, for example, decide that if both numbers are greater than 50, Bob will get the lower number to see, etc. In all these variation, the original strategy of Bob still guarantees to win strictly more than half the time. Any other ideas?",,"['probability', 'card-games']"
65,What is the probability that $THTH$ occurs before $HTHH$ in an infinite sequence of coin flips? [duplicate],What is the probability that  occurs before  in an infinite sequence of coin flips? [duplicate],THTH HTHH,"This question already has answers here : Coin sequence paradox from Martin Gardner's book (5 answers) Closed 4 years ago . What is the probability that $THTH$ occurs before $HTHH$ in an infinite sequence of coin flips? The expected number of flips until you first see $THTH$ is $6$ , while the expected number until you first see $HTHH$ is $10$ . Intuitively, I would guess that the probability that $THTH$ occurs before $HTHH$ is $3/4$ . Is there a formal argument to compute this probability? Probabilistic model: We denote by $(X_{n})_{n \geq 1}$ the random variable of coin flips, taking values in $\{H,T\}^{\mathbb{N}}$ . We let $t_{THTH}$ be the first time that $THTH$ occurs in the sequence. We have $$ \mathbb{E}[t_{H}] = \frac{1}{2} \mathbb{E}[t_{H} | X_{1} = H] +  \frac{1}{2} \mathbb{E}[t_{H} | X_{1} = T] = \frac{1}{2}  +  \frac{1}{2} (\mathbb{E}[t_{H}] + 1  ). $$ $$ \mathbb{E}[t_{TH}] = \frac{1}{2} \mathbb{E}[t_{TH} | X_{1} = H] +  \frac{1}{2} \mathbb{E}[t_{TH} | X_{1} = T] $$","This question already has answers here : Coin sequence paradox from Martin Gardner's book (5 answers) Closed 4 years ago . What is the probability that occurs before in an infinite sequence of coin flips? The expected number of flips until you first see is , while the expected number until you first see is . Intuitively, I would guess that the probability that occurs before is . Is there a formal argument to compute this probability? Probabilistic model: We denote by the random variable of coin flips, taking values in . We let be the first time that occurs in the sequence. We have","THTH HTHH THTH 6 HTHH 10 THTH HTHH 3/4 (X_{n})_{n \geq 1} \{H,T\}^{\mathbb{N}} t_{THTH} THTH 
\mathbb{E}[t_{H}] = \frac{1}{2} \mathbb{E}[t_{H} | X_{1} = H] + 
\frac{1}{2} \mathbb{E}[t_{H} | X_{1} = T] = \frac{1}{2}  + 
\frac{1}{2} (\mathbb{E}[t_{H}] + 1  ).
 
\mathbb{E}[t_{TH}] = \frac{1}{2} \mathbb{E}[t_{TH} | X_{1} = H] + 
\frac{1}{2} \mathbb{E}[t_{TH} | X_{1} = T]
","['probability', 'probability-theory', 'random-variables', 'random-walk', 'random']"
66,Expected number of vertices in a convex hull,Expected number of vertices in a convex hull,,"Suppose $X_1, ..., X_n$ are i.i.d. random variables uniformly distributed in the unit ball in $\mathbb{R}^m$ . What is the expected number of vertices that their convex hull has? The only thing I managed to prove here was: $$P(\text{ convex hull of }X_1, ..., X_n\text{ has exactly }k\text{ vertices}) = C_n^k P(X_{k+1}, ... ,X_n \text{ lie in the convex hull of }X_1, ..., X_n)$$ Not sure, however, whether this helps or not.","Suppose are i.i.d. random variables uniformly distributed in the unit ball in . What is the expected number of vertices that their convex hull has? The only thing I managed to prove here was: Not sure, however, whether this helps or not.","X_1, ..., X_n \mathbb{R}^m P(\text{ convex hull of }X_1, ..., X_n\text{ has exactly }k\text{ vertices}) = C_n^k P(X_{k+1}, ... ,X_n \text{ lie in the convex hull of }X_1, ..., X_n)","['probability', 'expected-value', 'uniform-distribution', 'convex-hulls']"
67,Do lower weights affect choices. (This question is based off one when thinking about college applications with binding decisions),Do lower weights affect choices. (This question is based off one when thinking about college applications with binding decisions),,"Three events $A, B, C$ . They are yes/no events. They are independent. $A$ is of greater weight/worth than $B$ , and $B$ than $C$ . In cases where multiple occur, only the greatest weight matters. You have the chance to increase the probability of $B$ at the cost that if $A$ and $B$ occur ( $A\ B$ and $C$ or $A\ B$ ), you must go with the lower weight $B$ . Does the weight of $C$ matter in your choice of whether or not you accept the proposition to increase the probability of $B$ with its costs? (Sorry for the poor wording—I'm not a probability guy).","Three events . They are yes/no events. They are independent. is of greater weight/worth than , and than . In cases where multiple occur, only the greatest weight matters. You have the chance to increase the probability of at the cost that if and occur ( and or ), you must go with the lower weight . Does the weight of matter in your choice of whether or not you accept the proposition to increase the probability of with its costs? (Sorry for the poor wording—I'm not a probability guy).","A, B, C A B B C B A B A\ B C A\ B B C B",['probability']
68,How my professor derived this CDF?,How my professor derived this CDF?,,"This was an example problem my professor went over in class. Let $X =$ uniform $(1,4)$ where $Y=(X-2)^2$ Find the CDF. He went on to derive: $F_Y(y)=P(Y\leq y) = P((x-2)^2 \leq y) = P(-\sqrt{y}\leq (x-2) \leq \sqrt(y))$ = $P(2 - \sqrt{y} \leq x \leq 2 + \sqrt{y})$ Then he said the CDF is: $$F_X(x)= \begin{cases}        0 & x\leq 1 \\       \frac{x-1}{3} & 1\leq x\leq 4 \\       1 & x\geq 4    \end{cases} $$ I am very confused as to how he derived this CDF. Could someone please explain? Edit: Unless he is wrong?",This was an example problem my professor went over in class. Let uniform where Find the CDF. He went on to derive: = Then he said the CDF is: I am very confused as to how he derived this CDF. Could someone please explain? Edit: Unless he is wrong?,"X = (1,4) Y=(X-2)^2 F_Y(y)=P(Y\leq y) = P((x-2)^2 \leq y) = P(-\sqrt{y}\leq (x-2) \leq \sqrt(y)) P(2 - \sqrt{y} \leq x \leq 2 + \sqrt{y}) F_X(x)= \begin{cases} 
      0 & x\leq 1 \\
      \frac{x-1}{3} & 1\leq x\leq 4 \\
      1 & x\geq 4
   \end{cases}
",['probability']
69,What is the largest possible probability that a random matrix over $\mathbb{F}_2$ is non-singular?,What is the largest possible probability that a random matrix over  is non-singular?,\mathbb{F}_2,"Suppose $A(p, n)=(a_{ij}(p))_{i, j \leq n}$ is an $n\times n$ random matrix over $\mathbb{F_2}$ , with  all its entries being i.i.d. and such that $P(a_{ij}(p) = 1) = p$ , where $p$ is some real number from $[0; 1]$ . What is the largest possible probability, that $A(p, n)$ is non-singular and with what $p$ is it reached? Note, that $A(p, n)$ in non-singular iff $det(A(p, n)) = 1$ . Solution for $n=1$ : $det(A(p, 1)) = 1$ with probability $p$ . The maximum of $det(A(p, 1))$ is $1$ and it is reached with $p = 1$ . Solution for $n = 2$ : $det(A(p, 2)) = 1$ with probability $2p^2(1 - p^2)$ . The maximum of $P(det(A(p, 2))=1)$ is $\frac{1}{2}$ and it is reached with $p = \frac{1}{\sqrt{2}}$ . However, I would like to know some sort of general formula (or at least asymptotics). EDIT: After I failed to solve this problem using determinants, I tried to prove this using the fact that asquare matrix is non-singular iff its rows are linearly dependent. As there exists only one non-zero element in $\mathbb{F_2}$ , we can write linear dependence of the vector system $\{v_i\}_{i \leq n}$ in $\mathbb{F}_2^n$ as $\forall S \subset \{1, ... , n\}$ such that $S \neq \emptyset$ we have $\sum_{i \in S} v_i \neq \overline{0}$ . I know the probability that a given set of vectors with i.i.d. random entries Bernoulli distributed with parameter $p$ $\{v_i\}_{i \leq k}$ over $\mathbb{F}_2^n$ satisfy $\sum_{i = 1}^k v_i \neq \overline{0}$ is $(1 - \frac{p((1 - 2p)^k - 1)}{1 - 2p})$ . However, I do not know how to proceed further in this direction.","Suppose is an random matrix over , with  all its entries being i.i.d. and such that , where is some real number from . What is the largest possible probability, that is non-singular and with what is it reached? Note, that in non-singular iff . Solution for : with probability . The maximum of is and it is reached with . Solution for : with probability . The maximum of is and it is reached with . However, I would like to know some sort of general formula (or at least asymptotics). EDIT: After I failed to solve this problem using determinants, I tried to prove this using the fact that asquare matrix is non-singular iff its rows are linearly dependent. As there exists only one non-zero element in , we can write linear dependence of the vector system in as such that we have . I know the probability that a given set of vectors with i.i.d. random entries Bernoulli distributed with parameter over satisfy is . However, I do not know how to proceed further in this direction.","A(p, n)=(a_{ij}(p))_{i, j \leq n} n\times n \mathbb{F_2} P(a_{ij}(p) = 1) = p p [0; 1] A(p, n) p A(p, n) det(A(p, n)) = 1 n=1 det(A(p, 1)) = 1 p det(A(p, 1)) 1 p = 1 n = 2 det(A(p, 2)) = 1 2p^2(1 - p^2) P(det(A(p, 2))=1) \frac{1}{2} p = \frac{1}{\sqrt{2}} \mathbb{F_2} \{v_i\}_{i \leq n} \mathbb{F}_2^n \forall S \subset \{1, ... , n\} S \neq \emptyset \sum_{i \in S} v_i \neq \overline{0} p \{v_i\}_{i \leq k} \mathbb{F}_2^n \sum_{i = 1}^k v_i \neq \overline{0} (1 - \frac{p((1 - 2p)^k - 1)}{1 - 2p})","['linear-algebra', 'probability', 'matrices', 'finite-fields', 'random-matrices']"
70,Deriving the Pollaczek - Khintchine formula,Deriving the Pollaczek - Khintchine formula,,"I used this result in a paper a while back and now I want to be clear about where it comes from (I know it's correct). I wonder if someone could explain? I have a moment generating function for an M/G/1 queue (ie Markovian, General, 1 server) of: $\frac{1-\rho}{1-\rho h^*(s)}$ Where $\rho$ is the traffic intensity ( $\rho=\lambda\mu$ where $\lambda$ is the poisson parameter - ie rate of arrivals and $\mu$ is the average service time) While $h^*(s)=\frac{1-g^*(s)}{s\mu}$ - and $g^*(s)$ is a Laplace transform (into the domain of s) of a distribution function $g(x)$ for service times. Now - so far, so standard - differentiating this and taking the negative of its value at $s=0$ should give us the expectation of waiting time in the queue. The standard result for this differentiation (and negation) is $\frac{\rho\mu(1+c^2)}{2(1-\rho)}$ , where $c$ is ""the co-efficient of variation"", namely the ratio of the standard deviation to the mean for service times. Now this differentiation is laborious and I don't think I am getting it right - and I suspect it involves knowledge of what property is revealed by $\frac{dg^*(s)}{ds}$ - which I am not clear about. I am happy to read a source if that's easier than an explanation but I would appreciate some pointers about how we get from $\frac{dg^*(s)}{ds}$ to $c$ .","I used this result in a paper a while back and now I want to be clear about where it comes from (I know it's correct). I wonder if someone could explain? I have a moment generating function for an M/G/1 queue (ie Markovian, General, 1 server) of: Where is the traffic intensity ( where is the poisson parameter - ie rate of arrivals and is the average service time) While - and is a Laplace transform (into the domain of s) of a distribution function for service times. Now - so far, so standard - differentiating this and taking the negative of its value at should give us the expectation of waiting time in the queue. The standard result for this differentiation (and negation) is , where is ""the co-efficient of variation"", namely the ratio of the standard deviation to the mean for service times. Now this differentiation is laborious and I don't think I am getting it right - and I suspect it involves knowledge of what property is revealed by - which I am not clear about. I am happy to read a source if that's easier than an explanation but I would appreciate some pointers about how we get from to .",\frac{1-\rho}{1-\rho h^*(s)} \rho \rho=\lambda\mu \lambda \mu h^*(s)=\frac{1-g^*(s)}{s\mu} g^*(s) g(x) s=0 \frac{\rho\mu(1+c^2)}{2(1-\rho)} c \frac{dg^*(s)}{ds} \frac{dg^*(s)}{ds} c,"['probability', 'statistics', 'stochastic-processes', 'queueing-theory']"
71,Probability: Optimal strategy in die game,Probability: Optimal strategy in die game,,"You are given a single die. When you roll the die, you have two choices: End the game here, in which case the number you just rolled is your final score. Continue the game and roll once again, after which you will face these same two choices. You can roll the die a maximum of 4 times. After the fourth roll, you will not have a choice and will have to accept whatever you rolled as your final score. There are two questions to answer here: What is the optimal strategy to maximize your final score? What is the expected value of the final score? I was asked this question in an interview and struggled to work it out. I ended up getting the job anyway, but am still interested to figure out the approach to this question. When I was unable to answer this question, my interviewer said that he didn't expect me to answer this question as it needs some intuition from Markov chains, which I had no prior exposure to.","You are given a single die. When you roll the die, you have two choices: End the game here, in which case the number you just rolled is your final score. Continue the game and roll once again, after which you will face these same two choices. You can roll the die a maximum of 4 times. After the fourth roll, you will not have a choice and will have to accept whatever you rolled as your final score. There are two questions to answer here: What is the optimal strategy to maximize your final score? What is the expected value of the final score? I was asked this question in an interview and struggled to work it out. I ended up getting the job anyway, but am still interested to figure out the approach to this question. When I was unable to answer this question, my interviewer said that he didn't expect me to answer this question as it needs some intuition from Markov chains, which I had no prior exposure to.",,"['probability', 'markov-chains']"
72,Prove $P(A) = \sum_{i=1}^{n}P(A_i) - 2\sum_{i<j \leq n}P(A_i \cap A_j) + \ldots)$,Prove,P(A) = \sum_{i=1}^{n}P(A_i) - 2\sum_{i<j \leq n}P(A_i \cap A_j) + \ldots),"Let $A$ be the collection of outcomes which belong to only one event among events $A_1, \ldots, A_n$ . Prove \begin{align*} P(A) &= \sum_{i=1}^{n}P(A_i) - 2\sum_{i<j \leq n}P(A_i \cap A_j) + 3\sum_{i<j<k \leq n}P(A_i \cap A_j \cap A_k) - \ldots \\ &\qquad \ldots + (-1)^{n-1} n P(\bigcap_{i=1}^n A_i) \end{align*} The question is from my course's exercise problem, the expression looks pretty similar to inclusion-exclusion formula, I tried induction but didn't work.","Let be the collection of outcomes which belong to only one event among events . Prove The question is from my course's exercise problem, the expression looks pretty similar to inclusion-exclusion formula, I tried induction but didn't work.","A A_1, \ldots, A_n \begin{align*}
P(A)
&= \sum_{i=1}^{n}P(A_i) - 2\sum_{i<j \leq n}P(A_i \cap A_j) + 3\sum_{i<j<k \leq n}P(A_i \cap A_j \cap A_k) - \ldots \\
&\qquad \ldots + (-1)^{n-1} n P(\bigcap_{i=1}^n A_i)
\end{align*}","['probability', 'probability-theory']"
73,Reasoning gone wrong?,Reasoning gone wrong?,,"While I was going through the previous year question paper of a college entrance examination conducted in our country, I came across this particular problem. The probability of men getting a certain disease is $\frac{1}{2}$ and that of women getting the same disease is $\frac{1}{5}$ . The blood test that identifies the disease gives the correct result with probability $4/5$ . Suppose a person is chosen at random from a group of $30$ males and $20$ females, the blood test of the person is found to be positive. What is the probablity that the chosen person is a man? Now at that time I wasn't aware of using conditional probability so I went a quite different way. The test could have been correct or maybe wrong. If we consider the case where the test is correct. Number of diseased men $= 30(\frac{1}{2})=15$ . Number of diseased women $ = 20(\frac{1}{5})=4$ . Given that the test is positive the probability is $(\frac{4}{5})(\frac{15}{15+4})$ If the test is incorrect then that particular person do not have the disease. Total men and women without the disease $15+16=31$ Probabilty for this case : $(\frac{1}{5})(\frac{15}{15+16})$ Adding both cases gives $\approx0.72$ However the real ansewer is around $0.70$ which is obatined by using conditional probabilty. After this I did dug into conditional probabilities but I am still curious about why my method didn't worked. If you could point it out, I will be very grateful. Thanks","While I was going through the previous year question paper of a college entrance examination conducted in our country, I came across this particular problem. The probability of men getting a certain disease is and that of women getting the same disease is . The blood test that identifies the disease gives the correct result with probability . Suppose a person is chosen at random from a group of males and females, the blood test of the person is found to be positive. What is the probablity that the chosen person is a man? Now at that time I wasn't aware of using conditional probability so I went a quite different way. The test could have been correct or maybe wrong. If we consider the case where the test is correct. Number of diseased men . Number of diseased women . Given that the test is positive the probability is If the test is incorrect then that particular person do not have the disease. Total men and women without the disease Probabilty for this case : Adding both cases gives However the real ansewer is around which is obatined by using conditional probabilty. After this I did dug into conditional probabilities but I am still curious about why my method didn't worked. If you could point it out, I will be very grateful. Thanks",\frac{1}{2} \frac{1}{5} 4/5 30 20 = 30(\frac{1}{2})=15  = 20(\frac{1}{5})=4 (\frac{4}{5})(\frac{15}{15+4}) 15+16=31 (\frac{1}{5})(\frac{15}{15+16}) \approx0.72 0.70,"['probability', 'conditional-probability']"
74,Market Making Card Game Strategy,Market Making Card Game Strategy,,"Recently i played a market making card game during a job round of a company. Following is the description of the same - In a game there are 5 players and 13 cards, used in total. Each card has a value. At the start of the game, each player is given a card from the set of 13 cards. There will be 4 cards face down on the table. The rest of the card will be discarded and will never come back in the game. Trading - The sum S of all the values of the cards will be traded in the game,i.e, the sum of the values of 9 cards. This will be done in several steps. Round 1 - Each player will know nothing but his own card, but in the subsequent rounds, cards faced down will be revealed one at a time. One of the player, say Player 1, starts by market making S. The initial market cannot be more than 20 points wide, i.e, the sell price cannot be more than higher than the buy price. All the players are free to trade. Once a trade happens, the market maker(i.e, player 1 will make a new market. This continues untill there are no trades. Round 2 - Before the start of the round, one card on the table will be turned up. Player 2 then makes the market at most 15 points wide. As before, others can trade or improve. Round 3-5 - In the further rounds, one card at a time will be revealed. Remaining players will start making markets. The market can be at most 10 points wide in round 3, and 5 wide in subsequent rounds. Settlement - At the end of the game, we shall calculate the sum of all the values of the cards on the table. The sum will be settlement value. What strategy i should apply for making most profit?","Recently i played a market making card game during a job round of a company. Following is the description of the same - In a game there are 5 players and 13 cards, used in total. Each card has a value. At the start of the game, each player is given a card from the set of 13 cards. There will be 4 cards face down on the table. The rest of the card will be discarded and will never come back in the game. Trading - The sum S of all the values of the cards will be traded in the game,i.e, the sum of the values of 9 cards. This will be done in several steps. Round 1 - Each player will know nothing but his own card, but in the subsequent rounds, cards faced down will be revealed one at a time. One of the player, say Player 1, starts by market making S. The initial market cannot be more than 20 points wide, i.e, the sell price cannot be more than higher than the buy price. All the players are free to trade. Once a trade happens, the market maker(i.e, player 1 will make a new market. This continues untill there are no trades. Round 2 - Before the start of the round, one card on the table will be turned up. Player 2 then makes the market at most 15 points wide. As before, others can trade or improve. Round 3-5 - In the further rounds, one card at a time will be revealed. Remaining players will start making markets. The market can be at most 10 points wide in round 3, and 5 wide in subsequent rounds. Settlement - At the end of the game, we shall calculate the sum of all the values of the cards on the table. The sum will be settlement value. What strategy i should apply for making most profit?",,"['probability', 'finance']"
75,Airplane seats probability [duplicate],Airplane seats probability [duplicate],,"This question already has an answer here : Disease probability with Bayes' Rule and airplane seats probability (1 answer) Closed 2 years ago . A company has small airplanes that fit $8$ people. Results show that 1 out of $10$ passengers does not show up when buying a ticket. Thus the company sells tickets to the first $10$ people who buy. The probability of k tickets sold is: \begin{align*} P(k=6) & = 0.3\\ P(k=7) & = 0.3\\ P(k=8) & = 0.2\\ P(k=9) & = 0.15\\ P(k=10) & = 0.05 \end{align*} What is the probability of more people showing up than there are available places? Attempt: $X =$ people who show up I'm looking for $P(X \geq 9)$ . So I believe that becomes $$P(X = 9|k=9)P(k=9) + P(X = 9|k=10)P(k=10) + P(X=10|k=10)P(k=10)$$ But I only know the $P(k=...)$ , right? How can I find the other terms? How do I take the $1$ out of $10$ into account for 9 people? Please help me out here, this exercise really troubles me.","This question already has an answer here : Disease probability with Bayes' Rule and airplane seats probability (1 answer) Closed 2 years ago . A company has small airplanes that fit people. Results show that 1 out of passengers does not show up when buying a ticket. Thus the company sells tickets to the first people who buy. The probability of k tickets sold is: What is the probability of more people showing up than there are available places? Attempt: people who show up I'm looking for . So I believe that becomes But I only know the , right? How can I find the other terms? How do I take the out of into account for 9 people? Please help me out here, this exercise really troubles me.","8 10 10 \begin{align*}
P(k=6) & = 0.3\\
P(k=7) & = 0.3\\
P(k=8) & = 0.2\\
P(k=9) & = 0.15\\
P(k=10) & = 0.05
\end{align*} X = P(X \geq 9) P(X = 9|k=9)P(k=9) + P(X = 9|k=10)P(k=10) + P(X=10|k=10)P(k=10) P(k=...) 1 10","['probability', 'statistics']"
76,Expected number of elements in intersection of two randomly sampled subsets from two different sets,Expected number of elements in intersection of two randomly sampled subsets from two different sets,,"Let's say you have two sets $A$ with $5000$ elements and $B$ with $8000$ elements, $A ∩ B$ contains $500$ elements. Let's say we randomly sample $500$ elements from set $A$ , name it $A'$ and randomly sample $800$ elements for set $B$ , name it $B'$ . What is the expected number of elements in the set $A' ∩ B'$ ? Thinking in the naive way results in an answer of $50$ , which is wrong. I am unable to proceed in any particular direction. Any leads would be helpful ?","Let's say you have two sets with elements and with elements, contains elements. Let's say we randomly sample elements from set , name it and randomly sample elements for set , name it . What is the expected number of elements in the set ? Thinking in the naive way results in an answer of , which is wrong. I am unable to proceed in any particular direction. Any leads would be helpful ?",A 5000 B 8000 A ∩ B 500 500 A A' 800 B B' A' ∩ B' 50,"['probability', 'expected-value']"
77,Simple combinatorics and probability theory related question,Simple combinatorics and probability theory related question,,"5 apples are randomly distributed to 4 boxes. We need to find probability that there are 2 boxes with 2 apples, 1 box with 1 apple and 1 empty box. I'm getting the correct answer with $\frac{\frac{5!}{2!2!1!0!} * 4 * 3}{4^5} = 0.3515625$ (anyway, the answer is said to be 0.35, but I think it is a matter of rounding). But I don't understand why there are $4^5$ elementary events in total. Firstly, I thought It should be $(\!\!\binom{4}{5}\!\!)$ - number of combinations with repetitions, but I couldn't get the proper answer. Isn't approach with $(\!\!\binom{4}{5}\!\!)$ elementary events more correct? Apples don't seem distinct to me - that's the reason.  Or, may be, we can solve this problem with sample space in which apples are not distinct?","5 apples are randomly distributed to 4 boxes. We need to find probability that there are 2 boxes with 2 apples, 1 box with 1 apple and 1 empty box. I'm getting the correct answer with (anyway, the answer is said to be 0.35, but I think it is a matter of rounding). But I don't understand why there are elementary events in total. Firstly, I thought It should be - number of combinations with repetitions, but I couldn't get the proper answer. Isn't approach with elementary events more correct? Apples don't seem distinct to me - that's the reason.  Or, may be, we can solve this problem with sample space in which apples are not distinct?",\frac{\frac{5!}{2!2!1!0!} * 4 * 3}{4^5} = 0.3515625 4^5 (\!\!\binom{4}{5}\!\!) (\!\!\binom{4}{5}\!\!),"['combinatorics', 'elementary-probability']"
78,Three dice are thrown simultaneously,Three dice are thrown simultaneously,,"Three dice are thrown simultaneously . The probability that 4 appears on two dice , given that 5 has appeared on one dice is . The way I’ve gone about it is : _ _ 5 , _ 5 _ , 5 _ _ A: event of 4 appearing twice B: event of 5 appearing once (In three throws ) Then , P(A/B) = P(A∩B)/P(B) = $\frac{^3C_1(1/6)^3}{^3C_1 (1/6)}$ Where $^3C_1$ in the numerator is for selecting any 1 dice for 5 and the other two automatically get selected for 4 . While $(1/6)^3$ Is probability of digits 5 ,4,4 appearing on the 3 dices . This method is not giving me the desired answer ,as given in the question . The ans given is $\frac{3}{91}$","Three dice are thrown simultaneously . The probability that 4 appears on two dice , given that 5 has appeared on one dice is . The way I’ve gone about it is : _ _ 5 , _ 5 _ , 5 _ _ A: event of 4 appearing twice B: event of 5 appearing once (In three throws ) Then , P(A/B) = P(A∩B)/P(B) = Where in the numerator is for selecting any 1 dice for 5 and the other two automatically get selected for 4 . While Is probability of digits 5 ,4,4 appearing on the 3 dices . This method is not giving me the desired answer ,as given in the question . The ans given is",\frac{^3C_1(1/6)^3}{^3C_1 (1/6)} ^3C_1 (1/6)^3 \frac{3}{91},"['probability', 'combinatorics', 'permutations', 'combinations', 'conditional-probability']"
79,Truncated Sieltjes r-atomic moment problem,Truncated Sieltjes r-atomic moment problem,,"Given a certain $n \in \mathbb{N}$ , can i construct a discrete positive random variable $X$ that fullfill the following conditions : $$\forall k \in \{1,...,n\}, \mathbb{E}(X^k) = \mu_k$$ for some $\mu_k$ given (parameters). We suppose that there exists such a random variable (in facts, the $\mu$ 's come from a random variable that i want to estimate). For exemple, for $n=1$ , it is enough to set a dirac in $\mu_1$ . for $n=2$ , take a radom variable with 2 atoms $\mu_1 +x$ and $\mu_1 -x$ with equal probability and choose x such that : $$\mu_1^2 + x^2 = \mu_2$$ giving $x = \sqrt{\mu_2 - \mu_1^2}$ . What about $n \ge 3$ ? Edits : 1° Yes, it is possible (prooved to be possible by many diffrent papers, notably Tchakaloff's theorems).  2° Yes, there exists some algorithm to do it, but i did not found a propper one yet.","Given a certain , can i construct a discrete positive random variable that fullfill the following conditions : for some given (parameters). We suppose that there exists such a random variable (in facts, the 's come from a random variable that i want to estimate). For exemple, for , it is enough to set a dirac in . for , take a radom variable with 2 atoms and with equal probability and choose x such that : giving . What about ? Edits : 1° Yes, it is possible (prooved to be possible by many diffrent papers, notably Tchakaloff's theorems).  2° Yes, there exists some algorithm to do it, but i did not found a propper one yet.","n \in \mathbb{N} X \forall k \in \{1,...,n\}, \mathbb{E}(X^k) = \mu_k \mu_k \mu n=1 \mu_1 n=2 \mu_1 +x \mu_1 -x \mu_1^2 + x^2 = \mu_2 x = \sqrt{\mu_2 - \mu_1^2} n \ge 3","['probability', 'random-variables', 'moment-problem']"
80,Proof of the equivalence of the two definitions of heavy-tailed distributions,Proof of the equivalence of the two definitions of heavy-tailed distributions,,"Heavy-tailed distributions have two equivalent definitions: For any $\lambda>0$ , the moment generating function of the distribution (denoted by $F$ ) blows up: $$\int_{\mathbb{R}}e^{\lambda x}\mathrm{d}F(x)=+\infty$$ or For any $\lambda>0$ , the decrease of the tail probability of $F$ is slower than exponentially increase: $$\lim_{x\to+\infty}e^{\lambda x}(1-F(x))=+\infty$$ That the second definition implies the first one is not difficult to prove, but how to give a proof to its converse, i.e. how to derive the second definition from the first one?","Heavy-tailed distributions have two equivalent definitions: For any , the moment generating function of the distribution (denoted by ) blows up: or For any , the decrease of the tail probability of is slower than exponentially increase: That the second definition implies the first one is not difficult to prove, but how to give a proof to its converse, i.e. how to derive the second definition from the first one?",\lambda>0 F \int_{\mathbb{R}}e^{\lambda x}\mathrm{d}F(x)=+\infty \lambda>0 F \lim_{x\to+\infty}e^{\lambda x}(1-F(x))=+\infty,"['calculus', 'probability', 'integration', 'probability-theory', 'probability-distributions']"
81,Differentiable top-k function,Differentiable top-k function,,"Is there any differentiable function that, for a given vector, selects and encourages the top-k maximum value and suppresses the rest of the values? For example for z = [0.01 0.1 0.04 0.5 0.24] the top 3 would something like this: top-3(z) = [1e-10 0.89 2e-9 0.98 0.92]","Is there any differentiable function that, for a given vector, selects and encourages the top-k maximum value and suppresses the rest of the values? For example for z = [0.01 0.1 0.04 0.5 0.24] the top 3 would something like this: top-3(z) = [1e-10 0.89 2e-9 0.98 0.92]",,"['probability', 'integration', 'functions', 'derivatives']"
82,Need help fixing/clarifying my thinking about iid RVs after learning some 1st Yr Stats,Need help fixing/clarifying my thinking about iid RVs after learning some 1st Yr Stats,,"First a warning: this is not the most interesting question but I want to update my understanding of independence now that I'm taking 1st year statistics I often heard in my 1st year probability class that ""independent RVs don't give any information about each other"" Rolling a fair dice $99$ times doesn't give info on the hundredth roll However, let's say $X_1, ..., X_{100}$ are iid discrete uniform from $1$ to $\theta$ which is unknown Then by observing $X_1,...,X_{99}$ you can make inferences about the hundredth observation and make a prediction interval Is it safe to say that: given you know all the parameters or complete pmf/pdf of $F$ , independent RVs don't give any information about each other. However, given that there are unknown parameters, independent RVs do give you information about each other. Does that make sense to even say? I know this is more of an English question versus formal definitions (splitting pmfs/pdfs) but I'd like to try and be precise about this. Thanks for your help and patience.","First a warning: this is not the most interesting question but I want to update my understanding of independence now that I'm taking 1st year statistics I often heard in my 1st year probability class that ""independent RVs don't give any information about each other"" Rolling a fair dice times doesn't give info on the hundredth roll However, let's say are iid discrete uniform from to which is unknown Then by observing you can make inferences about the hundredth observation and make a prediction interval Is it safe to say that: given you know all the parameters or complete pmf/pdf of , independent RVs don't give any information about each other. However, given that there are unknown parameters, independent RVs do give you information about each other. Does that make sense to even say? I know this is more of an English question versus formal definitions (splitting pmfs/pdfs) but I'd like to try and be precise about this. Thanks for your help and patience.","99 X_1, ..., X_{100} 1 \theta X_1,...,X_{99} F","['probability', 'independence']"
83,Probability of $y \leq x$ given $x \leq \frac 12$,Probability of  given,y \leq x x \leq \frac 12,"Please help me understand solve this problem. Let the sample space be the unit square, $\Omega =[0,1]^2$ , and let the probability of a set be the area of the set. Let $A$ be the set of points $(x,y) \in [0,1]^2$ for which $y \leq x$ . Let $B$ be the set of points for which $x \leq \frac 12$ . Find $\mathbf P(A∣B)$ . Is the region of $\mathbf P(A∣B)$ not the dark shaded triangle region in the following image? If so, isn't the area $\frac 12$ base height. In which case, I get $\frac 12 \cdot (\frac 12 \cdot \frac 12) = \frac 18$ . But my answer is wrong. How do I work this problem out? Thank you.","Please help me understand solve this problem. Let the sample space be the unit square, , and let the probability of a set be the area of the set. Let be the set of points for which . Let be the set of points for which . Find . Is the region of not the dark shaded triangle region in the following image? If so, isn't the area base height. In which case, I get . But my answer is wrong. How do I work this problem out? Thank you.","\Omega =[0,1]^2 A (x,y) \in [0,1]^2 y \leq x B x \leq \frac 12 \mathbf P(A∣B) \mathbf P(A∣B) \frac 12 \frac 12 \cdot (\frac 12 \cdot \frac 12) = \frac 18","['probability', 'probability-theory', 'conditional-probability']"
84,1 Black and 1 White Ball in an Urn Black Balls Added After Each Black Draw,1 Black and 1 White Ball in an Urn Black Balls Added After Each Black Draw,,"As in title I am looking for the answer to the following problem: We have an urn with 1 black and 1 white ball in it. If you pick a black ball, then you put in another black ball each time until you pick the white ball. Once the white ball is picked the game stops. What is the expected number of balls to be drawn in order for the game to end? Here is what I did: I denoted the probability of stopping at the $k$ -th draw with $P(X=k)$ . Then, $$P(X=1) = \frac 12, $$ $$P(X=2) = \frac 12*\frac13, $$ $$P(X=3) = \frac12*\frac23*\frac14,$$ $$P(X=4) = \frac12*\frac23*\frac34*\frac15$$ and continuing in this manner I find $$P(X=k) = \frac1{k(k+1)}$$ Now, to calculate the expected value, I multiply with $k$ and sum over all $k$ . $$E[X] = \sum_{k=1}^\infty \frac k{k*(k+1)} = \sum_{k=1}^\infty \frac 1{(k+1)}$$ which as we know from p-test, diverges. What am I doing wrong? Any suggestions? Thanks.","As in title I am looking for the answer to the following problem: We have an urn with 1 black and 1 white ball in it. If you pick a black ball, then you put in another black ball each time until you pick the white ball. Once the white ball is picked the game stops. What is the expected number of balls to be drawn in order for the game to end? Here is what I did: I denoted the probability of stopping at the -th draw with . Then, and continuing in this manner I find Now, to calculate the expected value, I multiply with and sum over all . which as we know from p-test, diverges. What am I doing wrong? Any suggestions? Thanks.","k P(X=k) P(X=1) = \frac 12,  P(X=2) = \frac 12*\frac13,  P(X=3) = \frac12*\frac23*\frac14, P(X=4) = \frac12*\frac23*\frac34*\frac15 P(X=k) = \frac1{k(k+1)} k k E[X] = \sum_{k=1}^\infty \frac k{k*(k+1)} = \sum_{k=1}^\infty \frac 1{(k+1)}","['probability', 'expected-value', 'polya-urn-model']"
85,Sum of two random variables uniformly distributed on circles,Sum of two random variables uniformly distributed on circles,,"Suppose we have two independent random variables $U_1$ and $U_2$ unfiorm  on \begin{align} S_i = \left\{ (s_1,s_2) \in \mathbb{R}: \sqrt{s_1^2+s_2^2} =r_i \right\}  \end{align} respectily. Assume $r_1 \ge r_2$ . Question: How to find the pdf of $U_1+U_2$ ? We know that it would be distributed on \begin{align} S_3 = \left\{ (s_1,s_2) \in \mathbb{R}: r_1-r_2 \le  \sqrt{s_1^2+s_2^2} \le r_1+r_2 \right\}  \end{align} In other words, show that the sum of two random variables on the circles results in a random variable distributed on an annulus. The question now is how to find the pdf of $U_1+U_2$ ? Can this, for example, be done by using characteristic functions?","Suppose we have two independent random variables and unfiorm  on respectily. Assume . Question: How to find the pdf of ? We know that it would be distributed on In other words, show that the sum of two random variables on the circles results in a random variable distributed on an annulus. The question now is how to find the pdf of ? Can this, for example, be done by using characteristic functions?","U_1 U_2 \begin{align}
S_i = \left\{ (s_1,s_2) \in \mathbb{R}: \sqrt{s_1^2+s_2^2} =r_i \right\} 
\end{align} r_1 \ge r_2 U_1+U_2 \begin{align}
S_3 = \left\{ (s_1,s_2) \in \mathbb{R}: r_1-r_2 \le  \sqrt{s_1^2+s_2^2} \le r_1+r_2 \right\} 
\end{align} U_1+U_2","['probability', 'probability-theory']"
86,Free throws in basketball game about probability [closed],Free throws in basketball game about probability [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last month . Improve this question Someone shoots free throws. He/She made the first one and missed the second one. From the third shot, the probability of hitting the ball equals to the free throw percentage he/she made before it. For example, if the made 87 out of 100 tries. Then the probability of making the next one is 87/100. What is the probability of the person making the n th? Does it matter whether he makes the n-1 th free throws?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed last month . Improve this question Someone shoots free throws. He/She made the first one and missed the second one. From the third shot, the probability of hitting the ball equals to the free throw percentage he/she made before it. For example, if the made 87 out of 100 tries. Then the probability of making the next one is 87/100. What is the probability of the person making the n th? Does it matter whether he makes the n-1 th free throws?",,['probability']
87,Recurrence of Brownian Motion,Recurrence of Brownian Motion,,"I am reading a proof of recurrence of Brownian Motion from the book of Morters and Peres. I have a question about a particular step in the proof of neighborhood recurrence for Brownian Motion in dimension 2. He has proven that if the Brownian Motion starts at $x\in {\Bbb R}^2$ then with probability 1 it enters any annulus in finite time. I have no problem with the way he proves this. Using this fact, he begins to prove the neighborhood recurrence for dimension 2. The proof is as follows. By the above property and shift-invariance the stopping time $ t_1$ = inf $\{t > 0: B(t) ∈ B(x, ε)\}$ is almost surely finite. Using the strong Markov property at time $t_1+1$ we see that this also applies to $t_2$ = inf $\{t > t_1 + 1: B(t) ∈ B(x, ε)\}$ , and continuing like this, we obtain a sequence of times $t_n ↑ \infty$ such that, almost surely, $B(t_n ) ∈ B(x, ε)$ for all $n ∈ {\Bbb N}$ . Taking an intersection over a countable family of balls $(B(x_i, ε_i): i = 1, 2, . . .)$ , forming a basis of the Euclidean topology, implies that in $d = 2$ Brownian motion is neighbourhood recurrent. My issue is with the application of the Strong Markov Property (SMP) in this proof. I assume we are applying the SMP for the stopping time $t_1+1$ . So now we consider the Brownian Motion starting at $t_1+1$ i.e we will consider the process $\{B^{(1)}(t)=B(t+t_1+1)-B(t_1+1):t\geq0\}$ . Since $\{B^{(1)}(t):t\geq0\}$ is a Brownian Motion starting at the origin, with probability 1, it will enter the ball $B(x,\epsilon)$ in finite time. However, $B^{(1)}$ only measures the displacement of $B(t)$ after the stopping time $t_1+1$ . How does $B^{(1)}(t)\in B(x,\epsilon)$ (or in fact $B^{(1)}(t)$ being in any other open ball) produce a new time point, say $t'\geq t_1+1$ such that $B(t')\in B(x.\epsilon)$ ? Once this issue is resolved, the rest of the proof I am fully on board with. It's just this part that is bugging me. I can intuitively see what the author is getting at but I'm looking for some rigorous justification. Clearly there is a step here but I cannot figure it out. Any help would be great. Thanks.","I am reading a proof of recurrence of Brownian Motion from the book of Morters and Peres. I have a question about a particular step in the proof of neighborhood recurrence for Brownian Motion in dimension 2. He has proven that if the Brownian Motion starts at then with probability 1 it enters any annulus in finite time. I have no problem with the way he proves this. Using this fact, he begins to prove the neighborhood recurrence for dimension 2. The proof is as follows. By the above property and shift-invariance the stopping time = inf is almost surely finite. Using the strong Markov property at time we see that this also applies to = inf , and continuing like this, we obtain a sequence of times such that, almost surely, for all . Taking an intersection over a countable family of balls , forming a basis of the Euclidean topology, implies that in Brownian motion is neighbourhood recurrent. My issue is with the application of the Strong Markov Property (SMP) in this proof. I assume we are applying the SMP for the stopping time . So now we consider the Brownian Motion starting at i.e we will consider the process . Since is a Brownian Motion starting at the origin, with probability 1, it will enter the ball in finite time. However, only measures the displacement of after the stopping time . How does (or in fact being in any other open ball) produce a new time point, say such that ? Once this issue is resolved, the rest of the proof I am fully on board with. It's just this part that is bugging me. I can intuitively see what the author is getting at but I'm looking for some rigorous justification. Clearly there is a step here but I cannot figure it out. Any help would be great. Thanks.","x\in {\Bbb R}^2  t_1 \{t >
0: B(t) ∈ B(x, ε)\} t_1+1 t_2 \{t > t_1 + 1: B(t) ∈ B(x, ε)\} t_n ↑ \infty B(t_n ) ∈ B(x, ε) n ∈ {\Bbb N} (B(x_i, ε_i): i = 1, 2, . . .) d = 2 t_1+1 t_1+1 \{B^{(1)}(t)=B(t+t_1+1)-B(t_1+1):t\geq0\} \{B^{(1)}(t):t\geq0\} B(x,\epsilon) B^{(1)} B(t) t_1+1 B^{(1)}(t)\in B(x,\epsilon) B^{(1)}(t) t'\geq t_1+1 B(t')\in B(x.\epsilon)","['probability', 'stochastic-processes', 'proof-explanation', 'brownian-motion']"
88,When a.e. convergence does not imply convergence in probability,When a.e. convergence does not imply convergence in probability,,"In Varadhan's probability theory text, it is noted that countable additivity is key for showing that convergence a.e. implies convergence in measure. I'm wondering if there is a salient example of a finitely additive ""probability"" measure (i.e. a measure that has all the properties of a probability measure except is merely finitely and not countably additive), such that convergence a.e. no longer implies convergence in probability. Of course, if we don't require that the entire space has finite measure, then we can come up with examples like $f_n = \chi_{n,n+1}$ , but this sort of example doesn't work in a probability space, since of course the tails have to vanish, so in fact this sort of r.v. does in fact converge in probability to zero. I'm more interested in a measure that otherwise acts like a probability measure outside of the countable additivity, in the hope that it will give me further intuition for why countable additivity is so crucial here (and please don't just refer to the proof for ""intuition"" -- I am familiar with the proof, and I understand in theory why countable additivity is important, but I think an illustrative example would make the phenomenon more salient).","In Varadhan's probability theory text, it is noted that countable additivity is key for showing that convergence a.e. implies convergence in measure. I'm wondering if there is a salient example of a finitely additive ""probability"" measure (i.e. a measure that has all the properties of a probability measure except is merely finitely and not countably additive), such that convergence a.e. no longer implies convergence in probability. Of course, if we don't require that the entire space has finite measure, then we can come up with examples like , but this sort of example doesn't work in a probability space, since of course the tails have to vanish, so in fact this sort of r.v. does in fact converge in probability to zero. I'm more interested in a measure that otherwise acts like a probability measure outside of the countable additivity, in the hope that it will give me further intuition for why countable additivity is so crucial here (and please don't just refer to the proof for ""intuition"" -- I am familiar with the proof, and I understand in theory why countable additivity is important, but I think an illustrative example would make the phenomenon more salient).","f_n = \chi_{n,n+1}","['probability', 'probability-theory', 'measure-theory', 'convergence-divergence']"
89,"Maximum entropy distribution given constrained minimum, maximum, and mean","Maximum entropy distribution given constrained minimum, maximum, and mean",,"What kind of distribution do we get if we constrain the range to be the unit interval and also constrain the mean to be $\alpha$ ? If we read this table , we see the following two examples of maximum entropy distributions. The standard normal distribution is the maximum entropy distribution with mean 0 and variance 1. Similarly, if we restrict out attention to distributions with bounded support, then the uniform distribution is the maximum entropy distribution. I'm writing a small library to estimate quantiles in a stream of data and am currently keeping track of the sample minimum, maximum, and mean, but am not using the sample mean to estimate quantiles directly. So, what kind of distribution do we get if we constrain the range to be the unit interval and also constrain the mean to be $\alpha$ ? In general, is there a good strategy for figuring out a closed form for the pdf of a maximum entropy distribution satisfying an arbitrary collection of properties?","What kind of distribution do we get if we constrain the range to be the unit interval and also constrain the mean to be ? If we read this table , we see the following two examples of maximum entropy distributions. The standard normal distribution is the maximum entropy distribution with mean 0 and variance 1. Similarly, if we restrict out attention to distributions with bounded support, then the uniform distribution is the maximum entropy distribution. I'm writing a small library to estimate quantiles in a stream of data and am currently keeping track of the sample minimum, maximum, and mean, but am not using the sample mean to estimate quantiles directly. So, what kind of distribution do we get if we constrain the range to be the unit interval and also constrain the mean to be ? In general, is there a good strategy for figuring out a closed form for the pdf of a maximum entropy distribution satisfying an arbitrary collection of properties?",\alpha \alpha,"['probability', 'entropy']"
90,Consistency for maximum likelihood estimator with a single sample,Consistency for maximum likelihood estimator with a single sample,,"Suppose you have a finite family of probability measures $\{\mu_\theta: \theta \in S\}$ on a finite space $\Omega$ (with respect to the discrete sigma algebra). Let $X$ be a random element of $\Omega$ distributed according to $\mu_{\theta_0}$ , for some fixed $\theta_0 \in \Omega$ . Consider the maximum likelihood estimator for $\theta_0$ : $\hat{\theta}_{MLE} = \arg\max_\theta L(\theta | X)$ . Here $L$ is the usual likelihood, $L(\theta | X) = \mu_\theta(X)$ . I'm curious about consistency for the MLE in this simple setup, but not in the usual sense of 'asymptotic consistency:' rather, I want to know if there are some conditions under which the MLE is consistent for a single sample , i.e. $\arg \max_\theta \mathbb{P}(\hat{\theta}_{MLE} = \theta) = \theta_0$ . (Sorry if my notation is a bit weird -- let me know if it's confusing and I'll try to clarify.) I am guessing this can fail in general -- is there a simple example? Are there some conditions under which it holds? It is true that the expected value of $L(\theta|X)$ is maximized at $\theta = \theta_0$ . Indeed, by Cauchy-Schwarz: $\mathbb{E}L(\theta | X) = \mathbb{E}\mu_\theta(X) = \sum_\omega \mu_\theta(\omega) \mu_{\theta_0}(\omega) \leq \sqrt{\sum_\omega \mu_\theta(\omega)^2 \sum_\omega \mu_{\theta_0}(\omega)^2}$ Equality occurs when $\theta = \theta_0$ . But this doesn't imply that the density of the MLE is maximized there. Edit 1: To be careful, the conclusion should be that $\theta_0$ is a point that maximizes the density of the MLE (not necessarily the only point).","Suppose you have a finite family of probability measures on a finite space (with respect to the discrete sigma algebra). Let be a random element of distributed according to , for some fixed . Consider the maximum likelihood estimator for : . Here is the usual likelihood, . I'm curious about consistency for the MLE in this simple setup, but not in the usual sense of 'asymptotic consistency:' rather, I want to know if there are some conditions under which the MLE is consistent for a single sample , i.e. . (Sorry if my notation is a bit weird -- let me know if it's confusing and I'll try to clarify.) I am guessing this can fail in general -- is there a simple example? Are there some conditions under which it holds? It is true that the expected value of is maximized at . Indeed, by Cauchy-Schwarz: Equality occurs when . But this doesn't imply that the density of the MLE is maximized there. Edit 1: To be careful, the conclusion should be that is a point that maximizes the density of the MLE (not necessarily the only point).",\{\mu_\theta: \theta \in S\} \Omega X \Omega \mu_{\theta_0} \theta_0 \in \Omega \theta_0 \hat{\theta}_{MLE} = \arg\max_\theta L(\theta | X) L L(\theta | X) = \mu_\theta(X) \arg \max_\theta \mathbb{P}(\hat{\theta}_{MLE} = \theta) = \theta_0 L(\theta|X) \theta = \theta_0 \mathbb{E}L(\theta | X) = \mathbb{E}\mu_\theta(X) = \sum_\omega \mu_\theta(\omega) \mu_{\theta_0}(\omega) \leq \sqrt{\sum_\omega \mu_\theta(\omega)^2 \sum_\omega \mu_{\theta_0}(\omega)^2} \theta = \theta_0 \theta_0,"['probability', 'statistics', 'maximum-likelihood']"
91,Poisson as a limit of the Binomial Characteristic Function,Poisson as a limit of the Binomial Characteristic Function,,"We are given $X_n\sim B(n,p_n)$ where $np_n\rightarrow\lambda$ , and $\lambda>0$ . The goal is to prove $X_n$ converges in distribution to Poisson( $\lambda$ ) by use of characteristic functions. My issue is proving this with $p_n$ being arbitrary as it is.  Here are my current steps: $\phi_{X_n}(t)=(1-p_n+p_ne^{it})^n=(1+p_ne^{it}-p_n)^n=(1+\frac{np_n(e^{it}-1)}{n})^n=e^{n\ln(1+\frac{np_n(e^{it}-1)}{n})}=e^\frac{\ln(1+\frac{np_n(e^{it}-1)}{n})}{1/n}$ Then evaluating the limit means examining the exponent: $\displaystyle\lim_{n\rightarrow\infty}\frac{\ln(1+\frac{np_n(e^{it}-1)}{n})}{1/n}=\frac{\ln(1+\frac{\lambda(e^{it}-1)}{\displaystyle\lim_{n\rightarrow\infty} n})}{\displaystyle\lim_{n\rightarrow\infty}1/n}=\frac{\ln(1)}{0}=\frac{0}{0}$ . At this point I look to applying L'Hoptials rule, but I need to tweak something because when doing a u-substitution of $u = 1+\frac{np_n(e^{it}-1)}{n}$ I'm not sure how to evaluate the derivative to get the result. I would imagine it is just zero, treating $p_n$ as a constant, but then this falls apart.  As for treating the derivative with $p_n$ , I don't see the trick.  My first thought was the difference quotient manually, but that did not lead anywhere obvious. The result should be $\displaystyle\lim_{n\rightarrow\infty}\phi_{X_n}(t)=e^{\lambda(e^{it}-1)}$ , which is the $Poisson(\lambda)$ characteristic function. Any feedback is much appreciated.","We are given where , and . The goal is to prove converges in distribution to Poisson( ) by use of characteristic functions. My issue is proving this with being arbitrary as it is.  Here are my current steps: Then evaluating the limit means examining the exponent: . At this point I look to applying L'Hoptials rule, but I need to tweak something because when doing a u-substitution of I'm not sure how to evaluate the derivative to get the result. I would imagine it is just zero, treating as a constant, but then this falls apart.  As for treating the derivative with , I don't see the trick.  My first thought was the difference quotient manually, but that did not lead anywhere obvious. The result should be , which is the characteristic function. Any feedback is much appreciated.","X_n\sim B(n,p_n) np_n\rightarrow\lambda \lambda>0 X_n \lambda p_n \phi_{X_n}(t)=(1-p_n+p_ne^{it})^n=(1+p_ne^{it}-p_n)^n=(1+\frac{np_n(e^{it}-1)}{n})^n=e^{n\ln(1+\frac{np_n(e^{it}-1)}{n})}=e^\frac{\ln(1+\frac{np_n(e^{it}-1)}{n})}{1/n} \displaystyle\lim_{n\rightarrow\infty}\frac{\ln(1+\frac{np_n(e^{it}-1)}{n})}{1/n}=\frac{\ln(1+\frac{\lambda(e^{it}-1)}{\displaystyle\lim_{n\rightarrow\infty} n})}{\displaystyle\lim_{n\rightarrow\infty}1/n}=\frac{\ln(1)}{0}=\frac{0}{0} u = 1+\frac{np_n(e^{it}-1)}{n} p_n p_n \displaystyle\lim_{n\rightarrow\infty}\phi_{X_n}(t)=e^{\lambda(e^{it}-1)} Poisson(\lambda)","['real-analysis', 'probability', 'probability-distributions', 'fourier-transform', 'characteristic-functions']"
92,A strange inconsistency between a calculation and a simulation of a TASEP,A strange inconsistency between a calculation and a simulation of a TASEP,,"Consider the following stochastic process, called a totally asymmetric simple exclusion process (TASEP), on the integers $\mathbb{Z}$ : The process evolves over discrete time steps $T = 1, 2, \ldots \infty$ . Denote the contents of the integer $n$ as $x(n)$ . Initially, at every integer $n$ , $x(n)=1$ with probability $0.5$ and otherwise $x(n)=0$ . If for some $n$ we have that $x(n)=1$ and $x(n+1)=0$ , then with probability $0.5$ , at the next time step we will have $x(n)=0$ and $x(n+1)=1$ . (In other words, every $1$ moves right with probability 0.5, assuming there isn't a $1$ blocking it in its new target position). It's simple to see that the initial distribution (where we have $1$ with probability $0.5$ ) is stationary. (Edit: Based on page 2 of this paper https://arxiv.org/abs/cond-mat/0101200 ), this means that in expectation we should expect the number of $1$ s passing through $n=0$ to be $T/4$ , where $T$ is the number of time steps that have passed. Now consider the following program, which I simulated on my computer: Initialize a 0-1 array a[-1000,1000] such that a[n] = 1 with probability 0.5. Simulate the above Stochastic process for 100 iterations. Count the number of times a[0] goes from 0 to 1. The result of this program is consistently around $15$ , but by the above reasoning we would expect $25$ . In fact, it seems it will always be on average a $0.15$ fraction of the number of iterations (even doing 200, or 300 iterations at a time). So is the math wrong, or is my simulation idea wrong? Actual code I used: https://pastebin.com/iPz1S1fK (""count"" is the number that comes out as 15; prob(50) means ""with probability 50""; Update() performs a single iteration of the TASEP)","Consider the following stochastic process, called a totally asymmetric simple exclusion process (TASEP), on the integers : The process evolves over discrete time steps . Denote the contents of the integer as . Initially, at every integer , with probability and otherwise . If for some we have that and , then with probability , at the next time step we will have and . (In other words, every moves right with probability 0.5, assuming there isn't a blocking it in its new target position). It's simple to see that the initial distribution (where we have with probability ) is stationary. (Edit: Based on page 2 of this paper https://arxiv.org/abs/cond-mat/0101200 ), this means that in expectation we should expect the number of s passing through to be , where is the number of time steps that have passed. Now consider the following program, which I simulated on my computer: Initialize a 0-1 array a[-1000,1000] such that a[n] = 1 with probability 0.5. Simulate the above Stochastic process for 100 iterations. Count the number of times a[0] goes from 0 to 1. The result of this program is consistently around , but by the above reasoning we would expect . In fact, it seems it will always be on average a fraction of the number of iterations (even doing 200, or 300 iterations at a time). So is the math wrong, or is my simulation idea wrong? Actual code I used: https://pastebin.com/iPz1S1fK (""count"" is the number that comes out as 15; prob(50) means ""with probability 50""; Update() performs a single iteration of the TASEP)","\mathbb{Z} T = 1, 2, \ldots \infty n x(n) n x(n)=1 0.5 x(n)=0 n x(n)=1 x(n+1)=0 0.5 x(n)=0 x(n+1)=1 1 1 1 0.5 1 n=0 T/4 T 15 25 0.15","['probability', 'stochastic-processes', 'markov-process']"
93,Prove that if $P[X\leq Y] =1$ then $E[X]\leq E[Y]$,Prove that if  then,P[X\leq Y] =1 E[X]\leq E[Y],I would like to prove/disprove that following claim: Prove that if $P[X\leq Y] =1$ then $E[X]\leq E[Y]$ How can it be done?,I would like to prove/disprove that following claim: Prove that if then How can it be done?,P[X\leq Y] =1 E[X]\leq E[Y],"['probability', 'expected-value']"
94,Generalized Owen's T function,Generalized Owen's T function,,"As Wikipedia teaches us https://en.wikipedia.org/wiki/Owen%27s_T_function the Owen's T function $T(h,a)$ defines a probability of a bivariate event $X>h$ and $0<Y<a X$ where $X,Y$ are standard, independent Gaussian random variables. Now in the context of question Multivariate gaussian integral over positive reals a necessity appeared to deal with a slightly more general quantity. \begin{equation} T(h,a,b):= {\bf P}\left(X>h \quad \wedge \quad a X+b > Y > 0 \left. \right| X = N(0,1) , Y=N(0,1)   \right) \end{equation} We have shown that : \begin{eqnarray} &&T(h,a,b)= \int\limits_h^\infty \frac{\exp(-1/2 \xi^2)}{\sqrt{2\pi}} \frac{1}{2} Erf(\frac{a \xi+b}{\sqrt{2}}) d\xi \quad (i1)\\ &&= \int\limits_0^a \frac{e^{-\frac{b^2}{2}-b h \xi -\frac{1}{2} h^2 \left(\xi ^2+1\right)}}{2 \pi  \left(\xi ^2+1\right)} d\xi - \frac{b}{2\sqrt{2}\sqrt{\pi}} \int\limits_0^a \frac{\xi  e^{-\frac{b^2}{2 \xi ^2+2}} \text{erfc}\left(\frac{\xi  (b+h \xi )+h}{\sqrt{2} \sqrt{\xi ^2+1}}\right)}{\left(\xi ^2+1\right)^{3/2}} d\xi + \frac{1}{4} \text{erf}\left(\frac{b}{\sqrt{2}}\right) \text{erfc}\left(\frac{h}{\sqrt{2}}\right) \quad (i2) \end{eqnarray} {a, b, h} = RandomReal[{0, 1}, 3, WorkingPrecision -> 50]; b = 0; NIntegrate[  Exp[-x^2/2]/Sqrt[2 Pi] 1/2 Erf[(a x + b)/Sqrt[2]], {x, h, Infinity},   WorkingPrecision -> 20] NIntegrate[(E^(-(b^2/2) - xi b h - 1/2 (1 + xi^2) h^2)) /(    2 (1 + xi^2) \[Pi]) -     b  /(2 Sqrt[2] Sqrt[ \[Pi]]) (     xi  Erfc[(h + xi (b + xi h))/(Sqrt[2] Sqrt[1 + xi^2])])/ ((1 +        xi^2)^(3/2)) E^(-(b^2/(2 + 2 xi^2))), {xi, 0, a},    WorkingPrecision -> 20] + Erfc[h/Sqrt[2]] Erf[b/Sqrt[2]] 1/4 Update: Let $A_j \in {\mathbb R}$ for $j=1,\cdots,3$ and let $x\in {\mathbb R}$ . Then we have: \begin{eqnarray} T(A_1 x, A_2, A_3 x) =  \frac{1}{2\pi} \left(\arctan(A_2)-\arctan(A_2+\frac{A_3}{A_1})-\arctan(\frac{A_1+A_2 A_3+A_2^2 A_1}{A_3})\right) + \frac{1}{4} erf[\frac{A_3 x}{\sqrt{2} \sqrt{1+A_2^2}}] + T(A_1 x, \frac{A_2 A_1+A_3}{A_1})+ T(\frac{A_3 x}{\sqrt{1+A_2^2}},\frac{A_1+A_2 A_3 + A_2^2 A_1}{A_3}) \quad (ii) \end{eqnarray} This identity comes from differentiating both sides with respect to $x$ then using the definition of the generalized Owen's T function to evaluate the derivative on the right hand side and having done this integrating both sides with respect to $x$ again. Let us present the proof of that in detail. Firstly we define $f(x) := T[A_1 x, A_2, A_3 x]$ . Now we compute the derivative using the chain rule. We have: \begin{eqnarray} \frac{d }{d x} f(x) &=& \partial_1 T[A_1 x, A_2 , A_3 x] \cdot A_1 + \partial_3 T[A_1 x, A_2, A_3 x] \cdot A_3 \\ &=& - \left. \rho(h) \frac{1}{2} erf[\frac{a h+b}{\sqrt{2}}] \right|_{\begin{array}{r} h=A_1 x \\ a=A_2 \\ b=A_3 x \end{array}}\cdot A_1  +  \left.\frac{1}{\sqrt{1+a^2}} \frac{1}{2} erf[\frac{h+a^2 h+a b}{\sqrt{2} \sqrt{1+a^2}}] \rho(\frac{b}{1+a^2})\right|_{\begin{array}{r} h=A_1 x \\ a=A_2 \\ b=A_3 x \end{array}} \cdot A_3 \\ &=& -\rho(A_1 x) \frac{1}{2} erf[\frac{A_1 A_2 + A_3}{\sqrt{2}} x] \cdot A_1 +  \frac{1}{\sqrt{1+A_2^2}} \rho(\frac{A_3 x}{\sqrt{1+A_2^2}}) \frac{1}{2} erfc[\frac{A_1+A_2 A_3 +A_1 A_2^2}{\sqrt{2} \sqrt{1+A_2^2}} x] \cdot A_3 \end{eqnarray} Now we integrate. We have: \begin{eqnarray} f(x)- f(0) &=& - \int\limits_0^x \rho(A_1 \xi) \frac{1}{2} erf[\frac{A_1 A_2 + A_3}{\sqrt{2}} \xi] d\xi \cdot A_1 + \\ &&\frac{1}{\sqrt{1+A_2^2}}\int\limits_0^x \rho(\frac{A_3 \xi}{\sqrt{1+A_2^2}}) \frac{1}{2} erfc[\frac{A_1+A_2 A_3 +A_1 A_2^2}{\sqrt{2} \sqrt{1+A_2^2}} \xi] d\xi \cdot A_3 \\ f(x) - \frac{1}{2\pi} \arctan(A_2) &=& - \frac{1}{2\pi} \arctan\left( \frac{A_1 A_2+A_3}{A_1}\right) + T(A_1 x, \frac{A_1 A_2 + A_3}{A_1}) + \\ && \frac{1}{4} erf\left( \frac{A_3}{\sqrt{2} \sqrt{1+A_2^2}} x\right) +\\ &&-\frac{1}{2\pi} \arctan\left( \frac{A_1+A_2 A_3 + A_1 A_2^2}{A_3}\right) + T\left( \frac{A_3}{\sqrt{1+A_2^2}} x, \frac{A_1+A_2 A_3 + A_1 A_2^2}{A_3}\right) \end{eqnarray} where in the second line we used the results from An integral involving error functions and a Gaussian and the definition of the Owen's T function. This completes the proof. (*A certain derivative. Used in Q869502.nb*) T[h_, a_, b_] :=    NIntegrate[(E^(-(b^2/2) - xi b h - 1/2 (1 + xi^2) h^2)) /(      2 (1 + xi^2) \[Pi]) -       b  /(2 Sqrt[2] Sqrt[ \[Pi]]) (       xi  Erfc[(h + xi (b + xi h))/(Sqrt[2] Sqrt[1 + xi^2])])/ ((1 +          xi^2)^(3/2)) E^(-(b^2/(2 + 2 xi^2))), {xi, 0, a},      WorkingPrecision -> 20] + Erfc[h/Sqrt[2]] Erf[b/Sqrt[2]] 1/4; {A1, A2, A3} = RandomReal[{-1, 1}, 3, WorkingPrecision -> 50]; u = Range[0, 1, 1/100]; mT = Interpolation[Transpose[{u, T[A1 u, A2, A3 u]}]]; u =.; u = RandomReal[{0, 1}, WorkingPrecision -> 50]; mT'[u] -rho[A1 u] 1/2 Erf[(A1 A2 + A3)/Sqrt[2] u] A1 +   1/Sqrt[1 + A2^2]    rho[(A3 u)/Sqrt[1 + A2^2]] 1/    2 Erfc[(A1 + A2 A3 + A1 A2^2)/(Sqrt[2] Sqrt[1 + A2^2]) u] A3  T[A1 u, A2, A3 u] 1/(2 Pi) (ArcTan[A2] - ArcTan[(A2 A1 + A3)/A1] -      ArcTan[(A1 + A2 A3 + A2^2 A1)/A3]) +   1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] +   OwenT[A1 u, (A2 A1 + A3)/A1] +   OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3] 1/(2 Pi) (-ArcTan[A3/((A1 + A2 A3 + A2^2 A1))] -      ArcTan[(A1 + A2 A3 + A2^2 A1)/A3]) +   1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] +   OwenT[A1 u, (A2 A1 + A3)/A1] +   OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3] -1/(2 Pi) Pi/2 (Sign[A3/((A1 + A2 A3 + A2^2 A1))]) +   1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] +   OwenT[A1 u, (A2 A1 + A3)/A1] +   OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3]   -(1/4) Sign[A3/((A1 + A2 A3 + A2^2 A1))] +   1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] +   OwenT[A1 u, (A2 A1 + A3)/A1] +   OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3] Now by both taking $x=1$ and replacing $A_1$ , $A_2$ and $A_3$ by $h$ , $a$ and $b$ in $(ii)$ we express the generalized Owen's T function through Owen's T function itself. We have: \begin{eqnarray} T(h,a,b) = \frac{1}{2\pi} \left(\arctan(a)-\arctan(a+\frac{b}{h})-\arctan(\frac{h+a b+a^2 h}{b})\right) + \frac{1}{4} erf[\frac{b}{\sqrt{2(1+a^2)}}] + T\left( h,\frac{a h+b}{h}\right) + T\left( \frac{b}{\sqrt{1+a^2}},\frac{h+a b+a^2 h}{b}\right) \end{eqnarray} As a sanity check we look at the limit $b$ going to zero. We have: \begin{eqnarray} \lim_{b \rightarrow 0_+} T(h,a,b) &=& \frac{1}{2\pi} \left(\arctan(a)-\arctan(a)-\frac{\pi}{2} sign(h))\right) + 0 + T(h,a) + \frac{1}{4} sign(h) \\ &=& T(h,a) \end{eqnarray} as it should be. As another sanity check we look at the case $a=\imath$ . Going back to the calculations of the derivative above we have: \begin{eqnarray} \frac{d}{d x} f(x)= -\phi(A_1 x) \frac{1}{2} erf(\frac{A_1 A_2+A_3}{\sqrt{2}} x) A_1 + \frac{1}{2\pi \imath x} \exp(-\frac{1}{2} x^2 (2 A_1 \imath A_3+A_3^2)) \end{eqnarray} where we used the asymptotic expansion for the complementary error function given in https://en.wikipedia.org/wiki/Error_function#Complementary_error_function . Now we take a number $M$ such that $1< M$ and we  integrate the above from unity to $M$ and we get: \begin{eqnarray} f(1)-f(M)=  \left.\left( T(A_1 \cdot \xi,A_2+\frac{A_3}{A_1}) + \frac{1}{4\pi \imath} Ei(-\frac{1}{2}(1+2\imath \frac{A_1}{A_3})(\xi A_3)^2\right)\right|_{\xi=M}^{\xi=1} \end{eqnarray} where $Ei()$ is the exponential integral.  Now it turns out that as $M\rightarrow \infty$ both $f(M)$ and $T(\dots M,\dots)$ tend to zero and \begin{equation} \lim\limits_{M\rightarrow \infty} \frac{1}{4 \pi \imath} Ei((a+\imath b) M) = sign(b) \cdot \frac{1}{4} \cdot 1_{a<0} + \infty \cdot 1_{a>0} \end{equation} Defining $b:=b_1+\imath b_2$ and taking $h>0$ this gives the final result: \begin{eqnarray} &&T(h,\imath , b) = \\ &&\left\{ \begin{array}{rr}  T(h,\imath + \frac{b}{h}) + \frac{1}{4\pi \imath} Ei(\frac{1}{2}(-b_1^2+b_2^2+2 b_2 h-2\imath b_1(b_2+h))) + sign(b_1(b_2+h)) \cdot \frac{1}{4} & \mbox{if $b_2<0$ and $-b_1^2 + b_2^2+2 b_2 h <0$} \\ \infty & \mbox{otherwise} \end{array} \right. \end{eqnarray} My question is the following. Has this quantity been ever analyzed in the literature before?","As Wikipedia teaches us https://en.wikipedia.org/wiki/Owen%27s_T_function the Owen's T function defines a probability of a bivariate event and where are standard, independent Gaussian random variables. Now in the context of question Multivariate gaussian integral over positive reals a necessity appeared to deal with a slightly more general quantity. We have shown that : {a, b, h} = RandomReal[{0, 1}, 3, WorkingPrecision -> 50]; b = 0; NIntegrate[  Exp[-x^2/2]/Sqrt[2 Pi] 1/2 Erf[(a x + b)/Sqrt[2]], {x, h, Infinity},   WorkingPrecision -> 20] NIntegrate[(E^(-(b^2/2) - xi b h - 1/2 (1 + xi^2) h^2)) /(    2 (1 + xi^2) \[Pi]) -     b  /(2 Sqrt[2] Sqrt[ \[Pi]]) (     xi  Erfc[(h + xi (b + xi h))/(Sqrt[2] Sqrt[1 + xi^2])])/ ((1 +        xi^2)^(3/2)) E^(-(b^2/(2 + 2 xi^2))), {xi, 0, a},    WorkingPrecision -> 20] + Erfc[h/Sqrt[2]] Erf[b/Sqrt[2]] 1/4 Update: Let for and let . Then we have: This identity comes from differentiating both sides with respect to then using the definition of the generalized Owen's T function to evaluate the derivative on the right hand side and having done this integrating both sides with respect to again. Let us present the proof of that in detail. Firstly we define . Now we compute the derivative using the chain rule. We have: Now we integrate. We have: where in the second line we used the results from An integral involving error functions and a Gaussian and the definition of the Owen's T function. This completes the proof. (*A certain derivative. Used in Q869502.nb*) T[h_, a_, b_] :=    NIntegrate[(E^(-(b^2/2) - xi b h - 1/2 (1 + xi^2) h^2)) /(      2 (1 + xi^2) \[Pi]) -       b  /(2 Sqrt[2] Sqrt[ \[Pi]]) (       xi  Erfc[(h + xi (b + xi h))/(Sqrt[2] Sqrt[1 + xi^2])])/ ((1 +          xi^2)^(3/2)) E^(-(b^2/(2 + 2 xi^2))), {xi, 0, a},      WorkingPrecision -> 20] + Erfc[h/Sqrt[2]] Erf[b/Sqrt[2]] 1/4; {A1, A2, A3} = RandomReal[{-1, 1}, 3, WorkingPrecision -> 50]; u = Range[0, 1, 1/100]; mT = Interpolation[Transpose[{u, T[A1 u, A2, A3 u]}]]; u =.; u = RandomReal[{0, 1}, WorkingPrecision -> 50]; mT'[u] -rho[A1 u] 1/2 Erf[(A1 A2 + A3)/Sqrt[2] u] A1 +   1/Sqrt[1 + A2^2]    rho[(A3 u)/Sqrt[1 + A2^2]] 1/    2 Erfc[(A1 + A2 A3 + A1 A2^2)/(Sqrt[2] Sqrt[1 + A2^2]) u] A3  T[A1 u, A2, A3 u] 1/(2 Pi) (ArcTan[A2] - ArcTan[(A2 A1 + A3)/A1] -      ArcTan[(A1 + A2 A3 + A2^2 A1)/A3]) +   1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] +   OwenT[A1 u, (A2 A1 + A3)/A1] +   OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3] 1/(2 Pi) (-ArcTan[A3/((A1 + A2 A3 + A2^2 A1))] -      ArcTan[(A1 + A2 A3 + A2^2 A1)/A3]) +   1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] +   OwenT[A1 u, (A2 A1 + A3)/A1] +   OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3] -1/(2 Pi) Pi/2 (Sign[A3/((A1 + A2 A3 + A2^2 A1))]) +   1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] +   OwenT[A1 u, (A2 A1 + A3)/A1] +   OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3]   -(1/4) Sign[A3/((A1 + A2 A3 + A2^2 A1))] +   1/4 Erf[(A3 u)/(Sqrt[2] Sqrt[1 + A2^2])] +   OwenT[A1 u, (A2 A1 + A3)/A1] +   OwenT[A3/Sqrt[1 + A2^2] u, (A1 + A2 A3 + A2^2 A1)/A3] Now by both taking and replacing , and by , and in we express the generalized Owen's T function through Owen's T function itself. We have: As a sanity check we look at the limit going to zero. We have: as it should be. As another sanity check we look at the case . Going back to the calculations of the derivative above we have: where we used the asymptotic expansion for the complementary error function given in https://en.wikipedia.org/wiki/Error_function#Complementary_error_function . Now we take a number such that and we  integrate the above from unity to and we get: where is the exponential integral.  Now it turns out that as both and tend to zero and Defining and taking this gives the final result: My question is the following. Has this quantity been ever analyzed in the literature before?","T(h,a) X>h 0<Y<a X X,Y \begin{equation}
T(h,a,b):= {\bf P}\left(X>h \quad \wedge \quad a X+b > Y > 0 \left. \right| X = N(0,1) , Y=N(0,1)   \right)
\end{equation} \begin{eqnarray}
&&T(h,a,b)= \int\limits_h^\infty \frac{\exp(-1/2 \xi^2)}{\sqrt{2\pi}} \frac{1}{2} Erf(\frac{a \xi+b}{\sqrt{2}}) d\xi \quad (i1)\\
&&= \int\limits_0^a \frac{e^{-\frac{b^2}{2}-b h \xi -\frac{1}{2} h^2 \left(\xi ^2+1\right)}}{2 \pi  \left(\xi ^2+1\right)} d\xi - \frac{b}{2\sqrt{2}\sqrt{\pi}} \int\limits_0^a \frac{\xi  e^{-\frac{b^2}{2 \xi ^2+2}} \text{erfc}\left(\frac{\xi  (b+h \xi )+h}{\sqrt{2} \sqrt{\xi ^2+1}}\right)}{\left(\xi ^2+1\right)^{3/2}} d\xi + \frac{1}{4} \text{erf}\left(\frac{b}{\sqrt{2}}\right) \text{erfc}\left(\frac{h}{\sqrt{2}}\right) \quad (i2)
\end{eqnarray} A_j \in {\mathbb R} j=1,\cdots,3 x\in {\mathbb R} \begin{eqnarray}
T(A_1 x, A_2, A_3 x) = 
\frac{1}{2\pi} \left(\arctan(A_2)-\arctan(A_2+\frac{A_3}{A_1})-\arctan(\frac{A_1+A_2 A_3+A_2^2 A_1}{A_3})\right) + \frac{1}{4} erf[\frac{A_3 x}{\sqrt{2} \sqrt{1+A_2^2}}] + T(A_1 x, \frac{A_2 A_1+A_3}{A_1})+ T(\frac{A_3 x}{\sqrt{1+A_2^2}},\frac{A_1+A_2 A_3 + A_2^2 A_1}{A_3}) \quad (ii)
\end{eqnarray} x x f(x) := T[A_1 x, A_2, A_3 x] \begin{eqnarray}
\frac{d }{d x} f(x) &=& \partial_1 T[A_1 x, A_2 , A_3 x] \cdot A_1 + \partial_3 T[A_1 x, A_2, A_3 x] \cdot A_3 \\
&=& - \left. \rho(h) \frac{1}{2} erf[\frac{a h+b}{\sqrt{2}}] \right|_{\begin{array}{r} h=A_1 x \\ a=A_2 \\ b=A_3 x \end{array}}\cdot A_1  + 
\left.\frac{1}{\sqrt{1+a^2}} \frac{1}{2} erf[\frac{h+a^2 h+a b}{\sqrt{2} \sqrt{1+a^2}}] \rho(\frac{b}{1+a^2})\right|_{\begin{array}{r} h=A_1 x \\ a=A_2 \\ b=A_3 x \end{array}} \cdot A_3 \\
&=& -\rho(A_1 x) \frac{1}{2} erf[\frac{A_1 A_2 + A_3}{\sqrt{2}} x] \cdot A_1 + 
\frac{1}{\sqrt{1+A_2^2}} \rho(\frac{A_3 x}{\sqrt{1+A_2^2}}) \frac{1}{2} erfc[\frac{A_1+A_2 A_3 +A_1 A_2^2}{\sqrt{2} \sqrt{1+A_2^2}} x] \cdot A_3
\end{eqnarray} \begin{eqnarray}
f(x)- f(0) &=& - \int\limits_0^x \rho(A_1 \xi) \frac{1}{2} erf[\frac{A_1 A_2 + A_3}{\sqrt{2}} \xi] d\xi \cdot A_1 + \\
&&\frac{1}{\sqrt{1+A_2^2}}\int\limits_0^x \rho(\frac{A_3 \xi}{\sqrt{1+A_2^2}}) \frac{1}{2} erfc[\frac{A_1+A_2 A_3 +A_1 A_2^2}{\sqrt{2} \sqrt{1+A_2^2}} \xi] d\xi \cdot A_3 \\
f(x) - \frac{1}{2\pi} \arctan(A_2) &=& - \frac{1}{2\pi} \arctan\left( \frac{A_1 A_2+A_3}{A_1}\right) + T(A_1 x, \frac{A_1 A_2 + A_3}{A_1}) + \\
&& \frac{1}{4} erf\left( \frac{A_3}{\sqrt{2} \sqrt{1+A_2^2}} x\right) +\\
&&-\frac{1}{2\pi} \arctan\left( \frac{A_1+A_2 A_3 + A_1 A_2^2}{A_3}\right) + T\left( \frac{A_3}{\sqrt{1+A_2^2}} x, \frac{A_1+A_2 A_3 + A_1 A_2^2}{A_3}\right)
\end{eqnarray} x=1 A_1 A_2 A_3 h a b (ii) \begin{eqnarray}
T(h,a,b) = \frac{1}{2\pi} \left(\arctan(a)-\arctan(a+\frac{b}{h})-\arctan(\frac{h+a b+a^2 h}{b})\right) + \frac{1}{4} erf[\frac{b}{\sqrt{2(1+a^2)}}] + T\left( h,\frac{a h+b}{h}\right) + T\left( \frac{b}{\sqrt{1+a^2}},\frac{h+a b+a^2 h}{b}\right)
\end{eqnarray} b \begin{eqnarray}
\lim_{b \rightarrow 0_+} T(h,a,b) &=& \frac{1}{2\pi} \left(\arctan(a)-\arctan(a)-\frac{\pi}{2} sign(h))\right) + 0 + T(h,a) + \frac{1}{4} sign(h) \\
&=& T(h,a)
\end{eqnarray} a=\imath \begin{eqnarray}
\frac{d}{d x} f(x)= -\phi(A_1 x) \frac{1}{2} erf(\frac{A_1 A_2+A_3}{\sqrt{2}} x) A_1 + \frac{1}{2\pi \imath x} \exp(-\frac{1}{2} x^2 (2 A_1 \imath A_3+A_3^2))
\end{eqnarray} M 1< M M \begin{eqnarray}
f(1)-f(M)= 
\left.\left( T(A_1 \cdot \xi,A_2+\frac{A_3}{A_1}) + \frac{1}{4\pi \imath} Ei(-\frac{1}{2}(1+2\imath \frac{A_1}{A_3})(\xi A_3)^2\right)\right|_{\xi=M}^{\xi=1}
\end{eqnarray} Ei() M\rightarrow \infty f(M) T(\dots M,\dots) \begin{equation}
\lim\limits_{M\rightarrow \infty} \frac{1}{4 \pi \imath} Ei((a+\imath b) M) = sign(b) \cdot \frac{1}{4} \cdot 1_{a<0} + \infty \cdot 1_{a>0}
\end{equation} b:=b_1+\imath b_2 h>0 \begin{eqnarray}
&&T(h,\imath , b) = \\
&&\left\{
\begin{array}{rr}
 T(h,\imath + \frac{b}{h}) + \frac{1}{4\pi \imath} Ei(\frac{1}{2}(-b_1^2+b_2^2+2 b_2 h-2\imath b_1(b_2+h))) + sign(b_1(b_2+h)) \cdot \frac{1}{4} & \mbox{if b_2<0 and -b_1^2 + b_2^2+2 b_2 h <0} \\
\infty & \mbox{otherwise}
\end{array}
\right.
\end{eqnarray}","['probability', 'indefinite-integrals', 'special-functions', 'gaussian-integral']"
95,Probability of $2$ pairs on $5$ dice,Probability of  pairs on  dice,2 5,"We throw $5$ dice. What is the probability of getting $2$ pairs ? My solution says it is $$\frac{6\cdot 5\cdot 4\cdot 5! }{6^5\cdot 2\cdot 2!\cdot 2!},$$ where as for me it's $$\frac{6\cdot 5\cdot 4\cdot 5!}{6^5\cdot 2!\cdot 2!}.$$ I do as follows: Throwing $5$ dice is the same thing as throwing one die $5$ times. What we want is $AABBC$ . We have $6$ possibilities for $A$ , $5$ possibilities for $B$ and 4 possibilities for C. Since the order doesn't count we have to multiply by $\frac{5!}{2!2!}$ . At the end, I get $$\frac{6\cdot 5\cdot 4 \cdot 5!}{6^5\cdot 2!\cdot 2!}.$$ What's wrong in my argument?","We throw dice. What is the probability of getting pairs ? My solution says it is where as for me it's I do as follows: Throwing dice is the same thing as throwing one die times. What we want is . We have possibilities for , possibilities for and 4 possibilities for C. Since the order doesn't count we have to multiply by . At the end, I get What's wrong in my argument?","5 2 \frac{6\cdot 5\cdot 4\cdot 5! }{6^5\cdot 2\cdot 2!\cdot 2!}, \frac{6\cdot 5\cdot 4\cdot 5!}{6^5\cdot 2!\cdot 2!}. 5 5 AABBC 6 A 5 B \frac{5!}{2!2!} \frac{6\cdot 5\cdot 4 \cdot 5!}{6^5\cdot 2!\cdot 2!}.","['probability', 'dice']"
96,Optimal code for simple game,Optimal code for simple game,,"Setup : Alice and Bob are playing a cooperative game. Alice chooses a number $y \in \{1, 2, 3, 4\}$ uniformly at random. Bob doesn't observe $y$ ; his goal is to guess $y$ . Alice can send Bob a message $z$ that contains at most 1 bit of information about $y$ (i.e., $I(z;y) = 1$ ). Problem : How should Alice encode information about $y$ into her message $z$ ? Potential Solutions : I have three ideas for what Alice should do, but they all give contradictory answers. If $y \in \{1, 2\}$ , Alice sends $z = 0$ ; otherwise, Alice sends $z = 1$ . The code $z$ contains 1 bit of information. Bob will guess $y$ correctly with probability 0.5. With probability 1/2, Alice sends $z = y$ (2 bits); otherwise, Alice sends some null message (0 bits). Thus, Alice sends 1 bit in expectation. Bob will guess $y$ correctly in the first case; in the second case, he will guess randomly and be correct with probability 0.25. In total, Bob will guess $y$ correctly with probability $0.5 \cdot 1.0 + 0.5 \cdot 0.25 = 0.625$ . Alice samples $z$ from the following 4-dimensional Categorical distribution that places probability 0.811 on $z = y$ and probability 0.063 on the other 3 atoms. The marginal $p(z)$ is uniform, so $H(z) = \log_2(4) = 2$ ; the conditional $p(z \mid y)$ has entropy $$H(z \mid y) = 0.811 \cdot \log_2(\frac{1}{0.811}) + 3 \cdot 0.063 \cdot \log_2(\frac{1}{0.063}) \approx 1 $$ The information content of Alice's message is $I(z;y) = H(z) - H(z \mid y) = 1$ . Bob's guess will be whatever message Alice sends, so he'll guess $y$ correctly with probability 0.811.","Setup : Alice and Bob are playing a cooperative game. Alice chooses a number uniformly at random. Bob doesn't observe ; his goal is to guess . Alice can send Bob a message that contains at most 1 bit of information about (i.e., ). Problem : How should Alice encode information about into her message ? Potential Solutions : I have three ideas for what Alice should do, but they all give contradictory answers. If , Alice sends ; otherwise, Alice sends . The code contains 1 bit of information. Bob will guess correctly with probability 0.5. With probability 1/2, Alice sends (2 bits); otherwise, Alice sends some null message (0 bits). Thus, Alice sends 1 bit in expectation. Bob will guess correctly in the first case; in the second case, he will guess randomly and be correct with probability 0.25. In total, Bob will guess correctly with probability . Alice samples from the following 4-dimensional Categorical distribution that places probability 0.811 on and probability 0.063 on the other 3 atoms. The marginal is uniform, so ; the conditional has entropy The information content of Alice's message is . Bob's guess will be whatever message Alice sends, so he'll guess correctly with probability 0.811.","y \in \{1, 2, 3, 4\} y y z y I(z;y) = 1 y z y \in \{1, 2\} z = 0 z = 1 z y z = y y y 0.5 \cdot 1.0 + 0.5 \cdot 0.25 = 0.625 z z = y p(z) H(z) = \log_2(4) = 2 p(z \mid y) H(z \mid y) = 0.811 \cdot \log_2(\frac{1}{0.811}) + 3 \cdot 0.063 \cdot \log_2(\frac{1}{0.063}) \approx 1  I(z;y) = H(z) - H(z \mid y) = 1 y","['probability', 'information-theory', 'coding-theory']"
97,A hint for the entropy problem-entropy of one discrete variable is greater than the entropy of another one,A hint for the entropy problem-entropy of one discrete variable is greater than the entropy of another one,,I need a hint on how to start solving the following problem. Entropy of a discrete variable X is $H(X) = −\sum_{x\in \{x:P(X=x)>0\}}P(X=x)logP(X=x)$ . Let $f:R → R$ be any function.\ a) Show that entropy of a discrete variable X is greater than or equal to entropy of a discrete variable f(X).\ b) Show that equality occurs if and only if function f is injective on {x : P(X = x) > 0},I need a hint on how to start solving the following problem. Entropy of a discrete variable X is . Let be any function.\ a) Show that entropy of a discrete variable X is greater than or equal to entropy of a discrete variable f(X).\ b) Show that equality occurs if and only if function f is injective on {x : P(X = x) > 0},H(X) = −\sum_{x\in \{x:P(X=x)>0\}}P(X=x)logP(X=x) f:R → R,"['probability', 'entropy']"
98,How to calculate a (possible) chance from a zero-incidence sample?,How to calculate a (possible) chance from a zero-incidence sample?,,"This is probably a very simple problem, but I want to make sure I have a correct understanding. I have a sample of $500$ events, in which a complication $C$ didn't occur. How do I calculate a reasonably correct chance for $C$ ? Would that be just $<1/500$ ? My intuition is that it would be a bit higher, as there is a sampling effect. Obviously, it is impossible to calculate the chance exactly, but does something like some kind of confidence interval exist for these types of observations? Much obliged, Joris","This is probably a very simple problem, but I want to make sure I have a correct understanding. I have a sample of events, in which a complication didn't occur. How do I calculate a reasonably correct chance for ? Would that be just ? My intuition is that it would be a bit higher, as there is a sampling effect. Obviously, it is impossible to calculate the chance exactly, but does something like some kind of confidence interval exist for these types of observations? Much obliged, Joris",500 C C <1/500,['probability']
99,Deriving Bayesian logistic regression,Deriving Bayesian logistic regression,,"I'm attempting to understand Bayesian logistic regression clearly, and I'm uncertain about (among other things) what is the most clear or most correct notation to use. Here is my current attempt at explaining Bayesian logistic regression: Suppose that we have a large population of objects (such as emails), each of which is described by a feature vector $x \in \mathbb R^p$ and a class label $y \in \{0,1\}$ (spam or not spam, for example). Consider the experiment of selecting an item at random from this population. Let $X$ and $Y$ be the feature vector and the label of the selected item (so $X$ and $Y$ are random variables). The goal of logistic regression is to find an approximation to the function $$ x \mapsto P(Y = 1 \mid X = x). $$ To achieve this goal, logistic regression makes a modeling assumption that there exists a vector $a \in \mathbb R^p$ and a scalar $b \in \mathbb R$ such that $$ P(Y = 1 \mid X = x) = S(a^T x + b), $$ where $S$ is the sigmoid function defined by $$ S(u) = \frac{e^u}{1 + e^{u}}. $$ Logistic regression computes the parameters $a$ and $b$ using maximum likelihood estimation. However , we can also take a Bayesian approach to estimating $a$ and $b$ by incorporating prior beliefs about the values of $a$ and $b$ . The parameters $a$ and $b$ are now viewed as being random variables. To be concrete, let's make the assumption that $b$ and the components of $a$ are independent and normally distributed with mean $0$ and variance $\sigma^2$ . The joint PDF of $a$ and $b$ will be denoted by $f_{a,b}$ . Consider the experiment of selecting $n$ objects at random (with replacement) from the population. Let $X_i$ and $Y_i$ be the feature vector and corresponding class label for the $i$ th object selected (so $X_i$ and $Y_i$ are random variables). Let $x_i$ and $y_i$ be the specific values of $X_i$ and $Y_i$ that we observe when we collect our training data. [ Here is where I think the notation gets difficult. ] Let $f$ be the PDF of the random variable $(X_1,Y_1,\ldots,X_n,Y_n)$ . Let $f_{X_i,Y_i}$ be the joint PDF of $X_i$ and $Y_i$ , and let $f_{X_i}$ be the PDF of $X_i$ . According to Bayes' theorem, we have \begin{align*}  &\quad f_{a,b}(\hat a, \hat b \mid (X_i,Y_i) = (x_i,y_i) \text{ for } i = 1,\ldots, n) \\ \propto &\quad    f(x_1,y_1,\ldots,x_n,y_n \mid a = \hat a, b = \hat b) f_{a,b}(\hat a, \hat b) \\ =&\quad  f_{a,b}(\hat a, \hat b) \Pi_{i=1}^n f_{X_i,Y_i}(x_i,y_i \mid a = \hat a, b = \hat b) \\ =&\quad  f_{a,b}(\hat a, \hat b) \Pi_{i=1}^n P(Y_i = y_i \mid X_i = x_i, a = \hat a, b = \hat b)  f_{X_i}(x_i \mid a = \hat a, b = \hat b) \\ =&\quad  f_{a,b}(\hat a, \hat b) \Pi_{i=1}^n P(Y_i = y_i \mid X_i = x_i, a = \hat a, b = \hat b)  f_{X_i}(x_i). \\ \end{align*} In the last step, we assumed that $X_i, a$ , and $b$ are independent. Now taking the natural log of the final expression and omitting terms that do not depend on $\hat a$ or $\hat b$ , we see that a maximum a posteriori estimate of $a$ and $b$ can be found by maximizing $$ \frac{-\| \hat a \|^2 - \hat b^2}{2 \sigma^2} + \sum_{i=1}^n \log(S(\hat a^T x_i + \hat b)) $$ with respect to $\hat a$ and $\hat b$ . This is a convex optimization problem, which can be solved using a method such as gradient ascent. (Further simplifications to the objective function are possible, but I'm not concerned with how to explain the remaining steps.) Here are some questions: Is this derivation correct? Do you see any errors? How can the notation be improved, clarified, or simplified? I want the notation to be perfectly correct (by the standards of a mathematician) but also clear. I think the statement Let $f$ be the PDF of the random variable $(X_1,Y_1,\ldots,X_n,Y_n)$ is incorrect because the random variables $Y_i$ are not continuous, so the term ""PDF"" can't be used here. How should this statement be rephrased? I'd be interested in hearing any comments or opinions about how to clarify the above derivation, including comments about picky details or tangential comments.","I'm attempting to understand Bayesian logistic regression clearly, and I'm uncertain about (among other things) what is the most clear or most correct notation to use. Here is my current attempt at explaining Bayesian logistic regression: Suppose that we have a large population of objects (such as emails), each of which is described by a feature vector and a class label (spam or not spam, for example). Consider the experiment of selecting an item at random from this population. Let and be the feature vector and the label of the selected item (so and are random variables). The goal of logistic regression is to find an approximation to the function To achieve this goal, logistic regression makes a modeling assumption that there exists a vector and a scalar such that where is the sigmoid function defined by Logistic regression computes the parameters and using maximum likelihood estimation. However , we can also take a Bayesian approach to estimating and by incorporating prior beliefs about the values of and . The parameters and are now viewed as being random variables. To be concrete, let's make the assumption that and the components of are independent and normally distributed with mean and variance . The joint PDF of and will be denoted by . Consider the experiment of selecting objects at random (with replacement) from the population. Let and be the feature vector and corresponding class label for the th object selected (so and are random variables). Let and be the specific values of and that we observe when we collect our training data. [ Here is where I think the notation gets difficult. ] Let be the PDF of the random variable . Let be the joint PDF of and , and let be the PDF of . According to Bayes' theorem, we have In the last step, we assumed that , and are independent. Now taking the natural log of the final expression and omitting terms that do not depend on or , we see that a maximum a posteriori estimate of and can be found by maximizing with respect to and . This is a convex optimization problem, which can be solved using a method such as gradient ascent. (Further simplifications to the objective function are possible, but I'm not concerned with how to explain the remaining steps.) Here are some questions: Is this derivation correct? Do you see any errors? How can the notation be improved, clarified, or simplified? I want the notation to be perfectly correct (by the standards of a mathematician) but also clear. I think the statement Let be the PDF of the random variable is incorrect because the random variables are not continuous, so the term ""PDF"" can't be used here. How should this statement be rephrased? I'd be interested in hearing any comments or opinions about how to clarify the above derivation, including comments about picky details or tangential comments.","x \in \mathbb R^p y \in \{0,1\} X Y X Y 
x \mapsto P(Y = 1 \mid X = x).
 a \in \mathbb R^p b \in \mathbb R 
P(Y = 1 \mid X = x) = S(a^T x + b),
 S 
S(u) = \frac{e^u}{1 + e^{u}}.
 a b a b a b a b b a 0 \sigma^2 a b f_{a,b} n X_i Y_i i X_i Y_i x_i y_i X_i Y_i f (X_1,Y_1,\ldots,X_n,Y_n) f_{X_i,Y_i} X_i Y_i f_{X_i} X_i \begin{align*}
 &\quad f_{a,b}(\hat a, \hat b \mid (X_i,Y_i) = (x_i,y_i) \text{ for } i = 1,\ldots, n) \\
\propto &\quad    f(x_1,y_1,\ldots,x_n,y_n \mid a = \hat a, b = \hat b) f_{a,b}(\hat a, \hat b) \\
=&\quad  f_{a,b}(\hat a, \hat b) \Pi_{i=1}^n f_{X_i,Y_i}(x_i,y_i \mid a = \hat a, b = \hat b) \\
=&\quad  f_{a,b}(\hat a, \hat b) \Pi_{i=1}^n P(Y_i = y_i \mid X_i = x_i, a = \hat a, b = \hat b)  f_{X_i}(x_i \mid a = \hat a, b = \hat b) \\
=&\quad  f_{a,b}(\hat a, \hat b) \Pi_{i=1}^n P(Y_i = y_i \mid X_i = x_i, a = \hat a, b = \hat b)  f_{X_i}(x_i). \\
\end{align*} X_i, a b \hat a \hat b a b 
\frac{-\| \hat a \|^2 - \hat b^2}{2 \sigma^2} + \sum_{i=1}^n \log(S(\hat a^T x_i + \hat b))
 \hat a \hat b f (X_1,Y_1,\ldots,X_n,Y_n) Y_i","['probability', 'statistics', 'regression']"
