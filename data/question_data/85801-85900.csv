,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Basis for $l^{\infty}$,Basis for,l^{\infty},"As the question stated, we know that $\{e_i\}$ doesn't form a basis for $l^{\infty}$. So how can we find a basis for $l^{\infty}$, no matter it is Schauder or Hamel basis.","As the question stated, we know that $\{e_i\}$ doesn't form a basis for $l^{\infty}$. So how can we find a basis for $l^{\infty}$, no matter it is Schauder or Hamel basis.",,['functional-analysis']
1,Adjoint of $L^{1}$ space,Adjoint of  space,L^{1},"I have a question about $L^{p}$ spaces. Question: Let $(X,\Sigma,\mu)$ be a $\sigma$-finite measure space. Let us consider $f \in L^{1}(X)$ satisfying the following property: \begin{align*} \forall g \in L^{1}(X) \cap L^{\infty}(X), \int_{X}fgd\mu=0 \end{align*} This implies $f=0$ ? My attempt: If $L^{1}(X)\cap L^{\infty}(X)$ is dense in $L^{\infty}(X)$ holds then we can obtain the following statement: \begin{align*} \forall g \in L^{\infty}(X), \int_{X}fgd\mu=0 \end{align*} This implies $f=0$ (by Hahn-Banach's theorem). Can we show that $L^{1}(X)\cap L^{\infty}(X)$ is dense in $L^{\infty}(X)$?","I have a question about $L^{p}$ spaces. Question: Let $(X,\Sigma,\mu)$ be a $\sigma$-finite measure space. Let us consider $f \in L^{1}(X)$ satisfying the following property: \begin{align*} \forall g \in L^{1}(X) \cap L^{\infty}(X), \int_{X}fgd\mu=0 \end{align*} This implies $f=0$ ? My attempt: If $L^{1}(X)\cap L^{\infty}(X)$ is dense in $L^{\infty}(X)$ holds then we can obtain the following statement: \begin{align*} \forall g \in L^{\infty}(X), \int_{X}fgd\mu=0 \end{align*} This implies $f=0$ (by Hahn-Banach's theorem). Can we show that $L^{1}(X)\cap L^{\infty}(X)$ is dense in $L^{\infty}(X)$?",,"['functional-analysis', 'measure-theory']"
2,"Part (a) of Exercise 13 of first chapter of Rudin's book ""Functional Analysis""","Part (a) of Exercise 13 of first chapter of Rudin's book ""Functional Analysis""",,"I would really appreciate it if you could give me some advice on the part (a) of Exercise 13 of first chapter of Walter Rudin's book "" Functional Analysis "": Let $C$ be the vector space of all complex continuous functions on $[0, 1]$. Define   \begin{equation} d(f,g) = \int_0^1 \frac{\lvert f(x) - g(x) \rvert}{1 + \lvert f(x) - g(x) \rvert} \ dx \ . \end{equation}   Let $(C, \sigma)$ be $C$ with the topology induced by this metric. Let $(C, \tau)$ be the topological vector space defined by the semi-norms   \begin{equation} P_x(f) = \lvert f(x) \rvert, \qquad (0 \leq x \leq 1), \end{equation}   Prove that every $\tau$-bounded set in $C$ is also $\sigma$-bounded and that the identity map $id: (C, \tau) \rightarrow (C, \sigma)$ therefore carries bounded sets into bounded sets. I tried using the theorem that says a set $E \subseteq C$ is bounded if and only if every semi-norm in our semi-norms is bounded on $E$. This theorem tells us that if $E$ be a bounded set in $(C, \tau)$, then for every $x \in [0, 1]$, $P_x(E)$ is bounded, i.e. \begin{equation} \forall x \in [0, 1] \ \exists M_x, \quad s.t. \quad \forall f \in E, \quad \lvert f(x) \rvert \leq M_x \ . \end{equation} I think now we should use Uniform boundedness principle and obtain $M > 0$ such that \begin{equation} \forall x \in [0, 1] \ \forall f \in E, \quad \lvert f(x) \rvert \leq M \ . \end{equation} Then we have $d(f, 0) \leq \frac{M}{1+M}$ for all $f \in E$. So $E$ is bounded in $(C, \sigma)$. In the last step, to use Uniform boundedness principle, I think we should prove that $(C, \tau)$ is a Banach space, and $(C, \sigma)$ a normed space. I don't know what should I do in this step.","I would really appreciate it if you could give me some advice on the part (a) of Exercise 13 of first chapter of Walter Rudin's book "" Functional Analysis "": Let $C$ be the vector space of all complex continuous functions on $[0, 1]$. Define   \begin{equation} d(f,g) = \int_0^1 \frac{\lvert f(x) - g(x) \rvert}{1 + \lvert f(x) - g(x) \rvert} \ dx \ . \end{equation}   Let $(C, \sigma)$ be $C$ with the topology induced by this metric. Let $(C, \tau)$ be the topological vector space defined by the semi-norms   \begin{equation} P_x(f) = \lvert f(x) \rvert, \qquad (0 \leq x \leq 1), \end{equation}   Prove that every $\tau$-bounded set in $C$ is also $\sigma$-bounded and that the identity map $id: (C, \tau) \rightarrow (C, \sigma)$ therefore carries bounded sets into bounded sets. I tried using the theorem that says a set $E \subseteq C$ is bounded if and only if every semi-norm in our semi-norms is bounded on $E$. This theorem tells us that if $E$ be a bounded set in $(C, \tau)$, then for every $x \in [0, 1]$, $P_x(E)$ is bounded, i.e. \begin{equation} \forall x \in [0, 1] \ \exists M_x, \quad s.t. \quad \forall f \in E, \quad \lvert f(x) \rvert \leq M_x \ . \end{equation} I think now we should use Uniform boundedness principle and obtain $M > 0$ such that \begin{equation} \forall x \in [0, 1] \ \forall f \in E, \quad \lvert f(x) \rvert \leq M \ . \end{equation} Then we have $d(f, 0) \leq \frac{M}{1+M}$ for all $f \in E$. So $E$ is bounded in $(C, \sigma)$. In the last step, to use Uniform boundedness principle, I think we should prove that $(C, \tau)$ is a Banach space, and $(C, \sigma)$ a normed space. I don't know what should I do in this step.",,"['functional-analysis', 'topological-vector-spaces']"
3,Assume $T$ is compact operator and $S(I- T) = I $.Is this true that $(I- T)S =I$?,Assume  is compact operator and .Is this true that ?,T S(I- T) = I  (I- T)S =I,"Suppose $S,T \in {\rm B}(X)$ and assume $T$ is compact operator and $S(I- T) = I $.Is this true that $(I- T)S =I$?","Suppose $S,T \in {\rm B}(X)$ and assume $T$ is compact operator and $S(I- T) = I $.Is this true that $(I- T)S =I$?",,['functional-analysis']
4,Existence of Certain Locally Integrable Function Defining a Tempered Distribution,Existence of Certain Locally Integrable Function Defining a Tempered Distribution,,"We say that a distribution $T$ is tempered if for every sequence $\left\{\phi_{n}\right\}$ in $C_{c}^{\infty}(\mathbb{R}^{n})$ tending to $0$ in the topology of the Schwartz space $\mathcal{S}(\mathbb{R}^{n})$, $\langle{T,\phi_{n}}\rangle\rightarrow 0$. In this case, the density of $C_{c}^{\infty}(\mathbb{R}^{n})$ in $\mathcal{S}(\mathbb{R}^{n})$ implies that $T$ has a unique extension to a continuous linear functional on $\mathcal{S}(\mathbb{R}^{n})$, which we denote by $T\in\mathcal{S}'(\mathbb{R}^{n})$. Given a locally integrable function $f\in L_{loc}^{1}(\mathbb{R}^{n})$, let $T_{f}\in\mathcal{D}'(\mathbb{R}^{n})$ be the distribution defined by $$\langle{T_{f},\phi}\rangle,\qquad\forall\phi\in C_{c}^{\infty}(\mathbb{R}^{n})$$ It is known that $L_{loc}^{1}(\mathbb{R}^{n})\not\subset\mathcal{S}'(\mathbb{R}^{n})$. As noted in the linked question, the Lebesgue integral $$\int_{\mathbb{R}^{n}}f\phi$$ may not exist for some $\phi\in\mathcal{S}(\mathbb{R}^{n})$, which gives some indication that $T_{f}$ is not tempered if $f$ grows too fast at $\infty$. My question is whether this condition is sufficient. My intuition is that it's not sufficient, but I don't have an example to show this at this moment. Question. Does there exist an $f\in L_{loc}^{1}(\mathbb{R}^{n})$ such that the distribution $T_{f}$ is tempered, but $f\phi\notin L^{1}(\mathbb{R}^{n})$ for some $\phi\in\mathcal{S}(\mathbb{R}^{n})$?","We say that a distribution $T$ is tempered if for every sequence $\left\{\phi_{n}\right\}$ in $C_{c}^{\infty}(\mathbb{R}^{n})$ tending to $0$ in the topology of the Schwartz space $\mathcal{S}(\mathbb{R}^{n})$, $\langle{T,\phi_{n}}\rangle\rightarrow 0$. In this case, the density of $C_{c}^{\infty}(\mathbb{R}^{n})$ in $\mathcal{S}(\mathbb{R}^{n})$ implies that $T$ has a unique extension to a continuous linear functional on $\mathcal{S}(\mathbb{R}^{n})$, which we denote by $T\in\mathcal{S}'(\mathbb{R}^{n})$. Given a locally integrable function $f\in L_{loc}^{1}(\mathbb{R}^{n})$, let $T_{f}\in\mathcal{D}'(\mathbb{R}^{n})$ be the distribution defined by $$\langle{T_{f},\phi}\rangle,\qquad\forall\phi\in C_{c}^{\infty}(\mathbb{R}^{n})$$ It is known that $L_{loc}^{1}(\mathbb{R}^{n})\not\subset\mathcal{S}'(\mathbb{R}^{n})$. As noted in the linked question, the Lebesgue integral $$\int_{\mathbb{R}^{n}}f\phi$$ may not exist for some $\phi\in\mathcal{S}(\mathbb{R}^{n})$, which gives some indication that $T_{f}$ is not tempered if $f$ grows too fast at $\infty$. My question is whether this condition is sufficient. My intuition is that it's not sufficient, but I don't have an example to show this at this moment. Question. Does there exist an $f\in L_{loc}^{1}(\mathbb{R}^{n})$ such that the distribution $T_{f}$ is tempered, but $f\phi\notin L^{1}(\mathbb{R}^{n})$ for some $\phi\in\mathcal{S}(\mathbb{R}^{n})$?",,"['functional-analysis', 'fourier-analysis', 'distribution-theory', 'harmonic-analysis']"
5,Intersection of Hilbert spaces,Intersection of Hilbert spaces,,"Consider two Hilbert spaces $H_1$ and $H_2$ with inner products $\langle \cdot,\cdot\rangle_1$ and $\langle \cdot,\cdot\rangle_2$ generating norms $\Vert \cdot \Vert_1$ and $\Vert \cdot \Vert_2$ respectively. I am trying to understand when $H = H_1 \cap H_2$ becomes a Hilbert space with the inner product $\langle \cdot,\cdot\rangle_1 + \langle \cdot,\cdot\rangle_2$. Or does this always hold? I can see that a Cauchy sequence in $H$ is Cauchy in both $H_1$ and $H_2$, but apriori, it is not clear to me that a common convergent subsequence can be found. Thanks for any help! Edit: Let us assume that $H_1$ and $H_2$ are sitting inside a larger Hilbert space $H$. As pointed out below, otherwise the question doesn't make sense.","Consider two Hilbert spaces $H_1$ and $H_2$ with inner products $\langle \cdot,\cdot\rangle_1$ and $\langle \cdot,\cdot\rangle_2$ generating norms $\Vert \cdot \Vert_1$ and $\Vert \cdot \Vert_2$ respectively. I am trying to understand when $H = H_1 \cap H_2$ becomes a Hilbert space with the inner product $\langle \cdot,\cdot\rangle_1 + \langle \cdot,\cdot\rangle_2$. Or does this always hold? I can see that a Cauchy sequence in $H$ is Cauchy in both $H_1$ and $H_2$, but apriori, it is not clear to me that a common convergent subsequence can be found. Thanks for any help! Edit: Let us assume that $H_1$ and $H_2$ are sitting inside a larger Hilbert space $H$. As pointed out below, otherwise the question doesn't make sense.",,"['functional-analysis', 'hilbert-spaces', 'inner-products']"
6,Two definitions of spectrums,Two definitions of spectrums,,"In Kreyszig's Introductory Functional Analysis Page 371, the point spectrum is defined as $\sigma_p(T)$ such that $R_\lambda(T) = (T - \lambda I)^{-1}$ does not exist. While in my functional analysis class lecture notes, the point spectrum is defined as $\sigma_p(T) = \{\lambda \in \mathbb C : ker(T - \lambda I) \neq \{0\}\}.$ The spectrum is defined as $\sigma(T) = \{T_\lambda := T - \lambda I$ is not invertible$\}.$ It seems to me that such two definitions are contradictory, that Kreyszig's definition of point spectrum is the definition of spectrum in my class lecture notes. Can someone explain to me the difference of such definitions?","In Kreyszig's Introductory Functional Analysis Page 371, the point spectrum is defined as $\sigma_p(T)$ such that $R_\lambda(T) = (T - \lambda I)^{-1}$ does not exist. While in my functional analysis class lecture notes, the point spectrum is defined as $\sigma_p(T) = \{\lambda \in \mathbb C : ker(T - \lambda I) \neq \{0\}\}.$ The spectrum is defined as $\sigma(T) = \{T_\lambda := T - \lambda I$ is not invertible$\}.$ It seems to me that such two definitions are contradictory, that Kreyszig's definition of point spectrum is the definition of spectrum in my class lecture notes. Can someone explain to me the difference of such definitions?",,"['functional-analysis', 'spectral-theory']"
7,Convergence in the weak operator topology implies uniform boundedness in the norm topology?,Convergence in the weak operator topology implies uniform boundedness in the norm topology?,,"If $\{T_n\}$ is a sequence of bounded operators on the Banach space $X$ which converge in the weak operator topology, could someone help me see why it is uniformly bounded in the norm topology? I know how to apply the uniform boundedness principle to reach the conclusion above under the stronger assumption that the $T_n$ converge in the strong operator topology. I'd appreciate any helpful hints.","If $\{T_n\}$ is a sequence of bounded operators on the Banach space $X$ which converge in the weak operator topology, could someone help me see why it is uniformly bounded in the norm topology? I know how to apply the uniform boundedness principle to reach the conclusion above under the stronger assumption that the $T_n$ converge in the strong operator topology. I'd appreciate any helpful hints.",,"['real-analysis', 'functional-analysis', 'banach-spaces']"
8,Arzela-Ascoli: Proof?,Arzela-Ascoli: Proof?,,"Problem Given a compact domain. Regard the function space: $$\mathcal{C}(\Omega):=\{f:\Omega\to\mathbb{C}:f\text{ continuous}\}$$ Consider a bounded family: $$\mathcal{F}\subseteq\mathcal{C}(\Omega):\quad\|f\|_{f\in\mathcal{F}}<\infty$$ Then Arzela-Ascoli states: $$\mathcal{F}\text{ precompact}\iff\mathcal{F}\text{ equicontinuous}$$ How to prove this from scratch? Attempt For a precompact family one finds: $$\mathcal{F}\subseteq\mathcal{B}_\delta(g_1)\cup\ldots\cup\mathcal{B}_\delta(g_I)$$ So one can always pick one close enough: $$f\in\mathcal{F}:\quad|f(x)-f(z)|\leq|f(x)-g_f(x)|+|g_f(x)-g_f(z)|+|g_f(z)-f(z)|<\varepsilon\quad(x\in B_\delta(z))$$ Conversely, prove for a sequence: $$f_n\in\mathcal{F}:\quad\|f_{m'}-f_{n'}\|\to0$$ For a compact domain one finds: $$\Omega\subseteq B_\delta(a_1)\cup\ldots\cup B_\delta(a_I)$$ Bolzano-Weierstrass gives a subsequence: $$|f_n(a_i)|_{n\in\mathbb{N}}<\infty:\quad|f_{m'}(a_i)-f_{n'}(a_i)|\to0$$ Take as threshold: $$m',n'\geq N':=\max_{i=1\ldots I}N'_i$$ So one can again always pick one close enough: $$x\in\Omega:\quad|f_{m'}(x)-f_{n'}(x)|\leq|f_{m'}(x)-f_{m'}(a_x)|+|f_{m'}(a_x)-f_{n'}(a_x)|+|f_{n'}(a_x)-f_{n'}(x)|<\varepsilon$$ Is this proof correct or do I miss something? Discussion Moreover, why does the usual proof exploit separability before? (For example see wiki: Arzela-Ascoli: Proof ) Sure for a proposition on its own: $$\Omega\text{ separable}:\quad|f_n(x)-f(x)|\to0$$ $$\Omega\text{ precompact}:\quad\|f_n-f\|\to0$$ But why both together in a single proof?","Problem Given a compact domain. Regard the function space: $$\mathcal{C}(\Omega):=\{f:\Omega\to\mathbb{C}:f\text{ continuous}\}$$ Consider a bounded family: $$\mathcal{F}\subseteq\mathcal{C}(\Omega):\quad\|f\|_{f\in\mathcal{F}}<\infty$$ Then Arzela-Ascoli states: $$\mathcal{F}\text{ precompact}\iff\mathcal{F}\text{ equicontinuous}$$ How to prove this from scratch? Attempt For a precompact family one finds: $$\mathcal{F}\subseteq\mathcal{B}_\delta(g_1)\cup\ldots\cup\mathcal{B}_\delta(g_I)$$ So one can always pick one close enough: $$f\in\mathcal{F}:\quad|f(x)-f(z)|\leq|f(x)-g_f(x)|+|g_f(x)-g_f(z)|+|g_f(z)-f(z)|<\varepsilon\quad(x\in B_\delta(z))$$ Conversely, prove for a sequence: $$f_n\in\mathcal{F}:\quad\|f_{m'}-f_{n'}\|\to0$$ For a compact domain one finds: $$\Omega\subseteq B_\delta(a_1)\cup\ldots\cup B_\delta(a_I)$$ Bolzano-Weierstrass gives a subsequence: $$|f_n(a_i)|_{n\in\mathbb{N}}<\infty:\quad|f_{m'}(a_i)-f_{n'}(a_i)|\to0$$ Take as threshold: $$m',n'\geq N':=\max_{i=1\ldots I}N'_i$$ So one can again always pick one close enough: $$x\in\Omega:\quad|f_{m'}(x)-f_{n'}(x)|\leq|f_{m'}(x)-f_{m'}(a_x)|+|f_{m'}(a_x)-f_{n'}(a_x)|+|f_{n'}(a_x)-f_{n'}(x)|<\varepsilon$$ Is this proof correct or do I miss something? Discussion Moreover, why does the usual proof exploit separability before? (For example see wiki: Arzela-Ascoli: Proof ) Sure for a proposition on its own: $$\Omega\text{ separable}:\quad|f_n(x)-f(x)|\to0$$ $$\Omega\text{ precompact}:\quad\|f_n-f\|\to0$$ But why both together in a single proof?",,"['real-analysis', 'functional-analysis', 'banach-spaces']"
9,Linear functional $f$ is continuous at $x_0=0$ if and only if $f$ is continuous $\forall x\in X$?,Linear functional  is continuous at  if and only if  is continuous ?,f x_0=0 f \forall x\in X,"Let $f$ be a linear functional on a normed space $(X, \|\cdot\|)$. Prove that $f$ is continuous at $x_0=0$ if and only if $f$ is continuous at every $x\in X$. I understand that the $\Leftarrow$ is trivial but what about the other way?","Let $f$ be a linear functional on a normed space $(X, \|\cdot\|)$. Prove that $f$ is continuous at $x_0=0$ if and only if $f$ is continuous at every $x\in X$. I understand that the $\Leftarrow$ is trivial but what about the other way?",,"['functional-analysis', 'continuity']"
10,Inequivalent norms (given by different inner products) on infinite dimensional Hilbert space.,Inequivalent norms (given by different inner products) on infinite dimensional Hilbert space.,,"I have this question in reviewing for my exam. Let $H$ be an infinite dimensional Hilbert space. Write down an inner product on $H$ that gives a norm inequivalent with the original norm. Is $H$ complete under the norm determined by the new inner product? In my understanding, as the norm of a Hilbert space is induced by the inner product it equipped, there are different inner products , all satisfy linearity, conjugate symmetry, positive-definiteness, hence different norms. My confusion is, why the question is asking ""original norm""?  Is a Hilbert space uniquely determined by the inner product it uses? For example, the collection of square integrable functions on $R^d$ is a Hilbert space and equipped with a inner product of integral form. Finite-dimensional complex Euclidean space with dot product. Or, there is a space can be equipped with different inner product (to define its norm) to form the same Hilbert space? For example, the Euclidean space? BTW, how is this question related to the fact that. All infinite-dimensional (separable) Hilbert spaces are $l^2$$(Z)$ in   disguise Due to my poor understanding of functional analysis, I am not sure how is this question trying to motivate my thinking. Any help would be appreciated!  Thanks in advance!","I have this question in reviewing for my exam. Let $H$ be an infinite dimensional Hilbert space. Write down an inner product on $H$ that gives a norm inequivalent with the original norm. Is $H$ complete under the norm determined by the new inner product? In my understanding, as the norm of a Hilbert space is induced by the inner product it equipped, there are different inner products , all satisfy linearity, conjugate symmetry, positive-definiteness, hence different norms. My confusion is, why the question is asking ""original norm""?  Is a Hilbert space uniquely determined by the inner product it uses? For example, the collection of square integrable functions on $R^d$ is a Hilbert space and equipped with a inner product of integral form. Finite-dimensional complex Euclidean space with dot product. Or, there is a space can be equipped with different inner product (to define its norm) to form the same Hilbert space? For example, the Euclidean space? BTW, how is this question related to the fact that. All infinite-dimensional (separable) Hilbert spaces are $l^2$$(Z)$ in   disguise Due to my poor understanding of functional analysis, I am not sure how is this question trying to motivate my thinking. Any help would be appreciated!  Thanks in advance!",,"['functional-analysis', 'hilbert-spaces', 'normed-spaces', 'inner-products']"
11,"Counterexample to the set of all algebraic polynomials being dense in $[0,1]$",Counterexample to the set of all algebraic polynomials being dense in,"[0,1]","Today in class the professor said that if we consider $X = [0, 1]$ to be equipped with the Lebesgue measure, then  the set of all algebraic polynomials is not dense in $L^\infty([0, 1])$. But I couldn't come up with a counterexample to convince myself. Could someone come up with one?","Today in class the professor said that if we consider $X = [0, 1]$ to be equipped with the Lebesgue measure, then  the set of all algebraic polynomials is not dense in $L^\infty([0, 1])$. But I couldn't come up with a counterexample to convince myself. Could someone come up with one?",,"['real-analysis', 'functional-analysis']"
12,"Functions in $L^p(\mathbb{R}^n)$, are tempered distributions.","Functions in , are tempered distributions.",L^p(\mathbb{R}^n),"How to prove that functions in $L^p(\mathbb{R}^n),1 \leq p \leq \infty$, are tempered distributions.","How to prove that functions in $L^p(\mathbb{R}^n),1 \leq p \leq \infty$, are tempered distributions.",,"['functional-analysis', 'lp-spaces']"
13,Does a compact operator always have a kernel?,Does a compact operator always have a kernel?,,"I am sorry if this question is stupid..... I raise it when I read Lax's book Functional Analysis. We know that some integral operators are compact, for example an integral operator from $L^2[Y]$ to $L^2[X]$ defined by    $$ (Kf)(x) = \int{K(x,y)f(y)dy}$$  is compact if $X$ and $Y$ are compact space and the kernel is square integrable. But how about the converse question? Does any compact operator from $L^2[Y]$ to $L^2[X]$ always has a kernel $K(x,y)\in{L^2}$? If not, under what conditions this compact operator have such kernel? Moreover, how about other spaces, such as $C(X)$, $L^p$ space? (For genreal $L^p$ space, I am not sure this question is meaningful, since the above integral may diverge....) Can anyone give me a hint or any references? Thank you!","I am sorry if this question is stupid..... I raise it when I read Lax's book Functional Analysis. We know that some integral operators are compact, for example an integral operator from $L^2[Y]$ to $L^2[X]$ defined by    $$ (Kf)(x) = \int{K(x,y)f(y)dy}$$  is compact if $X$ and $Y$ are compact space and the kernel is square integrable. But how about the converse question? Does any compact operator from $L^2[Y]$ to $L^2[X]$ always has a kernel $K(x,y)\in{L^2}$? If not, under what conditions this compact operator have such kernel? Moreover, how about other spaces, such as $C(X)$, $L^p$ space? (For genreal $L^p$ space, I am not sure this question is meaningful, since the above integral may diverge....) Can anyone give me a hint or any references? Thank you!",,"['functional-analysis', 'compact-operators', 'integral-operators']"
14,Fubini's theorem and $\sigma$-finiteness?,Fubini's theorem and -finiteness?,\sigma,"I'm reviewing my analysis notes, and I am really confused about what is meant by $\sigma$-finiteness being a hidden hypothesis of Fubini's theorem. Here is Fubini's theorem as was stated to me: Suppose $(X, \Sigma, \mu)$ and $(Y, \tau, \nu)$ are complete measure spaces.  Consider the complete product measure space $(X \times Y, \overline{\Sigma \times \tau}, \lambda)$.  If $f \in L^{1}(d\lambda)$, then $\int \limits_{X\times Y} f d\lambda = \int \limits_{X} \left [ \int \limits_{Y} f d\nu \right ] d\mu$. I was also told that a measure space $(X, \Sigma, \mu)$ being $\sigma$-finite is equivalent to there existing $f \in L^{1}(d\mu)$ such that $f > 0$.  This equivalence was easy to prove. I can't wrap my head around where $\sigma$-finiteness is ""hiding"" in this theorem (although my professor mentioned something about the ability to find a sequence of simple functions $s_{n}$ which is monotonic increasing and converges to our non-negative function $f$ -- this was a necessary step in our proof).  Thanks for any help you can offer.","I'm reviewing my analysis notes, and I am really confused about what is meant by $\sigma$-finiteness being a hidden hypothesis of Fubini's theorem. Here is Fubini's theorem as was stated to me: Suppose $(X, \Sigma, \mu)$ and $(Y, \tau, \nu)$ are complete measure spaces.  Consider the complete product measure space $(X \times Y, \overline{\Sigma \times \tau}, \lambda)$.  If $f \in L^{1}(d\lambda)$, then $\int \limits_{X\times Y} f d\lambda = \int \limits_{X} \left [ \int \limits_{Y} f d\nu \right ] d\mu$. I was also told that a measure space $(X, \Sigma, \mu)$ being $\sigma$-finite is equivalent to there existing $f \in L^{1}(d\mu)$ such that $f > 0$.  This equivalence was easy to prove. I can't wrap my head around where $\sigma$-finiteness is ""hiding"" in this theorem (although my professor mentioned something about the ability to find a sequence of simple functions $s_{n}$ which is monotonic increasing and converges to our non-negative function $f$ -- this was a necessary step in our proof).  Thanks for any help you can offer.",,"['real-analysis', 'functional-analysis', 'measure-theory']"
15,Alternative proof for the fact that a continuous function on a closed interval attains its boundaries.,Alternative proof for the fact that a continuous function on a closed interval attains its boundaries.,,"Let $f:[a,b]\to \mathbb{R}$  be a continuous function. We are interested in showing that $\exists  \beta \in [a,b]$, such that $f(\beta) = M$, where M is its upper boundary. I have managed to proof by myself the fact that any continuous function on a closed interval is bounded so I assume we can use this in our proof. I was playing a little with the pencil, doing some test work, and the following idea came to my mind: I defiend a new function $g:[a,b]\to \mathbb{R}$, $g(x) = \frac{1}{M-f(x)}$. $g$ is obviously continuous on $[a,b]$, and we have $g(x)>0,\forall x \in [a,b]$. Since $g$ is continouou on a closed interval, $g$ is bounded. Let $M_1$ be its upper boundary. Now we have that: $$ \frac{1}{M-f(x)} \leq M_1  $$ This actually implies that: $$f(x) \leq M - \frac{1}{M_1} < M $$ This can't be true! Because if it were true, $f$ wouldn't be bounded by $M$. So, here's what I don't get. I have arrived at a contradiction! But what have I managed to contradict? It seems to me that this contradiction arrived from the fact that $f$ was bounded. So have I proved that f can't be bounded? But this doesn't make any sense, because we know for sure that $f$ is bounded, since its continuous on a closed interval. I feel that I am very close to prove the claim. Could you please help me realise what am I doing wrong here?","Let $f:[a,b]\to \mathbb{R}$  be a continuous function. We are interested in showing that $\exists  \beta \in [a,b]$, such that $f(\beta) = M$, where M is its upper boundary. I have managed to proof by myself the fact that any continuous function on a closed interval is bounded so I assume we can use this in our proof. I was playing a little with the pencil, doing some test work, and the following idea came to my mind: I defiend a new function $g:[a,b]\to \mathbb{R}$, $g(x) = \frac{1}{M-f(x)}$. $g$ is obviously continuous on $[a,b]$, and we have $g(x)>0,\forall x \in [a,b]$. Since $g$ is continouou on a closed interval, $g$ is bounded. Let $M_1$ be its upper boundary. Now we have that: $$ \frac{1}{M-f(x)} \leq M_1  $$ This actually implies that: $$f(x) \leq M - \frac{1}{M_1} < M $$ This can't be true! Because if it were true, $f$ wouldn't be bounded by $M$. So, here's what I don't get. I have arrived at a contradiction! But what have I managed to contradict? It seems to me that this contradiction arrived from the fact that $f$ was bounded. So have I proved that f can't be bounded? But this doesn't make any sense, because we know for sure that $f$ is bounded, since its continuous on a closed interval. I feel that I am very close to prove the claim. Could you please help me realise what am I doing wrong here?",,"['real-analysis', 'functional-analysis', 'proof-verification']"
16,Basic Question about notation in the space of continuous functions,Basic Question about notation in the space of continuous functions,,"I am reading the book ""Introduction to Calculus of Variations"" by Bernard Dacorogna (Could not find a link in google books) where he defines $C(\bar{\Omega})$ to be the space of continuous functions $u : \Omega \to \mathbb{R}$ which can be continuously extended to $\bar{\Omega}$ (here $\Omega$ is an open set in $\mathbb{R}^n$). After this, he defines the norm over $C(\bar{\Omega})$ by  $\|u\|_0 = \sup_{x \in \bar{\Omega}} |u(x)|$ and then $C(\bar{\Omega})$ with this norm is a Banach Space. I am confused about two things:- 1) Does $C(\bar{\Omega})$ consist of functions $u : \Omega \to \mathbb{R}$ which can be continuously extended or functions $u : \bar{\Omega} \to \mathbb{R}$ 2)The ""norm"" $\|.\|_0$ is not a norm as $\bar{\Omega}$ need not be bounded and hence it can take an infinite value Can someone please let me know if I am right and if so, this notation is OK in some texts.","I am reading the book ""Introduction to Calculus of Variations"" by Bernard Dacorogna (Could not find a link in google books) where he defines $C(\bar{\Omega})$ to be the space of continuous functions $u : \Omega \to \mathbb{R}$ which can be continuously extended to $\bar{\Omega}$ (here $\Omega$ is an open set in $\mathbb{R}^n$). After this, he defines the norm over $C(\bar{\Omega})$ by  $\|u\|_0 = \sup_{x \in \bar{\Omega}} |u(x)|$ and then $C(\bar{\Omega})$ with this norm is a Banach Space. I am confused about two things:- 1) Does $C(\bar{\Omega})$ consist of functions $u : \Omega \to \mathbb{R}$ which can be continuously extended or functions $u : \bar{\Omega} \to \mathbb{R}$ 2)The ""norm"" $\|.\|_0$ is not a norm as $\bar{\Omega}$ need not be bounded and hence it can take an infinite value Can someone please let me know if I am right and if so, this notation is OK in some texts.",,['functional-analysis']
17,Unconditional bases equivallent to permutations of basis elements.,Unconditional bases equivallent to permutations of basis elements.,,"On page 9 of The Handbook of the Geometry of Banach Spaces: Volume I I found the following: ""A basis $\{x_n\}_{n=1}^{\infty}$ is said to be an unconditional basis provided that $\sum \alpha_n x_n$ converges unconditionally whenever it converges. This is equivalent to saying that every permutation of $\{x_n\}_{n=1}^{\infty}$ is also a basis."" How are those two statements equivalent?","On page 9 of The Handbook of the Geometry of Banach Spaces: Volume I I found the following: ""A basis $\{x_n\}_{n=1}^{\infty}$ is said to be an unconditional basis provided that $\sum \alpha_n x_n$ converges unconditionally whenever it converges. This is equivalent to saying that every permutation of $\{x_n\}_{n=1}^{\infty}$ is also a basis."" How are those two statements equivalent?",,"['functional-analysis', 'banach-spaces']"
18,Riesz Lemma for reflexive spaces,Riesz Lemma for reflexive spaces,,"I know the proof of Riesz Lemma: Let $Y$ be a closed (proper) subspace of a normed space $X$. Let $\varepsilon >0$. Then it exists an element $x \in X$ such that $||x||=1$ and $d(x, Y) \geq 1-\varepsilon$. Now I want to face the case in which $X$ is reflexive. I read in this case $\varepsilon=0$. To prove that, I think I have to use the following (James theorem?) but I don't manage to connect the dots... $X$ is reflexive if and only if given $\Lambda \in X^*$ it exists $x \in X$ such that $||x||=1$ and $||\Lambda||=\Lambda x$. I was thinking that $Y$ itself is also reflexive and applying the theorem to $Y$...","I know the proof of Riesz Lemma: Let $Y$ be a closed (proper) subspace of a normed space $X$. Let $\varepsilon >0$. Then it exists an element $x \in X$ such that $||x||=1$ and $d(x, Y) \geq 1-\varepsilon$. Now I want to face the case in which $X$ is reflexive. I read in this case $\varepsilon=0$. To prove that, I think I have to use the following (James theorem?) but I don't manage to connect the dots... $X$ is reflexive if and only if given $\Lambda \in X^*$ it exists $x \in X$ such that $||x||=1$ and $||\Lambda||=\Lambda x$. I was thinking that $Y$ itself is also reflexive and applying the theorem to $Y$...",,"['functional-analysis', 'operator-theory', 'banach-spaces']"
19,Sobolev spaces in one-dimensional vs multidimensional,Sobolev spaces in one-dimensional vs multidimensional,,"Here in Wikipedia, it is said that in the one-dimensional case, it is enough to assume that the $(k-1)$-th derivative of the function $f$, is differentiable almost everywhere  and is equal almost everywhere to the Lebesgue integral of its derivative. In the other hand in the multidimensional case , it is said that we should work with derivatives in the sense of distributions, because what was used in the one dimensional case does not work. I just want some clarification why there's such differences between the one dimensional and multidimensional case.","Here in Wikipedia, it is said that in the one-dimensional case, it is enough to assume that the $(k-1)$-th derivative of the function $f$, is differentiable almost everywhere  and is equal almost everywhere to the Lebesgue integral of its derivative. In the other hand in the multidimensional case , it is said that we should work with derivatives in the sense of distributions, because what was used in the one dimensional case does not work. I just want some clarification why there's such differences between the one dimensional and multidimensional case.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'distribution-theory', 'weak-derivatives']"
20,An inequality of $L^p$ norms of linear combinations of characteristic functions of balls,An inequality of  norms of linear combinations of characteristic functions of balls,L^p,"Let $1<p<\infty$. Let $(a_n)_{n=1}^\infty$ be a sequence of nonnegative real numbers and $\{B_{r_i}(x_i)\}_{i=1}^\infty$ be a sequence of open balls in $\mathbb{R}^n$. Prove that there exists $C>0$ such that  \begin{equation*} \Big\|\sum_i a_i\chi_{3B_i}\Big\|_p\leq C\Big\|\sum_ia_i \chi _{B_i}\Big\|_p. \end{equation*} Here $B_i=B_{r_i}(x_i)$, $3B_i=B_{3r_i}(x_i)$. Moreover, $C$ does not depend on the choice of $(a_n)_{n=1}^\infty$. Hint: Let $g\in L^q(\mathbb{R}^n)$ for $1/p+1/q=1$. Let  \begin{equation*} g^*(x)=\sup_{x\in B}\dfrac{\int_B|g| d\mu}{Vol(B)}. \end{equation*} Show that there exists $C_0>0$ such that  \begin{equation*} \int_{\mathbb{R}^n}\sum_i a_i\chi_{3b_i}(x)|g(x)|d\mu\leq C_0\int_{\mathbb{R}^n}\sum_i a_i\chi_{B_i}(x)g^*(x)d\mu. \end{equation*} How to solve  this? How to prove the hints and how to use the hints to prove the result? I get totally lost. Thanks.","Let $1<p<\infty$. Let $(a_n)_{n=1}^\infty$ be a sequence of nonnegative real numbers and $\{B_{r_i}(x_i)\}_{i=1}^\infty$ be a sequence of open balls in $\mathbb{R}^n$. Prove that there exists $C>0$ such that  \begin{equation*} \Big\|\sum_i a_i\chi_{3B_i}\Big\|_p\leq C\Big\|\sum_ia_i \chi _{B_i}\Big\|_p. \end{equation*} Here $B_i=B_{r_i}(x_i)$, $3B_i=B_{3r_i}(x_i)$. Moreover, $C$ does not depend on the choice of $(a_n)_{n=1}^\infty$. Hint: Let $g\in L^q(\mathbb{R}^n)$ for $1/p+1/q=1$. Let  \begin{equation*} g^*(x)=\sup_{x\in B}\dfrac{\int_B|g| d\mu}{Vol(B)}. \end{equation*} Show that there exists $C_0>0$ such that  \begin{equation*} \int_{\mathbb{R}^n}\sum_i a_i\chi_{3b_i}(x)|g(x)|d\mu\leq C_0\int_{\mathbb{R}^n}\sum_i a_i\chi_{B_i}(x)g^*(x)d\mu. \end{equation*} How to solve  this? How to prove the hints and how to use the hints to prove the result? I get totally lost. Thanks.",,"['real-analysis', 'analysis', 'functional-analysis', 'inequality', 'lp-spaces']"
21,If $u_n \rightharpoonup u$ in $W$ and $W \subset C$ then $u_n \rightharpoonup u$ in $C$?,If  in  and  then  in ?,u_n \rightharpoonup u W W \subset C u_n \rightharpoonup u C,"Let $W \subset C$ be Banach spaces with continuous embedding here. If $u_n \rightharpoonup u$ in $W$ and $W \subset C$ then is it true that $u_n \rightharpoonup u$ in $C$ for the same sequence (not a subsequence)? I saw this result used where $W=L^2(0,T;H^1) \cap H^1(0,T;H^{-1})$ and $C=C([0,T];L^2)$.","Let $W \subset C$ be Banach spaces with continuous embedding here. If $u_n \rightharpoonup u$ in $W$ and $W \subset C$ then is it true that $u_n \rightharpoonup u$ in $C$ for the same sequence (not a subsequence)? I saw this result used where $W=L^2(0,T;H^1) \cap H^1(0,T;H^{-1})$ and $C=C([0,T];L^2)$.",,"['functional-analysis', 'partial-differential-equations', 'weak-convergence']"
22,PDE uniqueness by energy method contradicts non-uniqueness???,PDE uniqueness by energy method contradicts non-uniqueness???,,"Consider  $$u_t - \Delta u + u = 0$$ $$\frac{\partial u}{\partial \nu} = 0$$ $$u(T) = u(0)$$ on a domain $\Omega$ (the BC is obviously on $\partial\Omega$. If $u$ solves this PDE, clearly as does $\lambda u $ for any constant $\lambda.$ So uniqueness is not there. Suppose we have two solutions $u$ and $v$. Their difference $d = u-v$ satisfies $$d_t - \Delta d + d = 0$$ $$\frac{\partial d}{\partial \nu} = 0$$ $$d(T) = d(0)$$ Multiplying the equation by $d$ and integrating by parts we get $$\frac{1}{2}\frac{d}{dt}\int_{\Omega} d^2(t) + \int_{\Omega} |\nabla d(t)|^2 + \int_{\Omega} d^2(t) = 0$$ Now integrating by time $$\frac{1}{2}|d(T)|_{L^2} - \frac{1}{2}|d(0)|_{L^2} + \int_{0}^T |\nabla d(t)|_{L^2}^2 + \int_0^2 |d(t)|_{L^2}^2 = 0$$ but the first two terms cancel each other out, and we get $d=0$ in $H^1$. So this shows that there is a unique solution. What am I doing wrong???!?! Edit : maybe $0$ is the only solution to this problem? How to prove this if so? What happens in nonhomogenous case?","Consider  $$u_t - \Delta u + u = 0$$ $$\frac{\partial u}{\partial \nu} = 0$$ $$u(T) = u(0)$$ on a domain $\Omega$ (the BC is obviously on $\partial\Omega$. If $u$ solves this PDE, clearly as does $\lambda u $ for any constant $\lambda.$ So uniqueness is not there. Suppose we have two solutions $u$ and $v$. Their difference $d = u-v$ satisfies $$d_t - \Delta d + d = 0$$ $$\frac{\partial d}{\partial \nu} = 0$$ $$d(T) = d(0)$$ Multiplying the equation by $d$ and integrating by parts we get $$\frac{1}{2}\frac{d}{dt}\int_{\Omega} d^2(t) + \int_{\Omega} |\nabla d(t)|^2 + \int_{\Omega} d^2(t) = 0$$ Now integrating by time $$\frac{1}{2}|d(T)|_{L^2} - \frac{1}{2}|d(0)|_{L^2} + \int_{0}^T |\nabla d(t)|_{L^2}^2 + \int_0^2 |d(t)|_{L^2}^2 = 0$$ but the first two terms cancel each other out, and we get $d=0$ in $H^1$. So this shows that there is a unique solution. What am I doing wrong???!?! Edit : maybe $0$ is the only solution to this problem? How to prove this if so? What happens in nonhomogenous case?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
23,Maximum Entropy (The existence of a Calculus of Variations problem),Maximum Entropy (The existence of a Calculus of Variations problem),,"Take maximum differential entropy as an example: Gaussian achieves the maximum differential entropy when the second order moment is fixed. The calculus of variation form: \begin{equation} \begin{split} \min & \int f(x)\log f(x) dx,\\ s.t. & \int f(x) dx=1,\\ & \int x^2 f(x) dx=\sigma^2 \end{split} \end{equation} By using Lagrange multipliers and Euler's Equation, we can conclude Gaussian is the necessary solution for this problem. However, how to prove the sufficiency of Gaussian? Most textbooks just end the proof with Lagrange multipliers (necessity), is that enough? I do not know too much about functional analysis. Can we move the theorems from convex function to this one? For example, prove the constraints form a compact set such that there is a minimum, and Gaussian is the only choice. Or prove Gaussian is the local minimum, since it's a convex function over a convex set, local=global? Sorry for the confusion, I am asking how to prove the sufficiency in Calculus of Variations way.","Take maximum differential entropy as an example: Gaussian achieves the maximum differential entropy when the second order moment is fixed. The calculus of variation form: \begin{equation} \begin{split} \min & \int f(x)\log f(x) dx,\\ s.t. & \int f(x) dx=1,\\ & \int x^2 f(x) dx=\sigma^2 \end{split} \end{equation} By using Lagrange multipliers and Euler's Equation, we can conclude Gaussian is the necessary solution for this problem. However, how to prove the sufficiency of Gaussian? Most textbooks just end the proof with Lagrange multipliers (necessity), is that enough? I do not know too much about functional analysis. Can we move the theorems from convex function to this one? For example, prove the constraints form a compact set such that there is a minimum, and Gaussian is the only choice. Or prove Gaussian is the local minimum, since it's a convex function over a convex set, local=global? Sorry for the confusion, I am asking how to prove the sufficiency in Calculus of Variations way.",,"['functional-analysis', 'calculus-of-variations']"
24,Banach Algebra: $\sigma(xy)\cup\{0\} = \sigma(yx)\cup\{0\}$,Banach Algebra:,\sigma(xy)\cup\{0\} = \sigma(yx)\cup\{0\},"It is Rudin excercise 10.4 where we aim to prove $\sigma(xy)\cup\{0\} = \sigma(yx)\cup \{0\}$ for elements $x,y\in A$ a Banach-algebra.( $\sigma$ being the spectrum) In (a) we prove that $e-yx$ invertible $\Leftrightarrow e-xy$ invertible. Following the hint: Put $z= (e-xy)^{-1}$, write $z$ as geometric series (assume $\left\|x\right\| < 1, \left\|y\right\|< 1$), and use the identity $(xy)^n = x(yx)^{n-1}y$ to obtain a finite formula $(e-yx)^{-1}$ in terms of $x,y,z $. Then show that this formula works without any restrictions  on  $\left\|x\right\|$ or $\left\|y\right\|$. Ok, so lets put \begin{align*} z = (e-xy)^{-1} &= \sum_{k=0}^{\infty} (xy)^k = e+\sum_{k=1}^{\infty} (xy)^k\\ & =e + \sum_{k=1}^{\infty}x(yx)^{k-1}y = e+ x(e-yx)^{-1}y \end{align*} Is this right? But I dont see how i can  single out out $(e-yx)^{-1}$. And how to make this work without restrictions on  $\left\|x\right\|$ or $\left\|y\right\|$? And second (b) I want to show that if $\lambda\neq 0$ and $\lambda \in \sigma(xy)$ then $\lambda \in \sigma(yx)$.  Thus $\sigma(xy)\cup\{0\} = \sigma(yx)\cup \{0\}$. Then also, how do we see that $\sigma(xy)$ doesn't have to be equal to $\sigma(yx)$. Thanks for tips and suggestions.","It is Rudin excercise 10.4 where we aim to prove $\sigma(xy)\cup\{0\} = \sigma(yx)\cup \{0\}$ for elements $x,y\in A$ a Banach-algebra.( $\sigma$ being the spectrum) In (a) we prove that $e-yx$ invertible $\Leftrightarrow e-xy$ invertible. Following the hint: Put $z= (e-xy)^{-1}$, write $z$ as geometric series (assume $\left\|x\right\| < 1, \left\|y\right\|< 1$), and use the identity $(xy)^n = x(yx)^{n-1}y$ to obtain a finite formula $(e-yx)^{-1}$ in terms of $x,y,z $. Then show that this formula works without any restrictions  on  $\left\|x\right\|$ or $\left\|y\right\|$. Ok, so lets put \begin{align*} z = (e-xy)^{-1} &= \sum_{k=0}^{\infty} (xy)^k = e+\sum_{k=1}^{\infty} (xy)^k\\ & =e + \sum_{k=1}^{\infty}x(yx)^{k-1}y = e+ x(e-yx)^{-1}y \end{align*} Is this right? But I dont see how i can  single out out $(e-yx)^{-1}$. And how to make this work without restrictions on  $\left\|x\right\|$ or $\left\|y\right\|$? And second (b) I want to show that if $\lambda\neq 0$ and $\lambda \in \sigma(xy)$ then $\lambda \in \sigma(yx)$.  Thus $\sigma(xy)\cup\{0\} = \sigma(yx)\cup \{0\}$. Then also, how do we see that $\sigma(xy)$ doesn't have to be equal to $\sigma(yx)$. Thanks for tips and suggestions.",,"['functional-analysis', 'banach-algebras']"
25,$\ell^1$ Schur property,Schur property,\ell^1,"I want to show that $\ell^1( \mathbb N )$ enjoys the Schur property . More precisely, I have to prove the following Theorem. Let $X = \ell^1 (\mathbb N )$, $\{ x^{(n)} \} \subset X$, $x \in X$. The following statements are equivalent: $x^{(n)} \overset{n \to \infty}{\rightharpoonup} x$ ; $x^{(n)} \overset{n \to \infty}{\to} x$. Now, $(2) \implies (1)$ is trivial. For the $(1) \implies (2)$ side, I tried something like: let $f \in \ell^1(\mathbb N)^\prime$ be an arbitrary linear functional. Then, by definition, \begin{equation} x^{(n)} \overset{n \to \infty}{\rightharpoonup} x \iff \langle f, x^{(n)} \rangle \to \langle f, x \rangle \implies \lvert \langle f, x^{(n)} - x \rangle \rvert \to 0 \quad (n \to \infty) . \end{equation} Hence \begin{equation} \lvert \langle f, x^{(n)} - x \rangle \rvert \leq \lVert f \rVert \lVert x^{(n)} - x \rVert. \end{equation} (This reasoning is actually applied for the other side; I wonder if something useful could be extracted in a similar way.) Now, by the Hahn-Banach theorem, we can choose $f$ such that $\lVert f \rVert = 1$ and $\langle f, x^{(n)} - x \rangle = \lVert x^{(n)} - x \rVert$. Since the left hand side of the last equation tends to zero for every $f \in \ell^1(\mathbb N)^\prime$ by definition of weak convergence, and in particular for the $f$ given by H-B theorem, it seems that the result would hold for every Banach space. This is clearly absurd , but I can't understand where the error is. Notice that it is obvious that the proof relies on the particular norm of $\ell^1$ and my original idea was to exploit it in same manner from the point where I'm stucked. I suspect there is no way to complete the preceding attempt and achieve a correct solution of the problem. (as one should expect in most cases he tries to copy the other part in a proof like that.) Nevertheless, I wanna detect the mistakes for many reasons. (proving the theorem, understanding the usage of the Hahn-Banach theorem, better myself, avoid similar mistakes in different situations, etc...) So I ask for a ""error-checking"" and for a proof of the theorem. (or references as well.) Thank you!","I want to show that $\ell^1( \mathbb N )$ enjoys the Schur property . More precisely, I have to prove the following Theorem. Let $X = \ell^1 (\mathbb N )$, $\{ x^{(n)} \} \subset X$, $x \in X$. The following statements are equivalent: $x^{(n)} \overset{n \to \infty}{\rightharpoonup} x$ ; $x^{(n)} \overset{n \to \infty}{\to} x$. Now, $(2) \implies (1)$ is trivial. For the $(1) \implies (2)$ side, I tried something like: let $f \in \ell^1(\mathbb N)^\prime$ be an arbitrary linear functional. Then, by definition, \begin{equation} x^{(n)} \overset{n \to \infty}{\rightharpoonup} x \iff \langle f, x^{(n)} \rangle \to \langle f, x \rangle \implies \lvert \langle f, x^{(n)} - x \rangle \rvert \to 0 \quad (n \to \infty) . \end{equation} Hence \begin{equation} \lvert \langle f, x^{(n)} - x \rangle \rvert \leq \lVert f \rVert \lVert x^{(n)} - x \rVert. \end{equation} (This reasoning is actually applied for the other side; I wonder if something useful could be extracted in a similar way.) Now, by the Hahn-Banach theorem, we can choose $f$ such that $\lVert f \rVert = 1$ and $\langle f, x^{(n)} - x \rangle = \lVert x^{(n)} - x \rVert$. Since the left hand side of the last equation tends to zero for every $f \in \ell^1(\mathbb N)^\prime$ by definition of weak convergence, and in particular for the $f$ given by H-B theorem, it seems that the result would hold for every Banach space. This is clearly absurd , but I can't understand where the error is. Notice that it is obvious that the proof relies on the particular norm of $\ell^1$ and my original idea was to exploit it in same manner from the point where I'm stucked. I suspect there is no way to complete the preceding attempt and achieve a correct solution of the problem. (as one should expect in most cases he tries to copy the other part in a proof like that.) Nevertheless, I wanna detect the mistakes for many reasons. (proving the theorem, understanding the usage of the Hahn-Banach theorem, better myself, avoid similar mistakes in different situations, etc...) So I ask for a ""error-checking"" and for a proof of the theorem. (or references as well.) Thank you!",,"['functional-analysis', 'weak-convergence']"
26,Supremum over dense subset of banach space,Supremum over dense subset of banach space,,Let $\{x_n\}$ be a countable dense subset of a Banach space $X$. How can I show that $$\sup_{x \in X}f(x) = \sup_{n \in \mathbb{N}}f(x_n)$$ where $f$ is continuous and real-valued??,Let $\{x_n\}$ be a countable dense subset of a Banach space $X$. How can I show that $$\sup_{x \in X}f(x) = \sup_{n \in \mathbb{N}}f(x_n)$$ where $f$ is continuous and real-valued??,,"['functional-analysis', 'banach-spaces']"
27,Dual of a topological vector space. Is it nontrivial?,Dual of a topological vector space. Is it nontrivial?,,"In the case of normed spaces we know their duals are nonempty using a quick application of the Hahn Banach Theorem. If we step back to the larger class of locally convex spaces, an enthralling sequence of separation results yields another nontrivial dual. What about general topological vector spaces?  Is it possible to have a nontrivial topological vector space over which every linear functional is discontinuous?","In the case of normed spaces we know their duals are nonempty using a quick application of the Hahn Banach Theorem. If we step back to the larger class of locally convex spaces, an enthralling sequence of separation results yields another nontrivial dual. What about general topological vector spaces?  Is it possible to have a nontrivial topological vector space over which every linear functional is discontinuous?",,"['functional-analysis', 'topological-vector-spaces', 'duality-theorems']"
28,Kolmogorov continuity theorem for Banach space valued random processes,Kolmogorov continuity theorem for Banach space valued random processes,,I am interested in the Kolmogorov continuity theorem . I would like to know if this theorem holds for Banach space valued random processes (probably separable Banach space). I cannot find a paper or a textbook that contains a version of the Kolmogorov continuity theorem for Banach space valued random processes. My questions are as follows: does the Kolmogorov continuity theorem hold for Banach space valued random processes; where can I find a paper or a textbook that contains the statement and the proof of the Kolmogorov continuity theorem for Banach space valued random processes? Any help is much appreciated!,I am interested in the Kolmogorov continuity theorem . I would like to know if this theorem holds for Banach space valued random processes (probably separable Banach space). I cannot find a paper or a textbook that contains a version of the Kolmogorov continuity theorem for Banach space valued random processes. My questions are as follows: does the Kolmogorov continuity theorem hold for Banach space valued random processes; where can I find a paper or a textbook that contains the statement and the proof of the Kolmogorov continuity theorem for Banach space valued random processes? Any help is much appreciated!,,"['functional-analysis', 'reference-request', 'probability-theory', 'stochastic-processes']"
29,Reference for compution adjoint of the operator $L=\Delta^2$,Reference for compution adjoint of the operator,L=\Delta^2,"I need to use adjoint operator of the partial differential operator $L=\Delta^2$, where $\Delta$ denotes the Laplacian. I do not want to put this computation in my thesis, because I feel is a bit distracting since it would probably involve the local and integral form of $L$. Is there some book where I can find this adjoint operator?","I need to use adjoint operator of the partial differential operator $L=\Delta^2$, where $\Delta$ denotes the Laplacian. I do not want to put this computation in my thesis, because I feel is a bit distracting since it would probably involve the local and integral form of $L$. Is there some book where I can find this adjoint operator?",,"['functional-analysis', 'reference-request', 'partial-differential-equations']"
30,"Showing that a set is complete in $L^2[0, \, \pi/2]$",Showing that a set is complete in,"L^2[0, \, \pi/2]","I'm trying to show that the set $S = \{ \sin((2n - 1)x)\}$ for $n = 1, 2, \dots $ forms a complete system for the Hilbert space $L^2[0, \, \pi/2]$. In other words I have to show that if $f \in L^2[0, \, \pi/2]$ satisfies $$\langle f , \, \sin((2n - 1)x) \rangle = \int_0^{\pi/2} f(x) \sin((2n - 1)x) = 0$$ for all $ n \in \mathbb{N}$, then $f = 0 $. One idea I have heard is to use the fact that $\{e^{i n x}\}_{n \in \mathbb{Z}} $ is a complete system for $L^2[-\pi, \, \pi]$. I think the idea is to extend the function $f$ to the interval $[-\pi, \, \pi]$ somehow, and use the completeness of the set $\{e^{i n x}\}$. I'm not entirely sure of the details however. So I guess my question is, how can we use the completeness of $\{e^{i n x}\}_{n \in \mathbb{Z}} $ on $[-\pi, \, \pi]$ to show completeness of $\{\sin((2n - 1)x)\}_{n \in \mathbb{N}}$ on $[0, \, \pi/2]$? Specifically why is it only the odd positive values of $n$ that are left over when going from $[-\pi, \, \pi]$ to $[0, \, \pi/2]$? Also, out of curiosity, is there an ""easy"" way to do this question from scratch (i.e., without relying on the fact that $\{e^{i n  x}\}_{n \in \mathbb{Z}} $ is a complete system)?","I'm trying to show that the set $S = \{ \sin((2n - 1)x)\}$ for $n = 1, 2, \dots $ forms a complete system for the Hilbert space $L^2[0, \, \pi/2]$. In other words I have to show that if $f \in L^2[0, \, \pi/2]$ satisfies $$\langle f , \, \sin((2n - 1)x) \rangle = \int_0^{\pi/2} f(x) \sin((2n - 1)x) = 0$$ for all $ n \in \mathbb{N}$, then $f = 0 $. One idea I have heard is to use the fact that $\{e^{i n x}\}_{n \in \mathbb{Z}} $ is a complete system for $L^2[-\pi, \, \pi]$. I think the idea is to extend the function $f$ to the interval $[-\pi, \, \pi]$ somehow, and use the completeness of the set $\{e^{i n x}\}$. I'm not entirely sure of the details however. So I guess my question is, how can we use the completeness of $\{e^{i n x}\}_{n \in \mathbb{Z}} $ on $[-\pi, \, \pi]$ to show completeness of $\{\sin((2n - 1)x)\}_{n \in \mathbb{N}}$ on $[0, \, \pi/2]$? Specifically why is it only the odd positive values of $n$ that are left over when going from $[-\pi, \, \pi]$ to $[0, \, \pi/2]$? Also, out of curiosity, is there an ""easy"" way to do this question from scratch (i.e., without relying on the fact that $\{e^{i n  x}\}_{n \in \mathbb{Z}} $ is a complete system)?",,['functional-analysis']
31,Question about finding the norm of a bounded linear operator,Question about finding the norm of a bounded linear operator,,"Let H be a Hilbert space. Suppose $(i_k)_1^\infty$ is a complete orthonormal sequence in H. Let $a_k \in \mathbb{C}$ for $k \in \mathbb{N}$. Assume there is a bounded linear operator  $T:H \rightarrow H$  such that $T(i_k) = a_ki_k$ given that ($a_k$), $\forall k \in \mathbb{N}$ is bounded. We want to find $||T||$. We know that $||T|| = \sup\{||Tx||: x \in H, ||x|| \le 1\}$. For any given $x \in H$ we can write $x = \sum_{n=1}^\infty (x, i_n)i_n $, therefore $||x||^2 = \sum_{n=1}^\infty |(x,i_n)|^2$ and by Cauchy-Schwarz we have $|(x,i_n)| \le ||x||$. I suspect that $||T|| = sup_k |a_k|$ thinking about it intuitively but not sure how to show that. Since we know T is linear then: $Tx = \sum_{n=1}^\infty (x, i_n)Ti_n = \sum_{n=1}^\infty (x, i_n)a_ni_n.$ From this $||Tx||^2 = \sum_{n=1}^\infty |(x, i_n)|^2|a_ni_n|^2 \le (sup|a_n|)^2||x||^2$ by Bessel inequality, then $||T|| \le sup|a_n|.$ If this is correct, how could we show equality?","Let H be a Hilbert space. Suppose $(i_k)_1^\infty$ is a complete orthonormal sequence in H. Let $a_k \in \mathbb{C}$ for $k \in \mathbb{N}$. Assume there is a bounded linear operator  $T:H \rightarrow H$  such that $T(i_k) = a_ki_k$ given that ($a_k$), $\forall k \in \mathbb{N}$ is bounded. We want to find $||T||$. We know that $||T|| = \sup\{||Tx||: x \in H, ||x|| \le 1\}$. For any given $x \in H$ we can write $x = \sum_{n=1}^\infty (x, i_n)i_n $, therefore $||x||^2 = \sum_{n=1}^\infty |(x,i_n)|^2$ and by Cauchy-Schwarz we have $|(x,i_n)| \le ||x||$. I suspect that $||T|| = sup_k |a_k|$ thinking about it intuitively but not sure how to show that. Since we know T is linear then: $Tx = \sum_{n=1}^\infty (x, i_n)Ti_n = \sum_{n=1}^\infty (x, i_n)a_ni_n.$ From this $||Tx||^2 = \sum_{n=1}^\infty |(x, i_n)|^2|a_ni_n|^2 \le (sup|a_n|)^2||x||^2$ by Bessel inequality, then $||T|| \le sup|a_n|.$ If this is correct, how could we show equality?",,"['analysis', 'functional-analysis', 'operator-theory']"
32,A theorem about operator theory,A theorem about operator theory,,"Define $$\operatorname{Ref}\mathcal{S}=\{T\in B(\mathcal{H}):Th\in[\mathcal{S}h], \forall h \in \mathcal{H}\},$$where $\mathcal{H}$ is a Hilbert space and $\mathcal{S}$ is a linear manifold of $B(\mathcal{H})$. A proposition of Conway's book A Course in Operator Theory says that $\operatorname{Ref}\mathcal{S^\ast}=(\operatorname{Ref}\mathcal{S})^\ast$ and the proof is left as an easy exercise. It is not easy for me, thanks to the one who can tell me a proof or give me a hint.","Define $$\operatorname{Ref}\mathcal{S}=\{T\in B(\mathcal{H}):Th\in[\mathcal{S}h], \forall h \in \mathcal{H}\},$$where $\mathcal{H}$ is a Hilbert space and $\mathcal{S}$ is a linear manifold of $B(\mathcal{H})$. A proposition of Conway's book A Course in Operator Theory says that $\operatorname{Ref}\mathcal{S^\ast}=(\operatorname{Ref}\mathcal{S})^\ast$ and the proof is left as an easy exercise. It is not easy for me, thanks to the one who can tell me a proof or give me a hint.",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
33,Do equivalent norms preserve dual spaces?,Do equivalent norms preserve dual spaces?,,"Suppose that $X^*$ is the dual space of a normed space $X$. If we renorm the space $X^*$ with a new norm equivalent to the first one, is this new normed space the dual of $X$ as well? (I think it suffices to prove that a functional $f$ is continuous with a norm1 if and only if it is continuous with norm2 where norm1 and norm2 are two equivalent norms. This seems to be obvious!). Thanks for the help.","Suppose that $X^*$ is the dual space of a normed space $X$. If we renorm the space $X^*$ with a new norm equivalent to the first one, is this new normed space the dual of $X$ as well? (I think it suffices to prove that a functional $f$ is continuous with a norm1 if and only if it is continuous with norm2 where norm1 and norm2 are two equivalent norms. This seems to be obvious!). Thanks for the help.",,"['functional-analysis', 'normed-spaces']"
34,Index of twisted Dirac operator,Index of twisted Dirac operator,,"I do not understand a step in the proof of the Lemma 11.4.1 in the book ""Analytic K-Homology"" by Higson, Roe. Let $S$ be a Dirac bundle over a closed manifold $M$ and $D$ the corresponding Dirac operator. Let $E$ be a Hermitian vector bundle over $M$. Then $S \otimes E$ is again a Dirac bundle, so let $D_E$ be the corresponding twisted Dirac operator. Let $P \colon M \to M_n(\mathbb{C})$ be the projection-valued function determining $E$. Let $D_n$ be the operator $1 \otimes D$ on $H_n := \mathbb{C}^n \otimes L^2(S)$. Let $\chi$ be a normalizing function. Then it is claimed that $\operatorname{Index}(\chi(D_E))$ equals the index of the operator $\chi(PD_nP)$ on the space $PH_n$. What bothers me is that the operator  $PD_nP$ does not depend on the chosen metric / connection on $E$, whereas the operator $D_E$ does depend on it. And it is never mentioned in the book that the index of the twisted operator $D_E$ is independent of this choices.","I do not understand a step in the proof of the Lemma 11.4.1 in the book ""Analytic K-Homology"" by Higson, Roe. Let $S$ be a Dirac bundle over a closed manifold $M$ and $D$ the corresponding Dirac operator. Let $E$ be a Hermitian vector bundle over $M$. Then $S \otimes E$ is again a Dirac bundle, so let $D_E$ be the corresponding twisted Dirac operator. Let $P \colon M \to M_n(\mathbb{C})$ be the projection-valued function determining $E$. Let $D_n$ be the operator $1 \otimes D$ on $H_n := \mathbb{C}^n \otimes L^2(S)$. Let $\chi$ be a normalizing function. Then it is claimed that $\operatorname{Index}(\chi(D_E))$ equals the index of the operator $\chi(PD_nP)$ on the space $PH_n$. What bothers me is that the operator  $PD_nP$ does not depend on the chosen metric / connection on $E$, whereas the operator $D_E$ does depend on it. And it is never mentioned in the book that the index of the twisted operator $D_E$ is independent of this choices.",,"['functional-analysis', 'differential-geometry', 'riemannian-geometry', 'topological-k-theory', 'k-theory']"
35,Definite states on C*-algebras,Definite states on C*-algebras,,"A state $\omega$ on a unital $C^*$ algebra $A$ is called definite at $a\in A$ self-adjoint  if $\omega(a^2)=\omega(a)^2$. I proved that if we have such a definite state at $a$, then for all $b\in A$ we have: $$\omega(ab)=\omega(ba)= \omega(a)\omega(b).$$ Now I want to prove the following. Let $a\in A$ be self-adjoint and assume that for all $0\neq b\in A$, there exists a definite state $\omega$ at $a$ such that $\omega(b)\neq0$. Prove that $a\in Z(A)$, where $Z(A)$ is the center of $A$. The problem is: we don't have any information which guarantee that $\omega$ is one-to-one, but I know that every state define a semi inner product on $A$ as follows : $\forall a,b\in A$: $\langle a,b\rangle =\omega(b^*a)$, does it help ?? Any idea is really appreciated. Thanks!","A state $\omega$ on a unital $C^*$ algebra $A$ is called definite at $a\in A$ self-adjoint  if $\omega(a^2)=\omega(a)^2$. I proved that if we have such a definite state at $a$, then for all $b\in A$ we have: $$\omega(ab)=\omega(ba)= \omega(a)\omega(b).$$ Now I want to prove the following. Let $a\in A$ be self-adjoint and assume that for all $0\neq b\in A$, there exists a definite state $\omega$ at $a$ such that $\omega(b)\neq0$. Prove that $a\in Z(A)$, where $Z(A)$ is the center of $A$. The problem is: we don't have any information which guarantee that $\omega$ is one-to-one, but I know that every state define a semi inner product on $A$ as follows : $\forall a,b\in A$: $\langle a,b\rangle =\omega(b^*a)$, does it help ?? Any idea is really appreciated. Thanks!",,"['functional-analysis', 'operator-algebras', 'c-star-algebras']"
36,"Sobolev inequality in $W_0^{1,p}$",Sobolev inequality in,"W_0^{1,p}","If $\Omega \subseteq \mathbb{R}^N$ is an open bounded domain and $1<p<N$, then the classical Sobolev Inequality: $$\| u\|_{p^*,\Omega} \leq C\ \| \nabla u\|_{p,\Omega}$$ holds with $C=C(p,N,\Omega)>0$ and $p^*:= Np/(N-p)$ for any $u\in W_0^{1,p}(\Omega)$. What about the case $p\geq N$? May I take the $L^\infty$-norm in the LHside? If I remember correctly, in general I cannot get the inequality with $\| \cdot \|_\infty$, for there are counterexemples of unbounded Sobolev functions... But, what if I know ""a priori"" that $u\in L^\infty(\Omega) \cap W_0^{1,p}(\Omega)$? Any reference? (Adams-Fournier? Brezis?) Thanks in advance.","If $\Omega \subseteq \mathbb{R}^N$ is an open bounded domain and $1<p<N$, then the classical Sobolev Inequality: $$\| u\|_{p^*,\Omega} \leq C\ \| \nabla u\|_{p,\Omega}$$ holds with $C=C(p,N,\Omega)>0$ and $p^*:= Np/(N-p)$ for any $u\in W_0^{1,p}(\Omega)$. What about the case $p\geq N$? May I take the $L^\infty$-norm in the LHside? If I remember correctly, in general I cannot get the inequality with $\| \cdot \|_\infty$, for there are counterexemples of unbounded Sobolev functions... But, what if I know ""a priori"" that $u\in L^\infty(\Omega) \cap W_0^{1,p}(\Omega)$? Any reference? (Adams-Fournier? Brezis?) Thanks in advance.",,"['functional-analysis', 'sobolev-spaces']"
37,From weak and weak star to norm convergence,From weak and weak star to norm convergence,,"I haven't found this yet and I'm somehow not sure if my idea is correct. The Problem: Let $X$ be a separable Banach-Space, let $x_k\to x$ weakly and such that for every $\lambda_k \to \lambda$ weakly-* there holds $\lambda_k(x_k)\to \lambda(x)$. Then $x_k\to x$ strongly (in the norm of $X$). My idea was to give a proof with contradiction. Hence assume there holds for some $\epsilon >0$ and a subsequence of $x_k$ denoted again by $k$: $$ \epsilon <||x_k-x||=|\lambda^*_k(x_k-x)| $$ for a functional provided by Hahn-Banach theorem with norm 1. From that and the separabilty we conclude that there is a further subsequence such that $\lambda_{k_l}^*\to \lambda^*$ weakly-* . Since each subsequence of $x_k$ also converges weakly to $x$ we use the ""weakly-*"" assumption to receive a contradiction since for the previous subsequence $$|\lambda^*_{k_l}(x_{k_l}-x)|=|\lambda^*_{k_l}(x_{k_l})-\lambda^*_{k_l}(x)|\to 0$$ Somehow this seems to easy and I feel like I'm not using especially the weak convergence in the right way.","I haven't found this yet and I'm somehow not sure if my idea is correct. The Problem: Let $X$ be a separable Banach-Space, let $x_k\to x$ weakly and such that for every $\lambda_k \to \lambda$ weakly-* there holds $\lambda_k(x_k)\to \lambda(x)$. Then $x_k\to x$ strongly (in the norm of $X$). My idea was to give a proof with contradiction. Hence assume there holds for some $\epsilon >0$ and a subsequence of $x_k$ denoted again by $k$: $$ \epsilon <||x_k-x||=|\lambda^*_k(x_k-x)| $$ for a functional provided by Hahn-Banach theorem with norm 1. From that and the separabilty we conclude that there is a further subsequence such that $\lambda_{k_l}^*\to \lambda^*$ weakly-* . Since each subsequence of $x_k$ also converges weakly to $x$ we use the ""weakly-*"" assumption to receive a contradiction since for the previous subsequence $$|\lambda^*_{k_l}(x_{k_l}-x)|=|\lambda^*_{k_l}(x_{k_l})-\lambda^*_{k_l}(x)|\to 0$$ Somehow this seems to easy and I feel like I'm not using especially the weak convergence in the right way.",,"['functional-analysis', 'convergence-divergence', 'banach-spaces', 'weak-convergence']"
38,Inequality regarding norms and weak-star convergence,Inequality regarding norms and weak-star convergence,,"Let $X$ be a normed space and $(x'_n) \subseteq X'$ a sequence of functionals where $x_n'$ has $x'$ has its limit in the *-weak topology in $X'$. Show that $$   ||x'|| \le \operatorname{lim inf}_{n\to \infty} ||x'_n||. $$ I have no glue how to show this, do you have any hints?","Let $X$ be a normed space and $(x'_n) \subseteq X'$ a sequence of functionals where $x_n'$ has $x'$ has its limit in the *-weak topology in $X'$. Show that $$   ||x'|| \le \operatorname{lim inf}_{n\to \infty} ||x'_n||. $$ I have no glue how to show this, do you have any hints?",,"['functional-analysis', 'convergence-divergence']"
39,Graph of symmetric linear map is closed,Graph of symmetric linear map is closed,,"A homework problem: Let $H$ be a Hilbert space. Let $T:H\rightarrow H$ be a symmetric linear map ( $\langle Tx,y\rangle=\langle x,Ty\rangle$ ). Show that $S$ is bounded. My attempt : I'd like to use the closed graph theorem. I take $(x_n)\subset H$ and assume $x_n \rightarrow x$ and $Tx_n\rightarrow y$ . I'd like to show $Tx=y$ . So I calculate: $\|Tx_n-Tx\|^2=\|T(x_n-x)\|^2=|\langle T(x_n-x), T(x_n-x)\rangle|=$ $|\langle x_n-x, T(T(x_n-x))\rangle|\leq \|x_n-x\|\cdot \|T(T(x_n-x))\|$ . So, it's enough to show that $\|T(T(x_n-x))\|$ is bounded. The fact that $T(x_n)$ converges tells me that $\|T(x_n-x)\|$ is bounded, but I don't know what about $\|T(T(x_n-x))\|$ .","A homework problem: Let be a Hilbert space. Let be a symmetric linear map ( ). Show that is bounded. My attempt : I'd like to use the closed graph theorem. I take and assume and . I'd like to show . So I calculate: . So, it's enough to show that is bounded. The fact that converges tells me that is bounded, but I don't know what about .","H T:H\rightarrow H \langle Tx,y\rangle=\langle x,Ty\rangle S (x_n)\subset H x_n \rightarrow x Tx_n\rightarrow y Tx=y \|Tx_n-Tx\|^2=\|T(x_n-x)\|^2=|\langle T(x_n-x), T(x_n-x)\rangle|= |\langle x_n-x, T(T(x_n-x))\rangle|\leq \|x_n-x\|\cdot \|T(T(x_n-x))\| \|T(T(x_n-x))\| T(x_n) \|T(x_n-x)\| \|T(T(x_n-x))\|","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
40,Continuity criterions for linear maps between Banach spaces?,Continuity criterions for linear maps between Banach spaces?,,"I just did one exercise stating: Prove that the linear map $M: X \rightarrow C([0,1])$, is continuous iff for every $t\in[0,1]$, the rule $x\rightarrow (Mx)(t)$ defines a continuous linear functional on X. the next exercise stated: State, and prove a similar continuity criterion for linear maps $M:X\rightarrow Y$ where Y is  an arbitrary Banach space. Is there some theorem which states that $M$ is continuous iff $x\mapsto \ell(Mx)$ is continous for all linear functionals $\ell:Y\rightarrow \mathbb{K}$ in $Y'$? or what does it mean? I posted a new try to a proof, can someone please confirm it or post another one?","I just did one exercise stating: Prove that the linear map $M: X \rightarrow C([0,1])$, is continuous iff for every $t\in[0,1]$, the rule $x\rightarrow (Mx)(t)$ defines a continuous linear functional on X. the next exercise stated: State, and prove a similar continuity criterion for linear maps $M:X\rightarrow Y$ where Y is  an arbitrary Banach space. Is there some theorem which states that $M$ is continuous iff $x\mapsto \ell(Mx)$ is continous for all linear functionals $\ell:Y\rightarrow \mathbb{K}$ in $Y'$? or what does it mean? I posted a new try to a proof, can someone please confirm it or post another one?",,"['functional-analysis', 'banach-spaces']"
41,Bounded sequences that form compact sets or not,Bounded sequences that form compact sets or not,,"a) Give an example of a bounded closed subset of    $$ A = \{(x_n) \in \ell^1: \sum_{n\geq1} x_n = 1\}$$   which is not compact. The metric we consider on A is induced by the normal norm on $\ell^1$. b) Show that the set    $$B = \{(x_n)\in \ell^1: \sum_{n\geq1} n|x_n| = 1\}$$   is compact in $\ell^1$. My try: a)The sequences in $\hat{A} = \{e_i = (0,\ldots 0 , 1 ,0 \ldots, ),\; \forall i \in \mathbb{N}\}$ has no converging subsequences. Is it a closed subset? It seems like it contains all its boundary points (A is not vector space). b) If we take a sequence $(x^k) \in B$ we also have $(x^k) \in \ell^\infty$. But since all elements in $\ell^\infty$ has subsequences that converges, this is true for  $(x^k)$? Edited: Davids method seems to work, both Im trying to get it to work with the following hint. Hint: You can use without proof the diagonalization process to conclude that every bounded sequence $(x_n) \in\ell^\infty$ has a subsequence $x^{n_k}$ that converges in each component. Moreover, sequences in $\ell^1$ are obviously bounded in their $\ell^1$ norm. So what I need to show is that the convergence of a sequence does not end up outside B?","a) Give an example of a bounded closed subset of    $$ A = \{(x_n) \in \ell^1: \sum_{n\geq1} x_n = 1\}$$   which is not compact. The metric we consider on A is induced by the normal norm on $\ell^1$. b) Show that the set    $$B = \{(x_n)\in \ell^1: \sum_{n\geq1} n|x_n| = 1\}$$   is compact in $\ell^1$. My try: a)The sequences in $\hat{A} = \{e_i = (0,\ldots 0 , 1 ,0 \ldots, ),\; \forall i \in \mathbb{N}\}$ has no converging subsequences. Is it a closed subset? It seems like it contains all its boundary points (A is not vector space). b) If we take a sequence $(x^k) \in B$ we also have $(x^k) \in \ell^\infty$. But since all elements in $\ell^\infty$ has subsequences that converges, this is true for  $(x^k)$? Edited: Davids method seems to work, both Im trying to get it to work with the following hint. Hint: You can use without proof the diagonalization process to conclude that every bounded sequence $(x_n) \in\ell^\infty$ has a subsequence $x^{n_k}$ that converges in each component. Moreover, sequences in $\ell^1$ are obviously bounded in their $\ell^1$ norm. So what I need to show is that the convergence of a sequence does not end up outside B?",,"['functional-analysis', 'compactness', 'lp-spaces']"
42,Countable family of Hilbert spaces is complete,Countable family of Hilbert spaces is complete,,"Let $H_1, H_2, \ldots, H_n$ be a countable family of Hilbert spaces. Let H be the set of tuples $x = (x_1, \ldots, x_n,\ldots)\in \prod_n H_n$ with the property that $$\|x \| ^2 =\sum_n \| x_n \| _{H_n}^2 <\infty.$$ Show that H is a Hilbert space. I have no problem showing that that it is a normed, but I have some problem with the completeness. If we define $x^*$ as the coordinatewise limit points. How do we then show that $$\| x^* \| <\infty$$ and  $$\lim_{k\rightarrow \infty} \| x^* - x_k \| \rightarrow 0 $$","Let $H_1, H_2, \ldots, H_n$ be a countable family of Hilbert spaces. Let H be the set of tuples $x = (x_1, \ldots, x_n,\ldots)\in \prod_n H_n$ with the property that $$\|x \| ^2 =\sum_n \| x_n \| _{H_n}^2 <\infty.$$ Show that H is a Hilbert space. I have no problem showing that that it is a normed, but I have some problem with the completeness. If we define $x^*$ as the coordinatewise limit points. How do we then show that $$\| x^* \| <\infty$$ and  $$\lim_{k\rightarrow \infty} \| x^* - x_k \| \rightarrow 0 $$",,"['functional-analysis', 'hilbert-spaces']"
43,Singular support of a tempered distribution is compact?,Singular support of a tempered distribution is compact?,,"I am reading Introduction to the Theory of Distributions by Friedlander and Joshi. As definition 8.6.1, they define the singular support of a tempered distribution $u$ to be the complement of {$x$: $u$ is $C^{\infty}$ on some neighborhood of $x$}. From this definition I cannot see why the singular support of a tempered distribution need to be compact. But in proof for Lemma 8.6.1, they begin by choosing a test function $\phi$ such that $\phi\equiv 1$ on the singular support of a given tempered distribution. Are they assuming that the singular support of a tempered distribution is compact? How can they do this? Thanks!","I am reading Introduction to the Theory of Distributions by Friedlander and Joshi. As definition 8.6.1, they define the singular support of a tempered distribution $u$ to be the complement of {$x$: $u$ is $C^{\infty}$ on some neighborhood of $x$}. From this definition I cannot see why the singular support of a tempered distribution need to be compact. But in proof for Lemma 8.6.1, they begin by choosing a test function $\phi$ such that $\phi\equiv 1$ on the singular support of a given tempered distribution. Are they assuming that the singular support of a tempered distribution is compact? How can they do this? Thanks!",,"['functional-analysis', 'partial-differential-equations', 'distribution-theory']"
44,"Is $x_n(t) = t^n$ for $n\ge 1$ dense in $L^1[0,1]$?",Is  for  dense in ?,"x_n(t) = t^n n\ge 1 L^1[0,1]","My question concerns the following problem Let $x_n(t) = t^n$ for $n\ge 1$. Is $\mathrm{span}(x_n; n\ge 1)$ dense in $L^1([0,1])$? By Weierstrass' approximation theorem, it suffices to check whether the constant function $1$ is contained in the $L^1$-closure of the linear span of the $x_n$. I think this is not the case, but I haven't found a proof so far. Some simple observations: I know that if $1$ is contained in the $L^1$-closure, then we can find a sequence of polynomials $p_n\in \mathrm{span}(x_n; n\ge 1)$ such that $p_n\to 1$ in $L^1$, almost everywhere and almost uniformly. Furthermore the sequence $q_n(x) = \int_0^x p_n(t) \, dt$ will converge uniformly to $x$ on $[0,1]$. I don't see how this helps, though.","My question concerns the following problem Let $x_n(t) = t^n$ for $n\ge 1$. Is $\mathrm{span}(x_n; n\ge 1)$ dense in $L^1([0,1])$? By Weierstrass' approximation theorem, it suffices to check whether the constant function $1$ is contained in the $L^1$-closure of the linear span of the $x_n$. I think this is not the case, but I haven't found a proof so far. Some simple observations: I know that if $1$ is contained in the $L^1$-closure, then we can find a sequence of polynomials $p_n\in \mathrm{span}(x_n; n\ge 1)$ such that $p_n\to 1$ in $L^1$, almost everywhere and almost uniformly. Furthermore the sequence $q_n(x) = \int_0^x p_n(t) \, dt$ will converge uniformly to $x$ on $[0,1]$. I don't see how this helps, though.",,"['real-analysis', 'functional-analysis', 'measure-theory']"
45,"For a reflexive Banach space, we have $\left\Vert x-y\right\Vert =\left\Vert x+F\right\Vert _{E/F}$","For a reflexive Banach space, we have",\left\Vert x-y\right\Vert =\left\Vert x+F\right\Vert _{E/F},"The problem is: Let E be a Banach space and $F\subset E$ be a closed linear subspace. Prove that for every $x \in E$ there exists $y \in F$ such that $\left\Vert x-y\right\Vert =\inf\left\{ \left\Vert x-z\right\Vert :\, z\in F\right\} =\left\Vert x+F\right\Vert _{E/F}$ . My efforts: By definition, we know that $\left\Vert x+F\right\Vert _{E/F}:=\inf\left\{ \left\Vert x+z\right\Vert :\, z\in F\right\} $ , and since $F$ is a linear subspace, we have that $\inf\left\{ \left\Vert x+z\right\Vert :\, z\in F\right\} =\inf\left\{ \left\Vert x-z\right\Vert :\, z\in F\right\} $ . My idea: We know that for every bounded sequence in a reflexive Banach space, there exists a weakly convergent subsequence. My question: How can I now use the weak convergence to prove the first equality of my statement? Have I done any mistake so far?","The problem is: Let E be a Banach space and be a closed linear subspace. Prove that for every there exists such that . My efforts: By definition, we know that , and since is a linear subspace, we have that . My idea: We know that for every bounded sequence in a reflexive Banach space, there exists a weakly convergent subsequence. My question: How can I now use the weak convergence to prove the first equality of my statement? Have I done any mistake so far?","F\subset E x \in E y \in F \left\Vert x-y\right\Vert =\inf\left\{ \left\Vert x-z\right\Vert :\, z\in F\right\} =\left\Vert x+F\right\Vert _{E/F} \left\Vert x+F\right\Vert _{E/F}:=\inf\left\{ \left\Vert x+z\right\Vert :\, z\in F\right\}  F \inf\left\{ \left\Vert x+z\right\Vert :\, z\in F\right\} =\inf\left\{ \left\Vert x-z\right\Vert :\, z\in F\right\} ","['analysis', 'functional-analysis', 'banach-spaces']"
46,The reflexivity of the product $L^p(I)\times L^p(I)$,The reflexivity of the product,L^p(I)\times L^p(I),"I am starting to read about the Sobolev spaces $W^{1,p}(I),$ where $I$ is an open interval in $\mathbb{R}.$ In order to establish  the reflexivity of $W^{1,p}(I)$ for $p\in ]1,\infty[,$ I need the reflexivity of $L^p(I)\times L^p(I).$ My question is: how to derive the reflexivity of $L^p(I)\times L^p(I)$ starting from the reflexivity of $L^p(I)?$","I am starting to read about the Sobolev spaces $W^{1,p}(I),$ where $I$ is an open interval in $\mathbb{R}.$ In order to establish  the reflexivity of $W^{1,p}(I)$ for $p\in ]1,\infty[,$ I need the reflexivity of $L^p(I)\times L^p(I).$ My question is: how to derive the reflexivity of $L^p(I)\times L^p(I)$ starting from the reflexivity of $L^p(I)?$",,"['functional-analysis', 'banach-spaces', 'sobolev-spaces']"
47,Subset of sequence space closed,Subset of sequence space closed,,"Is the set $E:=\{(x_n)_{n\in \mathbb{N}} \in \ell^{\infty}\ |\; x_i \in \mathbb{C}, \lim_{n \rightarrow \infty } x_n = 0 \}$ closed in $\ell^{\infty}$ equipped with $\lVert (x_n)_{n\in \mathbb{N}} \lVert_{\infty}=\sup_{n\in\mathbb{N}} |x_n|$? I've come to the following solution: Let $(x_n)_{n\in\mathbb{N}} \in \ell^{\infty}\setminus E$. So $\exists\, \varepsilon >0$ such that $\forall N \in \mathbb{N} \quad \exists m>N$ with $|x_m|>\varepsilon$. So for $(y_n)_{n\in\mathbb{N}} \in B_{\epsilon /2}((x_n)_{n\in \mathbb{N}})\quad \forall N\in\mathbb{N}\quad \exists m>N$ with $|y_m|>\epsilon /2$ and hence $(y_n)_{n\in\mathbb{N}} \in\ell^{\infty}\backslash E$. So $\ell^{\infty}\backslash E$ is open and $E$ is closed. Is this solution correct?","Is the set $E:=\{(x_n)_{n\in \mathbb{N}} \in \ell^{\infty}\ |\; x_i \in \mathbb{C}, \lim_{n \rightarrow \infty } x_n = 0 \}$ closed in $\ell^{\infty}$ equipped with $\lVert (x_n)_{n\in \mathbb{N}} \lVert_{\infty}=\sup_{n\in\mathbb{N}} |x_n|$? I've come to the following solution: Let $(x_n)_{n\in\mathbb{N}} \in \ell^{\infty}\setminus E$. So $\exists\, \varepsilon >0$ such that $\forall N \in \mathbb{N} \quad \exists m>N$ with $|x_m|>\varepsilon$. So for $(y_n)_{n\in\mathbb{N}} \in B_{\epsilon /2}((x_n)_{n\in \mathbb{N}})\quad \forall N\in\mathbb{N}\quad \exists m>N$ with $|y_m|>\epsilon /2$ and hence $(y_n)_{n\in\mathbb{N}} \in\ell^{\infty}\backslash E$. So $\ell^{\infty}\backslash E$ is open and $E$ is closed. Is this solution correct?",,['functional-analysis']
48,There exists an isometric embedding,There exists an isometric embedding,,"Let $W$ be a closed linear subspace of a normed vector space $V$. Let $i_V: V \to V^{**}$. and $i_W: W \to W^{**}$ be the canonical embeddings of V and W into their second duals. Prove that there exists an isometric embedding $\Phi: W^{**} \to V^{**}$.  Show that $\Phi(W^{**}) = (W^{\perp})^{\perp}$. Can you help me to prove this? $(W^{\perp})^{\perp}=\{\Gamma \in V^* | F(f) = 0 \quad \text{for all} \quad f \in V^* s.t. f(W)=0\}$ I think I have to use Hahn Banach theorem, but I don't know how.","Let $W$ be a closed linear subspace of a normed vector space $V$. Let $i_V: V \to V^{**}$. and $i_W: W \to W^{**}$ be the canonical embeddings of V and W into their second duals. Prove that there exists an isometric embedding $\Phi: W^{**} \to V^{**}$.  Show that $\Phi(W^{**}) = (W^{\perp})^{\perp}$. Can you help me to prove this? $(W^{\perp})^{\perp}=\{\Gamma \in V^* | F(f) = 0 \quad \text{for all} \quad f \in V^* s.t. f(W)=0\}$ I think I have to use Hahn Banach theorem, but I don't know how.",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
49,Finding the derivative of the norm,Finding the derivative of the norm,,Consider function from Hilbert space to real numbers. $F(x)=\| Ax\|$. My question how to find it's derivative $F'(x)$.,Consider function from Hilbert space to real numbers. $F(x)=\| Ax\|$. My question how to find it's derivative $F'(x)$.,,"['functional-analysis', 'derivatives']"
50,Weak convergence as convergence of matrix elements,Weak convergence as convergence of matrix elements,,"Let $H$ be a Hilbert space with orthonormal basis $(e_h)_{h \in \mathbb{N}}$ and let $(A_n)_{n \in \mathbb{N}}$ and $A$ be bounded linear operators. We say that $A_n$ converges weakly to $A$ if $$\forall \xi, \eta \in H, \quad (\eta, A_n\xi)\to (\eta, A\xi).$$ Question Is it true that $A_n$ converges weakly to $A$ if and only if $$\forall h, k \in \mathbb{N},\quad (e_h, A_n e_k) \to (e_h, Ae_k)?$$ Indeed, I'm wondering if it is correct to think at weak convergence as convergence of the matrix entries associated to the operators $A_n$ and $A$. Thank you.","Let $H$ be a Hilbert space with orthonormal basis $(e_h)_{h \in \mathbb{N}}$ and let $(A_n)_{n \in \mathbb{N}}$ and $A$ be bounded linear operators. We say that $A_n$ converges weakly to $A$ if $$\forall \xi, \eta \in H, \quad (\eta, A_n\xi)\to (\eta, A\xi).$$ Question Is it true that $A_n$ converges weakly to $A$ if and only if $$\forall h, k \in \mathbb{N},\quad (e_h, A_n e_k) \to (e_h, Ae_k)?$$ Indeed, I'm wondering if it is correct to think at weak convergence as convergence of the matrix entries associated to the operators $A_n$ and $A$. Thank you.",,"['functional-analysis', 'hilbert-spaces', 'operator-theory']"
51,How to solve Fredholm integral equation of the second kind? ($f(x) - \lambda\int\limits_0^1 9xtf(t) dt = ax^2 - 4x^2$),How to solve Fredholm integral equation of the second kind? (),f(x) - \lambda\int\limits_0^1 9xtf(t) dt = ax^2 - 4x^2,"I have an equation : $\ f(x) - \lambda\int\limits_0^1 9xtf(t) dt = ax^2 - 4x^2\ $ in $\ L_2[0,1]\ $ space. And I want to understand how to solve it, not just obtain an answer.","I have an equation : $\ f(x) - \lambda\int\limits_0^1 9xtf(t) dt = ax^2 - 4x^2\ $ in $\ L_2[0,1]\ $ space. And I want to understand how to solve it, not just obtain an answer.",,"['functional-analysis', 'integral-equations']"
52,"Does Uniform Boundedness in the Sobolev Space $W^{1,2}$ and Convergence in $L^p$ $(1 \leq p < 6)$ Imply Convergence in $L^6$?",Does Uniform Boundedness in the Sobolev Space  and Convergence in   Imply Convergence in ?,"W^{1,2} L^p (1 \leq p < 6) L^6","Let $B$ denote the open unit ball in $\mathbb{R}^3$.  I want to either prove or disprove that a sequence of functions $u_m$ in the Sobolev space $W^{1,2}(B)$ which is uniformly bounded in the $W^{1,2}(B)$ norm and which is convergent in $L^p(B)$ for all $1 \leq p < 6$ must be convergent in $L^6(B)$. Can someone please point me in the right direction? I know (cf. Chapter 5 of Evans PDE book) that the bound  $$ \| u \|_{L^q(U)} \leq C(k,p,n,U) \| u \|_{W^{k,p}(U)} $$ holds when $U$ is a subset of $\mathbb{R}^n$ having smooth boundary, $u \in W^{k,p}$, $k < \frac{n}{p}$, and $\frac{1}{q} = \frac{1}{p} - \frac{k}{n}$.  The constant $C = C(k,p,n,U)$ is independent of $u$. It follows from this bound that the $u_m$ are uniformly bounded in $L^6(B)$. Since $W^{1,2}(B)$ is a Hilbert Space, uniform boundedness of $u_m$ in $W^{1,2}(B)$ also implies existence of a subsequence $u_{m_j}$ that converges weakly in $W^{1,2}(B)$, hence weakly in $L^6(B)$. Thanks!","Let $B$ denote the open unit ball in $\mathbb{R}^3$.  I want to either prove or disprove that a sequence of functions $u_m$ in the Sobolev space $W^{1,2}(B)$ which is uniformly bounded in the $W^{1,2}(B)$ norm and which is convergent in $L^p(B)$ for all $1 \leq p < 6$ must be convergent in $L^6(B)$. Can someone please point me in the right direction? I know (cf. Chapter 5 of Evans PDE book) that the bound  $$ \| u \|_{L^q(U)} \leq C(k,p,n,U) \| u \|_{W^{k,p}(U)} $$ holds when $U$ is a subset of $\mathbb{R}^n$ having smooth boundary, $u \in W^{k,p}$, $k < \frac{n}{p}$, and $\frac{1}{q} = \frac{1}{p} - \frac{k}{n}$.  The constant $C = C(k,p,n,U)$ is independent of $u$. It follows from this bound that the $u_m$ are uniformly bounded in $L^6(B)$. Since $W^{1,2}(B)$ is a Hilbert Space, uniform boundedness of $u_m$ in $W^{1,2}(B)$ also implies existence of a subsequence $u_{m_j}$ that converges weakly in $W^{1,2}(B)$, hence weakly in $L^6(B)$. Thanks!",,"['analysis', 'functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
53,Folland & Functional Analysis,Folland & Functional Analysis,,"I'm reading Folland's Real Analysis to learn some basic functional analysis. I read through his section Normed Vector Spaces and could make my way through most of the exercises I attempted. I am reading through the next section on Linear Functionals (dual spaces, Hahn-Banach) and am finding the exercises very difficult. I had glanced through Folland's sections on measure theory and found the exercises rather easy; I though this book was at an appropriate level. I know Folland is more of a general analysis book; I just want to learn some of the basics (the cornerstone theorems, Hilbert spaces, Lp spaces) and so I did not think it necessary to delve into a specialized book. Is there a step down from Folland that still covers this material thoroughly-but-not-too-thoroughly? Or does anyone have any recommendation for a place to find easier problems to get myself started before tackling what I think are harder ones in Folland? The books I have seen seem to be beyond my level (e.g. Conway) or more applied books that may skip out on some of the theory (e.g. Luenberger). Perhaps my problem is just that I do not have much of an intuition with this material! Thanks.","I'm reading Folland's Real Analysis to learn some basic functional analysis. I read through his section Normed Vector Spaces and could make my way through most of the exercises I attempted. I am reading through the next section on Linear Functionals (dual spaces, Hahn-Banach) and am finding the exercises very difficult. I had glanced through Folland's sections on measure theory and found the exercises rather easy; I though this book was at an appropriate level. I know Folland is more of a general analysis book; I just want to learn some of the basics (the cornerstone theorems, Hilbert spaces, Lp spaces) and so I did not think it necessary to delve into a specialized book. Is there a step down from Folland that still covers this material thoroughly-but-not-too-thoroughly? Or does anyone have any recommendation for a place to find easier problems to get myself started before tackling what I think are harder ones in Folland? The books I have seen seem to be beyond my level (e.g. Conway) or more applied books that may skip out on some of the theory (e.g. Luenberger). Perhaps my problem is just that I do not have much of an intuition with this material! Thanks.",,"['reference-request', 'soft-question', 'functional-analysis']"
54,Symbol for twice differentiable functions,Symbol for twice differentiable functions,,Is there a symbol for the set of twice differentiable functions (2nd derivative not necessarily continuous)? I believe the symbol for twice continuously differentiable functions is $C^2(\mathbb F)$? Thanks,Is there a symbol for the set of twice differentiable functions (2nd derivative not necessarily continuous)? I believe the symbol for twice continuously differentiable functions is $C^2(\mathbb F)$? Thanks,,"['functional-analysis', 'notation']"
55,subset relations among Sobolev spaces and their duals,subset relations among Sobolev spaces and their duals,,"This may be a rather dense question, but I would nevertheless be grateful for some guidance. The question has to do with the Sobolev spaces $H^m (\Omega)$ on an open bounded domain $\Omega$ of $\mathbb{R}^n$, where $m \geq 0$ is integer.  These are Hilbert spaces; thus the Riesz representation theorem tells us that there is a one-to-one and onto correspondence between elements of $H^m (\Omega)$ and elements of its dual $H^{-m} (\Omega)$.  Yet, we also have the inclusion property $H^{m} (\Omega) \subset L_2 (\Omega) \subset H^{-m} (\Omega)$ (e.g. Oden and Reddy, Intro. to the Mathematical Theory of Finite Elements, p. 108).  How can both of these hold?  In other words, how can there be a one-to-one and onto correspondence between $H^m (\Omega)$ and $H^{-m} (\Omega)$, and yet the former is a strict subset of the latter?","This may be a rather dense question, but I would nevertheless be grateful for some guidance. The question has to do with the Sobolev spaces $H^m (\Omega)$ on an open bounded domain $\Omega$ of $\mathbb{R}^n$, where $m \geq 0$ is integer.  These are Hilbert spaces; thus the Riesz representation theorem tells us that there is a one-to-one and onto correspondence between elements of $H^m (\Omega)$ and elements of its dual $H^{-m} (\Omega)$.  Yet, we also have the inclusion property $H^{m} (\Omega) \subset L_2 (\Omega) \subset H^{-m} (\Omega)$ (e.g. Oden and Reddy, Intro. to the Mathematical Theory of Finite Elements, p. 108).  How can both of these hold?  In other words, how can there be a one-to-one and onto correspondence between $H^m (\Omega)$ and $H^{-m} (\Omega)$, and yet the former is a strict subset of the latter?",,['functional-analysis']
56,Addition of Unbounded Operators,Addition of Unbounded Operators,,"Let $H$ be a (separable complex) Hilbert space and let $A$ and $B$ be two densely-defined, maximally-defined linear operators on $H$ with domains $D(A)$ and $D(B)$ respectively.  (By maximall-defined, I mean that $A$ and $B$ admit no extensions).  Then, we can define the operator $A+B$ on $D(A)\cap D(B)$, however, in general, the operator $\left( D(A)\cap D(B),A+B\right)$ will not be maximally-defined.  The question is:  does this operator admit a unique maximal extension? My conjecture is that the answer is no, but I would absolutely love for the answer to be yes. Any ideas? Thanks again!","Let $H$ be a (separable complex) Hilbert space and let $A$ and $B$ be two densely-defined, maximally-defined linear operators on $H$ with domains $D(A)$ and $D(B)$ respectively.  (By maximall-defined, I mean that $A$ and $B$ admit no extensions).  Then, we can define the operator $A+B$ on $D(A)\cap D(B)$, however, in general, the operator $\left( D(A)\cap D(B),A+B\right)$ will not be maximally-defined.  The question is:  does this operator admit a unique maximal extension? My conjecture is that the answer is no, but I would absolutely love for the answer to be yes. Any ideas? Thanks again!",,"['functional-analysis', 'hilbert-spaces', 'operator-theory', 'inner-products']"
57,Finding eigenfunctions and eigenvalues,Finding eigenfunctions and eigenvalues,,"Let $K$ be the integral operator defined by $$ (Kf)(x)=\int_0^1 u(x)v(y)f(y) dy $$ for some continuous functions $u,v$ in the Hilbert space with inner product $\langle f,g \rangle = \int_0^1 f(x)^* g(x) dx$ on $(0,1)$. I want to find the eigenfunctions and eigenvalues corresponding to $K$. (this is problem 3.4 in http://www.mat.univie.ac.at/~gerald/ftp/book-fa/ ) The exercise is from a chapter about compact symmetric operators (which this operator is), but it only contains existence theorems. If I could get some helpful hints on how to get started, I'd be thankful. (I have a suspicion this is easier than it looks) Thanks in advance.","Let $K$ be the integral operator defined by $$ (Kf)(x)=\int_0^1 u(x)v(y)f(y) dy $$ for some continuous functions $u,v$ in the Hilbert space with inner product $\langle f,g \rangle = \int_0^1 f(x)^* g(x) dx$ on $(0,1)$. I want to find the eigenfunctions and eigenvalues corresponding to $K$. (this is problem 3.4 in http://www.mat.univie.ac.at/~gerald/ftp/book-fa/ ) The exercise is from a chapter about compact symmetric operators (which this operator is), but it only contains existence theorems. If I could get some helpful hints on how to get started, I'd be thankful. (I have a suspicion this is easier than it looks) Thanks in advance.",,"['functional-analysis', 'integral-equations']"
58,Ergodic Recurrence,Ergodic Recurrence,,"My solution concerning a problem about Ergodic Recurrence requires me to prove that $\|P_T 1_B\| > 0$. Where $P_T$ is the projection onto the space $I := \{f \in L^2 : f \circ T = f\}$, $T$ is a measure preserving mapping (so for all $B$ measurable $\mu(T^{-1} B) = \mu(B)$) and $B$ is of positive measure. Can someone hint my why $\|P_T 1_B\|$ should be strictly positive? If $1_B$ would be in $I$ then I would have that $T^{-1} B = B$ which is probably not the case.","My solution concerning a problem about Ergodic Recurrence requires me to prove that $\|P_T 1_B\| > 0$. Where $P_T$ is the projection onto the space $I := \{f \in L^2 : f \circ T = f\}$, $T$ is a measure preserving mapping (so for all $B$ measurable $\mu(T^{-1} B) = \mu(B)$) and $B$ is of positive measure. Can someone hint my why $\|P_T 1_B\|$ should be strictly positive? If $1_B$ would be in $I$ then I would have that $T^{-1} B = B$ which is probably not the case.",,"['functional-analysis', 'ergodic-theory']"
59,Is there a notion of basis for Banach spaces?,Is there a notion of basis for Banach spaces?,,Consider the Banach space $\ell^1(\mathbb N)$. The sequence $(e_n)_{n\in\mathbb N}$ feels like a kind of basis because every element $a\in\ell^1(\mathbb N)$ can be written as an absolutely convergent infinite linear combination $\sum_{n\in\mathbb N}a(n)e_n$ in a unique way. (Here $e_n$ denotes the vector whose $n$th entry is 1 and all of whose other entries vanish.) The same is true for the Banach space $c_0(\mathbb N)$. Is the above property of the sequence $(e_n)_{n\in\mathbb N}$ appropriate in order to abstractly define a basis of a Banach space? Has this been considered?,Consider the Banach space $\ell^1(\mathbb N)$. The sequence $(e_n)_{n\in\mathbb N}$ feels like a kind of basis because every element $a\in\ell^1(\mathbb N)$ can be written as an absolutely convergent infinite linear combination $\sum_{n\in\mathbb N}a(n)e_n$ in a unique way. (Here $e_n$ denotes the vector whose $n$th entry is 1 and all of whose other entries vanish.) The same is true for the Banach space $c_0(\mathbb N)$. Is the above property of the sequence $(e_n)_{n\in\mathbb N}$ appropriate in order to abstractly define a basis of a Banach space? Has this been considered?,,"['functional-analysis', 'banach-spaces']"
60,$L^2$-ness of the finite difference operator,-ness of the finite difference operator,L^2,"Is there a proof of the fact that the operator $\mathfrak{D}$ defined by $\mathfrak{D}[f](x,y):=\dfrac{f(x)-f(y)}{x-y}$ is continuous from $H^n(\mathbb{R})$ to $H^m(\mathbb{R}^2)$ or even $L^2(\mathbb{R}^2)$ assuming that $n$ is sufficiently big (i guess $n\geq m+1$ would suffice) ? Some insights why there exists $C>0$ such that for all $f\in H^n(\mathbb{R})$ , $\|\mathfrak{D}[f]\|_{L^2(\mathbb{R}^2)}\leq C \|f\|_{H^1(\mathbb{R})}$ might be very useful to guess how to show the result for derivatives of $\mathfrak{D}[f]$ . Also some formula for the derivatives of $\mathfrak{D}[f]$ hold, it basically has the form of a sum of Taylor sums divided by $(x-y)^{\alpha-j}$ where $\alpha=m_1+m_2+1$ where $m_1$ (resp. $m_2$ ) is the order of the derivative with respect to $x$ (resp. $y$ ).","Is there a proof of the fact that the operator defined by is continuous from to or even assuming that is sufficiently big (i guess would suffice) ? Some insights why there exists such that for all , might be very useful to guess how to show the result for derivatives of . Also some formula for the derivatives of hold, it basically has the form of a sum of Taylor sums divided by where where (resp. ) is the order of the derivative with respect to (resp. ).","\mathfrak{D} \mathfrak{D}[f](x,y):=\dfrac{f(x)-f(y)}{x-y} H^n(\mathbb{R}) H^m(\mathbb{R}^2) L^2(\mathbb{R}^2) n n\geq m+1 C>0 f\in H^n(\mathbb{R}) \|\mathfrak{D}[f]\|_{L^2(\mathbb{R}^2)}\leq C \|f\|_{H^1(\mathbb{R})} \mathfrak{D}[f] \mathfrak{D}[f] (x-y)^{\alpha-j} \alpha=m_1+m_2+1 m_1 m_2 x y","['functional-analysis', 'normed-spaces', 'operator-theory', 'compact-operators']"
61,Completion of operator space,Completion of operator space,,"Definition : An (abstract) operator space is a linear space $X$ together with a sequence $\{\|\cdot\|_n\}_{n=1}^\infty$ of norms such that $\|x\oplus y\|_{m+n}= \max\{\|x\|_m, \|y\|_n\}$ for $x\in M_m(X), y \in M_n(X)$ . $\|\alpha x \beta\|_n \le \|\alpha\|\|x\|_m\|\beta\|$ for $\alpha \in M_{n,m}(\mathbb{C}), x \in M_m(X), \beta \in M_{m,n}(\mathbb{C})$ . I now want to understand what the completion $Y$ of the operator space $X$ is, in a way that $Y$ becomes an operator space. The first step should be to begin to define $Y$ to be the Banach space completion of $X$ . To define an operator space structure on $Y$ , we still require norms on $$M_2(Y), M_3(Y), M_4(Y), \dots$$ and it is not clear to me how to do this with the definition of abstract operator spaces. If we use the concrete operator space approach (Ruan's theorem), then we can choose a Hilbert space $H$ and a complete isometry $$\sigma: X \to B(H).$$ We can then define $Y =  \overline{\sigma(X)}\subseteq B(H)$ which shows that the Banach space completion of $X$ carries the canonical structure of an operator space (of course, it should be shown that this does not depend on the choice of representation and stuff like that). I would like to know if there is a way to avoid Ruan's theorem? To illustrate where such a situation as in this question may happen: if $X,Y$ are operator spaces, then one can define norms on $M_n(X \odot Y)$ (where $X\odot Y$ is the algebraic tensor product) which satisfy the two requirements above. Thus, $X\odot Y$ becomes an abstract operator space. But then one defines the projective tensor product $X\hat{\otimes} Y$ to be the completion of this space (whatever this means).","Definition : An (abstract) operator space is a linear space together with a sequence of norms such that for . for . I now want to understand what the completion of the operator space is, in a way that becomes an operator space. The first step should be to begin to define to be the Banach space completion of . To define an operator space structure on , we still require norms on and it is not clear to me how to do this with the definition of abstract operator spaces. If we use the concrete operator space approach (Ruan's theorem), then we can choose a Hilbert space and a complete isometry We can then define which shows that the Banach space completion of carries the canonical structure of an operator space (of course, it should be shown that this does not depend on the choice of representation and stuff like that). I would like to know if there is a way to avoid Ruan's theorem? To illustrate where such a situation as in this question may happen: if are operator spaces, then one can define norms on (where is the algebraic tensor product) which satisfy the two requirements above. Thus, becomes an abstract operator space. But then one defines the projective tensor product to be the completion of this space (whatever this means).","X \{\|\cdot\|_n\}_{n=1}^\infty \|x\oplus y\|_{m+n}= \max\{\|x\|_m, \|y\|_n\} x\in M_m(X), y \in M_n(X) \|\alpha x \beta\|_n \le \|\alpha\|\|x\|_m\|\beta\| \alpha \in M_{n,m}(\mathbb{C}), x \in M_m(X), \beta \in M_{m,n}(\mathbb{C}) Y X Y Y X Y M_2(Y), M_3(Y), M_4(Y), \dots H \sigma: X \to B(H). Y =  \overline{\sigma(X)}\subseteq B(H) X X,Y M_n(X \odot Y) X\odot Y X\odot Y X\hat{\otimes} Y","['functional-analysis', 'operator-theory', 'complete-spaces', 'operator-spaces']"
62,Why does $C^\infty(\Omega)$ have the Heine-Borel property?,Why does  have the Heine-Borel property?,C^\infty(\Omega),"$ \let\uto\rightrightarrows \let\ii\infty \let\W\Omega \let\a\alpha \let\b\beta \let\e\varepsilon \let\d\delta \let\sbe\subseteq $ I'm struggling to understand the examples at the end of the first chapter of Rudin's Functional Analysis . I will focus the post on $C^\ii(\W)$ as hopefully getting a grasp of $C^\ii(\W)$ will clarify the spaces $C(\W)$ and $\mathcal{D}_K$ . An original post with all my questions on $C^\ii(\W)$ was closed due to lack of focus, so on the current post I will focus on proving $C^\ii(\W)$ has the Heine-Borel property. Below I try to to fill in the gaps in the proof given. I then write my doubts on the proofs and include pictures of the relevant book excerpts. Theorem: $C^\ii(\W)$ has the Heine-Borel property. Proof: let $E\sbe C^\ii(\W)$ be closed and bounded. We wish to show $E$ is compact. a) There are numbers $M_N < \ii$ such that $$p_N(f) \le M_N \iff  \sup_{\substack{x\in K_N\\ |\a|\le N}} \{|D^\a f(x)|\} \le M_N.$$ b) Fix $\b$ and $N$ with $|\b|\le N-1$ . The family $\mathcal{F}_{\b,N}$ of functions $$\{ D^\b f : f\in E\}$$ is equicontinuous on $K_{N-1}$ i.e. for any $\e>0$ there is a $\d>0$ such that $$d(x,y)< \d \implies |D^\b f(x) - D^\b f(y)| < \e$$ for any $x,y\in K_{N-1}$ and $D^\b f\in\mathcal{F}_{\b,N}$ . c) Since $\mathcal{F}_{\b,N}$ is pointwise bounded and equicontinuous on $K_{N-1}$ , Ascoli's Theorem (and its corollary) implies that $\mathcal{F}_{\b,N}$ is compact and that every sequence in $\mathcal{F}_{\b,N}$ contains a uniformly convergent subsequence. Therefore $E$ is compact. My questions: Firstly: are my outlines of Rudin's proof correct? If at any point I'm deviating from the argument in the book, please let me know. b) Why is $\mathcal{F}_{\b,N}$ equicontinuous on $K_{N-1}$ ? c) While I understand the rest of the paragraph, I do not see why the last sentence ""Therefore $E$ is compact"" follows. The main passage in question (regarding $C^\ii(\W)$ : The main results used:","I'm struggling to understand the examples at the end of the first chapter of Rudin's Functional Analysis . I will focus the post on as hopefully getting a grasp of will clarify the spaces and . An original post with all my questions on was closed due to lack of focus, so on the current post I will focus on proving has the Heine-Borel property. Below I try to to fill in the gaps in the proof given. I then write my doubts on the proofs and include pictures of the relevant book excerpts. Theorem: has the Heine-Borel property. Proof: let be closed and bounded. We wish to show is compact. a) There are numbers such that b) Fix and with . The family of functions is equicontinuous on i.e. for any there is a such that for any and . c) Since is pointwise bounded and equicontinuous on , Ascoli's Theorem (and its corollary) implies that is compact and that every sequence in contains a uniformly convergent subsequence. Therefore is compact. My questions: Firstly: are my outlines of Rudin's proof correct? If at any point I'm deviating from the argument in the book, please let me know. b) Why is equicontinuous on ? c) While I understand the rest of the paragraph, I do not see why the last sentence ""Therefore is compact"" follows. The main passage in question (regarding : The main results used:","
\let\uto\rightrightarrows
\let\ii\infty
\let\W\Omega
\let\a\alpha
\let\b\beta
\let\e\varepsilon
\let\d\delta
\let\sbe\subseteq
 C^\ii(\W) C^\ii(\W) C(\W) \mathcal{D}_K C^\ii(\W) C^\ii(\W) C^\ii(\W) E\sbe C^\ii(\W) E M_N < \ii p_N(f) \le M_N \iff
 \sup_{\substack{x\in K_N\\ |\a|\le N}} \{|D^\a f(x)|\} \le M_N. \b N |\b|\le N-1 \mathcal{F}_{\b,N} \{ D^\b f : f\in E\} K_{N-1} \e>0 \d>0 d(x,y)< \d \implies |D^\b f(x) - D^\b f(y)| < \e x,y\in K_{N-1} D^\b f\in\mathcal{F}_{\b,N} \mathcal{F}_{\b,N} K_{N-1} \mathcal{F}_{\b,N} \mathcal{F}_{\b,N} E \mathcal{F}_{\b,N} K_{N-1} E C^\ii(\W)","['functional-analysis', 'analysis', 'solution-verification', 'proof-explanation', 'topological-vector-spaces']"
63,Duistermaat and Kolk: definition of separating family of seminorms,Duistermaat and Kolk: definition of separating family of seminorms,,"I am reading the book ""Distributions: Theory and Applications"" by Duistermaat and Kolk. In chapter 8, Definition 8.5., they say that a family of semi-norms $\mathcal{N}$ is separating if For every $x\neq 0$ , there exists an $n\in \mathcal{N}$ such that $n(x)\neq 0$ . For every $n,m \in \mathcal{N}$ , there exists a $p\in \mathcal{N}$ , such that $n(x),m(x)\le p(x)$ , for all $x$ . However, in every other source I looked at, only the first requirement was stated. Do the authors include the second requirement because given a family of semi-norms that satisfies only the first, we can always extend it to one that also satisfies the second, by say including all finite sums?","I am reading the book ""Distributions: Theory and Applications"" by Duistermaat and Kolk. In chapter 8, Definition 8.5., they say that a family of semi-norms is separating if For every , there exists an such that . For every , there exists a , such that , for all . However, in every other source I looked at, only the first requirement was stated. Do the authors include the second requirement because given a family of semi-norms that satisfies only the first, we can always extend it to one that also satisfies the second, by say including all finite sums?","\mathcal{N} x\neq 0 n\in \mathcal{N} n(x)\neq 0 n,m \in \mathcal{N} p\in \mathcal{N} n(x),m(x)\le p(x) x","['functional-analysis', 'distribution-theory']"
64,Markov processes associated with generators being differential operators of higher order $n>2$,Markov processes associated with generators being differential operators of higher order,n>2,"Let $P$ be a $C_0$ -semigroup on the space of all bounded Borel functions on $\Bbb R^n$ with $P_t1= 1$ for all $t$ . It corresponds to a continuous time Markov process $X$ such that $\mathbb E(f(X_t)|X_0 = x) = P_tf(x)$ . A generator of $P$ is given by $$ Af(x):=\lim_{t\to 0}\frac{P_tf(x) - f(x)}t. $$ From what I know if $A$ is a first order differential operator, $X$ is a solution of an ODE if $A$ is a second order differential operator, $X$ is an Ito diffusion if $A$ has an integral term, $X$ has jumps. Yet, I have never saw an example of what happens when $A$ is a differential operator of an order higher than $2$ . Which kind of stochastic process will that correspond to? I'd be happy to see an example for $A = \frac{d^3}{d^3x}$ and $A = \frac{d^4}{d^4x}$ .","Let be a -semigroup on the space of all bounded Borel functions on with for all . It corresponds to a continuous time Markov process such that . A generator of is given by From what I know if is a first order differential operator, is a solution of an ODE if is a second order differential operator, is an Ito diffusion if has an integral term, has jumps. Yet, I have never saw an example of what happens when is a differential operator of an order higher than . Which kind of stochastic process will that correspond to? I'd be happy to see an example for and .","P C_0 \Bbb R^n P_t1= 1 t X \mathbb E(f(X_t)|X_0 = x) = P_tf(x) P 
Af(x):=\lim_{t\to 0}\frac{P_tf(x) - f(x)}t.
 A X A X A X A 2 A = \frac{d^3}{d^3x} A = \frac{d^4}{d^4x}","['functional-analysis', 'probability-theory', 'stochastic-processes']"
65,Continuous functions in Sobolev spaces,Continuous functions in Sobolev spaces,,"Let $W^{k,p} (\Omega)$ be a Sobolev space, $\Omega \subset \mathbb{R}^N$ . Formally, $W^{k,p}(\Omega)$ consists of equivalence classes of functions with finite Sobolev norm. Two functions, $f$ and $g$ , are said to be equivalent ('equal') if $\Vert f-g \Vert_{W^{k,p}} =0$ . In many proofs concerning Sobolev functions, say, Poincaré inequality, one first shows the claim for smooth functions and then generalises by using the fact that smooth functions $C_0^{\infty} (\Omega)$ are dense in $W_0^{1,2}(\Omega)$ . However, it is unclear to me what is meant by writing $u \in C_0^{\infty}(\Omega)$ . Does it mean that $u$ is equivalent to a smooth function (in the $W^{1,2}$ sense) or that $u$ is itself a smooth function? One proof for Poincaré inequality on $\Omega:=(a, b)\subset \mathbb{R}$ starts by writing the value of $u \in C_0^{\infty}(a, b)$ as $$ u(x)=\int_a^x u dx+u(a), $$ however, if $u$ is considered to be a Sobolev function, one cannot talk about its point wise values, $u(a)$ in particular. Or is it some kind of an agreement that $u(a)$ is the value of the smooth function to which $u$ is equivalent (in $W^{1,2}$ )? Another confusion arises when talking about the trace operator. In the Wiki page , it is said that the trace $T: W^{1,p}(\Omega) \rightarrow L^p (\partial \Omega)$ is such that $Tu = u\mid_{\partial \Omega}$ for any $u \in W^{1,p}(\Omega) \cap C(\overline{\Omega})$ . Again, $W^{1,p}$ consist of equivalence classes whereas $C(\overline{\Omega})$ consists of functions. So does the intersection mean functions with finite Sobolev norm which are equivalent to some continuous function? And is $u\mid_{\partial \Omega}$ the boundary function of $u$ , or the set of functions equivalent to it?","Let be a Sobolev space, . Formally, consists of equivalence classes of functions with finite Sobolev norm. Two functions, and , are said to be equivalent ('equal') if . In many proofs concerning Sobolev functions, say, Poincaré inequality, one first shows the claim for smooth functions and then generalises by using the fact that smooth functions are dense in . However, it is unclear to me what is meant by writing . Does it mean that is equivalent to a smooth function (in the sense) or that is itself a smooth function? One proof for Poincaré inequality on starts by writing the value of as however, if is considered to be a Sobolev function, one cannot talk about its point wise values, in particular. Or is it some kind of an agreement that is the value of the smooth function to which is equivalent (in )? Another confusion arises when talking about the trace operator. In the Wiki page , it is said that the trace is such that for any . Again, consist of equivalence classes whereas consists of functions. So does the intersection mean functions with finite Sobolev norm which are equivalent to some continuous function? And is the boundary function of , or the set of functions equivalent to it?","W^{k,p} (\Omega) \Omega \subset \mathbb{R}^N W^{k,p}(\Omega) f g \Vert f-g \Vert_{W^{k,p}} =0 C_0^{\infty} (\Omega) W_0^{1,2}(\Omega) u \in C_0^{\infty}(\Omega) u W^{1,2} u \Omega:=(a, b)\subset \mathbb{R} u \in C_0^{\infty}(a, b)  u(x)=\int_a^x u dx+u(a),  u u(a) u(a) u W^{1,2} T: W^{1,p}(\Omega) \rightarrow L^p (\partial \Omega) Tu = u\mid_{\partial \Omega} u \in W^{1,p}(\Omega) \cap C(\overline{\Omega}) W^{1,p} C(\overline{\Omega}) u\mid_{\partial \Omega} u","['real-analysis', 'functional-analysis', 'analysis', 'sobolev-spaces', 'trace-map']"
66,Is it necessary to consider the case $p=1$ separately?,Is it necessary to consider the case  separately?,p=1,"Let $p \in [1, \infty]$ . Let $f \in L^p_{\text{loc}} (\mathbb R)$ be $T$ -periodic, i.e., $f(x+T) = f(x)$ a.e. $x \in \mathbb R$ . Let $$ \bar f := \frac{1}{T} \int_0^T f (t) \, dt. $$ We define a sequence $(u_n) \subset L^p(0, 1)$ by $u_n (x) := f(nx)$ for all $x \in (0, 1)$ . Theorem $u_n \to \bar f$ in the weak topology $\sigma(L^p, L^{p'})$ where $p'$ is the Hölder conjugate of $p$ . I'm reading the proof of above theorem, i.e., Proof First, it is easy to check that $\int_a^b u_n(t) d t \rightarrow(b-a) \bar{f}$ (for every $\left.a, b \in(0,1)\right)$ . This implies that $u_n \rightarrow \bar{f}$ weakly $\sigma(L^p, L^{p^{\prime}})$ whenever $1<p \leq \infty$ (since $p^{\prime}<\infty$ , step functions are dense in $L^{p^{\prime}})$ . When $p=1$ , i.e., $f \in L_{\mathrm{loc}}^1(\mathbb{R})$ , there is a $T$ -periodic function $g \in L^{\infty}(\mathbb{R})$ such that $\frac{1}{T} \int_0^T|f-g|<\varepsilon$ (where $\varepsilon>0$ is fixed arbitrarily). Set $v_n(x)=g(n x), x \in(0,1)$ and let $\varphi \in L^{\infty}(0,1)$ . We have $$ \left|\int u_n \varphi-\bar{f} \int \varphi\right| \leq 3 \varepsilon\|\varphi\|_{\infty}+\left|\int v_n \varphi-\bar{g} \int \varphi\right| $$ and thus $\lim \sup _{n \rightarrow \infty}\left|\int u_n \varphi-\bar{f} \int \varphi\right| \leq 3 \varepsilon\|\varphi\|_{\infty} \forall \varepsilon>0$ . It follows that $u_n \rightarrow \bar{f}$ weakly $\sigma\left(L^1, L^{\infty}\right)$ . My question Clearly, $(0, 1)$ has finite Lebesgue measure, so $L^\infty (0, 1) \subset L^1(0, 1)$ and thus step functions are still dense in $L^\infty (0, 1)$ . Could you explain why the author still considers the case $p=1$ separately? $\lim \sup _{n \rightarrow \infty} \left|\int v_n \varphi-\bar{g} \int \varphi\right| =0$ in the proof? Update: I have added below steps for more clarity. We have $$ \begin{align} & \left|\int_0^1 u_n \varphi-\bar{f} \int_0^1 \varphi\right| \\ \le{} & \int_0^1 |u_n - v_n| \varphi + \bigg | \int_0^1 v_n \varphi - \bar g \int_0^1 \varphi \bigg | + \int |\bar g - \bar f| \varphi \\ \le{} & \|\varphi\|_\infty \int_0^1 |u_n - v_n| + \bigg | \int_0^1 v_n \varphi - \bar g \int_0^1 \varphi \bigg | + \|\varphi\|_\infty |\bar g - \bar f|. \end{align} $$ First, $|\bar g - \bar f| = \frac{1}{T} \int_0^T|f-g|< \varepsilon$ . Let $m := \lfloor n/T \rfloor$ . Then $$ \begin{align} \int_0^1 |u_n - v_n|  &= \int_0^1 |f(nx)-g(nx)| \, dx = \frac{1}{n} \int_0^n |f-g| \\ &= \frac{1}{n} \int_0^{mT} |f-g| + \frac{1}{n} \int_{mT}^n |f-g| \\ &= \frac{m}{n} \int_0^{T} |f-g| + \frac{1}{n} \int_{mT}^n |f-g| \\ &\le \frac{(m+1)\varepsilon T}{n} = \big ( \big \lfloor \frac{n}{T} \big \rfloor +1 \big )\frac{\varepsilon T}{n} \\ &\le 2 \frac{n}{T} \frac{\varepsilon T}{n} = 2 \varepsilon. \end{align} $$","Let . Let be -periodic, i.e., a.e. . Let We define a sequence by for all . Theorem in the weak topology where is the Hölder conjugate of . I'm reading the proof of above theorem, i.e., Proof First, it is easy to check that (for every . This implies that weakly whenever (since , step functions are dense in . When , i.e., , there is a -periodic function such that (where is fixed arbitrarily). Set and let . We have and thus . It follows that weakly . My question Clearly, has finite Lebesgue measure, so and thus step functions are still dense in . Could you explain why the author still considers the case separately? in the proof? Update: I have added below steps for more clarity. We have First, . Let . Then","p \in [1, \infty] f \in L^p_{\text{loc}} (\mathbb R) T f(x+T) = f(x) x \in \mathbb R 
\bar f := \frac{1}{T} \int_0^T f (t) \, dt.
 (u_n) \subset L^p(0, 1) u_n (x) := f(nx) x \in (0, 1) u_n \to \bar f \sigma(L^p, L^{p'}) p' p \int_a^b u_n(t) d t \rightarrow(b-a) \bar{f} \left.a, b \in(0,1)\right) u_n \rightarrow \bar{f} \sigma(L^p, L^{p^{\prime}}) 1<p \leq \infty p^{\prime}<\infty L^{p^{\prime}}) p=1 f \in L_{\mathrm{loc}}^1(\mathbb{R}) T g \in L^{\infty}(\mathbb{R}) \frac{1}{T} \int_0^T|f-g|<\varepsilon \varepsilon>0 v_n(x)=g(n x), x \in(0,1) \varphi \in L^{\infty}(0,1) 
\left|\int u_n \varphi-\bar{f} \int \varphi\right| \leq 3 \varepsilon\|\varphi\|_{\infty}+\left|\int v_n \varphi-\bar{g} \int \varphi\right|
 \lim \sup _{n \rightarrow \infty}\left|\int u_n \varphi-\bar{f} \int \varphi\right| \leq 3 \varepsilon\|\varphi\|_{\infty} \forall \varepsilon>0 u_n \rightarrow \bar{f} \sigma\left(L^1, L^{\infty}\right) (0, 1) L^\infty (0, 1) \subset L^1(0, 1) L^\infty (0, 1) p=1 \lim \sup _{n \rightarrow \infty} \left|\int v_n \varphi-\bar{g} \int \varphi\right| =0 
\begin{align}
& \left|\int_0^1 u_n \varphi-\bar{f} \int_0^1 \varphi\right| \\
\le{} & \int_0^1 |u_n - v_n| \varphi + \bigg | \int_0^1 v_n \varphi - \bar g \int_0^1 \varphi \bigg | + \int |\bar g - \bar f| \varphi \\
\le{} & \|\varphi\|_\infty \int_0^1 |u_n - v_n| + \bigg | \int_0^1 v_n \varphi - \bar g \int_0^1 \varphi \bigg | + \|\varphi\|_\infty |\bar g - \bar f|.
\end{align}
 |\bar g - \bar f| = \frac{1}{T} \int_0^T|f-g|< \varepsilon m := \lfloor n/T \rfloor 
\begin{align}
\int_0^1 |u_n - v_n|  &= \int_0^1 |f(nx)-g(nx)| \, dx = \frac{1}{n} \int_0^n |f-g| \\
&= \frac{1}{n} \int_0^{mT} |f-g| + \frac{1}{n} \int_{mT}^n |f-g| \\
&= \frac{m}{n} \int_0^{T} |f-g| + \frac{1}{n} \int_{mT}^n |f-g| \\
&\le \frac{(m+1)\varepsilon T}{n} = \big ( \big \lfloor \frac{n}{T} \big \rfloor +1 \big )\frac{\varepsilon T}{n} \\
&\le 2 \frac{n}{T} \frac{\varepsilon T}{n} = 2 \varepsilon.
\end{align}
","['functional-analysis', 'banach-spaces', 'lp-spaces', 'weak-convergence', 'weak-topology']"
67,Finding ideals of $C(X)$ where $X$ is compact Hausdorff space,Finding ideals of  where  is compact Hausdorff space,C(X) X,Here is the question above. I am stuck in part a) . here I am able to find a positive $f\in J$ with $\|f\|_\infty \le 1$ such that $f\ne 0$ on $X-U$ to get $f=1$ on $X-U$ we need to extend $1/f$ on $X$ which can be done by Teitze-extension . But how to control the norm of $g$ such that $\|f.g\|_\infty\le1$ where $g$ is the extension of $1/f$ .,Here is the question above. I am stuck in part a) . here I am able to find a positive with such that on to get on we need to extend on which can be done by Teitze-extension . But how to control the norm of such that where is the extension of .,f\in J \|f\|_\infty \le 1 f\ne 0 X-U f=1 X-U 1/f X g \|f.g\|_\infty\le1 g 1/f,"['functional-analysis', 'operator-theory', 'operator-algebras']"
68,Existence of smooth solutions to the heat equation with variable coefficients,Existence of smooth solutions to the heat equation with variable coefficients,,"Consider $$\partial_{t} u - a  \partial_{x}^{2}u = f, $$ in $[0,1]\times [0,T]$ ,  where $a, f : \mathbb{R} \times \mathbb{R}^+ \to \mathbb{R}$ are smooth. Additionally, the initial data $$u(x,0) = u_{0} $$ is smooth and we further endow $u$ with boundary conditions $$u(0,t) = u(1,t).  $$ Question: How can you prove the existence of a smooth solution to this problem? I have read somewhere that this follows from the theory of linear parabolic equations, but I don't know which theory exactly. I did see a proof in Evans for the homogeneous heat equation in $\mathbb{R}$ but that's about it.","Consider in ,  where are smooth. Additionally, the initial data is smooth and we further endow with boundary conditions Question: How can you prove the existence of a smooth solution to this problem? I have read somewhere that this follows from the theory of linear parabolic equations, but I don't know which theory exactly. I did see a proof in Evans for the homogeneous heat equation in but that's about it.","\partial_{t} u - a  \partial_{x}^{2}u = f,  [0,1]\times [0,T] a, f : \mathbb{R} \times \mathbb{R}^+ \to \mathbb{R} u(x,0) = u_{0}  u u(0,t) = u(1,t).   \mathbb{R}","['functional-analysis', 'analysis', 'partial-differential-equations', 'sobolev-spaces', 'heat-equation']"
69,Can a function satisfy two different elliptic PDEs?,Can a function satisfy two different elliptic PDEs?,,"Let $D\subset \mathbb{R}^2$ be a simply connected finite domain and consider two different 2nd order elliptic operators $\nabla^2$ and $\widetilde{\nabla}^2$ . We set some continuous arbitrary function $\Omega_{\mathsf{B}}$ defined on the boundary of $D$ . Apart from the case of $\widetilde{\nabla}^2$ and ${\nabla}^2$ being linearly dependent, is there an $\Omega$ such that $$ \begin{align} \nabla^2\Omega=0\:\:\:\text{with}\:\:\:\Omega\Big|_{\partial D}=\Omega_{\mathsf{B}}\\ \widetilde{\nabla}^2\Omega=0\:\:\:\text{with}\:\:\:\Omega\Big|_{\partial D}=\Omega_{\mathsf{B}} \end{align}  $$ By different I mean, for instance, that writing $\nabla^2=a_{ij}(x,y)\:\partial^2_{ij}$ and $\widetilde{\nabla}^2=\tilde{a}_{ij}(x,y)\:\partial^2_{ij}$ we have that $a_{ij}\neq\tilde{a}_{ij}$ for at least one point in the interior of $D$ . (As a special case I wish to take $\nabla^2$ to be the Laplacian, so the question would be rephrased as: given an elliptic $\widetilde{\nabla}^2$ , can we find a harmonic function $f$ with fixed boundary value such that $\widetilde{\nabla}^2f=0$ ?)","Let be a simply connected finite domain and consider two different 2nd order elliptic operators and . We set some continuous arbitrary function defined on the boundary of . Apart from the case of and being linearly dependent, is there an such that By different I mean, for instance, that writing and we have that for at least one point in the interior of . (As a special case I wish to take to be the Laplacian, so the question would be rephrased as: given an elliptic , can we find a harmonic function with fixed boundary value such that ?)","D\subset \mathbb{R}^2 \nabla^2 \widetilde{\nabla}^2 \Omega_{\mathsf{B}} D \widetilde{\nabla}^2 {\nabla}^2 \Omega 
\begin{align}
\nabla^2\Omega=0\:\:\:\text{with}\:\:\:\Omega\Big|_{\partial D}=\Omega_{\mathsf{B}}\\
\widetilde{\nabla}^2\Omega=0\:\:\:\text{with}\:\:\:\Omega\Big|_{\partial D}=\Omega_{\mathsf{B}}
\end{align} 
 \nabla^2=a_{ij}(x,y)\:\partial^2_{ij} \widetilde{\nabla}^2=\tilde{a}_{ij}(x,y)\:\partial^2_{ij} a_{ij}\neq\tilde{a}_{ij} D \nabla^2 \widetilde{\nabla}^2 f \widetilde{\nabla}^2f=0","['real-analysis', 'functional-analysis', 'analysis', 'partial-differential-equations', 'elliptic-equations']"
70,"""Functional Analysis"" by Kesavan, Exercise 2.32 (b)","""Functional Analysis"" by Kesavan, Exercise 2.32 (b)",,"""Functional Analysis"" by Kesavan, Exercise 2.32 (b) Define $T, S\colon \ell_2 \to \ell_2$ by \begin{align*}T(x) &= (0, x_1, x_2, \dots) \\ S(x) &= (x_2, x_3, \dots)\end{align*} where $x = (x_1, x_2, \dots) \in \ell_2$ . If $A$ is a continous linear operator on $\ell_2$ such that $\Vert A - T\Vert < 1$ , show that $A$ is also not invertible. Deduce that $\mathcal{G}$ , the set of invertible linear operators in $\mathcal{L}(V)$ , is not dense in $\mathcal{L}(V)$ , if $V$ is infinite dimensional. Part (a) of the question was to show that $T, S$ are continuous linear operators, and that $ST = I$ while $TS \neq I$ , which I could do. This shows that $T$ and $S$ are not invertible. For the second statement, I have an intuition that if $\mathcal{G}$ were dense in $\mathcal{L}(V)$ , then there would exist a sequence of invertible linear operators converging to $T$ , which woud mean that some $A_n \in \mathcal{G}$ must satisfy $\Vert A_n - T\Vert < 1$ , contradicting the first statement.","""Functional Analysis"" by Kesavan, Exercise 2.32 (b) Define by where . If is a continous linear operator on such that , show that is also not invertible. Deduce that , the set of invertible linear operators in , is not dense in , if is infinite dimensional. Part (a) of the question was to show that are continuous linear operators, and that while , which I could do. This shows that and are not invertible. For the second statement, I have an intuition that if were dense in , then there would exist a sequence of invertible linear operators converging to , which woud mean that some must satisfy , contradicting the first statement.","T, S\colon \ell_2 \to \ell_2 \begin{align*}T(x) &= (0, x_1, x_2, \dots) \\ S(x) &= (x_2, x_3, \dots)\end{align*} x = (x_1, x_2, \dots) \in \ell_2 A \ell_2 \Vert A - T\Vert < 1 A \mathcal{G} \mathcal{L}(V) \mathcal{L}(V) V T, S ST = I TS \neq I T S \mathcal{G} \mathcal{L}(V) T A_n \in \mathcal{G} \Vert A_n - T\Vert < 1","['functional-analysis', 'operator-theory']"
71,Inequality of a linearized function,Inequality of a linearized function,,"The following inequality is used in one of the steps for the proof of the centre manifold theorem. Consider the function $$f(x)=Ax+\tilde{f}(x)$$ where $x\in \mathbb{R}^n$ , $f:\mathbb{R}^n \rightarrow \mathbb{R}^n$ is of class $C^k$ for some $k\geq 1$ and $f(0)=0$ , $Df(0)=A$ . The author during the proof of a lemma proceeds to state the following result. $$\|f(x)\|\leq\|x\|\sup_{s\in[0,1]}\|Df(sx)\|$$ The author has not defined how the norm of $Df(sx)$ is defined and I am not sure if that is required. I tried proving this for the one dimensional case by replacing all the norms with moduli but couldn't come up with a simplification for the RHS. The text which this is taken from is A. Vanderbauwhede, ""Centre manifolds, normal forms and elementary bifurcations"", Dynamics Reported, Vol 2 (1989), pg 95.","The following inequality is used in one of the steps for the proof of the centre manifold theorem. Consider the function where , is of class for some and , . The author during the proof of a lemma proceeds to state the following result. The author has not defined how the norm of is defined and I am not sure if that is required. I tried proving this for the one dimensional case by replacing all the norms with moduli but couldn't come up with a simplification for the RHS. The text which this is taken from is A. Vanderbauwhede, ""Centre manifolds, normal forms and elementary bifurcations"", Dynamics Reported, Vol 2 (1989), pg 95.","f(x)=Ax+\tilde{f}(x) x\in \mathbb{R}^n f:\mathbb{R}^n \rightarrow \mathbb{R}^n C^k k\geq 1 f(0)=0 Df(0)=A \|f(x)\|\leq\|x\|\sup_{s\in[0,1]}\|Df(sx)\| Df(sx)","['functional-analysis', 'ordinary-differential-equations', 'dynamical-systems', 'nonlinear-dynamics', 'mean-value-theorem']"
72,$L^p_{\text{loc}}$ convergence implies almost everywhere convergence,convergence implies almost everywhere convergence,L^p_{\text{loc}},"Suppose $\{f_n\}\subset L^p(B)$ for the unit ball $B\subset\mathbb{R}^n$ converges in $L^p_{\text{loc}}$ , i.e. $\int_V\lvert f_n(x)-f(x)\rvert^p dx\rightarrow 0$ for all $V\subset\subset B$ . Can we say that $f_{n_i}(x)\rightarrow f(x)$ almost everywhere in $B$ for some subsequence $\{f_{n_i}\}$ ? My idea for a proof was to consider a sequence of balls $B_{r_k}$ with $r_k\rightarrow 1$ and denote by $\{f^k_n\}$ the subsequence that converges almost everywhere in $B_{r_k}$ . Then I thought I could pick a diagonal subsequence that converges almost everywhere in $B$ . However I'm not sure how to show that the diagonal sequence converges almost everywhere. Maybe this is not true, in that case can we find a counter-example?","Suppose for the unit ball converges in , i.e. for all . Can we say that almost everywhere in for some subsequence ? My idea for a proof was to consider a sequence of balls with and denote by the subsequence that converges almost everywhere in . Then I thought I could pick a diagonal subsequence that converges almost everywhere in . However I'm not sure how to show that the diagonal sequence converges almost everywhere. Maybe this is not true, in that case can we find a counter-example?",\{f_n\}\subset L^p(B) B\subset\mathbb{R}^n L^p_{\text{loc}} \int_V\lvert f_n(x)-f(x)\rvert^p dx\rightarrow 0 V\subset\subset B f_{n_i}(x)\rightarrow f(x) B \{f_{n_i}\} B_{r_k} r_k\rightarrow 1 \{f^k_n\} B_{r_k} B,"['real-analysis', 'functional-analysis', 'analysis', 'convergence-divergence', 'almost-everywhere']"
73,spectrum of an element of unital banach algebra is closed set,spectrum of an element of unital banach algebra is closed set,,"Let $A$ be a unital Banach algebra and $a \in A$ . Then the spectrum $\sigma(a)$ and set of invertible elements $\text{Inv}(A)$ are defined as: $$ \begin{align} &\text{Inv}(A):=\{a\in A~|~a \text{ is invertible}\}\\ &\sigma(a):=\{\lambda \in \mathbb C~|~\lambda 1-a \notin \text{Inv}(A)\}. \end{align} $$ I want to show that $\sigma(a)$ is closed subset of $\mathbb C$ . But I already know that $\text{Inv}(A)$ is an open subset of $A$ , since $A$ is a Banach algebra. I know there are many approaches to show that $\sigma(a)$ is closed, but I want to show by assuming $\text{Inv}(A)$ is an open subset of $A$ . Taking the set $\mathbb C-\sigma(a)$ , we have to show that this set is open provided $\text{Inv}(A)$ is an open. Can you please give me some hint?","Let be a unital Banach algebra and . Then the spectrum and set of invertible elements are defined as: I want to show that is closed subset of . But I already know that is an open subset of , since is a Banach algebra. I know there are many approaches to show that is closed, but I want to show by assuming is an open subset of . Taking the set , we have to show that this set is open provided is an open. Can you please give me some hint?","A a \in A \sigma(a) \text{Inv}(A) 
\begin{align}
&\text{Inv}(A):=\{a\in A~|~a \text{ is invertible}\}\\
&\sigma(a):=\{\lambda \in \mathbb C~|~\lambda 1-a \notin \text{Inv}(A)\}.
\end{align}
 \sigma(a) \mathbb C \text{Inv}(A) A A \sigma(a) \text{Inv}(A) A \mathbb C-\sigma(a) \text{Inv}(A)","['functional-analysis', 'operator-theory', 'operator-algebras', 'banach-algebras']"
74,Orthogonality in Sobolev $H^1$.,Orthogonality in Sobolev .,H^1,"Consider $H^1(-1,1)$ Sobolev space with natural dot product: $\langle f, g\rangle_{H^1} = \langle f, g\rangle_{L^2} + \langle f', g'\rangle_{L^2}$ . Let $U$ be the space of functions: $f(x) = 0$ $\forall x \le 0$ . We want to know $U^\perp$ . The first thing is $U^\perp = \{f: f(x) = 0, x > 0\}$ . But I guess the same trick (consider a neighborhood of zero) as for $C[-1,1]$ with $\langle f, g\rangle = \int_{-1}^1 f(x) g(x) dx$ doesn't work. But I guess the latter family of functions obviously orthogonal to the $U$ . But maybe there is something else? I've tried so: $$ \int_{0}^{t} f g + \int_{0}^{t} f'g' = \int_{0}^t f g + f(t)g'(t) - \int_0^t f(x) g''(x) dx=0 \iff$$ $$f(t) g(t) + f'(t) g'(t) + f(t) g''(t) - f(t)g''(t) + f(0)g''(0) = 0 $$ Hence we obtain something like: $f(t) = \bar{C}\exp\left(-\displaystyle\int \dfrac{g + c}{g'} dt\right)$ . But here we assume that there is exists $g''$ (which might be not true). Any ideas?",Consider Sobolev space with natural dot product: . Let be the space of functions: . We want to know . The first thing is . But I guess the same trick (consider a neighborhood of zero) as for with doesn't work. But I guess the latter family of functions obviously orthogonal to the . But maybe there is something else? I've tried so: Hence we obtain something like: . But here we assume that there is exists (which might be not true). Any ideas?,"H^1(-1,1) \langle f, g\rangle_{H^1} = \langle f, g\rangle_{L^2} + \langle f', g'\rangle_{L^2} U f(x) = 0 \forall x \le 0 U^\perp U^\perp = \{f: f(x) = 0, x > 0\} C[-1,1] \langle f, g\rangle = \int_{-1}^1 f(x) g(x) dx U 
\int_{0}^{t} f g + \int_{0}^{t} f'g' = \int_{0}^t f g + f(t)g'(t) - \int_0^t f(x) g''(x) dx=0 \iff f(t) g(t) + f'(t) g'(t) + f(t) g''(t) - f(t)g''(t) + f(0)g''(0) = 0
 f(t) = \bar{C}\exp\left(-\displaystyle\int \dfrac{g + c}{g'} dt\right) g''","['functional-analysis', 'sobolev-spaces']"
75,Weak convergence in $L^2$ implies boundness,Weak convergence in  implies boundness,L^2,"Let $f$ , $f_n \in L^2$ , we say that $f_n \rightharpoonup f$ converges weakly in $L^2$ if $$\lim_{n \to \infty} \langle (f_n-f),g \rangle_{L^2}=0\,\,\,\forall\,\,\, g \in L^2. $$ I know that using the Uniform boundedness principle ( Banach-Steinhaus Theorem) the sequence $(\lVert f_n \rVert_2)$ is bounded. But I wish to know a way to prove this boundness without using the uniform boundness principle. Given the particularity of the situation, I think that is not that hard, but nevertheless I still need help, thank you in advance! I was able to prove, using Riesz- Fréchet representation theorem that for each linear functional $\varphi:L^2 \to \mathbb{R}$ , the sequence $(\varphi(f_n))_n$ is bounded. There exist some particular $\varphi \in L^2$ which implies the boundness of the sequence $(\lVert f_n \rVert_2)$ ?","Let , , we say that converges weakly in if I know that using the Uniform boundedness principle ( Banach-Steinhaus Theorem) the sequence is bounded. But I wish to know a way to prove this boundness without using the uniform boundness principle. Given the particularity of the situation, I think that is not that hard, but nevertheless I still need help, thank you in advance! I was able to prove, using Riesz- Fréchet representation theorem that for each linear functional , the sequence is bounded. There exist some particular which implies the boundness of the sequence ?","f f_n \in L^2 f_n \rightharpoonup f L^2 \lim_{n \to \infty} \langle (f_n-f),g \rangle_{L^2}=0\,\,\,\forall\,\,\, g \in L^2.  (\lVert f_n \rVert_2) \varphi:L^2 \to \mathbb{R} (\varphi(f_n))_n \varphi \in L^2 (\lVert f_n \rVert_2)","['real-analysis', 'functional-analysis', 'analysis', 'measure-theory', 'weak-convergence']"
76,Functional derivative and arbitrary function,Functional derivative and arbitrary function,,"I have a questions regarding the definition of the functional derivative. Unfortunately a lot of text books give not a proper formal definition. Wikipedia gives the following definition \begin{align}  \int \frac{\delta F}{\delta\rho}(x) \phi(x) \; dx  &= \lim_{\varepsilon\to 0}\frac{F[\rho+\varepsilon \phi]-F[\rho]}{\varepsilon} \\ &= \left [ \frac{d}{d\varepsilon}F[\rho+\varepsilon \phi]\right ]_{\varepsilon=0}, \end{align} with $\phi$ an arbitrary function, $M$ be a manifold of continous functions $\rho$ and $F:M\to \mathbb{R}$ If $\phi$ is arbitrary then how do I know the left integral exists? Are there no constraints on $\phi$ like it has to be integrable and in $C_c^{\infty}$ ?","I have a questions regarding the definition of the functional derivative. Unfortunately a lot of text books give not a proper formal definition. Wikipedia gives the following definition with an arbitrary function, be a manifold of continous functions and If is arbitrary then how do I know the left integral exists? Are there no constraints on like it has to be integrable and in ?","\begin{align}
 \int \frac{\delta F}{\delta\rho}(x) \phi(x) \; dx 
&= \lim_{\varepsilon\to 0}\frac{F[\rho+\varepsilon \phi]-F[\rho]}{\varepsilon} \\
&= \left [ \frac{d}{d\varepsilon}F[\rho+\varepsilon \phi]\right ]_{\varepsilon=0},
\end{align} \phi M \rho F:M\to \mathbb{R} \phi \phi C_c^{\infty}",['functional-analysis']
77,Surjective operator to separable space,Surjective operator to separable space,,"Let $X,Y$ be Banach spaces and $T:X\to Y$ be a surjective bounded linear operator. If $Y$ is separable then there exists a separable subspace $Z$ of $X$ such that $T(Z)=Y$ . I tried the following: $Y = \overline{\{y_1, \dots, y_n, \dots\}}$ . Since $T$ is surjective $y_i = Tx_i$ for some $x_i \in X$ . Let $Z = \overline{\text{span}(x_1,\dots,x_n,\dots)}$ . I know that $Z$ is separable so if I could prove that $T(Z)=Y$ the proof would be complete. However I could only prove that $\overline{T(Z)}=Y$ . Any help would be appreciated. Thanks.",Let be Banach spaces and be a surjective bounded linear operator. If is separable then there exists a separable subspace of such that . I tried the following: . Since is surjective for some . Let . I know that is separable so if I could prove that the proof would be complete. However I could only prove that . Any help would be appreciated. Thanks.,"X,Y T:X\to Y Y Z X T(Z)=Y Y = \overline{\{y_1, \dots, y_n, \dots\}} T y_i = Tx_i x_i \in X Z = \overline{\text{span}(x_1,\dots,x_n,\dots)} Z T(Z)=Y \overline{T(Z)}=Y","['real-analysis', 'functional-analysis', 'operator-theory']"
78,Approximating Lipschitz Functions by Sigmoidal Functions,Approximating Lipschitz Functions by Sigmoidal Functions,,"We define a sigmoidal function $\sigma: \mathbb{R} \to [0,1]$ as a non-decreasing, continuous function with $\lim_{x\to\infty}\sigma(x) = 1$ and $\lim_{x\to-\infty}\sigma(x) = 0$ . I want to show that: If $g:\mathbb{R}\to \mathbb{R}$ is a Lipschitz on the interval [a,b], and $\epsilon>0$ , then I can find $f\in \left\{\sum_{i=1}^{n}a_i  \sigma(u_ix + b_i): a_i,u_i,b_i\in\mathbb{R}, n\geq 0,\right\}$ such that $$\sup_{x\in[a,b]} \left\lvert f(x) - g(x) \right\rvert <  \epsilon$$ In other words I want to show I can approximate $g$ with linear combinations of affinely shifted and scaled versions of $\sigma$ . I know for large enough $M>0$ , $\sigma(Mx)$ acts like the indicator function (i proved that it can approximate lipschitz functions), but I don't know how to go any further.","We define a sigmoidal function as a non-decreasing, continuous function with and . I want to show that: If is a Lipschitz on the interval [a,b], and , then I can find such that In other words I want to show I can approximate with linear combinations of affinely shifted and scaled versions of . I know for large enough , acts like the indicator function (i proved that it can approximate lipschitz functions), but I don't know how to go any further.","\sigma: \mathbb{R} \to [0,1] \lim_{x\to\infty}\sigma(x) = 1 \lim_{x\to-\infty}\sigma(x) = 0 g:\mathbb{R}\to \mathbb{R} \epsilon>0 f\in \left\{\sum_{i=1}^{n}a_i
 \sigma(u_ix + b_i): a_i,u_i,b_i\in\mathbb{R}, n\geq 0,\right\} \sup_{x\in[a,b]} \left\lvert f(x) - g(x) \right\rvert <
 \epsilon g \sigma M>0 \sigma(Mx)","['real-analysis', 'functional-analysis', 'approximation', 'approximation-theory']"
79,Is there an explicit equivalence of categories between real and complex commutative unital C* algebras,Is there an explicit equivalence of categories between real and complex commutative unital C* algebras,,Gelfand duality shows that the category of commutative unital C* algebras is dual to the category of compact Hausdorff spaces.  This holds for the real case (see Stone spaces of Johnstone) as well as the much better known case of complex C* algebras though the proofs are not the same.  Since these two categories are both dual to the same category they should be equivalent to each other.  Is this equivalence of categories explicitly described anywhere?,Gelfand duality shows that the category of commutative unital C* algebras is dual to the category of compact Hausdorff spaces.  This holds for the real case (see Stone spaces of Johnstone) as well as the much better known case of complex C* algebras though the proofs are not the same.  Since these two categories are both dual to the same category they should be equivalent to each other.  Is this equivalence of categories explicitly described anywhere?,,"['functional-analysis', 'category-theory']"
80,Can the derivative difference be arbitrarily larger than the function difference?,Can the derivative difference be arbitrarily larger than the function difference?,,"Background : Let $ f : \mathbb R ^ 2 \to \mathbb R $ be a continuous function such that $ f ( x , x ) = 0 $ for all real numbers $ x $ , and $ f ( x , y ) > 0 $ for all real numbers $ x , y $ with $ x > y $ . Hypothesis : For any such $ f $ , there exists a strictly increasing real function $ g $ such that $ g ' ( x ) - g ' ( y ) \ge f ( x , y ) \big( g ( x ) - g ( y ) \big) $ for all $ x , y $ that $ x > y > 0 $ . Is it possible to prove this hypothesis? Motivation: Since $ f ( x , y ) $ can be arbitrarily large, this question translates to: Can the derivative difference be arbitrarily larger than the function difference? From English the answer seems to be obviously no, but looking at the mathematical formula, the existence seems also obvious. Example 1: Let my try a a small example when $ f ( x , y ) $ has an upper bound, say $ k $ . Then, suppose that $ g ( x ) = e ^ { m x } $ where $ m > k $ . Can we verify that $ g ' ( x ) - g ' ( y ) \ge f ( x , y ) \big( g ( x ) - g ( y ) \big) $ ? Example 2: $ f ( x , y ) = ( x - y ) ^ 2 $ . (my try) Using Taylor expansion, one sufficient condition for the hypothesis is: for any $ n $ , for any $ y \in ( 0 , x ) $ , $$ ( x - y ) ^ n g ^ { ( n + 1 ) } ( x ) \ge ( x - y ) ^ 2 ( x - y ) ^ n g ^ n ( x ) $$ $$ g ^ { ( n + 1 ) } ( x ) \ge ( x - y ) ^ 2 g ^ n ( x ) \text . $$ A little work will show that, for any $ n $ , the solution set for this inequality does exist. However, I am not sure if the solution sets overlap. Related: Is it possible for the derivative of a function to grow arbitrarily faster than the function itself? First answer. Note: I took Martin's suggestion to make everything positive.","Background : Let be a continuous function such that for all real numbers , and for all real numbers with . Hypothesis : For any such , there exists a strictly increasing real function such that for all that . Is it possible to prove this hypothesis? Motivation: Since can be arbitrarily large, this question translates to: Can the derivative difference be arbitrarily larger than the function difference? From English the answer seems to be obviously no, but looking at the mathematical formula, the existence seems also obvious. Example 1: Let my try a a small example when has an upper bound, say . Then, suppose that where . Can we verify that ? Example 2: . (my try) Using Taylor expansion, one sufficient condition for the hypothesis is: for any , for any , A little work will show that, for any , the solution set for this inequality does exist. However, I am not sure if the solution sets overlap. Related: Is it possible for the derivative of a function to grow arbitrarily faster than the function itself? First answer. Note: I took Martin's suggestion to make everything positive."," f : \mathbb R ^ 2 \to \mathbb R   f ( x , x ) = 0   x   f ( x , y ) > 0   x , y   x > y   f   g   g ' ( x ) - g ' ( y ) \ge f ( x , y ) \big( g ( x ) - g ( y ) \big)   x , y   x > y > 0   f ( x , y )   f ( x , y )   k   g ( x ) = e ^ { m x }   m > k   g ' ( x ) - g ' ( y ) \ge f ( x , y ) \big( g ( x ) - g ( y ) \big)   f ( x , y ) = ( x - y ) ^ 2   n   y \in ( 0 , x )   ( x - y ) ^ n g ^ { ( n + 1 ) } ( x ) \ge ( x - y ) ^ 2 ( x - y ) ^ n g ^ n ( x )   g ^ { ( n + 1 ) } ( x ) \ge ( x - y ) ^ 2 g ^ n ( x ) \text .   n ","['real-analysis', 'functional-analysis', 'functions', 'functional-equations', 'functional-inequalities']"
81,Unitary Operators are Connected in a $C^*$-algebra,Unitary Operators are Connected in a -algebra,C^*,"Let $A$ be a unital $C^*$ - algebra. Let $U = \{ u \in A : u^*u=uu^*=1\}$ be the unitary group of $A$ . Let $U'= \{ e^{ia_1}e^{ia_2} \cdots e^{ia_n} : a_k = a^*_k \in A, \text{for } 1\leq k \leq n \}$ . Show that $U'$ is the connected component of the identity in $U$ . If $A$ is commutative, show that $U' = \{ e^{ia} : a = a ^* \in A\}$ . I thought of using the theorems below from Banach Algebra Techniques in Operator Theory by Douglas. Following the proof of 2.14, if $f = e^{ia} \in A$ . Then $f\in U$ . Consider $\phi: [0,1 ] \rightarrow e^(A)$ defined by $\phi(\lambda) = e^{i \lambda a}$ , I don't see why $f \in U'$ , and $e^A$ is contained in $U'$ ... I also showed that if $\| u-1\| <2 $ , then we have $-1 \ne spec(u) $ and we can write $u = e^{ia}$ for some self-adjoint $a \in A$ Any help or suggestions will be appreciated. Thank you!","Let be a unital - algebra. Let be the unitary group of . Let . Show that is the connected component of the identity in . If is commutative, show that . I thought of using the theorems below from Banach Algebra Techniques in Operator Theory by Douglas. Following the proof of 2.14, if . Then . Consider defined by , I don't see why , and is contained in ... I also showed that if , then we have and we can write for some self-adjoint Any help or suggestions will be appreciated. Thank you!","A C^* U = \{ u \in A : u^*u=uu^*=1\} A U'= \{ e^{ia_1}e^{ia_2} \cdots e^{ia_n} : a_k = a^*_k \in A, \text{for } 1\leq k \leq n \} U' U A U' = \{ e^{ia} : a = a ^* \in A\} f = e^{ia} \in A f\in U \phi: [0,1 ] \rightarrow e^(A) \phi(\lambda) = e^{i \lambda a} f \in U' e^A U' \| u-1\| <2  -1 \ne spec(u)  u = e^{ia} a \in A","['functional-analysis', 'operator-theory', 'connectedness', 'c-star-algebras']"
82,When exactly is the character space of a Banach algebra empty?,When exactly is the character space of a Banach algebra empty?,,"It is well-known that the character space, (i.e. the set of multiplicative characters) of a commutative, unital Banach algebra is non-empty. But is there a complete characterization of when exactly the character space of Banach algebra is empty? Or even an incomplete characterization (ie certain classes of Banach algebras which we know have empty character space)? Edit: I’d appreciate any responses, especially those with links for further reading!","It is well-known that the character space, (i.e. the set of multiplicative characters) of a commutative, unital Banach algebra is non-empty. But is there a complete characterization of when exactly the character space of Banach algebra is empty? Or even an incomplete characterization (ie certain classes of Banach algebras which we know have empty character space)? Edit: I’d appreciate any responses, especially those with links for further reading!",,"['functional-analysis', 'representation-theory', 'operator-algebras', 'banach-algebras', 'gelfand-representation']"
83,kernel of Haagerup tensor product of maps,kernel of Haagerup tensor product of maps,,"Haagerup tensor product $\otimes_{\rm h}$ is both injective and projective. Pisier, Gilles , Introduction to operator space theory, London Mathematical Society Lecture Note Series 294. Cambridge: Cambridge University Press (ISBN 0-521-81165-1/pbk). vii, 478 p. (2003). ZBL1093.46001 . Can the following be true? Let $q_i : E_i \rightarrow F_i$ be complete quotient maps of operator spaces. Then \begin{equation} {\rm Ker} \, q_1 \otimes_{\rm h} q_2 = {\rm Ker} \, q_1 \otimes_{\rm h} E_2 + E_1 \otimes_{\rm h} {\rm Ker} \, q_2. \end{equation} I have some hints which tilt me towards believing it is true. Denote by U the operator space on the right. Then $U \subset {\rm Ker} \, q_1 \otimes_{\rm h} q_2$ . Then the product map drops to a map on $(E_1 \otimes_{\rm h} E_2)/U$ and we need to prove that this map is injective. As for the algebraic tensor product, one finds an inverse map from $F_1 \otimes_{\rm h} F_2 \simeq E_1/{\rm Ker}\, q_1 \otimes_{\rm h} E_2/{\rm Ker} \, q_2$ to $(E_1 \otimes_{\rm h} E_2)/U$ . For this one starts from the bilinear map: $(\hat e_1,\hat e_2) \mapsto \widehat{e_1 \otimes e_2}$ , where the hats are the obvious classes. It is well defined and completely bounded. Hence it defines a linear map on the Haagerup product. Then one checks that it is the inverse map we looked for. I am hesitant because this implies $(E \otimes_{\rm h} F)/(G \otimes_{\rm h} F) \simeq (E/G) \otimes_{\rm h} F$ for any sub-space $G$ of $E$ .","Haagerup tensor product is both injective and projective. Pisier, Gilles , Introduction to operator space theory, London Mathematical Society Lecture Note Series 294. Cambridge: Cambridge University Press (ISBN 0-521-81165-1/pbk). vii, 478 p. (2003). ZBL1093.46001 . Can the following be true? Let be complete quotient maps of operator spaces. Then I have some hints which tilt me towards believing it is true. Denote by U the operator space on the right. Then . Then the product map drops to a map on and we need to prove that this map is injective. As for the algebraic tensor product, one finds an inverse map from to . For this one starts from the bilinear map: , where the hats are the obvious classes. It is well defined and completely bounded. Hence it defines a linear map on the Haagerup product. Then one checks that it is the inverse map we looked for. I am hesitant because this implies for any sub-space of .","\otimes_{\rm h} q_i : E_i \rightarrow F_i \begin{equation}
{\rm Ker} \, q_1 \otimes_{\rm h} q_2 = {\rm Ker} \, q_1 \otimes_{\rm h} E_2 + E_1 \otimes_{\rm h} {\rm Ker} \, q_2.
\end{equation} U \subset {\rm Ker} \, q_1 \otimes_{\rm h} q_2 (E_1 \otimes_{\rm h} E_2)/U F_1 \otimes_{\rm h} F_2 \simeq E_1/{\rm Ker}\, q_1 \otimes_{\rm h} E_2/{\rm Ker} \, q_2 (E_1 \otimes_{\rm h} E_2)/U (\hat e_1,\hat e_2) \mapsto \widehat{e_1 \otimes e_2} (E \otimes_{\rm h} F)/(G \otimes_{\rm h} F) \simeq (E/G) \otimes_{\rm h} F G E","['functional-analysis', 'tensor-products', 'operator-algebras', 'operator-spaces']"
84,"Weak Convergence in the Space $L_1$, Why So Special?","Weak Convergence in the Space , Why So Special?",L_1,"For $1< p< \infty$ and $U\subset \mathbb{R}^d$ , and let $p'$ be the conjugate of $p$ . We say that a sequence $\{f_n\}\in L^p(U)$ converges weakly to $f\in L^p(U)$ if $$ \lim_{n\to \infty}\int_U f_n(u) g(u) d(u)=\int_U f(u)g(u) d(u) \ \ \ \  \forall g\in L^{p'}(U).  $$ Knowing a small amount of probability I think of weak-convergence as convergence in average (mentioned in these notes https://www.uio.no/studier/emner/matnat/math/MAT4380/v06/Weakconvergence.pdf Remark 1.2). My question is what is so special about $L^1-$ convergence? What are the usual ways to guarantee a sequence converges weakly somewhere in $L^1$ ?","For and , and let be the conjugate of . We say that a sequence converges weakly to if Knowing a small amount of probability I think of weak-convergence as convergence in average (mentioned in these notes https://www.uio.no/studier/emner/matnat/math/MAT4380/v06/Weakconvergence.pdf Remark 1.2). My question is what is so special about convergence? What are the usual ways to guarantee a sequence converges weakly somewhere in ?",1< p< \infty U\subset \mathbb{R}^d p' p \{f_n\}\in L^p(U) f\in L^p(U)  \lim_{n\to \infty}\int_U f_n(u) g(u) d(u)=\int_U f(u)g(u) d(u) \ \ \ \  \forall g\in L^{p'}(U).   L^1- L^1,"['functional-analysis', 'functions', 'lp-spaces', 'weak-convergence']"
85,Can we show $\mu(gX) = \mu(X)$ if integral is translation invariant?,Can we show  if integral is translation invariant?,\mu(gX) = \mu(X),"Let $\mu$ be a Radon probability measure on the compact Hausdorff topological group $G$ such that $$\int_G f(g) \mu(dg) = \int_Gf(hg) \mu(dg)$$ for all $h \in G$ and for all $f \in C(G)$ . Can I deduce that $\mu(hX) = \mu(X)$ for a Borel set $X$ and $h \in G$ ? Attempt: $$\mu(hX) = \int_G I_{hX}(g) \mu(dg) = \int_G I_{X}(h^{-1}g) \mu(dg)\stackrel{(?)}= \int_G I_{X}(g) \mu(dg) = \mu(X)$$ Now, I try to explain $(?)$ . Maybe I can approximate with continuous functions or something like that?","Let be a Radon probability measure on the compact Hausdorff topological group such that for all and for all . Can I deduce that for a Borel set and ? Attempt: Now, I try to explain . Maybe I can approximate with continuous functions or something like that?",\mu G \int_G f(g) \mu(dg) = \int_Gf(hg) \mu(dg) h \in G f \in C(G) \mu(hX) = \mu(X) X h \in G \mu(hX) = \int_G I_{hX}(g) \mu(dg) = \int_G I_{X}(h^{-1}g) \mu(dg)\stackrel{(?)}= \int_G I_{X}(g) \mu(dg) = \mu(X) (?),"['functional-analysis', 'measure-theory']"
86,$T$ is compact operator Hilbert space,is compact operator Hilbert space,T,"I'm getting troubles to show the following Let $X$ be an infinite-dimensional separable Hilbert space and $T$ a self-adjoint operator. Assume $T^n$ is compact for some $n \in \mathbb{N}$ . Prove that $T$ is compact. I was thinking about using the spectral theorem. However, I don't see this clearly. Any hint would be amazing. Thank you.","I'm getting troubles to show the following Let be an infinite-dimensional separable Hilbert space and a self-adjoint operator. Assume is compact for some . Prove that is compact. I was thinking about using the spectral theorem. However, I don't see this clearly. Any hint would be amazing. Thank you.",X T T^n n \in \mathbb{N} T,"['functional-analysis', 'compact-operators']"
87,How to prove Laplace transform is bounded on $L^2(\mathbb{R}_+)$?,How to prove Laplace transform is bounded on ?,L^2(\mathbb{R}_+),"The Laplace transform is defined by \begin{equation} (\mathscr{L}f)(s) \triangleq   \int_0^\infty e^{-sx} f(x) dx, \quad s>0, \end{equation} then how can we check that the Laplace transform $\mathscr{L}$ is bounded as an operator from $L^2(\mathbb{R}_+)$ to $L^2(\mathbb{R}_+)$ with norm $\sqrt{\pi}$ ?",The Laplace transform is defined by then how can we check that the Laplace transform is bounded as an operator from to with norm ?,"\begin{equation}
(\mathscr{L}f)(s) \triangleq  
\int_0^\infty e^{-sx} f(x) dx, \quad s>0,
\end{equation} \mathscr{L} L^2(\mathbb{R}_+) L^2(\mathbb{R}_+) \sqrt{\pi}","['functional-analysis', 'operator-theory', 'laplace-transform', 'harmonic-analysis']"
88,Kreyszig's FA Prob. $6$ section $2.8$,Kreyszig's FA Prob.  section,6 2.8,"I'm having a difficult time understand the second part of this question: The space $C'[a,b]$ or $C^1[a,b]$ is the normed space of all continuously differentiable functions on $J=[a,b]$ with norm defined by: $||x||=\max_{t\in J}|x(t)|+\max_{t\in J}|x'(t)|$ . Show that the axioms of a norm are satisfied. Show that $f(x)=x'(c)$ , $c=(a+b)/2$ , defines a bounded linear functional on $C'[a,b]$ . Show that $f$ is not bounded, considered as a functional on the subspace of $C[a,b]$ which consists of all continuosly differentiable functions. For the first part it is easy to show that $f$ is indeed a linear functional and bounded because the elements are continuous and the domain is compact. However I can't understand the last part which states that $f$ is not bounded if we consider it as a functional on the subspace $C^1[a,b]$ of the larger space of continuous functions on $[a,b]$ . Maybe $C[a,b]$ is a Banach space (with respect to some norm) and if $f$ was indeed bounded on $C^1[a,b]$ (as a subspace) it would admit a bounded extension $\hat{f}$ defined on $C[a,b]$ and the question is asking me to show that it is impossible? Is the metric induced by the given norm defined $C[a,b]$ ? I'm really confused, any help is appreciated.","I'm having a difficult time understand the second part of this question: The space or is the normed space of all continuously differentiable functions on with norm defined by: . Show that the axioms of a norm are satisfied. Show that , , defines a bounded linear functional on . Show that is not bounded, considered as a functional on the subspace of which consists of all continuosly differentiable functions. For the first part it is easy to show that is indeed a linear functional and bounded because the elements are continuous and the domain is compact. However I can't understand the last part which states that is not bounded if we consider it as a functional on the subspace of the larger space of continuous functions on . Maybe is a Banach space (with respect to some norm) and if was indeed bounded on (as a subspace) it would admit a bounded extension defined on and the question is asking me to show that it is impossible? Is the metric induced by the given norm defined ? I'm really confused, any help is appreciated.","C'[a,b] C^1[a,b] J=[a,b] ||x||=\max_{t\in J}|x(t)|+\max_{t\in J}|x'(t)| f(x)=x'(c) c=(a+b)/2 C'[a,b] f C[a,b] f f C^1[a,b] [a,b] C[a,b] f C^1[a,b] \hat{f} C[a,b] C[a,b]","['functional-analysis', 'metric-spaces']"
89,"Characterizing smooth, square-integrable functions on $(0,1]$","Characterizing smooth, square-integrable functions on","(0,1]","Is there a simple way to characterize the functions in $C^\infty((0,1])\cap L^2((0,1])$ ? That is, given a function $f(t)\in C^\infty((0,1])$ , is there a necessary/sufficient condition I can check to see if it's square integrable?  An example of such a function is $f(t)=t^{-1/3}$ , which diverges as $t\to0$ but satisfies $\int_0^1 f(t)^2\,dt=3<\infty.$ Notes: I was hoping to prove something to the effect that $f(t)$ is square integrable if and only if $$\lim_{t\to0} \frac{f(t)^2}{t^p}=L < \infty$$ for some $p>-1$ .  This is certainily a sufficient condition by the "" limit comparison test "" for improper integrals, but I'm not sure if it's necessary.  (But, I also couldn't find a simple counterexample!)","Is there a simple way to characterize the functions in ? That is, given a function , is there a necessary/sufficient condition I can check to see if it's square integrable?  An example of such a function is , which diverges as but satisfies Notes: I was hoping to prove something to the effect that is square integrable if and only if for some .  This is certainily a sufficient condition by the "" limit comparison test "" for improper integrals, but I'm not sure if it's necessary.  (But, I also couldn't find a simple counterexample!)","C^\infty((0,1])\cap L^2((0,1]) f(t)\in C^\infty((0,1]) f(t)=t^{-1/3} t\to0 \int_0^1 f(t)^2\,dt=3<\infty. f(t) \lim_{t\to0} \frac{f(t)^2}{t^p}=L < \infty p>-1","['real-analysis', 'functional-analysis', 'convergence-divergence', 'improper-integrals']"
90,$c$ and $c_0$ are not isometrically isomorphic,and  are not isometrically isomorphic,c c_0,"I'm learning that the two Banach Spaces, $c$ and $c_0$ are not Isometrically Isomorphic. Where $c$ = The set of all converging sequences. $c_0$ = The set of sequences converging to zero. Seems like the reason behind this is that the closed unit ball in two spaces have a different behavior. That is in $c$ they have got ""extreme points"" and in $c_0$ they do not. I'm a bit confused about this word ""extreme point"". First I thought that they were the boundary points but they cannot be because for sequences like $a=(1,0,0,0,0,...)$ in both $c_0$ and $c$ , $||a||=\{\sup|a_n|: n\geq1\}=1$ . So it is a boundary point of the closed balls in both spaces. Could some one help me out explaining about the extreme points in the given closed unit balls and how to determine whether they have got such points or not","I'm learning that the two Banach Spaces, and are not Isometrically Isomorphic. Where = The set of all converging sequences. = The set of sequences converging to zero. Seems like the reason behind this is that the closed unit ball in two spaces have a different behavior. That is in they have got ""extreme points"" and in they do not. I'm a bit confused about this word ""extreme point"". First I thought that they were the boundary points but they cannot be because for sequences like in both and , . So it is a boundary point of the closed balls in both spaces. Could some one help me out explaining about the extreme points in the given closed unit balls and how to determine whether they have got such points or not","c c_0 c c_0 c c_0 a=(1,0,0,0,0,...) c_0 c ||a||=\{\sup|a_n|: n\geq1\}=1","['functional-analysis', 'banach-spaces']"
91,Proof of Hahn Banach Theorem corollary: the dual of a LCS sperates points,Proof of Hahn Banach Theorem corollary: the dual of a LCS sperates points,,"I am having troubles in understanding the proof of some corollaries to the Hahnn Banach Theorem, from Treves' ""Topological Vector Space, Distribution and Kernels"" Now summing up my doubts: In corollary 1, where is the hypothesis of local convexity exploited? Why $E/M_0$ Hausdorff automatically implies $f'$ continuous? In corollary 2 where is the hypothesys of Hausdorfness used ? The only reason I can come up with, adapting the proof of Corollary 1, as the author suggests, is that if $E$ is Hausdorff, then $$E/Cl\{0\}=E/\{0\}=E$$ , and hence the proof is simplified, we do not have to mess with the projection $\phi$ . But why is it essential? Finally, Schechter in his Handbook of Analysis and its foundations, claims the Corollary 2 is actually equivalent , and hence not properly a corollary,  to the Hahn Banach theorem.  Any direct way to see this ? For reference, I am using the following two versions of Hahn Banach (those of Treves). [(HB1): Geometric Hahn Banach Theorem ] Let E be a TVS, M a linear manifold in E and A a nonempty convex open subset of E such that $M\cap A=\emptyset$ . Then there exists an hyperplane containing M and not intersecting A. [(HB2): Analytical Hahn Banach Theorem] Let E be a vector space, p  a seminorm on E and M a subspace of E. If f is a linear form on M such that $|f(x)|\leq p(x)\ \forall x\in M$ then there exist a linear extension to E such that $|f_1(x)|\leq p(x)\ \forall x\in E$","I am having troubles in understanding the proof of some corollaries to the Hahnn Banach Theorem, from Treves' ""Topological Vector Space, Distribution and Kernels"" Now summing up my doubts: In corollary 1, where is the hypothesis of local convexity exploited? Why Hausdorff automatically implies continuous? In corollary 2 where is the hypothesys of Hausdorfness used ? The only reason I can come up with, adapting the proof of Corollary 1, as the author suggests, is that if is Hausdorff, then , and hence the proof is simplified, we do not have to mess with the projection . But why is it essential? Finally, Schechter in his Handbook of Analysis and its foundations, claims the Corollary 2 is actually equivalent , and hence not properly a corollary,  to the Hahn Banach theorem.  Any direct way to see this ? For reference, I am using the following two versions of Hahn Banach (those of Treves). [(HB1): Geometric Hahn Banach Theorem ] Let E be a TVS, M a linear manifold in E and A a nonempty convex open subset of E such that . Then there exists an hyperplane containing M and not intersecting A. [(HB2): Analytical Hahn Banach Theorem] Let E be a vector space, p  a seminorm on E and M a subspace of E. If f is a linear form on M such that then there exist a linear extension to E such that",E/M_0 f' E E/Cl\{0\}=E/\{0\}=E \phi M\cap A=\emptyset |f(x)|\leq p(x)\ \forall x\in M |f_1(x)|\leq p(x)\ \forall x\in E,"['functional-analysis', 'proof-explanation', 'topological-vector-spaces', 'duality-theorems', 'hahn-banach-theorem']"
92,Covering a set with $N$ balls of common minimal(!) radius (Existence of such a covering),Covering a set with  balls of common minimal(!) radius (Existence of such a covering),N,"Let $X$ be a Banach space, and denote by $B_r (x)$ the closed ball of radius $r > 0$ around $x \in X$ . Furthermore, let $A \subset X$ be compact and $N \in \Bbb{N}$ . I am interested in ""optimally"" covering $A$ by $N$ balls, i.e,. with as small radius as possible. More precisely, define $$   r_0   := \inf \Big\{             r > 0             \colon             \exists \, x_1,\dots,x_N \in X \text{ such that } A \subset \bigcup_{i=1}^N B_r (x_i)           \Big\}, $$ and assume that $r_0 > 0$ . I would like to know whether there necessarily exist $x_1,\dots,x_N \in X$ such that $A \subset \bigcup_{i=1}^N B_{r_0} (x_i)$ .   In other words, I would like to know if the infimum above is actually a minimum. Note I am taking the $x_i$ from the ""surrounding"" space $X$ , not from the compact set $A$ . I can prove the claim in case that $X$ is reflexive (even only assuming that $A$ is bounded), but I am not sure whether it is true for more general Banach spaces. I will give my proof for the reflexive case below, in case one can either generalize it, or use it to get an idea for a counterexample. Proof for the reflexive case: Choose a sequence $r_n \to r_0$ such that for each $n$ there are $x_1^n,\dots,x_N^n \subset X$ satisfying $A \subset \bigcup_{i=1}^N B_{r_n}(x_i^n)$ . If $B_{r_n} (x_i^n) \cap A = \emptyset$ for some $i,n$ , replace $x_i^n$ by zero. Note that this retains the property $A \subset \bigcup_{i=1}^N B_{r_n}(x_i^n)$ . Since $A$ and the sequence $(r_n)_{n}$ are bounded, there is $R > 0$ such that $\| x \| \leq R$ and $r_n \leq R$ for all $x \in A$ and $n \in \Bbb{N}$ : There are now two cases for each $i,n$ : 1) There is some $x \in A \cap B_{r_n} (x_i^n)$ ,    and hence $\| x_i^n \| \leq \| x_i^n - x \| + \| x \| \leq r_n + R \leq 2R$ . 2) There is no $x \in A \cap B_{r_n} (x_i^n)$ , and hence $x_i^n$ , whence $\| x_i^n \| \leq 2R$ . Therefore, each of the sequences $(x_i^n)_{n \in \Bbb{N}} \subset X$ is bounded. Since $X$ is assumed to be reflexive, we can choose a common subsequence (which I will ignore in the notation below) such that $x_i^n \to x_i$ weakly for all $i = 1,\dots,N$ . Now, let $x \in A$ be arbitrary. For each $n \in \Bbb{N}$ , there is $i_n \in \{1,\dots,N\}$ satisfying $\| x - x_i^n \| \leq r_n$ . Next, there is $\ell \in \{1,\dots,N\}$ such that $i_n = \ell$ for infinitely many $n \in \Bbb{N}$ , say for $n = n_m$ with $n_m \to \infty$ . Since $x - x_i^{n_m} \to x - x_i$ weakly and since the norm is lower semicontinuous with respect to weak convergence, we see that $\| x - x_\ell \| \leq \liminf_{m \to \infty} \| x - x_i^{n_m} \| \leq \liminf_{m \to \infty} r_{n_m} = r_0$ . Since this holds for any $x \in A$ , we get $A \subset \bigcup_{\ell=1}^N B_{r_0} (x_\ell)$ , as desired.","Let be a Banach space, and denote by the closed ball of radius around . Furthermore, let be compact and . I am interested in ""optimally"" covering by balls, i.e,. with as small radius as possible. More precisely, define and assume that . I would like to know whether there necessarily exist such that .   In other words, I would like to know if the infimum above is actually a minimum. Note I am taking the from the ""surrounding"" space , not from the compact set . I can prove the claim in case that is reflexive (even only assuming that is bounded), but I am not sure whether it is true for more general Banach spaces. I will give my proof for the reflexive case below, in case one can either generalize it, or use it to get an idea for a counterexample. Proof for the reflexive case: Choose a sequence such that for each there are satisfying . If for some , replace by zero. Note that this retains the property . Since and the sequence are bounded, there is such that and for all and : There are now two cases for each : 1) There is some ,    and hence . 2) There is no , and hence , whence . Therefore, each of the sequences is bounded. Since is assumed to be reflexive, we can choose a common subsequence (which I will ignore in the notation below) such that weakly for all . Now, let be arbitrary. For each , there is satisfying . Next, there is such that for infinitely many , say for with . Since weakly and since the norm is lower semicontinuous with respect to weak convergence, we see that . Since this holds for any , we get , as desired.","X B_r (x) r > 0 x \in X A \subset X N \in \Bbb{N} A N 
  r_0
  := \inf \Big\{
            r > 0
            \colon
            \exists \, x_1,\dots,x_N \in X \text{ such that } A \subset \bigcup_{i=1}^N B_r (x_i)
          \Big\},
 r_0 > 0 x_1,\dots,x_N \in X A \subset \bigcup_{i=1}^N B_{r_0} (x_i) x_i X A X A r_n \to r_0 n x_1^n,\dots,x_N^n \subset X A \subset \bigcup_{i=1}^N B_{r_n}(x_i^n) B_{r_n} (x_i^n) \cap A = \emptyset i,n x_i^n A \subset \bigcup_{i=1}^N B_{r_n}(x_i^n) A (r_n)_{n} R > 0 \| x \| \leq R r_n \leq R x \in A n \in \Bbb{N} i,n x \in A \cap B_{r_n} (x_i^n) \| x_i^n \| \leq \| x_i^n - x \| + \| x \| \leq r_n + R \leq 2R x \in A \cap B_{r_n} (x_i^n) x_i^n \| x_i^n \| \leq 2R (x_i^n)_{n \in \Bbb{N}} \subset X X x_i^n \to x_i i = 1,\dots,N x \in A n \in \Bbb{N} i_n \in \{1,\dots,N\} \| x - x_i^n \| \leq r_n \ell \in \{1,\dots,N\} i_n = \ell n \in \Bbb{N} n = n_m n_m \to \infty x - x_i^{n_m} \to x - x_i \| x - x_\ell \| \leq \liminf_{m \to \infty} \| x - x_i^{n_m} \| \leq \liminf_{m \to \infty} r_{n_m} = r_0 x \in A A \subset \bigcup_{\ell=1}^N B_{r_0} (x_\ell)","['functional-analysis', 'geometry', 'optimization', 'banach-spaces', 'reflexive-space']"
93,Use Fatou Lemma to show that $f$ takes real values almost everywhere.,Use Fatou Lemma to show that  takes real values almost everywhere.,f,"Let $(f_n)$ be a sequence in $L^p$ such that for each positive integer $n$ , $ \| f_{n+1}-f_n\|_{p} <\frac 1{2^n}  $ .   Define $f: X \to [0,\infty]$ with $$ f(x)= \sum_{n=1}^\infty| f_{n+1}(x)-f_n(x)|. $$ Use Fatou Lemma to show that $f$ takes real values almost everywhere. My thoughts: We must show the existence of $A$ such that $\mu(A)=0$ and for all $x\in A^C$ , $f\in\mathbb R$ using Fatous Lemma which states $$ \int_X\liminf_nf_n \le\liminf_n\int_X f_n. $$ My idea taking pieces of the completeness proof of $L^p$ is that we have that the series $f(x)=\displaystyle\sum_{n=1}^\infty\vert f_{n+1}(x)-f_n(x)\vert$ converges so $f(x)=\displaystyle\sum_{n=1}^\infty\vert f_{n+1}(x)-f_n(x)\vert<\infty$ and this holds for all $x\in X$ and then how will I define the set $A$ ? I am not using at all Fatou Lemma because I don't know how. [Added later:] I would also like to understand steps of the proof in Alex R.'s answer below. It is shown that $$\int_A|f(x)|^pd\mu\leq \liminf_m\int_A|F_m(x)|^p dx\leq\liminf_m\sum_{n=1}^m\frac{1}{2^{pn}}d\mu<\infty.$$ There are a lot of missing steps. I tried to fill. $\displaystyle\int_A\vert f(x)\vert^pdx =\int_A|\liminf_mF_m(x)|^pdx=\int_A\liminf_m|F_m(x)|^pdx\le\liminf_m\int_A|F_m(x)|^pdx =\liminf_m\int|\sum^m_{n=1}|f_{n+1}(x)-f_n(x)||^pdx \fbox{=}\liminf_m\sum^m_{n=1}\int_A|f_{n+1}(x)-f_n(x)|^pdx =\liminf_m\sum^m_{n=1}||f_{n+1}(x)-f_n(x)||_p^p\le\liminf_m\sum^m_{n=1}\frac{1}{2^{np}}\fbox=?$ Question1: Assuming the equalities and inequalities are correct, Why is the second equality, the boxed equality and what is equal in the last boxed equality? It is also shown that Taking $A$ to be $\mathbb{R}$ , it follows that $\int_A|f(x)|^pd\mu<\infty$ which implies $\mu(\{|f|=\infty\})=0$ . Question2: Should not have been written as Take $A$ to be $\mathbb R.$ From all the arguments above (and not only $A=\mathbb R$ ), it follows that $\int_A|f(x)|^pd\mu<\infty$ which implies $\mu(\{|f|=\infty\})=0$ ?? Seems like as it originally stands, the affirmation depends only on $A=\mathbb R$ . But it is independent of taking $A$ as $\mathbb R$ . Am I correct?","Let be a sequence in such that for each positive integer , .   Define with Use Fatou Lemma to show that takes real values almost everywhere. My thoughts: We must show the existence of such that and for all , using Fatous Lemma which states My idea taking pieces of the completeness proof of is that we have that the series converges so and this holds for all and then how will I define the set ? I am not using at all Fatou Lemma because I don't know how. [Added later:] I would also like to understand steps of the proof in Alex R.'s answer below. It is shown that There are a lot of missing steps. I tried to fill. Question1: Assuming the equalities and inequalities are correct, Why is the second equality, the boxed equality and what is equal in the last boxed equality? It is also shown that Taking to be , it follows that which implies . Question2: Should not have been written as Take to be From all the arguments above (and not only ), it follows that which implies ?? Seems like as it originally stands, the affirmation depends only on . But it is independent of taking as . Am I correct?","(f_n) L^p n 
\| f_{n+1}-f_n\|_{p}
<\frac 1{2^n} 
 f: X \to [0,\infty] 
f(x)= \sum_{n=1}^\infty| f_{n+1}(x)-f_n(x)|.
 f A \mu(A)=0 x\in A^C f\in\mathbb R 
\int_X\liminf_nf_n
\le\liminf_n\int_X f_n.
 L^p f(x)=\displaystyle\sum_{n=1}^\infty\vert f_{n+1}(x)-f_n(x)\vert f(x)=\displaystyle\sum_{n=1}^\infty\vert f_{n+1}(x)-f_n(x)\vert<\infty x\in X A \int_A|f(x)|^pd\mu\leq \liminf_m\int_A|F_m(x)|^p dx\leq\liminf_m\sum_{n=1}^m\frac{1}{2^{pn}}d\mu<\infty. \displaystyle\int_A\vert f(x)\vert^pdx
=\int_A|\liminf_mF_m(x)|^pdx=\int_A\liminf_m|F_m(x)|^pdx\le\liminf_m\int_A|F_m(x)|^pdx
=\liminf_m\int|\sum^m_{n=1}|f_{n+1}(x)-f_n(x)||^pdx
\fbox{=}\liminf_m\sum^m_{n=1}\int_A|f_{n+1}(x)-f_n(x)|^pdx
=\liminf_m\sum^m_{n=1}||f_{n+1}(x)-f_n(x)||_p^p\le\liminf_m\sum^m_{n=1}\frac{1}{2^{np}}\fbox=? A \mathbb{R} \int_A|f(x)|^pd\mu<\infty \mu(\{|f|=\infty\})=0 A \mathbb R. A=\mathbb R \int_A|f(x)|^pd\mu<\infty \mu(\{|f|=\infty\})=0 A=\mathbb R A \mathbb R","['real-analysis', 'functional-analysis', 'measure-theory', 'proof-explanation', 'lp-spaces']"
94,Equivalent operator norm on dense subset,Equivalent operator norm on dense subset,,"Let $X$ and $Y$ be normed vector spaces and let $X_{0}\subset X$ be a dense subspace. Further, let $T:X\longrightarrow Y$ be a bounded, linear operator. Prove that $||T||_{L(X,Y)}:=\underset{x\in X,\\||x||=1}{sup}||Tx||= \underset{x\in X_{0},\\||x||=1}{sup}||Tx||$ The strategy is to prove „ $\leq$ “ in both directions, whereas $||T||\geq \underset{x\in X_{0},\\||x||=1}{sup}||Tx| $ is clear because $X_{0}\subset X$ . However, I do not manage to show the reversed inequality, namely $||T||\leq \underset{x\in X_{0},\\||x||=1}{sup}||Tx||$ , because I don‘t see how to use the density property: for all $\epsilon>0$ and for all $x\in X$ there exists $y\in X_{0}$ such that $||x-y||<\epsilon$ . Can anyone help me out?","Let and be normed vector spaces and let be a dense subspace. Further, let be a bounded, linear operator. Prove that The strategy is to prove „ “ in both directions, whereas is clear because . However, I do not manage to show the reversed inequality, namely , because I don‘t see how to use the density property: for all and for all there exists such that . Can anyone help me out?","X Y X_{0}\subset X T:X\longrightarrow Y ||T||_{L(X,Y)}:=\underset{x\in X,\\||x||=1}{sup}||Tx||= \underset{x\in X_{0},\\||x||=1}{sup}||Tx|| \leq ||T||\geq \underset{x\in X_{0},\\||x||=1}{sup}||Tx|  X_{0}\subset X ||T||\leq \underset{x\in X_{0},\\||x||=1}{sup}||Tx|| \epsilon>0 x\in X y\in X_{0} ||x-y||<\epsilon","['functional-analysis', 'normed-spaces']"
95,Distributional derivative of Weierstrass function,Distributional derivative of Weierstrass function,,"How can we compute the distributional derivative of the Weierstrass function $$W(x) =\sum_{k=1}^\infty \lambda^{(s-2)k}\sin(\lambda^k x)$$ where $s \in (0,2)$ and $\lambda$ are fixed parameters? We know that the Weierstrass function is nowhere differentiable. This implies that it does not have a weak derivative. However, since $W \in L^1_{loc}$ , we can consider the associated distribution $T_W$ and compute its distributional derivative. I'm having troubles doing that computation because of the series representation of $W$ .","How can we compute the distributional derivative of the Weierstrass function where and are fixed parameters? We know that the Weierstrass function is nowhere differentiable. This implies that it does not have a weak derivative. However, since , we can consider the associated distribution and compute its distributional derivative. I'm having troubles doing that computation because of the series representation of .","W(x) =\sum_{k=1}^\infty \lambda^{(s-2)k}\sin(\lambda^k x) s \in (0,2) \lambda W \in L^1_{loc} T_W W","['calculus', 'functional-analysis', 'measure-theory', 'sobolev-spaces', 'distribution-theory']"
96,Find a norm in the dual space,Find a norm in the dual space,,"Let $X$ be a normed space and $Y$ a linear subspace of $X$ . We define $$Y^{\perp}=\{f\in X^*: f(y)=0, \; \forall y\in Y\}$$ and $$\|f\|_Y=\sup\{|f(y)|: y\in Y, \; \|y\|=1\}.$$ Prove that $$\|f\|_Y=\inf\{\|f-g\|: g\in Y^{\perp}\}$$ First of all, given $f\in X^*\backslash Y^\perp$ , then for any $g\in Y^\perp$ we get that \begin{equation*} \begin{split} \|f-g\|&=\sup\{|f(x)-g(x)|: x\in X, \; \|x\|=1\}\\ &\geq\sup\{|f(y)+g(y)|: y\in Y, \; \|y\|=1\} \\ &= \sup\{|f(y)|: y\in Y, \; \|y\|=1\}\\ &=\|f\|_Y \end{split} \end{equation*} As $g\in Y^\perp$ was arbitrary, we find that $$\|f\|_Y\leq\inf\{\|f-g\|: g\in Y^{\perp}\}$$ How can I prove the other inequality?","Let be a normed space and a linear subspace of . We define and Prove that First of all, given , then for any we get that As was arbitrary, we find that How can I prove the other inequality?","X Y X Y^{\perp}=\{f\in X^*: f(y)=0, \; \forall y\in Y\} \|f\|_Y=\sup\{|f(y)|: y\in Y, \; \|y\|=1\}. \|f\|_Y=\inf\{\|f-g\|: g\in Y^{\perp}\} f\in X^*\backslash Y^\perp g\in Y^\perp \begin{equation*}
\begin{split}
\|f-g\|&=\sup\{|f(x)-g(x)|: x\in X, \; \|x\|=1\}\\
&\geq\sup\{|f(y)+g(y)|: y\in Y, \; \|y\|=1\} \\
&= \sup\{|f(y)|: y\in Y, \; \|y\|=1\}\\
&=\|f\|_Y
\end{split}
\end{equation*} g\in Y^\perp \|f\|_Y\leq\inf\{\|f-g\|: g\in Y^{\perp}\}","['functional-analysis', 'hahn-banach-theorem']"
97,Weak$^*$ convergence in $L^1$,Weak convergence in,^* L^1,"Suppose we have a sequence $\{f_n\}$ of $L^1$ functions such that $||f_n||_1 \leq K_1$ , then viewing $L^1(\mathbb{R}) \subset \mathcal{M}(\mathbb{R})$ where $\mathcal{M}(\mathbb{R})$ is the space of Radon measure which is isomorphic to the dual space of $C_c(\mathbb{R})$ , we can extract a subsequence $\{{f_n}_k\}$ which converges to a Radon measure in the weak $^*$ topology on $\mathcal{M}(\mathbb{R})$ . Suppose in addition we have $$\int_{\mathbb{R}}f_n=K_2, \forall n \in \mathbb{N}$$ and $f_n \rightarrow f$ pointwise almost everywhere in $\mathbb{R}/\{0\} $ Then can we say that $\exists C \in \mathbb{R}$ such that $$\int_{\mathbb{R}} {f_n}_k\Phi(x)dx=\int_{\mathbb{R}} f(x)\Phi(x)dx+ C\Phi(0),$$ i.e the weak $^*$ limit is of the subsequence is of the form $f+C\delta_{0}$ ?","Suppose we have a sequence of functions such that , then viewing where is the space of Radon measure which is isomorphic to the dual space of , we can extract a subsequence which converges to a Radon measure in the weak topology on . Suppose in addition we have and pointwise almost everywhere in Then can we say that such that i.e the weak limit is of the subsequence is of the form ?","\{f_n\} L^1 ||f_n||_1 \leq K_1 L^1(\mathbb{R}) \subset \mathcal{M}(\mathbb{R}) \mathcal{M}(\mathbb{R}) C_c(\mathbb{R}) \{{f_n}_k\} ^* \mathcal{M}(\mathbb{R}) \int_{\mathbb{R}}f_n=K_2, \forall n \in \mathbb{N} f_n \rightarrow f \mathbb{R}/\{0\}  \exists C \in \mathbb{R} \int_{\mathbb{R}} {f_n}_k\Phi(x)dx=\int_{\mathbb{R}} f(x)\Phi(x)dx+ C\Phi(0), ^* f+C\delta_{0}","['functional-analysis', 'analysis', 'measure-theory', 'weak-convergence']"
98,Reference on Lipschitz property of the infimum of a family of Lipschitz functions,Reference on Lipschitz property of the infimum of a family of Lipschitz functions,,"I can prove the following fact:  the infimum, or supremum, of any family of L-Lipschitz functions is L-Lipschitz, as long as the constant L is fixed. However, since this is a very basic result, I am interested in a reference where it is proved. Any suggestions?","I can prove the following fact:  the infimum, or supremum, of any family of L-Lipschitz functions is L-Lipschitz, as long as the constant L is fixed. However, since this is a very basic result, I am interested in a reference where it is proved. Any suggestions?",,"['functional-analysis', 'reference-request', 'nonlinear-optimization', 'lipschitz-functions', 'non-convex-optimization']"
99,About weak convergence in $L^{\infty}$,About weak convergence in,L^{\infty},"doing my homework I'm dealing with this: Let, for all $n\in \mathbb{N} \quad f_n(t) := e^{-nt^2}, \quad t \in [-1,1]$ Show that 1) $f_n \overset{\ast}{\rightharpoonup} 0$ in $L^\infty(-1,1)$ 2) $f_n$ does not converge weakly to $0$ in $L^\infty (-1,1)$ So I did 1) simply considering \begin{equation} |f_n(x)g(x)| \le|g(x)| \quad \forall g \in L^1(-1,1) \end{equation} So the result follows easily from the dominated convergence theorem. But for 2) I know that given $f_n, f \in X^*$ \begin{equation} f_n \rightharpoonup f \quad \Leftrightarrow \quad \phi(f_n)\rightarrow \phi(f) \quad \forall \phi \in X^{**} \end{equation} But how can I identify the dual of $L^\infty$ to solve this?","doing my homework I'm dealing with this: Let, for all Show that 1) in 2) does not converge weakly to in So I did 1) simply considering So the result follows easily from the dominated convergence theorem. But for 2) I know that given But how can I identify the dual of to solve this?","n\in \mathbb{N} \quad f_n(t) := e^{-nt^2}, \quad t \in [-1,1] f_n \overset{\ast}{\rightharpoonup} 0 L^\infty(-1,1) f_n 0 L^\infty (-1,1) \begin{equation}
|f_n(x)g(x)| \le|g(x)| \quad \forall g \in L^1(-1,1)
\end{equation} f_n, f \in X^* \begin{equation}
f_n \rightharpoonup f \quad \Leftrightarrow \quad \phi(f_n)\rightarrow \phi(f) \quad \forall \phi \in X^{**}
\end{equation} L^\infty","['functional-analysis', 'weak-convergence', 'dual-spaces']"
