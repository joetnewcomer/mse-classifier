,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Pseudo-periodicity of analytic self-maps of the upper half-plane,Pseudo-periodicity of analytic self-maps of the upper half-plane,,"I have a couple of questions, in increasing order of softness: Consider an analytic map of the upper-half plane into itself $f: \mathbb{H}\to\mathbb{H}$ . When this function is $1$ -periodic, i.e., $f(z+1) = f(z)$ , then one can expand $f$ into a Fourier series (sometimes called the $q$ -expansion in this context). I'm interested in functions that have a ""pseudo-periodicity"" property, say, $f(z+3)=f(z)+1$ . Is there anything that can be said about the form $f$ must take in this case? More generally, I am interested in analytic maps $f: \mathbb{H}\to\mathbb{H}$ which satisfy a ""pseudo-equivariance"" (is there a better name for this?) condition: given a finite index subgroup $H<{\rm PSL}(2,\mathbb{Z})$ , there is some virtual endomorphism* $\phi: H\to G$ such that $$f(g.z) = \phi(g).f(z)$$ for every $g\in H$ . Basically this will correspond to a set of functional equations that $f$ must satisfy. My general hope is that if one is given sufficiently many of these functional equations, then the map $f$ will be more or less determined. My reasoning is that if one can determine the fundamental domain of $f$ under the action of $H$ , and also determine the image of this domain, then it should be possible to determine the map everywhere else as well. The theory of modular forms seemed like a good starting place for results along these lines, but the transformation condition for modular forms is quite different and I don't think there's a neat trick to transfer my problem into the modular form setting. Does anyone know any theories/papers which might be relevant here? I feel like problems of this sort have probably been studied before, but my google skills are failing me. *A virtual endomorphism of a group $G$ is a homomorphism from a subgroup of finite index $H \leq G$ into $G$ .","I have a couple of questions, in increasing order of softness: Consider an analytic map of the upper-half plane into itself . When this function is -periodic, i.e., , then one can expand into a Fourier series (sometimes called the -expansion in this context). I'm interested in functions that have a ""pseudo-periodicity"" property, say, . Is there anything that can be said about the form must take in this case? More generally, I am interested in analytic maps which satisfy a ""pseudo-equivariance"" (is there a better name for this?) condition: given a finite index subgroup , there is some virtual endomorphism* such that for every . Basically this will correspond to a set of functional equations that must satisfy. My general hope is that if one is given sufficiently many of these functional equations, then the map will be more or less determined. My reasoning is that if one can determine the fundamental domain of under the action of , and also determine the image of this domain, then it should be possible to determine the map everywhere else as well. The theory of modular forms seemed like a good starting place for results along these lines, but the transformation condition for modular forms is quite different and I don't think there's a neat trick to transfer my problem into the modular form setting. Does anyone know any theories/papers which might be relevant here? I feel like problems of this sort have probably been studied before, but my google skills are failing me. *A virtual endomorphism of a group is a homomorphism from a subgroup of finite index into .","f: \mathbb{H}\to\mathbb{H} 1 f(z+1) = f(z) f q f(z+3)=f(z)+1 f f: \mathbb{H}\to\mathbb{H} H<{\rm PSL}(2,\mathbb{Z}) \phi: H\to G f(g.z) = \phi(g).f(z) g\in H f f f H G H \leq G G","['complex-analysis', 'reference-request', 'soft-question', 'functional-equations', 'modular-forms']"
1,How to construct a locally injective entire holomorphic function such that the modulus is axially symmetric?,How to construct a locally injective entire holomorphic function such that the modulus is axially symmetric?,,"Let $f$ be an entire holomorphic function, with $f'$ vanishing nowhere in the complex plane. Is it possible to construct such a function such that $|f(z)|$ is symmetric with respect both $x$ -axis and $y$ -axis? My attempt is trying to find a function of the form $f(z)=ze^{g(z^2)}$ , where $g$ is transcendental holomorphic and the coefficients of Taylor expansion of $g$ are real. Such function satisfies $|f(z)|=|f(-z)|=|f(\bar{z})|$ , but in order that $f'$ is nowhere vanishing, we need to guarantee that $1+2z^2g'(z^2)$ has no zeros. I've no idea how to fufill this step. Maybe we cannot construct in this way, because if $1+2z^2 g'(z^2)$ has no zeros, then there exists another holomorphic function $h$ such that $1+2z^2g'(z^2)=e^{h(z)}$ . This seems to be impossible. Any ideas and comments are fully apreciated.","Let be an entire holomorphic function, with vanishing nowhere in the complex plane. Is it possible to construct such a function such that is symmetric with respect both -axis and -axis? My attempt is trying to find a function of the form , where is transcendental holomorphic and the coefficients of Taylor expansion of are real. Such function satisfies , but in order that is nowhere vanishing, we need to guarantee that has no zeros. I've no idea how to fufill this step. Maybe we cannot construct in this way, because if has no zeros, then there exists another holomorphic function such that . This seems to be impossible. Any ideas and comments are fully apreciated.",f f' |f(z)| x y f(z)=ze^{g(z^2)} g g |f(z)|=|f(-z)|=|f(\bar{z})| f' 1+2z^2g'(z^2) 1+2z^2 g'(z^2) h 1+2z^2g'(z^2)=e^{h(z)},['complex-analysis']
2,Why is complex derivative direction independent,Why is complex derivative direction independent,,"Visual complex analysis by Tristan Needham provides a great intuition by explaining the beauty of complex analysis. I have a question regarding the complex derivative. The image above shows a function $w(z)$ from $\mathbb{C}$ to $\mathbb{C}$ . When the complex number $z$ , is moved to $z+dz_{1}$ or $z+dz_2$ the corresponding values are $w(z+dz_1)$ and $w(z+dz_2)$ . Let's denote $dw_1=w(z+dz_1)-w(z)$ and similar thing with $dw_2$ . In that book complex derivative is defined, as a complex number such that $$dw_1=w'(z)dz_1$$ $$dw_2=w'(z)dz_2$$ .... My question:- Now, I am unable to convince myself about why $dz_1$ and $dz_2$ are multiplied with the same complex number to get $dw_1$ and $dw_2$ respectively.","Visual complex analysis by Tristan Needham provides a great intuition by explaining the beauty of complex analysis. I have a question regarding the complex derivative. The image above shows a function from to . When the complex number , is moved to or the corresponding values are and . Let's denote and similar thing with . In that book complex derivative is defined, as a complex number such that .... My question:- Now, I am unable to convince myself about why and are multiplied with the same complex number to get and respectively.",w(z) \mathbb{C} \mathbb{C} z z+dz_{1} z+dz_2 w(z+dz_1) w(z+dz_2) dw_1=w(z+dz_1)-w(z) dw_2 dw_1=w'(z)dz_1 dw_2=w'(z)dz_2 dz_1 dz_2 dw_1 dw_2,"['complex-analysis', 'complex-numbers']"
3,Understanding difference between a distinguished boundary and 'normal' boundary in several complex variables,Understanding difference between a distinguished boundary and 'normal' boundary in several complex variables,,"I am reading through Tasty Bits of Several Complex Variables and I come across the term distinguished boundary . It seems a distinguished boundary is different from a normal boundary as the author explains the latter has fewer dimensions than the latter. What is also confusing me is the image of the bidisk where I can't tell the difference between the distinguished boundary and the normal boundary? Is it that the distinguished boundary is illustrated as the bold lines/edges of the image and while the boundary cannot be fully represented on a 2D paper? Does the boundary include the shaded grey area whilst the distinguished boundary does not? Also the union of inside and outside of the donut confuses more. I feel i'm being short sighted here, can someone correct my vision?","I am reading through Tasty Bits of Several Complex Variables and I come across the term distinguished boundary . It seems a distinguished boundary is different from a normal boundary as the author explains the latter has fewer dimensions than the latter. What is also confusing me is the image of the bidisk where I can't tell the difference between the distinguished boundary and the normal boundary? Is it that the distinguished boundary is illustrated as the bold lines/edges of the image and while the boundary cannot be fully represented on a 2D paper? Does the boundary include the shaded grey area whilst the distinguished boundary does not? Also the union of inside and outside of the donut confuses more. I feel i'm being short sighted here, can someone correct my vision?",,"['complex-analysis', 'several-complex-variables', 'manifolds-with-boundary']"
4,Existence of Continuous Function on a Complex Region,Existence of Continuous Function on a Complex Region,,"I am working on the following problem: Let $\Omega = \mathbb C\backslash [-1,1]$ , i.e. deleting ``the line'' only, is there a function $f:\Omega\to \mathbb C$ such that $f$ satisfies $f(z)^2 = 1-z^2$ and is continuous on this region? My guess is that such a function would exist, but requires a piecewise definition. A candidate solution I have been working on is $f(z) = e^{\frac{1}{2}\log(1-z^2)}$ . The problem with this solution is having the domain, as I realize it is possible to have $1-z^2>1$ , where my solution is well-defined. Is there a way to work around this or should I try something else? Thanks!","I am working on the following problem: Let , i.e. deleting ``the line'' only, is there a function such that satisfies and is continuous on this region? My guess is that such a function would exist, but requires a piecewise definition. A candidate solution I have been working on is . The problem with this solution is having the domain, as I realize it is possible to have , where my solution is well-defined. Is there a way to work around this or should I try something else? Thanks!","\Omega = \mathbb C\backslash [-1,1] f:\Omega\to \mathbb C f f(z)^2 = 1-z^2 f(z) = e^{\frac{1}{2}\log(1-z^2)} 1-z^2>1","['complex-analysis', 'continuity']"
5,Cauchy's theorem and mathematica disagree? Integral involving branch points.,Cauchy's theorem and mathematica disagree? Integral involving branch points.,,"Consider the following integral: $$\int_{-\infty}^{\infty} \frac{dx}{\sqrt{x^2-2i\epsilon x -1}(x^2+1)}$$ where $\epsilon$ is an infinitesimal positive number. In the complex $x$ -plane, the integrand has two poles and two branch points. The poles are at $x=\pm i$ and the branch points are at $x=\pm 1 - i\epsilon$ . You can see that for $\epsilon>0$ the branch points are shifted away from the contour. The square-root function is taken to be the standard principal square-root function: the branch cut for $\sqrt{x}$ runs along $(-\infty,0]$ , and $$\sqrt{e^{i\left(\frac{\pi}{2}\pm\delta \right)}}=\pm i$$ This integral may be illustrated as follows: The green line represents the branch cut, across which the phase of the integrand is discontinuous. Because the integration contour (red line) does not pass through it, we should be able to solve this integral by closing the contour in the upper-half plane, picking up only the reside at $x=i$ . $$\begin{align} \int_{-\infty}^{\infty} \frac{dx}{\sqrt{x^2-2i\epsilon x -1}(x^2+1)}&=2\pi i \,\textrm{Res}\left(I(x);x=i\right)\\ &=2\pi i\frac{1}{i\sqrt{2} (2i)}\\ &=-\frac{i\pi}{\sqrt{2}}\\ &\approx -i\,2.22144 \end{align}$$ However when I integrate via Mathematica, I get a totally different answer. NIntegrate[1./(Sqrt[x^2 - 2.*I*0.0001*x - 1]*(x^2 + 1)), {x, -\[Infinity],\[Infinity]}, MaxRecursion -> 20, Method -> ""LocalAdaptive""]  > 1.24641 - 8.75132*10^-7 I So the answer Mathematica gives is approximately $1.246$ , which completely doesn't agree with the answer previously derived via the residue theorem. What's going on here? Which answer is wrong? Or are both answers wrong?","Consider the following integral: where is an infinitesimal positive number. In the complex -plane, the integrand has two poles and two branch points. The poles are at and the branch points are at . You can see that for the branch points are shifted away from the contour. The square-root function is taken to be the standard principal square-root function: the branch cut for runs along , and This integral may be illustrated as follows: The green line represents the branch cut, across which the phase of the integrand is discontinuous. Because the integration contour (red line) does not pass through it, we should be able to solve this integral by closing the contour in the upper-half plane, picking up only the reside at . However when I integrate via Mathematica, I get a totally different answer. NIntegrate[1./(Sqrt[x^2 - 2.*I*0.0001*x - 1]*(x^2 + 1)), {x, -\[Infinity],\[Infinity]}, MaxRecursion -> 20, Method -> ""LocalAdaptive""]  > 1.24641 - 8.75132*10^-7 I So the answer Mathematica gives is approximately , which completely doesn't agree with the answer previously derived via the residue theorem. What's going on here? Which answer is wrong? Or are both answers wrong?","\int_{-\infty}^{\infty} \frac{dx}{\sqrt{x^2-2i\epsilon x -1}(x^2+1)} \epsilon x x=\pm i x=\pm 1 - i\epsilon \epsilon>0 \sqrt{x} (-\infty,0] \sqrt{e^{i\left(\frac{\pi}{2}\pm\delta \right)}}=\pm i x=i \begin{align}
\int_{-\infty}^{\infty} \frac{dx}{\sqrt{x^2-2i\epsilon x -1}(x^2+1)}&=2\pi i \,\textrm{Res}\left(I(x);x=i\right)\\
&=2\pi i\frac{1}{i\sqrt{2} (2i)}\\
&=-\frac{i\pi}{\sqrt{2}}\\
&\approx -i\,2.22144
\end{align} 1.246","['integration', 'complex-analysis', 'complex-integration', 'mathematica']"
6,Is the following universal property of holomorphic functions true?,Is the following universal property of holomorphic functions true?,,"Suppose that we are given a smooth $f\in C^\infty(\mathbb{\mathbb{R}^2},\mathbb{C})$ and define $\iota$ to be the smooth embedding $$ \begin{aligned} \iota :\mathbb{R}^2&\to\mathbb{C}^2\\ (x,y)&\mapsto (x+iy,x-iy)=((x,y),(x,-y)). \end{aligned} $$ Is it true that there exists a unique holomorphic $\hat{f}\in\mathscr{O}({\mathbb{C}^2},\mathbb{C})$ such that $f=\hat{f}\circ \iota$ ? I suspect this universal property to be true, but my background on holomorphic functions in several variables is a bit weak and I could be wrong since I never saw it mentioned anywhere. Any hints or full answers are much appreciated. This question has occurred to me while studying complex manifolds. The aim is to make sense of the formal expression $f(z,\overline{z})$ used in that context for a smooth $f$ .","Suppose that we are given a smooth and define to be the smooth embedding Is it true that there exists a unique holomorphic such that ? I suspect this universal property to be true, but my background on holomorphic functions in several variables is a bit weak and I could be wrong since I never saw it mentioned anywhere. Any hints or full answers are much appreciated. This question has occurred to me while studying complex manifolds. The aim is to make sense of the formal expression used in that context for a smooth .","f\in C^\infty(\mathbb{\mathbb{R}^2},\mathbb{C}) \iota 
\begin{aligned}
\iota :\mathbb{R}^2&\to\mathbb{C}^2\\
(x,y)&\mapsto (x+iy,x-iy)=((x,y),(x,-y)).
\end{aligned}
 \hat{f}\in\mathscr{O}({\mathbb{C}^2},\mathbb{C}) f=\hat{f}\circ \iota f(z,\overline{z}) f","['complex-analysis', 'complex-geometry', 'several-complex-variables']"
7,Using residue theorem to calculate $\int_0^\infty \frac{dx}{x^\frac12 (1+x^2)}$ get a different value from the value obtained by classical method,Using residue theorem to calculate  get a different value from the value obtained by classical method,\int_0^\infty \frac{dx}{x^\frac12 (1+x^2)},"I'm trying to calculate the next integral by using residue theorem: $$ \int_0^\infty \frac{dx}{x^\frac12 (1+x^2)}. $$ Let $f(z)=1/(z^\frac12(1+z^2))$ and $\varepsilon,R$ be any real number such that $0 < \varepsilon < 1 < R$ . Choose the contour \begin{align} C_1&:z(t)=Re^{it}\quad(\theta \le t \le 2\pi-\theta)\\ C_2&:z(t)=t-i\varepsilon\quad(0\le t\le R\cos\theta) \\ C_3&:z(t)=\varepsilon e^{it}\quad(\frac\pi2\le t\le \frac{3\pi}2) \\ C_4&:z(t)=t+i\varepsilon\quad(0\le t\le R\cos\theta) \end{align} where $\theta= \arcsin\frac{\varepsilon}{R}$ . By residue theorem $$ \oint_{C_1-C_2-C_3+C_4}f(z)dz = 2\pi i\left( \operatorname{Res}(f,i) + \operatorname{Res}(f,-i)\right). $$ Here \begin{align} \operatorname{Res}(f,i) &= \lim_{z\to i}\frac{z-i}{z^\frac12 (1+z^2)} = \lim_{z\to i}\frac1{z^\frac12(z+i)} = \frac{1}{2i\cdot i^\frac12} = \frac{-1-i}{2\sqrt 2}, \\ \operatorname{Res}(f,-i)&= \lim_{z\to -i}\frac{z+i}{z^\frac12 (1+z^2)} = \lim_{z\to i}\frac1{z^\frac12(z-i)} = \frac1{-2i\cdot(-i)^\frac12} = \frac{-1+i}{2\sqrt2}. \end{align} Thus $$ \oint_{C_1-C_2-C_3+C_4}f(z)dz = -\frac{2\pi i}{\sqrt2}. $$ It is easy to check $\int_{C_1}f(z)dz,\int_{C_3}f(z)dz\to 0\ (\varepsilon\to0,R\to\infty)$ . And since $\exp(-\frac12(\ln|z|+i(\arg z+2\pi))) = -1/\sqrt z$ it obtains $$ \lim_{\substack{\varepsilon\to0\\R\to\infty}}\int_{C_4}f(z)dz = -\lim_{\substack{\varepsilon\to0\\R\to\infty}}\int_{C_2}f(z)dz = \int_0^\infty \frac{dx}{x^\frac12 (1+x^2)}. $$ Therefore $$ \int_0^\infty \frac{dx}{x^\frac12 (1+x^2)} = -\frac{\pi i}{\sqrt2}. $$ It is very curious that the integration of a real positive-valued function become a imaginary number. In fact, by using classical method, the integration will be $\pi/\sqrt2$ , which seems to be the true answer. Where is the mistake?","I'm trying to calculate the next integral by using residue theorem: Let and be any real number such that . Choose the contour where . By residue theorem Here Thus It is easy to check . And since it obtains Therefore It is very curious that the integration of a real positive-valued function become a imaginary number. In fact, by using classical method, the integration will be , which seems to be the true answer. Where is the mistake?","
\int_0^\infty \frac{dx}{x^\frac12 (1+x^2)}.
 f(z)=1/(z^\frac12(1+z^2)) \varepsilon,R 0 < \varepsilon < 1 < R \begin{align}
C_1&:z(t)=Re^{it}\quad(\theta \le t \le 2\pi-\theta)\\
C_2&:z(t)=t-i\varepsilon\quad(0\le t\le R\cos\theta) \\
C_3&:z(t)=\varepsilon e^{it}\quad(\frac\pi2\le t\le \frac{3\pi}2) \\
C_4&:z(t)=t+i\varepsilon\quad(0\le t\le R\cos\theta)
\end{align} \theta= \arcsin\frac{\varepsilon}{R} 
\oint_{C_1-C_2-C_3+C_4}f(z)dz = 2\pi i\left( \operatorname{Res}(f,i) + \operatorname{Res}(f,-i)\right).
 \begin{align}
\operatorname{Res}(f,i) &= \lim_{z\to i}\frac{z-i}{z^\frac12 (1+z^2)} = \lim_{z\to i}\frac1{z^\frac12(z+i)} = \frac{1}{2i\cdot i^\frac12} = \frac{-1-i}{2\sqrt 2}, \\
\operatorname{Res}(f,-i)&= \lim_{z\to -i}\frac{z+i}{z^\frac12 (1+z^2)} = \lim_{z\to i}\frac1{z^\frac12(z-i)} = \frac1{-2i\cdot(-i)^\frac12} = \frac{-1+i}{2\sqrt2}.
\end{align} 
\oint_{C_1-C_2-C_3+C_4}f(z)dz = -\frac{2\pi i}{\sqrt2}.
 \int_{C_1}f(z)dz,\int_{C_3}f(z)dz\to 0\ (\varepsilon\to0,R\to\infty) \exp(-\frac12(\ln|z|+i(\arg z+2\pi))) = -1/\sqrt z 
\lim_{\substack{\varepsilon\to0\\R\to\infty}}\int_{C_4}f(z)dz = -\lim_{\substack{\varepsilon\to0\\R\to\infty}}\int_{C_2}f(z)dz = \int_0^\infty \frac{dx}{x^\frac12 (1+x^2)}.
 
\int_0^\infty \frac{dx}{x^\frac12 (1+x^2)} = -\frac{\pi i}{\sqrt2}.
 \pi/\sqrt2","['complex-analysis', 'contour-integration', 'residue-calculus']"
8,Stuck proving that $\mid z\mid^2$ is not analytic in $z$,Stuck proving that  is not analytic in,\mid z\mid^2 z,"I am proving that $f(z) = \mid z\mid^2$ is not an analytic function. So i didn't want to use the Cauchy-Riemann condition or anything but i know that this particular function is diffentiable at only $z=0$ and nowhere else. So I check the differentiability at $z=0$ without any difficulty , just by using the definition of diffentiable complex valued function as in pic : Now I let a another arbitrary point $z_0 \neq 0 $ and check the differentiability at $z_0$ just by using the existence of this limit $$\lim_{z \to z_o} \frac{f(z)-f(z_0)}{ z - z_0}$$ $\implies$ $\lim_{z \to z0o} \frac{\mid{z}\mid^2-\mid{z_0}\mid^2}{ z - z_0}$ $\implies$ $\lim_{z \to z_0} \frac{(X^2-X_0^2) + ( Y^2 -Y_0^2 )}{ (X-X_0) + (Y-Y_0)\iota}$ But now I am stuck that how can I provde the non-existence of Limit  . If I will rationalise then also not getting any satisfactory results. Or choosing two different path is looking impossible because $z_0$ is an unknown point.","I am proving that is not an analytic function. So i didn't want to use the Cauchy-Riemann condition or anything but i know that this particular function is diffentiable at only and nowhere else. So I check the differentiability at without any difficulty , just by using the definition of diffentiable complex valued function as in pic : Now I let a another arbitrary point and check the differentiability at just by using the existence of this limit But now I am stuck that how can I provde the non-existence of Limit  . If I will rationalise then also not getting any satisfactory results. Or choosing two different path is looking impossible because is an unknown point.",f(z) = \mid z\mid^2 z=0 z=0 z_0 \neq 0  z_0 \lim_{z \to z_o} \frac{f(z)-f(z_0)}{ z - z_0} \implies \lim_{z \to z0o} \frac{\mid{z}\mid^2-\mid{z_0}\mid^2}{ z - z_0} \implies \lim_{z \to z_0} \frac{(X^2-X_0^2) + ( Y^2 -Y_0^2 )}{ (X-X_0) + (Y-Y_0)\iota} z_0,"['calculus', 'complex-analysis']"
9,Laurent series of $f(z) = \frac{z - 4}{(z+1)^2(z - 2)}$,Laurent series of,f(z) = \frac{z - 4}{(z+1)^2(z - 2)},I want to expand function $$f(z) = \frac{z - 4}{(z+1)^2(z - 2)}$$ for $1 < |z| < 2$ . My work so far By partial fraction decomposition we can get that: $$\frac{z - 4}{(z + 1)^2(z - 2)} = \frac{-3(z - 4)}{(z + 1)^2} + \frac{\frac 1 9 (z - 4)}{z - 2}$$ Now deriving Laurent expansion for second term is not so hard: $$\frac{1}{z - 2} = -\frac{1}{2} \frac{1}{1 - \frac z 2} = - \frac 1 2 \sum_{n = 0}^\infty (\frac z 2)^n = - \sum_{n = 0}^\infty \frac{z^2}{2^{n + 1}}$$ So we have that: $$ \frac{\frac 1 9 (z - 4)}{z - 2} = \sum_{n = 0}^\infty - \frac 1 9 \cdot \frac{z^n}{2^{n + 1}}(z - 4)$$ But I'm quite struggling with expanding $\frac{1}{(z + 1)^2}$ . I tried several possibilities but those all led me nowhere. Can I ask you for a hand in expanding form $\frac{1}{(z + 1)^2}$ ? EDIT We know that $\frac{1}{1 + z} = \sum_{n = 0}^\infty \frac{(-1)^n}{z^{n + 1}}$ As I understood the idea with derivative is to: $$\frac{d(\frac{1}{1 + z})}{dz} = \sum_{n = 0}^\infty \frac{d(\frac{(-1)^n}{z^{n + 1}})}{dz}$$ $$- \frac{1}{(1 + z)^2} = \sum_{n = 0}^\infty - (n + 1)z^{-n-2}(-1)^n$$ $$\frac{1}{(1 + z)^2} = \sum_{n = 0}^\infty (n + 1)z^{-(n + 2)}(-1)^n$$ Does it make any sense to you?,I want to expand function for . My work so far By partial fraction decomposition we can get that: Now deriving Laurent expansion for second term is not so hard: So we have that: But I'm quite struggling with expanding . I tried several possibilities but those all led me nowhere. Can I ask you for a hand in expanding form ? EDIT We know that As I understood the idea with derivative is to: Does it make any sense to you?,f(z) = \frac{z - 4}{(z+1)^2(z - 2)} 1 < |z| < 2 \frac{z - 4}{(z + 1)^2(z - 2)} = \frac{-3(z - 4)}{(z + 1)^2} + \frac{\frac 1 9 (z - 4)}{z - 2} \frac{1}{z - 2} = -\frac{1}{2} \frac{1}{1 - \frac z 2} = - \frac 1 2 \sum_{n = 0}^\infty (\frac z 2)^n = - \sum_{n = 0}^\infty \frac{z^2}{2^{n + 1}}  \frac{\frac 1 9 (z - 4)}{z - 2} = \sum_{n = 0}^\infty - \frac 1 9 \cdot \frac{z^n}{2^{n + 1}}(z - 4) \frac{1}{(z + 1)^2} \frac{1}{(z + 1)^2} \frac{1}{1 + z} = \sum_{n = 0}^\infty \frac{(-1)^n}{z^{n + 1}} \frac{d(\frac{1}{1 + z})}{dz} = \sum_{n = 0}^\infty \frac{d(\frac{(-1)^n}{z^{n + 1}})}{dz} - \frac{1}{(1 + z)^2} = \sum_{n = 0}^\infty - (n + 1)z^{-n-2}(-1)^n \frac{1}{(1 + z)^2} = \sum_{n = 0}^\infty (n + 1)z^{-(n + 2)}(-1)^n,"['sequences-and-series', 'complex-analysis', 'laurent-series']"
10,A question about analytic continuation,A question about analytic continuation,,"Let $\Omega = \{z: \frac{1}{2} < |z| < 2\}$ . For $n = 1,2,3, ...$ let $X_n$ be the set of all $f \in H(\Omega)$ that are nth derivatives of some $g \in H(\Omega)$ . [In other words, $X_n$ is the range of the differential operator $D^n$ with domain $H(\Omega)$ .] (a) Show that $f \in X_1$ if and only if $\int_\gamma f(z) dz = 0$ , where $\gamma$ is the positively oriented unit circle. (b) Show that $f \in X_n$ for every n if and only if $f$ extends to a holomorphic function in $D(0; 2)$ . For (a) $f \in X_1$ that $\int_\gamma f(z) dz = 0$ is easy get from Cauchy Theorem, but I cannot figure out the converse part. Maybe I can define a $F(z) = \int_{[a,z]}f$ Show that F is analytic in $\Omega$ and $F'=f$ But I totally have no idea about the (b), any relation between the analytic continuous and existence of f.","Let . For let be the set of all that are nth derivatives of some . [In other words, is the range of the differential operator with domain .] (a) Show that if and only if , where is the positively oriented unit circle. (b) Show that for every n if and only if extends to a holomorphic function in . For (a) that is easy get from Cauchy Theorem, but I cannot figure out the converse part. Maybe I can define a Show that F is analytic in and But I totally have no idea about the (b), any relation between the analytic continuous and existence of f.","\Omega = \{z: \frac{1}{2} < |z| < 2\} n = 1,2,3, ... X_n f \in H(\Omega) g \in H(\Omega) X_n D^n H(\Omega) f \in X_1 \int_\gamma f(z) dz = 0 \gamma f \in X_n f D(0; 2) f \in X_1 \int_\gamma f(z) dz = 0 F(z) = \int_{[a,z]}f \Omega F'=f",['complex-analysis']
11,Does this function ever have the same value twice?,Does this function ever have the same value twice?,,Consider the function from a real value to a complex value: $$f(x) = \cos(\sqrt{2} x ) + i \sin(\sqrt{3} x)$$ My contention is it never has the same complex value for two different real values of $x$ . i.e. $f(x)=f(y) \implies x=y$ Is this true? Is there a proof? My second contention is that it has no definable inverse. $f^{-1}(z)$ from a complex number to a real number. Edit: I realised this must be wrong! But I think it is correct for this function to a quaternion: $$g(x) = \cos(\sqrt{2} x ) + i \sin(\sqrt{2} x) + j\cos(\sqrt{3} x ) + k \sin(\sqrt{3} x)$$,Consider the function from a real value to a complex value: My contention is it never has the same complex value for two different real values of . i.e. Is this true? Is there a proof? My second contention is that it has no definable inverse. from a complex number to a real number. Edit: I realised this must be wrong! But I think it is correct for this function to a quaternion:,f(x) = \cos(\sqrt{2} x ) + i \sin(\sqrt{3} x) x f(x)=f(y) \implies x=y f^{-1}(z) g(x) = \cos(\sqrt{2} x ) + i \sin(\sqrt{2} x) + j\cos(\sqrt{3} x ) + k \sin(\sqrt{3} x),['complex-analysis']
12,Prove there exists $c\in\mathbb{C}$ such that $|c| \leq 1$ and $f(z)=ce^{z}$,Prove there exists  such that  and,c\in\mathbb{C} |c| \leq 1 f(z)=ce^{z},"Let $(a_k)_{k\geq 0}$ be a real sequence such that $\lim_{k\rightarrow \infty} a_k =+\infty$ . Let $f:\mathbb{C}\rightarrow\mathbb{C}$ be a holomorphic function such that: $$\forall k \in \mathbb{N}, \forall n\in\mathbb{N},~~|f^{(n)}(a_k)|\leq e^{-a_k} $$ Prove there exists $c\in\mathbb{C}$ such that $|c| \leq 1$ and, $$\forall z \in\mathbb{C}, ~~f(z)=ce^{-z}$$ Do you have an idea about how to approach this problem?","Let be a real sequence such that . Let be a holomorphic function such that: Prove there exists such that and, Do you have an idea about how to approach this problem?","(a_k)_{k\geq 0} \lim_{k\rightarrow \infty} a_k =+\infty f:\mathbb{C}\rightarrow\mathbb{C} \forall k \in \mathbb{N}, \forall n\in\mathbb{N},~~|f^{(n)}(a_k)|\leq e^{-a_k}  c\in\mathbb{C} |c| \leq 1 \forall z \in\mathbb{C}, ~~f(z)=ce^{-z}",['complex-analysis']
13,Milnor fundamental theorem of algebra : proof that $f: S^2 \rightarrow S^2$ is smooth,Milnor fundamental theorem of algebra : proof that  is smooth,f: S^2 \rightarrow S^2,"In the book of J.Milnor : ""Topology from the differentiable viewpoint"", in the chapter 1, p.8, he prooves the Fundamental Theorem of Algebra : Every complex polynomial $p: \mathbb{C} \rightarrow \mathbb{C}$ , not constant ( $k > 0$ ), $$    p(z) = \sum_{k=0}^{N} a_z z^{k}, \quad a_z \in \mathbb{C} \quad  $$ has at least one zero in $\mathbb{C}$ . To proove that, because $\mathbb{C}$ is not compact, he identifies the complex plane $\mathbb{C}$ with the Riemann sphere $S^2$ via the bijection $h_{+}$ and $h_{-}$ that are the stereographic projection of the north pole and south pole on the plane $\mathbb{R}^2 \times \{0\}$ . This allows us to extend $p: \mathbb{C} \rightarrow \mathbb{C}$ to $\hat{p}: \mathbb{C} \cup \{+\infty\} \rightarrow \mathbb{C} \cup \{+\infty\}$ and define an application, $$   f: S^2 \rightarrow S^2 $$ where, $$   f(u, v, w) =  \begin{cases}   h_{+}^{-1} \circ p \circ h_{+}(u,v,w), &\quad (u,v,w) \neq (0, 0, 1) \\   (0, 0, 1), &\quad (u,v,w) = (0, 0, 1) \end{cases} $$ Now, Milnor claims that $f$ is smooth . Seeing that f is smooth in $S^2 \setminus \{(0, 0, 1)\}$ is easy but for the north pole (0, 0, 1) I am not sure to understand the proof. We define, $$ Q(z) := h_{-} \circ f \circ (h_{-}(z))^{-1} $$ After some algebra, we can see that $Q(z)$ is a quotient of polynomial and that it is defined in $z = 0$ so that $Q(z)$ is smooth in $z = 0$ . So then $f \circ (h_{-}(0))^{-1} = f(0, 0, 1)$ is smooth at $(0, 0, 1)$ by composition with smooth functions $h_{-}$ and $h_{-}^{-1}$ ?","In the book of J.Milnor : ""Topology from the differentiable viewpoint"", in the chapter 1, p.8, he prooves the Fundamental Theorem of Algebra : Every complex polynomial , not constant ( ), has at least one zero in . To proove that, because is not compact, he identifies the complex plane with the Riemann sphere via the bijection and that are the stereographic projection of the north pole and south pole on the plane . This allows us to extend to and define an application, where, Now, Milnor claims that is smooth . Seeing that f is smooth in is easy but for the north pole (0, 0, 1) I am not sure to understand the proof. We define, After some algebra, we can see that is a quotient of polynomial and that it is defined in so that is smooth in . So then is smooth at by composition with smooth functions and ?","p: \mathbb{C} \rightarrow \mathbb{C} k > 0  
  p(z) = \sum_{k=0}^{N} a_z z^{k}, \quad a_z \in \mathbb{C} \quad 
 \mathbb{C} \mathbb{C} \mathbb{C} S^2 h_{+} h_{-} \mathbb{R}^2 \times \{0\} p: \mathbb{C} \rightarrow \mathbb{C} \hat{p}: \mathbb{C} \cup \{+\infty\} \rightarrow \mathbb{C} \cup \{+\infty\} 
  f: S^2 \rightarrow S^2
 
  f(u, v, w) = 
\begin{cases}
  h_{+}^{-1} \circ p \circ h_{+}(u,v,w), &\quad (u,v,w) \neq (0, 0, 1) \\
  (0, 0, 1), &\quad (u,v,w) = (0, 0, 1)
\end{cases}
 f S^2 \setminus \{(0, 0, 1)\} 
Q(z) := h_{-} \circ f \circ (h_{-}(z))^{-1}
 Q(z) z = 0 Q(z) z = 0 f \circ (h_{-}(0))^{-1} = f(0, 0, 1) (0, 0, 1) h_{-} h_{-}^{-1}","['complex-analysis', 'differential-geometry', 'differential-topology', 'smooth-manifolds', 'smooth-functions']"
14,A real vector space with an almost complex structure vs its complexification,A real vector space with an almost complex structure vs its complexification,,"Suppose $(V, J)$ is a real vector space of dimension $2n$ equipped with an almost complex structure $J$ such that $J^2 = -Id$ . $V$ can be realized as a complex vector space by setting $iv = J(v)$ for any $v \in V$ . On the other hand one can consider the complexification of $V$ , $V \otimes_{\mathbb R} \mathbb C$ and the complexification can be viewed as a complex vector space naturally. There are two almost complex structures on the complexification, one is the $\mathbb C-$ linear extension of $J$ and the other is multiplication by $i$ . What is the motivation behind considering the complexification in terms of doing complex geometry? Why can't we just consider the original tangent space? I understand the complexification can be decomposed into eigenspaces of $J$ , but what confuses me a bit is what is the benefit of doing so.","Suppose is a real vector space of dimension equipped with an almost complex structure such that . can be realized as a complex vector space by setting for any . On the other hand one can consider the complexification of , and the complexification can be viewed as a complex vector space naturally. There are two almost complex structures on the complexification, one is the linear extension of and the other is multiplication by . What is the motivation behind considering the complexification in terms of doing complex geometry? Why can't we just consider the original tangent space? I understand the complexification can be decomposed into eigenspaces of , but what confuses me a bit is what is the benefit of doing so.","(V, J) 2n J J^2 = -Id V iv = J(v) v \in V V V \otimes_{\mathbb R} \mathbb C \mathbb C- J i J","['linear-algebra', 'complex-analysis', 'complex-geometry', 'hodge-theory']"
15,"Show that if $|z|=2$, $\text{Im}(1-\bar{z}+z^2)\le 7$.","Show that if , .",|z|=2 \text{Im}(1-\bar{z}+z^2)\le 7,"Show that if $|z|=2$ , $|\text{Im}(1-\bar{z}+z^2)|\le 7$ . My attempt: Let $z=x+yi$ , $|z|=\sqrt{x^2+y^2}$ , $|z|^2=(\sqrt{x^2+y^2})^2=x^2+y^2$ . Since $|z|=2$ , then $|z|^2=2^2=4$ . So $x^2+y^2=4$ . Also, $(x-y)^2\ge0$ $\implies x^2+y^2\ge2xy$ ; $$xy\le2 $$ So $|y|\le2$ and $|x|\le 2$ . Now, $$\begin{aligned} 1-\bar{z}+z^2&=1-(x-yi)+(x+yi)^2\\ &=1-x+yi+x^2+2xyi-y^2\\ &=1-x+x^2-y^2+(2xy+y)i \end{aligned}$$ Thus, $$\begin{aligned} \ |\text{Im}(1-\bar{z}+z^2)|&=|y+2xy|\\ &\le|y|+|2xy|\\ &\le |y|+|x^2+y^2|\\ &\le2+4=6 \end{aligned}$$ How about the case when it is equal to $7$ ?","Show that if , . My attempt: Let , , . Since , then . So . Also, ; So and . Now, Thus, How about the case when it is equal to ?","|z|=2 |\text{Im}(1-\bar{z}+z^2)|\le 7 z=x+yi |z|=\sqrt{x^2+y^2} |z|^2=(\sqrt{x^2+y^2})^2=x^2+y^2 |z|=2 |z|^2=2^2=4 x^2+y^2=4 (x-y)^2\ge0 \implies x^2+y^2\ge2xy xy\le2  |y|\le2 |x|\le 2 \begin{aligned}
1-\bar{z}+z^2&=1-(x-yi)+(x+yi)^2\\
&=1-x+yi+x^2+2xyi-y^2\\
&=1-x+x^2-y^2+(2xy+y)i
\end{aligned} \begin{aligned}
\ |\text{Im}(1-\bar{z}+z^2)|&=|y+2xy|\\
&\le|y|+|2xy|\\
&\le |y|+|x^2+y^2|\\
&\le2+4=6
\end{aligned} 7",['complex-analysis']
16,Inverse Rouché problem?,Inverse Rouché problem?,,"The problem on one of my mock-exams is as follows: Suppose both $f$ and $g$ are entire with both a finite amount of zeros that all lie in a disk $D_r(0)$ . The zeros are counted by their multiplicity. Suppose that the amount of zeros of both function is is equal. Prove that there exists an entire function $h$ that has no zeros such that there is a sufficiently large $R > r$ for which it holds that $|f(z) - h(z)g(z)| < |f(z)|$ for all $|z|=R$ . A sub question I have to this is why do we need the condition that the amount of zeros is equal? Why can $h$ and $R>r$ not exist if the number of zeros aren't equal? I suppose this has to to with some kind of inverse of Rouché's theorem, because we're starting from to fact that the number of zeros is equal and we want to prove an inequality. $\textbf{Rouché's Theorem:}$ Suppose $f$ and $g$ are holomorphic in an open set containing a circle $C$ and its interior. If $|f(z)| > |g(z)|$ for all $z \in C$ then $f$ and $f+g$ have the same amount of zeros inside the circle $C$ . Could anyone give a hint? Thanks! This problem is similar to Inverse statement to Rouché's theorem in complex analysis.","The problem on one of my mock-exams is as follows: Suppose both and are entire with both a finite amount of zeros that all lie in a disk . The zeros are counted by their multiplicity. Suppose that the amount of zeros of both function is is equal. Prove that there exists an entire function that has no zeros such that there is a sufficiently large for which it holds that for all . A sub question I have to this is why do we need the condition that the amount of zeros is equal? Why can and not exist if the number of zeros aren't equal? I suppose this has to to with some kind of inverse of Rouché's theorem, because we're starting from to fact that the number of zeros is equal and we want to prove an inequality. Suppose and are holomorphic in an open set containing a circle and its interior. If for all then and have the same amount of zeros inside the circle . Could anyone give a hint? Thanks! This problem is similar to Inverse statement to Rouché's theorem in complex analysis.",f g D_r(0) h R > r |f(z) - h(z)g(z)| < |f(z)| |z|=R h R>r \textbf{Rouché's Theorem:} f g C |f(z)| > |g(z)| z \in C f f+g C,['complex-analysis']
17,How is the combinatorist's Lagrange Inversion equivalent to the complex analytic expression of the same theorem?,How is the combinatorist's Lagrange Inversion equivalent to the complex analytic expression of the same theorem?,,"I will present three equivalent combinatorical (I assume so, due to the contexts of the papers I found them in) formulations of the Lagrange Inversion Theorem - I have been baffled over the course of many hours as to how they agree with the Wikipedia statement of the theorem! In particular, it has been hinted but never really stated that Wikipedia's theorem is the same as everyone else's - so I don't even know if I'm wasting my time trying to make them match. If anyone knows where the link lies (or whether there is definitely no link) I'd greatly appreciate that - as usual, one has a hard time corroborating Wikipedia's mathematical statements. I did try to parse their ""formal residues"" explanation, but formal power series are not something I know much about, but their complex-analytic statement is of great interest to me. In these formulations, $[x^n]\{f(x)\}$ denotes the $n$ th coefficient of the curly-braced power series in $x$ . Let $R(t)$ be a power series not involving $x$ . Then there is a unique power series $f=f(x)$ such that $f(x)=x\cdot R(f(x))$ , and for any Laurent series $\varphi(t)$ not involving $x$ , and any integer $n\neq0$ , we have: $$\tag{1}[x^n]\{\varphi(f)\}=\frac{1}{n}[t^{n-1}]\{\varphi'(t)\cdot R(t)^n\}$$ From another source: Suppose $u=u(x)$ is a power series in $x$ satisfying $x=\frac{u}{\varphi(u)}$ where $\varphi(u)$ is a power series in $u$ with a nonzero constant term. Then for any power series $F(u)$ of $u$ , and $n(\in\Bbb Z)\neq0$ we have: $$\tag{2}[x^n]\{F(u(x))\}=\frac{1}{n}[u^{n-1}]\{F'(u)\cdot\varphi(u)^n\}$$ I write both presentations in case one is more revealing than the other. Another strangely put but more promising analytic formulation from the same sources (with proof!): Let $G(t)=\sum_{n=0}^\infty g_nt^n$ , where the $g_i$ are indeterminates. Then there is a unique power series $f$ satisfying: $$f=x+G(f)$$ -Note how this formulation uses an addition, not a multiplication- Then for any power series $\varphi(t)$ we have: $$\tag{3}\varphi(f)=\varphi(x)+\sum_{m=0}^\infty\frac{1}{m!}\frac{d^{m-1}}{dx^{m-1}}\left(\varphi'(x)\cdot G(x)^m\right)$$ But try as I might, I can think of no sensible choice of $f,G,\varphi,u,R$ , whatever, such that this boils down to: If $f$ is an analytic function in some neighbourhood of $a\in\Bbb C$ , such that $f'(a)\ne0$ , then (by the inverse function theorem), it has an analytic inverse $g$ in some neighbourhood of $a$ , such that if $z=f(w),\,g(z)=w$ for all $w$ in this neighbourhood. The Lagrange Inversion Theorem gives its power series as follows: $$\tag{4}g(z)=a+\sum_{n=0}^\infty\frac{(z-f(a))^n}{n!}\cdot\lim_{w\to a}\frac{d^{n-1}}{dw^{n-1}}\left[\left(\frac{w-a}{f(w)-f(a)}\right)^n\right]$$ At first, I attempted to show (by uniqueness of power series) that the coefficients in $4$ are in fact the same as $D_z^n g(z)|_{z=f(a)}$ , but that went unsuccessfully. I have spent quite some time with $1$ and $2$ , attempting to make them play nice (I saw in examples that it was common to let $F$ (as in $2$ ) equal the identity, so you just get $[x^n]\{u(x)\}=\frac{1}{n}[u^{n-1}]\{\varphi(u)^n\}$ ), but as the inverse in these combinatorical formulations is weird ( $u=x\cdot\varphi(u)$ does not yield the straightforward coefficient in $4$ to my eyes!) I had no luck. I can recognise Wikipedia's coefficient for $g$ as: $$D_z^{n-1}[(g'(z))^n]\big|_{z=f(a)}$$ Which suggests that the $\varphi$ function in $2$ should perhaps be $g'(z)$ , but as $\varphi$ has a bizarre relationship I couldn't proceed from here. The only successful observation I have made is that the $\frac{1}{n}$ does indeed make the $n!$ divisors balance - no further progress has been made. It has been shown to me - here - that $1,2,3$ are equivalent - but how are they equivalent to $4$ ?","I will present three equivalent combinatorical (I assume so, due to the contexts of the papers I found them in) formulations of the Lagrange Inversion Theorem - I have been baffled over the course of many hours as to how they agree with the Wikipedia statement of the theorem! In particular, it has been hinted but never really stated that Wikipedia's theorem is the same as everyone else's - so I don't even know if I'm wasting my time trying to make them match. If anyone knows where the link lies (or whether there is definitely no link) I'd greatly appreciate that - as usual, one has a hard time corroborating Wikipedia's mathematical statements. I did try to parse their ""formal residues"" explanation, but formal power series are not something I know much about, but their complex-analytic statement is of great interest to me. In these formulations, denotes the th coefficient of the curly-braced power series in . Let be a power series not involving . Then there is a unique power series such that , and for any Laurent series not involving , and any integer , we have: From another source: Suppose is a power series in satisfying where is a power series in with a nonzero constant term. Then for any power series of , and we have: I write both presentations in case one is more revealing than the other. Another strangely put but more promising analytic formulation from the same sources (with proof!): Let , where the are indeterminates. Then there is a unique power series satisfying: -Note how this formulation uses an addition, not a multiplication- Then for any power series we have: But try as I might, I can think of no sensible choice of , whatever, such that this boils down to: If is an analytic function in some neighbourhood of , such that , then (by the inverse function theorem), it has an analytic inverse in some neighbourhood of , such that if for all in this neighbourhood. The Lagrange Inversion Theorem gives its power series as follows: At first, I attempted to show (by uniqueness of power series) that the coefficients in are in fact the same as , but that went unsuccessfully. I have spent quite some time with and , attempting to make them play nice (I saw in examples that it was common to let (as in ) equal the identity, so you just get ), but as the inverse in these combinatorical formulations is weird ( does not yield the straightforward coefficient in to my eyes!) I had no luck. I can recognise Wikipedia's coefficient for as: Which suggests that the function in should perhaps be , but as has a bizarre relationship I couldn't proceed from here. The only successful observation I have made is that the does indeed make the divisors balance - no further progress has been made. It has been shown to me - here - that are equivalent - but how are they equivalent to ?","[x^n]\{f(x)\} n x R(t) x f=f(x) f(x)=x\cdot R(f(x)) \varphi(t) x n\neq0 \tag{1}[x^n]\{\varphi(f)\}=\frac{1}{n}[t^{n-1}]\{\varphi'(t)\cdot R(t)^n\} u=u(x) x x=\frac{u}{\varphi(u)} \varphi(u) u F(u) u n(\in\Bbb Z)\neq0 \tag{2}[x^n]\{F(u(x))\}=\frac{1}{n}[u^{n-1}]\{F'(u)\cdot\varphi(u)^n\} G(t)=\sum_{n=0}^\infty g_nt^n g_i f f=x+G(f) \varphi(t) \tag{3}\varphi(f)=\varphi(x)+\sum_{m=0}^\infty\frac{1}{m!}\frac{d^{m-1}}{dx^{m-1}}\left(\varphi'(x)\cdot G(x)^m\right) f,G,\varphi,u,R f a\in\Bbb C f'(a)\ne0 g a z=f(w),\,g(z)=w w \tag{4}g(z)=a+\sum_{n=0}^\infty\frac{(z-f(a))^n}{n!}\cdot\lim_{w\to a}\frac{d^{n-1}}{dw^{n-1}}\left[\left(\frac{w-a}{f(w)-f(a)}\right)^n\right] 4 D_z^n g(z)|_{z=f(a)} 1 2 F 2 [x^n]\{u(x)\}=\frac{1}{n}[u^{n-1}]\{\varphi(u)^n\} u=x\cdot\varphi(u) 4 g D_z^{n-1}[(g'(z))^n]\big|_{z=f(a)} \varphi 2 g'(z) \varphi \frac{1}{n} n! 1,2,3 4","['combinatorics', 'complex-analysis', 'proof-explanation', 'lagrange-inversion']"
18,Holomorphic function with Taylor series coefficients sum of reciprocal factorials,Holomorphic function with Taylor series coefficients sum of reciprocal factorials,,"I am trying to find a holomorphic function $f(z)$ with Taylor series $$ f(z) = \sum_{n=0}^{\infty}c_n z^n$$ where the Taylor series coefficients are given by $$ c_n = \sum_{\text{even } i}^n \frac{1}{(i+1)!}$$ The partial sums should be related to the incomplete Gamma function by the relation $$ \sum_{k=0}^n \frac{x^k}{k!} = \frac{\Gamma(n+1,x)e^x}{n!}$$ and setting $x=1$ . The question is then roughly can the incomplete Gamma function $\Gamma(n,x)$ be realised as an nth derivative! I'm dreaming of ultimately something like an integral expression for $f(z)$ . Thanks",I am trying to find a holomorphic function with Taylor series where the Taylor series coefficients are given by The partial sums should be related to the incomplete Gamma function by the relation and setting . The question is then roughly can the incomplete Gamma function be realised as an nth derivative! I'm dreaming of ultimately something like an integral expression for . Thanks,"f(z)  f(z) = \sum_{n=0}^{\infty}c_n z^n  c_n = \sum_{\text{even } i}^n \frac{1}{(i+1)!}  \sum_{k=0}^n \frac{x^k}{k!} = \frac{\Gamma(n+1,x)e^x}{n!} x=1 \Gamma(n,x) f(z)","['complex-analysis', 'taylor-expansion', 'gamma-function']"
19,Taylor series for a complex function $f(z) = \frac{1}{z^2 - 1}$ center at z=2,Taylor series for a complex function  center at z=2,f(z) = \frac{1}{z^2 - 1},"I was trying to find the taylor serie for $f(z) = \frac{1}{z^2 - 1}$ center at z=2 using $$f(x)=\sum_{k=0}^\infty f^{(k)}(a)\frac{(x-a)^k}{k!}$$ However, it seems really hard. I didn't find the ""series"" for $f,f',f'',f'''...$ I found that I can use the geometric series. I read that $$f(z) = \frac{1}{1-x} = \sum_{k=0}^\infty x^k$$ I know that $$f(z) = \frac{1}{z^2 - 1} = f(z) = \frac{1}{(z - 1)(z + 1)}$$ Thus, is it correct to say that $$\frac{1}{(z - 1)(z + 1)}  = \frac{1}{(z+1)} \cdot \sum_{k=0}^\infty z^k = \sum_{k=0}^\infty z^k \cdot\frac{1}{(z+1)}$$ Any help for for the rest will be appreciate. Edit: I just saw that my function is $\frac{1}{z-1}$ and not $\frac{1}{-z + 1}$ , so probably all I did is wrong.","I was trying to find the taylor serie for center at z=2 using However, it seems really hard. I didn't find the ""series"" for I found that I can use the geometric series. I read that I know that Thus, is it correct to say that Any help for for the rest will be appreciate. Edit: I just saw that my function is and not , so probably all I did is wrong.","f(z) = \frac{1}{z^2 - 1} f(x)=\sum_{k=0}^\infty f^{(k)}(a)\frac{(x-a)^k}{k!} f,f',f'',f'''... f(z) = \frac{1}{1-x} = \sum_{k=0}^\infty x^k f(z) = \frac{1}{z^2 - 1} = f(z) = \frac{1}{(z - 1)(z + 1)} \frac{1}{(z - 1)(z + 1)}  = \frac{1}{(z+1)} \cdot \sum_{k=0}^\infty z^k = \sum_{k=0}^\infty z^k \cdot\frac{1}{(z+1)} \frac{1}{z-1} \frac{1}{-z + 1}","['complex-analysis', 'taylor-expansion']"
20,Contour integral around a triangle equals the remainder term of the derivative - why?,Contour integral around a triangle equals the remainder term of the derivative - why?,,"This proof has two oddities in it. It is a proof of the Cauchy-Goursat theorem for triangle contours, i.e. the contour integral of a holomorphic function around the boundary of a triangle in $\Bbb C$ is zero. In the following, $\triangle$ is the original triangle and $\triangle_n$ is a sequence of triangles, where $\triangle_n\subseteq\triangle_{n-1}$ , and $\triangle_0$ is defined as $\triangle$ . $$\triangle\bigcap_{n=1}^\infty\triangle_n=\{z_0\}$$ For some unique $z_0$ , and they reference Cantor - what is the name of this theorem? The main  question however is about this: $$\int_{\partial\triangle_n}f(z)\,\mathrm{d}z=\int_{\partial\triangle_n}(f(z)-f(z_0)-f'(z_0)(z-z_0))\,\mathrm{d}z$$ They offer no explanation for this, other than that $f$ is complex differentiable at $z_0$ . How can it be that the contour integral is equal to this expression? By definition of differentiability, $f(z)=f(z_0)+f'(z_0)(z-z_0)+\psi(z)(z-z_0)$ , where $\psi$ is continuous and $\lim_{z\to z_0}\psi(z)=0$ , so the RHS of that integral is infact just the remainder term, $\psi(z)(z-z_0)$ , meaning that they have assumed that: $$\int_{\partial\triangle_n}f(z)\,\mathrm{d}z=\int_{\partial\triangle_n}\psi(z)(z-z_0)\,\mathrm{d}z$$ Which is only explainable (as far as I can tell) if you presuppose the conclusion of that proof, which is that the contour integral around a triangle is $0$ . What am I missing? Many thanks.","This proof has two oddities in it. It is a proof of the Cauchy-Goursat theorem for triangle contours, i.e. the contour integral of a holomorphic function around the boundary of a triangle in is zero. In the following, is the original triangle and is a sequence of triangles, where , and is defined as . For some unique , and they reference Cantor - what is the name of this theorem? The main  question however is about this: They offer no explanation for this, other than that is complex differentiable at . How can it be that the contour integral is equal to this expression? By definition of differentiability, , where is continuous and , so the RHS of that integral is infact just the remainder term, , meaning that they have assumed that: Which is only explainable (as far as I can tell) if you presuppose the conclusion of that proof, which is that the contour integral around a triangle is . What am I missing? Many thanks.","\Bbb C \triangle \triangle_n \triangle_n\subseteq\triangle_{n-1} \triangle_0 \triangle \triangle\bigcap_{n=1}^\infty\triangle_n=\{z_0\} z_0 \int_{\partial\triangle_n}f(z)\,\mathrm{d}z=\int_{\partial\triangle_n}(f(z)-f(z_0)-f'(z_0)(z-z_0))\,\mathrm{d}z f z_0 f(z)=f(z_0)+f'(z_0)(z-z_0)+\psi(z)(z-z_0) \psi \lim_{z\to z_0}\psi(z)=0 \psi(z)(z-z_0) \int_{\partial\triangle_n}f(z)\,\mathrm{d}z=\int_{\partial\triangle_n}\psi(z)(z-z_0)\,\mathrm{d}z 0","['complex-analysis', 'proof-explanation', 'contour-integration']"
21,Interesting growing behaviour of hypergeometric function,Interesting growing behaviour of hypergeometric function,,"Doing some computations and plottings I've found out that the function $$_2F_1(2s-1,s-\tfrac{1}{2};s;-1)$$ behaves for large real $s$ like $4^{-s}$ . More precisely: It seems that $$_2F_1(2s-1,s-\tfrac{1}{2};s;-1)4^s$$ grows, but very very slowly. No exponential growth or decay at all. If you modify the $4$ only slightly this of course changes and you get exponential groth or decay. So my question is to explain this phenomenon. Is $$\lim_{s\to \infty}\ _2F_1(2s-1,s-\tfrac{1}{2};s;-1)4^s = \infty?$$ Is there an easy to detemine for every $x>0$ the respective $b(x)>0$ such that you have $$_2F_1(2s-1,s-\tfrac{1}{2};s;-x) \sim b^{-s}?$$ What is $$\lim_{s\to \infty}\  _2F_1(2s-1,s-\tfrac{1}{2};s;-x) b^{s} $$ then?","Doing some computations and plottings I've found out that the function behaves for large real like . More precisely: It seems that grows, but very very slowly. No exponential growth or decay at all. If you modify the only slightly this of course changes and you get exponential groth or decay. So my question is to explain this phenomenon. Is Is there an easy to detemine for every the respective such that you have What is then?","_2F_1(2s-1,s-\tfrac{1}{2};s;-1) s 4^{-s} _2F_1(2s-1,s-\tfrac{1}{2};s;-1)4^s 4 \lim_{s\to \infty}\ _2F_1(2s-1,s-\tfrac{1}{2};s;-1)4^s = \infty? x>0 b(x)>0 _2F_1(2s-1,s-\tfrac{1}{2};s;-x) \sim b^{-s}? \lim_{s\to \infty}\  _2F_1(2s-1,s-\tfrac{1}{2};s;-x) b^{s} ","['real-analysis', 'complex-analysis', 'asymptotics', 'hypergeometric-function']"
22,How to integrate $\int_{-\infty}^{\infty} e^{-x^{2}}e^{ix^{3}}dx$,How to integrate,\int_{-\infty}^{\infty} e^{-x^{2}}e^{ix^{3}}dx,"I've been stuck on trying to integrate $\int_{-\infty}^{\infty} e^{-x^{2}}e^{ix^{3}}dx$ I initially thought this could be solved in similar fashion to solving $\int^{\infty}_{-\infty} e^{-x^{2}}e^{ix}dx$ where we define $F(t) = \int^{\infty}_{-\infty} e^{-x^{2}}e^{itx}dx$ and recognize is at as a Fourier transform of $f(x)=e^{-x^{2}}$ and then use the properties of the Fourier transform, namely that $\frac{d}{dt}(\mathcal{F}f)(t) = \mathcal{F}(ixf)(t)$ , to show that $F$ satisfies the differential equation $F'(t)=\frac{t}{2}F(t)$ . See here for more details. So I tried to adjust this by defining a transform as $\mathcal{F}_{c}f(t)=\int^{\infty}_{-\infty} f(x)e^{itx^{3}}dx$ and I saw that I actually get a similar property that $\frac{d}{dt}(\mathcal{F}_{c}f)(t) = \mathcal{F}(3ix^{2}f)(t)$ but I got stuck trying to apply this property in similar fashion to see what $F'(t)$ (in this case $F(t)$ is defined with the new transform instead of Fourier transform) was but ended up with the integral $$\int^{\infty}_{-\infty} (3ix^{2})e^{-x^{2}}e^{ix^{3}t}$$ and am stuck from here.... Anyways, I was looking for either help with my approach or another way entirely to evaluate the integral. I would be very happy either way!","I've been stuck on trying to integrate I initially thought this could be solved in similar fashion to solving where we define and recognize is at as a Fourier transform of and then use the properties of the Fourier transform, namely that , to show that satisfies the differential equation . See here for more details. So I tried to adjust this by defining a transform as and I saw that I actually get a similar property that but I got stuck trying to apply this property in similar fashion to see what (in this case is defined with the new transform instead of Fourier transform) was but ended up with the integral and am stuck from here.... Anyways, I was looking for either help with my approach or another way entirely to evaluate the integral. I would be very happy either way!",\int_{-\infty}^{\infty} e^{-x^{2}}e^{ix^{3}}dx \int^{\infty}_{-\infty} e^{-x^{2}}e^{ix}dx F(t) = \int^{\infty}_{-\infty} e^{-x^{2}}e^{itx}dx f(x)=e^{-x^{2}} \frac{d}{dt}(\mathcal{F}f)(t) = \mathcal{F}(ixf)(t) F F'(t)=\frac{t}{2}F(t) \mathcal{F}_{c}f(t)=\int^{\infty}_{-\infty} f(x)e^{itx^{3}}dx \frac{d}{dt}(\mathcal{F}_{c}f)(t) = \mathcal{F}(3ix^{2}f)(t) F'(t) F(t) \int^{\infty}_{-\infty} (3ix^{2})e^{-x^{2}}e^{ix^{3}t},"['complex-analysis', 'analysis', 'fourier-analysis', 'improper-integrals']"
23,How to solve the integral through a contour with branch points?,How to solve the integral through a contour with branch points?,,"Consider the integral $$ \int^{\infty}_{0} \frac{x^{\frac{1}{3}}}{1+x^2}dx $$ on the complex plane $$ \oint_{C} \frac{z^{\frac{1}{3}}}{1+z^2}dz $$ To find the poles $ 1+z^2=0 \Rightarrow z^2=-1 \Rightarrow z= \pm \sqrt{-1} \Rightarrow z= \pm i $ , by the residue theorems $$ \oint_{C} \frac{z^{\frac{1}{3}}}{1+z^2}dz = 2 \pi i \,\ Res f(z) $$ I know that $$  \oint_{C} \frac{z^{\frac{1}{3}}}{1+z^2}dz = \oint_{C_R} \frac{z^{\frac{1}{3}}}{1+z^2}dz  +\oint_{C_2} \frac{z^{\frac{1}{3}}}{1+z^2}dz + \oint_{C_r} \frac{z^{\frac{1}{3}}}{1+z^2}dz + \oint_{C_1} \frac{z^{\frac{1}{3}}}{1+z^2}dz  $$ the contour used is below: The integral in $C_R \rightarrow 0$ because $R \rightarrow \infty$ and the integral in $C_r \rightarrow 0$ because $r \rightarrow 0$ . But how can I calculate the integrals over $C_1$ and $C_2$ ? How can I calculate residuals? The teacher said the result is $$ I(1-e^{\frac{2 \pi i}{3}}) = 2 \pi i \Big[ \frac{e^{\frac{\pi i}{6}}}{2i}\Big] (1-e^{\frac{\pi i}{3}}) \quad \quad \Rightarrow  \quad \quad  I= \frac{\pi}{2 \sin(\frac{\pi}{3})} = \frac{\pi}{\sqrt{3}}$$","Consider the integral on the complex plane To find the poles , by the residue theorems I know that the contour used is below: The integral in because and the integral in because . But how can I calculate the integrals over and ? How can I calculate residuals? The teacher said the result is"," \int^{\infty}_{0} \frac{x^{\frac{1}{3}}}{1+x^2}dx   \oint_{C} \frac{z^{\frac{1}{3}}}{1+z^2}dz   1+z^2=0 \Rightarrow z^2=-1 \Rightarrow z= \pm \sqrt{-1} \Rightarrow z= \pm i   \oint_{C} \frac{z^{\frac{1}{3}}}{1+z^2}dz = 2 \pi i \,\ Res f(z)    \oint_{C} \frac{z^{\frac{1}{3}}}{1+z^2}dz = \oint_{C_R} \frac{z^{\frac{1}{3}}}{1+z^2}dz  +\oint_{C_2} \frac{z^{\frac{1}{3}}}{1+z^2}dz + \oint_{C_r} \frac{z^{\frac{1}{3}}}{1+z^2}dz + \oint_{C_1} \frac{z^{\frac{1}{3}}}{1+z^2}dz   C_R \rightarrow 0 R \rightarrow \infty C_r \rightarrow 0 r \rightarrow 0 C_1 C_2  I(1-e^{\frac{2 \pi i}{3}}) = 2 \pi i \Big[ \frac{e^{\frac{\pi i}{6}}}{2i}\Big] (1-e^{\frac{\pi i}{3}}) \quad \quad \Rightarrow  \quad \quad  I= \frac{\pi}{2 \sin(\frac{\pi}{3})} = \frac{\pi}{\sqrt{3}}","['complex-analysis', 'complex-numbers', 'residue-calculus']"
24,Determining $A = \{n\in\Bbb N : n\ge2$ and there exists a branch of $\sqrt[n]{f}$ in $D \}$,Determining  and there exists a branch of  in,A = \{n\in\Bbb N : n\ge2 \sqrt[n]{f} D \},"Consider $D = \Bbb C\setminus(\{e^{i\theta} : -\frac\pi2\le\theta\le\frac\pi2\}\cup(-\infty,0])$ and $f(z) = z(z^2+1)$ . We know that $f$ can't be zero for any $z\in D$ . If we consider now $A = \{n\in\Bbb N : n\ge2$ and there exists a branch of $\sqrt[n]{f}$ in $D \}$ , what is $A$ exactly? I tried the following: Take $\Gamma$ any closed curve (the only ones that interest us are the ones that go around $\{e^{i\theta} : -\frac\pi2\le\theta\le\frac\pi2\}$ ) \begin{equation} \frac1{2\pi i}\int_{\Gamma}\frac{f'(z)}{f(z)}\;dz = \frac1{2\pi i}\int_{\Gamma}\left(\frac1{z}+\frac1{z-i}+\frac1{z+i}\right)\;dz = n(\Gamma,0) + n(\Gamma,i) + n(\Gamma,-i) = 2n(\Gamma,i) \end{equation} With this, the only possibility is that $A\subset2\Bbb N$ . Rewrite $f(z) = \frac{z(z-i)}{(z+i)}(z+i)^2 = g(z)h(z)$ , with $g(z) = \frac{z(z-i)}{(z+i)}$ and $h(z) = (z+i)^2$ . By the same procedure as before, we know that $\frac1{2\pi i}\int_{\Gamma}\frac{g'(z)}{g(z)}\;dz = 0$ , so there exists a branch for $\log(g)$ , which means that there exists a branch for $\sqrt[n]g$ for any $n\ge2$ . The branch for $\sqrt h$ is just $z+i$ , so we know that there exists at least a branch of $\sqrt f$ , so $\{2\}\subset A \subset 2\Bbb N$ . Can we say that $A$ is either $\{2\}$ of $2\Bbb N$ ? If we instead consider $D' = \Bbb C\setminus(\{e^{i\theta} : -\frac\pi2\le\theta\le\frac\pi2\}\cup[-1,2])$ , for that same $f$ we would get $\frac1{2\pi i}\int_{\Gamma}\frac{f'(z)}{f(z)}\;dz = 3n(\Gamma,0)$ , and by the same reasoning as before, $\{3\}\subset A'\subset3\Bbb N$ . Could the same result for $A$ be said for $A'$ (but with $3$ 's instead of $2$ 's now)?","Consider and . We know that can't be zero for any . If we consider now and there exists a branch of in , what is exactly? I tried the following: Take any closed curve (the only ones that interest us are the ones that go around ) With this, the only possibility is that . Rewrite , with and . By the same procedure as before, we know that , so there exists a branch for , which means that there exists a branch for for any . The branch for is just , so we know that there exists at least a branch of , so . Can we say that is either of ? If we instead consider , for that same we would get , and by the same reasoning as before, . Could the same result for be said for (but with 's instead of 's now)?","D = \Bbb C\setminus(\{e^{i\theta} : -\frac\pi2\le\theta\le\frac\pi2\}\cup(-\infty,0]) f(z) = z(z^2+1) f z\in D A = \{n\in\Bbb N : n\ge2 \sqrt[n]{f} D \} A \Gamma \{e^{i\theta} : -\frac\pi2\le\theta\le\frac\pi2\} \begin{equation}
\frac1{2\pi i}\int_{\Gamma}\frac{f'(z)}{f(z)}\;dz = \frac1{2\pi i}\int_{\Gamma}\left(\frac1{z}+\frac1{z-i}+\frac1{z+i}\right)\;dz = n(\Gamma,0) + n(\Gamma,i) + n(\Gamma,-i) = 2n(\Gamma,i)
\end{equation} A\subset2\Bbb N f(z) = \frac{z(z-i)}{(z+i)}(z+i)^2 = g(z)h(z) g(z) = \frac{z(z-i)}{(z+i)} h(z) = (z+i)^2 \frac1{2\pi i}\int_{\Gamma}\frac{g'(z)}{g(z)}\;dz = 0 \log(g) \sqrt[n]g n\ge2 \sqrt h z+i \sqrt f \{2\}\subset A \subset 2\Bbb N A \{2\} 2\Bbb N D' = \Bbb C\setminus(\{e^{i\theta} : -\frac\pi2\le\theta\le\frac\pi2\}\cup[-1,2]) f \frac1{2\pi i}\int_{\Gamma}\frac{f'(z)}{f(z)}\;dz = 3n(\Gamma,0) \{3\}\subset A'\subset3\Bbb N A A' 3 2","['complex-analysis', 'branch-cuts']"
25,How do I choose the three pairs of points for a moebius transform?,How do I choose the three pairs of points for a moebius transform?,,"I somehow don't really understand how to choose the points for a moebius transform. I know that a moebius transform maps circles and lines to circles and lines and that it is a conformal(biholomorphic) map. Why do we always choose the three points on the boundary of the corresponding domain? When we for example want to construct a moebius transform from the open unit disk to the upper half plane, then we choose three points on the boundary of the unit disk which we want to map to the boundary of the upper half plane which is the real axis. Why is it necessary that all these points are on the corresponding boundary? How are the points exactly mapped to each other? It seems that one cannot just map the 3 points in any order to the image points. I have read that one has to keep the orientation in mind. What is meant by that? Do I have also to keep something in mind when I am mapping the 3 image and pre-image points to $0,1,\infty$ ? How are only 3 point-pairs with information on orientation enough to specify the mapping For me this seems unintuitive. I could just change the target domain a little bit so that the boundary points I chose still lie on the boundary of the domain. Wouldn't I get the exact same moebius transform although my target domain is different now?","I somehow don't really understand how to choose the points for a moebius transform. I know that a moebius transform maps circles and lines to circles and lines and that it is a conformal(biholomorphic) map. Why do we always choose the three points on the boundary of the corresponding domain? When we for example want to construct a moebius transform from the open unit disk to the upper half plane, then we choose three points on the boundary of the unit disk which we want to map to the boundary of the upper half plane which is the real axis. Why is it necessary that all these points are on the corresponding boundary? How are the points exactly mapped to each other? It seems that one cannot just map the 3 points in any order to the image points. I have read that one has to keep the orientation in mind. What is meant by that? Do I have also to keep something in mind when I am mapping the 3 image and pre-image points to ? How are only 3 point-pairs with information on orientation enough to specify the mapping For me this seems unintuitive. I could just change the target domain a little bit so that the boundary points I chose still lie on the boundary of the domain. Wouldn't I get the exact same moebius transform although my target domain is different now?","0,1,\infty","['complex-analysis', 'mobius-transformation']"
26,How to compute $\int_0^\infty \frac{\log(x)}{\sqrt{x}(x+1)} \ dx$ using the Residue Theorem?,How to compute  using the Residue Theorem?,\int_0^\infty \frac{\log(x)}{\sqrt{x}(x+1)} \ dx,"I have made the following attempt (I won't put every detail, but if necessary, I will edit the question). I consider $\Gamma_{R,\varepsilon}$ as the following path: and consider computing $\int_\Gamma \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx$ : \begin{equation} \begin{aligned} 2\pi i\operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right) & = \lim_{\substack{R\to\infty \\ \varepsilon\to0^+}}\int_\Gamma \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx = \int_0^\infty \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx - \int_0^\infty \frac{(\log(x)+2\pi i)^2}{\sqrt{x}(x+1)} = \\ & = \int_0^\infty \frac{\log^2(x)-\log^2(x)-4\pi i \log(x) + 4\pi^2}{\sqrt x(x+1)}\ dx = \int_0^\infty \frac{-4\pi i \log(x) + 4\pi^2}{\sqrt x(x+1)}\ dx \end{aligned} \end{equation} Therefore, \begin{equation} \begin{aligned} \int_0^\infty \frac{\log(x)}{\sqrt{x}(x+1)} \ dx & = -\frac{1}{4\pi i}\left( 2\pi i\operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right) - \int_0^\infty \frac{4\pi^2}{\sqrt{x}(x+1)\ dx} \right) \\ & = -\frac 12 \operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right)-\pi i\int_0^\infty \frac{1}{\sqrt{x}(x+1)}\ dx = \\ & = \frac 12 \pi^2i - \pi^2i = -\frac 12\pi^2i \end{aligned} \end{equation} If I compute the original integral in a calculator, the result is $0$ . Could anyone please help me out telling me what is wrong with my reasoning?","I have made the following attempt (I won't put every detail, but if necessary, I will edit the question). I consider as the following path: and consider computing : Therefore, If I compute the original integral in a calculator, the result is . Could anyone please help me out telling me what is wrong with my reasoning?","\Gamma_{R,\varepsilon} \int_\Gamma \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx \begin{equation}
\begin{aligned}
2\pi i\operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right) & = \lim_{\substack{R\to\infty \\ \varepsilon\to0^+}}\int_\Gamma \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx = \int_0^\infty \frac{\log^2(x)}{\sqrt{x}(x+1)} \ dx - \int_0^\infty \frac{(\log(x)+2\pi i)^2}{\sqrt{x}(x+1)} = \\
& = \int_0^\infty \frac{\log^2(x)-\log^2(x)-4\pi i \log(x) + 4\pi^2}{\sqrt x(x+1)}\ dx = \int_0^\infty \frac{-4\pi i \log(x) + 4\pi^2}{\sqrt x(x+1)}\ dx
\end{aligned}
\end{equation} \begin{equation}
\begin{aligned}
\int_0^\infty \frac{\log(x)}{\sqrt{x}(x+1)} \ dx & = -\frac{1}{4\pi i}\left( 2\pi i\operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right) - \int_0^\infty \frac{4\pi^2}{\sqrt{x}(x+1)\ dx} \right) \\
& = -\frac 12 \operatorname{Res}\left(\frac{\log^2(x)}{\sqrt{x}(x+1)},-1\right)-\pi i\int_0^\infty \frac{1}{\sqrt{x}(x+1)}\ dx = \\
& = \frac 12 \pi^2i - \pi^2i = -\frac 12\pi^2i
\end{aligned}
\end{equation} 0","['complex-analysis', 'improper-integrals', 'residue-calculus']"
27,How come the derivative of $e^{i\theta} $ never vanish,How come the derivative of  never vanish,e^{i\theta} ,"Since $e^{i\theta} $ where $0\leq\theta\leq 2\pi $ is paramaterization of the unit circle, I would expect its derivative to vanish, as the tangent line slope in some point definetly should be zero. What's different here?","Since where is paramaterization of the unit circle, I would expect its derivative to vanish, as the tangent line slope in some point definetly should be zero. What's different here?",e^{i\theta}  0\leq\theta\leq 2\pi ,['complex-analysis']
28,How can one integrate $(z^3)/[(z-6)(z^5-z+6)]$ along the circular path $|z|=5$?,How can one integrate  along the circular path ?,(z^3)/[(z-6)(z^5-z+6)] |z|=5,"My aim is to determine the value of $$\int_C f(z) \, dz = \int_{|z|=5} \frac{z^3}{(z-6)(z^5-z+6)}\,dz.$$ The quintic factor is troublesome. By splitting it as $(z^5)+(-z+6)$ and applying Rouché's Theorem, we see that all five roots are within our contour. By Decartes' Rule and by looking at its derivative and intercept, it has only one real root $\rho_1$ , which is negative. (We can factor via this root, but I don't see the use: $(z-\rho_1)(z^4+\rho_1 z^3 +\rho_1^2 z^2+\rho_1^3 z +\rho_1^4-1)$ .) By writing $z^3=((z-6)+6)^3=(z-6)^3 +3(6)(z-6)^2 +3(36)(z-6)+216,$ we can reduce our problem to finding $$\int_C f(z)\,dz=216\int_{|z|=5}\frac{1}{(z-6)(z^5-(z-6))}\,dz.$$ I have not gotten much further. That the quintic can be written as $z^5-(z-6)$ or $z(z^4-1)+6$ occurred to me. I also thought that if I could show that the five roots are distinct, then the poles are simple ones and the formula $$ \operatorname*{Res}_{z=\rho_j}f(z)=\lim_{z\to \rho_j}(z-\rho_j)g(z) $$ might apply, but then we'd express the answer in terms of the $\rho_j$ ? I am thinking rather that a concrete number can be given for the answer, since this is a past qualifying exam question.","My aim is to determine the value of The quintic factor is troublesome. By splitting it as and applying Rouché's Theorem, we see that all five roots are within our contour. By Decartes' Rule and by looking at its derivative and intercept, it has only one real root , which is negative. (We can factor via this root, but I don't see the use: .) By writing we can reduce our problem to finding I have not gotten much further. That the quintic can be written as or occurred to me. I also thought that if I could show that the five roots are distinct, then the poles are simple ones and the formula might apply, but then we'd express the answer in terms of the ? I am thinking rather that a concrete number can be given for the answer, since this is a past qualifying exam question.","\int_C f(z) \, dz = \int_{|z|=5} \frac{z^3}{(z-6)(z^5-z+6)}\,dz. (z^5)+(-z+6) \rho_1 (z-\rho_1)(z^4+\rho_1 z^3 +\rho_1^2 z^2+\rho_1^3 z +\rho_1^4-1) z^3=((z-6)+6)^3=(z-6)^3 +3(6)(z-6)^2 +3(36)(z-6)+216, \int_C f(z)\,dz=216\int_{|z|=5}\frac{1}{(z-6)(z^5-(z-6))}\,dz. z^5-(z-6) z(z^4-1)+6 
\operatorname*{Res}_{z=\rho_j}f(z)=\lim_{z\to \rho_j}(z-\rho_j)g(z)
 \rho_j","['complex-analysis', 'complex-integration', 'residue-calculus']"
29,Intermediate step in deriving integral representation of Euler–Mascheroni constant: $\int_0^1\frac{1-e^{-t}-e^{-1/t}}{t}dt$,Intermediate step in deriving integral representation of Euler–Mascheroni constant:,\int_0^1\frac{1-e^{-t}-e^{-1/t}}{t}dt,"I'm following a complex analysis course and am making an exercise in which I have to derive an integral representation for the Euler–Mascheroni constant. I have the following definition of the Euler–Mascheroni constant: $$\gamma = \lim_{n\rightarrow\infty}\left(1 + 1/2 + +\ldots+ 1/n - \log n\right)$$ I have shown (with induction): $$1 + 1/2 + \ldots+ 1/n = \int_0^1\frac{1-(1-t)^n}{t}dt$$ I now have to show: $$\gamma = \lim_\limits{n\to\infty}\left(\int_0^1 (1-(1-t/n)^n)\frac{dt}{t}  - \int_1^n(1-t/n)^n\frac{dt}{t}\right)$$ By using $e^t = \lim\limits_{n\to\infty}(1+t/n)^n$ and substituting $t$ for $1/t$ in the second integral, it then follows: $$\gamma = \int_0^1\frac{1-e^{-t}-e^{-1/t}}{t}dt$$ None of my ideas have been promising for the second step. Any suggestions?","I'm following a complex analysis course and am making an exercise in which I have to derive an integral representation for the Euler–Mascheroni constant. I have the following definition of the Euler–Mascheroni constant: I have shown (with induction): I now have to show: By using and substituting for in the second integral, it then follows: None of my ideas have been promising for the second step. Any suggestions?","\gamma = \lim_{n\rightarrow\infty}\left(1 + 1/2 + +\ldots+ 1/n - \log n\right) 1 + 1/2 + \ldots+ 1/n = \int_0^1\frac{1-(1-t)^n}{t}dt \gamma = \lim_\limits{n\to\infty}\left(\int_0^1 (1-(1-t/n)^n)\frac{dt}{t} 
- \int_1^n(1-t/n)^n\frac{dt}{t}\right) e^t = \lim\limits_{n\to\infty}(1+t/n)^n t 1/t \gamma = \int_0^1\frac{1-e^{-t}-e^{-1/t}}{t}dt","['integration', 'complex-analysis', 'euler-mascheroni-constant']"
30,Alternating Riemann Zeta Function (Dirichlet eta function) convergence proof,Alternating Riemann Zeta Function (Dirichlet eta function) convergence proof,,I am reading a proof on proving the convergence of the alternating Riemann Zeta Function but I cant understand how they went from the 2nd line of math to the 3rd. Can someone please explain why the inequality $\left| \frac{1}{(2n-1)^s}-\frac{1}{(2n)^s}\right|\leq\left|\frac{s}{(2n-1)^{s+1}}\right|$ is true? I understand everything else but why this inequality is true.,I am reading a proof on proving the convergence of the alternating Riemann Zeta Function but I cant understand how they went from the 2nd line of math to the 3rd. Can someone please explain why the inequality is true? I understand everything else but why this inequality is true.,\left| \frac{1}{(2n-1)^s}-\frac{1}{(2n)^s}\right|\leq\left|\frac{s}{(2n-1)^{s+1}}\right|,"['complex-analysis', 'riemann-zeta']"
31,Showing the remainder of a Taylor series is bounded by some sequence,Showing the remainder of a Taylor series is bounded by some sequence,,"I have the function $$f(z)=\frac{z^{2}+1}{z^{10}-2}$$ and I wish to show $$|R_{n}(z)|<\frac{1}{2^{n}}$$ for its Taylor series around $0$ , for all $|z|<\frac{1}{2}$ . I thought I should use $$R_{n}(z)=\frac{1}{2\pi i}(z-z_{0})^{n+1}\oint_{\gamma}\frac{f(w)}{(w-z_{0})^{n+1}(w-z)}\,\mathrm dw$$ considering $\gamma$ , a circle of radius $r_1$ around $z_0=0$ . Also, if we denote $r_0=\frac12$ , it is clear that $$|w-z|=|(w-z_{0})-(z-z_{0})|\geq r_{1}-r$$ from the inverse triangle inequality. We can also notice that $$|w-z_0| = |w| = r_1$$ and get after the integral evaluation: $$|R_{n}(z)|\leq\frac{\max\limits_{w\in\gamma}|f(w)|}{1-r/r_1}\left(\frac{r}{r_{1}}\right)^{n+1}$$ But I can't seem to see a way to proceed from here. It obviously has something to do with finding the maximum of the function on the circle, but that doesn't seem to lead me to the answer. I will be glad for any help.","I have the function and I wish to show for its Taylor series around , for all . I thought I should use considering , a circle of radius around . Also, if we denote , it is clear that from the inverse triangle inequality. We can also notice that and get after the integral evaluation: But I can't seem to see a way to proceed from here. It obviously has something to do with finding the maximum of the function on the circle, but that doesn't seem to lead me to the answer. I will be glad for any help.","f(z)=\frac{z^{2}+1}{z^{10}-2} |R_{n}(z)|<\frac{1}{2^{n}} 0 |z|<\frac{1}{2} R_{n}(z)=\frac{1}{2\pi i}(z-z_{0})^{n+1}\oint_{\gamma}\frac{f(w)}{(w-z_{0})^{n+1}(w-z)}\,\mathrm dw \gamma r_1 z_0=0 r_0=\frac12 |w-z|=|(w-z_{0})-(z-z_{0})|\geq r_{1}-r |w-z_0| = |w| = r_1 |R_{n}(z)|\leq\frac{\max\limits_{w\in\gamma}|f(w)|}{1-r/r_1}\left(\frac{r}{r_{1}}\right)^{n+1}","['complex-analysis', 'taylor-expansion']"
32,Prove $\frac{|a|-|b|}{1-|ab|}\leq \frac{|a+b|}{|1+ab|}\leq \frac{|a|+|b|}{1+|ab|}$,Prove,\frac{|a|-|b|}{1-|ab|}\leq \frac{|a+b|}{|1+ab|}\leq \frac{|a|+|b|}{1+|ab|},"Prove $\frac{|a|-|b|}{1-|ab|}\leq \frac{|a+b|}{|1+ab|}\leq \frac{|a|+|b|}{1+|ab|}$ where $|a|,|b|<1$ . My idea: Take $f:\mathbb{D}\rightarrow \mathbb{D}$ holomorphic with $f(-a)=0$ and the conformal map $h:\mathbb{D}\rightarrow\mathbb{D}$ with $$h(z)=\frac{z-a}{1-az}.$$ Then the inverse of $h$ is $$h^{-1}(z)=\frac{a+z}{1+az}.$$ Then the holomorphic mapping $$g(z)=f\circ h(z)$$ satisfies $g(0)=0$ . Then by Scharwz lemma $$|f\circ h(z)|\leq |z|.$$ Which implies $$|f(z)|\leq \left| \frac{a+z}{1+az}\right|.$$ If I am able to prove that I can choose $f(b)=\frac{|a|-|b|}{1-|ab|}$ then I get the first Inequality and I can get the other in a similar manner.",Prove where . My idea: Take holomorphic with and the conformal map with Then the inverse of is Then the holomorphic mapping satisfies . Then by Scharwz lemma Which implies If I am able to prove that I can choose then I get the first Inequality and I can get the other in a similar manner.,"\frac{|a|-|b|}{1-|ab|}\leq \frac{|a+b|}{|1+ab|}\leq \frac{|a|+|b|}{1+|ab|} |a|,|b|<1 f:\mathbb{D}\rightarrow \mathbb{D} f(-a)=0 h:\mathbb{D}\rightarrow\mathbb{D} h(z)=\frac{z-a}{1-az}. h h^{-1}(z)=\frac{a+z}{1+az}. g(z)=f\circ h(z) g(0)=0 |f\circ h(z)|\leq |z|. |f(z)|\leq \left| \frac{a+z}{1+az}\right|. f(b)=\frac{|a|-|b|}{1-|ab|}","['complex-analysis', 'inequality']"
33,Evaluate $\int_0^1 \sqrt\frac{1-x}{x}dx$ with the dogbone contour,Evaluate  with the dogbone contour,\int_0^1 \sqrt\frac{1-x}{x}dx,"I'm currently working on the integral $I = \int_0^1 \sqrt\frac{1-x}{x}dx$ . I would like to evaluate it with the dogbone contour specifically . Here's what I did so far: Denote $f(z) = \sqrt\frac{1-z}{z}$ the integrand function (with complex variable). Then I observe that $$f(z) = (1 - z)^{\frac{1}{2}}z^{-\frac{1}{2}} = \frac{|1 - z|^{\frac{1}{2}}}{|z|^{\frac{1}{2}}}e^{\frac{1}{2}i(\arg(z) - \arg(1 - z))} (*)$$ Since $\ln(z) = \ln(|z|) + i\arg(z)$ (and similarly $\ln(1 - z) = \ln(|1 - z|) + i\arg(1 - z)$ ). Denote $Arg = \frac{1}{2}(\arg(z) - \arg(1 - z))$ for the step to come. Next I defined $- \pi < \arg(z) \leq \pi$ and $0 \leq \arg(z) < 2\pi$ , to observe the behaviour of Arg in the intervals $(- \infty, 0)$ and $(0,1)$ . In $(- \infty, 0)$ , from above, we have: $\arg(z) \to \pi$ , $\arg(1 - z) \to 2\pi \implies Arg \to \frac{1}{2}(\pi - 2\pi) = - \frac{\pi}{2}$ In $(- \infty, 0)$ , from below, we have: $\arg(z) \to - \pi$ , $\arg(1 - z) \to 0 \implies Arg \to \frac{1}{2}(- \pi - 0) = - \frac{\pi}{2}$ Hence we deduce that our function is continuous everywhere on this interval. However: In $(0,1)$ , from above, we have: $\arg(z) \to 0$ , $\arg(1 - z) \to 2\pi \implies Arg \to \frac{1}{2}(0 - 2\pi) = - \pi$ In $(0,1)$ , from below, we have: $\arg(z) \to 0$ , $\arg(1 - z) \to 0 \implies Arg \to 0$ And in this interval our function is discontinuous since $e^{- i\pi} \ne e^0 = 1$ . Thus I introduced a dogbone contour, namely $C$ , aroud the branch $[0,1]$ such that: $$C = \psi_1 \cup \psi_2 \cup c_0 \cup c_1$$ Where $\psi_1$ is the blue segment from $1$ to $0$ and $\psi_2$ is the blue segment from $0$ to $1$ . (Thanks to @Zaid Alyafeai for the picture). Then we have the equality: $\oint_C f(z)dz = \int_{\psi_1} f(z)dz + \int_{\psi_2} f(z)dz + \int_{c_1} f(z)dz + \int_{c_2} f(z)dz$ ; and pumping up $C$ we also have that $\oint_C = - 2\pi i (res_{z = 0}f(z)dz + res_{z = \infty}f(z)dz)$ by Cauchy Residue Theorem since $0,\infty$ are the only singular points of $f(z)$ . Then I computed them: For $\int_{\psi_1} f(z)dz$ and $\int_{\psi_2} f(z)dz$ , I used $z = t + i\epsilon$ with $t \in [0,1] $ and $dz = dt$ : $$\int_{\psi_1}f(z)dz = - \int_0^1\frac{(1 - t - i\epsilon)^{\frac{1}{2}}}{(t + i\epsilon)^{\frac{1}{2}}}dt = - \int_0^1 \frac{|1 - t - i\epsilon|^{\frac{1}{2}}}{|t + i\epsilon|^{\frac{1}{2}}}e^{i\pi}dt$$ (I deduced the last integral from $(*)$ and from the arguments I computed above) Then taking the limt when $\epsilon \to 0$ I finally obtained that $\lim\limits_{\epsilon \to 0} \int_{\psi_1}f(z)dz = I$ . In a very similar way I found that $\lim\limits_{\epsilon \to 0} \int_{\psi_2}f(z)dz = I$ as well. Now for $\int_{c_0} f(z)dz$ and $\int_{c_1} f(z)dz$ , I used $z = \epsilon e^{i\theta}$ with $\theta \in [0,2\pi]$ and $dz = i\epsilon e^{i\theta}$ , and my goal was to find upper bounds of the absolute value of these integrals: $|\int_{c_0} f(z)dz| = |i\epsilon^{\frac{1}{2}}\int_0^{2\pi}(1 - \epsilon e^{i\theta})^{\frac{1}{2}}e^{\frac{1}{2}i\theta}dt| \leq i\epsilon^{\frac{1}{2}}\int_0^{2\pi}|1 - \epsilon e^{i\theta}|^{\frac{1}{2}}|e^{\frac{1}{2}i\theta}|dt \leq i\epsilon^{\frac{1}{2}}(1 + \epsilon)^{\frac{1}{2}}2\pi$ Thus I had: $0 \leq \lim\limits_{\epsilon \to 0}|\int_{c_0}f(z)dz[ \leq 0$ which implies that $\lim\limits_{\epsilon \to 0}\int_{c_0}f(z)dz = 0$ . In a very similar way again, I found that $\lim\limits_{\epsilon \to 0}\int_{c_1}f(z)dz = 0$ . Hence in the end I had: $\oint_Cf(z)dz = I + I + 0 + 0 = 2I$ , and since I also had that $\oint_Cf(z)dz = - 2\pi i (res_{z = 0}f(z)dz + res_{z = \infty}f(z)dz)$ , it follows that: $$2I = - 2\pi i (res_{z = 0}f(z)dz + res_{z = \infty}f(z)dz) (***)$$ And that's where my problem starts (or not !): I computed both residues and found they were both equal to 0, but this implies that $I = 0$ and I feel like this is wrong, because first I don't understand why they would be 0 when looking at their shape, and second this means the ""number"" of $I$ on the LHS of $(***)$ does not influence our result. So I hope you can help me either finding my mistake, either to show me that those residues are not 0 because I did not achieve to find another result (either to prove me that $I = 0$ because I don't think so). I already appreciated your time, but any help would be welcome!","I'm currently working on the integral . I would like to evaluate it with the dogbone contour specifically . Here's what I did so far: Denote the integrand function (with complex variable). Then I observe that Since (and similarly ). Denote for the step to come. Next I defined and , to observe the behaviour of Arg in the intervals and . In , from above, we have: , In , from below, we have: , Hence we deduce that our function is continuous everywhere on this interval. However: In , from above, we have: , In , from below, we have: , And in this interval our function is discontinuous since . Thus I introduced a dogbone contour, namely , aroud the branch such that: Where is the blue segment from to and is the blue segment from to . (Thanks to @Zaid Alyafeai for the picture). Then we have the equality: ; and pumping up we also have that by Cauchy Residue Theorem since are the only singular points of . Then I computed them: For and , I used with and : (I deduced the last integral from and from the arguments I computed above) Then taking the limt when I finally obtained that . In a very similar way I found that as well. Now for and , I used with and , and my goal was to find upper bounds of the absolute value of these integrals: Thus I had: which implies that . In a very similar way again, I found that . Hence in the end I had: , and since I also had that , it follows that: And that's where my problem starts (or not !): I computed both residues and found they were both equal to 0, but this implies that and I feel like this is wrong, because first I don't understand why they would be 0 when looking at their shape, and second this means the ""number"" of on the LHS of does not influence our result. So I hope you can help me either finding my mistake, either to show me that those residues are not 0 because I did not achieve to find another result (either to prove me that because I don't think so). I already appreciated your time, but any help would be welcome!","I = \int_0^1 \sqrt\frac{1-x}{x}dx f(z) = \sqrt\frac{1-z}{z} f(z) = (1 - z)^{\frac{1}{2}}z^{-\frac{1}{2}} = \frac{|1 - z|^{\frac{1}{2}}}{|z|^{\frac{1}{2}}}e^{\frac{1}{2}i(\arg(z) - \arg(1 - z))} (*) \ln(z) = \ln(|z|) + i\arg(z) \ln(1 - z) = \ln(|1 - z|) + i\arg(1 - z) Arg = \frac{1}{2}(\arg(z) - \arg(1 - z)) - \pi < \arg(z) \leq \pi 0 \leq \arg(z) < 2\pi (- \infty, 0) (0,1) (- \infty, 0) \arg(z) \to \pi \arg(1 - z) \to 2\pi \implies Arg \to \frac{1}{2}(\pi - 2\pi) = - \frac{\pi}{2} (- \infty, 0) \arg(z) \to - \pi \arg(1 - z) \to 0 \implies Arg \to \frac{1}{2}(- \pi - 0) = - \frac{\pi}{2} (0,1) \arg(z) \to 0 \arg(1 - z) \to 2\pi \implies Arg \to \frac{1}{2}(0 - 2\pi) = - \pi (0,1) \arg(z) \to 0 \arg(1 - z) \to 0 \implies Arg \to 0 e^{- i\pi} \ne e^0 = 1 C [0,1] C = \psi_1 \cup \psi_2 \cup c_0 \cup c_1 \psi_1 1 0 \psi_2 0 1 \oint_C f(z)dz = \int_{\psi_1} f(z)dz + \int_{\psi_2} f(z)dz + \int_{c_1} f(z)dz + \int_{c_2} f(z)dz C \oint_C = - 2\pi i (res_{z = 0}f(z)dz + res_{z = \infty}f(z)dz) 0,\infty f(z) \int_{\psi_1} f(z)dz \int_{\psi_2} f(z)dz z = t + i\epsilon t \in [0,1]  dz = dt \int_{\psi_1}f(z)dz = - \int_0^1\frac{(1 - t - i\epsilon)^{\frac{1}{2}}}{(t + i\epsilon)^{\frac{1}{2}}}dt = - \int_0^1 \frac{|1 - t - i\epsilon|^{\frac{1}{2}}}{|t + i\epsilon|^{\frac{1}{2}}}e^{i\pi}dt (*) \epsilon \to 0 \lim\limits_{\epsilon \to 0} \int_{\psi_1}f(z)dz = I \lim\limits_{\epsilon \to 0} \int_{\psi_2}f(z)dz = I \int_{c_0} f(z)dz \int_{c_1} f(z)dz z = \epsilon e^{i\theta} \theta \in [0,2\pi] dz = i\epsilon e^{i\theta} |\int_{c_0} f(z)dz| = |i\epsilon^{\frac{1}{2}}\int_0^{2\pi}(1 - \epsilon e^{i\theta})^{\frac{1}{2}}e^{\frac{1}{2}i\theta}dt| \leq i\epsilon^{\frac{1}{2}}\int_0^{2\pi}|1 - \epsilon e^{i\theta}|^{\frac{1}{2}}|e^{\frac{1}{2}i\theta}|dt \leq i\epsilon^{\frac{1}{2}}(1 + \epsilon)^{\frac{1}{2}}2\pi 0 \leq \lim\limits_{\epsilon \to 0}|\int_{c_0}f(z)dz[ \leq 0 \lim\limits_{\epsilon \to 0}\int_{c_0}f(z)dz = 0 \lim\limits_{\epsilon \to 0}\int_{c_1}f(z)dz = 0 \oint_Cf(z)dz = I + I + 0 + 0 = 2I \oint_Cf(z)dz = - 2\pi i (res_{z = 0}f(z)dz + res_{z = \infty}f(z)dz) 2I = - 2\pi i (res_{z = 0}f(z)dz + res_{z = \infty}f(z)dz) (***) I = 0 I (***) I = 0","['complex-analysis', 'solution-verification', 'contour-integration', 'residue-calculus']"
34,What are path and contour integrals?,What are path and contour integrals?,,"I am very confused on what path and contour integrals actually represent. I tried looking for an answer on Google but the only examples were related to Quantum Mechanics. For instance, real Riemann integrals can be thought as ""the area under the curve"". What about path/contour integrals? Also, is there a difference between path and contour integrals, or are they the same thing? I've been thinking of contour integrals as path integrals where the path is a ""closed loop"", but I'm not sure if that's the case. It's all so confusing, and not being able to visualise these concepts makes it feel like I'm just memorising formulas and theorems without any reason. I have been thinking about path integrals as integrating over a curve in three dimensions. For example, in an $xyz$ coordinate system (with $y$ pointing “up”), we have a path on the $x$ -"" $z$ "" plane and integrate over that path. That is, instead of integrating over and along "" $y=0$ "", we integrate over a certain path. But I don't know if this is a correct way to think of path integrals. This issue has been frustrating me a lot because I'm now studying theorems that involve path/contour integrals and I just can't understand what they really do or mean. By path integral I mean $$\int_{\gamma\vert_{[a,b]}}f(z)\hspace{0.2em}dz = \int_{a}^{b}f(\gamma(t))\cdot\gamma'(t)\hspace{0.2em}dt$$ where $f:U\subseteq\mathbb{C}\rightarrow\mathbb{C}$ is a function that satisfies all conditions for complex integration and $\gamma:[a,b]\rightarrow U\subseteq\mathbb{C}$ is at least a piece-wise regular path. Any help would be appreciated.","I am very confused on what path and contour integrals actually represent. I tried looking for an answer on Google but the only examples were related to Quantum Mechanics. For instance, real Riemann integrals can be thought as ""the area under the curve"". What about path/contour integrals? Also, is there a difference between path and contour integrals, or are they the same thing? I've been thinking of contour integrals as path integrals where the path is a ""closed loop"", but I'm not sure if that's the case. It's all so confusing, and not being able to visualise these concepts makes it feel like I'm just memorising formulas and theorems without any reason. I have been thinking about path integrals as integrating over a curve in three dimensions. For example, in an coordinate system (with pointing “up”), we have a path on the -"" "" plane and integrate over that path. That is, instead of integrating over and along "" "", we integrate over a certain path. But I don't know if this is a correct way to think of path integrals. This issue has been frustrating me a lot because I'm now studying theorems that involve path/contour integrals and I just can't understand what they really do or mean. By path integral I mean where is a function that satisfies all conditions for complex integration and is at least a piece-wise regular path. Any help would be appreciated.","xyz y x z y=0 \int_{\gamma\vert_{[a,b]}}f(z)\hspace{0.2em}dz = \int_{a}^{b}f(\gamma(t))\cdot\gamma'(t)\hspace{0.2em}dt f:U\subseteq\mathbb{C}\rightarrow\mathbb{C} \gamma:[a,b]\rightarrow U\subseteq\mathbb{C}","['integration', 'complex-analysis']"
35,Show f has a removable singularity at $z=0$,Show f has a removable singularity at,z=0,"Let f be analytic in $\mathbb{D}\setminus\{0\}$ and suppose there exists $M>0$ and $m\geq 1$ such that $\left|f^{(m)}(z)\right|\leq \frac{M}{|z|^m}$ for all $0<|z|<1$ . Show that f has a removable singularity at $0$ . My attempt: Since $f$ is analytic in $\mathbb{D}\setminus\{0\}$ it is holomorphic in in $\mathbb{D}\setminus\{0\}$ . Further, we have that $$(\forall z\in\mathbb{D}\setminus\{0\}):|z^m|\left|f^{(m)}(z)\right|\leq M.$$ Thus, the function $g(z):=z^mf^{(m)}(z)$ has a removable singularity at $z=0$ by Riemann's singularity theorem and so it can be extended to a function $h(z)$ that is holomorphic on the entire unit disk. And here, I do not know how to continue, since I was trying to show that $h(z)$ had a zero at $z=0$ but I was not getting very far. So, if anyone has any suggestions on how to move forward, I would appreciate it.","Let f be analytic in and suppose there exists and such that for all . Show that f has a removable singularity at . My attempt: Since is analytic in it is holomorphic in in . Further, we have that Thus, the function has a removable singularity at by Riemann's singularity theorem and so it can be extended to a function that is holomorphic on the entire unit disk. And here, I do not know how to continue, since I was trying to show that had a zero at but I was not getting very far. So, if anyone has any suggestions on how to move forward, I would appreciate it.",\mathbb{D}\setminus\{0\} M>0 m\geq 1 \left|f^{(m)}(z)\right|\leq \frac{M}{|z|^m} 0<|z|<1 0 f \mathbb{D}\setminus\{0\} \mathbb{D}\setminus\{0\} (\forall z\in\mathbb{D}\setminus\{0\}):|z^m|\left|f^{(m)}(z)\right|\leq M. g(z):=z^mf^{(m)}(z) z=0 h(z) h(z) z=0,"['complex-analysis', 'analysis', 'singularity']"
36,$(a_n)_{n=1}^\infty$ & $(b_n)_{n=1}^\infty$ are seq st $(a_n)_{n=1}^\infty$ & $[{(a_n)_{n=1}^\infty + (b_n)_{n=1}^\infty}]$ con. Prove $(b_n)$ con,&  are seq st  &  con. Prove  con,(a_n)_{n=1}^\infty (b_n)_{n=1}^\infty (a_n)_{n=1}^\infty [{(a_n)_{n=1}^\infty + (b_n)_{n=1}^\infty}] (b_n),"Suppose $(a_n)_{n=1}^\infty$ and $(b_n)_{n=1}^\infty$ are sequences such that $(a_n)_{n=1}^\infty$ and $[{(a_n)_{n=1}^\infty + (b_n)_{n=1}^\infty}]$ converge. Prove that $(b_n)_{n=1}^\infty$ converges I can say $b_n=(a_n + b_n)-a_n$ . Since both $(a_n)_{n=1}^\infty$ and $[{(a_n)_{n=1}^\infty + (b_n)_{n=1}^\infty}]$ converge, isnt' there a subtraction rule that says that because those both converge, that $b_n$ would also converge?","Suppose and are sequences such that and converge. Prove that converges I can say . Since both and converge, isnt' there a subtraction rule that says that because those both converge, that would also converge?",(a_n)_{n=1}^\infty (b_n)_{n=1}^\infty (a_n)_{n=1}^\infty [{(a_n)_{n=1}^\infty + (b_n)_{n=1}^\infty}] (b_n)_{n=1}^\infty b_n=(a_n + b_n)-a_n (a_n)_{n=1}^\infty [{(a_n)_{n=1}^\infty + (b_n)_{n=1}^\infty}] b_n,"['real-analysis', 'calculus', 'complex-analysis', 'analysis']"
37,Existence of holomorphic function $f$ such that $f^{(n)}(0) = n^{2n}$,Existence of holomorphic function  such that,f f^{(n)}(0) = n^{2n},I need help with the following problem: Is there a holomorphic function $f$ in an open disk around $0$ such that \begin{align} f^{(n)}(0) = n^{2n} \end{align} for all $n \in \mathbb{N}$ ? I thought quite long about this and came up with the following idea: Suppose there exists such a function. Then we can write it as \begin{align} f(z) = \sum_{n=0}^{\infty} \frac{n^{2n}}{n!}z^n. \end{align} We can compute the radius of convergence $R$ of this power series: \begin{align} R = \lim_{n \to \infty} \left| \frac{n^{2n}}{n!} \cdot \frac{(n+1)!}{(n+1)^{2n+2}} \right| = \lim_{n \to \infty}\left( \frac{n}{n+1}\right)^{2n} \cdot \frac{1}{n+1} \leq \lim_{n \to \infty} \frac{1}{n+1} = 0. \end{align} This contradicts the assumption that $f$ is holomorphic in an open disk around $0$ or with other words: $R > 0$ . I am not very confident looking at my solution. (Is it true?) Apart from that I was wondering whether or not there is an easier way to find an answer to this question. The problem reminds me of the Identity Theorem or even the generalized Cauchy Integral Formula. Still I failed to see if (and how) those two could have been used to solve this. In order to gain a better understanding of problems of this kind I would be glad if someone has another good idea for this question!,I need help with the following problem: Is there a holomorphic function in an open disk around such that for all ? I thought quite long about this and came up with the following idea: Suppose there exists such a function. Then we can write it as We can compute the radius of convergence of this power series: This contradicts the assumption that is holomorphic in an open disk around or with other words: . I am not very confident looking at my solution. (Is it true?) Apart from that I was wondering whether or not there is an easier way to find an answer to this question. The problem reminds me of the Identity Theorem or even the generalized Cauchy Integral Formula. Still I failed to see if (and how) those two could have been used to solve this. In order to gain a better understanding of problems of this kind I would be glad if someone has another good idea for this question!,"f 0 \begin{align}
f^{(n)}(0) = n^{2n}
\end{align} n \in \mathbb{N} \begin{align}
f(z) = \sum_{n=0}^{\infty} \frac{n^{2n}}{n!}z^n.
\end{align} R \begin{align}
R = \lim_{n \to \infty} \left| \frac{n^{2n}}{n!} \cdot \frac{(n+1)!}{(n+1)^{2n+2}} \right| = \lim_{n \to \infty}\left( \frac{n}{n+1}\right)^{2n} \cdot \frac{1}{n+1} \leq \lim_{n \to \infty} \frac{1}{n+1} = 0.
\end{align} f 0 R > 0","['complex-analysis', 'entire-functions']"
38,"If $f(z)$ is differentiable, show that $|f'(z)|^2=(\frac{\partial u}{\partial x})^2+(\frac{\partial v}{\partial x})^2$. [duplicate]","If  is differentiable, show that . [duplicate]",f(z) |f'(z)|^2=(\frac{\partial u}{\partial x})^2+(\frac{\partial v}{\partial x})^2,"This question already has answers here : Why $f^{\prime}(z)=u_{x}+iv_{x}$? (2 answers) Closed 3 years ago . Let $f(z)$ be a complex valued function which can be represented by $$f(z)=u(x,y) + iv(x,y).$$ If $f(z)$ is differentiable, show that $$\left|f'(z)\right|^2=\left(\frac{\partial u}{\partial x}\right)^2+\left(\frac{\partial v}{\partial x}\right)^2.$$ I am a beginner in complex analysis, so bear with me. In my solution, it is given that $$f'(z)=u_x + iv_x=\frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x}$$ and things follow from here. My doubt is, how does the above came into picture. As far as i know, $f(z)$ is a complex valued function with real part as $u(x,y)$ and imaginary part being $v(x,y)$ which are both functions of $x$ and $y$ . How does one calculate the derivative of $f(z)$ by taking partial derivative with respect to $x$ only? Any help would be appreciated from the community.","This question already has answers here : Why $f^{\prime}(z)=u_{x}+iv_{x}$? (2 answers) Closed 3 years ago . Let be a complex valued function which can be represented by If is differentiable, show that I am a beginner in complex analysis, so bear with me. In my solution, it is given that and things follow from here. My doubt is, how does the above came into picture. As far as i know, is a complex valued function with real part as and imaginary part being which are both functions of and . How does one calculate the derivative of by taking partial derivative with respect to only? Any help would be appreciated from the community.","f(z) f(z)=u(x,y) + iv(x,y). f(z) \left|f'(z)\right|^2=\left(\frac{\partial u}{\partial x}\right)^2+\left(\frac{\partial v}{\partial x}\right)^2. f'(z)=u_x + iv_x=\frac{\partial u}{\partial x} + i \frac{\partial v}{\partial x} f(z) u(x,y) v(x,y) x y f(z) x",['complex-analysis']
39,Summing $1+\cos(\theta)+\cos(2\theta) +\cdots + \cos(n\theta)$,Summing,1+\cos(\theta)+\cos(2\theta) +\cdots + \cos(n\theta),"First of all, I'd like to acknowledge that there are already solutions to this question on this forum. However, I'm repeating the question here because my solution doesn't quite get me what those other solutions are and I'm wondering if I'm doing something wrong. I know that taking $z\in \mathbb{C}$ s.t. $|z|=1$ and $\arg(z) = \theta$ , we get $z=\cos(\theta)+i\sin(\theta)$ . Then by DeMoivre's Theorem we get $z^n= (\cos(\theta)+i\sin(\theta))^n=\cos(n\theta)+i\sin(n\theta)$ , and we see that the sum $1+\cos(\theta)+\cos(2\theta) +\cdots + \cos(n\theta)$ is equal to $\operatorname{Re}(z^0+z^1+\cdots+z^n)$ (call it $S$ ). From there, using geometric sums, $S=\frac{z^{n+1}-1}{z-1}$ . In order to find $\operatorname{Re}(S)$ , I am multiplying the top and the bottom by $\overline{z-1}$ to get $S=\frac{(z^{n+1}-1)*(\overline{z-1})}{(z-1)*(\overline{z-1})}$ . This is where I'm running into trouble. Expanding $z$ into $\cos(\theta)+i\sin(\theta)$ I get that the denominator is equal to $2-2\cos(\theta)$ (and whatever other variants of this using trig identities). However, this doesn't seem to line up with any of the other standard answers I'm finding online (which mostly involve a $\sin(\frac{\theta}{2})$ in the denominator). I was wondering if anyone could point out if/where I've gone wrong in my process. Is there another way to handle this sum (while still using DeMoivre's Theorem)?","First of all, I'd like to acknowledge that there are already solutions to this question on this forum. However, I'm repeating the question here because my solution doesn't quite get me what those other solutions are and I'm wondering if I'm doing something wrong. I know that taking s.t. and , we get . Then by DeMoivre's Theorem we get , and we see that the sum is equal to (call it ). From there, using geometric sums, . In order to find , I am multiplying the top and the bottom by to get . This is where I'm running into trouble. Expanding into I get that the denominator is equal to (and whatever other variants of this using trig identities). However, this doesn't seem to line up with any of the other standard answers I'm finding online (which mostly involve a in the denominator). I was wondering if anyone could point out if/where I've gone wrong in my process. Is there another way to handle this sum (while still using DeMoivre's Theorem)?",z\in \mathbb{C} |z|=1 \arg(z) = \theta z=\cos(\theta)+i\sin(\theta) z^n= (\cos(\theta)+i\sin(\theta))^n=\cos(n\theta)+i\sin(n\theta) 1+\cos(\theta)+\cos(2\theta) +\cdots + \cos(n\theta) \operatorname{Re}(z^0+z^1+\cdots+z^n) S S=\frac{z^{n+1}-1}{z-1} \operatorname{Re}(S) \overline{z-1} S=\frac{(z^{n+1}-1)*(\overline{z-1})}{(z-1)*(\overline{z-1})} z \cos(\theta)+i\sin(\theta) 2-2\cos(\theta) \sin(\frac{\theta}{2}),['complex-analysis']
40,Calculate the following complex integral,Calculate the following complex integral,,"I try to calculate the following integral: $$\oint_{\{\vert z\vert=3\}}\frac{e^z}{(z-1)(z-2i)}$$ The integral encloses 2 poles in $1$ at $2i$ . Using the homotopy we see that expect the two circle of radius $\epsilon$ around both pole, the rest is cancelled out. Now my idea is to try to split the integral into something like $$\oint_{\{\vert z\vert=3\}}f(z)dz+\oint_{\{\vert z\vert=3\}}f(z)dz$$ and use the cauchy integral formular but I go stucked... EDIT: If I write now $$ \frac{1}{(z-1)(z-2i)}=\frac{A}{z-1}+\frac{B}{z-2i}\ . $$ as in the answer and I solve it. Then we get $A=-B$ and $A=-\frac{1}{2i-1}$ . Okay now we get $$A\oint_{\{\vert z\vert=3\}}\frac{e^z}{z-1}-A\oint_{\{\vert z\vert=3\}}\frac{e^z}{z-2i}$$ By the Cauchy Formular this is equal to: $$2\pi iA(e^1+e^{-2i})$$ Is this right?","I try to calculate the following integral: The integral encloses 2 poles in at . Using the homotopy we see that expect the two circle of radius around both pole, the rest is cancelled out. Now my idea is to try to split the integral into something like and use the cauchy integral formular but I go stucked... EDIT: If I write now as in the answer and I solve it. Then we get and . Okay now we get By the Cauchy Formular this is equal to: Is this right?","\oint_{\{\vert z\vert=3\}}\frac{e^z}{(z-1)(z-2i)} 1 2i \epsilon \oint_{\{\vert z\vert=3\}}f(z)dz+\oint_{\{\vert z\vert=3\}}f(z)dz 
\frac{1}{(z-1)(z-2i)}=\frac{A}{z-1}+\frac{B}{z-2i}\ .
 A=-B A=-\frac{1}{2i-1} A\oint_{\{\vert z\vert=3\}}\frac{e^z}{z-1}-A\oint_{\{\vert z\vert=3\}}\frac{e^z}{z-2i} 2\pi iA(e^1+e^{-2i})",['complex-analysis']
41,How do we show that ${\sum}_{w\in\wedge}\frac{1}{(z+w)^2}$ is not absolutely convergent?,How do we show that  is not absolutely convergent?,{\sum}_{w\in\wedge}\frac{1}{(z+w)^2},"This is from Complex Analysis by Shakarchi and Stein in the chapter of Elliptic functions. How do we show that ${\sum}_{w\in\wedge}\frac{1}{(z+w)^2}$ is not absolutely convergent, where $\wedge$ is a double lattice in complex plane? It seems difficult for me to show the absolute convergence of the complex infinite sums. Maybe I can try to bound this series and use the fact from real series, but I don't know how.","This is from Complex Analysis by Shakarchi and Stein in the chapter of Elliptic functions. How do we show that is not absolutely convergent, where is a double lattice in complex plane? It seems difficult for me to show the absolute convergence of the complex infinite sums. Maybe I can try to bound this series and use the fact from real series, but I don't know how.",{\sum}_{w\in\wedge}\frac{1}{(z+w)^2} \wedge,"['complex-analysis', 'elliptic-functions']"
42,Figuring out winding number of a curve using crossing rule of a point,Figuring out winding number of a curve using crossing rule of a point,,"In page-340 of Tristan Needham's Visual Complex Analysis, he introduces a theorem to find number of a loop. To motivate the theorem, he shows the situation of a point coming closer and closer to a segment of a curve: For the right most picture, he writes a relation between winding numbers: $$ v(K,r) = v(K,s)  + v(L,s)$$ Or, $$ v(K,r) = v(K,s) -1 $$ Or, $$ v(K,r) +1 =v(K,s) \tag{1}$$ Explanation given: Start from outside L, where you know the winding number is zero, move from region to region using crossing rule to add or subtract one at each crossing of L The equation (1) and the idea behind its derivation allows us to relate winding numbers between the interior and exterior of the sets in which the curve partitions the plane. However, how can this be used to figure out the winding numbers easily? Note: $v(k,s) $ means the winding number of the loop $k$ around the point $s$","In page-340 of Tristan Needham's Visual Complex Analysis, he introduces a theorem to find number of a loop. To motivate the theorem, he shows the situation of a point coming closer and closer to a segment of a curve: For the right most picture, he writes a relation between winding numbers: Or, Or, Explanation given: Start from outside L, where you know the winding number is zero, move from region to region using crossing rule to add or subtract one at each crossing of L The equation (1) and the idea behind its derivation allows us to relate winding numbers between the interior and exterior of the sets in which the curve partitions the plane. However, how can this be used to figure out the winding numbers easily? Note: means the winding number of the loop around the point"," v(K,r) = v(K,s)  + v(L,s)  v(K,r) = v(K,s) -1   v(K,r) +1 =v(K,s) \tag{1} v(k,s)  k s","['complex-analysis', 'winding-number']"
43,A $\zeta$-like sum of the positive roots of $\csc x=x$.,A -like sum of the positive roots of .,\zeta \csc x=x,"From this answer , I was very interested to learn the following. Let $x_n$ be the $n$ -th positive root of the equation $\csc x=x$ . Then $$\sum_{n\ge1}\frac{1}{x_n^2}=1,$$ and, setting $s(k)=\sum_{n\ge1}x_n^{-k}$ , we have $$\sum_{k\ge1}s(2k)x^{2k}=\frac{x}{2}\cdot\frac{1+x\cot x}{\csc x-x}.\tag 1$$ This result was very surprising and I've never seen anything like it before. The proof was discussed rather briefly in the comments and apparently it can be shown via a contour integral, but I've never done anything like that before so I have no idea how. Could I have some help proving $(1)$ ? Thanks! :)","From this answer , I was very interested to learn the following. Let be the -th positive root of the equation . Then and, setting , we have This result was very surprising and I've never seen anything like it before. The proof was discussed rather briefly in the comments and apparently it can be shown via a contour integral, but I've never done anything like that before so I have no idea how. Could I have some help proving ? Thanks! :)","x_n n \csc x=x \sum_{n\ge1}\frac{1}{x_n^2}=1, s(k)=\sum_{n\ge1}x_n^{-k} \sum_{k\ge1}s(2k)x^{2k}=\frac{x}{2}\cdot\frac{1+x\cot x}{\csc x-x}.\tag 1 (1)","['sequences-and-series', 'complex-analysis', 'number-theory', 'generating-functions']"
44,Interpretation of a certain general theorem used by Gauss in his work on theta functions.,Interpretation of a certain general theorem used by Gauss in his work on theta functions.,,"I'm trying to understand the meaning of a general proposition stated by Gauss in a posthomous paper (this paper is in pp. 470-481 of volume 3 of Gauss's werke) on theta functions, a proposition which seems to serve as a guiding and organizing principle of the vast amount of relations among theta functions that he found. Gauss's notation and definitions Denote by $P(x,y),Q(x,y),R(x,y)$ the following functions: $$P(x,y)=1+x(y+\frac{1}{y})+x^4(y^2+\frac{1}{y^2})+x^9(y^3+\frac{1}{y^3})+...$$ $$Q(x,y)= 1-x(y+\frac{1}{y})+x^4(y^2+\frac{1}{y^2})-x^9(y^3+\frac{1}{y^3})+...$$ $$R(x,y)=x^{\frac{1}{4}}(y^{\frac{1}{2}}+y^{-\frac{1}{2}})+x^{\frac{9}{4}}(y^{\frac{3}{2}}+y^{-\frac{3}{2}})+x^{\frac{25}{4}}(y^{\frac{5}{2}}+y^{-\frac{5}{2}})+...$$ These functions include Jacobi theta functions in their usual meaning as special cases; if $y$ is a complex number whose absolute value is $1$ , and $z$ is defined to be a real number such that $y = e^{2iz}$ , then we have: $$P(x,y)=1+2cos(2z)x+2cos(4z)x^4+2cos(6z)x^9+...=\vartheta_3(z,x)$$ which follows from the identity $cos(2nz)= \frac{e^{2inz}+e^{-2inz}}{2}$ . In paticular, we have: $$P(x,1)=1+2x+2x^4+2x^9+...=\vartheta_3(0,x)$$ , So one can understand $P(x,y),Q(x,y),R(x,y)$ as a generalization of Jacobi theta function $\vartheta(z,x)$ from purely real $z$ to a complex $z$ (non-zero imaginary part of z), so that $|y| \ne 1$ . Remark: I'm not very familiar with Jacobi's publications, so it's quite possible that Jacobi's original definition of his theta functions includes also the case when $z$ is complex, so Gauss's functions $P(x,y),Q(x,y),R(x,y)$ are nothing else than simply Jacobi's theta functions with different notation. Gauss's theorem On August 6, 1827, Gauss stated the following ""general theorem"": $$P(x,ty)\cdot P(x,\frac{y}{t}) = P(x^2,t^2)P(x^2,y^2) + R(x^2,t^2)R(x^2,y^2) $$ and then goes on to derive a multitude of relations from it. For more comprehensive background on this question, please look at the answer to HSM stackexchange post https://hsm.stackexchange.com/questions/6256/did-gauss-know-jacobis-four-squares-theorem . Therefore, i'd like to know how to interpret the general theorem stated by Gauss.","I'm trying to understand the meaning of a general proposition stated by Gauss in a posthomous paper (this paper is in pp. 470-481 of volume 3 of Gauss's werke) on theta functions, a proposition which seems to serve as a guiding and organizing principle of the vast amount of relations among theta functions that he found. Gauss's notation and definitions Denote by the following functions: These functions include Jacobi theta functions in their usual meaning as special cases; if is a complex number whose absolute value is , and is defined to be a real number such that , then we have: which follows from the identity . In paticular, we have: , So one can understand as a generalization of Jacobi theta function from purely real to a complex (non-zero imaginary part of z), so that . Remark: I'm not very familiar with Jacobi's publications, so it's quite possible that Jacobi's original definition of his theta functions includes also the case when is complex, so Gauss's functions are nothing else than simply Jacobi's theta functions with different notation. Gauss's theorem On August 6, 1827, Gauss stated the following ""general theorem"": and then goes on to derive a multitude of relations from it. For more comprehensive background on this question, please look at the answer to HSM stackexchange post https://hsm.stackexchange.com/questions/6256/did-gauss-know-jacobis-four-squares-theorem . Therefore, i'd like to know how to interpret the general theorem stated by Gauss.","P(x,y),Q(x,y),R(x,y) P(x,y)=1+x(y+\frac{1}{y})+x^4(y^2+\frac{1}{y^2})+x^9(y^3+\frac{1}{y^3})+... Q(x,y)= 1-x(y+\frac{1}{y})+x^4(y^2+\frac{1}{y^2})-x^9(y^3+\frac{1}{y^3})+... R(x,y)=x^{\frac{1}{4}}(y^{\frac{1}{2}}+y^{-\frac{1}{2}})+x^{\frac{9}{4}}(y^{\frac{3}{2}}+y^{-\frac{3}{2}})+x^{\frac{25}{4}}(y^{\frac{5}{2}}+y^{-\frac{5}{2}})+... y 1 z y = e^{2iz} P(x,y)=1+2cos(2z)x+2cos(4z)x^4+2cos(6z)x^9+...=\vartheta_3(z,x) cos(2nz)= \frac{e^{2inz}+e^{-2inz}}{2} P(x,1)=1+2x+2x^4+2x^9+...=\vartheta_3(0,x) P(x,y),Q(x,y),R(x,y) \vartheta(z,x) z z |y| \ne 1 z P(x,y),Q(x,y),R(x,y) P(x,ty)\cdot P(x,\frac{y}{t}) = P(x^2,t^2)P(x^2,y^2) + R(x^2,t^2)R(x^2,y^2) ","['sequences-and-series', 'complex-analysis', 'math-history', 'theta-functions']"
45,Can an arbitary Jordan curve be approximated by a smooth Jordan curve?,Can an arbitary Jordan curve be approximated by a smooth Jordan curve?,,"Given a Jordan curve $\gamma_1 \colon [a,b] \to \mathbb{C}$ and an $\epsilon > 0$ , can we find a continuously differentiable Jordan curve, $\gamma_2 \colon [a,b] \to \mathbb{C}$ , such that $ |\gamma_1(t) - \gamma_2(t) | < \epsilon$ for all $ t \in [a,b]$ ?","Given a Jordan curve and an , can we find a continuously differentiable Jordan curve, , such that for all ?","\gamma_1 \colon [a,b] \to \mathbb{C} \epsilon > 0 \gamma_2 \colon [a,b] \to \mathbb{C}  |\gamma_1(t) - \gamma_2(t) | < \epsilon  t \in [a,b]","['complex-analysis', 'differential-geometry', 'curves']"
46,Evaluating real integral using complex analysis. [duplicate],Evaluating real integral using complex analysis. [duplicate],,"This question already has answers here : $\int_0^\infty \frac{\sqrt x}{1+x^4} dx$ by residues (3 answers) Closed last month . I'm trying to compute the following integral: $$\int_0^{\infty}\frac{\sqrt{x}}{1+x^4}dx$$ I'll not write down everything I've done, but choosing the branch cut on the positive real axes we have that: $$\int_0^{\infty}\frac{\sqrt{x}}{1+x^4}dx=\pi i \sum_{z_i}Res(f,z_i) \qquad z_i\in\{\pm \sqrt{i},\pm\sqrt{-i}\}$$ So we have to compute four residues. My thought was changing the branch cut by putting it on the negative imaginary axes. We can do it by choosing $arg(z) \in (-\frac{\pi}{2},\frac{3\pi}{2}]$ . So we have that: $$(1+i)\int_0^{\infty}\frac{\sqrt{x}}{1+x^4}dx=2\pi i \sum_{z_i}Res(f,z_i) \qquad z_i\in\{e^{i\frac{\pi}{4}},e^{i\frac{3\pi}{4}}\}$$ By doing this, we now need to compute only two residues. But I'm really finding difficulties in computing those residues: in fact I can't obtain the result I'm expecting. Can you please show me the computation and tell me if my argument was clear and correct? Thanks in advance.","This question already has answers here : $\int_0^\infty \frac{\sqrt x}{1+x^4} dx$ by residues (3 answers) Closed last month . I'm trying to compute the following integral: I'll not write down everything I've done, but choosing the branch cut on the positive real axes we have that: So we have to compute four residues. My thought was changing the branch cut by putting it on the negative imaginary axes. We can do it by choosing . So we have that: By doing this, we now need to compute only two residues. But I'm really finding difficulties in computing those residues: in fact I can't obtain the result I'm expecting. Can you please show me the computation and tell me if my argument was clear and correct? Thanks in advance.","\int_0^{\infty}\frac{\sqrt{x}}{1+x^4}dx \int_0^{\infty}\frac{\sqrt{x}}{1+x^4}dx=\pi i \sum_{z_i}Res(f,z_i) \qquad z_i\in\{\pm \sqrt{i},\pm\sqrt{-i}\} arg(z) \in (-\frac{\pi}{2},\frac{3\pi}{2}] (1+i)\int_0^{\infty}\frac{\sqrt{x}}{1+x^4}dx=2\pi i \sum_{z_i}Res(f,z_i) \qquad z_i\in\{e^{i\frac{\pi}{4}},e^{i\frac{3\pi}{4}}\}","['complex-analysis', 'contour-integration', 'residue-calculus']"
47,Conformal mapping to upper half plane,Conformal mapping to upper half plane,,"I need to find conformal mapping of $U = \{z \in \mathbb{C}:Im(z) >0\}\setminus\{ it:t\in [1;\infty)\}$ to upper half plane. I tried to square $U$ and then use inverse of $w = \frac{1}{2}(z + \frac{1}{z})$ and on paper it seems like i am on the right way, but cannot understand what's wrong. Any hints?","I need to find conformal mapping of to upper half plane. I tried to square and then use inverse of and on paper it seems like i am on the right way, but cannot understand what's wrong. Any hints?",U = \{z \in \mathbb{C}:Im(z) >0\}\setminus\{ it:t\in [1;\infty)\} U w = \frac{1}{2}(z + \frac{1}{z}),"['complex-analysis', 'complex-numbers']"
48,A problem on the equation $\bar{\partial} g=f$ in complex analysis,A problem on the equation  in complex analysis,\bar{\partial} g=f,"I'm reading Voisin's famous book Hodge theory and Complex algebraic geometry, page 30. And in this section Voisin proved the following fact: given a smooth function $f$ , we can solve the equation $\bar{\partial} g=f$ locally. To be more precise, we can suppose that $f$ is of compact support and write down the explicit formula for $u$ as: $$ u(z)=\frac{1}{2 i \pi} \int_{\mathbb{C}} \frac{f(\zeta)}{\zeta-z} d \zeta \wedge d \bar{\zeta}. $$ Of course this looks very reasonable. But I also read Hormander's famous book Introduction to complex analysis in several variables. In page 30, theorem 2.3.1 (1990 edition), he wrote a remark, which said $\bar{\partial} g=f$ needn't have a solution even when $f$ is of compact support! He said [take an arbitrary $f$ with nonzero Lebesgue integral on $\mathbb{C}$ ]. I am very much confused for the conclusions on two masters' books look like quite different. Can anyone explain why Hormander said we can [take an arbitrary $f$ with nonzero Lebesgue integral on $\mathbb{C}$ ] as a counterexample? Or have I misunderstood anything? Thanks in advance!","I'm reading Voisin's famous book Hodge theory and Complex algebraic geometry, page 30. And in this section Voisin proved the following fact: given a smooth function , we can solve the equation locally. To be more precise, we can suppose that is of compact support and write down the explicit formula for as: Of course this looks very reasonable. But I also read Hormander's famous book Introduction to complex analysis in several variables. In page 30, theorem 2.3.1 (1990 edition), he wrote a remark, which said needn't have a solution even when is of compact support! He said [take an arbitrary with nonzero Lebesgue integral on ]. I am very much confused for the conclusions on two masters' books look like quite different. Can anyone explain why Hormander said we can [take an arbitrary with nonzero Lebesgue integral on ] as a counterexample? Or have I misunderstood anything? Thanks in advance!","f \bar{\partial} g=f f u 
u(z)=\frac{1}{2 i \pi} \int_{\mathbb{C}} \frac{f(\zeta)}{\zeta-z} d \zeta \wedge d \bar{\zeta}.
 \bar{\partial} g=f f f \mathbb{C} f \mathbb{C}","['complex-analysis', 'several-complex-variables']"
49,"Prove if a function is holomorphic, then its complex conjugate is holomorphic, by Cauchy-Riemann Equations","Prove if a function is holomorphic, then its complex conjugate is holomorphic, by Cauchy-Riemann Equations",,"Given a function $f(z)$ is holomorphic on a disc $D(0,R)$ , we want to prove that $g(z)= \overline {f(\bar z)}$ is holomorphic. Below is my proof. $\lim_{h\to 0} \frac{\overline {f(\overline{z+h})}-\overline{f(\bar z)}}{h} =  \lim_{h\to 0} \frac{\overline {f(\overline{z+h})-\overline{f(\bar z)}}}{h} = \overline{\lim_{h\to 0} \frac {f(\overline{z+h})-\overline{f(\bar z)}}{\bar h}} = \overline{f'(\bar z)}$ Since $ f'(\bar z)$ exists, $g(z)= \overline {f(\bar z)}$ is holomorphic. This question is actually an old one, but it is not duplicated, because I want to ask how to use Cauchy Riemann Equations to solve it. I mean, if I write $f(z)=u(x,y)+iv(x,y)$ and $g(z)=u(x,-y)-iv(x,-y)$ , and try to show $g(z)$ is holomorphic by CREs, what should I do? The relationship between partial derivatives of $u(x,y)$ and $u(x,-y)$ is not just addition inverse. So what should I do next? Also, I will be very grateful if you can help me to check my proof is correct. So, actually my question is, how do I write $\frac {\partial} {\partial x } u(x,-y),\frac {\partial} {\partial y } u(x,-y)$ ?","Given a function is holomorphic on a disc , we want to prove that is holomorphic. Below is my proof. Since exists, is holomorphic. This question is actually an old one, but it is not duplicated, because I want to ask how to use Cauchy Riemann Equations to solve it. I mean, if I write and , and try to show is holomorphic by CREs, what should I do? The relationship between partial derivatives of and is not just addition inverse. So what should I do next? Also, I will be very grateful if you can help me to check my proof is correct. So, actually my question is, how do I write ?","f(z) D(0,R) g(z)= \overline {f(\bar z)} \lim_{h\to 0} \frac{\overline {f(\overline{z+h})}-\overline{f(\bar z)}}{h} =  \lim_{h\to 0} \frac{\overline {f(\overline{z+h})-\overline{f(\bar z)}}}{h} = \overline{\lim_{h\to 0} \frac {f(\overline{z+h})-\overline{f(\bar z)}}{\bar h}} = \overline{f'(\bar z)}  f'(\bar z) g(z)= \overline {f(\bar z)} f(z)=u(x,y)+iv(x,y) g(z)=u(x,-y)-iv(x,-y) g(z) u(x,y) u(x,-y) \frac {\partial} {\partial x } u(x,-y),\frac {\partial} {\partial y } u(x,-y)","['complex-analysis', 'cauchy-riemann-equations']"
50,How to show that $ze^z$ is univalent on the unit disk?,How to show that  is univalent on the unit disk?,ze^z,"How can I show that the analytic function $z \mapsto ze^{z}$ is univalent (i.e. injective) on the unit disk $\mathbb{D} = \{z \in \mathbb{C} : |z|<1\} ?$ I can show it on the real interval $]-1,1[$ using increasing properties but not in the complex setting. Please, if possible, suggest me elementary methods (not involving Lambert functions).","How can I show that the analytic function is univalent (i.e. injective) on the unit disk I can show it on the real interval using increasing properties but not in the complex setting. Please, if possible, suggest me elementary methods (not involving Lambert functions).","z \mapsto ze^{z} \mathbb{D} = \{z \in \mathbb{C} : |z|<1\} ? ]-1,1[","['complex-analysis', 'exponential-function']"
51,Implications of Analyticity,Implications of Analyticity,,"After reading the text on analyticity and viewing different theorems, somehow I made the following conclusions. Can please someone validate and throw some light on them? If a function is differentiable at a point $z_0$ , then the partial derivatives may or may not be continuous at that point. So, if the partial derivatives are continuous at that point, then this would imply analyticity at that point. And if the partial derivatives are not continuous at that point, then it will not be analytic at that point. However, if a function is analytic at a point $z_0$ , then this assures the existence of continuous partial derivatives at that point. Well it seems true to me, as differentiability at a point and differentiability at a point along with its some neighborhood are two different things. At last, Can I have an example of a function f(z) which is differentiable at a point $z_0$ but does not have continuous partial derivatives at that point? I know this can happen.","After reading the text on analyticity and viewing different theorems, somehow I made the following conclusions. Can please someone validate and throw some light on them? If a function is differentiable at a point , then the partial derivatives may or may not be continuous at that point. So, if the partial derivatives are continuous at that point, then this would imply analyticity at that point. And if the partial derivatives are not continuous at that point, then it will not be analytic at that point. However, if a function is analytic at a point , then this assures the existence of continuous partial derivatives at that point. Well it seems true to me, as differentiability at a point and differentiability at a point along with its some neighborhood are two different things. At last, Can I have an example of a function f(z) which is differentiable at a point but does not have continuous partial derivatives at that point? I know this can happen.",z_0 z_0 z_0,"['complex-analysis', 'analytic-functions']"
52,A Complex Function is Constant if It Satisfies One of These Properties,A Complex Function is Constant if It Satisfies One of These Properties,,"I am given that a complex function $f(z) = u(x,y) + iv(x,y)$ is analytic in a region $\Omega$ . I am also given a list of conditions and must show that if $f$ satisfies any one of those conditions in $\Omega$ , then $f$ is constant in $\Omega$ . These are the conditions that I am having trouble with: a. $f(\Omega) = \{f(z) : z \in \Omega\}$ is a subset of a circle. b. $u^n(x,y) = v(x,y)$ for some $n \in \mathbb{N}$ . c. $Re(f)$ is analytic on $\Omega$ . My thoughts for part a: is this property saying that f is bounded by the subset of the circle? If so, can I apply Liouville's Theorem and say that since f is bounded, it must be constant? For part b., my approach was to substitute $u^n(x,y)$ in for $v(x,y)$ in the function, and then use the Cauchy Riemann equations (since $f(z)$ is analytic). Calculating the partial derivatives gave me $u_x = nu^{n-1}u_y$ and $u_y = -nu^{n-1}u_x$ . I am not sure if I did the partial differentiation correctly, though, and I'm not sure where to go from here. For part c., I understand what it means for a complex function to be analytic, but what does it mean for its real part to be analytic? And how does that show that $f$ is constant on the region $\Omega$ ?","I am given that a complex function is analytic in a region . I am also given a list of conditions and must show that if satisfies any one of those conditions in , then is constant in . These are the conditions that I am having trouble with: a. is a subset of a circle. b. for some . c. is analytic on . My thoughts for part a: is this property saying that f is bounded by the subset of the circle? If so, can I apply Liouville's Theorem and say that since f is bounded, it must be constant? For part b., my approach was to substitute in for in the function, and then use the Cauchy Riemann equations (since is analytic). Calculating the partial derivatives gave me and . I am not sure if I did the partial differentiation correctly, though, and I'm not sure where to go from here. For part c., I understand what it means for a complex function to be analytic, but what does it mean for its real part to be analytic? And how does that show that is constant on the region ?","f(z) = u(x,y) + iv(x,y) \Omega f \Omega f \Omega f(\Omega) = \{f(z) : z \in \Omega\} u^n(x,y) = v(x,y) n \in \mathbb{N} Re(f) \Omega u^n(x,y) v(x,y) f(z) u_x = nu^{n-1}u_y u_y = -nu^{n-1}u_x f \Omega",[]
53,Estimating $|\int_{\beta}\exp(iz^2)\ dz|$,Estimating,|\int_{\beta}\exp(iz^2)\ dz|,"Let $R > 0$ and consider a curve $$\beta(t) = R\exp(it), \ \ \ \ \ \ \ \ \ 0 \leq t \leq \pi/4.$$ I need to show that $$\left|\int_{\beta}\exp(iz^2)\ dz \right| \leq \frac{\pi(1-\exp(-R^2))}{4R}.$$ Attempt: Well, I thought I will just use the ML-estimate, but I got stuck. I have calculated the length of the arc of the curve $\beta$ : $$l(\beta) = \int_0^{\pi/4}|\beta^{\prime}(t)|dt = \int_0^{\pi/4}|iR\exp(it)|\ dt = \int_0^{\pi/4}R^2\ dt = \frac{\pi R^2}{4}.$$ Now I would like to find an $M > 0$ such that $|\exp(iz^2)|$ for any $z \in \ \text{Image}\ \beta $ . We have $|\exp(iz^2)| = \exp(-R^2\sin(2t))$ . Using $\sin(2t) \geq \frac{4}{\pi}t$ (which I dont understand how that is true), for any $t \in [0, \pi/4]$ , it yields that $$|\exp(iz^2)| \leq \exp\left(-R^2\frac{4}{\pi}t\right).$$ From here, I don't know how to proceed.","Let and consider a curve I need to show that Attempt: Well, I thought I will just use the ML-estimate, but I got stuck. I have calculated the length of the arc of the curve : Now I would like to find an such that for any . We have . Using (which I dont understand how that is true), for any , it yields that From here, I don't know how to proceed.","R > 0 \beta(t) = R\exp(it), \ \ \ \ \ \ \ \ \ 0 \leq t \leq \pi/4. \left|\int_{\beta}\exp(iz^2)\ dz \right| \leq \frac{\pi(1-\exp(-R^2))}{4R}. \beta l(\beta) = \int_0^{\pi/4}|\beta^{\prime}(t)|dt = \int_0^{\pi/4}|iR\exp(it)|\ dt = \int_0^{\pi/4}R^2\ dt = \frac{\pi R^2}{4}. M > 0 |\exp(iz^2)| z \in \ \text{Image}\ \beta  |\exp(iz^2)| = \exp(-R^2\sin(2t)) \sin(2t) \geq \frac{4}{\pi}t t \in [0, \pi/4] |\exp(iz^2)| \leq \exp\left(-R^2\frac{4}{\pi}t\right).","['complex-analysis', 'complex-integration']"
54,$q$-expansion of Klein's absolute invariant using infinite products,-expansion of Klein's absolute invariant using infinite products,q,"Given that $$j=\frac{1}{13824q^2}\left(2^8q^2\prod_{k\gt 0}(1+q^{2k})^{16}+\prod_{k\gt 0}(1+q^{2k-1})^{16}+\prod_{k\gt 0}(1-q^{2k-1})^{16}\right)^3,$$ how can I show that $$j=\frac{1}{1728q^2}(1+c_1 q^2+c_2 q^4+\cdots)$$ where $c_1,\, c_2,\, \ldots$ are some constants? I'm interested in the first term, i.e. $\frac{1}{1728q^2}$ . I tried expanding the product, which gives $$j=\frac{1}{13824q^2}\left(2^{24}q^6\prod_{k\gt 0}(1+q^{2k})^{48}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{32}(1+q^{2k-1})^{16}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{32}(1-q^{2k-1})^{16}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{16}(1+q^{2k-1})^{32}+6\cdot 2^8q^2\prod_{k\gt 0}(1+q^{2k}-q^{4k-2}-q^{6k-2})^{16}+3\cdot 2^8 q^2\prod_{k\gt 0}(1+q^{2k})^{16}(1-q^{2k-1})^{32}+\prod_{k\gt 0}(1+q^{2k-1})^{48}+3\prod_{k\gt 0}(1+q^{2k-1})^{32}(1-q^{2k-1})^{16}+3\prod_{k\gt 0}(1+q^{2k-1})^{16}(1-q^{2k-1})^{32}+\prod_{k\gt 0}(1-q^{2k-1})^{48}\right).$$ Expanding doesn't seem to help. But I know that the expression above can be written as $$j=\frac{1}{13824}\frac{(\theta _2 ^8(0)+\theta _3 ^8(0)+\theta _4 ^8(0))^3}{q^2\prod_{k\gt 0}(1-q^{2k})^{24}}$$ where $$\begin{align}\theta _2(0)&=2Pq^{\frac{1}{4}}\prod_{k\gt 0}(1+q^{2k})^2\\ \theta _3(0)&=P\prod_{k\gt 0}(1+q^{2k-1})^2\\ \theta _4(0)&=P\prod_{k\gt 0}(1-q^{2k-1})^2\end{align}$$ where $P=\prod_{k\gt 0}(1-q^{2k})$ and $$\theta _2 ^8(0)+\theta _3 ^8(0)+\theta _4 ^8(0)=\frac{3}{\pi ^4}(e_1 ^2+e_2 ^2+e_3 ^2).$$ The symbol $q$ is the nome $e^{\pi i\frac{\omega _1}{\omega _2}}$ and $e_1=\wp \left(\frac{\omega _1}{2}\right)$ , $e_2=\wp \left(\frac{\omega _2}{2}\right)$ and $e_3 =\wp \left(-\frac{\omega _1+\omega _2}{2}\right)$ for the Weierstrass's elliptic function $\wp$ .","Given that how can I show that where are some constants? I'm interested in the first term, i.e. . I tried expanding the product, which gives Expanding doesn't seem to help. But I know that the expression above can be written as where where and The symbol is the nome and , and for the Weierstrass's elliptic function .","j=\frac{1}{13824q^2}\left(2^8q^2\prod_{k\gt 0}(1+q^{2k})^{16}+\prod_{k\gt 0}(1+q^{2k-1})^{16}+\prod_{k\gt 0}(1-q^{2k-1})^{16}\right)^3, j=\frac{1}{1728q^2}(1+c_1 q^2+c_2 q^4+\cdots) c_1,\, c_2,\, \ldots \frac{1}{1728q^2} j=\frac{1}{13824q^2}\left(2^{24}q^6\prod_{k\gt 0}(1+q^{2k})^{48}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{32}(1+q^{2k-1})^{16}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{32}(1-q^{2k-1})^{16}+3\cdot 2^{16}q^4\prod_{k\gt 0}(1+q^{2k})^{16}(1+q^{2k-1})^{32}+6\cdot 2^8q^2\prod_{k\gt 0}(1+q^{2k}-q^{4k-2}-q^{6k-2})^{16}+3\cdot 2^8 q^2\prod_{k\gt 0}(1+q^{2k})^{16}(1-q^{2k-1})^{32}+\prod_{k\gt 0}(1+q^{2k-1})^{48}+3\prod_{k\gt 0}(1+q^{2k-1})^{32}(1-q^{2k-1})^{16}+3\prod_{k\gt 0}(1+q^{2k-1})^{16}(1-q^{2k-1})^{32}+\prod_{k\gt 0}(1-q^{2k-1})^{48}\right). j=\frac{1}{13824}\frac{(\theta _2 ^8(0)+\theta _3 ^8(0)+\theta _4 ^8(0))^3}{q^2\prod_{k\gt 0}(1-q^{2k})^{24}} \begin{align}\theta _2(0)&=2Pq^{\frac{1}{4}}\prod_{k\gt 0}(1+q^{2k})^2\\ \theta _3(0)&=P\prod_{k\gt 0}(1+q^{2k-1})^2\\ \theta _4(0)&=P\prod_{k\gt 0}(1-q^{2k-1})^2\end{align} P=\prod_{k\gt 0}(1-q^{2k}) \theta _2 ^8(0)+\theta _3 ^8(0)+\theta _4 ^8(0)=\frac{3}{\pi ^4}(e_1 ^2+e_2 ^2+e_3 ^2). q e^{\pi i\frac{\omega _1}{\omega _2}} e_1=\wp \left(\frac{\omega _1}{2}\right) e_2=\wp \left(\frac{\omega _2}{2}\right) e_3 =\wp \left(-\frac{\omega _1+\omega _2}{2}\right) \wp","['complex-analysis', 'infinite-product', 'q-series', 'modular-function']"
55,Simple proof for the result:$a$ is a removable singularity of $e^f$ iff $a$ is a removable singularity of $f$.,Simple proof for the result: is a removable singularity of  iff  is a removable singularity of .,a e^f a f,"Suppose $f$ is analytic in $0<|z-a|<R$ for some $R>0$ . Then $a$ is a removable singularity of $e^f$ $\iff$ $a$ is a removable singularity of $f$ . Proof : that $a$ is a removable singularity of $f$ implies $a$ is a removable singularity of $e^f$ is clear. For the other direction: for any $0<r<R$ , by the Argument Principle: $$\int_{|z-a|=r}\frac{\left(e^{f(z)}\right)'}{e^{f(z)}}\,dz =\int_{|z-a|=r}f'(z)\,dz = 0,$$ and this implies that $e^{f(z)}$ has no zero at $a$ . If $e^{f(z)}$ has a removable singularity at $a$ , then $e^{f(z)}$ is analytic in the disk $|z-a|<R$ , and $$e^{f(a)}=\lim_{z\to a}e^{f(z)},\qquad e^{f(z)}\neq 0,\quad |z-a|<R.$$ Let $F(z)=e^{f(z)}$ , then $f'(z)=F'(z)e^{-f(z)}$ is analytic in $|z-a|<R$ . So $f(z)$ has a removable singularity at $a$ . The proof above uses the ""Argument Principle"", it is seems to use a ""big"" tool to prove this ""small"" result. What I want to say is that: is there a ""simple"" method to prove this ""small"" result, any helps and hints will welcome!","Suppose is analytic in for some . Then is a removable singularity of is a removable singularity of . Proof : that is a removable singularity of implies is a removable singularity of is clear. For the other direction: for any , by the Argument Principle: and this implies that has no zero at . If has a removable singularity at , then is analytic in the disk , and Let , then is analytic in . So has a removable singularity at . The proof above uses the ""Argument Principle"", it is seems to use a ""big"" tool to prove this ""small"" result. What I want to say is that: is there a ""simple"" method to prove this ""small"" result, any helps and hints will welcome!","f 0<|z-a|<R R>0 a e^f \iff a f a f a e^f 0<r<R \int_{|z-a|=r}\frac{\left(e^{f(z)}\right)'}{e^{f(z)}}\,dz
=\int_{|z-a|=r}f'(z)\,dz = 0, e^{f(z)} a e^{f(z)} a e^{f(z)} |z-a|<R e^{f(a)}=\lim_{z\to a}e^{f(z)},\qquad e^{f(z)}\neq 0,\quad |z-a|<R. F(z)=e^{f(z)} f'(z)=F'(z)e^{-f(z)} |z-a|<R f(z) a",['complex-analysis']
56,Question in Proof of Riemann's theorem on removable singularities,Question in Proof of Riemann's theorem on removable singularities,,"I have this from Shakarchi, in the proof of the 'Riemann's theorem on removable singularities. He states the following: . He uses the following contour: and comes to the following conclusions about the smaller circle containing $z_{o}$ and so on. About the second integral he says: How is he arriving that the bounds is $\leq C\epsilon$ ?","I have this from Shakarchi, in the proof of the 'Riemann's theorem on removable singularities. He states the following: . He uses the following contour: and comes to the following conclusions about the smaller circle containing and so on. About the second integral he says: How is he arriving that the bounds is ?",z_{o} \leq C\epsilon,['complex-analysis']
57,Harmonic function and harmonic conjugate,Harmonic function and harmonic conjugate,,"Let $u:G\subset\mathbb{R} \rightarrow \mathbb{R}$ a harmonic function $v:G\rightarrow \mathbb{R}$ the harmonic conjugate function, with $G$ a domain. Prove that $u^2-v^2$ and $uv$ are harmonic without derivatives. Before this, I proved that $u^2$ is harmonic, if $u$ is an harmonic function. Then, I thought that $u^2$ and $v^2$ are harmonic functions, and I wanted to conclude that $u^2-v^2$ is a harmonic function. Nonetheless, this interpretation is wrong. Thanks in advance","Let a harmonic function the harmonic conjugate function, with a domain. Prove that and are harmonic without derivatives. Before this, I proved that is harmonic, if is an harmonic function. Then, I thought that and are harmonic functions, and I wanted to conclude that is a harmonic function. Nonetheless, this interpretation is wrong. Thanks in advance",u:G\subset\mathbb{R} \rightarrow \mathbb{R} v:G\rightarrow \mathbb{R} G u^2-v^2 uv u^2 u u^2 v^2 u^2-v^2,"['complex-analysis', 'harmonic-functions']"
58,Can anyone prove that gamma function is complex for complex inputs?,Can anyone prove that gamma function is complex for complex inputs?,,"I am learning about gamma function and just got a doubt that how can I prove that gamma function gives out a complex number when taken complex numbers as inputs and that no real number would be obtained when complex numbers are taken as inputs. I am trying to prove this,but I don't think so that I have enough information of gamma function to prove that. Thanks in advance","I am learning about gamma function and just got a doubt that how can I prove that gamma function gives out a complex number when taken complex numbers as inputs and that no real number would be obtained when complex numbers are taken as inputs. I am trying to prove this,but I don't think so that I have enough information of gamma function to prove that. Thanks in advance",,"['complex-analysis', 'number-theory', 'gamma-function', 'complex-integration']"
59,Understanding Difference Between Cauchy-Goursat and Related Theorem,Understanding Difference Between Cauchy-Goursat and Related Theorem,,"I am reading Brown and Churchill's Introductory complex analysis book, which states the Cauchy-Goursat theorem as follows: If a function $f$ is analytic at all points interior to and on a simple closed contour $C$ , then $$ \int_{C} f(z) dz =0 $$ I understand this result and its proof just fine. However, there is a second theorem which claims the following: If a function $f$ is analytic throughout a simply connected domain $D$ , then $$ \int_{C} f(z) dz =0 $$ for every closed contour $C$ lying in $D$ . So in this second theorem we don't $C$ to be simple due to the fact that $D$ is simply connected. However, if $f$ is analytic at all points interior to and on a closed contour $C$ , isn't the interior of the closed contour $C$ a simply-connected domain by default? To be more precise, if I rewrite the first theorem as: If a function $f$ is analytic at all points interior to and on a closed contour $C$ , then $$ \int_{C} f(z) dz =0 $$ is this not true? I don't see why we require $C$ to be simple, because even if $C$ intersects itself, we can just treat our non-simple closed contour as a union of simple closed contours, and those integrals are all $0$ .","I am reading Brown and Churchill's Introductory complex analysis book, which states the Cauchy-Goursat theorem as follows: If a function is analytic at all points interior to and on a simple closed contour , then I understand this result and its proof just fine. However, there is a second theorem which claims the following: If a function is analytic throughout a simply connected domain , then for every closed contour lying in . So in this second theorem we don't to be simple due to the fact that is simply connected. However, if is analytic at all points interior to and on a closed contour , isn't the interior of the closed contour a simply-connected domain by default? To be more precise, if I rewrite the first theorem as: If a function is analytic at all points interior to and on a closed contour , then is this not true? I don't see why we require to be simple, because even if intersects itself, we can just treat our non-simple closed contour as a union of simple closed contours, and those integrals are all .",f C  \int_{C} f(z) dz =0  f D  \int_{C} f(z) dz =0  C D C D f C C f C  \int_{C} f(z) dz =0  C C 0,"['complex-analysis', 'complex-integration', 'cauchy-integral-formula']"
60,Is $\oint_{\left | z \right |=2} \frac{e^{\frac{1}{z}}}{z(z^{2}+1))}dz$ equal to zero?,Is  equal to zero?,\oint_{\left | z \right |=2} \frac{e^{\frac{1}{z}}}{z(z^{2}+1))}dz,"I based my analysis on the fact that the only residue that's outside the curve is the reside in $\infty$ that's equal to zero, so all the other resides inside the curves must add to zero too. Am I correct?","I based my analysis on the fact that the only residue that's outside the curve is the reside in that's equal to zero, so all the other resides inside the curves must add to zero too. Am I correct?",\infty,"['complex-analysis', 'contour-integration', 'residue-calculus']"
61,Evaluating $I=\oint \frac{\cos(z)}{z(e^{z}-1)}dz$ along the unit circle,Evaluating  along the unit circle,I=\oint \frac{\cos(z)}{z(e^{z}-1)}dz,Evaluate the following along the unit circle: $$I=\oint \frac{\cos(z)}{z(e^{z}-1)}dz$$ I tried doing it by $$f(z)=\frac{\cos(z)}{e^{z}-1}$$ Then the integral would be: $$I=2\pi if(0)$$ The problem is that $f(0)$ gives me $\frac{1}{0}$ . So how do I solve it?,Evaluate the following along the unit circle: I tried doing it by Then the integral would be: The problem is that gives me . So how do I solve it?,I=\oint \frac{\cos(z)}{z(e^{z}-1)}dz f(z)=\frac{\cos(z)}{e^{z}-1} I=2\pi if(0) f(0) \frac{1}{0},"['calculus', 'complex-analysis', 'contour-integration', 'complex-integration']"
62,Taylor coefficient of $f(z)=\exp\left\{\frac{z+1}{z-1}\right\}$,Taylor coefficient of,f(z)=\exp\left\{\frac{z+1}{z-1}\right\},"I am trying to figure out the Taylor coefficient of $\exp\left\{\frac{z+1}{z-1}\right\}$ . My idea is as follows: $$f(z)=\exp\left\{\frac{z+1}{z-1}\right\}=\exp\left\{1+\frac{2}{z-1}\right\}=e\exp\left\{\frac{2}{z-1}\right\}.$$ Then we have $f(z)=e\sum_{n=0}^{+\infty}\frac{w^n}{n!}$ , where $w=\frac{2}{z-1}$ . Clearly, we have $$w^n=(-2)^n(1-z)^{-n}=(-2)^n\sum_{k=0}^{+\infty}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k.$$ It follows that $$f(z)=e\sum_{n=0}^{+\infty}\frac{w^n}{n!}=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\sum_{k=0}^{+\infty}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k=e\sum_{k=0}^{+\infty}\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k.$$ Namely, the $n$ -th coefficient of $f$ is given by $$\widehat{f}(k)=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+k)}{k!\Gamma(n)}.$$ I have checked that $\widehat{f}(0)=f(0)$ and $\widehat{f}(1)=f'(0)$ . Moreover, the fact that $f''(0)=0$ implies that $\widehat{f}(2)$ should be zero. But in our result it seems that $$\widehat{f}(2)=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+2)}{2!\Gamma(n)}\neq 0.$$ What is wrong with my formula? Could you help me figure our the problem and tfind out the Taylor coefficient of the $f$ ? Thank you!","I am trying to figure out the Taylor coefficient of . My idea is as follows: Then we have , where . Clearly, we have It follows that Namely, the -th coefficient of is given by I have checked that and . Moreover, the fact that implies that should be zero. But in our result it seems that What is wrong with my formula? Could you help me figure our the problem and tfind out the Taylor coefficient of the ? Thank you!",\exp\left\{\frac{z+1}{z-1}\right\} f(z)=\exp\left\{\frac{z+1}{z-1}\right\}=\exp\left\{1+\frac{2}{z-1}\right\}=e\exp\left\{\frac{2}{z-1}\right\}. f(z)=e\sum_{n=0}^{+\infty}\frac{w^n}{n!} w=\frac{2}{z-1} w^n=(-2)^n(1-z)^{-n}=(-2)^n\sum_{k=0}^{+\infty}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k. f(z)=e\sum_{n=0}^{+\infty}\frac{w^n}{n!}=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\sum_{k=0}^{+\infty}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k=e\sum_{k=0}^{+\infty}\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+k)}{k!\Gamma(n)}z^k. n f \widehat{f}(k)=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+k)}{k!\Gamma(n)}. \widehat{f}(0)=f(0) \widehat{f}(1)=f'(0) f''(0)=0 \widehat{f}(2) \widehat{f}(2)=e\sum_{n=0}^{+\infty}\frac{(-2)^n}{n!}\frac{\Gamma(n+2)}{2!\Gamma(n)}\neq 0. f,['complex-analysis']
63,Holomorphic maps preserve Hausdorff dimension.,Holomorphic maps preserve Hausdorff dimension.,,"In a paper I read there is the following claim: Let $f:\mathbb{C}\to \mathbb{C}$ be a non-constant entire transcendental function(essential singularity at infinity) and $A\subset \mathbb{C}$ a set in the complex plane. Then $f^{-1}(A)$ , $A$ and $f(A)$ have the same Hausdorff dimension. I know that bi-Lipschitz maps preserve Hausdorff dimension but I dont see why entire maps in the complex plane should too. Perhaps because entire maps are locally bi-Lipschitz away from critical points. But do locally bi-Lipschitz maps preserve the dimension? Can someone prove this or provide a reference for a proof?","In a paper I read there is the following claim: Let be a non-constant entire transcendental function(essential singularity at infinity) and a set in the complex plane. Then , and have the same Hausdorff dimension. I know that bi-Lipschitz maps preserve Hausdorff dimension but I dont see why entire maps in the complex plane should too. Perhaps because entire maps are locally bi-Lipschitz away from critical points. But do locally bi-Lipschitz maps preserve the dimension? Can someone prove this or provide a reference for a proof?",f:\mathbb{C}\to \mathbb{C} A\subset \mathbb{C} f^{-1}(A) A f(A),"['complex-analysis', 'geometric-measure-theory', 'dimension-theory-analysis']"
64,Find the singularities of $f(z) =\frac{1}{(2\sin z - 1)^2}$.,Find the singularities of .,f(z) =\frac{1}{(2\sin z - 1)^2},"Find the singularities of $f(z) =\frac{1}{(2\sin z - 1)^2}$ . I am just learning about singularities and I was wondering if someone could give me feedback on my work. So I think, for this function, that there are singularities at $z=\frac{\pi}{6}+2k\pi,\frac{5\pi}{6}+2k\pi$ , would this be correct? Additionally, I am classifying them as essential and nonremovable. Is this also correct? To determine that they were nonremovable, I tool the limit of the function approaching the singularities and found that they tended towards infinity.","Find the singularities of . I am just learning about singularities and I was wondering if someone could give me feedback on my work. So I think, for this function, that there are singularities at , would this be correct? Additionally, I am classifying them as essential and nonremovable. Is this also correct? To determine that they were nonremovable, I tool the limit of the function approaching the singularities and found that they tended towards infinity.","f(z) =\frac{1}{(2\sin z - 1)^2} z=\frac{\pi}{6}+2k\pi,\frac{5\pi}{6}+2k\pi","['complex-analysis', 'complex-numbers', 'singularity']"
65,Prove that $f(z)=\sum_{n=1}^\infty \exp(-n!z)$ has no analytic continuation,Prove that  has no analytic continuation,f(z)=\sum_{n=1}^\infty \exp(-n!z),"Prove that $f(z)=\sum_{n=1}^\infty\exp(-n!z)$ has no analytic continuation to any open connected subset of $\mathbb{C}$ that strictly contains $\{z\in\mathbb{C}:\text{Re}z>0\}$ . My proof: If $U$ is an open connected subset of $\mathbb{C}$ that strictly contains $\{z\in\mathbb{C}:\text{Re}z>0\}$ , and $f$ can be extended analytically to $U$ , then there exists $b\in\mathbb{R}$ such that $bi\in U$ . Furthermore, we may assume that $b$ is rational, which means that $n!b$ is an even integer for all $n$ large enough. This means that if $a>0$ , then $$f(a+bi)=C+e^{-n!a}+e^{-(n+1)!a}+e^{-(n+2)!a}+...$$ where $C$ is a complex number. Therefore, we get $|f(a+bi)|\rightarrow \infty$ as $a\rightarrow 0+$ by the monotone convergence theorem. This is means that there isn't even a continuous extension. My questions: is my proof correct? Also I feel like my proof is too specific to this question, if they change the formula of $f$ to for example $\sum_{n=1}^\infty e^{(-n!+\sin n)z}$ my proof will not work. Are there any better, more general proofs available? Thanks!!","Prove that has no analytic continuation to any open connected subset of that strictly contains . My proof: If is an open connected subset of that strictly contains , and can be extended analytically to , then there exists such that . Furthermore, we may assume that is rational, which means that is an even integer for all large enough. This means that if , then where is a complex number. Therefore, we get as by the monotone convergence theorem. This is means that there isn't even a continuous extension. My questions: is my proof correct? Also I feel like my proof is too specific to this question, if they change the formula of to for example my proof will not work. Are there any better, more general proofs available? Thanks!!",f(z)=\sum_{n=1}^\infty\exp(-n!z) \mathbb{C} \{z\in\mathbb{C}:\text{Re}z>0\} U \mathbb{C} \{z\in\mathbb{C}:\text{Re}z>0\} f U b\in\mathbb{R} bi\in U b n!b n a>0 f(a+bi)=C+e^{-n!a}+e^{-(n+1)!a}+e^{-(n+2)!a}+... C |f(a+bi)|\rightarrow \infty a\rightarrow 0+ f \sum_{n=1}^\infty e^{(-n!+\sin n)z},['complex-analysis']
66,Gradient of complex-valued function with respect to real and imaginary components,Gradient of complex-valued function with respect to real and imaginary components,,"Let $J(\mathbf{z})$ be a complex-valued (scalar) function where $\mathbf{z}\in \mathbb{C}^n$ , and write $\mathbf{z} = \mathbf{x} + i \mathbf{y}$ for real vectors $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$ . In the book I'm reading, the gradient of $J$ with respect to $\mathbf{x},\mathbf{y}$ as $$ \begin{align}\frac{\partial J}{\partial \mathbf{x}} &= \frac{\partial J}{\partial \mathbf{z}} + \frac{\partial J}{\partial \mathbf{z}^*}\\[1mm] \frac{\partial J}{\partial \mathbf{y}} &= i\frac{\partial J}{\partial \mathbf{z}} -i \frac{\partial J}{\partial \mathbf{z}^*}\end{align}, $$ where $\mathbf{z}^*$ is the conjugate of $\mathbf{z}$ . (I simplified the notation because the one used in the text is quite ugly, e.g., $\mathbf{z}$ is written as $\mathbf{c} = \mathbf{c_c} + j\mathbf{c_s}$ .) My question is: how is this set of equations derived? I understand that there is a one-to-one mapping between $(\mathbf{x},\mathbf{y})$ and $(\mathbf{z},\mathbf{z}^*)$ , but I'm not sure how to deal with ""chain rule"" (if that's a proper term) for vector transformations.","Let be a complex-valued (scalar) function where , and write for real vectors . In the book I'm reading, the gradient of with respect to as where is the conjugate of . (I simplified the notation because the one used in the text is quite ugly, e.g., is written as .) My question is: how is this set of equations derived? I understand that there is a one-to-one mapping between and , but I'm not sure how to deal with ""chain rule"" (if that's a proper term) for vector transformations.","J(\mathbf{z}) \mathbf{z}\in \mathbb{C}^n \mathbf{z} = \mathbf{x} + i \mathbf{y} \mathbf{x}, \mathbf{y} \in \mathbb{R}^n J \mathbf{x},\mathbf{y} 
\begin{align}\frac{\partial J}{\partial \mathbf{x}} &= \frac{\partial J}{\partial \mathbf{z}} + \frac{\partial J}{\partial \mathbf{z}^*}\\[1mm] \frac{\partial J}{\partial \mathbf{y}} &= i\frac{\partial J}{\partial \mathbf{z}} -i \frac{\partial J}{\partial \mathbf{z}^*}\end{align},
 \mathbf{z}^* \mathbf{z} \mathbf{z} \mathbf{c} = \mathbf{c_c} + j\mathbf{c_s} (\mathbf{x},\mathbf{y}) (\mathbf{z},\mathbf{z}^*)","['complex-analysis', 'partial-derivative', 'vector-analysis', 'chain-rule']"
67,Evaluate the integral using Euler integrals,Evaluate the integral using Euler integrals,,"I have the following integral: $$\int_{0}^\infty \frac{\sqrt{x}}{7+x^7} \ dx$$ I want to evaluate this using the Euler integral. What I have tried: I tried to make a substitution, because I want to evaluate it via gamma integrals. But I can not find the substitution. Can somebody help me with the substitution? My attempt: I made the substitution $$t = \frac{1}{7}x^7, \ \ \ x = (7x)^{1/7}, \ \ \ dx = (7t)^{-6/7} dt, \ \ \ \Rightarrow x^{1/2} = (7t)^{1/14}$$ I fill in and receive: $$\int_{0}^\infty \frac{\sqrt{x}}{7+x^7} \ dx = \frac{1}{7} \int_{0}^\infty \frac{\sqrt{x}}{1+\frac{1}{7}x^7} \ dx = \frac{7^{(-11/14)}}{7}\int_{0}^\infty \frac{t^{(1/14) - (6/7)}}{1+t} \ dt$$ After that, I continued: $$\frac{7^{(-11/14)}}{7}\int_{0}^\infty \frac{t^{(-11/14)}}{1+t} \ dt = \frac{7^{(-11/14)}}{7} B(\frac{3}{14}, 1-\frac{3}{14}) = \frac{7^{(-11/14)}}{7} \frac{\Gamma(\frac{3}{14})\cdot \Gamma(1-\frac{3}{14})}{\Gamma(1)} = \frac{7^{(-11/14)}}{7}\frac{\pi}{\sin(\frac{3\pi}{14})}$$ But the answer has to be $\frac{1}{7^{25/14}}\frac{\pi}{\sin(\frac{3\pi}{14})}$ Where did I make the mistake?","I have the following integral: I want to evaluate this using the Euler integral. What I have tried: I tried to make a substitution, because I want to evaluate it via gamma integrals. But I can not find the substitution. Can somebody help me with the substitution? My attempt: I made the substitution I fill in and receive: After that, I continued: But the answer has to be Where did I make the mistake?","\int_{0}^\infty \frac{\sqrt{x}}{7+x^7} \ dx t = \frac{1}{7}x^7, \ \ \ x = (7x)^{1/7}, \ \ \ dx = (7t)^{-6/7} dt, \ \ \ \Rightarrow x^{1/2} = (7t)^{1/14} \int_{0}^\infty \frac{\sqrt{x}}{7+x^7} \ dx = \frac{1}{7} \int_{0}^\infty \frac{\sqrt{x}}{1+\frac{1}{7}x^7} \ dx = \frac{7^{(-11/14)}}{7}\int_{0}^\infty \frac{t^{(1/14) - (6/7)}}{1+t} \ dt \frac{7^{(-11/14)}}{7}\int_{0}^\infty \frac{t^{(-11/14)}}{1+t} \ dt = \frac{7^{(-11/14)}}{7} B(\frac{3}{14}, 1-\frac{3}{14}) = \frac{7^{(-11/14)}}{7} \frac{\Gamma(\frac{3}{14})\cdot \Gamma(1-\frac{3}{14})}{\Gamma(1)} = \frac{7^{(-11/14)}}{7}\frac{\pi}{\sin(\frac{3\pi}{14})} \frac{1}{7^{25/14}}\frac{\pi}{\sin(\frac{3\pi}{14})}","['integration', 'complex-analysis']"
68,Using Euler-Lagrange equations to prove Cauchy's Theorem,Using Euler-Lagrange equations to prove Cauchy's Theorem,,"In complex analysis, there is a theorem that says whenever two curves $\gamma_0$ and $\gamma_1$ are homotopic and contained in an open set $\Omega$ in which $f$ is holomorphic, then we have $\int_{\gamma_0}f(z)dz = \int_{\gamma_1}f(z)dz$ I spotted, with an informal derivation, that this obeys the Euler-Lagrange conditions, for $z(t)$ being the function that varies in the functional. Could you then argue, loosely speaking, that as the 'functional limit' (I haven't studied functionals in any great detail) is zero everywhere, then the functional must be constant?","In complex analysis, there is a theorem that says whenever two curves and are homotopic and contained in an open set in which is holomorphic, then we have I spotted, with an informal derivation, that this obeys the Euler-Lagrange conditions, for being the function that varies in the functional. Could you then argue, loosely speaking, that as the 'functional limit' (I haven't studied functionals in any great detail) is zero everywhere, then the functional must be constant?",\gamma_0 \gamma_1 \Omega f \int_{\gamma_0}f(z)dz = \int_{\gamma_1}f(z)dz z(t),"['complex-analysis', 'functional-equations', 'euler-lagrange-equation']"
69,Computing $\int_{0}^{\infty} \frac{x}{x^{4}+1} dx$ using complex analysis.,Computing  using complex analysis.,\int_{0}^{\infty} \frac{x}{x^{4}+1} dx,"I want to compute $$\int_{0}^{\infty} \frac{x}{x^{4}+1} dx$$ using complex analysis. Now the first thing that strikes me is that $f(x)$ is not an even function. So this troubles me a bit since I would normally use $$\int_{0}^{\infty} f(x)dx = \frac{1}{2} \left[\lim_{R \rightarrow \infty} \int_{-R}^{R} f(z)dz + \int_{C_{R}}f(z)dz \right], $$ where $C_{R}$ is the semi cirle connecting $R$ to $-R$ in the positive imaginary part. Now we see that we have to compute the singularities of $f(z)$ , which we can do by computing the fourth root of $z$ . We then find $$ \begin{align*} z^{4} &= e^{i (\pi + 2n\pi)} \\ z &= e^{i ( \frac{\pi}{4} + \frac{n\pi}{2} )} \end{align*}. $$ Since we are only interested in singularities above the real line, we find $z_{0} = e^{i \frac{\pi}{4}}$ and $z_{1} = e^{i \frac{3\pi}{4}}$ . Then we let $p(z) = z$ and $q(z) = z^{4}+1$ , which makes $q'(z) = 4z^{3}$ .  We then compute $p(z_{0}), q(z_{0})$ and $q'(z_{0})$ and finally $\frac{p(z)}{q'(z)}$ which equals the residue at $z_{0}$ . However, when I do the above I find $\text{Res}(z_{0}) = - \frac{i}{4}$ and $\text{Res}(z_{1}) = \frac{i}{4}$ but this would make the integral equal zero since $2\pi i (\frac{i}{4} - \frac{i}{4})=0$ . Can anybody point me to my mistake? Also, when would find the value for this integral, I would argue we can not simply take half of it, since the initial function is not even. How would we fix that?","I want to compute using complex analysis. Now the first thing that strikes me is that is not an even function. So this troubles me a bit since I would normally use where is the semi cirle connecting to in the positive imaginary part. Now we see that we have to compute the singularities of , which we can do by computing the fourth root of . We then find Since we are only interested in singularities above the real line, we find and . Then we let and , which makes .  We then compute and and finally which equals the residue at . However, when I do the above I find and but this would make the integral equal zero since . Can anybody point me to my mistake? Also, when would find the value for this integral, I would argue we can not simply take half of it, since the initial function is not even. How would we fix that?","\int_{0}^{\infty} \frac{x}{x^{4}+1} dx f(x) \int_{0}^{\infty} f(x)dx = \frac{1}{2} \left[\lim_{R \rightarrow \infty} \int_{-R}^{R} f(z)dz + \int_{C_{R}}f(z)dz \right],
 C_{R} R -R f(z) z 
\begin{align*}
z^{4} &= e^{i (\pi + 2n\pi)} \\
z &= e^{i ( \frac{\pi}{4} + \frac{n\pi}{2} )}
\end{align*}.
 z_{0} = e^{i \frac{\pi}{4}} z_{1} = e^{i \frac{3\pi}{4}} p(z) = z q(z) = z^{4}+1 q'(z) = 4z^{3} p(z_{0}), q(z_{0}) q'(z_{0}) \frac{p(z)}{q'(z)} z_{0} \text{Res}(z_{0}) = - \frac{i}{4} \text{Res}(z_{1}) = \frac{i}{4} 2\pi i (\frac{i}{4} - \frac{i}{4})=0","['calculus', 'complex-analysis']"
70,Logarithm of a complex function on a non-simply connected space,Logarithm of a complex function on a non-simply connected space,,"It can be proven that on a simply connected set $U$ in $\mathbb{C}$ where a function $f$ has no zeroes there is a function $g$ such that $e^g = f$ on $U$ . This is done by observing that $\frac{f'}{f}$ is holomorphic and therefore has a ""primitive"". I suspect that the requirement that $U$ be simply connected is sufficient, but not required. This comes from an exercise I've been trying to solve: Consider $U=\mathbb{C} \setminus \{ -1,1 \}$ . This set is obviously not   simply connected, and the function $f(z) = z^2 -1$ has no zeroes on   it. Does there exist an holomorphic function $h$ on $U$ such that $e^{h(z)}=f(z)$ on $U$ ? Is there really such a function or is simple-connectedness necessary?","It can be proven that on a simply connected set in where a function has no zeroes there is a function such that on . This is done by observing that is holomorphic and therefore has a ""primitive"". I suspect that the requirement that be simply connected is sufficient, but not required. This comes from an exercise I've been trying to solve: Consider . This set is obviously not   simply connected, and the function has no zeroes on   it. Does there exist an holomorphic function on such that on ? Is there really such a function or is simple-connectedness necessary?","U \mathbb{C} f g e^g = f U \frac{f'}{f} U U=\mathbb{C} \setminus \{ -1,1 \} f(z) = z^2 -1 h U e^{h(z)}=f(z) U","['complex-analysis', 'logarithms', 'connectedness']"
71,If $\lim_{r \to 1} \frac{1}{2\pi}\int_0^{2\pi} \left| \log \left| f(re^{it}) \right| \right| dt = 0$ then $\left| f(z) \right| \leq 1$,If  then,\lim_{r \to 1} \frac{1}{2\pi}\int_0^{2\pi} \left| \log \left| f(re^{it}) \right| \right| dt = 0 \left| f(z) \right| \leq 1,"My aim is to prove that Blaschke products are the only holomorphic funcions that verify the property $$ \lim_{r \to 1} \frac{1}{2\pi} \int_0^{2\pi} \left| \log \left| f(re^{it}) \right| \right| dt = 0. $$ For this, I need to show that if $f$ is a holomorphic function defined in the open unit disc $\mathbb{D}$ such that $$ \lim_{r \to 1} \frac{1}{2\pi} \int_0^{2\pi} \left| \log \left| f(re^{it}) \right| \right| dt = 0 $$ then $\left| f(z) \right| \leq 1$ for all $z \in \mathbb{D}$ . I know that $z \in \mathbb{D} \mapsto \log \left| f(z) \right| $ is a subharmonic function and hence $$ t \in (0,1) \mapsto \frac{1}{2\pi} \int_0^{2\pi}  \log \left| f(re^{it}) \right| dt $$ is an increasing function. How can I conclude?","My aim is to prove that Blaschke products are the only holomorphic funcions that verify the property For this, I need to show that if is a holomorphic function defined in the open unit disc such that then for all . I know that is a subharmonic function and hence is an increasing function. How can I conclude?","
\lim_{r \to 1} \frac{1}{2\pi} \int_0^{2\pi} \left| \log \left| f(re^{it}) \right| \right| dt = 0.
 f \mathbb{D} 
\lim_{r \to 1} \frac{1}{2\pi} \int_0^{2\pi} \left| \log \left| f(re^{it}) \right| \right| dt = 0
 \left| f(z) \right| \leq 1 z \in \mathbb{D} z \in \mathbb{D} \mapsto \log \left| f(z) \right|  
t \in (0,1) \mapsto \frac{1}{2\pi} \int_0^{2\pi}  \log \left| f(re^{it}) \right| dt
","['complex-analysis', 'harmonic-functions', 'blaschke-products']"
72,Bounded number of zeros of derivatives can imply analyticity,Bounded number of zeros of derivatives can imply analyticity,,"I'm trying to prove that if $f\in C^{\infty}(]-1,1[,\mathbb{R})$ and there exists a $p \in \mathbb{N}$ so that for all $n\in\mathbb{N}$ , $f^{(n)}$ has at most $p$ zeros in $]-1,1[$ then $f$ is analytic. I still don't have any concrete idea to move on so any kind of help is fine. Thanks","I'm trying to prove that if and there exists a so that for all , has at most zeros in then is analytic. I still don't have any concrete idea to move on so any kind of help is fine. Thanks","f\in C^{\infty}(]-1,1[,\mathbb{R}) p \in \mathbb{N} n\in\mathbb{N} f^{(n)} p ]-1,1[ f","['calculus', 'complex-analysis', 'derivatives', 'analyticity']"
73,Prove the Uniform Convergence of a Certain Series on Any Compact Subset of C,Prove the Uniform Convergence of a Certain Series on Any Compact Subset of C,,"$D \subset C$ is a connected open set. $a \in D$ , $f \in H(D)$ , the series $\sum_{n=0}^\infty f^{(n)}(a)$ converges. Prove that: $f$ can be extended to an analytic function on $C$ . $\sum_{n=0}^\infty f^{(n)}(z)$ converges uniformly on every compact subset of $C$ . (I am stuck on question 2. After achieving this series $\sum_{n=0}^\infty f^{(n)}(z)=\sum_{n=0}^\infty \sum_{m=0}^\infty f^{(m+n)}{(a)}\frac{(z-a)^m}{m!}$ , I wonder if a limit interchange can be justified.)","is a connected open set. , , the series converges. Prove that: can be extended to an analytic function on . converges uniformly on every compact subset of . (I am stuck on question 2. After achieving this series , I wonder if a limit interchange can be justified.)",D \subset C a \in D f \in H(D) \sum_{n=0}^\infty f^{(n)}(a) f C \sum_{n=0}^\infty f^{(n)}(z) C \sum_{n=0}^\infty f^{(n)}(z)=\sum_{n=0}^\infty \sum_{m=0}^\infty f^{(m+n)}{(a)}\frac{(z-a)^m}{m!},"['sequences-and-series', 'complex-analysis', 'uniform-convergence']"
74,What mistakes were made in evaluating $\int_0^{2\pi}e^{2it}\ln(a^2-2a \cos(t) + 1)dt$,What mistakes were made in evaluating,\int_0^{2\pi}e^{2it}\ln(a^2-2a \cos(t) + 1)dt,"I'm trying to evaluate $$\int_0^{2\pi}e^{2it}\ln(a^2-2a \cos(t) + 1)dt$$ for $a \in (0, 1)$ . I keep getting different answers depending on the method.  First, if I split up the integrals in to real and imaginary parts I get: $$ = \int_0^{2\pi} (\cos(2t) + i \sin(2t)) \ln(a^2-2a \cos(t) + 1)dt\\ = \int_0^{2\pi} \cos(2t) \ln(a^2-2a \cos(t) + 1)dt + i \int_0^{2\pi} \sin(2t) \ln(a^2-2a \cos(t) + 1)dt\\ = - \frac{1}{4 a^2} \left[\begin{array}&  (a^4 + 1) t \\ - 2 (a^4 - 1) \arctan \frac{(a + 1) \tan(t/2)}{a - 1} \\ + 2 (a^3 + a) \sin(t) \\ + a^2 \sin(2 t) (1 - 2 \sin(2 t) \ln(a^2 - 2 a \cos(t) + 1)) \end{array} \right]_0^{2\pi} + i * 0 \\ = - \pi \frac{a^4 + 1}{2 a^2}$$ Where I got $\int \cos(2t) \ln(a^2-2a \cos(t) + 1) dt$ from Wolfram Alpha .  This other online integral calculator gives a different but equivalent antiderivative. Second, if I do a contour integral: $$ = \int_0^{2\pi} e^{2it} \ln((1-ae^{it}) (1 - a e^{-it})) dt \\ = \int_0^{2\pi} e^{2it} (\ln(1-ae^{it}) + \ln(1 - a e^{-it})) dt \\ = \int_0^{2\pi} e^{2it} \ln(1-ae^{it}) + \int_0^{2\pi} e^{2it} \ln(1 - a e^{-it}) dt \\ = \oint \frac{z \ln(1-az)}{i}dz - \oint \frac{\ln(1 - a z)}{iz^3} dz \\ = 2 \pi i (0 - \frac{a^2}{2i}) \\ = -\pi a^2 $$ Third, if I ask an online integral calculator , I just get 0. I have no idea which, if any, answer is correct, or what mistakes I made in any of the methods.  Any help would be appreciated.","I'm trying to evaluate for . I keep getting different answers depending on the method.  First, if I split up the integrals in to real and imaginary parts I get: Where I got from Wolfram Alpha .  This other online integral calculator gives a different but equivalent antiderivative. Second, if I do a contour integral: Third, if I ask an online integral calculator , I just get 0. I have no idea which, if any, answer is correct, or what mistakes I made in any of the methods.  Any help would be appreciated.","\int_0^{2\pi}e^{2it}\ln(a^2-2a \cos(t) + 1)dt a \in (0, 1)  = \int_0^{2\pi} (\cos(2t) + i \sin(2t)) \ln(a^2-2a \cos(t) + 1)dt\\
= \int_0^{2\pi} \cos(2t) \ln(a^2-2a \cos(t) + 1)dt
+ i \int_0^{2\pi} \sin(2t) \ln(a^2-2a \cos(t) + 1)dt\\
= - \frac{1}{4 a^2} \left[\begin{array}&
 (a^4 + 1) t \\
- 2 (a^4 - 1) \arctan \frac{(a + 1) \tan(t/2)}{a - 1} \\
+ 2 (a^3 + a) \sin(t) \\
+ a^2 \sin(2 t) (1 - 2 \sin(2 t) \ln(a^2 - 2 a \cos(t) + 1))
\end{array} \right]_0^{2\pi} + i * 0 \\
= - \pi \frac{a^4 + 1}{2 a^2} \int \cos(2t) \ln(a^2-2a \cos(t) + 1) dt  = \int_0^{2\pi} e^{2it} \ln((1-ae^{it}) (1 - a e^{-it})) dt \\
= \int_0^{2\pi} e^{2it} (\ln(1-ae^{it}) + \ln(1 - a e^{-it})) dt \\
= \int_0^{2\pi} e^{2it} \ln(1-ae^{it}) + \int_0^{2\pi} e^{2it} \ln(1 - a e^{-it}) dt \\
= \oint \frac{z \ln(1-az)}{i}dz - \oint \frac{\ln(1 - a z)}{iz^3} dz \\
= 2 \pi i (0 - \frac{a^2}{2i}) \\
= -\pi a^2
","['integration', 'complex-analysis', 'definite-integrals', 'contour-integration']"
75,Why doing Möbius transformation behaves like operating a 2X2 matrix of coefficients of Möbius transformation?,Why doing Möbius transformation behaves like operating a 2X2 matrix of coefficients of Möbius transformation?,,"So, I was doing proof that inverse of Möbius transformation is again a Möbius transformation. I started with $w= f(z)=\frac{az+b}{cz+d}$ . To find the inverse, I found z in terms of w by doing simple algebra and I got $z=\frac{dw-b}{-cw+a}$ =g(w) (say). Alternatively, I can just look at the inverse of the matrix of coefficients of f(z) i.e. \begin{pmatrix}a&b\\c&d\end{pmatrix} and find its inverse to get $\frac{1}{ad-bc} \begin{pmatrix}d&-b\\-c&a\end{pmatrix}$ . This inverse matrix has elements corresponding to the inverse transformation. I just can't see why. Please explain without using any group theory if possible.","So, I was doing proof that inverse of Möbius transformation is again a Möbius transformation. I started with . To find the inverse, I found z in terms of w by doing simple algebra and I got =g(w) (say). Alternatively, I can just look at the inverse of the matrix of coefficients of f(z) i.e. and find its inverse to get . This inverse matrix has elements corresponding to the inverse transformation. I just can't see why. Please explain without using any group theory if possible.",w= f(z)=\frac{az+b}{cz+d} z=\frac{dw-b}{-cw+a} \begin{pmatrix}a&b\\c&d\end{pmatrix} \frac{1}{ad-bc} \begin{pmatrix}d&-b\\-c&a\end{pmatrix},"['linear-algebra', 'complex-analysis', 'geometry']"
76,An analytic function $f$ on $|z|<1$ with $\sup_{|z|<1} |f(z)|=1$ and $|f(0)|=\frac{1}{2}$ has no zeros in $|z|<\frac{1}{2}$,An analytic function  on  with  and  has no zeros in,f |z|<1 \sup_{|z|<1} |f(z)|=1 |f(0)|=\frac{1}{2} |z|<\frac{1}{2},"Suppose $f(z)$ is an analytic function defined on $|z|<1$ such that $\sup_{|z|<1} |f(z)|=1$ and $|f(0)|=\frac{1}{2}$ . How can I show that $f$ has no zeros in $|z|<\frac{1}{2}$ ? The only theorem I know about zeros of analytic functions is Rouche's theorem, but I can't see how to apply it in this case. Any hints?","Suppose is an analytic function defined on such that and . How can I show that has no zeros in ? The only theorem I know about zeros of analytic functions is Rouche's theorem, but I can't see how to apply it in this case. Any hints?",f(z) |z|<1 \sup_{|z|<1} |f(z)|=1 |f(0)|=\frac{1}{2} f |z|<\frac{1}{2},['complex-analysis']
77,Closed form for $\Gamma (a+bi)\Gamma(a-bi)$ [duplicate],Closed form for  [duplicate],\Gamma (a+bi)\Gamma(a-bi),This question already has answers here : What is $\Gamma(z) \Gamma(\bar {z})$? (2 answers) Closed 4 years ago . I noticed that $$\Gamma (3+2i)\Gamma (3-2i)=\frac{160\pi}{e^{2\pi}-e^{-2\pi}}$$ and $$\Gamma (2+5i)\Gamma (2-5i)=\frac{260\pi}{e^{5\pi}-e^{-5\pi}}.$$ Is there a closed form for $\Gamma (a+bi)\Gamma (a-bi)$ in general?,This question already has answers here : What is $\Gamma(z) \Gamma(\bar {z})$? (2 answers) Closed 4 years ago . I noticed that and Is there a closed form for in general?,\Gamma (3+2i)\Gamma (3-2i)=\frac{160\pi}{e^{2\pi}-e^{-2\pi}} \Gamma (2+5i)\Gamma (2-5i)=\frac{260\pi}{e^{5\pi}-e^{-5\pi}}. \Gamma (a+bi)\Gamma (a-bi),"['complex-analysis', 'closed-form', 'gamma-function']"
78,"if $g$ is analytic on the open disk, is nonzero, and if $|g(z)| \to 1$ as $|z| \to 1$, then $g$ is constant","if  is analytic on the open disk, is nonzero, and if  as , then  is constant",g |g(z)| \to 1 |z| \to 1 g,"I am trying to show that If $g$ is analytic on the open disk, is nonzero, and if $|g(z)| \to 1$ as $|z| \to 1$ , then $g$ is constant. I want to apply the maximum principle and the minimum principle to conclude that the modulus is constant. I think that this would be possible if I could extend the domain to the closed disk as I would conclude that the maximum and minimum values of $g$ both have modulus 1. However, I do not know if I can/how to extend the definition of $g$ to the boundary. Any help would be greatly appreciated.","I am trying to show that If is analytic on the open disk, is nonzero, and if as , then is constant. I want to apply the maximum principle and the minimum principle to conclude that the modulus is constant. I think that this would be possible if I could extend the domain to the closed disk as I would conclude that the maximum and minimum values of both have modulus 1. However, I do not know if I can/how to extend the definition of to the boundary. Any help would be greatly appreciated.",g |g(z)| \to 1 |z| \to 1 g g g,['complex-analysis']
79,Holomorphic function with only removable singularities implies entire?,Holomorphic function with only removable singularities implies entire?,,"Suppose $f$ is a function which is holomorphic on $\mathbb{C}\setminus A$ where $A$ is the set of points where $f$ has a singularity. Suppose that all of the points in $A$ are removable singularities of $f$ . Here is my question: does this imply that $f$ is itself entire? I understand that by Riemann Extension Theorem, $f$ can be extended to an entire $F$ , but my question has to do with whether we can say that $f$ itself is entire. I have seen a few other questions on this site which make such a statement, e.g. Removable singularities and an entire function and I am not sure if they are just slurring notation or if I am missing something. The context in which this arose: I am trying to show that if two entire functions $f,g$ are such that $|f|\leq |g|$ , then one is a multiple of the other. Obviously the strategy is to take quotient, and show that each singularity is removable. I have been able to do this, but then after that I am lost. I know I am supposed to use liouville to show that bounded and entire implies constant, but I am not sure if $|f|/|g|$ is itself entire. Is it not supposed to be some extended function which is supposed to be entire? With such an extended function, indeed we would have bounded and entire, but then I am not sure how to show that $f$ and $g$ are multiples of one another on all of $\mathbb{C}$ , since things get strange around the singularities. I would appreciate anything which clarifies my understanding.","Suppose is a function which is holomorphic on where is the set of points where has a singularity. Suppose that all of the points in are removable singularities of . Here is my question: does this imply that is itself entire? I understand that by Riemann Extension Theorem, can be extended to an entire , but my question has to do with whether we can say that itself is entire. I have seen a few other questions on this site which make such a statement, e.g. Removable singularities and an entire function and I am not sure if they are just slurring notation or if I am missing something. The context in which this arose: I am trying to show that if two entire functions are such that , then one is a multiple of the other. Obviously the strategy is to take quotient, and show that each singularity is removable. I have been able to do this, but then after that I am lost. I know I am supposed to use liouville to show that bounded and entire implies constant, but I am not sure if is itself entire. Is it not supposed to be some extended function which is supposed to be entire? With such an extended function, indeed we would have bounded and entire, but then I am not sure how to show that and are multiples of one another on all of , since things get strange around the singularities. I would appreciate anything which clarifies my understanding.","f \mathbb{C}\setminus A A f A f f f F f f,g |f|\leq |g| |f|/|g| f g \mathbb{C}",['complex-analysis']
80,Doing calculations with $\operatorname{Arg}z$ vs. $\arg z$,Doing calculations with  vs.,\operatorname{Arg}z \arg z,"I am confused on when to perform calculations on complex numbers using the argument or principal argument of a complex number. I know the following properties do not necessarily hold for the principal argument: $\text{Arg}z_1z_2=\text{Arg}z_1+\text{Arg}z_2$ $\text{Arg}\frac{z_1}{z_2}=\text{Arg}z_1-\text{Arg}z_2$ I was asked to show $\frac{\pi}{4}=4\tan^{-1}(\frac{1}{5})-\tan^{-1}(\frac{1}{239})$ Using $(1+i)(5-i)^4$ First I found the argument, $\arg(1+i)(5-i)^4$ which was $\arg(1+i)(5-i)^4=\{-\tan^{-1}(\frac{1}{239})+2k\pi:k \in \mathbb{Z}\}$ Then I found using the additive property of arg, $\text{arg}(1+i)=\{\frac{\pi}{4}+2k\pi:k\in \mathbb{Z}\}$ and $\text{arg}(5-i)^4=\{-4 \tan^{-1}(\frac{1}{5})+2k\pi:k \in \mathbb{Z} \} $ I then avoided the additive terms $2k\pi$ and concluded this implies $\frac{\pi}{4}=4\tan^{-1}(\frac{1}{5})-\tan^{-1}(\frac{1}{239})$ My professor said we were supposed to use the principal argument to perform the calculations. I did not because $\text{Arg}z_1z_2=\text{Arg}z_1+\text{Arg}z_2$ is not necessarily true. Because of this I am very confused and do not know when I should and should not use the principal argument in calculations.Also my professor never went over these properties of the principal argument. I noticed also the book likes to use $\text{arg}$ without taking on values that are periodic with $2\pi$ I asked the professor,""can we ever abuse notation and let $\text{arg}$ take on a single value."" He said no. This makes me more confused, if we are asked to perform a calculation like the one above where $\text{Arg}z_1z_2=\text{Arg}z_1+\text{Arg}z_2$ is not satisfied.","I am confused on when to perform calculations on complex numbers using the argument or principal argument of a complex number. I know the following properties do not necessarily hold for the principal argument: I was asked to show Using First I found the argument, which was Then I found using the additive property of arg, and I then avoided the additive terms and concluded this implies My professor said we were supposed to use the principal argument to perform the calculations. I did not because is not necessarily true. Because of this I am very confused and do not know when I should and should not use the principal argument in calculations.Also my professor never went over these properties of the principal argument. I noticed also the book likes to use without taking on values that are periodic with I asked the professor,""can we ever abuse notation and let take on a single value."" He said no. This makes me more confused, if we are asked to perform a calculation like the one above where is not satisfied.",\text{Arg}z_1z_2=\text{Arg}z_1+\text{Arg}z_2 \text{Arg}\frac{z_1}{z_2}=\text{Arg}z_1-\text{Arg}z_2 \frac{\pi}{4}=4\tan^{-1}(\frac{1}{5})-\tan^{-1}(\frac{1}{239}) (1+i)(5-i)^4 \arg(1+i)(5-i)^4 \arg(1+i)(5-i)^4=\{-\tan^{-1}(\frac{1}{239})+2k\pi:k \in \mathbb{Z}\} \text{arg}(1+i)=\{\frac{\pi}{4}+2k\pi:k\in \mathbb{Z}\} \text{arg}(5-i)^4=\{-4 \tan^{-1}(\frac{1}{5})+2k\pi:k \in \mathbb{Z} \}  2k\pi \frac{\pi}{4}=4\tan^{-1}(\frac{1}{5})-\tan^{-1}(\frac{1}{239}) \text{Arg}z_1z_2=\text{Arg}z_1+\text{Arg}z_2 \text{arg} 2\pi \text{arg} \text{Arg}z_1z_2=\text{Arg}z_1+\text{Arg}z_2,['complex-analysis']
81,"Complex Analysis 2.1.2 - 1 If g(w) and f(z) are analytic functions, show that g(f(z)) is also analytic. [closed]","Complex Analysis 2.1.2 - 1 If g(w) and f(z) are analytic functions, show that g(f(z)) is also analytic. [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Complex Analysis 2.1.2 - 1 If $g(w)$ and $f(z)$ are analytic functions, show that $g(f(z))$ is also analytic.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question Complex Analysis 2.1.2 - 1 If and are analytic functions, show that is also analytic.",g(w) f(z) g(f(z)),"['complex-analysis', 'analyticity', 'analytic-functions']"
82,Tricky complex contour integration,Tricky complex contour integration,,"Show that $$\int_{0}^{2\pi} \frac{\cos^2{(\theta)}}{13-5\cos{(2\theta)}} \; d\theta = \frac{\pi}{10}$$ using complex contour integration. I let $z = e^{i\theta}$ which means $dz = ie^{i\theta} \; d\theta = iz \; d\theta$ (meaning we know integrate over the unit circle $C$ ). Hence, $$\int_{0}^{2\pi} \frac{\cos^2{(\theta)}}{13-5\cos{(2\theta)}} \; d\theta = \oint_{C} \frac{1/4\left(z+1/z\right)^2}{13-5/2\left(z^2+1/z^2\right)} \; \frac{dz}{iz} = -\frac{i}{2}\oint_{C}\frac{z(z^2+1)^2}{(z^3-5)(5z^3-1)} \; dz.$$ Not sure what to do next. Is it to find the poles that are in the unit circle? Thanks!!!","Show that using complex contour integration. I let which means (meaning we know integrate over the unit circle ). Hence, Not sure what to do next. Is it to find the poles that are in the unit circle? Thanks!!!",\int_{0}^{2\pi} \frac{\cos^2{(\theta)}}{13-5\cos{(2\theta)}} \; d\theta = \frac{\pi}{10} z = e^{i\theta} dz = ie^{i\theta} \; d\theta = iz \; d\theta C \int_{0}^{2\pi} \frac{\cos^2{(\theta)}}{13-5\cos{(2\theta)}} \; d\theta = \oint_{C} \frac{1/4\left(z+1/z\right)^2}{13-5/2\left(z^2+1/z^2\right)} \; \frac{dz}{iz} = -\frac{i}{2}\oint_{C}\frac{z(z^2+1)^2}{(z^3-5)(5z^3-1)} \; dz.,['complex-analysis']
83,Logarithmic Liouville Theorem,Logarithmic Liouville Theorem,,"I am studying for a preliminary exam, and the following question has appeared on a previous exam: Let $f$ be a holomorphic function on $\mathbb{C} \setminus \{ 0\}$ . Suppose that for any $z \neq 0$ , we have that $$ |f(z)| \leq |\log (|z|) |.$$ Show that $f(z) \equiv 0$ . I am a bit stuck on how to solve this question. Certainly it is a Liouville like theorem, so the proof should follow like Liouville's proof. To this end, there are a few ideas that might help: i) We could look at $g(z) = f(1/z)$ , which is well defined on $\mathbb{C} \setminus 0$ . This doesn't seem too helpful, since $|\log(|z|)| \rightarrow \infty$ as $|z| \rightarrow \infty$ and $|z| \rightarrow 0$ . ii) Expanding $f$ in a power series at $0$ gives $f(z) = \sum_{n=0}^\infty a_n z^n$ , so we may use the fact that $$|a_n| \leq \frac{1}{2 \pi r^n} \int_0^{2\pi} |f(re^{i \theta})| d \theta.$$ Using the bound $|f(z)| \leq |\log (|z|) |$ could show that $a_n =0$ for any $n $ , proving that $f(z) \equiv 0$ . I think that the second approach is more promising than the first, but I still need some help putting it all together. Any assistance would be appreciated.","I am studying for a preliminary exam, and the following question has appeared on a previous exam: Let be a holomorphic function on . Suppose that for any , we have that Show that . I am a bit stuck on how to solve this question. Certainly it is a Liouville like theorem, so the proof should follow like Liouville's proof. To this end, there are a few ideas that might help: i) We could look at , which is well defined on . This doesn't seem too helpful, since as and . ii) Expanding in a power series at gives , so we may use the fact that Using the bound could show that for any , proving that . I think that the second approach is more promising than the first, but I still need some help putting it all together. Any assistance would be appreciated.",f \mathbb{C} \setminus \{ 0\} z \neq 0  |f(z)| \leq |\log (|z|) |. f(z) \equiv 0 g(z) = f(1/z) \mathbb{C} \setminus 0 |\log(|z|)| \rightarrow \infty |z| \rightarrow \infty |z| \rightarrow 0 f 0 f(z) = \sum_{n=0}^\infty a_n z^n |a_n| \leq \frac{1}{2 \pi r^n} \int_0^{2\pi} |f(re^{i \theta})| d \theta. |f(z)| \leq |\log (|z|) | a_n =0 n  f(z) \equiv 0,['complex-analysis']
84,Hartogs' theorem for real functions,Hartogs' theorem for real functions,,"Context : Hartogs' theorem says that if a complex function $f:\mathbb{C}^2 \rightarrow \mathbb{C}$ is separately analytic in the two complex variables, then the function is continuous, and analytic. However, this fails when applied to real function. The counterexample given in Wikipedia is $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ , given by $$ f(x,y) = \frac{xy}{x^2+y^2}. $$ $f$ is not continuous along the lines $x=\pm y$ . Question : This raises two questions: Clearly, being separately analytic in x (i.e. keeping y constant, vary x) and separately analytic in y is not enough to ensure continuity, let alone analyticity of $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ . However, is it true that if $f$ is separately analytic along all directions in the $\mathbb{R}^2$ plane, then $f$ is analytic? Is the converse true? Specifically, if $f:\mathbb{R}^2 \rightarrow \mathbb{R}$ is analytic, then is it analytic along all directions in the $\mathbb{R}^2$ plane? Note : By analytic along a certain direction, I mean the following: Consider the line $y=mx$ in the plane. Along this line, $f(x,y) = \tilde{f}(x)$ , since x completely parametrizes the line. Then, being analytic along this line, in the sense that I'm using it, would mean that $\tilde{f}(x)$ is analytic in x. I apologize if this is a very simple question. I'm new to analysis, and would appreciate it if you could provide references where this has already been proven or disproven.","Context : Hartogs' theorem says that if a complex function is separately analytic in the two complex variables, then the function is continuous, and analytic. However, this fails when applied to real function. The counterexample given in Wikipedia is , given by is not continuous along the lines . Question : This raises two questions: Clearly, being separately analytic in x (i.e. keeping y constant, vary x) and separately analytic in y is not enough to ensure continuity, let alone analyticity of . However, is it true that if is separately analytic along all directions in the plane, then is analytic? Is the converse true? Specifically, if is analytic, then is it analytic along all directions in the plane? Note : By analytic along a certain direction, I mean the following: Consider the line in the plane. Along this line, , since x completely parametrizes the line. Then, being analytic along this line, in the sense that I'm using it, would mean that is analytic in x. I apologize if this is a very simple question. I'm new to analysis, and would appreciate it if you could provide references where this has already been proven or disproven.","f:\mathbb{C}^2 \rightarrow \mathbb{C} f: \mathbb{R}^2 \rightarrow \mathbb{R} 
f(x,y) = \frac{xy}{x^2+y^2}.
 f x=\pm y f:\mathbb{R}^2 \rightarrow \mathbb{R} f \mathbb{R}^2 f f:\mathbb{R}^2 \rightarrow \mathbb{R} \mathbb{R}^2 y=mx f(x,y) = \tilde{f}(x) \tilde{f}(x)","['real-analysis', 'complex-analysis']"
85,"How could the ""Riemann mapping group"" be a group?","How could the ""Riemann mapping group"" be a group?",,"Here is the definition of Riemann mapping group: A set of injective holomorphic functions from a closed unit disk $f:D\rightarrow\mathbb{C}$ which is holomorphic on the interior and smooth on boundary, normalized by the condition $f(0)=0$ and $f'(0)=1$ . How to define the group multiplication? There's another story that this group is isomorphic to the group $\mathrm{Diff}_+(S^1)/\mathrm{Rot}(S^1)$ , which is a conformal  transformation group in physics. For $f:D\rightarrow D$ , by Schwarz lemma, $f(z)=az$ for some $a\in\mathbb{C}$ with $|a|=1$ . We can then write $f=e^{i\theta}$ which is isomorphic to $\mathrm{Rot}(S^1)$ . But I don't know the detail about the general $f$ . I saw it at Bartlett's comment . And I guess the Kirillov's paper he mentioned is the origin.","Here is the definition of Riemann mapping group: A set of injective holomorphic functions from a closed unit disk which is holomorphic on the interior and smooth on boundary, normalized by the condition and . How to define the group multiplication? There's another story that this group is isomorphic to the group , which is a conformal  transformation group in physics. For , by Schwarz lemma, for some with . We can then write which is isomorphic to . But I don't know the detail about the general . I saw it at Bartlett's comment . And I guess the Kirillov's paper he mentioned is the origin.",f:D\rightarrow\mathbb{C} f(0)=0 f'(0)=1 \mathrm{Diff}_+(S^1)/\mathrm{Rot}(S^1) f:D\rightarrow D f(z)=az a\in\mathbb{C} |a|=1 f=e^{i\theta} \mathrm{Rot}(S^1) f,"['complex-analysis', 'group-theory']"
86,Is x^1/3 the same as cube root(x)?,Is x^1/3 the same as cube root(x)?,,"I needed to evaluate the surjectivity of cuberoot(x) and used Wolfram-Alpha for that.  To my surprise, cuberoot(x) is different than x^1/3 , as can be seen A and B . Further digging shows two contradictory school of thoughts: equal not equal From my memory, x power 1/n is the nth root of x. However, article B mentions De Moivre's theorem and I don't think I ever encountered it in the undergrad engineering curriculum. So are they the same?  And in which class do you study this theorem?","I needed to evaluate the surjectivity of cuberoot(x) and used Wolfram-Alpha for that.  To my surprise, cuberoot(x) is different than x^1/3 , as can be seen A and B . Further digging shows two contradictory school of thoughts: equal not equal From my memory, x power 1/n is the nth root of x. However, article B mentions De Moivre's theorem and I don't think I ever encountered it in the undergrad engineering curriculum. So are they the same?  And in which class do you study this theorem?",,"['complex-analysis', 'exponentiation', 'radicals', 'wolfram-alpha']"
87,Are products of analytic continuations also analytic?,Are products of analytic continuations also analytic?,,"The question of the value, if any depending on which answer you choose, of $\sum_{n=1}^\infty n$ has been addressed a few times.  At least here Does $\zeta(-1)=-1/12$ or $\zeta(-1) \to -1/12$? and here Why does $1+2+3+\cdots = -\frac{1}{12}$? .  I do not want to re-open that question in general, but I have a question about a specific step of one of the approaches (or purported approaches as you may like) to computing the result. Under the zeta function regularization technique, one ultimately observes that $$ \left( 1 - 2^{1-s} \right) \zeta(s) = \eta(s) $$ for the Riemann zeta function $\zeta$ and the Dirichlet eta function $\eta$ .  One usually arrives at this result by using the series representations of these two functions and performing manipulations on them that are valid for complex values of $s$ where the series representations of $\zeta$ and $\eta$ converge . That seems fine as far as it goes, under the assumption that each function is evaluated at a value of $s$ where the series converges.  The method then continues to assert that the relationship holds for the analytic continuations of $\zeta$ and $\eta$ .  That's the step that motivates my question. Is it generally true that if $f(s) g(s) = h(s)$ on an open set $U$ that this relationship will continue to hold for their analytic continuations to larger sets?  If not generally true, what is the special property of $\zeta$ and $\eta$ that makes it true for the case outlined above? My sense is that it's not generally true because of differences in which potential supersets of $U$ each individual function has an analytic continuation, but I'm operating well on the fringe of my understanding of this topic.","The question of the value, if any depending on which answer you choose, of has been addressed a few times.  At least here Does $\zeta(-1)=-1/12$ or $\zeta(-1) \to -1/12$? and here Why does $1+2+3+\cdots = -\frac{1}{12}$? .  I do not want to re-open that question in general, but I have a question about a specific step of one of the approaches (or purported approaches as you may like) to computing the result. Under the zeta function regularization technique, one ultimately observes that for the Riemann zeta function and the Dirichlet eta function .  One usually arrives at this result by using the series representations of these two functions and performing manipulations on them that are valid for complex values of where the series representations of and converge . That seems fine as far as it goes, under the assumption that each function is evaluated at a value of where the series converges.  The method then continues to assert that the relationship holds for the analytic continuations of and .  That's the step that motivates my question. Is it generally true that if on an open set that this relationship will continue to hold for their analytic continuations to larger sets?  If not generally true, what is the special property of and that makes it true for the case outlined above? My sense is that it's not generally true because of differences in which potential supersets of each individual function has an analytic continuation, but I'm operating well on the fringe of my understanding of this topic.",\sum_{n=1}^\infty n  \left( 1 - 2^{1-s} \right) \zeta(s) = \eta(s)  \zeta \eta s \zeta \eta s \zeta \eta f(s) g(s) = h(s) U \zeta \eta U,"['sequences-and-series', 'complex-analysis', 'riemann-zeta']"
88,Relationship between order of a pole and decay rate of a taylor series?,Relationship between order of a pole and decay rate of a taylor series?,,"Out of curiosity, is there a known relationship between the order of a functions pole and the rate of decay (/growth?) of the coefficients of a Taylor Series? Or one that can be proven? For example, say that we take a taylor series at $z=0$ of a function holomorphic at $z=0$ but with a simple pole at $z=a$ . Then the radius of convergence of this taylor series is at most equal to $a$ . From my understanding, the terms can also be shown to decay at rate $\dfrac{1}{a^n}$ (so that the series may converge). Are there any differences that may occur if the pole is of higher order? Because intuitively, this changes the nature of the function about the pole itself in terms of how quickly it ""goes off to infinity"" (for lack of a better term) and such.","Out of curiosity, is there a known relationship between the order of a functions pole and the rate of decay (/growth?) of the coefficients of a Taylor Series? Or one that can be proven? For example, say that we take a taylor series at of a function holomorphic at but with a simple pole at . Then the radius of convergence of this taylor series is at most equal to . From my understanding, the terms can also be shown to decay at rate (so that the series may converge). Are there any differences that may occur if the pole is of higher order? Because intuitively, this changes the nature of the function about the pole itself in terms of how quickly it ""goes off to infinity"" (for lack of a better term) and such.",z=0 z=0 z=a a \dfrac{1}{a^n},"['complex-analysis', 'taylor-expansion', 'meromorphic-functions']"
89,How to calculate the residue of a holomorph application germ in $\mathbb{C}^{n}$,How to calculate the residue of a holomorph application germ in,\mathbb{C}^{n},"Let $f : U \longrightarrow V $ be a holomorphic map germ defined by $f = (f_{1}, f_{2}) = (z_{2} + z_{1}^{2}, z_{1}^{2} + z_{2}^{2})$ , where $U$ and $V$ are open in $\mathbb{C}^{2}$ both containing $0 \in \mathbb{C}^{2}$ . Note that $f^{-1}(0) = \lbrace (i, 1), (-i, 1), (0,0)\rbrace $ . Let $\overline{U_{0}}$ the closure of a neighborhood $U_{0} \subset U$ of origin such that $\overline{U_{0}} \cap f^{-1}(0) = \lbrace 0 \rbrace$ (*) According with: Multidimensional Residues and Their Applications (A.K.Tsikh) (in our example) the local residue of meromorphic  form $\omega = \dfrac{hdz_{1} \wedge dz_{2}}{f_{1}.f_{2}}$ at the point $(0,0)$ is the integral : $$\text{res}_{(0,0)}\omega = \dfrac{1}{(2 \pi i)^{2}} \int_{\Gamma_{(0,0)}} \dfrac{hdz_{1} \wedge dz_{2}}{f_{1}.f_{2}}$$ where $\Gamma_{(0,0)} = \lbrace z \in U_{0} ; |f_{j}(z)| = \varepsilon_{j} \,, j = 1, 2 \rbrace$ . My doubts are: 1) Is it always possible to get a neighborhood like $U_{0}$ satisfying (*)? 2) If so, how to calculate the residue at $(0, 0) $ according to the definition above?  Can the function $h$ be $\text{det}J(f_{1}, f_{2})$ ? I tried to use power series in the denominator, but was unsuccessful in calculations. References, suggestions and help will be welcome. Thanks a lot.","Let be a holomorphic map germ defined by , where and are open in both containing . Note that . Let the closure of a neighborhood of origin such that (*) According with: Multidimensional Residues and Their Applications (A.K.Tsikh) (in our example) the local residue of meromorphic  form at the point is the integral : where . My doubts are: 1) Is it always possible to get a neighborhood like satisfying (*)? 2) If so, how to calculate the residue at according to the definition above?  Can the function be ? I tried to use power series in the denominator, but was unsuccessful in calculations. References, suggestions and help will be welcome. Thanks a lot.","f : U \longrightarrow V  f = (f_{1}, f_{2}) = (z_{2} + z_{1}^{2}, z_{1}^{2} + z_{2}^{2}) U V \mathbb{C}^{2} 0 \in \mathbb{C}^{2} f^{-1}(0) = \lbrace (i, 1), (-i, 1), (0,0)\rbrace  \overline{U_{0}} U_{0} \subset U \overline{U_{0}} \cap f^{-1}(0) = \lbrace 0 \rbrace \omega = \dfrac{hdz_{1} \wedge dz_{2}}{f_{1}.f_{2}} (0,0) \text{res}_{(0,0)}\omega = \dfrac{1}{(2 \pi i)^{2}} \int_{\Gamma_{(0,0)}} \dfrac{hdz_{1} \wedge dz_{2}}{f_{1}.f_{2}} \Gamma_{(0,0)} = \lbrace z \in U_{0} ; |f_{j}(z)| = \varepsilon_{j} \,, j = 1, 2 \rbrace U_{0} (0, 0)  h \text{det}J(f_{1}, f_{2})","['complex-analysis', 'residue-calculus', 'several-complex-variables']"
90,Show that $2\cos z = e^{iz} + e^{-iz}$. Do I need absolute convergence?,Show that . Do I need absolute convergence?,2\cos z = e^{iz} + e^{-iz},"I'm reading Conway's ""Functions of one complex variable"". Define $$e^z =\sum_{n=0}^\infty \frac{z^n}{n!}$$ $$\cos z =\sum_{n=0}^\infty \frac{(-1)^nz^{2n}}{(2n)!}$$ It is already shown that these converge for all $z \in \mathbb{C}$ . I'm asked to show that $$e^{iz} + e^{-iz} = 2 \cos z$$ I have two questions: (1) Is my attempt correct? (2) Did I need absolute convergence anywhere? (The author claims that this should be necessary) $$e^{iz} + z^{-iz} = \sum_{n=0}^\infty \frac{(iz)^n}{n!} + \sum_{n=0}^\infty \frac{(-iz)^n}{n!} \quad (definition)$$ $$= \sum_{k=0}^3 \left(\sum_{n=0}^\infty \frac{(iz)^{4n+k}}{(4n+k)!} + \sum_{n=0}^\infty \frac{(-iz)^{4n+k}}{(4n+k)!}\right) \quad (**, see \ lemma  \ down \ with \ k =4)$$ $$= 2 \left( \sum_{n=0}^\infty \frac{z^{4n}}{(4n)!}- \sum_{n=0}^\infty \frac{z^{4n+2}}{(4n+2)!} \right) \quad (simplifying \ sums)$$ $$= 2 \sum_{n=0}^\infty \left(\frac{z^{4n}}{(4n)!}- \frac{z^{4n+2}}{(4n+2)!} \right) \quad (linearity)$$ $$= 2 \sum_{n=0}^\infty \frac{(-1)^n z^{2n}}{(2n)!} = 2\cos z \quad (** \ with \ k =2, definition)$$ Note that I used the following lemma (**): $$k \geq 2, \sum_{n=0}^\infty a_n \mathrm{\ converges}\implies \sum_{n=0}^\infty a_n = \sum_{n=0}^\infty (a_{kn} + \dots a_{kn+(k-1)})$$ This can be proven by observing that the right series has partial sums that are a subsequence of the partial sums of the left series.","I'm reading Conway's ""Functions of one complex variable"". Define It is already shown that these converge for all . I'm asked to show that I have two questions: (1) Is my attempt correct? (2) Did I need absolute convergence anywhere? (The author claims that this should be necessary) Note that I used the following lemma (**): This can be proven by observing that the right series has partial sums that are a subsequence of the partial sums of the left series.","e^z =\sum_{n=0}^\infty \frac{z^n}{n!} \cos z =\sum_{n=0}^\infty \frac{(-1)^nz^{2n}}{(2n)!} z \in \mathbb{C} e^{iz} + e^{-iz} = 2 \cos z e^{iz} + z^{-iz} = \sum_{n=0}^\infty \frac{(iz)^n}{n!} + \sum_{n=0}^\infty \frac{(-iz)^n}{n!} \quad (definition) = \sum_{k=0}^3 \left(\sum_{n=0}^\infty \frac{(iz)^{4n+k}}{(4n+k)!} + \sum_{n=0}^\infty \frac{(-iz)^{4n+k}}{(4n+k)!}\right) \quad (**, see \ lemma  \ down \ with \ k =4) = 2 \left( \sum_{n=0}^\infty \frac{z^{4n}}{(4n)!}- \sum_{n=0}^\infty \frac{z^{4n+2}}{(4n+2)!} \right) \quad (simplifying \ sums) = 2 \sum_{n=0}^\infty \left(\frac{z^{4n}}{(4n)!}- \frac{z^{4n+2}}{(4n+2)!} \right) \quad (linearity) = 2 \sum_{n=0}^\infty \frac{(-1)^n z^{2n}}{(2n)!} = 2\cos z \quad (** \ with \ k =2, definition) k \geq 2, \sum_{n=0}^\infty a_n \mathrm{\ converges}\implies \sum_{n=0}^\infty a_n = \sum_{n=0}^\infty (a_{kn} + \dots a_{kn+(k-1)})","['sequences-and-series', 'complex-analysis']"
91,meromorphic function with period one on the upper half plane,meromorphic function with period one on the upper half plane,,"Let $H$ be the upper half complex plane and $f$ be a meromorphic function on $H$ . I wonder how to show that if $f$ satisfies $f(z+1)=f(z)$ for all $z\in H$ , then $f$ can be written as $$f(z)=\tilde{f}(e^{2\pi i z}),$$ where $\tilde{f}$ is meromorphic in the unit disk with the origin removed. I think here we are supposed to take something like $\tilde{f}=f\circ \log$ but I don't know how to prove it formally and use the condition $f(z+1)=f(z)$ . The original of this question is from Serre's a course in arithmetic, page 80","Let be the upper half complex plane and be a meromorphic function on . I wonder how to show that if satisfies for all , then can be written as where is meromorphic in the unit disk with the origin removed. I think here we are supposed to take something like but I don't know how to prove it formally and use the condition . The original of this question is from Serre's a course in arithmetic, page 80","H f H f f(z+1)=f(z) z\in H f f(z)=\tilde{f}(e^{2\pi i z}), \tilde{f} \tilde{f}=f\circ \log f(z+1)=f(z)",['complex-analysis']
92,A singularity at $0$ is removable if the complex function is square integrable.,A singularity at  is removable if the complex function is square integrable.,0,"I am working on a problem stating as below: Consider a holomorphic function $f$ defined on the puncture disc $D(0,1)\setminus\{0\}$ . Show that $0$ is a removable singularity of $f$ if $f$ is square integrable. This question is similar to the post here: Singularities in the punctured unit disc and square integrability In fact, I've solved it following the idea in above post. Below is my proof: We can write $f(z)$ as Laurent Expansion around $z_{0}=0$ , such that $$f(z)=\sum_{n=-\infty}^{\infty}a_{n}z^{n}.$$ Then, we have $$f(re^{i\theta})=\sum_{n=-\infty}^{\infty}a_{n}r^{n}e^{in\theta},\ \overline{f(re^{i\theta})}=\sum_{n=-\infty}^{\infty}\overline{a_{n}}r^{n}e^{-in\theta}.$$ Note that for the integral $$\int_{0}^{2\pi}e^{in\theta}e^{im\theta}d\theta,$$ if $n=-m$ , then the above integral is $2\pi$ , but if $n\neq -m$ , then the above integral is a complex integral of a holomorphic function along a circle and thus by Cauchy's Theorem, the above integral is $0$ . Now, with this in mind, we have \begin{align*} \int_{0}^{2\pi}|f(re^{i\theta}|^{2}d\theta&=\int_{0}^{2\pi}\Big(\sum_{n=-\infty}^{\infty}a_{n}r^{n}e^{in\theta}\Big)\Big(\sum_{n=-\infty}^{\infty}\overline{a_{n}}r^{n}e^{-in\theta}\Big)d\theta \\ &=2\pi\sum_{n=-\infty}^{\infty}|a_{n}|^{2}r^{2n}.\\ \end{align*} On the other hand, since $\|f\|_{L_{2}}<\infty$ , for any disc $D_{z_{0}}(R)$ centered at $z_{0}=0$ with radius $R$ , we have \begin{align*} \infty>\int_{D}|f(z)|^{2}dz&=\int_{0}^{R}\int_{0}^{2\pi}|f(re^{i\theta})|^{2}4d\theta dr\\ &=2\pi\int_{0}^{R}\sum_{n=-\infty}^{\infty}|a_{n}|^{2}r^{2n+1}dr\\ &=2\pi\sum_{n=-\infty}^{\infty}|a_{n}|^{2}\int_{0}^{R}r^{2n+1}dr\\ \end{align*} Now, for all $2n+1\geq 0$ , $\int_{0}^{R}r^{2n+1}dr<\infty$ , but for all $2n+1<0$ , $\int_{0}^{R}r^{2n+1}dr=\infty$ . Thus, the only way to make the above inequality hold is that $2n+1\geq 0$ , which means that $n\geq 0$ since $n\in\mathbb{Z}$ . This implies that in the Laurent series, $a_{n}=0$ for all $n\leq -1$ . This implies that $z_{0}=0$ is a removable singularity. However, this question is the part (c) of a problem, and I am wondering if there is another way to prove it, by using part (a) and (b). Here is the part (a) and part (b): (a) Show that $0$ is a removable singularity if $|f(z)|\leq C|z|^{-\alpha}$ , with $\alpha<1$ . (b) Show that, for any holomorphic function $g$ on the disc of center $b$ , radius $\epsilon$ , we have $$|g(b)|\leq\dfrac{C}{\epsilon}\Big(\int_{D(b,\epsilon)}|g(x+iy)|^{2}dxdy\Big)^{1/2}.$$ I have proven those two parts and they both of a generalization in Stein Chapter 3 Exercise 13 and 20, respectively. However, I have no idea about how to apply those two to part (c). Perhaps they are really not connected to each other.","I am working on a problem stating as below: Consider a holomorphic function defined on the puncture disc . Show that is a removable singularity of if is square integrable. This question is similar to the post here: Singularities in the punctured unit disc and square integrability In fact, I've solved it following the idea in above post. Below is my proof: We can write as Laurent Expansion around , such that Then, we have Note that for the integral if , then the above integral is , but if , then the above integral is a complex integral of a holomorphic function along a circle and thus by Cauchy's Theorem, the above integral is . Now, with this in mind, we have On the other hand, since , for any disc centered at with radius , we have Now, for all , , but for all , . Thus, the only way to make the above inequality hold is that , which means that since . This implies that in the Laurent series, for all . This implies that is a removable singularity. However, this question is the part (c) of a problem, and I am wondering if there is another way to prove it, by using part (a) and (b). Here is the part (a) and part (b): (a) Show that is a removable singularity if , with . (b) Show that, for any holomorphic function on the disc of center , radius , we have I have proven those two parts and they both of a generalization in Stein Chapter 3 Exercise 13 and 20, respectively. However, I have no idea about how to apply those two to part (c). Perhaps they are really not connected to each other.","f D(0,1)\setminus\{0\} 0 f f f(z) z_{0}=0 f(z)=\sum_{n=-\infty}^{\infty}a_{n}z^{n}. f(re^{i\theta})=\sum_{n=-\infty}^{\infty}a_{n}r^{n}e^{in\theta},\ \overline{f(re^{i\theta})}=\sum_{n=-\infty}^{\infty}\overline{a_{n}}r^{n}e^{-in\theta}. \int_{0}^{2\pi}e^{in\theta}e^{im\theta}d\theta, n=-m 2\pi n\neq -m 0 \begin{align*}
\int_{0}^{2\pi}|f(re^{i\theta}|^{2}d\theta&=\int_{0}^{2\pi}\Big(\sum_{n=-\infty}^{\infty}a_{n}r^{n}e^{in\theta}\Big)\Big(\sum_{n=-\infty}^{\infty}\overline{a_{n}}r^{n}e^{-in\theta}\Big)d\theta \\
&=2\pi\sum_{n=-\infty}^{\infty}|a_{n}|^{2}r^{2n}.\\
\end{align*} \|f\|_{L_{2}}<\infty D_{z_{0}}(R) z_{0}=0 R \begin{align*}
\infty>\int_{D}|f(z)|^{2}dz&=\int_{0}^{R}\int_{0}^{2\pi}|f(re^{i\theta})|^{2}4d\theta dr\\
&=2\pi\int_{0}^{R}\sum_{n=-\infty}^{\infty}|a_{n}|^{2}r^{2n+1}dr\\
&=2\pi\sum_{n=-\infty}^{\infty}|a_{n}|^{2}\int_{0}^{R}r^{2n+1}dr\\
\end{align*} 2n+1\geq 0 \int_{0}^{R}r^{2n+1}dr<\infty 2n+1<0 \int_{0}^{R}r^{2n+1}dr=\infty 2n+1\geq 0 n\geq 0 n\in\mathbb{Z} a_{n}=0 n\leq -1 z_{0}=0 0 |f(z)|\leq C|z|^{-\alpha} \alpha<1 g b \epsilon |g(b)|\leq\dfrac{C}{\epsilon}\Big(\int_{D(b,\epsilon)}|g(x+iy)|^{2}dxdy\Big)^{1/2}.",['complex-analysis']
93,"$f$ is holomorphic in $B(z_0,r)\setminus\{z_0\}$ and does not except real values. Then $z_0$ is a removable singularity",is holomorphic in  and does not except real values. Then  is a removable singularity,"f B(z_0,r)\setminus\{z_0\} z_0","$f$ is holomorphic at $B(z_0,r)\setminus\{z_0\}$ and $f$ doesn't except real values - i.e $f(z)\notin\mathbb{R}$ for all $z\in \mathbb{R}$ . Then $z_0$ is a removable singularity point ( $f$ can be extended holomorphically in $z_0$ ). Well I tried to use Riemann theorem, and show that $\exists 0<r'\le r$ such that $f$ is bounded in $B(z_0,r)$ , but didn't succeed to do so. Formerly I solved a similar question which demand that $\Re(f)>0$ and then by defining $e^{-f(z)}$ which is holomorphic and bounded, which by taking $log$ holomorphic branch promises $f$ is holomorphic. Is there any manipulation or composition I may make to $f$ , to get a similar results? I also tried to assume that $f$ is not bounded, so in $B(z_0,r)$ one may find $z$ such that $|f(z)|$ is arbitrary big. However, is there any kind of intermediate value principle which assures that $f$ must ""cross"" the real line in case $|f(z)|$ is not bounded in $B(z_0,r)$ ?","is holomorphic at and doesn't except real values - i.e for all . Then is a removable singularity point ( can be extended holomorphically in ). Well I tried to use Riemann theorem, and show that such that is bounded in , but didn't succeed to do so. Formerly I solved a similar question which demand that and then by defining which is holomorphic and bounded, which by taking holomorphic branch promises is holomorphic. Is there any manipulation or composition I may make to , to get a similar results? I also tried to assume that is not bounded, so in one may find such that is arbitrary big. However, is there any kind of intermediate value principle which assures that must ""cross"" the real line in case is not bounded in ?","f B(z_0,r)\setminus\{z_0\} f f(z)\notin\mathbb{R} z\in \mathbb{R} z_0 f z_0 \exists 0<r'\le r f B(z_0,r) \Re(f)>0 e^{-f(z)} log f f f B(z_0,r) z |f(z)| f |f(z)| B(z_0,r)","['complex-analysis', 'singularity']"
94,Proving that the Quotient of an Algebraic Curve $X/G$ is an Algebraic Curve.,Proving that the Quotient of an Algebraic Curve  is an Algebraic Curve.,X/G,"I am self-studying Miranda's book Algebraic Curves and Riemann Surfaces and I am looking for a hint for a problem. For those with the book, it is on page 178, and is Problem VI. $1$ .L. The problem is the following: Let $G$ be a finite group acting effectively on an algebraic curve $X$ . (i) Show that $G$ acts on the function field $\mathcal{M}(X)$ . (ii) Show that the function field of the quotient Riemann surface $X/G$ is the field of invariants $\mathcal{M}(X)^G$ . (iii) Show that $X/G$ is an algebraic curve. Parts (i) and (ii) I found rather easy, so that for part (iii) I have $\mathcal{M}(X)^G\cong \mathcal{M}(X/G)$ . According to Miranda, an algebraic curve is a compact Riemann surface $X$ so that $\mathcal{M}(X)$ separates points and separates tangents. So, I am trying to demonstrate that $\mathcal{M}(X)^G$ separates points on $X/G$ . Now, by assumption $\mathcal{M}(X)$ separates points on $X$ , the issue however is finding a function $f\in \mathcal{M}(X)^G$ separating points $x$ and $y$ lying in distinct $G$ -orbits. I tried fixing $f\in \mathcal{M}(X)$ such that $f(x)\ne f(y)$ . Then I produced a $G$ -invariant function $\overline{f}$ by $$ \overline{f}=\frac{1}{\lvert G\rvert}\sum_{g\in G} f\circ g$$ where I identify $G$ with a subgroup of $\operatorname{Aut}(X)$ . I suspect I might be able to show that this function has the desired property, but I have not succeeded. I am having similar difficulties with separation of tangents.","I am self-studying Miranda's book Algebraic Curves and Riemann Surfaces and I am looking for a hint for a problem. For those with the book, it is on page 178, and is Problem VI. .L. The problem is the following: Let be a finite group acting effectively on an algebraic curve . (i) Show that acts on the function field . (ii) Show that the function field of the quotient Riemann surface is the field of invariants . (iii) Show that is an algebraic curve. Parts (i) and (ii) I found rather easy, so that for part (iii) I have . According to Miranda, an algebraic curve is a compact Riemann surface so that separates points and separates tangents. So, I am trying to demonstrate that separates points on . Now, by assumption separates points on , the issue however is finding a function separating points and lying in distinct -orbits. I tried fixing such that . Then I produced a -invariant function by where I identify with a subgroup of . I suspect I might be able to show that this function has the desired property, but I have not succeeded. I am having similar difficulties with separation of tangents.",1 G X G \mathcal{M}(X) X/G \mathcal{M}(X)^G X/G \mathcal{M}(X)^G\cong \mathcal{M}(X/G) X \mathcal{M}(X) \mathcal{M}(X)^G X/G \mathcal{M}(X) X f\in \mathcal{M}(X)^G x y G f\in \mathcal{M}(X) f(x)\ne f(y) G \overline{f}  \overline{f}=\frac{1}{\lvert G\rvert}\sum_{g\in G} f\circ g G \operatorname{Aut}(X),"['complex-analysis', 'algebraic-geometry', 'algebraic-curves', 'riemann-surfaces']"
95,Show that $z^5 - z +16$ has two roots in the right half plane,Show that  has two roots in the right half plane,z^5 - z +16,"Show that the polynomial $$z^5 - z +16$$ has all of its roots in the region $$\{z\in \mathbb{C} \; | \; 1< |z| < 2\},$$ and show that two of its roots have positive real part. I have used Rouché's theorem to prove that all of its roots are in the above region. But I don't have any clue on how to show the second part, that two of the roots are in the right half plane.","Show that the polynomial has all of its roots in the region and show that two of its roots have positive real part. I have used Rouché's theorem to prove that all of its roots are in the above region. But I don't have any clue on how to show the second part, that two of the roots are in the right half plane.","z^5 - z +16 \{z\in \mathbb{C} \; | \; 1< |z| < 2\},","['complex-analysis', 'polynomials', 'complex-numbers', 'complex-integration', 'rouches-theorem']"
96,Mobius transformations from intersection of circles to two straight lines,Mobius transformations from intersection of circles to two straight lines,,"My textbook is pretty useless on Mobius transformations, and I just wanted to check this reasoning was correct! I want to find a Mobius mapping from the region $$\{z:|z-1|\lt\sqrt{2}, |z+1|\lt \sqrt{2}\}$$ to the region $$\{z:\frac{3\pi}{4}\lt argz \lt \frac{5\pi}{4}\}$$ I know that the two circles in the first region intersect at $i$ and $-i$ so I consider a Mobius transformation $z \mapsto \frac{z+i}{z-i}$ which takes $-i$ to $0$ and $i$ to $\infty$ . I then tested two points, one on the left circline that bounds the two circles' intersections (namely $1-\sqrt{2}$ ) and one on the right circline that bounds the two circle's intersections (namely $-1+\sqrt{2}$ ). From here I see that $1-\sqrt{2}$ goes to $-\frac{\sqrt{2}}{2}-\frac{\sqrt{2}}{2}i$ ,so onto the half line $y=x$ for $y,x\lt 0$ . And similarly, $-1+\sqrt{2}$ gets mapped to the line $x=-y$ for $x \lt 0$ and $y\gt 0$ . These two boundaries seem to bound precisely the region we want. Thus I think this mapping, $z \mapsto \frac{z+i}{z-i}$ is a Mobius mapping from the first region to the second. Is this correct?","My textbook is pretty useless on Mobius transformations, and I just wanted to check this reasoning was correct! I want to find a Mobius mapping from the region to the region I know that the two circles in the first region intersect at and so I consider a Mobius transformation which takes to and to . I then tested two points, one on the left circline that bounds the two circles' intersections (namely ) and one on the right circline that bounds the two circle's intersections (namely ). From here I see that goes to ,so onto the half line for . And similarly, gets mapped to the line for and . These two boundaries seem to bound precisely the region we want. Thus I think this mapping, is a Mobius mapping from the first region to the second. Is this correct?","\{z:|z-1|\lt\sqrt{2}, |z+1|\lt \sqrt{2}\} \{z:\frac{3\pi}{4}\lt argz \lt \frac{5\pi}{4}\} i -i z \mapsto \frac{z+i}{z-i} -i 0 i \infty 1-\sqrt{2} -1+\sqrt{2} 1-\sqrt{2} -\frac{\sqrt{2}}{2}-\frac{\sqrt{2}}{2}i y=x y,x\lt 0 -1+\sqrt{2} x=-y x \lt 0 y\gt 0 z \mapsto \frac{z+i}{z-i}","['complex-analysis', 'conformal-geometry', 'mobius-transformation']"
97,Find $ \int_{0}^{\infty} e^{ix} \sin(x) \frac{e^{-3x}}{x} dx$,Find, \int_{0}^{\infty} e^{ix} \sin(x) \frac{e^{-3x}}{x} dx,"The second contribution in the Born approximation for the Yukawa potential in scattering theory leads to the following integral (for some given ratio of parameters): \begin{align} \int_{0}^{\infty} e^{ix} \sin(x) \frac{e^{-3x}}{x} dx \end{align} The solution is said to be (wolframalpha) $\tan^{-1}(\frac{3}{10} + \frac{i}{10})$ . How is this derived? Is there a way to evaluate the numerical value of the integral (e.g. via the residue theorem?) Derivation of the integral: Starting point was an integral equation for the wave function of the scattering problem described by the Schroedinger equation: \begin{align} \phi_{\vec{k}}(\vec{r}) = \frac{1}{(2\pi)^{\frac{3}{2}}} e^{i \vec{k} \cdot \vec{r}} - \frac{m}{2\pi \hbar^2} \int^{}_{} d^3 r' \frac{e^{ik|\vec{r} -\vec{r}'|}}{|\vec{r} - \vec{r}'|} V(\vec{r}')      \phi_{\vec{k}}(\vec{r}') \end{align} Simply inserting plane waves in the RHS leads to what is called the Born approximation: \begin{align} \phi_{\vec{k}}(\vec{r}) = \frac{1}{(2\pi)^{\frac{3}{2}}} e^{i \vec{k} \cdot \vec{r}} - \frac{m}{2\pi \hbar^2} \int^{}_{} d^3 r' \frac{e^{ik|\vec{r} -\vec{r}'|}}{|\vec{r} - \vec{r}'|} V(\vec{r}')       \bigg(\frac{1}{(2\pi)^{\frac{3}{2}}}e^{i \vec{k} \vec{r}'} \bigg) \end{align} In class, we derived the following expression for the scattering amplitude, and furthermore used the Born approximation to show that it is the fourier transformed of the potential. \begin{align}   f_{\vec{k}} (\theta, \phi) = - \frac{\sqrt{2\pi}m}{ \hbar^2} \int^{}_{} d^3 r' e^{-i \vec{k}'(k,     \theta, \phi) \vec{r}'} V(\vec{r}') \phi_{\vec{k}}(\vec{r}') \approx -\frac{m}{2\pi \hbar^2}      \int^{}_{} d^3 r' e^{+i(\vec{k} - \vec{k}'(k,\theta, \phi)) \vec{r}'} V(\vec{r}') \end{align} In the lecture notes a formula is given to evaluate when the Born approximation is good. It starts from the above formula, assumes a symmetric potential with respect to rotation, goes over to spherical coordinates and most importantly assumes $\vec{r} =0$ for a potential centered at 0. The last assumption is justified as the influence of the potential should be the highest at this choice. This leads to the criterium \begin{align} \frac{2m}{\hbar^2 k} \bigg|\int^{\infty}_{0} dr' e^{ikr'} V(r') \sin(kr')\bigg| \ll 1 \end{align} The Yukawa potential reads $V(r) = A \frac{e^{-\lambda r}}{r}$ . The task was to numerically (I am just curious for an analytical perspective) evaluate for which $A$ the Born approximation is good with $\frac{k}{\lambda} = 3$ . The substitution $x = kr'$ leads to my initial question.","The second contribution in the Born approximation for the Yukawa potential in scattering theory leads to the following integral (for some given ratio of parameters): The solution is said to be (wolframalpha) . How is this derived? Is there a way to evaluate the numerical value of the integral (e.g. via the residue theorem?) Derivation of the integral: Starting point was an integral equation for the wave function of the scattering problem described by the Schroedinger equation: Simply inserting plane waves in the RHS leads to what is called the Born approximation: In class, we derived the following expression for the scattering amplitude, and furthermore used the Born approximation to show that it is the fourier transformed of the potential. In the lecture notes a formula is given to evaluate when the Born approximation is good. It starts from the above formula, assumes a symmetric potential with respect to rotation, goes over to spherical coordinates and most importantly assumes for a potential centered at 0. The last assumption is justified as the influence of the potential should be the highest at this choice. This leads to the criterium The Yukawa potential reads . The task was to numerically (I am just curious for an analytical perspective) evaluate for which the Born approximation is good with . The substitution leads to my initial question.","\begin{align}
\int_{0}^{\infty} e^{ix} \sin(x) \frac{e^{-3x}}{x} dx
\end{align} \tan^{-1}(\frac{3}{10} + \frac{i}{10}) \begin{align}
\phi_{\vec{k}}(\vec{r}) = \frac{1}{(2\pi)^{\frac{3}{2}}} e^{i \vec{k} \cdot \vec{r}} - \frac{m}{2\pi \hbar^2} \int^{}_{} d^3 r' \frac{e^{ik|\vec{r} -\vec{r}'|}}{|\vec{r} - \vec{r}'|} V(\vec{r}')
     \phi_{\vec{k}}(\vec{r}')
\end{align} \begin{align}
\phi_{\vec{k}}(\vec{r}) = \frac{1}{(2\pi)^{\frac{3}{2}}} e^{i \vec{k} \cdot \vec{r}} - \frac{m}{2\pi \hbar^2} \int^{}_{} d^3 r' \frac{e^{ik|\vec{r} -\vec{r}'|}}{|\vec{r} - \vec{r}'|} V(\vec{r}')
      \bigg(\frac{1}{(2\pi)^{\frac{3}{2}}}e^{i \vec{k} \vec{r}'} \bigg)
\end{align} \begin{align}
  f_{\vec{k}} (\theta, \phi) = - \frac{\sqrt{2\pi}m}{ \hbar^2} \int^{}_{} d^3 r' e^{-i \vec{k}'(k,
    \theta, \phi) \vec{r}'} V(\vec{r}') \phi_{\vec{k}}(\vec{r}') \approx -\frac{m}{2\pi \hbar^2} 
    \int^{}_{} d^3 r' e^{+i(\vec{k} - \vec{k}'(k,\theta, \phi)) \vec{r}'} V(\vec{r}')
\end{align} \vec{r} =0 \begin{align}
\frac{2m}{\hbar^2 k} \bigg|\int^{\infty}_{0} dr' e^{ikr'} V(r') \sin(kr')\bigg| \ll 1
\end{align} V(r) = A \frac{e^{-\lambda r}}{r} A \frac{k}{\lambda} = 3 x = kr'","['integration', 'complex-analysis', 'physics', 'mathematical-physics']"
98,"If $f$ is holomorphic in $\{|z|<1\}$ \ $\{0\}$ and doesn't get values in $(-\infty ,0]$ then $0$ is a removable singular point [duplicate]",If  is holomorphic in  \  and doesn't get values in  then  is a removable singular point [duplicate],"f \{|z|<1\} \{0\} (-\infty ,0] 0","This question already has an answer here : $f$ holomorphic on $D\setminus \{0\}$ and takes no values in $(-\infty,0],$ then $0$ removable (1 answer) Closed 5 years ago . Let $f$ b a holomorphic in $\{|z|<1\}$ \ $\{0\}$ . I want to show that if $f$ doesn't get values in $(-\infty ,0]$ then $0$ is a removable singular point. I am not sure where to start, but since $f$ is never equal to $0$ then I can probably work with $\frac{1}{f}$ which is also holomorphic in the same domain. From Riemann's theorem, I know that if $f$ is bounded in a neighborhood of $0$ then it is a removable singular point. However I don't think it gets me anywhere here. Help would be appreciated","This question already has an answer here : $f$ holomorphic on $D\setminus \{0\}$ and takes no values in $(-\infty,0],$ then $0$ removable (1 answer) Closed 5 years ago . Let b a holomorphic in \ . I want to show that if doesn't get values in then is a removable singular point. I am not sure where to start, but since is never equal to then I can probably work with which is also holomorphic in the same domain. From Riemann's theorem, I know that if is bounded in a neighborhood of then it is a removable singular point. However I don't think it gets me anywhere here. Help would be appreciated","f \{|z|<1\} \{0\} f (-\infty ,0] 0 f 0 \frac{1}{f} f 0","['complex-analysis', 'singularity']"
99,Standard inequality and Cauchy integral formula,Standard inequality and Cauchy integral formula,,Let $f$ be holomorphic on $\overline{D_2}$ with $|f(z)|\leq 1$ for all $z\in\overline{D_2}$ . Show that $|f''(z)|\leq 4$ for all $z\in\overline{D_1}$ . My attempt: By the standard inequality and the Cauchy integrla formula we have for all $z\in\overline{D_1}$ : $$|f''(z)|=\left|\frac{2!}{2\pi i}\oint_{\partial D_2}\frac{f(w)}{(w-z)^3}dw\right|=\frac{1}{\pi }\left|\oint_{\partial D_2}\frac{f(w)}{(w-z)^3}dw\right|\leq$$ $$\leq\frac{1}{\pi}\cdot 2\pi \max_{|w|=2}\left|\frac{f(w)}{(w-z)^3}\right|=2\max_{|w|=2}\frac{|f(w)|}{|w-z|^3}$$ Now I want to use $|f(w)|\leq 1$ since $D_1\subset D_2$ and also the triangle inequality: $$2\max_{|w|=2}\frac{|f(w)|}{|w-z|^3}\leq\max_{|w|=2} \frac{2}{||w|-|z||^3}=\frac{2}{|2-|z||^3}$$ And since $|z|\leq 1$ this is always less or equal to $2$ . So in total $|f''(z)|\leq 2$ on the given disk which is obviously less than $4$ . Is this correct?,Let be holomorphic on with for all . Show that for all . My attempt: By the standard inequality and the Cauchy integrla formula we have for all : Now I want to use since and also the triangle inequality: And since this is always less or equal to . So in total on the given disk which is obviously less than . Is this correct?,f \overline{D_2} |f(z)|\leq 1 z\in\overline{D_2} |f''(z)|\leq 4 z\in\overline{D_1} z\in\overline{D_1} |f''(z)|=\left|\frac{2!}{2\pi i}\oint_{\partial D_2}\frac{f(w)}{(w-z)^3}dw\right|=\frac{1}{\pi }\left|\oint_{\partial D_2}\frac{f(w)}{(w-z)^3}dw\right|\leq \leq\frac{1}{\pi}\cdot 2\pi \max_{|w|=2}\left|\frac{f(w)}{(w-z)^3}\right|=2\max_{|w|=2}\frac{|f(w)|}{|w-z|^3} |f(w)|\leq 1 D_1\subset D_2 2\max_{|w|=2}\frac{|f(w)|}{|w-z|^3}\leq\max_{|w|=2} \frac{2}{||w|-|z||^3}=\frac{2}{|2-|z||^3} |z|\leq 1 2 |f''(z)|\leq 2 4,"['complex-analysis', 'proof-verification', 'cauchy-integral-formula']"
