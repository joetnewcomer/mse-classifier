,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"A Way to make the following ""proof"" of the Hairy Ball Theorem rigorous?","A Way to make the following ""proof"" of the Hairy Ball Theorem rigorous?",,"I plan on giving a talk soon to undergraduates and I'd like to talk about the hairy ball theorem during the talk. I was trying to think of some sort of visually intuitive proof of this fact. (I already know several homotopical proofs), and this is roughly what I came up with: Suppose you have a vector field on a sphere. It's seems reasonable that if it is nonvanishing, all of the integral curves will be circles. (I think that's true? I know either an integral curve is periodic, a point, or a line... and we're assuming it's not a point, and I just feel like you couldn't fit a line in there for some silly reason.) If this is true then there is probably an integral curve with the smallest 'diameter,': a circle divides the sphere into two pieces (not easy to prove, but visually an audience could be convinced), and the 'diameter' is defined to be the smaller of the two different obvious ways one could define the diameter. This curve can't be a point, so it has nonempty 'interior' (again using the Jordan curve theorem, and we pick the 'smaller' interior). Pick a point in the interior and follow it's integral curve. This integral curve has to be contained inside the 'smallest'. Contradiction, since clearly the diameter of this one is less. Obviously there are lots of things that are not at all obvious. But I would be happy if this argument COULD be made rigorous, even with lots of technical details, because then I wouldn't feel bad giving it without the details since it's very visual.","I plan on giving a talk soon to undergraduates and I'd like to talk about the hairy ball theorem during the talk. I was trying to think of some sort of visually intuitive proof of this fact. (I already know several homotopical proofs), and this is roughly what I came up with: Suppose you have a vector field on a sphere. It's seems reasonable that if it is nonvanishing, all of the integral curves will be circles. (I think that's true? I know either an integral curve is periodic, a point, or a line... and we're assuming it's not a point, and I just feel like you couldn't fit a line in there for some silly reason.) If this is true then there is probably an integral curve with the smallest 'diameter,': a circle divides the sphere into two pieces (not easy to prove, but visually an audience could be convinced), and the 'diameter' is defined to be the smaller of the two different obvious ways one could define the diameter. This curve can't be a point, so it has nonempty 'interior' (again using the Jordan curve theorem, and we pick the 'smaller' interior). Pick a point in the interior and follow it's integral curve. This integral curve has to be contained inside the 'smallest'. Contradiction, since clearly the diameter of this one is less. Obviously there are lots of things that are not at all obvious. But I would be happy if this argument COULD be made rigorous, even with lots of technical details, because then I wouldn't feel bad giving it without the details since it's very visual.",,"['algebraic-topology', 'differential-geometry']"
1,Vector valued 2-forms which satisfy Jacobi Identity,Vector valued 2-forms which satisfy Jacobi Identity,,"Motivated by this MO  question we ask the following two questions: 1)What is  an example of  a compact manifold $M$ which does not admit any   smooth (1,2) tensor $\omega$ which restriction to each fibre(tangent space) gives  a simple Lie algebra? 2)What is  an example of  a compact manifold $M$ which  admit  at least one  smooth (1,2) tensor $\omega$ which restriction to each fibre(tangent space) gives  a simple Lie algebra?","Motivated by this MO  question we ask the following two questions: 1)What is  an example of  a compact manifold $M$ which does not admit any   smooth (1,2) tensor $\omega$ which restriction to each fibre(tangent space) gives  a simple Lie algebra? 2)What is  an example of  a compact manifold $M$ which  admit  at least one  smooth (1,2) tensor $\omega$ which restriction to each fibre(tangent space) gives  a simple Lie algebra?",,"['differential-geometry', 'manifolds', 'lie-algebras', 'tensors']"
2,"Prove that the Lie derivative of a vector field equals the Lie bracket: $\frac{d}{dt} ((\phi_{-t})_* Y)|_{t=0} = [X,Y]$",Prove that the Lie derivative of a vector field equals the Lie bracket:,"\frac{d}{dt} ((\phi_{-t})_* Y)|_{t=0} = [X,Y]","Let $X$ and $Y$ be vector fields on a smooth manifold $M$, and let $\phi_t$ be the flow of $X$, i.e. $\frac{d}{dt} \phi_t(p) = X_p$. I am trying to prove the following formula: $\frac{d}{dt} ((\phi_{-t})_* Y)|_{t=0} = [X,Y],$ where $[X,Y]$ is the commutator, defined by $[X,Y] = X\circ Y - Y\circ X$. This is a question from these online notes: http://www.math.ist.utl.pt/~jnatar/geometria_sem_exercicios.pdf .","Let $X$ and $Y$ be vector fields on a smooth manifold $M$, and let $\phi_t$ be the flow of $X$, i.e. $\frac{d}{dt} \phi_t(p) = X_p$. I am trying to prove the following formula: $\frac{d}{dt} ((\phi_{-t})_* Y)|_{t=0} = [X,Y],$ where $[X,Y]$ is the commutator, defined by $[X,Y] = X\circ Y - Y\circ X$. This is a question from these online notes: http://www.math.ist.utl.pt/~jnatar/geometria_sem_exercicios.pdf .",,"['differential-geometry', 'lie-algebras']"
3,"implicit equation for ""double torus"" (genus 2 orientable surface)","implicit equation for ""double torus"" (genus 2 orientable surface)",,"The embedded torus in $\mathbb R^3$ can be described by the set of points in $(x,y,z)\in \mathbb R^3$ satisfying $T(x,y,z)=0$, where $T$ is the polynomial $T(x,y,z)=(x^2+y^2+z^2+R^2-r^2)^2-4R^2(x^2+y^2)$ for $R>r>0$. Is it possible to find a polynomial that describes the sum of two (or $n$) tori? That is, is there a polynomial (or even a smooth function) $P$ such that the embedded double torus can be described as the set where $P(x,y,z)=0$?","The embedded torus in $\mathbb R^3$ can be described by the set of points in $(x,y,z)\in \mathbb R^3$ satisfying $T(x,y,z)=0$, where $T$ is the polynomial $T(x,y,z)=(x^2+y^2+z^2+R^2-r^2)^2-4R^2(x^2+y^2)$ for $R>r>0$. Is it possible to find a polynomial that describes the sum of two (or $n$) tori? That is, is there a polynomial (or even a smooth function) $P$ such that the embedded double torus can be described as the set where $P(x,y,z)=0$?",,"['differential-geometry', 'analytic-geometry', 'surfaces']"
4,Spin manifold and the second Stiefel-Whitney class,Spin manifold and the second Stiefel-Whitney class,,"We know that: Spin structures will exist if and only if the second Stiefel-Whitney class $w_2(M)\in H^2(M,\mathbb Z/2)$ of $M$ vanishes. Can someone use simple words and logic to show why the above is true? Note. More precisely, from Wikipedia : André Haefliger found necessary and sufficient conditions for the existence of a spin structure on an oriented Riemannian manifold (M,g). The obstruction to having a spin structure is certain element [k] of $H^2(M,\mathbb{Z}/2)$. For a spin structure the class [k] is the second Stiefel-Whitney class $w_2(M)\in H^2(M,\mathbb{Z}/2)$ of M. Hence, a spin structure exists if and only if the second Stiefel-Whitney class $w_2(M)\in H^2(M,\mathbb Z/2)$ of M vanishes. A. Haefliger (1956). ""Sur l’extension du groupe structural d’un espace fibré"". C. R. Acad. Sci. Paris 243: 558–560.","We know that: Spin structures will exist if and only if the second Stiefel-Whitney class $w_2(M)\in H^2(M,\mathbb Z/2)$ of $M$ vanishes. Can someone use simple words and logic to show why the above is true? Note. More precisely, from Wikipedia : André Haefliger found necessary and sufficient conditions for the existence of a spin structure on an oriented Riemannian manifold (M,g). The obstruction to having a spin structure is certain element [k] of $H^2(M,\mathbb{Z}/2)$. For a spin structure the class [k] is the second Stiefel-Whitney class $w_2(M)\in H^2(M,\mathbb{Z}/2)$ of M. Hence, a spin structure exists if and only if the second Stiefel-Whitney class $w_2(M)\in H^2(M,\mathbb Z/2)$ of M vanishes. A. Haefliger (1956). ""Sur l’extension du groupe structural d’un espace fibré"". C. R. Acad. Sci. Paris 243: 558–560.",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'characteristic-classes', 'spin-geometry']"
5,"Why study ""curves"" instead of 1-manifolds?","Why study ""curves"" instead of 1-manifolds?",,"In most undergraduate differential geometry courses -- I am thinking of do Carmo's ""Differential Geometry of Curves and Surfaces"" -- the topic of study is curves and surfaces in $\mathbb{R}^3$.  However, the definition of ""curve"" and ""surface"" are usually presented in very different ways. A curve is defined simply as a differentiable map $\gamma\colon I \to \mathbb{R}^3$, where $I \subset \mathbb{R}$ is an interval.  Of course, some authors prefer to define a curve as the image of such a map, and others require piecewise-differentiability, but the general concept is the same. On the other hand, surfaces are essentially defined as 2-manifolds. Similarly, in graduate courses on manifolds -- I am thinking of John Lee's ""Introduction to Smooth Manifolds"" -- one talks about curves $\gamma\colon I \to M$ in a manifold, and can do line integrals over such curves, but talks separately about embedded/immersed 1-dimensional submanifolds. My question, then, is: Why make (parametrized) curves the object of study rather than 1-manifolds? Earlier, I asked a question that was perhaps meant to hint at this one, though I didn't say so explicitly. Ultimately, I would simply like to say ""curves are 1-manifolds and surfaces are 2-manifolds,"" and am looking for reasons why this is correct/incorrect or at least a good/bad idea.  (So, yes, I'm looking for a standard definition of ""curve."")","In most undergraduate differential geometry courses -- I am thinking of do Carmo's ""Differential Geometry of Curves and Surfaces"" -- the topic of study is curves and surfaces in $\mathbb{R}^3$.  However, the definition of ""curve"" and ""surface"" are usually presented in very different ways. A curve is defined simply as a differentiable map $\gamma\colon I \to \mathbb{R}^3$, where $I \subset \mathbb{R}$ is an interval.  Of course, some authors prefer to define a curve as the image of such a map, and others require piecewise-differentiability, but the general concept is the same. On the other hand, surfaces are essentially defined as 2-manifolds. Similarly, in graduate courses on manifolds -- I am thinking of John Lee's ""Introduction to Smooth Manifolds"" -- one talks about curves $\gamma\colon I \to M$ in a manifold, and can do line integrals over such curves, but talks separately about embedded/immersed 1-dimensional submanifolds. My question, then, is: Why make (parametrized) curves the object of study rather than 1-manifolds? Earlier, I asked a question that was perhaps meant to hint at this one, though I didn't say so explicitly. Ultimately, I would simply like to say ""curves are 1-manifolds and surfaces are 2-manifolds,"" and am looking for reasons why this is correct/incorrect or at least a good/bad idea.  (So, yes, I'm looking for a standard definition of ""curve."")",,"['soft-question', 'differential-geometry', 'differential-topology']"
6,Isometries of the sphere $\mathbb{S}^{n}$,Isometries of the sphere,\mathbb{S}^{n},"Got this as homework and I don't know how to tackle this. Help please! Prove that the isometries of $\mathbb{S}^{n} \subset \mathbb{R}^{n+1}$, with the induced metric, are restrictions to $\mathbb{S}^{n}$ of the linear orthogonal transformations.","Got this as homework and I don't know how to tackle this. Help please! Prove that the isometries of $\mathbb{S}^{n} \subset \mathbb{R}^{n+1}$, with the induced metric, are restrictions to $\mathbb{S}^{n}$ of the linear orthogonal transformations.",,"['differential-geometry', 'lie-groups', 'riemannian-geometry']"
7,How a principal bundle and the associated vector bundle determine each other,How a principal bundle and the associated vector bundle determine each other,,"It seems to me that given a vector bundle, the associated principal bundle is univocally determined. In fact one has to construct a principal bundle given the base, the fibre (the group $G$ in which the transition functions of the vector bundle take values) and a local trivialization whose associated transition functions satisfy the cocycle condition. On the other hand, it seems to me that given a principal bundle, the associated vector bundle is far from unique: first one has to specify what is the vector space $V$ constituting the typical fibre, second one has to give a representation of $G$ on $V$. Even if the principal bundle is nontrivial, by taking the trivial representation the associated vector bundle is trivial. If what I say is correct, why is the terminology ""\emph{the} associated vector bundle"" so widely use when there is no such an object, even if the vector space itself is specified?","It seems to me that given a vector bundle, the associated principal bundle is univocally determined. In fact one has to construct a principal bundle given the base, the fibre (the group $G$ in which the transition functions of the vector bundle take values) and a local trivialization whose associated transition functions satisfy the cocycle condition. On the other hand, it seems to me that given a principal bundle, the associated vector bundle is far from unique: first one has to specify what is the vector space $V$ constituting the typical fibre, second one has to give a representation of $G$ on $V$. Even if the principal bundle is nontrivial, by taking the trivial representation the associated vector bundle is trivial. If what I say is correct, why is the terminology ""\emph{the} associated vector bundle"" so widely use when there is no such an object, even if the vector space itself is specified?",,"['differential-geometry', 'vector-bundles', 'principal-bundles']"
8,Expressing Differential Form in Different Coordinates,Expressing Differential Form in Different Coordinates,,"All: Please forgive me, I'm new and my editing/Latex needs improvement. I'm trying to derive the formula for change of variables for the differential form $\omega=dx\wedge dy$ in standard $xy$-coordinates in $\mathbb R^2 $, into polar coordinates in $\mathbb R^2$. I know we can use the quick-and-dirty change of variables: $$ x=r\cos t, \quad y=r\sin t. $$ Then sub-in, expand, and cancel terms with repeated $dr$'s and/or $dt$'s. But I'm trying to use the layout in J. Lee's Smooth Manifolds , pp 303-304, given by: Definition. Given a smooth map $F\colon M \to N$ and a form $\omega$ defined on $N$, the pullback $F^*$ is given by: \begin{equation} (F^*\omega)_p(X_1, \ldots, X_n) := \omega_{F(p)} (F_*X_1,....,F_*X_n). \qquad (**) \end{equation} Results. a) $F^*$ is linear on the space of smooth sections b) $F^*(\omega\wedge \eta)=F_*(\omega)\wedge F_*(\eta)$ c) In any smooth chart, and for every multi-index index $I=(i_1,i_2,\ldots,i_k)$:   $$ F^*(\sum' \omega_I dy^{i_1}\wedge dy^{i_2} \wedge \ldots \wedge dy^{i_k})=\sum'(\omega_I \circ F)d(y^{i_1} \circ F)\wedge\cdots\wedge d(y^{i_k} \circ F),$$ where $\sum'$ is a sum over increasing indices. So far, I have: $\omega=dx\wedge dy$; $F\colon\mathbb R^2\to\mathbb {R^2}'$, and $\omega$ is defined on the target ${\mathbb R^2}'$. We pull back by the map $F(x,y)=(r\cos t,r\sin t)$. Then, by  b, $F^*\omega =F^*(dx\wedge dy) =F^*(dx)\wedge F^*(dy)$. (Moreover, Lee has not yet defined the meaning of $dx$, nor of $dy^{i_k}$.) Now, I can only think of using $(**)$, but this does not help: $F^*(dx):=dx(\cos t, \sin t) (F_*X_1,\ldots,F_*X_n)$ where $F_*$ is given by $F_*(X)(f)=X(f\circ F)$. Any ideas?","All: Please forgive me, I'm new and my editing/Latex needs improvement. I'm trying to derive the formula for change of variables for the differential form $\omega=dx\wedge dy$ in standard $xy$-coordinates in $\mathbb R^2 $, into polar coordinates in $\mathbb R^2$. I know we can use the quick-and-dirty change of variables: $$ x=r\cos t, \quad y=r\sin t. $$ Then sub-in, expand, and cancel terms with repeated $dr$'s and/or $dt$'s. But I'm trying to use the layout in J. Lee's Smooth Manifolds , pp 303-304, given by: Definition. Given a smooth map $F\colon M \to N$ and a form $\omega$ defined on $N$, the pullback $F^*$ is given by: \begin{equation} (F^*\omega)_p(X_1, \ldots, X_n) := \omega_{F(p)} (F_*X_1,....,F_*X_n). \qquad (**) \end{equation} Results. a) $F^*$ is linear on the space of smooth sections b) $F^*(\omega\wedge \eta)=F_*(\omega)\wedge F_*(\eta)$ c) In any smooth chart, and for every multi-index index $I=(i_1,i_2,\ldots,i_k)$:   $$ F^*(\sum' \omega_I dy^{i_1}\wedge dy^{i_2} \wedge \ldots \wedge dy^{i_k})=\sum'(\omega_I \circ F)d(y^{i_1} \circ F)\wedge\cdots\wedge d(y^{i_k} \circ F),$$ where $\sum'$ is a sum over increasing indices. So far, I have: $\omega=dx\wedge dy$; $F\colon\mathbb R^2\to\mathbb {R^2}'$, and $\omega$ is defined on the target ${\mathbb R^2}'$. We pull back by the map $F(x,y)=(r\cos t,r\sin t)$. Then, by  b, $F^*\omega =F^*(dx\wedge dy) =F^*(dx)\wedge F^*(dy)$. (Moreover, Lee has not yet defined the meaning of $dx$, nor of $dy^{i_k}$.) Now, I can only think of using $(**)$, but this does not help: $F^*(dx):=dx(\cos t, \sin t) (F_*X_1,\ldots,F_*X_n)$ where $F_*$ is given by $F_*(X)(f)=X(f\circ F)$. Any ideas?",,['differential-geometry']
9,The Uniqueness Part of the Smooth-Manifold-Chart-Lemma in John M. Lee's Introduction to Smooth Manifolds.,The Uniqueness Part of the Smooth-Manifold-Chart-Lemma in John M. Lee's Introduction to Smooth Manifolds.,,"I am trying to understand the proof of Lemma 1.35 (Smooth Manifold Chart Lemma) of John. M. Lee's Introduction to Smooth Manifolds , 2nd Edition. The Lemma is an existence-and-uniqueness-lemma. I understand the existence part of it but not the uniqueness part. Here I state the Lemma and the proof of the existence part (the proof is essentially just a detailed version of the proof given in Lee's book.) LEMMA. Let $M$ be a set and $\{U_\alpha\}_{\alpha\in J}$ be a collection of subsets of $M$ , along with maps $\varphi_\alpha:U_\alpha\to\mathbf R^n$ , such that the following properties are satisfied: (i) $\forall \alpha\in J$ : $\varphi_\alpha$ is an injective map and $\varphi_\alpha(U_\alpha)$ is open in $\mathbf R^n$ . (ii) $\forall \alpha,\beta\in J$ : the sets $\varphi_\alpha(U_\alpha\cap U_\beta)$ and $\varphi_\beta(U_\alpha\cap U_\beta)$ are open in $\mathbf R^n$ . (iii) $\forall\alpha,\beta\in J$ : $U_\alpha\cap U_\beta\neq \emptyset 			\quad 			\Rightarrow 			\quad \varphi_\beta\circ\varphi_\alpha^{-1}:\varphi_\alpha(U_\alpha\cap U_\beta)\to \varphi_\beta(U_\alpha\cap U_\beta)$ is smooth. (iv) Countably many of the sets $U_\alpha$ cover $M$ . (v) $ \left. \begin{array}{c} p,q\in M\\ p\neq q \end{array} \right\} \quad \Rightarrow \quad \left\{ \begin{array}{c} \exists \alpha\in J\text{ such that } p,q\in U_\alpha,\quad\text{ or}\\ \exists \alpha,\beta\in J\text{ such that } p\in U_\alpha, q\in U_\beta \text{ and } U_\alpha\cap U_\beta=\emptyset \end{array} \right. $ Then $M$ has a unique manifold structure such that each pair $(U_\alpha,\varphi_\alpha)$ is a smooth chart. PROOF. Let $\mathcal B=\{\varphi_\alpha^{-1}(V):\alpha\in J, V\text{ open in } \mathbf R^n\}$ . Claim 1: $\mathcal B$ forms a basis for $M$ . Proof: We use $(i)$ --- $(iv)$ in this proof.  From $(iv)$ we see that the elements of $\mathcal B$ cover $M$ . Now let $\varphi_\alpha^{-1}(V)$ and $\varphi_\beta^{-1}(W)$ be two elements of $\mathcal B$ , where $V$ and $W$ are open in $\mathbf R^n$ . To show that $\mathcal B$ forms a basis, it is enough to show that $ \varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W)$ itself lies in $\mathcal B$ . Note that \begin{equation*} \varphi_\alpha^{-1}(V)\cap \varphi_\beta^{-1}(W)=\varphi_\alpha^{-1}\Big(V\cap(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)\Big) \tag{1} \end{equation*} But by (iii), $\varphi_\beta\circ\varphi_\alpha^{-1}$ is continuous, and therefore $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\varphi_\alpha(U_\alpha\cap U_\beta)$ . By (ii), $\varphi_\alpha(U_\alpha\cap U_\beta)$ is open in $\mathbf R^n$ and therefore $(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)$ is open in $\mathbf R^n$ . Using this in $(1)$ , we immediately see that $\varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W)$ is in $\mathcal B$ . This settles the claim. Let $\tau$ be the topology generated on $M$ by $\mathcal B$ . By definition of $\mathcal B$ , each function $\varphi_\alpha$ is a homeomorphism onto its image. Thus $(M,\tau)$ is locally Euclidean of dimension $n$ . Claim 2: $(M,\tau)$ is Hausdorff. Proof: This uses $(v)$ . Let $p,q\in M$ with $p\neq q$ . If $\exists \alpha,\beta\in J$ such that $p\in U_\alpha, q\in U_\beta$ and $U_\alpha\cap U_\beta=\emptyset$ , then we have nothing to prove. The other possibility if that $\exists \alpha\in J$ such that $p,q\in U_\alpha$ .             Now since $\varphi_\alpha(U_\alpha)$ is open in $\mathbf R^n$ , there exist disjoint open sets $V$ and $W$ open in $\varphi_\alpha(U_\alpha)$ containing $p$ and $q$ respectively. The neighborhoods $\varphi_\alpha^{-1}(V)$ and $\varphi_\alpha^{-1}(W)$ separate $p$ and $q$ in $M$ . Thus the claim is settled. Claim 3: $(M,\tau)$ is second countable. Proof: Note that since $\varphi_\alpha(U_\alpha)$ is second countable, and since $\varphi_\alpha:U_\alpha\to\varphi_\alpha(U_\alpha)$ is a homeomorphism, we must have $U_\alpha$ is second countable. The proof is now immediate from $(iv)$ and Lemma given at the bottom. The above working shows that $(M,\tau)$ is a topological $n$ -manifold. Now from $(iii)$ it is clear that $\{(U_\alpha,\varphi_\alpha)\}_{\alpha\in J}$ is a smooth atlas on $M$ , giving $M$ a smooth structure. Now we need to establish that this is the only smooth structure on $M$ such that each $\varphi_\alpha:U_\alpha\to\varphi_\alpha(U_\alpha)$ is a smooth chart on $M$ and here I am stuck. In fact what Lee writes is that ""It is clear that this topology and smooth structure are the unique ones satisfying the conclusions (conditions?) of the lemma."" Can somebody please explain this to me. LEMMA. Let $X$ be a topological space and $\{U_n\}_{n\in\mathbf N}$ be a countable open cover of $X$ such that each $U_i$ is second countable in the subspace topology. Then $X$ is second countable.","I am trying to understand the proof of Lemma 1.35 (Smooth Manifold Chart Lemma) of John. M. Lee's Introduction to Smooth Manifolds , 2nd Edition. The Lemma is an existence-and-uniqueness-lemma. I understand the existence part of it but not the uniqueness part. Here I state the Lemma and the proof of the existence part (the proof is essentially just a detailed version of the proof given in Lee's book.) LEMMA. Let be a set and be a collection of subsets of , along with maps , such that the following properties are satisfied: (i) : is an injective map and is open in . (ii) : the sets and are open in . (iii) : is smooth. (iv) Countably many of the sets cover . (v) Then has a unique manifold structure such that each pair is a smooth chart. PROOF. Let . Claim 1: forms a basis for . Proof: We use --- in this proof.  From we see that the elements of cover . Now let and be two elements of , where and are open in . To show that forms a basis, it is enough to show that itself lies in . Note that But by (iii), is continuous, and therefore is open in . By (ii), is open in and therefore is open in . Using this in , we immediately see that is in . This settles the claim. Let be the topology generated on by . By definition of , each function is a homeomorphism onto its image. Thus is locally Euclidean of dimension . Claim 2: is Hausdorff. Proof: This uses . Let with . If such that and , then we have nothing to prove. The other possibility if that such that .             Now since is open in , there exist disjoint open sets and open in containing and respectively. The neighborhoods and separate and in . Thus the claim is settled. Claim 3: is second countable. Proof: Note that since is second countable, and since is a homeomorphism, we must have is second countable. The proof is now immediate from and Lemma given at the bottom. The above working shows that is a topological -manifold. Now from it is clear that is a smooth atlas on , giving a smooth structure. Now we need to establish that this is the only smooth structure on such that each is a smooth chart on and here I am stuck. In fact what Lee writes is that ""It is clear that this topology and smooth structure are the unique ones satisfying the conclusions (conditions?) of the lemma."" Can somebody please explain this to me. LEMMA. Let be a topological space and be a countable open cover of such that each is second countable in the subspace topology. Then is second countable.","M \{U_\alpha\}_{\alpha\in J} M \varphi_\alpha:U_\alpha\to\mathbf R^n \forall \alpha\in J \varphi_\alpha \varphi_\alpha(U_\alpha) \mathbf R^n \forall \alpha,\beta\in J \varphi_\alpha(U_\alpha\cap U_\beta) \varphi_\beta(U_\alpha\cap U_\beta) \mathbf R^n \forall\alpha,\beta\in J U_\alpha\cap U_\beta\neq \emptyset
			\quad
			\Rightarrow
			\quad \varphi_\beta\circ\varphi_\alpha^{-1}:\varphi_\alpha(U_\alpha\cap U_\beta)\to \varphi_\beta(U_\alpha\cap U_\beta) U_\alpha M 
\left.
\begin{array}{c}
p,q\in M\\
p\neq q
\end{array}
\right\}
\quad
\Rightarrow
\quad
\left\{
\begin{array}{c}
\exists \alpha\in J\text{ such that } p,q\in U_\alpha,\quad\text{ or}\\
\exists \alpha,\beta\in J\text{ such that } p\in U_\alpha, q\in U_\beta \text{ and } U_\alpha\cap U_\beta=\emptyset
\end{array}
\right.
 M (U_\alpha,\varphi_\alpha) \mathcal B=\{\varphi_\alpha^{-1}(V):\alpha\in J, V\text{ open in } \mathbf R^n\} \mathcal B M (i) (iv) (iv) \mathcal B M \varphi_\alpha^{-1}(V) \varphi_\beta^{-1}(W) \mathcal B V W \mathbf R^n \mathcal B  \varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W) \mathcal B \begin{equation*}
\varphi_\alpha^{-1}(V)\cap \varphi_\beta^{-1}(W)=\varphi_\alpha^{-1}\Big(V\cap(\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W)\Big)
\tag{1}
\end{equation*} \varphi_\beta\circ\varphi_\alpha^{-1} (\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W) \varphi_\alpha(U_\alpha\cap U_\beta) \varphi_\alpha(U_\alpha\cap U_\beta) \mathbf R^n (\varphi_\beta\circ\varphi_\alpha^{-1})^{-1}(W) \mathbf R^n (1) \varphi_\alpha^{-1}(V)\cap\varphi_\beta^{-1}(W) \mathcal B \tau M \mathcal B \mathcal B \varphi_\alpha (M,\tau) n (M,\tau) (v) p,q\in M p\neq q \exists \alpha,\beta\in J p\in U_\alpha, q\in U_\beta U_\alpha\cap U_\beta=\emptyset \exists \alpha\in J p,q\in U_\alpha \varphi_\alpha(U_\alpha) \mathbf R^n V W \varphi_\alpha(U_\alpha) p q \varphi_\alpha^{-1}(V) \varphi_\alpha^{-1}(W) p q M (M,\tau) \varphi_\alpha(U_\alpha) \varphi_\alpha:U_\alpha\to\varphi_\alpha(U_\alpha) U_\alpha (iv) (M,\tau) n (iii) \{(U_\alpha,\varphi_\alpha)\}_{\alpha\in J} M M M \varphi_\alpha:U_\alpha\to\varphi_\alpha(U_\alpha) M X \{U_n\}_{n\in\mathbf N} X U_i X","['differential-geometry', 'smooth-manifolds']"
10,Stochastic interpretation of Einstein equations,Stochastic interpretation of Einstein equations,,"Einstein's theory of gravitation, general relativity , is a purely geometric theory . In a recent question I wanted to know what the relation of Brownian motion to the Helmholtz equation is and got a very thorough answer from George Lowther . He pointed out that there is, roughly speaking, a very general relation of semi-elliptic second order differential operators of the form $$Af = \frac12 a^{ij}f_{,ij} + b^i f_{,i} - cf = 0$$ to a ""killed"" Brownian motion. (I used some summation convention and $,i = \frac{\partial}{\partial x^i}$.) Now, the Einstein field equations $$R_{\mu\nu}-\frac12 g_{\mu\nu}R = \frac{8\pi G}{c^4}T_{\mu\nu}$$ are coupled hyperbolic-elliptic partial differential equations (I dropped the cosmological constant here). Can we somehow adopt the relation of a random process to this kind of equation, or Is there a way to interprete the   Einstein equations stochastically?","Einstein's theory of gravitation, general relativity , is a purely geometric theory . In a recent question I wanted to know what the relation of Brownian motion to the Helmholtz equation is and got a very thorough answer from George Lowther . He pointed out that there is, roughly speaking, a very general relation of semi-elliptic second order differential operators of the form $$Af = \frac12 a^{ij}f_{,ij} + b^i f_{,i} - cf = 0$$ to a ""killed"" Brownian motion. (I used some summation convention and $,i = \frac{\partial}{\partial x^i}$.) Now, the Einstein field equations $$R_{\mu\nu}-\frac12 g_{\mu\nu}R = \frac{8\pi G}{c^4}T_{\mu\nu}$$ are coupled hyperbolic-elliptic partial differential equations (I dropped the cosmological constant here). Can we somehow adopt the relation of a random process to this kind of equation, or Is there a way to interprete the   Einstein equations stochastically?",,"['differential-geometry', 'partial-differential-equations', 'stochastic-processes', 'mathematical-physics', 'general-relativity']"
11,A short question on shriek maps,A short question on shriek maps,,"This should be easy but I don't quite see it. Let $M^m, N^n, X^d$ be compact, connected and oriented smooth manifolds. Let also $f:M\rightarrow X$ and $g:N\rightarrow X$ be transverse smooth maps. Then $$M\times_XN=\{(p,q)\in M\times N:\ f(p)=g(q)\}$$ is a smooth manifold. Consider $\pi_M,\pi_N$ the respective projections from it to $M,N$. The question is how to prove that $$(\pi_M)_*[M\times_XN]=f_!g_*[N]$$ as elements of $H_{m+n-d}(M;\mathbb{Z})$ (here $f_!$ is the shriek map $f_!=PD_M\circ f^*\circ PD_X^{-1}$). N.B.: I can prove the result for real coefficients, but I would like to find a proof for integer coefficients. Edit: In view of Stella's comment I'll write down the proof I have for real coefficients. Let me work in cohomology instead of homology: the equality I want to prove is equivalent to $$\pi_M^!(1)=f^*g^!(1).$$ Consider the projections $$\pi_1:X\times X\rightarrow X,\ \tilde{\pi}_M:M\times N\rightarrow M,$$ the inclusion map $$i:M\times_XN\rightarrow M\times N$$ and the map $$(f,g):M\times N\rightarrow X\times X.$$ Then we have (1) $\pi_1\circ(f,g)=f\circ\tilde{\pi}_M$, (2) $\pi_M=\tilde{\pi}_M\circ i$ and (3) $M\times_XN=(f,g)^{-1}(\Delta)$. Moreover let $a_i$ be a basis for $H_{dR}(X)$ and let $b_i$ be its dual basis with respect to Poincaré duality. Then (4) $PD_{X\times X}^{-1}([\Delta])=\sum a_i\otimes b_i$. Now, from (3) we have that $$i^!(1)=((f,g)^*\circ PD_{X\times X}^{-1})([\Delta]),$$ which from (4) leads to $$i^!(1)=\sum f^*(a_i)\otimes g^*(b_i).$$ We use (2) to get $$\pi_M^!(1)=(\tilde{\pi}_M^!\circ i^!)(1)=\tilde{\pi}_M^!\left(\sum f^*(a_i)\otimes g^*(b_i)\right).$$ Finally, since $\tilde{\pi}_M^!$ is integration along the fibre we get $$\pi_M^!(1)=\sum f^*(a_i)\int_Ng^*(b_i).$$ On the other hand, $g^!(1)=(PD_X^{-1}\circ g_*)[N]=\sum a_i\int_Ng^*(b_i)$, and applying $f^*$ we get the same expression as above.","This should be easy but I don't quite see it. Let $M^m, N^n, X^d$ be compact, connected and oriented smooth manifolds. Let also $f:M\rightarrow X$ and $g:N\rightarrow X$ be transverse smooth maps. Then $$M\times_XN=\{(p,q)\in M\times N:\ f(p)=g(q)\}$$ is a smooth manifold. Consider $\pi_M,\pi_N$ the respective projections from it to $M,N$. The question is how to prove that $$(\pi_M)_*[M\times_XN]=f_!g_*[N]$$ as elements of $H_{m+n-d}(M;\mathbb{Z})$ (here $f_!$ is the shriek map $f_!=PD_M\circ f^*\circ PD_X^{-1}$). N.B.: I can prove the result for real coefficients, but I would like to find a proof for integer coefficients. Edit: In view of Stella's comment I'll write down the proof I have for real coefficients. Let me work in cohomology instead of homology: the equality I want to prove is equivalent to $$\pi_M^!(1)=f^*g^!(1).$$ Consider the projections $$\pi_1:X\times X\rightarrow X,\ \tilde{\pi}_M:M\times N\rightarrow M,$$ the inclusion map $$i:M\times_XN\rightarrow M\times N$$ and the map $$(f,g):M\times N\rightarrow X\times X.$$ Then we have (1) $\pi_1\circ(f,g)=f\circ\tilde{\pi}_M$, (2) $\pi_M=\tilde{\pi}_M\circ i$ and (3) $M\times_XN=(f,g)^{-1}(\Delta)$. Moreover let $a_i$ be a basis for $H_{dR}(X)$ and let $b_i$ be its dual basis with respect to Poincaré duality. Then (4) $PD_{X\times X}^{-1}([\Delta])=\sum a_i\otimes b_i$. Now, from (3) we have that $$i^!(1)=((f,g)^*\circ PD_{X\times X}^{-1})([\Delta]),$$ which from (4) leads to $$i^!(1)=\sum f^*(a_i)\otimes g^*(b_i).$$ We use (2) to get $$\pi_M^!(1)=(\tilde{\pi}_M^!\circ i^!)(1)=\tilde{\pi}_M^!\left(\sum f^*(a_i)\otimes g^*(b_i)\right).$$ Finally, since $\tilde{\pi}_M^!$ is integration along the fibre we get $$\pi_M^!(1)=\sum f^*(a_i)\int_Ng^*(b_i).$$ On the other hand, $g^!(1)=(PD_X^{-1}\circ g_*)[N]=\sum a_i\int_Ng^*(b_i)$, and applying $f^*$ we get the same expression as above.",,"['differential-geometry', 'algebraic-topology']"
12,Line bundles of the circle,Line bundles of the circle,,"Up to isomorphism, I think there exist only two line bundles of the circle: the trivial bundle (diffeomorphic to a cylinder) and a bundle that looks like to a Möbius band. Although it seems obvious geometrically I did not find a good argument to justify it. Do you have an idea?","Up to isomorphism, I think there exist only two line bundles of the circle: the trivial bundle (diffeomorphic to a cylinder) and a bundle that looks like to a Möbius band. Although it seems obvious geometrically I did not find a good argument to justify it. Do you have an idea?",,"['differential-geometry', 'vector-bundles']"
13,"Smooth surfaces that isn't the zero-set of $f(x,y,z)$",Smooth surfaces that isn't the zero-set of,"f(x,y,z)","The zero-set of any smooth function $f(x,y,z)$ with a non-vanishing gradient is a smooth surface. I was wondering if the reverse is true: is every smooth surface in $E^3$ the zero-set of some smooth function? If not, what do the counterexamples look like? I was thinking that a plane with a hole may qualify as a counterexample, but I have yet to prove it.","The zero-set of any smooth function $f(x,y,z)$ with a non-vanishing gradient is a smooth surface. I was wondering if the reverse is true: is every smooth surface in $E^3$ the zero-set of some smooth function? If not, what do the counterexamples look like? I was thinking that a plane with a hole may qualify as a counterexample, but I have yet to prove it.",,"['differential-geometry', 'manifolds']"
14,Any example of manifold without global trivialization of tangent bundle,Any example of manifold without global trivialization of tangent bundle,,"It is said for most manifolds, there does not exist a global trivialization of the tangent bundle. I am not quite clear about it. The tangent bundle is defined as $$TM=\bigsqcup_{p\in M}T_PM$$ So is the above statement saying that generally $$ \bigsqcup_{p\in M}T_PM\neq M\times\mathbb{R}^n? $$ But I think the tangent space is just attaching a $\mathbb{R}^n$ to every point on $M$, so I wonder what's the reason for it is not a product space? Plus, when defining trivialization, we have a lot of constraint on the function $F:TM\rightarrow M\times V$, can anyone explain the necessity of those constraint? At last, does $S^2$ has a global trivialization? Update: Following is my attempt to trivialize $S^2$, but meet some problem. I think it may reflect some aspect in the impossibility to trivialization of $S^2$, isn't it? We want to define trivialization $F:TS^2\rightarrow S^2\times \mathbb{R}^2$. First of all, $F$ should be well-defined. There are 3 different approach to define a tangent space, here I take the definition via chart. So, an element in $TS^2$ is $\left[(p, v, (U,\varphi))\right]$, and of course I try to define its image to be $(p, v)$. Then the problem comes. Because we need at least 2 chart to cover $S^2$, so when taking another representative $(p, w, (V,\phi))$ of the equivalent class $\left[(p, v, (U,\varphi))\right]$, we map it to $(p, w)$, which conflicts the previous image. Of course it is only one attempt, but I think it may reflect some difficulty to define $F$ because it need to preserve coordinate transformation. Right? Eh.. I realized my attempt is too trivial. If I apply this method to any manifold, $F$ is never well-define... Can anyone provide an manifold which can be trivialize? I think I may use it to get better understanding.","It is said for most manifolds, there does not exist a global trivialization of the tangent bundle. I am not quite clear about it. The tangent bundle is defined as $$TM=\bigsqcup_{p\in M}T_PM$$ So is the above statement saying that generally $$ \bigsqcup_{p\in M}T_PM\neq M\times\mathbb{R}^n? $$ But I think the tangent space is just attaching a $\mathbb{R}^n$ to every point on $M$, so I wonder what's the reason for it is not a product space? Plus, when defining trivialization, we have a lot of constraint on the function $F:TM\rightarrow M\times V$, can anyone explain the necessity of those constraint? At last, does $S^2$ has a global trivialization? Update: Following is my attempt to trivialize $S^2$, but meet some problem. I think it may reflect some aspect in the impossibility to trivialization of $S^2$, isn't it? We want to define trivialization $F:TS^2\rightarrow S^2\times \mathbb{R}^2$. First of all, $F$ should be well-defined. There are 3 different approach to define a tangent space, here I take the definition via chart. So, an element in $TS^2$ is $\left[(p, v, (U,\varphi))\right]$, and of course I try to define its image to be $(p, v)$. Then the problem comes. Because we need at least 2 chart to cover $S^2$, so when taking another representative $(p, w, (V,\phi))$ of the equivalent class $\left[(p, v, (U,\varphi))\right]$, we map it to $(p, w)$, which conflicts the previous image. Of course it is only one attempt, but I think it may reflect some difficulty to define $F$ because it need to preserve coordinate transformation. Right? Eh.. I realized my attempt is too trivial. If I apply this method to any manifold, $F$ is never well-define... Can anyone provide an manifold which can be trivialize? I think I may use it to get better understanding.",,"['differential-geometry', 'manifolds', 'vector-bundles']"
15,Recommending books for introductory differential geometry [duplicate],Recommending books for introductory differential geometry [duplicate],,"This question already has answers here : Teaching myself differential topology and differential geometry (10 answers) Closed 5 years ago . I was wondering if anyone could recommend some books for studying topics such as abstract manifolds, differential forms on manifolds, integration of differential forms, Stokes' theorem, de Rham cohomology, Hodge star operator? Our text is A Comprehensive Introduction to Differential Geometry by Spivak, but I think this book is very difficult for a beginner to learn. Thanks in advance.","This question already has answers here : Teaching myself differential topology and differential geometry (10 answers) Closed 5 years ago . I was wondering if anyone could recommend some books for studying topics such as abstract manifolds, differential forms on manifolds, integration of differential forms, Stokes' theorem, de Rham cohomology, Hodge star operator? Our text is A Comprehensive Introduction to Differential Geometry by Spivak, but I think this book is very difficult for a beginner to learn. Thanks in advance.",,"['differential-geometry', 'reference-request', 'book-recommendation']"
16,Can every continuous function between topological manifolds be turned into a differentiable map?,Can every continuous function between topological manifolds be turned into a differentiable map?,,"Let $M$ and $N$ be topological manifolds that admit differential structures and let $f:M\to N$ be continuous. Can $M$ and $N$ always be given differential structures to become differentiable manifolds $\widetilde M$ and $\widetilde N$ such that $f:\widetilde M\to\widetilde N$ is differentiable? What if we impose further restrictions, such as $\widetilde M$ and $\widetilde N$ being smooth manifolds, or $f$ becoming smooth? Are there certain differential structures which we can't do this with (i.e. if we want to make $f$ differentiable, we can never make $N$ diffeomorphic to $\overline N$ where $\overline N$ is some differential structure on $N$ )? What if $M$ already has a fixed differential structure?","Let and be topological manifolds that admit differential structures and let be continuous. Can and always be given differential structures to become differentiable manifolds and such that is differentiable? What if we impose further restrictions, such as and being smooth manifolds, or becoming smooth? Are there certain differential structures which we can't do this with (i.e. if we want to make differentiable, we can never make diffeomorphic to where is some differential structure on )? What if already has a fixed differential structure?",M N f:M\to N M N \widetilde M \widetilde N f:\widetilde M\to\widetilde N \widetilde M \widetilde N f f N \overline N \overline N N M,"['differential-geometry', 'manifolds', 'differential-topology']"
17,"Is the chart function of a smooth manifold a differomorphism, not just a homeomorphism","Is the chart function of a smooth manifold a differomorphism, not just a homeomorphism",,"It's clear that a smooth chart on a manifold is a diffeomorphism.  To me, the fact that smoothness of a manifold implies the smoothness of the transition function between the representation of two charts (whose domains overlap in M) should also imply that each plain old chart function is also a diffeomorphism.  But is this correct?","It's clear that a smooth chart on a manifold is a diffeomorphism.  To me, the fact that smoothness of a manifold implies the smoothness of the transition function between the representation of two charts (whose domains overlap in M) should also imply that each plain old chart function is also a diffeomorphism.  But is this correct?",,['differential-geometry']
18,What type of object is a differential form?,What type of object is a differential form?,,"This is a naive question; apologies in advance. For a point $p \in M$ on a smooth manifold $M$, a differential form can be viewed as a map $$T_p M\times \cdots \times T_p M \to \mathbb{R} \;.$$ What puzzles me about this object is that it is not ""differential."" Yes, I know, the tangent space $T_p M$ is differential in that it is tangent . But if $M=\mathbb{R}^n$, then I lose the intuitive sense of tangency, and just end up with a map from $k$ vectors to $\mathbb{R}$ with certain properties (the map is multilinear, and alternating). I seek a way to view differential forms intuitively that somehow emphasizes their differential aspects.  Help would be much appreciated---Thanks!","This is a naive question; apologies in advance. For a point $p \in M$ on a smooth manifold $M$, a differential form can be viewed as a map $$T_p M\times \cdots \times T_p M \to \mathbb{R} \;.$$ What puzzles me about this object is that it is not ""differential."" Yes, I know, the tangent space $T_p M$ is differential in that it is tangent . But if $M=\mathbb{R}^n$, then I lose the intuitive sense of tangency, and just end up with a map from $k$ vectors to $\mathbb{R}$ with certain properties (the map is multilinear, and alternating). I seek a way to view differential forms intuitively that somehow emphasizes their differential aspects.  Help would be much appreciated---Thanks!",,['differential-geometry']
19,Is there a way to make tangent bundle a monad?,Is there a way to make tangent bundle a monad?,,"The tangent bundle functor $T: \mathbf{Diff} \to \mathbf{Diff}$ together with the bundle projection $\pi: T \Rightarrow 1_\mathbf{Diff}$ basically screams 'monad' at me, especially because both $\pi T$ and $T \pi$ satisfy the associativity axiom, but so far I couldn't find a proper unit for it (the zero section doesn't work out, although there is still a chance that it will up to a 3-equivalence thanks to the canonical involution between $\pi T$ and $T \pi$). Is it possible to make $T$ a monad? Do $T$-algebras have a nice description then?","The tangent bundle functor $T: \mathbf{Diff} \to \mathbf{Diff}$ together with the bundle projection $\pi: T \Rightarrow 1_\mathbf{Diff}$ basically screams 'monad' at me, especially because both $\pi T$ and $T \pi$ satisfy the associativity axiom, but so far I couldn't find a proper unit for it (the zero section doesn't work out, although there is still a chance that it will up to a 3-equivalence thanks to the canonical involution between $\pi T$ and $T \pi$). Is it possible to make $T$ a monad? Do $T$-algebras have a nice description then?",,"['differential-geometry', 'category-theory', 'monads']"
20,What's special about $C^\infty$ functions?,What's special about  functions?,C^\infty,"In my experience, people usually use ""smooth"" to mean ""as smooth as I need for the upcoming proofs."" Those who want to be more formal might insist on smooth meaning $C^\infty$. While the operator taking $f$ to its Taylor series at some point in its domain uses information about all the partial derivatives of $f$ at once, I don't think I know an example to settle the following question: Is there anything I can do simultaneously with infinitely many derivatives of a $C^\infty$, not necessarily analytic function? I hope that's not phrased too vaguely. Since there are $C^\infty$ functions with zero Taylor series, for instance, something like ""sure-you can put all its derivatives into an infinite series!"" is probably not relevant. I won't be surprised if answer is ""No, $C^\infty$ doesn't mean materially more than $C^k$ for sufficiently large $k$."" But I'd be very interested to hear otherwise.","In my experience, people usually use ""smooth"" to mean ""as smooth as I need for the upcoming proofs."" Those who want to be more formal might insist on smooth meaning $C^\infty$. While the operator taking $f$ to its Taylor series at some point in its domain uses information about all the partial derivatives of $f$ at once, I don't think I know an example to settle the following question: Is there anything I can do simultaneously with infinitely many derivatives of a $C^\infty$, not necessarily analytic function? I hope that's not phrased too vaguely. Since there are $C^\infty$ functions with zero Taylor series, for instance, something like ""sure-you can put all its derivatives into an infinite series!"" is probably not relevant. I won't be surprised if answer is ""No, $C^\infty$ doesn't mean materially more than $C^k$ for sufficiently large $k$."" But I'd be very interested to hear otherwise.",,['differential-geometry']
21,How can I lift a path to $\mathrm{Spin}(n)$?,How can I lift a path to ?,\mathrm{Spin}(n),"Suppose I am given an explicit differentiable path $\gamma\colon[a,b]\to SO(n)$, with $\gamma(a)=\gamma(b)=I$.  Then $\gamma$ either does or does not lift to a closed loop in $\mathrm{Spin}(n)$.  How do I tell which is which? For example, let $\gamma\colon[0,2\pi]\to SO(4)$ be the function $$ \gamma(t) \;=\; \begin{bmatrix} \cos t \cos 2t & \sin t \cos 2t & 0 & \sin 2t \\[6.5pt] -\sin t\cos 3t & \cos t \cos 3t & \sin 3t & 0 \\[6.5pt] \sin t \sin 3t & -\cos t \sin 3t & \cos 3t & 0 \\[6.5pt] -\cos t \sin 2t & -\sin t \sin 2t & 0 & \cos 2t \end{bmatrix} $$ Does this lift to a loop in $\mathrm{Spin}(4)$, or not?  What calculation would I need to do to figure this out? Edit: Following Ryan's suggestion, I made a plot of the eigenvalues of the above matrix in Mathematica .  Only the two eigenvalues with $\mathrm{Im}(\lambda)>0\text{ }$are shown, but the other two are simply the complex conjugates: Note that a $-1$ eigenvalue corresponds to the top edge of the rectangle.  There are four obvious values of $t$ where one of the eigenvalues passes through $-1$ transversely, but it also appears that one of the eigenvalues is tangent to $-1$ at $t=\pi$. To resolve the tangency, I perturbed the path $\gamma(t)$ by a path $\delta(t) \in SO(4)$ that stays close to the identity matrix.  Here are the eignevalues for the product $\delta(t)\gamma(t)$: The tangency has now resolved itself into two transverse intersections, making a total of six transverse intersections.  Since six is even, this path lifts to a loop in $\mathrm{Spin}(4)$.","Suppose I am given an explicit differentiable path $\gamma\colon[a,b]\to SO(n)$, with $\gamma(a)=\gamma(b)=I$.  Then $\gamma$ either does or does not lift to a closed loop in $\mathrm{Spin}(n)$.  How do I tell which is which? For example, let $\gamma\colon[0,2\pi]\to SO(4)$ be the function $$ \gamma(t) \;=\; \begin{bmatrix} \cos t \cos 2t & \sin t \cos 2t & 0 & \sin 2t \\[6.5pt] -\sin t\cos 3t & \cos t \cos 3t & \sin 3t & 0 \\[6.5pt] \sin t \sin 3t & -\cos t \sin 3t & \cos 3t & 0 \\[6.5pt] -\cos t \sin 2t & -\sin t \sin 2t & 0 & \cos 2t \end{bmatrix} $$ Does this lift to a loop in $\mathrm{Spin}(4)$, or not?  What calculation would I need to do to figure this out? Edit: Following Ryan's suggestion, I made a plot of the eigenvalues of the above matrix in Mathematica .  Only the two eigenvalues with $\mathrm{Im}(\lambda)>0\text{ }$are shown, but the other two are simply the complex conjugates: Note that a $-1$ eigenvalue corresponds to the top edge of the rectangle.  There are four obvious values of $t$ where one of the eigenvalues passes through $-1$ transversely, but it also appears that one of the eigenvalues is tangent to $-1$ at $t=\pi$. To resolve the tangency, I perturbed the path $\gamma(t)$ by a path $\delta(t) \in SO(4)$ that stays close to the identity matrix.  Here are the eignevalues for the product $\delta(t)\gamma(t)$: The tangency has now resolved itself into two transverse intersections, making a total of six transverse intersections.  Since six is even, this path lifts to a loop in $\mathrm{Spin}(4)$.",,"['algebraic-topology', 'differential-geometry', 'lie-groups']"
22,Reversing the Ricci flow,Reversing the Ricci flow,,"Suppose $S$ is a closed, oriented surface (2-manifold) embedded in $\mathbb{R}^3$, which  inherits the metric from $\mathbb{R}^3$, so that distances are measured by shortest paths on the surface.  If it is at least crudely accurate to say that Ricci flow smooths out the metric/curvature so that the surface (eventually) evolves to a sphere, is there a sense in which ""reverse Ricci flow"" concentrates curvature, in some sense sharpens the curvature, and perhaps partitions $S$ into distinct regions? This is a naive question, for which I apologize in advance; it could be complete nonsense.  What I mean by reverse Ricci flow (my own terminology; perhaps there is standard terminology?), could be simply changing the sign in Hamilton's equation: $$\frac{\partial g}{\partial t} \ = \ 2 \ {\bf Ric}(g) \;.$$ What I mean by ""sharpens the curvature"" is something akin to image-processing operators which enhance the boundaries between regions to segment an image ( edge detection ).  I am imagining segmenting a surface $S$ by reverse Ricci flow. One problem I can foresee is that is that reversing the heat equation is inherently unstable, and maybe the same is true here.  But perhaps in the specific situation of $S \subset \mathbb{R}^3$ inheriting the Euclidean metric, the instabilities are not as severe as they might be for arbitrary Riemannian manifolds. All this is speculation on my part.  Reality checks,  references, or further speculation—all welcomed!","Suppose $S$ is a closed, oriented surface (2-manifold) embedded in $\mathbb{R}^3$, which  inherits the metric from $\mathbb{R}^3$, so that distances are measured by shortest paths on the surface.  If it is at least crudely accurate to say that Ricci flow smooths out the metric/curvature so that the surface (eventually) evolves to a sphere, is there a sense in which ""reverse Ricci flow"" concentrates curvature, in some sense sharpens the curvature, and perhaps partitions $S$ into distinct regions? This is a naive question, for which I apologize in advance; it could be complete nonsense.  What I mean by reverse Ricci flow (my own terminology; perhaps there is standard terminology?), could be simply changing the sign in Hamilton's equation: $$\frac{\partial g}{\partial t} \ = \ 2 \ {\bf Ric}(g) \;.$$ What I mean by ""sharpens the curvature"" is something akin to image-processing operators which enhance the boundaries between regions to segment an image ( edge detection ).  I am imagining segmenting a surface $S$ by reverse Ricci flow. One problem I can foresee is that is that reversing the heat equation is inherently unstable, and maybe the same is true here.  But perhaps in the specific situation of $S \subset \mathbb{R}^3$ inheriting the Euclidean metric, the instabilities are not as severe as they might be for arbitrary Riemannian manifolds. All this is speculation on my part.  Reality checks,  references, or further speculation—all welcomed!",,"['differential-geometry', 'partial-differential-equations', 'differential-topology', 'riemannian-geometry', 'ricci-flow']"
23,Definition of the principal symbol of a differential operator on a real vector bundle.,Definition of the principal symbol of a differential operator on a real vector bundle.,,"I'm trying to understand the construction of the dirac operator on a manifold, but actually I guess that doesn't really matter for the question at stake. I'm interested in understanding a definition of the principal symbol. Specifically, In Lawson and Michelsohn's Spin Geometry page 113 it says: Recall that the principal symbol of a differential operator $D:\Gamma (E) \to \Gamma (E)$ is a map which associates to each point $x \in X $ and each cotangent vector $\xi \in T^*_x(X)$ , a linear map $\sigma _{\xi}(D):E_x \to E_x$ defined as follows. If in local coordinates we have $$ D=\sum_{|\alpha|\leq m}A_{\alpha}(x)\frac{\partial ^{|\alpha|}}{\partial x^{\alpha}} \text{ and } \xi=\sum_k \xi_k dx_k$$ where m is the order of $D$ , then $$\sigma_{\xi}(D) = i^m \sum_{|\alpha|= m} A_{\alpha}(x)\xi^{\alpha}.$$ After going to the some other chapter you find out that $E$ is a complex vector bundle over $X$ , a riemannian manifold, with a local trivialization $E|_U\to U \times \mathbb{C}^q$ and $A_{\alpha}(x)$ is a $q\times q$ -matrix of smooth complex-valued functions. So the question I have is if one is working with real vector bundles how does one define the principal symbol. I mean, if now one has that $A_{\alpha}(x)$ is a $q\times q$ -matrix of smooth real-valued functions, how do you define the linear map $\sigma _{\xi}(D):E_x \to E_x$ , because just taking the "" $i^m$ "" factor off from the definition seems quite arbitrary. Any clarification is highly appreciated!","I'm trying to understand the construction of the dirac operator on a manifold, but actually I guess that doesn't really matter for the question at stake. I'm interested in understanding a definition of the principal symbol. Specifically, In Lawson and Michelsohn's Spin Geometry page 113 it says: Recall that the principal symbol of a differential operator is a map which associates to each point and each cotangent vector , a linear map defined as follows. If in local coordinates we have where m is the order of , then After going to the some other chapter you find out that is a complex vector bundle over , a riemannian manifold, with a local trivialization and is a -matrix of smooth complex-valued functions. So the question I have is if one is working with real vector bundles how does one define the principal symbol. I mean, if now one has that is a -matrix of smooth real-valued functions, how do you define the linear map , because just taking the "" "" factor off from the definition seems quite arbitrary. Any clarification is highly appreciated!",D:\Gamma (E) \to \Gamma (E) x \in X  \xi \in T^*_x(X) \sigma _{\xi}(D):E_x \to E_x  D=\sum_{|\alpha|\leq m}A_{\alpha}(x)\frac{\partial ^{|\alpha|}}{\partial x^{\alpha}} \text{ and } \xi=\sum_k \xi_k dx_k D \sigma_{\xi}(D) = i^m \sum_{|\alpha|= m} A_{\alpha}(x)\xi^{\alpha}. E X E|_U\to U \times \mathbb{C}^q A_{\alpha}(x) q\times q A_{\alpha}(x) q\times q \sigma _{\xi}(D):E_x \to E_x i^m,"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'differential-operators']"
24,Review on Riemannian Geometry,Review on Riemannian Geometry,,"I'm currently reading through Griffiths and Harris Principles of Algebraic Geometry, and the only subject in the foundational material section that I am not completely comfortable with is riemannian geometry, ie. notions of curvature, connections, riemann tensor. Is there an algebraic geometry text that has a more thorough review of these notions over $\mathbb{R}$, that reviews the subject comprehensively, but briefly in the first or so chapters? I've taken the course before, and I don't want to have to refer to a bigger text devoted to differential/riemannian geometry and I'd rather just read a brief review of the subject and the main/essential points. Thanks!","I'm currently reading through Griffiths and Harris Principles of Algebraic Geometry, and the only subject in the foundational material section that I am not completely comfortable with is riemannian geometry, ie. notions of curvature, connections, riemann tensor. Is there an algebraic geometry text that has a more thorough review of these notions over $\mathbb{R}$, that reviews the subject comprehensively, but briefly in the first or so chapters? I've taken the course before, and I don't want to have to refer to a bigger text devoted to differential/riemannian geometry and I'd rather just read a brief review of the subject and the main/essential points. Thanks!",,"['algebraic-geometry', 'differential-geometry', 'reference-request', 'soft-question', 'riemannian-geometry']"
25,Is the group of diffeomorphisms a Lie Group?,Is the group of diffeomorphisms a Lie Group?,,"consider a smooth manifold and the group of diffeomorphisms (or (local) isometries in case of riemannian manifolds) $\varphi:M \rightarrow M$. How can one define a smooth structure on this group, s.t. it becomes a Lie group? Regards","consider a smooth manifold and the group of diffeomorphisms (or (local) isometries in case of riemannian manifolds) $\varphi:M \rightarrow M$. How can one define a smooth structure on this group, s.t. it becomes a Lie group? Regards",,['differential-geometry']
26,Identification of integration on smooth chains with ordinary integration,Identification of integration on smooth chains with ordinary integration,,"Let $M$ be a smooth oriented $n$-dimensional manifold and denote by $A \in H_n(M;\mathbb{Z})$ the fundamental class of $M$ (a generator of singular homology consistent with the orientation of $M$). Consider the following two maps from the top de-Rham cohomology group $H^n_{\mathrm{dR}}(M)$ to $\mathbb{R}$: Regular integration of $n$-forms: $\omega \mapsto \int_M \omega$. This is defined using partition of unity and descends to cohomology by Stokes's theorem. Represent $A$ as a smooth chain $A = [\sum a_i \sigma_i]$ where $\sigma_i : \Delta^n \rightarrow M$ are smooth $n$-simplices and integrate $\omega$ by $$ \omega \mapsto \int_{\sum a_i \sigma_i} \omega := \sum a_i \int_{\Delta^n} \sigma_i^*(\omega). $$ This is well defined and independent of the representation of $A$ again by Stokes's theorem for chains. Both maps are $\mathbb{R}$-linear maps from a one dimensional real vector space to $\mathbb{R}$ and so are a real multiple of one another. Why are they equal? This should probably involve some careful tracing of definitions, identifications and dualities, but I can't put my finger on what is the crux of the matter.","Let $M$ be a smooth oriented $n$-dimensional manifold and denote by $A \in H_n(M;\mathbb{Z})$ the fundamental class of $M$ (a generator of singular homology consistent with the orientation of $M$). Consider the following two maps from the top de-Rham cohomology group $H^n_{\mathrm{dR}}(M)$ to $\mathbb{R}$: Regular integration of $n$-forms: $\omega \mapsto \int_M \omega$. This is defined using partition of unity and descends to cohomology by Stokes's theorem. Represent $A$ as a smooth chain $A = [\sum a_i \sigma_i]$ where $\sigma_i : \Delta^n \rightarrow M$ are smooth $n$-simplices and integrate $\omega$ by $$ \omega \mapsto \int_{\sum a_i \sigma_i} \omega := \sum a_i \int_{\Delta^n} \sigma_i^*(\omega). $$ This is well defined and independent of the representation of $A$ again by Stokes's theorem for chains. Both maps are $\mathbb{R}$-linear maps from a one dimensional real vector space to $\mathbb{R}$ and so are a real multiple of one another. Why are they equal? This should probably involve some careful tracing of definitions, identifications and dualities, but I can't put my finger on what is the crux of the matter.",,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
27,functoriality of derivations,functoriality of derivations,,"I seem to have problems understanding algebraically why given a map of manifolds $f: M \to N$ we get a bundle map $TM \to f^*TN$. Now, fiberwise it's all good. But I do not understand how to define on sections, as a map of sheaves of derivations. More to the point, say we have a map of rings $\varphi: B \leftarrow A$ (which I am thinking of opposite to $f$ above, in other words $A$ is global functions on $N$ and $B$ is global functions on $M$). And say that $\varphi$ is over a ground ring $k$ (everything in site is commutative!). Now, I do not see how to get a map $Der_k(B,B) \to Der_k(A,A) \otimes_A B$ (the latter being the pullback of $TN$ on $M$). While there is an obvious map $Der_k(B,B) \to Der_k(A,B)$, given by restriction, (which can be used to prove functoriality of the cotangent bundle) I do not see why we should have that $Der_k(A,A)\otimes_A B = Der_k(A,B)$ (although of course it needn't even hold). On the other hand one might define first the map on cotangent bundles and then declare this one as the transpose (but I'm trying to get grips with which one should be more ""natural"", in some very unfair sense). I guess my last comment is important to me when $M$ and $N$ at the beginning are taken to be singular varieties instead of manifolds.","I seem to have problems understanding algebraically why given a map of manifolds $f: M \to N$ we get a bundle map $TM \to f^*TN$. Now, fiberwise it's all good. But I do not understand how to define on sections, as a map of sheaves of derivations. More to the point, say we have a map of rings $\varphi: B \leftarrow A$ (which I am thinking of opposite to $f$ above, in other words $A$ is global functions on $N$ and $B$ is global functions on $M$). And say that $\varphi$ is over a ground ring $k$ (everything in site is commutative!). Now, I do not see how to get a map $Der_k(B,B) \to Der_k(A,A) \otimes_A B$ (the latter being the pullback of $TN$ on $M$). While there is an obvious map $Der_k(B,B) \to Der_k(A,B)$, given by restriction, (which can be used to prove functoriality of the cotangent bundle) I do not see why we should have that $Der_k(A,A)\otimes_A B = Der_k(A,B)$ (although of course it needn't even hold). On the other hand one might define first the map on cotangent bundles and then declare this one as the transpose (but I'm trying to get grips with which one should be more ""natural"", in some very unfair sense). I guess my last comment is important to me when $M$ and $N$ at the beginning are taken to be singular varieties instead of manifolds.",,"['algebraic-geometry', 'differential-geometry', 'commutative-algebra', 'sheaf-theory', 'differential-forms']"
28,Tangent bundle of $S^2$ not diffeomorphic to $S^2\times \mathbb{R}^2$ [duplicate],Tangent bundle of  not diffeomorphic to  [duplicate],S^2 S^2\times \mathbb{R}^2,"This question already has an answer here : Are $T\mathbb{S}^2$ and $\mathbb{S}^2 \times \mathbb{R}^2$ different? (1 answer) Closed 3 years ago . I am trying to show that the tangent bundle of $S^2$ not diffeomorphic to $S^2\times \mathbb{R}^2$. This is from an exam, where there is a hint stating that this is more than showing that $TS^2$ is non-trivial. I know how to show the hairy ball theorem, according to which $TS^n$ is non-trivial iff n is even. I also know that a vector bundle $\pi:E\rightarrow M$ of rank $m$ on a smooth manifold $M$ is trivial (by definition) iff there exists a diffeomorphism $f:E\rightarrow M\times \mathbb{R}^m$ such that for every $p\in M$, $f$ induces a vector space isomorphism $f:\pi^{-1}(p)\rightarrow \{p\}\times \mathbb{R}^m$. So I see that showing that $TS^2$ is non-trivial only guarantees that $TS^2$ is not diffeomorphic to $S^2\times \mathbb{R}^2$ via a diffeomorphism satisfying the property above, but it is not enough to conclude that there isn't any diffeomorphism. How can I show this then?","This question already has an answer here : Are $T\mathbb{S}^2$ and $\mathbb{S}^2 \times \mathbb{R}^2$ different? (1 answer) Closed 3 years ago . I am trying to show that the tangent bundle of $S^2$ not diffeomorphic to $S^2\times \mathbb{R}^2$. This is from an exam, where there is a hint stating that this is more than showing that $TS^2$ is non-trivial. I know how to show the hairy ball theorem, according to which $TS^n$ is non-trivial iff n is even. I also know that a vector bundle $\pi:E\rightarrow M$ of rank $m$ on a smooth manifold $M$ is trivial (by definition) iff there exists a diffeomorphism $f:E\rightarrow M\times \mathbb{R}^m$ such that for every $p\in M$, $f$ induces a vector space isomorphism $f:\pi^{-1}(p)\rightarrow \{p\}\times \mathbb{R}^m$. So I see that showing that $TS^2$ is non-trivial only guarantees that $TS^2$ is not diffeomorphic to $S^2\times \mathbb{R}^2$ via a diffeomorphism satisfying the property above, but it is not enough to conclude that there isn't any diffeomorphism. How can I show this then?",,['differential-geometry']
29,divergence of a vector field on a manifold,divergence of a vector field on a manifold,,"I've been asked to show the following: For a vector field $V$ on a semi-Riemannian manifold with metric $g$ that $$Div \cdot V = \frac{1}{\sqrt{\det(g)}}\partial_i\left(\sqrt{\det(g)}V^i\right)$$ I know we're supposed to use Christoffel symbols as well as a few matrix formulas, but I'm not sure how to proceed. In particular, we were given that for a (invertible) matrix $M$ with some parameter $s$, that $$\frac{d}{ds}\det M(s)=\det M(s) \cdot tr\left(M(s)^{-1}\frac{d}{ds}M(s)\right)$$ and $$\frac{d}{ds}(M(s)^{-1})=-M(s)^{-1}M'(s)M(s)^{-1}$$ Any help would be greatly appreciated. The definition of divergence that we were given was $$Div \cdot V = \nabla_{\partial_i}V^i = \partial_iV^i+\Gamma_{ij}^iV^i$$","I've been asked to show the following: For a vector field $V$ on a semi-Riemannian manifold with metric $g$ that $$Div \cdot V = \frac{1}{\sqrt{\det(g)}}\partial_i\left(\sqrt{\det(g)}V^i\right)$$ I know we're supposed to use Christoffel symbols as well as a few matrix formulas, but I'm not sure how to proceed. In particular, we were given that for a (invertible) matrix $M$ with some parameter $s$, that $$\frac{d}{ds}\det M(s)=\det M(s) \cdot tr\left(M(s)^{-1}\frac{d}{ds}M(s)\right)$$ and $$\frac{d}{ds}(M(s)^{-1})=-M(s)^{-1}M'(s)M(s)^{-1}$$ Any help would be greatly appreciated. The definition of divergence that we were given was $$Div \cdot V = \nabla_{\partial_i}V^i = \partial_iV^i+\Gamma_{ij}^iV^i$$",,['differential-geometry']
30,Good problem book in differential geometry,Good problem book in differential geometry,,"What are the books in Differential Geometry with a good collection of problems? At present I am having John M. Lee's Riemannian Manifolds , Kobayashi & Nomizu's Foundations of Differential  Geometry . I particularly like Dieudonne's books in Analysis as well as books like Alexander Kirillov's Functional Analysis . To be precise, the books that have a huge number of exercises. The books  I mentioned are definitely not of that category. Can anyone please suggest differential geometry books that gives a lot of exercises?","What are the books in Differential Geometry with a good collection of problems? At present I am having John M. Lee's Riemannian Manifolds , Kobayashi & Nomizu's Foundations of Differential  Geometry . I particularly like Dieudonne's books in Analysis as well as books like Alexander Kirillov's Functional Analysis . To be precise, the books that have a huge number of exercises. The books  I mentioned are definitely not of that category. Can anyone please suggest differential geometry books that gives a lot of exercises?",,"['reference-request', 'differential-geometry', 'riemannian-geometry', 'book-recommendation']"
31,Manifold has uncountable many smooth stuctures if it has one,Manifold has uncountable many smooth stuctures if it has one,,"This is the Problem 1-6 of John Lee's Introduction to smooth manifold: Let $M$ be a nonempty topological manifold of dimension $n\geq1$. If $M$ has a smooth structure, show that it has uncountably many distinct ones. [Hint: first show that for any $s>0$, $F_s(x)=|x|^{s-1}x$ defines a homeomorphism from $\mathbb{B}^n$ to itself, which is a diffeomorphism if and only if $s=1$.] What I tried: It can be proved there is a atlas $\mathcal{A}$ (not maximal) which is compact with the original smooth sturcture of $M$ and has the following property: $\forall(U,\psi)\in\mathcal{A}$, $\psi(U)=\mathbb{B}^n$. I tried to define $\psi'=F_s\circ\psi$ and hope $\{(U, \psi')\}$ to form a new atlas for $M$. But  $$\varphi'\circ(\psi')^{-1}=F_s\circ\varphi\circ\psi^{-1}\circ F_s^{-1}$$ may not be diffeomorphism. Any help, thanks.","This is the Problem 1-6 of John Lee's Introduction to smooth manifold: Let $M$ be a nonempty topological manifold of dimension $n\geq1$. If $M$ has a smooth structure, show that it has uncountably many distinct ones. [Hint: first show that for any $s>0$, $F_s(x)=|x|^{s-1}x$ defines a homeomorphism from $\mathbb{B}^n$ to itself, which is a diffeomorphism if and only if $s=1$.] What I tried: It can be proved there is a atlas $\mathcal{A}$ (not maximal) which is compact with the original smooth sturcture of $M$ and has the following property: $\forall(U,\psi)\in\mathcal{A}$, $\psi(U)=\mathbb{B}^n$. I tried to define $\psi'=F_s\circ\psi$ and hope $\{(U, \psi')\}$ to form a new atlas for $M$. But  $$\varphi'\circ(\psi')^{-1}=F_s\circ\varphi\circ\psi^{-1}\circ F_s^{-1}$$ may not be diffeomorphism. Any help, thanks.",,"['differential-geometry', 'manifolds', 'smooth-manifolds']"
32,No diffeomorphism that takes unit circle to unit square,No diffeomorphism that takes unit circle to unit square,,"This is not a homework problem. I am trying to learn my own from John M. Lee's Introduction to Smooth Manifolds . In Chapter 3, there is the problem 3-4 Let $C \subset \mathbb{R}^2$ be the unit circle, and let $S \subset \mathbb{R}^2$ be the boundary of the square of side 2 centred at origin: $S= \lbrace (x,y) \colon \max(|x|,|y|)=1 \rbrace.$ Show that there is a homeomorphism $F:\mathbb{R}^2 \to \mathbb{R}^2$ such that $F(C)=S$ , but there is no diffeomorphism with the same property. [Hint: Consider what $F$ does to the tangent vector to a suitable curve in $C$ ]. I can construct a homeomorphism (by placing the circle inside the square and then every radial line intersects the square at exactly one point). But, I don't know how to do the rest of the problem or understand the hint. I do not know how to write out what tangent space should be for the square. If there were a diffeomorphism then $F_\star$ is isomorphism between any two tangent space. If I show that the tangent space on the corner of square has dimension zero, would it solve problem?","This is not a homework problem. I am trying to learn my own from John M. Lee's Introduction to Smooth Manifolds . In Chapter 3, there is the problem 3-4 Let be the unit circle, and let be the boundary of the square of side 2 centred at origin: Show that there is a homeomorphism such that , but there is no diffeomorphism with the same property. [Hint: Consider what does to the tangent vector to a suitable curve in ]. I can construct a homeomorphism (by placing the circle inside the square and then every radial line intersects the square at exactly one point). But, I don't know how to do the rest of the problem or understand the hint. I do not know how to write out what tangent space should be for the square. If there were a diffeomorphism then is isomorphism between any two tangent space. If I show that the tangent space on the corner of square has dimension zero, would it solve problem?","C \subset \mathbb{R}^2 S \subset \mathbb{R}^2 S= \lbrace (x,y) \colon \max(|x|,|y|)=1 \rbrace. F:\mathbb{R}^2 \to \mathbb{R}^2 F(C)=S F C F_\star","['differential-geometry', 'diffeomorphism']"
33,What is the metric on the $n$-sphere in stereographic projection coordinates?,What is the metric on the -sphere in stereographic projection coordinates?,n,"The metric on the $n$-sphere is the metric induced from the ambient Euclidean metric. Find the metric, $d\Omega^2_n$, on the $n$-sphere and the volume form, $\Omega_{S_n}$ , of $S^n$ in terms of the stereographic coordinates on $U_N =S^n − (0, . . . , 0, 1)$. The stereographic projection coorinates $u_j$ are given by  $u_j=\frac{x_j}{1-x_{n+1}}$ for $j=1,\dots,n$. We also have $x_j=\frac{2u_j}{1+\sum_{k=1}^nu_k^2}$ and $x_{n+1}=\frac{1-\sum_{k=1}^nu_k^2}{1+\sum_{k=1}^nu_k^2}$ I took differentials and put them into the expression for the Euclidean metric put things are getting messy so I'm not sure if it's right. I also have to find the components of the Levi-Civitta connection, curvature tensor, Ricci tensor.","The metric on the $n$-sphere is the metric induced from the ambient Euclidean metric. Find the metric, $d\Omega^2_n$, on the $n$-sphere and the volume form, $\Omega_{S_n}$ , of $S^n$ in terms of the stereographic coordinates on $U_N =S^n − (0, . . . , 0, 1)$. The stereographic projection coorinates $u_j$ are given by  $u_j=\frac{x_j}{1-x_{n+1}}$ for $j=1,\dots,n$. We also have $x_j=\frac{2u_j}{1+\sum_{k=1}^nu_k^2}$ and $x_{n+1}=\frac{1-\sum_{k=1}^nu_k^2}{1+\sum_{k=1}^nu_k^2}$ I took differentials and put them into the expression for the Euclidean metric put things are getting messy so I'm not sure if it's right. I also have to find the components of the Levi-Civitta connection, curvature tensor, Ricci tensor.",,"['differential-geometry', 'spheres', 'stereographic-projections']"
34,What makes spinors mysterious?,What makes spinors mysterious?,,"Everyone familiar with spinors presumably knows the quote by Sir Michael Atiyah, that spinors are mysterious in spite of their algebra being formally understood. I have heard this sentiment echoed in other places, too. Being a novice to the subject, I am curious, what makes them so mysterious? It seems as though their definition is rather straightforward, that they are well behaved objects and that they complement the more intuitive notions from differential geometry. Where does the mystery kick in? Is it because there hasn't been some kind of big classification theorem yet? Of course, the concept of a spinor is far less intuitive than that of a vector. But there must be more to it than that. I would love some references to read about this further. Although there are plenty of texts to read about spinors, which I hope to do in due time, I am in particular looking for something that expands upon this ""mysterious"" nature.","Everyone familiar with spinors presumably knows the quote by Sir Michael Atiyah, that spinors are mysterious in spite of their algebra being formally understood. I have heard this sentiment echoed in other places, too. Being a novice to the subject, I am curious, what makes them so mysterious? It seems as though their definition is rather straightforward, that they are well behaved objects and that they complement the more intuitive notions from differential geometry. Where does the mystery kick in? Is it because there hasn't been some kind of big classification theorem yet? Of course, the concept of a spinor is far less intuitive than that of a vector. But there must be more to it than that. I would love some references to read about this further. Although there are plenty of texts to read about spinors, which I hope to do in due time, I am in particular looking for something that expands upon this ""mysterious"" nature.",,"['differential-geometry', 'reference-request', 'soft-question', 'spin-geometry']"
35,Smooth curves on a path connected smooth manifold,Smooth curves on a path connected smooth manifold,,"Suppose that $M$ is a path connected smooth manifold, so any two points $p,q\in M$ can be joined with a continuous curve on $M$. Is it true that any two points can  be joined  with a smooth (I mean $C^{\infty}$) curve on $M$?","Suppose that $M$ is a path connected smooth manifold, so any two points $p,q\in M$ can be joined with a continuous curve on $M$. Is it true that any two points can  be joined  with a smooth (I mean $C^{\infty}$) curve on $M$?",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds', 'path-connected']"
36,Definition of smooth manifold using sheaves.,Definition of smooth manifold using sheaves.,,"While defining differential manifolds using the concept of sheaves wikipedia gives the following definition. A differentiable manifold (of class $C_k$) consists of a pair $(M, \mathcal{O}_M)$ where $M$ is a topological space, and $\mathcal{O}_M$ is a sheaf of local $\mathbb{R}$-algebras defined on $M$, such that the locally ringed space $(M,\mathcal{O}_M)$ is locally isomorphic to $(\mathbb{R}^n, \mathcal{O})$. [$\mathcal{O}(U)=C^k(U,\mathbb{R})$ is the structure sheaf on $\mathbb{R}^n$.] In one of my courses I have been asked to verify whether the above definition is equivalent to the standard definition using atlases, but in that the condition of ""locally"" ringed spaces is missing, that is I am supposed to prove that $M$ is a smooth manifold if and only if there is a sheaf $\mathcal{O}_M$ of local $\mathbb{R}$-algebras defined on $M$, such that the ringed space $(M,\mathcal{O}_M)$ is locally isomorphic to $(\mathbb{R}^n, \mathcal{O})$ where $\mathcal{O}(U)=C^{\infty}(U,\mathbb{R})$ is the structure sheaf on $\mathbb{R}^n$. So I was wondering if the condition of every stalk being a local ring (locally ringed space) is necessary in the case of smooth manifolds.","While defining differential manifolds using the concept of sheaves wikipedia gives the following definition. A differentiable manifold (of class $C_k$) consists of a pair $(M, \mathcal{O}_M)$ where $M$ is a topological space, and $\mathcal{O}_M$ is a sheaf of local $\mathbb{R}$-algebras defined on $M$, such that the locally ringed space $(M,\mathcal{O}_M)$ is locally isomorphic to $(\mathbb{R}^n, \mathcal{O})$. [$\mathcal{O}(U)=C^k(U,\mathbb{R})$ is the structure sheaf on $\mathbb{R}^n$.] In one of my courses I have been asked to verify whether the above definition is equivalent to the standard definition using atlases, but in that the condition of ""locally"" ringed spaces is missing, that is I am supposed to prove that $M$ is a smooth manifold if and only if there is a sheaf $\mathcal{O}_M$ of local $\mathbb{R}$-algebras defined on $M$, such that the ringed space $(M,\mathcal{O}_M)$ is locally isomorphic to $(\mathbb{R}^n, \mathcal{O})$ where $\mathcal{O}(U)=C^{\infty}(U,\mathbb{R})$ is the structure sheaf on $\mathbb{R}^n$. So I was wondering if the condition of every stalk being a local ring (locally ringed space) is necessary in the case of smooth manifolds.",,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'sheaf-theory', 'ringed-spaces']"
37,Is the space of smooth sections of a vector bundle finitely generated as a $C^\infty$-module?,Is the space of smooth sections of a vector bundle finitely generated as a -module?,C^\infty,"Given a smooth finite-dimensional vector bundle $E\to M$ on a smooth manifold $M$, is the space of smooth global sections $\Gamma(E,M)$ always a finitely generated $C^\infty(M)$ module? This amounts to asking whether there exist finitely many smooth sections $s_1,...,s_m$ such that every $s\in \Gamma(E,M)$ can be written as $s=f_1 s_1+...+f_m s_m$ with smooth functions $f_1,...,f_m$.","Given a smooth finite-dimensional vector bundle $E\to M$ on a smooth manifold $M$, is the space of smooth global sections $\Gamma(E,M)$ always a finitely generated $C^\infty(M)$ module? This amounts to asking whether there exist finitely many smooth sections $s_1,...,s_m$ such that every $s\in \Gamma(E,M)$ can be written as $s=f_1 s_1+...+f_m s_m$ with smooth functions $f_1,...,f_m$.",,"['differential-geometry', 'vector-bundles']"
38,Top deRham cohomology group of a compact orientable manifold is 1-dimensional,Top deRham cohomology group of a compact orientable manifold is 1-dimensional,,"Let $M$ be a compact smooth orientable manifold of dimension $n$ . I am looking for a simple proof that $H_\mathrm{dR}^n(M) \cong \mathbb R$ . Equivalently, an $n$ -form which integrates to 0 is exact. I can show this via a rather indirect argument as follows: we know $H_\mathrm{dR}^n(M) \cong H^n(M, \mathbb R)$ , where $H^n$ denotes the singular cohomology. By the universal coefficient theorem (and the fact that $\mathbb R$ is a field) this is isomorphic to $\operatorname{Hom}(H_n(M, \mathbb Z) , \mathbb R)$ . From the (rather lengthy) proof in Section 3.3 of Hatcher's Algebraic Topology, we find that $H_n(M, \mathbb Z)$ is isomorphic to $\mathbb Z$ , and so $\operatorname{Hom}(H_n(M, \mathbb Z) , \mathbb R) \cong \mathbb R$ . However, it seems like there should be a simpler way to prove this. Does anyone know of one?","Let be a compact smooth orientable manifold of dimension . I am looking for a simple proof that . Equivalently, an -form which integrates to 0 is exact. I can show this via a rather indirect argument as follows: we know , where denotes the singular cohomology. By the universal coefficient theorem (and the fact that is a field) this is isomorphic to . From the (rather lengthy) proof in Section 3.3 of Hatcher's Algebraic Topology, we find that is isomorphic to , and so . However, it seems like there should be a simpler way to prove this. Does anyone know of one?","M n H_\mathrm{dR}^n(M) \cong \mathbb R n H_\mathrm{dR}^n(M) \cong H^n(M, \mathbb R) H^n \mathbb R \operatorname{Hom}(H_n(M, \mathbb Z) , \mathbb R) H_n(M, \mathbb Z) \mathbb Z \operatorname{Hom}(H_n(M, \mathbb Z) , \mathbb R) \cong \mathbb R","['differential-geometry', 'algebraic-topology', 'differential-forms', 'de-rham-cohomology']"
39,"Diffeomorphic, group-isomorphic Lie groups that are not isomorphic as Lie groups","Diffeomorphic, group-isomorphic Lie groups that are not isomorphic as Lie groups",,"Do there exist two Lie groups which are diffeomorphic as smooth manifolds, have isomorphic group structures, yet are not isomorphic as Lie groups? Of course, for this to happen, any diffeomorphism would fail to preserve the group structure, and any group isomorphism would either fail to be smooth, or its inverse would fail to be smooth. I have no other reason for asking this other than out of curiosity.  (In particular, this is not a problem I found out of a textbook.) Related Question: Are there topological groups that are homeomorphic and have isomorphic group structures, yet are not isomorphic as topological groups?","Do there exist two Lie groups which are diffeomorphic as smooth manifolds, have isomorphic group structures, yet are not isomorphic as Lie groups? Of course, for this to happen, any diffeomorphism would fail to preserve the group structure, and any group isomorphism would either fail to be smooth, or its inverse would fail to be smooth. I have no other reason for asking this other than out of curiosity.  (In particular, this is not a problem I found out of a textbook.) Related Question: Are there topological groups that are homeomorphic and have isomorphic group structures, yet are not isomorphic as topological groups?",,"['differential-geometry', 'differential-topology', 'lie-groups']"
40,Are $C^{k}$ manifolds the same as $C^{\infty}$ manifolds?,Are  manifolds the same as  manifolds?,C^{k} C^{\infty},"This is a theorem of Hassler Whitney: For $0<k<\infty$ and any $n$-dimensional $C^k$ manifold the maximal   atlas contains a $C^\infty$ atlas on the same underlying set. It seems to me that this theorem says every $C^{k}$ manifold can be thought of as if it were a $C^{\infty}$ manifold proceeding like this: Start with a given a $C^{k}$ atlas $\mathcal{A}$ on a topological manifold $M$ Consider the maximal $C^{k}$ atlas $\overline{\mathcal{A}}$ containing $\mathcal{A}$ (i.e. the atlas containing every $C^{k}$ chart on $M$ compatible with $\mathcal{A}$) Extract a $C^{\infty}$ subatlas $\mathcal{A}_{\infty}$ of $\overline{\mathcal{A}}$ (it can be done because of Whitney's theorem) Now make $M$ a $C^{\infty}$ manifold  considering the atlas $\mathcal{A}_{\infty}$ After this maneuver we ended up with two differentiable structures over the same underlying topological manifold $M$: one of $C^{k}$ type given by $\mathcal{A}$ and the other of $C^{\infty}$ type given by $\mathcal{A}_{\infty}$. My questions are: Up to what extent are this two differentiable manifolds, $(M,\mathcal{A})$ and $(M,\mathcal{A}_{\infty})$, the same? Is it true that the maximal atlas $\overline{\mathcal{A}_{\infty}}$ generated by $\mathcal{A}_{\infty}$ is the same as $\overline{\mathcal{A}}$ with all the non $C^{\infty}$ charts removed? Are there examples of $C^{k}$ manifolds for which exists a $C^{k}$ atlas such that none of its charts is $C^{r}$ for some $r>k$? When studying functions defined on a $C^{k}$ manifold $M$ we can consider differentials up to order $k$, with this limit $k$ imposed by the $C^{k}$ differentiable structure. Is the theorem of Whitney telling us that this restriction is artificial since we can get a $C^{\infty}$ atlas for $M$? Thanks.","This is a theorem of Hassler Whitney: For $0<k<\infty$ and any $n$-dimensional $C^k$ manifold the maximal   atlas contains a $C^\infty$ atlas on the same underlying set. It seems to me that this theorem says every $C^{k}$ manifold can be thought of as if it were a $C^{\infty}$ manifold proceeding like this: Start with a given a $C^{k}$ atlas $\mathcal{A}$ on a topological manifold $M$ Consider the maximal $C^{k}$ atlas $\overline{\mathcal{A}}$ containing $\mathcal{A}$ (i.e. the atlas containing every $C^{k}$ chart on $M$ compatible with $\mathcal{A}$) Extract a $C^{\infty}$ subatlas $\mathcal{A}_{\infty}$ of $\overline{\mathcal{A}}$ (it can be done because of Whitney's theorem) Now make $M$ a $C^{\infty}$ manifold  considering the atlas $\mathcal{A}_{\infty}$ After this maneuver we ended up with two differentiable structures over the same underlying topological manifold $M$: one of $C^{k}$ type given by $\mathcal{A}$ and the other of $C^{\infty}$ type given by $\mathcal{A}_{\infty}$. My questions are: Up to what extent are this two differentiable manifolds, $(M,\mathcal{A})$ and $(M,\mathcal{A}_{\infty})$, the same? Is it true that the maximal atlas $\overline{\mathcal{A}_{\infty}}$ generated by $\mathcal{A}_{\infty}$ is the same as $\overline{\mathcal{A}}$ with all the non $C^{\infty}$ charts removed? Are there examples of $C^{k}$ manifolds for which exists a $C^{k}$ atlas such that none of its charts is $C^{r}$ for some $r>k$? When studying functions defined on a $C^{k}$ manifold $M$ we can consider differentials up to order $k$, with this limit $k$ imposed by the $C^{k}$ differentiable structure. Is the theorem of Whitney telling us that this restriction is artificial since we can get a $C^{\infty}$ atlas for $M$? Thanks.",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
41,Reconstructing a manifold from critical points,Reconstructing a manifold from critical points,,"I am teaching theoretical calculus this semester, and on the last discussion section we were discussing critical points of functions. I explained the idea of Morse theory, and a student of mine asked me a question that I couldn't answer. I don't know a lot about the Morse theory, so the question might actually be easy. I would really appreciate if you can help me, or at least give me a reference. Suppose you are given an ordered set of signatures (i.e. number of $+$ and $-$ of the hessian) $\{(a_1,b_1),\dots,(a_r,b_r)\}$, that is supposed to be a set of critical points of some Morse function on a would be a $k$-manifold. The question is the following: When there exists a manifold with a Morse function having a given set of signatures of critical points? It is easy to see that the set of signatures must have signatures of the form $(k,0)$ and $(0,k)$, since any function on a compact manifold must have minimum and maximum. Also, we can't start with, say, $(k-1,1)$, since you must start with the point of minimum, which must be of signature $(k,0)$. Also, it is not true that we can always construct a manifold with given ordered set of signatures. For example, take the set $\{ (2,0) , (1,1), (0,2) \}$. Following the algorithm, first we attach a 0-cell, then we attach a 1-cell. Topologically it will be equivalent to a letter U made out of a tube (cylinder). But then you need two ""caps"" to make it into a closed compact thing, but we have only one critical point left. I have no idea what are the conditions when we can actually construct a required manifold. I've heard (but I am not sure if it is true) that if we have passed a sertain number of critical points in out reconstructing algorithm (maybe more than $r/2+1$), then there is unique way to finish the procedure to get a closed compact manifold. If this is correct, is it still true that we can always get a manifold having any set of the first $r/2+1$ signatures? Thank you very much!","I am teaching theoretical calculus this semester, and on the last discussion section we were discussing critical points of functions. I explained the idea of Morse theory, and a student of mine asked me a question that I couldn't answer. I don't know a lot about the Morse theory, so the question might actually be easy. I would really appreciate if you can help me, or at least give me a reference. Suppose you are given an ordered set of signatures (i.e. number of $+$ and $-$ of the hessian) $\{(a_1,b_1),\dots,(a_r,b_r)\}$, that is supposed to be a set of critical points of some Morse function on a would be a $k$-manifold. The question is the following: When there exists a manifold with a Morse function having a given set of signatures of critical points? It is easy to see that the set of signatures must have signatures of the form $(k,0)$ and $(0,k)$, since any function on a compact manifold must have minimum and maximum. Also, we can't start with, say, $(k-1,1)$, since you must start with the point of minimum, which must be of signature $(k,0)$. Also, it is not true that we can always construct a manifold with given ordered set of signatures. For example, take the set $\{ (2,0) , (1,1), (0,2) \}$. Following the algorithm, first we attach a 0-cell, then we attach a 1-cell. Topologically it will be equivalent to a letter U made out of a tube (cylinder). But then you need two ""caps"" to make it into a closed compact thing, but we have only one critical point left. I have no idea what are the conditions when we can actually construct a required manifold. I've heard (but I am not sure if it is true) that if we have passed a sertain number of critical points in out reconstructing algorithm (maybe more than $r/2+1$), then there is unique way to finish the procedure to get a closed compact manifold. If this is correct, is it still true that we can always get a manifold having any set of the first $r/2+1$ signatures? Thank you very much!",,"['reference-request', 'differential-geometry', 'manifolds', 'differential-topology', 'morse-theory']"
42,Geometric interpretation of the map $SO(4) \to SO(3)$,Geometric interpretation of the map,SO(4) \to SO(3),"Let me first explain the background of my question. As is well known, the group $SO(n+1)$ acts transitively on the sphere $S^n$, and the stabilizer is the group $SO(n)$, so that we get a fibration sequence $$ SO(n) \to SO(n+1) \to S^n.$$ Indeed this fibration is a principal-$SO(n)$-bundle and can actually be identified with the frame bundle of the tangent bundle of $S^n$, i.e., the tangent bundle $TS^n$ is the associated bundle to this principal-$SO(n)$-bundle along the tautological representation of $SO(n)$ on $\mathbb{R}^n$. Now let us consider the special case $n = 4$. Here we get a principal-$SO(3)$-bundle $$ SO(3) \to SO(4) \to S^3.$$ But we can identify the $S^3$ with $Sp(1)$, the symplectic group acting on the quaternions. Via this identification $S^3$ sits canonically in $SO(4)$, i.e. we have an embedding of topological groups $S^3 \cong Sp(1) \to SO(4)$. The standard theory of principal-bundles hence tells us that the above bundle splits (topologically) which means that there is a homeomorphism $$ SO(4) \cong SO(3)\times S^3 $$ in particular there is a continuous map $SO(4) \to SO(3)$ (which is not a morphism of lie groups). It is well known that the homotopy type $BSO(n)$ represents the functor of $n$-dimensional oriented vector bundles, and via the clutching function construction the group $SO(n)$ itself represents the functor of $n$-dimensional vector bundles over suspensions of spaces. Hence the above map $SO(4) \to SO(3)$ tells us that there is a natural transformation between the functor of rank $4$ vector bundles over suspensions to the functor of rank $3$ vector bundles over suspensions. Does anybody know a geometric construction of this transformation which I only understand homotopy theoretically? Any ideas or references are greatly appreciated.","Let me first explain the background of my question. As is well known, the group $SO(n+1)$ acts transitively on the sphere $S^n$, and the stabilizer is the group $SO(n)$, so that we get a fibration sequence $$ SO(n) \to SO(n+1) \to S^n.$$ Indeed this fibration is a principal-$SO(n)$-bundle and can actually be identified with the frame bundle of the tangent bundle of $S^n$, i.e., the tangent bundle $TS^n$ is the associated bundle to this principal-$SO(n)$-bundle along the tautological representation of $SO(n)$ on $\mathbb{R}^n$. Now let us consider the special case $n = 4$. Here we get a principal-$SO(3)$-bundle $$ SO(3) \to SO(4) \to S^3.$$ But we can identify the $S^3$ with $Sp(1)$, the symplectic group acting on the quaternions. Via this identification $S^3$ sits canonically in $SO(4)$, i.e. we have an embedding of topological groups $S^3 \cong Sp(1) \to SO(4)$. The standard theory of principal-bundles hence tells us that the above bundle splits (topologically) which means that there is a homeomorphism $$ SO(4) \cong SO(3)\times S^3 $$ in particular there is a continuous map $SO(4) \to SO(3)$ (which is not a morphism of lie groups). It is well known that the homotopy type $BSO(n)$ represents the functor of $n$-dimensional oriented vector bundles, and via the clutching function construction the group $SO(n)$ itself represents the functor of $n$-dimensional vector bundles over suspensions of spaces. Hence the above map $SO(4) \to SO(3)$ tells us that there is a natural transformation between the functor of rank $4$ vector bundles over suspensions to the functor of rank $3$ vector bundles over suspensions. Does anybody know a geometric construction of this transformation which I only understand homotopy theoretically? Any ideas or references are greatly appreciated.",,"['differential-geometry', 'algebraic-topology', 'lie-groups', 'homotopy-theory']"
43,Torsion of a connection as an obstruction to integrability,Torsion of a connection as an obstruction to integrability,,"Let $E$ be a vector bundle over a smooth manifold $M$ equipped with a linear connection $\nabla : \Gamma(E) \to \Omega^1(M;E).$  I say $(M,E,\nabla)$ is flat if it admits trivial local models; i.e. if for each $p \in M$ there is a $\nabla$-parallel local frame for $E$ defined on some neighbourhood of $p$. It is well known (and often instead taken as the definition) that $(M,E,\nabla)$ is flat if and only if the curvature form $R^\nabla \in  \Omega^2(M; E)$ vanishes; so the curvature can be motivated as an obstruction to flatness. When $E = TM$ so that $\nabla$ is an affine connection, a more restrictive definition is often used: we say $(M,\nabla)$ is flat if each $p \in M$ is contained in a chart whose coordinate frame is $\nabla$-parallel. This imposes an additional requirement on the local model: not only must we be able to choose a frame making $\nabla$ trivial, but this frame must be holonomic. Again, a nice characterization of this kind of flatness is well-known: it's equivalent to both the curvature $R^\nabla$ and the torsion $T^\nabla$ vanishing. Thus in the world of affine connections that are flat in the weaker sense ($R^\nabla = 0$), torsion has a very simple motivation: it is exactly the obstruction to the existence of trivial local models, by which I mean charts $x^i$ such that $\nabla \partial_i=0.$ One way to think about this is that torsion is an obstruction to the integrability of frames: thanks to $R^\nabla = 0$ we can find a parallel frame $e_i$, and $T^\nabla = 0$ (implying $[e_i,e_j] = 0$) is then exactly the condition guaranteeing that $e_i = \partial_i$ for some chart. Question. Without the assumption that $R^\nabla = 0$, can we motivate torsion as the obstruction to some kind of integrability? This is motivated in part by this nice answer on MO , which describes torsion as an obstruction to the integrability of various $G$-structures; but I don't see how this interpretation can apply in the case of a connection alone. One vague notion bouncing around in my head is some kind of Poincaré lemma for the solder form $\mathrm{id} \in \Omega^1(M;TM)$: we know $d^\nabla \mathrm{id}$ is the torsion, so perhaps vanishing torsion implies the solder form is locally the covariant derivative of some vector field? I'm not sure if this is actually true (I've only seen covariant exterior calculus treated for flat connections, since this is where you get a de Rham complex), nor how best to interpret it if it is. Cross-posted on MO .","Let $E$ be a vector bundle over a smooth manifold $M$ equipped with a linear connection $\nabla : \Gamma(E) \to \Omega^1(M;E).$  I say $(M,E,\nabla)$ is flat if it admits trivial local models; i.e. if for each $p \in M$ there is a $\nabla$-parallel local frame for $E$ defined on some neighbourhood of $p$. It is well known (and often instead taken as the definition) that $(M,E,\nabla)$ is flat if and only if the curvature form $R^\nabla \in  \Omega^2(M; E)$ vanishes; so the curvature can be motivated as an obstruction to flatness. When $E = TM$ so that $\nabla$ is an affine connection, a more restrictive definition is often used: we say $(M,\nabla)$ is flat if each $p \in M$ is contained in a chart whose coordinate frame is $\nabla$-parallel. This imposes an additional requirement on the local model: not only must we be able to choose a frame making $\nabla$ trivial, but this frame must be holonomic. Again, a nice characterization of this kind of flatness is well-known: it's equivalent to both the curvature $R^\nabla$ and the torsion $T^\nabla$ vanishing. Thus in the world of affine connections that are flat in the weaker sense ($R^\nabla = 0$), torsion has a very simple motivation: it is exactly the obstruction to the existence of trivial local models, by which I mean charts $x^i$ such that $\nabla \partial_i=0.$ One way to think about this is that torsion is an obstruction to the integrability of frames: thanks to $R^\nabla = 0$ we can find a parallel frame $e_i$, and $T^\nabla = 0$ (implying $[e_i,e_j] = 0$) is then exactly the condition guaranteeing that $e_i = \partial_i$ for some chart. Question. Without the assumption that $R^\nabla = 0$, can we motivate torsion as the obstruction to some kind of integrability? This is motivated in part by this nice answer on MO , which describes torsion as an obstruction to the integrability of various $G$-structures; but I don't see how this interpretation can apply in the case of a connection alone. One vague notion bouncing around in my head is some kind of Poincaré lemma for the solder form $\mathrm{id} \in \Omega^1(M;TM)$: we know $d^\nabla \mathrm{id}$ is the torsion, so perhaps vanishing torsion implies the solder form is locally the covariant derivative of some vector field? I'm not sure if this is actually true (I've only seen covariant exterior calculus treated for flat connections, since this is where you get a de Rham complex), nor how best to interpret it if it is. Cross-posted on MO .",,"['differential-geometry', 'connections']"
44,Relationship between Stokes's theorem and the Gauss-Bonnet theorem,Relationship between Stokes's theorem and the Gauss-Bonnet theorem,,"Stokes's theorem and the Gauss-Bonnet theorem are clearly very spiritually similar: they both relate the integral of a quantity $A$ over a region to the integral of some quantity $B$ over the boundary of the region, where $A$ can in some sense be thought of as a ""curvature at one higher derivative"" of $B$ or a closely related quantity.  Is either of these theorems a special case of the other?  If not, is there a more general theorem of which they are both special cases (which isn't too many levels higher up in abstraction)? Edit : the answers to this follow-up question provide derivations of the Gauss-Bonnet theorem from Stokes's theorem in this paper , on pg. 105 of this textbook , and in Chapter 6 Section 1 of this textbook . Unfortunately, the derivations are too advanced for me to understand, as I haven't formally studied graduate-level differential geometry. I would appreciate any answer that summarizes the basic idea of the derivation.","Stokes's theorem and the Gauss-Bonnet theorem are clearly very spiritually similar: they both relate the integral of a quantity over a region to the integral of some quantity over the boundary of the region, where can in some sense be thought of as a ""curvature at one higher derivative"" of or a closely related quantity.  Is either of these theorems a special case of the other?  If not, is there a more general theorem of which they are both special cases (which isn't too many levels higher up in abstraction)? Edit : the answers to this follow-up question provide derivations of the Gauss-Bonnet theorem from Stokes's theorem in this paper , on pg. 105 of this textbook , and in Chapter 6 Section 1 of this textbook . Unfortunately, the derivations are too advanced for me to understand, as I haven't formally studied graduate-level differential geometry. I would appreciate any answer that summarizes the basic idea of the derivation.",A B A B,"['differential-geometry', 'algebraic-topology', 'stokes-theorem']"
45,Why isn't differential Galois theory widely used?,Why isn't differential Galois theory widely used?,,"Ellis Kolchin developed differential Galois theory in the 1950s. It seems to be a powerful tool that can decide the solvability and the form of the solutions to a given differential equation. Why isn't differential Galois theory widely used in differential geometry? It is plausible that we can solve some problems of differential/integral geometry using this theory. So, what is the major pullback in this theory that prevents its wide application to other fields rather than discrete geometry (e.g., Diophantine geometry)?","Ellis Kolchin developed differential Galois theory in the 1950s. It seems to be a powerful tool that can decide the solvability and the form of the solutions to a given differential equation. Why isn't differential Galois theory widely used in differential geometry? It is plausible that we can solve some problems of differential/integral geometry using this theory. So, what is the major pullback in this theory that prevents its wide application to other fields rather than discrete geometry (e.g., Diophantine geometry)?",,"['differential-geometry', 'soft-question', 'galois-theory', 'differential-algebra', 'integral-geometry']"
46,"Building Intuition for Differential forms, exterior derivative, wedge [duplicate]","Building Intuition for Differential forms, exterior derivative, wedge [duplicate]",,"This question already has answers here : What's the geometrical intuition behind differential forms? (2 answers) Closed 2 years ago . I think I understood 1-forms fairly well with the help of these two sources. They are dual to vectors, so they measure them which can be visualized with planes the vectors pierce. Gravitation 1973 On the Visualisation of Differential Forms - Dan Piponi But I struggle with the explanations for higher order forms. The goal is to answer and understand these questions with drawings: How can I visualize the wedge between two 1-forms $\alpha\wedge\beta$ ? I think I understood the wedge between two vectors, as the parallelogram created by the two in a ""area sense"". The determinant comes in to make it only about the area which is why $v\wedge w = \frac{1}{2}v\wedge 2w$ since stretching the parallelogram by two in the w direction is compensated by squishing it in the v direction, so the area stays constant. So the wedge between two vectors is the area it spans with its vectors. But how does that translate to the dual space? Where 1-forms measure the length of the component of its dual vector. And can be visualized as planes the vectors pierce through. What is the visualization between two of these 1-forms as a wedge? Gravitation has this picture: Dan-Piponi drew it like this: Now these pictures make some sense as they are generated by intersecting the 1-forms. But I am not quite getting how the result is evaluated. The result (2-form) should map two vectors as input to a number. And I don't see how these intersections do that. While for 1-forms you count the numbers of planes a vector pierced. Why does it make sense that $d(d\alpha)=0$ for every differential form $\alpha$ What does Dan Piponi mean by saying: ""exterior derivative is none other than finding the boundary of the picture"" (4 Exterior Derivatives) Understand part 5 about Stokes' theorem from Dan Piponi's paper Note: I should maybe add that I have no background in physics, so I didn't understand a lot of the stuff in Gravitation. I just tried to read it after I couldn't quite understand other source since it was cited there. Similar questions: What's the geometrical intuition behind differential forms? Edit (since someone voted ""close"", based on this question as a duplicate): This question indicates not grasping how 1-forms work (""families of surfaces [...] Why do this interpretation makes any sense?"") not only does that invite explanations for 1-forms and hand-waving away the rest with ""it works similarly in higher dimensions"" but it in particular does not mention specific visualizations for 2-forms which kind of show that there should be an intuition for 2-forms (and maybe higher). And while this question accepted an answer already, this answer does not help to answer the (enumerated) questions above. So this is absolutely not a duplicate. Geometric understanding of differential forms. Visualizing Exterior Derivative","This question already has answers here : What's the geometrical intuition behind differential forms? (2 answers) Closed 2 years ago . I think I understood 1-forms fairly well with the help of these two sources. They are dual to vectors, so they measure them which can be visualized with planes the vectors pierce. Gravitation 1973 On the Visualisation of Differential Forms - Dan Piponi But I struggle with the explanations for higher order forms. The goal is to answer and understand these questions with drawings: How can I visualize the wedge between two 1-forms ? I think I understood the wedge between two vectors, as the parallelogram created by the two in a ""area sense"". The determinant comes in to make it only about the area which is why since stretching the parallelogram by two in the w direction is compensated by squishing it in the v direction, so the area stays constant. So the wedge between two vectors is the area it spans with its vectors. But how does that translate to the dual space? Where 1-forms measure the length of the component of its dual vector. And can be visualized as planes the vectors pierce through. What is the visualization between two of these 1-forms as a wedge? Gravitation has this picture: Dan-Piponi drew it like this: Now these pictures make some sense as they are generated by intersecting the 1-forms. But I am not quite getting how the result is evaluated. The result (2-form) should map two vectors as input to a number. And I don't see how these intersections do that. While for 1-forms you count the numbers of planes a vector pierced. Why does it make sense that for every differential form What does Dan Piponi mean by saying: ""exterior derivative is none other than finding the boundary of the picture"" (4 Exterior Derivatives) Understand part 5 about Stokes' theorem from Dan Piponi's paper Note: I should maybe add that I have no background in physics, so I didn't understand a lot of the stuff in Gravitation. I just tried to read it after I couldn't quite understand other source since it was cited there. Similar questions: What's the geometrical intuition behind differential forms? Edit (since someone voted ""close"", based on this question as a duplicate): This question indicates not grasping how 1-forms work (""families of surfaces [...] Why do this interpretation makes any sense?"") not only does that invite explanations for 1-forms and hand-waving away the rest with ""it works similarly in higher dimensions"" but it in particular does not mention specific visualizations for 2-forms which kind of show that there should be an intuition for 2-forms (and maybe higher). And while this question accepted an answer already, this answer does not help to answer the (enumerated) questions above. So this is absolutely not a duplicate. Geometric understanding of differential forms. Visualizing Exterior Derivative",\alpha\wedge\beta v\wedge w = \frac{1}{2}v\wedge 2w d(d\alpha)=0 \alpha,"['differential-geometry', 'soft-question', 'intuition', 'differential-forms', 'exterior-derivative']"
47,Determinant of non-square Jacobian,Determinant of non-square Jacobian,,"Suppose I have a 3d solid in ${\bf R}^4$ which can be parametrized by the function $F:W\subset{\bf R}^3\rightarrow{\bf R}^4$.  Now suppose I want to calculate the volume of this solid.  Then naively I would compute the Jacobian of this map and then compute the following integral $$\int_VdV=\int_W|\det{\bf J}_F(x,y,z)|dxdydz$$ But of course I can't do this since the Jacobian is not square.  My understanding is that the way to do this is to actually compute $\sqrt{\det{\bf J}_F^{\mathrm{T}}{\bf J}_F}$.  This of course reduces to $|\det{\bf J}_F|$ when the Jacobian is square, and also agrees with the definition of arc length found here , and the definition of surface integral found here . And when I tested it for a parametrization ${\bf R}^2\rightarrow{\bf R}^3$ it was equivalent to taking the 2-norm of the vector containing the three square sub-determinants of its associated $3\times 2$ Jacobian.  Furthermore it agrees with the way the Riemannian metric changes when you perform the pull-back, since the length of a tangent vector under the pull-back is given by $$\sqrt{\langle{\bf J}v, {\bf J}v\rangle}=\sqrt{v^{\mathrm{T}}{\bf J}^{\mathrm{T}}{\bf J}v}$$ Is all of this correct?  Am I missing something?  It was maddening to figure this out on my own as it's literally proposed no where in the introductory literature on vector calculus and differential geometry. I don't know much about differential topology, but I believe this is somehow all connected with the way differential forms operate, and I would conjecture that for a Jacobian, say $m\times n$ with $m\geq n$, we have that $\sqrt{\det{\bf J}^{\mathrm{T}}{\bf J}}$ is equal to the Euclidean norm of the $\binom{m}{n}$ square sub-determinants of $\bf J$.","Suppose I have a 3d solid in ${\bf R}^4$ which can be parametrized by the function $F:W\subset{\bf R}^3\rightarrow{\bf R}^4$.  Now suppose I want to calculate the volume of this solid.  Then naively I would compute the Jacobian of this map and then compute the following integral $$\int_VdV=\int_W|\det{\bf J}_F(x,y,z)|dxdydz$$ But of course I can't do this since the Jacobian is not square.  My understanding is that the way to do this is to actually compute $\sqrt{\det{\bf J}_F^{\mathrm{T}}{\bf J}_F}$.  This of course reduces to $|\det{\bf J}_F|$ when the Jacobian is square, and also agrees with the definition of arc length found here , and the definition of surface integral found here . And when I tested it for a parametrization ${\bf R}^2\rightarrow{\bf R}^3$ it was equivalent to taking the 2-norm of the vector containing the three square sub-determinants of its associated $3\times 2$ Jacobian.  Furthermore it agrees with the way the Riemannian metric changes when you perform the pull-back, since the length of a tangent vector under the pull-back is given by $$\sqrt{\langle{\bf J}v, {\bf J}v\rangle}=\sqrt{v^{\mathrm{T}}{\bf J}^{\mathrm{T}}{\bf J}v}$$ Is all of this correct?  Am I missing something?  It was maddening to figure this out on my own as it's literally proposed no where in the introductory literature on vector calculus and differential geometry. I don't know much about differential topology, but I believe this is somehow all connected with the way differential forms operate, and I would conjecture that for a Jacobian, say $m\times n$ with $m\geq n$, we have that $\sqrt{\det{\bf J}^{\mathrm{T}}{\bf J}}$ is equal to the Euclidean norm of the $\binom{m}{n}$ square sub-determinants of $\bf J$.",,"['differential-geometry', 'determinant', 'vector-analysis']"
48,"If a topological space is homeomorphic to a smooth manifold, then will it be a smooth manifold?","If a topological space is homeomorphic to a smooth manifold, then will it be a smooth manifold?",,If I have already known a topological space $N$ is homeomorphic to a smooth manifold $M$ then will it be a smooth manifold? The atlas of $N$ is the preimage of the atlas of $M$ and the coordinate map is the composition of homeomorphism composites the coordinate map?,If I have already known a topological space $N$ is homeomorphic to a smooth manifold $M$ then will it be a smooth manifold? The atlas of $N$ is the preimage of the atlas of $M$ and the coordinate map is the composition of homeomorphism composites the coordinate map?,,"['differential-geometry', 'differential-topology']"
49,Motivation behind the definition of tangent vectors,Motivation behind the definition of tangent vectors,,"I've been reading the book Gauge, Fields, Knots and Gravity by Baez. A tangent vector at $p \in M$ is defined as function $V$ from $C^{\infty}(M) $ to $\mathbb R$ satisfying the following properties: $V(f+g)=V(f) + V(g)$. $V(\alpha f)= \alpha V(F)$. $V(fg) = V(f)g(p) + V(g)f(p)$. Can someone explain me what is the physical interpretation of tangent vectors and the above definition?","I've been reading the book Gauge, Fields, Knots and Gravity by Baez. A tangent vector at $p \in M$ is defined as function $V$ from $C^{\infty}(M) $ to $\mathbb R$ satisfying the following properties: $V(f+g)=V(f) + V(g)$. $V(\alpha f)= \alpha V(F)$. $V(fg) = V(f)g(p) + V(g)f(p)$. Can someone explain me what is the physical interpretation of tangent vectors and the above definition?",,"['differential-geometry', 'motivation']"
50,How can we find geodesics on a one sheet hyperboloid?,How can we find geodesics on a one sheet hyperboloid?,,"I am looking at the following exercise: Describe four different geodesics on the hyperboloid of one sheet $$x^2+y^2-z^2=1$$ passing through the point $(1, 0, 0)$. $$$$ We have that a curve $\gamma$ on a surface $S$ is called a geodesic if $\ddot\gamma(t)$ is zero or perpendicular to the tangent plane of the surface at the point $\gamma (t)$, i.e., parallel to its unit normal, for all values of the parameter $t$. Equivalently, $\gamma$ is a geodesic if and only if its tangent vector $\dot\gamma$ is parallel along $\gamma$. $$$$ Could you give me some hints how we can find in this case the geodesics?","I am looking at the following exercise: Describe four different geodesics on the hyperboloid of one sheet $$x^2+y^2-z^2=1$$ passing through the point $(1, 0, 0)$. $$$$ We have that a curve $\gamma$ on a surface $S$ is called a geodesic if $\ddot\gamma(t)$ is zero or perpendicular to the tangent plane of the surface at the point $\gamma (t)$, i.e., parallel to its unit normal, for all values of the parameter $t$. Equivalently, $\gamma$ is a geodesic if and only if its tangent vector $\dot\gamma$ is parallel along $\gamma$. $$$$ Could you give me some hints how we can find in this case the geodesics?",,"['differential-geometry', 'surfaces', 'geodesic']"
51,"Since the Curvature tensor depends on a connection (not metric), is it the relevant quantity to characterize the curvature of Riemannian manifolds?","Since the Curvature tensor depends on a connection (not metric), is it the relevant quantity to characterize the curvature of Riemannian manifolds?",,"The definition of the Riemann curvature tensor does not include a metric. So, if we have a smooth manifold(not a Riemannian manifold), we can define the Riemannian curvature tensor for it by just giving it a connection (not the Levi-Civita connection). No metric is needed. Now, if we also assign a metric to the smooth manifold, we can take traces of the Riemann curvature tensor and get the Ricci scalar. Does this imply that, for a Riemannian manifold (not just smooth), the relevant quantity that measures the curvature is the Ricci scalar and not the full Riemannian curvature tensor? Because to define the Riemann curvature tensor we need a connection (not a metric) and to define the Ricci scalar we also need a metric. Lastly, since the Riemann curvature tensor depends on the connection and not the metric and the connection gives the way to parallel transport vectors, does it mean that parallel transporting the same vector along the same closed curve on two different Riemannian manifolds that correspond to the same smooth manifold (but we assign the same connection but different metric to each one), we will get the same angle of rotation for that vector at the end-point (which is also the starting-point) of the curve? Note: When talking about a connection, I do not mean the Levi-Civita connection which comes from a metric. The question is about the difference in the role that the connection and metric play (independently) in the Riemann curvature tensor.","The definition of the Riemann curvature tensor does not include a metric. So, if we have a smooth manifold(not a Riemannian manifold), we can define the Riemannian curvature tensor for it by just giving it a connection (not the Levi-Civita connection). No metric is needed. Now, if we also assign a metric to the smooth manifold, we can take traces of the Riemann curvature tensor and get the Ricci scalar. Does this imply that, for a Riemannian manifold (not just smooth), the relevant quantity that measures the curvature is the Ricci scalar and not the full Riemannian curvature tensor? Because to define the Riemann curvature tensor we need a connection (not a metric) and to define the Ricci scalar we also need a metric. Lastly, since the Riemann curvature tensor depends on the connection and not the metric and the connection gives the way to parallel transport vectors, does it mean that parallel transporting the same vector along the same closed curve on two different Riemannian manifolds that correspond to the same smooth manifold (but we assign the same connection but different metric to each one), we will get the same angle of rotation for that vector at the end-point (which is also the starting-point) of the curve? Note: When talking about a connection, I do not mean the Levi-Civita connection which comes from a metric. The question is about the difference in the role that the connection and metric play (independently) in the Riemann curvature tensor.",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'curvature', 'affine-geometry']"
52,Intuition about pullbacks in differential geometry,Intuition about pullbacks in differential geometry,,"I am struggling to understand the role of pullbacks after noticing that they are used when defining an integral of $k$-forms on a manifold. Let $F:M \to N$ be a map between differentiable manifolds. The pullback of a covector $\omega \in (T_{F(p)}N)^*$ under $F$ at a point $p \in M$ is $F^*:(T_{F(p)}N)^* \to (T_pM)^*$ with $$(F^*)_p(\omega)X = \omega((F_*)_pX)$$ where $X \in T_p(M)$. I know that the pushforward map $F_*$ takes a tangent vector at a point in $M$ to a tangent vector at a point in $N$. Am i missing something else? The pullback takes a covector in $N$ to a covector in $M$, but I can't see why it is important and don't have any intuition in it. I don't get why the pullback is used in integration either. I'd be grateful for any help.","I am struggling to understand the role of pullbacks after noticing that they are used when defining an integral of $k$-forms on a manifold. Let $F:M \to N$ be a map between differentiable manifolds. The pullback of a covector $\omega \in (T_{F(p)}N)^*$ under $F$ at a point $p \in M$ is $F^*:(T_{F(p)}N)^* \to (T_pM)^*$ with $$(F^*)_p(\omega)X = \omega((F_*)_pX)$$ where $X \in T_p(M)$. I know that the pushforward map $F_*$ takes a tangent vector at a point in $M$ to a tangent vector at a point in $N$. Am i missing something else? The pullback takes a covector in $N$ to a covector in $M$, but I can't see why it is important and don't have any intuition in it. I don't get why the pullback is used in integration either. I'd be grateful for any help.",,"['differential-geometry', 'differential-topology']"
53,"Isoperimetric inequality, isodiametric inequality, hyperplane conjecture... what are the inequalities of this kind known or conjectured?","Isoperimetric inequality, isodiametric inequality, hyperplane conjecture... what are the inequalities of this kind known or conjectured?",,"Question: Which inequalities similar to the famous isoperimetric inequality is known?   conjectured? I recently learned about some inequalities which are all similar to the famous isoperimetric inequality. Each time we consider two size functionals $\Sigma$ and $\Sigma'$ and along all the convex bodies (convex and compact) $K$ in $\mathbb{R}^d$ satisfying $\Sigma'(K)=1$, we give a bound for $\Sigma(K)$. For example in $\mathbb{R}^2$, with $\Sigma=\mathrm{Area}$ and  $\Sigma'=\mathrm{Perimeter}$ we have an upper-bound given by the famous isoperimetric inequality . If $\Sigma$ (resp. $\Sigma'$) is homogeneous of degree $k$ (resp. $k'$). The problem is equivalent to giving a bound to  $$\frac{\Sigma(K)^{1/k}}{\Sigma'(K)^{1/k'}}$$ for all $K$ with $\Sigma'(K)\neq 0$. Below I list the inequalities I encountered and give a quite general definition of what I consider size functionals. The classical isoperimetric inequality in higher dimensions states that for any convex body $K$ in $\mathbb{R}^d$ with positive $(d-1)$- intrinsic volume we have $$0<\frac{V_d(K)^{1/d}}{V_{d-1}(K)^{1/(d-1)}}\leq \frac{V_d(\mathrm{Ball})^{1/d}}{V_{d-1}(\mathrm{Ball})^{1/(d-1)}}$$ where $V_d$ is the $d$-dimensional volume, $V_{d-1}$ the $(d-1)$-intrisic volume (twice the perimeter if $d=2$ and twice the surface area if $d=3$), and $\mathrm{Ball}$ is any $d$-dimensional ball. The isodiametric inequality state that for any convex body $K$ in $\mathbb{R}^2$ with positive perimeter we have $$\frac{\mathrm{Diameter}(\mathrm{Disk})}{\mathrm{Perimeter}(\mathrm{Disk})} \leq\frac{\mathrm{Diameter}(K)}{\mathrm{Perimeter}(K)} \leq\frac12$$ where $\mathrm{Diameter}(K)$ is the maximum distance between two points of $K$.  It has been proved by Bieberbach in 1915 (in german), I found this reference in the introduction of the article Isodiametric Problems for Polygons by by Michael J. Mossinghoff. I guess this inequality is true in higher dimensions but I have no reference. Jung's theorem states that for any convex body $K$ in $\mathbb{R}^d$ with positive diameter we have the second of the following inequalities (the first is obvious) $$\frac{\mathrm{Outradius}(\mathrm{Disk})}{\mathrm{Diameter(\mathrm{Disk})}}\leq \frac{\mathrm{Outradius}(K)}{\mathrm{Diameter(K)}}\leq \frac{\mathrm{Outradius}(\Delta_d)}{\mathrm{Diameter(\Delta_d)}}$$ where $\Delta_d$ is the $d$-dimensional regular simplex. The hyperplane conjecture states there exists a universal constant $C$ such that in any dimension, for any convex body $K$ in $\mathbb{R}^d$ with positive volume, we have $$C\leq\frac{\mathrm{MaxSection}(K)^{1/(d-1)}}{\mathrm{Volume(K)}^{1/d}}<\infty$$ where $\mathrm{MaxSection}(K)=\max\left(V_{d-1}(K\cap H) : H \text{ any hyperplane of }\mathbb{R}^d\right)$ is the maximal hyperplane section of $K$. More generally if we note $\mathcal{K}=\mathcal{K}_d$ the set of convex body of $\mathbb{R}^d$ we can consider any size functional $\Sigma:\mathcal{K}\to\mathbb{R}_{\geq 0}$ satisfying the following natural axioms: $\Sigma$ is continuous, not identically zero, homogeneous of some degree $k$, that is: $\Sigma(\lambda K)=\lambda^k \Sigma(K)$. increasing under set inclusion, that is: $K\subset M \Rightarrow \Sigma(K)\leq\Sigma(M)$ invariant under translation, that is: $\Sigma(K+x)=\Sigma(K)$. This covers most of the size functionals we usually consider: volume = area in dimension 2, surface area =perimeter in dimension 2, mean-width, min-width, max-width (=diameter) , width with a given direction in-radius : the radius of the biggest ball include in $K$, out-radius : the radius of the smalles ball include in $K$, intrinsic volumes the maximal hyperplane section: $\max\left(V_{d-1}(K\cap H) : H \text{ any hyperplane of }\mathbb{R}^d\right)$ ... Now for any choice of couple of size functionals $\Sigma$ and $\Sigma'$ of degree $k$ and $k'$, if $K$ is a convex body with $\Sigma'(K)\neq0$ the fraction $$\frac{\Sigma(K)^{1/k}}{\Sigma'(K)^{1/k'}}\in[0,\infty[$$ is invariant under translation or rescaling of $K$. I am interested by lower or upper bound for such fraction once we have fixed the dimension $d$ and $\Sigma$ and $\Sigma'$.","Question: Which inequalities similar to the famous isoperimetric inequality is known?   conjectured? I recently learned about some inequalities which are all similar to the famous isoperimetric inequality. Each time we consider two size functionals $\Sigma$ and $\Sigma'$ and along all the convex bodies (convex and compact) $K$ in $\mathbb{R}^d$ satisfying $\Sigma'(K)=1$, we give a bound for $\Sigma(K)$. For example in $\mathbb{R}^2$, with $\Sigma=\mathrm{Area}$ and  $\Sigma'=\mathrm{Perimeter}$ we have an upper-bound given by the famous isoperimetric inequality . If $\Sigma$ (resp. $\Sigma'$) is homogeneous of degree $k$ (resp. $k'$). The problem is equivalent to giving a bound to  $$\frac{\Sigma(K)^{1/k}}{\Sigma'(K)^{1/k'}}$$ for all $K$ with $\Sigma'(K)\neq 0$. Below I list the inequalities I encountered and give a quite general definition of what I consider size functionals. The classical isoperimetric inequality in higher dimensions states that for any convex body $K$ in $\mathbb{R}^d$ with positive $(d-1)$- intrinsic volume we have $$0<\frac{V_d(K)^{1/d}}{V_{d-1}(K)^{1/(d-1)}}\leq \frac{V_d(\mathrm{Ball})^{1/d}}{V_{d-1}(\mathrm{Ball})^{1/(d-1)}}$$ where $V_d$ is the $d$-dimensional volume, $V_{d-1}$ the $(d-1)$-intrisic volume (twice the perimeter if $d=2$ and twice the surface area if $d=3$), and $\mathrm{Ball}$ is any $d$-dimensional ball. The isodiametric inequality state that for any convex body $K$ in $\mathbb{R}^2$ with positive perimeter we have $$\frac{\mathrm{Diameter}(\mathrm{Disk})}{\mathrm{Perimeter}(\mathrm{Disk})} \leq\frac{\mathrm{Diameter}(K)}{\mathrm{Perimeter}(K)} \leq\frac12$$ where $\mathrm{Diameter}(K)$ is the maximum distance between two points of $K$.  It has been proved by Bieberbach in 1915 (in german), I found this reference in the introduction of the article Isodiametric Problems for Polygons by by Michael J. Mossinghoff. I guess this inequality is true in higher dimensions but I have no reference. Jung's theorem states that for any convex body $K$ in $\mathbb{R}^d$ with positive diameter we have the second of the following inequalities (the first is obvious) $$\frac{\mathrm{Outradius}(\mathrm{Disk})}{\mathrm{Diameter(\mathrm{Disk})}}\leq \frac{\mathrm{Outradius}(K)}{\mathrm{Diameter(K)}}\leq \frac{\mathrm{Outradius}(\Delta_d)}{\mathrm{Diameter(\Delta_d)}}$$ where $\Delta_d$ is the $d$-dimensional regular simplex. The hyperplane conjecture states there exists a universal constant $C$ such that in any dimension, for any convex body $K$ in $\mathbb{R}^d$ with positive volume, we have $$C\leq\frac{\mathrm{MaxSection}(K)^{1/(d-1)}}{\mathrm{Volume(K)}^{1/d}}<\infty$$ where $\mathrm{MaxSection}(K)=\max\left(V_{d-1}(K\cap H) : H \text{ any hyperplane of }\mathbb{R}^d\right)$ is the maximal hyperplane section of $K$. More generally if we note $\mathcal{K}=\mathcal{K}_d$ the set of convex body of $\mathbb{R}^d$ we can consider any size functional $\Sigma:\mathcal{K}\to\mathbb{R}_{\geq 0}$ satisfying the following natural axioms: $\Sigma$ is continuous, not identically zero, homogeneous of some degree $k$, that is: $\Sigma(\lambda K)=\lambda^k \Sigma(K)$. increasing under set inclusion, that is: $K\subset M \Rightarrow \Sigma(K)\leq\Sigma(M)$ invariant under translation, that is: $\Sigma(K+x)=\Sigma(K)$. This covers most of the size functionals we usually consider: volume = area in dimension 2, surface area =perimeter in dimension 2, mean-width, min-width, max-width (=diameter) , width with a given direction in-radius : the radius of the biggest ball include in $K$, out-radius : the radius of the smalles ball include in $K$, intrinsic volumes the maximal hyperplane section: $\max\left(V_{d-1}(K\cap H) : H \text{ any hyperplane of }\mathbb{R}^d\right)$ ... Now for any choice of couple of size functionals $\Sigma$ and $\Sigma'$ of degree $k$ and $k'$, if $K$ is a convex body with $\Sigma'(K)\neq0$ the fraction $$\frac{\Sigma(K)^{1/k}}{\Sigma'(K)^{1/k'}}\in[0,\infty[$$ is invariant under translation or rescaling of $K$. I am interested by lower or upper bound for such fraction once we have fixed the dimension $d$ and $\Sigma$ and $\Sigma'$.",,"['differential-geometry', 'inequality', 'convex-analysis', 'big-list', 'conjectures']"
54,"What exactly does ""differential forms are coordinate free"" mean?","What exactly does ""differential forms are coordinate free"" mean?",,"Most introductory texts on differential forms praise their property of allowing for a ""coordinate free formulation"". What exactly does this mean? What would be a concrete example for which a coordinate free formulation is superior to choosing a coordinate system? I am aware that expressing calculations in differential geometry in local parametrizations can be a mess, but aren't we also always choosing a basis for differential forms in writing something like $$\omega = \sum_{k=1}^n a_i dx_i,$$ where $\{dx_1,\dots, dx_n\}$ is a basis of $T_p \mathbb{R}^n = \mathbb{R}^n$ for some point $p \in \mathbb{R}^n$?","Most introductory texts on differential forms praise their property of allowing for a ""coordinate free formulation"". What exactly does this mean? What would be a concrete example for which a coordinate free formulation is superior to choosing a coordinate system? I am aware that expressing calculations in differential geometry in local parametrizations can be a mess, but aren't we also always choosing a basis for differential forms in writing something like $$\omega = \sum_{k=1}^n a_i dx_i,$$ where $\{dx_1,\dots, dx_n\}$ is a basis of $T_p \mathbb{R}^n = \mathbb{R}^n$ for some point $p \in \mathbb{R}^n$?",,"['differential-geometry', 'differential-forms']"
55,Electrodynamics in general spacetime,Electrodynamics in general spacetime,,"Let $M\cong\mathbb{R}^4_1$ be the usual Minkowski spacetime. Then we can formulate electrodynamics in a Lorentz invariant way by giving the EM-field $2$-form $\mathcal{F}\in\Omega^2(M)$ and reformuling the homogeneous Maxwell equations as $$d\mathcal{F} = 0$$ Then the Poincaré lemma tells us that the first of the two equations (i.e. $\mathcal{F}$ is closed) implies that $\mathcal{F} = d\mathcal{A}$ for some $\mathcal{A}\in\Omega^1(M)$ (i.e. $\mathcal{F}$ is exact). $\mathcal{A}$ is the usual potential for ED. This automatically gives us the Gauge symmetry $\mathcal{A}'=\mathcal{A}+d\chi$, for any $\chi\in C^\infty(M)$. My question is: say we want to treat ED  on ageneral spacetime, i.e. any $4$-semi-Rimannian manifold $(M,g)$ using the same Maxwell equations. Then if $H^2(M)\neq 0$ (the $2$nd cohomology group) we don't have anymore that $\mathcal{F} = d\mathcal{A}$, and we also lose the Gauge symmetry, which would make things harder. How is the problem approached? How do you treat ED in general spacetime?","Let $M\cong\mathbb{R}^4_1$ be the usual Minkowski spacetime. Then we can formulate electrodynamics in a Lorentz invariant way by giving the EM-field $2$-form $\mathcal{F}\in\Omega^2(M)$ and reformuling the homogeneous Maxwell equations as $$d\mathcal{F} = 0$$ Then the Poincaré lemma tells us that the first of the two equations (i.e. $\mathcal{F}$ is closed) implies that $\mathcal{F} = d\mathcal{A}$ for some $\mathcal{A}\in\Omega^1(M)$ (i.e. $\mathcal{F}$ is exact). $\mathcal{A}$ is the usual potential for ED. This automatically gives us the Gauge symmetry $\mathcal{A}'=\mathcal{A}+d\chi$, for any $\chi\in C^\infty(M)$. My question is: say we want to treat ED  on ageneral spacetime, i.e. any $4$-semi-Rimannian manifold $(M,g)$ using the same Maxwell equations. Then if $H^2(M)\neq 0$ (the $2$nd cohomology group) we don't have anymore that $\mathcal{F} = d\mathcal{A}$, and we also lose the Gauge symmetry, which would make things harder. How is the problem approached? How do you treat ED in general spacetime?",,"['differential-geometry', 'manifolds', 'mathematical-physics', 'quantum-field-theory', 'electromagnetism']"
56,"""Drawable"" Examples of Vector Bundles","""Drawable"" Examples of Vector Bundles",,"I'm looking for examples of vector bundles that can be easily drawn  or ""illustrated"" on a whiteboard for a talk I am giving.  I know of a couple simple examples that I could use: When our base space is $\mathbb{S}^1$ and we assign to each $p \in \mathbb{S}^1$ a copy of $\mathbb{R}$ and make either a Cylinder (trivial) or a Möbius Bundle. We can also consider a trivial bundle $\mathbb{S}^1 \times \mathbb{R}^2$ like in this post. What are other good examples of (non-trivial?) vector bundles that can easily be explained/drawn? Also are there any surfaces on which the tangent bundle is used for something interesting? Although I understand what vector/tangent bundles are, I don't quite see the motivation for studying them yet.  If you have any examples of general fiber bundles that can be simply explained, that would be appreciated too. To provide more context, I am an undergraduate giving a talk to undergraduates in a differential geometry course that focuses on smooth surfaces. It is a small-stakes talk. I would rather the audience walk away with an intuitive sense of what a vector bundle is (a picture in their head) rather than just knowing the definition. Vector bundles themselves are not exactly part of what we've been talking about in the course, though we've touched on ideas relating to tangent bundles .","I'm looking for examples of vector bundles that can be easily drawn  or ""illustrated"" on a whiteboard for a talk I am giving.  I know of a couple simple examples that I could use: When our base space is $\mathbb{S}^1$ and we assign to each $p \in \mathbb{S}^1$ a copy of $\mathbb{R}$ and make either a Cylinder (trivial) or a Möbius Bundle. We can also consider a trivial bundle $\mathbb{S}^1 \times \mathbb{R}^2$ like in this post. What are other good examples of (non-trivial?) vector bundles that can easily be explained/drawn? Also are there any surfaces on which the tangent bundle is used for something interesting? Although I understand what vector/tangent bundles are, I don't quite see the motivation for studying them yet.  If you have any examples of general fiber bundles that can be simply explained, that would be appreciated too. To provide more context, I am an undergraduate giving a talk to undergraduates in a differential geometry course that focuses on smooth surfaces. It is a small-stakes talk. I would rather the audience walk away with an intuitive sense of what a vector bundle is (a picture in their head) rather than just knowing the definition. Vector bundles themselves are not exactly part of what we've been talking about in the course, though we've touched on ideas relating to tangent bundles .",,"['differential-geometry', 'manifolds', 'vector-bundles', 'fiber-bundles', 'smooth-manifolds']"
57,Reference for Gauss-Manin connection,Reference for Gauss-Manin connection,,"I wish to understand the notion of ``Gass-Manin connection''. I have some understanding of differential geometry, topology and algebraic geometry. Where should I begin? IF the sources are freely available, that will be good. Even better will be if someone can give some little motivation for the concept. My aim is to understand it in the context of moduli of curves.","I wish to understand the notion of ``Gass-Manin connection''. I have some understanding of differential geometry, topology and algebraic geometry. Where should I begin? IF the sources are freely available, that will be good. Even better will be if someone can give some little motivation for the concept. My aim is to understand it in the context of moduli of curves.",,"['algebraic-geometry', 'differential-geometry']"
58,why does Lie bracket of two coordinate vector fields always vanish?,why does Lie bracket of two coordinate vector fields always vanish?,,"This is really puzzling me. Say we are dealing with a Riemannian manifold $(M,g)$ . Suppose $\nabla$ is the unique torsion free connection on $M$ that is compatible with $g$ . Suppose we are in a neighbourhood $U$ with coordinate map $(x^1,\cdots, x^m )$ . Since the connection is torsion free, $$\left[\frac{\partial}{\partial x_i},\frac{\partial}{\partial x_j}\right]=\nabla_{\frac{\partial}{\partial x_i}}{\frac{\partial}{\partial x_j}}-\nabla_{\frac{\partial}{\partial x_j}}{\frac{\partial}{\partial x_i}}.$$ And since the $\Gamma_{i,j}^k$ is symmetric on $i,j$ , the right hand side of the above equation will vanish. So the Lie bracket will be $0$ . Now here is my confusion. If I start out with $m$ linearly independent vector fields $Y_1, \cdots, Y_m$ , then I can find a coordinate system $(y_1,\cdots, y_m)$ such that $Y_i = \frac{\partial }{\partial y_i}$ (Correct me if I am wrong, because I am not sure about this) . Then arguing as above, I can show that the Lie bracket of $Y_i$ and $Y_j$ vanishes. I know Lie bracket shouldn't vanish on any two random vector fields I pick. So there must be something wrong with my argument here. Thank you in advance!","This is really puzzling me. Say we are dealing with a Riemannian manifold . Suppose is the unique torsion free connection on that is compatible with . Suppose we are in a neighbourhood with coordinate map . Since the connection is torsion free, And since the is symmetric on , the right hand side of the above equation will vanish. So the Lie bracket will be . Now here is my confusion. If I start out with linearly independent vector fields , then I can find a coordinate system such that (Correct me if I am wrong, because I am not sure about this) . Then arguing as above, I can show that the Lie bracket of and vanishes. I know Lie bracket shouldn't vanish on any two random vector fields I pick. So there must be something wrong with my argument here. Thank you in advance!","(M,g) \nabla M g U (x^1,\cdots, x^m ) \left[\frac{\partial}{\partial x_i},\frac{\partial}{\partial x_j}\right]=\nabla_{\frac{\partial}{\partial x_i}}{\frac{\partial}{\partial x_j}}-\nabla_{\frac{\partial}{\partial x_j}}{\frac{\partial}{\partial x_i}}. \Gamma_{i,j}^k i,j 0 m Y_1, \cdots, Y_m (y_1,\cdots, y_m) Y_i = \frac{\partial }{\partial y_i} Y_i Y_j","['differential-geometry', 'riemannian-geometry']"
59,Difference between the Jacobian matrix and the metric tensor,Difference between the Jacobian matrix and the metric tensor,,"I am just studying curvilinear coordinates and coordinate transformations. I have recently come across the metric tensor ($g_{ij}=\dfrac{\partial x}{\partial e_i}\dfrac{\partial x}{\partial e_j}+\dfrac{\partial y}{\partial e_i}\dfrac{\partial y}{\partial e_j}+\dfrac{\partial z}{\partial e_i}\dfrac{\partial z}{\partial e_j}$). As far as I understand it is used when transforming the arc element ds from one coordinate system e.g Cartesian to another one e.g. cylindrical polars. Since the coordinates in the cylindrical polars are orthogonal only $g_{11},g_{22},g_{33}$ are non zero. And we can see that the non zero components of the metric tensor are actually the same as the  magnitude of metric coefficients  $magnitude(h_i)=g_{ii}$. But the metric coefficients are also present in the Jacobian matrix as collumns of the Jacobian matrix. But you can also use the Jacobian matrix to do the coordinate transformation. So based on that I am wondering whether there is a relation between the Jacobian matrix and the metric tensor? e.g. Jacobian matrix is used when we transform in the coordinate system with the locally perpendicular axis, but the metrix tensor is used more generally? Thank you for all the answeres in advanced","I am just studying curvilinear coordinates and coordinate transformations. I have recently come across the metric tensor ($g_{ij}=\dfrac{\partial x}{\partial e_i}\dfrac{\partial x}{\partial e_j}+\dfrac{\partial y}{\partial e_i}\dfrac{\partial y}{\partial e_j}+\dfrac{\partial z}{\partial e_i}\dfrac{\partial z}{\partial e_j}$). As far as I understand it is used when transforming the arc element ds from one coordinate system e.g Cartesian to another one e.g. cylindrical polars. Since the coordinates in the cylindrical polars are orthogonal only $g_{11},g_{22},g_{33}$ are non zero. And we can see that the non zero components of the metric tensor are actually the same as the  magnitude of metric coefficients  $magnitude(h_i)=g_{ii}$. But the metric coefficients are also present in the Jacobian matrix as collumns of the Jacobian matrix. But you can also use the Jacobian matrix to do the coordinate transformation. So based on that I am wondering whether there is a relation between the Jacobian matrix and the metric tensor? e.g. Jacobian matrix is used when we transform in the coordinate system with the locally perpendicular axis, but the metrix tensor is used more generally? Thank you for all the answeres in advanced",,"['differential-geometry', 'vector-spaces', 'coordinate-systems', 'tensors']"
60,"Which is the ""proper"" definition of a geodesic curve?","Which is the ""proper"" definition of a geodesic curve?",,"I'm taking a course on differential geometry, and up until now I'd always thought that the definition of a geodesic is (loosely speaking) a curve on a surface with the minimal length between its endpoints. My professor, taking his lead from do Carmo, however, defines it as any curve whose geodesic curvature $\kappa_g=0$ . We showed that this is equivalent to satisfying the following pair of nonlinear ordinary differential equations: $$(\boldsymbol{E}u' + \boldsymbol{F}v')' = \frac12(\boldsymbol{E}_u(u')^2 + 2\boldsymbol{F}_uu'v' + \boldsymbol{G}_u(v')^2)$$ $$(\boldsymbol{F}u' + \boldsymbol{G}v')' = \frac12(\boldsymbol{E}_v(u')^2 + 2\boldsymbol{F}_vu'v' + \boldsymbol{G}_v(v')^2)$$ We then went through an incredibly painful calculation on the length of the family of curves $\gamma_\lambda$ to show that geodesics (i.e, those curves satisfying the geodesic equations above) are critical points of the functional $$\displaystyle\mathcal{L}(\lambda) = \int_a^b{\left\|\frac{d\gamma_\lambda}{dt}\right\| dt},$$ which is the length of the curve. Therefore, according to my professor's (and the textbook's) definition, geodesics are not necessarily length-minimizing, just critical points of $\mathcal{L}$ . Therefore, on a sphere, two non-antipodal points have two geodesics: the obvious length-minimizing one, and the other one going the long way around the sphere (which is, in this case, a saddle point of $\mathcal{L}$ ). This is not just an oversight on my professor's part, he explicitly brought attention to this fact. My question is, what are the advantages and disadvantages of these two conflicting definitions? I still see the length-minimizing one almost everywhere. On a related note, the fact that a geodesic is only a critical point, not necessarily a minimum, leaves open the possibility of a geodesic actually being the longest path between two points. Are there any situations where this is actually possible? It seems you could always perturb a curve slightly to stay within the image of a chart while still increasing its length infinitesimally. Are there some weird spaces where this is not the case?","I'm taking a course on differential geometry, and up until now I'd always thought that the definition of a geodesic is (loosely speaking) a curve on a surface with the minimal length between its endpoints. My professor, taking his lead from do Carmo, however, defines it as any curve whose geodesic curvature . We showed that this is equivalent to satisfying the following pair of nonlinear ordinary differential equations: We then went through an incredibly painful calculation on the length of the family of curves to show that geodesics (i.e, those curves satisfying the geodesic equations above) are critical points of the functional which is the length of the curve. Therefore, according to my professor's (and the textbook's) definition, geodesics are not necessarily length-minimizing, just critical points of . Therefore, on a sphere, two non-antipodal points have two geodesics: the obvious length-minimizing one, and the other one going the long way around the sphere (which is, in this case, a saddle point of ). This is not just an oversight on my professor's part, he explicitly brought attention to this fact. My question is, what are the advantages and disadvantages of these two conflicting definitions? I still see the length-minimizing one almost everywhere. On a related note, the fact that a geodesic is only a critical point, not necessarily a minimum, leaves open the possibility of a geodesic actually being the longest path between two points. Are there any situations where this is actually possible? It seems you could always perturb a curve slightly to stay within the image of a chart while still increasing its length infinitesimally. Are there some weird spaces where this is not the case?","\kappa_g=0 (\boldsymbol{E}u' + \boldsymbol{F}v')' = \frac12(\boldsymbol{E}_u(u')^2 + 2\boldsymbol{F}_uu'v' + \boldsymbol{G}_u(v')^2) (\boldsymbol{F}u' + \boldsymbol{G}v')' = \frac12(\boldsymbol{E}_v(u')^2 + 2\boldsymbol{F}_vu'v' + \boldsymbol{G}_v(v')^2) \gamma_\lambda \displaystyle\mathcal{L}(\lambda) = \int_a^b{\left\|\frac{d\gamma_\lambda}{dt}\right\| dt}, \mathcal{L} \mathcal{L}","['differential-geometry', 'definition']"
61,Is there a way to associate a Lie algebra to the group of diffeomorphisms?,Is there a way to associate a Lie algebra to the group of diffeomorphisms?,,"Let $M$ a closed (smooth) manifold. The group $Diff(M)$ of all difeomorphisms of $M$ is infinite dimensional, therefore it is not a Lie group. Is there a way to associate a Lie algebra to this? If so, is there some concrete descrpition of such Lie algebra? EDIT: I would welcome some references.  According to the question in the comments: the Lie algebra of the Lie group $G$ is defined as Lie algebra of left invariant vetor fields on $G$. Therefore for an infinite dimensional $G$ we would like to have a notion of a vector field. Vector fields are defined as section of the tangent bundle: the fibers of the tangent bundle are tangent spaces. We define the tangent space at a given point $x$ as the set of classes of smooth curves $\gamma:I \to G, \gamma(0)=x$ with equivalence relation $\gamma_1 \sim \gamma_2$ iff for any chart $\varphi$ we have $\frac{d}{dt}(\varphi \circ \gamma_1)(0)=\frac{d}{dt}(\varphi \circ \gamma_2)(0)$. This set is in one to one correspondence with $\mathbb{R}^n$ for $n$-dimensional manifolds and the linear structure is transported via this correspondence. In infinite dimension there are few delicate moments: instead $\mathbb{R}^n$ we need another ,,model space''. Which model space we choose for infinite dimensional Lie groups, in particular for $Diff(M)$? Moreover while defining tangent space we need derivative: which notion do we use?","Let $M$ a closed (smooth) manifold. The group $Diff(M)$ of all difeomorphisms of $M$ is infinite dimensional, therefore it is not a Lie group. Is there a way to associate a Lie algebra to this? If so, is there some concrete descrpition of such Lie algebra? EDIT: I would welcome some references.  According to the question in the comments: the Lie algebra of the Lie group $G$ is defined as Lie algebra of left invariant vetor fields on $G$. Therefore for an infinite dimensional $G$ we would like to have a notion of a vector field. Vector fields are defined as section of the tangent bundle: the fibers of the tangent bundle are tangent spaces. We define the tangent space at a given point $x$ as the set of classes of smooth curves $\gamma:I \to G, \gamma(0)=x$ with equivalence relation $\gamma_1 \sim \gamma_2$ iff for any chart $\varphi$ we have $\frac{d}{dt}(\varphi \circ \gamma_1)(0)=\frac{d}{dt}(\varphi \circ \gamma_2)(0)$. This set is in one to one correspondence with $\mathbb{R}^n$ for $n$-dimensional manifolds and the linear structure is transported via this correspondence. In infinite dimension there are few delicate moments: instead $\mathbb{R}^n$ we need another ,,model space''. Which model space we choose for infinite dimensional Lie groups, in particular for $Diff(M)$? Moreover while defining tangent space we need derivative: which notion do we use?",,"['differential-geometry', 'lie-groups', 'lie-algebras', 'smooth-manifolds']"
62,Applications of Differential Geometry in Artificial Intelligence,Applications of Differential Geometry in Artificial Intelligence,,"I am new to this wonderful site. I searched around a bit but I couldn't find any well-discussed posts on applications of differential geometry to artificial intelligence, or more generally to computer science. I came across Riemannian Geometry a few months back via YouTube(lol) and have been hooked on it since. I even bought a textbook and started learning from there. I am an engineer and I have sufficient math skills to make sense of the book, but it hardly has any real life applications. Almost everything is ""Prove this"" or ""Theorem that"". So I wanted to know if there are any real-life implementable applications for CS. More specifically, in the field of AI and Machine Learning. From what I have understood, differential geometry allows us to ""see"",""understand"" and ""analyze"" curves in higher dimensional spaces. Is this accurate? And can this help in AI and Machine Learning? In subtopics like Natural Language Processing, Robotics, Computer Vision, Data analysis? I would sure like to start off with a simple project which helps me understand differential geometry better. Thanks PS: Sorry if I have not framed this question well, it is my first question.","I am new to this wonderful site. I searched around a bit but I couldn't find any well-discussed posts on applications of differential geometry to artificial intelligence, or more generally to computer science. I came across Riemannian Geometry a few months back via YouTube(lol) and have been hooked on it since. I even bought a textbook and started learning from there. I am an engineer and I have sufficient math skills to make sense of the book, but it hardly has any real life applications. Almost everything is ""Prove this"" or ""Theorem that"". So I wanted to know if there are any real-life implementable applications for CS. More specifically, in the field of AI and Machine Learning. From what I have understood, differential geometry allows us to ""see"",""understand"" and ""analyze"" curves in higher dimensional spaces. Is this accurate? And can this help in AI and Machine Learning? In subtopics like Natural Language Processing, Robotics, Computer Vision, Data analysis? I would sure like to start off with a simple project which helps me understand differential geometry better. Thanks PS: Sorry if I have not framed this question well, it is my first question.",,"['differential-geometry', 'computer-science', 'artificial-intelligence']"
63,"Intuitively, what is the difference between homeomorphism and diffeomorphism? Significance?","Intuitively, what is the difference between homeomorphism and diffeomorphism? Significance?",,"As the title suggests, intuitively,  what is the difference between homeomorphism and diffeomorphism? Many thanks in advance. What is the significance of such a difference?","As the title suggests, intuitively,  what is the difference between homeomorphism and diffeomorphism? Many thanks in advance. What is the significance of such a difference?",,['differential-geometry']
64,Lie bracket is a connection?,Lie bracket is a connection?,,"In Road to Reality , section 14.6 on Lie derivative Penrose writes: Now $\epsilon^2 [j,h]$ corresponds to an   $O(\epsilon^2)$ gap in the ‘parallelogram’ whose initial sides are $e_j$ and $e_h$ at   the origin I. The relevant notion of ‘parallelism’ comes from the group   action, supplying the needed notion of ‘parallel transport’, which actually gives a connection with torsion but no curvature.[14.17] and poses the the exercise: [14.17] Try to explain why there is torsion but no curvature. I find it surprising that one could get a connection just from the Lie bracket, since connections depend on additional structure like the metric tensor, while Lie brackets do not. One forum has a proposed answer giving the Lie bracket itself as the connection $\nabla_{L}M = [L, M]$ if I understood it correctly. The proof proposed there convincingly shows that there would be torsion & no curvature, but the proposed answer does not seem to be a connection in the first place since multiplying the the vector fields $L$ and $M$ by a scalar field $\phi$  does not satisfy a condition required given earlier in the book: linearity in $L$ : $\nabla_{\phi L}M = \phi\nabla_{L}M$ Treating veactors as directional derivative operators on scalar field shows how linearity in $L$ fails $$\begin{align} [\phi L, M](\psi) &= \phi L(M(\psi)) - M(\phi L(\psi)) \\    &=  \phi L(M(\psi)) - (M(\phi)L(\psi) + \phi M(L(\psi))) \\    &= \phi[L, M](\psi) -  M(\phi)L(\psi) \end{align}$$ because of the additional $M(\phi)L(\psi)$ term. Also if it is possible to define a connection just from the Lie bracket, why is it usually said that you need additional structure to define parallel transport? Is it just that the all torsion no curvature property stops this connection from being useful, so people disregard it? So what is Penrose getting at? Am I missing something? EDIT From the answers it seems that the Lie bracket really is a connection, just not a linear or affine one. The book does not formally define what a connection is in general or specify the type of connection is intended when the term is used without qualification. It only gives the derivative style algebraic laws connections a connection must satisfy, including linearity wrt $L$ above. So the Lie bracket does seem to be not a connection in the sense the term used in the rest of the book. That is what I was trying to figure out I am still curious why it is so frequently claimed that connections, parallel transport and covariant derivatives (which I in my understanding are equivalent concepts) require extra structure on a manifold while Lie derivatives do not, if the Lie bracket is a connection and this connection is hardly ever mentioned. Also is there a name for the Lie derivative as a connection? Lie connection??","In Road to Reality , section 14.6 on Lie derivative Penrose writes: Now $\epsilon^2 [j,h]$ corresponds to an   $O(\epsilon^2)$ gap in the ‘parallelogram’ whose initial sides are $e_j$ and $e_h$ at   the origin I. The relevant notion of ‘parallelism’ comes from the group   action, supplying the needed notion of ‘parallel transport’, which actually gives a connection with torsion but no curvature.[14.17] and poses the the exercise: [14.17] Try to explain why there is torsion but no curvature. I find it surprising that one could get a connection just from the Lie bracket, since connections depend on additional structure like the metric tensor, while Lie brackets do not. One forum has a proposed answer giving the Lie bracket itself as the connection $\nabla_{L}M = [L, M]$ if I understood it correctly. The proof proposed there convincingly shows that there would be torsion & no curvature, but the proposed answer does not seem to be a connection in the first place since multiplying the the vector fields $L$ and $M$ by a scalar field $\phi$  does not satisfy a condition required given earlier in the book: linearity in $L$ : $\nabla_{\phi L}M = \phi\nabla_{L}M$ Treating veactors as directional derivative operators on scalar field shows how linearity in $L$ fails $$\begin{align} [\phi L, M](\psi) &= \phi L(M(\psi)) - M(\phi L(\psi)) \\    &=  \phi L(M(\psi)) - (M(\phi)L(\psi) + \phi M(L(\psi))) \\    &= \phi[L, M](\psi) -  M(\phi)L(\psi) \end{align}$$ because of the additional $M(\phi)L(\psi)$ term. Also if it is possible to define a connection just from the Lie bracket, why is it usually said that you need additional structure to define parallel transport? Is it just that the all torsion no curvature property stops this connection from being useful, so people disregard it? So what is Penrose getting at? Am I missing something? EDIT From the answers it seems that the Lie bracket really is a connection, just not a linear or affine one. The book does not formally define what a connection is in general or specify the type of connection is intended when the term is used without qualification. It only gives the derivative style algebraic laws connections a connection must satisfy, including linearity wrt $L$ above. So the Lie bracket does seem to be not a connection in the sense the term used in the rest of the book. That is what I was trying to figure out I am still curious why it is so frequently claimed that connections, parallel transport and covariant derivatives (which I in my understanding are equivalent concepts) require extra structure on a manifold while Lie derivatives do not, if the Lie bracket is a connection and this connection is hardly ever mentioned. Also is there a name for the Lie derivative as a connection? Lie connection??",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'self-learning']"
65,Can the interior of a manifold be orientable but not its boundary?,Can the interior of a manifold be orientable but not its boundary?,,"Suppose $M^m$ is a manifold with boundary. If we are given an orientation for $M$, we can then derive an orientation for $\partial M$ by considering the orientation of $TM$ at $\partial M$ and then using an outward-pointing vector to get an orientation of $T(\partial M)$. This made me wonder: is it possible that $M^\circ = M \setminus \partial M$ is orientable but $M$ is not? Is it possible that $M^\circ$ is orientable but $\partial M$ is not?","Suppose $M^m$ is a manifold with boundary. If we are given an orientation for $M$, we can then derive an orientation for $\partial M$ by considering the orientation of $TM$ at $\partial M$ and then using an outward-pointing vector to get an orientation of $T(\partial M)$. This made me wonder: is it possible that $M^\circ = M \setminus \partial M$ is orientable but $M$ is not? Is it possible that $M^\circ$ is orientable but $\partial M$ is not?",,"['differential-geometry', 'smooth-manifolds', 'orientation']"
66,Right-invariance of a volume form on a compact Lie group,Right-invariance of a volume form on a compact Lie group,,"The following is a question from the second edition of John M. Lee's Introduction to Riemannian Manifolds . 3-9. Suppose $G$ is a compact Lie group with a left-invariant metric $g$ and a left-invariant orientation. Show that the Riemannian volume form $dV_g$ is bi-invariant. [Hint: Show that $dV_g$ is equal to the Riemannian volume form for a bi-invariant metric.] Since $G$ is compact, it admits a bi-invariant metric $\tilde g$ , and with this and the given orientation, we have a volume form $dV_{\tilde g}$ . It's easy to see that $dV_g$ and $dV_{\tilde g}$ are both left-invariant, using the fact that the metrics $g, \tilde g$ and the orientation are left-invariant. Since they are both left-invariant and positive with respect to the given orientation, there is a $c > 0$ such that $dV_g = c dV_{\tilde g}$ . Then $dV_g$ is equal to the Riemannian volume form corresponding to the bi-invariant metric $c^{2/n}\tilde g$ , as the hint suggests. I am having trouble showing that $dV_g$ is also right-invariant; here is my work thus far. Since for any $\varphi \in G$ the forms $R_\varphi^*(dV_g)$ and $dV_g$ are left-invariant, there is a function $f \colon G \to \mathbb{R}^\times$ such that $R_\varphi^*(dV_g) = f(\varphi) dV_g$ . Evaluating both sides at $e$ , one obtains $f(\varphi) = \det(\mathrm{Ad}(\varphi^{-1}))$ , a continuous homomorphism. Since $G$ is compact, $f(G)$ is a compact subgroup of $\mathbb{R}^\times$ , i.e. $f(G) = \{1\}$ or $f(G) = \{\pm 1\}$ . I do not see how to exclude the second case, i.e. if $R_\varphi$ is orientation-reversing for some $\varphi \in G$ . Since $f(e) = 1$ , $f$ is identically $1$ on the identity component of $G$ ; this would finish the problem if $G$ were connected, but unfortunately, it might not be. Since I haven't used the fact that $dV_g$ equals the volume form for a bi-invariant metric yet, I feel it must be used here, but I cannot see how. Some searching reveals this may be related to the idea of left/right-invariant Haar measures and unimodular Lie groups, but my measure theory knowledge is insufficient to understand that material. A small part of me believes that the problem is incorrect without the connectedness hypothesis (e.g. consider the diagonal matrix $A$ with $-1$ and $1$ in $O(2)$ , then $f(A) = -1$ ?), but the errata for the book reveals nothing. Any hints or suggestions on how to proceed with this problem would be appreciated.","The following is a question from the second edition of John M. Lee's Introduction to Riemannian Manifolds . 3-9. Suppose is a compact Lie group with a left-invariant metric and a left-invariant orientation. Show that the Riemannian volume form is bi-invariant. [Hint: Show that is equal to the Riemannian volume form for a bi-invariant metric.] Since is compact, it admits a bi-invariant metric , and with this and the given orientation, we have a volume form . It's easy to see that and are both left-invariant, using the fact that the metrics and the orientation are left-invariant. Since they are both left-invariant and positive with respect to the given orientation, there is a such that . Then is equal to the Riemannian volume form corresponding to the bi-invariant metric , as the hint suggests. I am having trouble showing that is also right-invariant; here is my work thus far. Since for any the forms and are left-invariant, there is a function such that . Evaluating both sides at , one obtains , a continuous homomorphism. Since is compact, is a compact subgroup of , i.e. or . I do not see how to exclude the second case, i.e. if is orientation-reversing for some . Since , is identically on the identity component of ; this would finish the problem if were connected, but unfortunately, it might not be. Since I haven't used the fact that equals the volume form for a bi-invariant metric yet, I feel it must be used here, but I cannot see how. Some searching reveals this may be related to the idea of left/right-invariant Haar measures and unimodular Lie groups, but my measure theory knowledge is insufficient to understand that material. A small part of me believes that the problem is incorrect without the connectedness hypothesis (e.g. consider the diagonal matrix with and in , then ?), but the errata for the book reveals nothing. Any hints or suggestions on how to proceed with this problem would be appreciated.","G g dV_g dV_g G \tilde g dV_{\tilde g} dV_g dV_{\tilde g} g, \tilde g c > 0 dV_g = c dV_{\tilde g} dV_g c^{2/n}\tilde g dV_g \varphi \in G R_\varphi^*(dV_g) dV_g f \colon G \to \mathbb{R}^\times R_\varphi^*(dV_g) = f(\varphi) dV_g e f(\varphi) = \det(\mathrm{Ad}(\varphi^{-1})) G f(G) \mathbb{R}^\times f(G) = \{1\} f(G) = \{\pm 1\} R_\varphi \varphi \in G f(e) = 1 f 1 G G dV_g A -1 1 O(2) f(A) = -1",['differential-geometry']
67,Compute distance induced by riemannian metric,Compute distance induced by riemannian metric,,"On $\mathbb{R}^4$ with coordinates $x_1,x_2,x_3,x_4$ consider the riemannian metric $g:=\displaystyle{\frac{dx_1^2+dx_2^2+dx_3^2+dx_4^2}{x_1^2+x_2^2}}$ defined on $X:=\{x_1^2+x_2^2\neq 0\}$ and call $d$ the  intrinsic induced metric. How can I compute explicitly $d(p_1,p_2)$ for any $p_1,p_2\in X$? Suppose for example $p_1=(1,0,1,0)$ and $p_2=(1,1,2,2)$. I computed the geodesic equations $$\ddot \gamma_1=\frac{2\gamma_2\dot\gamma_1\dot\gamma_2+\dot\gamma_1(\dot\gamma_1^2-\dot\gamma_2^2-\dot\gamma_3^2-\dot\gamma_4^2)}{\gamma_1^2+\gamma_2^2}$$ $$\ddot \gamma_2=\frac{2\gamma_1\dot\gamma_1\dot\gamma_2-\dot\gamma_2(\dot\gamma_1^2-\dot\gamma_2^2+\dot\gamma_3^2+\dot\gamma_4^2)}{\gamma_1^2+\gamma_2^2}$$ $$\ddot \gamma_3=\frac{2(\gamma_1\dot\gamma_1+\gamma_2\dot\gamma_2)\dot\gamma_3}{\gamma_1^2+\gamma_2^2}$$ $$\ddot \gamma_4=\frac{2(\gamma_1\dot\gamma_1+\gamma_2\dot\gamma_2)\dot\gamma_4}{\gamma_1^2+\gamma_2^2}$$ which have the following solutions: $$\gamma_1=\frac{k\operatorname{sech}(kt+d)\cos(at+b)}{\sqrt{A^2+B^2}}$$ $$\gamma_2=\frac{k\operatorname{sech}(kt+d)\sin(at+b)}{\sqrt{A^2+B^2}}$$ $$\gamma_3=\frac{Ak\operatorname{tanh}(kt+d)}{A^2+B^2}+c_1$$ $$\gamma_4=\frac{Bk\operatorname{tanh}(kt+d)}{A^2+B^2}+c_1$$ where $k,d,a,b,A,B,c_1,c_2$ are constants, $\operatorname{sech}$ is the hyperbolic secant and $\operatorname{tanh}$ is the hyperbolic tangent. The distance $d(p_1,p_2)$ is such that there exists a geodesic $\gamma=(\gamma_1,\gamma_2,\gamma_3,\gamma_4):[0,d(p_1,p_2)]\rightarrow X$ of the previous form with $\gamma(0)=p_1,\gamma(d(p_1,p_2))=p_2$. It's still not clear to me what is the easiest way to compute $d(p_1,p_2)$: should I find constants $k,d,a,b,A,B,c_1,c_2$ such that there exists a geodesic $\gamma$ and a constant $d(p_1,p_2)$ with $\gamma(0)=(1,0,1,0)$ and $\gamma((d(p_1,p_2))=(1,1,1,2)$? This seems extremely complicated and not directly solvable. Can you suggest me another way to proceed?","On $\mathbb{R}^4$ with coordinates $x_1,x_2,x_3,x_4$ consider the riemannian metric $g:=\displaystyle{\frac{dx_1^2+dx_2^2+dx_3^2+dx_4^2}{x_1^2+x_2^2}}$ defined on $X:=\{x_1^2+x_2^2\neq 0\}$ and call $d$ the  intrinsic induced metric. How can I compute explicitly $d(p_1,p_2)$ for any $p_1,p_2\in X$? Suppose for example $p_1=(1,0,1,0)$ and $p_2=(1,1,2,2)$. I computed the geodesic equations $$\ddot \gamma_1=\frac{2\gamma_2\dot\gamma_1\dot\gamma_2+\dot\gamma_1(\dot\gamma_1^2-\dot\gamma_2^2-\dot\gamma_3^2-\dot\gamma_4^2)}{\gamma_1^2+\gamma_2^2}$$ $$\ddot \gamma_2=\frac{2\gamma_1\dot\gamma_1\dot\gamma_2-\dot\gamma_2(\dot\gamma_1^2-\dot\gamma_2^2+\dot\gamma_3^2+\dot\gamma_4^2)}{\gamma_1^2+\gamma_2^2}$$ $$\ddot \gamma_3=\frac{2(\gamma_1\dot\gamma_1+\gamma_2\dot\gamma_2)\dot\gamma_3}{\gamma_1^2+\gamma_2^2}$$ $$\ddot \gamma_4=\frac{2(\gamma_1\dot\gamma_1+\gamma_2\dot\gamma_2)\dot\gamma_4}{\gamma_1^2+\gamma_2^2}$$ which have the following solutions: $$\gamma_1=\frac{k\operatorname{sech}(kt+d)\cos(at+b)}{\sqrt{A^2+B^2}}$$ $$\gamma_2=\frac{k\operatorname{sech}(kt+d)\sin(at+b)}{\sqrt{A^2+B^2}}$$ $$\gamma_3=\frac{Ak\operatorname{tanh}(kt+d)}{A^2+B^2}+c_1$$ $$\gamma_4=\frac{Bk\operatorname{tanh}(kt+d)}{A^2+B^2}+c_1$$ where $k,d,a,b,A,B,c_1,c_2$ are constants, $\operatorname{sech}$ is the hyperbolic secant and $\operatorname{tanh}$ is the hyperbolic tangent. The distance $d(p_1,p_2)$ is such that there exists a geodesic $\gamma=(\gamma_1,\gamma_2,\gamma_3,\gamma_4):[0,d(p_1,p_2)]\rightarrow X$ of the previous form with $\gamma(0)=p_1,\gamma(d(p_1,p_2))=p_2$. It's still not clear to me what is the easiest way to compute $d(p_1,p_2)$: should I find constants $k,d,a,b,A,B,c_1,c_2$ such that there exists a geodesic $\gamma$ and a constant $d(p_1,p_2)$ with $\gamma(0)=(1,0,1,0)$ and $\gamma((d(p_1,p_2))=(1,1,1,2)$? This seems extremely complicated and not directly solvable. Can you suggest me another way to proceed?",,['differential-geometry']
68,"If two Riemannian manifolds can be isometrically immersed in each other, are they isometric?","If two Riemannian manifolds can be isometrically immersed in each other, are they isometric?",,"Let $M,N$ be smooth compact oriented Riemannian manifolds with boundary. Suppose that both $M,N$ can be isometrically immersed in each other. Must $M,N$ be isometric? Does anything change if we also assume $\operatorname{Vol}(M)=\operatorname{Vol}(N)$ ? Note: I assume $M,N$ are connected (Otherwise, as mentioned by Del, we can take $N$ to be two disjoint copies of $M$ ). Of course, if both manifolds can be isometrically embedded in each other, then they are isometric. This follows from volume considerations: Suppose $i:M \to N,j:N \to M$ are isometric embeddings. Then, $i(M),M$ are isometric, hence $\operatorname{Vol}(M)=\operatorname{Vol}(i(M))\le \operatorname{Vol}(N)$ . Similarly, $\operatorname{Vol}(N)\le \operatorname{Vol}(M)$ . Thus, $\operatorname{Vol}(i(M))=\operatorname{Vol}(N)$ . Since $i(M)$ is compact, it is a closed subset of $N$ . Thus, if $i(M) \neq N$ , then $N\setminus i(M)$ is open, and so has a positive volume, contradicting $\operatorname{Vol}(i(M))=\operatorname{Vol}(N)$ . This shows $i,j$ are surjective, thus isometries. Updades and Remarks: $(1) \,$ If $M$ , $N$ have no boundaries, the answer is positive . This follows easily from a metric argument. Let $i:M \to N, j:N \to M$ be the given isometric immersions. Then $i(M)$ is clopen in $N$ , hence $i$ is surjective. Similarly, $j$ is surjective. A possible generalization to the case with boundaries: Assuming that every smooth orientation preserving isometric immersion maps boundary into boundary (see this question ) , we know that $j \circ i(\partial M) \subseteq \partial M$ , so we can imitate the above argument to this case: First, we note $i(\partial M) \subseteq \partial N$ (since $j(N^0) \subseteq M^0$ ). It follows $i(M^o)$ is clopen in $N^o$ , hence $i(M^o)=N^o$ . Since $i(M)$ is closed in $N$ , and contains the dense subset $N^o$ , $i$ is surjective, and moreover $i(\partial M) = \partial N , i(M^o)= N^o$ . By symmetry, $j$ is surjective, and the same argument in the previous case imply $j \circ i:M \to M $ is a surjective nonexpanding map, hence a metric isometry. Then, the $1$ -Lipschitzity of $i,j$ implies $i$ is a metric isometry. So, by the positive answer to this question $i$ is a smooth Riemannian isometry. $(2)$ It is enough to prove that an orientation-preserving isometric immersion $M \to M$ is a Riemannian isometry. (and in particular maps $\partial M$ onto $\partial M$ ). Indeed, let $i:M \to N, j:N \to M$ be the given immersions and assume the above statement holds. Then $j \circ i:M \to M$ is an isometry, and so $j \circ i(\partial M) = \partial M$ . This implies that $i(\partial M) \subseteq \partial N$ (since $j(N^0) \subseteq M^0$ ). Also, $j \circ i:M \to M$ is an isometry $\Rightarrow$ $i$ is injective and $j$ is surjective. By symmetry, $i,j$ are bijections. Since we know that $i(\partial M) \subseteq \partial N , i(M^o)\subseteq N^o$ , and $i$ is surjective it follows that $i(\partial M) = \partial N , i(M^o)= N^o$ . Since $i$ is in particular a metric isometry, the positive answer to this question , shows $i^{-1}$ is smooth, hence $i$ is a Riemannian isometry.","Let be smooth compact oriented Riemannian manifolds with boundary. Suppose that both can be isometrically immersed in each other. Must be isometric? Does anything change if we also assume ? Note: I assume are connected (Otherwise, as mentioned by Del, we can take to be two disjoint copies of ). Of course, if both manifolds can be isometrically embedded in each other, then they are isometric. This follows from volume considerations: Suppose are isometric embeddings. Then, are isometric, hence . Similarly, . Thus, . Since is compact, it is a closed subset of . Thus, if , then is open, and so has a positive volume, contradicting . This shows are surjective, thus isometries. Updades and Remarks: If , have no boundaries, the answer is positive . This follows easily from a metric argument. Let be the given isometric immersions. Then is clopen in , hence is surjective. Similarly, is surjective. A possible generalization to the case with boundaries: Assuming that every smooth orientation preserving isometric immersion maps boundary into boundary (see this question ) , we know that , so we can imitate the above argument to this case: First, we note (since ). It follows is clopen in , hence . Since is closed in , and contains the dense subset , is surjective, and moreover . By symmetry, is surjective, and the same argument in the previous case imply is a surjective nonexpanding map, hence a metric isometry. Then, the -Lipschitzity of implies is a metric isometry. So, by the positive answer to this question is a smooth Riemannian isometry. It is enough to prove that an orientation-preserving isometric immersion is a Riemannian isometry. (and in particular maps onto ). Indeed, let be the given immersions and assume the above statement holds. Then is an isometry, and so . This implies that (since ). Also, is an isometry is injective and is surjective. By symmetry, are bijections. Since we know that , and is surjective it follows that . Since is in particular a metric isometry, the positive answer to this question , shows is smooth, hence is a Riemannian isometry.","M,N M,N M,N \operatorname{Vol}(M)=\operatorname{Vol}(N) M,N N M i:M \to N,j:N \to M i(M),M \operatorname{Vol}(M)=\operatorname{Vol}(i(M))\le \operatorname{Vol}(N) \operatorname{Vol}(N)\le \operatorname{Vol}(M) \operatorname{Vol}(i(M))=\operatorname{Vol}(N) i(M) N i(M) \neq N N\setminus i(M) \operatorname{Vol}(i(M))=\operatorname{Vol}(N) i,j (1) \, M N i:M \to N, j:N \to M i(M) N i j j \circ i(\partial M) \subseteq \partial M i(\partial M) \subseteq \partial N j(N^0) \subseteq M^0 i(M^o) N^o i(M^o)=N^o i(M) N N^o i i(\partial M) = \partial N , i(M^o)= N^o j j \circ i:M \to M  1 i,j i i (2) M \to M \partial M \partial M i:M \to N, j:N \to M j \circ i:M \to M j \circ i(\partial M) = \partial M i(\partial M) \subseteq \partial N j(N^0) \subseteq M^0 j \circ i:M \to M \Rightarrow i j i,j i(\partial M) \subseteq \partial N , i(M^o)\subseteq N^o i i(\partial M) = \partial N , i(M^o)= N^o i i^{-1} i","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'isometry']"
69,Intuitive interpretation of Ricci Flow,Intuitive interpretation of Ricci Flow,,"What is the best way to interpret, explain or somehow visualize the basic idea behind formal definition of Ricci Flow? I am familiar with the hackneyed expressions like ""Ricci Flow is a non-linear analogue for the heat equation which smoothens metric"" , or ""Ricci Flow describes the deformation of the Riemannian metric tensor on manifold"" . However, I was looking for something similar to the balloon-under-pressure interpretation of the mean curvature flow,  in particular of the surface tension flow: Ultimately, I am looking for something that would make Ricci Flow concept clear for undergraduate students without diving too deep into technicalities of Ricci tensor and volume forms.","What is the best way to interpret, explain or somehow visualize the basic idea behind formal definition of Ricci Flow? I am familiar with the hackneyed expressions like ""Ricci Flow is a non-linear analogue for the heat equation which smoothens metric"" , or ""Ricci Flow describes the deformation of the Riemannian metric tensor on manifold"" . However, I was looking for something similar to the balloon-under-pressure interpretation of the mean curvature flow,  in particular of the surface tension flow: Ultimately, I am looking for something that would make Ricci Flow concept clear for undergraduate students without diving too deep into technicalities of Ricci tensor and volume forms.",,"['differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'ricci-flow']"
70,Yarn-like functions,Yarn-like functions,,"When wrapping yarn around a ball you cannot make sharp turns or the yarn will fall off. If we think of the yarn as a curve on the surface of the sphere, we would say it must have curvature less than some small constant m. (meaning the best fit tangental circle must have radius greater than $\frac 1m$) The yarn should be wrapped evenly: it should not overlap itself too often. (This would lead to the yarn ball taking on a non-spherical shape over time. No good!) The distribution of the self-intersections should be of nearly consistent density over the surface of the sphere. The yarn will divide the surface of the sphere in to regions. If $A_i, A_j$ are the areas of any two of these regions then for some small constant F, $|A_i- A_j| < F$, $\forall i, j$. As the curve is extended further and further (wrapped around more times) the density of intersections should increase and $A_i \rightarrow 0$ for all of the regions. I know one answer is a randomly generated curve that deviates from a straight path. Overtime it produces a perfect yarn ball. I want to know if there is a non-random answer to this question. My own try: *In trying to solving this myself I thought it might be a good idea to project the sphere on to the plane, as a Riemann surface. But, since so many of the requirements focus on uniformity, this makes the problem a little strage. Observe:  The area of the regions will need to increase as we move away from the unit circle toward infinity. If the curve ever passes through the north pole, then the plane version would shoot off to infinity. What I found even more weird is what would happen if the curve simply passed very near, but not through, the north pole. Then, on the plane, the curve would go very far from the origin and then loop back.  By making the curve near enough to the north pole the loops can be as large as we please.  Since wrapping increases the density uniformly, if we observe the wrapping pattern projected on to the plane it would be like loopy knot that, over time, keeps casting bigger and bigger outlier loops, it would always grow and be un-bounded. (even without any intersection with the north pole!) The requirement about curvature, would mean that the knot could be more curvy inside of the unit circle, and then grow less curvy as we move away from the origin. I know of no such curve, and so I abandoned this way of thinking about the problem. But, I thought I'd share. * Updated to add a drawing of the projection idea. Update 2: Maybe if I projected the following polar plot back on to the Riemann sphere? The graph of the form $r= \theta^2 \sin (k \theta)$ produced good-looking results for $0 < k <1$... but all of the graphs are far too dense near the origin. Also, wrapping would start in a lop-sided manner, filling in the bottom of the sphere first then moving up... and never reaching the north pole!  But, maybe there is some way to tweak this? (This graph shows the kind of non-random pattern I have in mind for a solution. In a practical sense a solution to this problem could be used to wind spherical balls of ropes, yarns, or cords in a factory setting. Now, I will think about how I would instruct a robot to wind a yarn ball... if the robot is unable to do things randomly. What would you tell the robot to do? )","When wrapping yarn around a ball you cannot make sharp turns or the yarn will fall off. If we think of the yarn as a curve on the surface of the sphere, we would say it must have curvature less than some small constant m. (meaning the best fit tangental circle must have radius greater than $\frac 1m$) The yarn should be wrapped evenly: it should not overlap itself too often. (This would lead to the yarn ball taking on a non-spherical shape over time. No good!) The distribution of the self-intersections should be of nearly consistent density over the surface of the sphere. The yarn will divide the surface of the sphere in to regions. If $A_i, A_j$ are the areas of any two of these regions then for some small constant F, $|A_i- A_j| < F$, $\forall i, j$. As the curve is extended further and further (wrapped around more times) the density of intersections should increase and $A_i \rightarrow 0$ for all of the regions. I know one answer is a randomly generated curve that deviates from a straight path. Overtime it produces a perfect yarn ball. I want to know if there is a non-random answer to this question. My own try: *In trying to solving this myself I thought it might be a good idea to project the sphere on to the plane, as a Riemann surface. But, since so many of the requirements focus on uniformity, this makes the problem a little strage. Observe:  The area of the regions will need to increase as we move away from the unit circle toward infinity. If the curve ever passes through the north pole, then the plane version would shoot off to infinity. What I found even more weird is what would happen if the curve simply passed very near, but not through, the north pole. Then, on the plane, the curve would go very far from the origin and then loop back.  By making the curve near enough to the north pole the loops can be as large as we please.  Since wrapping increases the density uniformly, if we observe the wrapping pattern projected on to the plane it would be like loopy knot that, over time, keeps casting bigger and bigger outlier loops, it would always grow and be un-bounded. (even without any intersection with the north pole!) The requirement about curvature, would mean that the knot could be more curvy inside of the unit circle, and then grow less curvy as we move away from the origin. I know of no such curve, and so I abandoned this way of thinking about the problem. But, I thought I'd share. * Updated to add a drawing of the projection idea. Update 2: Maybe if I projected the following polar plot back on to the Riemann sphere? The graph of the form $r= \theta^2 \sin (k \theta)$ produced good-looking results for $0 < k <1$... but all of the graphs are far too dense near the origin. Also, wrapping would start in a lop-sided manner, filling in the bottom of the sphere first then moving up... and never reaching the north pole!  But, maybe there is some way to tweak this? (This graph shows the kind of non-random pattern I have in mind for a solution. In a practical sense a solution to this problem could be used to wind spherical balls of ropes, yarns, or cords in a factory setting. Now, I will think about how I would instruct a robot to wind a yarn ball... if the robot is unable to do things randomly. What would you tell the robot to do? )",,"['differential-geometry', 'riemannian-geometry']"
71,Derivation of a representation through a vector field,Derivation of a representation through a vector field,,"Question: ( Exercise 3.4.12 - Sharpe ) Let $H$ be a Lie group, $V$ a vector space, and $\rho: H \to Gl(V)$ a representation. Let $U$ be a manifold, $X$ a vector field on $U$, and $h: U \to H$ and $f: U \to V$ smooth functions. Show that $$X(\rho (h^{-1})f) = \rho(h^{-1})X(f) - \rho_{*e}(Ad(h)(h^*\omega_H(H) )) f$$ where $\omega_H$ is a Maurer-Cartan form. Attempt: Here are some of the results I have used so far $(i)$ If $\iota : G \to G$ is the inverse function of $G$ and $\omega_H$ is a Maurer-Cartan form then $$\iota^* \omega_H(v) = - Ad(g)\omega_H(v) \,\,\, \text{for}\,\,\, v \in T_g(G)$$ $(ii)$ A smooth map $f:N \to M$ induces a pullback map $f^*: A^p(N,V) \to A^p(M,V)$ defined by $$(f^*\omega)_x (X_1, \ldots, X_p) = \omega_{f(x)} (f_*X_1, \ldots,f_*X_p)$$ where $X_1, \ldots, X_p \in T_x (M)$. By the Leibniz rule we have $$X(\rho (h^{-1})f)  = \rho (h^{-1})X(f) + X(\rho(h^{-1}))f$$ Now the idea was to show that $X(\rho(h^{-1})) = - \rho_{*e}(Ad(h)(h^*\omega_H(H) ))$. Thus, using the chain rule, $(i)$ and $(ii)$ we get $$\begin{align}X(\rho(h^{-1}))|_h &\underset{\text{def}}= \rho(h^{-1})_*(X_h)\\&\underset{\text{C.H.}}= (\rho_{*e}h^{-1}_*)(X)\\&=[\rho_{*e}(\iota h)_*](X)\\&\underset{\text{C.H.}}=\rho_{*e}[\iota_* h_*(X)]\\&=\rho_{*e}[L_{h*}\circ L_{h^{-1}*}\iota_* h_*(X)]\\&=\rho_{*e}[L_{h*}\omega_H(\iota_* h_*(X))]\\&\underset{\text(ii)}=\rho_{*e}[L_{h*}\iota^*(\omega_H(h_*X))]\\&\underset{\text{(ii)}}= \rho_{*e}[L_{h*} \iota^*(h^*\omega_H(X))]\\&\underset{\text{(i)}}= -\rho_{*e}[L_{h*}Ad(h)h^*\omega_H(X) ]\end{align}$$ this is what I got so far. $1)$ Is it correct? $2)$ What can be improved? $3)$ Where to go from here? 4) Should the vector field be considered left-invariant?","Question: ( Exercise 3.4.12 - Sharpe ) Let $H$ be a Lie group, $V$ a vector space, and $\rho: H \to Gl(V)$ a representation. Let $U$ be a manifold, $X$ a vector field on $U$, and $h: U \to H$ and $f: U \to V$ smooth functions. Show that $$X(\rho (h^{-1})f) = \rho(h^{-1})X(f) - \rho_{*e}(Ad(h)(h^*\omega_H(H) )) f$$ where $\omega_H$ is a Maurer-Cartan form. Attempt: Here are some of the results I have used so far $(i)$ If $\iota : G \to G$ is the inverse function of $G$ and $\omega_H$ is a Maurer-Cartan form then $$\iota^* \omega_H(v) = - Ad(g)\omega_H(v) \,\,\, \text{for}\,\,\, v \in T_g(G)$$ $(ii)$ A smooth map $f:N \to M$ induces a pullback map $f^*: A^p(N,V) \to A^p(M,V)$ defined by $$(f^*\omega)_x (X_1, \ldots, X_p) = \omega_{f(x)} (f_*X_1, \ldots,f_*X_p)$$ where $X_1, \ldots, X_p \in T_x (M)$. By the Leibniz rule we have $$X(\rho (h^{-1})f)  = \rho (h^{-1})X(f) + X(\rho(h^{-1}))f$$ Now the idea was to show that $X(\rho(h^{-1})) = - \rho_{*e}(Ad(h)(h^*\omega_H(H) ))$. Thus, using the chain rule, $(i)$ and $(ii)$ we get $$\begin{align}X(\rho(h^{-1}))|_h &\underset{\text{def}}= \rho(h^{-1})_*(X_h)\\&\underset{\text{C.H.}}= (\rho_{*e}h^{-1}_*)(X)\\&=[\rho_{*e}(\iota h)_*](X)\\&\underset{\text{C.H.}}=\rho_{*e}[\iota_* h_*(X)]\\&=\rho_{*e}[L_{h*}\circ L_{h^{-1}*}\iota_* h_*(X)]\\&=\rho_{*e}[L_{h*}\omega_H(\iota_* h_*(X))]\\&\underset{\text(ii)}=\rho_{*e}[L_{h*}\iota^*(\omega_H(h_*X))]\\&\underset{\text{(ii)}}= \rho_{*e}[L_{h*} \iota^*(h^*\omega_H(X))]\\&\underset{\text{(i)}}= -\rho_{*e}[L_{h*}Ad(h)h^*\omega_H(X) ]\end{align}$$ this is what I got so far. $1)$ Is it correct? $2)$ What can be improved? $3)$ Where to go from here? 4) Should the vector field be considered left-invariant?",,"['differential-geometry', 'proof-verification', 'lie-groups', 'differential-forms']"
72,How to Characterize Gradient Vector Fields?,How to Characterize Gradient Vector Fields?,,Let $V$ be a vector field on a smooth manifold $M$. Are there nice conditions under which there exists a (Riemannian) metric on $M$ such that $V$ is the gradient of some smooth function on $M$? One obstruction is that gradient vector fields have no closed integral curves (since a function is increasing on integral curves of its gradient).,Let $V$ be a vector field on a smooth manifold $M$. Are there nice conditions under which there exists a (Riemannian) metric on $M$ such that $V$ is the gradient of some smooth function on $M$? One obstruction is that gradient vector fields have no closed integral curves (since a function is increasing on integral curves of its gradient).,,"['differential-geometry', 'differential-topology']"
73,A space more fundamental than Euclidean space,A space more fundamental than Euclidean space,,"Summary: The mathematical physicist Paolo Budinich attributes to Élie Cartan the statement that the geometry of pure spinors is ""more elementary"" or more ""fundamental"" than Euclidean geometry, which is ""more complicated"".  This raises several questions: In what sense do pure spinors form a geometry?  What sort of geometry is this? Is there a precise sense in which this geometry is simpler than Euclidean geometry? Did Cartan ever make such a direct statement, or is Budinich inferring that Cartan held such views from the overall philosophy of Cartan's work?  What is the current status of this statement, e.g. vague philosophy, more or less precise body of conjecture, well-established theory? Budinich also suggests that there is a connection of this more fundamental geometry to the geometry of minimal surfaces, in particular, to the property that they are generated by null vectors by means of the Weierstrass–Enneper parameterization .  Is there some sort of geometry underlying the Weierstrass–Enneper parameterization that is more elementary or more fundamental than Euclidean geometry? Background: In a filmed conversation ( at $\color{blue}{\text{14:00}}$ mark ) involving Paolo Budinich, Abdus Salam, Dennis Sciama, and Ed Witten following Witten's 1986 Dirac Medal lecture (the caption at the start of the film, dating it to 1990, is certainly in error), Budinich makes the following remark: By which space-time is different than we thought. And by which I mean one could go back perhaps to Cartan who said the same thing in ’37, that Euclidean geometry is a very complicated geometry, while the geometry of zero vector is the more elementary one. Now there is a lot of zero vectors in these minimal surfaces—zero vectors. This was known 150 years ago, that zero vectors generate, by Weierstrass, minimal surfaces, so maybe that is also—that the Euclidean geometry is not the most elementary one. It seems likely that Budinich meant to say ""null vector"" here rather than ""zero vector"". The abstract of a contemporaneous paper by Budinich, P. Budinich, Null vectors, spinors, and strings, Commun. Math. Phys. 107 455–465 (1986), contains the following: It is shown how, in the frame of the Cartan conception of spinors, the old theorems on minimal surfaces, as generated from null curves formulated by Enneper–Weierstrass (1864–1866) for 3-dimensional ordinary space, and by Eisenhart (1911) for 4-dimensional space time, may be reformulated in terms of complex 2- and 4- component projective spinors respectively. A decade later, in the preprint Geometrical aspects of quantum mechanics in compactified momentum space , he writes of Cartan, He stressed the simplicity and elegance of spinor geometry and, because of this, he formulated the hypothesis of its fundamental character, insofar all the properties of euclidean geometry may be naturally derived from it, by considering the euclidean vectors as squares of simple spinors * (their components as bilinear polynomia of spinor components) [1]. * The historical fact that euclidean geometry was discovered long ago, and was thereafter universally considered as the most elementary form of geometry, might be due to the fact that its elements like planes, lines, points, are well accessible to our common, everyday intuition, based on our optical sensorial perceptions, while spinors were discovered much later, in the frame of advanced mathematics, and they are less accessible to our intuition, in fact a simple spinor may be conceived as a totally null plane, that is a plane whose (null) vectors are all orthogonal to each other, however, once the abstract mathematical reasoning is adopted, one is easily convinced of their geometrical simplicity and elegance which induced Cartan to formulate his conjecture on their fundamental role in elementary geometry. These quotations come from page 2 of the preprint.  Reference [1] is E. Cartan, Leçon sur la Théorie des Spinors (Hermann, Paris, 1937), which was translated into English as The Theory of Spinors .  The term ""simple spinor"" is used interchangeably with ""pure spinor"".  Similar statements can be found in many of Budinich's papers, spanning several decades. Remark: Michael Atiyah is quoted by G. Farmelo in his biography of Paul Dirac as having written No one fully understands spinors.  Their algebra is formally understood but their geometrical significance is mysterious.  In some sense they describe the 'square-root' of geometry and, just as understanding the concept of the square root of $-1$ took centuries, the same might be true of spinors. This seems to suggest that the idea that there is a simpler spinor geometry underlying Euclidean geometry is more of an uncompleted hope than a fully-developed theory.","Summary: The mathematical physicist Paolo Budinich attributes to Élie Cartan the statement that the geometry of pure spinors is ""more elementary"" or more ""fundamental"" than Euclidean geometry, which is ""more complicated"".  This raises several questions: In what sense do pure spinors form a geometry?  What sort of geometry is this? Is there a precise sense in which this geometry is simpler than Euclidean geometry? Did Cartan ever make such a direct statement, or is Budinich inferring that Cartan held such views from the overall philosophy of Cartan's work?  What is the current status of this statement, e.g. vague philosophy, more or less precise body of conjecture, well-established theory? Budinich also suggests that there is a connection of this more fundamental geometry to the geometry of minimal surfaces, in particular, to the property that they are generated by null vectors by means of the Weierstrass–Enneper parameterization .  Is there some sort of geometry underlying the Weierstrass–Enneper parameterization that is more elementary or more fundamental than Euclidean geometry? Background: In a filmed conversation ( at $\color{blue}{\text{14:00}}$ mark ) involving Paolo Budinich, Abdus Salam, Dennis Sciama, and Ed Witten following Witten's 1986 Dirac Medal lecture (the caption at the start of the film, dating it to 1990, is certainly in error), Budinich makes the following remark: By which space-time is different than we thought. And by which I mean one could go back perhaps to Cartan who said the same thing in ’37, that Euclidean geometry is a very complicated geometry, while the geometry of zero vector is the more elementary one. Now there is a lot of zero vectors in these minimal surfaces—zero vectors. This was known 150 years ago, that zero vectors generate, by Weierstrass, minimal surfaces, so maybe that is also—that the Euclidean geometry is not the most elementary one. It seems likely that Budinich meant to say ""null vector"" here rather than ""zero vector"". The abstract of a contemporaneous paper by Budinich, P. Budinich, Null vectors, spinors, and strings, Commun. Math. Phys. 107 455–465 (1986), contains the following: It is shown how, in the frame of the Cartan conception of spinors, the old theorems on minimal surfaces, as generated from null curves formulated by Enneper–Weierstrass (1864–1866) for 3-dimensional ordinary space, and by Eisenhart (1911) for 4-dimensional space time, may be reformulated in terms of complex 2- and 4- component projective spinors respectively. A decade later, in the preprint Geometrical aspects of quantum mechanics in compactified momentum space , he writes of Cartan, He stressed the simplicity and elegance of spinor geometry and, because of this, he formulated the hypothesis of its fundamental character, insofar all the properties of euclidean geometry may be naturally derived from it, by considering the euclidean vectors as squares of simple spinors * (their components as bilinear polynomia of spinor components) [1]. * The historical fact that euclidean geometry was discovered long ago, and was thereafter universally considered as the most elementary form of geometry, might be due to the fact that its elements like planes, lines, points, are well accessible to our common, everyday intuition, based on our optical sensorial perceptions, while spinors were discovered much later, in the frame of advanced mathematics, and they are less accessible to our intuition, in fact a simple spinor may be conceived as a totally null plane, that is a plane whose (null) vectors are all orthogonal to each other, however, once the abstract mathematical reasoning is adopted, one is easily convinced of their geometrical simplicity and elegance which induced Cartan to formulate his conjecture on their fundamental role in elementary geometry. These quotations come from page 2 of the preprint.  Reference [1] is E. Cartan, Leçon sur la Théorie des Spinors (Hermann, Paris, 1937), which was translated into English as The Theory of Spinors .  The term ""simple spinor"" is used interchangeably with ""pure spinor"".  Similar statements can be found in many of Budinich's papers, spanning several decades. Remark: Michael Atiyah is quoted by G. Farmelo in his biography of Paul Dirac as having written No one fully understands spinors.  Their algebra is formally understood but their geometrical significance is mysterious.  In some sense they describe the 'square-root' of geometry and, just as understanding the concept of the square root of $-1$ took centuries, the same might be true of spinors. This seems to suggest that the idea that there is a simpler spinor geometry underlying Euclidean geometry is more of an uncompleted hope than a fully-developed theory.",,"['differential-geometry', 'mathematical-physics', 'clifford-algebras', 'spin-geometry']"
74,The integral of a function on manifold and differential form,The integral of a function on manifold and differential form,,"When we want to integrate a function f over a manifold M, we may meet some problems, for example, the problem showed in the picture below: Then people used differential form to integrate. But it confused me:does that really solve the problem of integrating the function f on M? How can f be related directly to a k-form $\omega$? Is there a k-form $\omega$ to represent a specific function f on manifold M?","When we want to integrate a function f over a manifold M, we may meet some problems, for example, the problem showed in the picture below: Then people used differential form to integrate. But it confused me:does that really solve the problem of integrating the function f on M? How can f be related directly to a k-form $\omega$? Is there a k-form $\omega$ to represent a specific function f on manifold M?",,"['differential-geometry', 'manifolds', 'differential-forms', 'smooth-manifolds']"
75,Why is the surface of a torus flat?,Why is the surface of a torus flat?,,"Why is the surface of a torus is said to be flat? If you consider the geometry of the torus, its surface has locally positive (spherical), negative (hyperbolic) and flat curvature.","Why is the surface of a torus is said to be flat? If you consider the geometry of the torus, its surface has locally positive (spherical), negative (hyperbolic) and flat curvature.",,"['differential-geometry', 'curvature']"
76,Can $\mathbb CP^n$ be the boundary of a compact manifold?,Can  be the boundary of a compact manifold?,\mathbb CP^n,"Can $\mathbb CP^n$ be the boundary of a compact manifold? For example, when $n=1$, $\mathbb CP^n=S^2$, therefore it is the boundary of $B^3$.","Can $\mathbb CP^n$ be the boundary of a compact manifold? For example, when $n=1$, $\mathbb CP^n=S^2$, therefore it is the boundary of $B^3$.",,"['algebraic-topology', 'differential-geometry']"
77,"Prove a Levi-Civita connection gives $\nabla_XY(p)=\partial_t|_{t_0}[P^{-1}_{c_0,t_0,t}(Y(c(t)))]$ with $P$ parallel transport",Prove a Levi-Civita connection gives  with  parallel transport,"\nabla_XY(p)=\partial_t|_{t_0}[P^{-1}_{c_0,t_0,t}(Y(c(t)))] P","I'm having trouble with the following exercise in do Carmo's Riemannian geometry. Let $X$ and $Y$ be differentiable vector fields on a Riemannian manifold $M$. Let $p \in M$ and let $c: I \to M$ be an integral curve of $X$ through $p$, i.e. $c(t_0) = p$ and $\frac{dc}{dt} = X(c(t))$.  Prove that the Riemannian connection of $M$ is $(\nabla_XY \ )(p) = \frac{d}{dt} (P^{-1}_{c,t_0,t}(Y(c(t)))\ |_{t=t_0}$ where $P^{-1}_{c,t_0,t}: T_{c(t_0)}M \to T_{c(t)}M$ is the parallel transport along $c$, from $t_0$ to $t$. I guess, I don't have enough understanding of how to handle the parallel transport (since it is only given as the unique solution to a differential equation). Any hints would be greatly appreciated! Thank you, S. L. Edit: Do Carmo first introduced the notion of an affine connection $\nabla: \text{Vect}(M) \times \text{Vect}(M) \to \text{Vect}(M)$,   $(X,Y) \mapsto \nabla_XY$. With the following properties: $\nabla_{fX + gY}Z = f\nabla_XZ + g \nabla_YZ$ $\nabla_X(Y+Z) = \nabla_XY + \nabla_XZ$ $\nabla_X(fY) = f\nabla_XY + X(f)Y$ for $X,Y,Z \in \text{Vect}(M)$ and $f,g \in C^\infty(M)$. And then showed that there is a unique correspondence which associates to a vector field $V$ along the differentiable curve $c: I \to M$ another vector field $\frac{DV}{dt}$ along c, called covariant derivative of $V$ along $c$, with three more properties: $\frac{D}{dt}(V+W) =  \frac{D}{dt}V +  \frac{D}{dt}W$ $ \frac{D}{dt}(fV) =  \frac{df}{dt}V +  f\frac{D}{dt}V$ If $V$ is induced by a vector field $Y \in \text{Vect}(M), then  \frac{D}{dt}V = \nabla_{dc/dt}Y$ Then he showed existence and uniqueness of the parallel transport along a curve, and went on to prove existence and uniqueness of Levi-Civita connection. I hope this makes things clearer? Thanks for the quick answer!","I'm having trouble with the following exercise in do Carmo's Riemannian geometry. Let $X$ and $Y$ be differentiable vector fields on a Riemannian manifold $M$. Let $p \in M$ and let $c: I \to M$ be an integral curve of $X$ through $p$, i.e. $c(t_0) = p$ and $\frac{dc}{dt} = X(c(t))$.  Prove that the Riemannian connection of $M$ is $(\nabla_XY \ )(p) = \frac{d}{dt} (P^{-1}_{c,t_0,t}(Y(c(t)))\ |_{t=t_0}$ where $P^{-1}_{c,t_0,t}: T_{c(t_0)}M \to T_{c(t)}M$ is the parallel transport along $c$, from $t_0$ to $t$. I guess, I don't have enough understanding of how to handle the parallel transport (since it is only given as the unique solution to a differential equation). Any hints would be greatly appreciated! Thank you, S. L. Edit: Do Carmo first introduced the notion of an affine connection $\nabla: \text{Vect}(M) \times \text{Vect}(M) \to \text{Vect}(M)$,   $(X,Y) \mapsto \nabla_XY$. With the following properties: $\nabla_{fX + gY}Z = f\nabla_XZ + g \nabla_YZ$ $\nabla_X(Y+Z) = \nabla_XY + \nabla_XZ$ $\nabla_X(fY) = f\nabla_XY + X(f)Y$ for $X,Y,Z \in \text{Vect}(M)$ and $f,g \in C^\infty(M)$. And then showed that there is a unique correspondence which associates to a vector field $V$ along the differentiable curve $c: I \to M$ another vector field $\frac{DV}{dt}$ along c, called covariant derivative of $V$ along $c$, with three more properties: $\frac{D}{dt}(V+W) =  \frac{D}{dt}V +  \frac{D}{dt}W$ $ \frac{D}{dt}(fV) =  \frac{df}{dt}V +  f\frac{D}{dt}V$ If $V$ is induced by a vector field $Y \in \text{Vect}(M), then  \frac{D}{dt}V = \nabla_{dc/dt}Y$ Then he showed existence and uniqueness of the parallel transport along a curve, and went on to prove existence and uniqueness of Levi-Civita connection. I hope this makes things clearer? Thanks for the quick answer!",,['differential-geometry']
78,How to compute $I(d\omega)$? (Poincaré's Lemma),How to compute ? (Poincaré's Lemma),I(d\omega),"Suppose I have an $\ell$-form in $\Bbb R^n$ $$\omega=\sum_{i_1<\cdots<i_\ell}\omega_{i_1\cdots i_\ell} dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}$$ I will say this is written in the canonical form. Having written it canonically, define $I\omega$ to be the $\ell-1$ form that sends $x\in\Bbb R^n$ to $$I\omega(x)=\sum_{i_1<\cdots<i_\ell}\sum_{\alpha=1}^\ell (-1)^{\alpha-1}\int_0^1t^{\ell-1} \omega_{i_1\cdots i_\ell}(tx)dt \; x_{i_\alpha}\,\cdot dx_{i_1}\wedge\cdots \wedge \widehat{dx_{i_\alpha}}\wedge \cdots\wedge dx_{i_\ell}$$ where the hat means the term is ommited. We can denote this by $dx_{I,\alpha}$ for brevity. By linearity, we can focus on the basic forms $$\omega=f \;\cdot  dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}\;\;;\;\;i_1<\cdots <i_\ell$$ Again, in this case we will say this is written canonically. For brevity, will denote by $dx_I$ the full, ordered wedge product $dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}$. In this case $$I\omega(x)=\sum_{\alpha=1}^\ell (-1)^{\alpha-1}\int_0^1 t^{\ell-1} f(tx) dt\; x_{i_\alpha} \cdot dx_{I,\alpha}$$ Now, when we take the derivative of this, we get two parts by the product rule. First, $$\tag 1 \sum\limits_{\alpha  = 1}^\ell (-1)^{\alpha-1} {\int_0^1 {{t^{\ell  - 1}}} f\left( {tx} \right)dt\;\cdot d{x_{{i_\alpha }}} \wedge dx_{I,\alpha}}\\  = \int_0^1 {\ell {t^{\ell  - 1}}} f\left( {tx} \right)dt \cdot dx_I$$ since we move the form $dx_{i_\alpha}$, $\alpha-1$ places, filling the gap. While on the other hand we get $$\sum\limits_{\alpha  = 1}^\ell  {{{\left( { - 1} \right)}^{\alpha  - 1}}\sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt}\, {x_{{i_\alpha }}}\;\cdot dx_j\wedge dx_{I,\alpha}} $$ Now, consider the $\ell+1$ form $$d\omega  = \sum\limits_{j = 1}^n {{D_j}f} \;\cdot d{x_j} \wedge d{x_{{i_1}}} \wedge  \cdots  \wedge d{x_{{i_\ell }}}$$ This is not written canonically, but nevertheless we would like to find $I(d\omega)$. I should be getting that this is $$I(d\omega )\left( x \right) = \sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt}  {x_j}\cdot d{x_I} - \sum\limits_{\alpha  = 1}^\ell  {{{\left( { - 1} \right)}^{\alpha  - 1}}\sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt} x_{i_\alpha }\;\cdot  d{x_j} \wedge d{x_{I,\alpha }}} $$","Suppose I have an $\ell$-form in $\Bbb R^n$ $$\omega=\sum_{i_1<\cdots<i_\ell}\omega_{i_1\cdots i_\ell} dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}$$ I will say this is written in the canonical form. Having written it canonically, define $I\omega$ to be the $\ell-1$ form that sends $x\in\Bbb R^n$ to $$I\omega(x)=\sum_{i_1<\cdots<i_\ell}\sum_{\alpha=1}^\ell (-1)^{\alpha-1}\int_0^1t^{\ell-1} \omega_{i_1\cdots i_\ell}(tx)dt \; x_{i_\alpha}\,\cdot dx_{i_1}\wedge\cdots \wedge \widehat{dx_{i_\alpha}}\wedge \cdots\wedge dx_{i_\ell}$$ where the hat means the term is ommited. We can denote this by $dx_{I,\alpha}$ for brevity. By linearity, we can focus on the basic forms $$\omega=f \;\cdot  dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}\;\;;\;\;i_1<\cdots <i_\ell$$ Again, in this case we will say this is written canonically. For brevity, will denote by $dx_I$ the full, ordered wedge product $dx_{i_1}\wedge\cdots\wedge dx_{i_\ell}$. In this case $$I\omega(x)=\sum_{\alpha=1}^\ell (-1)^{\alpha-1}\int_0^1 t^{\ell-1} f(tx) dt\; x_{i_\alpha} \cdot dx_{I,\alpha}$$ Now, when we take the derivative of this, we get two parts by the product rule. First, $$\tag 1 \sum\limits_{\alpha  = 1}^\ell (-1)^{\alpha-1} {\int_0^1 {{t^{\ell  - 1}}} f\left( {tx} \right)dt\;\cdot d{x_{{i_\alpha }}} \wedge dx_{I,\alpha}}\\  = \int_0^1 {\ell {t^{\ell  - 1}}} f\left( {tx} \right)dt \cdot dx_I$$ since we move the form $dx_{i_\alpha}$, $\alpha-1$ places, filling the gap. While on the other hand we get $$\sum\limits_{\alpha  = 1}^\ell  {{{\left( { - 1} \right)}^{\alpha  - 1}}\sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt}\, {x_{{i_\alpha }}}\;\cdot dx_j\wedge dx_{I,\alpha}} $$ Now, consider the $\ell+1$ form $$d\omega  = \sum\limits_{j = 1}^n {{D_j}f} \;\cdot d{x_j} \wedge d{x_{{i_1}}} \wedge  \cdots  \wedge d{x_{{i_\ell }}}$$ This is not written canonically, but nevertheless we would like to find $I(d\omega)$. I should be getting that this is $$I(d\omega )\left( x \right) = \sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt}  {x_j}\cdot d{x_I} - \sum\limits_{\alpha  = 1}^\ell  {{{\left( { - 1} \right)}^{\alpha  - 1}}\sum\limits_{j = 1}^n {\int_0^1 {{t^\ell }{D_j}} f\left( {tx} \right)dt} x_{i_\alpha }\;\cdot  d{x_j} \wedge d{x_{I,\alpha }}} $$",,"['differential-geometry', 'differential-forms']"
79,"Proving that given any two points in a connected manifold, there exists a diffeomorphism taking one to the other","Proving that given any two points in a connected manifold, there exists a diffeomorphism taking one to the other",,"Suppose $M$ be a connected manifold and $x, y \in M$ are two points. Then I'm trying to show that there is a diffeomeorphism $f$ of $M$ that takes $x$ to $y$. Since the set of points for which there is a diffeomorphism of $M$ taking $x$ to that point is clopen and $M$ is connected, I think it should be enough to consider the case when both $x$ and $y$ lie in the same chart. But how do I proceed from here? I think I should somehow take a vector field and consider flows, but I'm not really sure. Can someone please provide a solution? Thanks in advance.","Suppose $M$ be a connected manifold and $x, y \in M$ are two points. Then I'm trying to show that there is a diffeomeorphism $f$ of $M$ that takes $x$ to $y$. Since the set of points for which there is a diffeomorphism of $M$ taking $x$ to that point is clopen and $M$ is connected, I think it should be enough to consider the case when both $x$ and $y$ lie in the same chart. But how do I proceed from here? I think I should somehow take a vector field and consider flows, but I'm not really sure. Can someone please provide a solution? Thanks in advance.",,"['differential-geometry', 'smooth-manifolds']"
80,Are there any simply connected parallelizable 4-manifolds?,Are there any simply connected parallelizable 4-manifolds?,,"On pp. 166 of Scorpan's ""The Wild World of 4--manifolds"", he gives an example of a parallelizable 4-manifold ($S^1\times S^3$) and then asserts: ""there are no simply connected examples"". It's confusing to me whether he means that there are no such examples in general, or examples that are 4-manifolds. In any case, here is my question: Do there exist (compact, smooth, oriented) simply connected manifolds that are parallelizable? 4-manifolds? (Recall that a manifold is called parallelizable if it has a trivial tangent bundle.)","On pp. 166 of Scorpan's ""The Wild World of 4--manifolds"", he gives an example of a parallelizable 4-manifold ($S^1\times S^3$) and then asserts: ""there are no simply connected examples"". It's confusing to me whether he means that there are no such examples in general, or examples that are 4-manifolds. In any case, here is my question: Do there exist (compact, smooth, oriented) simply connected manifolds that are parallelizable? 4-manifolds? (Recall that a manifold is called parallelizable if it has a trivial tangent bundle.)",,"['differential-geometry', 'algebraic-topology', 'vector-bundles', '4-manifolds']"
81,"Texts on Principal Bundles, Characteristic Classes, Intro to 4-manifolds / Gauge Theory","Texts on Principal Bundles, Characteristic Classes, Intro to 4-manifolds / Gauge Theory",,"I am looking for a textbook that might serve as an introduction to principal bundles, curvature forms and characteristic classes, and perhaps towards 4-manifolds and gauge theory. Currently, the only books I know of in this regard are: ""From Calculus to Cohomology"" (Madsen, Tornehave) ""Geometry of Differential Forms"" (Morita) ""Differential Forms in Algebraic Topology"" (Bott, Tu) I have been reading both ""Calculus to Cohomology"" and ""Geometry of Differential Forms,"" but am occasionally frustrated by the lack of thoroughness.  Both are at the perfect level for me, and cover almost exactly what I'm looking for, but I really prefer textbooks which are as thorough as possible, ideally to the extent of, say, John Lee's books (which I adore).  Meanwhile, Bott and Tu is a little advanced for me right now. Of course, I don't mean to be picky, but I also can't believe that the three I've listed are the most thorough accounts of the subject.","I am looking for a textbook that might serve as an introduction to principal bundles, curvature forms and characteristic classes, and perhaps towards 4-manifolds and gauge theory. Currently, the only books I know of in this regard are: ""From Calculus to Cohomology"" (Madsen, Tornehave) ""Geometry of Differential Forms"" (Morita) ""Differential Forms in Algebraic Topology"" (Bott, Tu) I have been reading both ""Calculus to Cohomology"" and ""Geometry of Differential Forms,"" but am occasionally frustrated by the lack of thoroughness.  Both are at the perfect level for me, and cover almost exactly what I'm looking for, but I really prefer textbooks which are as thorough as possible, ideally to the extent of, say, John Lee's books (which I adore).  Meanwhile, Bott and Tu is a little advanced for me right now. Of course, I don't mean to be picky, but I also can't believe that the three I've listed are the most thorough accounts of the subject.",,"['reference-request', 'differential-geometry', 'differential-topology', 'principal-bundles', 'gauge-theory']"
82,Why are geodesically convex sets diffeomorphic to $\Bbb R^n$?,Why are geodesically convex sets diffeomorphic to ?,\Bbb R^n,"In the construction of a good cover for a manifold $M^n$, Bott & Tu use the fact that each point in $M$ is contained in a geodesically convex set (after picking a Riemannian metric). They then claim that the intersection of geodesically convex sets is a geodesically convex set, and that makes sense. They further claim that any geodesically convex set is diffeomorphic to $\Bbb R^n$. For this, they reference Spivak, who does not actually show the last bit. Perhaps one way to do this is to show that the convex set is star-shaped, so the inverse image of it under the exponential map is convex, and somehow diffeomorphic to a ball, and thus to $\Bbb R^n$?","In the construction of a good cover for a manifold $M^n$, Bott & Tu use the fact that each point in $M$ is contained in a geodesically convex set (after picking a Riemannian metric). They then claim that the intersection of geodesically convex sets is a geodesically convex set, and that makes sense. They further claim that any geodesically convex set is diffeomorphic to $\Bbb R^n$. For this, they reference Spivak, who does not actually show the last bit. Perhaps one way to do this is to show that the convex set is star-shaped, so the inverse image of it under the exponential map is convex, and somehow diffeomorphic to a ball, and thus to $\Bbb R^n$?",,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'riemannian-geometry']"
83,Is the set of singular matrices ever a differentiable manifold?,Is the set of singular matrices ever a differentiable manifold?,,I can see that invertible matrices are a differentiable manifold however I don't know how to show that something is not a differentiable manifold so easily. Is it ever the case that singular matrices form a differentiable manifold?,I can see that invertible matrices are a differentiable manifold however I don't know how to show that something is not a differentiable manifold so easily. Is it ever the case that singular matrices form a differentiable manifold?,,['differential-geometry']
84,Is this surface diffeomorphic to a 2-sphere?,Is this surface diffeomorphic to a 2-sphere?,,"Let $f:\mathbb{R}^3\to \mathbb{R}$ be defined by $f(x,y,z)=x^4+y^6+z^8$ . Let $M=f^{−1}(1)$ . Is $M$ is diffeomorphic to a sphere $S^2$ ? I tried to solve this problem, but I realized that I have no tools to solve it. The constant rank theorem tells me $M$ is a smooth 2-dimensional manifold, but does not tell me how it looks like. And more generally, when is $N=\{x,y,z\in\mathbb{R}^3\mid ax^n+by^m+cz^l=1\}$ diffeomorphic to a sphere? What tools can I use to solve this problem? Thank you for reading. Hoping get some shedding light in your reply.","Let be defined by . Let . Is is diffeomorphic to a sphere ? I tried to solve this problem, but I realized that I have no tools to solve it. The constant rank theorem tells me is a smooth 2-dimensional manifold, but does not tell me how it looks like. And more generally, when is diffeomorphic to a sphere? What tools can I use to solve this problem? Thank you for reading. Hoping get some shedding light in your reply.","f:\mathbb{R}^3\to \mathbb{R} f(x,y,z)=x^4+y^6+z^8 M=f^{−1}(1) M S^2 M N=\{x,y,z\in\mathbb{R}^3\mid ax^n+by^m+cz^l=1\}","['differential-geometry', 'manifolds', 'morse-theory']"
85,Calculating the integral curves of a vector field,Calculating the integral curves of a vector field,,"How do I caluclate the integral curves of a vector field, i.e. how would I go about calculating the integral curves of: Define the vector field in $\mathbb{R}^3$ by: $ u = x_1\displaystyle\frac{\partial}{\partial x_2} +x_2\frac{\partial}{\partial x_1} + x_3\frac{\partial}{\partial x_3}$ Thanks for any help","How do I caluclate the integral curves of a vector field, i.e. how would I go about calculating the integral curves of: Define the vector field in $\mathbb{R}^3$ by: $ u = x_1\displaystyle\frac{\partial}{\partial x_2} +x_2\frac{\partial}{\partial x_1} + x_3\frac{\partial}{\partial x_3}$ Thanks for any help",,['differential-geometry']
86,Is the Structure Group of a Fibre Bundle Well-Defined?,Is the Structure Group of a Fibre Bundle Well-Defined?,,"Am I right in thinking that the structure group of a fibre bundle is any group $G$ of homeomorphisms of the fibre $F$ such that all transition functions map into $G$? Or is $G$ somehow the minimal such group, for all possible trivialisations? Another way of phrasing the question: am I correct in thinking that there are potentially many $G$-bundles which are the same as fibre bundles?","Am I right in thinking that the structure group of a fibre bundle is any group $G$ of homeomorphisms of the fibre $F$ such that all transition functions map into $G$? Or is $G$ somehow the minimal such group, for all possible trivialisations? Another way of phrasing the question: am I correct in thinking that there are potentially many $G$-bundles which are the same as fibre bundles?",,"['differential-geometry', 'group-actions', 'fiber-bundles']"
87,Definition of complex submanifold,Definition of complex submanifold,,"For smooth manifolds, we can define an embedded submanifold to be either (1) a subset locally cut out by ""slice"" charts, or (2) a subset that is a manifold in the subspace topology and admits a smooth structure such that the inclusion is smooth. These are equivalent (modulo details). What about the complex case? By analogy, we have: Definition 1. A subset $N$ of a complex manifold $M^m$ is called a complex submanifold of dimension $r$ if each point in $N$ has a neighborhood $U \subset M$ and a holomorphic chart $\phi: U \to \mathbb{C}^m$ such that $\phi(N \cap U)=\phi(U) \cap \mathbb{C}^r$. $$\text{vs.}$$ Definition 2. A subset $N$ of a complex manifold $M$ is called a complex submanifold if it is a smooth submanifold of $M$ admitting a complex structure such that the inclusion is holomorphic. Are these equivalent definitions of an embedded complex submanifold?","For smooth manifolds, we can define an embedded submanifold to be either (1) a subset locally cut out by ""slice"" charts, or (2) a subset that is a manifold in the subspace topology and admits a smooth structure such that the inclusion is smooth. These are equivalent (modulo details). What about the complex case? By analogy, we have: Definition 1. A subset $N$ of a complex manifold $M^m$ is called a complex submanifold of dimension $r$ if each point in $N$ has a neighborhood $U \subset M$ and a holomorphic chart $\phi: U \to \mathbb{C}^m$ such that $\phi(N \cap U)=\phi(U) \cap \mathbb{C}^r$. $$\text{vs.}$$ Definition 2. A subset $N$ of a complex manifold $M$ is called a complex submanifold if it is a smooth submanifold of $M$ admitting a complex structure such that the inclusion is holomorphic. Are these equivalent definitions of an embedded complex submanifold?",,"['differential-geometry', 'manifolds', 'complex-geometry']"
88,Visualizing Exterior Derivative,Visualizing Exterior Derivative,,"How do you visualize the exterior derivative of differential forms? I imagine differential forms to be some sort of (oriented) line segments, areas, volumes etc. That is if I imagine a two-form, I imagine two vectors, constituting a parallelogram. So I think provided I can imagine a field of oriented line segments, with exterior derivative I should imagine an appropriate field of oriented areas.","How do you visualize the exterior derivative of differential forms? I imagine differential forms to be some sort of (oriented) line segments, areas, volumes etc. That is if I imagine a two-form, I imagine two vectors, constituting a parallelogram. So I think provided I can imagine a field of oriented line segments, with exterior derivative I should imagine an appropriate field of oriented areas.",,"['differential-geometry', 'differential-forms', 'visualization']"
89,Is there a codifferential for a covariant exterior derivative?,Is there a codifferential for a covariant exterior derivative?,,"For forms on a Riemannian $n$-manifold $(M,g)$ there is a notion of a codifferential $\delta$, which is adjoint to the exterior derivative: $$\int \langle d \alpha, \beta \rangle \operatorname{vol} = \int \langle \alpha, \delta \beta \rangle \operatorname{vol} $$ $\langle \alpha, \beta \rangle$ is a scalar product of two differential forms induced by $g$, $\operatorname{vol}$ is a volume form, corresponding to $g$. Moreover, $\delta$ is defined through a Hodge star $*$ and exterior derivative $d$: $$   \delta : \Omega^k(M) \to \Omega^{k-1}(M) \\   \delta = (-1)^{n(k+1)+1}*d* $$ But since $M$ is Riemannian, $d$ can be extended with a Levi-Civita connection $\nabla$ to an exterior covariant derivative $d^\nabla$ to act on tensor-valued differential forms. Is there such a codifferential for $d^\nabla$ in such case, when scalar product of tensor-valued forms is considered? Is there an analogue of Hodge decomposition? And what happens in the special case of $M$ being Einstein manifold? Weaker question What is the adjoint $\nabla^*$ of Levi-Civita connection $\nabla : \Gamma(TM) \to \Gamma(TM \otimes T^*M)$ when acting on vector fields? $$\int \langle \nabla u, A \rangle \operatorname{vol} = \int \langle u, \nabla^* A \rangle \operatorname{vol} $$ $u \in \Gamma(TM)$ --- smooth vector fields, $A \in \Gamma(TM \otimes T^*M)$ --- a linear operator on vector fields. All the required conditions assumed on the boundary to get rid of boundary terms in integration by parts.","For forms on a Riemannian $n$-manifold $(M,g)$ there is a notion of a codifferential $\delta$, which is adjoint to the exterior derivative: $$\int \langle d \alpha, \beta \rangle \operatorname{vol} = \int \langle \alpha, \delta \beta \rangle \operatorname{vol} $$ $\langle \alpha, \beta \rangle$ is a scalar product of two differential forms induced by $g$, $\operatorname{vol}$ is a volume form, corresponding to $g$. Moreover, $\delta$ is defined through a Hodge star $*$ and exterior derivative $d$: $$   \delta : \Omega^k(M) \to \Omega^{k-1}(M) \\   \delta = (-1)^{n(k+1)+1}*d* $$ But since $M$ is Riemannian, $d$ can be extended with a Levi-Civita connection $\nabla$ to an exterior covariant derivative $d^\nabla$ to act on tensor-valued differential forms. Is there such a codifferential for $d^\nabla$ in such case, when scalar product of tensor-valued forms is considered? Is there an analogue of Hodge decomposition? And what happens in the special case of $M$ being Einstein manifold? Weaker question What is the adjoint $\nabla^*$ of Levi-Civita connection $\nabla : \Gamma(TM) \to \Gamma(TM \otimes T^*M)$ when acting on vector fields? $$\int \langle \nabla u, A \rangle \operatorname{vol} = \int \langle u, \nabla^* A \rangle \operatorname{vol} $$ $u \in \Gamma(TM)$ --- smooth vector fields, $A \in \Gamma(TM \otimes T^*M)$ --- a linear operator on vector fields. All the required conditions assumed on the boundary to get rid of boundary terms in integration by parts.",,"['reference-request', 'differential-geometry', 'riemannian-geometry', 'connections']"
90,How to introduce stress tensor on manifolds?,How to introduce stress tensor on manifolds?,,"I want to understand the type of stress tensor $\mathbf{P}$ in classical physics. Usually in physics it is said that the force $\text d \boldsymbol F$ (vector) acting on an infinitesimal area $\text d \boldsymbol s$ (vector) equals $\text d \boldsymbol F = \mathbf{P} \cdot \text d \boldsymbol s$ where $\cdot$ is a ""scalar product"". How can it be rigourised? I guess directed area can be $\star s$ where $s$ is a 2-form, but can I avoid using $\star$ by employing the volume form for example? The force should be 1-form. How is the power of surface forces is written? Usually it is given by $$\frac{dA}{dt} = \int_S \boldsymbol v \cdot \text d \boldsymbol F$$ $\boldsymbol v$ being the speed of the surface of the deformed body. What would be the corresponding local form, that is the power density of surface forces? UPDATE 1 If it helps, I found a whole appendix ""The Classical Cauchy Stress Tensor and Equations of Motion"" in the book ""The Geometry of Physics: An Introduction"" by Theodore Frankel. Particularly it says The Cauchy stress should be a vector-valued pseudo-$(n - 1)$-form. However currently I don't know what does it mean. Further development in the book is rather obscure and I'm afraid of that ""pseudo"". If a thing called ""pseudo-something"" I would prefer it stated as ""actual another thing"". UPDATE 2 Stress tensor can also be viewed as a (molecular) flux of momentum. Then the equation for balance of momentum would be the Newton's second law. Probably this approach would be more fruitful, analogues can be made with the flux of density.","I want to understand the type of stress tensor $\mathbf{P}$ in classical physics. Usually in physics it is said that the force $\text d \boldsymbol F$ (vector) acting on an infinitesimal area $\text d \boldsymbol s$ (vector) equals $\text d \boldsymbol F = \mathbf{P} \cdot \text d \boldsymbol s$ where $\cdot$ is a ""scalar product"". How can it be rigourised? I guess directed area can be $\star s$ where $s$ is a 2-form, but can I avoid using $\star$ by employing the volume form for example? The force should be 1-form. How is the power of surface forces is written? Usually it is given by $$\frac{dA}{dt} = \int_S \boldsymbol v \cdot \text d \boldsymbol F$$ $\boldsymbol v$ being the speed of the surface of the deformed body. What would be the corresponding local form, that is the power density of surface forces? UPDATE 1 If it helps, I found a whole appendix ""The Classical Cauchy Stress Tensor and Equations of Motion"" in the book ""The Geometry of Physics: An Introduction"" by Theodore Frankel. Particularly it says The Cauchy stress should be a vector-valued pseudo-$(n - 1)$-form. However currently I don't know what does it mean. Further development in the book is rather obscure and I'm afraid of that ""pseudo"". If a thing called ""pseudo-something"" I would prefer it stated as ""actual another thing"". UPDATE 2 Stress tensor can also be viewed as a (molecular) flux of momentum. Then the equation for balance of momentum would be the Newton's second law. Probably this approach would be more fruitful, analogues can be made with the flux of density.",,"['differential-geometry', 'manifolds', 'physics', 'tensors', 'classical-mechanics']"
91,uniqueness of the smooth structure on a manifold obtained by gluing,uniqueness of the smooth structure on a manifold obtained by gluing,,"I've just read a proof that If $M$, $N$ are smooth manifolds with boundary and $f: \partial M\rightarrow \partial N$ is a diffeomorphism then $M \cup_f N$ has a smooth manifold structure such that the obvious maps $M \rightarrow M \cup_f N$ and $N \rightarrow M \cup_f N$ are smooth imbeddings. The proof I read uses collar neighborhoods of the two boundaries to identify a neighborhood of the common boundary in the new manifold with a product of the common boundary and an interval. This left me wondering about the uniqueness of the smooth structure.  At first I thought it must be unique and I tried to show that the identity map is smooth but I couldn't show smoothness at points on the common boundary.  Then the thought of a decomposition of an exotic sphere into hemispheres made me think perhaps uniqueness isn't guaranteed. But then I wasn't sure whether the hemispheres were still $smooth$ submanifolds when you change to the exotic smooth structure.  Can anyone help me out by telling me whether we always have uniqueness and if so is it easy to see that the identity map will be smooth at points in the common boundary of M and N?  Thanks very much for your time.","I've just read a proof that If $M$, $N$ are smooth manifolds with boundary and $f: \partial M\rightarrow \partial N$ is a diffeomorphism then $M \cup_f N$ has a smooth manifold structure such that the obvious maps $M \rightarrow M \cup_f N$ and $N \rightarrow M \cup_f N$ are smooth imbeddings. The proof I read uses collar neighborhoods of the two boundaries to identify a neighborhood of the common boundary in the new manifold with a product of the common boundary and an interval. This left me wondering about the uniqueness of the smooth structure.  At first I thought it must be unique and I tried to show that the identity map is smooth but I couldn't show smoothness at points on the common boundary.  Then the thought of a decomposition of an exotic sphere into hemispheres made me think perhaps uniqueness isn't guaranteed. But then I wasn't sure whether the hemispheres were still $smooth$ submanifolds when you change to the exotic smooth structure.  Can anyone help me out by telling me whether we always have uniqueness and if so is it easy to see that the identity map will be smooth at points in the common boundary of M and N?  Thanks very much for your time.",,"['differential-geometry', 'differential-topology', 'manifolds']"
92,Exponential map on the $n$-sphere,Exponential map on the -sphere,n,"I might need some help on the following exercise : Let $\mathbb{S}^{n} \subset \mathbb{R}^{n+1}$ be the unit $n$-sphere. For any $p \in \mathbb{S}^{n}$, we have $$T_{p}\mathbb{S}^{n} = p^{\perp} = \lbrace v \in \mathbb{R}^{n+1}, \, p \cdot v = 0 \rbrace$$ The object of this exercise is to compute the exponential map $\exp \, : \, T\mathbb{S}^{n} \, \rightarrow \, \mathbb{S}^{n}$. Explain why, if $(M,g)$ is a Riemannian manifold, $x \in M$ and $f \, : \, M \, \rightarrow \, M$ an isometry such that $\mathrm{D}_{x}f \cdot v = v$ for some $v \in T_{x}M$ then, for the geodesic $\gamma \, : \, [a,b] \, \rightarrow \, M$ with $\gamma(0) =x$ and $\gamma'(0)=v$, we have $f \circ \gamma = \gamma$. Show that if $(p,v) \in T\mathbb{S}^{n}$ with $v \neq 0$, the reflection $R \, : \, \mathbb{R}^{n+1} \, \rightarrow \, \mathbb{R}^{n+1}$ that fixes pointwise the plane spanned by $p$ and $v$ and reverses all vectors perpendicular to $p$ and $v$ is an isometry of $\mathbb{S}^{n}$. Explain why this shows that the geodesic $\gamma \, : \, [a,b] \, \rightarrow \, \mathbb{S}^{n} \subset \mathbb{R}^{n+1}$ that satisfies $\gamma(0)=p$ and $\gamma'(0)=v$ must be of the form $ \gamma(t) = c(t) p + s(t) \frac{v}{\Vert v \Vert}$. Explain why we mush have $c(t) = \cos(t\Vert v \Vert)$ and $s(t) = \sin(t\Vert v \Vert)$. Here is what I did : Let $t \in [a,b]$. By definition, $ (f \circ \gamma)'(t) = \mathrm{D}_{t}(f \circ \gamma) \cdot \frac{d}{dt}$ and by the chain rule, $(f \circ \gamma)'(t) = \mathrm{D}_{\gamma(t)} f \circ \mathrm{D}_{t} \gamma \cdot \frac{d}{dt} = \mathrm{D}_{\gamma(t)} f \cdot \gamma'(t)$. It follows that $(f \circ \gamma)'(0) = \mathrm{D}_{x} f \cdot v = v$. Furthermore, if $L(\gamma)$ denotes the length of the curve $\gamma$, let $\tilde{\gamma}(t) = (f \circ \gamma)(t)$ and we have : $$ L(\tilde{\gamma}) = \int_{a}^{b} \Vert \dot{\tilde{\gamma}}(t) \Vert_{\tilde{\gamma}(t)} \: dt$$ where  $$ \begin{eqnarray*} \Vert \dot{\tilde{\gamma}}(t) \Vert_{\tilde{\gamma}(t)}^{2} & = & g_{\tilde{\gamma}(t)}\left( \dot{\tilde{\gamma}}(t) , \dot{\tilde{\gamma}}(t) \right) \\ & = & g_{(f \circ \gamma)(t)} \left( \mathrm{D}_{\gamma(t)} f \cdot \gamma'(t) , \mathrm{D}_{\gamma(t)} f \cdot \gamma'(t) \right) \\ & = & g_{\gamma(t)} \left( \gamma'(t) , \gamma'(t) \right) \\ & = & \Vert \dot{\gamma}(t) \Vert_{\gamma(t)}  \end{eqnarray*} $$ because $f$ is an isometry. We get $L(\tilde{\gamma}) = L(\gamma)$. I think it suffices to prove that $\tilde{\gamma} = \gamma$ but I don't know which theorem it follows from. (I'm not so sure for this one) Let $W = \mathrm{Vect}(p,v) = \mathrm{Vect}(p,\frac{v}{\Vert v \Vert})$. Since $\mathbb{R}^{n+1} = W \oplus W^{\perp}$, I can define the reflection $R$ on $\mathbb{R}^{n+1}$ as follows : $R = \mathrm{Id}$ on $W$ and $R = -\mathrm{Id}$ on $W^{\perp}$. Let $x \in \mathbb{S}^{n}$. There exists $\alpha \in W$ and $\beta \in W^{\perp}$ such that $x = \alpha + \beta$. Then, $R(x) = \alpha - \beta$. If $\Vert \cdot \Vert$ denotes the usual euclidean norm in $\mathbb{R}^{n+1}$, it follows from Pythagore's theorem that $\Vert R(x) \Vert = \Vert x \Vert$. So, $R$ is an isometry of $\mathbb{S}^{n}$. I think we need to use the result from 2. but I don't know how to use that $R \circ \gamma = \gamma$. I can use $\Vert \gamma'(t) \Vert = \Vert v \Vert$ and $\Vert \gamma(t) \Vert = 1$ for all $t \in [a,b]$. Since $p \cdot v = 0$, we have  $$ \Vert \gamma(t) \Vert^{2} = \vert c(t) \vert^{2} + \vert s(t) \vert^{2} = 1$$. So, we can say there exists some $\ell \in \mathbb{R}$ such that, for all $t \in [a,b]$, $c(t) = \cos(\ell t)$ and $s(t) = \sin(\ell t)$. From the condition $\Vert \gamma'(t) \Vert = \Vert v \Vert$, it follows that $\ell = \Vert v \Vert$. Thank you for your help !","I might need some help on the following exercise : Let $\mathbb{S}^{n} \subset \mathbb{R}^{n+1}$ be the unit $n$-sphere. For any $p \in \mathbb{S}^{n}$, we have $$T_{p}\mathbb{S}^{n} = p^{\perp} = \lbrace v \in \mathbb{R}^{n+1}, \, p \cdot v = 0 \rbrace$$ The object of this exercise is to compute the exponential map $\exp \, : \, T\mathbb{S}^{n} \, \rightarrow \, \mathbb{S}^{n}$. Explain why, if $(M,g)$ is a Riemannian manifold, $x \in M$ and $f \, : \, M \, \rightarrow \, M$ an isometry such that $\mathrm{D}_{x}f \cdot v = v$ for some $v \in T_{x}M$ then, for the geodesic $\gamma \, : \, [a,b] \, \rightarrow \, M$ with $\gamma(0) =x$ and $\gamma'(0)=v$, we have $f \circ \gamma = \gamma$. Show that if $(p,v) \in T\mathbb{S}^{n}$ with $v \neq 0$, the reflection $R \, : \, \mathbb{R}^{n+1} \, \rightarrow \, \mathbb{R}^{n+1}$ that fixes pointwise the plane spanned by $p$ and $v$ and reverses all vectors perpendicular to $p$ and $v$ is an isometry of $\mathbb{S}^{n}$. Explain why this shows that the geodesic $\gamma \, : \, [a,b] \, \rightarrow \, \mathbb{S}^{n} \subset \mathbb{R}^{n+1}$ that satisfies $\gamma(0)=p$ and $\gamma'(0)=v$ must be of the form $ \gamma(t) = c(t) p + s(t) \frac{v}{\Vert v \Vert}$. Explain why we mush have $c(t) = \cos(t\Vert v \Vert)$ and $s(t) = \sin(t\Vert v \Vert)$. Here is what I did : Let $t \in [a,b]$. By definition, $ (f \circ \gamma)'(t) = \mathrm{D}_{t}(f \circ \gamma) \cdot \frac{d}{dt}$ and by the chain rule, $(f \circ \gamma)'(t) = \mathrm{D}_{\gamma(t)} f \circ \mathrm{D}_{t} \gamma \cdot \frac{d}{dt} = \mathrm{D}_{\gamma(t)} f \cdot \gamma'(t)$. It follows that $(f \circ \gamma)'(0) = \mathrm{D}_{x} f \cdot v = v$. Furthermore, if $L(\gamma)$ denotes the length of the curve $\gamma$, let $\tilde{\gamma}(t) = (f \circ \gamma)(t)$ and we have : $$ L(\tilde{\gamma}) = \int_{a}^{b} \Vert \dot{\tilde{\gamma}}(t) \Vert_{\tilde{\gamma}(t)} \: dt$$ where  $$ \begin{eqnarray*} \Vert \dot{\tilde{\gamma}}(t) \Vert_{\tilde{\gamma}(t)}^{2} & = & g_{\tilde{\gamma}(t)}\left( \dot{\tilde{\gamma}}(t) , \dot{\tilde{\gamma}}(t) \right) \\ & = & g_{(f \circ \gamma)(t)} \left( \mathrm{D}_{\gamma(t)} f \cdot \gamma'(t) , \mathrm{D}_{\gamma(t)} f \cdot \gamma'(t) \right) \\ & = & g_{\gamma(t)} \left( \gamma'(t) , \gamma'(t) \right) \\ & = & \Vert \dot{\gamma}(t) \Vert_{\gamma(t)}  \end{eqnarray*} $$ because $f$ is an isometry. We get $L(\tilde{\gamma}) = L(\gamma)$. I think it suffices to prove that $\tilde{\gamma} = \gamma$ but I don't know which theorem it follows from. (I'm not so sure for this one) Let $W = \mathrm{Vect}(p,v) = \mathrm{Vect}(p,\frac{v}{\Vert v \Vert})$. Since $\mathbb{R}^{n+1} = W \oplus W^{\perp}$, I can define the reflection $R$ on $\mathbb{R}^{n+1}$ as follows : $R = \mathrm{Id}$ on $W$ and $R = -\mathrm{Id}$ on $W^{\perp}$. Let $x \in \mathbb{S}^{n}$. There exists $\alpha \in W$ and $\beta \in W^{\perp}$ such that $x = \alpha + \beta$. Then, $R(x) = \alpha - \beta$. If $\Vert \cdot \Vert$ denotes the usual euclidean norm in $\mathbb{R}^{n+1}$, it follows from Pythagore's theorem that $\Vert R(x) \Vert = \Vert x \Vert$. So, $R$ is an isometry of $\mathbb{S}^{n}$. I think we need to use the result from 2. but I don't know how to use that $R \circ \gamma = \gamma$. I can use $\Vert \gamma'(t) \Vert = \Vert v \Vert$ and $\Vert \gamma(t) \Vert = 1$ for all $t \in [a,b]$. Since $p \cdot v = 0$, we have  $$ \Vert \gamma(t) \Vert^{2} = \vert c(t) \vert^{2} + \vert s(t) \vert^{2} = 1$$. So, we can say there exists some $\ell \in \mathbb{R}$ such that, for all $t \in [a,b]$, $c(t) = \cos(\ell t)$ and $s(t) = \sin(\ell t)$. From the condition $\Vert \gamma'(t) \Vert = \Vert v \Vert$, it follows that $\ell = \Vert v \Vert$. Thank you for your help !",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
93,Torsion in two dimensions?,Torsion in two dimensions?,,"This question is about the notion of a connection with torsion in differential geometry, i.e., a connection that is not Levi-Civita. (It's not about the torsion of a curve in three dimensions.) Torsion has various physical applications in $\ge 4$ dimensions (Einstein-Cartan theory, string theory, experimental searches for coupling of spin to torsion) and in 3 dimensions ( crystallography ). The simplest examples of any given concept are always good to study, and lower-dimensional spaces are simpler. It seems that torsion should be a reasonable thing to study in two dimensions, although you can't have torsion that preserves tangent vectors, since there can't be a rotation around a fixed axis in two dimensions. This is equivalent to the fact that you can't have a totally antisymmetric torsion tensor $\tau_{abc}$ in two dimensions. Is there any mathematical reason why torsion in two dimensions is impossible, dull, or trivial? It would seem that if $\tau_{abc}$ is only required by definition to be antisymmetric on the two final indices, not all three, then you have 2 independent quantities, $\tau_{112}$ and $\tau_{212}$. Geometrically, I'm not clear on why there are two independent quantities and not just one. It seems to me that the only intrinsic quantity should be the failure of a parallelogram to close, and this should only give one degree of freedom, since I don't think the orientation of the parallelogram can make a difference in two dimensions. (A 90-degree rotation is the same as interchanging the two axes, which won't give an independent result.) If there is no mathematical reason why the 2-dimensional case doesn't work, are there any interesting real-world applications of torsion in two dimensions? Failing that, I would still be interested in any discussion of mathematically interesting, simple examples in two dimensions, e.g., a discussion of what phenomena  occur in a flat space with constant torsion, or a space of constant curvature with constant torsion. For example, I suppose that in the flat case with constant torsion, curves of extremal length are lines, whereas curves that parallel-transport their own tangent vectors are circles. In the positive-curvature case, I haven't thought this through carefully, but it seems that constant torsion on a sphere would be impossible due to something like the hairy ball theorem. Are there simple models of such geometries, in roughly the same sense that elliptic geometry can be modeled by identifying antipodal points on a sphere? (I know that you can't model a two-dimensional space with torsion in exactly this way, since all you naturally induce is the torsion-free structure.)","This question is about the notion of a connection with torsion in differential geometry, i.e., a connection that is not Levi-Civita. (It's not about the torsion of a curve in three dimensions.) Torsion has various physical applications in $\ge 4$ dimensions (Einstein-Cartan theory, string theory, experimental searches for coupling of spin to torsion) and in 3 dimensions ( crystallography ). The simplest examples of any given concept are always good to study, and lower-dimensional spaces are simpler. It seems that torsion should be a reasonable thing to study in two dimensions, although you can't have torsion that preserves tangent vectors, since there can't be a rotation around a fixed axis in two dimensions. This is equivalent to the fact that you can't have a totally antisymmetric torsion tensor $\tau_{abc}$ in two dimensions. Is there any mathematical reason why torsion in two dimensions is impossible, dull, or trivial? It would seem that if $\tau_{abc}$ is only required by definition to be antisymmetric on the two final indices, not all three, then you have 2 independent quantities, $\tau_{112}$ and $\tau_{212}$. Geometrically, I'm not clear on why there are two independent quantities and not just one. It seems to me that the only intrinsic quantity should be the failure of a parallelogram to close, and this should only give one degree of freedom, since I don't think the orientation of the parallelogram can make a difference in two dimensions. (A 90-degree rotation is the same as interchanging the two axes, which won't give an independent result.) If there is no mathematical reason why the 2-dimensional case doesn't work, are there any interesting real-world applications of torsion in two dimensions? Failing that, I would still be interested in any discussion of mathematically interesting, simple examples in two dimensions, e.g., a discussion of what phenomena  occur in a flat space with constant torsion, or a space of constant curvature with constant torsion. For example, I suppose that in the flat case with constant torsion, curves of extremal length are lines, whereas curves that parallel-transport their own tangent vectors are circles. In the positive-curvature case, I haven't thought this through carefully, but it seems that constant torsion on a sphere would be impossible due to something like the hairy ball theorem. Are there simple models of such geometries, in roughly the same sense that elliptic geometry can be modeled by identifying antipodal points on a sphere? (I know that you can't model a two-dimensional space with torsion in exactly this way, since all you naturally induce is the torsion-free structure.)",,['applications']
94,Difference between parallel transport and derivative of the exponential map,Difference between parallel transport and derivative of the exponential map,,"Given a Riemannian manifold $M$, let $c(t) = \exp_p(tX)$ be the geodesic emanating from $p \in M$ with initial value $X$. Let $t_0$ be small enough, then we have to ways to map $T_pM$ to $T_{c(t_0)} M$ isomorphically. One is the parallel transport along $c$, let's call it $P_{c, 0, t_0}$ and the other is given by $$ d \exp_p|_{tX}: T_{tX}T_pM \cong T_p M \longrightarrow T_{\exp_p(tX)}M = T_{c(t_0)}.$$ My question is: What is the relation between those two? The parallel transport is a linear isometry (in all dimensions), and the derivative of the exponential map is a radial isometry by the Gauss lemma (also in all dimensions), meaning $$ \langle d \exp_p|_{tX} \cdot Y, \dot{c}(t) \rangle = \langle Y, X \rangle $$ for all $Y \in T_pM$. In two dimensions, this means that the two mappings coincide up to scaling, as there is only on orthogonal direction to the radial one. However, in higher dimensions, this is not true, i guess, though I find it hard to actually compute examples... Are there formulas which relate the two concepts with curvature terms? \Edit: Computed that on $S^3$, conincides with the parallel transport except that vectors orthogonal to the direction of parallel transport are multiplied by $\frac{\sin r}{r}$.","Given a Riemannian manifold $M$, let $c(t) = \exp_p(tX)$ be the geodesic emanating from $p \in M$ with initial value $X$. Let $t_0$ be small enough, then we have to ways to map $T_pM$ to $T_{c(t_0)} M$ isomorphically. One is the parallel transport along $c$, let's call it $P_{c, 0, t_0}$ and the other is given by $$ d \exp_p|_{tX}: T_{tX}T_pM \cong T_p M \longrightarrow T_{\exp_p(tX)}M = T_{c(t_0)}.$$ My question is: What is the relation between those two? The parallel transport is a linear isometry (in all dimensions), and the derivative of the exponential map is a radial isometry by the Gauss lemma (also in all dimensions), meaning $$ \langle d \exp_p|_{tX} \cdot Y, \dot{c}(t) \rangle = \langle Y, X \rangle $$ for all $Y \in T_pM$. In two dimensions, this means that the two mappings coincide up to scaling, as there is only on orthogonal direction to the radial one. However, in higher dimensions, this is not true, i guess, though I find it hard to actually compute examples... Are there formulas which relate the two concepts with curvature terms? \Edit: Computed that on $S^3$, conincides with the parallel transport except that vectors orthogonal to the direction of parallel transport are multiplied by $\frac{\sin r}{r}$.",,"['differential-geometry', 'riemannian-geometry']"
95,Different definitions for submanifolds,Different definitions for submanifolds,,"I'm trying to better understand the concept of differentiable submanifold . However, it looks like many different definitions are adopted by various authors and so I'm trying to keep myself in sync by proving them equivalent. Now I'm stuck with the following two. Let $M$ denote a $n$-differentiable manifold and let $M' \subset M$: consider $M'$ equipped with the subspace topology. Also let $n' < n$ be an integer. I ) We say that $M'$ is a $n'$- submanifold of $M$ if it is locally a slice of coordinate system, i.e. for all $p'\in M'$ there exists a coordinate system $(U, x^1 \ldots x^n)$ for $M$ s.t. $$U \cap M'=\{ p \in M\mid x^{n'+1}(p)=\ldots=x^{n}(p)=0\}.$$ If this is the case $(U \cap M', x^1 \ldots x^{n'})$ is a local chart on $M'$ and the collection of such charts forms a differentiable atlas on it. II ) We say that $M'$ is a $n'$- submanifold of $M$ if for all $p'\in M'$ there exist an open neighborhood $U_{p'}$ of $p'$ in $M$ and a differentiable mapping $\tilde{F}_{p'} \colon U_{p'}\to \mathbb{R}^{n'}$ s.t.: i) The mapping $F_{p'}=\tilde{F}_{p'}|_{U_{p'} \cap M'}$ is one-one onto an open set $V$ of $\mathbb{R}^{n'}$; ii) The inverse mapping $F_{p'}^{-1}\colon V \to M$ is differentiable. If this is the case $(U_{p'}\cap M', F_{p'})$ is a local chart on $M'$ and the collection of such charts forms a differentiable atlas on it. The difficult part is proving that II $\Rightarrow$ I , that is, given a collection of $(U_{p'}\cap M', F_{p'})$ use them to show that $M'$ is locally a slice of some coordinate system. How do you build a coordinate system like that? Edit: Answer The following is based on Warner's Foundations of differentiable manifolds and Lie groups , Proposition 1.35. Let $M, M', p', U_{p'}, \tilde{F}_{p'}$ as in II and put $\tilde{F}_{p'}=(y^1\ldots y^{n'})$. Since $F_{p'}$ has a differentiable inverse, the functions $y^1 \ldots y^{n'}$ must be independent at $p'$ and so they form part of a local chart $(W, y=(y^1\ldots y^n))$, where $W$ is an open neighborhood of $p'$ in the big manifold $M$. With no loss of generality let us assume that $y(p')=(0\ldots 0)$. Now there is no need for the slice $\{p\in W \mid y^{n'+1}(p)=\ldots=y^{n}(p)=0\}$ to agree with $M'$. So we need to tweak this coordinate system a little. Define a mapping $Pr\colon W \to W \cap M'$ by setting $$Pr(p)=(y^1\ldots y^{n'})^{-1} (y^1(p) \ldots y^{n'}(p), 0 \ldots 0).$$ This mapping is best understood in coordinates: $Pr(p)$ is the unique point of $W\cap M'$ whose first $n'$ coordinates agree with the first $n'$ coordinates of $p$. It is clear that this mapping is differentiable (remember hypothesis (ii) above). Define functions $$z^i= \begin{cases}  y^i & i=1\ldots n' \\ y^i-y^i \circ Pr & i=n'+1 \ldots n  \end{cases};$$ those functions are independent at $p'$ and so they form a coordinate system in an open neighborhood $V$ of it. We have $\{p \in V \mid z^{n'+1}(p)=\ldots =z^n(p)=0\}=M' \cap V$: we have thus proven that $M'$ agrees locally with a slice of some coordinate system of $M$, that is, $M'$ verifies I . ////","I'm trying to better understand the concept of differentiable submanifold . However, it looks like many different definitions are adopted by various authors and so I'm trying to keep myself in sync by proving them equivalent. Now I'm stuck with the following two. Let $M$ denote a $n$-differentiable manifold and let $M' \subset M$: consider $M'$ equipped with the subspace topology. Also let $n' < n$ be an integer. I ) We say that $M'$ is a $n'$- submanifold of $M$ if it is locally a slice of coordinate system, i.e. for all $p'\in M'$ there exists a coordinate system $(U, x^1 \ldots x^n)$ for $M$ s.t. $$U \cap M'=\{ p \in M\mid x^{n'+1}(p)=\ldots=x^{n}(p)=0\}.$$ If this is the case $(U \cap M', x^1 \ldots x^{n'})$ is a local chart on $M'$ and the collection of such charts forms a differentiable atlas on it. II ) We say that $M'$ is a $n'$- submanifold of $M$ if for all $p'\in M'$ there exist an open neighborhood $U_{p'}$ of $p'$ in $M$ and a differentiable mapping $\tilde{F}_{p'} \colon U_{p'}\to \mathbb{R}^{n'}$ s.t.: i) The mapping $F_{p'}=\tilde{F}_{p'}|_{U_{p'} \cap M'}$ is one-one onto an open set $V$ of $\mathbb{R}^{n'}$; ii) The inverse mapping $F_{p'}^{-1}\colon V \to M$ is differentiable. If this is the case $(U_{p'}\cap M', F_{p'})$ is a local chart on $M'$ and the collection of such charts forms a differentiable atlas on it. The difficult part is proving that II $\Rightarrow$ I , that is, given a collection of $(U_{p'}\cap M', F_{p'})$ use them to show that $M'$ is locally a slice of some coordinate system. How do you build a coordinate system like that? Edit: Answer The following is based on Warner's Foundations of differentiable manifolds and Lie groups , Proposition 1.35. Let $M, M', p', U_{p'}, \tilde{F}_{p'}$ as in II and put $\tilde{F}_{p'}=(y^1\ldots y^{n'})$. Since $F_{p'}$ has a differentiable inverse, the functions $y^1 \ldots y^{n'}$ must be independent at $p'$ and so they form part of a local chart $(W, y=(y^1\ldots y^n))$, where $W$ is an open neighborhood of $p'$ in the big manifold $M$. With no loss of generality let us assume that $y(p')=(0\ldots 0)$. Now there is no need for the slice $\{p\in W \mid y^{n'+1}(p)=\ldots=y^{n}(p)=0\}$ to agree with $M'$. So we need to tweak this coordinate system a little. Define a mapping $Pr\colon W \to W \cap M'$ by setting $$Pr(p)=(y^1\ldots y^{n'})^{-1} (y^1(p) \ldots y^{n'}(p), 0 \ldots 0).$$ This mapping is best understood in coordinates: $Pr(p)$ is the unique point of $W\cap M'$ whose first $n'$ coordinates agree with the first $n'$ coordinates of $p$. It is clear that this mapping is differentiable (remember hypothesis (ii) above). Define functions $$z^i= \begin{cases}  y^i & i=1\ldots n' \\ y^i-y^i \circ Pr & i=n'+1 \ldots n  \end{cases};$$ those functions are independent at $p'$ and so they form a coordinate system in an open neighborhood $V$ of it. We have $\{p \in V \mid z^{n'+1}(p)=\ldots =z^n(p)=0\}=M' \cap V$: we have thus proven that $M'$ agrees locally with a slice of some coordinate system of $M$, that is, $M'$ verifies I . ////",,"['differential-geometry', 'differential-topology']"
96,What's the intuition behind the tangent bundle?,What's the intuition behind the tangent bundle?,,"Well, when we work with a smooth manifold $M$ we can associate with each point $p\in M$ a vector space $T_p M$ of all vectors at $p$ tangent to $M$: this is the space of linear functionals obeying liebniz rule in the algebra of germs of functions at $p$. This definition of vector is very intuitive, since it generalizes the main property of vectors in $\mathbb{R}^n$ of producing the directional derivative. Now, then we usually say: ""well, we must find a way to assemble all of the tangent spaces together to have a domain and range for the derivative"", then we define $TM$ as the disjoint union of all $T_p M$ and if $\pi : TM \to M$ is the projection on the first coordinate, we want to construct a vector bundle $\pi : TM \to M$. Now, what doesn't seem clear to me is why do we want the structure of a vector bundle. The definition of a fiber bundle is meant as I understand, to make a space that locally looks like a product space, but why do we want this? Is this because $T\mathbb{R}^n = \mathbb{R}^n \times \mathbb{R}^n$ and we want to ``copy'' this behavior locally? Also, how do we know that there's an obstruction in general to write $TM = M \times \mathbb{R}^n$? I've seem a question like this before here and there were answers based on hairy ball theorem and so on. The point is, this result needs that we first define $TM$ as it is define. If we don't know any of these theorems, how do we know that writing $TM$ that way is not possible? Thanks very much in advance for the aid!","Well, when we work with a smooth manifold $M$ we can associate with each point $p\in M$ a vector space $T_p M$ of all vectors at $p$ tangent to $M$: this is the space of linear functionals obeying liebniz rule in the algebra of germs of functions at $p$. This definition of vector is very intuitive, since it generalizes the main property of vectors in $\mathbb{R}^n$ of producing the directional derivative. Now, then we usually say: ""well, we must find a way to assemble all of the tangent spaces together to have a domain and range for the derivative"", then we define $TM$ as the disjoint union of all $T_p M$ and if $\pi : TM \to M$ is the projection on the first coordinate, we want to construct a vector bundle $\pi : TM \to M$. Now, what doesn't seem clear to me is why do we want the structure of a vector bundle. The definition of a fiber bundle is meant as I understand, to make a space that locally looks like a product space, but why do we want this? Is this because $T\mathbb{R}^n = \mathbb{R}^n \times \mathbb{R}^n$ and we want to ``copy'' this behavior locally? Also, how do we know that there's an obstruction in general to write $TM = M \times \mathbb{R}^n$? I've seem a question like this before here and there were answers based on hairy ball theorem and so on. The point is, this result needs that we first define $TM$ as it is define. If we don't know any of these theorems, how do we know that writing $TM$ that way is not possible? Thanks very much in advance for the aid!",,"['differential-geometry', 'manifolds', 'vector-bundles']"
97,Question about the proof of the index theorem appearing in Milnor's Morse Theory,Question about the proof of the index theorem appearing in Milnor's Morse Theory,,"I am trying to get through the proof of the index theorem. The background : I have been stuck for quite a while on the following point which Milnor says is evident: Let $\gamma: [0,1]\rightarrow M$ be a geodesic in a Riemannian manifold. Let $(t_0=0, t_1,…,t_k=1)$ be a partition of $[0,1]$ so that $\gamma$ sends $[t_i, t_{i+1}]$ into an open set U with the property that any two points in U can be connected by a distance minimizing geodesic which depends smoothly on the two endpoints.  If $\tau$ is between $t_j$ and $t_{j+1}$ then the space of ""broken"" Jacobi fields along $\gamma|_{[0,\tau]}$ (i.e. those piecewise smooth $V$ which are Jacobi fields along each piece of the partition of $[0, \tau]$) which vanish at $t=0$ and $t=\tau$ is isomorphic as a real vector space to the direct sum $T_{\gamma (t_1)}M\oplus...\oplus T_{\gamma (t_j)}M$ .  Call this latter sum $\Sigma$.  Then the Hessian of the energy function associated with $\gamma|_{[0,\tau]}$ (call it $E_\tau$) can be viewed as a bilinear form on $\Sigma$. My question: I want to know why this bilinear form should vary continuously with $(\tau, V, W) \in (t_j,t_{j+1})\times \Sigma \times \Sigma$.  I.e. if $V_\tau$ and $W_\tau$ are the broken Jacobi fields along $\gamma|_{[0,\tau]}$ associated with $V, W\in \Sigma$, why is $(t_j,t_{j+1})\times \Sigma \times \Sigma \rightarrow \mathbb{R}, (\tau, V, W)  \mapsto E_\tau (V_\tau , W_\tau )$ continuous? Where I am struck : From the second variation formula it seems as though I should start by proving that $D_t(V_\tau|_{[t_j,\tau]} )|_{t_j}$ varies continuously with $(\tau, V)$.  I'm having trouble showing this though.","I am trying to get through the proof of the index theorem. The background : I have been stuck for quite a while on the following point which Milnor says is evident: Let $\gamma: [0,1]\rightarrow M$ be a geodesic in a Riemannian manifold. Let $(t_0=0, t_1,…,t_k=1)$ be a partition of $[0,1]$ so that $\gamma$ sends $[t_i, t_{i+1}]$ into an open set U with the property that any two points in U can be connected by a distance minimizing geodesic which depends smoothly on the two endpoints.  If $\tau$ is between $t_j$ and $t_{j+1}$ then the space of ""broken"" Jacobi fields along $\gamma|_{[0,\tau]}$ (i.e. those piecewise smooth $V$ which are Jacobi fields along each piece of the partition of $[0, \tau]$) which vanish at $t=0$ and $t=\tau$ is isomorphic as a real vector space to the direct sum $T_{\gamma (t_1)}M\oplus...\oplus T_{\gamma (t_j)}M$ .  Call this latter sum $\Sigma$.  Then the Hessian of the energy function associated with $\gamma|_{[0,\tau]}$ (call it $E_\tau$) can be viewed as a bilinear form on $\Sigma$. My question: I want to know why this bilinear form should vary continuously with $(\tau, V, W) \in (t_j,t_{j+1})\times \Sigma \times \Sigma$.  I.e. if $V_\tau$ and $W_\tau$ are the broken Jacobi fields along $\gamma|_{[0,\tau]}$ associated with $V, W\in \Sigma$, why is $(t_j,t_{j+1})\times \Sigma \times \Sigma \rightarrow \mathbb{R}, (\tau, V, W)  \mapsto E_\tau (V_\tau , W_\tau )$ continuous? Where I am struck : From the second variation formula it seems as though I should start by proving that $D_t(V_\tau|_{[t_j,\tau]} )|_{t_j}$ varies continuously with $(\tau, V)$.  I'm having trouble showing this though.",,"['differential-geometry', 'riemannian-geometry', 'morse-theory']"
98,Polynomial in the components of the curvature tensor,Polynomial in the components of the curvature tensor,,"Consider a closed Riemannian manifold $(M,g)$ of dimension n and let $K(t,x,y)$ be its heat kernel. Then it is known that the heat kernel has an asymptotic expansion as $t\downarrow 0$: $$K(t,x,x)\sim (4\pi t)^{-n/2}\sum\limits_{k=0}^{\infty}u_k(x,x)t^k.$$ Often it is said that the functions $u_k(x.x)$ can be written as $O(n)-$invariant polynomials in the components of $R_x, (\nabla R)_x, (\nabla^2 R)_x,..., (\nabla^{2k-4} R)_x$ where $R$ denotes the Riemannian curvature tensor. The components of these polynomials do only depend on the dimension of $M$. I would really like to understand the above description for the functions $u_k(x,x)$ and need some help with it. My first naive interpretation would be the following: In order to evaluate $u_k(x,x)$, first choose an orthonormal basis $e_1,...,e_n$ of $T_xM$ and consider the 'components' of all the tensors above with respect to this orthonormal basis. The components would be: \begin{align} R_x &: \lbrace g(R(e_i,e_j)e_k, e_m) \vert i,j,k,m=1,...,n\rbrace \\  \nabla R_x&: \lbrace g(\nabla R(e_i,e_j,e_k,e_p), e_m)\vert i,j,k,m,p=1,...,n \rbrace ...\text{etc. up to $(\nabla^{4k-4}R)_x$} \end{align} There exist a polynomial $P_k(x)$ (only depending on $k$), $x\in\mathbb{R}^N$ with $N=N(k)$ sufficiently large and $$p(x)=\sum_{\alpha\in \mathbb{N_0}^N} a_{\alpha}x^{\alpha} $$ such that: 1)  the coefficients $a_{\alpha}\in\mathbb{R}$ do only depend on the dimension $n$ (but not the particular manifold $M$) 2) If we replace formally the variables $x_1,...,x_N$ by all of the components above, we get the value $u_k(x,x)$ 3) The value of the polynomial does not depend on the choice of orthonormal basis in $T_xM$. A different choice of orthonormal basis would obviously give rise to different components, but the values of the polynomial will not be effected by such a change of basis. (This would correspond to the $O(n)$-invariance of the polynomial) I am wondering if my interpretation is correct? Even if my suggestions are right, I am sure my interpretation is not the only possible or best one. So I would be glad if you could share your knowledge and can tell me different or better ways to handle this situation. Best wishes","Consider a closed Riemannian manifold $(M,g)$ of dimension n and let $K(t,x,y)$ be its heat kernel. Then it is known that the heat kernel has an asymptotic expansion as $t\downarrow 0$: $$K(t,x,x)\sim (4\pi t)^{-n/2}\sum\limits_{k=0}^{\infty}u_k(x,x)t^k.$$ Often it is said that the functions $u_k(x.x)$ can be written as $O(n)-$invariant polynomials in the components of $R_x, (\nabla R)_x, (\nabla^2 R)_x,..., (\nabla^{2k-4} R)_x$ where $R$ denotes the Riemannian curvature tensor. The components of these polynomials do only depend on the dimension of $M$. I would really like to understand the above description for the functions $u_k(x,x)$ and need some help with it. My first naive interpretation would be the following: In order to evaluate $u_k(x,x)$, first choose an orthonormal basis $e_1,...,e_n$ of $T_xM$ and consider the 'components' of all the tensors above with respect to this orthonormal basis. The components would be: \begin{align} R_x &: \lbrace g(R(e_i,e_j)e_k, e_m) \vert i,j,k,m=1,...,n\rbrace \\  \nabla R_x&: \lbrace g(\nabla R(e_i,e_j,e_k,e_p), e_m)\vert i,j,k,m,p=1,...,n \rbrace ...\text{etc. up to $(\nabla^{4k-4}R)_x$} \end{align} There exist a polynomial $P_k(x)$ (only depending on $k$), $x\in\mathbb{R}^N$ with $N=N(k)$ sufficiently large and $$p(x)=\sum_{\alpha\in \mathbb{N_0}^N} a_{\alpha}x^{\alpha} $$ such that: 1)  the coefficients $a_{\alpha}\in\mathbb{R}$ do only depend on the dimension $n$ (but not the particular manifold $M$) 2) If we replace formally the variables $x_1,...,x_N$ by all of the components above, we get the value $u_k(x,x)$ 3) The value of the polynomial does not depend on the choice of orthonormal basis in $T_xM$. A different choice of orthonormal basis would obviously give rise to different components, but the values of the polynomial will not be effected by such a change of basis. (This would correspond to the $O(n)$-invariance of the polynomial) I am wondering if my interpretation is correct? Even if my suggestions are right, I am sure my interpretation is not the only possible or best one. So I would be glad if you could share your knowledge and can tell me different or better ways to handle this situation. Best wishes",,"['differential-geometry', 'polynomials', 'riemannian-geometry', 'heat-equation', 'laplacian']"
99,The covering manifold of a complete Riemannian manifold is complete,The covering manifold of a complete Riemannian manifold is complete,,"This question is from Lectures on the Geometry of Manifolds by Nicolaescu. (Exercise 6.2.8 b) Let $(M,g)$ be a complete (connected) Riemannian manifold and let $(\tilde{M},\tilde{g})$ be its universal cover, $\pi:\tilde{M}\to M$ the covering transformation with $\tilde{g}=\pi^{\ast}g$. Prove that $(\tilde{M},\tilde{g})$ is complete. My thoughts: $\pi:\tilde{M}\to M$ is a local isometry. It suffices to prove that $\tilde{M}$ satisfies one of the hypotheses of Hopf-Rinow, and then we're done. My idea was to show that all geodesics on $\tilde{M}$ can be defined forever using a path-lifting argument. So if we have a geodesic for some $p\in M, V\in T_pM$, namely $\gamma:\mathbb{R}\to M$, take a fixed $q\in \pi^{-1}(p)$ and $X\in T_q\tilde{M}$ such that $d\pi_q(X)=V$ (since it is a local diffeomorphism), and let $\delta:(-\epsilon,\epsilon)\to \tilde{M}$ be a geodesic for $q,X$. Moreover, $\pi\circ \delta=\gamma$ at least on a small interval, because they have the same initial point and same initial derivative. Now, we can lift $\gamma$ to $\tilde{\gamma}:\mathbb{R}\to \tilde{M}$ starting at $q$. We have that $\pi\circ \tilde{\gamma}=\gamma$.By uniqueness, on a small interval, $\tilde{\gamma}=\delta$. Thus the geodesic $\delta$ can be extended to a map $\tilde{\gamma}:\mathbb{R}\to\tilde{M}$. Since this was arbitrary, $\tilde{M}$ is geodesically complete. Does this work? If not, how should I approach this problem?","This question is from Lectures on the Geometry of Manifolds by Nicolaescu. (Exercise 6.2.8 b) Let $(M,g)$ be a complete (connected) Riemannian manifold and let $(\tilde{M},\tilde{g})$ be its universal cover, $\pi:\tilde{M}\to M$ the covering transformation with $\tilde{g}=\pi^{\ast}g$. Prove that $(\tilde{M},\tilde{g})$ is complete. My thoughts: $\pi:\tilde{M}\to M$ is a local isometry. It suffices to prove that $\tilde{M}$ satisfies one of the hypotheses of Hopf-Rinow, and then we're done. My idea was to show that all geodesics on $\tilde{M}$ can be defined forever using a path-lifting argument. So if we have a geodesic for some $p\in M, V\in T_pM$, namely $\gamma:\mathbb{R}\to M$, take a fixed $q\in \pi^{-1}(p)$ and $X\in T_q\tilde{M}$ such that $d\pi_q(X)=V$ (since it is a local diffeomorphism), and let $\delta:(-\epsilon,\epsilon)\to \tilde{M}$ be a geodesic for $q,X$. Moreover, $\pi\circ \delta=\gamma$ at least on a small interval, because they have the same initial point and same initial derivative. Now, we can lift $\gamma$ to $\tilde{\gamma}:\mathbb{R}\to \tilde{M}$ starting at $q$. We have that $\pi\circ \tilde{\gamma}=\gamma$.By uniqueness, on a small interval, $\tilde{\gamma}=\delta$. Thus the geodesic $\delta$ can be extended to a map $\tilde{\gamma}:\mathbb{R}\to\tilde{M}$. Since this was arbitrary, $\tilde{M}$ is geodesically complete. Does this work? If not, how should I approach this problem?",,"['differential-geometry', 'riemannian-geometry']"
