,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Sum of Discrete Uniform Variables times extraction index,Sum of Discrete Uniform Variables times extraction index,,"Let $X_i$ be the $i-th$ extraction from an urn with $N$ balls numbered from $1$ to $N$. Let's make $N$ extractions without replacement, so that that the urn is left without balls. Let $Y_i = X_i \cdot i$ basically multiplying the number written on the extracted ball by the index of the extraction. Obviously $\Bbb E(Y_i) = i \cdot \frac{N+1}{2}$ You can get $Var(Y_i) = \frac{i^2(N^2-1)}{12}$ My question is $Var(\sum_{i=1}^N Y_i)$ Expected value of the sum is quite easy to find so let's assume we have it, any idea guys?","Let $X_i$ be the $i-th$ extraction from an urn with $N$ balls numbered from $1$ to $N$. Let's make $N$ extractions without replacement, so that that the urn is left without balls. Let $Y_i = X_i \cdot i$ basically multiplying the number written on the extracted ball by the index of the extraction. Obviously $\Bbb E(Y_i) = i \cdot \frac{N+1}{2}$ You can get $Var(Y_i) = \frac{i^2(N^2-1)}{12}$ My question is $Var(\sum_{i=1}^N Y_i)$ Expected value of the sum is quite easy to find so let's assume we have it, any idea guys?",,"['probability', 'probability-theory', 'statistics', 'variance']"
1,A case contains 5 red-wrapper chocolate and 10 white-wrapper chocolate. We randomly choose 8 chocolates at random without replacement.,A case contains 5 red-wrapper chocolate and 10 white-wrapper chocolate. We randomly choose 8 chocolates at random without replacement.,,"How likely is it that (a) 4 chocolates are red-wrapped? $\binom{5}{4}\binom{10}{4}\over\binom{15}{5}$ (b) all chocolates are white-wrapped? $\frac{10\times9\times8\times7\times6\times5\times4\times3}{15\times14\times13\times12\times11\times10\times9\times8}$ (c) at least one chocolate is red-wrapped? $\frac{C(10,8)}{C(15,8)}= \frac{45}{6435}$ $P=1-\frac{45}{6435}$ Have I done it correctly? Not sure how to go about it so I just followed the examples from the book. Would appreciate it if anyone could point out my mistakes.","How likely is it that (a) 4 chocolates are red-wrapped? $\binom{5}{4}\binom{10}{4}\over\binom{15}{5}$ (b) all chocolates are white-wrapped? $\frac{10\times9\times8\times7\times6\times5\times4\times3}{15\times14\times13\times12\times11\times10\times9\times8}$ (c) at least one chocolate is red-wrapped? $\frac{C(10,8)}{C(15,8)}= \frac{45}{6435}$ $P=1-\frac{45}{6435}$ Have I done it correctly? Not sure how to go about it so I just followed the examples from the book. Would appreciate it if anyone could point out my mistakes.",,"['probability', 'combinations']"
2,Is every continuous process an Ito process,Is every continuous process an Ito process,,"I see sometimes in Financial Maths literature that we have covered all continuous processes when assuming the following dynamics: $dX_t = \mu_t \, dt + \sigma_t \, dW_t$. I can formulate my question in two ways and I am not sure they are entirely equivalent: Is every continuous process an Ito process? Can every continuous process be decomposed in a Brownian part and a finite variation part (Semimartingale)? Thanks for your help.","I see sometimes in Financial Maths literature that we have covered all continuous processes when assuming the following dynamics: $dX_t = \mu_t \, dt + \sigma_t \, dW_t$. I can formulate my question in two ways and I am not sure they are entirely equivalent: Is every continuous process an Ito process? Can every continuous process be decomposed in a Brownian part and a finite variation part (Semimartingale)? Thanks for your help.",,"['probability', 'probability-theory', 'stochastic-processes', 'stochastic-calculus', 'brownian-motion']"
3,How to solve maximum likelihood estimates with inequality constraint?,How to solve maximum likelihood estimates with inequality constraint?,,"For example, let $ r_i \sim \operatorname{Binomial} (n, p_i)$, where $i \in [1,m]$. Assume that $ r_i $ are independent and also, put an inequality, $ p_1 < p_2 < \cdots < p_m $. How to find the maximum likelihood estimates of $ p_1, \ldots,p_m$ in such setting? I know the joint likelihood can be written as, $$ \sum_{i=1}^m \big(r_{i} \log p_{i} + (n-r_{i})\log(1-p_{i})\big)+ \text{constant}.$$ But how can I continue to derive the MLE with the constraint?","For example, let $ r_i \sim \operatorname{Binomial} (n, p_i)$, where $i \in [1,m]$. Assume that $ r_i $ are independent and also, put an inequality, $ p_1 < p_2 < \cdots < p_m $. How to find the maximum likelihood estimates of $ p_1, \ldots,p_m$ in such setting? I know the joint likelihood can be written as, $$ \sum_{i=1}^m \big(r_{i} \log p_{i} + (n-r_{i})\log(1-p_{i})\big)+ \text{constant}.$$ But how can I continue to derive the MLE with the constraint?",,"['probability', 'probability-theory', 'statistics', 'statistical-inference', 'maximum-likelihood']"
4,Quantile function for binomial distribution?,Quantile function for binomial distribution?,,"A test will succeed with a certain percentage. Now this test is repeated X number of times. I want to be able to get an estimate of the total number of succeeded test. Given that I know both the probability of success and the X number of attempts, is it possible to symbolically compute this estimate? I want to use this in a piece of software. Where I generate a random value [0, 1] and then use the requested formula as a mapping function. From what I gathered I need a quantile function of binomial distribution? Can I compute or estimate that one symbolically?","A test will succeed with a certain percentage. Now this test is repeated X number of times. I want to be able to get an estimate of the total number of succeeded test. Given that I know both the probability of success and the X number of attempts, is it possible to symbolically compute this estimate? I want to use this in a piece of software. Where I generate a random value [0, 1] and then use the requested formula as a mapping function. From what I gathered I need a quantile function of binomial distribution? Can I compute or estimate that one symbolically?",,"['probability', 'statistics', 'quantile']"
5,A Problem Dealing with putting balls in bin and Expected Value - possible wrong answer,A Problem Dealing with putting balls in bin and Expected Value - possible wrong answer,,"Please consider the problem below. Is my answer correct. If is not correct then where did I go wrong? Problem: You keep tossing balls into $n$ bins until one of the bins has two balls. For each toss there is a $\frac{1}{n}$ probability that the ball you toss lands in any one of the bins. What is the expected number of tosses? Answer: Let $p_i$ be the probability that after $i$ tosses we have at least one bin with two balls. \begin{eqnarray*} p_1 &=& 0 \\ p_2 &=& 1 - ( 1 - \frac{1}{n} ) = \frac{1}{n} \\ p_3 &=& 1 - (1 - \frac{1}{n})(1 - \frac{1}{n-1}) \\ p_3 &=& 1 - (\frac{n-1}{n})(\frac{n-1-1}{n-1}) \\ p_3 &=& 1 - (\frac{n-2}{n}) = \frac{2}{n} \\ p_4 &=& 1 - (1 - \frac{1}{n})(1 - \frac{1}{n-1})(1 - \frac{1}{n-2}) \\ p_4 &=& 1 - ( \frac{n-1}{n} )( \frac{n-2}{n-1} )( \frac{n - 2 -1}{n - 2} ) \\ p_4 &=& 1 - \frac{n-3}{n} = \frac{3}{n} \\ \end{eqnarray*} Now for $1 <= i <= n$ we have: $p_i = \frac{i-1}{n}$. \begin{eqnarray*} E &=& 2p_2 + 3p_3 + 4p_4 + ... (n+1)p_{n+1} \\ E &=& \sum_{i = 1}^{n} \frac{i(i+1)}{n} = \frac{1}{2n} \sum_{i=1}^{n} i^2 + i \\ E &=& \frac{1}{2n}(\frac{n(n+1)(2n+1)}{6} + \frac{n(n+1)}{2} ) \\ E &=& \frac{n+1}{4n} ( \frac{2n+1}{3} + 1 ) \\ \end{eqnarray*} Here is an update to my answer: Let $p_i$ be the probability that after $i$ tosses we have at least one bin with two balls. \newline \begin{eqnarray*} p_1 &=& 0 \\ p_2 &=& 1 - ( 1 - \frac{1}{n} ) = \frac{1}{n} \\ p_3 &=& 1 - (\frac{n-1}{n})( \frac{n-2}{n}) \\ p_3 &=& 1 - \frac{(n-1)(n-2)}{n^2} = \frac{n^2 - (n^2 - 3n + 2)}{n^2} \\ p_3 &=& \frac{3n-2}{n^2} \\ p_4 &=& 1 - (\frac{n-1}{n})(\frac{n-2}{n})(\frac{n-3}{n}) \\ p_4 &=& 1 - \frac{(n^2-3n+2)(n-3)}{n^3}\\ p_4 &=& 1 - \frac{n^3-3n^2+2n - 3n^2 +9n - 6}{n^3}\\ p_4 &=& \frac{3n^2-2n + 3n^2 - 9n + 6}{n^3}\\ p_4 &=& \frac{3n^2 + 3n^2 - 11n + 6}{n^3}\\ \end{eqnarray*} \begin{eqnarray*} E &=& 2p_2 + 3p_3 + 4p_4 + ... (n+1)p_{n+1} \\ \end{eqnarray*} Now, am on the right track? That is, is what I have so far correct? Thanks, Bob","Please consider the problem below. Is my answer correct. If is not correct then where did I go wrong? Problem: You keep tossing balls into $n$ bins until one of the bins has two balls. For each toss there is a $\frac{1}{n}$ probability that the ball you toss lands in any one of the bins. What is the expected number of tosses? Answer: Let $p_i$ be the probability that after $i$ tosses we have at least one bin with two balls. \begin{eqnarray*} p_1 &=& 0 \\ p_2 &=& 1 - ( 1 - \frac{1}{n} ) = \frac{1}{n} \\ p_3 &=& 1 - (1 - \frac{1}{n})(1 - \frac{1}{n-1}) \\ p_3 &=& 1 - (\frac{n-1}{n})(\frac{n-1-1}{n-1}) \\ p_3 &=& 1 - (\frac{n-2}{n}) = \frac{2}{n} \\ p_4 &=& 1 - (1 - \frac{1}{n})(1 - \frac{1}{n-1})(1 - \frac{1}{n-2}) \\ p_4 &=& 1 - ( \frac{n-1}{n} )( \frac{n-2}{n-1} )( \frac{n - 2 -1}{n - 2} ) \\ p_4 &=& 1 - \frac{n-3}{n} = \frac{3}{n} \\ \end{eqnarray*} Now for $1 <= i <= n$ we have: $p_i = \frac{i-1}{n}$. \begin{eqnarray*} E &=& 2p_2 + 3p_3 + 4p_4 + ... (n+1)p_{n+1} \\ E &=& \sum_{i = 1}^{n} \frac{i(i+1)}{n} = \frac{1}{2n} \sum_{i=1}^{n} i^2 + i \\ E &=& \frac{1}{2n}(\frac{n(n+1)(2n+1)}{6} + \frac{n(n+1)}{2} ) \\ E &=& \frac{n+1}{4n} ( \frac{2n+1}{3} + 1 ) \\ \end{eqnarray*} Here is an update to my answer: Let $p_i$ be the probability that after $i$ tosses we have at least one bin with two balls. \newline \begin{eqnarray*} p_1 &=& 0 \\ p_2 &=& 1 - ( 1 - \frac{1}{n} ) = \frac{1}{n} \\ p_3 &=& 1 - (\frac{n-1}{n})( \frac{n-2}{n}) \\ p_3 &=& 1 - \frac{(n-1)(n-2)}{n^2} = \frac{n^2 - (n^2 - 3n + 2)}{n^2} \\ p_3 &=& \frac{3n-2}{n^2} \\ p_4 &=& 1 - (\frac{n-1}{n})(\frac{n-2}{n})(\frac{n-3}{n}) \\ p_4 &=& 1 - \frac{(n^2-3n+2)(n-3)}{n^3}\\ p_4 &=& 1 - \frac{n^3-3n^2+2n - 3n^2 +9n - 6}{n^3}\\ p_4 &=& \frac{3n^2-2n + 3n^2 - 9n + 6}{n^3}\\ p_4 &=& \frac{3n^2 + 3n^2 - 11n + 6}{n^3}\\ \end{eqnarray*} \begin{eqnarray*} E &=& 2p_2 + 3p_3 + 4p_4 + ... (n+1)p_{n+1} \\ \end{eqnarray*} Now, am on the right track? That is, is what I have so far correct? Thanks, Bob",,"['probability', 'combinatorics']"
6,"Prove For $(X_n)_{n \geq1}$ independent RVs, $ X_n \rightarrow X \ \text{ a.s.} \Rightarrow \sum _{n\geq1} P(|X_n -X| \gt \varepsilon) \lt \infty$","Prove For  independent RVs,",(X_n)_{n \geq1}  X_n \rightarrow X \ \text{ a.s.} \Rightarrow \sum _{n\geq1} P(|X_n -X| \gt \varepsilon) \lt \infty,"I would like to show the following: For $(X_n)_{n \geq1}$ independent RVs, $$ X_n \rightarrow X \ \text{ a.s.} \Rightarrow\ \forall \varepsilon \gt0, \ \sum _{n\geq1} P(|X_n -X| \gt \varepsilon) \lt \infty$$ We don't know that $|X_n -X| \gt \varepsilon$ are independent so second Borel-Cantelli cannot be applied. Any hint is appreciated.","I would like to show the following: For $(X_n)_{n \geq1}$ independent RVs, $$ X_n \rightarrow X \ \text{ a.s.} \Rightarrow\ \forall \varepsilon \gt0, \ \sum _{n\geq1} P(|X_n -X| \gt \varepsilon) \lt \infty$$ We don't know that $|X_n -X| \gt \varepsilon$ are independent so second Borel-Cantelli cannot be applied. Any hint is appreciated.",,"['probability', 'borel-cantelli-lemmas']"
7,Finding probability of joint discrete rv,Finding probability of joint discrete rv,,"Let $X$ be poisson distribution with parameter $\lambda$ and $Y$   geometric with parameter $p$. Find $P(Y>X)$. ($\bf independent$) Attempt We know $p_X(x) = \frac{ e^{-\lambda} \lambda^x }{x!} $ and $p_Y(y) = (1-p)^{y-1} p$. Now, we have the region $\{(x,y) : y>x \}$ for integers $x,y$. We want to sum over this region. My thought is to first sum $y$ from $1$ to $\infty$ and $x$ is between $y$ and $\infty$. Thus, $$ P(Y>X) = \sum_{y=1}^{\infty} \sum_{x=y}^{\infty} \frac{ e^{-\lambda} \lambda^x }{x!} (1-p)^{y-1} p = pe^{-\lambda} \sum_{y=1}^{\infty} (1-p)^{y-1} \sum_{x=y}^{\infty} \frac{ \lambda^x}{x!} = p e^{-\lambda} \frac{1}{1-1+p} \sum_{x=y}^{\infty} \frac{ \lambda^x}{x!} = e^{- \lambda} \sum_{x=y}^{\infty} \frac{\lambda^x}{x!}$$ Here is where I get stuck. My answer key says it should $e^{- \lambda p }$. But I cant get to this answer. Any help?","Let $X$ be poisson distribution with parameter $\lambda$ and $Y$   geometric with parameter $p$. Find $P(Y>X)$. ($\bf independent$) Attempt We know $p_X(x) = \frac{ e^{-\lambda} \lambda^x }{x!} $ and $p_Y(y) = (1-p)^{y-1} p$. Now, we have the region $\{(x,y) : y>x \}$ for integers $x,y$. We want to sum over this region. My thought is to first sum $y$ from $1$ to $\infty$ and $x$ is between $y$ and $\infty$. Thus, $$ P(Y>X) = \sum_{y=1}^{\infty} \sum_{x=y}^{\infty} \frac{ e^{-\lambda} \lambda^x }{x!} (1-p)^{y-1} p = pe^{-\lambda} \sum_{y=1}^{\infty} (1-p)^{y-1} \sum_{x=y}^{\infty} \frac{ \lambda^x}{x!} = p e^{-\lambda} \frac{1}{1-1+p} \sum_{x=y}^{\infty} \frac{ \lambda^x}{x!} = e^{- \lambda} \sum_{x=y}^{\infty} \frac{\lambda^x}{x!}$$ Here is where I get stuck. My answer key says it should $e^{- \lambda p }$. But I cant get to this answer. Any help?",,['probability']
8,Ergodicity implies finite first moment in discrete time Markov chains?,Ergodicity implies finite first moment in discrete time Markov chains?,,"Suppose that $X(n)=(X_1(n),X_2(n))\in\mathbb{N}^2$ is a discrete time homogeneous Markov chain with uniformly bounded jumps (see below). Assume that the chain is ergodic and let $\pi$ be its invariant probability measure. If $Y$ is random variable distributed as $\pi$, is it true that $\mathbb{E}[Y]<\infty$? In other words, I'm interested in understanding whether ergodicity and uniformly bounded jumps ensure a finite first moment. Uniformly bounded jumps . I mean that there exists some finite $c>0$ such that the transition $x\mapsto x+(\Delta_1,\Delta_2)$ can occur only if $-c\le \Delta_1,\Delta_2<c$, for all $x$.","Suppose that $X(n)=(X_1(n),X_2(n))\in\mathbb{N}^2$ is a discrete time homogeneous Markov chain with uniformly bounded jumps (see below). Assume that the chain is ergodic and let $\pi$ be its invariant probability measure. If $Y$ is random variable distributed as $\pi$, is it true that $\mathbb{E}[Y]<\infty$? In other words, I'm interested in understanding whether ergodicity and uniformly bounded jumps ensure a finite first moment. Uniformly bounded jumps . I mean that there exists some finite $c>0$ such that the transition $x\mapsto x+(\Delta_1,\Delta_2)$ can occur only if $-c\le \Delta_1,\Delta_2<c$, for all $x$.",,"['probability', 'probability-theory', 'markov-chains', 'markov-process']"
9,"Expectation of Minimum Value of 4 Distinct Integers from the Set $ \left\{1, 2, 3, \ldots, 47, 48 \right\}$.",Expectation of Minimum Value of 4 Distinct Integers from the Set .," \left\{1, 2, 3, \ldots, 47, 48 \right\}","Suppose I choose $4$ distinct integers from the set $\{1,2,3,...,47,48\}$. What would be the expectation of the minimum of the four numbers (say $X$). My attempt: Using tail sum formula we get: $P(X\geq1)+...+P(X\geq45) = \frac{48C4}{48C4}+\frac{47C4}{48C4}+...+\frac{4C4}{48C4}.$ Where can I go from here? P.S. is there a way to approach this question from a more intuitive sense?","Suppose I choose $4$ distinct integers from the set $\{1,2,3,...,47,48\}$. What would be the expectation of the minimum of the four numbers (say $X$). My attempt: Using tail sum formula we get: $P(X\geq1)+...+P(X\geq45) = \frac{48C4}{48C4}+\frac{47C4}{48C4}+...+\frac{4C4}{48C4}.$ Where can I go from here? P.S. is there a way to approach this question from a more intuitive sense?",,"['probability', 'combinatorics', 'combinations', 'expectation']"
10,Joint pdf of uniform dependent random variables,Joint pdf of uniform dependent random variables,,"Take $n$ non-negative dependent random variables $X_1,...,X_n$ with $Pr(X_i \leq t) = t, t\in[0,1]$ for every $i$ (uniform marginal distributions). What is an example of a joint pdf for $X_1,...,X_n$ (with the given common marginal distribution), such that $E[\min_i X_i] = 1/2$?","Take $n$ non-negative dependent random variables $X_1,...,X_n$ with $Pr(X_i \leq t) = t, t\in[0,1]$ for every $i$ (uniform marginal distributions). What is an example of a joint pdf for $X_1,...,X_n$ (with the given common marginal distribution), such that $E[\min_i X_i] = 1/2$?",,"['probability', 'probability-theory', 'expectation']"
11,Branching process and calculating the probability of extinction,Branching process and calculating the probability of extinction,,"Suppose the male descendants of a man follow a branching process.We further suppose that each man has 3 children, and the number of male descendants follows a binomial distribution, Bin(3,0.5). (a) What is the probability that Guy A line of male descendants will become extinct by the third generation? How about becoming extinct exactly at the third generation? (b) Suppose Guy B has two sons and a daughter.What is the probability that Guy B line of male descendants will eventually become extinct? I have just started learning the branching process and not sure whether I did the question correctly.My working for the question is as follows, (a) I know that the generation function is of the form: $$P(s)=\frac18 + \frac38 s + \frac38 s^2 + \frac18 s^3 = \frac18(1+s)^3,$$ Let Un=P(Xn=0) where Xn denotes the number male descendants at time n. $$U(1)=P(X1=0)=\frac18$$ $$U(2)=P(U(1))=\frac{729}{4096}$$ $$U(3)=P(U(2))\approx 0.204325$$ Let T=min{n $\ge$ 1 : Xn=0) So I think the question in part (a) is asking P(T$\le$3|X0=1) and U(3), $$P(T\le3|X0=1)=U(1)+U(2)+U(3)\approx 0.5073$$ (b) If the initial generation has 1 male descendant, then the probability of it being extinction will be equals to solving P(u)=u where $0<u<1$. Solving it I get that the roots of u are 1,$-2+\sqrt 5$,$-2-\sqrt5$. Since $0<u<1$, then the probability of it being extinct given that guy B initial generation has 2 male descendants will be: $$(-2+\sqrt 5)^2=9-4\sqrt5$$","Suppose the male descendants of a man follow a branching process.We further suppose that each man has 3 children, and the number of male descendants follows a binomial distribution, Bin(3,0.5). (a) What is the probability that Guy A line of male descendants will become extinct by the third generation? How about becoming extinct exactly at the third generation? (b) Suppose Guy B has two sons and a daughter.What is the probability that Guy B line of male descendants will eventually become extinct? I have just started learning the branching process and not sure whether I did the question correctly.My working for the question is as follows, (a) I know that the generation function is of the form: $$P(s)=\frac18 + \frac38 s + \frac38 s^2 + \frac18 s^3 = \frac18(1+s)^3,$$ Let Un=P(Xn=0) where Xn denotes the number male descendants at time n. $$U(1)=P(X1=0)=\frac18$$ $$U(2)=P(U(1))=\frac{729}{4096}$$ $$U(3)=P(U(2))\approx 0.204325$$ Let T=min{n $\ge$ 1 : Xn=0) So I think the question in part (a) is asking P(T$\le$3|X0=1) and U(3), $$P(T\le3|X0=1)=U(1)+U(2)+U(3)\approx 0.5073$$ (b) If the initial generation has 1 male descendant, then the probability of it being extinction will be equals to solving P(u)=u where $0<u<1$. Solving it I get that the roots of u are 1,$-2+\sqrt 5$,$-2-\sqrt5$. Since $0<u<1$, then the probability of it being extinct given that guy B initial generation has 2 male descendants will be: $$(-2+\sqrt 5)^2=9-4\sqrt5$$",,"['probability', 'stochastic-processes']"
12,Probability basics,Probability basics,,Just a quick Q on the last question (c). Based on research of the average lifetime a couple assumes a probability of $0.75$ that the husband will still be alive in $20$ years while the wife has a chance of $0.8$. How likely are the following events? (a) Both are still alive in $20$ years. $$P(A∩B)= 0.75 \cdot 0.8$$ (b) None of them is still alive in $20$ years. $$P(A∩B)= 0.25 \cdot 0.2$$ (c) At least one of them is still alive in $20$ years. Now for c I used $$P(A∪B)= 0.75 + 0.8 -(0.75\cdot0.8)$$ but my friend said it's wrong and said I should use $(A∩B)$ but with additions. Is this correct? Was I wrong?,Just a quick Q on the last question (c). Based on research of the average lifetime a couple assumes a probability of $0.75$ that the husband will still be alive in $20$ years while the wife has a chance of $0.8$. How likely are the following events? (a) Both are still alive in $20$ years. $$P(A∩B)= 0.75 \cdot 0.8$$ (b) None of them is still alive in $20$ years. $$P(A∩B)= 0.25 \cdot 0.2$$ (c) At least one of them is still alive in $20$ years. Now for c I used $$P(A∪B)= 0.75 + 0.8 -(0.75\cdot0.8)$$ but my friend said it's wrong and said I should use $(A∩B)$ but with additions. Is this correct? Was I wrong?,,"['probability', 'probability-distributions']"
13,Probability : Roll of Die,Probability : Roll of Die,,"$\textsf{A}$ and $\textsf{B}$ are playing a game with $2$ standard dice. Both the dice are rolled together and the total is counted. $\textsf{A}$ says that a total of $2$ will be rolled first. $\textsf{B}$, whereas, says that two Consecutive totals of $7$′s will be rolled first. They keep rolling the dice till one of them wins !. What is the probability that $\textsf{A}$ wins the game ?. For a total of $2$, $\{(1,1)\}$ and for a total of $7$, $\{(1,6),(6,1),(2,4),(4,2),(3,4),(4,3)\}$ are the required scenarios. I don't understand how we need to incorporate the probabilities of $\textsf{A}$ winning, i.e., $1/36$ and $\textsf{B}$ winning, i.e. $6/36$ into a game of infinite rounds, i.e. until $\textsf{A}$ wins. –","$\textsf{A}$ and $\textsf{B}$ are playing a game with $2$ standard dice. Both the dice are rolled together and the total is counted. $\textsf{A}$ says that a total of $2$ will be rolled first. $\textsf{B}$, whereas, says that two Consecutive totals of $7$′s will be rolled first. They keep rolling the dice till one of them wins !. What is the probability that $\textsf{A}$ wins the game ?. For a total of $2$, $\{(1,1)\}$ and for a total of $7$, $\{(1,6),(6,1),(2,4),(4,2),(3,4),(4,3)\}$ are the required scenarios. I don't understand how we need to incorporate the probabilities of $\textsf{A}$ winning, i.e., $1/36$ and $\textsf{B}$ winning, i.e. $6/36$ into a game of infinite rounds, i.e. until $\textsf{A}$ wins. –",,['probability']
14,Combinatorial proof or interpretation of Bezout relation between $(1-p)^n$ and $p^m$?,Combinatorial proof or interpretation of Bezout relation between  and ?,(1-p)^n p^m,"Let $T_{n,m}(p)=\sum_{j=0}^{m-1} \binom{n+j-1}{j}p^j$. In answering a recent question , I discovered the identity $$ (1-p)^n T_{n,m}(p)+ p^m T_{m,n}(1-p)=1 \tag{1} $$ Is there a nice combinatorial proof or interpretation of (1) ? ($p$ looks a lot like the probablity of something in this formula, doesn't it.) I've got a feeling that this question is a duplicate of an already existing question, but my search was unsuccessful. UPDATE : as explained in orangeskid's answer to the abovelinked question, (1) can be nicely derived by expanding Newton's binomial in $(p+(1-p))^{n+m-1}=1$.  But this is still more computational than really combinatoric/probabilistic, I'm still waiting for a more direct interpretation of $T_{n,m}(p)$ and (1).","Let $T_{n,m}(p)=\sum_{j=0}^{m-1} \binom{n+j-1}{j}p^j$. In answering a recent question , I discovered the identity $$ (1-p)^n T_{n,m}(p)+ p^m T_{m,n}(1-p)=1 \tag{1} $$ Is there a nice combinatorial proof or interpretation of (1) ? ($p$ looks a lot like the probablity of something in this formula, doesn't it.) I've got a feeling that this question is a duplicate of an already existing question, but my search was unsuccessful. UPDATE : as explained in orangeskid's answer to the abovelinked question, (1) can be nicely derived by expanding Newton's binomial in $(p+(1-p))^{n+m-1}=1$.  But this is still more computational than really combinatoric/probabilistic, I'm still waiting for a more direct interpretation of $T_{n,m}(p)$ and (1).",,"['probability', 'combinatorics', 'polynomials', 'probability-distributions']"
15,Probability that A wins a best of 7 (4 matches),Probability that A wins a best of 7 (4 matches),,"$A$ and $B$ play a series of best of $4$. The probability that $A$ wins a given game is $p$. Assume that the games are independent of each other. What is the probability that $A$ wins? Let $A_{i}$ be the event that $A$ wins the series in $i$ matches. Then, the book states, $$P(A) = P(A_{4}) + P(A_{5}) + P(A_{6}) + P(A_{7}) = p^{4} + \binom{4}{3}p^{4}q + \binom{5}{3}p^{4}q^{2} + \binom{6}{3}p^{4}q^{3}.$$ I am having a bit of trouble understanding the calculation. I am trying to be a bit more formal here. As an example, lets concentrate on $A_{5}$. It really is $A \cap G_{5}$ where $G_{i}$ is the event that $i$ matches were played in the series. Then, $$P(A_{5}) = P(A \cap G_{5}) = P(A|G_{5})P(G_{5}) = \binom{5}{4}p^{4}qP(G_{5}).$$ Now, we equate this term to $P(A_{5})$ to get $\binom{5}{4}p^{4}qP(G_{5}) = \binom{4}{3}p^{4}q$, from which we get, $$P(G_{5}) = \frac{\binom{4}{3}}{\binom{5}{4}}.$$ Is this complete nonsense? If not, can someone give me an intuition for $P(G_{5})$? It just doesn't click in my head right now. To rephrase, $P(A_{5}) = \binom{4}{3}p^{4}q$ was given in the answer, but in my attempt, I have this $P(G_{5})$ term which I am not sure how to find without the equation $\binom{5}{4}p^{4}qP(G_{5}) = \binom{4}{3}p^{4}q$.","$A$ and $B$ play a series of best of $4$. The probability that $A$ wins a given game is $p$. Assume that the games are independent of each other. What is the probability that $A$ wins? Let $A_{i}$ be the event that $A$ wins the series in $i$ matches. Then, the book states, $$P(A) = P(A_{4}) + P(A_{5}) + P(A_{6}) + P(A_{7}) = p^{4} + \binom{4}{3}p^{4}q + \binom{5}{3}p^{4}q^{2} + \binom{6}{3}p^{4}q^{3}.$$ I am having a bit of trouble understanding the calculation. I am trying to be a bit more formal here. As an example, lets concentrate on $A_{5}$. It really is $A \cap G_{5}$ where $G_{i}$ is the event that $i$ matches were played in the series. Then, $$P(A_{5}) = P(A \cap G_{5}) = P(A|G_{5})P(G_{5}) = \binom{5}{4}p^{4}qP(G_{5}).$$ Now, we equate this term to $P(A_{5})$ to get $\binom{5}{4}p^{4}qP(G_{5}) = \binom{4}{3}p^{4}q$, from which we get, $$P(G_{5}) = \frac{\binom{4}{3}}{\binom{5}{4}}.$$ Is this complete nonsense? If not, can someone give me an intuition for $P(G_{5})$? It just doesn't click in my head right now. To rephrase, $P(A_{5}) = \binom{4}{3}p^{4}q$ was given in the answer, but in my attempt, I have this $P(G_{5})$ term which I am not sure how to find without the equation $\binom{5}{4}p^{4}qP(G_{5}) = \binom{4}{3}p^{4}q$.",,['probability']
16,Probability Problem based on the a set of numbers. Determine if the number is divisible by three,Probability Problem based on the a set of numbers. Determine if the number is divisible by three,,"Three distinct numbers are selected at random from the set $\{1,2,3,4,5,6\}$. What is the probability that their product is divisible by $3$? I think that since because $3$ and $6$ are the only numbers that divide into three with an integer remainder, the number would have to have $3$ or $6$ in the unit's digit. Since this is the case the probability would be  $2/6$ or $1/3$. Have I done anything wrong?","Three distinct numbers are selected at random from the set $\{1,2,3,4,5,6\}$. What is the probability that their product is divisible by $3$? I think that since because $3$ and $6$ are the only numbers that divide into three with an integer remainder, the number would have to have $3$ or $6$ in the unit's digit. Since this is the case the probability would be  $2/6$ or $1/3$. Have I done anything wrong?",,['probability']
17,Expected value of exactly one ball in n balls in n boxes,Expected value of exactly one ball in n balls in n boxes,,"$n$ balls are placed randomly into $n$ boxes. Let $N_1$ be the number of boxes with exactly one ball. Find $E(N_1)$. Show it is about $\frac{n}{e}$ I tried breaking it into indicator variables, where $N_1 = L_1 + L_2 + ... + L_n$ Where $L_i = 1$ if box i has ball 1, and $0$ otherwise, Then (I think) $P(L_i = 1) = \frac{(n-1)^{n-1}}{n^n}$ And since this is a binomial distribution, $E(N_1) = n\frac{(n-1)^{n-1}}{n^n}$ But I'm not sure how to get this to $\frac{n}{e}$","$n$ balls are placed randomly into $n$ boxes. Let $N_1$ be the number of boxes with exactly one ball. Find $E(N_1)$. Show it is about $\frac{n}{e}$ I tried breaking it into indicator variables, where $N_1 = L_1 + L_2 + ... + L_n$ Where $L_i = 1$ if box i has ball 1, and $0$ otherwise, Then (I think) $P(L_i = 1) = \frac{(n-1)^{n-1}}{n^n}$ And since this is a binomial distribution, $E(N_1) = n\frac{(n-1)^{n-1}}{n^n}$ But I'm not sure how to get this to $\frac{n}{e}$",,"['probability', 'combinatorics']"
18,Normal random variables: expectation of squared empirical mean divided by empirical second moment,Normal random variables: expectation of squared empirical mean divided by empirical second moment,,"Assume $X_1,\dotsc, X_n$ are iid $\mathcal{N}(\mu, \sigma^2)$-distributed. Define $m=\frac{1}{n} \sum_{i=1}^n X_i$ the empirical mean and $z^2 = \frac{1}{n} \sum_{i=1}^n X_i^2$ the empirical second moment. I am looking for the expectation $$\mathbf{E}\left[\frac{m^2}{z^2}\right].$$ The ultimate goal is to estimate the quantity $$\frac{\mu^2}{\mu^2 + \sigma^2}.$$ What I know so far: Since $z^2\geq m^2$ (Jensen's inequality), the fraction is bounded and the expectation exists. $m\sim \mathcal{N}(\mu, \frac{\sigma^2}{n})$ and, thus, $\mathbf{E}[m^2] = \mu^2 + \frac{\sigma^2}{n}$ $\mathbf{E}[z^2] = \mu^2 + \sigma^2$ $n\frac{z^2}{\sigma^2} = \sum_{i=1}^n \left( \frac{X_i}{\sigma} \right)^2$ follows a non-central chi-squared distribution with $n$ degrees of freedom and non-centrality parameter $\lambda = n\frac{\mu^2}{\sigma^2}$ $m^2$ and $z^2$ are obviously dependent, but $m$ is independent of the empirical variance $s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - m)^2 = \frac{n}{n-1} (z^2 - m^2)$. It is straight-forward to derive an expression for $\mathbf{cov}(m^2, z^2)$ Does anybody have an idea how to compute $\mathbf{E}[\frac{m^2}{z^2}]$ and/or how to estimate $\frac{\mu^2}{\mu^2+\sigma^2}$?","Assume $X_1,\dotsc, X_n$ are iid $\mathcal{N}(\mu, \sigma^2)$-distributed. Define $m=\frac{1}{n} \sum_{i=1}^n X_i$ the empirical mean and $z^2 = \frac{1}{n} \sum_{i=1}^n X_i^2$ the empirical second moment. I am looking for the expectation $$\mathbf{E}\left[\frac{m^2}{z^2}\right].$$ The ultimate goal is to estimate the quantity $$\frac{\mu^2}{\mu^2 + \sigma^2}.$$ What I know so far: Since $z^2\geq m^2$ (Jensen's inequality), the fraction is bounded and the expectation exists. $m\sim \mathcal{N}(\mu, \frac{\sigma^2}{n})$ and, thus, $\mathbf{E}[m^2] = \mu^2 + \frac{\sigma^2}{n}$ $\mathbf{E}[z^2] = \mu^2 + \sigma^2$ $n\frac{z^2}{\sigma^2} = \sum_{i=1}^n \left( \frac{X_i}{\sigma} \right)^2$ follows a non-central chi-squared distribution with $n$ degrees of freedom and non-centrality parameter $\lambda = n\frac{\mu^2}{\sigma^2}$ $m^2$ and $z^2$ are obviously dependent, but $m$ is independent of the empirical variance $s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - m)^2 = \frac{n}{n-1} (z^2 - m^2)$. It is straight-forward to derive an expression for $\mathbf{cov}(m^2, z^2)$ Does anybody have an idea how to compute $\mathbf{E}[\frac{m^2}{z^2}]$ and/or how to estimate $\frac{\mu^2}{\mu^2+\sigma^2}$?",,"['probability', 'statistics', 'probability-distributions']"
19,Fourier analysis step in an example regarding concentration of measure.,Fourier analysis step in an example regarding concentration of measure.,,"I am following Terrence Tao's notes on concentration of measures here , Tao defines ${S_n := X_1+\ldots+X_n}$ Then at a certain point he says: ""suppose that ${n = 2^m-1}$, and that ${X_j := (-1)^{a_j \cdot Y}}$, where ${Y}$ is drawn uniformly at random from the cube ${\{0,1\}^m}$, and ${a_1,\ldots,a_n}$ are an enumeration of the non-zero elements of ${\{0,1\}^m}$. Then a little Fourier analysis shows that each ${X_j}$ for ${1 \leq j \leq n}$ has mean zero, variance ${1}$, and are pairwise independent in ${j}$; but ${S_n}$ is equal to ${(n+1) {\bf I}( Y = 0 ) - 1}$, which is equal to ${n}$ with probability ${1/(n+1)}$; this is despite the standard deviation of ${S}$ being just ${\sqrt{n}}$."" What is this little Fourier analysis that makes the facts stated obvious?","I am following Terrence Tao's notes on concentration of measures here , Tao defines ${S_n := X_1+\ldots+X_n}$ Then at a certain point he says: ""suppose that ${n = 2^m-1}$, and that ${X_j := (-1)^{a_j \cdot Y}}$, where ${Y}$ is drawn uniformly at random from the cube ${\{0,1\}^m}$, and ${a_1,\ldots,a_n}$ are an enumeration of the non-zero elements of ${\{0,1\}^m}$. Then a little Fourier analysis shows that each ${X_j}$ for ${1 \leq j \leq n}$ has mean zero, variance ${1}$, and are pairwise independent in ${j}$; but ${S_n}$ is equal to ${(n+1) {\bf I}( Y = 0 ) - 1}$, which is equal to ${n}$ with probability ${1/(n+1)}$; this is despite the standard deviation of ${S}$ being just ${\sqrt{n}}$."" What is this little Fourier analysis that makes the facts stated obvious?",,"['probability', 'probability-theory', 'measure-theory', 'fourier-analysis']"
20,"Bags, probability and recurrence","Bags, probability and recurrence",,"I need help on this one: There are two bags, each of them contain $n$ balls. The first bag contains only white balls. The second bag contains only black balls. Pick one black ball and input it to first bag. Then choose one ball from first bag randomly and and throw out it. Repeat this process while second bag is not empty. Question: What is probability that last selected ball from first bag is white? I guess there are some recurrence formula for this probability...","I need help on this one: There are two bags, each of them contain $n$ balls. The first bag contains only white balls. The second bag contains only black balls. Pick one black ball and input it to first bag. Then choose one ball from first bag randomly and and throw out it. Repeat this process while second bag is not empty. Question: What is probability that last selected ball from first bag is white? I guess there are some recurrence formula for this probability...",,"['probability', 'combinatorics', 'recurrence-relations']"
21,"If a segment of length 1 is randomly divided into n intervals, with what probability are all intervals are less than 1/k?","If a segment of length 1 is randomly divided into n intervals, with what probability are all intervals are less than 1/k?",,"If $n-1$ points are chosen at random on a line segment of length $1$ (with uniform distribution), thus dividing it into $n$ segments, what is the probability that no segment has a length greater than $1/k$? I've gotten this far as of now- For $k=2$, only one segment can be greater than $1/2$, so, the probability is just 1 - n times the probability of first segment being of length greater than $1/2$. so $P = 1-(n/2^{n-1})$","If $n-1$ points are chosen at random on a line segment of length $1$ (with uniform distribution), thus dividing it into $n$ segments, what is the probability that no segment has a length greater than $1/k$? I've gotten this far as of now- For $k=2$, only one segment can be greater than $1/2$, so, the probability is just 1 - n times the probability of first segment being of length greater than $1/2$. so $P = 1-(n/2^{n-1})$",,"['probability', 'combinatorics', 'probability-distributions']"
22,Resnick - Probability Path - Exercise 6.16 (c),Resnick - Probability Path - Exercise 6.16 (c),,"I'm trying to solve the following exercise from Resnick's books: For any sequence of random variables {$X_n$} set $S_n = \sum_{i=1}^{n}X_i$ (c) Show $X_n \xrightarrow{P} 0$ does NOT imply $S_n/n \xrightarrow{P} 0$. Hint: Try $X_n = 2^n$ with probability $n^{-1}$ and $=0$ with probability  $1-n^{-1}.$ I could show the first part, that $X_n \xrightarrow{P} 0$, by taking: $\lim_{n\to\infty}P(X_n = 0) = \lim_{n\to\infty}(1-\frac{1}{n}) = 1$ $\Rightarrow \lim_{n\to\infty}P(|X_n - 0|\leq \epsilon) =1 $ $\Rightarrow \lim_{n\to\infty}P(|X_n - 0|> \epsilon) =0 $, by taking complements. How can I show the second part, that $S_n/n \xrightarrow{P} 0$ does not apply?","I'm trying to solve the following exercise from Resnick's books: For any sequence of random variables {$X_n$} set $S_n = \sum_{i=1}^{n}X_i$ (c) Show $X_n \xrightarrow{P} 0$ does NOT imply $S_n/n \xrightarrow{P} 0$. Hint: Try $X_n = 2^n$ with probability $n^{-1}$ and $=0$ with probability  $1-n^{-1}.$ I could show the first part, that $X_n \xrightarrow{P} 0$, by taking: $\lim_{n\to\infty}P(X_n = 0) = \lim_{n\to\infty}(1-\frac{1}{n}) = 1$ $\Rightarrow \lim_{n\to\infty}P(|X_n - 0|\leq \epsilon) =1 $ $\Rightarrow \lim_{n\to\infty}P(|X_n - 0|> \epsilon) =0 $, by taking complements. How can I show the second part, that $S_n/n \xrightarrow{P} 0$ does not apply?",,"['probability', 'convergence-divergence', 'random-variables']"
23,How do we convert a generating function that counts to a generating function of probabilities?,How do we convert a generating function that counts to a generating function of probabilities?,,"I am learning about the binomial coefficient and counting. We define:  $$ (1+x)^m = \sum^m_{n=0} \begin{pmatrix}  m \\ n \end{pmatrix} x^n $$ the coefficients of the powers of $x^n$ represent the number of ways of choosing $n$ objects from a set of $m$. Is there a way to convert this into a probability distribution by dividing each coefficient by  $$  \sum^m_{n=0} \begin{pmatrix}  m \\ n \end{pmatrix}.  $$ Example We have a set of three objects, $\{a, b , c\}$, we can draw 1 object three ways $(a + b + c)$, two objects three ways $(ab + ac + bc)$ and three objects one way $(abc)$. Then, $$ (1+x)^3 = 1x^0 + 3x^1 + 3x^2 + 1x^3  $$ If we divide each coefficient by the sum of coefficients (in this case 8) then they represent probabilities(?). Can we then say that $(1+x)^n$ is the generator for a distribution function $$ p_n = \frac{1}{\sum^m_{n=0} \begin{pmatrix}m \\ n \end{pmatrix}} \begin{pmatrix}  m \\ n \end{pmatrix}  $$ Such that $$ (1+x)^n = \sum_n p_n x^n $$","I am learning about the binomial coefficient and counting. We define:  $$ (1+x)^m = \sum^m_{n=0} \begin{pmatrix}  m \\ n \end{pmatrix} x^n $$ the coefficients of the powers of $x^n$ represent the number of ways of choosing $n$ objects from a set of $m$. Is there a way to convert this into a probability distribution by dividing each coefficient by  $$  \sum^m_{n=0} \begin{pmatrix}  m \\ n \end{pmatrix}.  $$ Example We have a set of three objects, $\{a, b , c\}$, we can draw 1 object three ways $(a + b + c)$, two objects three ways $(ab + ac + bc)$ and three objects one way $(abc)$. Then, $$ (1+x)^3 = 1x^0 + 3x^1 + 3x^2 + 1x^3  $$ If we divide each coefficient by the sum of coefficients (in this case 8) then they represent probabilities(?). Can we then say that $(1+x)^n$ is the generator for a distribution function $$ p_n = \frac{1}{\sum^m_{n=0} \begin{pmatrix}m \\ n \end{pmatrix}} \begin{pmatrix}  m \\ n \end{pmatrix}  $$ Such that $$ (1+x)^n = \sum_n p_n x^n $$",,"['probability', 'combinatorics', 'probability-distributions', 'binomial-coefficients', 'generating-functions']"
24,"A deck of 40 cards, 4 suits from 1 to 10, 2 cards extracted, probability the sum is 9?","A deck of 40 cards, 4 suits from 1 to 10, 2 cards extracted, probability the sum is 9?",,"You have a deck of $40$ cards, $4$ suits from $1$ to $10$, pick randomly $2$ cards, no reimmission, what  is the probability you get $9$ as a sum? How can I solve using the basic principle of counting? The favorable outcome are $(8+1)*4$, $(7+2)*4$, $(6+3)*4$ and $(5+4)*4$, so $64$ possible combination? But what about the all the possible outcome? Are $40*39$? From a MC simulation the results seems $~0.08$, but I can't do analytically. EDIT: The numerator is wrong, a combination can be also 1 and then 8, 2+7 and so on, the combinations are, actually, doubled, 128. $$ \frac{128}{40\cdot39} = .0821 $$  Thank you all for the answer.","You have a deck of $40$ cards, $4$ suits from $1$ to $10$, pick randomly $2$ cards, no reimmission, what  is the probability you get $9$ as a sum? How can I solve using the basic principle of counting? The favorable outcome are $(8+1)*4$, $(7+2)*4$, $(6+3)*4$ and $(5+4)*4$, so $64$ possible combination? But what about the all the possible outcome? Are $40*39$? From a MC simulation the results seems $~0.08$, but I can't do analytically. EDIT: The numerator is wrong, a combination can be also 1 and then 8, 2+7 and so on, the combinations are, actually, doubled, 128. $$ \frac{128}{40\cdot39} = .0821 $$  Thank you all for the answer.",,['probability']
25,Mean and Variance from a Cumulative Distribution Function,Mean and Variance from a Cumulative Distribution Function,,"I'm trying to find the mean (expected value) and variance for the following distribution function: $F(x)=\begin{cases}     0 & \text{for } x \lt  0\\     x/4 & \text{for } 0 \le x \lt 1\\     x^2/4 & \text{for } 1 \le x \lt 2\\     1  & \text{for } x \ge 2\\ \end{cases}$ First I got the probability density function by differentiating $f(x)=\begin{cases}     0 & \text{for } x \lt  0\\     1/4 & \text{for } 0 \le x \lt 1\\     x/2 & \text{for } 1 \le x \lt 2\\     0  & \text{for } x \ge 2\\ \end{cases}$ Which I simplified as $f(x)=\begin{cases}     1/4 & \text{for } 0 \le x \lt 1\\     x/2 & \text{for } 1 \le x \lt 2\\     0  & \text{elsewhere}\\ \end{cases}$ Now I need to find the mean (expected value) and variance. I know that $E(X)=\int xf(x)\,dx.$ Except I am not sure how I would calculate this as one value due to the function being in multiple parts. Any help is appreciated - Thank You!","I'm trying to find the mean (expected value) and variance for the following distribution function: $F(x)=\begin{cases}     0 & \text{for } x \lt  0\\     x/4 & \text{for } 0 \le x \lt 1\\     x^2/4 & \text{for } 1 \le x \lt 2\\     1  & \text{for } x \ge 2\\ \end{cases}$ First I got the probability density function by differentiating $f(x)=\begin{cases}     0 & \text{for } x \lt  0\\     1/4 & \text{for } 0 \le x \lt 1\\     x/2 & \text{for } 1 \le x \lt 2\\     0  & \text{for } x \ge 2\\ \end{cases}$ Which I simplified as $f(x)=\begin{cases}     1/4 & \text{for } 0 \le x \lt 1\\     x/2 & \text{for } 1 \le x \lt 2\\     0  & \text{elsewhere}\\ \end{cases}$ Now I need to find the mean (expected value) and variance. I know that $E(X)=\int xf(x)\,dx.$ Except I am not sure how I would calculate this as one value due to the function being in multiple parts. Any help is appreciated - Thank You!",,"['probability', 'statistics', 'probability-distributions', 'means', 'variance']"
26,Different types of sample spaces in probability,Different types of sample spaces in probability,,"In probability, sample space is a set of all possible outcomes of an experiment. A sample space can be finite or infinite. A sample space can be discrete or continuous. A sample space can be countable or uncountable. From some texts I got that finite sample space is same as discrete sample space and infinite sample space is continuous sample space . But some texts are saying that countable sample space is discrete sample space and uncountable sample space is continuous sample space . Which one of the following above is correct? I got confuse because of the following two statements in this text book Discrete Probability Law : If the sample space consists of a finite number of possible outcomes , then the probability law is specified by the probabilities of the events that consist of a single element. In particular, the probability of any event $\{s_1, s_2, . . . , s_n\}$ is the sum of the probabilities of its elements. Continuous Models : Probabilistic models with continuous sample spaces differ from their discrete counterparts in that the probabilities of the single-element events may not be sufficient to characterize the probability law. Discrete probability law deals with finite sample spaces, but continuous probability models deal with continuous sample spaces. So I am confused whether countably finite sample spaces comes under which probabilistic model. listen this also for accuracy.","In probability, sample space is a set of all possible outcomes of an experiment. A sample space can be finite or infinite. A sample space can be discrete or continuous. A sample space can be countable or uncountable. From some texts I got that finite sample space is same as discrete sample space and infinite sample space is continuous sample space . But some texts are saying that countable sample space is discrete sample space and uncountable sample space is continuous sample space . Which one of the following above is correct? I got confuse because of the following two statements in this text book Discrete Probability Law : If the sample space consists of a finite number of possible outcomes , then the probability law is specified by the probabilities of the events that consist of a single element. In particular, the probability of any event $\{s_1, s_2, . . . , s_n\}$ is the sum of the probabilities of its elements. Continuous Models : Probabilistic models with continuous sample spaces differ from their discrete counterparts in that the probabilities of the single-element events may not be sufficient to characterize the probability law. Discrete probability law deals with finite sample spaces, but continuous probability models deal with continuous sample spaces. So I am confused whether countably finite sample spaces comes under which probabilistic model. listen this also for accuracy.",,"['probability', 'notation', 'terminology', 'definition']"
27,Calculating distribution related to hitting time.,Calculating distribution related to hitting time.,,"Let $\xi_1, \xi_2,\cdots$ be i.i.d. random elements  with distribution $\mu$ in some measurable space $(S,\mathcal S)$, fix a set $A\in \mathcal S$ with $\mu A >0$, put $\tau$ = $\inf\{k; \xi_k \in A \}$ (the first hitting time). Show that $\xi_\tau$ has distribution $\mu[\cdot|A]=\mu[\cdot\cap A]/\mu A$. Intuitively, $\xi_\tau\in B \Leftrightarrow \xi_\tau \in A\cap B$, since $\xi_i$ are all i.i.d., we can intuitively call them $\xi$, its distribution is then  $P\{\xi_\tau \in B\} = P\{\xi\in B|\xi \in A\}=\mu[B\cap A]/\mu A$. But I don't know how to argue it rigorously, by definition $\xi_i$ and $\xi_j$ have identical distributions only means $P\{\xi_i\in B\} = P\{\xi_j\in B\}$. (I also accept answers that totally unrelated to my argument.) BTW, is it by definition $\xi_\tau(w)=\lim_{k\rightarrow \infty} \xi_k(w)$ if $\tau(w) = \infty$? But it becomes strange as $S$ is just a space hence we don't know what the $\lim$ means. (Though in this problem we could ignore it because it simply makes $\xi_\tau(w) \notin B$, so basically anyone answering this question could ignore this minor bug unless it's important in the answer.)","Let $\xi_1, \xi_2,\cdots$ be i.i.d. random elements  with distribution $\mu$ in some measurable space $(S,\mathcal S)$, fix a set $A\in \mathcal S$ with $\mu A >0$, put $\tau$ = $\inf\{k; \xi_k \in A \}$ (the first hitting time). Show that $\xi_\tau$ has distribution $\mu[\cdot|A]=\mu[\cdot\cap A]/\mu A$. Intuitively, $\xi_\tau\in B \Leftrightarrow \xi_\tau \in A\cap B$, since $\xi_i$ are all i.i.d., we can intuitively call them $\xi$, its distribution is then  $P\{\xi_\tau \in B\} = P\{\xi\in B|\xi \in A\}=\mu[B\cap A]/\mu A$. But I don't know how to argue it rigorously, by definition $\xi_i$ and $\xi_j$ have identical distributions only means $P\{\xi_i\in B\} = P\{\xi_j\in B\}$. (I also accept answers that totally unrelated to my argument.) BTW, is it by definition $\xi_\tau(w)=\lim_{k\rightarrow \infty} \xi_k(w)$ if $\tau(w) = \infty$? But it becomes strange as $S$ is just a space hence we don't know what the $\lim$ means. (Though in this problem we could ignore it because it simply makes $\xi_\tau(w) \notin B$, so basically anyone answering this question could ignore this minor bug unless it's important in the answer.)",,"['probability', 'probability-theory', 'probability-distributions']"
28,What is the probability that you win the second game given that you won the first if the outcomes of the two games are independent?,What is the probability that you win the second game given that you won the first if the outcomes of the two games are independent?,,"I’m working on a probability problem, but I’m having a hard time understanding the question exactly. The problem is: You are going to play two games of chess with an opponent you have never played against before. Your opponent is equally likely to be a beginner, intermediate, or master. Depending on which, your chances of winning an individual game are 90%, 50%, or 30%, respectively. a) What is your probability of winning the first game? b) Given the information that you won the first game, what is the probability that you will also win the second game ( assume that, given the skill level of your opponent, the outcomes of the two games of independent each other)? I’ve done problem a. $1/3\cdot 0.9+1/3\cdot 0.5+1/3\cdot 0.3=0.567$ For problem b, I am confused how independence works here. I know that the two games are independent, but if I am playing with the same opponent as the first game for my second game, wouldn’t I have a higher probability for problem b compared to problem a? Or does the question imply that I’ll get different opponents each time and the answer to problem b would be 0.567? I’ve searched, and the answer seems to be divided. Probability questions seem too much like English problems to me:( Could you please help me understand? Thank you in advance!","I’m working on a probability problem, but I’m having a hard time understanding the question exactly. The problem is: You are going to play two games of chess with an opponent you have never played against before. Your opponent is equally likely to be a beginner, intermediate, or master. Depending on which, your chances of winning an individual game are 90%, 50%, or 30%, respectively. a) What is your probability of winning the first game? b) Given the information that you won the first game, what is the probability that you will also win the second game ( assume that, given the skill level of your opponent, the outcomes of the two games of independent each other)? I’ve done problem a. For problem b, I am confused how independence works here. I know that the two games are independent, but if I am playing with the same opponent as the first game for my second game, wouldn’t I have a higher probability for problem b compared to problem a? Or does the question imply that I’ll get different opponents each time and the answer to problem b would be 0.567? I’ve searched, and the answer seems to be divided. Probability questions seem too much like English problems to me:( Could you please help me understand? Thank you in advance!",1/3\cdot 0.9+1/3\cdot 0.5+1/3\cdot 0.3=0.567,['probability']
29,There is a phone number with $10$ digits. What's the probability that each digit occurs exactly once?,There is a phone number with  digits. What's the probability that each digit occurs exactly once?,10,"There is a phone number with $10$ digits. What's the probability that   each digit occurs exactly once? This is a task of an old exam and I'm curious if my solution is correct. So we have a phone number made up of $10$ digits. Any number between $0$ and $9$ can occur as a digit. Thus in total we have $10^{10}$ combinations. But we want that each digit occurs exactly once. Since we have length $10$ with $10$ different numbers, there are $10!$ different possibilities of arranging those numbers (where each number occurs exactly once). What we need to do is $10^{10}-10!$ Thus the probability that each digit occurs exactly once in a phone number of length $10$ is $$\frac{1}{10^{10}-10!}$$ ? By the way, it took me about $15$ minutes to get to that solution and in the exam I got like $5$ minutes for one task.. :p I hope it's correct at least?","There is a phone number with $10$ digits. What's the probability that   each digit occurs exactly once? This is a task of an old exam and I'm curious if my solution is correct. So we have a phone number made up of $10$ digits. Any number between $0$ and $9$ can occur as a digit. Thus in total we have $10^{10}$ combinations. But we want that each digit occurs exactly once. Since we have length $10$ with $10$ different numbers, there are $10!$ different possibilities of arranging those numbers (where each number occurs exactly once). What we need to do is $10^{10}-10!$ Thus the probability that each digit occurs exactly once in a phone number of length $10$ is $$\frac{1}{10^{10}-10!}$$ ? By the way, it took me about $15$ minutes to get to that solution and in the exam I got like $5$ minutes for one task.. :p I hope it's correct at least?",,['probability']
30,Probability of getting a white a ball after $4$ balls are drawn,Probability of getting a white a ball after  balls are drawn,4,"A bag contain $6$ Red and $4$ White balls. $4$ balls are drawn one by one without replacement and were found to be at least $2$ white.What is the probability that next draw of a ball from this bag will give a white ball.? My try: As there were at least $2$ white balls, hence I made three cases. $2W$ and $2R$ or $3W$ and $1R$ or $4W$ Now Required probability=$\frac{C(4,2)C(6,2)}{C(10,4)}\left(\frac{2}{6}\right)+\frac{C(4,3)C(6,1)}{C(10,4)}\left(\frac{1}{6}\right)+0$ But it doesn't give right answer which is $\frac{34}{115}$. What is mistake in my method? How to get correct answer?","A bag contain $6$ Red and $4$ White balls. $4$ balls are drawn one by one without replacement and were found to be at least $2$ white.What is the probability that next draw of a ball from this bag will give a white ball.? My try: As there were at least $2$ white balls, hence I made three cases. $2W$ and $2R$ or $3W$ and $1R$ or $4W$ Now Required probability=$\frac{C(4,2)C(6,2)}{C(10,4)}\left(\frac{2}{6}\right)+\frac{C(4,3)C(6,1)}{C(10,4)}\left(\frac{1}{6}\right)+0$ But it doesn't give right answer which is $\frac{34}{115}$. What is mistake in my method? How to get correct answer?",,['probability']
31,Expected number of digits of the smallest prime factor?,Expected number of digits of the smallest prime factor?,,"Suppose, we have a $k$-digit number $n$. Suppose, $n$ is composite and has no prime factor below $10^{29}$. What is the expected number of digits of the smallest prime factor of $n$ ? In the concrete casse, I am interested in the composite number $$77^{77}+416$$ having $146$ digits and after I searched a factor via ECM for some hours, It seems to have no prime factor with less than $30$ digits. I know the asymptotic formula $$\prod_{p\le x,p\ prime} (1-\frac{1}{p})\approx \frac{e^{-\gamma}}{\ln(x)}$$ but I am not sure whether this approximation is good enough for $x=10^{29}$ because $n$ is very small compared to $p$#. Who can help ?","Suppose, we have a $k$-digit number $n$. Suppose, $n$ is composite and has no prime factor below $10^{29}$. What is the expected number of digits of the smallest prime factor of $n$ ? In the concrete casse, I am interested in the composite number $$77^{77}+416$$ having $146$ digits and after I searched a factor via ECM for some hours, It seems to have no prime factor with less than $30$ digits. I know the asymptotic formula $$\prod_{p\le x,p\ prime} (1-\frac{1}{p})\approx \frac{e^{-\gamma}}{\ln(x)}$$ but I am not sure whether this approximation is good enough for $x=10^{29}$ because $n$ is very small compared to $p$#. Who can help ?",,"['probability', 'number-theory', 'prime-numbers', 'asymptotics']"
32,Properties of inverse distribution function - continuity,Properties of inverse distribution function - continuity,,"I have some questions about inverse distribution functions. Let $F : \mathbb R \to [0,1]$ be a distribution function and define $F^{-1} : [0,1] \to \overline{\mathbb R}$ by $F^{-1}(y) := \inf\{x \in \mathbb R; F(x) \ge y\}$ with the convention that $\inf \emptyset := +\infty$. Futhermore, define $F^{-1+} : [0, 1] \to \overline{\mathbb R}$ by $F^{-1+}(y) := \sup\{x \in \mathbb R; F(x) \le y\}$, where $\sup \emptyset := -\infty$. The function $F^{-1}$ is the usual quantile function. I managed to prove the following properties: $F^{-1}$ and $F^{-1+}$ are non-decreasing. If $F^{-1} \in (-\infty, \infty)$, $F^{-1}$ is left-continuous at $y$ and admit a limit from the right at $y$. For $y \in \mathbb R$, set $A_y := \{x \in \mathbb R; F(x) = y\}$. Then, $(F^{-1}(y-), F^{-1}(y+)) \subseteq A_y$. Suppose that $F$ is strictly increasing. Then, $F^{-1}$ is continuous. It would be nice, if I could prove the properties 2 and 4 also for $F^{-1+}$. Do they hold also for $F^{-1+}$? I needed property 3 to prove 4.","I have some questions about inverse distribution functions. Let $F : \mathbb R \to [0,1]$ be a distribution function and define $F^{-1} : [0,1] \to \overline{\mathbb R}$ by $F^{-1}(y) := \inf\{x \in \mathbb R; F(x) \ge y\}$ with the convention that $\inf \emptyset := +\infty$. Futhermore, define $F^{-1+} : [0, 1] \to \overline{\mathbb R}$ by $F^{-1+}(y) := \sup\{x \in \mathbb R; F(x) \le y\}$, where $\sup \emptyset := -\infty$. The function $F^{-1}$ is the usual quantile function. I managed to prove the following properties: $F^{-1}$ and $F^{-1+}$ are non-decreasing. If $F^{-1} \in (-\infty, \infty)$, $F^{-1}$ is left-continuous at $y$ and admit a limit from the right at $y$. For $y \in \mathbb R$, set $A_y := \{x \in \mathbb R; F(x) = y\}$. Then, $(F^{-1}(y-), F^{-1}(y+)) \subseteq A_y$. Suppose that $F$ is strictly increasing. Then, $F^{-1}$ is continuous. It would be nice, if I could prove the properties 2 and 4 also for $F^{-1+}$. Do they hold also for $F^{-1+}$? I needed property 3 to prove 4.",,"['probability', 'probability-theory', 'probability-distributions']"
33,Showing Independence of quotient and sum of Chi-Squared Random Variables,Showing Independence of quotient and sum of Chi-Squared Random Variables,,"Let $X_i$ denote $\chi_{r_i}^2$ i.i.d random variables, where $r_i$ is a (possibly distinct) positive integer for each $i$.  I want to verify that $Y_1 = \frac{X_1}{X_2}$ and $Y_2 = X_1 + X_2$ are independent. I know that there are several ways of showing this - one way would be to try to compute the joint pdf of $Y_1$ and $Y_2$ and marginalize one out and show that it is the product of both of them - but I'm having trouble writing the joint pdf.  Another option would be to show that the conditional probabilities are equal to the individual probabilities.  But this too requires the pdf and while I know that $Y_2$ is a chi-squared random variable, it seems like it would be messy to do it this way too. Is there an more elegant way to show this?","Let $X_i$ denote $\chi_{r_i}^2$ i.i.d random variables, where $r_i$ is a (possibly distinct) positive integer for each $i$.  I want to verify that $Y_1 = \frac{X_1}{X_2}$ and $Y_2 = X_1 + X_2$ are independent. I know that there are several ways of showing this - one way would be to try to compute the joint pdf of $Y_1$ and $Y_2$ and marginalize one out and show that it is the product of both of them - but I'm having trouble writing the joint pdf.  Another option would be to show that the conditional probabilities are equal to the individual probabilities.  But this too requires the pdf and while I know that $Y_2$ is a chi-squared random variable, it seems like it would be messy to do it this way too. Is there an more elegant way to show this?",,"['probability', 'statistics', 'probability-distributions', 'proof-writing']"
34,Question regarding Gambler's Ruin,Question regarding Gambler's Ruin,,"Consider a gambling process $(X_n)_{n∈\mathbb{N}}$ on the state space $S = {0, 1, . . . , N}$, with probability $p$, resp. $q$, of moving up, resp. down, at each time step. For $x = 0, 1, . . . , N$, let $τ_x$ denote the first hitting time, $τ_x := \inf\{n ≥ 0 : X_n = x\}$ Let $p_x := P(τ_{x+1} < τ_0 | X_0 = x), x = 0, 1, . . . , N − 1$ Explain why $p_x$ satisfies the recursion $p_x = p + qp_{x−1}p_x$ for $x = 1, . . . , N − 1$. I apply the first step analysis, whereby $P(τ_{x+1} < τ_0 | X_0 = x) = P(τ_{x+1} < τ_0 | X_0 = x_1, X_1=x+1) \cdot P(X_1=x+1 |X_0 = x) + P(τ_{x+1} < τ_0 | X_0 = x_1, X_1=x-1) \cdot P(X_1=x-1 |X_0 = x)$ By the time homogeneous property, the equation reduces to, $P(τ_{x+1} < τ_0 | X_0 = x+1) \cdot P(X_1=x+1 |X_0 = x) + P(τ_{x+1} < τ_0 | X_0 =x-1) \cdot P(X_1=x-1 |X_0 = x)$ Given that initial state is $x+1$, we have already ""hit"" $x+1$ before hitting $0$. So the equation is now $1 \cdot p + P(τ_{x+1} < τ_0 | X_0 =x-1) \cdot q$ Now all left to do is to find $P(τ_{x+1} < τ_0 | X_0 =x-1)$ The Event $\{τ_{x+1} < τ_0 \}$ given that $X_0 =x-1$ can be pictured as paths with the following trends in the picture below. I think the graph on the right correctly portrays the 2 general trends of the outcomes in the event. It can be described as the paths starting at $x_1$, going up and down in any way except reaching $0$ before hitting $x+1$, and then eventually hitting either the absorption state $0$ or $N$. But, i was told that we should IGNORE the presence absorption state $N$ and do the following, Consider the graph on the left, First treat $x$ as an absorption state and thus the green line has probability $p_{x_1}$. Then treat $x+1$ as an absorption state and thus the blue line has the probability $p_{x}$. It stops here since it is an absorption state. Is the above approach valid? It seems very strange as $0$ and $N$ are defined to be the absorption states in the gambling process. If the above approach is valid, why so? (Edit: DEFINITELY NOT, Why did the person even tell me this). If not, what is the proper approach here? (Edit: The accepted answer).","Consider a gambling process $(X_n)_{n∈\mathbb{N}}$ on the state space $S = {0, 1, . . . , N}$, with probability $p$, resp. $q$, of moving up, resp. down, at each time step. For $x = 0, 1, . . . , N$, let $τ_x$ denote the first hitting time, $τ_x := \inf\{n ≥ 0 : X_n = x\}$ Let $p_x := P(τ_{x+1} < τ_0 | X_0 = x), x = 0, 1, . . . , N − 1$ Explain why $p_x$ satisfies the recursion $p_x = p + qp_{x−1}p_x$ for $x = 1, . . . , N − 1$. I apply the first step analysis, whereby $P(τ_{x+1} < τ_0 | X_0 = x) = P(τ_{x+1} < τ_0 | X_0 = x_1, X_1=x+1) \cdot P(X_1=x+1 |X_0 = x) + P(τ_{x+1} < τ_0 | X_0 = x_1, X_1=x-1) \cdot P(X_1=x-1 |X_0 = x)$ By the time homogeneous property, the equation reduces to, $P(τ_{x+1} < τ_0 | X_0 = x+1) \cdot P(X_1=x+1 |X_0 = x) + P(τ_{x+1} < τ_0 | X_0 =x-1) \cdot P(X_1=x-1 |X_0 = x)$ Given that initial state is $x+1$, we have already ""hit"" $x+1$ before hitting $0$. So the equation is now $1 \cdot p + P(τ_{x+1} < τ_0 | X_0 =x-1) \cdot q$ Now all left to do is to find $P(τ_{x+1} < τ_0 | X_0 =x-1)$ The Event $\{τ_{x+1} < τ_0 \}$ given that $X_0 =x-1$ can be pictured as paths with the following trends in the picture below. I think the graph on the right correctly portrays the 2 general trends of the outcomes in the event. It can be described as the paths starting at $x_1$, going up and down in any way except reaching $0$ before hitting $x+1$, and then eventually hitting either the absorption state $0$ or $N$. But, i was told that we should IGNORE the presence absorption state $N$ and do the following, Consider the graph on the left, First treat $x$ as an absorption state and thus the green line has probability $p_{x_1}$. Then treat $x+1$ as an absorption state and thus the blue line has the probability $p_{x}$. It stops here since it is an absorption state. Is the above approach valid? It seems very strange as $0$ and $N$ are defined to be the absorption states in the gambling process. If the above approach is valid, why so? (Edit: DEFINITELY NOT, Why did the person even tell me this). If not, what is the proper approach here? (Edit: The accepted answer).",,"['probability', 'stochastic-processes', 'markov-chains', 'random-walk']"
35,Maximum of $k$ binomial random variables?,Maximum of  binomial random variables?,k,"Imagine you have $k$  random variables $X_1,...,X_k$ drawn i.i.d. from a binomial distribution $B(n,1/2)$. For any $\epsilon > 0$, the probability that the maximum of these $k$ draws is above $(1-\epsilon) n$  $$ \Pr[\max_i X_i > (1-\epsilon) n] = 1- \Pr[X_k \leq (1-\epsilon) n]^k = 1 -\left( \sum_{i=0}^{\lfloor (1-\epsilon) n) \rfloor} \binom{n}{i} (1/2)^n\right)^k.$$ I want to show that if $k$ is chosen large enough (possibly larger than $n^s$ for some integer $s$), then $$\Pr[\max_i X_i > (1-\epsilon)n] \geq 1-  \frac{1}{\sqrt{n}}.$$ I know from previous questions ( Bounds for the maximum of binomial random variables ) that if $k = n$ this is unlikely to be the case, but is it true for $k = n^s$ for some power $s$?","Imagine you have $k$  random variables $X_1,...,X_k$ drawn i.i.d. from a binomial distribution $B(n,1/2)$. For any $\epsilon > 0$, the probability that the maximum of these $k$ draws is above $(1-\epsilon) n$  $$ \Pr[\max_i X_i > (1-\epsilon) n] = 1- \Pr[X_k \leq (1-\epsilon) n]^k = 1 -\left( \sum_{i=0}^{\lfloor (1-\epsilon) n) \rfloor} \binom{n}{i} (1/2)^n\right)^k.$$ I want to show that if $k$ is chosen large enough (possibly larger than $n^s$ for some integer $s$), then $$\Pr[\max_i X_i > (1-\epsilon)n] \geq 1-  \frac{1}{\sqrt{n}}.$$ I know from previous questions ( Bounds for the maximum of binomial random variables ) that if $k = n$ this is unlikely to be the case, but is it true for $k = n^s$ for some power $s$?",,['probability']
36,Finding normal probabilities (battery life),Finding normal probabilities (battery life),,"The lifespan of a calculator battery is normally distributed with a mean of 1100 days & standard dev. of 60 days. $$\\$$ 1) What percent of batteries is expected to survive more than 1200 days? 2) What percent of batteries will survive fewer than 800 days? 3) What length of warranty is needed so that no more than 10% of the batteries will be expected to fail during the warranty period? $$\\$$ This is what I have so far: 1) $P(x > 1200)$ = $1-P(\frac{1200-1100}{60})$ = $1-P(1.67)$ = $1-0.9525$ = 0.0475 2) $P(x < 800)$ = $P(\frac{800-1100}{60})$ = $P(-5)$ = 0 I'm not sure how to do #3. I would appreciate your help, thanks!","The lifespan of a calculator battery is normally distributed with a mean of 1100 days & standard dev. of 60 days. $$\\$$ 1) What percent of batteries is expected to survive more than 1200 days? 2) What percent of batteries will survive fewer than 800 days? 3) What length of warranty is needed so that no more than 10% of the batteries will be expected to fail during the warranty period? $$\\$$ This is what I have so far: 1) $P(x > 1200)$ = $1-P(\frac{1200-1100}{60})$ = $1-P(1.67)$ = $1-0.9525$ = 0.0475 2) $P(x < 800)$ = $P(\frac{800-1100}{60})$ = $P(-5)$ = 0 I'm not sure how to do #3. I would appreciate your help, thanks!",,"['probability', 'statistics', 'normal-distribution']"
37,Probability of visiting all but one state [duplicate],Probability of visiting all but one state [duplicate],,"This question already has answers here : Random walk on $n$-cycle (4 answers) Closed 6 years ago . Suppose I have a circular markov chain. At each state, you are equiprobable to transition to the state immediately to your left or right. I'm interested in the probability of visiting the jth state last?  That is to say, what is the probability of reaching all the other states at least once before the jth state?","This question already has answers here : Random walk on $n$-cycle (4 answers) Closed 6 years ago . Suppose I have a circular markov chain. At each state, you are equiprobable to transition to the state immediately to your left or right. I'm interested in the probability of visiting the jth state last?  That is to say, what is the probability of reaching all the other states at least once before the jth state?",,"['probability', 'markov-chains']"
38,Is the space of all probability measures a dual space,Is the space of all probability measures a dual space,,"Consider $(\Omega,\Sigma)$ a measurable space and let $P(\Sigma)$ denote the space of all probability measures on $(\Omega,\Sigma)$. I wonder if $P(\Sigma)$ can be identified with the dual space of some space $X$. If so, what is X? It can be assumed that $\Omega$ is atmost countable.","Consider $(\Omega,\Sigma)$ a measurable space and let $P(\Sigma)$ denote the space of all probability measures on $(\Omega,\Sigma)$. I wonder if $P(\Sigma)$ can be identified with the dual space of some space $X$. If so, what is X? It can be assumed that $\Omega$ is atmost countable.",,['probability']
39,What is the best way to sample from joint distributions with independent marginals?,What is the best way to sample from joint distributions with independent marginals?,,"Suppose we have an $n$ -dimensional joint distribution where all its marginals are independent. That is, if the joint density function is $p(x_1,\ldots,x_n)$ , then $p(x_1,\ldots,x_n)=p_1(x_1)\cdots p_n(x_n)$ , where $p_1,\ldots,p_n$ are marginal densities, and all these marginals are known and quite simple. Now we want to get samples ${\bf x}_k=(x_{k,1},\ldots,x_{k,n}),k=1,\ldots,m$ from $p$ where each sample is an $n$ -dimensional vector, and the objective is to use these samples to estimate the expectation of $E(h(X))$ where $h$ is a real-valued function, X is a random variable distributed according to $p$ , by computing the mean of $h({\bf x}_1),\ldots,h({\bf x}_m)$ . For this purpose $m$ is better to be a very large number. Anyone knows what is the most efficient way to do so besides MCMC ? The brutal naive way is to sample $x_{k,i}$ from $p_i$ for every $i=1,\ldots,n$ for every $k$ . This is not desirable when $m$ is large. We exclude MCMC because the cost is too high for our application. All marginals are independent, known, and simple. We don't want to involve this heavy machinery. A possible alternative may be that, after we sample ${\bf x}$ from $p$ , we then take turns to re-sample each dimension of ${\bf x}$ from corresponding marginal, but we are not sure if this is correct ( i.e. if the estimate is unbiased, will the convergence will be much slower ). Anyone can help prove or show counterexample of this?","Suppose we have an -dimensional joint distribution where all its marginals are independent. That is, if the joint density function is , then , where are marginal densities, and all these marginals are known and quite simple. Now we want to get samples from where each sample is an -dimensional vector, and the objective is to use these samples to estimate the expectation of where is a real-valued function, X is a random variable distributed according to , by computing the mean of . For this purpose is better to be a very large number. Anyone knows what is the most efficient way to do so besides MCMC ? The brutal naive way is to sample from for every for every . This is not desirable when is large. We exclude MCMC because the cost is too high for our application. All marginals are independent, known, and simple. We don't want to involve this heavy machinery. A possible alternative may be that, after we sample from , we then take turns to re-sample each dimension of from corresponding marginal, but we are not sure if this is correct ( i.e. if the estimate is unbiased, will the convergence will be much slower ). Anyone can help prove or show counterexample of this?","n p(x_1,\ldots,x_n) p(x_1,\ldots,x_n)=p_1(x_1)\cdots p_n(x_n) p_1,\ldots,p_n {\bf x}_k=(x_{k,1},\ldots,x_{k,n}),k=1,\ldots,m p n E(h(X)) h p h({\bf x}_1),\ldots,h({\bf x}_m) m x_{k,i} p_i i=1,\ldots,n k m {\bf x} p {\bf x}","['probability', 'statistics', 'numerical-methods']"
40,Probability puzzle about crossing lights – what is wrong with my reasoning?,Probability puzzle about crossing lights – what is wrong with my reasoning?,,"Calvin has to cross several signals when he walks from his home to   school. Each of these signals operate independently. They alternate   every 80 seconds between green light and red light.At each signal,   there is a counter display that tells him how long it will be before   the current signal light changes. Calvin has a magic wand which lets   him turn a signal from red to green instantaneously. However, this   wand comes with limited battery life, so he can use it only for a   specified number of times. If the total number of signals is 2 and Calvin can use his magic   wand only once, then what is the expected waiting time at the signals   when Calvin optimally walks from his home to school? I was convinced that I had the right solution, but apparently I didn't but I cannot see what is wrong with my reasoning. My solution is as follows: Each light, $Y_1$ and $Y_2$ have uniformly distributed waiting times in $[0, 80]$. Basically, he has to make a decision at the first light. At the second light, he always uses the wand if it is available. I assume that he has to pick some optimal waiting time $x \in [0, 80]$ at the first light such that if $Y_1 > x$, he uses the wand. In that case, the waiting time at the first light becomes $0$. Using this reasoning, the total expected time is $$ \mathbb E[Y_1 1_{\lbrace Y_1 \leq x \rbrace} + Y_2 1_{\lbrace Y_1 > x \rbrace}]  = \\  \mathbb E[Y_1 1_{\lbrace Y_1 \leq x \rbrace}] + \mathbb E[Y_2]\mathbb P(Y_1 > x ) $$ This becomes $$ \int^x_0 \frac{1}{80}u du + 40 \frac{80-x}{80} = \frac{1}{2} \left(\frac{x^2}{80} + 80 -x \right) $$ Then differentiating, setting to $0$, solving for $x$ and plugging it back into the expectation gives me $30$ as the answer. I have been told that this is incorrect. Where is the mistake?","Calvin has to cross several signals when he walks from his home to   school. Each of these signals operate independently. They alternate   every 80 seconds between green light and red light.At each signal,   there is a counter display that tells him how long it will be before   the current signal light changes. Calvin has a magic wand which lets   him turn a signal from red to green instantaneously. However, this   wand comes with limited battery life, so he can use it only for a   specified number of times. If the total number of signals is 2 and Calvin can use his magic   wand only once, then what is the expected waiting time at the signals   when Calvin optimally walks from his home to school? I was convinced that I had the right solution, but apparently I didn't but I cannot see what is wrong with my reasoning. My solution is as follows: Each light, $Y_1$ and $Y_2$ have uniformly distributed waiting times in $[0, 80]$. Basically, he has to make a decision at the first light. At the second light, he always uses the wand if it is available. I assume that he has to pick some optimal waiting time $x \in [0, 80]$ at the first light such that if $Y_1 > x$, he uses the wand. In that case, the waiting time at the first light becomes $0$. Using this reasoning, the total expected time is $$ \mathbb E[Y_1 1_{\lbrace Y_1 \leq x \rbrace} + Y_2 1_{\lbrace Y_1 > x \rbrace}]  = \\  \mathbb E[Y_1 1_{\lbrace Y_1 \leq x \rbrace}] + \mathbb E[Y_2]\mathbb P(Y_1 > x ) $$ This becomes $$ \int^x_0 \frac{1}{80}u du + 40 \frac{80-x}{80} = \frac{1}{2} \left(\frac{x^2}{80} + 80 -x \right) $$ Then differentiating, setting to $0$, solving for $x$ and plugging it back into the expectation gives me $30$ as the answer. I have been told that this is incorrect. Where is the mistake?",,[]
41,Expected value of the maximum of binomial random variables,Expected value of the maximum of binomial random variables,,"Let $X = \{X_1, ..., X_k\}$ be a set of $k$ iid variables drawn from a binomial distribution: $X_i \sim B(n, p)$. How to calculate the upper bound of the expected value of $max(X_i)$? Several related question (such as: Bounds for the maximum of binomial random variables or Maximum of Binomial Random Variables ) give such estimates for cases when $n = k$. I am, however, interested in the general case.","Let $X = \{X_1, ..., X_k\}$ be a set of $k$ iid variables drawn from a binomial distribution: $X_i \sim B(n, p)$. How to calculate the upper bound of the expected value of $max(X_i)$? Several related question (such as: Bounds for the maximum of binomial random variables or Maximum of Binomial Random Variables ) give such estimates for cases when $n = k$. I am, however, interested in the general case.",,"['probability', 'expectation', 'binomial-distribution']"
42,Assess if coin is fair based on length of longest run,Assess if coin is fair based on length of longest run,,A coin is tossed n times and is generating a sequence of heads and tails. A subsequence of consecutive heads is called a run of heads. For example in sequence HCHHHCCHHC there are two runs of lenght 3 and 2 and the longest run of heads is 3. For a sequence of length n = 1000 the longest run is equal to 6. Having this information do you believe the coin is fair or not? Do you have ideas how to construct appriopriate test for such problem? Any help would be much appreciated. Thank you.,A coin is tossed n times and is generating a sequence of heads and tails. A subsequence of consecutive heads is called a run of heads. For example in sequence HCHHHCCHHC there are two runs of lenght 3 and 2 and the longest run of heads is 3. For a sequence of length n = 1000 the longest run is equal to 6. Having this information do you believe the coin is fair or not? Do you have ideas how to construct appriopriate test for such problem? Any help would be much appreciated. Thank you.,,"['probability', 'statistics']"
43,"Probability of two people winning a prize, according to the number of tickets each person has","Probability of two people winning a prize, according to the number of tickets each person has",,"Since I find it hard to abstractly describe what I want to understand, I came up with the following example. Suppose that 6 people hold each a given number of a very special type of lottery tickets. Person A holds 2 tickets, person B holds 3 tickets, person C holds 1 ticket, person D has 5 tickets, person E has 6 tickets and person F has 3 tickets. The probability of each person winning a prize is directly proportional to the number of tickets each holds. So, in the end, N different contenders are going to be chosen winners. What I would like to learn is how can I calculate the probability of A, B, C, D, E and F of being one of the N winners? We can assume N=2 or whatever, if it makes it easier. Summary of probabilities: $$\begin{cases}P(A)=\frac{2}{20}\\P(B)=\frac{3}{20}\\P(C)=\frac{1}{20}\\P(D)=\frac{5}{20}\\P(E)=\frac{6}{20}\\P(F)=\frac{3}{20}\end{cases}$$","Since I find it hard to abstractly describe what I want to understand, I came up with the following example. Suppose that 6 people hold each a given number of a very special type of lottery tickets. Person A holds 2 tickets, person B holds 3 tickets, person C holds 1 ticket, person D has 5 tickets, person E has 6 tickets and person F has 3 tickets. The probability of each person winning a prize is directly proportional to the number of tickets each holds. So, in the end, N different contenders are going to be chosen winners. What I would like to learn is how can I calculate the probability of A, B, C, D, E and F of being one of the N winners? We can assume N=2 or whatever, if it makes it easier. Summary of probabilities: $$\begin{cases}P(A)=\frac{2}{20}\\P(B)=\frac{3}{20}\\P(C)=\frac{1}{20}\\P(D)=\frac{5}{20}\\P(E)=\frac{6}{20}\\P(F)=\frac{3}{20}\end{cases}$$",,"['probability', 'lotteries']"
44,"Suppose events $A$ and $B$ are such that $P(A)=0.6$ and $P(B)=0.7$, how do we answer the following questions about $P(A\cap B)$?","Suppose events  and  are such that  and , how do we answer the following questions about ?",A B P(A)=0.6 P(B)=0.7 P(A\cap B),"Suppose events $A$ and $B$ are such that $P(A)=0.6$ and $P(B)=0.7$, how do we answer the following questions about $P(A\cap B)$? $1.$ Is it possible that $P(A\cap B)=0.1$? I think this is impossible. We know that $P(A\cap B)=P(A)+P(B)-P(A\cup B)=1.3-P(A\cup B)$, then $P(A\cup B)=1.2$ which is impossible, but is my understanding wrong? $2. $ Is it possible that $P(A\cap B)=0.63$? Same procedure,$P(A\cap B)=P(A)+P(B)-P(A\cup B)=1.3-P(A\cup B)$, then $P(A\cup B)=0.67$, which may be possible? I feel this $0.63$ is odd to my calculation. $3.$ What is the largest possible value of $P(A\cap B)$? I think this is when $A$ is fully included in $B$. Thus the largest is $0.6$. Could someone clear my confusion?","Suppose events $A$ and $B$ are such that $P(A)=0.6$ and $P(B)=0.7$, how do we answer the following questions about $P(A\cap B)$? $1.$ Is it possible that $P(A\cap B)=0.1$? I think this is impossible. We know that $P(A\cap B)=P(A)+P(B)-P(A\cup B)=1.3-P(A\cup B)$, then $P(A\cup B)=1.2$ which is impossible, but is my understanding wrong? $2. $ Is it possible that $P(A\cap B)=0.63$? Same procedure,$P(A\cap B)=P(A)+P(B)-P(A\cup B)=1.3-P(A\cup B)$, then $P(A\cup B)=0.67$, which may be possible? I feel this $0.63$ is odd to my calculation. $3.$ What is the largest possible value of $P(A\cap B)$? I think this is when $A$ is fully included in $B$. Thus the largest is $0.6$. Could someone clear my confusion?",,"['probability', 'statistics']"
45,The $\limsup X_n \leq X$ almost surely,The  almost surely,\limsup X_n \leq X,"I have this following problem on my Probability problem set. Let $(X_{n})$ be a sequence of random variables and $X$ another random variable in $(\Omega, \mathcal{F}, P)$ such that $P(\{\omega \in \Omega: \limsup X_{n}(\omega) \leq X(\omega)\}) = 1$. Show that for any $\epsilon > 0$, there is an event $A$ with $P(A) < \epsilon$ and $N \in \mathbb{N}$ large enough so $X_{n}(\omega) < X(\omega) + \epsilon$ for all $n \geq N$ and for all $\omega \in A^{c}$. Here's my work. Given $\omega \in \Omega$, $(X_{n} (\omega))$ is a sequence of real numbers and I will omit $\omega$ but I have already chosen one in $\Omega$. Let $k \in \mathbb{N}$. Then, $\limsup X_{n} \leq X + 1/k$ if and only if there is some $n_{0}$ such that $X_{n} \leq X + 1/k, \forall n>n_{0}$. If this is right, this translates to: $\{\omega \in \Omega: \limsup X_{n}(\omega) \leq X(\omega)\} = \bigcap_{k=1}^{\infty}\bigcup_{n=1}^{\infty}\bigcap_{z=n}^{\infty}\{\omega \in \Omega: X_{z} < X + 1/k\}$ Then, I think that the result follows because we can take $A$ as the complement of the set in the LHS, which will have measure zero, less then any given $\epsilon > 0$ and if we let $\omega$ in the RHS set, we will have that for all $n > N$, with $N$ large enough, the desired inequality. My question is if the translation from limsup properties to the set language is right and if the whole argument is sound. Thanks a lot for the support!","I have this following problem on my Probability problem set. Let $(X_{n})$ be a sequence of random variables and $X$ another random variable in $(\Omega, \mathcal{F}, P)$ such that $P(\{\omega \in \Omega: \limsup X_{n}(\omega) \leq X(\omega)\}) = 1$. Show that for any $\epsilon > 0$, there is an event $A$ with $P(A) < \epsilon$ and $N \in \mathbb{N}$ large enough so $X_{n}(\omega) < X(\omega) + \epsilon$ for all $n \geq N$ and for all $\omega \in A^{c}$. Here's my work. Given $\omega \in \Omega$, $(X_{n} (\omega))$ is a sequence of real numbers and I will omit $\omega$ but I have already chosen one in $\Omega$. Let $k \in \mathbb{N}$. Then, $\limsup X_{n} \leq X + 1/k$ if and only if there is some $n_{0}$ such that $X_{n} \leq X + 1/k, \forall n>n_{0}$. If this is right, this translates to: $\{\omega \in \Omega: \limsup X_{n}(\omega) \leq X(\omega)\} = \bigcap_{k=1}^{\infty}\bigcup_{n=1}^{\infty}\bigcap_{z=n}^{\infty}\{\omega \in \Omega: X_{z} < X + 1/k\}$ Then, I think that the result follows because we can take $A$ as the complement of the set in the LHS, which will have measure zero, less then any given $\epsilon > 0$ and if we let $\omega$ in the RHS set, we will have that for all $n > N$, with $N$ large enough, the desired inequality. My question is if the translation from limsup properties to the set language is right and if the whole argument is sound. Thanks a lot for the support!",,"['probability', 'sequences-and-series', 'probability-theory', 'solution-verification', 'limsup-and-liminf']"
46,Proof that the discrete probability measures are dense in the space of all Borel probability,Proof that the discrete probability measures are dense in the space of all Borel probability,,"In the context of Bayesian nonparametrics, I want to prove that the discrete probability measures with finite support are dense in the space of all Borel probability measures on a Polish space (or $\mathbb{R}^d$ ), relative to the weak topology. According to my notes, this is the topology of convergence in distribution (I haven't worked much with this topology before). I could't find a proof of this proposition online. A very similar question was asked here: In the space of probability distributions, is the set of discrete distributions dense? , but I can't access the book that is referenced. So given a measure $\mu$ I want to construct a sequence of discrete measures with finite support $\mu_n$ such that for for all $x$ where $\mu$ is continuous, we have: $$F_n(x) \to F(x),$$ where $F_n$ and $F$ denote the cumulative probability functions corresponding to $\mu_n$ and $\mu$ . I think I have a proof in the case of $\mathbb{R}$ : For $n\in\mathbb{N}$ , define support points $p_1,\dots,p_{n-1}$ by $p_j = F^{-1}(\frac{j}{n})$ , and set $\mu_n(A) = \frac{1}{n-1}\sum_{j=1}^{n-1} \mathbb{1}_A(p_j)$ , where $\mathbb{1}_A$ denotes the indicator function. Now, (assuming $F$ is continuous at $p_j$ ), $F_n(p_j) = F(p_j)$ . At all other points $x\in[p_1,p_{n-1}]$ we have $F(x) - F_n(x) \le F(p_{k+1}) - F(p_k) = \frac{1}{n}$ , where $p_k \le x < p_{k+1}$ , and the difference is similarly bounded in the tails. I will need to add a few lines to account for discontinuities in $F$ but otherwise I think this works. Is this the right way to go? And I have trouble extending this approach to more dimensions. Any suggestions, or pointers to an actual proof of this theorem?","In the context of Bayesian nonparametrics, I want to prove that the discrete probability measures with finite support are dense in the space of all Borel probability measures on a Polish space (or ), relative to the weak topology. According to my notes, this is the topology of convergence in distribution (I haven't worked much with this topology before). I could't find a proof of this proposition online. A very similar question was asked here: In the space of probability distributions, is the set of discrete distributions dense? , but I can't access the book that is referenced. So given a measure I want to construct a sequence of discrete measures with finite support such that for for all where is continuous, we have: where and denote the cumulative probability functions corresponding to and . I think I have a proof in the case of : For , define support points by , and set , where denotes the indicator function. Now, (assuming is continuous at ), . At all other points we have , where , and the difference is similarly bounded in the tails. I will need to add a few lines to account for discontinuities in but otherwise I think this works. Is this the right way to go? And I have trouble extending this approach to more dimensions. Any suggestions, or pointers to an actual proof of this theorem?","\mathbb{R}^d \mu \mu_n x \mu F_n(x) \to F(x), F_n F \mu_n \mu \mathbb{R} n\in\mathbb{N} p_1,\dots,p_{n-1} p_j = F^{-1}(\frac{j}{n}) \mu_n(A) = \frac{1}{n-1}\sum_{j=1}^{n-1} \mathbb{1}_A(p_j) \mathbb{1}_A F p_j F_n(p_j) = F(p_j) x\in[p_1,p_{n-1}] F(x) - F_n(x) \le F(p_{k+1}) - F(p_k) = \frac{1}{n} p_k \le x < p_{k+1} F","['probability', 'measure-theory', 'borel-sets', 'borel-measures']"
47,"Let $X \sim N(0,1) $. Calculate the density function of $Y = \sqrt{\vert X \vert}$",Let . Calculate the density function of,"X \sim N(0,1)  Y = \sqrt{\vert X \vert}",Here is what I have done: $P(Y\le y) = P(\sqrt{\vert X \vert}\le y)=P(\vert X \vert \le y^2) =P(\pm X \le y^2)  $. $= P(x\le y^2) +P(-x \le y^2)=P(x \le y^2)+P(x\ge -y^2) = P(x\le y^2) +1-P(x\le -y^2)$ $ =2\phi(y^2)$. I am unable to get anywhere by this working. I think there has to be a better method. I am also unsure whether there is any error in the steps I have done. Any guidance is much appreciated,Here is what I have done: $P(Y\le y) = P(\sqrt{\vert X \vert}\le y)=P(\vert X \vert \le y^2) =P(\pm X \le y^2)  $. $= P(x\le y^2) +P(-x \le y^2)=P(x \le y^2)+P(x\ge -y^2) = P(x\le y^2) +1-P(x\le -y^2)$ $ =2\phi(y^2)$. I am unable to get anywhere by this working. I think there has to be a better method. I am also unsure whether there is any error in the steps I have done. Any guidance is much appreciated,,"['probability', 'probability-distributions']"
48,Set intersecting every interval in a group (probabilistic approach),Set intersecting every interval in a group (probabilistic approach),,"I'm trying to solve the following problem from a probabilistic method course: Prove that there is a constant $c>0$, such that for every prime $p$ and every set $A\subset Z_p, |A|=k$, there is $x\in Z_p$ such that $\{xa(mod p) : a\in A\}$ intersects every interval of length at least $c \frac{p}{\sqrt{k}}$ in $Z_p$. Any help would be much appreciated!","I'm trying to solve the following problem from a probabilistic method course: Prove that there is a constant $c>0$, such that for every prime $p$ and every set $A\subset Z_p, |A|=k$, there is $x\in Z_p$ such that $\{xa(mod p) : a\in A\}$ intersects every interval of length at least $c \frac{p}{\sqrt{k}}$ in $Z_p$. Any help would be much appreciated!",,"['probability', 'combinatorics', 'group-theory', 'probabilistic-method']"
49,Why does bayes theorem frequently have sum in denominator?,Why does bayes theorem frequently have sum in denominator?,,"I frequently see Bayes Theorem phrased in two different ways. Simple Bayes Theorem: $$P(X|Y) = \frac{P(X)P(Y|X)}{P(Y)}$$ Complex Bayes Theorem: Let $X_1, \dots, X_k$ be a partition of the sample space. $$P(X_i|Y) = \frac{P(X_i)P(Y|X_i)}{\sum_{j = 0}^k P(X_j)P(Y|X_j)}$$ The second version follows pretty quickly from the first by noticing $$\sum_{j = 1}^k P(X_j | Y) = 1.$$ Thus $$P(Y) = \sum_{j = 1}^k P(Y)P(X_j | Y) = \sum_{j = 1}^k P(X_j)P(Y | X_j)$$ My question is, why is the second version even mentioned? Is it used in that form frequently? How often can I easily find $P(X_j)P(Y|X_j)$ for each $j$, but not know $P(Y)$ off hand?","I frequently see Bayes Theorem phrased in two different ways. Simple Bayes Theorem: $$P(X|Y) = \frac{P(X)P(Y|X)}{P(Y)}$$ Complex Bayes Theorem: Let $X_1, \dots, X_k$ be a partition of the sample space. $$P(X_i|Y) = \frac{P(X_i)P(Y|X_i)}{\sum_{j = 0}^k P(X_j)P(Y|X_j)}$$ The second version follows pretty quickly from the first by noticing $$\sum_{j = 1}^k P(X_j | Y) = 1.$$ Thus $$P(Y) = \sum_{j = 1}^k P(Y)P(X_j | Y) = \sum_{j = 1}^k P(X_j)P(Y | X_j)$$ My question is, why is the second version even mentioned? Is it used in that form frequently? How often can I easily find $P(X_j)P(Y|X_j)$ for each $j$, but not know $P(Y)$ off hand?",,['probability']
50,distribution of one normal RV's rank within another normal distribution,distribution of one normal RV's rank within another normal distribution,,"This is a question originating from some research I'm doing on the discovery of correlations in a mass of time-series data. Suppose I have a random variable $X$ that is normally distributed with mean $\mu_X$ and variance $\sigma^2_X$.  In addition, I have i.i.d. random variables $Y_i$ ($1 \leq i \leq n$) that are also normally distributed, but with mean $\mu_Y$ and variance $\sigma^2_Y$.  Typically, $\mu_X > \mu_Y$, and we can assume that's the case in this question. I'm interested in the distribution of $X$'s rank within the $Y_i$—effectively, the number of $Y_i$ that are greater than $X$.  Is there a straightforward way of obtaining even an approximate expression for this? There is this question , but I'm not sure that's really sufficiently close to the same question.  For one thing, it concerns only two samples, one drawn from each distribution, and for another, it gives only the probability that $X > Y$.  This is of limited use in determining the distribution of $X$'s rank, since the event $X > Y_i$ is not in general independent of the event $X > Y_j$.  However, if someone can articulate why an answer to that question will give me the answer to mine (or if there is another, more related question and answer), I'd be satisfied with that.","This is a question originating from some research I'm doing on the discovery of correlations in a mass of time-series data. Suppose I have a random variable $X$ that is normally distributed with mean $\mu_X$ and variance $\sigma^2_X$.  In addition, I have i.i.d. random variables $Y_i$ ($1 \leq i \leq n$) that are also normally distributed, but with mean $\mu_Y$ and variance $\sigma^2_Y$.  Typically, $\mu_X > \mu_Y$, and we can assume that's the case in this question. I'm interested in the distribution of $X$'s rank within the $Y_i$—effectively, the number of $Y_i$ that are greater than $X$.  Is there a straightforward way of obtaining even an approximate expression for this? There is this question , but I'm not sure that's really sufficiently close to the same question.  For one thing, it concerns only two samples, one drawn from each distribution, and for another, it gives only the probability that $X > Y$.  This is of limited use in determining the distribution of $X$'s rank, since the event $X > Y_i$ is not in general independent of the event $X > Y_j$.  However, if someone can articulate why an answer to that question will give me the answer to mine (or if there is another, more related question and answer), I'd be satisfied with that.",,"['probability', 'probability-distributions', 'normal-distribution']"
51,Find the probability that $Z_1$ is less than $Z_2$,Find the probability that  is less than,Z_1 Z_2,"Let $Y=(Y_1,Y_2,Y_3)'\sim N_3(\mu,\sum)$ where $\mu=(1,-1,3)'$ and  $$\sum= \begin{pmatrix}  1 & 1 & 0\\ 1 & 2 & 3\\ 0 & 3 & 10\\ \end{pmatrix} \quad $$ and define $Z=(Z_1,Z_2)'$,  where $Z_1=Y_1+Y_2+Y_3$, $Z_2=3Y_1+Y_2-2Y_3$. Find the probability that $Z_1$ is less than $Z_2$ What I have so far:  We have to find $P(Z_1<Z_2)$ $Z$ has a normal distribution with mean $\begin{pmatrix} 3\\-4\\\end{pmatrix} \quad $ and variance $\begin{pmatrix} 21 & -14\\-14 & 45\\\end{pmatrix}. \quad $ Any comments are appreciated.","Let $Y=(Y_1,Y_2,Y_3)'\sim N_3(\mu,\sum)$ where $\mu=(1,-1,3)'$ and  $$\sum= \begin{pmatrix}  1 & 1 & 0\\ 1 & 2 & 3\\ 0 & 3 & 10\\ \end{pmatrix} \quad $$ and define $Z=(Z_1,Z_2)'$,  where $Z_1=Y_1+Y_2+Y_3$, $Z_2=3Y_1+Y_2-2Y_3$. Find the probability that $Z_1$ is less than $Z_2$ What I have so far:  We have to find $P(Z_1<Z_2)$ $Z$ has a normal distribution with mean $\begin{pmatrix} 3\\-4\\\end{pmatrix} \quad $ and variance $\begin{pmatrix} 21 & -14\\-14 & 45\\\end{pmatrix}. \quad $ Any comments are appreciated.",,"['linear-algebra', 'probability', 'statistics', 'normal-distribution']"
52,"If two different numbers are taken from the set {0,1,2,3, ......, 10} ...","If two different numbers are taken from the set {0,1,2,3, ......, 10} ...",,"If two different numbers are taken from the set {0,1,2,3, ......, 10} then what is the probability that their sum as well as absolute difference are both multiples of 4 Here is my work out The sample space here is equal to 55. Now to me the possible combinations are {0,4},{0,8},{2,6},{2,10},{4,8},{6,10} so to me the answer is 6/55","If two different numbers are taken from the set {0,1,2,3, ......, 10} then what is the probability that their sum as well as absolute difference are both multiples of 4 Here is my work out The sample space here is equal to 55. Now to me the possible combinations are {0,4},{0,8},{2,6},{2,10},{4,8},{6,10} so to me the answer is 6/55",,['probability']
53,5x5 board Bingo Question,5x5 board Bingo Question,,"There is a game which I play, it is like bingo. It starts with a 5x5. Lets say horizontally it goes ABCDE from left to right and vertically it goes 12345 from bottom to top. I have 2 random generators which will generate a letter and a number giving me a box to cross. So for example A2. Suppose I the generators don't generate a box that has been generated before, what is the probability that after the Nth amount of random generations, I get a bingo horizontally or vertically. I would like to also know the probability of the Nth generation to be a bingo.","There is a game which I play, it is like bingo. It starts with a 5x5. Lets say horizontally it goes ABCDE from left to right and vertically it goes 12345 from bottom to top. I have 2 random generators which will generate a letter and a number giving me a box to cross. So for example A2. Suppose I the generators don't generate a box that has been generated before, what is the probability that after the Nth amount of random generations, I get a bingo horizontally or vertically. I would like to also know the probability of the Nth generation to be a bingo.",,"['probability', 'probability-theory', 'computational-mathematics', 'probability-limit-theorems']"
54,Question about an inference involving an uncountable union of null events,Question about an inference involving an uncountable union of null events,,"Let $P$ and $Q$ be random probability measures on $(\Omega, \mathcal{F}, \mu)$ a probability space. That is, $P: \mathcal{F} \times \Omega\to [0,1]$ is a probability measure on $(\Omega, \mathcal{F})$ for each fixed $\omega \in \Omega$ and measurable for each fixed $A \in \mathcal{F}$. Same for $Q$. Let $d$ be the total variation distance, i.e. $d(\mu_1, \mu_2) = \sup_{A \in \mathcal{F}}|\mu_1(A) - \mu_2(A)|$ for any probability measures $\mu_1, \mu_2$ on $(\Omega, \mathcal{F})$. In this paper , I believe that something like the following inference is made (the relevant part is on page 644 in the proof of Theorem 9.2; I'm abstracting away from details in the paper that I believe to be irrelevant to my question). Suppose that for all $A \in \mathcal{F}$ and for $\mu$ almost every $\omega$ we have $$|P(A)(\omega) - Q(A)(\omega)| \leq g(\omega),$$ where $g$ is a random variable on $(\Omega, \mathcal{F})$. Then, taking a supremum over $A \in \mathcal{F}$ yields $$d(P(\omega), Q(\omega)) \leq g(\omega)$$ for $\mu$ almost every $\omega$. But this seems problematic to me since there are potentially uncountably many $A$. That is, we know that for each $A \in \mathcal{F}$, there is a $\mu$-null set $F_A$ of points at which the first inequality fails. The set of points at which the second inequality fails is $\cup_A F_A$, which may have positive $\mu$ probability because the union is uncountable. Am I correct to be doubtful about this or is the inference valid? Added. Actually, the inference in the paper is slightly different from the way I represented it above. But my worry remains and I'd appreciate feedback on both inferences. Suppose now that for all $A \in \mathcal{F}$ and for $\mu$ almost every $\omega$ we have $$|P(A)(\omega) - Q(A)(\omega)| \leq f(A,\omega),$$ where $f$ is a real-valued function on $\mathcal{F} \times \Omega$ satisfying any requisite measurability properties. Then, taking a supremum over $A \in \mathcal{F}$ yields $$d(P(\omega), Q(\omega)) \leq \sup_{A \in \mathcal{F}}f(A,\omega)$$ for $\mu$ almost every $\omega$. Now the worry is this. Let $F$ be the set of points at which the last inequality fails and let $\omega_0 \in F$. Then for some $A_0 \in \mathcal{F}$ we have $$|P(A_0)(\omega_0) - Q(A_0)(\omega_0)| > \sup_A f(A, \omega_0) \geq f(A_0, \omega_0).$$ So $\omega_0$ is a point at which $|P(A)(\omega) - Q(A)(\omega)| \leq f(A,\omega)$ fails for some $A$. Hence, repurposing the notation introduced above, we have $F \subseteq \cup_A F_A$. And $F$ need not have probability $0$ as the union is uncountable, contradicting our inference.","Let $P$ and $Q$ be random probability measures on $(\Omega, \mathcal{F}, \mu)$ a probability space. That is, $P: \mathcal{F} \times \Omega\to [0,1]$ is a probability measure on $(\Omega, \mathcal{F})$ for each fixed $\omega \in \Omega$ and measurable for each fixed $A \in \mathcal{F}$. Same for $Q$. Let $d$ be the total variation distance, i.e. $d(\mu_1, \mu_2) = \sup_{A \in \mathcal{F}}|\mu_1(A) - \mu_2(A)|$ for any probability measures $\mu_1, \mu_2$ on $(\Omega, \mathcal{F})$. In this paper , I believe that something like the following inference is made (the relevant part is on page 644 in the proof of Theorem 9.2; I'm abstracting away from details in the paper that I believe to be irrelevant to my question). Suppose that for all $A \in \mathcal{F}$ and for $\mu$ almost every $\omega$ we have $$|P(A)(\omega) - Q(A)(\omega)| \leq g(\omega),$$ where $g$ is a random variable on $(\Omega, \mathcal{F})$. Then, taking a supremum over $A \in \mathcal{F}$ yields $$d(P(\omega), Q(\omega)) \leq g(\omega)$$ for $\mu$ almost every $\omega$. But this seems problematic to me since there are potentially uncountably many $A$. That is, we know that for each $A \in \mathcal{F}$, there is a $\mu$-null set $F_A$ of points at which the first inequality fails. The set of points at which the second inequality fails is $\cup_A F_A$, which may have positive $\mu$ probability because the union is uncountable. Am I correct to be doubtful about this or is the inference valid? Added. Actually, the inference in the paper is slightly different from the way I represented it above. But my worry remains and I'd appreciate feedback on both inferences. Suppose now that for all $A \in \mathcal{F}$ and for $\mu$ almost every $\omega$ we have $$|P(A)(\omega) - Q(A)(\omega)| \leq f(A,\omega),$$ where $f$ is a real-valued function on $\mathcal{F} \times \Omega$ satisfying any requisite measurability properties. Then, taking a supremum over $A \in \mathcal{F}$ yields $$d(P(\omega), Q(\omega)) \leq \sup_{A \in \mathcal{F}}f(A,\omega)$$ for $\mu$ almost every $\omega$. Now the worry is this. Let $F$ be the set of points at which the last inequality fails and let $\omega_0 \in F$. Then for some $A_0 \in \mathcal{F}$ we have $$|P(A_0)(\omega_0) - Q(A_0)(\omega_0)| > \sup_A f(A, \omega_0) \geq f(A_0, \omega_0).$$ So $\omega_0$ is a point at which $|P(A)(\omega) - Q(A)(\omega)| \leq f(A,\omega)$ fails for some $A$. Hence, repurposing the notation introduced above, we have $F \subseteq \cup_A F_A$. And $F$ need not have probability $0$ as the union is uncountable, contradicting our inference.",,"['real-analysis', 'probability', 'probability-theory', 'measure-theory']"
55,Prove or disprove the following inequality?,Prove or disprove the following inequality?,,"Let $Y \geq X \geq 0$ be two random variables with cdf $F_X$ and $F_Y$ such that $var(Y) \leq var(X) < \infty$. Is $$ \int_{z + \mathbb{E}[X]}^{\infty}\mathbb{E}[(X - t)^+]F_X(t)dt \geq \int_{z + \mathbb{E}[Y]}^{\infty}\mathbb{E}[(Y - t)^+]F_Y(t)dt $$  true for all $z \in \mathbb{R}$? Edit: Moreover, assume that $esssup(X) = esssup(Y)$","Let $Y \geq X \geq 0$ be two random variables with cdf $F_X$ and $F_Y$ such that $var(Y) \leq var(X) < \infty$. Is $$ \int_{z + \mathbb{E}[X]}^{\infty}\mathbb{E}[(X - t)^+]F_X(t)dt \geq \int_{z + \mathbb{E}[Y]}^{\infty}\mathbb{E}[(Y - t)^+]F_Y(t)dt $$  true for all $z \in \mathbb{R}$? Edit: Moreover, assume that $esssup(X) = esssup(Y)$",,"['probability', 'probability-theory']"
56,"The pdf of last interval of a Poisson process in $[0,T]$",The pdf of last interval of a Poisson process in,"[0,T]","Assume a Poisson point process with rate $\lambda$ in time $[0,T]$. Supoose $X$ is the random variable representing the time between the last arrival and $T$. What is the probability density function of $X$ as $T\to \infty$? The pdf is $\frac{d}{dx}P\left(X\leq x\right)$. We can break up $P\left(X\leq x\right)$ by the number of arrivals in time $[0,T]$: \begin{align} P\left(X\leq x\right)&=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(X\leq x|k   \text{ arrivals}\right)\\ &=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(T-T_k\leq x|k   \text{ arrivals}\right)\\ &=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(T-T_k\leq x|T_k \leq T <T_{k+1}\right) \end{align} where $T_k=\sum_{i=1}^{k}A_i$ is the time $k^{th}$ arrival, and $A_i$ is the $i^{th}$ inter-arrival time. Any idea how to continue? Or, a resource that already has the answer?","Assume a Poisson point process with rate $\lambda$ in time $[0,T]$. Supoose $X$ is the random variable representing the time between the last arrival and $T$. What is the probability density function of $X$ as $T\to \infty$? The pdf is $\frac{d}{dx}P\left(X\leq x\right)$. We can break up $P\left(X\leq x\right)$ by the number of arrivals in time $[0,T]$: \begin{align} P\left(X\leq x\right)&=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(X\leq x|k   \text{ arrivals}\right)\\ &=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(T-T_k\leq x|k   \text{ arrivals}\right)\\ &=\sum_{k=1}^{\infty}Poisson(k, \lambda T)P\left(T-T_k\leq x|T_k \leq T <T_{k+1}\right) \end{align} where $T_k=\sum_{i=1}^{k}A_i$ is the time $k^{th}$ arrival, and $A_i$ is the $i^{th}$ inter-arrival time. Any idea how to continue? Or, a resource that already has the answer?",,"['probability', 'probability-theory', 'probability-distributions', 'stochastic-processes', 'stochastic-calculus']"
57,"What's the motivation for the definition of ""regular family"" in exponential family distribution?","What's the motivation for the definition of ""regular family"" in exponential family distribution?",,I know the definition of regular family is that the exponential family whose natural parameter space is an open set. But I don't know why do we need such a definition. What's the difference of the behaviour of the regular family and non-regular family? Do you have any idea about it?,I know the definition of regular family is that the exponential family whose natural parameter space is an open set. But I don't know why do we need such a definition. What's the difference of the behaviour of the regular family and non-regular family? Do you have any idea about it?,,"['probability', 'statistics', 'bayesian', 'bayesian-network']"
58,How to compute distribution conditional on two random variables,How to compute distribution conditional on two random variables,,"I have the following scenario: A fair coin is tossed, and we record the result ""heads"" or ""tails"" as random variable $Z$. If a head is observed, a random sample $X_1,\dots,X_n \sim \text{Bernoulli}(\theta)$ is collected, with fixed sample size $n$. If a tail is observed, a random sample $X_1,X_2,\ldots \sim \text{Bernoulli}(\theta)$ is collected until $k$ successes are obtained, for some $k<n$. Let $N$ denote the random variable recording the total number of $X$s observed, and let $M$ denote the number of successes in the observed $Xs$. I must show that the distribution of $Z$, given $N$ and $M$, does not depend on $\theta$. Say $Z=0$ represents ""heads"" and $Z=1$ represents ""tails"". We can then find conditional distributions for random variables $N$ and $M$. Here is what I have found so far. $$\text{P}[N=j\mid Z=0]=\begin{cases}0 & \text{if } j\neq n \\ 1 & \text{if } j=n\end{cases} \\ \text{P}[N=j\mid Z=1]=\binom{j-1}{k-1} \theta^k(1-\theta)^{j-k}, j=k,k+1,\dots$$ $$\text{P}[M=j\mid Z=0]=\binom{n}{j}\theta^j(1-\theta)^{n-j}, j=0,1,\dots,n\\ \text{P}[M=j\mid Z=1]=\begin{cases}0 & \text{if } j\neq k \\ 1 & \text{if } j=k \end{cases}$$ I also know the following result, by the definition of conditioning and using the law of total probability.  \begin{eqnarray} \text{P}[Z=z\mid N=j,M=j]&=&\frac{\text{P}[N=j,M=j\mid Z=z]\text{P}[Z=z]}{\text{P}[N=j,M=j]} \\ &=&\frac{\text{P}[N=j,M=j\mid Z=z]\text{P}[Z=z]}{\sum_z\text{P}[N=j,M=j\mid Z=z] \text{P}[Z=z]} \end{eqnarray} Here is where I am stuck. I cannot figure out how to use the above information to finish this computation. In particular, one of the distributions above involves $k$, and the other one does not--will I ever be able to get rid of the dependency on $\theta$ then? I would find any hints or steps on how to proceed extremely helpful.","I have the following scenario: A fair coin is tossed, and we record the result ""heads"" or ""tails"" as random variable $Z$. If a head is observed, a random sample $X_1,\dots,X_n \sim \text{Bernoulli}(\theta)$ is collected, with fixed sample size $n$. If a tail is observed, a random sample $X_1,X_2,\ldots \sim \text{Bernoulli}(\theta)$ is collected until $k$ successes are obtained, for some $k<n$. Let $N$ denote the random variable recording the total number of $X$s observed, and let $M$ denote the number of successes in the observed $Xs$. I must show that the distribution of $Z$, given $N$ and $M$, does not depend on $\theta$. Say $Z=0$ represents ""heads"" and $Z=1$ represents ""tails"". We can then find conditional distributions for random variables $N$ and $M$. Here is what I have found so far. $$\text{P}[N=j\mid Z=0]=\begin{cases}0 & \text{if } j\neq n \\ 1 & \text{if } j=n\end{cases} \\ \text{P}[N=j\mid Z=1]=\binom{j-1}{k-1} \theta^k(1-\theta)^{j-k}, j=k,k+1,\dots$$ $$\text{P}[M=j\mid Z=0]=\binom{n}{j}\theta^j(1-\theta)^{n-j}, j=0,1,\dots,n\\ \text{P}[M=j\mid Z=1]=\begin{cases}0 & \text{if } j\neq k \\ 1 & \text{if } j=k \end{cases}$$ I also know the following result, by the definition of conditioning and using the law of total probability.  \begin{eqnarray} \text{P}[Z=z\mid N=j,M=j]&=&\frac{\text{P}[N=j,M=j\mid Z=z]\text{P}[Z=z]}{\text{P}[N=j,M=j]} \\ &=&\frac{\text{P}[N=j,M=j\mid Z=z]\text{P}[Z=z]}{\sum_z\text{P}[N=j,M=j\mid Z=z] \text{P}[Z=z]} \end{eqnarray} Here is where I am stuck. I cannot figure out how to use the above information to finish this computation. In particular, one of the distributions above involves $k$, and the other one does not--will I ever be able to get rid of the dependency on $\theta$ then? I would find any hints or steps on how to proceed extremely helpful.",,['calculus']
59,Uniqueness Theorem,Uniqueness Theorem,,"I have a problem to the following exercise: Suppose that $f$ and $g$ are integrable functions that are $\mathcal F $  measurable. Suppose that we have a sequence of $\sigma$-fields {$\mathcal F_{n}$} such that $\mathcal F_{n} \subset \mathcal F_{n+1}$ and for which (1) $\int_{A}f(x)dx = \int_{A}g(x)dx$ for all A $\in \mathcal F_{n}$ Show that if $\mathcal F$ is the smallest $\sigma$-field that contains $\mathcal F_{n}$ for all n, then $f(x) = g(x)$ for all $x$ except a set of measure zero. There is also a Hint: Note that $\{x: f \gt g\} \in \mathcal F$. Next, it may be useful to show that equation (1) holds for all $A \in \mathcal F $. Here one may want to consider the set $\mathcal G$ of all A $\in \mathcal F$ for which we have equation (1) and then show that $\mathcal G$ is a $\sigma$-field. This was an Exercise given many years ago on my University but without a solution. But I'm interested in a proof of this problem. Can someone please give a nice proof. Thanks in advance","I have a problem to the following exercise: Suppose that $f$ and $g$ are integrable functions that are $\mathcal F $  measurable. Suppose that we have a sequence of $\sigma$-fields {$\mathcal F_{n}$} such that $\mathcal F_{n} \subset \mathcal F_{n+1}$ and for which (1) $\int_{A}f(x)dx = \int_{A}g(x)dx$ for all A $\in \mathcal F_{n}$ Show that if $\mathcal F$ is the smallest $\sigma$-field that contains $\mathcal F_{n}$ for all n, then $f(x) = g(x)$ for all $x$ except a set of measure zero. There is also a Hint: Note that $\{x: f \gt g\} \in \mathcal F$. Next, it may be useful to show that equation (1) holds for all $A \in \mathcal F $. Here one may want to consider the set $\mathcal G$ of all A $\in \mathcal F$ for which we have equation (1) and then show that $\mathcal G$ is a $\sigma$-field. This was an Exercise given many years ago on my University but without a solution. But I'm interested in a proof of this problem. Can someone please give a nice proof. Thanks in advance",,"['calculus', 'probability']"
60,"How to make unbiased coin from potentially biased coin, is my reasoning correct?","How to make unbiased coin from potentially biased coin, is my reasoning correct?",,"Problem: Let's say you have a coin that might be (you don't know how biased, or even whether biased in the first place) biased, and you want to come up with a way to simulate an unbiased flip. My reasoning (took me a few steps to get here but I'll spare you the struggle) is that no matter how biased the coin is, the probability of observing HT is the same as the probability of observing TH (assuming P(H) and P(T) are independent). So we can assign for example H to HT and T to TH, and just wait for either sequence to take place. I think that makes sense, but my intuition has been proven wrong so many times in the past that I really want to make sure my reasoning here is correct. I'm also very interested to hear other ways to think about this and other kinds of intuition for this idea. EDIT : Based on @Mariuslp's answer, I'd like to understand why we can't use a ""sliding window"", meaning why we have to toss away the first two flips if neither HT nor TH happens. From my comment to his answer : The way I think about it, the probability of the entire sequence that happens before either HT or TH is the same for either HT or TH since P(H) and P(T) are independent, so it shouldn't matter. What's the problem with my thinking?","Problem: Let's say you have a coin that might be (you don't know how biased, or even whether biased in the first place) biased, and you want to come up with a way to simulate an unbiased flip. My reasoning (took me a few steps to get here but I'll spare you the struggle) is that no matter how biased the coin is, the probability of observing HT is the same as the probability of observing TH (assuming P(H) and P(T) are independent). So we can assign for example H to HT and T to TH, and just wait for either sequence to take place. I think that makes sense, but my intuition has been proven wrong so many times in the past that I really want to make sure my reasoning here is correct. I'm also very interested to hear other ways to think about this and other kinds of intuition for this idea. EDIT : Based on @Mariuslp's answer, I'd like to understand why we can't use a ""sliding window"", meaning why we have to toss away the first two flips if neither HT nor TH happens. From my comment to his answer : The way I think about it, the probability of the entire sequence that happens before either HT or TH is the same for either HT or TH since P(H) and P(T) are independent, so it shouldn't matter. What's the problem with my thinking?",,['probability']
61,Probability - find the number of balls in a box,Probability - find the number of balls in a box,,"There are $20\%$ less white than black balls in a box. Two balls are randomly chosen. If the probability that at least one chosen ball is white is $12/17$, how many black balls are in a box? If $w$ is the number of white balls, and $b$ is the number of black balls, then: $$w=b-b/5=4b/5$$ Total number of balls in a box is $t=9w/4$ or $t=9b/5$. How can we find the total number of black balls after two are randomly chosen?","There are $20\%$ less white than black balls in a box. Two balls are randomly chosen. If the probability that at least one chosen ball is white is $12/17$, how many black balls are in a box? If $w$ is the number of white balls, and $b$ is the number of black balls, then: $$w=b-b/5=4b/5$$ Total number of balls in a box is $t=9w/4$ or $t=9b/5$. How can we find the total number of black balls after two are randomly chosen?",,['probability']
62,Balls and bins: filling $N$ bins with at least $K$ balls,Balls and bins: filling  bins with at least  balls,N K,Suppose an infinite number of balls are thrown into $N$ bins (uniformly distributed). What is the expectancy of the number of balls needed in order to fill all bins with at least $K$ balls in each bin. I found answers to this problem with $K=1$ and even a partial answer to $K=2$ but nothing for the generalized form.,Suppose an infinite number of balls are thrown into bins (uniformly distributed). What is the expectancy of the number of balls needed in order to fill all bins with at least balls in each bin. I found answers to this problem with and even a partial answer to but nothing for the generalized form.,N K K=1 K=2,"['probability', 'probability-distributions', 'balls-in-bins', 'coupon-collector']"
63,"Semantic confusion over the meaning of ""order matters/is important""","Semantic confusion over the meaning of ""order matters/is important""",,"Doubts have been expressed as to what exactly ""order matters/is important"" means in relation to the following question on this site here ""In a deck of 40 cards there are 4 aces. What is the probability that when drawing two cards only one ace is drawn."" There can be two cases: first card is the ace, or second card is the ace. One view expressed is that since both cases refer to one event , order is not important. The other view is that since we are considering two possible permutations , order is important. Or put differently, is ""order important/matters"" if (a) the order is specified , e.g. first card is an ace, or (b) the order is unspecified , i.e. all possible orders are to be considered I have the feeling that both the interpretations are being used on this site by different people. It would be good if some one could give a definitive opinion on this matter.","Doubts have been expressed as to what exactly ""order matters/is important"" means in relation to the following question on this site here ""In a deck of 40 cards there are 4 aces. What is the probability that when drawing two cards only one ace is drawn."" There can be two cases: first card is the ace, or second card is the ace. One view expressed is that since both cases refer to one event , order is not important. The other view is that since we are considering two possible permutations , order is important. Or put differently, is ""order important/matters"" if (a) the order is specified , e.g. first card is an ace, or (b) the order is unspecified , i.e. all possible orders are to be considered I have the feeling that both the interpretations are being used on this site by different people. It would be good if some one could give a definitive opinion on this matter.",,"['probability', 'permutations', 'combinations']"
64,Risk and Die-Rolling Probabilities,Risk and Die-Rolling Probabilities,,"If you aren't familiar with Risk, here is a short description of how the game works: In the game of Risk, players control countries by occupying them with a variable number of “armies.”  The object is to gain more territory by conducting battles between neighboring countries.  A battle consists of the armies of a single country going against an opponent’s armies occupying a neighboring country.  The battle progresses by each player rolling a prescribed number of dice, and applying rules to determine from the outcome how many armies are lost for each player.  The dice are rolled repeatedly until either the defender loses all his armies (in which case the attacker can occupy the disputed country), or until the attacker is reduced to a single army (in which case there is no army to spare for occupying the opponent’s country).  An attacker can never lose control of his own country.  The battle may also be stopped at any prior time at the attacker’s discretion. The rules for determining how many dice a player may shake are as follows: The attacker may shake one less die than the number of armies on his country, to a maximum of three. The defender may shake as many dice as the number of armies on his country, to a maximum of two. The rules for deciding the outcome of a particular throw of the dice are as follows: The highest attacker die is compared against the highest defender die.  Whoever has the lower number loses one army.  Ties go to the defender. The procedure is repeated for the second-highest dice. In cases where either the attacker or the defender only rolls a single die, a total of only one army will be lost; in all other cases a total of two armies will be lost. For the 1-1 die rolling situation, it is easy to determine that the probability of winning one battle is 15/16. How can I determine probabilities for the other scenarios? Do I have to brute force the calculation (which wouldn't be hard if I were to use python), or does there exist a mathematical way to determine the probabilities of the attacking side winning?","If you aren't familiar with Risk, here is a short description of how the game works: In the game of Risk, players control countries by occupying them with a variable number of “armies.”  The object is to gain more territory by conducting battles between neighboring countries.  A battle consists of the armies of a single country going against an opponent’s armies occupying a neighboring country.  The battle progresses by each player rolling a prescribed number of dice, and applying rules to determine from the outcome how many armies are lost for each player.  The dice are rolled repeatedly until either the defender loses all his armies (in which case the attacker can occupy the disputed country), or until the attacker is reduced to a single army (in which case there is no army to spare for occupying the opponent’s country).  An attacker can never lose control of his own country.  The battle may also be stopped at any prior time at the attacker’s discretion. The rules for determining how many dice a player may shake are as follows: The attacker may shake one less die than the number of armies on his country, to a maximum of three. The defender may shake as many dice as the number of armies on his country, to a maximum of two. The rules for deciding the outcome of a particular throw of the dice are as follows: The highest attacker die is compared against the highest defender die.  Whoever has the lower number loses one army.  Ties go to the defender. The procedure is repeated for the second-highest dice. In cases where either the attacker or the defender only rolls a single die, a total of only one army will be lost; in all other cases a total of two armies will be lost. For the 1-1 die rolling situation, it is easy to determine that the probability of winning one battle is 15/16. How can I determine probabilities for the other scenarios? Do I have to brute force the calculation (which wouldn't be hard if I were to use python), or does there exist a mathematical way to determine the probabilities of the attacking side winning?",,['probability']
65,Zeros of Brownian motion,Zeros of Brownian motion,,"I wanted to find out why for a Brownian motion $(B_t)_t$ almost surely for every $s\geq 0$ there exist $u,t\geq s$ s.t.  $$B_u<0<B_t.$$ I know that BM has to have zeros on every intervall $[0, \epsilon].$ But as $B_s$ varies in $\omega$, I am confused.","I wanted to find out why for a Brownian motion $(B_t)_t$ almost surely for every $s\geq 0$ there exist $u,t\geq s$ s.t.  $$B_u<0<B_t.$$ I know that BM has to have zeros on every intervall $[0, \epsilon].$ But as $B_s$ varies in $\omega$, I am confused.",,"['probability', 'probability-theory', 'brownian-motion']"
66,Probability that cutting a stick at two points forms a triangle?,Probability that cutting a stick at two points forms a triangle?,,"Math overflow has given many creative answers to this topic at link: https://mathoverflow.net/questions/2014/if-you-break-a-stick-at-two-points-chosen-uniformly-the-probability-the-three-r I mostly understand but just need one clarification to put me at ease. The solution I am most comfortable with in the context of my homework relates to uniform joint distributions. I refer to the answer given by ""Bill the Lizard"". ""The three pieces form a triangle if none of the pieces is greater than half the length of the stick . In other words..."" This conclusion leads to: $(y > 1/2) AND (x < 1/2) AND (y - x) < 1/2$ $(x > 1/2) AND (y < 1/2) AND (x - y) < 1/2$ Now, my confusion. If none of the pieces is greater than half the length of the stick , then why is $y > 1/2 \;\;and\;\; x > 1/2\;\;$ in the above inequalities?? Thank you.","Math overflow has given many creative answers to this topic at link: https://mathoverflow.net/questions/2014/if-you-break-a-stick-at-two-points-chosen-uniformly-the-probability-the-three-r I mostly understand but just need one clarification to put me at ease. The solution I am most comfortable with in the context of my homework relates to uniform joint distributions. I refer to the answer given by ""Bill the Lizard"". ""The three pieces form a triangle if none of the pieces is greater than half the length of the stick . In other words..."" This conclusion leads to: $(y > 1/2) AND (x < 1/2) AND (y - x) < 1/2$ $(x > 1/2) AND (y < 1/2) AND (x - y) < 1/2$ Now, my confusion. If none of the pieces is greater than half the length of the stick , then why is $y > 1/2 \;\;and\;\; x > 1/2\;\;$ in the above inequalities?? Thank you.",,"['probability', 'uniform-distribution']"
67,Prove that $X_{(n)}/n$ tends to zero in probability,Prove that  tends to zero in probability,X_{(n)}/n,"Let there be given a sample from the distribution $F$ such that $$ \lim\limits_{y \to \infty } y(1 - F(y) + F(-y)) = 0$$ Prove that $X_{(n)} / n \to 0$ in probability, where $X_{(n)}$ is order statistics. My attempt to solve it $$ \mathbb{P}(|X_{(n)}/n| > \epsilon) = \mathbb{P}(|X_{(n)}| > n\epsilon) = 1 - \mathbb{P}(|X_{(n)}| < n\epsilon) = 1 - \mathbb{P}(-n\epsilon < X_{(n)} < n\epsilon) = 1 - \mathbb{P}(X_{(n)} < n\epsilon) + \mathbb{P}(X_{(n)} < -n\epsilon) = 1 - (F(n\epsilon))^n + (F(-n\epsilon))^n$$ So, maybe from the initial statement it can be somehow deduce that the last tends to zero. Thanks for any help!","Let there be given a sample from the distribution $F$ such that $$ \lim\limits_{y \to \infty } y(1 - F(y) + F(-y)) = 0$$ Prove that $X_{(n)} / n \to 0$ in probability, where $X_{(n)}$ is order statistics. My attempt to solve it $$ \mathbb{P}(|X_{(n)}/n| > \epsilon) = \mathbb{P}(|X_{(n)}| > n\epsilon) = 1 - \mathbb{P}(|X_{(n)}| < n\epsilon) = 1 - \mathbb{P}(-n\epsilon < X_{(n)} < n\epsilon) = 1 - \mathbb{P}(X_{(n)} < n\epsilon) + \mathbb{P}(X_{(n)} < -n\epsilon) = 1 - (F(n\epsilon))^n + (F(-n\epsilon))^n$$ So, maybe from the initial statement it can be somehow deduce that the last tends to zero. Thanks for any help!",,"['real-analysis', 'probability', 'statistics']"
68,Density of order statistics,Density of order statistics,,"I need help with order statistics: Given a sample $X_1, \ldots, X_n$, $X_i \sim U_{0,1}$, i.e. the $X_i$ are uniformly distributed on $[0,1]$, determine the following for the corresponding order statistics: a) the density of $X_{(k)}$ b) the joint density of $X_{(1)}, X_{(n)}$ c) the density of the range $R:=X_{(n)} - X_{(1)}$ d) the limit distribution for $2n(1-R)$ with $n \rightarrow \infty$. Here is my idea for the first one: a) For  the density of an order statistic we've shown: $$f_{X_{(k)}}(t) = \binom{n}{k} k F_X(t)^{k-1}(1-F_X(t))^{n-k}f_X(t)$$ Given the fact that $X_i \sim U_{0,1}$, the density is pretty easy to determine, i.e. $$f_{X_{(k)}}(t) = \binom{n}{k} k t^{k-1}(1-t)^{n-k} \mathbb{1}_{[0,1]}$$ b) For b), I think I can use the following formula: $$f_{(i),(j)} = \dfrac{n!f(x_i)f(x_j)(F(X_i))^{i-1}(F(x_j)-F(x_i))^{j-1-i}(1-F(x_j))^{n-j}}{(i-1)!(j-1-i)!(n-j)!}$$ to get $$f_{(1),(n)} (x_1,x_n) = (n-1)n(x_n-x_1)^{n-2}$$ Is that correct? c) My idea was to use the transformation rule for densities, so $$ \begin{pmatrix} x \\ y  \end{pmatrix} = \phi ( z,u) =  \begin{pmatrix} z-u \\ u  \end{pmatrix} $$ $$ \begin{pmatrix} z \\ u  \end{pmatrix} = \phi^{-1}(x,y) =  \begin{pmatrix} x+u \\ y  \end{pmatrix} $$ with $J_{\phi^{-1}}(x,y) = \begin{vmatrix} 1 & 0 \\ 0 & 1  \end{vmatrix} = 1$ Then $f_R = f_{(n)}(\phi^{-1}(x,y))f_{(1)}(\phi^{-1}(x,y))\cdot1 = \cdots$ - how do I proceed now? d) Here I don't know how to start... Thank you for the help!","I need help with order statistics: Given a sample $X_1, \ldots, X_n$, $X_i \sim U_{0,1}$, i.e. the $X_i$ are uniformly distributed on $[0,1]$, determine the following for the corresponding order statistics: a) the density of $X_{(k)}$ b) the joint density of $X_{(1)}, X_{(n)}$ c) the density of the range $R:=X_{(n)} - X_{(1)}$ d) the limit distribution for $2n(1-R)$ with $n \rightarrow \infty$. Here is my idea for the first one: a) For  the density of an order statistic we've shown: $$f_{X_{(k)}}(t) = \binom{n}{k} k F_X(t)^{k-1}(1-F_X(t))^{n-k}f_X(t)$$ Given the fact that $X_i \sim U_{0,1}$, the density is pretty easy to determine, i.e. $$f_{X_{(k)}}(t) = \binom{n}{k} k t^{k-1}(1-t)^{n-k} \mathbb{1}_{[0,1]}$$ b) For b), I think I can use the following formula: $$f_{(i),(j)} = \dfrac{n!f(x_i)f(x_j)(F(X_i))^{i-1}(F(x_j)-F(x_i))^{j-1-i}(1-F(x_j))^{n-j}}{(i-1)!(j-1-i)!(n-j)!}$$ to get $$f_{(1),(n)} (x_1,x_n) = (n-1)n(x_n-x_1)^{n-2}$$ Is that correct? c) My idea was to use the transformation rule for densities, so $$ \begin{pmatrix} x \\ y  \end{pmatrix} = \phi ( z,u) =  \begin{pmatrix} z-u \\ u  \end{pmatrix} $$ $$ \begin{pmatrix} z \\ u  \end{pmatrix} = \phi^{-1}(x,y) =  \begin{pmatrix} x+u \\ y  \end{pmatrix} $$ with $J_{\phi^{-1}}(x,y) = \begin{vmatrix} 1 & 0 \\ 0 & 1  \end{vmatrix} = 1$ Then $f_R = f_{(n)}(\phi^{-1}(x,y))f_{(1)}(\phi^{-1}(x,y))\cdot1 = \cdots$ - how do I proceed now? d) Here I don't know how to start... Thank you for the help!",,"['probability', 'probability-theory', 'statistics', 'order-statistics', 'density-function']"
69,Finitely additive shift invariant probability measure on Z,Finitely additive shift invariant probability measure on Z,,"Does anybody know a specific function $\mu$ going from the power set of the integers to $[0,1]$ so that 1). $\mu(\mathbb{Z}) = 1$ 2). $\mu(A\cup B) = \mu(A)+\mu(B)$ if $A$ and $B$ are disjoint. 3). $\mu(A+1) = \mu(A)$ where $A+1 := \{a+1 | a \in A\}$? I've seen how to show one exists but I was wondering if someone could tell me a specific $\mu$ that works, or why it is impossible to construct explicitly such a $\mu$.","Does anybody know a specific function $\mu$ going from the power set of the integers to $[0,1]$ so that 1). $\mu(\mathbb{Z}) = 1$ 2). $\mu(A\cup B) = \mu(A)+\mu(B)$ if $A$ and $B$ are disjoint. 3). $\mu(A+1) = \mu(A)$ where $A+1 := \{a+1 | a \in A\}$? I've seen how to show one exists but I was wondering if someone could tell me a specific $\mu$ that works, or why it is impossible to construct explicitly such a $\mu$.",,"['real-analysis', 'probability', 'analysis']"
70,"If $X_1, \ldots, X_n \sim t_\nu$, a t-distribution with $\nu >1$, how to show $E\left(\max_{1 \leq i \leq n}|X_i|\right) = O\left(n^{1/\nu}\right)$?","If , a t-distribution with , how to show ?","X_1, \ldots, X_n \sim t_\nu \nu >1 E\left(\max_{1 \leq i \leq n}|X_i|\right) = O\left(n^{1/\nu}\right)","If $X_1, \ldots, X_n \sim t_\nu$, a t-distribution with $\nu >1$ degrees of free, with each of them independent, then a  result from probability theory is that: $$ E\left(\max_{1 \leq i \leq n}|X_i|\right) = O\left(n^{1/\nu}\right) $$ $X_n = O(Y_n)$ means that there exists a constant $a > 0$ such that $|X_n| \leq a|Y_n|$ for all $n$. The common trick is to use moment generating functions, for which it doesnt exist for a t-distribution. Does anyone have any ideas how to approach this?","If $X_1, \ldots, X_n \sim t_\nu$, a t-distribution with $\nu >1$ degrees of free, with each of them independent, then a  result from probability theory is that: $$ E\left(\max_{1 \leq i \leq n}|X_i|\right) = O\left(n^{1/\nu}\right) $$ $X_n = O(Y_n)$ means that there exists a constant $a > 0$ such that $|X_n| \leq a|Y_n|$ for all $n$. The common trick is to use moment generating functions, for which it doesnt exist for a t-distribution. Does anyone have any ideas how to approach this?",,"['probability', 'probability-theory', 'distribution-tails']"
71,Showing that two scalar random variables are independent when only their distributions are known,Showing that two scalar random variables are independent when only their distributions are known,,"Suppose that $X$ and $Y$ are two scalar random variables, and we know only their distributions. Is there some general strategy to show whether or not these two random variables are independent? In particular we have $$\mathbb{P}(X \leq x) = \begin{cases} 1 - e^{-2x}, & x \geq 0, \\ 0 , & x < 0, \end{cases}$$ and $$ \mathbb{P}(Y \leq y) = \begin{cases} 1 - e^{-y}, & y \geq 0, \\ 0 , & y < 0. \end{cases}$$ I feel as if I am missing something extremely trivial. If I knew the joint density or the distribution of the random vector $(X,Y)$ I could check whether $$ \mathbb{P}((X,Y) \in (-\infty, a] \times (-\infty, b]) = \mathbb{P}(X \leq a) \mathbb{P}(Y \leq b) \ .$$ However I am not given this information. Any ideas? I feel as if what I am asking is impossible.","Suppose that $X$ and $Y$ are two scalar random variables, and we know only their distributions. Is there some general strategy to show whether or not these two random variables are independent? In particular we have $$\mathbb{P}(X \leq x) = \begin{cases} 1 - e^{-2x}, & x \geq 0, \\ 0 , & x < 0, \end{cases}$$ and $$ \mathbb{P}(Y \leq y) = \begin{cases} 1 - e^{-y}, & y \geq 0, \\ 0 , & y < 0. \end{cases}$$ I feel as if I am missing something extremely trivial. If I knew the joint density or the distribution of the random vector $(X,Y)$ I could check whether $$ \mathbb{P}((X,Y) \in (-\infty, a] \times (-\infty, b]) = \mathbb{P}(X \leq a) \mathbb{P}(Y \leq b) \ .$$ However I am not given this information. Any ideas? I feel as if what I am asking is impossible.",,"['probability', 'probability-theory', 'probability-distributions']"
72,Probability on accident,Probability on accident,,There were four accidents in a town during a seven-day period. Would you be surprised if all four occurred on the same day? If each of the four occurred on a different day? I couldn't figure out how to solve this problem. It looks like that it is somewhat related to Poisson distribution.,There were four accidents in a town during a seven-day period. Would you be surprised if all four occurred on the same day? If each of the four occurred on a different day? I couldn't figure out how to solve this problem. It looks like that it is somewhat related to Poisson distribution.,,['probability']
73,Intricate Markov Bayesian Theorem Probability Problem.,Intricate Markov Bayesian Theorem Probability Problem.,,"Their exist a fraudulent gambling den that uses $2$ kinds of dices. A fair dice which has a $\frac16$ probability of rolling any number, their also exist a loaded dice that has $0.5$ possibility to roll a $6$ and $0.1$ possibility to roll any other number. The possibility that the fraudulent gambling den switches from the fair to loaded dice is $0.01$ and the probability of switching back from loaded to fair is $0.2$. Sequentially record dice by $q_{1},q_{2},q_{3}...,$ and numbers rolled by $o_{1},o_{2},o_{3}..$ for example $:q_{1}= F, o_{1}=2$ means the first die is Fair and by rolling the first die the number is observed is $2$, moreover $p(q_{1}=F)=P(q_{1}=L)=0.5.$ Derive the following possibility that : $P(o_{100}=4|q_{99}=F), P(q_{3}=L|o_{1}=1,o_{2}=3),$ $P(o_{100}=4 ,q_{99}=L| q_{98}=F), P(o_{15}=3,o_{16}=6|q_{14}=F), P(o_{1}=4,o_{2}=2,q_{2}=F), $ $P(o_{1}=4,o_{2}=2,o_{3}=4,q_{3}=F)$ One must use the theorem $$P(A_i | B) = \frac{P(B|A_i) * p(A_i)}{P(B)}$$ I must assume that $P(B|A) = 0.016666$ and $p(A_i) = 0.5$ $p(B) = 0.1$ Then $$P(A_i | B) =\frac{0.016666 * 0.5}{0.1} = 0.08$$ My question for this problem is there any steps that I may be missing. I feel that their must be a second step in this problem. Also the Markov chain must play in important part in solving this enigma.","Their exist a fraudulent gambling den that uses $2$ kinds of dices. A fair dice which has a $\frac16$ probability of rolling any number, their also exist a loaded dice that has $0.5$ possibility to roll a $6$ and $0.1$ possibility to roll any other number. The possibility that the fraudulent gambling den switches from the fair to loaded dice is $0.01$ and the probability of switching back from loaded to fair is $0.2$. Sequentially record dice by $q_{1},q_{2},q_{3}...,$ and numbers rolled by $o_{1},o_{2},o_{3}..$ for example $:q_{1}= F, o_{1}=2$ means the first die is Fair and by rolling the first die the number is observed is $2$, moreover $p(q_{1}=F)=P(q_{1}=L)=0.5.$ Derive the following possibility that : $P(o_{100}=4|q_{99}=F), P(q_{3}=L|o_{1}=1,o_{2}=3),$ $P(o_{100}=4 ,q_{99}=L| q_{98}=F), P(o_{15}=3,o_{16}=6|q_{14}=F), P(o_{1}=4,o_{2}=2,q_{2}=F), $ $P(o_{1}=4,o_{2}=2,o_{3}=4,q_{3}=F)$ One must use the theorem $$P(A_i | B) = \frac{P(B|A_i) * p(A_i)}{P(B)}$$ I must assume that $P(B|A) = 0.016666$ and $p(A_i) = 0.5$ $p(B) = 0.1$ Then $$P(A_i | B) =\frac{0.016666 * 0.5}{0.1} = 0.08$$ My question for this problem is there any steps that I may be missing. I feel that their must be a second step in this problem. Also the Markov chain must play in important part in solving this enigma.",,"['probability', 'statistics', 'markov-chains']"
74,Computing a certain probability.,Computing a certain probability.,,"Imagine a gun that is shooting a ball in a square of $(0,1) \times (0,1)$ as the figure below, So we can assume that the coordinates $(X,Y)$ are random variables with a uniform distribution on $(0,1)$ so if we let $W$ to be the random variable ""distance to the origin"" I want to compute $P(W<d)$, then I want to know $$P(W<d)=P(\sqrt{X^2+Y^2}<d)=P(X^2+Y^2<d^2)$$ Am I right?, and in case that I am, How can I compute this probability?. Thanks in advance.","Imagine a gun that is shooting a ball in a square of $(0,1) \times (0,1)$ as the figure below, So we can assume that the coordinates $(X,Y)$ are random variables with a uniform distribution on $(0,1)$ so if we let $W$ to be the random variable ""distance to the origin"" I want to compute $P(W<d)$, then I want to know $$P(W<d)=P(\sqrt{X^2+Y^2}<d)=P(X^2+Y^2<d^2)$$ Am I right?, and in case that I am, How can I compute this probability?. Thanks in advance.",,['probability']
75,What's the probability that space shuttle will fly?,What's the probability that space shuttle will fly?,,"Ques. NASA is developing two top-secret space shuttles. One has two engines, the other has four. All the engines are identical, and have the same probability of failure. Each is designed to fly if at least half of its engines work. A visiting scientist says, ""The four-engine shuttle is more reliable, isn't it?"" The NASA technician replies that the probability of failure is top secret, but that in fact both shuttles have the same probability of flying. The visitor then says, ""Aha! Never mind, now I know both the probability an engine will fail and the probability that the shuttle will fly."" How did he figure this out, and what are the two probabilities? Attempt: Let $x$ be the probability that an engine will work. Then the probability that an engine won't work is $1-x$. Space shuttle $1$ will fly when at least one engine will work= probability that one engine will work + probability that both engine will work Probability that space shuttle $1$ (with two engines) will fly $=x(1-x)+x^2$ Probability that space shuttle $2$ (with four engines) will fly $=x^2(1-x)^2+x^3(1-x)+x^4$ Now, we are given that both shuttles have same probability of flying  $\Rightarrow x(1-x)+x^2=x^2(1-x)^2+x^3(1-x)+x^4$ On solving we get $(x^2-x)(x^2+1)=0$ As $x$ should be real no. we get $x=0$ or $1$. Am I right ?","Ques. NASA is developing two top-secret space shuttles. One has two engines, the other has four. All the engines are identical, and have the same probability of failure. Each is designed to fly if at least half of its engines work. A visiting scientist says, ""The four-engine shuttle is more reliable, isn't it?"" The NASA technician replies that the probability of failure is top secret, but that in fact both shuttles have the same probability of flying. The visitor then says, ""Aha! Never mind, now I know both the probability an engine will fail and the probability that the shuttle will fly."" How did he figure this out, and what are the two probabilities? Attempt: Let $x$ be the probability that an engine will work. Then the probability that an engine won't work is $1-x$. Space shuttle $1$ will fly when at least one engine will work= probability that one engine will work + probability that both engine will work Probability that space shuttle $1$ (with two engines) will fly $=x(1-x)+x^2$ Probability that space shuttle $2$ (with four engines) will fly $=x^2(1-x)^2+x^3(1-x)+x^4$ Now, we are given that both shuttles have same probability of flying  $\Rightarrow x(1-x)+x^2=x^2(1-x)^2+x^3(1-x)+x^4$ On solving we get $(x^2-x)(x^2+1)=0$ As $x$ should be real no. we get $x=0$ or $1$. Am I right ?",,['probability']
76,Setting a limit for the continuous normal variable in normal distribution,Setting a limit for the continuous normal variable in normal distribution,,"In an example, where a test has a maximum score of $200$, and a minimum score of $0$, can one eliminate the infinite boundaries? Let's say my $\mu$ is $100$, and my $\sigma$ is $50$. Integrating the normal function for $200 \leq X$, I get: $$\int^\infty_{200} \frac{e^{-\frac{(x-100)^2}{2\times50^2}}}{50\sqrt{2\pi}}dx \approx 0.022$$ There is a 2.2% chance that one will score over the limit of 200. Is there any way to make scoring over 200 impossible, and changing the maximum bound from $\infty$ to 200, and $-\infty$ to 0 in a way, that the integral below is true: $$\int^{200}_{0} \frac{e^{-\frac{(x-100)^2}{2\times50^2}}}{50\sqrt{2\pi}}dx = 1$$","In an example, where a test has a maximum score of $200$, and a minimum score of $0$, can one eliminate the infinite boundaries? Let's say my $\mu$ is $100$, and my $\sigma$ is $50$. Integrating the normal function for $200 \leq X$, I get: $$\int^\infty_{200} \frac{e^{-\frac{(x-100)^2}{2\times50^2}}}{50\sqrt{2\pi}}dx \approx 0.022$$ There is a 2.2% chance that one will score over the limit of 200. Is there any way to make scoring over 200 impossible, and changing the maximum bound from $\infty$ to 200, and $-\infty$ to 0 in a way, that the integral below is true: $$\int^{200}_{0} \frac{e^{-\frac{(x-100)^2}{2\times50^2}}}{50\sqrt{2\pi}}dx = 1$$",,"['probability', 'normal-distribution']"
77,Reciprocal of a normal variable with non-zero mean and small variance,Reciprocal of a normal variable with non-zero mean and small variance,,"$X$ is a normal random variable: $$X \sim \mathcal{N}(\mu,\sigma^2)$$ Then $Y = 1/X$ has the following probability density function (see wiki ): $$f(y) = \frac{1}{y^2\sqrt{2\sigma^2\pi}}\, \exp\left(-\frac{(\frac{1}{y} - \mu)^2}{2 \sigma^2}\right)$$ This distribution of $Y$ does not have moments since ( stackExchange ): $$\int_{-\infty}^{+\infty}|x|f(x)\,dx = \infty$$ An intuitive explanation of this is that the distributions tails are too heavy and consequently the law of large number fails. The more samples that are drawn and averaged the less stable this average is. The non-zero probability density that $X = 0$ means that $Y$ will not have finite moments since there is a non-zero probability that $Y = \infty$. However in simulation for a non-zero mean and small variance $X \sim \mathcal{N}(1,0.1)$ the distribution of $Y$ is seemingly well-behaved with $E[Y] = 0.1010$ and $\text{Var}(Y) = 0.0109$. However theoretically these moments are not finite. As the variance of $X$ increases the mean and variance of $Y$ become both larger and increasingly unstable. As the variance of $X$ continues to increase the moments of $Y$ become increasingly unstable as the number of samples of $Y$ increases. This is contrary to the typical expectation that the variance of the mean estimate should decrease as the number of samples increases. Could you offer any insights into this strange behaviour? Why did the moments of $Y$ appear stable for $X \sim \mathcal{N}(1,0.1)$?","$X$ is a normal random variable: $$X \sim \mathcal{N}(\mu,\sigma^2)$$ Then $Y = 1/X$ has the following probability density function (see wiki ): $$f(y) = \frac{1}{y^2\sqrt{2\sigma^2\pi}}\, \exp\left(-\frac{(\frac{1}{y} - \mu)^2}{2 \sigma^2}\right)$$ This distribution of $Y$ does not have moments since ( stackExchange ): $$\int_{-\infty}^{+\infty}|x|f(x)\,dx = \infty$$ An intuitive explanation of this is that the distributions tails are too heavy and consequently the law of large number fails. The more samples that are drawn and averaged the less stable this average is. The non-zero probability density that $X = 0$ means that $Y$ will not have finite moments since there is a non-zero probability that $Y = \infty$. However in simulation for a non-zero mean and small variance $X \sim \mathcal{N}(1,0.1)$ the distribution of $Y$ is seemingly well-behaved with $E[Y] = 0.1010$ and $\text{Var}(Y) = 0.0109$. However theoretically these moments are not finite. As the variance of $X$ increases the mean and variance of $Y$ become both larger and increasingly unstable. As the variance of $X$ continues to increase the moments of $Y$ become increasingly unstable as the number of samples of $Y$ increases. This is contrary to the typical expectation that the variance of the mean estimate should decrease as the number of samples increases. Could you offer any insights into this strange behaviour? Why did the moments of $Y$ appear stable for $X \sim \mathcal{N}(1,0.1)$?",,"['probability', 'probability-distributions', 'inverse', 'means', 'simulation']"
78,Why $E[X|X=Y]\neq E[Y]$?,Why ?,E[X|X=Y]\neq E[Y],"The full question was: Let $X$ be the number of tosses until a coin with probability of $1\over 3$ to land on Heads does and $Y$ the number of tosses until a fair coin lands on Heads. What is $E[X|X=Y]$? The correct answer is apperently $3\over 2$, which is lower than both $E[X]$ and $E[Y]$. What I'm confused about is if I know that $X=Y$, and I know that $Y=2$, then also $X=2$, therefore $$E[X|X=Y]=\sum_k k\cdot P(X=k|X=Y) = \sum_k k \cdot P(Y=k) = E[Y]$$ which seems to be wrong, my guess would be because knowing that $X=Y$ also gives us information on $Y$, but I'm still not able to understand how or why it works.","The full question was: Let $X$ be the number of tosses until a coin with probability of $1\over 3$ to land on Heads does and $Y$ the number of tosses until a fair coin lands on Heads. What is $E[X|X=Y]$? The correct answer is apperently $3\over 2$, which is lower than both $E[X]$ and $E[Y]$. What I'm confused about is if I know that $X=Y$, and I know that $Y=2$, then also $X=2$, therefore $$E[X|X=Y]=\sum_k k\cdot P(X=k|X=Y) = \sum_k k \cdot P(Y=k) = E[Y]$$ which seems to be wrong, my guess would be because knowing that $X=Y$ also gives us information on $Y$, but I'm still not able to understand how or why it works.",,"['probability', 'expectation']"
79,Help with conditional expectation of a convolution of exponential random variables,Help with conditional expectation of a convolution of exponential random variables,,"I'm working through this paper , with lots of help from all the great people on this site. Obviously my statistics/probability is a lacking to follow all the mathematical steps. Currently, I'm trying to figure out how equation $(12)$ was derived from equation $(8)$: given the pdf    $$f_n(t) = \frac{\binom{n+1}{2}}{2N}\exp\left(-\frac{\binom{n+1}{2}}{2N} t\right)\;\;\; (5) $$   The convolution of $f_{n-1}(t),f_{n-2}(t),\ldots,f_m(t)$ has the expectation and variance:   $$E(t) = 2N\sum_{i=m+1}^{n}{\frac{1}{\binom{i}{2}}} = 2N \sum_{i=m+1}^{n}{\left(\frac{2}{i-l} - \frac{2}{i}\right)} = 4N\left(\frac{1}{m}-\frac{1}{n}\right) \;\;\; (8)\\ V(t) = 4N^2\sum_{i=m+1}^{n}{\frac{1}{\binom{i}{2}^2}} \;\;\; (9) $$   given that the starting frequency of a mutant is $\frac{k}{2N}$, show the expectation of $E\left(t\mid\frac{k}{2N}\right)$ (mean time for $k$ alleles to go to $2N$ alleles, also known as the fixation time (since there are $2N$ alleles in the population)) is:   $$ E\left(t\mid\frac{k}{2N}\right)=4N\left(1-\frac{1}{2N} - \sum_{i=1}^{k-1}{\frac{1}{i(i+1)}}\prod_{j=1}^{i}\frac{k-j}{2N-j} \right) \;\;\; (12) $$ so basically the exponential distribution listed above (equation $(5)$) is the probability that $N+1$ randomly sampled alleles come from $N$ ancestors. I don't understand why the conditional expectation is different when you start with a known number of alleles, you just be able to plug $k$ and $2N$ into equation $(8)$: $$ E(t) = 4N\left(\frac{1}{k}-\frac{1}{2N}\right)\;? $$ I know this is a bit ambiguous, especially without knowing the details of the paper, but I'm sure someone more knowledgeable of statistics/probability can probably identify what the authors are using to derive the last equation. Also, bonus points if you can derive the following from  equation $(12)$ as $N\to\infty$: $$E(t\mid p) = -4N(1/p - 1)\ln(1-p)\;,$$ where $p=\frac{k}{2N}$. Any help would be amazing!","I'm working through this paper , with lots of help from all the great people on this site. Obviously my statistics/probability is a lacking to follow all the mathematical steps. Currently, I'm trying to figure out how equation $(12)$ was derived from equation $(8)$: given the pdf    $$f_n(t) = \frac{\binom{n+1}{2}}{2N}\exp\left(-\frac{\binom{n+1}{2}}{2N} t\right)\;\;\; (5) $$   The convolution of $f_{n-1}(t),f_{n-2}(t),\ldots,f_m(t)$ has the expectation and variance:   $$E(t) = 2N\sum_{i=m+1}^{n}{\frac{1}{\binom{i}{2}}} = 2N \sum_{i=m+1}^{n}{\left(\frac{2}{i-l} - \frac{2}{i}\right)} = 4N\left(\frac{1}{m}-\frac{1}{n}\right) \;\;\; (8)\\ V(t) = 4N^2\sum_{i=m+1}^{n}{\frac{1}{\binom{i}{2}^2}} \;\;\; (9) $$   given that the starting frequency of a mutant is $\frac{k}{2N}$, show the expectation of $E\left(t\mid\frac{k}{2N}\right)$ (mean time for $k$ alleles to go to $2N$ alleles, also known as the fixation time (since there are $2N$ alleles in the population)) is:   $$ E\left(t\mid\frac{k}{2N}\right)=4N\left(1-\frac{1}{2N} - \sum_{i=1}^{k-1}{\frac{1}{i(i+1)}}\prod_{j=1}^{i}\frac{k-j}{2N-j} \right) \;\;\; (12) $$ so basically the exponential distribution listed above (equation $(5)$) is the probability that $N+1$ randomly sampled alleles come from $N$ ancestors. I don't understand why the conditional expectation is different when you start with a known number of alleles, you just be able to plug $k$ and $2N$ into equation $(8)$: $$ E(t) = 4N\left(\frac{1}{k}-\frac{1}{2N}\right)\;? $$ I know this is a bit ambiguous, especially without knowing the details of the paper, but I'm sure someone more knowledgeable of statistics/probability can probably identify what the authors are using to derive the last equation. Also, bonus points if you can derive the following from  equation $(12)$ as $N\to\infty$: $$E(t\mid p) = -4N(1/p - 1)\ln(1-p)\;,$$ where $p=\frac{k}{2N}$. Any help would be amazing!",,"['probability', 'probability-theory', 'statistics', 'convolution', 'biology']"
80,"Calculating the number of ""birthday days"" in the birthday problem","Calculating the number of ""birthday days"" in the birthday problem",,"Given 's' students in a room and 'd' days in the calendar year, what is the probability 'P' that there will be 'k' ""birthday days""? i.e., 'k = 1' means that everybody's birthday falls on the same day, 'k = 5' means that exactly 5 days of the year coincide with the birthday of at least one student, and 'k = s' means that everyone's birthday is unique. Assume d ≥ s. 'k' will range from 1 to 's', and ∑P from k = 1 to k = s will be 1 (in other words, P(k) is a probability mass function). What I Know So Far: • The total number of ways for the students to have birthdays is d^s. • P(1) = d/d^(s) (because there are 'd' days on which all students could all share the exact same birthday). • P(s) = d!/(d^(s)(d-s)!) (because this is compliment of the solution to the standard birthday problem) Any help/resources that get me closer to a formula for P(k) are greatly appreciated. Thanks!","Given 's' students in a room and 'd' days in the calendar year, what is the probability 'P' that there will be 'k' ""birthday days""? i.e., 'k = 1' means that everybody's birthday falls on the same day, 'k = 5' means that exactly 5 days of the year coincide with the birthday of at least one student, and 'k = s' means that everyone's birthday is unique. Assume d ≥ s. 'k' will range from 1 to 's', and ∑P from k = 1 to k = s will be 1 (in other words, P(k) is a probability mass function). What I Know So Far: • The total number of ways for the students to have birthdays is d^s. • P(1) = d/d^(s) (because there are 'd' days on which all students could all share the exact same birthday). • P(s) = d!/(d^(s)(d-s)!) (because this is compliment of the solution to the standard birthday problem) Any help/resources that get me closer to a formula for P(k) are greatly appreciated. Thanks!",,"['probability', 'combinatorics', 'birthday']"
81,Probability in $S_{15}$,Probability in,S_{15},"We consider the set of permutations of the first fifteen natural numbers. What is the probability that $1$ and $2$ aren't contiguous? My attempt: Denote by $C_{12}=$ ""The numbers $1,2$ are contiguos""; $R_i^{(1)}=$ ""The number $1$ is in i-th position "". Now, we have  $$P(C_{12})=\sum_{i=1}^{15}P(C_{12}|R_i^{(1)})P(R_i^{(1)}),$$  where $P(R_i^{(1)})=1/15$ for $i=1,2,\ldots,15$ and $P(C_{12}|R_i^{(1)})=2/14$ for $i=2,3,\ldots 14$ conversely $P(C_{12}|R_1^{(1)})=P(C_{12}|R_{15}^{(1)})=1/14$. In this way, we obtain $P(C_{12})=2/15$, then $$1-P(C_{12})=13/15.$$ Is it correct my attempt?","We consider the set of permutations of the first fifteen natural numbers. What is the probability that $1$ and $2$ aren't contiguous? My attempt: Denote by $C_{12}=$ ""The numbers $1,2$ are contiguos""; $R_i^{(1)}=$ ""The number $1$ is in i-th position "". Now, we have  $$P(C_{12})=\sum_{i=1}^{15}P(C_{12}|R_i^{(1)})P(R_i^{(1)}),$$  where $P(R_i^{(1)})=1/15$ for $i=1,2,\ldots,15$ and $P(C_{12}|R_i^{(1)})=2/14$ for $i=2,3,\ldots 14$ conversely $P(C_{12}|R_1^{(1)})=P(C_{12}|R_{15}^{(1)})=1/14$. In this way, we obtain $P(C_{12})=2/15$, then $$1-P(C_{12})=13/15.$$ Is it correct my attempt?",,"['probability', 'probability-theory', 'permutations']"
82,Convergence in probability,Convergence in probability,,"Can anyone tell me how they got the regions $0<\epsilon<\theta$ and $\epsilon >0 $. Also to clarify, is the last step where it says $\lim_{n \to \infty} P(|Y_n-\theta|>\epsilon)=0$","Can anyone tell me how they got the regions $0<\epsilon<\theta$ and $\epsilon >0 $. Also to clarify, is the last step where it says $\lim_{n \to \infty} P(|Y_n-\theta|>\epsilon)=0$",,"['probability', 'sequences-and-series', 'convergence-divergence', 'random-variables', 'uniform-distribution']"
83,Student test statistic and self normalizing sum.,Student test statistic and self normalizing sum.,,"I study the asymptotic distribution of self normalizing sums which are defined as  $S_n/V_n$ where $S_n=\sum_{i=1}^n X_i$ and $V_n^2 = \sum_{i=1}^n X_i^2$ for some i.i.d RV's $X_i$. Motivation to study such sums comes from the fact that the classical Student $T_n$ statistic could be expressed as: $T_n(X)= \frac{\sum_{i=1}^n X_i}{\sqrt{\frac{n}{n-1}\sum_{i=1}^n (X_i-\overline X)^2}} = \frac{S_n/V_n}{\sqrt{\frac{1}{n-1}(n - (S_n/V_n)^2)}}$ From the paper I study ( http://arxiv.org/pdf/1204.2074v2.pdf ) I know that: If $T_n$ or $S_n/V_n$ has an asymptotic distribution, then so does the other, and they coincide. but it do not seem trivial for me. Can someone explain it? I'm not sure if it is only showing that the denominator is equal 1 in probability and using the Slutsky-Theorem? https://de.wikipedia.org/wiki/Slutsky-Theorem","I study the asymptotic distribution of self normalizing sums which are defined as  $S_n/V_n$ where $S_n=\sum_{i=1}^n X_i$ and $V_n^2 = \sum_{i=1}^n X_i^2$ for some i.i.d RV's $X_i$. Motivation to study such sums comes from the fact that the classical Student $T_n$ statistic could be expressed as: $T_n(X)= \frac{\sum_{i=1}^n X_i}{\sqrt{\frac{n}{n-1}\sum_{i=1}^n (X_i-\overline X)^2}} = \frac{S_n/V_n}{\sqrt{\frac{1}{n-1}(n - (S_n/V_n)^2)}}$ From the paper I study ( http://arxiv.org/pdf/1204.2074v2.pdf ) I know that: If $T_n$ or $S_n/V_n$ has an asymptotic distribution, then so does the other, and they coincide. but it do not seem trivial for me. Can someone explain it? I'm not sure if it is only showing that the denominator is equal 1 in probability and using the Slutsky-Theorem? https://de.wikipedia.org/wiki/Slutsky-Theorem",,"['probability', 'statistics', 'weak-convergence', 'probability-limit-theorems', 'sums-of-squares']"
84,"Limit probability of a complete bipartite random graph $G(n,n,p)$ is connected",Limit probability of a complete bipartite random graph  is connected,"G(n,n,p)","I need to calculate the following probability limit for a complete bipartite random graph $G(n,n,p)$ in the Erdos-Renyi model: \begin{equation} \lim_{n\rightarrow\infty}\mathbb{P}[G(n,n,p) \text{ is connected}] \end{equation} when $np=\ln n + w(n)$ where $w(n)\rightarrow -\infty$ when $n\rightarrow\infty$. I know that the expected value of the number of isolated vertices in $G(n,n,p)$ is: \begin{equation} \mathbb{E}X=2n(1-p)^n \end{equation} Where X stands for the number of isolated vertices of course. So the graph $G(n,n,p)$ is connected if it doesn't have any isolated vertices then by Markov inequality: \begin{equation} \mathbb{P}(X\ge 1)\le \mathbb{E}X \end{equation} and so substituting the value of $p$ i get: \begin{eqnarray} \lim_{n\rightarrow\infty}\mathbb{P}[G(n,n,p) \text{ is connected}]&=&\lim_{n\rightarrow\infty}\mathbb{P}(X\ge1)\leq\lim_{n\rightarrow\infty}\mathbb{E}X\\ &=&\lim_{n\rightarrow\infty}2n\bigg(1-\cfrac{\ln n + w(n)}{n}\bigg)^n \end{eqnarray} My questions are 2 actually: 1- Is correct what i did? 2- If the answer for 1 is YES. How can i calculate that limit? Thanks in advance! The variance for the number of isolated vertices is  \begin{equation}  \mathbb{V}X=4n^2(1-p)^n+2n(n-1)(1-p)^{2n}+n^2(1-p)^{2n-1} \end{equation} And by Chebyshev inequality: \begin{eqnarray} \mathbb{P}(X=0)&\leq&\cfrac{\mathbb{V}X}{(\mathbb{E}X)^2} &\leq&\cfrac{4n^2(1-p)^n+2n(n-1)(1-p)^{2n}+n^2(1-p)^{2n-1}}{4n^2(1-p)^{2n}} \end{eqnarray} And sadly once again i got stuck with the limiting probability any hand on this?","I need to calculate the following probability limit for a complete bipartite random graph $G(n,n,p)$ in the Erdos-Renyi model: \begin{equation} \lim_{n\rightarrow\infty}\mathbb{P}[G(n,n,p) \text{ is connected}] \end{equation} when $np=\ln n + w(n)$ where $w(n)\rightarrow -\infty$ when $n\rightarrow\infty$. I know that the expected value of the number of isolated vertices in $G(n,n,p)$ is: \begin{equation} \mathbb{E}X=2n(1-p)^n \end{equation} Where X stands for the number of isolated vertices of course. So the graph $G(n,n,p)$ is connected if it doesn't have any isolated vertices then by Markov inequality: \begin{equation} \mathbb{P}(X\ge 1)\le \mathbb{E}X \end{equation} and so substituting the value of $p$ i get: \begin{eqnarray} \lim_{n\rightarrow\infty}\mathbb{P}[G(n,n,p) \text{ is connected}]&=&\lim_{n\rightarrow\infty}\mathbb{P}(X\ge1)\leq\lim_{n\rightarrow\infty}\mathbb{E}X\\ &=&\lim_{n\rightarrow\infty}2n\bigg(1-\cfrac{\ln n + w(n)}{n}\bigg)^n \end{eqnarray} My questions are 2 actually: 1- Is correct what i did? 2- If the answer for 1 is YES. How can i calculate that limit? Thanks in advance! The variance for the number of isolated vertices is  \begin{equation}  \mathbb{V}X=4n^2(1-p)^n+2n(n-1)(1-p)^{2n}+n^2(1-p)^{2n-1} \end{equation} And by Chebyshev inequality: \begin{eqnarray} \mathbb{P}(X=0)&\leq&\cfrac{\mathbb{V}X}{(\mathbb{E}X)^2} &\leq&\cfrac{4n^2(1-p)^n+2n(n-1)(1-p)^{2n}+n^2(1-p)^{2n-1}}{4n^2(1-p)^{2n}} \end{eqnarray} And sadly once again i got stuck with the limiting probability any hand on this?",,"['real-analysis', 'probability', 'analysis', 'graph-theory', 'random-graphs']"
85,proof of upper bound on differential entropy of f(X),proof of upper bound on differential entropy of f(X),,"I asked a similar question yesterday,  but I organized my question here a little and further asked my second question. Suppose $X$ is a continuous random variable with the pdf $f_x$, and $Y=g(X)$. If $g$ is a bijection, then via the change of variable method,  the pdf of $Y$ is $f_y = f_x/|J|$, where $|J|$ is the Jacobian of $g$. Therefore, $$h(Y)=h(X)+\int f_x \log |J| dx$$. From Wikipedia , if $dim(X)=dim(Y)$, there exists an upper bound on $h(Y)$ for a general map $g$: $$h(Y)\leq h(X)+\int f_x \log |J| dx \tag{1}$$  My first question is how to derive the inequality in Eq.(1). Second, is there a general approach to derive $h(Y)$ or an upper bound on it if $dim(X)\neq dim(Y)$. I'd appreciate any help and suggestions!","I asked a similar question yesterday,  but I organized my question here a little and further asked my second question. Suppose $X$ is a continuous random variable with the pdf $f_x$, and $Y=g(X)$. If $g$ is a bijection, then via the change of variable method,  the pdf of $Y$ is $f_y = f_x/|J|$, where $|J|$ is the Jacobian of $g$. Therefore, $$h(Y)=h(X)+\int f_x \log |J| dx$$. From Wikipedia , if $dim(X)=dim(Y)$, there exists an upper bound on $h(Y)$ for a general map $g$: $$h(Y)\leq h(X)+\int f_x \log |J| dx \tag{1}$$  My first question is how to derive the inequality in Eq.(1). Second, is there a general approach to derive $h(Y)$ or an upper bound on it if $dim(X)\neq dim(Y)$. I'd appreciate any help and suggestions!",,"['probability', 'information-theory', 'entropy']"
86,Help: SPSS and Data Interpretation of Voters. Republican vs. Democrats (1993 election)(Almost finished),Help: SPSS and Data Interpretation of Voters. Republican vs. Democrats (1993 election)(Almost finished),,"Hello everyone , I am Julieta this time I get stuck in the following exercise. It is a statistical analysis of pools, the statement is quite long I will try to keep it short and put some links. Note: Like in my other questions I asked here,I consider beacause the extension of this problem I will given at least 50 pts for the explanation of the problem. Also I am sorry for my broken grammar, english is my second language and I still improve it. :-) The problem was a real statistic problem that had social implication, and is explaned in the next article in NY times in detail: http://www.nytimes.com/1994/04/11/us/probability-experts-may-decide-pennsylvania-vote.html Here is the summary: Data: Year   District    DifferenceAbsentee    DifferenceMachine   82          2              346                    26427   82          4              282                    15904   82          8              223                    42448   84          1              593                    19444   84          3              572                    71797   84          5             -229                    -1017   84          7              671                    63406    86          2              293                    15671    86          4              360                    36276    86          8              306                    36710    88          1              401                    21848   88          3              378                    65862   88          5             -829                   -13194    88          7              394                    56100   90          2              151                      700   90          4             -349                    11529   90          8              160                    26047   92          1             1329                    44425   92          3              368                    45512   92          5             -434                    -5700    92          7              391                    51206   93          2             1025                     -564 There are several question and I will add my improvement in the mean time I can sussesfully reach an answer. I run SPSS over the given data and I obtained the following information, which I belive from this can be answer the all the following questions: (a) Find the p-value for the test H0 : β0 = 0 in your output. Explain (as you would to the judge in this case) what this number tells us. Interpret the results of the test in the context of the problem. SOLVED My ans: P-value=0.984  From the p-value obtained we have not enough evidence to reject the Ho in favor of the alternative, therefore Bo is not significative difference than 0. In the context of the problem this means that if there is no difference in Machine votes (DifferenceMachine=0) then we cannot say that the DiferenceAbstentees is different from 0. (b) Dr. Ashenfelter found that “the difference between the Democratic and Republican tallies in the machine-based vote has been a good indicator of the difference between the two parties’ absentee vote.” Explain how he could draw this conclusion based on your regression output. SOLVED My ans: I believe that the regression output is the table wich title is Model summary. But from my point of view Dr. Ashenfelter use that the value of p is sgnificant and therefore is a good indicator like he said. Is my answer correct? (b) The NY Times article states: “Assuming this relationship in the 21 previous elections had held in the most recent, Professor Ashenfelter estimates that the Republican’s 564-vote edge on the machines should have led to a 133-vote advantage in absentee ballots.” Explain (as Dr. Ashenfelter would explain to the judge), how one can come to this conclusion. SOLVED My answer: I used the model  y=b0+b1*x where b0 and b1 are the given from the model with 21 data point and not 22 and the anser is 133 as the statement said. (c) In the contested election the voting machine margin was -564. The absentee ballot margin, however, was 1025. Use your regression model to make a statistical argument for why this observation is unusual. Assume for now that the contested election was fair. Derive a probability for observing an absentee ballot margin as large or larger than the one observed if the election was fair. My answer: I am thinking I need to compute p(z>[(1025-133)/sqrt(MSE)]>2.74)  but the p value is not even close to 0.06. Why?? (d) Dr. Ashenfelter made a similar argument you just made and came up with a p-value of 0.06 for the test that decides H0 : the election was fair vs. Ha : there was fraud by the democrats The NY Times reporter interpreted this result as follows: “Putting it another way, if past elections are a reliable guide to current voting behavior, there is a 94 percent chance that irregularities in the absentee ballots, not chance alone, swung the elec- tion to the Democrat, Professor Ashenfelter concludes.”   Critique the reporter’s interpretation of the p-value. If the interpretation is correct, explain why. If the interpretation is incorrect, provide a correct interpretation instead. QUESTION: This is the last question that left answer, if someone know a good explanation. I belive the journalist is correct but I don't know how to verify this. Conclusion: Please, let me know if I need to improve something or change something. I will keep my work update, and like I said before I will be given points in the future. (I feel bad you reed such a long problem). THANKS AGAIN.","Hello everyone , I am Julieta this time I get stuck in the following exercise. It is a statistical analysis of pools, the statement is quite long I will try to keep it short and put some links. Note: Like in my other questions I asked here,I consider beacause the extension of this problem I will given at least 50 pts for the explanation of the problem. Also I am sorry for my broken grammar, english is my second language and I still improve it. :-) The problem was a real statistic problem that had social implication, and is explaned in the next article in NY times in detail: http://www.nytimes.com/1994/04/11/us/probability-experts-may-decide-pennsylvania-vote.html Here is the summary: Data: Year   District    DifferenceAbsentee    DifferenceMachine   82          2              346                    26427   82          4              282                    15904   82          8              223                    42448   84          1              593                    19444   84          3              572                    71797   84          5             -229                    -1017   84          7              671                    63406    86          2              293                    15671    86          4              360                    36276    86          8              306                    36710    88          1              401                    21848   88          3              378                    65862   88          5             -829                   -13194    88          7              394                    56100   90          2              151                      700   90          4             -349                    11529   90          8              160                    26047   92          1             1329                    44425   92          3              368                    45512   92          5             -434                    -5700    92          7              391                    51206   93          2             1025                     -564 There are several question and I will add my improvement in the mean time I can sussesfully reach an answer. I run SPSS over the given data and I obtained the following information, which I belive from this can be answer the all the following questions: (a) Find the p-value for the test H0 : β0 = 0 in your output. Explain (as you would to the judge in this case) what this number tells us. Interpret the results of the test in the context of the problem. SOLVED My ans: P-value=0.984  From the p-value obtained we have not enough evidence to reject the Ho in favor of the alternative, therefore Bo is not significative difference than 0. In the context of the problem this means that if there is no difference in Machine votes (DifferenceMachine=0) then we cannot say that the DiferenceAbstentees is different from 0. (b) Dr. Ashenfelter found that “the difference between the Democratic and Republican tallies in the machine-based vote has been a good indicator of the difference between the two parties’ absentee vote.” Explain how he could draw this conclusion based on your regression output. SOLVED My ans: I believe that the regression output is the table wich title is Model summary. But from my point of view Dr. Ashenfelter use that the value of p is sgnificant and therefore is a good indicator like he said. Is my answer correct? (b) The NY Times article states: “Assuming this relationship in the 21 previous elections had held in the most recent, Professor Ashenfelter estimates that the Republican’s 564-vote edge on the machines should have led to a 133-vote advantage in absentee ballots.” Explain (as Dr. Ashenfelter would explain to the judge), how one can come to this conclusion. SOLVED My answer: I used the model  y=b0+b1*x where b0 and b1 are the given from the model with 21 data point and not 22 and the anser is 133 as the statement said. (c) In the contested election the voting machine margin was -564. The absentee ballot margin, however, was 1025. Use your regression model to make a statistical argument for why this observation is unusual. Assume for now that the contested election was fair. Derive a probability for observing an absentee ballot margin as large or larger than the one observed if the election was fair. My answer: I am thinking I need to compute p(z>[(1025-133)/sqrt(MSE)]>2.74)  but the p value is not even close to 0.06. Why?? (d) Dr. Ashenfelter made a similar argument you just made and came up with a p-value of 0.06 for the test that decides H0 : the election was fair vs. Ha : there was fraud by the democrats The NY Times reporter interpreted this result as follows: “Putting it another way, if past elections are a reliable guide to current voting behavior, there is a 94 percent chance that irregularities in the absentee ballots, not chance alone, swung the elec- tion to the Democrat, Professor Ashenfelter concludes.”   Critique the reporter’s interpretation of the p-value. If the interpretation is correct, explain why. If the interpretation is incorrect, provide a correct interpretation instead. QUESTION: This is the last question that left answer, if someone know a good explanation. I belive the journalist is correct but I don't know how to verify this. Conclusion: Please, let me know if I need to improve something or change something. I will keep my work update, and like I said before I will be given points in the future. (I feel bad you reed such a long problem). THANKS AGAIN.",,"['probability', 'statistics', 'statistical-inference']"
87,Projection theorem for conditional probability,Projection theorem for conditional probability,,"$\def\cov{\mathop{\mathrm{cov}}}\def\var{\mathop{\mathrm{var}}}$My professor uses something that he calls the ""projection theorem"", to get rid of the condition in conditional probabilities (expectation and variance). I have not found anything about it on the internet, so I am wondering where it comes from, and if it is right. Here is the so-called ""projection theorem"": $$E[\tilde{x}\mid \tilde{y} = y] = E[\tilde{x}] + \frac{\cov(\tilde{x},\tilde{y})}{\var(\tilde{y})}\times(\tilde{y}-E(\tilde{y})),$$ and $$\var[\tilde{x}\mid \tilde{y}] = \var(\tilde{x})-\frac{\cov^2(\tilde{x},\tilde{y})}{\var(\tilde{y})}.$$ Are these formulas correct?","$\def\cov{\mathop{\mathrm{cov}}}\def\var{\mathop{\mathrm{var}}}$My professor uses something that he calls the ""projection theorem"", to get rid of the condition in conditional probabilities (expectation and variance). I have not found anything about it on the internet, so I am wondering where it comes from, and if it is right. Here is the so-called ""projection theorem"": $$E[\tilde{x}\mid \tilde{y} = y] = E[\tilde{x}] + \frac{\cov(\tilde{x},\tilde{y})}{\var(\tilde{y})}\times(\tilde{y}-E(\tilde{y})),$$ and $$\var[\tilde{x}\mid \tilde{y}] = \var(\tilde{x})-\frac{\cov^2(\tilde{x},\tilde{y})}{\var(\tilde{y})}.$$ Are these formulas correct?",,"['probability', 'conditional-expectation', 'covariance', 'variance']"
88,Multi-stage Probability,Multi-stage Probability,,"I think the easiest way to explain what I'm having trouble with is to give an example question: A monkey is given 12 blocks: 3 Squares, 3 Rectangles, 3 Triangles, 3 Circles. Calculate the probability of it drawing three of each kind in order - say, 3 triangles, then 3 squares and so on. I have done this question and gotten the right answer, however, I am not happy with my working out: $\frac{2}{11}* \frac{1}{10}* \frac{1}{4}* \frac{1}{7}* \frac{2}{5}* \frac{1}{4} = \frac{1}{15400}$ As you can see, I've basically gone through step by step, calculating the probability of each individual draw. My textbook shows the answer as this: $\frac{(4!)(3!)^4}{12!}=\frac{1}{15400}$ I have been told the reasoning is that firstly, there are $P_4^4$ ways of drawing the pattern in general (i.e. TCSR, CTRS, RTSC, etc.)... I understand this step but not sure as to why it is being done. Secondly, each pattern can be arranged in $P_3^3$ ways (i.e. T1, T3, T2). I understand this but i have no idea as to why the order of drawing these is relevant. Then from there I have absolutely no idea where any of the other part of the calculation arises from. Could someone please walk me through this example?","I think the easiest way to explain what I'm having trouble with is to give an example question: A monkey is given 12 blocks: 3 Squares, 3 Rectangles, 3 Triangles, 3 Circles. Calculate the probability of it drawing three of each kind in order - say, 3 triangles, then 3 squares and so on. I have done this question and gotten the right answer, however, I am not happy with my working out: $\frac{2}{11}* \frac{1}{10}* \frac{1}{4}* \frac{1}{7}* \frac{2}{5}* \frac{1}{4} = \frac{1}{15400}$ As you can see, I've basically gone through step by step, calculating the probability of each individual draw. My textbook shows the answer as this: $\frac{(4!)(3!)^4}{12!}=\frac{1}{15400}$ I have been told the reasoning is that firstly, there are $P_4^4$ ways of drawing the pattern in general (i.e. TCSR, CTRS, RTSC, etc.)... I understand this step but not sure as to why it is being done. Secondly, each pattern can be arranged in $P_3^3$ ways (i.e. T1, T3, T2). I understand this but i have no idea as to why the order of drawing these is relevant. Then from there I have absolutely no idea where any of the other part of the calculation arises from. Could someone please walk me through this example?",,"['probability', 'permutations']"
89,"Prove that if $X$ is subgaussian, then ${\bf E}e^{tX}=1+\sum_{k=1}^{\infty}\frac{t^k}{k!}{\bf E}X^k$","Prove that if  is subgaussian, then",X {\bf E}e^{tX}=1+\sum_{k=1}^{\infty}\frac{t^k}{k!}{\bf E}X^k,"Prove that if $X$ is subgaussian, then $${\bf E}e^{tX}=1+\sum_{k=1}^{\infty}\frac{t^k}{k!}{\bf E}X^k$$ So basically I just need to push the integral through the infinite sum $${\bf E}e^{tX}=\int_{\bf R}e^{tx}d\mu_X=\int_{\bf R}\sum_{k=0}^{\infty}\frac{(tx)^k}{k!}d\mu_X$$ Thus I'll use the dominated convergence theorem, bounding the absolute value of the partial sums by the (hopefully) $\mu_X$-integrable function $e^{|tx|}$, $$\Big|\sum_{k=0}^n\frac{(tx)^k}{k!}\Big|\leq e^{|tx|}$$ Now to show $e^{|tx|}$ is $\mu_X$-integrable, I have $$\int_{\bf R}e^{|tx|}d\mu_X=\;\;?$$ So by the subgaussian property of $X$ I have that $$P(|X|\geq\lambda)\leq\int_{\lambda}^{\infty}2cCxe^{-cx^2}dx=Ce^{-c\lambda^2}$$ for $c,C>0$ fixed and for any $\lambda>0$. Hence this integrand almost functions as my pdf for $X$, and if it did I could use the Radon-Nikodym theorem to solve this.  However even though any upper-tailed integral of it bounds that of the actual pdf , I can't quite see how to use it to bound the integral of $e^{|tx|}$.","Prove that if $X$ is subgaussian, then $${\bf E}e^{tX}=1+\sum_{k=1}^{\infty}\frac{t^k}{k!}{\bf E}X^k$$ So basically I just need to push the integral through the infinite sum $${\bf E}e^{tX}=\int_{\bf R}e^{tx}d\mu_X=\int_{\bf R}\sum_{k=0}^{\infty}\frac{(tx)^k}{k!}d\mu_X$$ Thus I'll use the dominated convergence theorem, bounding the absolute value of the partial sums by the (hopefully) $\mu_X$-integrable function $e^{|tx|}$, $$\Big|\sum_{k=0}^n\frac{(tx)^k}{k!}\Big|\leq e^{|tx|}$$ Now to show $e^{|tx|}$ is $\mu_X$-integrable, I have $$\int_{\bf R}e^{|tx|}d\mu_X=\;\;?$$ So by the subgaussian property of $X$ I have that $$P(|X|\geq\lambda)\leq\int_{\lambda}^{\infty}2cCxe^{-cx^2}dx=Ce^{-c\lambda^2}$$ for $c,C>0$ fixed and for any $\lambda>0$. Hence this integrand almost functions as my pdf for $X$, and if it did I could use the Radon-Nikodym theorem to solve this.  However even though any upper-tailed integral of it bounds that of the actual pdf , I can't quite see how to use it to bound the integral of $e^{|tx|}$.",,"['probability', 'measure-theory']"
90,"What is sample variance of sample variance, and what is theoretical sampling distribution?","What is sample variance of sample variance, and what is theoretical sampling distribution?",,"I am trying to work some things in R and I am having trouble understanding some of the instructions. I generated $1000$ samples of size $5$ from the standard normal distribution, and I calculated the mean of the sample variance of these. Now I want to know what the sample variance of my sample of sample variances is. But I am not sure I understand really what this means, nor how to implement this in R. Further, I am asked to overlay the histogram I generated from my sample with a histogram of the theoretical density of the sampling distribution. What does this mean? Ie, what is meant by the theoretical density of the sampling distribution of the sample variance. I know all my samples are coming from standard normal, where $\sigma^{2}=1$ and I know that if $X_{N}=X_{1}+...+X_{1000}$ would be $N(0,\frac{\sigma^{2}}{1000})$, is this at all what is being referred to? I will appreciate any help and advice. Thank you","I am trying to work some things in R and I am having trouble understanding some of the instructions. I generated $1000$ samples of size $5$ from the standard normal distribution, and I calculated the mean of the sample variance of these. Now I want to know what the sample variance of my sample of sample variances is. But I am not sure I understand really what this means, nor how to implement this in R. Further, I am asked to overlay the histogram I generated from my sample with a histogram of the theoretical density of the sampling distribution. What does this mean? Ie, what is meant by the theoretical density of the sampling distribution of the sample variance. I know all my samples are coming from standard normal, where $\sigma^{2}=1$ and I know that if $X_{N}=X_{1}+...+X_{1000}$ would be $N(0,\frac{\sigma^{2}}{1000})$, is this at all what is being referred to? I will appreciate any help and advice. Thank you",,"['probability', 'statistics', 'computer-algebra-systems']"
91,Bound on variance of bounded random variable,Bound on variance of bounded random variable,,"For a bounded random variable $X \in [a,b]$, we know $\operatorname{Var}(X) \le (b-a)^2/4$, see for example this answer . I am trying to give an alternate proof using symmetrization. If $Y$ is an independent copy of $X$, we can rewrite the variance as $\frac{1}{2} \mathbb{E}(X-Y)^2$, where the expectation is over $X$ and $Y$. Another formulation is $\mathbb{E}[(X-Y)^2\mathbf{1}[Y \ge X]]$. However, bounding $(X-Y)^2$ by $(b-a)^2$ gives the looser upper bound $(b-a)^2/2$. Is there a way to tighten this while still using this symmetrization idea, or can this approach not be used to get the optimal $(b-a)^2/4$ bound?","For a bounded random variable $X \in [a,b]$, we know $\operatorname{Var}(X) \le (b-a)^2/4$, see for example this answer . I am trying to give an alternate proof using symmetrization. If $Y$ is an independent copy of $X$, we can rewrite the variance as $\frac{1}{2} \mathbb{E}(X-Y)^2$, where the expectation is over $X$ and $Y$. Another formulation is $\mathbb{E}[(X-Y)^2\mathbf{1}[Y \ge X]]$. However, bounding $(X-Y)^2$ by $(b-a)^2$ gives the looser upper bound $(b-a)^2/2$. Is there a way to tighten this while still using this symmetrization idea, or can this approach not be used to get the optimal $(b-a)^2/4$ bound?",,"['probability', 'random-variables', 'expectation']"
92,"Will the conditional expectation always have this ""property""?(understanding/explanation of conditional expectation)","Will the conditional expectation always have this ""property""?(understanding/explanation of conditional expectation)",,"Lets say you have a probability space $(\Omega, \mathcal{A},P)$, and a random variable $X: \Omega \rightarrow \mathbb{R}$ on this space. Assume that we have a sub-sigma algebra $\mathcal{G}\subset \mathcal{A}$. We can then show that $\mu_X(G)=\int_GXdP$, is a measure on $(\Omega, \mathcal{G})$, it is also easy to see that this measure is absolutely continuous with respect to P. The Radon-Nikodym theorem tells us that we have a unique $P$-a.e $\mathcal{G}$-measurable function $\mathcal{E}(X|\mathcal{G})$ on $\Omega$, s.t. $\mu_X(G)=\int_G\mathcal{E}(X|\mathcal{G})dP, G \in \mathcal{G}$. My problem is that I have a hard time describing $\mathcal{E}(X|\mathcal{G})$ in general. If I make a specific example like this: $\Omega=\{1,2,3,4\}$ $\mathcal{A}=\{\emptyset,\{1\},\{2,3\},\{4\},\{1,4\},\{1,2,3\},\{2,3,4\},\Omega\}$ $ P(\{1\})=0.5,P(\{2,3\})=0.25, P(\{4\})=0.25$ $ X(1)=1, X(2)=3,X(3)=3,X(4)=4$ $\mathcal{G}=\{\emptyset, \{1,4\},\{2,3\},\Omega\}$ Then a calculation, and using the uniqueness of the radon nikodym derivative, gives us that: $\mathcal{E}(X|\mathcal{G})(\omega)=2\mathcal{X}_{\{1,4\}}(\omega)+3\mathcal{X}_{\{2,3\}}(\omega)$. Now comes my question: From elementary courses in probability and statistics, we can show that $E(X|\{1,4\})=2$ and $E(X|\{2,3\})=3$. So in this case, we see that the conditional expectation can be described this way: If you can only differentiate between the sets in $\mathcal{G}$ then the value of the conditional expectation for a given omega, is the value of the conditional expectation of the set in $\mathcal{G}$ containing $\Omega$ which is ""smallest"", or where we have eliminated most of the possibilities that did not happen, and that the sigma algebra $\mathcal{G}$ allows us to remove. But this was an easy example. And in general you may not have smallest sets like this? But is there an intuitive or good explanation of the value of the conditional expectation when we work with larger sets like countable or uncountable? Is there an equivalent way of saying in these cases for associating the value of the conditional expectation with the conditional expectation of a set as given in elementary statistics? Or is there some theorem or explanation that generalises what I did above for ""small"" sets. And gives a good intuitive justification for conditional expectation here? If you have other intuitive ""explanations"" of the conditional expectation, I would like to hear them as well.","Lets say you have a probability space $(\Omega, \mathcal{A},P)$, and a random variable $X: \Omega \rightarrow \mathbb{R}$ on this space. Assume that we have a sub-sigma algebra $\mathcal{G}\subset \mathcal{A}$. We can then show that $\mu_X(G)=\int_GXdP$, is a measure on $(\Omega, \mathcal{G})$, it is also easy to see that this measure is absolutely continuous with respect to P. The Radon-Nikodym theorem tells us that we have a unique $P$-a.e $\mathcal{G}$-measurable function $\mathcal{E}(X|\mathcal{G})$ on $\Omega$, s.t. $\mu_X(G)=\int_G\mathcal{E}(X|\mathcal{G})dP, G \in \mathcal{G}$. My problem is that I have a hard time describing $\mathcal{E}(X|\mathcal{G})$ in general. If I make a specific example like this: $\Omega=\{1,2,3,4\}$ $\mathcal{A}=\{\emptyset,\{1\},\{2,3\},\{4\},\{1,4\},\{1,2,3\},\{2,3,4\},\Omega\}$ $ P(\{1\})=0.5,P(\{2,3\})=0.25, P(\{4\})=0.25$ $ X(1)=1, X(2)=3,X(3)=3,X(4)=4$ $\mathcal{G}=\{\emptyset, \{1,4\},\{2,3\},\Omega\}$ Then a calculation, and using the uniqueness of the radon nikodym derivative, gives us that: $\mathcal{E}(X|\mathcal{G})(\omega)=2\mathcal{X}_{\{1,4\}}(\omega)+3\mathcal{X}_{\{2,3\}}(\omega)$. Now comes my question: From elementary courses in probability and statistics, we can show that $E(X|\{1,4\})=2$ and $E(X|\{2,3\})=3$. So in this case, we see that the conditional expectation can be described this way: If you can only differentiate between the sets in $\mathcal{G}$ then the value of the conditional expectation for a given omega, is the value of the conditional expectation of the set in $\mathcal{G}$ containing $\Omega$ which is ""smallest"", or where we have eliminated most of the possibilities that did not happen, and that the sigma algebra $\mathcal{G}$ allows us to remove. But this was an easy example. And in general you may not have smallest sets like this? But is there an intuitive or good explanation of the value of the conditional expectation when we work with larger sets like countable or uncountable? Is there an equivalent way of saying in these cases for associating the value of the conditional expectation with the conditional expectation of a set as given in elementary statistics? Or is there some theorem or explanation that generalises what I did above for ""small"" sets. And gives a good intuitive justification for conditional expectation here? If you have other intuitive ""explanations"" of the conditional expectation, I would like to hear them as well.",,"['real-analysis', 'probability', 'probability-theory', 'measure-theory', 'conditional-expectation']"
93,Expected Value of Maximum of Two Lognormal Random Variables,Expected Value of Maximum of Two Lognormal Random Variables,,"We have two random variables $X$ and $Y$ which are log normally distributed, with suitable parameters, what is the expected value for $\max(X,Y)$? Given, $$ X=e^{\mu+\sigma Z_{1}};\quad Y=e^{\nu+\tau Z_{2}};\quad Z_{1}\sim N(0,1);Z_{2}\sim N(0,1); $$ $Z_{1}, Z_{2}$ can be assumed independent if it simplifies matters. We need to find an expression for $$E[\text{max}(X,Y)]$$ Please note I have reached the step below, but am unsure how to proceed further. Steps Tried \begin{eqnarray*} E\left[\max\left(X,Y\right)\right]=\int_{0}^{\infty}xf_{Y}\left(x\right)F_{X}\left(x\right)dx+\int_{0}^{\infty}yf_{X}\left(y\right)F_{Y}\left(y\right)dy \end{eqnarray*} \begin{eqnarray*} \int_{0}^{\infty}xf_{Y}\left(x\right)F_{X}\left(x\right)dx{\displaystyle =\int_{0}^{\infty}\frac{1}{\tau}\phi\left(\frac{\ln x-\nu}{\tau}\right)}\Phi\left(\frac{\ln x-\mu}{\sigma}\right)dx \end{eqnarray*} \begin{eqnarray*} {\displaystyle =\int_{0}^{\infty}\frac{1}{\tau}\phi\left(\frac{\ln x-\nu}{\tau}\right)}\Phi\left(\frac{\ln x-\mu}{\sigma}\right)dx\quad\text{, Substitution }u=\left(\frac{\ln x-\nu}{\tau}\right)\Rightarrow du=\frac{1}{x\tau}dx \end{eqnarray*} \begin{eqnarray*} {\displaystyle =\int_{-\infty}^{\infty}e^{u\tau+\nu}\phi\left(u\right)}\Phi\left(\frac{u\tau+\nu-\mu}{\sigma}\right)du \end{eqnarray*} \begin{eqnarray*} {\displaystyle =e^{\nu}\int_{-\infty}^{\infty}e^{u\tau}\phi\left(u\right)}\Phi\left(\frac{u\tau+\nu-\mu}{\sigma}\right)du \end{eqnarray*} Related Question Please note, an earlier question considers the case where there is only one source of randomness. This earlier question was mis-phrased due to my limited knowledge; but still provides an interesting and instructive solution. Expected Value of Maximum of Two Lognormal Random Variables with One Source of Randomness Please let me know of any other suggestions …","We have two random variables $X$ and $Y$ which are log normally distributed, with suitable parameters, what is the expected value for $\max(X,Y)$? Given, $$ X=e^{\mu+\sigma Z_{1}};\quad Y=e^{\nu+\tau Z_{2}};\quad Z_{1}\sim N(0,1);Z_{2}\sim N(0,1); $$ $Z_{1}, Z_{2}$ can be assumed independent if it simplifies matters. We need to find an expression for $$E[\text{max}(X,Y)]$$ Please note I have reached the step below, but am unsure how to proceed further. Steps Tried \begin{eqnarray*} E\left[\max\left(X,Y\right)\right]=\int_{0}^{\infty}xf_{Y}\left(x\right)F_{X}\left(x\right)dx+\int_{0}^{\infty}yf_{X}\left(y\right)F_{Y}\left(y\right)dy \end{eqnarray*} \begin{eqnarray*} \int_{0}^{\infty}xf_{Y}\left(x\right)F_{X}\left(x\right)dx{\displaystyle =\int_{0}^{\infty}\frac{1}{\tau}\phi\left(\frac{\ln x-\nu}{\tau}\right)}\Phi\left(\frac{\ln x-\mu}{\sigma}\right)dx \end{eqnarray*} \begin{eqnarray*} {\displaystyle =\int_{0}^{\infty}\frac{1}{\tau}\phi\left(\frac{\ln x-\nu}{\tau}\right)}\Phi\left(\frac{\ln x-\mu}{\sigma}\right)dx\quad\text{, Substitution }u=\left(\frac{\ln x-\nu}{\tau}\right)\Rightarrow du=\frac{1}{x\tau}dx \end{eqnarray*} \begin{eqnarray*} {\displaystyle =\int_{-\infty}^{\infty}e^{u\tau+\nu}\phi\left(u\right)}\Phi\left(\frac{u\tau+\nu-\mu}{\sigma}\right)du \end{eqnarray*} \begin{eqnarray*} {\displaystyle =e^{\nu}\int_{-\infty}^{\infty}e^{u\tau}\phi\left(u\right)}\Phi\left(\frac{u\tau+\nu-\mu}{\sigma}\right)du \end{eqnarray*} Related Question Please note, an earlier question considers the case where there is only one source of randomness. This earlier question was mis-phrased due to my limited knowledge; but still provides an interesting and instructive solution. Expected Value of Maximum of Two Lognormal Random Variables with One Source of Randomness Please let me know of any other suggestions …",,"['probability', 'probability-distributions', 'expectation']"
94,"What is the probability that a family with $3$ children has at least one girl, given that at least one is a boy$?$","What is the probability that a family with  children has at least one girl, given that at least one is a boy",3 ?,"$(1)$ What is the probability that that a family with $3$ children has at least one girl, given that at least one is a boy? $(2)$ And what's the probability that they have at least one boy AND one girl? $(3)$ And what's the probability that they have at least one boy OR one girl? All possible combinations: BBB    BBG   BGB   BGG   GBB   GBG   GGB   GGG Question $(1)$: Exclude the 'GGG' option. $\implies$ $P$(at least $1$ boy) $= 7/8$ The new sample space is $7$ of which $6$ have at least $1$ girl $\implies$ $P$(at least $1$ girl $\mid$ at least $1$ boy) $= 6/7$ Question $(2)$: By looking at the combinations I can quickly say that there are $6$ out of $8$ that satisfy (at least $1$ girl AND at least $1$ boy). $\implies 6/8 = 3/4$.  However, considering larger data sets, this becomes impossible. According to: $P(A\ \text{and}\ B) = P(A)*P(B|A) = \frac{7}{8} \times  \frac{6}{7} = \frac{6}{8} = \frac{3}{4} $  I get the same result. So, why does multiplying  $7/8 \times  6/7$ provide the correct result? I know that the denominators $7\times 8$ produce a new sample space (permutations), and the $7\times 6$ new desirable outcomes (permutations). But these are permutations of $(x,y)$ ($2$ children) not $(x,y,z)$ ($3$ children). But I cannot explain why it works, since the original sample space does not consider permutations. Or am I wrong? Many thanks for assistance in explaining why this works. $(3)$ What is the difference between $(2)$ and $(3)?$ Are they not the same?","$(1)$ What is the probability that that a family with $3$ children has at least one girl, given that at least one is a boy? $(2)$ And what's the probability that they have at least one boy AND one girl? $(3)$ And what's the probability that they have at least one boy OR one girl? All possible combinations: BBB    BBG   BGB   BGG   GBB   GBG   GGB   GGG Question $(1)$: Exclude the 'GGG' option. $\implies$ $P$(at least $1$ boy) $= 7/8$ The new sample space is $7$ of which $6$ have at least $1$ girl $\implies$ $P$(at least $1$ girl $\mid$ at least $1$ boy) $= 6/7$ Question $(2)$: By looking at the combinations I can quickly say that there are $6$ out of $8$ that satisfy (at least $1$ girl AND at least $1$ boy). $\implies 6/8 = 3/4$.  However, considering larger data sets, this becomes impossible. According to: $P(A\ \text{and}\ B) = P(A)*P(B|A) = \frac{7}{8} \times  \frac{6}{7} = \frac{6}{8} = \frac{3}{4} $  I get the same result. So, why does multiplying  $7/8 \times  6/7$ provide the correct result? I know that the denominators $7\times 8$ produce a new sample space (permutations), and the $7\times 6$ new desirable outcomes (permutations). But these are permutations of $(x,y)$ ($2$ children) not $(x,y,z)$ ($3$ children). But I cannot explain why it works, since the original sample space does not consider permutations. Or am I wrong? Many thanks for assistance in explaining why this works. $(3)$ What is the difference between $(2)$ and $(3)?$ Are they not the same?",,"['probability', 'combinatorics']"
95,If a sequence of quadratic forms converges in probability and a random vector converges in distribution then $X_n^TQ_nX_n$ converges,If a sequence of quadratic forms converges in probability and a random vector converges in distribution then  converges,X_n^TQ_nX_n,"If a sequence of quadratic forms converges in probability $Q_n\xrightarrow{P}Q$ and a random vector converges in distribution  $X_n\xrightarrow{d}X$ then $X_n^TQ_nX_n\xrightarrow{d}X^TQX$. This is a statement from an online source in statistics. It follows by Slutsky's theorem and the continuous mapping theorem. I can also see how intuitively it should be true, but I'm having trouble setting up the argument. No matter what I do, in the end I have a product of two things converging only in distribution.","If a sequence of quadratic forms converges in probability $Q_n\xrightarrow{P}Q$ and a random vector converges in distribution  $X_n\xrightarrow{d}X$ then $X_n^TQ_nX_n\xrightarrow{d}X^TQX$. This is a statement from an online source in statistics. It follows by Slutsky's theorem and the continuous mapping theorem. I can also see how intuitively it should be true, but I'm having trouble setting up the argument. No matter what I do, in the end I have a product of two things converging only in distribution.",,['probability']
96,"If the sum of two independent random variables is $ L^{p} $, does it imply that each is $ L^{p} $?","If the sum of two independent random variables is , does it imply that each is ?", L^{p}   L^{p} ,"Let $ X $ and $ Y $ be two independent random variables, i.e., $$ \forall a,b \in \Bbb{R}: \quad \textbf{Pr}(X < a,Y < b) = \textbf{Pr}(X < a) ~ \textbf{Pr}(Y < b). $$ Let $ p > 0 $ (not necessarily $ > 1 $). If $ \Bbb{E}[|X + Y|^{p}] < \infty $, how can we prove that $ \Bbb{E}[|X|^{p}] < \infty $?","Let $ X $ and $ Y $ be two independent random variables, i.e., $$ \forall a,b \in \Bbb{R}: \quad \textbf{Pr}(X < a,Y < b) = \textbf{Pr}(X < a) ~ \textbf{Pr}(Y < b). $$ Let $ p > 0 $ (not necessarily $ > 1 $). If $ \Bbb{E}[|X + Y|^{p}] < \infty $, how can we prove that $ \Bbb{E}[|X|^{p}] < \infty $?",,"['probability', 'random-variables', 'expectation', 'lp-spaces']"
97,Convergence to normal distribution,Convergence to normal distribution,,"Consider the probability distribution of the simple symmetric walk.  That is the random variable $X_i$ equals $c$ or $-c$ with equal probability and all $X_i$ are independent and $c\geq1$.  We are interested in $$S_n = X_1 + X_2 + \dots + X_n.$$ We know from the central limit theorem that $S_n/\sqrt{n}$ converges in distribution to the normal distribution $N(0,c^2)$. We also know that the entropy of the normal distribution $N(0,c^2)$ is $\frac{1}{2}\ln(2\pi e c^2)$. It is clear we can't tell derive the entropy of $S_n$ as $n \rightarrow \infty$ directly from this formula for the normal distribution. This is because the entropy of $S_n$ is invariant to $c$ but the entropy of the normal distribution is not. The differential entropy wikipedia page gives a correction term but I can't understand how to apply it. How exactly do you apply the correction term to $\frac{1}{2}\ln(2\pi e  \sigma^2)$ in this example to get the correct entropy for $S_n$ as $n  \to \infty$?","Consider the probability distribution of the simple symmetric walk.  That is the random variable $X_i$ equals $c$ or $-c$ with equal probability and all $X_i$ are independent and $c\geq1$.  We are interested in $$S_n = X_1 + X_2 + \dots + X_n.$$ We know from the central limit theorem that $S_n/\sqrt{n}$ converges in distribution to the normal distribution $N(0,c^2)$. We also know that the entropy of the normal distribution $N(0,c^2)$ is $\frac{1}{2}\ln(2\pi e c^2)$. It is clear we can't tell derive the entropy of $S_n$ as $n \rightarrow \infty$ directly from this formula for the normal distribution. This is because the entropy of $S_n$ is invariant to $c$ but the entropy of the normal distribution is not. The differential entropy wikipedia page gives a correction term but I can't understand how to apply it. How exactly do you apply the correction term to $\frac{1}{2}\ln(2\pi e  \sigma^2)$ in this example to get the correct entropy for $S_n$ as $n  \to \infty$?",,['probability']
98,Actuarial Problem. (Policyholder).What is the probability that a new policyholder will have an accident within a year of purchasinag a policy?,Actuarial Problem. (Policyholder).What is the probability that a new policyholder will have an accident within a year of purchasinag a policy?,,"Problem said: Suppose people can be divided into two classes: those   who are accident-prone and those who are not. The statistics show that   an accident-prone person will have an accident at some time within a   fide 1-year period with probability 0.35, whereas this probability for   a non-accidenta-prone person is 0.18. Assume that 30.3% of the   population is accident-prone. What is the probability that a new policyholder will have an accident   within a year of purchasinag a policy? I apply the law of the total probability: I have: P(a new policyholder will have an accident )=(0.303) (.35)+(.697) (0.18)=0.23152 Is that correct? Thanks.","Problem said: Suppose people can be divided into two classes: those   who are accident-prone and those who are not. The statistics show that   an accident-prone person will have an accident at some time within a   fide 1-year period with probability 0.35, whereas this probability for   a non-accidenta-prone person is 0.18. Assume that 30.3% of the   population is accident-prone. What is the probability that a new policyholder will have an accident   within a year of purchasinag a policy? I apply the law of the total probability: I have: P(a new policyholder will have an accident )=(0.303) (.35)+(.697) (0.18)=0.23152 Is that correct? Thanks.",,"['probability', 'actuarial-science']"
99,Prove uniform distribution,Prove uniform distribution,,"For any random variable $X$, there exists a $U(0,1)$ random variable $U_X$ such that $X=F_X^{-1}(U_X)$ almost surely. Proof: In the case that $F_X$ is continuous, using $U_X=F_X(X)$ would suffice. In the general case, the statement is proven by using $U_X=F_X(X^-)+V(F_X(X)-F_X(X^-))$, where $V$ is a $U(0,1)$ random variable independent of $X$ and $F_X(x^-)$ denotes the left limit of $F_X$ for $x\in\mathbb{R}$. How does one easily see/show that $U_X$ in the general case is a $U(0,1)$ random variable?","For any random variable $X$, there exists a $U(0,1)$ random variable $U_X$ such that $X=F_X^{-1}(U_X)$ almost surely. Proof: In the case that $F_X$ is continuous, using $U_X=F_X(X)$ would suffice. In the general case, the statement is proven by using $U_X=F_X(X^-)+V(F_X(X)-F_X(X^-))$, where $V$ is a $U(0,1)$ random variable independent of $X$ and $F_X(x^-)$ denotes the left limit of $F_X$ for $x\in\mathbb{R}$. How does one easily see/show that $U_X$ in the general case is a $U(0,1)$ random variable?",,"['probability', 'statistics', 'probability-distributions', 'order-statistics']"
