,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Proof of Riesz Lemma,Proof of Riesz Lemma,,"Here is the proof of the Riesz Lemma. When the author show that $\| z-y \| \geq \theta$, I don't understand the following step: $$\dfrac{1}{\| v-y_0 \|} \| v-y_0 - (\| v-y_0 \|)y \| \geq \dfrac{\alpha}{\| v-y_0 \|}$$ How to obtain the above step?","Here is the proof of the Riesz Lemma. When the author show that $\| z-y \| \geq \theta$, I don't understand the following step: $$\dfrac{1}{\| v-y_0 \|} \| v-y_0 - (\| v-y_0 \|)y \| \geq \dfrac{\alpha}{\| v-y_0 \|}$$ How to obtain the above step?",,"['functional-analysis', 'proof-verification']"
1,"Dual of ""Dual of Fréchet Space with Weak*-Topology"" Equals Dual of ""Dual of Fréchet Space with Topology of Compact Convergence""","Dual of ""Dual of Fréchet Space with Weak*-Topology"" Equals Dual of ""Dual of Fréchet Space with Topology of Compact Convergence""",,"Let $X$ be a Fréchet space. I know that: Closed convex, balanced, hulls of compact subsets of $X$ are compact. Let ${X^*}$ denote the (topological) dual space. I know that: ${X^*}$ is also the dual of ""$X$ with the weak topology (induced by ${X^*}$)"". Weakly bounded sets in $X$ are bounded sets in $X$. Now, ${X^*}$ can be given the weak*-topology (induced by $X$). I know that: The dual of ""${X^*}$ with the weak* topology"" is $X$ (as vector spaces). ${X^*}$ can also be given the topology of uniform convergence on compact subsets of $X$. Is it possible to prove directly - without delving into the theory of locally convex topologies on dual pairs and the Mackey-Arens theorem - that in this special case, starting with a Fréchet space $X$, the dual of ""${X^*}$ with the topology of uniform convergence on compact subsets of $X$"" is $X$ (as vector spaces)?","Let $X$ be a Fréchet space. I know that: Closed convex, balanced, hulls of compact subsets of $X$ are compact. Let ${X^*}$ denote the (topological) dual space. I know that: ${X^*}$ is also the dual of ""$X$ with the weak topology (induced by ${X^*}$)"". Weakly bounded sets in $X$ are bounded sets in $X$. Now, ${X^*}$ can be given the weak*-topology (induced by $X$). I know that: The dual of ""${X^*}$ with the weak* topology"" is $X$ (as vector spaces). ${X^*}$ can also be given the topology of uniform convergence on compact subsets of $X$. Is it possible to prove directly - without delving into the theory of locally convex topologies on dual pairs and the Mackey-Arens theorem - that in this special case, starting with a Fréchet space $X$, the dual of ""${X^*}$ with the topology of uniform convergence on compact subsets of $X$"" is $X$ (as vector spaces)?",,['functional-analysis']
2,How is the weak-star topology useful?,How is the weak-star topology useful?,,"Today I learnt something about the weak-star topology, but I don't know what the use of weak-star topology is. I hope someone can tell me what we can do with the weak-star topology. Thanks in advance!","Today I learnt something about the weak-star topology, but I don't know what the use of weak-star topology is. I hope someone can tell me what we can do with the weak-star topology. Thanks in advance!",,"['functional-analysis', 'banach-spaces', 'locally-convex-spaces']"
3,Approximating a Hilbert-Schmidt operator,Approximating a Hilbert-Schmidt operator,,"Let $H$ be a separable Hilbert space.  Recall that a bounded operator $A : H \to H$ is said to be Hilbert-Schmidt if $$\|A\|_{HS}^2 := \sum_{i=1}^\infty \|A e_i\|^2 < \infty$$ where $\{e_i\}_{i=1}^\infty$ is an orthonormal basis for $H$.  (The value of $\|A\|_{HS}$ does not depend on the basis chosen.) Suppose that $A$ is Hilbert-Schmidt, and let $\{P_n\}$ be a sequence of finite-rank orthogonal projection operators on $H$, such that $P_n \to I$ strongly (i.e. $P_n x \to x$ for every $x \in H$).  Does $P_n A P_n \to A$ in the Hilbert-Schmidt norm $\|\cdot\|_{HS}$? I can prove this under the additional assumption that $\{P_n\}$ is increasing, i.e. $P_n H \subset P_{n+1} H$.  In this case, we may choose an orthonormal basis $\{e_i\}$ for $H$ such that for each $n$, $e_1, \dots, e_{d_n}$ is an orthonormal basis for $P_n H$, where $d_n$ is the rank of $P_n$.  Then $P_n e_i$ = $e_i$ for $i \le d_n$, and $P_n e_i = 0$ otherwise, so we can write $$\|P_n A P_n - A\|_{HS}^2 = \sum_{i=1}^{d_n} \|(P_n - I) A e_i\|^2 + \sum_{i=d_n+1}^\infty \|A e_i\|^2.$$ As $n \to \infty$, $d_n \to \infty$, and the second term goes to 0 because it is the tail of the convergent series $\sum \|A e_i\|^2 = \|A\|_{HS}^2$.  For the first term, we have $$\|(P_n - I) A e_i\| \le \|P_n - I\| \|A e_i\| \le 2 \|A e_i\|$$ which is a square-summable sequence because $A$ is Hilbert-Schmidt.  And for each $i$ we have $\|(P_n - I) A e_i\| \to 0$ since $P_n \to I$ strongly.  So by the dominated convergence theorem, we conclude the first term also goes to 0. However, without this assumption, $P_n e_i$ is harder to deal with, and I don't see how to craft a proof (nor a counterexample). If it helps, I'm most interested in the case where $A$ is skew-adjoint, i.e. $A^* = -A$. I'd also be interested to know if this statement still holds if we drop the assumption that $P_n$ are orthogonal projections, and only assume that they are finite rank and converge strongly to $I$. Thanks!","Let $H$ be a separable Hilbert space.  Recall that a bounded operator $A : H \to H$ is said to be Hilbert-Schmidt if $$\|A\|_{HS}^2 := \sum_{i=1}^\infty \|A e_i\|^2 < \infty$$ where $\{e_i\}_{i=1}^\infty$ is an orthonormal basis for $H$.  (The value of $\|A\|_{HS}$ does not depend on the basis chosen.) Suppose that $A$ is Hilbert-Schmidt, and let $\{P_n\}$ be a sequence of finite-rank orthogonal projection operators on $H$, such that $P_n \to I$ strongly (i.e. $P_n x \to x$ for every $x \in H$).  Does $P_n A P_n \to A$ in the Hilbert-Schmidt norm $\|\cdot\|_{HS}$? I can prove this under the additional assumption that $\{P_n\}$ is increasing, i.e. $P_n H \subset P_{n+1} H$.  In this case, we may choose an orthonormal basis $\{e_i\}$ for $H$ such that for each $n$, $e_1, \dots, e_{d_n}$ is an orthonormal basis for $P_n H$, where $d_n$ is the rank of $P_n$.  Then $P_n e_i$ = $e_i$ for $i \le d_n$, and $P_n e_i = 0$ otherwise, so we can write $$\|P_n A P_n - A\|_{HS}^2 = \sum_{i=1}^{d_n} \|(P_n - I) A e_i\|^2 + \sum_{i=d_n+1}^\infty \|A e_i\|^2.$$ As $n \to \infty$, $d_n \to \infty$, and the second term goes to 0 because it is the tail of the convergent series $\sum \|A e_i\|^2 = \|A\|_{HS}^2$.  For the first term, we have $$\|(P_n - I) A e_i\| \le \|P_n - I\| \|A e_i\| \le 2 \|A e_i\|$$ which is a square-summable sequence because $A$ is Hilbert-Schmidt.  And for each $i$ we have $\|(P_n - I) A e_i\| \to 0$ since $P_n \to I$ strongly.  So by the dominated convergence theorem, we conclude the first term also goes to 0. However, without this assumption, $P_n e_i$ is harder to deal with, and I don't see how to craft a proof (nor a counterexample). If it helps, I'm most interested in the case where $A$ is skew-adjoint, i.e. $A^* = -A$. I'd also be interested to know if this statement still holds if we drop the assumption that $P_n$ are orthogonal projections, and only assume that they are finite rank and converge strongly to $I$. Thanks!",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
4,Is the weak-star topology on the dual of a Banach space completely regular?,Is the weak-star topology on the dual of a Banach space completely regular?,,"Does the weak-star topology on the dual of a separable Banach space make the dual completely regular under weak-star topology? So I have come to the stage in a proof where if I could show this, then I would be done! In case you are interested in the original problem. That is to show that a weak-star closed subset of the unit ball $B'$ in the dual space, is a Z-set in $B'$","Does the weak-star topology on the dual of a separable Banach space make the dual completely regular under weak-star topology? So I have come to the stage in a proof where if I could show this, then I would be done! In case you are interested in the original problem. That is to show that a weak-star closed subset of the unit ball $B'$ in the dual space, is a Z-set in $B'$",,[]
5,Metrizability of weak convergence by the bounded Lipschitz metric,Metrizability of weak convergence by the bounded Lipschitz metric,,"Why is the weak convergence of probability measures on $\mathbb{R}$  with respect to bounded continuous test functions $C^0_b(\mathbb{R})$ metrizable by the bounded Lipschitz metric $$d(\mu, \nu) = \sup_{f \in \text{Lip}(\mathbb{R})} \Big | \int_{\mathbb{R}} f d \nu - \int_{\mathbb{R}} f d \mu \Big |$$ where $$\text{Lip}(\mathbb{R}) = \Big \{ f \in C_b(\mathbb{R}) : \sup_x |f(x) | \leq 1, \sup_{x \neq y} \frac{| f(x) - f(y) |}{|x-y|} \leq 1 \Big \}?$$ For those who would like a reference, this is invoked in the proof of the truncated version of Wigner's semicircle law in Anderson-Guionnet-Zeitouni's $\textit{Introduction to Random Matrices}$ and is cited in the appendix as part of Theorem C.8, though no proof is given there.  If anyone could help me with this fact, I'd greatly appreciate it!","Why is the weak convergence of probability measures on $\mathbb{R}$  with respect to bounded continuous test functions $C^0_b(\mathbb{R})$ metrizable by the bounded Lipschitz metric $$d(\mu, \nu) = \sup_{f \in \text{Lip}(\mathbb{R})} \Big | \int_{\mathbb{R}} f d \nu - \int_{\mathbb{R}} f d \mu \Big |$$ where $$\text{Lip}(\mathbb{R}) = \Big \{ f \in C_b(\mathbb{R}) : \sup_x |f(x) | \leq 1, \sup_{x \neq y} \frac{| f(x) - f(y) |}{|x-y|} \leq 1 \Big \}?$$ For those who would like a reference, this is invoked in the proof of the truncated version of Wigner's semicircle law in Anderson-Guionnet-Zeitouni's $\textit{Introduction to Random Matrices}$ and is cited in the appendix as part of Theorem C.8, though no proof is given there.  If anyone could help me with this fact, I'd greatly appreciate it!",,"['analysis', 'functional-analysis', 'measure-theory', 'metric-spaces']"
6,(Product) Lebesgue measure on infinite dimensional spaces?,(Product) Lebesgue measure on infinite dimensional spaces?,,I am trying to understand measure construction procedures on infinite-dimensional spaces. Why is it not possible in general to construct Lebesgue measure on $\mathbb{R}^\mathbb{N}$ or $\mathbb{R}^\mathbb{R}$?,I am trying to understand measure construction procedures on infinite-dimensional spaces. Why is it not possible in general to construct Lebesgue measure on $\mathbb{R}^\mathbb{N}$ or $\mathbb{R}^\mathbb{R}$?,,"['functional-analysis', 'reference-request', 'measure-theory']"
7,Criterion for convergence of the sequence of powers of a linear operator to $0$,Criterion for convergence of the sequence of powers of a linear operator to,0,"Let $T$ be a linear operator in a Banach space $\mathbf{B}$. Suppose that for every $x \in \mathbf{B}$ there exists some real numbers $c_x>0$ and $a_x<1$ such that $||T^nx|| \leq ca^n$, for all $n \in \mathbb{N}$. Prove that $||T^n|| \to 0$ as $n \to \infty$. I could only deduce that $T^nx \to 0$ for all $x \in \mathbf{B}$, but I don't think it's enough. It's easy to show, using the uniform boundedness principle, that $||T^n||$ is bounded, but again that's not enough.","Let $T$ be a linear operator in a Banach space $\mathbf{B}$. Suppose that for every $x \in \mathbf{B}$ there exists some real numbers $c_x>0$ and $a_x<1$ such that $||T^nx|| \leq ca^n$, for all $n \in \mathbb{N}$. Prove that $||T^n|| \to 0$ as $n \to \infty$. I could only deduce that $T^nx \to 0$ for all $x \in \mathbf{B}$, but I don't think it's enough. It's easy to show, using the uniform boundedness principle, that $||T^n||$ is bounded, but again that's not enough.",,"['functional-analysis', 'banach-spaces']"
8,Is it true that the Laplace-Beltrami operator on the sphere has compact resolvents?,Is it true that the Laplace-Beltrami operator on the sphere has compact resolvents?,,"We consider the Riemannian structure on the sphere $\mathbb{S}^n$ seen as a submanifold of $\mathbb{R}^{n+1}$ and the Laplace-Beltrami operator defined on $C^\infty(\mathbb{S}^n)$ by the equation $$\Delta f= -\operatorname{div}\operatorname{grad} f = -\frac{1}{\sqrt{g}}\frac{\partial}{\partial u^i}\left(\sqrt{g}g^{ij}\frac{\partial f}{\partial u^j}\right).$$ We regard $C^{\infty}(\mathbb{S}^n)$ as a dense subspace of the Hilbert space $L^2(\mathbb{S}^n)$. Question Is it true that $\Delta$ has compact resolvents, meaning that there exists $\lambda \in \mathbb{R}$ such that the closure of $\Delta-\lambda$ is invertible and its inverse operator is compact? I think that we can easily work out the special case $n=1$: in this case the equation $\Delta u-\lambda u = v$ reduces to the standard Sturm-Liouville problem $$\begin{cases} -\frac{d^2}{dt^2}u-\lambda u = v & t\in (-\pi, \pi) \\ {}\\ u(-\pi)=u(\pi) \\ u'(-\pi)=u'(\pi)\end{cases}$$ which admits Green's function for, say, $\lambda=-1$ (actually any $\lambda \notin \{0, 1, 4, 9 \ldots\}$ will do). So the inverse of $-d^2/dt^2+1$ is an integral operator and in particular it is compact. I suspect that, similarly, the operator $\Delta_{\mathbb{S}^n}+1$ admits Green's function in any dimension $n$, but I am unable to prove (or disprove) this. Thank you for reading.","We consider the Riemannian structure on the sphere $\mathbb{S}^n$ seen as a submanifold of $\mathbb{R}^{n+1}$ and the Laplace-Beltrami operator defined on $C^\infty(\mathbb{S}^n)$ by the equation $$\Delta f= -\operatorname{div}\operatorname{grad} f = -\frac{1}{\sqrt{g}}\frac{\partial}{\partial u^i}\left(\sqrt{g}g^{ij}\frac{\partial f}{\partial u^j}\right).$$ We regard $C^{\infty}(\mathbb{S}^n)$ as a dense subspace of the Hilbert space $L^2(\mathbb{S}^n)$. Question Is it true that $\Delta$ has compact resolvents, meaning that there exists $\lambda \in \mathbb{R}$ such that the closure of $\Delta-\lambda$ is invertible and its inverse operator is compact? I think that we can easily work out the special case $n=1$: in this case the equation $\Delta u-\lambda u = v$ reduces to the standard Sturm-Liouville problem $$\begin{cases} -\frac{d^2}{dt^2}u-\lambda u = v & t\in (-\pi, \pi) \\ {}\\ u(-\pi)=u(\pi) \\ u'(-\pi)=u'(\pi)\end{cases}$$ which admits Green's function for, say, $\lambda=-1$ (actually any $\lambda \notin \{0, 1, 4, 9 \ldots\}$ will do). So the inverse of $-d^2/dt^2+1$ is an integral operator and in particular it is compact. I suspect that, similarly, the operator $\Delta_{\mathbb{S}^n}+1$ admits Green's function in any dimension $n$, but I am unable to prove (or disprove) this. Thank you for reading.",,"['functional-analysis', 'partial-differential-equations', 'riemannian-geometry', 'spectral-theory']"
9,Does the Gelfand transformation on $\ell^1(\mathbb Z)$ possess a continuous inverse on its image?,Does the Gelfand transformation on  possess a continuous inverse on its image?,\ell^1(\mathbb Z),"I am interested in the Gelfand transformation $$ \Phi\colon\ell^1(\mathbb Z)\to\mathcal C(\mathbb T),\quad a\mapsto\sum_{n\in\mathbb Z}a_n z^n. $$ This is an injective homomorphism of Banach algebras. It is neither isometric nor surjective. However, its image---the Wiener algebra $W$ consisting of all continuous functions on $\mathbb T$ whose Fourier series is absolutely convergent---is a subalgebra of $\mathcal C(\mathbb T)$ which is dense in the subspace topology. Question: Can we prove of disprove that $\Phi$ has a continuous inverse on its image $W$? In other words: Is $\Phi\colon\ell^1(\mathbb Z)\to W$ an isomorphism of topological algebras? (Here $W$ carries the topology induced by the sup-norm from $\mathcal C(\mathbb T)$.","I am interested in the Gelfand transformation $$ \Phi\colon\ell^1(\mathbb Z)\to\mathcal C(\mathbb T),\quad a\mapsto\sum_{n\in\mathbb Z}a_n z^n. $$ This is an injective homomorphism of Banach algebras. It is neither isometric nor surjective. However, its image---the Wiener algebra $W$ consisting of all continuous functions on $\mathbb T$ whose Fourier series is absolutely convergent---is a subalgebra of $\mathcal C(\mathbb T)$ which is dense in the subspace topology. Question: Can we prove of disprove that $\Phi$ has a continuous inverse on its image $W$? In other words: Is $\Phi\colon\ell^1(\mathbb Z)\to W$ an isomorphism of topological algebras? (Here $W$ carries the topology induced by the sup-norm from $\mathcal C(\mathbb T)$.",,['functional-analysis']
10,On the linearity of metric projections,On the linearity of metric projections,,"Let $X$ be a reflexive and strictly convex Banach space. If $V$ is a closed subspace of $X$ then for each $x \in X$ there exists a unique vector $P_V(x) \in V$ that solves the feasibility problem $ \inf_{v \in V} ||x-v|| $ .  The map $P_V \colon X \to V ,  ~ x \mapsto P_V(x) ,$ is called the   metric projection onto $V$ . In general, such a map need not be linear. It is linear if $X$ is a Hilbert space, since it coincides with the orthogonal projection on $V$ (which is linear) I was wondering if Hilbert spaces are the only ones with the property that each of its metric projection onto closed subspaces is linear. To be more exact, is the following statement true? Let $X$ be a reflexive and strictly convex Banach space. Suppose  that each of its metric  projections onto closed subspaces is linear. Then $X$ is a Hilbert  space. Any help is appreciated!","Let be a reflexive and strictly convex Banach space. If is a closed subspace of then for each there exists a unique vector that solves the feasibility problem .  The map is called the   metric projection onto . In general, such a map need not be linear. It is linear if is a Hilbert space, since it coincides with the orthogonal projection on (which is linear) I was wondering if Hilbert spaces are the only ones with the property that each of its metric projection onto closed subspaces is linear. To be more exact, is the following statement true? Let be a reflexive and strictly convex Banach space. Suppose  that each of its metric  projections onto closed subspaces is linear. Then is a Hilbert  space. Any help is appreciated!","X V X x \in X P_V(x) \in V  \inf_{v \in V} ||x-v||  P_V \colon X \to V ,  ~ x \mapsto P_V(x) , V X V X X","['functional-analysis', 'hilbert-spaces', 'banach-spaces', 'approximation-theory']"
11,"Sup norm of Fourier transform of $ \frac{\sin |x|}{|x|^\lambda} \mathbb 1_{\{2^k\le |x| <2^{k+1}\}}, \ 0<\lambda<n $",Sup norm of Fourier transform of," \frac{\sin |x|}{|x|^\lambda} \mathbb 1_{\{2^k\le |x| <2^{k+1}\}}, \ 0<\lambda<n ","It seems to me that in a paper of Charles Fefferman ( open access ), it is claimed in the introduction that (3rd page of the PDF file, 'page 11', $\lambda\in(0,n)$ ) $$\sup_{\xi\in\mathbb R^n}\left| \int_{2^k\le  |x| <2^{k+1}} \frac{\sin |x|}{|x|^\lambda}  e^{2\pi i x \cdot\xi} \, dx \right| \le 2^{(\frac{n+1}2-\lambda)k}.$$ (He claims that Plancharel's formula should be used, I expect this to mean that we should compute the $L^\infty$ norm of the symbol.) By using asymptotics of Bessel functions, I can get the upper bound for $\xi\gg 1$ , but I am worried about $\xi\approx 0$ . At $\xi=0$ , the Fourier transform is just $\int\frac{\sin\dots}{\dots} dx$ leading to the estimate ( $C_n$ is the volume of the unit $n$ -sphere) $$ \left| \int_{2^k\le  |x| <2^{k+1}} \frac{\sin |x|}{|x|^\lambda}   \, dx \right|  \le C_n  2^{(n-\lambda)k} $$ which is bigger for $n>1$ ? Am I missing something simple? Calculation details can be provided on request.","It seems to me that in a paper of Charles Fefferman ( open access ), it is claimed in the introduction that (3rd page of the PDF file, 'page 11', ) (He claims that Plancharel's formula should be used, I expect this to mean that we should compute the norm of the symbol.) By using asymptotics of Bessel functions, I can get the upper bound for , but I am worried about . At , the Fourier transform is just leading to the estimate ( is the volume of the unit -sphere) which is bigger for ? Am I missing something simple? Calculation details can be provided on request.","\lambda\in(0,n) \sup_{\xi\in\mathbb R^n}\left| \int_{2^k\le  |x| <2^{k+1}} \frac{\sin |x|}{|x|^\lambda}  e^{2\pi i x \cdot\xi} \, dx \right| \le 2^{(\frac{n+1}2-\lambda)k}. L^\infty \xi\gg 1 \xi\approx 0 \xi=0 \int\frac{\sin\dots}{\dots} dx C_n n  \left| \int_{2^k\le  |x| <2^{k+1}} \frac{\sin |x|}{|x|^\lambda}   \, dx \right|  \le C_n  2^{(n-\lambda)k}  n>1","['functional-analysis', 'fourier-analysis', 'fourier-transform', 'harmonic-analysis', 'bessel-functions']"
12,The eigenfunctions of $\Delta \colon H_0^1(\Omega)\cap H^2(\Omega) \to L^2(\Omega)$ form an orthonormal basis?,The eigenfunctions of  form an orthonormal basis?,\Delta \colon H_0^1(\Omega)\cap H^2(\Omega) \to L^2(\Omega),"Let $\Omega$ be a bounded open subset of $\mathbb{R}^n$ with smooth boundary. Consider the Dirichlet Laplace operator $$\begin{cases} D(A)=H^1_0(\Omega)\cap H^2(\Omega)\\ Au=\Delta u. \end{cases} $$  I usually see in some references that the eigenfunctions of this operator are an orthonormal basis for the Hilbert space $L^2(\Omega)$. It is stated in Wikipedia that this result follows from the spectral theorem on compact self-adjoint operators, applied to the inverse of the Laplacian (which is compact, by the Poincaré inequality and Rellich–Kondrachov theorem). I have some questions about this: 1) first why the operator $A$ is invertible 2) why the inverse is a bounded operator. (my guess is that the boundedness maybe follows from the closed graph theorem, $A$ closed operator implies $A^{-1}$ is also closed? I am I right?) however I didn't prove that $A$ is a closed operator, I just have a feeling it is closed. 3) I don't see how the compactness of the operator $A^{-1}$ follows from the Poincaré inequality and Rellich–Kondrachov.","Let $\Omega$ be a bounded open subset of $\mathbb{R}^n$ with smooth boundary. Consider the Dirichlet Laplace operator $$\begin{cases} D(A)=H^1_0(\Omega)\cap H^2(\Omega)\\ Au=\Delta u. \end{cases} $$  I usually see in some references that the eigenfunctions of this operator are an orthonormal basis for the Hilbert space $L^2(\Omega)$. It is stated in Wikipedia that this result follows from the spectral theorem on compact self-adjoint operators, applied to the inverse of the Laplacian (which is compact, by the Poincaré inequality and Rellich–Kondrachov theorem). I have some questions about this: 1) first why the operator $A$ is invertible 2) why the inverse is a bounded operator. (my guess is that the boundedness maybe follows from the closed graph theorem, $A$ closed operator implies $A^{-1}$ is also closed? I am I right?) however I didn't prove that $A$ is a closed operator, I just have a feeling it is closed. 3) I don't see how the compactness of the operator $A^{-1}$ follows from the Poincaré inequality and Rellich–Kondrachov.",,"['functional-analysis', 'partial-differential-equations', 'eigenvalues-eigenvectors', 'operator-theory', 'laplacian']"
13,Alternative proof to non-emptiness of spectrum/spectral radius formula,Alternative proof to non-emptiness of spectrum/spectral radius formula,,"The following two results are probably the most basic results in the spectral theory: Let $a$ be an element in a unital Banach algebra $\mathcal{A}$ (over $\mathbb{C}$). The spectrum of $a$, $\sigma(a) = \{\lambda \in \mathbb{C} \mid (\lambda \mathbb{1} - a) \text{ isn't invertible} \}$, is non-empty. This allows us to define the spectral radius $r(a) = \sup \{ \lvert \lambda \rvert \mid \lambda \in \sigma(a)\}$ for which $r(a) = \lim_{n \to \infty} \lVert a^n \rVert^{1/n}$ holds. All proofs I've seen of these two theorems are essentially the same. The sketch of the proof of the first proposition goes as follows: We prove this via contradiction, so suppose $\sigma(a)$ is empty. Define the resolvent of $a$ as the map $$ R:\mathbb{C} \to \mathcal{A}: \lambda \mapsto (\lambda \mathbb{1} - a)^{-1}. $$ It's analytic in the sense that $\phi \circ R$ is analytic for all $\phi$ continuous linear functionals on $\mathcal{A}$. Then it's not so hard to prove $R$ is bounded, so by Liouville's theorem $\phi \circ R$ must be constant for every $\phi$. This then implies $R$ must be constant and zero and thus we arrive at a contradiction. The proof of the second theorem is very similar: First it's proven that $r(a) \leq \inf_n \lVert a^n \rVert^{1/n}$, which is not so hard. Then all that is left to prove is that $r(a) \geq \limsup_n \lVert a^n \rVert^{1/n}$. Let $\Omega$ be the open disk in $\mathbb{C}$ around $0$ with radius $\frac{1}{r(a)}$ and define $$ f:\Omega \to \mathbb{C}: \lambda \mapsto (\mathbb{1} - \lambda a )^{-1}. $$ We prove that $\phi \circ f$ is analytic for every $\phi$ as before. Then we can argue that $\phi(a^n) \lambda^n$ is a bounded sequence for every $\phi$ and $\lambda \in \Omega$ by using the power series of $\phi \circ f$. By Banach-Steinhaus we then have that $a^n \lambda^n$ is bounded for every $\lvert \lambda \rvert < \frac{1}{r(a)}$. It then follows that $r(a) \geq \limsup_n \lVert a^n \rVert^{1/n}$. Every text I've encountered so far describe the same proof, maybe in a slightly different fashion but essentially the same. Are there any alternatives to these proofs? Preferably ones that use less complex analysis. I imagine this could be very hard, particularly for the second one. This because that formula is already very reminiscent of the root test for series, so it ""screams"" power series to me. But I would be very interested if there were any at all. Edit: I would also like to add my interest in proving only the convergence of $\lVert a^n \rVert^{1/n}$ without relying on the proof described here. So no proof that it's equal to the spectral radius, but simply a proof that it converges.","The following two results are probably the most basic results in the spectral theory: Let $a$ be an element in a unital Banach algebra $\mathcal{A}$ (over $\mathbb{C}$). The spectrum of $a$, $\sigma(a) = \{\lambda \in \mathbb{C} \mid (\lambda \mathbb{1} - a) \text{ isn't invertible} \}$, is non-empty. This allows us to define the spectral radius $r(a) = \sup \{ \lvert \lambda \rvert \mid \lambda \in \sigma(a)\}$ for which $r(a) = \lim_{n \to \infty} \lVert a^n \rVert^{1/n}$ holds. All proofs I've seen of these two theorems are essentially the same. The sketch of the proof of the first proposition goes as follows: We prove this via contradiction, so suppose $\sigma(a)$ is empty. Define the resolvent of $a$ as the map $$ R:\mathbb{C} \to \mathcal{A}: \lambda \mapsto (\lambda \mathbb{1} - a)^{-1}. $$ It's analytic in the sense that $\phi \circ R$ is analytic for all $\phi$ continuous linear functionals on $\mathcal{A}$. Then it's not so hard to prove $R$ is bounded, so by Liouville's theorem $\phi \circ R$ must be constant for every $\phi$. This then implies $R$ must be constant and zero and thus we arrive at a contradiction. The proof of the second theorem is very similar: First it's proven that $r(a) \leq \inf_n \lVert a^n \rVert^{1/n}$, which is not so hard. Then all that is left to prove is that $r(a) \geq \limsup_n \lVert a^n \rVert^{1/n}$. Let $\Omega$ be the open disk in $\mathbb{C}$ around $0$ with radius $\frac{1}{r(a)}$ and define $$ f:\Omega \to \mathbb{C}: \lambda \mapsto (\mathbb{1} - \lambda a )^{-1}. $$ We prove that $\phi \circ f$ is analytic for every $\phi$ as before. Then we can argue that $\phi(a^n) \lambda^n$ is a bounded sequence for every $\phi$ and $\lambda \in \Omega$ by using the power series of $\phi \circ f$. By Banach-Steinhaus we then have that $a^n \lambda^n$ is bounded for every $\lvert \lambda \rvert < \frac{1}{r(a)}$. It then follows that $r(a) \geq \limsup_n \lVert a^n \rVert^{1/n}$. Every text I've encountered so far describe the same proof, maybe in a slightly different fashion but essentially the same. Are there any alternatives to these proofs? Preferably ones that use less complex analysis. I imagine this could be very hard, particularly for the second one. This because that formula is already very reminiscent of the root test for series, so it ""screams"" power series to me. But I would be very interested if there were any at all. Edit: I would also like to add my interest in proving only the convergence of $\lVert a^n \rVert^{1/n}$ without relying on the proof described here. So no proof that it's equal to the spectral radius, but simply a proof that it converges.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
14,Intuition behind Riesz-Markov Representation Theorem,Intuition behind Riesz-Markov Representation Theorem,,"I am currently reading Big Rudin and I have this theorem that I've been struggling with for some time now. Usually, when reading, I either try to get a concrete intuition behind the idea, visualise the theorem and its proof in my head, or at least connect it to something I already know, as well as try to connect the proof to other proofs I know. However, upon this theorem, I truly stumbled. As Rudin notes in the beginning of the chapter, one can see a little connection between the measure and linear functionals as $b-a$ can be approximated by $\Lambda f$ where $\Lambda f=\int_a^b fdx$ and $f$ is a continuous function on $[a;b]$ with range lying in $[0;1]$. However, this honestly felt like ""cheating"". As to why this is cheating, it seems so to me for various reasons. First of all, he gave the most trivial of examples while one needs a general idea. However, the real reason is the fact that the linear function he uses is actually intimately related to measure by itself, without any need for a representation theorem. The ideas of measure and integrations are intertwined and thus stating that we can find a measure that represents an integral (especially since it's only on an interval) seems useless and uninformative. Is there a way to intuitively understand why such a representation is possible or is this theorem too complex for any intuition? Thanks in advance.","I am currently reading Big Rudin and I have this theorem that I've been struggling with for some time now. Usually, when reading, I either try to get a concrete intuition behind the idea, visualise the theorem and its proof in my head, or at least connect it to something I already know, as well as try to connect the proof to other proofs I know. However, upon this theorem, I truly stumbled. As Rudin notes in the beginning of the chapter, one can see a little connection between the measure and linear functionals as $b-a$ can be approximated by $\Lambda f$ where $\Lambda f=\int_a^b fdx$ and $f$ is a continuous function on $[a;b]$ with range lying in $[0;1]$. However, this honestly felt like ""cheating"". As to why this is cheating, it seems so to me for various reasons. First of all, he gave the most trivial of examples while one needs a general idea. However, the real reason is the fact that the linear function he uses is actually intimately related to measure by itself, without any need for a representation theorem. The ideas of measure and integrations are intertwined and thus stating that we can find a measure that represents an integral (especially since it's only on an interval) seems useless and uninformative. Is there a way to intuitively understand why such a representation is possible or is this theorem too complex for any intuition? Thanks in advance.",,"['functional-analysis', 'measure-theory', 'banach-spaces', 'riesz-representation-theorem']"
15,Do we need to identify dual spaces in PDEs?,Do we need to identify dual spaces in PDEs?,,"In PDEs we often use the fact that we can identify dual spaces eg. $L^2(0,T;V)^* = L^2(0,T;V^*)$ in the sense that $$u_t + Au = f$$ where $u_t$, $f \in L^2(0,T;V^*)$ and $A:L^2(0,T;V) \to [L^2(0,T;V)]^*$ (eg. $A=\Delta$). Because we identify the dual spaces, $Au$ and $f$ both lie in the same space hence the equality makes sense. There are more complicated examples with $L^p(0,T;V)^*$ and $L^q(0,T;V^*)$ where $p$ and $q$ are conjugate. My question is, is this identification always necessary when dealing with PDE problems? Every paper I read seems to use this identification. Suppose I have a very weird space and I cannot show that I can identify the dual spaces (eg. if $V$ is not Banach/reflexive). Can one pose the problem differently?","In PDEs we often use the fact that we can identify dual spaces eg. $L^2(0,T;V)^* = L^2(0,T;V^*)$ in the sense that $$u_t + Au = f$$ where $u_t$, $f \in L^2(0,T;V^*)$ and $A:L^2(0,T;V) \to [L^2(0,T;V)]^*$ (eg. $A=\Delta$). Because we identify the dual spaces, $Au$ and $f$ both lie in the same space hence the equality makes sense. There are more complicated examples with $L^p(0,T;V)^*$ and $L^q(0,T;V^*)$ where $p$ and $q$ are conjugate. My question is, is this identification always necessary when dealing with PDE problems? Every paper I read seems to use this identification. Suppose I have a very weird space and I cannot show that I can identify the dual spaces (eg. if $V$ is not Banach/reflexive). Can one pose the problem differently?",,"['functional-analysis', 'partial-differential-equations']"
16,"functional analysis in probability theory, Feller processes, contraction semigroups","functional analysis in probability theory, Feller processes, contraction semigroups",,"In an entire year of probability theory coursework at the graduate level, there was only one time when functional analysis seriously appeared.  That was ergodic theory.  Now that my self-studies have carried me away to Feller processes, it has shown up again, and some serious analysis as opposed to combinatorics and elementary measure theory has begun to show up.  Are there any other points where functional analysis or operator theory plays a big role? More specifically, I have noticed that the notion of a contraction semigroup, which is important in Feller processes, can be generalized for contractions on a banach space. (In the Feller theory, the correspondence of generator, semigroup, and Feller process occurs where the semigroup is defined on the vanishing-at-infinity continuous functions on some locally compact separable metric space.)  Is this merely for curiosity's sake, or is there some use of this in probability theory or elsewhere? (Don't contraction semigroups have something to do with the Feynman path integral characterization of quantum mechanics?)","In an entire year of probability theory coursework at the graduate level, there was only one time when functional analysis seriously appeared.  That was ergodic theory.  Now that my self-studies have carried me away to Feller processes, it has shown up again, and some serious analysis as opposed to combinatorics and elementary measure theory has begun to show up.  Are there any other points where functional analysis or operator theory plays a big role? More specifically, I have noticed that the notion of a contraction semigroup, which is important in Feller processes, can be generalized for contractions on a banach space. (In the Feller theory, the correspondence of generator, semigroup, and Feller process occurs where the semigroup is defined on the vanishing-at-infinity continuous functions on some locally compact separable metric space.)  Is this merely for curiosity's sake, or is there some use of this in probability theory or elsewhere? (Don't contraction semigroups have something to do with the Feynman path integral characterization of quantum mechanics?)",,"['functional-analysis', 'probability-theory', 'operator-theory']"
17,Min Max Principle and Rayleigh-Ritz-Method for eigenvalues of unbounded operators?,Min Max Principle and Rayleigh-Ritz-Method for eigenvalues of unbounded operators?,,"Finding eigenvalues of matrices using the Rayleigh-Ritz quotient is well-known, c.f. http://en.wikipedia.org/wiki/Min-max_theorem Does the following generalization of that fact also hold? Theorem: Let $H$ be a complex Hilbert space, $T:D \to H$ be an unbounded operator defined on a dense domain $D \subset H$. Assume that $T$ is self-adjoint and has discrete spectrum contained in some interval $[c,\infty[$, $c > 0$. Enumerate the eigenvalues by $\lambda_1 \leq \lambda_2 \leq \ldots$ counting with multiplicities. Then for each $k \in \mathbb{N}$ $$ \lambda_k = \min_{\substack{U \subset D, \\ \dim U=k }}{\max_{\substack{x \in U, \\\|x\|=1}}{\langle Tx, x  \rangle}} $$ If this is true, can you give a good reference for this?","Finding eigenvalues of matrices using the Rayleigh-Ritz quotient is well-known, c.f. http://en.wikipedia.org/wiki/Min-max_theorem Does the following generalization of that fact also hold? Theorem: Let $H$ be a complex Hilbert space, $T:D \to H$ be an unbounded operator defined on a dense domain $D \subset H$. Assume that $T$ is self-adjoint and has discrete spectrum contained in some interval $[c,\infty[$, $c > 0$. Enumerate the eigenvalues by $\lambda_1 \leq \lambda_2 \leq \ldots$ counting with multiplicities. Then for each $k \in \mathbb{N}$ $$ \lambda_k = \min_{\substack{U \subset D, \\ \dim U=k }}{\max_{\substack{x \in U, \\\|x\|=1}}{\langle Tx, x  \rangle}} $$ If this is true, can you give a good reference for this?",,"['functional-analysis', 'reference-request', 'eigenvalues-eigenvectors', 'operator-theory']"
18,A compact operator is completely continuous.,A compact operator is completely continuous.,,"I have a question. If $X$ and $Y$ are Banach spaces, we have to prove that a compact linear operator is completely continuous.  A mapping $T \colon X \to Y$ is called completely continuous, if it maps a weakly convergent sequence in $X$ to a strongly convergent sequence in $Y$ , i.e., $x_n\underset{n\to +\infty}\rightharpoonup x$  implies $\lVert Tx_n-  Tx\rVert_Y\to 0$.","I have a question. If $X$ and $Y$ are Banach spaces, we have to prove that a compact linear operator is completely continuous.  A mapping $T \colon X \to Y$ is called completely continuous, if it maps a weakly convergent sequence in $X$ to a strongly convergent sequence in $Y$ , i.e., $x_n\underset{n\to +\infty}\rightharpoonup x$  implies $\lVert Tx_n-  Tx\rVert_Y\to 0$.",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'compact-operators']"
19,Krein-Milman theorem and dividing pizza with toppings,Krein-Milman theorem and dividing pizza with toppings,,"In this question the OP mentions the following problem as an exercise on Krein-Milman theorem : You have a great circular pizza with $n$ toppings. Show that you can divide the pizza equitably among $k$ persons, which means every person gets a piece of pizza with exactly $\frac{1}{k}$ of any of the $n$ topping on it. I would like to ask both about interpretation (formalization) of this exercise and about the solution. I am not sure whether I interpreted it correctly. To me it seems that mathematical reformulation of the problem could be that I have functions $f_i\colon X\to [0,1]$ for $i=1,\dots,n$ corresponding to how the toppings are distributed on the surface of pizza - the space $X$. And I would like to obtain a decomposition $X=A_1,\dots,A_k$ such that for any $i=1,\dots,n$ I have $\int_{A_1} f_i = \dots = \int_{A_k} f_i$, i.e., each person has the same portion from each of the toppings. I am not sure whether this is the correct formalization. (Certainly the fact that Krein-Milman is supposed to be used is some kind of a hint on how the problem is supposed to be interpreted.) But even if my interpretation is correct, I am not sure where to start. To apply Krein-Milman theorem, I need some locally convex topological vector space and some compact convex subset. I am not sure what space I could choose, since based on the above formulation it seems that the elements of this spaces should be somehow related to divisions of the circle. Another possible interpretation I can think of is that I work with the functions $\{1,2,\dots,k\} \to \mathbb R^n$ representing how much of each topping gets the $k$-the person. It is certainly possible that $k$-the person gets the whole pizza, which would correspond to $f(k)=(1,1,\dots,1)$ and $f(i)=(0,0,\dots,0)$ for $i\ne k$. By I do not see how to show that the set of all admissible possibilities is convex. And if I can show that it is convex, then I do not really need Krein-Milman theorem.","In this question the OP mentions the following problem as an exercise on Krein-Milman theorem : You have a great circular pizza with $n$ toppings. Show that you can divide the pizza equitably among $k$ persons, which means every person gets a piece of pizza with exactly $\frac{1}{k}$ of any of the $n$ topping on it. I would like to ask both about interpretation (formalization) of this exercise and about the solution. I am not sure whether I interpreted it correctly. To me it seems that mathematical reformulation of the problem could be that I have functions $f_i\colon X\to [0,1]$ for $i=1,\dots,n$ corresponding to how the toppings are distributed on the surface of pizza - the space $X$. And I would like to obtain a decomposition $X=A_1,\dots,A_k$ such that for any $i=1,\dots,n$ I have $\int_{A_1} f_i = \dots = \int_{A_k} f_i$, i.e., each person has the same portion from each of the toppings. I am not sure whether this is the correct formalization. (Certainly the fact that Krein-Milman is supposed to be used is some kind of a hint on how the problem is supposed to be interpreted.) But even if my interpretation is correct, I am not sure where to start. To apply Krein-Milman theorem, I need some locally convex topological vector space and some compact convex subset. I am not sure what space I could choose, since based on the above formulation it seems that the elements of this spaces should be somehow related to divisions of the circle. Another possible interpretation I can think of is that I work with the functions $\{1,2,\dots,k\} \to \mathbb R^n$ representing how much of each topping gets the $k$-the person. It is certainly possible that $k$-the person gets the whole pizza, which would correspond to $f(k)=(1,1,\dots,1)$ and $f(i)=(0,0,\dots,0)$ for $i\ne k$. By I do not see how to show that the set of all admissible possibilities is convex. And if I can show that it is convex, then I do not really need Krein-Milman theorem.",,"['functional-analysis', 'convex-analysis', 'locally-convex-spaces']"
20,Complementary text for mathematical Quantum Mechanics lectures,Complementary text for mathematical Quantum Mechanics lectures,,"I'm looking for a text to complement Frederic Schuller's lectures on QM.  His approach is very mathematical -- in fact it looks like the first 12 of 21 lectures are just about the mathematical foundations of QM.  He introduces Hilbert and Banach spaces from scratch (from basic linear algebra and analysis really), derives the functional analysis version of the spectral theorem, and gives what I assume are more rigorous definitions.  For instance in all of the undergrad books I've looked at, quantum states -- if they're given any definition at all -- are said to be elements of the Hilbert space.  But Schuller claims that that is not correct.  States are in fact positive trace-class linear maps on the Hilbert space .  Does anyone know a good undergrad level QM book that I can follow along with so I have some exercises and extra material to work through as I go through the lectures?  Thanks.","I'm looking for a text to complement Frederic Schuller's lectures on QM.  His approach is very mathematical -- in fact it looks like the first 12 of 21 lectures are just about the mathematical foundations of QM.  He introduces Hilbert and Banach spaces from scratch (from basic linear algebra and analysis really), derives the functional analysis version of the spectral theorem, and gives what I assume are more rigorous definitions.  For instance in all of the undergrad books I've looked at, quantum states -- if they're given any definition at all -- are said to be elements of the Hilbert space.  But Schuller claims that that is not correct.  States are in fact positive trace-class linear maps on the Hilbert space .  Does anyone know a good undergrad level QM book that I can follow along with so I have some exercises and extra material to work through as I go through the lectures?  Thanks.",,"['functional-analysis', 'reference-request', 'mathematical-physics', 'book-recommendation', 'quantum-mechanics']"
21,Proving that the eigenfunctions of the Laplacian form a basis of $L^2(\Omega)$ (and of $H_0^1(\Omega)$),Proving that the eigenfunctions of the Laplacian form a basis of  (and of ),L^2(\Omega) H_0^1(\Omega),"I am studying the eigenfunctions and eigenvalues of the Laplacian on an open, bounded domain $\Omega \subset \mathbb{R}^n$ with homogeneous Dirichlet boundary conditions. I have read about the the weak and variational formulation of the problem. I understand the result that the first eigenvalue is given by: $$ \lambda_1 = \inf_{H_0^1(\Omega)} R = \inf_{v \in H_0^1(\Omega)} \frac{\int_\Omega \| \nabla v\|^2 \, \mathrm{d}x}{\int_\Omega v^2 \, \mathrm{d}x}$$ and the associated eigenfunction is $u_1$ such that $R(u_1) = \lambda_1$, as well as the characterization of the nth eigenvalue/eigenfunction. I have proved some of the basic results, such as the fact that the sequence of eigenvalues is unbounded and eigenfunctions associated to different eigenvalues are orthogonal (both in $L^2(\Omega)$ and $H_0^1(\Omega)$). Now I am trying to prove that the eigenfunctions $u_1,u_2,\ldots$ form a basis of $L^2(\Omega)$. I have seen some proofs of this fact (e.g. Jost's book on PDEs and Mihai Nica's article), but I am trying to use a different approach. I have a sketch of this proof but I need to fill in some details. The proof argues by contradiction. We define $V$ to be the closure in $H_0^1(\Omega)$ of the set: $$\left\{ u \in H_0^1(\Omega) : \exists \, N \in \mathbb{N}: u = \sum_{n=1}^N\alpha_nu_n\right\},$$ where $\alpha_n \in \mathbb{R}$ and the $u_n$'s are the eigenfunctions. Then $V$ is a closed subspace of $H_0^1(\Omega)$. We assume, for the sake of contradiction, that $V \neq H_0^1(\Omega)$. 1) This should then imply that $V^\perp \neq \{0\}$, but I am not sure why. I know that it is not necessary for a subset of a Hilbert space $H$ to be equal to the whole space $H$ for its orthogonal complement to be trivial. However here the space is closed so it is possible that this may force the orthogonal complement to be trivial, but I am not sure if that is enough. Then $V^\perp$ is a non-trivial closed subspace of $H_0^1(\Omega)$ and hence we can apply the same methods used to determine the existence of eigenvalues and eigenfunctions to deduce the existence of an eigenfunction $u$ in $V^\perp$. It can then be shown that the eigenvalue associated to this eigenfunction must equal one of the previously determined eigenvalues (I understand how to do this). 2) Then I am not sure why this leads us to a contradiction. My guess is that then this $u\in V^\perp$ should equal some $u_n \in V$ (it is obvious that $V$ contains all the $u_n$'s) and this would imply that $V\cap V^\perp \neq \varnothing$, which is impossible. 3) This would then prove that $V = H_0^1(\Omega)$ but I have some doubts/confusion as to why this shows that the $u_n$'s form a basis of $H_0^1(\Omega)$, if they do. 4) Then I am not sure how to extend this to $L^2(\Omega)$. I suspect that the fact that $H_0^1(\Omega)$ is dense in $L^2(\Omega)$ should play a role. I would be very grateful for any help (and/or references) on the numbered points.","I am studying the eigenfunctions and eigenvalues of the Laplacian on an open, bounded domain $\Omega \subset \mathbb{R}^n$ with homogeneous Dirichlet boundary conditions. I have read about the the weak and variational formulation of the problem. I understand the result that the first eigenvalue is given by: $$ \lambda_1 = \inf_{H_0^1(\Omega)} R = \inf_{v \in H_0^1(\Omega)} \frac{\int_\Omega \| \nabla v\|^2 \, \mathrm{d}x}{\int_\Omega v^2 \, \mathrm{d}x}$$ and the associated eigenfunction is $u_1$ such that $R(u_1) = \lambda_1$, as well as the characterization of the nth eigenvalue/eigenfunction. I have proved some of the basic results, such as the fact that the sequence of eigenvalues is unbounded and eigenfunctions associated to different eigenvalues are orthogonal (both in $L^2(\Omega)$ and $H_0^1(\Omega)$). Now I am trying to prove that the eigenfunctions $u_1,u_2,\ldots$ form a basis of $L^2(\Omega)$. I have seen some proofs of this fact (e.g. Jost's book on PDEs and Mihai Nica's article), but I am trying to use a different approach. I have a sketch of this proof but I need to fill in some details. The proof argues by contradiction. We define $V$ to be the closure in $H_0^1(\Omega)$ of the set: $$\left\{ u \in H_0^1(\Omega) : \exists \, N \in \mathbb{N}: u = \sum_{n=1}^N\alpha_nu_n\right\},$$ where $\alpha_n \in \mathbb{R}$ and the $u_n$'s are the eigenfunctions. Then $V$ is a closed subspace of $H_0^1(\Omega)$. We assume, for the sake of contradiction, that $V \neq H_0^1(\Omega)$. 1) This should then imply that $V^\perp \neq \{0\}$, but I am not sure why. I know that it is not necessary for a subset of a Hilbert space $H$ to be equal to the whole space $H$ for its orthogonal complement to be trivial. However here the space is closed so it is possible that this may force the orthogonal complement to be trivial, but I am not sure if that is enough. Then $V^\perp$ is a non-trivial closed subspace of $H_0^1(\Omega)$ and hence we can apply the same methods used to determine the existence of eigenvalues and eigenfunctions to deduce the existence of an eigenfunction $u$ in $V^\perp$. It can then be shown that the eigenvalue associated to this eigenfunction must equal one of the previously determined eigenvalues (I understand how to do this). 2) Then I am not sure why this leads us to a contradiction. My guess is that then this $u\in V^\perp$ should equal some $u_n \in V$ (it is obvious that $V$ contains all the $u_n$'s) and this would imply that $V\cap V^\perp \neq \varnothing$, which is impossible. 3) This would then prove that $V = H_0^1(\Omega)$ but I have some doubts/confusion as to why this shows that the $u_n$'s form a basis of $H_0^1(\Omega)$, if they do. 4) Then I am not sure how to extend this to $L^2(\Omega)$. I suspect that the fact that $H_0^1(\Omega)$ is dense in $L^2(\Omega)$ should play a role. I would be very grateful for any help (and/or references) on the numbered points.",,"['functional-analysis', 'optimization', 'sobolev-spaces', 'laplacian', 'eigenfunctions']"
22,Characterization for the convergence of a series,Characterization for the convergence of a series,,"Problem. Let $X$ be a topological spaces which is compact and Hausdorff, $\mathbb{K}\in\{\mathbb{R},\mathbb{C}\}$, and suppose there exists a sequence $\{x_n\}_{n\in\mathbb N}\subset X$, such that $x_n\neq x_m$ for $n\neq m$. Moreover, assume that we have a sequence $\{\lambda_n\}_{n\in\mathbb N}\subset \mathbb{K}$ with the property that for every $f\in C(X,\mathbb{K})$ the series $\sum_{n\in\mathbb N}\lambda_n\, f(x_n)$ is convergent. Show that $\sum_{n\in\mathbb N} \lvert\lambda_n\rvert<\infty$. The opposite implication also holds. It follows from Weierstrass theorem.","Problem. Let $X$ be a topological spaces which is compact and Hausdorff, $\mathbb{K}\in\{\mathbb{R},\mathbb{C}\}$, and suppose there exists a sequence $\{x_n\}_{n\in\mathbb N}\subset X$, such that $x_n\neq x_m$ for $n\neq m$. Moreover, assume that we have a sequence $\{\lambda_n\}_{n\in\mathbb N}\subset \mathbb{K}$ with the property that for every $f\in C(X,\mathbb{K})$ the series $\sum_{n\in\mathbb N}\lambda_n\, f(x_n)$ is convergent. Show that $\sum_{n\in\mathbb N} \lvert\lambda_n\rvert<\infty$. The opposite implication also holds. It follows from Weierstrass theorem.",,"['analysis', 'functional-analysis', 'convergence-divergence', 'banach-spaces']"
23,Categorical Banach space theory,Categorical Banach space theory,,"Consider the category $\mathsf{NormVect}_1$ of normed vector spaces with short linear maps $^{\dagger}$ and the full subcategory $\mathsf{Ban}_1$ of Banach spaces with short linear maps. Both categories are complete, cocomplete, and have a closed symmetric monoidal structure, given by the projective tensor product (see here ). The forgetful functor $\mathsf{Ban}_1 \to \mathsf{NormVect}_1$ is continuous (but not cocontinuous), in fact has a left adjoint (which is symmetric monoidal), the Cauchy completion. Question. Can you name a categorical property of $\mathsf{Ban}_1$ which is useful in practice, but which is not satisfied by $\mathsf{NormVect}_1$? Background: There is a branch called categorical Banach space theory, and I really wonder why there one does not consider the larger category of all normed vector spaces somehow as a first approximation. In functional analysis it is well-known that (and why) Banach spaces are more useful than normed vector spaces. I would like to know if or why this is also true for the corresponding categories. $^{\dagger}$ Notice that the subscript $1$ indicates that we restrict ourselves to short linear maps, which is quite important for having the mentioned categorical properties. For me, the moral of this choice is that if you use continuous linear maps, you don't take the whole structure of the objects into account, which tends to be bad.","Consider the category $\mathsf{NormVect}_1$ of normed vector spaces with short linear maps $^{\dagger}$ and the full subcategory $\mathsf{Ban}_1$ of Banach spaces with short linear maps. Both categories are complete, cocomplete, and have a closed symmetric monoidal structure, given by the projective tensor product (see here ). The forgetful functor $\mathsf{Ban}_1 \to \mathsf{NormVect}_1$ is continuous (but not cocontinuous), in fact has a left adjoint (which is symmetric monoidal), the Cauchy completion. Question. Can you name a categorical property of $\mathsf{Ban}_1$ which is useful in practice, but which is not satisfied by $\mathsf{NormVect}_1$? Background: There is a branch called categorical Banach space theory, and I really wonder why there one does not consider the larger category of all normed vector spaces somehow as a first approximation. In functional analysis it is well-known that (and why) Banach spaces are more useful than normed vector spaces. I would like to know if or why this is also true for the corresponding categories. $^{\dagger}$ Notice that the subscript $1$ indicates that we restrict ourselves to short linear maps, which is quite important for having the mentioned categorical properties. For me, the moral of this choice is that if you use continuous linear maps, you don't take the whole structure of the objects into account, which tends to be bad.",,"['functional-analysis', 'category-theory', 'banach-spaces', 'normed-spaces', 'monoidal-categories']"
24,"For a Hilbert space $\mathcal{H}$, is every bounded linear operator on $\mathcal{H}$ a linear combination of unitary operators?","For a Hilbert space , is every bounded linear operator on  a linear combination of unitary operators?",\mathcal{H} \mathcal{H},"Let $(\mathcal{H}, (\cdot, \cdot))$ be a Hilbert space, and let $B \in \mathcal{B}(H)$ be a bounded linear operator on $H$ . If $\mathcal{H}$ is a complex Hilbert space, then $B$ can be written as a linear combination of unitary operators. How do we do this? First, we write $B$ as a linear combination of self-adjoint operators: $$B = \frac{1}{2}(B + B^*) - \frac{i}{2}(iB - iB^*)$$ So so it suffices to show that any self adjoint operator $A \in \mathcal{B}(H)$ is a linear combination of unitary operators. Even more, it is no problem to assume the operator norm $\|A\| \le 1$ . Then, a short computation shows that $(A \pm i\sqrt{I - A^2})$ is unitary, and furthermore we have: $$A = \frac{1}{2}(A + i\sqrt{I - A^2}) + \frac{1}{2}(A - i\sqrt{I - A^2}).$$ Note that, because $\|A\| \le 1$ , it's easy to see that $I-A^2$ is a positive operator, hence it has a well-defined square root. My concern is, can we still write $B$ as a combination of unitary operators, even if $\mathcal{H}$ is just a real Hilbert space? In the real case, we do not have the complex number $i$ to work with, and it seems to be crucial in the above argument. Hints or solutions are greatly appreciated.","Let be a Hilbert space, and let be a bounded linear operator on . If is a complex Hilbert space, then can be written as a linear combination of unitary operators. How do we do this? First, we write as a linear combination of self-adjoint operators: So so it suffices to show that any self adjoint operator is a linear combination of unitary operators. Even more, it is no problem to assume the operator norm . Then, a short computation shows that is unitary, and furthermore we have: Note that, because , it's easy to see that is a positive operator, hence it has a well-defined square root. My concern is, can we still write as a combination of unitary operators, even if is just a real Hilbert space? In the real case, we do not have the complex number to work with, and it seems to be crucial in the above argument. Hints or solutions are greatly appreciated.","(\mathcal{H}, (\cdot, \cdot)) B \in \mathcal{B}(H) H \mathcal{H} B B B = \frac{1}{2}(B + B^*) - \frac{i}{2}(iB - iB^*) A \in \mathcal{B}(H) \|A\| \le 1 (A \pm i\sqrt{I - A^2}) A = \frac{1}{2}(A + i\sqrt{I - A^2}) + \frac{1}{2}(A - i\sqrt{I - A^2}). \|A\| \le 1 I-A^2 B \mathcal{H} i","['functional-analysis', 'operator-theory', 'hilbert-spaces']"
25,Counterexamples for L1-convergence not implying L2-convergence and vice versa,Counterexamples for L1-convergence not implying L2-convergence and vice versa,,"I am trying to find counterexamples for the following statements. Let $\{f_n\}$ be a sequence in $L^1(\mathbb{R}^d) \cap L^2(\mathbb{R}^d)$ , and let $f$ also be in $L^1(\mathbb{R}^d) \cap L^2(\mathbb{R}^d)$ . $f_n \stackrel{L^1}{\longrightarrow} f$ implies $f_n \stackrel{L^2}{\longrightarrow} f$ $f_n \stackrel{L^2}{\longrightarrow} f$ implies $f_n \stackrel{L^1}{\longrightarrow} f$ A counterexample for the first statement would be $f_n:= \sqrt{n}\cdot \chi_{[0,1/n]}$ and $f\equiv 0$ . However, I am having trouble figuring out a counterexample for the second statement. I originally thought it was true but apparently it is not... Any hints for a counterexample would be appreciated. I would also like to know if there are any extra conditions that would make the second statement true.","I am trying to find counterexamples for the following statements. Let be a sequence in , and let also be in . implies implies A counterexample for the first statement would be and . However, I am having trouble figuring out a counterexample for the second statement. I originally thought it was true but apparently it is not... Any hints for a counterexample would be appreciated. I would also like to know if there are any extra conditions that would make the second statement true.","\{f_n\} L^1(\mathbb{R}^d) \cap L^2(\mathbb{R}^d) f L^1(\mathbb{R}^d) \cap L^2(\mathbb{R}^d) f_n \stackrel{L^1}{\longrightarrow} f f_n \stackrel{L^2}{\longrightarrow} f f_n \stackrel{L^2}{\longrightarrow} f f_n \stackrel{L^1}{\longrightarrow} f f_n:= \sqrt{n}\cdot \chi_{[0,1/n]} f\equiv 0","['functional-analysis', 'measure-theory', 'convergence-divergence', 'examples-counterexamples', 'lebesgue-integral']"
26,The the image of the unit ball in X is weak-* dense in the unit ball of X**,The the image of the unit ball in X is weak-* dense in the unit ball of X**,,"I am trying to prove the following theorem and am stuck. Let $X$ be a Banach space. The the image of the unit ball in $X$ is weak-* dense in the unit ball of $X^{**}$ . My proof idea Assume $X^{**}$ is equipped with its weak-* topology. Let $Q$ be the isometric map from $X$ to $X^{**}$ such that $Q(x)(\pi) = \pi(x)$ . Denote by $Q(B_x)$ the image of the unit ball $B_x$ in $X$ . Now for every $ y \in Q(B_x)$ if $\|y\| < 1$ then $Q(B_x)\subset B_{x^{**}}$ where $B_{x^{**}}$ is the unit ball in $X^{**}$ . But this is equivalent to showing that every vector in the complement of the closure of the $Q(B_x)$ has norm greater than $1$ . (*) Let $Q'(B_x)$ denote the closure of $Q(B_x)$ in $X^{**}$ . Take $ \pi \in X^{**}\setminus Q'(B_x)$ . As $Q'(B_x)$ is closed and $\{\pi \}$ is  compact, by the Hahn-Banach seperation theorem, we have that there exists a continuous linear functional $\omega': X^{**} \to \mathbb{C}$ and $\alpha \in \mathbb{R}$ such that $\text{Re}(\omega'(\pi)) \leq \alpha \leq \text{Re}(\omega'(y))$ for all $y \in Q'(B_x)$ . I am stuck here. I know that for $x \in X$ we have $Q(x)(\pi) = \pi(x)$ and $ \pi(x) = \|x\|$ . So if $ x \notin B_x$ then $ \pi(x) > 1$ but I cannot find a way of putting these together. I would appreciate if someone could tell me how to proceed. I thank you for your time. (*) Cannot use a direct approach as there are possibly infinite number of vectors in $X$ . Edit: I would also appreciate if you would give me suggestions towards writing a formal proof.","I am trying to prove the following theorem and am stuck. Let be a Banach space. The the image of the unit ball in is weak-* dense in the unit ball of . My proof idea Assume is equipped with its weak-* topology. Let be the isometric map from to such that . Denote by the image of the unit ball in . Now for every if then where is the unit ball in . But this is equivalent to showing that every vector in the complement of the closure of the has norm greater than . (*) Let denote the closure of in . Take . As is closed and is  compact, by the Hahn-Banach seperation theorem, we have that there exists a continuous linear functional and such that for all . I am stuck here. I know that for we have and . So if then but I cannot find a way of putting these together. I would appreciate if someone could tell me how to proceed. I thank you for your time. (*) Cannot use a direct approach as there are possibly infinite number of vectors in . Edit: I would also appreciate if you would give me suggestions towards writing a formal proof.",X X X^{**} X^{**} Q X X^{**} Q(x)(\pi) = \pi(x) Q(B_x) B_x X  y \in Q(B_x) \|y\| < 1 Q(B_x)\subset B_{x^{**}} B_{x^{**}} X^{**} Q(B_x) 1 Q'(B_x) Q(B_x) X^{**}  \pi \in X^{**}\setminus Q'(B_x) Q'(B_x) \{\pi \} \omega': X^{**} \to \mathbb{C} \alpha \in \mathbb{R} \text{Re}(\omega'(\pi)) \leq \alpha \leq \text{Re}(\omega'(y)) y \in Q'(B_x) x \in X Q(x)(\pi) = \pi(x)  \pi(x) = \|x\|  x \notin B_x  \pi(x) > 1 X,['functional-analysis']
27,Weak* operator topology and finite rank operators,Weak* operator topology and finite rank operators,,"We will say that ${T_i}\subset B(X,Y^*)$ converges to $T$ in W*-operator topology if $T_i(x)\rightarrow T(x)$ in W*-topology of $Y^*$( $\forall y\in Y \langle T_i(x),y\rangle \rightarrow \langle T(x),y\rangle$). Now someone has proved the below theorem. Is it true? BEGIN Let $X$ and $Y$ be two arbitrary Banach spaces. Then $F (X; Y^*)$(Finite rank operator) is dense in $B(X; Y^*)$ with respect to the weak* operator topology. Proof. Let $T \in B(X; Y^*)$ and take a finite subset $F =\{ x_1,...,x_n\}$ of X. Assume that $x_1,...,x_m$ are linearly independent for all $m\leq n$. By the Hahn Banach theorem, for each $j\in \{1,2,...,m\}$ there is $f_j\in X^*$ such that $f_j(x_j) = 1$ and $f_j(x_i) = 0$ for all $i\in\{1,2,...,m\}-\{j\}$.For each $j\in\{1,...,m\}$ define $T_j\in B(X; Y^*)$ by $T_j(x) = f_j(x)T(x_j)$.Then $$T_j(x_j) = T(x_j); T_j(x_i) = 0\ \  (i, j\in\{1,...,m\}, i\neq j)$$ Now define $T_F = T_1 +...+ T_m$. It can be easily seen that $$T_F(x_i) = T(x_i)\ \ (i\in\{1,...,n\})$$ So $T_F = T$ on the span of $F$ and $\operatorname{rank}(T_F)\leq \dim F$. Now it is obvious that the net $(T_F)_{F\in F(X)}$$\big(F(X)=$ all finite subset of $X\big)$ converges to $T$ in the weak* operator topology, as desired. END If it is true then my question is this that why we can't say $T_F\rightarrow T$ in strong operator topology($T_F(x)\rightarrow T(x) \ \ \forall x\in X$)?","We will say that ${T_i}\subset B(X,Y^*)$ converges to $T$ in W*-operator topology if $T_i(x)\rightarrow T(x)$ in W*-topology of $Y^*$( $\forall y\in Y \langle T_i(x),y\rangle \rightarrow \langle T(x),y\rangle$). Now someone has proved the below theorem. Is it true? BEGIN Let $X$ and $Y$ be two arbitrary Banach spaces. Then $F (X; Y^*)$(Finite rank operator) is dense in $B(X; Y^*)$ with respect to the weak* operator topology. Proof. Let $T \in B(X; Y^*)$ and take a finite subset $F =\{ x_1,...,x_n\}$ of X. Assume that $x_1,...,x_m$ are linearly independent for all $m\leq n$. By the Hahn Banach theorem, for each $j\in \{1,2,...,m\}$ there is $f_j\in X^*$ such that $f_j(x_j) = 1$ and $f_j(x_i) = 0$ for all $i\in\{1,2,...,m\}-\{j\}$.For each $j\in\{1,...,m\}$ define $T_j\in B(X; Y^*)$ by $T_j(x) = f_j(x)T(x_j)$.Then $$T_j(x_j) = T(x_j); T_j(x_i) = 0\ \  (i, j\in\{1,...,m\}, i\neq j)$$ Now define $T_F = T_1 +...+ T_m$. It can be easily seen that $$T_F(x_i) = T(x_i)\ \ (i\in\{1,...,n\})$$ So $T_F = T$ on the span of $F$ and $\operatorname{rank}(T_F)\leq \dim F$. Now it is obvious that the net $(T_F)_{F\in F(X)}$$\big(F(X)=$ all finite subset of $X\big)$ converges to $T$ in the weak* operator topology, as desired. END If it is true then my question is this that why we can't say $T_F\rightarrow T$ in strong operator topology($T_F(x)\rightarrow T(x) \ \ \forall x\in X$)?",,"['functional-analysis', 'operator-theory', 'operator-algebras', 'compact-operators']"
28,Paley-Wiener type theorems for distributions?,Paley-Wiener type theorems for distributions?,,"In general a theorem of Paley-Wiener type gives a relation between the decay of a function and the smoothness of its Fourier transformation, and there are plenty of them since there are many kinds of bound for decay rates of functions and many types of characterizations of smoothness. However,when the objects are tempered distributions I only know one such theorem, the one given in Wiki page as Schwartz's Paley-Wiener theorem , which deals only with the case of compact support distributions. I wonder whether there are other Paley-Wiener type theorems for distributions that might be less restrictive. Thanks!","In general a theorem of Paley-Wiener type gives a relation between the decay of a function and the smoothness of its Fourier transformation, and there are plenty of them since there are many kinds of bound for decay rates of functions and many types of characterizations of smoothness. However,when the objects are tempered distributions I only know one such theorem, the one given in Wiki page as Schwartz's Paley-Wiener theorem , which deals only with the case of compact support distributions. I wonder whether there are other Paley-Wiener type theorems for distributions that might be less restrictive. Thanks!",,"['functional-analysis', 'fourier-analysis', 'big-list', 'distribution-theory']"
29,Pointwise convergence of continuous functions implies uniform convergence on some open subset,Pointwise convergence of continuous functions implies uniform convergence on some open subset,,For some Banachspace $A$ we have a sequence of continuous functions $g_n:A\rightarrow \mathbb{R}$ pointwise converging to some $g:A\rightarrow\mathbb{R}$. Prove that for any $\epsilon>0$ there exist $\emptyset\not=U\subset A$ open and $N\in\mathbb{N}$ such that for all $n>N$ we have $\sup_{x\in U}\left|g_n(x)-g(x)\right|<\epsilon$. I'm not sure how to approach this problem. Is it a good idea to prove something like local boundedness first?,For some Banachspace $A$ we have a sequence of continuous functions $g_n:A\rightarrow \mathbb{R}$ pointwise converging to some $g:A\rightarrow\mathbb{R}$. Prove that for any $\epsilon>0$ there exist $\emptyset\not=U\subset A$ open and $N\in\mathbb{N}$ such that for all $n>N$ we have $\sup_{x\in U}\left|g_n(x)-g(x)\right|<\epsilon$. I'm not sure how to approach this problem. Is it a good idea to prove something like local boundedness first?,,"['functional-analysis', 'banach-spaces']"
30,A convergence problem in Banach spaces related to ergodic theory,A convergence problem in Banach spaces related to ergodic theory,,"Suppose $X$ is a Banach space, $T\in B(X)$, satisfied the following condition. $\sup \Big\lVert\frac{1}{n}\sum \limits_{i=0}^{n-1}T^{i}\Big\rVert<\infty$ $\frac{1}{n}\lVert T\rVert^{n}\rightarrow0$, as $n \rightarrow\infty$ For $x \in X$, take $x_{n}=\frac{1}{n} \sum\limits_{i=0}^{n-1}T^{i}x$. If there is a subquence $\{x_{n_{k}}\}$ which has a weak limit  $x^{*}$(in the weak topology), prove that $x_{n} $ is convergent to $ x^{*}$, in the norm topology, and $Tx^{*}=x^{*}$ This can been seen as a generalization of the von Neumann Ergodic Theorem for Banach spaces. Any advice and discussions will be appreciated.","Suppose $X$ is a Banach space, $T\in B(X)$, satisfied the following condition. $\sup \Big\lVert\frac{1}{n}\sum \limits_{i=0}^{n-1}T^{i}\Big\rVert<\infty$ $\frac{1}{n}\lVert T\rVert^{n}\rightarrow0$, as $n \rightarrow\infty$ For $x \in X$, take $x_{n}=\frac{1}{n} \sum\limits_{i=0}^{n-1}T^{i}x$. If there is a subquence $\{x_{n_{k}}\}$ which has a weak limit  $x^{*}$(in the weak topology), prove that $x_{n} $ is convergent to $ x^{*}$, in the norm topology, and $Tx^{*}=x^{*}$ This can been seen as a generalization of the von Neumann Ergodic Theorem for Banach spaces. Any advice and discussions will be appreciated.",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'ergodic-theory']"
31,Is there a residue theorem for holomorphic operator-valued functions?,Is there a residue theorem for holomorphic operator-valued functions?,,"I'm wondering whether there is such a thing as a ""residue theorem for holomorphic operator-valued functions"". More precisely, I want to evaluate an integral of the form $P:=\int_{\Gamma} (A(\lambda) - \lambda)^{-1} d \lambda$ where each $A(\lambda)$ is a closed operator and $\Gamma$ encloses an eigenvalue $\lambda_0$ of the holomorphic operator pencil $A(\lambda) - \lambda$, i.e., for some eigenfunction $u_0$ we have $A(\lambda_0)u_0 - \lambda_0u_0=0$. In the case of a $\lambda$-independent $A$ the operator $P$ is (up to a constant) the well-known Riesz Projection corresponding to $\lambda_0$. If (and how) this can be generalized to a $\lambda$-nonlinear eigenvalue problem is precisely what my question is concerned with. Thanks for any help in advance!","I'm wondering whether there is such a thing as a ""residue theorem for holomorphic operator-valued functions"". More precisely, I want to evaluate an integral of the form $P:=\int_{\Gamma} (A(\lambda) - \lambda)^{-1} d \lambda$ where each $A(\lambda)$ is a closed operator and $\Gamma$ encloses an eigenvalue $\lambda_0$ of the holomorphic operator pencil $A(\lambda) - \lambda$, i.e., for some eigenfunction $u_0$ we have $A(\lambda_0)u_0 - \lambda_0u_0=0$. In the case of a $\lambda$-independent $A$ the operator $P$ is (up to a constant) the well-known Riesz Projection corresponding to $\lambda_0$. If (and how) this can be generalized to a $\lambda$-nonlinear eigenvalue problem is precisely what my question is concerned with. Thanks for any help in advance!",,"['functional-analysis', 'spectral-theory']"
32,"Dual of Sobolev space $W^{1,p}(U)$ for $U$ an arbitrary subset of $\mathbb R^n$",Dual of Sobolev space  for  an arbitrary subset of,"W^{1,p}(U) U \mathbb R^n","this question may be shameful, but nevertheless I can't help myself. Let $U \subset \mathbb R^n$ be arbitrary, in particular not the whole of the space itself. I wonder about the dual of the space $W^{1,p}(U)$, for $p < \infty$. For $U = \mathbb R^n$, we have $(W^{1,p})' = (W^{1,p'})$ with $p' = \frac{p}{p-1}$. How about different $U$? For example, in case $U = B_1(0)$ being the closed $1$-Ball, it seems the dual is not a function space. Just recall that the trace is well-defined, linear and continuous on $W^{1,p}(U)$ and, with $S_1$ the boundary of $B_1(0)$ and $w \in L^p(S_1)$, we are given are continuous linear functional by $ W^{1,p}(B_1(0)) \longrightarrow \mathbb C \, , f \mapsto \int_{S_1} w \cdot tr f dx $. In fact, I wouldn't be surprised if the above example were somehow prototypical, but I have no clue how to proceed from this point. I regard this relevant, as these spaces are ubiquitous in analysis. Thank you!","this question may be shameful, but nevertheless I can't help myself. Let $U \subset \mathbb R^n$ be arbitrary, in particular not the whole of the space itself. I wonder about the dual of the space $W^{1,p}(U)$, for $p < \infty$. For $U = \mathbb R^n$, we have $(W^{1,p})' = (W^{1,p'})$ with $p' = \frac{p}{p-1}$. How about different $U$? For example, in case $U = B_1(0)$ being the closed $1$-Ball, it seems the dual is not a function space. Just recall that the trace is well-defined, linear and continuous on $W^{1,p}(U)$ and, with $S_1$ the boundary of $B_1(0)$ and $w \in L^p(S_1)$, we are given are continuous linear functional by $ W^{1,p}(B_1(0)) \longrightarrow \mathbb C \, , f \mapsto \int_{S_1} w \cdot tr f dx $. In fact, I wouldn't be surprised if the above example were somehow prototypical, but I have no clue how to proceed from this point. I regard this relevant, as these spaces are ubiquitous in analysis. Thank you!",,"['functional-analysis', 'distribution-theory']"
33,Does the ordering of a Schauder basis matter in Hilbert space?,Does the ordering of a Schauder basis matter in Hilbert space?,,"If $S=\{v_i\}_{i\in\mathbb N}$ is a (not necessarily orthogonal) Schauder basis for a Hilbert space $H$ , must $S$ be an unconditional Schauder basis? I define these terms below because not every source I have found agrees perfectly on the definitions. On general Banach spaces (where orthogonality is undefined), there exist conditional Schauder bases. But if the Schauder basis is on a Hilbert space and is orthogonal, then it is indeed unconditional. So my question is therefore whether this unconditional property remains if we stay in Hilbert space but orthogonality is removed. Definitions: An ordered countable subset $\{v_i\}_{i\in\mathbb N}$ of a Banach space $V$ is a Schauder basis if every $v\in V$ can be written uniquely as a series $v=\sum_{i=1}^\infty a_i v_i$ , where convergence is with respect to the norm-induced topology. A Schauder basis is unconditional if the terms of any convergent series can be rearranged without affecting the sum. A Hilbert basis is a maximal orthonormal subset of a Hilbert space $H$ , possibly uncountable. It is known that even for non-separable Hilbert spaces, there exists a Hilbert basis $B$ , and that every $v\in H$ can be expressed uniquely as a sum of a countable subset of $B$ , which is always independent of summation order.","If is a (not necessarily orthogonal) Schauder basis for a Hilbert space , must be an unconditional Schauder basis? I define these terms below because not every source I have found agrees perfectly on the definitions. On general Banach spaces (where orthogonality is undefined), there exist conditional Schauder bases. But if the Schauder basis is on a Hilbert space and is orthogonal, then it is indeed unconditional. So my question is therefore whether this unconditional property remains if we stay in Hilbert space but orthogonality is removed. Definitions: An ordered countable subset of a Banach space is a Schauder basis if every can be written uniquely as a series , where convergence is with respect to the norm-induced topology. A Schauder basis is unconditional if the terms of any convergent series can be rearranged without affecting the sum. A Hilbert basis is a maximal orthonormal subset of a Hilbert space , possibly uncountable. It is known that even for non-separable Hilbert spaces, there exists a Hilbert basis , and that every can be expressed uniquely as a sum of a countable subset of , which is always independent of summation order.",S=\{v_i\}_{i\in\mathbb N} H S \{v_i\}_{i\in\mathbb N} V v\in V v=\sum_{i=1}^\infty a_i v_i H B v\in H B,"['functional-analysis', 'hilbert-spaces', 'conditional-convergence', 'schauder-basis']"
34,Dense subset of two Banach spaces also dense in the intersection,Dense subset of two Banach spaces also dense in the intersection,,"My question is: Let $ V $ be a vector space (over $ \mathbb K\in\{\mathbb{R}, \mathbb{C}\} $ ), $ X,Y\subseteq V $ two subspaces equipped with norms $ \|\cdot\|_X, \|\cdot\|_Y $ such that $ (X,\|\cdot\|_X) $ and $(Y,\|\cdot\|_Y)$ are Banach spaces and $ D\subseteq X\cap Y$ . If $ D $ is dense in $ (X,\|\cdot\|_X) $ and $(Y,\|\cdot\|_Y)$ , is $ D $ also dense in $ X\cap Y $ equipped with $ \|\cdot\|:=\|\cdot\|_X + \|\cdot\|_Y $ ? At first sight, it seemed very clear to me that this should be true. But I even fail to answer the following (possibly) easier question: Let $ X $ be a vector space over $ \mathbb K $ equipped with two norms $ \|\cdot\|_1, \|\cdot\|_2 $ such that $ (X,\|\cdot\|_1) $ and $(X,\|\cdot\|_1)$ are Banach spaces and $ D\subseteq X$ . If $ D $ is dense in $ (X,\|\cdot\|_1) $ and $(X,\|\cdot\|_2)$ , is $ D $ also dense in $ X $ equipped with $ \|\cdot\|:=\|\cdot\|_1 + \|\cdot\|_2 $ ? The answer is yes, if $ \|\cdot\|_1, \|\cdot\|_2 $ are equivalent, so I tried to think about a counterexample using nonequivalent norms on a specific space and I also found a nice paper about nonisomorphic complete norms ( https://www.researchgate.net/publication/226200984_Equivalent_complete_norms_and_positivity ) but it didn't helped me so far to construct anything useful for my question. Thanks for your help!","My question is: Let be a vector space (over ), two subspaces equipped with norms such that and are Banach spaces and . If is dense in and , is also dense in equipped with ? At first sight, it seemed very clear to me that this should be true. But I even fail to answer the following (possibly) easier question: Let be a vector space over equipped with two norms such that and are Banach spaces and . If is dense in and , is also dense in equipped with ? The answer is yes, if are equivalent, so I tried to think about a counterexample using nonequivalent norms on a specific space and I also found a nice paper about nonisomorphic complete norms ( https://www.researchgate.net/publication/226200984_Equivalent_complete_norms_and_positivity ) but it didn't helped me so far to construct anything useful for my question. Thanks for your help!"," V   \mathbb K\in\{\mathbb{R}, \mathbb{C}\}   X,Y\subseteq V   \|\cdot\|_X, \|\cdot\|_Y   (X,\|\cdot\|_X)  (Y,\|\cdot\|_Y)  D\subseteq X\cap Y  D   (X,\|\cdot\|_X)  (Y,\|\cdot\|_Y)  D   X\cap Y   \|\cdot\|:=\|\cdot\|_X + \|\cdot\|_Y   X   \mathbb K   \|\cdot\|_1, \|\cdot\|_2   (X,\|\cdot\|_1)  (X,\|\cdot\|_1)  D\subseteq X  D   (X,\|\cdot\|_1)  (X,\|\cdot\|_2)  D   X   \|\cdot\|:=\|\cdot\|_1 + \|\cdot\|_2   \|\cdot\|_1, \|\cdot\|_2 ","['functional-analysis', 'banach-spaces']"
35,"If $\operatorname{Ker} f$ is a $G_\delta$ set in $X$, then $f$ is continuous","If  is a  set in , then  is continuous",\operatorname{Ker} f G_\delta X f,"$X$ is a Banach space and $f$ be a linear functional from $X$ to $\mathbb{C}$. If $\operatorname{Ker} f$ is a $G_\delta$ set in $X$, then $f$ is continuous. I know that if $\operatorname{Ker} f$ is closed, then $f$ is continuous. The argument is based on getting a ball of radius $r$ in $(\operatorname{Ker} f)^c$ and then showing that $|f(x)|\le \frac1r||x||$. I was trying to extended this idea to the above problem, but failed. Any hint/ suggestions.","$X$ is a Banach space and $f$ be a linear functional from $X$ to $\mathbb{C}$. If $\operatorname{Ker} f$ is a $G_\delta$ set in $X$, then $f$ is continuous. I know that if $\operatorname{Ker} f$ is closed, then $f$ is continuous. The argument is based on getting a ball of radius $r$ in $(\operatorname{Ker} f)^c$ and then showing that $|f(x)|\le \frac1r||x||$. I was trying to extended this idea to the above problem, but failed. Any hint/ suggestions.",,"['functional-analysis', 'banach-spaces', 'complete-spaces']"
36,proof: Hilbert Schmidt operator is compact,proof: Hilbert Schmidt operator is compact,,"Consider the Hilbert Schmidt operator $K: L^2(\Omega) \rightarrow L^2(\Omega)$ , $\Omega \subset \subset \mathbb R^N$ , with $k \in L^2(\Omega \times \Omega)$ and $f \in L^2(\Omega)$ , $$(Kf)(x) := \int_\Omega k(x,y)f(y)\, dy.$$ I want to show that the Hilbert Schmidt operator $K$ is a compact operator. Therefore I'm using this characterization. Let $X$ , $Y$ be normed linear spaces and $X$ reflexive. A continuous linear operator $T: X \rightarrow Y$ that maps weakly convergent sequences onto strongly convergent sequences is compact. (We already know that $K$ is well-defined as is proven here .) My question here is, isn't it obvious that $K$ is compact? We know that $K$ is linear and bounded, hence continuous. Every continuous map takes weakly convergent sequences to weakly convergent sequences. The norm itself is also continuous. Weak convergence together with convergence of the norms implies convergence. Thus $K$ is compact. Am I missing something here? Or better: What am I missing here? $\,$ I'm also adding the proof from the textbook for completeness: Proof. Let $(f_n)_{n \in \mathbb N} \subset L^2(\Omega)$ a weakly convergent sequence, then $(f_n)_{n \in \mathbb N}$ is bounded. That is, $\exists C > 0 $ such that $||f_n||_{L^2(\Omega)} \leq C$ , $\forall n \in \mathbb N$ . By Fubini's theorem we have for almost every $x\in \Omega$ that $$ || k(x,\cdot) ||_{L^2(\Omega)} = \int_\Omega |k(x,y)|^2 \, dy < \infty .$$ Thus for almost every $x \in \Omega$ we have $\begin{align} \lim_{n \rightarrow \infty} (Kf_n)(x) & = \int_\Omega k(x,y)f_n(y) \, dy = \lim_{n \rightarrow \infty} \langle k(x,\cdot), f_n \rangle_{L^2(\Omega)} \\ & = \langle k(x,\cdot), f \rangle_{L^2(\Omega)} = \int_\Omega k(x,y)f(y) \, dy = (Kf)(x) \end{align}$ By Cauchy-Schwarz's inequality we have $$ (Kf_n)(x) \leq ||f_n||_{L^2(\Omega)} \int_\Omega |k(x,y)|^2 \, dy \leq C \, \int_\Omega |k(x,y)|^2 \, dy $$ Hence by Lebesgue's dominant convergence theorem we have convergence of the norms $$ \lim_{n \rightarrow \infty} \int_\Omega |(Kf_n)(x)| \, dx = \int_\Omega |(Kf)(x)| \, dx ,$$ that is $|| Kf_n ||_{L^2(\Omega)} \rightarrow || Kf ||_{L^2(\Omega)}\, \, (n\rightarrow \infty)$ . Since weak convergence together with (strong or normal) convergence of the norms implies (strong) convergence, $K$ is compact.","Consider the Hilbert Schmidt operator , , with and , I want to show that the Hilbert Schmidt operator is a compact operator. Therefore I'm using this characterization. Let , be normed linear spaces and reflexive. A continuous linear operator that maps weakly convergent sequences onto strongly convergent sequences is compact. (We already know that is well-defined as is proven here .) My question here is, isn't it obvious that is compact? We know that is linear and bounded, hence continuous. Every continuous map takes weakly convergent sequences to weakly convergent sequences. The norm itself is also continuous. Weak convergence together with convergence of the norms implies convergence. Thus is compact. Am I missing something here? Or better: What am I missing here? I'm also adding the proof from the textbook for completeness: Proof. Let a weakly convergent sequence, then is bounded. That is, such that , . By Fubini's theorem we have for almost every that Thus for almost every we have By Cauchy-Schwarz's inequality we have Hence by Lebesgue's dominant convergence theorem we have convergence of the norms that is . Since weak convergence together with (strong or normal) convergence of the norms implies (strong) convergence, is compact.","K: L^2(\Omega) \rightarrow L^2(\Omega) \Omega \subset \subset \mathbb R^N k \in L^2(\Omega \times \Omega) f \in L^2(\Omega) (Kf)(x) := \int_\Omega k(x,y)f(y)\, dy. K X Y X T: X \rightarrow Y K K K K \, (f_n)_{n \in \mathbb N} \subset L^2(\Omega) (f_n)_{n \in \mathbb N} \exists C > 0  ||f_n||_{L^2(\Omega)} \leq C \forall n \in \mathbb N x\in \Omega  || k(x,\cdot) ||_{L^2(\Omega)} = \int_\Omega |k(x,y)|^2 \, dy < \infty . x \in \Omega \begin{align}
\lim_{n \rightarrow \infty} (Kf_n)(x) & = \int_\Omega k(x,y)f_n(y) \, dy = \lim_{n \rightarrow \infty} \langle k(x,\cdot), f_n \rangle_{L^2(\Omega)} \\
& = \langle k(x,\cdot), f \rangle_{L^2(\Omega)} = \int_\Omega k(x,y)f(y) \, dy = (Kf)(x)
\end{align}  (Kf_n)(x) \leq ||f_n||_{L^2(\Omega)} \int_\Omega |k(x,y)|^2 \, dy \leq C \, \int_\Omega |k(x,y)|^2 \, dy   \lim_{n \rightarrow \infty} \int_\Omega |(Kf_n)(x)| \, dx = \int_\Omega |(Kf)(x)| \, dx , || Kf_n ||_{L^2(\Omega)} \rightarrow || Kf ||_{L^2(\Omega)}\, \, (n\rightarrow \infty) K","['functional-analysis', 'operator-theory', 'banach-spaces', 'normed-spaces', 'weak-convergence']"
37,In a uniformly convex Banach space $x_n\stackrel{w}\to x$ and $||x_n||\to ||x||$ implies $||x_n-x||\to 0$,In a uniformly convex Banach space  and  implies,x_n\stackrel{w}\to x ||x_n||\to ||x|| ||x_n-x||\to 0,In a uniformly convex Banach space $$x_n\stackrel{w}\to x  \ \ \text{and} \ \ ||x_n||\to ||x||  \ \ \text{implies}  \ ||x_n-x||\to 0.$$ Can you  help me to solve it? Thanks in advance.,In a uniformly convex Banach space $$x_n\stackrel{w}\to x  \ \ \text{and} \ \ ||x_n||\to ||x||  \ \ \text{implies}  \ ||x_n-x||\to 0.$$ Can you  help me to solve it? Thanks in advance.,,"['functional-analysis', 'banach-spaces']"
38,Closed $\iff$ weakly closed subspace,Closed  weakly closed subspace,\iff,"On this link http://at.yorku.ca/cgi-bin/bbqa?forum=ask_an_analyst_2004;task=show_msg;msg=1414.0001 is the argument that a linear subspace in a normed space is closed w.r.t. norm iff it is weakly closed. On the other hand, $c_0$ (sequences convergent to $0$) is a norm-closed linear subspace of $l_\infty$ (bounded sequences), but it is not weakly closed, since the base vectors $e_i$ are weakly dense in $l_\infty$. Since I studied func.an. quite a while ago, my question is - what am I missing?","On this link http://at.yorku.ca/cgi-bin/bbqa?forum=ask_an_analyst_2004;task=show_msg;msg=1414.0001 is the argument that a linear subspace in a normed space is closed w.r.t. norm iff it is weakly closed. On the other hand, $c_0$ (sequences convergent to $0$) is a norm-closed linear subspace of $l_\infty$ (bounded sequences), but it is not weakly closed, since the base vectors $e_i$ are weakly dense in $l_\infty$. Since I studied func.an. quite a while ago, my question is - what am I missing?",,"['functional-analysis', 'weak-convergence']"
39,Fixed Point Theorems,Fixed Point Theorems,,"Theorem 1. Let $B=\{x\in \mathbb R^n :∥x∥≤1\}$  be the closed unit ball in $\mathbb R^n$  . Any continuous function $f:B\rightarrow B$  has a fixed point. Theorem 2. Let $X$  be a finite dimensional normed vector space, and let $K\subset X$  be a non-empty, compact, and convex set. Then given any continuous mapping $f:K\rightarrow K$  there exists $x\in K$  such that $f(x)=x$. Theorem 3. Let $X$  be a normed vector space, and let $K\subset X$  be a non-empty, compact, and convex set. Then given any continuous mapping $f:K\rightarrow K$  there exists $x\in K$  such that $f(x)=x$. Theorem 4. Let $X$  be a normed vector space, and let $K\subset X$  be a non-empty, closed, and bounded set. Then given any compact mapping $f:K\rightarrow K$  there exists $x\in K$  such that $f(x)=x$. For some authors Theorem 1 is Brouwer's fixed-point theorem. For others Brouwer's fixed-point theorem is Theorem 2. Actually there is no difference because every non-empty, compact and convex set in a finite dimensional normed vector space is is homeomorphic to the closed unit ball. My problem is with theorems 3 and 4. For some authors Theorem 3 is Schauder's fixed-point theorem, for others Schauder's fixed-point theorem is Theorem 4. Are Theorem 3 and Theorem 4 are equivalent? If not, are Theorems 1 and 2 special cases of Theorem 4?","Theorem 1. Let $B=\{x\in \mathbb R^n :∥x∥≤1\}$  be the closed unit ball in $\mathbb R^n$  . Any continuous function $f:B\rightarrow B$  has a fixed point. Theorem 2. Let $X$  be a finite dimensional normed vector space, and let $K\subset X$  be a non-empty, compact, and convex set. Then given any continuous mapping $f:K\rightarrow K$  there exists $x\in K$  such that $f(x)=x$. Theorem 3. Let $X$  be a normed vector space, and let $K\subset X$  be a non-empty, compact, and convex set. Then given any continuous mapping $f:K\rightarrow K$  there exists $x\in K$  such that $f(x)=x$. Theorem 4. Let $X$  be a normed vector space, and let $K\subset X$  be a non-empty, closed, and bounded set. Then given any compact mapping $f:K\rightarrow K$  there exists $x\in K$  such that $f(x)=x$. For some authors Theorem 1 is Brouwer's fixed-point theorem. For others Brouwer's fixed-point theorem is Theorem 2. Actually there is no difference because every non-empty, compact and convex set in a finite dimensional normed vector space is is homeomorphic to the closed unit ball. My problem is with theorems 3 and 4. For some authors Theorem 3 is Schauder's fixed-point theorem, for others Schauder's fixed-point theorem is Theorem 4. Are Theorem 3 and Theorem 4 are equivalent? If not, are Theorems 1 and 2 special cases of Theorem 4?",,"['functional-analysis', 'fixed-point-theorems']"
40,Using Galerkin method for PDE with Neumann boundary condition?,Using Galerkin method for PDE with Neumann boundary condition?,,"I am wanting to show existence of solutions to $$u_t +L(u) = f \;\;\text{on}\;\; \Omega$$ with initial condition $u|_{t=0} = u_0$ and Neumann boundary condition $\nabla u\cdot \nu = 0$ on ${\partial\Omega}$. How do I do this with the Galerkin method? My problem is with the boundary condition. Recall that the Galerkin method requires a triple $V \subset H$ with continuous dense inclusion. In this case,  $$V = \{u \in H^1 : \nabla u \cdot \nu = 0 \;\;\text{on}\;\; \partial\Omega\}$$ and $H = L^2$. But showing $V$ is dense in $H$ is a problem. So I guess this is not how we do it. How else can I tackle this problem without putting the BC in the Hilbert space? Thanks","I am wanting to show existence of solutions to $$u_t +L(u) = f \;\;\text{on}\;\; \Omega$$ with initial condition $u|_{t=0} = u_0$ and Neumann boundary condition $\nabla u\cdot \nu = 0$ on ${\partial\Omega}$. How do I do this with the Galerkin method? My problem is with the boundary condition. Recall that the Galerkin method requires a triple $V \subset H$ with continuous dense inclusion. In this case,  $$V = \{u \in H^1 : \nabla u \cdot \nu = 0 \;\;\text{on}\;\; \partial\Omega\}$$ and $H = L^2$. But showing $V$ is dense in $H$ is a problem. So I guess this is not how we do it. How else can I tackle this problem without putting the BC in the Hilbert space? Thanks",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
41,differential operator on manifold,differential operator on manifold,,"I am currently trying to understand the local expression of a (pseudo)differential operator $$ \int_{R^n} e^{(x - y)\cdot \xi} \sigma(x,\xi) \, d \xi $$ on a manifold $M$ (compact and boundaryless, say), where $\sigma(x,\xi)$, as usual, is the symbol of the operator.  (alternatively one may also write this as $$ \int_{R^n} e^{(x - y)\cdot \xi} a(x,y,\xi) \, d \xi $$ where $a(x,y,\xi)$ belongs to the same symbol class as $\sigma$.) now the picture I have in my head is that the variable $(x,\xi)$ stands for a local coordinate in the cotangent bundle $T^*M$.  but then, at the same time, the variables $(x,y)$ are local coordinates for some subset $U \times V$ of $M \times M$, so I fear I am mixing something up here? Also, I was wondering whether the dot product $$(x - y) \cdot \xi$$ in the exponential term has anything to do with the pairing of elements from $T^*M$ with elements of the tangent bundle $TM$? some sources for example write the dot product in terms of a braket, $$(x - y) \cdot \xi = \langle (x - y), \xi \rangle$$ which makes this even more suggestive. but I struggle to make sense of this, I don't really know how to relate $(x - y)$ to the tangent bundle $TM$, making it very likely that this picture is wrong anyways. Many thanks for your comments!","I am currently trying to understand the local expression of a (pseudo)differential operator $$ \int_{R^n} e^{(x - y)\cdot \xi} \sigma(x,\xi) \, d \xi $$ on a manifold $M$ (compact and boundaryless, say), where $\sigma(x,\xi)$, as usual, is the symbol of the operator.  (alternatively one may also write this as $$ \int_{R^n} e^{(x - y)\cdot \xi} a(x,y,\xi) \, d \xi $$ where $a(x,y,\xi)$ belongs to the same symbol class as $\sigma$.) now the picture I have in my head is that the variable $(x,\xi)$ stands for a local coordinate in the cotangent bundle $T^*M$.  but then, at the same time, the variables $(x,y)$ are local coordinates for some subset $U \times V$ of $M \times M$, so I fear I am mixing something up here? Also, I was wondering whether the dot product $$(x - y) \cdot \xi$$ in the exponential term has anything to do with the pairing of elements from $T^*M$ with elements of the tangent bundle $TM$? some sources for example write the dot product in terms of a braket, $$(x - y) \cdot \xi = \langle (x - y), \xi \rangle$$ which makes this even more suggestive. but I struggle to make sense of this, I don't really know how to relate $(x - y)$ to the tangent bundle $TM$, making it very likely that this picture is wrong anyways. Many thanks for your comments!",,"['functional-analysis', 'differential-geometry', 'partial-differential-equations', 'differential-operators']"
42,Approximating $L^1(\mu)$ functions by smooth functions,Approximating  functions by smooth functions,L^1(\mu),"Let $\mu$ be a Borel measure on $\mathbb R^{d+1}$ having continuous positive density with respect to the Lebesgue measure. Is $C^\infty(\mathbb R^{d+1})$ dense in $L^1(\mu)$ ? What is an approximating sequence? Let $\psi\in L^1(\mu)\,$ . I would like to find a sequence $\psi_n\in C^\infty(\mathbb R^{d+1})$ such that $$\int_{\mathbb R^{d+1}}|\psi_n-\psi|\,d\mu\to0 \;.$$ Moreover I am interested in preserving the support in the following sense: if $\psi$ is continuous and $$\text{supp}\psi\subseteq K\times\mathbb R$$ for some $K$ compact subset of $\mathbb R^d$ , then I would like $\psi_n$ to have the same property (possibly for a larger compact set $K_n$ ). Can I choose $$ \psi_n(x) \,=\, (\psi*f_n)(x) \,=\, \int_{\mathbb R^{d+1}}\psi(x-y)\,f_n(y)\,d y$$ where $f_n$ is a sequence of mollifiers?","Let be a Borel measure on having continuous positive density with respect to the Lebesgue measure. Is dense in ? What is an approximating sequence? Let . I would like to find a sequence such that Moreover I am interested in preserving the support in the following sense: if is continuous and for some compact subset of , then I would like to have the same property (possibly for a larger compact set ). Can I choose where is a sequence of mollifiers?","\mu \mathbb R^{d+1} C^\infty(\mathbb R^{d+1}) L^1(\mu) \psi\in L^1(\mu)\, \psi_n\in C^\infty(\mathbb R^{d+1}) \int_{\mathbb R^{d+1}}|\psi_n-\psi|\,d\mu\to0 \;. \psi \text{supp}\psi\subseteq K\times\mathbb R K \mathbb R^d \psi_n K_n  \psi_n(x) \,=\, (\psi*f_n)(x) \,=\, \int_{\mathbb R^{d+1}}\psi(x-y)\,f_n(y)\,d y f_n","['functional-analysis', 'measure-theory', 'convolution', 'approximation-theory']"
43,Trace inequality for a trace class operator with powers of $x$ and $\nabla$,Trace inequality for a trace class operator with powers of  and,x \nabla,"I have the following problem. Let $A$ be a symmetric positive trace class operator on $L^2(\mathbb{R})$ such that $\mathrm{Tr}(x^6A)$ and $\mathrm{Tr}((-\Delta)^3A)$ are bounded. Is $$\mathrm{Tr}(x^5∇A)$$ bounded as well? Either by algebra formulas or by diagonalizing the operator $A$ , in which case it a problem looking like Sobolev embeddings with weights ? (Here, $x^n$ is the operator of multiplication by $x^n$ and I write $AB$ the composition of two operators, so that for example for any $\varphi\in L^2(\mathbb{R})$ , the operator $∇A$ evaluated in $\varphi$ yields $(∇A)\varphi(x) = ∇(A\varphi(x))$ ). Other possible directions: A simplified and more analytic version of the same question is the following: if a function $f∈H^{3}(\mathbb{R},\mathbb{C})$ and $\|x^3f\|_{L^2(\mathbb{R},\mathbb{C})} < ∞$ , does it imply that $$∫_{\mathbb{R}} x^5\,\bar{f}\,∇f$$ is bounded? Another way to approach the problem: does anyone knows references about non-commutative interpolation theory in weighted spaces? Remark: Interestingly, it work in the case when $(6,3,5)$ is replaced by $(4,2,3)$ , i.e., trying to bound $\mathrm{Tr}(x^3∇A)$ by $\mathrm{Tr}(x^4A)$ and $\mathrm{Tr}(\nabla^4A)$ , since by commutation in the trace and Hölder's inequality for the trace $$ \begin{align*} \left(\mathrm{Tr}(x^3∇A)\right)^2 = \left(\mathrm{Tr}(A^{1/2}x^2x∇A^{1/2})\right)^2 &≤ \mathrm{Tr}(|A^{1/2}x^2|^2)\, \mathrm{Tr}(|x∇A^{1/2 }|^2) \\ &≤ \mathrm{Tr}(x^2Ax^2)\, \mathrm{Tr}(A^\frac{1}{2}∇x^2∇A^\frac{1}{2}) \\ &≤ \mathrm{Tr}(x^4A)\, \mathrm{Tr}(∇x^2∇A) \end{align*} $$ where I use the notation $|B|^2 := B^*B$ . And using the fact that $∇x^2 = 2x + x^2∇$ $$ \begin{align*} \mathrm{Tr}(∇x^2∇A) &= 2\,\mathrm{Tr}(x∇A) + \mathrm{Tr}(x^2∇^2A) \end{align*} $$ and then using again commutation and Hölder's inequality $$ \begin{align*} (\mathrm{Tr}(x∇A))^2 = (\mathrm{Tr}(A^\frac{1}{2}x∇A^\frac{1}{2}))^2 &\leq  \mathrm{Tr}(|A^{1/2}x|^2)\, \mathrm{Tr}(|∇A^{1/2 }|^2) \\ &\leq \mathrm{Tr}(x^2A)\,\mathrm{Tr}(\nabla^2A) \\ &\leq \mathrm{Tr}(A)^\frac{1}{2}\mathrm{Tr}(x^4A)^\frac{1}{2}\,\mathrm{Tr}(A)^\frac{1}{2} \mathrm{Tr}(\nabla^4A)^\frac{1}{2} \\ (\mathrm{Tr}(x^2∇^2A))^2 = (\mathrm{Tr}(A^\frac{1}{2}x^2∇^2A^\frac{1}{2}))^2 &\leq  \mathrm{Tr}(|A^{1/2}x^2|^2)\, \mathrm{Tr}(|∇^2A^{1/2 }|^2) \\ &\leq \mathrm{Tr}(x^4A)\,\mathrm{Tr}(\nabla^4A) \end{align*} $$","I have the following problem. Let be a symmetric positive trace class operator on such that and are bounded. Is bounded as well? Either by algebra formulas or by diagonalizing the operator , in which case it a problem looking like Sobolev embeddings with weights ? (Here, is the operator of multiplication by and I write the composition of two operators, so that for example for any , the operator evaluated in yields ). Other possible directions: A simplified and more analytic version of the same question is the following: if a function and , does it imply that is bounded? Another way to approach the problem: does anyone knows references about non-commutative interpolation theory in weighted spaces? Remark: Interestingly, it work in the case when is replaced by , i.e., trying to bound by and , since by commutation in the trace and Hölder's inequality for the trace where I use the notation . And using the fact that and then using again commutation and Hölder's inequality","A L^2(\mathbb{R}) \mathrm{Tr}(x^6A) \mathrm{Tr}((-\Delta)^3A) \mathrm{Tr}(x^5∇A) A x^n x^n AB \varphi\in L^2(\mathbb{R}) ∇A \varphi (∇A)\varphi(x) = ∇(A\varphi(x)) f∈H^{3}(\mathbb{R},\mathbb{C}) \|x^3f\|_{L^2(\mathbb{R},\mathbb{C})} < ∞ ∫_{\mathbb{R}} x^5\,\bar{f}\,∇f (6,3,5) (4,2,3) \mathrm{Tr}(x^3∇A) \mathrm{Tr}(x^4A) \mathrm{Tr}(\nabla^4A) 
\begin{align*}
\left(\mathrm{Tr}(x^3∇A)\right)^2 = \left(\mathrm{Tr}(A^{1/2}x^2x∇A^{1/2})\right)^2 &≤ \mathrm{Tr}(|A^{1/2}x^2|^2)\, \mathrm{Tr}(|x∇A^{1/2 }|^2)
\\
&≤ \mathrm{Tr}(x^2Ax^2)\, \mathrm{Tr}(A^\frac{1}{2}∇x^2∇A^\frac{1}{2})
\\
&≤ \mathrm{Tr}(x^4A)\, \mathrm{Tr}(∇x^2∇A)
\end{align*}
 |B|^2 := B^*B ∇x^2 = 2x + x^2∇ 
\begin{align*}
\mathrm{Tr}(∇x^2∇A) &= 2\,\mathrm{Tr}(x∇A) + \mathrm{Tr}(x^2∇^2A)
\end{align*}
 
\begin{align*}
(\mathrm{Tr}(x∇A))^2 = (\mathrm{Tr}(A^\frac{1}{2}x∇A^\frac{1}{2}))^2 &\leq  \mathrm{Tr}(|A^{1/2}x|^2)\, \mathrm{Tr}(|∇A^{1/2 }|^2)
\\
&\leq \mathrm{Tr}(x^2A)\,\mathrm{Tr}(\nabla^2A)
\\
&\leq \mathrm{Tr}(A)^\frac{1}{2}\mathrm{Tr}(x^4A)^\frac{1}{2}\,\mathrm{Tr}(A)^\frac{1}{2} \mathrm{Tr}(\nabla^4A)^\frac{1}{2}
\\
(\mathrm{Tr}(x^2∇^2A))^2 = (\mathrm{Tr}(A^\frac{1}{2}x^2∇^2A^\frac{1}{2}))^2 &\leq  \mathrm{Tr}(|A^{1/2}x^2|^2)\, \mathrm{Tr}(|∇^2A^{1/2 }|^2)
\\
&\leq \mathrm{Tr}(x^4A)\,\mathrm{Tr}(\nabla^4A)
\end{align*}
","['functional-analysis', 'inequality', 'operator-theory', 'trace', 'compact-operators']"
44,Spectrum can be an arbitrary subset.,Spectrum can be an arbitrary subset.,,"Given any subset $E$ of field $\mathbb{F}$ (real or complex), does there exist a normed linear space $X$ over $\mathbb{F}$ and a bounded linear operator $$A:X\rightarrow X$$ such that spectrum of $A$ is precisely the set $E$ . NOTE : It is known that this is true for compact sets as we can use their separability to construct such an operator.","Given any subset of field (real or complex), does there exist a normed linear space over and a bounded linear operator such that spectrum of is precisely the set . NOTE : It is known that this is true for compact sets as we can use their separability to construct such an operator.",E \mathbb{F} X \mathbb{F} A:X\rightarrow X A E,"['functional-analysis', 'operator-theory', 'spectral-theory']"
45,Does the modulus of a linear operator change continuously with the operator?,Does the modulus of a linear operator change continuously with the operator?,,"Let $X,Y$ be real Banach spaces, and let $B(X,Y)$ be the space of bounded linear operators. Given $T \in B(X,Y)$ the modulus of $T$ is defined to be $$ \gamma(T):=\inf \{ \,\|Tx\| \, \, | \, \, d(x,\ker T)=1 \}. $$ It is known that if the image of $T$ is closed in $Y$, then $\gamma(T)>0$. Suppose that: $T_n \in B(X,Y)$ is a sequence of operators with closed images, and that $T_n \to T$ in the operator norm. $T$ has a closed image. $\dim \ker T_n=\dim \ker T< \infty$. (All the kernels are finite-dimensional and of the same dimension). Is it true that $\gamma(T_n) \ge c $ for some $ c >0$ independent of $n$? If the modulus was a continuous map $B(X,Y) \to \mathbb{R}$, then we had $\gamma(T_n) \to \gamma(T)>0$. So the answer would be positive. However, I am not sure the modulus is continuous. Nonetheless, I am interested in the weaker result - must the modulus of a convergent sequence be bounded?","Let $X,Y$ be real Banach spaces, and let $B(X,Y)$ be the space of bounded linear operators. Given $T \in B(X,Y)$ the modulus of $T$ is defined to be $$ \gamma(T):=\inf \{ \,\|Tx\| \, \, | \, \, d(x,\ker T)=1 \}. $$ It is known that if the image of $T$ is closed in $Y$, then $\gamma(T)>0$. Suppose that: $T_n \in B(X,Y)$ is a sequence of operators with closed images, and that $T_n \to T$ in the operator norm. $T$ has a closed image. $\dim \ker T_n=\dim \ker T< \infty$. (All the kernels are finite-dimensional and of the same dimension). Is it true that $\gamma(T_n) \ge c $ for some $ c >0$ independent of $n$? If the modulus was a continuous map $B(X,Y) \to \mathbb{R}$, then we had $\gamma(T_n) \to \gamma(T)>0$. So the answer would be positive. However, I am not sure the modulus is continuous. Nonetheless, I am interested in the weaker result - must the modulus of a convergent sequence be bounded?",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'normed-spaces', 'perturbation-theory']"
46,Normalizing a semi-normalized Schauder basis,Normalizing a semi-normalized Schauder basis,,"Here's something that is probably obvious but I can't seem to see it. Suppose $(x_n)_{n=1}^\infty$ is a Schauder basis for a Banach space $X$, ""seminormalized"" in the sense that we have $$0<\inf\|x_n\|\leq\sup\|x_n\|<\infty.$$ Now consider the corresponding normalized basis formed by setting $$y_n=\frac{x_n}{\|x_n\|},\quad n\in\mathbb{N}.$$ Recall that two Schauder bases $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ are said to be equivalent whenever there is a constant $C\in[1,\infty)$ satisfying the property $$C^{-1}\left\|\sum_{n=1}^\infty a_ny_n\right\| \leq \left\|\sum_{n=1}^\infty a_nx_n\right\| \leq C\left\|\sum_{n=1}^\infty a_ny_n\right\| \qquad \forall\,(a_n)_{n=1}^\infty\in c_{00},$$ where $c_{00}$ denotes the space of all scalar sequences with finitely many nonzero entries. Question #1. Is $(x_n)_{n=1}^\infty$ always equivalent to $(y_n)_{n=1}^\infty$? The principle of small perturbations guarantees that they have equivalent basic subsequences, but this is not enough.  I want the original bases themselves to be equivalent. It's also easy to see that they are equivalent whenever they are unconditional.  However, again, this is not enough for me.  I want equivalence to be guaranteed even when the bases are conditional. If the answer to Question #1 above is negative, then: Question #2. What is a specific counter-example to question #1?  In other words, can we give an example of a seminormalized basis $(x_n)_{n=1}^\infty$ which is not equivalent to its normalized counterpart $(y_n)_{n=1}^\infty$?","Here's something that is probably obvious but I can't seem to see it. Suppose $(x_n)_{n=1}^\infty$ is a Schauder basis for a Banach space $X$, ""seminormalized"" in the sense that we have $$0<\inf\|x_n\|\leq\sup\|x_n\|<\infty.$$ Now consider the corresponding normalized basis formed by setting $$y_n=\frac{x_n}{\|x_n\|},\quad n\in\mathbb{N}.$$ Recall that two Schauder bases $(x_n)_{n=1}^\infty$ and $(y_n)_{n=1}^\infty$ are said to be equivalent whenever there is a constant $C\in[1,\infty)$ satisfying the property $$C^{-1}\left\|\sum_{n=1}^\infty a_ny_n\right\| \leq \left\|\sum_{n=1}^\infty a_nx_n\right\| \leq C\left\|\sum_{n=1}^\infty a_ny_n\right\| \qquad \forall\,(a_n)_{n=1}^\infty\in c_{00},$$ where $c_{00}$ denotes the space of all scalar sequences with finitely many nonzero entries. Question #1. Is $(x_n)_{n=1}^\infty$ always equivalent to $(y_n)_{n=1}^\infty$? The principle of small perturbations guarantees that they have equivalent basic subsequences, but this is not enough.  I want the original bases themselves to be equivalent. It's also easy to see that they are equivalent whenever they are unconditional.  However, again, this is not enough for me.  I want equivalence to be guaranteed even when the bases are conditional. If the answer to Question #1 above is negative, then: Question #2. What is a specific counter-example to question #1?  In other words, can we give an example of a seminormalized basis $(x_n)_{n=1}^\infty$ which is not equivalent to its normalized counterpart $(y_n)_{n=1}^\infty$?",,"['functional-analysis', 'banach-spaces', 'schauder-basis']"
47,Does convexity in each variable implies polynomial convexity?,Does convexity in each variable implies polynomial convexity?,,"Let $\Omega$ be a domain in $\mathbb{C}^{m}$, $m\geq 1$. For each $a\in\Omega$, $i\in\{1,\ldots,m\}$, define $\Omega_{a,i}=\{z\in\mathbb{C}:a+ze_{i}\in\Omega\}$, where $e_{i}$ be the $i$-th standard basis element of $\mathbb{C}^{m}$. $\Omega$ is said to be convex in each variable if all of these $\Omega_{a,i}$'s are convex in $\mathbb{C}$. Does this force $\Omega$ to be polynomially convex $?$ A domain $D \subseteq \mathbb{C}^{m}$ is said to be polynomially convex if, for every compact subset $K$ of $D$, the polynomially convex hull of $K$, namely $\hat{K}=\{z\in\mathbb{C}^{n}:|p(z)|\leq \sup_{z\in K}|p(z)|$ for all polynomials$~p\}$ is contained in $D$.","Let $\Omega$ be a domain in $\mathbb{C}^{m}$, $m\geq 1$. For each $a\in\Omega$, $i\in\{1,\ldots,m\}$, define $\Omega_{a,i}=\{z\in\mathbb{C}:a+ze_{i}\in\Omega\}$, where $e_{i}$ be the $i$-th standard basis element of $\mathbb{C}^{m}$. $\Omega$ is said to be convex in each variable if all of these $\Omega_{a,i}$'s are convex in $\mathbb{C}$. Does this force $\Omega$ to be polynomially convex $?$ A domain $D \subseteq \mathbb{C}^{m}$ is said to be polynomially convex if, for every compact subset $K$ of $D$, the polynomially convex hull of $K$, namely $\hat{K}=\{z\in\mathbb{C}^{n}:|p(z)|\leq \sup_{z\in K}|p(z)|$ for all polynomials$~p\}$ is contained in $D$.",,"['complex-analysis', 'functional-analysis', 'convex-analysis', 'several-complex-variables']"
48,"Distribution on $(0, \infty)$ which cannot be extended to $\mathbb{R}$",Distribution on  which cannot be extended to,"(0, \infty) \mathbb{R}","I am working on exercises from Friedlander's Introduction to the Theory of Distributions and I am stuck in a particular problem. The question is: ""Show that $\langle u, \phi\rangle = \sum_\limits{k \geq 1} \partial^k \phi(1/k)$ is a distribution on $(0, \infty)$, but that there is no $v\in \mathcal{D}'(\mathbb{R})$ whose restriction to $(0, \infty)$ is equal to $u$."" I believe I have managed to prove the first part: Given any compact $K \subset (0,\infty)$, take a test function $\phi\in C^{\infty}_c(0, \infty)$ with $\operatorname{supp} \phi \subset K$. Take then $N$ such that $\frac{1}{N+1} < \min \operatorname{supp} \phi$. We have that $\langle u, \phi\rangle = \sum_\limits{k = 1}^N \partial^k \phi(1/k)$, since $\phi(1/k) = 0, \forall k>N+1$. And so it is clear that $\exists C$ and $\exists N$ such that $u$ satisfies the seminorm estimates $|\langle u, \phi\rangle| \leq \sum\limits_{k=1}^N |\sup\partial^k \phi|$ for any $\phi$. Now, the second part is troubling me. I believe the way is to suppose there is a distribution $v\in \mathcal{D}'(\mathbb{R})$ with $v|_{(0,\infty)} = u$, and show that it would not satisfy the seminorm estimate because of the restriction. However, I am struggling to see how that should be done. Note: I have recognized this distribution to be equivalent to $\sum\limits_{k\geq 1} \delta^{(k)}(x-1/k)$ but I am not sure how this helps!","I am working on exercises from Friedlander's Introduction to the Theory of Distributions and I am stuck in a particular problem. The question is: ""Show that $\langle u, \phi\rangle = \sum_\limits{k \geq 1} \partial^k \phi(1/k)$ is a distribution on $(0, \infty)$, but that there is no $v\in \mathcal{D}'(\mathbb{R})$ whose restriction to $(0, \infty)$ is equal to $u$."" I believe I have managed to prove the first part: Given any compact $K \subset (0,\infty)$, take a test function $\phi\in C^{\infty}_c(0, \infty)$ with $\operatorname{supp} \phi \subset K$. Take then $N$ such that $\frac{1}{N+1} < \min \operatorname{supp} \phi$. We have that $\langle u, \phi\rangle = \sum_\limits{k = 1}^N \partial^k \phi(1/k)$, since $\phi(1/k) = 0, \forall k>N+1$. And so it is clear that $\exists C$ and $\exists N$ such that $u$ satisfies the seminorm estimates $|\langle u, \phi\rangle| \leq \sum\limits_{k=1}^N |\sup\partial^k \phi|$ for any $\phi$. Now, the second part is troubling me. I believe the way is to suppose there is a distribution $v\in \mathcal{D}'(\mathbb{R})$ with $v|_{(0,\infty)} = u$, and show that it would not satisfy the seminorm estimate because of the restriction. However, I am struggling to see how that should be done. Note: I have recognized this distribution to be equivalent to $\sum\limits_{k\geq 1} \delta^{(k)}(x-1/k)$ but I am not sure how this helps!",,"['functional-analysis', 'distribution-theory']"
49,Nested families of balls in Banach spaces,Nested families of balls in Banach spaces,,"Is it possible to find a Banach space $X$, $x_i\in X$ and $r_i > 0$ indexed by some $i\in I$, possibly infinite, such that for each $n\in \mathbb{N}$ $$\bigcap_{i\in I} B\big(x_i, (1+\tfrac{1}{n})r_i\big)\neq \varnothing$$ but $$\bigcap_{i\in I} B\big(x_i, r_i\big)= \varnothing ?$$ Here $B(x,r)$ stands for the closed ball centred at $x$ with radius $r$. There is no restriction on cardinality of $I$ here (for instance, $I$ may be uncountable). Also the radii $r_i$ may be unbounded too. Note that $X$ cannot be isometric to a dual space (which rules out $\ell_1$ and all reflexive spaces, for example). For those who don't believe, here is the proof. If $X$ is a dual space, then all closed balls are weakly* compact by the Banach-Alaoglu theorem. However,  $$\bigcap_{i\in I} B\big(x_i, r_i\big) = \bigcap_n \bigcap_{i\in I} B\big(x_i, (1+\tfrac{1}{n})r_i\big) $$ must be non-empty being the intersection of a descending sequence of compact sets .","Is it possible to find a Banach space $X$, $x_i\in X$ and $r_i > 0$ indexed by some $i\in I$, possibly infinite, such that for each $n\in \mathbb{N}$ $$\bigcap_{i\in I} B\big(x_i, (1+\tfrac{1}{n})r_i\big)\neq \varnothing$$ but $$\bigcap_{i\in I} B\big(x_i, r_i\big)= \varnothing ?$$ Here $B(x,r)$ stands for the closed ball centred at $x$ with radius $r$. There is no restriction on cardinality of $I$ here (for instance, $I$ may be uncountable). Also the radii $r_i$ may be unbounded too. Note that $X$ cannot be isometric to a dual space (which rules out $\ell_1$ and all reflexive spaces, for example). For those who don't believe, here is the proof. If $X$ is a dual space, then all closed balls are weakly* compact by the Banach-Alaoglu theorem. However,  $$\bigcap_{i\in I} B\big(x_i, r_i\big) = \bigcap_n \bigcap_{i\in I} B\big(x_i, (1+\tfrac{1}{n})r_i\big) $$ must be non-empty being the intersection of a descending sequence of compact sets .",,"['functional-analysis', 'metric-spaces', 'banach-spaces']"
50,Why is the Minimum in the Min-Max Principle for Self-Adjoint Operators attained?,Why is the Minimum in the Min-Max Principle for Self-Adjoint Operators attained?,,"Let's consider a self-adjoint operator $A$ (not necessarily bounded) on a Hilbert space which is bounded from below, with domain $D$ and whose resolvent is compact. Then, the spectrum consists solely of isolated eigenvalues which are given (in increasing order) by the min-max principle: \begin{equation} \lambda_k = \min_{\substack{V \subset D\\ \dim V  = k}} \max_{\substack{x \in V \\ x \neq 0}} \frac{\langle \,x , Ax \rangle}{\langle \, x, x \rangle}, \ k \in \mathbb{N}. \end{equation} The proof I know shows $\lambda_k \geq \min \max \frac{\langle \,x , Ax \rangle}{\langle \, x, x \rangle}$ and $\lambda_k \leq \min \max \frac{\langle \,x , Ax \rangle}{\langle \, x, x \rangle}$ by using a orthonormal basis of eigenvectors. As seen here: Why is the Maximum in the Min-Max Principle for Self-Adjoint Operators attained? , we know that the maximum is attained since the unit sphere is compact in a finite dimensional vector space. But why is the minimum also attained?","Let's consider a self-adjoint operator $A$ (not necessarily bounded) on a Hilbert space which is bounded from below, with domain $D$ and whose resolvent is compact. Then, the spectrum consists solely of isolated eigenvalues which are given (in increasing order) by the min-max principle: \begin{equation} \lambda_k = \min_{\substack{V \subset D\\ \dim V  = k}} \max_{\substack{x \in V \\ x \neq 0}} \frac{\langle \,x , Ax \rangle}{\langle \, x, x \rangle}, \ k \in \mathbb{N}. \end{equation} The proof I know shows $\lambda_k \geq \min \max \frac{\langle \,x , Ax \rangle}{\langle \, x, x \rangle}$ and $\lambda_k \leq \min \max \frac{\langle \,x , Ax \rangle}{\langle \, x, x \rangle}$ by using a orthonormal basis of eigenvectors. As seen here: Why is the Maximum in the Min-Max Principle for Self-Adjoint Operators attained? , we know that the maximum is attained since the unit sphere is compact in a finite dimensional vector space. But why is the minimum also attained?",,"['functional-analysis', 'spectral-theory']"
51,Categorical formulations of basic results and ideas from functional analysis?,Categorical formulations of basic results and ideas from functional analysis?,,"I'm taking a first (undergrad) course on functional analysis. Though the material is nice, the approach seems very ad hoc and in a sense, near-sighted (?). I was wondering whether the/a big picture of (parts of) the elementary landscape of functional analysis admits some nice categorical descriptions. What are some basic facts, theorems, and constructions in elementary functional analysis admit enlightening categorical formulations?","I'm taking a first (undergrad) course on functional analysis. Though the material is nice, the approach seems very ad hoc and in a sense, near-sighted (?). I was wondering whether the/a big picture of (parts of) the elementary landscape of functional analysis admits some nice categorical descriptions. What are some basic facts, theorems, and constructions in elementary functional analysis admit enlightening categorical formulations?",,"['functional-analysis', 'category-theory', 'big-list', 'big-picture']"
52,Existence of a function,Existence of a function,,"I need some help: I am thinking about this problem. Any advice would be appreciated. Let's fix $\epsilon>0$. Does there exists some $f\in C^0([0,\pi])$ such that: $f\mid_{[\epsilon,\pi-\epsilon]}>0$ $f=\sum_{k=3}^\infty{a_k\cos(kx)+b_k\sin(kx)}$? Thanks :)","I need some help: I am thinking about this problem. Any advice would be appreciated. Let's fix $\epsilon>0$. Does there exists some $f\in C^0([0,\pi])$ such that: $f\mid_{[\epsilon,\pi-\epsilon]}>0$ $f=\sum_{k=3}^\infty{a_k\cos(kx)+b_k\sin(kx)}$? Thanks :)",,"['functional-analysis', 'fourier-analysis', 'approximation']"
53,"Is $W_0^{1,p}(\Omega)$ complemented in $W^{1,p}(\Omega)$?",Is  complemented in ?,"W_0^{1,p}(\Omega) W^{1,p}(\Omega)","Let $\Omega\subset\mathbb{R}^N$ be a bounded domain and $p\in (1,\infty)$. It is know that there exists a unique bounded surjective linear map $T: W^{1,p}(\Omega)\to W^{1-1/p,p}(\partial\Omega)$ with the property that $$Tu=u_{|\partial\Omega},\ \forall\ u\in C^\infty(\overline{\Omega})$$ It is also know that there exists a bounded linear map $\ell : W^{1-1/p,p}(\partial\Omega) \to W^{1,p}(\Omega)$ which is a right inverse for $T$. This map is sometimes called the lift map (see Necas Theorem 5.7). In proving the existence of $\ell$, Necas explicit constructs the map $\ell$. I want to avoid this construction and use an argument from Functional Analysis, to wit, Theorem 2.12 of Brezis . To use it, I have to prove that $W_0^{1,p}(\Omega)$ is complemented in $W^{1,p}(\Omega)$, however I am stuck here. How would I go about this?","Let $\Omega\subset\mathbb{R}^N$ be a bounded domain and $p\in (1,\infty)$. It is know that there exists a unique bounded surjective linear map $T: W^{1,p}(\Omega)\to W^{1-1/p,p}(\partial\Omega)$ with the property that $$Tu=u_{|\partial\Omega},\ \forall\ u\in C^\infty(\overline{\Omega})$$ It is also know that there exists a bounded linear map $\ell : W^{1-1/p,p}(\partial\Omega) \to W^{1,p}(\Omega)$ which is a right inverse for $T$. This map is sometimes called the lift map (see Necas Theorem 5.7). In proving the existence of $\ell$, Necas explicit constructs the map $\ell$. I want to avoid this construction and use an argument from Functional Analysis, to wit, Theorem 2.12 of Brezis . To use it, I have to prove that $W_0^{1,p}(\Omega)$ is complemented in $W^{1,p}(\Omega)$, however I am stuck here. How would I go about this?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
54,Weak convergence in $L^p$ and uniform convergence,Weak convergence in  and uniform convergence,L^p,"I don't understand the last line of a proof (which is supposed to be obvious...), could you help me? The context is the following. We have a bounded open set $U$ of $\mathbb{R}^m$, and a $C^\infty$-mapping $$F : \mathbb{R}^m \times \mathbb{R} \times U \to \mathbb{R}^m$$ We also have a sequence $(u_n)_n$ of $W^{1,p}(U)$ ($p > 1$) and $u \in W^{1,p}(U)$ such that $u_n$ converges uniformly to $u$ and $\nabla u_n$ converges weakly in $L^p(U,\mathbb{R}^m)$ to $\nabla u$. Last, we know that $|u| + |\nabla u| < M$ for some $M < +\infty$. The first thing said is that $F(\nabla u, u_n, .)$ converges uniformly to $F(\nabla u, u, .)$ on $U$. I have the intuition that it's true but I don't know how to prove it formally. Is it just obvious from some sort of theorem about function composition? I suppose I have to use the condition $|u| + |\nabla u| < M$ somewhere... Secondly, $$\displaystyle\lim\limits_{n\to\infty}\int_U F(\nabla u(x), u_n(x),x)\cdot (\nabla u_n(x) - \nabla u(x)) dx = 0$$(We know that the definite integral exists and is finite for each $n$). They said that ""weak convergence is, by its very definition, compatible with linear expressions, and so the limit holds"", but I don't understand this statement... Thank you in advance if you can explain me one of the two affirmations (and sorry for my not perfect english) :). I perhaps have forgotten some hypothesis (even if I hope not), so don't hesitate if you think there is something missing or unclear.","I don't understand the last line of a proof (which is supposed to be obvious...), could you help me? The context is the following. We have a bounded open set $U$ of $\mathbb{R}^m$, and a $C^\infty$-mapping $$F : \mathbb{R}^m \times \mathbb{R} \times U \to \mathbb{R}^m$$ We also have a sequence $(u_n)_n$ of $W^{1,p}(U)$ ($p > 1$) and $u \in W^{1,p}(U)$ such that $u_n$ converges uniformly to $u$ and $\nabla u_n$ converges weakly in $L^p(U,\mathbb{R}^m)$ to $\nabla u$. Last, we know that $|u| + |\nabla u| < M$ for some $M < +\infty$. The first thing said is that $F(\nabla u, u_n, .)$ converges uniformly to $F(\nabla u, u, .)$ on $U$. I have the intuition that it's true but I don't know how to prove it formally. Is it just obvious from some sort of theorem about function composition? I suppose I have to use the condition $|u| + |\nabla u| < M$ somewhere... Secondly, $$\displaystyle\lim\limits_{n\to\infty}\int_U F(\nabla u(x), u_n(x),x)\cdot (\nabla u_n(x) - \nabla u(x)) dx = 0$$(We know that the definite integral exists and is finite for each $n$). They said that ""weak convergence is, by its very definition, compatible with linear expressions, and so the limit holds"", but I don't understand this statement... Thank you in advance if you can explain me one of the two affirmations (and sorry for my not perfect english) :). I perhaps have forgotten some hypothesis (even if I hope not), so don't hesitate if you think there is something missing or unclear.",,['functional-analysis']
55,Basic Open Problems in Functional Analysis,Basic Open Problems in Functional Analysis,,"Hello I was wondering if there exists open problems in functional analysis that don't require too much machinary for studying them, I mean, problems that don't require high level prerequisites.. Does anyone know any of them:","Hello I was wondering if there exists open problems in functional analysis that don't require too much machinary for studying them, I mean, problems that don't require high level prerequisites.. Does anyone know any of them:",,['functional-analysis']
56,Sobolev space and equivalence of norms,Sobolev space and equivalence of norms,,"I'm considering the space $W\{n,p\}[0,1]$ of functions with $n-1$ continuous derivatives $f^{(n-1)}$ is absolutely continuous and $f^{(n)}$ is in $L^p[0,1]$. The usual norm is the sum of the $p$-norms of each derivative from $1$ to $n$ and the $p$ norm of the function. Now just consider the $p$ norm of the function + $p$ norm of the $n^{th}$ derivative, i.e.$(\int |f(x)|^p)^{1/p}$ + $(\int |f^{(n)}|^p)^{1/p}$  I want to show that this is equivalent to the usual norm defined above. This requires finding positive constants and sandwiching this new norm. In one direction it's obvious since the new norm is less than the usual norm for every $x$, say $\|x\|_2 \leq \|x\|_1$. I'm not sure how to show the other direction.","I'm considering the space $W\{n,p\}[0,1]$ of functions with $n-1$ continuous derivatives $f^{(n-1)}$ is absolutely continuous and $f^{(n)}$ is in $L^p[0,1]$. The usual norm is the sum of the $p$-norms of each derivative from $1$ to $n$ and the $p$ norm of the function. Now just consider the $p$ norm of the function + $p$ norm of the $n^{th}$ derivative, i.e.$(\int |f(x)|^p)^{1/p}$ + $(\int |f^{(n)}|^p)^{1/p}$  I want to show that this is equivalent to the usual norm defined above. This requires finding positive constants and sandwiching this new norm. In one direction it's obvious since the new norm is less than the usual norm for every $x$, say $\|x\|_2 \leq \|x\|_1$. I'm not sure how to show the other direction.",,"['functional-analysis', 'sobolev-spaces', 'absolute-continuity']"
57,Hilbert Schmidt integral operator,Hilbert Schmidt integral operator,,"Hilbert-Schmidt Integral operators are usually defined from $H=L_2[a,b]$ into $H=L_2[a,b]$ as $$(Tf)(x) = \int_a^b K(x,y)f(y) dy,$$ provided that  $K(x,y)$ is a Hilbert Schmidt kernel, namely $$\int_a^b \int_a^b |K(x,y)|^2dx dy < \infty.$$ I was wondering if the following extension is used with the same name. Letting $H_1 = L_2[a,b]$, $H_2=L_2[c,d]$, and $$\int_a^b \int_c^d |K(x,y)|^2dx dy < \infty,$$ consider the integral operators $T_1:H_2 \rightarrow H_1$ and $T_2:H_1 \rightarrow H_2$ $$(T_1 f)(x) = \int_c^d K(x,y)f(y) dy,$$ $$(T_2 f)(y) = \int_a^b K(x,y)g(x) dx.$$ Can one still call these operators and corresponding kernel of Hilbert-Schmidt type?","Hilbert-Schmidt Integral operators are usually defined from $H=L_2[a,b]$ into $H=L_2[a,b]$ as $$(Tf)(x) = \int_a^b K(x,y)f(y) dy,$$ provided that  $K(x,y)$ is a Hilbert Schmidt kernel, namely $$\int_a^b \int_a^b |K(x,y)|^2dx dy < \infty.$$ I was wondering if the following extension is used with the same name. Letting $H_1 = L_2[a,b]$, $H_2=L_2[c,d]$, and $$\int_a^b \int_c^d |K(x,y)|^2dx dy < \infty,$$ consider the integral operators $T_1:H_2 \rightarrow H_1$ and $T_2:H_1 \rightarrow H_2$ $$(T_1 f)(x) = \int_c^d K(x,y)f(y) dy,$$ $$(T_2 f)(y) = \int_a^b K(x,y)g(x) dx.$$ Can one still call these operators and corresponding kernel of Hilbert-Schmidt type?",,"['functional-analysis', 'hilbert-spaces', 'operator-theory']"
58,Cyclicity of the trace for operators,Cyclicity of the trace for operators,,"I know that if I have two operators $A$ and $B$ and one is bounded and the other is trace class, then $$ \mathrm{Tr}(AB) = \mathrm{Tr}(BA). $$ Another case where this works is when $A$ and $B$ are both Hilbert-Schmidt operators. But I heard that it is actually sufficient to have $\mathrm{Tr}(|AB|)<\infty$ and $\mathrm{Tr}(|BA|)<\infty$ . Has anyone a reference about that? Are there other cases where the cyclicity of the trace still works, or at least where it works ""in a certain sense""? In particular I am interested in the case where $A$ is a really nice operator and $B$ is unbounded. For example, say $B=x$ is the unbounded operator of multiplication by $x\in\Bbb R$ and $A$ is a compact positive operator acting on $L^2$ functions $\varphi$ through the formula $$A\varphi(x) = \sum_j \lambda_j\, \psi_j(x) \int_{\Bbb R} \psi_j\,\varphi$$ with $\sum_j \lambda_j\int_{\Bbb R} |\psi_j(x)|^2\,(1+|x|)\,\mathrm d x< C$ . Then $$ \mathrm{Tr}(AB) = \mathrm{Tr}(BA) = \sum_j \lambda_j \int_{\Bbb R} |\psi_j(x)|^2\,x\,\mathrm d x $$ Remark: Another quite borderline case where I know how to do the proof is if $A$ and $B$ are positive operators and $\sqrt A\sqrt B$ is an Hilbert-Schmidt operator and one defines $\mathrm{Tr}(AB) := \mathrm{Tr}(\sqrt B\,A\,\sqrt B) = \|\sqrt A\sqrt B\|_2^2$ . Then by invariance of the Hilbert-Schmidt norm by taking the adjoint, $$ \mathrm{Tr}(AB) = \|\sqrt A\sqrt B\|_2^2 = \|\sqrt B\sqrt A\|_2^2 = \mathrm{Tr}(BA). $$","I know that if I have two operators and and one is bounded and the other is trace class, then Another case where this works is when and are both Hilbert-Schmidt operators. But I heard that it is actually sufficient to have and . Has anyone a reference about that? Are there other cases where the cyclicity of the trace still works, or at least where it works ""in a certain sense""? In particular I am interested in the case where is a really nice operator and is unbounded. For example, say is the unbounded operator of multiplication by and is a compact positive operator acting on functions through the formula with . Then Remark: Another quite borderline case where I know how to do the proof is if and are positive operators and is an Hilbert-Schmidt operator and one defines . Then by invariance of the Hilbert-Schmidt norm by taking the adjoint,","A B 
\mathrm{Tr}(AB) = \mathrm{Tr}(BA).
 A B \mathrm{Tr}(|AB|)<\infty \mathrm{Tr}(|BA|)<\infty A B B=x x\in\Bbb R A L^2 \varphi A\varphi(x) = \sum_j \lambda_j\, \psi_j(x) \int_{\Bbb R} \psi_j\,\varphi \sum_j \lambda_j\int_{\Bbb R} |\psi_j(x)|^2\,(1+|x|)\,\mathrm d x< C 
\mathrm{Tr}(AB) = \mathrm{Tr}(BA) = \sum_j \lambda_j \int_{\Bbb R} |\psi_j(x)|^2\,x\,\mathrm d x
 A B \sqrt A\sqrt B \mathrm{Tr}(AB) := \mathrm{Tr}(\sqrt B\,A\,\sqrt B) = \|\sqrt A\sqrt B\|_2^2 
\mathrm{Tr}(AB) = \|\sqrt A\sqrt B\|_2^2 = \|\sqrt B\sqrt A\|_2^2 = \mathrm{Tr}(BA).
","['functional-analysis', 'operator-theory', 'trace']"
59,"Connection between two analytic notions of ""spectrum""","Connection between two analytic notions of ""spectrum""",,"In Spectral Theory and Analytic Geometry over Non-Archimedean Fields Berkovich defines the spectrum of a commutative, unital Banach ring $A$ to be the set of all bounded multiplicative seminorms on $A$ with the weak topology with respect to the family of functions $$\phi_f: || \mapsto |f|$$ In another class, I learned the definition of spectrum $\sigma(T)$ of an element of a Banach algebra to be the set of all the $\lambda$ such that $T - \lambda I$ is non-invertible. Many times I try to look something up related to Berkovich's text (such as the Gel'fand transform, characters),  and I find a concept by the same or similar name that seems similar but is definitionally different. So are the two definitions connected somehow? This section of Wikipeda seems promising, as well as the page on the Gel'fand representation, but I could use some help connecting the dots.","In Spectral Theory and Analytic Geometry over Non-Archimedean Fields Berkovich defines the spectrum of a commutative, unital Banach ring to be the set of all bounded multiplicative seminorms on with the weak topology with respect to the family of functions In another class, I learned the definition of spectrum of an element of a Banach algebra to be the set of all the such that is non-invertible. Many times I try to look something up related to Berkovich's text (such as the Gel'fand transform, characters),  and I find a concept by the same or similar name that seems similar but is definitionally different. So are the two definitions connected somehow? This section of Wikipeda seems promising, as well as the page on the Gel'fand representation, but I could use some help connecting the dots.",A A \phi_f: || \mapsto |f| \sigma(T) \lambda T - \lambda I,"['functional-analysis', 'analytic-geometry', 'spectral-theory', 'banach-algebras']"
60,The inverse of a $\Psi$DO is a $\Psi$DO,The inverse of a DO is a DO,\Psi \Psi,"The following question looks quite simple, but unfortunately I was not able to find an answer in the literature so far. Let $A \in OPS^m(X)$, $m \in \mathbb R$, be a pseudodifferential operator on a compact manifold $X$. If $A$ is invertible, is it true that the inverse $A^{-1}$ is actually a pseudo-differential operator $A^{-1} \in OPS^{-m}(X)$? By invertble I mean that $A^{-1}$ is defined on $C^\infty(X)$ and in this space $AA^{-1} = A^{-1}A = \mathrm{Id}$. For example, a similar statement is used in the beginning of p.293 of [M.Taylor, Pseudodifferential Operators, 1981]: If $\in OPS^m$ is elliptic, positive self-adjoint operator on a   compact manifold $X$, or order $m>0$, then $(I+P)^{-1} \in OPS^{-m}$ is compact. Since it is not explained, I think it must be quite obvious.","The following question looks quite simple, but unfortunately I was not able to find an answer in the literature so far. Let $A \in OPS^m(X)$, $m \in \mathbb R$, be a pseudodifferential operator on a compact manifold $X$. If $A$ is invertible, is it true that the inverse $A^{-1}$ is actually a pseudo-differential operator $A^{-1} \in OPS^{-m}(X)$? By invertble I mean that $A^{-1}$ is defined on $C^\infty(X)$ and in this space $AA^{-1} = A^{-1}A = \mathrm{Id}$. For example, a similar statement is used in the beginning of p.293 of [M.Taylor, Pseudodifferential Operators, 1981]: If $\in OPS^m$ is elliptic, positive self-adjoint operator on a   compact manifold $X$, or order $m>0$, then $(I+P)^{-1} \in OPS^{-m}$ is compact. Since it is not explained, I think it must be quite obvious.",,"['functional-analysis', 'pseudo-differential-operators', 'microlocal-analysis']"
61,Why is Existence and Uniqueness for Navier-Stokes Easier in 2-D than in 3-D? [duplicate],Why is Existence and Uniqueness for Navier-Stokes Easier in 2-D than in 3-D? [duplicate],,"This question already has an answer here : Why Navier-Stokes Partial Differential Equations Are Difficult To Simulate (1 answer) Closed 10 months ago . I know that existence and uniqueness for incompressible viscous flow in the 2-D case has already been established$^1$, and that doing the same for the 3-D case has yet to be shown. Not only that, but it's one of the hardest problems out there in mathematics today. Clearly then, the 2-D case is considerably easier than the 3-D case, but why is this so? As quoted from the Navier-Stokes Millenium Problem's problem statement, ""This gives no hint about the three-dimensional case, since the main   difficulties are absent in two dimensions."" What are these main difficulties? I'm looking for any answers, going as deep into any subjects as necessary. I'm ready to read long and deeply for this. P.S: I've only started self-studying basic partial-differential equations, but I'm really interested in numerical (and analytic too) methods for solving PDE's. [1] Ladyzhenskaya, Olga A. Mathematics and Its Applications : The Mathematical Theory of Viscous Incompressible Flow. 2nd ed. 2. Camberwell, Australia: Gordon and Breach Science Publishers, 1969. 224. Print.","This question already has an answer here : Why Navier-Stokes Partial Differential Equations Are Difficult To Simulate (1 answer) Closed 10 months ago . I know that existence and uniqueness for incompressible viscous flow in the 2-D case has already been established$^1$, and that doing the same for the 3-D case has yet to be shown. Not only that, but it's one of the hardest problems out there in mathematics today. Clearly then, the 2-D case is considerably easier than the 3-D case, but why is this so? As quoted from the Navier-Stokes Millenium Problem's problem statement, ""This gives no hint about the three-dimensional case, since the main   difficulties are absent in two dimensions."" What are these main difficulties? I'm looking for any answers, going as deep into any subjects as necessary. I'm ready to read long and deeply for this. P.S: I've only started self-studying basic partial-differential equations, but I'm really interested in numerical (and analytic too) methods for solving PDE's. [1] Ladyzhenskaya, Olga A. Mathematics and Its Applications : The Mathematical Theory of Viscous Incompressible Flow. 2nd ed. 2. Camberwell, Australia: Gordon and Breach Science Publishers, 1969. 224. Print.",,"['functional-analysis', 'ordinary-differential-equations', 'partial-differential-equations', 'sobolev-spaces']"
62,Definition of continuous spectrum of a bounded operator,Definition of continuous spectrum of a bounded operator,,"Let $T$ be a bounded operator acting on a Banach space $X$. The point spectrum $\sigma_p(T)$ is of $T$ is defined to be $$\sigma_p(T):=\{\lambda\in\mathbb C~|~T-\lambda\text{ has nonempty kernel}\}$$ and the residual spectrum $\sigma_r(T)$ is defined to be $$\sigma_r(T):=\{\lambda\in\mathbb C~|~T-\lambda\text{ has empty kernel but Ran}(T-\lambda)\text{ is not even dense in }X\}.$$  For the continuous spectrum there seem to exist two non-equivalent definitions. For example, Dunford-Schwartz defines $$\sigma_c(T):=\{\lambda\in\mathbb C~|~T-\lambda\text{ has empty kernel but Ran}(T-\lambda)\text{ is a dense proper subset of } X\}$$ whereas for example Kato or Schmüdgen define \begin{align*}\sigma_c'(T)&:=\{\lambda\in\mathbb C~|~\text{Ran}(T-\lambda)\text{ is not a closed subset of } X\}\\ \sigma_r'(T)&:=\{\lambda\in\mathbb C~|~T-\lambda\text{ has a bounded inverse defined only on a proper subset of } X\}. \end{align*} Does anyone have insights on the difference of these definitions? What are the advantages? The former one gives a partition of the spectrum, so that's kind of nice, but why is the second definition (more?) useful? Edit: I just created a table that categorizes parts of the spectrum in terms of the questions: Is $K_\lambda:=$Ker$(T-\lambda)$ zero or nonzero? Is $R_\lambda:=$Ran$(T-\lambda)$ closed or not? Is $R_\lambda:=$Ran$(T-\lambda)$ dense or not? According to this table the point spectrum can be subdivided into four subtypes and the residual spectrum can be subdivided into two subtypes. The alternative definitions would correspond to \begin{align*}\sigma_c'(T)&=\sigma_{c}(T)\cup\sigma_{r,1}(T)\cup\sigma_{p,2}(T)\cup\sigma_{p,3}(T)\\ \sigma_r'(T)&=\sigma_{r,1}(T) \end{align*} The approximate point spectrum and compression spectrum on the other hand are given by \begin{align*} \sigma_{ap}(T)&=\sigma_{c}(T)\cup\sigma_{r,1}(T)\cup\sigma_{p,1}(T)\cup\sigma_{p,2}(T)\cup\sigma_{p,3}(T)\cup\sigma_{p,4}(T)\\ \sigma_{com}(T)&=\sigma_{r,1}(T)\cup\sigma_{r,2}(T)\cup\sigma_{p,3}(T)\cup\sigma_{p,4}(T). \end{align*}","Let $T$ be a bounded operator acting on a Banach space $X$. The point spectrum $\sigma_p(T)$ is of $T$ is defined to be $$\sigma_p(T):=\{\lambda\in\mathbb C~|~T-\lambda\text{ has nonempty kernel}\}$$ and the residual spectrum $\sigma_r(T)$ is defined to be $$\sigma_r(T):=\{\lambda\in\mathbb C~|~T-\lambda\text{ has empty kernel but Ran}(T-\lambda)\text{ is not even dense in }X\}.$$  For the continuous spectrum there seem to exist two non-equivalent definitions. For example, Dunford-Schwartz defines $$\sigma_c(T):=\{\lambda\in\mathbb C~|~T-\lambda\text{ has empty kernel but Ran}(T-\lambda)\text{ is a dense proper subset of } X\}$$ whereas for example Kato or Schmüdgen define \begin{align*}\sigma_c'(T)&:=\{\lambda\in\mathbb C~|~\text{Ran}(T-\lambda)\text{ is not a closed subset of } X\}\\ \sigma_r'(T)&:=\{\lambda\in\mathbb C~|~T-\lambda\text{ has a bounded inverse defined only on a proper subset of } X\}. \end{align*} Does anyone have insights on the difference of these definitions? What are the advantages? The former one gives a partition of the spectrum, so that's kind of nice, but why is the second definition (more?) useful? Edit: I just created a table that categorizes parts of the spectrum in terms of the questions: Is $K_\lambda:=$Ker$(T-\lambda)$ zero or nonzero? Is $R_\lambda:=$Ran$(T-\lambda)$ closed or not? Is $R_\lambda:=$Ran$(T-\lambda)$ dense or not? According to this table the point spectrum can be subdivided into four subtypes and the residual spectrum can be subdivided into two subtypes. The alternative definitions would correspond to \begin{align*}\sigma_c'(T)&=\sigma_{c}(T)\cup\sigma_{r,1}(T)\cup\sigma_{p,2}(T)\cup\sigma_{p,3}(T)\\ \sigma_r'(T)&=\sigma_{r,1}(T) \end{align*} The approximate point spectrum and compression spectrum on the other hand are given by \begin{align*} \sigma_{ap}(T)&=\sigma_{c}(T)\cup\sigma_{r,1}(T)\cup\sigma_{p,1}(T)\cup\sigma_{p,2}(T)\cup\sigma_{p,3}(T)\cup\sigma_{p,4}(T)\\ \sigma_{com}(T)&=\sigma_{r,1}(T)\cup\sigma_{r,2}(T)\cup\sigma_{p,3}(T)\cup\sigma_{p,4}(T). \end{align*}",,"['functional-analysis', 'banach-spaces', 'spectral-theory']"
63,Representation of a linear functional Lipschitz in total variation,Representation of a linear functional Lipschitz in total variation,,"Let $\Omega$ be a Borel space and let $\mathcal P(\Omega)$ be the space of all Borel probability measures on $\Omega$ endowed with the topology of weak convergence. Define the total variation metric on the latter space $$   d(\mu,\nu) :=\sup\left\{\int_\Omega f\;\mathrm d\mu - \int_\Omega f\;\mathrm d\nu:f\in \mathcal B_1(\Omega)\right\} $$  where $\mathcal B_1(\Omega)$ is the space of all Borel functions on $\Omega$ whose absolute value does not exceed $1$. Clearly, any linear functional $\phi:\mathcal P(\Omega)\to \Bbb R$ of the form  $$   \phi(\mu) = \int_\Omega(c+f)\mathrm d\mu \tag{1} $$ for any $f\in \mathcal B_1(\Omega)$ and $c\in \Bbb R$ satisfies the following Lipschitz condition $$   |\phi(\mu) - \phi(\nu)| \leq d(\mu,\nu). \tag{2} $$ Is that true that any linear functional $\phi$ that satisfies $(2)$ can be represented as $(1)$? Borel space is a topological space homeomorphic to a Borel subset of a complete separable metric space. The answer below does not seem to be correct according to its author.","Let $\Omega$ be a Borel space and let $\mathcal P(\Omega)$ be the space of all Borel probability measures on $\Omega$ endowed with the topology of weak convergence. Define the total variation metric on the latter space $$   d(\mu,\nu) :=\sup\left\{\int_\Omega f\;\mathrm d\mu - \int_\Omega f\;\mathrm d\nu:f\in \mathcal B_1(\Omega)\right\} $$  where $\mathcal B_1(\Omega)$ is the space of all Borel functions on $\Omega$ whose absolute value does not exceed $1$. Clearly, any linear functional $\phi:\mathcal P(\Omega)\to \Bbb R$ of the form  $$   \phi(\mu) = \int_\Omega(c+f)\mathrm d\mu \tag{1} $$ for any $f\in \mathcal B_1(\Omega)$ and $c\in \Bbb R$ satisfies the following Lipschitz condition $$   |\phi(\mu) - \phi(\nu)| \leq d(\mu,\nu). \tag{2} $$ Is that true that any linear functional $\phi$ that satisfies $(2)$ can be represented as $(1)$? Borel space is a topological space homeomorphic to a Borel subset of a complete separable metric space. The answer below does not seem to be correct according to its author.",,"['functional-analysis', 'measure-theory', 'probability-theory', 'duality-theorems']"
64,Prove the boundedness of a bilinear continuous mapping.,Prove the boundedness of a bilinear continuous mapping.,,"Let $X,Y,Z$ are Banach spaces and $$B:X\times Y\to Z$$ is bilinear and continuous. Prove that there exists $M<\infty$ such that  $$\lVert B(x,y)\rVert \leq M\lVert x\rVert\lVert y\rVert.$$ Is completeness needed here? The bilinearity of $B$ means for a fixed  $x\in X$,$B_x\colon Y\to Z$ is linear and for a fix $y\in Y$, $B^y:X\to Z$ is linear. Since $X,Y,Z$ are metrizable by norms, I think what we do is to show that $B$ is bounded. Let $E_1,E_2$ are bounded, then $E_1\subset t_1V_1$ and $E_2\subset t_2V_2$ for all large $t_1,t_2$; put $M=\max\{t_1,t_2\}$, so that $$B(E_1\times E_2)\subset B(t_1V_1\times t_2V_2)\subset MB(V_1\times V_2)\subset MW,$$ in which $V_1,V_2$ are balanced neighborhoods of  origins in $X,Y$ respectively and $W$ is a neighborhood of $0$ in $Z$. Can someone point out if there is some errors in my thought or give a straightforward path?","Let $X,Y,Z$ are Banach spaces and $$B:X\times Y\to Z$$ is bilinear and continuous. Prove that there exists $M<\infty$ such that  $$\lVert B(x,y)\rVert \leq M\lVert x\rVert\lVert y\rVert.$$ Is completeness needed here? The bilinearity of $B$ means for a fixed  $x\in X$,$B_x\colon Y\to Z$ is linear and for a fix $y\in Y$, $B^y:X\to Z$ is linear. Since $X,Y,Z$ are metrizable by norms, I think what we do is to show that $B$ is bounded. Let $E_1,E_2$ are bounded, then $E_1\subset t_1V_1$ and $E_2\subset t_2V_2$ for all large $t_1,t_2$; put $M=\max\{t_1,t_2\}$, so that $$B(E_1\times E_2)\subset B(t_1V_1\times t_2V_2)\subset MB(V_1\times V_2)\subset MW,$$ in which $V_1,V_2$ are balanced neighborhoods of  origins in $X,Y$ respectively and $W$ is a neighborhood of $0$ in $Z$. Can someone point out if there is some errors in my thought or give a straightforward path?",,"['functional-analysis', 'banach-spaces', 'continuity', 'normed-spaces']"
65,Almost everywhere convergence and convergence of $L^{p}$ norms implies weak convergence,Almost everywhere convergence and convergence of  norms implies weak convergence,L^{p},"Let $(f_n)$ be functions in $L^p(\Omega), 1<p<\infty$ such that $(f_n) \rightarrow f$ almost everywhere and $\Vert f_n\Vert_p \rightarrow \Vert f\Vert_p$. How does one show that $f_n \rightarrow f$ weakly in $L^p(\Omega)$ without first showing that $f_n \rightarrow f$ strongly in $L^p(\Omega)$? (I know that under these hypotheses we in fact get that $f_n \rightarrow f$ strongly, as explained here If $f_k \to f$ a.e. and the $L^p$ norms converge, then $f_k \to f$ in $L^p$ , but there must be an easier, direct argument that $f_n \rightarrow f$ weakly.) I know that some subsequence $(f_{n_k})$ converges weakly to some $g$ in $L^p(\Omega)$ since the $f_n's$ are bounded, but then (1) how do we pass from the subsequence to the original sequence, and (2) how do we show that $g=f$? Thanks!","Let $(f_n)$ be functions in $L^p(\Omega), 1<p<\infty$ such that $(f_n) \rightarrow f$ almost everywhere and $\Vert f_n\Vert_p \rightarrow \Vert f\Vert_p$. How does one show that $f_n \rightarrow f$ weakly in $L^p(\Omega)$ without first showing that $f_n \rightarrow f$ strongly in $L^p(\Omega)$? (I know that under these hypotheses we in fact get that $f_n \rightarrow f$ strongly, as explained here If $f_k \to f$ a.e. and the $L^p$ norms converge, then $f_k \to f$ in $L^p$ , but there must be an easier, direct argument that $f_n \rightarrow f$ weakly.) I know that some subsequence $(f_{n_k})$ converges weakly to some $g$ in $L^p(\Omega)$ since the $f_n's$ are bounded, but then (1) how do we pass from the subsequence to the original sequence, and (2) how do we show that $g=f$? Thanks!",,"['functional-analysis', 'banach-spaces', 'weak-convergence']"
66,"What is the name for the archetypical example of a test function, $\varphi(x)=e^{1/(x^2-1)}$?","What is the name for the archetypical example of a test function, ?",\varphi(x)=e^{1/(x^2-1)},"$$ \varphi(x)=e^{1/(x^2-1)} $$ This function (on the interval $\quad]\!-1,1[ \,\,\, $, outside of it simply $\equiv0$) is used as the typical example of a test function / bump function, I have so far seen it it every book that covers $\mathcal{C}_0^\infty$ functions. But it's usually not called any specific name, though it does seem to have one, at least I heard it being called by some name recently, but forgot it. I'd greatly like to know a name for this function, both for my computer functions library and for ease when writing proofs where a test function is required, and you can quickly reassure its existence with a simple ""like the ...-function"". Friedrichs'sche Glättungsfunktion is in fact the name I was looking for!","$$ \varphi(x)=e^{1/(x^2-1)} $$ This function (on the interval $\quad]\!-1,1[ \,\,\, $, outside of it simply $\equiv0$) is used as the typical example of a test function / bump function, I have so far seen it it every book that covers $\mathcal{C}_0^\infty$ functions. But it's usually not called any specific name, though it does seem to have one, at least I heard it being called by some name recently, but forgot it. I'd greatly like to know a name for this function, both for my computer functions library and for ease when writing proofs where a test function is required, and you can quickly reassure its existence with a simple ""like the ...-function"". Friedrichs'sche Glättungsfunktion is in fact the name I was looking for!",,"['functional-analysis', 'terminology', 'distribution-theory']"
67,"For a normed vector space, is $\|x-y\| \leq \|x\|+\|y\|$ true?","For a normed vector space, is  true?",\|x-y\| \leq \|x\|+\|y\|,"I have a question about an inequality in normed vector spaces and I want to know if my proof is correct. Claim: Let $X$ be a normed vector space. Then \begin{equation} \|x-y\| \leq \|x\|+\|y\|\end{equation} for all $x,y \in X$ . Proof: Using the triangle inequality and the fact that $\|z\|=\|-z\|$ , we have \begin{equation} \begin{split} \|x-y\|&= \|x+(-y)\|\\ &\leq \|x\|+\|-y\| \\ &= \|x\|+\|y\| \end{split} \end{equation} Thanks for your answers!","I have a question about an inequality in normed vector spaces and I want to know if my proof is correct. Claim: Let be a normed vector space. Then for all . Proof: Using the triangle inequality and the fact that , we have Thanks for your answers!","X \begin{equation} \|x-y\| \leq \|x\|+\|y\|\end{equation} x,y \in X \|z\|=\|-z\| \begin{equation}
\begin{split}
\|x-y\|&= \|x+(-y)\|\\
&\leq \|x\|+\|-y\| \\
&= \|x\|+\|y\|
\end{split}
\end{equation}","['functional-analysis', 'vector-spaces', 'solution-verification', 'normed-spaces']"
68,A finite order restriction of a Fredholm operator is also a Fredholm operator.,A finite order restriction of a Fredholm operator is also a Fredholm operator.,,"Let $A:D(A) \subseteq H \to H$ and $B:D(B) \subseteq H \to H$ be closed linear operators on a Hilbert space $H$ such that $A$ is a finite order extension of $B$ , that is, $B \subseteq A$ and $\mbox{dim } D(A)/D(B) < \infty$ . I need to show that if $\lambda \notin \sigma(A)$ and $\lambda I-A$ is a Fredholm operator, then $\lambda I-B$ is also a Fredholm operator. There is a hint: Since $A$ is a finite order extension of $B$ , the difference of the resolvents is of finite order. But, I don't know how can I use the hint. Can I say that $\lambda \notin \sigma(B)$ ? My attempt Since $\lambda I-A$ is a Fredholm operator, by definition of a Fredholm operator we know that $\mbox{dim} (\ker (\lambda I-A))<\infty$ , $\mbox{dim} (H/R(\lambda I-A))<\infty$ and the range $R(\lambda I-A)$ of $\lambda I-A$ is closed in $H$ . From here we get that $\mbox{dim} (\ker (\lambda I-B))<\infty$ . Thank you for any help you can privide me.","Let and be closed linear operators on a Hilbert space such that is a finite order extension of , that is, and . I need to show that if and is a Fredholm operator, then is also a Fredholm operator. There is a hint: Since is a finite order extension of , the difference of the resolvents is of finite order. But, I don't know how can I use the hint. Can I say that ? My attempt Since is a Fredholm operator, by definition of a Fredholm operator we know that , and the range of is closed in . From here we get that . Thank you for any help you can privide me.",A:D(A) \subseteq H \to H B:D(B) \subseteq H \to H H A B B \subseteq A \mbox{dim } D(A)/D(B) < \infty \lambda \notin \sigma(A) \lambda I-A \lambda I-B A B \lambda \notin \sigma(B) \lambda I-A \mbox{dim} (\ker (\lambda I-A))<\infty \mbox{dim} (H/R(\lambda I-A))<\infty R(\lambda I-A) \lambda I-A H \mbox{dim} (\ker (\lambda I-B))<\infty,"['functional-analysis', 'operator-theory', 'spectral-theory']"
69,Prove that a kernel operator has no eigenvalues,Prove that a kernel operator has no eigenvalues,,"Good evening! I'm just popping here for a quick question. I'm just starting to work on kernel operators, from $L^2(\mathbb{R}_+)$ to itself, ie: $f \mapsto \left(x \mapsto \displaystyle\int_{\mathbb{R}_+} K(x,y)f(y)dy\right)$ , with $K$ a function from $\mathbb{R}^2$ to $\mathbb{R}$ . In the case where $K$ can be written as a finite sum of functions of $x$ and $y$ (ie $K(x,y) = \displaystyle\sum\limits_{i} u_i(x)v_i(y)$ , with $u_i$ and $v_i$ real functions), it is fairly easy to find eigenvalues and eigenfunctions (or prove there are none). But what if $K$ cannot be written as such? For example, I'm faced with the case $K(x,y) = \dfrac{1}{x+y}$ . What to do then? I know this operator has no eigenfunctions, but I'm trying to prove it. I've been looking for solutions in books on the subject, mostly A Hilbert space problem book by Paul Helmos, but the closest I could find to it was the proof that a Volterra operator had no eigenfunctions. So if anyone would have any idea where I could find resources on how to prove that.. maybe a book, or an article. I'd be grateful :) Thanks, have a nice day.","Good evening! I'm just popping here for a quick question. I'm just starting to work on kernel operators, from to itself, ie: , with a function from to . In the case where can be written as a finite sum of functions of and (ie , with and real functions), it is fairly easy to find eigenvalues and eigenfunctions (or prove there are none). But what if cannot be written as such? For example, I'm faced with the case . What to do then? I know this operator has no eigenfunctions, but I'm trying to prove it. I've been looking for solutions in books on the subject, mostly A Hilbert space problem book by Paul Helmos, but the closest I could find to it was the proof that a Volterra operator had no eigenfunctions. So if anyone would have any idea where I could find resources on how to prove that.. maybe a book, or an article. I'd be grateful :) Thanks, have a nice day.","L^2(\mathbb{R}_+) f \mapsto \left(x \mapsto \displaystyle\int_{\mathbb{R}_+} K(x,y)f(y)dy\right) K \mathbb{R}^2 \mathbb{R} K x y K(x,y) = \displaystyle\sum\limits_{i} u_i(x)v_i(y) u_i v_i K K(x,y) = \dfrac{1}{x+y}","['functional-analysis', 'operator-theory', 'spectral-theory']"
70,Convergent piecewise-constant approximation of l.s.c function,Convergent piecewise-constant approximation of l.s.c function,,"I have a lower semi-continuous (l.s.c) extended-valued function $f: \mathbb{R}^3 \to \mathbb{R} \cup \{+\infty\}$. I know the following properties: $\operatorname{dom}(f)$ is compact, and we have its bounding box $B$, $f$ is bounded, $f$ is piecewise-continuous - there exists a finite partition  $\operatorname{dom}(f) = \bigcup_{i=1}^m D_i$  such that $f$ is continuous on each $D_i$, and $\operatorname{cl}(D_i) = \operatorname{cl} (\operatorname{int} (D_i))$. For my purposes, I would like to approximate $f$ by partitioning $B$ into a regular grid of $\nu$ points along each axis, and defining my approximation $f_\nu$ to be constant in each grid box. My objective is to obtain convergence of $f_\nu$ to $f$ in some sense. My best-case scenario is having epi-graphical convergence, since I want to use the approximation in an optimization context. My question is: what value should my approximation have in each grid cell? I tried the function value at the center of each cell, but I was not able to prove epigraphical convergence. Restrictions: Computationally, I have an oracle which can evaluate $f$ at any given point. In particular, it is not possible to compute the infimum of $f$ on each grid cell. Just evaluate it at a finite number of points. I do not have any information about the discontinuity set, except for the knowledge that the finite partition above exists. Update I posted a proof, which is hopefully correct. Answers providing a simpler proof, or a reference to an existing article which already shows such a result are very welcome, and will receive the bounty.","I have a lower semi-continuous (l.s.c) extended-valued function $f: \mathbb{R}^3 \to \mathbb{R} \cup \{+\infty\}$. I know the following properties: $\operatorname{dom}(f)$ is compact, and we have its bounding box $B$, $f$ is bounded, $f$ is piecewise-continuous - there exists a finite partition  $\operatorname{dom}(f) = \bigcup_{i=1}^m D_i$  such that $f$ is continuous on each $D_i$, and $\operatorname{cl}(D_i) = \operatorname{cl} (\operatorname{int} (D_i))$. For my purposes, I would like to approximate $f$ by partitioning $B$ into a regular grid of $\nu$ points along each axis, and defining my approximation $f_\nu$ to be constant in each grid box. My objective is to obtain convergence of $f_\nu$ to $f$ in some sense. My best-case scenario is having epi-graphical convergence, since I want to use the approximation in an optimization context. My question is: what value should my approximation have in each grid cell? I tried the function value at the center of each cell, but I was not able to prove epigraphical convergence. Restrictions: Computationally, I have an oracle which can evaluate $f$ at any given point. In particular, it is not possible to compute the infimum of $f$ on each grid cell. Just evaluate it at a finite number of points. I do not have any information about the discontinuity set, except for the knowledge that the finite partition above exists. Update I posted a proof, which is hopefully correct. Answers providing a simpler proof, or a reference to an existing article which already shows such a result are very welcome, and will receive the bounty.",,"['functional-analysis', 'optimization', 'approximation']"
71,Can any uncountable dimensional real vector space be made into a Banach space?,Can any uncountable dimensional real vector space be made into a Banach space?,,"On any real vector space $V$ of uncountable dimension , can we always define a norm such that endowed with that norm , $V$ becomes a complete normed linear space ? ( I know it can be done if $V$ is finite dimensional but what if $V$ is infinite dimensional ? The only thing I know is that any infinite dimensional Banach space must be of uncountable dimension  )","On any real vector space $V$ of uncountable dimension , can we always define a norm such that endowed with that norm , $V$ becomes a complete normed linear space ? ( I know it can be done if $V$ is finite dimensional but what if $V$ is infinite dimensional ? The only thing I know is that any infinite dimensional Banach space must be of uncountable dimension  )",,"['functional-analysis', 'vector-spaces']"
72,"Do Electrical Engineering Researchers Usually Know Higher Math? e.g. Measure and Distribution Theory, Functional Analysis","Do Electrical Engineering Researchers Usually Know Higher Math? e.g. Measure and Distribution Theory, Functional Analysis",,"I am an EE undergraduate student, and I recently took two courses in signals and systems. We were exposed to things like the Dirac delta (without mention of distributions ), Fourier series (without mention of convergence or function spaces ), the Laplace and Fourier transforms, and the sampling theorem. I still don't truly understand the sifting property, or why sampling is multiplication with a shifted delta instead of a shifted 1 (which would preserve the value of the signal at that point right?). I'm still not sure how to determine when a signal's Fourier series will converge, when you are allowed to take a Fourier or Laplace transform, or whether the derivations of the transform properties we learned are mathematically justified and rigorous. This led me to self study books like Tolstov's Fourier Series and Richards's Theory of Distributions , which I could not follow due to my non-rigorous math background. The Osgood Stanford lectures were quite helpful, but I still feel quite sad that I do not have a deeper understanding of my math tools. According to my school's EE graduate course catalog, there are a couple of classes covering Hilbert, Banach, and L^p spaces, and linear functionals. Is it possible to cover these topics without a formal mathematical background? Should I begin self learning real and complex analysis to prepare for these topics? Forgive me for this lengthy question. Thanks!","I am an EE undergraduate student, and I recently took two courses in signals and systems. We were exposed to things like the Dirac delta (without mention of distributions ), Fourier series (without mention of convergence or function spaces ), the Laplace and Fourier transforms, and the sampling theorem. I still don't truly understand the sifting property, or why sampling is multiplication with a shifted delta instead of a shifted 1 (which would preserve the value of the signal at that point right?). I'm still not sure how to determine when a signal's Fourier series will converge, when you are allowed to take a Fourier or Laplace transform, or whether the derivations of the transform properties we learned are mathematically justified and rigorous. This led me to self study books like Tolstov's Fourier Series and Richards's Theory of Distributions , which I could not follow due to my non-rigorous math background. The Osgood Stanford lectures were quite helpful, but I still feel quite sad that I do not have a deeper understanding of my math tools. According to my school's EE graduate course catalog, there are a couple of classes covering Hilbert, Banach, and L^p spaces, and linear functionals. Is it possible to cover these topics without a formal mathematical background? Should I begin self learning real and complex analysis to prepare for these topics? Forgive me for this lengthy question. Thanks!",,"['functional-analysis', 'soft-question', 'fourier-analysis', 'distribution-theory', 'advice']"
73,Relationship between functional analysis and differential geometry,Relationship between functional analysis and differential geometry,,I am taking courses on functional analysis (through Coursera.com) and differential geometry (textbook author : O'neil) on my university. I made the following table on my own. Are the similar concepts linear form and 1-form? Also I want to know more relationships deeply. Or any recommendation (book or whatever) (Modified and added) I feel that the weak topology is generated by pulling back in dual space so that we get small open sets. I wonder whether it is the same story as pulling forms back.,I am taking courses on functional analysis (through Coursera.com) and differential geometry (textbook author : O'neil) on my university. I made the following table on my own. Are the similar concepts linear form and 1-form? Also I want to know more relationships deeply. Or any recommendation (book or whatever) (Modified and added) I feel that the weak topology is generated by pulling back in dual space so that we get small open sets. I wonder whether it is the same story as pulling forms back.,,"['functional-analysis', 'differential-geometry']"
74,Dual space of space of all smooth function,Dual space of space of all smooth function,,"On the space $C^\infty(S^1,\mathbb R)$, for each $n\in \mathbb N$, define  $$p_N(\gamma)= \max\{|f^{(k)}(t): t\in S^1, k\leq N\}$$ Topology of all norms above define a metrizable locally convex topology (in fact Frechet space) on this space [Rudin Functional analysis page 35]. How to calculate dual space to this space, For dual space, I mean set of all continuous linear functional on $C^\infty(S^1, M)$ with norms $$p'_M(f)= \sup_{\gamma\in M\subset C^\infty(S^1,\mathbb R)}|f(\gamma)|$$ and $M$ runs through all bounded subsets of $L$. My background and others:  I do not have enough practice and knowledge of functional analysis course.. Hence i will be happy if i get reference reading for this so that i can calculate dual myself. What are the books/topic name which i should read to get comfortable   in calculating these type questions","On the space $C^\infty(S^1,\mathbb R)$, for each $n\in \mathbb N$, define  $$p_N(\gamma)= \max\{|f^{(k)}(t): t\in S^1, k\leq N\}$$ Topology of all norms above define a metrizable locally convex topology (in fact Frechet space) on this space [Rudin Functional analysis page 35]. How to calculate dual space to this space, For dual space, I mean set of all continuous linear functional on $C^\infty(S^1, M)$ with norms $$p'_M(f)= \sup_{\gamma\in M\subset C^\infty(S^1,\mathbb R)}|f(\gamma)|$$ and $M$ runs through all bounded subsets of $L$. My background and others:  I do not have enough practice and knowledge of functional analysis course.. Hence i will be happy if i get reference reading for this so that i can calculate dual myself. What are the books/topic name which i should read to get comfortable   in calculating these type questions",,"['functional-analysis', 'reference-request', 'locally-convex-spaces']"
75,Subspaces of $l_p$ and Banach-Mazur distance,Subspaces of  and Banach-Mazur distance,l_p,"It is well-known that every subspace of $l_2$ is isometric to $l_2$. When $p\neq 2$, $l_p$ has subspaces that are not even isomorphic, let alone isometric, to $l_p$. Suppose $X$ is a subspace of $l_p$ with $p\neq 2$ such that $X$ is isomorphic to $l_p$. What can one say about the Banach-Mazur distance between $X$ and $l_p$? More precisely, which one of the following mutually exclusive options holds true: 1) Given $K$, there exists a subspace $X$ of $l_p$, isomorphic to $l_p$, such that for any isomorphism $T:X\to l_p$ one has $||T||\cdot||T^{-1}||>K$. OR 2) There exist a constant $K$ (possibly depending on $p$), such that for any subspace $X$ of $l_p$, isomorphic to $l_p$, there exist an isomorphism $T:X\to l_p$ such that  $||T||\cdot||T^{-1}||\leq K$. Intuitively, I very strongly suspect it is 1) but I do not have an argument to exclude 2) and, if it is indeed 1), I would like to see a concrete example of a subspace having that property.","It is well-known that every subspace of $l_2$ is isometric to $l_2$. When $p\neq 2$, $l_p$ has subspaces that are not even isomorphic, let alone isometric, to $l_p$. Suppose $X$ is a subspace of $l_p$ with $p\neq 2$ such that $X$ is isomorphic to $l_p$. What can one say about the Banach-Mazur distance between $X$ and $l_p$? More precisely, which one of the following mutually exclusive options holds true: 1) Given $K$, there exists a subspace $X$ of $l_p$, isomorphic to $l_p$, such that for any isomorphism $T:X\to l_p$ one has $||T||\cdot||T^{-1}||>K$. OR 2) There exist a constant $K$ (possibly depending on $p$), such that for any subspace $X$ of $l_p$, isomorphic to $l_p$, there exist an isomorphism $T:X\to l_p$ such that  $||T||\cdot||T^{-1}||\leq K$. Intuitively, I very strongly suspect it is 1) but I do not have an argument to exclude 2) and, if it is indeed 1), I would like to see a concrete example of a subspace having that property.",,"['functional-analysis', 'banach-spaces']"
76,Operators similar to operators with spectral radius 1,Operators similar to operators with spectral radius 1,,"Let $A$ be a linear bounded operator acting on a Banach space $X.$ Assume the spectral radius of $A$ is equal $1.$ Do there exist  invertible operators $U_n:X\to X,$ such that $$\|U_n^{-1}AU_n\|<1+{1\over n},\quad n\ge 1\ ?$$ I can do it for Hilbert space $X$ (see Szwarc, Ryszard; Problems and Solutions: Solutions of Advanced Problems: 6496. Amer. Math. Monthly 94 (1987), no. 2, 197–199). For the Banach space $X,$ I am able to construct a new norm $\|\cdot\|_n$ on $X,$ equivalent to the original norm $\|\cdot \|,$ such that the norm of $A:(X,\|\cdot\|_n)\to (X,\|\cdot\|_n)$ is less than $1+1/n.$ But I am unable to decide whether it can be done by similarity, as described above. I have checked (to be on the safe side) it works for two-dimensional space with norm $\|(z_1,z_2)\|=|z_1|+|z_2|.$ In general, the conclusion is true for any finite-dimensional normed space $X=\mathbb{C}^n,$ once it holds for the euclidean norm. This should follow from Jordan's decomposition of matrices and the fact that any two norms on finite-dimensional space $M_{n\times n}(\mathbb{C})$ are equivalent.","Let be a linear bounded operator acting on a Banach space Assume the spectral radius of is equal Do there exist  invertible operators such that I can do it for Hilbert space (see Szwarc, Ryszard; Problems and Solutions: Solutions of Advanced Problems: 6496. Amer. Math. Monthly 94 (1987), no. 2, 197–199). For the Banach space I am able to construct a new norm on equivalent to the original norm such that the norm of is less than But I am unable to decide whether it can be done by similarity, as described above. I have checked (to be on the safe side) it works for two-dimensional space with norm In general, the conclusion is true for any finite-dimensional normed space once it holds for the euclidean norm. This should follow from Jordan's decomposition of matrices and the fact that any two norms on finite-dimensional space are equivalent.","A X. A 1. U_n:X\to X, \|U_n^{-1}AU_n\|<1+{1\over n},\quad n\ge 1\ ? X X, \|\cdot\|_n X, \|\cdot \|, A:(X,\|\cdot\|_n)\to (X,\|\cdot\|_n) 1+1/n. \|(z_1,z_2)\|=|z_1|+|z_2|. X=\mathbb{C}^n, M_{n\times n}(\mathbb{C})","['functional-analysis', 'operator-theory', 'spectral-radius']"
77,"If a strictly convex function attains a minimum on the unit ball, does it attain a minimum on every weak*-compact set?","If a strictly convex function attains a minimum on the unit ball, does it attain a minimum on every weak*-compact set?",,"Let $X'$ be the topological dual of a normed TVS $X$ , and let $f$ be a real, strictly convex function on $X'$ If $f$ attains a minimum on the closed unit ball of $X'$ , does it attain a minimum on every weak*-compact subset of $X'$ ? Attempt. My guess is that it's not true. Let $X = X' = \mathbb R$ , so that the closed unit ball in $X'$ is $[1,-1]$ . The idea now is to define $f$ so that it's continuous on $[-1,1]$ , and therefore achieves a minimum, but introduce a discontinuity elsewhere so that it doesn't achieve a minimum on some other closed interval. For example, I was thinking something like $f(x) = (x-2)^2$ if $x \in (-\infty,2)$ and $f(x)$ is a linear on $[2,\infty)$ with, say, $f(2)=1$ . Then $f$ doesn't attain a minimum on $[1,2]$ . I'm not sure I can define $f$ in a way that makes it strictly convex, however. (Turns out I can't. See diracdeltafunk's comment below.)","Let be the topological dual of a normed TVS , and let be a real, strictly convex function on If attains a minimum on the closed unit ball of , does it attain a minimum on every weak*-compact subset of ? Attempt. My guess is that it's not true. Let , so that the closed unit ball in is . The idea now is to define so that it's continuous on , and therefore achieves a minimum, but introduce a discontinuity elsewhere so that it doesn't achieve a minimum on some other closed interval. For example, I was thinking something like if and is a linear on with, say, . Then doesn't attain a minimum on . I'm not sure I can define in a way that makes it strictly convex, however. (Turns out I can't. See diracdeltafunk's comment below.)","X' X f X' f X' X' X = X' = \mathbb R X' [1,-1] f [-1,1] f(x) = (x-2)^2 x \in (-\infty,2) f(x) [2,\infty) f(2)=1 f [1,2] f","['functional-analysis', 'convex-analysis', 'convex-optimization', 'topological-vector-spaces']"
78,Is the $p$-norm of the fourier transform of a function greatest when its phase is constant?,Is the -norm of the fourier transform of a function greatest when its phase is constant?,p,"Suppose $f\in L^2$ and define $g\in L^2$ by $g(x) = \lvert f(x)\rvert$ . Based on numerical experiments I believe that $$ \Big\lVert\hat f\Big\rVert_p\leq\Big\lVert\hat g\Big\rVert_p$$ whenever $p\geq 4$ . How can I prove this? I do have a proof in the case when $p=2n$ for $n\in\mathbb Z$ . Then we can write: $$\left\lVert \hat f\right\rVert_p = \left\lVert \hat    f\right\rVert_{2n} = \left\lVert {\hat    f}^n\right\rVert_{2}^{1/n}=\left\lVert f^{*n}\right\rVert_{2}^{1/n}$$ (using the convolution power ) and likewise $\left\lVert \hat    g\right\rVert_p =\left\lVert g^{*n}\right\rVert_{2}^{1/n}$ . Then since we have $$\lvert f^{*n}(x)\rvert=\left\lvert\int_{\sum x_i=x}f(x_0)\dots    f(x_{n-1})\right\rvert\leq\int_{\sum x_i=x}\lvert f(x_0)\rvert\dots    \lvert f(x_{n-1})\rvert=\lvert g^{*n}(x)\rvert$$ for all $x$ , we are done. So I'm interested in the more general case where $p$ is an arbitrary real number (greater than or equal to $4$ ). My numerical experiments were based on the discrete fourier transform. The requirement that $p\geq 4$ comes from the example $f = (1,-1,0)$ . Then $$\left\lVert\hat f\right\rVert_p=\left(\frac{\sqrt{3}^p+\sqrt{3}^p+0^p}3\right)^{1/p}$$ and $$\left\lVert\hat g\right\rVert_p=\left(\frac{2^p+1^p+1^p}3\right)^{1/p}.$$ Thus for this $f$ and $g$ , the inequality $ \Big\lVert\hat f\Big\rVert_p\leq\Big\lVert\hat g\Big\rVert_p$ holds only when $p\leq 2$ or $p\geq 4$ . The motivation for this question is to try to tighten the entropic uncertainty principle in quantum mechanics. The theorem would say that for a given position distribution and $n\geq 2$ , the Rényi entropy $H_n$ of the momentum distribution is minimized by the wavefunction with constant phase. (I do know how to prove that this wavefunction minimizes the variance of the momentum distribution, so it already gives a tightening of Heisenberg's uncertainty principle.)","Suppose and define by . Based on numerical experiments I believe that whenever . How can I prove this? I do have a proof in the case when for . Then we can write: (using the convolution power ) and likewise . Then since we have for all , we are done. So I'm interested in the more general case where is an arbitrary real number (greater than or equal to ). My numerical experiments were based on the discrete fourier transform. The requirement that comes from the example . Then and Thus for this and , the inequality holds only when or . The motivation for this question is to try to tighten the entropic uncertainty principle in quantum mechanics. The theorem would say that for a given position distribution and , the Rényi entropy of the momentum distribution is minimized by the wavefunction with constant phase. (I do know how to prove that this wavefunction minimizes the variance of the momentum distribution, so it already gives a tightening of Heisenberg's uncertainty principle.)","f\in L^2 g\in L^2 g(x) = \lvert f(x)\rvert  \Big\lVert\hat f\Big\rVert_p\leq\Big\lVert\hat g\Big\rVert_p p\geq 4 p=2n n\in\mathbb Z \left\lVert \hat f\right\rVert_p = \left\lVert \hat
   f\right\rVert_{2n} = \left\lVert {\hat
   f}^n\right\rVert_{2}^{1/n}=\left\lVert f^{*n}\right\rVert_{2}^{1/n} \left\lVert \hat
   g\right\rVert_p =\left\lVert g^{*n}\right\rVert_{2}^{1/n} \lvert f^{*n}(x)\rvert=\left\lvert\int_{\sum x_i=x}f(x_0)\dots
   f(x_{n-1})\right\rvert\leq\int_{\sum x_i=x}\lvert f(x_0)\rvert\dots
   \lvert f(x_{n-1})\rvert=\lvert g^{*n}(x)\rvert x p 4 p\geq 4 f = (1,-1,0) \left\lVert\hat f\right\rVert_p=\left(\frac{\sqrt{3}^p+\sqrt{3}^p+0^p}3\right)^{1/p} \left\lVert\hat g\right\rVert_p=\left(\frac{2^p+1^p+1^p}3\right)^{1/p}. f g  \Big\lVert\hat f\Big\rVert_p\leq\Big\lVert\hat g\Big\rVert_p p\leq 2 p\geq 4 n\geq 2 H_n","['functional-analysis', 'fourier-analysis', 'lp-spaces', 'fourier-transform']"
79,Complete reducibility for the Poincaré group,Complete reducibility for the Poincaré group,,"If $(\rho,V)$ is a unitary representation of a group $G$ which is finite dimensional, then complete reducibility is kind of easy to prove. Indeed, if $V$ is not irreducible, then it has one proper invariant subspace $W$. The orthogonal complement of $W$, namely $W^\perp$ is then another proper invariant subspace so that $V$ decomposes as $$V = W\oplus W^\perp,$$ decomposing $\rho$ as $\rho|_W\oplus  \rho|_{W^{\perp}}$. Furthermore, since $V$ is finite dimensional and $W$ is a proper subspace, $\dim W,\dim W^\perp < \dim V$. We can repeat this process with $W,W^\perp$ and so on, until we get irreducible representations, and we are assured this will end because each step lowers the dimension. Now consider the Poincaré group $\mathbb{R}^4\rtimes SL(2,\mathbb{C})$. One looks for unitary representations of this group. It is then one theorem that there are no finite dimensional unitary representations. So they are all infinite dimensional. The procedure above doesn't work. Each step won't lower the dimension. Still, physicists seem to still try to somehow get complete reducibility here. What they do, which is actually quite cryptic really is: let $(U,\mathscr{H})$ be a unitary representation in the Hilbert space $\mathscr{H}$. Consider a pure translation, namely, $U(a,1)$. This is $U(a,1)=e^{-ia^\mu P_\mu}$ for hermitian operators $P_\mu$. Then they ""diagonalize"" these operators with the improper basis $\Psi_{p,\sigma}$ so that $$P_\mu \Psi_{p,\sigma}=p_\mu \Psi_{p,\sigma}.$$ Then one works on this basis, and notices that a pure $SL(2,\mathbb{C})$ transformation, $U(0,\Lambda)$ acting on $\Psi_{p,\sigma}$ is such that $$P_\mu U(0,\Lambda)\Psi_{p,\sigma}=\sum_{\sigma'}C_{\sigma\sigma'}(p,\Lambda)\Psi_{\Lambda p,\sigma'}.$$ From this, Weinberg, e.g., says: In general it may be possible by using suitable linear combinations of the $\Psi_{p,\sigma}$ to choose the $\sigma$ labels in such a way that the matrix $C_{\sigma'\sigma}(\Lambda,p)$ is block-diagonal; in other words, so that the $\Psi_{p,\sigma}$ with $\sigma$ within any one block by themselves furnish a representation of the inhomogeneous Lorentz group. It is natural to identify the states of a specific particle type with the components of a representation of the inhomogeneous Lorentz group which is irreducible, in the sense that it cannot be further decomposed in this way. So it seems that all this procedure I described above is some sort of ""complete reducibility under the hood"". It seems more like ""complete reducibility parametrized by $p$"" actually. But I confess I don't get the point. Actually I've read in this blog post that the matter is actually so subtle so a ""direct integral"" decomposition would be required. So what is going on here? How is complete reducibility actually dealt with for the Poincare group? What is this ""physicists procedure"" Weinberg shows and comments all about?","If $(\rho,V)$ is a unitary representation of a group $G$ which is finite dimensional, then complete reducibility is kind of easy to prove. Indeed, if $V$ is not irreducible, then it has one proper invariant subspace $W$. The orthogonal complement of $W$, namely $W^\perp$ is then another proper invariant subspace so that $V$ decomposes as $$V = W\oplus W^\perp,$$ decomposing $\rho$ as $\rho|_W\oplus  \rho|_{W^{\perp}}$. Furthermore, since $V$ is finite dimensional and $W$ is a proper subspace, $\dim W,\dim W^\perp < \dim V$. We can repeat this process with $W,W^\perp$ and so on, until we get irreducible representations, and we are assured this will end because each step lowers the dimension. Now consider the Poincaré group $\mathbb{R}^4\rtimes SL(2,\mathbb{C})$. One looks for unitary representations of this group. It is then one theorem that there are no finite dimensional unitary representations. So they are all infinite dimensional. The procedure above doesn't work. Each step won't lower the dimension. Still, physicists seem to still try to somehow get complete reducibility here. What they do, which is actually quite cryptic really is: let $(U,\mathscr{H})$ be a unitary representation in the Hilbert space $\mathscr{H}$. Consider a pure translation, namely, $U(a,1)$. This is $U(a,1)=e^{-ia^\mu P_\mu}$ for hermitian operators $P_\mu$. Then they ""diagonalize"" these operators with the improper basis $\Psi_{p,\sigma}$ so that $$P_\mu \Psi_{p,\sigma}=p_\mu \Psi_{p,\sigma}.$$ Then one works on this basis, and notices that a pure $SL(2,\mathbb{C})$ transformation, $U(0,\Lambda)$ acting on $\Psi_{p,\sigma}$ is such that $$P_\mu U(0,\Lambda)\Psi_{p,\sigma}=\sum_{\sigma'}C_{\sigma\sigma'}(p,\Lambda)\Psi_{\Lambda p,\sigma'}.$$ From this, Weinberg, e.g., says: In general it may be possible by using suitable linear combinations of the $\Psi_{p,\sigma}$ to choose the $\sigma$ labels in such a way that the matrix $C_{\sigma'\sigma}(\Lambda,p)$ is block-diagonal; in other words, so that the $\Psi_{p,\sigma}$ with $\sigma$ within any one block by themselves furnish a representation of the inhomogeneous Lorentz group. It is natural to identify the states of a specific particle type with the components of a representation of the inhomogeneous Lorentz group which is irreducible, in the sense that it cannot be further decomposed in this way. So it seems that all this procedure I described above is some sort of ""complete reducibility under the hood"". It seems more like ""complete reducibility parametrized by $p$"" actually. But I confess I don't get the point. Actually I've read in this blog post that the matter is actually so subtle so a ""direct integral"" decomposition would be required. So what is going on here? How is complete reducibility actually dealt with for the Poincare group? What is this ""physicists procedure"" Weinberg shows and comments all about?",,"['group-theory', 'functional-analysis', 'representation-theory', 'lie-groups', 'mathematical-physics']"
80,Green's functions/fundamental solution to a non-constant coefficients pde,Green's functions/fundamental solution to a non-constant coefficients pde,,"We already know the relationship between Green's function and solution to elliptic partial differential equation, i.e $$u(y)=\int_{\partial \Omega}u\frac{\partial G}{\partial n} ds+\int_\Omega G\Delta u dx $$ where $n$ is the unit outward normal , $G$ is Green's function on $\Omega$, and $p=\frac{\partial G}{\partial n}$ is called the Poisson kernel. So now I'm wondering the case if we have a partial differential operator $$Lu(t,x)=\partial_tu(t,x)+\sum_{i,j}^da_{i,j}(t,x)\frac{\partial^2u(t,x)}{\partial x_i\partial x_j}$$  I know that in this case we call $G$ the fundamental solution if $$LG(s,y;t,x)=\delta(s-t)\delta(x-y)$$  Then we can find that $$u(t,x)=\int G(s,y;t,x)Lu(s,y)dsdy$$ without boundary conditions, if my understanding is correct. Are there the similar relationship between fundamental solution and Poisson kernel (if this notion is correct) on the boundary?  In one paper, $$L=\frac{\partial}{\partial t}+\operatorname{div}\big(A(x,t)\nabla_x\big)$$ where $A$ is a $d\times d$  real symmetric matrix, uniformly elliptic on $\Omega=D\times(0,\infty)$. They have the corresponding Poisson kernel $$p(x,t;y,s)=\frac{\partial G}{\partial N(y,s)}(x,t;y,s)$$ where $N(y,s)=A(y,s)n(y)$ with $n(y)$ is the unit inner normal to $\partial D$ at $y$. It confused me for several days. I really want to figure out how it was calculated.","We already know the relationship between Green's function and solution to elliptic partial differential equation, i.e $$u(y)=\int_{\partial \Omega}u\frac{\partial G}{\partial n} ds+\int_\Omega G\Delta u dx $$ where $n$ is the unit outward normal , $G$ is Green's function on $\Omega$, and $p=\frac{\partial G}{\partial n}$ is called the Poisson kernel. So now I'm wondering the case if we have a partial differential operator $$Lu(t,x)=\partial_tu(t,x)+\sum_{i,j}^da_{i,j}(t,x)\frac{\partial^2u(t,x)}{\partial x_i\partial x_j}$$  I know that in this case we call $G$ the fundamental solution if $$LG(s,y;t,x)=\delta(s-t)\delta(x-y)$$  Then we can find that $$u(t,x)=\int G(s,y;t,x)Lu(s,y)dsdy$$ without boundary conditions, if my understanding is correct. Are there the similar relationship between fundamental solution and Poisson kernel (if this notion is correct) on the boundary?  In one paper, $$L=\frac{\partial}{\partial t}+\operatorname{div}\big(A(x,t)\nabla_x\big)$$ where $A$ is a $d\times d$  real symmetric matrix, uniformly elliptic on $\Omega=D\times(0,\infty)$. They have the corresponding Poisson kernel $$p(x,t;y,s)=\frac{\partial G}{\partial N(y,s)}(x,t;y,s)$$ where $N(y,s)=A(y,s)n(y)$ with $n(y)$ is the unit inner normal to $\partial D$ at $y$. It confused me for several days. I really want to figure out how it was calculated.",,"['functional-analysis', 'partial-differential-equations']"
81,Singular linear systems of ODEs,Singular linear systems of ODEs,,"A classical problem in quantum mechanics involving the Dirac Delta function is given by $$ y''+(\delta(x)-\lambda^2)y=0. $$ Then, to find ''bound states'', you solve on the right and find the converging solution as $x\rightarrow \infty$ , then solve on the left similarly. Assume continuity of the solution $y$ . The jump condition on $y'$ is found by integrating from $-\epsilon$ to $\epsilon$ and take $\epsilon\rightarrow 0$ . The only value of $\lambda$ giving a bound state is then found to be $1/2$ . In the literature, there are a lot of results concerning more complicated singular Schrödinger eigenvalue problems. More generally, I am looking at linear systems of ODEs with singular coefficients such as the coefficient in the example given above. The problem given above can simply be thought of as the limit of smooth systems where you would replace the Dirac function by a parameter dependent function, which converges to the Dirac function when the parameter goes to zero. So, one would think that the eigenvector goes to the eigenvector given above as the parameter goes to zero. My question is this: Are there results, known examples, or references in the literature dealing with singular systems which have solutions, eigenvectors, or behaviors, which strictly appear in the singular limit and which are not obtained by taking the limit of smooth systems. In other words, I would like to know if there is something more to those systems involving Dirac functions than being the limit of smooth systems.","A classical problem in quantum mechanics involving the Dirac Delta function is given by Then, to find ''bound states'', you solve on the right and find the converging solution as , then solve on the left similarly. Assume continuity of the solution . The jump condition on is found by integrating from to and take . The only value of giving a bound state is then found to be . In the literature, there are a lot of results concerning more complicated singular Schrödinger eigenvalue problems. More generally, I am looking at linear systems of ODEs with singular coefficients such as the coefficient in the example given above. The problem given above can simply be thought of as the limit of smooth systems where you would replace the Dirac function by a parameter dependent function, which converges to the Dirac function when the parameter goes to zero. So, one would think that the eigenvector goes to the eigenvector given above as the parameter goes to zero. My question is this: Are there results, known examples, or references in the literature dealing with singular systems which have solutions, eigenvectors, or behaviors, which strictly appear in the singular limit and which are not obtained by taking the limit of smooth systems. In other words, I would like to know if there is something more to those systems involving Dirac functions than being the limit of smooth systems.","
y''+(\delta(x)-\lambda^2)y=0.
 x\rightarrow \infty y y' -\epsilon \epsilon \epsilon\rightarrow 0 \lambda 1/2","['functional-analysis', 'ordinary-differential-equations', 'distribution-theory', 'eigenfunctions', 'singularity']"
82,Stable local minimizers of functions on a Banach space,Stable local minimizers of functions on a Banach space,,"Let $X$ be a Banach space and $f:X\rightarrow (-\infty,\infty]$ be a lower semicontinuous function. We are interested in  some conceptions of local minimizer: We say that $\bar{x}\in X$ is a stable strict local minimizer of $f$ if $f(\bar{x})$ is finite and there exists $\varepsilon>0$ such that the mapping $$ 	M:x^*\mapsto\text{argmin}_{\|x-\bar{x}\|\leq\varepsilon}\{f(x)-\langle x^*,x\rangle\} 	$$ from $X^*$ to $X$ is single-valued on some neighborhood of $0$ with $M(0)=\bar{x}$ . We say that $\bar{x}\in X$ is a stable well posed local minimizer of $f$ if $f(\bar{x})$ is finite and there exists $\varepsilon>0$ such that for every vector $x^*\in X^*$ near the origin, there is a point $x_{x^*}$ in $U:=\overline{B}(\bar{x},\varepsilon)$ with $x_0=\bar{x}$ so that in terms of the perturbed functions $f_{x^*}(\cdot):=f(\cdot)-\langle x^*,\cdot\rangle$ we have $$ 	f_{x^*}(x_{x^*})=\inf_{x\in U}f_{x^*}(x) 	$$ and every sequence $(x_n)\subset U$ along which $f_{x^*}(x_n)\rightarrow f_{x^*}(x_{x^*})$ obeys $\|x_n-x_{x^*}\|\rightarrow 0$ . We say that $\bar{x}\in X$ is a stable strong local minimizer of $f$ if $f(\bar{x})$ is finite and there exist $\varepsilon>0$ and $\kappa>0$ such that for every vector $x^*\in X^*$ near the origin, there is a point $x_{x^*}$ in $U:=\overline{B}(\bar{x},\varepsilon)$ with $x_0=\bar{x}$ so that in terms of the perturbed functions $f_{x^*}:=f(\cdot)-\langle x^*,\cdot\rangle$ the inequality $$ 	f_{x^*}(x)\geq f_{x^*}(x_{x^*})+\kappa\|x-x_{x^*}\|^2 	$$ holds for every $x\in U$ . A point $\bar{x}\in X$ is called a stable Lipschitz local minimizer of the function $f$ if $f(\bar{x})$ is finite and there exists $\varepsilon>0$ such that the mapping $$ 	M:x^*\mapsto\text{argmin}_{\|x-\bar{x}\|\leq\varepsilon}\{f(x)-\langle x^*,x\rangle\} 	$$ is single-valued and Lipschitz continuous on some neighborhood of $0$ with $M(0)=\bar{x}$ . We have observed that: stable strong local minimizer $\Rightarrow$ stable well posed local minimizer $\Rightarrow$ stable strict local minimizer. stable strong local minimizer $\Rightarrow$ stable Lipschitz local minimizer $\Rightarrow$ stable strict local minimizer. When $X$ is finite dimensional,  stable strict local minimizer $\Leftrightarrow$ stable well posed local minimizer. When $X$ is finite dimensional,  stable strong local minimizer $\Leftrightarrow$ stable Lipschitz local minimizer. We would like to construct: a stable well posed local minimizer of $f$ which is not a stable strong local minimizer of $f$ a stable strict local minimizer of $f$ which is not a stable well posed local minimizer of $f$ a stable Lipschitz local minimizer of $f$ which is not a stable strong local minimizer of $f$ a stable Lipschitz local minimizer of $f$ which is not a stable well posed local minimizer of $f$ a stable well posed local minimizer of $f$ which is not a stable Lipschitz local minimizer of $f$ Thank you for all kind help and comments.","Let be a Banach space and be a lower semicontinuous function. We are interested in  some conceptions of local minimizer: We say that is a stable strict local minimizer of if is finite and there exists such that the mapping from to is single-valued on some neighborhood of with . We say that is a stable well posed local minimizer of if is finite and there exists such that for every vector near the origin, there is a point in with so that in terms of the perturbed functions we have and every sequence along which obeys . We say that is a stable strong local minimizer of if is finite and there exist and such that for every vector near the origin, there is a point in with so that in terms of the perturbed functions the inequality holds for every . A point is called a stable Lipschitz local minimizer of the function if is finite and there exists such that the mapping is single-valued and Lipschitz continuous on some neighborhood of with . We have observed that: stable strong local minimizer stable well posed local minimizer stable strict local minimizer. stable strong local minimizer stable Lipschitz local minimizer stable strict local minimizer. When is finite dimensional,  stable strict local minimizer stable well posed local minimizer. When is finite dimensional,  stable strong local minimizer stable Lipschitz local minimizer. We would like to construct: a stable well posed local minimizer of which is not a stable strong local minimizer of a stable strict local minimizer of which is not a stable well posed local minimizer of a stable Lipschitz local minimizer of which is not a stable strong local minimizer of a stable Lipschitz local minimizer of which is not a stable well posed local minimizer of a stable well posed local minimizer of which is not a stable Lipschitz local minimizer of Thank you for all kind help and comments.","X f:X\rightarrow (-\infty,\infty] \bar{x}\in X f f(\bar{x}) \varepsilon>0 
	M:x^*\mapsto\text{argmin}_{\|x-\bar{x}\|\leq\varepsilon}\{f(x)-\langle x^*,x\rangle\}
	 X^* X 0 M(0)=\bar{x} \bar{x}\in X f f(\bar{x}) \varepsilon>0 x^*\in X^* x_{x^*} U:=\overline{B}(\bar{x},\varepsilon) x_0=\bar{x} f_{x^*}(\cdot):=f(\cdot)-\langle x^*,\cdot\rangle 
	f_{x^*}(x_{x^*})=\inf_{x\in U}f_{x^*}(x)
	 (x_n)\subset U f_{x^*}(x_n)\rightarrow f_{x^*}(x_{x^*}) \|x_n-x_{x^*}\|\rightarrow 0 \bar{x}\in X f f(\bar{x}) \varepsilon>0 \kappa>0 x^*\in X^* x_{x^*} U:=\overline{B}(\bar{x},\varepsilon) x_0=\bar{x} f_{x^*}:=f(\cdot)-\langle x^*,\cdot\rangle 
	f_{x^*}(x)\geq f_{x^*}(x_{x^*})+\kappa\|x-x_{x^*}\|^2
	 x\in U \bar{x}\in X f f(\bar{x}) \varepsilon>0 
	M:x^*\mapsto\text{argmin}_{\|x-\bar{x}\|\leq\varepsilon}\{f(x)-\langle x^*,x\rangle\}
	 0 M(0)=\bar{x} \Rightarrow \Rightarrow \Rightarrow \Rightarrow X \Leftrightarrow X \Leftrightarrow f f f f f f f f f f","['functional-analysis', 'optimization', 'banach-spaces', 'lipschitz-functions']"
83,"The sum of eigenvalues of integral operator $S(f)(x)=\int_{\mathcal{X}} k(x,y)f(y)d\mu(y)$ is given by $\int_{\mathcal{X}} k(x,x) d\mu(x)$?",The sum of eigenvalues of integral operator  is given by ?,"S(f)(x)=\int_{\mathcal{X}} k(x,y)f(y)d\mu(y) \int_{\mathcal{X}} k(x,x) d\mu(x)","Setup: Let $(\mathcal{X},d_{\mathcal{X}})$ and $(\mathcal{Y},d_{\mathcal{Y}})$ be two separable metric spaces. Let $M^1(\mathcal{X})$ be the space of Borel probability measures on $\mathcal{X}$ with finite first moment, i.e. a Borel probability measure $\mu$ on $\mathcal{X}$ is in $M^1(\mathcal{X})$ if $\int d_{\mathcal{X}}(x,o) d\mu(x)<\infty$ for any $o\in\mathcal{X}$ . The space $M^1(\mathcal{Y})$ is defined in similar fashion. Fix $\mu\in M^1(\mathcal{X})$ and $\nu\in M^1(\mathcal{Y})$ and define $$ d_\mu(x_1,x_2)= d_{\mathcal{X}}(x_1,x_2) -\int d_{\mathcal{X}}(x_1,x)\,  d\mu(x) - \int d_{\mathcal{X}}(x_2,x)\,  d\mu(x) + \int  d_{\mathcal{X}}(x,x')\,  d\mu^2(x,x'), $$ and a similar definition of $d_\nu:\mathcal{Y}\times \mathcal{Y}\to\mathbb{R}$ . Now let $S:L^2(\mathcal{X}\times \mathcal{Y},\mathcal{B}(\mathcal{X})\otimes \mathcal{B}(\mathcal{Y}),\mu\times \nu) \to L^2(\mathcal{X}\times \mathcal{Y},\mathcal{B}(\mathcal{X})\otimes \mathcal{B}(\mathcal{Y}),\mu\times \nu),$ be a Hilbert-Schmidt operator given by $$ S(f)(x,y) = \int d_\mu(x,x')d_\nu(y,y') f(x',y') d\mu\times \nu(x',y'). $$ and let $\{\lambda_i\}_{i\geq 1}$ denote the non-zero eigenvalues of $S$ repeated according to multiplicity. Question: How do I prove the following identity: $$\sum_{i=1}^\infty\lambda_i=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y).$$ I tried but failed to show that $S$ is of trace class, since they under certain conditions (which I also can't verify in this setup) satisfy that $$ Trace(S)=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y), $$ which yields the result since $Trace(S)=\sum_{i=1}^\infty\lambda_i$ (if it were of trace class). The identity $\sum_{i=1}^\infty\lambda_i=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y)$ is stated in Distance covariance in metric spaces by Russell Lyons (2013) Theorem 2.7 , without proof, so my approach with traces is only an idea. If another way of proving the identity appears or if there is a counterexample, that would more than satisfy my needs. In the case of a counterexample i would very much appreciate stronger initial conditions rendering the identity true. Please bear in mind that i am a novice in the theory of operators and trace class operators (only went down this road to explain the equality above), so references would be much appriciated. Update: A counterexample to the operator being of trace-class is presented by Russell Lyons in the errata to the mentioned paper. Furthermore a proof that the formula holds and that the operator is of traceclass, whenever the marginal spaces posses additional nice proporties (isometric embeddability into hilbert spaces), is also presented in this errata.","Setup: Let and be two separable metric spaces. Let be the space of Borel probability measures on with finite first moment, i.e. a Borel probability measure on is in if for any . The space is defined in similar fashion. Fix and and define and a similar definition of . Now let be a Hilbert-Schmidt operator given by and let denote the non-zero eigenvalues of repeated according to multiplicity. Question: How do I prove the following identity: I tried but failed to show that is of trace class, since they under certain conditions (which I also can't verify in this setup) satisfy that which yields the result since (if it were of trace class). The identity is stated in Distance covariance in metric spaces by Russell Lyons (2013) Theorem 2.7 , without proof, so my approach with traces is only an idea. If another way of proving the identity appears or if there is a counterexample, that would more than satisfy my needs. In the case of a counterexample i would very much appreciate stronger initial conditions rendering the identity true. Please bear in mind that i am a novice in the theory of operators and trace class operators (only went down this road to explain the equality above), so references would be much appriciated. Update: A counterexample to the operator being of trace-class is presented by Russell Lyons in the errata to the mentioned paper. Furthermore a proof that the formula holds and that the operator is of traceclass, whenever the marginal spaces posses additional nice proporties (isometric embeddability into hilbert spaces), is also presented in this errata.","(\mathcal{X},d_{\mathcal{X}}) (\mathcal{Y},d_{\mathcal{Y}}) M^1(\mathcal{X}) \mathcal{X} \mu \mathcal{X} M^1(\mathcal{X}) \int d_{\mathcal{X}}(x,o) d\mu(x)<\infty o\in\mathcal{X} M^1(\mathcal{Y}) \mu\in M^1(\mathcal{X}) \nu\in M^1(\mathcal{Y}) 
d_\mu(x_1,x_2)= d_{\mathcal{X}}(x_1,x_2) -\int d_{\mathcal{X}}(x_1,x)\,  d\mu(x) - \int d_{\mathcal{X}}(x_2,x)\,  d\mu(x) + \int  d_{\mathcal{X}}(x,x')\,  d\mu^2(x,x'),
 d_\nu:\mathcal{Y}\times \mathcal{Y}\to\mathbb{R} S:L^2(\mathcal{X}\times \mathcal{Y},\mathcal{B}(\mathcal{X})\otimes \mathcal{B}(\mathcal{Y}),\mu\times \nu) \to L^2(\mathcal{X}\times \mathcal{Y},\mathcal{B}(\mathcal{X})\otimes \mathcal{B}(\mathcal{Y}),\mu\times \nu), 
S(f)(x,y) = \int d_\mu(x,x')d_\nu(y,y') f(x',y') d\mu\times \nu(x',y').
 \{\lambda_i\}_{i\geq 1} S \sum_{i=1}^\infty\lambda_i=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y). S 
Trace(S)=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y),
 Trace(S)=\sum_{i=1}^\infty\lambda_i \sum_{i=1}^\infty\lambda_i=\int d_\mu(x,x)d_\nu(y,y) \, d\mu\times \nu(x,y)","['functional-analysis', 'statistics', 'operator-theory', 'spectral-theory', 'trace']"
84,Correct spaces for quantum mechanics,Correct spaces for quantum mechanics,,"The general formulation of quantum mechanics is done by describing quantum mechanical states by vectors $|\psi_t(x)\rangle$ in some Hilbert space $\mathcal{H}$ and describes their time evolution by the Schrödinger equation $$i\hbar\frac{\partial}{\partial t}|\psi_t\rangle = H|\psi_t\rangle$$ where $H$ is the Hamilton operator (for the free particle we have $H=-\frac{\hbar^2}{2m}\Delta$). Now I have often seen used spaces like $\mathcal{H}=L^2(\mathbb{R}^3)$ (in the case of a single particle), but I was wondering whether this is correct or not.  In fact shouldn't we require to be able to derivate $\left|\psi_t\right>$ twice in $x$ and thus choose something like $\mathcal{H} = H^2(\mathbb{R}^3)$? If we treat directly $\psi(t,x) := \psi_t(x)$, shouldn't we require them to be in something like $H^1(\mathbb{R};H^2(\mathbb{R}^3))$? i.e., functions in $H^1(\mathbb{R})$ with values in $H^2(\mathbb{R}^3)$, e.g. the function $t\mapsto\psi_t$.","The general formulation of quantum mechanics is done by describing quantum mechanical states by vectors $|\psi_t(x)\rangle$ in some Hilbert space $\mathcal{H}$ and describes their time evolution by the Schrödinger equation $$i\hbar\frac{\partial}{\partial t}|\psi_t\rangle = H|\psi_t\rangle$$ where $H$ is the Hamilton operator (for the free particle we have $H=-\frac{\hbar^2}{2m}\Delta$). Now I have often seen used spaces like $\mathcal{H}=L^2(\mathbb{R}^3)$ (in the case of a single particle), but I was wondering whether this is correct or not.  In fact shouldn't we require to be able to derivate $\left|\psi_t\right>$ twice in $x$ and thus choose something like $\mathcal{H} = H^2(\mathbb{R}^3)$? If we treat directly $\psi(t,x) := \psi_t(x)$, shouldn't we require them to be in something like $H^1(\mathbb{R};H^2(\mathbb{R}^3))$? i.e., functions in $H^1(\mathbb{R})$ with values in $H^2(\mathbb{R}^3)$, e.g. the function $t\mapsto\psi_t$.",,"['functional-analysis', 'partial-differential-equations', 'hilbert-spaces', 'mathematical-physics', 'quantum-mechanics']"
85,Elliptic regularity on the Hypercube,Elliptic regularity on the Hypercube,,"Assume $$ Lu=f\quad \text{in } [0,1]^d\\ u=0 \quad\text{ on } \partial[0,1]^d $$ for some strongly-elliptic operator $L$, and $f\in H^k$$, k\geq -1$. Do we have $u\in H^{k+2}$? I can only find the result for smooth domains. I am pretty sure the answer is yes, for the Laplacian I can derive it myself. However, all proofs for general $L$ rely on ""flattening the boundary"", i.e. a $C^{k+2}$ boundary.","Assume $$ Lu=f\quad \text{in } [0,1]^d\\ u=0 \quad\text{ on } \partial[0,1]^d $$ for some strongly-elliptic operator $L$, and $f\in H^k$$, k\geq -1$. Do we have $u\in H^{k+2}$? I can only find the result for smooth domains. I am pretty sure the answer is yes, for the Laplacian I can derive it myself. However, all proofs for general $L$ rely on ""flattening the boundary"", i.e. a $C^{k+2}$ boundary.",,"['functional-analysis', 'reference-request', 'partial-differential-equations', 'elliptic-equations']"
86,A nilpotent element of an algebra which does not lie in the span of commutator elements.,A nilpotent element of an algebra which does not lie in the span of commutator elements.,,"What is  an example of a  C $^{*}$ algebra such that the span of  nilpotent elements is not a sub vector space of the span of commutator elements? Obviously any such C $^{*}$ algebra would be  a  counter example to the question $2$ of the following  MO post: https://mathoverflow.net/questions/231328/the-saturation-of-murray-von-neumann-relation I know that every stable C $^{*}$ algebra or every properly infinite C $^{*}$ algebra can be generated by nilpotent elements. But it seems that such algebras do not admit ""nice"" trace. However for my purpose an algebraic trace (a linear tracial functional which vanishes on commutators, not necessarily positive or bounded) is sufficient.","What is  an example of a  C algebra such that the span of  nilpotent elements is not a sub vector space of the span of commutator elements? Obviously any such C algebra would be  a  counter example to the question of the following  MO post: https://mathoverflow.net/questions/231328/the-saturation-of-murray-von-neumann-relation I know that every stable C algebra or every properly infinite C algebra can be generated by nilpotent elements. But it seems that such algebras do not admit ""nice"" trace. However for my purpose an algebraic trace (a linear tracial functional which vanishes on commutators, not necessarily positive or bounded) is sufficient.",^{*} ^{*} 2 ^{*} ^{*},"['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras', 'noncommutative-geometry']"
87,"$W^{1,p}$ is separable for $1\leq p<\infty$",is separable for,"W^{1,p} 1\leq p<\infty","I've been asked to prove that the Sobolev spaces $W^{1,p}(\Omega)$, $\Omega$ open in $\mathbb R^n$, are separable for $1\leq p <\infty$ using the map $$i\colon W^{1,p}(\Omega)\to L^p(\Omega)\times L^p(\Omega)^n \quad u\mapsto (u,\nabla u).$$ I've done something and I would like to know if it is correct. $W^{1,p}(\Omega)$ is endow with the norm $||u||_{W^{1,p}}:=||u||_{L^p}+||\nabla u||_{{(L^p)}^n}$. Now, I guess that $L^p(\Omega)\times L^p(\Omega)^n$ is endowed with the same norm as $W^{1,p}(\Omega)$ (right?), that makes $L^p(\Omega)\times L^p(\Omega)^n$ a Banach space. With this norm, $i$ is a linear isometry. Moreover $L^p(\Omega)\times L^p(\Omega)^n$, with the norm above, is a separable metric space. In particular $i(W^{1,p}(\Omega))$ is separable, that is, there exists a countable subset $S\subset L^p(\Omega)\times L^p(\Omega)^n$ which is dense in $i(W^{1,p}(\Omega))$. Since $i$ is an isometry, we have that $i^{-1}(S)$ is a countable dense subset of $W^{1,p}(\Omega).$ Is it correct?","I've been asked to prove that the Sobolev spaces $W^{1,p}(\Omega)$, $\Omega$ open in $\mathbb R^n$, are separable for $1\leq p <\infty$ using the map $$i\colon W^{1,p}(\Omega)\to L^p(\Omega)\times L^p(\Omega)^n \quad u\mapsto (u,\nabla u).$$ I've done something and I would like to know if it is correct. $W^{1,p}(\Omega)$ is endow with the norm $||u||_{W^{1,p}}:=||u||_{L^p}+||\nabla u||_{{(L^p)}^n}$. Now, I guess that $L^p(\Omega)\times L^p(\Omega)^n$ is endowed with the same norm as $W^{1,p}(\Omega)$ (right?), that makes $L^p(\Omega)\times L^p(\Omega)^n$ a Banach space. With this norm, $i$ is a linear isometry. Moreover $L^p(\Omega)\times L^p(\Omega)^n$, with the norm above, is a separable metric space. In particular $i(W^{1,p}(\Omega))$ is separable, that is, there exists a countable subset $S\subset L^p(\Omega)\times L^p(\Omega)^n$ which is dense in $i(W^{1,p}(\Omega))$. Since $i$ is an isometry, we have that $i^{-1}(S)$ is a countable dense subset of $W^{1,p}(\Omega).$ Is it correct?",,"['functional-analysis', 'metric-spaces', 'solution-verification', 'sobolev-spaces', 'topological-vector-spaces']"
88,Composition of function with linear functional is Lipschitz implies function itself is Lipschitz,Composition of function with linear functional is Lipschitz implies function itself is Lipschitz,,"This is taken from Conway's A course in functional Analysis (p. 98, Exercise 9): If $(S,d)$ is a metric space and $X$ is a normed space, show that if $f:S\rightarrow X$ is a function such that for all $L\in X^*$ (the continuous dual of $X$) $L\circ f:S\rightarrow\mathbb C$ is Lipschitz, then so is $f$. I tried deriving the claim using the Uniform Boundedness Principle but it seems the wrong tool, for to apply it I somehow need to be looking at a Banach space and bounded operators from it. The natural choice seems to consider $X^*$ and $A_s\in\mathcal B(X^*,\mathbb C)$ given by $A_s(L)=L(f(s))$ for any $s\in S$, but both the fact that the Lipschitz constants can depend on $L$ and no obvious way of relating a bound on $||A_s||$ to $|f|$ make me a little bit puzzled. Any pointer would be greatly appreciated, thanks!","This is taken from Conway's A course in functional Analysis (p. 98, Exercise 9): If $(S,d)$ is a metric space and $X$ is a normed space, show that if $f:S\rightarrow X$ is a function such that for all $L\in X^*$ (the continuous dual of $X$) $L\circ f:S\rightarrow\mathbb C$ is Lipschitz, then so is $f$. I tried deriving the claim using the Uniform Boundedness Principle but it seems the wrong tool, for to apply it I somehow need to be looking at a Banach space and bounded operators from it. The natural choice seems to consider $X^*$ and $A_s\in\mathcal B(X^*,\mathbb C)$ given by $A_s(L)=L(f(s))$ for any $s\in S$, but both the fact that the Lipschitz constants can depend on $L$ and no obvious way of relating a bound on $||A_s||$ to $|f|$ make me a little bit puzzled. Any pointer would be greatly appreciated, thanks!",,['functional-analysis']
89,Is there any difference between Bounded and Totally bounded?,Is there any difference between Bounded and Totally bounded?,,Is there any difference between bounded and totally bounded? (in a metric space),Is there any difference between bounded and totally bounded? (in a metric space),,"['functional-analysis', 'metric-spaces']"
90,Bounded operator that does not attain its norm,Bounded operator that does not attain its norm,,"What is a bounded operator on a Hilbert space that does not attain its norm? An example in $L^2$ or $l^2$ would be preferred. All of the simple examples I have looked at (the identity operator, the shift operator) attain their respective norms.","What is a bounded operator on a Hilbert space that does not attain its norm? An example in $L^2$ or $l^2$ would be preferred. All of the simple examples I have looked at (the identity operator, the shift operator) attain their respective norms.",,"['functional-analysis', 'hilbert-spaces', 'operator-theory']"
91,"how to show that $C[0,1]$ is not a Hilbert space with respect to any inner product",how to show that  is not a Hilbert space with respect to any inner product,"C[0,1]","Show that the space $C[0, 1]$ of real-valued continuous functions on the unit interval $[0, 1]$ with the sup norm $$ \|f\|=\sup\{|f(x)|:\ x\in[0,1]\} $$ is not a Hilbert space  with respect to any  inner  product . My attempts:  as I have to find a Cauchy sequence  $(f_n)_n$ which converges to a function $f$ which is not continuous, but I can't construct such a sequence $(f_n)_n$.","Show that the space $C[0, 1]$ of real-valued continuous functions on the unit interval $[0, 1]$ with the sup norm $$ \|f\|=\sup\{|f(x)|:\ x\in[0,1]\} $$ is not a Hilbert space  with respect to any  inner  product . My attempts:  as I have to find a Cauchy sequence  $(f_n)_n$ which converges to a function $f$ which is not continuous, but I can't construct such a sequence $(f_n)_n$.",,[]
92,Unbounded operator whose spectrum is the entire complex plane?,Unbounded operator whose spectrum is the entire complex plane?,,"The question is simple: how to find an unbounded operator $T:H\to H$ where $H$ is a Hilbert space such that $\text{Sp} T = \mathbb C$ ? This seems a very basic thing, but I have not found an example in the literature. In some proofs, we need to consider this case separately. This example should be quite important.","The question is simple: how to find an unbounded operator where is a Hilbert space such that ? This seems a very basic thing, but I have not found an example in the literature. In some proofs, we need to consider this case separately. This example should be quite important.",T:H\to H H \text{Sp} T = \mathbb C,"['functional-analysis', 'spectral-theory']"
93,Hölder norm of the Hilbert Transform,Hölder norm of the Hilbert Transform,,"Let $\mathcal{H}$ the Hilbert transform defined by $$\mathcal{H}f(x)= p.v.\int_{-\infty}^{+\infty}\frac{f(x-y)}{y}dy.$$ We know that, for each $1<p<\infty$ , it is true that $$||\mathcal{H}f||_{L^p}\leq C_p||f||_{L^p}$$ for some positive constant depending only of $p$ . My question is: Consider $0<\alpha<1$ and $||f||_{C^{\alpha}}$ is the $\alpha^{th}$ -Holder norm, e.g, $$||f||_{C^{\alpha}(\Omega)}=\sup_{x\neq y\in\Omega}\frac{|f(x)-f(y)|}{|x-y|^{\alpha}}.$$ Is it true that $$||\mathcal{H}{f}||_{C^{\alpha}}\leq C||f||_{C^{\alpha}}?$$ Edit: I will accept answer of the David as correct. To the other readers, I ask you to read all the answers and comments to understand such a choice.","Let the Hilbert transform defined by We know that, for each , it is true that for some positive constant depending only of . My question is: Consider and is the -Holder norm, e.g, Is it true that Edit: I will accept answer of the David as correct. To the other readers, I ask you to read all the answers and comments to understand such a choice.",\mathcal{H} \mathcal{H}f(x)= p.v.\int_{-\infty}^{+\infty}\frac{f(x-y)}{y}dy. 1<p<\infty ||\mathcal{H}f||_{L^p}\leq C_p||f||_{L^p} p 0<\alpha<1 ||f||_{C^{\alpha}} \alpha^{th} ||f||_{C^{\alpha}(\Omega)}=\sup_{x\neq y\in\Omega}\frac{|f(x)-f(y)|}{|x-y|^{\alpha}}. ||\mathcal{H}{f}||_{C^{\alpha}}\leq C||f||_{C^{\alpha}}?,"['functional-analysis', 'harmonic-analysis']"
94,"Finding the norm of the shift operator on $l^\infty$, $(x_1,x_2, \dots)\mapsto (x_2,x_3,\dots)$","Finding the norm of the shift operator on ,","l^\infty (x_1,x_2, \dots)\mapsto (x_2,x_3,\dots)","Let $T:l^\infty\rightarrow l^\infty$ be defined by $(x_1,x_2, \dots)\mapsto (x_2,x_3,\dots)$. I have seen a claim without justification that $\|T\|=1$, but I am not convinced. I know that $\|T\| = \sup_{{\|x\|=1}}\|Tx\|$  . If $\|x\|=1$ then surely $\|Tx\|\le 1$. So $$\|T\| = \sup\limits_{\|x\|=1}\|Tx\|\le 1.$$ I don't see how it can be claimed that $\|T\| = 1$ Is it true or I am missing something?","Let $T:l^\infty\rightarrow l^\infty$ be defined by $(x_1,x_2, \dots)\mapsto (x_2,x_3,\dots)$. I have seen a claim without justification that $\|T\|=1$, but I am not convinced. I know that $\|T\| = \sup_{{\|x\|=1}}\|Tx\|$  . If $\|x\|=1$ then surely $\|Tx\|\le 1$. So $$\|T\| = \sup\limits_{\|x\|=1}\|Tx\|\le 1.$$ I don't see how it can be claimed that $\|T\| = 1$ Is it true or I am missing something?",,"['functional-analysis', 'linear-transformations', 'normed-spaces', 'lp-spaces', 'supremum-and-infimum']"
95,Applications of the open mapping theorem for Banach spaces?,Applications of the open mapping theorem for Banach spaces?,,"Does anybody know of any common/standard/famous practical applications of the open mapping theorem for Banach spaces? Textbooks describe the theorem as a ""cornerstone of functional analysis"", and yet I have never come across a practical problem that is solved using it. I do know that the open mapping theorem implies the inverse mapping theorem and the closed graph theorem. I would imagine the closed graph theorem to be of more direct applicability than the open mapping theorem itself. For instance, the closed graph theorem tells you that, in order to prove that a map $f : X \to Y$ between Banach spaces is continuous, you only have to prove that if $\lim_{n \to \infty}x_n = x$ and $\lim_{n \to \infty} f(x_n) = y$, then $y = f(x)$, i.e. it is okay to assume that the limit $\lim_{n \to \infty} f(x_n)$ exists. Still, it bothers me that I have never seen this technique applied to a concrete example that anyone cares about!","Does anybody know of any common/standard/famous practical applications of the open mapping theorem for Banach spaces? Textbooks describe the theorem as a ""cornerstone of functional analysis"", and yet I have never come across a practical problem that is solved using it. I do know that the open mapping theorem implies the inverse mapping theorem and the closed graph theorem. I would imagine the closed graph theorem to be of more direct applicability than the open mapping theorem itself. For instance, the closed graph theorem tells you that, in order to prove that a map $f : X \to Y$ between Banach spaces is continuous, you only have to prove that if $\lim_{n \to \infty}x_n = x$ and $\lim_{n \to \infty} f(x_n) = y$, then $y = f(x)$, i.e. it is okay to assume that the limit $\lim_{n \to \infty} f(x_n)$ exists. Still, it bothers me that I have never seen this technique applied to a concrete example that anyone cares about!",,['functional-analysis']
96,Proof that Legendre Polynomials are Complete,Proof that Legendre Polynomials are Complete,,"Can somebody either point me to, or show me a proof, that the Legendre polynomials , or any set of eigenfunctions, are complete?","Can somebody either point me to, or show me a proof, that the Legendre polynomials , or any set of eigenfunctions, are complete?",,"['functional-analysis', 'polynomials']"
97,How to show that $p-$Laplacian operator is monotone?,How to show that Laplacian operator is monotone?,p-,"Define  $$\langle -\Delta_p u, v \rangle_{(W^{1,p})', W^{1,p}} = \int_{\Omega}|\nabla u |^{p-2}\nabla u \nabla v.$$ How do I show that this operator is monotone? I get $$\langle-\Delta_p u_1 - \Delta_p u_2, u_1-u_2\rangle = \int(\nabla u_1 - \nabla u_2)(|\nabla u_1|^{p-2}\nabla u_1 - |\nabla u_2|^{p-2}\nabla u_2) $$ Now adding and subtracting $|\nabla u_1|^{p-2}\nabla u_2$ in the brackets still doesn't help with one of the terms.. (Recall an operator is monotone if $\langle Tx - Ty, x-y\rangle \geq 0.$)","Define  $$\langle -\Delta_p u, v \rangle_{(W^{1,p})', W^{1,p}} = \int_{\Omega}|\nabla u |^{p-2}\nabla u \nabla v.$$ How do I show that this operator is monotone? I get $$\langle-\Delta_p u_1 - \Delta_p u_2, u_1-u_2\rangle = \int(\nabla u_1 - \nabla u_2)(|\nabla u_1|^{p-2}\nabla u_1 - |\nabla u_2|^{p-2}\nabla u_2) $$ Now adding and subtracting $|\nabla u_1|^{p-2}\nabla u_2$ in the brackets still doesn't help with one of the terms.. (Recall an operator is monotone if $\langle Tx - Ty, x-y\rangle \geq 0.$)",,"['functional-analysis', 'sobolev-spaces', 'monotone-operator-theory']"
98,"$TT^*=T^2$, show that $T$ is self-adjoint",", show that  is self-adjoint",TT^*=T^2 T,"Let $V$ be an inner product space, finitely generated over $\mathbb{C}$, $T\in \operatorname{End}(V)$ that satisfies $TT^*=T^2$, show that $T$ is self-adjoint. I know that $TT^*$ is positive so has positive square-root, thus the square root is positive definite. But I don't feel like this is a proof. Can anyone prove it without considering square root?","Let $V$ be an inner product space, finitely generated over $\mathbb{C}$, $T\in \operatorname{End}(V)$ that satisfies $TT^*=T^2$, show that $T$ is self-adjoint. I know that $TT^*$ is positive so has positive square-root, thus the square root is positive definite. But I don't feel like this is a proof. Can anyone prove it without considering square root?",,['functional-analysis']
99,Video lectures on Functional Analysis,Video lectures on Functional Analysis,,I am looking for excellent VIDEO lectures on functional analysis. They should be (1) in English (2) the video quality and voice is good (3) the lecture should not be presented in boring style I am very thankful for your suggestions,I am looking for excellent VIDEO lectures on functional analysis. They should be (1) in English (2) the video quality and voice is good (3) the lecture should not be presented in boring style I am very thankful for your suggestions,,['functional-analysis']
