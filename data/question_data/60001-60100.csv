,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What is that curve that appears when I use $\ln$ on Pascal's triangle?,What is that curve that appears when I use  on Pascal's triangle?,\ln,"I made a little program that generates Pascal triangles as images : I first tried it associating to each pixel a color whose intensity was proportional to the number in the Pascal triangle The colors being 0-255, i used the following function to convert value to colors: $$f(x)=\frac{x-m}{M-m}255$$ where $x$ is the value in the Pascal triangle, $M$ is the max value in the triangle, and $m$ in the min value in the triangle.  : size 50*50 : The axis are like in this picture : However, as you can see, most of the picture is black due to the numbers being really distant (great distance between highs and lows) Therefore, i thought it would be good to use a logarithmic scale : $$f(x)=\frac{\ln(1+x-m)}{\ln(1+M-m)}255$$ Which gives me : size 50*50 : That's way better. Yet, something was bugging me : as I increased the number of rows, I noticed that some curve was being drawn : size 50*50 : size 100*100 : size 150*150 : I can't try really high numbers, as my computer isn't good enough, nor is the software I use. Is there something behind that 'curve' ? If so, what curve would it be ? Could someone provide explanation why I get such results ? Thank you. Progress We're looking at the level curves of $\ln\binom{N-y}{x},N\in\mathbb{N}^*$ By Stirling, as @TedShifrin remarked,  $\ln(n!)\sim n\ln(n)$ therefore $\ln\binom{N-y}{x}\sim y\ln(N-y)-x\ln(x)-(N-y-x)\ln(N-y-x)$ and seem to give us nice curves (cf his answer). Is there an equation y=f(x) for those curves ?","I made a little program that generates Pascal triangles as images : I first tried it associating to each pixel a color whose intensity was proportional to the number in the Pascal triangle The colors being 0-255, i used the following function to convert value to colors: $$f(x)=\frac{x-m}{M-m}255$$ where $x$ is the value in the Pascal triangle, $M$ is the max value in the triangle, and $m$ in the min value in the triangle.  : size 50*50 : The axis are like in this picture : However, as you can see, most of the picture is black due to the numbers being really distant (great distance between highs and lows) Therefore, i thought it would be good to use a logarithmic scale : $$f(x)=\frac{\ln(1+x-m)}{\ln(1+M-m)}255$$ Which gives me : size 50*50 : That's way better. Yet, something was bugging me : as I increased the number of rows, I noticed that some curve was being drawn : size 50*50 : size 100*100 : size 150*150 : I can't try really high numbers, as my computer isn't good enough, nor is the software I use. Is there something behind that 'curve' ? If so, what curve would it be ? Could someone provide explanation why I get such results ? Thank you. Progress We're looking at the level curves of $\ln\binom{N-y}{x},N\in\mathbb{N}^*$ By Stirling, as @TedShifrin remarked,  $\ln(n!)\sim n\ln(n)$ therefore $\ln\binom{N-y}{x}\sim y\ln(N-y)-x\ln(x)-(N-y-x)\ln(N-y-x)$ and seem to give us nice curves (cf his answer). Is there an equation y=f(x) for those curves ?",,"['combinatorics', 'algebra-precalculus']"
1,Why do you add +1 in counting test questions?,Why do you add +1 in counting test questions?,,"Here's an example question from the SAT question of the day : On the last day of a one-week sale, customers numbered 149 through 201 were waited on. How many customers were waited on that day?   Possible answers: 51, 52, 53, 152, 153. The correct answer here is 53, which is the result of (201-149) + 1 = 53. What's the reasoning in adding the +1?","Here's an example question from the SAT question of the day : On the last day of a one-week sale, customers numbered 149 through 201 were waited on. How many customers were waited on that day?   Possible answers: 51, 52, 53, 152, 153. The correct answer here is 53, which is the result of (201-149) + 1 = 53. What's the reasoning in adding the +1?",,['combinatorics']
2,Show that a generalized knight can return to its original position only after an even number of moves,Show that a generalized knight can return to its original position only after an even number of moves,,"Source: German Mathematical Olympiad Problem: On an arbitrarily large chessboard, a generalized knight moves by jumping p squares in one direction and q squares in a perpendicular direction, p, q > 0. Show that such a knight can return to its original position only after an even number of moves. Attempt: Assume, wlog, the knight moves $q$ steps to the right after its $p$ steps. Let the valid moves for the knight be ""LU"", ""UR"", ""DL"", ""RD"" i.e. when it moves L eft, it has to go U p(""LU""), or when it goes U p , it has to go R ight(""UR"") and so on. Let the knight be stationed at $(0,0)$ . We note that after any move its coordinates will be integer multiples of $p,q$ . Let its final position be $(pk, qr)$ for $ k,r\in\mathbb{Z}$ . We follow sign conventions of coordinate system. Let knight move by $-pk$ horizontally and $-qk$ vertically by repeated application of one step. So, its new position is $(0,q(r-k))$ I am thinking that somehow I need to cancel that $q(r-k)$ to achieve $(0,0)$ , but don't be able to do the same. Any hints please?","Source: German Mathematical Olympiad Problem: On an arbitrarily large chessboard, a generalized knight moves by jumping p squares in one direction and q squares in a perpendicular direction, p, q > 0. Show that such a knight can return to its original position only after an even number of moves. Attempt: Assume, wlog, the knight moves steps to the right after its steps. Let the valid moves for the knight be ""LU"", ""UR"", ""DL"", ""RD"" i.e. when it moves L eft, it has to go U p(""LU""), or when it goes U p , it has to go R ight(""UR"") and so on. Let the knight be stationed at . We note that after any move its coordinates will be integer multiples of . Let its final position be for . We follow sign conventions of coordinate system. Let knight move by horizontally and vertically by repeated application of one step. So, its new position is I am thinking that somehow I need to cancel that to achieve , but don't be able to do the same. Any hints please?","q p (0,0) p,q (pk, qr)  k,r\in\mathbb{Z} -pk -qk (0,q(r-k)) q(r-k) (0,0)","['combinatorics', 'geometry', 'arithmetic']"
3,Numbers on blackboard,Numbers on blackboard,,"All numbers $1$ to $155$ are written on a blackboard, one time each. We randomly choose two numbers and delete them, by replacing one of them with their product plus their sum. We repeat the process until there is only one number left. What is the average value of this number? I don't know how to approach it: For two numbers, $1$ and $2$ , the only number is $1\cdot 2+1+2=5$ For three numbers, $1, 2$ and $3$ , we can opt to replace $1$ and $2$ with $5$ and then $3$ and $5$ with $23$ , or $1$ and $3$ with $7$ and then $2$ , $7$ with $23$ or $2$ , $3$ with $11$ and $1$ , $11$ with $23$ so we see that no matter which two numbers we choose, the average number remains the same. Does this lead us anywhere?","All numbers to are written on a blackboard, one time each. We randomly choose two numbers and delete them, by replacing one of them with their product plus their sum. We repeat the process until there is only one number left. What is the average value of this number? I don't know how to approach it: For two numbers, and , the only number is For three numbers, and , we can opt to replace and with and then and with , or and with and then , with or , with and , with so we see that no matter which two numbers we choose, the average number remains the same. Does this lead us anywhere?","1 155 1 2 1\cdot 2+1+2=5 1, 2 3 1 2 5 3 5 23 1 3 7 2 7 23 2 3 11 1 11 23",['combinatorics']
4,Beautiful identity: $\sum_{k=m}^n (-1)^{k-m} \binom{k}{m} \binom{n}{k} = \delta_{mn}$,Beautiful identity:,\sum_{k=m}^n (-1)^{k-m} \binom{k}{m} \binom{n}{k} = \delta_{mn},"Let $m,n\ge 0$ be two integers. Prove that $$\sum_{k=m}^n (-1)^{k-m} \binom{k}{m} \binom{n}{k} = \delta_{mn}$$ where $\delta_{mn}$ stands for the Kronecker's delta (defined by $\delta_{mn} = \begin{cases} 1, & \text{if } m=n; \\ 0, & \text{if } m\neq n \end{cases}$). Note: I put the tag ""linear algebra"" because i think there is an elegant way to attack the problem using a certain type of matrices. I hope you will enjoy. :)","Let $m,n\ge 0$ be two integers. Prove that $$\sum_{k=m}^n (-1)^{k-m} \binom{k}{m} \binom{n}{k} = \delta_{mn}$$ where $\delta_{mn}$ stands for the Kronecker's delta (defined by $\delta_{mn} = \begin{cases} 1, & \text{if } m=n; \\ 0, & \text{if } m\neq n \end{cases}$). Note: I put the tag ""linear algebra"" because i think there is an elegant way to attack the problem using a certain type of matrices. I hope you will enjoy. :)",,"['combinatorics', 'summation', 'binomial-coefficients']"
5,The pigeonhole principle and a professor who knows $9$ jokes and tells $3$ jokes per lecture,The pigeonhole principle and a professor who knows  jokes and tells  jokes per lecture,9 3,"A professor knows $9$ jokes and tells $3$ jokes per lecture.   Prove that in a course of $13$ lectures there is going to be a pair of jokes that will be told together in at least $2$ lectures. I've started with counting how many possibilities there are to tell jokes in a lecture. Let $$J := \{1,2,\dots,9\}$$ The amount of all different possible combinations for jokes is $9 \choose 3$ and for each lecture there are going to be $3$ unique pairs of jokes $\left(\frac{3!}{2!}=3\right)$. I'm not sure how to continue from here to get to the PHP, I think I might be doing something wrong here, any advice how to abstract it properly? This is an exercise from the Tel-Aviv University entry test preparation and I'm not a student yet so elementry combinatorics should do here.","A professor knows $9$ jokes and tells $3$ jokes per lecture.   Prove that in a course of $13$ lectures there is going to be a pair of jokes that will be told together in at least $2$ lectures. I've started with counting how many possibilities there are to tell jokes in a lecture. Let $$J := \{1,2,\dots,9\}$$ The amount of all different possible combinations for jokes is $9 \choose 3$ and for each lecture there are going to be $3$ unique pairs of jokes $\left(\frac{3!}{2!}=3\right)$. I'm not sure how to continue from here to get to the PHP, I think I might be doing something wrong here, any advice how to abstract it properly? This is an exercise from the Tel-Aviv University entry test preparation and I'm not a student yet so elementry combinatorics should do here.",,"['combinatorics', 'permutations']"
6,Is a Sudoku a Cayley table for a group?,Is a Sudoku a Cayley table for a group?,,"I want to know if the popular Sudoku puzzle is a Cayley table for a group. Methods I've looked at: Someone I've spoken to told me they're not because counting the number of puzzle solutions against the number of tables with certain permutations of elements, rows and columns, the solutions are bigger than the tables, but I can't see why because I don't know how to count the different tables for a group of order 9, and then permute the rows, columns and elements in different ways.  Also I believe the rotations/reflections will matter in comparing these numbers too.  It would also be nice if there was a way to know if the operation is associative just from the table.","I want to know if the popular Sudoku puzzle is a Cayley table for a group. Methods I've looked at: Someone I've spoken to told me they're not because counting the number of puzzle solutions against the number of tables with certain permutations of elements, rows and columns, the solutions are bigger than the tables, but I can't see why because I don't know how to count the different tables for a group of order 9, and then permute the rows, columns and elements in different ways.  Also I believe the rotations/reflections will matter in comparing these numbers too.  It would also be nice if there was a way to know if the operation is associative just from the table.",,"['combinatorics', 'group-theory', 'finite-groups', 'permutations', 'sudoku']"
7,Calculating the total number of surjective functions,Calculating the total number of surjective functions,,"It is quite easy to calculate the total number of functions from a set $X$ with $m$ elements to a set $Y$ with $n$ elements ($n^{m}$), and also the total number of injective functions ($n^{\underline{m}}$, denoting the falling factorial). But I am thinking about how to calculate the total number of surjective functions $f\colon X \twoheadrightarrow Y $. The way I thought of doing this is as follows: firstly, since all $n$ elements of the codomain $Y$ need to be mapped to, you choose any $n$ elements from the $m$ elements of the set $X$ to be mapped one-to-one with the $n$ elements of $Y$. This results in $n!$ possible pairings. But the number of ways of choosing $n$ elements from $m$ elements is $\frac{m!}{(m-n)!\,n!}$, so the total number of ways of matching $n$ elements in $X$ to be one-to-one with the $n$ elements of $Y$ is $\frac{m!}{(m-n)!\,n!} \times n! = \frac{m!}{(m-n)!}$. Now we have 'covered' the codomain $Y$ with $n$ elements from $X$, the remaining unpaired $m-n$ elements from $X$ can be mapped to any of the elements of $Y$, so there are $n^{m-n}$ ways of doing this. Therefore I think that the total number of surjective functions should be $\frac{m!}{(m-n)!} \, n^{m-n}$. Is this anything like correct or have I made a major mistake here?","It is quite easy to calculate the total number of functions from a set $X$ with $m$ elements to a set $Y$ with $n$ elements ($n^{m}$), and also the total number of injective functions ($n^{\underline{m}}$, denoting the falling factorial). But I am thinking about how to calculate the total number of surjective functions $f\colon X \twoheadrightarrow Y $. The way I thought of doing this is as follows: firstly, since all $n$ elements of the codomain $Y$ need to be mapped to, you choose any $n$ elements from the $m$ elements of the set $X$ to be mapped one-to-one with the $n$ elements of $Y$. This results in $n!$ possible pairings. But the number of ways of choosing $n$ elements from $m$ elements is $\frac{m!}{(m-n)!\,n!}$, so the total number of ways of matching $n$ elements in $X$ to be one-to-one with the $n$ elements of $Y$ is $\frac{m!}{(m-n)!\,n!} \times n! = \frac{m!}{(m-n)!}$. Now we have 'covered' the codomain $Y$ with $n$ elements from $X$, the remaining unpaired $m-n$ elements from $X$ can be mapped to any of the elements of $Y$, so there are $n^{m-n}$ ways of doing this. Therefore I think that the total number of surjective functions should be $\frac{m!}{(m-n)!} \, n^{m-n}$. Is this anything like correct or have I made a major mistake here?",,"['combinatorics', 'functions', 'stirling-numbers']"
8,The Hexagonal Property of Pascal's Triangle,The Hexagonal Property of Pascal's Triangle,,"Any hexagon in Pascal's triangle, whose vertices are 6 binomial coefficients surrounding any entry, has the property that: the product of non-adjacent vertices is constant. the greatest common divisor of non-adjacent vertices is constant. Below is one such hexagon. As an example, here we have that $4 \cdot 10  \cdot 15 = 6 \cdot 20  \cdot 5$ , as well as $\gcd(4, 10, 15) = \gcd(6,20,5)$ . $$ 1 \\ 1 \qquad  1\\ 1\qquad 2\qquad 1\\ 1\qquad3\qquad3\qquad1\\ 1\qquad\mathbf{4}\qquad\mathbf{6}\qquad4\qquad1\\ 1\qquad\mathbf{5}\qquad10\qquad\mathbf{10}\qquad5\qquad1 \\ 1\qquad6\qquad\mathbf{15}\qquad\mathbf{20}\qquad15\qquad6\qquad1$$ There is a quick proof here (pdf). The original proof should be in V. E. Hoggatt, Jr., & W. Hansell. ""The Hidden Hexagon Squares."" The Fibonacci Quarterly 9(1971):120, 133. but I cannot access it. I am, however, intereseted in a purely combinatorial proof. I do not know how to approach this at all: I cannot see what the non-adjacent vertices represent and/or I do not know how to remodel their meaning. Can anyone help? EDIT: To specify my question more closely, what I am looking for is some natural bijection between the two sets of triads that create the hexagon. Thanks.","Any hexagon in Pascal's triangle, whose vertices are 6 binomial coefficients surrounding any entry, has the property that: the product of non-adjacent vertices is constant. the greatest common divisor of non-adjacent vertices is constant. Below is one such hexagon. As an example, here we have that , as well as . There is a quick proof here (pdf). The original proof should be in V. E. Hoggatt, Jr., & W. Hansell. ""The Hidden Hexagon Squares."" The Fibonacci Quarterly 9(1971):120, 133. but I cannot access it. I am, however, intereseted in a purely combinatorial proof. I do not know how to approach this at all: I cannot see what the non-adjacent vertices represent and/or I do not know how to remodel their meaning. Can anyone help? EDIT: To specify my question more closely, what I am looking for is some natural bijection between the two sets of triads that create the hexagon. Thanks.","4 \cdot 10  \cdot 15 = 6 \cdot 20  \cdot 5 \gcd(4, 10, 15) = \gcd(6,20,5)  1 \\
1 \qquad  1\\
1\qquad 2\qquad 1\\
1\qquad3\qquad3\qquad1\\
1\qquad\mathbf{4}\qquad\mathbf{6}\qquad4\qquad1\\
1\qquad\mathbf{5}\qquad10\qquad\mathbf{10}\qquad5\qquad1
\\
1\qquad6\qquad\mathbf{15}\qquad\mathbf{20}\qquad15\qquad6\qquad1","['combinatorics', 'binomial-coefficients', 'alternative-proof', 'combinatorial-proofs']"
9,Counting trails in a triangular grid,Counting trails in a triangular grid,,"A triangular grid has $N$ vertices, labeled from 1 to $N$. Two vertices $i$ and $j$ are adjacent if and only if $|i-j|=1$ or $|i-j|=2$. See the figure below for the case $N = 7$. How many trails are there from $1$ to $N$ in this graph? A trail is allowed to visit a vertex more than once, but it cannot travel along the same edge twice. I wrote a program to count the trails, and I obtained the following results for $1 \le N \le 17$. $$1, 1, 2, 4, 9, 23, 62, 174, 497, 1433, 4150, 12044, 34989, 101695, 295642, 859566, 2499277$$ This sequence is not in the OEIS , but Superseeker reports that the sequence satisfies the fourth-order linear recurrence $$2 a(N) + 3 a(N + 1) - a(N + 2) - 3 a(N + 3) + a(N + 4) = 0.$$ Question: Can anyone prove that this equation holds for all $N$?","A triangular grid has $N$ vertices, labeled from 1 to $N$. Two vertices $i$ and $j$ are adjacent if and only if $|i-j|=1$ or $|i-j|=2$. See the figure below for the case $N = 7$. How many trails are there from $1$ to $N$ in this graph? A trail is allowed to visit a vertex more than once, but it cannot travel along the same edge twice. I wrote a program to count the trails, and I obtained the following results for $1 \le N \le 17$. $$1, 1, 2, 4, 9, 23, 62, 174, 497, 1433, 4150, 12044, 34989, 101695, 295642, 859566, 2499277$$ This sequence is not in the OEIS , but Superseeker reports that the sequence satisfies the fourth-order linear recurrence $$2 a(N) + 3 a(N + 1) - a(N + 2) - 3 a(N + 3) + a(N + 4) = 0.$$ Question: Can anyone prove that this equation holds for all $N$?",,"['graph-theory', 'combinatorics']"
10,Combinatorics Problem: Box Riddle,Combinatorics Problem: Box Riddle,,"A huge group of people live a bizarre box based existence. Every day, everyone changes the box that they're in, and every day they share their box with exactly one person, and never share a box with the same person twice. One of the people of the boxes gets sick. The illness is spread by co-box-itation. What is the minimum number of people who are ill on day n? Additional information (not originally included in problem): Potentially relevant OEIS sequence: http://oeis.org/A007843","A huge group of people live a bizarre box based existence. Every day, everyone changes the box that they're in, and every day they share their box with exactly one person, and never share a box with the same person twice. One of the people of the boxes gets sick. The illness is spread by co-box-itation. What is the minimum number of people who are ill on day n? Additional information (not originally included in problem): Potentially relevant OEIS sequence: http://oeis.org/A007843",,"['combinatorics', 'logic']"
11,Six real numbers so that product of any five is the sixth one,Six real numbers so that product of any five is the sixth one,,"One needs to choose six real numbers $x_1,x_2,\cdots,x_6$ such that the product of any five of them is equal to other number. The number of such choices is A) $3$ B) $33$ C) $63$ D) $93$ I believe this is not so hard problem but I got no clue to proceed. The work I did till now. Say the numbers be $a,b,c,d,e, abcde$ . Then, $b\cdot c\cdot d\cdot e\cdot abcde=a$ hence $bcde= +-1$ . Basically I couldn't even find a single occasion where such things occcur except all of these numbers being either $1$ or $-1$ . Are these all cases?","One needs to choose six real numbers such that the product of any five of them is equal to other number. The number of such choices is A) B) C) D) I believe this is not so hard problem but I got no clue to proceed. The work I did till now. Say the numbers be . Then, hence . Basically I couldn't even find a single occasion where such things occcur except all of these numbers being either or . Are these all cases?","x_1,x_2,\cdots,x_6 3 33 63 93 a,b,c,d,e, abcde b\cdot c\cdot d\cdot e\cdot abcde=a bcde= +-1 1 -1",['combinatorics']
12,Prove that at a party of $25$ people there is one person knows at least twelve people.,Prove that at a party of  people there is one person knows at least twelve people.,25,"So, the full problem goes like this: There are $25$ people at a party. Assuming that among any three people, at least two of them know each other, prove that there exists one person who must know at least twelve people. I've been stuck on this problem for a while and haven't really figured out how to proceed. I'm pretty sure that there is an answer that can be found via the pigeonhole principle or some graph theory, but I'm not really sure how to get started. Any help would be appreciated.","So, the full problem goes like this: There are $25$ people at a party. Assuming that among any three people, at least two of them know each other, prove that there exists one person who must know at least twelve people. I've been stuck on this problem for a while and haven't really figured out how to proceed. I'm pretty sure that there is an answer that can be found via the pigeonhole principle or some graph theory, but I'm not really sure how to get started. Any help would be appreciated.",,"['combinatorics', 'discrete-mathematics', 'graph-theory', 'contest-math', 'pigeonhole-principle']"
13,Combinatorial interpretation of Binomial Inversion,Combinatorial interpretation of Binomial Inversion,,"It is known that if $f_n = \sum\limits_{i=0}^{n} g_i \binom{n}{i}$ for all $0 \le n \le m$, then $g_n = \sum_{i=0}^{n} (-1)^{i+n} f_i \binom{n}{i}$ for $0 \le n \le m$. This sort of inversion is called binomial inversion , for obvious reasons. Many nice elegant proofs exist (my favorite uses exponential generating functions of $f_n$ and $g_n$), and also many applications (such as proving that if polynomial $f$ of degree $n$ assumes integers values on $0,1,\cdots,n$, then $f(i) \in \mathbb{Z}$ for all integers $i$). What I'm interested is the following: A nice inclusion-exclusion proof - similar to interpreting Möbius inversion as inclusion-exclusion. If $f_0 = g_0 = 0$ and $i | f_i$ for $i>1$, we get, by the Binomial Inversion, that $i | g_i$ (reason: $i\binom{n}{i} = n\binom{n-1}{i-1}$). Is there a nice combinatorial interpretation of this phenomena? Nice applications? Are there any more famous/cool inversions (I know of Möbius inversion, binomial inversion, and the discrete derivative inversion $a_i \to a_{i+1}-a_{i})$?","It is known that if $f_n = \sum\limits_{i=0}^{n} g_i \binom{n}{i}$ for all $0 \le n \le m$, then $g_n = \sum_{i=0}^{n} (-1)^{i+n} f_i \binom{n}{i}$ for $0 \le n \le m$. This sort of inversion is called binomial inversion , for obvious reasons. Many nice elegant proofs exist (my favorite uses exponential generating functions of $f_n$ and $g_n$), and also many applications (such as proving that if polynomial $f$ of degree $n$ assumes integers values on $0,1,\cdots,n$, then $f(i) \in \mathbb{Z}$ for all integers $i$). What I'm interested is the following: A nice inclusion-exclusion proof - similar to interpreting Möbius inversion as inclusion-exclusion. If $f_0 = g_0 = 0$ and $i | f_i$ for $i>1$, we get, by the Binomial Inversion, that $i | g_i$ (reason: $i\binom{n}{i} = n\binom{n-1}{i-1}$). Is there a nice combinatorial interpretation of this phenomena? Nice applications? Are there any more famous/cool inversions (I know of Möbius inversion, binomial inversion, and the discrete derivative inversion $a_i \to a_{i+1}-a_{i})$?",,"['combinatorics', 'discrete-mathematics', 'binomial-coefficients']"
14,Combination of smartphones' pattern password,Combination of smartphones' pattern password,,"Have you ever seen this interface? Nowadays, it is used for locking smartphones. If you haven't, here is a short video on it. The rules for creating a pattern is as follows. We must use four nodes or more to make a pattern at least. Once a node is visited, then the node can't be visited anymore. You can start at any node. A pattern has to be connected. Cycle is not allowed. How many distinct patterns are possible?","Have you ever seen this interface? Nowadays, it is used for locking smartphones. If you haven't, here is a short video on it. The rules for creating a pattern is as follows. We must use four nodes or more to make a pattern at least. Once a node is visited, then the node can't be visited anymore. You can start at any node. A pattern has to be connected. Cycle is not allowed. How many distinct patterns are possible?",,"['combinatorics', 'permutations']"
15,Is it possible to assemble copies of this shape into a cube?,Is it possible to assemble copies of this shape into a cube?,,"A couple of friends of mine were discussing a problem concerning this shape: Is it possible to assemble enough of these to form a cube? I have discovered a lot of impossible positions but was not successful in creating something useful. We have managed to build a 12x12x4 tower with leftover blocks at the top, however. Maybe someone here has any ideas on how to tackle this problem? My next steps would be to try and extend our 12x12x4 tower, and if that doesn't work, to write a program to search for solutions.","A couple of friends of mine were discussing a problem concerning this shape: Is it possible to assemble enough of these to form a cube? I have discovered a lot of impossible positions but was not successful in creating something useful. We have managed to build a 12x12x4 tower with leftover blocks at the top, however. Maybe someone here has any ideas on how to tackle this problem? My next steps would be to try and extend our 12x12x4 tower, and if that doesn't work, to write a program to search for solutions.",,"['combinatorics', 'puzzle', 'tiling']"
16,In how many ways can a number be expressed as a sum of consecutive numbers? [duplicate],In how many ways can a number be expressed as a sum of consecutive numbers? [duplicate],,"This question already has answers here : All even $n \neq 2^k$ are a sum of consecutive integers (and counting the ways) (5 answers) Closed 3 years ago . All the positive numbers can be expressed as a sum of one, two or more consecutive positive integers. For example $9$ can be expressed in three such ways, $2+3+4$ , $4+5$ or simply $9$ . In how many ways can a number be expressed as a sum of consecutive numbers? In how many ways can this work for $65$ ? Here, for $9$ answer is $3$ , for $10$ answer is $3$ , for $11$ answer is $2$ .","This question already has answers here : All even $n \neq 2^k$ are a sum of consecutive integers (and counting the ways) (5 answers) Closed 3 years ago . All the positive numbers can be expressed as a sum of one, two or more consecutive positive integers. For example can be expressed in three such ways, , or simply . In how many ways can a number be expressed as a sum of consecutive numbers? In how many ways can this work for ? Here, for answer is , for answer is , for answer is .",9 2+3+4 4+5 9 65 9 3 10 3 11 2,"['combinatorics', 'number-theory', 'elementary-number-theory']"
17,Dividing a polyhedron into two similar copies of itself,Dividing a polyhedron into two similar copies of itself,,"The paper Dividing a polygon into two similar polygons provides that there are only three families of polygons that are irrep-2-tiles (can be subdivided into similar copies of the original). Right angled triangles $1:\sqrt{2}$ parallelograms The Golden Bee I wish to find examples of polyhedra that are irrep-2-tiles. The only example I have been able to find is: The $1:2^\frac{1}{3}:2^\frac{2}{3}$ parallelopipeds. Are there further examples? I would like to find as many as possible. I have now posted this question on MathOverflow also. Edit: A diagram of the Golden Bee from the linked paper. It seems plausible that there could be a $3d$ analogue. Addressing Jaap Scherphuis' comment, such a polyhedron would be able to tile $\mathbb{R}^3$ , provided you used copies of different sizes. An analogue of the Pinwheel tiling would work. However, I can't think of a way to guarantee that we only use a finite amount of different sizes of the tile. The ""natural"" tiling, adjoining copies of the polyhedron again and again to cover the entire plane will need arbitrarily large polyhedra. We can subdivide these to reduce their size, but unless we have some lucky scaling factors we'll end up with infinitely many different sizes of tile.","The paper Dividing a polygon into two similar polygons provides that there are only three families of polygons that are irrep-2-tiles (can be subdivided into similar copies of the original). Right angled triangles parallelograms The Golden Bee I wish to find examples of polyhedra that are irrep-2-tiles. The only example I have been able to find is: The parallelopipeds. Are there further examples? I would like to find as many as possible. I have now posted this question on MathOverflow also. Edit: A diagram of the Golden Bee from the linked paper. It seems plausible that there could be a analogue. Addressing Jaap Scherphuis' comment, such a polyhedron would be able to tile , provided you used copies of different sizes. An analogue of the Pinwheel tiling would work. However, I can't think of a way to guarantee that we only use a finite amount of different sizes of the tile. The ""natural"" tiling, adjoining copies of the polyhedron again and again to cover the entire plane will need arbitrarily large polyhedra. We can subdivide these to reduce their size, but unless we have some lucky scaling factors we'll end up with infinitely many different sizes of tile.",1:\sqrt{2} 1:2^\frac{1}{3}:2^\frac{2}{3} 3d \mathbb{R}^3,"['combinatorics', 'geometry', 'polyhedra', 'tiling', 'iterated-function-system']"
18,Unexpected Proofs Using Generating Functions,Unexpected Proofs Using Generating Functions,,"I recently came across this beautiful proof by Erdős that uses generating functions in a unique way: Let $S = \{a_1, \cdots, a_n \}$ be a finite set of positive integers such that no two subsets of $S$ have the same sum. Prove that $$\sum_{i=1}^n \frac{1}{a_i} < 2.$$ Question: Are there any more examples of surprising or unexpected proofs using generating functions that this community is aware of? (Please refrain from posting answers that are widely known such as change making, closed form for Fibonacci, etc.) The proof of the above theorem: Proof: Suppose $0< x < 1$. We have  $$\prod_{i=1}^n (1 + x^{a_i}) < \sum_{i = 0}^{\infty} x^i = \frac{1}{1-x}.$$ Thus,  $$\begin{align*} \sum_{i=1}^n \log(1+x^{a_i}) &< - \log(1-x) \\ \sum_{i=1}^n \int_0^1 \frac{\log(1+x^{a_i})}{x} \ dx &< - \int_0^1 \frac{\log(1-x)}x \ dx . \end{align*}$$ Putting $x^{a_i} = y$, we obtain  $$\begin{align*} \sum_{i=1}^{n} \frac{1}{a_i} \int_0^1 \frac{\log(1+y)}{y} \ dy < - \int_0^1 \frac{\log(1-x)}{x} \ dx  \end{align*}$$ i.e., $$\sum_{i=1}^n \frac{1}{a_i} \left( \frac{\pi^2}{12} \right) < \frac{\pi^2}6.$$ Thus, $\sum_{i=1}^n \frac{1}{a_i} < 2$ and the theorem is proved.","I recently came across this beautiful proof by Erdős that uses generating functions in a unique way: Let $S = \{a_1, \cdots, a_n \}$ be a finite set of positive integers such that no two subsets of $S$ have the same sum. Prove that $$\sum_{i=1}^n \frac{1}{a_i} < 2.$$ Question: Are there any more examples of surprising or unexpected proofs using generating functions that this community is aware of? (Please refrain from posting answers that are widely known such as change making, closed form for Fibonacci, etc.) The proof of the above theorem: Proof: Suppose $0< x < 1$. We have  $$\prod_{i=1}^n (1 + x^{a_i}) < \sum_{i = 0}^{\infty} x^i = \frac{1}{1-x}.$$ Thus,  $$\begin{align*} \sum_{i=1}^n \log(1+x^{a_i}) &< - \log(1-x) \\ \sum_{i=1}^n \int_0^1 \frac{\log(1+x^{a_i})}{x} \ dx &< - \int_0^1 \frac{\log(1-x)}x \ dx . \end{align*}$$ Putting $x^{a_i} = y$, we obtain  $$\begin{align*} \sum_{i=1}^{n} \frac{1}{a_i} \int_0^1 \frac{\log(1+y)}{y} \ dy < - \int_0^1 \frac{\log(1-x)}{x} \ dx  \end{align*}$$ i.e., $$\sum_{i=1}^n \frac{1}{a_i} \left( \frac{\pi^2}{12} \right) < \frac{\pi^2}6.$$ Thus, $\sum_{i=1}^n \frac{1}{a_i} < 2$ and the theorem is proved.",,"['combinatorics', 'analysis', 'generating-functions', 'big-list']"
19,What is the period of Langton's ant on a torus?,What is the period of Langton's ant on a torus?,,"Langton's ant runs on an infinite white grid. At every white square, it turns right, flips the color of the square, and moves forward one square. At every black square, it turns left, flips the color of the square, and moves forward one square. After many interations, you get complex emergent behavior, such as ""recurrent highways"" starting at step ~10,000. Let's suppose that Langton's ant awakens instead on a torus of size $n \times n$ . It follows its two rules, thus changing the coloring of the torus. At some point, however, it encounters a colouration it has seen before, while being in the same spot as before, and finds itself in a cycle. How do we find the length of a cycle for a size $n$ torus, and is this result known? We can get a stupid upper bound by observing that there are at most $2^{n^2}$ colorings, $n^2$ positions, and $4$ orientations, so a cycle cannot be longer than $2^{n^2+2}n^2$ . Is there a closed form for this, or at least some tighter bounds? EDIT 1 I ran some quick calculations just to get a feel for the magnitudes of the numbers 1 . Here's an animation of Langton's ant on a $3 \times 3$ torus, where the cycle takes 22 steps: Some more results I got are: $$\begin{matrix} \text{Size} & \text{Steps} & \text{Factorization}\\ \hline 1 & 2 & 2\\ 2 & 8 & 2^3\\  3 & 66 & 2 \cdot 3 \cdot 11\\  4 & 96 & 2^5 \cdot 3\\  5 & 11,710 & 2 \cdot 5 \cdot 1171\\  6 & 4,592 & 2^4 \cdot 7 \cdot 41\\  7 & 64,165,598 & 2 \cdot 7^2 \cdot 31 \cdot 21121\\  8 & 11,502,464 & 2^7 \cdot 73 \cdot 1231\\  9 & 919,057,222,998 & 2 \cdot 3^2 \cdot 51058734611 \\ 10 & 150,192,928,160 & 2^{5}\cdot5\cdot11\cdot85336891 \\ 11 & >5.7 \cdot 10^{11} & \\ 12 & >5.6 \cdot 10^{11} & \\ \end{matrix}$$ The values for $n=9$ and $10$ are due to Connor Harris . This does not, to my knowledge, match any sequence in OEIS . EDIT 2 The only real pattern I've found thus far is in the prime factorizations—for odd-sized tori, there is (so far) exactly one factor of 2 in the factorization. However, in even-sized tori, the factors of 2 have multiplicities 3, 5, 4, and 7, which seems interesting. Is there any reason to believe this pattern holds for all even/odd-sized periods? Footnotes 1: as per Connor Harris's comment , I only checked until the initial state reappeared (i.e., the torus became blank). 2: using Connor Harris's definition of a quasi-cycle as the amount of time it takes to get back to a blank (or full) grid.","Langton's ant runs on an infinite white grid. At every white square, it turns right, flips the color of the square, and moves forward one square. At every black square, it turns left, flips the color of the square, and moves forward one square. After many interations, you get complex emergent behavior, such as ""recurrent highways"" starting at step ~10,000. Let's suppose that Langton's ant awakens instead on a torus of size . It follows its two rules, thus changing the coloring of the torus. At some point, however, it encounters a colouration it has seen before, while being in the same spot as before, and finds itself in a cycle. How do we find the length of a cycle for a size torus, and is this result known? We can get a stupid upper bound by observing that there are at most colorings, positions, and orientations, so a cycle cannot be longer than . Is there a closed form for this, or at least some tighter bounds? EDIT 1 I ran some quick calculations just to get a feel for the magnitudes of the numbers 1 . Here's an animation of Langton's ant on a torus, where the cycle takes 22 steps: Some more results I got are: The values for and are due to Connor Harris . This does not, to my knowledge, match any sequence in OEIS . EDIT 2 The only real pattern I've found thus far is in the prime factorizations—for odd-sized tori, there is (so far) exactly one factor of 2 in the factorization. However, in even-sized tori, the factors of 2 have multiplicities 3, 5, 4, and 7, which seems interesting. Is there any reason to believe this pattern holds for all even/odd-sized periods? Footnotes 1: as per Connor Harris's comment , I only checked until the initial state reappeared (i.e., the torus became blank). 2: using Connor Harris's definition of a quasi-cycle as the amount of time it takes to get back to a blank (or full) grid.","n \times n n 2^{n^2} n^2 4 2^{n^2+2}n^2 3 \times 3 \begin{matrix}
\text{Size} & \text{Steps} & \text{Factorization}\\
\hline
1 & 2 & 2\\
2 & 8 & 2^3\\ 
3 & 66 & 2 \cdot 3 \cdot 11\\ 
4 & 96 & 2^5 \cdot 3\\ 
5 & 11,710 & 2 \cdot 5 \cdot 1171\\ 
6 & 4,592 & 2^4 \cdot 7 \cdot 41\\ 
7 & 64,165,598 & 2 \cdot 7^2 \cdot 31 \cdot 21121\\ 
8 & 11,502,464 & 2^7 \cdot 73 \cdot 1231\\ 
9 & 919,057,222,998 & 2 \cdot 3^2 \cdot 51058734611 \\
10 & 150,192,928,160 & 2^{5}\cdot5\cdot11\cdot85336891 \\
11 & >5.7 \cdot 10^{11} & \\
12 & >5.6 \cdot 10^{11} & \\
\end{matrix} n=9 10","['combinatorics', 'group-theory', 'finite-groups', 'automata', 'finite-state-machine']"
20,How many ways are there to eat a chocolate bar?,How many ways are there to eat a chocolate bar?,,"I'm teaching an intro programming course and came up with a recursion problem for my students to solve that's inspired by the game Chomp . Here's the problem statement: You have a chocolate bar that’s subdivided into individual squares.   You decide to eat the bar according to the following rule: if you   choose to eat one of the chocolate squares, you have to also eat every   square below and/or to the right of that square. For example, here’s one of the many ways you could eat a 3 × 5   chocolate bar while obeying the rule. The star at each step indicates   the square chosen out of the chocolate bar, and the gray squares   indicate which squares must also be eaten in order to comply with the   above rule. The particular choice of the starred square at each step was   completely arbitrary, but once a starred square is picked the choice   of grayed-out squares is forced. You have to eat the starred square,   plus each square that’s to the right of that square, below that   square, or both. The above route is only one way to eat the chocolate   bar. Here’s another: As before, there’s no particular pattern to how the starred squares   were chosen, but once we know which square is starred the choice of   gray squares is forced. Now, given an $m \times n$ candy bar, determine the number of different ways you can eat the candy bar while obeying the above rule. When I gave this to my students, I asked them to solve it by writing a recursive function that explores all the different routes by which the chocolate bar could be eaten. But as I was writing this problem, I started wondering - is there a closed-form solution? I used my own solution to this problem to compute the number of different sequences that exist for different values of $m$ and $n$ , and here's what I found: $$\left(\begin{matrix} 1 & 1 & 1 & 1 & 1 & 1 & 1\\ 1 & 1 & 2 & 4 & 8 & 16 & 32\\ 1 & 2 & 10 & 58 & 370 & 2514 & 17850\\ 1 & 4 & 58 & 1232 & 33096 & 1036972 & 36191226\\ 1 & 8 & 370 & 33096 & 4418360 & 768194656 & 161014977260\\ 1 & 16 & 2514 & 1036972 & 768194656 & 840254670736 & 1213757769879808\\ 1 & 32 & 17850 & 36191226 & 161014977260 & 1213757769879808 & 13367266491668337972 \end{matrix}\right)$$ Some of these rows show nice patterns. The second row looks like it's all the powers of two, and that makes sense because if you have a $1 \times n$ chocolate bar then any subsequence of the squares that includes the first square, taken in sorted order, is a way to eat the candy bar. The third row shows up as A086871 on the OEIS, but none of the rows after that appear to be known sequences. The diagonal sequence also isn't on the OEIS, I believe that this problem is equivalent to a different one: Consider the partial order defined as the Cartesian product of the less-than relation over the sets $[m] = \{0, 1, 2, ..., m - 1\}$ and $[n]$ . How many distinct sequences of elements of this partial order exist so that no term in the sequence is dominated by any previous element and the final element is the maximum element of the order? I'm completely at a loss for how to determine the answer to that question. Is there a nice closed-form solution to this problem?","I'm teaching an intro programming course and came up with a recursion problem for my students to solve that's inspired by the game Chomp . Here's the problem statement: You have a chocolate bar that’s subdivided into individual squares.   You decide to eat the bar according to the following rule: if you   choose to eat one of the chocolate squares, you have to also eat every   square below and/or to the right of that square. For example, here’s one of the many ways you could eat a 3 × 5   chocolate bar while obeying the rule. The star at each step indicates   the square chosen out of the chocolate bar, and the gray squares   indicate which squares must also be eaten in order to comply with the   above rule. The particular choice of the starred square at each step was   completely arbitrary, but once a starred square is picked the choice   of grayed-out squares is forced. You have to eat the starred square,   plus each square that’s to the right of that square, below that   square, or both. The above route is only one way to eat the chocolate   bar. Here’s another: As before, there’s no particular pattern to how the starred squares   were chosen, but once we know which square is starred the choice of   gray squares is forced. Now, given an candy bar, determine the number of different ways you can eat the candy bar while obeying the above rule. When I gave this to my students, I asked them to solve it by writing a recursive function that explores all the different routes by which the chocolate bar could be eaten. But as I was writing this problem, I started wondering - is there a closed-form solution? I used my own solution to this problem to compute the number of different sequences that exist for different values of and , and here's what I found: Some of these rows show nice patterns. The second row looks like it's all the powers of two, and that makes sense because if you have a chocolate bar then any subsequence of the squares that includes the first square, taken in sorted order, is a way to eat the candy bar. The third row shows up as A086871 on the OEIS, but none of the rows after that appear to be known sequences. The diagonal sequence also isn't on the OEIS, I believe that this problem is equivalent to a different one: Consider the partial order defined as the Cartesian product of the less-than relation over the sets and . How many distinct sequences of elements of this partial order exist so that no term in the sequence is dominated by any previous element and the final element is the maximum element of the order? I'm completely at a loss for how to determine the answer to that question. Is there a nice closed-form solution to this problem?","m \times n m n \left(\begin{matrix}
1 & 1 & 1 & 1 & 1 & 1 & 1\\
1 & 1 & 2 & 4 & 8 & 16 & 32\\
1 & 2 & 10 & 58 & 370 & 2514 & 17850\\
1 & 4 & 58 & 1232 & 33096 & 1036972 & 36191226\\
1 & 8 & 370 & 33096 & 4418360 & 768194656 & 161014977260\\
1 & 16 & 2514 & 1036972 & 768194656 & 840254670736 & 1213757769879808\\
1 & 32 & 17850 & 36191226 & 161014977260 & 1213757769879808 & 13367266491668337972
\end{matrix}\right) 1 \times n [m] = \{0, 1, 2, ..., m - 1\} [n]","['combinatorics', 'recreational-mathematics']"
21,How many possible combinations in 8 character password?,How many possible combinations in 8 character password?,,"I need to calculate the possible combinations for 8 characters password. The password must contain at least one of the following: (lower case letters, upper case letters, digits, punctuations, special characters). Assume I have 95 ascii characters (lower case letters, upper case letters, digits, punctuations, special characters). lower case letters = $26$ upper case letters = $26$ digits = $10$ punctuations & special characters = $33$ The general formula for the possible passwords that I can from from these 95 characters is: $95^8$. But, accurately, I feel the above formula is incorrect. Please, correct me. The password policy requires at least one of the listed above ascii characters. Therefore, the password possible combinations = $(26)*(26)*(10)*(33)*(95)*(95)*(95)*(95)$ Which calculation is correct? EDIT: Please, note that I mean 8 characters password and exactly 8. Also, There is no order specified (i.e. it could start with small letter, symbol, etc.). But it should contain at least one of the specified characters set (upper case, lower case, symbol, no., etc.).","I need to calculate the possible combinations for 8 characters password. The password must contain at least one of the following: (lower case letters, upper case letters, digits, punctuations, special characters). Assume I have 95 ascii characters (lower case letters, upper case letters, digits, punctuations, special characters). lower case letters = $26$ upper case letters = $26$ digits = $10$ punctuations & special characters = $33$ The general formula for the possible passwords that I can from from these 95 characters is: $95^8$. But, accurately, I feel the above formula is incorrect. Please, correct me. The password policy requires at least one of the listed above ascii characters. Therefore, the password possible combinations = $(26)*(26)*(10)*(33)*(95)*(95)*(95)*(95)$ Which calculation is correct? EDIT: Please, note that I mean 8 characters password and exactly 8. Also, There is no order specified (i.e. it could start with small letter, symbol, etc.). But it should contain at least one of the specified characters set (upper case, lower case, symbol, no., etc.).",,"['combinatorics', 'permutations']"
22,Guaranteed Checkmate with Rooks in High-Dimensional Chess,Guaranteed Checkmate with Rooks in High-Dimensional Chess,,"Given an infinite (in all directions), $n$-dimensional chess board $\mathbb Z^n$, and a black king. What is the minimum number of white rooks necessary that can guarantee a checkmate in a finite number of moves? To avoid trivial exceptions, assume the king starts a very large distance away from the nearest rook. Rooks can change one coordinate to anything. King can change any set of coordinates by one. And same problem with i) Bishops and ii) Queens, in place of rooks.","Given an infinite (in all directions), $n$-dimensional chess board $\mathbb Z^n$, and a black king. What is the minimum number of white rooks necessary that can guarantee a checkmate in a finite number of moves? To avoid trivial exceptions, assume the king starts a very large distance away from the nearest rook. Rooks can change one coordinate to anything. King can change any set of coordinates by one. And same problem with i) Bishops and ii) Queens, in place of rooks.",,"['combinatorics', 'geometry', 'puzzle', 'recreational-mathematics', 'combinatorial-game-theory']"
23,Symmetry of bicycle-lock numbers,Symmetry of bicycle-lock numbers,,"Suppose you have a combination bicycle lock of this sort: with $n$ dials and $k$ numbers on each dial. Let $m(n,k)$ denote the minimum number of turns that always suffice to open the lock from any starting position, where a turn consists of rotating any number of adjacent rings by one place. For example $m(2,10)=6$ and $m(3,10)=10$. I have found an efficient algorithm to compute these numbers , which reveals a symmetry I can’t currently explain: $m(n, k+1) = m(k, n+1)$ This is such a striking symmetry that I guess it has a simple explanation. Can anyone find one? Here’s the table of values for small $n$ and $k$, exhibiting the conjectured symmetry: n\k|   2    3    4    5    6    7    8    9   10 ---+--------------------------------------------- 1  |   1    1    2    2    3    3    4    4    5 2  |   1    2    2    3    4    4    5    6    6 3  |   2    2    4    4    6    6    8    8   10 4  |   2    3    4    6    6    8    9   10   12 5  |   3    4    6    6    9    9   12   12   15 6  |   3    4    6    8    9   12   12   15   16 7  |   4    5    8    9   12   12   16   16   20 8  |   4    6    8   10   12   15   16   20   20 9  |   5    6   10   12   15   16   20   20   25 10 |   5    7   10   12   15   18   20   24   25","Suppose you have a combination bicycle lock of this sort: with $n$ dials and $k$ numbers on each dial. Let $m(n,k)$ denote the minimum number of turns that always suffice to open the lock from any starting position, where a turn consists of rotating any number of adjacent rings by one place. For example $m(2,10)=6$ and $m(3,10)=10$. I have found an efficient algorithm to compute these numbers , which reveals a symmetry I can’t currently explain: $m(n, k+1) = m(k, n+1)$ This is such a striking symmetry that I guess it has a simple explanation. Can anyone find one? Here’s the table of values for small $n$ and $k$, exhibiting the conjectured symmetry: n\k|   2    3    4    5    6    7    8    9   10 ---+--------------------------------------------- 1  |   1    1    2    2    3    3    4    4    5 2  |   1    2    2    3    4    4    5    6    6 3  |   2    2    4    4    6    6    8    8   10 4  |   2    3    4    6    6    8    9   10   12 5  |   3    4    6    6    9    9   12   12   15 6  |   3    4    6    8    9   12   12   15   16 7  |   4    5    8    9   12   12   16   16   20 8  |   4    6    8   10   12   15   16   20   20 9  |   5    6   10   12   15   16   20   20   25 10 |   5    7   10   12   15   18   20   24   25",,"['combinatorics', 'conjectures']"
24,How many ways can seven people sit around a circular table?,How many ways can seven people sit around a circular table?,,"How many ways seven people can sit around a circular table? For first, I thought it was $7!$ (the number of ways of sitting in seven chairs), but the answer is $(7-1)!$. I don't understand how sitting around a circular table and sitting in seven chairs are different. Could somebody explain it please?","How many ways seven people can sit around a circular table? For first, I thought it was $7!$ (the number of ways of sitting in seven chairs), but the answer is $(7-1)!$. I don't understand how sitting around a circular table and sitting in seven chairs are different. Could somebody explain it please?",,['combinatorics']
25,Undergrad-level combinatorics texts easier than Stanley's Enumerative Combinatorics?,Undergrad-level combinatorics texts easier than Stanley's Enumerative Combinatorics?,,"I am an undergrad, math major, and I had basic combinatorics class using Combinatorics and Graph Theory by Harris et al before (undergrad level). Currently reading Stanley's Enumerative Combinatorics with other math folks. We have found this book somewhat challenging, especially the exercises~ Do you have any suggestions on other books to read? Or books to help going through Enumerative Combinatorics ?","I am an undergrad, math major, and I had basic combinatorics class using Combinatorics and Graph Theory by Harris et al before (undergrad level). Currently reading Stanley's Enumerative Combinatorics with other math folks. We have found this book somewhat challenging, especially the exercises~ Do you have any suggestions on other books to read? Or books to help going through Enumerative Combinatorics ?",,"['combinatorics', 'reference-request', 'book-recommendation', 'algebraic-combinatorics']"
26,Are there rigorous formulation and proof of the pigeonhole principle?,Are there rigorous formulation and proof of the pigeonhole principle?,,"The well known and intuitive pigeonhole principle states that if $n$ items are put in $m$ containers, and $n>m$, then there is  at least one container which has more than one object. I've always relied on this principle when solving combinatorics problems for the mathematical olympiads, where a high level of formalization is not necessary, but recently I've seen it in a group theory proof, so I wonder: is there a mathematically formal and rigorous formulation of this principle and, if so, what is its proof?","The well known and intuitive pigeonhole principle states that if $n$ items are put in $m$ containers, and $n>m$, then there is  at least one container which has more than one object. I've always relied on this principle when solving combinatorics problems for the mathematical olympiads, where a high level of formalization is not necessary, but recently I've seen it in a group theory proof, so I wonder: is there a mathematically formal and rigorous formulation of this principle and, if so, what is its proof?",,"['combinatorics', 'pigeonhole-principle']"
27,Prove this determinant identity combinatorially,Prove this determinant identity combinatorially,,"This is for those of you who understand the Lindstrom-Gessel-Viennot lemma. I am looking for a proof of the following identity using paths and such: Let $A$ be an $n\times n$ matrix, and for $i,j\in\{1,\ldots,n\}$, let $A^{ij}$ denote the matrix resulting from $A$ after removing row $i$ and column $j$, then: $$\det\left(\begin{array}{cccc}\det(A^{11})&\det(A^{12})&\cdots&\det(A^{1n})\\ \det(A^{21})&\det(A^{22})&\cdots&\det(A^{2n})\\ \vdots &\vdots &\ddots &\vdots\\ \det(A^{n1})&\det(A^{n2})&\cdots &\det(A^{nn})\end{array}\right)=\det(A)^{n-1}$$ Read this for the algebraic proof: Is this a well known determinant identity? Are there any generalizations?","This is for those of you who understand the Lindstrom-Gessel-Viennot lemma. I am looking for a proof of the following identity using paths and such: Let $A$ be an $n\times n$ matrix, and for $i,j\in\{1,\ldots,n\}$, let $A^{ij}$ denote the matrix resulting from $A$ after removing row $i$ and column $j$, then: $$\det\left(\begin{array}{cccc}\det(A^{11})&\det(A^{12})&\cdots&\det(A^{1n})\\ \det(A^{21})&\det(A^{22})&\cdots&\det(A^{2n})\\ \vdots &\vdots &\ddots &\vdots\\ \det(A^{n1})&\det(A^{n2})&\cdots &\det(A^{nn})\end{array}\right)=\det(A)^{n-1}$$ Read this for the algebraic proof: Is this a well known determinant identity? Are there any generalizations?",,"['combinatorics', 'determinant']"
28,Prove that the 25 people can be seated in this way,Prove that the 25 people can be seated in this way,,"5 mathematicians, 5 biologists, 5 chemists, 5 physicists, and 5 economists sit around a large round table. Prove that the 25 people can be seated such that, if A and B are two different people with the same specialty (for example, two mathematicians), then the people sitting to the immediate left of A and to the immediate left of B are of different specialties (for example, a biologist and a chemist). I thought to use induction, since $n=1$ and $n=2$ are easy to do. However, I don't know how to continue.","5 mathematicians, 5 biologists, 5 chemists, 5 physicists, and 5 economists sit around a large round table. Prove that the 25 people can be seated such that, if A and B are two different people with the same specialty (for example, two mathematicians), then the people sitting to the immediate left of A and to the immediate left of B are of different specialties (for example, a biologist and a chemist). I thought to use induction, since $n=1$ and $n=2$ are easy to do. However, I don't know how to continue.",,"['combinatorics', 'induction']"
29,Why is it important to study combinatorics?,Why is it important to study combinatorics?,,"I was having a discussion with my friend Sayan Mukherjee about why we need to study combinatorics which admittedly, is not our favorite subject because we see very less motivation for it (I am not saying that there does not exist motivation for studying it, it's just that I have not found it). Here are some of the ""uses"" of combinatorics that we could come up with: Counting - the number of ways in which we can perform a finite sequence of operations and how objects can be arranged or selected. For example,the number of ways in which we can select $k$ odd and even elements from the set $S=\{1,2,\dots, 2n\}$ so that at most 3 odd elements consecutive elements could occur in the section. Drawing bijections- The classic Stars and bars problem provides us key ideas to count the number of integral solutions to equations of the form $x_1+x_2+\dots x_n=k$ . The Seven Bridges of Königsberg which captivated me as a child. I have refrained from mentioning recursions and generating functions as I see them more as tools. But I am looking for more motivation; counting, as described in problems seems to be tip of the iceberg and I will appreciate more examples where combinatorics and graph theory can be powerful tools. Can we please have a list of uses of combinatorics? I am not looking for applications to industry, just pure math. It is  not essential that the answers be pitched at high-school level; additional info will certainly be fun to revisit!","I was having a discussion with my friend Sayan Mukherjee about why we need to study combinatorics which admittedly, is not our favorite subject because we see very less motivation for it (I am not saying that there does not exist motivation for studying it, it's just that I have not found it). Here are some of the ""uses"" of combinatorics that we could come up with: Counting - the number of ways in which we can perform a finite sequence of operations and how objects can be arranged or selected. For example,the number of ways in which we can select odd and even elements from the set so that at most 3 odd elements consecutive elements could occur in the section. Drawing bijections- The classic Stars and bars problem provides us key ideas to count the number of integral solutions to equations of the form . The Seven Bridges of Königsberg which captivated me as a child. I have refrained from mentioning recursions and generating functions as I see them more as tools. But I am looking for more motivation; counting, as described in problems seems to be tip of the iceberg and I will appreciate more examples where combinatorics and graph theory can be powerful tools. Can we please have a list of uses of combinatorics? I am not looking for applications to industry, just pure math. It is  not essential that the answers be pitched at high-school level; additional info will certainly be fun to revisit!","k S=\{1,2,\dots, 2n\} x_1+x_2+\dots x_n=k",['combinatorics']
30,Making Change for a Dollar (and other number partitioning problems),Making Change for a Dollar (and other number partitioning problems),,"I was trying to solve a problem similar to the ""how many ways are there to make change for a dollar"" problem.  I ran across a site that said I could use a generating function similar to the one quoted below: The answer to our problem ( $293$ ) is the coefficient of $x^{100}$ in the reciprocal of the following: $(1-x)(1-x^5)(1-x^{10})(1-x^{25})(1-x^{50})(1-x^{100})$ But I must be missing something, as I can't figure out how they get from that to $293$ . Any help on this would be appreciated.","I was trying to solve a problem similar to the ""how many ways are there to make change for a dollar"" problem.  I ran across a site that said I could use a generating function similar to the one quoted below: The answer to our problem ( ) is the coefficient of in the reciprocal of the following: But I must be missing something, as I can't figure out how they get from that to . Any help on this would be appreciated.",293 x^{100} (1-x)(1-x^5)(1-x^{10})(1-x^{25})(1-x^{50})(1-x^{100}) 293,"['combinatorics', 'generating-functions', 'integer-partitions']"
31,Formula for Combinations With Replacement,Formula for Combinations With Replacement,,"I understand how combinations and permutations work (without replacement). I also see why a permutation of $n$ elements ordered $k$ at a time (with replacement) is equal to $n^{k}$. Through some browsing I've found that the number of combinations with replacement of $n$ items taken $k$ at a time can be expressed as $(\binom{n}{k})$ [this ""double"" set of parentheses is the notation developed by Richard Stanley to convey the idea of combinations with replacement]. Alternatively, $(\binom{n}{k})$ = $\binom{n+k-1}{k}$. This is more familiar notation. Unfortunately, I have not found a clear explanation as to why the above formula applies to the combinations with replacement. Could anyone be so kind to explain how this formula was developed?","I understand how combinations and permutations work (without replacement). I also see why a permutation of $n$ elements ordered $k$ at a time (with replacement) is equal to $n^{k}$. Through some browsing I've found that the number of combinations with replacement of $n$ items taken $k$ at a time can be expressed as $(\binom{n}{k})$ [this ""double"" set of parentheses is the notation developed by Richard Stanley to convey the idea of combinations with replacement]. Alternatively, $(\binom{n}{k})$ = $\binom{n+k-1}{k}$. This is more familiar notation. Unfortunately, I have not found a clear explanation as to why the above formula applies to the combinations with replacement. Could anyone be so kind to explain how this formula was developed?",,"['combinatorics', 'combinations']"
32,$n$ people sitting on a circular table without repeating neighbour-sets,people sitting on a circular table without repeating neighbour-sets,n,"I made this problem up and it's been bothering me ever since. We're organising team activities in our company for the next few days. Our team consists of $n$ people seated on a circular table. To spice it up, we plan to do it in such a way that no single person has to sit with the same pair of people on any two given days. What's the longest period of time for which this can be done, without running out of arrangements? The upper-bound to this is, of course, $\binom{n-1}2$, because if we pick a member and find the number of ways to seat neighbours around him, we see that it is $\binom{n-1}2$. Since this pair of neighbours can only be seated once on that day, by pigeonhole (or whatever it's called) we cannot pick any more combinations after $\binom{n-1}2$ days. Roughly sketching it for $n = 3, 4, 5$, it's actually equal to the aforementioned upper bound, so that's a nice fact. But otherwise, I've gone off to tangents that will probably not be relevant to this discussion, and that's all the work I could come up with.","I made this problem up and it's been bothering me ever since. We're organising team activities in our company for the next few days. Our team consists of $n$ people seated on a circular table. To spice it up, we plan to do it in such a way that no single person has to sit with the same pair of people on any two given days. What's the longest period of time for which this can be done, without running out of arrangements? The upper-bound to this is, of course, $\binom{n-1}2$, because if we pick a member and find the number of ways to seat neighbours around him, we see that it is $\binom{n-1}2$. Since this pair of neighbours can only be seated once on that day, by pigeonhole (or whatever it's called) we cannot pick any more combinations after $\binom{n-1}2$ days. Roughly sketching it for $n = 3, 4, 5$, it's actually equal to the aforementioned upper bound, so that's a nice fact. But otherwise, I've gone off to tangents that will probably not be relevant to this discussion, and that's all the work I could come up with.",,"['combinatorics', 'discrete-mathematics', 'graph-theory', 'ramsey-theory']"
33,Number of ways of distributing $n$ identical objects among $r$ groups,Number of ways of distributing  identical objects among  groups,n r,"I came across this formula in a list:  The number of ways of distributing $n$ identical objects among $r$ groups such that each group can have $0$ or more $(\le n)$ objects I know that standard way of doing this is to solve the problem of distributing n identical objects and $(r-1)$ partitions among themselves which can be done in $C(n+r-1,r-1)$ ways. But I am unable to prove to myself why it is not $(r+1)^n$.  Because each of the n objects has r+1 choices, either group1, group2,... group r or none at all.","I came across this formula in a list:  The number of ways of distributing $n$ identical objects among $r$ groups such that each group can have $0$ or more $(\le n)$ objects I know that standard way of doing this is to solve the problem of distributing n identical objects and $(r-1)$ partitions among themselves which can be done in $C(n+r-1,r-1)$ ways. But I am unable to prove to myself why it is not $(r+1)^n$.  Because each of the n objects has r+1 choices, either group1, group2,... group r or none at all.",,['combinatorics']
34,Minimum number of straight lines to cover $n \times n$ grid?,Minimum number of straight lines to cover  grid?,n \times n,"I want to know the minimum number of lines needed to touch every square of an $n \times n$ grid. The only added rule is that the line has to pass inside the square, not on the edge/corner. I have found a solution for $n-1$ lines for all $2<n\le 10$ but not with fewer lines. I figure you can represent the lines by the squares they pass through, thus making a finite amount of ""lines"", but I don't have many further ideas. Here is an example of what I mean by ""covering a square"". The line just needs to pass through any part of the square: Here is also a solution for a $3 \times 3$ grid with 2 lines:","I want to know the minimum number of lines needed to touch every square of an grid. The only added rule is that the line has to pass inside the square, not on the edge/corner. I have found a solution for lines for all but not with fewer lines. I figure you can represent the lines by the squares they pass through, thus making a finite amount of ""lines"", but I don't have many further ideas. Here is an example of what I mean by ""covering a square"". The line just needs to pass through any part of the square: Here is also a solution for a grid with 2 lines:",n \times n n-1 2<n\le 10 3 \times 3,"['combinatorics', 'discrete-mathematics', 'computational-geometry']"
35,"Combinatorics looks incomprehensible, is it that I lack ""mathematical maturity"" and what should I do?","Combinatorics looks incomprehensible, is it that I lack ""mathematical maturity"" and what should I do?",,"I think this soft question may be marked ""opinion-based"" or ""off-topic"", but I really do not know where else to get help. So please read my question before it's closed, I am really desperately in need of help... Thanks in advance for all people paying attention to this question! Background I am a high school student who has participated in mathematical olympiads, where there are tons of tough combinatorics problems. I already know the basic counting techniques (binomial coefficients, inclusion-exclusion principle, etc.), some notions and theorems in graph theory (trees, Ramsey numbers, etc.), yet I do not know much beyond the definitions. Accordingly, I plan to (self-)studying this subject systematically. (I actually study for fun, not for better performance in olympiads.) Context A few days ago I stumbled upon the book A Course in Combinatorics and started working through this book with dilligence. It was not long before I found the problems way too hard . I am just halfway in chapter 2, and there are three problems (out of a dozen or so) that I cannot solve even after I read the hints and literally thinking for hours. I am unsure about whether I should pursue reading this book but a more important question arises: Why do I find the problems too hard? Is it that I lack the so-called ""mathematical maturity"" required for an undergraduate text like that, or that I am not gifted enough, or something else? I am not sure whether I do have the slightest degree of mathematical maturity, but I have been reading mathematics texts for at least half a year. I have worked through the first seven chapters of baby Rudin (and solved all the exercises, which would look ""easy"" to me compared to the problems in that combinatorics book), and I am learning linear algebra from Hoffman & Kunze and abstract algebra from Herstein, and having fun reading the three volumes Analysis from Amann & Escher. Then there are other books like Folland's Real Analysis or Artin's Algebra , which I have read only several chapters. Of all the books in mathematics I have read about, the problems of this book are the hardest. However, no one has ever mentioned that the book has tough problems. (Maybe it is just me?) By the way, I posted a problem that I literally thought for an entire afternoon here . Questions All in all, my question boils down to these: Is it normal to find it hard to solve the problems in that book? Can you possibly tell me why I am finding it hard? I will surely provide more details if necessary. (This question seems impossible to answer, so feel free to ignore it.) What should I do if I still want to study combinatorics? For example, what books are recommended for my situation? And, more importantly, how can I improve my skills in solving combinatorics problems? Please tell me what else I should add to get better answers. Again, thank you for reading this!","I think this soft question may be marked ""opinion-based"" or ""off-topic"", but I really do not know where else to get help. So please read my question before it's closed, I am really desperately in need of help... Thanks in advance for all people paying attention to this question! Background I am a high school student who has participated in mathematical olympiads, where there are tons of tough combinatorics problems. I already know the basic counting techniques (binomial coefficients, inclusion-exclusion principle, etc.), some notions and theorems in graph theory (trees, Ramsey numbers, etc.), yet I do not know much beyond the definitions. Accordingly, I plan to (self-)studying this subject systematically. (I actually study for fun, not for better performance in olympiads.) Context A few days ago I stumbled upon the book A Course in Combinatorics and started working through this book with dilligence. It was not long before I found the problems way too hard . I am just halfway in chapter 2, and there are three problems (out of a dozen or so) that I cannot solve even after I read the hints and literally thinking for hours. I am unsure about whether I should pursue reading this book but a more important question arises: Why do I find the problems too hard? Is it that I lack the so-called ""mathematical maturity"" required for an undergraduate text like that, or that I am not gifted enough, or something else? I am not sure whether I do have the slightest degree of mathematical maturity, but I have been reading mathematics texts for at least half a year. I have worked through the first seven chapters of baby Rudin (and solved all the exercises, which would look ""easy"" to me compared to the problems in that combinatorics book), and I am learning linear algebra from Hoffman & Kunze and abstract algebra from Herstein, and having fun reading the three volumes Analysis from Amann & Escher. Then there are other books like Folland's Real Analysis or Artin's Algebra , which I have read only several chapters. Of all the books in mathematics I have read about, the problems of this book are the hardest. However, no one has ever mentioned that the book has tough problems. (Maybe it is just me?) By the way, I posted a problem that I literally thought for an entire afternoon here . Questions All in all, my question boils down to these: Is it normal to find it hard to solve the problems in that book? Can you possibly tell me why I am finding it hard? I will surely provide more details if necessary. (This question seems impossible to answer, so feel free to ignore it.) What should I do if I still want to study combinatorics? For example, what books are recommended for my situation? And, more importantly, how can I improve my skills in solving combinatorics problems? Please tell me what else I should add to get better answers. Again, thank you for reading this!",,"['combinatorics', 'soft-question', 'self-learning', 'advice']"
36,A sequence of coefficients of $x+(x+(x+(x+(x+(x+\dots)^6)^5)^4)^3)^2$,A sequence of coefficients of,x+(x+(x+(x+(x+(x+\dots)^6)^5)^4)^3)^2,"Let's consider a function (or a way to obtain a formal power series): $$f(x)=x+(x+(x+(x+(x+(x+\dots)^6)^5)^4)^3)^2$$ Where $\dots$ is replaced by an infinite sequence of nested brackets raised to $n$th power. The function is defined as the limit of: $$f_1(x)=x$$ $$f_2(x)=x+x^2$$ $$f_3(x)=x+(x+x^3)^2$$ etc. For $|x|$ 'small enough' we have a finite limit $f(x)$, but I'm not really interested in it right now. What I'm interested in - if we consider the function to be represented by a (formal) power series, then we can expand the terms $f_n$ and study the sequence of coefficients. It appears to converge as well (i.e. the coefficients for first $N$ powers of $x$ stop changing after a while). For example, we have the correct first $50$ coefficients for $f_{10}$: $$(a_n)=$$ 0,1,1,0,2,0,1,6,0,6,6,24,15,26,48,56,240,60,303,504,780,1002,1776,3246,3601,7826,7500,18980,26874,38130,56196,99360,153636,210084,390348,486420,900428,1310118,2064612,3073008,4825138,7558008,11428162,18596886,26006031,43625940,65162736,100027728,152897710,242895050,365185374 I say they are correct, because they are the same up until $f_{15}$ at least (checked with Mathematica). Is there any other way to define this integer sequence? What can we say about the rate of growth of this sequence, the existence of small $a_n$ for large $n$, etc.? (see numerical estimations below) Does it become monotone after $a_{18}=60$? (Actually, $a_{27}=7500$ is smaller than the previous term as well) (see numerical estimations below) Are $a_0,a_3,a_5,a_8$ the only zero members of the sequence? (appears to be yes, see numerical estimations below) The sequence is not in OEIS (which is not surprising to me). Edit Following Winther's lead I computed the ratios of successive terms for $f_{70}$ until $n=35 \cdot 69=2415$: $$c_n=\frac{a_{n+1}}{a_n}$$ And also the differences between the successive ratios: $$d_n=c_n-c_{n+1}$$ We have: $$c_{2413}=1.428347168$$ $$c_{2414}=1.428338038$$ I conjecture that $c_{\infty}=\sqrt{2}$, but I'm not sure. After much effort, I computed $$c_{4949}=1.4132183695$$ Which seems to disprove my conjecture. The nearby values seem to agree with this. $$c_{4948}=1.4132224343 \\  c_{4947}=1.4132265001$$ But the most striking thing - just how much the sequence stabilizes after the first $200-300$ terms. How can we explain this behaviour? Why does the sequence start with more or less 'random' terms, but becomes monotone for large $n$? UPDATE The sequence is now in OEIS, number A276436","Let's consider a function (or a way to obtain a formal power series): $$f(x)=x+(x+(x+(x+(x+(x+\dots)^6)^5)^4)^3)^2$$ Where $\dots$ is replaced by an infinite sequence of nested brackets raised to $n$th power. The function is defined as the limit of: $$f_1(x)=x$$ $$f_2(x)=x+x^2$$ $$f_3(x)=x+(x+x^3)^2$$ etc. For $|x|$ 'small enough' we have a finite limit $f(x)$, but I'm not really interested in it right now. What I'm interested in - if we consider the function to be represented by a (formal) power series, then we can expand the terms $f_n$ and study the sequence of coefficients. It appears to converge as well (i.e. the coefficients for first $N$ powers of $x$ stop changing after a while). For example, we have the correct first $50$ coefficients for $f_{10}$: $$(a_n)=$$ 0,1,1,0,2,0,1,6,0,6,6,24,15,26,48,56,240,60,303,504,780,1002,1776,3246,3601,7826,7500,18980,26874,38130,56196,99360,153636,210084,390348,486420,900428,1310118,2064612,3073008,4825138,7558008,11428162,18596886,26006031,43625940,65162736,100027728,152897710,242895050,365185374 I say they are correct, because they are the same up until $f_{15}$ at least (checked with Mathematica). Is there any other way to define this integer sequence? What can we say about the rate of growth of this sequence, the existence of small $a_n$ for large $n$, etc.? (see numerical estimations below) Does it become monotone after $a_{18}=60$? (Actually, $a_{27}=7500$ is smaller than the previous term as well) (see numerical estimations below) Are $a_0,a_3,a_5,a_8$ the only zero members of the sequence? (appears to be yes, see numerical estimations below) The sequence is not in OEIS (which is not surprising to me). Edit Following Winther's lead I computed the ratios of successive terms for $f_{70}$ until $n=35 \cdot 69=2415$: $$c_n=\frac{a_{n+1}}{a_n}$$ And also the differences between the successive ratios: $$d_n=c_n-c_{n+1}$$ We have: $$c_{2413}=1.428347168$$ $$c_{2414}=1.428338038$$ I conjecture that $c_{\infty}=\sqrt{2}$, but I'm not sure. After much effort, I computed $$c_{4949}=1.4132183695$$ Which seems to disprove my conjecture. The nearby values seem to agree with this. $$c_{4948}=1.4132224343 \\  c_{4947}=1.4132265001$$ But the most striking thing - just how much the sequence stabilizes after the first $200-300$ terms. How can we explain this behaviour? Why does the sequence start with more or less 'random' terms, but becomes monotone for large $n$? UPDATE The sequence is now in OEIS, number A276436",,"['combinatorics', 'generating-functions', 'integers', 'formal-power-series', 'oeis']"
37,Dividing a square into equal-area rectangles,Dividing a square into equal-area rectangles,,"How many ways are there to tile an $n\times n$ square with exactly $n$ rectangles, each of which has integer sides and area $n$? The sequence $C(n)$ begins 1, 2, 2, 9, 2, 46, 2, 250, 37. Clearly $C(p) = 2$ for prime $p$.  The value $C(8) = 250$ was provided to me by Sjoerd Visscher, but I cannot vouch for it personally, not having seen the details of his enumeration. OEIS was no help.","How many ways are there to tile an $n\times n$ square with exactly $n$ rectangles, each of which has integer sides and area $n$? The sequence $C(n)$ begins 1, 2, 2, 9, 2, 46, 2, 250, 37. Clearly $C(p) = 2$ for prime $p$.  The value $C(8) = 250$ was provided to me by Sjoerd Visscher, but I cannot vouch for it personally, not having seen the details of his enumeration. OEIS was no help.",,"['combinatorics', 'geometry', 'recreational-mathematics', 'discrete-geometry', 'tiling']"
38,A Combinatorial Proof of Dixon's Identity,A Combinatorial Proof of Dixon's Identity,,"Dixon's Identity states: $$ \sum_{k} (-1)^k\binom {a+b}{b+k}\binom{b+c}{c+k}\binom{c+a}{a+k} = \binom{a+b+c} {a,b,c}$$ A bit of history:  The case $a=b=c$ was proved by Dixon in 1891 using trigonometric integrals. He proved the general case 11 years later using other analytical methods.  In 1916, MacMahon proved his master theorem which gives another short analytical proof for the identity. Using the WZ-method, Zeilberger gave a short proof in 1990 (with the aid of his computer). In 2003, Victor Guo gave a short proof using polynomials. But what really interests me are the combinatorial interpretations. Zeilberger gives a proof using sign-reversing involutions in this lecture (starting from 39:30). Does it exist in some paper? I believe he credits it to Foata in this opinion . In this monograph by Foata , there seems to be a combinatorial proof of Dixon's identity and other related identities (pages 37 to 40). I wasn't able to understand the part in pages 37-38, where the following is derived combinatorially:  $$\binom{b+c}{c+k}\binom{c+a}{a+k}\binom{a+b}{b+k}=\sum_{n\ge |k|} \binom{a+b+c-n}{a-n,b-n,c-n,n+k,n-k}$$ Where both sides seem to count directed graphs with the following adjacency matrix: $$\begin{bmatrix} 0 & c+k & b-k \\ c-k & 0 & a+k\\ b+k & a-k & 0 \end{bmatrix}$$ The LHS counts it directly, and the RHS counts it by decomposing by using 5 basic cycles: $1\to 2 \to 1$ (appearing $a-n$ times), $1\to 3 \to 1$ ($b-n$ times), $2\to 3 \to 2$ ($c-n$ times), $1\to 2 \to 3 \to 1$ ($n+k$ times), $1\to 3 \to 2 \to 1$ ($n-k$ times). But I don't really understand how they actually count it. Here's a picture of the relevant pages: Is the paper ""100 years of Dixon's identity"" by James Ward (published in 1991 in the Irish Mathematical Society Bulletin"") available online?","Dixon's Identity states: $$ \sum_{k} (-1)^k\binom {a+b}{b+k}\binom{b+c}{c+k}\binom{c+a}{a+k} = \binom{a+b+c} {a,b,c}$$ A bit of history:  The case $a=b=c$ was proved by Dixon in 1891 using trigonometric integrals. He proved the general case 11 years later using other analytical methods.  In 1916, MacMahon proved his master theorem which gives another short analytical proof for the identity. Using the WZ-method, Zeilberger gave a short proof in 1990 (with the aid of his computer). In 2003, Victor Guo gave a short proof using polynomials. But what really interests me are the combinatorial interpretations. Zeilberger gives a proof using sign-reversing involutions in this lecture (starting from 39:30). Does it exist in some paper? I believe he credits it to Foata in this opinion . In this monograph by Foata , there seems to be a combinatorial proof of Dixon's identity and other related identities (pages 37 to 40). I wasn't able to understand the part in pages 37-38, where the following is derived combinatorially:  $$\binom{b+c}{c+k}\binom{c+a}{a+k}\binom{a+b}{b+k}=\sum_{n\ge |k|} \binom{a+b+c-n}{a-n,b-n,c-n,n+k,n-k}$$ Where both sides seem to count directed graphs with the following adjacency matrix: $$\begin{bmatrix} 0 & c+k & b-k \\ c-k & 0 & a+k\\ b+k & a-k & 0 \end{bmatrix}$$ The LHS counts it directly, and the RHS counts it by decomposing by using 5 basic cycles: $1\to 2 \to 1$ (appearing $a-n$ times), $1\to 3 \to 1$ ($b-n$ times), $2\to 3 \to 2$ ($c-n$ times), $1\to 2 \to 3 \to 1$ ($n+k$ times), $1\to 3 \to 2 \to 1$ ($n-k$ times). But I don't really understand how they actually count it. Here's a picture of the relevant pages: Is the paper ""100 years of Dixon's identity"" by James Ward (published in 1991 in the Irish Mathematical Society Bulletin"") available online?",,"['combinatorics', 'reference-request', 'binomial-coefficients']"
39,Sum of Squares of Harmonic Numbers,Sum of Squares of Harmonic Numbers,,"Let $H_n$ be the $n^{th}$ harmonic number, $$ H_n  = \sum_{i=1}^{n} \frac{1}{i} $$ Question: Calculate the following $$\sum_{j=1}^{n} H_j^2.$$ I have attempted a generating function approach but could not solve this.","Let $H_n$ be the $n^{th}$ harmonic number, $$ H_n  = \sum_{i=1}^{n} \frac{1}{i} $$ Question: Calculate the following $$\sum_{j=1}^{n} H_j^2.$$ I have attempted a generating function approach but could not solve this.",,"['combinatorics', 'summation', 'power-series', 'harmonic-numbers']"
40,Prove that $(mn)!$ is divisible by $(n!)\cdot(m!)^n$,Prove that  is divisible by,(mn)! (n!)\cdot(m!)^n,"Let $m$ be a positive integer and $n$ a nonnegative integer. Prove that $$(n!)\cdot(m!)^n|(mn)!$$ I can prove it using Legendre's Formula , but I have to use the lemma that $$ \dfrac{\displaystyle\left(\sum_{i=1}^na_i\right)!}{\displaystyle\prod_{i=1}^na_i!} \in \mathbb{N} $$ I believe that it can be proved using the lemma, since in this answer of Qiaochu Yuan he has mentioned so at the end of his answer. Any help will be appreciated. Thanks.","Let be a positive integer and a nonnegative integer. Prove that I can prove it using Legendre's Formula , but I have to use the lemma that I believe that it can be proved using the lemma, since in this answer of Qiaochu Yuan he has mentioned so at the end of his answer. Any help will be appreciated. Thanks.",m n (n!)\cdot(m!)^n|(mn)!  \dfrac{\displaystyle\left(\sum_{i=1}^na_i\right)!}{\displaystyle\prod_{i=1}^na_i!} \in \mathbb{N} ,"['combinatorics', 'algebra-precalculus', 'elementary-number-theory', 'divisibility', 'factorial']"
41,How do you prove ${n \choose k}$ is maximum when $k$ is $ \lceil \tfrac n2 \rceil$ or $ \lfloor \tfrac n2\rfloor $?,How do you prove  is maximum when  is  or ?,{n \choose k} k  \lceil \tfrac n2 \rceil  \lfloor \tfrac n2\rfloor ,"How do you prove $n \choose k$ is maximum when $k$ is $\lceil n/2 \rceil$ or $\lfloor n/2 \rfloor$ ? This link provides a proof of sorts but it is not satisfying. From what I understand, it focuses on product pairings present in $k! (n-k)!$ term which are of the form $i \times (i-1)$ . Since these are minimized when $i=n/2$ , we get the result. But what about the reasoning for the rest of the terms?","How do you prove is maximum when is or ? This link provides a proof of sorts but it is not satisfying. From what I understand, it focuses on product pairings present in term which are of the form . Since these are minimized when , we get the result. But what about the reasoning for the rest of the terms?",n \choose k k \lceil n/2 \rceil \lfloor n/2 \rfloor k! (n-k)! i \times (i-1) i=n/2,"['combinatorics', 'inequality', 'optimization', 'binomial-coefficients']"
42,Why is the Derangement Probability so Close to $\frac{1}{e}$?,Why is the Derangement Probability so Close to ?,\frac{1}{e},"A derangement is a permutation $\sigma$ of $\{1,2,3,\dots,n\}$ such that $\sigma(i) \neq i$ for every $i$ .  A common application of inclusion/exclusion in undergraduate combinatorics and probability classes is to compute the number of derangements, and in the process show that the probability a random permutation is a derangement approaches $\frac{1}{e}$ for large $n$ . There's also a ""standard"" intuition for this probability, which goes roughly as follows:  Let $E_i$ be the event that $\sigma(i)=i$ . 1) For a given $i$ , the probability of $E_i$ is exactly $\frac{1}{n}$ . 2) If $n$ is large, than these events should be ""nearly"" independent ( $E_i$ occurring means that $\sigma(i) \neq j$ , making it a tiny bit more likely that $\sigma(j)=j$ , but this shouldn't have much of an effect for large $n$ ), so we'd expect the probability none of the $E_i$ occur to be roughly $\left(1-\frac{1}{n}\right)^n$ . 3) For large $n$ , $\left(1-\frac{1}{n} \right)^n \approx \frac{1}{e}$ . Now the last approximation alone already has an error proportional to $\frac{1}{n}$ .  What's suprising then is that, after working through the inclusion/exclusion , you find that the probability is not just approximately $\frac{1}{e}$ , but incredibly close -- the error is less than $\frac{1}{(n+1)!}$ . Is there some alternative intuitive explanation for the $\frac{1}{e}$ asymptotic probability that gives a sense of why the convergence is so fast?","A derangement is a permutation of such that for every .  A common application of inclusion/exclusion in undergraduate combinatorics and probability classes is to compute the number of derangements, and in the process show that the probability a random permutation is a derangement approaches for large . There's also a ""standard"" intuition for this probability, which goes roughly as follows:  Let be the event that . 1) For a given , the probability of is exactly . 2) If is large, than these events should be ""nearly"" independent ( occurring means that , making it a tiny bit more likely that , but this shouldn't have much of an effect for large ), so we'd expect the probability none of the occur to be roughly . 3) For large , . Now the last approximation alone already has an error proportional to .  What's suprising then is that, after working through the inclusion/exclusion , you find that the probability is not just approximately , but incredibly close -- the error is less than . Is there some alternative intuitive explanation for the asymptotic probability that gives a sense of why the convergence is so fast?","\sigma \{1,2,3,\dots,n\} \sigma(i) \neq i i \frac{1}{e} n E_i \sigma(i)=i i E_i \frac{1}{n} n E_i \sigma(i) \neq j \sigma(j)=j n E_i \left(1-\frac{1}{n}\right)^n n \left(1-\frac{1}{n} \right)^n \approx \frac{1}{e} \frac{1}{n} \frac{1}{e} \frac{1}{(n+1)!} \frac{1}{e}","['combinatorics', 'intuition', 'inclusion-exclusion', 'derangements']"
43,How many triangles are there?,How many triangles are there?,,The question is how many triangles are there in the following picture? I have thought to solve it by creating a formula based on the angles of the lines starting from the bottom of each side. I don't get it right though. Any clues/ideas would be appreciated.,The question is how many triangles are there in the following picture? I have thought to solve it by creating a formula based on the angles of the lines starting from the bottom of each side. I don't get it right though. Any clues/ideas would be appreciated.,,"['geometry', 'combinatorics', 'triangles']"
44,"Placing the integers $\{1,2,\ldots,n\}$ on a circle ( for $n>1$) in some special order",Placing the integers  on a circle ( for ) in some special order,"\{1,2,\ldots,n\} n>1","For which integer $n>1$ can we place the integers $\{1,2,\ldots,n\}$ on a circle (say boundary of $S^1$ ) in some order such that for each $s \in \{1,2,\ldots,\dfrac {n(n+1)}{2}\}$ , there exist a connected subset of the circle on which the sum of the integers placed is exactly $s$?","For which integer $n>1$ can we place the integers $\{1,2,\ldots,n\}$ on a circle (say boundary of $S^1$ ) in some order such that for each $s \in \{1,2,\ldots,\dfrac {n(n+1)}{2}\}$ , there exist a connected subset of the circle on which the sum of the integers placed is exactly $s$?",,['combinatorics']
45,Blocking directed paths on a DAG with a linear number of vertex defects.,Blocking directed paths on a DAG with a linear number of vertex defects.,,"Let $G=(V,E)$ be a directed acyclic graph. Define the set of all directed paths in $G$ by $\Gamma$ . Given a subset $W\subseteq V$ , let $\Gamma_W\subseteq \Gamma$ be the set of all paths $\gamma\in\Gamma$ supported on $V\backslash W$ (i.e all vertices in $\gamma$ belong to $V\backslash W$ ). Now define $l(W)$ to be: $$l(W)=\max_{\gamma\in \Gamma_W} |\gamma|$$ Where $|\gamma|$ is the number of vertices in $\gamma$ . I want to prove (or disprove) the following claim: ${\bf Claim:}$ For every $\epsilon>0$ and every $k>0$ , there are constants $L$ and $N$ such that  for any directed acyclic graph $G=(V, E)$ satisfying $|V|>N$ with the sum of incoming and outgoing degrees bounded by $k$ , there exists a subset $W\subseteq V$ such that $\frac{|W|}{|V|}<\epsilon$ and $l(W)<L$ . The claim is true for directed trees (see edit 1 for a proof) but the same proof idea fails to work in more general DAGs. Moreover, the statement fails to be true if we remove the constant degree requirement for $G$ . Indeed, the maximal topological order on vertices indexed from 1 to n can not be ""blocked"" for any $\epsilon>0$ by any set $W$ of size linear in $n$ . Any direction or idea would be welcome. Edit 1: For trees, a standard proof would go like this: For $0\leq i\leq L-1$ , Define $W_L^i$ to be the set of all vertices reachable from the root with a directed path of length $i \pmod L$ . Since the graph is a tree, any such path is uniquely defined for every vertex and therefore, for a given $L$ , the set $\{W_L^i\}_{0\leq i\leq L-1}$ gives a partition of $V$ . Therefore choosing $L=\frac{1}{\epsilon}$ , there is some $i_0$ such that $|W_L^{i_0}|$ is at most $\frac{|V|}{L}=\epsilon |V|$ . It is left to show that every $W_L^i$ is indeed $L$ -blocking, but this is trivial since any step in a directed path down the tree increases the distance from the root by exactly 1, so the longest path containing no vertices from $W_L^i$ has to be of length at most $L-1$ (Connecting 2 adjacent floors in $W_L^i$ ) Edit 2: In general, the claim is true for any DAG for the special case of $\epsilon = \frac{2k}{2k+1}$ and $L=1$ . To see that consider the following algorithm: 1- choose a vertex $v$ in the graph that still has neighbours. Keep $v$ , and remove all of its neighbours (in both directions) from graph 2 - if any non isolated vertex is left, go back to 1. Otherwise exit. The resulting graph is completely disconnected ( $L=1$ ) and we removed at most an $\epsilon=\frac{2k}{2k+1}$ fraction of vertices from the graph. The claim follows. Edit 3: As Misha Lavrov showed, the previous bound can be made tighter and we can prove the claim for $\epsilon=\frac{k}{k+1}$ . I discovered that this bound is not tight when the DAG has total degree bounded by 3. In this case, I will prove the claim for any $\epsilon>\frac{1}{2}$ where the previous bound is only $\epsilon=\frac{2}{3}$ . Define the in-degree and out-degree of a vertex $v$ in $G$ by $in(v)$ and $out(v)$ respectively. From the assumption, for all $v \in V$ , $in(v)+out(v)\leq 3$ . Define 4 sets: $\{V_i\}_{i=0}^3$ by: $$V_i=\{v\in V | in(v)=i\}$$ Obviously, $\{V_i\}_{i=0}^3$ forms a partition of $V$ . Therefore, either of the sets $V_1$ or $V_2$ has cardinality at most $\frac{n}{2}$ . W.l.o.g, assume it is $V_1$ . Let $G'$ be the subgraph of $G$ induced by $V_2$ . Obviously, for all $v\in V_2$ , $out(v)\leq 1$ and therefore, $G'$ is a disjoint union of directed trees with one vertex sink. Using the proof for trees, for any $\epsilon>0$ ,  we can find a subset $W\subseteq V_2$ such that $\frac{|W|}{|V_2|}<\epsilon$ and $W$ is $\frac{1}{\epsilon}$ -blocking in $G'$ . Finally, define $W'= V_1 \cup W$ . On one hand, $|W'|$ is upper bounded by $(\frac{1}{2}+\epsilon)n$ and on the other hand $W'$ is $(\frac{1}{\epsilon}+2)$ -blocking since a directed path in $G$ can either stay in $V_2$ and get blocked by $W$ or get outside of $V_2$ and either be blocked by $V_1$ or do one last step from $V_0$ , to $V_3$ or both. This proves the claim. PS. Crossposted at MO.","Let be a directed acyclic graph. Define the set of all directed paths in by . Given a subset , let be the set of all paths supported on (i.e all vertices in belong to ). Now define to be: Where is the number of vertices in . I want to prove (or disprove) the following claim: For every and every , there are constants and such that  for any directed acyclic graph satisfying with the sum of incoming and outgoing degrees bounded by , there exists a subset such that and . The claim is true for directed trees (see edit 1 for a proof) but the same proof idea fails to work in more general DAGs. Moreover, the statement fails to be true if we remove the constant degree requirement for . Indeed, the maximal topological order on vertices indexed from 1 to n can not be ""blocked"" for any by any set of size linear in . Any direction or idea would be welcome. Edit 1: For trees, a standard proof would go like this: For , Define to be the set of all vertices reachable from the root with a directed path of length . Since the graph is a tree, any such path is uniquely defined for every vertex and therefore, for a given , the set gives a partition of . Therefore choosing , there is some such that is at most . It is left to show that every is indeed -blocking, but this is trivial since any step in a directed path down the tree increases the distance from the root by exactly 1, so the longest path containing no vertices from has to be of length at most (Connecting 2 adjacent floors in ) Edit 2: In general, the claim is true for any DAG for the special case of and . To see that consider the following algorithm: 1- choose a vertex in the graph that still has neighbours. Keep , and remove all of its neighbours (in both directions) from graph 2 - if any non isolated vertex is left, go back to 1. Otherwise exit. The resulting graph is completely disconnected ( ) and we removed at most an fraction of vertices from the graph. The claim follows. Edit 3: As Misha Lavrov showed, the previous bound can be made tighter and we can prove the claim for . I discovered that this bound is not tight when the DAG has total degree bounded by 3. In this case, I will prove the claim for any where the previous bound is only . Define the in-degree and out-degree of a vertex in by and respectively. From the assumption, for all , . Define 4 sets: by: Obviously, forms a partition of . Therefore, either of the sets or has cardinality at most . W.l.o.g, assume it is . Let be the subgraph of induced by . Obviously, for all , and therefore, is a disjoint union of directed trees with one vertex sink. Using the proof for trees, for any ,  we can find a subset such that and is -blocking in . Finally, define . On one hand, is upper bounded by and on the other hand is -blocking since a directed path in can either stay in and get blocked by or get outside of and either be blocked by or do one last step from , to or both. This proves the claim. PS. Crossposted at MO.","G=(V,E) G \Gamma W\subseteq V \Gamma_W\subseteq \Gamma \gamma\in\Gamma V\backslash W \gamma V\backslash W l(W) l(W)=\max_{\gamma\in \Gamma_W} |\gamma| |\gamma| \gamma {\bf Claim:} \epsilon>0 k>0 L N G=(V, E) |V|>N k W\subseteq V \frac{|W|}{|V|}<\epsilon l(W)<L G \epsilon>0 W n 0\leq i\leq L-1 W_L^i i \pmod L L \{W_L^i\}_{0\leq i\leq L-1} V L=\frac{1}{\epsilon} i_0 |W_L^{i_0}| \frac{|V|}{L}=\epsilon |V| W_L^i L W_L^i L-1 W_L^i \epsilon = \frac{2k}{2k+1} L=1 v v L=1 \epsilon=\frac{2k}{2k+1} \epsilon=\frac{k}{k+1} \epsilon>\frac{1}{2} \epsilon=\frac{2}{3} v G in(v) out(v) v \in V in(v)+out(v)\leq 3 \{V_i\}_{i=0}^3 V_i=\{v\in V | in(v)=i\} \{V_i\}_{i=0}^3 V V_1 V_2 \frac{n}{2} V_1 G' G V_2 v\in V_2 out(v)\leq 1 G' \epsilon>0 W\subseteq V_2 \frac{|W|}{|V_2|}<\epsilon W \frac{1}{\epsilon} G' W'= V_1 \cup W |W'| (\frac{1}{2}+\epsilon)n W' (\frac{1}{\epsilon}+2) G V_2 W V_2 V_1 V_0 V_3","['combinatorics', 'graph-theory', 'directed-graphs']"
46,Prove that $\frac{100!}{50!\cdot2^{50}} \in \Bbb{Z}$,Prove that,\frac{100!}{50!\cdot2^{50}} \in \Bbb{Z},I'm trying to prove that : $$\frac{100!}{50!\cdot2^{50}}$$ is an integer . For the moment I did the following : $$\frac{100!}{50!\cdot2^{50}} = \frac{51 \cdot 52 \cdots 99 \cdot 100}{2^{50}}$$ But it still doesn't quite work out . Hints anyone ? Thanks,I'm trying to prove that : $$\frac{100!}{50!\cdot2^{50}}$$ is an integer . For the moment I did the following : $$\frac{100!}{50!\cdot2^{50}} = \frac{51 \cdot 52 \cdots 99 \cdot 100}{2^{50}}$$ But it still doesn't quite work out . Hints anyone ? Thanks,,['combinatorics']
47,The $5n+1$ Problem,The  Problem,5n+1,"The Collatz Conjecture is a famous conjecture in mathematics that has lasted for over 70 years. It goes as follows: Define $f(n)$ to be as a function on the natural numbers by: $f(n) = n/2$ if $n$ is even and $f(n) = 3n+1$ if $n$ is odd The conjecture is that for all $n \in \mathbb{N}$, $n$ eventually converges under iteration by $f$ to $1$. I was wondering if the ""5n+1"" problem has been solved. This problem is the same as the Collatz problem except that in the above one replaces $3n+1$ with $5n+1$.","The Collatz Conjecture is a famous conjecture in mathematics that has lasted for over 70 years. It goes as follows: Define $f(n)$ to be as a function on the natural numbers by: $f(n) = n/2$ if $n$ is even and $f(n) = 3n+1$ if $n$ is odd The conjecture is that for all $n \in \mathbb{N}$, $n$ eventually converges under iteration by $f$ to $1$. I was wondering if the ""5n+1"" problem has been solved. This problem is the same as the Collatz problem except that in the above one replaces $3n+1$ with $5n+1$.",,"['combinatorics', 'conjectures', 'collatz-conjecture']"
48,Counting bounded integer solutions to $\sum_ia_ix_i\leqq n$,Counting bounded integer solutions to,\sum_ia_ix_i\leqq n,"I want to find the number of nonnegative integer solutions to $$x_1+x_2+x_3+x_4=22$$ which is also the number of combinations with replacement of $22$ items in $4$ types. How do I apply stars and bars for this? What if there is an inequality or the lower bounds on the $x_i$ are not zero? More generally, what do I use if the $x_i$ are multiplied by integer constants, such as in this equation? $$3x_1+2x_2+x_3+x_4=47$$","I want to find the number of nonnegative integer solutions to which is also the number of combinations with replacement of items in types. How do I apply stars and bars for this? What if there is an inequality or the lower bounds on the are not zero? More generally, what do I use if the are multiplied by integer constants, such as in this equation?",x_1+x_2+x_3+x_4=22 22 4 x_i x_i 3x_1+2x_2+x_3+x_4=47,"['combinatorics', 'combinations', 'diophantine-equations', 'integer-partitions', 'faq']"
49,Xmas Maths 2014,Xmas Maths 2014,,"Inspired the various** algebraic X'mas greetings sent to me over the festive period, I thought I would try to devise one of my own. $$\Large \color{red}{\sum_{i=a-1}^{r-1}}\color{green}{\sum_{j=s-1}^{r-1}}\color{orange}{\binom {e-x}{m-x}}\color{red}{\binom ex}\color{orange}{ \binom i{a-1}}\color{green}{\binom j{s-1}}\color{red}{\binom y{\prod_{k=1}^{2014}k}}\\ $$ The colours are purely ornamental! ** Actually there were only two versions: one was an equation with a $\ln$ function and the other required knowledge of Newton's second law; both of these have popped up in various places on web as well.","Inspired the various** algebraic X'mas greetings sent to me over the festive period, I thought I would try to devise one of my own. $$\Large \color{red}{\sum_{i=a-1}^{r-1}}\color{green}{\sum_{j=s-1}^{r-1}}\color{orange}{\binom {e-x}{m-x}}\color{red}{\binom ex}\color{orange}{ \binom i{a-1}}\color{green}{\binom j{s-1}}\color{red}{\binom y{\prod_{k=1}^{2014}k}}\\ $$ The colours are purely ornamental! ** Actually there were only two versions: one was an equation with a $\ln$ function and the other required knowledge of Newton's second law; both of these have popped up in various places on web as well.",,"['combinatorics', 'summation', 'binomial-coefficients', 'recreational-mathematics']"
50,6-letter permutations in MISSISSIPPI [duplicate],6-letter permutations in MISSISSIPPI [duplicate],,"This question already has answers here : How to find the number of $k$-permutations of $n$ objects with $x$ types, and $r_1, r_2, r_3, \cdots , r_x$ = the number of each type of object? (4 answers) Closed 2 years ago . How many 6-letter permutations can be formed using only the letters of the word, MISSISSIPPI ? I understand the trivial case where there are no repeating letters in the word (for arranging smaller words) but I stumble when this isn't satisfied. I'm wondering if there's a simpler way to computing all the possible permutations, as an alternative to manually calculating all the possible 6-letter combinations and summing the corresponding permutations of each. In addition, is there a method to generalize the result based on any P number of letters in a set with repeating letters, to calculate the number of n -letter permutations? Sorry if this question (or similar) has been asked before, but if it has, please link me to the relevant page. I also apologize if the explanation is unclear, or if I've incorrectly used any terminology (I'm only a high-school student.) If so, please comment. :-)","This question already has answers here : How to find the number of $k$-permutations of $n$ objects with $x$ types, and $r_1, r_2, r_3, \cdots , r_x$ = the number of each type of object? (4 answers) Closed 2 years ago . How many 6-letter permutations can be formed using only the letters of the word, MISSISSIPPI ? I understand the trivial case where there are no repeating letters in the word (for arranging smaller words) but I stumble when this isn't satisfied. I'm wondering if there's a simpler way to computing all the possible permutations, as an alternative to manually calculating all the possible 6-letter combinations and summing the corresponding permutations of each. In addition, is there a method to generalize the result based on any P number of letters in a set with repeating letters, to calculate the number of n -letter permutations? Sorry if this question (or similar) has been asked before, but if it has, please link me to the relevant page. I also apologize if the explanation is unclear, or if I've incorrectly used any terminology (I'm only a high-school student.) If so, please comment. :-)",,"['permutations', 'combinatorics']"
51,When is $\binom{n}{k}$ divisible by $n$?,When is  divisible by ?,\binom{n}{k} n,Is there any way of determining if $\binom{n}{k} \equiv 0\pmod{n}$.  Note that I am aware of the case when $n =p$ a prime.  Other than that there does not seem to be any sort of pattern (I checked up to $n=50$).  Are there any known special cases where the problem becomes easier?  As a place to start I was thinking of using $e_p(n!)$ defined as: $$e_p(n!) = \sum_{k=1}^{\infty}\left \lfloor\frac{n}{p^k}\right \rfloor$$ Which counts the exponent of $p$ in $n!$ (Legendre's theorem I believe?) Then knowing the prime factorization of $n$ perhaps we can determine if these primes appear more times in the numerator of $\binom{n}{k}$ than the denominator. Essentially I am looking to see if this method has any traction to it and what other types of research have been done on this problem (along with any proofs of results) before.  Thanks!,Is there any way of determining if $\binom{n}{k} \equiv 0\pmod{n}$.  Note that I am aware of the case when $n =p$ a prime.  Other than that there does not seem to be any sort of pattern (I checked up to $n=50$).  Are there any known special cases where the problem becomes easier?  As a place to start I was thinking of using $e_p(n!)$ defined as: $$e_p(n!) = \sum_{k=1}^{\infty}\left \lfloor\frac{n}{p^k}\right \rfloor$$ Which counts the exponent of $p$ in $n!$ (Legendre's theorem I believe?) Then knowing the prime factorization of $n$ perhaps we can determine if these primes appear more times in the numerator of $\binom{n}{k}$ than the denominator. Essentially I am looking to see if this method has any traction to it and what other types of research have been done on this problem (along with any proofs of results) before.  Thanks!,,"['combinatorics', 'number-theory', 'modular-arithmetic', 'binomial-coefficients', 'divisibility']"
52,Iteratively replacing $3$ chocolates in a box of $10$,Iteratively replacing  chocolates in a box of,3 10,"In the fridge there is a box containing 10 expensive high quality Belgian chocolates, which my mum keeps for visitors. Every day, when mum leaves home for work, I secretly pick 3 chocolates at random, I eat them and replace them with ordinary cheap ones, that have exactly the same wrapping. On the next day I do the same, obviously risking to eat also some of the cheap ones. How many days on average will it take for the full replacement of the expensive chocolates with cheap ones? I would say $10/3$ but this is very simplistic.  Also, the total number of ways to pick 3 chocolates out of 10 is $\binom {10} 3=\frac {10!}{3!7!} = 120$ which means that after 120 days I will have replaced all chocolates but I don't think it is correct. Any help?","In the fridge there is a box containing 10 expensive high quality Belgian chocolates, which my mum keeps for visitors. Every day, when mum leaves home for work, I secretly pick 3 chocolates at random, I eat them and replace them with ordinary cheap ones, that have exactly the same wrapping. On the next day I do the same, obviously risking to eat also some of the cheap ones. How many days on average will it take for the full replacement of the expensive chocolates with cheap ones? I would say but this is very simplistic.  Also, the total number of ways to pick 3 chocolates out of 10 is which means that after 120 days I will have replaced all chocolates but I don't think it is correct. Any help?",10/3 \binom {10} 3=\frac {10!}{3!7!} = 120,['combinatorics']
53,Symmetric polynomials,Symmetric polynomials,,"I've got a seemingly simple question that I've become curious about as a result of supervising some undergraduate research.  Let's suppose we have some sequence of polynomials $f_0, f_1, f_2, \cdots \in \mathbb{Z}[X]$, where $f_0=1$.  Now, define the following sequence of symmetric polynomials on variables $x_1, \ldots x_n$: $$P_m(x_1, \ldots, x_n)=\sum\limits_{m_1+\cdots+m_n=m}f_{m_1}(x_1) \cdots f_{m_n}(x_n)$$ If you want, you can think of this as the coefficient of $y^m$ in the two-variable generating function $\prod\limits_{i=1}^{n}\left(\sum\limits_{j \ge 0}f_j(x_i)y^j\right)$.  Now my question is, if you know $x_1, \ldots, x_n$ are positive integers, and you know the values of $P_m(x_1, \ldots, x_n)$ for $m=0, 1, \ldots$, what conditions need to be true on $f_1, f_2, \ldots$ in order for the values of of $x_1, \ldots, x_n$ to be completely determined (up to ordering)?  I think it's key that we need to work with inputs in $\mathbb{Z}^+$ - if we work over $\mathbb{C}$, the answer may be different (see the edit below). For example, if $f_1(x)=x$, and $f_2=f_3=\cdots=0$, then $P_m$ is just the $m$-th elementary symmetric polynomial $\sigma_m$, and then obviously, $x_1, \ldots, x_n$ are determined by $\sigma_1, \sigma_2, \ldots$, being the roots of the polynomial with coefficients $(-1)^i\sigma_i$.  If $f_i(x)=x^i$ for each $i$, then it's a little less straightforward, but still not hard: $P_m=\sum\limits_{j=1}^{m}(-1)^{j-1}\sigma_j P_{m-j}$, and so we can show by induction on $m$ that $P_1, \ldots, P_m$ together determine $\sigma_1, \ldots, \sigma_m$, and hence, $x_1, \ldots, x_n$ are again determined.  For the general case, we can equivalently ask whether the values of $P_1, P_2, \ldots$ uniquely determine the values of $\sigma_1, \sigma_2, \ldots$ (and this is perhaps a more natural question). As long as the polynomials $f_1$ aren't all constants, I don't, off the top of my head, know any sequences of polynomials $f_1, f_2, \ldots$ for which the values of $P_1, P_2, \ldots$ don't determine $x_1, \ldots, x_n$.  So I'm wondering if it's true given that at least one of the $f_i$'s is nontrivial. EDIT: I feel it's worth pointing out that what I'm asking isn't the same thing as asking that the $P_i$ generate the ring of symmetric polynomials.  For example, if the values of the $P_i$ were to determine the values of $\sigma_1^2, \sigma_2^2, \ldots$, that would determine the values of $\sigma_1, \sigma_2, \ldots$, even if the $P_i$ don't generate the ring.  This is why the condition that the $x_i$'s are positive integers is important.  That said, I don't know the answer over $\mathbb{C}$ either.","I've got a seemingly simple question that I've become curious about as a result of supervising some undergraduate research.  Let's suppose we have some sequence of polynomials $f_0, f_1, f_2, \cdots \in \mathbb{Z}[X]$, where $f_0=1$.  Now, define the following sequence of symmetric polynomials on variables $x_1, \ldots x_n$: $$P_m(x_1, \ldots, x_n)=\sum\limits_{m_1+\cdots+m_n=m}f_{m_1}(x_1) \cdots f_{m_n}(x_n)$$ If you want, you can think of this as the coefficient of $y^m$ in the two-variable generating function $\prod\limits_{i=1}^{n}\left(\sum\limits_{j \ge 0}f_j(x_i)y^j\right)$.  Now my question is, if you know $x_1, \ldots, x_n$ are positive integers, and you know the values of $P_m(x_1, \ldots, x_n)$ for $m=0, 1, \ldots$, what conditions need to be true on $f_1, f_2, \ldots$ in order for the values of of $x_1, \ldots, x_n$ to be completely determined (up to ordering)?  I think it's key that we need to work with inputs in $\mathbb{Z}^+$ - if we work over $\mathbb{C}$, the answer may be different (see the edit below). For example, if $f_1(x)=x$, and $f_2=f_3=\cdots=0$, then $P_m$ is just the $m$-th elementary symmetric polynomial $\sigma_m$, and then obviously, $x_1, \ldots, x_n$ are determined by $\sigma_1, \sigma_2, \ldots$, being the roots of the polynomial with coefficients $(-1)^i\sigma_i$.  If $f_i(x)=x^i$ for each $i$, then it's a little less straightforward, but still not hard: $P_m=\sum\limits_{j=1}^{m}(-1)^{j-1}\sigma_j P_{m-j}$, and so we can show by induction on $m$ that $P_1, \ldots, P_m$ together determine $\sigma_1, \ldots, \sigma_m$, and hence, $x_1, \ldots, x_n$ are again determined.  For the general case, we can equivalently ask whether the values of $P_1, P_2, \ldots$ uniquely determine the values of $\sigma_1, \sigma_2, \ldots$ (and this is perhaps a more natural question). As long as the polynomials $f_1$ aren't all constants, I don't, off the top of my head, know any sequences of polynomials $f_1, f_2, \ldots$ for which the values of $P_1, P_2, \ldots$ don't determine $x_1, \ldots, x_n$.  So I'm wondering if it's true given that at least one of the $f_i$'s is nontrivial. EDIT: I feel it's worth pointing out that what I'm asking isn't the same thing as asking that the $P_i$ generate the ring of symmetric polynomials.  For example, if the values of the $P_i$ were to determine the values of $\sigma_1^2, \sigma_2^2, \ldots$, that would determine the values of $\sigma_1, \sigma_2, \ldots$, even if the $P_i$ don't generate the ring.  This is why the condition that the $x_i$'s are positive integers is important.  That said, I don't know the answer over $\mathbb{C}$ either.",,"['combinatorics', 'symmetric-polynomials']"
54,How to prove that the number $1!+2!+3!+...+n!$ is never square?,How to prove that the number  is never square?,1!+2!+3!+...+n!,How to prove that the number $1!+2!+3!+...+n! \ \forall n \geq 4$ is never square? I was told to count permutations but I cannot figure out what we are permuting.... Thanks!,How to prove that the number $1!+2!+3!+...+n! \ \forall n \geq 4$ is never square? I was told to count permutations but I cannot figure out what we are permuting.... Thanks!,,['combinatorics']
55,How can I learn about generating functions?,How can I learn about generating functions?,,"The intent of this question is to provide a list of learning resources for people who are new to generating functions and would like to learn about them. I'm personally interested in combinatorics, and I sometimes use generating functions in answers to combinatorial questions on stackexchange, but I know many readers are not familiar with these objects.  I hope this list will help those readers and provoke interest in GFs generally. I will provide an answer below, but feel free to edit my answer or provide your own answer.  Initially it will be a short list, but maybe it will grow over time.  Please regard this question and its answers as a community resource. Acknowledgement: In asking this self-answered question I was prompted by helpful advice provided by this discussion on mathematics meta stackexchange, users quid and John Omielan in particular.  Thank you.","The intent of this question is to provide a list of learning resources for people who are new to generating functions and would like to learn about them. I'm personally interested in combinatorics, and I sometimes use generating functions in answers to combinatorial questions on stackexchange, but I know many readers are not familiar with these objects.  I hope this list will help those readers and provoke interest in GFs generally. I will provide an answer below, but feel free to edit my answer or provide your own answer.  Initially it will be a short list, but maybe it will grow over time.  Please regard this question and its answers as a community resource. Acknowledgement: In asking this self-answered question I was prompted by helpful advice provided by this discussion on mathematics meta stackexchange, users quid and John Omielan in particular.  Thank you.",,"['combinatorics', 'generating-functions']"
56,Combinatorial proof of a Stirling number identity.,Combinatorial proof of a Stirling number identity.,,"Consider the identity $$\sum_{k=0}^n (-1)^kk!{n \brace k} = (-1)^n$$ where ${n\brace k}$ is a Stirling number of the second kind. This is slightly reminiscent of the binomial identity $$\sum_{k=0}^n(-1)^k\binom{n}{k} = 0$$ which essentially states that the number of even subsets of a set is equal to the number of odd subsets. Now there is an easy proof of the binomial identity using symmetric differences to biject between even and odd subsets. I am wondering if there is an analogous combinatorial interpretation for the Stirling numbers. The term $k!{n\brace k}$ counts the number of set partitions of an $n$ element set into $k$ ordered parts. Perhaps there is something relating odd ordered partitions with even ordered partitions? As an added note, there is a similar identity $$\sum_{k=1}^n(-1)^k(k-1)!{n\brace k}=0$$ for $n \geq 2$ . A combinatorial interpretation of this one would also be appreciated.","Consider the identity where is a Stirling number of the second kind. This is slightly reminiscent of the binomial identity which essentially states that the number of even subsets of a set is equal to the number of odd subsets. Now there is an easy proof of the binomial identity using symmetric differences to biject between even and odd subsets. I am wondering if there is an analogous combinatorial interpretation for the Stirling numbers. The term counts the number of set partitions of an element set into ordered parts. Perhaps there is something relating odd ordered partitions with even ordered partitions? As an added note, there is a similar identity for . A combinatorial interpretation of this one would also be appreciated.",\sum_{k=0}^n (-1)^kk!{n \brace k} = (-1)^n {n\brace k} \sum_{k=0}^n(-1)^k\binom{n}{k} = 0 k!{n\brace k} n k \sum_{k=1}^n(-1)^k(k-1)!{n\brace k}=0 n \geq 2,"['combinatorics', 'summation', 'combinatorial-proofs', 'stirling-numbers']"
57,Proof/derivation of $\lim\limits_{n\to\infty}{\frac1{2^n}\sum\limits_{k=0}^n\binom{n}{k}\frac{an+bk}{cn+dk}}\stackrel?=\frac{2a+b}{2c+d}$?,Proof/derivation of ?,\lim\limits_{n\to\infty}{\frac1{2^n}\sum\limits_{k=0}^n\binom{n}{k}\frac{an+bk}{cn+dk}}\stackrel?=\frac{2a+b}{2c+d},"I just came up with the following identity while solving some combinatorial problem but not sure if it's correct. I've done some numerical computations and they coincide. $$\lim_{n\to \infty}{\frac{1}{2^n}\sum_{k=0}^{n}\binom{n}{k}\frac{an+bk}{cn+dk}}\;\stackrel?=\;\frac{2a+b}{2c+d}$$ Here $a$, $b$, $c$, and $d$ are reals except that $c$ mustn't $0$ and $2c+d\neq0$. I wish I could explain how I came up with it, but I did nothing but comparing numbers with the answer then formulated the identity, and just did numerical computations.","I just came up with the following identity while solving some combinatorial problem but not sure if it's correct. I've done some numerical computations and they coincide. $$\lim_{n\to \infty}{\frac{1}{2^n}\sum_{k=0}^{n}\binom{n}{k}\frac{an+bk}{cn+dk}}\;\stackrel?=\;\frac{2a+b}{2c+d}$$ Here $a$, $b$, $c$, and $d$ are reals except that $c$ mustn't $0$ and $2c+d\neq0$. I wish I could explain how I came up with it, but I did nothing but comparing numbers with the answer then formulated the identity, and just did numerical computations.",,"['combinatorics', 'limits', 'summation', 'binomial-coefficients']"
58,"Why is a general formula for Kostka numbers ""unlikely"" to exist?","Why is a general formula for Kostka numbers ""unlikely"" to exist?",,"In reference to Stanley's Enumerative Combinatorics Vol. 2: right after he has defined Kostka numbers (section 7.10), he mentions that it is unlikely that a general formula for $K_{\lambda\mu}$ exists, where $K_{\lambda\mu}$ is the number of semistandard Young tableaux of shape $\lambda$ and type $\mu$ with $\lambda\vdash n$ and $\mu$ a weak composition of $n$. Why? In particular, is this an expression of something rigorous, and if so, what?","In reference to Stanley's Enumerative Combinatorics Vol. 2: right after he has defined Kostka numbers (section 7.10), he mentions that it is unlikely that a general formula for $K_{\lambda\mu}$ exists, where $K_{\lambda\mu}$ is the number of semistandard Young tableaux of shape $\lambda$ and type $\mu$ with $\lambda\vdash n$ and $\mu$ a weak composition of $n$. Why? In particular, is this an expression of something rigorous, and if so, what?",,"['combinatorics', 'representation-theory']"
59,Possible Playable Chords on a Guitar,Possible Playable Chords on a Guitar,,"Fingerstyle Guitar Chord Diversity Check Considering a $20$-fret $6$-string acoustic guitar and supposing that the fretting range (inclusive of the fingered notes) for an average hand is $4$ frets in the first $8$ frets, $5$ frets in the $9-14$ fret region and $6$ frets on the remaining of the fretboard, how many combinations of at least $3$ different notes can be strummed if we ignore barring and use at most $4$ fingers to fret? We would have the worst fretting range if our fingered frets involve any of the $3$ prescribed regions down the fretboard (i.e. $8$ fret region, $9−14$ fret region and the remaining of the fretboard). Suppose you decide to fret $12$ on the first string, then, the lowest other fret you can finger is $9$ since fretting $8$ would require a fret range of $5$ while playing $8$ reduces your fret range to $4$ since we consider the worst fret range on overlapping fret regions. In our case, a chord is defined as a collection of $3$ to $6$ distinct notes strummed together. Each chord is unique. For example, fretting $3$ on sixth string, $2$ on the fifth string, $3$ on the first string and strumming all 6 strings is the same as fretting $3$ on sixth string, $2$ on the fifth string, $3$ on the second string and $3$ on the first string and strumming all 6 strings as both would produce a $\text{G}$ chord.","Fingerstyle Guitar Chord Diversity Check Considering a $20$-fret $6$-string acoustic guitar and supposing that the fretting range (inclusive of the fingered notes) for an average hand is $4$ frets in the first $8$ frets, $5$ frets in the $9-14$ fret region and $6$ frets on the remaining of the fretboard, how many combinations of at least $3$ different notes can be strummed if we ignore barring and use at most $4$ fingers to fret? We would have the worst fretting range if our fingered frets involve any of the $3$ prescribed regions down the fretboard (i.e. $8$ fret region, $9−14$ fret region and the remaining of the fretboard). Suppose you decide to fret $12$ on the first string, then, the lowest other fret you can finger is $9$ since fretting $8$ would require a fret range of $5$ while playing $8$ reduces your fret range to $4$ since we consider the worst fret range on overlapping fret regions. In our case, a chord is defined as a collection of $3$ to $6$ distinct notes strummed together. Each chord is unique. For example, fretting $3$ on sixth string, $2$ on the fifth string, $3$ on the first string and strumming all 6 strings is the same as fretting $3$ on sixth string, $2$ on the fifth string, $3$ on the second string and $3$ on the first string and strumming all 6 strings as both would produce a $\text{G}$ chord.",,"['combinatorics', 'music-theory']"
60,Two interview questions,Two interview questions,,"I recently came across two interview questions for admission in B.Math at an university. I gave the two questions a try and want to know if my solutions are correct or not. Q1: Given that $x^4-4x^3+ax^2+bx+1=0$ has all positive roots and $a,b\in\Bbb R$, prove that all the roots are equal. My solution: Let $p,q,r,s$ be the four roots of the given equation. Using Vieta's formulas, we have, $$p+q+r+s=4\quad\textrm{and}\quad pqrs=1$$ Since $p,q,r,s$ are all positive, we have, by the AM-GM inequality, $$\frac{p+q+r+s}{4}\geq\sqrt[4]{pqrs}=\sqrt[4]{1}=1\implies p+q+r+s\geq 4$$ Since we got $p+q+r+s=4$ using Vieta's formulas and knowing that the equality case in AM-GM inequality holds iff $p=q=r=s$, we conclude that all the roots to the given equation are equal. $_\square$ Q2: Without actually computing anything, find the value of $\dbinom{p+q}2-\dbinom p2-\dbinom q2$. My solution: Since it's told not to actually compute anything, I suppose that they were asking for a combinatorial proof. I have the following argument: Suppose we have $p+q$ people in a room with $p$ people in Group 1 and $q$ people in Group 2. Then, $\dbinom{p+q}2$ counts the number of ways we can select two people from the people in the entire room. However, $\dbinom p2$ and $\dbinom q2$ count the number of ways we can select two people from Group 1 and Group 2 respectively. Now, we can select two people from the entire room by either taking two people from Group 1 or taking two people from Group 1 or taking one person from Group 1 and another from Group 2. These are the only possible methods. So, the expression we have counts the number of ways we can select one person from Group 1 containing $p$ people and another person from Group 2 containing $q$ people. By the rule of product, we have $pq$ ways to do this and hence the value of the given expression is $pq$. $_\square$","I recently came across two interview questions for admission in B.Math at an university. I gave the two questions a try and want to know if my solutions are correct or not. Q1: Given that $x^4-4x^3+ax^2+bx+1=0$ has all positive roots and $a,b\in\Bbb R$, prove that all the roots are equal. My solution: Let $p,q,r,s$ be the four roots of the given equation. Using Vieta's formulas, we have, $$p+q+r+s=4\quad\textrm{and}\quad pqrs=1$$ Since $p,q,r,s$ are all positive, we have, by the AM-GM inequality, $$\frac{p+q+r+s}{4}\geq\sqrt[4]{pqrs}=\sqrt[4]{1}=1\implies p+q+r+s\geq 4$$ Since we got $p+q+r+s=4$ using Vieta's formulas and knowing that the equality case in AM-GM inequality holds iff $p=q=r=s$, we conclude that all the roots to the given equation are equal. $_\square$ Q2: Without actually computing anything, find the value of $\dbinom{p+q}2-\dbinom p2-\dbinom q2$. My solution: Since it's told not to actually compute anything, I suppose that they were asking for a combinatorial proof. I have the following argument: Suppose we have $p+q$ people in a room with $p$ people in Group 1 and $q$ people in Group 2. Then, $\dbinom{p+q}2$ counts the number of ways we can select two people from the people in the entire room. However, $\dbinom p2$ and $\dbinom q2$ count the number of ways we can select two people from Group 1 and Group 2 respectively. Now, we can select two people from the entire room by either taking two people from Group 1 or taking two people from Group 1 or taking one person from Group 1 and another from Group 2. These are the only possible methods. So, the expression we have counts the number of ways we can select one person from Group 1 containing $p$ people and another person from Group 2 containing $q$ people. By the rule of product, we have $pq$ ways to do this and hence the value of the given expression is $pq$. $_\square$",,"['combinatorics', 'algebra-precalculus', 'proof-verification', 'combinatorial-proofs']"
61,Calculating the number of possible paths through some squares,Calculating the number of possible paths through some squares,,I'm prepping for the GRE. Would appreciate if someone could explain the right way to solve this problem. It seems simple to me but the site where I found this problem says I'm wrong but doesn't explain their answer. So here is the problem verbatim: Find the number of paths from x to y moving only right (R) or down (D). My answer is 6. What am I missing?? Thanks for any help.,I'm prepping for the GRE. Would appreciate if someone could explain the right way to solve this problem. It seems simple to me but the site where I found this problem says I'm wrong but doesn't explain their answer. So here is the problem verbatim: Find the number of paths from x to y moving only right (R) or down (D). My answer is 6. What am I missing?? Thanks for any help.,,"['combinatorics', 'permutations', 'combinations']"
62,A beautiful game of gold and silver coins,A beautiful game of gold and silver coins,,"A stack of silver coins is on the table. For each step we can either remove a silver coin and write the number of gold coins on a piece of paper, or we can add a gold coin and write the number of silver coins on another piece of paper. We stop when only gold coins are left. Prove that the sums of numbers on these two papers are equal. Tried playing the game and the problem seems right each time,  but I can't proceed from there. Is it done by induction?","A stack of silver coins is on the table. For each step we can either remove a silver coin and write the number of gold coins on a piece of paper, or we can add a gold coin and write the number of silver coins on another piece of paper. We stop when only gold coins are left. Prove that the sums of numbers on these two papers are equal. Tried playing the game and the problem seems right each time,  but I can't proceed from there. Is it done by induction?",,"['combinatorics', 'algebra-precalculus', 'game-theory', 'puzzle']"
63,Exactly half of the elements of $\mathcal{P}(A)$ are odd-sized,Exactly half of the elements of  are odd-sized,\mathcal{P}(A),"Let $A$ be a non-empty set and $n$ be the number of elements in $A$, i.e. $n:=|A|$. I know that the number of elements of the power set of $A$ is $2^n$, i.e.  $|\mathcal{P}(A)|=2^n$. I came across the fact that exactly half of the elements of $\mathcal{P}(A)$ contain an odd number of elements, and half of them an even number of elements. Can someone prove this? Or hint at a proof?","Let $A$ be a non-empty set and $n$ be the number of elements in $A$, i.e. $n:=|A|$. I know that the number of elements of the power set of $A$ is $2^n$, i.e.  $|\mathcal{P}(A)|=2^n$. I came across the fact that exactly half of the elements of $\mathcal{P}(A)$ contain an odd number of elements, and half of them an even number of elements. Can someone prove this? Or hint at a proof?",,"['combinatorics', 'elementary-set-theory']"
64,Using Pigeonhole Principle to prove two numbers in a subset of $[2n]$ divide each other,Using Pigeonhole Principle to prove two numbers in a subset of  divide each other,[2n],"Let $n$ be greater or equal to $1$ , and let $S$ be an $(n+1)$ -subset of $[2n]$ . Prove that there exist two numbers in $S$ such that one divides the other.","Let be greater or equal to , and let be an -subset of . Prove that there exist two numbers in such that one divides the other.",n 1 S (n+1) [2n] S,"['combinatorics', 'pigeonhole-principle']"
65,Can a collection of points be recovered from its multiset of distances?,Can a collection of points be recovered from its multiset of distances?,,"Consider $n$ distinct points $x_1,\dots,x_n$ on $\mathbb{R}$. Associated to these points is the multiset of all distances $d(x_i,x_j)$ between two points. Suppose one is only handed this multiset (you do not know the corresponding indices). Does this allow one to uniquely recover the original points up to reflection and translation?","Consider $n$ distinct points $x_1,\dots,x_n$ on $\mathbb{R}$. Associated to these points is the multiset of all distances $d(x_i,x_j)$ between two points. Suppose one is only handed this multiset (you do not know the corresponding indices). Does this allow one to uniquely recover the original points up to reflection and translation?",,"['combinatorics', 'discrete-mathematics', 'metric-spaces', 'recreational-mathematics']"
66,Extended stars-and-bars problem(where the upper limit of the variable is bounded),Extended stars-and-bars problem(where the upper limit of the variable is bounded),,"The problem of counting the solutions $(a_1,a_2,\ldots,a_n)$ with integer $a_i\geq0$ for $i\in\{1,2,\ldots,n\}$ such that $$a_1+a_2+a_3+\ldots+a_n=N$$ can be solved with a stars-and-bars argument. What is the solution if one adds the constraint that $a_i\leq r_{i}$ for certain integers $r_{1},\ldots,r_n$ ? e.g. for $n=3$ , $N=6$ and $(r_1,r_2,r_3)=(3,3,2)$ , the tuple $(a_1,a_2,a_3)=(2,3,1)$ is a solution, but $(2,1,3)$ is not a solution because $a_{3}=3>2=r_3$ .","The problem of counting the solutions with integer for such that can be solved with a stars-and-bars argument. What is the solution if one adds the constraint that for certain integers ? e.g. for , and , the tuple is a solution, but is not a solution because .","(a_1,a_2,\ldots,a_n) a_i\geq0 i\in\{1,2,\ldots,n\} a_1+a_2+a_3+\ldots+a_n=N a_i\leq r_{i} r_{1},\ldots,r_n n=3 N=6 (r_1,r_2,r_3)=(3,3,2) (a_1,a_2,a_3)=(2,3,1) (2,1,3) a_{3}=3>2=r_3","['combinatorics', 'multisets']"
67,An identity for the factorial function,An identity for the factorial function,,"A friend of mine was doodling with numbers arranged somewhat reminiscent of Pascal's Triangle, where the first row was $ 1^{n-1} \ \  2^{n-1} \ \cdots \ n^{n-1} $ and subsequent rows were computed by taking the difference of adjacent terms. He conjectured that the number we get at the end is $ n! $ but I've not been able to prove or disprove this. The first few computations are given below: $$      \begin{pmatrix}     1 \\     \end{pmatrix} $$ $$     \begin{pmatrix}     1   &     & 2   \\         & 1   &     \\     \end{pmatrix} $$ $$         \begin{pmatrix}         1   &     & 4   &     & 9   \\             & 3   &     & 5   &     \\             &     & 2   &     &     \\         \end{pmatrix} $$ $$         \begin{pmatrix}         1   &     & 8   &     & 27  &     & 64  \\             & 7   &     & 19  &     & 37  &     \\             &     & 12  &     & 18  &     &     \\             &     &     & 6   &     &     &     \\         \end{pmatrix} $$ $$ \newcommand\pad[1]{\rlap{#1}\phantom{625}}         \begin{pmatrix}         1   &     & 16  &     & 81  &     & 256 &     & 625 \\             & 15  &     & 65  &     & 175 &     & 369 &     \\             &     & 50  &     & 110 &     & 194 &     &     \\             &     &     & 60  &     & 84  &     &     &     \\             &     &     &     & 24  &     &     &     &     \\         \end{pmatrix} $$ I attempted to write down the general term and tried to reduce that to the required form. The general term worked out as $$        \sum_{i=0}^n (-1)^{n-i} \binom{n}{i} (i+1)^{n}. $$ I tried applying various identities of the binomial coefficients but I'm barely making any progress. Any help would be appreciated. Small note : If I instead start with the first row as $ 0^{n} \ \  1^{n} \ \cdots \ n^{n} $ then I still get $n!$ at the end of the computation, and the general formula in this case works out as $$        \sum_{i=0}^n (-1)^{n-i} \binom{n}{i} i^{n}. $$ In fact, we can start with any $n$ consecutive natural numbers, each raised to the $(n-1)$th power, and we still get $n!$ at the end of the computation.","A friend of mine was doodling with numbers arranged somewhat reminiscent of Pascal's Triangle, where the first row was $ 1^{n-1} \ \  2^{n-1} \ \cdots \ n^{n-1} $ and subsequent rows were computed by taking the difference of adjacent terms. He conjectured that the number we get at the end is $ n! $ but I've not been able to prove or disprove this. The first few computations are given below: $$      \begin{pmatrix}     1 \\     \end{pmatrix} $$ $$     \begin{pmatrix}     1   &     & 2   \\         & 1   &     \\     \end{pmatrix} $$ $$         \begin{pmatrix}         1   &     & 4   &     & 9   \\             & 3   &     & 5   &     \\             &     & 2   &     &     \\         \end{pmatrix} $$ $$         \begin{pmatrix}         1   &     & 8   &     & 27  &     & 64  \\             & 7   &     & 19  &     & 37  &     \\             &     & 12  &     & 18  &     &     \\             &     &     & 6   &     &     &     \\         \end{pmatrix} $$ $$ \newcommand\pad[1]{\rlap{#1}\phantom{625}}         \begin{pmatrix}         1   &     & 16  &     & 81  &     & 256 &     & 625 \\             & 15  &     & 65  &     & 175 &     & 369 &     \\             &     & 50  &     & 110 &     & 194 &     &     \\             &     &     & 60  &     & 84  &     &     &     \\             &     &     &     & 24  &     &     &     &     \\         \end{pmatrix} $$ I attempted to write down the general term and tried to reduce that to the required form. The general term worked out as $$        \sum_{i=0}^n (-1)^{n-i} \binom{n}{i} (i+1)^{n}. $$ I tried applying various identities of the binomial coefficients but I'm barely making any progress. Any help would be appreciated. Small note : If I instead start with the first row as $ 0^{n} \ \  1^{n} \ \cdots \ n^{n} $ then I still get $n!$ at the end of the computation, and the general formula in this case works out as $$        \sum_{i=0}^n (-1)^{n-i} \binom{n}{i} i^{n}. $$ In fact, we can start with any $n$ consecutive natural numbers, each raised to the $(n-1)$th power, and we still get $n!$ at the end of the computation.",,['combinatorics']
68,Bruteforcing a keypad lock,Bruteforcing a keypad lock,,"A particular lock at my university has a keypad with the digits 1-5 on it. When pressed in the correct permutation of those five digits, the lock will open. Obviously, since there are only 120 permutations, we can bruteforce the lock in 600 presses. But we can do better! The sequence 1234512 actually tests three distinct sequences with only seven presses - 12345 , 23451 , and 34512 . What's the fastest strategy to bruteforce this lock? (and for bonus points, other locks with more numbers, longer passcodes, etc.) (I've taken a few stabs at this problem with no progress to speak of - particularly, De Bruijn sequences are not directly relevant here)","A particular lock at my university has a keypad with the digits 1-5 on it. When pressed in the correct permutation of those five digits, the lock will open. Obviously, since there are only 120 permutations, we can bruteforce the lock in 600 presses. But we can do better! The sequence 1234512 actually tests three distinct sequences with only seven presses - 12345 , 23451 , and 34512 . What's the fastest strategy to bruteforce this lock? (and for bonus points, other locks with more numbers, longer passcodes, etc.) (I've taken a few stabs at this problem with no progress to speak of - particularly, De Bruijn sequences are not directly relevant here)",,"['combinatorics', 'permutations', 'puzzle']"
69,Purely combinatorial proof that$ (e^x)' = e^x$,Purely combinatorial proof that, (e^x)' = e^x,"At the beginning of Week 300 of John Baez's blog , Baez gives a proof that the ""number"" of finite sets (more specifically, the cardinality of the groupoid of all finite sets, where an object in the groupoid counts as $1/n!$ if it has $n!$ symmetries) equals $e$. He then says that this leads to a purely combinatorial proof that $e^x$ is its own derivative. Can anyone explain the purely combinatorial proof?","At the beginning of Week 300 of John Baez's blog , Baez gives a proof that the ""number"" of finite sets (more specifically, the cardinality of the groupoid of all finite sets, where an object in the groupoid counts as $1/n!$ if it has $n!$ symmetries) equals $e$. He then says that this leads to a purely combinatorial proof that $e^x$ is its own derivative. Can anyone explain the purely combinatorial proof?",,"['combinatorics', 'groupoids']"
70,a problem from 1977 all Soviet Union Mathematical Olympiad,a problem from 1977 all Soviet Union Mathematical Olympiad,,"Seven dwarfs are sitting at a round table. Each has a cup, and some cups contain milk. Each dwarf in turn pours all his milk into the other six cups, dividing it equally among them. After the seventh dwarf has done this, they find that each cup again contains its initial quantity of milk. How much milk does each cup contain, if there were 42 ounces of milk altogether? The problem can be found here Futility Closet","Seven dwarfs are sitting at a round table. Each has a cup, and some cups contain milk. Each dwarf in turn pours all his milk into the other six cups, dividing it equally among them. After the seventh dwarf has done this, they find that each cup again contains its initial quantity of milk. How much milk does each cup contain, if there were 42 ounces of milk altogether? The problem can be found here Futility Closet",,['combinatorics']
71,How many nodes in the smallest $k$-dense graph?,How many nodes in the smallest -dense graph?,k,"Let's call a directed graph $k$ -dense if: Each node has exactly two children (outgoing neighbors); Each two nodes have at least three different children (besides themselves); Each three nodes have at least four different children (besides themselves); ... Each $k$ nodes have at least $k+1$ different children (besides themselves); What is the smallest number of nodes required for a $k$ -dense graph? Here are some special cases. For $k=1$ , the smallest number of nodes is $3$ : 1->[2,3],   2->[3,1],   3->[1,2] For $k=2$ , the smallest number of nodes is $7$ . To see this we can build the graph greedily based on the following constraint: a node's child must be different than its parent(s) and is sibling(s). Why? Because a node and its parent together must have three children besides themselves. $1$ has two children: call them $2$ and $3$ . $2$ must have two children different than its parent ( $1$ ) and sibling ( $3$ ): call them $4$ and $5$ . $3$ must have two children different than its parent ( $1$ ) and sibling ( $2$ ). The first can be $4$ . Now, $3$ and $2$ together have only two children besides themselves ( $4$ and $5$ ), so $3$ must have another different child - call it $6$ . $4$ must have two children different than its parents ( $2$ and $3$ ) and siblings ( $5$ and $6$ ). The first can be $1$ and the second must be new - call it $7$ . $5$ must have two children different than its parent ( $2$ ) and siblings ( $4$ ). The first can be $1$ . The second cannot be one of $1$ 's children ( $2$ and $3$ ) or siblings ( $7$ ) so it must be $6$ . $6$ must have two children different than its parents ( $3$ and $5$ ) and siblings ( $4$ and $1$ ). These must be $2$ and $7$ . $7$ must have two children different than its parents ( $4$ and $6$ ) and siblings ( $2$ and $1$ ). These must be $3$ and $5$ . All in all, we have the following $2$ -dense graph with $n=7$ nodes: 1->[2,3]  2->[4,5]  3->[4,6]  4->[1,7]  5->[1,6]  6->[2,7]  7->[3,5] For $k=3$ , I used a similar greedy algorithm (with more constraints) to construct the following graph: 1->[2,3]    2->[4,5]    3->[6,7]    4->[6,8]     5->[7,9]  6->[10,11]  7->[12,13]  8->[1,9]    9->[10,14]  10->[2,12]   11->[1,13]  12->[8,15]  13->[4,14]  14->[3,15]   15->[5,11] I used a computer program to check all possibilities with at most $14$ nodes, and found none, so (assuming my program is correct) $n=15$ is the minimum number required for $k=3$ . This hints that the minimum number of nodes in a $k$ -dense graph should be: $2^{k+1}-1$ . Is this true? What is the smallest number of nodes required for general $k$ ? UPDATE 1: I have just learned about vertex expansion . It seems closely related but I am still not sure how exactly.","Let's call a directed graph -dense if: Each node has exactly two children (outgoing neighbors); Each two nodes have at least three different children (besides themselves); Each three nodes have at least four different children (besides themselves); ... Each nodes have at least different children (besides themselves); What is the smallest number of nodes required for a -dense graph? Here are some special cases. For , the smallest number of nodes is : 1->[2,3],   2->[3,1],   3->[1,2] For , the smallest number of nodes is . To see this we can build the graph greedily based on the following constraint: a node's child must be different than its parent(s) and is sibling(s). Why? Because a node and its parent together must have three children besides themselves. has two children: call them and . must have two children different than its parent ( ) and sibling ( ): call them and . must have two children different than its parent ( ) and sibling ( ). The first can be . Now, and together have only two children besides themselves ( and ), so must have another different child - call it . must have two children different than its parents ( and ) and siblings ( and ). The first can be and the second must be new - call it . must have two children different than its parent ( ) and siblings ( ). The first can be . The second cannot be one of 's children ( and ) or siblings ( ) so it must be . must have two children different than its parents ( and ) and siblings ( and ). These must be and . must have two children different than its parents ( and ) and siblings ( and ). These must be and . All in all, we have the following -dense graph with nodes: 1->[2,3]  2->[4,5]  3->[4,6]  4->[1,7]  5->[1,6]  6->[2,7]  7->[3,5] For , I used a similar greedy algorithm (with more constraints) to construct the following graph: 1->[2,3]    2->[4,5]    3->[6,7]    4->[6,8]     5->[7,9]  6->[10,11]  7->[12,13]  8->[1,9]    9->[10,14]  10->[2,12]   11->[1,13]  12->[8,15]  13->[4,14]  14->[3,15]   15->[5,11] I used a computer program to check all possibilities with at most nodes, and found none, so (assuming my program is correct) is the minimum number required for . This hints that the minimum number of nodes in a -dense graph should be: . Is this true? What is the smallest number of nodes required for general ? UPDATE 1: I have just learned about vertex expansion . It seems closely related but I am still not sure how exactly.",k k k+1 k k=1 3 k=2 7 1 2 3 2 1 3 4 5 3 1 2 4 3 2 4 5 3 6 4 2 3 5 6 1 7 5 2 4 1 1 2 3 7 6 6 3 5 4 1 2 7 7 4 6 2 1 3 5 2 n=7 k=3 14 n=15 k=3 k 2^{k+1}-1 k,"['combinatorics', 'graph-theory', 'directed-graphs']"
72,When can we quit a game of War?,When can we quit a game of War?,,"Consider the game of War. (The rules are below.) It would be nice to be able to end the game early. Suppose, for example, one player has 50 of the 52 cards. It is very likely that they're going to win. Without knowing what's in their hand, [1] can we say how likely it is that they're going to win? More generally, what is the likelihood of a win for a player once they have $n$ of the 52 cards? I'm looking for a formula. However, I ran a simulation, and will share the results in case it helps someone find a formula (and for general interest). I used war.pl (from version 1.45 of the Games::Cards Perl module) to play 1,000,000 games of war. [2] For each ( $i$ th) game, I noted the greatest number $m_i$ of cards held by the loser at any time during the game. Then, for each integer $n\in[27,52]$ , I found the number $w$ of games for which $m_i<n$ . [3] Those results are: cards n   games w      27    117488      28    202416      29    280208      30    332080      31    396849      32    439204      33    502378      34    536453      35    594499      36    621622      37    675878      38    697617      39    747468      40    764932      41    811182      42    825481      43    867215      44    878880      45    917070      46    925920      47    959246      48    965522      49    987942      50    989722      51    999968      52   1000000 Rules of War: You start with a standard 52-card deck, shuffled, and two players. Distribute 26 cards to each player. Start of a round: Each player displays their top card; the higher rank wins the round, and proceed to the ""Disposition of a round"" step. If there's a tie, proceed to the next step: Each player displays four more cards off the top. Among the respective last cards displayed by each player, the higher rank wins the round, and proceed to the ""Disposition of a round"" step. If there's a tie, repeat this step. If a player has run out of cards, their last card is always the one to compare to the other player's, no matter how many times the other player displays four more cards. If both players have run out of cards and there's a tie, the game is over: it's a draw. [4] Disposition of a round: The winner of the round takes all the cards that have played this round and puts them at the bottom of their set of cards. Note the ambiguity in this last step — I haven't said what order the player should take them in. Indeed, in my experience playing War, there is no rule, and each player can do what they want, including taking them in differing orders during different rounds. For the purposes of this question, I'd be happy with an answer that answers the question according to any rule of your choosing. I don't know what rules war.pl uses (I didn't trace through its dependencies), and you should feel free to use those rules instead of my own. [1] This is unlikely, but let's assume it anyway. [2] I edited the script to not give up after any finite number of turns, but every game ended anyway. I also edited it so it would give me the information noted in the text above. (See the next footnote.) But I didn't change the rules it used for the game. [3] In case anyone is wondering (or finds a bug), here's the script I used. To war.pl I added the line map {$size[$_] = $Hands[$_]->size if $size[$_] < $Hands[$_]->size} keys @Hands to the start of each turn and print $size[$other[$winner]] to sub win . Then in a separate script I collected the $m_i$ s by for (1..1_000_000) {my $score = `perl war.pl`; $scores{$score}++;} and displayed the $w$ s by $\=$/;for my $score (sort{$a<=>$b} keys %scores) {print (($score+1) . ' ' . ((sum0 map { ($_<=$score) * $scores{$_} } keys %scores) / sum0 values %scores))} . [4] I made that rule up for the purposes of this question, so the game is well defined. I don't think it has ever actually come up in my years of playing War, and I don't know what I would do if it did. If you prefer to use a different rule in answering this question, by all means do so.","Consider the game of War. (The rules are below.) It would be nice to be able to end the game early. Suppose, for example, one player has 50 of the 52 cards. It is very likely that they're going to win. Without knowing what's in their hand, [1] can we say how likely it is that they're going to win? More generally, what is the likelihood of a win for a player once they have of the 52 cards? I'm looking for a formula. However, I ran a simulation, and will share the results in case it helps someone find a formula (and for general interest). I used war.pl (from version 1.45 of the Games::Cards Perl module) to play 1,000,000 games of war. [2] For each ( th) game, I noted the greatest number of cards held by the loser at any time during the game. Then, for each integer , I found the number of games for which . [3] Those results are: cards n   games w      27    117488      28    202416      29    280208      30    332080      31    396849      32    439204      33    502378      34    536453      35    594499      36    621622      37    675878      38    697617      39    747468      40    764932      41    811182      42    825481      43    867215      44    878880      45    917070      46    925920      47    959246      48    965522      49    987942      50    989722      51    999968      52   1000000 Rules of War: You start with a standard 52-card deck, shuffled, and two players. Distribute 26 cards to each player. Start of a round: Each player displays their top card; the higher rank wins the round, and proceed to the ""Disposition of a round"" step. If there's a tie, proceed to the next step: Each player displays four more cards off the top. Among the respective last cards displayed by each player, the higher rank wins the round, and proceed to the ""Disposition of a round"" step. If there's a tie, repeat this step. If a player has run out of cards, their last card is always the one to compare to the other player's, no matter how many times the other player displays four more cards. If both players have run out of cards and there's a tie, the game is over: it's a draw. [4] Disposition of a round: The winner of the round takes all the cards that have played this round and puts them at the bottom of their set of cards. Note the ambiguity in this last step — I haven't said what order the player should take them in. Indeed, in my experience playing War, there is no rule, and each player can do what they want, including taking them in differing orders during different rounds. For the purposes of this question, I'd be happy with an answer that answers the question according to any rule of your choosing. I don't know what rules war.pl uses (I didn't trace through its dependencies), and you should feel free to use those rules instead of my own. [1] This is unlikely, but let's assume it anyway. [2] I edited the script to not give up after any finite number of turns, but every game ended anyway. I also edited it so it would give me the information noted in the text above. (See the next footnote.) But I didn't change the rules it used for the game. [3] In case anyone is wondering (or finds a bug), here's the script I used. To war.pl I added the line map {$size[$_] = $Hands[$_]->size if $size[$_] < $Hands[$_]->size} keys @Hands to the start of each turn and print $size[$other[$winner]] to sub win . Then in a separate script I collected the s by for (1..1_000_000) {my $score = `perl war.pl`; $scores{$score}++;} and displayed the s by $\=$/;for my $score (sort{$a<=>$b} keys %scores) {print (($score+1) . ' ' . ((sum0 map { ($_<=$score) * $scores{$_} } keys %scores) / sum0 values %scores))} . [4] I made that rule up for the purposes of this question, so the game is well defined. I don't think it has ever actually come up in my years of playing War, and I don't know what I would do if it did. If you prefer to use a different rule in answering this question, by all means do so.","n i m_i n\in[27,52] w m_i<n m_i w","['combinatorics', 'card-games']"
73,"How many positive integers $< 1{,}000{,}000$ contain the digit $2$?",How many positive integers  contain the digit ?,"< 1{,}000{,}000 2","How many positive integers less than $1{,}000{,}000$ have the digit $2$ in them? I could determine it by summing it in terms of the number of decimal places, i.e. between $999{,}999$ and $100{,}000$, etc. Then to determine the number of numbers between $999{,}999$ and $100{,}000$ that have the digit $2$ in them would be $9^5$. Is this correct, or am I miscounting?","How many positive integers less than $1{,}000{,}000$ have the digit $2$ in them? I could determine it by summing it in terms of the number of decimal places, i.e. between $999{,}999$ and $100{,}000$, etc. Then to determine the number of numbers between $999{,}999$ and $100{,}000$ that have the digit $2$ in them would be $9^5$. Is this correct, or am I miscounting?",,['combinatorics']
74,Good textbooks on combinatorics for self-study [duplicate],Good textbooks on combinatorics for self-study [duplicate],,This question already has answers here : Good Book On Combinatorics (22 answers) Closed 2 years ago . Can anyone recommend a good introductory textbook on analytic combinatorics for self studying? It should be for a first year graduate student.,This question already has answers here : Good Book On Combinatorics (22 answers) Closed 2 years ago . Can anyone recommend a good introductory textbook on analytic combinatorics for self studying? It should be for a first year graduate student.,,"['combinatorics', 'reference-request', 'book-recommendation']"
75,Intuitive explanation of binomial coefficient,Intuitive explanation of binomial coefficient,,"We know that $$\dbinom{n}r = \dfrac{n!}{(n-r)!r!}$$ An intuitive explanation of the formula is that, if I partition the total number of permutations of objects by $r!$, and choose one member of each partition, then no similarly ordered pattern will be registered more than once. Is there a more intuitive explanation than this?","We know that $$\dbinom{n}r = \dfrac{n!}{(n-r)!r!}$$ An intuitive explanation of the formula is that, if I partition the total number of permutations of objects by $r!$, and choose one member of each partition, then no similarly ordered pattern will be registered more than once. Is there a more intuitive explanation than this?",,"['combinatorics', 'permutations', 'binomial-coefficients']"
76,Is this math game always winnable?,Is this math game always winnable?,,"Kent Haines describes the game of Integer Solitaire , which I find to be excellent for young kids learning arithmetic. I'm sure they will be motivated by this game to get a lot of practice. Kent asks a question about his game, which I find very interesting, and so I am asking here, in the hopes that Math.SE might be able to answer. The child draws 18 cards from an ordinary deck of cards, and then regards the cards to have values Ace = 1, 2, 3, ..., Jack = 11, Queen = 12, King = 13, except that Black means a positive value and Red means a negative value. Using 14 of the 18, the child seeks to find solutions of four equations: For example, a successful solution would look like: Question. Does every set of 18 cards admit a solution? Kent Haines says, ""I have no idea whether all combinations of 18 cards are solvable in this game. But I have played this game for five years with dozens of students, and I have yet to see a combination of 18 cards that is unsolvable."" Follow up Question. In the event that the answer is negative, what is the probability of having a winning set? For the follow up question, it may be that an exact answer is out of reach, but bounds on the probability would be welcome.","Kent Haines describes the game of Integer Solitaire , which I find to be excellent for young kids learning arithmetic. I'm sure they will be motivated by this game to get a lot of practice. Kent asks a question about his game, which I find very interesting, and so I am asking here, in the hopes that Math.SE might be able to answer. The child draws 18 cards from an ordinary deck of cards, and then regards the cards to have values Ace = 1, 2, 3, ..., Jack = 11, Queen = 12, King = 13, except that Black means a positive value and Red means a negative value. Using 14 of the 18, the child seeks to find solutions of four equations: For example, a successful solution would look like: Question. Does every set of 18 cards admit a solution? Kent Haines says, ""I have no idea whether all combinations of 18 cards are solvable in this game. But I have played this game for five years with dozens of students, and I have yet to see a combination of 18 cards that is unsolvable."" Follow up Question. In the event that the answer is negative, what is the probability of having a winning set? For the follow up question, it may be that an exact answer is out of reach, but bounds on the probability would be welcome.",,"['combinatorics', 'card-games']"
77,Each person has at most 3 enemies in a group. Show that we can separate them into two groups where a person will have at most one enemy in the group.,Each person has at most 3 enemies in a group. Show that we can separate them into two groups where a person will have at most one enemy in the group.,,"The question that I saw is as follows: In the Parliament of Sikinia, each member has at most three enemies. Prove that the house can be separated into two houses, so that each member has at most one enemy in his own house. I built a graph where each person corresponds to a vertex and there is an edge between them if the two are enemies. Then I tried to color the vertices of the graph using two colors and remove edges that were between vertices of different colors. The goal is to arrive at a graph with max degree 1. I tried a couple of examples. It seems to workout fine, but I don't know how to prove it.","The question that I saw is as follows: In the Parliament of Sikinia, each member has at most three enemies. Prove that the house can be separated into two houses, so that each member has at most one enemy in his own house. I built a graph where each person corresponds to a vertex and there is an edge between them if the two are enemies. Then I tried to color the vertices of the graph using two colors and remove edges that were between vertices of different colors. The goal is to arrive at a graph with max degree 1. I tried a couple of examples. It seems to workout fine, but I don't know how to prove it.",,"['combinatorics', 'graph-theory', 'algorithms', 'puzzle', 'formal-proofs']"
78,Simplifying Catalan number recurrence relation,Simplifying Catalan number recurrence relation,,"While solving a problem, I reduced it in the form of the following recurrence relation. $ C_{0} = 1, C_{n} =  \displaystyle\sum_{i=0}^{n - 1} C_{i}C_{n - i - 1} $ However https://en.wikipedia.org/wiki/Catalan_number tells me, this is the recurrence relation for catalan numbers and it can be further simplified as, $ C_{0} = 1, C_{n} = \displaystyle\frac {2(2n - 1)}{n + 1} C_{n - 1}$ How can I derive the second relationship from the first one ? One way is to prove it is by induction, but we don't know the simplified recurrence so far.","While solving a problem, I reduced it in the form of the following recurrence relation. $ C_{0} = 1, C_{n} =  \displaystyle\sum_{i=0}^{n - 1} C_{i}C_{n - i - 1} $ However https://en.wikipedia.org/wiki/Catalan_number tells me, this is the recurrence relation for catalan numbers and it can be further simplified as, $ C_{0} = 1, C_{n} = \displaystyle\frac {2(2n - 1)}{n + 1} C_{n - 1}$ How can I derive the second relationship from the first one ? One way is to prove it is by induction, but we don't know the simplified recurrence so far.",,"['combinatorics', 'computer-science', 'catalan-numbers']"
79,What is the intuition behind generating functions? What makes them valuable?,What is the intuition behind generating functions? What makes them valuable?,,"I'm sorry if this question makes no sense. I have been reading generatingfunctionology and I have been able to solve the problems in the first chapters and I understand the mechanism I have to follow to use generating functions to obtain closed formulas for sequences given generating functions. I don't really understand what is going on behind the obvious. It just sort of seems like magic to me that generating functions let us ""solve"" recurrence relations. What is it about placing the terms into an infinite series that makes it such a valuable asset?","I'm sorry if this question makes no sense. I have been reading generatingfunctionology and I have been able to solve the problems in the first chapters and I understand the mechanism I have to follow to use generating functions to obtain closed formulas for sequences given generating functions. I don't really understand what is going on behind the obvious. It just sort of seems like magic to me that generating functions let us ""solve"" recurrence relations. What is it about placing the terms into an infinite series that makes it such a valuable asset?",,"['combinatorics', 'intuition', 'generating-functions']"
80,Six Frogs - Puzzle (order reversal using special transpositions),Six Frogs - Puzzle (order reversal using special transpositions),,"I had come across a puzzle: The six educated frogs in the illustration are trained to reverse their order, so that their numbers shall read 6, 5, 4, 3, 2, 1, with the blank square in its present position.    They can jump to the next square (if vacant) or leap over one frog to the next square beyond (if vacant), just as we move in the game of draughts, and can go backwards or forwards at pleasure. Can you show how they perform their feat in the fewest possible moves? It is quite easy, so when you have done it add a seventh frog to the right and try again.    Then add more frogs until you are able to give the shortest solution for any number.    For it can always be done, with that single vacant square, no matter how many frogs there are. Answer: Move the frogs in the following order: 2, 4, 6, 5, 3, 1 (repeat these moves in the same order twice more), 2, 4, 6.    This is a solution in twenty-one moves - the fewest possible. If $n$, the number of frogs, be even, we require $\frac{n^2+n}{2}$ moves, of which $\frac{n^2-n}{2}$ will be leaps and $n$ simple moves. If $n$ be odd, we shall need $\frac{n^2+3n}{2}-4$ moves, of which $\frac{n^2-n}{2}$ will be leaps and $2n-4$ simple moves. In the even cases write, for the moves, all the even numbers in ascending order and the odd numbers in descending order.    This series must be repeated $\frac{1}{2}n$ times and followed by the even numbers in ascending order once only.    Thus the solution for 14 frogs will be (2, 4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 3, 1) repeated 7 times and followed by 2, 4, 6, 8, 10, 12, 14 = 105 moves. In the odd cases, write the even numbers in ascending order and the odd numbers in descending order, repeat this series $\frac{1}{2}(n-1)$ times, follow with the even numbers in ascending order (omitting $n-1$), the odd numbers in descending order (omitting 1), and conclude with all the numbers (odd and even) in their natural order (omitting 1 and n).    Thus for 11 frogs: (2, 4, 6, 8, 10, 11, 9, 7, 5, 3, 1) repeated 5 times, 2, 4, 6, 8, 11, 9, 7, 5, 3, and 2, 3, 4, 5, 6, 7, 8, 9, 10 = 73 moves. ( source ) which I had tried to solve but could not find the reasoning behind the moves used in the solution could anybody tell how to handle this type of puzzles without hit and trial?","I had come across a puzzle: The six educated frogs in the illustration are trained to reverse their order, so that their numbers shall read 6, 5, 4, 3, 2, 1, with the blank square in its present position.    They can jump to the next square (if vacant) or leap over one frog to the next square beyond (if vacant), just as we move in the game of draughts, and can go backwards or forwards at pleasure. Can you show how they perform their feat in the fewest possible moves? It is quite easy, so when you have done it add a seventh frog to the right and try again.    Then add more frogs until you are able to give the shortest solution for any number.    For it can always be done, with that single vacant square, no matter how many frogs there are. Answer: Move the frogs in the following order: 2, 4, 6, 5, 3, 1 (repeat these moves in the same order twice more), 2, 4, 6.    This is a solution in twenty-one moves - the fewest possible. If $n$, the number of frogs, be even, we require $\frac{n^2+n}{2}$ moves, of which $\frac{n^2-n}{2}$ will be leaps and $n$ simple moves. If $n$ be odd, we shall need $\frac{n^2+3n}{2}-4$ moves, of which $\frac{n^2-n}{2}$ will be leaps and $2n-4$ simple moves. In the even cases write, for the moves, all the even numbers in ascending order and the odd numbers in descending order.    This series must be repeated $\frac{1}{2}n$ times and followed by the even numbers in ascending order once only.    Thus the solution for 14 frogs will be (2, 4, 6, 8, 10, 12, 14, 13, 11, 9, 7, 5, 3, 1) repeated 7 times and followed by 2, 4, 6, 8, 10, 12, 14 = 105 moves. In the odd cases, write the even numbers in ascending order and the odd numbers in descending order, repeat this series $\frac{1}{2}(n-1)$ times, follow with the even numbers in ascending order (omitting $n-1$), the odd numbers in descending order (omitting 1), and conclude with all the numbers (odd and even) in their natural order (omitting 1 and n).    Thus for 11 frogs: (2, 4, 6, 8, 10, 11, 9, 7, 5, 3, 1) repeated 5 times, 2, 4, 6, 8, 11, 9, 7, 5, 3, and 2, 3, 4, 5, 6, 7, 8, 9, 10 = 73 moves. ( source ) which I had tried to solve but could not find the reasoning behind the moves used in the solution could anybody tell how to handle this type of puzzles without hit and trial?",,"['combinatorics', 'group-theory', 'finite-groups', 'permutations', 'puzzle']"
81,Hat 'trick': Can one of them guess right?,Hat 'trick': Can one of them guess right?,,"There are $n$ boys and $n$ girls. Each of them is given a hat of only 4 possible (known) colors and doesn't know its color. Now each can only see all the colors of hats of those of the other gender and no contact is allowed, then each is asked to guess the color of their own hat at the same time . Determine whether such $n$ exists that there is a strategy that at least one child can guess right under any circumstances. When there are only 3 possible colors, the problem has been solved ($n=2$ is OK) through simple algebra. But when it comes to 4 colors, the problem seems much harder. Please help. Solution for 3 colors ($n=2$): we use 0, 1, 2 to represent the colors, the boys are $a, b$ and girls are $c, d$, respectively. Each boy knows the value of $c, d$, while each girl knows the value of $a, b$. Now consider the four number:$$a+b+c,$$ $$d+a-b,$$ $$d+b-c,$$ $$d+c-a.$$ It's easy to show at least one of them is divisible by 3. As a result, the strategy is: $A, B, C, D$ guess $c+d$, $c-d$, $-a-b$, $b-a$$\pmod 3$ respectively, and one of them must be right.","There are $n$ boys and $n$ girls. Each of them is given a hat of only 4 possible (known) colors and doesn't know its color. Now each can only see all the colors of hats of those of the other gender and no contact is allowed, then each is asked to guess the color of their own hat at the same time . Determine whether such $n$ exists that there is a strategy that at least one child can guess right under any circumstances. When there are only 3 possible colors, the problem has been solved ($n=2$ is OK) through simple algebra. But when it comes to 4 colors, the problem seems much harder. Please help. Solution for 3 colors ($n=2$): we use 0, 1, 2 to represent the colors, the boys are $a, b$ and girls are $c, d$, respectively. Each boy knows the value of $c, d$, while each girl knows the value of $a, b$. Now consider the four number:$$a+b+c,$$ $$d+a-b,$$ $$d+b-c,$$ $$d+c-a.$$ It's easy to show at least one of them is divisible by 3. As a result, the strategy is: $A, B, C, D$ guess $c+d$, $c-d$, $-a-b$, $b-a$$\pmod 3$ respectively, and one of them must be right.",,"['combinatorics', 'recreational-mathematics', 'puzzle', 'game-theory', 'combinatorial-game-theory']"
82,Exceptional books on real world applications of graph theory.,Exceptional books on real world applications of graph theory.,,"What are some exceptional graph theory books geared explicitly towards real-world applications? I would be interested in both general books on the subject (essentially surveys of applied graph theory as a discipline) as well as books about specific applications. One may assume up to a year-ish of graph theoretic background.  I am not looking for an introductory graph theory book, nor am I interested in pure graph theory books containing only a few canonical applications (e.g. Bondy & Murty's GTWA).  The book should contain as much exposition connecting the mathematics to the real world as possible, as well as exercises and concrete examples related to applications themselves (e.g. ""design a traffic network given the following constraints""). Please mention in your answer what the book does well which sets it apart from others, e.g. ""Book X has a great section on graph theory in computational geometry.""","What are some exceptional graph theory books geared explicitly towards real-world applications? I would be interested in both general books on the subject (essentially surveys of applied graph theory as a discipline) as well as books about specific applications. One may assume up to a year-ish of graph theoretic background.  I am not looking for an introductory graph theory book, nor am I interested in pure graph theory books containing only a few canonical applications (e.g. Bondy & Murty's GTWA).  The book should contain as much exposition connecting the mathematics to the real world as possible, as well as exercises and concrete examples related to applications themselves (e.g. ""design a traffic network given the following constraints""). Please mention in your answer what the book does well which sets it apart from others, e.g. ""Book X has a great section on graph theory in computational geometry.""",,"['combinatorics', 'reference-request', 'graph-theory', 'applications', 'book-recommendation']"
83,When is $\binom{2n}{n}\cdot \frac{1}{2n}$ an integer?,When is  an integer?,\binom{2n}{n}\cdot \frac{1}{2n},"In a recent question here , asking about the number of necklaces of $n$ white and $n$ black beads ( reworded in terms of apples and oranges ), one of the naive and incorrect answers was that as there are $\binom{2n}{n}$ ways to arrange the beads in a straight line, dividing by $2n$ to account for the symmetry of the circle would correct the count. In the case that $p$ is a prime not equal to two, it is clear to see that $\dfrac{(2p)!}{p!p!2p}$ has a factor of $p$ exactly twice in the numerator yet three times in the denominator and is thus not even an integer. My question: For what values of $n$ will $\binom{2n}{n}\frac{1}{2n}$ be an integer? A similar question was asked here for the more general case of when $\frac{1}{n}\binom{n}{k}$ is an integer, generating some very nice graphics, and some special cases were mentioned such as when $\gcd(n,k)=1$, however that will never be the case in the special case I ask about (since $\gcd(2n,n)=n\neq 1$ for all $n>1$).  Indeed, when looking at the lovely image made by @BrunoJoyal, one notices a black line down the center of the image, which would correspond to those positions I am interested in. Wolfram gives us the beginnings of a sequence $1,6,15,28,42,45,66,77,91,\dots$  With the exception of $42$ and $77$ these numbers are the first hexagonal numbers, but that pattern breaks with $120$ not being in the sequence. A longer list from the comments by @BanachTarski: There are 89 such numbers in the first 1000 natural numbers 1, 6, 15, 28, 42, 45, 66, 77, 91, 110, 126, 140, 153, 156, 170, 187, 190, 204, 209, 210, 220, 228, 231, 238, 266, 276, 299, 308, 312, 315, 322, 325, 330, 345, 378, 414, 420, 429, 435, 440, 442, 450, 459, 460, 468, 476, 483, 493, 496, 510, 527, 551, 558, 561, 570, 580, 589, 600, 609, 620, 651, 665, 682, 684, 696, 703, 740, 744, 748, 770, 777, 806, 812, 814, 851, 861, 868, 888, 902, 920, 924, 936, 943, 946, 950, 962, 966, 988, 989 Is there anything special we can say about those $n$ for which this is the case?  (By imposing the extra condition on $k$ and $n$ in the generalized question, more patterns will hopefully emerge)","In a recent question here , asking about the number of necklaces of $n$ white and $n$ black beads ( reworded in terms of apples and oranges ), one of the naive and incorrect answers was that as there are $\binom{2n}{n}$ ways to arrange the beads in a straight line, dividing by $2n$ to account for the symmetry of the circle would correct the count. In the case that $p$ is a prime not equal to two, it is clear to see that $\dfrac{(2p)!}{p!p!2p}$ has a factor of $p$ exactly twice in the numerator yet three times in the denominator and is thus not even an integer. My question: For what values of $n$ will $\binom{2n}{n}\frac{1}{2n}$ be an integer? A similar question was asked here for the more general case of when $\frac{1}{n}\binom{n}{k}$ is an integer, generating some very nice graphics, and some special cases were mentioned such as when $\gcd(n,k)=1$, however that will never be the case in the special case I ask about (since $\gcd(2n,n)=n\neq 1$ for all $n>1$).  Indeed, when looking at the lovely image made by @BrunoJoyal, one notices a black line down the center of the image, which would correspond to those positions I am interested in. Wolfram gives us the beginnings of a sequence $1,6,15,28,42,45,66,77,91,\dots$  With the exception of $42$ and $77$ these numbers are the first hexagonal numbers, but that pattern breaks with $120$ not being in the sequence. A longer list from the comments by @BanachTarski: There are 89 such numbers in the first 1000 natural numbers 1, 6, 15, 28, 42, 45, 66, 77, 91, 110, 126, 140, 153, 156, 170, 187, 190, 204, 209, 210, 220, 228, 231, 238, 266, 276, 299, 308, 312, 315, 322, 325, 330, 345, 378, 414, 420, 429, 435, 440, 442, 450, 459, 460, 468, 476, 483, 493, 496, 510, 527, 551, 558, 561, 570, 580, 589, 600, 609, 620, 651, 665, 682, 684, 696, 703, 740, 744, 748, 770, 777, 806, 812, 814, 851, 861, 868, 888, 902, 920, 924, 936, 943, 946, 950, 962, 966, 988, 989 Is there anything special we can say about those $n$ for which this is the case?  (By imposing the extra condition on $k$ and $n$ in the generalized question, more patterns will hopefully emerge)",,"['combinatorics', 'number-theory', 'elementary-number-theory']"
84,What combinatorial quantity the tetration of two natural numbers represents?,What combinatorial quantity the tetration of two natural numbers represents?,,"Tetration is a generalization of exponentiation in arithmetic and a part of a series of other generalized notions, Hyperoperators . Consider $m\uparrow n$ denotes the tetration of $m$ and $n$. i.e. $$\underbrace{m^{m^{m^{.^{.^{.^{m}}}}}}}_{n-times}$$ Note that one can find a combinatorial description of each one of operators sum , multiplication and exponentiation as follows: $m+n$ is the size of disjoint union of two sets with $m$ and $n$ elements . $m.n$ is the size of Cartesian product of two sets with $m$ and $n$ elements . $m^n$ is the size of set of all functions from a set with $n$ elements to a set with $m$ elements. $m\uparrow n$ is the size of ... (?) Question: Is it possible to introduce a combinatorial set (defined by $m$, $n$) which its size is $m\uparrow n$ as well as the case of $m+n$, $m.n$, $m^n$? What about other Hyperoperators like pentation and hexation? The simple and most natural expressions are more interesting.","Tetration is a generalization of exponentiation in arithmetic and a part of a series of other generalized notions, Hyperoperators . Consider $m\uparrow n$ denotes the tetration of $m$ and $n$. i.e. $$\underbrace{m^{m^{m^{.^{.^{.^{m}}}}}}}_{n-times}$$ Note that one can find a combinatorial description of each one of operators sum , multiplication and exponentiation as follows: $m+n$ is the size of disjoint union of two sets with $m$ and $n$ elements . $m.n$ is the size of Cartesian product of two sets with $m$ and $n$ elements . $m^n$ is the size of set of all functions from a set with $n$ elements to a set with $m$ elements. $m\uparrow n$ is the size of ... (?) Question: Is it possible to introduce a combinatorial set (defined by $m$, $n$) which its size is $m\uparrow n$ as well as the case of $m+n$, $m.n$, $m^n$? What about other Hyperoperators like pentation and hexation? The simple and most natural expressions are more interesting.",,"['combinatorics', 'arithmetic']"
85,Does Birkhoff - von Neumann imply any of the fundamental theorems in combinatorics?,Does Birkhoff - von Neumann imply any of the fundamental theorems in combinatorics?,,"I recently had the occasion to think about Hall's Marriage Theorem for the first time since my undergraduate combinatorics class more than a decade ago.  Reading the wikipedia article linked above, I was interested to see that it is regarded as equivalent to several other fundamental theorems in combinatorics, for instance Dilworth's Theorem on posets of finite width and König's Theorem on matching in (finite?) graphs.  I was able to track down the proofs of these equivalences online. However, the article also claims that Hall's Marriage Theorem is equivalent to the (König-)Birkhoff - von Neumann Theorem , which asserts that a real matrix is doubly stochastic iff it is a convex combination of permutation matrices (if you know the Minkowski-Krein-Milman theory of extreme points in convex sets, then an equivalent assertion is that the doubly stochastic matrices form a compact convex subset of $M_n(\mathbb{R})$ with extreme points precisely the permutation matrices, and since there are finitely many extreme points one has in fact a convex polytope, the Birkhoff polytope ). But the attribution here is strange: the only citation is to this series of slides by R.D. Borgersen , for which the title is ""Equivalence of seven major theorems in combinatorics""...but it only shows some of the implications!  In particular, it is not shown that Birkhoff - von Neumann implies any of the theorems as above.  So now we get to the question in my title: does it? As a secondary question, is there a nice source which treats all these theorems (maybe not Birkhoff - von Neumann, but the other five or six, depending on how you count) at once?  In particular much of the literature I've found seems to be a bit sloppy on whether the structures involved need to be finite: it seems that ""some, but not all"" finiteness conditions are needed for these theorems to hold and that the folkloric equivalence is understood to apply in the finite case only. Is this correct?","I recently had the occasion to think about Hall's Marriage Theorem for the first time since my undergraduate combinatorics class more than a decade ago.  Reading the wikipedia article linked above, I was interested to see that it is regarded as equivalent to several other fundamental theorems in combinatorics, for instance Dilworth's Theorem on posets of finite width and König's Theorem on matching in (finite?) graphs.  I was able to track down the proofs of these equivalences online. However, the article also claims that Hall's Marriage Theorem is equivalent to the (König-)Birkhoff - von Neumann Theorem , which asserts that a real matrix is doubly stochastic iff it is a convex combination of permutation matrices (if you know the Minkowski-Krein-Milman theory of extreme points in convex sets, then an equivalent assertion is that the doubly stochastic matrices form a compact convex subset of $M_n(\mathbb{R})$ with extreme points precisely the permutation matrices, and since there are finitely many extreme points one has in fact a convex polytope, the Birkhoff polytope ). But the attribution here is strange: the only citation is to this series of slides by R.D. Borgersen , for which the title is ""Equivalence of seven major theorems in combinatorics""...but it only shows some of the implications!  In particular, it is not shown that Birkhoff - von Neumann implies any of the theorems as above.  So now we get to the question in my title: does it? As a secondary question, is there a nice source which treats all these theorems (maybe not Birkhoff - von Neumann, but the other five or six, depending on how you count) at once?  In particular much of the literature I've found seems to be a bit sloppy on whether the structures involved need to be finite: it seems that ""some, but not all"" finiteness conditions are needed for these theorems to hold and that the folkloric equivalence is understood to apply in the finite case only. Is this correct?",,"['combinatorics', 'graph-theory', 'order-theory', 'birkhoff-polytopes']"
86,A combinatorial identity involving generalized harmonic numbers,A combinatorial identity involving generalized harmonic numbers,,"[This problem has now an answer here .] The $n$-th harmonic number is defined as $$ H_n=\sum_{k=1}^{n}\frac{1}{k}, $$ and the generalized harmonic numbers are defined by $$ H_{n}^{(r)}=\sum_{k=1}^{n}\frac{1}{k^r}. $$ Recently, I have found the following combinatorial identity involving the second-order harmonic numbers (I have computational evidence). Question: \begin{align} \sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s }{s+1}H_{s}^{(2)}=\frac{2(-1)^m}{m+1}\sum_{s=0}^m H_{s}^{(2)}.  \end{align} Is this a known combinatorial identity? Any proof or reference? However, if I replace $H_s^{(2)}$ by other generalized harmonic numbers in the above identity, I can not find some similar identities. Comments: (1) This combinatorial identity was motivated by the following identity \begin{align} \sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s}{s+1}=(-1)^m. \end{align} One can refer to How to prove $\sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s}{s+1}=(-1)^m$? (2) This problem has also been posted here . I appreciate any hints, pointers etc.!","[This problem has now an answer here .] The $n$-th harmonic number is defined as $$ H_n=\sum_{k=1}^{n}\frac{1}{k}, $$ and the generalized harmonic numbers are defined by $$ H_{n}^{(r)}=\sum_{k=1}^{n}\frac{1}{k^r}. $$ Recently, I have found the following combinatorial identity involving the second-order harmonic numbers (I have computational evidence). Question: \begin{align} \sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s }{s+1}H_{s}^{(2)}=\frac{2(-1)^m}{m+1}\sum_{s=0}^m H_{s}^{(2)}.  \end{align} Is this a known combinatorial identity? Any proof or reference? However, if I replace $H_s^{(2)}$ by other generalized harmonic numbers in the above identity, I can not find some similar identities. Comments: (1) This combinatorial identity was motivated by the following identity \begin{align} \sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s}{s+1}=(-1)^m. \end{align} One can refer to How to prove $\sum_{s=0}^{m}{2s\choose s}{s\choose m-s}\frac{(-1)^s}{s+1}=(-1)^m$? (2) This problem has also been posted here . I appreciate any hints, pointers etc.!",,"['combinatorics', 'summation', 'binomial-coefficients']"
87,How do you correctly reason that this directed graph is acyclic?,How do you correctly reason that this directed graph is acyclic?,,"How can you correctly reason that this directed graph is acyclic? I can only visually say that this graph is acyclic because there is not a single path in the graph where the starting vertex is equal to the ending vertex. But is this actually a reason you can say if someone asks you? Is there maybe some kind of rule / formula where you can determine this by comparing the amount of vertices with the amount of edges? We have here $6$ vertices and $10$ edges. I hope you can give me some help because if someone asks me why this directed graph or generally a directed graph is acyclic, I would go like that here and I don't feel good about it.","How can you correctly reason that this directed graph is acyclic? I can only visually say that this graph is acyclic because there is not a single path in the graph where the starting vertex is equal to the ending vertex. But is this actually a reason you can say if someone asks you? Is there maybe some kind of rule / formula where you can determine this by comparing the amount of vertices with the amount of edges? We have here vertices and edges. I hope you can give me some help because if someone asks me why this directed graph or generally a directed graph is acyclic, I would go like that here and I don't feel good about it.",6 10,"['combinatorics', 'discrete-mathematics', 'graph-theory', 'computer-science', 'directed-graphs']"
88,"Counting matchings, the modern way","Counting matchings, the modern way",,"A hundred years ago, if you had $k$ men and $k$ women and wanted to marry them all off in pairs, it was easy to see that there are exactly $k!$ ways to do that. Today, however, societal standards have evolved, and many countries now recognize same-sex marriages. Mathematically we can model that by saying that men can now be brides and women can now be grooms. Each wedding still needs one bride and one groom, however, if only because one of the spouses needs to be listed in the left rubric on the marriage certificate and the other on the right. How many ways are there now to marry off our $2k$ persons in pairs? A bit of elementary combinatorics and algebra shows that we have $$ \tag{$\dagger$} \frac{(2k)!}{k!} = (k+1)\cdot(k+2)\cdot(k+3)\cdots(2k-2)\cdot (2k-1) \cdot 2k $$ possibilities, when we want to remember who's the bride and who's the groom in each couple. However, every way I can think of to justify this formula depends on first counting a larger number of somethings, and then dividing out some factors to account for overcounting. (If we justify $(2k)!/k!$ as $\binom{2k}{k}k!$ the division is hidden inside the argument that $\binom nk=\frac{n}{k!(n-k)!}$). Question: Is there an intuitive way to explain the result $\text{($\dagger$)}$ where each of the $k$ factors have a discrete meaning? Or, in other words, an explicit description of a bijection from the set   $$ \{1,2,\ldots,k,k+1\}\times\{1,2,\ldots,k,k+1,k+2\}\times\cdots\times\{1,2,\ldots,2k\} $$   to the set of possible matchings?","A hundred years ago, if you had $k$ men and $k$ women and wanted to marry them all off in pairs, it was easy to see that there are exactly $k!$ ways to do that. Today, however, societal standards have evolved, and many countries now recognize same-sex marriages. Mathematically we can model that by saying that men can now be brides and women can now be grooms. Each wedding still needs one bride and one groom, however, if only because one of the spouses needs to be listed in the left rubric on the marriage certificate and the other on the right. How many ways are there now to marry off our $2k$ persons in pairs? A bit of elementary combinatorics and algebra shows that we have $$ \tag{$\dagger$} \frac{(2k)!}{k!} = (k+1)\cdot(k+2)\cdot(k+3)\cdots(2k-2)\cdot (2k-1) \cdot 2k $$ possibilities, when we want to remember who's the bride and who's the groom in each couple. However, every way I can think of to justify this formula depends on first counting a larger number of somethings, and then dividing out some factors to account for overcounting. (If we justify $(2k)!/k!$ as $\binom{2k}{k}k!$ the division is hidden inside the argument that $\binom nk=\frac{n}{k!(n-k)!}$). Question: Is there an intuitive way to explain the result $\text{($\dagger$)}$ where each of the $k$ factors have a discrete meaning? Or, in other words, an explicit description of a bijection from the set   $$ \{1,2,\ldots,k,k+1\}\times\{1,2,\ldots,k,k+1,k+2\}\times\cdots\times\{1,2,\ldots,2k\} $$   to the set of possible matchings?",,['combinatorics']
89,Number of ways to stack LEGO bricks,Number of ways to stack LEGO bricks,,"One of the most surprising combinatorial formulas I know of counts the number of LEGO towers built from $n$ "" $1 \times 2$ "" blocks subject to four rules: The bricks lie in a single plane. Each brick is offset by 1 stud (as in a brick wall). The bottom layer is contiguous. Each brick has at least one brick below it (apart from the bottom layer). Example Formula On page 26 of Miklós Bóna's Handbook of Enumerative Combinatorics , the author states the combinatorial formula (!!): Remarkably there are $3^{n-1}$ domino towers consisting of $n$ bricks. Equally remarkably, no simple bijection is known. The formula was first proven in 1988 by Gouyou-Beauchamps and Viennot . Question While writing up a short essay on this fact, I became interested in what happens when you relax some of the rules. In particular, for the small values I checked on the computer, removing the second rule (""Each brick is offset by 1 stud"") appears to result in $4^{n-1}$ towers with $n$ bricks. I imagine this result exists in the literature, and I was hoping MSE could help me find it. If it hasn't been written down anywhere, I was hoping for insight for how to adapt Bóna's proof into this new setting.","One of the most surprising combinatorial formulas I know of counts the number of LEGO towers built from "" "" blocks subject to four rules: The bricks lie in a single plane. Each brick is offset by 1 stud (as in a brick wall). The bottom layer is contiguous. Each brick has at least one brick below it (apart from the bottom layer). Example Formula On page 26 of Miklós Bóna's Handbook of Enumerative Combinatorics , the author states the combinatorial formula (!!): Remarkably there are domino towers consisting of bricks. Equally remarkably, no simple bijection is known. The formula was first proven in 1988 by Gouyou-Beauchamps and Viennot . Question While writing up a short essay on this fact, I became interested in what happens when you relax some of the rules. In particular, for the small values I checked on the computer, removing the second rule (""Each brick is offset by 1 stud"") appears to result in towers with bricks. I imagine this result exists in the literature, and I was hoping MSE could help me find it. If it hasn't been written down anywhere, I was hoping for insight for how to adapt Bóna's proof into this new setting.",n 1 \times 2 3^{n-1} n 4^{n-1} n,"['combinatorics', 'reference-request', 'recreational-mathematics', 'discrete-geometry', 'statistical-mechanics']"
90,Bound on the sum of squared distances between points inside a semi-circle,Bound on the sum of squared distances between points inside a semi-circle,,"There are $n$ points $(a_0, ..., a_{n-1})$ inside a half-disk of diameter $D$. I would like to prove that there exists a permutation of the $n$ points $(b_0, b_1, .., b_{n-1})=(a_{j_0},a_{j_1} \cdots a_{j_{n-1}})$ such that $$\sum_{i=1}^{n-1} \operatorname {d}(b_{i-1},b_i)^2 \leq D ^2.$$ Here, $\operatorname {d}(\cdot,\cdot)$ denotes the euclidean distance between two points. I tried to use analytic geometry, yet it doesn't help. And I think there is a nice combinatoric way to solve this...","There are $n$ points $(a_0, ..., a_{n-1})$ inside a half-disk of diameter $D$. I would like to prove that there exists a permutation of the $n$ points $(b_0, b_1, .., b_{n-1})=(a_{j_0},a_{j_1} \cdots a_{j_{n-1}})$ such that $$\sum_{i=1}^{n-1} \operatorname {d}(b_{i-1},b_i)^2 \leq D ^2.$$ Here, $\operatorname {d}(\cdot,\cdot)$ denotes the euclidean distance between two points. I tried to use analytic geometry, yet it doesn't help. And I think there is a nice combinatoric way to solve this...",,"['combinatorics', 'geometry']"
91,Height of all skyscraper,Height of all skyscraper,,"There is a bunch of skyscapers, each have a height, which is a positive integer. You are given at the start the total sum of their height. Now everyday you can make one measurement, which will tell you how many skyscapers there are which have height at least $k$, for some $k$ of your choice. You are allowed to choose that $k$ whatever knowledge you have obtained so far, such that measurement results from previous days. You can stop once you know with perfect certainty the height of each skyscrapers. (also, you are not given the number of skyscrapers at the start, but asymptotically, that does not matter since you can always pick $k=1$ on the first day) So my question is, what is the algorithm for choosing the measurement each day such that the number of days in take in worst case is asymptotically optimal, and what is that number of days asymptotically. Example: Let's say that the final result would be $3,1$ (there are $2$ skyscrapers, and the height of the skyscapers are $3$ and $1$). First you know the total height is $4$. You pick $k=1$ on the first day, you now know there is $2$ skyscrapers of height at least $1$ (which means there are $2$ skyscapers). The next day you pick $k=2$, and you learn there is only $1$ skyscapers of height at least $2$. So exactly one of them have height $1$, and the other one must have the remaining height, which is $3$. Hence you are done after $2$ days. EDIT: I made some edits to the question to clarify certain points.","There is a bunch of skyscapers, each have a height, which is a positive integer. You are given at the start the total sum of their height. Now everyday you can make one measurement, which will tell you how many skyscapers there are which have height at least $k$, for some $k$ of your choice. You are allowed to choose that $k$ whatever knowledge you have obtained so far, such that measurement results from previous days. You can stop once you know with perfect certainty the height of each skyscrapers. (also, you are not given the number of skyscrapers at the start, but asymptotically, that does not matter since you can always pick $k=1$ on the first day) So my question is, what is the algorithm for choosing the measurement each day such that the number of days in take in worst case is asymptotically optimal, and what is that number of days asymptotically. Example: Let's say that the final result would be $3,1$ (there are $2$ skyscrapers, and the height of the skyscapers are $3$ and $1$). First you know the total height is $4$. You pick $k=1$ on the first day, you now know there is $2$ skyscrapers of height at least $1$ (which means there are $2$ skyscapers). The next day you pick $k=2$, and you learn there is only $1$ skyscapers of height at least $2$. So exactly one of them have height $1$, and the other one must have the remaining height, which is $3$. Hence you are done after $2$ days. EDIT: I made some edits to the question to clarify certain points.",,"['combinatorics', 'algorithms', 'information-theory']"
92,Minimal time gossip problem,Minimal time gossip problem,,"The gossip problem (telephone problem) is an information dissemination problem where each of $n$ nodes of a communication network has a unique piece of information that must be transmitted to all the other nodes using two-way communications (telephone calls) between the pairs of nodes. Upon a call between the given two nodes, they exchange the whole information known to them at that moment. The minimum number of calls needed to guarantee the spread of whole information is $2n-4$. http://www.mathematik.uni-bielefeld.de/~sillke/PUZZLES/gossips.pdf Assuming that the calls between non-overlapping pairs of nodes can take place simultaneously, the minimum amount of time $T(n)$ required to complete gossiping is $\lceil \log_2 n \rceil$ for even $n$ and $\lceil \log_2 n \rceil + 1$ for odd $n$. http://onlinelibrary.wiley.com/doi/10.1002/net.3230180406/abstract As it is written in the paper by R. Labahn, ""Kernels of minimum size gossip schemes"", Discrete Mathematics 143 (1995) 99-139 : Theorem 5.3 Any gossip scheme on $n \geq 4$ vertices with $2n-4$ calls has at least $2\lceil \log_2 n \rceil - 3$ rounds. My question is following. Is there a result on the problem to find the minimum number of calls of a gossip scheme with time (rounds) $T(n)$.","The gossip problem (telephone problem) is an information dissemination problem where each of $n$ nodes of a communication network has a unique piece of information that must be transmitted to all the other nodes using two-way communications (telephone calls) between the pairs of nodes. Upon a call between the given two nodes, they exchange the whole information known to them at that moment. The minimum number of calls needed to guarantee the spread of whole information is $2n-4$. http://www.mathematik.uni-bielefeld.de/~sillke/PUZZLES/gossips.pdf Assuming that the calls between non-overlapping pairs of nodes can take place simultaneously, the minimum amount of time $T(n)$ required to complete gossiping is $\lceil \log_2 n \rceil$ for even $n$ and $\lceil \log_2 n \rceil + 1$ for odd $n$. http://onlinelibrary.wiley.com/doi/10.1002/net.3230180406/abstract As it is written in the paper by R. Labahn, ""Kernels of minimum size gossip schemes"", Discrete Mathematics 143 (1995) 99-139 : Theorem 5.3 Any gossip scheme on $n \geq 4$ vertices with $2n-4$ calls has at least $2\lceil \log_2 n \rceil - 3$ rounds. My question is following. Is there a result on the problem to find the minimum number of calls of a gossip scheme with time (rounds) $T(n)$.",,"['combinatorics', 'graph-theory', 'discrete-mathematics']"
93,Is there a combinatorial interpretation of the triangular numbers?,Is there a combinatorial interpretation of the triangular numbers?,,"The triangular numbers count the number of items in a triangle with $n$ items on a side, like this: This can be calculated exactly by the formula $T_n = \sum_{k=1}^n k = \frac{n(n+1)}{2} = {n+1 \choose 2} = {n+1 \choose n-1}$. Is there any combinatorial interpretation to that formula, as in some way to interpret arranging objects in a triangle with $n$ on a side as the number of ways to choose 2 or $n-1$ objects out of a collection of $n+1$ objects?","The triangular numbers count the number of items in a triangle with $n$ items on a side, like this: This can be calculated exactly by the formula $T_n = \sum_{k=1}^n k = \frac{n(n+1)}{2} = {n+1 \choose 2} = {n+1 \choose n-1}$. Is there any combinatorial interpretation to that formula, as in some way to interpret arranging objects in a triangle with $n$ on a side as the number of ways to choose 2 or $n-1$ objects out of a collection of $n+1$ objects?",,"['combinatorics', 'discrete-mathematics', 'summation', 'binomial-coefficients', 'combinatorial-proofs']"
94,The number of partitions of $n$ into distinct parts equals the number of partitions of $n$ into odd parts,The number of partitions of  into distinct parts equals the number of partitions of  into odd parts,n n,"This seems to be a common result. I've been trying to follow the bijective proof of it, which can be found easily online, but the explanations go over my head. It would be wonderful if you could give me an understandable explanation of the proof and let me know how I'd go about finding such a bijection.","This seems to be a common result. I've been trying to follow the bijective proof of it, which can be found easily online, but the explanations go over my head. It would be wonderful if you could give me an understandable explanation of the proof and let me know how I'd go about finding such a bijection.",,"['number-theory', 'combinatorics', 'integer-partitions']"
95,How many ways are there for 8 men and 5 women to stand in a line so that no two women stand next to each other?,How many ways are there for 8 men and 5 women to stand in a line so that no two women stand next to each other?,,"I have a homework problem in my textbook that has stumped me so far. There is a similar one to it that has not been assigned and has an answer in the back of the textbook. It reads: How many ways are there for $8$ men and $5$ women to stand in a line so that no two women stand next to each other? The answer is $609638400$, but no matter what I try I cannot reach that number. I have tried doing $2(8!5!/3!)*(8!/5!)$ since each woman must be paired with a man in order to prevent two women getting near each other. But of course, it's the wrong answer. What am I doing wrong here?","I have a homework problem in my textbook that has stumped me so far. There is a similar one to it that has not been assigned and has an answer in the back of the textbook. It reads: How many ways are there for $8$ men and $5$ women to stand in a line so that no two women stand next to each other? The answer is $609638400$, but no matter what I try I cannot reach that number. I have tried doing $2(8!5!/3!)*(8!/5!)$ since each woman must be paired with a man in order to prevent two women getting near each other. But of course, it's the wrong answer. What am I doing wrong here?",,"['combinatorics', 'permutations']"
96,Is it possible to put $+$ or $-$ signs in such a way that $\pm 1 \pm 2 \pm \cdots \pm 100 = 101$?,Is it possible to put  or  signs in such a way that ?,+ - \pm 1 \pm 2 \pm \cdots \pm 100 = 101,"I'm reading a book about combinatorics. Even though the book is about combinatorics there is a problem in the book that I can think of no solutions to it except by using number theory. Problem: Is it possible to put $+$ or $-$ signs in such a way that $\pm 1 \pm 2 \pm \cdots  \pm 100 = 101$? My proof is kinda simple. Let's work in mod $2$. We'll have: $\pm 1 \pm 2 \pm \cdots  \pm 100 \equiv 101 \mod 2$ but since $+1 \equiv -1 \mod 2$ and there are exactly $50$ odd numbers and $50$ even numbers from $1$ to $100$  we can write: $(1 + 0 + \cdots + 1 + 0 \equiv 50\times 1 \equiv 0) \not\equiv (101\equiv 1) \mod 2$ which is contradictory. Therefore, it's not possible to choose $+$ or $-$ signs in any way to make them equal. Now is there a combinatorial proof of that fact except what I have in mind?","I'm reading a book about combinatorics. Even though the book is about combinatorics there is a problem in the book that I can think of no solutions to it except by using number theory. Problem: Is it possible to put $+$ or $-$ signs in such a way that $\pm 1 \pm 2 \pm \cdots  \pm 100 = 101$? My proof is kinda simple. Let's work in mod $2$. We'll have: $\pm 1 \pm 2 \pm \cdots  \pm 100 \equiv 101 \mod 2$ but since $+1 \equiv -1 \mod 2$ and there are exactly $50$ odd numbers and $50$ even numbers from $1$ to $100$  we can write: $(1 + 0 + \cdots + 1 + 0 \equiv 50\times 1 \equiv 0) \not\equiv (101\equiv 1) \mod 2$ which is contradictory. Therefore, it's not possible to choose $+$ or $-$ signs in any way to make them equal. Now is there a combinatorial proof of that fact except what I have in mind?",,['combinatorics']
97,Why are there only a few known Ramsey numbers?,Why are there only a few known Ramsey numbers?,,"Can someone explain in a simple way why there are so few known exact Ramsey numbers ? I guess it's because there are no efficient algorithms for this task, but are there so many combinations to test? And an additional question: How are the bounds determined? Why do the bounds, that are known, have those values? Why not i.e. try to take a lower number for the upper bound for some 2-coloring?","Can someone explain in a simple way why there are so few known exact Ramsey numbers ? I guess it's because there are no efficient algorithms for this task, but are there so many combinations to test? And an additional question: How are the bounds determined? Why do the bounds, that are known, have those values? Why not i.e. try to take a lower number for the upper bound for some 2-coloring?",,"['combinatorics', 'np-complete', 'ramsey-theory']"
98,Why there are $11$ non-isomorphic graphs of order $4$?,Why there are  non-isomorphic graphs of order ?,11 4,"I'm new to graph theory and I don't plan to become a serious student of graph theory either. My book suggests that there are $11$ non-isomorphic graphs of order $4$, but I can't see why. I know that the most naive approach is that I can use brute force and draw four vertices and then try to connect two vertices by an edge in such a way that I don't get isomorphic graphs in each step. But then the question is, how should I know I have counted all possibilities at the end? And when the size of the graph becomes larger, how should I know I'm not counting two isomorphic structures more than once? To be more precise, I have 5 questions about determining the number of non-isomorphic graphs with $n$ vertices: Is there an algorithmic approach for creating all non-isomorphic graphs of a certain order $n$? Does it have anything to do with graphic sequences and Havel-Hakimi algorithm or something? Is it possible to count the number of non-isomorphic graphs with $n$ vertices without actually knowing them or it's still an open problem? Is it possible to partially solve this by using group theory? How can I see that there are $11$ non-isomorphic graphs with $4$ vertices without brute force?","I'm new to graph theory and I don't plan to become a serious student of graph theory either. My book suggests that there are $11$ non-isomorphic graphs of order $4$, but I can't see why. I know that the most naive approach is that I can use brute force and draw four vertices and then try to connect two vertices by an edge in such a way that I don't get isomorphic graphs in each step. But then the question is, how should I know I have counted all possibilities at the end? And when the size of the graph becomes larger, how should I know I'm not counting two isomorphic structures more than once? To be more precise, I have 5 questions about determining the number of non-isomorphic graphs with $n$ vertices: Is there an algorithmic approach for creating all non-isomorphic graphs of a certain order $n$? Does it have anything to do with graphic sequences and Havel-Hakimi algorithm or something? Is it possible to count the number of non-isomorphic graphs with $n$ vertices without actually knowing them or it's still an open problem? Is it possible to partially solve this by using group theory? How can I see that there are $11$ non-isomorphic graphs with $4$ vertices without brute force?",,"['combinatorics', 'graph-theory', 'algebraic-graph-theory', 'graph-isomorphism']"
99,Finding the n-th lexicographic permutation of a string,Finding the n-th lexicographic permutation of a string,,"I have an ordered set of symbols S = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. I want to find the 1,000,000-th permutation in lexicographic order of S. It is a programming puzzle, but I wanted to figure out a way without brute-forcing the task. So my thinking was like this: For 10 variable symbol positions, we have 10! permutations, obviously. Now we want to find the first symbol. If we fix the first symbol, then the remaining 9 symbols can have 9! combinations. That means that 0 or 1 cannot be the first symbol, because the highest possible position is 2*9! = 725,760, which is lower than 1,000,000. The lowest position for a leading 3 is 3*9! + 1 = 1,088,641, so it can't be 3 or higher, either. Therefore, the first number must be 2. 2*9! is the largest multiple of 9! no greater than 1,000,000, so I need the 2nd symbol (zero-based) from the current set. So now the question becomes, of the remaining S := S \{2}, which permutation of these symbols is at lexicographic position (1,000,000 - 2*9!) = 274,240? 6*8! = 241,920 is the largest multiple of 8! which is smaller than 274,240, so I need the 6th-smallest symbol of the remaining set, which is 7. So the prefix should be 27 by now. That way, I keep going and finally arrive at: 1,000,000 = 2*9! + 6*8! + 6*7! + 2*6! + 5*5! + 1*4! + 2*3! + 2*2! + 0*1! + 0*0! which results in ""2783905614"" as my solution. However, according to the solution tester , (free reg. req.) that is incorrect. Where did I go wrong in thinking or applying?","I have an ordered set of symbols S = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }. I want to find the 1,000,000-th permutation in lexicographic order of S. It is a programming puzzle, but I wanted to figure out a way without brute-forcing the task. So my thinking was like this: For 10 variable symbol positions, we have 10! permutations, obviously. Now we want to find the first symbol. If we fix the first symbol, then the remaining 9 symbols can have 9! combinations. That means that 0 or 1 cannot be the first symbol, because the highest possible position is 2*9! = 725,760, which is lower than 1,000,000. The lowest position for a leading 3 is 3*9! + 1 = 1,088,641, so it can't be 3 or higher, either. Therefore, the first number must be 2. 2*9! is the largest multiple of 9! no greater than 1,000,000, so I need the 2nd symbol (zero-based) from the current set. So now the question becomes, of the remaining S := S \{2}, which permutation of these symbols is at lexicographic position (1,000,000 - 2*9!) = 274,240? 6*8! = 241,920 is the largest multiple of 8! which is smaller than 274,240, so I need the 6th-smallest symbol of the remaining set, which is 7. So the prefix should be 27 by now. That way, I keep going and finally arrive at: 1,000,000 = 2*9! + 6*8! + 6*7! + 2*6! + 5*5! + 1*4! + 2*3! + 2*2! + 0*1! + 0*0! which results in ""2783905614"" as my solution. However, according to the solution tester , (free reg. req.) that is incorrect. Where did I go wrong in thinking or applying?",,"['combinatorics', 'puzzle']"
