,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to convert up/down votes into a single number?,How to convert up/down votes into a single number?,,I've got a website with voting system where people can vote a review either up or down. For example: “Did you find this review helpful? [Yes] or [No]?” In order to order the reviews by how much they were appreciated I'd like a single number to order them by. Just using the percentage of up votes doesn't cut it because it doesn't take the total number of votes into account. A review with 2 up votes and 0 down votes (100%) should not be shown before a review with 95 up votes and 5 down votes (95%). Any ideas on which formula to use? Thanks.,I've got a website with voting system where people can vote a review either up or down. For example: “Did you find this review helpful? [Yes] or [No]?” In order to order the reviews by how much they were appreciated I'd like a single number to order them by. Just using the percentage of up votes doesn't cut it because it doesn't take the total number of votes into account. A review with 2 up votes and 0 down votes (100%) should not be shown before a review with 95 up votes and 5 down votes (95%). Any ideas on which formula to use? Thanks.,,"['statistics', 'descriptive-statistics']"
1,monotone functions and pdf's,monotone functions and pdf's,,"Could you please show me step by step? Also how does the probability integral transformation come into play? ""If the random variable $X$ has pdf $$ f(x)= \begin{cases} \tfrac{1}{2}(x-1)\quad \text{if }1< x< 3,\\  0 \qquad\qquad\;\, \text{otherwise}, \end{cases} $$ then find a monotone function $u$ such that random variable $Y = u(X)$ has a uniform $(0,1)$ distribution."" The answer key says ""From the probability integral transformation, Theorem 2.1.10, we know that if $u(x) = F_X(x)$, then $F_X(X)$ is uniformly distributed in $(0,1)$. Therefore, for the given pdf, calculate $$ u(x) = F_X(x) = \begin{cases} 0 \qquad\qquad \;\,\text{if }  x\leq 1,\\ \tfrac{1}{4}(x − 1)^2 \quad \text{if  }1 < x < 3, \\ 1 \qquad\qquad\;\, \text{if } x\geq 3. \end{cases} $$ But what does this mean?","Could you please show me step by step? Also how does the probability integral transformation come into play? ""If the random variable $X$ has pdf $$ f(x)= \begin{cases} \tfrac{1}{2}(x-1)\quad \text{if }1< x< 3,\\  0 \qquad\qquad\;\, \text{otherwise}, \end{cases} $$ then find a monotone function $u$ such that random variable $Y = u(X)$ has a uniform $(0,1)$ distribution."" The answer key says ""From the probability integral transformation, Theorem 2.1.10, we know that if $u(x) = F_X(x)$, then $F_X(X)$ is uniformly distributed in $(0,1)$. Therefore, for the given pdf, calculate $$ u(x) = F_X(x) = \begin{cases} 0 \qquad\qquad \;\,\text{if }  x\leq 1,\\ \tfrac{1}{4}(x − 1)^2 \quad \text{if  }1 < x < 3, \\ 1 \qquad\qquad\;\, \text{if } x\geq 3. \end{cases} $$ But what does this mean?",,"['probability', 'statistics']"
2,I am confused about Bayes' rule in MCMC,I am confused about Bayes' rule in MCMC,,"Bayes' rule appears to bevery simple at first sight, but when studied deeply I find it is difficult and confusing, especially in MCMC applications when multiple parameters need to be estimated. For example, assuming $x,y,z,t$ are four parameters, which of the following three expressions are true (or true under some specifications)? $P(x)P(z\mid x,y)=P(x,z\mid y)$ $P(x\mid y)P(z\mid x,y)=P(x,z\mid y)$ $P(x\mid y)P(z\mid x,t)=P(x,z\mid y,t)$ I usually see formulas similar with 3, but I wonder why it hold. Could someone explain it in detail? If there are any excellent books that could help me, pls list them.","Bayes' rule appears to bevery simple at first sight, but when studied deeply I find it is difficult and confusing, especially in MCMC applications when multiple parameters need to be estimated. For example, assuming $x,y,z,t$ are four parameters, which of the following three expressions are true (or true under some specifications)? $P(x)P(z\mid x,y)=P(x,z\mid y)$ $P(x\mid y)P(z\mid x,y)=P(x,z\mid y)$ $P(x\mid y)P(z\mid x,t)=P(x,z\mid y,t)$ I usually see formulas similar with 3, but I wonder why it hold. Could someone explain it in detail? If there are any excellent books that could help me, pls list them.",,"['probability', 'statistics', 'bayesian']"
3,Hmm. help with a tiny statistics question please,Hmm. help with a tiny statistics question please,,"This isn't homework, I am boggling my head over it though. I got all sorts of answers, just not the answer my book demands. For what value of $x$ the mean of the given observations $2x - 5, x + 3, 7 - x, 5-x$ and $x + 9$ with frequencies $2,3,4,6$ and $1$ respectively is $4$? I seriously cant solve this, help would be MUCH appreciated. Note: Please don't use any advanced statistics formula, we are still on the basics. Sum of $f_ix_i$ over sum of $f_i$ is all I can use.","This isn't homework, I am boggling my head over it though. I got all sorts of answers, just not the answer my book demands. For what value of $x$ the mean of the given observations $2x - 5, x + 3, 7 - x, 5-x$ and $x + 9$ with frequencies $2,3,4,6$ and $1$ respectively is $4$? I seriously cant solve this, help would be MUCH appreciated. Note: Please don't use any advanced statistics formula, we are still on the basics. Sum of $f_ix_i$ over sum of $f_i$ is all I can use.",,['statistics']
4,basic t-test statistics,basic t-test statistics,,"I'm writing an article, and I'm on a deadline so please be kind to me, I'd like to test for statistical significance of the difference before and after an intervention but I'm no real math genious My sample size is 63 pre and post-intervention interviews, and I have two different mean scores of 134,192 and 178,324 Are these significantly different? How do I do it? In excel or anywhere else is fine. Thanks a whole bunch.","I'm writing an article, and I'm on a deadline so please be kind to me, I'd like to test for statistical significance of the difference before and after an intervention but I'm no real math genious My sample size is 63 pre and post-intervention interviews, and I have two different mean scores of 134,192 and 178,324 Are these significantly different? How do I do it? In excel or anywhere else is fine. Thanks a whole bunch.",,['statistics']
5,Identity related to binomial distribution?,Identity related to binomial distribution?,,"While writing a (non-math) paper I came across the following apparent identity: $N \cdot \mathop \sum \limits_{i = 1}^N \frac{1}{i}\left( {\begin{array}{*{20}{c}} {N - 1}\\ {i - 1} \end{array}} \right){p^{i - 1}}{\left( {1 - p} \right)^{N - i}} = \frac{{1 - {{\left( {1 - p} \right)}^N}}}{p}$ where $N$ is a positive integer and $p$ is a nonzero probability. Based on intuition and some manual checks, this looks like it should be true for all such $N$ and $p$. I can't prove this, and being mostly ignorant about math, I don't know how to learn what I need to prove this. I'd really appreciate anything helpful, whether a quick pointer in the right direction or the whole proof (or a proof or example that the two aren't identical). Note also that ${1 - {\left( {1 - p} \right)}^N} = {{\sum\limits_{i = 1}^N {\left( {\begin{array}{*{20}{c}} N\\ i \end{array}} \right){p^i}{{\left( {1 - p} \right)}^{N - i}}} }}$ and that ${p = {1 - {\left( {1 - p} \right)}^1}}$ For background, see the current draft with relevant highlightings here .","While writing a (non-math) paper I came across the following apparent identity: $N \cdot \mathop \sum \limits_{i = 1}^N \frac{1}{i}\left( {\begin{array}{*{20}{c}} {N - 1}\\ {i - 1} \end{array}} \right){p^{i - 1}}{\left( {1 - p} \right)^{N - i}} = \frac{{1 - {{\left( {1 - p} \right)}^N}}}{p}$ where $N$ is a positive integer and $p$ is a nonzero probability. Based on intuition and some manual checks, this looks like it should be true for all such $N$ and $p$. I can't prove this, and being mostly ignorant about math, I don't know how to learn what I need to prove this. I'd really appreciate anything helpful, whether a quick pointer in the right direction or the whole proof (or a proof or example that the two aren't identical). Note also that ${1 - {\left( {1 - p} \right)}^N} = {{\sum\limits_{i = 1}^N {\left( {\begin{array}{*{20}{c}} N\\ i \end{array}} \right){p^i}{{\left( {1 - p} \right)}^{N - i}}} }}$ and that ${p = {1 - {\left( {1 - p} \right)}^1}}$ For background, see the current draft with relevant highlightings here .",,"['probability', 'combinatorics', 'statistics']"
6,Detecting significant decreases in a signal,Detecting significant decreases in a signal,,"I'd like to find a way to detect a significant drop/decrease in a signal.  Below is an actual example of what I'd like to accomplish, with the arrow denoting the change that I'd like to detect (only the red curve). The data is fairly straightforward...the x-values are integers starting from zero and increasing by 1 at each data point.  The y-values are also integers.  I know that the dip I'd like to detect always occurs after the minimum value (denoted by the small circle).  However, I'm not sure of the best way to find this drop. What's the best methodology or algorithm for a situation like this?","I'd like to find a way to detect a significant drop/decrease in a signal.  Below is an actual example of what I'd like to accomplish, with the arrow denoting the change that I'd like to detect (only the red curve). The data is fairly straightforward...the x-values are integers starting from zero and increasing by 1 at each data point.  The y-values are also integers.  I know that the dip I'd like to detect always occurs after the minimum value (denoted by the small circle).  However, I'm not sure of the best way to find this drop. What's the best methodology or algorithm for a situation like this?",,"['statistics', 'signal-processing']"
7,Can this statistics question be solved as it stands?,Can this statistics question be solved as it stands?,,"I have been presented with the following question: An attorney claims that more than 25% of all lawyers advertise. A sample of 200 lawyers in a certain city showed that 63 had used some form of advertisement. At $\alpha$ = 0.05 is there enough evidence to support the attorney's claim? Use the P-value method. I don't know what method I should use to solve it, because it seems as though a standard deviation is needed in order to generate a test-statistic. I believe a z-score test will be used but I can't be positive. Can anyone shed light on this situation? Thanks!","I have been presented with the following question: An attorney claims that more than 25% of all lawyers advertise. A sample of 200 lawyers in a certain city showed that 63 had used some form of advertisement. At $\alpha$ = 0.05 is there enough evidence to support the attorney's claim? Use the P-value method. I don't know what method I should use to solve it, because it seems as though a standard deviation is needed in order to generate a test-statistic. I believe a z-score test will be used but I can't be positive. Can anyone shed light on this situation? Thanks!",,['statistics']
8,What is to median as first central moment is to mean?,What is to median as first central moment is to mean?,,"The question sounds like a riddle, but it isn't intended to be one. I've been thinking about the Cauchy Distribution which, famously doesn't have any central moments defined.  A very informal justification for this  is that as the angle approaches $\pm90^\circ$ from the origin, the value of the function tends quickly to infinity... hence, if we were to attempt to calculate the mean, its value would vary to $\pm\infty$ very, easily.  Essentially, rather than summarise the data-set as a whole, one would identify only whether or not your samples were biased very slightly to the positive or negative values. An obvious approach to establish an estimate of expected value would be to calculate the median - which would avoid the outlying data points overwhelming the summary.  This single scalar summary value - analogous to mean - then suggests a more reasonable estimate of 'expected' value in some circumstances.  Is it common to extend such analysis with measures analogous to variance, skew and kurtosis - to better describe the distribution?  If so, how are these concepts commonly defined? UPDATE: Many thanks for the pointer to MAD... that's definitely relevant.  While I wasn't clear about this previously, central moments appealed because they generated a progression of values each further refining the description of a normal distribution... and I really hoped to do something similar for systems where the empirical mean and standard deviation can't be trusted to give a meaningful summary.","The question sounds like a riddle, but it isn't intended to be one. I've been thinking about the Cauchy Distribution which, famously doesn't have any central moments defined.  A very informal justification for this  is that as the angle approaches $\pm90^\circ$ from the origin, the value of the function tends quickly to infinity... hence, if we were to attempt to calculate the mean, its value would vary to $\pm\infty$ very, easily.  Essentially, rather than summarise the data-set as a whole, one would identify only whether or not your samples were biased very slightly to the positive or negative values. An obvious approach to establish an estimate of expected value would be to calculate the median - which would avoid the outlying data points overwhelming the summary.  This single scalar summary value - analogous to mean - then suggests a more reasonable estimate of 'expected' value in some circumstances.  Is it common to extend such analysis with measures analogous to variance, skew and kurtosis - to better describe the distribution?  If so, how are these concepts commonly defined? UPDATE: Many thanks for the pointer to MAD... that's definitely relevant.  While I wasn't clear about this previously, central moments appealed because they generated a progression of values each further refining the description of a normal distribution... and I really hoped to do something similar for systems where the empirical mean and standard deviation can't be trusted to give a meaningful summary.",,"['probability', 'statistics', 'probability-distributions']"
9,Why is the Kendall tau distance a metric?,Why is the Kendall tau distance a metric?,,"So I am trying to see how the Kendall $\tau$ distance is considered a metric; i.e. that it satisfies the triangle inequality. The Kendall $\tau$ distance is defined as follows: $$K(\tau_1,\tau_2) = |(i,j): i < j, ( \tau_1(i) < \tau_1(j) \land \tau_2(i) > \tau_2(j) ) \lor ( \tau_1(i) > \tau_1(j) \land \tau_2(i) < \tau_2(j) )|$$ Thank you in advance.","So I am trying to see how the Kendall $\tau$ distance is considered a metric; i.e. that it satisfies the triangle inequality. The Kendall $\tau$ distance is defined as follows: $$K(\tau_1,\tau_2) = |(i,j): i < j, ( \tau_1(i) < \tau_1(j) \land \tau_2(i) > \tau_2(j) ) \lor ( \tau_1(i) > \tau_1(j) \land \tau_2(i) < \tau_2(j) )|$$ Thank you in advance.",,['statistics']
10,Estimate a upper bound of IQ scores,Estimate a upper bound of IQ scores,,"Suppose the IQ scores of a million individuals have a mean of 100 and an SD of 10. a)Without making any further assumptions about the distribution of the cores, find an upper bound on the number of scores exceeding 130 b)Find a smaller upper bound on the number of scores exceeding 130 assuming the distribution of scores is symmetric about 100. For part a. I used Chebychev's Inequality to calculate the upper bound which the probability is $1/3^2 = 1/9$ And for part b, I understand that if the distribution is symmetric about 100 implies that $P(X\ge 130) = P(X\le 70)$, but I am not sure how to get a smaller upper bound. Can someone help me here? And how many methods of finding an upper bound of a distribution are there in general?","Suppose the IQ scores of a million individuals have a mean of 100 and an SD of 10. a)Without making any further assumptions about the distribution of the cores, find an upper bound on the number of scores exceeding 130 b)Find a smaller upper bound on the number of scores exceeding 130 assuming the distribution of scores is symmetric about 100. For part a. I used Chebychev's Inequality to calculate the upper bound which the probability is $1/3^2 = 1/9$ And for part b, I understand that if the distribution is symmetric about 100 implies that $P(X\ge 130) = P(X\le 70)$, but I am not sure how to get a smaller upper bound. Can someone help me here? And how many methods of finding an upper bound of a distribution are there in general?",,"['probability', 'statistics']"
11,mean and std deviation of a population equal?,mean and std deviation of a population equal?,,"Hypothetically, if we have a population of size $n$ whose mean and std deviation are equal, I think with some work we have a constraint that the ratio, (Sum of squared points)/(Sum of points$)^2$ $= \frac{(2n-1)}{n^2}$, which gets small quickly as $n$ gets large. Are there heuristic considerations that might render such a population plausible as an extension of, say, the binomial distribution (as with the Poisson distribution, although that distribution the mean is equal to the variance)? Does this property (mean = Sqrt[variance] ) suggest anything about the population generally, if that question is not too vague? I have not encountered a population with this property in any texts, but am fairly sure it has been considered...?","Hypothetically, if we have a population of size $n$ whose mean and std deviation are equal, I think with some work we have a constraint that the ratio, (Sum of squared points)/(Sum of points$)^2$ $= \frac{(2n-1)}{n^2}$, which gets small quickly as $n$ gets large. Are there heuristic considerations that might render such a population plausible as an extension of, say, the binomial distribution (as with the Poisson distribution, although that distribution the mean is equal to the variance)? Does this property (mean = Sqrt[variance] ) suggest anything about the population generally, if that question is not too vague? I have not encountered a population with this property in any texts, but am fairly sure it has been considered...?",,['statistics']
12,Expectation of absorption time for a random walk which remains at n with probability 1/2,Expectation of absorption time for a random walk which remains at n with probability 1/2,,"A random walk moves from k to k+1 with probability 1/2 and to k-1 with probability 1/2, except when k=n, in which case it remains at n with probability 1/2 and moves to n-1 with probability 1/2. Suppose it starts at n. Let T be the first time the path reaches 0. What is the expected value of T? Is there an easy way to solve this using well known facts about Markov chains? This is problem 2.3 of the book Markov Chains and Mixing Times (by David A. Levin, Yuval Peres, and Elizabeth Wilmer). Their solution is clearly wrong as it seems to assume the path goes down to n-1 with probability 1.","A random walk moves from k to k+1 with probability 1/2 and to k-1 with probability 1/2, except when k=n, in which case it remains at n with probability 1/2 and moves to n-1 with probability 1/2. Suppose it starts at n. Let T be the first time the path reaches 0. What is the expected value of T? Is there an easy way to solve this using well known facts about Markov chains? This is problem 2.3 of the book Markov Chains and Mixing Times (by David A. Levin, Yuval Peres, and Elizabeth Wilmer). Their solution is clearly wrong as it seems to assume the path goes down to n-1 with probability 1.",,"['probability', 'statistics', 'random-walk']"
13,"Birthday attack/problem, calculate exact numbers? [duplicate]","Birthday attack/problem, calculate exact numbers? [duplicate]",,"This question already has answers here : Closed 12 years ago . Possible Duplicate: Birthday-coverage problem An example of what I wish to do is the following: https://stackoverflow.com/questions/4681913/substr-md5-collision/4785456#4785456 How would I calculate how many people would be required, as in the link above, to reach 50% or 0.001% or n % probability of collision exactly? I am able to calculate the likelyhood of a collision in say a hash, with $1-e^\frac{-n^2}{(2*10^6)}$ 10^6 being six numerical digits from zero to nine. However, I would have to guess a lot of times before I got the exact number of people it would take to reach exactly 50%, which may be a fraction (i.e. 20.2 people) How would I be able to find this?","This question already has answers here : Closed 12 years ago . Possible Duplicate: Birthday-coverage problem An example of what I wish to do is the following: https://stackoverflow.com/questions/4681913/substr-md5-collision/4785456#4785456 How would I calculate how many people would be required, as in the link above, to reach 50% or 0.001% or n % probability of collision exactly? I am able to calculate the likelyhood of a collision in say a hash, with $1-e^\frac{-n^2}{(2*10^6)}$ 10^6 being six numerical digits from zero to nine. However, I would have to guess a lot of times before I got the exact number of people it would take to reach exactly 50%, which may be a fraction (i.e. 20.2 people) How would I be able to find this?",,"['probability', 'statistics', 'birthday']"
14,Why do we subtract the variance?,Why do we subtract the variance?,,"This is not a question for doing my homework. This is a question to understand the deeper meaning of the answer. So in part b), it subtracts the variance. Why do we subtract variance and what does it mean to subtract variance? I understood variance as the distance the numbers are spread apart, so what does subtracting that mean? Question: Suppose that 30% of all students who   have to buy a text for a particular   course want a new copy (the   successes!), whereas the other 70%   want a used copy. Consider randomly   selecting 25 purchasers. a. What are   the mean value and standard deviation   of the number who want a new copy of   the book? b. What is the probability   that the number who want new copies is   more than two standard deviations away   from the mean value? Answer: X ~ Bin(25,.3) a. E(X) = np = 7.5;   Var(X) = npq = 5.25 → SD(X) = 2.29 b.    P(|X – 5.25| > 2(2.29)) = P(X <   0.67 or X > 9.83) = P(X = 0) + P(X > 9.83) = b(0;25,.3) + 1 – P(X ≤ 9) = b(0;25,.3) + 1 – B(9;25,.3) = .000 + 1   – .811 = .189","This is not a question for doing my homework. This is a question to understand the deeper meaning of the answer. So in part b), it subtracts the variance. Why do we subtract variance and what does it mean to subtract variance? I understood variance as the distance the numbers are spread apart, so what does subtracting that mean? Question: Suppose that 30% of all students who   have to buy a text for a particular   course want a new copy (the   successes!), whereas the other 70%   want a used copy. Consider randomly   selecting 25 purchasers. a. What are   the mean value and standard deviation   of the number who want a new copy of   the book? b. What is the probability   that the number who want new copies is   more than two standard deviations away   from the mean value? Answer: X ~ Bin(25,.3) a. E(X) = np = 7.5;   Var(X) = npq = 5.25 → SD(X) = 2.29 b.    P(|X – 5.25| > 2(2.29)) = P(X <   0.67 or X > 9.83) = P(X = 0) + P(X > 9.83) = b(0;25,.3) + 1 – P(X ≤ 9) = b(0;25,.3) + 1 – B(9;25,.3) = .000 + 1   – .811 = .189",,['statistics']
15,"How to calculate the expected value $E(XY)$ with known $E(X)$, $E(Y)$ and $\sigma_{i}$?","How to calculate the expected value  with known ,  and ?",E(XY) E(X) E(Y) \sigma_{i},"I am trying to understand the value of $\bar{x_{1} x_{2}}+E(x_{1} x_{2})$. For all $i$, $E(x_{i})$ and $\sigma_{i}$ are given. Wikipedia gives the joint probability density function: $E(XY) = \int \int x y j(x,y) dx dy$ then I can find out from wikipedia that: $E(XY) = Cov(X,Y) + E(X)E(Y)$ and by Cauchy-Swartz: $| Cov(X,Y) | \leq \sigma(X) \sigma(Y)$ but I cannot find a precise formula to find the value of $E(XY)$, only an upper bound with finite variances. A crux point to find the matrix $\rho$ so that I can calculate the $\sigma$ matrix. So how can I calculate the $E(XY)$ when only $E(x_{i})$ and $\sigma_{i}$ for all $i$ are given?","I am trying to understand the value of $\bar{x_{1} x_{2}}+E(x_{1} x_{2})$. For all $i$, $E(x_{i})$ and $\sigma_{i}$ are given. Wikipedia gives the joint probability density function: $E(XY) = \int \int x y j(x,y) dx dy$ then I can find out from wikipedia that: $E(XY) = Cov(X,Y) + E(X)E(Y)$ and by Cauchy-Swartz: $| Cov(X,Y) | \leq \sigma(X) \sigma(Y)$ but I cannot find a precise formula to find the value of $E(XY)$, only an upper bound with finite variances. A crux point to find the matrix $\rho$ so that I can calculate the $\sigma$ matrix. So how can I calculate the $E(XY)$ when only $E(x_{i})$ and $\sigma_{i}$ for all $i$ are given?",,['statistics']
16,Calculating probability with a piecewise density function,Calculating probability with a piecewise density function,,"I tried solving this, and I am pretty sure I am integrating this correctly, however, my solution manual shows -1 in the equation when doing this and I do not know why.  The answer in the solution manual is correct. Problem: Find the corresponding distribution function and use it to determine the probability that a random variable having the distribution function will take on a value between 0.4 and 1.6. f(x) = x for 0 < x < 1        2-x for 1 <= x < 2        0 elsewhere so for F(0.4 < x < 1.6) I did after integrating: 2(1.6) - [(1.6)^2 / 2] - [(0.4)^2 / 2] = 1.84 however the correct answer is 0.84.  The solution manual has a -1 in their equation, but I do not know how they got it.","I tried solving this, and I am pretty sure I am integrating this correctly, however, my solution manual shows -1 in the equation when doing this and I do not know why.  The answer in the solution manual is correct. Problem: Find the corresponding distribution function and use it to determine the probability that a random variable having the distribution function will take on a value between 0.4 and 1.6. f(x) = x for 0 < x < 1        2-x for 1 <= x < 2        0 elsewhere so for F(0.4 < x < 1.6) I did after integrating: 2(1.6) - [(1.6)^2 / 2] - [(0.4)^2 / 2] = 1.84 however the correct answer is 0.84.  The solution manual has a -1 in their equation, but I do not know how they got it.",,"['statistics', 'integration', 'probability']"
17,Confusing statement in stats book,Confusing statement in stats book,,"I just picked up a book, and while I was skimming through it one statement caught my eye. In Chapter 2, page 47 of Statistical Inference it reads: If X is a random variable with cdf $F_X(x)$ then any function of X, say g(X), is also random variable. I am not quick to assume that book is in the wrong, but it is the case now isn't it? It should only hold for discrete $X$ or by adding assumption that $g$ is measurable. A bit off topic: this book is recommended a lot and presented as rigorous ( for example here ), but all the books I've read on stats completely disregard measure theory and skip technical aspects. Is it just a normal approach in statistics and I am not missing out by going with such books, or should i get something more technical?","I just picked up a book, and while I was skimming through it one statement caught my eye. In Chapter 2, page 47 of Statistical Inference it reads: If X is a random variable with cdf then any function of X, say g(X), is also random variable. I am not quick to assume that book is in the wrong, but it is the case now isn't it? It should only hold for discrete or by adding assumption that is measurable. A bit off topic: this book is recommended a lot and presented as rigorous ( for example here ), but all the books I've read on stats completely disregard measure theory and skip technical aspects. Is it just a normal approach in statistics and I am not missing out by going with such books, or should i get something more technical?",F_X(x) X g,"['statistics', 'book-recommendation']"
18,Expected Number of Dice Rolls to See All Sides,Expected Number of Dice Rolls to See All Sides,,"I want to check if the solution to the following question is an application of the property $E[X + Y] = E[X] + E[Y]$ . The question: What is the expected number of rolls needed to see all six sides of a fair die? The solution: We find that as we continue to make rolls and as we continue to see new values, the probability of seeing a new value changes overtime, from 1 to $\frac{5}{6}$ to $\frac{4}{6}$ and so on until we get to $\frac{1}{6}$ .  By treating each roll as a Geometric Random Variable, we find that the expected value of each of these rolls is given by $\frac{1}{p}$ , so for example after the first roll, the second roll's expected value would be $\frac{6}{5}$ . By adding up all these expectations, we find that the expected number of rolls needed to see all six sides of a fair die is 14.7 I'm asking because I'm having difficulty reconciling this solution with my understanding of the definition of expectation for discrete random variables, which is $E[X] = \Sigma xp(x)$ .","I want to check if the solution to the following question is an application of the property . The question: What is the expected number of rolls needed to see all six sides of a fair die? The solution: We find that as we continue to make rolls and as we continue to see new values, the probability of seeing a new value changes overtime, from 1 to to and so on until we get to .  By treating each roll as a Geometric Random Variable, we find that the expected value of each of these rolls is given by , so for example after the first roll, the second roll's expected value would be . By adding up all these expectations, we find that the expected number of rolls needed to see all six sides of a fair die is 14.7 I'm asking because I'm having difficulty reconciling this solution with my understanding of the definition of expectation for discrete random variables, which is .",E[X + Y] = E[X] + E[Y] \frac{5}{6} \frac{4}{6} \frac{1}{6} \frac{1}{p} \frac{6}{5} E[X] = \Sigma xp(x),"['probability', 'statistics', 'expected-value', 'means']"
19,"""Show that T is an unbiased estimator"" follow-up","""Show that T is an unbiased estimator"" follow-up",,"Yesterday I posted this question Show that $T$ is an unbiased estimator and with the help of others, I got to understand why $T=\frac{n+1}{2n+1}X_{(n)}$ is an unbiased estimator of $\theta$ , with regard to the PDF $f(x)$ in the question. Following the same reasoning, I proved the second part of the exercise, that $U=\frac{n+1}{5n+4}(2X_{(n)}+X_{(1)})$ is also an unbiased estimator of $\theta$ . So, we have $E[T]=E[U]=\theta$ . Now, onto the thrid part of the exercise, where I need a bit of help. I am asked to show that $Var(T)\geqslant Var(U)$ . I choosed the straight-forward path (using $Var(X)=E[X^2]-(E[X])^2$ ) ; $$Var(T)\geqslant Var(U) \iff E[T^2]-(E[T])^2 \geqslant E[U^2]-(E[U])^2 \iff E[T^2] \geqslant E[U^2]$$ since $(E[T])^2 = (E[U])^2 = \theta$ . Moving on, $$E[\left(\frac{n+1}{2n+1}X_{(n)}\right)^2] \geqslant E[\left(\frac{n+1}{5n+4}(2X_{(n)}+X_{(1)})\right)^2]$$ $$\iff  \left(\frac{n+1}{2n+1}\right)^2 E[(X_{(n)})^2] \geqslant \left(\frac{n+1}{5n+4}\right)^2 E[(2X_{(n)}+X_{(1)})^2$$ $$\iff \left(\frac{1}{2n+1}\right)^2 E[(X_{(n)})^2] \geqslant \left(\frac{1}{5n+4}\right)^2 (E \left[4(X_{(n)})^2+ 4X_{(1)}X_{(n)}+ (X_{(1)})^2 \right]$$ $$\iff \left(\frac{5n+4}{2n+1}\right)^2 E[(X_{(n)})^2] \geqslant 4E(X_{(n)})^2 ]+ 4E[X_{(1)}X_{(n)} ]+ E[(X_{(1)})^2 ]$$ $$\iff \left( \left(\frac{5n+4}{2n+1}\right)^2 -4\right)E(X_{(n)})^2 ] \geqslant 4E[X_{(1)}X_{(n)} ]+ E[(X_{(1)})^2 ]$$ Now, we know that if $X\geqslant Y$ , then $E[X] \geqslant E[Y]$ . Since $X_{(n)}=max{X_i}, i=1,2,....,n$ , then it is obvious that $E(X_{(n)})^2 ] \geqslant E[X_{(1)}X_{(n)} ]$ and that $E(X_{(n)})^2 ] \geqslant E[(X_{(1)})^2 ]$ (all of the variables are positive, if that matters). So, $$4E[X_{(1)}X_{(n)} ]+E[(X_{(1)})^2 ] \leqslant 5E[(X_{(n)})^2 ]$$ Therefore, if I manage to show that $$\left( \left(\frac{5n+4}{2n+1}\right)^2 -4\right)E[(X_{(n)})^2 \geqslant 5E(X_{(n)})^2 ]$$ the proof will be over. $$\left( \left(\frac{5n+4}{2n+1}\right)^2 -4\right)E[(X_{(n)})^2 \geqslant 5E(X_{(n)})^2 ]$$ $$\iff \left(\frac{5n+4}{2n+1}\right)^2 -4 \geqslant 5$$ $$\iff \left(\frac{5n+4}{2n+1}\right)^2  \geqslant 9=3^2$$ $$\iff \frac{5n+4}{2n+1} \geqslant 3$$ (the negative solutions are not acceptable, since $n$ is the number of the sample we get, hence positive) $$\iff 5n+4 \geqslant 6n+3 \iff n \leqslant 1$$ Now, clearly that cannot be, in fact I should get exactly the opposite inequality $n \geqslant 1$ . So, two things may be happening; either $a)$ The exercise has a typo, and $Var(T)\leqslant Var(U)$ and not "" $\geqslant$ "", or $b$ ) I have made a mistake, either in my reasoning or in the calculations. Once again, any help would be really helpful, to confirm that the exercise indeed has a typo or to   find out what the mistake is. Thanks in advance (and sorry for the long, long text)!","Yesterday I posted this question Show that $T$ is an unbiased estimator and with the help of others, I got to understand why is an unbiased estimator of , with regard to the PDF in the question. Following the same reasoning, I proved the second part of the exercise, that is also an unbiased estimator of . So, we have . Now, onto the thrid part of the exercise, where I need a bit of help. I am asked to show that . I choosed the straight-forward path (using ) ; since . Moving on, Now, we know that if , then . Since , then it is obvious that and that (all of the variables are positive, if that matters). So, Therefore, if I manage to show that the proof will be over. (the negative solutions are not acceptable, since is the number of the sample we get, hence positive) Now, clearly that cannot be, in fact I should get exactly the opposite inequality . So, two things may be happening; either The exercise has a typo, and and not "" "", or ) I have made a mistake, either in my reasoning or in the calculations. Once again, any help would be really helpful, to confirm that the exercise indeed has a typo or to   find out what the mistake is. Thanks in advance (and sorry for the long, long text)!","T=\frac{n+1}{2n+1}X_{(n)} \theta f(x) U=\frac{n+1}{5n+4}(2X_{(n)}+X_{(1)}) \theta E[T]=E[U]=\theta Var(T)\geqslant Var(U) Var(X)=E[X^2]-(E[X])^2 Var(T)\geqslant Var(U) \iff E[T^2]-(E[T])^2 \geqslant E[U^2]-(E[U])^2 \iff E[T^2] \geqslant E[U^2] (E[T])^2 = (E[U])^2 = \theta E[\left(\frac{n+1}{2n+1}X_{(n)}\right)^2] \geqslant E[\left(\frac{n+1}{5n+4}(2X_{(n)}+X_{(1)})\right)^2] \iff  \left(\frac{n+1}{2n+1}\right)^2 E[(X_{(n)})^2] \geqslant \left(\frac{n+1}{5n+4}\right)^2 E[(2X_{(n)}+X_{(1)})^2 \iff \left(\frac{1}{2n+1}\right)^2 E[(X_{(n)})^2] \geqslant \left(\frac{1}{5n+4}\right)^2 (E \left[4(X_{(n)})^2+ 4X_{(1)}X_{(n)}+ (X_{(1)})^2 \right] \iff \left(\frac{5n+4}{2n+1}\right)^2 E[(X_{(n)})^2] \geqslant 4E(X_{(n)})^2 ]+ 4E[X_{(1)}X_{(n)} ]+ E[(X_{(1)})^2 ] \iff \left( \left(\frac{5n+4}{2n+1}\right)^2 -4\right)E(X_{(n)})^2 ] \geqslant 4E[X_{(1)}X_{(n)} ]+ E[(X_{(1)})^2 ] X\geqslant Y E[X] \geqslant E[Y] X_{(n)}=max{X_i}, i=1,2,....,n E(X_{(n)})^2 ] \geqslant E[X_{(1)}X_{(n)} ] E(X_{(n)})^2 ] \geqslant E[(X_{(1)})^2 ] 4E[X_{(1)}X_{(n)} ]+E[(X_{(1)})^2 ] \leqslant 5E[(X_{(n)})^2 ] \left( \left(\frac{5n+4}{2n+1}\right)^2 -4\right)E[(X_{(n)})^2 \geqslant 5E(X_{(n)})^2 ] \left( \left(\frac{5n+4}{2n+1}\right)^2 -4\right)E[(X_{(n)})^2 \geqslant 5E(X_{(n)})^2 ] \iff \left(\frac{5n+4}{2n+1}\right)^2 -4 \geqslant 5 \iff \left(\frac{5n+4}{2n+1}\right)^2  \geqslant 9=3^2 \iff \frac{5n+4}{2n+1} \geqslant 3 n \iff 5n+4 \geqslant 6n+3 \iff n \leqslant 1 n \geqslant 1 a) Var(T)\leqslant Var(U) \geqslant b","['statistics', 'variance']"
20,"Central Limit Theorem and Law of Large Numbers for Non-Constant ""N""?","Central Limit Theorem and Law of Large Numbers for Non-Constant ""N""?",,"This is a question I have been having for a while. Usually, we define the Central Limit Theorem as: Let $X_1, X_2, \dots, X_n$ be a random sample of size $n$ from a population with mean $\mu$ and finite variance $\sigma^2$ . As $n$ approaches infinity, the distribution of the sample mean $\overline{X}$ converges to a normal distribution with mean $\mu$ and variance $\frac{\sigma^2}{n}$ , i.e., $$\sqrt{n} \left( \frac{\overline{X} - \mu}{\sigma} \right) \xrightarrow{d} N(0,1)$$ Similarly, we can also define the Law of Large Numbers as: Let $X_1, X_2, \dots, X_n$ be a sequence of independent and identically distributed random variables with finite mean $\mu$ . The Law of Large Numbers states that as the sample size $n$ increases, the sample mean $\overline{X}$ converges in probability to the population mean $\mu$ , i.e., $$\overline{X} = \frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{p} \mu$$ Given this definition, I thought of the following example: Suppose there are fish in a river Naturally, fish have the ability to enter and exit the river (e.g. birth , death, migration) We are interested in estimating the average mercury level in the average fish Suppose we take a random sample of fish from this river and measure the mercury level of each fish in the sample In most introductory mathematics textbooks, we would use both the Central Limit Theorem and Law of Large Numbers to argue that : As we measure the mercury level of more and more fish - our average sample measurement would better and better reflect the true average mercury measurement of the population. However, it seems that there is an implicit assumption that the underlying fish population of the river is constant. This brings me to my question: Are there any variations of the Central Limit Theorem and Law of Large Numbers that can be applied in situations where the population size is not-constant? Or is this actually irrelevant? (i.e. The results of both the Central Limit Theorem and Law of Large Numbers are still valid when the population size is non-constant provided that there is a large enough sample size?) Thanks!","This is a question I have been having for a while. Usually, we define the Central Limit Theorem as: Let be a random sample of size from a population with mean and finite variance . As approaches infinity, the distribution of the sample mean converges to a normal distribution with mean and variance , i.e., Similarly, we can also define the Law of Large Numbers as: Let be a sequence of independent and identically distributed random variables with finite mean . The Law of Large Numbers states that as the sample size increases, the sample mean converges in probability to the population mean , i.e., Given this definition, I thought of the following example: Suppose there are fish in a river Naturally, fish have the ability to enter and exit the river (e.g. birth , death, migration) We are interested in estimating the average mercury level in the average fish Suppose we take a random sample of fish from this river and measure the mercury level of each fish in the sample In most introductory mathematics textbooks, we would use both the Central Limit Theorem and Law of Large Numbers to argue that : As we measure the mercury level of more and more fish - our average sample measurement would better and better reflect the true average mercury measurement of the population. However, it seems that there is an implicit assumption that the underlying fish population of the river is constant. This brings me to my question: Are there any variations of the Central Limit Theorem and Law of Large Numbers that can be applied in situations where the population size is not-constant? Or is this actually irrelevant? (i.e. The results of both the Central Limit Theorem and Law of Large Numbers are still valid when the population size is non-constant provided that there is a large enough sample size?) Thanks!","X_1, X_2, \dots, X_n n \mu \sigma^2 n \overline{X} \mu \frac{\sigma^2}{n} \sqrt{n} \left( \frac{\overline{X} - \mu}{\sigma} \right) \xrightarrow{d} N(0,1) X_1, X_2, \dots, X_n \mu n \overline{X} \mu \overline{X} = \frac{1}{n} \sum_{i=1}^n X_i \xrightarrow{p} \mu","['probability', 'statistics', 'central-limit-theorem', 'law-of-large-numbers']"
21,Convergence in distribution to the derivative,Convergence in distribution to the derivative,,"Let $f(x)$ has a derivative in point $x = 0$ . Then if for sequences of random variables $\left\{\xi_n\right\}_{n = 1} ^ \infty, \left\{\eta_n\right\}_{n = 1} ^ \infty$ we have: $$ \xi_n\eta_n \xrightarrow{d} \eta\\ \eta_n \xrightarrow{\mathbb{P}} 0 $$ then $\xi_n(f(\eta_n) - f(0)) \xrightarrow{d} f'(0)\eta$ . My solution looks something like this: By the hereditary convergence theorem for continuous function $h(x) = 1/x$ i can write $\frac{1}{\xi_n\eta_n} \xrightarrow{d} \frac{1}{\eta}$ . Since $\eta_n \xrightarrow{\mathbb{P}} 0$ , then $\eta_n \xrightarrow{d} 0$ . So, i can write by Slutsky's Theorem that $\frac{\eta_n}{\xi_n\eta_n} \xrightarrow{d} 0$ . Then i use following theorem. Let $\xi_n \xrightarrow{d} \xi$ . For a function $h(x)$ differentiable at a point and a sequence $b_n \rightarrow 0, b_n \neq 0$ , the following holds: $$ \frac{h(a + \xi_nb_n) - h(a)}{b_n} \xrightarrow{d} h'(a)\xi $$ where I put $b_n = \frac{1}{\xi_n}$ and $\xi_n = \xi_n\eta_n$ But I'm not sure about this solution because the function $\frac{1}{x}$ is not continuous at zero. I would be very grateful for the hint","Let has a derivative in point . Then if for sequences of random variables we have: then . My solution looks something like this: By the hereditary convergence theorem for continuous function i can write . Since , then . So, i can write by Slutsky's Theorem that . Then i use following theorem. Let . For a function differentiable at a point and a sequence , the following holds: where I put and But I'm not sure about this solution because the function is not continuous at zero. I would be very grateful for the hint","f(x) x = 0 \left\{\xi_n\right\}_{n = 1} ^ \infty, \left\{\eta_n\right\}_{n = 1} ^ \infty 
\xi_n\eta_n \xrightarrow{d} \eta\\
\eta_n \xrightarrow{\mathbb{P}} 0
 \xi_n(f(\eta_n) - f(0)) \xrightarrow{d} f'(0)\eta h(x) = 1/x \frac{1}{\xi_n\eta_n} \xrightarrow{d} \frac{1}{\eta} \eta_n \xrightarrow{\mathbb{P}} 0 \eta_n \xrightarrow{d} 0 \frac{\eta_n}{\xi_n\eta_n} \xrightarrow{d} 0 \xi_n \xrightarrow{d} \xi h(x) b_n \rightarrow 0, b_n \neq 0 
\frac{h(a + \xi_nb_n) - h(a)}{b_n} \xrightarrow{d} h'(a)\xi
 b_n = \frac{1}{\xi_n} \xi_n = \xi_n\eta_n \frac{1}{x}","['probability', 'statistics']"
22,"Odds of Winning Viral ""Number Ordering"" Game","Odds of Winning Viral ""Number Ordering"" Game",,"I have recently seen on social media a game that is quite amusing and addicting to watch. Here is a link to a guy playing it. Here is a description of the specific rendition I just shared. Given a RNG that gives $20$ random numbers between $1$ and $1000$ , sequentially order the numbers without knowing what is going to come next with the intention of having all $20$ numbers sorted at the end (i.e. if you draw $500$ rank it at ~ $10$ , then rank the next number, then the next, etc.) At the end of the game if all $20$ numbers are sorted properly in increasing order you win, if they are not you lose. Let's assume for the purpose of this analysis that the set of numbers we are drawing from is sufficiently large that we do not have to worry about repeating numbers. We can just assume we are drawing random real numbers between $0$ and $1$ if you will. And also since we have no idea of the numbers that are going to come the only strategy that we can employ to win the game is basic statistical ranking, assuming a uniformly distributed RNG. My question is: What are the odds of winning this game for $n$ randomly drawn numbers that are to be ordered? The case for when $n=2$ is straight forward. If the numbers drawn are $a$ and $b$ respectively, if $a$ is greater than $0.5$ it will be ranked at $2$ and so we will win if $b$ is smaller than $a$ , the opposite is true in the other case. In the first case we will win an average of $\frac{3}{4}$ of the time, and so too in the second case. So we can expect to win about $\frac{3}{4}$ of the time for $n=2$ . I have been working on some code to simulate the game and the ranking process to get some Monte Carlo results. But I would be interested in a closed form solution.","I have recently seen on social media a game that is quite amusing and addicting to watch. Here is a link to a guy playing it. Here is a description of the specific rendition I just shared. Given a RNG that gives random numbers between and , sequentially order the numbers without knowing what is going to come next with the intention of having all numbers sorted at the end (i.e. if you draw rank it at ~ , then rank the next number, then the next, etc.) At the end of the game if all numbers are sorted properly in increasing order you win, if they are not you lose. Let's assume for the purpose of this analysis that the set of numbers we are drawing from is sufficiently large that we do not have to worry about repeating numbers. We can just assume we are drawing random real numbers between and if you will. And also since we have no idea of the numbers that are going to come the only strategy that we can employ to win the game is basic statistical ranking, assuming a uniformly distributed RNG. My question is: What are the odds of winning this game for randomly drawn numbers that are to be ordered? The case for when is straight forward. If the numbers drawn are and respectively, if is greater than it will be ranked at and so we will win if is smaller than , the opposite is true in the other case. In the first case we will win an average of of the time, and so too in the second case. So we can expect to win about of the time for . I have been working on some code to simulate the game and the ranking process to get some Monte Carlo results. But I would be interested in a closed form solution.",20 1 1000 20 500 10 20 0 1 n n=2 a b a 0.5 2 b a \frac{3}{4} \frac{3}{4} n=2,"['statistics', 'random-variables', 'combinations']"
23,Chi-squared convergence to the Gaussian distribution,Chi-squared convergence to the Gaussian distribution,,"I'm taking a Statistics course this semester and the professor mentioned that the chi-squared distribution $\chi_n^2$ satisfies that $$\sqrt{2\chi_n^2}-\sqrt{2n-1}$$ converges to a Gaussian distribution. I have been looking for a proof of this result, but haven't found one. We have defined the chi-squared distribution via its density function: $$ f(x)=\left\{\begin{array}{rl} 0 & \text{if }x\leq 0 \\ \frac{x^{n/2-1}e^{x/2}}{2^{n/2}\Gamma(n/2)} & \text{if }x>0 \end{array} \right. $$ and also shown that, if n is a positive integer, it follows the same distribution as the sum of $n$ independent squared gaussian variables. I am familiar with the concept of generating functions and the central limit theorem. Is there a reference for a proof of this result? Preferrably, one that uses the definitions and results stated above. If not, could I be provided with one?","I'm taking a Statistics course this semester and the professor mentioned that the chi-squared distribution satisfies that converges to a Gaussian distribution. I have been looking for a proof of this result, but haven't found one. We have defined the chi-squared distribution via its density function: and also shown that, if n is a positive integer, it follows the same distribution as the sum of independent squared gaussian variables. I am familiar with the concept of generating functions and the central limit theorem. Is there a reference for a proof of this result? Preferrably, one that uses the definitions and results stated above. If not, could I be provided with one?","\chi_n^2 \sqrt{2\chi_n^2}-\sqrt{2n-1} 
f(x)=\left\{\begin{array}{rl}
0 & \text{if }x\leq 0 \\
\frac{x^{n/2-1}e^{x/2}}{2^{n/2}\Gamma(n/2)} & \text{if }x>0
\end{array}
\right.
 n","['probability', 'statistics', 'convergence-divergence', 'normal-distribution', 'chi-squared']"
24,Max. likelihood and sufficient statistic of exponential distribution.,Max. likelihood and sufficient statistic of exponential distribution.,,"Consider the following probability function of a random variable $Y$ : $$ f(y \mid \theta)=e^{-(y-\theta)},\quad y\ge\theta $$ and $0$ otherwise. We take a random sample $(Y_1,Y_2,...,Y_k)$ and want to find a sufficient statistic and a maximum likelihood estimator for $\theta$ . Now, the likelihood is given by $$ L\left(y_1, y_2, \ldots, y_k \mid \theta\right)=\prod_{i=1}^k e^{-\left(y_i-\theta\right)}=\exp \left(-\sum_{i=1}^k y_i+k \theta\right) $$ Obviously, this is maximized when $\theta$ is maximized. Since the density function is nonzero only when $y\ge\theta$ , my first intuition is that the MLE for $\theta$ is $\min(y_1,y_2,...,y_k)$ , although I am not sure that it is correct. For the sufficient statistic, I believe we can choose $S=-\sum_{i=1}^k Y_i$ , in which case the likelihood function can be written as the product of $g(s, \theta)=e^{s+k \theta}$ and $h(y_1,y_2,...,y_k)=1$ , and a theorem then tells us that $S$ is a sufficient statistic. Can someone tell me if I have made a mistake or misunderstood something?","Consider the following probability function of a random variable : and otherwise. We take a random sample and want to find a sufficient statistic and a maximum likelihood estimator for . Now, the likelihood is given by Obviously, this is maximized when is maximized. Since the density function is nonzero only when , my first intuition is that the MLE for is , although I am not sure that it is correct. For the sufficient statistic, I believe we can choose , in which case the likelihood function can be written as the product of and , and a theorem then tells us that is a sufficient statistic. Can someone tell me if I have made a mistake or misunderstood something?","Y 
f(y \mid \theta)=e^{-(y-\theta)},\quad y\ge\theta
 0 (Y_1,Y_2,...,Y_k) \theta 
L\left(y_1, y_2, \ldots, y_k \mid \theta\right)=\prod_{i=1}^k e^{-\left(y_i-\theta\right)}=\exp \left(-\sum_{i=1}^k y_i+k \theta\right)
 \theta y\ge\theta \theta \min(y_1,y_2,...,y_k) S=-\sum_{i=1}^k Y_i g(s, \theta)=e^{s+k \theta} h(y_1,y_2,...,y_k)=1 S","['probability', 'statistics', 'solution-verification', 'maximum-likelihood', 'sufficient-statistics']"
25,Example of Bayes Theorem...,Example of Bayes Theorem...,,"In the paternity suit, the mother's blood type is A, the man's blood type is B, and the child's blood type is AB. According to various circumstances, the possibility that the man identified as a real father is 50:50. Based on the given blood type data, find the probability that he is a real father, if the father's blood type is A or O (86% of the total population), the child cannot be AB, and if the father's blood type is B or AB (14% of the total population), the probability that the child is AB is 1/4. If the man is not the father, the father is considered the representative of the general population. I'm trying to solve it with Bayes Theorem. Below are the events I defined. P(F): Event that he is a real father. We know that the prior is 1/2 by the second paragraph. P(F $^c$ ) : Complement of P(F) which is 1/2 as well P(AB|F) : Given that he is a real father, probability of the child's blood type is AB P(AB|F $^c$ ) : Given that he is not a real father, probability of the child's blood type is AB P(F|AB) : Posterior that I would like to know. P(F|AB) = $\frac{P(AB|F)P(F)}{P(AB|F)P(F) + P(AB|F^c)P(F^c)}$ Here's the thing, I'm not sure about P(AB|F $^c$ ). Did I define the events wrong or Did I miss something...(I don't think I understand the meaning of the last paragraph => ""If the man is not the father, the father is considered the representative of the general population"") Can anyone help me with this? Thank you.","In the paternity suit, the mother's blood type is A, the man's blood type is B, and the child's blood type is AB. According to various circumstances, the possibility that the man identified as a real father is 50:50. Based on the given blood type data, find the probability that he is a real father, if the father's blood type is A or O (86% of the total population), the child cannot be AB, and if the father's blood type is B or AB (14% of the total population), the probability that the child is AB is 1/4. If the man is not the father, the father is considered the representative of the general population. I'm trying to solve it with Bayes Theorem. Below are the events I defined. P(F): Event that he is a real father. We know that the prior is 1/2 by the second paragraph. P(F ) : Complement of P(F) which is 1/2 as well P(AB|F) : Given that he is a real father, probability of the child's blood type is AB P(AB|F ) : Given that he is not a real father, probability of the child's blood type is AB P(F|AB) : Posterior that I would like to know. P(F|AB) = Here's the thing, I'm not sure about P(AB|F ). Did I define the events wrong or Did I miss something...(I don't think I understand the meaning of the last paragraph => ""If the man is not the father, the father is considered the representative of the general population"") Can anyone help me with this? Thank you.",^c ^c \frac{P(AB|F)P(F)}{P(AB|F)P(F) + P(AB|F^c)P(F^c)} ^c,"['probability', 'statistics', 'bayes-theorem']"
26,"Given a random vector has univariate normal marginals, and a positive definite Covariance. Does this mean the vector is multivariate normal?","Given a random vector has univariate normal marginals, and a positive definite Covariance. Does this mean the vector is multivariate normal?",,"So the question is basically in the title. We know that if $X \sim N(\mu, \sigma)$ is multivariate normal for $\sigma$ positive definite, then we have that $X_i$ is normal. But is the converse statement true? Say $X = (X_1, ..., X_n)$ with $X_i \sim N(\mu_i, \sigma_{ii})$ , $\sigma_{ij} = Cov(X_i, X_j)$ such that $\sigma$ is positive definite. Does that mean that $X$ is multivariate normal? If we leave out the positive definite - condition, we can easily construct a counterexample, e.g. $X = -Y \sim N(\mu, \sigma)$ but $X+Y \equiv 0$ , so we have found a non trivial linear combination of $(X, Y)$ which is not normal. I have looked quite a bit in the literature and couln't find a proof or counterexample. Thanks","So the question is basically in the title. We know that if is multivariate normal for positive definite, then we have that is normal. But is the converse statement true? Say with , such that is positive definite. Does that mean that is multivariate normal? If we leave out the positive definite - condition, we can easily construct a counterexample, e.g. but , so we have found a non trivial linear combination of which is not normal. I have looked quite a bit in the literature and couln't find a proof or counterexample. Thanks","X \sim N(\mu, \sigma) \sigma X_i X = (X_1, ..., X_n) X_i \sim N(\mu_i, \sigma_{ii}) \sigma_{ij} = Cov(X_i, X_j) \sigma X X = -Y \sim N(\mu, \sigma) X+Y \equiv 0 (X, Y)","['probability', 'statistics', 'normal-distribution']"
27,Finding the MSE of some Estimator $\hat{\theta}$ the best way possible.,Finding the MSE of some Estimator  the best way possible.,\hat{\theta},"I'd glad if you could help me. I was given the following question in my exam, but i just couldn't finish that on time. I wonder if there's some easier way to solve this. Given the following random samples $(X_1, X_2,...,X_n)$ of independent random variables with the same probability density function: $$f_X(x)= \begin{cases} e^{\lambda - x},  & \text{$x\ge \lambda$ } \\ 0, & \text{$x < \lambda$} \end{cases}$$ where $\lambda >0$ . We want to estimate the unknown parameter $\theta=\lambda$ . We are given with the following Estimator: $\hat{\theta}=X_{(1)}-\frac{1}{n}$ where $X_{(1)}=min\{X_1,X_2,...,X_n\}$ and we need to find it's MSE (Mean Square Error: $E\big((\hat{\theta}-\lambda)^2\big)$ . I already solve this problem, but that was too complicated. I wonder if there's a ""catch"". I don't know, maybe we can identify some familiar distributaion along the way, something that can help us find the Expected Value much quicker. That's usually the case. My calculation was: Fiding CDF of $X_{(1)}: \quad  F_{X_{(1)}}(t)=1-e^{n(\lambda -x)}$ Fiding PDF of $X_{(1)}: \quad  f_{X_{(1)}}(t)=ne^{n(\lambda -x)}$ Fiding Expected Value of $X_{(1)}:$ $$ E(X_{(1)})= \int_{\lambda}^{\infty}xne^{n(\lambda -x)}dx= \text{...long calculation...} =\lambda + \frac{1}{n}$$ here we can see that $\hat{\theta}=X_{(1)}-\frac{1}{n}$ is unbiased: $E\big(\hat{\theta} \big) = E \big( X_{(1)}-\frac{1}{n} \big) =  E\big( X_{(1)}\big) - E\big( \frac{1}{n} \big) = \lambda + \frac{1}{n} - \frac{1}{n} = \lambda = \theta$ , so one last thing to do is to find the Variance of $\hat{\theta}$ : Find $$ V(\hat{\theta}) = V( X_{(1)}-\frac{1}{n} ) = V( X_{(1)} )  =  E \big( (X_{(1)} - \lambda)^2 \big) = \int_{\lambda}^{\infty} {(x-\lambda)^2ne^{n(\lambda -x)}}dx= \text{...too long calculation. I calculated using WolframAlpha} = \frac{2}{n^2} = MSE(\hat{\theta})$$","I'd glad if you could help me. I was given the following question in my exam, but i just couldn't finish that on time. I wonder if there's some easier way to solve this. Given the following random samples of independent random variables with the same probability density function: where . We want to estimate the unknown parameter . We are given with the following Estimator: where and we need to find it's MSE (Mean Square Error: . I already solve this problem, but that was too complicated. I wonder if there's a ""catch"". I don't know, maybe we can identify some familiar distributaion along the way, something that can help us find the Expected Value much quicker. That's usually the case. My calculation was: Fiding CDF of Fiding PDF of Fiding Expected Value of here we can see that is unbiased: , so one last thing to do is to find the Variance of : Find","(X_1, X_2,...,X_n) f_X(x)=
\begin{cases}
e^{\lambda - x},  & \text{x\ge \lambda } \\
0, & \text{x < \lambda}
\end{cases} \lambda >0 \theta=\lambda \hat{\theta}=X_{(1)}-\frac{1}{n} X_{(1)}=min\{X_1,X_2,...,X_n\} E\big((\hat{\theta}-\lambda)^2\big) X_{(1)}: \quad  F_{X_{(1)}}(t)=1-e^{n(\lambda -x)} X_{(1)}: \quad  f_{X_{(1)}}(t)=ne^{n(\lambda -x)} X_{(1)}:  E(X_{(1)})= \int_{\lambda}^{\infty}xne^{n(\lambda -x)}dx= \text{...long calculation...} =\lambda + \frac{1}{n} \hat{\theta}=X_{(1)}-\frac{1}{n} E\big(\hat{\theta} \big) = E \big( X_{(1)}-\frac{1}{n} \big) = 
E\big( X_{(1)}\big) - E\big( \frac{1}{n} \big) = \lambda + \frac{1}{n} - \frac{1}{n} = \lambda = \theta \hat{\theta}  V(\hat{\theta}) = V( X_{(1)}-\frac{1}{n} ) = V( X_{(1)} )  =  E \big( (X_{(1)} - \lambda)^2 \big) = \int_{\lambda}^{\infty} {(x-\lambda)^2ne^{n(\lambda -x)}}dx= \text{...too long calculation. I calculated using WolframAlpha} = \frac{2}{n^2} = MSE(\hat{\theta})","['probability', 'statistics', 'probability-distributions', 'parameter-estimation', 'mean-square-error']"
28,Statistical method of giving an upper estimate for $\|f\|_2^2$ from a data,Statistical method of giving an upper estimate for  from a data,\|f\|_2^2,"Suppose, that we are given an i.i.d. sample of $(X_i,Y_i), i=1,...,n$ input-output pairs, where $Y_i=f(X_i)+\varepsilon_i$ , where $f: [0,1] \to [0,1]$ is the data-generating function, and $\varepsilon_i$ are the independent noise terms. The task would be to give an upper approximation for the $L_2$ -norm of the data generating function, namely: $$\|f\|_2^2 = \int |f(x)|^2 \,dx$$ I have done some research, but I couldn't find any results which provide a suitable (let's denote it with $\kappa$ ) upper bound for this norm, when one is given a noisy input-output data pair. For the noise-free case (namely, when $\varepsilon_k = 0$ for every $k = 1,...,n$ ), a suitable approximation is the following term: $$\kappa := \frac{1}{n} \sum_{i=1}^n Y_i^2 \Rightarrow \mathbb{E}(\kappa) = \mathbb{E}\Big(\frac{1}{n}\sum_{i=1}^n Y_i^2\Big) = \mathbb{E} \Big(\frac{1}{n}\sum_{i=1}^n (f(X_i) \Big)^2 = \|f\|_2^2.$$ However, once the noise terms are not all $0$ , this term looks like this: $$\frac{1}{n} \sum_{i=1}^n Y_i^2 = \frac{1}{n} \sum_{i=1}^n (f(X_i)+\varepsilon_i)^2 = \frac{1}{n} \sum_{i=1}^n f(X_i)^2 + \varepsilon_i^2 + 2 f(X_i) \varepsilon_i$$ If we use the following notion (the difference between the noisy and the noise-free case) $$D := \frac{1}{n} \sum_{i=1}^n \varepsilon_i^2 + 2 f(X_i) \varepsilon_i,$$ we can easily obtain that $\mathbb{E}(D) > 0$ , because $\mathbb{E}(\varepsilon_i^2) > 0$ , therefore this approximation doesn't hold on the noisy case. I am gladly looking for any statistical methods or ideas, which provide me an upper estimate of this function norm on the noisy case. Any help is greatly appreciated!","Suppose, that we are given an i.i.d. sample of input-output pairs, where , where is the data-generating function, and are the independent noise terms. The task would be to give an upper approximation for the -norm of the data generating function, namely: I have done some research, but I couldn't find any results which provide a suitable (let's denote it with ) upper bound for this norm, when one is given a noisy input-output data pair. For the noise-free case (namely, when for every ), a suitable approximation is the following term: However, once the noise terms are not all , this term looks like this: If we use the following notion (the difference between the noisy and the noise-free case) we can easily obtain that , because , therefore this approximation doesn't hold on the noisy case. I am gladly looking for any statistical methods or ideas, which provide me an upper estimate of this function norm on the noisy case. Any help is greatly appreciated!","(X_i,Y_i), i=1,...,n Y_i=f(X_i)+\varepsilon_i f: [0,1] \to [0,1] \varepsilon_i L_2 \|f\|_2^2 = \int |f(x)|^2 \,dx \kappa \varepsilon_k = 0 k = 1,...,n \kappa := \frac{1}{n} \sum_{i=1}^n Y_i^2 \Rightarrow \mathbb{E}(\kappa) = \mathbb{E}\Big(\frac{1}{n}\sum_{i=1}^n Y_i^2\Big) = \mathbb{E} \Big(\frac{1}{n}\sum_{i=1}^n (f(X_i) \Big)^2 = \|f\|_2^2. 0 \frac{1}{n} \sum_{i=1}^n Y_i^2 = \frac{1}{n} \sum_{i=1}^n (f(X_i)+\varepsilon_i)^2 = \frac{1}{n} \sum_{i=1}^n f(X_i)^2 + \varepsilon_i^2 + 2 f(X_i) \varepsilon_i D := \frac{1}{n} \sum_{i=1}^n \varepsilon_i^2 + 2 f(X_i) \varepsilon_i, \mathbb{E}(D) > 0 \mathbb{E}(\varepsilon_i^2) > 0","['statistics', 'data-analysis']"
29,"Is there a more general version of ""handshakes"" formula n*(n-1)/2? [closed]","Is there a more general version of ""handshakes"" formula n*(n-1)/2? [closed]",,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I tried to solve ""birthdays paradox"" using the ""direct way"" but not the one mentioned here in one of the topics - tried my own, and as one of the solutions I figured out that there was a need to consider cases where not only couples share same birthday but maybe groups of three four five etc. Well, there is a well known formula to count unique handshakes (unique couples) amount when we have as given n (people amount): n*(n-1)/2 My question: Is there more general formula that I can use if I need to know how many unique groups of three, or unique groups of four, or five etc...are there for a given n Thank you","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 2 years ago . Improve this question I tried to solve ""birthdays paradox"" using the ""direct way"" but not the one mentioned here in one of the topics - tried my own, and as one of the solutions I figured out that there was a need to consider cases where not only couples share same birthday but maybe groups of three four five etc. Well, there is a well known formula to count unique handshakes (unique couples) amount when we have as given n (people amount): n*(n-1)/2 My question: Is there more general formula that I can use if I need to know how many unique groups of three, or unique groups of four, or five etc...are there for a given n Thank you",,"['probability', 'combinatorics', 'statistics']"
30,Prove that $P(A \cap B^*) = P(A) - P(A \cap B )$,Prove that,P(A \cap B^*) = P(A) - P(A \cap B ),Just started studying elementary statistics and I am trying to figure out why $P(A \cap B^*) = P(A) - P(A \cap B )$ (not a problem from a book) but I get stuck: I use the following two 2 equations: $$ \begin{align*} P(A^*) &= 1- P(A) & (1)\\ P(A \cup B ) &= P(A) + P(B) - P(A \cap B) & (2)\end{align*}$$ First I write LHS of the problem using the RHS of the second equation $$ \begin{align*}  P(A \cap B^*) &= P(A) + P(B^*) - P(A \cup B^* ) \\ &= P(A) + 1 - P(B) - P(A \cup B^* )    \end{align*}$$ This is where I get stuck. Can you help me?,Just started studying elementary statistics and I am trying to figure out why (not a problem from a book) but I get stuck: I use the following two 2 equations: First I write LHS of the problem using the RHS of the second equation This is where I get stuck. Can you help me?,"P(A \cap B^*) = P(A) - P(A \cap B )  \begin{align*} P(A^*) &= 1- P(A) & (1)\\ P(A \cup B ) &= P(A) + P(B) - P(A \cap B) & (2)\end{align*}  \begin{align*}  P(A \cap B^*) &= P(A) + P(B^*) - P(A \cup B^* ) \\ &= P(A) + 1 - P(B) - P(A \cup B^* )   
\end{align*}","['probability', 'statistics', 'elementary-set-theory']"
31,Why does the bounds of this integral not consider both equalities?,Why does the bounds of this integral not consider both equalities?,,"I'm trying to show that this function is a joint probability density function. $$f(x,y)=\begin{cases}1/x&:& 0<y<x<1\\0&:&\text{otherwise}\end{cases}$$ To do this, I need to integrate the function over the bounds of x and the bounds of y and check that the area equals one. According to the problem, 0 < y < x, and y < x < 1. However, in the solution , only the inequality for y is used when integrating over the bounds for y (from 0 to x). However, the bounds for the integral with respect to x is from 0 to 1. According to the problem specifications though,y < x < 1 and thus x > y, so I thought that the bounds of the outside integral with respect to x would be from y to 1. Why is this not the case?","I'm trying to show that this function is a joint probability density function. To do this, I need to integrate the function over the bounds of x and the bounds of y and check that the area equals one. According to the problem, 0 < y < x, and y < x < 1. However, in the solution , only the inequality for y is used when integrating over the bounds for y (from 0 to x). However, the bounds for the integral with respect to x is from 0 to 1. According to the problem specifications though,y < x < 1 and thus x > y, so I thought that the bounds of the outside integral with respect to x would be from y to 1. Why is this not the case?","f(x,y)=\begin{cases}1/x&:& 0<y<x<1\\0&:&\text{otherwise}\end{cases}","['calculus', 'probability', 'statistics']"
32,"Why is there no UMVUE for $\mu$ with two samples from $N(\mu, \sigma^2)$, $N(\mu, \tau^2)$?","Why is there no UMVUE for  with two samples from , ?","\mu N(\mu, \sigma^2) N(\mu, \tau^2)","Question: I have an attempted answer below; I don't think it's quite correct. I also have another sketch of a proof at the bottom. My attempt: (d) The family of independent samples $X_1, \dots, X_m$ from $N(\mu, \sigma^2)$ and $Y_1, \dots, Y_n$ from $N(\mu, \tau^2)$ have distributions having densities of the form \begin{align*} f_{X_1, \dots, X_m, Y_1, \dots, Y_n}(x_1, \dots, x_m, y_1, \dots, y_n; \mu, \sigma^2, \tau^2) =\\ \frac{1}{(\sqrt{2\pi})^m (\sqrt{2\pi})^n}\exp\Bigg[\frac{\mu}{\sigma^2}\sum_{i = 1}^m x_i - \frac{1}{2\sigma^2}\sum_{i = 1}^m x_i^2 - m\frac{\mu^2}{2\sigma^2} - m\log \sigma\\ + \frac{\mu}{\tau^2}\sum_{i = 1}^n y_i - \frac{1}{2\tau^2}\sum_{i = 1}^n y_i^2 - n\frac{\mu^2}{2\tau^2} - n\log \tau\Bigg]. \end{align*} According to the theory of exponential families, this is a four-dimensional exponential family. We have parameter space $\Theta = \mathbb R \times (0, \infty) \times (0, \infty)$ . Let $\theta = (\mu, \sigma^2, \tau^2) \in \Theta$ . Define the function \begin{align*} \eta'' \colon \Theta &\to \mathbb R^4 \text{ by}\\ \theta &\mapsto \Big(\frac{\mu}{\sigma^2}, -\frac{1}{2\sigma^2}, \frac{\mu}{\tau^2}, -\frac{1}{2\tau^2}\Big). \end{align*} We can write \begin{align*} \eta''(\theta) &= \begin{pmatrix} \frac{1}{\sigma^2} & 0 & 0\\ \\ 0 & -\frac{1}{2\sigma^4} & 0\\ \\ 0 & 0 &\frac{\mu}{\tau^4} \\ \\ 0 & 0 & -\frac{1}{2\tau^4} \end{pmatrix} \begin{pmatrix} \mu\\ \\ \sigma^2\\ \\ \tau^2 \end{pmatrix}\\ \\ &= \begin{pmatrix} \frac{\mu}{\sigma^2}\\ \\ -\frac{1}{2\sigma^2}\\ \\ \frac{\mu}{\tau^2}\\ \\ -\frac{1}{2\tau^2} \end{pmatrix}. \end{align*} If I can argue that three vectors (the column vectors in the matrix) can't have an image in $\mathbb R^4$ containing an open ball, then I am done, right? This would prove that the conditions for Lehmann-Scheffé can't be satisified. (e) The exponential family isn't full rank, so Lehmann-Scheffé doesn't apply. Another outline of a proof: Can anybody develop the argument below into a full proof? I don't get it. Why $\bar X - \bar Y$ ?","Question: I have an attempted answer below; I don't think it's quite correct. I also have another sketch of a proof at the bottom. My attempt: (d) The family of independent samples from and from have distributions having densities of the form According to the theory of exponential families, this is a four-dimensional exponential family. We have parameter space . Let . Define the function We can write If I can argue that three vectors (the column vectors in the matrix) can't have an image in containing an open ball, then I am done, right? This would prove that the conditions for Lehmann-Scheffé can't be satisified. (e) The exponential family isn't full rank, so Lehmann-Scheffé doesn't apply. Another outline of a proof: Can anybody develop the argument below into a full proof? I don't get it. Why ?","X_1, \dots, X_m N(\mu, \sigma^2) Y_1, \dots, Y_n N(\mu, \tau^2) \begin{align*}
f_{X_1, \dots, X_m, Y_1, \dots, Y_n}(x_1, \dots, x_m, y_1, \dots, y_n; \mu, \sigma^2, \tau^2) =\\
\frac{1}{(\sqrt{2\pi})^m (\sqrt{2\pi})^n}\exp\Bigg[\frac{\mu}{\sigma^2}\sum_{i = 1}^m x_i - \frac{1}{2\sigma^2}\sum_{i = 1}^m x_i^2 - m\frac{\mu^2}{2\sigma^2} - m\log \sigma\\
+ \frac{\mu}{\tau^2}\sum_{i = 1}^n y_i - \frac{1}{2\tau^2}\sum_{i = 1}^n y_i^2 - n\frac{\mu^2}{2\tau^2} - n\log \tau\Bigg].
\end{align*} \Theta = \mathbb R \times (0, \infty) \times (0, \infty) \theta = (\mu, \sigma^2, \tau^2) \in \Theta \begin{align*}
\eta'' \colon \Theta &\to \mathbb R^4 \text{ by}\\
\theta &\mapsto \Big(\frac{\mu}{\sigma^2}, -\frac{1}{2\sigma^2}, \frac{\mu}{\tau^2}, -\frac{1}{2\tau^2}\Big).
\end{align*} \begin{align*}
\eta''(\theta) &=
\begin{pmatrix}
\frac{1}{\sigma^2} & 0 & 0\\ \\
0 & -\frac{1}{2\sigma^4} & 0\\ \\
0 & 0 &\frac{\mu}{\tau^4} \\ \\
0 & 0 & -\frac{1}{2\tau^4}
\end{pmatrix}
\begin{pmatrix}
\mu\\ \\
\sigma^2\\ \\
\tau^2
\end{pmatrix}\\ \\
&=
\begin{pmatrix}
\frac{\mu}{\sigma^2}\\ \\
-\frac{1}{2\sigma^2}\\ \\
\frac{\mu}{\tau^2}\\ \\
-\frac{1}{2\tau^2}
\end{pmatrix}.
\end{align*} \mathbb R^4 \bar X - \bar Y","['statistics', 'normal-distribution']"
33,Solution verification of picking balls from a bag,Solution verification of picking balls from a bag,,"The question is like this, ""A bag contains 7 green balls, 4 red balls, and 5 blue balls."" 5 balls are drawn without being placed back. What is the probability that 2 or more blue balls are drawn? Balls are drawn from the bag until a blue ball is found. What is the probability that this will take 3 or more draws? 5 balls are drawn and placed back each time. What is the probability function for the number of green balls drawn? Same question as 3. but the balls not placed back. My answers: This one I used hyper geometric distribution. So, $F(x \geq 2)=1- (F(x = 0) + F(x = 1))=1 - (\frac{\binom{5}{1} \binom{11}{4}}{\binom{16}{5}}+ \frac{\binom{5}{2} \binom{11}{3}}{\binom{16}{5}})$ This is finding the first time of choosing a blue ball. So geometric distribution is used here. $F(x \geq 3)=1-(F(x = 0)+F(x = 1)+F(x = 2))$ . The equation is too long so I'm not write it. But it's simple, so $F(x = 1)=(0.3125)(0.6875)$ because probability is $\frac{5}{16}=0.3125$ . 5 blue balls This is using a binomial distribution. So $F(x)=\binom{5}{x}(0.4375)^x(0.5625)^{5-x}$ . The probability is $\frac{7}{16}=0.4375$ This is similar like 3. But I used hyper geometric distribution. $F(x)=\frac{\binom{7}{x}\binom{9}{5-x}}{\binom{16}{5}}$ , because there's 16 balls total, and 7 green balls. Anyone can check my answer is helpful, thank you.","The question is like this, ""A bag contains 7 green balls, 4 red balls, and 5 blue balls."" 5 balls are drawn without being placed back. What is the probability that 2 or more blue balls are drawn? Balls are drawn from the bag until a blue ball is found. What is the probability that this will take 3 or more draws? 5 balls are drawn and placed back each time. What is the probability function for the number of green balls drawn? Same question as 3. but the balls not placed back. My answers: This one I used hyper geometric distribution. So, This is finding the first time of choosing a blue ball. So geometric distribution is used here. . The equation is too long so I'm not write it. But it's simple, so because probability is . 5 blue balls This is using a binomial distribution. So . The probability is This is similar like 3. But I used hyper geometric distribution. , because there's 16 balls total, and 7 green balls. Anyone can check my answer is helpful, thank you.",F(x \geq 2)=1- (F(x = 0) + F(x = 1))=1 - (\frac{\binom{5}{1} \binom{11}{4}}{\binom{16}{5}}+ \frac{\binom{5}{2} \binom{11}{3}}{\binom{16}{5}}) F(x \geq 3)=1-(F(x = 0)+F(x = 1)+F(x = 2)) F(x = 1)=(0.3125)(0.6875) \frac{5}{16}=0.3125 F(x)=\binom{5}{x}(0.4375)^x(0.5625)^{5-x} \frac{7}{16}=0.4375 F(x)=\frac{\binom{7}{x}\binom{9}{5-x}}{\binom{16}{5}},"['probability', 'statistics', 'probability-distributions', 'solution-verification']"
34,Why does this assumption give an under approximation for both the expected maximum and minimum,Why does this assumption give an under approximation for both the expected maximum and minimum,,"The well known result, $\mathbb{E}[\text{min} \{X_i \}_{i=1}^n ] = \frac{1}{n+1}$ and $\mathbb{E}[\text{max} \{X_i \}_{i=1}^n ] = \frac{n}{n+1}$ where $X_i$ are I.I.D Uniform $(0,1)$ random variables is a lifesaver. It can be extrapolated to find the expected minimum and maximum of $n$ Uniform $(a,b)$ variables. I tried to use it in the discrete case. For example, consider the maximum of $10$ rolls of a $100$ sided die, the quick formula gives: $ \frac{10}{11}\cdot 100 = 90\frac{1}{11} \approx 90.91$ . The true answer however is $91.4007585757 $ (using tail sum formula : $100 - \sum\limits_{i=1}^{99}(\frac{i}{100})^{10}$ ) Notice the approximation gives an underestimate. Now consider using it to approximate the expected minimum. $\frac{1}{11}\cdot 100 = 9\frac{1}{11} \approx 9.09$ . The true answer however is $9.59924142434$ and again this formula under-approximates? Why does this happen in both cases? Is there a cheeky way to tweek it for the discrete case to get a bit more accurate? Thanks! A little thing I have noticed that might help is the following: The approximate min + approximate max is always $n$ . However, by symmetry the true min + true max is always $n+1$ . (because they are centred around the mean of $\frac{n+1}{2}$","The well known result, and where are I.I.D Uniform random variables is a lifesaver. It can be extrapolated to find the expected minimum and maximum of Uniform variables. I tried to use it in the discrete case. For example, consider the maximum of rolls of a sided die, the quick formula gives: . The true answer however is (using tail sum formula : ) Notice the approximation gives an underestimate. Now consider using it to approximate the expected minimum. . The true answer however is and again this formula under-approximates? Why does this happen in both cases? Is there a cheeky way to tweek it for the discrete case to get a bit more accurate? Thanks! A little thing I have noticed that might help is the following: The approximate min + approximate max is always . However, by symmetry the true min + true max is always . (because they are centred around the mean of","\mathbb{E}[\text{min} \{X_i \}_{i=1}^n ] = \frac{1}{n+1} \mathbb{E}[\text{max} \{X_i \}_{i=1}^n ] = \frac{n}{n+1} X_i (0,1) n (a,b) 10 100  \frac{10}{11}\cdot 100 = 90\frac{1}{11} \approx 90.91 91.4007585757
 100 - \sum\limits_{i=1}^{99}(\frac{i}{100})^{10} \frac{1}{11}\cdot 100 = 9\frac{1}{11} \approx 9.09 9.59924142434 n n+1 \frac{n+1}{2}","['probability', 'statistics', 'approximation']"
35,Variance of the Square,Variance of the Square,,"Suppose $X_1, \cdots, X_n$ are a sample of independent variables taken from a normally distributed population with mean $\mu$ and variance $\sigma^2$ . I would like to determine the variance of the squares $X_1^2, \cdots, X_n^2$ . From a Monte Carlo simulation it seems that when $\mu$ is large enough, it is close to $\operatorname{Var}(X^2)= (2\mu\sigma)^2$ , but I have no proof, and I'm struggling to come up with one. I understand it has to do with the Chi-Square distribution, but I have not connected the dots.","Suppose are a sample of independent variables taken from a normally distributed population with mean and variance . I would like to determine the variance of the squares . From a Monte Carlo simulation it seems that when is large enough, it is close to , but I have no proof, and I'm struggling to come up with one. I understand it has to do with the Chi-Square distribution, but I have not connected the dots.","X_1, \cdots, X_n \mu \sigma^2 X_1^2, \cdots, X_n^2 \mu \operatorname{Var}(X^2)= (2\mu\sigma)^2","['statistics', 'normal-distribution', 'variance', 'sums-of-squares']"
36,Sample size from proportions,Sample size from proportions,,"Let $X$ be a random variable that follows a Bernoulli distribution with parameter $p$ . If the maximum error of the $90$ % confidence interval is $0.2$ , what sample size is required under the following scenarios (i) $p$ is unknown. (ii) $p \geq 0.8$ My attempt: (i) As $p$ is unknown the sample size needed is: $$n = \frac{z_{\alpha/2}^2 \cdot 0.25}{E^2} = \frac{1.6448536^2 \cdot 0.25}{0.2^2} \approx 16.9096$$ We take the upper integer $17$ . (ii) $p\geq 0.8 \implies 1-p \leq 0.2 \implies p(1-p) \leq 0.16$ The sample size needed here is: $$n = \frac{z_{\alpha/2}^2 \cdot 0.16}{E^2} = \frac{1.6448536^2 \cdot 0.16}{0.2^2} \approx 10.8222$$ We take the upper integer $11$ . Are these correct? Any assistance is appreciated.","Let be a random variable that follows a Bernoulli distribution with parameter . If the maximum error of the % confidence interval is , what sample size is required under the following scenarios (i) is unknown. (ii) My attempt: (i) As is unknown the sample size needed is: We take the upper integer . (ii) The sample size needed here is: We take the upper integer . Are these correct? Any assistance is appreciated.",X p 90 0.2 p p \geq 0.8 p n = \frac{z_{\alpha/2}^2 \cdot 0.25}{E^2} = \frac{1.6448536^2 \cdot 0.25}{0.2^2} \approx 16.9096 17 p\geq 0.8 \implies 1-p \leq 0.2 \implies p(1-p) \leq 0.16 n = \frac{z_{\alpha/2}^2 \cdot 0.16}{E^2} = \frac{1.6448536^2 \cdot 0.16}{0.2^2} \approx 10.8222 11,"['statistics', 'solution-verification', 'random-variables']"
37,Probability of Type 1 Error when using $X_{min}$ as a test static,Probability of Type 1 Error when using  as a test static,X_{min},"Let $X_1,X_2, ..., X_{15}$ be a random sample from the exponential distribution with $\lambda > 0 $ . To test $H_0 : \lambda = 1/5$ versus $H_A : \lambda < 1/5$ use $X_{min}$ as a test statistic. If $X_{min} \geq 1$ reject the null hypothesis. My problem is then to compute the probability of a type 1 error. I know that I have to calculate $$\begin{align*}   P(\text{Type 1 Error}) & = P(\text{Reject} \ H_0 \ | \ H_0 \ \text{True}) \\   & = P(X_{min} \geq 1 \ | \ \lambda = 1/5) \\   & =  \end{align*} $$ However, I am not sure how to proceed now. As a hint in my book, I have to look an exercise where the PDF for $x_{min}$ is found. Do I have to find the pdf for $X_{min}$ now? I know that the PDF for $x_{min}$ is $$ f_{min}(x) = n(1 - F(x))^{n-1}f(x) $$ Do I have to use this? Furthermore, is there any way to calculate this probability with in r studio? All help is appreciated. TIA.","Let be a random sample from the exponential distribution with . To test versus use as a test statistic. If reject the null hypothesis. My problem is then to compute the probability of a type 1 error. I know that I have to calculate However, I am not sure how to proceed now. As a hint in my book, I have to look an exercise where the PDF for is found. Do I have to find the pdf for now? I know that the PDF for is Do I have to use this? Furthermore, is there any way to calculate this probability with in r studio? All help is appreciated. TIA.","X_1,X_2, ..., X_{15} \lambda > 0  H_0 : \lambda = 1/5 H_A : \lambda < 1/5 X_{min} X_{min} \geq 1 \begin{align*}
  P(\text{Type 1 Error}) & = P(\text{Reject} \ H_0 \ | \ H_0 \ \text{True}) \\
  & = P(X_{min} \geq 1 \ | \ \lambda = 1/5) \\
  & = 
\end{align*}
 x_{min} X_{min} x_{min} 
f_{min}(x) = n(1 - F(x))^{n-1}f(x)
","['probability', 'statistics']"
38,How to Find $E(X^2+Y^2)$,How to Find,E(X^2+Y^2),"I have a question consisting of 5 parts. It is an old practice midterm question I wanted to explain it to my friend. But I seem to have forgotten how to do it.  I could do the easy parts A and B not the rest. I think D is $0$ since they are independent variables but I want to double check with you guys. BUT I need help with the rest. QUESTION: Given: $X$ and $Y$ are independent random variables. $X$ has mean $4$ and variance $14$ . $X+Y$ has mean $6$ and variance $20$ . Solve: A-)mean $Y \Rightarrow E(X+Y)=E(X)+E(Y)=6 \Rightarrow 4+E(Y)=6 \Rightarrow$ ANSWER: $E(Y)=2$ B-)variance $y \Rightarrow Var(X+Y)=Var(X)+Var(Y)=20 \Rightarrow 14+Var(Y)=20 \Rightarrow$ ANSWER: $Var(Y)=6$ C-) $E(X^2+Y^2)$ : I can't figure this out. D-)Correlation $(X,Y)$ : Should be $0$ since they are independent right? E-) $COV(XY,X+Y)$ : $\Rightarrow COV(XY,X)+COV(XY,Y)$ : Can't remember what is next. Can anyone help me?",I have a question consisting of 5 parts. It is an old practice midterm question I wanted to explain it to my friend. But I seem to have forgotten how to do it.  I could do the easy parts A and B not the rest. I think D is since they are independent variables but I want to double check with you guys. BUT I need help with the rest. QUESTION: Given: and are independent random variables. has mean and variance . has mean and variance . Solve: A-)mean ANSWER: B-)variance ANSWER: C-) : I can't figure this out. D-)Correlation : Should be since they are independent right? E-) : : Can't remember what is next. Can anyone help me?,"0 X Y X 4 14 X+Y 6 20 Y \Rightarrow E(X+Y)=E(X)+E(Y)=6 \Rightarrow 4+E(Y)=6 \Rightarrow E(Y)=2 y \Rightarrow Var(X+Y)=Var(X)+Var(Y)=20 \Rightarrow 14+Var(Y)=20 \Rightarrow Var(Y)=6 E(X^2+Y^2) (X,Y) 0 COV(XY,X+Y) \Rightarrow COV(XY,X)+COV(XY,Y)","['probability', 'statistics']"
39,An intuitive explanation for the ecological fallacy,An intuitive explanation for the ecological fallacy,,"I believe that it is called the ecological fallacy. People say that one cannot apply population-wide statistics to individuals of that population. So, just because some trait exists in a higher proportion in population A than it does in B, that doesn't mean that an individual from pop. A is more likely to have that trait than an individual from pop. B. Now, this doesn't make sense to me. An individual coming from a population where a certain trait is more common, is more likely to have that trait than an individual coming from a population where said trait is less common, right? I guess this depends on how one mathematically defines ""common"". The mean and the average are a bit scary statistical quantifications. I see how ""the average"" is problematic, but a weighted average is surely quite illuminatory of the real likelihoods?","I believe that it is called the ecological fallacy. People say that one cannot apply population-wide statistics to individuals of that population. So, just because some trait exists in a higher proportion in population A than it does in B, that doesn't mean that an individual from pop. A is more likely to have that trait than an individual from pop. B. Now, this doesn't make sense to me. An individual coming from a population where a certain trait is more common, is more likely to have that trait than an individual coming from a population where said trait is less common, right? I guess this depends on how one mathematically defines ""common"". The mean and the average are a bit scary statistical quantifications. I see how ""the average"" is problematic, but a weighted average is surely quite illuminatory of the real likelihoods?",,"['probability', 'statistics', 'intuition']"
40,How to calculate 1 in _______ chance from a percentage?,How to calculate 1 in _______ chance from a percentage?,,"I am wondering, how do I ago about calculating 1 in chances from a percentage? Example: A 1 in 2 chance is 50% and 0.5 as a decimal. What I want to do: I have the value 0.1431 (14.3%) and want to convert that into a 1 in chance - any help is much appreciated, thanks.","I am wondering, how do I ago about calculating 1 in chances from a percentage? Example: A 1 in 2 chance is 50% and 0.5 as a decimal. What I want to do: I have the value 0.1431 (14.3%) and want to convert that into a 1 in chance - any help is much appreciated, thanks.",,['probability']
41,Testing goodness of fit using Kolmogorov-Smirnov test,Testing goodness of fit using Kolmogorov-Smirnov test,,"I want to check if two probability distributions (experimental and theoretical) are same. The distributions are not normal distributions so I decided to use KS test. I used the MATLAB function KStest2 and got p-value = 1! Now, it means that I can't reject the null hypothesis that the two distributions are same. I have two main concerns: Does it mean I can accept the null hypothesis? I'm confused about the statement 'fail to reject the null hypothesis' What is the p-value for the hypothesis that distributions are same. Can I calculate it as 1-p? As I'm interested in testing whether my theory is correct and want to give a p-value for that. https://se.mathworks.com/help/stats/kstest2.html","I want to check if two probability distributions (experimental and theoretical) are same. The distributions are not normal distributions so I decided to use KS test. I used the MATLAB function KStest2 and got p-value = 1! Now, it means that I can't reject the null hypothesis that the two distributions are same. I have two main concerns: Does it mean I can accept the null hypothesis? I'm confused about the statement 'fail to reject the null hypothesis' What is the p-value for the hypothesis that distributions are same. Can I calculate it as 1-p? As I'm interested in testing whether my theory is correct and want to give a p-value for that. https://se.mathworks.com/help/stats/kstest2.html",,"['statistics', 'mathematical-physics', 'statistical-inference', 'hypothesis-testing', 'p-value']"
42,Motivation For Weight Choice In Pooled Variance,Motivation For Weight Choice In Pooled Variance,,"In the formula for pooled variance , the estimated variance of each population of size $n_i$ is weighted by $n_i-1$ .  Is there a good motivation for this?  I would assume the formula is always unbiased, even when different weights are chosen.  But my guess is that the variance of the variance estimation is minimized by this choice, assuming a nice distribution of the 'real' error.  If that's true, where can I read a proof of it?  If not, what other motivation is there for this choice?","In the formula for pooled variance , the estimated variance of each population of size is weighted by .  Is there a good motivation for this?  I would assume the formula is always unbiased, even when different weights are chosen.  But my guess is that the variance of the variance estimation is minimized by this choice, assuming a nice distribution of the 'real' error.  If that's true, where can I read a proof of it?  If not, what other motivation is there for this choice?",n_i n_i-1,"['statistics', 'reference-request', 'variance']"
43,Expected value of sin of brownian motion,Expected value of sin of brownian motion,,"I am having trouble finding $E[X_t]$ , where $X_t = \sin(B_t)$ and $B_t$ is a Brownian motion. I have learned a little about Ito integrals but I don't think I really understand how to use them. Here is my approach at the moment: $$E[X_t] =E[\sin(B_t)] =\left(\frac{1}{\sqrt {2\pi t} } \int_{-\infty}^\infty e^\frac{-(x)^2}{2t} \sin(x) dx\right)\bigg\rvert_{x=B_t}$$ Is this the right approach? Any help would be appreciated, thank you!","I am having trouble finding , where and is a Brownian motion. I have learned a little about Ito integrals but I don't think I really understand how to use them. Here is my approach at the moment: Is this the right approach? Any help would be appreciated, thank you!",E[X_t] X_t = \sin(B_t) B_t E[X_t] =E[\sin(B_t)] =\left(\frac{1}{\sqrt {2\pi t} } \int_{-\infty}^\infty e^\frac{-(x)^2}{2t} \sin(x) dx\right)\bigg\rvert_{x=B_t},"['probability', 'integration']"
44,Why in Statistics do we use R-squared when Comparing Linear Models instead of Least Squares?,Why in Statistics do we use R-squared when Comparing Linear Models instead of Least Squares?,,"In Machine Learning we use a cost function such as least squared errors to evaluate how good the model is and if one model has a better score than the other, assuming that it does not overfit we choose said model. But in statistics, R-squared seems to be favored in model selection and not Least Squares. What's the point of R-squared/Adjusted R-squared when we have Least squared to measure performance in general? What am I missing? or am I just confused?","In Machine Learning we use a cost function such as least squared errors to evaluate how good the model is and if one model has a better score than the other, assuming that it does not overfit we choose said model. But in statistics, R-squared seems to be favored in model selection and not Least Squares. What's the point of R-squared/Adjusted R-squared when we have Least squared to measure performance in general? What am I missing? or am I just confused?",,"['statistics', 'machine-learning', 'mathematical-modeling', 'least-squares', 'linear-regression']"
45,Using Normal and Binomial approximations for airline tickets,Using Normal and Binomial approximations for airline tickets,,"Question: An airline finds that 7% of the people who make reservations on a certain flight do not show up for the flight. If the airline sells 185 tickets for a flight with only 180 seats, use the normal approximation to the binomial distribution to find the probability that a seat will be available for every person holding a reservation and planning to fly. (Round your answer to four decimal places.) I am frustrated at this problem. I need to use a normal approximation to a binomial distribution. My attempt starts by letting $n=185$ for the total number of tickets sold. Then, I let $p=0.93$ which is the probability of people showing up which leaves $q=0.07$ being no shows. So, this is what I got... Since $np = 185 \cdot 0.93$ and $nq = 185 \cdot 0.07$ $P(Y \leq 185) \approx P(W \leq 185.5) = P(Z \leq \frac{185.5-172.05}{\sqrt{185 \cdot 0.07 \cdot 0.93}})$ $P(Z \leq \frac{13.45}{\sqrt{12.0435}})$ $P(Z \leq \frac{13.45}{3.470374})$ $P(Z \leq 3.875)$ This is $0.9999$ but this is wrong which I don't understand because I even watched a tutorial video and followed each step. I even use R on this as pbinom(180,185,0.93) which is $0.9969$ and that is still wrong. What am I missing?","Question: An airline finds that 7% of the people who make reservations on a certain flight do not show up for the flight. If the airline sells 185 tickets for a flight with only 180 seats, use the normal approximation to the binomial distribution to find the probability that a seat will be available for every person holding a reservation and planning to fly. (Round your answer to four decimal places.) I am frustrated at this problem. I need to use a normal approximation to a binomial distribution. My attempt starts by letting for the total number of tickets sold. Then, I let which is the probability of people showing up which leaves being no shows. So, this is what I got... Since and This is but this is wrong which I don't understand because I even watched a tutorial video and followed each step. I even use R on this as pbinom(180,185,0.93) which is and that is still wrong. What am I missing?",n=185 p=0.93 q=0.07 np = 185 \cdot 0.93 nq = 185 \cdot 0.07 P(Y \leq 185) \approx P(W \leq 185.5) = P(Z \leq \frac{185.5-172.05}{\sqrt{185 \cdot 0.07 \cdot 0.93}}) P(Z \leq \frac{13.45}{\sqrt{12.0435}}) P(Z \leq \frac{13.45}{3.470374}) P(Z \leq 3.875) 0.9999 0.9969,"['statistics', 'statistical-inference', 'binomial-distribution']"
46,Showing the probability of guessing correctly goes down as more and more questions are answered correctly.,Showing the probability of guessing correctly goes down as more and more questions are answered correctly.,,"A student answers a multiple choice examination with questions that have four possible answers each. Suppose that the probability that the student knows the answer to a question is 0.80 and the probability that the student guesses is 0.20. If the student guesses, the probability of guessing the correct answer is 0.25. The questions are independent, that is, knowing the answer on one question is not influenced by the other question. (a) If there is one question on the exam and he answered the question correctly, what is the probability he knew the answer? (b) If there are two questions on the exam and he answered both questions correctly, what is the probability he knew both answers? (c) How would you generalize the above to n questions, that is, if the student answered an infinite number of questions correctly, what is the probability he knew the answers? I know the answer to A using Bayes Theorem is $\ P(A∣C)=\frac{P(C∣A)P(A)}{P(C∣A)P(A)+P(C∣Ac)P(Ac)}$ $\ \frac{(.8)(1)}{(.8)(1)+(.25)(.20)}$ But I'm completely stuck on B and C.","A student answers a multiple choice examination with questions that have four possible answers each. Suppose that the probability that the student knows the answer to a question is 0.80 and the probability that the student guesses is 0.20. If the student guesses, the probability of guessing the correct answer is 0.25. The questions are independent, that is, knowing the answer on one question is not influenced by the other question. (a) If there is one question on the exam and he answered the question correctly, what is the probability he knew the answer? (b) If there are two questions on the exam and he answered both questions correctly, what is the probability he knew both answers? (c) How would you generalize the above to n questions, that is, if the student answered an infinite number of questions correctly, what is the probability he knew the answers? I know the answer to A using Bayes Theorem is But I'm completely stuck on B and C.",\ P(A∣C)=\frac{P(C∣A)P(A)}{P(C∣A)P(A)+P(C∣Ac)P(Ac)} \ \frac{(.8)(1)}{(.8)(1)+(.25)(.20)},"['statistics', 'bayes-theorem']"
47,Does an UMVUE always exist?,Does an UMVUE always exist?,,"Let $\Psi= \{f_\theta: \theta \in \Theta\}$ be a statistical model. Define $\Upsilon= \{T: E[T]= g(\theta)\}$ - i.e., the class of unbiased estimator of $g(\theta)$ . Basically, I have two doubts: Does an UMVUE always exist? Thanks to Rao-Blackwell theorem, we can improve the ""goodness"" of an unbiased estimator using a sufficient statistic, i.e. $T\mid U$ where $T$ is our unbiased estimator and $U$ our sufficient statistic. Moreover, thanks to Lehmann–Scheffé theorem, I have that if $U$ is also complete, then $T^*= E[T\mid U]$ is UMVUE. My dilemma here is that I wrote on my notes that it is not true that an UMVUE for $g(\theta)$ always exist, but I cannot understand how it is possible. If UMVUE does not always exist, it implies that a complete statistic does not always exist or an unbiased estimator of $g(\theta)$ that is function of the complete statistic does not always exist. If this is true, could you provide me a counterexample- i.e. an example where an UMVUE does not exist? Suppose that $T$ is an efficient estimator for $g(\theta)$ - i.e. $V(T)$ = Cramér-Rao lower bound. I already know that if $T$ is efficient for $g(\theta)$ , then $a+bT$ is efficient for $a+bg(\theta)$ but for no other transformation. But is $g(T)$ always UMVUE for a $g(g(\theta)) \,\forall g$ - i.e. if $T$ is an efficient estimator of $g(\theta)$ , a transformation of $T$ is always UMVUE for a transformation of $g(\theta)$ ?","Let be a statistical model. Define - i.e., the class of unbiased estimator of . Basically, I have two doubts: Does an UMVUE always exist? Thanks to Rao-Blackwell theorem, we can improve the ""goodness"" of an unbiased estimator using a sufficient statistic, i.e. where is our unbiased estimator and our sufficient statistic. Moreover, thanks to Lehmann–Scheffé theorem, I have that if is also complete, then is UMVUE. My dilemma here is that I wrote on my notes that it is not true that an UMVUE for always exist, but I cannot understand how it is possible. If UMVUE does not always exist, it implies that a complete statistic does not always exist or an unbiased estimator of that is function of the complete statistic does not always exist. If this is true, could you provide me a counterexample- i.e. an example where an UMVUE does not exist? Suppose that is an efficient estimator for - i.e. = Cramér-Rao lower bound. I already know that if is efficient for , then is efficient for but for no other transformation. But is always UMVUE for a - i.e. if is an efficient estimator of , a transformation of is always UMVUE for a transformation of ?","\Psi= \{f_\theta: \theta \in \Theta\} \Upsilon= \{T: E[T]= g(\theta)\} g(\theta) T\mid U T U U T^*= E[T\mid U] g(\theta) g(\theta) T g(\theta) V(T) T g(\theta) a+bT a+bg(\theta) g(T) g(g(\theta)) \,\forall g T g(\theta) T g(\theta)","['statistics', 'statistical-inference', 'parameter-estimation']"
48,"Distribution of number of heads, when we keep tossing a coin until we have 4 tails","Distribution of number of heads, when we keep tossing a coin until we have 4 tails",,"We toss a fair coin until we've tossed tails exactly 4 times. Let $X$ be the number of tossed heads. What is the distribution of $X$ ? My attempt: We keep tossing the coin until we have registered 4 tails. Suppose that we needed $n$ tosses. The last toss has to be tails, and exactly three of the preceding tosses had to be tails as well: $$ P(\text{4 tails}|n \text{ tosses})=\frac12\cdot \binom{n-1}{3}\left(\frac 12\right)^3\left(\frac 12\right)^{n-4}=\frac{(n-1)(n-2)(n-3)}{6\cdot 2^n}.$$ This is also the probability of tossing $n-4$ heads, knowing that we needed $n$ tosses to stop the game. Is this the answer to the question? How do I find 'the distribution' of $X$ ? Thanks.","We toss a fair coin until we've tossed tails exactly 4 times. Let be the number of tossed heads. What is the distribution of ? My attempt: We keep tossing the coin until we have registered 4 tails. Suppose that we needed tosses. The last toss has to be tails, and exactly three of the preceding tosses had to be tails as well: This is also the probability of tossing heads, knowing that we needed tosses to stop the game. Is this the answer to the question? How do I find 'the distribution' of ? Thanks.",X X n  P(\text{4 tails}|n \text{ tosses})=\frac12\cdot \binom{n-1}{3}\left(\frac 12\right)^3\left(\frac 12\right)^{n-4}=\frac{(n-1)(n-2)(n-3)}{6\cdot 2^n}. n-4 n X,"['probability', 'statistics', 'solution-verification']"
49,Understanding the least squares regression formula?,Understanding the least squares regression formula?,,"I've seen the following tutorial on it, but the formula itself had not been explained ( https://www.youtube.com/watch?v=Qa2APhWjQPc ). I understanding the intuition behind finding a line that ""best fits"" the data set where the error is minimised (image below). However, I don't see how the formula relates to the intuition? If anyone could explain the formula, as I can't visualise what it's trying to achieve. A simple gradient is the dy/dx , would't we just do $\sum(Y - y) \ ÷ \sum (X - x)$ where Y and X are the centroid values (average values). By my logic, that would be how you calculate the average gradient? Could someone explain this to me?","I've seen the following tutorial on it, but the formula itself had not been explained ( https://www.youtube.com/watch?v=Qa2APhWjQPc ). I understanding the intuition behind finding a line that ""best fits"" the data set where the error is minimised (image below). However, I don't see how the formula relates to the intuition? If anyone could explain the formula, as I can't visualise what it's trying to achieve. A simple gradient is the dy/dx , would't we just do where Y and X are the centroid values (average values). By my logic, that would be how you calculate the average gradient? Could someone explain this to me?",\sum(Y - y) \ ÷ \sum (X - x),"['statistics', 'least-squares', 'linear-regression']"
50,How to derive the variance of this MLE estimator,How to derive the variance of this MLE estimator,,"Let $(x_i, Y_i)\in\mathbb{R}^2$ be independent observations on $n$ subjects, such that $$Y_i|x_i\sim N(x_i\beta, \sigma^2)$$ where $(\beta, \sigma^2)\in\mathbb{R}^2$ are unknown coefficients. I computed the maximum likelihood estimate $\hat\beta$ of $\beta$ , which is $\hat\beta = \frac{\sum_{i=1}^n y_{i}x_i}{\sum_{i=1}^n x_i^2}$ , and we want to compute the variance of this estimator $\hat\beta$ . Using that $Var(\hat\beta)= E[\hat\beta^2]-E[\hat\beta]^2$ , I would only need $E[\hat\beta^2]$ to get the variance, as I already showed $E[\hat\beta]=\beta$ , but I'm struggling with it. $$E[\hat\beta^2]=E[(\frac{\sum_{i=1}^n y_{i}x_i}{\sum_{i=1}^n x_i^2})^2]=\frac{1}{(\sum_{i=1}^n x_i^2)^2}E[(\sum_{i=1}^n y_{i}x_i)^2]$$ I do not really know how to compute this expectation. Any help would be appreaciated.","Let be independent observations on subjects, such that where are unknown coefficients. I computed the maximum likelihood estimate of , which is , and we want to compute the variance of this estimator . Using that , I would only need to get the variance, as I already showed , but I'm struggling with it. I do not really know how to compute this expectation. Any help would be appreaciated.","(x_i, Y_i)\in\mathbb{R}^2 n Y_i|x_i\sim N(x_i\beta, \sigma^2) (\beta, \sigma^2)\in\mathbb{R}^2 \hat\beta \beta \hat\beta = \frac{\sum_{i=1}^n y_{i}x_i}{\sum_{i=1}^n x_i^2} \hat\beta Var(\hat\beta)= E[\hat\beta^2]-E[\hat\beta]^2 E[\hat\beta^2] E[\hat\beta]=\beta E[\hat\beta^2]=E[(\frac{\sum_{i=1}^n y_{i}x_i}{\sum_{i=1}^n x_i^2})^2]=\frac{1}{(\sum_{i=1}^n x_i^2)^2}E[(\sum_{i=1}^n y_{i}x_i)^2]","['statistics', 'estimation', 'maximum-likelihood', 'parameter-estimation']"
51,p-value and t-distribution,p-value and t-distribution,,"Given a data set $(x_1,\ldots, x_n)$ , ( for $n$ - large ) which is realization of a random sample $(X_1, \ldots , X_n)$ . Assume the null hypothesis $H_0:\mu = \mu_0$ and alternative hypothesis $H_1 : \mu > \mu_1$ . Then which is an appropriate method of testing whether or not to reject $H_0$ ? One way would be to use $t$ -test method and find $\pm t_{n-1,\alpha/2}$ ( if $\alpha$ - the significance level is given ) and check where our current observation $T_0 = (X_{\text{average}} - \mu_0)/(S_n/\sqrt n)$ lies. But I also thought about computing the probability that $T$ is at least as extreme as our current our observation ( i.e just compute the $p$ -value $P(T > T_0)$ . My question is when to use p-value and when t-distribution as a motivation for a decision whether to reject $H_0$ .","Given a data set , ( for - large ) which is realization of a random sample . Assume the null hypothesis and alternative hypothesis . Then which is an appropriate method of testing whether or not to reject ? One way would be to use -test method and find ( if - the significance level is given ) and check where our current observation lies. But I also thought about computing the probability that is at least as extreme as our current our observation ( i.e just compute the -value . My question is when to use p-value and when t-distribution as a motivation for a decision whether to reject .","(x_1,\ldots, x_n) n (X_1, \ldots , X_n) H_0:\mu = \mu_0 H_1 : \mu > \mu_1 H_0 t \pm t_{n-1,\alpha/2} \alpha T_0 = (X_{\text{average}} - \mu_0)/(S_n/\sqrt n) T p P(T > T_0) H_0","['probability', 'statistics', 'hypothesis-testing']"
52,Maximum-likelihood estimator of set of data from Normal Distributions,Maximum-likelihood estimator of set of data from Normal Distributions,,"I have -before- found the MLE of the two parameters of a Normal Distribution but I don't have any idea about how to proceed in this case. Problem A sample of size $n$ is drawn from each of four normal populations, all of which have the same variance $\sigma^2$ . The means of the four populations are $a + b + c$ , $a + b - c$ , $a - b + c$ , and $a - b - c$ . What are the maximum-likelihood estimators   of $a, b, c$ , and $\sigma^2$ ? (The sample observations may be denoted by $X_{ij}$ , $i = 1, 2, 3,4$ and $j = 1,2, ... , n$ .)","I have -before- found the MLE of the two parameters of a Normal Distribution but I don't have any idea about how to proceed in this case. Problem A sample of size is drawn from each of four normal populations, all of which have the same variance . The means of the four populations are , , , and . What are the maximum-likelihood estimators   of , and ? (The sample observations may be denoted by , and .)","n \sigma^2 a + b + c a + b - c a - b + c a - b - c a, b, c \sigma^2 X_{ij} i = 1,
2, 3,4 j = 1,2, ... , n","['statistics', 'normal-distribution', 'statistical-inference', 'maximum-likelihood']"
53,Why is the probability that a continuous random variable takes any one specific value equal to 0? [duplicate],Why is the probability that a continuous random variable takes any one specific value equal to 0? [duplicate],,This question already has answers here : Why is the probability that a continuous random variable takes a specific value zero? (4 answers) Closed 5 years ago . What would the intuitive explanation be? Would it be because there are infinately many values and so the probability of any specific value is infinitely small hence we say 'close enough' to 0?,This question already has answers here : Why is the probability that a continuous random variable takes a specific value zero? (4 answers) Closed 5 years ago . What would the intuitive explanation be? Would it be because there are infinately many values and so the probability of any specific value is infinitely small hence we say 'close enough' to 0?,,"['probability', 'statistics']"
54,"Degree of the minimal sufficient statistic for $\theta$ in $U(\theta-1,\theta+1)$ distribution",Degree of the minimal sufficient statistic for  in  distribution,"\theta U(\theta-1,\theta+1)","Suppose $X_1,X_2,...,X_n$ is a random sample from the Uniform distribution over the interval $(\theta-1,\theta+1)$ . By the factorization theorem, it is clear that the order statistics $Y_1=X_\left(1\right)$ and $Y_n=X_\left(n\right)$ are joint sufficient statistics for $\theta$ . Now, because $$\theta-1 < Y_1 < Y_n < \theta+1 $$ implies that $Y_n -1 < \theta < Y_1 + 1$ , choosing $\hat\theta \in (Y_n-1,Y_1+1)$ will force the likelihood function to achieve its maximum; that is, $$L(\hat\theta)=\left(\frac{1}{2}\right)^n, \forall \hat\theta\in(Y_n-1,Y_1+1)$$ Typically, statisticians takes the value for $\hat\theta$ to be the midrange of $Y_1,Y_n$ : $\hat\theta=\frac{Y_1+Y_n}{2}$ . Now, because such a value for $\hat\theta$ maximizes the likelihood function, it follows that $\hat\theta$ is an mle for $\theta$ of in $Unif(\theta-1,\theta+1)$ . It is noted in the Hogg, McKean, Craig textbook ""Introduction to Mathematical Statistics"" ( $7^{th}$ edition), however, that even though $\hat\theta$ is an mle of $\theta$ and a function of the joint sufficient statistics $Y_1,Y_n$ for $\theta$ , it does not represent a minimal sufficient statistic; this is because $\hat\theta$ is itself not a sufficient statistic for theta. What I'm wondering here is $why$ $\hat\theta = \frac{Y_1+Y_n}{2}$ is not a sufficient statistic for $\theta$ . By the definition of a sufficient statistic and using the factorization theorem, $Y_1,Y_n$ being the joint sufficient statistics for $\theta$ imply that the likelihood function can be written as $$\prod_1^nf(x_i;\theta) = K_1(Y_1,Y_n;\theta)*K_2(x_1,x_2,...,x_n)$$ where $K_1(Y_1,Y_2;\theta)$ depends on $x_1,...x_n$ only through $Y_1,Y_n$ and $K_2(x_1,x_2,...,x_n)$ does not depend upon $\theta$ ; in our case, $$K_1(Y_1,Y_n;\theta)=\left(\frac1{2}\right)^n \cdot \mathbf 1_{(\theta-1,\theta+1)}(Y_1) \cdot \mathbf 1_{(\theta-1,\theta+1)}(Y_n) $$ Now, although it is clear that we cannot reduce the product of the two indicator functions down any further to any single order statistic $Y_i$ such that an equality remains between $K_1$ and our new function, why is it not the case that $$\mathbf 1_{(\theta-1,\theta+1)}(\frac{Y_1+Y_2}{2}) \neq \mathbf 1_{(\theta-1,\theta+1)}(Y_1) \cdot \mathbf 1_{(\theta-1,\theta+1)}(Y_n)$$ is a valid equality? In proceeding further in my reasoning, let's reference this question . For an overview, this question revolves around the sufficient statistics for the uniform distribution $Unif(-\theta,\theta)$ . In this problem, one can reduce their argument from the joint sufficient statistics $X_\left(1\right),X_\left(n\right)$ down to the single sufficient statistic $max\{X_\left(1\right),X_\left(n\right)\}=Y^*$ . Does it happen to be so that the only thing stopping us from reducing our two-dimensional joint sufficient statistic(s), $\mathbf Y=(Y_1,Y_n)$ , for $\theta$ down into the single-dimensional (""minimal"") sufficient statistic, $Y=Y^*$ , for $\theta$ the fact that our Uniform distribution is not distributed symmetrically about the Y-axis? I could see this argument being the case, but I'd like to be sufficiently (no pun intended) sure of that before proceeding on in my studies. It took me quite a bit of investigating to begin to understand how to work through various operations when working with the indicator function, so I still might a little lost when it comes to the finer intricacies of manipulating this function.","Suppose is a random sample from the Uniform distribution over the interval . By the factorization theorem, it is clear that the order statistics and are joint sufficient statistics for . Now, because implies that , choosing will force the likelihood function to achieve its maximum; that is, Typically, statisticians takes the value for to be the midrange of : . Now, because such a value for maximizes the likelihood function, it follows that is an mle for of in . It is noted in the Hogg, McKean, Craig textbook ""Introduction to Mathematical Statistics"" ( edition), however, that even though is an mle of and a function of the joint sufficient statistics for , it does not represent a minimal sufficient statistic; this is because is itself not a sufficient statistic for theta. What I'm wondering here is is not a sufficient statistic for . By the definition of a sufficient statistic and using the factorization theorem, being the joint sufficient statistics for imply that the likelihood function can be written as where depends on only through and does not depend upon ; in our case, Now, although it is clear that we cannot reduce the product of the two indicator functions down any further to any single order statistic such that an equality remains between and our new function, why is it not the case that is a valid equality? In proceeding further in my reasoning, let's reference this question . For an overview, this question revolves around the sufficient statistics for the uniform distribution . In this problem, one can reduce their argument from the joint sufficient statistics down to the single sufficient statistic . Does it happen to be so that the only thing stopping us from reducing our two-dimensional joint sufficient statistic(s), , for down into the single-dimensional (""minimal"") sufficient statistic, , for the fact that our Uniform distribution is not distributed symmetrically about the Y-axis? I could see this argument being the case, but I'd like to be sufficiently (no pun intended) sure of that before proceeding on in my studies. It took me quite a bit of investigating to begin to understand how to work through various operations when working with the indicator function, so I still might a little lost when it comes to the finer intricacies of manipulating this function.","X_1,X_2,...,X_n (\theta-1,\theta+1) Y_1=X_\left(1\right) Y_n=X_\left(n\right) \theta \theta-1 < Y_1 < Y_n < \theta+1  Y_n -1 < \theta < Y_1 + 1 \hat\theta \in (Y_n-1,Y_1+1) L(\hat\theta)=\left(\frac{1}{2}\right)^n, \forall \hat\theta\in(Y_n-1,Y_1+1) \hat\theta Y_1,Y_n \hat\theta=\frac{Y_1+Y_n}{2} \hat\theta \hat\theta \theta Unif(\theta-1,\theta+1) 7^{th} \hat\theta \theta Y_1,Y_n \theta \hat\theta why \hat\theta = \frac{Y_1+Y_n}{2} \theta Y_1,Y_n \theta \prod_1^nf(x_i;\theta) = K_1(Y_1,Y_n;\theta)*K_2(x_1,x_2,...,x_n) K_1(Y_1,Y_2;\theta) x_1,...x_n Y_1,Y_n K_2(x_1,x_2,...,x_n) \theta K_1(Y_1,Y_n;\theta)=\left(\frac1{2}\right)^n \cdot \mathbf 1_{(\theta-1,\theta+1)}(Y_1) \cdot \mathbf 1_{(\theta-1,\theta+1)}(Y_n)  Y_i K_1 \mathbf 1_{(\theta-1,\theta+1)}(\frac{Y_1+Y_2}{2}) \neq \mathbf 1_{(\theta-1,\theta+1)}(Y_1) \cdot \mathbf 1_{(\theta-1,\theta+1)}(Y_n) Unif(-\theta,\theta) X_\left(1\right),X_\left(n\right) max\{X_\left(1\right),X_\left(n\right)\}=Y^* \mathbf Y=(Y_1,Y_n) \theta Y=Y^* \theta","['statistics', 'uniform-distribution', 'order-statistics', 'sufficient-statistics']"
55,Monotone Likelihood ratio and Karlin-Rubin test,Monotone Likelihood ratio and Karlin-Rubin test,,"I'm studying the Karlin-Rubin test on the book Statistical Inference by Casella and Berger. There the MLR property for a family of pdf is defined as: $\forall \theta_2>\theta_1\:\: \frac{g(t,\theta_2)}{g(t,\theta_1)}$ is a monotone function of $t$ on the union of the supports. Then Karlin-Rubin test says that if $T$ is a sufficient statistic for $\theta$ and his family of densities has the MLR, then a UMP level $\alpha$ test for testing $H_0: \theta\leq\theta_0$ vs $H_0: \theta>\theta_0$ has a rejection region with shape $\{T>t_0\}$ (for an appropriate $t_0$ ). My question: If I choose $-T$ then I will still have a sufficient statistic for $\theta$ with the MLR. However, using the theorem I will get a region $\{-T>t_1\}$ which is equivalent to $\{T<-t_1\}$ that has got an opposite shape to the one above. Is this correct? I believe that the definition of MLR given there is wrong ... ... and that one should require that the ratio is increasing, but I'm not sure about that. Also I'm not sure about the contradiction in what I got.","I'm studying the Karlin-Rubin test on the book Statistical Inference by Casella and Berger. There the MLR property for a family of pdf is defined as: is a monotone function of on the union of the supports. Then Karlin-Rubin test says that if is a sufficient statistic for and his family of densities has the MLR, then a UMP level test for testing vs has a rejection region with shape (for an appropriate ). My question: If I choose then I will still have a sufficient statistic for with the MLR. However, using the theorem I will get a region which is equivalent to that has got an opposite shape to the one above. Is this correct? I believe that the definition of MLR given there is wrong ... ... and that one should require that the ratio is increasing, but I'm not sure about that. Also I'm not sure about the contradiction in what I got.","\forall \theta_2>\theta_1\:\: \frac{g(t,\theta_2)}{g(t,\theta_1)} t T \theta \alpha H_0: \theta\leq\theta_0 H_0: \theta>\theta_0 \{T>t_0\} t_0 -T \theta \{-T>t_1\} \{T<-t_1\}","['statistics', 'statistical-inference', 'hypothesis-testing']"
56,What is the probability that a deck of $52$ cards is more than $0.55$ inches in thickness?,What is the probability that a deck of  cards is more than  inches in thickness?,52 0.55,"The thickness of the individual cards produced by a certain playing card manufacturer is normally distributed with mean $0.01$ inches and variance $0.000052$ . What is the probability that a deck of $52$ cards is more than $0.55$ inches in thickness? (The thickness of each card is independent of the others). Solve: \begin{align}P(X>0.55)&=P\left(Z>\frac{\frac{0.55}{52}-0.01}{\frac{\sqrt{0.00052}}{\sqrt{52}}}\right)\\ &=P(Z>0.182)\\ &=0.427\end{align} (from the standard normal tables) From the book solution it should be $P(Z > 0.58) ≈ 0.28$ , but I can't see where I'm wrong, can someone help me?","The thickness of the individual cards produced by a certain playing card manufacturer is normally distributed with mean inches and variance . What is the probability that a deck of cards is more than inches in thickness? (The thickness of each card is independent of the others). Solve: (from the standard normal tables) From the book solution it should be , but I can't see where I'm wrong, can someone help me?","0.01 0.000052 52 0.55 \begin{align}P(X>0.55)&=P\left(Z>\frac{\frac{0.55}{52}-0.01}{\frac{\sqrt{0.00052}}{\sqrt{52}}}\right)\\
&=P(Z>0.182)\\
&=0.427\end{align} P(Z > 0.58) ≈ 0.28","['probability', 'statistics']"
57,Why the average of a set of value has the least square error?,Why the average of a set of value has the least square error?,,"Now we have the equation $$\sum_{i}(x_i-\hat x_i)^2,$$ where $x_i$ is the observed value of a data sample $S$ . Here is the question: Why does this expression get its minimum value when $\hat x_i$ is the average of the data sample $S$ ? I tried to take the derivatives of that equation and make it to zero, but it seems there's something wrong, because $\hat x_i$ is kind of multi-variable.  Can anyone help me out? Thanks a lot!","Now we have the equation where is the observed value of a data sample . Here is the question: Why does this expression get its minimum value when is the average of the data sample ? I tried to take the derivatives of that equation and make it to zero, but it seems there's something wrong, because is kind of multi-variable.  Can anyone help me out? Thanks a lot!","\sum_{i}(x_i-\hat x_i)^2, x_i S \hat x_i S \hat x_i","['statistics', 'least-squares']"
58,How is the auto-correlation of vectors defined?,How is the auto-correlation of vectors defined?,,"Suppose $v$ is an $n$ -ary vector with entries from the set $\{0,1\}$ (i.e. a vector of ones and zeros). A paper I am reading defines the ""auto-correlation sequences"" $$v*v$$ where $*$ denotes the correlation operator. 1) What is an auto-correlation sequence of a vector? 2) What is the correlation operator? (I'm assuming it can be applied to two distinct vectors too) My first guess was that to auto-correlate a vector you try all the possible rotational permutations of the vector and measure the cosine of the angle between each permuted vector with the original. However, Mathematica's CorrelationFunction on $\{1,0\}$ with $lag=0$ returns 1 and with $lag=1$ returns $-\frac{1}{2}$ , which shoots down my theory since I would expect orthogonal vectors to have $0$ correlation. So what is Mathematica doing here?","Suppose is an -ary vector with entries from the set (i.e. a vector of ones and zeros). A paper I am reading defines the ""auto-correlation sequences"" where denotes the correlation operator. 1) What is an auto-correlation sequence of a vector? 2) What is the correlation operator? (I'm assuming it can be applied to two distinct vectors too) My first guess was that to auto-correlate a vector you try all the possible rotational permutations of the vector and measure the cosine of the angle between each permuted vector with the original. However, Mathematica's CorrelationFunction on with returns 1 and with returns , which shoots down my theory since I would expect orthogonal vectors to have correlation. So what is Mathematica doing here?","v n \{0,1\} v*v * \{1,0\} lag=0 lag=1 -\frac{1}{2} 0","['linear-algebra', 'statistics', 'correlation']"
59,Cumulative Distribution Function of a Variable with Exponential Distribution,Cumulative Distribution Function of a Variable with Exponential Distribution,,"Suppose we have a variable $X$ that has an exponential distribution with a probability density function: $f(x) = 3e^{-3x}, x >0$ Then the cumulative distribution function is: $\int_{-\infty}^{x} f(x)dx = \int_{-\infty}^0 f(x)dx + \int_0^x f(x)dx$ $= \int_0^x f(x) dx \space\space\space$ Since x > 0 $= (-e^{-3x})|_0^x$ $= -e^{-3x} - (-e^0)$ $= 1 - e^{-3x}$ Is this correct, that part I'm not sure about is disregarding the $\int_{-\infty}^0 f(x)dx$ because $x > 0$ .","Suppose we have a variable that has an exponential distribution with a probability density function: Then the cumulative distribution function is: Since x > 0 Is this correct, that part I'm not sure about is disregarding the because .","X f(x) = 3e^{-3x}, x >0 \int_{-\infty}^{x} f(x)dx = \int_{-\infty}^0 f(x)dx + \int_0^x f(x)dx = \int_0^x f(x) dx \space\space\space = (-e^{-3x})|_0^x = -e^{-3x} - (-e^0) = 1 - e^{-3x} \int_{-\infty}^0 f(x)dx x > 0","['integration', 'statistics', 'probability-distributions', 'exponential-distribution']"
60,HyperGeometric distribution : Inutition for symmetry,HyperGeometric distribution : Inutition for symmetry,,"Wikipedia page on HyperGeometric distribution says Swapping the roles of green and drawn marbles: $$ f ( k ; N , K , n ) = f ( k ; N , n , K ) $$ where in LHS, N = Total number of marbles n = number of draws K = number of green marbles(others are red) k = number of green marbles in n draws I understand how the equality holds mathematically, but I can't understand why this equality holds intuitively.","Wikipedia page on HyperGeometric distribution says Swapping the roles of green and drawn marbles: where in LHS, N = Total number of marbles n = number of draws K = number of green marbles(others are red) k = number of green marbles in n draws I understand how the equality holds mathematically, but I can't understand why this equality holds intuitively."," f ( k ; N , K , n ) = f ( k ; N , n , K ) ","['statistics', 'statistical-inference', 'hypergeometric-function']"
61,MP test construction for shifted exponential distribution,MP test construction for shifted exponential distribution,,"For the pdf $f_{\theta}(x)=e^{-(x-\theta)} , x \ge \theta$, find a most powerful test of size $\alpha$, using Neyman Pearson Lemma to test $\theta=\theta_{0}$ against $\theta=\theta_1(> \theta_0)$, based on a sample of size $n$. I am facing difficulty as the parameter here is range dependent  However, if $X_{(1)}>\theta_1$, then $f_1(x)>\lambda f_0(x)$ if $e^{n(\theta_1- \theta_0)}> \lambda$ would mean rejection of null hypothesis. But how will I make this test a size $\alpha$ test? The ratio is coming to be constant. Please help!","For the pdf $f_{\theta}(x)=e^{-(x-\theta)} , x \ge \theta$, find a most powerful test of size $\alpha$, using Neyman Pearson Lemma to test $\theta=\theta_{0}$ against $\theta=\theta_1(> \theta_0)$, based on a sample of size $n$. I am facing difficulty as the parameter here is range dependent  However, if $X_{(1)}>\theta_1$, then $f_1(x)>\lambda f_0(x)$ if $e^{n(\theta_1- \theta_0)}> \lambda$ would mean rejection of null hypothesis. But how will I make this test a size $\alpha$ test? The ratio is coming to be constant. Please help!",,['statistics']
62,Explaining Why the Zero Conditional Mean Assumption is Important,Explaining Why the Zero Conditional Mean Assumption is Important,,"I am currently relearning econometrics in more depth than I had before. One thing I am trying to make sense of currently is why it is necessary for the assumption of:  $$E(u\mid x)=E(u) $$ to be true (where $u$ is the error term). Here is how I have tried to reason through it, although I am not sure if this is a good reasoning on why. Let's say $u$ is somehow correlated with some variable $y$, which $x$ is also correlated with. In this case,  $$E(u\mid x) \not= E(u) $$ since for greater $x$ values the expectation of the error would go up or down since it is correlated with $x$ through the $y$ variable. With this being the case, the line of best fit would end up with greater or lesser expected errors as $x$ increases and decreases. Is this what the zero conditional mean assumption is trying to say, or is there a better reasoning that I'm not hitting on? Thank you!","I am currently relearning econometrics in more depth than I had before. One thing I am trying to make sense of currently is why it is necessary for the assumption of:  $$E(u\mid x)=E(u) $$ to be true (where $u$ is the error term). Here is how I have tried to reason through it, although I am not sure if this is a good reasoning on why. Let's say $u$ is somehow correlated with some variable $y$, which $x$ is also correlated with. In this case,  $$E(u\mid x) \not= E(u) $$ since for greater $x$ values the expectation of the error would go up or down since it is correlated with $x$ through the $y$ variable. With this being the case, the line of best fit would end up with greater or lesser expected errors as $x$ increases and decreases. Is this what the zero conditional mean assumption is trying to say, or is there a better reasoning that I'm not hitting on? Thank you!",,"['statistics', 'conditional-expectation', 'regression', 'economics']"
63,Number of distinct scatterplots from $p$ variables in a data set,Number of distinct scatterplots from  variables in a data set,p,"Consider the following quote from the text An Introduction to Statistical Learning: In practice, we often encounter data   sets that contain many more than two variables. In this case, we cannot   easily plot the observations. For instance, if there are p variables in our   data set, then p(p − 1)/2 distinct scatterplots can be made, and visual   inspection is simply not a viable way to identify clusters. What exactly do the authors mean by the fact that $$\frac{p(p-1)}{2}$$ distinct scatterplots can be made?  The quote is not referring to any specific data or any specific example, so this is the only context. I understand that this question would be a better post for the Cross Validated Stack Exchange; however, this site is more popular and more active, so I thought I would post it here.  Nevertheless, it is still math. Thanks in advance!","Consider the following quote from the text An Introduction to Statistical Learning: In practice, we often encounter data   sets that contain many more than two variables. In this case, we cannot   easily plot the observations. For instance, if there are p variables in our   data set, then p(p − 1)/2 distinct scatterplots can be made, and visual   inspection is simply not a viable way to identify clusters. What exactly do the authors mean by the fact that $$\frac{p(p-1)}{2}$$ distinct scatterplots can be made?  The quote is not referring to any specific data or any specific example, so this is the only context. I understand that this question would be a better post for the Cross Validated Stack Exchange; however, this site is more popular and more active, so I thought I would post it here.  Nevertheless, it is still math. Thanks in advance!",,['statistics']
64,Conflicting Results from t-test and F-based stepwise regression in multiple regression.,Conflicting Results from t-test and F-based stepwise regression in multiple regression.,,"I currently am tasked with building a multiple regression model with two predictor variables to consider.  That means there are potentially three terms in the model, Predictor A (PA), Predictor B (PB) and PA*PB. In one instance, I made a LS model containing all three terms, and did simple t-tests.  I divided the parameter estimates by their standard errors to calculate t-statistics, and determined that only the intercept and PA*PB coefficients were significantly different from zero. In another instance, I did stepwise regression by first creating a model with only PA, and then fit a model to PA and PB, and did an F-test based on the Sum of Squares between the two models.  The F-test concluded that PB was a significant predictor to include in the model, and when I repeated the procedure, the PA*PB coefficient was found to reduce SSE significantly as well. So in summary, the t-test approach tells me that only the cross-product term PA*PB has a significant regression coefficient when all terms are included in the model, but the stepwise approach tells me to include all terms in the model. Based on these conflicting results, what course of action would you recommend?","I currently am tasked with building a multiple regression model with two predictor variables to consider.  That means there are potentially three terms in the model, Predictor A (PA), Predictor B (PB) and PA*PB. In one instance, I made a LS model containing all three terms, and did simple t-tests.  I divided the parameter estimates by their standard errors to calculate t-statistics, and determined that only the intercept and PA*PB coefficients were significantly different from zero. In another instance, I did stepwise regression by first creating a model with only PA, and then fit a model to PA and PB, and did an F-test based on the Sum of Squares between the two models.  The F-test concluded that PB was a significant predictor to include in the model, and when I repeated the procedure, the PA*PB coefficient was found to reduce SSE significantly as well. So in summary, the t-test approach tells me that only the cross-product term PA*PB has a significant regression coefficient when all terms are included in the model, but the stepwise approach tells me to include all terms in the model. Based on these conflicting results, what course of action would you recommend?",,"['statistics', 'regression']"
65,Boxplots and Quartiles,Boxplots and Quartiles,,"I'm studying Boxplots for statistics. What i've not understood is : since a boxplot represents 4 quartiles and each of them collects the 25% of the dataset, why is it possible to have data samples that are outside the boxplot ?","I'm studying Boxplots for statistics. What i've not understood is : since a boxplot represents 4 quartiles and each of them collects the 25% of the dataset, why is it possible to have data samples that are outside the boxplot ?",,"['probability', 'statistics']"
66,Trouble with proof of deviations square,Trouble with proof of deviations square,,"I apologize upfront for any spelling mistakes, I'm not used to writing math in english! I tried searching for this question in here already but was not sure I used the best tags while doing so. Anyway, to the question: It was taken from a brazilian textbook on Basic Statistics (Bussab & Morettin, 2013). It basically justs asks me to show that: $${\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = \sum\limits_{i = 1}^n {{x_i}^2 - n{{\overline x }^2} = \sum\limits_{i = 1}^n {{x_i}^2 - {{{{\left( {\Sigma {x_i}} \right)}^2}} \over n}} } $$ Now, I didn't really know where to start or if there's an official recommended approach to such proofs, but I just tried to start it by opening the first term: $$\eqalign{   & {\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = {\left( {{x_1} - \overline x } \right)^2} + {\left( {{x_2} - \overline x } \right)^2} + ... + {\left( {{x_n} - \overline x } \right)^2}  \cr    & {\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = \left( {{x_1}^2 - 2{x_1}\overline x  + {{\overline x }^2}} \right) + \left( {{x_2}^2 - 2{x_2}\overline x  + {{\overline x }^2}} \right) + ...\left( {{x_n}^2 - 2{x_n}\overline x  + {{\overline x }^2}} \right) \cr} $$ At which point I felt I was close enough to start regrouping the pieces: $$\eqalign{   & {\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = \left( {{x_1}^2 + {x_2}^2 + ...{x_n}^2} \right) + \left( {{{\overline x }^2} + {{\overline x }^2} + ... + {{\overline x }^2}} \right) - 2\overline x \left( {{x_1} + {x_2} + ... + {x_n}} \right)  \cr    & {\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = \sum\limits_{i = 1}^n {{x_i}^2}  + n{\overline x ^2} - 2\overline x \left( {{x_1} + {x_2} + ... + {x_n}} \right) \cr} $$ And that's where I stuck. I can get the $ + n{\overline x ^2}$ to be $ - n{\overline x ^2}$, and I don't know how to ""get rid"" of the third term.","I apologize upfront for any spelling mistakes, I'm not used to writing math in english! I tried searching for this question in here already but was not sure I used the best tags while doing so. Anyway, to the question: It was taken from a brazilian textbook on Basic Statistics (Bussab & Morettin, 2013). It basically justs asks me to show that: $${\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = \sum\limits_{i = 1}^n {{x_i}^2 - n{{\overline x }^2} = \sum\limits_{i = 1}^n {{x_i}^2 - {{{{\left( {\Sigma {x_i}} \right)}^2}} \over n}} } $$ Now, I didn't really know where to start or if there's an official recommended approach to such proofs, but I just tried to start it by opening the first term: $$\eqalign{   & {\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = {\left( {{x_1} - \overline x } \right)^2} + {\left( {{x_2} - \overline x } \right)^2} + ... + {\left( {{x_n} - \overline x } \right)^2}  \cr    & {\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = \left( {{x_1}^2 - 2{x_1}\overline x  + {{\overline x }^2}} \right) + \left( {{x_2}^2 - 2{x_2}\overline x  + {{\overline x }^2}} \right) + ...\left( {{x_n}^2 - 2{x_n}\overline x  + {{\overline x }^2}} \right) \cr} $$ At which point I felt I was close enough to start regrouping the pieces: $$\eqalign{   & {\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = \left( {{x_1}^2 + {x_2}^2 + ...{x_n}^2} \right) + \left( {{{\overline x }^2} + {{\overline x }^2} + ... + {{\overline x }^2}} \right) - 2\overline x \left( {{x_1} + {x_2} + ... + {x_n}} \right)  \cr    & {\sum\limits_{i = 1}^n {\left( {{x_i} - \overline x } \right)} ^2} = \sum\limits_{i = 1}^n {{x_i}^2}  + n{\overline x ^2} - 2\overline x \left( {{x_1} + {x_2} + ... + {x_n}} \right) \cr} $$ And that's where I stuck. I can get the $ + n{\overline x ^2}$ to be $ - n{\overline x ^2}$, and I don't know how to ""get rid"" of the third term.",,"['statistics', 'proof-explanation']"
67,"A box has an unknown number of tickets serially numbered 1,2,...,N. Two tickets are drawn using simple random sampling without replacement","A box has an unknown number of tickets serially numbered 1,2,...,N. Two tickets are drawn using simple random sampling without replacement",,"A box has an unknown number of tickets serially numbered 1,2,...,N. Two tickets are drawn using simple random sampling without replacement (SRSWOR) from the box. If X and Y are the numbers on these two tickets and $Z = max(X,Y )$, show that (a) Z is not unbiased for N (b) $aX+bY +c$ is unbiased for N if and only if $ a+b = 2 \text{ and}\ c = −1.$ What is the the pmf of Z,  Any tips on how to proceed?","A box has an unknown number of tickets serially numbered 1,2,...,N. Two tickets are drawn using simple random sampling without replacement (SRSWOR) from the box. If X and Y are the numbers on these two tickets and $Z = max(X,Y )$, show that (a) Z is not unbiased for N (b) $aX+bY +c$ is unbiased for N if and only if $ a+b = 2 \text{ and}\ c = −1.$ What is the the pmf of Z,  Any tips on how to proceed?",,"['statistics', 'self-learning', 'estimation', 'sampling']"
68,Trying to understand a simple function,Trying to understand a simple function,,"I'm trying to make sense of a simple equation from Bingzhe Wu, Haodong Duan, Zhichao Liu, Guangyu Sun's paper SRPGAN: Perceptual Generative Adversarial Network for Single Image Super Resolution What I don't understand is $\rho(x)=\sqrt{x^2 + \epsilon^2}$. How am I supposed to find $\epsilon$ (the error term I guess?) if $p$ only takes $x$ as input? Thanks","I'm trying to make sense of a simple equation from Bingzhe Wu, Haodong Duan, Zhichao Liu, Guangyu Sun's paper SRPGAN: Perceptual Generative Adversarial Network for Single Image Super Resolution What I don't understand is $\rho(x)=\sqrt{x^2 + \epsilon^2}$. How am I supposed to find $\epsilon$ (the error term I guess?) if $p$ only takes $x$ as input? Thanks",,"['statistics', 'machine-learning']"
69,Link between PCA and the Eckart-Young theorem,Link between PCA and the Eckart-Young theorem,,"We can find a really good explanation about the link between: finding the subspace upon which the projected data cloud has the  maximal variance (or ""inertie"") finding the subspace upon which the distance between the projected data cloud and the original data cloud is minimal (we use Pythagoras to show this equivalence and it results that the projection is orthogonal) However there is a result from 1936 by Eckart and Young that states the following $$\sum_1^r d_k u_k v_k^T = \arg \min_{\hat{X} \in M(r)} \| X - \hat{X} \|_F^2$$ where $M(r)$ is the set of rank-$r$ matrices, which basically means first $r$ components of the SVD of $X$ gives the best low-rank matrix approximation of $X$ and best is defined in terms of the squared Frobenius norm - the sum of squared elements of a matrix. This is a general result for matrices and at first sight has nothing to do with data sets or dimensionality reduction (but it is related , in fact). So, I would really appreciate if you could explain (and prove) the link with the above. Thanks.","We can find a really good explanation about the link between: finding the subspace upon which the projected data cloud has the  maximal variance (or ""inertie"") finding the subspace upon which the distance between the projected data cloud and the original data cloud is minimal (we use Pythagoras to show this equivalence and it results that the projection is orthogonal) However there is a result from 1936 by Eckart and Young that states the following $$\sum_1^r d_k u_k v_k^T = \arg \min_{\hat{X} \in M(r)} \| X - \hat{X} \|_F^2$$ where $M(r)$ is the set of rank-$r$ matrices, which basically means first $r$ components of the SVD of $X$ gives the best low-rank matrix approximation of $X$ and best is defined in terms of the squared Frobenius norm - the sum of squared elements of a matrix. This is a general result for matrices and at first sight has nothing to do with data sets or dimensionality reduction (but it is related , in fact). So, I would really appreciate if you could explain (and prove) the link with the above. Thanks.",,"['linear-algebra', 'statistics', 'least-squares', 'data-analysis', 'svd']"
70,Binomial distribution: gamification for online casino,Binomial distribution: gamification for online casino,,"This'll be my first post here and I haven't done any statistics in 10 years, so I need some help getting back into it. So I'm working on a gamification system for an online casino and I'm trying to figure out the likelyhood of certain events, and a fair prize for completing the event. Slot $X$ has a hit frequency of $44.9$%. The odds for winning $3$ times in a row (binomial distribution) is $9.05188$% How many times, on average, do I need to spin to win 3 times in a row? Any help would be greatly appreciated!","This'll be my first post here and I haven't done any statistics in 10 years, so I need some help getting back into it. So I'm working on a gamification system for an online casino and I'm trying to figure out the likelyhood of certain events, and a fair prize for completing the event. Slot $X$ has a hit frequency of $44.9$%. The odds for winning $3$ times in a row (binomial distribution) is $9.05188$% How many times, on average, do I need to spin to win 3 times in a row? Any help would be greatly appreciated!",,"['statistics', 'binomial-distribution']"
71,"Finding MLE for uniform distribution $U[\theta_1 - \theta_2, \theta_1 + \theta_2]$",Finding MLE for uniform distribution,"U[\theta_1 - \theta_2, \theta_1 + \theta_2]","Problem statement: Let $X_1, \ldots, X_n$ be a random sample from a uniform distribution $U[\theta_1 - \theta_2, \theta_1 + \theta_2]$, with $\theta_1 \in \mathbb{R}$ and $\theta_2 > 0$. Determine the MLE for $(\theta_1, \theta_2)$. My attempt: The density function for $X$ is $$f_X(x) = \frac{1}{2 \theta_2} 1_{[\theta_1 - \theta_2, \theta_1 + \theta_2]} (x). $$ Then the likelihood function is $$ L(\theta_1, \theta_2; \vec{x}) = \frac{1}{(2 \theta_2)^n} \prod_{i=1}^n 1_{[\theta_1 - \theta_2, \theta_1 + \theta_2]} (x_i). $$ So I need to minimize $$ (2 \theta_2)^n$$ subject to the contraint $$ \theta_1 - \theta_2 \leq x_{(1)} \leq x_{(n)} \leq \theta_1 + \theta_2.$$ From the left most inequality I have $\theta_1 - x_{(1)} \leq \theta_2$. From the right most inequality I have $x_{(n)} - \theta_1 \leq \theta_2$. Adding these I get $x_{(n)} - x_{(1)} \leq 2 \theta_2$. So I think an estimator for $\theta_2$ is $$ \hat{\theta}_2 = \frac{1}{2} ( x_{(n)} - x_{(1)}). $$ Is this reasoning correct? And also, how to find an estimator for $\theta_1$ from this? Thank you for any help!","Problem statement: Let $X_1, \ldots, X_n$ be a random sample from a uniform distribution $U[\theta_1 - \theta_2, \theta_1 + \theta_2]$, with $\theta_1 \in \mathbb{R}$ and $\theta_2 > 0$. Determine the MLE for $(\theta_1, \theta_2)$. My attempt: The density function for $X$ is $$f_X(x) = \frac{1}{2 \theta_2} 1_{[\theta_1 - \theta_2, \theta_1 + \theta_2]} (x). $$ Then the likelihood function is $$ L(\theta_1, \theta_2; \vec{x}) = \frac{1}{(2 \theta_2)^n} \prod_{i=1}^n 1_{[\theta_1 - \theta_2, \theta_1 + \theta_2]} (x_i). $$ So I need to minimize $$ (2 \theta_2)^n$$ subject to the contraint $$ \theta_1 - \theta_2 \leq x_{(1)} \leq x_{(n)} \leq \theta_1 + \theta_2.$$ From the left most inequality I have $\theta_1 - x_{(1)} \leq \theta_2$. From the right most inequality I have $x_{(n)} - \theta_1 \leq \theta_2$. Adding these I get $x_{(n)} - x_{(1)} \leq 2 \theta_2$. So I think an estimator for $\theta_2$ is $$ \hat{\theta}_2 = \frac{1}{2} ( x_{(n)} - x_{(1)}). $$ Is this reasoning correct? And also, how to find an estimator for $\theta_1$ from this? Thank you for any help!",,"['probability', 'statistics', 'statistical-inference']"
72,Why is the expected frequency during a chi square dependence test calculated the way that it is?,Why is the expected frequency during a chi square dependence test calculated the way that it is?,,"I understand the chi square test for testing whether or not a certain model is appropriate. I understand the process based upon which we pick the expected values. But, when it comes to the dependence test (the one where we use a contingency table), I don't understand why the expected frequency is  calculated from the observed frequencies in the contingency table using (row total x column total)/grand total. Someone please explain.","I understand the chi square test for testing whether or not a certain model is appropriate. I understand the process based upon which we pick the expected values. But, when it comes to the dependence test (the one where we use a contingency table), I don't understand why the expected frequency is  calculated from the observed frequencies in the contingency table using (row total x column total)/grand total. Someone please explain.",,"['statistics', 'probability-distributions']"
73,What qualifies as an infinite population?,What qualifies as an infinite population?,,"I've been looking for a clear guideline to distinguish between a finite population and an infinite one, for example, in some places an infinite population is described as something like the number of stars in the universe, and in other places it's described as something way smaller, like the number of products in the market. I'm studying highschool math so I'd like an answer for that level of knowledge. Thanks!","I've been looking for a clear guideline to distinguish between a finite population and an infinite one, for example, in some places an infinite population is described as something like the number of stars in the universe, and in other places it's described as something way smaller, like the number of products in the market. I'm studying highschool math so I'd like an answer for that level of knowledge. Thanks!",,"['statistics', 'descriptive-statistics']"
74,Death probability in time interval,Death probability in time interval,,"I have the following question Given the anual death rate $r$ for a group of persons (units of deaths per $1,000$ individuals per year), what is the probability that any given individual will die within the next $x$ months? This is assuming that death is an IID event, and of course, which can only happen once. My problem is that I haven't been able to identify which probability distribution to use, nor which are the parameters given for such distribution. I'd really appreciate your help :)","I have the following question Given the anual death rate $r$ for a group of persons (units of deaths per $1,000$ individuals per year), what is the probability that any given individual will die within the next $x$ months? This is assuming that death is an IID event, and of course, which can only happen once. My problem is that I haven't been able to identify which probability distribution to use, nor which are the parameters given for such distribution. I'd really appreciate your help :)",,"['probability', 'statistics', 'probability-distributions']"
75,Confidence Intervals: Sampling Distribution of the Sample Mean or the Distribution itself?,Confidence Intervals: Sampling Distribution of the Sample Mean or the Distribution itself?,,"When I see a confidence interval, such as the Z-Interval, is it approximating the sampling distribution of sample means or approximating a normal distribution from the sample or is it something else entirely? In particular, I'm wondering about Garwood’s CI for the Poisson Distribution.","When I see a confidence interval, such as the Z-Interval, is it approximating the sampling distribution of sample means or approximating a normal distribution from the sample or is it something else entirely? In particular, I'm wondering about Garwood’s CI for the Poisson Distribution.",,"['statistics', 'confidence-interval']"
76,Proving independence of 2 random variables from a 4-variable joint distribution,Proving independence of 2 random variables from a 4-variable joint distribution,,"A book I'm reading has the following problem. Even looking at the author's solution, I can't make heads or tails of it - it seems wrong to me, unless I'm missing something. Problem The joint probability $\Pr(w,x,y,z)$ over four variables factorizes as $$ \Pr(w,x,y,z)=\Pr(w)\Pr(z|y)\Pr(y|x,w)\Pr(x). $$ Demonstrate that $x$ is independent of $w$ by showing that $\Pr(x,w)=\Pr(x)\Pr(w)$. Author's Solution We compute the distribution $\Pr(x,w)$ by marginalizing the joint distribution $\Pr(w,x,y,z)$ with respect to the unwanted variables $y$ and $z$: $$ \begin{align} \Pr(x,w)&=\int\int\Pr(w,x,y,z)\,dy\,dz\\ &=\int\int\Pr(w)\Pr(z|y)\Pr(y|x,w)\Pr(x)\,dy\,dz\\ &=\Pr(x)\Pr(w) \end{align} $$ where in the third line we have simply integrated over the unwanted variables $y$ and $z$, removing them from the equations. My Objection I'm obviously okay until the second line. I understand that $\Pr(x)$ and $\Pr(w)$ can be moved outside the integrals because they are not functions of $y$ and/or $z$. We're left with: $$ \begin{align} \Pr(x,w)=\Pr(x)\Pr(w)\int\int\Pr(z|y)\Pr(y|x,w)\,dy\,dz\\ \end{align} $$ But in general, when we evaluate that integral we get a function of $x$ and $w$, because they're both present in the second factor. Why is this function necessarily equal to $1$?","A book I'm reading has the following problem. Even looking at the author's solution, I can't make heads or tails of it - it seems wrong to me, unless I'm missing something. Problem The joint probability $\Pr(w,x,y,z)$ over four variables factorizes as $$ \Pr(w,x,y,z)=\Pr(w)\Pr(z|y)\Pr(y|x,w)\Pr(x). $$ Demonstrate that $x$ is independent of $w$ by showing that $\Pr(x,w)=\Pr(x)\Pr(w)$. Author's Solution We compute the distribution $\Pr(x,w)$ by marginalizing the joint distribution $\Pr(w,x,y,z)$ with respect to the unwanted variables $y$ and $z$: $$ \begin{align} \Pr(x,w)&=\int\int\Pr(w,x,y,z)\,dy\,dz\\ &=\int\int\Pr(w)\Pr(z|y)\Pr(y|x,w)\Pr(x)\,dy\,dz\\ &=\Pr(x)\Pr(w) \end{align} $$ where in the third line we have simply integrated over the unwanted variables $y$ and $z$, removing them from the equations. My Objection I'm obviously okay until the second line. I understand that $\Pr(x)$ and $\Pr(w)$ can be moved outside the integrals because they are not functions of $y$ and/or $z$. We're left with: $$ \begin{align} \Pr(x,w)=\Pr(x)\Pr(w)\int\int\Pr(z|y)\Pr(y|x,w)\,dy\,dz\\ \end{align} $$ But in general, when we evaluate that integral we get a function of $x$ and $w$, because they're both present in the second factor. Why is this function necessarily equal to $1$?",,"['probability', 'statistics', 'probability-distributions']"
77,Conditional expectation of independent identically distributed random variables,Conditional expectation of independent identically distributed random variables,,"Let $X, Y, Z$ -- independent identically distributed random variables. I need to calculate the conditional expectation $\mathbb{E}(3X - 3Y + Z | X + Y + Z)$. I use linearity property: $3\mathbb{E}(X| X + Y + Z) - 3\mathbb{E}(Y | X + Y + Z) + \mathbb{E}( Z | X + Y + Z)$. But what about the right side conditional expectation?","Let $X, Y, Z$ -- independent identically distributed random variables. I need to calculate the conditional expectation $\mathbb{E}(3X - 3Y + Z | X + Y + Z)$. I use linearity property: $3\mathbb{E}(X| X + Y + Z) - 3\mathbb{E}(Y | X + Y + Z) + \mathbb{E}( Z | X + Y + Z)$. But what about the right side conditional expectation?",,"['probability', 'statistics', 'conditional-expectation']"
78,Partial sum of order statistics of exponential r.v.'s and $\chi^2$,Partial sum of order statistics of exponential r.v.'s and,\chi^2,"Suppose $X_i \sim Exp(\frac{1}{\lambda}), i = 1,\cdots,n$, where $f(x) = I_{(0,\infty)}\frac{1}{\lambda}e^{-\frac{x}{\lambda}}$ is the p.d.f. of $X_i$'s.  And we have a positive integer $r$, and the order statistics $$X_{(1)}\leq X_{(2)} \leq \cdots \leq X_{(r)}$$ where $1<r \leq n$. Then, denote $$T = \sum_{i=1}^{r} X_{(i)} + (n-r)X_{(r)}$$ The problem is to prove that $\frac{2T}{\lambda} \sim \chi^2_{2r}$. I'm quite at loss here. It seems to have a lot to do with Gamma distribution, but it doesn't seem the sum of first r- order statistics follows it. Even if the sum of the first r items does follow Gamma, I don't know how to handle the following $(n-r)X_{(r)}$. It doesn't seem right to directly compute the p.d.f. of $T$, which I've tried and failed. I'd appreciate it enormously if anyone can give me any hint or solution !","Suppose $X_i \sim Exp(\frac{1}{\lambda}), i = 1,\cdots,n$, where $f(x) = I_{(0,\infty)}\frac{1}{\lambda}e^{-\frac{x}{\lambda}}$ is the p.d.f. of $X_i$'s.  And we have a positive integer $r$, and the order statistics $$X_{(1)}\leq X_{(2)} \leq \cdots \leq X_{(r)}$$ where $1<r \leq n$. Then, denote $$T = \sum_{i=1}^{r} X_{(i)} + (n-r)X_{(r)}$$ The problem is to prove that $\frac{2T}{\lambda} \sim \chi^2_{2r}$. I'm quite at loss here. It seems to have a lot to do with Gamma distribution, but it doesn't seem the sum of first r- order statistics follows it. Even if the sum of the first r items does follow Gamma, I don't know how to handle the following $(n-r)X_{(r)}$. It doesn't seem right to directly compute the p.d.f. of $T$, which I've tried and failed. I'd appreciate it enormously if anyone can give me any hint or solution !",,"['probability', 'statistics', 'probability-distributions', 'order-statistics', 'exponential-distribution']"
79,Combining geometric means from different datasets,Combining geometric means from different datasets,,"In statistics, one sometimes uses the geometric mean which for a dataset $\{x_i\}_{i=1}^N$ is defined as  $$(\prod\limits_{i=1}^N x_i)^{(1/N)}.$$ This is particularly useful when the data of the experiment is distributed across many orders of magnitude, so that it would make more sense to plot histograms on a log scale than a linear scale. Now suppose I am doing an experiment to determine some experimental variable $X$, which theoretically is  the geometric mean of the data set I measure. Suppose I have done this experiment repeatedly to generate $r$ data sets with geometric means $\mu_1, \mu_2, \ldots, \mu_r$ and geometric standard deviations $\sigma_1,\sigma_2, \ldots, \sigma_r$. How do I combine the data from these different experiments to obtain one geometric mean that is the best estimate for the variable? Can one simply take the arithmetic mean and standard error of this collection of means? If so, why? Or should we consider a different 'geometric error of the mean'?","In statistics, one sometimes uses the geometric mean which for a dataset $\{x_i\}_{i=1}^N$ is defined as  $$(\prod\limits_{i=1}^N x_i)^{(1/N)}.$$ This is particularly useful when the data of the experiment is distributed across many orders of magnitude, so that it would make more sense to plot histograms on a log scale than a linear scale. Now suppose I am doing an experiment to determine some experimental variable $X$, which theoretically is  the geometric mean of the data set I measure. Suppose I have done this experiment repeatedly to generate $r$ data sets with geometric means $\mu_1, \mu_2, \ldots, \mu_r$ and geometric standard deviations $\sigma_1,\sigma_2, \ldots, \sigma_r$. How do I combine the data from these different experiments to obtain one geometric mean that is the best estimate for the variable? Can one simply take the arithmetic mean and standard error of this collection of means? If so, why? Or should we consider a different 'geometric error of the mean'?",,"['probability', 'statistics']"
80,Residuals vs fits Plot,Residuals vs fits Plot,,"I'm a little confused on the residuals vs fitted values plot. I take data in a table and create a scatter plot.  Then I run a linear regression computation using my calculator or other program that gives me a linear regression line in the form of $y=mx+b$. I then create a table which calculates the estimated or predicted value $y$ based on the input ($x$).  I compare this predicted value with the actual value to compute the difference or ""residual"". I then plot this on a graph showing the $x$ values on the horizontal axis and the residual values (difference value) on the y axis. This is how my text shows it.  However, when I look online at other stats sites I see the residuals plotted with the ""Fitted Value"" on the $x$-axis. This does NOT seem to be the same thing as the original $x$ values from the table.  And to confound things further, I read that the most common residual plots show the fitted value.  What is the fitted value?  Why isn't it the same as the original $x$ values? Am I misunderstanding this?","I'm a little confused on the residuals vs fitted values plot. I take data in a table and create a scatter plot.  Then I run a linear regression computation using my calculator or other program that gives me a linear regression line in the form of $y=mx+b$. I then create a table which calculates the estimated or predicted value $y$ based on the input ($x$).  I compare this predicted value with the actual value to compute the difference or ""residual"". I then plot this on a graph showing the $x$ values on the horizontal axis and the residual values (difference value) on the y axis. This is how my text shows it.  However, when I look online at other stats sites I see the residuals plotted with the ""Fitted Value"" on the $x$-axis. This does NOT seem to be the same thing as the original $x$ values from the table.  And to confound things further, I read that the most common residual plots show the fitted value.  What is the fitted value?  Why isn't it the same as the original $x$ values? Am I misunderstanding this?",,['statistics']
81,Power of a random variable and related notion of moment,Power of a random variable and related notion of moment,,"I am trying to grasp the idea of a power of a random variable, defined as a function $\Omega \to E$. In understand how a function can self-compose with itself, but I am unable to relate this to the power of random variables. I haven't been able to verify online that the referred to power is indeed the functional power, and I'm uncertain to assume so, since, as far as I understand, a self-composing function $f:X \to Y$ would require that $Y ⊆ X$, which does not hold with a RV. I am self-teaching, and so getting by on bits and pieces, thus even though I make a sincere effort not to, there might be an important thing I'm missing for which I'd greatly appreciate any reference and perhaps explanation. A related question I have concerns the moments of a RV's distribution. How can we assume an expected value for the kth power of a random variable X $E[X^k]$, or better, how can we know the specific underlying distribution of the kth powers of X, for which its first moment (expected value) would be given with $E[X^k]$? Where does this multitude arise?","I am trying to grasp the idea of a power of a random variable, defined as a function $\Omega \to E$. In understand how a function can self-compose with itself, but I am unable to relate this to the power of random variables. I haven't been able to verify online that the referred to power is indeed the functional power, and I'm uncertain to assume so, since, as far as I understand, a self-composing function $f:X \to Y$ would require that $Y ⊆ X$, which does not hold with a RV. I am self-teaching, and so getting by on bits and pieces, thus even though I make a sincere effort not to, there might be an important thing I'm missing for which I'd greatly appreciate any reference and perhaps explanation. A related question I have concerns the moments of a RV's distribution. How can we assume an expected value for the kth power of a random variable X $E[X^k]$, or better, how can we know the specific underlying distribution of the kth powers of X, for which its first moment (expected value) would be given with $E[X^k]$? Where does this multitude arise?",,['statistics']
82,Variance of aggregated distributions of binomial random variables,Variance of aggregated distributions of binomial random variables,,"Let two random variables: $$x_1 \sim Bin(100, 0.5) \\ x_2 \sim Bin(100, 0.6)$$ Now, we define a third random variable, $x_{12}$ which it's distribution is the aggregated distributions of $x_1$ and $x_2$, so it's not quite like $x_1 + x_2$ even though empirically the variance seems like the sum of the two variances. Is that the case? How can I show it? Thanks.","Let two random variables: $$x_1 \sim Bin(100, 0.5) \\ x_2 \sim Bin(100, 0.6)$$ Now, we define a third random variable, $x_{12}$ which it's distribution is the aggregated distributions of $x_1$ and $x_2$, so it's not quite like $x_1 + x_2$ even though empirically the variance seems like the sum of the two variances. Is that the case? How can I show it? Thanks.",,"['probability', 'statistics']"
83,Prove that $\frac1n\sum\limits^n_{i=1}(X_i-\overline{X})^2=\overline{X^2}-\overline{X}^{\ 2}$,Prove that,\frac1n\sum\limits^n_{i=1}(X_i-\overline{X})^2=\overline{X^2}-\overline{X}^{\ 2},"Prove that $\frac{1}{n}\sum\limits^n_{i=1}(X_i-\overline{X})^2=\overline{X^2}-\overline{X}^{\ 2}$ where $\overline{X}=\frac{1}{n}\sum\limits^n_{i=1}X_i$ and $\overline{X^2}=\frac{1}{n}\sum\limits^n_{i=1}X_i^2$ From the left, I can see that $$\frac{1}{n}\sum^n_{i=1}(X_i-\overline{X})^2=\frac{(X_1-\overline{X})^2+\cdots+(X_n-\overline{X})^2}{n} = \frac{(X_1-\frac{X_1+\cdots+X_n}{n})^2+\cdots+(X_n-\frac{X_1+\cdots+X_n}{n})^2}{n} = \cdots$$ I don't see how we can get to the right. Any suggestions?","Prove that $\frac{1}{n}\sum\limits^n_{i=1}(X_i-\overline{X})^2=\overline{X^2}-\overline{X}^{\ 2}$ where $\overline{X}=\frac{1}{n}\sum\limits^n_{i=1}X_i$ and $\overline{X^2}=\frac{1}{n}\sum\limits^n_{i=1}X_i^2$ From the left, I can see that $$\frac{1}{n}\sum^n_{i=1}(X_i-\overline{X})^2=\frac{(X_1-\overline{X})^2+\cdots+(X_n-\overline{X})^2}{n} = \frac{(X_1-\frac{X_1+\cdots+X_n}{n})^2+\cdots+(X_n-\frac{X_1+\cdots+X_n}{n})^2}{n} = \cdots$$ I don't see how we can get to the right. Any suggestions?",,"['statistics', 'summation', 'standard-deviation', 'means']"
84,Is minimizing the squared errors optimal?,Is minimizing the squared errors optimal?,,"In least squares regression, we try to minimize the sum of the squares error terms. I was wondering if this would unfairly penalize a model for having terms that are too far away. For example, a term that is $1$ unit away from the line of best fit would have $1^2=1$ effect on the MSE, but a term that is $2$ units away would have $2^2=4$ effect on the MSE. It seems to me that the term that is 2 units away seems to have 4 times as large an influence on the ""performance"" of a linear model compared with the first term. I was wondering why this was the case, and if there's some intuitive explanation for why this is so. Is the square used because cubics, quartics, etc, are harder to work with? I'd imagine it's easier to optimize for a square than an absolute value. Is there some fundamental reason for why this is so or is it convention? If anybody would have an intuitive explanation, that'd be perfect. Thanks so much!","In least squares regression, we try to minimize the sum of the squares error terms. I was wondering if this would unfairly penalize a model for having terms that are too far away. For example, a term that is $1$ unit away from the line of best fit would have $1^2=1$ effect on the MSE, but a term that is $2$ units away would have $2^2=4$ effect on the MSE. It seems to me that the term that is 2 units away seems to have 4 times as large an influence on the ""performance"" of a linear model compared with the first term. I was wondering why this was the case, and if there's some intuitive explanation for why this is so. Is the square used because cubics, quartics, etc, are harder to work with? I'd imagine it's easier to optimize for a square than an absolute value. Is there some fundamental reason for why this is so or is it convention? If anybody would have an intuitive explanation, that'd be perfect. Thanks so much!",,"['statistics', 'regression', 'machine-learning', 'least-squares', 'mean-square-error']"
85,Why minimising the MSE in Variance-Bias tradeoff?,Why minimising the MSE in Variance-Bias tradeoff?,,"As I understand the Variance-Bias tradeoff, modifying estimators to minimise bias might increase the variance of the estimator and vice-versa. For the simple case of the biased variance estimator, using $\frac{n}{(n-1)}$ as a correction factor might overcome the bias but the estimator has an un-optimal variance. At several places regarding this, as a more suited goal of supervised learning, correction factors to minimise the Mean Squared Error are used ($\frac{n}{n+1}$ for the sample variance). Why is minimising MSE a better objective (than that of minimising only bias)?","As I understand the Variance-Bias tradeoff, modifying estimators to minimise bias might increase the variance of the estimator and vice-versa. For the simple case of the biased variance estimator, using $\frac{n}{(n-1)}$ as a correction factor might overcome the bias but the estimator has an un-optimal variance. At several places regarding this, as a more suited goal of supervised learning, correction factors to minimise the Mean Squared Error are used ($\frac{n}{n+1}$ for the sample variance). Why is minimising MSE a better objective (than that of minimising only bias)?",,"['statistics', 'descriptive-statistics', 'variance']"
86,operations on probability distributions,operations on probability distributions,,I've found that you can do certain arithmetic operations on random variables such as : multiply or divide two log-normal distributed variables add or divide two gamma distributed variables I've been searching on Internet and I found nearly nothing. I would like to compute the mean and variance for each of these operations. Do you know any website which give the formulas or do you have the answer ?,I've found that you can do certain arithmetic operations on random variables such as : multiply or divide two log-normal distributed variables add or divide two gamma distributed variables I've been searching on Internet and I found nearly nothing. I would like to compute the mean and variance for each of these operations. Do you know any website which give the formulas or do you have the answer ?,,"['probability', 'statistics', 'probability-distributions']"
87,Does a factorable joint CDF/PDF always imply independence?,Does a factorable joint CDF/PDF always imply independence?,,"Say we have two random variables, x and y , with $F_{xy}(x,y)$ and $f_{xy}(x,y)$ denoting their joint CDF and PDF respectively. If they can be written such that $$F_{xy}(x,y)=G(x)H(y)$$ $$f_{xy}(x,y)=g(x)h(y)$$ is that enough to guarantee x and y are independent? My intuition suggests that it should be possible to construct a counterexample (either where none of the possible $g$/$G$ and $h$/$H$ functions are the marginal statistics or where $F$ might be factorable while $f$ is not), but so far I've had no luck. I've also had a hard time proving that it is always the case if it is in fact true.","Say we have two random variables, x and y , with $F_{xy}(x,y)$ and $f_{xy}(x,y)$ denoting their joint CDF and PDF respectively. If they can be written such that $$F_{xy}(x,y)=G(x)H(y)$$ $$f_{xy}(x,y)=g(x)h(y)$$ is that enough to guarantee x and y are independent? My intuition suggests that it should be possible to construct a counterexample (either where none of the possible $g$/$G$ and $h$/$H$ functions are the marginal statistics or where $F$ might be factorable while $f$ is not), but so far I've had no luck. I've also had a hard time proving that it is always the case if it is in fact true.",,['statistics']
88,Why Cauchy Distribution isn't Exponental Family?,Why Cauchy Distribution isn't Exponental Family?,,We know that the density function of standard Cauchy Distribution is $p(x)=\frac{\lambda}{\pi (\lambda^2+x^2)}$. It seems that $p(x)$ can't be written as the form of Exponential Family $$f_{X}(x;\theta)=h(x)\exp\Big(\sum^{s}_{i=1}{\eta_i (\theta)T_i (x)-A(\theta)}\Big)$$ But how to prove it strictly? or how to show that Cauchy Distribution doesn't belong to the Exponential Family?,We know that the density function of standard Cauchy Distribution is $p(x)=\frac{\lambda}{\pi (\lambda^2+x^2)}$. It seems that $p(x)$ can't be written as the form of Exponential Family $$f_{X}(x;\theta)=h(x)\exp\Big(\sum^{s}_{i=1}{\eta_i (\theta)T_i (x)-A(\theta)}\Big)$$ But how to prove it strictly? or how to show that Cauchy Distribution doesn't belong to the Exponential Family?,,"['probability', 'statistics']"
89,"If the number of persons per car is a random variable $H$ with mean $4$ and variance $2$, what is $P(\bar H\geq 5)$?","If the number of persons per car is a random variable  with mean  and variance , what is ?",H 4 2 P(\bar H\geq 5),"The question is as follows: According to a transportation safety board, the number of persons per car passing   a certain intersection between 8:00 and 9:00am, is a random variable $H$ with mean $4$ and variance $2$. For a random sample of $30$ cars at this intersection during this time period, what is the probability that the average number of persons per car is at least $5$? I've figured out that I'll be using the Central Limit Theorem to solve this, and thus far have found that: $$P(H > 5) = 1 - P( H \leq  5).$$ But I can't seem to incorporate the sample of $30$ cars in my equation, this would only be true for a sample $n$ of $1$ car. How can I work from here?","The question is as follows: According to a transportation safety board, the number of persons per car passing   a certain intersection between 8:00 and 9:00am, is a random variable $H$ with mean $4$ and variance $2$. For a random sample of $30$ cars at this intersection during this time period, what is the probability that the average number of persons per car is at least $5$? I've figured out that I'll be using the Central Limit Theorem to solve this, and thus far have found that: $$P(H > 5) = 1 - P( H \leq  5).$$ But I can't seem to incorporate the sample of $30$ cars in my equation, this would only be true for a sample $n$ of $1$ car. How can I work from here?",,"['probability', 'statistics', 'central-limit-theorem']"
90,Find the inverse cdf of Y: find $F ^{−1}_ Y (y)$.,Find the inverse cdf of Y: find .,F ^{−1}_ Y (y),"$$f(x, y) = \begin{cases} \frac{3}{4} & : 0 ≤ y ≤ 1 − x^2, −1 ≤ x ≤ 1 \\ 0 & : \textsf{elsewise}\end{cases}$$ find $ {F}_Y^{\raise{.5ex}{−1}}(y)$. So far I have that $f(y) = \frac{3}{2}\sqrt{1-y}$ but I don't know how to get the inverse cdf from that","$$f(x, y) = \begin{cases} \frac{3}{4} & : 0 ≤ y ≤ 1 − x^2, −1 ≤ x ≤ 1 \\ 0 & : \textsf{elsewise}\end{cases}$$ find $ {F}_Y^{\raise{.5ex}{−1}}(y)$. So far I have that $f(y) = \frac{3}{2}\sqrt{1-y}$ but I don't know how to get the inverse cdf from that",,"['probability', 'statistics']"
91,Determine periodicity from transition matrix?,Determine periodicity from transition matrix?,,"I have a two part question. Let's say we have a transition matrix T: \begin{bmatrix}     0 & 0.2 & 0.8 & 0  & 0 \\     0.7 & 0 & 0.3 & 0  & 0 \\     0.6 & 0.4 & 0 & 0  & 0 \\     0 & 0 & 0 & 0.1  & 0.9 \\     0 & 0 & 0 & 0.25  & 0.75 \\ \end{bmatrix} There are 5 states, so lets call them A through E. I want to determine if this is irreducible and aperiodic. Clearly this isnt isnt irreducible because there's no way for state A for example to reach state D. Now, for periodicity, I think T is aperiodic. I did this part by drawing out the state diagram and seeing if there's any way for a state to reach itself with a GCF bigger than 1. Here are my questions: 1) Was I right in thinking this is aperiodic? 2) Is there a way to determine periodicity just from the transition matrix? Without drawing the diagram I mean. Any help is appreciated.","I have a two part question. Let's say we have a transition matrix T: \begin{bmatrix}     0 & 0.2 & 0.8 & 0  & 0 \\     0.7 & 0 & 0.3 & 0  & 0 \\     0.6 & 0.4 & 0 & 0  & 0 \\     0 & 0 & 0 & 0.1  & 0.9 \\     0 & 0 & 0 & 0.25  & 0.75 \\ \end{bmatrix} There are 5 states, so lets call them A through E. I want to determine if this is irreducible and aperiodic. Clearly this isnt isnt irreducible because there's no way for state A for example to reach state D. Now, for periodicity, I think T is aperiodic. I did this part by drawing out the state diagram and seeing if there's any way for a state to reach itself with a GCF bigger than 1. Here are my questions: 1) Was I right in thinking this is aperiodic? 2) Is there a way to determine periodicity just from the transition matrix? Without drawing the diagram I mean. Any help is appreciated.",,"['probability', 'statistics', 'stochastic-processes', 'markov-chains', 'sampling']"
92,"Let $E(X)=\mu$ and $\operatorname{Var}(X)=\sigma^2$. If $E(Y|X)=a+bX$, find $E(XY)$ as a function of $\mu$ and $\sigma$.","Let  and . If , find  as a function of  and .",E(X)=\mu \operatorname{Var}(X)=\sigma^2 E(Y|X)=a+bX E(XY) \mu \sigma,"I can't figure out the answer for a question on my econometrics course. Somehow it seems simple, but still I can't seem to figure it out. Maybe I am thinking the wrong way about it. Could someone perhaps help me to figure this out? The question is a follows: Let $E(X)=\mu$ and $\operatorname{Var}(X)=\sigma^2$. If $E(Y|X)=a+bX$, find $E(XY)$ as a function of $\mu$ and $\sigma$. Now I see that $y$ is linearly dependent on $x$, but that is the conditional expectation of $y$. Of course, I would be happy with the answer. I was wondering, however, if someone could also perhaps attempt to explain how I should approach such a problem? This would help me a lot. Thank you in advance!","I can't figure out the answer for a question on my econometrics course. Somehow it seems simple, but still I can't seem to figure it out. Maybe I am thinking the wrong way about it. Could someone perhaps help me to figure this out? The question is a follows: Let $E(X)=\mu$ and $\operatorname{Var}(X)=\sigma^2$. If $E(Y|X)=a+bX$, find $E(XY)$ as a function of $\mu$ and $\sigma$. Now I see that $y$ is linearly dependent on $x$, but that is the conditional expectation of $y$. Of course, I would be happy with the answer. I was wondering, however, if someone could also perhaps attempt to explain how I should approach such a problem? This would help me a lot. Thank you in advance!",,"['probability', 'statistics', 'expectation', 'conditional-expectation']"
93,"How do $P( A | B , C) < P(A| B^c,C)$ and $P( A | B , C^c ) < P(A| B^c,C^c) \Longrightarrow P( A|B) > P(A|B^c)$?",How do  and ?,"P( A | B , C) < P(A| B^c,C) P( A | B , C^c ) < P(A| B^c,C^c) \Longrightarrow P( A|B) > P(A|B^c)","In general, Simpson's Paradox occurs because situation such as following occurs for some arbitrary events $A,B,$ and $C$: $P( A | B , C) < P(A| B^c,C) \tag{1}$ $P( A | B , C^c ) < P(A| B^c,C^c) \tag{2}$ Can someone show me a step-by-step way to arrive at $P( A|B) > P(A|B^c)$ from (1), (2)? The Law of Total Probability $P( A | B ) = P( A | B , C ) P( C | B) + P( A | B, C^c) P(C^c | B)$ appears  somehow involved but I don't see how. Any help would be appreciated.","In general, Simpson's Paradox occurs because situation such as following occurs for some arbitrary events $A,B,$ and $C$: $P( A | B , C) < P(A| B^c,C) \tag{1}$ $P( A | B , C^c ) < P(A| B^c,C^c) \tag{2}$ Can someone show me a step-by-step way to arrive at $P( A|B) > P(A|B^c)$ from (1), (2)? The Law of Total Probability $P( A | B ) = P( A | B , C ) P( C | B) + P( A | B, C^c) P(C^c | B)$ appears  somehow involved but I don't see how. Any help would be appreciated.",,"['probability', 'statistics', 'inequality', 'paradoxes', 'simpsons-rule']"
94,"Statistics, least square method","Statistics, least square method",,"I am having problems with an exercise. I have some observations of the random variable $Y$: $0.17, 0.06, 1.76, 3.41, 11.68, 1.86, 1.27, 0.00, 0.04,$ and $2.10$. I know that $Y = X^2$ and that $X \sim \mathrm{N}(\mu, 1)$. Now I am supposed to estimate $\mu$ using the least square method. I use the formula: $$Q(\mu) = \sum_{i=1}^{10} (x_i - \mu)^.2$$ My solution is that since $Y = X^2 \Leftrightarrow X = \sqrt{Y}$, then using the formula I have $$Q(\mu) = \sum_{i=1}^{10} (\sqrt{y_i} - \mu)^2 = \sum_{i=1}^{10} (\sqrt{y_i}^2 - 2 \mu \sum_{i=1}^{10} \sqrt{y_i} + \sum_{i=1}^{10} \mu^2$$ which gives me $$(0.17 + 0.06 +\cdots +2.10)-2\mu (\sqrt{0.17}+\sqrt{0.06}+\cdots+\sqrt{2.10}) + 10\mu^2$$ and $$Q'(\mu) = 20\mu - 2(\sqrt{0.17}+\sqrt{0.06}+\cdots+\sqrt{2.10}).$$ Setting this to zero (to minimize) gives me $$\mu = 2(\sqrt{0.17}+\sqrt{0.06}+\cdots+\sqrt{2.10})/20 = 1.13880\ldots$$ However, the answer should be 1.111. Can you spot any obvious mistakes? I feel like I have double checked this so many times now and I still think it looks alright, so the only conclusion I can draw is that I have missed something important about how to use this method. Any help is appreciated.","I am having problems with an exercise. I have some observations of the random variable $Y$: $0.17, 0.06, 1.76, 3.41, 11.68, 1.86, 1.27, 0.00, 0.04,$ and $2.10$. I know that $Y = X^2$ and that $X \sim \mathrm{N}(\mu, 1)$. Now I am supposed to estimate $\mu$ using the least square method. I use the formula: $$Q(\mu) = \sum_{i=1}^{10} (x_i - \mu)^.2$$ My solution is that since $Y = X^2 \Leftrightarrow X = \sqrt{Y}$, then using the formula I have $$Q(\mu) = \sum_{i=1}^{10} (\sqrt{y_i} - \mu)^2 = \sum_{i=1}^{10} (\sqrt{y_i}^2 - 2 \mu \sum_{i=1}^{10} \sqrt{y_i} + \sum_{i=1}^{10} \mu^2$$ which gives me $$(0.17 + 0.06 +\cdots +2.10)-2\mu (\sqrt{0.17}+\sqrt{0.06}+\cdots+\sqrt{2.10}) + 10\mu^2$$ and $$Q'(\mu) = 20\mu - 2(\sqrt{0.17}+\sqrt{0.06}+\cdots+\sqrt{2.10}).$$ Setting this to zero (to minimize) gives me $$\mu = 2(\sqrt{0.17}+\sqrt{0.06}+\cdots+\sqrt{2.10})/20 = 1.13880\ldots$$ However, the answer should be 1.111. Can you spot any obvious mistakes? I feel like I have double checked this so many times now and I still think it looks alright, so the only conclusion I can draw is that I have missed something important about how to use this method. Any help is appreciated.",,"['statistics', 'statistical-inference', 'least-squares']"
95,Probability of investment loss/gain problem,Probability of investment loss/gain problem,,"I'm trying to determine the total expected gain or loss over a one year period given an investment that has the following probabilities (over the same one year period): $P($2000 loss) = .25 $P($1000 profit) = .2 $P($5000 profit) = .15 $P($0 profit) = .4 My approach is as follows: $P($loss) = .25(-2000) = - 500 $P($gain) = .2(1000)+.15(5000)+.4(0) = 950 Expected gain/loss = gain - loss Expected gain/loss = 950 - 500 = $450 I feel like i'm missing something critical here, mostly pertaining to the 40% probability of breaking even.","I'm trying to determine the total expected gain or loss over a one year period given an investment that has the following probabilities (over the same one year period): $P($2000 loss) = .25 $P($1000 profit) = .2 $P($5000 profit) = .15 $P($0 profit) = .4 My approach is as follows: $P($loss) = .25(-2000) = - 500 $P($gain) = .2(1000)+.15(5000)+.4(0) = 950 Expected gain/loss = gain - loss Expected gain/loss = 950 - 500 = $450 I feel like i'm missing something critical here, mostly pertaining to the 40% probability of breaking even.",,"['probability', 'statistics']"
96,MSE of an estimator as sum of bias and variance,MSE of an estimator as sum of bias and variance,,"I am reading that how the MSE of an estimator $\hat{\theta}$ of $\theta$ can be expressed as $E(\hat{\theta} - \theta)^2$. Then this can be further simplified to   $ (E[\hat{\theta}] - \theta)^2  + Var[\hat{\theta}],$ where the first term is the square of the bias. I am trying to understand that what the expectation is over what. An elaborate explanation over what is happening here or an appropriate link will be very welcome.","I am reading that how the MSE of an estimator $\hat{\theta}$ of $\theta$ can be expressed as $E(\hat{\theta} - \theta)^2$. Then this can be further simplified to   $ (E[\hat{\theta}] - \theta)^2  + Var[\hat{\theta}],$ where the first term is the square of the bias. I am trying to understand that what the expectation is over what. An elaborate explanation over what is happening here or an appropriate link will be very welcome.",,"['statistics', 'statistical-inference', 'machine-learning']"
97,Distribution of $Y= \frac{X_1}{|X_2|}$?,Distribution of ?,Y= \frac{X_1}{|X_2|},"If $X_1$ and $X_2$ are independent and identically distributed Gaussian random variables with parameters $0$ and $\sigma^2$, how do I find the distribution of $Y= \frac{X_1}{|X_2|}$? I'm not supposed to use the method using the Jacobian but I'm not sure what the ""easier"" way to go about this is.","If $X_1$ and $X_2$ are independent and identically distributed Gaussian random variables with parameters $0$ and $\sigma^2$, how do I find the distribution of $Y= \frac{X_1}{|X_2|}$? I'm not supposed to use the method using the Jacobian but I'm not sure what the ""easier"" way to go about this is.",,"['probability', 'statistics', 'normal-distribution']"
98,Why is the average of a sum equal the sum of the averages?,Why is the average of a sum equal the sum of the averages?,,"I came across this website showing the proof of the above question in the Expected Value section. However, I do not quite understand why the probability of $xy$ becomes the probability of $x$ (or $y$) and why then the two summations reduce to only one in each term? Is it possible that $P_{xy}(x,y) = P_x(x) = P_y(y)$?","I came across this website showing the proof of the above question in the Expected Value section. However, I do not quite understand why the probability of $xy$ becomes the probability of $x$ (or $y$) and why then the two summations reduce to only one in each term? Is it possible that $P_{xy}(x,y) = P_x(x) = P_y(y)$?",,"['statistics', 'summation', 'average']"
99,"A grasshopper starts at the origin and is equally likely to hop north,s,e,w. What is the probability that it's coordinates will be 0,0 after 4 hops?","A grasshopper starts at the origin and is equally likely to hop north,s,e,w. What is the probability that it's coordinates will be 0,0 after 4 hops?",,"The grasshopper must hop in all $4$ directions (North, South, East, and West) to get back to the origin after $4$ hops. Therefore, I did: $\frac{(4 \cdot 3 \cdot 2 \cdot1)}{4^4} = .09375$. However, the answer key tells me that the answer should be $\frac{36}{256} = .140625$, which is exactly six times my answer. I'm not sure why my answer would be incorrect (since the grasshopper can hope either North, South, East, or West the first time, and if it hopped North, it can hop South, East, or West; if it hopped East, it can hop South or West, and so on.) it covers all the different orders that the grasshopper could hop in.","The grasshopper must hop in all $4$ directions (North, South, East, and West) to get back to the origin after $4$ hops. Therefore, I did: $\frac{(4 \cdot 3 \cdot 2 \cdot1)}{4^4} = .09375$. However, the answer key tells me that the answer should be $\frac{36}{256} = .140625$, which is exactly six times my answer. I'm not sure why my answer would be incorrect (since the grasshopper can hope either North, South, East, or West the first time, and if it hopped North, it can hop South, East, or West; if it hopped East, it can hop South or West, and so on.) it covers all the different orders that the grasshopper could hop in.",,"['probability', 'combinatorics', 'statistics']"
