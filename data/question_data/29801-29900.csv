,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,A question on calculating probabilities for the random walk,A question on calculating probabilities for the random walk,,"I am currently working on a high school project revolving around the 'Cliff Hanger Problem' taken from ”Fifty Challenging Problems in Probability with Solutions” by Frederick Mosteller. The problem is 'From where he stands, one step toward the cliff would send the drunken man over the bridge. He takes random steps, either toward or away from the cliff. At any step his probability of taking a step away is $\frac{2}{3}$ of a step toward the cliff $\frac{1}{3}$ . What is his chance of escaping the cliff?' Although the book provided a solution for the eventual probability of falling via the use of recursive equations, I decided to see if I can derive an expression to compute the probability of one falling down prior step N. What I did was to calculate the number of paths that one can take such that he reaches $X_n=1$, where n=2m-1 for some m (this is because at even steps the person would not fall so I'm only considering the case with odd steps) without reaching $X_j=1$ for any $0\le j< 2m-1$. The following expression is what I have calculated. $P_n=1-\sum\limits_{i=0}^{m} p_{2i+1}\\ =1-\sum\limits_{i=0}^{m} \left({{2i+1}\choose{i+1}} - \sum\limits_{k=1}^{i}{{2k}\choose{k}}\right)\left(\left(\frac{1}{3}\right)^{i+1}\left(\frac{2}{3}\right)^{i}\right)$ (I actually made a mistake here as I considered 2m+1 rather than 2m-1, which left the summation sign with $\sum\limits_{k=1}^{i}{{2k}\choose{k}}$ undefined when i=0) Where $p_2i+1=$ the probability of the path touching 1 at $n=2i+1$ without touching $1$ prior to the step. The first binomial expression corresponds to choosing n+1 steps towards the cliff out of the 2n+1 steps. The second binomial expression is to subtract the paths that stemmed from previous 1's (in order to ensure that the path did not touch 1 prior to $n=2i+1$.) However as I plotted this into excel I found that the probability does not converge to $\frac{1}{2}$ as n->infinity, which is the answer the book obtained through recursive relations. I reviewed my argument but I don't know what did I do wrong (whether I've overcounted or undercounted). Can anyone help?","I am currently working on a high school project revolving around the 'Cliff Hanger Problem' taken from ”Fifty Challenging Problems in Probability with Solutions” by Frederick Mosteller. The problem is 'From where he stands, one step toward the cliff would send the drunken man over the bridge. He takes random steps, either toward or away from the cliff. At any step his probability of taking a step away is $\frac{2}{3}$ of a step toward the cliff $\frac{1}{3}$ . What is his chance of escaping the cliff?' Although the book provided a solution for the eventual probability of falling via the use of recursive equations, I decided to see if I can derive an expression to compute the probability of one falling down prior step N. What I did was to calculate the number of paths that one can take such that he reaches $X_n=1$, where n=2m-1 for some m (this is because at even steps the person would not fall so I'm only considering the case with odd steps) without reaching $X_j=1$ for any $0\le j< 2m-1$. The following expression is what I have calculated. $P_n=1-\sum\limits_{i=0}^{m} p_{2i+1}\\ =1-\sum\limits_{i=0}^{m} \left({{2i+1}\choose{i+1}} - \sum\limits_{k=1}^{i}{{2k}\choose{k}}\right)\left(\left(\frac{1}{3}\right)^{i+1}\left(\frac{2}{3}\right)^{i}\right)$ (I actually made a mistake here as I considered 2m+1 rather than 2m-1, which left the summation sign with $\sum\limits_{k=1}^{i}{{2k}\choose{k}}$ undefined when i=0) Where $p_2i+1=$ the probability of the path touching 1 at $n=2i+1$ without touching $1$ prior to the step. The first binomial expression corresponds to choosing n+1 steps towards the cliff out of the 2n+1 steps. The second binomial expression is to subtract the paths that stemmed from previous 1's (in order to ensure that the path did not touch 1 prior to $n=2i+1$.) However as I plotted this into excel I found that the probability does not converge to $\frac{1}{2}$ as n->infinity, which is the answer the book obtained through recursive relations. I reviewed my argument but I don't know what did I do wrong (whether I've overcounted or undercounted). Can anyone help?",,"['probability', 'combinatorics', 'stochastic-processes', 'random-walk']"
1,Probability with card game,Probability with card game,,"I need help calculating the chances of winning this strange game that I'm going to explain right now: You have a deck of 52 cards(4 suits,Ace to King). All you have to do is turning  the cards one by one counting one,two,three while you turn them. If you get an   Ace when you count one or a two when you count two or a three when you count  three you lose. For example if you get: 2(one),K(two),6(three),3(one),Q(two),3(three) You lose,because you get a 3 when you counted three. The only way I could think to resolve this problem is to calculate the chances of losing and then: \begin{equation} P(W)=1-P(L) \end{equation} where $ P(W) $ is chances of winning and $ P(L) $ is chances of losing. But how do I calculate $ P(L) $ ? I've tried this,but I'm almost sure that's wrong: $P(L)=$chances of getting an ace in first position or chances of getting a 2 in second position or chances of gettin a 3 in third position or chances of getting an ace in fourth position and so on... So: \begin{equation} P(L)=\frac{4}{52}+\frac{4}{51}+\frac{4}{50}+\frac{3}{49}+\frac{3}{48}+\frac{3}{47}+\frac{2}{46}+\frac{2}{45}+\frac{2}{44}+\frac{1}{43}+\frac{1}{42}+\frac{1}{41} \end{equation} Thanks everybody:)","I need help calculating the chances of winning this strange game that I'm going to explain right now: You have a deck of 52 cards(4 suits,Ace to King). All you have to do is turning  the cards one by one counting one,two,three while you turn them. If you get an   Ace when you count one or a two when you count two or a three when you count  three you lose. For example if you get: 2(one),K(two),6(three),3(one),Q(two),3(three) You lose,because you get a 3 when you counted three. The only way I could think to resolve this problem is to calculate the chances of losing and then: \begin{equation} P(W)=1-P(L) \end{equation} where $ P(W) $ is chances of winning and $ P(L) $ is chances of losing. But how do I calculate $ P(L) $ ? I've tried this,but I'm almost sure that's wrong: $P(L)=$chances of getting an ace in first position or chances of getting a 2 in second position or chances of gettin a 3 in third position or chances of getting an ace in fourth position and so on... So: \begin{equation} P(L)=\frac{4}{52}+\frac{4}{51}+\frac{4}{50}+\frac{3}{49}+\frac{3}{48}+\frac{3}{47}+\frac{2}{46}+\frac{2}{45}+\frac{2}{44}+\frac{1}{43}+\frac{1}{42}+\frac{1}{41} \end{equation} Thanks everybody:)",,"['probability', 'card-games']"
2,Conditional Density Function Derivation,Conditional Density Function Derivation,,"Let $(\Omega, \mathcal{F},P)$ be a probability space and $X\colon\Omega \to \mathbb{R},Y \colon \Omega \to \mathbb{R}$ be continuous random variables (i.e. random variables which have a density function. I am assuming that this implies $P(X=x)=P(Y=y)=0~\forall x,y \in \mathbb{R}$). According to Papoulis , the conditional distribution function $F_{X|Y} = P(X \leq x | Y = y)$ is defined by considering the probability $P(X \leq x | y \leq Y \leq y + \delta y)$ and taking the limit $\delta y\to 0$. However, I do not find the derivation given there rigorous. It is easy to write: $$P(X \leq x | y \leq Y \leq y + \delta y) = \frac{P( X \leq x, y \leq Y \leq y + \delta y)}{P(y \leq Y \leq y + \delta y)} = \frac{F_{X,Y}(x,y+\delta y) - F_{X,Y}(x,y)}{F_Y(y+\delta y) - F_Y(y)}$$ from definition of $F_{X,Y}$, $F_Y$ and the fact that the point probabilities are zero. I am not sure how to evaulate the limit: $$\lim_{\delta y \to 0} \frac{F_{X,Y}(x,y+\delta y) - F_{X,Y}(x,y)}{F_Y(y+\delta y) - F_Y(y)}.$$ I have tried using the L'Hopital rule as this limit is of the form $\frac{0}{0}$ but I am not sure if that is the right direction. Any help is much appreciated. EDIT: Papoulis obtains a formula for the density function by differentiating the term inside the limit. i.e.,  $$ f_{X|Y}(x,y) =  \lim_{\delta y \to 0} \left(\frac{\partial F_{X,Y}(x,y+\delta y) - F_{X,Y}(x,y)}{\partial x}\frac{1}{F_Y(y+\delta y) - F_Y(y)}\right)$$ I believe I should have asked for the derivation of the density function as I am afraid that the Conditional Distribution functions does not have a neat expression. Thanks, Phanindra","Let $(\Omega, \mathcal{F},P)$ be a probability space and $X\colon\Omega \to \mathbb{R},Y \colon \Omega \to \mathbb{R}$ be continuous random variables (i.e. random variables which have a density function. I am assuming that this implies $P(X=x)=P(Y=y)=0~\forall x,y \in \mathbb{R}$). According to Papoulis , the conditional distribution function $F_{X|Y} = P(X \leq x | Y = y)$ is defined by considering the probability $P(X \leq x | y \leq Y \leq y + \delta y)$ and taking the limit $\delta y\to 0$. However, I do not find the derivation given there rigorous. It is easy to write: $$P(X \leq x | y \leq Y \leq y + \delta y) = \frac{P( X \leq x, y \leq Y \leq y + \delta y)}{P(y \leq Y \leq y + \delta y)} = \frac{F_{X,Y}(x,y+\delta y) - F_{X,Y}(x,y)}{F_Y(y+\delta y) - F_Y(y)}$$ from definition of $F_{X,Y}$, $F_Y$ and the fact that the point probabilities are zero. I am not sure how to evaulate the limit: $$\lim_{\delta y \to 0} \frac{F_{X,Y}(x,y+\delta y) - F_{X,Y}(x,y)}{F_Y(y+\delta y) - F_Y(y)}.$$ I have tried using the L'Hopital rule as this limit is of the form $\frac{0}{0}$ but I am not sure if that is the right direction. Any help is much appreciated. EDIT: Papoulis obtains a formula for the density function by differentiating the term inside the limit. i.e.,  $$ f_{X|Y}(x,y) =  \lim_{\delta y \to 0} \left(\frac{\partial F_{X,Y}(x,y+\delta y) - F_{X,Y}(x,y)}{\partial x}\frac{1}{F_Y(y+\delta y) - F_Y(y)}\right)$$ I believe I should have asked for the derivation of the density function as I am afraid that the Conditional Distribution functions does not have a neat expression. Thanks, Phanindra",,['probability']
3,Hausdorff dimension of graphs of one-dimensional Brownian motion,Hausdorff dimension of graphs of one-dimensional Brownian motion,,"First question here, my apologies if it is a duplicate or inappropriate. There is a page on Wikipedia listing fractals by Hausdorff dimension and it includes the graph of a ""regular Brownian function"" as having Hausdorff dimension 1.5. Does this mean that a Brownian motion has Hausdorff dimension almost always, or is it the expected value, or something else? I've tried to look for references (besides the Wikipedia one that I can't get) and googling for more information to little avail. If it's not true that the graph of a Brownian motion has Hausdorff dimension 1.5 almost always, is it true that the Hausdorff dimension >1 almost always?","First question here, my apologies if it is a duplicate or inappropriate. There is a page on Wikipedia listing fractals by Hausdorff dimension and it includes the graph of a ""regular Brownian function"" as having Hausdorff dimension 1.5. Does this mean that a Brownian motion has Hausdorff dimension almost always, or is it the expected value, or something else? I've tried to look for references (besides the Wikipedia one that I can't get) and googling for more information to little avail. If it's not true that the graph of a Brownian motion has Hausdorff dimension 1.5 almost always, is it true that the Hausdorff dimension >1 almost always?",,"['probability', 'fractals', 'brownian-motion']"
4,When can i get away with approximating the expected value of a ratio as the ratio of expected values,When can i get away with approximating the expected value of a ratio as the ratio of expected values,,"I'm actually an engineering student so I'm not too good with probability and was hoping someone may be able to help with the following: So I have a ratio of discrete random variables. I want to be able to know when I can get away with approximating its expected value as a ratio of expected values. For example, for the continuous case I came across the following formulation from a Taylor series expansion $\text{E}[x/y]=\text{E}[x]/ \text{E}[y]- \text{Cov}[x ,y]/ \text{E}[y]^2 + \text{E}[x] \text{Var}[y]/ \text{E}[y]^3$ Does this apply for discrete random variables? if not, what is its analogous expression? thank you! hadi","I'm actually an engineering student so I'm not too good with probability and was hoping someone may be able to help with the following: So I have a ratio of discrete random variables. I want to be able to know when I can get away with approximating its expected value as a ratio of expected values. For example, for the continuous case I came across the following formulation from a Taylor series expansion $\text{E}[x/y]=\text{E}[x]/ \text{E}[y]- \text{Cov}[x ,y]/ \text{E}[y]^2 + \text{E}[x] \text{Var}[y]/ \text{E}[y]^3$ Does this apply for discrete random variables? if not, what is its analogous expression? thank you! hadi",,['probability']
5,About a weighted sum of hitting times for random walks on graphs,About a weighted sum of hitting times for random walks on graphs,,"Consider a random walk on an undirected, non-bipartite graph. Let $\pi$ be the stationary distribution of this process, and let the hitting time $H(s,t)$ be the expected time until a walk beginning at node $s$ reaches node $t$. I learned from Random walks on graphs: a survey, by L. Lovasz, that the quantity $$ \sum_{t} \pi(t) H(s,t)$$ is independent of $s$. In the Lovasz survey, this falls out as a byproduct of a lengthy calculation. I have two questions: (i) Is there a simple (calculation-free, combinatorial) proof of this statement? (ii) In what generality does this statement hold? Random walks on undirected graphs are a very particular kind of Markov process. What conditions on the probability transition matrix of the process do you need for the above to hold?","Consider a random walk on an undirected, non-bipartite graph. Let $\pi$ be the stationary distribution of this process, and let the hitting time $H(s,t)$ be the expected time until a walk beginning at node $s$ reaches node $t$. I learned from Random walks on graphs: a survey, by L. Lovasz, that the quantity $$ \sum_{t} \pi(t) H(s,t)$$ is independent of $s$. In the Lovasz survey, this falls out as a byproduct of a lengthy calculation. I have two questions: (i) Is there a simple (calculation-free, combinatorial) proof of this statement? (ii) In what generality does this statement hold? Random walks on undirected graphs are a very particular kind of Markov process. What conditions on the probability transition matrix of the process do you need for the above to hold?",,"['probability', 'stochastic-processes']"
6,Variance lower bound for discrete random variables,Variance lower bound for discrete random variables,,"We know that for a continuous random variable $X$ with density $f$ , $$Var(X) \geq \frac{e^{2h(f)}}{2\pi e},$$ where $h(f)$ is the differential entropy. This follows from Eq (8.80), Theorem 8.6.6 of Thomas & Cover Information Theory book: Can we get a similar lower bound for a discrete random variable? Let's say $X\in\{-N,\cdots,-1,0,1,2,\cdots,N\}$ for finite N with some probability mass function $p(.)$ . We can't apply the argument in eq.(8.80) above since uniform distribution is the maximum entropy for discrete random variables! We know that $Var(X)=0$ if and only if X is degenerate. So I think we can get a lower bound in this case as well, but I am not able to come up with anything. :( Thanks for any help in advance! Edit 1: From here , there doesn't seem to be a closed-form known discrete distribution for the maximum entropy when variance is known.","We know that for a continuous random variable with density , where is the differential entropy. This follows from Eq (8.80), Theorem 8.6.6 of Thomas & Cover Information Theory book: Can we get a similar lower bound for a discrete random variable? Let's say for finite N with some probability mass function . We can't apply the argument in eq.(8.80) above since uniform distribution is the maximum entropy for discrete random variables! We know that if and only if X is degenerate. So I think we can get a lower bound in this case as well, but I am not able to come up with anything. :( Thanks for any help in advance! Edit 1: From here , there doesn't seem to be a closed-form known discrete distribution for the maximum entropy when variance is known.","X f Var(X) \geq \frac{e^{2h(f)}}{2\pi e}, h(f) X\in\{-N,\cdots,-1,0,1,2,\cdots,N\} p(.) Var(X)=0","['probability', 'probability-theory', 'inequality', 'probability-distributions', 'variance']"
7,Probability of a random distribution being in a set of distributions,Probability of a random distribution being in a set of distributions,,"Let $S=\{s_1,\dots,s_k\}$ be some set of size $k$ and let $\mathit{Dist}(S)$ be the set of all probability distributions over $S$ where a probability distribution is simply a function $p \colon S \rightarrow [0,1]$ with $\sum_{s\in S}p(s) = 1$ . We construct a random probability distribution $t$ over $S=\{s_1,\dots,s_k\}$ in the following way: generate a multiset $R$ of $k-1$ random variables each sampled uniformly from $[0,1]$ sort them ascending and label them $n_1$ to $n_k$ , i.e., $\hat{\{}n_i\mid i\in \{1,\dots,k-1\}\hat{\}}=R$ and $n_1\leq n_2 \leq \dots \leq n_{k-1}$ define $n_0=0$ and $n_k=1$ for each $i$ we define $t(s_i)=n_i-n_{i-1}$ This can be visualised as taking the number line from 0 to 1, split it into $k$ parts by dropping $k-1$ separators randomly and asserting each probability a value that corresponds to the distance between two adjacent separators. Note that $t$ is indeed a probability distribution since $n_i\geq n_{i-1}$ and $\sum_{s\in S}t(s) = 1$ . Given a set of distributions $T \subseteq Dist(S)$ , what is the probability that $t \in T$ ? If it helps, we can assume that $T$ gives a dense range of possible values for the probability of each element of $S$ , i.e., for each $i \in \{1,\dots,k\}$ there are some $\underline{p_i},\overline{p_i}\in [0,1]$ with $\underline{p_i} < \overline{p_i}$ and $T = \{ p \mid p \in \mathit{Dist}(S) \text{ and } \forall i.p(s_i)\in [\underline{p_i},\overline{p_i}] \}$ . For $k=2$ this is straight forward since $p(s_1) = 1-p(s_2)$ , i.e., it is essentially just one random variable. However even extending this to a set of three elements already gives me troubles. The main issue I keep running into is that I know the $p(s_i)$ are not independent (since they have to add to 1). I'm not looking for a closed form necessarily. A way to compute this algorithmically would be perfectly fine.","Let be some set of size and let be the set of all probability distributions over where a probability distribution is simply a function with . We construct a random probability distribution over in the following way: generate a multiset of random variables each sampled uniformly from sort them ascending and label them to , i.e., and define and for each we define This can be visualised as taking the number line from 0 to 1, split it into parts by dropping separators randomly and asserting each probability a value that corresponds to the distance between two adjacent separators. Note that is indeed a probability distribution since and . Given a set of distributions , what is the probability that ? If it helps, we can assume that gives a dense range of possible values for the probability of each element of , i.e., for each there are some with and . For this is straight forward since , i.e., it is essentially just one random variable. However even extending this to a set of three elements already gives me troubles. The main issue I keep running into is that I know the are not independent (since they have to add to 1). I'm not looking for a closed form necessarily. A way to compute this algorithmically would be perfectly fine.","S=\{s_1,\dots,s_k\} k \mathit{Dist}(S) S p \colon S \rightarrow [0,1] \sum_{s\in S}p(s) = 1 t S=\{s_1,\dots,s_k\} R k-1 [0,1] n_1 n_k \hat{\{}n_i\mid i\in \{1,\dots,k-1\}\hat{\}}=R n_1\leq n_2 \leq \dots \leq n_{k-1} n_0=0 n_k=1 i t(s_i)=n_i-n_{i-1} k k-1 t n_i\geq n_{i-1} \sum_{s\in S}t(s) = 1 T \subseteq Dist(S) t \in T T S i \in \{1,\dots,k\} \underline{p_i},\overline{p_i}\in [0,1] \underline{p_i} < \overline{p_i} T = \{ p \mid p \in \mathit{Dist}(S) \text{ and } \forall i.p(s_i)\in [\underline{p_i},\overline{p_i}] \} k=2 p(s_1) = 1-p(s_2) p(s_i)","['probability', 'probability-theory', 'probability-distributions']"
8,Replacement only when 'prize' is found,Replacement only when 'prize' is found,,"There are $a$ balls in a jar. One is gold, the rest are black. Balls are taken from the jar. If a black ball is taken, it is not replaced. If a gold ball is taken, all balls are replaced. I am interested in finding a closed form solution for the expected number of gold balls taken after $k$ balls have been taken in total. My approach so far is to form a recurrence relation with $E_n =$ the expected number of gold balls taken after $n$ balls have been taken in total. The starting condition is $$E_0 = 0$$ Conditioning on getting the gold ball on the $i$ th try (probability $\frac{1}{a}$ ), For $0 < k < a$ , $$E_k = \left(\frac{1}{a}\right)\left(\sum^{k}_{i=1}1+E_{k-i}\right)$$ For $k \geq a$ , $$E_k = \left(\frac{1}{a}\right)\left(\sum^{a}_{i=1}1+E_{k-i}\right)$$ The relation can be simplified to $$E_{<0} = -1, E_0 = 0$$ $$E_{k>0} = 1+\left(\frac{1}{a}\right)\left(\sum^{a}_{i=1}E_{k-i}\right)$$ I'm not sure where to go from here, or if this is the best approach. Another thing I'm a bit confused on is some intuition. When $a=2$ and the jar is full, the expected number of balls it takes to get the golden ball is $\frac{1}{2}+\frac{2}{2}=\frac{3}{2}=1.5$ , I believe. On the other hand, if the above recurrence is correct, then for $a=2$ , $E_3=\frac{15}{8}=1.875$ . So you expect $1.875$ gold balls after taking $3$ balls. I can't figure out why this is less than $2$ , intuitively, which leads me to be unsure about my recurrence. On the other hand, I notice as $k$ grows large (from plotting the recurrence), the difference between the expected number of gold balls every $3$ balls taken tends to $2$ from below. What I've said above seems to generalise for all $a$ . Table of recurrence for $a=2$ . Left column is $k$ , right is $E_k$ .","There are balls in a jar. One is gold, the rest are black. Balls are taken from the jar. If a black ball is taken, it is not replaced. If a gold ball is taken, all balls are replaced. I am interested in finding a closed form solution for the expected number of gold balls taken after balls have been taken in total. My approach so far is to form a recurrence relation with the expected number of gold balls taken after balls have been taken in total. The starting condition is Conditioning on getting the gold ball on the th try (probability ), For , For , The relation can be simplified to I'm not sure where to go from here, or if this is the best approach. Another thing I'm a bit confused on is some intuition. When and the jar is full, the expected number of balls it takes to get the golden ball is , I believe. On the other hand, if the above recurrence is correct, then for , . So you expect gold balls after taking balls. I can't figure out why this is less than , intuitively, which leads me to be unsure about my recurrence. On the other hand, I notice as grows large (from plotting the recurrence), the difference between the expected number of gold balls every balls taken tends to from below. What I've said above seems to generalise for all . Table of recurrence for . Left column is , right is .","a k E_n = n E_0 = 0 i \frac{1}{a} 0 < k < a E_k = \left(\frac{1}{a}\right)\left(\sum^{k}_{i=1}1+E_{k-i}\right) k \geq a E_k = \left(\frac{1}{a}\right)\left(\sum^{a}_{i=1}1+E_{k-i}\right) E_{<0} = -1, E_0 = 0 E_{k>0} = 1+\left(\frac{1}{a}\right)\left(\sum^{a}_{i=1}E_{k-i}\right) a=2 \frac{1}{2}+\frac{2}{2}=\frac{3}{2}=1.5 a=2 E_3=\frac{15}{8}=1.875 1.875 3 2 k 3 2 a a=2 k E_k",['probability']
9,Max. distance of 2D random walk,Max. distance of 2D random walk,,"We take a random walk starting at $(0,0)\in\mathbb{Z}^2$ and at each step, with probability $p=1/4$ , we move either one unit up, down, left or right. After $n$ steps, what is the expected value of the maximum $||\cdot||_1$ -distance (taxicab-distance) the walker had to the origin? I don't actually know if there is a closed formula for this. If not, are there ideas on how to find interesting bounds? Would the question become easier when considering other distances? I believe that there is a lower bound of $\sqrt{n}$ . Is this correct? Any ideas on how to show this?","We take a random walk starting at and at each step, with probability , we move either one unit up, down, left or right. After steps, what is the expected value of the maximum -distance (taxicab-distance) the walker had to the origin? I don't actually know if there is a closed formula for this. If not, are there ideas on how to find interesting bounds? Would the question become easier when considering other distances? I believe that there is a lower bound of . Is this correct? Any ideas on how to show this?","(0,0)\in\mathbb{Z}^2 p=1/4 n ||\cdot||_1 \sqrt{n}","['probability', 'random-walk']"
10,"If all powers of two random variables are uncorrelated, are they independent?","If all powers of two random variables are uncorrelated, are they independent?",,"Let $X$ and $Y$ be random variables on a common probability space. If $$\def\E{\mathbb E}\E[X^nY^m]=\E[X^n]\,\E[Y^m]<\infty $$ for all integers $n,m\ge 0$ , does it follow that $X$ and $Y$ independent? I strongly suspect the answer is no. In the same way that the a random variable is not determined by its moments, a random vector is not determined by its joint moments. I have looked at several counter-examples of distinct random variables with the same moments, which I found here . The examples are derived by looking at characteristic functions, but I am not sure if they can be generalized to multivariate characteristic functions. This question shows that $\E[f(X)g(Y)]=\E[f(X)]\,\E[g(Y)]$ for all bounded and continuous $f$ and $g$ implies $X$ and $Y$ are independent. My question is if we get the same result when we restrict $f$ and $g$ to be polynomials.","Let and be random variables on a common probability space. If for all integers , does it follow that and independent? I strongly suspect the answer is no. In the same way that the a random variable is not determined by its moments, a random vector is not determined by its joint moments. I have looked at several counter-examples of distinct random variables with the same moments, which I found here . The examples are derived by looking at characteristic functions, but I am not sure if they can be generalized to multivariate characteristic functions. This question shows that for all bounded and continuous and implies and are independent. My question is if we get the same result when we restrict and to be polynomials.","X Y \def\E{\mathbb E}\E[X^nY^m]=\E[X^n]\,\E[Y^m]<\infty  n,m\ge 0 X Y \E[f(X)g(Y)]=\E[f(X)]\,\E[g(Y)] f g X Y f g","['probability', 'probability-theory', 'examples-counterexamples', 'moment-problem']"
11,Optimal way to stack deck against uniformly random opponent?,Optimal way to stack deck against uniformly random opponent?,,"A card game is played by splitting a face-down shuffled deck evenly between two players. The deck consists of cards numbered 1-52. Each player reveals the top card of their deck, and the player whose card has higher rank scores 1 point. Both cards are then discarded. The process is repeated until both decks have been depleted. The winner of the game is the one with the largest number of points. Suppose you can cheat at this game: first, you know the contents, but not the order, of both decks. Second, each round before your opponent reveals a card, you can choose which card in your deck you will reveal. (That is, you can choose which card you will reveal next based on all of the information you have up to the point where the opponent will reveal a new card.) My friend suggested that even if you can cheat in this way, there is no strategy you can play which will give you a higher score on average than playing at random. This doesn't seem true to me, but I've had trouble proving that cheating helps in simple cases, or proving (e.g. inductively) that it doesn't matter. Any help is appreciated. Edit: If it helps, I've previously considered a simpler version of this game, in which you know the fixed order of your opponents' cards, which are played in order. If you are allowed to cheat in this deterministic version, you can optimize your score according to the following strategy. First, it suffices to establish a mapping between their cards and your cards --- the card you will play when they play their card.  To create this mapping, list your cards in ascending order of rank and list their cards in the same way.  If their highest ranked card beats your highest ranked card, pair it with your lowest-ranked card. Otherwise, pair it with the lowest-ranked card you have that still beats it. Remove both cards, and repeat this process. Edit 2: Conjecture . Even if you cheat, there is no strategy which performs better than chance. In particular, regardless of which strategy you employ, your expected score is simply the probability that a random card from your deck beats a random card from their deck, times the total number of cards in each deck. If you create an $n\times n$ matrix whose $(i,j)$ entry is 1 if your $i$ th card beats their $j$ th card, your expected score on any strategy is 1/ $n$ times the sum of the entries of the matrix. I think I have an inductive proof of this, but am still figuring out how to write it out formally.","A card game is played by splitting a face-down shuffled deck evenly between two players. The deck consists of cards numbered 1-52. Each player reveals the top card of their deck, and the player whose card has higher rank scores 1 point. Both cards are then discarded. The process is repeated until both decks have been depleted. The winner of the game is the one with the largest number of points. Suppose you can cheat at this game: first, you know the contents, but not the order, of both decks. Second, each round before your opponent reveals a card, you can choose which card in your deck you will reveal. (That is, you can choose which card you will reveal next based on all of the information you have up to the point where the opponent will reveal a new card.) My friend suggested that even if you can cheat in this way, there is no strategy you can play which will give you a higher score on average than playing at random. This doesn't seem true to me, but I've had trouble proving that cheating helps in simple cases, or proving (e.g. inductively) that it doesn't matter. Any help is appreciated. Edit: If it helps, I've previously considered a simpler version of this game, in which you know the fixed order of your opponents' cards, which are played in order. If you are allowed to cheat in this deterministic version, you can optimize your score according to the following strategy. First, it suffices to establish a mapping between their cards and your cards --- the card you will play when they play their card.  To create this mapping, list your cards in ascending order of rank and list their cards in the same way.  If their highest ranked card beats your highest ranked card, pair it with your lowest-ranked card. Otherwise, pair it with the lowest-ranked card you have that still beats it. Remove both cards, and repeat this process. Edit 2: Conjecture . Even if you cheat, there is no strategy which performs better than chance. In particular, regardless of which strategy you employ, your expected score is simply the probability that a random card from your deck beats a random card from their deck, times the total number of cards in each deck. If you create an matrix whose entry is 1 if your th card beats their th card, your expected score on any strategy is 1/ times the sum of the entries of the matrix. I think I have an inductive proof of this, but am still figuring out how to write it out formally.","n\times n (i,j) i j n","['probability', 'game-theory', 'card-games']"
12,Is the set of measurable functions measurable?,Is the set of measurable functions measurable?,,"Let $M$ be the set of measurable functions in $\mathbb{R^R}$ . Now, $\mathbb{R^R}$ has the borelian sigma-algebra associated with its product topology, which allows us to ask the following question : Is $M$ measurable? On the positive side, I have two remarks: $M$ is sequentially closed (a pointwise limit of measurable functions is measurable) but alas it is not closed; also, in some models of ZF, $M$ is $\mathbb{R^R}$ so is obviously measurable. On the negative side, I feel like a borelian subset of $\mathbb{R^R}$ will only give constraints on the value of functions at countably many points, which is probably not enough to make them measurable. So I don't know, in case it matters, I specify that I am interested in answers in ZFC :) If it might be useful, I can explain why I was asking this question: I wanted to be sure that functions were almost always non-measurable. So I decided to measure the set of functions $\mathbb R\to \mathbb{R/Z}$ for the Haar measure ( $\mathbb{(R/Z)^R}$ is a compact group). Assuming this set is measurable, I know thanks to a Facebook commenter (Dani Spivak) that it must have measure zero, which is intuitively nice but not enough. So, if the answer is ""no"" or ""it is undecidable"", I am also interested in the weaker question: Is the set of measurable functions $\mathbb R\to\mathbb{R/Z}$ a subset of some measurable subset of $\mathbb{(R/Z)^R}$ that has measure zero?","Let be the set of measurable functions in . Now, has the borelian sigma-algebra associated with its product topology, which allows us to ask the following question : Is measurable? On the positive side, I have two remarks: is sequentially closed (a pointwise limit of measurable functions is measurable) but alas it is not closed; also, in some models of ZF, is so is obviously measurable. On the negative side, I feel like a borelian subset of will only give constraints on the value of functions at countably many points, which is probably not enough to make them measurable. So I don't know, in case it matters, I specify that I am interested in answers in ZFC :) If it might be useful, I can explain why I was asking this question: I wanted to be sure that functions were almost always non-measurable. So I decided to measure the set of functions for the Haar measure ( is a compact group). Assuming this set is measurable, I know thanks to a Facebook commenter (Dani Spivak) that it must have measure zero, which is intuitively nice but not enough. So, if the answer is ""no"" or ""it is undecidable"", I am also interested in the weaker question: Is the set of measurable functions a subset of some measurable subset of that has measure zero?",M \mathbb{R^R} \mathbb{R^R} M M M \mathbb{R^R} \mathbb{R^R} \mathbb R\to \mathbb{R/Z} \mathbb{(R/Z)^R} \mathbb R\to\mathbb{R/Z} \mathbb{(R/Z)^R},"['probability', 'measure-theory', 'measurable-functions', 'haar-measure']"
13,Sum of identically distributed but not independent Bernoulli's is non-uniform,Sum of identically distributed but not independent Bernoulli's is non-uniform,,"Let $X_1,X_2,\dots$ denote a sequence of identically distributed, exchangeable, but not independent, Bernoulli $(p)$ random variables. If there exists $n>0$ such that $$ \sum_{i=1}^{n}X_i $$ is not uniformly distributed on $\{0,1,\dots,n\}$ , how can we show that this implies $$ \sum_{i=1}^{n}X_i + X_{n+1} $$ is not uniformly distributed on $\{0,1,\dots,n+1\}$ ? If $p \ne 1/2$ then the claim follows by expectations, so we can consider $p=1/2$ .","Let denote a sequence of identically distributed, exchangeable, but not independent, Bernoulli random variables. If there exists such that is not uniformly distributed on , how can we show that this implies is not uniformly distributed on ? If then the claim follows by expectations, so we can consider .","X_1,X_2,\dots (p) n>0 
\sum_{i=1}^{n}X_i
 \{0,1,\dots,n\} 
\sum_{i=1}^{n}X_i + X_{n+1}
 \{0,1,\dots,n+1\} p \ne 1/2 p=1/2","['probability', 'sequences-and-series', 'probability-theory', 'random-variables']"
14,"Is the probability that half the sets are half red, more than half?","Is the probability that half the sets are half red, more than half?",,"There are $2n$ sets, each of which contains an even number of integers. Each integer is colored red with probability $1\over2$, independently of the others. Say that a set is good if at least half its elements are red. Say that a coloring is good if at least $n$ out of the $2n$ sets are good What is the probability $p$ that the random coloring is good? It is clear that $p\geq {1\over2}$, since for every coloring in which $m$ sets are not good, in the opposite coloring at least $m$ sets are good. Therefore, for every not-good coloring, the opposite coloring is good. Is it always true that $p>{1\over2}$ strictly?","There are $2n$ sets, each of which contains an even number of integers. Each integer is colored red with probability $1\over2$, independently of the others. Say that a set is good if at least half its elements are red. Say that a coloring is good if at least $n$ out of the $2n$ sets are good What is the probability $p$ that the random coloring is good? It is clear that $p\geq {1\over2}$, since for every coloring in which $m$ sets are not good, in the opposite coloring at least $m$ sets are good. Therefore, for every not-good coloring, the opposite coloring is good. Is it always true that $p>{1\over2}$ strictly?",,"['probability', 'combinatorics']"
15,Why not defining random variables as equivalence classes?,Why not defining random variables as equivalence classes?,,"The usual definition of a random variable (or random element) is that of a measurable function $X : (\Omega, \mathcal{F}, P) \rightarrow (\Omega', \mathcal{F}')$. Now I am not aware of any property/theorem that depends on the specific values of $X$ for every $\omega \in \Omega$. In particular any other $P$-almost surely equal random variable $X'$ is generally considered as equivalent to $X$ for all practical purposes. So is there a good reason not to define random variables as equivalent classes rather than laboriously precising each time that such or such statement is true almost surely, that such or such sequence converges almost surely, that such or such object is unique almost surely, etc ? As a comparison defining $L^p$ spaces as spaces of equivalent classes of almost everywhere equal functions helps a lot in simplifying the phrasing of the theory. So are there some interesting/complex cases where we would really need to keep the distinction between almost surely equal random variables? Edit In agreement with @Pedro Tamaroff's comment I'm removing the last addendum to this question and opening a new one .","The usual definition of a random variable (or random element) is that of a measurable function $X : (\Omega, \mathcal{F}, P) \rightarrow (\Omega', \mathcal{F}')$. Now I am not aware of any property/theorem that depends on the specific values of $X$ for every $\omega \in \Omega$. In particular any other $P$-almost surely equal random variable $X'$ is generally considered as equivalent to $X$ for all practical purposes. So is there a good reason not to define random variables as equivalent classes rather than laboriously precising each time that such or such statement is true almost surely, that such or such sequence converges almost surely, that such or such object is unique almost surely, etc ? As a comparison defining $L^p$ spaces as spaces of equivalent classes of almost everywhere equal functions helps a lot in simplifying the phrasing of the theory. So are there some interesting/complex cases where we would really need to keep the distinction between almost surely equal random variables? Edit In agreement with @Pedro Tamaroff's comment I'm removing the last addendum to this question and opening a new one .",,"['probability', 'measure-theory', 'random-variables', 'definition']"
16,equality of two Borel measures,equality of two Borel measures,,"Assume we have a measurable space $(X, \mathscr{B})$, where $X$ is a separable metric space and $\mathscr{B}$ is the Borel sigma algebra. Then, since $X$ is separable, then, $\mathscr{B}$ equals to the sigma algebra generated by open balls. The question: assume that two probability measures on $\mathscr{B}$ are such that they agree on every open ball (just ball!) of $X$. Is it true that they are equal?","Assume we have a measurable space $(X, \mathscr{B})$, where $X$ is a separable metric space and $\mathscr{B}$ is the Borel sigma algebra. Then, since $X$ is separable, then, $\mathscr{B}$ equals to the sigma algebra generated by open balls. The question: assume that two probability measures on $\mathscr{B}$ are such that they agree on every open ball (just ball!) of $X$. Is it true that they are equal?",,"['probability', 'functional-analysis', 'probability-theory', 'measure-theory', 'statistics']"
17,Conditioning a random variable $X$ by a function of $X$: the continuous case,Conditioning a random variable  by a function of : the continuous case,X X,"I have a seemingly basic question, but surprisingly my web search didn't give any satisfying answers. Consider some random variable $X$ of support $(a,b)$ with continuous density $f$. Let $$ \gamma:(a,b)\rightarrow (c,d) $$ be some non-injective differentiable function. This certainly induces some random variable $Y=\gamma(X)$ with density $g$ on $(c,d)$. Assume for simplicity that the pre-image $\gamma^{-1}(y)$ is finite for all $y\in\gamma(X)$. I am interested in  $P(X=x\mid Y=\gamma(x))$. So, if the distributions were discrete, we would just have $$P(X=x\mid Y=\gamma(x))=\frac{P(X=x\text{ and }Y=\gamma(x))}{P(Y=\gamma(x))}=\frac{P(X=x)}{\sum\limits_{x_i\in\gamma^{-1}(y)}P(X=x_i)}$$ I am convinced that the solution in the continuous case should be $$P(X=x\mid Y=\gamma(x))=\frac{\gamma'(x)f(x)}{\sum\limits_{x_i\in\gamma^{-1}(y)}\gamma'(x_i)f(x_i)}$$ Is this true? What is the best way to prove it? Are there any hidden measure-theoretic traps? Are there any references for that kind of calculation rules?","I have a seemingly basic question, but surprisingly my web search didn't give any satisfying answers. Consider some random variable $X$ of support $(a,b)$ with continuous density $f$. Let $$ \gamma:(a,b)\rightarrow (c,d) $$ be some non-injective differentiable function. This certainly induces some random variable $Y=\gamma(X)$ with density $g$ on $(c,d)$. Assume for simplicity that the pre-image $\gamma^{-1}(y)$ is finite for all $y\in\gamma(X)$. I am interested in  $P(X=x\mid Y=\gamma(x))$. So, if the distributions were discrete, we would just have $$P(X=x\mid Y=\gamma(x))=\frac{P(X=x\text{ and }Y=\gamma(x))}{P(Y=\gamma(x))}=\frac{P(X=x)}{\sum\limits_{x_i\in\gamma^{-1}(y)}P(X=x_i)}$$ I am convinced that the solution in the continuous case should be $$P(X=x\mid Y=\gamma(x))=\frac{\gamma'(x)f(x)}{\sum\limits_{x_i\in\gamma^{-1}(y)}\gamma'(x_i)f(x_i)}$$ Is this true? What is the best way to prove it? Are there any hidden measure-theoretic traps? Are there any references for that kind of calculation rules?",,"['probability', 'probability-theory']"
18,Birthday line to get ticket in a unique setup,Birthday line to get ticket in a unique setup,,"At a movie theater, the whimsical manager announces that a free ticket will be given to the first person in line whose birthday is the same as someone in line who has already bought a ticket.  You have the option of choosing any position in the line. Assuming that you don't know anyone else's birthday, and that birthdays are uniformly distributed throughout the year (365 days year), what position in line gives you the best chance of getting free ticket?","At a movie theater, the whimsical manager announces that a free ticket will be given to the first person in line whose birthday is the same as someone in line who has already bought a ticket.  You have the option of choosing any position in the line. Assuming that you don't know anyone else's birthday, and that birthdays are uniformly distributed throughout the year (365 days year), what position in line gives you the best chance of getting free ticket?",,"['probability', 'probability-distributions']"
19,Probability that one part of a randomly cut equilateral triangle covers the other,Probability that one part of a randomly cut equilateral triangle covers the other,,"If you make a straight cut through a square, one part can always be made to cover the other. (This is true by symmetry if the cut goes through the centre, and if it doesn't, you can shift it to the centre while taking from one part and giving to the other.) However, if you cut an equilateral triangle, it may or may not be the case that one part can be made to cover the other. In some cases it may depend on whether we're allowed to flip the parts; I'll leave that to you in case one or the other version has a more elegant solution. How can the cuts that allow one part to cover the other best be characterized? What is the probability that a random cut will allow one part to cover the other? Of course we need to specify a distribution for the cuts, and again I'll leave you to choose between two plausible distributions in case one yields a nicer result: Either Jaynes' solution to the Bertrand ""paradox"" (i.e. random straws thrown from afar, with uniformly distributed directions and uniformly distributed coordinates perpendicular to their direction), or a cut defined by two independently uniformly distributed points on two different sides of the triangle. Update : I've posted the case without flipping as a separate question .","If you make a straight cut through a square, one part can always be made to cover the other. (This is true by symmetry if the cut goes through the centre, and if it doesn't, you can shift it to the centre while taking from one part and giving to the other.) However, if you cut an equilateral triangle, it may or may not be the case that one part can be made to cover the other. In some cases it may depend on whether we're allowed to flip the parts; I'll leave that to you in case one or the other version has a more elegant solution. How can the cuts that allow one part to cover the other best be characterized? What is the probability that a random cut will allow one part to cover the other? Of course we need to specify a distribution for the cuts, and again I'll leave you to choose between two plausible distributions in case one yields a nicer result: Either Jaynes' solution to the Bertrand ""paradox"" (i.e. random straws thrown from afar, with uniformly distributed directions and uniformly distributed coordinates perpendicular to their direction), or a cut defined by two independently uniformly distributed points on two different sides of the triangle. Update : I've posted the case without flipping as a separate question .",,"['probability', 'triangles', 'geometric-probability']"
20,Stopping time on an asymmetric random walk,Stopping time on an asymmetric random walk,,"Suppose we have an asymmetric random walk whose step $x_i$ is distributed as $P(\xi_i = 1) = p$ and $P(\xi_i = -1) = 1-p = q$ , where $p >1/2$ . The hitting time, $T_x$ is defined as $\inf{\{n : S_n = x\}}$ where $S_n$ represents the simple walk $S_n = \sum_{i \leq n} \xi_i$ . It can be shown that $$\Bbb E T_1 = (p-q)^{-1}$$ However, how can we deduce from this that $\Bbb ET_b = b(p-q)^{-1}$ for all $b>0$ ? I tried to use Wald's equation, but does not seem to work.","Suppose we have an asymmetric random walk whose step is distributed as and , where . The hitting time, is defined as where represents the simple walk . It can be shown that However, how can we deduce from this that for all ? I tried to use Wald's equation, but does not seem to work.",x_i P(\xi_i = 1) = p P(\xi_i = -1) = 1-p = q p >1/2 T_x \inf{\{n : S_n = x\}} S_n S_n = \sum_{i \leq n} \xi_i \Bbb E T_1 = (p-q)^{-1} \Bbb ET_b = b(p-q)^{-1} b>0,"['probability', 'stochastic-processes', 'martingales', 'random-walk', 'stopping-times']"
21,Proof of the DKW inequality,Proof of the DKW inequality,,"My goal is to prove the following inequality, known as the Dvoretsky-Kiefer-Wolfowitz inequality (1956) : Let $(X_i)_{i \geqslant}$ be iid random variables. Let $\displaystyle F_n(x)= \frac{1}{n}\sum _{i=1}^n 1_{X_i \leqslant x}$ and $F$ the distribution function of $X_1$. Then there exists a constant $C>0$ such that for every $\varepsilon >0$ : $$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  C e^{-2n\varepsilon ^2}$$ I did not find any proof on the web (only the article of DKW of 1956 but it is not understandable to me due to their notations). The only thing I found was the proof that :  $$\mathbb{E} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| \right) \leqslant  \frac{c}{\sqrt{n}}$$ in this paper : https://www.math.ens.fr/enseignement/telecharger_fichier.php?fichier=474 (theorem 3.3) which is named the DKW inequality. I was not able to prove the DKW inquality from this result btu here is my try  : By the Markov inequality and for every function : $$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  \frac{\mathbb{E} \left( f \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)|\right) \right)}{f(\varepsilon)} $$. With $f(x)=e^{tx}$ and using the convexity of $f$ the Jensen inequality gives : $$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  \frac{e^{ctn^{-1/2}}}{e^{t \varepsilon}} $$ But that does not give the correct result. Question. Does anyone can help me with proving the DKW inequality with the estimate  $\mathbb{E} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| \right) \leqslant  \frac{c}{\sqrt{n}}$ for start ? Or maybe just giving me a paper with the proof in modern language. Thank you.","My goal is to prove the following inequality, known as the Dvoretsky-Kiefer-Wolfowitz inequality (1956) : Let $(X_i)_{i \geqslant}$ be iid random variables. Let $\displaystyle F_n(x)= \frac{1}{n}\sum _{i=1}^n 1_{X_i \leqslant x}$ and $F$ the distribution function of $X_1$. Then there exists a constant $C>0$ such that for every $\varepsilon >0$ : $$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  C e^{-2n\varepsilon ^2}$$ I did not find any proof on the web (only the article of DKW of 1956 but it is not understandable to me due to their notations). The only thing I found was the proof that :  $$\mathbb{E} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| \right) \leqslant  \frac{c}{\sqrt{n}}$$ in this paper : https://www.math.ens.fr/enseignement/telecharger_fichier.php?fichier=474 (theorem 3.3) which is named the DKW inequality. I was not able to prove the DKW inquality from this result btu here is my try  : By the Markov inequality and for every function : $$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  \frac{\mathbb{E} \left( f \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)|\right) \right)}{f(\varepsilon)} $$. With $f(x)=e^{tx}$ and using the convexity of $f$ the Jensen inequality gives : $$\mathbb{P} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| > \varepsilon \right) \leqslant  \frac{e^{ctn^{-1/2}}}{e^{t \varepsilon}} $$ But that does not give the correct result. Question. Does anyone can help me with proving the DKW inequality with the estimate  $\mathbb{E} \left( \sup_{x \in \mathbb{R}} |F_n(x)-F(x)| \right) \leqslant  \frac{c}{\sqrt{n}}$ for start ? Or maybe just giving me a paper with the proof in modern language. Thank you.",,"['probability', 'statistics', 'probability-distributions']"
22,Mean of overcooking time,Mean of overcooking time,,"This question came up this week when I had to put my rice in the microwave for a third time. Suppose the perfect cooking time for a meal is given by a random variable $X$ with values in seconds. Now suppose a quick check allows to determine if the food is : Uncooked, Perfectly cooked, Overcooked. What is the estimated overcooking time in seconds if one uses the following technique : Start by cooking for $T$ seconds, then a) Check food state. b) If food if perfectly cooked or overcooked, stop. c) If food is uncooked, double the last $T$ used. An answer could also hint for a better technique or optimize the choice of $T$. EDIT : As suggested bellow, let us assume that $X\sim N(\mu;\sigma^2)$.","This question came up this week when I had to put my rice in the microwave for a third time. Suppose the perfect cooking time for a meal is given by a random variable $X$ with values in seconds. Now suppose a quick check allows to determine if the food is : Uncooked, Perfectly cooked, Overcooked. What is the estimated overcooking time in seconds if one uses the following technique : Start by cooking for $T$ seconds, then a) Check food state. b) If food if perfectly cooked or overcooked, stop. c) If food is uncooked, double the last $T$ used. An answer could also hint for a better technique or optimize the choice of $T$. EDIT : As suggested bellow, let us assume that $X\sim N(\mu;\sigma^2)$.",,"['probability', 'random-variables', 'stopping-times']"
23,What is the Cohomology Tree Probability Distribution?,What is the Cohomology Tree Probability Distribution?,,"As the title says, I'm interested in finding out what is meant by Cohomology Tree Probability Distribution.  I came across this term on group props , and it seems to be a distribution for randomly selecting a group of a given order. At first, it seems like this is a simple Google-able request, but surprisingly, searching for ""Cohomology Tree Probability Distribution"" (in quotes) yields only hits from group props.  Moreover, group props itself doesn't even have a page on it! It only seems to be listed for various $p$-groups, which makes me suspect that it has something to do with nilpotency, but I really have no idea.  Has anyone heard of this?  Does anyone know the definition?  Can someone point me towards a resource to read about this?","As the title says, I'm interested in finding out what is meant by Cohomology Tree Probability Distribution.  I came across this term on group props , and it seems to be a distribution for randomly selecting a group of a given order. At first, it seems like this is a simple Google-able request, but surprisingly, searching for ""Cohomology Tree Probability Distribution"" (in quotes) yields only hits from group props.  Moreover, group props itself doesn't even have a page on it! It only seems to be listed for various $p$-groups, which makes me suspect that it has something to do with nilpotency, but I really have no idea.  Has anyone heard of this?  Does anyone know the definition?  Can someone point me towards a resource to read about this?",,"['probability', 'group-theory', 'finite-groups', 'group-cohomology']"
24,Infinitesimal Generator of Poisson process,Infinitesimal Generator of Poisson process,,I would like to compute the infinitesimal generator of a Poisson process $N$ with intensity $\lambda$. So I can write: $$\mathbb{E}[\ f(N_{t+s})-f(N_s)\ |\ \mathcal{F_t^0} \ ]  = \mathbb{E}[\ f(N_{t+s}-N_s+N_s)-f(N_s)\ |\ \mathcal{F_t^0} \ ]$$ $$= \sum_{k=0}^\infty \frac{e^{-t \lambda}(\lambda t)^k}{k!}\cdot(\ f(N_{t}+k)-f(N_t)\ ) $$ where $\mathcal{F_t^0}$ is the raw filtration generated by $N$ and $f$ is a bounded and measurable function. The result of the series should be: $$\lambda t e^{-\lambda t}[\ f(N_{t}+1)-f(N_t)\ ] +O(t^2)$$ but I do not see how. I tried to manipulate the series as it is done for the computation of the expected value of a Poisson random variable but did not get anywhere.,I would like to compute the infinitesimal generator of a Poisson process $N$ with intensity $\lambda$. So I can write: $$\mathbb{E}[\ f(N_{t+s})-f(N_s)\ |\ \mathcal{F_t^0} \ ]  = \mathbb{E}[\ f(N_{t+s}-N_s+N_s)-f(N_s)\ |\ \mathcal{F_t^0} \ ]$$ $$= \sum_{k=0}^\infty \frac{e^{-t \lambda}(\lambda t)^k}{k!}\cdot(\ f(N_{t}+k)-f(N_t)\ ) $$ where $\mathcal{F_t^0}$ is the raw filtration generated by $N$ and $f$ is a bounded and measurable function. The result of the series should be: $$\lambda t e^{-\lambda t}[\ f(N_{t}+1)-f(N_t)\ ] +O(t^2)$$ but I do not see how. I tried to manipulate the series as it is done for the computation of the expected value of a Poisson random variable but did not get anywhere.,,"['probability', 'stochastic-processes', 'stochastic-calculus', 'poisson-distribution']"
25,Difference between the largest and second largest observations from a sample of iid normal variables,Difference between the largest and second largest observations from a sample of iid normal variables,,"What can we say about the distribution of $s_1 - s_2$, where $s_1$ and $s_2$ are the largest and second largest draws from a sample of $N$ iid normal variables? ""Who's the world's greatest mathematician?"" doesn't seem to be as interesting a question as it was in the days of Gauss and Euler. Might this be because there are more mathaticians in the world today, or in spite of that fact? Imagine there are $N$ mathematicians in the world. Each mathematician's ability $a_i$ is drawn independently from a standard normal distribution. Let $s_1$ be the max of the $a_i$ and $s_2$ be the second largest of the $a_i$. What can we say about the distribution of $s_1 - s_2$?","What can we say about the distribution of $s_1 - s_2$, where $s_1$ and $s_2$ are the largest and second largest draws from a sample of $N$ iid normal variables? ""Who's the world's greatest mathematician?"" doesn't seem to be as interesting a question as it was in the days of Gauss and Euler. Might this be because there are more mathaticians in the world today, or in spite of that fact? Imagine there are $N$ mathematicians in the world. Each mathematician's ability $a_i$ is drawn independently from a standard normal distribution. Let $s_1$ be the max of the $a_i$ and $s_2$ be the second largest of the $a_i$. What can we say about the distribution of $s_1 - s_2$?",,"['probability', 'order-statistics']"
26,deriving cdf of uniform distribution,deriving cdf of uniform distribution,,"I have that the pdf for a uniform distribution is given by $$f(x) = \frac{1}{b-a}$$ if $a \leq x \leq b $ and $0$ otherwise. I am trying to derive the cdf. From definition I have that the cdf is given by $F(x) = \int_{-\infty}^x f(t) \ dt$ So I will split it up to 3 intervals: If $x < a$ we have that $f(x) = 0$ so $F(x) = 0$ here. If $ a \leq x \leq b $ we have that $$F(x) = \int_{a}^x f(t) \ dt = \frac{x-a}{b-a}$$ If $ x > b$ the pdf says that $f(x) = 0$ here, so surely the cdf would be $$F(x) = \int_{-\infty}^\infty 0 \ dt = 0 $$ but however it is equal to $1$. What is wrong with my approach, and how would you usually derive these answers.","I have that the pdf for a uniform distribution is given by $$f(x) = \frac{1}{b-a}$$ if $a \leq x \leq b $ and $0$ otherwise. I am trying to derive the cdf. From definition I have that the cdf is given by $F(x) = \int_{-\infty}^x f(t) \ dt$ So I will split it up to 3 intervals: If $x < a$ we have that $f(x) = 0$ so $F(x) = 0$ here. If $ a \leq x \leq b $ we have that $$F(x) = \int_{a}^x f(t) \ dt = \frac{x-a}{b-a}$$ If $ x > b$ the pdf says that $f(x) = 0$ here, so surely the cdf would be $$F(x) = \int_{-\infty}^\infty 0 \ dt = 0 $$ but however it is equal to $1$. What is wrong with my approach, and how would you usually derive these answers.",,['probability']
27,distribution of the maximum of independent poisson random variables.,distribution of the maximum of independent poisson random variables.,,"Let $X_i$ $i=1,\dots,n$ be independent poisson random variables with $X_i \sim \text{Poisson}(\lambda_i)$  then we define $X = \max_i X_i$ how does $X$ distribute? Is easy to see that $$\mathbb{P}(X \leq k) = \prod_{i=1}^n \sum_{j=1}^k \frac{e^{-\lambda_i}}{j!}\lambda_i^j$$ But i don't know how to find a close formula. Any help will be appreciated.","Let $X_i$ $i=1,\dots,n$ be independent poisson random variables with $X_i \sim \text{Poisson}(\lambda_i)$  then we define $X = \max_i X_i$ how does $X$ distribute? Is easy to see that $$\mathbb{P}(X \leq k) = \prod_{i=1}^n \sum_{j=1}^k \frac{e^{-\lambda_i}}{j!}\lambda_i^j$$ But i don't know how to find a close formula. Any help will be appreciated.",,"['probability', 'probability-theory', 'probability-distributions']"
28,Approximation of minimum among many binomials,Approximation of minimum among many binomials,,"We choose $k$ numbers independently from the binomial distribution $B(n,1/2)$, where we can think of $n$ as large. What is the expectation of the minimum of the $k$ numbers? Is there a good way to approximate? (We can compute the exact probability that all $k$ numbers are below some constant $c$, but that involves a lot of binomial terms.)","We choose $k$ numbers independently from the binomial distribution $B(n,1/2)$, where we can think of $n$ as large. What is the expectation of the minimum of the $k$ numbers? Is there a good way to approximate? (We can compute the exact probability that all $k$ numbers are below some constant $c$, but that involves a lot of binomial terms.)",,"['probability', 'approximation', 'expectation']"
29,Probability of rounding off a fraction to an even number,Probability of rounding off a fraction to an even number,,"In a quiz the following question was asked : """"Let x and y be two random numbers between 0 and 1. What is the probability that $\frac{x}{y}$ rounds to an even number?"""" My friend calculated the answer to be $$\frac{5}{4}-\frac{\pi}{4}$$ which is roughly equal to 46 percent. I don't know whether his answer is definitely correct but could not find any flaws in his reasoning or calculation. So my question arises as follows: Since x/y has values ranging from $0$ to infinity, why isn't the probability of rounding x/y to an even or odd number equal. $\mathbf{EDIT:}$My friend used probability spaces in his answer. He plotted the two numbers x and y on a graph with both x and y varying from $0$ to $1$. This gives us a unit square. Then he calculated the area of the regions of the square which sastisfied the condition that x/y rounds to an even number. This gave him an infinite number of triangles with decreasing area. He applied summation on the areas of the triangles to get the answer.","In a quiz the following question was asked : """"Let x and y be two random numbers between 0 and 1. What is the probability that $\frac{x}{y}$ rounds to an even number?"""" My friend calculated the answer to be $$\frac{5}{4}-\frac{\pi}{4}$$ which is roughly equal to 46 percent. I don't know whether his answer is definitely correct but could not find any flaws in his reasoning or calculation. So my question arises as follows: Since x/y has values ranging from $0$ to infinity, why isn't the probability of rounding x/y to an even or odd number equal. $\mathbf{EDIT:}$My friend used probability spaces in his answer. He plotted the two numbers x and y on a graph with both x and y varying from $0$ to $1$. This gives us a unit square. Then he calculated the area of the regions of the square which sastisfied the condition that x/y rounds to an even number. This gave him an infinite number of triangles with decreasing area. He applied summation on the areas of the triangles to get the answer.",,['probability']
30,Convergence in total variation,Convergence in total variation,,"There are the very basic convergence types in probability theory: almost sure, in $L^p$-norm, in measure and in distribution. Besides that there is the concept of convergence in total variation norm. It is obvious that convergence in TV norm implies convergence in distribution. But is there anything we can say about relations between convergence in total variation norm and convergence a.s.,in $L^p$ or in measure?- I did not get any direct hints by googling this, so maybe there is nothing to say about.","There are the very basic convergence types in probability theory: almost sure, in $L^p$-norm, in measure and in distribution. Besides that there is the concept of convergence in total variation norm. It is obvious that convergence in TV norm implies convergence in distribution. But is there anything we can say about relations between convergence in total variation norm and convergence a.s.,in $L^p$ or in measure?- I did not get any direct hints by googling this, so maybe there is nothing to say about.",,"['probability', 'measure-theory']"
31,Consecutive heads in $N$ coin tosses.,Consecutive heads in  coin tosses.,N,"Suppose we toss a fair coin $n$ times. We want to show that we can find a run of $\log_2 n - O(\log_2 \log_2 n)$ heads with probability at least $1 - 1/n^c$ for any $c \geq 1$. I realize that there are already questions and answers on stack exchange where the length of the run is for arbitrary $k$. However, in this case I have a specific run length and am trying to show that we can find a relatively simple lower bound. Initially, I feel like the ""trick"" is try to find a way to deal with the $O(\log_2 \log_2 n)$ term. In order to try to accomplish this, we can use a union bound argument to show that the probability of $\log_2 n$ consecutive heads is bounded above by 1. The problem with this is it makes it very difficult to deal with the $O(\log_2 \log_2 n)$ term and as a result, I get stuck. This isn't homework, but is a problem I came across awhile back. It has really been bugging me. Any help/hint would be appreciated. :)","Suppose we toss a fair coin $n$ times. We want to show that we can find a run of $\log_2 n - O(\log_2 \log_2 n)$ heads with probability at least $1 - 1/n^c$ for any $c \geq 1$. I realize that there are already questions and answers on stack exchange where the length of the run is for arbitrary $k$. However, in this case I have a specific run length and am trying to show that we can find a relatively simple lower bound. Initially, I feel like the ""trick"" is try to find a way to deal with the $O(\log_2 \log_2 n)$ term. In order to try to accomplish this, we can use a union bound argument to show that the probability of $\log_2 n$ consecutive heads is bounded above by 1. The problem with this is it makes it very difficult to deal with the $O(\log_2 \log_2 n)$ term and as a result, I get stuck. This isn't homework, but is a problem I came across awhile back. It has really been bugging me. Any help/hint would be appreciated. :)",,['probability']
32,How many arrangements of a (generalized) deck of (generalised) cards have pairs in them?,How many arrangements of a (generalized) deck of (generalised) cards have pairs in them?,,"Consider a generalized deck of $n$ cards. That is, $n$ objects (generalized cards) characterized by a pair of discrete indices: $(i,j)$, where $i$ is the rank and $i=1,\dots,R$ and $j$ is the suit and $j=1,\dots,S$. For a regular deck we have $R=13$ (Ace to King) and $S=4$ (Spades to Hearts). In addition we consider a $T$-""tuple"" of cards with $T \leq S$. A $T$-tuple is $T$ (or more) cards of the same rank (same i index) in a row within the shuffled deck. Question: How many arrangements of these cards n have $T$-tuples in them? intuitive: My question originated from the special case of a regular deck and $T=2$ i.e. pairs. How many arrangements of the $52$ cards have no pairs in them? (and from there one can easily calculate the probability of finding no pairs in a shuffled deck) for example a shuffled deck that goes like 8 3 7 4 6 7 5 4 K Q K K ...etc  hits a pair in the last 2 cards","Consider a generalized deck of $n$ cards. That is, $n$ objects (generalized cards) characterized by a pair of discrete indices: $(i,j)$, where $i$ is the rank and $i=1,\dots,R$ and $j$ is the suit and $j=1,\dots,S$. For a regular deck we have $R=13$ (Ace to King) and $S=4$ (Spades to Hearts). In addition we consider a $T$-""tuple"" of cards with $T \leq S$. A $T$-tuple is $T$ (or more) cards of the same rank (same i index) in a row within the shuffled deck. Question: How many arrangements of these cards n have $T$-tuples in them? intuitive: My question originated from the special case of a regular deck and $T=2$ i.e. pairs. How many arrangements of the $52$ cards have no pairs in them? (and from there one can easily calculate the probability of finding no pairs in a shuffled deck) for example a shuffled deck that goes like 8 3 7 4 6 7 5 4 K Q K K ...etc  hits a pair in the last 2 cards",,"['probability', 'combinatorics']"
33,Birthday paradox for non-uniform distributions,Birthday paradox for non-uniform distributions,,"The classic birthday paradox considers all $n$ possible choices to be equally likely (i.e. every day is chosen with probability $1/n$) and once $\Omega(\sqrt{n})$ days are chosen, the probability of $2$ being the same, is a constant. I'm wondering if someone could point me to an analysis that also works for a non-uniform distribution of days?","The classic birthday paradox considers all $n$ possible choices to be equally likely (i.e. every day is chosen with probability $1/n$) and once $\Omega(\sqrt{n})$ days are chosen, the probability of $2$ being the same, is a constant. I'm wondering if someone could point me to an analysis that also works for a non-uniform distribution of days?",,"['probability', 'reference-request', 'birthday']"
34,Distribution of Ratio of Exponential and Gamma random variable,Distribution of Ratio of Exponential and Gamma random variable,,"A recent question ( Are there any (pairs of) simple distributions that give rise to a power law ratio? ) asked about the distribution of the ratio of two random variables, and the answer accepted there was a reference to Wikipedia which (in simplified and restated form) claims that if $X$ is a Gamma random variable with parameters $(n, 1)$ and $Y$ is an exponential random variable with parameter $1$ , then $Y/X$ is a Pareto random variable with parameters $(1, n)$ .  Presumably $X$ and $Y$ need to be independent for this result to hold.  But, Wikipedia's page on Pareto random variables doesn't seem to include a statement as to what $(1, n)$ means, though based on what it does says, a reasonable interpretation is that the Pareto random variable takes on values in $(1,\infty)$ and its complementary CDF decays away as $z^{-n}$ . My question is:  what is the intuitive explanation for the ratio $Y/X$ to have value $1$ or more?  It would seem that all positive values should occur, and indeed the event $\{Y < X\}$ should have large probability since the Gamma random variable has larger mean than the exponential random variable. I did work out the complementary CDF of $Y/X$ and got $(1+z)^{-n}$ for $z > 0$ which is not quite what Wikipedia claims. Added Note:  Thanks to Sasha and Didier Piau for confirming my calculation that for $z > 0$ , $P\{Y/X > z\} = (1+z)^{-n}$ which of course implies that $$P\{Y/X + 1 > z\} = P\{Y/X > z-1\} = (1 + z - 1)^{-n} = z^{-n}~ \text{for}~ z > 1$$ and thus it is $Y/X + 1$ which is a Pareto random variable, not $Y/X$ as claimed by Wikipedia.  This leads to a simple answer to  a question posed by S Huntsman:  Are there any (pairs) of simple distributions that give rise to a power law ratio? If $W$ and $X$ are the $(n+1)$ -th and $n$ -th arrival times in a (homogeneous) Poisson process, then $W/X$ is a Pareto $(1,n)$ random variable: $P\{W/X > a\} = a^{-n}$ for $a > 1$ . I suspect that this result is quite well known in the theory  of Poisson processes but I don't have a reference for it.","A recent question ( Are there any (pairs of) simple distributions that give rise to a power law ratio? ) asked about the distribution of the ratio of two random variables, and the answer accepted there was a reference to Wikipedia which (in simplified and restated form) claims that if is a Gamma random variable with parameters and is an exponential random variable with parameter , then is a Pareto random variable with parameters .  Presumably and need to be independent for this result to hold.  But, Wikipedia's page on Pareto random variables doesn't seem to include a statement as to what means, though based on what it does says, a reasonable interpretation is that the Pareto random variable takes on values in and its complementary CDF decays away as . My question is:  what is the intuitive explanation for the ratio to have value or more?  It would seem that all positive values should occur, and indeed the event should have large probability since the Gamma random variable has larger mean than the exponential random variable. I did work out the complementary CDF of and got for which is not quite what Wikipedia claims. Added Note:  Thanks to Sasha and Didier Piau for confirming my calculation that for , which of course implies that and thus it is which is a Pareto random variable, not as claimed by Wikipedia.  This leads to a simple answer to  a question posed by S Huntsman:  Are there any (pairs) of simple distributions that give rise to a power law ratio? If and are the -th and -th arrival times in a (homogeneous) Poisson process, then is a Pareto random variable: for . I suspect that this result is quite well known in the theory  of Poisson processes but I don't have a reference for it.","X (n, 1) Y 1 Y/X (1, n) X Y (1, n) (1,\infty) z^{-n} Y/X 1 \{Y < X\} Y/X (1+z)^{-n} z > 0 z > 0 P\{Y/X > z\} = (1+z)^{-n} P\{Y/X + 1 > z\} = P\{Y/X > z-1\} = (1 + z - 1)^{-n} = z^{-n}~ \text{for}~ z > 1 Y/X + 1 Y/X W X (n+1) n W/X (1,n) P\{W/X > a\} = a^{-n} a > 1","['probability', 'probability-distributions']"
35,Stochastic assignment problem,Stochastic assignment problem,,"Given an $n \times n$ real matrix $C$, we can try to maximize  $$\Phi(C, \pi) = \frac{1}{n} \sum_{i} C_{i,\pi(i)} $$ over $\pi \in S_n$, the set of all permutations on $n$ objects. What can one say about this problem if the $C_{ij}$ are random variables? Numerical evidence indicates that for normally distributed independent entries $C_{ij} \sim N(0,1)$, the optimal value  $argmax_\pi \Phi$ of the objective function has a mean of about $.67 (\log n)^.82$ and a standard deviation approximately equal to $.84/\sqrt{n \log n}$, if $n \ge 10$ or so. Is this known? Is there a theory that implies these observations and makes them more precise?","Given an $n \times n$ real matrix $C$, we can try to maximize  $$\Phi(C, \pi) = \frac{1}{n} \sum_{i} C_{i,\pi(i)} $$ over $\pi \in S_n$, the set of all permutations on $n$ objects. What can one say about this problem if the $C_{ij}$ are random variables? Numerical evidence indicates that for normally distributed independent entries $C_{ij} \sim N(0,1)$, the optimal value  $argmax_\pi \Phi$ of the objective function has a mean of about $.67 (\log n)^.82$ and a standard deviation approximately equal to $.84/\sqrt{n \log n}$, if $n \ge 10$ or so. Is this known? Is there a theory that implies these observations and makes them more precise?",,"['probability', 'optimization', 'asymptotics']"
36,An occupancy problem,An occupancy problem,,Consider the scheme of random placing balls into $N=1000$ cells. We continue the procedure of placing balls as long as a last cell remains empty. The process terminates when a ball is placed into this cell. At this moment several cells (or a certain cell) contain(s) a maximum number of balls among all cells. What is the expectation of this maximum? As an application of this scheme consider $N$ people who enter a lottery game. Each raffle is equivalent to the random placing of a ball into $N$ cells. We take a look at this process as long as each person has won at least once.,Consider the scheme of random placing balls into $N=1000$ cells. We continue the procedure of placing balls as long as a last cell remains empty. The process terminates when a ball is placed into this cell. At this moment several cells (or a certain cell) contain(s) a maximum number of balls among all cells. What is the expectation of this maximum? As an application of this scheme consider $N$ people who enter a lottery game. Each raffle is equivalent to the random placing of a ball into $N$ cells. We take a look at this process as long as each person has won at least once.,,['probability']
37,Binomial distribution and upper bound,Binomial distribution and upper bound,,"This is from Feller's Introduction to Probability Theory and Its Applications . In the context of Bernoulli trials, we define: $$b(k;n,p) = \binom{n}{k}p^kq^{n-k},$$ $$P\{S_n \ge r\} = \sum_{v=0}^{\infty}b(r+v;n,p).$$ The latter being the probability of having at least $r$ successes. Now, supposing $r \gt np$ and knowing that $$\frac{b(k; n,p)}{b(k-1;n,p)}=\frac{(n-k+1)p}{kq}=1+\frac{(n+1)p-k}{kq},$$ show that $$P\{S_n \ge r\} \le b(r;n,p)\frac{rq}{r-np}.$$ According to Feller, it follows from the obvious fact that the terms of the series decrease faster than the terms of a geometric series with ratio $1-\frac{r-np}{rq}$. However, it's not obvious for me and I don't see how the upper bound follows.","This is from Feller's Introduction to Probability Theory and Its Applications . In the context of Bernoulli trials, we define: $$b(k;n,p) = \binom{n}{k}p^kq^{n-k},$$ $$P\{S_n \ge r\} = \sum_{v=0}^{\infty}b(r+v;n,p).$$ The latter being the probability of having at least $r$ successes. Now, supposing $r \gt np$ and knowing that $$\frac{b(k; n,p)}{b(k-1;n,p)}=\frac{(n-k+1)p}{kq}=1+\frac{(n+1)p-k}{kq},$$ show that $$P\{S_n \ge r\} \le b(r;n,p)\frac{rq}{r-np}.$$ According to Feller, it follows from the obvious fact that the terms of the series decrease faster than the terms of a geometric series with ratio $1-\frac{r-np}{rq}$. However, it's not obvious for me and I don't see how the upper bound follows.",,[]
38,Should I tick a multiple choice question at random or not in an exam with different weight for correct and wrong answer?,Should I tick a multiple choice question at random or not in an exam with different weight for correct and wrong answer?,,"The JEE exam contains only questions with 4 answer choices. If you select right choice then you get 4 marks If you select wrong  you get -1 marks( lose) If you don't select anything you don't get or lose any mark. Given this scenario, is it a better idea to select any choice of every question in which student has no idea of all 4 choices?","The JEE exam contains only questions with 4 answer choices. If you select right choice then you get 4 marks If you select wrong  you get -1 marks( lose) If you don't select anything you don't get or lose any mark. Given this scenario, is it a better idea to select any choice of every question in which student has no idea of all 4 choices?",,"['probability', 'statistics']"
39,Probability of a random set of binary numbers XORing to $0$,Probability of a random set of binary numbers XORing to,0,"Question - Given a randomly generated set of binary numbers, what is the probability that all of them, when XORed with each other, yield $0$ ? Additional information - All of the binary numbers in the set are different from each other. As an example, $\{0001, 0010, 0011\}$ is a valid set, but not $\{0001, 0010, 0010\}$ or $\{0010, 0010, 0010\}$ . All of the binary numbers have equal length $n$ which is some given. For example, one could have a given length of 4, meaning numbers such as $00001$ and $010$ are not allowed. The length of the set $m$ is a given, its members are randomly generated. Each possible valid binary number has an equal likelihood of being generated. Context - For a school math project, I decided to analytically investigate the average percentage of errors an error correction code can correct given a data set and error rate. This question I am asking was a part of said project that I am unable to solve. If necessary, I can provide additional context. I already know how to do this problem if restriction 1 is lifted, but did not really know how to proceed. I visualized the randomly generated data set as being one number stacked on top of another, kind of how we write when adding large numbers on paper by hand, and then taking my answer to be the probability that each column of bits had an even number of $1$ s. Updated context - Looking at the answers already provided and doing some of the math myself, it is clear that using this in my project will take me well over the page count in all of the explanations. I have come up with a simpler path for my investigation, but am leaving this question up here as I am still interested in this problem and I see no reason to stop anyone interested in answering or seeing answers to this question from doing so. 1rst edit - I have assigned $m$ as the length of the set and $n$ as the length of the binary sequences 2nd edit - I have added additional context","Question - Given a randomly generated set of binary numbers, what is the probability that all of them, when XORed with each other, yield ? Additional information - All of the binary numbers in the set are different from each other. As an example, is a valid set, but not or . All of the binary numbers have equal length which is some given. For example, one could have a given length of 4, meaning numbers such as and are not allowed. The length of the set is a given, its members are randomly generated. Each possible valid binary number has an equal likelihood of being generated. Context - For a school math project, I decided to analytically investigate the average percentage of errors an error correction code can correct given a data set and error rate. This question I am asking was a part of said project that I am unable to solve. If necessary, I can provide additional context. I already know how to do this problem if restriction 1 is lifted, but did not really know how to proceed. I visualized the randomly generated data set as being one number stacked on top of another, kind of how we write when adding large numbers on paper by hand, and then taking my answer to be the probability that each column of bits had an even number of s. Updated context - Looking at the answers already provided and doing some of the math myself, it is clear that using this in my project will take me well over the page count in all of the explanations. I have come up with a simpler path for my investigation, but am leaving this question up here as I am still interested in this problem and I see no reason to stop anyone interested in answering or seeing answers to this question from doing so. 1rst edit - I have assigned as the length of the set and as the length of the binary sequences 2nd edit - I have added additional context","0 \{0001, 0010, 0011\} \{0001, 0010, 0010\} \{0010, 0010, 0010\} n 00001 010 m 1 m n","['probability', 'binary']"
40,The distribution for the sum of sequences of independent random variable,The distribution for the sum of sequences of independent random variable,,"$(X_n)_{n \geq 1}$ and $(Y_n )_{n \geq 1}$ are two sequences of independent random variables with a value in $\{ 0,1\}$ . Suppose that the random variables are mutually independent and $\forall n \geq 1, ~ p(X_n=1) = p$ and $ P (Y_n = 1) = q~$ where $p, q  \in (0, 1).$ Define $S_n = \sum_{k=1}^n X_k$ , $T_n = \sum_{k=1}^n X_k Y_k$ and $N = \inf\{n \geq 0, T_{n+1} = 1\}.$ Find the distribution of $S_n,~ T_n$ and $N$ . I don't have an idea how to find the distribution of $T_n$ or $N$ . For $S_n$ : Thanks to the comment of NCh , I modified the answer for $S_n$ as $S_n = X_1+ \dots + X_n$ where each $X_i$ takes the value $0$ with probability $1-p$ and $1$ with probability $p$ . Define the value $1$ as success while $0$ failure, then $ S_n = \sum_{i=1}^n X_i$ represents the number of successes which follows the binomial distribution $\text{Binomial}(n,p)$ . Could you please help and tell me what to do with $T_n$ and $N$","and are two sequences of independent random variables with a value in . Suppose that the random variables are mutually independent and and where Define , and Find the distribution of and . I don't have an idea how to find the distribution of or . For : Thanks to the comment of NCh , I modified the answer for as where each takes the value with probability and with probability . Define the value as success while failure, then represents the number of successes which follows the binomial distribution . Could you please help and tell me what to do with and","(X_n)_{n \geq 1} (Y_n )_{n \geq 1} \{ 0,1\} \forall n \geq 1, ~ p(X_n=1) = p  P (Y_n = 1) = q~ p, q  \in (0, 1). S_n = \sum_{k=1}^n X_k T_n = \sum_{k=1}^n X_k Y_k N = \inf\{n \geq 0, T_{n+1} = 1\}. S_n,~ T_n N T_n N S_n S_n S_n = X_1+ \dots + X_n X_i 0 1-p 1 p 1 0  S_n = \sum_{i=1}^n X_i \text{Binomial}(n,p) T_n N","['probability', 'probability-theory', 'probability-distributions']"
41,Challenging probability problem,Challenging probability problem,,"Hy, I hope everyone is doing fine. Lately I have been studying the topic of probability, I am aiming to improve on it, recently i came across this hard problem. Let $(u_{n})$ a sequence of random independent variables identically distributed following Rademacher distribution. And let $f(x)=\sum_{n \geq 0} u_{n} x^{n}$ . Prove that : $$ f(x)~~\text{almost surely has infinitely many zeros  in}~~ [0,1].$$ I have been stuck on it for weeks now, but I did find out a hint to solve it on a forum by searching about it, Here is the hint:  Construct an increasing sequence $(x_{k})$ such that the event $A_{k}=\{f(x_{0}),...,f(x_{k}) \text{are not zero and have the same sign} \}$ are such that $p(A_{k+1})\leq \frac{6}{7} p(A_{k})$ . I find it difficult to construct by induction such sequence in a way that may permit us to solve the problem. Any proposition is welcome.","Hy, I hope everyone is doing fine. Lately I have been studying the topic of probability, I am aiming to improve on it, recently i came across this hard problem. Let a sequence of random independent variables identically distributed following Rademacher distribution. And let . Prove that : I have been stuck on it for weeks now, but I did find out a hint to solve it on a forum by searching about it, Here is the hint:  Construct an increasing sequence such that the event are such that . I find it difficult to construct by induction such sequence in a way that may permit us to solve the problem. Any proposition is welcome.","(u_{n}) f(x)=\sum_{n \geq 0} u_{n} x^{n}  f(x)~~\text{almost surely has infinitely many zeros  in}~~ [0,1]. (x_{k}) A_{k}=\{f(x_{0}),...,f(x_{k}) \text{are not zero and have the same sign} \} p(A_{k+1})\leq \frac{6}{7} p(A_{k})","['probability', 'sequences-and-series', 'power-series', 'roots']"
42,Finding correlation given variance-covariance matrix,Finding correlation given variance-covariance matrix,,"I've been looking all over the internet and have been having trouble finding good uses of a covariance matrix to find the correlation coefficient. I know that, from a simple $2 \times2$ variance-covariance matrix, the correlation is given by $\mathrm{COR}\left(X,Y\right)=\frac{\mathrm{COV} \left(X,Y\right)}{\sqrt{Var\left(X\right)\cdot V a r\left(Y\right)}}$ . But, if a variance-covariance matrix is a $3 \times 3$ , like in this example: m                s               df m    1.004899e-04   -4.762594e-06     -7.856965e-02 s   -4.762594e-06    7.781352e-05      4.741813e-01 df  -7.856965e-02    4.741813e-01   8278.92601173 Is it possible to compute $\mathrm{COR}\left(X,Y\right)$ ?","I've been looking all over the internet and have been having trouble finding good uses of a covariance matrix to find the correlation coefficient. I know that, from a simple variance-covariance matrix, the correlation is given by . But, if a variance-covariance matrix is a , like in this example: m                s               df m    1.004899e-04   -4.762594e-06     -7.856965e-02 s   -4.762594e-06    7.781352e-05      4.741813e-01 df  -7.856965e-02    4.741813e-01   8278.92601173 Is it possible to compute ?","2 \times2 \mathrm{COR}\left(X,Y\right)=\frac{\mathrm{COV} \left(X,Y\right)}{\sqrt{Var\left(X\right)\cdot V a r\left(Y\right)}} 3 \times 3 \mathrm{COR}\left(X,Y\right)","['probability', 'statistics', 'covariance', 'variance', 'correlation']"
43,Mean of two numbers by infinite sequences,Mean of two numbers by infinite sequences,,"Consider two numbers $a$ and $b$ , and the following sequence alternating between even and odd positions: $$ a+2b+3a+4b+5a+6b\ldots, $$ If we ''normalize'' $$ \frac{a+2b+3a+4b+\ldots}{1+2+3+4+\ldots}, $$ it turns out this ratio approaches the mean value of $a$ and $b$ : $(a+b)/2$ . In general $$ \frac{a+2^n b+3^n a+4^n b+\ldots}{1^n+2^n+3^n+4^n+\ldots}=\frac{a+b}{2} $$ for $n\geq1$ . However if we use exponential functions instead powers: $$ \frac{m^1 a+m^2 b+m^3 a+m^4 b+\ldots}{m^1 +m^2 +m^3 +m^4 +\ldots} $$ for some $m>1$ , this ratio oscillates and does not approach any number. Could someone explain why convergence to the mean is obtained by using sequences of powers, and the ratio diverges for sequences of exponentials?","Consider two numbers and , and the following sequence alternating between even and odd positions: If we ''normalize'' it turns out this ratio approaches the mean value of and : . In general for . However if we use exponential functions instead powers: for some , this ratio oscillates and does not approach any number. Could someone explain why convergence to the mean is obtained by using sequences of powers, and the ratio diverges for sequences of exponentials?","a b 
a+2b+3a+4b+5a+6b\ldots,
 
\frac{a+2b+3a+4b+\ldots}{1+2+3+4+\ldots},
 a b (a+b)/2 
\frac{a+2^n b+3^n a+4^n b+\ldots}{1^n+2^n+3^n+4^n+\ldots}=\frac{a+b}{2}
 n\geq1 
\frac{m^1 a+m^2 b+m^3 a+m^4 b+\ldots}{m^1 +m^2 +m^3 +m^4 +\ldots}
 m>1","['probability', 'sequences-and-series', 'limits', 'limsup-and-liminf']"
44,Characterizing uniform probability on a finite group,Characterizing uniform probability on a finite group,,"The following exercise comes from Diaconis' book Group Representations in Probability and Statistics . Here $G$ is a finite group, and $U$ is the uniform distribution on $G$, i.e., $U(s) = 1/|G|$ for all $s\in G$. Exercise 5. Let $P$ be a probability on $G$. Define $\overline P(s) = P(s^{-1})$. Show that $U = P\ast \overline P$ if and only if $P$ is uniform. A probability $P\colon G\to\Bbb R_{\ge 0}$ is a function satisfying $\sum_{s\in G}P(s) = 1$. Note that if $P$ and $Q$ are probabilities, then by definition, $$ P\ast Q(s) = \sum_{t\in G}P(st^{-1})Q(t). $$ If $P = U$, then it's not hard to show $U = P\ast \overline P$. My question is about the other direction. I have tried using the Fourier inversion formula: $$ P(s) = \sum_id_i\operatorname{Tr}(\rho_i(s^{-1})\hat P(\rho_i)), $$ where the $\rho_i$ are the irreducible representations of $G$ and $d_i$ is the degree of $\rho_i$. By definition, $\hat P(\rho_i) = \sum_{s\in G} P(s)\rho_i(s)$. However, this didn't yield anything besides $P(s) = 1/|G| \cdot P(s)\cdot |G|$. I did manage to show that $\sum_{s\in G}P(s)^2 = 1/|G|$ by looking at the regular representation of $G$, which is certainly a property that the uniform distribution on $G$ has, but I haven't been able to make further progress. Also relevant here is the Plancherel formula : $$ \sum_{s\in G}f(s^{-1})h(s) = \frac{1}{|G|}\sum_id_i\operatorname{Tr}(\hat{f}(\rho_i)\cdot\hat h(\rho_i)), $$ where $f,h$ are any two functions $G\to\Bbb C$ and the sum on the right is over all irreducible representations of $G$. Another relevant equation is $$ \widehat{P\ast Q}(\rho) = \hat P(\rho)\cdot\hat Q(\rho). $$ Any hints or suggestions are welcome in figuring this out.","The following exercise comes from Diaconis' book Group Representations in Probability and Statistics . Here $G$ is a finite group, and $U$ is the uniform distribution on $G$, i.e., $U(s) = 1/|G|$ for all $s\in G$. Exercise 5. Let $P$ be a probability on $G$. Define $\overline P(s) = P(s^{-1})$. Show that $U = P\ast \overline P$ if and only if $P$ is uniform. A probability $P\colon G\to\Bbb R_{\ge 0}$ is a function satisfying $\sum_{s\in G}P(s) = 1$. Note that if $P$ and $Q$ are probabilities, then by definition, $$ P\ast Q(s) = \sum_{t\in G}P(st^{-1})Q(t). $$ If $P = U$, then it's not hard to show $U = P\ast \overline P$. My question is about the other direction. I have tried using the Fourier inversion formula: $$ P(s) = \sum_id_i\operatorname{Tr}(\rho_i(s^{-1})\hat P(\rho_i)), $$ where the $\rho_i$ are the irreducible representations of $G$ and $d_i$ is the degree of $\rho_i$. By definition, $\hat P(\rho_i) = \sum_{s\in G} P(s)\rho_i(s)$. However, this didn't yield anything besides $P(s) = 1/|G| \cdot P(s)\cdot |G|$. I did manage to show that $\sum_{s\in G}P(s)^2 = 1/|G|$ by looking at the regular representation of $G$, which is certainly a property that the uniform distribution on $G$ has, but I haven't been able to make further progress. Also relevant here is the Plancherel formula : $$ \sum_{s\in G}f(s^{-1})h(s) = \frac{1}{|G|}\sum_id_i\operatorname{Tr}(\hat{f}(\rho_i)\cdot\hat h(\rho_i)), $$ where $f,h$ are any two functions $G\to\Bbb C$ and the sum on the right is over all irreducible representations of $G$. Another relevant equation is $$ \widehat{P\ast Q}(\rho) = \hat P(\rho)\cdot\hat Q(\rho). $$ Any hints or suggestions are welcome in figuring this out.",,"['probability', 'fourier-analysis', 'representation-theory']"
45,Probability that a random permutation fixes no elements for large $n$,Probability that a random permutation fixes no elements for large,n,"Here's a problem that's been going around my friend group. I have solved this problem, and am interested in a generalization of it. Here's the original problem: Pick an element of $\sigma\in S_n$ uniformity at random, and let $X(n)$ be the random variable that is the number of fixed points of $\sigma$. Compute $$\lim_{n\to\infty}P(X(n)=0)$$ Here's the extension: Suppose instead of $S_n$ we are interested in a class of subgroups, $\{H_n:n\in I\subseteq\mathbb{N}\}$. We can then ask: what is the probability the limit yields $$\lim_{n\to\infty}\frac{\mu(H_n)}{|H_n|}$$ where $\mu(G)$ is the biggest number such that every element of $G$ fixes $\mu(G)$ or more elements of $[n]$ when viewed as a subset of $S_n$. The notion I'm trying to formalize here is ""the least number of fixed points that is actually achieved"" as for many groups, every element has a fixed point. This seems to be the right generalization of the problem, though other generalizations are welcome. I'm mostly asking this out of curiosity to see what can be proven. Results about transitive groups, doubly-transitive subgroups, $D_{2n}$, or any other reasonably interesting class of groups would be exciting for me. This link seems relevant, but it's not clear to me that this problem can be solved simply by summing Recontre numbers. This MSE post also seems relevant, but not quite enough to solve the problem on its own.","Here's a problem that's been going around my friend group. I have solved this problem, and am interested in a generalization of it. Here's the original problem: Pick an element of $\sigma\in S_n$ uniformity at random, and let $X(n)$ be the random variable that is the number of fixed points of $\sigma$. Compute $$\lim_{n\to\infty}P(X(n)=0)$$ Here's the extension: Suppose instead of $S_n$ we are interested in a class of subgroups, $\{H_n:n\in I\subseteq\mathbb{N}\}$. We can then ask: what is the probability the limit yields $$\lim_{n\to\infty}\frac{\mu(H_n)}{|H_n|}$$ where $\mu(G)$ is the biggest number such that every element of $G$ fixes $\mu(G)$ or more elements of $[n]$ when viewed as a subset of $S_n$. The notion I'm trying to formalize here is ""the least number of fixed points that is actually achieved"" as for many groups, every element has a fixed point. This seems to be the right generalization of the problem, though other generalizations are welcome. I'm mostly asking this out of curiosity to see what can be proven. Results about transitive groups, doubly-transitive subgroups, $D_{2n}$, or any other reasonably interesting class of groups would be exciting for me. This link seems relevant, but it's not clear to me that this problem can be solved simply by summing Recontre numbers. This MSE post also seems relevant, but not quite enough to solve the problem on its own.",,"['probability', 'combinatorics', 'group-theory', 'permutations']"
46,50% probability of seeing all cards,50% probability of seeing all cards,,"I have a deck of $20$ different cards. Each time, a card is pulled randomly, then put back in the deck. We shuffle and proceed to pull another card (thus keeping the randomness of pulls). The question is this: After how many pulls the probability of seeing all cards in the deck is $50$$\%$?","I have a deck of $20$ different cards. Each time, a card is pulled randomly, then put back in the deck. We shuffle and proceed to pull another card (thus keeping the randomness of pulls). The question is this: After how many pulls the probability of seeing all cards in the deck is $50$$\%$?",,"['probability', 'coupon-collector']"
47,Double pendulum probability distribution,Double pendulum probability distribution,,Double Pendulum has a very beautiful stochastic trajectory. Is there any way to calculate the distribution of probability of finding the end of pendulum at each point? Link to formulations .,Double Pendulum has a very beautiful stochastic trajectory. Is there any way to calculate the distribution of probability of finding the end of pendulum at each point? Link to formulations .,,"['probability', 'probability-distributions', 'stochastic-processes', 'dynamical-systems']"
48,Expected number of tosses until 3 heads in a row - via Martingale method,Expected number of tosses until 3 heads in a row - via Martingale method,,"(Quant job interviews - questions and  answers - Question 3.8) For a fair coin, what is the expected number of tosses to get 3 heads in a row The answer is stated as : We gamble in such a way that we make money on heads but such that if we get a T on toss $n$, our position is $-n$.  We therefore gamble one unit on the first toss and on each toss after a $T$.   After one head, we gamble three. This guarantees that if we get a $T$ next then we go to $-n$.   After two heads we are therefore up 4, and so we gamble 7  to get us to $-n$ again. our gambling winnings is a martingale since we are making finite trades in a martingale (any bounded trading strategy in a martingale is a martingale).  After three heads our position is $11 - (n-3)=14-n$. the time taken to get three heads is a stopping time with finite expectation so if we stop at it we still have a martingale (Optional sampling theorem) thus $\mathbb E (14 -n) = 0 $ and we are done. I realise there are a few answers to this already, however i am not sure the explanation above, which uses martingale theory, is entirely clear. The author states that any bounded trading strategy in a martingale is a martingale but what is the underlying martingale here ? Also I don't understand the underlying  motivation for gambling the way described, please could someone put it in more mathematical terms so i can understand the reason for the sizes of the bets ?","(Quant job interviews - questions and  answers - Question 3.8) For a fair coin, what is the expected number of tosses to get 3 heads in a row The answer is stated as : We gamble in such a way that we make money on heads but such that if we get a T on toss $n$, our position is $-n$.  We therefore gamble one unit on the first toss and on each toss after a $T$.   After one head, we gamble three. This guarantees that if we get a $T$ next then we go to $-n$.   After two heads we are therefore up 4, and so we gamble 7  to get us to $-n$ again. our gambling winnings is a martingale since we are making finite trades in a martingale (any bounded trading strategy in a martingale is a martingale).  After three heads our position is $11 - (n-3)=14-n$. the time taken to get three heads is a stopping time with finite expectation so if we stop at it we still have a martingale (Optional sampling theorem) thus $\mathbb E (14 -n) = 0 $ and we are done. I realise there are a few answers to this already, however i am not sure the explanation above, which uses martingale theory, is entirely clear. The author states that any bounded trading strategy in a martingale is a martingale but what is the underlying martingale here ? Also I don't understand the underlying  motivation for gambling the way described, please could someone put it in more mathematical terms so i can understand the reason for the sizes of the bets ?",,"['probability', 'martingales']"
49,A Probabilistic Approach to Stirling's Formula,A Probabilistic Approach to Stirling's Formula,,"I am working on the following problem: Suppose $X_1, X_2,\dots$ are i.i.d Poisson $(1)$ random variables, and let $S_n=X_1+\dots+X_n$ . a)Compute $E\left[\left( \frac{S_n-n}{\sqrt{n}} \right)^-\right]$ exactly, where $x^- = (-x)\lor 0.$ b) Explain why $\left( \frac{S_n-n}{\sqrt{n}} \right)^- \implies N^-,$ where $\implies$ denotes convergence in distribution, and $N\sim N(0,1).$ c) Show that $E\left[\left( \frac{S_n-n}{\sqrt{n}} \right)^-\right]\rightarrow E(N^-)=\frac{1}{\sqrt{2\pi}}$ . d) Conclude that $n! \sim n^n e^{-n}\sqrt{2\pi n}$ So far for part (a) I was able to compute that $E\left[\left( \frac{S_n-n}{\sqrt{n}} \right)^-\right]=\frac{e^{-n}n^{n+1/2}}{n!}$ . For part (b) since $x^-$ is a continuous function and $\frac{S_n-n}{\sqrt{n}}\implies N\sim N(0,1)$ we get that $\left( \frac{S_n-n}{\sqrt{n}} \right)^-\implies N^-$ . Once I prove (c), (d) follows through manipulation of the two expectations. I am stuck on proving (c) and could use some help. By (b) I know that $\left( \frac{S_n-n}{\sqrt{n}} \right)^-\implies N^-$ , if I can show that $\{\left( \frac{S_n-n}{\sqrt{n}} \right)^-\}_n$ is uniformly integrable then I get $E\left[\left( \frac{S_n-n}{\sqrt{n}} \right)^-\right]\rightarrow E(N^-)$ . I could use help showing that $\{\left( \frac{S_n-n}{\sqrt{n}} \right)^-\}_n$ is uniformly integrable. Thanks! UPDATE: So my professor told me the following to help with this problem. If $\{\left|\frac{S_n-n}{n}\right|\}_n$ is uniformly integrable then $\{\left( \frac{S_n-n}{\sqrt{n}} \right)^-\}_n$ is uniformly integrable. Which is true because $\left( \frac{S_n-n}{\sqrt{n}} \right)^-\leq \left|\frac{S_n-n}{n}\right|$ . Then I was told that I should recall that $S_n$ can be written as the sum of $n$ i.i.d random variables. So now I am stuck trying to show that $\{\left|\frac{S_n-n}{n}\right|\}$ is uniformly integrable.","I am working on the following problem: Suppose are i.i.d Poisson random variables, and let . a)Compute exactly, where b) Explain why where denotes convergence in distribution, and c) Show that . d) Conclude that So far for part (a) I was able to compute that . For part (b) since is a continuous function and we get that . Once I prove (c), (d) follows through manipulation of the two expectations. I am stuck on proving (c) and could use some help. By (b) I know that , if I can show that is uniformly integrable then I get . I could use help showing that is uniformly integrable. Thanks! UPDATE: So my professor told me the following to help with this problem. If is uniformly integrable then is uniformly integrable. Which is true because . Then I was told that I should recall that can be written as the sum of i.i.d random variables. So now I am stuck trying to show that is uniformly integrable.","X_1, X_2,\dots (1) S_n=X_1+\dots+X_n E\left[\left( \frac{S_n-n}{\sqrt{n}} \right)^-\right] x^- = (-x)\lor 0. \left( \frac{S_n-n}{\sqrt{n}} \right)^- \implies N^-, \implies N\sim N(0,1). E\left[\left( \frac{S_n-n}{\sqrt{n}} \right)^-\right]\rightarrow E(N^-)=\frac{1}{\sqrt{2\pi}} n! \sim n^n e^{-n}\sqrt{2\pi n} E\left[\left( \frac{S_n-n}{\sqrt{n}} \right)^-\right]=\frac{e^{-n}n^{n+1/2}}{n!} x^- \frac{S_n-n}{\sqrt{n}}\implies N\sim N(0,1) \left( \frac{S_n-n}{\sqrt{n}} \right)^-\implies N^- \left( \frac{S_n-n}{\sqrt{n}} \right)^-\implies N^- \{\left( \frac{S_n-n}{\sqrt{n}} \right)^-\}_n E\left[\left( \frac{S_n-n}{\sqrt{n}} \right)^-\right]\rightarrow E(N^-) \{\left( \frac{S_n-n}{\sqrt{n}} \right)^-\}_n \{\left|\frac{S_n-n}{n}\right|\}_n \{\left( \frac{S_n-n}{\sqrt{n}} \right)^-\}_n \left( \frac{S_n-n}{\sqrt{n}} \right)^-\leq \left|\frac{S_n-n}{n}\right| S_n n \{\left|\frac{S_n-n}{n}\right|\}","['probability', 'probability-theory', 'uniform-integrability']"
50,How Do I Find My Car,How Do I Find My Car,,"I have been discussing this problem with a coworker for a few days now and neither of us have made any headway on it. I would appreciate any help with a possible solution or maybe a suggestion of a book on related subject matter. The problem is as follows: I usually park my car near the doors of a convenience store but I constantly forget where my car is parked. Let's say that my car is parked somewhere on the real axis. Let's also assume that the probability distribution of my cars location is given by a normal distribution centered at zero. Starting at zero, I will walk along the real axis until I reach my car's position or turn around and walk back in the other direction. Given that I am extremely lazy, what is the optimal search strategy that minimizes the expected distance I have to walk?","I have been discussing this problem with a coworker for a few days now and neither of us have made any headway on it. I would appreciate any help with a possible solution or maybe a suggestion of a book on related subject matter. The problem is as follows: I usually park my car near the doors of a convenience store but I constantly forget where my car is parked. Let's say that my car is parked somewhere on the real axis. Let's also assume that the probability distribution of my cars location is given by a normal distribution centered at zero. Starting at zero, I will walk along the real axis until I reach my car's position or turn around and walk back in the other direction. Given that I am extremely lazy, what is the optimal search strategy that minimizes the expected distance I have to walk?",,"['probability', 'statistics', 'probability-distributions', 'recreational-mathematics']"
51,Secret Santa Perfect Loop problem,Secret Santa Perfect Loop problem,,(n) people put their name in a hat. Each person picks a name out of the hat to buy a gift for. If a person picks out themselves they put the name back into the hat. If the last person can only pick themselves then the loop is invalid and either . start again . or step back until a valid loop can be reached. What is the probability that if n is 33 that the chain creates a perfect loop? An example of a perfect loop where n is 4: A gives to B B gives to C C gives to D. D gives to A. An example of a valid but not perfect loop where n is 4: A gives to B B gives to A C gives to D. D gives to C.,(n) people put their name in a hat. Each person picks a name out of the hat to buy a gift for. If a person picks out themselves they put the name back into the hat. If the last person can only pick themselves then the loop is invalid and either . start again . or step back until a valid loop can be reached. What is the probability that if n is 33 that the chain creates a perfect loop? An example of a perfect loop where n is 4: A gives to B B gives to C C gives to D. D gives to A. An example of a valid but not perfect loop where n is 4: A gives to B B gives to A C gives to D. D gives to C.,,"['probability', 'graph-theory', 'recreational-mathematics']"
52,Second pair of matching birthdays,Second pair of matching birthdays,,"The ""birthday problem"" is well-known and well-studied.  There are many versions of it and many questions one might ask.  For example, ""how many people do we need in a room to obtain at least a 50% chance that some pair shares a birthday?""  (Answer: 23) Another is this: ""Given $M$ bins, what is the expected number of balls I must toss uniformly at random into bins before some bin will contain 2 balls?""  (Answer: $\sqrt{M \pi/2} +2/3$) Here is my question: what is the expected number of balls I must toss into $M$ bins to get two  collisions?  More precisely, how many expected balls must I toss to obtain the event ""ball lands in occupied bin"" twice? I need an answer for very large $M$, so solutions including summations are not helpful. Silly Observation: The birthday problem predicts we need about 25 US Presidents for them to share a birthday.  It actually took 28 presidents to happen (Harding and Polk were both born on Nov 2).  We see from the answers below that after about 37 US Presidents we should have a 2nd collision.  However Obama is the 43rd and it still hasn't happened (nor would it have happened if McCain had won or Romney had won; nor will it happen if H. Clinton wins in 2016).","The ""birthday problem"" is well-known and well-studied.  There are many versions of it and many questions one might ask.  For example, ""how many people do we need in a room to obtain at least a 50% chance that some pair shares a birthday?""  (Answer: 23) Another is this: ""Given $M$ bins, what is the expected number of balls I must toss uniformly at random into bins before some bin will contain 2 balls?""  (Answer: $\sqrt{M \pi/2} +2/3$) Here is my question: what is the expected number of balls I must toss into $M$ bins to get two  collisions?  More precisely, how many expected balls must I toss to obtain the event ""ball lands in occupied bin"" twice? I need an answer for very large $M$, so solutions including summations are not helpful. Silly Observation: The birthday problem predicts we need about 25 US Presidents for them to share a birthday.  It actually took 28 presidents to happen (Harding and Polk were both born on Nov 2).  We see from the answers below that after about 37 US Presidents we should have a 2nd collision.  However Obama is the 43rd and it still hasn't happened (nor would it have happened if McCain had won or Romney had won; nor will it happen if H. Clinton wins in 2016).",,"['probability', 'balls-in-bins']"
53,The parking problem riddle,The parking problem riddle,,"Assume a street of 300 meters, that you can park your car alongside the pavement. Assume that there is a big parking problem in the area. Assume that the pavement is continuous, without interruptions, and that you can park alongside all of it. Assume that the length of a car is 3 meters long. Assume, for simplicity, that cars can park without space between them (bumper to bumper). Assume, that when a car comes to the street if chooses an equally random parking space (please try to express this randomness) from the free spaces left. Therefore, it may ""ruin"" parking places for other cars. Please try to determine what is the expectancy of cars the can park alongside the street.","Assume a street of 300 meters, that you can park your car alongside the pavement. Assume that there is a big parking problem in the area. Assume that the pavement is continuous, without interruptions, and that you can park alongside all of it. Assume that the length of a car is 3 meters long. Assume, for simplicity, that cars can park without space between them (bumper to bumper). Assume, that when a car comes to the street if chooses an equally random parking space (please try to express this randomness) from the free spaces left. Therefore, it may ""ruin"" parking places for other cars. Please try to determine what is the expectancy of cars the can park alongside the street.",,"['probability', 'random']"
54,Repeatedly Toss Balls into Bins,Repeatedly Toss Balls into Bins,,"$n$ balls are randomly tossed into $m$ bins, each bin can hold $k$ balls. If a ball is tossed into a full bin (already has $k$ balls in it), it can be tossed repeatedly and randomly into the $m$ bins again until an empty or partly loaded bin is met. The question is that what is the expectation of the toss times for the $n$ balls, and what is the distribution of the number of balls in the $m$ bins ($n \leq mk$). For the first question, a simplified version can also be: when there are already $n$ balls accumulated in the $m$ bins according to the above toss rule, what is the average toss times for another ball tossed into the bins (we could discuss the case in this stable state rather than the build process). I know without the re-toss process, the number of balls in the bins must follow the binomial distribution; however, when the re-toss is added, it turns to be quite different.","$n$ balls are randomly tossed into $m$ bins, each bin can hold $k$ balls. If a ball is tossed into a full bin (already has $k$ balls in it), it can be tossed repeatedly and randomly into the $m$ bins again until an empty or partly loaded bin is met. The question is that what is the expectation of the toss times for the $n$ balls, and what is the distribution of the number of balls in the $m$ bins ($n \leq mk$). For the first question, a simplified version can also be: when there are already $n$ balls accumulated in the $m$ bins according to the above toss rule, what is the average toss times for another ball tossed into the bins (we could discuss the case in this stable state rather than the build process). I know without the re-toss process, the number of balls in the bins must follow the binomial distribution; however, when the re-toss is added, it turns to be quite different.",,"['probability', 'probability-distributions', 'stochastic-processes', 'random', 'balls-in-bins']"
55,Compute probability of a particular ordering of normal random variables,Compute probability of a particular ordering of normal random variables,,"There are $m$ normally distributed, independent random variables $N_1, \ldots, N_m$ with distinct means $\mu_1, \ldots \mu_m$ and standard deviations $\sigma_1, \ldots, \sigma_m$. Then, we get a permutation of the numbers $\{1, \ldots, m\}$. How can we efficiently compute, numerically, the (log) probability of observing the random variables in same ordering as this permutation? An example: we have four independent random variables $N_1, N_2, N_3, N_4$, all with different means and variances. We are given the permutation (3, 1, 2, 4). What's $\Pr(N_3 > N_1 > N_2 > N_4)$? A closed-form solution is not necessary, but computing the solution using an efficient algorithm with good accuracy is. Also, it's probably necessary to compute a log probability due to the fact that when the number of variables becomes large, computing the actual probability will result in a floating-point underflow. Some starting points, perhaps... The most direct way to compute this value, using the example above, is evaluating one of the following integrals, which I believe are equivalent: $$ \int_{-\infty}^\infty \int_{n_4}^\infty \int_{n_2}^\infty \int_{n_1}^\infty p(n_1)p(n_2)p(n_3)p(n_4)\ dn_3 dn_1 dn_2 dn_4 $$ $$ \int_{-\infty}^\infty \int_{-\infty}^{n_3} \int_{-\infty}^{n_1} \int_{-\infty}^{n_2} p(n_1)p(n_2)p(n_3)p(n_4)\ dn_4 dn_2 dn_1 dn_3 $$ Where $p(n_i)$ is the density function of the variable $N_i$. However, when I tried to implement this numerically, it is inefficient, prone to inaccuracy, and runs into underflow errors when the number of variables gets large. If you think you can compute this integral in an acceptable way, please do post your answer! From one of the answers below, we observe that it's possible to compute $\Pr(N_3 > N_1 > N_2 > N_4)$ directly by evaluating a multivariate normal CDF of dimension $(m-1)$, or 3 in this case. However, this is still nontrivial (though there may be libraries for it), and will underflow for many variables. Perhaps we can divide the probability up as follows: $$\Pr(N_3 > N_1 > N_2 > N_4) = $$ $$\Pr(N_3 > N_1 \mid N_1 > N_2, N_2 > N_4 )\Pr(N_1 > N_2 \mid N_2 > N_4 )\Pr(N_2 > N_4)$$ Being able to compute the probabilities of each part directly would make it very easy to compute the log probability simply by adding. We can compute the conditional probabilities separately using the MVN CDF method, which could help if the product might underflow. Another observation: the $m!$ possible probabilities corresponding to the different permutations must sum to 1. Perhaps there is a way to compute the probabilities iteratively or using dynamic programming: i.e.: $(N_2 >  N_3)$, an ordering over a pair, has some fixed probability, which is further divided into three values by the three possible places to insert $N_1$ into the ordering, further divided into the four values by the possible places to insert $N_3$. This is semantically equivalent to the conditional probabilities above but it might be easier to think of it this way. Any math wizards have suggestions on how to solve this problem? I would greatly appreciate any ideas!","There are $m$ normally distributed, independent random variables $N_1, \ldots, N_m$ with distinct means $\mu_1, \ldots \mu_m$ and standard deviations $\sigma_1, \ldots, \sigma_m$. Then, we get a permutation of the numbers $\{1, \ldots, m\}$. How can we efficiently compute, numerically, the (log) probability of observing the random variables in same ordering as this permutation? An example: we have four independent random variables $N_1, N_2, N_3, N_4$, all with different means and variances. We are given the permutation (3, 1, 2, 4). What's $\Pr(N_3 > N_1 > N_2 > N_4)$? A closed-form solution is not necessary, but computing the solution using an efficient algorithm with good accuracy is. Also, it's probably necessary to compute a log probability due to the fact that when the number of variables becomes large, computing the actual probability will result in a floating-point underflow. Some starting points, perhaps... The most direct way to compute this value, using the example above, is evaluating one of the following integrals, which I believe are equivalent: $$ \int_{-\infty}^\infty \int_{n_4}^\infty \int_{n_2}^\infty \int_{n_1}^\infty p(n_1)p(n_2)p(n_3)p(n_4)\ dn_3 dn_1 dn_2 dn_4 $$ $$ \int_{-\infty}^\infty \int_{-\infty}^{n_3} \int_{-\infty}^{n_1} \int_{-\infty}^{n_2} p(n_1)p(n_2)p(n_3)p(n_4)\ dn_4 dn_2 dn_1 dn_3 $$ Where $p(n_i)$ is the density function of the variable $N_i$. However, when I tried to implement this numerically, it is inefficient, prone to inaccuracy, and runs into underflow errors when the number of variables gets large. If you think you can compute this integral in an acceptable way, please do post your answer! From one of the answers below, we observe that it's possible to compute $\Pr(N_3 > N_1 > N_2 > N_4)$ directly by evaluating a multivariate normal CDF of dimension $(m-1)$, or 3 in this case. However, this is still nontrivial (though there may be libraries for it), and will underflow for many variables. Perhaps we can divide the probability up as follows: $$\Pr(N_3 > N_1 > N_2 > N_4) = $$ $$\Pr(N_3 > N_1 \mid N_1 > N_2, N_2 > N_4 )\Pr(N_1 > N_2 \mid N_2 > N_4 )\Pr(N_2 > N_4)$$ Being able to compute the probabilities of each part directly would make it very easy to compute the log probability simply by adding. We can compute the conditional probabilities separately using the MVN CDF method, which could help if the product might underflow. Another observation: the $m!$ possible probabilities corresponding to the different permutations must sum to 1. Perhaps there is a way to compute the probabilities iteratively or using dynamic programming: i.e.: $(N_2 >  N_3)$, an ordering over a pair, has some fixed probability, which is further divided into three values by the three possible places to insert $N_1$ into the ordering, further divided into the four values by the possible places to insert $N_3$. This is semantically equivalent to the conditional probabilities above but it might be easier to think of it this way. Any math wizards have suggestions on how to solve this problem? I would greatly appreciate any ideas!",,"['probability', 'combinatorics', 'integration', 'probability-distributions', 'normal-distribution']"
56,Probability question.,Probability question.,,"Consider a random process where integers are sampled uniformly with replacement from $\{1,\ldots,n\}$.  Let $X$ be a random variable that represents the number of samples until a duplicate is found. So if the samples were $1,6,3,2, 5,1$ then $X=6$. Let $Y$ be a random variable that represents the number of samples before  both the values $1$ and $2$ have been found.  So in our example $Y=4$. How does one find the following. The probability $P(X<Y)$ or in other words $P(Y-X > 0)$. The conditional probability $P(X \geq x \,\mid \, X<Y)$.","Consider a random process where integers are sampled uniformly with replacement from $\{1,\ldots,n\}$.  Let $X$ be a random variable that represents the number of samples until a duplicate is found. So if the samples were $1,6,3,2, 5,1$ then $X=6$. Let $Y$ be a random variable that represents the number of samples before  both the values $1$ and $2$ have been found.  So in our example $Y=4$. How does one find the following. The probability $P(X<Y)$ or in other words $P(Y-X > 0)$. The conditional probability $P(X \geq x \,\mid \, X<Y)$.",,[]
57,Intuition behind independence and conditional probability,Intuition behind independence and conditional probability,,"I have a good intuition that $A$ is independent of $B$ if $P(A \vert B) = P(A)$ , and I see how you can easily derive from this that it must hold that $P(A,B) = P(A)P(B)$ . But the first statement is not normally taken as a definition; instead the second is. What is the intuition, or even derivation behind defining $A$ and $B$ as independent iff $P(A, B) = P(A)(B)$ ? The kind of explanation I am looking for would be one similar to that given by Jaynes for the definition of conditional probability in the first chapter of Probability: The Logic of Science, or even a Kolmogorov axiomatic explanation would help.","I have a good intuition that is independent of if , and I see how you can easily derive from this that it must hold that . But the first statement is not normally taken as a definition; instead the second is. What is the intuition, or even derivation behind defining and as independent iff ? The kind of explanation I am looking for would be one similar to that given by Jaynes for the definition of conditional probability in the first chapter of Probability: The Logic of Science, or even a Kolmogorov axiomatic explanation would help.","A B P(A \vert B) = P(A) P(A,B) = P(A)P(B) A B P(A, B) = P(A)(B)","['probability', 'definition', 'motivation']"
58,Erdős Probabilistic method,Erdős Probabilistic method,,"My question is based on the Erdos probabilistic method. I am trying to read from the paper here . The proof of Theorem 1 contains the statement Since a block sequence is monochromatic with probability $2^{1−k}$, it follows from the linearity of expectation that the expected number of monochromatic k-term quasi-progressions under a random coloring is at most $2N^2(c/2)^k/(k − 1)$. Essentially as I understand the probablistic argument should run as follows: The probability of a particular event $A$ is $2^{1−k}$. We then conclude that the probability of the occuurence of any such event is bounded above by $2^{1−k}\times$ the number of such possible events. The number of possible events is bounded above as per the previous arguments (according to my understanding) in the paper by $N(N-k+1)c^k/(k − 1)$, and forcing $2N(N-k+1)(c/2)^k/(k − 1)$ to be less then $1$ will give us a bound for $N$ within which if $N$ is chosen the desired event is not guaranteed and hence we have a lower bound. What I am unclear is about the following: The reference to the expected number ? Why is $2N(N-k+1)(c/2)^k/(k − 1)$ not used instead of $2N^2(c/2)^k/(k − 1)$ ? If there is some further clarification needed I will be glad to supply it. Thanks.","My question is based on the Erdos probabilistic method. I am trying to read from the paper here . The proof of Theorem 1 contains the statement Since a block sequence is monochromatic with probability $2^{1−k}$, it follows from the linearity of expectation that the expected number of monochromatic k-term quasi-progressions under a random coloring is at most $2N^2(c/2)^k/(k − 1)$. Essentially as I understand the probablistic argument should run as follows: The probability of a particular event $A$ is $2^{1−k}$. We then conclude that the probability of the occuurence of any such event is bounded above by $2^{1−k}\times$ the number of such possible events. The number of possible events is bounded above as per the previous arguments (according to my understanding) in the paper by $N(N-k+1)c^k/(k − 1)$, and forcing $2N(N-k+1)(c/2)^k/(k − 1)$ to be less then $1$ will give us a bound for $N$ within which if $N$ is chosen the desired event is not guaranteed and hence we have a lower bound. What I am unclear is about the following: The reference to the expected number ? Why is $2N(N-k+1)(c/2)^k/(k − 1)$ not used instead of $2N^2(c/2)^k/(k − 1)$ ? If there is some further clarification needed I will be glad to supply it. Thanks.",,['probability']
59,Expected number of cards in the stack?,Expected number of cards in the stack?,,"Suppose we have a deck of cards, ordered $[$$1$$,52$ ] (using e.g. the bridge ordering). Shuffle the cards (uniformly at random). Turn over the top card, it has value $v_0$ . We will turn over cards one by one and place them either on the stack or in the discard. The stack starts off empty. Let $v_t$ be the value of the top card in the stack (or $\infty$ when the stack is empty). Now we begin turning over additional cards. For each card $i$ with value $v_i$ , if $v_0 < v_i < v_t$ then we place card $i$ on the top of the stack, so that now $v_t = v_i$ . Otherwise, we place card $i$ in the discard. After turning over $k$ cards, what is the expected number of cards in the stack?","Suppose we have a deck of cards, ordered ] (using e.g. the bridge ordering). Shuffle the cards (uniformly at random). Turn over the top card, it has value . We will turn over cards one by one and place them either on the stack or in the discard. The stack starts off empty. Let be the value of the top card in the stack (or when the stack is empty). Now we begin turning over additional cards. For each card with value , if then we place card on the top of the stack, so that now . Otherwise, we place card in the discard. After turning over cards, what is the expected number of cards in the stack?","[1,52 v_0 v_t \infty i v_i v_0 < v_i < v_t i v_t = v_i i k","['probability', 'combinatorics', 'expected-value', 'card-games']"
60,Arithmetic error in Feller's Introduction to Probability?,Arithmetic error in Feller's Introduction to Probability?,,"In my copy of An Introduction to Probability by William Feller (3rd ed, v.1), section I.2(b) begins as follows: (b) Random placement of r balls in n cells. The more general case of [counting the number of ways to put] $r$ balls in $n$ cells can be studied in the same manner, except that the number of possible arrangements increases rapidly with $r$ and $n$.  For $r=4$ balls in $n=3$ cells, the sample space contains already 64 points ... This statement seems incorrect to me.  I think there are $3^4 = 81$ ways to put 4 balls in 3 cells; you have to choose one of the three cells for each of the four balls.  Feller's answer of 64 seems to come from $4^3$.  It's clear that one of us has made a very simple mistake. Who's right, me or Feller?  I find it hard to believe the third edition of a universally-respected textbook contains such a simple mistake, on page 10 no less.  Other possible explanations include: (1) My copy, a cheap-o international student edition, is prone to such errors and the domestic printings don't contain this mistake. (2) I'm misunderstanding the problem Feller was examining.","In my copy of An Introduction to Probability by William Feller (3rd ed, v.1), section I.2(b) begins as follows: (b) Random placement of r balls in n cells. The more general case of [counting the number of ways to put] $r$ balls in $n$ cells can be studied in the same manner, except that the number of possible arrangements increases rapidly with $r$ and $n$.  For $r=4$ balls in $n=3$ cells, the sample space contains already 64 points ... This statement seems incorrect to me.  I think there are $3^4 = 81$ ways to put 4 balls in 3 cells; you have to choose one of the three cells for each of the four balls.  Feller's answer of 64 seems to come from $4^3$.  It's clear that one of us has made a very simple mistake. Who's right, me or Feller?  I find it hard to believe the third edition of a universally-respected textbook contains such a simple mistake, on page 10 no less.  Other possible explanations include: (1) My copy, a cheap-o international student edition, is prone to such errors and the domestic printings don't contain this mistake. (2) I'm misunderstanding the problem Feller was examining.",,"['probability', 'combinatorics']"
61,Must every event have a probability?,Must every event have a probability?,,"Is it possible for an event to simply happen for which it is impossible to define any probability? (Note: By ""impossible"" I don't mean just ""impractical"" -- I really mean that the event should not follow any probability distribution.) Somewhat similarly: can a ""random"" number generator exist which does not follow any probability distribution?","Is it possible for an event to simply happen for which it is impossible to define any probability? (Note: By ""impossible"" I don't mean just ""impractical"" -- I really mean that the event should not follow any probability distribution.) Somewhat similarly: can a ""random"" number generator exist which does not follow any probability distribution?",,['probability']
62,Weak*-topology and probability measures,Weak*-topology and probability measures,,"Let $Y$ denote a separable metric space, and $\mathcal{P}(Y)$ the set of probability (understood as countably additive) measures on the Borel $\sigma$-algebra of $Y$. The weak*-topology says that a sequence $\mu_{n}$ (or more generally a net) in $\mathcal{P}(Y)$ converges to $\mu$ when $\int fd\mu_{n}$ converges to $\int fd\mu$ for each bounded continuous mapping $f:Y \to \mathbb{R}$. My question is: It is known that the set $\mathcal{P}(Y)$ is not necessarily closed when endowed with such a topology (see one example here where the limit is not countably additive). Is it possible to say more generally that whenever $Y$ is not finite (or perhaps ""richer"" in some sense) there exists a sequence in $\mathcal{P}(Y)$ weakly* converging to zero? Thanks!","Let $Y$ denote a separable metric space, and $\mathcal{P}(Y)$ the set of probability (understood as countably additive) measures on the Borel $\sigma$-algebra of $Y$. The weak*-topology says that a sequence $\mu_{n}$ (or more generally a net) in $\mathcal{P}(Y)$ converges to $\mu$ when $\int fd\mu_{n}$ converges to $\int fd\mu$ for each bounded continuous mapping $f:Y \to \mathbb{R}$. My question is: It is known that the set $\mathcal{P}(Y)$ is not necessarily closed when endowed with such a topology (see one example here where the limit is not countably additive). Is it possible to say more generally that whenever $Y$ is not finite (or perhaps ""richer"" in some sense) there exists a sequence in $\mathcal{P}(Y)$ weakly* converging to zero? Thanks!",,"['probability', 'general-topology']"
63,Efficient sampling of a mixture model,Efficient sampling of a mixture model,,"I know there is an easy way to sample standard mixture models if the mixture components can be easily sampled. But, I have a slightly different scenario and I'm wondering if there is an analogous method (or any method at all that is nice). I'll first explain the standard scenario so there is no confusion, and then explain how my problem is different. Sorry if some of this is too remedial, I just want my question to be completely clear. A standard mixture model has pdf $$f_X(x) = \sum_i w_i f^i_X(x)$$ where the $w_i$'s are non-negative and sum to one and the $f^i$'s are pdfs. A pretty important mixture model is mixture of Gaussians, where the $f^i$'s are normal distributions with different means and variances, i.e., $$f_X(x) = \sum_i w_i \mathcal{N}(\mu_i, \sigma^2_i; x)$$ I can easily sample this distribution with two samples. I'll assume there is a latent variable that governs which of the components generates the value of the random variable. Thus, I can choose $i$ with probability $w_i$ and then sample $\mathcal{N}(\mu_i, \sigma^2_i; \cdot)$ to generate my sample $\bar{x}$. In my case, I have a slightly different mixture model $$f_X(x) = \sum_i w_i f^i_X(x) - \sum_j w_j f^j_X(x)$$ Basically, some of the weights are negative so the components $w_j f^j$ subtract from the density at any $x$. Assume that $f_X$ is a pdf, so it is non-negative and integrates to one. Of course, there are methods for generating samples from arbitrary distributions, but it seems that computing the cdf for this one may be hard. What is the best way to draw a sequence of samples from this distribution? Thanks in advance for any help you can provide.","I know there is an easy way to sample standard mixture models if the mixture components can be easily sampled. But, I have a slightly different scenario and I'm wondering if there is an analogous method (or any method at all that is nice). I'll first explain the standard scenario so there is no confusion, and then explain how my problem is different. Sorry if some of this is too remedial, I just want my question to be completely clear. A standard mixture model has pdf $$f_X(x) = \sum_i w_i f^i_X(x)$$ where the $w_i$'s are non-negative and sum to one and the $f^i$'s are pdfs. A pretty important mixture model is mixture of Gaussians, where the $f^i$'s are normal distributions with different means and variances, i.e., $$f_X(x) = \sum_i w_i \mathcal{N}(\mu_i, \sigma^2_i; x)$$ I can easily sample this distribution with two samples. I'll assume there is a latent variable that governs which of the components generates the value of the random variable. Thus, I can choose $i$ with probability $w_i$ and then sample $\mathcal{N}(\mu_i, \sigma^2_i; \cdot)$ to generate my sample $\bar{x}$. In my case, I have a slightly different mixture model $$f_X(x) = \sum_i w_i f^i_X(x) - \sum_j w_j f^j_X(x)$$ Basically, some of the weights are negative so the components $w_j f^j$ subtract from the density at any $x$. Assume that $f_X$ is a pdf, so it is non-negative and integrates to one. Of course, there are methods for generating samples from arbitrary distributions, but it seems that computing the cdf for this one may be hard. What is the best way to draw a sequence of samples from this distribution? Thanks in advance for any help you can provide.",,['probability']
64,Question about Brownian motion,Question about Brownian motion,,"Let $\{B(t), t \in \mathbb{R} \}$ be a two sided brownian motion defined as $$ B(t) = \begin{cases} B_1(t),\quad t >0 \\ 0, \quad t = 0 \\ B_2(-t), \quad t < 0 \end{cases} $$ where $B_1$ and $B_2$ are independent standard Brownian motions on $\mathbb{R}^+$. Fix $x_0 > 0$ and let $x_k = B(x_{k-1})$ for $k=1,2,\dots$.  What can we say about $\lim_{k\rightarrow \infty} x_k$? If it converges, then I imagine the limit would have to be to $0$ a.s., since the limit $y$ would satisfy $B(y) = y$ a.s..  But I don't know how to show this sequence converges.  Any ideas? (this isn't homework, just a problem my friend and I thought up)","Let $\{B(t), t \in \mathbb{R} \}$ be a two sided brownian motion defined as $$ B(t) = \begin{cases} B_1(t),\quad t >0 \\ 0, \quad t = 0 \\ B_2(-t), \quad t < 0 \end{cases} $$ where $B_1$ and $B_2$ are independent standard Brownian motions on $\mathbb{R}^+$. Fix $x_0 > 0$ and let $x_k = B(x_{k-1})$ for $k=1,2,\dots$.  What can we say about $\lim_{k\rightarrow \infty} x_k$? If it converges, then I imagine the limit would have to be to $0$ a.s., since the limit $y$ would satisfy $B(y) = y$ a.s..  But I don't know how to show this sequence converges.  Any ideas? (this isn't homework, just a problem my friend and I thought up)",,"['probability', 'stochastic-processes']"
65,$\exists f:\mathbb{R}\to\mathbb{R}$ such that $\frac{f(X_1)}{X_1+X_2}$ is independent of $X_1$?,such that  is independent of ?,\exists f:\mathbb{R}\to\mathbb{R} \frac{f(X_1)}{X_1+X_2} X_1,"Let $X_1, X_2$ be independent real random variables. Does there exist a non-zero measurable function $f:\mathbb{R}\to\mathbb{R}$ such that $$\frac{f(X_1)}{X_1+X_2}\text{ is independent of }X_1?$$ I am especially interested in the case when $X_1, X_2$ are continuous, but we do not assume anything else about them. My ideas are the following: if $\frac{f(X_1)}{X_1+X_2 }$ does not depend on $X_1$ , then $\frac{f(X_1)}{X_1+X_2}=g(X_2)$ . Rewriting this we get $X_1+X_2 = f(X_1)g^{-1}(X_2)$ . But on the left-hand side, we have a sum, and on the right side a product. Hence, that's a contradiction.  However, these steps are not rigorous and I am not really sure if I can make them. Especially, the existence of $g$ probably does not hold.","Let be independent real random variables. Does there exist a non-zero measurable function such that I am especially interested in the case when are continuous, but we do not assume anything else about them. My ideas are the following: if does not depend on , then . Rewriting this we get . But on the left-hand side, we have a sum, and on the right side a product. Hence, that's a contradiction.  However, these steps are not rigorous and I am not really sure if I can make them. Especially, the existence of probably does not hold.","X_1, X_2 f:\mathbb{R}\to\mathbb{R} \frac{f(X_1)}{X_1+X_2}\text{ is independent of }X_1? X_1, X_2 \frac{f(X_1)}{X_1+X_2 } X_1 \frac{f(X_1)}{X_1+X_2}=g(X_2) X_1+X_2 = f(X_1)g^{-1}(X_2) g","['probability', 'probability-theory', 'measure-theory', 'random-variables', 'measurable-functions']"
66,Drawing marbles until you run out of one color,Drawing marbles until you run out of one color,,"You have a bag with marbles and draw without replacement. The marbles have $k$ distinct colors and there are exactly $n$ marbles of each color. All marbles are equally likely to be drawn. You continue drawing until the bag runs out of a color so you have drawn all $n$ marbles of that color. What is the expected number of marbles you need to draw and what is the probability distribution to model this process? You clearly have do draw at least $n$ marbles and at most $k(n-1) +1$ by the pigeon hole principle. This looks similar to the negative hypergeometric distribution but it doesn't quite fit because I want to stop drawing the moment I run out of any color not just one particular color. Simplest example: There are $2$ red and $2$ green marbles in the bag. Without loss of generality let the first marble drawn be red. There is now a $1/3$ probability that the second marble is also red and I stop. If the second marble is green, the third marble will be either red or green and the bag will be out of that color so I stop no matter what. So with probability $2/3$ I will draw $3$ marbles. Hence the expected number of marbles drawn is $2\cdot (1/3) + 3\cdot (2/3)=2.67$ .","You have a bag with marbles and draw without replacement. The marbles have distinct colors and there are exactly marbles of each color. All marbles are equally likely to be drawn. You continue drawing until the bag runs out of a color so you have drawn all marbles of that color. What is the expected number of marbles you need to draw and what is the probability distribution to model this process? You clearly have do draw at least marbles and at most by the pigeon hole principle. This looks similar to the negative hypergeometric distribution but it doesn't quite fit because I want to stop drawing the moment I run out of any color not just one particular color. Simplest example: There are red and green marbles in the bag. Without loss of generality let the first marble drawn be red. There is now a probability that the second marble is also red and I stop. If the second marble is green, the third marble will be either red or green and the bag will be out of that color so I stop no matter what. So with probability I will draw marbles. Hence the expected number of marbles drawn is .",k n n n k(n-1) +1 2 2 1/3 2/3 3 2\cdot (1/3) + 3\cdot (2/3)=2.67,"['probability', 'probability-distributions']"
67,Subgaussian tail bounds for maximum of subgaussian random variables: concentration around the true expectation?,Subgaussian tail bounds for maximum of subgaussian random variables: concentration around the true expectation?,,"As in this question , it is not too hard to show that if $X_1,\dots,X_n$ are $\sigma^2$ -subgaussian (not even necessarily independent) then $\mathbb{E}[\max_{1\leq i\leq n} X_i] \leq \sqrt{2\sigma^2\log n}$ and $$ \mathbb{P}\!\left\{\max_{1\leq i\leq n} X_i \geq \sqrt{2\sigma^2\log n}+ u \right\} \leq e^{-\frac{u^2}{2\sigma^2}} \tag{$\dagger$} $$ for all $u>0$ . Now, in $(\dagger)$ above we have our upper bound on the expected value, not the expected value itself. Both basically coincide in the case of actual Gaussians, but not in general: for subgaussians r'v's, the expected value $\mathbb{E}[\max_{1\leq i\leq n} X_i]$ could be much smaller than that. Question: is it possible to replace $\sqrt{2\sigma^2\log n}$ by $\mathbb{E}[\max_{1\leq i\leq n} X_i]$ in $(\dagger)$ , either with or without an independent assumption for $(X_i)_i$ ? (the proof I had in the linked post does not allow that) if not, what is a counterexample? (for independent r.v's? arbitrary ones?)","As in this question , it is not too hard to show that if are -subgaussian (not even necessarily independent) then and for all . Now, in above we have our upper bound on the expected value, not the expected value itself. Both basically coincide in the case of actual Gaussians, but not in general: for subgaussians r'v's, the expected value could be much smaller than that. Question: is it possible to replace by in , either with or without an independent assumption for ? (the proof I had in the linked post does not allow that) if not, what is a counterexample? (for independent r.v's? arbitrary ones?)","X_1,\dots,X_n \sigma^2 \mathbb{E}[\max_{1\leq i\leq n} X_i] \leq \sqrt{2\sigma^2\log n} 
\mathbb{P}\!\left\{\max_{1\leq i\leq n} X_i \geq \sqrt{2\sigma^2\log n}+ u \right\} \leq e^{-\frac{u^2}{2\sigma^2}} \tag{\dagger}
 u>0 (\dagger) \mathbb{E}[\max_{1\leq i\leq n} X_i] \sqrt{2\sigma^2\log n} \mathbb{E}[\max_{1\leq i\leq n} X_i] (\dagger) (X_i)_i","['probability', 'inequality']"
68,Median Concentration implies mean concentrarion,Median Concentration implies mean concentrarion,,"I want to prove that if X is such that $$P[|X-m_X|\geq t] \leq c_1 e^{-c_2t^2},$$ for $c_1, c_2$ positive constants, $t\geq 0$ , then it holds that $$P[|X-E[X]|\geq t] \leq c_3 e^{-c_4t^2},$$ with $c_3=1+2c_1$ and $c_4=c_2/4$ . There is a proof of reverse direction here .","I want to prove that if X is such that for positive constants, , then it holds that with and . There is a proof of reverse direction here .","P[|X-m_X|\geq t] \leq c_1 e^{-c_2t^2}, c_1, c_2 t\geq 0 P[|X-E[X]|\geq t] \leq c_3 e^{-c_4t^2}, c_3=1+2c_1 c_4=c_2/4","['probability', 'statistics', 'means', 'median', 'concentration-of-measure']"
69,Intuition of Kolmogorov‘s 0-1 Law,Intuition of Kolmogorov‘s 0-1 Law,,Kolmogorov‘s 0-1 Law seems to say something very intuitive: Tail events of independent objects have probability $0$ or $1$ . At least it should be intuitive - but it is not to me. Why exactly are tail events supposed to have this behaviour? What‘s the intuitive argument?,Kolmogorov‘s 0-1 Law seems to say something very intuitive: Tail events of independent objects have probability or . At least it should be intuitive - but it is not to me. Why exactly are tail events supposed to have this behaviour? What‘s the intuitive argument?,0 1,"['probability', 'probability-theory', 'independence']"
70,Prove that every position is equally as likely in this random walk scenario,Prove that every position is equally as likely in this random walk scenario,,"There are two points $A$ and $B$ . You are standing in the middle between them. In each step, go half the way to the point $A$ , or half the way to the point $B$ , each with probability of $0.5$ . Mark the point where you stop. Prove that the ratio of amount of marks on each pair of subintervals of interval $[A, B]$ of the same length converges to $1$ .","There are two points and . You are standing in the middle between them. In each step, go half the way to the point , or half the way to the point , each with probability of . Mark the point where you stop. Prove that the ratio of amount of marks on each pair of subintervals of interval of the same length converges to .","A B A B 0.5 [A, B] 1","['probability', 'random-walk']"
71,Searching for tagged balls under constraints,Searching for tagged balls under constraints,,"(This is a modification of this problem .) You have $k$ white balls and $k$ black balls, and know that exactly one of each color is radioactive.  You can place any number of balls of your choosing in a radiation detector that reveals only whether $0$ , $1$ or $2$ measured balls are radioactive. Specify an algorithm that identifies the two radioactive balls in as few such measurements as possible in the worst case. Some thoughts: The total uncertainty in the initial system, in bits, is $\log_2 k + \log_2 k = 2 \log_2 k = \log_2 k^2$ . (Sparked by a comment by @leonbloy.) The selection is a Bernoulli process and the most information one can obtain is $3/2$ bits.  Thus in principle the total number of needed measurements is bounded by: $$\left\lceil \frac{2\log_2 k}{3/2}\right \rceil.$$ Here is a decision tree for the small case $k=2$ .  We label the balls $b_1, b_2, w_1, w_2$ and first measure $b_1$ with $w_1$ .  (I'm pretty sure that testing one black and one white provides the maximum information.)  The arcs denote the output of the measurement.  In the case of $0$ or $2$ detected radioactive balls, we are done and the red boxed leafs are our answers. If the result is $1$ , we then measure $b_1 w_2$ which can only give a $0$ or $2$ output, and our final conclusions are shown at the bottom leafs. The expected number of measurements is ${\cal E}[m] = \frac{1}{2} \cdot 1 + \frac{1}{2} \cdot 2 = 1.5$ . Of course there are other ways to guarantee an answer in two measurements, for instance one measurement on a single black, then one measurement on a single white.  But that algorithm guarantees you will need two measurements, i.e, ${\cal E}[m] = 2$ .  (Admittedly, both algorithms have the same worst case performance.) The decision tree above gives you an answer half of the time with just a single measurement--it exploits more from the three-way answer than would a two-way answer. (I have a feeling this problem has been solved in the literature, but I couldn't find it on SE nor with a cursory search online.)","(This is a modification of this problem .) You have white balls and black balls, and know that exactly one of each color is radioactive.  You can place any number of balls of your choosing in a radiation detector that reveals only whether , or measured balls are radioactive. Specify an algorithm that identifies the two radioactive balls in as few such measurements as possible in the worst case. Some thoughts: The total uncertainty in the initial system, in bits, is . (Sparked by a comment by @leonbloy.) The selection is a Bernoulli process and the most information one can obtain is bits.  Thus in principle the total number of needed measurements is bounded by: Here is a decision tree for the small case .  We label the balls and first measure with .  (I'm pretty sure that testing one black and one white provides the maximum information.)  The arcs denote the output of the measurement.  In the case of or detected radioactive balls, we are done and the red boxed leafs are our answers. If the result is , we then measure which can only give a or output, and our final conclusions are shown at the bottom leafs. The expected number of measurements is . Of course there are other ways to guarantee an answer in two measurements, for instance one measurement on a single black, then one measurement on a single white.  But that algorithm guarantees you will need two measurements, i.e, .  (Admittedly, both algorithms have the same worst case performance.) The decision tree above gives you an answer half of the time with just a single measurement--it exploits more from the three-way answer than would a two-way answer. (I have a feeling this problem has been solved in the literature, but I couldn't find it on SE nor with a cursory search online.)","k k 0 1 2 \log_2 k + \log_2 k = 2 \log_2 k = \log_2 k^2 3/2 \left\lceil \frac{2\log_2 k}{3/2}\right \rceil. k=2 b_1, b_2, w_1, w_2 b_1 w_1 0 2 1 b_1 w_2 0 2 {\cal E}[m] = \frac{1}{2} \cdot 1 + \frac{1}{2} \cdot 2 = 1.5 {\cal E}[m] = 2","['probability', 'information-theory', 'coding-theory']"
72,Exit poll in elections,Exit poll in elections,,"We want to run an exit poll for the government referendum, by asking the voters in one vote center whether they voted for option A or B.   We have an urn with 5 red, 3 green and 2 blue marbles. Each voter randomly picks one marble from the urn, sees its color and then places it back in the urn. If it is red, he tells the truth (we assume that he must have voted either A or B – there is no other option). If it is green, he replies “B”, regardless of what he has actually voted and if it is blue, he replies “A”, again regardless of what he has actually voted.    At the end of the exit poll, we got 40% A’s. What is the actual percentage of the A’s voters in this vote center? Probabilities is not my strong area of knowledge :( I was told that this is an easy example of Bayes theorem - I went through it but really can't find how to apply it! \begin{align} \mathsf P(R\mid G, B) & = \frac{\mathsf P(R,G,B)}{\mathsf P(G, B)} \end{align} OK of course the probability of R is 0.5, of G 0.333 and for B 0.2.  But I don't know what to do then.","We want to run an exit poll for the government referendum, by asking the voters in one vote center whether they voted for option A or B.   We have an urn with 5 red, 3 green and 2 blue marbles. Each voter randomly picks one marble from the urn, sees its color and then places it back in the urn. If it is red, he tells the truth (we assume that he must have voted either A or B – there is no other option). If it is green, he replies “B”, regardless of what he has actually voted and if it is blue, he replies “A”, again regardless of what he has actually voted.    At the end of the exit poll, we got 40% A’s. What is the actual percentage of the A’s voters in this vote center? Probabilities is not my strong area of knowledge :( I was told that this is an easy example of Bayes theorem - I went through it but really can't find how to apply it! OK of course the probability of R is 0.5, of G 0.333 and for B 0.2.  But I don't know what to do then.","\begin{align}
\mathsf P(R\mid G, B) & = \frac{\mathsf P(R,G,B)}{\mathsf P(G, B)}
\end{align}",['probability']
73,Interpret $\prod_{n=3}^\infty 1- \frac{1}{n\choose 2}$ as a probability,Interpret  as a probability,\prod_{n=3}^\infty 1- \frac{1}{n\choose 2},"Find the infinite product $$\prod_{n=3}^\infty 1- \dfrac{1}{n\choose 2}$$ It is quite simple to expand and cancel alternating terms to obtain $\frac13$ as the answer. However, notice how the expression looks the product of ""not"" probabilities of some event iterated over different sample spaces. All I want is a simple probabilistic proof of this evaluation. One can do this by finding a bijection between this expression and that event. For example, I thought of the situation as having bags having $2,3,4,\dots$ balls respectively. Now we select $2$ balls from each bag one by one, and write the probability of not coming up with a specific pair of balls from each bag. This is exactly equal to the given expression. Update : Check @Ian's answer for such a bijection. Now the problem remains to connect it to 1/3.","Find the infinite product It is quite simple to expand and cancel alternating terms to obtain as the answer. However, notice how the expression looks the product of ""not"" probabilities of some event iterated over different sample spaces. All I want is a simple probabilistic proof of this evaluation. One can do this by finding a bijection between this expression and that event. For example, I thought of the situation as having bags having balls respectively. Now we select balls from each bag one by one, and write the probability of not coming up with a specific pair of balls from each bag. This is exactly equal to the given expression. Update : Check @Ian's answer for such a bijection. Now the problem remains to connect it to 1/3.","\prod_{n=3}^\infty 1- \dfrac{1}{n\choose 2} \frac13 2,3,4,\dots 2","['probability', 'combinatorics', 'infinite-product', 'combinatorial-proofs']"
74,Probability of finding a random mass,Probability of finding a random mass,,"Suppose we have a list of distinctive elements:  $$X_0=\{x_1,x_2,x_3,\cdots,x_n\}$$ Each element has mass 1. Suppose we take two elements at random and make a new element with appropriate mass. For example we take $x_1$ and $x_n$ and we make a new elements $(x_{n+1})$ of mass two, we put the new element back in the list so,  $$X_1=\{x_1,x_2,x_3,\cdots,x_n,x_{n+1}\}$$ Now if we repeat this procedure $t$ times we will have  $$X_t=\{x_1,x_2,x_3,\cdots,x_n,x_{n+1},x_{n+2},x_{n+3},\cdots,x_{n+t}\}$$ Surely as the process of taking two elements and making a new one is random the masses also will be distributed randomly. Now I was wondering can anyone use probability theory and compute the mass of particle $x_i$ at a given time?","Suppose we have a list of distinctive elements:  $$X_0=\{x_1,x_2,x_3,\cdots,x_n\}$$ Each element has mass 1. Suppose we take two elements at random and make a new element with appropriate mass. For example we take $x_1$ and $x_n$ and we make a new elements $(x_{n+1})$ of mass two, we put the new element back in the list so,  $$X_1=\{x_1,x_2,x_3,\cdots,x_n,x_{n+1}\}$$ Now if we repeat this procedure $t$ times we will have  $$X_t=\{x_1,x_2,x_3,\cdots,x_n,x_{n+1},x_{n+2},x_{n+3},\cdots,x_{n+t}\}$$ Surely as the process of taking two elements and making a new one is random the masses also will be distributed randomly. Now I was wondering can anyone use probability theory and compute the mass of particle $x_i$ at a given time?",,"['probability', 'sequences-and-series', 'probability-theory', 'random-walk']"
75,Birthday problem without electronic aids in a nuclear winter,Birthday problem without electronic aids in a nuclear winter,,"The Birthday Problem is well known, with many related questions and answers on this site. Most solutions somewhere make use of a statement equivalent to: $\frac{365!}{342!365^{23}} < \frac 1 2$. The correctness of this statement is usually demonstrated by asserting (by use of a calculator, other electronic means, or log tables) that the left hand side is approximately 0.492703. My question asks: ""What would be the most efficient way of demonstrating the truth of the above statement using only pen and paper?""  Assume that all computers and tables of logarithms have been destroyed in a nuclear holocaust. Clearly it would be possible (but painful) to do this following long-division in long-hand: $$\frac{365\cdot 364 \cdot 363 \cdot \dots \cdot 343 } {365\cdot 365 \cdot 365 \cdot \dots \cdot 365}$$ but there must be better ways. My first thought was to prove something simpler from which the result still follows.  For example, one can show easily with pen and paper that $$\frac{365!}{342!365^{23}} = \prod_{k=0}^{22}\left(1-\frac k {365}\right)<\prod_{k=0}^{22}  e^{-\frac k {365}}= \exp\left({-\frac {253}{365}}\right).$$  It would therefore be sufficient to demonstrate that $\exp\left({-\frac {253}{365}}\right) < \frac 1 2$ (which is a true statement since $\exp\left({-\frac {253}{365}}\right) \approx 0.4999982478$). Equivalently it would be sufficient to show that $\frac{253}{365}>\ln 2$.  But these may not be the best ways of proceeding, and I have not managed to bring them to a satisfactory pen-and-paper conclusion.","The Birthday Problem is well known, with many related questions and answers on this site. Most solutions somewhere make use of a statement equivalent to: $\frac{365!}{342!365^{23}} < \frac 1 2$. The correctness of this statement is usually demonstrated by asserting (by use of a calculator, other electronic means, or log tables) that the left hand side is approximately 0.492703. My question asks: ""What would be the most efficient way of demonstrating the truth of the above statement using only pen and paper?""  Assume that all computers and tables of logarithms have been destroyed in a nuclear holocaust. Clearly it would be possible (but painful) to do this following long-division in long-hand: $$\frac{365\cdot 364 \cdot 363 \cdot \dots \cdot 343 } {365\cdot 365 \cdot 365 \cdot \dots \cdot 365}$$ but there must be better ways. My first thought was to prove something simpler from which the result still follows.  For example, one can show easily with pen and paper that $$\frac{365!}{342!365^{23}} = \prod_{k=0}^{22}\left(1-\frac k {365}\right)<\prod_{k=0}^{22}  e^{-\frac k {365}}= \exp\left({-\frac {253}{365}}\right).$$  It would therefore be sufficient to demonstrate that $\exp\left({-\frac {253}{365}}\right) < \frac 1 2$ (which is a true statement since $\exp\left({-\frac {253}{365}}\right) \approx 0.4999982478$). Equivalently it would be sufficient to show that $\frac{253}{365}>\ln 2$.  But these may not be the best ways of proceeding, and I have not managed to bring them to a satisfactory pen-and-paper conclusion.",,"['probability', 'inequality', 'numerical-methods', 'asymptotics', 'taylor-expansion']"
76,Calculating the Fabius function.,Calculating the Fabius function.,,"Yesterday I learned about the strange Fabius function $f$ in this question . Given my interest in neural networks and the fact that this function has a distinct sigmoid shape, I became curious about how to calculate this function. Three formulas are given on the wikipedia page above: First regarding it's Fourier Transform: $$ \mathcal F(f(x))(z)=\hat f (z) = \prod_{m=1}^{\infty} \left(\cos\left(\frac{\pi z}{2^m}\right)\right)^m$$ A probabilistic formula regarding it says that it equals the cumulative distribution function of $$\sum_{n=1}^{\infty}2^{-n}\xi_n, \text{ where } \xi_n = U(0,1)$$ A functional equation is also given, which it fulfils: $$f'(x) = 2f(2x)$$ So now to the question ... given these equations, or what we can derive from them, what would be a practical approach to calculate function values on an equally spaced grid for this function? In other words to estimate $$f(\Delta_t n), \,\, \text{ where }\,\,\cases{ n= \{0,\cdots ,2^{m}-1\}\\ \Delta_t = 2^{-m}}$$ Bonus points for considering all in all computational resources required for the calculations.","Yesterday I learned about the strange Fabius function $f$ in this question . Given my interest in neural networks and the fact that this function has a distinct sigmoid shape, I became curious about how to calculate this function. Three formulas are given on the wikipedia page above: First regarding it's Fourier Transform: $$ \mathcal F(f(x))(z)=\hat f (z) = \prod_{m=1}^{\infty} \left(\cos\left(\frac{\pi z}{2^m}\right)\right)^m$$ A probabilistic formula regarding it says that it equals the cumulative distribution function of $$\sum_{n=1}^{\infty}2^{-n}\xi_n, \text{ where } \xi_n = U(0,1)$$ A functional equation is also given, which it fulfils: $$f'(x) = 2f(2x)$$ So now to the question ... given these equations, or what we can derive from them, what would be a practical approach to calculate function values on an equally spaced grid for this function? In other words to estimate $$f(\Delta_t n), \,\, \text{ where }\,\,\cases{ n= \{0,\cdots ,2^{m}-1\}\\ \Delta_t = 2^{-m}}$$ Bonus points for considering all in all computational resources required for the calculations.",,"['probability', 'functional-analysis', 'analysis', 'soft-question', 'computational-mathematics']"
77,expected error when flipping bits of binary string,expected error when flipping bits of binary string,,"Assume we have a binary string with $n$ bits. Now we flip $k$ (different) bits and get a new binary string. For any Gray code the two binary strings represent integers $x$ and $x'$. What is the expected error $|x-x'|$? Any idea how to calculate this? I'am interested in an analytical answer depending on $n$ and $k$. I'am not interested in approximation or a correct answer for small values by write force. Update: So I thought a bit more about this problem and I think the following is true. Let $M = \{0,\dots , 2^n-1\}$ and $\pi\colon M \rightarrow M$ a bijection. Then $$\sum_{x,x'\in M, d(x,x') = k} |\pi(x) - \pi(x')| = \sum_{x,x'\in M, d(x,x') = k} |x - x'|.$$ where $d(x,x')$ denotes the hamming distance. I haven't proved this, but letting $\pi$ be the above mentioned Gray code, this seems to be numerically correct. Computing the expected error when flipping $k$ bits is not so difficult anymore. I think it should be  $$\frac{k}{n\cdot{n-1 \choose k-1}} \sum_{i=0}^{n-1}2^i {i\choose k-1}.$$","Assume we have a binary string with $n$ bits. Now we flip $k$ (different) bits and get a new binary string. For any Gray code the two binary strings represent integers $x$ and $x'$. What is the expected error $|x-x'|$? Any idea how to calculate this? I'am interested in an analytical answer depending on $n$ and $k$. I'am not interested in approximation or a correct answer for small values by write force. Update: So I thought a bit more about this problem and I think the following is true. Let $M = \{0,\dots , 2^n-1\}$ and $\pi\colon M \rightarrow M$ a bijection. Then $$\sum_{x,x'\in M, d(x,x') = k} |\pi(x) - \pi(x')| = \sum_{x,x'\in M, d(x,x') = k} |x - x'|.$$ where $d(x,x')$ denotes the hamming distance. I haven't proved this, but letting $\pi$ be the above mentioned Gray code, this seems to be numerically correct. Computing the expected error when flipping $k$ bits is not so difficult anymore. I think it should be  $$\frac{k}{n\cdot{n-1 \choose k-1}} \sum_{i=0}^{n-1}2^i {i\choose k-1}.$$",,"['probability', 'combinatorics', 'expectation']"
78,How long does it take for rain drops cover a square?,How long does it take for rain drops cover a square?,,"Consider a square divided into $n \times n$ grid. Each rain drop falls from the sky and covers an $r \times r$ grid chosen uniformly at random within the square. What is the expected number of rain drops needed to cover the whole square? To avoid boundary conditions, we can assume that the square is actually a torus . In other words, the top and the bottom of the square are glued together, while the left side and the right side of the squares are guled together. If $r=1$, then this is the classical coupon collector problem . It also gives an upper bound of $n^2 \log(n^2)$ for this rain drop model. I wonder if this model has already been studied? It seems to be natural extension of coupon collector.","Consider a square divided into $n \times n$ grid. Each rain drop falls from the sky and covers an $r \times r$ grid chosen uniformly at random within the square. What is the expected number of rain drops needed to cover the whole square? To avoid boundary conditions, we can assume that the square is actually a torus . In other words, the top and the bottom of the square are glued together, while the left side and the right side of the squares are guled together. If $r=1$, then this is the classical coupon collector problem . It also gives an upper bound of $n^2 \log(n^2)$ for this rain drop model. I wonder if this model has already been studied? It seems to be natural extension of coupon collector.",,"['probability', 'probability-theory']"
79,Multiple choice exam where no two consecutive answers are the same (2),Multiple choice exam where no two consecutive answers are the same (2),,"Continuing from this question , except I've changed the statement so that no two questions have the same answer. You are given a multiple choice exam. It has twelve questions, and each question has four possible answers labelled (a)-(d).You didn't study for the exam at all, so you might as well just guess the answer to each question. But you do have one important piece of information: the exam was designed so that no two consecutive correct answers have the same label. So if one answer is (c), the next one cannot be (c). What strategy should you adopt to maximize the probability that you get at least half the questions correct, at least one question correct. I'm asking this question because I really have no intuition on how these two questions are that different from the previous (linked) question.","Continuing from this question , except I've changed the statement so that no two questions have the same answer. You are given a multiple choice exam. It has twelve questions, and each question has four possible answers labelled (a)-(d).You didn't study for the exam at all, so you might as well just guess the answer to each question. But you do have one important piece of information: the exam was designed so that no two consecutive correct answers have the same label. So if one answer is (c), the next one cannot be (c). What strategy should you adopt to maximize the probability that you get at least half the questions correct, at least one question correct. I'm asking this question because I really have no intuition on how these two questions are that different from the previous (linked) question.",,"['probability', 'combinatorics']"
80,two integers are chosen at random between $0$ and $10$ what is the probability that they differ by no more than $5$?,two integers are chosen at random between  and  what is the probability that they differ by no more than ?,0 10 5,"I've started studying geometric probability and I am having some difficulty with this version of problem : Two integers are chosen at random between $0$ and $10$ inclusive. What is the   probability that they differ by no more than $5$ ? The integers restriction really makes it harder for me,without this restriction I would  tackle the problem like this(I am not sure it is correct): Given two numbers $x,y$ we want $0\le y-x \le 5$ or $x \le y \le 5+x $ From the last restriction I have to satisfy the following inequalities $y \le 5+x$ and $y \ge x $ where $ 0 \le y,x \le 10$ (look image below) Therefore the area I want is $75$ Thus the probability would be $\cfrac{75}{100} $ Now with the integers restriction I would have where the red filled circles indicate the integers which satisfy the restriction. How do I count them now ?I can't simply count the dots as that would lead me to a probability higher than the previous one,which is impossible (I would get $\cfrac{42}{100}$)..","I've started studying geometric probability and I am having some difficulty with this version of problem : Two integers are chosen at random between $0$ and $10$ inclusive. What is the   probability that they differ by no more than $5$ ? The integers restriction really makes it harder for me,without this restriction I would  tackle the problem like this(I am not sure it is correct): Given two numbers $x,y$ we want $0\le y-x \le 5$ or $x \le y \le 5+x $ From the last restriction I have to satisfy the following inequalities $y \le 5+x$ and $y \ge x $ where $ 0 \le y,x \le 10$ (look image below) Therefore the area I want is $75$ Thus the probability would be $\cfrac{75}{100} $ Now with the integers restriction I would have where the red filled circles indicate the integers which satisfy the restriction. How do I count them now ?I can't simply count the dots as that would lead me to a probability higher than the previous one,which is impossible (I would get $\cfrac{42}{100}$)..",,['probability']
81,Finding an algorithm for the given problem,Finding an algorithm for the given problem,,"Let's presume that we have a PVP fight scene, where 1 or 2 heroes, are fighting 3 monsters. The monsters that the heroes are fighting are the following: Skeleton (2 of this monster) Health: 1 Defense: 0 Attack: 1 Death Knight (1 of this monster) Health: 4 Defense: 1 Attack: 3 Whenever a hero attacks, the defense of the monster is reduced from the damage the hero deals. The heroes are the same, they can use one of two attacks, an attack, that deals 1 damage to every enemy, or an attack, that deals 3 damage to a single enemy. The objective of the heroes are to sustain as few damage as possible from the monsters. If a single hero faces this threat, the optimal move would be, to use it's mass attack, to kill the two Skeletons first with one shot, and then kill the Death Knight in the following two turns, this way sustaining a total damage of: (3)+(3)=6 . (if the single hero tries to kill the Death Knight first, he needs two turns to do so, so he will sustain (3+1+1)+(1+1)=7 damage But if two heroes are present, it would be more wiser for the heroes, to gang up on the Death Knight firstly, with two single attacks(which eliminate him), and then either clear out the skeletons with a single mass attack, or with two simple attacks. This way the total damage sustained would be (1+1)=2 . (if they clear the Skeletons with a single mass attack, and the other hero attacks the Death Knight , they would sustain a total of (3)=6 damage, as they would still need a second turn to kill the Death Knight.) NOTE: the parantheses are the damages sustained in a turn How could I find an algorithm, that would tell my heroes which attack is more cost-worthy for them to use? I could try brute forcing it, but in larger scenarios (ie: 4 heroes vs 9 different monsters) it just too resource intensive to achieve. This would be used in a little script, which makes some calculations for me, which will be used to balance a board game that I am in the progress of making. If this isn't the correct stack site for my question, please point me in the correct direction. Note: I only need an algorithm, which I should use, no programming advice needed for the completion of the script. EDIT 1: Based on this example, I could say that the correct move is always the one, which kills the most monsters in a single case, but this isn't correct, if we increase the Death Knights damage, so the correct move must have a score which is calculated using the monsters attack, and the number of monsters that can be killed in a single turn. Am I right in assuming this?","Let's presume that we have a PVP fight scene, where 1 or 2 heroes, are fighting 3 monsters. The monsters that the heroes are fighting are the following: Skeleton (2 of this monster) Health: 1 Defense: 0 Attack: 1 Death Knight (1 of this monster) Health: 4 Defense: 1 Attack: 3 Whenever a hero attacks, the defense of the monster is reduced from the damage the hero deals. The heroes are the same, they can use one of two attacks, an attack, that deals 1 damage to every enemy, or an attack, that deals 3 damage to a single enemy. The objective of the heroes are to sustain as few damage as possible from the monsters. If a single hero faces this threat, the optimal move would be, to use it's mass attack, to kill the two Skeletons first with one shot, and then kill the Death Knight in the following two turns, this way sustaining a total damage of: (3)+(3)=6 . (if the single hero tries to kill the Death Knight first, he needs two turns to do so, so he will sustain (3+1+1)+(1+1)=7 damage But if two heroes are present, it would be more wiser for the heroes, to gang up on the Death Knight firstly, with two single attacks(which eliminate him), and then either clear out the skeletons with a single mass attack, or with two simple attacks. This way the total damage sustained would be (1+1)=2 . (if they clear the Skeletons with a single mass attack, and the other hero attacks the Death Knight , they would sustain a total of (3)=6 damage, as they would still need a second turn to kill the Death Knight.) NOTE: the parantheses are the damages sustained in a turn How could I find an algorithm, that would tell my heroes which attack is more cost-worthy for them to use? I could try brute forcing it, but in larger scenarios (ie: 4 heroes vs 9 different monsters) it just too resource intensive to achieve. This would be used in a little script, which makes some calculations for me, which will be used to balance a board game that I am in the progress of making. If this isn't the correct stack site for my question, please point me in the correct direction. Note: I only need an algorithm, which I should use, no programming advice needed for the completion of the script. EDIT 1: Based on this example, I could say that the correct move is always the one, which kills the most monsters in a single case, but this isn't correct, if we increase the Death Knights damage, so the correct move must have a score which is calculated using the monsters attack, and the number of monsters that can be killed in a single turn. Am I right in assuming this?",,"['probability', 'algorithms']"
82,Asymptotic Behavior of Ratio of Random Variables,Asymptotic Behavior of Ratio of Random Variables,,"Let $X_n \ge 0$ and $Y_n > 0$ be sequences of random variables. Suppose that for a positive sequence of numbers $\{a_n\}$, $P(Y_n < a_n) \rightarrow 0$ as $n \rightarrow \infty$ and $X_n/a_n \rightarrow 0$ in probability. My question is: can we say that $X_n/Y_n \rightarrow 0$ in some  (probabilistic) sense? If there are further conditions under which this is true, what are they? I know that if $X_n$ and $Y_n$ converged to constants $a$, $b$ in probability, we would have $X_n/Y_n \rightarrow a/b$ in probability. Some things I have tried: Split the ratio in two cases with indicators $1(Y_n \ge a_n)$ and $1(Y_n \le a_n)$. Try to combine Markov with Cauchy-Schwarz to provide an upper bound. Thanks in advance!","Let $X_n \ge 0$ and $Y_n > 0$ be sequences of random variables. Suppose that for a positive sequence of numbers $\{a_n\}$, $P(Y_n < a_n) \rightarrow 0$ as $n \rightarrow \infty$ and $X_n/a_n \rightarrow 0$ in probability. My question is: can we say that $X_n/Y_n \rightarrow 0$ in some  (probabilistic) sense? If there are further conditions under which this is true, what are they? I know that if $X_n$ and $Y_n$ converged to constants $a$, $b$ in probability, we would have $X_n/Y_n \rightarrow a/b$ in probability. Some things I have tried: Split the ratio in two cases with indicators $1(Y_n \ge a_n)$ and $1(Y_n \le a_n)$. Try to combine Markov with Cauchy-Schwarz to provide an upper bound. Thanks in advance!",,['probability']
83,Where can I find the solutions to exercises of Probabilistic Graphical Models?,Where can I find the solutions to exercises of Probabilistic Graphical Models?,,"I am self-learning Probabilistic Graphical Models written by Daphne Koller. And for testing   how well I learned, I did the exercises in the textbook. But I have no solutions to these exercises. Can anybody give me a copy of the solutions?","I am self-learning Probabilistic Graphical Models written by Daphne Koller. And for testing   how well I learned, I did the exercises in the textbook. But I have no solutions to these exercises. Can anybody give me a copy of the solutions?",,"['probability', 'machine-learning', 'probabilistic-method', 'bayesian-network']"
84,Properties of Markov chains,Properties of Markov chains,,"We covered Markov chains in class and after going through the details, I still have a few questions. (I encourage you to give short answers to the question, as this may become very cumbersome otherwise) 1.) There are many theorems like: If $(X_n)$ is an irreducible( with a state space $S$), positive recurrent markov chain, then...(for example there is a unique stationary distribution $\pi>0$). Now, assuming that $(X_n)$ is not irreducible, but contains a positive recurrent class $A \subset S$. Does this mean that we can say that there is a unique stationary distribution $\pi|_A>0$ and $\pi=0$ elsewhere? So my question is: If we want to talk about one positive recurrent class instead of one irreducible chain, does this method of transferring the results ( by restricting the result to the subset $A$) always work? When I thought about it, I considered this to be a trivial conclusion, but most books don't even talk about this simple generalisation, so I wanted to ask this here. 2.) When you want to identify communication classes of a Markov chain on a finite set you can do this by drawing a picture and look whether there is a pathway between two states. But is there also a way of calculating the classes directly from the transition matrix? If my guess in question (1) holds, then there should be a one-one correspondence between eigenvectors $\pi^T = \pi^T P $ with $\pi_A >0$ (and $\pi_{A^C}=0$) and positive recurrent classes $A$. In that case the only question would be how to find the remaining classes. But probably, the remaining transient states are just the states that always have a zero component in every stationary distirbution we get from the eigenvalue problem $P^T \pi = \pi$. 3.) The same as question 2) for the period. Is there a faster method of calculating the period of a state than calculating the powers of the transition matrix? Or at least a fast way to determine whether a state is periodic or aperiodic? 4.) I am struggeling with closed states. My intuition tells me that: Every finite closed class is recurrent and every recurrent class is closed. So for finite chains the terms closed and (positive) recurrent should be $1:1$. Is this true?  It obviously diverges over infinite sets as the randomn walk in $\mathbb{Z}^3$ is transient, but the whole state space is closed. 5.) In case that we regard the continuous case of a homogenous markov chain and $P(X_{n+1} \in A |X_n =x) = \int_A q(x,y) dy$. How do we get $P(X_{n+k} \in A |X_n = x) $? 6.) For a transient states $i,j$ in one class we have: $\sum_{n = 0}^{\infty} p^{(n)}_{ij} < \infty$. For a (positive) recurrent states $i,j$ in one class we have: $\sum_{n = 0}^{\infty} p^{(n)}_{ij} = \infty$. This is in my opinion a consequence of the fact that transience/recurrence is a class property, but I just wanted to be sure about this. Unfortunately, this questions seems to be very unpopular. Any suggestion how I could improve my question is highly appreciated.","We covered Markov chains in class and after going through the details, I still have a few questions. (I encourage you to give short answers to the question, as this may become very cumbersome otherwise) 1.) There are many theorems like: If $(X_n)$ is an irreducible( with a state space $S$), positive recurrent markov chain, then...(for example there is a unique stationary distribution $\pi>0$). Now, assuming that $(X_n)$ is not irreducible, but contains a positive recurrent class $A \subset S$. Does this mean that we can say that there is a unique stationary distribution $\pi|_A>0$ and $\pi=0$ elsewhere? So my question is: If we want to talk about one positive recurrent class instead of one irreducible chain, does this method of transferring the results ( by restricting the result to the subset $A$) always work? When I thought about it, I considered this to be a trivial conclusion, but most books don't even talk about this simple generalisation, so I wanted to ask this here. 2.) When you want to identify communication classes of a Markov chain on a finite set you can do this by drawing a picture and look whether there is a pathway between two states. But is there also a way of calculating the classes directly from the transition matrix? If my guess in question (1) holds, then there should be a one-one correspondence between eigenvectors $\pi^T = \pi^T P $ with $\pi_A >0$ (and $\pi_{A^C}=0$) and positive recurrent classes $A$. In that case the only question would be how to find the remaining classes. But probably, the remaining transient states are just the states that always have a zero component in every stationary distirbution we get from the eigenvalue problem $P^T \pi = \pi$. 3.) The same as question 2) for the period. Is there a faster method of calculating the period of a state than calculating the powers of the transition matrix? Or at least a fast way to determine whether a state is periodic or aperiodic? 4.) I am struggeling with closed states. My intuition tells me that: Every finite closed class is recurrent and every recurrent class is closed. So for finite chains the terms closed and (positive) recurrent should be $1:1$. Is this true?  It obviously diverges over infinite sets as the randomn walk in $\mathbb{Z}^3$ is transient, but the whole state space is closed. 5.) In case that we regard the continuous case of a homogenous markov chain and $P(X_{n+1} \in A |X_n =x) = \int_A q(x,y) dy$. How do we get $P(X_{n+k} \in A |X_n = x) $? 6.) For a transient states $i,j$ in one class we have: $\sum_{n = 0}^{\infty} p^{(n)}_{ij} < \infty$. For a (positive) recurrent states $i,j$ in one class we have: $\sum_{n = 0}^{\infty} p^{(n)}_{ij} = \infty$. This is in my opinion a consequence of the fact that transience/recurrence is a class property, but I just wanted to be sure about this. Unfortunately, this questions seems to be very unpopular. Any suggestion how I could improve my question is highly appreciated.",,"['probability', 'probability-theory']"
85,"Lies, damned lies, and statistics","Lies, damned lies, and statistics",,"A story currently in the U.S. news is that an organization has (in)conveniently had several specific hard disk drives fail within the same short period of time. The question is what is the likelihood that this would happen? I would imagine that it can be determined quantitatively to be very unlikely, and I would like to know if a simple analysis is sufficient to come to that conclusion, or is it necessarily more complicated. We can start with some assumptions, all of which can be challenged. A hard drive fails with an exponential probability density function (pdf) $p(t)= \lambda  e^{- \lambda t}$, where $\lambda$ is the reciprocal of the MTBF (mean time between failures). All hard drives have an MTBF of 500,000 hours and operate under typical conditions . The hard drive failures are independent. (They run on different computers.There is no systematic relationship that would result in a dependency between these failures and any other commonly shared event or condition.) The failures are physical (not systematic, such as software induced) The organization operates 100,000 hard drives like these simultaneously. While investigators argue about who has the better credentials relevant to the question, I believe it's amenable to a straightforward analysis, as follows: An upper bound on $P_{1}(T)$, the probability of a single failure in time T, can be calculated from integrating the pdf on the interval $[0, T]$, where the pdf is maximum. The probability distribution $$P(t) = 1-e^{- \lambda t}$$ can be used to calculate $P(t=T)$. The probability $P_{N}$ of N specific hard drives failing in that time interval is $P_{N}(T)=(P_{1}(T))^N$. The facts in the actual investigation are not totally clear, but it appears that we are talking about 6 specific hard drives failing in a 1 week (168 hours). This leads to $$P_{1}(168)=1-e^{- 168/500,000}=3.36 \times 10^{-4}$$ and $$P_{6}(168)=1.44 \times 10^{-21}$$ This is so incredibly unlikely that I would try modifying my assumptions. First, if the time interval is 13 weeks, then $P_{6}(13*168)=6.85 \times 10^{-15}$. Still incredibly unlikely. Even reducing the MTBF to 10,000 leaves us with $P_{6}(13*168)=5.7 \times 10^{-5}$ or nearly a one in a million chance. One assumption that I didn't use was assumption number 5, that there are 100,000 hard drives within the organization. This is where the lies, damn lies and statistics creep in. But I think it's safe to say that this is irrelevant, given the other assumptions and that we are talking about specific hard drives. Based on this analysis, calculating the probability that N specific hard drives would fail in an interval of time can be easily calculated. Have I made a mistake? Are there other factors that would have a significant effect on the result? If so, how?","A story currently in the U.S. news is that an organization has (in)conveniently had several specific hard disk drives fail within the same short period of time. The question is what is the likelihood that this would happen? I would imagine that it can be determined quantitatively to be very unlikely, and I would like to know if a simple analysis is sufficient to come to that conclusion, or is it necessarily more complicated. We can start with some assumptions, all of which can be challenged. A hard drive fails with an exponential probability density function (pdf) $p(t)= \lambda  e^{- \lambda t}$, where $\lambda$ is the reciprocal of the MTBF (mean time between failures). All hard drives have an MTBF of 500,000 hours and operate under typical conditions . The hard drive failures are independent. (They run on different computers.There is no systematic relationship that would result in a dependency between these failures and any other commonly shared event or condition.) The failures are physical (not systematic, such as software induced) The organization operates 100,000 hard drives like these simultaneously. While investigators argue about who has the better credentials relevant to the question, I believe it's amenable to a straightforward analysis, as follows: An upper bound on $P_{1}(T)$, the probability of a single failure in time T, can be calculated from integrating the pdf on the interval $[0, T]$, where the pdf is maximum. The probability distribution $$P(t) = 1-e^{- \lambda t}$$ can be used to calculate $P(t=T)$. The probability $P_{N}$ of N specific hard drives failing in that time interval is $P_{N}(T)=(P_{1}(T))^N$. The facts in the actual investigation are not totally clear, but it appears that we are talking about 6 specific hard drives failing in a 1 week (168 hours). This leads to $$P_{1}(168)=1-e^{- 168/500,000}=3.36 \times 10^{-4}$$ and $$P_{6}(168)=1.44 \times 10^{-21}$$ This is so incredibly unlikely that I would try modifying my assumptions. First, if the time interval is 13 weeks, then $P_{6}(13*168)=6.85 \times 10^{-15}$. Still incredibly unlikely. Even reducing the MTBF to 10,000 leaves us with $P_{6}(13*168)=5.7 \times 10^{-5}$ or nearly a one in a million chance. One assumption that I didn't use was assumption number 5, that there are 100,000 hard drives within the organization. This is where the lies, damn lies and statistics creep in. But I think it's safe to say that this is irrelevant, given the other assumptions and that we are talking about specific hard drives. Based on this analysis, calculating the probability that N specific hard drives would fail in an interval of time can be easily calculated. Have I made a mistake? Are there other factors that would have a significant effect on the result? If so, how?",,"['probability', 'statistics', 'probability-distributions']"
86,What is the intuition behind the generalized confidence interval?,What is the intuition behind the generalized confidence interval?,,What is the intuition behind the generalized confidence interval? My best description on GCI that it is the way to derive a formula to calcuate the area of the center region in a asymetry distribution where it has the two-sided-equal-tailed regions in which the area of the two-sided-equal-tailed regions are the same in the n dimensional case. A paper on the GCI: http://www.stat.colostate.edu/statresearch/stattechreports/Technical%20Reports/2002/02_10.pdf Also: http://www3.stat.sinica.edu.tw/statistica/oldpdf/a10n420.pdf,What is the intuition behind the generalized confidence interval? My best description on GCI that it is the way to derive a formula to calcuate the area of the center region in a asymetry distribution where it has the two-sided-equal-tailed regions in which the area of the two-sided-equal-tailed regions are the same in the n dimensional case. A paper on the GCI: http://www.stat.colostate.edu/statresearch/stattechreports/Technical%20Reports/2002/02_10.pdf Also: http://www3.stat.sinica.edu.tw/statistica/oldpdf/a10n420.pdf,,"['probability', 'statistics', 'probability-distributions', 'intuition']"
87,Covariance of two random variables with monotone transformation,Covariance of two random variables with monotone transformation,,"Suppose I know that, for two random variables $X,Y$, we have  $$Cov(X,Y)\neq 0.$$ What happens if we take a monotone transformation of $X$; will the inequality persist? That is, say $f(.)$ is a strictly increasing (not necessarily linear) function, then does it follow that  $$Cov(f(X),Y)\neq 0?$$ Since covariance depicts linear relationships, this would only follow if $f$ were linear, right? In that case, under which assumptions on the relation of $X,Y$ can we say that it does follow for nonlinear transformations $f$? (If it helps, I am currently looking at the case where $f$ is the cdf of the standard normal $\Phi$.)","Suppose I know that, for two random variables $X,Y$, we have  $$Cov(X,Y)\neq 0.$$ What happens if we take a monotone transformation of $X$; will the inequality persist? That is, say $f(.)$ is a strictly increasing (not necessarily linear) function, then does it follow that  $$Cov(f(X),Y)\neq 0?$$ Since covariance depicts linear relationships, this would only follow if $f$ were linear, right? In that case, under which assumptions on the relation of $X,Y$ can we say that it does follow for nonlinear transformations $f$? (If it helps, I am currently looking at the case where $f$ is the cdf of the standard normal $\Phi$.)",,"['probability', 'statistics', 'probability-theory']"
88,Three equal die rolls in a row in a $3\times 3$ array,Three equal die rolls in a row in a  array,3\times 3,"If 9 six-sided dice were rolled consecutively and displayed in a $3\times3$ format, what is the probability of a line of 3 of the same number occurring? Considering the 8 ways that are possible; 3 horizontally, 3 vertically and 2 diagonally. The example below shows a line of three diagonally; $A_1, B_2$ and $C_3$. $$\begin{array}{ccc} \begin{array}{ccc} A_1&A_2&A_3\\B_1&B_2&B_3\\C_1&C_2&C_3 \end{array} &\to& \begin{array}{ccc} 2&4&5 \\ 4&2&3 \\ 6&6&2 \end{array} \end{array} $$ What are the players odds of winning given that only one line of three is needed to win. Thanks so much to the smart person that can work this out and possibly explain in simple terms the process of working it out! Very much appreciated! =)","If 9 six-sided dice were rolled consecutively and displayed in a $3\times3$ format, what is the probability of a line of 3 of the same number occurring? Considering the 8 ways that are possible; 3 horizontally, 3 vertically and 2 diagonally. The example below shows a line of three diagonally; $A_1, B_2$ and $C_3$. $$\begin{array}{ccc} \begin{array}{ccc} A_1&A_2&A_3\\B_1&B_2&B_3\\C_1&C_2&C_3 \end{array} &\to& \begin{array}{ccc} 2&4&5 \\ 4&2&3 \\ 6&6&2 \end{array} \end{array} $$ What are the players odds of winning given that only one line of three is needed to win. Thanks so much to the smart person that can work this out and possibly explain in simple terms the process of working it out! Very much appreciated! =)",,"['probability', 'dice', 'inclusion-exclusion']"
89,Derivation of the density function of product of two random variables,Derivation of the density function of product of two random variables,,"I am looking for distribution of product of two random variables. Best I could found so far was this formula from the relevant Wikipedia page : $$ f_Z(z) = \int_{-\infty}^{+\infty} \frac{1}{|x|} f_{XY}(x, \frac{z}{x}) dx $$ However, when I try to derive it myself, I find a different result. The work I have done so far is below. $X$: The first random variable $Y$: The second random variable $Z$: The product of these two random variables; that is: $$ Z = XY $$ $$ F_Z(z) = P(Z \leq z) = \iint\limits_{D_z} f_{XY}(x, y) dx dy $$ Region of $Z$, $D_Z$, depends on the sign of $Z$: So I decided to solve it in the situations; for $z<0$ and $z>0$. Case #1 - $(z>0)$ $$ F_Z(z) = \int_{y=-\infty}^{y=0} \int_{x=\frac{z}{y}}^{x=0} f_{XY}(x, y) dx dy + \int_{y=0}^{y=+\infty} \int_{x=0}^{x=\frac{z}{y}} f_{XY}(x, y) dx dy $$ $$ f_Z(z) = \frac{d F_Z(z)}{dz} = \int_{y=-\infty}^{y=0} (-\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy + \int_{y=0}^{y=+\infty} (\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy $$ Case #2 - $(z<0)$ $$ F_Z(z) = \int_{y=-\infty}^{y=0} \int_{x=0}^{x=\frac{z}{y}} f_{XY}(x, y) dx dy + \int_{y=0}^{y=+\infty} \int_{x=\frac{z}{y}}^{x=0} f_{XY}(x, y) dx dy $$ $$ f_Z(z) = \frac{d F_Z(z)}{dz} = \int_{y=-\infty}^{y=0} (\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy + \int_{y=0}^{y=+\infty} (-\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy $$ By combining these two cases, I find the general partial equation: $$ f_Z(z) = \left\{ 	\begin{array}{ll} 		+ \int_{y=-\infty}^{y=0} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy - \int_{y=0}^{y=+\infty} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy   & \mbox{if } z < 0 \\ 		??? & \mbox{if } z = 0 \\ 		- \int_{y=-\infty}^{y=0} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy + \int_{y=0}^{y=+\infty} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy  & \mbox{if } z > 0 	\end{array} \right.$$ Why is my solution SO different from the one in Wikipedia? What am I doing wrong? Can you please fix any mistakes in my derivation, or make the derivation in your own way?","I am looking for distribution of product of two random variables. Best I could found so far was this formula from the relevant Wikipedia page : $$ f_Z(z) = \int_{-\infty}^{+\infty} \frac{1}{|x|} f_{XY}(x, \frac{z}{x}) dx $$ However, when I try to derive it myself, I find a different result. The work I have done so far is below. $X$: The first random variable $Y$: The second random variable $Z$: The product of these two random variables; that is: $$ Z = XY $$ $$ F_Z(z) = P(Z \leq z) = \iint\limits_{D_z} f_{XY}(x, y) dx dy $$ Region of $Z$, $D_Z$, depends on the sign of $Z$: So I decided to solve it in the situations; for $z<0$ and $z>0$. Case #1 - $(z>0)$ $$ F_Z(z) = \int_{y=-\infty}^{y=0} \int_{x=\frac{z}{y}}^{x=0} f_{XY}(x, y) dx dy + \int_{y=0}^{y=+\infty} \int_{x=0}^{x=\frac{z}{y}} f_{XY}(x, y) dx dy $$ $$ f_Z(z) = \frac{d F_Z(z)}{dz} = \int_{y=-\infty}^{y=0} (-\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy + \int_{y=0}^{y=+\infty} (\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy $$ Case #2 - $(z<0)$ $$ F_Z(z) = \int_{y=-\infty}^{y=0} \int_{x=0}^{x=\frac{z}{y}} f_{XY}(x, y) dx dy + \int_{y=0}^{y=+\infty} \int_{x=\frac{z}{y}}^{x=0} f_{XY}(x, y) dx dy $$ $$ f_Z(z) = \frac{d F_Z(z)}{dz} = \int_{y=-\infty}^{y=0} (\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy + \int_{y=0}^{y=+\infty} (-\frac{1}{y}) f_{XY}(\frac{z}{y}, y) dy $$ By combining these two cases, I find the general partial equation: $$ f_Z(z) = \left\{ 	\begin{array}{ll} 		+ \int_{y=-\infty}^{y=0} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy - \int_{y=0}^{y=+\infty} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy   & \mbox{if } z < 0 \\ 		??? & \mbox{if } z = 0 \\ 		- \int_{y=-\infty}^{y=0} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy + \int_{y=0}^{y=+\infty} \frac{1}{y} f_{XY}(\frac{z}{y}, y) dy  & \mbox{if } z > 0 	\end{array} \right.$$ Why is my solution SO different from the one in Wikipedia? What am I doing wrong? Can you please fix any mistakes in my derivation, or make the derivation in your own way?",,"['probability', 'probability-distributions', 'proof-writing']"
90,Why does maximum likelihood estimation work the way that it does?,Why does maximum likelihood estimation work the way that it does?,,"I'm wrapping my head around MLE right now and there's something about it that bothers me, irrationally I'm sure. I believe I understand the procedure: essentially we hold our observations fixed and maximize the likelihood function with respect to the parameters to find the parameters which would make a PDF that assigns a maximum value to our observations. My question it this: why do we care about finding such a PDF? In particular, I'm imagining that we end up with a very skewed PDF so that the expected value is far from the maximum. Or what if we have an even weirder PDF than that? If $f$ is a PDF, it was my understanding that the number $f(x)$ is not particularly meaningful for continuous random variables—it's the area under the curve that we care about. So why aren't we in some way trying to maximize the area under our observations, or taking the expected value into account or something? Hopefully this question makes a little bit of sense. I can try to clarify if it doesn't.","I'm wrapping my head around MLE right now and there's something about it that bothers me, irrationally I'm sure. I believe I understand the procedure: essentially we hold our observations fixed and maximize the likelihood function with respect to the parameters to find the parameters which would make a PDF that assigns a maximum value to our observations. My question it this: why do we care about finding such a PDF? In particular, I'm imagining that we end up with a very skewed PDF so that the expected value is far from the maximum. Or what if we have an even weirder PDF than that? If $f$ is a PDF, it was my understanding that the number $f(x)$ is not particularly meaningful for continuous random variables—it's the area under the curve that we care about. So why aren't we in some way trying to maximize the area under our observations, or taking the expected value into account or something? Hopefully this question makes a little bit of sense. I can try to clarify if it doesn't.",,"['probability', 'statistics']"
91,2 people on a random walk,2 people on a random walk,,"Say you have a building of $HJ$ rooms, where $H$ and $J$ are positive integers (a rectangular grid of rooms of size $H$ times $J$). You can label the rooms $(h,j)$ where $1 \le h \le H$ and $1 \le j \le J$. One person enters the building of rooms at $(1,j_0)$ and the other person enters at $(h_0,1)$. After each minute, they choose randomly another room which must be adjacent to it ; i.e. if you are at coordinate $(h,j)$, you can go to $(h \pm 1, j)$ or to $(h, j \pm 1)$ with probability $1/4$, but the probability goes to $1/3$ if you are on a ""side"" (i.e. at coordinate $(1,j)$ you go to $(2,j)$ or $(1, j \pm 1)$ with probability $1/3$, and at coordinate $(1,1)$ you go to $(2,1)$ or $(1,2)$ with probability $1/2$). When the person that entered at $(1,j_0)$ reaches the room $(h_0,1)$, she ""exits"" the building using the entrance the other person used (this is not the case if the person at $(1,j_0)$ goes back to $(1,j_0)$). The same applies to the other person ; if person 2 goes back to the entrance of person 1 she exits the building. The question is : What is the probability that the two persons are in the same room at some point during their walk? My attempts : for $H=J=1$, the probability is $1$. For $H=2$ and $J=1$ (or the opposite) and $h_0 = H$, the probability is zero, since the two persons will just switch rooms and leave, without meeting (the hallways don't count :P). So it seems that it depends a lot on $H$ and $J$. Actually, if $H = 1$ and $J \ge 1$ then the probability is $1$ if $j_0$ is odd and $0$ if $j_0$ is even, because then the number of rooms between the two is always even, so for this number to reach $0$ we must have $j_0$ odd. Conversely, if $j_0$ is odd then since the two persons are forced to cross the same rooms they must meet at some point. The same goes by symmetry if $J = 1$. Obviously it cannot only depend on the parity of $H$ and $J$ ; when $H$ and $J$ are not $1$ there always exists paths where the two persons meet and don't meet. I can do by hand the computations for $H=J=h_0=j_0=2$ but in the general case I have no idea how to tackle this problem. This is actually a question in my friend's homework, and there is nothing in the course about stochastic processes. Thanks in advance,","Say you have a building of $HJ$ rooms, where $H$ and $J$ are positive integers (a rectangular grid of rooms of size $H$ times $J$). You can label the rooms $(h,j)$ where $1 \le h \le H$ and $1 \le j \le J$. One person enters the building of rooms at $(1,j_0)$ and the other person enters at $(h_0,1)$. After each minute, they choose randomly another room which must be adjacent to it ; i.e. if you are at coordinate $(h,j)$, you can go to $(h \pm 1, j)$ or to $(h, j \pm 1)$ with probability $1/4$, but the probability goes to $1/3$ if you are on a ""side"" (i.e. at coordinate $(1,j)$ you go to $(2,j)$ or $(1, j \pm 1)$ with probability $1/3$, and at coordinate $(1,1)$ you go to $(2,1)$ or $(1,2)$ with probability $1/2$). When the person that entered at $(1,j_0)$ reaches the room $(h_0,1)$, she ""exits"" the building using the entrance the other person used (this is not the case if the person at $(1,j_0)$ goes back to $(1,j_0)$). The same applies to the other person ; if person 2 goes back to the entrance of person 1 she exits the building. The question is : What is the probability that the two persons are in the same room at some point during their walk? My attempts : for $H=J=1$, the probability is $1$. For $H=2$ and $J=1$ (or the opposite) and $h_0 = H$, the probability is zero, since the two persons will just switch rooms and leave, without meeting (the hallways don't count :P). So it seems that it depends a lot on $H$ and $J$. Actually, if $H = 1$ and $J \ge 1$ then the probability is $1$ if $j_0$ is odd and $0$ if $j_0$ is even, because then the number of rooms between the two is always even, so for this number to reach $0$ we must have $j_0$ odd. Conversely, if $j_0$ is odd then since the two persons are forced to cross the same rooms they must meet at some point. The same goes by symmetry if $J = 1$. Obviously it cannot only depend on the parity of $H$ and $J$ ; when $H$ and $J$ are not $1$ there always exists paths where the two persons meet and don't meet. I can do by hand the computations for $H=J=h_0=j_0=2$ but in the general case I have no idea how to tackle this problem. This is actually a question in my friend's homework, and there is nothing in the course about stochastic processes. Thanks in advance,",,['probability']
92,Tuning the birthday paradox,Tuning the birthday paradox,,"I have limited access to a collection $X_1,\ldots,X_m$ of sets of positive integers.  Each $X_i$ is ""moderately large"" (a brief survey has found them to contain about $10^6$ elements in each set), but $X_i ∩ X_j = \{\}$ unless $i=j$. $m$ is between $50000$ and a few million, so also ""moderately large"". I also have limited access to a sequence $Y_1,\ldots,Y_n$ of elements of $X$, where $n$ is really fairly small, like $n ≤ 50$.  I would like to know the identification $f : [1..n] → [1..m]$ so that $Y_i = X_{f(i)}$. The problem is I only have limited access to the $X_i$ and the $Y_i$: I have random variables $x_i$ and $y_i$ on unknown, but hopefully somewhat uniform, measure spaces, that take values in $X_i$ and $Y_i$. Sampling $x_i$ and $y_i$ takes a small but non-neglible time, and I wish to compute $f$ as quickly as possible.  My plan is to simply keep records of the samples, and look for collisions, since $X_i$ and $Y_j$ are either equal or disjoint.  I can generate about one thousand samples per second. The question is how often should I sample from the $x_i$, and how often from the $y_i$? I began by only sampling once from the $x_i$, and then sampling the $y_j$ until I found that specific value of $x_i$, but this seems very unlikely to happen early (out of $578000$ $y$ samples, I have $532405$ distinct values, none of which are the specific $x$ values found). On the other hand, sampling often from the $x$ is going to get very expensive simply because there are so many of them and so few of the $y$ in comparison! How do I quantify this?","I have limited access to a collection $X_1,\ldots,X_m$ of sets of positive integers.  Each $X_i$ is ""moderately large"" (a brief survey has found them to contain about $10^6$ elements in each set), but $X_i ∩ X_j = \{\}$ unless $i=j$. $m$ is between $50000$ and a few million, so also ""moderately large"". I also have limited access to a sequence $Y_1,\ldots,Y_n$ of elements of $X$, where $n$ is really fairly small, like $n ≤ 50$.  I would like to know the identification $f : [1..n] → [1..m]$ so that $Y_i = X_{f(i)}$. The problem is I only have limited access to the $X_i$ and the $Y_i$: I have random variables $x_i$ and $y_i$ on unknown, but hopefully somewhat uniform, measure spaces, that take values in $X_i$ and $Y_i$. Sampling $x_i$ and $y_i$ takes a small but non-neglible time, and I wish to compute $f$ as quickly as possible.  My plan is to simply keep records of the samples, and look for collisions, since $X_i$ and $Y_j$ are either equal or disjoint.  I can generate about one thousand samples per second. The question is how often should I sample from the $x_i$, and how often from the $y_i$? I began by only sampling once from the $x_i$, and then sampling the $y_j$ until I found that specific value of $x_i$, but this seems very unlikely to happen early (out of $578000$ $y$ samples, I have $532405$ distinct values, none of which are the specific $x$ values found). On the other hand, sampling often from the $x$ is going to get very expensive simply because there are so many of them and so few of the $y$ in comparison! How do I quantify this?",,"['probability', 'statistics', 'algorithms', 'computer-science']"
93,Relations between Order Statistics of Uniform RVs and Exponential RVs,Relations between Order Statistics of Uniform RVs and Exponential RVs,,"Say we have $U_1 \dots U_n$ i.i.d. random variables uniform on $[0,1]$ and $Y_1 \dots Y_{n+1}$ i.i.d. random variables distributed as $Y_i \sim Exp(1)$. I know that the joint distribution of the order statistics $(U_{(1)}, \dots, U_{(n)})$ is equal in distribution to $(\frac{Y_1}{\sum_i^{n+1} Y_i}, \frac{Y_1+Y_2}{\sum_i^{n+1} Y_i}, \dots, \frac{Y_1+\dots+Y_n}{\sum_i^{n+1} Y_i})$. I can prove the result using a transformation of variables, Jacobians, etc., but this is rather tedious. Is there a more elegant way of deriving this statement? Maybe something with poisson processes?","Say we have $U_1 \dots U_n$ i.i.d. random variables uniform on $[0,1]$ and $Y_1 \dots Y_{n+1}$ i.i.d. random variables distributed as $Y_i \sim Exp(1)$. I know that the joint distribution of the order statistics $(U_{(1)}, \dots, U_{(n)})$ is equal in distribution to $(\frac{Y_1}{\sum_i^{n+1} Y_i}, \frac{Y_1+Y_2}{\sum_i^{n+1} Y_i}, \dots, \frac{Y_1+\dots+Y_n}{\sum_i^{n+1} Y_i})$. I can prove the result using a transformation of variables, Jacobians, etc., but this is rather tedious. Is there a more elegant way of deriving this statement? Maybe something with poisson processes?",,"['probability', 'probability-theory', 'stochastic-processes', 'probability-distributions']"
94,How are Blackjack Basic Strategy tables calculated (What is the maths behind them),How are Blackjack Basic Strategy tables calculated (What is the maths behind them),,"Lets assume a very basic set of rules and table for them, these rules are unlikely to be seen in any casino and the reason is clear, there is only a 0.04% edge in favour of the casino, this could be beaten without ever counting cards simply by applying basic strategy and not even knowing the exceptions to it. Here are the rules. 1). We always start with a full deck of cards. a). Assume this for 2 reasons, first the count (for card counters) is irrelevant as there is not enough cards out to establish a pattern (such patterns can affect the way you play using basic strategy and therefore the stats of the game). b). Second it means we are always working from the same base numbers outlined below 2). We have 1 full deck of 52 cards 3). 4 of these cards are gone out of the deck leaving 48 (these 4 cards are the first 4 used in play above) 4). One of the 4 cards above in point 3 are unknown (because it is the dealers face down card) 5). This leaves only 3 cards whose value are known to us (from which we make all our decisions) 6). After the game is finished, all the cards are replaced in the deck and the deck is reshuffled to begin again (this brings us back to point 1 to repeat the process for every game). I cannot include screenshots because I am new to this forum. But I wanted to post one of a basic strategy table with the rules specified. If the dealer up card is 6, and your two cards show a total of 14 (perhaps 8 and 6, or 9 and 4, it does not matter the combination), you should stand (take no more cards). However if your hand was an A3 (soft 14), you should double down. Finally if your hand was a 77, (double 7), you should split. The questions I have are, what are these decisions based on. The reasons for questioning these tables are because almost every website or book quotes such tables without explaining the maths behind them. And when the maths is outlined, it’s usually done in either a convoluted and inefficient way, or over simplified to the point that it does not explain properly the other decisions in the table. Essentially what I am asking is how do you calculate your next move given a set of rules and a specific hand. Meaning how exactly are the three examples above worked out. Is there a specific formula that can be used so that I may program it and build my own tables.","Lets assume a very basic set of rules and table for them, these rules are unlikely to be seen in any casino and the reason is clear, there is only a 0.04% edge in favour of the casino, this could be beaten without ever counting cards simply by applying basic strategy and not even knowing the exceptions to it. Here are the rules. 1). We always start with a full deck of cards. a). Assume this for 2 reasons, first the count (for card counters) is irrelevant as there is not enough cards out to establish a pattern (such patterns can affect the way you play using basic strategy and therefore the stats of the game). b). Second it means we are always working from the same base numbers outlined below 2). We have 1 full deck of 52 cards 3). 4 of these cards are gone out of the deck leaving 48 (these 4 cards are the first 4 used in play above) 4). One of the 4 cards above in point 3 are unknown (because it is the dealers face down card) 5). This leaves only 3 cards whose value are known to us (from which we make all our decisions) 6). After the game is finished, all the cards are replaced in the deck and the deck is reshuffled to begin again (this brings us back to point 1 to repeat the process for every game). I cannot include screenshots because I am new to this forum. But I wanted to post one of a basic strategy table with the rules specified. If the dealer up card is 6, and your two cards show a total of 14 (perhaps 8 and 6, or 9 and 4, it does not matter the combination), you should stand (take no more cards). However if your hand was an A3 (soft 14), you should double down. Finally if your hand was a 77, (double 7), you should split. The questions I have are, what are these decisions based on. The reasons for questioning these tables are because almost every website or book quotes such tables without explaining the maths behind them. And when the maths is outlined, it’s usually done in either a convoluted and inefficient way, or over simplified to the point that it does not explain properly the other decisions in the table. Essentially what I am asking is how do you calculate your next move given a set of rules and a specific hand. Meaning how exactly are the three examples above worked out. Is there a specific formula that can be used so that I may program it and build my own tables.",,"['probability', 'recreational-mathematics']"
95,Negativity in a CIR model discretized by Ito-Taylor expansion,Negativity in a CIR model discretized by Ito-Taylor expansion,,"Let $X = (X_t: t \in [0,T])$ be a stochastic process satisfying a CIR model $$ dX_t = \beta (X_t - \gamma) dt + \sigma\sqrt{X_t} dB_t, $$ where $B_t$ is a standard Brownian motion, $\beta$ is a negative constant, $\gamma, \sigma$ are positive constants. In order for the SDE to make sense, assume that $X_t > 0$ for all $t \in [0,T]$. Consider following two ways to simulate the model based on discretization of $t$ with Ito-Taylor expansion: the Euler scheme: $$                                                                 X_{t + \Delta} \approx X_t + \beta(X_t - \gamma)\Delta + \sigma \sqrt{X_t} Z \Delta,  $$ where $Z$ is $N(0, 1)$ Gaussian variable. the Milstein scheme $$ X_{t + \Delta} \approx X_t + \beta(X_t - \gamma)\Delta + \sigma \sqrt{X_t}Z\sqrt{\Delta} + \frac{1}{4}\sigma^2 \Delta (Z^2-1) $$ where $Z$ is $N(0, 1)$ Gaussian variable. I was wondering why these two schemes have a positive probability of generating negative values of $X_t$ and therefore cannot be used without suitable modifications? References (book, tutorial and/or paper) will be helpful too! Thanks and regards!","Let $X = (X_t: t \in [0,T])$ be a stochastic process satisfying a CIR model $$ dX_t = \beta (X_t - \gamma) dt + \sigma\sqrt{X_t} dB_t, $$ where $B_t$ is a standard Brownian motion, $\beta$ is a negative constant, $\gamma, \sigma$ are positive constants. In order for the SDE to make sense, assume that $X_t > 0$ for all $t \in [0,T]$. Consider following two ways to simulate the model based on discretization of $t$ with Ito-Taylor expansion: the Euler scheme: $$                                                                 X_{t + \Delta} \approx X_t + \beta(X_t - \gamma)\Delta + \sigma \sqrt{X_t} Z \Delta,  $$ where $Z$ is $N(0, 1)$ Gaussian variable. the Milstein scheme $$ X_{t + \Delta} \approx X_t + \beta(X_t - \gamma)\Delta + \sigma \sqrt{X_t}Z\sqrt{\Delta} + \frac{1}{4}\sigma^2 \Delta (Z^2-1) $$ where $Z$ is $N(0, 1)$ Gaussian variable. I was wondering why these two schemes have a positive probability of generating negative values of $X_t$ and therefore cannot be used without suitable modifications? References (book, tutorial and/or paper) will be helpful too! Thanks and regards!",,"['probability', 'stochastic-processes']"
96,Limit distribution of the number of longest runs in a random binary sequence of length $n\to\infty.$,Limit distribution of the number of longest runs in a random binary sequence of length,n\to\infty.,"Let $X_n$ be the number of longest runs in a sequence of $n$ i.i.d. Bernoulli(1/2) random variables. Here, ""run"" means a nonempty block of adjacent $1$ s; e.g., in the sequence $110110001$ , there are two longest runs (each being $11$ ). By using a program from OEIS, the limiting distribution of $X_n$ , as $n\to\infty,$ is ""empirically"" suggested to be $$p_k:=\lim_{n\to\infty}P[X_n=k]={1\over k\ 2^k\ \log(2)}\ \ (k=1,2,3,...)$$ Question : As this is probably a known result, can someone cite a published proof? (Or provide any information on how to prove it.) ""Derivation"": As described elsewhere , for $n\ge 1$ , there is a bijection between (a) the compositions of $n$ with exactly $k$ largest parts, and (b) the binary strings of length $n-1$ with exactly $k$ longest runs of $1$ s, such that these are equal in number. This number is listed as $T(n,k)$ at OEIS A238341 , where a  program for $T(n,k)$ is also given. (I've posted a separate question asking for explanation/sources of the algorithm implemented by this program.) NB : Letting $A(n,k)$ be the number of length- $n$ binary strings with $k$ longest runs, and $T(n,k)$ be the number of compositions of $n$ with exactly $k$ largest parts, there is an ""edge effect"" due to which these are related as follows: $$A(n,k)=\begin{cases} 1&\text{if $k=0$}\\[1ex] T(n+1,k) &\text{otherwise} \end{cases}$$ and it is to be noted that in fact $A(n,k)=0$ if $k\gt\lceil{n\over 2}\rceil$ . Thus, we have $$P[X_n=k]={A(n,k)\over 2^n} \ \ (k=0,1,2,3,...)$$ Using the OEIS program gives $P[X_n=1]\approx 0.7213$ for $n\gt 100,$ which led me to guess that $p_1={1\over 2 \log 2}$ . I then let $c_k:= p_k\ \log 2$ , which implies $\sum_{k=1}^\infty c_k=\log 2;$ i.e.,  a series converging to $\log 2.$ One of the best-known such series is $c_k={1\over k\ 2^k},$ which is strongly supported by computing $(P[X_n=k] \log 2)_{n\gt 100}\approx(1/2,1/8,1/24,1/64, 1/160,...)=({1\over k\ 2^k})_{k=1,2,...}.$ A Python/SageMath rendition of the OEIS program is online at SageMathCell . It takes about a minute there to plot $(P[X_n=k])_{n=1..45}$ for $k=0,1,2,3$ . Aside : (Sorry for the length, but I thought someone might be interested ...) @kodlu's comment has led me to show that the limit distribution of the number of longest runs in a random binary sequence of length $n\to\infty$ is the same distribution for all of the following different definitions of ""run"" : D1:  ""run"" means a nonempty block of adjacent $1$ s. D2:  ""run"" means a nonempty block of adjacent $1$ s, or a nonempty block of adjacent $0$ s. D3:  ""run"" means a nonempty block of adjacent $1$ s, flanked on each side either by a $0$ or by the start/end of the sequence. D4:   ""run"" means a nonempty block of adjacent $1$ s, flanked on each side either by a $0$ or by the start/end of the sequence, or a nonempty block of adjacent $0$ s, flanked on each side either by a $1$ or by the start/end of the sequence. Proof: Clearly, D1 and D3 give the same distribution for all $n$ because the longest run is the same by either definition (hence the limit distributions are the same). Similarly, D2 and D4 give the same distribution for all $n$ (though different from  those for D1 and D3). Therefore, all that remains to show is that the limit distribution for D1 is the same as that for D2. To do so, let $A(n,k)$ (resp. $B(n,k)$ ) denote the number of length- $n$ binary strings with exactly $k$ longest runs,  according to definition D1 (resp. D2), and let $X_n(s)$ (resp. $Y_n(s)$ ) denote the number of longest runs in sequence $s$ , according to definition D1 (D2, resp.).  We will show that $$B(n,k)=2\ A(n-1,k)  \ \ (0\lt k\lt n)$$ from which it follows that for $0\lt k\lt n$ , $$P[Y_n=k] = {B(n,k)\over 2^n}={A(n-1,k)\over 2^{n-1}}=P[X_{n-1}=k] $$ and hence $$\lim_{n\to\infty}P[Y_n=k]=\lim_{n\to\infty}P[X_n=k]\ \ (k=1,2,3,\dots).$$ (We can dispense with $k=0$ , because $P[Y_n=0]=0$ and $P[X_n=0]=2^{-n}\to 0.$ ) Thus proceeding, with $s[1]$ denoting the first element of $s$ , we have, for $0\lt k\lt n$ : $$\begin{align}B(n,k) &\overset{1}{=}|\{s\in\{0,1\}^n:\ Y_n(s)=k\}|\\ &\overset{2}{=}2\ |\{s\in\{0,1\}^n:\ Y_n(s)=k,\ s[1]=0\}|\\ &\overset{3}{=}2\ |\{s\in\{0,1\}^{n-1}:\ X_{n-1}(s)=k\}\\ &\overset{4}{=}2\ A(n-1,k) \end{align}$$ Eq.1 implies Eq.2 because there is a bijection between the sequences beginning with $0$ and those beginning with $1$ , pairing each $s$ to its complement $\bar s$ (i.e. with all bits complemented), such that $Y_n(s)=Y_n(\bar s).$ (Any run in $s$ exactly matches a run of the complementary symbol in $\bar s.$ ) To show that Eq.2 implies Eq.3, denote the corresponding sets (suppressing $k$ ) as $$T_n:=\{s\in\{0,1\}^n:\ Y_n(s)=k,\ s[1]=0\}\\[1ex] S_{n-1}:=\{s\in\{0,1\}^{n-1}:\ X_{n-1}(s)=k\}$$ Now, any element of $T_n$ can be written,  with unique positive integers $(n_1,...,n_j)$ summing to $n$ , in the usual ""run-length encoding"" form $$t =  \ 0^{n_1}1^{n_2}0^{n_3}1^{n_4}\dots b^{n_j}, \ \ b=(j+1)\bmod 2$$ and any element of $S_{n-1}$ can be written, with unique positive integers $(n_1,...,n_j)$ summing to $n$ , in the special form $$s =  \ 1^{n_1-1}01^{n_2-1}01^{n_3-1}\dots01^{n_j-1}$$ thus setting up the bijections $$\underbrace{0^{n_1}1^{n_2}0^{n_3}1^{n_4}\dots b^{n_j}}_{\in T_n}\leftrightarrow(n_1,\dots,n_j)\leftrightarrow\underbrace{1^{n_1-1}01^{n_2-1}01^{n_3-1}\dots01^{n_j-1}}_{\in S_{n-1}}$$ Now, $Y_n(0^{n_1}1^{n_2}0^{n_3}1^{n_4}\dots b^{n_j})=X_{n-1}(1^{n_1-1}01^{n_2-1}01^{n_3-1}\dots01^{n_j-1})=$ the multiplicity of $\max(n_1,...,n_j)$ , the sole exception being when $n_1=\dots=n_j=1$ (which occurs iff $k=0$ or $k=n$ ; i.e. when $Y_n(0101...)=n\ne 0=X_{n-1}(000...)).$ Consequently, $|T_n| = |S_{n-1}|$ for $0\lt k\lt n$ . QED","Let be the number of longest runs in a sequence of i.i.d. Bernoulli(1/2) random variables. Here, ""run"" means a nonempty block of adjacent s; e.g., in the sequence , there are two longest runs (each being ). By using a program from OEIS, the limiting distribution of , as is ""empirically"" suggested to be Question : As this is probably a known result, can someone cite a published proof? (Or provide any information on how to prove it.) ""Derivation"": As described elsewhere , for , there is a bijection between (a) the compositions of with exactly largest parts, and (b) the binary strings of length with exactly longest runs of s, such that these are equal in number. This number is listed as at OEIS A238341 , where a  program for is also given. (I've posted a separate question asking for explanation/sources of the algorithm implemented by this program.) NB : Letting be the number of length- binary strings with longest runs, and be the number of compositions of with exactly largest parts, there is an ""edge effect"" due to which these are related as follows: and it is to be noted that in fact if . Thus, we have Using the OEIS program gives for which led me to guess that . I then let , which implies i.e.,  a series converging to One of the best-known such series is which is strongly supported by computing A Python/SageMath rendition of the OEIS program is online at SageMathCell . It takes about a minute there to plot for . Aside : (Sorry for the length, but I thought someone might be interested ...) @kodlu's comment has led me to show that the limit distribution of the number of longest runs in a random binary sequence of length is the same distribution for all of the following different definitions of ""run"" : D1:  ""run"" means a nonempty block of adjacent s. D2:  ""run"" means a nonempty block of adjacent s, or a nonempty block of adjacent s. D3:  ""run"" means a nonempty block of adjacent s, flanked on each side either by a or by the start/end of the sequence. D4:   ""run"" means a nonempty block of adjacent s, flanked on each side either by a or by the start/end of the sequence, or a nonempty block of adjacent s, flanked on each side either by a or by the start/end of the sequence. Proof: Clearly, D1 and D3 give the same distribution for all because the longest run is the same by either definition (hence the limit distributions are the same). Similarly, D2 and D4 give the same distribution for all (though different from  those for D1 and D3). Therefore, all that remains to show is that the limit distribution for D1 is the same as that for D2. To do so, let (resp. ) denote the number of length- binary strings with exactly longest runs,  according to definition D1 (resp. D2), and let (resp. ) denote the number of longest runs in sequence , according to definition D1 (D2, resp.).  We will show that from which it follows that for , and hence (We can dispense with , because and ) Thus proceeding, with denoting the first element of , we have, for : Eq.1 implies Eq.2 because there is a bijection between the sequences beginning with and those beginning with , pairing each to its complement (i.e. with all bits complemented), such that (Any run in exactly matches a run of the complementary symbol in ) To show that Eq.2 implies Eq.3, denote the corresponding sets (suppressing ) as Now, any element of can be written,  with unique positive integers summing to , in the usual ""run-length encoding"" form and any element of can be written, with unique positive integers summing to , in the special form thus setting up the bijections Now, the multiplicity of , the sole exception being when (which occurs iff or ; i.e. when Consequently, for . QED","X_n n 1 110110001 11 X_n n\to\infty, p_k:=\lim_{n\to\infty}P[X_n=k]={1\over k\ 2^k\ \log(2)}\ \ (k=1,2,3,...) n\ge 1 n k n-1 k 1 T(n,k) T(n,k) A(n,k) n k T(n,k) n k A(n,k)=\begin{cases}
1&\text{if k=0}\\[1ex]
T(n+1,k) &\text{otherwise}
\end{cases} A(n,k)=0 k\gt\lceil{n\over 2}\rceil P[X_n=k]={A(n,k)\over 2^n} \ \ (k=0,1,2,3,...) P[X_n=1]\approx 0.7213 n\gt 100, p_1={1\over 2 \log 2} c_k:= p_k\ \log 2 \sum_{k=1}^\infty c_k=\log 2; \log 2. c_k={1\over k\ 2^k}, (P[X_n=k] \log 2)_{n\gt 100}\approx(1/2,1/8,1/24,1/64, 1/160,...)=({1\over k\ 2^k})_{k=1,2,...}. (P[X_n=k])_{n=1..45} k=0,1,2,3 n\to\infty 1 1 0 1 0 1 0 0 1 n n A(n,k) B(n,k) n k X_n(s) Y_n(s) s B(n,k)=2\ A(n-1,k)  \ \ (0\lt k\lt n) 0\lt k\lt n P[Y_n=k] = {B(n,k)\over 2^n}={A(n-1,k)\over 2^{n-1}}=P[X_{n-1}=k]
 \lim_{n\to\infty}P[Y_n=k]=\lim_{n\to\infty}P[X_n=k]\ \ (k=1,2,3,\dots). k=0 P[Y_n=0]=0 P[X_n=0]=2^{-n}\to 0. s[1] s 0\lt k\lt n \begin{align}B(n,k)
&\overset{1}{=}|\{s\in\{0,1\}^n:\ Y_n(s)=k\}|\\
&\overset{2}{=}2\ |\{s\in\{0,1\}^n:\ Y_n(s)=k,\ s[1]=0\}|\\
&\overset{3}{=}2\ |\{s\in\{0,1\}^{n-1}:\ X_{n-1}(s)=k\}\\
&\overset{4}{=}2\ A(n-1,k)
\end{align} 0 1 s \bar s Y_n(s)=Y_n(\bar s). s \bar s. k T_n:=\{s\in\{0,1\}^n:\ Y_n(s)=k,\ s[1]=0\}\\[1ex] S_{n-1}:=\{s\in\{0,1\}^{n-1}:\ X_{n-1}(s)=k\} T_n (n_1,...,n_j) n t =  \ 0^{n_1}1^{n_2}0^{n_3}1^{n_4}\dots b^{n_j}, \ \ b=(j+1)\bmod 2 S_{n-1} (n_1,...,n_j) n s =  \ 1^{n_1-1}01^{n_2-1}01^{n_3-1}\dots01^{n_j-1} \underbrace{0^{n_1}1^{n_2}0^{n_3}1^{n_4}\dots b^{n_j}}_{\in T_n}\leftrightarrow(n_1,\dots,n_j)\leftrightarrow\underbrace{1^{n_1-1}01^{n_2-1}01^{n_3-1}\dots01^{n_j-1}}_{\in S_{n-1}} Y_n(0^{n_1}1^{n_2}0^{n_3}1^{n_4}\dots b^{n_j})=X_{n-1}(1^{n_1-1}01^{n_2-1}01^{n_3-1}\dots01^{n_j-1})= \max(n_1,...,n_j) n_1=\dots=n_j=1 k=0 k=n Y_n(0101...)=n\ne 0=X_{n-1}(000...)). |T_n| = |S_{n-1}| 0\lt k\lt n","['probability', 'combinatorics', 'probability-distributions']"
97,Are X and Y independent if the $MGF_{X+Y} = MGF_X MGF_Y$?,Are X and Y independent if the ?,MGF_{X+Y} = MGF_X MGF_Y,"I know that when two random variables $X$ and $Y$ are independent, then the MGF of $X+Y$ is $$ MGF_{X+Y}(t) = \mathbb{E}[e^{t(X + Y)}] = \mathbb{E}[e^{tX}e^{tY}] = MGF_{X}(t)MGF_{Y}(t) $$ However, is the reverse true? If we know that $MGF_{X+Y}(t) = MGF_{X}(t)MGF_{Y}(t)$ , then are $X$ and $Y$ necessarily independent?","I know that when two random variables and are independent, then the MGF of is However, is the reverse true? If we know that , then are and necessarily independent?","X Y X+Y 
MGF_{X+Y}(t) = \mathbb{E}[e^{t(X + Y)}] = \mathbb{E}[e^{tX}e^{tY}] = MGF_{X}(t)MGF_{Y}(t)
 MGF_{X+Y}(t) = MGF_{X}(t)MGF_{Y}(t) X Y","['probability', 'probability-theory', 'random-variables', 'independence', 'moment-generating-functions']"
98,Show that $X_n - Y_n\to 0$ in probability.,Show that  in probability.,X_n - Y_n\to 0,"Let $X_n$ converges to $X$ in distribution and $Y_n$ converges to $X$ in distribution. If $P(X_n - Y_n < -\epsilon) \rightarrow 0$ then show that $X_n-Y_n \rightarrow 0$ in probability. We know that $P[|X_n-Y_n|>\epsilon] = P[X_n -Y_n > \epsilon]+P[X_n-Y_n < -\epsilon]$ . So, if it can be shown that $P[X_n-Y_n > \epsilon] \rightarrow 0$ then we are done. But how to show this?","Let converges to in distribution and converges to in distribution. If then show that in probability. We know that . So, if it can be shown that then we are done. But how to show this?",X_n X Y_n X P(X_n - Y_n < -\epsilon) \rightarrow 0 X_n-Y_n \rightarrow 0 P[|X_n-Y_n|>\epsilon] = P[X_n -Y_n > \epsilon]+P[X_n-Y_n < -\epsilon] P[X_n-Y_n > \epsilon] \rightarrow 0,"['probability', 'probability-theory', 'measure-theory', 'weak-convergence', 'probability-limit-theorems']"
99,"Probability that the sum of two integers in $\{1,\dots,n\}$ equals a perfect square",Probability that the sum of two integers in  equals a perfect square,"\{1,\dots,n\}","I found the following question in MIT OCW's Mathematical Problem Solving and I'd like to know if my solution is ok: ""Let $p_n$ be the probability that $c+d$ is a perfect square when the integers $c$ and $d$ are selected independently at random from the set $\{1,\dots,n\}$ . Show that $\lim_{n\to \infty} p_n\sqrt{n}$ exists, and express this limit in the form $r(\sqrt{s}-t)$ where $s$ and $t$ are integers and $r$ is a rational number."" To me, it looks like that $$p_n= \sum_{k=2}^{\lfloor\sqrt{n}\rfloor} \sum_{i=1}^{k^2-1} P\left(c=i,d=k^2-i\right)=\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}\sum_{i=1}^{k^2-1} \frac{1}{n^2}=\frac{\lfloor\sqrt{n}\rfloor(2\lfloor\sqrt{n}\rfloor^2+3\lfloor\sqrt{n}\rfloor-5)}{6n^2}$$ for $n\ge 4$ and hence $\lim p_n\sqrt{n}=\frac{1}{3}$ using $\lfloor\sqrt{n}\rfloor\le \sqrt{n}<\lfloor\sqrt{n}\rfloor+1$ and sandwich theorem. However, the form the problem tells to write the answer makes me think I may have made some mistake. Can someone say whether my solution is correct or not and in negative case, where I missed? Thanks in advance! EDIT: I realized that the question does not say that the perfect square must be in $\{1,\dots,n\}$ . So I must add to the above a sum with $\lfloor \sqrt{n}\rfloor<k\le \lfloor\sqrt{2n}\rfloor$ , being careful to the restrictions that $1\le c,d\le n$ . Hence: $$p_n=\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}\sum_{i=1}^{k^2-1} \frac{1}{n^2}+\sum_{k=\lfloor\sqrt{n}\rfloor+1}^{\lfloor\sqrt{2n-1}\rfloor} \sum_{i=k^2-n}^{n-1} \frac{1}{n^2}=$$ $$=\frac{m_n(2m_n^2+3m_n-2)}{3n^2}-\frac{q_n(q_n+1)(2q_n+1)}{6n^2}+\frac{2q_n}{n}-\frac{2m_n}{n}$$ where $m_n=\lfloor \sqrt{n}\rfloor$ and $q_n=\lfloor \sqrt{2n-1}\rfloor$ . We can compute $$\lim_n \frac{m_n(2m_n^2+3m_n-2)}{3n^{3/2}}=\frac{2}{3}$$ $$\lim_n \frac{q_n(q_n+1)(2q_n+1)}{6n^{3/2}}=\frac{2\sqrt{2}}{3}$$ $$\lim_n \frac{2q_n}{\sqrt{n}}=2\sqrt{2}$$ $$\lim_n \frac{2m_n}{\sqrt{n}}=2$$ Therefore $$\lim_{n\to \infty}\ p_n\sqrt{n}=\frac{4}{3}(\sqrt{2}-1)\approx 0.552284749831$$","I found the following question in MIT OCW's Mathematical Problem Solving and I'd like to know if my solution is ok: ""Let be the probability that is a perfect square when the integers and are selected independently at random from the set . Show that exists, and express this limit in the form where and are integers and is a rational number."" To me, it looks like that for and hence using and sandwich theorem. However, the form the problem tells to write the answer makes me think I may have made some mistake. Can someone say whether my solution is correct or not and in negative case, where I missed? Thanks in advance! EDIT: I realized that the question does not say that the perfect square must be in . So I must add to the above a sum with , being careful to the restrictions that . Hence: where and . We can compute Therefore","p_n c+d c d \{1,\dots,n\} \lim_{n\to \infty} p_n\sqrt{n} r(\sqrt{s}-t) s t r p_n= \sum_{k=2}^{\lfloor\sqrt{n}\rfloor} \sum_{i=1}^{k^2-1} P\left(c=i,d=k^2-i\right)=\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}\sum_{i=1}^{k^2-1} \frac{1}{n^2}=\frac{\lfloor\sqrt{n}\rfloor(2\lfloor\sqrt{n}\rfloor^2+3\lfloor\sqrt{n}\rfloor-5)}{6n^2} n\ge 4 \lim p_n\sqrt{n}=\frac{1}{3} \lfloor\sqrt{n}\rfloor\le \sqrt{n}<\lfloor\sqrt{n}\rfloor+1 \{1,\dots,n\} \lfloor \sqrt{n}\rfloor<k\le \lfloor\sqrt{2n}\rfloor 1\le c,d\le n p_n=\sum_{k=2}^{\lfloor\sqrt{n}\rfloor}\sum_{i=1}^{k^2-1} \frac{1}{n^2}+\sum_{k=\lfloor\sqrt{n}\rfloor+1}^{\lfloor\sqrt{2n-1}\rfloor} \sum_{i=k^2-n}^{n-1} \frac{1}{n^2}= =\frac{m_n(2m_n^2+3m_n-2)}{3n^2}-\frac{q_n(q_n+1)(2q_n+1)}{6n^2}+\frac{2q_n}{n}-\frac{2m_n}{n} m_n=\lfloor \sqrt{n}\rfloor q_n=\lfloor \sqrt{2n-1}\rfloor \lim_n \frac{m_n(2m_n^2+3m_n-2)}{3n^{3/2}}=\frac{2}{3} \lim_n \frac{q_n(q_n+1)(2q_n+1)}{6n^{3/2}}=\frac{2\sqrt{2}}{3} \lim_n \frac{2q_n}{\sqrt{n}}=2\sqrt{2} \lim_n \frac{2m_n}{\sqrt{n}}=2 \lim_{n\to \infty}\ p_n\sqrt{n}=\frac{4}{3}(\sqrt{2}-1)\approx 0.552284749831","['probability', 'combinatorics', 'recreational-mathematics', 'problem-solving']"
