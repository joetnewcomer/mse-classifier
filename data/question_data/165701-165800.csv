,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Finite additivity of Jordan measure [duplicate],Finite additivity of Jordan measure [duplicate],,"This question already has an answer here : Union/intersection of two Jordan measurable sets is Jordan measurable using definition (1 answer) Closed 2 years ago . Let $E, F\subset \mathbb{R^d}$ be Jordan measurable sets. I have to show that $E  \cup F$ is Jordan measurable, that is, $sup_{A \subset E \cup F,\space A\space elementary}m(A) = inf_{E \cup F \subset B,\space B\space elementary}m(B)$ , where m(A) is the elementary measure of an elementary set A. (Exercise 1.1.6 of Terence Tao's An Introduction to Measure Theory ) E,F are Jordan measurable iff for every $\epsilon > 0$ , there are sets $A_{1} \subset E \subset B_{1}$ , $A_{2} \subset F \subset B_{2}$ such that m( $B_{1}$ \ $A_{1}$ ) < $\epsilon$ and m( $B_{2}$ \ $A_{2}$ ) < $\epsilon$ .","This question already has an answer here : Union/intersection of two Jordan measurable sets is Jordan measurable using definition (1 answer) Closed 2 years ago . Let be Jordan measurable sets. I have to show that is Jordan measurable, that is, , where m(A) is the elementary measure of an elementary set A. (Exercise 1.1.6 of Terence Tao's An Introduction to Measure Theory ) E,F are Jordan measurable iff for every , there are sets , such that m( \ ) < and m( \ ) < .","E, F\subset \mathbb{R^d} E  \cup F sup_{A \subset E \cup F,\space A\space elementary}m(A) = inf_{E \cup F \subset B,\space B\space elementary}m(B) \epsilon > 0 A_{1} \subset E \subset B_{1} A_{2} \subset F \subset B_{2} B_{1} A_{1} \epsilon B_{2} A_{2} \epsilon",['real-analysis']
1,"$E_{n,k}= \bigcup_{m\ge n} \Big\{x : |f_m(x)-f(x)|>\frac{1}{k}\Big\}$.Show that $\lim_{n\to \infty}m(E_{n,k})=0$",.Show that,"E_{n,k}= \bigcup_{m\ge n} \Big\{x : |f_m(x)-f(x)|>\frac{1}{k}\Big\} \lim_{n\to \infty}m(E_{n,k})=0","Let m be the Lebesgue measure on $[0, 1]$ . Suppose that $\{f_n\}$ is a sequence of Borel measurable functions on $[0, 1]$ that converges almost everywhere to $f$ . For each $n, k$ let $$E_{n,k}= \bigcup_{m\ge n} \Big\{x : |f_m(x)-f(x)|>\frac{1}{k}\Big\}$$ Show that $\lim_{n\to \infty}m(E_{n,k})=0$ for each $k$ . Is the following correct? for each $k$ \begin{align} E_k =\lim_{n\to \infty} E_{n,k}= \bigcap_{n=1}^\infty \bigcup_{m\ge n}E_{n,k} =\bigcap_{n=1}^\infty\bigcup_{m\ge n}\Big\{x : |f_m(x)-f(x)|>\frac{1}{k}\Big\} \end{align} where $E_k$ is decreasing in $k$ (???????), but since $f_n \to f$ a.e. $$m(\bigcup_{k\ge 1}\bigcap_{n=1}^\infty \bigcup_{m\ge n}E_{n,k})=0$$ $$\bigcap_{n=1}^\infty \bigcup_{m\ge n}E_{n,k}\subset \bigcup_{k\ge 1}\bigcap_{n=1}^\infty \bigcup_{m\ge n}E_{n,k} \implies \lim_{n\to \infty}m(E_{n,k})=0$$","Let m be the Lebesgue measure on . Suppose that is a sequence of Borel measurable functions on that converges almost everywhere to . For each let Show that for each . Is the following correct? for each where is decreasing in (???????), but since a.e.","[0, 1] \{f_n\} [0, 1] f n, k E_{n,k}= \bigcup_{m\ge n} \Big\{x : |f_m(x)-f(x)|>\frac{1}{k}\Big\} \lim_{n\to \infty}m(E_{n,k})=0 k k \begin{align}
E_k =\lim_{n\to \infty} E_{n,k}= \bigcap_{n=1}^\infty \bigcup_{m\ge n}E_{n,k} =\bigcap_{n=1}^\infty\bigcup_{m\ge n}\Big\{x : |f_m(x)-f(x)|>\frac{1}{k}\Big\}
\end{align} E_k k f_n \to f m(\bigcup_{k\ge 1}\bigcap_{n=1}^\infty \bigcup_{m\ge n}E_{n,k})=0 \bigcap_{n=1}^\infty \bigcup_{m\ge n}E_{n,k}\subset \bigcup_{k\ge 1}\bigcap_{n=1}^\infty \bigcup_{m\ge n}E_{n,k} \implies \lim_{n\to \infty}m(E_{n,k})=0","['real-analysis', 'measure-theory', 'solution-verification']"
2,"Weak and weak* sequential convergence of measures, Grothendieck space","Weak and weak* sequential convergence of measures, Grothendieck space",,"Let $X$ be a set and $\Sigma$ be a $\sigma$ -algebra on $X$ . Consider the space $M_b(X, \Sigma)$ of bounded $\Sigma$ -measurable functions equipped with the supremum norm. Then $M_b(X, \Sigma)' = ba(\Sigma)$ is the space of finitely additive signed measures on $\Sigma$ with bounded variation. Denote by $ca(\Sigma) \subseteq ba(\Sigma)$ the subspace of countably additive measures. On the Banach space $ca(\Sigma)$ consider the weak topology (relative to $ca(\Sigma)'$ ) and the weak $^*$ topology relative to $M_b(X, \Sigma)$ . Then weak convergence implies weak $^*$ -convergence. However, it seems to me that sequential convergence in $ca(\Sigma)$ coincides for the weak and weak $^*$ topologies: Weak $^*$ -convergence $\mu_n \to^* \mu$ means $\mu_n f \to \mu f$ for all $f \in M_b(X, \Sigma)$ For weak convergence, it is known that $\mu_n \to \mu$ weakly if and only if $\mu_n(B) \to \mu(B)$ for all $B \in \Sigma$ [Dunford-Schwartz, ""Linear Operators"", IV.9.5]. So, by choosing $f = \chi_B \in M_b(X, \Sigma)$ we get $\mu_n \to^* \mu$ implies $\mu_n \to \mu$ . Is this somehow related to the notion of a Grothendieck space? A Banach space $E$ is called a Grothendieck space if in $E'$ weak $^*$ -convergence for sequences implies weak convergence (so that they then coincide).","Let be a set and be a -algebra on . Consider the space of bounded -measurable functions equipped with the supremum norm. Then is the space of finitely additive signed measures on with bounded variation. Denote by the subspace of countably additive measures. On the Banach space consider the weak topology (relative to ) and the weak topology relative to . Then weak convergence implies weak -convergence. However, it seems to me that sequential convergence in coincides for the weak and weak topologies: Weak -convergence means for all For weak convergence, it is known that weakly if and only if for all [Dunford-Schwartz, ""Linear Operators"", IV.9.5]. So, by choosing we get implies . Is this somehow related to the notion of a Grothendieck space? A Banach space is called a Grothendieck space if in weak -convergence for sequences implies weak convergence (so that they then coincide).","X \Sigma \sigma X M_b(X, \Sigma) \Sigma M_b(X, \Sigma)' = ba(\Sigma) \Sigma ca(\Sigma) \subseteq ba(\Sigma) ca(\Sigma) ca(\Sigma)' ^* M_b(X, \Sigma) ^* ca(\Sigma) ^* ^* \mu_n \to^* \mu \mu_n f \to \mu f f \in M_b(X, \Sigma) \mu_n \to \mu \mu_n(B) \to \mu(B) B \in \Sigma f = \chi_B \in M_b(X, \Sigma) \mu_n \to^* \mu \mu_n \to \mu E E' ^*","['functional-analysis', 'measure-theory']"
3,"Why $\frac{1}{x}$ is not Riemann integrable in $[0,1]$ but $\ln{x}$ is?",Why  is not Riemann integrable in  but  is?,"\frac{1}{x} [0,1] \ln{x}","In Rene Schilling - Measures, Integrals and Martingales , on page 94, Theorem 11.8 states that: A bounded function $f:[a,b]\rightarrow\mathbb{R}$ is Riemann integrable if, and only if, the   points in $(a,b)$ where f is discontinuous are a Lebesgue null set. Well, then I don't really understand why the function $f(x)=\frac{1}{x}$ is not Riemann integrable on $[0,1]$ (of course I actually do, cause it is not bounded there) but $g(x)=\ln{x}$ is. Why is happening this? $g$ is unbounded in the same interval but still Riemann integrable (it's integral is -1) Which differs from $f$ to $g$ ?","In Rene Schilling - Measures, Integrals and Martingales , on page 94, Theorem 11.8 states that: A bounded function is Riemann integrable if, and only if, the   points in where f is discontinuous are a Lebesgue null set. Well, then I don't really understand why the function is not Riemann integrable on (of course I actually do, cause it is not bounded there) but is. Why is happening this? is unbounded in the same interval but still Riemann integrable (it's integral is -1) Which differs from to ?","f:[a,b]\rightarrow\mathbb{R} (a,b) f(x)=\frac{1}{x} [0,1] g(x)=\ln{x} g f g","['measure-theory', 'lebesgue-integral', 'riemann-integration']"
4,Is $f(f^{-1}(B))$ a Borel set?,Is  a Borel set?,f(f^{-1}(B)),"Let $f:\Bbb R \to \Bbb R$ be a Borel measurable function, i.e. $f^{-1}(B)$ is a Borel set for any Borel set $B$ . For any Borel set $B\subset \Bbb R$ , is it true that $f(f^{-1}(B))$ is a Borel set? I know that even a continuous image of a Borel set need not be Borel, i.e. $f(A)$ need not be Borel for a Borel set $A$ . However, does anything change if $A$ has a very special form of $A=f^{-1}(B)$ ? I have a feeling that $f(f^{-1}(B))$ need not be a Borel set but I can't think of a good counterexample yet.","Let be a Borel measurable function, i.e. is a Borel set for any Borel set . For any Borel set , is it true that is a Borel set? I know that even a continuous image of a Borel set need not be Borel, i.e. need not be Borel for a Borel set . However, does anything change if has a very special form of ? I have a feeling that need not be a Borel set but I can't think of a good counterexample yet.",f:\Bbb R \to \Bbb R f^{-1}(B) B B\subset \Bbb R f(f^{-1}(B)) f(A) A A A=f^{-1}(B) f(f^{-1}(B)),"['real-analysis', 'probability', 'measure-theory']"
5,When is a measure a product measure?,When is a measure a product measure?,,"Let $(\Omega_1, \mathcal{A_1})$ and $(\Omega_2, \mathcal{A}_2)$ be two measurable spaces and lets consider the measure space $(\Omega_1\times \Omega_2, \mathcal{A}_1\times \mathcal{A}_2, \mu_p)$ . Under which conditions is it possible to factorize $\mu_p$ meaning that we have $\mu_p=\mu_1\times\mu_2$ where $\mu_1, \mu_2$ are measure on the spaces mentioned. For example, I know that if $\Omega_1=\mathbb{R}^n,\Omega_2=\mathbb{R}^m$ and $\mathcal{A}_1=\mathcal{B}(\mathbb{R}^n), \mathcal{A}_2=\mathcal{B}(\mathbb{R}^m)$ we can write the $n$ -dimensional Lebesgue measure as the product on the individual spaces, which is $\lambda^{m+n}=\lambda^n\cdot\lambda^m$ I also know that it is not always possible if we pick the measurable spaces arbitrarily. So is it always possible if we have something like $\Omega_1=X^n, \Omega_2=X^m$ and create some $\sigma$ -algebras on $X$ in the same way , e.g. the Borel algebra? What in general do I have to assume for this to work?","Let and be two measurable spaces and lets consider the measure space . Under which conditions is it possible to factorize meaning that we have where are measure on the spaces mentioned. For example, I know that if and we can write the -dimensional Lebesgue measure as the product on the individual spaces, which is I also know that it is not always possible if we pick the measurable spaces arbitrarily. So is it always possible if we have something like and create some -algebras on in the same way , e.g. the Borel algebra? What in general do I have to assume for this to work?","(\Omega_1, \mathcal{A_1}) (\Omega_2, \mathcal{A}_2) (\Omega_1\times \Omega_2, \mathcal{A}_1\times \mathcal{A}_2, \mu_p) \mu_p \mu_p=\mu_1\times\mu_2 \mu_1, \mu_2 \Omega_1=\mathbb{R}^n,\Omega_2=\mathbb{R}^m \mathcal{A}_1=\mathcal{B}(\mathbb{R}^n), \mathcal{A}_2=\mathcal{B}(\mathbb{R}^m) n \lambda^{m+n}=\lambda^n\cdot\lambda^m \Omega_1=X^n, \Omega_2=X^m \sigma X",['measure-theory']
6,"Non-negative, continuous function $f \in L^1(\mathbb{R})$ that is unbounded?","Non-negative, continuous function  that is unbounded?",f \in L^1(\mathbb{R}),"I'm trying to construct a non-negative, continuous function $f \in L^1(\mathbb{R})$ such that $\limsup\limits_{x\to \infty} f(x) = \infty.$ If someone could look over my attempt below, I would appreciate it! Consider $$g_n(x) = \begin{cases}   2n^4x-2n^5+n & \text{if $n-\frac{1}{2n^3}<x<n$}   \\  -2n^4x+2n^5+n & \text{if $n \leq x<n+\frac{1}{2n^3}$} \\ 0 & \text{otherwise} \end{cases}$$ My idea here was to construct a function with triangular bumps at each $n=1,2,3,...$ with height $n$ and base width $\frac{1}{n^3}$ . We note that the $g_n$ are continuous, non-negative and have support $[n-\frac{1}{2n^3}, n+\frac{1}{2n^3}]$ . The supremum for each $g_n$ is $n$ . Moreover, its integral is finite and given by $\frac{1}{2n^2}.$ Now, we consider the sum $$G(x) :=\sum_{n=1}^{\infty}g_n(x)=\sum_{n=1}^{\infty}(2n^4x-2n^5+n)\chi_{(n-1/2n^3, n)}(x)+(-2n^4x+2n^5+n)\chi_{[n, n+1/2n^3)}(x)$$ We note that $G(x)$ is also continuous and non-negative. Its $L^1$ norm is given by $$\sum_{n=1}^{\infty}\frac{1}{2n^2} = \frac{\pi^2}{12}<\infty$$ so $G \in L^1.$ However, the heights of the function increase without bound, so we have that $\limsup\limits_{x\to \infty} f(x) = \infty.$ G(x) should look like this:","I'm trying to construct a non-negative, continuous function such that If someone could look over my attempt below, I would appreciate it! Consider My idea here was to construct a function with triangular bumps at each with height and base width . We note that the are continuous, non-negative and have support . The supremum for each is . Moreover, its integral is finite and given by Now, we consider the sum We note that is also continuous and non-negative. Its norm is given by so However, the heights of the function increase without bound, so we have that G(x) should look like this:","f \in L^1(\mathbb{R}) \limsup\limits_{x\to \infty} f(x) = \infty. g_n(x) = \begin{cases}
  2n^4x-2n^5+n & \text{if n-\frac{1}{2n^3}<x<n}   \\
 -2n^4x+2n^5+n & \text{if n \leq x<n+\frac{1}{2n^3}} \\
0 & \text{otherwise}
\end{cases} n=1,2,3,... n \frac{1}{n^3} g_n [n-\frac{1}{2n^3}, n+\frac{1}{2n^3}] g_n n \frac{1}{2n^2}. G(x) :=\sum_{n=1}^{\infty}g_n(x)=\sum_{n=1}^{\infty}(2n^4x-2n^5+n)\chi_{(n-1/2n^3, n)}(x)+(-2n^4x+2n^5+n)\chi_{[n, n+1/2n^3)}(x) G(x) L^1 \sum_{n=1}^{\infty}\frac{1}{2n^2} = \frac{\pi^2}{12}<\infty G \in L^1. \limsup\limits_{x\to \infty} f(x) = \infty.","['real-analysis', 'functional-analysis', 'measure-theory', 'proof-verification']"
7,Does $m^{***}(A)=m^*(A)$ imply that $A$ is measurable?,Does  imply that  is measurable?,m^{***}(A)=m^*(A) A,"I am trying to solve an exercise from Royden's Real Analysis, 4th ed. For any set $A \subseteq \mathbb{R}$ , define $m^{***}(A)=sup\{m^*(F):F\subseteq A$ is a closed set $\}$ . How is this set function $m^{***}$ related to outer measure $m^*$ ? I am aware that this exercise Relation between $m^{***}$ with $m^*$? has been discussed before on SE, yet I do not find it satisfactory because I am not assuming per se that $A$ is measurable. Relevant definitions and theorems Keep in mind that Royden defines outer measure $m^*(A)=inf\{\sum _{i=1}^ \infty l(I_i):$ $I_1,I_2,...$ is a sequence of nonempty, bounded, open intervals whose union covers $A$ }. This is defined regardless of whether $A$ is measurable or not. It has also been proven that we have five equivalent definitions of measurability: The following are equivalent: $\forall A \subseteq \mathbb{R}[m^*(A)=m^*(A\cap E)+m^*(A \cap E^c)]$ $\forall \epsilon >0\exists$ open set $O \supseteq E$ [ $m^*(O-E)< \epsilon]$ $\exists G_δ$ set $G \supseteq E[m^*(G-E)=0]$ $\forall \epsilon >0\exists$ closed set $F \subseteq E$ [ $m^*(E-F)< \epsilon]$ $\exists F_σ$ set $F \subseteq E[m^*(E-F)=0]$ Now we tackle the actual problem... My progress so far We always have $m^{***}(A) \leq m^*(A)$ obviously. I have formulated the following conjecture: $m^{***}(A)=m^*(A)$ if and only if $A$ is measurable. I have shown that $A$ measurable implies $m^{***}(A)=m^*(A)$ . For the other direction, I have managed to show that $m^{***}(A)=m^*(A)$ implies $A$ is measurable in the special case that $m^*(A)< \infty$ . But if $m^*(A)= \infty$ , I don't know how to show it. I was able to prove the finite case by finding some $F_δ$ set $F\subseteq A$ having the same measure as $A$ , observing that $m^*(A)=m^*(A-F)+m^*(F)=m^*(A-F)+m^*(A)$ , and subtracting $m^*(A)$ from each side to obtain $m^*(A-F)=0$ (meaning that $A$ is meaurable). If $m^*(A)= \infty$ , I don't know what to since I obviously can't subtract $\infty$ from both sides.","I am trying to solve an exercise from Royden's Real Analysis, 4th ed. For any set , define is a closed set . How is this set function related to outer measure ? I am aware that this exercise Relation between $m^{***}$ with $m^*$? has been discussed before on SE, yet I do not find it satisfactory because I am not assuming per se that is measurable. Relevant definitions and theorems Keep in mind that Royden defines outer measure is a sequence of nonempty, bounded, open intervals whose union covers }. This is defined regardless of whether is measurable or not. It has also been proven that we have five equivalent definitions of measurability: The following are equivalent: open set [ set closed set [ set Now we tackle the actual problem... My progress so far We always have obviously. I have formulated the following conjecture: if and only if is measurable. I have shown that measurable implies . For the other direction, I have managed to show that implies is measurable in the special case that . But if , I don't know how to show it. I was able to prove the finite case by finding some set having the same measure as , observing that , and subtracting from each side to obtain (meaning that is meaurable). If , I don't know what to since I obviously can't subtract from both sides.","A \subseteq \mathbb{R} m^{***}(A)=sup\{m^*(F):F\subseteq A \} m^{***} m^* A m^*(A)=inf\{\sum _{i=1}^ \infty l(I_i): I_1,I_2,... A A \forall A \subseteq \mathbb{R}[m^*(A)=m^*(A\cap E)+m^*(A \cap E^c)] \forall \epsilon >0\exists O \supseteq E m^*(O-E)< \epsilon] \exists G_δ G \supseteq E[m^*(G-E)=0] \forall \epsilon >0\exists F \subseteq E m^*(E-F)< \epsilon] \exists F_σ F \subseteq E[m^*(E-F)=0] m^{***}(A) \leq m^*(A) m^{***}(A)=m^*(A) A A m^{***}(A)=m^*(A) m^{***}(A)=m^*(A) A m^*(A)< \infty m^*(A)= \infty F_δ F\subseteq A A m^*(A)=m^*(A-F)+m^*(F)=m^*(A-F)+m^*(A) m^*(A) m^*(A-F)=0 A m^*(A)= \infty \infty","['real-analysis', 'measure-theory', 'lebesgue-measure']"
8,Strict Markov's inequality,Strict Markov's inequality,,"Let $(X,\mathcal{A},\mu)$ be a measure space. If $f$ is a non-negative measurable function and $a>0$ , then we have Markov's inequality: $$\mu\left( \{f\geqslant a\} \right)\leqslant \frac1a \int_X f\,d\mu.$$ In an exercise, I have to prove the same equality for $\mu(\{f>a\})$ . Could someone verify my proof? $$\mu(\{f>a \})=\mu\left(\bigcup_{n\geqslant 1}\left\{f\geqslant a+\tfrac1n \right\}\right)=\lim_{n\to\infty} \mu\left(\left\{f\geqslant a+\tfrac1n \right\}\right).$$ Well, for all $n\geqslant 1$ , we have Markov's inequality from above, so when we take the limit $\lim_{n\to\infty}$ on both sides, we obtain $$\lim_{n\to\infty} \mu\left(\left\{f\geqslant a+\tfrac1n \right\}\right)\leqslant \lim_{n\to\infty}\frac{1}{a+\frac1n}\int_X f\,d\mu=\frac{1}{a}\int_X f\,d\mu.$$","Let be a measure space. If is a non-negative measurable function and , then we have Markov's inequality: In an exercise, I have to prove the same equality for . Could someone verify my proof? Well, for all , we have Markov's inequality from above, so when we take the limit on both sides, we obtain","(X,\mathcal{A},\mu) f a>0 \mu\left( \{f\geqslant a\} \right)\leqslant \frac1a \int_X f\,d\mu. \mu(\{f>a\}) \mu(\{f>a \})=\mu\left(\bigcup_{n\geqslant 1}\left\{f\geqslant a+\tfrac1n \right\}\right)=\lim_{n\to\infty} \mu\left(\left\{f\geqslant a+\tfrac1n \right\}\right). n\geqslant 1 \lim_{n\to\infty} \lim_{n\to\infty} \mu\left(\left\{f\geqslant a+\tfrac1n \right\}\right)\leqslant \lim_{n\to\infty}\frac{1}{a+\frac1n}\int_X f\,d\mu=\frac{1}{a}\int_X f\,d\mu.",['measure-theory']
9,Is f continuous? lower semicontinuous? upper semicontinuous?,Is f continuous? lower semicontinuous? upper semicontinuous?,,"I'm learning analysis on my own, and I'm having difficulties. Let $$\mu_{x_0}(E)=\begin{cases} 1 & x_0\in E \\ 0 & x_0\not\in E \end{cases}$$ and $V= B_r(x_0)=\{x|d(x,x_0)<r\}$ . Is $f(x)=\mu(V+x)$ continuous? lower semicontinuous? upper semicontinuous? My attempt: So $V+x=B_r(x_0+x)=\{x|d(x,x_0+x)<r\},$ $d(x,x_0+x) \leq d(x,x)+d(x_0,x) < r$ so $x_0 \not\in V+x,$ so $\mu(V+x)=0=f(x)$ How do we proceed?","I'm learning analysis on my own, and I'm having difficulties. Let and . Is continuous? lower semicontinuous? upper semicontinuous? My attempt: So so so How do we proceed?","\mu_{x_0}(E)=\begin{cases} 1 & x_0\in E \\ 0 & x_0\not\in E \end{cases} V= B_r(x_0)=\{x|d(x,x_0)<r\} f(x)=\mu(V+x) V+x=B_r(x_0+x)=\{x|d(x,x_0+x)<r\}, d(x,x_0+x) \leq d(x,x)+d(x_0,x) < r x_0 \not\in V+x, \mu(V+x)=0=f(x)","['real-analysis', 'measure-theory']"
10,"$sup \{ \mu (B): B \subset A, B \in K, \mu(B) < \infty \}$ is a measure",is a measure,"sup \{ \mu (B): B \subset A, B \in K, \mu(B) < \infty \}","I'd like to prove that $\mu(A)^* = sup\{\mu (B): B \subset A, B \in K, \mu(B) < \infty \}$ is a measure, where $(X, K, \mu)$ is a measure room and $\mu^*: K \rightarrow [0; \infty]$ . Proof: It's clear that $\mu(\emptyset) = 0$ Then, I would continue as follows: Let $A$ be such that $\mu^*(A) < \infty$ and let $B \subset A$ be a measurable set such that $\mu(B) = \mu^*(A).$ Then $$\mu^*(A \setminus B) = \mu^*(A) - \mu^*(B) = 0.$$ For the previous equalities to be true, we need the assumption $\mu^*(A) < \infty$ . This is in general not true otherwise, indeed one can consider $A = \mathbb{R}$ and $B = (0,\infty)$ . Then $\mu(A) = \mu(B) = \infty$ , but clearly $$\mu(A \setminus B) = \mu((-\infty,0)) = \infty.$$ This shows that $A \setminus B$ is measurable since by the Caratheodory condition sets of outer measure $0$ are measurable. To conclude the argument it is enough to notice that $A$ belongs to the $\sigma$ -algebra of measurable sets since it can be written as the union of two measurable sets: $$A = B \cup (A \setminus B).$$ The result is not true in general if $\mu^*(A) = \infty$ . Indeed, let $C \subset (-1,0)$ be a non -measurable set and consider $B = (0,\infty)$ and $A = B \cup C$ . Is this a plausible proof?","I'd like to prove that is a measure, where is a measure room and . Proof: It's clear that Then, I would continue as follows: Let be such that and let be a measurable set such that Then For the previous equalities to be true, we need the assumption . This is in general not true otherwise, indeed one can consider and . Then , but clearly This shows that is measurable since by the Caratheodory condition sets of outer measure are measurable. To conclude the argument it is enough to notice that belongs to the -algebra of measurable sets since it can be written as the union of two measurable sets: The result is not true in general if . Indeed, let be a non -measurable set and consider and . Is this a plausible proof?","\mu(A)^* = sup\{\mu (B): B \subset A, B \in K, \mu(B) < \infty \} (X, K, \mu) \mu^*: K \rightarrow [0; \infty] \mu(\emptyset) = 0 A \mu^*(A) < \infty B \subset A \mu(B) = \mu^*(A). \mu^*(A \setminus B) = \mu^*(A) - \mu^*(B) = 0. \mu^*(A) < \infty A = \mathbb{R} B = (0,\infty) \mu(A) = \mu(B) = \infty \mu(A \setminus B) = \mu((-\infty,0)) = \infty. A \setminus B 0 A \sigma A = B \cup (A \setminus B). \mu^*(A) = \infty C \subset (-1,0) B = (0,\infty) A = B \cup C","['measure-theory', 'proof-verification']"
11,Intersection/union of measurable and nonmeasurable sets,Intersection/union of measurable and nonmeasurable sets,,"Given a (Lebesgue) measurable set $A$ and a nonmeasurable set $B$ , when is $A \cap B$ measurable? Nonmeasurable? I think I know a case where the intersection turns out to be nonmeasurable (it involves the Cantor-Lebesgue function). I assume there are trivial cases (e.g. intersecting two disjoint sets), but I'm curious about more general results. Also, what about the union of measurable and nonmeasurable sets? I apologize in advance if this is a duplicate; I looked around MSE for a bit so to my knowledge it is not.","Given a (Lebesgue) measurable set and a nonmeasurable set , when is measurable? Nonmeasurable? I think I know a case where the intersection turns out to be nonmeasurable (it involves the Cantor-Lebesgue function). I assume there are trivial cases (e.g. intersecting two disjoint sets), but I'm curious about more general results. Also, what about the union of measurable and nonmeasurable sets? I apologize in advance if this is a duplicate; I looked around MSE for a bit so to my knowledge it is not.",A B A \cap B,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
12,Proving Egorov's Theorem with Dini's Theorem?,Proving Egorov's Theorem with Dini's Theorem?,,"Egorov's theorem states: let $f_n$ be a sequence of measurable functions that converges pointwise to a measurable function $f$ on domain $E$ with $m(E)<\infty$ then there exists $E_0\subset E$ such that the $f_n$ converges uniformly to $f$ on $E_0$ and $m(E \setminus E_0)<\epsilon$ My proof attempt using Dini's theorem: By theorem 3.4 in Real Analysis by Stein & Shakarchi if $E$ is measurable, which it is in above case, there exists a compact set $K \subset E$ with $m(E \setminus K)<\epsilon$ . The proof of this is pretty simple it involves taking an inner approximation of $E$ by a closed set and then intersecting that closed set by an arbitrarily large closed, bounded ball. Let $E_0=K$ , since $K$ is compact and the $f_n$ converge pointwise on all of $K$ we can invoke Dini's theorem to get uniform convergence on $K$ if we can guarantee the $f_n$ are monotonic. Is there any way the sequence can be manipulated so we can guarantee they are monotonic? Is all the effort in proving Egorov's theorem really about dealing with non-monotic sequences?","Egorov's theorem states: let be a sequence of measurable functions that converges pointwise to a measurable function on domain with then there exists such that the converges uniformly to on and My proof attempt using Dini's theorem: By theorem 3.4 in Real Analysis by Stein & Shakarchi if is measurable, which it is in above case, there exists a compact set with . The proof of this is pretty simple it involves taking an inner approximation of by a closed set and then intersecting that closed set by an arbitrarily large closed, bounded ball. Let , since is compact and the converge pointwise on all of we can invoke Dini's theorem to get uniform convergence on if we can guarantee the are monotonic. Is there any way the sequence can be manipulated so we can guarantee they are monotonic? Is all the effort in proving Egorov's theorem really about dealing with non-monotic sequences?",f_n f E m(E)<\infty E_0\subset E f_n f E_0 m(E \setminus E_0)<\epsilon E K \subset E m(E \setminus K)<\epsilon E E_0=K K f_n K K f_n,"['real-analysis', 'measure-theory']"
13,The density of simple functions in the intersection of mixed norm spaces,The density of simple functions in the intersection of mixed norm spaces,,"Problem 1. Let $\mathcal{A}([0,1] \times [0,1])$ be the set of all measurable functions $f:[0,1] \times [0,1] \to \mathbb{C}$ that satisfy the conditions $$ \alpha_1(f) = \operatorname*{ess sup}_{y \in [0,1]} \int\limits_{0}^{1} \lvert f(x,y) \rvert \, dx < \infty, $$ $$ \alpha_2(f) = \operatorname*{ess sup}_{x \in [0,1]} \int\limits_{0}^{1} \lvert f(x,y) \rvert \, dy <\infty. $$ One can prove that $\mathcal{A}([0,1] \times [0,1])$ is a Banach space with the norm $$ \lVert f \rVert_{\mathcal{A}([0,1] \times [0,1])} = \max \bigl(\alpha_{1}(f), \alpha_{2}(f) \bigr). $$ Question 1. Consider the set $\Phi([0,1] \times [0,1])$ of a simple functions of the form $$ \phi(x,y) = \sum_{i=1}^{N} \lambda_i \, \chi_{E_i}(x,y), $$ where $\lambda_1, \ldots \lambda_N, \in \mathbb{C}$ is a sequence of complex numbers, $E_1, \ldots, E_N$ is a sequence of disjoint measurable subsets of a set $[0,1] \times [0,1]$ , $\chi_{E_i}$ is the indicator function of the set $E_i$ . Is $\Phi([0,1] \times [0,1])$ dense in $\mathcal{A}([0,1] \times [0,1])$ ? Question 2. Consider the set $\Psi([0,1] \times [0,1])$ of a simple functions of the form $$ \psi(x,y) = \sum_{i=1}^{N} \lambda_i \, \chi_{X_i}(x) \, \chi_{Y_i}(y), $$ where $X_1, \ldots, X_N$ and $Y_1, \ldots, Y_N$ are sequences of disjoint measurable subsets of a set $[0,1]$ . Is $\Psi([0,1] \times [0,1])$ dense in $\mathcal{A}([0,1] \times [0,1])$ ? Problem 2. Let $\mathcal{A}(\mathbb{R} \times \mathbb{R})$ be the set of all measurable functions $f:\mathbb{R} \times \mathbb{R} \to \mathbb{C}$ that satisfy the conditions $$ \alpha_1(f)  = \operatorname*{ess sup}_{y \in \mathbb{R}} \int\limits_{-\infty}^{\infty} \lvert f(x,y) \rvert \, dx < \infty, $$ $$ \alpha_2(f) = \operatorname*{ess sup}_{x \in \mathbb{R}} \int\limits_{-\infty}^{\infty} \lvert f(x,y) \rvert \, dy <\infty. $$ It is not hard to show that $\mathcal{A}(\mathbb{R} \times \mathbb{R})$ is a Banach space with the norm \begin{equation} \lVert f \rVert_{\mathcal{A}(\mathbb{R} \times \mathbb{R})} = \max \bigl(\alpha_{1}(f), \alpha_{2}(f) \bigr). \end{equation} Question 3. Similar to questions 1 and 2: are $\Phi(\mathbb{R} \times \mathbb{R})$ and $\Psi(\mathbb{R} \times \mathbb{R})$ dense in $\mathcal{A}(\mathbb{R} \times \mathbb{R})$ ? As I can figure it out, simple functions are not dense in the Banach space of functions $f:\mathbb{R} \times \mathbb{R} \to \mathbb{C}$ that satisfy the condition $\alpha_1(f) < \infty$ only. (See A. Benedek, R. Panzone. The spaces $L^p$ with mixed norm, Duke Mathematical Journal, Volume 28, issue 3, 1961, p. 308), but I failed to understand why. And what about the space $\mathcal{A}(\mathbb{R} \times \mathbb{R})$ ? My attempt to answer question 1. Let $E \subset [0,1] \times [0,1]$ , and define \begin{equation*} E^x = \{y \in [0,1]:\: (x,y) \in E \}, \end{equation*} \begin{equation*} E^y = \{x \in [0,1]:\: (x,y) \in E \}. \end{equation*} Since for any $\phi \in \Phi([0,1] \times [0,1])$ \begin{equation*} \alpha_{1} (\phi) = \operatorname*{ess sup}_{y \in [0,1]} \sum_{i=1}^{N} \lambda_i \,  \mu(E_i^y), \quad \alpha_{2} (\phi) = \operatorname*{ess sup}_{x \in [0,1]} \sum_{i=1}^{N} \lambda_i \,  \mu(E_i^x), \end{equation*} where $\mu$ is the measure on $[0,1]$ , then $\Phi([0,1] \times [0,1]) \subset \mathcal{A}([0,1] \times [0,1])$ . Suppose $f^+ \in \mathcal{A}([0,1] \times [0,1])$ , $f^+(x,y) \geqslant 0$ for any $x,y \in [0,1]$ and define $$ \phi_m(x,y) = \begin{cases} \frac{k}{2^m}, &\text{if} \ \frac{k}{2^m} \leqslant f^+(x,y) <  \frac{k+1}{2^m}, \ k=0,1,\ldots, 2^{m}m - 1, \\ m, &\text{if} \ f^+(x,y) \geqslant m. \end{cases} $$ Then we have $$ \forall m \in \mathbb{N}: \quad \phi_m \in \Phi([0,1] \times [0,1]), $$ $$\forall x,y \in [0,1]: \quad \phi_1(x,y) \leqslant \phi_2(x,y) \leqslant \ldots \leqslant f^+(x,y), $$ and \begin{equation*} \forall x,y \in [0,1]: \quad f^+(x,y) = \lim\limits_{m \to \infty} \phi_m(x,y). \end{equation*} From conditions $\alpha_1(f^+) < \infty$ and $\alpha_2(f^+) < \infty$ it follows that for any fixed $y \in [0,1]$ the function $f^+(\cdot, y)$ is integrable and for any fixed $x \in [0,1]$ the function $f^+(x, \cdot)$ is integrable too. Hence, the dominated convergence theorem shows that the sequences of functions \begin{equation*} g^{1}_m(y) = \int\limits_{0}^{1} \left( f^+(x, y) - \phi_m(x,y) \right) dx, \quad y \in [0,1], \end{equation*} \begin{equation*} g^{2}_m(x) = \int\limits_{0}^{1} \left( f^+(x, y) - \phi_m(x,y) \right) dy, \quad x \in [0,1], \end{equation*} converges to $0$ pointwise. Now using Egorov's theorem we can conclude that the sequences $g^{1}_m$ and $g^{2}_m$ converges to $0$ almost uniform but not uniform. Any help would be greatly appreciated!","Problem 1. Let be the set of all measurable functions that satisfy the conditions One can prove that is a Banach space with the norm Question 1. Consider the set of a simple functions of the form where is a sequence of complex numbers, is a sequence of disjoint measurable subsets of a set , is the indicator function of the set . Is dense in ? Question 2. Consider the set of a simple functions of the form where and are sequences of disjoint measurable subsets of a set . Is dense in ? Problem 2. Let be the set of all measurable functions that satisfy the conditions It is not hard to show that is a Banach space with the norm Question 3. Similar to questions 1 and 2: are and dense in ? As I can figure it out, simple functions are not dense in the Banach space of functions that satisfy the condition only. (See A. Benedek, R. Panzone. The spaces with mixed norm, Duke Mathematical Journal, Volume 28, issue 3, 1961, p. 308), but I failed to understand why. And what about the space ? My attempt to answer question 1. Let , and define Since for any where is the measure on , then . Suppose , for any and define Then we have and From conditions and it follows that for any fixed the function is integrable and for any fixed the function is integrable too. Hence, the dominated convergence theorem shows that the sequences of functions converges to pointwise. Now using Egorov's theorem we can conclude that the sequences and converges to almost uniform but not uniform. Any help would be greatly appreciated!","\mathcal{A}([0,1] \times [0,1]) f:[0,1] \times [0,1] \to \mathbb{C} 
\alpha_1(f)
=
\operatorname*{ess sup}_{y \in [0,1]}
\int\limits_{0}^{1}
\lvert f(x,y) \rvert \,
dx
< \infty,
 
\alpha_2(f)
=
\operatorname*{ess sup}_{x \in [0,1]}
\int\limits_{0}^{1}
\lvert f(x,y) \rvert \,
dy
<\infty.
 \mathcal{A}([0,1] \times [0,1]) 
\lVert f \rVert_{\mathcal{A}([0,1] \times [0,1])}
=
\max \bigl(\alpha_{1}(f), \alpha_{2}(f) \bigr).
 \Phi([0,1] \times [0,1]) 
\phi(x,y)
=
\sum_{i=1}^{N}
\lambda_i \, \chi_{E_i}(x,y),
 \lambda_1, \ldots \lambda_N, \in \mathbb{C} E_1, \ldots, E_N [0,1] \times [0,1] \chi_{E_i} E_i \Phi([0,1] \times [0,1]) \mathcal{A}([0,1] \times [0,1]) \Psi([0,1] \times [0,1]) 
\psi(x,y)
=
\sum_{i=1}^{N}
\lambda_i \, \chi_{X_i}(x) \, \chi_{Y_i}(y),
 X_1, \ldots, X_N Y_1, \ldots, Y_N [0,1] \Psi([0,1] \times [0,1]) \mathcal{A}([0,1] \times [0,1]) \mathcal{A}(\mathbb{R} \times \mathbb{R}) f:\mathbb{R} \times \mathbb{R} \to \mathbb{C} 
\alpha_1(f) 
=
\operatorname*{ess sup}_{y \in \mathbb{R}}
\int\limits_{-\infty}^{\infty}
\lvert f(x,y) \rvert \,
dx
< \infty,
 
\alpha_2(f)
=
\operatorname*{ess sup}_{x \in \mathbb{R}}
\int\limits_{-\infty}^{\infty}
\lvert f(x,y) \rvert \,
dy
<\infty.
 \mathcal{A}(\mathbb{R} \times \mathbb{R}) \begin{equation}
\lVert f \rVert_{\mathcal{A}(\mathbb{R} \times \mathbb{R})}
=
\max \bigl(\alpha_{1}(f), \alpha_{2}(f) \bigr).
\end{equation} \Phi(\mathbb{R} \times \mathbb{R}) \Psi(\mathbb{R} \times \mathbb{R}) \mathcal{A}(\mathbb{R} \times \mathbb{R}) f:\mathbb{R} \times \mathbb{R} \to \mathbb{C} \alpha_1(f) < \infty L^p \mathcal{A}(\mathbb{R} \times \mathbb{R}) E \subset [0,1] \times [0,1] \begin{equation*}
E^x = \{y \in [0,1]:\: (x,y) \in E \},
\end{equation*} \begin{equation*}
E^y = \{x \in [0,1]:\: (x,y) \in E \}.
\end{equation*} \phi \in \Phi([0,1] \times [0,1]) \begin{equation*}
\alpha_{1} (\phi)
=
\operatorname*{ess sup}_{y \in [0,1]}
\sum_{i=1}^{N}
\lambda_i \,  \mu(E_i^y),
\quad
\alpha_{2} (\phi)
=
\operatorname*{ess sup}_{x \in [0,1]}
\sum_{i=1}^{N}
\lambda_i \,  \mu(E_i^x),
\end{equation*} \mu [0,1] \Phi([0,1] \times [0,1]) \subset \mathcal{A}([0,1] \times [0,1]) f^+ \in \mathcal{A}([0,1] \times [0,1]) f^+(x,y) \geqslant 0 x,y \in [0,1] 
\phi_m(x,y) =
\begin{cases}
\frac{k}{2^m},
&\text{if} \
\frac{k}{2^m} \leqslant f^+(x,y) <  \frac{k+1}{2^m}, \
k=0,1,\ldots, 2^{m}m - 1,
\\
m,
&\text{if} \
f^+(x,y) \geqslant m.
\end{cases}
 
\forall m \in \mathbb{N}: \quad \phi_m \in \Phi([0,1] \times [0,1]),
 \forall x,y \in [0,1]: \quad \phi_1(x,y) \leqslant \phi_2(x,y) \leqslant \ldots \leqslant f^+(x,y),
 \begin{equation*}
\forall x,y \in [0,1]: \quad f^+(x,y) = \lim\limits_{m \to \infty} \phi_m(x,y).
\end{equation*} \alpha_1(f^+) < \infty \alpha_2(f^+) < \infty y \in [0,1] f^+(\cdot, y) x \in [0,1] f^+(x, \cdot) \begin{equation*}
g^{1}_m(y) =
\int\limits_{0}^{1}
\left(
f^+(x, y) - \phi_m(x,y)
\right)
dx,
\quad
y \in [0,1],
\end{equation*} \begin{equation*}
g^{2}_m(x) =
\int\limits_{0}^{1}
\left(
f^+(x, y) - \phi_m(x,y)
\right)
dy,
\quad x \in [0,1],
\end{equation*} 0 g^{1}_m g^{2}_m 0","['real-analysis', 'functional-analysis', 'measure-theory', 'lp-spaces']"
14,weak derivative of Lipschitz function is Borel measurable,weak derivative of Lipschitz function is Borel measurable,,"In Krylov's book , he asserts that ""the generalized derivative $u_x$ of a function $u$ continuous in $\Omega\subset \mathbb{R}^n$ does not exceed a constant $N_1$ almost everywhere if and only if the function $u$ satisfies the Lipschitz condition in $\Omega$ with the same constant"". Here he requires a generalized derivative must be Borel measurable as follows: I knew that a Lipschitz function on $\mathbb{R}^n$ is in $W^{1,\infty}(\Omega)$ and is differentiable Lebesgue almost everywhere. But usually $W^{1,\infty}$ means Lebesuge measurable weak derivatives. Could you suggest any reference which shows a Lipschitz function has a Borel measurable weak derivative? I guess one can show it by using a weak convergence argument and the fact that $L^2(\Omega, \mathcal{B}(\Omega), \mathcal{L}_n)$ is a Hilbert space, where $\mathcal{L}_n$ denotes the Lebesgue measure on $\mathbb{R}^n$ .  But I felt that this should be a fairly standard result and must have been shown somewhere.","In Krylov's book , he asserts that ""the generalized derivative of a function continuous in does not exceed a constant almost everywhere if and only if the function satisfies the Lipschitz condition in with the same constant"". Here he requires a generalized derivative must be Borel measurable as follows: I knew that a Lipschitz function on is in and is differentiable Lebesgue almost everywhere. But usually means Lebesuge measurable weak derivatives. Could you suggest any reference which shows a Lipschitz function has a Borel measurable weak derivative? I guess one can show it by using a weak convergence argument and the fact that is a Hilbert space, where denotes the Lebesgue measure on .  But I felt that this should be a fairly standard result and must have been shown somewhere.","u_x u \Omega\subset \mathbb{R}^n N_1 u \Omega \mathbb{R}^n W^{1,\infty}(\Omega) W^{1,\infty} L^2(\Omega, \mathcal{B}(\Omega), \mathcal{L}_n) \mathcal{L}_n \mathbb{R}^n","['measure-theory', 'sobolev-spaces', 'lipschitz-functions']"
15,Is this enough to prove that every continuous function $u:\mathbb{R}\rightarrow \mathbb{R}$ is measurable?,Is this enough to prove that every continuous function  is measurable?,u:\mathbb{R}\rightarrow \mathbb{R},"In one exercise I am asked to prove that every continuous function $u:\mathbb{R}\rightarrow \mathbb{R}$ is $\mathcal{B}/\mathcal{B}$ - measurable. I have an answer for this question but it does not look the same as the suggested one, so I would like to know if I am doing something wrong or the two are equivalent. My answer goes as follows: We know that for every continuous function we have that the pre-image of an open set is again an open set. a function $u$ is $\mathcal{B}/\mathcal{B}$ - measurable  iff $u^{-1}(B)\in \mathcal{B},  \forall B\in\mathcal{O}$ , where $\mathcal{B}$ is the Borel sigma algebra, and $\mathcal{O}$ is the family of open sets on $\mathbb{R}$ ( a generator of the Borel sigma-algebra). Hence I take an open set $B\in \mathcal{O}$ and by the first point we have that $u^{-1}(B)$ is an open set. It follows that $ u^{-1}(B)\in \mathcal{O}\subset \mathcal{B}$ . Is this enough as a prove? Thanks in advance.","In one exercise I am asked to prove that every continuous function is - measurable. I have an answer for this question but it does not look the same as the suggested one, so I would like to know if I am doing something wrong or the two are equivalent. My answer goes as follows: We know that for every continuous function we have that the pre-image of an open set is again an open set. a function is - measurable  iff , where is the Borel sigma algebra, and is the family of open sets on ( a generator of the Borel sigma-algebra). Hence I take an open set and by the first point we have that is an open set. It follows that . Is this enough as a prove? Thanks in advance.","u:\mathbb{R}\rightarrow \mathbb{R} \mathcal{B}/\mathcal{B} u \mathcal{B}/\mathcal{B} u^{-1}(B)\in \mathcal{B},  \forall B\in\mathcal{O} \mathcal{B} \mathcal{O} \mathbb{R} B\in \mathcal{O} u^{-1}(B)  u^{-1}(B)\in \mathcal{O}\subset \mathcal{B}","['measure-theory', 'proof-verification']"
16,A Baire measure with different extensions to a Radon measure,A Baire measure with different extensions to a Radon measure,,"Let $X$ be a Hausdorff space. Let $\mu : \mathcal{B}a(X) \to [0, \infty)$ be a finite Baire measure where $\mathcal{B}a(X) := \sigma(C_b(X))$ is the $\sigma$ -algebra generated by the continuous (bounded) functions $C_b(X)$ . Facts: If $\mu$ is a tight Baire measure then $\mu$ has an extension to a Radon measure, i.e. a measure $\mu : \mathcal{B}(X) \to [0, \infty)$ defined on the Borel $\sigma$ -algebra $\mathcal{B}(X)$ that is inner regular with respect to the compact sets on all Borel sets, i.e. $\mu(B) = \inf \{ \mu(K) \mid K \subseteq B,\, K \textrm{ compact} \}$ for all $B \in \mathcal{B}(X)$ [Bogachev, ""Measure Theory"", 7.3.10]. If in addition $X$ is completely regular then this Radon measure extension is unique [Bogachev, 7.3.3] (there can may be also Borel measure extensions of $\mu$ that are not Radon). Moreover, two Radon measures coincide if and only if they already coincide on the compact sets. Is there an example of a Hausdorff space $X$ (that is necessarily not completely regular) and a Baire measure $\mu$ on $X$ that has two different Radon measure extensions? These Radon measures must be different on some compact set which is not contained in the Baire $\sigma$ -algebra.","Let be a Hausdorff space. Let be a finite Baire measure where is the -algebra generated by the continuous (bounded) functions . Facts: If is a tight Baire measure then has an extension to a Radon measure, i.e. a measure defined on the Borel -algebra that is inner regular with respect to the compact sets on all Borel sets, i.e. for all [Bogachev, ""Measure Theory"", 7.3.10]. If in addition is completely regular then this Radon measure extension is unique [Bogachev, 7.3.3] (there can may be also Borel measure extensions of that are not Radon). Moreover, two Radon measures coincide if and only if they already coincide on the compact sets. Is there an example of a Hausdorff space (that is necessarily not completely regular) and a Baire measure on that has two different Radon measure extensions? These Radon measures must be different on some compact set which is not contained in the Baire -algebra.","X \mu : \mathcal{B}a(X) \to [0, \infty) \mathcal{B}a(X) := \sigma(C_b(X)) \sigma C_b(X) \mu \mu \mu : \mathcal{B}(X) \to [0, \infty) \sigma \mathcal{B}(X) \mu(B) = \inf \{ \mu(K) \mid K \subseteq B,\, K \textrm{ compact} \} B \in \mathcal{B}(X) X \mu X \mu X \sigma",['measure-theory']
17,for which $\sigma$-algebra this set function is a measure?,for which -algebra this set function is a measure?,\sigma,"Lets say we have $X=\mathbb{R}$ , and we have the following function $$\mu(A)=\cases{0, \text{if  $A=\emptyset$}\\ 1, \text{if $A\neq \emptyset$}}$$ I am asked to say for which $\sigma$ -algebra the latter is a measure. First, it's easy to see that $\mu(\emptyset)=0$ , and I know that the measure must satisfy $\sigma$ -additivity. My guess goes as follows: Suppose $A_1,A_2\in X$ , $A_1, A_2 \neq \emptyset$ and $A_1, A_2$ are disjoint. Let $A=A_1\bigcup A_2$ , hence $A\neq \emptyset$ and hence $\mu(A)=1$ . But if we use the $\sigma$ -additivity we have that $$\mu(A_1\bigcup A_2)=1+1=2$$ So I suppose that the $\sigma$ -algebra must be something like $\{X,\emptyset\}$ Is this correct? If this is not the right approach, how could I face this kind of problems?","Lets say we have , and we have the following function I am asked to say for which -algebra the latter is a measure. First, it's easy to see that , and I know that the measure must satisfy -additivity. My guess goes as follows: Suppose , and are disjoint. Let , hence and hence . But if we use the -additivity we have that So I suppose that the -algebra must be something like Is this correct? If this is not the right approach, how could I face this kind of problems?","X=\mathbb{R} \mu(A)=\cases{0, \text{if  A=\emptyset}\\ 1, \text{if A\neq \emptyset}} \sigma \mu(\emptyset)=0 \sigma A_1,A_2\in X A_1, A_2 \neq \emptyset A_1, A_2 A=A_1\bigcup A_2 A\neq \emptyset \mu(A)=1 \sigma \mu(A_1\bigcup A_2)=1+1=2 \sigma \{X,\emptyset\}",['measure-theory']
18,Image of a Topologically Regular Set?,Image of a Topologically Regular Set?,,"This question has come up as a small question in my research and I think I'm a little too thick in the weeds with extraneous details to see it cleanly. If necessary, I can add some more conditions on the spaces and maps that follow---just ask! Suppose $(X, d_x, \mu_x)$ and $(Y, d_y, \mu_y)$ are metric measure spaces, with metrics $d_x$ and $d_y$ and Borel measures $\mu_x$ and $\mu_y$ respectively. Let $f:X \to Y$ be continuous (and hence measureable). Generally assume that $X$ and $Y$ are ""nice"" (e.g., manifolds) but $f$ is ""messy."" Definition : A set $U$ is called topologically regular (or a regular closed set ) if it is the closure of its interior, i.e., $\overline{\mathrm{int } U} = U$ . Theorem : If $A \subseteq X$ is compact and $f$ is continous, then $f(A) \subseteq Y$ is compact. Suppose for everything that follows that $A \subseteq X$ is non-empty, compact, and topologically regular. My aim is to establish the weakest possible condition on $f$ such that $f(A) \subseteq Y$ is also topologically regular. Baby Question : If $f:X \to Y$ is continuous, is $f(A) \subseteq Y$ topologically regular? Counter Example: Consider $f:\mathbb{R}^2 \to \mathbb{R}^2$ with the Euclidean metrics and Lebesgue measures. Let $f(x,y):=(x, 0)$ ; observe that $f$ is clearly continuous. However, $[0,1]^2$ is topologically regular but $f([0,1]^2) = [0,1] \times \{0\}$ which has empty interior and is hence not topologically regular. $\blacksquare$ Clearly we need a stronger condition on $f$ in order to guarantee that the image is also topologically regular. The following would be sufficient, but is a stronger condition than I could ever possibly dream of in my context. Theorem : If $f:X \to Y$ is a homeomorphism, then $f(A)$ is topologically regular. Proof: Clearly $f( \mathrm{int}~A) = \mathrm{int}~ f(A)$ as $f$ is a homeomorphism; since $A$ is topologically regular and non-empty, we have that $\mathrm{int}~A \neq \emptyset$ and hence $\mathrm{int}~f(A) \neq \emptyset$ . Let $y \in \partial f(A)$ and $\epsilon > 0$ be given. We seek to show that the ball $B(y, \epsilon)$ has non-trivial intersection with $\mathrm{int}~f(A)$ .  Since $f(A)$ is compact (and hence closed), we have that $y \in f(A)$ and hence $x:= f^{-1}(y) \in A$ . Since $A$ is topologically regular, we have that $f^{-1}(B(y, \epsilon)) \cap \mathrm{int}~A \neq \emptyset$ and therefore $$B(y, \epsilon) \cap f(\mathrm{int}~A) = B(y, \epsilon) \cap \mathrm{int}~f(A) \neq \emptyset.$$ Hence $y \in \overline{\mathrm{int}~f(A)}$ and thus $f(A) = \overline{\mathrm{int}~f(A)}$ as desired. $\blacksquare$ The Question In my specific context, $f$ will land somewhere on the spectrum between being continuous (trivially easy) and being a homeomorphism (provably impossible). What are the weakest possible conditions on $f$ to guarantee that $f(A)$ is topologically regular? Do any (or all?) of the following suffice? If they fail, what additional (if any) hypotheses on $f$ or the spaces $X$ and $Y$ are necessary? $f:X \to Y$ is continuous and bounded-to-one , i.e., there exists $M \in \mathbb{N}$ such that $\mathrm{Card } f^{-1}(y) \leq M$ for all $y \in Y$ . $f:X \to Y$ is continuous and almost everywhere constant-to-one , i.e., there exists $M \in \mathbb{N}$ such that $\mathrm{Card}~f^{-1}(y) = M$ almost everywhere. $f:X \to Y$ is continuous and almost everywhere injective. $f: X \to Y$ is Lipschitz continuous. Edit: See above counter example $f: X \to Y$ is $\alpha$ -Holder continuous. Edit: See above counter example Edit Per comments from @WilliamElliot and @HennoBrandsma, $f$ being continuous and an open (or closed) mapping suffices. The proof is similar to that of $f$ being a homeomorphism as above, but with some care taken as to inclusions instead of inequalities. In my specific context, this actually solves my problem as I can show that $f$ is a closed map. I still think there's some interesting analysis to be done regarding the five conditions I've listed above, so I'll leave the question open for now. Edit 2: Open Mapping There seems to be some confusion in the comments. I give a proof below that $f$ is continuous and an open mapping suffices. I also give proof that my Counter-Example is neither an open mapping nor a closed mapping. Proposition E1 : The map $f:\mathbb{R}^2 \to \mathbb{R}^2$ given by $f(x,y):= (x,0)$ is not an open mapping. Proof: Given open $U \subseteq \mathbb{R}^2$ , we have that $f(U)= A \times \{0\}$ for some $A \subseteq \mathbb{R}$ , which is not open in $\mathbb{R}^2$ . $\blacksquare$ Proposition E2 : The map $f:\mathbb{R}^2 \to \mathbb{R}^2$ given by $f(x,y):= (x,0)$ is not a closed mapping. Proof. Define $U:=\{(x,y) \in \mathbb{R}^2 \mid y \geq 1/x \text{ and } x > 0\}$ . We have that $U$ is closed, but $f(U) = (0, \infty)\times \{0\}$ which is not closed. $\blacksquare$ Proposition E3 : Suppose $f:X \to Y$ is continuous. If $f$ is an open mapping and $A \subseteq X$ is topologically regular, then $f(A)$ is topologically regular. Proof. Let topologically regular $A \subseteq X$ be given. We begin by noting that if $A=\emptyset$ , then the proposition holds vacuously. Therefore, assume that $A \neq \emptyset$ and thus $\mathrm{int} A \neq \emptyset$ . Since $\mathrm{int} A \subseteq A$ , we have that $f(\mathrm{int} A) \subseteq \mathrm{int} f(A)$ and in particular is non-empty. Let $y \in f(A)$ and open neighborhood $U\ni y$ be given. Since $f$ is continuous, $f^{-1}(U)$ is open in $X$ and in particular $f^{-1}(U) \cap A$ is non-empty. As $\overline{\mathrm{int} A} = A$ , we have that $f^{-1}(U) \cap \mathrm{int} A \neq \emptyset$ . Therefore $$U \cap \mathrm{int} f(A) \supseteq U \cap f(\mathrm{int} A) \supseteq f \left(f^{-1}(U) \cap \mathrm{int} A \right) \neq \emptyset$$ and thus $y \in \overline{\mathrm{int} f(A)}$ as desired. $\blacksquare$ Edit 3: Closed Mapping Having $f$ be continuous and a closed mapping is insufficient to guarantee that the image is topologically regular. Counter-Example: Consider $f:[0,1]^2 \to [0,1]^2$ (with the standard topologies) defined by $f(x,y):=(x,0)$ . We can clearly see that $f$ is continuous and we will show that $f$ is a closed mapping. Let a closed subset $A \subseteq [0,1]^2$ . As $A$ is a closed and bounded subset of $\mathbb{R}^2$ , we have that $A$ is compact. Since the image of a compact set is compact (and thus closed), we have that $f(A)$ is closed as well and thus $f$ is a closed mapping. However, $f(A) \subseteq [0,1] \times \{0\}$ and thus $\mathrm{int}~f(A) = \emptyset$ in $[0,1]^2$ . Therefore, given any non-empty $A$ we have that $\overline{\mathrm{int} f(A)} = \emptyset \neq f(A)$ and thus $f(A)$ cannot be topologically regular. $\blacksquare$","This question has come up as a small question in my research and I think I'm a little too thick in the weeds with extraneous details to see it cleanly. If necessary, I can add some more conditions on the spaces and maps that follow---just ask! Suppose and are metric measure spaces, with metrics and and Borel measures and respectively. Let be continuous (and hence measureable). Generally assume that and are ""nice"" (e.g., manifolds) but is ""messy."" Definition : A set is called topologically regular (or a regular closed set ) if it is the closure of its interior, i.e., . Theorem : If is compact and is continous, then is compact. Suppose for everything that follows that is non-empty, compact, and topologically regular. My aim is to establish the weakest possible condition on such that is also topologically regular. Baby Question : If is continuous, is topologically regular? Counter Example: Consider with the Euclidean metrics and Lebesgue measures. Let ; observe that is clearly continuous. However, is topologically regular but which has empty interior and is hence not topologically regular. Clearly we need a stronger condition on in order to guarantee that the image is also topologically regular. The following would be sufficient, but is a stronger condition than I could ever possibly dream of in my context. Theorem : If is a homeomorphism, then is topologically regular. Proof: Clearly as is a homeomorphism; since is topologically regular and non-empty, we have that and hence . Let and be given. We seek to show that the ball has non-trivial intersection with .  Since is compact (and hence closed), we have that and hence . Since is topologically regular, we have that and therefore Hence and thus as desired. The Question In my specific context, will land somewhere on the spectrum between being continuous (trivially easy) and being a homeomorphism (provably impossible). What are the weakest possible conditions on to guarantee that is topologically regular? Do any (or all?) of the following suffice? If they fail, what additional (if any) hypotheses on or the spaces and are necessary? is continuous and bounded-to-one , i.e., there exists such that for all . is continuous and almost everywhere constant-to-one , i.e., there exists such that almost everywhere. is continuous and almost everywhere injective. is Lipschitz continuous. Edit: See above counter example is -Holder continuous. Edit: See above counter example Edit Per comments from @WilliamElliot and @HennoBrandsma, being continuous and an open (or closed) mapping suffices. The proof is similar to that of being a homeomorphism as above, but with some care taken as to inclusions instead of inequalities. In my specific context, this actually solves my problem as I can show that is a closed map. I still think there's some interesting analysis to be done regarding the five conditions I've listed above, so I'll leave the question open for now. Edit 2: Open Mapping There seems to be some confusion in the comments. I give a proof below that is continuous and an open mapping suffices. I also give proof that my Counter-Example is neither an open mapping nor a closed mapping. Proposition E1 : The map given by is not an open mapping. Proof: Given open , we have that for some , which is not open in . Proposition E2 : The map given by is not a closed mapping. Proof. Define . We have that is closed, but which is not closed. Proposition E3 : Suppose is continuous. If is an open mapping and is topologically regular, then is topologically regular. Proof. Let topologically regular be given. We begin by noting that if , then the proposition holds vacuously. Therefore, assume that and thus . Since , we have that and in particular is non-empty. Let and open neighborhood be given. Since is continuous, is open in and in particular is non-empty. As , we have that . Therefore and thus as desired. Edit 3: Closed Mapping Having be continuous and a closed mapping is insufficient to guarantee that the image is topologically regular. Counter-Example: Consider (with the standard topologies) defined by . We can clearly see that is continuous and we will show that is a closed mapping. Let a closed subset . As is a closed and bounded subset of , we have that is compact. Since the image of a compact set is compact (and thus closed), we have that is closed as well and thus is a closed mapping. However, and thus in . Therefore, given any non-empty we have that and thus cannot be topologically regular.","(X, d_x, \mu_x) (Y, d_y, \mu_y) d_x d_y \mu_x \mu_y f:X \to Y X Y f U \overline{\mathrm{int } U} = U A \subseteq X f f(A) \subseteq Y A \subseteq X f f(A) \subseteq Y f:X \to Y f(A) \subseteq Y f:\mathbb{R}^2 \to \mathbb{R}^2 f(x,y):=(x, 0) f [0,1]^2 f([0,1]^2) = [0,1] \times \{0\} \blacksquare f f:X \to Y f(A) f( \mathrm{int}~A) = \mathrm{int}~ f(A) f A \mathrm{int}~A \neq \emptyset \mathrm{int}~f(A) \neq \emptyset y \in \partial f(A) \epsilon > 0 B(y, \epsilon) \mathrm{int}~f(A) f(A) y \in f(A) x:= f^{-1}(y) \in A A f^{-1}(B(y, \epsilon)) \cap \mathrm{int}~A \neq \emptyset B(y, \epsilon) \cap f(\mathrm{int}~A) = B(y, \epsilon) \cap \mathrm{int}~f(A) \neq \emptyset. y \in \overline{\mathrm{int}~f(A)} f(A) = \overline{\mathrm{int}~f(A)} \blacksquare f f f(A) f X Y f:X \to Y M \in \mathbb{N} \mathrm{Card } f^{-1}(y) \leq M y \in Y f:X \to Y M \in \mathbb{N} \mathrm{Card}~f^{-1}(y) = M f:X \to Y f: X \to Y f: X \to Y \alpha f f f f f:\mathbb{R}^2 \to \mathbb{R}^2 f(x,y):= (x,0) U \subseteq \mathbb{R}^2 f(U)= A \times \{0\} A \subseteq \mathbb{R} \mathbb{R}^2 \blacksquare f:\mathbb{R}^2 \to \mathbb{R}^2 f(x,y):= (x,0) U:=\{(x,y) \in \mathbb{R}^2 \mid y \geq 1/x \text{ and } x > 0\} U f(U) = (0, \infty)\times \{0\} \blacksquare f:X \to Y f A \subseteq X f(A) A \subseteq X A=\emptyset A \neq \emptyset \mathrm{int} A \neq \emptyset \mathrm{int} A \subseteq A f(\mathrm{int} A) \subseteq \mathrm{int} f(A) y \in f(A) U\ni y f f^{-1}(U) X f^{-1}(U) \cap A \overline{\mathrm{int} A} = A f^{-1}(U) \cap \mathrm{int} A \neq \emptyset U \cap \mathrm{int} f(A) \supseteq U \cap f(\mathrm{int} A) \supseteq f \left(f^{-1}(U) \cap \mathrm{int} A \right) \neq \emptyset y \in \overline{\mathrm{int} f(A)} \blacksquare f f:[0,1]^2 \to [0,1]^2 f(x,y):=(x,0) f f A \subseteq [0,1]^2 A \mathbb{R}^2 A f(A) f f(A) \subseteq [0,1] \times \{0\} \mathrm{int}~f(A) = \emptyset [0,1]^2 A \overline{\mathrm{int} f(A)} = \emptyset \neq f(A) f(A) \blacksquare","['general-topology', 'measure-theory']"
19,Convergence of measure topology,Convergence of measure topology,,"Let $(\Omega,\mu)$ be a $\sigma$ -finite measure space. Let $1\leq p<\infty.$ Suppose $T:L^p(\Omega)\to L^p(\Omega)$ be a bounded positive function, i.e. it takes nonnegative functions to nonnegative functions. Suppose he restriction of $T$ on any $L^p(A)$ , where A has finite measure, is continuous in topology of convergence in measure for both domain and codomain ( $L^p(A)$ has the $\sigma$ algebra as the restriction of the whole $\sigma$ -algebra). Does it imply that $T:L^p(\Omega)\to L^p(\Omega)$ is continuous in the topology of convergence in measure?","Let be a -finite measure space. Let Suppose be a bounded positive function, i.e. it takes nonnegative functions to nonnegative functions. Suppose he restriction of on any , where A has finite measure, is continuous in topology of convergence in measure for both domain and codomain ( has the algebra as the restriction of the whole -algebra). Does it imply that is continuous in the topology of convergence in measure?","(\Omega,\mu) \sigma 1\leq p<\infty. T:L^p(\Omega)\to L^p(\Omega) T L^p(A) L^p(A) \sigma \sigma T:L^p(\Omega)\to L^p(\Omega)","['general-topology', 'measure-theory', 'lp-spaces']"
20,Volume Form induces Borel Measure Proof-Verification,Volume Form induces Borel Measure Proof-Verification,,"Proposition. Let $M$ be a compact smooth manifold of positive dimension and $\omega$ a volume form on $M$ . Suppose that $F \in \operatorname{Diff}(M)$ such that $F^*\omega = \omega$ . Then there   exists a finite $F$ -invariant regular Borel measure on $M$ . Proof. Define $I \in (C^\infty(M))^*$ by $$I(f) := \int_M f\omega.$$ Because $C^\infty(M)$ is dense in $C^0(M)$ under the sup-norm, $I$ extends uniquely to an element of $(C^0(M))^*$ . By the Riesz representation theorem, there exists a unique finite regular Borel measure $\mu$ such that $$I(f) = \int_M fd\mu$$ for all $f \in C^0(M)$ . Thus left to show is $F$ -invariance, that is $$\mu(F^{-1}(A)) = \mu(A)$$ for all measurable $A \subseteq M$ or equivalently, $F_* \mu = \mu$ , where $F_*\mu$ denotes the pushforward-measure of $\mu$ under $F$ . By assumption, we have that $$I(f) = \int_M F^*(f\omega) = \int_M (f \circ F)\omega = I(f \circ F)$$ for all $f \in C^\infty(M)$ since $F^*\omega = \omega$ implies that $F$ is orientation-preserving. Thus also $$\int_M f d\mu = \int_M(f \circ F)d\mu$$ for all $f \in C^0(M)$ . The latter is exactly the integral $$\int_M f d(F_*\mu).$$ But then also $$I(f) = \int_M fd(F_*\mu)$$ for all $f \in C^0(M)$ which implies by uniqueness that $$F_*\mu = \mu$$ because $F_*\mu$ is also regular as $\mu$ is. $\square$ Is that proof correct? Is there a simpler argument?","Proposition. Let be a compact smooth manifold of positive dimension and a volume form on . Suppose that such that . Then there   exists a finite -invariant regular Borel measure on . Proof. Define by Because is dense in under the sup-norm, extends uniquely to an element of . By the Riesz representation theorem, there exists a unique finite regular Borel measure such that for all . Thus left to show is -invariance, that is for all measurable or equivalently, , where denotes the pushforward-measure of under . By assumption, we have that for all since implies that is orientation-preserving. Thus also for all . The latter is exactly the integral But then also for all which implies by uniqueness that because is also regular as is. Is that proof correct? Is there a simpler argument?","M \omega M F \in
\operatorname{Diff}(M) F^*\omega = \omega F M I \in (C^\infty(M))^* I(f) := \int_M f\omega. C^\infty(M) C^0(M) I (C^0(M))^* \mu I(f) = \int_M fd\mu f \in C^0(M) F \mu(F^{-1}(A)) = \mu(A) A \subseteq M F_* \mu = \mu F_*\mu \mu F I(f) = \int_M F^*(f\omega) = \int_M (f \circ F)\omega = I(f \circ F) f \in C^\infty(M) F^*\omega = \omega F \int_M f d\mu = \int_M(f \circ F)d\mu f \in C^0(M) \int_M f d(F_*\mu). I(f) = \int_M fd(F_*\mu) f \in C^0(M) F_*\mu = \mu F_*\mu \mu \square","['measure-theory', 'proof-verification', 'differential-geometry']"
21,Nonnegativity of solution of $u_t=\Delta u+u$,Nonnegativity of solution of,u_t=\Delta u+u,"Consider the following evolution equation $$u_t=\Delta u+u$$ in a bounded and regular open subset $\Omega$ of $\mathbb{R}^N$ , with smooth initial conditions $u_0\geq 0$ and homogeneous Dirichlet boundary conditions. It is known that this equation has a smooth global solution $u$ . My goal is to prove that the solution remains nonnegative. So I consider $w=\min(0,u)$ and its energy $E(t):=\int_\Omega w^2 dx$ . We know that \begin{align} E(0) &= \int_\Omega w(0,x)^2 dx \\ &=\int_\Omega \min(0,u(0,x))^2 dx \\ &=\int_\Omega \min(0,u_0(x))^2 dx \\ &=0 \end{align} By differentiating $E(t)$ and using integration parts we get \begin{align} E'(t) &= 2\int_\Omega ww_t \\ &= 2\int_\Omega wu_t \\ &= 2\int_\Omega w\Delta u+2\int_\Omega wu \\ &= -2\int_\Omega \nabla w \cdot \nabla u+2\int_\Omega w^2 \\ &= -2\int_\Omega |\nabla w|^2+2E(t) \\ &\leq-\frac{2}{c^2}\int_\Omega w^2 dx+2E(t)\\ &\leq\left(2-\frac{2}{c^2}\right)E(t),\quad \text{for almost every} \ t \end{align} where $c$ is the Poincaré constant.  Thus $E(t)\leq e^{\left(2-\frac{2}{c^2}\right)t}E(0)=0$ for almost every $t$ which implies that for a.e $t\geq 0$ $w(t,x)=0$ for a.e $x\in \Omega$ . But since $w=\min(0,u)$ is continuous then $w(t,x)=0$ for all $t\geq 0$ and for all $x\in \Omega.$ Therefore $u(t,x)\geq 0$ for all $t\geq 0$ and for all $x\in \Omega.$ My concerns are : 1) How can I justify the derivation under integral sign $E'(t)=2\int_\Omega ww_t$ because unlike $u$ which is smooth, $w=\min(0,u)$ has only weak time derivative $w_t=u_t \mathbb{1}_{\{u\leq0\}}.$ 2) In the end I proved that for a.e $t\geq 0$ , $\int w(t,x)^2dx=0$ , thus for a.e $t\geq 0$ : $w(t,x)=0$ for a.e $x\in \Omega$ . I then concluded by continuity of $w$ that this holds for all $t\geq 0$ and for all $x\in \Omega.$ I am not use but the space negligable sets of $\Omega$ might depend on time $t$ . Does this make my argument still valid?","Consider the following evolution equation in a bounded and regular open subset of , with smooth initial conditions and homogeneous Dirichlet boundary conditions. It is known that this equation has a smooth global solution . My goal is to prove that the solution remains nonnegative. So I consider and its energy . We know that By differentiating and using integration parts we get where is the Poincaré constant.  Thus for almost every which implies that for a.e for a.e . But since is continuous then for all and for all Therefore for all and for all My concerns are : 1) How can I justify the derivation under integral sign because unlike which is smooth, has only weak time derivative 2) In the end I proved that for a.e , , thus for a.e : for a.e . I then concluded by continuity of that this holds for all and for all I am not use but the space negligable sets of might depend on time . Does this make my argument still valid?","u_t=\Delta u+u \Omega \mathbb{R}^N u_0\geq 0 u w=\min(0,u) E(t):=\int_\Omega w^2 dx \begin{align}
E(0) &= \int_\Omega w(0,x)^2 dx \\
&=\int_\Omega \min(0,u(0,x))^2 dx \\
&=\int_\Omega \min(0,u_0(x))^2 dx \\
&=0
\end{align} E(t) \begin{align}
E'(t) &= 2\int_\Omega ww_t \\
&= 2\int_\Omega wu_t \\
&= 2\int_\Omega w\Delta u+2\int_\Omega wu \\
&= -2\int_\Omega \nabla w \cdot \nabla u+2\int_\Omega w^2 \\
&= -2\int_\Omega |\nabla w|^2+2E(t) \\
&\leq-\frac{2}{c^2}\int_\Omega w^2 dx+2E(t)\\
&\leq\left(2-\frac{2}{c^2}\right)E(t),\quad \text{for almost every} \ t
\end{align} c E(t)\leq e^{\left(2-\frac{2}{c^2}\right)t}E(0)=0 t t\geq 0 w(t,x)=0 x\in \Omega w=\min(0,u) w(t,x)=0 t\geq 0 x\in \Omega. u(t,x)\geq 0 t\geq 0 x\in \Omega. E'(t)=2\int_\Omega ww_t u w=\min(0,u) w_t=u_t \mathbb{1}_{\{u\leq0\}}. t\geq 0 \int w(t,x)^2dx=0 t\geq 0 w(t,x)=0 x\in \Omega w t\geq 0 x\in \Omega. \Omega t","['measure-theory', 'partial-differential-equations', 'lebesgue-integral', 'lp-spaces', 'weak-derivatives']"
22,"$||\phi-\phi_\epsilon||_{L^1(\mu)}<\epsilon$ and $||\phi-\tilde{\phi}_\epsilon ||_{L^1(v\mu)}<\epsilon$, then $\tilde{\phi}_\epsilon= \phi_\epsilon$?","and , then ?",||\phi-\phi_\epsilon||_{L^1(\mu)}<\epsilon ||\phi-\tilde{\phi}_\epsilon ||_{L^1(v\mu)}<\epsilon \tilde{\phi}_\epsilon= \phi_\epsilon,"Let $\Omega\subset \mathbb{R}^n$ be an open and bounded set. Let $\mu:\mathcal{B}(\Omega)\to [0,+\infty)$ a bounded Radon measure and let $\varphi, \, v \in L^1(\Omega,\,\mu)$ , $v\geq 0$ . Then $v\mu$ is a bounded Radon measure too (and it is absolutely continuous with respect to $\mu$ ), where $$v\mu(B):=\int_Bv\,d\mu.$$ It is well is well known that $\forall \varepsilon>0$ there exists $\varphi_\varepsilon$ smooth (for my purpose $C^0$ is enough) s.t. $||\varphi - \varphi_\varepsilon ||_{L^1(\mu)}<\varepsilon$ and $\tilde{\varphi}_\varepsilon$ smooth s.t. $||\varphi - \tilde{\varphi}_\varepsilon ||_{L^1(v\mu)}<\varepsilon$ . Can I suppose that $\tilde{\varphi}_\varepsilon= \varphi_\varepsilon$ ? Perhaps it is sufficient to use the fact that $v\mu$ is AC with respect to $\mu$ ?","Let be an open and bounded set. Let a bounded Radon measure and let , . Then is a bounded Radon measure too (and it is absolutely continuous with respect to ), where It is well is well known that there exists smooth (for my purpose is enough) s.t. and smooth s.t. . Can I suppose that ? Perhaps it is sufficient to use the fact that is AC with respect to ?","\Omega\subset \mathbb{R}^n \mu:\mathcal{B}(\Omega)\to [0,+\infty) \varphi, \, v \in L^1(\Omega,\,\mu) v\geq 0 v\mu \mu v\mu(B):=\int_Bv\,d\mu. \forall \varepsilon>0 \varphi_\varepsilon C^0 ||\varphi - \varphi_\varepsilon ||_{L^1(\mu)}<\varepsilon \tilde{\varphi}_\varepsilon ||\varphi - \tilde{\varphi}_\varepsilon ||_{L^1(v\mu)}<\varepsilon \tilde{\varphi}_\varepsilon= \varphi_\varepsilon v\mu \mu","['real-analysis', 'measure-theory', 'approximation-theory', 'radon-nikodym']"
23,A bounded linear operator $ T: L^2 \to L^2$ with these properties (Proof check)?,A bounded linear operator  with these properties (Proof check)?, T: L^2 \to L^2,"A bounded linear operator $ T: L^2 \to L^2$ with these properties : Commutes with translation Commutes with dilation Has in its kernel functions $ f $ such that support $\hat {f} \subseteq [0,\infty) $ . where $\hat {f}$ is the fourier transform of $f$ For  a Schwartz function $f$ , $T= f* \mu$ where $\mu $ is a tempered distribution. Then $\int_{-\infty}^0\hat {f}(s)e^{2i\pi s x} ds =c Tf (x)$ where $ c $ is s constant. Is the proof below correct ? Known result from Riesz Representation theorem see here : $\int Tf(s)u(s) ds=\int f(s)T^*u(s)ds$ written as $<Tf,u>=<f,T^*u>$ , where $ T^*$ is the linear adjoint operator of $ T $ , $ u \in L^2$ now for $f(s)$ translated  by $x$ , $f(s+x)$ we have $\int Tf(s+x)u(s)ds=\int f(s+x)T^*u(s)ds$ Now take Let $u_{\epsilon}=\phi_\epsilon(s)=\phi(s/\epsilon)\epsilon^{-1}$ where $\phi(s)$ is normalized gaussian function with zero mean. $\int Tf(s+x)u_{\epsilon}(-s) ds=\int Tf(s+x)u_{\epsilon}(s)ds=\int f(s+x)T^*u_{\epsilon}(s)ds$ $H(s)=Tf(s)$ , by translation commutation $H(s+x)=Tf(s+x)$ $R(-s)=T^*u_{\epsilon}$ we have $\lim_{\epsilon \to 0} H* u_{\epsilon}=\lim_{\epsilon \to 0} f*R$ $\lim_{\epsilon \to 0} H*u_{\epsilon}=H(x)$ ae for $u \in L^1$ function, we have the following theorem regarding fourier transform: $v(x)=g*u=\int g(s)u(x-s) ds$ for $g \in L^2$ , define $\hat{g}=lim_{n \to \infty}\int_{n}^{-n}g(s)e^{2i\pi x z} dx$ the limit exists in the sense of $L^2$ . If $u \in L^1$ and $\int |g(s)||u(x-s)| ds \le P$ where $P$ is a non negative integrable function in $L^2$ then $\hat{v}=\hat{g}\hat{u}$ Proof : $g_n=g1_{[-n,n]},v_n=g_n*u$ it's known that $\hat{v_n}=\hat{g_n}\hat{u}$ By dominated convergence theorem $lim_{n \to \infty} ||v-v_n||^2=0$ and by Plancherel theorem $lim_{n \to \infty} ||v-v_m||^2= lim_{n \to \infty} ||\hat{v}-\hat{v_n}||^2=0$ This implies $lim_{n \to \infty} \hat{v_n}=\hat{v}$ Now from our equation when $u$ is a normalized  Gaussian we have $|H|* |u_{\epsilon}| \le MH(x)$ where $MH(x)$ is the Hardy Littlewood Maximal function (also $ ||MH(x)||^2 \le ||H(x)||^2$ ) using Fourier transform $\hat{H}(z)\hat{u_{\epsilon}}(z)=\hat{f}(z)G(z)$ where $G(z)=\hat{R}$ $\lim_{\epsilon \to 0}\hat{ u_{\epsilon}}=1$ $\lim_{\epsilon \to 0}G=m(z)$ consequently we have $\hat{Hf}(z)=m(z)\hat{f}(z)$ Therefore $L^2$ limit: $H(x)=\lim_{n \to \infty}\int_{-n}^{n}m(z)\hat {f}(z)e^{2i\pi x z} dz$ Now using dilation commutation $\lim_{n \to \infty}\int_{-n}^{n}m(z)\hat {f}(z)e^{2i\pi s z} dz=\lim_{n \to \infty}\int_{-n}^{n}a^{-1}m(z)\hat {f}(a^{-1}z)e^{2i\pi a^{-1}s z} dz=\lim_{n \to \infty}\int_{-a^{-1}n}^{a^{-1}n}m(az)\hat {f}(z)e^{2i\pi s z} dz$ define $ g=m(az)\hat{f}(z)$ define $g_n=g_{[{-n,n}]}-g_{[{-a^{-1}n,a^{-1}n}]}$ $\lim_{n \to \infty} ||g_n||^2=0$ $\hat{g_n}=\int_{-n}^{n}m(az)\hat {f}(z)e^{2i\pi s z} dz-\int_{-a^{-1}n}^{a^{-1}n}m(az)\hat {f}(z)e^{2i\pi s z} dz$ By Plancherel theorem $\lim_{n \to \infty} ||\hat{g_n}||^2=\lim_{n \to \infty} ||g_n||^2=0$ Therefore there is a subsequence $\{n\}$ such that $\lim_{n \to \infty}\int_{-a^{-1}n}^{a^{-1}n}m(az)\hat {f}(z)e^{2i\pi s z} = \lim_{n \to \infty}\int_{-n}^{n}m(az)\hat {f}(z)e^{2i\pi s z}$ so $\lim_{n \to \infty}\int_{-n}^{n}(m(z)-m(az))\hat {f}(z)e^{2i\pi s z} dz=0$ and by using Plancherel theorem this implies $m(az)=m(z)$ ae for any $a>0$ Therefore $m(z)=c_{-} $ ae on $z \in (-\infty ,0)$ and $m(z)=c_{+}$ ae on $ z \in (0,\infty)$ according to see here Given the 3rd condition $c_{+}\int_{0}^{\infty}\hat {f}(z)e^{2i\pi x z}dz=0$ ,since we know $\int_{0}^{\infty}\hat {f}(z)e^{2i\pi x z}dz\ne 0$ ,so $c_{+}=0$ Therefore $Hf(x)=c_{-}\int_{-\infty}^0\hat {f}(z)e^{2i\pi z x} dz$ ae","A bounded linear operator with these properties : Commutes with translation Commutes with dilation Has in its kernel functions such that support . where is the fourier transform of For  a Schwartz function , where is a tempered distribution. Then where is s constant. Is the proof below correct ? Known result from Riesz Representation theorem see here : written as , where is the linear adjoint operator of , now for translated  by , we have Now take Let where is normalized gaussian function with zero mean. , by translation commutation we have ae for function, we have the following theorem regarding fourier transform: for , define the limit exists in the sense of . If and where is a non negative integrable function in then Proof : it's known that By dominated convergence theorem and by Plancherel theorem This implies Now from our equation when is a normalized  Gaussian we have where is the Hardy Littlewood Maximal function (also ) using Fourier transform where consequently we have Therefore limit: Now using dilation commutation define define By Plancherel theorem Therefore there is a subsequence such that so and by using Plancherel theorem this implies ae for any Therefore ae on and ae on according to see here Given the 3rd condition ,since we know ,so Therefore ae"," T: L^2 \to L^2  f  \hat {f} \subseteq [0,\infty)  \hat {f} f f T= f* \mu \mu  \int_{-\infty}^0\hat {f}(s)e^{2i\pi s x} ds =c Tf (x)  c  \int Tf(s)u(s) ds=\int f(s)T^*u(s)ds <Tf,u>=<f,T^*u>  T^*  T   u \in L^2 f(s) x f(s+x) \int Tf(s+x)u(s)ds=\int f(s+x)T^*u(s)ds u_{\epsilon}=\phi_\epsilon(s)=\phi(s/\epsilon)\epsilon^{-1} \phi(s) \int Tf(s+x)u_{\epsilon}(-s) ds=\int Tf(s+x)u_{\epsilon}(s)ds=\int f(s+x)T^*u_{\epsilon}(s)ds H(s)=Tf(s) H(s+x)=Tf(s+x) R(-s)=T^*u_{\epsilon} \lim_{\epsilon \to 0} H* u_{\epsilon}=\lim_{\epsilon \to 0} f*R \lim_{\epsilon \to 0} H*u_{\epsilon}=H(x) u \in L^1 v(x)=g*u=\int g(s)u(x-s) ds g \in L^2 \hat{g}=lim_{n \to \infty}\int_{n}^{-n}g(s)e^{2i\pi x z} dx L^2 u \in L^1 \int |g(s)||u(x-s)| ds \le P P L^2 \hat{v}=\hat{g}\hat{u} g_n=g1_{[-n,n]},v_n=g_n*u \hat{v_n}=\hat{g_n}\hat{u} lim_{n \to \infty} ||v-v_n||^2=0 lim_{n \to \infty} ||v-v_m||^2= lim_{n \to \infty} ||\hat{v}-\hat{v_n}||^2=0 lim_{n \to \infty} \hat{v_n}=\hat{v} u |H|* |u_{\epsilon}| \le MH(x) MH(x)  ||MH(x)||^2 \le ||H(x)||^2 \hat{H}(z)\hat{u_{\epsilon}}(z)=\hat{f}(z)G(z) G(z)=\hat{R} \lim_{\epsilon \to 0}\hat{ u_{\epsilon}}=1 \lim_{\epsilon \to 0}G=m(z) \hat{Hf}(z)=m(z)\hat{f}(z) L^2 H(x)=\lim_{n \to \infty}\int_{-n}^{n}m(z)\hat {f}(z)e^{2i\pi x z} dz \lim_{n \to \infty}\int_{-n}^{n}m(z)\hat {f}(z)e^{2i\pi s z} dz=\lim_{n \to \infty}\int_{-n}^{n}a^{-1}m(z)\hat {f}(a^{-1}z)e^{2i\pi a^{-1}s z} dz=\lim_{n \to \infty}\int_{-a^{-1}n}^{a^{-1}n}m(az)\hat {f}(z)e^{2i\pi s z} dz  g=m(az)\hat{f}(z) g_n=g_{[{-n,n}]}-g_{[{-a^{-1}n,a^{-1}n}]} \lim_{n \to \infty} ||g_n||^2=0 \hat{g_n}=\int_{-n}^{n}m(az)\hat {f}(z)e^{2i\pi s z} dz-\int_{-a^{-1}n}^{a^{-1}n}m(az)\hat {f}(z)e^{2i\pi s z} dz \lim_{n \to \infty} ||\hat{g_n}||^2=\lim_{n \to \infty} ||g_n||^2=0 \{n\} \lim_{n \to \infty}\int_{-a^{-1}n}^{a^{-1}n}m(az)\hat {f}(z)e^{2i\pi s z} = \lim_{n \to \infty}\int_{-n}^{n}m(az)\hat {f}(z)e^{2i\pi s z} \lim_{n \to \infty}\int_{-n}^{n}(m(z)-m(az))\hat {f}(z)e^{2i\pi s z} dz=0 m(az)=m(z) a>0 m(z)=c_{-}  z \in (-\infty ,0) m(z)=c_{+}  z \in (0,\infty) c_{+}\int_{0}^{\infty}\hat {f}(z)e^{2i\pi x z}dz=0 \int_{0}^{\infty}\hat {f}(z)e^{2i\pi x z}dz\ne 0 c_{+}=0 Hf(x)=c_{-}\int_{-\infty}^0\hat {f}(z)e^{2i\pi z x} dz","['functional-analysis', 'measure-theory', 'solution-verification', 'fourier-analysis', 'operator-theory']"
24,Extending a regular conditional distribution,Extending a regular conditional distribution,,"Let $(X\times Y,\mathcal{X}\otimes\mathcal{Y}, P)$ be a product probability space and $f_1, f_2$ the two projection maps. Let $Q:\mathcal{X}\times\Omega\rightarrow [0,1]$ be a conditional distribution of $f_1$ given $f_2$ , i.e.~ $\omega\mapsto Q(A,.)$ is $Y$ -measurable for any $A\in\mathcal{X}$ ; $Q(.,\omega)$ is a probability distribution for any $\omega\in\Omega$ ; $P(A\cap B)=\int_BQ(A,\omega)dP$ for any $A\in\mathcal{X}$ and $B\in\mathcal{Y}$ . My question is whether there is a canonical extension of this $Q$ to a regular conditional distribution of $P$ given $f_2$ (which is a function $Q': \mathcal{X}\otimes\mathcal{Y}\times \Omega\rightarrow [0,1]$ ). Right now I know how to define $Q'(A\times B,\omega)=Q(A,\omega)1_B(\omega)$ . So the question could also be framed as one about extending a regular conditional distribution defined on $\mathcal{C}\times\Omega$ to $\sigma C\times\Omega$ . Thanks in advance for any help! (I have tried to extend $Q(.,\omega)$ pointwise by the Caratheodory extension theorem, but I don't know how to prove that this extension preserves measurability...)","Let be a product probability space and the two projection maps. Let be a conditional distribution of given , i.e.~ is -measurable for any ; is a probability distribution for any ; for any and . My question is whether there is a canonical extension of this to a regular conditional distribution of given (which is a function ). Right now I know how to define . So the question could also be framed as one about extending a regular conditional distribution defined on to . Thanks in advance for any help! (I have tried to extend pointwise by the Caratheodory extension theorem, but I don't know how to prove that this extension preserves measurability...)","(X\times Y,\mathcal{X}\otimes\mathcal{Y}, P) f_1, f_2 Q:\mathcal{X}\times\Omega\rightarrow [0,1] f_1 f_2 \omega\mapsto Q(A,.) Y A\in\mathcal{X} Q(.,\omega) \omega\in\Omega P(A\cap B)=\int_BQ(A,\omega)dP A\in\mathcal{X} B\in\mathcal{Y} Q P f_2 Q': \mathcal{X}\otimes\mathcal{Y}\times \Omega\rightarrow [0,1] Q'(A\times B,\omega)=Q(A,\omega)1_B(\omega) \mathcal{C}\times\Omega \sigma C\times\Omega Q(.,\omega)","['probability', 'measure-theory', 'conditional-probability']"
25,Extension of the Lebesgue measurable sets,Extension of the Lebesgue measurable sets,,"My question is the following : is there a $\sigma$-algebra $\mathcal{T}$ (of subsets of $\mathbb{R^n}$) that contains strictly the $\sigma$-algebra $\mathcal{L}$ of  Lebesgue measurable sets (in $\mathbb{R}^n$), and such that there is a measure on $\mathcal{T}$ that extends the usual Lebesgue measure on $\mathcal{L}$ ? I guess not, but I did not find a reference.","My question is the following : is there a $\sigma$-algebra $\mathcal{T}$ (of subsets of $\mathbb{R^n}$) that contains strictly the $\sigma$-algebra $\mathcal{L}$ of  Lebesgue measurable sets (in $\mathbb{R}^n$), and such that there is a measure on $\mathcal{T}$ that extends the usual Lebesgue measure on $\mathcal{L}$ ? I guess not, but I did not find a reference.",,"['real-analysis', 'measure-theory']"
26,Linear trasformation and Lebesgue measure,Linear trasformation and Lebesgue measure,,"Let $T\colon\mathbb{R}\to\mathbb{R}$ a linear trasformation of $\mathbb{R}$ defined as $Tx:=ax+b$ , where $a,b\in\mathbb{R}$ , $a\ne 0.$ We denote with $\mathcal{L}(\mathbb{R})$ the Lebesgue $\sigma-$ algebra and we denote with $\lambda^*$ the Lebesgue outer measure. Let $E\in2^{\mathbb{R}}$ , we must prove that Proposition. $T(E)\in\mathbb{\mathcal{L}(\mathbb{R})}$ $\iff$ $E\in\mathcal{L}(\mathbb{R})$ I just proved that $$\lambda^*(T(E))=|a|\lambda^*(E)\tag1.$$ Regarding the implication $(\Leftarrow)$ there are not problems. $(\Rightarrow)$ Proof. Suppose that $T(E)\in\mathcal{L}(\mathbb{R})$ , then $\lambda^*(Z)=\lambda^*(Z\cap T(E))+\lambda^*(Z\cap\complement T(E))$ for all $Z\in 2^{\mathbb{R}}$ . Therefore we have that $$\lambda^*(T(Z))=\lambda^*(T(Z)\cap T(E))+\lambda^*(T(Z)\cap \complement T(E)),$$ so $$\lambda^*(T(Z))=\lambda^*(T(Z\cap E))+\lambda^*(T(Z\cap\complement E)).$$ Multiplying the members for $|a|^{-1}$ we have $$|a|^{-1}\lambda^*(T(Z))=|a|^{-1}\lambda^*(T(Z\cap E))+|a|^{-1}\lambda^*(T(Z\cap\complement E)),$$ for $(1)$ we obtain $$\lambda^*(Z)=\lambda^*(Z\cap E)+\lambda^*(Z\cap \complement E),$$ then $E\in\mathcal{L}(\mathbb{R}).$ Proof 2. Observe that $$\lambda^*(E)=\lambda^*(T[T^{-1}(E)])=|a|\lambda^*(T^{-1}(E)),$$ then $$\lambda^*(T^{-1}(E))=\frac{1}{|a|}\lambda^*(E)\tag2.$$ Let $T(E)\in\mathcal{L}(\mathbb{R})$ then $\lambda^*(Z)=\lambda^*(Z\cap T(E))+\lambda^*(Z\cap\complement T(E))$ , therefore $$\lambda^*(T(Z))=\lambda^*(T(Z\cap E))+\lambda^*(T(Z\cap\complement E)).$$ Now, $$\frac{1}{|a|}\lambda^*(T(Z))=\frac{1}{|a|}\lambda^*(T(Z\cap E))+\frac{1}{|a|}\lambda^*(T(Z\cap\complement E)),$$ then for $(2)$ we have $$\lambda^*(T^{-1}[T(Z)])=\lambda^*(T^{-1}[T(Z\cap E)])+\lambda^*(T^{-1}[T(Z\cap\complement E)])$$ and so $$\lambda^*(Z)=\lambda^*(Z\cap E)+\lambda^*(Z\cap \complement E),$$ then $E\in\mathcal{L}(\mathbb{R}).$ Thanks! Question Are the proofs correct?","Let a linear trasformation of defined as , where , We denote with the Lebesgue algebra and we denote with the Lebesgue outer measure. Let , we must prove that Proposition. I just proved that Regarding the implication there are not problems. Proof. Suppose that , then for all . Therefore we have that so Multiplying the members for we have for we obtain then Proof 2. Observe that then Let then , therefore Now, then for we have and so then Thanks! Question Are the proofs correct?","T\colon\mathbb{R}\to\mathbb{R} \mathbb{R} Tx:=ax+b a,b\in\mathbb{R} a\ne 0. \mathcal{L}(\mathbb{R}) \sigma- \lambda^* E\in2^{\mathbb{R}} T(E)\in\mathbb{\mathcal{L}(\mathbb{R})} \iff E\in\mathcal{L}(\mathbb{R}) \lambda^*(T(E))=|a|\lambda^*(E)\tag1. (\Leftarrow) (\Rightarrow) T(E)\in\mathcal{L}(\mathbb{R}) \lambda^*(Z)=\lambda^*(Z\cap T(E))+\lambda^*(Z\cap\complement T(E)) Z\in 2^{\mathbb{R}} \lambda^*(T(Z))=\lambda^*(T(Z)\cap T(E))+\lambda^*(T(Z)\cap \complement T(E)), \lambda^*(T(Z))=\lambda^*(T(Z\cap E))+\lambda^*(T(Z\cap\complement E)). |a|^{-1} |a|^{-1}\lambda^*(T(Z))=|a|^{-1}\lambda^*(T(Z\cap E))+|a|^{-1}\lambda^*(T(Z\cap\complement E)), (1) \lambda^*(Z)=\lambda^*(Z\cap E)+\lambda^*(Z\cap \complement E), E\in\mathcal{L}(\mathbb{R}). \lambda^*(E)=\lambda^*(T[T^{-1}(E)])=|a|\lambda^*(T^{-1}(E)), \lambda^*(T^{-1}(E))=\frac{1}{|a|}\lambda^*(E)\tag2. T(E)\in\mathcal{L}(\mathbb{R}) \lambda^*(Z)=\lambda^*(Z\cap T(E))+\lambda^*(Z\cap\complement T(E)) \lambda^*(T(Z))=\lambda^*(T(Z\cap E))+\lambda^*(T(Z\cap\complement E)). \frac{1}{|a|}\lambda^*(T(Z))=\frac{1}{|a|}\lambda^*(T(Z\cap E))+\frac{1}{|a|}\lambda^*(T(Z\cap\complement E)), (2) \lambda^*(T^{-1}[T(Z)])=\lambda^*(T^{-1}[T(Z\cap E)])+\lambda^*(T^{-1}[T(Z\cap\complement E)]) \lambda^*(Z)=\lambda^*(Z\cap E)+\lambda^*(Z\cap \complement E), E\in\mathcal{L}(\mathbb{R}).","['measure-theory', 'proof-verification', 'proof-writing', 'lebesgue-measure']"
27,L2 Norm Inequality,L2 Norm Inequality,,"Let $f_1,f_2,f_3:\mathbb{R}^2\to\mathbb{R}_{\ge 0}$ be measurable, bounded, and compactly supported. Prove that $$\int_{\mathbb{R}^3}f_1(y,z)f_2(x,z)f_3(x,y)d(x,y,z)\le\lVert f_1\rVert_{L^2(\mathbb{R}^2)}\lVert f_2\rVert_{L^2(\mathbb{R}^2)}\lVert f_3\rVert_{L^2(\mathbb{R}^2)}$$ By Tonelli's Theorem and Cauchy, \begin{align} \int_{\mathbb{R}^3}f_1(y,z)f_2(x,z)f_3(x,y)d(x,y,z) &=\int_{\mathbb{R}^2}\left(f_1(y,z)\int_{\mathbb{R}}f_2(x,z)f_3(x,y)dx\right)d(y,z)\\ &\le\sqrt{\int_{\mathbb{R}^2}f_1^2(y,z)d(y,z)\int_{\mathbb{R}^2}\left(\int_{\mathbb{R}}f_2(x,z)f_3(x,y)dx\right)^2d(y,z)} \\ &\le\lVert f_1\rVert_{L^2(\mathbb{R}^2)}\sqrt{\int_{\mathbb{R}^2}\left(\int_{\mathbb{R}}f_2^2(x,z)f_3^2(x,y)dx\right)d(y,z)} \\ &=\Vert f_1\Vert_{L^2(\mathbb{R}^2)}\sqrt{\int_{\mathbb{R}^3}f_2^2(x,z)f_3^2(x,y)d(x,y,z)} \\ &=\lVert f_1\rVert_{L^2(\mathbb{R}^2)}\sqrt{\int_{\mathbb{R}^2}\left(f_2^2(x,z)\int_{\mathbb{R}}f_3^2(x,y)dy\right)d(x,z)} \\ &\le\lVert f_1\rVert_{L^2(\mathbb{R}^2)}\sqrt[4]{\int_{\mathbb{R}^2}f_2^4(x,z)d(x,z)\int_{\mathbb{R}^2}\left(\int_{\mathbb{R}}f_3^2(x,y)dy\right)^2d(x,z)} \end{align}  As you can see, this doesn't seem to be going anywhere.","Let $f_1,f_2,f_3:\mathbb{R}^2\to\mathbb{R}_{\ge 0}$ be measurable, bounded, and compactly supported. Prove that $$\int_{\mathbb{R}^3}f_1(y,z)f_2(x,z)f_3(x,y)d(x,y,z)\le\lVert f_1\rVert_{L^2(\mathbb{R}^2)}\lVert f_2\rVert_{L^2(\mathbb{R}^2)}\lVert f_3\rVert_{L^2(\mathbb{R}^2)}$$ By Tonelli's Theorem and Cauchy, \begin{align} \int_{\mathbb{R}^3}f_1(y,z)f_2(x,z)f_3(x,y)d(x,y,z) &=\int_{\mathbb{R}^2}\left(f_1(y,z)\int_{\mathbb{R}}f_2(x,z)f_3(x,y)dx\right)d(y,z)\\ &\le\sqrt{\int_{\mathbb{R}^2}f_1^2(y,z)d(y,z)\int_{\mathbb{R}^2}\left(\int_{\mathbb{R}}f_2(x,z)f_3(x,y)dx\right)^2d(y,z)} \\ &\le\lVert f_1\rVert_{L^2(\mathbb{R}^2)}\sqrt{\int_{\mathbb{R}^2}\left(\int_{\mathbb{R}}f_2^2(x,z)f_3^2(x,y)dx\right)d(y,z)} \\ &=\Vert f_1\Vert_{L^2(\mathbb{R}^2)}\sqrt{\int_{\mathbb{R}^3}f_2^2(x,z)f_3^2(x,y)d(x,y,z)} \\ &=\lVert f_1\rVert_{L^2(\mathbb{R}^2)}\sqrt{\int_{\mathbb{R}^2}\left(f_2^2(x,z)\int_{\mathbb{R}}f_3^2(x,y)dy\right)d(x,z)} \\ &\le\lVert f_1\rVert_{L^2(\mathbb{R}^2)}\sqrt[4]{\int_{\mathbb{R}^2}f_2^4(x,z)d(x,z)\int_{\mathbb{R}^2}\left(\int_{\mathbb{R}}f_3^2(x,y)dy\right)^2d(x,z)} \end{align}  As you can see, this doesn't seem to be going anywhere.",,"['analysis', 'lebesgue-integral', 'lp-spaces', 'holder-inequality']"
28,Sub-dimensional linear subspaces of $\mathbb{R}^{n}$ have measure zero.,Sub-dimensional linear subspaces of  have measure zero.,\mathbb{R}^{n},"I would appreciate it if someone could refer me to a proof (or simply give one here) for the statement in the title. That is: If $k<n$, then every $k-$dimensional subspace of $\mathbb{R}^{n}$ has $n-$dimensional Lebesgue measure zero. I've seen some proofs that use Sard's lemma but I'm not really familiar with that subject and I've never seen a proof of said lemma so I'd appreciate a proof that doesn't use it if possible. Thanks in advance!","I would appreciate it if someone could refer me to a proof (or simply give one here) for the statement in the title. That is: If $k<n$, then every $k-$dimensional subspace of $\mathbb{R}^{n}$ has $n-$dimensional Lebesgue measure zero. I've seen some proofs that use Sard's lemma but I'm not really familiar with that subject and I've never seen a proof of said lemma so I'd appreciate a proof that doesn't use it if possible. Thanks in advance!",,"['real-analysis', 'measure-theory', 'vector-spaces', 'lebesgue-measure', 'geometric-measure-theory']"
29,"Let $f$ a measurable function, then $kf$ is a measurable function with $k\in\mathbb{R}$","Let  a measurable function, then  is a measurable function with",f kf k\in\mathbb{R},"Let $f$ a measurable function, then $k.f$ is a measurable function with $k\in\mathbb{R}$ and $\mathbb{A}$ a sigma-algebra of sets. My attempt Suppose $k>0$ $x\in (k.f)^{-1}((\ c,\infty\ ))\iff k.f(x)>c \iff f(x)>\frac{c}{k}$ As $f$ is a measurable function then for all $\alpha=c/k\in\mathbb{R}$ we have $f^{-1}((\ a,\infty\ )\in \mathbb{A}$ this implies $\{x:f(x)>\alpha\}\in\mathbb{A}$ Then $(k.f)^{-1}((\ c,\infty\ ))\in\mathbb{A}$ In consequence, $k.f$ is a measurable function. For the other cases is analogous. is correct this?","Let a measurable function, then is a measurable function with and a sigma-algebra of sets. My attempt Suppose As is a measurable function then for all we have this implies Then In consequence, is a measurable function. For the other cases is analogous. is correct this?","f k.f k\in\mathbb{R} \mathbb{A} k>0 x\in (k.f)^{-1}((\ c,\infty\ ))\iff k.f(x)>c \iff f(x)>\frac{c}{k} f \alpha=c/k\in\mathbb{R} f^{-1}((\ a,\infty\ )\in \mathbb{A} \{x:f(x)>\alpha\}\in\mathbb{A} (k.f)^{-1}((\ c,\infty\ ))\in\mathbb{A} k.f",['measure-theory']
30,"If $\mu$ and $\nu$, is $\frac{d\mu}{d\nu}$ more a notation or does it make sense?","If  and , is  more a notation or does it make sense?",\mu \nu \frac{d\mu}{d\nu},"Let $\mu$ and $\nu$ two measure. I know that $$\frac{d\mu}{d\nu}=f$$ mean that $$\mu(A)=\int_A fd\nu.\tag{D}$$ But is $\frac{d\mu}{d\nu}=f$ is a notation for $(D)$ or does it really has a ""variational sense"" ?","Let and two measure. I know that mean that But is is a notation for or does it really has a ""variational sense"" ?",\mu \nu \frac{d\mu}{d\nu}=f \mu(A)=\int_A fd\nu.\tag{D} \frac{d\mu}{d\nu}=f (D),['measure-theory']
31,Measure upon which pointwise convergence of averaging operator fails in $L^1$,Measure upon which pointwise convergence of averaging operator fails in,L^1,"If $\mu$ is a doubling Radon measure on $\mathbf{R}^n$ , it is well known that for any locally integrable function $f$ , the values $$ (A_\delta f)(x) = \frac{1}{\mu(B(x,\delta))} \int_{B(x,\delta)} f(t) d\mu(t)  $$ converges pointwise $\mu$ almost everywhere to $f(x)$ . Are there any simple examples of non doubling absolutely continuous measures $\mu$ where this phenomenon fails to occur?","If is a doubling Radon measure on , it is well known that for any locally integrable function , the values converges pointwise almost everywhere to . Are there any simple examples of non doubling absolutely continuous measures where this phenomenon fails to occur?","\mu \mathbf{R}^n f  (A_\delta f)(x) = \frac{1}{\mu(B(x,\delta))} \int_{B(x,\delta)} f(t) d\mu(t)   \mu f(x) \mu","['measure-theory', 'harmonic-analysis', 'geometric-measure-theory']"
32,Spectral measure of a finite graph,Spectral measure of a finite graph,,"Let $A$ be the adjacency operator of connected, locally finite graph $G = (V,E)$ ( $A$ seen as an operator on $\ell^2(V)$ ). Then we have the spectral representation $$ A = \int_{\sigma(A)} t \mu(dt)$$ where $\mu$ is a resolution of the identity. For $u, v \in V$ , let $e_u$ be the vector in $\ell^2(V)$ whose $u$ -entry is $1$ and all other entries are $0$ . Define the spectral measures by $$\mu_{u,v}(dt) = \langle \mu(dt) e_u, e_v \rangle.$$ In this case, $\mu_{u,u}$ is the unique probability measure on $\mathbb{R}$ such that for all integers $k \geq 1$ , $$ \int_{\sigma(A)} t^k \mu_{u,u}(dt) = \langle A^k e_u, e_u \rangle.$$ Question: if $|V|$ is finite, then $A$ is a symmetric matrix (and self-adjoint), and the spectrum is discrete. If $(v_1, \ldots, v_n)$ is an orthonormal basis of eigenvectors associated to the eigenvalues $(\lambda_1, \ldots, \lambda_n)$ , how can one show from the definition that $$\mu_{u,u} = \sum_{k=1}^n \langle v_k, e_u \rangle^2 \delta_{\lambda_k},$$ or I think equivalently that $$\mu = \frac{1}{n} \sum_{i=1}^n \delta_{\lambda_i},$$ especially if one should be able to recover $A$ from $\mu$ ?","Let be the adjacency operator of connected, locally finite graph ( seen as an operator on ). Then we have the spectral representation where is a resolution of the identity. For , let be the vector in whose -entry is and all other entries are . Define the spectral measures by In this case, is the unique probability measure on such that for all integers , Question: if is finite, then is a symmetric matrix (and self-adjoint), and the spectrum is discrete. If is an orthonormal basis of eigenvectors associated to the eigenvalues , how can one show from the definition that or I think equivalently that especially if one should be able to recover from ?","A G = (V,E) A \ell^2(V)  A = \int_{\sigma(A)} t \mu(dt) \mu u, v \in V e_u \ell^2(V) u 1 0 \mu_{u,v}(dt) = \langle \mu(dt) e_u, e_v \rangle. \mu_{u,u} \mathbb{R} k \geq 1  \int_{\sigma(A)} t^k \mu_{u,u}(dt) = \langle A^k e_u, e_u \rangle. |V| A (v_1, \ldots, v_n) (\lambda_1, \ldots, \lambda_n) \mu_{u,u} = \sum_{k=1}^n \langle v_k, e_u \rangle^2 \delta_{\lambda_k}, \mu = \frac{1}{n} \sum_{i=1}^n \delta_{\lambda_i}, A \mu","['integration', 'functional-analysis', 'measure-theory', 'graph-theory', 'spectral-graph-theory']"
33,Limit of outer measure of set intersection,Limit of outer measure of set intersection,,"This is a question on Axler's book Measure, Integration & Real Analysis available here: http://measure.axler.net/ Prove that $|A|=\lim_{k\to\infty} |A\cap [-k,k]|$ for all $|A|\subset \mathbb{R}$ . where $|\cdot|$ is the outer measure. Essentially I think that by the definition given in that book, we have $$\lim_{k\to\infty}|A\cap[-k,k]|=\lim_{k\to\infty}\inf\left(\sum_{j=1}^\infty \ell(I_j):I_1,\text{... are open sets s.t. } A\cap[-k,k] \subset\bigcup_{j=1}^\infty I_j\right)$$ And I feel like we can just say the $\lim \inf$ of this is $|A|$ , but I can't really justify why.","This is a question on Axler's book Measure, Integration & Real Analysis available here: http://measure.axler.net/ Prove that for all . where is the outer measure. Essentially I think that by the definition given in that book, we have And I feel like we can just say the of this is , but I can't really justify why.","|A|=\lim_{k\to\infty} |A\cap [-k,k]| |A|\subset \mathbb{R} |\cdot| \lim_{k\to\infty}|A\cap[-k,k]|=\lim_{k\to\infty}\inf\left(\sum_{j=1}^\infty \ell(I_j):I_1,\text{... are open sets s.t. } A\cap[-k,k] \subset\bigcup_{j=1}^\infty I_j\right) \lim \inf |A|",['measure-theory']
34,Stability of optimal transference mappings (Exercise 2.17 in Villani's Topics in Optimal Transportaiton),Stability of optimal transference mappings (Exercise 2.17 in Villani's Topics in Optimal Transportaiton),,"I'm really stuck on the first part of this exercise. I've tried to type it up in a fashion that is as self-contained as possible, but some background in optimal transport is likely required to read this. Let $P_{ac,2}(\mathbb{R}^n)$ denote the space of absolutely continuous probability measures with finite second moments. Suppose $\sigma \in P_{ac,2}(\mathbb{R}^n)$ is given, as well as a family $\rho_k \in P_{ac,2}(\mathbb{R}^n)$ that weakly converges to some $\rho \in P_{ac,2}(\mathbb{R}^n)$ . Let $\nabla \varphi_k$ be the optimal mapping of the Monge problem with quadratic cost between $\sigma$ and $\rho_k$ , i.e. $$\int_{\mathbb{R}^n} |x-\nabla \varphi_k(x)|^2 d\sigma(x) = \inf_{T \# \sigma = \rho_k} \int_{\mathbb{R}^n} |x - T(x)|^2 d\sigma(x)$$ Here, the infimum is taken over functions $T : x \mapsto T(x)$ satisfying the pushforward constraint. Similarly, we can define $\nabla \varphi$ between $\sigma$ and $\rho$ . Let $d\pi_k(x,y) = d\sigma(x) \delta(y = \nabla \varphi_k(x))$ , and similarly define $\pi$ between $\sigma$ and $\rho$ . How can I show that $\pi_k$ weakly converges to $\pi$ ? (The hint given is to note that the optimal transference plan is unique.)","I'm really stuck on the first part of this exercise. I've tried to type it up in a fashion that is as self-contained as possible, but some background in optimal transport is likely required to read this. Let denote the space of absolutely continuous probability measures with finite second moments. Suppose is given, as well as a family that weakly converges to some . Let be the optimal mapping of the Monge problem with quadratic cost between and , i.e. Here, the infimum is taken over functions satisfying the pushforward constraint. Similarly, we can define between and . Let , and similarly define between and . How can I show that weakly converges to ? (The hint given is to note that the optimal transference plan is unique.)","P_{ac,2}(\mathbb{R}^n) \sigma \in P_{ac,2}(\mathbb{R}^n) \rho_k \in P_{ac,2}(\mathbb{R}^n) \rho \in P_{ac,2}(\mathbb{R}^n) \nabla \varphi_k \sigma \rho_k \int_{\mathbb{R}^n} |x-\nabla \varphi_k(x)|^2 d\sigma(x) = \inf_{T \# \sigma = \rho_k} \int_{\mathbb{R}^n} |x - T(x)|^2 d\sigma(x) T : x \mapsto T(x) \nabla \varphi \sigma \rho d\pi_k(x,y) = d\sigma(x) \delta(y = \nabla \varphi_k(x)) \pi \sigma \rho \pi_k \pi","['measure-theory', 'convex-analysis', 'optimal-transport']"
35,Spectral Theorem: Realization of a direct sum of $L^2$ spaces as a single $L^2$ space,Spectral Theorem: Realization of a direct sum of  spaces as a single  space,L^2 L^2,"The following is motivated by an attempt to understand the Spectral Theorem for Bounded operators on a none separable Hilbert space. One version of the theorem states that for a bounded (say normal) operator on a Hilbert space $A \in \mathcal{L(H)}$ , there exists an index set $I$ such that there is an isomorphism $$Q:\mathcal{H} \to \bigoplus_{i \in I} L^2 (S,\mu_i)$$ Where $S\in \mathbb{C}$ is the spectrum of $A$ , a compact set, with a probability measure $\mu_i$ , such that for $(f_i(z))_{i \in I}$ a sequence of functions in this direct sum, we have $$QAQ^{-1}(f_i(z))_{i \in I}=(zf_i(z))_{i \in I}$$ This is a remarkable result in it's own right. But one may want a single $L^2$ space to realize this direct sum. In the separable case, one can look certain direct sum of disjoint copies of $S$ with the measures $\mu_i$ , $(X, \mu) = \bigoplus_{i=1}^{\infty}(S,\mu_i)$ , where $\mu = \sum_{i=1}^\infty \frac{1}{2^i} \mu_i$ . Then $L^2(X, \mu)$ realizes $A$ as a multiplication operator with some $F \in L^\infty(X,\mu)$ . How can one do the same thing with a none separable $\mathcal{H}$ ? I.e. how can we realize it as a multiplication operator with a bounded function given this direct sum decomposition? . any reference or answer is appreciated.","The following is motivated by an attempt to understand the Spectral Theorem for Bounded operators on a none separable Hilbert space. One version of the theorem states that for a bounded (say normal) operator on a Hilbert space , there exists an index set such that there is an isomorphism Where is the spectrum of , a compact set, with a probability measure , such that for a sequence of functions in this direct sum, we have This is a remarkable result in it's own right. But one may want a single space to realize this direct sum. In the separable case, one can look certain direct sum of disjoint copies of with the measures , , where . Then realizes as a multiplication operator with some . How can one do the same thing with a none separable ? I.e. how can we realize it as a multiplication operator with a bounded function given this direct sum decomposition? . any reference or answer is appreciated.","A \in \mathcal{L(H)} I Q:\mathcal{H} \to \bigoplus_{i \in I} L^2 (S,\mu_i) S\in \mathbb{C} A \mu_i (f_i(z))_{i \in I} QAQ^{-1}(f_i(z))_{i \in I}=(zf_i(z))_{i \in I} L^2 S \mu_i (X, \mu) = \bigoplus_{i=1}^{\infty}(S,\mu_i) \mu = \sum_{i=1}^\infty \frac{1}{2^i} \mu_i L^2(X, \mu) A F \in L^\infty(X,\mu) \mathcal{H}","['functional-analysis', 'measure-theory', 'operator-theory', 'hilbert-spaces', 'spectral-theory']"
36,"Existence of non decreasing sequence of continuous functions aproximating $f$ in $L_p(0,\infty)$",Existence of non decreasing sequence of continuous functions aproximating  in,"f L_p(0,\infty)","I know that the continuous functions $f:(0,\infty) \rightarrow R $ are dense in $L_p(0,\infty)$ , with respect to the norm $|| \space||_p$ . Therefore, if $f\in L_p(0,\infty)$ then there exists a sequence of continous functions $\{f_n\}$ in $L_p$ such that $f_n \rightarrow f$ . I'm wondering if there exists a sequence that does this, but also is non-decreasing, meaning $f_{n+1}\geq f_n$ pointwise por each $n$ . I believe this to be true, but I haven't been able to prove it. So, is this true? If it is, I would appreciete any tips on how to prove it. Thanks!","I know that the continuous functions are dense in , with respect to the norm . Therefore, if then there exists a sequence of continous functions in such that . I'm wondering if there exists a sequence that does this, but also is non-decreasing, meaning pointwise por each . I believe this to be true, but I haven't been able to prove it. So, is this true? If it is, I would appreciete any tips on how to prove it. Thanks!","f:(0,\infty) \rightarrow R  L_p(0,\infty) || \space||_p f\in L_p(0,\infty) \{f_n\} L_p f_n \rightarrow f f_{n+1}\geq f_n n",['measure-theory']
37,"If $f$ measurable and $E \subset \mathbb{R}^n$ measurable, when will the set $f(E)$ be measurable?","If  measurable and  measurable, when will the set  be measurable?",f E \subset \mathbb{R}^n f(E),"If $f : \mathbb{R}^n \to \mathbb{R}$ measurable and $E \subset \mathbb{R}^n$ measurable, examples show that $f(E) = \{ f(x) : x \in E \}$ may be unmeasurable. My confusion is that under what assumptions about $f$ will the conclusion hold, i.e., $f(E)$ will be measurable. And is there an equivalence condition for this problem?","If measurable and measurable, examples show that may be unmeasurable. My confusion is that under what assumptions about will the conclusion hold, i.e., will be measurable. And is there an equivalence condition for this problem?",f : \mathbb{R}^n \to \mathbb{R} E \subset \mathbb{R}^n f(E) = \{ f(x) : x \in E \} f f(E),"['real-analysis', 'measure-theory']"
38,"An infinite $\sigma$-algebra contains a infinite sequence of disjoint nonempty sets, my attempt.","An infinite -algebra contains a infinite sequence of disjoint nonempty sets, my attempt.",\sigma,"As stated in the title the question is ""Show that an infinite $\sigma$ -algebra contains a infinite sequence of disjoint nonempty sets"". I've seen this question asked a lot here, many with different answers. I'd like to know if my approach to it is correct. Consider $\mathcal{A}$ an infinite $\sigma$ -algebra on $X$ and define $$\mathfrak{C}=\{\mathcal{C}\subset \mathcal{A}-\{\emptyset\},\, \mathcal{C}\text{ is a disjoint collection of subsets} \}$$ Let show that there exists finite $\mathcal{C}\in\mathfrak{C}$ of arbitrarily large size. If this wasn't the case, take $N=\max\{|\mathcal{C}|,\,\mathcal{C}\in \mathfrak{C}\}$ , there exists $\mathcal{C}_0$ such that $|\mathcal{C}_0|=N$ and therefore $\mathcal{C}_0=\{E_1,\dots,E_N\}$ . If $\bigcup_{n=1}^N E_n \neq X$ then $\mathcal{C}_0$ would not be maximal as $\mathcal{C}_0\cup \{X-\bigcup_{n=1}^N E_n\}$ would be a collection of $N+1$ disjoint subsets, therefore we have $\bigcup_{n=1}^N E_n = X$ . Now consider $\mathcal{A}'$ , the $\sigma$ -algebra generated by $\mathcal{C}_0$ , $\mathcal{A}'$ will be finite due to $\mathcal{C}_0$ being finite. Since $\mathcal{A}$ is infinite there exists $E\in \mathcal{A}-\mathcal{A}'$ . For some $n_0$ we must have $E_{n_0}\not\subset E$ and $E_{n_0}\cap E\neq \emptyset$ , otherwise we would have that for all $n$ either $E_n\subset E$ or $E_n\cap E=\emptyset$ meaning $$E=\bigcup_{E_n\cap E\neq \emptyset} E_n\in \mathcal{A}'$$ Now, set $E'_{n_0}:=E_{n_0}\cap E\in \mathcal{A}-\{\emptyset\}$ and $E_{N+1}:=E_{n_0}-E'_{n_0}\in \mathcal{A}-\{\emptyset\}$ . We have $E_{n_0}=E'_{n_0}\cup E_{N+1}$ where the union is disjoint, moreover $$\mathcal{C}:=\{E_1,\dots,E'_{n_0},\dots,E_N,E_{N+1}\}\in \mathfrak{C}$$ and $|\mathcal{C}|=N+1$ . This contradicts the maximality of $N$ , therefore there exists finite $\mathcal{C}\in\mathfrak{C}$ of arbitrarily large size. EDIT: As detailed in the comments there was a mistake, I'll try to see if I can salvage part of this proof.","As stated in the title the question is ""Show that an infinite -algebra contains a infinite sequence of disjoint nonempty sets"". I've seen this question asked a lot here, many with different answers. I'd like to know if my approach to it is correct. Consider an infinite -algebra on and define Let show that there exists finite of arbitrarily large size. If this wasn't the case, take , there exists such that and therefore . If then would not be maximal as would be a collection of disjoint subsets, therefore we have . Now consider , the -algebra generated by , will be finite due to being finite. Since is infinite there exists . For some we must have and , otherwise we would have that for all either or meaning Now, set and . We have where the union is disjoint, moreover and . This contradicts the maximality of , therefore there exists finite of arbitrarily large size. EDIT: As detailed in the comments there was a mistake, I'll try to see if I can salvage part of this proof.","\sigma \mathcal{A} \sigma X \mathfrak{C}=\{\mathcal{C}\subset \mathcal{A}-\{\emptyset\},\, \mathcal{C}\text{ is a disjoint collection of subsets} \} \mathcal{C}\in\mathfrak{C} N=\max\{|\mathcal{C}|,\,\mathcal{C}\in \mathfrak{C}\} \mathcal{C}_0 |\mathcal{C}_0|=N \mathcal{C}_0=\{E_1,\dots,E_N\} \bigcup_{n=1}^N E_n \neq X \mathcal{C}_0 \mathcal{C}_0\cup \{X-\bigcup_{n=1}^N E_n\} N+1 \bigcup_{n=1}^N E_n = X \mathcal{A}' \sigma \mathcal{C}_0 \mathcal{A}' \mathcal{C}_0 \mathcal{A} E\in \mathcal{A}-\mathcal{A}' n_0 E_{n_0}\not\subset E E_{n_0}\cap E\neq \emptyset n E_n\subset E E_n\cap E=\emptyset E=\bigcup_{E_n\cap E\neq \emptyset} E_n\in \mathcal{A}' E'_{n_0}:=E_{n_0}\cap E\in \mathcal{A}-\{\emptyset\} E_{N+1}:=E_{n_0}-E'_{n_0}\in \mathcal{A}-\{\emptyset\} E_{n_0}=E'_{n_0}\cup E_{N+1} \mathcal{C}:=\{E_1,\dots,E'_{n_0},\dots,E_N,E_{N+1}\}\in \mathfrak{C} |\mathcal{C}|=N+1 N \mathcal{C}\in\mathfrak{C}","['real-analysis', 'measure-theory', 'proof-verification', 'elementary-set-theory']"
39,Change of variables - Lebesgue-Stieltjes integral,Change of variables - Lebesgue-Stieltjes integral,,"I am trying to find a proof of a result as follows: Let $\rho(\lambda)$ be a real function. Suppose that $\rho(\lambda)$ is monotone increasing and bounded. Suppose that $f(\lambda)$ is measurable and essentialy bounded with respect $\rho(\lambda)$ . Denote by $\chi_{\mu}(\lambda)$ the function defined by $\chi_{\mu}(\lambda)=1$ if $f(\lambda) \leq \mu$ and $\chi_{\mu}(\lambda)=0$ if $f(\lambda)>\mu$ . Define $\beta(\mu)=\int_{\mathbb{R}}\chi_{\mu}(\lambda) d\rho(\lambda)$ . Proposition: Let $g(\mu)$ be a real function Lebesgue-Stieltjes integrable over $\mathbb{R}$ with respect $\beta(\mu)$ . Then, $g(f(\lambda))$ is Lebesgue-Stieltjes integrable over $\mathbb{R}$ with respect $\rho(\lambda)$ and $\int_{\mathbb{R}}g(f(\lambda))d\rho(\lambda)=\int_{\mathbb{R}}g(\mu)d\beta (\mu).$ Unfortunately, I could not find anything like that.","I am trying to find a proof of a result as follows: Let be a real function. Suppose that is monotone increasing and bounded. Suppose that is measurable and essentialy bounded with respect . Denote by the function defined by if and if . Define . Proposition: Let be a real function Lebesgue-Stieltjes integrable over with respect . Then, is Lebesgue-Stieltjes integrable over with respect and Unfortunately, I could not find anything like that.",\rho(\lambda) \rho(\lambda) f(\lambda) \rho(\lambda) \chi_{\mu}(\lambda) \chi_{\mu}(\lambda)=1 f(\lambda) \leq \mu \chi_{\mu}(\lambda)=0 f(\lambda)>\mu \beta(\mu)=\int_{\mathbb{R}}\chi_{\mu}(\lambda) d\rho(\lambda) g(\mu) \mathbb{R} \beta(\mu) g(f(\lambda)) \mathbb{R} \rho(\lambda) \int_{\mathbb{R}}g(f(\lambda))d\rho(\lambda)=\int_{\mathbb{R}}g(\mu)d\beta (\mu).,"['measure-theory', 'stieltjes-integral']"
40,"A question about a lemma in Kenneth Kunen's article ""Some points in $\beta \mathbb{N}$.""","A question about a lemma in Kenneth Kunen's article ""Some points in .""",\beta \mathbb{N},"The article reference is: Kunen, K. (1976). Some points in βN. Mathematical Proceedings of the Cambridge Philosophical Society, 80(3), 385-398. doi:10.1017/S0305004100053032. I am stuck in lemma 5.2 which says: Let $\mathcal{U}$ be a selective ultrafilter and $(\mathcal{M}, v)$ a non-atomic measure algebra. Then, in $V^{\mathcal{M}}$ , there is  no $\mathcal{P}$ -point extending $\mathcal{U}$ . The proof goes like this: ""Define a finitely additive measure $\rho$ on $\mathcal{P}(\omega)$ in $V^{\mathcal{M}}$ as follows. If $[[x\subseteq \omega]]=1$ , define a measure $\sigma_x$ on $\mathcal{M}$ (in $\mathcal{V}$ ) by $\sigma_x(b)=\mathcal{U}- \lim (v([[n\in x]] \wedge b):n\in \omega)$ . $\sigma_x$ may be identified with an $\mathcal{M}$ -valued element of $[0,1]$ , which we call $\rho(x)$ .  "" (The following is the assertion which i'm troubling with:) ""Since $\mathcal{M}$ is non-atomic, $\rho$ is with value 1 non-atomic. "" Why is $\rho$ with value 1, non-atomic? Sorry if the question is too little elaborate, but is something very specific I need to understand. Thanks for the help!!","The article reference is: Kunen, K. (1976). Some points in βN. Mathematical Proceedings of the Cambridge Philosophical Society, 80(3), 385-398. doi:10.1017/S0305004100053032. I am stuck in lemma 5.2 which says: Let be a selective ultrafilter and a non-atomic measure algebra. Then, in , there is  no -point extending . The proof goes like this: ""Define a finitely additive measure on in as follows. If , define a measure on (in ) by . may be identified with an -valued element of , which we call .  "" (The following is the assertion which i'm troubling with:) ""Since is non-atomic, is with value 1 non-atomic. "" Why is with value 1, non-atomic? Sorry if the question is too little elaborate, but is something very specific I need to understand. Thanks for the help!!","\mathcal{U} (\mathcal{M}, v) V^{\mathcal{M}} \mathcal{P} \mathcal{U} \rho \mathcal{P}(\omega) V^{\mathcal{M}} [[x\subseteq \omega]]=1 \sigma_x \mathcal{M} \mathcal{V} \sigma_x(b)=\mathcal{U}- \lim (v([[n\in x]] \wedge b):n\in \omega) \sigma_x \mathcal{M} [0,1] \rho(x) \mathcal{M} \rho \rho","['measure-theory', 'set-theory', 'proof-explanation', 'boolean-algebra']"
41,Martingale convergence theory question,Martingale convergence theory question,,"I'm confused on what this proof would look like. I know that by Martingale Convergence Theorem: $$X= \lim Z_n / \mu^n$$ exists a.s. I also know that Kesten Stigum Theorem: Assume that $E[L] >1$ and that $p_1 \neq 1$ . Then $X>0$ a.s. on the event of survival iff $E[L\log_{+} L] < \infty$ Is that theorem useful in proving what i want to prove? Edit: Let $\xi{i}^n , i, n, \geq 1$ be i.i.d. nonnegative integer random variables. Define a sequence $Z_n, n \geq 0 $ by $Z_0 =1$ and $Z_{n+1} = \xi_1^{n+1}+...+ \xi_{Z_n}^{n+1}$ if $Z_n >0$ , $0$ if $Z_n=0$ $Z_n$ is the galton-watosn process. $ \mu = E\xi_m^i \in (0,\infty)$","I'm confused on what this proof would look like. I know that by Martingale Convergence Theorem: exists a.s. I also know that Kesten Stigum Theorem: Assume that and that . Then a.s. on the event of survival iff Is that theorem useful in proving what i want to prove? Edit: Let be i.i.d. nonnegative integer random variables. Define a sequence by and if , if is the galton-watosn process.","X= \lim Z_n / \mu^n E[L] >1 p_1 \neq 1 X>0 E[L\log_{+} L] < \infty \xi{i}^n , i, n, \geq 1 Z_n, n \geq 0  Z_0 =1 Z_{n+1} = \xi_1^{n+1}+...+ \xi_{Z_n}^{n+1} Z_n >0 0 Z_n=0 Z_n  \mu = E\xi_m^i \in (0,\infty)","['measure-theory', 'martingales']"
42,Proof that continuous curve in $\mathbb{R}^2$ has Lebesgue measure zero,Proof that continuous curve in  has Lebesgue measure zero,\mathbb{R}^2,"Suppose $\Gamma$ is a curve $y = f(x)$ in $\mathbb{R}^2$ , where $f$ is continuous. Show that $m(\Gamma)=0.$ [Hint: Cover $\Gamma$ by rectangles, using the uniform continuity of $f$ .] My attempt: Let $\varepsilon>0$ be given. Take the real line and consider the segments with endpoints at the integers. Without loss of generality now consider the segment $[0,1].$ Note that this is a closed and bounded set, so $f$ is uniformly continuous on it. Let $0<\delta<1$ be the one that works for this uniform continuity, and if necessary, pick a smaller $\delta$ which can partition the interval evenly. Then we can write $[0,1]=[0,\delta]\cup[\delta,2\delta]\cup\cdot\cdot\cdot\cup[n\delta,1],$ for some $n\geq1$ . Then for $x\in [i\delta,(i+1)\delta],$ with $i=0,\dots,n-1$ , the curve is enclosed inside a rectangle of width $\delta$ and height $2\varepsilon$ . Hence the measure of that portion of the curve is smaller than or equal to $2\delta\varepsilon.$ Since $\varepsilon>0$ was  arbitrary, it follows that each such portion of the curve has measure zero, and hence the same follows for every other portion. Repeating this process for every other interval in the real line with endpoints at the integers yields the same result, and thus by countable sub-additivity, the result follows. Is the proof above correct? Any comments are welcomed, be it about correctness or the quality of the style of the proof. Thank you for your time and feedback.","Suppose is a curve in , where is continuous. Show that [Hint: Cover by rectangles, using the uniform continuity of .] My attempt: Let be given. Take the real line and consider the segments with endpoints at the integers. Without loss of generality now consider the segment Note that this is a closed and bounded set, so is uniformly continuous on it. Let be the one that works for this uniform continuity, and if necessary, pick a smaller which can partition the interval evenly. Then we can write for some . Then for with , the curve is enclosed inside a rectangle of width and height . Hence the measure of that portion of the curve is smaller than or equal to Since was  arbitrary, it follows that each such portion of the curve has measure zero, and hence the same follows for every other portion. Repeating this process for every other interval in the real line with endpoints at the integers yields the same result, and thus by countable sub-additivity, the result follows. Is the proof above correct? Any comments are welcomed, be it about correctness or the quality of the style of the proof. Thank you for your time and feedback.","\Gamma y = f(x) \mathbb{R}^2 f m(\Gamma)=0. \Gamma f \varepsilon>0 [0,1]. f 0<\delta<1 \delta [0,1]=[0,\delta]\cup[\delta,2\delta]\cup\cdot\cdot\cdot\cup[n\delta,1], n\geq1 x\in [i\delta,(i+1)\delta], i=0,\dots,n-1 \delta 2\varepsilon 2\delta\varepsilon. \varepsilon>0","['real-analysis', 'measure-theory', 'proof-verification', 'lebesgue-measure']"
43,Approximation of an element in the dual of the Sobolev Space,Approximation of an element in the dual of the Sobolev Space,,"Let $F\in L^2(\Omega)$ be such that $-\text{div}F\in W^{-1,2}(\Omega)$ (Dual of the Sobolev Space $W_0^{1,2}(\Omega)$ ) be non-negative where $\Omega$ is a bounded domain in $\mathbb{R}^N$ . My question is about the existence of an approximation of $-\text{div}F$ in such a way that (1) there exists a sequence of function $F_n\in (W^{1,\infty}(\Omega))^N$ which converges to $F$ in $L^2(\Omega)$ with the property $F_n\leq F$ in $\Omega$ (2) Moreover, $-\text{div}(F_n)\geq f$ for some $f\geq 0$ in $\Omega$ and $f\geq c_{k}>0$ for all $k\subset\subset\Omega$ . Can you kindly help me whether such approximation is possible or not, even if one imposes some extra hypothesis on $F$ ? Thanks in advance.","Let be such that (Dual of the Sobolev Space ) be non-negative where is a bounded domain in . My question is about the existence of an approximation of in such a way that (1) there exists a sequence of function which converges to in with the property in (2) Moreover, for some in and for all . Can you kindly help me whether such approximation is possible or not, even if one imposes some extra hypothesis on ? Thanks in advance.","F\in L^2(\Omega) -\text{div}F\in W^{-1,2}(\Omega) W_0^{1,2}(\Omega) \Omega \mathbb{R}^N -\text{div}F F_n\in (W^{1,\infty}(\Omega))^N F L^2(\Omega) F_n\leq F \Omega -\text{div}(F_n)\geq f f\geq 0 \Omega f\geq c_{k}>0 k\subset\subset\Omega F","['functional-analysis', 'measure-theory', 'partial-differential-equations', 'harmonic-analysis', 'regularity-theory-of-pdes']"
44,"Problem with showing the integrability of $\int_{B}(x^2+y^2)^{-3/2}d\lambda^2(x,y)$",Problem with showing the integrability of,"\int_{B}(x^2+y^2)^{-3/2}d\lambda^2(x,y)","Define $B:=\{(x,y) \in \mathbb R^{2}: x^2+y^2\leq1\}$ , determine whether $$ \int_{B}\frac{1}{(x^2+y^2)^{3/2}}d\lambda^2(x,y) \quad \text{and} \quad \int_{\mathbb R^2-B}\frac{1}{(x^2+y^2)^{3/2}}d\lambda^2(x,y) $$ are integrable. My ideas: Set $C:=\{(x,y) \in \mathbb R_{+}^{2}: x^2+y^2\leq1\}$ to get $$ \begin{split} I &= \int_{B}\frac{1}{(x^2+y^2)^{3/2}}d\lambda^2(x,y) \\   &= 2\int_{C}\frac{1}{(x^2+y^2)^{3/2}} d\lambda^2(x,y)      \quad \text{and using polar coordinates} \\   &= 2\int_0^1 \int_0^\pi \frac{rd\phi dr}{r^3} \\   &= 2\pi \left[\left.-\frac{1}{r}\right|_{0}^{1}\right]    =\infty \end{split} $$ I do not know what to say on the case $$\int_{\mathbb R^2-B}\frac{1}{(x^2+y^2)^{3/2}}d\lambda^2(x,y).$$ It is clear that it is not integrable but how do I show this? Questions : In the above case finding $$ \int_B \left|\frac{1}{(x^2+y^2)^{3/2}}\right|d\lambda^2(x,y) $$ was easy due to the symmetry of on $B$ , but how can I solve a problem like when there is no symmetry involved? Do I simply divide the functions in positive and negative parts? Our professors are very pedantic on the use of correct reasoning. I need to reason why I can write $$\int_{B}|\frac{1}{(x^2+y^2)^{3/2}}|d\lambda^2(x,y),$$ in other words I need to reason why $$\left|\frac{1}{(x^2+y^2)^{3/2}}\right|$$ is measurable but surely I cannot show this as ( $f$ measurable $\Rightarrow |f|$ measurable ) is not true in general is it?","Define , determine whether are integrable. My ideas: Set to get I do not know what to say on the case It is clear that it is not integrable but how do I show this? Questions : In the above case finding was easy due to the symmetry of on , but how can I solve a problem like when there is no symmetry involved? Do I simply divide the functions in positive and negative parts? Our professors are very pedantic on the use of correct reasoning. I need to reason why I can write in other words I need to reason why is measurable but surely I cannot show this as ( measurable measurable ) is not true in general is it?","B:=\{(x,y) \in \mathbb R^{2}: x^2+y^2\leq1\} 
\int_{B}\frac{1}{(x^2+y^2)^{3/2}}d\lambda^2(x,y)
\quad \text{and} \quad
\int_{\mathbb R^2-B}\frac{1}{(x^2+y^2)^{3/2}}d\lambda^2(x,y)
 C:=\{(x,y) \in \mathbb R_{+}^{2}: x^2+y^2\leq1\} 
\begin{split}
I &= \int_{B}\frac{1}{(x^2+y^2)^{3/2}}d\lambda^2(x,y) \\
  &= 2\int_{C}\frac{1}{(x^2+y^2)^{3/2}} d\lambda^2(x,y)
     \quad \text{and using polar coordinates} \\
  &= 2\int_0^1 \int_0^\pi \frac{rd\phi dr}{r^3} \\
  &= 2\pi \left[\left.-\frac{1}{r}\right|_{0}^{1}\right]
   =\infty
\end{split}
 \int_{\mathbb R^2-B}\frac{1}{(x^2+y^2)^{3/2}}d\lambda^2(x,y). 
\int_B \left|\frac{1}{(x^2+y^2)^{3/2}}\right|d\lambda^2(x,y)
 B \int_{B}|\frac{1}{(x^2+y^2)^{3/2}}|d\lambda^2(x,y), \left|\frac{1}{(x^2+y^2)^{3/2}}\right| f \Rightarrow |f|","['real-analysis', 'integration', 'measure-theory']"
45,"Problem about Borel-measurability, pushforward measure and $L^1$ spaces.","Problem about Borel-measurability, pushforward measure and  spaces.",L^1,"I am trying to solve this exercise. I get stuck in the last part, but I write all the exercise for context. Also, I am not sure that some explanations I give are enough to justify these results. (Sorry for my poor English) Let $\varphi: \mathbb R \to \mathbb R$ be the function given by $$\varphi (x) = \dfrac{2x}{x-1} \chi _{(-\infty, -1)} (x) + \chi _{[-1,1]} (x) + \dfrac{2x}{x+1} \chi _{(1,+\infty)} (x), \quad x \in \mathbb R.$$ Prove that $\varphi$ is Borel-measurable over $\mathbb R$ . Let $m$ be the Borel-Lebesgue measure in $\mathbb R$ . Find the pushforward measure $\varphi (m)$ over the $\sigma$ -algebra of the borel sets of $\mathbb R$ and its Lebesgue decomposition with respect to $m$ . Let $$f(y) = \sqrt{2-y} \, \arctan (2-y) \, \chi _{(0,2)} (y), \quad y \in \mathbb R.$$ Show that $f\in L^1 (\varphi (m))$ . Since $\varphi$ is continuous, it is Borel-measurable. (I feel that I have been lucky with this. What would I have to do to prove Borel-measurability if it wasn't continuous?) Drawing $\varphi(x)$ I find that the support of $\varphi(m)$ is $[1,+\infty)$ . Let $E\subseteq (-\infty, 1)$ , then $\varphi(m)(E)=0$ . Also, $$\varphi(m) (\{ 1 \})= m (\varphi ^{-1} (1)) = m ([-1,1]) =2.$$ Let $(a,b)\subset (1,+\infty)$ , then $$\varphi^{-1}((a,b))=\left( \frac{b}{b-2}, \frac{a}{a-2} \right) \cup \left( \frac{a}{2-a}, \frac{b}{2-b} \right).$$ Then $$m(\varphi ^{-1} ((a,b)))=\left( \frac{a}{a-2}- \frac{b}{b-2} \right) + \left( \frac{b}{2-b}-\frac{a}{2-a} \right)=$$ $$=2\left( \frac{a}{a-2}- \frac{b}{b-2} \right)=-2\left( \frac{b}{b-2}- \frac{a}{a-2} \right)=$$ $$=-2\int _a ^b \! \left( \frac{t}{t-2} \right) ' \, \mathrm d t=-2\int _a ^b \! \frac{-2}{(t-2)^2} \, \mathrm d t=4\int _a ^b \! \frac{1}{(t-2)^2} \, \mathrm d t.$$ Therefore we can write (is this correct?) $$\varphi (m) ((a,b))= \underbrace{2 \delta _{\{1\}}}_{\varphi(m)_s}+\underbrace{4\chi_{[1,+\infty)}\int _a ^b \! \frac{1}{(t-2)^2} \, \mathrm d t}_{\varphi(m)_a},$$ where $\varphi(m)_s \perp m$ and $\varphi(m)_a \ll m$ . Thus we have found its Lebesgue decomposition. I don't know how to solve this part. The only thing that crosses my mind is that $f\in L^1 \varphi(m)$ if and only if $$\int \vert f \vert \, \mathrm d \varphi (m)=\int (\vert f \vert \circ \varphi) \mathrm d m \in \mathbb R.$$ But it seems hard to compute that integral and maybe is there something easier that I am not thinking. Thank you for your help.","I am trying to solve this exercise. I get stuck in the last part, but I write all the exercise for context. Also, I am not sure that some explanations I give are enough to justify these results. (Sorry for my poor English) Let be the function given by Prove that is Borel-measurable over . Let be the Borel-Lebesgue measure in . Find the pushforward measure over the -algebra of the borel sets of and its Lebesgue decomposition with respect to . Let Show that . Since is continuous, it is Borel-measurable. (I feel that I have been lucky with this. What would I have to do to prove Borel-measurability if it wasn't continuous?) Drawing I find that the support of is . Let , then . Also, Let , then Then Therefore we can write (is this correct?) where and . Thus we have found its Lebesgue decomposition. I don't know how to solve this part. The only thing that crosses my mind is that if and only if But it seems hard to compute that integral and maybe is there something easier that I am not thinking. Thank you for your help.","\varphi: \mathbb R \to \mathbb R \varphi (x) = \dfrac{2x}{x-1} \chi _{(-\infty, -1)} (x) + \chi _{[-1,1]} (x) + \dfrac{2x}{x+1} \chi _{(1,+\infty)} (x), \quad x \in \mathbb R. \varphi \mathbb R m \mathbb R \varphi (m) \sigma \mathbb R m f(y) = \sqrt{2-y} \, \arctan (2-y) \, \chi _{(0,2)} (y), \quad y \in \mathbb R. f\in L^1 (\varphi (m)) \varphi \varphi(x) \varphi(m) [1,+\infty) E\subseteq (-\infty, 1) \varphi(m)(E)=0 \varphi(m) (\{ 1 \})= m (\varphi ^{-1} (1)) = m ([-1,1]) =2. (a,b)\subset (1,+\infty) \varphi^{-1}((a,b))=\left( \frac{b}{b-2}, \frac{a}{a-2} \right) \cup \left( \frac{a}{2-a}, \frac{b}{2-b} \right). m(\varphi ^{-1} ((a,b)))=\left( \frac{a}{a-2}- \frac{b}{b-2} \right) + \left( \frac{b}{2-b}-\frac{a}{2-a} \right)= =2\left( \frac{a}{a-2}- \frac{b}{b-2} \right)=-2\left( \frac{b}{b-2}- \frac{a}{a-2} \right)= =-2\int _a ^b \! \left( \frac{t}{t-2} \right) ' \, \mathrm d t=-2\int _a ^b \! \frac{-2}{(t-2)^2} \, \mathrm d t=4\int _a ^b \! \frac{1}{(t-2)^2} \, \mathrm d t. \varphi (m) ((a,b))= \underbrace{2 \delta _{\{1\}}}_{\varphi(m)_s}+\underbrace{4\chi_{[1,+\infty)}\int _a ^b \! \frac{1}{(t-2)^2} \, \mathrm d t}_{\varphi(m)_a}, \varphi(m)_s \perp m \varphi(m)_a \ll m f\in L^1 \varphi(m) \int \vert f \vert \, \mathrm d \varphi (m)=\int (\vert f \vert \circ \varphi) \mathrm d m \in \mathbb R.","['integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
46,Distribution of Gaussian Random variable. Concentrated measure.,Distribution of Gaussian Random variable. Concentrated measure.,,"Let $\mu$ be the standard Gaussian distribution on $\mathbb{R}$ . Show that if $B$ is a Borel set (w.r.t the Euclidean metric) and $\mu(B)\geq 1/2$ then $$\mu(B_{r})\geq 1-\frac{1}{2}e^{-\frac{t^2}{2}} $$ For all $r>0$ , where $B_{r} := \{x \in \mathbb{R} : \inf_{y\in B} |x-y|<r \}$ . Attempt : Since $\mu(B)\geq 1/2$ (and since we are centred) it follows $\mu(B_{r})\geq \mu((-\infty,r])$ So $$\mu(B_{r})\geq 1- \int_{r}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-(t^2)/2}dt\geq 1-\frac{1}{\sqrt{2\pi}r}e^{-(r^2)/2}$$","Let be the standard Gaussian distribution on . Show that if is a Borel set (w.r.t the Euclidean metric) and then For all , where . Attempt : Since (and since we are centred) it follows So","\mu \mathbb{R} B \mu(B)\geq 1/2 \mu(B_{r})\geq 1-\frac{1}{2}e^{-\frac{t^2}{2}}  r>0 B_{r} := \{x \in \mathbb{R} : \inf_{y\in B} |x-y|<r \} \mu(B)\geq 1/2 \mu(B_{r})\geq \mu((-\infty,r]) \mu(B_{r})\geq 1- \int_{r}^{\infty}\frac{1}{\sqrt{2\pi}}e^{-(t^2)/2}dt\geq 1-\frac{1}{\sqrt{2\pi}r}e^{-(r^2)/2}","['probability', 'measure-theory', 'normal-distribution', 'gaussian-integral']"
47,von Neumann sub algebras of $L^{\infty}$,von Neumann sub algebras of,L^{\infty},"I know that $L^{\infty}([0,1],\mu)$ acting on $L^{2}([0,1],\mu)$ is a von Neumann algebra. How will be the von Neumann sub algebras $L^{\infty}([0,1],\mu)$ look like?",I know that acting on is a von Neumann algebra. How will be the von Neumann sub algebras look like?,"L^{\infty}([0,1],\mu) L^{2}([0,1],\mu) L^{\infty}([0,1],\mu)","['measure-theory', 'von-neumann-algebras']"
48,"Formal construction of the Cantor set $K$ and determination of $[0,1]\setminus K.$",Formal construction of the Cantor set  and determination of,"K [0,1]\setminus K.","Let $J_{0,1}:=[0,1]$ . Step 1. We remove the central open interval $I_{0,1}=\big(\frac{1}{3},\frac{2}{3}\big)$ . We denote with $J_{1,1}:=\big[0,\frac{1}{3}\big]$ and with $J_{1,2}:=\big[\frac{2}{3},1\big]$ . We define $K_1:=J_{1,1}\cup J_{1,2}$ then $\complement{K_1}=I_{0,1}.$ Step 2. We remove from $J_{1,1}$ and $J_{1,2}$ the central open interval of length $\frac{1}{9}$ . Then we define what remains with $K_2:=J_{2,1}\cup J_{2,2}\cup J_{2,3}\cup J_{2,4}$ , where $J_{2,1}=\big[0,\frac{1}{9}\big]$ , $J_{2,2}=\big[\frac{2}{9},\frac{1}{3}\big]$ , $J_{2,3}=\big[\frac{2}{3},\frac{7}{9}\big]$ , $J_{2,4}=\big[\frac{8}{9}, 1\big]$ . At this point we define with $I_{1,1}=\big(\frac{1}{9}, \frac{2}{9}\big)$ , $I_{1,2}=\big(\frac{7}{9},\frac{8}{9}\big)$ the two open interval just removed. Therefore, $\complement{K_2}=\complement{K_1}\cup \big(I_{1,1}\cup I_{1,2}\big)$ At the end of step $n$ we will have $2^n$ close interval $J_{n,k}$ for $k=1,\cdots, 2^n$ of length $1/3^n.$ For all $n\in\mathbb{N}$ we define $$K_{n}:=\bigcup_{k=1}^{2^n} J_{n,k}$$ We define the Cantor set $K$ in the follow way $$K:=\bigcap_{n=1}^{+\infty} K_n.$$ In general, as discussed above, $$\complement{K_n}= \complement{K_{n-1}}\cup\bigcup_{k=1}^{2^n/2} I_{n-1,k}\tag1$$ Question 1. It's correct (1)? We determine, $$[0,1]\setminus K=[0,1]\cap \bigg[\bigcup_{n=1}^{+\infty}\complement{K_{n-1}}\cup \bigcup_{n=1}^{+\infty}\bigcup_{k=1}^{2^n/2} I_{n-1,k}\bigg]\tag2$$ Question 2. How can I proceed in (2)? I would like to prove that $$[0,1]\setminus K =\bigcup_{n=0}^{+\infty}\bigcup_{k=1}^{2^n}I_{n,k}.$$ My answer at question 2. \begin{equation} \begin{split} [0,1]\setminus K &= [0,1]\cap\bigg[\bigcup_{n=1}^{+\infty}\complement{K_n}\bigg]\\ =&\bigcup_{n=1}^{+\infty} \complement{K_n}\\ =&\bigcup_{n=1}^{+\infty}\complement{K_{n-1}}\cup\bigcup_{n=1}^{+\infty}\bigcup_{k=1}^{2^n/2}I_{n-1,k}\\ \color{BLUE}{=}& \bigcup_{n=1}^{+\infty}\bigcup_{k=1}^{2^n/2} I_{n-1,k}\\ \color{RED}{=}&\bigcup_{n=0}^{+\infty}\bigcup_{k=1}^{2^n} I_{n,k}. \end{split} \end{equation} For the blue equality I used the fact that $$\bigcup_{n=1}^{+\infty}\complement{K_{n-1}}\subseteq\bigcup_{n=1}^{+\infty}\bigcup_{k=1}^{2^n/2}I_{n-1,k} $$ and the red equality it is a simple rewriting of the indexes. Question 3. It's correct my answer? Thanks!","Let . Step 1. We remove the central open interval . We denote with and with . We define then Step 2. We remove from and the central open interval of length . Then we define what remains with , where , , , . At this point we define with , the two open interval just removed. Therefore, At the end of step we will have close interval for of length For all we define We define the Cantor set in the follow way In general, as discussed above, Question 1. It's correct (1)? We determine, Question 2. How can I proceed in (2)? I would like to prove that My answer at question 2. For the blue equality I used the fact that and the red equality it is a simple rewriting of the indexes. Question 3. It's correct my answer? Thanks!","J_{0,1}:=[0,1] I_{0,1}=\big(\frac{1}{3},\frac{2}{3}\big) J_{1,1}:=\big[0,\frac{1}{3}\big] J_{1,2}:=\big[\frac{2}{3},1\big] K_1:=J_{1,1}\cup J_{1,2} \complement{K_1}=I_{0,1}. J_{1,1} J_{1,2} \frac{1}{9} K_2:=J_{2,1}\cup J_{2,2}\cup J_{2,3}\cup J_{2,4} J_{2,1}=\big[0,\frac{1}{9}\big] J_{2,2}=\big[\frac{2}{9},\frac{1}{3}\big] J_{2,3}=\big[\frac{2}{3},\frac{7}{9}\big] J_{2,4}=\big[\frac{8}{9}, 1\big] I_{1,1}=\big(\frac{1}{9}, \frac{2}{9}\big) I_{1,2}=\big(\frac{7}{9},\frac{8}{9}\big) \complement{K_2}=\complement{K_1}\cup \big(I_{1,1}\cup I_{1,2}\big) n 2^n J_{n,k} k=1,\cdots, 2^n 1/3^n. n\in\mathbb{N} K_{n}:=\bigcup_{k=1}^{2^n} J_{n,k} K K:=\bigcap_{n=1}^{+\infty} K_n. \complement{K_n}= \complement{K_{n-1}}\cup\bigcup_{k=1}^{2^n/2} I_{n-1,k}\tag1 [0,1]\setminus K=[0,1]\cap \bigg[\bigcup_{n=1}^{+\infty}\complement{K_{n-1}}\cup \bigcup_{n=1}^{+\infty}\bigcup_{k=1}^{2^n/2} I_{n-1,k}\bigg]\tag2 [0,1]\setminus K =\bigcup_{n=0}^{+\infty}\bigcup_{k=1}^{2^n}I_{n,k}. \begin{equation}
\begin{split}
[0,1]\setminus K &= [0,1]\cap\bigg[\bigcup_{n=1}^{+\infty}\complement{K_n}\bigg]\\
=&\bigcup_{n=1}^{+\infty} \complement{K_n}\\
=&\bigcup_{n=1}^{+\infty}\complement{K_{n-1}}\cup\bigcup_{n=1}^{+\infty}\bigcup_{k=1}^{2^n/2}I_{n-1,k}\\
\color{BLUE}{=}& \bigcup_{n=1}^{+\infty}\bigcup_{k=1}^{2^n/2} I_{n-1,k}\\
\color{RED}{=}&\bigcup_{n=0}^{+\infty}\bigcup_{k=1}^{2^n} I_{n,k}.
\end{split}
\end{equation} \bigcup_{n=1}^{+\infty}\complement{K_{n-1}}\subseteq\bigcup_{n=1}^{+\infty}\bigcup_{k=1}^{2^n/2}I_{n-1,k} ","['real-analysis', 'measure-theory', 'lebesgue-measure', 'cantor-set']"
49,Egorov’s theorem: Small compact set,Egorov’s theorem: Small compact set,,"Let $K \subset \mathbb R^n, n \in \mathbb N$ , be compact and suppose the measurable $f_n: K \to \mathbb R$ converge almost everywhere to a function $f: K \to \mathbb R$ . By Egorov‘s theorem, for any $\varepsilon \gt 0$ we may find a measurable $A_\varepsilon$ with $|A_\varepsilon| \lt \varepsilon$ and $f_n \to f$ uniformly on $K \setminus A_\varepsilon$ . One can always find an $A_\varepsilon$ additionally being open. Question: Can one also always find a compact set $A_\varepsilon$ (satisfying $|A_\varepsilon| \lt \varepsilon$ and $f_n \to f$ uniformly on $K \setminus A_\varepsilon$ )? Sadly, the measure of the closure of an open set may be much larger than the measure of the open set, so I am not really sure where to start here. However, I was also unable to come up with a counter example.","Let , be compact and suppose the measurable converge almost everywhere to a function . By Egorov‘s theorem, for any we may find a measurable with and uniformly on . One can always find an additionally being open. Question: Can one also always find a compact set (satisfying and uniformly on )? Sadly, the measure of the closure of an open set may be much larger than the measure of the open set, so I am not really sure where to start here. However, I was also unable to come up with a counter example.","K \subset \mathbb R^n, n \in \mathbb N f_n: K \to \mathbb R f: K \to \mathbb R \varepsilon \gt 0 A_\varepsilon |A_\varepsilon| \lt \varepsilon f_n \to f K \setminus A_\varepsilon A_\varepsilon A_\varepsilon |A_\varepsilon| \lt \varepsilon f_n \to f K \setminus A_\varepsilon","['real-analysis', 'measure-theory']"
50,Definition of ergodic map,Definition of ergodic map,,"I ask the similar question before. About definition of Ergodic theorem . Now just sincerely ask another fundamental problem about the definition of ergodic map. The following definition is what I read in my textbook: Let $(X,\mathcal{A},\mu)$ be a probability space. Let $T: X\rightarrow X$ is $\mu$ -invariant ( $\mu$ -preserving). Then $T$ is ergodic if for every $E\in \mathcal{A}$ with $T^{-1}(E) = E$ if and only if $\mu(E)=0$ or $1$ . In this definition, it requires $T^{-1}(E) = E$ . However, in the following paper, it seems to use $T(E) = E$ as the definition. https://www.tandfonline.com/doi/abs/10.1080/10236190601045788 (p.1154, Def 2.16, please also see "" $A$ is invariant, i.e. $T(A)=A$ on the top of that page."") My questions are: What is the difference between them? or is the definition in the paper not correct? For the definition by using $T^{-1}(E) = E$ , does it imply $E$ is not an attractor? since the only initial condition such that $T(x_0) \in E$ is $x_0 \in E$ instead of $x_0\in X\setminus E$ . So if we want to discuss $E$ being an attractor, we have to use $T(E) = E$ since this could imply the possibility that $T(x)\in E$ for $x\in X\setminus E$ . Do I make sense? Thanks in advance.","I ask the similar question before. About definition of Ergodic theorem . Now just sincerely ask another fundamental problem about the definition of ergodic map. The following definition is what I read in my textbook: Let be a probability space. Let is -invariant ( -preserving). Then is ergodic if for every with if and only if or . In this definition, it requires . However, in the following paper, it seems to use as the definition. https://www.tandfonline.com/doi/abs/10.1080/10236190601045788 (p.1154, Def 2.16, please also see "" is invariant, i.e. on the top of that page."") My questions are: What is the difference between them? or is the definition in the paper not correct? For the definition by using , does it imply is not an attractor? since the only initial condition such that is instead of . So if we want to discuss being an attractor, we have to use since this could imply the possibility that for . Do I make sense? Thanks in advance.","(X,\mathcal{A},\mu) T: X\rightarrow X \mu \mu T E\in \mathcal{A} T^{-1}(E) = E \mu(E)=0 1 T^{-1}(E) = E T(E) = E A T(A)=A T^{-1}(E) = E E T(x_0) \in E x_0 \in E x_0\in X\setminus E E T(E) = E T(x)\in E x\in X\setminus E","['measure-theory', 'operator-theory', 'ergodic-theory']"
51,Infinite product of Haar measures,Infinite product of Haar measures,,"Suppose that $(G_n,\mu_n)$ is a sequence of compact metrizable groups such that each $\mu_n$ is a probability (right-invariant) Haar measure on $G_n$ . Is it true that the product measure $\otimes_n \mu_n$ on $\prod_n G_n$ is also the unique probability (right-invariant) Haar measure on it ? Edit : we consider compact metrizable groups so the Borel sigma algebra of the product is the product sigma-algebra.",Suppose that is a sequence of compact metrizable groups such that each is a probability (right-invariant) Haar measure on . Is it true that the product measure on is also the unique probability (right-invariant) Haar measure on it ? Edit : we consider compact metrizable groups so the Borel sigma algebra of the product is the product sigma-algebra.,"(G_n,\mu_n) \mu_n G_n \otimes_n \mu_n \prod_n G_n","['probability', 'group-theory', 'measure-theory']"
52,Terrence Tao's definition of Lebesgue measurability as an extension of Jordan measurability,Terrence Tao's definition of Lebesgue measurability as an extension of Jordan measurability,,"I'm reading Terrence Tao's An Introduction to Measure Theory. On pp. 20, he writes, In analogy with the Jordan theory, we would also like to define   a concept of “Lebesgue inner measure” to complement that of outer   measure. Here, there is an asymmetry (which ultimately arises from   the fact that elementary measure is subadditive rather than superadditive): one does not gain any increase in power in the Jordan inner   measure by replacing finite unions of boxes with countable ones. I don't quite get this argument. The definition of the Jordan Inner Measure is: For a bounded set, $A$ , in $\mathbb{R}^d$ , \begin{align} m_{* (J)}(A) = \sup_{E \subset A} m(A),  \end{align} where $E$ is an elementary set in $\mathbb{R}^d$ definite to be the finite union of boxes, which are just $d-$ dimensional Cartesian products of intervals in $\mathbb{R}$ . If we replace finite unions by countable unions, we can define, \begin{align} m_{* (L)}(A) = \sup_{E \subset A} m(A), \end{align} where $m_{*(L)}(A)$ is the Lebesgue inner measure. Clearly, we have, \begin{align} m_{*(J)}(A) \leq m_{*(L)}(A). \end{align} This is analogous to the result, \begin{align} m^{*(L)}(A) \leq m^{*(J)}(A). \end{align} Since it's not too hard to show that, \begin{align} m_{*(L)}(A) \leq m^{*(L)}(A), \end{align} we have, \begin{align} m_{*(J)}(A) \leq m_{*(L)}(A) \leq m^{*(L)}(A) \leq m^{*(L)}(A). \end{align} Hence the Lebesgue measure can be though of as a refinement of the Jordan measure. In light of this discussion, why does Tao dismiss the idea of defining the Lebesgue measurable sets as those for which the inner and outer measures coincide? Here are the link to the notes: https://terrytao.files.wordpress.com/2011/01/measure-book1.pdf","I'm reading Terrence Tao's An Introduction to Measure Theory. On pp. 20, he writes, In analogy with the Jordan theory, we would also like to define   a concept of “Lebesgue inner measure” to complement that of outer   measure. Here, there is an asymmetry (which ultimately arises from   the fact that elementary measure is subadditive rather than superadditive): one does not gain any increase in power in the Jordan inner   measure by replacing finite unions of boxes with countable ones. I don't quite get this argument. The definition of the Jordan Inner Measure is: For a bounded set, , in , where is an elementary set in definite to be the finite union of boxes, which are just dimensional Cartesian products of intervals in . If we replace finite unions by countable unions, we can define, where is the Lebesgue inner measure. Clearly, we have, This is analogous to the result, Since it's not too hard to show that, we have, Hence the Lebesgue measure can be though of as a refinement of the Jordan measure. In light of this discussion, why does Tao dismiss the idea of defining the Lebesgue measurable sets as those for which the inner and outer measures coincide? Here are the link to the notes: https://terrytao.files.wordpress.com/2011/01/measure-book1.pdf","A \mathbb{R}^d \begin{align}
m_{* (J)}(A) = \sup_{E \subset A} m(A), 
\end{align} E \mathbb{R}^d d- \mathbb{R} \begin{align}
m_{* (L)}(A) = \sup_{E \subset A} m(A),
\end{align} m_{*(L)}(A) \begin{align}
m_{*(J)}(A) \leq m_{*(L)}(A).
\end{align} \begin{align}
m^{*(L)}(A) \leq m^{*(J)}(A).
\end{align} \begin{align}
m_{*(L)}(A) \leq m^{*(L)}(A),
\end{align} \begin{align}
m_{*(J)}(A) \leq m_{*(L)}(A) \leq m^{*(L)}(A) \leq m^{*(L)}(A).
\end{align}",['measure-theory']
53,Isn't a semialgebra an algebra?,Isn't a semialgebra an algebra?,,"I was solving this exercise in a book, ""A First Look at Rigorous Probability Theory"", by Jeffrey Rosenthal. Exercise 2.7.3. Suppose $\mathcal{F}$ is a  collection of subsets of $\Omega$ , such that $\Omega \in \mathcal{F}$ . b) Assume $\mathcal{F}$ is a semialgebra.  Prove that $\mathcal{F}$ is an algebra. However, it seems to me this exercise is wrong.  A counterexample suffices to show it. Suppose a set $\mathcal{J}$ of all intervals in $[0,1]$ . Then, it is easy to show that $\mathcal{J}$ is a semi-algebra. Suppose two different intervals $A = [0,\frac{1}{3}]$ and $B = [\frac{2}{3},1]$ are present in $\mathcal{J}$ . $A \cup B$ does not belong to $\mathcal{J}$ because it is not an interval. $\mathcal{J}$ is not an algebra because it is not closed under finite unions. Am I missing something?","I was solving this exercise in a book, ""A First Look at Rigorous Probability Theory"", by Jeffrey Rosenthal. Exercise 2.7.3. Suppose is a  collection of subsets of , such that . b) Assume is a semialgebra.  Prove that is an algebra. However, it seems to me this exercise is wrong.  A counterexample suffices to show it. Suppose a set of all intervals in . Then, it is easy to show that is a semi-algebra. Suppose two different intervals and are present in . does not belong to because it is not an interval. is not an algebra because it is not closed under finite unions. Am I missing something?","\mathcal{F} \Omega \Omega \in \mathcal{F} \mathcal{F} \mathcal{F} \mathcal{J} [0,1] \mathcal{J} A = [0,\frac{1}{3}] B = [\frac{2}{3},1] \mathcal{J} A \cup B \mathcal{J} \mathcal{J}","['measure-theory', 'examples-counterexamples']"
54,"$f$ integrable on $A \times B$, show subset of $A$ is negligible","integrable on , show subset of  is negligible",f A \times B A,"$A \subset \mathbb R^m$ and $B \subset \mathbb R^n$ are boxes, and $f$ is integrable in the riemann sense on $(A\times B)$ . We define $$A_1 =\left\{a \in A \left|\exists \int_{B}f(a,b)db\right.\right\} \subset A.$$ Show that $A \setminus A_1$ has zero volume.","and are boxes, and is integrable in the riemann sense on . We define Show that has zero volume.","A \subset \mathbb R^m B \subset \mathbb R^n f (A\times B) A_1 =\left\{a \in A \left|\exists \int_{B}f(a,b)db\right.\right\} \subset A. A \setminus A_1","['integration', 'measure-theory']"
55,Is the sum of such two banach spaces also a banach space?,Is the sum of such two banach spaces also a banach space?,,"Let $L^2(\mu)$ and $L^2(\nu)$ with respect to two different positive measures, then they are two Banach spaces. I'm considering whether the space $$L^2(\mu)+L^2(\nu)$$ is still a Banach space? e.g. $\mu$ be Lebesgue measure, $d\nu=ln(1+|x|)d\mu$ , my idea is that since both $L^2(\mu)$ and $L^2(\nu)$ are continuous embedded to the measurable functions space $\mathcal M$ , it's done.","Let and with respect to two different positive measures, then they are two Banach spaces. I'm considering whether the space is still a Banach space? e.g. be Lebesgue measure, , my idea is that since both and are continuous embedded to the measurable functions space , it's done.",L^2(\mu) L^2(\nu) L^2(\mu)+L^2(\nu) \mu d\nu=ln(1+|x|)d\mu L^2(\mu) L^2(\nu) \mathcal M,"['real-analysis', 'functional-analysis', 'measure-theory']"
56,Adaptedness of Solution to SPDE,Adaptedness of Solution to SPDE,,"I'm trying to understand existence of solutions to SDPEs of the form $$ dX = AXdt + F(t,X)dt + B(t,X)dW $$ from the Hilbert space point of view, following Da Prato & Zabcyzk.  They rely on the standard fixe point method, showing that if the interval $[0,T]$ , is sufficiently small, the mapping $$ \mathcal{K}(Y)(t)= S(t)\xi + \int_0^t S(t-s)F(t,Y)dt + S(t-s)B(t,Y)dW $$ has a fixed point in the space $$ C([0,T];L^2(\Omega, \mathbb{P};H)) $$ equipped with the norm $$ \|X\|_T^2= \sup_{0\leq t\leq T}\mathbb{E}\|X(t)\|_H^2. $$ The existence argument is standard, using the sequence $X_0 =\xi$ , $X_{n+1} = \mathcal{K}(X_n)$ . What I am curious/unsure about is the adaptedness, both of the sequence and the limiting solution.  Assuming $\xi$ is $\mathcal{F}_0$ , how can I see that: Each $X_n$ is adapted The limit, $X$ , is also adapted","I'm trying to understand existence of solutions to SDPEs of the form from the Hilbert space point of view, following Da Prato & Zabcyzk.  They rely on the standard fixe point method, showing that if the interval , is sufficiently small, the mapping has a fixed point in the space equipped with the norm The existence argument is standard, using the sequence , . What I am curious/unsure about is the adaptedness, both of the sequence and the limiting solution.  Assuming is , how can I see that: Each is adapted The limit, , is also adapted","
dX = AXdt + F(t,X)dt + B(t,X)dW
 [0,T] 
\mathcal{K}(Y)(t)= S(t)\xi + \int_0^t S(t-s)F(t,Y)dt + S(t-s)B(t,Y)dW
 
C([0,T];L^2(\Omega, \mathbb{P};H))
 
\|X\|_T^2= \sup_{0\leq t\leq T}\mathbb{E}\|X(t)\|_H^2.
 X_0 =\xi X_{n+1} = \mathcal{K}(X_n) \xi \mathcal{F}_0 X_n X","['probability', 'measure-theory', 'stochastic-processes']"
57,Bochner integrability of mappings of Bochner integrable functions,Bochner integrability of mappings of Bochner integrable functions,,"Suppose I have a Bochner integrable function, $t\mapsto u(t)\in X$ , with $X$ a separable Banach space, and $0\leq t\leq T<\infty$ .  If I introduce a mapping $f:[0,T]\times X\to X$ , under what assumptions will $t\mapsto f(t,u(t))$ be Bochner integrable?  Is joint measurabiity of $f$ sufficient?  Continuity?","Suppose I have a Bochner integrable function, , with a separable Banach space, and .  If I introduce a mapping , under what assumptions will be Bochner integrable?  Is joint measurabiity of sufficient?  Continuity?","t\mapsto u(t)\in X X 0\leq t\leq T<\infty f:[0,T]\times X\to X t\mapsto f(t,u(t)) f","['functional-analysis', 'measure-theory', 'lebesgue-measure']"
58,Proving that every Cauchy sequence in measure converges in measure,Proving that every Cauchy sequence in measure converges in measure,,"Let $(X,\mathcal{A},\mu)$ be a measure space and $(f_n)$ a sequence of real-valued functions on $X$ which is Cauchy in measure; that is, for any $\epsilon>0$ there exists $N\in\mathbb{N}$ such that for all $m,n\geq N$ we have $\mu(\{x\in X \ | \ |f_n(x)-f_m(x)|\geq \epsilon\})<\epsilon$ . Prove that there is a function $f$ on $X$ to which $(f_n)$ converges to $f$ in measure. (Convergence in measure: For any $\epsilon>0,\displaystyle\lim_{n \to \infty} \mu(\{x\in X \ | \ |f_n(x)-f(x)|\geq \epsilon\})=0.$ ) (This is not a homework problem.) I'm finding this very difficult, probably because the definitions are so complicated. I'm not sure how to approach it. Usually when one tries to prove 'Cauchy implies convergent'-type statements it's just a routine application of the completeness of $\mathbb{R}$ . One approach may be to establish to existence of a Cauchy subsequence for each $x$ but that's more of a guess rather than an idea inspired by understanding. It's just difficult to get a strong enough intuitive understanding for what's going on to solve it. Fixing an $x$ and constructing $f(x)$ individually is not easy as it seems to depend on all the other $f(x)$ as well (measure being a more global property). Any small hints would be appreciated. Edit: Not sure if this is common thing on StackExchange but I wanted to make a copy of this question myself in order to get a hint for the problem instead of seeing the answer (and spoiling the problem).","Let be a measure space and a sequence of real-valued functions on which is Cauchy in measure; that is, for any there exists such that for all we have . Prove that there is a function on to which converges to in measure. (Convergence in measure: For any ) (This is not a homework problem.) I'm finding this very difficult, probably because the definitions are so complicated. I'm not sure how to approach it. Usually when one tries to prove 'Cauchy implies convergent'-type statements it's just a routine application of the completeness of . One approach may be to establish to existence of a Cauchy subsequence for each but that's more of a guess rather than an idea inspired by understanding. It's just difficult to get a strong enough intuitive understanding for what's going on to solve it. Fixing an and constructing individually is not easy as it seems to depend on all the other as well (measure being a more global property). Any small hints would be appreciated. Edit: Not sure if this is common thing on StackExchange but I wanted to make a copy of this question myself in order to get a hint for the problem instead of seeing the answer (and spoiling the problem).","(X,\mathcal{A},\mu) (f_n) X \epsilon>0 N\in\mathbb{N} m,n\geq N \mu(\{x\in X \ | \ |f_n(x)-f_m(x)|\geq \epsilon\})<\epsilon f X (f_n) f \epsilon>0,\displaystyle\lim_{n \to \infty} \mu(\{x\in X \ | \ |f_n(x)-f(x)|\geq \epsilon\})=0. \mathbb{R} x x f(x) f(x)","['real-analysis', 'measure-theory', 'cauchy-sequences']"
59,Equivalence of definitions of ergodic action,Equivalence of definitions of ergodic action,,"Let $G$ be a group acting on a probability measure space $(X, \mu)$ by measure-preserving transformations. I have read the two following definitions of ergodicity of such an action: For every measurable set $A$ such that $\mu(gA \Delta A) = 0$ for all $g \in G$ , we have $\mu(A) = 0$ or $1$ . For every measurable set $A$ such that $gA = A$ for all $g \in G$ , we have $\mu(A) = 0$ or $1$ . It is clear that 1 implies 2. It is not hard to show that 2 implies 1 if the group is countable. But what about the more general case? What if, for instance, $G$ is a separable group acting continuously on a topological, or even metric space $X$ ? Would that be enough? Also, it is clear that a transitive action satisfies 2. But when does it satisfy 1 in the general case? Would the hypotheses above help?","Let be a group acting on a probability measure space by measure-preserving transformations. I have read the two following definitions of ergodicity of such an action: For every measurable set such that for all , we have or . For every measurable set such that for all , we have or . It is clear that 1 implies 2. It is not hard to show that 2 implies 1 if the group is countable. But what about the more general case? What if, for instance, is a separable group acting continuously on a topological, or even metric space ? Would that be enough? Also, it is clear that a transitive action satisfies 2. But when does it satisfy 1 in the general case? Would the hypotheses above help?","G (X, \mu) A \mu(gA \Delta A) = 0 g \in G \mu(A) = 0 1 A gA = A g \in G \mu(A) = 0 1 G X","['group-theory', 'measure-theory', 'group-actions', 'ergodic-theory']"
60,"Measure on Lie Algebra ""induced"" by Haar measure on U(n)","Measure on Lie Algebra ""induced"" by Haar measure on U(n)",,"On the unitary group $U(n)$ , the Haar measure provides a suitable notion of uniformity for many applications. The Lie Group $U(n)$ is generated by the Hermitian matrices, i.e., I can write any $A \in U(n)$ as $$A = \exp(\sum_{j,k=1}^n i a_{jk}\Omega_{jk})$$ where $a_{jk}$ are real coefficients dependent on A and $\Omega_{jk}$ are the standard basis elements of the Lie Algebra $\mathfrak{u}(n) = \{X \in \mathbb{C}^{n \times n } | X^\dagger = X\}$ . My question is this: What is the measure ""induced"" on the Lie Algebra by the Haar measure on $U(n)$ ? Put another way: What measure on $\mathbb{R}^{n \times n}$ do I have to use to sample the $a_{jk}$ if I want the corresponding unitary matrices to be distributed according to the Haar measure?","On the unitary group , the Haar measure provides a suitable notion of uniformity for many applications. The Lie Group is generated by the Hermitian matrices, i.e., I can write any as where are real coefficients dependent on A and are the standard basis elements of the Lie Algebra . My question is this: What is the measure ""induced"" on the Lie Algebra by the Haar measure on ? Put another way: What measure on do I have to use to sample the if I want the corresponding unitary matrices to be distributed according to the Haar measure?","U(n) U(n) A \in U(n) A = \exp(\sum_{j,k=1}^n i a_{jk}\Omega_{jk}) a_{jk} \Omega_{jk} \mathfrak{u}(n) = \{X \in \mathbb{C}^{n \times n } | X^\dagger = X\} U(n) \mathbb{R}^{n \times n} a_{jk}","['measure-theory', 'lie-groups', 'lie-algebras', 'haar-measure']"
61,Uncountable family of measurable functions and limits,Uncountable family of measurable functions and limits,,"Let $(f_t)_{t \in \mathbb{R}}$ be a family of measurable functions on a measurable set $E$ . Suppose that $\lim_{t \to 0} f_t(x) $ exists for all $x \in E$ . Define $f(x) = \lim_{t \to 0} f_t(x)$ . Is f a measurable function? My immediate response is to say “yes”. However, I have only seen results on taking limits $n \to \infty$ of countable sequences of measurable functions. It is not clear to me if the same results should stand here (e.g. that the limit of a sequence of measurable functions is also measurable), since I know uncountability has a bad habit of breaking things! If the result is true, how can I extend the normal results about sequences of measurable functions to this case? If not, how do I find a counter example?","Let be a family of measurable functions on a measurable set . Suppose that exists for all . Define . Is f a measurable function? My immediate response is to say “yes”. However, I have only seen results on taking limits of countable sequences of measurable functions. It is not clear to me if the same results should stand here (e.g. that the limit of a sequence of measurable functions is also measurable), since I know uncountability has a bad habit of breaking things! If the result is true, how can I extend the normal results about sequences of measurable functions to this case? If not, how do I find a counter example?",(f_t)_{t \in \mathbb{R}} E \lim_{t \to 0} f_t(x)  x \in E f(x) = \lim_{t \to 0} f_t(x) n \to \infty,"['real-analysis', 'general-topology', 'measure-theory', 'lebesgue-measure', 'measurable-functions']"
62,Holder inequality is equality for $p =1$ and $q=\infty$,Holder inequality is equality for  and,p =1 q=\infty,"Suppose $p=1$ and $q=\infty$ , and the right hand side of Holder inequality is finite. Then, Holder inequality is equality iff $|g| = ||g||_\infty$ a.e. on $\{x: f(x) \not=0\}$ . And here is the solution I found on the internet: I understand this part $\int_{A_\varepsilon} |fg| \le -\delta \varepsilon^2 + \int_{A_\varepsilon} |f |||g||_\infty$ . But, to hold the inequality, we have to show $\int_{X\sim A_\varepsilon} |fg| = \int_{X\sim A_\varepsilon} |f|||g||_\infty$ . I have $$X\setminus A_\varepsilon = \{x: |f(x)| < \varepsilon\} \cup \{x: |g(x)|> ||g||_\infty -\varepsilon\}.$$ Since we have the reverse inequality, $g(x) = ||g||_\infty$ on $x \in X\setminus A_\varepsilon$ . Is this correct? Also, the last equality does not make sense to me because $-\delta\varepsilon^2 + ||g||_\infty\int_X |f| \ge ||g||_\infty \int_X |f|$ . Lastly, suppose that this equation holds. Why is the condition $\{x: f(x) \not=0\}$ necessary? I appreciate if you give me some help.","Suppose and , and the right hand side of Holder inequality is finite. Then, Holder inequality is equality iff a.e. on . And here is the solution I found on the internet: I understand this part . But, to hold the inequality, we have to show . I have Since we have the reverse inequality, on . Is this correct? Also, the last equality does not make sense to me because . Lastly, suppose that this equation holds. Why is the condition necessary? I appreciate if you give me some help.",p=1 q=\infty |g| = ||g||_\infty \{x: f(x) \not=0\} \int_{A_\varepsilon} |fg| \le -\delta \varepsilon^2 + \int_{A_\varepsilon} |f |||g||_\infty \int_{X\sim A_\varepsilon} |fg| = \int_{X\sim A_\varepsilon} |f|||g||_\infty X\setminus A_\varepsilon = \{x: |f(x)| < \varepsilon\} \cup \{x: |g(x)|> ||g||_\infty -\varepsilon\}. g(x) = ||g||_\infty x \in X\setminus A_\varepsilon -\delta\varepsilon^2 + ||g||_\infty\int_X |f| \ge ||g||_\infty \int_X |f| \{x: f(x) \not=0\},"['measure-theory', 'holder-inequality']"
63,pacing between iid r.v. : why introduce a scaling $\frac{1}{Np_X(x)}$ in proving $\hat p(\hat s)\sim e^{\hat s}$,pacing between iid r.v. : why introduce a scaling  in proving,\frac{1}{Np_X(x)} \hat p(\hat s)\sim e^{\hat s},"Let $\{X_1,...,X_n\}$ iid r.v. We denote $p_X(x)=P_{X_i}(x)$ the PDF of $X_i$ for all $i$ . In the section 2.3 page 12 of this paper , we have Let $p_N(s\mid X_i=x)$ is the probability that given $X_j=x$ , there is a r.v. variable $X_k$ ( $k\neq j$ ) s.t. $X_{k}=x+s$ and there is no other r.v. lie between. We can prove that $$p(s\mid X_j=x)=p_X(x+s)[1+F(x)-F(x+s)]^{N-2},$$ where $F$ is the CDF of the $X_i$ 's. From this, we can conclude that $$p(s\mid any\ X=x)=\sum_{j=1}^N p_N(s\mid X_j=x)\mathbb P\{X_i=x\}=Np_N(s\mid X_i=x)p_X(x),$$ and finally $$p_N(s)=N\int_\sigma  p_N(s\mid X_j=x)p_X(x)dx,$$ where $\sigma $ is the support of the $X_i's$ . Now, we are interested is to compute the spacing distribution function when we have an infinite number of r.v. ,i.e. for $\{X_i\}_{i=1}^\infty$ iid. What they do is that they introduce the substitution $s=\frac{\hat s}{Np_X(x)}$ , and says that this distribution is given by $$p(s)=\lim_{n\to \infty}\hat p_N(\hat s)=\lim_{N\to \infty}p\left(s=\frac{\hat s}{Np_X(x)}\right)\frac{ds}{d\hat s}=...=e^{\hat s}.$$ Question : I don't understand the argument here ! 1) First, why the scaling $\frac{\hat s}{Np_X(x)}$ ? 2) What does mean $\lim_{N\to \infty}p\left(s=\frac{\hat s}{Np_X(x)}\right)\frac{ds}{d\hat s}$ ? I guess it's $$\lim_{N\to \infty}p_N\left(\frac{\hat s}{Np_N(x)}\right)\frac{d}{d\hat s}\left(\frac{\hat s}{Np_X(x)}\right)=\lim_{N\to \infty}p_N\left(\frac{\hat s}{Np_N(x)}\right)\frac{1}{Np_X(x)},$$ but I've never see such a thing : why introducing the term $\frac{d s}{d\hat s}$ ?","Let iid r.v. We denote the PDF of for all . In the section 2.3 page 12 of this paper , we have Let is the probability that given , there is a r.v. variable ( ) s.t. and there is no other r.v. lie between. We can prove that where is the CDF of the 's. From this, we can conclude that and finally where is the support of the . Now, we are interested is to compute the spacing distribution function when we have an infinite number of r.v. ,i.e. for iid. What they do is that they introduce the substitution , and says that this distribution is given by Question : I don't understand the argument here ! 1) First, why the scaling ? 2) What does mean ? I guess it's but I've never see such a thing : why introducing the term ?","\{X_1,...,X_n\} p_X(x)=P_{X_i}(x) X_i i p_N(s\mid X_i=x) X_j=x X_k k\neq j X_{k}=x+s p(s\mid X_j=x)=p_X(x+s)[1+F(x)-F(x+s)]^{N-2}, F X_i p(s\mid any\ X=x)=\sum_{j=1}^N p_N(s\mid X_j=x)\mathbb P\{X_i=x\}=Np_N(s\mid X_i=x)p_X(x), p_N(s)=N\int_\sigma  p_N(s\mid X_j=x)p_X(x)dx, \sigma  X_i's \{X_i\}_{i=1}^\infty s=\frac{\hat s}{Np_X(x)} p(s)=\lim_{n\to \infty}\hat p_N(\hat s)=\lim_{N\to \infty}p\left(s=\frac{\hat s}{Np_X(x)}\right)\frac{ds}{d\hat s}=...=e^{\hat s}. \frac{\hat s}{Np_X(x)} \lim_{N\to \infty}p\left(s=\frac{\hat s}{Np_X(x)}\right)\frac{ds}{d\hat s} \lim_{N\to \infty}p_N\left(\frac{\hat s}{Np_N(x)}\right)\frac{d}{d\hat s}\left(\frac{\hat s}{Np_X(x)}\right)=\lim_{N\to \infty}p_N\left(\frac{\hat s}{Np_N(x)}\right)\frac{1}{Np_X(x)}, \frac{d s}{d\hat s}","['probability', 'measure-theory', 'random-matrices']"
64,Confusion between dual of continuous functions and borel functions,Confusion between dual of continuous functions and borel functions,,"Let $X$ be a compact Hausdorff space and let $$C(X) = \{\text{ Continuous complex functions on } X\}$$ $$B(X) = \{ \text{Bounded complex Borel-measurable functions on X}\}$$ both equipped with the sup-norm, and therefore Banach spaces. We have that $C(X)^*=M(X)$ is the set of complex Radon measures, while $B(X)^* = \operatorname{ba}(X)$ are the bounded, finitely additive measures . Each element $T$ of $\operatorname{ba}(X)$ is continuous when restricted to $C(X)\subset B(X)$ . Thus, by the Riesz representation theorem, there is a countably additive Radon measure on $C(X)$ corresponding to $T$ . However, all the elements of $M(X)$ are countably additive, while those in $B(X)$ need not be! I am wondering where I am going wrong as I get this contradictory conclusion. Thank you.","Let be a compact Hausdorff space and let both equipped with the sup-norm, and therefore Banach spaces. We have that is the set of complex Radon measures, while are the bounded, finitely additive measures . Each element of is continuous when restricted to . Thus, by the Riesz representation theorem, there is a countably additive Radon measure on corresponding to . However, all the elements of are countably additive, while those in need not be! I am wondering where I am going wrong as I get this contradictory conclusion. Thank you.",X C(X) = \{\text{ Continuous complex functions on } X\} B(X) = \{ \text{Bounded complex Borel-measurable functions on X}\} C(X)^*=M(X) B(X)^* = \operatorname{ba}(X) T \operatorname{ba}(X) C(X)\subset B(X) C(X) T M(X) B(X),"['general-topology', 'functional-analysis', 'measure-theory', 'banach-spaces']"
65,Definition of a semiring of sets,Definition of a semiring of sets,,"I'm reading Halmos's Measure Theory and his definition of semiring seems to disagree with the ones that I find on the internet. Halmos's definition (p. 22): A semiring is a non empty class $\mathbf{P}$ of sets such that if $E\in\mathbf{P}$ and $F\in\mathbf{P}$ . then $E\cap F\in\mathbf{P}$ . and if $E\in\mathbf{P}$ and $F\in\mathbf{P}$ and $E\subset F$ , then there is a finite class $\{C_0, C_1, \cdots, C_n\}$ of sets in $\mathbf{P}$ such that $E=C_0\subset C_1\subset\cdots\subset C_n=F$ and $D_i=C_i-C_{i-1}\in\mathbf{P}$ for $i=1,\cdots,n$ . Wikipedia's definition (for example): A semiring (of sets) is a non-empty collection $S$ of sets such that $\emptyset \in S$ If $E\in S$ and $F\in S$ then $E\cap F\in S$ . If $E\in S$ and $F\in S$ then there exists a finite number of mutually disjoint sets $C_{i}\in S$ for $i=1,\ldots ,n$ such that $E\setminus F=\bigcup _{i=1}^{n}C_{i}$ . These definitions are not equivalent!  For example, the collection $\{\emptyset,\{a\},\{b\}, \{c\}, \{a,b,c\}\}$ is a semiring under the second definition, but not the first. Questions: History question: why does Halmos use a different definition than we do today?  Was the definition weakened at some point in order to be more general? Math question: what are the advantages/disadvantages of these two definitions from the standpoint of measure theory?","I'm reading Halmos's Measure Theory and his definition of semiring seems to disagree with the ones that I find on the internet. Halmos's definition (p. 22): A semiring is a non empty class of sets such that if and . then . and if and and , then there is a finite class of sets in such that and for . Wikipedia's definition (for example): A semiring (of sets) is a non-empty collection of sets such that If and then . If and then there exists a finite number of mutually disjoint sets for such that . These definitions are not equivalent!  For example, the collection is a semiring under the second definition, but not the first. Questions: History question: why does Halmos use a different definition than we do today?  Was the definition weakened at some point in order to be more general? Math question: what are the advantages/disadvantages of these two definitions from the standpoint of measure theory?","\mathbf{P} E\in\mathbf{P} F\in\mathbf{P} E\cap F\in\mathbf{P} E\in\mathbf{P} F\in\mathbf{P} E\subset F \{C_0, C_1, \cdots, C_n\} \mathbf{P} E=C_0\subset C_1\subset\cdots\subset C_n=F D_i=C_i-C_{i-1}\in\mathbf{P} i=1,\cdots,n S \emptyset \in S E\in S F\in S E\cap F\in S E\in S F\in S C_{i}\in S i=1,\ldots ,n E\setminus F=\bigcup _{i=1}^{n}C_{i} \{\emptyset,\{a\},\{b\}, \{c\}, \{a,b,c\}\}",['measure-theory']
66,Finding possible p's for signed measure,Finding possible p's for signed measure,,"Im new here at StackExchange and hope some of you can help me with a problem I'm dealing with. We are considering a signed measure $\nu$ on $(\mathbb{N},2^{\mathbb{N}})$ , which is given by $\nu(\{k\}):= k^p (-1)^k$ with $k \in \mathbb{N}$ . Now I have to find out, which values of $p \in \mathbb{R}$ are possible? I know, that signed measures satisfy $\nu( \emptyset ) = 0$ . Due to there is not given, what happens with empty sets, I would associate this with inserting zero for k (assuming, that $0 \notin \mathbb{N}$ ). So this doesn't give me additional information to determine possible $p$ 's Furthermore for countable $I$ and a set of pairwise disjoint $A_i$ 's holds $\nu(\bigcup_{i\in I}A_i) = \sum_{i \in I} \nu(A_i)$ . I guess this is one information, that might be used to determine possible $p$ 's. But my problem is, that I don't really know, how to use this, due to there is no real definition, what happens, if I put something different than singletons in $\nu$ . Is there anything, that I have overseen, or is there something missing in the indication? Or is there a reason, why we can claim, that $\nu(\{k,m\}):= (k+m)^p (-1)^{k+m} = \nu(\{k+m\})$ ? Thank you very much for your help!","Im new here at StackExchange and hope some of you can help me with a problem I'm dealing with. We are considering a signed measure on , which is given by with . Now I have to find out, which values of are possible? I know, that signed measures satisfy . Due to there is not given, what happens with empty sets, I would associate this with inserting zero for k (assuming, that ). So this doesn't give me additional information to determine possible 's Furthermore for countable and a set of pairwise disjoint 's holds . I guess this is one information, that might be used to determine possible 's. But my problem is, that I don't really know, how to use this, due to there is no real definition, what happens, if I put something different than singletons in . Is there anything, that I have overseen, or is there something missing in the indication? Or is there a reason, why we can claim, that ? Thank you very much for your help!","\nu (\mathbb{N},2^{\mathbb{N}}) \nu(\{k\}):= k^p (-1)^k k \in \mathbb{N} p \in \mathbb{R} \nu( \emptyset ) = 0 0 \notin \mathbb{N} p I A_i \nu(\bigcup_{i\in I}A_i) = \sum_{i \in I} \nu(A_i) p \nu \nu(\{k,m\}):= (k+m)^p (-1)^{k+m} = \nu(\{k+m\})",['measure-theory']
67,Convergence in exponential moments implies convergence in distribution,Convergence in exponential moments implies convergence in distribution,,"We say a sequence of random variables ${x_n}$ converge in exponential moments to $X$ if $\mathbb E(e^{zX_n})\to \mathbb E(e^{zX})$ uniformly in some neighborhood of $0\in \mathbb C$ . I want to show the convergence in exponential moments implies the convergence in distribution. To this end, it suffices to show that for any $t\in \mathbb R$ , we have $\mathbb E(e^{itX_n})\to \mathbb E(e^{itX_0})$ . The difficult part is that $U$ may not necessarily contain the whole imaginary axis (we only have the convergence on a neighborhood of $0$ ). Thanks for help!","We say a sequence of random variables converge in exponential moments to if uniformly in some neighborhood of . I want to show the convergence in exponential moments implies the convergence in distribution. To this end, it suffices to show that for any , we have . The difficult part is that may not necessarily contain the whole imaginary axis (we only have the convergence on a neighborhood of ). Thanks for help!",{x_n} X \mathbb E(e^{zX_n})\to \mathbb E(e^{zX}) 0\in \mathbb C t\in \mathbb R \mathbb E(e^{itX_n})\to \mathbb E(e^{itX_0}) U 0,"['probability', 'measure-theory']"
68,Uniqueness for classical solution of PDE,Uniqueness for classical solution of PDE,,"I have the following conservation law in my hand: $\partial_{t} u + \partial_{x}f(u) = -u$ , with the associated initial   data $u(x,0) = u_{0}(x)$ - where $u_{0} \in C^{1}$ . I have to show classical solution ( $u \in C^{1}$ ) of the equation is   unique . My thoughts For me the obvious approach was to show the $L^{1}$ -contraction, i.e. assuming $\exists$ two $C^{1}$ -functions $u_{1}$ and $u_{2}$ which solve the above conservation law with initial data $u_{0,1}(x)$ and $u_{0,2}(x)$ to show $||u_{1}(\cdot,t) - u_{2}(\cdot,t)||_{L^{1}(\mathbb{R})} \leq ||u_{0,1}(\cdot) - u_{0,2}(\cdot)||_{L^{1}(\mathbb{R})}$ . With this aim in mind I subtracted two conservation laws given by $u_{1}$ and $u_{2}$ and multiply the resulting equation by a smooth function $\eta'(w)$ where $w = u_{1} - u_{2}$ and $\eta$ is a smooth approximation of modulus. Can someone show me how to estimate the terms $\eta'(w) \partial_{x}(f(u_{1}) - f(u_{2}))$ and $\eta'(w)w$ ?? Thanks in advance!! :)","I have the following conservation law in my hand: , with the associated initial   data - where . I have to show classical solution ( ) of the equation is   unique . My thoughts For me the obvious approach was to show the -contraction, i.e. assuming two -functions and which solve the above conservation law with initial data and to show . With this aim in mind I subtracted two conservation laws given by and and multiply the resulting equation by a smooth function where and is a smooth approximation of modulus. Can someone show me how to estimate the terms and ?? Thanks in advance!! :)","\partial_{t} u + \partial_{x}f(u) = -u u(x,0) = u_{0}(x) u_{0} \in C^{1} u \in C^{1} L^{1} \exists C^{1} u_{1} u_{2} u_{0,1}(x) u_{0,2}(x) ||u_{1}(\cdot,t) - u_{2}(\cdot,t)||_{L^{1}(\mathbb{R})} \leq ||u_{0,1}(\cdot) - u_{0,2}(\cdot)||_{L^{1}(\mathbb{R})} u_{1} u_{2} \eta'(w) w = u_{1} - u_{2} \eta \eta'(w) \partial_{x}(f(u_{1}) - f(u_{2})) \eta'(w)w","['measure-theory', 'partial-differential-equations', 'regularity-theory-of-pdes', 'hyperbolic-equations']"
69,intuitively obvious integration identity,intuitively obvious integration identity,,"Let $\mu$ denote the Lebesgue measure on $[-\infty,\infty]$ . For each measurable subset $E\subset(0,\infty)$ , define the nondecreasing function $m_E:(0,\mu(E))\to(0,\infty)$ by the rule $$m_E(t)=\inf\left\{s\in(0,\infty):\mu\left(E\cap(0,s)\right)=t\right\}.$$ Question 1. I would like to show the following:  If $f:(0,\infty)\to[0,\infty]$ is a (nonnegative) measurable function, then $$\int_Ef(t)\;dt=\int_0^{\mu(E)}(f\circ m_E)(t)\;dt.$$ Discussion. My intuition tells me it should work, but I'm too rusty on my measure theory to prove it. The analogy here is to the $\ell_1$ norm of subsequences.  For example, if $B\subset\mathbb{N}$ , then let $$i_B(n)=\left\{i\in B:\#\left(B\cap[0,i]\right)\leq n\right\}.$$ It follows that, for any sequence of nonnegative scalars $(a_n)_{n=1}^\infty$ , we have $$\sum_{n\in B}a_n=\sum_{n=1}^{\#B}a_{i_B(n)}.$$ In other words, we have ""pushed"" $(a_n)_{n\in B}$ down to $(a_{i_B(n)})_{n=1}^{\#B}$ so that their $\#$ -integrals are the same. I would like to construct an analogous transformation to work with nonnegative functions on $(0,\infty)$ . Thanks!","Let denote the Lebesgue measure on . For each measurable subset , define the nondecreasing function by the rule Question 1. I would like to show the following:  If is a (nonnegative) measurable function, then Discussion. My intuition tells me it should work, but I'm too rusty on my measure theory to prove it. The analogy here is to the norm of subsequences.  For example, if , then let It follows that, for any sequence of nonnegative scalars , we have In other words, we have ""pushed"" down to so that their -integrals are the same. I would like to construct an analogous transformation to work with nonnegative functions on . Thanks!","\mu [-\infty,\infty] E\subset(0,\infty) m_E:(0,\mu(E))\to(0,\infty) m_E(t)=\inf\left\{s\in(0,\infty):\mu\left(E\cap(0,s)\right)=t\right\}. f:(0,\infty)\to[0,\infty] \int_Ef(t)\;dt=\int_0^{\mu(E)}(f\circ m_E)(t)\;dt. \ell_1 B\subset\mathbb{N} i_B(n)=\left\{i\in B:\#\left(B\cap[0,i]\right)\leq n\right\}. (a_n)_{n=1}^\infty \sum_{n\in B}a_n=\sum_{n=1}^{\#B}a_{i_B(n)}. (a_n)_{n\in B} (a_{i_B(n)})_{n=1}^{\#B} \# (0,\infty)","['real-analysis', 'integration', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
70,When is a positive power of $f(x)$ integrable?,When is a positive power of  integrable?,f(x),"I want to ask the complement to this question ( Lebesgue-integrability of roots and powers of a function ). Suppose $f$ is a Lebesgue measurable function and in particular that $f(x) \geq 0 \: \forall x \in \mathcal{X}$ and $\int_{\mathcal{X}} f(t) dt = 1$ , i.e., $f$ is a probability density function (pdf). I want to know what are the conditions I need on $f$ such that $\int_{\mathcal{X}} f(t)^p dt < \infty$ for $ 0 < p < \infty$ . Edit Following feedback from @Dog_69 (!) and @Clement C. and some digging on my own, here are a few more observations I hope will be useful. Let $\{g_n\}$ be ""a sequence of nonnegative simple functions"". According to this ( http://mathworld.wolfram.com/LebesgueIntegrable.html ) we would need the following two conditions on $f(x)^p$ : $\sum_{n=1}^\infty\int_{\mathcal{X}} g_n(t) dt < \infty$ , and; $f(x)^p = \sum_{n=1}^\infty g_n(x)$ a.e. Now, if one could frame the counter-examples to my foolish claim (edited out) that the function is integrable for $ 0 <p \leq 1$ by showing that they do not conform to these conditions, it would be a start, I reckon. More edits According to this link Product of measurable and integrable functions , if $f$ is integrable and $g$ is bounded and measurable, then $fg$ will be integrable. Since here $f(x)$ is assumed  to be integrable, a sufficient condition is that $g(x) = f(x)^{p-1}$ is bounded and measurable. I had erroneously claimed that for $ 0 < p < 1$ any pdf would integrable. Let us work on the counter-examples kindly provided by @Dog_69 and @Clement C. to find out what went south: $f_0(x) = \frac{2}{x^2}$ with $\mathcal{X} = [2, +\infty)$ . Take $p = 1/2$ and thus $f_0(x)^{1/2} = \frac{2}{x^2} \cdot \frac{x}{\sqrt{2}}$ . Since $g_0(x) = \frac{x}{\sqrt{2}}$ is not bounded on $\mathcal{X}$ we have that it doesn't conform to the condition above. $f_1(x) = \frac{1}{\pi(1+x^2)}$ with $\mathcal{X} = (-\infty, +\infty)$ . For simplicity, again take $p = 1/2$ and hence we have $f_1(x)^{1/2} = \frac{1}{\pi(1+x^2)} \cdot \sqrt{\pi (1+x^2)}$ . Again, $g_1(x) = \sqrt{\pi (1+x^2)}$ is not bounded on $\mathcal{X}$ . If one could show that the result in the link is an iff statement, we'd be done, because we'd have a necessary and sufficient condition on $f$ . But unfortunately this is not the case. Consider $\int_{0}^{+\infty} t^2 h(t) dt$ where $h$ is, say, a Gamma pdf. Clearly this expectation exists, but $g(t) = t^2$ is measurable but unbounded on $\mathcal{X}$ .","I want to ask the complement to this question ( Lebesgue-integrability of roots and powers of a function ). Suppose is a Lebesgue measurable function and in particular that and , i.e., is a probability density function (pdf). I want to know what are the conditions I need on such that for . Edit Following feedback from @Dog_69 (!) and @Clement C. and some digging on my own, here are a few more observations I hope will be useful. Let be ""a sequence of nonnegative simple functions"". According to this ( http://mathworld.wolfram.com/LebesgueIntegrable.html ) we would need the following two conditions on : , and; a.e. Now, if one could frame the counter-examples to my foolish claim (edited out) that the function is integrable for by showing that they do not conform to these conditions, it would be a start, I reckon. More edits According to this link Product of measurable and integrable functions , if is integrable and is bounded and measurable, then will be integrable. Since here is assumed  to be integrable, a sufficient condition is that is bounded and measurable. I had erroneously claimed that for any pdf would integrable. Let us work on the counter-examples kindly provided by @Dog_69 and @Clement C. to find out what went south: with . Take and thus . Since is not bounded on we have that it doesn't conform to the condition above. with . For simplicity, again take and hence we have . Again, is not bounded on . If one could show that the result in the link is an iff statement, we'd be done, because we'd have a necessary and sufficient condition on . But unfortunately this is not the case. Consider where is, say, a Gamma pdf. Clearly this expectation exists, but is measurable but unbounded on .","f f(x) \geq 0 \: \forall x \in \mathcal{X} \int_{\mathcal{X}} f(t) dt = 1 f f \int_{\mathcal{X}} f(t)^p dt < \infty  0 < p < \infty \{g_n\} f(x)^p \sum_{n=1}^\infty\int_{\mathcal{X}} g_n(t) dt < \infty f(x)^p = \sum_{n=1}^\infty g_n(x)  0 <p \leq 1 f g fg f(x) g(x) = f(x)^{p-1}  0 < p < 1 f_0(x) = \frac{2}{x^2} \mathcal{X} = [2, +\infty) p = 1/2 f_0(x)^{1/2} = \frac{2}{x^2} \cdot \frac{x}{\sqrt{2}} g_0(x) = \frac{x}{\sqrt{2}} \mathcal{X} f_1(x) = \frac{1}{\pi(1+x^2)} \mathcal{X} = (-\infty, +\infty) p = 1/2 f_1(x)^{1/2} = \frac{1}{\pi(1+x^2)} \cdot \sqrt{\pi (1+x^2)} g_1(x) = \sqrt{\pi (1+x^2)} \mathcal{X} f \int_{0}^{+\infty} t^2 h(t) dt h g(t) = t^2 \mathcal{X}","['calculus', 'probability', 'measure-theory', 'lebesgue-integral']"
71,Lebesgue Monotone Conv. Theorem's Proof by W. Rudin,Lebesgue Monotone Conv. Theorem's Proof by W. Rudin,,"The proof is the following The proposition 1.25 and Theorem 1.19(d) that refers to are these Why do we need that constant $0 <c <1$ in the proof of Leb. Mon. Conv. Thm?   For me, the proof works fine if we take just any simple function $s $ and define the sets $E_n $ with $s $ instead of $cs$. Thank you! :)","The proof is the following The proposition 1.25 and Theorem 1.19(d) that refers to are these Why do we need that constant $0 <c <1$ in the proof of Leb. Mon. Conv. Thm?   For me, the proof works fine if we take just any simple function $s $ and define the sets $E_n $ with $s $ instead of $cs$. Thank you! :)",,['measure-theory']
72,Doubt about the RADEMACHER'S THEOREM demonstration.,Doubt about the RADEMACHER'S THEOREM demonstration.,,"I was recently reading an article called An Elementary Proof of Rademacher's Theorem. In the text below $U$ is a ball and $ f: U \to \mathbb{R}$ is a lipschitz function. Let $S$ the set of $x\in U$ for which $\partial_v f(x)$ does not exist. My question. How can we prove that the continuity of $ f $ implies that the set $ S $ is measurable? I'm trying to look at $ S $ as the following set. $$ S= \left\{  x\in U  \left| \begin{matrix}  \forall T:\mathbb{R}^n\to \mathbb{R} \mbox{ linear }\exists \epsilon>0  \\ \mbox{ such that } \forall \delta>0  \\ |t|<\delta \mbox{ and } \frac{|f(x+tv)-f(x)-Tv|}{|v|}>\epsilon \end{matrix} \right. \right\} $$ Then, prove that such a set is measurable. But something tells me that $ S $ can not be described in this way. So the question seems to be this. How to describe $ S $ properly and then prove that it is a measurable set? Update. Examining the text in the image better, I realized that I can express the set $ S $ in the form below. I believe it's the correct expression for $ S $. Recall that $|v|=1$. $S=\{x\in U: \partial_{v}f(x) \mbox{ does not exist }\}$ $S=\left\{x\in U: \lim_{t\to 0} \frac{f(x+tv)-f(x)}{t}\mbox{ does not exist }\right\}$ $S=\left\{x\in U\left| \begin{matrix} \mbox{ logical negation of} \\ (\exists \partial_vf(x)\in\mathbb{R}) (\forall \epsilon>0)(\exists \delta >0) \\ 0<|t|<\delta\implies\left|\frac{f(x+tv)-f(x)}{t}-\partial_vf(x)\right|<\epsilon \end{matrix}\right.\right\}$ $S=\left\{x\in U\left| \begin{matrix} (\forall \partial_vf(x)\in\mathbb{R}) (\exists \epsilon>0)(\forall \delta >0) \\ 0<|t|<\delta\mbox{ and } \left|\frac{f(x+tv)-f(x)}{t}-\partial_vf(x)\right|\geq \epsilon \end{matrix}\right.\right\}$ $S=\displaystyle\bigcap_{L\in\mathbb{R}} \displaystyle\bigcap_{\delta>0} \big( S_{L,\delta}^+\cup S_{L,\delta}^+)  $ for  $ S_{L,\delta}^+=\left\{x\in U\left|  \frac{f(x+tv)-f(x)}{t}\leq L+ \epsilon, 0<|t|<\delta \right.\right\} $  and  $ S_{L,\delta}^-=\left\{x\in U\left|  \frac{f(x+tv)-f(x)}{t}\geq L - \epsilon, 0<|t|<\delta \right.\right\} $","I was recently reading an article called An Elementary Proof of Rademacher's Theorem. In the text below $U$ is a ball and $ f: U \to \mathbb{R}$ is a lipschitz function. Let $S$ the set of $x\in U$ for which $\partial_v f(x)$ does not exist. My question. How can we prove that the continuity of $ f $ implies that the set $ S $ is measurable? I'm trying to look at $ S $ as the following set. $$ S= \left\{  x\in U  \left| \begin{matrix}  \forall T:\mathbb{R}^n\to \mathbb{R} \mbox{ linear }\exists \epsilon>0  \\ \mbox{ such that } \forall \delta>0  \\ |t|<\delta \mbox{ and } \frac{|f(x+tv)-f(x)-Tv|}{|v|}>\epsilon \end{matrix} \right. \right\} $$ Then, prove that such a set is measurable. But something tells me that $ S $ can not be described in this way. So the question seems to be this. How to describe $ S $ properly and then prove that it is a measurable set? Update. Examining the text in the image better, I realized that I can express the set $ S $ in the form below. I believe it's the correct expression for $ S $. Recall that $|v|=1$. $S=\{x\in U: \partial_{v}f(x) \mbox{ does not exist }\}$ $S=\left\{x\in U: \lim_{t\to 0} \frac{f(x+tv)-f(x)}{t}\mbox{ does not exist }\right\}$ $S=\left\{x\in U\left| \begin{matrix} \mbox{ logical negation of} \\ (\exists \partial_vf(x)\in\mathbb{R}) (\forall \epsilon>0)(\exists \delta >0) \\ 0<|t|<\delta\implies\left|\frac{f(x+tv)-f(x)}{t}-\partial_vf(x)\right|<\epsilon \end{matrix}\right.\right\}$ $S=\left\{x\in U\left| \begin{matrix} (\forall \partial_vf(x)\in\mathbb{R}) (\exists \epsilon>0)(\forall \delta >0) \\ 0<|t|<\delta\mbox{ and } \left|\frac{f(x+tv)-f(x)}{t}-\partial_vf(x)\right|\geq \epsilon \end{matrix}\right.\right\}$ $S=\displaystyle\bigcap_{L\in\mathbb{R}} \displaystyle\bigcap_{\delta>0} \big( S_{L,\delta}^+\cup S_{L,\delta}^+)  $ for  $ S_{L,\delta}^+=\left\{x\in U\left|  \frac{f(x+tv)-f(x)}{t}\leq L+ \epsilon, 0<|t|<\delta \right.\right\} $  and  $ S_{L,\delta}^-=\left\{x\in U\left|  \frac{f(x+tv)-f(x)}{t}\geq L - \epsilon, 0<|t|<\delta \right.\right\} $",,"['real-analysis', 'measure-theory', 'lebesgue-measure', 'partial-derivative']"
73,What is the Stone space of the free sigma-algebra on countably many generators,What is the Stone space of the free sigma-algebra on countably many generators,,The Stone space of the free Boolean algebra on countably many generators is the Cantor space $2^\omega$. What is the Stone space of the free (Boolean) $\sigma$-algebra on countably many generators?,The Stone space of the free Boolean algebra on countably many generators is the Cantor space $2^\omega$. What is the Stone space of the free (Boolean) $\sigma$-algebra on countably many generators?,,"['measure-theory', 'order-theory', 'boolean-algebra', 'lattice-orders', 'compactification']"
74,Why $|y|=|x||T^{-1}\rho(x)|<\varepsilon_k\delta_k$ where $2\delta_k \sup_{0\leq |x|\leq \varepsilon_k}|T^{-1}\rho(x)|$,Why  where,|y|=|x||T^{-1}\rho(x)|<\varepsilon_k\delta_k 2\delta_k \sup_{0\leq |x|\leq \varepsilon_k}|T^{-1}\rho(x)|,"Let $\varphi:U\to \mathbb R^n$ a $\mathcal C^1$ application where $U\subset \mathbb R^n$ open. Let $(\varepsilon_k)\subset \mathbb R^*_+$ a sequence of positif number s.t. $\varepsilon_k\to 0$ and denote  $$C_k:=\{x\in\mathbb R^n\mid \|x-a_k\|_{\infty }\leq \frac{\varepsilon_k}{2}\},$$where $\displaystyle\|x\|_\infty :=\max_{i=1,...,n}|x_i|$ Suppose $0\in C_k$ for all $k\geq 1$ and that $\varphi(0)=0$. Let $T:=\mathcal J_{\varphi}(0)$ the Jacobian matrix of $\varphi$ at $x=0$. I'm trying to understand the proof of $$\liminf_{n\to \infty }\frac{m(\varphi(C_k))}{m(C_k)}\leq |\det T|,$$ where $m$ is the Lebesgue measure of $\mathbb R^n$. So we suppose $\det T\neq 0$. Then $$\varphi(x)=Tx+\|x\|_\infty \rho(x),$$ where $\|\rho(x)\|_\infty \to 0$ when $\|x\|_\infty \to 0$. Therefore $$T^{-1}\varphi(x)=x+\|x\|_\infty T^{-1}\rho(x).$$ Observe that $\|T^{-1}\rho(x)\|_\infty \to 0$ when $\|x\|_\infty \to 0$. Recall that $0\in C_k$, i.e. $\|a_k\|_\infty \leq \frac{\varepsilon_k}{2}.$ Therefore, if $x\in C_k$, then $$\|x\|_\infty \leq \|x-a_k\|_\infty +\|a_k\|_\infty \leq \frac{\varepsilon_k}{2}+\frac{\varepsilon_k}{2} =\varepsilon_k.$$ Therefore, if $x\in C_k$, then $$T^{-1}\varphi(x)=x+y,$$ where $$\|y\|_\infty =\|x\|_\infty \|T^{-1}\rho(x)\|_\infty <\varepsilon_k\delta_k,$$ where $$2\delta_k=\sup_{0\leq \|x\|_{\infty }\leq \varepsilon_k}\|T^{-1}\rho(x)\|_\infty .$$ This is what I don't understand : Question : For me $$\|y\|_{\infty }=\underbrace{\|x\|_\infty}_{\leq \varepsilon_k} \underbrace{\|T^{-1}\rho(x)\|_\infty}_{\leq 2\delta_k}\leq 2\varepsilon_k\delta_k,$$ So how do they get $\|y\|_\infty <\varepsilon_k\delta_k$ ? (i.e. the strict inequality and the upperbound $\varepsilon_k\delta_k$.)","Let $\varphi:U\to \mathbb R^n$ a $\mathcal C^1$ application where $U\subset \mathbb R^n$ open. Let $(\varepsilon_k)\subset \mathbb R^*_+$ a sequence of positif number s.t. $\varepsilon_k\to 0$ and denote  $$C_k:=\{x\in\mathbb R^n\mid \|x-a_k\|_{\infty }\leq \frac{\varepsilon_k}{2}\},$$where $\displaystyle\|x\|_\infty :=\max_{i=1,...,n}|x_i|$ Suppose $0\in C_k$ for all $k\geq 1$ and that $\varphi(0)=0$. Let $T:=\mathcal J_{\varphi}(0)$ the Jacobian matrix of $\varphi$ at $x=0$. I'm trying to understand the proof of $$\liminf_{n\to \infty }\frac{m(\varphi(C_k))}{m(C_k)}\leq |\det T|,$$ where $m$ is the Lebesgue measure of $\mathbb R^n$. So we suppose $\det T\neq 0$. Then $$\varphi(x)=Tx+\|x\|_\infty \rho(x),$$ where $\|\rho(x)\|_\infty \to 0$ when $\|x\|_\infty \to 0$. Therefore $$T^{-1}\varphi(x)=x+\|x\|_\infty T^{-1}\rho(x).$$ Observe that $\|T^{-1}\rho(x)\|_\infty \to 0$ when $\|x\|_\infty \to 0$. Recall that $0\in C_k$, i.e. $\|a_k\|_\infty \leq \frac{\varepsilon_k}{2}.$ Therefore, if $x\in C_k$, then $$\|x\|_\infty \leq \|x-a_k\|_\infty +\|a_k\|_\infty \leq \frac{\varepsilon_k}{2}+\frac{\varepsilon_k}{2} =\varepsilon_k.$$ Therefore, if $x\in C_k$, then $$T^{-1}\varphi(x)=x+y,$$ where $$\|y\|_\infty =\|x\|_\infty \|T^{-1}\rho(x)\|_\infty <\varepsilon_k\delta_k,$$ where $$2\delta_k=\sup_{0\leq \|x\|_{\infty }\leq \varepsilon_k}\|T^{-1}\rho(x)\|_\infty .$$ This is what I don't understand : Question : For me $$\|y\|_{\infty }=\underbrace{\|x\|_\infty}_{\leq \varepsilon_k} \underbrace{\|T^{-1}\rho(x)\|_\infty}_{\leq 2\delta_k}\leq 2\varepsilon_k\delta_k,$$ So how do they get $\|y\|_\infty <\varepsilon_k\delta_k$ ? (i.e. the strict inequality and the upperbound $\varepsilon_k\delta_k$.)",,"['real-analysis', 'measure-theory']"
75,Where does Kolmogorov stand among the pantheon of mathematicians? [closed],Where does Kolmogorov stand among the pantheon of mathematicians? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question Kind of a soft question. More out of historical curiosity than really seeking an affirmative answer. Reading up a little bit, over time, I am increasingly tempted to believe that, the Soviet mathematician Andrey Kolmogorov is not celebrated as much as an equivalent European or American genius of similar calibre. His contribution to modern science, including probability theory and computational complexity are not often talked about as much in the mainstream. Is this a mere coincidence or just that his work missed the visibility aspect, because of the geo political situation of the 20th century? Isn't  Kolmogorov, one of the top 3 applied mathematician of 20th century?","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question Kind of a soft question. More out of historical curiosity than really seeking an affirmative answer. Reading up a little bit, over time, I am increasingly tempted to believe that, the Soviet mathematician Andrey Kolmogorov is not celebrated as much as an equivalent European or American genius of similar calibre. His contribution to modern science, including probability theory and computational complexity are not often talked about as much in the mainstream. Is this a mere coincidence or just that his work missed the visibility aspect, because of the geo political situation of the 20th century? Isn't  Kolmogorov, one of the top 3 applied mathematician of 20th century?",,"['probability', 'measure-theory', 'soft-question', 'math-history']"
76,Why is outer measure called outer?,Why is outer measure called outer?,,"Why is outer measure called outer? http://mathworld.wolfram.com/OuterMeasure.html Is it because the $\inf$ in $$\mu^* (E)=\inf \sum_{i=1}^{\infty} \mu(E_k)$$ Takes the smallest bound for all the measures? So in that sense it can be thought to give the ""(outer) bound"" for the measures?","Why is outer measure called outer? http://mathworld.wolfram.com/OuterMeasure.html Is it because the $\inf$ in $$\mu^* (E)=\inf \sum_{i=1}^{\infty} \mu(E_k)$$ Takes the smallest bound for all the measures? So in that sense it can be thought to give the ""(outer) bound"" for the measures?",,['measure-theory']
77,Is this $\sigma$-algebra generated by the canonical projections?,Is this -algebra generated by the canonical projections?,\sigma,"I came across the following question to which I could not figure out a straightforward answer: Let $H$ be a separable, (in general infinite-dimensional) real Hilbert space and $V$ a separable Banach space such that $V \subseteq H$ continuously and densely. $\mathbb{B}$ is defined as the following space of paths: $$\mathbb{B} := \{y \in C(\mathbb{R}_+,H)|\int_{0}^{T}||y(s)||_V\text{d}s < \infty \,\,\forall \,\,T >0\}.$$ One defines a metric $\rho$ on $\mathbb{B}$ through $$\rho(\omega_1,\omega_2) := \sum_{k=1}^{\infty}2^{-k}\bigg[\bigg(\int_{0}^{k}||\omega_2(s)-\omega_1(s)||_V \text{d}s + \underset{t \in [0,k]}{\text{sup}}||\omega_2(t)-\omega_1(t)||_{H}\bigg)\wedge 1\bigg].$$ Finally let $\pi_t:\mathbb{B} \to H$ denote the canonical projection at time $t \geq 0$, i.e. $\pi_t(y) := y_t$. Now I want to consider the Borel $\sigma$-algebra of the topology on $\mathbb{B}$, which is induced through $\rho$, denoted by $\mathcal{B}(\mathbb{B})$ as usual. **My question: Is it true - and if yes: how does one show this - that ** $$\mathcal{B}(\mathbb{B}) = \sigma(\pi_t|t \geq 0)?$$ Clearly each $\pi_t$ is continuous and hence ""$\supseteq$"" is trivial. But the other inclusion does not seem to be clear to me. I am especially concerned, because the definition of the metric involves the $V$-norm, which is not equivalent to the norm on $H$, but might be much bigger. Hence - in general - the metric $\rho$ could be much bigger than just the weighted sup-norm (i.e. the metric we'd obtain by dropping the first summand for every $k$). I would be very grateful for any hint on this! Thanks a lot!","I came across the following question to which I could not figure out a straightforward answer: Let $H$ be a separable, (in general infinite-dimensional) real Hilbert space and $V$ a separable Banach space such that $V \subseteq H$ continuously and densely. $\mathbb{B}$ is defined as the following space of paths: $$\mathbb{B} := \{y \in C(\mathbb{R}_+,H)|\int_{0}^{T}||y(s)||_V\text{d}s < \infty \,\,\forall \,\,T >0\}.$$ One defines a metric $\rho$ on $\mathbb{B}$ through $$\rho(\omega_1,\omega_2) := \sum_{k=1}^{\infty}2^{-k}\bigg[\bigg(\int_{0}^{k}||\omega_2(s)-\omega_1(s)||_V \text{d}s + \underset{t \in [0,k]}{\text{sup}}||\omega_2(t)-\omega_1(t)||_{H}\bigg)\wedge 1\bigg].$$ Finally let $\pi_t:\mathbb{B} \to H$ denote the canonical projection at time $t \geq 0$, i.e. $\pi_t(y) := y_t$. Now I want to consider the Borel $\sigma$-algebra of the topology on $\mathbb{B}$, which is induced through $\rho$, denoted by $\mathcal{B}(\mathbb{B})$ as usual. **My question: Is it true - and if yes: how does one show this - that ** $$\mathcal{B}(\mathbb{B}) = \sigma(\pi_t|t \geq 0)?$$ Clearly each $\pi_t$ is continuous and hence ""$\supseteq$"" is trivial. But the other inclusion does not seem to be clear to me. I am especially concerned, because the definition of the metric involves the $V$-norm, which is not equivalent to the norm on $H$, but might be much bigger. Hence - in general - the metric $\rho$ could be much bigger than just the weighted sup-norm (i.e. the metric we'd obtain by dropping the first summand for every $k$). I would be very grateful for any hint on this! Thanks a lot!",,"['functional-analysis', 'measure-theory']"
78,How can I apply the law of large numbers here?,How can I apply the law of large numbers here?,,"I have a finite set $\lbrace r_i \rbrace_{i \in \Lambda}$ with $0 < r_i < 1$ for each $i$. Each $r_i$ has a probability $p_i$ associated to it. I define  $$ r = \prod_{i \in \Lambda}r_i^{p_i} $$ so that $\log r = \sum_{i \in \Lambda} p_i \log r_i$. Then it is claimed that by the law of large numbers, with probability tending to $1$, the random element $r_I = r_{i_1} \cdot \ldots\cdot r_{i_n}$ chosen with probability $p_I = p_{i_1} \cdot \ldots \cdot p_{i_n}$ satisfies  $$ r_I = r^{n(1 + o(1))}. $$ In other words, we claim that when $n$ is large, $r_I = r^n$ almost surely. How can I see this? I can calculate the expected value of $\log r_I$ which is $\log r^n$ but does the law of large numbers not apply into the mean of a sum of random variables? How can I say anything about this single variable? (The notation $o(1)$ stands for a quantity tending to $0$ as $n \to \infty$.) EDIT: In which variables am I even using the law on? The conclusion is about $r_I$ which is a singe RV $I \mapsto \mathbb{R}$. Can I present it as a mean of some other variables with expected value $r^n$? EDIT2: $\log r_I = \sum_{k=1}^n \log r_{i_k}$ and since $\mathbb{E}(\log r_{i_k}) = \log r$, I have $\dfrac{\log r_I}{n} \to \log r$ a.s. EDIT3: Oh wait I solved it, never mind","I have a finite set $\lbrace r_i \rbrace_{i \in \Lambda}$ with $0 < r_i < 1$ for each $i$. Each $r_i$ has a probability $p_i$ associated to it. I define  $$ r = \prod_{i \in \Lambda}r_i^{p_i} $$ so that $\log r = \sum_{i \in \Lambda} p_i \log r_i$. Then it is claimed that by the law of large numbers, with probability tending to $1$, the random element $r_I = r_{i_1} \cdot \ldots\cdot r_{i_n}$ chosen with probability $p_I = p_{i_1} \cdot \ldots \cdot p_{i_n}$ satisfies  $$ r_I = r^{n(1 + o(1))}. $$ In other words, we claim that when $n$ is large, $r_I = r^n$ almost surely. How can I see this? I can calculate the expected value of $\log r_I$ which is $\log r^n$ but does the law of large numbers not apply into the mean of a sum of random variables? How can I say anything about this single variable? (The notation $o(1)$ stands for a quantity tending to $0$ as $n \to \infty$.) EDIT: In which variables am I even using the law on? The conclusion is about $r_I$ which is a singe RV $I \mapsto \mathbb{R}$. Can I present it as a mean of some other variables with expected value $r^n$? EDIT2: $\log r_I = \sum_{k=1}^n \log r_{i_k}$ and since $\mathbb{E}(\log r_{i_k}) = \log r$, I have $\dfrac{\log r_I}{n} \to \log r$ a.s. EDIT3: Oh wait I solved it, never mind",,"['probability', 'measure-theory']"
79,Proof of Sard's theorem.,Proof of Sard's theorem.,,"In proof of Sard's theorem in Guillemin as well as in Milnor we consider $C$ such that if $x \in C$ then $\text{rank} \ df_x < p$  of function $f:U \rightarrow \mathbb R^p$, $U \subset R^n$ and $C_i$ such that all the partial derivatives of order $\leq i$ are $0$. In the proof of the theorem the following appears For each $x \in C-C_1, \exists  V \ \text{open}, x\in V $ such that $f(V \cap C)   $ has measure $0$. How to prove this?","In proof of Sard's theorem in Guillemin as well as in Milnor we consider $C$ such that if $x \in C$ then $\text{rank} \ df_x < p$  of function $f:U \rightarrow \mathbb R^p$, $U \subset R^n$ and $C_i$ such that all the partial derivatives of order $\leq i$ are $0$. In the proof of the theorem the following appears For each $x \in C-C_1, \exists  V \ \text{open}, x\in V $ such that $f(V \cap C)   $ has measure $0$. How to prove this?",,"['general-topology', 'measure-theory', 'differential-topology']"
80,Holomorphic functions with values in $L^2(X)$ vs. pointwise holomorphy.,Holomorphic functions with values in  vs. pointwise holomorphy.,L^2(X),"Let $X$ be a measure space. By Riesz-Fischer, $L^2(X)$ is a Banach space. When $U \subseteq \mathbb C$ is open, we have a notion of holomorphic functions $U \to L^2(X)$. (See the bottom for definitions.) Let's write such functions as $E(s, w)$. When $X$ has a nice topology (say it a Riemannian manifold) and $E$ is continuous in $(s, w)$ it makes sense to evaluate in $w$ and ask whether the complex-valued $E(s, w_0)$ is holomorphic for a specific $w_0$. Question. Are there any implications between the holomorphy of $E : U \to L^2(X)$ and the holomorphy of $E(\cdot, w_0) : U \to \mathbb C$ for all $w_0$? Here's one result in this direction I found: suppose $E : U \to L^2(X)$ is compactly supported, continuous in $(s, w)$, holomorphic in $s$ for all $w$ and $E'$ is continuous in $(s,w)$. Then $E$ and $E'$ are in $L^2$ and we have $$E(s, w) - E(s_0, w) = E'(s_0, w) (s-s_0) + o_w(s-s_0) $$ By assumption the little-$o$ term divided by $s-s_0$ is continuous in $(s,w)$, hence is square integrable and we have $$E(s, w) - E(s_0, w) = E'(s_0, w) (s-s_0) + o(s-s_0) $$ as an $L^2$-statement. I.e. $E : U \to L^2(X)$ is holomorphic. Equivalent definitions of holomorphic functions $f : U \to Y$, for $Y$ a Banach space are: $f$ is everywhere approximately linear: $f(s)-f(s_0) = f'(s_0)(s-s_0) + o(s-s_0)$ $\lambda \circ f$ is holomorphic for all $\lambda \in Y^*$ $f$ is locally a power series of the form $\sum A_n (s-s_0)^n$ Note the similarity between 2. and the question, where in a sense we look at $\lambda$ being the evaluation in a point (which is not well-defined on $L^2$).","Let $X$ be a measure space. By Riesz-Fischer, $L^2(X)$ is a Banach space. When $U \subseteq \mathbb C$ is open, we have a notion of holomorphic functions $U \to L^2(X)$. (See the bottom for definitions.) Let's write such functions as $E(s, w)$. When $X$ has a nice topology (say it a Riemannian manifold) and $E$ is continuous in $(s, w)$ it makes sense to evaluate in $w$ and ask whether the complex-valued $E(s, w_0)$ is holomorphic for a specific $w_0$. Question. Are there any implications between the holomorphy of $E : U \to L^2(X)$ and the holomorphy of $E(\cdot, w_0) : U \to \mathbb C$ for all $w_0$? Here's one result in this direction I found: suppose $E : U \to L^2(X)$ is compactly supported, continuous in $(s, w)$, holomorphic in $s$ for all $w$ and $E'$ is continuous in $(s,w)$. Then $E$ and $E'$ are in $L^2$ and we have $$E(s, w) - E(s_0, w) = E'(s_0, w) (s-s_0) + o_w(s-s_0) $$ By assumption the little-$o$ term divided by $s-s_0$ is continuous in $(s,w)$, hence is square integrable and we have $$E(s, w) - E(s_0, w) = E'(s_0, w) (s-s_0) + o(s-s_0) $$ as an $L^2$-statement. I.e. $E : U \to L^2(X)$ is holomorphic. Equivalent definitions of holomorphic functions $f : U \to Y$, for $Y$ a Banach space are: $f$ is everywhere approximately linear: $f(s)-f(s_0) = f'(s_0)(s-s_0) + o(s-s_0)$ $\lambda \circ f$ is holomorphic for all $\lambda \in Y^*$ $f$ is locally a power series of the form $\sum A_n (s-s_0)^n$ Note the similarity between 2. and the question, where in a sense we look at $\lambda$ being the evaluation in a point (which is not well-defined on $L^2$).",,"['complex-analysis', 'functional-analysis', 'measure-theory', 'banach-spaces', 'holomorphic-functions']"
81,"$ \int^1_0 \max\{f_1(x), . . . , f_n(x)\} \, dx \leq C $, $f_n \geq 0$ and $f_n \to 0$, then $f_n \to 0$ in $L^1(0,1)$",",  and , then  in"," \int^1_0 \max\{f_1(x), . . . , f_n(x)\} \, dx \leq C  f_n \geq 0 f_n \to 0 f_n \to 0 L^1(0,1)","Let $f_n \in L^1(0, 1)$ and $C > 0$ be such that $f_n \geq 0$, $f_n \to 0$ a.e. in $(0, 1)$, and $$ \int^1_0 \max\{f_1(x), . . . , f_n(x)\} \, dx \leq C $$ for every $n$. Prove that $f_n \to 0$ in $L^1(0,1)$. My solution. I define $g_n(x)=\max\{f_1(x), . . . , f_n(x)\}$. First of all I observe that $0\leq f_n \leq g_n$ a.e. The sequence $g_n$ is increasing and positive, then there exists a function $g\geq 0$ (eventually $g\equiv +\infty$) such that $g_n\to g$ a.e. By monotone convergence theorem we get $$ \int^1_0  g\, dx = \lim_{n\to\infty}\, \int^1_0  g_n \, dx\leq C  ,$$ then $g\in L^1(0,1)$ (and in particular a.e. finite). Now we are in position to use the ""generalized"" dominated convergence theorem (e.g. Variant of dominated convergence theorem, does it follow that $\int f_n \to \int f$? ). Do you agree with my proof ? I am also interested in different kind of solution. Thanks in advance. Update: it is not necessary to use the generalized DCT. If fact, since $g_n$ is increasing, we have $0\leq f_n \leq g_n \leq g$. So we can use the classical DCT using $g$ as dominant function for the sequence $f_n$. My mistake.","Let $f_n \in L^1(0, 1)$ and $C > 0$ be such that $f_n \geq 0$, $f_n \to 0$ a.e. in $(0, 1)$, and $$ \int^1_0 \max\{f_1(x), . . . , f_n(x)\} \, dx \leq C $$ for every $n$. Prove that $f_n \to 0$ in $L^1(0,1)$. My solution. I define $g_n(x)=\max\{f_1(x), . . . , f_n(x)\}$. First of all I observe that $0\leq f_n \leq g_n$ a.e. The sequence $g_n$ is increasing and positive, then there exists a function $g\geq 0$ (eventually $g\equiv +\infty$) such that $g_n\to g$ a.e. By monotone convergence theorem we get $$ \int^1_0  g\, dx = \lim_{n\to\infty}\, \int^1_0  g_n \, dx\leq C  ,$$ then $g\in L^1(0,1)$ (and in particular a.e. finite). Now we are in position to use the ""generalized"" dominated convergence theorem (e.g. Variant of dominated convergence theorem, does it follow that $\int f_n \to \int f$? ). Do you agree with my proof ? I am also interested in different kind of solution. Thanks in advance. Update: it is not necessary to use the generalized DCT. If fact, since $g_n$ is increasing, we have $0\leq f_n \leq g_n \leq g$. So we can use the classical DCT using $g$ as dominant function for the sequence $f_n$. My mistake.",,"['measure-theory', 'proof-verification', 'convergence-divergence', 'lebesgue-integral', 'alternative-proof']"
82,"Bernoulli-measure on sup- and subspace: ""Decompose"" metric entropy?","Bernoulli-measure on sup- and subspace: ""Decompose"" metric entropy?",,"Let $X=A^{\mathbb{Z}}$ for finite set $A$ of cardinality $\text{card}(A)=k<\infty$. Let $\tau$ denote the topology on $X$ with basis given by the set $C$ of  cylinders  $$ C_n(c_0,c_1,\ldots,c_m):=\{x\in X: x_n=c_0,\ldots,x_{n+m}=c_m\} $$ and $B(\tau)$ the Borel $\sigma$-algebra with the uniform Bernoulli-measure,  $$ \mu(C_n(c_0,\ldots,c_m)):=k^{-(m+1)}, $$ on it. Suppose $Y\subseteq X$ is a $T$-invariant subset, i.e. $T(Y)\subseteq Y$. Consider $S:=T_{|Y}$, the restriction of $T$ on $Y$. Similarly as above, let $\tau'$ be the topology on $Y$ with basis given by the set $C'$ of the cylinders $$ Y\cap C_n(c_0,c_1,\ldots,c_m). $$ Let $B(\tau')$ be the Borel $\sigma$-algebra with uniform Bernoulli-measure $\lambda$ on it. I have two questions concerning measure theory/ dynamics: (1) Am I right that $B(\tau')\subseteq B(\tau)$ and $\lambda=\mu_{|B(\tau')}$? (2) For the measure-theoretical entropy, do we have a statement or property telling that we can ""split"" it like     $$ h_{\mu}(T)=h_{\lambda}(S)+h_{\mu_{|B(\tau')^C}}(T_{|Y^C})? $$ (1) I think this follows by $\tau'\subseteq \tau$, hence $B(\tau')=\sigma(\tau')\subseteq\sigma(\tau)=B(\tau)$. Moreoever, both $(X,\tau)$ and $(Y,\tau')$ are separable, hence $B(\tau)=\sigma(C)$ and $B(\tau')=\sigma(C')$, meaning that the Borel $\sigma$-algebras coincide with the product $\sigma$-algebras (= cylinder $\sigma$-algebras). Moreover, $\mu=\lambda$ on $C'$ and $C'$ is invariant under intersection. By uniqueness theorem, $\mu=\lambda$ on $\sigma(C')$. (2) The reason why I am asking this is because I have an example where I can argue that $h_{\lambda}(S)=0$ and for further investigation I would like to know if this implies that $h_{\mu}(T)$ can be determined by neglecting ""what $S$ and $\lambda$ do"".  I have no idea... In case the splitting above is not correct, maybe there is another formula connecting $h_{\mu}(T)$ and $h_{\lambda}(S)$?","Let $X=A^{\mathbb{Z}}$ for finite set $A$ of cardinality $\text{card}(A)=k<\infty$. Let $\tau$ denote the topology on $X$ with basis given by the set $C$ of  cylinders  $$ C_n(c_0,c_1,\ldots,c_m):=\{x\in X: x_n=c_0,\ldots,x_{n+m}=c_m\} $$ and $B(\tau)$ the Borel $\sigma$-algebra with the uniform Bernoulli-measure,  $$ \mu(C_n(c_0,\ldots,c_m)):=k^{-(m+1)}, $$ on it. Suppose $Y\subseteq X$ is a $T$-invariant subset, i.e. $T(Y)\subseteq Y$. Consider $S:=T_{|Y}$, the restriction of $T$ on $Y$. Similarly as above, let $\tau'$ be the topology on $Y$ with basis given by the set $C'$ of the cylinders $$ Y\cap C_n(c_0,c_1,\ldots,c_m). $$ Let $B(\tau')$ be the Borel $\sigma$-algebra with uniform Bernoulli-measure $\lambda$ on it. I have two questions concerning measure theory/ dynamics: (1) Am I right that $B(\tau')\subseteq B(\tau)$ and $\lambda=\mu_{|B(\tau')}$? (2) For the measure-theoretical entropy, do we have a statement or property telling that we can ""split"" it like     $$ h_{\mu}(T)=h_{\lambda}(S)+h_{\mu_{|B(\tau')^C}}(T_{|Y^C})? $$ (1) I think this follows by $\tau'\subseteq \tau$, hence $B(\tau')=\sigma(\tau')\subseteq\sigma(\tau)=B(\tau)$. Moreoever, both $(X,\tau)$ and $(Y,\tau')$ are separable, hence $B(\tau)=\sigma(C)$ and $B(\tau')=\sigma(C')$, meaning that the Borel $\sigma$-algebras coincide with the product $\sigma$-algebras (= cylinder $\sigma$-algebras). Moreover, $\mu=\lambda$ on $C'$ and $C'$ is invariant under intersection. By uniqueness theorem, $\mu=\lambda$ on $\sigma(C')$. (2) The reason why I am asking this is because I have an example where I can argue that $h_{\lambda}(S)=0$ and for further investigation I would like to know if this implies that $h_{\mu}(T)$ can be determined by neglecting ""what $S$ and $\lambda$ do"".  I have no idea... In case the splitting above is not correct, maybe there is another formula connecting $h_{\mu}(T)$ and $h_{\lambda}(S)$?",,"['general-topology', 'measure-theory', 'entropy']"
83,measurability of argmin,measurability of argmin,,"Define for every $\omega\in\Omega$: $$f_\omega=\operatorname{argmin}_{f\in S} L(\omega,f)$$ where $\Omega$ is a measurable space $S\subseteq \big(C(\mathbb{R}^d,\mathbb{R}^n),\|{\cdot}\|_\infty\big)$ compact $L\colon\, \Omega\times C(\mathbb{R}^d,\mathbb{R}^n)\to [0,\infty)$ $\omega \mapsto L(\omega,f)$ is measurable for every $f\in C(\mathbb{R}^d,\mathbb{R}^n)$ $C(\mathbb{R}^d,\mathbb{R}^n) \ni f \mapsto L(\omega,f)$ is continuous for every $\omega\in\Omega$ Can we choose the minimizer $f_\omega$ for every $\omega$ in a way such that the mapping $(\Omega,\mathbb{R}^d) \ni(\omega,x)\mapsto f_{\omega}(x)$ is measurable? Idea: I think that Theorem 18.19 in Aliprantis & Border 2006 could be applicable? ( Measurability of supremum over measurable set )","Define for every $\omega\in\Omega$: $$f_\omega=\operatorname{argmin}_{f\in S} L(\omega,f)$$ where $\Omega$ is a measurable space $S\subseteq \big(C(\mathbb{R}^d,\mathbb{R}^n),\|{\cdot}\|_\infty\big)$ compact $L\colon\, \Omega\times C(\mathbb{R}^d,\mathbb{R}^n)\to [0,\infty)$ $\omega \mapsto L(\omega,f)$ is measurable for every $f\in C(\mathbb{R}^d,\mathbb{R}^n)$ $C(\mathbb{R}^d,\mathbb{R}^n) \ni f \mapsto L(\omega,f)$ is continuous for every $\omega\in\Omega$ Can we choose the minimizer $f_\omega$ for every $\omega$ in a way such that the mapping $(\Omega,\mathbb{R}^d) \ni(\omega,x)\mapsto f_{\omega}(x)$ is measurable? Idea: I think that Theorem 18.19 in Aliprantis & Border 2006 could be applicable? ( Measurability of supremum over measurable set )",,"['functional-analysis', 'measure-theory', 'optimization', 'calculus-of-variations', 'measurable-functions']"
84,Intuition behind the Caratheodory’s Criterion of a measurable set,Intuition behind the Caratheodory’s Criterion of a measurable set,,"This week I saw the definition of a measurable set for an outer measure. Let $\mu^*$ be an outer measure on a set $X$. We call $A \subseteq X$ measurable if $$\mu^*(E) = \mu^*(A\cap E) + \mu^*(A^c\cap E)$$ for every $E \subseteq X$. This is not the first time I've seen this definition. Unlike most other things in mathematics, over time I have gained absolutely no intuition as to why this is the definition. The only explanation I've ever seen is that a set is measurable if it 'breaks up' other sets in the way you'd want. I don't really see why this is the motivation though. One reason I am not comfortable with it is that you require a measurable set to break up sets which, according to this definition, are non-measurable; why would you require that? Of course, you can't say what a non-measurable set is without first defining what it means to be measurable so I suppose no matter what your condition is, it will have to apply to all subsets of $X$. Is there an intuitive way to think about the definition of measurable sets? Is there a good reason why we should use this definition, aside from ""it works""?","This week I saw the definition of a measurable set for an outer measure. Let $\mu^*$ be an outer measure on a set $X$. We call $A \subseteq X$ measurable if $$\mu^*(E) = \mu^*(A\cap E) + \mu^*(A^c\cap E)$$ for every $E \subseteq X$. This is not the first time I've seen this definition. Unlike most other things in mathematics, over time I have gained absolutely no intuition as to why this is the definition. The only explanation I've ever seen is that a set is measurable if it 'breaks up' other sets in the way you'd want. I don't really see why this is the motivation though. One reason I am not comfortable with it is that you require a measurable set to break up sets which, according to this definition, are non-measurable; why would you require that? Of course, you can't say what a non-measurable set is without first defining what it means to be measurable so I suppose no matter what your condition is, it will have to apply to all subsets of $X$. Is there an intuitive way to think about the definition of measurable sets? Is there a good reason why we should use this definition, aside from ""it works""?",,"['measure-theory', 'intuition', 'measurable-sets']"
85,Importance of $\sigma$-finiteness for Uniqueness of Measure $dm_f = f dm$,Importance of -finiteness for Uniqueness of Measure,\sigma dm_f = f dm,"Background Given a measure $m : X \rightarrow [0,+\infty]$ and a measurable function $f : X \rightarrow [0,+\infty]$, we can define a new measure by integrating $f$ as below: $$ m_f(E) = \int_E f \, dm $$ I'm not aware of a name for $m_f$, hence the awkward title.  My question arises from Exercise #1.2.2 of Tao, ""Epsilon of Room, Vol. I"" , which states the following: EOR #1.2.2: Let $m$ be $\sigma$-finite.  Given two functions $f,g : X \rightarrow [0,+\infty]$, show that $m_f = m_g$ if and only if $f = g$ for $m$-almost every $x$.  Give and example to show that this uniqueness statement can fail if $m$ is not $\sigma$-finite. I am trying to better understand the importance of the $\sigma$-finiteness condition.  For reference, here is my proof of the statement. Proof The $\impliedby$ direction is easy and true even when $X$ is not $\sigma$-finite.  For the $\implies$ direction, we prove the contrapositive. Let $\mu(X) < +\infty$ and suppose $f$ is not almost-everywhere equal to $g$, that is, $f \neq g$ on a set $E$ of positive but possibly infinite measure. Without loss of generality, we can take $f > g$ on $E$ since the sets $E \cap 1_{f > g}$ and $E \cap 1_{f < g}$ cannot both be null.  This condition prevents $g$ from being infinite on $E$. Moreover, we may assume $\mu(E) < +\infty$ is finite because each infinite-measure set in a sigma-finite space necessarily has a subset of positive measure.  This ensures $m_g(E) < +\infty$. Then, $m_f(E) = \int_E f \, dm > \int_E g \, dm  = m_g(E)$, where it is possible for $m_f(E) = +\infty$ but $m_g(E)$ must be finite. Counterexample Let $X = \{ a \}$ be a singleton set and $\mu : \{ \emptyset, X \} \rightarrow [0,+\infty]$ be the measure which assigns $\mu(\emptyset) = 0$ and $\mu(X) = +\infty$.  Clearly $X$ is not $\sigma$-finite.  Let $f(a) = 1$ and $g(a) = 2$.  Then $m_f(X) = m_g(X) = +\infty$, but $f \neq g$. Questions What is stopping uniqueness from being true when $X$ is not $\sigma$-finite? Like the counterexample suggests, we run into problems when $f$ and $g$ only disagree on sets of infinite measure, because then it is possible that $m_f(E) = m_g(E) = +\infty$.  Is this the only problematic case? For which classes of functions is $m_f$ unique even when $X$ is not $\sigma$-finite? What if we restrict $g$ to be integrable?  Then for any $E$, we have $m_g(E) < \int_X g dm < +\infty$.  This could be too strong an assumption though since integrable functions have $\sigma$-finite support.","Background Given a measure $m : X \rightarrow [0,+\infty]$ and a measurable function $f : X \rightarrow [0,+\infty]$, we can define a new measure by integrating $f$ as below: $$ m_f(E) = \int_E f \, dm $$ I'm not aware of a name for $m_f$, hence the awkward title.  My question arises from Exercise #1.2.2 of Tao, ""Epsilon of Room, Vol. I"" , which states the following: EOR #1.2.2: Let $m$ be $\sigma$-finite.  Given two functions $f,g : X \rightarrow [0,+\infty]$, show that $m_f = m_g$ if and only if $f = g$ for $m$-almost every $x$.  Give and example to show that this uniqueness statement can fail if $m$ is not $\sigma$-finite. I am trying to better understand the importance of the $\sigma$-finiteness condition.  For reference, here is my proof of the statement. Proof The $\impliedby$ direction is easy and true even when $X$ is not $\sigma$-finite.  For the $\implies$ direction, we prove the contrapositive. Let $\mu(X) < +\infty$ and suppose $f$ is not almost-everywhere equal to $g$, that is, $f \neq g$ on a set $E$ of positive but possibly infinite measure. Without loss of generality, we can take $f > g$ on $E$ since the sets $E \cap 1_{f > g}$ and $E \cap 1_{f < g}$ cannot both be null.  This condition prevents $g$ from being infinite on $E$. Moreover, we may assume $\mu(E) < +\infty$ is finite because each infinite-measure set in a sigma-finite space necessarily has a subset of positive measure.  This ensures $m_g(E) < +\infty$. Then, $m_f(E) = \int_E f \, dm > \int_E g \, dm  = m_g(E)$, where it is possible for $m_f(E) = +\infty$ but $m_g(E)$ must be finite. Counterexample Let $X = \{ a \}$ be a singleton set and $\mu : \{ \emptyset, X \} \rightarrow [0,+\infty]$ be the measure which assigns $\mu(\emptyset) = 0$ and $\mu(X) = +\infty$.  Clearly $X$ is not $\sigma$-finite.  Let $f(a) = 1$ and $g(a) = 2$.  Then $m_f(X) = m_g(X) = +\infty$, but $f \neq g$. Questions What is stopping uniqueness from being true when $X$ is not $\sigma$-finite? Like the counterexample suggests, we run into problems when $f$ and $g$ only disagree on sets of infinite measure, because then it is possible that $m_f(E) = m_g(E) = +\infty$.  Is this the only problematic case? For which classes of functions is $m_f$ unique even when $X$ is not $\sigma$-finite? What if we restrict $g$ to be integrable?  Then for any $E$, we have $m_g(E) < \int_X g dm < +\infty$.  This could be too strong an assumption though since integrable functions have $\sigma$-finite support.",,"['real-analysis', 'measure-theory', 'radon-nikodym']"
86,Space of finite measures as an $L_1$ space,Space of finite measures as an  space,L_1,"The dual of the space of continuous functions on a compact space $K$ is the space of regular signed measures with finite total variation, $rca(K)$. I have seen it stated (for example in this answer https://math.stackexchange.com/a/74877/564061 ) that this is isometric to $L_1(\mu)$ for some measure $\mu$ on $K$. I know that the space is isomorphic to the $l_1$ sum of spaces $L_1(\mu_i)$ for mutually singular probability measures $\mu_i$, $i\in\mathcal{A}$ (possibly uncountable), see $\mathcal M(K)$ is an $\mathcal{l}_1-$sum of $L_1(\mu)$ spaces . Is there a way to relate this space to one of the form $L_1(\mu)$? It seems to me that the obvious candidate bijection would map $(f_i)_{i\in\mathcal{A}}$ to $\sum_{i\in\mathcal{A}}f_i$. I think we can make sense of this sum since only countably many of the $f_i$ are non-zero at any $x\in K$, but I am not sure how to progress. At first I thought that for any $x$ there was at most one $i\in\mathcal{A}$ such that $f_i(x)\neq 0$, but that isn't the case. I am asking because I wish to write elements of $C(K)^{**}$ as functions on $K$. The above relation allows us to equate $C(K)^{**}$ and the $l_{\infty}$-product of the spaces $L_{\infty}(\mu_i)$, and really I would just like a 'nice' relation between $C(K)^{**}$ and some space of functions, to avoid dealing with these nets of functions- the properties of the space aren't important. I am interested particularly in the case where $K\subseteq \mathbb{R}^2$.","The dual of the space of continuous functions on a compact space $K$ is the space of regular signed measures with finite total variation, $rca(K)$. I have seen it stated (for example in this answer https://math.stackexchange.com/a/74877/564061 ) that this is isometric to $L_1(\mu)$ for some measure $\mu$ on $K$. I know that the space is isomorphic to the $l_1$ sum of spaces $L_1(\mu_i)$ for mutually singular probability measures $\mu_i$, $i\in\mathcal{A}$ (possibly uncountable), see $\mathcal M(K)$ is an $\mathcal{l}_1-$sum of $L_1(\mu)$ spaces . Is there a way to relate this space to one of the form $L_1(\mu)$? It seems to me that the obvious candidate bijection would map $(f_i)_{i\in\mathcal{A}}$ to $\sum_{i\in\mathcal{A}}f_i$. I think we can make sense of this sum since only countably many of the $f_i$ are non-zero at any $x\in K$, but I am not sure how to progress. At first I thought that for any $x$ there was at most one $i\in\mathcal{A}$ such that $f_i(x)\neq 0$, but that isn't the case. I am asking because I wish to write elements of $C(K)^{**}$ as functions on $K$. The above relation allows us to equate $C(K)^{**}$ and the $l_{\infty}$-product of the spaces $L_{\infty}(\mu_i)$, and really I would just like a 'nice' relation between $C(K)^{**}$ and some space of functions, to avoid dealing with these nets of functions- the properties of the space aren't important. I am interested particularly in the case where $K\subseteq \mathbb{R}^2$.",,"['functional-analysis', 'measure-theory', 'banach-spaces']"
87,Can divergence be thought of as a Radon-Nikodym derivative?,Can divergence be thought of as a Radon-Nikodym derivative?,,"The divergence theorem states roughly $$\int_\Omega \operatorname{div}U\ dV=\int_{\partial \Omega}U\cdot n\ dS$$ where $U$ is a vector field, $\Omega$ is a region of space with a smooth boundary, $n$ is a smooth normal vector field on its boundary. This looks alot like a Radon-Nikodym derivative: a certain function on sets can be obtained by integrating something on that set. In this interpretation, we would think of the right hand side of the equation, the flux of $U$ out of $\Omega$, as a (signed) measure. It seems like it should be additive like a measure should be, and perhaps it can even be extended to the Borel sigma algebra via something like Carathéodory's extension theorem. The other question is if this ""flux measure"" is absolutely continuous with respect to the Lebesgue measure. This is plausible since the flux out of a flat surface should be zero: remember that we're thinking of closed surfaces here, so we should be integrating on ""both sides"" of the flat surface, which will cancel out. Can this interpretation in any way be made rigorous?","The divergence theorem states roughly $$\int_\Omega \operatorname{div}U\ dV=\int_{\partial \Omega}U\cdot n\ dS$$ where $U$ is a vector field, $\Omega$ is a region of space with a smooth boundary, $n$ is a smooth normal vector field on its boundary. This looks alot like a Radon-Nikodym derivative: a certain function on sets can be obtained by integrating something on that set. In this interpretation, we would think of the right hand side of the equation, the flux of $U$ out of $\Omega$, as a (signed) measure. It seems like it should be additive like a measure should be, and perhaps it can even be extended to the Borel sigma algebra via something like Carathéodory's extension theorem. The other question is if this ""flux measure"" is absolutely continuous with respect to the Lebesgue measure. This is plausible since the flux out of a flat surface should be zero: remember that we're thinking of closed surfaces here, so we should be integrating on ""both sides"" of the flat surface, which will cancel out. Can this interpretation in any way be made rigorous?",,"['real-analysis', 'measure-theory', 'multivariable-calculus', 'radon-nikodym']"
88,(Measure theory) Convergence under integral sign of a decreasing sequence,(Measure theory) Convergence under integral sign of a decreasing sequence,,"I am stuck with the following problem. The problem is still unsolved. Let $\left(X,\mu\right)$ be a measure space with a positive, finite  measure $\mu$; and let $\left\{ f_{j}\in L^{\infty}\left(X\right)\right\}$  be a decreasing sequence converging pointwise to $f;$ $f_{j}\searrow f.$ Assume that  $$ \intop_{X}f_{j}d\mu\geq-1. $$  Can we conclude that  $$ \intop_{X}fd\mu\geq-1? $$ Thank you.","I am stuck with the following problem. The problem is still unsolved. Let $\left(X,\mu\right)$ be a measure space with a positive, finite  measure $\mu$; and let $\left\{ f_{j}\in L^{\infty}\left(X\right)\right\}$  be a decreasing sequence converging pointwise to $f;$ $f_{j}\searrow f.$ Assume that  $$ \intop_{X}f_{j}d\mu\geq-1. $$  Can we conclude that  $$ \intop_{X}fd\mu\geq-1? $$ Thank you.",,"['real-analysis', 'integration', 'functional-analysis', 'measure-theory']"
89,application for Integration of non-negative measurable functions,application for Integration of non-negative measurable functions,,"For each $n = 1, 2, 3, . . .,$  let $f_n : \Bbb R → \Bbb R$  be the function $f_n = \chi[n,n+1)− \chi[n+1,n+2)$; i.e., let $f_n(x)$ equal $+1$ when $x ∈ [n, n + 1)$, equal $−1$ when $x ∈ [n + 1, n + 2)$, and $0$ everywhere else. Show that $\int_\Bbb R \sum_{n=1}^\infty f_n \ne \sum_{n=1}^\infty\int_\Bbb R  f_n$ My work: Notice that $f_n+f_{n+1}= χ[n,n+1)− χ[n+2,n+3)$. This implies that $\sum_{n=1}^{\infty} f_n= \chi[1,2)$  because every other point the characteristic function become zero for all rest of the partial sum. Therefore, $\int_\Bbb R \sum_{n=1}^\infty f_n =\int_\Bbb R \chi[1,2)=1 $  but $\sum_{n=1}^\infty\int_\Bbb R  f_n=0$. Thus we are done.  Did I miss anything? I was wondering if you could help me to solve this problem. I appreciate your kind help. Thank you!","For each $n = 1, 2, 3, . . .,$  let $f_n : \Bbb R → \Bbb R$  be the function $f_n = \chi[n,n+1)− \chi[n+1,n+2)$; i.e., let $f_n(x)$ equal $+1$ when $x ∈ [n, n + 1)$, equal $−1$ when $x ∈ [n + 1, n + 2)$, and $0$ everywhere else. Show that $\int_\Bbb R \sum_{n=1}^\infty f_n \ne \sum_{n=1}^\infty\int_\Bbb R  f_n$ My work: Notice that $f_n+f_{n+1}= χ[n,n+1)− χ[n+2,n+3)$. This implies that $\sum_{n=1}^{\infty} f_n= \chi[1,2)$  because every other point the characteristic function become zero for all rest of the partial sum. Therefore, $\int_\Bbb R \sum_{n=1}^\infty f_n =\int_\Bbb R \chi[1,2)=1 $  but $\sum_{n=1}^\infty\int_\Bbb R  f_n=0$. Thus we are done.  Did I miss anything? I was wondering if you could help me to solve this problem. I appreciate your kind help. Thank you!",,"['real-analysis', 'measure-theory', 'lebesgue-integral', 'lebesgue-measure']"
90,st printed over equality symbol,st printed over equality symbol,,"I'm reading an older statistical paper (1994 - not too old, but before computers were in every office) and the author writes the following: From (#) we see that $\mathbf P$ satisfies the distributional equation   $$\mathbf P \stackrel{st}{=}\theta_1\mathbf D + (1 - \theta_1)\mathbf P$$ I should add for clarity that $\mathbf P$ is a vector obtained by applying a random probability measure on a measurable partition of the sample space and $\mathbf D$ is a series of indicator variables with respect to the same partition. I think I understand what's going on in the paper, and it would make sense based on this (and other uses in the paper) for this symbol to indicate equality in distribution - but I've never seen that notation before. (I've always seen it written with a lower case $d$: (e.g. $\stackrel{d}{=}$).  Is the ""obvious"" definition correct, or am I missing something subtle? For anyone interested (or who found my explanation overly simplistic), a link to the whole paper is here: http://www3.stat.sinica.edu.tw/statistica/j4n2/j4n216/j4n216.htm It should be open access.  My goal is simply to verify the meaning of the symbol. Thanks!","I'm reading an older statistical paper (1994 - not too old, but before computers were in every office) and the author writes the following: From (#) we see that $\mathbf P$ satisfies the distributional equation   $$\mathbf P \stackrel{st}{=}\theta_1\mathbf D + (1 - \theta_1)\mathbf P$$ I should add for clarity that $\mathbf P$ is a vector obtained by applying a random probability measure on a measurable partition of the sample space and $\mathbf D$ is a series of indicator variables with respect to the same partition. I think I understand what's going on in the paper, and it would make sense based on this (and other uses in the paper) for this symbol to indicate equality in distribution - but I've never seen that notation before. (I've always seen it written with a lower case $d$: (e.g. $\stackrel{d}{=}$).  Is the ""obvious"" definition correct, or am I missing something subtle? For anyone interested (or who found my explanation overly simplistic), a link to the whole paper is here: http://www3.stat.sinica.edu.tw/statistica/j4n2/j4n216/j4n216.htm It should be open access.  My goal is simply to verify the meaning of the symbol. Thanks!",,"['statistics', 'measure-theory']"
91,What is the meaning of vector measures?,What is the meaning of vector measures?,,"In the case measures, assume that we are considering a positive measure $\mu$ on $\mathcal{B}(R^{2})$-which is the set of borel sets in $R^{2}$, that has density f(x,y)-it can be seen as density of polulation. Then, when we consider a borel set $A\subset R^{2}$, we obtain the information of the population in the set A which is $$\mu(A)=\int_{A} f(x,y)d\mu.$$ So, now could you give me some practical examples that can illustrate the concept of vector measures?.","In the case measures, assume that we are considering a positive measure $\mu$ on $\mathcal{B}(R^{2})$-which is the set of borel sets in $R^{2}$, that has density f(x,y)-it can be seen as density of polulation. Then, when we consider a borel set $A\subset R^{2}$, we obtain the information of the population in the set A which is $$\mu(A)=\int_{A} f(x,y)d\mu.$$ So, now could you give me some practical examples that can illustrate the concept of vector measures?.",,"['measure-theory', 'geometric-measure-theory']"
92,Differentiating the single-layer potential,Differentiating the single-layer potential,,"Suppose $f\in L^2[-1,1]$ and consider the single layer potential with moment $f$ on $[-1,1]$ $$ Kf(x,y) = -\frac{1}{2\pi}\int_{-1}^1 \ln|(x,y) - (\xi,0)|f(\xi)\, d\xi $$ Formally I shown that for $x\in[-1,1]$ $$ \frac{\partial Kf}{\partial y}\bigg|_{y=0} = \frac{f(x)}{2} $$ by differentiating under the integral sign. But I have trouble justifying interchanging the differentiation and integration. As far as I am aware, this is doable if $f\in C^0[-1,1]$ (or maybe $f\in C_c^0[-1,1]$), but I'm not entirely sure if I am allowed to simply abuse the fact that $C^0[-1,1]$ is dense in $L^2[-1,1]$. I am looking for a reference to this result if possible, since layer potential theory is well-studied.","Suppose $f\in L^2[-1,1]$ and consider the single layer potential with moment $f$ on $[-1,1]$ $$ Kf(x,y) = -\frac{1}{2\pi}\int_{-1}^1 \ln|(x,y) - (\xi,0)|f(\xi)\, d\xi $$ Formally I shown that for $x\in[-1,1]$ $$ \frac{\partial Kf}{\partial y}\bigg|_{y=0} = \frac{f(x)}{2} $$ by differentiating under the integral sign. But I have trouble justifying interchanging the differentiation and integration. As far as I am aware, this is doable if $f\in C^0[-1,1]$ (or maybe $f\in C_c^0[-1,1]$), but I'm not entirely sure if I am allowed to simply abuse the fact that $C^0[-1,1]$ is dense in $L^2[-1,1]$. I am looking for a reference to this result if possible, since layer potential theory is well-studied.",,"['measure-theory', 'partial-differential-equations', 'integral-equations', 'potential-theory']"
93,"Showing that a measurable function is almost everywhere 0, proof check.","Showing that a measurable function is almost everywhere 0, proof check.",,"Let $f$ measurable and almost everywhere finite on $[0,1]$. Let $\int_{E} f\,d\lambda = 0$ for any measurable $E\subset[0,1]$ with $\lambda(E) = \frac{1}{2}$. (Where $\lambda$ is the Lebesgue measure and the function is Lebesgue measurable). I would like to show that $f$ is almost everywhere $0$. That is the last part in a many part question but it would kill every other part. I believe my proof is correct. Put $A=f^{-1}((0,\infty])$, $B=f^{-1}([-\infty,0))$, $C=f^{-1}(\{0 \})$. Notice that $A\cup B \cup C = [0,1]$. Claim: We have that $\lambda(A) < \frac{1}{2}$ and $\lambda(B) < \frac{1}{2}$ (and so $\lambda(C) > 0$). Proof: Suppose that $\lambda(A) \geq \frac{1}{2}$. Put $A' = \{x\in[0,1]:\lambda(A\cap[0,x]) \geq \frac{1}{2} \}$. This set is nonempty as it contains $1$. Put $\alpha = \inf A'$. The continuity of the measure provides that $\lambda(A\cap[0,\alpha]) = \frac{1}{2}$. By hypothesis we then have $$\int_{A\cap[0,\alpha]}f\,d\lambda = 0. $$ Since $f$ is nonnegative on the domain of integration, it must be that this $f$ is almost everywhere $0$ on it. This contradicts that $f$ is strictly positive on $A$. A similar proof gives the result for $B$. Since $\lambda(B) < \frac{1}{2}$ it must be that $\lambda(A\cup C) = \lambda(A)+\lambda(C) \geq \frac{1}{2}$. But then we may do the same trick. Claim: We have that $\lambda(A) = \lambda(B) = 0$ and so $\lambda(C) = 1$ (and $f$ is 0 almost everywhere) Proof:Put $A'' = \{x\in[0,1] : \lambda(A\cup(C\cap[0,x]))\geq\frac{1}{2} \}$. This set is also nonempty because it contains $1$. Put $\beta = \inf A''$. The continuity of the measure provides that $\lambda(A\cup(C\cap[0,\beta])) = \frac{1}{2}$. By hypothesis we have $$\int_{A\cup(C\cap[0,\beta])}f\,d\lambda = 0 .$$ Since $f$ is nonnegative on the domain of integration, it must be that $f$ is almost everywhere $0$ on it. Since $f$ is strictly positive on $A$, this can only be so $\lambda(A) = 0$. A similar proof gives the result for $B$.","Let $f$ measurable and almost everywhere finite on $[0,1]$. Let $\int_{E} f\,d\lambda = 0$ for any measurable $E\subset[0,1]$ with $\lambda(E) = \frac{1}{2}$. (Where $\lambda$ is the Lebesgue measure and the function is Lebesgue measurable). I would like to show that $f$ is almost everywhere $0$. That is the last part in a many part question but it would kill every other part. I believe my proof is correct. Put $A=f^{-1}((0,\infty])$, $B=f^{-1}([-\infty,0))$, $C=f^{-1}(\{0 \})$. Notice that $A\cup B \cup C = [0,1]$. Claim: We have that $\lambda(A) < \frac{1}{2}$ and $\lambda(B) < \frac{1}{2}$ (and so $\lambda(C) > 0$). Proof: Suppose that $\lambda(A) \geq \frac{1}{2}$. Put $A' = \{x\in[0,1]:\lambda(A\cap[0,x]) \geq \frac{1}{2} \}$. This set is nonempty as it contains $1$. Put $\alpha = \inf A'$. The continuity of the measure provides that $\lambda(A\cap[0,\alpha]) = \frac{1}{2}$. By hypothesis we then have $$\int_{A\cap[0,\alpha]}f\,d\lambda = 0. $$ Since $f$ is nonnegative on the domain of integration, it must be that this $f$ is almost everywhere $0$ on it. This contradicts that $f$ is strictly positive on $A$. A similar proof gives the result for $B$. Since $\lambda(B) < \frac{1}{2}$ it must be that $\lambda(A\cup C) = \lambda(A)+\lambda(C) \geq \frac{1}{2}$. But then we may do the same trick. Claim: We have that $\lambda(A) = \lambda(B) = 0$ and so $\lambda(C) = 1$ (and $f$ is 0 almost everywhere) Proof:Put $A'' = \{x\in[0,1] : \lambda(A\cup(C\cap[0,x]))\geq\frac{1}{2} \}$. This set is also nonempty because it contains $1$. Put $\beta = \inf A''$. The continuity of the measure provides that $\lambda(A\cup(C\cap[0,\beta])) = \frac{1}{2}$. By hypothesis we have $$\int_{A\cup(C\cap[0,\beta])}f\,d\lambda = 0 .$$ Since $f$ is nonnegative on the domain of integration, it must be that $f$ is almost everywhere $0$ on it. Since $f$ is strictly positive on $A$, this can only be so $\lambda(A) = 0$. A similar proof gives the result for $B$.",,"['measure-theory', 'proof-verification']"
94,Under what condition does the weak limit of function a function?,Under what condition does the weak limit of function a function?,,"Let $B$ be the set of bounded functions $[0, 1] \rightarrow \mathbb R$.  a sequence $f_n$ of $B$ converges weakly to a distribution $\mu$ if  $$\int_0^1 g(t) f_n(t) \rm{d}t  \rightarrow \int_0^1 g d\mu \quad \text{ for all continuous functions } g.$$ Under what conditions is $\mu$ absolutely continuous w.r.t the Lebesgues measure? (i.e. $\exists f \in B \text{ s.t } d\mu  = f dt$?) One such a condition is that the $f_n$ be uniformly bounded. Are there others?","Let $B$ be the set of bounded functions $[0, 1] \rightarrow \mathbb R$.  a sequence $f_n$ of $B$ converges weakly to a distribution $\mu$ if  $$\int_0^1 g(t) f_n(t) \rm{d}t  \rightarrow \int_0^1 g d\mu \quad \text{ for all continuous functions } g.$$ Under what conditions is $\mu$ absolutely continuous w.r.t the Lebesgues measure? (i.e. $\exists f \in B \text{ s.t } d\mu  = f dt$?) One such a condition is that the $f_n$ be uniformly bounded. Are there others?",,"['measure-theory', 'lebesgue-measure', 'weak-convergence']"
95,Outer measure induced by a Jump function,Outer measure induced by a Jump function,,"This is from exercise 4.4 of Elstrodt's measure theory textbook. By a jump function $F:\mathbb{R}\rightarrow\mathbb{R}$ we mean a function which can be written in the form $$F(x)= \begin{cases}\phantom{-}\sum_{y\in A\cap(0,x]}p(y)&\text{if $x\geq0$}\\-\sum_{y\in A\cap(x,0]}p(y)&\text{if $x<0$}\end{cases}$$ where $A$ is some subset of $\mathbb{R}$ and $p:A\rightarrow(0,\infty)$ is a function satisfying the 'local summability' condition; that is, we require that $\sum_{y\in A\cap B}p(y)<\infty$ for every bounded subset $B$ of $\mathbb{R}$. (This makes $A$ necessarily a countable subset.) We now consider the outer measure induced by $F$. Writing this by $\eta_F$, we have, by definition, $$\eta_F(S)=\inf\left\{\sum_{i=1}^{\infty}(F(b_i)-F(a_i)):S\subset\bigcup_{i=1}^{\infty}(a_i,b_i]\right\}$$ where $S$ is any subset of $\mathbb{R}$ and $a_i,b_i\in\mathbb{R}$. With this outer measure, the Caratheodory construction now gives the $\sigma$-algebra of $\eta_F$-measurable subsets. The problem is to show that EVERY subset of $\mathbb{R}$ is $\eta_F$-measurable. I've added the original German text below for clarity. What I have tried: The problem is equivalent to showing that $\eta_F(S\cup T)=\eta_F(S)+\eta_F(T)$ for every disjoint subsets $S,T$ of $\mathbb{R}$. I figured that maybe $\eta_F(S)=\sum_{y\in A\cap S}p(y)$ holds for every $S$, and tried to prove this. I've succeeded in showing $\eta_F(S)\geq\sum_{y\in A\cap S}p(y)$, but got stuck on the other inequality. Right now I'm not quite sure whether this is the right idea... Any advice is welcome!","This is from exercise 4.4 of Elstrodt's measure theory textbook. By a jump function $F:\mathbb{R}\rightarrow\mathbb{R}$ we mean a function which can be written in the form $$F(x)= \begin{cases}\phantom{-}\sum_{y\in A\cap(0,x]}p(y)&\text{if $x\geq0$}\\-\sum_{y\in A\cap(x,0]}p(y)&\text{if $x<0$}\end{cases}$$ where $A$ is some subset of $\mathbb{R}$ and $p:A\rightarrow(0,\infty)$ is a function satisfying the 'local summability' condition; that is, we require that $\sum_{y\in A\cap B}p(y)<\infty$ for every bounded subset $B$ of $\mathbb{R}$. (This makes $A$ necessarily a countable subset.) We now consider the outer measure induced by $F$. Writing this by $\eta_F$, we have, by definition, $$\eta_F(S)=\inf\left\{\sum_{i=1}^{\infty}(F(b_i)-F(a_i)):S\subset\bigcup_{i=1}^{\infty}(a_i,b_i]\right\}$$ where $S$ is any subset of $\mathbb{R}$ and $a_i,b_i\in\mathbb{R}$. With this outer measure, the Caratheodory construction now gives the $\sigma$-algebra of $\eta_F$-measurable subsets. The problem is to show that EVERY subset of $\mathbb{R}$ is $\eta_F$-measurable. I've added the original German text below for clarity. What I have tried: The problem is equivalent to showing that $\eta_F(S\cup T)=\eta_F(S)+\eta_F(T)$ for every disjoint subsets $S,T$ of $\mathbb{R}$. I figured that maybe $\eta_F(S)=\sum_{y\in A\cap S}p(y)$ holds for every $S$, and tried to prove this. I've succeeded in showing $\eta_F(S)\geq\sum_{y\in A\cap S}p(y)$, but got stuck on the other inequality. Right now I'm not quite sure whether this is the right idea... Any advice is welcome!",,"['real-analysis', 'measure-theory', 'real-numbers', 'outer-measure']"
96,The sum of continuous almost everywhere function is also continuous almost everywhere?,The sum of continuous almost everywhere function is also continuous almost everywhere?,,"My textbook is asking me to solve this exercise. I thought this is trivial, but The author put ‘prove or disprove’. So I’m confusing. Let f and g be a real-valued function on [a,b]. And assume that f and g are continuous almost everywhere on [a,b]. Prove or disprove : f+g is continuous almost everywhere. I think this is true. If f is continuous at x and g is continuous at x, f+g is continuous at x. So if A is the set of points of discontinuity of f, and B is of g, then AUB contains the set C of discontinuous points of f+g, i.e. C is contained in AUB By definition, A and B is of measure zero. And the sum of countably many measure zero sets is also of measure zero. So, AUB is of measure zero. Therefore C is of measure zero. So f+g is continuous almost everywhere. Am I right? Thanks","My textbook is asking me to solve this exercise. I thought this is trivial, but The author put ‘prove or disprove’. So I’m confusing. Let f and g be a real-valued function on [a,b]. And assume that f and g are continuous almost everywhere on [a,b]. Prove or disprove : f+g is continuous almost everywhere. I think this is true. If f is continuous at x and g is continuous at x, f+g is continuous at x. So if A is the set of points of discontinuity of f, and B is of g, then AUB contains the set C of discontinuous points of f+g, i.e. C is contained in AUB By definition, A and B is of measure zero. And the sum of countably many measure zero sets is also of measure zero. So, AUB is of measure zero. Therefore C is of measure zero. So f+g is continuous almost everywhere. Am I right? Thanks",,"['real-analysis', 'measure-theory', 'almost-everywhere']"
97,"problem with non measurable, bochner-integrable function","problem with non measurable, bochner-integrable function",,"Let $(S,\Sigma,\mu)$ be a measure space and $(X,\Vert .\Vert_X)$ a Banach space. I got a question concerning the properties of the Bochner Integral (as it is defined here: https://en.wikipedia.org/wiki/Bochner_integral ) in the case of an non-complete measure space (for definition and example look here: https://en.wikipedia.org/wiki/Complete_measure ). In the wikipedia article (or in 'Analysis in Banach Spaces - Volume 1' by Hytönen, van Neerven, Vera, Weis as a recent alternative reference) it is mentioned, that for a Bochner-measurable function $f:S\mapsto X$ bochner-integrability is equivalent to the lebesgue-integrability of $\Vert f\Vert_X$. On page 14. in the mentioned book, the authors claim: 'If f is Bochner integrable and f=g almost everywhere, then g is Bochner integrable and the Bochner integrals of f and g agree.' ($f, g:S\mapsto X$) Now if $(S,\Sigma,\mu)$ is non-complete, then there exists a set $M\in\Sigma$ with $\mu(M)=0$ and a subset $N\subset M$ such that $N\notin\Sigma$. For this set N, the characteristic function $\chi_N$ equals almost everywhere (on the complement of the nullset M) the Bochner integrable zero function, and hence, by the mentioned equivalence, $\chi_N$ is Lebesgue integrable without even being measurable. I hope someone can help me in my confusion. Thanks so far PS: One can find alternative examples without using the claimed fact, that Bochner integrability is preserved by an almost everywhere equality.","Let $(S,\Sigma,\mu)$ be a measure space and $(X,\Vert .\Vert_X)$ a Banach space. I got a question concerning the properties of the Bochner Integral (as it is defined here: https://en.wikipedia.org/wiki/Bochner_integral ) in the case of an non-complete measure space (for definition and example look here: https://en.wikipedia.org/wiki/Complete_measure ). In the wikipedia article (or in 'Analysis in Banach Spaces - Volume 1' by Hytönen, van Neerven, Vera, Weis as a recent alternative reference) it is mentioned, that for a Bochner-measurable function $f:S\mapsto X$ bochner-integrability is equivalent to the lebesgue-integrability of $\Vert f\Vert_X$. On page 14. in the mentioned book, the authors claim: 'If f is Bochner integrable and f=g almost everywhere, then g is Bochner integrable and the Bochner integrals of f and g agree.' ($f, g:S\mapsto X$) Now if $(S,\Sigma,\mu)$ is non-complete, then there exists a set $M\in\Sigma$ with $\mu(M)=0$ and a subset $N\subset M$ such that $N\notin\Sigma$. For this set N, the characteristic function $\chi_N$ equals almost everywhere (on the complement of the nullset M) the Bochner integrable zero function, and hence, by the mentioned equivalence, $\chi_N$ is Lebesgue integrable without even being measurable. I hope someone can help me in my confusion. Thanks so far PS: One can find alternative examples without using the claimed fact, that Bochner integrability is preserved by an almost everywhere equality.",,"['integration', 'measure-theory']"
98,How to prove the following application of the Stiltjes series expansion,How to prove the following application of the Stiltjes series expansion,,"We begin with a density given by $$ \tag 1 K(\xi)=\sum_{k=1}^K p_k\delta\left(\xi -\xi_k\right)  $$ The question is how to prove the following $$ \tag 2 \int_0^{max(\xi)}K(\xi)\frac{(z\xi)^{1-K}}{1-z\xi}d\xi=\sum_{k=1-K}^{K}z^kM_k $$ where the moment equation  $$ \tag 3 \sum_{k=1}^Kp_k(\xi_k)^m=M_m, $$ holds.  I don't understand how the summation limits in (2) are derived and why the term $(z\xi)^{1-K}$ is needed. I also don't understand how this relates to the formula for the Stiltjes transformation given here Motivation: The reasoning behind this is to find the values of $\xi_k$. This is done using the theorem, which states that if we would define  $$ f(z)=\int_0^\infty\frac{d\phi(u)}{1-zu} $$ for a real, non-decreasing and bounded function $\phi(x)$ for $x\in[0,\infty)$, for $\forall z \in \mathbb{C}\setminus \left ( \mathbb{R}^+ \right ) $ exists the series expansion in terms of the moments $f_j$ $$ f(z)=\sum\limits_{j=0}^\infty f_j z^j $$ By using the $[N+1][N]$ Pade expansion it can be shown that $$ f(z)=\frac{a_0+a_1z+a_2z^2+\dots +a_{N+1}z^{N+1}}{b_0+b_1z+b_2z^2+\dots +a_{N}z^{N}}=\sum\limits_{i=1}^N\frac{w_i}{z-z_i}. $$ In that case the poles $z_j$ are simple and real. The proof of the above statement can be found in this paper . (pdf link)","We begin with a density given by $$ \tag 1 K(\xi)=\sum_{k=1}^K p_k\delta\left(\xi -\xi_k\right)  $$ The question is how to prove the following $$ \tag 2 \int_0^{max(\xi)}K(\xi)\frac{(z\xi)^{1-K}}{1-z\xi}d\xi=\sum_{k=1-K}^{K}z^kM_k $$ where the moment equation  $$ \tag 3 \sum_{k=1}^Kp_k(\xi_k)^m=M_m, $$ holds.  I don't understand how the summation limits in (2) are derived and why the term $(z\xi)^{1-K}$ is needed. I also don't understand how this relates to the formula for the Stiltjes transformation given here Motivation: The reasoning behind this is to find the values of $\xi_k$. This is done using the theorem, which states that if we would define  $$ f(z)=\int_0^\infty\frac{d\phi(u)}{1-zu} $$ for a real, non-decreasing and bounded function $\phi(x)$ for $x\in[0,\infty)$, for $\forall z \in \mathbb{C}\setminus \left ( \mathbb{R}^+ \right ) $ exists the series expansion in terms of the moments $f_j$ $$ f(z)=\sum\limits_{j=0}^\infty f_j z^j $$ By using the $[N+1][N]$ Pade expansion it can be shown that $$ f(z)=\frac{a_0+a_1z+a_2z^2+\dots +a_{N+1}z^{N+1}}{b_0+b_1z+b_2z^2+\dots +a_{N}z^{N}}=\sum\limits_{i=1}^N\frac{w_i}{z-z_i}. $$ In that case the poles $z_j$ are simple and real. The proof of the above statement can be found in this paper . (pdf link)",,"['complex-analysis', 'measure-theory', 'power-series', 'pade-approximation']"
99,Metric Density always zero or one?,Metric Density always zero or one?,,"I am given a fixed Borel measurable set $E\subset\mathbb [0,1]^n$, $|E|>0$, and I want to show that there exists some $\epsilon_0>0$ such that for all $\delta>0$ there exists a cube $C_\delta\subset [0,1]^n$ with $|C_\delta|\le\delta$ such that $$ \epsilon_0\le\frac{|C_\delta\cap E|}{|C_\delta|}\le 1-\epsilon_0. $$ This would hold true if there existed a point at which the metric density of $E$ was neither zero nor one. My question therefore is: Does there always exist such a point? And if not, how else can I prove the claim above? A simple example is $E = [0,\tfrac 1 2]$ in $[0,1]$ (i.e., $n=1$). Then we can choose $C_\delta = (\tfrac 1 2-\tfrac\delta 2,\tfrac 1 2+\tfrac\delta 2)$.","I am given a fixed Borel measurable set $E\subset\mathbb [0,1]^n$, $|E|>0$, and I want to show that there exists some $\epsilon_0>0$ such that for all $\delta>0$ there exists a cube $C_\delta\subset [0,1]^n$ with $|C_\delta|\le\delta$ such that $$ \epsilon_0\le\frac{|C_\delta\cap E|}{|C_\delta|}\le 1-\epsilon_0. $$ This would hold true if there existed a point at which the metric density of $E$ was neither zero nor one. My question therefore is: Does there always exist such a point? And if not, how else can I prove the claim above? A simple example is $E = [0,\tfrac 1 2]$ in $[0,1]$ (i.e., $n=1$). Then we can choose $C_\delta = (\tfrac 1 2-\tfrac\delta 2,\tfrac 1 2+\tfrac\delta 2)$.",,"['measure-theory', 'lebesgue-measure']"
