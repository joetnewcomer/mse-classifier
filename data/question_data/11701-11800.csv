,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,A function whose partial derivatives exist at a point but is not continuous,A function whose partial derivatives exist at a point but is not continuous,,"I am asked to determine whether or not a function can have all of its partial derivatives exist at a point but not be continuous at that point. I have tried to construct a counterexample but am unsure whether or not I have succeeded. Consider the following function: $$ f(x,y) = \left\{ \begin{array}{cc} x & y=0 \\ 0 & \text{otherwise} \end{array}\right. $$ Let $(x_0,y_0) \not= 0$ then we can compute the partials of $f$ at this point. Doing so is not difficult we just have to make sure we are careful about the partials with respect to $y$. $$ \begin{align*} f_x(x_0,y_0) &= \lim_{h\rightarrow 0} \frac{f(x_0+h,y_0)-f(x_0,y_0)}{h} \\  \text{if $y_0=0$} & \implies \lim_{h\rightarrow 0} \frac{x_0+h-x_0}{h} = 1 \\ \text{if $y_0\not=0$} &\implies \lim_{h\rightarrow 0} \frac{0}{h} = 0 \\ f_y(x_0,y_0) &= \lim_{h\rightarrow 0} \frac{f(x_0,y_0+h)-f(x_0,y_0)}{h} \\ \text{if $y_0=0$} &\implies \lim_{h\rightarrow 0}\frac{x_0-x_0}{h} = 0 \\ \text{if $y_0\not=0$} &\implies \lim_{h\rightarrow 0} \frac{0}h = 0 \end{align*} $$ In all of these cases the partials of $f$ exist, however it is clear that for $x_0\not=0$ we will have that $f$ is not continuous at $(x_0,0)$. Becuase along any path where $y\not=0$ we will have that the limit is $0$, but along the path $y=0$ we obtain the limit being $x_0$. So $f$ is not continuous, but its partials exist. Is this a valid construction? It felt kind of fishy, any advice would be appreciated.","I am asked to determine whether or not a function can have all of its partial derivatives exist at a point but not be continuous at that point. I have tried to construct a counterexample but am unsure whether or not I have succeeded. Consider the following function: $$ f(x,y) = \left\{ \begin{array}{cc} x & y=0 \\ 0 & \text{otherwise} \end{array}\right. $$ Let $(x_0,y_0) \not= 0$ then we can compute the partials of $f$ at this point. Doing so is not difficult we just have to make sure we are careful about the partials with respect to $y$. $$ \begin{align*} f_x(x_0,y_0) &= \lim_{h\rightarrow 0} \frac{f(x_0+h,y_0)-f(x_0,y_0)}{h} \\  \text{if $y_0=0$} & \implies \lim_{h\rightarrow 0} \frac{x_0+h-x_0}{h} = 1 \\ \text{if $y_0\not=0$} &\implies \lim_{h\rightarrow 0} \frac{0}{h} = 0 \\ f_y(x_0,y_0) &= \lim_{h\rightarrow 0} \frac{f(x_0,y_0+h)-f(x_0,y_0)}{h} \\ \text{if $y_0=0$} &\implies \lim_{h\rightarrow 0}\frac{x_0-x_0}{h} = 0 \\ \text{if $y_0\not=0$} &\implies \lim_{h\rightarrow 0} \frac{0}h = 0 \end{align*} $$ In all of these cases the partials of $f$ exist, however it is clear that for $x_0\not=0$ we will have that $f$ is not continuous at $(x_0,0)$. Becuase along any path where $y\not=0$ we will have that the limit is $0$, but along the path $y=0$ we obtain the limit being $x_0$. So $f$ is not continuous, but its partials exist. Is this a valid construction? It felt kind of fishy, any advice would be appreciated.",,"['calculus', 'limits', 'continuity']"
1,Why does the Hessian work?,Why does the Hessian work?,,"I am working through Leonard Susskind's The Theoretical Minimum (on physics, but it also includes some maths). In particular, there is an interlude for which he discusses partial differentiation. He discusses a surface, a function of two variable. Let $A=f(x,y)$ \begin{pmatrix}  \frac{\partial^2A}{\partial x^2} & \frac{\partial^2A}{\partial x \partial y} \\  \frac{\partial^2A}{\partial y \partial x} & \frac{\partial^2A}{\partial y^2} \end{pmatrix} I understand individually what the partial derivatives are doing (though shouldn't the second and third entries into the matrix be equivalent?). I can also accept that they can be arranged into a matrix. However, he then says If the determinant and the trace are positive, the point is a local minimum. If the determinant is positive and the trace negative, the point is a local maximum. If the determinant is negative, the point is a saddle point. I'm sure I could apply these rules, but why do these rules work?","I am working through Leonard Susskind's The Theoretical Minimum (on physics, but it also includes some maths). In particular, there is an interlude for which he discusses partial differentiation. He discusses a surface, a function of two variable. Let I understand individually what the partial derivatives are doing (though shouldn't the second and third entries into the matrix be equivalent?). I can also accept that they can be arranged into a matrix. However, he then says If the determinant and the trace are positive, the point is a local minimum. If the determinant is positive and the trace negative, the point is a local maximum. If the determinant is negative, the point is a saddle point. I'm sure I could apply these rules, but why do these rules work?","A=f(x,y) \begin{pmatrix}
 \frac{\partial^2A}{\partial x^2} & \frac{\partial^2A}{\partial x \partial y} \\
 \frac{\partial^2A}{\partial y \partial x} & \frac{\partial^2A}{\partial y^2}
\end{pmatrix}","['calculus', 'matrices', 'multivariable-calculus', 'hessian-matrix', 'scalar-fields']"
2,Finding the limit of $\frac{1-\cos x}{x^2}$,Finding the limit of,\frac{1-\cos x}{x^2},$$\lim _{x \to 0}{1-\cos x\over x^2}={2\sin^2\left(\frac{x}{2}\right)\over x^2}={\frac{2}{x^2}\cdot {\sin^2\left(\frac{x}{2}\right)\over \left(\frac{x}{2}\right)^2}}\cdot\left(\frac{x}{2}\right)^2$$ now $$\lim_{x \to 0}{\sin^2\left(\frac{x}{2}\right)\over \left(\frac{x}{2}\right)^2}=\left({\sin\left(\frac{x}{2}\right)\over \left(\frac{x}{2}\right)}\right)^2=1^2$$ So we have $$\frac{2}{x^2}\cdot \left(\frac{x}{2}\right)^2=\frac{2}{x^2}\cdot \left(\frac{x^2}{4}\right)=\frac{1}{2}$$ Are the moves right?,$$\lim _{x \to 0}{1-\cos x\over x^2}={2\sin^2\left(\frac{x}{2}\right)\over x^2}={\frac{2}{x^2}\cdot {\sin^2\left(\frac{x}{2}\right)\over \left(\frac{x}{2}\right)^2}}\cdot\left(\frac{x}{2}\right)^2$$ now $$\lim_{x \to 0}{\sin^2\left(\frac{x}{2}\right)\over \left(\frac{x}{2}\right)^2}=\left({\sin\left(\frac{x}{2}\right)\over \left(\frac{x}{2}\right)}\right)^2=1^2$$ So we have $$\frac{2}{x^2}\cdot \left(\frac{x}{2}\right)^2=\frac{2}{x^2}\cdot \left(\frac{x^2}{4}\right)=\frac{1}{2}$$ Are the moves right?,,"['calculus', 'limits']"
3,Beautiful Indefinite Integrals. [closed],Beautiful Indefinite Integrals. [closed],,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 10 years ago . Improve this question These are some of the integrals with beautiful solutions I came across- $$\int \frac{x^2}{(x\sin x+\cos x)^2} dx$$ $$\int\frac {1}{\sin^3x+\cos^3x} dx$$ $$\int \frac{1}{x^4+1}dx$$ I'd love if you share some of the ones you came across.,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 10 years ago . Improve this question These are some of the integrals with beautiful solutions I came across- $$\int \frac{x^2}{(x\sin x+\cos x)^2} dx$$ $$\int\frac {1}{\sin^3x+\cos^3x} dx$$ $$\int \frac{1}{x^4+1}dx$$ I'd love if you share some of the ones you came across.,,"['calculus', 'integration', 'soft-question', 'indefinite-integrals']"
4,Does $\sum \limits_{n=1}^\infty\frac{\sin n}{n}(1+\frac{1}{2}+\cdots+\frac{1}{n})$ converge (absolutely)?,Does  converge (absolutely)?,\sum \limits_{n=1}^\infty\frac{\sin n}{n}(1+\frac{1}{2}+\cdots+\frac{1}{n}),"I've had no luck with this one. None of the convergence tests pop into mind. I tried looking at it in this form $\sum \sin n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}$ and apply Dirichlets test. I know that $\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n} \to 0$ but not sure if it's decreasing. Regarding absolute convergence, I tried: $$|\sin n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}|\geq \sin^2 n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}=$$ $$=\frac{1}{2}\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}-\frac{1}{2}\cos 2n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}$$ But again I'm stuck with $\cos 2n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}$. Assuming it converges then I've shown that $\sum \sin n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}$ doesn't converge absolutely.","I've had no luck with this one. None of the convergence tests pop into mind. I tried looking at it in this form $\sum \sin n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}$ and apply Dirichlets test. I know that $\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n} \to 0$ but not sure if it's decreasing. Regarding absolute convergence, I tried: $$|\sin n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}|\geq \sin^2 n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}=$$ $$=\frac{1}{2}\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}-\frac{1}{2}\cos 2n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}$$ But again I'm stuck with $\cos 2n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}$. Assuming it converges then I've shown that $\sum \sin n\frac{1+\frac{1}{2}+\cdots+\frac{1}{n}}{n}$ doesn't converge absolutely.",,"['calculus', 'sequences-and-series']"
5,Evaluating $\displaystyle\int_0^1\frac{\sqrt{1-y^2}}{1+y^2}dy$ without trig substitution,Evaluating  without trig substitution,\displaystyle\int_0^1\frac{\sqrt{1-y^2}}{1+y^2}dy,"A problem in our calculus text requires the evaluation of $\displaystyle\int_0^1\frac{\sqrt{1-y^2}}{1+y^2}dy$, and I have evaluated it by substituting $y=\sin\theta$ (or $y=\tanh u$) and then using another substitution and partial fractions; but I would like to find out if there is a simpler way to find this integral that does not involve trig substitution (or hyperbolic substitution). (I know some MSE people dislike this type of question, so I apologize in advance.)","A problem in our calculus text requires the evaluation of $\displaystyle\int_0^1\frac{\sqrt{1-y^2}}{1+y^2}dy$, and I have evaluated it by substituting $y=\sin\theta$ (or $y=\tanh u$) and then using another substitution and partial fractions; but I would like to find out if there is a simpler way to find this integral that does not involve trig substitution (or hyperbolic substitution). (I know some MSE people dislike this type of question, so I apologize in advance.)",,"['calculus', 'integration', 'definite-integrals']"
6,Derivative of a determinant whose entries are functions,Derivative of a determinant whose entries are functions,,"I do not understand a remark in Adams' Calculus (page 628 $7^{th}$ edition). This remark is about the derivative of a determinant whose entries are functions as quoted below. Since every term in the expansion of a determinant of any order is a product involving one element from each row, the general product rule implies that the derivative of an $n\times n$ determinant whose elements are functions will be the sum of $n$ such $n\times n$ determinants, each with the elements of one of the rows differentiated. For the $3\times 3$ case we have $$\frac{d}{dt}\begin{vmatrix}   a_{11}(t) & a_{12}(t) & a_{13}(t) \\   a_{21}(t) & a_{22}(t) & a_{23}(t) \\   a_{31}(t) & a_{32}(t) & a_{33}(t)   \end{vmatrix}=\begin{vmatrix}   a'_{11}(t) & a'_{12}(t) & a'_{13}(t) \\   a_{21}(t) & a_{22}(t) & a_{23}(t) \\   a_{31}(t) & a_{32}(t) & a_{33}(t)   \end{vmatrix}+\begin{vmatrix}   a_{11}(t) & a_{12}(t) & a_{13}(t) \\   a'_{21}(t) & a'_{22}(t) & a'_{23}(t) \\   a_{31}(t) & a_{32}(t) & a_{33}(t)   \end{vmatrix}+\begin{vmatrix}   a_{11}(t) & a_{12}(t) & a_{13}(t) \\   a_{21}(t) & a_{22}(t) & a_{23}(t) \\   a'_{31}(t) & a'_{32}(t) & a'_{33}(t)   \end{vmatrix}.$$ It is not difficult to check this equality by simply expanding both sides. However, the remark sounds like using some clever trick to get this result. Can anyone explain it to me, please? Thank you!","I do not understand a remark in Adams' Calculus (page 628 edition). This remark is about the derivative of a determinant whose entries are functions as quoted below. Since every term in the expansion of a determinant of any order is a product involving one element from each row, the general product rule implies that the derivative of an determinant whose elements are functions will be the sum of such determinants, each with the elements of one of the rows differentiated. For the case we have It is not difficult to check this equality by simply expanding both sides. However, the remark sounds like using some clever trick to get this result. Can anyone explain it to me, please? Thank you!","7^{th} n\times n n n\times n 3\times 3 \frac{d}{dt}\begin{vmatrix}
  a_{11}(t) & a_{12}(t) & a_{13}(t) \\
  a_{21}(t) & a_{22}(t) & a_{23}(t) \\
  a_{31}(t) & a_{32}(t) & a_{33}(t)
  \end{vmatrix}=\begin{vmatrix}
  a'_{11}(t) & a'_{12}(t) & a'_{13}(t) \\
  a_{21}(t) & a_{22}(t) & a_{23}(t) \\
  a_{31}(t) & a_{32}(t) & a_{33}(t)
  \end{vmatrix}+\begin{vmatrix}
  a_{11}(t) & a_{12}(t) & a_{13}(t) \\
  a'_{21}(t) & a'_{22}(t) & a'_{23}(t) \\
  a_{31}(t) & a_{32}(t) & a_{33}(t)
  \end{vmatrix}+\begin{vmatrix}
  a_{11}(t) & a_{12}(t) & a_{13}(t) \\
  a_{21}(t) & a_{22}(t) & a_{23}(t) \\
  a'_{31}(t) & a'_{32}(t) & a'_{33}(t)
  \end{vmatrix}.","['calculus', 'matrices', 'derivatives', 'determinant', 'self-learning']"
7,How to prove that $f(f(x))=-x$ implies that $f$ is not continuous? [duplicate],How to prove that  implies that  is not continuous? [duplicate],f(f(x))=-x f,"This question already has answers here : Find a real function $f:\mathbb{R}\to\mathbb{R}$ such that $f(f(x)) = -x$? (7 answers) Closed 10 years ago . I am trying to prove that: Given an $f:\mathbb{R} \rightarrow \mathbb{R}$, if $f(f(x))=-x$ then  $f$ is not continuous? any help? Thank you!","This question already has answers here : Find a real function $f:\mathbb{R}\to\mathbb{R}$ such that $f(f(x)) = -x$? (7 answers) Closed 10 years ago . I am trying to prove that: Given an $f:\mathbb{R} \rightarrow \mathbb{R}$, if $f(f(x))=-x$ then  $f$ is not continuous? any help? Thank you!",,"['calculus', 'functional-equations']"
8,Computing the primitive $\int\frac{1}{1+x^n} dx$,Computing the primitive,\int\frac{1}{1+x^n} dx,"Well, this might be a really simple one. But still... What will be the soln. to --- \begin{aligned} \int\frac{1}{1+x^n} dx \end{aligned} Is substituting \begin{aligned} 1+x^n \end{aligned} by tan z the correct step? Thanks for the Help.","Well, this might be a really simple one. But still... What will be the soln. to --- \begin{aligned} \int\frac{1}{1+x^n} dx \end{aligned} Is substituting \begin{aligned} 1+x^n \end{aligned} by tan z the correct step? Thanks for the Help.",,"['calculus', 'integration', 'indefinite-integrals']"
9,Integral $\int_{-\infty}^{\infty}\frac{\cos(s \arctan(ax))}{(1+x^2)(1+a^2x^2)^{s/2}}dx$,Integral,\int_{-\infty}^{\infty}\frac{\cos(s \arctan(ax))}{(1+x^2)(1+a^2x^2)^{s/2}}dx,"Prove that: $$ \int_{-\infty}^{\infty}{\cos\left(\vphantom{\Large A} s\ \arctan\left(\vphantom{\large A}ax\right)\right)\over \left(1 + x^{2}\right)\left(1 + a^{2}x^{2}\right)^{s/2}}\,{\rm d}x ={\pi \over \left(1 + a\right)^{s}}$$ where $a,s \in \mathbb{R}^{+}$. This looks difficult. What would be a good start? Can we use the Residue Theorem?","Prove that: $$ \int_{-\infty}^{\infty}{\cos\left(\vphantom{\Large A} s\ \arctan\left(\vphantom{\large A}ax\right)\right)\over \left(1 + x^{2}\right)\left(1 + a^{2}x^{2}\right)^{s/2}}\,{\rm d}x ={\pi \over \left(1 + a\right)^{s}}$$ where $a,s \in \mathbb{R}^{+}$. This looks difficult. What would be a good start? Can we use the Residue Theorem?",,"['calculus', 'complex-analysis', 'integration', 'definite-integrals', 'improper-integrals']"
10,When are definite integrals undefined?,When are definite integrals undefined?,,"We have $$\int_{-1}^{1} \dfrac{1}{x} \, dx$$ as undefined and then we have $$\int^1_{-1} f(x)\delta(x) = f(0)$$ assuming $f(x)$ is continuous everywhere and $$\delta(x) = \begin{cases} 0 & x\ne 0,  \\ \infty & x = 0. \end{cases}$$ In both cases the integrand is infinite for $x = 0$, then why second integral is not undefined?","We have $$\int_{-1}^{1} \dfrac{1}{x} \, dx$$ as undefined and then we have $$\int^1_{-1} f(x)\delta(x) = f(0)$$ assuming $f(x)$ is continuous everywhere and $$\delta(x) = \begin{cases} 0 & x\ne 0,  \\ \infty & x = 0. \end{cases}$$ In both cases the integrand is infinite for $x = 0$, then why second integral is not undefined?",,"['calculus', 'definite-integrals', 'dirac-delta']"
11,Why is there only one term on the RHS of this chain rule with partial derivatives?,Why is there only one term on the RHS of this chain rule with partial derivatives?,,"I know that if $u=u(s,t)$ and $s=s(x,y)$ and $t=t(x,y)$ then the chain rule is $$\begin{align}\color{blue}{\fbox{$\frac{\partial u}{\partial x}=\frac{\partial u}{\partial s}\times \frac{\partial s}{\partial x}+\frac{\partial u}{\partial t}\times \frac{\partial t}{\partial x}$}}\color{#F80}{\tag{A}}\end{align}$$ A short extract from my book tells me that: If $u=(x^2+2y)^2 + 4$ and $p=x^2 + 2y$ then $u=p^2 + 4$ therefore $$\frac{\partial u}{\partial x}=\frac{\partial u}{\partial p}\times \frac{\partial p}{\partial x}\tag{1}$$ as $u=u(x,y)$ and $p=p(x,y)$ The book mentions no origin of equation $(1)$ and unlike $\color{#F80}{\rm{(A)}}$ is has only one term on the RHS; So I would like to know how it was formed. Is $(1)$ simply equivalent to $\color{#F80}{\rm{(A)}}$ but with the last term missing? Or is there more to it than that? Many thanks, BLAZE.","I know that if $u=u(s,t)$ and $s=s(x,y)$ and $t=t(x,y)$ then the chain rule is $$\begin{align}\color{blue}{\fbox{$\frac{\partial u}{\partial x}=\frac{\partial u}{\partial s}\times \frac{\partial s}{\partial x}+\frac{\partial u}{\partial t}\times \frac{\partial t}{\partial x}$}}\color{#F80}{\tag{A}}\end{align}$$ A short extract from my book tells me that: If $u=(x^2+2y)^2 + 4$ and $p=x^2 + 2y$ then $u=p^2 + 4$ therefore $$\frac{\partial u}{\partial x}=\frac{\partial u}{\partial p}\times \frac{\partial p}{\partial x}\tag{1}$$ as $u=u(x,y)$ and $p=p(x,y)$ The book mentions no origin of equation $(1)$ and unlike $\color{#F80}{\rm{(A)}}$ is has only one term on the RHS; So I would like to know how it was formed. Is $(1)$ simply equivalent to $\color{#F80}{\rm{(A)}}$ but with the last term missing? Or is there more to it than that? Many thanks, BLAZE.",,"['calculus', 'derivatives', 'partial-derivative', 'chain-rule']"
12,How do I evaluate $\int \frac{x+1}{(x^2+1) \sqrt{x^2-6x+1}} dx$?,How do I evaluate ?,\int \frac{x+1}{(x^2+1) \sqrt{x^2-6x+1}} dx,"I am trying to evaluate this indefinite integral: $$\int \frac{x+1}{(x^2+1) \sqrt{x^2-6x+1}} dx$$ What I tried Substitution $u = \arctan(x)$ . However, no luck after this Find substitutions to convert $x^2 - 6x + 1$ into $(a + bu)^2$ or $a - (b + cu)^2$ , however I could not find any Converted $x^2 - 6x + 1$ into $(x-3)^2 - 8$ and used the derivative of $\sec^{-1}{(x)}$ but not any luck after that as well. I suspect that it has a real solution, so the solution from wolfram alfa is not what I am looking for. Any help/solutions would be very much appreciated!","I am trying to evaluate this indefinite integral: What I tried Substitution . However, no luck after this Find substitutions to convert into or , however I could not find any Converted into and used the derivative of but not any luck after that as well. I suspect that it has a real solution, so the solution from wolfram alfa is not what I am looking for. Any help/solutions would be very much appreciated!",\int \frac{x+1}{(x^2+1) \sqrt{x^2-6x+1}} dx u = \arctan(x) x^2 - 6x + 1 (a + bu)^2 a - (b + cu)^2 x^2 - 6x + 1 (x-3)^2 - 8 \sec^{-1}{(x)},"['calculus', 'integration', 'indefinite-integrals']"
13,Elementary proof for $\lim\limits_{n \to\infty}\frac{n!e^n}{n^n} = +\infty$,Elementary proof for,\lim\limits_{n \to\infty}\frac{n!e^n}{n^n} = +\infty,"As seen in this question, the series $\sum\limits_{n=1}^{\infty} \dfrac{n!e^n}{n^n}$ diverges. (One way to see this is by noting that the terms of the sum are greater than $1$ and, therefore, don't converge to zero.) However, more is true: not only are the terms greater than $1$, they blow up to $+\infty$! To see this, one can apply Stirling's approximation and get $\dfrac{n!e^n}{n^n} \sim \sqrt{2\pi n}$. My question is: is there an elementary proof for $\lim_{n \to\infty}\dfrac{n!e^n}{n^n} = +\infty$? The reason I'm asking this is that I'm taking a Calculus course and I was assigned the exercise of proving the divergence of the series above and I would feel more satisfied if I could prove that its terms go to $+\infty$ (as opposed to merely proving the terms are greater than $1$.) Obviously, things like Stirling's approximation are outside the scope of the course, so I can't really use them. (To be clear, you can use anything one learns in $4$ semesters of standard Calculus courses. I hope this restriction is not too obscure.)","As seen in this question, the series $\sum\limits_{n=1}^{\infty} \dfrac{n!e^n}{n^n}$ diverges. (One way to see this is by noting that the terms of the sum are greater than $1$ and, therefore, don't converge to zero.) However, more is true: not only are the terms greater than $1$, they blow up to $+\infty$! To see this, one can apply Stirling's approximation and get $\dfrac{n!e^n}{n^n} \sim \sqrt{2\pi n}$. My question is: is there an elementary proof for $\lim_{n \to\infty}\dfrac{n!e^n}{n^n} = +\infty$? The reason I'm asking this is that I'm taking a Calculus course and I was assigned the exercise of proving the divergence of the series above and I would feel more satisfied if I could prove that its terms go to $+\infty$ (as opposed to merely proving the terms are greater than $1$.) Obviously, things like Stirling's approximation are outside the scope of the course, so I can't really use them. (To be clear, you can use anything one learns in $4$ semesters of standard Calculus courses. I hope this restriction is not too obscure.)",,"['calculus', 'sequences-and-series', 'limits']"
14,Finding the value of $\beta(5)$ via a definite integral,Finding the value of  via a definite integral,\beta(5),"I was trying to compute the integral: $$ I = \int_0^1 \frac{(\operatorname{ln}x)^4}{1+x^2} dx$$ This is not a very difficult integral to evaluate if one knows the standard procedure used in evaluating such types of integral. I substituted $-\operatorname{ln}x = t$ and the integral becomes: $$ I = \int_0^{\infty} \frac{t^4 \cdot e^{-t}}{1+e^{-2t}} dt$$ $$ I = \int_0^{\infty} t^4 \cdot e^{-t} \cdot \sum_{n=0}^{\infty} (-1)^n \cdot e^{-2nt} dt$$ $$ I = \sum_{n=0}^{\infty} (-1)^n \cdot \int_0^{\infty} t^4 \cdot e^{-(2n+1)t} dt$$ $$ I = \sum_{n=0}^{\infty} (-1)^n \cdot \frac{(4!)}{(2n+1)^5} = 24\beta(5)$$ When I checked the value of $I$ in WolframAlpha, it suggested that it is equal to $\frac{5 \pi^5}{64}$ . So that must mean $$ \beta(5) = \frac{5 \pi^5}{24 \cdot 64} = \frac{5 \pi^5}{1536}$$ Which is indeed true. What I want to know is - Is there any other way to compute $\beta(5)$ , like how we compute $\zeta(2)$ ? Note that the $\beta$ function in this question refers to the Dirichlet beta function , not to be confused with the Eulerian Beta function.","I was trying to compute the integral: This is not a very difficult integral to evaluate if one knows the standard procedure used in evaluating such types of integral. I substituted and the integral becomes: When I checked the value of in WolframAlpha, it suggested that it is equal to . So that must mean Which is indeed true. What I want to know is - Is there any other way to compute , like how we compute ? Note that the function in this question refers to the Dirichlet beta function , not to be confused with the Eulerian Beta function.", I = \int_0^1 \frac{(\operatorname{ln}x)^4}{1+x^2} dx -\operatorname{ln}x = t  I = \int_0^{\infty} \frac{t^4 \cdot e^{-t}}{1+e^{-2t}} dt  I = \int_0^{\infty} t^4 \cdot e^{-t} \cdot \sum_{n=0}^{\infty} (-1)^n \cdot e^{-2nt} dt  I = \sum_{n=0}^{\infty} (-1)^n \cdot \int_0^{\infty} t^4 \cdot e^{-(2n+1)t} dt  I = \sum_{n=0}^{\infty} (-1)^n \cdot \frac{(4!)}{(2n+1)^5} = 24\beta(5) I \frac{5 \pi^5}{64}  \beta(5) = \frac{5 \pi^5}{24 \cdot 64} = \frac{5 \pi^5}{1536} \beta(5) \zeta(2) \beta,"['calculus', 'integration']"
15,What is the relation between analytical Fourier transform and DFT?,What is the relation between analytical Fourier transform and DFT?,,First of all let me state that I searched for this topic before asking. My question is as follows we have the Analytical Fourier Transform represented with an integral and Discrete Fourier Transform represented with a summation usually computed by a numerical software. My question is that although the relationship is exact at the sampled data points assuming they are equally spaced(say they are equally spaced in time) how can we say about the accuracy of the transform that is if we transform into frequency-domain both with DFT and AFT how will the coefficients for a particular frequency be related? Are they going to be the similar or the same under some conditions?,First of all let me state that I searched for this topic before asking. My question is as follows we have the Analytical Fourier Transform represented with an integral and Discrete Fourier Transform represented with a summation usually computed by a numerical software. My question is that although the relationship is exact at the sampled data points assuming they are equally spaced(say they are equally spaced in time) how can we say about the accuracy of the transform that is if we transform into frequency-domain both with DFT and AFT how will the coefficients for a particular frequency be related? Are they going to be the similar or the same under some conditions?,,"['calculus', 'numerical-methods', 'fourier-analysis']"
16,Differentiating with respect to the limit of integration,Differentiating with respect to the limit of integration,,"I'm confused about problems involving differentiation with respect to the limit of an integral, I just want to check that my understanding is correct. For example, are the following statements correct? : $$ \frac{d}{dx}\int_0^xs^2ds=x^2 $$ $$ \frac{d}{ds}\int_0^xs^2ds=\int_0^x2s~ds $$ and by the product rule: $$ \frac{d}{dx}\int_0^x~x~s^2ds=\int_0^xs^2~ds+x^3 $$","I'm confused about problems involving differentiation with respect to the limit of an integral, I just want to check that my understanding is correct. For example, are the following statements correct? : $$ \frac{d}{dx}\int_0^xs^2ds=x^2 $$ $$ \frac{d}{ds}\int_0^xs^2ds=\int_0^x2s~ds $$ and by the product rule: $$ \frac{d}{dx}\int_0^x~x~s^2ds=\int_0^xs^2~ds+x^3 $$",,"['calculus', 'integration', 'derivatives']"
17,How to show $ \int_{-\infty}^{\infty} \frac{e^{-(x+1)^2}}{1+e^{-x}}\mathrm{d}x = \frac{\left(2\sqrt[4]{e} -1 \right)\sqrt{\pi}}{2e}$?,How to show ?, \int_{-\infty}^{\infty} \frac{e^{-(x+1)^2}}{1+e^{-x}}\mathrm{d}x = \frac{\left(2\sqrt[4]{e} -1 \right)\sqrt{\pi}}{2e},"I was recently looking at this post where the following formula is shown: $$ \int_{-\infty}^{\infty} \frac{E(x)}{1+\mathcal{E}(x)^{O(x)}}\mathrm{d}x= \int_0^{\infty} E(x) \mathrm{d}x $$ where $E(x), \mathcal{E}(x)$ are even functions and $O(x)$ is an odd function. One nice application of this formula would be the integral $$ \int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+e^{-x}}\mathrm{d}x = \frac{\sqrt{\pi}}{2} $$ where the problem reduces to the evaluation of the Gaussian integral. I then wondered what would happen if I made slight alterations to the above integral, like changing $x^2\to (x+1)^2$ . WA evaluates said integral as: $$  \int_{-\infty}^{\infty} \frac{e^{-(x+1)^2}}{1+e^{-x}}\mathrm{d}x = \frac{\left(2\sqrt[4]{e} -1 \right)\sqrt{\pi}}{2e} $$ The even/odd formula can't be applied since the $+1$ makes the function not even anymore. Recalling that $\int^\infty_{-\infty} e^{-(ax^2 + bx+c)}\mathrm{d}x=\sqrt{\frac{\pi}{a}}e^{\frac{b^2}{4a}-c} $ I attempted to evaluate the integral using geometric series $$ \int_{-\infty}^{\infty} \frac{e^{-(x+1)^2}}{1+e^{-x}}\mathrm{d}x =  \sum_{n\ge 0}(-1)^n \int_{-\infty}^{\infty}e^{-(x^2+(n+2)x+1)}\, \mathrm{d}x = \frac{\sqrt{\pi}}{e}  \sum_{n\ge 0}(-1)^n e^{\frac{(n+2)^2}{4}} $$ but the resulting series is divergent, so this method won't work. Does anyone have any ideas on how to evaluate this integral? Thank you!","I was recently looking at this post where the following formula is shown: where are even functions and is an odd function. One nice application of this formula would be the integral where the problem reduces to the evaluation of the Gaussian integral. I then wondered what would happen if I made slight alterations to the above integral, like changing . WA evaluates said integral as: The even/odd formula can't be applied since the makes the function not even anymore. Recalling that I attempted to evaluate the integral using geometric series but the resulting series is divergent, so this method won't work. Does anyone have any ideas on how to evaluate this integral? Thank you!","
\int_{-\infty}^{\infty} \frac{E(x)}{1+\mathcal{E}(x)^{O(x)}}\mathrm{d}x= \int_0^{\infty} E(x) \mathrm{d}x
 E(x), \mathcal{E}(x) O(x) 
\int_{-\infty}^{\infty} \frac{e^{-x^2}}{1+e^{-x}}\mathrm{d}x = \frac{\sqrt{\pi}}{2}
 x^2\to (x+1)^2 
 \int_{-\infty}^{\infty} \frac{e^{-(x+1)^2}}{1+e^{-x}}\mathrm{d}x = \frac{\left(2\sqrt[4]{e} -1 \right)\sqrt{\pi}}{2e}
 +1 \int^\infty_{-\infty} e^{-(ax^2 + bx+c)}\mathrm{d}x=\sqrt{\frac{\pi}{a}}e^{\frac{b^2}{4a}-c}
 
\int_{-\infty}^{\infty} \frac{e^{-(x+1)^2}}{1+e^{-x}}\mathrm{d}x =  \sum_{n\ge 0}(-1)^n \int_{-\infty}^{\infty}e^{-(x^2+(n+2)x+1)}\, \mathrm{d}x = \frac{\sqrt{\pi}}{e}  \sum_{n\ge 0}(-1)^n e^{\frac{(n+2)^2}{4}}
","['calculus', 'integration', 'definite-integrals', 'closed-form', 'gaussian-integral']"
18,Evaluating $\int_{0}^{\infty} \left[\left(\frac{2015}{2015+x}+\cdots +\frac{2}{2+x}+\frac{1}{1+x}-x\right)^{2016}+1 \right] ^{-1}\mathrm{d}x$,Evaluating,\int_{0}^{\infty} \left[\left(\frac{2015}{2015+x}+\cdots +\frac{2}{2+x}+\frac{1}{1+x}-x\right)^{2016}+1 \right] ^{-1}\mathrm{d}x,"I need to evaluate $$\int_{0}^{\infty} \left[\left(\frac{2015}{2015+x}+\cdots  +\frac{2}{2+x}+\frac{1}{1+x}-x\right)^{2016}+1 \right] ^{-1}\mathrm{d}x $$ I've been told that the way forward is showing that the integral is the same as $$\int_0^{\infty} (x^{2016} + 1)^{-1} \, \mathrm{d}x$$ i.e: that the weird sum of fractions doesn't affect the integral. I've tried $$\sum_{n=1}^{2015} \frac{n}{n+x} = \sum_{n=1}^{2015} \left(1 - \frac{x}{n+x}\right) = 2015 - \sum_{n=1}^{2015} \frac{x}{n+x}$$ but it's getting me nowhere.","I need to evaluate $$\int_{0}^{\infty} \left[\left(\frac{2015}{2015+x}+\cdots  +\frac{2}{2+x}+\frac{1}{1+x}-x\right)^{2016}+1 \right] ^{-1}\mathrm{d}x $$ I've been told that the way forward is showing that the integral is the same as $$\int_0^{\infty} (x^{2016} + 1)^{-1} \, \mathrm{d}x$$ i.e: that the weird sum of fractions doesn't affect the integral. I've tried $$\sum_{n=1}^{2015} \frac{n}{n+x} = \sum_{n=1}^{2015} \left(1 - \frac{x}{n+x}\right) = 2015 - \sum_{n=1}^{2015} \frac{x}{n+x}$$ but it's getting me nowhere.",,"['calculus', 'integration', 'definite-integrals', 'recreational-mathematics']"
19,Proof that the limit of the square root is the square root of the limit,Proof that the limit of the square root is the square root of the limit,,I'm trying to prove that: $$\lim_{n\rightarrow\infty} \sqrt{a_n} = \sqrt{\lim_{n\rightarrow\infty} a_n}$$ Given $a_n > 0$ for all $n$. My initial idea was to start with the definition of limit (assuming $\lim_{n\rightarrow\infty} a_n = l$): $$|\sqrt{a_n} - \sqrt{l}| = |\frac{(\sqrt{a_n} - \sqrt{l}) (\sqrt{a_n} + \sqrt{l})}{(\sqrt{a_n} + \sqrt{l})}| = |\frac{a_n - l}{(\sqrt{a_n} + \sqrt{l})}|$$ The problem is that $\sqrt{a_n} + \sqrt{l}$ could be less than $1$. And therefore I can't continue the proof using this approach. Edit: forgot to mention that $a_n$ converges is another hypothesis.,I'm trying to prove that: $$\lim_{n\rightarrow\infty} \sqrt{a_n} = \sqrt{\lim_{n\rightarrow\infty} a_n}$$ Given $a_n > 0$ for all $n$. My initial idea was to start with the definition of limit (assuming $\lim_{n\rightarrow\infty} a_n = l$): $$|\sqrt{a_n} - \sqrt{l}| = |\frac{(\sqrt{a_n} - \sqrt{l}) (\sqrt{a_n} + \sqrt{l})}{(\sqrt{a_n} + \sqrt{l})}| = |\frac{a_n - l}{(\sqrt{a_n} + \sqrt{l})}|$$ The problem is that $\sqrt{a_n} + \sqrt{l}$ could be less than $1$. And therefore I can't continue the proof using this approach. Edit: forgot to mention that $a_n$ converges is another hypothesis.,,"['calculus', 'sequences-and-series', 'analysis']"
20,Solving $\int_0^\infty\dfrac{dx}{(1+x^n)^n}=1$,Solving,\int_0^\infty\dfrac{dx}{(1+x^n)^n}=1,"A friend has challenged me to find the value of $n$ such that $\displaystyle\int_0^\infty\dfrac{dx}{(1+x^n)^n}=1.$ I know that the value of $n$ is equal to $\phi,$ but I do not know how to prove this.","A friend has challenged me to find the value of $n$ such that $\displaystyle\int_0^\infty\dfrac{dx}{(1+x^n)^n}=1.$ I know that the value of $n$ is equal to $\phi,$ but I do not know how to prove this.",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
21,Evaluate $\int \frac{\sin ^3(\theta/2)}{\cos(\theta/2)\sqrt{\cos^3\theta+\cos^2\theta+\cos \theta}}d\theta$,Evaluate,\int \frac{\sin ^3(\theta/2)}{\cos(\theta/2)\sqrt{\cos^3\theta+\cos^2\theta+\cos \theta}}d\theta,"I came about the following practice problem in a book of integration:- $Q.$ Evaluate $$I=\int \frac{\sin ^3(\theta/2)}{\cos(\theta/2)\sqrt{\cos^3\theta+\cos^2\theta+\cos \theta}}d\theta$$ To do this, first I substituted $\cos(\theta/2)=u \implies \frac {-1}{2}\sin (\frac{\theta}2)\ d\theta=du \implies \sin^3 (\frac{\theta}2)d\theta=-2(1-u^2)\ du$. This gives $$\begin{align}I&=\int \frac{2(u^2-1)\ du}{u\sqrt{(2u^2-1)^3+(2u^2-1)^2+(2u^2-1)}}\\&=\frac 12\int \frac {(u^2-1)(4u\ du)}{u^2\sqrt{(2u^2-1)^3+(2u^2-1)^2+(2u^2-1)}}\end{align}$$ Now substitute $z=2u^2-1 \implies dz=4u\ du$. We have $u^2=\frac {z+1}2 \implies u^2-1=\frac {z-1}2$. Hence $$\begin{align}I&=\int \frac {{{z-1}\over2}\ dz}{(\frac {z+1}2)\sqrt{z^3+z^2+z}}\\&=\int \frac{(z-1)\ dz}{(z+1)\sqrt{z^3+z^2+z}}\\&=\int \left[\frac{1}{\sqrt{z^3+z^2+z}}-\frac2{(z+1)\sqrt{z^3+z^2+z}}\right]\ dz\end{align}$$ I don't know how to proceed further. Some hints would be appreciated. Is there any easier way to integrate the given expression? I also tried substituting $\tan (\theta/2)=u$, but it becomes even more messier than what I have shown here.","I came about the following practice problem in a book of integration:- $Q.$ Evaluate $$I=\int \frac{\sin ^3(\theta/2)}{\cos(\theta/2)\sqrt{\cos^3\theta+\cos^2\theta+\cos \theta}}d\theta$$ To do this, first I substituted $\cos(\theta/2)=u \implies \frac {-1}{2}\sin (\frac{\theta}2)\ d\theta=du \implies \sin^3 (\frac{\theta}2)d\theta=-2(1-u^2)\ du$. This gives $$\begin{align}I&=\int \frac{2(u^2-1)\ du}{u\sqrt{(2u^2-1)^3+(2u^2-1)^2+(2u^2-1)}}\\&=\frac 12\int \frac {(u^2-1)(4u\ du)}{u^2\sqrt{(2u^2-1)^3+(2u^2-1)^2+(2u^2-1)}}\end{align}$$ Now substitute $z=2u^2-1 \implies dz=4u\ du$. We have $u^2=\frac {z+1}2 \implies u^2-1=\frac {z-1}2$. Hence $$\begin{align}I&=\int \frac {{{z-1}\over2}\ dz}{(\frac {z+1}2)\sqrt{z^3+z^2+z}}\\&=\int \frac{(z-1)\ dz}{(z+1)\sqrt{z^3+z^2+z}}\\&=\int \left[\frac{1}{\sqrt{z^3+z^2+z}}-\frac2{(z+1)\sqrt{z^3+z^2+z}}\right]\ dz\end{align}$$ I don't know how to proceed further. Some hints would be appreciated. Is there any easier way to integrate the given expression? I also tried substituting $\tan (\theta/2)=u$, but it becomes even more messier than what I have shown here.",,"['calculus', 'integration', 'trigonometry']"
22,Hard integral to find,Hard integral to find,,"I've to find this integral for a project I'm working on and I've no idea how to proceed, can someone help me out? $$ \begin{align} & \int\left(\frac{1}{2}\left((\cos(2x)+1)\left(\frac{2\tanh^{-1}(x^2)} {\cos(2x)+1}+\cos(x)+\sin^2(x)\right)\right)\right)dx \\[10pt] = {} & \frac{1}{2}\int\left((\cos( 2x)+1)\left(\frac{2\tanh^{-1}(x^2)} {\cos(2x)+1}+\cos(x)+\sin^2(x)\right)\right)dx=\cdots \end{align} $$","I've to find this integral for a project I'm working on and I've no idea how to proceed, can someone help me out? $$ \begin{align} & \int\left(\frac{1}{2}\left((\cos(2x)+1)\left(\frac{2\tanh^{-1}(x^2)} {\cos(2x)+1}+\cos(x)+\sin^2(x)\right)\right)\right)dx \\[10pt] = {} & \frac{1}{2}\int\left((\cos( 2x)+1)\left(\frac{2\tanh^{-1}(x^2)} {\cos(2x)+1}+\cos(x)+\sin^2(x)\right)\right)dx=\cdots \end{align} $$",,['calculus']
23,Help me to finish calculating $\int_0^{\infty} \frac{1}{x^3-1}dx$,Help me to finish calculating,\int_0^{\infty} \frac{1}{x^3-1}dx,"$$\int_0^{\infty} \frac{1}{x^3-1}dx$$ What I did: $$\lim_{\epsilon\to0}\int_0^{1-\epsilon} \frac{1}{x^3-1}dx+\lim_{\epsilon\to0}\int_{1+\epsilon}^{\infty} \frac{1}{x^3-1}dx$$ $$\lim_{\epsilon\to0}\int_0^{1-\epsilon}\frac{1}{3(x-1)}-\frac{2x+1}{6(x^2+x+1)}-\frac{1}{2(x^2+x+1)}dx+\lim_{\epsilon\to0}\int_{1+\epsilon}^{\infty}\frac{1}{3(x-1)}-\frac{2x+1}{6(x^2+x+1)}-\frac{1}{2(x^2+x+1)}dx$$ $$\lim_{\epsilon\to0}\int_0^{1-\epsilon}\frac{1}{3(x-1)}-\frac{2x+1}{6(x^2+x+1)}-\frac{1}{2[(x+\frac{1}{2})^2+\frac{3}{4}]}dx+\lim_{\epsilon\to0}\int_{1+\epsilon}^{\infty}\frac{1}{3(x-1)}-\frac{2x+1}{6(x^2+x+1)}-\frac{1}{2[(x+\frac{1}{2})^2+\frac{3}{4}]}dx$$ $$[\frac{1}{3}ln(x-1)-\frac{1}{6}ln(x^2+x+1)-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{0}^{1-\epsilon}+[\frac{1}{3}ln(x-1)-\frac{1}{6}ln(x^2+x+1)-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{1+\epsilon}^{\infty}$$ $$[\frac{1}{6}(2ln(x-1)-ln(x^2+x+1))-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{0}^{1-\epsilon}+[\frac{1}{6}ln{2(x-1})-\frac{1}{6}ln(x^2+x+1)-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{1+\epsilon}^{\infty}$$ $$[\frac{1}{6}ln(\frac{(x-1)^2}{x^2+x+1})-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{0}^{1-\epsilon}+[\frac{1}{6}ln(\frac{(x-1)^2}{x^2+x+1})-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{1+\epsilon}^{\infty}$$ $$[\frac{1}{6}ln(\frac{x^2-2x+1}{x^2+x+1})-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{0}^{1-\epsilon}+[\frac{1}{6}ln(\frac{x^2-2x+1}{x^2+x+1})-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{1+\epsilon}^{\infty}$$ $$\lim_{\epsilon\to0}[\frac{1}{6}ln(\frac{(1-\epsilon)^2-2(1-\epsilon)+1}{(1-\epsilon)^2+1-\epsilon+1})-\frac{1}{\sqrt3}\arctan(\frac{2(1-\epsilon)+1}{\sqrt3})+\frac{1}{\sqrt3}\arctan(\frac{1}{\sqrt3})]+\lim_{\epsilon\to 0} [ \frac{1}{6}ln(\frac{(\infty)^2-2(\infty)+1}{(\infty)^2+(\infty)+1})+\cdots]$$ This is where my problem is, what is : $$ \frac{1}{6}ln(\frac{(\infty)^2-2(\infty)+1}{(\infty)^2+(\infty)+1})$$ ^^^ If I know past this, I know how to proceed. The only thing stopping me is this ^^^. Please help.","What I did: This is where my problem is, what is : ^^^ If I know past this, I know how to proceed. The only thing stopping me is this ^^^. Please help.",\int_0^{\infty} \frac{1}{x^3-1}dx \lim_{\epsilon\to0}\int_0^{1-\epsilon} \frac{1}{x^3-1}dx+\lim_{\epsilon\to0}\int_{1+\epsilon}^{\infty} \frac{1}{x^3-1}dx \lim_{\epsilon\to0}\int_0^{1-\epsilon}\frac{1}{3(x-1)}-\frac{2x+1}{6(x^2+x+1)}-\frac{1}{2(x^2+x+1)}dx+\lim_{\epsilon\to0}\int_{1+\epsilon}^{\infty}\frac{1}{3(x-1)}-\frac{2x+1}{6(x^2+x+1)}-\frac{1}{2(x^2+x+1)}dx \lim_{\epsilon\to0}\int_0^{1-\epsilon}\frac{1}{3(x-1)}-\frac{2x+1}{6(x^2+x+1)}-\frac{1}{2[(x+\frac{1}{2})^2+\frac{3}{4}]}dx+\lim_{\epsilon\to0}\int_{1+\epsilon}^{\infty}\frac{1}{3(x-1)}-\frac{2x+1}{6(x^2+x+1)}-\frac{1}{2[(x+\frac{1}{2})^2+\frac{3}{4}]}dx [\frac{1}{3}ln(x-1)-\frac{1}{6}ln(x^2+x+1)-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{0}^{1-\epsilon}+[\frac{1}{3}ln(x-1)-\frac{1}{6}ln(x^2+x+1)-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{1+\epsilon}^{\infty} [\frac{1}{6}(2ln(x-1)-ln(x^2+x+1))-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{0}^{1-\epsilon}+[\frac{1}{6}ln{2(x-1})-\frac{1}{6}ln(x^2+x+1)-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{1+\epsilon}^{\infty} [\frac{1}{6}ln(\frac{(x-1)^2}{x^2+x+1})-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{0}^{1-\epsilon}+[\frac{1}{6}ln(\frac{(x-1)^2}{x^2+x+1})-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{1+\epsilon}^{\infty} [\frac{1}{6}ln(\frac{x^2-2x+1}{x^2+x+1})-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{0}^{1-\epsilon}+[\frac{1}{6}ln(\frac{x^2-2x+1}{x^2+x+1})-\frac{1}{\sqrt3}\arctan(\frac{2x+1}{\sqrt3})]_{1+\epsilon}^{\infty} \lim_{\epsilon\to0}[\frac{1}{6}ln(\frac{(1-\epsilon)^2-2(1-\epsilon)+1}{(1-\epsilon)^2+1-\epsilon+1})-\frac{1}{\sqrt3}\arctan(\frac{2(1-\epsilon)+1}{\sqrt3})+\frac{1}{\sqrt3}\arctan(\frac{1}{\sqrt3})]+\lim_{\epsilon\to 0} [ \frac{1}{6}ln(\frac{(\infty)^2-2(\infty)+1}{(\infty)^2+(\infty)+1})+\cdots]  \frac{1}{6}ln(\frac{(\infty)^2-2(\infty)+1}{(\infty)^2+(\infty)+1}),"['calculus', 'integration', 'definite-integrals', 'cauchy-principal-value']"
24,Is there a geometrical definition of a tangent line?,Is there a geometrical definition of a tangent line?,,"Calculus books often give the ""secant through two points coming closer together"" description to give some intuition for tangent lines. They then say that the tangent line is what the curve ""looks like"" at that point, or that it's the ""best approximation"" to the curve at that point, and just take it for granted that (1) it's obvious what that means, and (2) that it's visually obvious that such statements are true. To be fair, it's true that (1) I can sort of see what they mean, and (2) yes, I do have some visual intuition that something like that is correct. But I can't put into words what exactly a tangent line is, all I have is either the formal definition or this unsatisfying vague sense that a tangent ""just touches the curve"". Is there a purely geometrical definition of a tangent line to a curve? Something without coordinates or functions, like an ancient Greek might have stated it. As an example, ""A line that passes through the curve but does not cut it"" is exactly the kind of thing I want, but of course it doesn't work for all curves at all points.","Calculus books often give the ""secant through two points coming closer together"" description to give some intuition for tangent lines. They then say that the tangent line is what the curve ""looks like"" at that point, or that it's the ""best approximation"" to the curve at that point, and just take it for granted that (1) it's obvious what that means, and (2) that it's visually obvious that such statements are true. To be fair, it's true that (1) I can sort of see what they mean, and (2) yes, I do have some visual intuition that something like that is correct. But I can't put into words what exactly a tangent line is, all I have is either the formal definition or this unsatisfying vague sense that a tangent ""just touches the curve"". Is there a purely geometrical definition of a tangent line to a curve? Something without coordinates or functions, like an ancient Greek might have stated it. As an example, ""A line that passes through the curve but does not cut it"" is exactly the kind of thing I want, but of course it doesn't work for all curves at all points.",,"['calculus', 'geometry']"
25,Integrating using Laplace Transforms,Integrating using Laplace Transforms,,$$\int_{0}^\infty {\cos(xt)\over 1+t^2}dt $$ I'm supposed to solve this using Laplace Transformations. I've been trying this since this morning but I haven't figured it out. Any pointers to push me in the right direction?,$$\int_{0}^\infty {\cos(xt)\over 1+t^2}dt $$ I'm supposed to solve this using Laplace Transformations. I've been trying this since this morning but I haven't figured it out. Any pointers to push me in the right direction?,,"['calculus', 'improper-integrals', 'laplace-transform']"
26,Parabola as a limit of sequence of function $f(x)=\sum_{k=-n}^{n} |x+k|$,Parabola as a limit of sequence of function,f(x)=\sum_{k=-n}^{n} |x+k|,"I was fooling around with the following expression: $|x-3|+|x-2|+|x-1|+|x|+|x+1|+|x+2|+|x+3|$ the graph looks something like this: similarly for y= $\sum_{i=-5}^{5} |x-i|$ Now if we increment by only 0.01(ie. $y= \sum_{i=-10}^{10} |x-0.01i|$ but vary i from  -10 to 10 we get: Now my question is , do these graphs $ approximately$ represent parabolas as the value of i gets larger and the increment (call it h) gets smaller? I think of something to do with reimann sums but my efforts till now have proved to be futile. Because this sequence of functions looks like parabolas to me. Or are they completely different like $cosh(x)$ ?Or maybe thereis no pattern at all and this is just a coincidence?","I was fooling around with the following expression: the graph looks something like this: similarly for y= Now if we increment by only 0.01(ie. but vary i from  -10 to 10 we get: Now my question is , do these graphs represent parabolas as the value of i gets larger and the increment (call it h) gets smaller? I think of something to do with reimann sums but my efforts till now have proved to be futile. Because this sequence of functions looks like parabolas to me. Or are they completely different like ?Or maybe thereis no pattern at all and this is just a coincidence?",|x-3|+|x-2|+|x-1|+|x|+|x+1|+|x+2|+|x+3| \sum_{i=-5}^{5} |x-i| y= \sum_{i=-10}^{10} |x-0.01i|  approximately cosh(x),"['calculus', 'limits', 'functions']"
27,How to evaluate $\int \frac{dx}{\sin(\ln(x))}$?,How to evaluate ?,\int \frac{dx}{\sin(\ln(x))},"I am wondering how to evaluate the indefinite integral $$\int \frac{dx}{\sin(\ln(x))} \quad (1)$$ Attempt 1 I tried using Weierstrass substitution. The Weierstrass substitution , (named after K.Weierstrass (1815)), is a substitution used in order to convert trigonometric functions rational expressions to polynomial rational expressions. Integrals of this type are usually easier to evaluate. This substitution is constructed by letting: $$t = \tan\left(\frac{x}{2}\right) \iff x = 2\arctan(t)  \iff dx = \frac{2}{t^2+1}$$ Using basic trigonometric identities it is easy to prove that: $$\cos x = \dfrac{1 - t^2}{1 +  t^2}$$ $$\sin x = \dfrac{2t}{1 + t^2}$$ But I couldn't express $\ln(x)$ in terms of $t$ . Attempt 2 I tried using integration by parts but I couldn't find a workaround, it gets more complicated, really fast. $$ \int \frac{dx}{\sin(\ln(x))} \ = x \sin(\ln(x)) - \int \frac{\cot \left(\ln \left(x\right)\right)}{x\sin \left(\ln \left(x\right)\right)} $$ Attempt 3 The most logical substitution I could think of. It doesn't seem to lead anywhere though. Let, $\ln(x) = u \iff dx = \, e^u du$ $$ (1) \iff \int \frac{dx}{\sin(\ln(x))} = \int \frac{e^u}{\sin(u)} du = \int \frac{(e^u)'}{\sin(u)} du = $$ $$ \frac{(e^u)'}{\sin(u)} - \int e^u \left(\frac{1}{\sin(u)}\right)' = \frac{(e^u)'}{\sin(u)} - \int e^u \frac{\cos(u)}{\sin^2(u)} =  ?$$ Attempt 4 A combination of attempts 1,2, 3. Let $\ln(x) = t$ then $dx = e^t dt$ , therefore, $$\int \frac{dx}{\sin(\ln(x))} dx = \int \frac{e^t }{\sin(t)}dt \quad (1)$$ Let's first evaluate $$ \int \frac{1\:}{\sin\left(t\right)}dt \quad (2)$$ Using the Weierstrass substitution $$ t = \arctan(\frac{x}{2})$$ it is easy to prove that $$ (2) = \int \frac{1\:}{\sin\left(t\right)}dt= \ln \left|\tan \left(\frac{t}{2}\right)\right|+C$$ Therefore, $$ (1) \iff I = \int e^x\left(\ln \:\left|\tan \:\left(\frac{t}{2}\right)\right|\right)'dt = e^x \ln \:\left|\tan \:\left(\frac{t}{2}\right)\right| - \int (e^x)' \ln \:\left|\tan \:\left(\frac{t}{2}\right)\right|dt = $$ $$  e^x \ln \:\left|\tan \:\left(\frac{t}{2}\right)\right| - \left( e^x \ln \:\left|\tan \:\left(\frac{t}{2}\right)\right|  - \int e^x \left(\ln \:\left|\tan \:\left(\frac{t}{2}\right)\right|\right)'dt \right) $$ $$ I = 0 + I \iff 0=0$$ Tautology. No answer here. Attempt 5 Ask a question on MathExchange: Any ideas? Note: A complex-plane solution was proposed in the comments, but I am evaluating this on $\mathbb{R}$","I am wondering how to evaluate the indefinite integral Attempt 1 I tried using Weierstrass substitution. The Weierstrass substitution , (named after K.Weierstrass (1815)), is a substitution used in order to convert trigonometric functions rational expressions to polynomial rational expressions. Integrals of this type are usually easier to evaluate. This substitution is constructed by letting: Using basic trigonometric identities it is easy to prove that: But I couldn't express in terms of . Attempt 2 I tried using integration by parts but I couldn't find a workaround, it gets more complicated, really fast. Attempt 3 The most logical substitution I could think of. It doesn't seem to lead anywhere though. Let, Attempt 4 A combination of attempts 1,2, 3. Let then , therefore, Let's first evaluate Using the Weierstrass substitution it is easy to prove that Therefore, Tautology. No answer here. Attempt 5 Ask a question on MathExchange: Any ideas? Note: A complex-plane solution was proposed in the comments, but I am evaluating this on","\int \frac{dx}{\sin(\ln(x))} \quad (1) t = \tan\left(\frac{x}{2}\right) \iff x = 2\arctan(t)  \iff dx = \frac{2}{t^2+1} \cos x = \dfrac{1 - t^2}{1 +  t^2} \sin x = \dfrac{2t}{1 + t^2} \ln(x) t  \int \frac{dx}{\sin(\ln(x))} \ = x \sin(\ln(x)) - \int \frac{\cot \left(\ln \left(x\right)\right)}{x\sin \left(\ln \left(x\right)\right)}  \ln(x) = u \iff dx = \, e^u du  (1) \iff \int \frac{dx}{\sin(\ln(x))} = \int \frac{e^u}{\sin(u)} du = \int \frac{(e^u)'}{\sin(u)} du =   \frac{(e^u)'}{\sin(u)} - \int e^u \left(\frac{1}{\sin(u)}\right)' = \frac{(e^u)'}{\sin(u)} - \int e^u \frac{\cos(u)}{\sin^2(u)} =  ? \ln(x) = t dx = e^t dt \int \frac{dx}{\sin(\ln(x))} dx = \int \frac{e^t }{\sin(t)}dt \quad (1)  \int \frac{1\:}{\sin\left(t\right)}dt \quad (2)  t = \arctan(\frac{x}{2})  (2) = \int \frac{1\:}{\sin\left(t\right)}dt= \ln \left|\tan \left(\frac{t}{2}\right)\right|+C  (1) \iff I = \int e^x\left(\ln \:\left|\tan \:\left(\frac{t}{2}\right)\right|\right)'dt = e^x \ln \:\left|\tan \:\left(\frac{t}{2}\right)\right| - \int (e^x)' \ln \:\left|\tan \:\left(\frac{t}{2}\right)\right|dt =    e^x \ln \:\left|\tan \:\left(\frac{t}{2}\right)\right| - \left( e^x \ln \:\left|\tan \:\left(\frac{t}{2}\right)\right|  - \int e^x \left(\ln \:\left|\tan \:\left(\frac{t}{2}\right)\right|\right)'dt \right)   I = 0 + I \iff 0=0 \mathbb{R}","['calculus', 'integration', 'indefinite-integrals']"
28,Definition of a derivative,Definition of a derivative,,"This may seem like a very stupid question but I know the definition of a derivative is $f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}$, is an equivalent definition of the derivative: $f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h/2)-f(x-h/2)}{h}$? If I draw a graph, it appears to me that they should be the same, but how can I show it algebraically?","This may seem like a very stupid question but I know the definition of a derivative is $f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h)-f(x)}{h}$, is an equivalent definition of the derivative: $f'(x) = \lim_{h \rightarrow 0} \frac{f(x+h/2)-f(x-h/2)}{h}$? If I draw a graph, it appears to me that they should be the same, but how can I show it algebraically?",,"['calculus', 'limits', 'derivatives', 'definition']"
29,Faster way to find Taylor series,Faster way to find Taylor series,,"I'm trying to figure out if there is a better way to teach the following Taylor series problem.  I can do the problem myself, but my solution doesn't seem very nice! Let's say I want to find the first $n$ terms (small $n$ - say 3 or 4) in the Taylor series for $$ f(z) = \frac{1}{1+z^2}  $$ around $z_0 = 2$ (or more generally around any $z_0\neq 0$, to make it interesting!)  Obviously, two methods that come to mind are 1) computing the derivatives $f^{(n)}(z_0)$, which quickly turns into a bit of a mess, and 2) making a change of variables $w = z-z_0$, then computing the power series expansion for $$ g(w) = \frac{1}{1+(w+z_0)^2} $$ and trying to simplify it, which also turns into a bit of a mess.  Neither approach seems particularly rapid or elegant.  Any thoughts?","I'm trying to figure out if there is a better way to teach the following Taylor series problem.  I can do the problem myself, but my solution doesn't seem very nice! Let's say I want to find the first $n$ terms (small $n$ - say 3 or 4) in the Taylor series for $$ f(z) = \frac{1}{1+z^2}  $$ around $z_0 = 2$ (or more generally around any $z_0\neq 0$, to make it interesting!)  Obviously, two methods that come to mind are 1) computing the derivatives $f^{(n)}(z_0)$, which quickly turns into a bit of a mess, and 2) making a change of variables $w = z-z_0$, then computing the power series expansion for $$ g(w) = \frac{1}{1+(w+z_0)^2} $$ and trying to simplify it, which also turns into a bit of a mess.  Neither approach seems particularly rapid or elegant.  Any thoughts?",,"['calculus', 'taylor-expansion']"
30,"Come up with some fun ""equation Limericks""","Come up with some fun ""equation Limericks""",,"We were discussing ""Limericks"" in my Calculus class. Specifically, ""equation Limericks"" . A Limerick is a poem with five lines. The first, second, and fifth lines should have nine syllables each and rhyme with each other, and the third and fourth should have six syllables each and rhyme with each other. An obscure subtype of the limerick is the ""equation Limerick"" , which states an equation. Here are some examples given in class: A dozen, a gross, plus a score Plus three times the square root of four Divided by seven Plus five times eleven Is nine squared (and not a bit more). The integral tee squared dee tee From one to the cube root of three Times the cosine Of three pi over nine Is the log of the cube root of e. The log of e to the four Times the square root of ten twenty-four Adding six dozen please Minus eight twenty-three's Is sixteen, case is closed, shut the door. I was able to come up with a couple of my own Limericks, but they are a bit simple compared to the ones above. Surprisingly, there are not many resources online regarding equation Limericks. Can anyone come up with their own that they would like to share?","We were discussing ""Limericks"" in my Calculus class. Specifically, ""equation Limericks"" . A Limerick is a poem with five lines. The first, second, and fifth lines should have nine syllables each and rhyme with each other, and the third and fourth should have six syllables each and rhyme with each other. An obscure subtype of the limerick is the ""equation Limerick"" , which states an equation. Here are some examples given in class: A dozen, a gross, plus a score Plus three times the square root of four Divided by seven Plus five times eleven Is nine squared (and not a bit more). The integral tee squared dee tee From one to the cube root of three Times the cosine Of three pi over nine Is the log of the cube root of e. The log of e to the four Times the square root of ten twenty-four Adding six dozen please Minus eight twenty-three's Is sixteen, case is closed, shut the door. I was able to come up with a couple of my own Limericks, but they are a bit simple compared to the ones above. Surprisingly, there are not many resources online regarding equation Limericks. Can anyone come up with their own that they would like to share?",,"['calculus', 'arithmetic', 'recreational-mathematics', 'puzzle']"
31,Computing $ \int_a^b \frac{x^p}{\sqrt{(x-a)(b-x)}} \mathrm dx$,Computing, \int_a^b \frac{x^p}{\sqrt{(x-a)(b-x)}} \mathrm dx,I would like to compute the integral: $$ \int_a^b \frac{x^p}{\sqrt{(x-a)(b-x)}} \mathrm dx$$ where $$ a<b$$ and $$ p\in\mathbb{N}$$ $$ \int_a^b \frac{x^p}{\sqrt{(x-a)(b-x)}} \mathrm dx=\frac{2}{b-a} \int_a^b \frac{x^p \mathrm dx}{\sqrt{1-\left(\frac{2x-(a+b)}{b-a}\right)^2}} $$ The substitution $x\rightarrow \frac{2x-(a+b)}{b-a}$ gives: $$ \frac{1}{2^p} \int_{-1}^{1} \frac{((b-a)x+a+b)^p}{\sqrt{1-x^2}} \mathrm dx$$ I tried to make an integration by parts: $$ \frac{1}{2^p}\left(2^{p-1}\pi(a^p+b^p)-p(b-a) \int_{-1}^1 \arcsin(x)((b-a)x+a+b)^{p-1} \mathrm dx \right)$$ What about the integral $$ \int_{-1}^1 \arcsin(x)((b-a)x+a+b)^{p-1} \mathrm dx $$?,I would like to compute the integral: $$ \int_a^b \frac{x^p}{\sqrt{(x-a)(b-x)}} \mathrm dx$$ where $$ a<b$$ and $$ p\in\mathbb{N}$$ $$ \int_a^b \frac{x^p}{\sqrt{(x-a)(b-x)}} \mathrm dx=\frac{2}{b-a} \int_a^b \frac{x^p \mathrm dx}{\sqrt{1-\left(\frac{2x-(a+b)}{b-a}\right)^2}} $$ The substitution $x\rightarrow \frac{2x-(a+b)}{b-a}$ gives: $$ \frac{1}{2^p} \int_{-1}^{1} \frac{((b-a)x+a+b)^p}{\sqrt{1-x^2}} \mathrm dx$$ I tried to make an integration by parts: $$ \frac{1}{2^p}\left(2^{p-1}\pi(a^p+b^p)-p(b-a) \int_{-1}^1 \arcsin(x)((b-a)x+a+b)^{p-1} \mathrm dx \right)$$ What about the integral $$ \int_{-1}^1 \arcsin(x)((b-a)x+a+b)^{p-1} \mathrm dx $$?,,"['calculus', 'integration', 'definite-integrals']"
32,A mysterious equality $\int_0^1 \left( e^x+x-1\right) e^{-\frac{x}{\mathrm{e}^x-1}}~dx=(e-1)^2e^{\frac e{1-e}}$,A mysterious equality,\int_0^1 \left( e^x+x-1\right) e^{-\frac{x}{\mathrm{e}^x-1}}~dx=(e-1)^2e^{\frac e{1-e}},"I can't prove this mysterious equality $$\int_0^1 \left(e^x+x-1\right)e^{-\frac{x}{\mathrm{e}^x-1}}dx=(e-1)^2e^{\frac e{1-e}}.$$ The changes of variables I used lead to nowhere. Origin : My friend proposed  me two integrals: The first is the object of the question and the second is to prove that $\quad\displaystyle \int_0^\infty \dfrac{x}{1-\text{e}^{-x}}\exp\left(\dfrac{x}{\text{e}^{-x}-1}\right)dx=1$ . The second is of the form $\displaystyle \int_0^\infty g(h(x) dx$ where $h(x)=\dfrac{x}{1-\text{e}^{-x}}$ and $g(x)=xe^{-x}$ . By using properties of h and g and especially that $h(x)-h(-x)=x,\quad  \forall x\in \mathbb R$ , we can show that $\displaystyle \int_0^\infty g(x)dx=\int_0^\infty g\circ h(u)du$ and the result is proven.","I can't prove this mysterious equality The changes of variables I used lead to nowhere. Origin : My friend proposed  me two integrals: The first is the object of the question and the second is to prove that . The second is of the form where and . By using properties of h and g and especially that , we can show that and the result is proven.","\int_0^1 \left(e^x+x-1\right)e^{-\frac{x}{\mathrm{e}^x-1}}dx=(e-1)^2e^{\frac e{1-e}}. \quad\displaystyle \int_0^\infty \dfrac{x}{1-\text{e}^{-x}}\exp\left(\dfrac{x}{\text{e}^{-x}-1}\right)dx=1 \displaystyle \int_0^\infty g(h(x) dx h(x)=\dfrac{x}{1-\text{e}^{-x}} g(x)=xe^{-x} h(x)-h(-x)=x,\quad  \forall x\in \mathbb R \displaystyle \int_0^\infty g(x)dx=\int_0^\infty g\circ h(u)du","['calculus', 'integration', 'definite-integrals']"
33,An AMM-like integral $\int_0^1\frac{\arctan x}x\ln\frac{(1+x^2)^3}{(1+x)^2}dx$,An AMM-like integral,\int_0^1\frac{\arctan x}x\ln\frac{(1+x^2)^3}{(1+x)^2}dx,How can we evaluate $$I=\int_0^1\frac{\arctan x}x\ln\frac{(1+x^2)^3}{(1+x)^2}dx=0?$$ I tried substitution $x=\frac{1-t}{1+t}$ and got $$I=\int_0^1\frac{2 \ln \frac{2 (t^2+1)^3}{(t+1)^4} \arctan \frac{t-1}{t+1}}{t^2-1}dt\\ =\int_0^1\frac{2 \ln \frac{2 (t^2+1)^3}{(t+1)^4} (\arctan t-\frac\pi4)}{t^2-1}dt$$ I'm able to evaluate $$\int_0^1\frac{\ln \frac{2 (t^2+1)^3}{(t+1)^4}}{t^2-1}dt$$ But I have no idea where to start with the rest one.,How can we evaluate I tried substitution and got I'm able to evaluate But I have no idea where to start with the rest one.,"I=\int_0^1\frac{\arctan x}x\ln\frac{(1+x^2)^3}{(1+x)^2}dx=0? x=\frac{1-t}{1+t} I=\int_0^1\frac{2 \ln \frac{2 (t^2+1)^3}{(t+1)^4} \arctan \frac{t-1}{t+1}}{t^2-1}dt\\
=\int_0^1\frac{2 \ln \frac{2 (t^2+1)^3}{(t+1)^4} (\arctan t-\frac\pi4)}{t^2-1}dt \int_0^1\frac{\ln \frac{2 (t^2+1)^3}{(t+1)^4}}{t^2-1}dt","['calculus', 'integration', 'definite-integrals']"
34,Line integral with respect to arc length,Line integral with respect to arc length,,"I ran into a problem that, initially, I thought was a typo. $$\int_C\ e^xdx $$ where C is the arc of the curve $x=y^3$ from $(-1,-1)$ to $(1,1)$. I have only encountered line integrals with $ds$ before, not $dx$ (or $dy$, for that matter). At first, I thought the $dx$ was supposed to be a $ds$, but that led to an unsolvable integral. Unfortunately, my book does not cover this topic very well, and the online answers I have found are rather vague. I tried plugging in $x=y^3$ to get $$ \int_{-1}^{1}\ e^{y^3}3y^2dy $$ which evaluates to $e - \frac{1}{e}$. This is also what I get when I do $ \int_{-1}^{1}\ e^{x}dx $, so I am inclined to believe it is correct. However, I'm not sure, and I'd like to know for certain if my intuition is valid.","I ran into a problem that, initially, I thought was a typo. $$\int_C\ e^xdx $$ where C is the arc of the curve $x=y^3$ from $(-1,-1)$ to $(1,1)$. I have only encountered line integrals with $ds$ before, not $dx$ (or $dy$, for that matter). At first, I thought the $dx$ was supposed to be a $ds$, but that led to an unsolvable integral. Unfortunately, my book does not cover this topic very well, and the online answers I have found are rather vague. I tried plugging in $x=y^3$ to get $$ \int_{-1}^{1}\ e^{y^3}3y^2dy $$ which evaluates to $e - \frac{1}{e}$. This is also what I get when I do $ \int_{-1}^{1}\ e^{x}dx $, so I am inclined to believe it is correct. However, I'm not sure, and I'd like to know for certain if my intuition is valid.",,"['calculus', 'definite-integrals', 'line-integrals']"
35,Asymptotics of $\int_1^L\int_1^L\int_1^L\int_1^L \frac{\mathrm dx_1~\mathrm dx_2 ~ \mathrm dx_3 ~ \mathrm dx_4}{(x_1+x_2)(x_2+x_3)(x_3+x_4)(x_4+x_1)}$,Asymptotics of,\int_1^L\int_1^L\int_1^L\int_1^L \frac{\mathrm dx_1~\mathrm dx_2 ~ \mathrm dx_3 ~ \mathrm dx_4}{(x_1+x_2)(x_2+x_3)(x_3+x_4)(x_4+x_1)},"Let $L>1$. I am looking for the value, or the leading asymptotics for $L\to\infty$, of $$\int_1^L\int_1^L\int_1^L\int_1^L \dfrac{\mathrm dx_1~\mathrm dx_2 ~ \mathrm  dx_3 ~ \mathrm dx_4}{(x_1+x_2)(x_2+x_3)(x_3+x_4)(x_4+x_1)}$$ More generally, I'd like to know the leading asymptotics of an expression like this with $2n$ terms, where the above has $2n=4$.","Let $L>1$. I am looking for the value, or the leading asymptotics for $L\to\infty$, of $$\int_1^L\int_1^L\int_1^L\int_1^L \dfrac{\mathrm dx_1~\mathrm dx_2 ~ \mathrm  dx_3 ~ \mathrm dx_4}{(x_1+x_2)(x_2+x_3)(x_3+x_4)(x_4+x_1)}$$ More generally, I'd like to know the leading asymptotics of an expression like this with $2n$ terms, where the above has $2n=4$.",,"['calculus', 'integration', 'limits', 'improper-integrals']"
36,Why is $i^i$ real? [duplicate],Why is  real? [duplicate],i^i,"This question already has answers here : Closed 11 years ago . Possible Duplicate: How to raise a complex number to the power of another complex number? My calculator (as well as WolframAlpha) gives me the approximation: $$0.2078795763507619085469...$$ But I don't understand how exponentiating two purely imaginary constructs yields a real (albeit irrational) number. When I do $i^{i+1}$ it gives me an imaginary number as well as $(i+1)^i$. So why does $i^i$ fall into that precise point where it is real and no longer imaginary? What is happening? I understand that exponentiation is not repeated multiplication, and it wouldn't make sense to multiply $i$ by itself $i$ times (because it would only yield $i$, $-i$, $1$, or $-1$). So what are we doing behind the scenes to get such a number?","This question already has answers here : Closed 11 years ago . Possible Duplicate: How to raise a complex number to the power of another complex number? My calculator (as well as WolframAlpha) gives me the approximation: $$0.2078795763507619085469...$$ But I don't understand how exponentiating two purely imaginary constructs yields a real (albeit irrational) number. When I do $i^{i+1}$ it gives me an imaginary number as well as $(i+1)^i$. So why does $i^i$ fall into that precise point where it is real and no longer imaginary? What is happening? I understand that exponentiation is not repeated multiplication, and it wouldn't make sense to multiply $i$ by itself $i$ times (because it would only yield $i$, $-i$, $1$, or $-1$). So what are we doing behind the scenes to get such a number?",,"['calculus', 'algebra-precalculus']"
37,Evaluate the indefinite integral $\int \frac{\sin^3\frac\theta 2}{\cos\frac\theta2 \sqrt{\cos^3\theta + \cos^2\theta + \cos\theta}} d\theta$,Evaluate the indefinite integral,\int \frac{\sin^3\frac\theta 2}{\cos\frac\theta2 \sqrt{\cos^3\theta + \cos^2\theta + \cos\theta}} d\theta,$$\int \frac{\sin^3\frac\theta 2}{\cos\frac\theta2 \sqrt{\cos^3\theta + \cos^2\theta + \cos\theta}} d\theta$$ My Attempt : $$I = \int \frac{\sin^2\frac\theta2\cdot\sin\frac\theta2\cos\frac\theta2}{\cos^2\frac\theta2 \sqrt{\cos^3\theta + \cos^2\theta + \cos\theta}}  d\theta \\ = \frac12 \int \frac{(1-\cos\theta)\sin\theta}{(1+\cos\theta)\sqrt{\cos^3\theta + \cos^2\theta + \cos\theta}}  d\theta$$ $$\text{let }\cos\theta = t \implies -\sin\theta d\theta = dt$$ $$I = \frac12 \int \frac{t-1}{(t+1) \sqrt{ t^3+t^2+t } } dt $$ I am not sure how to proceed further from here. Any hints/solutions on how to resolve the cubic expression under the square root?,My Attempt : I am not sure how to proceed further from here. Any hints/solutions on how to resolve the cubic expression under the square root?,"\int \frac{\sin^3\frac\theta 2}{\cos\frac\theta2 \sqrt{\cos^3\theta + \cos^2\theta + \cos\theta}} d\theta I = \int \frac{\sin^2\frac\theta2\cdot\sin\frac\theta2\cos\frac\theta2}{\cos^2\frac\theta2 \sqrt{\cos^3\theta + \cos^2\theta + \cos\theta}} 
d\theta \\ = \frac12 \int \frac{(1-\cos\theta)\sin\theta}{(1+\cos\theta)\sqrt{\cos^3\theta + \cos^2\theta + \cos\theta}} 
d\theta \text{let }\cos\theta = t \implies -\sin\theta d\theta = dt I = \frac12 \int \frac{t-1}{(t+1) \sqrt{ t^3+t^2+t } } dt ","['calculus', 'integration', 'indefinite-integrals']"
38,Comparison of integrals by algebraic means,Comparison of integrals by algebraic means,,"$$ \begin{align}A&:=\int_0^1\frac1{\sqrt{x(1-x)}}\ \mathrm dx \\ B&:=\int_0^1\sqrt{x(1-x)}\ \mathrm dx \end{align} $$ My CAS tells me that $A = \pi$ and $B = \frac18\pi$ . How can one prove that $A=8B$ using just basic rules of integration such as the chain rule? Trigonometric functions are not allowed since they are not definable as integrals. Neither is the Gamma function allowed, since it is defined in terms of exp, which is like a trigonometric function. These restrictions are part of what I mean by ""algebraic means"". On the other hand, integration by parts is fine. Equivalently, the fundamental theorem of calculus is also fine.","My CAS tells me that and . How can one prove that using just basic rules of integration such as the chain rule? Trigonometric functions are not allowed since they are not definable as integrals. Neither is the Gamma function allowed, since it is defined in terms of exp, which is like a trigonometric function. These restrictions are part of what I mean by ""algebraic means"". On the other hand, integration by parts is fine. Equivalently, the fundamental theorem of calculus is also fine.", \begin{align}A&:=\int_0^1\frac1{\sqrt{x(1-x)}}\ \mathrm dx \\ B&:=\int_0^1\sqrt{x(1-x)}\ \mathrm dx \end{align}  A = \pi B = \frac18\pi A=8B,"['calculus', 'integration']"
39,Proving that $\int_0^\infty\sin(x)dx=1$,Proving that,\int_0^\infty\sin(x)dx=1,"Logically and by method 1 the limit should be undefined, but with some juggling it comes out to be $1$. Method 1. $\displaystyle \lim_{k\to\infty} \int_0^k \sin(x) \, dx = -\lim_{k\to\infty} (\cos(k)-1) = \text{not defined}$. Method 2. Let $I = \int e^{-tx}\sin(x) \, dx$ and $J=\int e^{-tx}\cos(x) \, dx$. Using integration by parts, \begin{align*} I &= -e^{-tx}\cos x - tJ, \tag{i} \\ J &= e^{-tx}\sin x + tI \tag{ii} \end{align*} from $\text{(i)}$ and $\text{(ii)}$, $$ I = -e^{-tx} \left[ \frac{\cos x + t\sin x}{1+t^2} \right], \qquad J = e^{tx}\left[ \frac{\sin x-t\cos x}{1+t^2} \right]. $$ Thus $\int_0^\infty e^{-tx}\sin(x) \, dx = \frac{1}{1+t^2}$. Taking limit $t \to 0$ $$ \lim_{t\to 0}\int_{0}^{\infty} e^{-tx}\sin(x) \, dx = \int_{0}^{\infty} \sin(x) \, dx = 1. $$ Is the integral $1$ or undefined?","Logically and by method 1 the limit should be undefined, but with some juggling it comes out to be $1$. Method 1. $\displaystyle \lim_{k\to\infty} \int_0^k \sin(x) \, dx = -\lim_{k\to\infty} (\cos(k)-1) = \text{not defined}$. Method 2. Let $I = \int e^{-tx}\sin(x) \, dx$ and $J=\int e^{-tx}\cos(x) \, dx$. Using integration by parts, \begin{align*} I &= -e^{-tx}\cos x - tJ, \tag{i} \\ J &= e^{-tx}\sin x + tI \tag{ii} \end{align*} from $\text{(i)}$ and $\text{(ii)}$, $$ I = -e^{-tx} \left[ \frac{\cos x + t\sin x}{1+t^2} \right], \qquad J = e^{tx}\left[ \frac{\sin x-t\cos x}{1+t^2} \right]. $$ Thus $\int_0^\infty e^{-tx}\sin(x) \, dx = \frac{1}{1+t^2}$. Taking limit $t \to 0$ $$ \lim_{t\to 0}\int_{0}^{\infty} e^{-tx}\sin(x) \, dx = \int_{0}^{\infty} \sin(x) \, dx = 1. $$ Is the integral $1$ or undefined?",,"['calculus', 'integration', 'limits', 'definite-integrals', 'fake-proofs']"
40,$\int_{-\infty}^{\infty}{e^x+1\over (e^x-x+1)^2+\pi^2}\mathrm dx=\int_{-\infty}^{\infty}{e^x+1\over (e^x+x+1)^2+\pi^2}\mathrm dx=1$,,\int_{-\infty}^{\infty}{e^x+1\over (e^x-x+1)^2+\pi^2}\mathrm dx=\int_{-\infty}^{\infty}{e^x+1\over (e^x+x+1)^2+\pi^2}\mathrm dx=1,"Look-alike integrals $$I_1+I_2=\int_{-\infty}^{\infty}{e^x+1\over (e^x-x+1)^2+\pi^2}\mathrm dx=\int_{-\infty}^{\infty}{e^x+1\over (e^x+x+1)^2+\pi^2}\mathrm dx=1\tag1$$ I just wonder if these integrals $I_1$ and $I_2$ are the same in term of transforming is concern? Or they just only happened to give the same closed form? If I make a substitution of $u=e^x+1$, nothing much happened $$\int_{1}^{\infty}{u\over u-1}\cdot{\mathrm du\over (u-\ln{(u-1)})^2+\pi^2}=\int_{1}^{\infty}{u\over u-1}\cdot{\mathrm du\over (u+\ln{(u-1)})^2+\pi^2}\tag2$$ Note: I can't show it but I think $I_1$ and $I_2$ are not related in term of transforming into each other. Else How can we show that $I_1$ or $I_2$ has a value of one?","Look-alike integrals $$I_1+I_2=\int_{-\infty}^{\infty}{e^x+1\over (e^x-x+1)^2+\pi^2}\mathrm dx=\int_{-\infty}^{\infty}{e^x+1\over (e^x+x+1)^2+\pi^2}\mathrm dx=1\tag1$$ I just wonder if these integrals $I_1$ and $I_2$ are the same in term of transforming is concern? Or they just only happened to give the same closed form? If I make a substitution of $u=e^x+1$, nothing much happened $$\int_{1}^{\infty}{u\over u-1}\cdot{\mathrm du\over (u-\ln{(u-1)})^2+\pi^2}=\int_{1}^{\infty}{u\over u-1}\cdot{\mathrm du\over (u+\ln{(u-1)})^2+\pi^2}\tag2$$ Note: I can't show it but I think $I_1$ and $I_2$ are not related in term of transforming into each other. Else How can we show that $I_1$ or $I_2$ has a value of one?",,"['calculus', 'integration', 'definite-integrals']"
41,Does $\int_{0}^{\infty}{\sin{(\pi{x^2})}\over \sinh{(\pi{x}})\tanh(x\pi)}\mathrm{d}x$ have a simple closed from?,Does  have a simple closed from?,\int_{0}^{\infty}{\sin{(\pi{x^2})}\over \sinh{(\pi{x}})\tanh(x\pi)}\mathrm{d}x,Does this integral $(1)$ has a simple closed form? $$\int_{0}^{\infty}{\sin{(\pi{x^2})}\over \sinh{(\pi{x}})\tanh(x\pi)}\mathrm dx\tag1$$ An attempt of approach $$\int_{0}^{\infty}{\sin{(\pi{x^2})}\cosh{(x\pi)}\over \sinh{(\pi{x}})^2}\mathrm dx\tag2$$ $$\int_{0}^{\infty}{\sin{(\pi{x^2})}\cosh{(x\pi)}\over 1-\cosh{(\pi{x}})^2}\mathrm dx\tag3$$ $$\int_{0}^{\infty}{\sin{(\pi{x^2})}\cosh{(x\pi)}\over (1-\cosh{(\pi{x}}))(1+\cosh{(x\pi)})}\mathrm dx\tag4$$ $${1\over2}\int_{0}^{\infty}{\sin{(\pi{x^2})}\over 1-\cosh{(\pi{x}})}\mathrm dx-{1\over 2}\int_{0}^{\infty}{\sin{(\pi{x^2})}\over 1+\cosh{(\pi{x}})}\mathrm dx\tag5$$ Not sure what to do next. Any help?,Does this integral $(1)$ has a simple closed form? $$\int_{0}^{\infty}{\sin{(\pi{x^2})}\over \sinh{(\pi{x}})\tanh(x\pi)}\mathrm dx\tag1$$ An attempt of approach $$\int_{0}^{\infty}{\sin{(\pi{x^2})}\cosh{(x\pi)}\over \sinh{(\pi{x}})^2}\mathrm dx\tag2$$ $$\int_{0}^{\infty}{\sin{(\pi{x^2})}\cosh{(x\pi)}\over 1-\cosh{(\pi{x}})^2}\mathrm dx\tag3$$ $$\int_{0}^{\infty}{\sin{(\pi{x^2})}\cosh{(x\pi)}\over (1-\cosh{(\pi{x}}))(1+\cosh{(x\pi)})}\mathrm dx\tag4$$ $${1\over2}\int_{0}^{\infty}{\sin{(\pi{x^2})}\over 1-\cosh{(\pi{x}})}\mathrm dx-{1\over 2}\int_{0}^{\infty}{\sin{(\pi{x^2})}\over 1+\cosh{(\pi{x}})}\mathrm dx\tag5$$ Not sure what to do next. Any help?,,"['calculus', 'integration']"
42,Rather weird integral,Rather weird integral,,"I've reached a pretty weird integral $$\int_0^{5} \frac{\ln(y)}{(y+3)\sqrt{y}} dy,$$ And I'm having some difficulties starting from the $u$-substitution method. I had the intuition that I may take $\sqrt{y} = u$ and thus $\frac{1}{2\sqrt{y}}dy = du.$ However, this method seems to get tangled with the issues related to the natural log in the numerator. I felt that I could start on integration by parts, but then I thought that there may be a cleaner method with partial fractions. Could someone give me some suggestions on either method in this problem?","I've reached a pretty weird integral $$\int_0^{5} \frac{\ln(y)}{(y+3)\sqrt{y}} dy,$$ And I'm having some difficulties starting from the $u$-substitution method. I had the intuition that I may take $\sqrt{y} = u$ and thus $\frac{1}{2\sqrt{y}}dy = du.$ However, this method seems to get tangled with the issues related to the natural log in the numerator. I felt that I could start on integration by parts, but then I thought that there may be a cleaner method with partial fractions. Could someone give me some suggestions on either method in this problem?",,"['calculus', 'integration']"
43,An equivalent for $\sum_{n=0}^{\infty} e^{-x\sqrt{n}}$ as $x$ tends to $0^+$,An equivalent for  as  tends to,\sum_{n=0}^{\infty} e^{-x\sqrt{n}} x 0^+,"I would like to obtain an equivalent form for $$ f(x)=\sum_{n=0}^{\infty} e^{-x\sqrt{n}} $$ as $x \rightarrow 0^+$. I tried without success to ""remove"" the $\sqrt{\cdot}$ in the summand by summing over some new index $p$ writing $\displaystyle \sum_{n=0}^{\infty} =\sum_{p=0}^{\infty}\sum_{k=p^2}^{(p+1)^2-1}$. Thanks for your help.","I would like to obtain an equivalent form for $$ f(x)=\sum_{n=0}^{\infty} e^{-x\sqrt{n}} $$ as $x \rightarrow 0^+$. I tried without success to ""remove"" the $\sqrt{\cdot}$ in the summand by summing over some new index $p$ writing $\displaystyle \sum_{n=0}^{\infty} =\sum_{p=0}^{\infty}\sum_{k=p^2}^{(p+1)^2-1}$. Thanks for your help.",,"['calculus', 'integration', 'sequences-and-series', 'definite-integrals', 'asymptotics']"
44,Help to clarify proof of Euler's Theorem on homogenous equations,Help to clarify proof of Euler's Theorem on homogenous equations,,"Why is the last step (setting $\lambda = 1$ allowed? I have trouble accepting this because if I set $\lambda =1 $ at the very start, then: $f(\lambda x , \lambda y)=\lambda^r f(x,y)$ becomes $f(x,y) = f(x,y)$ and so I can't prove the theorem. Why does setting $\lambda = 1$ at the end of the proof work? EDIT For example, let $f(x,y)=x^2y^2$ Therefore, $f(x,y)$ is homogeneous of degree 4. Therefore, the second to last step will be: $4x^2y^2=4\lambda^3x^2y^2$ The above equation is only true if $\lambda=1$ Why doesn't the theorem make a qualification that $\lambda$ must be equal to 1? It seems to me that this theorem is saying that there is a special relationship between the derivatives of a homogenous function and its degree but this relationship holds only when $\lambda=1$. Please correct me if my observation is wrong.","Why is the last step (setting $\lambda = 1$ allowed? I have trouble accepting this because if I set $\lambda =1 $ at the very start, then: $f(\lambda x , \lambda y)=\lambda^r f(x,y)$ becomes $f(x,y) = f(x,y)$ and so I can't prove the theorem. Why does setting $\lambda = 1$ at the end of the proof work? EDIT For example, let $f(x,y)=x^2y^2$ Therefore, $f(x,y)$ is homogeneous of degree 4. Therefore, the second to last step will be: $4x^2y^2=4\lambda^3x^2y^2$ The above equation is only true if $\lambda=1$ Why doesn't the theorem make a qualification that $\lambda$ must be equal to 1? It seems to me that this theorem is saying that there is a special relationship between the derivatives of a homogenous function and its degree but this relationship holds only when $\lambda=1$. Please correct me if my observation is wrong.",,"['calculus', 'proof-writing']"
45,"Evaluating $\int_{0}^{\infty}\frac{\arctan (a\,\sin^2x)}{x^2}dx$",Evaluating,"\int_{0}^{\infty}\frac{\arctan (a\,\sin^2x)}{x^2}dx","This is the sequel of my previous question $$I(a)=\int_{0}^{\infty}\frac{\arctan (a\,\sin^2x)}{x^2}dx$$ I want to use differentiation under the integral sign with respect to parameter ""a"" but so far without success. Any hint?","This is the sequel of my previous question $$I(a)=\int_{0}^{\infty}\frac{\arctan (a\,\sin^2x)}{x^2}dx$$ I want to use differentiation under the integral sign with respect to parameter ""a"" but so far without success. Any hint?",,"['calculus', 'integration', 'improper-integrals']"
46,"How do we find the exact value of $\int_{0}^{\infty} \frac{\ln ^{n}\left(1+x^{2}\right)}{1+x^{2}} d x$, where $n\in \mathbb N?$","How do we find the exact value of , where",\int_{0}^{\infty} \frac{\ln ^{n}\left(1+x^{2}\right)}{1+x^{2}} d x n\in \mathbb N?,"Latest Edit By @KStarGamers help, I can finally find a reduction formula for $I_n$ as below: $$\boxed{I_n= 2 \ln 2 I_{n-1}+ (n-1)!\sum_{k=0}^{n-2} \frac{2^{n-k}-2}{k!}\zeta(n-k)  I_k} $$ where $n\geq 2.$ In my post , I started to evaluate $$I_1=\int_{0}^{\infty} \frac{\ln \left(1+x^{2}\right)}{1+x^{2}} d x =\pi \ln 2, $$ then I challenge myself on $$I_2=\int_{0}^{\infty} \frac{\ln ^{2}\left(1+x^{2}\right)}{1+x^{2}}dx$$ Again, letting $x=\tan \theta$ as for $I_1$ yields $$I_2=\int_{0}^{\frac{\pi}{2}} \ln ^{2}\left(\sec ^{2} \theta\right) d \theta= 4 \int_{0}^{\frac{\pi}{2}} \ln ^{2}(\cos x) dx $$ Its very hard to deal with $\ln^2$ and I was stuck. Suddenly a wonderful identity came to my mind. $$ 2\left(a^{2}+b^{2}\right)=(a+b)^{2}+(a-b)^{2}, \\$$ by which $\displaystyle 2\left[\ln ^{2}(\sin x)+\ln ^{2}(\cos x)\right]=[\ln (\sin x)+\ln (\cos x)]^{2}+[\ln (\sin x)-\ln (\cos x)]^{2} ,\tag*{}\\ $ we have $\displaystyle 4 L=\underbrace{\int_{0}^{\frac{\pi}{2}} \ln ^{2}\left(\frac{\sin 2 x}{2}\right)}_{J} d x+\underbrace{\int_{0}^{\frac{\pi}{2}} \ln ^{2}(\tan x) d x}_{K} \tag*{}\\ $ For the first integral, using $ \int_{0}^{\frac{\pi}{2}} \ln (\sin x) d x=-\dfrac{\pi}{2} \ln 2 $ yields $ \begin{aligned}J &=\int_{0}^{\frac{\pi}{2}}[\ln (\sin 2 x)-\ln 2]^{2} d x \\&=\int_{0}^{\frac{\pi}{2}} \ln ^{2}(\sin 2 x) d x-2 \ln 2 \int_{0}^{\frac{\pi}{2}} \ln (\sin 2 x) d x +\frac{\pi \ln ^{2} 2}{2} \\& \stackrel{x\mapsto 2x}{=} \frac{1}{2} \int_{0}^{\pi} \ln ^{2}(\sin x) d x-\ln 2 \int_{0}^{\pi} \ln (\sin x) d x+\frac{\pi \ln ^{2} 2}{2} \\& \stackrel{symmetry}{=} L-\ln 2(-\pi \ln 2)+\frac{\pi \ln ^{2} 2}{2} \\&=L+\frac{3 \pi \ln ^{2} 2}{2}\end{aligned}\tag*{} \\$ For the second integral, letting $ y=\tan x $ and using my post yields $ \displaystyle K=\int_{0}^{\infty} \frac{\ln ^{2} y}{1+y^{2}} d y=\frac{\pi^{3}}{8}, \tag*{} \\$ then $ \displaystyle 4L=L+\frac{3 \pi \ln ^{2} 2}{2}+\frac{\pi^{3}}{8} \Rightarrow L=\frac{\pi^{3}}{24}+\frac{\pi \ln ^{2} 2}{2}\tag*{} $ Hence $ \displaystyle \boxed{I_2=4L= \frac{\pi^{3}}{6}+2 \pi \ln ^{2} 2} \tag*{} $ My Question : Can I go further with $I_n$ , where $n\geq 3$ ?","Latest Edit By @KStarGamers help, I can finally find a reduction formula for as below: where In my post , I started to evaluate then I challenge myself on Again, letting as for yields Its very hard to deal with and I was stuck. Suddenly a wonderful identity came to my mind. by which we have For the first integral, using yields For the second integral, letting and using my post yields then Hence My Question : Can I go further with , where ?","I_n \boxed{I_n= 2 \ln 2 I_{n-1}+ (n-1)!\sum_{k=0}^{n-2} \frac{2^{n-k}-2}{k!}\zeta(n-k)  I_k}
 n\geq 2. I_1=\int_{0}^{\infty} \frac{\ln \left(1+x^{2}\right)}{1+x^{2}} d x =\pi \ln 2,  I_2=\int_{0}^{\infty} \frac{\ln ^{2}\left(1+x^{2}\right)}{1+x^{2}}dx x=\tan \theta I_1 I_2=\int_{0}^{\frac{\pi}{2}} \ln ^{2}\left(\sec ^{2} \theta\right) d \theta= 4 \int_{0}^{\frac{\pi}{2}} \ln ^{2}(\cos x) dx  \ln^2 
2\left(a^{2}+b^{2}\right)=(a+b)^{2}+(a-b)^{2},
\\ \displaystyle 2\left[\ln ^{2}(\sin x)+\ln ^{2}(\cos x)\right]=[\ln (\sin x)+\ln (\cos x)]^{2}+[\ln (\sin x)-\ln (\cos x)]^{2} ,\tag*{}\\  \displaystyle 4 L=\underbrace{\int_{0}^{\frac{\pi}{2}} \ln ^{2}\left(\frac{\sin 2 x}{2}\right)}_{J} d x+\underbrace{\int_{0}^{\frac{\pi}{2}} \ln ^{2}(\tan x) d x}_{K} \tag*{}\\   \int_{0}^{\frac{\pi}{2}} \ln (\sin x) d x=-\dfrac{\pi}{2} \ln 2   \begin{aligned}J &=\int_{0}^{\frac{\pi}{2}}[\ln (\sin 2 x)-\ln 2]^{2} d x \\&=\int_{0}^{\frac{\pi}{2}} \ln ^{2}(\sin 2 x) d x-2 \ln 2 \int_{0}^{\frac{\pi}{2}} \ln (\sin 2 x) d x +\frac{\pi \ln ^{2} 2}{2} \\& \stackrel{x\mapsto 2x}{=} \frac{1}{2} \int_{0}^{\pi} \ln ^{2}(\sin x) d x-\ln 2 \int_{0}^{\pi} \ln (\sin x) d x+\frac{\pi \ln ^{2} 2}{2} \\& \stackrel{symmetry}{=} L-\ln 2(-\pi \ln 2)+\frac{\pi \ln ^{2} 2}{2} \\&=L+\frac{3 \pi \ln ^{2} 2}{2}\end{aligned}\tag*{} \\  y=\tan x   \displaystyle K=\int_{0}^{\infty} \frac{\ln ^{2} y}{1+y^{2}} d y=\frac{\pi^{3}}{8}, \tag*{} \\  \displaystyle 4L=L+\frac{3 \pi \ln ^{2} 2}{2}+\frac{\pi^{3}}{8} \Rightarrow L=\frac{\pi^{3}}{24}+\frac{\pi \ln ^{2} 2}{2}\tag*{}   \displaystyle \boxed{I_2=4L= \frac{\pi^{3}}{6}+2 \pi \ln ^{2} 2} \tag*{}  I_n n\geq 3","['calculus', 'integration', 'trigonometry', 'definite-integrals', 'logarithms']"
47,"Evaluation of complete elliptic integrals $K(k) $ for $k=\tan(\pi/8),\sin(\pi/12)$",Evaluation of complete elliptic integrals  for,"K(k)  k=\tan(\pi/8),\sin(\pi/12)","This is inspired from here . I will repeat some information from the linked question for the benefit of readers. Let $k\in(0,1)$ and the elliptic integrals $K, E$ are defined as follows: $$K(k)=\int_{0}^{\pi/2}\frac{dx}{\sqrt{1 - k^{2}\sin^{2}x}},\,E(k)=\int_{0}^{\pi/2}\sqrt{1-k^{2}\sin^{2}x}\,dx\tag{1}$$ The number $k$ is called the modulus and a complementary modulus $k'$ is defined by $k'=\sqrt{1-k^{2}}$ and if the value of $k$ is available from context then the integrals $K(k), E(k), K(k'), E(k') $ are generally denoted by $K, E, K', E'$. If $n$ is a positive rational number then it can be proved that there is a unique modulus $k$ such that $K'/K=\sqrt{n} $ and moreover this $k$ is an algebraic number. Such values of $k$ are famous and are called singular moduli and one may denote them by $k_{n} $ corresponding to the rational number $n$. Chowla and Selberg proved in this paper that Theorem : Let $k$ be a singular modulus. Then the elliptic integrals $K(k), E(k) $ can be expressed in terms of Gamma values at rational points and $\pi$. The linked paper of Chowla and Selberg uses theory of quadratic forms and related complex analytic techniques to prove their theorem. On the other hand Ramanujan knew the evaluation of $K$ in terms of Gamma values and $\pi$ for some singular moduli $k$. In his classic paper Modular Equations and Approximations to $\pi$ he gave the evaluations for $n=1,2,3$ without proof. It is thus reasonable to assume that the evaluations are possible by remaining within the limits of real analysis methods at least for $n=1,2,3$. The case $n=1$ is covered in this answer . My question  concerns the cases $n=2,3$ for which $k=\tan(\pi/8),\sin(\pi/12)$ respectively: Show that $$\int_{0}^{\pi/2}\frac{dx}{\sqrt{1-\tan^{2}(\pi/8)\sin^{2}x}}=\frac{\sqrt{\sqrt{2} +1} \Gamma (1/8)\Gamma (3/8)}{2^{13/4}\sqrt{\pi}}\tag{2}$$ and $$\int_{0}^{\pi/2}\frac{dx}{\sqrt{1-\sin^{2}(\pi/12)\sin^{2}x}}=\frac{3^{1/4}\Gamma ^{3}(1/3)}{2^{7/3}\pi}\tag{3}$$ Evaluation based on real analysis methods is desirable. Update : I have managed to prove the above mentioned results using hints given in exercises from Borwein's Pi and the AGM (see my answer). But these methods are totally non-obvious and it is desirable to find solutions based on general techniques for evaluation of definite integrals. Borwein's book was with me for a long time and these exercises lay dormant until I receieved a gentle push via user ""Simply Beautiful Art""'s question linked above. Thanks to him for the same.","This is inspired from here . I will repeat some information from the linked question for the benefit of readers. Let $k\in(0,1)$ and the elliptic integrals $K, E$ are defined as follows: $$K(k)=\int_{0}^{\pi/2}\frac{dx}{\sqrt{1 - k^{2}\sin^{2}x}},\,E(k)=\int_{0}^{\pi/2}\sqrt{1-k^{2}\sin^{2}x}\,dx\tag{1}$$ The number $k$ is called the modulus and a complementary modulus $k'$ is defined by $k'=\sqrt{1-k^{2}}$ and if the value of $k$ is available from context then the integrals $K(k), E(k), K(k'), E(k') $ are generally denoted by $K, E, K', E'$. If $n$ is a positive rational number then it can be proved that there is a unique modulus $k$ such that $K'/K=\sqrt{n} $ and moreover this $k$ is an algebraic number. Such values of $k$ are famous and are called singular moduli and one may denote them by $k_{n} $ corresponding to the rational number $n$. Chowla and Selberg proved in this paper that Theorem : Let $k$ be a singular modulus. Then the elliptic integrals $K(k), E(k) $ can be expressed in terms of Gamma values at rational points and $\pi$. The linked paper of Chowla and Selberg uses theory of quadratic forms and related complex analytic techniques to prove their theorem. On the other hand Ramanujan knew the evaluation of $K$ in terms of Gamma values and $\pi$ for some singular moduli $k$. In his classic paper Modular Equations and Approximations to $\pi$ he gave the evaluations for $n=1,2,3$ without proof. It is thus reasonable to assume that the evaluations are possible by remaining within the limits of real analysis methods at least for $n=1,2,3$. The case $n=1$ is covered in this answer . My question  concerns the cases $n=2,3$ for which $k=\tan(\pi/8),\sin(\pi/12)$ respectively: Show that $$\int_{0}^{\pi/2}\frac{dx}{\sqrt{1-\tan^{2}(\pi/8)\sin^{2}x}}=\frac{\sqrt{\sqrt{2} +1} \Gamma (1/8)\Gamma (3/8)}{2^{13/4}\sqrt{\pi}}\tag{2}$$ and $$\int_{0}^{\pi/2}\frac{dx}{\sqrt{1-\sin^{2}(\pi/12)\sin^{2}x}}=\frac{3^{1/4}\Gamma ^{3}(1/3)}{2^{7/3}\pi}\tag{3}$$ Evaluation based on real analysis methods is desirable. Update : I have managed to prove the above mentioned results using hints given in exercises from Borwein's Pi and the AGM (see my answer). But these methods are totally non-obvious and it is desirable to find solutions based on general techniques for evaluation of definite integrals. Borwein's book was with me for a long time and these exercises lay dormant until I receieved a gentle push via user ""Simply Beautiful Art""'s question linked above. Thanks to him for the same.",,"['calculus', 'integration', 'definite-integrals', 'elliptic-integrals']"
48,How to integrate $\int\limits_{0}^{\pi/2}\frac{dx}{\cos^3{x}+\sin^3{x}}$?,How to integrate ?,\int\limits_{0}^{\pi/2}\frac{dx}{\cos^3{x}+\sin^3{x}},I have$$\int\limits_{0}^{\pi/2}\frac{\text{d}x}{\cos^3{x}+\sin^3{x}}$$ Tangent half-angle substitution gives a fourth-degree polynomial in the denominator that is difficult to factor.,I have$$\int\limits_{0}^{\pi/2}\frac{\text{d}x}{\cos^3{x}+\sin^3{x}}$$ Tangent half-angle substitution gives a fourth-degree polynomial in the denominator that is difficult to factor.,,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
49,How to integrate $\int\limits_0^1 \left(-1\right)^{^{\left\lfloor\frac{1}{x}\right\rfloor}} dx$?,How to integrate ?,\int\limits_0^1 \left(-1\right)^{^{\left\lfloor\frac{1}{x}\right\rfloor}} dx,"As my title says, I need help integrating with floor functions, $$\int\limits_0^1 \left(-1\right)^{^{\left\lfloor\frac{1}{x}\right\rfloor}} dx$$ What does this even mean exactly? How would approach this?","As my title says, I need help integrating with floor functions, $$\int\limits_0^1 \left(-1\right)^{^{\left\lfloor\frac{1}{x}\right\rfloor}} dx$$ What does this even mean exactly? How would approach this?",,"['calculus', 'integration', 'ceiling-and-floor-functions']"
50,Can I derive the formula for expected value of continuous random variables from the discrete case?,Can I derive the formula for expected value of continuous random variables from the discrete case?,,"I've previously asked the question on Stats SE, but I guess it fits the Math SE better. Is it possible to rigorously derive the formula for expected value of continuous random variable starting with expected variable in discrete case, i.e. $$E[X] = \sum_{i=1}^{n}p_i x_i$$ to obtain $$E[X]=\int_{-\infty}^{\infty}xf(x)dx$$ When formulating the definition for continuous case, the intention was, I believe, to make it 'equivalent' to the discrete case. So for example, I'd like $E[X]$ of a continuous random variable $X$ to be equal to the sum of every possible value of $X$ times probability of that particular value. The problem is that the probability of any particular value of $X$ is $0$, and the expected value calculated that way would always be $0$. But some people tried to convince me that it's possible overcome these issues with help of Lebesgue integral. Could anyone explain intuitively how is that possible? I'm convinced that no matter what integration we use, we cannot somehow magically assign non-zero probabilities to single values the random variable $X$ might take. They will always be $0$! Or maybe there's no magic involved and best we can do is work with infinitely thin intervals of $X$? From what I've managed to find out (I don't have time to study all measure theory and Lebesgue integration at the moment to figure it out on my own) it's about approximating the original continuous random variable $X$ with step function, and the more steps there are, the better is the approximation. But still, all we have is calculating probability of intervals (they are infinitely thin though, but they are intervals anyway). The fact that something gets closer and closer to original function in the limit doesn't mean it behaves the same as the original function (check the very popular example here ). In the 'very popular example' above, even though the curve approaches the circle, its length will never be the same as the perimeter of that circle.  Similarly, here , in 'The Riemann-Stieltjes integral: intuition' part. they say the discrete r.v. $X_n$ converges to continuous r.v. $X$, as $n \to \infty$, in the limit it becomes the same variable. So it's important to ask whether it's reasonable to expect the approximation of the cont. r.v. $X$ to behave the same as the original random variable $X$, even if in the limit the are 'indistinguishable' in the limit, whatever that word means in mathematics. The curve and circle are indistinguishable too, but still have different properties. So apparently it's that the continuous case is not derived from discrete case, but is a generalization of the discrete case. I guess in every mathematical theory, there is no such thing as 'the only correct' generalization, so the contunous formula could look different. If you claim this is the only 'valid one', then shouldn't we call it a derivation of the formula?","I've previously asked the question on Stats SE, but I guess it fits the Math SE better. Is it possible to rigorously derive the formula for expected value of continuous random variable starting with expected variable in discrete case, i.e. $$E[X] = \sum_{i=1}^{n}p_i x_i$$ to obtain $$E[X]=\int_{-\infty}^{\infty}xf(x)dx$$ When formulating the definition for continuous case, the intention was, I believe, to make it 'equivalent' to the discrete case. So for example, I'd like $E[X]$ of a continuous random variable $X$ to be equal to the sum of every possible value of $X$ times probability of that particular value. The problem is that the probability of any particular value of $X$ is $0$, and the expected value calculated that way would always be $0$. But some people tried to convince me that it's possible overcome these issues with help of Lebesgue integral. Could anyone explain intuitively how is that possible? I'm convinced that no matter what integration we use, we cannot somehow magically assign non-zero probabilities to single values the random variable $X$ might take. They will always be $0$! Or maybe there's no magic involved and best we can do is work with infinitely thin intervals of $X$? From what I've managed to find out (I don't have time to study all measure theory and Lebesgue integration at the moment to figure it out on my own) it's about approximating the original continuous random variable $X$ with step function, and the more steps there are, the better is the approximation. But still, all we have is calculating probability of intervals (they are infinitely thin though, but they are intervals anyway). The fact that something gets closer and closer to original function in the limit doesn't mean it behaves the same as the original function (check the very popular example here ). In the 'very popular example' above, even though the curve approaches the circle, its length will never be the same as the perimeter of that circle.  Similarly, here , in 'The Riemann-Stieltjes integral: intuition' part. they say the discrete r.v. $X_n$ converges to continuous r.v. $X$, as $n \to \infty$, in the limit it becomes the same variable. So it's important to ask whether it's reasonable to expect the approximation of the cont. r.v. $X$ to behave the same as the original random variable $X$, even if in the limit the are 'indistinguishable' in the limit, whatever that word means in mathematics. The curve and circle are indistinguishable too, but still have different properties. So apparently it's that the continuous case is not derived from discrete case, but is a generalization of the discrete case. I guess in every mathematical theory, there is no such thing as 'the only correct' generalization, so the contunous formula could look different. If you claim this is the only 'valid one', then shouldn't we call it a derivation of the formula?",,"['calculus', 'probability', 'lebesgue-integral']"
51,Integrate $\int_{-\infty}^{\infty} \frac{dx}{1+x^{12}}$using partial fractions,Integrate using partial fractions,\int_{-\infty}^{\infty} \frac{dx}{1+x^{12}},"How do I integrate the improper integral $$\int_{-\infty}^{\infty} \frac{dx}{1+x^{12}}$$ using partial fraction decomposition? I am restricted to use only the principles taught in Calculus 2, which entails partial fraction decomposition. I have tried factoring the denominator but was quickly stumped at the complicated roots. I am unsure of how to proceed. I even thought of looking at it as a series but I don't think I can do that. Thank you very much for your help. I greatly appreciate it.","How do I integrate the improper integral using partial fraction decomposition? I am restricted to use only the principles taught in Calculus 2, which entails partial fraction decomposition. I have tried factoring the denominator but was quickly stumped at the complicated roots. I am unsure of how to proceed. I even thought of looking at it as a series but I don't think I can do that. Thank you very much for your help. I greatly appreciate it.",\int_{-\infty}^{\infty} \frac{dx}{1+x^{12}},"['calculus', 'integration']"
52,When are two series the same?,When are two series the same?,,"A series is an expression of the form $$ \sum_{n=k}^{\infty} a_n $$ where the $a_n$ are real numbers and they depend on $n$. If $a_n = b_n$ for all $n\geq k$, then I would assume that one would say that the two series $$ \sum_{n=k}^{\infty} a_n\quad\text{and}\quad \sum_{n=k}^{\infty} b_n $$ are the same series. Is it true that if two series $$ \sum_{n=k}^{\infty} a_n\quad\text{and}\quad \sum_{n=k}^{\infty} b_n $$ are the same, then $a_n = b_n$ are the same for all $n$? The reason that I am asking is because I would think that the two series $$ 0 + 1 + 2 + 3 + \dots \quad\text{and}\quad 1 + 2 + 3 + 4 + \dots $$ are the same, but $0\neq 1, 1\neq 2, \dots $. So, when exactly are two series the same when considered as elements in the set of all series? Edit: Given the comment and answer below, maybe what I need to know is if it makes sense to talk about the set of all series. If this does make sense, what does it mean that two elements of this set are the same.","A series is an expression of the form $$ \sum_{n=k}^{\infty} a_n $$ where the $a_n$ are real numbers and they depend on $n$. If $a_n = b_n$ for all $n\geq k$, then I would assume that one would say that the two series $$ \sum_{n=k}^{\infty} a_n\quad\text{and}\quad \sum_{n=k}^{\infty} b_n $$ are the same series. Is it true that if two series $$ \sum_{n=k}^{\infty} a_n\quad\text{and}\quad \sum_{n=k}^{\infty} b_n $$ are the same, then $a_n = b_n$ are the same for all $n$? The reason that I am asking is because I would think that the two series $$ 0 + 1 + 2 + 3 + \dots \quad\text{and}\quad 1 + 2 + 3 + 4 + \dots $$ are the same, but $0\neq 1, 1\neq 2, \dots $. So, when exactly are two series the same when considered as elements in the set of all series? Edit: Given the comment and answer below, maybe what I need to know is if it makes sense to talk about the set of all series. If this does make sense, what does it mean that two elements of this set are the same.",,"['calculus', 'sequences-and-series']"
53,Integration being the opposite of differentiation?,Integration being the opposite of differentiation?,,"I know that if we start with an original function and take one derivative, we get another function. If we take the integral of that new function we get the original function back. So I see how they are opposite operations but I don't see how they are opposite in the sense that the integral is supposed to be the area under the curve and the derivative is supposed to be the instantaneous slope. It seems like they are separate; deriving one function is the opposite of integrating it but when we look at it graphically it doesn't make sense. Also, if I start with some function, differentiate it and then take the integral I get the original function so how is that the area under the curve? Thanks.","I know that if we start with an original function and take one derivative, we get another function. If we take the integral of that new function we get the original function back. So I see how they are opposite operations but I don't see how they are opposite in the sense that the integral is supposed to be the area under the curve and the derivative is supposed to be the instantaneous slope. It seems like they are separate; deriving one function is the opposite of integrating it but when we look at it graphically it doesn't make sense. Also, if I start with some function, differentiate it and then take the integral I get the original function so how is that the area under the curve? Thanks.",,['calculus']
54,Fourier Series for $|\cos(x)|$,Fourier Series for,|\cos(x)|,"I'm having trouble figuring out the Fourier series of $|\cos(x)|$ from $-\pi$ to $\pi$. I understand its an even function, so all the $b_n$s are $0$ $$a_0 = \frac 2 \pi \int_0^\pi |\cos(x)|\,dx = 0$$ $$a_n = \frac 2 \pi \int _0^\pi  |\cos(x)| \cos(nx) \, dx = \frac 2 \pi \int_0^\pi \cos^2(x)\,dx.$$ since for all $j,k$ not equal the integral is zero. so only $a_1$ remains. is this correct? How would I evaluate $\sum_{n=1}^\infty (-1)^{n-1} /(4n^2 - 1)\  {}$?","I'm having trouble figuring out the Fourier series of $|\cos(x)|$ from $-\pi$ to $\pi$. I understand its an even function, so all the $b_n$s are $0$ $$a_0 = \frac 2 \pi \int_0^\pi |\cos(x)|\,dx = 0$$ $$a_n = \frac 2 \pi \int _0^\pi  |\cos(x)| \cos(nx) \, dx = \frac 2 \pi \int_0^\pi \cos^2(x)\,dx.$$ since for all $j,k$ not equal the integral is zero. so only $a_1$ remains. is this correct? How would I evaluate $\sum_{n=1}^\infty (-1)^{n-1} /(4n^2 - 1)\  {}$?",,"['calculus', 'sequences-and-series', 'ordinary-differential-equations', 'fourier-analysis']"
55,Why is integration the inverse of differentiation,Why is integration the inverse of differentiation,,"Why is integration the inverse of differentiation, I mean why do I get the same function when I integrate and then differentiate the result?","Why is integration the inverse of differentiation, I mean why do I get the same function when I integrate and then differentiate the result?",,"['calculus', 'integration', 'derivatives']"
56,Evaluating a slow sum,Evaluating a slow sum,,"In my integration adventures, I came across this sum which I could not simplify: $$\sum_{n=1}^{\infty}\frac{(-1)^{n}\log(2n+1)}{2n+1}$$ Wolfram seems to believe the sum diverges and is not of much help here. Does a closed form for this sum exist?  If not, can this sum be transformed nicely that has faster convergence?","In my integration adventures, I came across this sum which I could not simplify: $$\sum_{n=1}^{\infty}\frac{(-1)^{n}\log(2n+1)}{2n+1}$$ Wolfram seems to believe the sum diverges and is not of much help here. Does a closed form for this sum exist?  If not, can this sum be transformed nicely that has faster convergence?",,"['calculus', 'sequences-and-series', 'definite-integrals']"
57,Integrate $\int_{0}^{\pi}{\frac{x\cos{x}}{1+\sin^{2}{x}}dx}$,Integrate,\int_{0}^{\pi}{\frac{x\cos{x}}{1+\sin^{2}{x}}dx},Integrate $$\displaystyle \int_{0}^{\pi}{\frac{x\cos{x}}{1+\sin^{2}{x}}dx}$$,Integrate $$\displaystyle \int_{0}^{\pi}{\frac{x\cos{x}}{1+\sin^{2}{x}}dx}$$,,"['calculus', 'integration', 'definite-integrals', 'trigonometric-integrals']"
58,Proving the continued fraction representation of $\sqrt{2}$,Proving the continued fraction representation of,\sqrt{2},"There's a question in Spivak's Calculus ( I don't happen to have the question number in front of me in the 2nd Edition, it's Chapter 21, Problem 7) that develops the concept of continued fraction, specifically the continued fraction representation of $\sqrt{2}$.  Having only recently become aware of continued fractions, I'm trying to work my way through this problem, but I'm stuck at the very last stage. Here's what I've got so far:  Let $\{a_n\}$ be the sequence defined recursively as $$a_1 = 1, a_{n + 1} = 1 + \frac{1}{1 + a_n}$$  Consider the two subsequences $\{a_{2n}\}$ and $\{a_{2n - 1}\}$.  I've already shown that $\{a_{2n}\}$ is monotonic, strictly decreasing, and bounded below by $\sqrt{2}$, and similarly I've shown that $\{a_{2n - 1}\}$ is monotonic, strictly increasing, and bounded above by $\sqrt{2}$.  Obviously, both of these subsequences converge. Although of course in general, if two subsequences of a sequence happen to converge to the same value, that doesn't guarantee that the sequence itself converges at all (much less to that same value), in the case where the subsequences are $\{a_{2n}\}$ and $\{a_{2n - 1}\}$, it's easy to show that if they both converge to the same value, then so will $\{a_n\}$ (since every term of $\{a_n\}$ is a term of one of the two subsequences).  So no problem there. In other words, it remains only to show that not only do the subsequences converge, but they converge to $\sqrt{2}$ in particular.  Take, for starters, $\{a_{2n - 1}\}$ (if I can get $\{a_{2n - 1}\}$ to converge to $\sqrt{2}$, I'm sure getting $\{a_{2n}\}$ to converge to $\sqrt{2}$ won't be very different).  Because it's strictly increasing and bounded above by $\sqrt{2}$, it converges to some number $x \leq \sqrt{2}$.  Suppose that $x < \sqrt{2}$.  We want to show this doesn't happen. But this is where I'm getting stuck.  I feel like I want to take $\epsilon = \sqrt{2} - x$ and show that there exists some $N$ such that $a_{2N - 1} > x$, which would finish the problem due to the monotonicity of $\{a_{2n - 1}\}$.  But this isn't working. Any hints?  Thanks a ton.","There's a question in Spivak's Calculus ( I don't happen to have the question number in front of me in the 2nd Edition, it's Chapter 21, Problem 7) that develops the concept of continued fraction, specifically the continued fraction representation of $\sqrt{2}$.  Having only recently become aware of continued fractions, I'm trying to work my way through this problem, but I'm stuck at the very last stage. Here's what I've got so far:  Let $\{a_n\}$ be the sequence defined recursively as $$a_1 = 1, a_{n + 1} = 1 + \frac{1}{1 + a_n}$$  Consider the two subsequences $\{a_{2n}\}$ and $\{a_{2n - 1}\}$.  I've already shown that $\{a_{2n}\}$ is monotonic, strictly decreasing, and bounded below by $\sqrt{2}$, and similarly I've shown that $\{a_{2n - 1}\}$ is monotonic, strictly increasing, and bounded above by $\sqrt{2}$.  Obviously, both of these subsequences converge. Although of course in general, if two subsequences of a sequence happen to converge to the same value, that doesn't guarantee that the sequence itself converges at all (much less to that same value), in the case where the subsequences are $\{a_{2n}\}$ and $\{a_{2n - 1}\}$, it's easy to show that if they both converge to the same value, then so will $\{a_n\}$ (since every term of $\{a_n\}$ is a term of one of the two subsequences).  So no problem there. In other words, it remains only to show that not only do the subsequences converge, but they converge to $\sqrt{2}$ in particular.  Take, for starters, $\{a_{2n - 1}\}$ (if I can get $\{a_{2n - 1}\}$ to converge to $\sqrt{2}$, I'm sure getting $\{a_{2n}\}$ to converge to $\sqrt{2}$ won't be very different).  Because it's strictly increasing and bounded above by $\sqrt{2}$, it converges to some number $x \leq \sqrt{2}$.  Suppose that $x < \sqrt{2}$.  We want to show this doesn't happen. But this is where I'm getting stuck.  I feel like I want to take $\epsilon = \sqrt{2} - x$ and show that there exists some $N$ such that $a_{2N - 1} > x$, which would finish the problem due to the monotonicity of $\{a_{2n - 1}\}$.  But this isn't working. Any hints?  Thanks a ton.",,"['calculus', 'sequences-and-series', 'continued-fractions']"
59,What's the limit of the series $\log_2(1-x)+x+x^2+x^4+x^8+\cdots$. [closed],What's the limit of the series . [closed],\log_2(1-x)+x+x^2+x^4+x^8+\cdots,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Find $$\lim_{x\to1^-}\log_2(1-x)+x+x^2+x^4+x^8+\cdots$$ I have found $1-\dfrac{1}{\ln2}$ as a lower bound, but not further than that","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Find $$\lim_{x\to1^-}\log_2(1-x)+x+x^2+x^4+x^8+\cdots$$ I have found $1-\dfrac{1}{\ln2}$ as a lower bound, but not further than that",,"['calculus', 'sequences-and-series', 'limits']"
60,"MIT Integration Bee 2017 problem:$\int_0^{\pi/2}\frac 1 {1+\tan^{2017} x} \, dx$ : Need hints [duplicate]",MIT Integration Bee 2017 problem: : Need hints [duplicate],"\int_0^{\pi/2}\frac 1 {1+\tan^{2017} x} \, dx","This question already has answers here : Evaluate the integral $\int^{\frac{\pi}{2}}_0 \frac{\sin^3x}{\sin^3x+\cos^3x}\,\mathrm dx$. [duplicate] (3 answers) Closed 6 years ago . This is a problem from MIT integration bee 2017. $$\int_0^{\pi/2} \frac 1 {1+\tan^{2017} x} \, dx$$ I have tried substitution method, multiplying numerator and denominator with $\sec^2x$ , breaking the numerator in terms of linear combination of the denominator and the derivative of it. None of these methods work. Some hints please?","This question already has answers here : Evaluate the integral $\int^{\frac{\pi}{2}}_0 \frac{\sin^3x}{\sin^3x+\cos^3x}\,\mathrm dx$. [duplicate] (3 answers) Closed 6 years ago . This is a problem from MIT integration bee 2017. I have tried substitution method, multiplying numerator and denominator with , breaking the numerator in terms of linear combination of the denominator and the derivative of it. None of these methods work. Some hints please?","\int_0^{\pi/2} \frac 1 {1+\tan^{2017} x} \, dx \sec^2x","['calculus', 'integration', 'trigonometry', 'contest-math']"
61,How to prove this series about Fibonacci number: $\sum_{n=1}^{\infty }\frac{F_{n}}{2^{n}}=2$? [duplicate],How to prove this series about Fibonacci number: ? [duplicate],\sum_{n=1}^{\infty }\frac{F_{n}}{2^{n}}=2,"This question already has answers here : Infinite Series: Fibonacci/ $2^n$ [duplicate] (3 answers) Closed 8 years ago . How to prove this series result: $$\sum_{n=1}^{\infty }\frac{F_{n}}{2^{n}}=2$$ where $F_{1}=1,~F_{2}=1,~F_n=F_{n-1}+F_{n-2},~~n\geq 3$. I have no idea where to start.","This question already has answers here : Infinite Series: Fibonacci/ $2^n$ [duplicate] (3 answers) Closed 8 years ago . How to prove this series result: $$\sum_{n=1}^{\infty }\frac{F_{n}}{2^{n}}=2$$ where $F_{1}=1,~F_{2}=1,~F_n=F_{n-1}+F_{n-2},~~n\geq 3$. I have no idea where to start.",,"['calculus', 'sequences-and-series', 'power-series', 'closed-form', 'fibonacci-numbers']"
62,Complex Conjugate of Integral,Complex Conjugate of Integral,,"I want to know that the equality $$ \overline{\int_{\mathbb R} f(x)dx} = \int_{\mathbb R} \overline{f(x)}dx $$ holds, if the both integral converges. Here $f:\mathbb R \ni x \mapsto f(x)\in \mathbb C $.","I want to know that the equality $$ \overline{\int_{\mathbb R} f(x)dx} = \int_{\mathbb R} \overline{f(x)}dx $$ holds, if the both integral converges. Here $f:\mathbb R \ni x \mapsto f(x)\in \mathbb C $.",,"['calculus', 'integration', 'complex-analysis', 'functional-analysis']"
63,Find the maximum value of $ \sqrt{x^4-3x^2-6x+13} - \sqrt{x^4-x^2+1} $ [duplicate],Find the maximum value of  [duplicate], \sqrt{x^4-3x^2-6x+13} - \sqrt{x^4-x^2+1} ,"This question already has an answer here : Absolute maximum of $f(x) = \sqrt{x^4-3x^2-6x+13}-\sqrt{x^4-x^2+1}$ (1 answer) Closed 2 years ago . If $x\in\mathbb{R}$  find the maximum value of $$ \sqrt{x^4-3x^2-6x+13} - \sqrt{x^4-x^2+1} $$ I tried this: Let $$y= \sqrt{x^4-3x^2-6x+13} - \sqrt{x^4-x^2+1}$$   For maxima $\frac{dy}{dx}=0$ and $\frac{d^2y}{dx^2} < 0$. However, the equation $\frac{dy}{dx}=0$ (after simplifying and clearing the square roots) came out to be a nine degree equation which gave me a nightmare! Moreover, simplifying the derivative was also a tedious task. I found this question in my book in the chapter on theory of equation. I can't think of an algebraic solution. Please Help! Thanks!","This question already has an answer here : Absolute maximum of $f(x) = \sqrt{x^4-3x^2-6x+13}-\sqrt{x^4-x^2+1}$ (1 answer) Closed 2 years ago . If $x\in\mathbb{R}$  find the maximum value of $$ \sqrt{x^4-3x^2-6x+13} - \sqrt{x^4-x^2+1} $$ I tried this: Let $$y= \sqrt{x^4-3x^2-6x+13} - \sqrt{x^4-x^2+1}$$   For maxima $\frac{dy}{dx}=0$ and $\frac{d^2y}{dx^2} < 0$. However, the equation $\frac{dy}{dx}=0$ (after simplifying and clearing the square roots) came out to be a nine degree equation which gave me a nightmare! Moreover, simplifying the derivative was also a tedious task. I found this question in my book in the chapter on theory of equation. I can't think of an algebraic solution. Please Help! Thanks!",,"['calculus', 'algebra-precalculus', 'polynomials', 'roots', 'radicals']"
64,Why does exponentiating the derivative yield the shift operator?,Why does exponentiating the derivative yield the shift operator?,,"If we formally exponentiate the derivative operator $\frac{d}{dx}$ on $\mathbb{R}$, we get $$e^\frac{d}{dx} = I+\frac{d}{dx}+\frac{1}{2!}\frac{d^2}{dx^2}+\frac{1}{3!}\frac{d^3}{dx^3}+ \cdots$$ Applying this operator to a real analytic function, we have $$\begin{align*}e^\frac{d}{dx} f(x) &=  f(x)+f'(x)+\frac{1}{2!}f''(x)+\cdots\\ &=f(x)+f'(x)((x+1)-x)+\frac{1}{2!}f''(x)((x+1)-x)^2+\cdots\\ &=f(x+1) \end{align*}$$ Does anyone have an explanation of why this should ""morally"" be true?  I do not have a very good intuition for the matrix exponential which is probably holding me back here...","If we formally exponentiate the derivative operator $\frac{d}{dx}$ on $\mathbb{R}$, we get $$e^\frac{d}{dx} = I+\frac{d}{dx}+\frac{1}{2!}\frac{d^2}{dx^2}+\frac{1}{3!}\frac{d^3}{dx^3}+ \cdots$$ Applying this operator to a real analytic function, we have $$\begin{align*}e^\frac{d}{dx} f(x) &=  f(x)+f'(x)+\frac{1}{2!}f''(x)+\cdots\\ &=f(x)+f'(x)((x+1)-x)+\frac{1}{2!}f''(x)((x+1)-x)^2+\cdots\\ &=f(x+1) \end{align*}$$ Does anyone have an explanation of why this should ""morally"" be true?  I do not have a very good intuition for the matrix exponential which is probably holding me back here...",,"['calculus', 'operator-theory', 'lie-groups', 'lie-algebras', 'operator-algebras']"
65,"Darboux's Integral vs. the ""High School"" Integral","Darboux's Integral vs. the ""High School"" Integral",,"The definition of the integral below is what I usually call the ""High School definition,"" because that's usually where I've seen it in use. Take a partition $\Delta = \{ x_0, x_1, x_2, \ldots, x_n\}$, where $$a = x_0 \leq x_1 \leq \cdots \leq x_{n-1} \leq x_n = b$$ of an interval $[a, b]$, such that $\Delta x_i = x_i - x_{i - 1}$ is constant, and define the norm of this partition $||\Delta||$ by $$||\Delta||=\frac{b-a}{n}.$$ Let $c_i$ be any point in $[x_{i-1}, x_i]$. If the following limit exists, then we call it the definite integral of a function $f$ on $[a, b]$.    $$\lim_{||\Delta|| \to 0}\sum_{i=1}^nf(c_i)\Delta x_i = \int_{a}^bf(x)\ dx.$$ The integral often used in more advanced textbooks (that aren't advanced enough to into Riemann-Stieltjes integrals or Lebesgue integration), which I believe is called the ""Darboux integral"", I've seen defined roughly as follows. Take a partition $\Delta$ of an interval $[a, b]$, in the same way as above, and define $$m_i=\inf\{f(x) : x_{i-1} \leq x \leq x_i \},$$ $$M_i = \sup\{ f(x) : x_{i - 1} \leq x \leq x_i \}.$$   Then, the lower and upper sums of $f$ for the partition $\Delta$ are defined as $$L(f, \Delta) = \sum_{i = 1}^n m_i(x_i - x_{i - 1}),$$ $$U(f, \Delta) = \sum_{i = 1}^n M_i(t_i - t_{i - 1}).$$ After the hassle of proving (I'm not going to type it up, as it's lengthy and irrelevant) that for any two partitions $\Delta_1, \Delta_2$, that we have $$L(f, \Delta_1) \leq U(f, \Delta_2),$$ it is stated that if we have $$\sup\{ L(f, \Delta) : \Delta\ \mathrm{is\ a\ partition\ of\ } [a, b] \} = \inf\{ U(f, \Delta) : \Delta\ \mathrm{is\ a\ partition\ of\ } [a, b] \}$$ then we define this common value to be $$\int_{a}^{b} f(x)\ dx.$$ It seems that the ""High School definition"" is significantly simpler than the Darboux integral, so my question is: why does the latter definition often appear in more advanced texts (e.g. Spivak's Calculus )? Are these two definitions equivalent, or does each have specific advantages over the other? I assume that the first definition is preferred in most lower-level classes because it avoids the need for $\sup$'s and $\inf$'s, but this still does not explain why the second definition is used in other texts (especially because it seems to take considerably more time to construct).","The definition of the integral below is what I usually call the ""High School definition,"" because that's usually where I've seen it in use. Take a partition $\Delta = \{ x_0, x_1, x_2, \ldots, x_n\}$, where $$a = x_0 \leq x_1 \leq \cdots \leq x_{n-1} \leq x_n = b$$ of an interval $[a, b]$, such that $\Delta x_i = x_i - x_{i - 1}$ is constant, and define the norm of this partition $||\Delta||$ by $$||\Delta||=\frac{b-a}{n}.$$ Let $c_i$ be any point in $[x_{i-1}, x_i]$. If the following limit exists, then we call it the definite integral of a function $f$ on $[a, b]$.    $$\lim_{||\Delta|| \to 0}\sum_{i=1}^nf(c_i)\Delta x_i = \int_{a}^bf(x)\ dx.$$ The integral often used in more advanced textbooks (that aren't advanced enough to into Riemann-Stieltjes integrals or Lebesgue integration), which I believe is called the ""Darboux integral"", I've seen defined roughly as follows. Take a partition $\Delta$ of an interval $[a, b]$, in the same way as above, and define $$m_i=\inf\{f(x) : x_{i-1} \leq x \leq x_i \},$$ $$M_i = \sup\{ f(x) : x_{i - 1} \leq x \leq x_i \}.$$   Then, the lower and upper sums of $f$ for the partition $\Delta$ are defined as $$L(f, \Delta) = \sum_{i = 1}^n m_i(x_i - x_{i - 1}),$$ $$U(f, \Delta) = \sum_{i = 1}^n M_i(t_i - t_{i - 1}).$$ After the hassle of proving (I'm not going to type it up, as it's lengthy and irrelevant) that for any two partitions $\Delta_1, \Delta_2$, that we have $$L(f, \Delta_1) \leq U(f, \Delta_2),$$ it is stated that if we have $$\sup\{ L(f, \Delta) : \Delta\ \mathrm{is\ a\ partition\ of\ } [a, b] \} = \inf\{ U(f, \Delta) : \Delta\ \mathrm{is\ a\ partition\ of\ } [a, b] \}$$ then we define this common value to be $$\int_{a}^{b} f(x)\ dx.$$ It seems that the ""High School definition"" is significantly simpler than the Darboux integral, so my question is: why does the latter definition often appear in more advanced texts (e.g. Spivak's Calculus )? Are these two definitions equivalent, or does each have specific advantages over the other? I assume that the first definition is preferred in most lower-level classes because it avoids the need for $\sup$'s and $\inf$'s, but this still does not explain why the second definition is used in other texts (especially because it seems to take considerably more time to construct).",,"['calculus', 'integration', 'education']"
66,Integral $\int_0^1\sqrt{1-x^4}dx$,Integral,\int_0^1\sqrt{1-x^4}dx,I am asked to show $\int_0^1\sqrt{1-x^4}dx=\frac{\{\Gamma(1/4)\}^2}{6\sqrt{2\pi}}$. I know the gamma function is defined by $\Gamma(n)=\int_0^\infty x^{n-1}e^{-x}dx$. I tried to substituted $x^2=\sin(t)$ but couldn't go further. I am really questioned how a radical function can convert to an exponential one? :-0 Thank you.,I am asked to show $\int_0^1\sqrt{1-x^4}dx=\frac{\{\Gamma(1/4)\}^2}{6\sqrt{2\pi}}$. I know the gamma function is defined by $\Gamma(n)=\int_0^\infty x^{n-1}e^{-x}dx$. I tried to substituted $x^2=\sin(t)$ but couldn't go further. I am really questioned how a radical function can convert to an exponential one? :-0 Thank you.,,"['calculus', 'gamma-function']"
67,Formula for curve parallel to a parabola,Formula for curve parallel to a parabola,,"I have a simple parabola in the form $y = a + bx^2$. I would like to find the formula for a curve which is parallel to this curve by distance $c$. By parallel I mean that there is an equal distance along a line perpendicular to the tangent to my curve at all points. I've established that the curve isn't in the form $y = a + c + dx^2$, whilst I can make this satisfy for $x=0$ and $x$ equal to one other number is isn't valid across the range. Any help much appreciated. Rob","I have a simple parabola in the form $y = a + bx^2$. I would like to find the formula for a curve which is parallel to this curve by distance $c$. By parallel I mean that there is an equal distance along a line perpendicular to the tangent to my curve at all points. I've established that the curve isn't in the form $y = a + c + dx^2$, whilst I can make this satisfy for $x=0$ and $x$ equal to one other number is isn't valid across the range. Any help much appreciated. Rob",,"['calculus', 'analytic-geometry', 'plane-curves', 'conic-sections']"
68,Finding the inverse of the arc length function,Finding the inverse of the arc length function,,"I'm just a simple high school math student, so please don't eat me =) In my calculus text, I have the formula: $$L(x) = \int_{c}^{x} \sqrt{[f'(t)]^2 + 1}\,dt$$ Where $L(x)$ is the arc length of a curve $f(x)$ from $c$ to $x$. How can I invert this function so that I can find valid values of $x$ to satisfy a given arc length? Something like $L^{-1}(x)$.","I'm just a simple high school math student, so please don't eat me =) In my calculus text, I have the formula: $$L(x) = \int_{c}^{x} \sqrt{[f'(t)]^2 + 1}\,dt$$ Where $L(x)$ is the arc length of a curve $f(x)$ from $c$ to $x$. How can I invert this function so that I can find valid values of $x$ to satisfy a given arc length? Something like $L^{-1}(x)$.",,['calculus']
69,Taking constants out of indefinite integrals,Taking constants out of indefinite integrals,,"In the case of definite integrals, the linearity property implies that constants can be taken out of the integrals, $$\int_{a}^{b} \alpha f(x) d x=\alpha \int_{a}^{b} f(x) d x \tag{1}$$ However, in the case of indefinite integrals, this leads to contradictory results in the case $\alpha=0$ , since $$\int 0\,dx = \int 0 \cdot 1 \,dx = 0 \int 1 \,dx = 0(x+C) = 0$$ while the derivative of any constant equals $0$ , so $\int 0\,dx =C$ . Therefore, can't constants be taken out of indefinite integrals?","In the case of definite integrals, the linearity property implies that constants can be taken out of the integrals, However, in the case of indefinite integrals, this leads to contradictory results in the case , since while the derivative of any constant equals , so . Therefore, can't constants be taken out of indefinite integrals?","\int_{a}^{b} \alpha f(x) d x=\alpha \int_{a}^{b} f(x) d x \tag{1} \alpha=0 \int 0\,dx = \int 0 \cdot 1 \,dx = 0 \int 1 \,dx = 0(x+C) = 0 0 \int 0\,dx =C","['calculus', 'indefinite-integrals']"
70,"Given $f(x)$ is continuous on $[0,1]$ and $f(f(x))=1$ for $x\in[0,1]$. Prove that $\int_0^1 f(x)\,dx > \frac34$.",Given  is continuous on  and  for . Prove that .,"f(x) [0,1] f(f(x))=1 x\in[0,1] \int_0^1 f(x)\,dx > \frac34","Let $f$ be a continuous function whose domain includes $[0,1]$ , such that $0 \le f(x) \le 1$ for all $x \in [0,1]$ , and such that $f(f(x)) = 1$ for all $x \in [0,1]$ . Prove that $\int_0^1 f(x)\,dx > \frac34$ . Here's all that I have, from the Mean Value Theorem, we have some $c\in[0,1]$ , and $a$ , such that $$a=f(c)=\int_0^1 f(x)dx.$$ By the Extreme Value Theorem, there exist some $m$ , $n\in[0,1]$ such that $$f(m)\ge f(x)\ge f(n).$$ I'm stuck here. Is this the right approach? Where do I go from here? I also got to know what the very fact that $f(f(x))=1$ shows that there is some $x$ such that $f(x)=1$ because the range of $f(x)$ is the domain of $f(x)$ (which I'm still trying to understand; I know what it means, I'm just trying to take it in).","Let be a continuous function whose domain includes , such that for all , and such that for all . Prove that . Here's all that I have, from the Mean Value Theorem, we have some , and , such that By the Extreme Value Theorem, there exist some , such that I'm stuck here. Is this the right approach? Where do I go from here? I also got to know what the very fact that shows that there is some such that because the range of is the domain of (which I'm still trying to understand; I know what it means, I'm just trying to take it in).","f [0,1] 0 \le f(x) \le 1 x \in [0,1] f(f(x)) = 1 x \in [0,1] \int_0^1 f(x)\,dx > \frac34 c\in[0,1] a a=f(c)=\int_0^1 f(x)dx. m n\in[0,1] f(m)\ge f(x)\ge f(n). f(f(x))=1 x f(x)=1 f(x) f(x)","['calculus', 'integration', 'continuity', 'proof-writing', 'extreme-value-theorem']"
71,Find $\lim_{x \to \infty} \frac{\sin{x}+\cos{x}}{x}$,Find,\lim_{x \to \infty} \frac{\sin{x}+\cos{x}}{x},"Find $$\lim_{x \to \infty} \Bigg(\frac{\sin{x}+\cos{x}}{x}\Bigg)$$ My thinking is $$-1 < \sin{x} < 1 $$ $$-1 < \cos{x} < 1.$$ Therefore $$-2 < \sin{x} + \cos{x} < 2$$ $$\frac{-2}{x} < \frac{\sin{x} + \cos{x}}{x} < \frac{2}{x}.$$ But is this even allowed? If so, why? Thanks","Find My thinking is Therefore But is this even allowed? If so, why? Thanks",\lim_{x \to \infty} \Bigg(\frac{\sin{x}+\cos{x}}{x}\Bigg) -1 < \sin{x} < 1  -1 < \cos{x} < 1. -2 < \sin{x} + \cos{x} < 2 \frac{-2}{x} < \frac{\sin{x} + \cos{x}}{x} < \frac{2}{x}.,"['calculus', 'limits', 'proof-verification', 'limits-without-lhopital']"
72,Find $\sin\frac{\pi}{3}+\frac{1}{2}\sin\frac{2\pi}{3}+\frac{1}{3}\sin\frac{3\pi}{3}+\cdots$,Find,\sin\frac{\pi}{3}+\frac{1}{2}\sin\frac{2\pi}{3}+\frac{1}{3}\sin\frac{3\pi}{3}+\cdots,"Find $$\sin\frac{\pi}{3}+\frac{1}{2}\sin\frac{2\pi}{3}+\frac{1}{3}\sin\frac{3\pi}{3}+\cdots$$ The general term is $\frac{1}{r}\sin\frac{r\pi}{3}$ Let $z=e^{i\frac{\pi}{3}}$ Then, $$\frac{1}{r}z^r=\frac{1}{r}e^{i\frac{r\pi}{3}}$$ I have to find the imaginary part of $$P=\sum_{r=1}^\infty \frac{1}{r}z^r$$ Let $$S=1+z+z^2+\cdots$$ Hence, $$P=\int_0^z Sdz=z+\frac{z^2}{2}+\frac{z^3}{3}+\cdots$$ which is the required sum. $$S=\frac{1}{1-z}$$ $$P=\int_0^z \frac{1}{1-z}dz$$ $$P=\ln\left(\frac{1}{1-z}\right)=\ln\left(\frac{1}{1-e^{i\frac{\pi}{3}}}\right)=i\frac{\pi}{3}$$ Hence, the imaginary part of $P$ is $\frac{\pi}{3}$ Is this method correct? Is there any method that does not require complex numbers?","Find $$\sin\frac{\pi}{3}+\frac{1}{2}\sin\frac{2\pi}{3}+\frac{1}{3}\sin\frac{3\pi}{3}+\cdots$$ The general term is $\frac{1}{r}\sin\frac{r\pi}{3}$ Let $z=e^{i\frac{\pi}{3}}$ Then, $$\frac{1}{r}z^r=\frac{1}{r}e^{i\frac{r\pi}{3}}$$ I have to find the imaginary part of $$P=\sum_{r=1}^\infty \frac{1}{r}z^r$$ Let $$S=1+z+z^2+\cdots$$ Hence, $$P=\int_0^z Sdz=z+\frac{z^2}{2}+\frac{z^3}{3}+\cdots$$ which is the required sum. $$S=\frac{1}{1-z}$$ $$P=\int_0^z \frac{1}{1-z}dz$$ $$P=\ln\left(\frac{1}{1-z}\right)=\ln\left(\frac{1}{1-e^{i\frac{\pi}{3}}}\right)=i\frac{\pi}{3}$$ Hence, the imaginary part of $P$ is $\frac{\pi}{3}$ Is this method correct? Is there any method that does not require complex numbers?",,"['calculus', 'algebra-precalculus', 'complex-numbers']"
73,"If $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty$, does $\lim\limits_{x\rightarrow\infty} f(x) $ exist?","If , does  exist?",\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty \lim\limits_{x\rightarrow\infty} f(x) ,"I want to prove or disprove this problem: If there exist $\lim\limits_{x\rightarrow \infty} (f'(x)+f(x))=L<\infty$ then $\lim\limits_{x\rightarrow\infty} f(x) =L$. When I assume problem below: If there exist $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty$, There exists $\lim\limits_{x\rightarrow\infty} f(x)$? I can use mean-value theorem to show that. So my question is: If $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x))=L<\infty$, does $\lim\limits_{x\rightarrow\infty} f(x)$ exist?","I want to prove or disprove this problem: If there exist $\lim\limits_{x\rightarrow \infty} (f'(x)+f(x))=L<\infty$ then $\lim\limits_{x\rightarrow\infty} f(x) =L$. When I assume problem below: If there exist $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty$, There exists $\lim\limits_{x\rightarrow\infty} f(x)$? I can use mean-value theorem to show that. So my question is: If $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x))=L<\infty$, does $\lim\limits_{x\rightarrow\infty} f(x)$ exist?",,"['calculus', 'limits']"
74,$\sum\limits_{n=1}^\infty |a_n|$ converges implies $\sum\limits_{n=1}^\infty |a_n|^2$ converges? [duplicate],converges implies  converges? [duplicate],\sum\limits_{n=1}^\infty |a_n| \sum\limits_{n=1}^\infty |a_n|^2,"This question already has answers here : Closed 11 years ago . Possible Duplicate: Prove that $\sum_{n=1}^{\infty}\ a_n^2$ is convergent if $\sum_{n=1}^{\infty}\ a_n$ is absolutely convergent If $\sum\limits_{n=1}^\infty |a_n|$ converges, the $\sum\limits_{n=1}^\infty (a_n)^2$ is also always convergent?","This question already has answers here : Closed 11 years ago . Possible Duplicate: Prove that $\sum_{n=1}^{\infty}\ a_n^2$ is convergent if $\sum_{n=1}^{\infty}\ a_n$ is absolutely convergent If $\sum\limits_{n=1}^\infty |a_n|$ converges, the $\sum\limits_{n=1}^\infty (a_n)^2$ is also always convergent?",,"['calculus', 'sequences-and-series', 'convergence-divergence']"
75,Integration by Parts implies U-substitution?,Integration by Parts implies U-substitution?,,"So I feel a bit strange asking a Calculus question, but this came up today while teaching. One can check that if you start with some integral, which can be see as an ""obvious u-substitution problem"", that you can instead use integration by parts, and wind up with the scenario where you have have the original integral on both sides of your equation so you solve for the integral. Example: Given $I=\int g^n(x)g'(x)dx$ we can clearly use u-substitution, but if we use integration by parts we get the equation $I=-nI+g^{n+1}$. This is nothing exciting or surprising, but it yields the observation that u-sub leads to one of these int by parts equations. Question Is the opposite true? What I mean to say is, if you do integration by parts and you wind up with an equation of this type, does it mean that you could of used some very clever u-substitution? I feel like I should know this, but I have thought about it today, and asked a friend or two, and we don't see an immediate proof of this. Thanks!","So I feel a bit strange asking a Calculus question, but this came up today while teaching. One can check that if you start with some integral, which can be see as an ""obvious u-substitution problem"", that you can instead use integration by parts, and wind up with the scenario where you have have the original integral on both sides of your equation so you solve for the integral. Example: Given $I=\int g^n(x)g'(x)dx$ we can clearly use u-substitution, but if we use integration by parts we get the equation $I=-nI+g^{n+1}$. This is nothing exciting or surprising, but it yields the observation that u-sub leads to one of these int by parts equations. Question Is the opposite true? What I mean to say is, if you do integration by parts and you wind up with an equation of this type, does it mean that you could of used some very clever u-substitution? I feel like I should know this, but I have thought about it today, and asked a friend or two, and we don't see an immediate proof of this. Thanks!",,['calculus']
76,Closed form for $\int_0^1\left(\frac1x-1\right)^x\mathrm dx$?,Closed form for ?,\int_0^1\left(\frac1x-1\right)^x\mathrm dx,"Is there a closed form for $I=\int_0^1\left(\frac1x-1\right)^x\mathrm dx\approx 0.838104577482$ ? That is, can $I$ be expressed in terms of known functions (elementary or otherwise) or established constants? I know this is not is not a strict definition of ""closed form""; I'm just trying to see what can be said about this integral. Wolfram does not give a closed form. Here is the graph of $y=\left(\frac1x-1\right)^x$ . (It is close to the cubic curve $y=4x^3-8x^2+3x+1$ for $0<x<1$ .) Context I'm interested in Pascal's triangle, in particular, numbers that represent the entire triangle . I found that if we take the $n$ th root of each number in Pascal's triangle, where $n$ is each number's row number, then the mean value of the resulting numbers for the entire triangle is $2\int_0^1\left(\frac1x-1\right)^x\mathrm dx\approx 1.67620915496$ . I'm wondering if this value has a closed form. Related fun fact: If we take the log of the $n$ th root of each number in Pascal's triangle, where $n$ is each number's row number, then the mean value of the resulting numbers for the entire triangle is $\dfrac12$ and  the variance is $\dfrac{21-2\pi^2}{36}$ . Related integrals $\int_0^1 \frac{1}{x^x}\mathrm dx\approx 1.2913$ (which equals $\sum\limits_{n=1}^\infty \frac{1}{n^n}$ ) does not have a closed form. $\int_0^\infty \frac{1}{x^x}\mathrm dx\approx 1.9955$ does not have a closed form (but it can be shown to be less than $2$ ).","Is there a closed form for ? That is, can be expressed in terms of known functions (elementary or otherwise) or established constants? I know this is not is not a strict definition of ""closed form""; I'm just trying to see what can be said about this integral. Wolfram does not give a closed form. Here is the graph of . (It is close to the cubic curve for .) Context I'm interested in Pascal's triangle, in particular, numbers that represent the entire triangle . I found that if we take the th root of each number in Pascal's triangle, where is each number's row number, then the mean value of the resulting numbers for the entire triangle is . I'm wondering if this value has a closed form. Related fun fact: If we take the log of the th root of each number in Pascal's triangle, where is each number's row number, then the mean value of the resulting numbers for the entire triangle is and  the variance is . Related integrals (which equals ) does not have a closed form. does not have a closed form (but it can be shown to be less than ).",I=\int_0^1\left(\frac1x-1\right)^x\mathrm dx\approx 0.838104577482 I y=\left(\frac1x-1\right)^x y=4x^3-8x^2+3x+1 0<x<1 n n 2\int_0^1\left(\frac1x-1\right)^x\mathrm dx\approx 1.67620915496 n n \dfrac12 \dfrac{21-2\pi^2}{36} \int_0^1 \frac{1}{x^x}\mathrm dx\approx 1.2913 \sum\limits_{n=1}^\infty \frac{1}{n^n} \int_0^\infty \frac{1}{x^x}\mathrm dx\approx 1.9955 2,"['calculus', 'integration', 'definite-integrals', 'binomial-coefficients', 'closed-form']"
77,Integrals of $\int_{0}^{1} \left ( \frac{K^\prime}{K} \right )^{s-1} f(k)\text{d}k$,Integrals of,\int_{0}^{1} \left ( \frac{K^\prime}{K} \right )^{s-1} f(k)\text{d}k,"Consider a type of integrals $$ \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} f(k)\text{d}k $$ where $K=K(k),K^\prime=K(\sqrt{1-k^2})$ are complete elliptic integrals, and $k$ is an elliptic modulus. $f(k)$ will be chosen if it satisfies some properties. And meanwhile their values can be obtained in brief forms(expressed by Dirichlet $L$ -series in most cases). Several cases have been considered in Question.1 , Question.2 . The paper gave out numerous and rich examples, e.g. $$ \left ( \frac{2}{\pi}  \right )^2 \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} K(k)\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-2). $$ To start, I should list the $L$ -series to be used. $$ \beta(s)=\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)^s},\eta(s)=(1-2^{1-s})\zeta(s),\lambda(s)=(1-2^{-s})\zeta(s),\\ $$ $$ L_8(s)=\sum_{n=0}^{\infty}\left ( \frac{1}{(8n+1)^s} -  \frac{1}{(8n+3)^s}- \frac{1}{(8n+5)^s}+ \frac{1}{(8n+7)^s}\right ),\\L_{-8}(s)=\sum_{n=0}^{\infty}\left ( \frac{1}{(8n+1)^s}+ \frac{1}{(8n+3)^s}- \frac{1}{(8n+5)^s}-\frac{1}{(8n+7)^s}\right ),\\ L_{-20}(s) =\sum_{n=1}^{\infty} \left ( \frac{-20}{n}  \right ) \frac{1}{n^s}. $$ $(\frac{m}{n})$ is the Kronecker symbol. The main instructions are the same as what did in the paper. Consider $$ \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} g(k)\text{d}\left ( \frac{K^\prime}{K}  \right ). $$ By making a substitution $x=K^\prime/K$ , we have $$ \int_{0}^{\infty}x^{s-1}g\left ( \frac{\theta_2(q)^2}{\theta_3(q)^2}  \right ) \text{d}x. $$ It's clear that $$ \frac{2K}{\pi} =1+2\sum_{n=1}^{\infty} \frac{1}{\cosh(\pi nx)},x=K^\prime/K. $$ Taking mellin transforms both sides. Suppose for $s$ large sufficiently, we have \begin{aligned} \int_{0}^{\infty}x^{s-1}\left ( \frac{2K}{\pi} -1 \right )\text{d}x  & = 2\int_{0}^{\infty} \sum_{n = 1}^{\infty} \frac{x^{s-1}}{\cosh(\pi n x)} \text{d} x\\ &=2\sum_{n=1}^{\infty}\frac{1}{(\pi n)^s} \int_{0}^{\infty} \frac{x^{s-1}}{\cosh(x)} \text{d}x\\ &=4\pi^{-s}\Gamma(s)\zeta(s)\beta(s). \end{aligned} Now consider series of functions, $$ f(z)=\operatorname{ns}(z,k^\prime) \left(\frac{\mathrm{d}^{2n}}{\mathrm{d}y^{2n}}  \frac{1}{\cosh(y)} \right)\Big|_{y\rightarrow\frac{\pi z}{2K} }. $$ Follow same steps we obtain: \begin{aligned} &\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{1}{(1-k^2)K(k)} \text{d}k =2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s),\\ &\left ( \frac{2}{\pi}  \right )^2 \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} K(k)\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-2),\\ &\left ( \frac{2}{\pi}  \right )^4 \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} (1-5k^2)K(k)^3\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-4),\\ &\left ( \frac{2}{\pi}  \right )^6 \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} (1-46k^2+61k^4)K(k)^5\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-6),\\ &\left ( \frac{2}{\pi}  \right )^8 \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} (1-411k^2+1731k^4-1385k^6)K(k)^7\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-8),\\ &\left ( \frac{2}{\pi}  \right )^{10} \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} (1-3692k^2+41838k^4-88412k^6+50521k^8)K(k)^9\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-10) \end{aligned} and etc. Consider $$ f(z)=\operatorname{nc}(z,k^\prime) \left(\frac{\mathrm{d}^{2n+1}}{\mathrm{d}y^{2n+1}}  \frac{1}{\cosh(y)} \right)\Big|_{y\rightarrow\frac{\pi z}{2K} }, $$ which generates $\beta(s)\beta(s-2n-1)$ : $$ \left ( \frac{2}{\pi}  \right ) \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{1}{\sqrt{1-k^2}}\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\beta(s)\beta(s-1), $$ $$ \left ( \frac{2}{\pi}  \right )^3 \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{(1-2k^2)K(k)^2}{\sqrt{1-k^2}}\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\beta(s)\beta(s-3), $$ $$ \left ( \frac{2}{\pi}  \right )^{11} \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{P_{11}(k)K(k)^{10}}{\sqrt{1-k^2}}\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\beta(s)\beta(s-11), $$ where $P_{11}(k)=1-11074k^2+210112k^4-729728k^6+884480k^8-353792k^{10}$ . Consider $$ f(z)=\operatorname{sc}(z,k^\prime) \left(\frac{\mathrm{d}^{2n}}{\mathrm{d}y^{2n}}  \frac{\cosh(y)}{\cosh(2y)} \right)\Big|_{y\rightarrow\frac{\pi z}{2K} }, $$ which generates $\lambda(s)L_{-8}(s-2n)$ . We have $$ \frac{2\sqrt{2} }{\pi^2}  \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{\left(1+k^2+\sqrt{1-k^2}\right) }{\sqrt{1-k^2}  ( 1+\sqrt{1-k^2} )^{3/2} }K(k) \text{d}k =2^{s+1}\pi^{-s}\Gamma(s)\lambda(s)L_{-8}(s-2) $$ Or can be written in a pleasant form: $$ \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{(1+3k)K(k)}{\sqrt{k(1+k)} } \text{d}k =2^{2s-1}\pi^{2-s}\Gamma(s)\lambda(s)L_{-8}(s-2). $$ Consider $$ f(z)=\operatorname{nc}(z,k^\prime) \left(\frac{\mathrm{d}^{2n+1}}{\mathrm{d}y^{2n+1}}  \frac{\cosh(y)}{\cosh(2y)} \right)\Big|_{y\rightarrow\frac{\pi z}{2K} }, $$ which generates $\beta(s)L_{-8}(s-2n-1)$ . We have $$ \frac{4\sqrt{2} }{\pi^3}  \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{\left(1-2k^2+\sqrt{1-k^2}(1+4k^2)\right) }{(1-k^2)^{3/4} \left ( 1+\sqrt{1-k^2}  \right )^{3/2} }K(k)^2\text{d}k =2^{s+1}\pi^{-s}\Gamma(s)\beta(s)L_{-8}(s-3) $$ Some other examples are considered: $$ \frac{\sqrt{2} }{\pi}  \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{1}{\sqrt{1-k^2}\sqrt{1+\sqrt{1-k^2} }  } \text{d}k =2^{s+1}\pi^{-s}\Gamma(s)\lambda(s)L_8(s-1), $$ $$\frac{4\sqrt{2} }{\pi^3}  \int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1} \frac{\left ( 1+k^2+\frac{1-5k^2}{\sqrt{1-k^2} }  \right ) }{(1+\sqrt{1-k^2})^{3/2}  }K(k)^2\text{d}k =2^{s+1}\pi^{-s}\Gamma(s)\lambda(s)L_8(s-3). $$ Question: How to discover more generalizations, or how to find a method extensively calculating these integrals?","Consider a type of integrals where are complete elliptic integrals, and is an elliptic modulus. will be chosen if it satisfies some properties. And meanwhile their values can be obtained in brief forms(expressed by Dirichlet -series in most cases). Several cases have been considered in Question.1 , Question.2 . The paper gave out numerous and rich examples, e.g. To start, I should list the -series to be used. is the Kronecker symbol. The main instructions are the same as what did in the paper. Consider By making a substitution , we have It's clear that Taking mellin transforms both sides. Suppose for large sufficiently, we have Now consider series of functions, Follow same steps we obtain: and etc. Consider which generates : where . Consider which generates . We have Or can be written in a pleasant form: Consider which generates . We have Some other examples are considered: Question: How to discover more generalizations, or how to find a method extensively calculating these integrals?","
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
f(k)\text{d}k
 K=K(k),K^\prime=K(\sqrt{1-k^2}) k f(k) L 
\left ( \frac{2}{\pi}  \right )^2
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
K(k)\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-2).
 L 
\beta(s)=\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)^s},\eta(s)=(1-2^{1-s})\zeta(s),\lambda(s)=(1-2^{-s})\zeta(s),\\
 
L_8(s)=\sum_{n=0}^{\infty}\left ( \frac{1}{(8n+1)^s}
-  \frac{1}{(8n+3)^s}- \frac{1}{(8n+5)^s}+ \frac{1}{(8n+7)^s}\right ),\\L_{-8}(s)=\sum_{n=0}^{\infty}\left ( \frac{1}{(8n+1)^s}+ \frac{1}{(8n+3)^s}- \frac{1}{(8n+5)^s}-\frac{1}{(8n+7)^s}\right ),\\
L_{-20}(s)
=\sum_{n=1}^{\infty} \left ( \frac{-20}{n}  \right )
\frac{1}{n^s}.
 (\frac{m}{n}) 
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
g(k)\text{d}\left ( \frac{K^\prime}{K}  \right ).
 x=K^\prime/K 
\int_{0}^{\infty}x^{s-1}g\left ( \frac{\theta_2(q)^2}{\theta_3(q)^2}  \right )
\text{d}x.
 
\frac{2K}{\pi} =1+2\sum_{n=1}^{\infty} \frac{1}{\cosh(\pi nx)},x=K^\prime/K.
 s \begin{aligned}
\int_{0}^{\infty}x^{s-1}\left ( \frac{2K}{\pi} -1 \right )\text{d}x 
& = 2\int_{0}^{\infty} \sum_{n = 1}^{\infty} \frac{x^{s-1}}{\cosh(\pi n x)}
\text{d} x\\
&=2\sum_{n=1}^{\infty}\frac{1}{(\pi n)^s} \int_{0}^{\infty} \frac{x^{s-1}}{\cosh(x)} \text{d}x\\
&=4\pi^{-s}\Gamma(s)\zeta(s)\beta(s).
\end{aligned} 
f(z)=\operatorname{ns}(z,k^\prime)
\left(\frac{\mathrm{d}^{2n}}{\mathrm{d}y^{2n}} 
\frac{1}{\cosh(y)} \right)\Big|_{y\rightarrow\frac{\pi z}{2K} }.
 \begin{aligned}
&\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{1}{(1-k^2)K(k)} \text{d}k
=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s),\\
&\left ( \frac{2}{\pi}  \right )^2
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
K(k)\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-2),\\
&\left ( \frac{2}{\pi}  \right )^4
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
(1-5k^2)K(k)^3\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-4),\\
&\left ( \frac{2}{\pi}  \right )^6
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
(1-46k^2+61k^4)K(k)^5\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-6),\\
&\left ( \frac{2}{\pi}  \right )^8
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
(1-411k^2+1731k^4-1385k^6)K(k)^7\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-8),\\
&\left ( \frac{2}{\pi}  \right )^{10}
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
(1-3692k^2+41838k^4-88412k^6+50521k^8)K(k)^9\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\lambda(s)\beta(s-10)
\end{aligned} 
f(z)=\operatorname{nc}(z,k^\prime)
\left(\frac{\mathrm{d}^{2n+1}}{\mathrm{d}y^{2n+1}} 
\frac{1}{\cosh(y)} \right)\Big|_{y\rightarrow\frac{\pi z}{2K} },
 \beta(s)\beta(s-2n-1) 
\left ( \frac{2}{\pi}  \right )
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{1}{\sqrt{1-k^2}}\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\beta(s)\beta(s-1),
 
\left ( \frac{2}{\pi}  \right )^3
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{(1-2k^2)K(k)^2}{\sqrt{1-k^2}}\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\beta(s)\beta(s-3),
 
\left ( \frac{2}{\pi}  \right )^{11}
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{P_{11}(k)K(k)^{10}}{\sqrt{1-k^2}}\text{d}k=2^{s+2}\pi^{-s}\Gamma(s)\beta(s)\beta(s-11),
 P_{11}(k)=1-11074k^2+210112k^4-729728k^6+884480k^8-353792k^{10} 
f(z)=\operatorname{sc}(z,k^\prime)
\left(\frac{\mathrm{d}^{2n}}{\mathrm{d}y^{2n}} 
\frac{\cosh(y)}{\cosh(2y)} \right)\Big|_{y\rightarrow\frac{\pi z}{2K} },
 \lambda(s)L_{-8}(s-2n) 
\frac{2\sqrt{2} }{\pi^2} 
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{\left(1+k^2+\sqrt{1-k^2}\right) }{\sqrt{1-k^2}  ( 1+\sqrt{1-k^2} )^{3/2} }K(k) \text{d}k
=2^{s+1}\pi^{-s}\Gamma(s)\lambda(s)L_{-8}(s-2)
 
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{(1+3k)K(k)}{\sqrt{k(1+k)} } \text{d}k
=2^{2s-1}\pi^{2-s}\Gamma(s)\lambda(s)L_{-8}(s-2).
 
f(z)=\operatorname{nc}(z,k^\prime)
\left(\frac{\mathrm{d}^{2n+1}}{\mathrm{d}y^{2n+1}} 
\frac{\cosh(y)}{\cosh(2y)} \right)\Big|_{y\rightarrow\frac{\pi z}{2K} },
 \beta(s)L_{-8}(s-2n-1) 
\frac{4\sqrt{2} }{\pi^3} 
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{\left(1-2k^2+\sqrt{1-k^2}(1+4k^2)\right) }{(1-k^2)^{3/4} \left ( 1+\sqrt{1-k^2}  \right )^{3/2} }K(k)^2\text{d}k
=2^{s+1}\pi^{-s}\Gamma(s)\beta(s)L_{-8}(s-3)
 
\frac{\sqrt{2} }{\pi} 
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{1}{\sqrt{1-k^2}\sqrt{1+\sqrt{1-k^2} }  } \text{d}k
=2^{s+1}\pi^{-s}\Gamma(s)\lambda(s)L_8(s-1),
 \frac{4\sqrt{2} }{\pi^3} 
\int_{0}^{1} \left ( \frac{K^\prime}{K}  \right )^{s-1}
\frac{\left ( 1+k^2+\frac{1-5k^2}{\sqrt{1-k^2} }  \right ) }{(1+\sqrt{1-k^2})^{3/2}  }K(k)^2\text{d}k
=2^{s+1}\pi^{-s}\Gamma(s)\lambda(s)L_8(s-3).
","['calculus', 'integration', 'contour-integration', 'elliptic-integrals', 'elliptic-functions']"
78,Partial Derivative of a Dot Product with Respect to one of its Vectors,Partial Derivative of a Dot Product with Respect to one of its Vectors,,"Say we have a function \begin{cases} f: \mathbb{R}^n \to \mathbb{R}\\ f(\mathbf{v}) = \mathbf{u}^\top \mathbf{v} \end{cases} where $\mathbf{u} \in \mathbb{R}^n$ . Apparently taking the partial derivate of $f$ with respect to $\mathbf{v}$ yields $\mathbf{u}$ : $$\frac{\partial f}{\partial \mathbf{v}} = \mathbf{u}$$ Why is that? This makes no sense to me. As $f$ returns real numbers, the rate of change in $f$ should be a real number, I would have assumed. Why is the rate of change a vector? Vectors are not even part of co-domain of $f$ . Also, what subject do I need to look into for this? I just got confronted with that isolated claim that $\frac{\partial f}{\partial \mathbf{v}} = \mathbf{u}$ , here .","Say we have a function where . Apparently taking the partial derivate of with respect to yields : Why is that? This makes no sense to me. As returns real numbers, the rate of change in should be a real number, I would have assumed. Why is the rate of change a vector? Vectors are not even part of co-domain of . Also, what subject do I need to look into for this? I just got confronted with that isolated claim that , here .","\begin{cases}
f: \mathbb{R}^n \to \mathbb{R}\\
f(\mathbf{v}) = \mathbf{u}^\top \mathbf{v}
\end{cases} \mathbf{u} \in \mathbb{R}^n f \mathbf{v} \mathbf{u} \frac{\partial f}{\partial \mathbf{v}} = \mathbf{u} f f f \frac{\partial f}{\partial \mathbf{v}} = \mathbf{u}","['calculus', 'linear-algebra', 'vector-analysis']"
79,A series with Fibonacci numbers and the golden ratio,A series with Fibonacci numbers and the golden ratio,,"How can we prove this identity: $$\sum _{n=1}^\infty\arctan\frac{(-1)^n}{\phi^{2n+1}} = \sum _{n=1}^\infty \frac{(-1)^n}{\sqrt5 \, \phi ^{4 n-2} \, (2n-1) \, F_{2n-1}},\tag{$\diamond$}$$ where $F_n$ are the Fibonacci numbers, and $\phi=\frac{1+\sqrt5}2$ is the golden ratio? Numerically, both sides look the same: $$-0.1668065238140974961621200570365353119855145764209454554444463...$$","How can we prove this identity: $$\sum _{n=1}^\infty\arctan\frac{(-1)^n}{\phi^{2n+1}} = \sum _{n=1}^\infty \frac{(-1)^n}{\sqrt5 \, \phi ^{4 n-2} \, (2n-1) \, F_{2n-1}},\tag{$\diamond$}$$ where $F_n$ are the Fibonacci numbers, and $\phi=\frac{1+\sqrt5}2$ is the golden ratio? Numerically, both sides look the same: $$-0.1668065238140974961621200570365353119855145764209454554444463...$$",,"['calculus', 'sequences-and-series', 'trigonometry', 'fibonacci-numbers', 'golden-ratio']"
80,Can there be a symbol for continuous product? [closed],Can there be a symbol for continuous product? [closed],,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question We know that continuous version of $\sum$ is $\int$, but, can there be a continuous version of $\Pi$?","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 4 years ago . Improve this question We know that continuous version of $\sum$ is $\int$, but, can there be a continuous version of $\Pi$?",,"['calculus', 'analysis', 'soft-question', 'terminology']"
81,Shortest distance from point to curve,Shortest distance from point to curve,,"I could use some help solving the following problem. I have many more like this but I figured if I learn how to do one then I can figure out the rest on my own. Thanks in advance! A curve described by the equation $y=\sqrt{16x^2+5x+16}$ on a Cartesian plane. What is the shortest distance between coordinate $(2,0)$ and this line?","I could use some help solving the following problem. I have many more like this but I figured if I learn how to do one then I can figure out the rest on my own. Thanks in advance! A curve described by the equation $y=\sqrt{16x^2+5x+16}$ on a Cartesian plane. What is the shortest distance between coordinate $(2,0)$ and this line?",,"['calculus', 'linear-algebra', 'algebra-precalculus']"
82,Conditions for integrability,Conditions for integrability,,"Michael Spivak, in his ""Calculus"" writes Although it is possible to say precisely which functions are integrable,the criterion for integrability is too difficult to be stated here I request someone to please state that condition.Thank you very much!","Michael Spivak, in his ""Calculus"" writes Although it is possible to say precisely which functions are integrable,the criterion for integrability is too difficult to be stated here I request someone to please state that condition.Thank you very much!",,['calculus']
83,"Show that $\left(\nabla_c\nabla_d-\nabla_d\nabla_c\right)v^a=R_{bcd}^av^b$ for vector field, $v$, and the Riemann curvature tensor, $R_{bcd}^a$","Show that  for vector field, , and the Riemann curvature tensor,",\left(\nabla_c\nabla_d-\nabla_d\nabla_c\right)v^a=R_{bcd}^av^b v R_{bcd}^a,"I'm going to be asking about parts of the author's solution to the following question. I feel this is a very important question to understand as it touches on some crucial aspects of the covariant derivative. Show that (without torsion) $$\left(\nabla_c\nabla_d-\nabla_d\nabla_c\right)v^a=R_{bcd}^av^b\tag{1}$$ where $$R_{bcd}^a=\partial_c\Gamma_{bd}^a-\partial_d \Gamma_{bc}^a+\Gamma_{ec}^a\Gamma_{bd}^e-\Gamma_{ed}^a\Gamma_{bc}^e$$ is the Riemann curvature tensor. Hint: determine $\nabla_c\nabla_dv^a$ . I'm trying to understand the following solution to the question above: $$\nabla_c\nabla_dv^a=\partial_c\nabla_dv^a-\Gamma_{dc}^b\nabla_b v^a+\Gamma_{bc}^a\nabla_d v^b\tag{a}$$ $$=\partial_c\left(\partial_dv^a+\Gamma_{bd}^av^b\right)-\Gamma_{dc}^b\left(\partial_bv^a+\Gamma_{eb}^av^e\right)+\Gamma_{bc}^a\left(\partial_dv^b+\Gamma_{ed}^bv^e\right)\tag{b}$$ $$=\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e + \text{contribution symmetric in $c$ and $d$ indices}\tag{c}$$ $$=\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{ec}^a\Gamma_{bd}^ev^b + \text{contribution symmetric in $c$ and $d$ indices}\tag{d}$$ on exchanging dummy $b$ and $e$ indices in the second term. Subtracting $\nabla_d\nabla_cv^a$ gives the stated result. In order for me to make sense of the author's solution, I need to understand each of the four equalities, $(\mathrm{a})-(\mathrm{d})$ , in turn. So starting with $(\mathrm{a})$ , for a contravariant vector field $v^a(x)$ , the covariant derivative, $\nabla_{\text{cov}}$ is defined through $$\nabla_{\text{cov}}v^a=\partial_{\text{cov}}v^a+\Gamma_{b,\,{\text{cov}}}^av^b\tag{2}$$ Similarly, for a covariant vector field $v_b(x)$ , the covariant derivative, $\nabla_{\text{cov}}$ is defined through $$\nabla_{\text{cov}}v_b=\partial_{\text{cov}}v_b-\Gamma_{b,\,{\text{cov}}}^av_a\tag{3}$$ [Please note that I have purposely used ' $\mathrm{cov}$ ' to represent the index for the covariant derivative, this was done to avoid writing say, ' $\nabla_c$ ', which would cause confusion with the notation that follows]. For a tensor field of type $(1,1)$ , $T_b^a$ , the covariant derivative of this tensor field, $\nabla_c$ is $$\nabla_c T_b^a=\partial_c T_{b}^a+\Gamma_{cd}^a T_{b}^d-\Gamma_{bc}^e T_{e}^a \tag{4}$$ Since the gradient of a vector field is a tensor (field), let the tensor (field) of type $(1,1)$ be $T_d^a=\nabla_d v^a$ . Now, using the hint at the end of the question and eqn $(4)$ , $$\begin{align}\nabla_c\left(\nabla_dv^a\right)&=\nabla_cT_d^a\\&=\partial_cT_d^a+\Gamma_{bc}^aT_d^b-\Gamma_{cd}^e T_e^a\\&=\partial_c\nabla_dv^a+\Gamma_{bc}^a\nabla_dv^b-\Gamma_{cd}^e \nabla_ev^a\tag{5}\end{align}$$ and this is the equivalent of $(\mathrm{a})$ in the author's solution. The next equality, $(\mathrm{b})$ , can be found by direct substitution of eqn $(2)$ into $(5)$ . To try to understand the last two equalities, $(\mathrm{c})-(\mathrm{d})$ , I multiply out eqn $(\mathrm{b})$ : $$\begin{align}\nabla_c\nabla_dv^a &=\partial_c\left(\partial_dv^a+\Gamma_{bd}^av^b\right)-\Gamma_{dc}^b\left(\partial_bv^a+\Gamma_{eb}^av^e\right)+\Gamma_{bc}^a\left(\partial_dv^b+\Gamma_{ed}^bv^e\right)\\&=\partial_c\partial_dv^a+\partial_c\Gamma_{bd}^av^b-\Gamma_{dc}^b\partial_bv^a-\Gamma_{dc}^b\Gamma_{eb}^av^e+\Gamma_{bc}^a\partial_dv^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e\tag{6}\\& \stackrel{\color{red}{?}}{=}\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e+ \text{contribution symmetric in $c$ and $d$ indices}\tag{7}\end{align}$$ But the final equality (marked with a red question mark above the equals sign) can only be true if out of the six terms in eqn $(6)$ we have $$\partial_c\partial_dv^a=-\Gamma_{dc}^b\partial_bv^a=\Gamma_{bc}^a\partial_dv^b=0\tag{8}$$ and therefore I identify $$-\Gamma_{dc}^b\Gamma_{eb}^av^e\tag{9}$$ as the contribution symmetric in $c$ and $d$ indices in $(7)$ . I'll reserve asking about part $(\mathrm{d})$ for now until I have understood part $(\mathrm{c})$ . So my questions about eqn $(\mathrm{c})$ are: What justifies those particular three terms from eqn $(6)$ being equal to zero in $(8)$ , and why are the others non-zero? Is $(9)$ the unidentified symmetric contribution in the $c$ and $d$ indices eluded to $(7)$ ? Here I embed images of the question and its' solution in case I made any typos while typesetting this post: and here is the solution: Update: Even though a good answer has already been provided the part I still can't understand is the resulting expression $(\mathrm{c})$ : $$\nabla_c\nabla_dv^a=\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e + \text{contribution symmetric in $c$ and $d$ indices}$$ I understand how $(\mathrm{d})$ was obtained from $(\mathrm{c})$ but since my question revolves almost entirely about how to get from eqn $(\mathrm{b})$ to $(\mathrm{c})$ , for the purposes of this question and to stay consistent with the answer given by @ContraKinta I will use eqn $(\mathrm{c})$ . I think the line ""contribution symmetric in $c$ and $d$ indices"" is the part causing me the most confusion. For instance, if I were to explicitly write down these 'symmetric contributions' when indices $c$ is switched with $d$ and vice versa then I think the resulting expression should be: $$\nabla_c\nabla_dv^a=\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e+\left(\partial_{\color{blue}{d}}\Gamma_{b\color{red}{c}}^a\right)v^b+\Gamma_{b \color{blue}{d}}^a\Gamma_{e\color{red}{c}}^bv^e\tag{e}$$ Where the third and fourth terms are just the first and second terms repeated, respectively, but with the positions of the $d$ and $c$ indices interchanged, as marked by the blue and red colors, respectively. But this is not what I see when I look at the full expression for $\nabla_c\nabla_dv^a$ : $$\nabla_c\nabla_dv^a=\underbrace{\partial_c\nabla_dv^a}_{(\mathrm{f})}-\underbrace{\Gamma_{dc}^b\nabla_b v^a}_{(\mathrm{g})}+\underbrace{\Gamma_{bc}^a\nabla_d v^b}_{(\mathrm{h})}$$ $$=\partial_c\left(\partial_dv^a+\Gamma_{bd}^av^b\right)-\Gamma_{dc}^b\left(\partial_bv^a+\Gamma_{eb}^av^e\right)+\Gamma_{bc}^a\left(\partial_dv^b+\Gamma_{ed}^bv^e\right)$$ $$=\partial_c\partial_dv^a+\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bd}^a\partial_cv^b\tag{f}$$ $$-\Gamma_{dc}^b\partial_bv^a-\Gamma_{dc}^b\Gamma_{eb}^av^e\tag{g}$$ $$+\Gamma_{bc}^a\partial_dv^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e\tag{h}$$ $$=\fbox{$\partial_c\partial_dv^a+\left(\partial_c\Gamma_{bd}^a\right)v^b-\Gamma_{dc}^b\partial_bv^a-\Gamma_{dc}^b\Gamma_{eb}^av^e+\Gamma_{bc}^a\Gamma_{ed}^bv^e+\Gamma_{bd}^a\partial_cv^b+\Gamma_{bc}^a\partial_dv^b$}$$ The labelled eqns ( $\mathrm{f}$ - $\mathrm{h}$ ) show the expansion of each of the terms above in the two equations above. There are in fact $7$ terms, the last two terms are symmetric in the $c$ and $d$ indices, that is, swapping the $c$ and $d$ indices in the 6th term of the boxed expression gives the 7th and final term, namely, $\Gamma_{bc}^a\partial_d  v^b$ . By comparing the boxed equation for $\nabla_c\nabla_dv^a$ and eqn $(\mathrm{c})$ , in fact, the only two terms common to both the boxed eqn and $(\mathrm{c})$ are the 2nd and 5th terms in the boxed eqn. So what happened to the other terms? More importantly, why did the 1st term, $\partial_c\partial_dv^a$ disappear? I can't invoke $\partial_c\partial_dv^a-\partial_d\partial_cv^a=0$ as explained in the answer as I have not subtracted off $\nabla_d\nabla_cv^a$ yet. For the sake of completeness I will now compute $\nabla_d\nabla_cv^a$ (though this is only for reference and is not needed to answer the questions I have here): $$\nabla_d\nabla_cv^a=\underbrace{\partial_d\nabla_cv^a}_{(\mathrm{i})}-\underbrace{\Gamma_{cd}^b\nabla_b v^a}_{(\mathrm{j})}+\underbrace{\Gamma_{bd}^a\nabla_c v^b}_{(\mathrm{k})}$$ $$=\partial_d\left(\partial_cv^a+\Gamma_{bc}^av^b\right)-\Gamma_{cd}^b\left(\partial_bv^a+\Gamma_{eb}^av^e\right)+\Gamma_{bd}^a\left(\partial_cv^b+\Gamma_{ec}^bv^e\right)$$ $$=\partial_d\partial_cv^a+\left(\partial_d\Gamma_{bc}^a\right)v^b+\Gamma_{bc}^a\partial_dv^b\tag{i}$$ $$-\Gamma_{cd}^b\partial_bv^a-\Gamma_{cd}^b\Gamma_{eb}^av^e\tag{j}$$ $$+\Gamma_{bd}^a\partial_cv^b+\Gamma_{bd}^a\Gamma_{ec}^bv^e\tag{k}$$ $$=\fbox{$\partial_d\partial_cv^a+\left(\partial_d\Gamma_{bc}^a\right)v^b-\Gamma_{cd}^b\partial_bv^a-\Gamma_{cd}^b\Gamma_{eb}^av^e+\Gamma_{bd}^a\Gamma_{ec}^bv^e+\Gamma_{bc}^a\partial_dv^b+\Gamma_{bd}^a\partial_cv^b$}$$ The eqns ( $\mathrm{i}$ - $\mathrm{k}$ ) simply represent expanded forms of the each of the terms in the equations above. I didn't want to resort to doing this and it was tedious to type this all out in full, but I did it for a reason: I am beginning to doubt myself on the validity of the boxed expressions I have worked out. For instance, what is to stop me writing the last term of the 2nd boxed expression as $\Gamma_{cd}^b\partial_bv^a$ ? This term has the same contravariant index as the LHS, $\nabla_d\nabla_cv^a$ , namely, $a$ and the same covariant indices, $d$ and $c$ on the LHS. So I know this may seem like a question in its' own right, but I consider it to be pertinent to this post, so does this mean that $\Gamma_{bd}^a\partial_cv^b=\Gamma_{cd}^b\partial_bv^a$ ? I never thought they could be equal but now I'm not so sure as the live indices are all preseved. Final remarks: Due to work commitments, I was unable to respond to this post or even self-study until now. My apologies for this and for an excessively long post, I laboured the point somewhat to convey my confusion in the most effective way I could think of. For these reasons I think that placing a bounty on this question is the least I could do. 2nd update addressing recent answers/comments: I see some very nice answers emerging, which, for the most part answers my main question; how to obtain eqn $(\mathrm{c})$ from $(\mathrm{b})$ . I would like to thank all participants for your kind help so far. One of the questions I asked that did go overlooked, was What is to stop me from writing the last term of the 2nd boxed expression as $\Gamma_{cd}^b\partial_bv^a$ ? This term has the same contravariant index as the LHS, $\nabla_d\nabla_cv^a$ , namely, $a$ and the same covariant indices, $d$ and $c$ on the LHS? In short, does the 7th (final) term of the second boxed expression satisfy $$\Gamma_{bd}^a\partial_cv^b=\Gamma_{cd}^b\partial_bv^a\tag{?}$$ If that was too vague, then put another way, am I at liberty to switch around whichever tensor indices I like (even if they belong to differential operators, etc), with the caveat that I preserve the overall labelling of the contravariant and covariant indices? If any term in the expression on the LHS or RHS has a contravariant index $a$ and covariant indices $d$ and $c$ as long as this is maintained throughout all other terms may I switch the indices to different factors of the terms ( $\Gamma_{bd}^a\partial_cv^b=\Gamma_{cd}^b\partial_bv^a$ )?","I'm going to be asking about parts of the author's solution to the following question. I feel this is a very important question to understand as it touches on some crucial aspects of the covariant derivative. Show that (without torsion) where is the Riemann curvature tensor. Hint: determine . I'm trying to understand the following solution to the question above: on exchanging dummy and indices in the second term. Subtracting gives the stated result. In order for me to make sense of the author's solution, I need to understand each of the four equalities, , in turn. So starting with , for a contravariant vector field , the covariant derivative, is defined through Similarly, for a covariant vector field , the covariant derivative, is defined through [Please note that I have purposely used ' ' to represent the index for the covariant derivative, this was done to avoid writing say, ' ', which would cause confusion with the notation that follows]. For a tensor field of type , , the covariant derivative of this tensor field, is Since the gradient of a vector field is a tensor (field), let the tensor (field) of type be . Now, using the hint at the end of the question and eqn , and this is the equivalent of in the author's solution. The next equality, , can be found by direct substitution of eqn into . To try to understand the last two equalities, , I multiply out eqn : But the final equality (marked with a red question mark above the equals sign) can only be true if out of the six terms in eqn we have and therefore I identify as the contribution symmetric in and indices in . I'll reserve asking about part for now until I have understood part . So my questions about eqn are: What justifies those particular three terms from eqn being equal to zero in , and why are the others non-zero? Is the unidentified symmetric contribution in the and indices eluded to ? Here I embed images of the question and its' solution in case I made any typos while typesetting this post: and here is the solution: Update: Even though a good answer has already been provided the part I still can't understand is the resulting expression : I understand how was obtained from but since my question revolves almost entirely about how to get from eqn to , for the purposes of this question and to stay consistent with the answer given by @ContraKinta I will use eqn . I think the line ""contribution symmetric in and indices"" is the part causing me the most confusion. For instance, if I were to explicitly write down these 'symmetric contributions' when indices is switched with and vice versa then I think the resulting expression should be: Where the third and fourth terms are just the first and second terms repeated, respectively, but with the positions of the and indices interchanged, as marked by the blue and red colors, respectively. But this is not what I see when I look at the full expression for : The labelled eqns ( - ) show the expansion of each of the terms above in the two equations above. There are in fact terms, the last two terms are symmetric in the and indices, that is, swapping the and indices in the 6th term of the boxed expression gives the 7th and final term, namely, . By comparing the boxed equation for and eqn , in fact, the only two terms common to both the boxed eqn and are the 2nd and 5th terms in the boxed eqn. So what happened to the other terms? More importantly, why did the 1st term, disappear? I can't invoke as explained in the answer as I have not subtracted off yet. For the sake of completeness I will now compute (though this is only for reference and is not needed to answer the questions I have here): The eqns ( - ) simply represent expanded forms of the each of the terms in the equations above. I didn't want to resort to doing this and it was tedious to type this all out in full, but I did it for a reason: I am beginning to doubt myself on the validity of the boxed expressions I have worked out. For instance, what is to stop me writing the last term of the 2nd boxed expression as ? This term has the same contravariant index as the LHS, , namely, and the same covariant indices, and on the LHS. So I know this may seem like a question in its' own right, but I consider it to be pertinent to this post, so does this mean that ? I never thought they could be equal but now I'm not so sure as the live indices are all preseved. Final remarks: Due to work commitments, I was unable to respond to this post or even self-study until now. My apologies for this and for an excessively long post, I laboured the point somewhat to convey my confusion in the most effective way I could think of. For these reasons I think that placing a bounty on this question is the least I could do. 2nd update addressing recent answers/comments: I see some very nice answers emerging, which, for the most part answers my main question; how to obtain eqn from . I would like to thank all participants for your kind help so far. One of the questions I asked that did go overlooked, was What is to stop me from writing the last term of the 2nd boxed expression as ? This term has the same contravariant index as the LHS, , namely, and the same covariant indices, and on the LHS? In short, does the 7th (final) term of the second boxed expression satisfy If that was too vague, then put another way, am I at liberty to switch around whichever tensor indices I like (even if they belong to differential operators, etc), with the caveat that I preserve the overall labelling of the contravariant and covariant indices? If any term in the expression on the LHS or RHS has a contravariant index and covariant indices and as long as this is maintained throughout all other terms may I switch the indices to different factors of the terms ( )?","\left(\nabla_c\nabla_d-\nabla_d\nabla_c\right)v^a=R_{bcd}^av^b\tag{1} R_{bcd}^a=\partial_c\Gamma_{bd}^a-\partial_d \Gamma_{bc}^a+\Gamma_{ec}^a\Gamma_{bd}^e-\Gamma_{ed}^a\Gamma_{bc}^e \nabla_c\nabla_dv^a \nabla_c\nabla_dv^a=\partial_c\nabla_dv^a-\Gamma_{dc}^b\nabla_b v^a+\Gamma_{bc}^a\nabla_d v^b\tag{a} =\partial_c\left(\partial_dv^a+\Gamma_{bd}^av^b\right)-\Gamma_{dc}^b\left(\partial_bv^a+\Gamma_{eb}^av^e\right)+\Gamma_{bc}^a\left(\partial_dv^b+\Gamma_{ed}^bv^e\right)\tag{b} =\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e + \text{contribution symmetric in c and d indices}\tag{c} =\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{ec}^a\Gamma_{bd}^ev^b + \text{contribution symmetric in c and d indices}\tag{d} b e \nabla_d\nabla_cv^a (\mathrm{a})-(\mathrm{d}) (\mathrm{a}) v^a(x) \nabla_{\text{cov}} \nabla_{\text{cov}}v^a=\partial_{\text{cov}}v^a+\Gamma_{b,\,{\text{cov}}}^av^b\tag{2} v_b(x) \nabla_{\text{cov}} \nabla_{\text{cov}}v_b=\partial_{\text{cov}}v_b-\Gamma_{b,\,{\text{cov}}}^av_a\tag{3} \mathrm{cov} \nabla_c (1,1) T_b^a \nabla_c \nabla_c T_b^a=\partial_c T_{b}^a+\Gamma_{cd}^a T_{b}^d-\Gamma_{bc}^e T_{e}^a \tag{4} (1,1) T_d^a=\nabla_d v^a (4) \begin{align}\nabla_c\left(\nabla_dv^a\right)&=\nabla_cT_d^a\\&=\partial_cT_d^a+\Gamma_{bc}^aT_d^b-\Gamma_{cd}^e T_e^a\\&=\partial_c\nabla_dv^a+\Gamma_{bc}^a\nabla_dv^b-\Gamma_{cd}^e \nabla_ev^a\tag{5}\end{align} (\mathrm{a}) (\mathrm{b}) (2) (5) (\mathrm{c})-(\mathrm{d}) (\mathrm{b}) \begin{align}\nabla_c\nabla_dv^a &=\partial_c\left(\partial_dv^a+\Gamma_{bd}^av^b\right)-\Gamma_{dc}^b\left(\partial_bv^a+\Gamma_{eb}^av^e\right)+\Gamma_{bc}^a\left(\partial_dv^b+\Gamma_{ed}^bv^e\right)\\&=\partial_c\partial_dv^a+\partial_c\Gamma_{bd}^av^b-\Gamma_{dc}^b\partial_bv^a-\Gamma_{dc}^b\Gamma_{eb}^av^e+\Gamma_{bc}^a\partial_dv^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e\tag{6}\\& \stackrel{\color{red}{?}}{=}\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e+ \text{contribution symmetric in c and d indices}\tag{7}\end{align} (6) \partial_c\partial_dv^a=-\Gamma_{dc}^b\partial_bv^a=\Gamma_{bc}^a\partial_dv^b=0\tag{8} -\Gamma_{dc}^b\Gamma_{eb}^av^e\tag{9} c d (7) (\mathrm{d}) (\mathrm{c}) (\mathrm{c}) (6) (8) (9) c d (7) (\mathrm{c}) \nabla_c\nabla_dv^a=\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e + \text{contribution symmetric in c and d indices} (\mathrm{d}) (\mathrm{c}) (\mathrm{b}) (\mathrm{c}) (\mathrm{c}) c d c d \nabla_c\nabla_dv^a=\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e+\left(\partial_{\color{blue}{d}}\Gamma_{b\color{red}{c}}^a\right)v^b+\Gamma_{b \color{blue}{d}}^a\Gamma_{e\color{red}{c}}^bv^e\tag{e} d c \nabla_c\nabla_dv^a \nabla_c\nabla_dv^a=\underbrace{\partial_c\nabla_dv^a}_{(\mathrm{f})}-\underbrace{\Gamma_{dc}^b\nabla_b v^a}_{(\mathrm{g})}+\underbrace{\Gamma_{bc}^a\nabla_d v^b}_{(\mathrm{h})} =\partial_c\left(\partial_dv^a+\Gamma_{bd}^av^b\right)-\Gamma_{dc}^b\left(\partial_bv^a+\Gamma_{eb}^av^e\right)+\Gamma_{bc}^a\left(\partial_dv^b+\Gamma_{ed}^bv^e\right) =\partial_c\partial_dv^a+\left(\partial_c\Gamma_{bd}^a\right)v^b+\Gamma_{bd}^a\partial_cv^b\tag{f} -\Gamma_{dc}^b\partial_bv^a-\Gamma_{dc}^b\Gamma_{eb}^av^e\tag{g} +\Gamma_{bc}^a\partial_dv^b+\Gamma_{bc}^a\Gamma_{ed}^bv^e\tag{h} =\fbox{\partial_c\partial_dv^a+\left(\partial_c\Gamma_{bd}^a\right)v^b-\Gamma_{dc}^b\partial_bv^a-\Gamma_{dc}^b\Gamma_{eb}^av^e+\Gamma_{bc}^a\Gamma_{ed}^bv^e+\Gamma_{bd}^a\partial_cv^b+\Gamma_{bc}^a\partial_dv^b} \mathrm{f} \mathrm{h} 7 c d c d \Gamma_{bc}^a\partial_d 
v^b \nabla_c\nabla_dv^a (\mathrm{c}) (\mathrm{c}) \partial_c\partial_dv^a \partial_c\partial_dv^a-\partial_d\partial_cv^a=0 \nabla_d\nabla_cv^a \nabla_d\nabla_cv^a \nabla_d\nabla_cv^a=\underbrace{\partial_d\nabla_cv^a}_{(\mathrm{i})}-\underbrace{\Gamma_{cd}^b\nabla_b v^a}_{(\mathrm{j})}+\underbrace{\Gamma_{bd}^a\nabla_c v^b}_{(\mathrm{k})} =\partial_d\left(\partial_cv^a+\Gamma_{bc}^av^b\right)-\Gamma_{cd}^b\left(\partial_bv^a+\Gamma_{eb}^av^e\right)+\Gamma_{bd}^a\left(\partial_cv^b+\Gamma_{ec}^bv^e\right) =\partial_d\partial_cv^a+\left(\partial_d\Gamma_{bc}^a\right)v^b+\Gamma_{bc}^a\partial_dv^b\tag{i} -\Gamma_{cd}^b\partial_bv^a-\Gamma_{cd}^b\Gamma_{eb}^av^e\tag{j} +\Gamma_{bd}^a\partial_cv^b+\Gamma_{bd}^a\Gamma_{ec}^bv^e\tag{k} =\fbox{\partial_d\partial_cv^a+\left(\partial_d\Gamma_{bc}^a\right)v^b-\Gamma_{cd}^b\partial_bv^a-\Gamma_{cd}^b\Gamma_{eb}^av^e+\Gamma_{bd}^a\Gamma_{ec}^bv^e+\Gamma_{bc}^a\partial_dv^b+\Gamma_{bd}^a\partial_cv^b} \mathrm{i} \mathrm{k} \Gamma_{cd}^b\partial_bv^a \nabla_d\nabla_cv^a a d c \Gamma_{bd}^a\partial_cv^b=\Gamma_{cd}^b\partial_bv^a (\mathrm{c}) (\mathrm{b}) \Gamma_{cd}^b\partial_bv^a \nabla_d\nabla_cv^a a d c \Gamma_{bd}^a\partial_cv^b=\Gamma_{cd}^b\partial_bv^a\tag{?} a d c \Gamma_{bd}^a\partial_cv^b=\Gamma_{cd}^b\partial_bv^a","['calculus', 'proof-explanation', 'riemannian-geometry', 'tensors', 'connections']"
84,Prove $\int_0^1 \frac{dx}{(x-2) \sqrt[5]{x^2{(1-x)}^3}} = -\frac{2^{11/10} \pi}{\sqrt{5+\sqrt{5}}}$,Prove,\int_0^1 \frac{dx}{(x-2) \sqrt[5]{x^2{(1-x)}^3}} = -\frac{2^{11/10} \pi}{\sqrt{5+\sqrt{5}}},"$$ \mbox{Prove}\quad \int_{0}^{1}{\mathrm{d}x \over \left(\,{x - 2}\,\right)\, \sqrt[\Large 5]{\,x^{2}\,\left(\,{1 - x}\,\right)^{3}\,}\,} = -\,{2^{11/10}\,\pi \over \,\sqrt{\,{5 + \,\sqrt{\,{5}\,}}\,}\,} $$ Being honest I havent got a clue where to start.  I dont think any obvious substitutions will help ( $x \to 1-x, \frac{1}{x}, \sqrt{x},$ more). The indefinite integral involves hypergeometric function so some miracle substitution has to work with the bounds I suspect. Maybe gamma function is involved some how ??. If anyone has an idea and can provide help I would appreciate it.",Being honest I havent got a clue where to start.  I dont think any obvious substitutions will help ( more). The indefinite integral involves hypergeometric function so some miracle substitution has to work with the bounds I suspect. Maybe gamma function is involved some how ??. If anyone has an idea and can provide help I would appreciate it.,"
\mbox{Prove}\quad
\int_{0}^{1}{\mathrm{d}x \over
\left(\,{x - 2}\,\right)\,
\sqrt[\Large 5]{\,x^{2}\,\left(\,{1 - x}\,\right)^{3}\,}\,}
=
-\,{2^{11/10}\,\pi \over \,\sqrt{\,{5 + \,\sqrt{\,{5}\,}}\,}\,}
 x \to 1-x, \frac{1}{x}, \sqrt{x},","['calculus', 'integration']"
85,Why does this $u$-substitution zero out my integral?,Why does this -substitution zero out my integral?,u,"Here's how I understand $u$-substitution working for an integral. Essentially, it involves substitution of differential expressions, allowing you to cancel out terms of the integrand. When we change the limits of integration, we essentially evaluate $u(x)$ to make sure the value stays the same. $$ \begin{gather*} \int_{x=0}^{x=2} \frac{x}{\sqrt{1 + x^2}} \, dx \\ \text{let $u = 1 + x^2$ so $du = 2x \, dx$ and $dx = \frac{1}{2} du / x$} \\ \int_{u=1}^{u=5} \frac{\color{red}{x}}{\sqrt{u}} \, \left( \frac{1}{2\color{red}{x}} du \right) \\ \frac{1}{2} \int_{u=1}^{u=5} u^{-1/2} \, du \\ \frac{1}{2} \left( \left. 2\sqrt{u} \  \right|_{u=1}^{u=5} \right) \\ \sqrt{5} - 1. \end{gather*} $$ That's all well and good. But I can choose anything for my $u$-expression. What if I wanted to let $u = (x)(x - 2)$? Then the limits of integration are $$\int_{u=(0)(0-2)}^{u=(2)(2-2)} \implies \int_{u=0}^{u=0}$$ and so the whole integral becomes zero. Clearly this is invalid. The correct result for the integral is indeed $\sqrt{5} - 1$. But what am I missing here? Why can't I set the integral up like this? My thoughts: This is a definite integral, so there's no ""$+ C$"" constant of integration business going on. (Right?) Even if you end up having some $x$s in your expression because the $u$-substitution doesn't cancel them out, that doesn't matter because you're still integrating over an empty domain. (Right?) Plus, I can also get this to ""work"" with $\int_{y=-r}^{y=r} (r^2-y^2)^{-1/2}y^2\,dy$ with $u = r^2-y^2$, and that can be expressed as $\int_{u=0}^{u=0} u^{-1/2}\sqrt{r^2-u} \, du$, which is completely in terms of $u$. (I think?) Does it have something to do with the multiple solutions of quadratic equations? How do I know when I'm doing this by mistake? It seems like it could be pretty subtle.","Here's how I understand $u$-substitution working for an integral. Essentially, it involves substitution of differential expressions, allowing you to cancel out terms of the integrand. When we change the limits of integration, we essentially evaluate $u(x)$ to make sure the value stays the same. $$ \begin{gather*} \int_{x=0}^{x=2} \frac{x}{\sqrt{1 + x^2}} \, dx \\ \text{let $u = 1 + x^2$ so $du = 2x \, dx$ and $dx = \frac{1}{2} du / x$} \\ \int_{u=1}^{u=5} \frac{\color{red}{x}}{\sqrt{u}} \, \left( \frac{1}{2\color{red}{x}} du \right) \\ \frac{1}{2} \int_{u=1}^{u=5} u^{-1/2} \, du \\ \frac{1}{2} \left( \left. 2\sqrt{u} \  \right|_{u=1}^{u=5} \right) \\ \sqrt{5} - 1. \end{gather*} $$ That's all well and good. But I can choose anything for my $u$-expression. What if I wanted to let $u = (x)(x - 2)$? Then the limits of integration are $$\int_{u=(0)(0-2)}^{u=(2)(2-2)} \implies \int_{u=0}^{u=0}$$ and so the whole integral becomes zero. Clearly this is invalid. The correct result for the integral is indeed $\sqrt{5} - 1$. But what am I missing here? Why can't I set the integral up like this? My thoughts: This is a definite integral, so there's no ""$+ C$"" constant of integration business going on. (Right?) Even if you end up having some $x$s in your expression because the $u$-substitution doesn't cancel them out, that doesn't matter because you're still integrating over an empty domain. (Right?) Plus, I can also get this to ""work"" with $\int_{y=-r}^{y=r} (r^2-y^2)^{-1/2}y^2\,dy$ with $u = r^2-y^2$, and that can be expressed as $\int_{u=0}^{u=0} u^{-1/2}\sqrt{r^2-u} \, du$, which is completely in terms of $u$. (I think?) Does it have something to do with the multiple solutions of quadratic equations? How do I know when I'm doing this by mistake? It seems like it could be pretty subtle.",,"['calculus', 'integration', 'fake-proofs']"
86,Evaluating some Limits as Riemann sums.,Evaluating some Limits as Riemann sums.,,"I really have difficulties with Riemann Sums, especially the ones as below: $$\lim_{n\to\infty} \left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{3n}\right)$$ When i try to write this as a sum, it becomes $$\frac { 1 }{ n } \sum _{ k=1 }^{ 2n } \frac { 1 }{ 1+\frac { k }{ n }  } .$$   The problem is, however, to be able to compute this limit as an integral I need to have this sum from $1$ to $n$. There are some other questions like this, but if I can understand it, I will be able solve others.","I really have difficulties with Riemann Sums, especially the ones as below: $$\lim_{n\to\infty} \left(\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{3n}\right)$$ When i try to write this as a sum, it becomes $$\frac { 1 }{ n } \sum _{ k=1 }^{ 2n } \frac { 1 }{ 1+\frac { k }{ n }  } .$$   The problem is, however, to be able to compute this limit as an integral I need to have this sum from $1$ to $n$. There are some other questions like this, but if I can understand it, I will be able solve others.",,"['calculus', 'limits', 'definite-integrals', 'riemann-sum']"
87,What is the difference between Riemann and Riemann-Stieltjes integrals?,What is the difference between Riemann and Riemann-Stieltjes integrals?,,"I'm quite confused, what is the difference between these two integrals (R and RS)? It seems that RS is closer to Lebesgue in its treatment of discontinuities, but otherwise I don't understand. If someone could give an example of a function for which they were different, it would be very beneficial. Thanks.","I'm quite confused, what is the difference between these two integrals (R and RS)? It seems that RS is closer to Lebesgue in its treatment of discontinuities, but otherwise I don't understand. If someone could give an example of a function for which they were different, it would be very beneficial. Thanks.",,"['calculus', 'integration', 'riemann-integration']"
88,Sufficient and necessary condition for strictly monotone differentiable functions,Sufficient and necessary condition for strictly monotone differentiable functions,,"I read from a book without proof the following theorem: Let $f(x)$ be a differentiable function, then $f(x)$ is strictly increasing if and only if $f'(x) \geq 0$, and $f'(x) \gt 0$ almost everywhere. Is it correct? I doubt, but I could neither prove it nor give a counter example.","I read from a book without proof the following theorem: Let $f(x)$ be a differentiable function, then $f(x)$ is strictly increasing if and only if $f'(x) \geq 0$, and $f'(x) \gt 0$ almost everywhere. Is it correct? I doubt, but I could neither prove it nor give a counter example.",,"['calculus', 'analysis']"
89,At what point of mathematical education can you start inventing new math?,At what point of mathematical education can you start inventing new math?,,"I am a 2nd year student doing an honors program in math and statistics. Everything that I have been learning has been formulas, theorems, and mathematical concepts that other people have discovered/invented/created. Some very simplistic formulas I am able to modify to meet the needs of what I am trying to accomplish, but still I am using someone else discoveries as a basis for what I am modifying. Friends and family say I am becoming a mathematician, but I dont feel that way as I do not have the ability to invent/create/discover new math, I am simply regurgitating what others have discovered. At what point in your mathematical education are you able to invent new math? For example, the linear regression formula. How did Francis Galton know that the formula he created would accomplish what he wanted to accomplish? Note: Sorry to the editors as I could not find a relevant tag for this question.","I am a 2nd year student doing an honors program in math and statistics. Everything that I have been learning has been formulas, theorems, and mathematical concepts that other people have discovered/invented/created. Some very simplistic formulas I am able to modify to meet the needs of what I am trying to accomplish, but still I am using someone else discoveries as a basis for what I am modifying. Friends and family say I am becoming a mathematician, but I dont feel that way as I do not have the ability to invent/create/discover new math, I am simply regurgitating what others have discovered. At what point in your mathematical education are you able to invent new math? For example, the linear regression formula. How did Francis Galton know that the formula he created would accomplish what he wanted to accomplish? Note: Sorry to the editors as I could not find a relevant tag for this question.",,['calculus']
90,"Closed-form of $\int_0^1 \frac{\ln^2(x)}{\sqrt{x(a-bx)}}\,dx$",Closed-form of,"\int_0^1 \frac{\ln^2(x)}{\sqrt{x(a-bx)}}\,dx","I'm interesed in the following integral, for $a,b>0$: $$ \mathcal{I}(a,b) := \int_0^1 \frac{\ln^2(x)}{\sqrt{x(a-bx)}}\,dx $$ Mathematica could evaluate it in term of hypergeometric functions, but I'm looking for a simpler closed-form. If it is too difficult, then it would be nice to see a proof for the following two special cases: $$\begin{align} \mathcal{I}(1,1) &= \int_0^1 \frac{\ln^2(x)}{\sqrt{x(1-x)}}\,dx = \frac{\pi^3}{3}+4\pi\ln^2(2)\\ \mathcal{I}(4,1) &= \int_0^1 \frac{\ln^2(x)}{\sqrt{x(4-x)}}\,dx = \frac{7\pi^3}{27} \end{align}$$ Any other simple special case are welcome.","I'm interesed in the following integral, for $a,b>0$: $$ \mathcal{I}(a,b) := \int_0^1 \frac{\ln^2(x)}{\sqrt{x(a-bx)}}\,dx $$ Mathematica could evaluate it in term of hypergeometric functions, but I'm looking for a simpler closed-form. If it is too difficult, then it would be nice to see a proof for the following two special cases: $$\begin{align} \mathcal{I}(1,1) &= \int_0^1 \frac{\ln^2(x)}{\sqrt{x(1-x)}}\,dx = \frac{\pi^3}{3}+4\pi\ln^2(2)\\ \mathcal{I}(4,1) &= \int_0^1 \frac{\ln^2(x)}{\sqrt{x(4-x)}}\,dx = \frac{7\pi^3}{27} \end{align}$$ Any other simple special case are welcome.",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
91,"Closed form of $\int_0^1\int_0^1\int_0^1\frac{\left(1-x^y\right)\left(1-x^z\right)\ln x}{(1-x)^3}\,\mathrm dx\;\mathrm dy\;\mathrm dz$",Closed form of,"\int_0^1\int_0^1\int_0^1\frac{\left(1-x^y\right)\left(1-x^z\right)\ln x}{(1-x)^3}\,\mathrm dx\;\mathrm dy\;\mathrm dz","While trying to find several references to answer Pranav's problem , I encounter the following multiple integrals $$I=\int_0^1\int_0^1\int_0^1\frac{\left(1-x^y\right)\left(1-x^z\right)\ln x}{(1-x)^3}\,\mathrm dx\;\mathrm dy\;\mathrm dz$$ Question : Does the above integral have a closed form? If it has a closed form, how to obtain it? According to Chriss'sis in the chat room , the integral has a nice closed form $$\frac{2\ln 2 \pi -2 \gamma -5}{4}$$ but no proof given so far. Since the term $\ln 2 \pi$ appears in the close form, I have a hunch that it would involve Stirling's approximation. After trying to evaluate it for hours, I think it is about time to ask it on the main page. Here is my attempt so far: \begin{align} I&=\int_0^1\int_0^1\left(1-x^y\right)\;\mathrm dy\int_0^1\left(1-x^z\right)\;\mathrm dz\frac{\ln x}{(1-x)^3}\,\mathrm dx\\[7pt] &=\int_0^1\frac{\ln x+1-x}{\ln x}\cdot\frac{\ln x+1-x}{\ln x}\cdot\frac{\ln x}{(1-x)^3}\,\mathrm dx\\[7pt] &=\int_0^1\frac{\left(\ln x+1-x\right)^2}{(1-x)^3\ln x}\,\mathrm dx\\ \end{align} I'm stuck in the latter expression. I'm thinking of the following parametric integral $$I(s)=\int_0^1\frac{x^s\left(\ln x+1-x\right)^2}{(1-x)^3\ln x}\,\mathrm dx\quad\implies\quad I'(s)=\int_0^1\frac{x^s\left(\ln x+1-x\right)^2}{(1-x)^3}\,\mathrm dx$$ then expanding the quadratic term and using series representation of $$\frac{1}{(1-x)^3}=\frac{1}{2}\sum_{n=1}^\infty n(n-1)x^{n-2}$$  but the calculation would be cumbersome. Is there a better way? Thanks in advance for your help.","While trying to find several references to answer Pranav's problem , I encounter the following multiple integrals $$I=\int_0^1\int_0^1\int_0^1\frac{\left(1-x^y\right)\left(1-x^z\right)\ln x}{(1-x)^3}\,\mathrm dx\;\mathrm dy\;\mathrm dz$$ Question : Does the above integral have a closed form? If it has a closed form, how to obtain it? According to Chriss'sis in the chat room , the integral has a nice closed form $$\frac{2\ln 2 \pi -2 \gamma -5}{4}$$ but no proof given so far. Since the term $\ln 2 \pi$ appears in the close form, I have a hunch that it would involve Stirling's approximation. After trying to evaluate it for hours, I think it is about time to ask it on the main page. Here is my attempt so far: \begin{align} I&=\int_0^1\int_0^1\left(1-x^y\right)\;\mathrm dy\int_0^1\left(1-x^z\right)\;\mathrm dz\frac{\ln x}{(1-x)^3}\,\mathrm dx\\[7pt] &=\int_0^1\frac{\ln x+1-x}{\ln x}\cdot\frac{\ln x+1-x}{\ln x}\cdot\frac{\ln x}{(1-x)^3}\,\mathrm dx\\[7pt] &=\int_0^1\frac{\left(\ln x+1-x\right)^2}{(1-x)^3\ln x}\,\mathrm dx\\ \end{align} I'm stuck in the latter expression. I'm thinking of the following parametric integral $$I(s)=\int_0^1\frac{x^s\left(\ln x+1-x\right)^2}{(1-x)^3\ln x}\,\mathrm dx\quad\implies\quad I'(s)=\int_0^1\frac{x^s\left(\ln x+1-x\right)^2}{(1-x)^3}\,\mathrm dx$$ then expanding the quadratic term and using series representation of $$\frac{1}{(1-x)^3}=\frac{1}{2}\sum_{n=1}^\infty n(n-1)x^{n-2}$$  but the calculation would be cumbersome. Is there a better way? Thanks in advance for your help.",,"['calculus', 'integration', 'definite-integrals', 'improper-integrals', 'closed-form']"
92,Differentiation of a function $f:\mathbb{Q}\to \mathbb{Q}$(Rational Calculus),Differentiation of a function (Rational Calculus),f:\mathbb{Q}\to \mathbb{Q},"Assume that $f:\mathbb{Q}\to \mathbb{Q}$ is  given such that $\forall   a\in \mathbb{Q}$ the following limit, exists \begin{equation} \lim_{x\to a}  \frac{f(x)-f(a)}{x-a}\in \mathbb{R} \end{equation} Is it true  to say that the above limit is  a rational number?","Assume that $f:\mathbb{Q}\to \mathbb{Q}$ is  given such that $\forall   a\in \mathbb{Q}$ the following limit, exists \begin{equation} \lim_{x\to a}  \frac{f(x)-f(a)}{x-a}\in \mathbb{R} \end{equation} Is it true  to say that the above limit is  a rational number?",,"['calculus', 'functions', 'derivatives', 'rational-numbers']"
93,"chain rule using tree diagram, why does it work?","chain rule using tree diagram, why does it work?",,"In multivariable calculus, I was taught to compute the chain rule by drawing a ""tree diagram"" (a directed acyclic graph) representing the dependence of one variable on the others. I now want to understand the theory behind it. Examples: Let $y$ and $x$ both be functions of $t$. Let $z$ be a function of both $x$ and $y$. The derivative of z with respect to t is: $$\frac{dz}{dt} = \frac{\partial z}{\partial x} \frac{dx}{dt} + \frac{\partial z}{\partial y} \frac{dy}{dt}$$ To compute this derivative, I was taught to draw a graph with the following edges: $x \to z$, $y \to z$, $t \to x$, and $t \to y$. Source: http://www.math.hmc.edu/calculus/tutorials/multichainrule/ These tree diagrams can be constructed for arbitrarily complex functions with many variables. In general, to find a derivative of a dependent variable with respect to an independent variable, you need to take the sum of all of the different paths to reach the dependent variable from the independent variable. Traveling down a path, you multiply the functions (e.g. $\frac{\partial z}{\partial x} \cdot \frac{dx}{dt}$). Why does this work?","In multivariable calculus, I was taught to compute the chain rule by drawing a ""tree diagram"" (a directed acyclic graph) representing the dependence of one variable on the others. I now want to understand the theory behind it. Examples: Let $y$ and $x$ both be functions of $t$. Let $z$ be a function of both $x$ and $y$. The derivative of z with respect to t is: $$\frac{dz}{dt} = \frac{\partial z}{\partial x} \frac{dx}{dt} + \frac{\partial z}{\partial y} \frac{dy}{dt}$$ To compute this derivative, I was taught to draw a graph with the following edges: $x \to z$, $y \to z$, $t \to x$, and $t \to y$. Source: http://www.math.hmc.edu/calculus/tutorials/multichainrule/ These tree diagrams can be constructed for arbitrarily complex functions with many variables. In general, to find a derivative of a dependent variable with respect to an independent variable, you need to take the sum of all of the different paths to reach the dependent variable from the independent variable. Traveling down a path, you multiply the functions (e.g. $\frac{\partial z}{\partial x} \cdot \frac{dx}{dt}$). Why does this work?",,"['calculus', 'graph-theory', 'functions']"
94,Did the directional derivative get developed before the gradient?,Did the directional derivative get developed before the gradient?,,"In learning multivariable calculus, I've often seen the gradient introduced before the directional derivative. To me this is backwards. Once we have partials, we treat then as rates of change in the direction of the axes. We should then naturally ask ""what if the direction were not aligned with the axes?"". From there, a natural question of ""in which direction is the rate of change maximal?"" Seems to arise.  In the development of calculus, which came first? I find that by introducing the gradient before directional derivatives it seems like some arbitrary vector that was pulled out of no where. It only seems to make sense once we understand directional derivatives.","In learning multivariable calculus, I've often seen the gradient introduced before the directional derivative. To me this is backwards. Once we have partials, we treat then as rates of change in the direction of the axes. We should then naturally ask ""what if the direction were not aligned with the axes?"". From there, a natural question of ""in which direction is the rate of change maximal?"" Seems to arise.  In the development of calculus, which came first? I find that by introducing the gradient before directional derivatives it seems like some arbitrary vector that was pulled out of no where. It only seems to make sense once we understand directional derivatives.",,"['calculus', 'math-history']"
95,Why in calculus the angles are measured in radians? [duplicate],Why in calculus the angles are measured in radians? [duplicate],,This question already has answers here : Why does the derivative of sine only work for radians? (17 answers) Why do we require radians in calculus? (11 answers) Closed 7 years ago . Why is the formula $\lim\limits_{h\rightarrow 0}\frac{\sin h}{h}=1$ not valid when $h$ is measured in degrees?,This question already has answers here : Why does the derivative of sine only work for radians? (17 answers) Why do we require radians in calculus? (11 answers) Closed 7 years ago . Why is the formula $\lim\limits_{h\rightarrow 0}\frac{\sin h}{h}=1$ not valid when $h$ is measured in degrees?,,"['calculus', 'geometry', 'limits', 'trigonometry', 'angle']"
96,How to prove there exist distinct $a_{i}$ such $f'(a_{1})f'(a_{2})f'(a_{3})\cdots f'(a_{n})=1$,How to prove there exist distinct  such,a_{i} f'(a_{1})f'(a_{2})f'(a_{3})\cdots f'(a_{n})=1,"Let $f$ be a continuous map from $[0,1]$ to $R$ that is differentiable on $(0,1)$,with $f(0)=0,f(1)=1$, show that for each postive integer $n$ there exist distinct numbers $a_{1},a_{2},\cdots,a_{n}\in (0,1)$,such that $$f'(a_{1})f'(a_{2})f'(a_{3})\cdots f'(a_{n})=1$$Thanks in advance.","Let $f$ be a continuous map from $[0,1]$ to $R$ that is differentiable on $(0,1)$,with $f(0)=0,f(1)=1$, show that for each postive integer $n$ there exist distinct numbers $a_{1},a_{2},\cdots,a_{n}\in (0,1)$,such that $$f'(a_{1})f'(a_{2})f'(a_{3})\cdots f'(a_{n})=1$$Thanks in advance.",,['calculus']
97,"A strange ""pattern"" in the continued fraction convergents of pi?","A strange ""pattern"" in the continued fraction convergents of pi?",,"From the simple continued fraction of $\pi$ , one gets the convergents, $$p_n = \frac{3}{1}, \frac{22}{7}, \frac{333}{106}, \frac{355}{113}, \frac{103993}{33102}, \frac{104348}{33215}, \frac{208341}{66317}, \frac{312689}{99532}, \frac{833719}{265381}, \frac{1146408}{364913}, \dots,$$ starting with $n=1$ , where the numerators and denominators are A002485 and A002486 , respectively. If you stare at it hard enough, a pattern will emerge between three consecutive convergents. Define, $$\left(a_n,\,b_n,\,c_n\right) = \left(p_{n}-3,\;\; p_{n+1}-3,\;\; p_{n+2}-3\right),$$ $$v_n=\text{Numerator}\,(a_n)\,\text{Numerator}\,(b_n).$$ Then, for even $n \ge 2$ , $$F(n) = \sqrt{\frac{a_n c_n}{a_n-c_n}-v_n}\in\mathbb{Z}\text{ (often)}.$$ For example, for $n = 2$ , $$\left(a_2,\,b_2,\,c_2\right) = \left(\frac{22}{7}-3,\; \frac{333}{106}-3,\; \frac{355}{113}-3\right),$$ $$F(2) = 1.$$ More generally, $$\begin{array}{cc} n&F(n) \\ 2&1 \\  4&16\\ 6&4703\\ 8&14093\\  10&51669\\ 12&122126\sqrt{2}\\ 14&7468474\\  16&\frac{18549059}{\sqrt{2}}\\ \end{array}$$ and so on. For even $n<100$ , I found half of the $F(n)$ were either integer or half-integer. (And all the non-integers were of form $N\sqrt{d}$ for some very small d .) Some questions: For $n<500$ , $n<1000$ , etc, how many $F(n)$ are integers or half-integers? More importantly, why is $F(n)$ often an integer?","From the simple continued fraction of , one gets the convergents, starting with , where the numerators and denominators are A002485 and A002486 , respectively. If you stare at it hard enough, a pattern will emerge between three consecutive convergents. Define, Then, for even , For example, for , More generally, and so on. For even , I found half of the were either integer or half-integer. (And all the non-integers were of form for some very small d .) Some questions: For , , etc, how many are integers or half-integers? More importantly, why is often an integer?","\pi p_n = \frac{3}{1}, \frac{22}{7}, \frac{333}{106}, \frac{355}{113}, \frac{103993}{33102}, \frac{104348}{33215}, \frac{208341}{66317}, \frac{312689}{99532}, \frac{833719}{265381}, \frac{1146408}{364913}, \dots, n=1 \left(a_n,\,b_n,\,c_n\right) = \left(p_{n}-3,\;\; p_{n+1}-3,\;\; p_{n+2}-3\right), v_n=\text{Numerator}\,(a_n)\,\text{Numerator}\,(b_n). n \ge 2 F(n) = \sqrt{\frac{a_n c_n}{a_n-c_n}-v_n}\in\mathbb{Z}\text{ (often)}. n = 2 \left(a_2,\,b_2,\,c_2\right) = \left(\frac{22}{7}-3,\; \frac{333}{106}-3,\; \frac{355}{113}-3\right), F(2) = 1. \begin{array}{cc}
n&F(n) \\
2&1 \\ 
4&16\\
6&4703\\
8&14093\\ 
10&51669\\
12&122126\sqrt{2}\\
14&7468474\\ 
16&\frac{18549059}{\sqrt{2}}\\
\end{array} n<100 F(n) N\sqrt{d} n<500 n<1000 F(n) F(n)","['calculus', 'sequences-and-series', 'approximation', 'pi', 'continued-fractions']"
98,Is the maximum function of a continuous function continuous?,Is the maximum function of a continuous function continuous?,,"Suppose $f(x)$ is continuous on the closed interval $[a,b]$. Define $m(x)=\max_{a\leq s\leq x}\, f(s)$, $a\leq x\leq b$. Is $m(x)$ continuous necessarily? Thank you.","Suppose $f(x)$ is continuous on the closed interval $[a,b]$. Define $m(x)=\max_{a\leq s\leq x}\, f(s)$, $a\leq x\leq b$. Is $m(x)$ continuous necessarily? Thank you.",,['calculus']
99,Find $\int _0^1\frac{12\arctan ^2 x\ln (\frac{(1-x)^2}{1+x^2})-\ln ^3(\frac{(1-x)^2}{1+x^2})}{x}\:dx$,Find,\int _0^1\frac{12\arctan ^2 x\ln (\frac{(1-x)^2}{1+x^2})-\ln ^3(\frac{(1-x)^2}{1+x^2})}{x}\:dx,"I want to find and prove that: $$\int _0^1\frac{12\arctan ^2\left(x\right)\ln \left(\frac{\left(1-x\right)^2}{1+x^2}\right)-\ln ^3\left(\frac{\left(1-x\right)^2}{1+x^2}\right)}{x}\:dx=\frac{9 \pi ^4}{16}$$ I tried to split the integral: $$=12\int _0^1\frac{\arctan ^2\left(x\right)\ln \left(\frac{\left(1-x\right)^2}{1+x^2}\right)}{x}\:dx+12\int _0^1\frac{\ln ^2\left(1-x\right)\ln \left(1+x^2\right)}{x}\:dx$$ $$-6\int _0^1\frac{\ln \left(1-x\right)\ln ^2\left(1+x^2\right)}{x}\:dx+\int _0^1\frac{\ln ^3\left(1+x^2\right)}{x}\:dx-8\int _0^1\frac{\ln ^3\left(1-x\right)}{x}\:dx$$ But the first $3$ integrals are very tough, expanding some terms yield very complicated series. I also attempted to integrate by parts but it was rather messy and I'd prefer not to put it here. I have faith that there must be a trick for finding this one because of its closed forms simplicity. Note $2$ : I found this integral in a certain mathematics group, I've ask for hints but received none.","I want to find and prove that: I tried to split the integral: But the first integrals are very tough, expanding some terms yield very complicated series. I also attempted to integrate by parts but it was rather messy and I'd prefer not to put it here. I have faith that there must be a trick for finding this one because of its closed forms simplicity. Note : I found this integral in a certain mathematics group, I've ask for hints but received none.",\int _0^1\frac{12\arctan ^2\left(x\right)\ln \left(\frac{\left(1-x\right)^2}{1+x^2}\right)-\ln ^3\left(\frac{\left(1-x\right)^2}{1+x^2}\right)}{x}\:dx=\frac{9 \pi ^4}{16} =12\int _0^1\frac{\arctan ^2\left(x\right)\ln \left(\frac{\left(1-x\right)^2}{1+x^2}\right)}{x}\:dx+12\int _0^1\frac{\ln ^2\left(1-x\right)\ln \left(1+x^2\right)}{x}\:dx -6\int _0^1\frac{\ln \left(1-x\right)\ln ^2\left(1+x^2\right)}{x}\:dx+\int _0^1\frac{\ln ^3\left(1+x^2\right)}{x}\:dx-8\int _0^1\frac{\ln ^3\left(1-x\right)}{x}\:dx 3 2,"['calculus', 'integration', 'definite-integrals', 'logarithms', 'trigonometric-integrals']"
