,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Where does this expression of Gaussian curvature come from?,Where does this expression of Gaussian curvature come from?,,"In my Differential Geometry course, we have seen a way to calculate the Gaussian curvature $K$ given a metric expressed as the sum of two Pfaff forms $Q = ω_1^2 + ω_2^2$: we find another Pfaff form $ω_3$ (which they said is unique) that meets these equations $$ \mathrm{d} ω_1 = ω_2 \wedge ω_3 \\ \mathrm{d} ω_2 = ω_3 \wedge ω_1 $$ Then, the Gaussian curvature $K$ is the only function such that $$ \mathrm{d} ω_3 = K ω_1 \wedge ω_2$$ or alternatively $$ K = \frac{\mathrm{d}ω_3}{ω_1\wedge ω_2} $$ My question is, where does this expression come from? I understand what is Gaussian curvature and its relationship to the geometry of a surface and first and second fundamental forms (or at least I think I understand it), but this expression is absolutely misterious to me. I've googled a lot and only found that it may be related to connections but we haven't studied topology yet.","In my Differential Geometry course, we have seen a way to calculate the Gaussian curvature $K$ given a metric expressed as the sum of two Pfaff forms $Q = ω_1^2 + ω_2^2$: we find another Pfaff form $ω_3$ (which they said is unique) that meets these equations $$ \mathrm{d} ω_1 = ω_2 \wedge ω_3 \\ \mathrm{d} ω_2 = ω_3 \wedge ω_1 $$ Then, the Gaussian curvature $K$ is the only function such that $$ \mathrm{d} ω_3 = K ω_1 \wedge ω_2$$ or alternatively $$ K = \frac{\mathrm{d}ω_3}{ω_1\wedge ω_2} $$ My question is, where does this expression come from? I understand what is Gaussian curvature and its relationship to the geometry of a surface and first and second fundamental forms (or at least I think I understand it), but this expression is absolutely misterious to me. I've googled a lot and only found that it may be related to connections but we haven't studied topology yet.",,"['differential-geometry', 'curvature']"
1,"Calculating the Lie algebra of $SO(2,1)$",Calculating the Lie algebra of,"SO(2,1)","I am trying to calculate the Lie algebra of the group $SO(2,1)$, realized as $$SO(2,1)=\{X\in \operatorname{Mat}_3(\mathbb{R}) \,|\, X^t\eta X=\eta, \det(X)=1\},$$ where $$\eta = \left ( \begin{array}{ccc} 1 &0&0\\0&1&0\\0&0&-1\end{array}\right ) .$$ But I am a bit unsure as how to procee:, I know that I need to take a curve in $SO(2,1)$ that passes through the identity at 0 and then differentiate at 0 but I am unsure as to what the form of curves in $SO(2,1)$ are? So do I let $a(t)\in SO(2,1)$ be a curve with $a(0)=1$ so that: $$a'(0)^t\eta+\eta a'(0)=\eta ?$$","I am trying to calculate the Lie algebra of the group $SO(2,1)$, realized as $$SO(2,1)=\{X\in \operatorname{Mat}_3(\mathbb{R}) \,|\, X^t\eta X=\eta, \det(X)=1\},$$ where $$\eta = \left ( \begin{array}{ccc} 1 &0&0\\0&1&0\\0&0&-1\end{array}\right ) .$$ But I am a bit unsure as how to procee:, I know that I need to take a curve in $SO(2,1)$ that passes through the identity at 0 and then differentiate at 0 but I am unsure as to what the form of curves in $SO(2,1)$ are? So do I let $a(t)\in SO(2,1)$ be a curve with $a(0)=1$ so that: $$a'(0)^t\eta+\eta a'(0)=\eta ?$$",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
2,Notation to work with vector-valued differential forms,Notation to work with vector-valued differential forms,,"What it the standard notation used while working with vector-valued differential forms? I tried using abstract index notation, for example denoting a $1$-form valued $2$-form as $P_{i[bc]}$, but I'm not sure I'm doing it right. What is the standard way to denote vector-valued differential forms (at least of kind $\Lambda^p(T^*M) \otimes \Lambda^n(T^*M)$), tensor and exterior products, exterior derivative, Hodge dual, and contractions of all kinds? If you are interested why do I need all these, that's because of fluxes and balance equations, and not only for scalar quantities.","What it the standard notation used while working with vector-valued differential forms? I tried using abstract index notation, for example denoting a $1$-form valued $2$-form as $P_{i[bc]}$, but I'm not sure I'm doing it right. What is the standard way to denote vector-valued differential forms (at least of kind $\Lambda^p(T^*M) \otimes \Lambda^n(T^*M)$), tensor and exterior products, exterior derivative, Hodge dual, and contractions of all kinds? If you are interested why do I need all these, that's because of fluxes and balance equations, and not only for scalar quantities.",,"['reference-request', 'differential-geometry', 'notation', 'multilinear-algebra']"
3,What does holonomy measure?,What does holonomy measure?,,"I have difficulty understanding conceptually what holonomy measures. it can return a phase shift of the vector transported parallel along the connection. If there is no phase shift, it means that the connection is flat, and if there is phase shift, then it should indicate that the space is curved. But I have found examples where a flat space can have non-trivial holonomy, for example a cone has non-trivial holonomy (see On a flat surface, can a holonomy can be nontrivial around certain curves ). So my question: what information does holonomy give us? anything about the curvature?","I have difficulty understanding conceptually what holonomy measures. it can return a phase shift of the vector transported parallel along the connection. If there is no phase shift, it means that the connection is flat, and if there is phase shift, then it should indicate that the space is curved. But I have found examples where a flat space can have non-trivial holonomy, for example a cone has non-trivial holonomy (see On a flat surface, can a holonomy can be nontrivial around certain curves ). So my question: what information does holonomy give us? anything about the curvature?",,"['differential-geometry', 'riemannian-geometry']"
4,Abstract definition of tangent space,Abstract definition of tangent space,,"I've been learning some introductory analysis on manifolds and have had a small issue ever since the notion of tangent spaces at points on a differentiable manifold was introduced. In our lectures, we began with the definition using equivalence classes of curves. But it is also possible to define tangent spaces using derivations of smooth functions (and apparently several other ways too, but for now I'm only familiar with these two). It seems intuitively sensible to call both these pictures (the curve and derivative ones) ""equivalent"": let the point of interest be $p$ and pick a local chart $\phi$ . Then we form a quotient of the set of curves through $p$ (parametrized so that $p=\gamma(0)$ ), declaring $\gamma_1\sim\gamma_2$ iff $(\phi\,\circ\,\gamma_1)'(0)=(\phi\,\circ\,\gamma_2)'(0)$ . This is one particular version of a tangent space at $p$ . But we could also define it as the space of derivations, i.e. linear maps from $C^\infty(M)$ to $\mathbb{R}$ satisfying the Leibnitz rule $$D(fg)=D(f)g(p)+f(p)D(g)$$ For any equivalence class of curves $[\gamma]$ at $p$ , the operator defined on $C^\infty(M)$ by $$ D_{[\gamma]}(f)=(f\circ\gamma)'(0) $$ is a derivation; conversely, it is true that every derivation is such a directional derivative (proof: Equivalence of definitions of tangent space ). Most of this a recap of a part of Wikipedia . At any rate, both of these notions seem to give in some sense ""the same"" tangent spaces. Here is my problem: I don't actually understand what precisely it is we are checking for when trying to decide if some two definitions are equivalent; right now, all I would personally try to do is show isomorphism of vector spaces and then try to convince myself that this isomorphism respects some vague notion of direction. But then $\mathbb{R}^{\mathrm{dim}(M)}$ is certainly isomorphic to any tangent space of the manifold $M$ , at least as a vector space. Nevertheless, just declaring $T_pM=\mathbb{R}^{\mathrm{dim}(M)}$ doesn't strike me as a successful construction of a tangent space. Now, there are two levels to my question, ordered by ""degree of abstraction"", so to speak (presumably they also get harder to answer). I do, however, believe they are connected. First, is there some precise notion of vector space isomorphisms respecting direction on a manifold? Specifically, is $\mathbb{R}^{\mathrm{dim}(M)}$ a valid tangent space or is it not, or do I perhaps have to specify some additional structure on it and then check that the additional structure relates to, say, the curve definition in a correct way? (I suppose this last case would require taking one definition of the tangent space as the absolute foundation and comparing all others to it, which I find somewhat unsatisfying.) Second, is there perhaps an abstract, ""external"" definition of a tangent space? What I'm talking about could be something like, ""Given a smooth manifold $M$ , a point $p\in M$ and a vector space $V$ , this vector space is called a tangent space at $p$ if it satisfies some properties $X,Y,Z...$ "" where these $X,Y,Z$ don't depend on the type of objects in $V$ or other particular details specific to $V$ . The motivation behind asking this is related to the situation with ordered pairs of objects (yes, this is quite a leap): I can use the Kuratowski definition or infinitely many others, and in each case, I will be able to eventually convince myself that, indeed, this thing before me works just as well to encode ""ordered-ness"" of objects as any other. But I don't have to keep referring to one of these specific cases, I just need to describe how pairs should arise and behave in general: there is a two-place function $f$ that sends two objects $x$ and $y$ to $(x,y)$ and there are two projections $\pi_1,\pi_2$ that pull $x$ and $y$ back out. (For a precise definition see this PDF , I summarised the discussion from there. It goes on to define products also within category theory.) Furthermore, I would find it highly suspect if some theorem about ordered pairs referred to the particulars of the Kuratowski definition - all the relevant information about $(x,y)$ should be recoverable from just the abstract setup described above (or better yet, in the linked PDF). Is there some way of treating tangent spaces in this same spirit? I know this question is vague, but I honestly don't know how better to phrase it, I hope I've at least gotten the mindset across if nothing else.","I've been learning some introductory analysis on manifolds and have had a small issue ever since the notion of tangent spaces at points on a differentiable manifold was introduced. In our lectures, we began with the definition using equivalence classes of curves. But it is also possible to define tangent spaces using derivations of smooth functions (and apparently several other ways too, but for now I'm only familiar with these two). It seems intuitively sensible to call both these pictures (the curve and derivative ones) ""equivalent"": let the point of interest be and pick a local chart . Then we form a quotient of the set of curves through (parametrized so that ), declaring iff . This is one particular version of a tangent space at . But we could also define it as the space of derivations, i.e. linear maps from to satisfying the Leibnitz rule For any equivalence class of curves at , the operator defined on by is a derivation; conversely, it is true that every derivation is such a directional derivative (proof: Equivalence of definitions of tangent space ). Most of this a recap of a part of Wikipedia . At any rate, both of these notions seem to give in some sense ""the same"" tangent spaces. Here is my problem: I don't actually understand what precisely it is we are checking for when trying to decide if some two definitions are equivalent; right now, all I would personally try to do is show isomorphism of vector spaces and then try to convince myself that this isomorphism respects some vague notion of direction. But then is certainly isomorphic to any tangent space of the manifold , at least as a vector space. Nevertheless, just declaring doesn't strike me as a successful construction of a tangent space. Now, there are two levels to my question, ordered by ""degree of abstraction"", so to speak (presumably they also get harder to answer). I do, however, believe they are connected. First, is there some precise notion of vector space isomorphisms respecting direction on a manifold? Specifically, is a valid tangent space or is it not, or do I perhaps have to specify some additional structure on it and then check that the additional structure relates to, say, the curve definition in a correct way? (I suppose this last case would require taking one definition of the tangent space as the absolute foundation and comparing all others to it, which I find somewhat unsatisfying.) Second, is there perhaps an abstract, ""external"" definition of a tangent space? What I'm talking about could be something like, ""Given a smooth manifold , a point and a vector space , this vector space is called a tangent space at if it satisfies some properties "" where these don't depend on the type of objects in or other particular details specific to . The motivation behind asking this is related to the situation with ordered pairs of objects (yes, this is quite a leap): I can use the Kuratowski definition or infinitely many others, and in each case, I will be able to eventually convince myself that, indeed, this thing before me works just as well to encode ""ordered-ness"" of objects as any other. But I don't have to keep referring to one of these specific cases, I just need to describe how pairs should arise and behave in general: there is a two-place function that sends two objects and to and there are two projections that pull and back out. (For a precise definition see this PDF , I summarised the discussion from there. It goes on to define products also within category theory.) Furthermore, I would find it highly suspect if some theorem about ordered pairs referred to the particulars of the Kuratowski definition - all the relevant information about should be recoverable from just the abstract setup described above (or better yet, in the linked PDF). Is there some way of treating tangent spaces in this same spirit? I know this question is vague, but I honestly don't know how better to phrase it, I hope I've at least gotten the mindset across if nothing else.","p \phi p p=\gamma(0) \gamma_1\sim\gamma_2 (\phi\,\circ\,\gamma_1)'(0)=(\phi\,\circ\,\gamma_2)'(0) p C^\infty(M) \mathbb{R} D(fg)=D(f)g(p)+f(p)D(g) [\gamma] p C^\infty(M) 
D_{[\gamma]}(f)=(f\circ\gamma)'(0)
 \mathbb{R}^{\mathrm{dim}(M)} M T_pM=\mathbb{R}^{\mathrm{dim}(M)} \mathbb{R}^{\mathrm{dim}(M)} M p\in M V p X,Y,Z... X,Y,Z V V f x y (x,y) \pi_1,\pi_2 x y (x,y)","['differential-geometry', 'smooth-manifolds']"
5,Do minimal hyperbolic surfaces exist? What do they look like?,Do minimal hyperbolic surfaces exist? What do they look like?,,"I understand that it is impossible to embed* the entire hyperbolic plane in $\mathbb{R}^3$. But, can one create a embedding of part of the hyperbolic plane such that the resulting surface is also minimal? Basically, do there exist surfaces which have $\kappa_1 + \kappa_2 = 0$, but also $\kappa_1 \kappa_2 = const < 0$? What do they look like? *""Embed"" may not be the correct term here, but I hope the idea is clear.","I understand that it is impossible to embed* the entire hyperbolic plane in $\mathbb{R}^3$. But, can one create a embedding of part of the hyperbolic plane such that the resulting surface is also minimal? Basically, do there exist surfaces which have $\kappa_1 + \kappa_2 = 0$, but also $\kappa_1 \kappa_2 = const < 0$? What do they look like? *""Embed"" may not be the correct term here, but I hope the idea is clear.",,"['differential-geometry', 'hyperbolic-geometry', 'curvature']"
6,Differential geometry in the context of manifolds,Differential geometry in the context of manifolds,,"I am an undergraduate student of mathematics. I have a solid background on calculus, linear algebra, real analysis and point set topology, but I have never studied differential geometry. I am very interested in studying differentiable manifolds, but, should I first study classical differential geometry? Should I first study curves, surfaces and curvature? I make an emphasis in the word 'should', because I've been told it is not strictly necessary to master these concepts.","I am an undergraduate student of mathematics. I have a solid background on calculus, linear algebra, real analysis and point set topology, but I have never studied differential geometry. I am very interested in studying differentiable manifolds, but, should I first study classical differential geometry? Should I first study curves, surfaces and curvature? I make an emphasis in the word 'should', because I've been told it is not strictly necessary to master these concepts.",,"['differential-geometry', 'soft-question']"
7,Is there any embedding theorem for fibre bundles?,Is there any embedding theorem for fibre bundles?,,"I would like to know whether there is an embedding theorem for fibre bundles, like Whitney embedding theorem. When can a given fibre bundle be a subbundle of some higher dimensional bundle?","I would like to know whether there is an embedding theorem for fibre bundles, like Whitney embedding theorem. When can a given fibre bundle be a subbundle of some higher dimensional bundle?",,"['differential-geometry', 'manifolds', 'differential-topology']"
8,Turning higher spheres inside out,Turning higher spheres inside out,,"I know that one can turn a sphere $S^2$ in $\mathbb{R}^3$ inside-out having at each time an immersion of $S^2$ into $\mathbb{R}^3$. It is called Smale paradox. There is beautiful animation about that. Do you know if the same thing is possible for higher dimensional spheres? I mean, for a sphere $S^k$ in $\mathbb{R}^{k+1}$ for $k\geq 3$. Thank you!","I know that one can turn a sphere $S^2$ in $\mathbb{R}^3$ inside-out having at each time an immersion of $S^2$ into $\mathbb{R}^3$. It is called Smale paradox. There is beautiful animation about that. Do you know if the same thing is possible for higher dimensional spheres? I mean, for a sphere $S^k$ in $\mathbb{R}^{k+1}$ for $k\geq 3$. Thank you!",,"['differential-geometry', 'algebraic-topology', 'differential-topology']"
9,Constant Rank theorem for domain with nonempty boundary,Constant Rank theorem for domain with nonempty boundary,,"Problem 4-3 in J.M. Lee's introductory text about smooth manifolds, asks to formulate and prove a version of the constant rank theorem for a map of constant rank whose domain is a smooth manifold with boundary. That is, show that, If $F:M\rightarrow N$ is smooth, $N$ with empty boundary, $F$ of constant rank $r$, then, for every point $p$ in $M$, $F$ has a local representation of the form $\tilde{F}(x)=(x_1, ...,x_r,0,...,0)$ Lee gives a hint: After extending $F$ (the interesting case is when $p\in\partial M$), follow the proof of the regular constant rank theorem,  until you have to make use of the constant rank hypothesis. The problem may be that the extension has higher rank. Lee's hint is to modify the map so that it has constant rank. I don't see how to do this. (If it's a silly question, I'm sorry, I haven't slept in over 24hs.)","Problem 4-3 in J.M. Lee's introductory text about smooth manifolds, asks to formulate and prove a version of the constant rank theorem for a map of constant rank whose domain is a smooth manifold with boundary. That is, show that, If $F:M\rightarrow N$ is smooth, $N$ with empty boundary, $F$ of constant rank $r$, then, for every point $p$ in $M$, $F$ has a local representation of the form $\tilde{F}(x)=(x_1, ...,x_r,0,...,0)$ Lee gives a hint: After extending $F$ (the interesting case is when $p\in\partial M$), follow the proof of the regular constant rank theorem,  until you have to make use of the constant rank hypothesis. The problem may be that the extension has higher rank. Lee's hint is to modify the map so that it has constant rank. I don't see how to do this. (If it's a silly question, I'm sorry, I haven't slept in over 24hs.)",,"['differential-geometry', 'manifolds']"
10,Problem about Ricci flow,Problem about Ricci flow,,"On page 12 of ""Lectures On Ricci Flow"" by Peter Topping is written: In two dimensions, we know that the Ricci curvature can be written in terms of the Gauss curvature $K$ as $Ric(g) = Kg$. Working directly from the equation $\frac{\partial g}{\partial t}=-2Ric(g) $, we then see that regions in which $K < 0$ tend to expand, and regions where $K > 0$ tend to shrink. Can anyone solve the Ricci flow PDE in this case and show regions in which $K < 0$ tend to expand, and regions where $K > 0$ tend to shrink? thanks","On page 12 of ""Lectures On Ricci Flow"" by Peter Topping is written: In two dimensions, we know that the Ricci curvature can be written in terms of the Gauss curvature $K$ as $Ric(g) = Kg$. Working directly from the equation $\frac{\partial g}{\partial t}=-2Ric(g) $, we then see that regions in which $K < 0$ tend to expand, and regions where $K > 0$ tend to shrink. Can anyone solve the Ricci flow PDE in this case and show regions in which $K < 0$ tend to expand, and regions where $K > 0$ tend to shrink? thanks",,"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'curvature', 'ricci-flow']"
11,"Is there an ""opposite"" of a geodesic?","Is there an ""opposite"" of a geodesic?",,"If I understand correctly, a geodesic between two points $a$ and $b$ is the ""most direct"" path from $a$ to $b$. Geodesics on a plane are straight lines, geodesics on a sphere are great circle arcs. Geodesics can be defined on any Riemannian manifold (right?). If I've got that roughly correct, then what might be the ""opposite"" of a geodesic? And can a unique ""opposite"" be defined? What about this definition: let a cisedoeg (the opposite of a geodesic) be a curve that connects $a$ and $b$ but that nowhere intersects the geodesic between $a$ and $b$. Also let the tangents to the cisedoeg all be parallel.","If I understand correctly, a geodesic between two points $a$ and $b$ is the ""most direct"" path from $a$ to $b$. Geodesics on a plane are straight lines, geodesics on a sphere are great circle arcs. Geodesics can be defined on any Riemannian manifold (right?). If I've got that roughly correct, then what might be the ""opposite"" of a geodesic? And can a unique ""opposite"" be defined? What about this definition: let a cisedoeg (the opposite of a geodesic) be a curve that connects $a$ and $b$ but that nowhere intersects the geodesic between $a$ and $b$. Also let the tangents to the cisedoeg all be parallel.",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
12,Metric of spacetime with zero speed of light,Metric of spacetime with zero speed of light,,"Despite references to physical spaces, this question is purely mathematical on differential geometry. While deriving coordinate transformations based on common assumptions of homogeneity and uniformity of space and time (see A Primer on Special Relativity or Nothing but Relativity ), typically three logical options are considered: Finite speed of light - Minkowski spacetime. Infinite speed of light - Galilean spacetime, ruled out by observation. Imaginary speed of light (negative square) - Euclidean spacetime, ruled out by causality. There exist however the forth logical option: Zero speed of light. At first it appears unreal, but in fact there exists a conceptual case asymptotically close to this scenario. Imagine a thin spherical shell approaching its Schwarzschild radius. Spacetime inside this empty shell is locally flat Minkowski with the same time dilation as at the shell. As the shell approaches an infinite time dilation at the Schwarzschild radius, the speed of light at and inside the shell approaches zero. What is the metric structure of this space in the limit of the speed of light being exactly zero? Metrics for other three cases are well known. The Euclidean and Minkowski metrics don't require an introduction. The Galilean structure is described here: What is a mathematical definition of the Maxwellian spacetime? Would the $c=0$ spacetime collapse simply to a 3D Euclidean space with no time or would it have two separate metrics for space and time like the Galilean spacetime?","Despite references to physical spaces, this question is purely mathematical on differential geometry. While deriving coordinate transformations based on common assumptions of homogeneity and uniformity of space and time (see A Primer on Special Relativity or Nothing but Relativity ), typically three logical options are considered: Finite speed of light - Minkowski spacetime. Infinite speed of light - Galilean spacetime, ruled out by observation. Imaginary speed of light (negative square) - Euclidean spacetime, ruled out by causality. There exist however the forth logical option: Zero speed of light. At first it appears unreal, but in fact there exists a conceptual case asymptotically close to this scenario. Imagine a thin spherical shell approaching its Schwarzschild radius. Spacetime inside this empty shell is locally flat Minkowski with the same time dilation as at the shell. As the shell approaches an infinite time dilation at the Schwarzschild radius, the speed of light at and inside the shell approaches zero. What is the metric structure of this space in the limit of the speed of light being exactly zero? Metrics for other three cases are well known. The Euclidean and Minkowski metrics don't require an introduction. The Galilean structure is described here: What is a mathematical definition of the Maxwellian spacetime? Would the spacetime collapse simply to a 3D Euclidean space with no time or would it have two separate metrics for space and time like the Galilean spacetime?",c=0,"['differential-geometry', 'metric-spaces']"
13,Gradient of a function restricted to a submanifold,Gradient of a function restricted to a submanifold,,Let $f$ be a sufficiently smooth function on a manifold $S$. Let $M$ be a sub manifold of $S$. Can someone show how is it then true that $(\text{grad}f|_M)_p$ at a point $p$ (gradient of the mapping $f|_M$ restricted to $M$ at a point $p\in M$) is the orthogonal projection of $(\text{grad}f)_p$ onto $T_p(M)$?,Let $f$ be a sufficiently smooth function on a manifold $S$. Let $M$ be a sub manifold of $S$. Can someone show how is it then true that $(\text{grad}f|_M)_p$ at a point $p$ (gradient of the mapping $f|_M$ restricted to $M$ at a point $p\in M$) is the orthogonal projection of $(\text{grad}f)_p$ onto $T_p(M)$?,,"['differential-geometry', 'riemannian-geometry']"
14,How do manifolds have enough structure to do calculus?,How do manifolds have enough structure to do calculus?,,"I am referring, of course, to to differentiable manifolds. I've seen a few different definitions. The one I like best is the one which says it's a topological space such that every point has a neighborhood homeomorphic to an open set in $\mathbb{R}^n$ and the overlap functions are diffeomorphisms. I can see that we want the transition maps are diffeomorpisms, so the calculus we do on each coordinate chart agrees with the others, but how do homeomorphisms to Euclidean space give enough structure to develop a derivative, for instance, in a coordinate patch? I mean, the circle and the sphere are homeomorphic but I'd only call one of those smooth. How does smoothness on overlaps do it for the whole manifold? I've seen it said that once a differentiable structure is defined, the homeomorphisms become diffeomorphisms. Is this correct and could somebody expand on that if it is? Furthermore, I've seen definitions given for manifolds with bijections rather than homeomorphisms. Can that possibly work? Bijections don't have to be particularly nice at all, so I can't for the life of me see how you'd get enough structure out of that. Please correct me if I've misunderstood some part of this.","I am referring, of course, to to differentiable manifolds. I've seen a few different definitions. The one I like best is the one which says it's a topological space such that every point has a neighborhood homeomorphic to an open set in $\mathbb{R}^n$ and the overlap functions are diffeomorphisms. I can see that we want the transition maps are diffeomorpisms, so the calculus we do on each coordinate chart agrees with the others, but how do homeomorphisms to Euclidean space give enough structure to develop a derivative, for instance, in a coordinate patch? I mean, the circle and the sphere are homeomorphic but I'd only call one of those smooth. How does smoothness on overlaps do it for the whole manifold? I've seen it said that once a differentiable structure is defined, the homeomorphisms become diffeomorphisms. Is this correct and could somebody expand on that if it is? Furthermore, I've seen definitions given for manifolds with bijections rather than homeomorphisms. Can that possibly work? Bijections don't have to be particularly nice at all, so I can't for the life of me see how you'd get enough structure out of that. Please correct me if I've misunderstood some part of this.",,"['differential-geometry', 'manifolds']"
15,"Proper, smooth action with singular orbit space","Proper, smooth action with singular orbit space",,"This is a problem from Lee, Smooth Manifolds (Problem 9.4). It's not an homework problem, I'm just systematically solving every problem of that book, and I got stuck on this one. Usually I try not to ask for help unless I really don't have a clue, but I suspect that this problem is really simple, and it's getting on my nerves. ""Give an example of smooth, proper action of a Lie group on a smooth manifold such that the orbit space is not a topological manifold"" Since the action is assumed to be proper, the orbit space is indeed Hausdorff (and also second countable, of course). Then, the only thing that can go wrong is the orbit space not being locally Euclidean. Therefore, I was trying to devise smooth action of some group on $\mathbb{R}^2$, whose orbit space is the ""cross-shaped"" set. However, I can't figure out any concrete example. In particular, in the examples I've figured out so far, the action turns out to be not proper. A compact group would do the trick. Perhaps, since there may be some confusion, it's better to provide my (Lee's) definition of proper action. Let $G$ a Lie Group acting on a smooth manifold $M$. The action is proper if the map $G\times M \to M\times M$ given by $(g,p)\to (p,g\cdot p)$ is a proper map. Equivalently, the action is proper iff the following condition is satisfied: ""If $\{p_i\}$ is a convergent sequence in $M$ and $\{g_i\}$ is a sequence in $G$ such that $\{g_i \cdot p_i\}$ converges, then a subsequence of $\{g_i\}$ converges"".","This is a problem from Lee, Smooth Manifolds (Problem 9.4). It's not an homework problem, I'm just systematically solving every problem of that book, and I got stuck on this one. Usually I try not to ask for help unless I really don't have a clue, but I suspect that this problem is really simple, and it's getting on my nerves. ""Give an example of smooth, proper action of a Lie group on a smooth manifold such that the orbit space is not a topological manifold"" Since the action is assumed to be proper, the orbit space is indeed Hausdorff (and also second countable, of course). Then, the only thing that can go wrong is the orbit space not being locally Euclidean. Therefore, I was trying to devise smooth action of some group on $\mathbb{R}^2$, whose orbit space is the ""cross-shaped"" set. However, I can't figure out any concrete example. In particular, in the examples I've figured out so far, the action turns out to be not proper. A compact group would do the trick. Perhaps, since there may be some confusion, it's better to provide my (Lee's) definition of proper action. Let $G$ a Lie Group acting on a smooth manifold $M$. The action is proper if the map $G\times M \to M\times M$ given by $(g,p)\to (p,g\cdot p)$ is a proper map. Equivalently, the action is proper iff the following condition is satisfied: ""If $\{p_i\}$ is a convergent sequence in $M$ and $\{g_i\}$ is a sequence in $G$ such that $\{g_i \cdot p_i\}$ converges, then a subsequence of $\{g_i\}$ converges"".",,"['differential-geometry', 'lie-groups']"
16,Converse To Quotient Manifold Theorem [Exercise in Lee Smooth Manifolds],Converse To Quotient Manifold Theorem [Exercise in Lee Smooth Manifolds],,"I would like help with the following problem (chapter 9, #4) from Lee's Smooth Manifolds [its not homework, I'm reading it and I got stuck on this one] If a Lie group $G$ acts smoothly and freely on a smooth manifold $M$ and the orbit space $M/G$ has a smooth manifold structure such that the quotient map $\pi: M\to M/G$ is a smooth submersion, then $G$ acts properly. Its kind of a converse to the standard theorem about quotienting a manifold by a group action. Any hints/help?","I would like help with the following problem (chapter 9, #4) from Lee's Smooth Manifolds [its not homework, I'm reading it and I got stuck on this one] If a Lie group $G$ acts smoothly and freely on a smooth manifold $M$ and the orbit space $M/G$ has a smooth manifold structure such that the quotient map $\pi: M\to M/G$ is a smooth submersion, then $G$ acts properly. Its kind of a converse to the standard theorem about quotienting a manifold by a group action. Any hints/help?",,"['differential-geometry', 'manifolds', 'differential-topology']"
17,"$h^{p,q}$ of a complex torus.",of a complex torus.,"h^{p,q}","As we know, a compact Kähler surface with trivial canonical bundle is a K3 surface or a torus of dimension 2. I know $h^{0,2}$ of a K3 surface is 1, and I know $h^{0,2}$ of a torus must not be zero (otherwise it is always algebraic), but I don't know how to compute $h^{0,2}$ of a complex torus of dimension 2. By the way, is there a general method to compute all the Hodge numbers of a complex torus of dimension $n$ ? Any comments are welcome!","As we know, a compact Kähler surface with trivial canonical bundle is a K3 surface or a torus of dimension 2. I know of a K3 surface is 1, and I know of a torus must not be zero (otherwise it is always algebraic), but I don't know how to compute of a complex torus of dimension 2. By the way, is there a general method to compute all the Hodge numbers of a complex torus of dimension ? Any comments are welcome!","h^{0,2} h^{0,2} h^{0,2} n","['differential-geometry', 'algebraic-geometry', 'complex-geometry', 'kahler-manifolds', 'hodge-theory']"
18,Wedge product = set intersection?,Wedge product = set intersection?,,"In a research article [1] I found the following formulation: The wedge product may be considered as set intersection. For   example, surfaces of constant $f(x,y,z)$ and surface of constant $g(x,y,z)$   intersects along the lines given by $df \wedge dg$. The notion   of interpreting the wedge product as set intersection is appealing   from a topological standpoint. The article almost does not make use of exterior differential systems or other sophisticated math. It also gives no precise reference for the above statement. Questions: Does this viewpoint (wedge product = set intersection) make sense at all? What is meant with ""the lines given by $df \wedge dg$""? Edit: E.g. When I set $f(x,y,z) = \frac{1}{2}(x^2 + y^2 + z^2) $ and $g(x,y,z) = ax + by + cz$ with real constants $a,b,c$. Then we have $df\wedge dg = (x dx + y dy + z dz)\wedge(a dx + b dy + c dz)$. But what line does correspond to this 2-form. (I would suspect that we obtain circles.) [1] http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990890","In a research article [1] I found the following formulation: The wedge product may be considered as set intersection. For   example, surfaces of constant $f(x,y,z)$ and surface of constant $g(x,y,z)$   intersects along the lines given by $df \wedge dg$. The notion   of interpreting the wedge product as set intersection is appealing   from a topological standpoint. The article almost does not make use of exterior differential systems or other sophisticated math. It also gives no precise reference for the above statement. Questions: Does this viewpoint (wedge product = set intersection) make sense at all? What is meant with ""the lines given by $df \wedge dg$""? Edit: E.g. When I set $f(x,y,z) = \frac{1}{2}(x^2 + y^2 + z^2) $ and $g(x,y,z) = ax + by + cz$ with real constants $a,b,c$. Then we have $df\wedge dg = (x dx + y dy + z dz)\wedge(a dx + b dy + c dz)$. But what line does correspond to this 2-form. (I would suspect that we obtain circles.) [1] http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990890",,"['differential-geometry', 'differential-topology', 'differential-forms', 'exterior-algebra']"
19,Degree of Gauss map equal to half the Euler characteristic and Poincaré-Hopf,Degree of Gauss map equal to half the Euler characteristic and Poincaré-Hopf,,"The Poincaré-Hopf theorem states that for a smooth compact $m$-manifold $M$ without boundary and a vector field $X\in\operatorname{Vect}(M)$ of $M$ with only isolated zeroes we have the equality $$\sum_{\substack{p\in M\\X(p)=0}}\iota(p,X)=\chi(M)$$ where $\iota(p,X)$ denotes the index of $X$ at $p$ and $\chi(M)$ denotes the Euler characteristic of $M$. Let $m$ be even and $M\subset\mathbb{R}^{m+1}$ be a $m$-dimensional smooth compact submanifold without boundary and denote by $\nu:M\to S^m$ its Gauss map. How can I deduce from the Poincaré-Hopf theorem that the Brouwer degree of $\nu$ is equal to half the Euler characteristic of $M$ i.e. $$\deg(\nu)=\frac{1}{2}\chi(M)?$$ After many repeated (unsuccessful) tries I was hoping hat someone else might shed some light onto this...","The Poincaré-Hopf theorem states that for a smooth compact $m$-manifold $M$ without boundary and a vector field $X\in\operatorname{Vect}(M)$ of $M$ with only isolated zeroes we have the equality $$\sum_{\substack{p\in M\\X(p)=0}}\iota(p,X)=\chi(M)$$ where $\iota(p,X)$ denotes the index of $X$ at $p$ and $\chi(M)$ denotes the Euler characteristic of $M$. Let $m$ be even and $M\subset\mathbb{R}^{m+1}$ be a $m$-dimensional smooth compact submanifold without boundary and denote by $\nu:M\to S^m$ its Gauss map. How can I deduce from the Poincaré-Hopf theorem that the Brouwer degree of $\nu$ is equal to half the Euler characteristic of $M$ i.e. $$\deg(\nu)=\frac{1}{2}\chi(M)?$$ After many repeated (unsuccessful) tries I was hoping hat someone else might shed some light onto this...",,"['differential-geometry', 'differential-topology']"
20,Supremum length of space curves contained in the open unit ball having always less than unity curvature,Supremum length of space curves contained in the open unit ball having always less than unity curvature,,"I am in the process of proving that if a space curve (in $R^3$) has infinite length and the curvature tends towards $0$ as the natural parameter $s$ tends to infinity, the curve must be unbounded - i.e. not contained in any sphere of finite radius. This seems correct intuitively, but I have no guarantee it is correct, unless I am missing something obvious. One way to prove my hunch, I have deduced, is to use a lemma that any curve contained in the open unit ball with curvature always less than one must have a finite upper bound on its length (possibly $2π$, but it could be greater for all I know). How might one go about proving such an upper bound exists, or if it exists? It might also be nice to know what the bound specifically is, too. I've thought it might be possible to pose this as a variational problem - maximizing length - and then reducing it into a simpler problem, but that appears to be hellishly complicated. Thoughts?","I am in the process of proving that if a space curve (in $R^3$) has infinite length and the curvature tends towards $0$ as the natural parameter $s$ tends to infinity, the curve must be unbounded - i.e. not contained in any sphere of finite radius. This seems correct intuitively, but I have no guarantee it is correct, unless I am missing something obvious. One way to prove my hunch, I have deduced, is to use a lemma that any curve contained in the open unit ball with curvature always less than one must have a finite upper bound on its length (possibly $2π$, but it could be greater for all I know). How might one go about proving such an upper bound exists, or if it exists? It might also be nice to know what the bound specifically is, too. I've thought it might be possible to pose this as a variational problem - maximizing length - and then reducing it into a simpler problem, but that appears to be hellishly complicated. Thoughts?",,"['differential-geometry', 'calculus-of-variations']"
21,Square differential forms in cohomology,Square differential forms in cohomology,,"Let $X$ be a differentiable manifold (connected, compact, orientiable) of dimension $4n$ . Consider on $X$ a closed $2n$ -form $\omega$ , with associated cohomology class $[\omega] \in H^{2n}(X,\mathbb{R})$ . The integral of its square is some real number, $$ \int_X \omega \wedge \omega \in \mathbb{R} \,, $$ which may be negative, positive, or zero. In general, the integrand $\omega \wedge \omega$ need not have the same sign everywhere as the result of the integral. However, the integral $\int_X \omega \wedge \omega$ is a function only of the cohomology class $[\omega]$ , while $\omega \wedge \omega$ depends on the choice of representative $\omega \in [\omega]$ . So my question is: Is it possible to find a cohomologically equivalent $\omega' \in [\omega]$ such that everywhere $\mathrm{sgn}\big(\omega' \wedge \omega'\big) = \mathrm{sgn}\big(\int_X \omega \wedge \omega\big)$ ? In the case that the answer is negative, I wonder if one can give criteria under which it holds. A negative answer was given to a related question here . However, that answer crucially relied on the existence of the Massey triple product, which vanishes in the present case, so it doesn't seem possible to make a similar argument here.","Let be a differentiable manifold (connected, compact, orientiable) of dimension . Consider on a closed -form , with associated cohomology class . The integral of its square is some real number, which may be negative, positive, or zero. In general, the integrand need not have the same sign everywhere as the result of the integral. However, the integral is a function only of the cohomology class , while depends on the choice of representative . So my question is: Is it possible to find a cohomologically equivalent such that everywhere ? In the case that the answer is negative, I wonder if one can give criteria under which it holds. A negative answer was given to a related question here . However, that answer crucially relied on the existence of the Massey triple product, which vanishes in the present case, so it doesn't seem possible to make a similar argument here.","X 4n X 2n \omega [\omega] \in H^{2n}(X,\mathbb{R}) 
\int_X \omega \wedge \omega \in \mathbb{R} \,,
 \omega \wedge \omega \int_X \omega \wedge \omega [\omega] \omega \wedge \omega \omega \in [\omega] \omega' \in [\omega] \mathrm{sgn}\big(\omega' \wedge \omega'\big) = \mathrm{sgn}\big(\int_X \omega \wedge \omega\big)","['differential-geometry', 'homology-cohomology', 'differential-forms', 'de-rham-cohomology']"
22,Hodge star operator independent of orthonormal basis,Hodge star operator independent of orthonormal basis,,"I'm reading the book on differential geometry by Gockeler and Schucker and I came across a proof which I don't understand regarding the Hodge star operator. In the book, they define the Hodge star operator on an $n$ -dimensional oriented vector space by picking some positively oriented orthonormal basis $\{e_i\}_{i=1}^n$ and defining the map on the forms induced by the duals: $$*:\Lambda^p V\rightarrow \Lambda^{n-p}V$$ $$ *(e^{i_1}\wedge\cdots\wedge e^{i_p})=\epsilon_{i_1\ldots i_n}\eta^{i_1i_1}\cdots\eta^{i_pi_p}e^{i_{p+1}}\wedge\cdots\wedge e^{i_n} $$ Where $\epsilon$ is the Levi-Civita symbol and $\eta$ is a pseudo-Riemannian metric, which is diagonal with $r$ diagonal entries equal to $1$ and $s$ equal to $-1$ . They then claim that this definition does not depend on the choice of oriented orthonormal basis, and they explain it as follows: Where equation $3.16$ is the equation written above and equation $3.9$ is the equation which defines the elements of $O(r,s)$ : $$(\Lambda ^{-1})^t\eta \Lambda=\eta$$ I don't really understand their argument, and I'd appreciate any help in understanding it, even for the simple case of $\eta$ being the identity matrix (so just the usual Euclidean metric). I came across this related post, but it didn't contain a complete solution I could understand. I tried proving it myself, by taking another positive orthonormal basis $\{x_i\}_{i=1}^n$ , and writing $e_i=Ax_i$ for some matrix $A\in SO(r,s)$ and plugging this into the formula above, but I'm not sure on how to proceed from here. Thanks in advance.","I'm reading the book on differential geometry by Gockeler and Schucker and I came across a proof which I don't understand regarding the Hodge star operator. In the book, they define the Hodge star operator on an -dimensional oriented vector space by picking some positively oriented orthonormal basis and defining the map on the forms induced by the duals: Where is the Levi-Civita symbol and is a pseudo-Riemannian metric, which is diagonal with diagonal entries equal to and equal to . They then claim that this definition does not depend on the choice of oriented orthonormal basis, and they explain it as follows: Where equation is the equation written above and equation is the equation which defines the elements of : I don't really understand their argument, and I'd appreciate any help in understanding it, even for the simple case of being the identity matrix (so just the usual Euclidean metric). I came across this related post, but it didn't contain a complete solution I could understand. I tried proving it myself, by taking another positive orthonormal basis , and writing for some matrix and plugging this into the formula above, but I'm not sure on how to proceed from here. Thanks in advance.","n \{e_i\}_{i=1}^n *:\Lambda^p V\rightarrow \Lambda^{n-p}V  *(e^{i_1}\wedge\cdots\wedge e^{i_p})=\epsilon_{i_1\ldots i_n}\eta^{i_1i_1}\cdots\eta^{i_pi_p}e^{i_{p+1}}\wedge\cdots\wedge e^{i_n}  \epsilon \eta r 1 s -1 3.16 3.9 O(r,s) (\Lambda ^{-1})^t\eta \Lambda=\eta \eta \{x_i\}_{i=1}^n e_i=Ax_i A\in SO(r,s)","['differential-geometry', 'riemannian-geometry', 'tensors', 'differential-forms', 'multilinear-algebra']"
23,Ricci Flow: PDE details?,Ricci Flow: PDE details?,,"Over the past few weeks I have been reading 'Ricci flow: An introduction' (Chow and Knopf) which is, in my opinion, a very well written and quick introduction to the topic. However I find that the book focusses mainly on geometric aspects (which I understand is the real point of the book) rather than on the details of PDE existence-uniqueness-regularity theory. Moreover the book doesn't give sufficient references for some of the PDE theorems they use. For example, after introducing the Ricci-DeTurck flow, the book says that the equation is strictly parabolic and it is a standard result that for any smooth initial metric one has existence of unique short-time solution. I was wondering if someone could point me to some references for such theorems. How do they construct weak solutions? Which sobolev spaces do they work in?","Over the past few weeks I have been reading 'Ricci flow: An introduction' (Chow and Knopf) which is, in my opinion, a very well written and quick introduction to the topic. However I find that the book focusses mainly on geometric aspects (which I understand is the real point of the book) rather than on the details of PDE existence-uniqueness-regularity theory. Moreover the book doesn't give sufficient references for some of the PDE theorems they use. For example, after introducing the Ricci-DeTurck flow, the book says that the equation is strictly parabolic and it is a standard result that for any smooth initial metric one has existence of unique short-time solution. I was wondering if someone could point me to some references for such theorems. How do they construct weak solutions? Which sobolev spaces do they work in?",,"['differential-geometry', 'partial-differential-equations', 'heat-equation', 'regularity-theory-of-pdes', 'ricci-flow']"
24,Reynolds transport theorem: link with the Lie derivative?,Reynolds transport theorem: link with the Lie derivative?,,"In this Wikipedia article (see ""Higher dimensions"") there seems to be a connection between the Reynolds transport theorem ( here ) and the Lie derivative: $$\frac{d}{dt}\int_{\Omega(t)}\omega=\int_{\Omega(t)} i_{\vec{\textbf v}}(d\omega)+\int_{\partial \Omega(t)} i_{\vec{\textbf v}} \omega+\int_{\Omega(t)}\dot{\omega} \qquad(1)$$ were $\omega$ is a p-form and the domain is time-varying. The symbol $i_X$ denotes the contraction with the vector field $X$. By using the Cartan magic formula  $L_{X} \omega = d (i_X \omega) + i_X (d \omega)$, it seems that $$\frac{d}{dt}\int_{\Omega(t)}\omega=\int_{\Omega(t)} i_{\vec{\textbf v}}(d\omega)+\int_{\Omega(t)} d(i_{\vec{\textbf v}} \omega)+\int_{\Omega(t)}\dot{\omega} \, ,$$ namely $$\frac{d}{dt}\int_{\Omega(t)}\omega = \int_{\Omega(t)} L_{\vec{\textbf v}}\omega+\int_{\Omega(t)}\dot{\omega} \, .$$ It is clear that the Reynolds transport theorem is equivalent to the conservation of mass in hydrodynamics: $$\frac{d}{dt}\int_{\Omega(t)}\rho = \int_{\Omega(t)} div(\rho \vec{\bf{v}}) +\int_{\Omega(t)}\dot{\rho} \, .$$ What is the relation between the two formulations? Clearly $\omega =\rho$ is not the correct thing to do: we can only integrate 3-forms and $\rho$ is a 0-form (the domain $\Omega(t)$ is three dimensional). How to derive the mass conservation from equation (1)?","In this Wikipedia article (see ""Higher dimensions"") there seems to be a connection between the Reynolds transport theorem ( here ) and the Lie derivative: $$\frac{d}{dt}\int_{\Omega(t)}\omega=\int_{\Omega(t)} i_{\vec{\textbf v}}(d\omega)+\int_{\partial \Omega(t)} i_{\vec{\textbf v}} \omega+\int_{\Omega(t)}\dot{\omega} \qquad(1)$$ were $\omega$ is a p-form and the domain is time-varying. The symbol $i_X$ denotes the contraction with the vector field $X$. By using the Cartan magic formula  $L_{X} \omega = d (i_X \omega) + i_X (d \omega)$, it seems that $$\frac{d}{dt}\int_{\Omega(t)}\omega=\int_{\Omega(t)} i_{\vec{\textbf v}}(d\omega)+\int_{\Omega(t)} d(i_{\vec{\textbf v}} \omega)+\int_{\Omega(t)}\dot{\omega} \, ,$$ namely $$\frac{d}{dt}\int_{\Omega(t)}\omega = \int_{\Omega(t)} L_{\vec{\textbf v}}\omega+\int_{\Omega(t)}\dot{\omega} \, .$$ It is clear that the Reynolds transport theorem is equivalent to the conservation of mass in hydrodynamics: $$\frac{d}{dt}\int_{\Omega(t)}\rho = \int_{\Omega(t)} div(\rho \vec{\bf{v}}) +\int_{\Omega(t)}\dot{\rho} \, .$$ What is the relation between the two formulations? Clearly $\omega =\rho$ is not the correct thing to do: we can only integrate 3-forms and $\rho$ is a 0-form (the domain $\Omega(t)$ is three dimensional). How to derive the mass conservation from equation (1)?",,"['differential-geometry', 'fluid-dynamics', 'stokes-theorem', 'lie-derivative']"
25,What is the surface by identifying antipodal points of a 2-torus embedded in $\mathbb{R}^3$?,What is the surface by identifying antipodal points of a 2-torus embedded in ?,\mathbb{R}^3,"We define antipodal points in $\mathbb{R}^3$ as $(x,y,z)\to (-x,-y,-z)$ . As we all know, the 2-torus can be expressed as $$ \left(\sqrt{x^2+y^2}-R\right)^2+z^2=r^2, $$ where $0<r<R$ . Some were saying it was a Klein bottle. So I am considering that since torus can be regarded as a square with opposite edges identified in the same order. By identifying the antipodal points, we should also identify the interior of the identified square, so it is not quite the same as we have for Klein bottle. Can anyone hint on this? Thanks!","We define antipodal points in as . As we all know, the 2-torus can be expressed as where . Some were saying it was a Klein bottle. So I am considering that since torus can be regarded as a square with opposite edges identified in the same order. By identifying the antipodal points, we should also identify the interior of the identified square, so it is not quite the same as we have for Klein bottle. Can anyone hint on this? Thanks!","\mathbb{R}^3 (x,y,z)\to (-x,-y,-z) 
\left(\sqrt{x^2+y^2}-R\right)^2+z^2=r^2,
 0<r<R","['differential-geometry', 'algebraic-topology', 'differential-topology']"
26,Dense curve on torus not an embedded submanifold,Dense curve on torus not an embedded submanifold,,"In reference to Showing a subset of the torus is dense , the responders helped show the poster that the image set $f(\mathbb{R})$ is dense in the torus. But, it's not immediately clear to me why the image set is not an embedded submanifold. If $f(\mathbb{R})$ is an embedded submanifold, we must have that it's a smooth manifold in the subspace topology and that the inclusion map from $f(\mathbb{R})$ to $T^2$ is a smooth embedding. It's visually clear to me that under the subspace topology, $f(\mathbb{R})$ is not locally Euclidean (as it's not locally path connected). But, I can't seem to formalize this or any argument, using that $f(\mathbb{R})$ is dense in $T^2$, which says that $f(\mathbb{R})$ fails 1) or 2). Thanks for any help!","In reference to Showing a subset of the torus is dense , the responders helped show the poster that the image set $f(\mathbb{R})$ is dense in the torus. But, it's not immediately clear to me why the image set is not an embedded submanifold. If $f(\mathbb{R})$ is an embedded submanifold, we must have that it's a smooth manifold in the subspace topology and that the inclusion map from $f(\mathbb{R})$ to $T^2$ is a smooth embedding. It's visually clear to me that under the subspace topology, $f(\mathbb{R})$ is not locally Euclidean (as it's not locally path connected). But, I can't seem to formalize this or any argument, using that $f(\mathbb{R})$ is dense in $T^2$, which says that $f(\mathbb{R})$ fails 1) or 2). Thanks for any help!",,['differential-geometry']
27,Horizontal bundle and the notion of connection,Horizontal bundle and the notion of connection,,"Jost explains (in Riemannian Geometry and Geometric Analysis ) the term connection with the direct sum of the tangent space to a vector bundle $T_eE=V_e\oplus H_e$ as follows. Let $E$ be a vector bundle with connection $\nabla$, $e\in\Gamma(E)$ and $x=\pi(e)\in M$, $M$ manifold. Considering the tangent space $T_e E$ there is a distinguished subspace, the vertical space $V_e$, namely the tangent space $T_eE_x$ to the fiber $E_x\subset E$. However, there is no distinguished ""horizontal space"" $H_e$ complementary to $V_e$, i.e. satisfying $T_eE=V_e\oplus H_e$. If we have a connection $\nabla$, however, we can parallely transport $e$ for each $X\in T_xM$ along a curve $c(t)$ with $c(0)=x,~\dot{c}(0)=X$. Thus, for each $X$, we obtain a curve $e(t)$ in $E$. The subspace of $T_eE$ spanned by all tangent vectors to $E$ at $e$ of the form $$\left.\frac{\mathrm{d}}{\mathrm{d}t}e(t)\right|_{t=0}$$   then is the horizontal space $H_e$. In this manner, one obtains a rule for how the fibers in neighboring points are ""connected"" with each other. First (and probably very naive), with this definition of $H_e$ it is not clear to me why the direct sum $T_eE=V_e\oplus H_e$ does hold. Why is $\left.\frac{\mathrm{d}}{\mathrm{d}t}e(t)\right|_{t=0}\notin T_eE_x=V_e$ true? Second, I cannot really make sense of the term connection with this direct sum in mind. Many other authors (e.g. J.M. Lee) refer the term connection to the isomorphism between fibers given by parallel transport along a curve $c$, $P_{c,t}:E_{c(0)}\to E_{c(t)}$ which seems to explain the connection better. So, I would like to know: What exactly is meant by ""a rule"" for how the fibers are connected with each other? I have read, that the concept of vertical and horizontal (sub-)bundle is closely related to an Ehresmann connection, but since I am unaware of this notion, I would prefer answers not using Ehresmann connection. Also, I hope the second question is not too soft, but I am highly interested in understanding this (alternative) notion of connection.","Jost explains (in Riemannian Geometry and Geometric Analysis ) the term connection with the direct sum of the tangent space to a vector bundle $T_eE=V_e\oplus H_e$ as follows. Let $E$ be a vector bundle with connection $\nabla$, $e\in\Gamma(E)$ and $x=\pi(e)\in M$, $M$ manifold. Considering the tangent space $T_e E$ there is a distinguished subspace, the vertical space $V_e$, namely the tangent space $T_eE_x$ to the fiber $E_x\subset E$. However, there is no distinguished ""horizontal space"" $H_e$ complementary to $V_e$, i.e. satisfying $T_eE=V_e\oplus H_e$. If we have a connection $\nabla$, however, we can parallely transport $e$ for each $X\in T_xM$ along a curve $c(t)$ with $c(0)=x,~\dot{c}(0)=X$. Thus, for each $X$, we obtain a curve $e(t)$ in $E$. The subspace of $T_eE$ spanned by all tangent vectors to $E$ at $e$ of the form $$\left.\frac{\mathrm{d}}{\mathrm{d}t}e(t)\right|_{t=0}$$   then is the horizontal space $H_e$. In this manner, one obtains a rule for how the fibers in neighboring points are ""connected"" with each other. First (and probably very naive), with this definition of $H_e$ it is not clear to me why the direct sum $T_eE=V_e\oplus H_e$ does hold. Why is $\left.\frac{\mathrm{d}}{\mathrm{d}t}e(t)\right|_{t=0}\notin T_eE_x=V_e$ true? Second, I cannot really make sense of the term connection with this direct sum in mind. Many other authors (e.g. J.M. Lee) refer the term connection to the isomorphism between fibers given by parallel transport along a curve $c$, $P_{c,t}:E_{c(0)}\to E_{c(t)}$ which seems to explain the connection better. So, I would like to know: What exactly is meant by ""a rule"" for how the fibers are connected with each other? I have read, that the concept of vertical and horizontal (sub-)bundle is closely related to an Ehresmann connection, but since I am unaware of this notion, I would prefer answers not using Ehresmann connection. Also, I hope the second question is not too soft, but I am highly interested in understanding this (alternative) notion of connection.",,['differential-geometry']
28,Covariant derivative,Covariant derivative,,"In my book the author makes the remark: If $X,Y$ are smooth vector fields, and $\nabla$ is a connection, then $\nabla_X Y(p)$  depends on the Value of $X(p)$ and the value of $Y$ along a curve, tangent to $X(p)$. When I got it right, then we can consider a curve $c:I\rightarrow M$ with $c(0)=p$ and $c'(0)=X_p$. I was wondering, why this is true. When I consider a coordinate representation around the point p, i.e. $X=\sum x^i\cdot \partial_i$ and $Y=\sum y^i \cdot \partial_i$, then we can calculate that $\nabla_X Y(p)$ depends on: $x^i(p)$, $y^i(p)$ and $X_p(y^i)$. This again is only depending on $X_p$ and the values of $y^i=Y(x^i)$ in a arbitrary small neighborhood of $p$.  But I cannot see any curve ... I hope you can help me! Regards","In my book the author makes the remark: If $X,Y$ are smooth vector fields, and $\nabla$ is a connection, then $\nabla_X Y(p)$  depends on the Value of $X(p)$ and the value of $Y$ along a curve, tangent to $X(p)$. When I got it right, then we can consider a curve $c:I\rightarrow M$ with $c(0)=p$ and $c'(0)=X_p$. I was wondering, why this is true. When I consider a coordinate representation around the point p, i.e. $X=\sum x^i\cdot \partial_i$ and $Y=\sum y^i \cdot \partial_i$, then we can calculate that $\nabla_X Y(p)$ depends on: $x^i(p)$, $y^i(p)$ and $X_p(y^i)$. This again is only depending on $X_p$ and the values of $y^i=Y(x^i)$ in a arbitrary small neighborhood of $p$.  But I cannot see any curve ... I hope you can help me! Regards",,['differential-geometry']
29,basic differential forms,basic differential forms,,"Given a fiber bundle $f: E\rightarrow M$ with connected fibers we call the image $f^*(\Omega^k(M))\subset \Omega^k(E)$ the subspace of basic forms. Clearly, for any vertical vector field $X$ on $E$ we have that the interior product $i_X(f^*\omega)$ and the Lie derivative $L_X(f^*\omega)$ vanish for all $\omega \in \Omega^k(M)$. Is the converse true? That is, if $\alpha \in \Omega^k(E)$ is a form such that $i_X(\alpha)=0$ and $L_X(\alpha)=0$ for all vertical vector fields $X$ on $E$, is it true that $\alpha$ is a basic form? I believe so, but I am not sure how to prove it. Thanks for your help.","Given a fiber bundle $f: E\rightarrow M$ with connected fibers we call the image $f^*(\Omega^k(M))\subset \Omega^k(E)$ the subspace of basic forms. Clearly, for any vertical vector field $X$ on $E$ we have that the interior product $i_X(f^*\omega)$ and the Lie derivative $L_X(f^*\omega)$ vanish for all $\omega \in \Omega^k(M)$. Is the converse true? That is, if $\alpha \in \Omega^k(E)$ is a form such that $i_X(\alpha)=0$ and $L_X(\alpha)=0$ for all vertical vector fields $X$ on $E$, is it true that $\alpha$ is a basic form? I believe so, but I am not sure how to prove it. Thanks for your help.",,"['differential-geometry', 'differential-topology', 'fiber-bundles']"
30,What are some examples of $\text{Isom}(M)$ and $\text{Conf}(M)$?,What are some examples of  and ?,\text{Isom}(M) \text{Conf}(M),"Edit: Since I did not quite get the responses I would have liked when I asked this question four months ago, let me reformulate it slightly: What are some examples of $\text{Isom}(M)$ and $\text{Conf}(M)$? For example, Aaron mentions in his (very helpful) answer that $\text{Isom}(\mathbb{S}^n) \cong O(n+1)$.  What about hyperbolic n-space?  Or the n-torus?  The more examples the better. For precision, I am hoping that we can express $\text{Isom}(M)$ or $\text{Conf}(M)$ as some sort of ""recognizable"" Lie group, by which I mean a product, quotient, and/or connected sum of linear groups, euclidean spaces, or spheres. Original Question: (What are some examples of automorphism groups of manifolds which turn out to be Lie groups?) I recently read that the group of diffeomorphisms of a smooth manifold which preserve some sort of geometric structure (e.g. Riemannian structure, conformal structure, etc.) frequently turn out to be a Lie group.  What are some examples of this? I've read about the euclidean group $E(n)$ which are the isometries of $\mathbb{R}^n$, and also about the conformal automorphisms of the complex plane, upper half plane, and unit disc.  What others are there?  Do the groups Diff(M), Iso(M), etc. frequently turn out to be something recognizable?  What are the isometry groups or conformal groups of n-spheres, say, or some common 2-manifolds?","Edit: Since I did not quite get the responses I would have liked when I asked this question four months ago, let me reformulate it slightly: What are some examples of $\text{Isom}(M)$ and $\text{Conf}(M)$? For example, Aaron mentions in his (very helpful) answer that $\text{Isom}(\mathbb{S}^n) \cong O(n+1)$.  What about hyperbolic n-space?  Or the n-torus?  The more examples the better. For precision, I am hoping that we can express $\text{Isom}(M)$ or $\text{Conf}(M)$ as some sort of ""recognizable"" Lie group, by which I mean a product, quotient, and/or connected sum of linear groups, euclidean spaces, or spheres. Original Question: (What are some examples of automorphism groups of manifolds which turn out to be Lie groups?) I recently read that the group of diffeomorphisms of a smooth manifold which preserve some sort of geometric structure (e.g. Riemannian structure, conformal structure, etc.) frequently turn out to be a Lie group.  What are some examples of this? I've read about the euclidean group $E(n)$ which are the isometries of $\mathbb{R}^n$, and also about the conformal automorphisms of the complex plane, upper half plane, and unit disc.  What others are there?  Do the groups Diff(M), Iso(M), etc. frequently turn out to be something recognizable?  What are the isometry groups or conformal groups of n-spheres, say, or some common 2-manifolds?",,"['reference-request', 'differential-geometry']"
31,Lie bracket of exact differential one-forms,Lie bracket of exact differential one-forms,,"Let $(M,g)$ be a Riemannian manifold. The musical isomorphisms $^\flat:\chi(M) \to \Omega^1(M)$ and $^\sharp:\Omega^1(M) \to \chi(M)$ allow the space of differential one-forms $\Omega^1(M)$ to be identified with the space of vector fields $\chi(M)$. If I'm not mistaken, I can define the Lie bracket of two differential one forms $\alpha,\beta$ by $$[\alpha,\beta] := [\alpha^\sharp, \beta^\sharp]^\flat.$$ Now suppose that $\alpha$ and $\beta$ are exact; i.e. there exist smooth functions $A,B:M\to \mathbb{R}$ such that $\alpha = dA$ and $\beta = dB$, where $``d""$ denotes the exterior derivative. Is it necessarily true that $[dA,dB] = 0$? Here is the motivation for my question: On a $k$-manifold $M$, the integral curves of $k$ vector fields linearly independent at the point $x \in  M$ are the coordinate curves of a local coordinate system centered at $x$ if and only if their pairwise Lie brackets are zero (see, e.g., the discussion here ). On a Riemannian manifold, differential one-forms also have integral curves after identifying these one-forms with vector fields. I would like to know if there are ""natural"" conditions on a collection of $k$ differential one-forms that determine whether their integral curves similarly form the coordinate lines of a coordinate chart.","Let $(M,g)$ be a Riemannian manifold. The musical isomorphisms $^\flat:\chi(M) \to \Omega^1(M)$ and $^\sharp:\Omega^1(M) \to \chi(M)$ allow the space of differential one-forms $\Omega^1(M)$ to be identified with the space of vector fields $\chi(M)$. If I'm not mistaken, I can define the Lie bracket of two differential one forms $\alpha,\beta$ by $$[\alpha,\beta] := [\alpha^\sharp, \beta^\sharp]^\flat.$$ Now suppose that $\alpha$ and $\beta$ are exact; i.e. there exist smooth functions $A,B:M\to \mathbb{R}$ such that $\alpha = dA$ and $\beta = dB$, where $``d""$ denotes the exterior derivative. Is it necessarily true that $[dA,dB] = 0$? Here is the motivation for my question: On a $k$-manifold $M$, the integral curves of $k$ vector fields linearly independent at the point $x \in  M$ are the coordinate curves of a local coordinate system centered at $x$ if and only if their pairwise Lie brackets are zero (see, e.g., the discussion here ). On a Riemannian manifold, differential one-forms also have integral curves after identifying these one-forms with vector fields. I would like to know if there are ""natural"" conditions on a collection of $k$ differential one-forms that determine whether their integral curves similarly form the coordinate lines of a coordinate chart.",,"['differential-geometry', 'differential-topology', 'vector-analysis']"
32,Differential Forms on submanifolds,Differential Forms on submanifolds,,"Say I take an embedded submanifold of $\Bbb R^n$, like the sphere. Any differential form on $\Bbb R^n$ can be restricted to the sphere. My question is this: is any differential form on the sphere (or any embedded submanifold) the restriction of a form on $\Bbb R^n$? My gut says no, but I can't think of any counter examples.","Say I take an embedded submanifold of $\Bbb R^n$, like the sphere. Any differential form on $\Bbb R^n$ can be restricted to the sphere. My question is this: is any differential form on the sphere (or any embedded submanifold) the restriction of a form on $\Bbb R^n$? My gut says no, but I can't think of any counter examples.",,"['differential-geometry', 'manifolds', 'differential-forms']"
33,Isometry Group of a Manifold,Isometry Group of a Manifold,,"Let $(M,g)$ be a Riemannian manifold and let $I = Iso(M)$ be the group of isometries of $M$. Suppose that $I$ has no subgroups. What does this tell us about $M$?","Let $(M,g)$ be a Riemannian manifold and let $I = Iso(M)$ be the group of isometries of $M$. Suppose that $I$ has no subgroups. What does this tell us about $M$?",,['differential-geometry']
34,Ideal of smooth function on a manifold vanishing at a point,Ideal of smooth function on a manifold vanishing at a point,,"I'm trying to prove the following lemma: let $M$ be a smooth manifold and consider the algebra $C^{\infty}(M)$ of smooth functions $f\colon M \to \mathbb{R}$. Given $x_0 \in M$, consider the ideals $$\mathfrak{m}_{x_0} := \{f\in C^{\infty}(M) : f(x_0)=0\},$$ $$\mathfrak{I}_{x_0} := \{f\in C^{\infty}(M) : f(x_0)=0, df(x_0)=0\}.$$ Then $\mathfrak{I}_{x_0} = \mathfrak{m}^2_{x_0}$, i.e. any function $f$ vanishing at $x_0$ together with its derivatives can be written as $$f=\sum_kg_kh_k, \quad g_k, h_k \in \mathfrak{m}_{x_0}.$$ I have no idea about how to prove the inclusion $\mathfrak{I}_{x_0} \subseteq \mathfrak{m}^2_{x_0}$.","I'm trying to prove the following lemma: let $M$ be a smooth manifold and consider the algebra $C^{\infty}(M)$ of smooth functions $f\colon M \to \mathbb{R}$. Given $x_0 \in M$, consider the ideals $$\mathfrak{m}_{x_0} := \{f\in C^{\infty}(M) : f(x_0)=0\},$$ $$\mathfrak{I}_{x_0} := \{f\in C^{\infty}(M) : f(x_0)=0, df(x_0)=0\}.$$ Then $\mathfrak{I}_{x_0} = \mathfrak{m}^2_{x_0}$, i.e. any function $f$ vanishing at $x_0$ together with its derivatives can be written as $$f=\sum_kg_kh_k, \quad g_k, h_k \in \mathfrak{m}_{x_0}.$$ I have no idea about how to prove the inclusion $\mathfrak{I}_{x_0} \subseteq \mathfrak{m}^2_{x_0}$.",,"['differential-geometry', 'manifolds']"
35,Structures on torus,Structures on torus,,"Quotienting $\mathbb R^2$ by different lattices isomorphic to $\mathbb Z^2$, we get different tori. Somehow I think of the tori as having different ""structures"", but thinking more about it, I am not quite sure what different structures I am really thinking of. Two structures I am guessing at are complex structures and metrics. Could someone explain how these differ? Also, am I thinking of the right kind of structure? Are there other structures which vary with the lattice chosen?","Quotienting $\mathbb R^2$ by different lattices isomorphic to $\mathbb Z^2$, we get different tori. Somehow I think of the tori as having different ""structures"", but thinking more about it, I am not quite sure what different structures I am really thinking of. Two structures I am guessing at are complex structures and metrics. Could someone explain how these differ? Also, am I thinking of the right kind of structure? Are there other structures which vary with the lattice chosen?",,['differential-geometry']
36,Explicit formula for the curvaure of a connection,Explicit formula for the curvaure of a connection,,"Let $E$ be a vector bundle over $M$ and denote by $\mathcal{A}^k(E)$ the space of sections of $\Lambda^k (TM)^* \otimes E$, i.e. the space $k$-forms with values in $E$. A connection $\nabla:\mathcal{A}^0(E) \to \mathcal{A}^1(E)$ extends to a map $\nabla:\mathcal{A}^k(E) \to \mathcal{A}^{k+1}(E)$ by setting $\nabla(\alpha \otimes s)= d \alpha \otimes s + (-1)^k \alpha \wedge\nabla s$ and we can define the curvature of $\nabla$ as the composition $F_\nabla=\nabla \circ \nabla: \mathcal{A}^0(E) \to \mathcal{A}^2(E)$. From the Leibniz rule one can see that $F_{\nabla}(fs) = f F_{\nabla}(s)$ and therefore we can view $F_\nabla$ as an element of $\mathcal{A}^2(\text{End}(E))$ ($F_\nabla$ evaluated at a pair of tangent vectors is the endomorphism $s \mapsto F_\nabla(X,Y)(s)$. My question is whether the formula $F_{\nabla}(X,Y) = \nabla_X \nabla_Y  - \nabla_Y \nabla_Y - \nabla_{[X,Y]}$ holds true. I could prove it when $E=TM$ and $\nabla$ is a torsion free connection (because in that case we have a formula relating the exterior derivative with $\nabla$) but I don't know how to deal with the general case.","Let $E$ be a vector bundle over $M$ and denote by $\mathcal{A}^k(E)$ the space of sections of $\Lambda^k (TM)^* \otimes E$, i.e. the space $k$-forms with values in $E$. A connection $\nabla:\mathcal{A}^0(E) \to \mathcal{A}^1(E)$ extends to a map $\nabla:\mathcal{A}^k(E) \to \mathcal{A}^{k+1}(E)$ by setting $\nabla(\alpha \otimes s)= d \alpha \otimes s + (-1)^k \alpha \wedge\nabla s$ and we can define the curvature of $\nabla$ as the composition $F_\nabla=\nabla \circ \nabla: \mathcal{A}^0(E) \to \mathcal{A}^2(E)$. From the Leibniz rule one can see that $F_{\nabla}(fs) = f F_{\nabla}(s)$ and therefore we can view $F_\nabla$ as an element of $\mathcal{A}^2(\text{End}(E))$ ($F_\nabla$ evaluated at a pair of tangent vectors is the endomorphism $s \mapsto F_\nabla(X,Y)(s)$. My question is whether the formula $F_{\nabla}(X,Y) = \nabla_X \nabla_Y  - \nabla_Y \nabla_Y - \nabla_{[X,Y]}$ holds true. I could prove it when $E=TM$ and $\nabla$ is a torsion free connection (because in that case we have a formula relating the exterior derivative with $\nabla$) but I don't know how to deal with the general case.",,"['differential-geometry', 'vector-bundles', 'curvature']"
37,Alternate definition of a 'geodesic ball',Alternate definition of a 'geodesic ball',,"Background: Let $M$ be a Riemannian manifold.  Let $p \in M$ and $\epsilon \gt 0$. For sufficiently small $\epsilon$, the standard definition (correct me if I'm wrong) for the 'geodesic ball of radius $\epsilon$ centered at $p$' is: $$B = \{ \gamma(1) \mid \gamma \text{ is a geodesic}, \gamma(0)=p, \text{ and } \langle \gamma'(0), \gamma'(0) \rangle \, \lt \epsilon \} .$$ I am wondering: suppose we instead consider the set $$B_{\text{alt}} = \{ \gamma(\epsilon) \mid \gamma \text{ is a geodesic}, \gamma(0)=p, \text{ and } \langle \gamma'(0), \gamma'(0) \rangle  \lt 1 \} .$$ (Roughly speaking, $B$ takes an $\epsilon$-ball in $T_pM$ and runs the geodesics forward by 1, while $B_{\text{alt}}$ takes the unit ball in $T_pM$ and runs the geodesics forward by $\epsilon$.  $\langle \cdot , \cdot \rangle$ is the metric inner product.) Question: Do we have $B = B_{\text{alt}}$?  If not, is there a nice counter-example?  Or an intuitive reason why we should not expect the equality to hold? Note: I have tried to compute the volume of $B_{\text{alt}}$ (to next-to-leading order in $\epsilon$) in the special case of a two-dimensional manifold with a diagonal metric.  Despite many careful checks, my answer does not match the standard answer for the volume of a geodesic ball -- so I suspect that $B \ne B_{\text{alt}}$. Thanks for any help! Appendix - calculation of $Vol(B_{alt})$ (added 12/23) I'm going to redo my calculation of the volume of $B_{alt}$, taking account of joriki's comment below.  The problem I was having (which I don't think is resolved by joriki's suggestion to replace $\epsilon$ by $\epsilon^{1/2}$, but will have to check to be sure) is described in the next two paragraphs. I'm doing the calculation in a particular coordinate chart, assuming the metric is diagonal: $ds^2 = g_{11}(x^1,x^2) (dx^1)^2 + g_{22}(x^1,x^2) (dx^2)^2$.  I find that $Vol(B_{alt})$ includes (at next-to-leading order in $\epsilon$) the terms $(\partial_1)^2 g_{11}|_p$ and $(\partial_2)^2 g_{22}|_p$.  In a diagonal metric (and using the Levi-Civita connection), the only Christoffel symbol in which $\partial_1 g_{11}$ appears is $\Gamma^1_{11} = \frac{1}{2} g^{11} \partial_1 g_{11}$.  However, the formula $R^a_{bcd} = \partial_c \Gamma^a_{db} - \partial_d \Gamma^a_{cb} + \Gamma^a_{ce} \Gamma^e_{db} - \Gamma^a_{de} \Gamma^e_{cb}$ shows that $\partial_1 \Gamma^1_{11}$ doesn't appear in the scalar curvature - the first two terms in the preceeding formula just cancel when all indices are equal to 1. Now I will explain how these bad terms appear in my calculation.  My approach is to calculate $Vol(B_{alt}) = \int_{B_{alt}} dx^1 dx^2 \sqrt{g_{11}(x^1,x^2) g_{22}(x^1,x^2)}$ by Taylor-expanding the integrand about the point $p \leftrightarrow (x^1_0,x^2_0)$.  Given $a\ \partial_1 |_p + b\ \partial_2 |_p$ in the unit ball in $T_pM$, the corresponding point in $B_{alt}$ is $(x^1_0 + a\ \epsilon + C(a,b)\ \epsilon^2 + O(\epsilon^3), x^2_0 + b\ \epsilon + D(a,b)\ \epsilon^2 + O(\epsilon^3))$, where $C,D$ are constants we can get from the geodesic equation.(**)  There's a Jacobian factor to change variables from $(x^1, x^2)$ to $(a,b)$.  But the only way (it seems to me) to get the second derivatives of the metric that appear in $R$ is to Taylor-expand $\sqrt{det\quad g}$ to second order.  That's exactly the order at which the bad terms $(\partial_1)^2 g_{11}|_p$ and $(\partial_2)^2 g_{22}|_p$ appear (even if we replace $\epsilon$ by $\epsilon^{1/2}$). (**) $C(a,b) = -\frac{1}{2}(a^2 \Gamma^1_{11} + b^2 \Gamma^1_{22} + a\ b\ \Gamma^1_{12})|_p$. Thank you Srivatsan for your TeX edits... I am still fairly new to TeX.","Background: Let $M$ be a Riemannian manifold.  Let $p \in M$ and $\epsilon \gt 0$. For sufficiently small $\epsilon$, the standard definition (correct me if I'm wrong) for the 'geodesic ball of radius $\epsilon$ centered at $p$' is: $$B = \{ \gamma(1) \mid \gamma \text{ is a geodesic}, \gamma(0)=p, \text{ and } \langle \gamma'(0), \gamma'(0) \rangle \, \lt \epsilon \} .$$ I am wondering: suppose we instead consider the set $$B_{\text{alt}} = \{ \gamma(\epsilon) \mid \gamma \text{ is a geodesic}, \gamma(0)=p, \text{ and } \langle \gamma'(0), \gamma'(0) \rangle  \lt 1 \} .$$ (Roughly speaking, $B$ takes an $\epsilon$-ball in $T_pM$ and runs the geodesics forward by 1, while $B_{\text{alt}}$ takes the unit ball in $T_pM$ and runs the geodesics forward by $\epsilon$.  $\langle \cdot , \cdot \rangle$ is the metric inner product.) Question: Do we have $B = B_{\text{alt}}$?  If not, is there a nice counter-example?  Or an intuitive reason why we should not expect the equality to hold? Note: I have tried to compute the volume of $B_{\text{alt}}$ (to next-to-leading order in $\epsilon$) in the special case of a two-dimensional manifold with a diagonal metric.  Despite many careful checks, my answer does not match the standard answer for the volume of a geodesic ball -- so I suspect that $B \ne B_{\text{alt}}$. Thanks for any help! Appendix - calculation of $Vol(B_{alt})$ (added 12/23) I'm going to redo my calculation of the volume of $B_{alt}$, taking account of joriki's comment below.  The problem I was having (which I don't think is resolved by joriki's suggestion to replace $\epsilon$ by $\epsilon^{1/2}$, but will have to check to be sure) is described in the next two paragraphs. I'm doing the calculation in a particular coordinate chart, assuming the metric is diagonal: $ds^2 = g_{11}(x^1,x^2) (dx^1)^2 + g_{22}(x^1,x^2) (dx^2)^2$.  I find that $Vol(B_{alt})$ includes (at next-to-leading order in $\epsilon$) the terms $(\partial_1)^2 g_{11}|_p$ and $(\partial_2)^2 g_{22}|_p$.  In a diagonal metric (and using the Levi-Civita connection), the only Christoffel symbol in which $\partial_1 g_{11}$ appears is $\Gamma^1_{11} = \frac{1}{2} g^{11} \partial_1 g_{11}$.  However, the formula $R^a_{bcd} = \partial_c \Gamma^a_{db} - \partial_d \Gamma^a_{cb} + \Gamma^a_{ce} \Gamma^e_{db} - \Gamma^a_{de} \Gamma^e_{cb}$ shows that $\partial_1 \Gamma^1_{11}$ doesn't appear in the scalar curvature - the first two terms in the preceeding formula just cancel when all indices are equal to 1. Now I will explain how these bad terms appear in my calculation.  My approach is to calculate $Vol(B_{alt}) = \int_{B_{alt}} dx^1 dx^2 \sqrt{g_{11}(x^1,x^2) g_{22}(x^1,x^2)}$ by Taylor-expanding the integrand about the point $p \leftrightarrow (x^1_0,x^2_0)$.  Given $a\ \partial_1 |_p + b\ \partial_2 |_p$ in the unit ball in $T_pM$, the corresponding point in $B_{alt}$ is $(x^1_0 + a\ \epsilon + C(a,b)\ \epsilon^2 + O(\epsilon^3), x^2_0 + b\ \epsilon + D(a,b)\ \epsilon^2 + O(\epsilon^3))$, where $C,D$ are constants we can get from the geodesic equation.(**)  There's a Jacobian factor to change variables from $(x^1, x^2)$ to $(a,b)$.  But the only way (it seems to me) to get the second derivatives of the metric that appear in $R$ is to Taylor-expand $\sqrt{det\quad g}$ to second order.  That's exactly the order at which the bad terms $(\partial_1)^2 g_{11}|_p$ and $(\partial_2)^2 g_{22}|_p$ appear (even if we replace $\epsilon$ by $\epsilon^{1/2}$). (**) $C(a,b) = -\frac{1}{2}(a^2 \Gamma^1_{11} + b^2 \Gamma^1_{22} + a\ b\ \Gamma^1_{12})|_p$. Thank you Srivatsan for your TeX edits... I am still fairly new to TeX.",,"['differential-geometry', 'riemannian-geometry']"
38,Bundle orientability vs manifold orientability,Bundle orientability vs manifold orientability,,"Given a vector bundle, I am a bit hazy about the difference between the notions of its orientability as a bundle and as a manifold. I think I know that the following are true, A tangent bundle of a manifold is orientable if and only if the manifold is orientable. The tangent bundle of any manifold thought of as a new manifold is in some sense always ""trivially"" orientable. And also I vaguely remember there being something special about the orientability of the tangent bundle of the tangent bundle of the manifold. I am not aware if there is any generic relationship between the orientability of a vector bundle and its base manifold. It would be helpful if someone can help me tie up these loose ends and help me see the full picture.","Given a vector bundle, I am a bit hazy about the difference between the notions of its orientability as a bundle and as a manifold. I think I know that the following are true, A tangent bundle of a manifold is orientable if and only if the manifold is orientable. The tangent bundle of any manifold thought of as a new manifold is in some sense always ""trivially"" orientable. And also I vaguely remember there being something special about the orientability of the tangent bundle of the tangent bundle of the manifold. I am not aware if there is any generic relationship between the orientability of a vector bundle and its base manifold. It would be helpful if someone can help me tie up these loose ends and help me see the full picture.",,"['differential-geometry', 'differential-topology', 'differential-forms']"
39,Quotient of $ S^3 \times S^3$ by a free torus action.,Quotient of  by a free torus action., S^3 \times S^3,"I am looking for a direct method to compute the quotient of the action of the torus $T^2$ acting on $S^3 \times S^3$ (thinking of $T^2$ as pairs of complex numbers and $S^3$ as unit quaternions) where the action is given by $(z,w)\cdot (p,q)=(zp,z^{n+2k}q\bar{w})$ where $n$ and $k$ are any integers. I am pretty sure that the quotient should be $S^2 \times S^2$ , however, I've used up all of my usual tricks and cannot prove it.","I am looking for a direct method to compute the quotient of the action of the torus acting on (thinking of as pairs of complex numbers and as unit quaternions) where the action is given by where and are any integers. I am pretty sure that the quotient should be , however, I've used up all of my usual tricks and cannot prove it.","T^2 S^3 \times S^3 T^2 S^3 (z,w)\cdot (p,q)=(zp,z^{n+2k}q\bar{w}) n k S^2 \times S^2","['differential-geometry', 'algebraic-topology', 'lie-groups', 'riemannian-geometry']"
40,Intuition for nontrivial fiber bundles in terms of sections,Intuition for nontrivial fiber bundles in terms of sections,,"I understand the notion of a nontrivial fiber bundle with fiber $F$ over a base manifold $B$, as defined in terms of the projection map $\pi$: for any sufficiently small region $U \subset B$, the preimage $\pi^{-1}(U)$ is homeomorphic to the product space $U \times F$, but the preimage $\pi^{-1}(B)$ itself (the total space) is not homeomorphic to $B \times F$. The Mobius strip is a standard example for visual intuition. However, physicists like myself often think of a fiber bundle in terms of its sections rather than its projection map. Is there an equivalent definition of a nontrivial bundle formulated in terms of its sections $\sigma$ (the right-inverses of $\pi$)? I.e. a statement of the form ""a fiber bundle is nontrivial iff (some section $\sigma$ has)/(all sections $\sigma$ have) property $X$""? If not, is there any intuition for what the sections of a nontrivial bundle ""look like""? I know that a principle bundle is nontrivial iff it does not admit any global section, but I'm curious how things work for general fiber bundles.","I understand the notion of a nontrivial fiber bundle with fiber $F$ over a base manifold $B$, as defined in terms of the projection map $\pi$: for any sufficiently small region $U \subset B$, the preimage $\pi^{-1}(U)$ is homeomorphic to the product space $U \times F$, but the preimage $\pi^{-1}(B)$ itself (the total space) is not homeomorphic to $B \times F$. The Mobius strip is a standard example for visual intuition. However, physicists like myself often think of a fiber bundle in terms of its sections rather than its projection map. Is there an equivalent definition of a nontrivial bundle formulated in terms of its sections $\sigma$ (the right-inverses of $\pi$)? I.e. a statement of the form ""a fiber bundle is nontrivial iff (some section $\sigma$ has)/(all sections $\sigma$ have) property $X$""? If not, is there any intuition for what the sections of a nontrivial bundle ""look like""? I know that a principle bundle is nontrivial iff it does not admit any global section, but I'm curious how things work for general fiber bundles.",,"['differential-geometry', 'intuition', 'fiber-bundles']"
41,"$\omega_{FS}^n$, the top form of Fubini Study metric",", the top form of Fubini Study metric",\omega_{FS}^n,"Given $\mathbb{C}P^n$, we look at the open set $U_0 = \{[Z_0, \cdots, Z_n]: Z_0 \neq 0\}$, and a coordinate map $\phi: U_0 \rightarrow \mathbb{C}^n$ by  $$[Z_0,\cdots Z_n] \mapsto (Z_1/Z_0, \cdots, Z_n/Z_0).$$ Recall that the Fubini-Study metric $\omega_{FS}$ on $U_0$ is defined as  $$(\phi^{-1})^*\omega_{FS}  =  \frac{i}{2} \sum_{j,k}\frac{(1+|z|^2)\delta_{jk} - \bar z_j z_k}{(1+|z|^2)^2} dz_j \wedge d\bar z_k.$$ I want to show that  $$\int_{U_0} \omega_{FS}^n  = \int_{\mathbb{C}^n} (\phi^{-1})^*\omega_{FS}^n = \pi^n$$  (I showed this for $\mathbb{C}P^1$) but I am having trouble seeing what the wedge product is for  $$(\phi^{-1})^*\omega_{FS}^n=  \Big((\phi^{-1})^*\omega_{FS}\Big)^n.$$ Edit: I did the following calculation for $\mathbb{C}P^2$, we have the wedge product with itself \begin{gather} \left(\frac{-z_1 \bar z_2}{(1+|z|^2)^2} dz_2 \wedge d\bar z_1 + \frac{-z_2 \bar z_1}{(1+|z|^2)^2} dz_1 \wedge d\bar z_2 \\ + \frac{((1+|z|^2)-|z_1|^2}{(1+|z|^2)^2} dz_1 \wedge d\bar z_1+\frac{((1+|z|^2)-|z_2|^2}{(1+|z|^2)^2} dz_2 \wedge d\bar z_2\right)^{\wedge 2}\\ = \frac{2}{(1+|z|^2)^3} dz_1\wedge d\bar z_1\wedge dz_2 \wedge d\bar z_2 \end{gather} Now combine the constants from Fubini-Study metric, we have \begin{gather} \int_{U_0} \omega_{FS}^2 = \int_{\mathbb{C}^2} \frac{-1}{4}\frac{2}{(1+|z|^2)^3} dz_1\wedge d\bar z_1\wedge dz_2 \wedge d\bar z_2 \\ = 4\int_{\mathbb{R}^4} \frac{1}{4}\frac{2}{(1+|x|^2)^3} dx_1dx_2dx_3dx_4\\ = 2\left(\frac{2\pi^2}{1!}\right)\int_0^\infty \frac{r^3}{(1+r^2)^3} dr  \end{gather} using trig substitution for $[x=\tan \theta]$, I got $\pi^2$ for the final calculation.","Given $\mathbb{C}P^n$, we look at the open set $U_0 = \{[Z_0, \cdots, Z_n]: Z_0 \neq 0\}$, and a coordinate map $\phi: U_0 \rightarrow \mathbb{C}^n$ by  $$[Z_0,\cdots Z_n] \mapsto (Z_1/Z_0, \cdots, Z_n/Z_0).$$ Recall that the Fubini-Study metric $\omega_{FS}$ on $U_0$ is defined as  $$(\phi^{-1})^*\omega_{FS}  =  \frac{i}{2} \sum_{j,k}\frac{(1+|z|^2)\delta_{jk} - \bar z_j z_k}{(1+|z|^2)^2} dz_j \wedge d\bar z_k.$$ I want to show that  $$\int_{U_0} \omega_{FS}^n  = \int_{\mathbb{C}^n} (\phi^{-1})^*\omega_{FS}^n = \pi^n$$  (I showed this for $\mathbb{C}P^1$) but I am having trouble seeing what the wedge product is for  $$(\phi^{-1})^*\omega_{FS}^n=  \Big((\phi^{-1})^*\omega_{FS}\Big)^n.$$ Edit: I did the following calculation for $\mathbb{C}P^2$, we have the wedge product with itself \begin{gather} \left(\frac{-z_1 \bar z_2}{(1+|z|^2)^2} dz_2 \wedge d\bar z_1 + \frac{-z_2 \bar z_1}{(1+|z|^2)^2} dz_1 \wedge d\bar z_2 \\ + \frac{((1+|z|^2)-|z_1|^2}{(1+|z|^2)^2} dz_1 \wedge d\bar z_1+\frac{((1+|z|^2)-|z_2|^2}{(1+|z|^2)^2} dz_2 \wedge d\bar z_2\right)^{\wedge 2}\\ = \frac{2}{(1+|z|^2)^3} dz_1\wedge d\bar z_1\wedge dz_2 \wedge d\bar z_2 \end{gather} Now combine the constants from Fubini-Study metric, we have \begin{gather} \int_{U_0} \omega_{FS}^2 = \int_{\mathbb{C}^2} \frac{-1}{4}\frac{2}{(1+|z|^2)^3} dz_1\wedge d\bar z_1\wedge dz_2 \wedge d\bar z_2 \\ = 4\int_{\mathbb{R}^4} \frac{1}{4}\frac{2}{(1+|x|^2)^3} dx_1dx_2dx_3dx_4\\ = 2\left(\frac{2\pi^2}{1!}\right)\int_0^\infty \frac{r^3}{(1+r^2)^3} dr  \end{gather} using trig substitution for $[x=\tan \theta]$, I got $\pi^2$ for the final calculation.",,"['differential-geometry', 'manifolds', 'riemannian-geometry']"
42,Example of two atlases on a manifold $M$ which give rise to different sets of smooth functions on $M$.,Example of two atlases on a manifold  which give rise to different sets of smooth functions on .,M M,"Lee states that there will be many possible atlases that give rise to the same smooth structures on a manifold $M$; that is they determine the same collection of smooth functions on $M$. Unfortunately, I don't see how different atlases will give rise to different collections of smooth functions in the first place. For example, I'm struggling to think of two atlases on $\mathbb{R}$ which would not give the same collection of smooth functions; namely the ones in the sense of ordinary calculus. Could someone provide me with an example of a manifold and two atlases on this manifold such that the collection of smooth functions determined by the atlases are not equivalent?","Lee states that there will be many possible atlases that give rise to the same smooth structures on a manifold $M$; that is they determine the same collection of smooth functions on $M$. Unfortunately, I don't see how different atlases will give rise to different collections of smooth functions in the first place. For example, I'm struggling to think of two atlases on $\mathbb{R}$ which would not give the same collection of smooth functions; namely the ones in the sense of ordinary calculus. Could someone provide me with an example of a manifold and two atlases on this manifold such that the collection of smooth functions determined by the atlases are not equivalent?",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
43,How to differentiate exponential map with parameter dependent basepoint,How to differentiate exponential map with parameter dependent basepoint,,"Let $(M,g)$ be a  Riemannian manifold, $\gamma:I\rightarrow M$ a geodesic. Let $c:(-\varepsilon,\varepsilon)$ is defined to be another geodesic with  $$c(0)= \gamma(0),\ \ \ c^\prime(0)=X.$$ Let $V(s)$,$W(s)$ be parallel vector fields along $c$. The derivative that I want to compute is  $$\frac{\partial}{\partial s}\exp_{c(s)} \big(t\cdot(V(s)+sW(s))\big)$$ at $s=0$. I looked at examples, but there is no such thing as the $c(t)$ there so I can not figure it out. Thank you very much, I hope it is not a too simple calculation question for this forum.","Let $(M,g)$ be a  Riemannian manifold, $\gamma:I\rightarrow M$ a geodesic. Let $c:(-\varepsilon,\varepsilon)$ is defined to be another geodesic with  $$c(0)= \gamma(0),\ \ \ c^\prime(0)=X.$$ Let $V(s)$,$W(s)$ be parallel vector fields along $c$. The derivative that I want to compute is  $$\frac{\partial}{\partial s}\exp_{c(s)} \big(t\cdot(V(s)+sW(s))\big)$$ at $s=0$. I looked at examples, but there is no such thing as the $c(t)$ there so I can not figure it out. Thank you very much, I hope it is not a too simple calculation question for this forum.",,"['differential-geometry', 'riemannian-geometry']"
44,How does a left group action on the fiber of a principal bundle induce a right action on the total space?,How does a left group action on the fiber of a principal bundle induce a right action on the total space?,,"Suppose I define a ""principal $G$-bundle"" as follows: A principal $G$-bundle is a fiber bundle $F \to P \overset{\pi}{\to} X$ with a left group action of $G$ on $F$ that is free and transitive, together with a trivializing cover whose transition maps are $G$-valued. However, it seems that many references define ""principal $G$-bundle"" via a right action of $G$ on $P$ (not $F$). How does my definition induce a natural right action of $G$ on $P$?  Can this be done without saying the phrase ""identify $F$ with $G$""? The reason I would like to avoid this identification is two-fold.  First, I would like to keep the fiber $F$ and the group $G$ separate in my head -- at least for now -- in part because not all $G$-bundles are principal.  Second, and more importantly, I am concerned that any identification of $F$ with $G$ will involve an arbitrary choice of base-point of $F$, and I would rather not make such unnecessary choices if possible. Ultimately, I would like to say that the specified trivializations in my definition of ""principal $G$-bundle"" are $G$-equivariant with respect to the actions on $P$ and $F$.  I would like to deduce this as a consequence of the definition of the $G$-action on $P$, rather than taking this equivariance as the definition of the action. Aside: As usual, this question is a refinement of a previous, less focused question of mine.","Suppose I define a ""principal $G$-bundle"" as follows: A principal $G$-bundle is a fiber bundle $F \to P \overset{\pi}{\to} X$ with a left group action of $G$ on $F$ that is free and transitive, together with a trivializing cover whose transition maps are $G$-valued. However, it seems that many references define ""principal $G$-bundle"" via a right action of $G$ on $P$ (not $F$). How does my definition induce a natural right action of $G$ on $P$?  Can this be done without saying the phrase ""identify $F$ with $G$""? The reason I would like to avoid this identification is two-fold.  First, I would like to keep the fiber $F$ and the group $G$ separate in my head -- at least for now -- in part because not all $G$-bundles are principal.  Second, and more importantly, I am concerned that any identification of $F$ with $G$ will involve an arbitrary choice of base-point of $F$, and I would rather not make such unnecessary choices if possible. Ultimately, I would like to say that the specified trivializations in my definition of ""principal $G$-bundle"" are $G$-equivariant with respect to the actions on $P$ and $F$.  I would like to deduce this as a consequence of the definition of the $G$-action on $P$, rather than taking this equivariance as the definition of the action. Aside: As usual, this question is a refinement of a previous, less focused question of mine.",,"['differential-geometry', 'differential-topology', 'geometric-topology', 'fiber-bundles', 'principal-bundles']"
45,Connection on pullback bundle,Connection on pullback bundle,,"Let $\mathcal{V}\stackrel{\pi_N}{\longrightarrow}N$ be a $V$-vector bundle on a smooth manifold $N$, let $D$ a connection on this bundle and let $f:M\rightarrow N$ be a smooth function. Then we can define the pullback bundle $f^*\mathcal{V}\stackrel{\pi_M}{\longrightarrow}M$ as the bundle given by all the elements of type $\{(p,v)|p\in M,\ \pi_N(v)=f(p)\}$ (with the obvious projection $\pi_M$). Now I have been told that $D$ induces a connection ${}^fD$ on the pullback bundle which is completely determined by the fact that if $\eta$ is a section of $\mathcal{V}\stackrel{\pi_N}{\longrightarrow}N$ and $v\in T_pM$, then $${}^fD_vf^*\eta=D_{f^*v}\eta$$ I have a feeling that it is not true, because there could be sections of $f^*\mathcal{V}\stackrel{\pi_M}{\longrightarrow}M$ that are not the pullback of any section of $\mathcal{V}\stackrel{\pi_N}{\longrightarrow}N$. Am I wrong or there is really something missing to describe completely ${}^fD$?","Let $\mathcal{V}\stackrel{\pi_N}{\longrightarrow}N$ be a $V$-vector bundle on a smooth manifold $N$, let $D$ a connection on this bundle and let $f:M\rightarrow N$ be a smooth function. Then we can define the pullback bundle $f^*\mathcal{V}\stackrel{\pi_M}{\longrightarrow}M$ as the bundle given by all the elements of type $\{(p,v)|p\in M,\ \pi_N(v)=f(p)\}$ (with the obvious projection $\pi_M$). Now I have been told that $D$ induces a connection ${}^fD$ on the pullback bundle which is completely determined by the fact that if $\eta$ is a section of $\mathcal{V}\stackrel{\pi_N}{\longrightarrow}N$ and $v\in T_pM$, then $${}^fD_vf^*\eta=D_{f^*v}\eta$$ I have a feeling that it is not true, because there could be sections of $f^*\mathcal{V}\stackrel{\pi_M}{\longrightarrow}M$ that are not the pullback of any section of $\mathcal{V}\stackrel{\pi_N}{\longrightarrow}N$. Am I wrong or there is really something missing to describe completely ${}^fD$?",,"['differential-geometry', 'vector-bundles']"
46,Metric on Steifel and Grassmannian manifolds generalizing Fubini-Study,Metric on Steifel and Grassmannian manifolds generalizing Fubini-Study,,"If $F$ is $\mathbb{R}, \mathbb{C}$, or $ \mathbb{H}$, the Grassmannian manifold $G_k(\textbf F^n)$ is the space of all $k$ dimensional subspaces of the $n$ dimensional vector space $F^n$. The Stiefel manifold $V_k(\textbf F^n)$ is the set of $k$-tuples representing $k$ orthonormal vectors in $F^n$. In other words $$ V_k(\textbf F^n) = \{A\in\text{Mat}_{n\times k}(\textbf F^n)|A^\ast A = I_{k\times k}\}.$$ There is a natural projection $V_k(\textbf F^n)\longrightarrow G_k(\textbf F^n)$ sending a $k$-tuple to the $k$-dimensional subspace that it spans. The fiber of this projection over each point is all $k$-tuples that live in a fixed $k$-dimensional subspace of $\textbf F^n$, which can be thought of $V_k(\textbf F^k) = O(k,\textbf F)$. So we have the fibrations $$ O(k,\textbf F)\rightarrow V_k(\textbf F^n)\longrightarrow G_k(\textbf F^n).$$ When $k=1$, these reduce to the Hopf fibrations \begin{eqnarray*}S^0&\rightarrow& S^{n-1}\longrightarrow \mathbb{R}P^{n-1}\\ S^1&\rightarrow& S^{2n-1}\longrightarrow \mathbb{C}P^{n-1}\\ S^3&\rightarrow& S^{4n-1}\longrightarrow \mathbb{H}P^{n-1}\end{eqnarray*} If each of the spheres $S^{n-1}, S^{2n-1},$ and $S^{4n-1}$ are given the round metric, there are ""natural"" metrics on $\mathbb{R}P^{n}, \mathbb{C}P^{n},$ and $\mathbb{H}P^{n}$, respectively, defined as the metrics that make these submersions Riemannian submersions. When $\textbf{F} = \mathbb{R}$, this is the constant curvature 1 metric on $\mathbb{R}P^n$ and when $\textbf F=\mathbb{C}$, this is the Fubini-Study metric on $\textbf{C}P^n$. Question: Are there ""natural"" metrics on $V_k(\textbf{F}^n)$ which give generalization of this? That is, is there a generalization of the Fubini-study metric to $G_k(\textbf{F}^n)$. If so, (where) can I find out more information about these metrics? If not, why won't it work?","If $F$ is $\mathbb{R}, \mathbb{C}$, or $ \mathbb{H}$, the Grassmannian manifold $G_k(\textbf F^n)$ is the space of all $k$ dimensional subspaces of the $n$ dimensional vector space $F^n$. The Stiefel manifold $V_k(\textbf F^n)$ is the set of $k$-tuples representing $k$ orthonormal vectors in $F^n$. In other words $$ V_k(\textbf F^n) = \{A\in\text{Mat}_{n\times k}(\textbf F^n)|A^\ast A = I_{k\times k}\}.$$ There is a natural projection $V_k(\textbf F^n)\longrightarrow G_k(\textbf F^n)$ sending a $k$-tuple to the $k$-dimensional subspace that it spans. The fiber of this projection over each point is all $k$-tuples that live in a fixed $k$-dimensional subspace of $\textbf F^n$, which can be thought of $V_k(\textbf F^k) = O(k,\textbf F)$. So we have the fibrations $$ O(k,\textbf F)\rightarrow V_k(\textbf F^n)\longrightarrow G_k(\textbf F^n).$$ When $k=1$, these reduce to the Hopf fibrations \begin{eqnarray*}S^0&\rightarrow& S^{n-1}\longrightarrow \mathbb{R}P^{n-1}\\ S^1&\rightarrow& S^{2n-1}\longrightarrow \mathbb{C}P^{n-1}\\ S^3&\rightarrow& S^{4n-1}\longrightarrow \mathbb{H}P^{n-1}\end{eqnarray*} If each of the spheres $S^{n-1}, S^{2n-1},$ and $S^{4n-1}$ are given the round metric, there are ""natural"" metrics on $\mathbb{R}P^{n}, \mathbb{C}P^{n},$ and $\mathbb{H}P^{n}$, respectively, defined as the metrics that make these submersions Riemannian submersions. When $\textbf{F} = \mathbb{R}$, this is the constant curvature 1 metric on $\mathbb{R}P^n$ and when $\textbf F=\mathbb{C}$, this is the Fubini-Study metric on $\textbf{C}P^n$. Question: Are there ""natural"" metrics on $V_k(\textbf{F}^n)$ which give generalization of this? That is, is there a generalization of the Fubini-study metric to $G_k(\textbf{F}^n)$. If so, (where) can I find out more information about these metrics? If not, why won't it work?",,"['differential-geometry', 'riemannian-geometry']"
47,Proposition 3.6 part 1 - Do Carmo's Riemannian Geometry,Proposition 3.6 part 1 - Do Carmo's Riemannian Geometry,,"Proposition 3.6 Let $p \in \mathcal{M}$ , $U$ a normal neighborhood of $p$ , $B \subset U$ a normal ball of center $p$ . Let $\gamma : [0,1] \to B$ be a geodesic segment with $\gamma(0) = p$ . If $c : [0,1]\to \mathcal{M}$ is any piecewise differentiable curve joining $\gamma(0)$ to $\gamma(1)$ then $l(\gamma) \leq l(c)$ and if equality holds then $\gamma([0,1]) = c([0,1])$ . For the proof Suppose initially that $c([0,1]) \subset B$ . Since $\exp_p$ is a diffeomorphism on $U$ , the curve $c(t)$ , for $t \neq 0$ , can be written uniquely as $\exp_p (r(t) \cdot v(t)) = f(r(t),t)$ where $t \to v(t)$ is a curve in $T_p\mathcal{M}$ with $\left| v(t) \right| = 1$ and $r : (0,1] \to \mathbb{R}$ is a positive piecewise differentiable function. The first question is why can $c(t)$ be written in such a way? My first guess is because in $B$ by definition of exponential map there's a unique geodesic such that $$ \exp_p(v) = \alpha(1,p,v) $$ And I can write $v$ in the form stated in the theorem and the equation $$ c(t) = \exp_p(v) $$ Is well defined. Carrying on with the prof It follows that, except for a finite number of points, $$ \frac{dc}{dt} = \frac{\partial f}{\partial r} r'(t) + \frac{\partial f}{\partial t} $$ I think it's clear the rule applied is essentially the chain rule. However I do struggle to derive the formula using the definition of differentials in manifolds (rigorously). My attempt was to decompose $f$ as $$ t \to (r(t),t) \to f(r(t),t) $$ So $f = f_2 \circ f_1$ , where $f_1 : \mathbb{R} \to \mathbb{R}^2$ and $f_2 : \mathbb{R}^2 \to \mathcal{M}$ , for $f_1$ the differential is simply a derivative wrt $t$ componentwise. For $f_2$ I would assume I can use $$ d f_{2_{(r,t)}} = \left[ d f_{2_{(r,t)}} \left( \frac{\partial}{\partial r} \right) \; d f_{2_{(r,t)}} \left(\frac{\partial}{\partial t} \right) \right] $$ And using the author notation I'll end up with the same expression, the question is whether my derivation is correct. Finally From the Gauss lemma, $\left\langle \frac{\partial f}{\partial r}, \frac{\partial f}{\partial t} \right\rangle = 0$ I'd assume from the Gauss Lemma more specifically it follows that $$\left\langle \frac{\partial f}{\partial r}, \frac{\partial f}{\partial t} \right\rangle = \left\langle \frac{\partial}{\partial r}, \frac{\partial}{\partial t} \right\rangle$$ And the two vectors $\frac{\partial}{\partial r}$ and $\frac{\partial}{\partial t}$ and these are orthogonal. Again, is this correct? Very last bit Since $\left| \frac{\partial f}{\partial r} \right| = 1$ , ...   I'm not quite sure I understand why is 1, could you explain? I'm still reading through the rest of the proof it seems ok, but I'll potentially ask a different question. Also just to clarify shouldn't the expression $$ \frac{dc}{dt} = \frac{\partial f}{\partial r} r'(t) + \frac{\partial f}{\partial t} $$ actually be $$ \frac{dc}{dt} = r'(t) \frac{\partial f}{\partial r} + \frac{\partial f}{\partial t} $$ Mostly because $r'(t)$ is considered an element of a scalar field, while $\frac{\partial f}{\partial r}$ is a vector. Thank you","Proposition 3.6 Let , a normal neighborhood of , a normal ball of center . Let be a geodesic segment with . If is any piecewise differentiable curve joining to then and if equality holds then . For the proof Suppose initially that . Since is a diffeomorphism on , the curve , for , can be written uniquely as where is a curve in with and is a positive piecewise differentiable function. The first question is why can be written in such a way? My first guess is because in by definition of exponential map there's a unique geodesic such that And I can write in the form stated in the theorem and the equation Is well defined. Carrying on with the prof It follows that, except for a finite number of points, I think it's clear the rule applied is essentially the chain rule. However I do struggle to derive the formula using the definition of differentials in manifolds (rigorously). My attempt was to decompose as So , where and , for the differential is simply a derivative wrt componentwise. For I would assume I can use And using the author notation I'll end up with the same expression, the question is whether my derivation is correct. Finally From the Gauss lemma, I'd assume from the Gauss Lemma more specifically it follows that And the two vectors and and these are orthogonal. Again, is this correct? Very last bit Since , ...   I'm not quite sure I understand why is 1, could you explain? I'm still reading through the rest of the proof it seems ok, but I'll potentially ask a different question. Also just to clarify shouldn't the expression actually be Mostly because is considered an element of a scalar field, while is a vector. Thank you","p \in \mathcal{M} U p B \subset U p \gamma : [0,1] \to B \gamma(0) = p c : [0,1]\to \mathcal{M} \gamma(0) \gamma(1) l(\gamma) \leq l(c) \gamma([0,1]) = c([0,1]) c([0,1]) \subset B \exp_p U c(t) t \neq 0 \exp_p (r(t) \cdot v(t)) = f(r(t),t) t \to v(t) T_p\mathcal{M} \left| v(t) \right| = 1 r : (0,1] \to \mathbb{R} c(t) B 
\exp_p(v) = \alpha(1,p,v)
 v 
c(t) = \exp_p(v)
 
\frac{dc}{dt} = \frac{\partial f}{\partial r} r'(t) + \frac{\partial f}{\partial t}
 f 
t \to (r(t),t) \to f(r(t),t)
 f = f_2 \circ f_1 f_1 : \mathbb{R} \to \mathbb{R}^2 f_2 : \mathbb{R}^2 \to \mathcal{M} f_1 t f_2 
d f_{2_{(r,t)}} = \left[ d f_{2_{(r,t)}} \left( \frac{\partial}{\partial r} \right) \; d f_{2_{(r,t)}} \left(\frac{\partial}{\partial t} \right) \right]
 \left\langle \frac{\partial f}{\partial r}, \frac{\partial f}{\partial t} \right\rangle = 0 \left\langle \frac{\partial f}{\partial r}, \frac{\partial f}{\partial t} \right\rangle = \left\langle \frac{\partial}{\partial r}, \frac{\partial}{\partial t} \right\rangle \frac{\partial}{\partial r} \frac{\partial}{\partial t} \left| \frac{\partial f}{\partial r} \right| = 1 
\frac{dc}{dt} = \frac{\partial f}{\partial r} r'(t) + \frac{\partial f}{\partial t}
 
\frac{dc}{dt} = r'(t) \frac{\partial f}{\partial r} + \frac{\partial f}{\partial t}
 r'(t) \frac{\partial f}{\partial r}","['differential-geometry', 'manifolds', 'riemannian-geometry']"
48,Two different definitions of a Liouville measure,Two different definitions of a Liouville measure,,"Ok, I'm currently confused because of two different definitions for the Liouville measure associated to a smooth manifold $M$ of dimension $n$. These are: a) The measure $\mu$ on the cotangent bundle $T^*M$ induced by the volume form $(d\alpha)^n$ where $\alpha$ is the canonical 1-form on $T^*M$ and $\omega:=d\alpha$ makes $T^*M$ a symplectic manifold. This $\mu$ is invariant under any Hamiltonian flow (that is, any flow that integrates a vector field $X_H$ defined for some smooth $H:T^*M\to \mathbb{R}$ by $\theta(X_H)=\omega(\theta,dH)$ for all $\theta\in T^*(T^*M)$ ). b) The measure $\nu$ that may be defined, once $M$ is endowed with a Riemannian metric $g$, on $SM$, the unit tangent bundle. This measure is given locally by the product of the Riemannian volume on $M$ (i.e. $\text{det}(g_{ij})dx_1\wedge\dots\wedge dx_n$) and the usual Lebesgue measure on the unit sphere. This $\nu$ is invariant under the geodesic flow on $SM$. Now, what is, if any, the relationship between these measures? I imagine that once $M$ is endowed with $g$ we can identify $T^*M$ with $TM$ ($q,p\to q,v$ iff $p(v')=g(v,v')$ for al $v'\in T_qM$). Will then the restriction of $\mu$ to the unit cotangent bundle (assuming this restriction to a submanifold of smaller dimension is well defined) correspond to $\nu$? It's the only reason I could imagine for giving the same name to two different measures defined on two different spaces ($T^*M$ and $SM$, respectively), but I could not find such a statement on any reference book.","Ok, I'm currently confused because of two different definitions for the Liouville measure associated to a smooth manifold $M$ of dimension $n$. These are: a) The measure $\mu$ on the cotangent bundle $T^*M$ induced by the volume form $(d\alpha)^n$ where $\alpha$ is the canonical 1-form on $T^*M$ and $\omega:=d\alpha$ makes $T^*M$ a symplectic manifold. This $\mu$ is invariant under any Hamiltonian flow (that is, any flow that integrates a vector field $X_H$ defined for some smooth $H:T^*M\to \mathbb{R}$ by $\theta(X_H)=\omega(\theta,dH)$ for all $\theta\in T^*(T^*M)$ ). b) The measure $\nu$ that may be defined, once $M$ is endowed with a Riemannian metric $g$, on $SM$, the unit tangent bundle. This measure is given locally by the product of the Riemannian volume on $M$ (i.e. $\text{det}(g_{ij})dx_1\wedge\dots\wedge dx_n$) and the usual Lebesgue measure on the unit sphere. This $\nu$ is invariant under the geodesic flow on $SM$. Now, what is, if any, the relationship between these measures? I imagine that once $M$ is endowed with $g$ we can identify $T^*M$ with $TM$ ($q,p\to q,v$ iff $p(v')=g(v,v')$ for al $v'\in T_qM$). Will then the restriction of $\mu$ to the unit cotangent bundle (assuming this restriction to a submanifold of smaller dimension is well defined) correspond to $\nu$? It's the only reason I could imagine for giving the same name to two different measures defined on two different spaces ($T^*M$ and $SM$, respectively), but I could not find such a statement on any reference book.",,"['differential-geometry', 'riemannian-geometry', 'symplectic-geometry']"
49,Non-vanishing differential forms,Non-vanishing differential forms,,"Let $M$ be a differentiable manifold of dimension $n$. If the tangent bundle is trivial, then the cotangent bundle is trivial, and so are its exterior powers. In other words, on a parallelizable manifold we can also find parallel (and so, non-vanishing) differential forms of any degree up to $n$. I have the ""converse"" question. Suppose we have a globally non-vanishing form of degree $k\le n$. Does this imply any condition on the bundles (either cotangent, or its exterior powers)? What if we have $n\choose k$ independent forms? For example, it is clear that if $k=n$ the only condition is that the manifold is orientable (what does it mean in terms of bundles?). What happens for the generic order $k$? Thanks.","Let $M$ be a differentiable manifold of dimension $n$. If the tangent bundle is trivial, then the cotangent bundle is trivial, and so are its exterior powers. In other words, on a parallelizable manifold we can also find parallel (and so, non-vanishing) differential forms of any degree up to $n$. I have the ""converse"" question. Suppose we have a globally non-vanishing form of degree $k\le n$. Does this imply any condition on the bundles (either cotangent, or its exterior powers)? What if we have $n\choose k$ independent forms? For example, it is clear that if $k=n$ the only condition is that the manifold is orientable (what does it mean in terms of bundles?). What happens for the generic order $k$? Thanks.",,"['differential-geometry', 'differential-forms', 'vector-bundles', 'exterior-algebra']"
50,A linear connection induces a covariant derivative of tensor fields.,A linear connection induces a covariant derivative of tensor fields.,,"Let $M$ be a smooth manifold. notation: $\mathcal T(M)^{(k,l)}$ is the $C^{\infty}(M)$-module of all tensor fields of type $(k,l)$ on $M$ ($k$ indicates the covariant part). $\mathcal T(M):=\mathcal T(M)^{(1,0)}$ is the $C^{\infty}(M)$-module of all vector fields on $M$. All tensor fields are smooth. Now let $\nabla:\mathcal T(M)\times\mathcal T(M)\to \mathcal T(M)$ be a linear connection on $M$; $\nabla$ should be extended in a unique way to a (Koszul) connection, indicated with the same name, $$\nabla:\mathcal T(M)\times\mathcal T(M)^{(k,l)}\to\mathcal T(M)^{(k,l)}$$ $$(X,Y)\mapsto\nabla_XY$$ respecting some properties. I don't understand in which way the tensor field $\nabla_XY$ is defined. By the characterization lemma of tensor fields it is enough to give a multilinear function: $$\varphi:\underbrace{\mathcal T(M)^{(0,1)}\times \mathcal T(M)^{(0,1)}}_{k}\times\underbrace{\mathcal T(M)^{(1,0)}\times\ldots\times \mathcal T(M)^{(1,0)}}_{l}\to C^{\infty}(M)$$ but how can I define such $\varphi$?","Let $M$ be a smooth manifold. notation: $\mathcal T(M)^{(k,l)}$ is the $C^{\infty}(M)$-module of all tensor fields of type $(k,l)$ on $M$ ($k$ indicates the covariant part). $\mathcal T(M):=\mathcal T(M)^{(1,0)}$ is the $C^{\infty}(M)$-module of all vector fields on $M$. All tensor fields are smooth. Now let $\nabla:\mathcal T(M)\times\mathcal T(M)\to \mathcal T(M)$ be a linear connection on $M$; $\nabla$ should be extended in a unique way to a (Koszul) connection, indicated with the same name, $$\nabla:\mathcal T(M)\times\mathcal T(M)^{(k,l)}\to\mathcal T(M)^{(k,l)}$$ $$(X,Y)\mapsto\nabla_XY$$ respecting some properties. I don't understand in which way the tensor field $\nabla_XY$ is defined. By the characterization lemma of tensor fields it is enough to give a multilinear function: $$\varphi:\underbrace{\mathcal T(M)^{(0,1)}\times \mathcal T(M)^{(0,1)}}_{k}\times\underbrace{\mathcal T(M)^{(1,0)}\times\ldots\times \mathcal T(M)^{(1,0)}}_{l}\to C^{\infty}(M)$$ but how can I define such $\varphi$?",,"['differential-geometry', 'riemannian-geometry', 'tensors']"
51,Symplectic geometry as a prerequisite for Heegaard Floer homology,Symplectic geometry as a prerequisite for Heegaard Floer homology,,"I would like to study Heegaard Floer homology in the future in the connection to knot theory. I read a wikipedia article and it seems that I need to first learn a symplectic geometry (topology?). I took a basic differential geometry class. But I have never studied symplectic geometry. What is a good way to study symplectic geometry in the scope of studying Heegaard Floer homology in the future? What textbook is adequate fo this purpose. Also, what are the other prerequisites? I know basics of algebraic topology.","I would like to study Heegaard Floer homology in the future in the connection to knot theory. I read a wikipedia article and it seems that I need to first learn a symplectic geometry (topology?). I took a basic differential geometry class. But I have never studied symplectic geometry. What is a good way to study symplectic geometry in the scope of studying Heegaard Floer homology in the future? What textbook is adequate fo this purpose. Also, what are the other prerequisites? I know basics of algebraic topology.",,"['differential-geometry', 'algebraic-topology']"
52,What would be the shortest path between 2 points when there are objects obstructing the straight path?,What would be the shortest path between 2 points when there are objects obstructing the straight path?,,"How would an algorithm find the shortest distance between 2 points on a horizontal 2d plane , especially when a straight path is not possible? Could it be something on the lines of calculating least displacement from the straight path?","How would an algorithm find the shortest distance between 2 points on a horizontal 2d plane , especially when a straight path is not possible? Could it be something on the lines of calculating least displacement from the straight path?",,"['differential-geometry', 'algorithms', 'artificial-intelligence']"
53,Second fundamental form for Lie group $SO(n)$,Second fundamental form for Lie group,SO(n),"I'm given $\mathbb{R}^{n^2} = \mathbb{R}^{n \times n}$ with the usual metric $\langle A, B \rangle = \text{Trace} (AB^T) = \text{Trace} (A^T B)$ . Then $SO(n)$ is a submanifold of $\mathbb{R}^{n^2}$ of dimension $\frac{1}{2} n (n-1)$ . I have shown that the tangent space $T_{I} SO(n)$ consists of all skew-symmetric matrices with zero trace. I wish to show that the normal space $N_I SO(n)$ consists of symmetric matrices. Furthermore, I need to calculate the second fundamental form tensor for $SO(n)$ . I'm given $X$ and $Y$ left-invariant vector fields determined by skew-symmetric matrices at the identity. If $O$ is an arbitrary orthogonal matrix, then $X(O) = OA $ and $Y(O) = OB$ . I need to prove that $$D_Y X(O) = \frac{1}{2} O [B, A] + \frac{1}{2} O (BA + AB) $$ and to find expressions for $\nabla_Y X$ , $h(X,Y)$ and $[X, Y]$ . Here $\nabla_X Y$ denotes the covariant derivative on $SO(n)$ , while $D_X Y$ denotes the covariant derivative on $\mathbb{R}^{n^2}$ . Also, $h(X,Y)$ denotes the second fundamental form tensor. Attempt: I know that $D_X Y = \nabla_X Y + h(X,Y)$ is the Gauss formula. On $\mathbb{R}^{n^2}$ , I have $$ D_Y X (O) = D_{Y(O)} X = Y(O) X. $$ To calculate the latter, we take a curve through $O$ with tangent vector $Y(O) = OB$ . Such a curve is $O \exp(Bt)$ . Then $$ Y(O) X = \frac{d}{dt}_{t = 0} X (O \exp (Bt)) = OBA. $$ How can I prove that $$ 2 h(X,Y) = D_X Y + D_Y X $$ ? This would give me that $$h(X,Y) (O) = \frac{1}{2} O (AB + BA). $$ Also, I'm not sure how to calculate $\nabla_Y X$ .","I'm given with the usual metric . Then is a submanifold of of dimension . I have shown that the tangent space consists of all skew-symmetric matrices with zero trace. I wish to show that the normal space consists of symmetric matrices. Furthermore, I need to calculate the second fundamental form tensor for . I'm given and left-invariant vector fields determined by skew-symmetric matrices at the identity. If is an arbitrary orthogonal matrix, then and . I need to prove that and to find expressions for , and . Here denotes the covariant derivative on , while denotes the covariant derivative on . Also, denotes the second fundamental form tensor. Attempt: I know that is the Gauss formula. On , I have To calculate the latter, we take a curve through with tangent vector . Such a curve is . Then How can I prove that ? This would give me that Also, I'm not sure how to calculate .","\mathbb{R}^{n^2} = \mathbb{R}^{n \times n} \langle A, B \rangle = \text{Trace} (AB^T) = \text{Trace} (A^T B) SO(n) \mathbb{R}^{n^2} \frac{1}{2} n (n-1) T_{I} SO(n) N_I SO(n) SO(n) X Y O X(O) = OA  Y(O) = OB D_Y X(O) = \frac{1}{2} O [B, A] + \frac{1}{2} O (BA + AB)  \nabla_Y X h(X,Y) [X, Y] \nabla_X Y SO(n) D_X Y \mathbb{R}^{n^2} h(X,Y) D_X Y = \nabla_X Y + h(X,Y) \mathbb{R}^{n^2}  D_Y X (O) = D_{Y(O)} X = Y(O) X.  O Y(O) = OB O \exp(Bt)  Y(O) X = \frac{d}{dt}_{t = 0} X (O \exp (Bt)) = OBA.   2 h(X,Y) = D_X Y + D_Y X  h(X,Y) (O) = \frac{1}{2} O (AB + BA).  \nabla_Y X","['differential-geometry', 'lie-groups', 'riemannian-geometry']"
54,"How to tell which manifolds can be embedded in $\mathbb{R}^n$, for a given $n$?","How to tell which manifolds can be embedded in , for a given ?",\mathbb{R}^n n,"Given $k \leq n$, is there a general method that can help us determine whether a given $k-$ dimensional smooth manifold $M$ (let's assume $M$ has empty boundary) can be embedded in $\mathbb{R}^n$? I know of some ways to know this in a couple of (very particular) cases: $1)$ If $k = n$ and $M$ is compact, it's never possible (we would have $f(M) = \mathbb{R}^n $, since the embedding must be open in this case). $2) $If $k = n-1$, then in order for this to be possible $M$ must be orientable ( see the answer by Georges Elencwajg to this question ). But of course these are very limited (for example, using them I can't even refute the statement 'every $k-$dimensional manifold embeds into $\mathbb{R}^{k+2}$'). Are there other techniques that can help in more general cases? I'd appreciate any partial answers. Thanks in advance. EDIT: I also know about Whitney's embedding theorem. The motivation for posting this question came from thinking about why a sharper bound can't be achieved.","Given $k \leq n$, is there a general method that can help us determine whether a given $k-$ dimensional smooth manifold $M$ (let's assume $M$ has empty boundary) can be embedded in $\mathbb{R}^n$? I know of some ways to know this in a couple of (very particular) cases: $1)$ If $k = n$ and $M$ is compact, it's never possible (we would have $f(M) = \mathbb{R}^n $, since the embedding must be open in this case). $2) $If $k = n-1$, then in order for this to be possible $M$ must be orientable ( see the answer by Georges Elencwajg to this question ). But of course these are very limited (for example, using them I can't even refute the statement 'every $k-$dimensional manifold embeds into $\mathbb{R}^{k+2}$'). Are there other techniques that can help in more general cases? I'd appreciate any partial answers. Thanks in advance. EDIT: I also know about Whitney's embedding theorem. The motivation for posting this question came from thinking about why a sharper bound can't be achieved.",,"['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
55,Details in a proof of coarea formula in $\mathbb{R}^n$.,Details in a proof of coarea formula in .,\mathbb{R}^n,"Let $\Omega\subseteq\mathbb{R}^n$ be an open set, and let $u:\bar{\Omega}\rightarrow\mathbb{R}$ be a function of class $C^1(\bar{\Omega})$. Given $\lambda\in\mathbb{R}$, let $\Gamma_\lambda=\{x\in\Omega:\,u(x)=\lambda\}$. Coarea formula: Suppose $|\nabla u|>0$ on $\bar{\Omega}$, and let $f\in L^1(\Omega)$. Then $$\int_\Omega f\,dx=\int_\mathbb{R}\int_{\Gamma_\lambda} \frac{f}{|\nabla u|}\,d\sigma\,d\lambda.$$ I present a proof that I think would work, and I want to ask about a (very important) step inside the proof. I know that coarea formula can be proved in a more general setting, but I am interested on solving this particular proof. For each $p\in\Omega$, there is $i\in\{1,\ldots,n\}$ with $|u_{x_i}(p)|>0$. By continuity, there exists $r_p>0$ such that for all $x\in B(p,r_p)\subseteq\Omega$ we have $|u_{x_i}(x)|>0$. As $\Omega$ is Lindelöf, $\Omega=\cup_{j=1}^{\infty} B_j$, where $B_j$ is some of such balls. Partition of the unity: there exists $\psi_j\in C_c^{\infty}(B_j)$ with $0\leq\psi_j\leq 1$ and $\sum_{j=1}^{\infty}\psi_j(x)=1$ for all $x\in\Omega$. Define $f_j=f\,\psi_j$ on $\Omega$. From now on, fix one of the balls $B=B_j$ and for simplicity of notation assume that $|u_{x_n}|>0$ on $B$. By the implicit function theorem, $\Gamma_\lambda\cap B=\{x\in B:\,u(x)=\lambda\}=\{(x',\varphi(x',\lambda)):\,x'\in\tilde{B}\}$, where $\tilde{B}$ open in $\mathbb{R}^{n-1}$ and $\varphi(\cdot,\lambda)\in C^1(\tilde{B})$. Question: can I assume that $\tilde{B}$ is chosen independently of $\lambda$? Do we have $\varphi(x',\cdot)\in C^1$? On the one hand, $$\int_\mathbb{R}\int_{\Gamma_\lambda}f_j\,d\sigma\,d\lambda=\int_\mathbb{R}\int_{\Gamma_\lambda\cap B}f_j\,d\sigma\,d\lambda=\int_\mathbb{R}\int_{\tilde{B}}f_j(x',\varphi(x',\lambda))\sqrt{1+|\nabla_{x'}\varphi(x',\lambda)|^2}\,dx'\,d\lambda.$$ On the other hand, if the question has a positive answer, \begin{equation} \begin{split} \int_\Omega f_j\,|\nabla u|\,dx &=\int_B f_j\,|\nabla u|\,dx \\ &\stackrel{\substack{\text{change}\\\text{variable}}}{=}\int_\mathbb{R}\int_{\tilde{B}}f_j(x',\varphi(x',\lambda))|\nabla u(x',\varphi(x',\lambda))|\,|\varphi_\lambda (x',\lambda)|\,dx'\,d\lambda. \end{split} \end{equation} Finally use $u(x',\varphi(x',\lambda))=\lambda$ for all $x'\in \tilde{B}$, and derivating with respect to $x'$ and $\lambda$ (if the question has a positive answer), one arrives at the equality between the last two big expressions. If the answer to the question were negative, are there any alternatives to make this proof work? I don't know, something like changing the balls by rectangles...","Let $\Omega\subseteq\mathbb{R}^n$ be an open set, and let $u:\bar{\Omega}\rightarrow\mathbb{R}$ be a function of class $C^1(\bar{\Omega})$. Given $\lambda\in\mathbb{R}$, let $\Gamma_\lambda=\{x\in\Omega:\,u(x)=\lambda\}$. Coarea formula: Suppose $|\nabla u|>0$ on $\bar{\Omega}$, and let $f\in L^1(\Omega)$. Then $$\int_\Omega f\,dx=\int_\mathbb{R}\int_{\Gamma_\lambda} \frac{f}{|\nabla u|}\,d\sigma\,d\lambda.$$ I present a proof that I think would work, and I want to ask about a (very important) step inside the proof. I know that coarea formula can be proved in a more general setting, but I am interested on solving this particular proof. For each $p\in\Omega$, there is $i\in\{1,\ldots,n\}$ with $|u_{x_i}(p)|>0$. By continuity, there exists $r_p>0$ such that for all $x\in B(p,r_p)\subseteq\Omega$ we have $|u_{x_i}(x)|>0$. As $\Omega$ is Lindelöf, $\Omega=\cup_{j=1}^{\infty} B_j$, where $B_j$ is some of such balls. Partition of the unity: there exists $\psi_j\in C_c^{\infty}(B_j)$ with $0\leq\psi_j\leq 1$ and $\sum_{j=1}^{\infty}\psi_j(x)=1$ for all $x\in\Omega$. Define $f_j=f\,\psi_j$ on $\Omega$. From now on, fix one of the balls $B=B_j$ and for simplicity of notation assume that $|u_{x_n}|>0$ on $B$. By the implicit function theorem, $\Gamma_\lambda\cap B=\{x\in B:\,u(x)=\lambda\}=\{(x',\varphi(x',\lambda)):\,x'\in\tilde{B}\}$, where $\tilde{B}$ open in $\mathbb{R}^{n-1}$ and $\varphi(\cdot,\lambda)\in C^1(\tilde{B})$. Question: can I assume that $\tilde{B}$ is chosen independently of $\lambda$? Do we have $\varphi(x',\cdot)\in C^1$? On the one hand, $$\int_\mathbb{R}\int_{\Gamma_\lambda}f_j\,d\sigma\,d\lambda=\int_\mathbb{R}\int_{\Gamma_\lambda\cap B}f_j\,d\sigma\,d\lambda=\int_\mathbb{R}\int_{\tilde{B}}f_j(x',\varphi(x',\lambda))\sqrt{1+|\nabla_{x'}\varphi(x',\lambda)|^2}\,dx'\,d\lambda.$$ On the other hand, if the question has a positive answer, \begin{equation} \begin{split} \int_\Omega f_j\,|\nabla u|\,dx &=\int_B f_j\,|\nabla u|\,dx \\ &\stackrel{\substack{\text{change}\\\text{variable}}}{=}\int_\mathbb{R}\int_{\tilde{B}}f_j(x',\varphi(x',\lambda))|\nabla u(x',\varphi(x',\lambda))|\,|\varphi_\lambda (x',\lambda)|\,dx'\,d\lambda. \end{split} \end{equation} Finally use $u(x',\varphi(x',\lambda))=\lambda$ for all $x'\in \tilde{B}$, and derivating with respect to $x'$ and $\lambda$ (if the question has a positive answer), one arrives at the equality between the last two big expressions. If the answer to the question were negative, are there any alternatives to make this proof work? I don't know, something like changing the balls by rectangles...",,"['differential-geometry', 'vector-analysis', 'geometric-measure-theory']"
56,Naturality of tensors in Differential Geometry,Naturality of tensors in Differential Geometry,,"I have always had a hard time understanding the big picture of tensors and tensor fields . I have no problem understanding why low type tensors and tensor fields such as \begin{align} \text{$scalars$ and $smooth$ $functions$ --- type $(0,0)$,}\\ \text{$vectors$ and $vector$ $fields$ --- type $(1,0)$,}\\ \text{$covectors$ and $differential$ $forms$ --- type $(0,1)$,}\\ \text{$linear$ $transformations$ and $vector$-$field$ $morphisms$ --- type $(1,1)$,}\\ \text{$inner$ $products$ and $Riemannian$ $metrics$ --- type $(0,2)$ } \end{align} are so useful and natural. As these objects all share a lot of algebraic structure I understand the reason to encapsulate them within the notion of tensor, in an algebraic context. But, from an Analysis-Geometry setting, they are way different objects, so I see no natural reason to join together all these objects and expect the resulting object (tensors) to be of so much use in Differential Geometry. Yet they are, and they are everywhere!! Q: Am I missing some reason of Analytic-Geometric character which motivates this generalization? If not, how does it turn out that an object whose generalization seem to be natural only algebraically end up playing such a central role in Differential Geometry? Maybe I am just underestimating the role that the algebraic structure play in this context?","I have always had a hard time understanding the big picture of tensors and tensor fields . I have no problem understanding why low type tensors and tensor fields such as \begin{align} \text{$scalars$ and $smooth$ $functions$ --- type $(0,0)$,}\\ \text{$vectors$ and $vector$ $fields$ --- type $(1,0)$,}\\ \text{$covectors$ and $differential$ $forms$ --- type $(0,1)$,}\\ \text{$linear$ $transformations$ and $vector$-$field$ $morphisms$ --- type $(1,1)$,}\\ \text{$inner$ $products$ and $Riemannian$ $metrics$ --- type $(0,2)$ } \end{align} are so useful and natural. As these objects all share a lot of algebraic structure I understand the reason to encapsulate them within the notion of tensor, in an algebraic context. But, from an Analysis-Geometry setting, they are way different objects, so I see no natural reason to join together all these objects and expect the resulting object (tensors) to be of so much use in Differential Geometry. Yet they are, and they are everywhere!! Q: Am I missing some reason of Analytic-Geometric character which motivates this generalization? If not, how does it turn out that an object whose generalization seem to be natural only algebraically end up playing such a central role in Differential Geometry? Maybe I am just underestimating the role that the algebraic structure play in this context?",,"['differential-geometry', 'soft-question']"
57,Does the Tangent Space Vary Continuously with The Points On a Manifold?,Does the Tangent Space Vary Continuously with The Points On a Manifold?,,"I recently read about Grassmannian manifolds. The following question naturally comes to mind. Let  $GR_k(\mathbf R^n)$ is the grassmannian manifold of $k$ dimensional linear subspaces of $\mathbf R^n$.   Let $M$ be a smooth $k$-manifold in $\mathbf R^n$.   Define a function $f:M\to M\times GR_k(\mathbf R^n)$ as    $$f(\mathbf p)=(\mathbf p,T_{\mathbf p}M)$$   for all $\mathbf p\in M$. Then is $f$ continuous? Is it also smooth? (All our tangent spaces pass through the origin. Usually the point at which we talk about the tangent space is also important. But since we are working in a Euclidean space, we can translate all of them to the origin). I have no idea how to go about proving or disproving the above. Does anybody know if the above is true? If not, then are there some extra conditions under which the above is true? Note: Think of a particle moving in $3$-space. We can ask if the particle is moving ``continuously"" in space. If $f:\mathbf R\to\mathbf R^3$ is a function such that at time $t$ the particle is at $f(t)$, then we say that the particle is moving continuously with time if the function $f$ is continuous. Similary, we ave an intuitive notion of an infinite rigid rod (basically a line) moving continuously in $2$ or $3$-space. To make this notion precise we can use the concept of the real projective space. Suppose at time $t$, the line be written as $L(t)$. We say that the line is moving continuously with time if the function $f:\mathbf R\to \mathbf RP^3$ defined as $f(t)=L(t)$ is continuous. The Grassmann manifolds generalize this notions to ``planes moving continuously (or smoothly)"" in Euclidean spaces.","I recently read about Grassmannian manifolds. The following question naturally comes to mind. Let  $GR_k(\mathbf R^n)$ is the grassmannian manifold of $k$ dimensional linear subspaces of $\mathbf R^n$.   Let $M$ be a smooth $k$-manifold in $\mathbf R^n$.   Define a function $f:M\to M\times GR_k(\mathbf R^n)$ as    $$f(\mathbf p)=(\mathbf p,T_{\mathbf p}M)$$   for all $\mathbf p\in M$. Then is $f$ continuous? Is it also smooth? (All our tangent spaces pass through the origin. Usually the point at which we talk about the tangent space is also important. But since we are working in a Euclidean space, we can translate all of them to the origin). I have no idea how to go about proving or disproving the above. Does anybody know if the above is true? If not, then are there some extra conditions under which the above is true? Note: Think of a particle moving in $3$-space. We can ask if the particle is moving ``continuously"" in space. If $f:\mathbf R\to\mathbf R^3$ is a function such that at time $t$ the particle is at $f(t)$, then we say that the particle is moving continuously with time if the function $f$ is continuous. Similary, we ave an intuitive notion of an infinite rigid rod (basically a line) moving continuously in $2$ or $3$-space. To make this notion precise we can use the concept of the real projective space. Suppose at time $t$, the line be written as $L(t)$. We say that the line is moving continuously with time if the function $f:\mathbf R\to \mathbf RP^3$ defined as $f(t)=L(t)$ is continuous. The Grassmann manifolds generalize this notions to ``planes moving continuously (or smoothly)"" in Euclidean spaces.",,"['differential-geometry', 'manifolds', 'grassmannian']"
58,Two definitions of smooth manifolds,Two definitions of smooth manifolds,,"In Milnor/Stasheff they give the definition of smooth manifold as follows (page 4): A subset $M \subset \mathbb R^A$ is a smooth manifold of dimension $n \ge 0$ if, for each $x \in M$ there exists a smooth function  $$ h: U \to \mathbb R^A$$ defined on an open set $U \subset \mathbb R^n$ such that 1) $h$ maps $U$ homeomorphically onto an open neighborhood $V$ of $x$ in $M$ and 2) for each $u \in U$ the matrix $[\partial h_\alpha (u) / \partial u_j]$ has rank $n$. This differs from the definition I know: $M$ is a smooth $n$-manifold if for any two charts $\varphi, \psi$ the transition map $\varphi \circ \psi^{-1}$ is smooth. Are these two definitions equivalent?","In Milnor/Stasheff they give the definition of smooth manifold as follows (page 4): A subset $M \subset \mathbb R^A$ is a smooth manifold of dimension $n \ge 0$ if, for each $x \in M$ there exists a smooth function  $$ h: U \to \mathbb R^A$$ defined on an open set $U \subset \mathbb R^n$ such that 1) $h$ maps $U$ homeomorphically onto an open neighborhood $V$ of $x$ in $M$ and 2) for each $u \in U$ the matrix $[\partial h_\alpha (u) / \partial u_j]$ has rank $n$. This differs from the definition I know: $M$ is a smooth $n$-manifold if for any two charts $\varphi, \psi$ the transition map $\varphi \circ \psi^{-1}$ is smooth. Are these two definitions equivalent?",,"['differential-geometry', 'manifolds', 'differential-topology']"
59,Chern class of tautological line bundle,Chern class of tautological line bundle,,"I'm studying characteristic classes from the Chern-Weil construction (via connection and curvature). I'm trying to compute some simple examples. Let $E$ be the tautological line bundle over projective space $P(\mathbf{C}^n)$. I want to show that the first Chern class of $E$ does not vanish. I suppose I could just introduce a connection on $E$ using local trivializations (is there a natural choice?), patch things together, compute the curvature and from this the first Chern class. However, that sounds a bit tedious. Are there more elegant ways to compute it?","I'm studying characteristic classes from the Chern-Weil construction (via connection and curvature). I'm trying to compute some simple examples. Let $E$ be the tautological line bundle over projective space $P(\mathbf{C}^n)$. I want to show that the first Chern class of $E$ does not vanish. I suppose I could just introduce a connection on $E$ using local trivializations (is there a natural choice?), patch things together, compute the curvature and from this the first Chern class. However, that sounds a bit tedious. Are there more elegant ways to compute it?",,"['differential-geometry', 'vector-bundles', 'characteristic-classes']"
60,Characterizing singularities using sheaves of smooth functions,Characterizing singularities using sheaves of smooth functions,,"Short version: Let $H\subset M$ be a closed subset of a smooth manifold. Equip $H$ with the sheaf $\mathcal{F}$ of smooth functions (so that a section over an open $U$ is the restriction to $U$ of a smooth function on some open of $M$). If $p\in H$ has a neighbourhood $U$ in $H$ such that $(U,\mathcal{F}_{\mid U})$ is isomorphic to a euclidean ball with its sheaf of smooth functions, then does $p$ have a neighbourhood $V\subset M$ such that $H\cap V$ is an embedded submanifold of $V$? The whole story I am studying a certain space $H$. This space can be identified with the inverse image of a singleton under a smooth map between smooth manifolds (by smooth, I mean $C^\infty$, although you may replace smooth by real analytic throughout the question if you wish). For the sake of notation, let us say that $f:M\to N$ is the smooth map between smooth manifolds, and that $H=f^{-1}(\{p\})$. Now $H$ need not be a submanifold of $M$ because $p$ could be a singular value of $f$ (and in my case, it typically is). I would therefore like to split $H$ into a smooth and a singular part, and then study the smooth part as a manifold. It seems to me there is a straightforward way to do this: take the smooth part to be all points of $H$ where $f$ is submersive, and call all other points singular. Then the smooth part is an open subset of $H$ and a submanifold of $M$. Nice. However, this approach has the disadvantage of using the map $f$ and not just the set $H$. Suppose for example that $$f:\mathbb{R}^2\to\mathbb{R}:(x,y)\mapsto x^2 ,$$ then $f^{-1}(\{0\})$ is a line, but all its points are considered singular. We could construct the same line as $g^{-1}(\{0\})$ for the map $g(x,y)=x$, and then all points are smooth. This shows why splitting $H$ using submersivity of $f$ may be a bad idea. My problem may thus be stated as: how can we distinguish between singular and smooth points of $H$ ? First proposal. One solution would be to call a point of $H$ smooth iff it has some neighbourhood $U$ in $M$ such that $H\cap U$ is a submanifold of $U$. This seems very close to geometrical intuition. I should make an important remark, however. Although $H$ was identified with a level set of $f$, there are many other maps $f':M'\to N'$ and points $p'\in N'$ such that $H$ can also be identified with the level set $(f')^{-1}(\{p'\})$. If the splitting of $H$ is to make sense, then I want the singularities of $H$ seen as a subset of $M$ to be the same as the singularities of $H$ seen as a subset of $M'$. I know that there are smooth maps $\alpha:M\to M'$ and $\beta:M'\to M$ both of which restrict to the ""identity"" on $H$. It is not clear to me that the first proposal will result in the same splitting if we use $f'$ instead of $f$. This leads me to my second proposal. Second proposal. For every open of $H$ we could look at all functions on it that are restrictions of smooth functions on some open of $M$. I believe this defines a sheaf on $H$, though I'm new to sheaves. We can then define a point to be smooth if it has some neighbourhood such that this neighbourhood equipped with the restriction of the sheaf is isomorphic to an open euclidean ball with its sheaf of smooth functions. This has the advantage that it does not depend on whether we use $f$ or $f'$ because $H$ will be equipped with the same sheaf in both cases (thanks to the maps $\alpha$ and $\beta$). It is also clear that points that are smooth according to the first proposal are also smooth according to the second. However, this proposal is not nearly as attractive to me as the first one in terms of geometrical intuition. Maybe some points that are labeled as smooth by this proposal are not supposed to be. This approach is also mentioned briefly in Thomas Klimpel's answer to Smooth structure on the topological space . What geometrical intuition can motivate the second proposal? In particular, is every point that is smooth according to the second proposal also smooth according to the first one?","Short version: Let $H\subset M$ be a closed subset of a smooth manifold. Equip $H$ with the sheaf $\mathcal{F}$ of smooth functions (so that a section over an open $U$ is the restriction to $U$ of a smooth function on some open of $M$). If $p\in H$ has a neighbourhood $U$ in $H$ such that $(U,\mathcal{F}_{\mid U})$ is isomorphic to a euclidean ball with its sheaf of smooth functions, then does $p$ have a neighbourhood $V\subset M$ such that $H\cap V$ is an embedded submanifold of $V$? The whole story I am studying a certain space $H$. This space can be identified with the inverse image of a singleton under a smooth map between smooth manifolds (by smooth, I mean $C^\infty$, although you may replace smooth by real analytic throughout the question if you wish). For the sake of notation, let us say that $f:M\to N$ is the smooth map between smooth manifolds, and that $H=f^{-1}(\{p\})$. Now $H$ need not be a submanifold of $M$ because $p$ could be a singular value of $f$ (and in my case, it typically is). I would therefore like to split $H$ into a smooth and a singular part, and then study the smooth part as a manifold. It seems to me there is a straightforward way to do this: take the smooth part to be all points of $H$ where $f$ is submersive, and call all other points singular. Then the smooth part is an open subset of $H$ and a submanifold of $M$. Nice. However, this approach has the disadvantage of using the map $f$ and not just the set $H$. Suppose for example that $$f:\mathbb{R}^2\to\mathbb{R}:(x,y)\mapsto x^2 ,$$ then $f^{-1}(\{0\})$ is a line, but all its points are considered singular. We could construct the same line as $g^{-1}(\{0\})$ for the map $g(x,y)=x$, and then all points are smooth. This shows why splitting $H$ using submersivity of $f$ may be a bad idea. My problem may thus be stated as: how can we distinguish between singular and smooth points of $H$ ? First proposal. One solution would be to call a point of $H$ smooth iff it has some neighbourhood $U$ in $M$ such that $H\cap U$ is a submanifold of $U$. This seems very close to geometrical intuition. I should make an important remark, however. Although $H$ was identified with a level set of $f$, there are many other maps $f':M'\to N'$ and points $p'\in N'$ such that $H$ can also be identified with the level set $(f')^{-1}(\{p'\})$. If the splitting of $H$ is to make sense, then I want the singularities of $H$ seen as a subset of $M$ to be the same as the singularities of $H$ seen as a subset of $M'$. I know that there are smooth maps $\alpha:M\to M'$ and $\beta:M'\to M$ both of which restrict to the ""identity"" on $H$. It is not clear to me that the first proposal will result in the same splitting if we use $f'$ instead of $f$. This leads me to my second proposal. Second proposal. For every open of $H$ we could look at all functions on it that are restrictions of smooth functions on some open of $M$. I believe this defines a sheaf on $H$, though I'm new to sheaves. We can then define a point to be smooth if it has some neighbourhood such that this neighbourhood equipped with the restriction of the sheaf is isomorphic to an open euclidean ball with its sheaf of smooth functions. This has the advantage that it does not depend on whether we use $f$ or $f'$ because $H$ will be equipped with the same sheaf in both cases (thanks to the maps $\alpha$ and $\beta$). It is also clear that points that are smooth according to the first proposal are also smooth according to the second. However, this proposal is not nearly as attractive to me as the first one in terms of geometrical intuition. Maybe some points that are labeled as smooth by this proposal are not supposed to be. This approach is also mentioned briefly in Thomas Klimpel's answer to Smooth structure on the topological space . What geometrical intuition can motivate the second proposal? In particular, is every point that is smooth according to the second proposal also smooth according to the first one?",,"['differential-geometry', 'sheaf-theory']"
61,Which coefficients of the characteristic polynomial of the shape operator are isometric invariants?,Which coefficients of the characteristic polynomial of the shape operator are isometric invariants?,,"Let $M^n \subset \mathbb{R}^{n+1}$ be an isometrically immersed Riemannian hypersurface.  The shape operator $s$ is the $(1,1)$ tensor field characterized by $$\langle X, sY \rangle = \langle \text{II}(X,Y), N\rangle,$$ where $X$, $Y$ are vector fields, $\text{II}$ is the second fundamental form, and $N$ is a unit normal vector field.  We can then define the mean curvature and Gaussian curvature by $$H = \frac{1}{n}\text{tr}(s), \ \ \ \ \ \ K = \det(s).$$ Gauss' Theorema Egregium is the statement that $K$ is an isometry invariant of $M$ when $\mathbf{n = 2}$ .  By contrast, $H$ is not.  This makes me wonder about the following: Question: Let $p(\lambda) = \lambda^n + a_{n-1}\lambda^{n-1} + \ldots + a_0$ denote the characteristic polynomial of the shape operator $s$.  For $n > 2$, are any of the coefficients $a_i$ (local) isometry invariants of $M$?  If so, which? Again, a previous question of mine was meant to get at this, but my thoughts were not quite so clear.","Let $M^n \subset \mathbb{R}^{n+1}$ be an isometrically immersed Riemannian hypersurface.  The shape operator $s$ is the $(1,1)$ tensor field characterized by $$\langle X, sY \rangle = \langle \text{II}(X,Y), N\rangle,$$ where $X$, $Y$ are vector fields, $\text{II}$ is the second fundamental form, and $N$ is a unit normal vector field.  We can then define the mean curvature and Gaussian curvature by $$H = \frac{1}{n}\text{tr}(s), \ \ \ \ \ \ K = \det(s).$$ Gauss' Theorema Egregium is the statement that $K$ is an isometry invariant of $M$ when $\mathbf{n = 2}$ .  By contrast, $H$ is not.  This makes me wonder about the following: Question: Let $p(\lambda) = \lambda^n + a_{n-1}\lambda^{n-1} + \ldots + a_0$ denote the characteristic polynomial of the shape operator $s$.  For $n > 2$, are any of the coefficients $a_i$ (local) isometry invariants of $M$?  If so, which? Again, a previous question of mine was meant to get at this, but my thoughts were not quite so clear.",,"['differential-geometry', 'riemannian-geometry']"
62,"How to generalize the Euclidean ""unicycle"" model?","How to generalize the Euclidean ""unicycle"" model?",,"There is a common system of ODEs known as the unicycle model / Dubin's model which describes the kinematics of an ant-like ""unicycle"" that can drive forward with some velocity $v(t) \in \mathbb{R}$ and turn in-place with some angular velocity $\omega(t) \in \mathbb{R}$ about the ground normal. The position of the unicycle / ant is described by $\big{(}x(t), y(t)\big{)} \in \mathbb{R}^2$ and its orientation is described by its ""heading"" angle $\ \theta(t) \in \mathcal{S}^1$ . \begin{align} \dot{x} &= v\cos(\theta)\\[2pt] \dot{y} &= v\sin(\theta)\\[2pt] \dot{\theta} &= \omega \end{align} These equations rely on the ant traversing a flat 2D plane. I have been thinking a lot about how to generalize this simple model to an arbitrarily curved (but smooth) 2D surface. We can imagine the infinity of geodesics that intersect $\big{(}x(t_0), y(t_0)\big{)}$ . Then $\theta(t_0)$ essentially picks one of those geodesics. While $v > 0$ and $\omega = 0$ , the ant moves what it thinks is ""straight forward."" It will follow the same geodesic until it chooses to turn ( $\omega \neq 0$ ) onto a different geodesic. Suppose our smooth surface is defined by an injective function that embeds it in 3D Euclidean space: $$ r : \mathbb{R}^2 \to \mathbb{R}^3\ ,\ \ \ r(x,y) = \begin{bmatrix} \bar{x}(x,y) \\ \bar{y}(x,y) \\ \bar{z}(x,y) \end{bmatrix} $$ We have its Jacobian and any necessary higher partial derivatives as well: $$ J(x,y) := \begin{bmatrix}\frac{\partial r}{\partial x}(x,y)\,\ \frac{\partial r}{\partial y}(x,y)\end{bmatrix} \in \mathbb{R}^{3 \times 2} $$ The velocity vector is, $$ \dot{r} = \dot{x}\frac{\partial r}{\partial x} + \dot{y}\frac{\partial r}{\partial y} = J \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix} $$ The scalar velocity $v$ in the flat model would correspond to the magnitude of the velocity vector in the general model, i.e. $v = ||\dot{r}||$ . Letting $\hat{\tau}$ be the direction of $\dot{r}$ we can write, $$ \dot{r} = v\hat{\tau} = J \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix} $$ Non-degeneracy of the surface-coordinates implies that $\frac{\partial r}{\partial x}$ is linearly independent of $\frac{\partial r}{\partial y}$ . Thus, $J$ is full-column-rank. Left-multiplying the above by $J^\intercal$ and inverting yields, $$ \begin{bmatrix} \dot{x} \\ \dot{y}\end{bmatrix} = v(J^\intercal J)^{-1}J^\intercal\hat{\tau} \tag{1} $$ It's noteworthy that $J^\intercal J$ is the metric tensor in coordinates. This is almost the ODE I'd need for $\big{(}x, y\big{)}$ , but $\hat{\tau}$ is undefined when evaluating the right-hand-side. I tried defining $\hat{\tau}$ in terms of some rotation $\theta$ of the surface gradients (with $\dot{\theta} = \omega$ ) and got cool but erroneous results: $$ \text{This ^ uses Eq.1 with:}\ \ \ \ \hat{\tau} = \cos(\theta)\frac{\frac{\partial r}{\partial x}}{\big{|}\big{|}\frac{\partial r}{\partial x}\big{|}\big{|}} + \sin(\theta)\frac{\frac{\partial r}{\partial y}}{\big{|}\big{|}\frac{\partial r}{\partial y}\big{|}\big{|}} ,\ \ \ \ \dot{\theta}=\omega$$ The error is that for $\omega = 0$ and $v \neq 0$ , holding $\hat{\tau}$ some fixed $\theta$ away from a gradient direction doesn't cause the ant to move along a geodesic. Moreover, it doesn't make sense for $\theta=0$ to yield a $\frac{\partial r}{\partial x}$ -follower... $\hat{\tau}$ really needs to be parallel-transported along the surface. Parallel-transport is a statement about how tangent vectors (e.g. $\dot{r}$ ) change , so we need to examine acceleration. If the ant never turned or varied speed, then its acceleration would be strictly normal to the surface (acceleration just due to curvature): \begin{gather} \langle \frac{\partial r}{\partial x}, \ddot{r} \rangle \ \ \overset{\dot{v}=\omega=0}{=}\ \ 0\\[3pt] \langle \frac{\partial r}{\partial y}, \ddot{r} \rangle \ \ \overset{\dot{v}=\omega=0}{=}\ \ 0 \end{gather} The left-hand-side can be expressed more compactly as $J^\intercal \ddot{r}$ . Expanding $\ddot{r}$ , \begin{align} \ddot{r} &= J \begin{bmatrix} \ddot{x} \\ \ddot{y} \end{bmatrix} + \dot{J} \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix}\\[4pt] J^\intercal \ddot{r} &= J^\intercal J \begin{bmatrix} \ddot{x} \\ \ddot{y} \end{bmatrix} + J^\intercal \dot{J} \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix} \ \ \overset{\dot{v}=\omega=0}{=}\ \ 0 \end{align} and finally left-multiplying by the inverse metric tensor $(J^\intercal J)^{-1}$ , $$ \begin{bmatrix} \ddot{x} \\ \ddot{y} \end{bmatrix} + (J^\intercal J)^{-1} J^\intercal \dot{J} \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix} \ \ \overset{\dot{v}=\omega=0}{=}\ \ 0 \tag{2} $$ This is the geodesic equation . The second term can be simplified with Christoffel symbols, but that isn't really necessary. $\dot{J} = \dot{x}\frac{\partial J}{\partial x} + \dot{y}\frac{\partial J}{\partial y}$ is just another computable function to me. I can use Equation 1 to convert some arbitrary initial $\hat{\tau}$ heading direction into an initial condition on $\big{(} \dot{x}, \dot{y} \big{)}$ and then integrate Equation 2 for the motion along the geodesic as long as $\dot{v} = \omega = 0$ . I suspect that to generalize this to the $\omega \neq 0$ and $\dot{v} \neq 0$ case, the right-hand-side will have to be some function of them rather than $0$ . But what function? Edit: And how do we encode ""heading"" so that the ant can ""stand still"" when $v = 0$ , and even turn ""in-place"" (about the normal)? What (if any) ODE system describes the ant / unicycle moving on an arbitrary smooth 2D surface? $$ \overset{?}{f}(x,y,\theta;v,\omega,r) = 0 $$ where $f$ can involve any derivatives up to second-order. Thanks in advance! :) Addendum The answer given by Kajelad below seems correct! Though for posterity I would like to add an elaboration of that answer here, using notation consistent with the above and providing more motivation / steps. First lets define the Frenet-Serret basis: $$ \hat{\tau} := \frac{\dot{r}}{||\dot{r}||},\ \ \ \ \hat{\eta} := \frac{\frac{\partial r}{\partial x} \times \frac{\partial r}{\partial y}}{\big{|}\big{|}\frac{\partial r}{\partial x} \times \frac{\partial r}{\partial y}\big{|}\big{|}},\ \ \ \ \hat{\beta} := \hat{\eta} \times \hat{\tau} $$ These are the standard tangent, normal, and binormal vectors respectively ( $\hat{\tau}$ being the same as I had previously defined) and they span $\mathbb{R}^3$ orthonormally at all points on the surface. Thus, the ambient acceleration vector can be expressed as some linear combination of them. $$ \ddot{r} = a\hat{\tau} + b\hat{\beta} + c\hat{\eta} $$ From the previous discussion, we know that if $\dot{v} = \omega = 0$ , then $\ddot{r} = c\hat{\eta}$ will yield geodesic motion. Therefore $a$ and $b$ must depend multiplicatively on $\dot{v}$ and $\omega$ . We also know that this must reduce to the traditional model in the Euclidean case. As we'll see, the correct relations are (rather intuitively), $$ a = \dot{v},\ \ \ \ b = \omega v $$ For clarity in the following algebra I'll define these shorthands, $$ q := \begin{bmatrix} x \\ y \end{bmatrix},\ \ \ \ \tilde{J} := (J^\intercal J)^{-1}J^\intercal $$ This makes our previous Eq.1 appear nicely as $\dot{q} = v\tilde{J}\hat{\tau}$ , and we also have $\ddot{r} = J\ddot{q} + \dot{J}\dot{q}$ . Thus, $$ J\ddot{q} = \dot{v}\hat{\tau} + \omega v \hat{\beta} + c\hat{\eta} - \dot{J}\dot{q} $$ Left-multiplying by $\tilde{J}$ not only cancels the leftmost $J$ , but also kills the $c\hat{\eta}$ term because $J^\intercal \hat{\eta}=0$ . $$ \ddot{q} = \dot{v}\tilde{J}\hat{\tau} + \omega v \tilde{J}\hat{\beta} - \tilde{J}\dot{J}\dot{q} \tag{3} $$ Next, lets define our generalization of ""heading"" as the unique vector $h(t) \in \mathbb{R}^2$ satisfying, \begin{align} \hat{\tau} &= Jh\\[4pt] h &= \tilde{J}\hat{\tau} = \tfrac{1}{v} \dot{q} \end{align} This vector exists because $\hat{\tau}$ lives in the tangent space (the span of $J$ ). Furthermore, $\hat{\beta}$ also lives in the tangent space as a $90^\circ$ rotation about the normal from $\hat{\tau}$ . Calling that transform $R^{\hat{\eta}}_{90^\circ} \in \mathbb{SO}3$ , we have, \begin{align} \hat{\beta} &= R^{\hat{\eta}}_{90^\circ} \hat{\tau}\\[4pt] \tilde{J} \hat{\beta} &= (J^\intercal J)^{-1} J^T R^{\hat{\eta}}_{90^\circ} J h \tag{$\hat{\tau} \to Jh$}\\[4pt] &= \sqrt{|J^\intercal J|}(J^\intercal J)^{-1}\begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix}h\\[4pt] &=: Rh \end{align} We can derive an ODE for $h$ by using the above relations to put Eq.3 in terms of $h$ . \begin{align} \ddot{q} &= \dot{v}h + \omega v Rh - v\tilde{J}\dot{J}h\ \ \tag{$\tilde{J}\hat{\tau} \to h,\ \tilde{J}\hat{\beta} \to Rh,\ \dot{q} \to v h$} \\[4pt] \dot{v}h + v\dot{h} &= \dot{v}h + \omega v Rh - v\tilde{J}\dot{J}h \tag{$\ddot{q} \to \dot{v}h + v\dot{h}$}\\[4pt] \dot{h} &= \omega Rh - \tilde{J}\dot{J}h \tag{cancellations} \end{align} The $\dot{J}$ is still hiding a $\dot{q}$ dependence, so lets expand it in terms of the Hessian $H := \frac{dJ}{dq}$ . $$ \dot{J} = \dot{x}\frac{\partial J}{\partial x} + \dot{y}\frac{\partial J}{\partial y} =: H \odot \dot{q} = v H \odot h $$ Finally, we arrive at, $$ \dot{h} = \omega Rh - v\tilde{J}(H \odot h)h $$ The rightmost-term can be simplified using Christoffel symbols, but that isn't critical as it is already something I can compute. This equation mirrors Kajelad's result: $$ \dot{T}^i = \omega R^i{}_j T^j-v\Gamma^i{}_{jk}T^jT^k $$ So in summary, the generalized model is: \begin{gather} \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix} = vh \tag{4}\\[4pt] \dot{h} = \omega Rh - v(J^\intercal J)^{-1}J^\intercal(H \odot h)h \tag{5}\\[4pt] R = \sqrt{|J^\intercal J|}(J^\intercal J)^{-1}\begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} \tag{6} \end{gather} where heading $h(t) \in \mathbb{R}^2$ , $J$ and $H$ are the embedded surface's Jacobian and Hessian respectively, and $v$ and $\omega$ are the specified ant/unicycle movements. This could be (more commonly) written in terms of the metric tensor ( $J^\intercal J$ ) and Christoffel symbols (gradients of the metric tensor). The appeal of that form is that it's completely independent of any embedding of our surface $r$ ; only the metric tensor field is needed. Note that the units are consistent ( $H$ has units of inverse-space). In the Euclidean case, the Hessian vanishes and the ODE reduces to the classic model. Lastly, if $\omega = 0$ , the $\dot{h}$ equation becomes a parallel-transport / geodesic equation. Now to test in simulation! ( Concluding remark: While very mechanical, the above derivation is a reflection of some rather fundamental and cool concepts in differential geometry, which Kajelad's answer used explicitly and may have gone beyond my background with. The key idea here, I think, is the Levi-Civita connection, or more specifically, the "" covariant-derivative ."" We took a covariant-derivative in the above when we took a regular derivative of $\dot{r}$ and then projected it onto the tangent space by left-multiplying $\tilde{J}$ . Instead, I could have used the abstract parlance and just defined $\nabla_{\dot{r}} \dot{r} = \ddot{r} - c\hat{\eta}$ . The ugliness in my derivation above is in how tied it is to coordinate representations of all the geometric quantities involved. To those unfamiliar with differential geometry, however, it is far more grounded, and can even serve as a gateway to the beautiful abstraction.)","There is a common system of ODEs known as the unicycle model / Dubin's model which describes the kinematics of an ant-like ""unicycle"" that can drive forward with some velocity and turn in-place with some angular velocity about the ground normal. The position of the unicycle / ant is described by and its orientation is described by its ""heading"" angle . These equations rely on the ant traversing a flat 2D plane. I have been thinking a lot about how to generalize this simple model to an arbitrarily curved (but smooth) 2D surface. We can imagine the infinity of geodesics that intersect . Then essentially picks one of those geodesics. While and , the ant moves what it thinks is ""straight forward."" It will follow the same geodesic until it chooses to turn ( ) onto a different geodesic. Suppose our smooth surface is defined by an injective function that embeds it in 3D Euclidean space: We have its Jacobian and any necessary higher partial derivatives as well: The velocity vector is, The scalar velocity in the flat model would correspond to the magnitude of the velocity vector in the general model, i.e. . Letting be the direction of we can write, Non-degeneracy of the surface-coordinates implies that is linearly independent of . Thus, is full-column-rank. Left-multiplying the above by and inverting yields, It's noteworthy that is the metric tensor in coordinates. This is almost the ODE I'd need for , but is undefined when evaluating the right-hand-side. I tried defining in terms of some rotation of the surface gradients (with ) and got cool but erroneous results: The error is that for and , holding some fixed away from a gradient direction doesn't cause the ant to move along a geodesic. Moreover, it doesn't make sense for to yield a -follower... really needs to be parallel-transported along the surface. Parallel-transport is a statement about how tangent vectors (e.g. ) change , so we need to examine acceleration. If the ant never turned or varied speed, then its acceleration would be strictly normal to the surface (acceleration just due to curvature): The left-hand-side can be expressed more compactly as . Expanding , and finally left-multiplying by the inverse metric tensor , This is the geodesic equation . The second term can be simplified with Christoffel symbols, but that isn't really necessary. is just another computable function to me. I can use Equation 1 to convert some arbitrary initial heading direction into an initial condition on and then integrate Equation 2 for the motion along the geodesic as long as . I suspect that to generalize this to the and case, the right-hand-side will have to be some function of them rather than . But what function? Edit: And how do we encode ""heading"" so that the ant can ""stand still"" when , and even turn ""in-place"" (about the normal)? What (if any) ODE system describes the ant / unicycle moving on an arbitrary smooth 2D surface? where can involve any derivatives up to second-order. Thanks in advance! :) Addendum The answer given by Kajelad below seems correct! Though for posterity I would like to add an elaboration of that answer here, using notation consistent with the above and providing more motivation / steps. First lets define the Frenet-Serret basis: These are the standard tangent, normal, and binormal vectors respectively ( being the same as I had previously defined) and they span orthonormally at all points on the surface. Thus, the ambient acceleration vector can be expressed as some linear combination of them. From the previous discussion, we know that if , then will yield geodesic motion. Therefore and must depend multiplicatively on and . We also know that this must reduce to the traditional model in the Euclidean case. As we'll see, the correct relations are (rather intuitively), For clarity in the following algebra I'll define these shorthands, This makes our previous Eq.1 appear nicely as , and we also have . Thus, Left-multiplying by not only cancels the leftmost , but also kills the term because . Next, lets define our generalization of ""heading"" as the unique vector satisfying, This vector exists because lives in the tangent space (the span of ). Furthermore, also lives in the tangent space as a rotation about the normal from . Calling that transform , we have, We can derive an ODE for by using the above relations to put Eq.3 in terms of . The is still hiding a dependence, so lets expand it in terms of the Hessian . Finally, we arrive at, The rightmost-term can be simplified using Christoffel symbols, but that isn't critical as it is already something I can compute. This equation mirrors Kajelad's result: So in summary, the generalized model is: where heading , and are the embedded surface's Jacobian and Hessian respectively, and and are the specified ant/unicycle movements. This could be (more commonly) written in terms of the metric tensor ( ) and Christoffel symbols (gradients of the metric tensor). The appeal of that form is that it's completely independent of any embedding of our surface ; only the metric tensor field is needed. Note that the units are consistent ( has units of inverse-space). In the Euclidean case, the Hessian vanishes and the ODE reduces to the classic model. Lastly, if , the equation becomes a parallel-transport / geodesic equation. Now to test in simulation! ( Concluding remark: While very mechanical, the above derivation is a reflection of some rather fundamental and cool concepts in differential geometry, which Kajelad's answer used explicitly and may have gone beyond my background with. The key idea here, I think, is the Levi-Civita connection, or more specifically, the "" covariant-derivative ."" We took a covariant-derivative in the above when we took a regular derivative of and then projected it onto the tangent space by left-multiplying . Instead, I could have used the abstract parlance and just defined . The ugliness in my derivation above is in how tied it is to coordinate representations of all the geometric quantities involved. To those unfamiliar with differential geometry, however, it is far more grounded, and can even serve as a gateway to the beautiful abstraction.)","v(t) \in \mathbb{R} \omega(t) \in \mathbb{R} \big{(}x(t), y(t)\big{)} \in \mathbb{R}^2 \ \theta(t) \in \mathcal{S}^1 \begin{align}
\dot{x} &= v\cos(\theta)\\[2pt]
\dot{y} &= v\sin(\theta)\\[2pt]
\dot{\theta} &= \omega
\end{align} \big{(}x(t_0), y(t_0)\big{)} \theta(t_0) v > 0 \omega = 0 \omega \neq 0 
r : \mathbb{R}^2 \to \mathbb{R}^3\ ,\ \ \ r(x,y) = \begin{bmatrix} \bar{x}(x,y) \\ \bar{y}(x,y) \\ \bar{z}(x,y) \end{bmatrix}
 
J(x,y) := \begin{bmatrix}\frac{\partial r}{\partial x}(x,y)\,\ \frac{\partial r}{\partial y}(x,y)\end{bmatrix} \in \mathbb{R}^{3 \times 2}
 
\dot{r} = \dot{x}\frac{\partial r}{\partial x} + \dot{y}\frac{\partial r}{\partial y} = J \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix}
 v v = ||\dot{r}|| \hat{\tau} \dot{r} 
\dot{r} = v\hat{\tau} = J \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix}
 \frac{\partial r}{\partial x} \frac{\partial r}{\partial y} J J^\intercal 
\begin{bmatrix} \dot{x} \\ \dot{y}\end{bmatrix} = v(J^\intercal J)^{-1}J^\intercal\hat{\tau} \tag{1}
 J^\intercal J \big{(}x, y\big{)} \hat{\tau} \hat{\tau} \theta \dot{\theta} = \omega 
\text{This ^ uses Eq.1 with:}\ \ \ \ \hat{\tau} = \cos(\theta)\frac{\frac{\partial r}{\partial x}}{\big{|}\big{|}\frac{\partial r}{\partial x}\big{|}\big{|}} + \sin(\theta)\frac{\frac{\partial r}{\partial y}}{\big{|}\big{|}\frac{\partial r}{\partial y}\big{|}\big{|}}
,\ \ \ \ \dot{\theta}=\omega \omega = 0 v \neq 0 \hat{\tau} \theta \theta=0 \frac{\partial r}{\partial x} \hat{\tau} \dot{r} \begin{gather}
\langle \frac{\partial r}{\partial x}, \ddot{r} \rangle \ \ \overset{\dot{v}=\omega=0}{=}\ \ 0\\[3pt]
\langle \frac{\partial r}{\partial y}, \ddot{r} \rangle \ \ \overset{\dot{v}=\omega=0}{=}\ \ 0
\end{gather} J^\intercal \ddot{r} \ddot{r} \begin{align}
\ddot{r} &= J \begin{bmatrix} \ddot{x} \\ \ddot{y} \end{bmatrix} + \dot{J} \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix}\\[4pt]
J^\intercal \ddot{r} &= J^\intercal J \begin{bmatrix} \ddot{x} \\ \ddot{y} \end{bmatrix} + J^\intercal \dot{J} \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix} \ \ \overset{\dot{v}=\omega=0}{=}\ \ 0
\end{align} (J^\intercal J)^{-1} 
\begin{bmatrix} \ddot{x} \\ \ddot{y} \end{bmatrix} + (J^\intercal J)^{-1} J^\intercal \dot{J} \begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix} \ \ \overset{\dot{v}=\omega=0}{=}\ \ 0 \tag{2}
 \dot{J} = \dot{x}\frac{\partial J}{\partial x} + \dot{y}\frac{\partial J}{\partial y} \hat{\tau} \big{(} \dot{x}, \dot{y} \big{)} \dot{v} = \omega = 0 \omega \neq 0 \dot{v} \neq 0 0 v = 0 
\overset{?}{f}(x,y,\theta;v,\omega,r) = 0
 f 
\hat{\tau} := \frac{\dot{r}}{||\dot{r}||},\ \ \ \ \hat{\eta} := \frac{\frac{\partial r}{\partial x} \times \frac{\partial r}{\partial y}}{\big{|}\big{|}\frac{\partial r}{\partial x} \times \frac{\partial r}{\partial y}\big{|}\big{|}},\ \ \ \ \hat{\beta} := \hat{\eta} \times \hat{\tau}
 \hat{\tau} \mathbb{R}^3 
\ddot{r} = a\hat{\tau} + b\hat{\beta} + c\hat{\eta}
 \dot{v} = \omega = 0 \ddot{r} = c\hat{\eta} a b \dot{v} \omega 
a = \dot{v},\ \ \ \ b = \omega v
 
q := \begin{bmatrix} x \\ y \end{bmatrix},\ \ \ \ \tilde{J} := (J^\intercal J)^{-1}J^\intercal
 \dot{q} = v\tilde{J}\hat{\tau} \ddot{r} = J\ddot{q} + \dot{J}\dot{q} 
J\ddot{q} = \dot{v}\hat{\tau} + \omega v \hat{\beta} + c\hat{\eta} - \dot{J}\dot{q}
 \tilde{J} J c\hat{\eta} J^\intercal \hat{\eta}=0 
\ddot{q} = \dot{v}\tilde{J}\hat{\tau} + \omega v \tilde{J}\hat{\beta} - \tilde{J}\dot{J}\dot{q} \tag{3}
 h(t) \in \mathbb{R}^2 \begin{align}
\hat{\tau} &= Jh\\[4pt]
h &= \tilde{J}\hat{\tau} = \tfrac{1}{v} \dot{q}
\end{align} \hat{\tau} J \hat{\beta} 90^\circ \hat{\tau} R^{\hat{\eta}}_{90^\circ} \in \mathbb{SO}3 \begin{align}
\hat{\beta} &= R^{\hat{\eta}}_{90^\circ} \hat{\tau}\\[4pt]
\tilde{J} \hat{\beta} &= (J^\intercal J)^{-1} J^T R^{\hat{\eta}}_{90^\circ} J h \tag{\hat{\tau} \to Jh}\\[4pt]
&= \sqrt{|J^\intercal J|}(J^\intercal J)^{-1}\begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix}h\\[4pt]
&=: Rh
\end{align} h h \begin{align}
\ddot{q} &= \dot{v}h + \omega v Rh - v\tilde{J}\dot{J}h\ \ \tag{\tilde{J}\hat{\tau} \to h,\ \tilde{J}\hat{\beta} \to Rh,\ \dot{q} \to v h} \\[4pt]
\dot{v}h + v\dot{h} &= \dot{v}h + \omega v Rh - v\tilde{J}\dot{J}h \tag{\ddot{q} \to \dot{v}h + v\dot{h}}\\[4pt]
\dot{h} &= \omega Rh - \tilde{J}\dot{J}h \tag{cancellations}
\end{align} \dot{J} \dot{q} H := \frac{dJ}{dq} 
\dot{J} = \dot{x}\frac{\partial J}{\partial x} + \dot{y}\frac{\partial J}{\partial y} =: H \odot \dot{q} = v H \odot h
 
\dot{h} = \omega Rh - v\tilde{J}(H \odot h)h
 
\dot{T}^i = \omega R^i{}_j T^j-v\Gamma^i{}_{jk}T^jT^k
 \begin{gather}
\begin{bmatrix} \dot{x} \\ \dot{y} \end{bmatrix} = vh \tag{4}\\[4pt]
\dot{h} = \omega Rh - v(J^\intercal J)^{-1}J^\intercal(H \odot h)h \tag{5}\\[4pt]
R = \sqrt{|J^\intercal J|}(J^\intercal J)^{-1}\begin{bmatrix} 0 & -1 \\ 1 & 0 \end{bmatrix} \tag{6}
\end{gather} h(t) \in \mathbb{R}^2 J H v \omega J^\intercal J r H \omega = 0 \dot{h} \dot{r} \tilde{J} \nabla_{\dot{r}} \dot{r} = \ddot{r} - c\hat{\eta}","['differential-geometry', 'mathematical-modeling', 'geodesic', 'kinematics']"
63,"Milnor's exercise: for any manifold $M$, $\mathrm{Hom}(C^\infty(M,\mathbb{R}),\mathbb{R})\cong M$","Milnor's exercise: for any manifold ,","M \mathrm{Hom}(C^\infty(M,\mathbb{R}),\mathbb{R})\cong M","I am studying some chapters of Kolar-Michor-Slovak, Natural Operations in Differential Geometry , in particular the one on Weil bundles, where they present the famous ""Milnor's exercise"". They give two similar proofs, one much shorter than the other, supposedly because of omitted details. I would like to understand it better. So we have to prove the: Theorem For any manifold $M$ , $\mathrm{Hom}(C^\infty(M,\mathbb{R}),\mathbb{R})\cong M$ Where $\mathrm{Hom}$ refers to morphisms of commutative unital algebras and $\cong$ to bijection of sets (I suppose). Now the short proof goes like this: Consider an homomorphism of algebras $C^\infty(M,\mathbb{R}\xrightarrow{\phi}\mathbb{R})$ , by the usual short exact sequence argument , $\ker(\phi)\leq C^\infty(M,\mathbb{R})$ is an ideal of codimension $1$ ( notice that such an homomorphism cannot be the zero map, since $\phi(1_\mathbb{R})=1\in\mathbb{R}$ ). Now, consider the following system of subsets of $M$ , where $V(f)=f^{-1}(0)$ : $$\{V(f)\mid (M\xrightarrow{f}\mathbb{R})\in \ker(\phi)\}$$ this is clearly a filter of closed sets of $M$ , since $V(f^2+g^2)=V(f)\cap V(g)$ . Find a function $M\xrightarrow{f^*}\mathbb{R}\in \ker(\phi)$ which is unbounded on each non-compact closed subset of $M$ ( for instance a positive proper function, such as the square of the geodesic distance w.r.t. any Riemannian metric ). Then $V(f^*)$ is a compact set contained in $\bigcap_{f\in \ker(\phi)} V(f)$ , which is then nonempty. Let $x_0$ be one of its elements. Then for any $f\in C^\infty(M,\mathbb{R})$ $f-\phi(f)1$ is in $\ker(\phi)$ so $(f-\phi(f)1)(x_0)=0$ , and $\phi(f)=f(x_0)$ . So $x_0$ completely determines $\phi$ and the map $\phi\mapsto x_0$ is the desired bijection. I have fetched the italicised details. What I am having trouble understanding is the bold passage. Moreover I don't see where we use the fact that the given system of sets is a filter and that $\ker(\phi)$ has codimension 1: I suspect these are relevant for the bold passage also. Any help would be much appreciated.","I am studying some chapters of Kolar-Michor-Slovak, Natural Operations in Differential Geometry , in particular the one on Weil bundles, where they present the famous ""Milnor's exercise"". They give two similar proofs, one much shorter than the other, supposedly because of omitted details. I would like to understand it better. So we have to prove the: Theorem For any manifold , Where refers to morphisms of commutative unital algebras and to bijection of sets (I suppose). Now the short proof goes like this: Consider an homomorphism of algebras , by the usual short exact sequence argument , is an ideal of codimension ( notice that such an homomorphism cannot be the zero map, since ). Now, consider the following system of subsets of , where : this is clearly a filter of closed sets of , since . Find a function which is unbounded on each non-compact closed subset of ( for instance a positive proper function, such as the square of the geodesic distance w.r.t. any Riemannian metric ). Then is a compact set contained in , which is then nonempty. Let be one of its elements. Then for any is in so , and . So completely determines and the map is the desired bijection. I have fetched the italicised details. What I am having trouble understanding is the bold passage. Moreover I don't see where we use the fact that the given system of sets is a filter and that has codimension 1: I suspect these are relevant for the bold passage also. Any help would be much appreciated.","M \mathrm{Hom}(C^\infty(M,\mathbb{R}),\mathbb{R})\cong M \mathrm{Hom} \cong C^\infty(M,\mathbb{R}\xrightarrow{\phi}\mathbb{R}) \ker(\phi)\leq C^\infty(M,\mathbb{R}) 1 \phi(1_\mathbb{R})=1\in\mathbb{R} M V(f)=f^{-1}(0) \{V(f)\mid (M\xrightarrow{f}\mathbb{R})\in \ker(\phi)\} M V(f^2+g^2)=V(f)\cap V(g) M\xrightarrow{f^*}\mathbb{R}\in \ker(\phi) M V(f^*) \bigcap_{f\in \ker(\phi)} V(f) x_0 f\in C^\infty(M,\mathbb{R}) f-\phi(f)1 \ker(\phi) (f-\phi(f)1)(x_0)=0 \phi(f)=f(x_0) x_0 \phi \phi\mapsto x_0 \ker(\phi)","['differential-geometry', 'commutative-algebra', 'proof-explanation', 'manifolds']"
64,A curve where all tangent lines are concurrent must be straight line,A curve where all tangent lines are concurrent must be straight line,,"I'm trying to solve this question in the classical Do Carmo's differential geometry book (page 23): A regular parametrized curve $\alpha$ has the property that all its tangent lines pass through a fixed point. Prove that the trace of $\alpha$ is a (segment of a) a straight line. My attempt Following the statement of the question, we have $\alpha(t)+\lambda(s)\alpha'(s)=const$. Taking the derivative of both sides we have $\alpha'(s)+\lambda'(s)\alpha'(s)+\lambda(s)\alpha''(s)=0$ which is equal to $(1+\lambda'(s))\alpha'(s)+\lambda(s)\alpha''(s)=0$. Since $\alpha'(s)$ and $\alpha''(s)$ are linearly independent, we have $\lambda'(s)=-1$ and $\lambda(s)=0$ for every $s$ which I found strange, since the derivative of the zero function is zero. I need a clarification at this point and a hand to finish my attempt of solution.","I'm trying to solve this question in the classical Do Carmo's differential geometry book (page 23): A regular parametrized curve $\alpha$ has the property that all its tangent lines pass through a fixed point. Prove that the trace of $\alpha$ is a (segment of a) a straight line. My attempt Following the statement of the question, we have $\alpha(t)+\lambda(s)\alpha'(s)=const$. Taking the derivative of both sides we have $\alpha'(s)+\lambda'(s)\alpha'(s)+\lambda(s)\alpha''(s)=0$ which is equal to $(1+\lambda'(s))\alpha'(s)+\lambda(s)\alpha''(s)=0$. Since $\alpha'(s)$ and $\alpha''(s)$ are linearly independent, we have $\lambda'(s)=-1$ and $\lambda(s)=0$ for every $s$ which I found strange, since the derivative of the zero function is zero. I need a clarification at this point and a hand to finish my attempt of solution.",,['differential-geometry']
65,"Computation in Wikipedia's article ""Riemann Curvature Tensor""","Computation in Wikipedia's article ""Riemann Curvature Tensor""",,"This Wikipedia article explains how the Riemann curvature tensor is a measure of the failure for a tangent vector to parallel translate back to itself along an infinitesimally small loop. The article gives $X,Y,Z\in\Gamma(TM)$ and lets $tX$ and $tY$ denote the integral curves of $X$ and $Y$ respectively. They let $$\tau_{tX}:T_pM\to T_pM \ \ \ \ \ \ \  \text{ and } \ \ \ \ \ \ \ \tau_{tY}:T_pM\to T_pM$$ denote the parallel transport maps along the respective integral curves. I am hoping someone can explain the computation giving this equality: $$\left.\frac{d}{ds}\frac{d}{dt}\right|_{t,s=0}\tau_{sX}^{-1}\tau_{tY}^{-1}\tau_{sX}\tau_{tY}Z=\left(\nabla_X\nabla_Y-\nabla_Y\nabla_X-\nabla_{[X,Y]}\right)Z.$$ I understand that if $P_\gamma$ denotes parallel transport along a curve $\gamma(t)$ then $$\nabla_{\gamma^\prime(t)}Z=\left.\frac{d}{dt}\right|_{t=0}P_{\gamma(t)}Z$$but there is some crazy chain rule stuff going on in the curvature expression that I can't seem to get right.","This Wikipedia article explains how the Riemann curvature tensor is a measure of the failure for a tangent vector to parallel translate back to itself along an infinitesimally small loop. The article gives $X,Y,Z\in\Gamma(TM)$ and lets $tX$ and $tY$ denote the integral curves of $X$ and $Y$ respectively. They let $$\tau_{tX}:T_pM\to T_pM \ \ \ \ \ \ \  \text{ and } \ \ \ \ \ \ \ \tau_{tY}:T_pM\to T_pM$$ denote the parallel transport maps along the respective integral curves. I am hoping someone can explain the computation giving this equality: $$\left.\frac{d}{ds}\frac{d}{dt}\right|_{t,s=0}\tau_{sX}^{-1}\tau_{tY}^{-1}\tau_{sX}\tau_{tY}Z=\left(\nabla_X\nabla_Y-\nabla_Y\nabla_X-\nabla_{[X,Y]}\right)Z.$$ I understand that if $P_\gamma$ denotes parallel transport along a curve $\gamma(t)$ then $$\nabla_{\gamma^\prime(t)}Z=\left.\frac{d}{dt}\right|_{t=0}P_{\gamma(t)}Z$$but there is some crazy chain rule stuff going on in the curvature expression that I can't seem to get right.",,"['differential-geometry', 'riemannian-geometry']"
66,$L^\infty$-bounds on eigenfunctions of Laplace-Beltrami opeator,-bounds on eigenfunctions of Laplace-Beltrami opeator,L^\infty,"Let $w_k$ be the eigenfunctions of the Laplace-Beltrami operator on a compact manifold $M$ without boundary. We assume that $\{w_k\}$ are orthonormal, thus $\|w_k \|_{L^2} = 1$. We know $w_k$ are smooth functions. Is such a bound true: $$\lVert w_k \rVert_{L^\infty(M)} \leq C$$ for all $k$? i.e. are all the eigenfunctions bounded above p/w a.e. by a single constant? Can we remove the a.e. part? In 1D domains the eigenfunctions are sine and cosine functions which are nice of course.","Let $w_k$ be the eigenfunctions of the Laplace-Beltrami operator on a compact manifold $M$ without boundary. We assume that $\{w_k\}$ are orthonormal, thus $\|w_k \|_{L^2} = 1$. We know $w_k$ are smooth functions. Is such a bound true: $$\lVert w_k \rVert_{L^\infty(M)} \leq C$$ for all $k$? i.e. are all the eigenfunctions bounded above p/w a.e. by a single constant? Can we remove the a.e. part? In 1D domains the eigenfunctions are sine and cosine functions which are nice of course.",,"['differential-geometry', 'eigenvalues-eigenvectors', 'manifolds', 'eigenfunctions']"
67,Vector fields on manifolds,Vector fields on manifolds,,"I have recently started a course on differential geometry (from a physicists perspective) and I am having trouble convincing myself why vector fields are represented as differential operators on manifolds? Is it because, in general, one cannot define a vector on a manifold as an arrow between two points on the manifold (as it generally will not be Euclidean) and as such the best we can do is consider the tangent space at each point on the manifold. Now, we could define vectors as the directional derivatives of the coordinate curves at that point, however this is very much coordinate dependent, which doesn't fit in with the notion of a vector. As such, if we consider tangent vector at a point as a differential operator that defines a tangent space at that point, then we satisfy the axioms of a vector space and thus achieve the notion of vectors on manifolds? Apologies for any inaccuracies and the wordiness of my attempt to answer my problem. I would really appreciate an intuitive explanation if possible. Thanks for your time.","I have recently started a course on differential geometry (from a physicists perspective) and I am having trouble convincing myself why vector fields are represented as differential operators on manifolds? Is it because, in general, one cannot define a vector on a manifold as an arrow between two points on the manifold (as it generally will not be Euclidean) and as such the best we can do is consider the tangent space at each point on the manifold. Now, we could define vectors as the directional derivatives of the coordinate curves at that point, however this is very much coordinate dependent, which doesn't fit in with the notion of a vector. As such, if we consider tangent vector at a point as a differential operator that defines a tangent space at that point, then we satisfy the axioms of a vector space and thus achieve the notion of vectors on manifolds? Apologies for any inaccuracies and the wordiness of my attempt to answer my problem. I would really appreciate an intuitive explanation if possible. Thanks for your time.",,"['differential-geometry', 'vector-analysis']"
68,How to check whether a vector field is Morse-Smale?,How to check whether a vector field is Morse-Smale?,,"Setup and notation: Let $f:M\to \mathbb{R}$ be a Morse-function on the compact $m$-dimensional manifold $M$ and let $X$ be a gradient-like vector field for the function $f$. Denote the unstable respectively stable manifold by $W^u_f(p)=\{x\in M\, |\, \lim_{t\to -\infty}\varphi^t(x)=p\}$ resp.  $W^s_f(p)=\{x\in M\, |\, \lim_{t\to \infty}\varphi^t(x)=p\}$ where $\varphi^t$ is the flow of the vector field $X$ and $p\in Crit(f)$ is some critical point of $f$. We have a free $\mathbb{R}$-action (at least if $p\neq q$) on the intersection $\mathcal{M}(p,q):=W^u_f(p)\cap W^s_f(q)$ by $s\cdot x = \varphi^s(x)$. I would like to check whether the vector field $X$ is Morse-Smale, i.e. whether $W^u_f(p)\pitchfork W^s_f(q)$ for all $p,q\in Crit(f)$. Question: Suppose $p\neq q$ and $\mathcal{M}(p,q)\neq \emptyset$ and that the intersection is transverse at $r\in \mathcal{M}(p,q)$ (i.e. if $T_rM=T_rW^u_f(p)+T_rW^s_f(q)$).   Does this imply that the intersection is transverse at $\varphi^s(r)$ for every $s\in \mathbb{R}$? In other words, to check whether $X$ is Morse-Smale, is it enough to check that the intersection is transverse for any single point on each flow line connecting $p$ and $q$? Relevant references are also much appreciated.","Setup and notation: Let $f:M\to \mathbb{R}$ be a Morse-function on the compact $m$-dimensional manifold $M$ and let $X$ be a gradient-like vector field for the function $f$. Denote the unstable respectively stable manifold by $W^u_f(p)=\{x\in M\, |\, \lim_{t\to -\infty}\varphi^t(x)=p\}$ resp.  $W^s_f(p)=\{x\in M\, |\, \lim_{t\to \infty}\varphi^t(x)=p\}$ where $\varphi^t$ is the flow of the vector field $X$ and $p\in Crit(f)$ is some critical point of $f$. We have a free $\mathbb{R}$-action (at least if $p\neq q$) on the intersection $\mathcal{M}(p,q):=W^u_f(p)\cap W^s_f(q)$ by $s\cdot x = \varphi^s(x)$. I would like to check whether the vector field $X$ is Morse-Smale, i.e. whether $W^u_f(p)\pitchfork W^s_f(q)$ for all $p,q\in Crit(f)$. Question: Suppose $p\neq q$ and $\mathcal{M}(p,q)\neq \emptyset$ and that the intersection is transverse at $r\in \mathcal{M}(p,q)$ (i.e. if $T_rM=T_rW^u_f(p)+T_rW^s_f(q)$).   Does this imply that the intersection is transverse at $\varphi^s(r)$ for every $s\in \mathbb{R}$? In other words, to check whether $X$ is Morse-Smale, is it enough to check that the intersection is transverse for any single point on each flow line connecting $p$ and $q$? Relevant references are also much appreciated.",,"['differential-geometry', 'differential-topology', 'morse-theory']"
69,Hodge Star Operator,Hodge Star Operator,,"I'm trying to understand the Hodge star operation, but have come across an impasse almost immediately. I have the definition $$(\star \omega)_{a_1\dots a_{n-p}}=\frac{1}{p!}\epsilon_{a_1\dots a_{n-1}b_1\dots b_p}\omega^{b_1\dots b_p}$$ where $\epsilon = \frac{1}{n!}\sqrt{|\det{g}|}\ dx^1\wedge\dots\wedge dx^n$ is the volume form on the manifold. I thought I'd try to find a formula for $\star (dx^{\mu_1}\wedge\dots dx^{\mu_p})$ as an exercise. But I can't seem to get it to come out to a nice answer. In particular I get lots of terms like $$g^{\mu_{\alpha} b_{\alpha}}$$ from lowering indices. No texts that I've read seem to involve these! Could someone possibly tell me the correct formula for the result, and give me some hints as to how to do the calculation efficiently? Many thanks!","I'm trying to understand the Hodge star operation, but have come across an impasse almost immediately. I have the definition $$(\star \omega)_{a_1\dots a_{n-p}}=\frac{1}{p!}\epsilon_{a_1\dots a_{n-1}b_1\dots b_p}\omega^{b_1\dots b_p}$$ where $\epsilon = \frac{1}{n!}\sqrt{|\det{g}|}\ dx^1\wedge\dots\wedge dx^n$ is the volume form on the manifold. I thought I'd try to find a formula for $\star (dx^{\mu_1}\wedge\dots dx^{\mu_p})$ as an exercise. But I can't seem to get it to come out to a nice answer. In particular I get lots of terms like $$g^{\mu_{\alpha} b_{\alpha}}$$ from lowering indices. No texts that I've read seem to involve these! Could someone possibly tell me the correct formula for the result, and give me some hints as to how to do the calculation efficiently? Many thanks!",,"['differential-geometry', 'differential-forms', 'mathematical-physics']"
70,Total mean curvature in $L^2$ and minimal surfaces in spaces with non-positive sectional curvature,Total mean curvature in  and minimal surfaces in spaces with non-positive sectional curvature,L^2,"Let's suppose we have a Riemannian $n$-manifold $(N,g)$ and an immersed surface $f:\Sigma\rightarrow N$, with genus zero, equipped with the induced metric.  Let's further assume that the ambient space has non-positive sectional curvature. If $f$ is minimal, i.e. $$ \vec{H} = 0 $$ where $\vec{H}$ is the mean curvature vector of $f$ (with respect to the induced metric $f^*g$), then $f$ is not closed.  (The only proof I know of this fact uses the maximum principle.  A geometric proof would be nice, if anybody has a reference.  Perhaps using Cartan-Hadamard?) Clearly then, for $f$ closed with genus zero, an inequality of the form $$ \int_\Sigma |\vec{H}|^2d\mu > c_g > 0 $$ should hold, for some $c_g$ depending only on $(N,g)$. My question is: what are the known values of $c_g$?","Let's suppose we have a Riemannian $n$-manifold $(N,g)$ and an immersed surface $f:\Sigma\rightarrow N$, with genus zero, equipped with the induced metric.  Let's further assume that the ambient space has non-positive sectional curvature. If $f$ is minimal, i.e. $$ \vec{H} = 0 $$ where $\vec{H}$ is the mean curvature vector of $f$ (with respect to the induced metric $f^*g$), then $f$ is not closed.  (The only proof I know of this fact uses the maximum principle.  A geometric proof would be nice, if anybody has a reference.  Perhaps using Cartan-Hadamard?) Clearly then, for $f$ closed with genus zero, an inequality of the form $$ \int_\Sigma |\vec{H}|^2d\mu > c_g > 0 $$ should hold, for some $c_g$ depending only on $(N,g)$. My question is: what are the known values of $c_g$?",,"['differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'curvature', 'minimal-surfaces']"
71,"Does projectivizing always fix problems at infinity? (Or, am I making a mistake somewhere?)","Does projectivizing always fix problems at infinity? (Or, am I making a mistake somewhere?)",,"This question is motivated by the following homework problem.  I'm trying to explicitly compute the homeomorphism $f:S^2 \rightarrow \mathbb{CP}^1$ by using stereographic projection and considering $\mathbb{CP}^1 = \mathbb{C}\cup {\infty}$.  I'll want to prove that this is an isometry, where $S^2$ has the standard angle metric and $\mathbb{CP}^1$ has the Fubini-Study metric given by $d(\overline{x},\overline{y})=2\cos^{-1}|(x,y)|$, where $x,y\in \mathbb{C}^2$ are unit vectors (and presumably $(-,-)$ is the usual Hermitian inner product).  Later, I'll use this to explicitly compute the Lie group homomorphism $U(2)\rightarrow SO(3)$. My stereographic projection is from the north pole, takes the equator to the unit circle, and puts the south pole at the origin.  What I've gotten so far is that for $z\not= 1$, \begin{equation*} f(x,y,z)=\left( \frac{x}{1-z} , \frac{y}{1-z} \right) = \frac{x+iy}{1-z} = [x+iy : 1-z ], \end{equation*} where these are coordinates in $\mathbb{R}^2$, $\mathbb{C}$, and $\mathbb{C}\subseteq \mathbb{CP}^1$ respectively.  This is troublesome, because philosophically I'd expect that I should be able to define this for $(x,y,z)\not= (0,0,1)$ and then end up with a function to projective space that extends continuously over the north pole; that's sort of the point of projective space, to make $\infty$ into just another point.  However, it is not immediately obvious that this works, although luckily \begin{equation*} \left| \frac{x+iy}{1-z} \right| = \sqrt{ \frac{|x+iy|^2}{(1-z)^2} } = \sqrt{ \frac{1-z^2}{(1-z)^2}}, \end{equation*} and the limit of this expression as $z\rightarrow 1^-$ is indeed $\infty$. So, fair enough.  This ends up extending to a continuous function after all.  But: Am I wrong in my philosophical understanding of projective space? (For what it's worth, I tried using my calculations to verify that $f$ is an isometry, and it didn't look like it was going to work out.  So maybe I really am just doing something wrong.)","This question is motivated by the following homework problem.  I'm trying to explicitly compute the homeomorphism $f:S^2 \rightarrow \mathbb{CP}^1$ by using stereographic projection and considering $\mathbb{CP}^1 = \mathbb{C}\cup {\infty}$.  I'll want to prove that this is an isometry, where $S^2$ has the standard angle metric and $\mathbb{CP}^1$ has the Fubini-Study metric given by $d(\overline{x},\overline{y})=2\cos^{-1}|(x,y)|$, where $x,y\in \mathbb{C}^2$ are unit vectors (and presumably $(-,-)$ is the usual Hermitian inner product).  Later, I'll use this to explicitly compute the Lie group homomorphism $U(2)\rightarrow SO(3)$. My stereographic projection is from the north pole, takes the equator to the unit circle, and puts the south pole at the origin.  What I've gotten so far is that for $z\not= 1$, \begin{equation*} f(x,y,z)=\left( \frac{x}{1-z} , \frac{y}{1-z} \right) = \frac{x+iy}{1-z} = [x+iy : 1-z ], \end{equation*} where these are coordinates in $\mathbb{R}^2$, $\mathbb{C}$, and $\mathbb{C}\subseteq \mathbb{CP}^1$ respectively.  This is troublesome, because philosophically I'd expect that I should be able to define this for $(x,y,z)\not= (0,0,1)$ and then end up with a function to projective space that extends continuously over the north pole; that's sort of the point of projective space, to make $\infty$ into just another point.  However, it is not immediately obvious that this works, although luckily \begin{equation*} \left| \frac{x+iy}{1-z} \right| = \sqrt{ \frac{|x+iy|^2}{(1-z)^2} } = \sqrt{ \frac{1-z^2}{(1-z)^2}}, \end{equation*} and the limit of this expression as $z\rightarrow 1^-$ is indeed $\infty$. So, fair enough.  This ends up extending to a continuous function after all.  But: Am I wrong in my philosophical understanding of projective space? (For what it's worth, I tried using my calculations to verify that $f$ is an isometry, and it didn't look like it was going to work out.  So maybe I really am just doing something wrong.)",,"['differential-geometry', 'lie-groups', 'projective-space']"
72,Dense subset of cut locus,Dense subset of cut locus,,"Given a complete Riemannian manifold $M$ and point $p\in M$ , denote $\mathrm{Cut}_p$ the cut locus of $p$ and $\mathrm{Cut}_p^1\subset \mathrm{Cut}_p$ the set of points $q$ which are connected to $p$ by more than one length minimising geodesic. According to a remark in Sakai's Riemannian geometry book (Rmk. 4.9), the latter forms a dense subset - but I don't understand why. Question: Why is $\mathrm{Cut}_p^1\subset \mathrm{Cut}_p$ dense? (I use density in this answer on MO. Comments on how to avoid this property to prove regularity of Riemannian distance function are also very welcome.)","Given a complete Riemannian manifold and point , denote the cut locus of and the set of points which are connected to by more than one length minimising geodesic. According to a remark in Sakai's Riemannian geometry book (Rmk. 4.9), the latter forms a dense subset - but I don't understand why. Question: Why is dense? (I use density in this answer on MO. Comments on how to avoid this property to prove regularity of Riemannian distance function are also very welcome.)",M p\in M \mathrm{Cut}_p p \mathrm{Cut}_p^1\subset \mathrm{Cut}_p q p \mathrm{Cut}_p^1\subset \mathrm{Cut}_p,"['differential-geometry', 'riemannian-geometry']"
73,An almost complex structure on $M$ is equivalent to a reduction of the structure group of the tangent bundle,An almost complex structure on  is equivalent to a reduction of the structure group of the tangent bundle,M,"Let $M$ be an $2n$ -dimensional manifold. Let $\mathcal{F}_{\mathrm{GL}(2n, \mathbb{R})}$ be the frame bundle over $M$ . Consider the subgroup $\mathrm{GL}(n, \mathbb{C})\subset\mathrm{GL}(2n, \mathbb{R})$ . What I'm trying to prove is: If $M$ has an almost complex structure $J:TM\rightarrow TM$ then there is a reduction of the structure group $\mathrm{GL}(2n, \mathbb{R})$ of $\mathcal{F}_{\mathrm{GL}(2n, \mathbb{R})}$ to $\mathrm{GL}(n, \mathbb{C})$ . The reciprocal is also true, and I was able to prove it. But I'm stuck on this direction. Does anyone have a suggestion?","Let be an -dimensional manifold. Let be the frame bundle over . Consider the subgroup . What I'm trying to prove is: If has an almost complex structure then there is a reduction of the structure group of to . The reciprocal is also true, and I was able to prove it. But I'm stuck on this direction. Does anyone have a suggestion?","M 2n \mathcal{F}_{\mathrm{GL}(2n, \mathbb{R})} M \mathrm{GL}(n, \mathbb{C})\subset\mathrm{GL}(2n, \mathbb{R}) M J:TM\rightarrow TM \mathrm{GL}(2n, \mathbb{R}) \mathcal{F}_{\mathrm{GL}(2n, \mathbb{R})} \mathrm{GL}(n, \mathbb{C})","['differential-geometry', 'principal-bundles', 'complex-manifolds', 'almost-complex']"
74,Ricci curvature of sum of metrics,Ricci curvature of sum of metrics,,"Is there an estimate for Ric$(g+h)$ in terms of Ric$(g)$ and Ric$(h)$, where $g,h$ are smooth Riemannian metrics? More specifically can one say that the eigenvalues will decrease (resp. increase) if we take h to be something of constant negative (resp. positive) Ricci? In the examples I have computed this seems to be the case but I am at a loss of how to prove something in general. If it is helpful I can take the metrics to be K\""ahler?","Is there an estimate for Ric$(g+h)$ in terms of Ric$(g)$ and Ric$(h)$, where $g,h$ are smooth Riemannian metrics? More specifically can one say that the eigenvalues will decrease (resp. increase) if we take h to be something of constant negative (resp. positive) Ricci? In the examples I have computed this seems to be the case but I am at a loss of how to prove something in general. If it is helpful I can take the metrics to be K\""ahler?",,"['differential-geometry', 'complex-geometry', 'kahler-manifolds']"
75,Computing curvature of hyperbolic space,Computing curvature of hyperbolic space,,"Consider the unit ball in $\mathbb R^2$ endowed with the Poincaré metric: $$ds^2=\frac{4(dx^2+dy^2)}{(1-x^2-y^2)^2}.$$ I want to compute the Gaussian curvature and find that it is $-1$. Given that the curvature is the same at every point (the space is homogeneous and isotropic), it suffices to compute the curvature at $0$. By definition, $$K=\frac{Rm(\partial_1, \partial_2, \partial_2, \partial_1)}{|\partial_1|^2 |\partial_2|^2}=\frac{Rm(\partial_1, \partial_2, \partial_2, \partial_1)}{16}$$ at the point $(0,0)$, as $\langle \partial_i, \partial_i\rangle = 4$ at $(0,0)$. Computing $R(\partial_1, \partial_2)\partial_2$ and taking the $\partial_1$ component, I get $$\partial_1 \Gamma_{22}^1 - \partial_2 \Gamma_{12}^1.$$ There are also a bunch of products of Christoffel symbols, but since the Christoffel symbols are sums of first derivatives of $f$, and all first derivatives of $f$ are $0$ at $(0,0)$, we can ignore these. I compute  $$\Gamma^1_{22}=\frac{-f_x}{2f}.$$ $$\Gamma^1_{12}=\frac{f_y}{2f}.$$ $$\partial_1 \Gamma^1_{22}=-\frac{2f f_{xx} - 2f_xf_x}{4f^2}.$$ $$\partial_1 \Gamma^1_{12}=\frac{2f f_{yy} - 2f_yf_y}{4f^2}.$$ Ignoring the first derivatives again and using symmetry, this leads us to consider $$-\frac{f_{xx}}{f}.$$ This is -4 at 0 (-16/4), and dividing by the factor of 16 noted above gives $-1/4$. We are off by a factor of $4$. Where have I gone wrong? edit: I note it really is a factor of $4$, not another computational error, because doing the calculations with $$ds^2=\frac{4R^4(dx^2+dy^2)}{(R^2-x^2-y^2)^2}$$ yields $-1/(4R^2)$, which is off by $1/4$ from the desired $-1/R^2$. Edit: Let me see if I can adapt @mauddib's answer to my own way of thinking. The error is that the above actually computes $R_{122}^1$/16. (I can't get the LaTeX right, but the raised index should be in the last place.) We must lower the index to get the desired tensor.  $$R_{1221}=g_{m1}R^1_{221} =g_{11}  \left(-\frac{f_{xx}}{f}\right) = -f_{xx}.$$ Now this is $-16$, so dividing by $16$ gets the right answer. Wonderful.","Consider the unit ball in $\mathbb R^2$ endowed with the Poincaré metric: $$ds^2=\frac{4(dx^2+dy^2)}{(1-x^2-y^2)^2}.$$ I want to compute the Gaussian curvature and find that it is $-1$. Given that the curvature is the same at every point (the space is homogeneous and isotropic), it suffices to compute the curvature at $0$. By definition, $$K=\frac{Rm(\partial_1, \partial_2, \partial_2, \partial_1)}{|\partial_1|^2 |\partial_2|^2}=\frac{Rm(\partial_1, \partial_2, \partial_2, \partial_1)}{16}$$ at the point $(0,0)$, as $\langle \partial_i, \partial_i\rangle = 4$ at $(0,0)$. Computing $R(\partial_1, \partial_2)\partial_2$ and taking the $\partial_1$ component, I get $$\partial_1 \Gamma_{22}^1 - \partial_2 \Gamma_{12}^1.$$ There are also a bunch of products of Christoffel symbols, but since the Christoffel symbols are sums of first derivatives of $f$, and all first derivatives of $f$ are $0$ at $(0,0)$, we can ignore these. I compute  $$\Gamma^1_{22}=\frac{-f_x}{2f}.$$ $$\Gamma^1_{12}=\frac{f_y}{2f}.$$ $$\partial_1 \Gamma^1_{22}=-\frac{2f f_{xx} - 2f_xf_x}{4f^2}.$$ $$\partial_1 \Gamma^1_{12}=\frac{2f f_{yy} - 2f_yf_y}{4f^2}.$$ Ignoring the first derivatives again and using symmetry, this leads us to consider $$-\frac{f_{xx}}{f}.$$ This is -4 at 0 (-16/4), and dividing by the factor of 16 noted above gives $-1/4$. We are off by a factor of $4$. Where have I gone wrong? edit: I note it really is a factor of $4$, not another computational error, because doing the calculations with $$ds^2=\frac{4R^4(dx^2+dy^2)}{(R^2-x^2-y^2)^2}$$ yields $-1/(4R^2)$, which is off by $1/4$ from the desired $-1/R^2$. Edit: Let me see if I can adapt @mauddib's answer to my own way of thinking. The error is that the above actually computes $R_{122}^1$/16. (I can't get the LaTeX right, but the raised index should be in the last place.) We must lower the index to get the desired tensor.  $$R_{1221}=g_{m1}R^1_{221} =g_{11}  \left(-\frac{f_{xx}}{f}\right) = -f_{xx}.$$ Now this is $-16$, so dividing by $16$ gets the right answer. Wonderful.",,"['differential-geometry', 'riemannian-geometry']"
76,Proving that the quotient manifold is orientable if and only if the group action is orientation-preserving,Proving that the quotient manifold is orientable if and only if the group action is orientation-preserving,,"I'm trying to solve the following exercise in Lee's book. Suppose M is a connected, oriented smooth manifold and Γ is a discrete group acting freely and properly on M. We say the action is orientation-preserving if for each γ ∈ Γ, the diﬀeomorphism $x\rightarrow γx$ is orientation-preserving. Show that M/Γ is orientable if and only if Γ is orientation-preserving. Assuming $\Gamma $ to be orientation-preserving, I tried taking a commutative diagram taking an orientation of M to one of M$/\Gamma$ and vice-versa and tried using local diffeomorphism arguments to prove the orientability of M$/\Gamma$. However, I can't make this proof explicit. Nor can I proceed for the other direction. Can someone please provide a proof for both if and only if parts? Thanks in advance.","I'm trying to solve the following exercise in Lee's book. Suppose M is a connected, oriented smooth manifold and Γ is a discrete group acting freely and properly on M. We say the action is orientation-preserving if for each γ ∈ Γ, the diﬀeomorphism $x\rightarrow γx$ is orientation-preserving. Show that M/Γ is orientable if and only if Γ is orientation-preserving. Assuming $\Gamma $ to be orientation-preserving, I tried taking a commutative diagram taking an orientation of M to one of M$/\Gamma$ and vice-versa and tried using local diffeomorphism arguments to prove the orientability of M$/\Gamma$. However, I can't make this proof explicit. Nor can I proceed for the other direction. Can someone please provide a proof for both if and only if parts? Thanks in advance.",,"['differential-geometry', 'orientation']"
77,Infinite dimensional constant rank theorem,Infinite dimensional constant rank theorem,,"Suppose you have an analytic map $\phi : E \rightarrow \mathbb{C}^n$, where $E$ is a complex Banach space, and such that the rank of $D \phi$ is constant. Is it true then that the set $\phi^{-1}(\{0\})$ is a Banach submanifold of $E$ (with finite codimension, and tangent space equal to $\ker D \phi$ ?) I guess the question amounts to using an infinite version of the constant rank theorem, but I couldn't find a reference for it. Thank you very much in advance !","Suppose you have an analytic map $\phi : E \rightarrow \mathbb{C}^n$, where $E$ is a complex Banach space, and such that the rank of $D \phi$ is constant. Is it true then that the set $\phi^{-1}(\{0\})$ is a Banach submanifold of $E$ (with finite codimension, and tangent space equal to $\ker D \phi$ ?) I guess the question amounts to using an infinite version of the constant rank theorem, but I couldn't find a reference for it. Thank you very much in advance !",,"['reference-request', 'differential-geometry', 'banach-spaces', 'manifolds']"
78,Lie Group Multiplication in Coordinates,Lie Group Multiplication in Coordinates,,"I'm having a bit of trouble with the last bit of Problem 3.2 in Kirillov Jr.'s Introduction to Lie Groups and Lie Algebras . (3.2) Let $f: \mathfrak{g} \rightarrow G$ be any smooth map such that $f(0)=1_G$ and $f_*(0) = \text{id}_{\mathfrak{g}}.$  Show that the group law in this coordinate system near the identity has the form $f(x) f(y) = f(x+y+B_f(x,y)+ \cdots )$ for some bilinear map $B: \mathfrak{g} \otimes \mathfrak{g} \rightarrow \mathfrak{g}$ and that $B_f(x,y)-B_f(y,x)= [x,y]$. The inverse function theorem lets us write $f(x)\cdot f(y) = f(\mu_f(x,y))$ for some smooth map $\mu_f: \tilde{U} \rightarrow \mathfrak{g}$ defined on some open set $\tilde{U} \subset \mathfrak{g} \times \mathfrak{g}$.  Restricting to $x=0$ then $y=0$ in the Taylor expansion of $\mu_f$ around $0 \times 0$ reveals that $\mu_f(x,y) = x+y+ B_f(x,y) + \cdots$ for some bilinear map $B_f : \mathfrak{g} \otimes \mathfrak{g} \rightarrow \mathfrak{g}$ which is defined everywhere even though $\mu_f$ might not be since we can rescale.  We know that in the case where $f= \text{exp}: \mathfrak{g} \rightarrow G$ we have $B_{\text{exp}} (x,y)= \frac{1}{2} [x,y]$, which means it's enough to show that for any other $\tilde{f}$ satisfying the conditions of the problem statement we have $$B_f(x,y)-B_f(y,x)=B_{\tilde{f}}(x,y)-B_{\tilde{f}}(y,x)$$ for all $x,y \in \mathfrak{g}$.  This is all I've got so far - I can't seem to find the right view to take in order to finish the problem. Note that unlike the exponential map, in general we don't expect there to be a relationship between $f(x)$ and $f( \lambda x)$ for $\lambda \in \mathbb{R}$ since all we know is that $f$ is smooth. Any help would be greatly appreciated!","I'm having a bit of trouble with the last bit of Problem 3.2 in Kirillov Jr.'s Introduction to Lie Groups and Lie Algebras . (3.2) Let $f: \mathfrak{g} \rightarrow G$ be any smooth map such that $f(0)=1_G$ and $f_*(0) = \text{id}_{\mathfrak{g}}.$  Show that the group law in this coordinate system near the identity has the form $f(x) f(y) = f(x+y+B_f(x,y)+ \cdots )$ for some bilinear map $B: \mathfrak{g} \otimes \mathfrak{g} \rightarrow \mathfrak{g}$ and that $B_f(x,y)-B_f(y,x)= [x,y]$. The inverse function theorem lets us write $f(x)\cdot f(y) = f(\mu_f(x,y))$ for some smooth map $\mu_f: \tilde{U} \rightarrow \mathfrak{g}$ defined on some open set $\tilde{U} \subset \mathfrak{g} \times \mathfrak{g}$.  Restricting to $x=0$ then $y=0$ in the Taylor expansion of $\mu_f$ around $0 \times 0$ reveals that $\mu_f(x,y) = x+y+ B_f(x,y) + \cdots$ for some bilinear map $B_f : \mathfrak{g} \otimes \mathfrak{g} \rightarrow \mathfrak{g}$ which is defined everywhere even though $\mu_f$ might not be since we can rescale.  We know that in the case where $f= \text{exp}: \mathfrak{g} \rightarrow G$ we have $B_{\text{exp}} (x,y)= \frac{1}{2} [x,y]$, which means it's enough to show that for any other $\tilde{f}$ satisfying the conditions of the problem statement we have $$B_f(x,y)-B_f(y,x)=B_{\tilde{f}}(x,y)-B_{\tilde{f}}(y,x)$$ for all $x,y \in \mathfrak{g}$.  This is all I've got so far - I can't seem to find the right view to take in order to finish the problem. Note that unlike the exponential map, in general we don't expect there to be a relationship between $f(x)$ and $f( \lambda x)$ for $\lambda \in \mathbb{R}$ since all we know is that $f$ is smooth. Any help would be greatly appreciated!",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
79,Why do we always need the Schwarz lemma when bounding the trace of a Kähler metric?,Why do we always need the Schwarz lemma when bounding the trace of a Kähler metric?,,"My undergraduate thesis topic is Kähler geometry. The general direction is something like the Calabi-Yau theorem or more adventurously some singular Calabi-Yau theorem, but this is not certain yet. One thing that I am noticing a lot of in my reading of Kähler geometry is that if we have two Kähler metrics $\omega$ , $\eta$ , then to get a bound of the form $$\text{tr}_{\omega}(\eta) \leq C$$ we need to use the Schwarz lemma -- Essentially, we apply the maximum principle to some term like $$\log \text{tr}_{\omega}(\eta) - A \varphi,$$ where $\omega = \eta + dd^c \varphi$ and $A>0$ is large. This requires an assumption on the (Ricci/bisectional/holomorphic sectional) curvatures of $\omega$ , $\eta$ (depending on which Laplacian one computes with). I feel that I understand how to use the Schwarz lemma to get these estimates, but I want to ask why we have to use it (if we have to?). This is prompted by studying singular metrics, for examples cone and cusp metrics: To formulate my question, let $D$ be a divisor in a compact Kähler manifold $M$ , and for simplicity, assume that $D$ has simple normal crossings. A cone Kähler metric is a Kähler metric which is smooth on $M - D$ and is quasi-isometric to $$\frac{i}{2} \sum_{j=1}^k | z_j |^{2(1-\beta_j)} dz_j \wedge d\overline{z}_j + \frac{i}{2} \sum_{j \geq k+1} dz_j \wedge d\overline{z}_j.$$ A cusp Kähler metric is a smooth Kähler metric on $M-D$ which is quasi-isometric to $$\frac{i}{2} \sum_{j=1}^k | z_j |^{-2}| \log | z_i |^2 |^2 dz_j \wedge d\overline{z}_j + \frac{i}{2} \sum_{j \geq k+1} dz_j \wedge d\overline{z}_j.$$ From these descriptions, can one not see immediately that if $\omega$ is cusp and $\eta$ is cone, then $$\text{tr}_{\omega}(\eta) \leq C | z_i|^2 | \log | z_i |^2|^2,$$ which would give $$\text{tr}_{\omega}(\eta) \leq C \prod_j | \sigma_j |^2 | \log | \sigma_j |^2 |^2,$$ if $\sigma_j$ are the defining sections for the divisor $D$ ? What initially came to my mind is a coordinate dependence problem, but this seems to contradict the fact that many calculations of this type involve normal coordinate calculations. Sorry if this question is silly.","My undergraduate thesis topic is Kähler geometry. The general direction is something like the Calabi-Yau theorem or more adventurously some singular Calabi-Yau theorem, but this is not certain yet. One thing that I am noticing a lot of in my reading of Kähler geometry is that if we have two Kähler metrics , , then to get a bound of the form we need to use the Schwarz lemma -- Essentially, we apply the maximum principle to some term like where and is large. This requires an assumption on the (Ricci/bisectional/holomorphic sectional) curvatures of , (depending on which Laplacian one computes with). I feel that I understand how to use the Schwarz lemma to get these estimates, but I want to ask why we have to use it (if we have to?). This is prompted by studying singular metrics, for examples cone and cusp metrics: To formulate my question, let be a divisor in a compact Kähler manifold , and for simplicity, assume that has simple normal crossings. A cone Kähler metric is a Kähler metric which is smooth on and is quasi-isometric to A cusp Kähler metric is a smooth Kähler metric on which is quasi-isometric to From these descriptions, can one not see immediately that if is cusp and is cone, then which would give if are the defining sections for the divisor ? What initially came to my mind is a coordinate dependence problem, but this seems to contradict the fact that many calculations of this type involve normal coordinate calculations. Sorry if this question is silly.","\omega \eta \text{tr}_{\omega}(\eta) \leq C \log \text{tr}_{\omega}(\eta) - A \varphi, \omega = \eta + dd^c \varphi A>0 \omega \eta D M D M - D \frac{i}{2} \sum_{j=1}^k | z_j |^{2(1-\beta_j)} dz_j \wedge d\overline{z}_j + \frac{i}{2} \sum_{j \geq k+1} dz_j \wedge d\overline{z}_j. M-D \frac{i}{2} \sum_{j=1}^k | z_j |^{-2}| \log | z_i |^2 |^2 dz_j \wedge d\overline{z}_j + \frac{i}{2} \sum_{j \geq k+1} dz_j \wedge d\overline{z}_j. \omega \eta \text{tr}_{\omega}(\eta) \leq C | z_i|^2 | \log | z_i |^2|^2, \text{tr}_{\omega}(\eta) \leq C \prod_j | \sigma_j |^2 | \log | \sigma_j |^2 |^2, \sigma_j D","['differential-geometry', 'algebraic-geometry']"
80,Lie group structure of the tangent bundle,Lie group structure of the tangent bundle,,"Suppose we have a (finite dimensional) Lie group $G$ with Lie algebra $\mathfrak g$. I am interested in the properties of the tangent bundle $$TG = \bigsqcup\limits_{g \in G} T_gG \cong \mathfrak g\times G.$$ Specifically, I want to equip $TG$ with a product making it a Lie group. Of course, one could just define the product component wise, as $\mathfrak g$ is a vector space and thus an additive Lie group. But to me this seems unnatural, as it ignores the possible non-commutativity of $G$. From The Tangent bundle of a lie group is isomorphic to a semidirect product. we obtain a more natural group structure on the tangent bundle, induced by the semi-direct outer product: $\mathfrak g \rtimes_{\operatorname{Ad}} G$. Now for my questions: Suppose $G$ is a Matrix Lie group. Is there an easy / obvious way to represent $\mathfrak g \rtimes_{\operatorname{Ad}} G$ as a Matrix Lie group? This is easily achieved in the special euclidean group $\mathbb{SE}(3) \cong \mathbb R^ 3 \rtimes \mathbb{SO}(3)$, which seems to be similar to the abstract question. What is the Lie algebra of $TG$? An obvious choice would be $\mathfrak g \rtimes_{\operatorname{ad}} \mathfrak g$, but does this induce the correct Lie bracket? It seems to me, that depending on $G$, $\operatorname{ad}(g)(\cdot)$ may not be a automorphism of $\mathfrak g$. Then $\mathfrak g \rtimes_{\operatorname{ad}} \mathfrak g$ would not be well defined. Is there a nice representation of $\exp_{TG}$ in the given setting?","Suppose we have a (finite dimensional) Lie group $G$ with Lie algebra $\mathfrak g$. I am interested in the properties of the tangent bundle $$TG = \bigsqcup\limits_{g \in G} T_gG \cong \mathfrak g\times G.$$ Specifically, I want to equip $TG$ with a product making it a Lie group. Of course, one could just define the product component wise, as $\mathfrak g$ is a vector space and thus an additive Lie group. But to me this seems unnatural, as it ignores the possible non-commutativity of $G$. From The Tangent bundle of a lie group is isomorphic to a semidirect product. we obtain a more natural group structure on the tangent bundle, induced by the semi-direct outer product: $\mathfrak g \rtimes_{\operatorname{Ad}} G$. Now for my questions: Suppose $G$ is a Matrix Lie group. Is there an easy / obvious way to represent $\mathfrak g \rtimes_{\operatorname{Ad}} G$ as a Matrix Lie group? This is easily achieved in the special euclidean group $\mathbb{SE}(3) \cong \mathbb R^ 3 \rtimes \mathbb{SO}(3)$, which seems to be similar to the abstract question. What is the Lie algebra of $TG$? An obvious choice would be $\mathfrak g \rtimes_{\operatorname{ad}} \mathfrak g$, but does this induce the correct Lie bracket? It seems to me, that depending on $G$, $\operatorname{ad}(g)(\cdot)$ may not be a automorphism of $\mathfrak g$. Then $\mathfrak g \rtimes_{\operatorname{ad}} \mathfrak g$ would not be well defined. Is there a nice representation of $\exp_{TG}$ in the given setting?",,"['differential-geometry', 'lie-groups', 'lie-algebras']"
81,Good video lectures in Differential Geometry,Good video lectures in Differential Geometry,,"I was not fortunate enough to learn Differential Geometry during my Masters. As now I am having my thesis in PDEs, and I miss a lot of mathematics from the people who do PDEs on Manifold setting. I badly want to learn Differential geometry, especially from the point of view of PDEs. Do anyone know good video lectures on the subject? PLEASE let me know. Thanks","I was not fortunate enough to learn Differential Geometry during my Masters. As now I am having my thesis in PDEs, and I miss a lot of mathematics from the people who do PDEs on Manifold setting. I badly want to learn Differential geometry, especially from the point of view of PDEs. Do anyone know good video lectures on the subject? PLEASE let me know. Thanks",,"['differential-geometry', 'reference-request']"
82,constant-curvature Riemannian metric for Bring's surface,constant-curvature Riemannian metric for Bring's surface,,"There is a well-known and very symmetric space that is called either ""Bring's curve"" or ""Bring's surface"", depending upon the context.  (Bring was a Swedish mathematician in the 18th century.)   Let's here call it simply $B$ .  In brief, I am looking for an explicit formula for a constant-curvature Riemannian metric on $B$ . If we treat quintuples of complex numbers $[z_0,...,z_4]$ as the homogeneous coordinates of points in complex projective 4-space, then $B$ consists of all solutions of the three simultaneous equations $\sum_i z_i=0$ , $\sum_i z_i^2=0$ , and $\sum_i z_i^3=0$ .  The first of those equations is linear, cutting out a projective 3-space.  The second equation gives a quadric surface in that 3-space, while the third gives a cubic surface.  Bring's curve $B$ is the complete intersection of those two surfaces, which is a nonsingular sextic curve in complex projective 3-space.  So $B$ is a complex $1$ -manifold.  Since we can permute the five coordinates freely, $B$ has at least an $S_5$ of automorphisms -- in fact, it has exactly those 120 automorphisms.  We can also take the complex conjugates of all five coordinates; so there are also 120 antiautomorphisms. If we work over the real numbers, rather than over the complexes, we view $B$ as a smooth, orientable manifold of real dimension 2 and of genus 4.  It has 240 automorphisms, 120 of which preserve orientation and 120 of which reverse it. ​As a complex 1-manifold, Bring's curve $B$ comes to us with a conformal structure.  Unless I am confused, it follows from the Uniformization Theorem that $B$ can be equipped with a Riemannian metric, compatible with that conformal structure, under which its Gaussian curvature is the constant $-1$ . Question 1: Is that metric unique?  To remain compatible with the conformal structure, our only freedom is a positive-real magnification factor at each point.  And it might be the case that the smooth function giving this magnification factor is uniquely determined by the requirement that the resulting Gaussian curvature turn out to be everywhere $-1$ .  But maybe not. Question 2: Whatever the answer to Question 1, I am trying to find an explicit description of some constant-curvature metric.  If there are multiple such metrics, then choose some simple one. If we equip $B$ with such a metric, we can then lay $B$ out in the hyperbolic plane, getting a repeating pattern.  Given the structure of the automorphism group, we can tile a fundamental domain of that pattern with 240 hyperbolic triangles, each of which has vertex angles of $\pi/5$ , $\pi/4$ , and $\pi/2$ --- that is, 36, 45, and 90 degrees.  Let's call those triangles ""basic triangles"".  The page http://en.wikipedia.org/wiki/Orbifold_notation#mediaviewer/File:H2checkers_245.png shows the hyperbolic plane tiled by basic triangles; but note that there are various subsets of 240 of them that constitute a fundamental domain.  The area of each basic triangle is $\pi/20$ , leading to a total area for the fundamental domain of $12\pi$ , as the Gauss-Bonnet Theorem requires for a surface of genus 4.  And any one of the basic triangles can be taken to any other, either by an automorphism, if the two triangles are the same color in the picture above, or by an antiautomorphism, if they are opposite colors. I know explicit formulas, in terms of the coordinates $[z_i]$ , for the vertices and edges of all of the basic triangles, as I will describe in a moment.  But that's all that I have managed to do so far. Given the coordinates $[z_0,...,z_4]$ of some point along one of the edges of a basic triangle, I would like to be able to compute the distances from that point to the two vertices at the endpoints of the edge.  Finally, I would like to compute distances also for points in the interiors of the triangles. Here are further details, in case anyone is still reading. The 36-degree vertex of any basic triangle is, in fact, the 36-degree vertex of ten basic triangles.  So there are 240/10 = 24 such vertices, and we'll call them Type A.  The 45-degree vertex of any triangle is the 45-degree vertex of eight triangles.  So there are 240/8 = 30 such, which we'll call Type B.  And the 90-degree vertex of any triangle is the 90-degree vertex of four triangles.  So there are 240/4 = 60 such, which we'll call Type C. The paper ""Bring's curve"", by W. L. Edge, published in volume 2-18 of the Journal of the London Math. Society in 1978, pages 539-545, gives explicit formulas for the coordinates of these various vertices.  For vertices of Type A, let $\epsilon:=e^{2 \pi i/5}$ be a primitive fifth root of unity, and then freely permute these coordinates: $$[1, \epsilon, \epsilon^2, \epsilon^3, \epsilon^4].$$ There are 120 ways to permute those five coordinates, of course, but the homogeneity of the coordinates means that we can multiply by any nonzero complex number, and multiplying by powers of $\epsilon$ puts those 120 permutations into groups of size 5, of which there must be 24. The vertices of Type B result from freely permuting the coordinates: $$[0, 1, i, -1, -i].$$ Again, there are 120 ways to permute those coordinates, but multiplying by any power of $i$ puts them into groups of size 4, of which there must be 30. The vertices of Type C are a bit more complicated.  Let $\alpha$ , $\beta$ , and $\gamma$ denote the three roots of the cubic polynomial $z^3+2z^2+3z+4$ .  Then, the Type C vertices result from permuting the coordinates: $$[1, 1, \alpha, \beta, \gamma].$$ The 120 permutations come in pairs that differ only in swapping the two copies of 1; so we get precisely the 60 vertices of Type C. Now, these vertices lie along various hyperbolic lines.  Let's refer to the edges of a basic triangle as being of Type a, Type b, or Type c, where the edge of Type a is opposite the vertex of Type A, and so forth.  So the edges of Type c are the hypotenuses of their triangles, those of Type b are the longer legs, and those of Type a are the shorter legs. In the resulting tiling, there are lines of two types, say Type 1 and Type 2.  A line of Type 1 passes through vertices in the pattern $(A B A C)^4$ .  So it passes through eight vertices of Type A, four of Type B, and four of Type C.  In the process, it travels along eight edges of Type c and eight of Type b, in the repeating pattern $(c c b b)^4$ .  So there must be 15 lines of Type 1, which travel along a total of 120 edges of Type c and 120 of Type b --- each such edge acting as an edge for two of the 240 basic triangles. A line of Type 2 passes through vertices in the pattern $(B C)^6$ .  In the process, it travels along twelve edges, all of Type a.  So there must be 10 lines of Type 2, which travel along the 120 edges of Type a. The formulas for these lines must involve something beyond complex arithmetic, and that extra something is complex conjugation.  Let consider lines of Type 2 first.  One such line consists of all points for which $[z_0,...,z_4]$ coincides, homogeneously, with $[\bar z_1,\bar z_0,\bar z_2,\bar z_3,\bar z_4]$ .  That is, we swap the first two coordinates and we conjugate all five coordinates.  If that combined process leaves us where we started, homogeneously, then the point where we started lies on our current example of a line of Type 2, which we might call ""the (0,1) line of Type 2"".  The ten lines of Type 2 are determined by the ten ways of choosing which two coordinates to swap. Lines of Type 1 are similar, but we swap two pairs of coordinates, rather than just one.  There are fifteen ways to choose two separate pairs of coordinates to swap, and those choices give rise to the fifteen lines of Type 1. As we move along any line of either type, consider the ratio $r:=z_i/z_j$ , for some fixed indices $i$ and $j$ .  The ratio $r$ moves along one of five algebraic curves in the complex plane, which one depending upon how the indices $i$ and $j$ relate to the pairs of coordinates that get swapped -- a single pair for a line of Type 2 or two pairs for a line of Type 1.  The five resulting curves turn out to be of degrees 1, 2, 3, 6, and 12, and it might be helpful to study how they cut up the Riemann sphere. But those curves, along with all of the other structure discussed so far, are forced by how the automorphisms behave on $B$ .  Is the entire constant-curvature metric also forced?  And, if so, how?","There is a well-known and very symmetric space that is called either ""Bring's curve"" or ""Bring's surface"", depending upon the context.  (Bring was a Swedish mathematician in the 18th century.)   Let's here call it simply .  In brief, I am looking for an explicit formula for a constant-curvature Riemannian metric on . If we treat quintuples of complex numbers as the homogeneous coordinates of points in complex projective 4-space, then consists of all solutions of the three simultaneous equations , , and .  The first of those equations is linear, cutting out a projective 3-space.  The second equation gives a quadric surface in that 3-space, while the third gives a cubic surface.  Bring's curve is the complete intersection of those two surfaces, which is a nonsingular sextic curve in complex projective 3-space.  So is a complex -manifold.  Since we can permute the five coordinates freely, has at least an of automorphisms -- in fact, it has exactly those 120 automorphisms.  We can also take the complex conjugates of all five coordinates; so there are also 120 antiautomorphisms. If we work over the real numbers, rather than over the complexes, we view as a smooth, orientable manifold of real dimension 2 and of genus 4.  It has 240 automorphisms, 120 of which preserve orientation and 120 of which reverse it. ​As a complex 1-manifold, Bring's curve comes to us with a conformal structure.  Unless I am confused, it follows from the Uniformization Theorem that can be equipped with a Riemannian metric, compatible with that conformal structure, under which its Gaussian curvature is the constant . Question 1: Is that metric unique?  To remain compatible with the conformal structure, our only freedom is a positive-real magnification factor at each point.  And it might be the case that the smooth function giving this magnification factor is uniquely determined by the requirement that the resulting Gaussian curvature turn out to be everywhere .  But maybe not. Question 2: Whatever the answer to Question 1, I am trying to find an explicit description of some constant-curvature metric.  If there are multiple such metrics, then choose some simple one. If we equip with such a metric, we can then lay out in the hyperbolic plane, getting a repeating pattern.  Given the structure of the automorphism group, we can tile a fundamental domain of that pattern with 240 hyperbolic triangles, each of which has vertex angles of , , and --- that is, 36, 45, and 90 degrees.  Let's call those triangles ""basic triangles"".  The page http://en.wikipedia.org/wiki/Orbifold_notation#mediaviewer/File:H2checkers_245.png shows the hyperbolic plane tiled by basic triangles; but note that there are various subsets of 240 of them that constitute a fundamental domain.  The area of each basic triangle is , leading to a total area for the fundamental domain of , as the Gauss-Bonnet Theorem requires for a surface of genus 4.  And any one of the basic triangles can be taken to any other, either by an automorphism, if the two triangles are the same color in the picture above, or by an antiautomorphism, if they are opposite colors. I know explicit formulas, in terms of the coordinates , for the vertices and edges of all of the basic triangles, as I will describe in a moment.  But that's all that I have managed to do so far. Given the coordinates of some point along one of the edges of a basic triangle, I would like to be able to compute the distances from that point to the two vertices at the endpoints of the edge.  Finally, I would like to compute distances also for points in the interiors of the triangles. Here are further details, in case anyone is still reading. The 36-degree vertex of any basic triangle is, in fact, the 36-degree vertex of ten basic triangles.  So there are 240/10 = 24 such vertices, and we'll call them Type A.  The 45-degree vertex of any triangle is the 45-degree vertex of eight triangles.  So there are 240/8 = 30 such, which we'll call Type B.  And the 90-degree vertex of any triangle is the 90-degree vertex of four triangles.  So there are 240/4 = 60 such, which we'll call Type C. The paper ""Bring's curve"", by W. L. Edge, published in volume 2-18 of the Journal of the London Math. Society in 1978, pages 539-545, gives explicit formulas for the coordinates of these various vertices.  For vertices of Type A, let be a primitive fifth root of unity, and then freely permute these coordinates: There are 120 ways to permute those five coordinates, of course, but the homogeneity of the coordinates means that we can multiply by any nonzero complex number, and multiplying by powers of puts those 120 permutations into groups of size 5, of which there must be 24. The vertices of Type B result from freely permuting the coordinates: Again, there are 120 ways to permute those coordinates, but multiplying by any power of puts them into groups of size 4, of which there must be 30. The vertices of Type C are a bit more complicated.  Let , , and denote the three roots of the cubic polynomial .  Then, the Type C vertices result from permuting the coordinates: The 120 permutations come in pairs that differ only in swapping the two copies of 1; so we get precisely the 60 vertices of Type C. Now, these vertices lie along various hyperbolic lines.  Let's refer to the edges of a basic triangle as being of Type a, Type b, or Type c, where the edge of Type a is opposite the vertex of Type A, and so forth.  So the edges of Type c are the hypotenuses of their triangles, those of Type b are the longer legs, and those of Type a are the shorter legs. In the resulting tiling, there are lines of two types, say Type 1 and Type 2.  A line of Type 1 passes through vertices in the pattern .  So it passes through eight vertices of Type A, four of Type B, and four of Type C.  In the process, it travels along eight edges of Type c and eight of Type b, in the repeating pattern .  So there must be 15 lines of Type 1, which travel along a total of 120 edges of Type c and 120 of Type b --- each such edge acting as an edge for two of the 240 basic triangles. A line of Type 2 passes through vertices in the pattern .  In the process, it travels along twelve edges, all of Type a.  So there must be 10 lines of Type 2, which travel along the 120 edges of Type a. The formulas for these lines must involve something beyond complex arithmetic, and that extra something is complex conjugation.  Let consider lines of Type 2 first.  One such line consists of all points for which coincides, homogeneously, with .  That is, we swap the first two coordinates and we conjugate all five coordinates.  If that combined process leaves us where we started, homogeneously, then the point where we started lies on our current example of a line of Type 2, which we might call ""the (0,1) line of Type 2"".  The ten lines of Type 2 are determined by the ten ways of choosing which two coordinates to swap. Lines of Type 1 are similar, but we swap two pairs of coordinates, rather than just one.  There are fifteen ways to choose two separate pairs of coordinates to swap, and those choices give rise to the fifteen lines of Type 1. As we move along any line of either type, consider the ratio , for some fixed indices and .  The ratio moves along one of five algebraic curves in the complex plane, which one depending upon how the indices and relate to the pairs of coordinates that get swapped -- a single pair for a line of Type 2 or two pairs for a line of Type 1.  The five resulting curves turn out to be of degrees 1, 2, 3, 6, and 12, and it might be helpful to study how they cut up the Riemann sphere. But those curves, along with all of the other structure discussed so far, are forced by how the automorphisms behave on .  Is the entire constant-curvature metric also forced?  And, if so, how?","B B [z_0,...,z_4] B \sum_i z_i=0 \sum_i z_i^2=0 \sum_i z_i^3=0 B B 1 B S_5 B B B -1 -1 B B \pi/5 \pi/4 \pi/2 \pi/20 12\pi [z_i] [z_0,...,z_4] \epsilon:=e^{2 \pi i/5} [1, \epsilon, \epsilon^2, \epsilon^3, \epsilon^4]. \epsilon [0, 1, i, -1, -i]. i \alpha \beta \gamma z^3+2z^2+3z+4 [1, 1, \alpha, \beta, \gamma]. (A B A C)^4 (c c b b)^4 (B C)^6 [z_0,...,z_4] [\bar z_1,\bar z_0,\bar z_2,\bar z_3,\bar z_4] r:=z_i/z_j i j r i j B","['differential-geometry', 'riemann-surfaces', 'hyperbolic-geometry']"
83,Basic misunderstanding of the theorema egregium,Basic misunderstanding of the theorema egregium,,"The theorema egregium demonstrates that the Gaussian curvature, $K$, is an intrinsic property. What I think this means is that if you know the metric corresponding to the surface, then you can compute the Gaussian curvature. Equivalently, two isometric surfaces have the same curvature. Gauss gave an explicit formula for $K$ which only depends on $E,F,G$ and their derivatives, where $E,F,G$ are the matrix elements of the metric. Because of the independence of the embedding, it makes sense to study surfaces in their own right, i.e. not being embedded into $\mathbb{R}^3$, right? What I don't understand is that $E,F,G$ are coming from the metric upstairs. How could someone living on this surface calculate the curvature using this formula? That would mean they know $E,F,G$ which would mean they know the embedding, which means they know that there exists some higher dimensional space. A person living on a surface doesn't know of the third dimension. To them, their world is a 2 dimensional plane, right? So to them they would always measure distance the standard way, using $dx^2+dy^2$. This person could perhaps calculate the interior angles of a triangle and see that the sum is not $180$, but that's not using the formula for $K$. It seems that a person in $\mathbb{R}^3$ is calculating the induced metric and saying this is the metric on the surface. But a person on the surface thinks they live in $\mathbb{R}^2$ and so are using a metric that has no dependence on the $z$-coordinate. How does a person on the surface calculate the Gaussian curvature of their world?","The theorema egregium demonstrates that the Gaussian curvature, $K$, is an intrinsic property. What I think this means is that if you know the metric corresponding to the surface, then you can compute the Gaussian curvature. Equivalently, two isometric surfaces have the same curvature. Gauss gave an explicit formula for $K$ which only depends on $E,F,G$ and their derivatives, where $E,F,G$ are the matrix elements of the metric. Because of the independence of the embedding, it makes sense to study surfaces in their own right, i.e. not being embedded into $\mathbb{R}^3$, right? What I don't understand is that $E,F,G$ are coming from the metric upstairs. How could someone living on this surface calculate the curvature using this formula? That would mean they know $E,F,G$ which would mean they know the embedding, which means they know that there exists some higher dimensional space. A person living on a surface doesn't know of the third dimension. To them, their world is a 2 dimensional plane, right? So to them they would always measure distance the standard way, using $dx^2+dy^2$. This person could perhaps calculate the interior angles of a triangle and see that the sum is not $180$, but that's not using the formula for $K$. It seems that a person in $\mathbb{R}^3$ is calculating the induced metric and saying this is the metric on the surface. But a person on the surface thinks they live in $\mathbb{R}^2$ and so are using a metric that has no dependence on the $z$-coordinate. How does a person on the surface calculate the Gaussian curvature of their world?",,"['differential-geometry', 'riemannian-geometry']"
84,Shallow tent like soap film,Shallow tent like soap film,,A soap film circle in $x-y$ plane with center at origin can be carefully pricked with a blunt soapy pin at center and drawn out a little bit on $z$-axis forming a surface of revolution somewhat like a tent roof. What shape/equation does it have before onset of Goldschmidt instability collapse? It is easy to practically check out its formation with liquid detergent. The $y = c \cosh (x/c)$ classic catenoid minimal area case between two rings with $c$ depending on surface tension etc. is the only  symmetric case mentioned in text books.,A soap film circle in $x-y$ plane with center at origin can be carefully pricked with a blunt soapy pin at center and drawn out a little bit on $z$-axis forming a surface of revolution somewhat like a tent roof. What shape/equation does it have before onset of Goldschmidt instability collapse? It is easy to practically check out its formation with liquid detergent. The $y = c \cosh (x/c)$ classic catenoid minimal area case between two rings with $c$ depending on surface tension etc. is the only  symmetric case mentioned in text books.,,"['differential-geometry', 'calculus-of-variations', 'minimal-surfaces']"
85,Definition of the algebraic intersection number of oriented closed curves.,Definition of the algebraic intersection number of oriented closed curves.,,"Can anyone point me to a reference (book/paper) where I can read up on the  the algebraic intersection number of closed curves on an orientable surface? In this paper by John Franks it is used to prove Proposition 2.7. The only resource where I could find something is Farb and Margalit: A primer on MCGs . It says there on page 28: Let $\alpha,\beta$ be two oriented, transverse, simple closed curves on an oriented surface $S$. The algebraic intersection number $\hat{i}(\alpha,\beta)$ is defined as the sum of the indeces of the intersection points of $\alpha$ and $\beta$, where an index of an intersection point is $+1$ if the orientation of the intersection agrees with the orientation of $S$ and $-1$ otherwise. First of all, I can't really make sense of the notion of agreement of the orientation of an intersection with the orientation of the surface. What I could imagine is choosing one of the curves ($\alpha$) as a reference and counting an intersetion with $+1$ if the other curve ($\beta$) crosses $\alpha$ from left to right and with $-1$ if $\beta$ crosses $\alpha$ from right to left. In Farb and Margalit's book it is mentioned that this intersection number is invariant for homologically equivalent loops. Does anyone know where I can find a proof?","Can anyone point me to a reference (book/paper) where I can read up on the  the algebraic intersection number of closed curves on an orientable surface? In this paper by John Franks it is used to prove Proposition 2.7. The only resource where I could find something is Farb and Margalit: A primer on MCGs . It says there on page 28: Let $\alpha,\beta$ be two oriented, transverse, simple closed curves on an oriented surface $S$. The algebraic intersection number $\hat{i}(\alpha,\beta)$ is defined as the sum of the indeces of the intersection points of $\alpha$ and $\beta$, where an index of an intersection point is $+1$ if the orientation of the intersection agrees with the orientation of $S$ and $-1$ otherwise. First of all, I can't really make sense of the notion of agreement of the orientation of an intersection with the orientation of the surface. What I could imagine is choosing one of the curves ($\alpha$) as a reference and counting an intersetion with $+1$ if the other curve ($\beta$) crosses $\alpha$ from left to right and with $-1$ if $\beta$ crosses $\alpha$ from right to left. In Farb and Margalit's book it is mentioned that this intersection number is invariant for homologically equivalent loops. Does anyone know where I can find a proof?",,"['differential-geometry', 'algebraic-topology', 'homotopy-theory', 'surfaces', 'homology-cohomology']"
86,How to prove the holonomy group is preserved under Ricci flow?,How to prove the holonomy group is preserved under Ricci flow?,,"I've heard that on a Kähler manifold $(M,g_0)$, if you evolve the metric $g$ by Ricci flow $\partial g_{ij}(t)/\partial t=-2R_{ij}$, and $g(0)=g_0$, then you always have $g(t)$ is a Kähler metric on $M$. All the references I saw refer this fact to that the holonomy group of $(M,g(t))$ is preserved under Ricci flow, but I don't know how to prove it.","I've heard that on a Kähler manifold $(M,g_0)$, if you evolve the metric $g$ by Ricci flow $\partial g_{ij}(t)/\partial t=-2R_{ij}$, and $g(0)=g_0$, then you always have $g(t)$ is a Kähler metric on $M$. All the references I saw refer this fact to that the holonomy group of $(M,g(t))$ is preserved under Ricci flow, but I don't know how to prove it.",,"['differential-geometry', 'riemannian-geometry', 'ricci-flow', 'kahler-manifolds']"
87,Technical Details in do Carmo's Riemannian Geometry,Technical Details in do Carmo's Riemannian Geometry,,"I am confused about a proof in do Carmo's Riemannian Geometry . The following side-to-side screenshots are pages 227 - 228 in Section 4 of Chapter 10. I have included them so as to keep the question self-contained. The main post is directly below the pictures. If it helps, we may assume that $N$ is an embedded submanifold (the case I care about). For reference's sake, I will also include a screenshot of the ""Weingarten equation"" theorem from Chapter 6 of the same book. I am confused about do Carmo's proof of property (ii). do Carmo writes $$ \frac{DA}{ds}(0) = \left.\overline{\nabla}_{J(0)}A(s)\right|_{s = 0}. $$ The right-hand side doesn't make a lot of sense to me. $A(s)$ is a vector field defined along a curve and not on an open subset of $M$ . If $A(s)$ is extendible to a vector field $X$ in a neighborhood of $p$ with $X(\alpha(s)) = A(s)$ for small enough $s$ , then the definition of $DA/ds(0)$ implies that $DA/ds(0) = \overline{\nabla}_{J(0)}X$ , and then we could continue the proof just fine. I cannot think of any other possible interpretation for the right-hand side of the above equation. But what if $A(s)$ is not extendible? Is there something that guarantees it in this case, or is this a missing assumption? Question 1: How do we choose such a vector field $X$ on $M$ near $p$ , such that for small enough $s$ , $X(\alpha(s)) = A(s)$ ? (Are we necessarily able to in this case, or is do Carmo omitting an important hypothesis?) If, for example, $\alpha'(0) = J(0) \neq 0$ , then $\alpha$ is locally an embedding, and so I can find local coordinates $(x^1,\dots,x^n)$ for $M$ with $\alpha(s) = (0, \dots, 0, s)$ , and then extend $A$ in the obvious way, But what if $J(0) = 0$ ? I do not see what to do in this case. It suffices in this case to prove that $J'(0) \in (T_pM)^\perp$ , but I don't know how to show this. Now, let's assume that we've chosen such an $X$ . I interpret the last equation as saying that $$ \left.\left\langle\left(\overline{\nabla}_{J(0)}A(s)\right)^\top,v\right\rangle\right|_{s = 0} = \left\langle \left(\overline{\nabla}_{J(0)}X\right)^\top,v\right\rangle = \left\langle -S_{\gamma'(0)}(J(0)), v \right\rangle, $$ where the last equality supposedly follows from the Weingarten equation (reference above). In order to apply this, we have to choose our local extension $X$ in such a way that $X$ is normal to $N$ . Question 2: As a follow-up to Question 1, how can we choose $X$ normal to $N$ ? I apologize for the very long post. Any insights or help would be appreciated. I haven't been able to find anything on this online or in other textbooks, which is why I've decided to post this. If anyone could share any references with proofs of the fact do Carmo is proving, that would also be very helpful. (Of course, if I am making a fundamental misunderstanding and overcomplicating something, I would also welcome that as an answer.) Edit: Inspired by this post, I noticed that Question 1 can be whittled down to a specific case. If $\alpha'(0) \neq 0$ , then, as I remarked above, we can extend $A(s)$ . (The question of how to choose the extension normal to $N$ still stands.) If $\alpha'(s) = 0$ for all $s$ sufficiently close to $0$ , then $\alpha(s) \equiv p$ for small $s$ . In this case, $A(s)$ is a curve in the vector space $(T_pN)^\perp$ , so it follows that $J'(0) = DA/ds(0) = dA/ds(0) \in (T_pN)^\perp$ , which proves (ii) directly. It only remains to figure out what happens when we have a sequence $s_n \to 0$ with $\alpha'(s_n) \neq 0$ but $\alpha'(0) = 0$ . This, I have made no progress on.","I am confused about a proof in do Carmo's Riemannian Geometry . The following side-to-side screenshots are pages 227 - 228 in Section 4 of Chapter 10. I have included them so as to keep the question self-contained. The main post is directly below the pictures. If it helps, we may assume that is an embedded submanifold (the case I care about). For reference's sake, I will also include a screenshot of the ""Weingarten equation"" theorem from Chapter 6 of the same book. I am confused about do Carmo's proof of property (ii). do Carmo writes The right-hand side doesn't make a lot of sense to me. is a vector field defined along a curve and not on an open subset of . If is extendible to a vector field in a neighborhood of with for small enough , then the definition of implies that , and then we could continue the proof just fine. I cannot think of any other possible interpretation for the right-hand side of the above equation. But what if is not extendible? Is there something that guarantees it in this case, or is this a missing assumption? Question 1: How do we choose such a vector field on near , such that for small enough , ? (Are we necessarily able to in this case, or is do Carmo omitting an important hypothesis?) If, for example, , then is locally an embedding, and so I can find local coordinates for with , and then extend in the obvious way, But what if ? I do not see what to do in this case. It suffices in this case to prove that , but I don't know how to show this. Now, let's assume that we've chosen such an . I interpret the last equation as saying that where the last equality supposedly follows from the Weingarten equation (reference above). In order to apply this, we have to choose our local extension in such a way that is normal to . Question 2: As a follow-up to Question 1, how can we choose normal to ? I apologize for the very long post. Any insights or help would be appreciated. I haven't been able to find anything on this online or in other textbooks, which is why I've decided to post this. If anyone could share any references with proofs of the fact do Carmo is proving, that would also be very helpful. (Of course, if I am making a fundamental misunderstanding and overcomplicating something, I would also welcome that as an answer.) Edit: Inspired by this post, I noticed that Question 1 can be whittled down to a specific case. If , then, as I remarked above, we can extend . (The question of how to choose the extension normal to still stands.) If for all sufficiently close to , then for small . In this case, is a curve in the vector space , so it follows that , which proves (ii) directly. It only remains to figure out what happens when we have a sequence with but . This, I have made no progress on.","N 
\frac{DA}{ds}(0) = \left.\overline{\nabla}_{J(0)}A(s)\right|_{s = 0}.
 A(s) M A(s) X p X(\alpha(s)) = A(s) s DA/ds(0) DA/ds(0) = \overline{\nabla}_{J(0)}X A(s) X M p s X(\alpha(s)) = A(s) \alpha'(0) = J(0) \neq 0 \alpha (x^1,\dots,x^n) M \alpha(s) = (0, \dots, 0, s) A J(0) = 0 J'(0) \in (T_pM)^\perp X 
\left.\left\langle\left(\overline{\nabla}_{J(0)}A(s)\right)^\top,v\right\rangle\right|_{s = 0} = \left\langle \left(\overline{\nabla}_{J(0)}X\right)^\top,v\right\rangle = \left\langle -S_{\gamma'(0)}(J(0)), v \right\rangle,
 X X N X N \alpha'(0) \neq 0 A(s) N \alpha'(s) = 0 s 0 \alpha(s) \equiv p s A(s) (T_pN)^\perp J'(0) = DA/ds(0) = dA/ds(0) \in (T_pN)^\perp s_n \to 0 \alpha'(s_n) \neq 0 \alpha'(0) = 0",['differential-geometry']
88,Finding a metric to make a certain curve a circle,Finding a metric to make a certain curve a circle,,"Given a  simple closed, regular $C^\infty$ curve $\phi$ in $U\subset\mathbb{R}^n$ naturally parametrized (by it's arc length), is there any way to obtain a Riemaniann manifold $(S,g)$ of dimension 2 without boundary (isometrically embedded in $\mathbb{R}^m$ equipped with the standard metric) such that there is a geodesic circle in this surface that is equal to the curve (meaning that it is mapped by the embedding to $\phi$ )? Two examples: $1)\gamma(t)=\begin{pmatrix} \left(\frac{\sin(20\pi t)}{10}+1\right)\sin(2\pi t)\\ \left(\frac{\sin(20\pi t)}{10}+1\right) \cos(2\pi t)\\ \sin(2\pi t)\end{pmatrix}\\ 2)\gamma(t)=\begin{pmatrix} \left(\frac{\sin(20\pi t)}{10}+1\right)\sin(2\pi t)\\ \left(\frac{\sin(20\pi t)}{10}+1\right) \cos(2\pi t)\end{pmatrix}$ One possibility, considering $\gamma \in \mathbb{R}^2$ , is to use the Riemann smooth mapping theorem in such a way to obtain a complex diffeomorphism $\phi$ between $\gamma\bigcup \text{Int}(\gamma)$ and the closed unitary disk $D$ . In this way, we might define the metric tensor on $S=\phi^{-1}(D)$ as the pullback of the euclidean metric tensor restricted to the unitary disk, but that leaves us with a manifold with boundary. We may try to extend it, but such a subject is quite technical, and I would not know how to proceed. Even if this idea was succesful This method would work only in $\mathbb{R}^2$ , leaving open the question for $n>2$ . The questions are thus: 1) Is my idea efficient to solve the problem in $\mathbb{R}^2$ ? If so, how to remove the boundary? 2)How to attack the problem if $\gamma \subset \mathbb{R}^n$ with $n>2$ (as an example, see the first example)?","Given a  simple closed, regular curve in naturally parametrized (by it's arc length), is there any way to obtain a Riemaniann manifold of dimension 2 without boundary (isometrically embedded in equipped with the standard metric) such that there is a geodesic circle in this surface that is equal to the curve (meaning that it is mapped by the embedding to )? Two examples: One possibility, considering , is to use the Riemann smooth mapping theorem in such a way to obtain a complex diffeomorphism between and the closed unitary disk . In this way, we might define the metric tensor on as the pullback of the euclidean metric tensor restricted to the unitary disk, but that leaves us with a manifold with boundary. We may try to extend it, but such a subject is quite technical, and I would not know how to proceed. Even if this idea was succesful This method would work only in , leaving open the question for . The questions are thus: 1) Is my idea efficient to solve the problem in ? If so, how to remove the boundary? 2)How to attack the problem if with (as an example, see the first example)?","C^\infty \phi U\subset\mathbb{R}^n (S,g) \mathbb{R}^m \phi 1)\gamma(t)=\begin{pmatrix} \left(\frac{\sin(20\pi t)}{10}+1\right)\sin(2\pi t)\\ \left(\frac{\sin(20\pi t)}{10}+1\right) \cos(2\pi t)\\ \sin(2\pi t)\end{pmatrix}\\
2)\gamma(t)=\begin{pmatrix} \left(\frac{\sin(20\pi t)}{10}+1\right)\sin(2\pi t)\\ \left(\frac{\sin(20\pi t)}{10}+1\right) \cos(2\pi t)\end{pmatrix} \gamma \in \mathbb{R}^2 \phi \gamma\bigcup \text{Int}(\gamma) D S=\phi^{-1}(D) \mathbb{R}^2 n>2 \mathbb{R}^2 \gamma \subset \mathbb{R}^n n>2","['differential-geometry', 'metric-spaces']"
89,Points where the Jacobian of a coordinate transformation vanishes,Points where the Jacobian of a coordinate transformation vanishes,,"Consider the coordinate transformation  \begin{align*} x &= r\sin\theta\cos\phi \\ y &= r\sin\theta\sin\phi \\ z &= r\cos\theta \end{align*} from spherical coordinates $(r,\theta,\phi)$ to rectangular coordinates $(x,y,z)$. Here $r$ is the radius, $\theta$ is the inclination, and $\phi$ is the azimuth. Its Jacobian  $$\frac{\partial(x,y,z)}{\partial(r,\theta,\phi)} = r^2\sin\theta$$ vanishes on the $z$-axis. According to C. Lanczos in The Variational Principles of Mechanics : [The Jacobian of a coordinate transformation may vanish] at certain singular points, which have to be excluded from consideration. For example, [for the coordinate transformation above] special care is required at the values $r = 0$ and $\theta = 0$, for which the Jacobian of the transformation vanishes. Question : Are points at which the Jacobian of a coordinate transformation vanishes ""excluded from consideration"" altogether or included in the analysis but handled with ""special care""? Perhaps a problem (from the same book) will clarify the question. Characterize the position of a spherical pendulum of length $l$ by spherical coordinates $r$, $\theta$, $\phi$ and obtain :    \begin{align*} T &= \frac{m}{2}l^2\Big(\dot{\theta}^{\,2} + \sin^2\!\theta \,\dot{\phi}^{\,2}\Big), \\ V &= mgl(1 - \cos\theta). \end{align*}   Form the Lagrangian equations of motion. The Lagrangian is  $$L = T - V = \frac{m}{2}l^2\Big(\dot{\theta}^{\,2} + \sin^2\!\theta \,\dot{\phi}^{\,2}\Big) + mgl(\cos\theta - 1).$$ Since  \begin{gather*} \partial_{\dot{\theta}}L = ml^2\dot{\theta}, \\ \partial_\theta L = ml^2\sin\theta\cos\theta\,\dot{\phi}^{\,2} - mgl\sin\theta, \\  \partial_{\dot{\phi}}L = ml^2\sin^2\!\theta\,\dot{\phi}, \\ \partial_\phi L = 0, \end{gather*} the Lagrangian equations of motion are \begin{gather*} \frac{d}{dt}\Big(ml^2\dot{\theta}\Big) - ml^2\sin\theta\cos\theta\,\dot{\phi}^{\,2} + mgl\sin\theta = 0 \\ \frac{d}{dt}\Big(ml^2\sin^2\!\theta\,\dot{\phi}\Big) = 0 \end{gather*} In the solution to this problem, should it be stated that points on the $z$-axis are ""excluded from consideration""? Or should they be included, but treated with ""special care""? In particular: Do the equations in this problem (for kinetic and potential energy; the Euler-Lagrange equations) hold on the $z$-axis? Do the partial derivatives $\partial_r$, $\partial_\theta$, $\partial_\phi$ (as defined in differential geometry) exist on the $z$-axis?","Consider the coordinate transformation  \begin{align*} x &= r\sin\theta\cos\phi \\ y &= r\sin\theta\sin\phi \\ z &= r\cos\theta \end{align*} from spherical coordinates $(r,\theta,\phi)$ to rectangular coordinates $(x,y,z)$. Here $r$ is the radius, $\theta$ is the inclination, and $\phi$ is the azimuth. Its Jacobian  $$\frac{\partial(x,y,z)}{\partial(r,\theta,\phi)} = r^2\sin\theta$$ vanishes on the $z$-axis. According to C. Lanczos in The Variational Principles of Mechanics : [The Jacobian of a coordinate transformation may vanish] at certain singular points, which have to be excluded from consideration. For example, [for the coordinate transformation above] special care is required at the values $r = 0$ and $\theta = 0$, for which the Jacobian of the transformation vanishes. Question : Are points at which the Jacobian of a coordinate transformation vanishes ""excluded from consideration"" altogether or included in the analysis but handled with ""special care""? Perhaps a problem (from the same book) will clarify the question. Characterize the position of a spherical pendulum of length $l$ by spherical coordinates $r$, $\theta$, $\phi$ and obtain :    \begin{align*} T &= \frac{m}{2}l^2\Big(\dot{\theta}^{\,2} + \sin^2\!\theta \,\dot{\phi}^{\,2}\Big), \\ V &= mgl(1 - \cos\theta). \end{align*}   Form the Lagrangian equations of motion. The Lagrangian is  $$L = T - V = \frac{m}{2}l^2\Big(\dot{\theta}^{\,2} + \sin^2\!\theta \,\dot{\phi}^{\,2}\Big) + mgl(\cos\theta - 1).$$ Since  \begin{gather*} \partial_{\dot{\theta}}L = ml^2\dot{\theta}, \\ \partial_\theta L = ml^2\sin\theta\cos\theta\,\dot{\phi}^{\,2} - mgl\sin\theta, \\  \partial_{\dot{\phi}}L = ml^2\sin^2\!\theta\,\dot{\phi}, \\ \partial_\phi L = 0, \end{gather*} the Lagrangian equations of motion are \begin{gather*} \frac{d}{dt}\Big(ml^2\dot{\theta}\Big) - ml^2\sin\theta\cos\theta\,\dot{\phi}^{\,2} + mgl\sin\theta = 0 \\ \frac{d}{dt}\Big(ml^2\sin^2\!\theta\,\dot{\phi}\Big) = 0 \end{gather*} In the solution to this problem, should it be stated that points on the $z$-axis are ""excluded from consideration""? Or should they be included, but treated with ""special care""? In particular: Do the equations in this problem (for kinetic and potential energy; the Euler-Lagrange equations) hold on the $z$-axis? Do the partial derivatives $\partial_r$, $\partial_\theta$, $\partial_\phi$ (as defined in differential geometry) exist on the $z$-axis?",,"['differential-geometry', 'physics', 'coordinate-systems', 'spherical-coordinates']"
90,Basis of cohomology of curve,Basis of cohomology of curve,,"Let $R$ be a Riemann surface of genus g and $p\in R$ a point. I'm searching for a way to compute linearly independent differential 1-forms on $R$ which: are closed and not exact, not holomorphic, not anti-holomorphic are zero on $p$ Is there a standard way to do so? Thank you","Let $R$ be a Riemann surface of genus g and $p\in R$ a point. I'm searching for a way to compute linearly independent differential 1-forms on $R$ which: are closed and not exact, not holomorphic, not anti-holomorphic are zero on $p$ Is there a standard way to do so? Thank you",,"['differential-geometry', 'algebraic-geometry', 'differential-forms', 'complex-geometry', 'riemann-surfaces']"
91,What is the canonical bundle of a smooth divisor?,What is the canonical bundle of a smooth divisor?,,"I am currently trying to learn some complex geometry, using mainly the book by Huybrechts. There is one thing confusing me, however: For example on Wikipedia people are talking about the canonical bundle of a smooth divisor (in the linked article called $\omega_D$) and I am not sure what that is. I do understand how to define the canonical bundle of a complex manifold. Therefore, I also understand how to define the canonical bundle of, say, a smooth hypersurface. I also know that every hypersurface Y defines a divisor $D = \sum_i [Y_i]$, where $Y_i$ are the irreducible components. Given a smooth divisor $D = \sum_i a_i [Y_i]$ one could assign the hypersurface $Y = \bigcup_i Y_i$ to it and define $\omega_D = \omega_Y$. But (like Huybrechts also writes in his book) this construction is clearly not very natural. It just doesn't seem to be right to me. How is the bundle $\omega_D$ defined then? (What is, e.g., the base space of this bundle?)","I am currently trying to learn some complex geometry, using mainly the book by Huybrechts. There is one thing confusing me, however: For example on Wikipedia people are talking about the canonical bundle of a smooth divisor (in the linked article called $\omega_D$) and I am not sure what that is. I do understand how to define the canonical bundle of a complex manifold. Therefore, I also understand how to define the canonical bundle of, say, a smooth hypersurface. I also know that every hypersurface Y defines a divisor $D = \sum_i [Y_i]$, where $Y_i$ are the irreducible components. Given a smooth divisor $D = \sum_i a_i [Y_i]$ one could assign the hypersurface $Y = \bigcup_i Y_i$ to it and define $\omega_D = \omega_Y$. But (like Huybrechts also writes in his book) this construction is clearly not very natural. It just doesn't seem to be right to me. How is the bundle $\omega_D$ defined then? (What is, e.g., the base space of this bundle?)",,"['algebraic-geometry', 'differential-geometry', 'complex-geometry']"
92,Riemann tensor symmetries,Riemann tensor symmetries,,The Riemann tensor has its component expression: $R^{\mu}_{\nu\rho\sigma}=\partial_{\rho}\Gamma^{\mu}_{\sigma\nu}-\partial_{\sigma}\Gamma^{\mu}_{\rho\nu}+\Gamma^{\mu}_{\rho\lambda}\Gamma^{\lambda}_{\sigma\nu}-\Gamma^{\mu}_{\sigma\lambda}\Gamma^{\lambda}_{\rho\nu}.$ It is straight forward to prove the antisymmetry of $R$ in the last two indices; but how to prove the antisymmetry in the first two ones without assuming symmetric connection/torsion-free metric?,The Riemann tensor has its component expression: $R^{\mu}_{\nu\rho\sigma}=\partial_{\rho}\Gamma^{\mu}_{\sigma\nu}-\partial_{\sigma}\Gamma^{\mu}_{\rho\nu}+\Gamma^{\mu}_{\rho\lambda}\Gamma^{\lambda}_{\sigma\nu}-\Gamma^{\mu}_{\sigma\lambda}\Gamma^{\lambda}_{\rho\nu}.$ It is straight forward to prove the antisymmetry of $R$ in the last two indices; but how to prove the antisymmetry in the first two ones without assuming symmetric connection/torsion-free metric?,,"['differential-geometry', 'general-relativity']"
93,Do any exotic smooth structures on $\mathbb R^n$ leave addition and negation smooth?,Do any exotic smooth structures on  leave addition and negation smooth?,\mathbb R^n,"Let $V$ be a finite-dimensional real vector space with the standard topology. We can equip $V$ with the ""standard smooth structure,"" which includes as charts every linear isomorphism $\phi:V\to\mathbb R^n$ . With this smooth structure, $V$ becomes a Lie group because $(x, y)\mapsto x+y$ and $x\mapsto -x$ are smooth. Do any nonstandard/exotic smooth structures on $V$ also make these operations smooth? I'm wondering if perhaps the solution to Hilbert's fifth problem (or more basic principles) rule this out, but I'm too much of a novice in this area to understand what those results entail. There are also some other posts regarding the relationship between exotic smooth structures and Lie groups [1] [2] [3] , but again I'm too much of a novice to see whether those questions are directly relevant to this one.","Let be a finite-dimensional real vector space with the standard topology. We can equip with the ""standard smooth structure,"" which includes as charts every linear isomorphism . With this smooth structure, becomes a Lie group because and are smooth. Do any nonstandard/exotic smooth structures on also make these operations smooth? I'm wondering if perhaps the solution to Hilbert's fifth problem (or more basic principles) rule this out, but I'm too much of a novice in this area to understand what those results entail. There are also some other posts regarding the relationship between exotic smooth structures and Lie groups [1] [2] [3] , but again I'm too much of a novice to see whether those questions are directly relevant to this one.","V V \phi:V\to\mathbb R^n V (x, y)\mapsto x+y x\mapsto -x V","['differential-geometry', 'lie-groups', 'smooth-manifolds', 'topological-groups']"
94,Extending the tangent bundle of a submanifold to a subbundle of the manifold,Extending the tangent bundle of a submanifold to a subbundle of the manifold,,"Given an $m$ -dimensional manifold $M$ , and an $n$ -dimensional submanifold $N$ , with $n<m$ , the tangent bundle of $N$ is a smooth $n$ -dimensional subbundle of $TM|_N$ . When can $TN$ be extended to an $n$ -dimensional subbundle of $TM$ ? There are obvious examples where it's easy to extend $TN$ to a subbundle of $TM$ , but for a spiral in $\mathbb{R}^2$ , or the equator in a sphere it is not possible. Edit - It's interesting to note that a sphere doesn't admit any $1$ -dimensional subbundle. On the other hand, $\mathbb{R}^2$ obviously admits a $1$ -dimensional subbundle, but still the tangent bundle of the spiral can't be extended to a full subbundle. Similar ""spiral""-like submanifolds of any dimension $1 \le n < m$ can be found for every $m$ -dimensional manifold. Cross posted to MO","Given an -dimensional manifold , and an -dimensional submanifold , with , the tangent bundle of is a smooth -dimensional subbundle of . When can be extended to an -dimensional subbundle of ? There are obvious examples where it's easy to extend to a subbundle of , but for a spiral in , or the equator in a sphere it is not possible. Edit - It's interesting to note that a sphere doesn't admit any -dimensional subbundle. On the other hand, obviously admits a -dimensional subbundle, but still the tangent bundle of the spiral can't be extended to a full subbundle. Similar ""spiral""-like submanifolds of any dimension can be found for every -dimensional manifold. Cross posted to MO",m M n N n<m N n TM|_N TN n TM TN TM \mathbb{R}^2 1 \mathbb{R}^2 1 1 \le n < m m,"['differential-geometry', 'smooth-manifolds', 'vector-bundles']"
95,Is a spherically symmetric space-time isometric to a warped product?,Is a spherically symmetric space-time isometric to a warped product?,,"A spherically symmetric spacetime is a Lorentian 4-dimensional manifold $(M, g)$ whose isometry group contains a subgroup $G$ isomorphic to $\text{SO}(3)$ and whose orbits are 2-spheres. Here I am already confused. How can the orbits of $G$ , which are submanifolds of $M$ , be 2-spheres? Am I missing some general definition of 2-spheres that does not require being in Euclidean space? Next, how can we rigorously decompose the metric of this spacetime into one of the form $$ g = A(r, t) \text d r ^2 + B(r, t) \text d r \text d t + C(r, t) \text d t^2 + C(r, t) \text d \Omega ^2 \ ?  $$ I am willing to take for granted that $\text{Iso}(M)$ is a Lie group and thus $G$ is diffeomorphic to $\text{SO}(3)$ . In particular, the Lie algebra of $G$ is isomorphic to that of $\text{SO}(3)$ which is isomorphic to $(\Bbb R^3, \times)$ . Because the Lie algebra of the isometry group consists of Killing fields, this means we have 3 Killing Fields $V_i$ s.t. $$ [V_i, V_j] = \epsilon_{ijk} V_k. $$ By Frobenius theorem, these vector fields generate  foliation of $M$ , and around every point of $M$ we can find a coordinate chart $(U, x^i)$ s.t. each leaf of our foliation corresponds to slices of constant $x^i$ with, say, $i = 0, 1$ . Now I somehow need to find a coordinate transformation that ensures the vector fields $\partial_0$ and $\partial_1$ are orthogonal to every leaf of the foliation. To show that the inner products of the coordinate vector fields are independent of their location on each leaf I imagine I have to use the isometry conditions, but I do not know how the coordinate vector fields relate to the isometries themselves. Is there a canonical way to do this?","A spherically symmetric spacetime is a Lorentian 4-dimensional manifold whose isometry group contains a subgroup isomorphic to and whose orbits are 2-spheres. Here I am already confused. How can the orbits of , which are submanifolds of , be 2-spheres? Am I missing some general definition of 2-spheres that does not require being in Euclidean space? Next, how can we rigorously decompose the metric of this spacetime into one of the form I am willing to take for granted that is a Lie group and thus is diffeomorphic to . In particular, the Lie algebra of is isomorphic to that of which is isomorphic to . Because the Lie algebra of the isometry group consists of Killing fields, this means we have 3 Killing Fields s.t. By Frobenius theorem, these vector fields generate  foliation of , and around every point of we can find a coordinate chart s.t. each leaf of our foliation corresponds to slices of constant with, say, . Now I somehow need to find a coordinate transformation that ensures the vector fields and are orthogonal to every leaf of the foliation. To show that the inner products of the coordinate vector fields are independent of their location on each leaf I imagine I have to use the isometry conditions, but I do not know how the coordinate vector fields relate to the isometries themselves. Is there a canonical way to do this?","(M, g) G \text{SO}(3) G M 
g = A(r, t) \text d r ^2 + B(r, t) \text d r \text d t + C(r, t) \text d t^2 + C(r, t) \text d \Omega ^2 \ ? 
 \text{Iso}(M) G \text{SO}(3) G \text{SO}(3) (\Bbb R^3, \times) V_i 
[V_i, V_j] = \epsilon_{ijk} V_k.
 M M (U, x^i) x^i i = 0, 1 \partial_0 \partial_1","['differential-geometry', 'riemannian-geometry', 'foliations']"
96,Computing curvature of the quotient of the tautological connection,Computing curvature of the quotient of the tautological connection,,"I am trying to understand a certain passage in the book ""Geometry of Four-Manifolds"" by Donaldson and Kronheimer (specifically, a computation in section 5.2.3). I am confused on the proof of Proposition 5.2.17, which states: Proposition (5.2.17) Let $\hat{\nabla}$ be the tautological connection on the $SO(3)$ -bundle $\mathfrak g_{\pi_2^*E}$ , and $\nabla$ the quotient of this connection on the quotient bundle $\mathfrak g_{\mathbb{P}}\to \mathscr{B}^*\times X$ . The three components of the curvature of $\nabla$ at a point $([A], x)$ are given by $F(\nabla)(u,v) = F(A)(u,v)$ $F(\nabla)(a,v) = \langle a, v\rangle$ $F(\nabla)(a,b) = - 2 G_A\{a,b\}|_x$ . Here, $u,v\in T_x X$ , $a,b\in \Omega^1(\mathfrak g_E)$ satisfying $d_A^*a=d_A^*b=0$ ; $G_A$ is the Green's operator for the Laplacian $d_A^*d_A$ on $\Omega^0(\mathfrak g_E)$ ; and $\{,\}$ is the natural pairing formed from a metric on $X$ and the Lie bracket on $\operatorname{Lie}(G)$ , $G$ being the gauge group. Here, $\mathscr{B}^*$ is the space of irreducible connections on a bundle $E\to X$ modulo the action of the group of gauge transformations. I am specifically confused about how they apply equation (5.2.16) (which is marked as $(*)$ below) to deduce this curvature, mainly because I do not understand how they figure out what $\Phi$ ""does"" in the case of the qoutient of the tautological connection. So, my question is, How do they determine what $\Phi$ is in order to apply equation $(*)$ below to deduce this Proposition? Here are the relevant details from this passage in the book. Suppose a Lie group $\Gamma$ acts freely and properly on a manifold $\hat{Y}$ . Also assume we have a bundle $\hat{E}\to \hat{Y}$ and an action of $\Gamma$ on $\hat{E}$ that is linear on fibers and that covers the group action on $\hat{Y}$ . Let $Y := \hat{Y}/\Gamma$ and $E:= \hat{E}/\Gamma$ . We now suppose we are given two things: A connection $\hat{\nabla}$ in $\hat{E}$ invariant under $\Gamma$ . A connection $H$ in the $\Gamma$ -bundle $p:\hat{Y}\to Y$ . One then gets a quotient connection $\nabla$ in $E$ from this. Then, in order to compute its curvature, introduce the 1-form $B \in \Omega_{ \hat Y }^1 \otimes \operatorname{End}(\hat{E})$ given by $$ B:= \hat{\nabla} - p^* \nabla.$$ Then, because $B$ vanishes on $H$ -horizontal vectors, we can write $B$ as $\Phi \circ \theta$ , where $\theta$ is the connection 1-form for $H$ and $\Phi: \operatorname{Lie}(\Gamma) \to \operatorname{End}(\hat{E})$ is a linear map. One can then compute that $$(*)\quad F(\nabla)(U,V) = F(\hat{\nabla})(\hat{U},\hat{V}) - \Phi\circ \Theta(U,V)$$ where $U,V\in T_y Y$ and $\hat{U},\hat{V}$ are horizontal lifts to $T\hat{Y}$ . They apply this to the $SO(3)$ -bundle of Lie algebras $g_{\pi_2^*E}$ obtained from the pullback of $E$ along $\pi_2:\mathscr{A}^*\times X \to X$ and $\mathscr A^*$ is the space of irreducible connections on $E$ ; where $\Gamma$ the group of gauge transformations modulo $\pm 1$ ; with $\hat{Y} = \mathscr{A}^*\times X$ ; with $H$ being the connection on $\mathscr{A}^*$ obtained from slice neighborhoods for the action of the gauge transformations; and $\hat{\nabla}$ is the tautological connection on $\pi_2^*(E)$ (or, rather, the induced one on $\mathfrak g_{\pi_2^* E}$ ). They use the results that for $H$ , the connection form $\theta$ and curvature form $\Theta$ are $\theta_A(a) = -G_A d_A^* a$ and $\Theta_A(a,b) = -2G_A{a,b}$ , which I am fine with. What is really bothering me is how they figure what $\Phi$ (or $B$ for that matter) is, since the pullback of the quotient of the tautological connection $p^* \nabla$ gives me a serious headache. Really, any advice or other resources for this calculation would be appreciated. Edit: I have attempted to try and calculate it from basic principles. Let's call the Let's say we are at a point $(A, x)$ of $\mathscr{A}^*\times X$ . The mapping $\gamma:\operatorname{Lie}(G)\to T_\nabla \mathscr{A}^* \times T_x X$ is given by taking a section $\xi \in \Omega^0(\mathfrak{g}_E)$ and sending it to $$\gamma(\xi) = (d_A\xi, 0)\in \Omega^1(\mathfrak{g}_E)\times T_x X = T_\nabla \mathscr{A}^*\times T_xX.$$ The value of $\Phi(\xi)$ at $x$ is the endomorphism on $\mathfrak{g}_{\pi_2^*E}$ determined by $B(\gamma(\xi))$ . Then we proceed to determine how $\hat{\nabla}_{\gamma(\xi)}$ and $(p^*\nabla)_{\gamma(\xi)}$ perform on sections of $\mathfrak{g}_{\pi_2^*E}$ . I think $p^*\nabla$ is easiest to calculate: since a pullback connection is uniquely determined by the general formula $$ (p^*\nabla)_v(p^*s) = p^*(\nabla_{p_*v} s), \quad v\in T\hat{Y}, s:Y\to E, $$ we see that $p^*(\nabla)_{\gamma(\xi)}$ is identically $0$ on all sections because $p_*(\gamma (\xi))=0$ , which is true because $\gamma$ maps into the vertical subspace. However, because $\hat\nabla$ is tautological, it is trivial in the $\mathscr{A}^*$ directions, so I also think $\hat\nabla_{\gamma (\xi)}=0$ . This leads me to think $\Phi$ is identically $0$ , which seems suspect.","I am trying to understand a certain passage in the book ""Geometry of Four-Manifolds"" by Donaldson and Kronheimer (specifically, a computation in section 5.2.3). I am confused on the proof of Proposition 5.2.17, which states: Proposition (5.2.17) Let be the tautological connection on the -bundle , and the quotient of this connection on the quotient bundle . The three components of the curvature of at a point are given by . Here, , satisfying ; is the Green's operator for the Laplacian on ; and is the natural pairing formed from a metric on and the Lie bracket on , being the gauge group. Here, is the space of irreducible connections on a bundle modulo the action of the group of gauge transformations. I am specifically confused about how they apply equation (5.2.16) (which is marked as below) to deduce this curvature, mainly because I do not understand how they figure out what ""does"" in the case of the qoutient of the tautological connection. So, my question is, How do they determine what is in order to apply equation below to deduce this Proposition? Here are the relevant details from this passage in the book. Suppose a Lie group acts freely and properly on a manifold . Also assume we have a bundle and an action of on that is linear on fibers and that covers the group action on . Let and . We now suppose we are given two things: A connection in invariant under . A connection in the -bundle . One then gets a quotient connection in from this. Then, in order to compute its curvature, introduce the 1-form given by Then, because vanishes on -horizontal vectors, we can write as , where is the connection 1-form for and is a linear map. One can then compute that where and are horizontal lifts to . They apply this to the -bundle of Lie algebras obtained from the pullback of along and is the space of irreducible connections on ; where the group of gauge transformations modulo ; with ; with being the connection on obtained from slice neighborhoods for the action of the gauge transformations; and is the tautological connection on (or, rather, the induced one on ). They use the results that for , the connection form and curvature form are and , which I am fine with. What is really bothering me is how they figure what (or for that matter) is, since the pullback of the quotient of the tautological connection gives me a serious headache. Really, any advice or other resources for this calculation would be appreciated. Edit: I have attempted to try and calculate it from basic principles. Let's call the Let's say we are at a point of . The mapping is given by taking a section and sending it to The value of at is the endomorphism on determined by . Then we proceed to determine how and perform on sections of . I think is easiest to calculate: since a pullback connection is uniquely determined by the general formula we see that is identically on all sections because , which is true because maps into the vertical subspace. However, because is tautological, it is trivial in the directions, so I also think . This leads me to think is identically , which seems suspect.","\hat{\nabla} SO(3) \mathfrak g_{\pi_2^*E} \nabla \mathfrak g_{\mathbb{P}}\to \mathscr{B}^*\times X \nabla ([A], x) F(\nabla)(u,v) = F(A)(u,v) F(\nabla)(a,v) = \langle a, v\rangle F(\nabla)(a,b) = - 2 G_A\{a,b\}|_x u,v\in T_x X a,b\in \Omega^1(\mathfrak g_E) d_A^*a=d_A^*b=0 G_A d_A^*d_A \Omega^0(\mathfrak g_E) \{,\} X \operatorname{Lie}(G) G \mathscr{B}^* E\to X (*) \Phi \Phi (*) \Gamma \hat{Y} \hat{E}\to \hat{Y} \Gamma \hat{E} \hat{Y} Y := \hat{Y}/\Gamma E:= \hat{E}/\Gamma \hat{\nabla} \hat{E} \Gamma H \Gamma p:\hat{Y}\to Y \nabla E B \in \Omega_{ \hat Y }^1 \otimes \operatorname{End}(\hat{E})  B:= \hat{\nabla} - p^* \nabla. B H B \Phi \circ \theta \theta H \Phi: \operatorname{Lie}(\Gamma) \to \operatorname{End}(\hat{E}) (*)\quad F(\nabla)(U,V) = F(\hat{\nabla})(\hat{U},\hat{V}) - \Phi\circ \Theta(U,V) U,V\in T_y Y \hat{U},\hat{V} T\hat{Y} SO(3) g_{\pi_2^*E} E \pi_2:\mathscr{A}^*\times X \to X \mathscr A^* E \Gamma \pm 1 \hat{Y} = \mathscr{A}^*\times X H \mathscr{A}^* \hat{\nabla} \pi_2^*(E) \mathfrak g_{\pi_2^* E} H \theta \Theta \theta_A(a) = -G_A d_A^* a \Theta_A(a,b) = -2G_A{a,b} \Phi B p^* \nabla (A, x) \mathscr{A}^*\times X \gamma:\operatorname{Lie}(G)\to T_\nabla \mathscr{A}^* \times T_x X \xi \in \Omega^0(\mathfrak{g}_E) \gamma(\xi) = (d_A\xi, 0)\in \Omega^1(\mathfrak{g}_E)\times T_x X = T_\nabla \mathscr{A}^*\times T_xX. \Phi(\xi) x \mathfrak{g}_{\pi_2^*E} B(\gamma(\xi)) \hat{\nabla}_{\gamma(\xi)} (p^*\nabla)_{\gamma(\xi)} \mathfrak{g}_{\pi_2^*E} p^*\nabla 
(p^*\nabla)_v(p^*s) = p^*(\nabla_{p_*v} s), \quad v\in T\hat{Y}, s:Y\to E,
 p^*(\nabla)_{\gamma(\xi)} 0 p_*(\gamma (\xi))=0 \gamma \hat\nabla \mathscr{A}^* \hat\nabla_{\gamma (\xi)}=0 \Phi 0","['differential-geometry', 'gauge-theory']"
97,Volume form on $S^2$,Volume form on,S^2,"I have some basic understanding problem on this. Any help is appreciated: The volume form of $S^2 \subset R^3$ is given by $$ \omega = x \ dy \land dz-y \ dx \land dz +z \ dx \land dy$$ In polar coordinates this becomes $$ \omega = sin\Theta\ d\Theta \land d\phi$$ A volume form ought to be non-vanishing everywhere on the sphere. But how can this be since at the pole $\Theta=0$ the form seems to vanish identically? Second confusion: A volume form cannot be exact. If it was, by the use of Stokes law, the area of the sphere would be identically to zero which cannot be true. However if one writes,  $$ \omega = sin\Theta\ d\Theta \land d\phi=d(-cos\Theta \land d\phi)\equiv d\Lambda$$ where $\Lambda=-cos\Theta \ d\phi$ $,\omega$ seems closed!?. $\Lambda$ appears single-valued,smooth and everywhere well defined on the sphere. What is wrong with $\Lambda$? How can one see that $\omega$ is not exact without resorting to the argument based on Stokes law. Many thanks!","I have some basic understanding problem on this. Any help is appreciated: The volume form of $S^2 \subset R^3$ is given by $$ \omega = x \ dy \land dz-y \ dx \land dz +z \ dx \land dy$$ In polar coordinates this becomes $$ \omega = sin\Theta\ d\Theta \land d\phi$$ A volume form ought to be non-vanishing everywhere on the sphere. But how can this be since at the pole $\Theta=0$ the form seems to vanish identically? Second confusion: A volume form cannot be exact. If it was, by the use of Stokes law, the area of the sphere would be identically to zero which cannot be true. However if one writes,  $$ \omega = sin\Theta\ d\Theta \land d\phi=d(-cos\Theta \land d\phi)\equiv d\Lambda$$ where $\Lambda=-cos\Theta \ d\phi$ $,\omega$ seems closed!?. $\Lambda$ appears single-valued,smooth and everywhere well defined on the sphere. What is wrong with $\Lambda$? How can one see that $\omega$ is not exact without resorting to the argument based on Stokes law. Many thanks!",,['differential-geometry']
98,Relation between de Rham Cohomology group of Lie group as a manifold and group cohomology of Lie group,Relation between de Rham Cohomology group of Lie group as a manifold and group cohomology of Lie group,,"Is there some relation between De Rham Cohomology group of Lie group as a manifold and group cohomology of Lie group? At first glance, they are two different things. De Rham Cohomology group is defined by differential form on manifold. While group cohomology is used to classify the group extension. My question: 1.For group cohomology $H^n_\sigma(G,A)$, we need group $G$, abelian group $A$ and $\sigma : G\rightarrow Aut(A)$. If I fixed $G$ is some Lie group,  $A=\mathbb{R}$ and $\sigma$ as trivial homomorphism. Is there some relation between group cohomology $H^n_0(G,\mathbb{R})$ and De Rham cohomology $H^{n}_{dR}(G)$?","Is there some relation between De Rham Cohomology group of Lie group as a manifold and group cohomology of Lie group? At first glance, they are two different things. De Rham Cohomology group is defined by differential form on manifold. While group cohomology is used to classify the group extension. My question: 1.For group cohomology $H^n_\sigma(G,A)$, we need group $G$, abelian group $A$ and $\sigma : G\rightarrow Aut(A)$. If I fixed $G$ is some Lie group,  $A=\mathbb{R}$ and $\sigma$ as trivial homomorphism. Is there some relation between group cohomology $H^n_0(G,\mathbb{R})$ and De Rham cohomology $H^{n}_{dR}(G)$?",,"['differential-geometry', 'algebraic-topology', 'group-cohomology']"
99,Commuting Laplacian and Divergence,Commuting Laplacian and Divergence,,"I'm trying to understand why $$\Delta(\nabla f) - \nabla(\Delta f) = (n - 1) \text{Ric}(\nabla f),$$ where I'm working on a Riemannian manifold, $\Delta$ is the Laplace-Beltrami operator, $\nabla$ is the gradient, and $\text{Ric}(\cdot)$ is the linear map on vector fields induced by $$\langle \text{Ric}(X),Y \rangle = \text{Ric}(X,Y),$$ where $\langle \cdot, \cdot \rangle$ is the metric and $\text{Ric}(\cdot,\cdot)$ is the Ricci tensor. Let $\{E_{1},\dots,E_{n}\}$ be a local orthonormal frame on $M$.  Appealing to the definitions, we obtain \begin{align*} \langle \Delta(\nabla f), E_{k} \rangle - \langle \nabla(\Delta f), E_{k} \rangle &= \sum_{i = 1}^{n} \langle \nabla_{E_{i}} \nabla_{E_{i}} \nabla f, E_{k} \rangle - \langle \nabla_{\nabla_{E_{i}} E_{i}} \nabla f, E_{k} \rangle - E_{k}(\langle \nabla_{E_{i}} \nabla f, E_{i} \rangle) \\ 			&= \sum_{i = 1}^{n} E_{i}(\langle \nabla_{E_{i}} \nabla f, E_{k} \rangle) - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle - \langle \nabla_{E_{k}} \nabla f, \nabla_{E_{i}} E_{i} \rangle \\ 			&\quad - \langle \nabla_{E_{k}} \nabla_{E_{i}} \nabla f, E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle \end{align*} Above we used the fact that $\nabla^{2} f$ is symmetric to obtain $\langle \nabla_{\nabla_{E_{i}} E_{i}} \nabla f, E_{k} \rangle = \langle \nabla_{E_{k}} \nabla f, \nabla_{E_{i}} E_{i} \rangle$.  By symmetry, we also find $E_{i}(\nabla_{E_{i}} \nabla f, E_{k} \rangle) = E_{i}(\nabla_{E_{k}} \nabla f, E_{i} \rangle)$.  Thus, \begin{align*} \langle \Delta(\nabla f), E_{k} \rangle - \langle \nabla(\Delta f), E_{k} \rangle &= \sum_{i = 1}^{n} \langle \nabla_{E_{i}} \nabla_{E_{k}} \nabla f, E_{i} \rangle + \langle \nabla_{E_{k}} \nabla f, \nabla_{E_{i}} E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle \\ 		&\quad - \langle \nabla_{E_{k}} \nabla f, \nabla_{E_{i}} E_{i} \rangle - \langle \nabla_{E_{k}} \nabla_{E_{i}} \nabla f, E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle \\ 		&= \sum_{i = 1}^{n} \langle \nabla_{E_{i}} \nabla_{E_{k}} \nabla f, E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle  - \langle \nabla_{E_{k}} \nabla_{E_{i}} \nabla f, E_{i} \rangle \\ 		&\quad - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle  \end{align*} Now I'm confused because there appears to be a sign error.  If the last term were $\langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle$ without the minus sign, then I could combine it with $-\langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle$ to get $$\langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle = \langle \nabla_{E_{i}} \nabla f, [E_{k},E_{i}] \rangle$$ by symmetry of the Levi-Civita connection.  Using symmetry of $\nabla^{2}f$, this yields $$\langle \nabla_{[E_{k},E_{i}]} \nabla f, E_{i} \rangle,$$ which is exactly the term I need to get $\langle R(E_{k},E_{i})\nabla f, E_{i}\rangle$ and then conclude. Nonetheless, if I used a geodesic frame, then I could assume $\nabla_{E_{i}} E_{j} = 0$ at some point $p$ and then the whole computation goes through since the offending terms vanish and the $\nabla_{[E_{k},E_{i}]} \nabla f$ term would also vanish (again, symmetry of Levi-Civita).  So what I have so far works if I use a geodesic frame.  That seems weird: working backwards, this seems to mean $\langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle = - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle$ in the general case, which implies that quantity vanishes, but I can't see why it should. Did I make a sign error above?  If not, how do I complete the computation if I don't want to assume I'm working with a geodesic frame?","I'm trying to understand why $$\Delta(\nabla f) - \nabla(\Delta f) = (n - 1) \text{Ric}(\nabla f),$$ where I'm working on a Riemannian manifold, $\Delta$ is the Laplace-Beltrami operator, $\nabla$ is the gradient, and $\text{Ric}(\cdot)$ is the linear map on vector fields induced by $$\langle \text{Ric}(X),Y \rangle = \text{Ric}(X,Y),$$ where $\langle \cdot, \cdot \rangle$ is the metric and $\text{Ric}(\cdot,\cdot)$ is the Ricci tensor. Let $\{E_{1},\dots,E_{n}\}$ be a local orthonormal frame on $M$.  Appealing to the definitions, we obtain \begin{align*} \langle \Delta(\nabla f), E_{k} \rangle - \langle \nabla(\Delta f), E_{k} \rangle &= \sum_{i = 1}^{n} \langle \nabla_{E_{i}} \nabla_{E_{i}} \nabla f, E_{k} \rangle - \langle \nabla_{\nabla_{E_{i}} E_{i}} \nabla f, E_{k} \rangle - E_{k}(\langle \nabla_{E_{i}} \nabla f, E_{i} \rangle) \\ 			&= \sum_{i = 1}^{n} E_{i}(\langle \nabla_{E_{i}} \nabla f, E_{k} \rangle) - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle - \langle \nabla_{E_{k}} \nabla f, \nabla_{E_{i}} E_{i} \rangle \\ 			&\quad - \langle \nabla_{E_{k}} \nabla_{E_{i}} \nabla f, E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle \end{align*} Above we used the fact that $\nabla^{2} f$ is symmetric to obtain $\langle \nabla_{\nabla_{E_{i}} E_{i}} \nabla f, E_{k} \rangle = \langle \nabla_{E_{k}} \nabla f, \nabla_{E_{i}} E_{i} \rangle$.  By symmetry, we also find $E_{i}(\nabla_{E_{i}} \nabla f, E_{k} \rangle) = E_{i}(\nabla_{E_{k}} \nabla f, E_{i} \rangle)$.  Thus, \begin{align*} \langle \Delta(\nabla f), E_{k} \rangle - \langle \nabla(\Delta f), E_{k} \rangle &= \sum_{i = 1}^{n} \langle \nabla_{E_{i}} \nabla_{E_{k}} \nabla f, E_{i} \rangle + \langle \nabla_{E_{k}} \nabla f, \nabla_{E_{i}} E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle \\ 		&\quad - \langle \nabla_{E_{k}} \nabla f, \nabla_{E_{i}} E_{i} \rangle - \langle \nabla_{E_{k}} \nabla_{E_{i}} \nabla f, E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle \\ 		&= \sum_{i = 1}^{n} \langle \nabla_{E_{i}} \nabla_{E_{k}} \nabla f, E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle  - \langle \nabla_{E_{k}} \nabla_{E_{i}} \nabla f, E_{i} \rangle \\ 		&\quad - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle  \end{align*} Now I'm confused because there appears to be a sign error.  If the last term were $\langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle$ without the minus sign, then I could combine it with $-\langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle$ to get $$\langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{i}} E_{k} \rangle = \langle \nabla_{E_{i}} \nabla f, [E_{k},E_{i}] \rangle$$ by symmetry of the Levi-Civita connection.  Using symmetry of $\nabla^{2}f$, this yields $$\langle \nabla_{[E_{k},E_{i}]} \nabla f, E_{i} \rangle,$$ which is exactly the term I need to get $\langle R(E_{k},E_{i})\nabla f, E_{i}\rangle$ and then conclude. Nonetheless, if I used a geodesic frame, then I could assume $\nabla_{E_{i}} E_{j} = 0$ at some point $p$ and then the whole computation goes through since the offending terms vanish and the $\nabla_{[E_{k},E_{i}]} \nabla f$ term would also vanish (again, symmetry of Levi-Civita).  So what I have so far works if I use a geodesic frame.  That seems weird: working backwards, this seems to mean $\langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle = - \langle \nabla_{E_{i}} \nabla f, \nabla_{E_{k}} E_{i} \rangle$ in the general case, which implies that quantity vanishes, but I can't see why it should. Did I make a sign error above?  If not, how do I complete the computation if I don't want to assume I'm working with a geodesic frame?",,['differential-geometry']
