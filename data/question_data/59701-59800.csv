,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Infinite Geometric Series,Infinite Geometric Series,,"I'm currently stuck on this question: What is the value of c if $\sum_{n=1}^\infty (1 + c)^{-n}$ = 4 and c > 0? This appears to be an infinite geometric series with a = 1 and r = $(1 + c)^{-1}$, so if I plug this all into the sum of infinite geometric series formula $S = \frac{a}{1 - r}$, then I get the following: $4 = \frac{1}{1 - (1 + c)^{-1}}$, which eventually lets me solve c = $\frac{1}{3}$. But this answer isn't right. Can someone help me out? Thanks in advance!","I'm currently stuck on this question: What is the value of c if $\sum_{n=1}^\infty (1 + c)^{-n}$ = 4 and c > 0? This appears to be an infinite geometric series with a = 1 and r = $(1 + c)^{-1}$, so if I plug this all into the sum of infinite geometric series formula $S = \frac{a}{1 - r}$, then I get the following: $4 = \frac{1}{1 - (1 + c)^{-1}}$, which eventually lets me solve c = $\frac{1}{3}$. But this answer isn't right. Can someone help me out? Thanks in advance!",,['sequences-and-series']
1,"If $T(n) = \sum_i T(\lfloor r_i n \rfloor) $ for $n \ge 1$, then $T(n)/n \to 0$","If  for , then",T(n) = \sum_i T(\lfloor r_i n \rfloor)  n \ge 1 T(n)/n \to 0,"Let $(r_i)_{i=1}^m$ be a sequence of positive reals such that $\sum_i r_i < 1$ and let $t$ be a positive real. Consider the sequence $T(n)$ defined by $T(0) = t$, $T(n) = \sum_i T(\lfloor r_i n \rfloor) $ for $n \ge 1$. Show that $T(n) = o(n)$, that is, $\lim_{n \to \infty} \dfrac{T(n)}{n} = 0 $. Note: This is a variation on If $T(n) = un + \sum_i T(\lfloor r_i n \rfloor) $, show that $T(n) = \Theta(n)$ . It is gotten by setting $u=0$ there. I am close to a solution, and hope to have one in a few days. If I find one, I will post it. Note: It is easy to prove that $T(n) = O(n)$. The problem is showing that $T(n)/n \to 0$.","Let $(r_i)_{i=1}^m$ be a sequence of positive reals such that $\sum_i r_i < 1$ and let $t$ be a positive real. Consider the sequence $T(n)$ defined by $T(0) = t$, $T(n) = \sum_i T(\lfloor r_i n \rfloor) $ for $n \ge 1$. Show that $T(n) = o(n)$, that is, $\lim_{n \to \infty} \dfrac{T(n)}{n} = 0 $. Note: This is a variation on If $T(n) = un + \sum_i T(\lfloor r_i n \rfloor) $, show that $T(n) = \Theta(n)$ . It is gotten by setting $u=0$ there. I am close to a solution, and hope to have one in a few days. If I find one, I will post it. Note: It is easy to prove that $T(n) = O(n)$. The problem is showing that $T(n)/n \to 0$.",,"['sequences-and-series', 'recurrence-relations']"
2,Prove $\sum_n^{\infty} \prod_{k=0}^n \dfrac{1}{x+k} = e \sum_ n^{\infty} \dfrac{(-1)^n}{(x+n)n!}$,Prove,\sum_n^{\infty} \prod_{k=0}^n \dfrac{1}{x+k} = e \sum_ n^{\infty} \dfrac{(-1)^n}{(x+n)n!},Let $$f_n(x) = \prod_{k=0}^n \dfrac{1}{x+k}.$$ Show that $$\sum_{n=0}^{\infty} f_n(x) = e \sum_ {n=0}^{\infty} \dfrac{(-1)^n}{(x+n)n!}.$$,Let $$f_n(x) = \prod_{k=0}^n \dfrac{1}{x+k}.$$ Show that $$\sum_{n=0}^{\infty} f_n(x) = e \sum_ {n=0}^{\infty} \dfrac{(-1)^n}{(x+n)n!}.$$,,"['calculus', 'real-analysis', 'sequences-and-series']"
3,Extending Cauchy's Condensation Test,Extending Cauchy's Condensation Test,,"The Cauchy test states $\sum a_n$ converges $\iff$ $\sum 2^k a_{2^k}$ converges. In Rudin 3ed, the (excerpt) proof is outlined as follows Can I modify (8) so we get For $n < 3^k$ $$s_n = (a_1 + a_2 + a_3) + (a_4  + \dots + a_9) \leq 3a_1 + 3^2a_3 + \dots + 3^{k+1} a_{3^k} =t_k$$ For $n > 3^k$ $$s_n = (a_1 + a_2) + (a_3 + a_4 + \dots + a_{11} ) + a_{12} + \dots \geq a_1 + 2a_1 + 3^2 a_3 + \dots = t_k$$ So that we may test $\sum 3^{k+1}a_{3^k}$ instead?","The Cauchy test states $\sum a_n$ converges $\iff$ $\sum 2^k a_{2^k}$ converges. In Rudin 3ed, the (excerpt) proof is outlined as follows Can I modify (8) so we get For $n < 3^k$ $$s_n = (a_1 + a_2 + a_3) + (a_4  + \dots + a_9) \leq 3a_1 + 3^2a_3 + \dots + 3^{k+1} a_{3^k} =t_k$$ For $n > 3^k$ $$s_n = (a_1 + a_2) + (a_3 + a_4 + \dots + a_{11} ) + a_{12} + \dots \geq a_1 + 2a_1 + 3^2 a_3 + \dots = t_k$$ So that we may test $\sum 3^{k+1}a_{3^k}$ instead?",,"['calculus', 'sequences-and-series']"
4,"Is $n!a$, $a$ irrational, equidistributed mod 1?","Is ,  irrational, equidistributed mod 1?",n!a a,"I have been trying without success to prove a weaker result, that the fractional part of $n!a$, where $a$ is irrational, does not tend to $1/2$ as $n$ tends to infinity. My objective was to show that for each real $x$ $(n-1)!\cos(n!x)$ (the derivative of $n^{-1}\sin(n!x)$) does not converge as $n\to\infty$.","I have been trying without success to prove a weaker result, that the fractional part of $n!a$, where $a$ is irrational, does not tend to $1/2$ as $n$ tends to infinity. My objective was to show that for each real $x$ $(n-1)!\cos(n!x)$ (the derivative of $n^{-1}\sin(n!x)$) does not converge as $n\to\infty$.",,"['real-analysis', 'sequences-and-series']"
5,These two sequences have the same limit,These two sequences have the same limit,,"Let $a_1$ and $b_1$ be any two positive numbers, and define $\{ a_n\}$ and $\{ b_n\}$ by $$a_n = \frac{2a_{n-1}b_{n-1}}{a_{n-1}+b_{n-1}},$$ $$b_n = \sqrt{a_{n-1}b_{n-1} }.$$ Prove that the sequences $\{a_n\}$ and $\{b_n\}$ converge and have the same limit. Source: Problem Solving Through Problems by Loren C. Larson. Hint: Use the squeeze principle.","Let $a_1$ and $b_1$ be any two positive numbers, and define $\{ a_n\}$ and $\{ b_n\}$ by $$a_n = \frac{2a_{n-1}b_{n-1}}{a_{n-1}+b_{n-1}},$$ $$b_n = \sqrt{a_{n-1}b_{n-1} }.$$ Prove that the sequences $\{a_n\}$ and $\{b_n\}$ converge and have the same limit. Source: Problem Solving Through Problems by Loren C. Larson. Hint: Use the squeeze principle.",,"['real-analysis', 'sequences-and-series', 'contest-math']"
6,Do sequences in $\ell^p$ belong to some $\ell^q$ for $q<p$?,Do sequences in  belong to some  for ?,\ell^p \ell^q q<p,"For every $p\in [1,\infty)$, consider the set $\ell^p$ of real sequences $x=(x_n)=(x_1,x_2,\ldots)$ such that $\sum_{n=1}^\infty |x_n|^p<\infty$. This is a Banach space with the norm $\Vert x\Vert_p=(\sum|x_n|^p)^{1/p}$. I have the following problem: Is it true that $\ell^p=\bigcup_{1\leq q<p}\ell^q$ for $p>1$? I don't think it is true, but I'm having problems to show this. Clearly, the statement is true for some $p>1$ iff it is true for every $p>1$. I'm trying to find a sequence $(a_n)$ such that $\sum |a_n|^s$ converges iff $s\geq 1$. I've tried many sequences (such as $(n^{1+1/n})$, involving $\log$, etc...), but none of them worked.","For every $p\in [1,\infty)$, consider the set $\ell^p$ of real sequences $x=(x_n)=(x_1,x_2,\ldots)$ such that $\sum_{n=1}^\infty |x_n|^p<\infty$. This is a Banach space with the norm $\Vert x\Vert_p=(\sum|x_n|^p)^{1/p}$. I have the following problem: Is it true that $\ell^p=\bigcup_{1\leq q<p}\ell^q$ for $p>1$? I don't think it is true, but I'm having problems to show this. Clearly, the statement is true for some $p>1$ iff it is true for every $p>1$. I'm trying to find a sequence $(a_n)$ such that $\sum |a_n|^s$ converges iff $s\geq 1$. I've tried many sequences (such as $(n^{1+1/n})$, involving $\log$, etc...), but none of them worked.",,"['real-analysis', 'sequences-and-series', 'functional-analysis', 'divergent-series']"
7,Proving that $\sum (-1)^{n+1} n^{-z}$ defines an analytic function in $Re z>0$,Proving that  defines an analytic function in,\sum (-1)^{n+1} n^{-z} Re z>0,"I want to show that the series $\sum_{n=1}^\infty (-1)^{n+1} n^{-z}$ converges to an analytic function for $\Re z>0$. For $\Re z>1$ the terms are dominated by $n^{-x}$ so that we have absolute and uniform convergence on compact sets, and by Weierstrass' theorem the sum is analytic there. For $\Re z \leq 1$ however I can't show absolute convergence. I tried splitting into real and imaginary parts: $$\sum_{n=1}^\infty (-1)^{n+1} n^{-z}=\sum_{n=1}^\infty (-1)^{n+1} n^{-x}\cos(-y \ln n)+i\sum_{n=1}^\infty (-1)^{n+1} n^{-x}\sin(-y \ln n),$$ and showing convergence for both using Leibniz's test (or even the more general Dirichlet's test) without success. I'd love to have any hints about how to do this right.","I want to show that the series $\sum_{n=1}^\infty (-1)^{n+1} n^{-z}$ converges to an analytic function for $\Re z>0$. For $\Re z>1$ the terms are dominated by $n^{-x}$ so that we have absolute and uniform convergence on compact sets, and by Weierstrass' theorem the sum is analytic there. For $\Re z \leq 1$ however I can't show absolute convergence. I tried splitting into real and imaginary parts: $$\sum_{n=1}^\infty (-1)^{n+1} n^{-z}=\sum_{n=1}^\infty (-1)^{n+1} n^{-x}\cos(-y \ln n)+i\sum_{n=1}^\infty (-1)^{n+1} n^{-x}\sin(-y \ln n),$$ and showing convergence for both using Leibniz's test (or even the more general Dirichlet's test) without success. I'd love to have any hints about how to do this right.",,"['sequences-and-series', 'complex-analysis', 'convergence-divergence', 'riemann-zeta']"
8,Pointwise convergence domain of function series,Pointwise convergence domain of function series,,"I'm stuck at finding pointwise convergence domain of the following function series $$\sum_{n=1}^\infty \frac{\sqrt[3]{(n+1)}-\sqrt[3]{n}}{n^x+1}$$ I tried to use d'Alembert and Weierstrass tests, but it seems to me they don't work here.","I'm stuck at finding pointwise convergence domain of the following function series $$\sum_{n=1}^\infty \frac{\sqrt[3]{(n+1)}-\sqrt[3]{n}}{n^x+1}$$ I tried to use d'Alembert and Weierstrass tests, but it seems to me they don't work here.",,"['sequences-and-series', 'convergence-divergence', 'zeta-functions']"
9,Equality involving $\sum_n \sin(\gamma_n \log x)/\gamma_n$,Equality involving,\sum_n \sin(\gamma_n \log x)/\gamma_n,"This is I think an algebra confusion about an equality of Littlewood, $$\frac{\psi(x) - x}{\sqrt{x}} = -2\sum_{1}^{\infty}\frac{\sin( \gamma_n\log x)}{\gamma_n} + O(1).\hspace{20mm}(1)$$ He refers the reader to ""equivalent formulas"" in Landau, and for this one the equivalent formula is the explicit formula, $\psi(x) = x - \frac{1}{2}\log(1 - 1/x^2)-\log 2\pi -\sum\frac{x^\rho}{\rho}.\hspace{20mm}(2)$ I infer that $\sum\frac{x^{\rho}}{\rho} \sim 2\sqrt{x}\sum\frac{\sin\gamma_n\log x}{\gamma_n}\hspace{40mm}(3)$ Now if we assume RH we can show that (edit: for the real part of $\sum \frac{x^{\rho}}{\rho}$) $Re\left(\sum \frac{x^{\rho}}{\rho}\right) = \sqrt{x}\sum \frac{\cos(\gamma_n \log x) +2\gamma_n\sin(\gamma_n\log x) }{1/4+\gamma_n^2}.\hspace{35mm}(4)$ Littlewood says he is assuming RH, so I would think (for the real parts) $$2\sum_{2}^{\infty}\frac{\sin( \gamma_n\log x)}{\gamma_n} = \sum \frac{\cos(\gamma_n \log x) +2\gamma_n\sin(\gamma_n\log x) }{1/4+\gamma_n^2}\hspace{20mm}(5)$$ So (5) is a check on my inferences and I haven't been able to make the algebra work. I think (3) is perhaps wrong but then I don't know what equivalence  Littlewood meant to suggest. Any help with inferences and/or algebra appreciated. Thank you.","This is I think an algebra confusion about an equality of Littlewood, $$\frac{\psi(x) - x}{\sqrt{x}} = -2\sum_{1}^{\infty}\frac{\sin( \gamma_n\log x)}{\gamma_n} + O(1).\hspace{20mm}(1)$$ He refers the reader to ""equivalent formulas"" in Landau, and for this one the equivalent formula is the explicit formula, $\psi(x) = x - \frac{1}{2}\log(1 - 1/x^2)-\log 2\pi -\sum\frac{x^\rho}{\rho}.\hspace{20mm}(2)$ I infer that $\sum\frac{x^{\rho}}{\rho} \sim 2\sqrt{x}\sum\frac{\sin\gamma_n\log x}{\gamma_n}\hspace{40mm}(3)$ Now if we assume RH we can show that (edit: for the real part of $\sum \frac{x^{\rho}}{\rho}$) $Re\left(\sum \frac{x^{\rho}}{\rho}\right) = \sqrt{x}\sum \frac{\cos(\gamma_n \log x) +2\gamma_n\sin(\gamma_n\log x) }{1/4+\gamma_n^2}.\hspace{35mm}(4)$ Littlewood says he is assuming RH, so I would think (for the real parts) $$2\sum_{2}^{\infty}\frac{\sin( \gamma_n\log x)}{\gamma_n} = \sum \frac{\cos(\gamma_n \log x) +2\gamma_n\sin(\gamma_n\log x) }{1/4+\gamma_n^2}\hspace{20mm}(5)$$ So (5) is a check on my inferences and I haven't been able to make the algebra work. I think (3) is perhaps wrong but then I don't know what equivalence  Littlewood meant to suggest. Any help with inferences and/or algebra appreciated. Thank you.",,"['sequences-and-series', 'complex-analysis', 'number-theory']"
10,Deriving the series representation of the digamma function from the functional equation,Deriving the series representation of the digamma function from the functional equation,,"By repeatedly using the functional equation $ \displaystyle\psi(z+1) = \frac{1}{z} + \psi(z)$, I get that $$ \psi(z) = \psi(z+n)  - \frac{1}{z+n-1} - \ldots - \frac{1}{z+1} - \frac{1}{z}$$ or $$\psi(z+1) = \psi(z+n+1) - \frac{1}{z+n} - \ldots - \frac{1}{z+2} - \frac{1}{z+1} . $$ Is it possible to derive the series representation $ \displaystyle \psi(z+1) = - \gamma - \sum_{n=1}^{\infty} \Big( \frac{1}{z+n} - \frac{1}{n} \Big)$ from that?","By repeatedly using the functional equation $ \displaystyle\psi(z+1) = \frac{1}{z} + \psi(z)$, I get that $$ \psi(z) = \psi(z+n)  - \frac{1}{z+n-1} - \ldots - \frac{1}{z+1} - \frac{1}{z}$$ or $$\psi(z+1) = \psi(z+n+1) - \frac{1}{z+n} - \ldots - \frac{1}{z+2} - \frac{1}{z+1} . $$ Is it possible to derive the series representation $ \displaystyle \psi(z+1) = - \gamma - \sum_{n=1}^{\infty} \Big( \frac{1}{z+n} - \frac{1}{n} \Big)$ from that?",,"['sequences-and-series', 'functional-equations', 'gamma-function']"
11,A problem on continuity of a function on irrationals for $f(x) = \sum_{r_n \leq x} 1/n^2$ [duplicate],A problem on continuity of a function on irrationals for  [duplicate],f(x) = \sum_{r_n \leq x} 1/n^2,"This question already has an answer here : Real Analysis Question: continuity of $f(x) = \sum_{q_n<x} 1/n^2$ (1 answer) Closed 10 years ago . Let $\langle r_n\rangle$ be an enumeration of the set $\mathbb Q$ of rational numbers such that $r_n \neq r_m\,$ if $\,n\neq m.$ $$\text{Define}\; f: \mathbb R \to \mathbb R\;\text{by}\;\displaystyle f(x) = \sum_{r_n \leq x} 1/n^{2},\;x\in \mathbb R.$$   Prove that $f$ is continuous at each point of $\mathbb Q^c$ and discontinuous at each point of $\mathbb Q$. I find it difficult to prove especially the continuity on irrationals, I proved the discontinuity on a rational number in the following way is it correct? Let $ c \in \Bbb Q $ then $ c=r_n $ for some $n \in \Bbb N  $ and Let $ \epsilon_0 = 1/n^{2} $ Let $\delta > 0 $ be arbitrary and let $ x \in (c-\delta. c+\delta)$ such that $x<c $ Then $|f(x)-f(c)|>1/n^{2}=\epsilon_0 $ How do prove that it is continuous on irrationals?","This question already has an answer here : Real Analysis Question: continuity of $f(x) = \sum_{q_n<x} 1/n^2$ (1 answer) Closed 10 years ago . Let $\langle r_n\rangle$ be an enumeration of the set $\mathbb Q$ of rational numbers such that $r_n \neq r_m\,$ if $\,n\neq m.$ $$\text{Define}\; f: \mathbb R \to \mathbb R\;\text{by}\;\displaystyle f(x) = \sum_{r_n \leq x} 1/n^{2},\;x\in \mathbb R.$$   Prove that $f$ is continuous at each point of $\mathbb Q^c$ and discontinuous at each point of $\mathbb Q$. I find it difficult to prove especially the continuity on irrationals, I proved the discontinuity on a rational number in the following way is it correct? Let $ c \in \Bbb Q $ then $ c=r_n $ for some $n \in \Bbb N  $ and Let $ \epsilon_0 = 1/n^{2} $ Let $\delta > 0 $ be arbitrary and let $ x \in (c-\delta. c+\delta)$ such that $x<c $ Then $|f(x)-f(c)|>1/n^{2}=\epsilon_0 $ How do prove that it is continuous on irrationals?",,"['real-analysis', 'sequences-and-series']"
12,Problems using Euler-Maclaurin for $\sum e^{-2 \pi z a^2}$,Problems using Euler-Maclaurin for,\sum e^{-2 \pi z a^2},"I'm trying to evaluate $\sum_{a=-\infty}^{\infty} e^{-2 \pi z a^2}$ using Euler-Maclaurin, but I get $\frac{1}{\sqrt{2z}}$. The only alternative I have is to calculate the remainder term directly for a small level of approximation, but I don't want to do this if there's a simple mistake I'm making and fixing it would let me avoid doing so, or if for some reason Euler-Maclaurin doesn't work at all. SUMMARY: By Euler-Maclaurin, we have: $\sum_{a=-\infty}^{\infty}e^{-ca^2}-\int_{-\infty}^{\infty} e^{-ca^2} da = \sum_{k=2}^{\infty} \frac{b_k}{k!}(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty}$, where $b_k=B_k(0)$ are the Bernoulli numbers. Implicitly, the remainder term (due to the large factorial) and the halved endpoints of the sum (due to $e^{-ca^2}$ vanishing in the infinite limits) vanish. First, observe $\frac{d^n}{da^n}e^{-c a^2}$ is of the form $e^{-c a^2}p(a)$ for a polynomial $p$. (1) Secondly, observe that $lim_{a \rightarrow \infty} \frac{p(a)}{e^{c a^2}} = 0$ for any polynomial $p$ and constant $c \gt 0$. (2) Thirdly, observe that $e^{-ca^2}$ is even, and hence its odd derivatives (the derivatives taken for even $k$) are odd, and its even derivatives (odd $k$) are even. The latter implies that for odd $k$, $(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty}$ vanishes, and for even k, $(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty} = 2 \lim_{a \rightarrow \infty} (e^{-cx^2})^{(k-1)'}(a) = 2 \lim_{a \rightarrow \infty} e^{-ca^2}p(a) = 0.$ Therefore all terms of the series vanish, implying $\sum_{n=-\infty}^{\infty}e^{-cx^2} = \int_{-\infty}^{\infty} e^{-cx^2} da = \frac{\sqrt{\pi}}{\sqrt{c}}$, and in this case $\frac{\sqrt{\pi}}{\sqrt{2 \pi z}} = \frac{1}{\sqrt{2z}}.$ DETAILS: (1) follows by induction from $\frac{d}{da}e^{-ca^2}p(a) = e^{-ca^2}(\frac{d}{da}p(a)-2ca\ p(a)),$ which is of the form $e^{-ca^2}p(a)$. Proof of (2): $\frac{\frac{d}{dx}a^n}{\frac{d}{dx}e^{c a^2}} = \frac{a^{n-1}}{2cae^{c a^2}} = \frac{a^{n-2}}{2ce^{c a^2}}, \implies \frac{\frac{d^m}{dx^m}a^n}{\frac{d^m}{dx^m}e^{c a^2}} = \frac{a^{n-2m}}{(2c)^m e^{ca}}, \implies lim_{a \rightarrow \infty} \frac{a^n}{e^{c a^2}} = 0 \implies lim_{a \rightarrow \infty} \frac{p(a)}{e^{c a^2}} = 0$ I have also derived an explicit formula for the derivatives from Faà di Bruno's formula together with $\frac{d^n}{dx^n}f(cx)=c^nf^{(n)}(cx)$, which yields a polynomial multiple of $e^{-ca^2}$, which by (2) vanishes in the limit, and is again even for even derivatives and odd for odd ones.","I'm trying to evaluate $\sum_{a=-\infty}^{\infty} e^{-2 \pi z a^2}$ using Euler-Maclaurin, but I get $\frac{1}{\sqrt{2z}}$. The only alternative I have is to calculate the remainder term directly for a small level of approximation, but I don't want to do this if there's a simple mistake I'm making and fixing it would let me avoid doing so, or if for some reason Euler-Maclaurin doesn't work at all. SUMMARY: By Euler-Maclaurin, we have: $\sum_{a=-\infty}^{\infty}e^{-ca^2}-\int_{-\infty}^{\infty} e^{-ca^2} da = \sum_{k=2}^{\infty} \frac{b_k}{k!}(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty}$, where $b_k=B_k(0)$ are the Bernoulli numbers. Implicitly, the remainder term (due to the large factorial) and the halved endpoints of the sum (due to $e^{-ca^2}$ vanishing in the infinite limits) vanish. First, observe $\frac{d^n}{da^n}e^{-c a^2}$ is of the form $e^{-c a^2}p(a)$ for a polynomial $p$. (1) Secondly, observe that $lim_{a \rightarrow \infty} \frac{p(a)}{e^{c a^2}} = 0$ for any polynomial $p$ and constant $c \gt 0$. (2) Thirdly, observe that $e^{-ca^2}$ is even, and hence its odd derivatives (the derivatives taken for even $k$) are odd, and its even derivatives (odd $k$) are even. The latter implies that for odd $k$, $(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty}$ vanishes, and for even k, $(e^{-cx^2})^{(k-1)'}\vert_{-\infty}^{\infty} = 2 \lim_{a \rightarrow \infty} (e^{-cx^2})^{(k-1)'}(a) = 2 \lim_{a \rightarrow \infty} e^{-ca^2}p(a) = 0.$ Therefore all terms of the series vanish, implying $\sum_{n=-\infty}^{\infty}e^{-cx^2} = \int_{-\infty}^{\infty} e^{-cx^2} da = \frac{\sqrt{\pi}}{\sqrt{c}}$, and in this case $\frac{\sqrt{\pi}}{\sqrt{2 \pi z}} = \frac{1}{\sqrt{2z}}.$ DETAILS: (1) follows by induction from $\frac{d}{da}e^{-ca^2}p(a) = e^{-ca^2}(\frac{d}{da}p(a)-2ca\ p(a)),$ which is of the form $e^{-ca^2}p(a)$. Proof of (2): $\frac{\frac{d}{dx}a^n}{\frac{d}{dx}e^{c a^2}} = \frac{a^{n-1}}{2cae^{c a^2}} = \frac{a^{n-2}}{2ce^{c a^2}}, \implies \frac{\frac{d^m}{dx^m}a^n}{\frac{d^m}{dx^m}e^{c a^2}} = \frac{a^{n-2m}}{(2c)^m e^{ca}}, \implies lim_{a \rightarrow \infty} \frac{a^n}{e^{c a^2}} = 0 \implies lim_{a \rightarrow \infty} \frac{p(a)}{e^{c a^2}} = 0$ I have also derived an explicit formula for the derivatives from Faà di Bruno's formula together with $\frac{d^n}{dx^n}f(cx)=c^nf^{(n)}(cx)$, which yields a polynomial multiple of $e^{-ca^2}$, which by (2) vanishes in the limit, and is again even for even derivatives and odd for odd ones.",,"['sequences-and-series', 'modular-forms', 'euler-maclaurin']"
13,Upper bound on the partial sum of exponential series,Upper bound on the partial sum of exponential series,,"How can I upper-bound the following function: $$f(n;a)=\sum_{k=0}^{n-1}\frac{(n-a\sqrt{n})^k}{k!}$$ where $0<a<\sqrt{n}$ is a constant. Since it's a partial sum of exponential series, a trivial upper bound is $e^{n-a\sqrt{n}}$.  However, as in this question , the partial sum does not reach that bound because the series gets cut off just as the terms get large. The answer to the aforementioned question uses the Taylor series with the remainder to derive an approximation. However, I am having trouble writing down the remainder function $R_n(n-a\sqrt{n})=\int_0^{n-a\sqrt{n}}\frac{(n-a\sqrt{n}-t)^n}{n!}f^{n+1}(t)dt$, since $f^{n+1}(t)=\left.\frac{\partial^{n+1}}{\partial x^n}e^{x-a\sqrt{x}}\right|_{t=x}$ is a mess. Does anyone have any ideas? ADDENDUM This post has the following bound: $$f(n;a)\leq e^{n-a\sqrt{n}}-\frac{(n-a\sqrt{n})^n}{n!}$$ However, as the original poster says in his last comment, this bound is too lose, and I agree -- the improvement from the trivial bound seems to be the subtraction of at most a constant, per application of Stirling's approximation).  Is there anything better?","How can I upper-bound the following function: $$f(n;a)=\sum_{k=0}^{n-1}\frac{(n-a\sqrt{n})^k}{k!}$$ where $0<a<\sqrt{n}$ is a constant. Since it's a partial sum of exponential series, a trivial upper bound is $e^{n-a\sqrt{n}}$.  However, as in this question , the partial sum does not reach that bound because the series gets cut off just as the terms get large. The answer to the aforementioned question uses the Taylor series with the remainder to derive an approximation. However, I am having trouble writing down the remainder function $R_n(n-a\sqrt{n})=\int_0^{n-a\sqrt{n}}\frac{(n-a\sqrt{n}-t)^n}{n!}f^{n+1}(t)dt$, since $f^{n+1}(t)=\left.\frac{\partial^{n+1}}{\partial x^n}e^{x-a\sqrt{x}}\right|_{t=x}$ is a mess. Does anyone have any ideas? ADDENDUM This post has the following bound: $$f(n;a)\leq e^{n-a\sqrt{n}}-\frac{(n-a\sqrt{n})^n}{n!}$$ However, as the original poster says in his last comment, this bound is too lose, and I agree -- the improvement from the trivial bound seems to be the subtraction of at most a constant, per application of Stirling's approximation).  Is there anything better?",,"['real-analysis', 'sequences-and-series', 'taylor-expansion']"
14,Proving $\ell_\infty$ is complete,Proving  is complete,\ell_\infty,"I start by taking a Cauchy sequence $(a_i)$ in $\ell_\infty$. I denote the terms of $(a_i)$ as $f_1, f_2, f_3, \dots$ and so on. For each $x \in \mathbb{N}$, the sequence $(f_1(x), f_2(x), f_3(x), \dots)$ converges. I define the sequence $L$ as $L(x) = \displaystyle \lim_{n \to \infty} f_n (x)$. I'm having trouble showing $L$ is bounded, but I have what I believe is the first step to an argument. Since $(a_i)$ is Cauchy, it is bounded, so $d(f_n, f_m) \leq S$ for all naturals $m$ and $n$. (Where $d$ is the metric in $\ell_\infty$). So let $x, n \in \mathbb{N}$. Then $|L(x)| \leq |L(x) - f_n(x)| + |f_n(x)| \leq |f_m(x) - f_n(x)| + |f_n(x)| \leq d(f_m,f_n) + \text{sup} f_n \leq S + $sup $f_n$. So $S + $sup $f_n$ bounds $\{|L(x)| | x \in \mathbb{N} \}$, implying $L$ is a bounded sequence. My issue is choosing some $m \in \mathbb{N}$ such that $|L(x) - f_n(x)| \leq |f_m (x) - f_n(x)|$. Does such an $m$ always exist regardless of the choice of $x$ and $m$?","I start by taking a Cauchy sequence $(a_i)$ in $\ell_\infty$. I denote the terms of $(a_i)$ as $f_1, f_2, f_3, \dots$ and so on. For each $x \in \mathbb{N}$, the sequence $(f_1(x), f_2(x), f_3(x), \dots)$ converges. I define the sequence $L$ as $L(x) = \displaystyle \lim_{n \to \infty} f_n (x)$. I'm having trouble showing $L$ is bounded, but I have what I believe is the first step to an argument. Since $(a_i)$ is Cauchy, it is bounded, so $d(f_n, f_m) \leq S$ for all naturals $m$ and $n$. (Where $d$ is the metric in $\ell_\infty$). So let $x, n \in \mathbb{N}$. Then $|L(x)| \leq |L(x) - f_n(x)| + |f_n(x)| \leq |f_m(x) - f_n(x)| + |f_n(x)| \leq d(f_m,f_n) + \text{sup} f_n \leq S + $sup $f_n$. So $S + $sup $f_n$ bounds $\{|L(x)| | x \in \mathbb{N} \}$, implying $L$ is a bounded sequence. My issue is choosing some $m \in \mathbb{N}$ such that $|L(x) - f_n(x)| \leq |f_m (x) - f_n(x)|$. Does such an $m$ always exist regardless of the choice of $x$ and $m$?",,"['sequences-and-series', 'functional-analysis', 'metric-spaces', 'banach-spaces', 'normed-spaces']"
15,The closed form of $\sum_{k=1}^{\infty}\left(\frac{2}{3}\right)^{k^2}\frac{3^k}{2^k-3^k}$,The closed form of,\sum_{k=1}^{\infty}\left(\frac{2}{3}\right)^{k^2}\frac{3^k}{2^k-3^k},Are you kind to show me the way? I want to find its closed form. $$\sum_{k=1}^{\infty}\left(\frac{2}{3}\right)^{k^2}\frac{3^k}{2^k-3^k}$$,Are you kind to show me the way? I want to find its closed form. $$\sum_{k=1}^{\infty}\left(\frac{2}{3}\right)^{k^2}\frac{3^k}{2^k-3^k}$$,,['sequences-and-series']
16,$a_{[n/1]}+a_{[n/2]}+...+a_{[n/n]}=1$,,a_{[n/1]}+a_{[n/2]}+...+a_{[n/n]}=1,"The sequence $a_n$ satisfy  $$a_{[n/1]}+a_{[n/2]}+...+a_{[n/n]}=1,$$ for all $n \in \Bbb N$. (the subscript $[n/k]$ is the integer part of $n/k$) $Proof:$for any $k>0$,$$\lim_{n \rightarrow \infty} \frac{a_n}{n^{1/2+k}} = 0$$ Thanks!","The sequence $a_n$ satisfy  $$a_{[n/1]}+a_{[n/2]}+...+a_{[n/n]}=1,$$ for all $n \in \Bbb N$. (the subscript $[n/k]$ is the integer part of $n/k$) $Proof:$for any $k>0$,$$\lim_{n \rightarrow \infty} \frac{a_n}{n^{1/2+k}} = 0$$ Thanks!",,"['sequences-and-series', 'limits', 'analytic-number-theory']"
17,Reducing a power series to a rational function,Reducing a power series to a rational function,,I have the series $$\sum_{n=0}^\infty (-1)^n 2n x^{(2n -1)}$$ It turns out that this series is equal to the function $$\frac{-2x}{(1+x^2)^2}$$ Is there a general method that would demonstrate this fact beforehand? I'm looking for an algorithm that expresses a power series as a rational function whenever the power series converges to a rational function.,I have the series $$\sum_{n=0}^\infty (-1)^n 2n x^{(2n -1)}$$ It turns out that this series is equal to the function $$\frac{-2x}{(1+x^2)^2}$$ Is there a general method that would demonstrate this fact beforehand? I'm looking for an algorithm that expresses a power series as a rational function whenever the power series converges to a rational function.,,"['real-analysis', 'sequences-and-series']"
18,Moore–Smith convergence; Universal nets,Moore–Smith convergence; Universal nets,,"I am looking at John Kelley's General Topology . This is exercise J  from chapter $2$. I seem to be having trouble with problems c) and d). c) Prove the following Lemma: If $S$ is a net in $X$, then there   exists a family $C$ of subsets of $X$ such that: 1) $S$ falls often in each element of $C$. 2) The intersection of any two elements of $C$ stays in $C$. 3) $(\forall A\subset X)(A\in C \lor X\setminus A\in C)$ HINT: Show that if the family C is maximal regarding the first two   properties, then the third one holds. (I believe maximal means maximal   regarding set theoretic inclusion.) d) Prove that every net has a universal subnet. A side question is why if $f:X \to Y$ and $S$ is a universal net in X then $f\circ S$ is a universal net in $Y$. Some may deem it trivial but I could not quite get convinced. p.s. I apologize for any confusion of terminology as I am translating my Bulgarian copy of the textbook, and I don't have any mathematical dictionaries. Corrections are welcome. Edit: The book advices to use theorem 2.5 to prove d). Lemma 2.5: Let $S$ be a net and $A$ a family of sets such that the intersection of any two elements of $A$ contains and elements of $A$, and $S$ is often in each element of $A$. Then there is a subnet of $S$ that is almost completely in each element of $A$.","I am looking at John Kelley's General Topology . This is exercise J  from chapter $2$. I seem to be having trouble with problems c) and d). c) Prove the following Lemma: If $S$ is a net in $X$, then there   exists a family $C$ of subsets of $X$ such that: 1) $S$ falls often in each element of $C$. 2) The intersection of any two elements of $C$ stays in $C$. 3) $(\forall A\subset X)(A\in C \lor X\setminus A\in C)$ HINT: Show that if the family C is maximal regarding the first two   properties, then the third one holds. (I believe maximal means maximal   regarding set theoretic inclusion.) d) Prove that every net has a universal subnet. A side question is why if $f:X \to Y$ and $S$ is a universal net in X then $f\circ S$ is a universal net in $Y$. Some may deem it trivial but I could not quite get convinced. p.s. I apologize for any confusion of terminology as I am translating my Bulgarian copy of the textbook, and I don't have any mathematical dictionaries. Corrections are welcome. Edit: The book advices to use theorem 2.5 to prove d). Lemma 2.5: Let $S$ be a net and $A$ a family of sets such that the intersection of any two elements of $A$ contains and elements of $A$, and $S$ is often in each element of $A$. Then there is a subnet of $S$ that is almost completely in each element of $A$.",,"['general-topology', 'sequences-and-series', 'convergence-divergence', 'nets']"
19,"Please, help me to find where is a mistake in the solutions of the equation.","Please, help me to find where is a mistake in the solutions of the equation.",,"I have this equation and I will be very thankful to anyone who can provide me any help with the one discrepancy in my solution and the solution from the self-learning website: $$ \frac{1+\tan(x) + \tan^2(x) + ... + \tan^n(x) + ...}{1-\tan(x) + \tan^2(x) - ... +(-1)^n\tan^n(x) ...}= 1+\sin(2x) $$ My solution I solved it in not too graceful way. First I found the roots for this equation: $$ \require{cancel} \begin{align} &\boxed{\frac{1+\tan(x)}{1-\tan(x)}= 1+\sin(2x)} \\ \\ &\frac{(1+\tan(x))\cancel{(1-\tan(x))}}{\cancel{1-\tan(x)}}= (1+\sin(2x))(1-\tan(x))\\ \\ &\cancel{1}+\tan(x)=\cancel{1} - \tan(x) + \sin(2x) - \sin(2x)\tan(x) \\ &\frac{\sin(2x)}{\tan(x)} - \frac{\sin(2x)\cancel{\tan(x)}}{\cancel{\tan(x)}} -\frac{2\cancel{\tan(x)}}{\cancel{\tan(x)}} = 0\\ \\ &\bbox[Beige]{\boxed{\sin(2\alpha)=2\sin(\alpha)\cos(\alpha)}} \\ \\ &\frac{\cancel{2}\cancel{\sin(x)}\cos(x)\cos(x)}{\cancel{\sin(x)}} - \cancel{2}\sin(x)\cos(x) - \cancel{2} = 0 \\ \\ &\cos^2(x) - \sin(x)\cos(x) -1 = 0\\ \\ &\bbox[Beige]{\boxed{\sin^2(\alpha) + \cos^2(\alpha) = 1}} \\ \\ &\cancel{\cos^2(x)} - \sin(x)\cos(x) - \sin^2(x) - \cancel{\cos^2(x)} = 0\\ \\ &\sin^2(x) + \sin(x)\cos(x) = 0 \\ \\ &\sin(x)(\sin(x) + \cos(x)) = 0 \\ \\ &\sin(x) = 0 \implies \boxed{x_1=\pi k ,\space k \in \mathbb{Z}} \\ \\ &\sin(x) + \cos(x) = 0 \implies \tan(x) = -1 \implies \boxed{x_2=\frac{\pi}{4}\left(4m - 1\right) ,\space m \in \mathbb{Z}} \end{align} $$ Also I checked that there were no parasite and missing roots, cause I've divided the equation by $\tan(x)$ and multiplied it by $1-\tan(x)$. There were no such ones cause $\tan(x)$ cannot assume $1$, when $\sin(x)=0$ or $\tan(x) = -1$, and the missing roots with $\tan(x) = 0$ are a subset of $x_1$. Then I checked which of these roots fitted the next equation: $$ \frac{1+\tan(x) + \tan^2(x)}{1-\tan(x) + \tan^2(x)}= 1+\sin(2x) $$ And it turned out that only $x_1$ did. Then my logic was: if there were another roots for the next steps of this sequence, e.g. $\frac{1+\tan(x) + \tan^2(x) + \tan^3(x)}{1-\tan(x) + \tan^2(x) - \tan^3(x)}= 1+\sin(2x)$ they would not fit the first step while $x_1$ would fit all steps. So the only solution is $x_1 = \pi k ,\space k \in \mathbb{Z}$ Possibly the wrong solution with my correction. You can see the original one at the www.bymath.com It is obvious that the fraction numerator and denominator are geometrical sequences (progressions) with the common ratios $\tan(x)$ and $-\tan(x)$ correspondingly. Note, that here $|\tan(x)| < 1$, otherwise the left-hand side expression is meaningless. Therefore it is possible to transform the fraction numerator and denominator by the sum formula for the unboundedly decreasing geometric sequence (progression) $\bbox[Beige]{\boxed{S = \frac{b_1}{1-q}}}$, where $b$ is the first member of a sequence and $q$ in a ratio. $$ \begin{align} &\frac{1}{1 - \tan(x)} : \frac{1}{1 - (-\tan(x))} = 1 + \sin(2x) \\ &\frac{1}{1 - \tan(x)} * (1 + \tan(x)) = 1 + \sin(2x) \\ &\bbox[Beige]{\boxed{\sin(\alpha) = \frac{2\tan(\frac{\alpha}{2})}{1+\tan^2(\frac{\alpha}{2})}}} \\ &\frac{1 + \tan(x)}{1 - \tan(x)} - 1 - \frac{2\tan(x)}{1+\tan^2(x)} = 0\\ \\ &\frac{(1 + \tan(x))(1+\tan^2(x)) - (1 - \tan(x))(1+\tan^2(x)) - 2\tan(x)(1 - \tan(x))}{(1 - \tan(x))(1+\tan^2(x))} = 0\\ \\ &\frac{1 + \tan^2 x + \tan x + \tan^3 x  -(1 + \tan^2 x - \tan x - \tan^3 x ) -2\tan x + 2\tan^2 x}{(1 - \tan x)(1+\tan^2 x)} =0 \\ \end{align} $$ So here is the point where this second solution is wrong . The right is this: $$ \begin{align} &\frac{\cancel{1} + \cancel{\tan^2 x} + \cancel{\tan x} + \tan^3 x -\cancel{1} - \cancel{\tan^2 x} + \cancel{\tan x} + \tan^3 x -\cancel{2\tan x} + 2\tan^2 x}{(1 - \tan x)(1+\tan^2 x)} =0 \\ &\frac{2\tan^3 x + 2\tan^2 x}{(1 - \tan x)(1+\tan^2 x)} =0 \implies \tan x = 0, \ \tan x = -1 \\ \end{align} $$ Whereas the author of the site got this : $\frac{4\tan^3 x}{(1 - \tan x)(1+\tan^2 x)} =0 \implies \tan x = 0$ and lost one root $x_2=\frac{\pi}{4}\left(4m - 1\right) ,\space m \in \mathbb{Z}$ ACTUALLY QUESTION So when I looked to the second solution I was pretty confused with this: in that solution it is said that unless $|tan(x)| < 1$ the left-hand side of the equation in meaningless. Why, can somebody explain, please? I suppose that this is not true cause: while the transformation with the sum formula was correct, the solution itself was wrong the right solution gives us two roots one of which does not fit all possible steps of the sequences, hence the numerator and denominator are not a unboundedly decreasing geometric sequence (progression) . Is my conclusion correct? My sincerest appreciation.","I have this equation and I will be very thankful to anyone who can provide me any help with the one discrepancy in my solution and the solution from the self-learning website: $$ \frac{1+\tan(x) + \tan^2(x) + ... + \tan^n(x) + ...}{1-\tan(x) + \tan^2(x) - ... +(-1)^n\tan^n(x) ...}= 1+\sin(2x) $$ My solution I solved it in not too graceful way. First I found the roots for this equation: $$ \require{cancel} \begin{align} &\boxed{\frac{1+\tan(x)}{1-\tan(x)}= 1+\sin(2x)} \\ \\ &\frac{(1+\tan(x))\cancel{(1-\tan(x))}}{\cancel{1-\tan(x)}}= (1+\sin(2x))(1-\tan(x))\\ \\ &\cancel{1}+\tan(x)=\cancel{1} - \tan(x) + \sin(2x) - \sin(2x)\tan(x) \\ &\frac{\sin(2x)}{\tan(x)} - \frac{\sin(2x)\cancel{\tan(x)}}{\cancel{\tan(x)}} -\frac{2\cancel{\tan(x)}}{\cancel{\tan(x)}} = 0\\ \\ &\bbox[Beige]{\boxed{\sin(2\alpha)=2\sin(\alpha)\cos(\alpha)}} \\ \\ &\frac{\cancel{2}\cancel{\sin(x)}\cos(x)\cos(x)}{\cancel{\sin(x)}} - \cancel{2}\sin(x)\cos(x) - \cancel{2} = 0 \\ \\ &\cos^2(x) - \sin(x)\cos(x) -1 = 0\\ \\ &\bbox[Beige]{\boxed{\sin^2(\alpha) + \cos^2(\alpha) = 1}} \\ \\ &\cancel{\cos^2(x)} - \sin(x)\cos(x) - \sin^2(x) - \cancel{\cos^2(x)} = 0\\ \\ &\sin^2(x) + \sin(x)\cos(x) = 0 \\ \\ &\sin(x)(\sin(x) + \cos(x)) = 0 \\ \\ &\sin(x) = 0 \implies \boxed{x_1=\pi k ,\space k \in \mathbb{Z}} \\ \\ &\sin(x) + \cos(x) = 0 \implies \tan(x) = -1 \implies \boxed{x_2=\frac{\pi}{4}\left(4m - 1\right) ,\space m \in \mathbb{Z}} \end{align} $$ Also I checked that there were no parasite and missing roots, cause I've divided the equation by $\tan(x)$ and multiplied it by $1-\tan(x)$. There were no such ones cause $\tan(x)$ cannot assume $1$, when $\sin(x)=0$ or $\tan(x) = -1$, and the missing roots with $\tan(x) = 0$ are a subset of $x_1$. Then I checked which of these roots fitted the next equation: $$ \frac{1+\tan(x) + \tan^2(x)}{1-\tan(x) + \tan^2(x)}= 1+\sin(2x) $$ And it turned out that only $x_1$ did. Then my logic was: if there were another roots for the next steps of this sequence, e.g. $\frac{1+\tan(x) + \tan^2(x) + \tan^3(x)}{1-\tan(x) + \tan^2(x) - \tan^3(x)}= 1+\sin(2x)$ they would not fit the first step while $x_1$ would fit all steps. So the only solution is $x_1 = \pi k ,\space k \in \mathbb{Z}$ Possibly the wrong solution with my correction. You can see the original one at the www.bymath.com It is obvious that the fraction numerator and denominator are geometrical sequences (progressions) with the common ratios $\tan(x)$ and $-\tan(x)$ correspondingly. Note, that here $|\tan(x)| < 1$, otherwise the left-hand side expression is meaningless. Therefore it is possible to transform the fraction numerator and denominator by the sum formula for the unboundedly decreasing geometric sequence (progression) $\bbox[Beige]{\boxed{S = \frac{b_1}{1-q}}}$, where $b$ is the first member of a sequence and $q$ in a ratio. $$ \begin{align} &\frac{1}{1 - \tan(x)} : \frac{1}{1 - (-\tan(x))} = 1 + \sin(2x) \\ &\frac{1}{1 - \tan(x)} * (1 + \tan(x)) = 1 + \sin(2x) \\ &\bbox[Beige]{\boxed{\sin(\alpha) = \frac{2\tan(\frac{\alpha}{2})}{1+\tan^2(\frac{\alpha}{2})}}} \\ &\frac{1 + \tan(x)}{1 - \tan(x)} - 1 - \frac{2\tan(x)}{1+\tan^2(x)} = 0\\ \\ &\frac{(1 + \tan(x))(1+\tan^2(x)) - (1 - \tan(x))(1+\tan^2(x)) - 2\tan(x)(1 - \tan(x))}{(1 - \tan(x))(1+\tan^2(x))} = 0\\ \\ &\frac{1 + \tan^2 x + \tan x + \tan^3 x  -(1 + \tan^2 x - \tan x - \tan^3 x ) -2\tan x + 2\tan^2 x}{(1 - \tan x)(1+\tan^2 x)} =0 \\ \end{align} $$ So here is the point where this second solution is wrong . The right is this: $$ \begin{align} &\frac{\cancel{1} + \cancel{\tan^2 x} + \cancel{\tan x} + \tan^3 x -\cancel{1} - \cancel{\tan^2 x} + \cancel{\tan x} + \tan^3 x -\cancel{2\tan x} + 2\tan^2 x}{(1 - \tan x)(1+\tan^2 x)} =0 \\ &\frac{2\tan^3 x + 2\tan^2 x}{(1 - \tan x)(1+\tan^2 x)} =0 \implies \tan x = 0, \ \tan x = -1 \\ \end{align} $$ Whereas the author of the site got this : $\frac{4\tan^3 x}{(1 - \tan x)(1+\tan^2 x)} =0 \implies \tan x = 0$ and lost one root $x_2=\frac{\pi}{4}\left(4m - 1\right) ,\space m \in \mathbb{Z}$ ACTUALLY QUESTION So when I looked to the second solution I was pretty confused with this: in that solution it is said that unless $|tan(x)| < 1$ the left-hand side of the equation in meaningless. Why, can somebody explain, please? I suppose that this is not true cause: while the transformation with the sum formula was correct, the solution itself was wrong the right solution gives us two roots one of which does not fit all possible steps of the sequences, hence the numerator and denominator are not a unboundedly decreasing geometric sequence (progression) . Is my conclusion correct? My sincerest appreciation.",,"['sequences-and-series', 'trigonometry', 'self-learning', 'roots']"
20,Sequence and series problems with slick group theoretic solutions.,Sequence and series problems with slick group theoretic solutions.,,"So I'm trying to get this unmotivated student in my class interested in learning group theory.  I've recently ascertained that he likes analysis a bit better than algebra, and that sequences and series are his favorite part. Does anyone know of some cool sequences/series results which involve group theory in an essential way?  I would be especially receptive to interesting problems with slick group theoretic solutions.","So I'm trying to get this unmotivated student in my class interested in learning group theory.  I've recently ascertained that he likes analysis a bit better than algebra, and that sequences and series are his favorite part. Does anyone know of some cool sequences/series results which involve group theory in an essential way?  I would be especially receptive to interesting problems with slick group theoretic solutions.",,"['sequences-and-series', 'group-theory', 'reference-request', 'finite-groups', 'problem-solving']"
21,Determine the limit for $a\geq-1$,Determine the limit for,a\geq-1,"Let $s_n(a)=1^a+2^a+\cdots+n^a$ where $a$ is real. Determine: $$\lim_{n\to\infty}\frac{s_n(a+1)}{ns_n(a)}$$ for $a\geq-1$. I can show that it converges. I can also find the limit for particular case when $a=0$. I think I could find a formula for natural numbers and prove it by induction. But since $a$ is real, I am stuck. Any tips of how should I proceed? Thanks!","Let $s_n(a)=1^a+2^a+\cdots+n^a$ where $a$ is real. Determine: $$\lim_{n\to\infty}\frac{s_n(a+1)}{ns_n(a)}$$ for $a\geq-1$. I can show that it converges. I can also find the limit for particular case when $a=0$. I think I could find a formula for natural numbers and prove it by induction. But since $a$ is real, I am stuck. Any tips of how should I proceed? Thanks!",,"['calculus', 'sequences-and-series', 'limits']"
22,Convergence of $\sum_{n=1}^{\infty}(-1)^n\frac{n}{f_n}$ where $f_n$ is the $n$'th Fibonacci number,Convergence of  where  is the 'th Fibonacci number,\sum_{n=1}^{\infty}(-1)^n\frac{n}{f_n} f_n n,Can we show convergence of$$B=\sum_{n=1}^{\infty}(-1)^n\frac{n}{f_n}$$where $f_n$ is the $n$'th Fibonacci number? And then can we determine the exact value of $B$?,Can we show convergence of$$B=\sum_{n=1}^{\infty}(-1)^n\frac{n}{f_n}$$where $f_n$ is the $n$'th Fibonacci number? And then can we determine the exact value of $B$?,,"['calculus', 'real-analysis', 'sequences-and-series', 'fibonacci-numbers']"
23,let $ {t_n}$ be sequence on positive numbers how prove this series $\sum_{n=1}^\infty\left(\frac1n\right)\cdot \frac{t_{n+1}+1}{t_n} $ is divergent,let  be sequence on positive numbers how prove this series  is divergent, {t_n} \sum_{n=1}^\infty\left(\frac1n\right)\cdot \frac{t_{n+1}+1}{t_n} ,let $ {t_n}$ be sequence on positive numbers how prove this series $$\sum_{n=1}^\infty\left(\frac1n\right)\cdot \frac{t_{n+1}+1}{t_n} $$ is divergent thanks in advance,let $ {t_n}$ be sequence on positive numbers how prove this series $$\sum_{n=1}^\infty\left(\frac1n\right)\cdot \frac{t_{n+1}+1}{t_n} $$ is divergent thanks in advance,,"['sequences-and-series', 'analysis']"
24,proving convergence of $\sum a^\sqrt{n} $ for $ 0 < a<1 $,proving convergence of  for,\sum a^\sqrt{n}   0 < a<1 ,"my textbook says it can be proven in three steps : 1) for very large $ n $, $ a^{2^{n/2}} < 3^{-n} $ 2) $ \sum 2^{n}a^{2^{n/2}} < \infty $ 3) $ \sum_{n=1} a^{\sqrt{n}} <  \sum_{n=0} 2^{n}a^{2^{n/2}} < \infty  $ step 1) is trivial since $a^{2^{n/2}}$ decreases exponentially. step 2) is proven from step 1. the convergence of  $ \sum (\frac{2}{3})^n $ is a proof. I'm stuck at step 3). I think i'm missing something critical here - from my naive understanding, the exponential decrease of $ a^{2^{n/2}} $ should outweigh everything. how can the convergence of  $ \sum a^{\sqrt{n}} $ for $ (0<a<1) $ can be proven?","my textbook says it can be proven in three steps : 1) for very large $ n $, $ a^{2^{n/2}} < 3^{-n} $ 2) $ \sum 2^{n}a^{2^{n/2}} < \infty $ 3) $ \sum_{n=1} a^{\sqrt{n}} <  \sum_{n=0} 2^{n}a^{2^{n/2}} < \infty  $ step 1) is trivial since $a^{2^{n/2}}$ decreases exponentially. step 2) is proven from step 1. the convergence of  $ \sum (\frac{2}{3})^n $ is a proof. I'm stuck at step 3). I think i'm missing something critical here - from my naive understanding, the exponential decrease of $ a^{2^{n/2}} $ should outweigh everything. how can the convergence of  $ \sum a^{\sqrt{n}} $ for $ (0<a<1) $ can be proven?",,"['sequences-and-series', 'convergence-divergence']"
25,Demonstrate: $ \sqrt{2}=\lim_{n\rightarrow\infty}{\sum_{i=0}^n{\frac{\left(-1\right)^i\left(-\frac{1}{2}\right)_i}{i!}}} $,Demonstrate:, \sqrt{2}=\lim_{n\rightarrow\infty}{\sum_{i=0}^n{\frac{\left(-1\right)^i\left(-\frac{1}{2}\right)_i}{i!}}} ,"Demonstrate that $\sqrt2$ can be expressed as: $$ \sqrt{2}=\lim_{n\rightarrow\infty}{\sum_{i=0}^n{\frac{\left(-1\right)^i\left(-\frac{1}{2}\right)_i}{i!}}} $$ Where $\left(z\right)_i$ is the Pochhammer symbol $\left(z\right)_i=z(z+1)(z+2)...(z+i-1);  (z)_0=1$ This is a nice problem, just wanted to share it.","Demonstrate that $\sqrt2$ can be expressed as: $$ \sqrt{2}=\lim_{n\rightarrow\infty}{\sum_{i=0}^n{\frac{\left(-1\right)^i\left(-\frac{1}{2}\right)_i}{i!}}} $$ Where $\left(z\right)_i$ is the Pochhammer symbol $\left(z\right)_i=z(z+1)(z+2)...(z+i-1);  (z)_0=1$ This is a nice problem, just wanted to share it.",,"['calculus', 'sequences-and-series', 'limits']"
26,Calculating prime sequences,Calculating prime sequences,,"Let $\omega(k)$ be the prime omega function, it counts how many distinct prime factors k has. The dirichlet series for  $\omega(k)$ can be written as,$$\sum_{k=1}^\infty\frac{\omega(k)}{k^s}=\prod_{p}\frac{1}{1-p^{-s}}*\sum_{p}\frac{1}{p^s}=\zeta(s)*P(s)$$ I know I cant re-write $$\sum_{k=0}^\infty\frac{\omega(ak+b)}{(ak+b)^s}=\prod_{p\equiv\text{b  mod a} }\frac{1}{1-p^{-s}}*\sum_{p\equiv\text{b mod a}}\frac{1}{p^s}$$ But can I re-write it, as somthing similar?","Let $\omega(k)$ be the prime omega function, it counts how many distinct prime factors k has. The dirichlet series for  $\omega(k)$ can be written as,$$\sum_{k=1}^\infty\frac{\omega(k)}{k^s}=\prod_{p}\frac{1}{1-p^{-s}}*\sum_{p}\frac{1}{p^s}=\zeta(s)*P(s)$$ I know I cant re-write $$\sum_{k=0}^\infty\frac{\omega(ak+b)}{(ak+b)^s}=\prod_{p\equiv\text{b  mod a} }\frac{1}{1-p^{-s}}*\sum_{p\equiv\text{b mod a}}\frac{1}{p^s}$$ But can I re-write it, as somthing similar?",,['sequences-and-series']
27,Convergence of a sequence,Convergence of a sequence,,"Problem statement: Determine the limit of the following sequence: $\sqrt{a},\sqrt{1+\sqrt{a}}, \sqrt{1+\sqrt{1+\sqrt{a}}},... $ My progress: Let´s begin by introducing some notation. Let $a_{n}$ denote the nth term of the sequence. We have $a_{1}=\sqrt{a}$ and $a_{n}=\sqrt{1+a_{n-1}}$. My instinct tells me now to rewrite as $a_{n}^2-a_{n-1}-1=0$ which has a root $\frac{1+\sqrt{5}}{2}$ (neglect the negative root for obvious reasons). However: My friend told me this is only an eventually value of the sequence and not necessarily. I have to determine that this sequence converges before i can conclude this. How can I do this? And what does it actually mean when I solve the quadratic(because that is only an instinct of mine)?","Problem statement: Determine the limit of the following sequence: $\sqrt{a},\sqrt{1+\sqrt{a}}, \sqrt{1+\sqrt{1+\sqrt{a}}},... $ My progress: Let´s begin by introducing some notation. Let $a_{n}$ denote the nth term of the sequence. We have $a_{1}=\sqrt{a}$ and $a_{n}=\sqrt{1+a_{n-1}}$. My instinct tells me now to rewrite as $a_{n}^2-a_{n-1}-1=0$ which has a root $\frac{1+\sqrt{5}}{2}$ (neglect the negative root for obvious reasons). However: My friend told me this is only an eventually value of the sequence and not necessarily. I have to determine that this sequence converges before i can conclude this. How can I do this? And what does it actually mean when I solve the quadratic(because that is only an instinct of mine)?",,['sequences-and-series']
28,Suppose that $a_k$ are positive and decreasing. Prove that $\sum_{k=1}^{\infty}(a_k)$ if and only if $\sum_{k=1}^{\infty}{2^ka_{2^k}}$ converges. [duplicate],Suppose that  are positive and decreasing. Prove that  if and only if  converges. [duplicate],a_k \sum_{k=1}^{\infty}(a_k) \sum_{k=1}^{\infty}{2^ka_{2^k}},This question already has answers here : Closed 11 years ago . Possible Duplicate: proving cauchy condensation test Suppose that $a_k$ are positive and decreasing. Prove that $\sum_{k=1}^{\infty}(a_k)$ if and only if $\sum_{k=1}^{\infty}{2^ka_{2^k}}$ converges. By using decreasing how can I prove this?,This question already has answers here : Closed 11 years ago . Possible Duplicate: proving cauchy condensation test Suppose that $a_k$ are positive and decreasing. Prove that $\sum_{k=1}^{\infty}(a_k)$ if and only if $\sum_{k=1}^{\infty}{2^ka_{2^k}}$ converges. By using decreasing how can I prove this?,,"['calculus', 'real-analysis', 'sequences-and-series', 'convergence-divergence']"
29,What determines if a series does not tend to 0 quickly enough?,What determines if a series does not tend to 0 quickly enough?,,"When examining a p-series (see below), any series where $p > 1$ is considered to converge. However, the stated series with $p = 1$ diverges. The only explanation I've found thus far states that the reason for this is that the series where $p = 1$ ""does not tend to $0$ quickly enough"". How is it determined that the series where $p = 1$ does not tend toward $0$ quickly enough to warrant convergence? $$\sum_{n=1}^\infty {1\over n^p}$$","When examining a p-series (see below), any series where $p > 1$ is considered to converge. However, the stated series with $p = 1$ diverges. The only explanation I've found thus far states that the reason for this is that the series where $p = 1$ ""does not tend to $0$ quickly enough"". How is it determined that the series where $p = 1$ does not tend toward $0$ quickly enough to warrant convergence? $$\sum_{n=1}^\infty {1\over n^p}$$",,"['calculus', 'sequences-and-series']"
30,Powers of $2 \times 2$ matrices expressed in linear form,Powers of  matrices expressed in linear form,2 \times 2,"I recently reopened an old high school math textbook and came upon the matrices unit. Some of the questions were those rewrite-in-linear-form problems: given, say, $M^2 = 2M - I$, express in linear form ($aM+bI$) the matrices $M^3$ and $M^4$. The method of solution would be to express $M^n$ as $M^{n-1}M$ and continue expanding each consecutive set of powers until you end up substituting in the original $M^2 = 2M-I$, for answers of $M^3 = 3M-2I$ and $M^4 = 4M-3I$. Further, induction proof problems could also be posed, such as proving that $M^n = nM - (n-1)I$ for all $n \in \mathbb{Z}^+$. (Technically, it could also be for $n \in \mathbb{Z}$ if you consider $M^{-n} \equiv (M^{-1})^n \equiv (M^n)^{-1}$, which is relevant.) I decided to take this a step further, and see if I could take powers of $M$ where $M^2 = aM + bI$. After some experimentation, one can define two related sequences $(a_n)$ and $(b_n)$ which describe linear form coefficients of $M^n$. Trivially, $M^1 = M = 1M + 0I$ and $M^0 = MM^{-1} = I = 0M + 1I$, which defines $a_0$, $a_1$, $b_0$, and $b_1$ as 0, 1, 1 and 0, respectively. From this, and by the properties of expanding powers through $M^2 = a_2M + b_2I$, $$\begin{align} &\text{Basic} \\ a_0 &= b_1 = 0 \\ a_1 &= b_0 = 1 \\ \\ &\text{Following} \\ a_{n+1} &= a_2 a_n + b_n \\ b_{n+1} &= b_2 a_n \\ \\ &\text{Preceding} \\ a_{n-1} &= \frac{1}{b_2}b_n \\ b_{n-1} &= a_n - \frac{a_2}{b_2} b_n \\ \end{align}$$ With a little playing around, one finds that $$a_n = a_2 a_{n-1} + b_2 a_{n-2}$$ which looks a little like the Fibonacci sequence, and since $b_n$ is already defined in terms of $a_n$, the crux of the problem lies in a non-recurring equation for $a_n$, given $a_2$ and $b_2$ as parameters. Is there a formula for $a_n$, and subsequently, $b_n$? Am I on the right track with this method or is there a more elegant exploitability in these sequences?","I recently reopened an old high school math textbook and came upon the matrices unit. Some of the questions were those rewrite-in-linear-form problems: given, say, $M^2 = 2M - I$, express in linear form ($aM+bI$) the matrices $M^3$ and $M^4$. The method of solution would be to express $M^n$ as $M^{n-1}M$ and continue expanding each consecutive set of powers until you end up substituting in the original $M^2 = 2M-I$, for answers of $M^3 = 3M-2I$ and $M^4 = 4M-3I$. Further, induction proof problems could also be posed, such as proving that $M^n = nM - (n-1)I$ for all $n \in \mathbb{Z}^+$. (Technically, it could also be for $n \in \mathbb{Z}$ if you consider $M^{-n} \equiv (M^{-1})^n \equiv (M^n)^{-1}$, which is relevant.) I decided to take this a step further, and see if I could take powers of $M$ where $M^2 = aM + bI$. After some experimentation, one can define two related sequences $(a_n)$ and $(b_n)$ which describe linear form coefficients of $M^n$. Trivially, $M^1 = M = 1M + 0I$ and $M^0 = MM^{-1} = I = 0M + 1I$, which defines $a_0$, $a_1$, $b_0$, and $b_1$ as 0, 1, 1 and 0, respectively. From this, and by the properties of expanding powers through $M^2 = a_2M + b_2I$, $$\begin{align} &\text{Basic} \\ a_0 &= b_1 = 0 \\ a_1 &= b_0 = 1 \\ \\ &\text{Following} \\ a_{n+1} &= a_2 a_n + b_n \\ b_{n+1} &= b_2 a_n \\ \\ &\text{Preceding} \\ a_{n-1} &= \frac{1}{b_2}b_n \\ b_{n-1} &= a_n - \frac{a_2}{b_2} b_n \\ \end{align}$$ With a little playing around, one finds that $$a_n = a_2 a_{n-1} + b_2 a_{n-2}$$ which looks a little like the Fibonacci sequence, and since $b_n$ is already defined in terms of $a_n$, the crux of the problem lies in a non-recurring equation for $a_n$, given $a_2$ and $b_2$ as parameters. Is there a formula for $a_n$, and subsequently, $b_n$? Am I on the right track with this method or is there a more elegant exploitability in these sequences?",,"['sequences-and-series', 'matrices', 'recurrence-relations']"
31,Series Expansion,Series Expansion,,"An old problem from Whittaker and Watson I'm having issues with. Any guidance would be appreciated . Show that the function $$ f(x)=\int_0^\infty \left\{ \log u +\log\left(\frac{1}{1-e^{-u}} \right) \right\}\frac{du}{u}e^{-xu} $$ has the asymptotic expansion $$ f(x)\sim\frac{1}{2x}-\frac{B_1}{2^2x^2}+\frac{B_3}{4^2x^4}-\frac{B_5}{6^2x^6}+\ldots, $$ where $B_1, B_3, \ldots$ are Bernoulli's numbers. Show also that $f(x)$ can be developed as an absolutely convergent series of the form $$ f(x)=\sum_{k=1}^\infty\frac{c_k}{(x+1)(x+2)\ldots(x+k)}. $$",An old problem from Whittaker and Watson I'm having issues with. Any guidance would be appreciated . Show that the function has the asymptotic expansion where are Bernoulli's numbers. Show also that can be developed as an absolutely convergent series of the form,"
f(x)=\int_0^\infty \left\{ \log u +\log\left(\frac{1}{1-e^{-u}} \right) \right\}\frac{du}{u}e^{-xu}
 
f(x)\sim\frac{1}{2x}-\frac{B_1}{2^2x^2}+\frac{B_3}{4^2x^4}-\frac{B_5}{6^2x^6}+\ldots,
 B_1, B_3, \ldots f(x) 
f(x)=\sum_{k=1}^\infty\frac{c_k}{(x+1)(x+2)\ldots(x+k)}.
","['real-analysis', 'sequences-and-series']"
32,Hypergeometric functions inequality,Hypergeometric functions inequality,,"Let $_2F_1(a,b;c,z)$ be the (Gauss) hypergeometric function, and $m$ and $n$ positive integers. From a simple plot it looks like $_2F_1(m+n,1,m+1,\frac{m}{m+n})>\frac{m}{n} \,_2F_1(m+n,1,n+1,\frac{n}{m+n})$ when $m<n$, but how do I prove this? Hope this is not too trivial, I am not very familiar with such functions.","Let $_2F_1(a,b;c,z)$ be the (Gauss) hypergeometric function, and $m$ and $n$ positive integers. From a simple plot it looks like $_2F_1(m+n,1,m+1,\frac{m}{m+n})>\frac{m}{n} \,_2F_1(m+n,1,n+1,\frac{n}{m+n})$ when $m<n$, but how do I prove this? Hope this is not too trivial, I am not very familiar with such functions.",,"['sequences-and-series', 'analysis', 'functions', 'inequality', 'special-functions']"
33,"How ""many"" sub-sequences in a given sequence (cardinality of the set of countably infinite subsets of a countably infinite set)","How ""many"" sub-sequences in a given sequence (cardinality of the set of countably infinite subsets of a countably infinite set)",,"I don't know how ""many"" (cardinality) sub-sequences are there in a sequence. Or equivalently, What is the cardinality of the set of countably infinite subsets of a countably infinite set? I guess it should not be $\aleph_0$, maybe $2^{\aleph_0}$ ($\aleph_0$ is the cardinality of natural numbers). Thank you.","I don't know how ""many"" (cardinality) sub-sequences are there in a sequence. Or equivalently, What is the cardinality of the set of countably infinite subsets of a countably infinite set? I guess it should not be $\aleph_0$, maybe $2^{\aleph_0}$ ($\aleph_0$ is the cardinality of natural numbers). Thank you.",,"['sequences-and-series', 'elementary-set-theory']"
34,Upper bound for the series $\sum_{n\geq 1}\frac{1}{(n+1)^{a+1}}\sum_{k=0}^n b^k\left(\frac{(n-k)!}{n!}\right)^a$,Upper bound for the series,\sum_{n\geq 1}\frac{1}{(n+1)^{a+1}}\sum_{k=0}^n b^k\left(\frac{(n-k)!}{n!}\right)^a,"I want to show that the series $$\sum_{n\geq 1}\frac{1}{(n+1)^{a+1}}\sum_{k=0}^n b^k\left(\frac{(n-k)!}{n!}\right)^a$$ converges for $a,b>0$. I have tried this so much that the smallest hint will probably suffice. I asked a question before which would have been enough but it is not true. Right now I am really stuck and frustrated. Any help would be greatly appreciated!","I want to show that the series $$\sum_{n\geq 1}\frac{1}{(n+1)^{a+1}}\sum_{k=0}^n b^k\left(\frac{(n-k)!}{n!}\right)^a$$ converges for $a,b>0$. I have tried this so much that the smallest hint will probably suffice. I asked a question before which would have been enough but it is not true. Right now I am really stuck and frustrated. Any help would be greatly appreciated!",,"['calculus', 'sequences-and-series', 'limits', 'factorial']"
35,Questions on limits of the sequence $a_{n}=\frac{(-1)^{n}n+1}{n}$,Questions on limits of the sequence,a_{n}=\frac{(-1)^{n}n+1}{n},"Given $a_{n}=\frac{(-1)^{n}n+1}{n}$, compute    $$\lim\limits{\inf(a_{n})}$$   $$\lim\limits{\sup(a_{n})}$$    $$\inf\{a_{n}\}$$   $${\sup(a_{n})}$$ My attempt: I tried taking different values ​​for the sequence and reached the following results: $$\lim\limits{\inf(a_{n})}=1$$ $$\lim\limits{\sup(a_{n})}=-1$$  $$\inf\{a_{n}\}=3/2$$ $${\sup(a_{n})}=-1$$ The teacher told me to do it more formally, anyone can help me please?","Given $a_{n}=\frac{(-1)^{n}n+1}{n}$, compute    $$\lim\limits{\inf(a_{n})}$$   $$\lim\limits{\sup(a_{n})}$$    $$\inf\{a_{n}\}$$   $${\sup(a_{n})}$$ My attempt: I tried taking different values ​​for the sequence and reached the following results: $$\lim\limits{\inf(a_{n})}=1$$ $$\lim\limits{\sup(a_{n})}=-1$$  $$\inf\{a_{n}\}=3/2$$ $${\sup(a_{n})}=-1$$ The teacher told me to do it more formally, anyone can help me please?",,"['real-analysis', 'sequences-and-series', 'limsup-and-liminf']"
36,Convergence and closed form of this infinite series?,Convergence and closed form of this infinite series?,,"If we have a circle of radius $r$ with an $n$-gon inscribed within this circle (i.e. with the same circumradius), we can find the difference of the areas using: $$A_n =\overbrace{\pi r^2}^\text{Area of circle}-\overbrace{\frac{1}{2} r^2 n \sin (\frac{2 \pi}{n})}^\text{Area of n-gon} =r^2(\pi-\frac{1}{2} n \sin (\frac{2 \pi}{n}))$$ I want to find the following sum (starting with $n=3$, i.e. the $n$-gon is a triangle): $$\Lambda=\sum_{n=3}^{\infty}A_n =  r^2\sum_{n=3}^{\infty}(\pi -\frac{1}{2}  n \sin (\frac{2 \pi}{n})) =  r^2 \lim_{k \rightarrow \infty}  (\pi (k-3)-\frac{1}{2} \sum_{n=3}^{k} n \sin (\frac{2 \pi}{n})) $$ I have not tested this sum for convergence, but a quick numerical estimate reveals that, if $k=100000, r=1, \Lambda \approx 7.417$.  Increasing $k$ gives the same approximation, suggesting convergence. Does this series converge, and if so, does it have a closed form? Can we find if $\Lambda$ is rational?","If we have a circle of radius $r$ with an $n$-gon inscribed within this circle (i.e. with the same circumradius), we can find the difference of the areas using: $$A_n =\overbrace{\pi r^2}^\text{Area of circle}-\overbrace{\frac{1}{2} r^2 n \sin (\frac{2 \pi}{n})}^\text{Area of n-gon} =r^2(\pi-\frac{1}{2} n \sin (\frac{2 \pi}{n}))$$ I want to find the following sum (starting with $n=3$, i.e. the $n$-gon is a triangle): $$\Lambda=\sum_{n=3}^{\infty}A_n =  r^2\sum_{n=3}^{\infty}(\pi -\frac{1}{2}  n \sin (\frac{2 \pi}{n})) =  r^2 \lim_{k \rightarrow \infty}  (\pi (k-3)-\frac{1}{2} \sum_{n=3}^{k} n \sin (\frac{2 \pi}{n})) $$ I have not tested this sum for convergence, but a quick numerical estimate reveals that, if $k=100000, r=1, \Lambda \approx 7.417$.  Increasing $k$ gives the same approximation, suggesting convergence. Does this series converge, and if so, does it have a closed form? Can we find if $\Lambda$ is rational?",,"['sequences-and-series', 'trigonometry', 'limits', 'circles']"
37,Property of a sequence involving near-primes,Property of a sequence involving near-primes,,"Let $p_k(m)^2:=$ the square of $m^{th}$ number containing k prime factors, including repetitions. Empirically for smallish numbers and as a conjecture, it appears that for every m and sufficiently large k, the formula $p_k(m)^2  = p_{2k}(n)$ returns the same value of n. Examples: $p_1(1)^2 = 4 = p_2(1)$, $p_2(1)^2 = 16 = p_4(1)$,... $p_1(5)^2 = 121 = p_2(40)$ $p_2(5)^2 = 196 = p_4(24)$ $p_3(5)^2 = 729 = p_6(23)$ $p_4(5)^2 = 2916 = p_8(23)$, ... For m = 1-7 the elements of the sequence are: 1, 3, 8, 12, 23, 26, 32,... The case m = 1 is easy enough. After that I'm not so sure. Thanks for any insights into this property. Edit: I think this generalizes a bit. For example, $p_i(a)p_j(b)...p_k(c) = p_{i+j+...+k}(d)$, in which i, j,..., k are increased by 1 stepwise so their difference remains constant, also returns a constant d. It also seems that the order of {a,b,...,c} does not change the value of d. For example, $p_1(2)p_2(3)p_4(5) = p_7(23)$ and using the conjecture, $p_3(2)p_4(3)p_6(5) = p_{13}(23)$ and if order unimportant$^*$, $p_3(5)p_4(2)p_6(3) = p_{13}(23)$ and again using the conjecture, $p_4(5)p_5(2)p_7(3) = p_{16}(23)$, verified computationally. And as an aside, again for ""sufficiently"" large subscripts, if we know that, e.g., $p_1(2)p_3(5)p_8(6) = p_{12}(41)$ we can augment subscripts pairwise to get $p_3(2)p_5(5)p_8(6) = p_{16}(41)$. $^*$ Changing the order of {a,b,...c} may change the size of subscripts needed for the property to obtain. The subscripts {1,2,4} and {2,3,5} do not work for the product in the last line, but {3,4,6} and higher appear to.","Let $p_k(m)^2:=$ the square of $m^{th}$ number containing k prime factors, including repetitions. Empirically for smallish numbers and as a conjecture, it appears that for every m and sufficiently large k, the formula $p_k(m)^2  = p_{2k}(n)$ returns the same value of n. Examples: $p_1(1)^2 = 4 = p_2(1)$, $p_2(1)^2 = 16 = p_4(1)$,... $p_1(5)^2 = 121 = p_2(40)$ $p_2(5)^2 = 196 = p_4(24)$ $p_3(5)^2 = 729 = p_6(23)$ $p_4(5)^2 = 2916 = p_8(23)$, ... For m = 1-7 the elements of the sequence are: 1, 3, 8, 12, 23, 26, 32,... The case m = 1 is easy enough. After that I'm not so sure. Thanks for any insights into this property. Edit: I think this generalizes a bit. For example, $p_i(a)p_j(b)...p_k(c) = p_{i+j+...+k}(d)$, in which i, j,..., k are increased by 1 stepwise so their difference remains constant, also returns a constant d. It also seems that the order of {a,b,...,c} does not change the value of d. For example, $p_1(2)p_2(3)p_4(5) = p_7(23)$ and using the conjecture, $p_3(2)p_4(3)p_6(5) = p_{13}(23)$ and if order unimportant$^*$, $p_3(5)p_4(2)p_6(3) = p_{13}(23)$ and again using the conjecture, $p_4(5)p_5(2)p_7(3) = p_{16}(23)$, verified computationally. And as an aside, again for ""sufficiently"" large subscripts, if we know that, e.g., $p_1(2)p_3(5)p_8(6) = p_{12}(41)$ we can augment subscripts pairwise to get $p_3(2)p_5(5)p_8(6) = p_{16}(41)$. $^*$ Changing the order of {a,b,...c} may change the size of subscripts needed for the property to obtain. The subscripts {1,2,4} and {2,3,5} do not work for the product in the last line, but {3,4,6} and higher appear to.",,"['number-theory', 'sequences-and-series', 'prime-numbers']"
38,Explain the steps for finding the upper bound of a sequence,Explain the steps for finding the upper bound of a sequence,,For example we have the two sequences $A(n) = \dfrac{3n^2+n+2}{n^2-n+1}$ and $ B(n) = 1+(-1/2) + (-1/2)^2 + (-1/2)^3 +\cdots+ (-1/2)^{n-1}$ I can't figure out the steps to work out the upper bound of these two sequences. I've searched so much but I couldn't find any clear examples of that type of questions about bounded sequences.,For example we have the two sequences $A(n) = \dfrac{3n^2+n+2}{n^2-n+1}$ and $ B(n) = 1+(-1/2) + (-1/2)^2 + (-1/2)^3 +\cdots+ (-1/2)^{n-1}$ I can't figure out the steps to work out the upper bound of these two sequences. I've searched so much but I couldn't find any clear examples of that type of questions about bounded sequences.,,['sequences-and-series']
39,What's another form of $\sum\limits_{k=1}^\infty{\frac{x^k}{1-y^k}}$?,What's another form of ?,\sum\limits_{k=1}^\infty{\frac{x^k}{1-y^k}},"We can consider the function $$\displaystyle\sum_{k=1}^\infty{\frac{x^k}{1-y^k}} .$$ Is it possible to obtain a closed form expression for this?  Or, if not, perhaps an integral is possible.  Can we obtain any form of expression that states this without using summation?  If so, I'd like to see how we can obtain this expression. Alternatively, I'm also interested in the expression: $$\displaystyle\sum_{k=1}^\infty{\frac{x^k}{1+y^k}} .$$","We can consider the function $$\displaystyle\sum_{k=1}^\infty{\frac{x^k}{1-y^k}} .$$ Is it possible to obtain a closed form expression for this?  Or, if not, perhaps an integral is possible.  Can we obtain any form of expression that states this without using summation?  If so, I'd like to see how we can obtain this expression. Alternatively, I'm also interested in the expression: $$\displaystyle\sum_{k=1}^\infty{\frac{x^k}{1+y^k}} .$$",,"['sequences-and-series', 'generating-functions', 'digamma-function']"
40,Limit of sum of unbounded and bounded sequence,Limit of sum of unbounded and bounded sequence,,"Suppose $a_n \rightarrow +-\infty$ and $(b_n)$ is bounded. Show that $a_n+b_n \rightarrow +-\infty$. I tried this: $|a_n|\rightarrow +-\infty$, so $|a_n+-\infty|<\epsilon$. It is also true that $|b_n|<M$, because $(b_n)$ was bounded. Now, if you add those together, you will get: $|a_n+-\infty|+|b_n|<\epsilon+M$ and therefor: $|a_n+b_n+-\infty|\le|a_n+-\infty|+|b_n|<\epsilon+M$. But, since M is fixed (say M was $2$), you can't get closer than $2$ to the limit (because $\epsilon$ must be negative in that case). Am I missing something? Regards, Kevin","Suppose $a_n \rightarrow +-\infty$ and $(b_n)$ is bounded. Show that $a_n+b_n \rightarrow +-\infty$. I tried this: $|a_n|\rightarrow +-\infty$, so $|a_n+-\infty|<\epsilon$. It is also true that $|b_n|<M$, because $(b_n)$ was bounded. Now, if you add those together, you will get: $|a_n+-\infty|+|b_n|<\epsilon+M$ and therefor: $|a_n+b_n+-\infty|\le|a_n+-\infty|+|b_n|<\epsilon+M$. But, since M is fixed (say M was $2$), you can't get closer than $2$ to the limit (because $\epsilon$ must be negative in that case). Am I missing something? Regards, Kevin",,"['real-analysis', 'sequences-and-series', 'analysis', 'limits']"
41,Limit of quotient is zero if denominator goes to infinity and numerator is bounded,Limit of quotient is zero if denominator goes to infinity and numerator is bounded,,We need to proof that $b_n/a_n\rightarrow0$ for $a_n\rightarrow\pm\infty$ and $(b_n)$ is restricted. But I came to $|b_n| \cdot 1/|a_n| \lt \epsilon$ and now I'm really stuck.. Can someone help me?,We need to proof that $b_n/a_n\rightarrow0$ for $a_n\rightarrow\pm\infty$ and $(b_n)$ is restricted. But I came to $|b_n| \cdot 1/|a_n| \lt \epsilon$ and now I'm really stuck.. Can someone help me?,,"['real-analysis', 'sequences-and-series', 'analysis', 'limits']"
42,Arithmetic progression,Arithmetic progression,,"I'm studying for a test, and I am having a hard time with this particular exercise. The first member is equal to 7 and the fifth member is equal to 59.  How many members should be taken in to the sequence that it would amount to 24,217? So far I have found out that d=13, but having trouble with the equation. Any help would be appreciated. Thank you.","I'm studying for a test, and I am having a hard time with this particular exercise. The first member is equal to 7 and the fifth member is equal to 59.  How many members should be taken in to the sequence that it would amount to 24,217? So far I have found out that d=13, but having trouble with the equation. Any help would be appreciated. Thank you.",,"['sequences-and-series', 'algebra-precalculus', 'arithmetic']"
43,How to convert a powerseries into a Dirichlet series?,How to convert a powerseries into a Dirichlet series?,,"[Update 3] : I realized, that the series $s(h)$ below is simply a ""(general) Dirichlet-series"" (1), so after I know the principle how to find the Taylor-series for some function (which may be given by its Dirichlet-series) I can now make my question more precise as: how to find the Dirichlet-series-representation of a function, given its Taylor-series? (1) - the attribute ""general"" means a series $ \sum_{k=1}^{\infty} a_k*e^{- \lambda _k s}$ where the $\lambda _k$ form a strictly monotone sequence of real numbers increasing to $+\infty$ (K. Knopp, ""Infinite series..."", german ed.) (I did not change the text below) [end update 3] In the study of functional iteration and the Schröder function I'm concerned with series of the type: $$ s(h)= a_0* (u^0)^h + a_1* (u^1)^h + a_2 * (u^2)^h + ... $$  where h is the (iteration-) ""height""-parameter. Usually, if this converges, in the numerical evaluation I change order of computation: $$ s(h)= a_0*(u^h)^0 + a_1*(u^h)^1 + a_2*(u^h)^2 + ... $$  which means in many cases I handle this as a power series in $u^h$ . But when I considered further analysis, for instance the derivative with respect to h , I differentiate using $h$ as highest exponent. (BTW, what is the name of that type of series?) Now by accident I asked Pari/GP for the coefficients of $s(x)$ and what I got back was a power series in x . I never thought deeper about such a conversion, except that I remember the case of the conversion of the zeta-series into a power series using the Stieltjes constants. Example: s(h) = 2*1^h -1.09662*1/4^h + 0.100215*1/16^h  -0.00366327*1/64^h       + 0.0000717362*1/256^h  -0.000000874084*1/1024^h + ... - ...  ps(x) = 1.00000 + 1.25723*x - 0.699161*x^2 + 0.172874*x^3 + 0.0350749*x^4          - 0.0550780*x^5 + 0.0288564*x^6 - 0.00942667*x^7 + O(x^8) Well, I think, what Pari/GP internally does is to compute the derivatives of $s(h)$ and construct the Taylor series. But now I'm curious (and that's my question): How could I convert a power series ps(x) into a series of the s(h) -type? [update] I think the comment to Mitch would be a good additional background and explanation for the question, so I copy it to here and extend it a bit I'm originally interested in the method : how one would do such a conversion of $ps(x)$ to $s(h)$ ? Note that some values for $s(h)$ are $s(1) \approx 1.73205$ , $s(2) \approx 1.93185$. My example comes from iteration of the function $$f(x) = \sqrt{2+x}$$ $$f(f(x))=\sqrt{2+\sqrt{2+x}} $$  $$f(f(f(x))) =\sqrt{2+\sqrt{2+\sqrt{2+x}}} $$ and so on. Now $f(x)$ has a power series in $x$, as well as $f(f(x))$ and for each iterate there is another power series. The method of Schröder functions applied to a recentered version of $f(x)$, which has no constant term (also called ""regular iteration""), allows to find a power series $F(x,h)$ in two variables where $h$ means the iteration-""height"". In such a function $F(x,h)$  the coefficients at powers of $x$ are polynomials in $\lambda^{ h}$ (where $\lambda$ is an eigenvalue of the function which I usually denote as $u$ for ASCII-readability). If I set $x=1$ and reorder summation collecting like powers of $\lambda^h $ I get a series in $\lambda^h$ only which I called $S(h)$ This function gives exactly the value of the h 'th iterate of $f(x)$ beginning at x=1 simply meaning $  s(h) = F(1,h) $ But $s(h)$ has not the usual form of a power series in $h$ as shown above. When I asked Pari/GP for an evaluation at some h I accidentally typed $s(x)$ and Pari/GP gave back a power series in x , I called it above $ps(x)$. $s()$ and $ps()$ have completely different forms but give the same result: $s(h) = ps(h)$ where both functions converge. The $s(h)$ as well as the $ps(x)$-form allow also continuous (i.e fractional) iteration giving the same values. Interestingly the behave of the convergence of the two forms is completely different. The limit for $h\to\infty$ is immediately visible in $s(h)$ but for $ps(h)$ that would likely be a divergent series, while for $h=0$ we see immediately that $ps(h)=1$ but would not recognize it by $s(h)$","[Update 3] : I realized, that the series $s(h)$ below is simply a ""(general) Dirichlet-series"" (1), so after I know the principle how to find the Taylor-series for some function (which may be given by its Dirichlet-series) I can now make my question more precise as: how to find the Dirichlet-series-representation of a function, given its Taylor-series? (1) - the attribute ""general"" means a series $ \sum_{k=1}^{\infty} a_k*e^{- \lambda _k s}$ where the $\lambda _k$ form a strictly monotone sequence of real numbers increasing to $+\infty$ (K. Knopp, ""Infinite series..."", german ed.) (I did not change the text below) [end update 3] In the study of functional iteration and the Schröder function I'm concerned with series of the type: $$ s(h)= a_0* (u^0)^h + a_1* (u^1)^h + a_2 * (u^2)^h + ... $$  where h is the (iteration-) ""height""-parameter. Usually, if this converges, in the numerical evaluation I change order of computation: $$ s(h)= a_0*(u^h)^0 + a_1*(u^h)^1 + a_2*(u^h)^2 + ... $$  which means in many cases I handle this as a power series in $u^h$ . But when I considered further analysis, for instance the derivative with respect to h , I differentiate using $h$ as highest exponent. (BTW, what is the name of that type of series?) Now by accident I asked Pari/GP for the coefficients of $s(x)$ and what I got back was a power series in x . I never thought deeper about such a conversion, except that I remember the case of the conversion of the zeta-series into a power series using the Stieltjes constants. Example: s(h) = 2*1^h -1.09662*1/4^h + 0.100215*1/16^h  -0.00366327*1/64^h       + 0.0000717362*1/256^h  -0.000000874084*1/1024^h + ... - ...  ps(x) = 1.00000 + 1.25723*x - 0.699161*x^2 + 0.172874*x^3 + 0.0350749*x^4          - 0.0550780*x^5 + 0.0288564*x^6 - 0.00942667*x^7 + O(x^8) Well, I think, what Pari/GP internally does is to compute the derivatives of $s(h)$ and construct the Taylor series. But now I'm curious (and that's my question): How could I convert a power series ps(x) into a series of the s(h) -type? [update] I think the comment to Mitch would be a good additional background and explanation for the question, so I copy it to here and extend it a bit I'm originally interested in the method : how one would do such a conversion of $ps(x)$ to $s(h)$ ? Note that some values for $s(h)$ are $s(1) \approx 1.73205$ , $s(2) \approx 1.93185$. My example comes from iteration of the function $$f(x) = \sqrt{2+x}$$ $$f(f(x))=\sqrt{2+\sqrt{2+x}} $$  $$f(f(f(x))) =\sqrt{2+\sqrt{2+\sqrt{2+x}}} $$ and so on. Now $f(x)$ has a power series in $x$, as well as $f(f(x))$ and for each iterate there is another power series. The method of Schröder functions applied to a recentered version of $f(x)$, which has no constant term (also called ""regular iteration""), allows to find a power series $F(x,h)$ in two variables where $h$ means the iteration-""height"". In such a function $F(x,h)$  the coefficients at powers of $x$ are polynomials in $\lambda^{ h}$ (where $\lambda$ is an eigenvalue of the function which I usually denote as $u$ for ASCII-readability). If I set $x=1$ and reorder summation collecting like powers of $\lambda^h $ I get a series in $\lambda^h$ only which I called $S(h)$ This function gives exactly the value of the h 'th iterate of $f(x)$ beginning at x=1 simply meaning $  s(h) = F(1,h) $ But $s(h)$ has not the usual form of a power series in $h$ as shown above. When I asked Pari/GP for an evaluation at some h I accidentally typed $s(x)$ and Pari/GP gave back a power series in x , I called it above $ps(x)$. $s()$ and $ps()$ have completely different forms but give the same result: $s(h) = ps(h)$ where both functions converge. The $s(h)$ as well as the $ps(x)$-form allow also continuous (i.e fractional) iteration giving the same values. Interestingly the behave of the convergence of the two forms is completely different. The limit for $h\to\infty$ is immediately visible in $s(h)$ but for $ps(h)$ that would likely be a divergent series, while for $h=0$ we see immediately that $ps(h)=1$ but would not recognize it by $s(h)$",,"['sequences-and-series', 'functional-analysis', 'power-series']"
44,Proof whether or not 1/k by 1/(k+1) rectangles fit inside a unit square,Proof whether or not 1/k by 1/(k+1) rectangles fit inside a unit square,,"I am reading Concrete Mathematics and came across an interesting problem, number 37 of chapter 2. The answers to exercises lists no known answer to this problem: Will all the 1/k by 1/(k+1) rectangles, for k $\ge$ 1, fit together inside a 1 by 1 square? (Recall that their areas sum to 1) My question is: Has a solution been found in the years after the book's publishing? Mathematics is a very large field, and much of the terminology that might aid in googling I am not yet aware of.","I am reading Concrete Mathematics and came across an interesting problem, number 37 of chapter 2. The answers to exercises lists no known answer to this problem: Will all the 1/k by 1/(k+1) rectangles, for k $\ge$ 1, fit together inside a 1 by 1 square? (Recall that their areas sum to 1) My question is: Has a solution been found in the years after the book's publishing? Mathematics is a very large field, and much of the terminology that might aid in googling I am not yet aware of.",,"['geometry', 'sequences-and-series']"
45,Taylor polynomial with Lagrange remainder,Taylor polynomial with Lagrange remainder,,"In my course there's a paragraph: Taylor polynomial with Lagrange remainder, The paragraph starts with a theorem (I left out the constraints): $$ ( \exists \theta \in ]0,1[)(f(a +h) = T_{f,a,n}(a + h) + \frac{h^{n+1}}{(n+1)!}D^{n+1}f(a + \theta h)) $$ With $f$ an  $R-R$ function and $a$ and $a + h$ defined over an interval $I$. And the only other thing in the paragraph is a proof of the above theorem. Before I'm starting with the proof, could someone please explain the above theorem in human language ? I understand what a Taylor polynomial is, and what it's good for, but I can't turn this into anything that makes sense...","In my course there's a paragraph: Taylor polynomial with Lagrange remainder, The paragraph starts with a theorem (I left out the constraints): $$ ( \exists \theta \in ]0,1[)(f(a +h) = T_{f,a,n}(a + h) + \frac{h^{n+1}}{(n+1)!}D^{n+1}f(a + \theta h)) $$ With $f$ an  $R-R$ function and $a$ and $a + h$ defined over an interval $I$. And the only other thing in the paragraph is a proof of the above theorem. Before I'm starting with the proof, could someone please explain the above theorem in human language ? I understand what a Taylor polynomial is, and what it's good for, but I can't turn this into anything that makes sense...",,"['calculus', 'analysis', 'sequences-and-series', 'taylor-expansion']"
46,Finding n-th position of occurence of a number in an infinite series of numbers,Finding n-th position of occurence of a number in an infinite series of numbers,,"Let's call $S$ the infinite string that is made by concatenating the consecutive positive integers written down in base $10$ . Thus, $$S = 12345678910111213141516171819202122232425\ldots$$ Any number in $S$ occurs multiple times. The first occurrence of $3$ is in the third position of the series, the second occurrence is in the seventeenth position, and so on. How do I find the position of the hundredth occurrence of $3$ ? Is there a pattern?","Let's call the infinite string that is made by concatenating the consecutive positive integers written down in base . Thus, Any number in occurs multiple times. The first occurrence of is in the third position of the series, the second occurrence is in the seventeenth position, and so on. How do I find the position of the hundredth occurrence of ? Is there a pattern?",S 10 S = 12345678910111213141516171819202122232425\ldots S 3 3,['combinatorics']
47,Alternating series test to prove the convergence of the series,Alternating series test to prove the convergence of the series,,"I want to apply the alternating series test to prove the convergence of the series $\sum_{n\geq 1} (-1)^n u_n$ where $u_1=1$ and $\forall n\in \mathbb{N},\quad u_{n+1}=\frac{\cos(u_n)}{n^\alpha}$ where $\alpha>0$ . We can show that $0\leq u_n\leq 1$ for all $n$ and that $u_n\to 0$ . Numerically, it seems that the sequence $u_n$ is decreasing after a certain point, but I don't see how to prove it.","I want to apply the alternating series test to prove the convergence of the series where and where . We can show that for all and that . Numerically, it seems that the sequence is decreasing after a certain point, but I don't see how to prove it.","\sum_{n\geq 1} (-1)^n u_n u_1=1 \forall n\in \mathbb{N},\quad u_{n+1}=\frac{\cos(u_n)}{n^\alpha} \alpha>0 0\leq u_n\leq 1 n u_n\to 0 u_n","['real-analysis', 'sequences-and-series']"
48,What is the reason for these strange oscillations? Issue with Desmos?,What is the reason for these strange oscillations? Issue with Desmos?,,"Take a partition of $\Bbb R^2_{\gt 0}$ by the union of functions indexed by real $t\ge 0$ $$\mathcal F:=\bigg \lbrace \mathcal M[\chi_t(x)]\cup \mathcal M\bigg[\frac{1}{1-\chi_t(x)}\bigg] \bigg \rbrace$$ where $$\mathcal M[\chi_t(x)]:=\int_{(0,1)} \chi_t(x)x^{s-1}~dx=  2\sqrt{\frac{t}{s}}K_1(2\sqrt{ts})=\Phi_t(s)$$ and $$\mathcal M\bigg[\frac{1}{1-\chi_t(x)}\bigg] :=\int_{(0,1)} \frac{1}{1-\chi_t(x)}x^{s-1}~dx= \Psi_t(s)= \sum_{n=0}^\infty \Phi_{tn}(s)=\sum_{n=0}^\infty 2\sqrt{\frac{tn}{s}}K_1(2\sqrt{ts})$$ for $K_1$ Bessel function. Consider the functions indexed again by $t$ $$H_t(x)=-\frac{\Phi'{_t}(s)}{\Phi{_t}(s)\Psi_t(s)}  $$ This set of functions forms a real analytic partition (even a foliation) of $\Bbb R^2_{\gt 0}$ we have that $$\bigcup_{t\ge 0} H_t(x)=\Bbb R^2_{\gt 0}$$ But I am curious, what is the reason for the oscillations in the plot? Is this an issue with Desmos? Here is a picture of the partition. Link to the plot: Desmos Plot .","Take a partition of by the union of functions indexed by real where and for Bessel function. Consider the functions indexed again by This set of functions forms a real analytic partition (even a foliation) of we have that But I am curious, what is the reason for the oscillations in the plot? Is this an issue with Desmos? Here is a picture of the partition. Link to the plot: Desmos Plot .","\Bbb R^2_{\gt 0} t\ge 0 \mathcal F:=\bigg \lbrace \mathcal M[\chi_t(x)]\cup \mathcal M\bigg[\frac{1}{1-\chi_t(x)}\bigg] \bigg \rbrace \mathcal M[\chi_t(x)]:=\int_{(0,1)} \chi_t(x)x^{s-1}~dx=  2\sqrt{\frac{t}{s}}K_1(2\sqrt{ts})=\Phi_t(s) \mathcal M\bigg[\frac{1}{1-\chi_t(x)}\bigg] :=\int_{(0,1)} \frac{1}{1-\chi_t(x)}x^{s-1}~dx= \Psi_t(s)= \sum_{n=0}^\infty \Phi_{tn}(s)=\sum_{n=0}^\infty 2\sqrt{\frac{tn}{s}}K_1(2\sqrt{ts}) K_1 t H_t(x)=-\frac{\Phi'{_t}(s)}{\Phi{_t}(s)\Psi_t(s)}   \Bbb R^2_{\gt 0} \bigcup_{t\ge 0} H_t(x)=\Bbb R^2_{\gt 0}","['real-analysis', 'integration', 'sequences-and-series', 'definite-integrals', 'graphing-functions']"
49,"Prove via contraposition that if $(a_n)$ is decreasing and $\sum_{n=1}^\infty a_n<\infty$, then $\lim_{n\to\infty}na_n=0$","Prove via contraposition that if  is decreasing and , then",(a_n) \sum_{n=1}^\infty a_n<\infty \lim_{n\to\infty}na_n=0,"""Normal way"" Let $(a_n)_{n\in\mathbb{N}}$ be a monotonically decreasing sequence of non-negative real numbers. Furthermore, let $\sum_{n=1}^\infty a_n$ be convergent. To show is $\lim_{n\to\infty}n\cdot a_n=0$ Cauchy's convergence test gives us $$\forall \varepsilon>0 \quad \exists N\in\mathbb{N} \quad \forall m > n \ge N \colon \quad \sum_{k=n+1}^m a_k < \varepsilon$$ Since $(a_n)_{n\in\mathbb{N}}$ is monotonically decreasing, we get $$(m-n)a_m\leq\sum_{k=n+1}^m a_k < \varepsilon$$ Now, let $m\geq 2N$ and $n:=\left\lfloor\frac{m}{2}\right\rfloor$ , which satisfies $m > n \ge N$ , so we get $$\frac{m}{2}a_m\leq(m-n)a_m< \varepsilon$$ So, $\lim_{n\to\infty}\frac{n}{2}\cdot a_n=0$ and thus $$\lim_{n\to\infty}n\cdot a_n=0$$ Contraposition This wasn't a big deal, however I'm wondering, whether the statement can also be proven directly via its contraposition, so: Let $(a_n)_{n\in\mathbb{N}}$ be a monotonically decreasing sequence of non-negative real numbers. Furthermore, let $\lim_{n\to\infty}n\cdot a_n\neq0$ To show is that $\sum_{n=1}^\infty a_n$ is not convergent. By definition, we have $$\exists \varepsilon>0 \; \forall N\in\mathbb{N} \; \exists n \ge N\colon \; n\cdot a_n\geq\varepsilon$$ However, this only gives us $a_n\geq\frac{\varepsilon}{n}$ , and then due to $(a_n)_{n\in\mathbb{N}}$ being monotonically decreasing, we get $\sum_{k=1}^n a_k\geq\varepsilon$ , and that doesn't seem to be of much use. Question Do you see how the proof via contraposition could be done?","""Normal way"" Let be a monotonically decreasing sequence of non-negative real numbers. Furthermore, let be convergent. To show is Cauchy's convergence test gives us Since is monotonically decreasing, we get Now, let and , which satisfies , so we get So, and thus Contraposition This wasn't a big deal, however I'm wondering, whether the statement can also be proven directly via its contraposition, so: Let be a monotonically decreasing sequence of non-negative real numbers. Furthermore, let To show is that is not convergent. By definition, we have However, this only gives us , and then due to being monotonically decreasing, we get , and that doesn't seem to be of much use. Question Do you see how the proof via contraposition could be done?",(a_n)_{n\in\mathbb{N}} \sum_{n=1}^\infty a_n \lim_{n\to\infty}n\cdot a_n=0 \forall \varepsilon>0 \quad \exists N\in\mathbb{N} \quad \forall m > n \ge N \colon \quad \sum_{k=n+1}^m a_k < \varepsilon (a_n)_{n\in\mathbb{N}} (m-n)a_m\leq\sum_{k=n+1}^m a_k < \varepsilon m\geq 2N n:=\left\lfloor\frac{m}{2}\right\rfloor m > n \ge N \frac{m}{2}a_m\leq(m-n)a_m< \varepsilon \lim_{n\to\infty}\frac{n}{2}\cdot a_n=0 \lim_{n\to\infty}n\cdot a_n=0 (a_n)_{n\in\mathbb{N}} \lim_{n\to\infty}n\cdot a_n\neq0 \sum_{n=1}^\infty a_n \exists \varepsilon>0 \; \forall N\in\mathbb{N} \; \exists n \ge N\colon \; n\cdot a_n\geq\varepsilon a_n\geq\frac{\varepsilon}{n} (a_n)_{n\in\mathbb{N}} \sum_{k=1}^n a_k\geq\varepsilon,"['real-analysis', 'sequences-and-series', 'convergence-divergence', 'alternative-proof']"
50,Proving the inequality $\sum_{n=1}^\infty\frac{1}{(n+1)\sqrt{n}} \lt 2$,Proving the inequality,\sum_{n=1}^\infty\frac{1}{(n+1)\sqrt{n}} \lt 2,"The question goes out as follows: Prove the inequality $$\sum_{n=1}^\infty\frac{1}{(n+1)\sqrt{n}} \lt 2$$ The solution is as follows: \begin{align*} \sum_{n=1}^\infty\frac{1}{(n+1)\sqrt{n}} &= 1 + \sum_{n=2}^\infty\frac{\sqrt{n}-\sqrt{n-1}}{n} \\ &\lt 1 + \sum_{n=2}^\infty\frac{\sqrt{n}-\sqrt{n-1}}{\sqrt{n}\sqrt{n-1}} \\ &= 1 + \sum_{n=2}^\infty\frac{1}{\sqrt{n-1}}-\frac{1}{\sqrt{n}} = 2. \end{align*} But here's the thing, I didn't understand the first step itself. The other steps were fine, but I didn't get the first step. Can anyone help me out here? Thanks in advance! P.S. It's worth mentioning that $\frac{1}{(n+1)\sqrt{n}} = \frac{\sqrt{n}}{n}-\frac{\sqrt{n}}{n+1}$","The question goes out as follows: Prove the inequality The solution is as follows: But here's the thing, I didn't understand the first step itself. The other steps were fine, but I didn't get the first step. Can anyone help me out here? Thanks in advance! P.S. It's worth mentioning that","\sum_{n=1}^\infty\frac{1}{(n+1)\sqrt{n}} \lt 2 \begin{align*}
\sum_{n=1}^\infty\frac{1}{(n+1)\sqrt{n}} &= 1 + \sum_{n=2}^\infty\frac{\sqrt{n}-\sqrt{n-1}}{n} \\
&\lt 1 + \sum_{n=2}^\infty\frac{\sqrt{n}-\sqrt{n-1}}{\sqrt{n}\sqrt{n-1}} \\
&= 1 + \sum_{n=2}^\infty\frac{1}{\sqrt{n-1}}-\frac{1}{\sqrt{n}} = 2.
\end{align*} \frac{1}{(n+1)\sqrt{n}} = \frac{\sqrt{n}}{n}-\frac{\sqrt{n}}{n+1}","['sequences-and-series', 'inequality']"
51,Radius of Convergence of Laurent Series Confusion,Radius of Convergence of Laurent Series Confusion,,"Determine the largest number $R$ such that the Laurent series of $$f(z)= \dfrac{2sin(z)}{z^2-4} + \dfrac{cos(z)}{z-3i}$$ about $z=-2$ converges for $0<|z+2|<R$ ? I know the maclaurin series for sine and cosine which are valid for all complex numbers. For $\frac{1}{z^2-4} = -\frac{0.25}{z+2} + \frac{0.25}{z-2} = \frac{-0.25}{z+2} + \frac{0.25}{-4+(z+2)} = \frac{-0.25}{z+2} + \frac{-1}{4}\frac{0.25}{1-(\frac{z+2}{4})}$ , which is only valid for | $\frac{z+2}{4}$ | < 1 which means $R=4$ as of now when applying the geometric series. For $\frac{1}{z-3i} = \frac{1}{z+2-(2+3i)} = \frac{-1}{2+3i}\frac{1}{1-\frac{z+2}{2+3i}}$ . When applying the geometric series only valid on $|\frac{z+2}{2+3i}| < 1$ so $R = \sqrt{13}$ . Is this right?","Determine the largest number such that the Laurent series of about converges for ? I know the maclaurin series for sine and cosine which are valid for all complex numbers. For , which is only valid for | | < 1 which means as of now when applying the geometric series. For . When applying the geometric series only valid on so . Is this right?",R f(z)= \dfrac{2sin(z)}{z^2-4} + \dfrac{cos(z)}{z-3i} z=-2 0<|z+2|<R \frac{1}{z^2-4} = -\frac{0.25}{z+2} + \frac{0.25}{z-2} = \frac{-0.25}{z+2} + \frac{0.25}{-4+(z+2)} = \frac{-0.25}{z+2} + \frac{-1}{4}\frac{0.25}{1-(\frac{z+2}{4})} \frac{z+2}{4} R=4 \frac{1}{z-3i} = \frac{1}{z+2-(2+3i)} = \frac{-1}{2+3i}\frac{1}{1-\frac{z+2}{2+3i}} |\frac{z+2}{2+3i}| < 1 R = \sqrt{13},"['sequences-and-series', 'complex-analysis', 'analysis', 'taylor-expansion']"
52,How are these two conditions equivalent?,How are these two conditions equivalent?,,"I'm reading an article and I quote the author here : The condition $\sum_{n=1}^{\infty} n^t L(n) \operatorname{Pr}\left(|X|>n^{1 / r}\right)<\infty$ is equivalent to the moment condition $E\left[|X|^{(t+1) r} L(X)\right]<\infty$ . $t \geq 0, 0<r <2$ , $X$ is an arbitrary random variable and $L(\cdot)$ is a slowly varying function but shouldn't matter here, I know that generally for positive random variables we got $\mathrm{E}[X] \sim \sum_{n=0}^{\infty} \mathrm{P}(X>n)$ but it doesn't seem to me that there's a an obvious way of arranging terms to get that equivalence of conditions. if somebody can help that'll be cool.","I'm reading an article and I quote the author here : The condition is equivalent to the moment condition . , is an arbitrary random variable and is a slowly varying function but shouldn't matter here, I know that generally for positive random variables we got but it doesn't seem to me that there's a an obvious way of arranging terms to get that equivalence of conditions. if somebody can help that'll be cool.","\sum_{n=1}^{\infty} n^t L(n) \operatorname{Pr}\left(|X|>n^{1 / r}\right)<\infty E\left[|X|^{(t+1) r} L(X)\right]<\infty t \geq 0, 0<r <2 X L(\cdot) \mathrm{E}[X] \sim \sum_{n=0}^{\infty} \mathrm{P}(X>n)","['integration', 'sequences-and-series', 'probability-theory']"
53,"If a sequence $ \{ a_n \} $ is contained in a finite union of sets, then there is a subsequence of $ \{ a_n \} $ contained in only one of the sets.","If a sequence  is contained in a finite union of sets, then there is a subsequence of  contained in only one of the sets.", \{ a_n \}   \{ a_n \} ,"Edit : It has been pointed out that the title is stated ambiguously, please refer to the post by @Prem as to why. The title should actually be: If a sequence $ \{ a_n \} $ is contained in a finite union of sets, then there is a subsequence of $ \{ a_n \} $ contained entirely in one of the sets. In other words, if $ \{a_{n_i} \}$ is the desired subsequence, then there is some $ 1 \leq k \leq m $ such that $ a_{n_i} \in E_k $ for all $ i $ where $ \{n_i\} $ is the index selection sequence. I'm working on a proof in which I would like to use the following result: Suppose that a sequence $ \{ a_n \} $ is contained in a finite union of sets $ E_1 \cup \dots \cup E_m $ , then there exists a subsequence $ \{ a_{n_i} \} $ of $ \{ a_n \} $ contained entirely in one of the $ E_k $ where $ 1 \leq k \leq m $ . Here $ \{n_i\} $ is the index selection sequence. However, I have trouble finding a proof of this result in any of my textbooks. I've looked around the internet as well but haven't found anything. Intuitively, I'm certain that this is true, so I tried cooking up a proof of my own but I'm worried it might not be correct/rigorous: Since the sequence $ \{ a_{n} \} $ is infinite, we must have that it occurs infinitely often in at least one of the sets $ E_1, \dots, E_m $ . But this implies that there is some subsequence $ \{ a_{n_i} \} $ contained entirely in one of the sets $ E_1, \dots, E_m $ .","Edit : It has been pointed out that the title is stated ambiguously, please refer to the post by @Prem as to why. The title should actually be: If a sequence is contained in a finite union of sets, then there is a subsequence of contained entirely in one of the sets. In other words, if is the desired subsequence, then there is some such that for all where is the index selection sequence. I'm working on a proof in which I would like to use the following result: Suppose that a sequence is contained in a finite union of sets , then there exists a subsequence of contained entirely in one of the where . Here is the index selection sequence. However, I have trouble finding a proof of this result in any of my textbooks. I've looked around the internet as well but haven't found anything. Intuitively, I'm certain that this is true, so I tried cooking up a proof of my own but I'm worried it might not be correct/rigorous: Since the sequence is infinite, we must have that it occurs infinitely often in at least one of the sets . But this implies that there is some subsequence contained entirely in one of the sets ."," \{ a_n \}   \{ a_n \}   \{a_{n_i} \}  1 \leq k \leq m   a_{n_i} \in E_k   i   \{n_i\}   \{ a_n \}   E_1 \cup \dots \cup E_m   \{ a_{n_i} \}   \{ a_n \}   E_k   1 \leq k \leq m   \{n_i\}   \{ a_{n} \}   E_1, \dots, E_m   \{ a_{n_i} \}   E_1, \dots, E_m ","['real-analysis', 'sequences-and-series', 'general-topology', 'solution-verification']"
54,Does anyone know why this is happening with 1/7? [duplicate],Does anyone know why this is happening with 1/7? [duplicate],,"This question already has answers here : Recurring decimal expansion of $\frac17$ (4 answers) Is there a reason why $\frac{1}{7}$ as a decimal so perfectly seems to follow multiples of $7$? (1 answer) Doubling sequences of the cyclic decimal parts of the fraction numbers (1 answer) Closed 7 months ago . (I've never posted on here before, so apologies for any formatting problems) I had always noticed this property of the decimal form of $1/7$ ( $0.14285714...$ ) where the decimals went $14$ , then $28$ , then $57$ , which is almost exactly the formula $f(x)=7*2^x$ , starting with $f(1)$ - except for $57$ , which is $1$ more than $56$ . However, if you add the next number in the series, $f(4)=112$ , to the tail end of $56$ , then you get $57$ and are left with the second $1$ and the $2$ to add to the end of the decimal, which is exactly where the $71$ lands in the $.14285714...$ string of digits. If you keep doing this with the next number in the formula, $f(5)=224$ , and add to the end of $112$ , you get $2+2$ , which accounts the $4$ and the $2$ , and so on. I continued this pattern and found that this process of adding digits together works all the way up to the $45th$ digit , which is where I stopped. Is this simply a coincidence or is there a reason for this to occur? And if there really is something behind this (which I'm sure there is, does anyone know why this happens? I would appreciate any attempt at solving this. Work for said question (apologies if it's messy, I did this work in a cramped notebook lol) I know this seems very confusing, but if anyone needs me to clarify, I will do my best.","This question already has answers here : Recurring decimal expansion of $\frac17$ (4 answers) Is there a reason why $\frac{1}{7}$ as a decimal so perfectly seems to follow multiples of $7$? (1 answer) Doubling sequences of the cyclic decimal parts of the fraction numbers (1 answer) Closed 7 months ago . (I've never posted on here before, so apologies for any formatting problems) I had always noticed this property of the decimal form of ( ) where the decimals went , then , then , which is almost exactly the formula , starting with - except for , which is more than . However, if you add the next number in the series, , to the tail end of , then you get and are left with the second and the to add to the end of the decimal, which is exactly where the lands in the string of digits. If you keep doing this with the next number in the formula, , and add to the end of , you get , which accounts the and the , and so on. I continued this pattern and found that this process of adding digits together works all the way up to the digit , which is where I stopped. Is this simply a coincidence or is there a reason for this to occur? And if there really is something behind this (which I'm sure there is, does anyone know why this happens? I would appreciate any attempt at solving this. Work for said question (apologies if it's messy, I did this work in a cramped notebook lol) I know this seems very confusing, but if anyone needs me to clarify, I will do my best.",1/7 0.14285714... 14 28 57 f(x)=7*2^x f(1) 57 1 56 f(4)=112 56 57 1 2 71 .14285714... f(5)=224 112 2+2 4 2 45th,"['sequences-and-series', 'elementary-number-theory', 'decimal-expansion']"
55,Mathematical proof for the following infinite double summation.,Mathematical proof for the following infinite double summation.,,"In this Physics Stack Exchange post , I detailed my discovery of the following equation $$\sum_{i=0}^{\infty}\sum_{j=0}^{\infty}\frac{(-1)^{i+j}}{(2i+1)(2j+1)\cosh\left(\frac{\sqrt{(2i+1)^2+(2j+1)^2}\pi}{2}\right)} = \frac{\pi^2}{48},$$ through solving a physics problem in two different ways. Question: I was wondering if there exists any other proof of this equation, that is more 'mathematical'? Here, I mean 'mathematical', in the sense that it does not delve into the physical context of a specific problem as done in the post, but rather relies on theorems of pure mathematics to prove the result.","In this Physics Stack Exchange post , I detailed my discovery of the following equation through solving a physics problem in two different ways. Question: I was wondering if there exists any other proof of this equation, that is more 'mathematical'? Here, I mean 'mathematical', in the sense that it does not delve into the physical context of a specific problem as done in the post, but rather relies on theorems of pure mathematics to prove the result.","\sum_{i=0}^{\infty}\sum_{j=0}^{\infty}\frac{(-1)^{i+j}}{(2i+1)(2j+1)\cosh\left(\frac{\sqrt{(2i+1)^2+(2j+1)^2}\pi}{2}\right)} = \frac{\pi^2}{48},","['sequences-and-series', 'physics', 'mathematical-physics']"
56,Problem from the 1960 Putnam Olympiad involving the sum of a series,Problem from the 1960 Putnam Olympiad involving the sum of a series,,"Suppose that $\sum\limits_{i=1}^n x_i $ is a convergent series of positive terms that monotonically decrease (that is, $ x_1 \geqslant x_2 \geqslant x_3 \geqslant.. $ ). Let P denote the set of all numbers that are sums of some (finite or infinite) subseries of $\sum_{n=1}^{\infty}$ xi  . Show that P is an interval if and only if $$x_n \leq \sum_{i=n+1}^{\infty}x_i$$ for every integer n,which we call condition(1). This is the condition of the problem, I guessed part of the solution, but I am as sure of it as I am uncertain. My solution. Let P be the interval (a,b), where b>a>0. Since b is the largest sum of all possible subsequences, it includes all elements and equal $\sum\limits_{i=1}^n x_i = S$ . To get the smallest element, you need to take the smallest terms from sequense, since by condition the series converges,that $\lim_{n\to \infty}x_n=0$ .This means that to get a we can take terms tending to zero,a= $0$ .P=( $0$ ,S). For any c from the interval we can find a subsequence whose sum is equal to c.Let us assume here that $\exists x_k > \sum_{i=k+1}^{\infty}x_i$ .Take $c > x_k$ and $c < x_{k-1}$ (Such as c is exists since the sequence is monotonic).Then for $c-x_k$ exists subsequence which sum equal $x_k$ (it is obvious that all elements of the sequence $< x_k$ ) ,but $x_k > \sum_{i=k+1}^{\infty}x_i$ .That mean $c-x_k +  \sum_{i=k+1}^{\infty}x_i <c$ contradiction. On the contrary, I don’t really understand how to prove.","Suppose that is a convergent series of positive terms that monotonically decrease (that is, ). Let P denote the set of all numbers that are sums of some (finite or infinite) subseries of xi  . Show that P is an interval if and only if for every integer n,which we call condition(1). This is the condition of the problem, I guessed part of the solution, but I am as sure of it as I am uncertain. My solution. Let P be the interval (a,b), where b>a>0. Since b is the largest sum of all possible subsequences, it includes all elements and equal . To get the smallest element, you need to take the smallest terms from sequense, since by condition the series converges,that .This means that to get a we can take terms tending to zero,a= .P=( ,S). For any c from the interval we can find a subsequence whose sum is equal to c.Let us assume here that .Take and (Such as c is exists since the sequence is monotonic).Then for exists subsequence which sum equal (it is obvious that all elements of the sequence ) ,but .That mean contradiction. On the contrary, I don’t really understand how to prove.",\sum\limits_{i=1}^n x_i   x_1 \geqslant x_2 \geqslant x_3 \geqslant..  \sum_{n=1}^{\infty} x_n \leq \sum_{i=n+1}^{\infty}x_i \sum\limits_{i=1}^n x_i = S \lim_{n\to \infty}x_n=0 0 0 \exists x_k > \sum_{i=k+1}^{\infty}x_i c > x_k c < x_{k-1} c-x_k x_k < x_k x_k > \sum_{i=k+1}^{\infty}x_i c-x_k +  \sum_{i=k+1}^{\infty}x_i <c,"['sequences-and-series', 'problem-solving']"
57,"if $\sum_{n=1}^{\infty}a_n$ converges, then $\sum_{n=1}^{\infty} a_{2n-1}$ converges?","if  converges, then  converges?",\sum_{n=1}^{\infty}a_n \sum_{n=1}^{\infty} a_{2n-1},"I think this statement is wrong. Consider $a_1=1, a_2=-1, a_3=1/2, a_4=-1/2, a_5=1/3, a_6=-1/3, \dots$ Is my logic correct?",I think this statement is wrong. Consider Is my logic correct?,"a_1=1, a_2=-1, a_3=1/2, a_4=-1/2, a_5=1/3, a_6=-1/3, \dots","['calculus', 'sequences-and-series', 'convergence-divergence']"
58,How do I find the value of the summation: $\dfrac{1}{1^2}+\dfrac{1}{7^2}+\dfrac{1}{9^2}+\dfrac{1}{15^2}+\dfrac{1}{17^2}+\cdots$,How do I find the value of the summation:,\dfrac{1}{1^2}+\dfrac{1}{7^2}+\dfrac{1}{9^2}+\dfrac{1}{15^2}+\dfrac{1}{17^2}+\cdots,"I used a flawed approach to generalizing Basel-like problems, Please refer: https://math.stackexchange.com/q/4769685 I assumed $\cos=0$ (for which the roots are $\dfrac{\pi}{2},\dfrac{-\pi}{2},\dfrac{3\pi}{2},\cdots$ $a_0$ becomes 1) for deriving the Basel problem in the cited answer, if instead I used $\cos=\dfrac{1}{\sqrt{2}}$ (for which the roots are $\dfrac{\pi}{4},\dfrac{9\pi}{4},\dfrac{-7\pi}{4},\cdots$ $a_0$ becomes $1-\dfrac{1}{\sqrt{2}}$ ) the resulting summation would be: $\dfrac{1}{1^2}+\dfrac{1}{7^2}+\dfrac{1}{9^2}+\dfrac{1}{15^2}+\dfrac{1}{17^2}+\cdots$ Which results in the value $$\dfrac{\pi^2\cdot(\sqrt{2}(\sqrt{2}+1))}{32}=\dfrac{1}{1^2}+\dfrac{1}{7^2}+\dfrac{1}{9^2}+\dfrac{1}{15^2}+\dfrac{1}{17^2}+\cdots$$ These results can be seemingly generalized as (Where $X_e=\dfrac{\pi}{n}$ ): $$\dfrac{X_e^2}{2}(\csc^2(X_e)(1+\cos(X_e)))=\dfrac{\pi^2}{2\cdot n^2}(\csc^2(\dfrac{\pi}{n})(1+\cos(\dfrac{\pi}{n})))=\dfrac{1}{1^2}+\dfrac{1}{(2n-1)^2}+\dfrac{1}{(2n+1)^2}+\dfrac{1}{(1-4n)^2}+\dfrac{1}{(1+4n)^2}+\cdots$$ (For n>1) However I acknowledge that the method I used is fundamentally flawed. Is there an alternate derivation for finding the value of the summation and by extension the observed generalization? If yes, has this generalization been found before or is it wrong?","I used a flawed approach to generalizing Basel-like problems, Please refer: https://math.stackexchange.com/q/4769685 I assumed (for which the roots are becomes 1) for deriving the Basel problem in the cited answer, if instead I used (for which the roots are becomes ) the resulting summation would be: Which results in the value These results can be seemingly generalized as (Where ): (For n>1) However I acknowledge that the method I used is fundamentally flawed. Is there an alternate derivation for finding the value of the summation and by extension the observed generalization? If yes, has this generalization been found before or is it wrong?","\cos=0 \dfrac{\pi}{2},\dfrac{-\pi}{2},\dfrac{3\pi}{2},\cdots a_0 \cos=\dfrac{1}{\sqrt{2}} \dfrac{\pi}{4},\dfrac{9\pi}{4},\dfrac{-7\pi}{4},\cdots a_0 1-\dfrac{1}{\sqrt{2}} \dfrac{1}{1^2}+\dfrac{1}{7^2}+\dfrac{1}{9^2}+\dfrac{1}{15^2}+\dfrac{1}{17^2}+\cdots \dfrac{\pi^2\cdot(\sqrt{2}(\sqrt{2}+1))}{32}=\dfrac{1}{1^2}+\dfrac{1}{7^2}+\dfrac{1}{9^2}+\dfrac{1}{15^2}+\dfrac{1}{17^2}+\cdots X_e=\dfrac{\pi}{n} \dfrac{X_e^2}{2}(\csc^2(X_e)(1+\cos(X_e)))=\dfrac{\pi^2}{2\cdot n^2}(\csc^2(\dfrac{\pi}{n})(1+\cos(\dfrac{\pi}{n})))=\dfrac{1}{1^2}+\dfrac{1}{(2n-1)^2}+\dfrac{1}{(2n+1)^2}+\dfrac{1}{(1-4n)^2}+\dfrac{1}{(1+4n)^2}+\cdots","['sequences-and-series', 'trigonometry']"
59,Evaluate $\sum_{k\ge1}\frac{(-1)^{k+1}}{k^2}\log\left[ \frac{\Gamma\left(1+\frac{k}{2}\right)}{\Gamma\left(\frac12+\frac{k}{2}\right)} \right]$,Evaluate,\sum_{k\ge1}\frac{(-1)^{k+1}}{k^2}\log\left[ \frac{\Gamma\left(1+\frac{k}{2}\right)}{\Gamma\left(\frac12+\frac{k}{2}\right)} \right],"I am struggling to evaluate the following series: $$\mathcal{S}=\sum_{k=1}^\infty\frac{(-1)^{k+1}}{k^2}\log\left[ \frac{\Gamma\left(1+\frac{k}{2}\right)}{\Gamma\left(\frac12+\frac{k}{2}\right)} \right]=-0.13360...$$ From what I tried, I figured out that, if a closed form does exist, it must be really difficult to find. Here are my attempts: Attempt (1): using the fact that, for $\Re(z)>0$ and $\Re(z-x)>0$ $$\frac{\Gamma(z+1)}{\Gamma(z+1-x)}=e^{-\gamma x}\prod_{n=1}^\infty\left[ \left(1-\frac{x}{z+n}\right)e^{\frac{x}{n}} \right]$$ $$\implies \frac{\Gamma(z+1)}{\Gamma\left(z+\frac12\right)}=e^{-\frac{\gamma}{2}}\prod_{n=1}^\infty\left[ \left(1-\frac{1}{2(z+n)}\right)e^{\frac{1}{2n}} \right]$$ $$\implies \frac{\Gamma\left(1+\frac{k}{2}\right)}{\Gamma\left(\frac12+\frac{k}{2}\right)}=e^{-\frac{\gamma}{2}}\prod_{n=1}^\infty\left[ \left(1-\frac{1}{k+2n}\right)e^{\frac{1}{2n}} \right]$$ $$\implies \log\left[ \frac{\Gamma\left(1+\frac{k}{2}\right)}{\Gamma\left(\frac12+\frac{k}{2}\right)} \right]=-\frac{\gamma}{2}+\sum_{n=1}^\infty \left[\frac{1}{2n}+\log\left(1-\frac{1}{k+2n}\right)\right]$$ and here the tough part is the double sum that we end up with after plugging this value into the original $\mathcal{S}$ . Notice that all these steps where valid only for $k>1$ , so we would get $$\mathcal{S}=\log\left(\frac{\sqrt{\pi}}{2}\right)+\frac{\gamma}{2}\left(1-\frac{\pi^2}{12} \right) +\sum_{k=2}^\infty \sum_{n=1}^\infty \frac{(-1)^{k+1}}{k^2}\left[\frac{1}{2n}+\log\left(1-\frac{1}{k+2n}\right)\right]$$ which had me stuck. Attempt (2): I tried splitting the sum into even and odd terms, in order to get rid of the gamma functions. For instance, the odd terms form the following series: $$\mathcal{S_1}=\sum_{k=0}^\infty\frac{1}{(2k+1)^2}\log\left[ \frac{\Gamma(k+1+\frac12)}{\Gamma(k+1)} \right]$$ Now, using the fact that $$\frac{\Gamma(n+\frac12)}{\Gamma (n)}={{2n} \choose n}\frac{n}{4^n}\sqrt{\pi}$$ we have $$\mathcal{S_1}=\sum_{k=0}^\infty\frac{1}{(2k+1)^2}\log\left[{{2k} \choose k}\frac{2k+1}{4^k}\frac{\sqrt{\pi}}{2} \right]$$ $$=\frac{\pi^2}{8}\log\left(\frac{\sqrt{\pi}}{2}\right)+\sum_{k=0}^\infty\frac{1}{(2k+1)^2}\log\left[{{2k} \choose k}\frac{2k+1}{4^k} \right]$$ but now this series has this $\log$ term that is difficult to handle. We can't even split it using $\log$ properties, since the resulting series wouldn't converge at all. Attempt (3): It can be shown that $$\int_0^1\int_0^1\frac{\log(1+x^a)}{1+x}\text{d}x \text{d}a=2\log^22+\frac{\pi^2}{24}\log\pi+\mathcal{S}$$ and notice that here, changing the order of integration is allowed. I couldn't evaluate this double integral either in the end. EDIT: Attempt (4): Using this we can rewrite $\mathcal{S}$ as: $$\mathcal{S}=-\frac{\pi^2}{24}\log\pi-\int_0^1\frac{\text{Li}_2(-x)+\frac{\pi^2}{12}}{(x+1)\log x}\text{d}x$$ and this integral is similar to the ones that appear here and here , so maybe it can be expressed as a series involving harmonic numbers as well?","I am struggling to evaluate the following series: From what I tried, I figured out that, if a closed form does exist, it must be really difficult to find. Here are my attempts: Attempt (1): using the fact that, for and and here the tough part is the double sum that we end up with after plugging this value into the original . Notice that all these steps where valid only for , so we would get which had me stuck. Attempt (2): I tried splitting the sum into even and odd terms, in order to get rid of the gamma functions. For instance, the odd terms form the following series: Now, using the fact that we have but now this series has this term that is difficult to handle. We can't even split it using properties, since the resulting series wouldn't converge at all. Attempt (3): It can be shown that and notice that here, changing the order of integration is allowed. I couldn't evaluate this double integral either in the end. EDIT: Attempt (4): Using this we can rewrite as: and this integral is similar to the ones that appear here and here , so maybe it can be expressed as a series involving harmonic numbers as well?",\mathcal{S}=\sum_{k=1}^\infty\frac{(-1)^{k+1}}{k^2}\log\left[ \frac{\Gamma\left(1+\frac{k}{2}\right)}{\Gamma\left(\frac12+\frac{k}{2}\right)} \right]=-0.13360... \Re(z)>0 \Re(z-x)>0 \frac{\Gamma(z+1)}{\Gamma(z+1-x)}=e^{-\gamma x}\prod_{n=1}^\infty\left[ \left(1-\frac{x}{z+n}\right)e^{\frac{x}{n}} \right] \implies \frac{\Gamma(z+1)}{\Gamma\left(z+\frac12\right)}=e^{-\frac{\gamma}{2}}\prod_{n=1}^\infty\left[ \left(1-\frac{1}{2(z+n)}\right)e^{\frac{1}{2n}} \right] \implies \frac{\Gamma\left(1+\frac{k}{2}\right)}{\Gamma\left(\frac12+\frac{k}{2}\right)}=e^{-\frac{\gamma}{2}}\prod_{n=1}^\infty\left[ \left(1-\frac{1}{k+2n}\right)e^{\frac{1}{2n}} \right] \implies \log\left[ \frac{\Gamma\left(1+\frac{k}{2}\right)}{\Gamma\left(\frac12+\frac{k}{2}\right)} \right]=-\frac{\gamma}{2}+\sum_{n=1}^\infty \left[\frac{1}{2n}+\log\left(1-\frac{1}{k+2n}\right)\right] \mathcal{S} k>1 \mathcal{S}=\log\left(\frac{\sqrt{\pi}}{2}\right)+\frac{\gamma}{2}\left(1-\frac{\pi^2}{12} \right) +\sum_{k=2}^\infty \sum_{n=1}^\infty \frac{(-1)^{k+1}}{k^2}\left[\frac{1}{2n}+\log\left(1-\frac{1}{k+2n}\right)\right] \mathcal{S_1}=\sum_{k=0}^\infty\frac{1}{(2k+1)^2}\log\left[ \frac{\Gamma(k+1+\frac12)}{\Gamma(k+1)} \right] \frac{\Gamma(n+\frac12)}{\Gamma (n)}={{2n} \choose n}\frac{n}{4^n}\sqrt{\pi} \mathcal{S_1}=\sum_{k=0}^\infty\frac{1}{(2k+1)^2}\log\left[{{2k} \choose k}\frac{2k+1}{4^k}\frac{\sqrt{\pi}}{2} \right] =\frac{\pi^2}{8}\log\left(\frac{\sqrt{\pi}}{2}\right)+\sum_{k=0}^\infty\frac{1}{(2k+1)^2}\log\left[{{2k} \choose k}\frac{2k+1}{4^k} \right] \log \log \int_0^1\int_0^1\frac{\log(1+x^a)}{1+x}\text{d}x \text{d}a=2\log^22+\frac{\pi^2}{24}\log\pi+\mathcal{S} \mathcal{S} \mathcal{S}=-\frac{\pi^2}{24}\log\pi-\int_0^1\frac{\text{Li}_2(-x)+\frac{\pi^2}{12}}{(x+1)\log x}\text{d}x,"['real-analysis', 'calculus', 'integration', 'sequences-and-series', 'analysis']"
60,Determining whether $\sum_{i=1}^\infty \frac{t^{i}}{{i}!} (\sum_{j=0}^{i-1} k^j)$ converges,Determining whether  converges,\sum_{i=1}^\infty \frac{t^{i}}{{i}!} (\sum_{j=0}^{i-1} k^j),"Let's consider a map $L$ between complex matrices: $L(A) = kA + B$ for some real value $k$ and matrix $B$ . I am trying to calculate $e^{tL}(A)$ for some real value $t>0$ . Here is my attempt: Since $L^n(A) = k^nA + \big(\sum_{i=0}^{n-1}k^i\big)B$ , we have: $e^{tL}(A) = A + tL(A) + \frac{t^2}{2!}L^2(A) + \frac{t^3}{3!}L^3(A) + \dotsc $ $= A + t(kA + B) + \frac{t^2}{2!}\big(k^2A + (k+1)B\big) + \frac{t^3}{3!}\big(k^3A + (k^2+k+1)B\big) + \dotsc $ $= \big(1 + k + \frac{(kt)^2}{2!} + \dotsc\big)A + \big(t + \frac{t^2}{2!}(k+1) + \frac{t^3}{3!}(k^2+k+1) + \dotsc \big)B$ $= e^{kt}A + \big(t + \frac{t^2}{2!}(k+1) + \frac{t^3}{3!}(k^2+k+1) + \dotsc \big)B$ . I am not sure how to calculate the coefficient for the matrix $B$ , which is $\sum_{i=1}^\infty \frac{t^{i}}{{i}!} (\sum_{j=0}^{i-1} k^j)$ . Does it converge/diverge? If it diverges, is it possible to obtain a condition on $k$ such that it converges?","Let's consider a map between complex matrices: for some real value and matrix . I am trying to calculate for some real value . Here is my attempt: Since , we have: . I am not sure how to calculate the coefficient for the matrix , which is . Does it converge/diverge? If it diverges, is it possible to obtain a condition on such that it converges?",L L(A) = kA + B k B e^{tL}(A) t>0 L^n(A) = k^nA + \big(\sum_{i=0}^{n-1}k^i\big)B e^{tL}(A) = A + tL(A) + \frac{t^2}{2!}L^2(A) + \frac{t^3}{3!}L^3(A) + \dotsc  = A + t(kA + B) + \frac{t^2}{2!}\big(k^2A + (k+1)B\big) + \frac{t^3}{3!}\big(k^3A + (k^2+k+1)B\big) + \dotsc  = \big(1 + k + \frac{(kt)^2}{2!} + \dotsc\big)A + \big(t + \frac{t^2}{2!}(k+1) + \frac{t^3}{3!}(k^2+k+1) + \dotsc \big)B = e^{kt}A + \big(t + \frac{t^2}{2!}(k+1) + \frac{t^3}{3!}(k^2+k+1) + \dotsc \big)B B \sum_{i=1}^\infty \frac{t^{i}}{{i}!} (\sum_{j=0}^{i-1} k^j) k,"['sequences-and-series', 'convergence-divergence']"
61,Series expansion for $\text{Li}_2(x)$? Why is this wrong?,Series expansion for ? Why is this wrong?,\text{Li}_2(x),"In this answer it is claimed by @ClaudeLeibovici that $\text{Li}_2(x)$ has the following power series expansion: $$S(x)=\sum_{n=0}^\infty \frac{\psi ^{(0)}\left(\frac{n+3}{2}\right)-\psi    ^{(0)}\left(\frac{n+2}{2}\right)}{2(n+1)}\,x^{2n+1}$$ However, this seems wrong to me, since $$S(1)\simeq0.5797622205888950\dots$$ $$\text{Li}_2(1)\simeq1.6449340668482\dots$$ and this is just one counterexample, they differ for every value of $x$ . To get the series, they suggest to take the series for $-\frac{\log (1-x)}{x}$ and integrate termwise, but the series expansion for this function is $$-\frac{\log (1-x)}{x}=\sum_{k=1}^{\infty}\frac{x^{k-1}}{k}$$ which, when integrated from $0$ to $z$ leads to $$\text{Li}_2(z)=\sum_{k=1}^{\infty}\frac{z^k}{k^2}$$ which is just the definition of the dilogarithm! So no digamma functions at all! Also, if you remove the $2$ in the denominator of the series (it could be a typo), the result is still wrong. Do you have any clue of what is going on here? Am I missing something? Or is this just wrong?","In this answer it is claimed by @ClaudeLeibovici that has the following power series expansion: However, this seems wrong to me, since and this is just one counterexample, they differ for every value of . To get the series, they suggest to take the series for and integrate termwise, but the series expansion for this function is which, when integrated from to leads to which is just the definition of the dilogarithm! So no digamma functions at all! Also, if you remove the in the denominator of the series (it could be a typo), the result is still wrong. Do you have any clue of what is going on here? Am I missing something? Or is this just wrong?","\text{Li}_2(x) S(x)=\sum_{n=0}^\infty \frac{\psi ^{(0)}\left(\frac{n+3}{2}\right)-\psi
   ^{(0)}\left(\frac{n+2}{2}\right)}{2(n+1)}\,x^{2n+1} S(1)\simeq0.5797622205888950\dots \text{Li}_2(1)\simeq1.6449340668482\dots x -\frac{\log (1-x)}{x} -\frac{\log (1-x)}{x}=\sum_{k=1}^{\infty}\frac{x^{k-1}}{k} 0 z \text{Li}_2(z)=\sum_{k=1}^{\infty}\frac{z^k}{k^2} 2","['calculus', 'integration', 'sequences-and-series']"
62,Does the series $\sum\limits_{n=1}^{\infty }(-1)^n\left ( \sqrt{n^2+4n+1}-\sqrt{n^2+n+4} \right )$ converge?,Does the series  converge?,\sum\limits_{n=1}^{\infty }(-1)^n\left ( \sqrt{n^2+4n+1}-\sqrt{n^2+n+4} \right ),Check for absolute and conditional convergence $$\sum_{n=1}^{\infty }(-1)^n\left ( \sqrt{n^2+4n+1}-\sqrt{n^2+n+4} \right )$$ My attempt: $$\sum_{n=1}^{\infty }(-1)^n\left ( \sqrt{n^2+4n+1}-\sqrt{n^2+n+4} \right )=$$ $$=\sum_{n=1}^{\infty }(-1)^n\left ( \sqrt{n^2+4n+1}-\sqrt{n^2+n+4} \right )\cdot \frac{\sqrt{n^2+4n+1}+\sqrt{n^2+n+4}}{\sqrt{n^2+4n+1}+\sqrt{n^2+n+4}}=$$ $$=\sum_{n=1}^{\infty }(-1)^n\frac{3n-3}{\sqrt{n^2+4n+1}+\sqrt{n^2+n+4}}$$ $$\frac{3n-3}{\sqrt{n^2+4n+1}+\sqrt{n^2+n+4}}=3\cdot \frac{n-1}{n\sqrt{1+\frac{4}{n}+\frac{1}{n^2}}+n\sqrt{1+\frac{1}{n}+\frac{4}{n^2}}}=\frac{3}{n}\cdot \frac{n-1}{n+2+\mathcal{O}\left ( \frac{1}{n} \right )+n+\frac{1}{2}+\mathcal{O}\left ( \frac{1}{n} \right )}=\frac{3}{n}\cdot \frac{n-1}{2n+\frac{3}{2}+\mathcal{O}\left ( \frac{1}{n} \right )}=\frac{3}{2}-\frac{27}{8n}+\mathcal{O}\left ( \frac{1}{n} \right )$$ I have found that the series does not converge and does not converge at all. Did I solve the problem correctly? Question: What can I say about conditional convergence?,Check for absolute and conditional convergence My attempt: I have found that the series does not converge and does not converge at all. Did I solve the problem correctly? Question: What can I say about conditional convergence?,\sum_{n=1}^{\infty }(-1)^n\left ( \sqrt{n^2+4n+1}-\sqrt{n^2+n+4} \right ) \sum_{n=1}^{\infty }(-1)^n\left ( \sqrt{n^2+4n+1}-\sqrt{n^2+n+4} \right )= =\sum_{n=1}^{\infty }(-1)^n\left ( \sqrt{n^2+4n+1}-\sqrt{n^2+n+4} \right )\cdot \frac{\sqrt{n^2+4n+1}+\sqrt{n^2+n+4}}{\sqrt{n^2+4n+1}+\sqrt{n^2+n+4}}= =\sum_{n=1}^{\infty }(-1)^n\frac{3n-3}{\sqrt{n^2+4n+1}+\sqrt{n^2+n+4}} \frac{3n-3}{\sqrt{n^2+4n+1}+\sqrt{n^2+n+4}}=3\cdot \frac{n-1}{n\sqrt{1+\frac{4}{n}+\frac{1}{n^2}}+n\sqrt{1+\frac{1}{n}+\frac{4}{n^2}}}=\frac{3}{n}\cdot \frac{n-1}{n+2+\mathcal{O}\left ( \frac{1}{n} \right )+n+\frac{1}{2}+\mathcal{O}\left ( \frac{1}{n} \right )}=\frac{3}{n}\cdot \frac{n-1}{2n+\frac{3}{2}+\mathcal{O}\left ( \frac{1}{n} \right )}=\frac{3}{2}-\frac{27}{8n}+\mathcal{O}\left ( \frac{1}{n} \right ),"['real-analysis', 'calculus', 'sequences-and-series', 'summation']"
63,"Proof of $\inf\left \{ \frac{\mathrm{d} (n^2)}{\mathrm{d} (n)} \; \bigg| \; n \in \mathbb{N} \right \}=0$, where $d(n)$ is the sum of digits of $n$","Proof of , where  is the sum of digits of",\inf\left \{ \frac{\mathrm{d} (n^2)}{\mathrm{d} (n)} \; \bigg| \; n \in \mathbb{N} \right \}=0 d(n) n,"So I wanted to find the infimum of the set described in the title, and I'm pretty confident on what the subsequence should be to ensure a 0 infimum. $[4899,4899899999,4899899999899999999999, \dotsc]$ , where the next term in the sequence is the previous + '8' + '9' * $(2s+1)$ , where $s$ is the length of the previous set of consecutive nines. In the sequence I provided, it goes 2,5,11... (I'm fairly confident 1,3,7,15... also works). But a proof of this eludes me. I tried some funky stuff with the multinomial theorem and binomial theorem $(10^6 4899 + 899999)^2$ and tried to chunk it based on the first section and second but I really couldn't go anywhere due to the $2\cdot 899999 \cdot 10^6 \cdot 4899$ term. EDIT: 49 is a good starting term to look at.","So I wanted to find the infimum of the set described in the title, and I'm pretty confident on what the subsequence should be to ensure a 0 infimum. , where the next term in the sequence is the previous + '8' + '9' * , where is the length of the previous set of consecutive nines. In the sequence I provided, it goes 2,5,11... (I'm fairly confident 1,3,7,15... also works). But a proof of this eludes me. I tried some funky stuff with the multinomial theorem and binomial theorem and tried to chunk it based on the first section and second but I really couldn't go anywhere due to the term. EDIT: 49 is a good starting term to look at.","[4899,4899899999,4899899999899999999999, \dotsc] (2s+1) s (10^6 4899 + 899999)^2 2\cdot 899999 \cdot 10^6 \cdot 4899","['sequences-and-series', 'number-theory', 'recreational-mathematics', 'supremum-and-infimum', 'decimal-expansion']"
64,Show that $\sum_{k=1}^\infty 1/(k(k+1)(k+1)!)=3-e$,Show that,\sum_{k=1}^\infty 1/(k(k+1)(k+1)!)=3-e,"This is my attempt. I start with calling the sequence $x_n$ : $$x_n = \sum_{k=1}^{n} \frac{1}{k(k+1)(k+1)!}$$ Using partial fraction decomposition: $$\frac{1}{k(k+1)(k+1)!} = \frac{A}{k} + \frac{B}{k+1} + \frac{C}{(k+1)!}$$ Multiply both sides by $$(k(k+1)(k+1)!$$ $$1 = A(k+1)(k+1)! + B(k)(k+1)! + C(k)(k+1)$$ Using $$k=0 \rightarrow A=1$$ , $$k=-1 \rightarrow B=-1$$ , and $$k=1 \rightarrow C=-\frac{1}{2}$$ Rewrite the sequence: $$\sum_{k=1}^{n} \left[\frac{1}{k} - \frac{1}{k+1} - \frac{1}{2(k+1)!}\right]$$ The first two terms form a telescoping series: $$1 - \left(-\frac{1}{2} + \frac{1}{2}\right) + \left(\frac{1}{3} - \frac{1}{3}\right) + \ldots + \left(\frac{1}{n} - \frac{1}{n+1}\right) = 1 - \frac{1}{n+1}$$ For the last term in the sequence, we can add and subtract $$\left(\frac{1}{0!} + \frac{1}{1!}\right)$$ . Now, the last step is to sum the two results: $$1 - \frac{1}{n+1} - \frac{1}{2} \sum_{k=-1}^{n} \frac{1}{(k+1)!} + \frac{1}{2}\left(\frac{1}{0!} + \frac{1}{1!}\right)$$ Taking the limit as (n) approaches infinity, we get: $$1 - 0 - \frac{e}{2} + 1 = 2 - \frac{e}{2}$$ ""The right answer is $3-e$ ."" Where is the mistake and I tried so much to use partial fraction decomposition method but it didn't work😔 Last thing I will drag the book's solution for this question: I want someone to help me know how did the author evaluate the right-hand side equation??","This is my attempt. I start with calling the sequence : Using partial fraction decomposition: Multiply both sides by Using , , and Rewrite the sequence: The first two terms form a telescoping series: For the last term in the sequence, we can add and subtract . Now, the last step is to sum the two results: Taking the limit as (n) approaches infinity, we get: ""The right answer is ."" Where is the mistake and I tried so much to use partial fraction decomposition method but it didn't work😔 Last thing I will drag the book's solution for this question: I want someone to help me know how did the author evaluate the right-hand side equation??",x_n x_n = \sum_{k=1}^{n} \frac{1}{k(k+1)(k+1)!} \frac{1}{k(k+1)(k+1)!} = \frac{A}{k} + \frac{B}{k+1} + \frac{C}{(k+1)!} (k(k+1)(k+1)! 1 = A(k+1)(k+1)! + B(k)(k+1)! + C(k)(k+1) k=0 \rightarrow A=1 k=-1 \rightarrow B=-1 k=1 \rightarrow C=-\frac{1}{2} \sum_{k=1}^{n} \left[\frac{1}{k} - \frac{1}{k+1} - \frac{1}{2(k+1)!}\right] 1 - \left(-\frac{1}{2} + \frac{1}{2}\right) + \left(\frac{1}{3} - \frac{1}{3}\right) + \ldots + \left(\frac{1}{n} - \frac{1}{n+1}\right) = 1 - \frac{1}{n+1} \left(\frac{1}{0!} + \frac{1}{1!}\right) 1 - \frac{1}{n+1} - \frac{1}{2} \sum_{k=-1}^{n} \frac{1}{(k+1)!} + \frac{1}{2}\left(\frac{1}{0!} + \frac{1}{1!}\right) 1 - 0 - \frac{e}{2} + 1 = 2 - \frac{e}{2} 3-e,"['real-analysis', 'sequences-and-series', 'limits', 'summation']"
65,Prove a sequence of functions is bounded,Prove a sequence of functions is bounded,,"Context I am reading the text book Calculus With Applications, by Peter D. Lax and have a problem in the section of 'Approximating $e^x$ '. The way to do this is to take the functions $e_n(x)=(1+\frac{x}{n})^n$ and prove they converge uniformly to the function $e^x$ . The problem I confront is in the first step, which is to prove the sequence $\{e_n(x)\}$ is bounded. Complete problem description Show that for each $x>0$ , the sequence $\{e_n(x)\}$ is bounded. Hint: For $x<2$ , $e_n(x)<(1+\frac{2}{n})^n$ . Set $n=2m$ to conclude that $e_m(x)<e^2$ . My progress The confused part to me is the hint, and I wrote something like: for $x<c$ $e_n(x)=(1+\frac{x}{n})^n<(1+\frac{c}{n})^n$ let $n=cm$ $e_{cm}(x)=(1+\frac{x}{cm})^{cm}<(1+\frac{1}{m})^{m\cdot c}=e_m^c$ Now I'm stuck, especially don't know how to do with $e_{cm}(x)$ Other thinking Since the book does not clearly define the bound of a sequence of functions and how to find it. I want to make sure if it is the same as I thought: For a sequence of functions to be bounded, we need to prove that for every $x$ (in their common domain D), the sequence of numbers $\{f_n(x)\}$ is bounded.","Context I am reading the text book Calculus With Applications, by Peter D. Lax and have a problem in the section of 'Approximating '. The way to do this is to take the functions and prove they converge uniformly to the function . The problem I confront is in the first step, which is to prove the sequence is bounded. Complete problem description Show that for each , the sequence is bounded. Hint: For , . Set to conclude that . My progress The confused part to me is the hint, and I wrote something like: for let Now I'm stuck, especially don't know how to do with Other thinking Since the book does not clearly define the bound of a sequence of functions and how to find it. I want to make sure if it is the same as I thought: For a sequence of functions to be bounded, we need to prove that for every (in their common domain D), the sequence of numbers is bounded.",e^x e_n(x)=(1+\frac{x}{n})^n e^x \{e_n(x)\} x>0 \{e_n(x)\} x<2 e_n(x)<(1+\frac{2}{n})^n n=2m e_m(x)<e^2 x<c e_n(x)=(1+\frac{x}{n})^n<(1+\frac{c}{n})^n n=cm e_{cm}(x)=(1+\frac{x}{cm})^{cm}<(1+\frac{1}{m})^{m\cdot c}=e_m^c e_{cm}(x) x \{f_n(x)\},"['calculus', 'sequences-and-series']"
66,"$f$ is holomorphic in $U(z_0,\delta)$ $\implies\displaystyle{\lim_{n\to\infty}\frac{f(z_n)-f(w_n)}{z_n-w_n}}=f'(z_0)$.",is holomorphic in  .,"f U(z_0,\delta) \implies\displaystyle{\lim_{n\to\infty}\frac{f(z_n)-f(w_n)}{z_n-w_n}}=f'(z_0)","Suppose $f$ is holomorphic in $U(z_0,\delta)$ and $z_n\to z_0,w_n\to z_0\ (n\to\infty), z_n\neq w_n$ , then $$\lim_{n\to\infty}\frac{f(z_n)-f(w_n)}{z_n-w_n}=f'(z_0).$$ Unlike in real analysis, we can't use MVT (MVT is not ture for holomorphic functions). I can prove the result by using power series expansion as follows: WLG, we can suppose $z_0=0$ , and then $$f(z)=\sum_{k=0}^{\infty}a_kz^k,\quad z\in U(0,\delta).$$ $$f(z_n)-f(w_n)=\sum_{k=1}^{\infty}a_k\left(z^k_n-w^k_n\right) =a_1(z_n-w_n)+\sum_{k=2}^{\infty}a_k\left(z^k_n-w^k_n\right).$$ We need only to prove $$\lim_{n\to\infty}\frac{\sum\limits_{k=2}^{\infty}a_k\left(z^k_n-w^k_n\right)}{z_n-w_n}=0,$$ which is not difficult by using the umiform convergence. If there is another method such as $\epsilon-N$ language. Any help or hints will be welcomed.","Suppose is holomorphic in and , then Unlike in real analysis, we can't use MVT (MVT is not ture for holomorphic functions). I can prove the result by using power series expansion as follows: WLG, we can suppose , and then We need only to prove which is not difficult by using the umiform convergence. If there is another method such as language. Any help or hints will be welcomed.","f U(z_0,\delta) z_n\to z_0,w_n\to z_0\ (n\to\infty), z_n\neq w_n \lim_{n\to\infty}\frac{f(z_n)-f(w_n)}{z_n-w_n}=f'(z_0). z_0=0 f(z)=\sum_{k=0}^{\infty}a_kz^k,\quad z\in U(0,\delta). f(z_n)-f(w_n)=\sum_{k=1}^{\infty}a_k\left(z^k_n-w^k_n\right)
=a_1(z_n-w_n)+\sum_{k=2}^{\infty}a_k\left(z^k_n-w^k_n\right). \lim_{n\to\infty}\frac{\sum\limits_{k=2}^{\infty}a_k\left(z^k_n-w^k_n\right)}{z_n-w_n}=0, \epsilon-N","['sequences-and-series', 'complex-analysis']"
67,Testing convergence of $ \sum_{n=1}^{\infty} (-1)^n \frac{\sqrt[n]{3}-1}{\cot(\frac{1}{n})+(-1)^n} $,Testing convergence of, \sum_{n=1}^{\infty} (-1)^n \frac{\sqrt[n]{3}-1}{\cot(\frac{1}{n})+(-1)^n} ,I'm having trouble testing the convergence of the following series: $$ \sum_{n=1}^{\infty} (-1)^n \frac{\sqrt[n]{3}-1}{\cot(\frac{1}{n})+(-1)^n} $$ Any advice?,I'm having trouble testing the convergence of the following series: Any advice?,"
\sum_{n=1}^{\infty} (-1)^n \frac{\sqrt[n]{3}-1}{\cot(\frac{1}{n})+(-1)^n}
","['calculus', 'sequences-and-series', 'convergence-divergence']"
68,How to prove $\sum_{n=1}^{+\infty}\dfrac{1}{(n+1)\sqrt[e]{n}}$ converges to a number $<e$.,How to prove  converges to a number .,\sum_{n=1}^{+\infty}\dfrac{1}{(n+1)\sqrt[e]{n}} <e,"I can prove that $\sum_{n=1}^{+\infty}\dfrac{1}{(n+1)\sqrt[e]{n}}$ converges, but don't know how to transform the $\sqrt[e]{n}$ item to prove it less than $e$ , could someone help/hint me?","I can prove that converges, but don't know how to transform the item to prove it less than , could someone help/hint me?",\sum_{n=1}^{+\infty}\dfrac{1}{(n+1)\sqrt[e]{n}} \sqrt[e]{n} e,"['calculus', 'sequences-and-series', 'convergence-divergence']"
69,Multiplicative strictly increasing sequences,Multiplicative strictly increasing sequences,,"Suppose $1=x_1<x_2<x_3<\cdots$ is a strictly increasing sequence such that $x_{nm}=x_n x_m$ for all $n,m$ . Is it true that there has to exist some $c>0$ such that $x_n=n^c$ ?",Suppose is a strictly increasing sequence such that for all . Is it true that there has to exist some such that ?,"1=x_1<x_2<x_3<\cdots x_{nm}=x_n x_m n,m c>0 x_n=n^c","['sequences-and-series', 'analysis']"
70,"What is the sum $\sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{1}{(m+in)^\alpha}$ equal to?",What is the sum  equal to?,"\sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{1}{(m+in)^\alpha}","I had a look at this webpage , which led me to wonder what $$\sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{1}{(m+in)^\alpha}$$ would equal to. My thoughts are as follows: \begin{align} \sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{1}{(m+in)^\alpha}&=\sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{(m-in)^\alpha}{\left(m^2+n^2\right)^\alpha} \\ &=\sum_{m\in\mathbb{Z}/\{0\}}\frac{1}{m^\alpha}+\sum_{n\in\mathbb{Z}/\{0\}}\frac{1}{(in)^\alpha}+\sum^\infty_{m=-\infty}\sum^\infty_{n=1}\frac{(m-in)^\alpha+(m+in)^\alpha+(-m+in)^\alpha+(-m-in)^\alpha}{\left(m^2+n^2\right)^\alpha} \\ &=\sum_{m=1}^\infty\frac{1}{m^\alpha}+\sum_{m=1}^\infty\frac{1}{(-m)^\alpha}+\sum_{n=1}^\infty\frac{1}{(in)^\alpha}+\sum_{n=1}^\infty\frac{1}{(-in)^\alpha}+\sum^\infty_{m=1}\sum^\infty_{n=1}\frac{\left(1+(-1)^\alpha\right)\left[(m-in)^\alpha+(m+in)^\alpha\right]}{\left(m^2+n^2\right)^\alpha} \\ &=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+\sum^\infty_{m=1}\sum^\infty_{n=1}\frac{\left(1+(-1)^\alpha\right)\cdot2\sqrt{m^2+n^2}^\alpha\cos\left[\alpha\arctan\left(\frac nm\right)\right]}{\left(m^2+n^2\right)^\alpha} \\ &=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+2\left(1+(-1)^\alpha\right)\sum^\infty_{m=1}\sum^\infty_{n=1}\frac{\cos\left[\alpha\arctan\left(\frac nm\right)\right]}{\left(m^2+n^2\right)^\frac\alpha2} \\ &=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+2\left(1+(-1)^\alpha\right)\sum^\infty_{k=1}\sum_{\gcd(m,n)=1}\frac{\cos\left[\alpha\arctan\left(\frac{kn}{km}\right)\right]}{\left(k^2m^2+k^2n^2\right)^\frac\alpha2} \\ &=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+2\left(1+(-1)^\alpha\right)\sum^\infty_{k=1}\sum_{\gcd(m,n)=1}\frac{\cos\left[\alpha\arctan\left(\frac{n}{m}\right)\right]}{\left(k^2m^2+k^2n^2\right)^\frac\alpha2} \\ &=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+2\left(1+(-1)^\alpha\right)\sum^\infty_{k=1}\frac{1}{k^\alpha}\sum_{\gcd(m,n)=1}\frac{\cos\left[\alpha\arctan\left(\frac{n}{m}\right)\right]}{\left(m^2+n^2\right)^\frac\alpha2} \\ &=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha+2\left(1+(-1)^\alpha\right)\sum_{\gcd(m,n)=1}\frac{\cos\left[\alpha\arctan\left(\frac{n}{m}\right)\right]}{\left(m^2+n^2\right)^\frac\alpha2}\right)\zeta(\alpha) \\ \end{align} Though I couldn't (and presumably lack the analytical ability to) simply the expression further. This seems tangentially related to the sum $$\sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{1}{(m^2+n^2)^\frac{\alpha}{2}}$$ which is equal to $4\beta\left(\frac{\alpha}{2}\right)\zeta\left(\frac{\alpha}{2}\right)$ , though I don't know how this sum can be applied.","I had a look at this webpage , which led me to wonder what would equal to. My thoughts are as follows: Though I couldn't (and presumably lack the analytical ability to) simply the expression further. This seems tangentially related to the sum which is equal to , though I don't know how this sum can be applied.","\sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{1}{(m+in)^\alpha} \begin{align}
\sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{1}{(m+in)^\alpha}&=\sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{(m-in)^\alpha}{\left(m^2+n^2\right)^\alpha} \\
&=\sum_{m\in\mathbb{Z}/\{0\}}\frac{1}{m^\alpha}+\sum_{n\in\mathbb{Z}/\{0\}}\frac{1}{(in)^\alpha}+\sum^\infty_{m=-\infty}\sum^\infty_{n=1}\frac{(m-in)^\alpha+(m+in)^\alpha+(-m+in)^\alpha+(-m-in)^\alpha}{\left(m^2+n^2\right)^\alpha} \\
&=\sum_{m=1}^\infty\frac{1}{m^\alpha}+\sum_{m=1}^\infty\frac{1}{(-m)^\alpha}+\sum_{n=1}^\infty\frac{1}{(in)^\alpha}+\sum_{n=1}^\infty\frac{1}{(-in)^\alpha}+\sum^\infty_{m=1}\sum^\infty_{n=1}\frac{\left(1+(-1)^\alpha\right)\left[(m-in)^\alpha+(m+in)^\alpha\right]}{\left(m^2+n^2\right)^\alpha} \\
&=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+\sum^\infty_{m=1}\sum^\infty_{n=1}\frac{\left(1+(-1)^\alpha\right)\cdot2\sqrt{m^2+n^2}^\alpha\cos\left[\alpha\arctan\left(\frac nm\right)\right]}{\left(m^2+n^2\right)^\alpha} \\
&=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+2\left(1+(-1)^\alpha\right)\sum^\infty_{m=1}\sum^\infty_{n=1}\frac{\cos\left[\alpha\arctan\left(\frac nm\right)\right]}{\left(m^2+n^2\right)^\frac\alpha2} \\
&=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+2\left(1+(-1)^\alpha\right)\sum^\infty_{k=1}\sum_{\gcd(m,n)=1}\frac{\cos\left[\alpha\arctan\left(\frac{kn}{km}\right)\right]}{\left(k^2m^2+k^2n^2\right)^\frac\alpha2} \\
&=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+2\left(1+(-1)^\alpha\right)\sum^\infty_{k=1}\sum_{\gcd(m,n)=1}\frac{\cos\left[\alpha\arctan\left(\frac{n}{m}\right)\right]}{\left(k^2m^2+k^2n^2\right)^\frac\alpha2} \\
&=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha\right)\zeta(\alpha)+2\left(1+(-1)^\alpha\right)\sum^\infty_{k=1}\frac{1}{k^\alpha}\sum_{\gcd(m,n)=1}\frac{\cos\left[\alpha\arctan\left(\frac{n}{m}\right)\right]}{\left(m^2+n^2\right)^\frac\alpha2} \\
&=\left(1+i^\alpha+(-1)^\alpha+(-i)^\alpha+2\left(1+(-1)^\alpha\right)\sum_{\gcd(m,n)=1}\frac{\cos\left[\alpha\arctan\left(\frac{n}{m}\right)\right]}{\left(m^2+n^2\right)^\frac\alpha2}\right)\zeta(\alpha) \\
\end{align} \sum_{(m, n)\in\mathbb{Z}\\(m,n)\neq(0,0)}\frac{1}{(m^2+n^2)^\frac{\alpha}{2}} 4\beta\left(\frac{\alpha}{2}\right)\zeta\left(\frac{\alpha}{2}\right)","['sequences-and-series', 'riemann-zeta', 'integer-lattices']"
71,Is $\|\cdot\|_{\pi} = \|\cdot\|$?,Is ?,\|\cdot\|_{\pi} = \|\cdot\|,"Let $\ell^{1}(\mathbb{N})$ be the space of complex-valued sequences such as: $$\|a\|_{\ell^{1}} = \sum_{n\in \mathbb{N}}|a_{n}| < +\infty$$ and set $\ell^{1}(\mathbb{R})\otimes \ell^{1}(\mathbb{R})$ to be the set of all finite sums of sequences of the form $a\otimes b = \{(a\otimes b)_{n,m}\}_{n,m \in \mathbb{N}}$ , with $(a\otimes b)_{n,m} = a_{n}b_{m}$ . If $c = \sum_{k}a_{k}\otimes b_{k}$ is an element of this space, define: $$\|c\| := \sum_{n,m}|\sum_{k}(a_{k}\otimes b_{k})_{n,m}|$$ In addition, define: $$\|c\|_{\pi} := \inf \sum_{k}\|a\|_{\ell^{1}}\|b\|_{\ell^{1}}$$ where the infimum is over all possible representations of $c$ as a sum of finite elements of $a_{k}\otimes b_{k}$ . Do $\|\cdot\|$ and $\|\cdot\|_{\pi}$ agree? I proved $\|\cdot\| \le \|\cdot\|_{\pi}$ but not the converse. I believe the $\|\cdot\|_{\pi}$ is called projective norm in the literature.","Let be the space of complex-valued sequences such as: and set to be the set of all finite sums of sequences of the form , with . If is an element of this space, define: In addition, define: where the infimum is over all possible representations of as a sum of finite elements of . Do and agree? I proved but not the converse. I believe the is called projective norm in the literature.","\ell^{1}(\mathbb{N}) \|a\|_{\ell^{1}} = \sum_{n\in \mathbb{N}}|a_{n}| < +\infty \ell^{1}(\mathbb{R})\otimes \ell^{1}(\mathbb{R}) a\otimes b = \{(a\otimes b)_{n,m}\}_{n,m \in \mathbb{N}} (a\otimes b)_{n,m} = a_{n}b_{m} c = \sum_{k}a_{k}\otimes b_{k} \|c\| := \sum_{n,m}|\sum_{k}(a_{k}\otimes b_{k})_{n,m}| \|c\|_{\pi} := \inf \sum_{k}\|a\|_{\ell^{1}}\|b\|_{\ell^{1}} c a_{k}\otimes b_{k} \|\cdot\| \|\cdot\|_{\pi} \|\cdot\| \le \|\cdot\|_{\pi} \|\cdot\|_{\pi}","['sequences-and-series', 'functional-analysis', 'analysis', 'normed-spaces']"
72,"Finding general expression of series expansion $A^{-1} = \sum_{n=0}^{\infty} (-1)^n a_n x^n$, $A = \sum_{n=0}^{\infty} a_n x^n$","Finding general expression of series expansion ,",A^{-1} = \sum_{n=0}^{\infty} (-1)^n a_n x^n A = \sum_{n=0}^{\infty} a_n x^n,"Let \begin{align} &A^{-1} = \sum_{n=0}^{\infty} (-1)^n a_n x^n \\ &A = \sum_{n=0}^{\infty} a_n x^n \end{align} Using the relation $A^{-1} A =1$ , I want to find the general expression for $a_n$ . My assumption and initial conditions are given as follows with $a_0=1, a_1=1$ . With this I find explicitly, $a_2= \frac{1}{2}$ , $a_3 = \frac{1}{4}$ , $a_4 = \frac{1}{8}$ , $a_5=0, \cdots$ . How I can set the general expression for $a_n$ ? After seeing the comment from @metamorphy,  I want additionally impose all odd powers vanishes except $a_3$ . i.e., $a_{2n+1}=0$ for $n>1$ . In this case, is this fix the uniqueness? Additionally I relax the positiveness condition for $a_n$ .","Let Using the relation , I want to find the general expression for . My assumption and initial conditions are given as follows with . With this I find explicitly, , , , . How I can set the general expression for ? After seeing the comment from @metamorphy,  I want additionally impose all odd powers vanishes except . i.e., for . In this case, is this fix the uniqueness? Additionally I relax the positiveness condition for .","\begin{align}
&A^{-1} = \sum_{n=0}^{\infty} (-1)^n a_n x^n \\
&A = \sum_{n=0}^{\infty} a_n x^n
\end{align} A^{-1} A =1 a_n a_0=1, a_1=1 a_2= \frac{1}{2} a_3 = \frac{1}{4} a_4 = \frac{1}{8} a_5=0, \cdots a_n a_3 a_{2n+1}=0 n>1 a_n","['sequences-and-series', 'recurrence-relations', 'power-series', 'formal-power-series']"
73,How to calculate $\sum _{n=1}^{\infty }\:\left(\frac{2}{3}\right)^n\sin\left(\frac{\pi }{3}n\right)$,How to calculate,\sum _{n=1}^{\infty }\:\left(\frac{2}{3}\right)^n\sin\left(\frac{\pi }{3}n\right),"I believe that Complex numbers should be used in order to calculate this. Let $z = \frac{2}{3}e^{\frac{i\pi }{3}}$ , So, $$\sum _{n=1}^{\infty }\left(\frac{2}{3}\right)^n\sin\left(\frac{\pi }{3}n\right)=\sum _{n=1}^{\infty }\text{Im}\left(\frac{2}{3}e^{\frac{i\pi}{3}}\right)^n=\text{Im}\left[\sum _{n=1}^{\infty }\left(\frac{2}{3}e^{\frac{i\pi}{3}}\right)^n\right]$$ Is this correct? How do you go about solving it further? I believe this might be a infinite geometric series where, $a_1 = z, q = z$ ?","I believe that Complex numbers should be used in order to calculate this. Let , So, Is this correct? How do you go about solving it further? I believe this might be a infinite geometric series where, ?","z = \frac{2}{3}e^{\frac{i\pi }{3}} \sum _{n=1}^{\infty }\left(\frac{2}{3}\right)^n\sin\left(\frac{\pi }{3}n\right)=\sum _{n=1}^{\infty }\text{Im}\left(\frac{2}{3}e^{\frac{i\pi}{3}}\right)^n=\text{Im}\left[\sum _{n=1}^{\infty }\left(\frac{2}{3}e^{\frac{i\pi}{3}}\right)^n\right] a_1 = z, q = z","['sequences-and-series', 'complex-numbers']"
74,Existence of subsequences of sequences of real numbers under certain conditions,Existence of subsequences of sequences of real numbers under certain conditions,,"I want to show that if $n > srp$ , then any sequence of $n$ real numbers must contain either a strictly increasing subsequence of length greater than $s$ , a strictly decreasing subsequence of length greater than $r$ , or a constant subsequence of length greater than $p$ . I thought I can prove this by assuming that two of the conditions do NOT hold, and forcing the third as a consequence. We would have to do this thrice to complete the proof. But I am stuck after assuming the hypothesis. Is there a more direct way to prove this or am I on the right track?","I want to show that if , then any sequence of real numbers must contain either a strictly increasing subsequence of length greater than , a strictly decreasing subsequence of length greater than , or a constant subsequence of length greater than . I thought I can prove this by assuming that two of the conditions do NOT hold, and forcing the third as a consequence. We would have to do this thrice to complete the proof. But I am stuck after assuming the hypothesis. Is there a more direct way to prove this or am I on the right track?",n > srp n s r p,['real-analysis']
75,"$a_{m^2}=a_m^2,a_{m^2+k^2}=a_ma_k$ sequence",sequence,"a_{m^2}=a_m^2,a_{m^2+k^2}=a_ma_k","Sequence $\{a_n\},n\in\mathbb N_+$ with all terms positive integers satisfy $a_{m^2}=a_m^2,a_{m^2+k^2}=a_ma_k$ . Find $\{a_n\}$ . I suppose all terms of $\{a_n\}$ are $1$ . This problem makes me think of a lot of conclusions, including $n\in\mathbb{Z}_+$ can be written as the sum of two squares as long as for every prime $p\equiv3\pmod4$ there's $2\mid V_p(n)$ . $(m^2+n^2)^2=(m^2-n^2)^2+(2mn)^2$ . $(a^2+b^2)(c^2+d^2)=(ac+bd)^2+(ad-bc)^2=(ac-bd)^2+(ad+bc)^2$ . Perhaps we can let the first non- $1$ term of the sequence be $a_s$ and derive a contradiction?","Sequence with all terms positive integers satisfy . Find . I suppose all terms of are . This problem makes me think of a lot of conclusions, including can be written as the sum of two squares as long as for every prime there's . . . Perhaps we can let the first non- term of the sequence be and derive a contradiction?","\{a_n\},n\in\mathbb N_+ a_{m^2}=a_m^2,a_{m^2+k^2}=a_ma_k \{a_n\} \{a_n\} 1 n\in\mathbb{Z}_+ p\equiv3\pmod4 2\mid V_p(n) (m^2+n^2)^2=(m^2-n^2)^2+(2mn)^2 (a^2+b^2)(c^2+d^2)=(ac+bd)^2+(ad-bc)^2=(ac-bd)^2+(ad+bc)^2 1 a_s",[]
76,"If a sequence converges, then if its quotient converges, then it converges to less than or equal to one","If a sequence converges, then if its quotient converges, then it converges to less than or equal to one",,"I want to show the following. Let $a_n$ converge. If $\frac{a_{n+1}}{a_n}$ converges then $|\lim\frac{a_{n+1}}{a_n}|\leq 1$ . I attach my proof below, but I would be happy to see if there is a more elegant and simple one. I would think one could use the following theorem, but I do not know how: If $a_n$ converges and $\frac{a_{n+1}}{a_n}$ converges, then $\sqrt[n]{a_n}$ converges and $\lim\left(\frac{a_{n+1}}{a_n}\right)=\lim\left(\sqrt[n]{a_n}\right).$ My proof - mind that the students have only learned the definitions regarding convergence, basic theorems regarding convergence and convergence to infinity. They still haven't learned the theorems regarding convergence and monotonic series, partial limits, Cauchy series, etc. Let us assume that $a_n$ converges and $\frac{a_{n+1}}{a_n}$ converges. Let us denote $\lim(a_n)=L$ . $$\lim(a_{n+1})=\lim(\frac{a_{n+1}}{a_n}\cdot a_n)=\lim(\frac{a_{n+1}}{a_n})\lim(a_n).$$ $$L=\lim(\frac{a_{n+1}}{a_n})L,$$ $$L(1-\lim(\frac{a_{n+1}}{a_n}))=0,$$ $$L=0 \vee \lim(\frac{a_{n+1}}{a_n})=1.$$ The second case - proves our goal instantly. Let us assume that $L=0$ . Let us assume in negation that $\lim(\frac{a_{n+1}}{a_n})>1$ (we would also need to prove the other case). Let us denote $\lim(\frac{a_{n+1}}{a_n})=D$ . Because the limit of $\lim(\frac{a_{n+1}}{a_n})$ exists then: $$\forall \epsilon >0. \exists n_0.\forall n>n_0 . \lim(\frac{a_{n+1}}{a_n}) \in (d-\epsilon,D+\epsilon).$$ Specifically for $\epsilon=\frac{D-1}{2}$ . So: $\exists n_0.\forall n>n_0. D-\frac{D-1}{2}<\frac{a_{n+1}}{a_n}$ $\exists n_0.\forall n>n_0. \frac{D+1}{2}a_n<a_{n+1}$ Now because $a_n$ converges to 0 then: $\forall \epsilon>0.\exists n_0. \forall n>n_0. a_n\in (-\epsilon,\epsilon)$ But because $\exists n_0.\forall n>n_0. \frac{D+1}{2}a_n<a_{n+1}$ for some $\epsilon$ for all $n_0$ we could find a $n>n_0$ that $a_n\notin (-\epsilon,\epsilon)$ in negation with the assumption that $a_n$ converges.","I want to show the following. Let converge. If converges then . I attach my proof below, but I would be happy to see if there is a more elegant and simple one. I would think one could use the following theorem, but I do not know how: If converges and converges, then converges and My proof - mind that the students have only learned the definitions regarding convergence, basic theorems regarding convergence and convergence to infinity. They still haven't learned the theorems regarding convergence and monotonic series, partial limits, Cauchy series, etc. Let us assume that converges and converges. Let us denote . The second case - proves our goal instantly. Let us assume that . Let us assume in negation that (we would also need to prove the other case). Let us denote . Because the limit of exists then: Specifically for . So: Now because converges to 0 then: But because for some for all we could find a that in negation with the assumption that converges.","a_n \frac{a_{n+1}}{a_n} |\lim\frac{a_{n+1}}{a_n}|\leq 1 a_n \frac{a_{n+1}}{a_n} \sqrt[n]{a_n} \lim\left(\frac{a_{n+1}}{a_n}\right)=\lim\left(\sqrt[n]{a_n}\right). a_n \frac{a_{n+1}}{a_n} \lim(a_n)=L \lim(a_{n+1})=\lim(\frac{a_{n+1}}{a_n}\cdot a_n)=\lim(\frac{a_{n+1}}{a_n})\lim(a_n). L=\lim(\frac{a_{n+1}}{a_n})L, L(1-\lim(\frac{a_{n+1}}{a_n}))=0, L=0 \vee \lim(\frac{a_{n+1}}{a_n})=1. L=0 \lim(\frac{a_{n+1}}{a_n})>1 \lim(\frac{a_{n+1}}{a_n})=D \lim(\frac{a_{n+1}}{a_n}) \forall \epsilon >0. \exists n_0.\forall n>n_0 . \lim(\frac{a_{n+1}}{a_n}) \in (d-\epsilon,D+\epsilon). \epsilon=\frac{D-1}{2} \exists n_0.\forall n>n_0. D-\frac{D-1}{2}<\frac{a_{n+1}}{a_n} \exists n_0.\forall n>n_0. \frac{D+1}{2}a_n<a_{n+1} a_n \forall \epsilon>0.\exists n_0. \forall n>n_0. a_n\in (-\epsilon,\epsilon) \exists n_0.\forall n>n_0. \frac{D+1}{2}a_n<a_{n+1} \epsilon n_0 n>n_0 a_n\notin (-\epsilon,\epsilon) a_n","['calculus', 'sequences-and-series', 'solution-verification']"
77,How many sub-sums of the harmonic series converge to a given $x$?,How many sub-sums of the harmonic series converge to a given ?,x,"Pick some positive $x$ . $\hspace{0.5mm}$ Let $\mathcal{C}_x$ be the set of all subsets $S \subset \mathbb{Z}^{+}$ such that $\displaystyle{\hspace{1mm} \sum_{n \in S} \frac{1}{n} = x}$ . Is $\mathcal{C}_x$ countable? (There are follow-ups and generalizations of this question one might ask, too, which I omit here to keep it neat. $\hspace{0.5mm}$ However, answers to more general versions of this question are welcome.)","Pick some positive . Let be the set of all subsets such that . Is countable? (There are follow-ups and generalizations of this question one might ask, too, which I omit here to keep it neat. However, answers to more general versions of this question are welcome.)",x \hspace{0.5mm} \mathcal{C}_x S \subset \mathbb{Z}^{+} \displaystyle{\hspace{1mm} \sum_{n \in S} \frac{1}{n} = x} \mathcal{C}_x \hspace{0.5mm},"['real-analysis', 'sequences-and-series', 'cardinals']"
78,"On the log-cosine integral $\int\limits_0^{\pi/2}\ln(\cos(x))\,dx$",On the log-cosine integral,"\int\limits_0^{\pi/2}\ln(\cos(x))\,dx","I know that $$\mathcal I = \int\limits_0^{\pi/2}\ln(\cos(x))\,dx = -\frac\pi2 \ln(2)$$ and I am aware of a few different clever ways to demonstrate this result (e.g. MSE 4065767 and MSE 1992462 ). I would like to know if there's any way to wrap up the method I outline below. Substituting $t=\tan\left(\frac x2\right)$ yields $$\mathcal I= 2\int_0^1 \frac{\ln\left(\frac{1-t^2}{1+t^2}\right)}{1+t^2} \, dt = 2 \left(\underbrace{\int_0^1\frac{\ln(1-t^2)}{1+t^2}\,dt}_{\mathcal J^-} - \underbrace{\int_0^1\frac{\ln(1+t^2)}{1+t^2} \, dt}_{\mathcal J^+} \right)$$ Exploiting the series expansion for $\frac1{1+t^2}$ , we have $$\mathcal J^- = \int_0^1 \ln(1-t^2) \sum_{n=0}^\infty (-t^2)^n = \sum_{n=0}^\infty (-1)^n \underbrace{\int_0^1 t^{2n} \ln(1-t^2) \, dt}_{{J_n}^-}$$ and similarly, $$\mathcal J^+ = \sum_{n=0}^\infty \underbrace{\int_0^1 t^{2n} \ln(1+t^2) \, dt}_{{J_n}^+}$$ I derive the following recurrences for ${J_n}^{\pm}$ : $$\begin{cases}{J_0}^- = 2\ln(2) - 2 \\ {J_n}^- = \frac{2n-1}{(2n+1)^2} - \frac1{2n+1} + \frac{2n-1}{2n+1} {J_{n-1}}^- & \text{for }n\ge1\end{cases}$$ $$\begin{cases}{J_0}^+ = \ln(2) - 2 + \frac\pi2 \\ {J_n}^+ = \frac{2n-1}{(2n+1)^2} - \frac{2\ln(2)-1}{2n+1} - \frac{2n-1}{2n+1}{J_{n-1}}^+ & \text{for }n\ge1\end{cases}$$ where ${J_0}^\pm$ are found by exploiting the series for $\ln(1\pm t)$ and several others derived from the expansion of $\frac1{1-t}$ . I managed to solve these for ${J_n}^{\pm}$ , so that $$\mathcal J^- = \frac{(\ln(2)-1)\pi}2 + \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} \left(\sum_{i=0}^{n-1} \frac{2i+1}{2i+3} - n\right)$$ $$\mathcal J^+ = \frac{\pi^2-3\pi}8 + \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} \sum_{i=0}^{n-1} (-1)^i \frac{2i+1}{2i+3}$$ Barring any mistakes, the remaining sum seems to be $$2 \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} \left(\sum_{i=0}^{n-1} (1-(-1)^i) \frac{2i+1}{2i+3} - n\right) = \frac{3\pi}2\ln(2) - \frac{\pi^2}4 - \frac\pi4$$ but I have no idea where to go with this. Is there anything I can do to further refine $\mathcal J^- - \mathcal J^+$ ? I do see a bit of cancellation of terms when $i$ is even, which lets me simplify the inner sum to $$2\sum_{i=0}^{\left\lfloor\frac{n-1}2\right\rfloor} \frac{4i+1}{4i+3} - n$$ but that doesn't seem helpful. We do have, with $H_n$ the $n$ -th harmonic number, $$\sum_{i=0}^{n-1} \frac{2i+1}{2i+3} = \sum_{i=0}^{n-1}\left(1 - \frac2{2i+3}\right) = n - 2\left(H_{2n+1} - \frac12 H_n - 1\right)$$ though I'm not so sure I can write its alternating counterpart in $\mathcal J^+$ in a similar way. Then $$\mathcal J^- = \frac12\ln(2) - \pi - 2 \sum_{n=0}^\infty \frac{(-1)^n H_{2n+1}}{2n+1} + \sum_{n=0}^\infty \frac{(-1)^n H_n}{2n+1} = \frac{2\ln(2)-\pi}4 - G$$","I know that and I am aware of a few different clever ways to demonstrate this result (e.g. MSE 4065767 and MSE 1992462 ). I would like to know if there's any way to wrap up the method I outline below. Substituting yields Exploiting the series expansion for , we have and similarly, I derive the following recurrences for : where are found by exploiting the series for and several others derived from the expansion of . I managed to solve these for , so that Barring any mistakes, the remaining sum seems to be but I have no idea where to go with this. Is there anything I can do to further refine ? I do see a bit of cancellation of terms when is even, which lets me simplify the inner sum to but that doesn't seem helpful. We do have, with the -th harmonic number, though I'm not so sure I can write its alternating counterpart in in a similar way. Then","\mathcal I = \int\limits_0^{\pi/2}\ln(\cos(x))\,dx = -\frac\pi2 \ln(2) t=\tan\left(\frac x2\right) \mathcal I= 2\int_0^1 \frac{\ln\left(\frac{1-t^2}{1+t^2}\right)}{1+t^2} \, dt = 2 \left(\underbrace{\int_0^1\frac{\ln(1-t^2)}{1+t^2}\,dt}_{\mathcal J^-} - \underbrace{\int_0^1\frac{\ln(1+t^2)}{1+t^2} \, dt}_{\mathcal J^+} \right) \frac1{1+t^2} \mathcal J^- = \int_0^1 \ln(1-t^2) \sum_{n=0}^\infty (-t^2)^n = \sum_{n=0}^\infty (-1)^n \underbrace{\int_0^1 t^{2n} \ln(1-t^2) \, dt}_{{J_n}^-} \mathcal J^+ = \sum_{n=0}^\infty \underbrace{\int_0^1 t^{2n} \ln(1+t^2) \, dt}_{{J_n}^+} {J_n}^{\pm} \begin{cases}{J_0}^- = 2\ln(2) - 2 \\ {J_n}^- = \frac{2n-1}{(2n+1)^2} - \frac1{2n+1} + \frac{2n-1}{2n+1} {J_{n-1}}^- & \text{for }n\ge1\end{cases} \begin{cases}{J_0}^+ = \ln(2) - 2 + \frac\pi2 \\ {J_n}^+ = \frac{2n-1}{(2n+1)^2} - \frac{2\ln(2)-1}{2n+1} - \frac{2n-1}{2n+1}{J_{n-1}}^+ & \text{for }n\ge1\end{cases} {J_0}^\pm \ln(1\pm t) \frac1{1-t} {J_n}^{\pm} \mathcal J^- = \frac{(\ln(2)-1)\pi}2 + \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} \left(\sum_{i=0}^{n-1} \frac{2i+1}{2i+3} - n\right) \mathcal J^+ = \frac{\pi^2-3\pi}8 + \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} \sum_{i=0}^{n-1} (-1)^i \frac{2i+1}{2i+3} 2 \sum_{n=0}^\infty \frac{(-1)^n}{2n+1} \left(\sum_{i=0}^{n-1} (1-(-1)^i) \frac{2i+1}{2i+3} - n\right) = \frac{3\pi}2\ln(2) - \frac{\pi^2}4 - \frac\pi4 \mathcal J^- - \mathcal J^+ i 2\sum_{i=0}^{\left\lfloor\frac{n-1}2\right\rfloor} \frac{4i+1}{4i+3} - n H_n n \sum_{i=0}^{n-1} \frac{2i+1}{2i+3} = \sum_{i=0}^{n-1}\left(1 - \frac2{2i+3}\right) = n - 2\left(H_{2n+1} - \frac12 H_n - 1\right) \mathcal J^+ \mathcal J^- = \frac12\ln(2) - \pi - 2 \sum_{n=0}^\infty \frac{(-1)^n H_{2n+1}}{2n+1} + \sum_{n=0}^\infty \frac{(-1)^n H_n}{2n+1} = \frac{2\ln(2)-\pi}4 - G","['sequences-and-series', 'definite-integrals', 'summation']"
79,On a property similar to sequentially compact,On a property similar to sequentially compact,,"Suppose $(X,d)$ is a metric space. If $A$ is a subspace of $X$ and every sequence $\{x_n \}_{n\in \mathbb{N}}$ in $A$ has a subsequence $\{x_{n_{k}} \}_{k\in \mathbb{N}}$ that converges to a point $p$ in $X$ ( $p$ is not necessarily in $A$ ), can we prove that $\overline{A}$ has the same property? i.e., Every sequence $\{x_n \}_{n\in \mathbb{N}}$ in $\overline{A}$ has a subsequence $\{x_{n_{k}} \}_{k\in \mathbb{N}}$ that converges to a point $p$ in $X$ . My thought: if the result does not hold, then we can find a sequence $\{x_n \}_{n\in \mathbb{N}}$ in $\overline{A}\setminus A$ and $\{x_n \}_{n\in \mathbb{N}}$ does not have convergent subsequence in $X$ . But can we find a contradiction using this sequence? Anyway, the construction is as follows: Suppose the result does not hold. Then $\exists \{x_n \}_{n\in \mathbb{N}} \subset \overline {A} $ s.t. its any subsequence $\{x_{n_{k}} \}_{k\in \mathbb{N}}$ does not converge. We claim that there are infinite number of $m\in \mathbb{N}$ s.t. $x_m \in \overline{A}\setminus A$ . For otherwise there are only finite number of $m\in \mathbb{N}$ s.t. $x_m \in \overline{A}\setminus A$ . Then we just throw away these $x_m$ from $\{x_n\}$ , and the rest subsequence $\{x'_n \}_{n\in \mathbb{N}}$ is in $A$ , hence it has a convergent subsequence by the property of $A$ , contradiction. We thus find a sequence $\{x_m \}_{m\in \mathbb{N}}$ in $\overline{A}\setminus A$ and $\{x_m \}_{m\in \mathbb{N}}$ does not have convergent subsequence in $X$ .","Suppose is a metric space. If is a subspace of and every sequence in has a subsequence that converges to a point in ( is not necessarily in ), can we prove that has the same property? i.e., Every sequence in has a subsequence that converges to a point in . My thought: if the result does not hold, then we can find a sequence in and does not have convergent subsequence in . But can we find a contradiction using this sequence? Anyway, the construction is as follows: Suppose the result does not hold. Then s.t. its any subsequence does not converge. We claim that there are infinite number of s.t. . For otherwise there are only finite number of s.t. . Then we just throw away these from , and the rest subsequence is in , hence it has a convergent subsequence by the property of , contradiction. We thus find a sequence in and does not have convergent subsequence in .","(X,d) A X \{x_n \}_{n\in \mathbb{N}} A \{x_{n_{k}} \}_{k\in \mathbb{N}} p X p A \overline{A} \{x_n \}_{n\in \mathbb{N}} \overline{A} \{x_{n_{k}} \}_{k\in \mathbb{N}} p X \{x_n \}_{n\in \mathbb{N}} \overline{A}\setminus A \{x_n \}_{n\in \mathbb{N}} X \exists \{x_n \}_{n\in \mathbb{N}} \subset \overline {A}  \{x_{n_{k}} \}_{k\in \mathbb{N}} m\in \mathbb{N} x_m \in \overline{A}\setminus A m\in \mathbb{N} x_m \in \overline{A}\setminus A x_m \{x_n\} \{x'_n \}_{n\in \mathbb{N}} A A \{x_m \}_{m\in \mathbb{N}} \overline{A}\setminus A \{x_m \}_{m\in \mathbb{N}} X","['sequences-and-series', 'general-topology', 'metric-spaces', 'compactness']"
80,Closed form for $T_n$ if $T_{n+3}=2 T_{n+2}+2 T_{n+1}-T_{n}$,Closed form for  if,T_n T_{n+3}=2 T_{n+2}+2 T_{n+1}-T_{n},"Consider the recurrence relation $$T_{n+3}=2 T_{n+2}+2 T_{n+1}-T_{n}$$ with first three terms as: $T_{1}=20, T_{2}=12, T_{3}=70$ Find the closed form expression for $T_n$ . My try: Since it is a constant coefficient difference equation, the auxiliary equation is: $$\lambda^3-2\lambda^2-2\lambda+1=0$$ whose roots are: $-1,\frac{3\pm\sqrt{5}}{2}$ Thus we have: $$T_{n}=A(-1)^{n}+B\left(\frac{3+\sqrt{5}}{2}\right)^{n}+C\left(\frac{3-\sqrt{5}}{2}\right)^{n}$$ where the constants $A,B,C$ to be determined by values of $T_1,T_2,T_3$ but its becoming too tedious to solve. Any alternate approach?","Consider the recurrence relation with first three terms as: Find the closed form expression for . My try: Since it is a constant coefficient difference equation, the auxiliary equation is: whose roots are: Thus we have: where the constants to be determined by values of but its becoming too tedious to solve. Any alternate approach?","T_{n+3}=2 T_{n+2}+2 T_{n+1}-T_{n} T_{1}=20, T_{2}=12, T_{3}=70 T_n \lambda^3-2\lambda^2-2\lambda+1=0 -1,\frac{3\pm\sqrt{5}}{2} T_{n}=A(-1)^{n}+B\left(\frac{3+\sqrt{5}}{2}\right)^{n}+C\left(\frac{3-\sqrt{5}}{2}\right)^{n} A,B,C T_1,T_2,T_3","['sequences-and-series', 'algebra-precalculus', 'recurrence-relations']"
81,Fibonacci Like Sequence,Fibonacci Like Sequence,,"I'm working on this problem but I'm not sure how to solve it. Consider a sequence of positive integers $1, a_2, a_3, \dots , a_k=55$ where each term in the sequence is the sum of any two previous (not necessarily distinct) terms. What is the smallest value of $k$ such that the sequence exists? Just for clarification, a possible sequence would be $1, 2, 4, 8, 16, 32, 48, 52, 54, a_{10}=55$ , where the second through sixth terms are created by adding the previous term twice, the seventh term is created by adding 16 to the previous term, the eighth term is created by adding 4 to the previous term, the ninth term is created by adding 2 to the eighth term, and 55 is created by adding 1 to the ninth term. This sequence would have $k=10$ . I found a possible sequence for $k=9$ , which is $1, 2, 4, 6, 12, 24, 48, 54, 55$ , and I'm pretty sure I can't find one for $k=8$ . However, I'm not sure how to prove that $k=9$ is the lowest I can go. Thanks for any help on this problem.","I'm working on this problem but I'm not sure how to solve it. Consider a sequence of positive integers where each term in the sequence is the sum of any two previous (not necessarily distinct) terms. What is the smallest value of such that the sequence exists? Just for clarification, a possible sequence would be , where the second through sixth terms are created by adding the previous term twice, the seventh term is created by adding 16 to the previous term, the eighth term is created by adding 4 to the previous term, the ninth term is created by adding 2 to the eighth term, and 55 is created by adding 1 to the ninth term. This sequence would have . I found a possible sequence for , which is , and I'm pretty sure I can't find one for . However, I'm not sure how to prove that is the lowest I can go. Thanks for any help on this problem.","1, a_2, a_3, \dots , a_k=55 k 1, 2, 4, 8, 16, 32, 48, 52, 54, a_{10}=55 k=10 k=9 1, 2, 4, 6, 12, 24, 48, 54, 55 k=8 k=9","['sequences-and-series', 'elementary-number-theory', 'optimization']"
82,How can I use fixed point iteration for $2x^3-4x^2+x+1=0$ to find the negative root?,How can I use fixed point iteration for  to find the negative root?,2x^3-4x^2+x+1=0,"How can I use fixed point iteration for $2x^3-4x^2+x+1=0$ to find the negative root? The  worked solution to the question uses the following iterative formula, it apparently finds a solution at -0.3660 (4sf) but I am unable to retrieve this result: $$x_{r+1}=\sqrt{\frac{2x_r^3+x_r+1}{4}}$$ I can find positive roots such as 1 and 1.366(4sf) [link] , but I am unable to find the negative root for the function using fixed point iteration. I have tried $x_0=-0.5$ which eventually finds the root at $1$ . $x_0=-1$ and below seems to result in the square root of a negative number that does not have a real solution.","How can I use fixed point iteration for to find the negative root? The  worked solution to the question uses the following iterative formula, it apparently finds a solution at -0.3660 (4sf) but I am unable to retrieve this result: I can find positive roots such as 1 and 1.366(4sf) [link] , but I am unable to find the negative root for the function using fixed point iteration. I have tried which eventually finds the root at . and below seems to result in the square root of a negative number that does not have a real solution.",2x^3-4x^2+x+1=0 x_{r+1}=\sqrt{\frac{2x_r^3+x_r+1}{4}} x_0=-0.5 1 x_0=-1,"['sequences-and-series', 'fixed-point-theorems']"
83,"Find all function $f$ such that, for any sequence $(x_n)$ Cesàro-convergent, the sequence $(f (x_n))$ is also Cesàro-convergent","Find all function  such that, for any sequence  Cesàro-convergent, the sequence  is also Cesàro-convergent",f (x_n) (f (x_n)),"Let's say that a function $f$ is Cesàro-continuous at $x_0$ iff for any sequence $(u_n)_\Bbb{N}$ whose Cesàro mean converges to $x_0$ , the Cesàro mean of the sequence $(f(u_n))_\Bbb{N}$ converges to $f(x_0)$ . At first, I was interested in the following question Find all functions $f : \mathbb{R} \to \mathbb{R}$ Cesàro-continuous. I realized that it is a classic question and the answer is that $f$ must be affine. Now I'm interested in this question Find all function $f : \mathbb{R} \to \mathbb{R}$ such that, for any sequence $(x_n)$ Cesàro-convergent, the sequence, the sequence $(f(x_n))$ is also Cesàro-convergent? It seems to me that the two questions are equivalent, but I do not know if it's true and how to prove it. I need help. The idea of the question came to me by this question .","Let's say that a function is Cesàro-continuous at iff for any sequence whose Cesàro mean converges to , the Cesàro mean of the sequence converges to . At first, I was interested in the following question Find all functions Cesàro-continuous. I realized that it is a classic question and the answer is that must be affine. Now I'm interested in this question Find all function such that, for any sequence Cesàro-convergent, the sequence, the sequence is also Cesàro-convergent? It seems to me that the two questions are equivalent, but I do not know if it's true and how to prove it. I need help. The idea of the question came to me by this question .",f x_0 (u_n)_\Bbb{N} x_0 (f(u_n))_\Bbb{N} f(x_0) f : \mathbb{R} \to \mathbb{R} f f : \mathbb{R} \to \mathbb{R} (x_n) (f(x_n)),"['sequences-and-series', 'functional-analysis', 'convergence-divergence']"
84,What is known about sums of the form $\sum_{n=-\infty}^{\infty} \operatorname{sinc} (n^{p})$?,What is known about sums of the form ?,\sum_{n=-\infty}^{\infty} \operatorname{sinc} (n^{p}),"Recently, I've become fascinated with the whole 'sum = integral' concept. The sinc function harbours some great examples. For instance, the authors R. Bailie, D. Borwein and J. Borwein described in their paper “Surprising Sinc Sums and Integrals” (p. 8) that the equality $$\sum_{n=1}^{\infty} \operatorname{sinc}(n)^{N} = - \frac{1}{2} + \int_{0}^{\infty} \operatorname{sinc}(x)^{N} dx $$ holds for $1 \leq N \leq 6$ . There are many other examples in the paper and in this MSE question. Currently, I'm looking at a related expression involving the sinc function. Instead of having the powers outside the function, I wonder what happens once they get inside the sinc. In other words, I'm looking at sums of the form $$\sum_{n=-\infty}^{\infty} \operatorname{sinc} (n^{p}),\tag{*}$$ where $p \in \mathbb{Z}_{>1}$ . It appears that integrals of the form $$\int_{-\infty}^{\infty} \operatorname{sinc}(x^{p})dx $$ can be found, as we have for instance $$\int_{-\infty}^{\infty} \operatorname{sinc}(x^{2})dx = \sqrt{2 \pi} ,$$ and $$\int_{-\infty}^{\infty} \operatorname{sinc}(x^{3})dx = \frac{\Gamma(-2/3)}{\sqrt{3}} ,$$ and : $$\int_{-\infty}^{\infty} \operatorname{sinc}(x^{4})dx =  \frac{2}{3} \cos(\pi/8)\Gamma(1/4). $$ However, I haven't been able to find closed forms for sums of the form $(*)$ . One thing that probably has to do with this is that the Fourier transform of $\operatorname{sinc}(x^{2})$ amounts to a Fresnel integral, and that the Fourier transform of the sinc of univariate polynomials of higher powers does not have an expression in terms of known mathematical functions. Therefore, one can't apply the Poisson Summation Formula to these types of sums. Question : Can a closed form be obtained for sums of the type $(*)$ ? References are much appreciated.","Recently, I've become fascinated with the whole 'sum = integral' concept. The sinc function harbours some great examples. For instance, the authors R. Bailie, D. Borwein and J. Borwein described in their paper “Surprising Sinc Sums and Integrals” (p. 8) that the equality holds for . There are many other examples in the paper and in this MSE question. Currently, I'm looking at a related expression involving the sinc function. Instead of having the powers outside the function, I wonder what happens once they get inside the sinc. In other words, I'm looking at sums of the form where . It appears that integrals of the form can be found, as we have for instance and and : However, I haven't been able to find closed forms for sums of the form . One thing that probably has to do with this is that the Fourier transform of amounts to a Fresnel integral, and that the Fourier transform of the sinc of univariate polynomials of higher powers does not have an expression in terms of known mathematical functions. Therefore, one can't apply the Poisson Summation Formula to these types of sums. Question : Can a closed form be obtained for sums of the type ? References are much appreciated.","\sum_{n=1}^{\infty} \operatorname{sinc}(n)^{N} = - \frac{1}{2} + \int_{0}^{\infty} \operatorname{sinc}(x)^{N} dx  1 \leq N \leq 6 \sum_{n=-\infty}^{\infty} \operatorname{sinc} (n^{p}),\tag{*} p \in \mathbb{Z}_{>1} \int_{-\infty}^{\infty} \operatorname{sinc}(x^{p})dx  \int_{-\infty}^{\infty} \operatorname{sinc}(x^{2})dx = \sqrt{2 \pi} , \int_{-\infty}^{\infty} \operatorname{sinc}(x^{3})dx = \frac{\Gamma(-2/3)}{\sqrt{3}} , \int_{-\infty}^{\infty} \operatorname{sinc}(x^{4})dx =  \frac{2}{3} \cos(\pi/8)\Gamma(1/4).  (*) \operatorname{sinc}(x^{2}) (*)","['sequences-and-series', 'reference-request', 'definite-integrals', 'trigonometric-integrals', 'trigonometric-series']"
85,Finding $\limsup_{n\to\infty}\sqrt[n]{|a_n|}$ for a recursively defined sequence $(a_n)$ with $a_{n}=\frac13(a_{n-1}+a_{n-2}+a_{n-1}a_{n-2})$,Finding  for a recursively defined sequence  with,\limsup_{n\to\infty}\sqrt[n]{|a_n|} (a_n) a_{n}=\frac13(a_{n-1}+a_{n-2}+a_{n-1}a_{n-2}),"Question. Let $(a_n)$ be a complex sequence defined recursively: $$ a_0 = 0,\quad  a_1=1, \quad a_{n}=\frac13(a_{n-1}+a_{n-2}+a_{n-1}a_{n-2})\quad (n>1) $$ What is $\displaystyle\limsup_{n\to\infty}\sqrt[n]{|a_n|}$ ? Remarks. This question is motivated by an unanswered question on the site that I am not able to solve. By the Cauchy-Hadamard theorem , the problem of finding the radius of convergence for the power series $f(z)=\sum_{n=0}^\infty a_nz^n$ reduces to the limit problem above. One can probably find some other way to figure out the radius of convergence, but I would like to focus on Cauchy-Hadamard and thus particularly the limit in the question. One straightforward attempt is to find a closed-form formula for the sequence so that one may able to apply asymptotic techniques to analyze $|a_n|^{1/n}$ . While there are systematic ways to handle the linear recurrence , I don't know how to handle this particular nonlinear case. The usual idea of ""linearizing the nonlinear problem"" seems not helpful here. With help of the short Python script, I plotted the sequence $(|a_n|^{1/n})$ . The result seems to suggest that the limit is $1$ .","Question. Let be a complex sequence defined recursively: What is ? Remarks. This question is motivated by an unanswered question on the site that I am not able to solve. By the Cauchy-Hadamard theorem , the problem of finding the radius of convergence for the power series reduces to the limit problem above. One can probably find some other way to figure out the radius of convergence, but I would like to focus on Cauchy-Hadamard and thus particularly the limit in the question. One straightforward attempt is to find a closed-form formula for the sequence so that one may able to apply asymptotic techniques to analyze . While there are systematic ways to handle the linear recurrence , I don't know how to handle this particular nonlinear case. The usual idea of ""linearizing the nonlinear problem"" seems not helpful here. With help of the short Python script, I plotted the sequence . The result seems to suggest that the limit is .","(a_n) 
a_0 = 0,\quad  a_1=1, \quad a_{n}=\frac13(a_{n-1}+a_{n-2}+a_{n-1}a_{n-2})\quad (n>1)
 \displaystyle\limsup_{n\to\infty}\sqrt[n]{|a_n|} f(z)=\sum_{n=0}^\infty a_nz^n |a_n|^{1/n} (|a_n|^{1/n}) 1","['real-analysis', 'sequences-and-series']"
86,Using complex analysis for evaluating summations: some general queries,Using complex analysis for evaluating summations: some general queries,,"So, I was reading some old course materials, and came across the following summation, which is to be evaluated through complex analysis: $$\sum_{-\infty}^{\infty}\frac{1}{n^2+a^2}, \ \ \ \ \ \ \ a\ne 0$$ I am fine with the mathematical manipulation for the most part. Instead, I am more curious as to the motivations between a couple of points in the method (below). In my course notes, the following is written: ""Firstly, one considers the integral $$I_N(a) = \oint_{\mathcal{C}} \frac{\pi \cot(\pi z)}{z^2+a^2} dz$$ Where the contour $\mathcal{C}$ is the circle of radius $N+1/2$ ( $N$ integer), and centred on the origin. This contour contains $2N+1$ poles of the function $\pi\cot(\pi z)$ (integers from $-N$ to $N$ ), as well as $\pm ia$ from $(z^2+a^2)^{-1}$ (assuming $N+1/2 > |a|$ ) leading to: $$I_N(a) = \sum_{-N}^{N} \frac{2i\pi}{n^2+a^2}+2i\pi\left(\frac{\pi\cot(i\pi a)}{2ia} + \frac{\pi\cot(-i\pi a)}{-2i\pi a}\right) = \sum_{-N}^{N}\frac{2i\pi}{n^2+a^2}-2i\pi\frac{\pi\coth{\pi a}}{a}$$ But $I_N(a)\propto N^{-1}$ as $N\rightarrow \infty$ since the numerator is of order $1$ , the denominator $N^2$ , and the contour length is of order $N$ , leading (in the limit) to: $$\sum_{-\infty}^{\infty}\frac{1}{n^2+a^2} = \frac{\pi}{a}\coth(\pi a),\ \ \ \ \ \ a\ne 0$$ "" Q1) EDIT: Now understood thanks to the answers and comments below What caught my attention revisiting this, is how seemingly ""out of nowhere"" the function $\pi\cot(\pi z)$ seems to have appeared. For sums like this (and any other that can be analysed similarly), how is such an integral as $I_N(a)$ above even determined- what motivates the decision to choose this integral? (i.e. why is the $\pi\cot(\pi z)$ required to correctly determine this sum? Is it arbitrary? Are there other integrals that would yield the same results?) Q2) EDIT: Now understood thanks to Ron Gordon's answer (below) Is there any significance to the contour being of radius $N+1/2$ in this example? If I understand correctly, radius $N$ would cause the perimeter of the contour to lie on another pole; but why can we not use, say $N+1/4$ , or $N-1/2$ as the radius, or some other non-integer radius? What motivates this decision? Q3) EDIT: Now understood thanks to Ron Gordon's answer + comments (below) $2N+1$ poles of $\pi\cot(\pi z)$ within the contour? Simple thing here- I think I've confused myself slightly, thinking that there are $2N$ integers in the range $[-N, N]$ ... Am I correct in thinking that the $+1$ accounts for $0$ being a pole? (and if the radius is different, as per Q2) above, is there an easy way to determine how many poles you have for a periodic function like this?) Q4) EDIT: Now understood thanks to Ron Gordon's answer (below) ""...and the contour length is of order $N$ ""- just a sanity check really- is the significance of the contour length contributing in the limit of $I_N(a)$ ( $N\rightarrow\infty$ ) because it is effectively a line integral? Not sure if I'm just overthinking, or misunderstanding exactly what's going on here, so a clarification would be appreciated. Any sort of pointers in the right direction, or things for me to think about to try and understand this would be very welcome! Thanks :)","So, I was reading some old course materials, and came across the following summation, which is to be evaluated through complex analysis: I am fine with the mathematical manipulation for the most part. Instead, I am more curious as to the motivations between a couple of points in the method (below). In my course notes, the following is written: ""Firstly, one considers the integral Where the contour is the circle of radius ( integer), and centred on the origin. This contour contains poles of the function (integers from to ), as well as from (assuming ) leading to: But as since the numerator is of order , the denominator , and the contour length is of order , leading (in the limit) to: "" Q1) EDIT: Now understood thanks to the answers and comments below What caught my attention revisiting this, is how seemingly ""out of nowhere"" the function seems to have appeared. For sums like this (and any other that can be analysed similarly), how is such an integral as above even determined- what motivates the decision to choose this integral? (i.e. why is the required to correctly determine this sum? Is it arbitrary? Are there other integrals that would yield the same results?) Q2) EDIT: Now understood thanks to Ron Gordon's answer (below) Is there any significance to the contour being of radius in this example? If I understand correctly, radius would cause the perimeter of the contour to lie on another pole; but why can we not use, say , or as the radius, or some other non-integer radius? What motivates this decision? Q3) EDIT: Now understood thanks to Ron Gordon's answer + comments (below) poles of within the contour? Simple thing here- I think I've confused myself slightly, thinking that there are integers in the range ... Am I correct in thinking that the accounts for being a pole? (and if the radius is different, as per Q2) above, is there an easy way to determine how many poles you have for a periodic function like this?) Q4) EDIT: Now understood thanks to Ron Gordon's answer (below) ""...and the contour length is of order ""- just a sanity check really- is the significance of the contour length contributing in the limit of ( ) because it is effectively a line integral? Not sure if I'm just overthinking, or misunderstanding exactly what's going on here, so a clarification would be appreciated. Any sort of pointers in the right direction, or things for me to think about to try and understand this would be very welcome! Thanks :)","\sum_{-\infty}^{\infty}\frac{1}{n^2+a^2}, \ \ \ \ \ \ \ a\ne 0 I_N(a) = \oint_{\mathcal{C}} \frac{\pi \cot(\pi z)}{z^2+a^2} dz \mathcal{C} N+1/2 N 2N+1 \pi\cot(\pi z) -N N \pm ia (z^2+a^2)^{-1} N+1/2 > |a| I_N(a) = \sum_{-N}^{N} \frac{2i\pi}{n^2+a^2}+2i\pi\left(\frac{\pi\cot(i\pi a)}{2ia} + \frac{\pi\cot(-i\pi a)}{-2i\pi a}\right) = \sum_{-N}^{N}\frac{2i\pi}{n^2+a^2}-2i\pi\frac{\pi\coth{\pi a}}{a} I_N(a)\propto N^{-1} N\rightarrow \infty 1 N^2 N \sum_{-\infty}^{\infty}\frac{1}{n^2+a^2} = \frac{\pi}{a}\coth(\pi a),\ \ \ \ \ \ a\ne 0 \pi\cot(\pi z) I_N(a) \pi\cot(\pi z) N+1/2 N N+1/4 N-1/2 2N+1 \pi\cot(\pi z) 2N [-N, N] +1 0 N I_N(a) N\rightarrow\infty","['sequences-and-series', 'complex-analysis', 'summation', 'complex-integration']"
87,What exactly is a Collatz-like Problem,What exactly is a Collatz-like Problem,,"What exactly is a Collatz-like problem? Let $f:\mathbb{N} \to\mathbb{N}$ . The Collatz function states that the following iterated map will eventually equal to 1: $$f(n) = \begin{cases} n/2,  & \text{if}\  2\mid n\\ 3n+1, & \text{otherwise} \\ \end{cases}$$ I have seen many different iterated functions ( 1 , 2 , 3 )being described as Collatz-like or Collatz related once the search is for bounded or unbounded orbits. Searching for bounded or unbounded orbits is the intention of the person behind the function and doesn’t constitute a definition to me (but I could be wrong). This led me to wonder if there is a formal mathematical definition for a Collatz-like problem.","What exactly is a Collatz-like problem? Let . The Collatz function states that the following iterated map will eventually equal to 1: I have seen many different iterated functions ( 1 , 2 , 3 )being described as Collatz-like or Collatz related once the search is for bounded or unbounded orbits. Searching for bounded or unbounded orbits is the intention of the person behind the function and doesn’t constitute a definition to me (but I could be wrong). This led me to wonder if there is a formal mathematical definition for a Collatz-like problem.","f:\mathbb{N} \to\mathbb{N} f(n) =
\begin{cases}
n/2,  & \text{if}\  2\mid n\\
3n+1, & \text{otherwise} \\
\end{cases}","['sequences-and-series', 'number-theory', 'dynamical-systems', 'collatz-conjecture']"
88,What is the series $ \dfrac{1}{\left( x-{y}^{2} \right) \left(1- yx \right) \left( {x}^{2}-y \right)} $ expansion?,What is the series  expansion?, \dfrac{1}{\left( x-{y}^{2} \right) \left(1- yx \right) \left( {x}^{2}-y \right)} ,"Consider the series expansion $$ \frac{1}{\left( x-{y}^{2} \right)  \left(1- yx \right)  \left( {x}^{2}-y \right)}=P_0(y)+P_1(y)x+P_2(y)x^2+\cdots+P_n(y) x^n+\cdots. $$ For small $n$ we have \begin{gather*} P_0(y)=\frac{1}{y^3},\\ P_1(y)={\frac {{y}^{3}+1}{{y}^{5}}},\\ P_2(y)={\frac {{y}^{6}+2\,{y}^{3}+1}{{y}^{7}}},\\ P_3(y)={\frac {{y}^{9}+2\,{y}^{6}+2\,{y}^{3}+1}{{y}^{9}}},\\ P_4(y)=\frac{{y}^{12}+2\,{y}^{9}+3\,{y}^{6}+2\,{y}^{3}+1}{y^{11}},\\ P_5(y)={\frac {{y}^{15}+2\,{y}^{12}+3\,{y}^{9}+3\,{y}^{6}+2\,{y}^{3}+1}{{y}^{ 13}}}. \end{gather*} Question: What is a close expression for $P_n(y)$ ? My attempt.  The $P_n(y)$ has  a form $$  P_n(y)=\frac{1}{y^{2n+3}}(c_{n,1}+c_{n,2}y^3+c_{n,3}y^{6}+\cdots+с_{n,k} y^{3(k-1)}+\cdots+c_{n,n+1}y^{3n}) $$ for some  unknown sequence $c_{n,k}.$ By empirical way I have found that $$ c(n,k)= \left \{ \begin{array}{l} \min(n{-}k+2,k) , 1 \leq    k \leq n+1, \\ \\ 0,  \text{ otherwise, } \end{array} \right. $$ but I can't find a rigorous proof. Any help?",Consider the series expansion For small we have Question: What is a close expression for ? My attempt.  The has  a form for some  unknown sequence By empirical way I have found that but I can't find a rigorous proof. Any help?,"
\frac{1}{\left( x-{y}^{2} \right)  \left(1- yx \right)  \left( {x}^{2}-y \right)}=P_0(y)+P_1(y)x+P_2(y)x^2+\cdots+P_n(y) x^n+\cdots.
 n \begin{gather*}
P_0(y)=\frac{1}{y^3},\\
P_1(y)={\frac {{y}^{3}+1}{{y}^{5}}},\\
P_2(y)={\frac {{y}^{6}+2\,{y}^{3}+1}{{y}^{7}}},\\
P_3(y)={\frac {{y}^{9}+2\,{y}^{6}+2\,{y}^{3}+1}{{y}^{9}}},\\
P_4(y)=\frac{{y}^{12}+2\,{y}^{9}+3\,{y}^{6}+2\,{y}^{3}+1}{y^{11}},\\
P_5(y)={\frac {{y}^{15}+2\,{y}^{12}+3\,{y}^{9}+3\,{y}^{6}+2\,{y}^{3}+1}{{y}^{
13}}}.
\end{gather*} P_n(y) P_n(y) 
 P_n(y)=\frac{1}{y^{2n+3}}(c_{n,1}+c_{n,2}y^3+c_{n,3}y^{6}+\cdots+с_{n,k} y^{3(k-1)}+\cdots+c_{n,n+1}y^{3n})
 c_{n,k}. 
c(n,k)= \left \{
\begin{array}{l}
\min(n{-}k+2,k) , 1 \leq    k \leq n+1, \\
\\
0,  \text{ otherwise, }
\end{array}
\right.
","['sequences-and-series', 'combinatorics', 'power-series']"
89,Discrete calculus: is my proof about the difference of two consecutive powers correct?,Discrete calculus: is my proof about the difference of two consecutive powers correct?,,"Theorem statement: $\displaystyle \Delta^dF_n(x) = \sum_{k=0}^{n-1} \binom{n-1}{k} \Delta^{d-1}F_{n-1-k}(x)(-1)^k$ Proof: $$\begin{align} F_n(x) &= x^n =\Delta^0F(x) \\[2ex] \Delta^1F_n(x) &= x^n -(x-1)^n \\[2ex] &= x^n - \sum_{k=0}^n\binom nk x^{n-k}(-1)^k \\[2ex] &= \sum_{k=0}^{n-1}\binom{n-1}{k}x^{n-k}(-1)^{k} \\[2ex] &=x^{n-1} -(n-1)x^{n-2} + \ldots \pm (n-1)x^2 \mp 1 \\[2ex] &= \sum_{k=0}^{n-1}\binom{n-1}{k}\Delta^0F_{n-1-k}(x)(-1)^k\end{align}$$ $$\begin{align}\Delta^2F_n(x) &=\Delta^1F_n(x) -\Delta^1F_n(x-1) \\[2ex] &= \sum_{k=0}^{n-1}\binom{n-1}{k}x^{n-k}(-1)^k - \sum_{k=0}^{n-1}\binom{n-1}{k}(x-1)^{n-k}(-1)^k \\[2ex] & = x^{n-1}-(x-1)^{n-1}- (n-1)x^{n-2} - (n-1)(x-1)^{n-2} +\ldots \pm(n-1)x^2 -(n-1)(x-1)^2 \\[2ex] & = \sum_{k=0}^{n-1} \binom{n-1}{k}\Delta^1F_{n-1-k}(x)(-1)^k\end{align}$$ $$\begin{align} \Delta^3F_n(x) &= \Delta^2F_n(x) - \Delta^2F_n(x-1) \\[2ex] &= \sum_{k=0}^{n-1} \binom{n-1}{k}\Delta^1F_{n-1-k}(x)(-1)^k -\sum_{k=0}^{n-1} \binom{n-1}{k}\Delta^1F_{n-1-k}(x-1)(-1)^k \\[2ex] &= \sum_{k=0}^{n-1} \binom{n-1}{k} (\Delta^1F_{n-1-k}(x) - \Delta^1F_{n-1-k}(x-1))(-1)^k \\[2ex] &= \sum_{k=0}^{n-1} \binom{n-1}{k} \Delta^2F_{n-1-k}(x)(-1)^k \end{align}$$ $$\therefore \Delta^dF_n(x) = \sum_{k=0}^{n-1} \binom{n-1}{k} \Delta^{d-1}F_{n-1-k}(x)(-1)^k$$ Is this correct? If not, where did I go wrong? If it is correct, what can I do with this? Where can I apply the derived identity? I originally set out to prove that $\Delta^n F_n(x) = c \ \forall x$ , but I'm not sure if I'm any closer to this now.","Theorem statement: Proof: Is this correct? If not, where did I go wrong? If it is correct, what can I do with this? Where can I apply the derived identity? I originally set out to prove that , but I'm not sure if I'm any closer to this now.",\displaystyle \Delta^dF_n(x) = \sum_{k=0}^{n-1} \binom{n-1}{k} \Delta^{d-1}F_{n-1-k}(x)(-1)^k \begin{align} F_n(x) &= x^n =\Delta^0F(x) \\[2ex] \Delta^1F_n(x) &= x^n -(x-1)^n \\[2ex] &= x^n - \sum_{k=0}^n\binom nk x^{n-k}(-1)^k \\[2ex] &= \sum_{k=0}^{n-1}\binom{n-1}{k}x^{n-k}(-1)^{k} \\[2ex] &=x^{n-1} -(n-1)x^{n-2} + \ldots \pm (n-1)x^2 \mp 1 \\[2ex] &= \sum_{k=0}^{n-1}\binom{n-1}{k}\Delta^0F_{n-1-k}(x)(-1)^k\end{align} \begin{align}\Delta^2F_n(x) &=\Delta^1F_n(x) -\Delta^1F_n(x-1) \\[2ex] &= \sum_{k=0}^{n-1}\binom{n-1}{k}x^{n-k}(-1)^k - \sum_{k=0}^{n-1}\binom{n-1}{k}(x-1)^{n-k}(-1)^k \\[2ex] & = x^{n-1}-(x-1)^{n-1}- (n-1)x^{n-2} - (n-1)(x-1)^{n-2} +\ldots \pm(n-1)x^2 -(n-1)(x-1)^2 \\[2ex] & = \sum_{k=0}^{n-1} \binom{n-1}{k}\Delta^1F_{n-1-k}(x)(-1)^k\end{align} \begin{align} \Delta^3F_n(x) &= \Delta^2F_n(x) - \Delta^2F_n(x-1) \\[2ex] &= \sum_{k=0}^{n-1} \binom{n-1}{k}\Delta^1F_{n-1-k}(x)(-1)^k -\sum_{k=0}^{n-1} \binom{n-1}{k}\Delta^1F_{n-1-k}(x-1)(-1)^k \\[2ex] &= \sum_{k=0}^{n-1} \binom{n-1}{k} (\Delta^1F_{n-1-k}(x) - \Delta^1F_{n-1-k}(x-1))(-1)^k \\[2ex] &= \sum_{k=0}^{n-1} \binom{n-1}{k} \Delta^2F_{n-1-k}(x)(-1)^k \end{align} \therefore \Delta^dF_n(x) = \sum_{k=0}^{n-1} \binom{n-1}{k} \Delta^{d-1}F_{n-1-k}(x)(-1)^k \Delta^n F_n(x) = c \ \forall x,"['sequences-and-series', 'combinatorics', 'solution-verification', 'exponential-function', 'discrete-calculus']"
90,Is there an analytic expression for $\sum\limits_{n=0}^{\infty}x^{n^2}$,Is there an analytic expression for,\sum\limits_{n=0}^{\infty}x^{n^2},"In statistical mechanics I often come across average energies of the form: $$\begin{equation} \langle\epsilon_n\rangle=\alpha \sum_{n=0}^{\infty}n^2e^{-\alpha n^2} \end{equation}$$ where $\alpha$ is positive and by rewriting $$\begin{equation} \langle\epsilon_n\rangle=-\alpha \partial_{\alpha}\sum_{n=0}^{\infty}e^{-\alpha n^2} \end{equation}$$ However, I cannot seem to solve these kinds of sums. Is there any way to solve the sum $$\sum_{n=0}^{\infty}x^{n^2}$$ analytically?","In statistical mechanics I often come across average energies of the form: where is positive and by rewriting However, I cannot seem to solve these kinds of sums. Is there any way to solve the sum analytically?","\begin{equation}
\langle\epsilon_n\rangle=\alpha \sum_{n=0}^{\infty}n^2e^{-\alpha n^2}
\end{equation} \alpha \begin{equation}
\langle\epsilon_n\rangle=-\alpha \partial_{\alpha}\sum_{n=0}^{\infty}e^{-\alpha n^2}
\end{equation} \sum_{n=0}^{\infty}x^{n^2}","['sequences-and-series', 'summation', 'theta-functions']"
91,Eventually $\implies$ Frequently,Eventually  Frequently,\implies,"Sequence $<x_n>$ is called eventually in $X$ if $\exists n_0\in \mathbb{N}$ such that $x_n\in X,\forall n\geq n_0$ Sequence $<x_n>$ is called frequently in $X$ if $\forall n_1\in \mathbb{N},\exists n\in \mathbb{N}$ such that $x_n\in X \,\text{and}\, n\geq n_1$ My lecture notes say eventually $\implies$ frequently because $\forall n_1\in \mathbb{N}\ni n_1\geq n_0,\exists n\in \mathbb{N}$ such that $x_n\in X \,\text{and}\, n\geq n_1$ . But this prove only works for $\forall n_1\geq n_0$ not $\forall n_1\in \mathbb{N}$ . So how could this proof be enough? Shouldn't the proof be eventually $\implies$ frequently because $\forall n_1\in \mathbb{N},\exists n\in \mathbb{N}\ni n\geq n_0$ such that $x_n\in X \,\text{and}\, n\geq n_1$ .",Sequence is called eventually in if such that Sequence is called frequently in if such that My lecture notes say eventually frequently because such that . But this prove only works for not . So how could this proof be enough? Shouldn't the proof be eventually frequently because such that .,"<x_n> X \exists n_0\in \mathbb{N} x_n\in X,\forall n\geq n_0 <x_n> X \forall n_1\in \mathbb{N},\exists n\in \mathbb{N} x_n\in X \,\text{and}\, n\geq n_1 \implies \forall n_1\in \mathbb{N}\ni n_1\geq n_0,\exists n\in \mathbb{N} x_n\in X \,\text{and}\, n\geq n_1 \forall n_1\geq n_0 \forall n_1\in \mathbb{N} \implies \forall n_1\in \mathbb{N},\exists n\in \mathbb{N}\ni n\geq n_0 x_n\in X \,\text{and}\, n\geq n_1","['real-analysis', 'sequences-and-series']"
92,distance between sorted arrays,distance between sorted arrays,,"Assume we have two arrays of real numbers: $$ X = \{x_{1}, x_{2}, \dots, x_{n} \} $$ and $$ Y = \{y_{1}, y_{2}, \dots, y_{n} \} $$ Next, assume that $d = \max(|x_{i} - y_{i}|)$ . Next let us sort both arrays in increasing order: $$ X'=\{x_{1}', x_{2}', \dots, x_{n}' \} = sort(X) $$ and $$ Y'=\{y_{1}', y_{2}', \dots, y_{n}' \} = sort(Y) $$ Then, let $d' = \max(|x_{i}' - y_{i}'|)$ . Is it always $d' \leq d$ ?","Assume we have two arrays of real numbers: and Next, assume that . Next let us sort both arrays in increasing order: and Then, let . Is it always ?","
X = \{x_{1}, x_{2}, \dots, x_{n} \}
 
Y = \{y_{1}, y_{2}, \dots, y_{n} \}
 d = \max(|x_{i} - y_{i}|) 
X'=\{x_{1}', x_{2}', \dots, x_{n}' \} = sort(X)
 
Y'=\{y_{1}', y_{2}', \dots, y_{n}' \} = sort(Y)
 d' = \max(|x_{i}' - y_{i}'|) d' \leq d","['sequences-and-series', 'combinatorics', 'geometry', 'sorting', 'rearrangement-inequality']"
93,"For all diagonals $a$ of Pascal's triangle (figurate numbers), $\sum_{k=a}^\infty {k\choose a}\frac{1}{2^k}=2$? [duplicate]","For all diagonals  of Pascal's triangle (figurate numbers), ? [duplicate]",a \sum_{k=a}^\infty {k\choose a}\frac{1}{2^k}=2,"This question already has answers here : Generalized binomial identity that converges to 2 [duplicate] (2 answers) Closed 2 years ago . I am looking for the derivation of the closed form along any given diagonal $a$ of Pascal's triangle, $$\sum_{k=a}^n {k\choose a}\frac{1}{2^k}=?$$ Numbered observations follow. As for the limit proposed in the title given by: Observation 1 $$\sum_{k=a}^\infty {k\choose a}\frac{1}{2^k}=2,$$ when I calculate the sums numerically using MS Excel for any $a$ within the domain ( $0\le a \le100$ ) the sum approaches 2.000000 in all cases within total steps $n\le285$ . The first series with $a=0$ is a familiar geometric series, and perhaps others look familiar to you as well: $$\sum_{k=0}^\infty {k\choose 0}\frac{1}{2^k}=1+\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+... =2,$$ $$\sum_{k=1}^\infty {k\choose 1}\frac{1}{2^k}=\frac{1}{2}+\frac{1}{2}+\frac{3}{8}+\frac{1}{4}+\frac{5}{32}... =2,$$ $$\sum_{k=2}^\infty {k\choose 2}\frac{1}{2^k}=\frac{1}{4}+\frac{3}{8}+\frac{3}{8}+\frac{5}{16}+\frac{15}{64}... =2,$$ but it is both surprising and elegantly beautiful that these sums across all diagonals appear to approach the same value. Some additional observations from the numerically determined sums: Observation 2 The maximum value of any term ${k\choose a}\frac{1}{2^k}$ within a diagonal $a$ for the domain $(a>0)$ is attained at $k=2a-1$ and repeated for the term immediately following ( $k=2a$ ). Observation 3 $$\sum_{k=a}^{2a} {k\choose a}\frac{1}{2^k}=1$$ Observation 4 $$\sum_{k=a}^{n} {k\choose a}\frac{1}{2^k} + \sum_{k=n-a}^{n} {k\choose n-a}\frac{1}{2^k}=2$$ It's very likely that the general closed form has been derived before, but searching for the past several days has produced no results. It appears that setting up the appropriate generating function may play a role, but I am at a loss as to how to proceed. Looking forward to the responses.","This question already has answers here : Generalized binomial identity that converges to 2 [duplicate] (2 answers) Closed 2 years ago . I am looking for the derivation of the closed form along any given diagonal of Pascal's triangle, Numbered observations follow. As for the limit proposed in the title given by: Observation 1 when I calculate the sums numerically using MS Excel for any within the domain ( ) the sum approaches 2.000000 in all cases within total steps . The first series with is a familiar geometric series, and perhaps others look familiar to you as well: but it is both surprising and elegantly beautiful that these sums across all diagonals appear to approach the same value. Some additional observations from the numerically determined sums: Observation 2 The maximum value of any term within a diagonal for the domain is attained at and repeated for the term immediately following ( ). Observation 3 Observation 4 It's very likely that the general closed form has been derived before, but searching for the past several days has produced no results. It appears that setting up the appropriate generating function may play a role, but I am at a loss as to how to proceed. Looking forward to the responses.","a \sum_{k=a}^n {k\choose a}\frac{1}{2^k}=? \sum_{k=a}^\infty {k\choose a}\frac{1}{2^k}=2, a 0\le a \le100 n\le285 a=0 \sum_{k=0}^\infty {k\choose 0}\frac{1}{2^k}=1+\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+... =2, \sum_{k=1}^\infty {k\choose 1}\frac{1}{2^k}=\frac{1}{2}+\frac{1}{2}+\frac{3}{8}+\frac{1}{4}+\frac{5}{32}... =2, \sum_{k=2}^\infty {k\choose 2}\frac{1}{2^k}=\frac{1}{4}+\frac{3}{8}+\frac{3}{8}+\frac{5}{16}+\frac{15}{64}... =2, {k\choose a}\frac{1}{2^k} a (a>0) k=2a-1 k=2a \sum_{k=a}^{2a} {k\choose a}\frac{1}{2^k}=1 \sum_{k=a}^{n} {k\choose a}\frac{1}{2^k} + \sum_{k=n-a}^{n} {k\choose n-a}\frac{1}{2^k}=2","['sequences-and-series', 'summation', 'binomial-coefficients']"
94,"Proving convergence of a sequence $\{x_{n}\}$ satisfying$|f( x_{n}) |=|f'( x_{n+1}) ||x_{n} -a|$,where $f$ is a function satisfying some conditions.","Proving convergence of a sequence  satisfying,where  is a function satisfying some conditions.",\{x_{n}\} |f( x_{n}) |=|f'( x_{n+1}) ||x_{n} -a| f,"Theorem: Let $\displaystyle f:[ a,b]\rightarrow \mathbb{R}$ be a function differentiable on $\displaystyle [ a,b]$ such that $\displaystyle f( a) =0$ and that there exists $\displaystyle A\in \mathbb{R}$ such that $\displaystyle |f'( x) |\leq A|f( x) |$ for all $\displaystyle x\in [ a,b]$ , then $\displaystyle f\equiv 0$ on $\displaystyle [ a,b]$ . I tried to prove the above stated theorem and in the process I came across the question in title. Here's what I tried to prove the above stated theorem: For $\displaystyle A=0,$ the result is true so let $\displaystyle A >0.\ $ Suppose on the contrary that there exists $\displaystyle x_{0} \in ( a,b]$ such that $\displaystyle f( x_{0}) \neq 0$ . By MVT, there exists an $\displaystyle x_{1} \in ( a,x_{0})$ such that $\displaystyle |f( x_{0}) -f( a) |=|f'( x_{1}) ||x_{0} -a|\Longrightarrow |f( x_{0}) |=|f'( x_{1}) ||x_{0} -a|$ . Similarly, there exists $\displaystyle x_{2} \in ( a,x_{1})$ such that $\displaystyle |f( x_{1}) |=|f'( x_{2}) ||x_{1} -a|$ .  We continue like this and having found $\displaystyle x_{0} ,x_{1} ,x_{2} ,...,x_{n-1}$ we find $\displaystyle x_{n}$ by applying MVT on $\displaystyle [ a,x_{n-1}]$ so the construction of decreasing sequence $\displaystyle \{x_{n} \}$ can be done. So we have a sequence $\displaystyle \{x_{n} \}$ such that $\displaystyle x_{n}  >x_{n+1}$ for all $\displaystyle n\in \mathbb{N} \cup \{0\}$ and $\displaystyle |f( x_{n}) |=|f'( x_{n+1}) ||x_{n} -a|$ for all $\displaystyle n\in \mathbb{N} \cup \{0\}$ . It is clear that the sequence is bounded below by $\displaystyle a$ and hence it must converge. Intuitively, it seems to me that the sequence $\displaystyle \{x_{n} \}$ converges to $\displaystyle a$ . But I am having difficulties proving it (please refer Note ). Assuming that $\displaystyle x_{n}\rightarrow a$ , the theorem can be proved as follows: We have: $\displaystyle |f( x_{0}) |=|f'( x_{1}) ||x_{0} -a|\leq A|f( x_{1}) ||x_{0} -a|=A|f'( x_{2}) ||x_{0} -a||x_{1} -a|\leq A^{2} |f( x_{2}) ||x_{0} -a||x_{1} -a|$ Proceeding like this to get: \begin{equation*} |f( x_{0}) |\leq A^{n+1} |f( x_{n+1}) ||x_{0} -a||x_{1} -a|...|x_{n} -a|\leq A^{n+1} s|x_{0} -a||x_{1} -a|...|x_{n} -a| \end{equation*} where $\displaystyle s=\max |f|[ a,b]$ , which is finite because $\displaystyle |f|$ is continuous on $\displaystyle [ a,b] .$ I take $\displaystyle n-$ th root on both sides to get: \begin{equation*} |f( x_{0}) |^{\frac{1}{n}} \leq A^{\frac{1}{n} +1} s^{\frac{1}{n}}( |x_{0} -a||x_{1} -a|...|x_{n} -a|)^{\frac{1}{n}} \end{equation*} Now taking $\displaystyle n\rightarrow \infty $ on both sides to get $\displaystyle |f( x_{0}) |^{\frac{1}{n}}\rightarrow 0$ (please note that $\displaystyle ( |x_{0} -a||x_{1} -a|...|x_{n} -a|)^{\frac{1}{n}}\rightarrow 0$ because $\displaystyle x_{n}\rightarrow a$ ). Now $\displaystyle \left( |f( x_{0}) |^{\frac{1}{n}}\rightarrow 0\right) \Longrightarrow |f( x_{0}) |=0$ , which is a contradiction. Note: Let $\displaystyle x_{n}\rightarrow l$ then from the iterative definition of our $x_{n}$ , i.e. $\displaystyle |f( x_{n}) |=|f'( x_{n+1}) ||x_{n} -a|$ and noting that $|f|$ is continuous, we should get $\displaystyle |f( l) |\leq A|f( l) ||l-a|$ , which is where I got stuck as it does not give me $\displaystyle l=a$ . Please help me to prove that $\displaystyle x_{n}\rightarrow a$ . Thanks.","Theorem: Let be a function differentiable on such that and that there exists such that for all , then on . I tried to prove the above stated theorem and in the process I came across the question in title. Here's what I tried to prove the above stated theorem: For the result is true so let Suppose on the contrary that there exists such that . By MVT, there exists an such that . Similarly, there exists such that .  We continue like this and having found we find by applying MVT on so the construction of decreasing sequence can be done. So we have a sequence such that for all and for all . It is clear that the sequence is bounded below by and hence it must converge. Intuitively, it seems to me that the sequence converges to . But I am having difficulties proving it (please refer Note ). Assuming that , the theorem can be proved as follows: We have: Proceeding like this to get: where , which is finite because is continuous on I take th root on both sides to get: Now taking on both sides to get (please note that because ). Now , which is a contradiction. Note: Let then from the iterative definition of our , i.e. and noting that is continuous, we should get , which is where I got stuck as it does not give me . Please help me to prove that . Thanks.","\displaystyle f:[ a,b]\rightarrow \mathbb{R} \displaystyle [ a,b] \displaystyle f( a) =0 \displaystyle A\in \mathbb{R} \displaystyle |f'( x) |\leq A|f( x) | \displaystyle x\in [ a,b] \displaystyle f\equiv 0 \displaystyle [ a,b] \displaystyle A=0, \displaystyle A >0.\  \displaystyle x_{0} \in ( a,b] \displaystyle f( x_{0}) \neq 0 \displaystyle x_{1} \in ( a,x_{0}) \displaystyle |f( x_{0}) -f( a) |=|f'( x_{1}) ||x_{0} -a|\Longrightarrow |f( x_{0}) |=|f'( x_{1}) ||x_{0} -a| \displaystyle x_{2} \in ( a,x_{1}) \displaystyle |f( x_{1}) |=|f'( x_{2}) ||x_{1} -a| \displaystyle x_{0} ,x_{1} ,x_{2} ,...,x_{n-1} \displaystyle x_{n} \displaystyle [ a,x_{n-1}] \displaystyle \{x_{n} \} \displaystyle \{x_{n} \} \displaystyle x_{n}  >x_{n+1} \displaystyle n\in \mathbb{N} \cup \{0\} \displaystyle |f( x_{n}) |=|f'( x_{n+1}) ||x_{n} -a| \displaystyle n\in \mathbb{N} \cup \{0\} \displaystyle a \displaystyle \{x_{n} \} \displaystyle a \displaystyle x_{n}\rightarrow a \displaystyle |f( x_{0}) |=|f'( x_{1}) ||x_{0} -a|\leq A|f( x_{1}) ||x_{0} -a|=A|f'( x_{2}) ||x_{0} -a||x_{1} -a|\leq A^{2} |f( x_{2}) ||x_{0} -a||x_{1} -a| \begin{equation*}
|f( x_{0}) |\leq A^{n+1} |f( x_{n+1}) ||x_{0} -a||x_{1} -a|...|x_{n} -a|\leq A^{n+1} s|x_{0} -a||x_{1} -a|...|x_{n} -a|
\end{equation*} \displaystyle s=\max |f|[ a,b] \displaystyle |f| \displaystyle [ a,b] . \displaystyle n- \begin{equation*}
|f( x_{0}) |^{\frac{1}{n}} \leq A^{\frac{1}{n} +1} s^{\frac{1}{n}}( |x_{0} -a||x_{1} -a|...|x_{n} -a|)^{\frac{1}{n}}
\end{equation*} \displaystyle n\rightarrow \infty  \displaystyle |f( x_{0}) |^{\frac{1}{n}}\rightarrow 0 \displaystyle ( |x_{0} -a||x_{1} -a|...|x_{n} -a|)^{\frac{1}{n}}\rightarrow 0 \displaystyle x_{n}\rightarrow a \displaystyle \left( |f( x_{0}) |^{\frac{1}{n}}\rightarrow 0\right) \Longrightarrow |f( x_{0}) |=0 \displaystyle x_{n}\rightarrow l x_{n} \displaystyle |f( x_{n}) |=|f'( x_{n+1}) ||x_{n} -a| |f| \displaystyle |f( l) |\leq A|f( l) ||l-a| \displaystyle l=a \displaystyle x_{n}\rightarrow a","['real-analysis', 'sequences-and-series', 'proof-writing']"
95,"How many of the first $100$ terms are the same in the arithmetic sequences $2,9,16,\ldots$ and $5,11,17,\ldots$?",How many of the first  terms are the same in the arithmetic sequences  and ?,"100 2,9,16,\ldots 5,11,17,\ldots","If $\{a_n\}$ is an arithmetic sequence with 100 terms where $a_1=2$ and $a_2=9$ , and $\{b_n\}$ is an arithmetic sequence with 100 terms where $b_1=5$ and $b_2=11$ , how many terms are the same in each sequence? I think the answer is 17, but how I got it seemed too easy and I just want someone to verify my answer. Here is how I found my solution: The sequence for $$a_n= 2, 9, 16, 23, 30, 37, 44, 51, 58, 65, 72,79,86,93,100,107,114,121,\ldots$$ The sequence for $$b_n= 5, 11,17, 23, 29, 35, 41, 47, 53, 59, 65, 71,77,83,89,95,101,107, \ldots$$ Ignoring the 1st four terms, I noticed that after the 4th term, the same terms appear in every 6th term for $a_n$ and 7th term for $b_n$ . Therefore, $100-4=96/6=16$ . Then I added $1$ to include $23$ . I hope this makes sense and thank you for your help.","If is an arithmetic sequence with 100 terms where and , and is an arithmetic sequence with 100 terms where and , how many terms are the same in each sequence? I think the answer is 17, but how I got it seemed too easy and I just want someone to verify my answer. Here is how I found my solution: The sequence for The sequence for Ignoring the 1st four terms, I noticed that after the 4th term, the same terms appear in every 6th term for and 7th term for . Therefore, . Then I added to include . I hope this makes sense and thank you for your help.","\{a_n\} a_1=2 a_2=9 \{b_n\} b_1=5 b_2=11 a_n= 2, 9, 16, 23, 30, 37, 44, 51, 58, 65, 72,79,86,93,100,107,114,121,\ldots b_n= 5, 11,17, 23, 29, 35, 41, 47, 53, 59, 65, 71,77,83,89,95,101,107, \ldots a_n b_n 100-4=96/6=16 1 23","['sequences-and-series', 'algebra-precalculus']"
96,Can a power series conditionally converge outside its radius of convergence?,Can a power series conditionally converge outside its radius of convergence?,,"Having learned about conditional and absolute convergence of series, I was confused when the methods used to find the interval of convergence of a power series seemed to consider only absolute convergence. Let $\sum_{n = 0}^\infty b_n (x-c)^n$ be a power series with $\lim_{n\to \infty} \lvert \frac{b_n}{b_{n+1}} \rvert = R$ where $R \ne 0$ . Usually, to find the interval and radius of convergence of $\sum_{n = 0}^\infty b_n (x-c)^n$ , we check absolute convergence. Let $a_n = \lvert b_n(x-c)^n \rvert$ . Using the Ratio Test, $$ \lim_{n\to \infty} \frac{a_n}{a_{n+1}} = \lim_{n\to \infty} \lvert \frac{b_{n+1}(x-c)^{n+1}}{b_n(x-c)^n} \rvert $$ $$= \lvert x-c \rvert\lim_{n\to \infty} \lvert \frac{b_{n+1}}{b_n} \rvert$$ $$= \frac{\lvert x-c \rvert}{R}$$ By the Ratio Test, $\sum_{n = 0}^\infty a_n$ converges for $\frac{\lvert x-c \rvert}{R} < 1 \iff \lvert x-c \rvert < R$ . Absolute convergence implies convergence, so $\sum_{n = 0}^\infty b_n (x-c)^n$ is convergent for $\lvert x-c \rvert < R$ . For the endpoints $x = c$ or $x = -c$ , the Ratio Test for $\sum_{n = 0}^\infty a_n$ is inconclusive, so we usually test $\sum_{n = 0}^\infty b_n (x-c)^n$ using methods other than the Ratio Test at the endpoints. We usually consider $[-R+c,R+c], (-R+c,R+c], [-R+c,R+c),$ or $(-R+c,R+c)$ to be the radius of convergence depending on the convergence of the series at the endpoints. According to the calculations above, $\sum_{n = 0}^\infty a_n$ is divergent for $\lvert x-c \rvert > R$ . However, this only means that $\sum_{n = 0}^\infty b_n (x-c)^n$ is not absolutely convergent. Could it be conditionally convergent for some $\lvert x-c \rvert > R$ ? I would be grateful if you could explain this in a way that is understandable to an undergraduate student like myself. Thank you.","Having learned about conditional and absolute convergence of series, I was confused when the methods used to find the interval of convergence of a power series seemed to consider only absolute convergence. Let be a power series with where . Usually, to find the interval and radius of convergence of , we check absolute convergence. Let . Using the Ratio Test, By the Ratio Test, converges for . Absolute convergence implies convergence, so is convergent for . For the endpoints or , the Ratio Test for is inconclusive, so we usually test using methods other than the Ratio Test at the endpoints. We usually consider or to be the radius of convergence depending on the convergence of the series at the endpoints. According to the calculations above, is divergent for . However, this only means that is not absolutely convergent. Could it be conditionally convergent for some ? I would be grateful if you could explain this in a way that is understandable to an undergraduate student like myself. Thank you.","\sum_{n = 0}^\infty b_n (x-c)^n \lim_{n\to \infty} \lvert \frac{b_n}{b_{n+1}} \rvert = R R \ne 0 \sum_{n = 0}^\infty b_n (x-c)^n a_n = \lvert b_n(x-c)^n \rvert  \lim_{n\to \infty} \frac{a_n}{a_{n+1}} = \lim_{n\to \infty} \lvert \frac{b_{n+1}(x-c)^{n+1}}{b_n(x-c)^n} \rvert  = \lvert x-c \rvert\lim_{n\to \infty} \lvert \frac{b_{n+1}}{b_n} \rvert = \frac{\lvert x-c \rvert}{R} \sum_{n = 0}^\infty a_n \frac{\lvert x-c \rvert}{R} < 1 \iff \lvert x-c \rvert < R \sum_{n = 0}^\infty b_n (x-c)^n \lvert x-c \rvert < R x = c x = -c \sum_{n = 0}^\infty a_n \sum_{n = 0}^\infty b_n (x-c)^n [-R+c,R+c], (-R+c,R+c], [-R+c,R+c), (-R+c,R+c) \sum_{n = 0}^\infty a_n \lvert x-c \rvert > R \sum_{n = 0}^\infty b_n (x-c)^n \lvert x-c \rvert > R","['sequences-and-series', 'power-series', 'absolute-convergence', 'conditional-convergence']"
97,Rudin Theorem $3.4 (b)$,Rudin Theorem,3.4 (b),"Rudin left this proof as an exercise, so I would appreciate if someone could look over my attempt. (b) Suppose $\{x_n\}$ , $\{y_n\}$ are sequences in $\mathbb{R}^k$ , $\{\beta_n\}$ is a sequence of real numbers, and $x_n \to x$ , $y_n \to y$ , $\beta_n \to \beta$ . Then \begin{align*} \lim\limits_{n \to \infty} (x_n + y_n) & = x + y \\ \lim\limits_{n \to \infty} x_n \cdot y_n & = x \cdot y \\ \lim\limits_{n \to \infty} \beta_n x_n & = \beta x. \end{align*} Here is my attempt. I'm going to stick to the notation used by Rudin. Let $x_n = (a_{1,n}, \ldots, a_{k,n})$ , $y_n = (b_{1,n} \ldots, b_{k,n})$ , $\beta_n = (\beta_1, \ldots, \beta_k)$ , $x = (a_1, \ldots, a_n)$ , $y = (b_1, \ldots, b_n)$ . Then for any $n$ , we have: $$  x_n + y_n = (a_{1,n} + b_{1,n}, \ldots, a_{k,n} + b_{k,n}) $$ Since $x_n \to x$ , by part (a), the sequence converges component-wise, so $a_{j,n} \to a_j$ for each $j$ . Since $y_n \to y$ , we have $b_{j,n} \to b_j$ for each $j$ . So for each $j$ , $a_{j,n} + b_{j,n} \to a_j + b_j$ by Theorem 3.3(a) (sum of convergent sequences). So, by part (a) again, since $x_n + y_n$ converges componentwise, we have $$  x_n + y_n \to (a_1 + b_1, \ldots, a_k + b_k) = (a_1, \ldots, a_k) + (b_1, \ldots, b_k) = x + y. $$ Moving to the second limit. For any $n$ , we have $$  x_n \cdot y_n = (a_{1,n}, \ldots, a_{k,n}) \cdot (b_{1,n}, \ldots, a_{k,n}) = \sum\limits_{i=1}^k a_{i,n} b_{i,n}. $$ Again, as $x_n \to x$ , we have $a_{j,n} \to a_j$ , and as $y_n \to y$ , we have $b_{j,n} \to b_j$ . By Theorem 3.3, products of convergent sequences convergence, so for each $j$ , we have $a_{j,n} b_{j,n}$ converges to $a_j b_j$ . By Theorem 3.3 again and induction on $k$ , we have \begin{align*} \sum\limits_{i=1}^k a_{i,n} b_{i,n} \to \sum\limits_{i=1}^k a_i b_i = (a_1, \ldots, a_k) \cdot (b_1, \ldots, b_k) = x \cdot y. \end{align*} Moving now to the third limit. For any $n$ , we have $$  \beta_n x_n = (\beta_n a_{1,n}, \ldots, \beta_{n} a_{k,n}). $$ By Theorem 3.3, for each $j$ , we have $\beta_n a_{j,n} \to \beta a_j$ (product of convergent sequences). So $\beta_n x_n$ converges component-wise, so it converges, and we have $$  \beta_n x_n \to (\beta a_1, \ldots, \beta a_k) = \beta (a_1, \ldots, a_k) = \beta x. $$ How do these look?","Rudin left this proof as an exercise, so I would appreciate if someone could look over my attempt. (b) Suppose , are sequences in , is a sequence of real numbers, and , , . Then Here is my attempt. I'm going to stick to the notation used by Rudin. Let , , , , . Then for any , we have: Since , by part (a), the sequence converges component-wise, so for each . Since , we have for each . So for each , by Theorem 3.3(a) (sum of convergent sequences). So, by part (a) again, since converges componentwise, we have Moving to the second limit. For any , we have Again, as , we have , and as , we have . By Theorem 3.3, products of convergent sequences convergence, so for each , we have converges to . By Theorem 3.3 again and induction on , we have Moving now to the third limit. For any , we have By Theorem 3.3, for each , we have (product of convergent sequences). So converges component-wise, so it converges, and we have How do these look?","\{x_n\} \{y_n\} \mathbb{R}^k \{\beta_n\} x_n \to x y_n \to y \beta_n \to \beta \begin{align*}
\lim\limits_{n \to \infty} (x_n + y_n) & = x + y \\
\lim\limits_{n \to \infty} x_n \cdot y_n & = x \cdot y \\
\lim\limits_{n \to \infty} \beta_n x_n & = \beta x.
\end{align*} x_n = (a_{1,n}, \ldots, a_{k,n}) y_n = (b_{1,n} \ldots, b_{k,n}) \beta_n = (\beta_1, \ldots, \beta_k) x = (a_1, \ldots, a_n) y = (b_1, \ldots, b_n) n  
x_n + y_n = (a_{1,n} + b_{1,n}, \ldots, a_{k,n} + b_{k,n})
 x_n \to x a_{j,n} \to a_j j y_n \to y b_{j,n} \to b_j j j a_{j,n} + b_{j,n} \to a_j + b_j x_n + y_n  
x_n + y_n \to (a_1 + b_1, \ldots, a_k + b_k) = (a_1, \ldots, a_k) + (b_1, \ldots, b_k) = x + y.
 n  
x_n \cdot y_n = (a_{1,n}, \ldots, a_{k,n}) \cdot (b_{1,n}, \ldots, a_{k,n}) = \sum\limits_{i=1}^k a_{i,n} b_{i,n}.
 x_n \to x a_{j,n} \to a_j y_n \to y b_{j,n} \to b_j j a_{j,n} b_{j,n} a_j b_j k \begin{align*}
\sum\limits_{i=1}^k a_{i,n} b_{i,n} \to \sum\limits_{i=1}^k a_i b_i = (a_1, \ldots, a_k) \cdot (b_1, \ldots, b_k) = x \cdot y.
\end{align*} n  
\beta_n x_n = (\beta_n a_{1,n}, \ldots, \beta_{n} a_{k,n}).
 j \beta_n a_{j,n} \to \beta a_j \beta_n x_n  
\beta_n x_n \to (\beta a_1, \ldots, \beta a_k) = \beta (a_1, \ldots, a_k) = \beta x.
","['sequences-and-series', 'solution-verification']"
98,$f_n(x)= f(x+n)$ show that the limit function is uniformly continuous,show that the limit function is uniformly continuous,f_n(x)= f(x+n),"Let $f$ be a real-valued continuous function on $I=\{x\in \mathbb{R} | x \geq 0\}$ . For a positive integer $n$ the function on $I$ is defined by \begin{align*}f_n(x)= f(x+n)\end{align*} Answer the following questions when the sequence of functions $\{f_n(x)\}_{n=1}^\infty$ converges uniformly on $I$ The function $g$ on $I$ is defined by $g(x)=\lim _{n\xrightarrow{}{}\infty}f_n(x)$ , show that $g$ is uniformly continuous on $I$ show that $f$ is uniformly continuous on $I$ Here we need to show that $|g(x)-g(y)|<\epsilon$ whenever $|x-y|<\delta$ for all $x,y\in I$ . Since $\{f_n(x)\}_{n=1}^\infty$ coverge uniformly to $g$ we have $|f_n{(x)}-g(x)|<\epsilon \implies |f(x+n)-g(x)|<\epsilon$ whenever $n>N$ . How do we proceed from here. Any hints or a solution would be appreciated.","Let be a real-valued continuous function on . For a positive integer the function on is defined by Answer the following questions when the sequence of functions converges uniformly on The function on is defined by , show that is uniformly continuous on show that is uniformly continuous on Here we need to show that whenever for all . Since coverge uniformly to we have whenever . How do we proceed from here. Any hints or a solution would be appreciated.","f I=\{x\in \mathbb{R} | x \geq 0\} n I \begin{align*}f_n(x)= f(x+n)\end{align*} \{f_n(x)\}_{n=1}^\infty I g I g(x)=\lim _{n\xrightarrow{}{}\infty}f_n(x) g I f I |g(x)-g(y)|<\epsilon |x-y|<\delta x,y\in I \{f_n(x)\}_{n=1}^\infty g |f_n{(x)}-g(x)|<\epsilon \implies |f(x+n)-g(x)|<\epsilon n>N","['sequences-and-series', 'continuity', 'uniform-convergence', 'uniform-continuity', 'sequence-of-function']"
99,Prime numbers dividing infinitely many numbers in a sequence,Prime numbers dividing infinitely many numbers in a sequence,,"Here I found a question: Show that every prime not equal to $2$ or $5$ divides infinitely many of the numbers $1,11,111,1111,\dots$ etc. which is partly solved here Prime numbers divide an element from a set . From this the following conjecture seems reasonable: Given any finite set $S=\{q_1,\dots,q_k\}$ of $k$ primes, then any prime $p\notin S$ divides infinitely many of the numbers $a_1,a_2,a_3\dots$ , where $a_1=1$ and $a_{n+1}=1+a_n\prod q_i$ . Can this be proved?","Here I found a question: Show that every prime not equal to or divides infinitely many of the numbers etc. which is partly solved here Prime numbers divide an element from a set . From this the following conjecture seems reasonable: Given any finite set of primes, then any prime divides infinitely many of the numbers , where and . Can this be proved?","2 5 1,11,111,1111,\dots S=\{q_1,\dots,q_k\} k p\notin S a_1,a_2,a_3\dots a_1=1 a_{n+1}=1+a_n\prod q_i","['sequences-and-series', 'elementary-number-theory', 'divisibility']"
