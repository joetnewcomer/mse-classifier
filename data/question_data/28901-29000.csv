,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Why do we always assume waiting time has exponential distribution?,Why do we always assume waiting time has exponential distribution?,,"In many continuous models, like waiting for a car, we always assume the waiting time $t$ to have an exponential distribution. Why is such an assumption appropriate?","In many continuous models, like waiting for a car, we always assume the waiting time $t$ to have an exponential distribution. Why is such an assumption appropriate?",,"['probability', 'stochastic-processes']"
1,Density of randomly packing a box,Density of randomly packing a box,,"I want to throw a lot of copies of an object of nonzero volume, randomly into a large box. Ignoring boundary effects of the box, with which type of object will the expected packing density be the largest? Is anything known about the 2D analogue, with any kind of random dropping of objects.","I want to throw a lot of copies of an object of nonzero volume, randomly into a large box. Ignoring boundary effects of the box, with which type of object will the expected packing density be the largest? Is anything known about the 2D analogue, with any kind of random dropping of objects.",,"['probability', 'geometry', 'packing-problem']"
2,Expected tetrahedron volume from normal distribution,Expected tetrahedron volume from normal distribution,,"Two equivalent formulas for the volume of a random tetrahedron are given. Further on you can find an interesting conjecture for the expected volume that shall be proved. Tetrahedron volume Given are 12 independent standard normal distributed variables $$x_i=\mathcal{N}(0,1)_{i=1,...,12}$$ that define the 4 coordinates $$\vec{a}=(x_1,x_2,x_3),\;\; \vec{b}=(x_4,x_5,x_6),\;\; \vec{c}=(x_7,x_8,x_9),\;\; \vec{d}=(x_{10},x_{11},x_{12})$$ of a 3-simplex in $\mathbb{R}^3$ . The first formula for the non-oriented simplex volume is $$V=\frac{1}{6}\left| (\vec{a}-\vec{d})\cdot \left((\vec{b}-\vec{d}) \times (\vec{c}-\vec{d})\right) \right|\tag{1}$$ $$=\frac{1}{6}\left| x_2 x_6 x_7 + x_3 x_4 x_8+ x_1 x_5 x_9+ x_3 x_5 x_{10} + x_6 x_8 x_{10} + x_2 x_9 x_{10}+ x_1 x_6 x_{11}+  x_3 x_7 x_{11}+  x_4 x_9 x_{11}+ x_2 x_4 x_{12}+ x_5 x_7 x_{12}+ x_1 x_8 x_{12}-x_3 x_5 x_7- x_2 x_6 x_{10}-  x_3 x_8 x_{10} - x_1 x_6 x_8 - x_2 x_4 x_{9}- x_5 x_9 x_{10}- x_3 x_4 x_{11}- x_6 x_7 x_{11}- x_1 x_9 x_{11}- x_1 x_5 x_{12}- x_2 x_7 x_{12}- x_4 x_8 x_{12}\right|.$$ If the coordinate system is shifted $$\vec{p}=\vec{a}-\vec{d},\;\;\vec{q}=\vec{b}-\vec{d},\;\;\vec{r}=\vec{c}-\vec{d}$$ the new coordinates are $$\vec{p}=(y_1,y_2,y_3),\;\; \vec{q}=(y_4,y_5,y_6),\;\;\vec{r}=(y_7,y_8,y_9)$$ with new random variables $$y_i=\mathcal{N}(0,\sqrt{2})_{i=1,...,9}.$$ The shift reduces the number of random variables from 12 to 9 and increases the standard deviation from $1$ to $\sqrt{2}$ (this corresponds to a double variance $=\sqrt{2}^2)$ . However the variables are not independent anymore. Their correlation $\rho=0.5$ is given by their covariance normalized by the standard deviation $$\rho=\frac{\mathbb{Cov}[y_i,y_j]}{\sqrt{\mathbb{Var}[y_i]}\sqrt{\mathbb{Var}[y_j]}}= \frac{\mathbb{Cov}[x_m-x_k,x_n-x_k]}{\sqrt{\mathbb{Var}[x_m-x_k]}\sqrt{\mathbb{Var}[x_n-x_k]}} =\frac{\mathbb{E}[x_k^2]}{\sqrt{\mathbb{Var}[x_m-x_k]}\sqrt{\mathbb{Var}[x_n-x_k]}}=\frac{\mathbb{E}[x_k]^2+\mathbb{Var}[x_k]}{\sqrt{\mathbb{Var}[x_m-x_k]}\sqrt{\mathbb{Var}[x_n-x_k]}} =\frac{1}{\sqrt{2}\sqrt{2}}=\frac{1}{2}\;\;\;\text{for}\;i\ne j \land n\ne m \ne k.$$ The second formula for the non-oriented volume as function of the dependent variables is $$V=\frac{1}{6}\left|\vec{p}\cdot (\vec{q} \times \vec{r}\right)|\tag{2}$$ $$=\frac{1}{6}\left| y_2y_6y_7+y_3y_4y_8+y_1y_5y_9-y_1y_6y_8-y_2y_4y_9-y_3y_5y_7\right|.$$ Equation (2) has only a quarter of summands of eq.(1) however the variables correlate with $\rho=0.5$ . Question What is the analytical expression for the expected volume $\mathbb{E}[V]$ ? What is known? Conjecture It is conjectured that $\mathbb{E}[V]=\frac{2}{3}\sqrt{\frac{2}{\pi}}$ or $\mathbb{E}[V]=\frac{21}{4\pi^2}$ . Assuming  the first conjecture is true please note the relation to a standard half-normal distribution in $\mathbb{R^1}$ that has expectation $\sqrt{\frac{2}{\pi}}$ . Moments All even moments are precisely known and the odd moments are approximately known. The first moments are \begin{array}{|l|l|}\hline \text{odd moments} & \text{even moments} \\ \text{(simulation)} & \text{(analytic)} \\ \hline m_1\approx 0.532 & m_2=\frac{2}{3}\\ \hline m_3\approx\sqrt{2} &m_4=\frac{40}{9} \\ \hline m_5\approx18.9 &m_6=\frac{2800}{27} \\ \hline \end{array} (more moments on demand). Solution strategies One could try to integrate over a subvolume where the sign of the volume is constant. Due to symmetry every subvolume should have equal size. The challenge is therefore to find the right suitable integration borders. A related question about the expected area of a triangle with standard normal distributed coordinates in $\mathbb{R}^3$ was proven to be $\sqrt{3}$ . If these methods would be applied to the tetrahedron case then according to the answerer ""ultimately it comes down to the product of independent chi-distributed variables and a variable for the spherical angle they determine: finding the expectation of the latter is the crux of the question."" Other equations for the volume There are other methods to calculate the volume however they include at least 1 square root, an unwanted property for such problems. Expected oriented volume The expression for the volume is a sum of triple products of random variables. As the expectations of the independent $x_i$ in eq.(1) are $\mathbb{E}[x_i]=0$ it holds $$\mathbb{E}[x_i x_j x_k\pm x_l x_m x_n]=0\cdot 0 \cdot 0\pm 0\cdot 0 \cdot 0=0\;\;\;\text{for}\; 1\le i,j,k,l,m,n \le 12$$ The expected oriented volume is therefore $0$ .","Two equivalent formulas for the volume of a random tetrahedron are given. Further on you can find an interesting conjecture for the expected volume that shall be proved. Tetrahedron volume Given are 12 independent standard normal distributed variables that define the 4 coordinates of a 3-simplex in . The first formula for the non-oriented simplex volume is If the coordinate system is shifted the new coordinates are with new random variables The shift reduces the number of random variables from 12 to 9 and increases the standard deviation from to (this corresponds to a double variance . However the variables are not independent anymore. Their correlation is given by their covariance normalized by the standard deviation The second formula for the non-oriented volume as function of the dependent variables is Equation (2) has only a quarter of summands of eq.(1) however the variables correlate with . Question What is the analytical expression for the expected volume ? What is known? Conjecture It is conjectured that or . Assuming  the first conjecture is true please note the relation to a standard half-normal distribution in that has expectation . Moments All even moments are precisely known and the odd moments are approximately known. The first moments are (more moments on demand). Solution strategies One could try to integrate over a subvolume where the sign of the volume is constant. Due to symmetry every subvolume should have equal size. The challenge is therefore to find the right suitable integration borders. A related question about the expected area of a triangle with standard normal distributed coordinates in was proven to be . If these methods would be applied to the tetrahedron case then according to the answerer ""ultimately it comes down to the product of independent chi-distributed variables and a variable for the spherical angle they determine: finding the expectation of the latter is the crux of the question."" Other equations for the volume There are other methods to calculate the volume however they include at least 1 square root, an unwanted property for such problems. Expected oriented volume The expression for the volume is a sum of triple products of random variables. As the expectations of the independent in eq.(1) are it holds The expected oriented volume is therefore .","x_i=\mathcal{N}(0,1)_{i=1,...,12} \vec{a}=(x_1,x_2,x_3),\;\; \vec{b}=(x_4,x_5,x_6),\;\; \vec{c}=(x_7,x_8,x_9),\;\; \vec{d}=(x_{10},x_{11},x_{12}) \mathbb{R}^3 V=\frac{1}{6}\left| (\vec{a}-\vec{d})\cdot \left((\vec{b}-\vec{d}) \times (\vec{c}-\vec{d})\right) \right|\tag{1} =\frac{1}{6}\left| x_2 x_6 x_7 + x_3 x_4 x_8+ x_1 x_5 x_9+ x_3 x_5 x_{10} + x_6 x_8 x_{10} + x_2 x_9 x_{10}+ x_1 x_6 x_{11}+  x_3 x_7 x_{11}+  x_4 x_9 x_{11}+ x_2 x_4 x_{12}+ x_5 x_7 x_{12}+ x_1 x_8 x_{12}-x_3 x_5 x_7- x_2 x_6 x_{10}-  x_3 x_8 x_{10} - x_1 x_6 x_8 - x_2 x_4 x_{9}- x_5 x_9 x_{10}- x_3 x_4 x_{11}- x_6 x_7 x_{11}- x_1 x_9 x_{11}- x_1 x_5 x_{12}- x_2 x_7 x_{12}- x_4 x_8 x_{12}\right|. \vec{p}=\vec{a}-\vec{d},\;\;\vec{q}=\vec{b}-\vec{d},\;\;\vec{r}=\vec{c}-\vec{d} \vec{p}=(y_1,y_2,y_3),\;\; \vec{q}=(y_4,y_5,y_6),\;\;\vec{r}=(y_7,y_8,y_9) y_i=\mathcal{N}(0,\sqrt{2})_{i=1,...,9}. 1 \sqrt{2} =\sqrt{2}^2) \rho=0.5 \rho=\frac{\mathbb{Cov}[y_i,y_j]}{\sqrt{\mathbb{Var}[y_i]}\sqrt{\mathbb{Var}[y_j]}}=
\frac{\mathbb{Cov}[x_m-x_k,x_n-x_k]}{\sqrt{\mathbb{Var}[x_m-x_k]}\sqrt{\mathbb{Var}[x_n-x_k]}}
=\frac{\mathbb{E}[x_k^2]}{\sqrt{\mathbb{Var}[x_m-x_k]}\sqrt{\mathbb{Var}[x_n-x_k]}}=\frac{\mathbb{E}[x_k]^2+\mathbb{Var}[x_k]}{\sqrt{\mathbb{Var}[x_m-x_k]}\sqrt{\mathbb{Var}[x_n-x_k]}}
=\frac{1}{\sqrt{2}\sqrt{2}}=\frac{1}{2}\;\;\;\text{for}\;i\ne j \land n\ne m \ne k. V=\frac{1}{6}\left|\vec{p}\cdot (\vec{q} \times \vec{r}\right)|\tag{2} =\frac{1}{6}\left| y_2y_6y_7+y_3y_4y_8+y_1y_5y_9-y_1y_6y_8-y_2y_4y_9-y_3y_5y_7\right|. \rho=0.5 \mathbb{E}[V] \mathbb{E}[V]=\frac{2}{3}\sqrt{\frac{2}{\pi}} \mathbb{E}[V]=\frac{21}{4\pi^2} \mathbb{R^1} \sqrt{\frac{2}{\pi}} \begin{array}{|l|l|}\hline
\text{odd moments} & \text{even moments} \\
\text{(simulation)} & \text{(analytic)} \\ \hline
m_1\approx 0.532 & m_2=\frac{2}{3}\\ \hline
m_3\approx\sqrt{2} &m_4=\frac{40}{9} \\ \hline
m_5\approx18.9 &m_6=\frac{2800}{27} \\ \hline
\end{array} \mathbb{R}^3 \sqrt{3} x_i \mathbb{E}[x_i]=0 \mathbb{E}[x_i x_j x_k\pm x_l x_m x_n]=0\cdot 0 \cdot 0\pm 0\cdot 0 \cdot 0=0\;\;\;\text{for}\; 1\le i,j,k,l,m,n \le 12 0","['probability', 'probability-distributions', 'normal-distribution', 'simplex', 'geometric-probability']"
3,Variance of the Euclidean norm under finite moment assumptions,Variance of the Euclidean norm under finite moment assumptions,,"Let $X = (X_1,X_2 \cdots X_n)$ be random vector in $R^n$ with independent coordinate $X_i$ that satisfy $E[X_i^2]=1$ and $E[X_i^4] \leq K^4$ . Then show that $$\operatorname{Var}(\| X\|_2) \leq CK^4$$ where $C$ is a absolute  constant and $\|   \ \|_2$ denotes euclidian norm. Here is my attempt: $$\begin{align*}   E(\|X\|_2^2 -n)^2 &= E[(\sum_{i=1}^n X_i^2)^2 ]-n^2 \\ &=E[\sum_{i=1}^n X_i^4]+E[\sum_{i<j}X_i^2X_j^2]  -n^2 \\ &\leq nK^4 +  2{{n}\choose {2}}-n^2 \\ &\leq n(K^4-1) \\ & \leq nk^4 \end{align*}$$ since $$ E(\|X\|_2^2 -n)^2 \leq nk^4 \rightarrow E\left(\frac{\|X\|_2^2}{n} -1\right)^2 \leq \frac{K^4}{n}$$ and  since $$(\forall z \geq 0 \ \ |z-1|\leq |z^2-1|) \rightarrow   E(\frac{\|X\|_2}{\sqrt n} -1)^2\leq E(\frac{\|X\|_2^2}{n} -1)^2 $$ thus: $$E(\frac{\|X\|_2}{\sqrt n} -1)^2 \leq K^4/n  \rightarrow E(\|X\|_2-\sqrt n)^2\leq K^4$$ by Jensen inequality: $$(E[\|X\|_2] - \sqrt n)^2 \leq K^4 $$ which is equivalence to $$ |E[\|X\|_2] - \sqrt n)| \leq K^2$$ then when I am trying to bound $Var(\| X\|_2)$ I meet some problem : $$\operatorname{Var}(\| X\|_2)=E[\|X\|_2^2] -(E[\|X\|_2])^2 \leq n- (K^2-\sqrt n)^2 \leq -K^4+2K^2\sqrt n$$ which is not bound by constant , how can I bound that?","Let be random vector in with independent coordinate that satisfy and . Then show that where is a absolute  constant and denotes euclidian norm. Here is my attempt: since and  since thus: by Jensen inequality: which is equivalence to then when I am trying to bound I meet some problem : which is not bound by constant , how can I bound that?","X = (X_1,X_2 \cdots X_n) R^n X_i E[X_i^2]=1 E[X_i^4] \leq K^4 \operatorname{Var}(\| X\|_2) \leq CK^4 C \|   \ \|_2 \begin{align*}   E(\|X\|_2^2 -n)^2 &= E[(\sum_{i=1}^n X_i^2)^2 ]-n^2 \\
&=E[\sum_{i=1}^n X_i^4]+E[\sum_{i<j}X_i^2X_j^2]  -n^2 \\
&\leq nK^4 +  2{{n}\choose {2}}-n^2 \\
&\leq n(K^4-1) \\
& \leq nk^4
\end{align*}  E(\|X\|_2^2 -n)^2 \leq nk^4 \rightarrow E\left(\frac{\|X\|_2^2}{n} -1\right)^2 \leq \frac{K^4}{n} (\forall z \geq 0 \ \ |z-1|\leq |z^2-1|) \rightarrow
  E(\frac{\|X\|_2}{\sqrt n} -1)^2\leq E(\frac{\|X\|_2^2}{n} -1)^2  E(\frac{\|X\|_2}{\sqrt n} -1)^2 \leq K^4/n  \rightarrow E(\|X\|_2-\sqrt n)^2\leq K^4 (E[\|X\|_2] - \sqrt n)^2 \leq K^4   |E[\|X\|_2] - \sqrt n)| \leq K^2 Var(\| X\|_2) \operatorname{Var}(\| X\|_2)=E[\|X\|_2^2] -(E[\|X\|_2])^2 \leq n- (K^2-\sqrt n)^2 \leq -K^4+2K^2\sqrt n","['probability', 'random-variables', 'normed-spaces', 'variance', 'concentration-of-measure']"
4,Sum of subgaussian random variables,Sum of subgaussian random variables,,"Let $\{X_i\}_{i=1}^N$ be a set of $\nu$-subgaussian random variables, meaning $$ \mathbb{E}(\exp(tX_i)) \leq e^{\nu t^2/2}. $$ Suppose also that $X_i$ are normalized so that $\mathbb{E}(X_i) = 0$ and $\mathbb{E}(X_i^2) = 1$. Let $a_i$ be a fixed (deterministic) sequence of coefficients, and define the random variables $$ Y = \sum_{i=1}^N a_i X_i, $$ and its normalization $$ Z = \frac{Y}{\sqrt{\mathbb{E} Y^2}}.  $$ If the $X_i$ are assumed to be independent, then it is not hard to check that $Z$ is also $\nu$-subgaussian, because one can compute its moment generating function. My question is whether this hypothesis is necessary. Is $Z$ a $\nu$-subgaussian random variable, even if $X_i$ are not independent? The reason one might hope that this is true is that the normalization of $Z$ takes care of any growth of $Z$ that might arise from the dependencies. My best guess for how to prove this is to bound the joint distribution of $(X_i)$ by a multivariate Gaussian distribution, and then observe that $Y$ is some marginal and is therefore bounded by a Gaussian of the correct variance(?).  But I'm not sure how to fill in the details.","Let $\{X_i\}_{i=1}^N$ be a set of $\nu$-subgaussian random variables, meaning $$ \mathbb{E}(\exp(tX_i)) \leq e^{\nu t^2/2}. $$ Suppose also that $X_i$ are normalized so that $\mathbb{E}(X_i) = 0$ and $\mathbb{E}(X_i^2) = 1$. Let $a_i$ be a fixed (deterministic) sequence of coefficients, and define the random variables $$ Y = \sum_{i=1}^N a_i X_i, $$ and its normalization $$ Z = \frac{Y}{\sqrt{\mathbb{E} Y^2}}.  $$ If the $X_i$ are assumed to be independent, then it is not hard to check that $Z$ is also $\nu$-subgaussian, because one can compute its moment generating function. My question is whether this hypothesis is necessary. Is $Z$ a $\nu$-subgaussian random variable, even if $X_i$ are not independent? The reason one might hope that this is true is that the normalization of $Z$ takes care of any growth of $Z$ that might arise from the dependencies. My best guess for how to prove this is to bound the joint distribution of $(X_i)$ by a multivariate Gaussian distribution, and then observe that $Y$ is some marginal and is therefore bounded by a Gaussian of the correct variance(?).  But I'm not sure how to fill in the details.",,"['probability', 'random-variables']"
5,Expectation of the maximum absolute value of gaussian random variables,Expectation of the maximum absolute value of gaussian random variables,,"Let $\{X_i\}_{i=1}^n$ be an i.i.d. sequence of $\mathcal{N}(0, \sigma^2)$ variables, and consider the random variable  $$Z_n : = \max_{i=1,\ldots,n}|X_i|.$$ I need to prove the bound $$ E[Z_n] \leq \sqrt{2\sigma^{2}\log{n}} + \frac{4 \sigma}{\sqrt{2\log{n}}} \quad \text{for all } n \geq 2. $$ I know how to prove the bound  $ E[Z_n] \leq \sqrt{2\sigma^{2}\log{n}} $  (using the moment generating function), which is even better, but the hint in the exrcise says that I should use the tail bound  $$ P[|U| \geq x] \leq \sqrt\frac{2}{\pi}\frac{1}{x} e^{-\tfrac{x^2}{2}}, \quad \text{where $U$ is a standart normal r.v.} \qquad (1) $$ My idea. Since $Z_n$ is a non-negative r.v., then  $$ E[Z_n] = \int_{0}^{\infty} P[Z_n \geq x] \ dx = \int_{0}^{\infty}  \Bigl( 1 - \bigl(1 - P[|X_1| \geq x] \bigr)^n \Bigr) dx. $$ I tried to use the tail bound (1), but it was unsuccessful. I even don't understand why this integral converges. I would appreciate any ideas. Thanks!","Let $\{X_i\}_{i=1}^n$ be an i.i.d. sequence of $\mathcal{N}(0, \sigma^2)$ variables, and consider the random variable  $$Z_n : = \max_{i=1,\ldots,n}|X_i|.$$ I need to prove the bound $$ E[Z_n] \leq \sqrt{2\sigma^{2}\log{n}} + \frac{4 \sigma}{\sqrt{2\log{n}}} \quad \text{for all } n \geq 2. $$ I know how to prove the bound  $ E[Z_n] \leq \sqrt{2\sigma^{2}\log{n}} $  (using the moment generating function), which is even better, but the hint in the exrcise says that I should use the tail bound  $$ P[|U| \geq x] \leq \sqrt\frac{2}{\pi}\frac{1}{x} e^{-\tfrac{x^2}{2}}, \quad \text{where $U$ is a standart normal r.v.} \qquad (1) $$ My idea. Since $Z_n$ is a non-negative r.v., then  $$ E[Z_n] = \int_{0}^{\infty} P[Z_n \geq x] \ dx = \int_{0}^{\infty}  \Bigl( 1 - \bigl(1 - P[|X_1| \geq x] \bigr)^n \Bigr) dx. $$ I tried to use the tail bound (1), but it was unsuccessful. I even don't understand why this integral converges. I would appreciate any ideas. Thanks!",,"['probability', 'normal-distribution', 'concentration-of-measure']"
6,What is the PDF of random variable Z=XY?,What is the PDF of random variable Z=XY?,,"Given two independent random variables X and Y , how can I find the PDF of random variable $Z=XY$? *If their joint distribution is required, assume that we also have it.","Given two independent random variables X and Y , how can I find the PDF of random variable $Z=XY$? *If their joint distribution is required, assume that we also have it.",,"['probability', 'probability-theory', 'probability-distributions', 'random-variables']"
7,Probability of global epidemic,Probability of global epidemic,,"Consider $\mathbb{Z}^2$ as a graph, where each node has four neighbours. 4 signals are emitted from $(0,0)$ in each of four directions (1 per direction) . A node that receives one signal (or more) at a timestep will re-emit it along the 4 edges to its four neighbours at the next time step. A node that did not receive a signal at the previous timestep will not emit a signal irrespective of whether it earlier received a signal. There is a $50\%$ chance that a signal will be lost when travelling along a single edge between two neighbouring nodes. A node that receives more then 1 signal acts the same as if it received only 1. The emitting of a signal in each of the 4 directions are independent events. What is the probability that the signal will sometime arrive at $(10^5,10^5)$? Research: Simulations show: Yes. ~90% What is the probability that the signal will sometime arrive at $(x,y)$ if a signal traveling along an edge dies with probability $0<p<1$? What is the least p, for which the probability that N initial random live cells die out approaches 0, as N approaches infinity? Experiment shows p close to 0.2872 . In $\mathbb{Z}^1$, $p_{min}=0.6445...$, how to calculate this? In $\mathbb{Z}^3$, $p_{min}=0.1775...$, how to calculate this?","Consider $\mathbb{Z}^2$ as a graph, where each node has four neighbours. 4 signals are emitted from $(0,0)$ in each of four directions (1 per direction) . A node that receives one signal (or more) at a timestep will re-emit it along the 4 edges to its four neighbours at the next time step. A node that did not receive a signal at the previous timestep will not emit a signal irrespective of whether it earlier received a signal. There is a $50\%$ chance that a signal will be lost when travelling along a single edge between two neighbouring nodes. A node that receives more then 1 signal acts the same as if it received only 1. The emitting of a signal in each of the 4 directions are independent events. What is the probability that the signal will sometime arrive at $(10^5,10^5)$? Research: Simulations show: Yes. ~90% What is the probability that the signal will sometime arrive at $(x,y)$ if a signal traveling along an edge dies with probability $0<p<1$? What is the least p, for which the probability that N initial random live cells die out approaches 0, as N approaches infinity? Experiment shows p close to 0.2872 . In $\mathbb{Z}^1$, $p_{min}=0.6445...$, how to calculate this? In $\mathbb{Z}^3$, $p_{min}=0.1775...$, how to calculate this?",,"['probability', 'graph-theory', 'stochastic-processes', 'probability-distributions', 'network-flow']"
8,Computing $\int _0^{\infty }e^{-b x} x^{b-1} \log \left((1-a x)^2\right)dx$ or $ \mathbb E \log\left[(c- \chi^2_{2b} )^2\right]$,Computing  or,\int _0^{\infty }e^{-b x} x^{b-1} \log \left((1-a x)^2\right)dx  \mathbb E \log\left[(c- \chi^2_{2b} )^2\right],"For $a>0,b\geq 1$ , what is the value of the following integral? $$\int _0^{\infty }e^{-b x} x^{b-1} \log \left((1-a x)^2\right)dx$$ Motivation: I need the following expectation for random variable $X$ where $2b X$ is distributed as Chi-squared with $2b$ degrees of freedom: $$E \log\left[(1-a X)^2\right]$$ The corresponding integral is $$\int_0^\infty \frac{\left(\frac{1}{b}\right)^{-b} e^{-b x} x^{b-1} \log \left((1-a x)^2\right)}{\Gamma (b)}$$ Mathematica gets the following formulas for $b=1,\ldots,6$ in terms of $\operatorname{Ei}(x)=-\int_{-z}^\infty e^{-t}/t \mathbb{d}t$ $$\begin{array}{ll} b=1&-2 e^{-1/a} \text{Ei}\left(\frac{1}{a}\right)\\ b=2&2-\frac{2 (a+2) e^{-2/a} \text{Ei}\left(\frac{2}{a}\right)}{a}\\ b=3&\frac{3 a (a+1)-(2 (a+3) a+9) e^{-3/a} \text{Ei}\left(\frac{3}{a}\right)}{a^2}\\ b=4&\frac{a ((11 a+16) a+16)-2 (3 ((a+4) a+8) a+32) e^{-4/a} \text{Ei}\left(\frac{4}{a}\right)}{3 a^3}\\ b=5&\frac{5 a ((2 (5 a+9) a+25) a+25)-(4 (3 (2 (a+5) a+25) a+125) a+625) e^{-5/a} \text{Ei}\left(\frac{5}{a}\right)}{12 a^4}\\ b=6&\frac{a ((((137 a+288) a+486) a+648) a+648)-12 (5 ((((a+6) a+18) a+36) a+54) a+324) e^{-6/a} \text{Ei}\left(\frac{6}{a}\right)}{30 a^5} \end{array} $$ What is the general formula in terms of $b$ ? The code to compute the formulas (takes about 2 minutes to run) $Assumptions = {x > 0, a > 0}; dist[n_] =    TransformedDistribution[x/n,     x \[Distributed] ChiSquareDistribution[n]]; pdf[n_, x_] = PDF[dist[n], x]; mean[b_?IntegerQ] :=    Integrate[Log[(1 - a x)^2] pdf[2 b, x], {x, 0, 1/a, \[Infinity]}]; formulas = FullSimplify@mean[#] & /@ Range[6] Background Solving for $a$ in $E[\log(1-a X^2)^2]=0$ gives the largest convergent learning rate for linear least squares mini-batch SGD with batch size $2b$ , step size $a$ and observations $X$ distributed as standard normal in $d=1$ dimensions. Batch-size 1 case is also known as LMS filter . Stability of LMS filter w.r.t. to step size is not fully understood, so characterizing it completely for a simple case of Gaussian observations is interesting. Related discussion here addresses the issue of convergence with batch size 1 and $d\ge 1$ Curiosuly, 1d iteration appears to become more unstable with increased batch size. In other words, applying random iteration several times and averaging updates at each step, can turn a stable random iteration into an unstable one. Notebook","For , what is the value of the following integral? Motivation: I need the following expectation for random variable where is distributed as Chi-squared with degrees of freedom: The corresponding integral is Mathematica gets the following formulas for in terms of What is the general formula in terms of ? The code to compute the formulas (takes about 2 minutes to run) $Assumptions = {x > 0, a > 0}; dist[n_] =    TransformedDistribution[x/n,     x \[Distributed] ChiSquareDistribution[n]]; pdf[n_, x_] = PDF[dist[n], x]; mean[b_?IntegerQ] :=    Integrate[Log[(1 - a x)^2] pdf[2 b, x], {x, 0, 1/a, \[Infinity]}]; formulas = FullSimplify@mean[#] & /@ Range[6] Background Solving for in gives the largest convergent learning rate for linear least squares mini-batch SGD with batch size , step size and observations distributed as standard normal in dimensions. Batch-size 1 case is also known as LMS filter . Stability of LMS filter w.r.t. to step size is not fully understood, so characterizing it completely for a simple case of Gaussian observations is interesting. Related discussion here addresses the issue of convergence with batch size 1 and Curiosuly, 1d iteration appears to become more unstable with increased batch size. In other words, applying random iteration several times and averaging updates at each step, can turn a stable random iteration into an unstable one. Notebook","a>0,b\geq 1 \int _0^{\infty }e^{-b x} x^{b-1} \log \left((1-a x)^2\right)dx X 2b X 2b E \log\left[(1-a X)^2\right] \int_0^\infty \frac{\left(\frac{1}{b}\right)^{-b} e^{-b x} x^{b-1} \log \left((1-a x)^2\right)}{\Gamma (b)} b=1,\ldots,6 \operatorname{Ei}(x)=-\int_{-z}^\infty e^{-t}/t \mathbb{d}t \begin{array}{ll}
b=1&-2 e^{-1/a} \text{Ei}\left(\frac{1}{a}\right)\\
b=2&2-\frac{2 (a+2) e^{-2/a} \text{Ei}\left(\frac{2}{a}\right)}{a}\\
b=3&\frac{3 a (a+1)-(2 (a+3) a+9) e^{-3/a} \text{Ei}\left(\frac{3}{a}\right)}{a^2}\\
b=4&\frac{a ((11 a+16) a+16)-2 (3 ((a+4) a+8) a+32) e^{-4/a} \text{Ei}\left(\frac{4}{a}\right)}{3 a^3}\\
b=5&\frac{5 a ((2 (5 a+9) a+25) a+25)-(4 (3 (2 (a+5) a+25) a+125) a+625) e^{-5/a} \text{Ei}\left(\frac{5}{a}\right)}{12 a^4}\\
b=6&\frac{a ((((137 a+288) a+486) a+648) a+648)-12 (5 ((((a+6) a+18) a+36) a+54) a+324) e^{-6/a} \text{Ei}\left(\frac{6}{a}\right)}{30 a^5}
\end{array}
 b a E[\log(1-a X^2)^2]=0 2b a X d=1 d\ge 1","['probability', 'integration', 'sequences-and-series', 'special-functions']"
9,"Probability of rolling 4 dice and obtaining a sum from 2 dice of 3, 8, or 11?","Probability of rolling 4 dice and obtaining a sum from 2 dice of 3, 8, or 11?",,"Problem: You roll 4 dice. What is the probability of getting 2 of the 4 dice to have a sum of 3, 8, or 11? Examples: 1 2 3 4 $\rightarrow$ counts $\rightarrow$ as 1 + 2 = 3 1 2 3 6 $\rightarrow$ counts $\rightarrow$ as 1 + 2 = 3 OR 2 + 6 = 8 1 3 4 6 $\rightarrow$ doesn't count $\rightarrow$ since you can't combine any 2 dice to get the sum of 3, 8, or 11 1 1 1 1 $\rightarrow$ doesn't count $\rightarrow$ same as above Breakdown: To get a sum of 3, you need the combination (1, 2). To get a sum of 11, you need the combination (5, 6). To get a sum of 8, you can have the combinations (2, 6), (3, 5), or (4, 4). My take: For the sums of 3 and 11, there is only one possible combination each. So, the problem can be simplified to ""Rolling 4 dice, what is the probability of getting at least one 1 and at least one 2"" (or at least one 5 and one 6 for 11). I used the inclusion/exclusion principle to solve it, which gives an answer of 0.233025. However, I'm stuck on calculating the probability for a sum of 8 and how to combine all three answers to get the final result. Note: I used code to get the final answer, it should be around 0.758488. But I'm still struggling to find a way to solve it using Math.","Problem: You roll 4 dice. What is the probability of getting 2 of the 4 dice to have a sum of 3, 8, or 11? Examples: 1 2 3 4 counts as 1 + 2 = 3 1 2 3 6 counts as 1 + 2 = 3 OR 2 + 6 = 8 1 3 4 6 doesn't count since you can't combine any 2 dice to get the sum of 3, 8, or 11 1 1 1 1 doesn't count same as above Breakdown: To get a sum of 3, you need the combination (1, 2). To get a sum of 11, you need the combination (5, 6). To get a sum of 8, you can have the combinations (2, 6), (3, 5), or (4, 4). My take: For the sums of 3 and 11, there is only one possible combination each. So, the problem can be simplified to ""Rolling 4 dice, what is the probability of getting at least one 1 and at least one 2"" (or at least one 5 and one 6 for 11). I used the inclusion/exclusion principle to solve it, which gives an answer of 0.233025. However, I'm stuck on calculating the probability for a sum of 8 and how to combine all three answers to get the final result. Note: I used code to get the final answer, it should be around 0.758488. But I'm still struggling to find a way to solve it using Math.",\rightarrow \rightarrow \rightarrow \rightarrow \rightarrow \rightarrow \rightarrow \rightarrow,"['probability', 'dice', 'inclusion-exclusion']"
10,Distribution of distances between random points on spheres,Distribution of distances between random points on spheres,,"This is in relation to the following blog post by John Baez: Random Points on a Sphere (Part 1) It is claimed that, for two unit quaternions $x,y\in S^3$ , uniformly randomly selected, the probability distribution of $|xy-yx|$ (how ""far apart"" $x$ and $y$ are from commuting) is given by: $$ P(d) = d-\frac{2d\arcsin(d/2)}{\pi},\quad d = |xy-yx|,\quad x,y\in S^3. $$ More generally, the probability distribution for the distance between two uniformly randomly chosen points on the $n$ -sphere is given by: $$P_n(d) = \frac{d^{n-2}(4-d^2)^{\frac{n-3}{2}}\Gamma(n/2)}{2^{n-3}\sqrt{\pi}\ \Gamma(\frac{n-1}{2})},\quad d=|x-y|,\quad x,y\in S^n.$$ My knowledge of probability theory is in all honesty, severely lacking. So my question is: Q: How does one derive these probability distributions?","This is in relation to the following blog post by John Baez: Random Points on a Sphere (Part 1) It is claimed that, for two unit quaternions , uniformly randomly selected, the probability distribution of (how ""far apart"" and are from commuting) is given by: More generally, the probability distribution for the distance between two uniformly randomly chosen points on the -sphere is given by: My knowledge of probability theory is in all honesty, severely lacking. So my question is: Q: How does one derive these probability distributions?","x,y\in S^3 |xy-yx| x y  P(d) = d-\frac{2d\arcsin(d/2)}{\pi},\quad d = |xy-yx|,\quad x,y\in S^3.  n P_n(d) = \frac{d^{n-2}(4-d^2)^{\frac{n-3}{2}}\Gamma(n/2)}{2^{n-3}\sqrt{\pi}\ \Gamma(\frac{n-1}{2})},\quad d=|x-y|,\quad x,y\in S^n.","['probability', 'geometry', 'probability-distributions', 'quaternions', 'geometric-probability']"
11,Elevator stops in building,Elevator stops in building,,"Bill is working in the 38th floor of an 100-floors building. This building has a strange elevator which only has 2 buttons: the green one which takes you to the next floor every time you press it (and if you are at the last floor, it takes you to the 1st) and a red button which takes you to a random floor every time you press it. Once you enter the elevator, the first stop is selected at random, without pressing any button. Bill wants to eventually arrive at his office at the 38th floor. How is he going to do it, with the least number of steps? I am thinking of a very simplistic approach: Since the first stop is decided at random, depending on the number of the floor where the elevator stops, Bill will decide which button to use: If he is near the 38th and before it, he will keep pressing the green button until he reaches the 38th. If it stops in a floor $>38$ , he will press the red button until the elevator stops at some floor $<38$ , but I assume the problem involves the expected number of stops etc probabilities, which I am not very familiar with! Any help is really appreciated!","Bill is working in the 38th floor of an 100-floors building. This building has a strange elevator which only has 2 buttons: the green one which takes you to the next floor every time you press it (and if you are at the last floor, it takes you to the 1st) and a red button which takes you to a random floor every time you press it. Once you enter the elevator, the first stop is selected at random, without pressing any button. Bill wants to eventually arrive at his office at the 38th floor. How is he going to do it, with the least number of steps? I am thinking of a very simplistic approach: Since the first stop is decided at random, depending on the number of the floor where the elevator stops, Bill will decide which button to use: If he is near the 38th and before it, he will keep pressing the green button until he reaches the 38th. If it stops in a floor , he will press the red button until the elevator stops at some floor , but I assume the problem involves the expected number of stops etc probabilities, which I am not very familiar with! Any help is really appreciated!",>38 <38,"['probability', 'puzzle', 'discrete-optimization']"
12,How rare is it to get a $8$ in minesweeper? (Bruh reputation requirements),How rare is it to get a  in minesweeper? (Bruh reputation requirements),8,"I need help on this, ignore if it is already answered. Ok so today I was wondering, could you get an $8$ in minesweeper, and how rare it is? All I know is that it will be rare. Very rare indeed. I don't really know how to say it. It is so annoying to be honest (tbh) . I also do not know what you'd need to answer, so it is complicated, well, because of that. If you are answering, it might be hard. Oh, I probably don't know but here is a predicted formula of how rare it is First, this variable. p8 = How rare it is to get 8 mines forming a hole like below. X = empty / O = mine O O O O X O O O O Rc = How rare it is to randomly click inside a patch that has minesweepers in all the directions you look, using the same example as the square mines forming a hole in the middle (This means there is no middle mine therefore) And then, the predicted formula below. It isn't advanced so you could make a better formula. It would please me. p8 รท Rc = 8r Forgot to mention. 8r = formula result So yeah. Not much to explain because I'm new to stack exchange. Anyways, the end of this, probably.","I need help on this, ignore if it is already answered. Ok so today I was wondering, could you get an in minesweeper, and how rare it is? All I know is that it will be rare. Very rare indeed. I don't really know how to say it. It is so annoying to be honest (tbh) . I also do not know what you'd need to answer, so it is complicated, well, because of that. If you are answering, it might be hard. Oh, I probably don't know but here is a predicted formula of how rare it is First, this variable. p8 = How rare it is to get 8 mines forming a hole like below. X = empty / O = mine O O O O X O O O O Rc = How rare it is to randomly click inside a patch that has minesweepers in all the directions you look, using the same example as the square mines forming a hole in the middle (This means there is no middle mine therefore) And then, the predicted formula below. It isn't advanced so you could make a better formula. It would please me. p8 รท Rc = 8r Forgot to mention. 8r = formula result So yeah. Not much to explain because I'm new to stack exchange. Anyways, the end of this, probably.",8,['probability']
13,Existence of a random variable,Existence of a random variable,,"Let $\mu$ be a probability measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$, where $\mathcal{B}(\mathbb{R})$ denotes the Borel sets. Then, is it true that there exists a probability space $(\Omega,\Sigma,\mathbb{P})$ and a random variable $X$ defined on this probability space such that $$ P(X \in B) = \mu(B)$$ for every borel set $B$? I know the ""converse"" of the claim is true: given a random variable $X$ on some probability space, there exists a probability measure on $\mathbb{R}$ such that $ P(X \in B) = \mu(B)$.","Let $\mu$ be a probability measure on $(\mathbb{R},\mathcal{B}(\mathbb{R}))$, where $\mathcal{B}(\mathbb{R})$ denotes the Borel sets. Then, is it true that there exists a probability space $(\Omega,\Sigma,\mathbb{P})$ and a random variable $X$ defined on this probability space such that $$ P(X \in B) = \mu(B)$$ for every borel set $B$? I know the ""converse"" of the claim is true: given a random variable $X$ on some probability space, there exists a probability measure on $\mathbb{R}$ such that $ P(X \in B) = \mu(B)$.",,"['probability', 'probability-theory']"
14,How much space do I need to sort my socks?,How much space do I need to sort my socks?,,"In my pile of finished laundry, there are $2n$ socks of $n$ types, comprising $n$ easily distinguishable pairs. I sort the socks into pairs by picking one sock at a time randomly from the pile and either (1) laying it in a row of distinct socks or (2) pairing it with a sock already in the row, if there is such a sock, and putting the pair away. What is the expected maximum number of socks in the row? Let $N$ be the peak number of socks in the row. Clearly $1\leqslant N\leqslant n$. And obviously, if $n=1$, then $N=\mathrm E[N]=1$. For $n=2$, I get $\mathrm E[N]=\frac53$. As $n$ increases, the calculation gets more complicated, and I don't know whether $\mathrm E[N]$ has a reasonable explicit general formulation. If not, perhaps it still has a nice asymptotic expression for large $n$. My guess is that there are positive constants $\alpha$ and $\beta$ such that $\lim_{\,n\rightarrow\infty}\mathrm E[N]/n^\beta=\alpha$.","In my pile of finished laundry, there are $2n$ socks of $n$ types, comprising $n$ easily distinguishable pairs. I sort the socks into pairs by picking one sock at a time randomly from the pile and either (1) laying it in a row of distinct socks or (2) pairing it with a sock already in the row, if there is such a sock, and putting the pair away. What is the expected maximum number of socks in the row? Let $N$ be the peak number of socks in the row. Clearly $1\leqslant N\leqslant n$. And obviously, if $n=1$, then $N=\mathrm E[N]=1$. For $n=2$, I get $\mathrm E[N]=\frac53$. As $n$ increases, the calculation gets more complicated, and I don't know whether $\mathrm E[N]$ has a reasonable explicit general formulation. If not, perhaps it still has a nice asymptotic expression for large $n$. My guess is that there are positive constants $\alpha$ and $\beta$ such that $\lim_{\,n\rightarrow\infty}\mathrm E[N]/n^\beta=\alpha$.",,"['probability', 'combinatorics']"
15,Probability of $\limsup$ of a sequence of sets (Borel-Cantelli lemma),Probability of  of a sequence of sets (Borel-Cantelli lemma),\limsup,"Let $(E_n)$ be a sequence of events in a probability space such that $$\lim_{n\to\infty}\mathbb P(E_n)=0.$$ I am trying to prove that if $$\sum_{n=1}^\infty\mathbb P (E_n\setminus E_{n+1}) <\infty$$ then $$\mathbb P\left(\limsup_{n\to\infty} E_n\right)=0.$$ For an example I am using the sequence of intervals $[0, 1/n]$ which goes to $0$ as $n$ increases to infinity. Then I can see how the probability of infinite sum of the intersection of the $E_n$ and the complement of $E_{n+1}$  is less than infinity and the probability of $\limsup_{n\to\infty} E_n$ equals zero. Can anyone help me figure out how to prove this in general using any sequence? Especially to show how $\mathbb P\left(\limsup_{n\to\infty} E_n\right)=0$? Thank you in advance for your thoughts.","Let $(E_n)$ be a sequence of events in a probability space such that $$\lim_{n\to\infty}\mathbb P(E_n)=0.$$ I am trying to prove that if $$\sum_{n=1}^\infty\mathbb P (E_n\setminus E_{n+1}) <\infty$$ then $$\mathbb P\left(\limsup_{n\to\infty} E_n\right)=0.$$ For an example I am using the sequence of intervals $[0, 1/n]$ which goes to $0$ as $n$ increases to infinity. Then I can see how the probability of infinite sum of the intersection of the $E_n$ and the complement of $E_{n+1}$  is less than infinity and the probability of $\limsup_{n\to\infty} E_n$ equals zero. Can anyone help me figure out how to prove this in general using any sequence? Especially to show how $\mathbb P\left(\limsup_{n\to\infty} E_n\right)=0$? Thank you in advance for your thoughts.",,"['probability', 'measure-theory', 'limsup-and-liminf']"
16,Regression towards the mean v/s the Gambler's fallacy,Regression towards the mean v/s the Gambler's fallacy,,"Suppose you toss a (fair) coin 9 times, and get heads on all of them. Wouldn't the probability of getting a tails increase from 50/50 due to regression towards the mean? I know that that shouldn't happen, as the tosses are independent event. However, it seems to go against the idea of ""things evening out"".","Suppose you toss a (fair) coin 9 times, and get heads on all of them. Wouldn't the probability of getting a tails increase from 50/50 due to regression towards the mean? I know that that shouldn't happen, as the tosses are independent event. However, it seems to go against the idea of ""things evening out"".",,['probability']
17,Centre dot in probability notation?,Centre dot in probability notation?,,"What does the dot mean in probability notation I sometimes see things like $x \sim P_t(\centerdot \vert x, \theta_{db})$","What does the dot mean in probability notation I sometimes see things like $x \sim P_t(\centerdot \vert x, \theta_{db})$",,"['probability', 'statistics', 'notation']"
18,"Total variation distance, $L^1$ norm","Total variation distance,  norm",L^1,"Total variation distance is a measure for comparing two probability distributions (assuming that these are unit vectors in a finite space- where basis corresponds to the sample space ( $\omega$ )). I know a distance measure need to obey triangle inequality and it should satisfy that orthogonal vectors have maximum distance and the same distributions should have distance $0$ . Others should like between these two. I completely don't understand why the $L^1$ norm is chosen for measuring the distance between these vectors (prob. distributions).  I also want to know why it is exactly defined the way it is. $TV(P_1,P_2) = \frac{1}{2}\sum_{x \in \omega} \mid {P_1(x)-P_2(x) \mid}$",Total variation distance is a measure for comparing two probability distributions (assuming that these are unit vectors in a finite space- where basis corresponds to the sample space ( )). I know a distance measure need to obey triangle inequality and it should satisfy that orthogonal vectors have maximum distance and the same distributions should have distance . Others should like between these two. I completely don't understand why the norm is chosen for measuring the distance between these vectors (prob. distributions).  I also want to know why it is exactly defined the way it is.,"\omega 0 L^1 TV(P_1,P_2) = \frac{1}{2}\sum_{x \in \omega} \mid {P_1(x)-P_2(x) \mid}","['probability', 'probability-theory', 'measure-theory', 'probability-distributions']"
19,What is the expected number of random small circles it takes to cover a large circle? [duplicate],What is the expected number of random small circles it takes to cover a large circle? [duplicate],,"This question already has answers here : Rain droplets falling on a table (4 answers) Closed 2 years ago . I have a large circle of radius $B$ . I choose a random point inside the large circle, and draw a small circle of radius $A$ around it ( $A<B$ ). What are the chances that, after drawing $n$ such small circles, the union of their area covers the large circle (i.e., includes every point in the large circle)? What is the expected value of the number of small circles I must draw to cover the large circle? My progress so far: If I pick any point in the large circle, the chance that it has not been covered by $n$ small circles is: 1 minus the chance that it has been covered = 1 minus the chance that the origin of a small circle is within $A$ of this point, after $n$ tries = 1 minus (the small circle of radius $A$ around this point divided by the total area of the large circle), after $n$ tries = $\left(1 - \frac{\pi A^2}{\pi B^2}\right)^n$ = $\left(\frac{B^2 - A^2}{B^2}\right)^n$ So, the chance that any point has been covered is $1 - \left(\frac{B^2 - A^2}{B^2}\right)^n$ . How do I use this info to know whether all point have been covered after $n$ small circles? And find the expected value of the number of small circles it takes? Also, even this oversimplifies it: If the point I pick in the large circle is within $A$ away from the edge, a circle of radius $A$ around it isn't completely contained in $B$ , so the ratio of ""hits"" is actually less than $\frac{A^2}{B^2}$ . I assume we can calculate the amount of overlap for the ""average"" small circle, which is 100% for most of them but less than that (is it $\frac{3}{4}$ ?) for $\frac{A}{B}$ of them.","This question already has answers here : Rain droplets falling on a table (4 answers) Closed 2 years ago . I have a large circle of radius . I choose a random point inside the large circle, and draw a small circle of radius around it ( ). What are the chances that, after drawing such small circles, the union of their area covers the large circle (i.e., includes every point in the large circle)? What is the expected value of the number of small circles I must draw to cover the large circle? My progress so far: If I pick any point in the large circle, the chance that it has not been covered by small circles is: 1 minus the chance that it has been covered = 1 minus the chance that the origin of a small circle is within of this point, after tries = 1 minus (the small circle of radius around this point divided by the total area of the large circle), after tries = = So, the chance that any point has been covered is . How do I use this info to know whether all point have been covered after small circles? And find the expected value of the number of small circles it takes? Also, even this oversimplifies it: If the point I pick in the large circle is within away from the edge, a circle of radius around it isn't completely contained in , so the ratio of ""hits"" is actually less than . I assume we can calculate the amount of overlap for the ""average"" small circle, which is 100% for most of them but less than that (is it ?) for of them.",B A A<B n n A n A n \left(1 - \frac{\pi A^2}{\pi B^2}\right)^n \left(\frac{B^2 - A^2}{B^2}\right)^n 1 - \left(\frac{B^2 - A^2}{B^2}\right)^n n A A B \frac{A^2}{B^2} \frac{3}{4} \frac{A}{B},"['probability', 'circles', 'area']"
20,Is there a simple reason why the expected number of coin flips till getting $m$ more heads than tails or $n$ more tails than heads should be $mn$?,Is there a simple reason why the expected number of coin flips till getting  more heads than tails or  more tails than heads should be ?,m n mn,"I flip a coin until I get $m$ more heads than tails, or $n$ more tails than heads. Let the expected number of flips of the coin before stopping be $f(m,n)$ . I obtained $f(m,n)=mn$ from the recursion $f(m,n)=1+\frac{f(m-1,n+1)+f(m+1,n-1)}2$ with $f(k,0)=f(0,k)=0$ for all $k$ . Other than going through this recursion (and either solving by inspection or by writing as linear recurrence in single variable and solving brute force), is there an intuitive reason you should expect this process to take $mn$ flips? I was thinking about the more general problem with probability $p$ of getting heads and was struck by how simple the formula became when handling, what turned out to be a special case (general formula broke down) of $p=\frac12$ .","I flip a coin until I get more heads than tails, or more tails than heads. Let the expected number of flips of the coin before stopping be . I obtained from the recursion with for all . Other than going through this recursion (and either solving by inspection or by writing as linear recurrence in single variable and solving brute force), is there an intuitive reason you should expect this process to take flips? I was thinking about the more general problem with probability of getting heads and was struck by how simple the formula became when handling, what turned out to be a special case (general formula broke down) of .","m n f(m,n) f(m,n)=mn f(m,n)=1+\frac{f(m-1,n+1)+f(m+1,n-1)}2 f(k,0)=f(0,k)=0 k mn p p=\frac12","['probability', 'recreational-mathematics']"
21,Are decompositions of a random variable into a sum of two IID random variables unique?,Are decompositions of a random variable into a sum of two IID random variables unique?,,"Let $Z$ be a real-valued random variable, and suppose that $Z = X_1 + X_2$ where $X_1$ and $X_2$ are i.i.d. random variables. Suppose further that $Z = Y_1 + Y_2$ where $Y_1$ and $Y_2$ i.i.d. random variables. Does it follow that $Y_1$ and $X_1$ are identically distributed? I've looked into indecomposable distributions and infinitely divisible distributions, but could not find a result/example immediately answering the above question.","Let be a real-valued random variable, and suppose that where and are i.i.d. random variables. Suppose further that where and i.i.d. random variables. Does it follow that and are identically distributed? I've looked into indecomposable distributions and infinitely divisible distributions, but could not find a result/example immediately answering the above question.",Z Z = X_1 + X_2 X_1 X_2 Z = Y_1 + Y_2 Y_1 Y_2 Y_1 X_1,"['probability', 'probability-theory', 'probability-distributions', 'independence', 'characteristic-functions']"
22,Probability that no team in a tournament wins all games or loses all games.,Probability that no team in a tournament wins all games or loses all games.,,"Five teams play a tournament in which every team plays every other team exactly once. No ties occur, and each team has a $1/2$ probability of winning any game it plays. Find the probability that no team wins/loses all the games. My try: Each team plays all other teams once. So there are $\binom{5}{2} = 10$ games.  For each game there are 2 possible outcomes so there's a total of $2^{10}$ possible outcomes. Number of outcomes where $1$ team wins all its games:  Let's say team A wins all its games ($4$ in total).  Then other $6$ games can end in $2$ possible outcomes.  Since anyone team could win all its games, we get $5 \times 2^6 $ as the number of outcomes where $1$ team wins all its games. Similarly by symmetry, we get $5 \times 2^6 $ as the number of outcomes where $1$ team loses all its games. It's also possible for $1$ team to win all its games, and another team to lose all its games. But these will have been included in both totals above (i.e. calculated twice), so we must subtract this amount once from the totals above:  Let's say team A wins all its games and team B loses all it's games (these include $7$ games, $4$ games for team A and $4$ games for team B, but we must remember that teams A and B play each other once, so there are only $7$ games in which team A or team B plays with certain victory or losing respectively). So, since any of the $5$ teams could be the one to win all its games, and any of the $4$ remaining teams could be the one to lose all its games, we get $5 \times 4 \times 2^3 = 20 \times 2^3. $ Probability that at least one team wins/loses all their games is  $\frac{(5 \times 2^6 + 5 \times 2^6 โ 20 \times 2^3)}{ 2^{10}}  = \frac{15}{32}. $ Hence, probability that no team wins/loses all their games is $\frac{17}{32}.$ Is this alright?","Five teams play a tournament in which every team plays every other team exactly once. No ties occur, and each team has a $1/2$ probability of winning any game it plays. Find the probability that no team wins/loses all the games. My try: Each team plays all other teams once. So there are $\binom{5}{2} = 10$ games.  For each game there are 2 possible outcomes so there's a total of $2^{10}$ possible outcomes. Number of outcomes where $1$ team wins all its games:  Let's say team A wins all its games ($4$ in total).  Then other $6$ games can end in $2$ possible outcomes.  Since anyone team could win all its games, we get $5 \times 2^6 $ as the number of outcomes where $1$ team wins all its games. Similarly by symmetry, we get $5 \times 2^6 $ as the number of outcomes where $1$ team loses all its games. It's also possible for $1$ team to win all its games, and another team to lose all its games. But these will have been included in both totals above (i.e. calculated twice), so we must subtract this amount once from the totals above:  Let's say team A wins all its games and team B loses all it's games (these include $7$ games, $4$ games for team A and $4$ games for team B, but we must remember that teams A and B play each other once, so there are only $7$ games in which team A or team B plays with certain victory or losing respectively). So, since any of the $5$ teams could be the one to win all its games, and any of the $4$ remaining teams could be the one to lose all its games, we get $5 \times 4 \times 2^3 = 20 \times 2^3. $ Probability that at least one team wins/loses all their games is  $\frac{(5 \times 2^6 + 5 \times 2^6 โ 20 \times 2^3)}{ 2^{10}}  = \frac{15}{32}. $ Hence, probability that no team wins/loses all their games is $\frac{17}{32}.$ Is this alright?",,"['probability', 'permutations']"
23,Random Sum of random variables: Without replacement,Random Sum of random variables: Without replacement,,"I have the numbers between 1 and 100 in an urn. I randomly draw $h$ many ($h$ fixed parameter) of them, without replacement. My random variable of interest is their sum. All approaches I could think of are iterative logic (""If drawn this, then draw that second time,..."") and become unmanageable when $h$ is large. Is there a generic way to compute the pdf of this RV? I'm not familiar with characteristic functions, so I'd appreciate an approach more if it wouldn't require those.","I have the numbers between 1 and 100 in an urn. I randomly draw $h$ many ($h$ fixed parameter) of them, without replacement. My random variable of interest is their sum. All approaches I could think of are iterative logic (""If drawn this, then draw that second time,..."") and become unmanageable when $h$ is large. Is there a generic way to compute the pdf of this RV? I'm not familiar with characteristic functions, so I'd appreciate an approach more if it wouldn't require those.",,"['probability', 'statistics', 'probability-distributions']"
24,Two randomly chosen coprime integers,Two randomly chosen coprime integers,,"This is a twist on the problem commonly known to have solution $6/\pi^2$.  Suppose when choosing from all natural numbers $\mathbb{N}$, the probability of choosing $n \in \mathbb{N}$ is given by $P(n)=\frac{1}{2^n}$.  Now when choosing two natural numbers, what is the probability (in closed form) of choosing two coprime numbers? Notice, the probability of choosing something divisible by $p$ is $$\frac{1}{2^p}+\frac{1}{2^{2p}}+\frac{1}{2^{3p}}+\frac{1}{2^{4p}}+\ldots=\frac{1}{2^p-1}$$ so the probability of choosing two numbers both divisible by $p$ is $$\frac{1}{(2^p-1)^2}$$ Meaning $$P(a,b;p)=1-\frac{1}{(2^p-1)^2}$$ where $P(a, b;p)$ is the probability that either $a$ or $b$ is not divisible by $p$.  Then the answer I'm looking for is $$P(a,b)=\prod_{p\text{ prime}}P(a,b;p)=\prod_{p\text{ prime}}\left(1-\frac{1}{(2^p-1)^2}\right)$$ where $P(a,b)$ is the probability that $a$ and $b$ are coprime. Anyway, I'm curious about a closed form expression for this number, similar to the original problem I mentioned.  Any insight would be very helpful. Edit As Mark Fischler has pointed out below, this product representation assumes the events of $p|a$ and $p|b$ are independent, which should not be the case.  If anyone can also explain a way of constructing a more correct probability, it would be very helpful.","This is a twist on the problem commonly known to have solution $6/\pi^2$.  Suppose when choosing from all natural numbers $\mathbb{N}$, the probability of choosing $n \in \mathbb{N}$ is given by $P(n)=\frac{1}{2^n}$.  Now when choosing two natural numbers, what is the probability (in closed form) of choosing two coprime numbers? Notice, the probability of choosing something divisible by $p$ is $$\frac{1}{2^p}+\frac{1}{2^{2p}}+\frac{1}{2^{3p}}+\frac{1}{2^{4p}}+\ldots=\frac{1}{2^p-1}$$ so the probability of choosing two numbers both divisible by $p$ is $$\frac{1}{(2^p-1)^2}$$ Meaning $$P(a,b;p)=1-\frac{1}{(2^p-1)^2}$$ where $P(a, b;p)$ is the probability that either $a$ or $b$ is not divisible by $p$.  Then the answer I'm looking for is $$P(a,b)=\prod_{p\text{ prime}}P(a,b;p)=\prod_{p\text{ prime}}\left(1-\frac{1}{(2^p-1)^2}\right)$$ where $P(a,b)$ is the probability that $a$ and $b$ are coprime. Anyway, I'm curious about a closed form expression for this number, similar to the original problem I mentioned.  Any insight would be very helpful. Edit As Mark Fischler has pointed out below, this product representation assumes the events of $p|a$ and $p|b$ are independent, which should not be the case.  If anyone can also explain a way of constructing a more correct probability, it would be very helpful.",,"['probability', 'prime-numbers', 'infinite-product']"
25,Intuition for partial averaging eqution,Intuition for partial averaging eqution,,"I just learnt about the condition expectation and as is known, the definition is as follows: My question is for the second property (partial averaging property), what kind of intuition does it express? How can I understand in a more perceptual way. Thanks so much!","I just learnt about the condition expectation and as is known, the definition is as follows: My question is for the second property (partial averaging property), what kind of intuition does it express? How can I understand in a more perceptual way. Thanks so much!",,['probability']
26,Probability that $xy = yx$ for random elements in a finite group [duplicate],Probability that  for random elements in a finite group [duplicate],xy = yx,"This question already has an answer here : Prove: if $a,b\in G$ commute with probability $>5/8$, then $G$ is abelian (1 answer) Closed 5 years ago . let $G$ a finite group, not abelian. I don't know if a short proof of this fact exists : $$\mathbb{P}(xy = yx) \leq 5/8$$ $x,y$ are randomly picked. Edit : If possible, i want to know if there is a shorter proof than this one : (in french sorry)","This question already has an answer here : Prove: if $a,b\in G$ commute with probability $>5/8$, then $G$ is abelian (1 answer) Closed 5 years ago . let $G$ a finite group, not abelian. I don't know if a short proof of this fact exists : $$\mathbb{P}(xy = yx) \leq 5/8$$ $x,y$ are randomly picked. Edit : If possible, i want to know if there is a shorter proof than this one : (in french sorry)",,['probability']
27,An extrasensory perception strategy :-),An extrasensory perception strategy :-),,"Inspired by classical Joseph Banks Rhine experiments demonstrating an extrasensory perception (see, for instance, the beginning of the respective chapter of Jeffrey Mishlove book โThe Roots of Consciousnessโ), I consider the following experiment. A deck of cards is given to a magician John. Then John consecutively takes the cards from the deck, trying to guess suit of the taken card. He looks at the card after the guess for a feedback. The magician wishes to maximize the expected number $E$ of right guesses. For this purpose he devised the following Strategy: at each turn to guess a suit which has a maximal number of card left in the deck. As an easy exercise we can prove that for any sequence of cards in the deck Strategy ensures at least $n$ right guesses, where $n$ is the maximal number of cards with one suit in the deck. But we can consider a more interesting and complicated problem to calculate the expectation $E$ for Strategy (here we are assuming that the deck is so well shuffled such that all sequences of cards have equal probability). By the way, I conjecture that Strategy is the best for maximizing the expectation $E$, that is any other strategy yields not greater value of $E$. Now I wish to evaluate the expectation $E$ for Strategy. For the simplicity we shall consider only a case when there are only two suits ($m\ge 0$ cards of the first suit and $n\ge m$ cards of the second suit).  Then $E(0,n)=n$ for each $n$ and we have the following recurrence $$E(m,n)=\frac{n}{m+n}(E(m,n-1)+1)+ \frac{m}{m+n}E(m-1,n)$$ for each $n\ge m\ge 1$. The rest is true provided I did not a stupid arithmetic mistake. I was interested mainly in asymptotics for the case $m=n$ and computer calculations suggested that $E(n,n)\sim n+c\sqrt{n}+o(\sqrt{n})$ for $c\approx 0.88\dots$. Evaluating formulas for $E(m,n)$ for small values of $m\le 6$, I conjectured that there is a general formula $$E(m,n)=n+m\sum_{i=1}^m\frac {c_{m,i}}{n+i}$$ for each $n\ge m\ge 1$, where $c_{m,i}$ are some integers satisfying the recurrence $$(m-i)c_{m,i}+ic_{m,i+1}=(m-1)c_{m-1,i}$$ for every $1\le i\le m-1$. Here are my values for $c_{m,i}$ i\m|  1   2   3   4   5   6  ---+------------------------  1 |  1   2   4   8  16  32   2 |     -1  -4 -12 -32 -80   3 |          1   6  24  80   4 |             -1  -8 -40   5 |                  1  10   6 |                     -1 Then I discovered that for my data $c_{m,i}$ is divisible by $2^{m-i}$. After I did the division, I surprisingly obtained that  $$c_{m,i}=(-1)^{i-1}2^{m-i}{m-1 \choose i-1}.$$ I expect that I can easily prove this equality by induction. But I did not stop at this point because I observed that now the general formula for $E(m,n)$ can be compressed to the form $$E(m,n)=n+m\int_0^1 x^n(2-x)^{m-1} dx.$$ All of above sounds nice for me and I spent a good time investigating the problem, but I am a professional mathematician, although I am not a specialist in the domain of the above problem. Therefore I care about the following questions. Are the above results new, good and worthy to be published somewhere? What another related problems are worthy to be investigated? Thanks and merry Holidays.","Inspired by classical Joseph Banks Rhine experiments demonstrating an extrasensory perception (see, for instance, the beginning of the respective chapter of Jeffrey Mishlove book โThe Roots of Consciousnessโ), I consider the following experiment. A deck of cards is given to a magician John. Then John consecutively takes the cards from the deck, trying to guess suit of the taken card. He looks at the card after the guess for a feedback. The magician wishes to maximize the expected number $E$ of right guesses. For this purpose he devised the following Strategy: at each turn to guess a suit which has a maximal number of card left in the deck. As an easy exercise we can prove that for any sequence of cards in the deck Strategy ensures at least $n$ right guesses, where $n$ is the maximal number of cards with one suit in the deck. But we can consider a more interesting and complicated problem to calculate the expectation $E$ for Strategy (here we are assuming that the deck is so well shuffled such that all sequences of cards have equal probability). By the way, I conjecture that Strategy is the best for maximizing the expectation $E$, that is any other strategy yields not greater value of $E$. Now I wish to evaluate the expectation $E$ for Strategy. For the simplicity we shall consider only a case when there are only two suits ($m\ge 0$ cards of the first suit and $n\ge m$ cards of the second suit).  Then $E(0,n)=n$ for each $n$ and we have the following recurrence $$E(m,n)=\frac{n}{m+n}(E(m,n-1)+1)+ \frac{m}{m+n}E(m-1,n)$$ for each $n\ge m\ge 1$. The rest is true provided I did not a stupid arithmetic mistake. I was interested mainly in asymptotics for the case $m=n$ and computer calculations suggested that $E(n,n)\sim n+c\sqrt{n}+o(\sqrt{n})$ for $c\approx 0.88\dots$. Evaluating formulas for $E(m,n)$ for small values of $m\le 6$, I conjectured that there is a general formula $$E(m,n)=n+m\sum_{i=1}^m\frac {c_{m,i}}{n+i}$$ for each $n\ge m\ge 1$, where $c_{m,i}$ are some integers satisfying the recurrence $$(m-i)c_{m,i}+ic_{m,i+1}=(m-1)c_{m-1,i}$$ for every $1\le i\le m-1$. Here are my values for $c_{m,i}$ i\m|  1   2   3   4   5   6  ---+------------------------  1 |  1   2   4   8  16  32   2 |     -1  -4 -12 -32 -80   3 |          1   6  24  80   4 |             -1  -8 -40   5 |                  1  10   6 |                     -1 Then I discovered that for my data $c_{m,i}$ is divisible by $2^{m-i}$. After I did the division, I surprisingly obtained that  $$c_{m,i}=(-1)^{i-1}2^{m-i}{m-1 \choose i-1}.$$ I expect that I can easily prove this equality by induction. But I did not stop at this point because I observed that now the general formula for $E(m,n)$ can be compressed to the form $$E(m,n)=n+m\int_0^1 x^n(2-x)^{m-1} dx.$$ All of above sounds nice for me and I spent a good time investigating the problem, but I am a professional mathematician, although I am not a specialist in the domain of the above problem. Therefore I care about the following questions. Are the above results new, good and worthy to be published somewhere? What another related problems are worthy to be investigated? Thanks and merry Holidays.",,"['probability', 'combinatorics', 'reference-request', 'asymptotics', 'binomial-coefficients']"
28,Prove the lecturer is a liar...,Prove the lecturer is a liar...,,"I was given this puzzle: At the end of the seminar, the lecturer waited outside to greet the attendees. The first three seen leaving were all women. The lecturer noted "" assuming the attendees are leaving in random order, the probability of that is precisely 1/3."" Show the lecturer is lying (or badly mistaken). I've puzzled it out to proving that there is no ratio of $\binom{a}{3}/\binom{a+b}{3}$ that is 1/3, where $ a,b \in\mathbb{N}$ and $a\ge3$ and $b\ge0$, $a$ being the number of women and $b$ the number of men. I'm stuck at this point (but empirically pretty convinced). Any help/pointers appreciated. Rasher PS- as an amusing aside, the first 12 values in the sequence of values for $\binom{3+b}{3}$ are the total number of gifts received for each day of the ""12 days of Christmas"" song. I've narrowed it down to proving that in the sequence generated by $n^3+3 n^2+2 n$ with $n \in\mathbb{N}$ and $n\ge1$ it is impossible for $3(n^3+3 n^2+2 n)$ to exist in the form of $n^3+3 n^2+2 n$ . Still stymied at this point. I found today a (somewhat) similar question at MathOverflow . Since my question seems to boil down to showing the Diophantine $6 a - 9 a^2 + 3 a^3 - 2 b + 3 b^2 - b^3=0$ has no solutions for $(a,b) \in\mathbb{N}$ and $(a,b)>= 3$ would it be appropriate to close this here and ask for help at MathOverflow to determine if this can be proved? An update: I asked a post-doc here at Stanford if he'd have a look (he's done some heavy lifting in the area of bounds on ways $t$ can be represented as a binomial coefficient). To paraphrase his response ""That's hard...probably beyond proof in the general case"". Since I've tested for explicit solutions to beyond 100M, I'm settling with the lecturer is lying/mistaken at least in spirit unless one admits lecture halls the size of a state.","I was given this puzzle: At the end of the seminar, the lecturer waited outside to greet the attendees. The first three seen leaving were all women. The lecturer noted "" assuming the attendees are leaving in random order, the probability of that is precisely 1/3."" Show the lecturer is lying (or badly mistaken). I've puzzled it out to proving that there is no ratio of $\binom{a}{3}/\binom{a+b}{3}$ that is 1/3, where $ a,b \in\mathbb{N}$ and $a\ge3$ and $b\ge0$, $a$ being the number of women and $b$ the number of men. I'm stuck at this point (but empirically pretty convinced). Any help/pointers appreciated. Rasher PS- as an amusing aside, the first 12 values in the sequence of values for $\binom{3+b}{3}$ are the total number of gifts received for each day of the ""12 days of Christmas"" song. I've narrowed it down to proving that in the sequence generated by $n^3+3 n^2+2 n$ with $n \in\mathbb{N}$ and $n\ge1$ it is impossible for $3(n^3+3 n^2+2 n)$ to exist in the form of $n^3+3 n^2+2 n$ . Still stymied at this point. I found today a (somewhat) similar question at MathOverflow . Since my question seems to boil down to showing the Diophantine $6 a - 9 a^2 + 3 a^3 - 2 b + 3 b^2 - b^3=0$ has no solutions for $(a,b) \in\mathbb{N}$ and $(a,b)>= 3$ would it be appropriate to close this here and ask for help at MathOverflow to determine if this can be proved? An update: I asked a post-doc here at Stanford if he'd have a look (he's done some heavy lifting in the area of bounds on ways $t$ can be represented as a binomial coefficient). To paraphrase his response ""That's hard...probably beyond proof in the general case"". Since I've tested for explicit solutions to beyond 100M, I'm settling with the lecturer is lying/mistaken at least in spirit unless one admits lecture halls the size of a state.",,"['probability', 'number-theory', 'binomial-coefficients', 'diophantine-equations']"
29,Probability of consecutive dice rolls,Probability of consecutive dice rolls,,"This is probably quite a simple question but here I go.. Suppose you are going to roll a six-sided (fair) die N times, what is the probability that you will get at least one set of three consecutive numbers in a row? Hopefully that's clear enough but as an example, in nine rolls you may get: 1, 4, 2, 6, 4, 4, 4, 4, 3 With the 4s making two sets of consecutive rolls. Thanks!","This is probably quite a simple question but here I go.. Suppose you are going to roll a six-sided (fair) die N times, what is the probability that you will get at least one set of three consecutive numbers in a row? Hopefully that's clear enough but as an example, in nine rolls you may get: 1, 4, 2, 6, 4, 4, 4, 4, 3 With the 4s making two sets of consecutive rolls. Thanks!",,"['probability', 'dice']"
30,What is the expected convex depth of a set of $m$ randomly chosen points in the unit square?,What is the expected convex depth of a set of  randomly chosen points in the unit square?,m,"Definition. Let $X$ be a set of points in $\mathbb{R}^2$ .  Then the vertex sequence of $X$ is defined by $X_{0}=X$ , and $X_{i+1}=\left\{x\in \operatorname{Conv}(X_{i}): x \notin \operatorname{Conv}(X_{i}\setminus\{x\})\right\}$ . The convex depth of $X$ is the smallest $k\in \mathbb{N}$ such that $X_{k}$ is empty. Here is an example where $|X|=30$ . My question is, What is the expected convex depth of a set of $m$ randomly chosen points in the unit square? The answer should be a function of $m$ .  I have simulated some data for this, pictured below, where the $x$ - axis is $m$ and $y$ - axis is the mean convex depth.  It looks $\sqrt{m}$ ish (or maybe something closer to $m^{3/2}$ , as suggested by lhf's link in the comments).  I'm not sure how to prove it, though. .","Definition. Let be a set of points in .  Then the vertex sequence of is defined by , and . The convex depth of is the smallest such that is empty. Here is an example where . My question is, What is the expected convex depth of a set of randomly chosen points in the unit square? The answer should be a function of .  I have simulated some data for this, pictured below, where the - axis is and - axis is the mean convex depth.  It looks ish (or maybe something closer to , as suggested by lhf's link in the comments).  I'm not sure how to prove it, though. .",X \mathbb{R}^2 X X_{0}=X X_{i+1}=\left\{x\in \operatorname{Conv}(X_{i}): x \notin \operatorname{Conv}(X_{i}\setminus\{x\})\right\} X k\in \mathbb{N} X_{k} |X|=30 m m x m y \sqrt{m} m^{3/2},"['probability', 'general-topology', 'probability-theory', 'convex-analysis', 'combinatorial-geometry']"
31,Generating a random probability vector,Generating a random probability vector,,"Suppose that I want to generate a random probability vector $p = (p_1,\dots,p_d) \in [0,1]^d$, distributed uniformly over the simplex of probability vectors in $\mathbb{R}^d$. I would like to generate $U_i \stackrel{i.i.d.}{\sim} F, \;i=1,\dots,d$ from some distribution $F$, so that $(p_i) := (\frac{U_i}{\sum_{j=1}^d U_j})$ gives the desired random probability vector. What should $F$ be?","Suppose that I want to generate a random probability vector $p = (p_1,\dots,p_d) \in [0,1]^d$, distributed uniformly over the simplex of probability vectors in $\mathbb{R}^d$. I would like to generate $U_i \stackrel{i.i.d.}{\sim} F, \;i=1,\dots,d$ from some distribution $F$, so that $(p_i) := (\frac{U_i}{\sum_{j=1}^d U_j})$ gives the desired random probability vector. What should $F$ be?",,"['probability', 'probability-distributions']"
32,Finding a more direct way to reach $\mathbb{E} \left( \sum (X_i - \mu)^2 \right) - \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right) = \sigma^2$,Finding a more direct way to reach,\mathbb{E} \left( \sum (X_i - \mu)^2 \right) - \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right) = \sigma^2,"Let $X_i$ be independent random variables, $\forall\,i \in \mathbf{n} \equiv \{0,\dots,n-1\}$, with identical expectation value $\mathbb{E}(X_i)=\mu$, and identical variance $\mathrm{Var}(X_i)=\sigma^2$. 1 Also, let $\overline{X}$ be their average, $\frac{1}{n}\sum X_i$ (where the summation for all $i\in \mathbf{n}$ is implicit, a convention I'll use throughout). It is not hard to show, by direct (if slightly tedious) calculation, that $$ \textstyle \mathbb{E} \left( \sum (X_i - \mu)^2 \right) - \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right) = \sigma^2 $$ Whenever I arrive at a very ""simple"" result through a ""tedious"" derivation, as in this case, I get the strong suspicion that there has to be a more direct, and yet entirely rigorous, reasoning to reach it.  Or rather, a way to view the problem that makes the result immediately ""obvious"". 2 In this case, the best I have found goes something like this: the above result follows  from the fact that, first, $$ \textstyle \mathbb{E}  \left( \sum (X_i - \mu)^2 \right) = n \sigma^2 $$ and, second, if we subtract $\overline{X}$ instead of $\mu$, we have ""lost one degree of freedom"" , and ""therefore"" $$ \textstyle \mathbb{E}  \left( \sum (X_i - \overline{X})^2 \right) = (n - 1) \sigma^2 $$ I find this hand-wavy argument thoroughly unconvincing.  (I doubt that those who propose it would believe it if they didn't already know the result from a more rigorous derivation.) Is there something better? EDIT: Here's an example of the kind of argument I'm looking for.  It still has too many gaps to be satisfactory, but at least it shows a reasoning that does not require pencil and paper : it could be delivered orally, or with crude ""marks in the sand"" (no algebra), and be readily understood. First we can see that $$ \textstyle \mathbb{E} \left( \sum (X_i - \mu)^2 \right) \geq \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right) $$ Why?  Because, the value of $c$ that minimizes $\sum (X_i - c)^2$ is $c = \overline{X}$ (a fact for which I could give a similarly hand-wavy, not-entirely-watertight argument, though easy to prove by tedious computation), which means that whenever $\overline{X} \neq \mu$, we would have $\sum (X_i - \mu)^2 > \sum (X_i - \overline{X})^2$. Now, what ""drives"" $\overline{X}$ away from $\mu$ (so to speak) is $\sigma^2$.  So we can conclude that the difference $$ \textstyle \mathbb{E} \left( \sum (X_i - \mu)^2 \right) - \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right) \geq 0 $$ should increase monotonically as $\sigma^2$ increases... Fair enough, but why is the difference exactly $\sigma^2$, and not, say, $\sigma^2/n$, or *gasp* $\pi \sigma^2/n$?  Here my hand-waving begins to run out of steam...  It is suggestive that $\mathbb{E}(\overline{X}) = \mu$ and $$\mathrm{Var}(\overline{X}) = \frac{\sigma^2}{n} = \mathbb{E} \left( ( \overline{X} - \mathbb{E}(\overline{X}))^2 \right) = \mathbb{E} \left( ( \overline{X} - \mu )^2 \right)$$ Therefore it is tempting to surmise that, since, for each $i$, $(X_i - \mu) - (X_i - \overline{X}) = \overline{X} - \mu$, then each term $(X_i - \mu)^2 - (X_i - \overline{X})^2$ would contribute, ""on average"", $\mathbb{E}\left( ( \overline{X} - \mu )^2 \right) = \sigma^2/n$ to the total difference.  This would require justifying the tantalizingly Pythagorean-looking equality: $$\mathbb{E} \left( ( X_i - \mu )^2 \right) = \mathbb{E} \left( ( X_i - \overline{X})^2 + ( \overline{X} - \mu )^2 \right)$$ ...though I readily concede that this is beginning to look as tedious as any algebraic computation. (I note that in this argument I did not use the fact that in this case $\mathrm{Var}(\sum X_i)=\sum\mathrm{Var}(X_i)$, which is surely the way forward.) 1 The typically given condition is to say that the $X_i$ are independent and identically distributed , but, AFAICT, the last condition is stronger than necessary.  For that matter, as Dilip Sarwate pointed out, the independence condition is also stronger than needed.  It is sufficient that $\mathrm{Var}(\sum X_i)=\sum\mathrm{Var}(X_i)$. 2 The ""scare quotes"" around ""simple"", ""tedious"", and ""obvious"" aim to convey the concession that these terms are all, of course, in the eye of the beholder.  So ""simplicity"" is shorthand for subjective simplicity or perceived simplicity , etc.  Also in the eye of the beholder is how much (perceived) tedium seems too much relative to the (perceived) simplicity.  If the difference $\mathbb{E} \left( \sum (X_i - \mu)^2 \right) - \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right)$ had been, say, $\sigma^2/\sqrt{\pi}$, I would not have perceived the standard algebraic derivation as particularly tedious, because $\sigma^2/\sqrt{\pi}$ does not seem to me particularly simple.","Let $X_i$ be independent random variables, $\forall\,i \in \mathbf{n} \equiv \{0,\dots,n-1\}$, with identical expectation value $\mathbb{E}(X_i)=\mu$, and identical variance $\mathrm{Var}(X_i)=\sigma^2$. 1 Also, let $\overline{X}$ be their average, $\frac{1}{n}\sum X_i$ (where the summation for all $i\in \mathbf{n}$ is implicit, a convention I'll use throughout). It is not hard to show, by direct (if slightly tedious) calculation, that $$ \textstyle \mathbb{E} \left( \sum (X_i - \mu)^2 \right) - \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right) = \sigma^2 $$ Whenever I arrive at a very ""simple"" result through a ""tedious"" derivation, as in this case, I get the strong suspicion that there has to be a more direct, and yet entirely rigorous, reasoning to reach it.  Or rather, a way to view the problem that makes the result immediately ""obvious"". 2 In this case, the best I have found goes something like this: the above result follows  from the fact that, first, $$ \textstyle \mathbb{E}  \left( \sum (X_i - \mu)^2 \right) = n \sigma^2 $$ and, second, if we subtract $\overline{X}$ instead of $\mu$, we have ""lost one degree of freedom"" , and ""therefore"" $$ \textstyle \mathbb{E}  \left( \sum (X_i - \overline{X})^2 \right) = (n - 1) \sigma^2 $$ I find this hand-wavy argument thoroughly unconvincing.  (I doubt that those who propose it would believe it if they didn't already know the result from a more rigorous derivation.) Is there something better? EDIT: Here's an example of the kind of argument I'm looking for.  It still has too many gaps to be satisfactory, but at least it shows a reasoning that does not require pencil and paper : it could be delivered orally, or with crude ""marks in the sand"" (no algebra), and be readily understood. First we can see that $$ \textstyle \mathbb{E} \left( \sum (X_i - \mu)^2 \right) \geq \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right) $$ Why?  Because, the value of $c$ that minimizes $\sum (X_i - c)^2$ is $c = \overline{X}$ (a fact for which I could give a similarly hand-wavy, not-entirely-watertight argument, though easy to prove by tedious computation), which means that whenever $\overline{X} \neq \mu$, we would have $\sum (X_i - \mu)^2 > \sum (X_i - \overline{X})^2$. Now, what ""drives"" $\overline{X}$ away from $\mu$ (so to speak) is $\sigma^2$.  So we can conclude that the difference $$ \textstyle \mathbb{E} \left( \sum (X_i - \mu)^2 \right) - \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right) \geq 0 $$ should increase monotonically as $\sigma^2$ increases... Fair enough, but why is the difference exactly $\sigma^2$, and not, say, $\sigma^2/n$, or *gasp* $\pi \sigma^2/n$?  Here my hand-waving begins to run out of steam...  It is suggestive that $\mathbb{E}(\overline{X}) = \mu$ and $$\mathrm{Var}(\overline{X}) = \frac{\sigma^2}{n} = \mathbb{E} \left( ( \overline{X} - \mathbb{E}(\overline{X}))^2 \right) = \mathbb{E} \left( ( \overline{X} - \mu )^2 \right)$$ Therefore it is tempting to surmise that, since, for each $i$, $(X_i - \mu) - (X_i - \overline{X}) = \overline{X} - \mu$, then each term $(X_i - \mu)^2 - (X_i - \overline{X})^2$ would contribute, ""on average"", $\mathbb{E}\left( ( \overline{X} - \mu )^2 \right) = \sigma^2/n$ to the total difference.  This would require justifying the tantalizingly Pythagorean-looking equality: $$\mathbb{E} \left( ( X_i - \mu )^2 \right) = \mathbb{E} \left( ( X_i - \overline{X})^2 + ( \overline{X} - \mu )^2 \right)$$ ...though I readily concede that this is beginning to look as tedious as any algebraic computation. (I note that in this argument I did not use the fact that in this case $\mathrm{Var}(\sum X_i)=\sum\mathrm{Var}(X_i)$, which is surely the way forward.) 1 The typically given condition is to say that the $X_i$ are independent and identically distributed , but, AFAICT, the last condition is stronger than necessary.  For that matter, as Dilip Sarwate pointed out, the independence condition is also stronger than needed.  It is sufficient that $\mathrm{Var}(\sum X_i)=\sum\mathrm{Var}(X_i)$. 2 The ""scare quotes"" around ""simple"", ""tedious"", and ""obvious"" aim to convey the concession that these terms are all, of course, in the eye of the beholder.  So ""simplicity"" is shorthand for subjective simplicity or perceived simplicity , etc.  Also in the eye of the beholder is how much (perceived) tedium seems too much relative to the (perceived) simplicity.  If the difference $\mathbb{E} \left( \sum (X_i - \mu)^2 \right) - \mathbb{E} \left( \sum (X_i - \overline{X})^2 \right)$ had been, say, $\sigma^2/\sqrt{\pi}$, I would not have perceived the standard algebraic derivation as particularly tedious, because $\sigma^2/\sqrt{\pi}$ does not seem to me particularly simple.",,"['probability', 'statistics']"
33,Probability of Gambler's Ruin with Unequal Gain/Loss,Probability of Gambler's Ruin with Unequal Gain/Loss,,"I've spent some time reading other questions about Gambler's Ruin, but couldn't find the answer I was looking for. In most questions, it is assumed the Gambler wins \$1 or loses \$1. I'm curious how one could approach the problem with a payoff or loss that is not equal. For example, what is the probability of ruin on a gambler who starts with \$1000.00 who wins \$41.00 with probability 0.6 and loses \$43.00 with probability 0.4? Is it possible to generalize such a solution? Cheers, Josh","I've spent some time reading other questions about Gambler's Ruin, but couldn't find the answer I was looking for. In most questions, it is assumed the Gambler wins \$1 or loses \$1. I'm curious how one could approach the problem with a payoff or loss that is not equal. For example, what is the probability of ruin on a gambler who starts with \$1000.00 who wins \$41.00 with probability 0.6 and loses \$43.00 with probability 0.4? Is it possible to generalize such a solution? Cheers, Josh",,"['probability', 'stochastic-processes']"
34,Reproducing Kernel Hilbert Space is dense?,Reproducing Kernel Hilbert Space is dense?,,"Let $E=C[0,1]$ , space of all real-valued continuous functions on $[0,1]$ , $\mathcal{E}$ be its Borel $\sigma$ -algebra and $\mu$ a Gaussian measure on $E$ . Let $E^*$ be a space of all continuous linear functions on $E$ . Define map $R$ on $E^*$ by $$x^* \mapsto R(x^*)=\int_E\langle x^*,x\rangle x\;\mu(dx)=\int_E x^*(x)\; x\;\mu(dx)$$ And let $H_\mu$ be the completion of $R(E^*)$ with respect a norm induced by an inner product defined as $\langle Rx^*,Ry^* \rangle=\int_Ex^*(x)y^*(y)\;\mu(dx)$ . $H_\mu$ stands for Reproducing Kernel Hilbert Space and it is dense $^1$ in $E$ if topological support $^2$ of $\mu$ is the whole space $E$ . Why? I think I understand the construction well enough, but the statement is somewhat unexpected. $^1$ $i(H_\mu)$ to be precise, $i$ for inclusion from $H_\mu$ to $E$ . $^2$ topological support is the smallest closed set $F$ such that $\mu(F) = 1$ . Edit This is page 84 of Interest Rate Models: an Infinite Dimensional Stochastic Analysis Perspective. Read online on Springer: Link (the statement is on page 88)","Let , space of all real-valued continuous functions on , be its Borel -algebra and a Gaussian measure on . Let be a space of all continuous linear functions on . Define map on by And let be the completion of with respect a norm induced by an inner product defined as . stands for Reproducing Kernel Hilbert Space and it is dense in if topological support of is the whole space . Why? I think I understand the construction well enough, but the statement is somewhat unexpected. to be precise, for inclusion from to . topological support is the smallest closed set such that . Edit This is page 84 of Interest Rate Models: an Infinite Dimensional Stochastic Analysis Perspective. Read online on Springer: Link (the statement is on page 88)","E=C[0,1] [0,1] \mathcal{E} \sigma \mu E E^* E R E^* x^* \mapsto R(x^*)=\int_E\langle x^*,x\rangle x\;\mu(dx)=\int_E x^*(x)\; x\;\mu(dx) H_\mu R(E^*) \langle Rx^*,Ry^* \rangle=\int_Ex^*(x)y^*(y)\;\mu(dx) H_\mu ^1 E ^2 \mu E ^1 i(H_\mu) i H_\mu E ^2 F \mu(F) = 1","['probability', 'functional-analysis', 'stochastic-processes', 'hilbert-spaces']"
35,A probability game,A probability game,,"Motivation: A friend asked me this question. The Problem: Suppose you start off with a dollar. You flip a fair coin, if it lands on heads you win $50$ cents otherwise you lose $50$ cents. If after $n$ flips you have a nonzero amount of money, you win. What's the probability you win? What about the limiting case as $n$ tends to infinity? edit: In this game you are not allowed to have negative money. Thanks, Jonathan Fischoff, the linked helped greatly.","Motivation: A friend asked me this question. The Problem: Suppose you start off with a dollar. You flip a fair coin, if it lands on heads you win $50$ cents otherwise you lose $50$ cents. If after $n$ flips you have a nonzero amount of money, you win. What's the probability you win? What about the limiting case as $n$ tends to infinity? edit: In this game you are not allowed to have negative money. Thanks, Jonathan Fischoff, the linked helped greatly.",,[]
36,Entropy of fair but correlated coin flips,Entropy of fair but correlated coin flips,,"Consider the joint distribution, $p(\xi_1,...\xi_N)$ , with components defined as $\xi_i=\mathrm{sign}(x_i)$ , with $(x_1,...,x_N)\sim\mathcal{N}(0,\Sigma)$ with $ \Sigma_{ij}=\delta_{ij}+(1-\delta_{ij})\tilde{\rho} $ , i.e. all off-diagonal entries of $\Sigma$ are $\tilde{\rho}$ . Since all components $x_i$ have unit variance (i.e. diagonal entries of $\Sigma$ are $1$ ), $\tilde{\rho}$ is then the correlation of any pair $(x_i,x_j)$ . Note that all single component marginals $p(\xi_i)=1/2$ , i.e. the coins are unbiased; we can always set the value of $\tilde{\rho}$ so that any pair $(\xi_i,\xi_j)$ has the desired correlation of $\rho$ . What is the formula for the entropy of $p(\xi_1,...\xi_N)$ , denoted $H_N(\rho)$ ? The parametrization of $\tilde{\rho}$ by $\rho$ depends on $N$ and is obtained by calculating the pair marginal probability $p(\xi_i=1,\xi_j=1)$ , denoted $p_{11}$ . Let $f_N(\tilde{\rho})$ be the function of $\tilde{\rho}$ that gives this probability. The formula for the correlation between two binary random variables, $$ \rho=\frac{p_{11}-p_{-1}p_1}{\sqrt{p_{-1}(1-p_{-1})p_1(1-p_1)}}={4}p_{11}-1\;, $$ with $p_{\pm1}$ denoting $p(\xi_i=\pm 1)=p(\xi_j=\pm 1)=1/2$ , gives the desired parametrization, $$ \tilde{\rho}_N(\rho):=f^{-1}_N\left(\frac{\rho+1}{4}\right)\;.\;\;\;\;(\mathrm{eq}.1) $$ Solution for $N=2$ : Computing the 2D Gaussian integral using spherical coordinates gives $\tilde{\rho}_{N=2}(\rho)=\sin(\frac{\pi}{2}\rho)$ . In this special case, $(\mathrm{eq}.1)$ and symmetry constraints completely specify the distribution $p(\xi_1,\xi_2)=(1+\xi_1\xi_2\rho)/4$ . Calculation of the entropy from its definition gives $$ H_{N=2}(\rho)=H(\xi_1,\xi_2)=\sum_{\eta=(1\pm\rho)/4}2\left(-\eta\log_2\eta\right). $$ We have $H_{N=2}(0)=2$ bits and $H_{N=2}(1)=1$ bit. In fact, we know $H_N(\rho=0)=N$ and $H_N(\rho=1)=1$ for all $N$ . For $N>2$ : There are lots of Gaussian integrals to do. Due to the symmetry in the index permutations there are only $N$ distinct integral values among the $2^N$ terms in the entropy. They can be grouped by how many 1s they contain. The pair of all $-1$ s can be grouped with the singleton group of all $1$ s due to the reflective symmetry in the plane normal to the main diagonal. We just need compute the multiplicity and the integral for each of the $N$ terms. E.g. for $N=2$ there are 2 terms (listed above with multiplicity 2). For $N=3$ there are three terms (two for tuples containing one and two 1s), the third being the extreme group having $(-1,-1,-1)$ and $(1,1,1)$ in binary notation. In section 3.2 of this paper , Six gives a recursive solution to the distribution. This could be used to compute the entropy and the parametrization function $\tilde{\rho}_N(\rho)$ . Accepted Answer : In the end, an alternative approach based on expressing $x_i=\sqrt{1-\tilde{\rho}}y_i+\sqrt{\tilde{\rho}}s$ , with $y_i,s\sim\mathcal{N}(0,1)$ , seems to be more straightforward and is the accepted answer below. That answer also indicates that the $f_N(\tilde{\rho})$ does NOT seem to depend on $N$ after all.","Consider the joint distribution, , with components defined as , with with , i.e. all off-diagonal entries of are . Since all components have unit variance (i.e. diagonal entries of are ), is then the correlation of any pair . Note that all single component marginals , i.e. the coins are unbiased; we can always set the value of so that any pair has the desired correlation of . What is the formula for the entropy of , denoted ? The parametrization of by depends on and is obtained by calculating the pair marginal probability , denoted . Let be the function of that gives this probability. The formula for the correlation between two binary random variables, with denoting , gives the desired parametrization, Solution for : Computing the 2D Gaussian integral using spherical coordinates gives . In this special case, and symmetry constraints completely specify the distribution . Calculation of the entropy from its definition gives We have bits and bit. In fact, we know and for all . For : There are lots of Gaussian integrals to do. Due to the symmetry in the index permutations there are only distinct integral values among the terms in the entropy. They can be grouped by how many 1s they contain. The pair of all s can be grouped with the singleton group of all s due to the reflective symmetry in the plane normal to the main diagonal. We just need compute the multiplicity and the integral for each of the terms. E.g. for there are 2 terms (listed above with multiplicity 2). For there are three terms (two for tuples containing one and two 1s), the third being the extreme group having and in binary notation. In section 3.2 of this paper , Six gives a recursive solution to the distribution. This could be used to compute the entropy and the parametrization function . Accepted Answer : In the end, an alternative approach based on expressing , with , seems to be more straightforward and is the accepted answer below. That answer also indicates that the does NOT seem to depend on after all.","p(\xi_1,...\xi_N) \xi_i=\mathrm{sign}(x_i) (x_1,...,x_N)\sim\mathcal{N}(0,\Sigma) 
\Sigma_{ij}=\delta_{ij}+(1-\delta_{ij})\tilde{\rho}
 \Sigma \tilde{\rho} x_i \Sigma 1 \tilde{\rho} (x_i,x_j) p(\xi_i)=1/2 \tilde{\rho} (\xi_i,\xi_j) \rho p(\xi_1,...\xi_N) H_N(\rho) \tilde{\rho} \rho N p(\xi_i=1,\xi_j=1) p_{11} f_N(\tilde{\rho}) \tilde{\rho} 
\rho=\frac{p_{11}-p_{-1}p_1}{\sqrt{p_{-1}(1-p_{-1})p_1(1-p_1)}}={4}p_{11}-1\;,
 p_{\pm1} p(\xi_i=\pm 1)=p(\xi_j=\pm 1)=1/2 
\tilde{\rho}_N(\rho):=f^{-1}_N\left(\frac{\rho+1}{4}\right)\;.\;\;\;\;(\mathrm{eq}.1)
 N=2 \tilde{\rho}_{N=2}(\rho)=\sin(\frac{\pi}{2}\rho) (\mathrm{eq}.1) p(\xi_1,\xi_2)=(1+\xi_1\xi_2\rho)/4 
H_{N=2}(\rho)=H(\xi_1,\xi_2)=\sum_{\eta=(1\pm\rho)/4}2\left(-\eta\log_2\eta\right).
 H_{N=2}(0)=2 H_{N=2}(1)=1 H_N(\rho=0)=N H_N(\rho=1)=1 N N>2 N 2^N -1 1 N N=2 N=3 (-1,-1,-1) (1,1,1) \tilde{\rho}_N(\rho) x_i=\sqrt{1-\tilde{\rho}}y_i+\sqrt{\tilde{\rho}}s y_i,s\sim\mathcal{N}(0,1) f_N(\tilde{\rho}) N","['probability', 'probability-distributions', 'information-theory', 'multiple-integral', 'entropy']"
37,How to group people so everyone meets?,How to group people so everyone meets?,,"I have sort of a stupid maths problem which I was thinking about recently, given the UK's covid rules about only being able to meet with 6 people max. If I have a group of $N$ friends (e.g. 15) and everyone wants to hang out with everyone else, what's the fewest number of meet-ups we would need to accomplish this (with max 6 people in each)? This seems similar to the social golfer problem. Is it possible to come up with a general solution? (obviously not planning to go and do this in person, but I was thinking about this and couldn't come up with a solution)","I have sort of a stupid maths problem which I was thinking about recently, given the UK's covid rules about only being able to meet with 6 people max. If I have a group of friends (e.g. 15) and everyone wants to hang out with everyone else, what's the fewest number of meet-ups we would need to accomplish this (with max 6 people in each)? This seems similar to the social golfer problem. Is it possible to come up with a general solution? (obviously not planning to go and do this in person, but I was thinking about this and couldn't come up with a solution)",N,"['probability', 'combinatorics', 'combinations']"
38,Average number of strings with edit distance at most 4,Average number of strings with edit distance at most 4,,"Consider a binary string of length $n \geq 4$ .   An edit operation is a single bit insert, delete or substitution.  The edit distance between two strings is the minimum number of edit operations needed to transform one string into the other one.  Given a string $S$ , my question relates to the number of distinct strings of length $n$ which are edit distance at most $4$ from $S$ . Let us write $g_k(S)$ for the number of distinct strings of length $n$ which are edit distance at most $k$ from $S$ . Let $X_n$ be a random variable representing a random binary string of length $n$ , with the bits chosen uniformly and independently. We can compute $\mathbb{E}(g_k(X_n))$ for $k = 0, 1, 2, 3$ explicitly. $\mathbb{E}(g_0(X_n)) = 1$ $\mathbb{E}(g_1(X_n)) = n+1$ $\mathbb{E}(g_2(X_n)) = \frac{13}{2} - \frac{5n}{2}  + n^2 - 6\cdot2^{-n}$ $\mathbb{E}(g_3(X_n)) =  -\frac{83}{2 }+ \frac{331n}{12} -6 n^2 + \frac{2n^3}{3} + 2^{-n}(40 + 6n -4n^2)$ ( Ref 1 and Ref 2 ) This leads directly to my question: Let $X_n$ be a random variable representing a random binary string of   length $n$ , with the bits chosen uniformly and independently.  What is: $$\mathbb{E}(g_4(X_n))\;?$$ For small $n$ we can compute the value exactly: $\mathbb{E}(g_4(X_4)) = 16$ . $\mathbb{E}(g_4(X_5)) = 31 \frac{11}{16}$ . $\mathbb{E}(g_4(X_6)) = 61 \frac{21}{32}$ . $\mathbb{E}(g_4(X_7)) = 116 \frac{7}{8}$ . $\mathbb{E}(g_4(X_8)) = 214 \frac{43}{128}$ . $\mathbb{E}(g_4(X_9)) = 378 \frac{49}{246}$ . $\mathbb{E}(g_4(X_{10})) = 640 \frac{301}{512}$ . $\mathbb{E}(g_4(X_{11})) = 1042 \frac{1}{16}$ . $\mathbb{E}(g_4(X_{12})) = 1631 \frac{1345}{2048}$ . $\mathbb{E}(g_4(X_{13})) = 2466 \frac{3909}{4096}$ . $\mathbb{E}(g_4(X_{14})) = 3614 \frac{563}{8192}$ It seems tempting to guess the general form of $\mathbb{E}(g_4(X_n))$ from the examples of $\mathbb{E}(g_2(X_n))$ and $\mathbb{E}(g_3(X_n))$ but I have not succeeded in getting that to work.","Consider a binary string of length .   An edit operation is a single bit insert, delete or substitution.  The edit distance between two strings is the minimum number of edit operations needed to transform one string into the other one.  Given a string , my question relates to the number of distinct strings of length which are edit distance at most from . Let us write for the number of distinct strings of length which are edit distance at most from . Let be a random variable representing a random binary string of length , with the bits chosen uniformly and independently. We can compute for explicitly. ( Ref 1 and Ref 2 ) This leads directly to my question: Let be a random variable representing a random binary string of   length , with the bits chosen uniformly and independently.  What is: For small we can compute the value exactly: . . . . . . . . . . It seems tempting to guess the general form of from the examples of and but I have not succeeded in getting that to work.","n \geq 4 S n 4 S g_k(S) n k S X_n n \mathbb{E}(g_k(X_n)) k = 0, 1, 2, 3 \mathbb{E}(g_0(X_n)) = 1 \mathbb{E}(g_1(X_n)) = n+1 \mathbb{E}(g_2(X_n)) = \frac{13}{2} - \frac{5n}{2}  + n^2 - 6\cdot2^{-n} \mathbb{E}(g_3(X_n)) =  -\frac{83}{2 }+ \frac{331n}{12} -6 n^2 + \frac{2n^3}{3} + 2^{-n}(40 + 6n -4n^2) X_n n \mathbb{E}(g_4(X_n))\;? n \mathbb{E}(g_4(X_4)) = 16 \mathbb{E}(g_4(X_5)) = 31 \frac{11}{16} \mathbb{E}(g_4(X_6)) = 61 \frac{21}{32} \mathbb{E}(g_4(X_7)) = 116 \frac{7}{8} \mathbb{E}(g_4(X_8)) = 214 \frac{43}{128} \mathbb{E}(g_4(X_9)) = 378 \frac{49}{246} \mathbb{E}(g_4(X_{10})) = 640 \frac{301}{512} \mathbb{E}(g_4(X_{11})) = 1042 \frac{1}{16} \mathbb{E}(g_4(X_{12})) = 1631 \frac{1345}{2048} \mathbb{E}(g_4(X_{13})) = 2466 \frac{3909}{4096} \mathbb{E}(g_4(X_{14})) = 3614 \frac{563}{8192} \mathbb{E}(g_4(X_n)) \mathbb{E}(g_2(X_n)) \mathbb{E}(g_3(X_n))",['probability']
39,Counterexamples concerning the central limit theorem,Counterexamples concerning the central limit theorem,,"The central limit theorem states that, if $X$ is a random variable with finite variance $\sigma^2$ and expected value $\mu$ , and if $(X_n)$ is a sequence of independent random variables identically distributed like $ X $ , then \begin{equation} Z_n = {\frac{{\overline{X}}_n-\mu}{\sqrt{\sigma^2/n}}}\ \rightsquigarrow N(0,1), \end{equation} where ${\overline{X}}_{n} = \frac{1}{n} \sum_{i=1}^{n} X_i$ and $\rightsquigarrow$ means convergence in distribution, which in this case is equivalent to the pointwise convergence of the cdf of $Z_n$ to the cdf of a $N(0,1)$ . Suppose moreover that $X_n$ is absolutely continuous for all $n$ โs. Then $Z_n$ is absolutely continuous for all $n$ โs. Are there examples of such sequences $(X_n)$ , such that the pdf of $Z_n$ does not converge pointwise to the pdf of a $N(0,1)$ , not even almost everywhere (w.r.t. the Lebesgue measure on $\mathbb R$ )?","The central limit theorem states that, if is a random variable with finite variance and expected value , and if is a sequence of independent random variables identically distributed like , then where and means convergence in distribution, which in this case is equivalent to the pointwise convergence of the cdf of to the cdf of a . Suppose moreover that is absolutely continuous for all โs. Then is absolutely continuous for all โs. Are there examples of such sequences , such that the pdf of does not converge pointwise to the pdf of a , not even almost everywhere (w.r.t. the Lebesgue measure on )?","X \sigma^2 \mu (X_n)  X  \begin{equation}
Z_n = {\frac{{\overline{X}}_n-\mu}{\sqrt{\sigma^2/n}}}\ \rightsquigarrow N(0,1),
\end{equation} {\overline{X}}_{n} = \frac{1}{n} \sum_{i=1}^{n} X_i \rightsquigarrow Z_n N(0,1) X_n n Z_n n (X_n) Z_n N(0,1) \mathbb R","['probability', 'probability-theory', 'central-limit-theorem']"
40,"""Distribution"" of numbers $0\leq a\leq b\leq c\leq d\leq 1$","""Distribution"" of numbers",0\leq a\leq b\leq c\leq d\leq 1,"A friend came up with the next problem: Consider $0\leq a\leq b\leq c\leq d\leq 1$ numbers such that $a+b+c+d=1$. Are there numbers $a_{0}$, $b_{0}$, $c_{0}$, $d_{0}$ that minimize $$|a-a_{0}|+|b-b_{0}|+|c-c_{0}|+|d-d_{0}|$$ most of the time? I mean, if we repeat the process of choosing $a$, $b$, $c$ and $d$ randomly, is there a expected value for $a$, $b$, $c$ and $d$? And what it is? I tried to start with an easiest problem, with just $a$ and $b$, such that $0\leq a\leq b\leq 1$ and $a+b=1$ but I had no idea where to start, so I decided to try with some numerical sampling, and I did the next in Python: Choose a number $x\in [0,1]$ uniformely, and define $a=\min\{x,1-x\}$ and $b=\max\{x,1-x\}$. Clearly $0\leq a\leq b\leq 1$ and $a+b=1$. Doing this, and repeating a lot of times I got that the ""expected value"" for $a$ was $0.25$ and for $b$ was $0.75$, so the ratio is $1:3$ . Next, I tried the same in Python but with two values: Choose $x,y\in [0,1]$ uniformely, and let $x_{1}=\min\{x,y\}$ and $x_{2}=\max\{x,y\}$, now define $$A=\{x_{1},x_{2}-x_{1},1-x_{2}\}$$ and let $a_{1}$, $a_{2}$, $a_{3}$ be the elements of $A$ in increasing order. Clearly $0\leq a_{1}\leq a_{2}\leq a_{3}\leq 1$, and $a_{1}+a_{2}+a_{3}=1$, and repeting a lot of times I got that the ""expected values"" were of the ratio $2:5:11$ . Repeating the same method but now with one more variable I got that the ""expected values"" were on ratio $3:7:13:25$ . Lastly, with one more variable the ratios were $12:27:47:77:137$ . All this calculations were found just by trial and error, and are clearly non mathematically justified, but seems like, at least, a good conjecture. Is there any hidden pattern behind these ratios? Is there any reason for this numbers to came up? Any help would be appreciated.","A friend came up with the next problem: Consider $0\leq a\leq b\leq c\leq d\leq 1$ numbers such that $a+b+c+d=1$. Are there numbers $a_{0}$, $b_{0}$, $c_{0}$, $d_{0}$ that minimize $$|a-a_{0}|+|b-b_{0}|+|c-c_{0}|+|d-d_{0}|$$ most of the time? I mean, if we repeat the process of choosing $a$, $b$, $c$ and $d$ randomly, is there a expected value for $a$, $b$, $c$ and $d$? And what it is? I tried to start with an easiest problem, with just $a$ and $b$, such that $0\leq a\leq b\leq 1$ and $a+b=1$ but I had no idea where to start, so I decided to try with some numerical sampling, and I did the next in Python: Choose a number $x\in [0,1]$ uniformely, and define $a=\min\{x,1-x\}$ and $b=\max\{x,1-x\}$. Clearly $0\leq a\leq b\leq 1$ and $a+b=1$. Doing this, and repeating a lot of times I got that the ""expected value"" for $a$ was $0.25$ and for $b$ was $0.75$, so the ratio is $1:3$ . Next, I tried the same in Python but with two values: Choose $x,y\in [0,1]$ uniformely, and let $x_{1}=\min\{x,y\}$ and $x_{2}=\max\{x,y\}$, now define $$A=\{x_{1},x_{2}-x_{1},1-x_{2}\}$$ and let $a_{1}$, $a_{2}$, $a_{3}$ be the elements of $A$ in increasing order. Clearly $0\leq a_{1}\leq a_{2}\leq a_{3}\leq 1$, and $a_{1}+a_{2}+a_{3}=1$, and repeting a lot of times I got that the ""expected values"" were of the ratio $2:5:11$ . Repeating the same method but now with one more variable I got that the ""expected values"" were on ratio $3:7:13:25$ . Lastly, with one more variable the ratios were $12:27:47:77:137$ . All this calculations were found just by trial and error, and are clearly non mathematically justified, but seems like, at least, a good conjecture. Is there any hidden pattern behind these ratios? Is there any reason for this numbers to came up? Any help would be appreciated.",,"['probability', 'statistics']"
41,Asymptotic length of reduced word on free group with replacements,Asymptotic length of reduced word on free group with replacements,,"This seems to be an elementary question, but it's proving hard for me to just Google. Suppose you have a sequence which picks elements out of $\{a, a^{-1}, b, b^{-1}, c, c^{-1}\}$ with equal probability. After, say, seven steps you'll get words like $a b c c^{-1} a c b^{-1} $ which in this case reduces to $a b a c  b^{-1} $ after canceling inverses. My question is this: if I write $c$ as some string of $a, a^{-1}, b, b^{-1}$, (and write $c^{-1}$ as the inverse of that) are there any theorems about the expected length of the new sequence after reduction? For example, I could take $c = a^{-1} b b$ so my previous word becomes just $ab b$. I care mostly about the case of a very long word.","This seems to be an elementary question, but it's proving hard for me to just Google. Suppose you have a sequence which picks elements out of $\{a, a^{-1}, b, b^{-1}, c, c^{-1}\}$ with equal probability. After, say, seven steps you'll get words like $a b c c^{-1} a c b^{-1} $ which in this case reduces to $a b a c  b^{-1} $ after canceling inverses. My question is this: if I write $c$ as some string of $a, a^{-1}, b, b^{-1}$, (and write $c^{-1}$ as the inverse of that) are there any theorems about the expected length of the new sequence after reduction? For example, I could take $c = a^{-1} b b$ so my previous word becomes just $ab b$. I care mostly about the case of a very long word.",,"['probability', 'group-theory', 'reference-request', 'free-groups', 'combinatorics-on-words']"
42,What is the probability that the product of $20$ random numbers between $1$ and $2$ is greater than $10000$?,What is the probability that the product of  random numbers between  and  is greater than ?,20 1 2 10000,"Twenty random real numbers $a_1,a_2,\dots,a_{20}$ are chosen such that $1\le a_i \le 2$ . What is the probability that their product is greater than $10000$ ? (By random, I mean each real number in the interval $[1,2]$ has an equal chance of being chosen. All twenty numbers are chosen independently of each other.)","Twenty random real numbers are chosen such that . What is the probability that their product is greater than ? (By random, I mean each real number in the interval has an equal chance of being chosen. All twenty numbers are chosen independently of each other.)","a_1,a_2,\dots,a_{20} 1\le a_i \le 2 10000 [1,2]","['probability', 'products']"
43,The probability of a drunk person/random walk,The probability of a drunk person/random walk,,"A drunk person wonders aimlessly along a path by going forward 1 step and backward 1 step with equal probabilities of $\frac12$. a) After 10 steps, what is the probability that he has moved 2 steps forward? b) What is the probability that he will make it to his front door within 20 steps before he collapses with the door being 6 steps in front of him. My approach was to use Binomial in both cases: a)${10\choose6} 0.5^{10}$. I can move 6 steps forward and 4 backwards and I will be in spot +2. b)${20\choose6} 0.5^{20}$ I believe I have part a) correct but not b). I don't know how to handle the fact that in the spot 6+ is the house, a stop. Can someone help me with part b)? I am seeing this wrong? I am thinking he is at zero but he can go -1 spot. Actually I am not sure if he can go from 0 to -1.","A drunk person wonders aimlessly along a path by going forward 1 step and backward 1 step with equal probabilities of $\frac12$. a) After 10 steps, what is the probability that he has moved 2 steps forward? b) What is the probability that he will make it to his front door within 20 steps before he collapses with the door being 6 steps in front of him. My approach was to use Binomial in both cases: a)${10\choose6} 0.5^{10}$. I can move 6 steps forward and 4 backwards and I will be in spot +2. b)${20\choose6} 0.5^{20}$ I believe I have part a) correct but not b). I don't know how to handle the fact that in the spot 6+ is the house, a stop. Can someone help me with part b)? I am seeing this wrong? I am thinking he is at zero but he can go -1 spot. Actually I am not sure if he can go from 0 to -1.",,"['probability', 'statistics', 'probability-theory', 'probability-distributions', 'conditional-probability']"
44,A Proof of Correctness of Durstenfeld's Random Permutation Algorithm,A Proof of Correctness of Durstenfeld's Random Permutation Algorithm,,"Question : Does anyone have a precise mathematical proof of Durstenfeld's Algorithm ? The first $O(n)$ shuffle or random permutation generator was published by Richard Durstenfeld in 1964. This algorithm came to the notice of programmers because it was included in Knuth 1969, page 125, 2 , as Algorithm P . A succinct statement of the algorithm is: \begin{equation} \text{for  }\ k \leftarrow n,n-1,\ldots,2\ \text{ do } \begin{cases} \text{Choose at random a number}\ \ r \in [1,k] \\\ \text{Interchange }\pi[r] \text{ and }\pi[k],\\ \end{cases} \end{equation} where $\pi[1 \ldots n]$ is the array to be shuffled or randomly permuted. This is a truly elegant algorithm, computationally and mathematically. Computationally it handles set operations by dividing the array $\pi$ into an unshuffled set $\pi[1,\ldots, k]$, and a shuffled set $\pi[k+1,\ldots, n]$. At each iteration $k$, it chooses a random element $\pi[r]$ from the unshuffled set  $\pi[1,\ldots, k]$, and interchanges it with $\pi[k]$. This moves $\pi[r]$ into the new shuffled set $\pi[k,\ldots, n]$, where it remains, unmoved, for all subsequent iterations. This is done in $O(1)$ time and space. Thus, the time and space complexity of Durstenfeld's algorithm is $O(n)$, which is optimal. Mathematically, the algorithm is elegant because it implicitly uses the well-known lemma that every permutation $\pi$ is a product of transpositions. At each iteration $k$, the algorithm chooses a random number $r_k \in [1,\ldots,k]$ and performs a transposition $(\pi[k], \pi[r_k])$. Thus the random permutation produced can be written as $$ \pi = (\pi[n],\pi[r_n])(\pi[n-1],\pi[r_{n-1}]) \cdots (\pi[k],\pi[r_k])\cdots (\pi[2],\pi[r_2]), $$ where $(\pi[k],\pi[r_k])$ is the transposition or interchange of $\pi[k]$ and $\pi[r_k]$. Matlab Implementation of Durstenfeld's Algorithm function p = GRPdurG(p) % ------------------------------------------------------------- % Randomly permute the elements of p(1:n) using Durstenfeld's  % Random Permutation Algorithm, CACM, Vol 7, No. 7, 1964.  % See Knuth, Section 3.4.2, TAOCP, Vol 2, 3rd Ed. % Derek O'Connor, 8 Dec 2010. [emailยprotected] % % USE: n=10^7; p = 1:n; p = GRPdur(p); % ------------------------------------------------------------- n = length(p); for k = n:-1:2         r = 1+floor(rand*k);    % random integer between 1 and k     t    = p(k);     p(k) = p(r);            % Swap(p(r),p(k)).     p(r) = t;                   end %  GRPdurG A Combinatorial Conundrum A random permutation of the integers $\{1,2, \ldots,10^7\}$ can be generated in a few seconds using the Durstenfeld Shuffle algorithm on a standard PC. The combinatorial space $\mathcal{C}$ in this case is set of all permutations of  size $10^7$. The size of this sample space is \begin{equation*} |\mathcal{C}| = n! = (10^7)! \approx 10^{65,657,059} \end{equation*} This is a gigantic number and very far beyond limits of any known random number generator. That is, $|\mathcal{C}| \ggg |\mathcal{G}|$, the state space of the random number generator. For example, the period (size of state space) of the well-known Mersenne Twister RNG (MT) is about $10^{6000}$. Hence random permutation generators using MT must miss nearly all permutations in this space. None-the-less, the Matlab function above produces random permutations of length $10^7$ in the correct statistical proportions, e.g, $1/e$  are derangements, $1/n$ are cycles, etc., yet it must miss most of the possible permutations. Hence the conundrum. The most important question to me is: Do random permutation generators sample uniformly from the space of permutations ? assuming they use the best random number generator available. I suspect that this is a difficult mathematical problem. See this Matlab discussion: What Does RANDPERM Miss? Historical Note I believe that Durstenfeld's Algorithm was incorrectly attributed to Fisher and Yates by Knuth, in (2) below. See here O'Connor Scribd Note on Fisher-Yates . The original Durstenfeld Algorithm is here: CACM Algorithm References Durstenfeld, R. 1964: ACM Algorithm 235: Random Permutation, Communications of the ACM , Vol 7, No 7. Knuth, D. 1969, 1998: Seminumerical Algorithms 1st & 3rd Eds. The Art of Computer Programming Series , Volume 2.","Question : Does anyone have a precise mathematical proof of Durstenfeld's Algorithm ? The first $O(n)$ shuffle or random permutation generator was published by Richard Durstenfeld in 1964. This algorithm came to the notice of programmers because it was included in Knuth 1969, page 125, 2 , as Algorithm P . A succinct statement of the algorithm is: \begin{equation} \text{for  }\ k \leftarrow n,n-1,\ldots,2\ \text{ do } \begin{cases} \text{Choose at random a number}\ \ r \in [1,k] \\\ \text{Interchange }\pi[r] \text{ and }\pi[k],\\ \end{cases} \end{equation} where $\pi[1 \ldots n]$ is the array to be shuffled or randomly permuted. This is a truly elegant algorithm, computationally and mathematically. Computationally it handles set operations by dividing the array $\pi$ into an unshuffled set $\pi[1,\ldots, k]$, and a shuffled set $\pi[k+1,\ldots, n]$. At each iteration $k$, it chooses a random element $\pi[r]$ from the unshuffled set  $\pi[1,\ldots, k]$, and interchanges it with $\pi[k]$. This moves $\pi[r]$ into the new shuffled set $\pi[k,\ldots, n]$, where it remains, unmoved, for all subsequent iterations. This is done in $O(1)$ time and space. Thus, the time and space complexity of Durstenfeld's algorithm is $O(n)$, which is optimal. Mathematically, the algorithm is elegant because it implicitly uses the well-known lemma that every permutation $\pi$ is a product of transpositions. At each iteration $k$, the algorithm chooses a random number $r_k \in [1,\ldots,k]$ and performs a transposition $(\pi[k], \pi[r_k])$. Thus the random permutation produced can be written as $$ \pi = (\pi[n],\pi[r_n])(\pi[n-1],\pi[r_{n-1}]) \cdots (\pi[k],\pi[r_k])\cdots (\pi[2],\pi[r_2]), $$ where $(\pi[k],\pi[r_k])$ is the transposition or interchange of $\pi[k]$ and $\pi[r_k]$. Matlab Implementation of Durstenfeld's Algorithm function p = GRPdurG(p) % ------------------------------------------------------------- % Randomly permute the elements of p(1:n) using Durstenfeld's  % Random Permutation Algorithm, CACM, Vol 7, No. 7, 1964.  % See Knuth, Section 3.4.2, TAOCP, Vol 2, 3rd Ed. % Derek O'Connor, 8 Dec 2010. [emailยprotected] % % USE: n=10^7; p = 1:n; p = GRPdur(p); % ------------------------------------------------------------- n = length(p); for k = n:-1:2         r = 1+floor(rand*k);    % random integer between 1 and k     t    = p(k);     p(k) = p(r);            % Swap(p(r),p(k)).     p(r) = t;                   end %  GRPdurG A Combinatorial Conundrum A random permutation of the integers $\{1,2, \ldots,10^7\}$ can be generated in a few seconds using the Durstenfeld Shuffle algorithm on a standard PC. The combinatorial space $\mathcal{C}$ in this case is set of all permutations of  size $10^7$. The size of this sample space is \begin{equation*} |\mathcal{C}| = n! = (10^7)! \approx 10^{65,657,059} \end{equation*} This is a gigantic number and very far beyond limits of any known random number generator. That is, $|\mathcal{C}| \ggg |\mathcal{G}|$, the state space of the random number generator. For example, the period (size of state space) of the well-known Mersenne Twister RNG (MT) is about $10^{6000}$. Hence random permutation generators using MT must miss nearly all permutations in this space. None-the-less, the Matlab function above produces random permutations of length $10^7$ in the correct statistical proportions, e.g, $1/e$  are derangements, $1/n$ are cycles, etc., yet it must miss most of the possible permutations. Hence the conundrum. The most important question to me is: Do random permutation generators sample uniformly from the space of permutations ? assuming they use the best random number generator available. I suspect that this is a difficult mathematical problem. See this Matlab discussion: What Does RANDPERM Miss? Historical Note I believe that Durstenfeld's Algorithm was incorrectly attributed to Fisher and Yates by Knuth, in (2) below. See here O'Connor Scribd Note on Fisher-Yates . The original Durstenfeld Algorithm is here: CACM Algorithm References Durstenfeld, R. 1964: ACM Algorithm 235: Random Permutation, Communications of the ACM , Vol 7, No 7. Knuth, D. 1969, 1998: Seminumerical Algorithms 1st & 3rd Eds. The Art of Computer Programming Series , Volume 2.",,"['probability', 'combinatorics', 'permutations']"
45,Can Averages be Averaged?,Can Averages be Averaged?,,"I am trying to understand if averages of different variables can be combined together to produce ""better"" estimates. For example - suppose there are 100 high schools, and we randomly select students (i.e. sample) from each of these 100 high schools. Suppose we find that in these randomly selected students (this is all the information we have - we only have the aggregate summaries and not data on individual students): The graduation rate for males is 55% and for females 65% The graduation rate for students who study more than 10 hours a week is 80% and the for students who study less than 10 hours a week is 60% Suppose for one of these high schools that we randomly studied, we would like to ""interpolate"" and find out how many students might graduate. We know the population of this school: There are 500 males and 500 females There are 400 students that study more than 10 hours a week and 600 students that study less than 10 hours a week We are interested in estimating how many students will graduate. Using the gender as a variable, we could say that $500 \times 0.55 + 500 \times 0.65 = 600$ students are expected to graduate on average Using hours of studied as a variable, we could say that $400 \times 0.8 + 600 \times 0.6 = 680$ students are expected to graduate on average But could we take the average for both of these numbers and say that $(600 + 680)/2 = 640$ students are expected to graduate on average? Would this be a more ""reliable"" estimate that averages out possible errors in the initial graduation rates we used to base our estimates on? I am trying to figure out if this logic is correct (e.g. is this mathematically correct?) - can someone please comment on this? I also wonder if this method might somehow allow you to assign some measure of ""risk"" to this estimate, e.g. 640 plus/minus ""c""? ( Confidence interval without std? ) Thank you!","I am trying to understand if averages of different variables can be combined together to produce ""better"" estimates. For example - suppose there are 100 high schools, and we randomly select students (i.e. sample) from each of these 100 high schools. Suppose we find that in these randomly selected students (this is all the information we have - we only have the aggregate summaries and not data on individual students): The graduation rate for males is 55% and for females 65% The graduation rate for students who study more than 10 hours a week is 80% and the for students who study less than 10 hours a week is 60% Suppose for one of these high schools that we randomly studied, we would like to ""interpolate"" and find out how many students might graduate. We know the population of this school: There are 500 males and 500 females There are 400 students that study more than 10 hours a week and 600 students that study less than 10 hours a week We are interested in estimating how many students will graduate. Using the gender as a variable, we could say that students are expected to graduate on average Using hours of studied as a variable, we could say that students are expected to graduate on average But could we take the average for both of these numbers and say that students are expected to graduate on average? Would this be a more ""reliable"" estimate that averages out possible errors in the initial graduation rates we used to base our estimates on? I am trying to figure out if this logic is correct (e.g. is this mathematically correct?) - can someone please comment on this? I also wonder if this method might somehow allow you to assign some measure of ""risk"" to this estimate, e.g. 640 plus/minus ""c""? ( Confidence interval without std? ) Thank you!",500 \times 0.55 + 500 \times 0.65 = 600 400 \times 0.8 + 600 \times 0.6 = 680 (600 + 680)/2 = 640,"['probability', 'statistics']"
46,Example of a compact topological space $M$ such that $\mathcal M_1(M)$ is not compact.,Example of a compact topological space  such that  is not compact.,M \mathcal M_1(M),"It is well known that if $(M,\tau)$ is a compact Hausdorff topological space then (by RieszโMarkovโKakutani representation theorem + BanachโAlaoglu theorem ) we have that the space $$\mathcal M_1(M) :=\left\{\mu;\ \mu\ \text{is a }\tau\text{-Borel probability measure on }M\right\} $$ is compact in the weak $^*$ topology, $\textit{i.e}.$ the topology generated by the basis of neighborhoods $$V(\mu;f_1,\ldots,f_n;\varepsilon):=\left\{\lambda\in\mathcal M_1(M);\ \left|\int f_i\  \mathrm{d}\mu - \int f_i\  \mathrm{d}\lambda\right|<\varepsilon, \ \forall \ i\in\{1,\ldots,n\}\right\}, $$ where $f_1,\ldots,f_n \in C^0_b(M)=\{g: M\to\mathbb R; \ g \text{ is a continuous bounded function}\}$ . My question: Is there an example of a compact topological space $M$ , such that $\mathcal M_1(M)$ is not compact in the weak ${^*}$ topology? I have searched online but I was not able to find any reference for this problem. Moreover, I have tried to construct a counter-example but I have failed miserably. Can anyone help me?","It is well known that if is a compact Hausdorff topological space then (by RieszโMarkovโKakutani representation theorem + BanachโAlaoglu theorem ) we have that the space is compact in the weak topology, the topology generated by the basis of neighborhoods where . My question: Is there an example of a compact topological space , such that is not compact in the weak topology? I have searched online but I was not able to find any reference for this problem. Moreover, I have tried to construct a counter-example but I have failed miserably. Can anyone help me?","(M,\tau) \mathcal M_1(M) :=\left\{\mu;\ \mu\ \text{is a }\tau\text{-Borel probability measure on }M\right\}  ^* \textit{i.e}. V(\mu;f_1,\ldots,f_n;\varepsilon):=\left\{\lambda\in\mathcal M_1(M);\ \left|\int f_i\  \mathrm{d}\mu - \int f_i\  \mathrm{d}\lambda\right|<\varepsilon, \ \forall \ i\in\{1,\ldots,n\}\right\},  f_1,\ldots,f_n \in C^0_b(M)=\{g: M\to\mathbb R; \ g \text{ is a continuous bounded function}\} M \mathcal M_1(M) {^*}","['probability', 'functional-analysis', 'measure-theory', 'ergodic-theory']"
47,What precisely is the Friendship Paradox (and is Wikipedia wrong?),What precisely is the Friendship Paradox (and is Wikipedia wrong?),,"Friendship paradox is the somewhat well-known statement that ""statistically speaking, your friends have more friends than you do"". To my mind, which is surely ignorant of any complexities of social sciences, it seems that this should translate into the following statement: Friendship Paradox Theorem I. Let $G = (V,E)$ is an undirected graph. Then the average degree of a vertex sampled uniformly at random from the neighbourhood of a vertex sampled uniformly at random from $V$ is at least as large as the average degree of a vertex sampled uniformly at random from $V$, i.e., $$ \frac{1}{|V|} \sum_{v \in V} \frac{1}{\deg(v)} \sum_{u : uv \in E} \deg(u) \geq \frac{1}{|V|} \sum_{v \in V} \deg(v).\tag{1} $$ Hence, I was somewhat to see that Wikipedia justifies the friendship by a different inequality. Friendship Paradox Theorem II. Let $G = (V,E)$ is an undirected graph. Then the average degree of a vertex sampled by choosing a random endpoint of an edge sampled uniformly at random is at least as large as the average degree of a vertex sampled uniformly at random from $V$, i.e., $$ \frac{1}{2|E|} \sum_{v \in V} \deg(v)^2 \geq \frac{1}{|V|} \sum_{v \in V} \deg(v). \tag{2} $$ Now, both inequalities are true, and friendship paradox is an empirical observation, so there is not much of a problem. However, I would be grateful if someone could explain to me the intuitive appeal of (2) as a justification of said observation (right now, it seems to me that it's just obtained by choosing the distribution on $V$ so as to make computations easier). Of course, it could be the case that no such justification exist, in which case I would be grateful for references (and moral support) to edit the relevant Wikipedia page.","Friendship paradox is the somewhat well-known statement that ""statistically speaking, your friends have more friends than you do"". To my mind, which is surely ignorant of any complexities of social sciences, it seems that this should translate into the following statement: Friendship Paradox Theorem I. Let $G = (V,E)$ is an undirected graph. Then the average degree of a vertex sampled uniformly at random from the neighbourhood of a vertex sampled uniformly at random from $V$ is at least as large as the average degree of a vertex sampled uniformly at random from $V$, i.e., $$ \frac{1}{|V|} \sum_{v \in V} \frac{1}{\deg(v)} \sum_{u : uv \in E} \deg(u) \geq \frac{1}{|V|} \sum_{v \in V} \deg(v).\tag{1} $$ Hence, I was somewhat to see that Wikipedia justifies the friendship by a different inequality. Friendship Paradox Theorem II. Let $G = (V,E)$ is an undirected graph. Then the average degree of a vertex sampled by choosing a random endpoint of an edge sampled uniformly at random is at least as large as the average degree of a vertex sampled uniformly at random from $V$, i.e., $$ \frac{1}{2|E|} \sum_{v \in V} \deg(v)^2 \geq \frac{1}{|V|} \sum_{v \in V} \deg(v). \tag{2} $$ Now, both inequalities are true, and friendship paradox is an empirical observation, so there is not much of a problem. However, I would be grateful if someone could explain to me the intuitive appeal of (2) as a justification of said observation (right now, it seems to me that it's just obtained by choosing the distribution on $V$ so as to make computations easier). Of course, it could be the case that no such justification exist, in which case I would be grateful for references (and moral support) to edit the relevant Wikipedia page.",,"['probability', 'graph-theory', 'applications']"
48,Limit of lights in rooms,Limit of lights in rooms,,"There are $k$ rooms with $n$ lights each. Each light is on with equal probability $p$ independently of other lights. As $k$ stays fixed and $n$ goes to infinity, what is the limit of the probability that Room 1 has the maximum number of lights on (possibly sharing this maximum with other rooms)? By symmetry, this probability is clearly at least $1/k$ for any $n$. However, for fixed $n$ it is slightly larger than $1/k$ because the maximum can be equal for many rooms. Still I think the limit should be $1/k$.","There are $k$ rooms with $n$ lights each. Each light is on with equal probability $p$ independently of other lights. As $k$ stays fixed and $n$ goes to infinity, what is the limit of the probability that Room 1 has the maximum number of lights on (possibly sharing this maximum with other rooms)? By symmetry, this probability is clearly at least $1/k$ for any $n$. However, for fixed $n$ it is slightly larger than $1/k$ because the maximum can be equal for many rooms. Still I think the limit should be $1/k$.",,"['probability', 'limits']"
49,Confidence Interval of Information Entropy?,Confidence Interval of Information Entropy?,,"Information entropy, $IE$, is defined as: $$IE = \sum_{i} p_i log\frac{1}{p_i}$$ Where $p_i$ is the probability of event $i$ (and we are summing over all possible events). Let's say I have data only, and estimate $p_i$, with $\hat{p_i}$, where: $$\hat{p_i} = \frac{n_i}{N}$$ Where $n_i$ is the number of occurances of event $i$ in the data, and $N$ is the total number of observations. Then I can estimate $IE$ with $\hat{IE}$ as: $$ \hat{IE} = \sum_{i} \hat{p_i} log\frac{1}{\hat{p_i}}$$ Is there a way to analytically find, say, a 95% confidence interval on $\hat{IE}$?","Information entropy, $IE$, is defined as: $$IE = \sum_{i} p_i log\frac{1}{p_i}$$ Where $p_i$ is the probability of event $i$ (and we are summing over all possible events). Let's say I have data only, and estimate $p_i$, with $\hat{p_i}$, where: $$\hat{p_i} = \frac{n_i}{N}$$ Where $n_i$ is the number of occurances of event $i$ in the data, and $N$ is the total number of observations. Then I can estimate $IE$ with $\hat{IE}$ as: $$ \hat{IE} = \sum_{i} \hat{p_i} log\frac{1}{\hat{p_i}}$$ Is there a way to analytically find, say, a 95% confidence interval on $\hat{IE}$?",,"['probability', 'statistics', 'probability-theory', 'information-theory']"
50,"notation (ab)use for random variables, distributions, pdfs/pmfs","notation (ab)use for random variables, distributions, pdfs/pmfs",,"This question is about notation for random variables (RVs), distributions and pdfs/pmfs and their common (ab)use as I recently got confused. Let $X,Y$ denote random variables. First, notations I usually encounter. Please correct me: values a RV takes on are usually denoted by small caps so that $P(X=x) \in [0,1]$ denotes the probability of the RV $X$ taking on the value $x$ $X_1,...,X_n \sim X$ means ""let X_1,...,X_n be RV with same distribution as $X$"" (often $\overset{\text{iid}}{\sim}$) if $X$ is discrete it's pmf is usually denoted by $p(x) = p_X(x) = P(X=x) \in [0,1]$ if $X$ is non-discrete it's pdf is usually denoted by $f(x) = f_X(x) \in [0,\infty)$ or $p(x) = p_X(x)$ to easily talk about discrete and non-discrete RVs at the same time the cdf is usually written as $F(x) = F_X(x) = P(X \leq x)$ which is a sum/integral using the pdf/pmf The following notations I've usually understood in an ""intuitive"" way or assumed to just be sloppy but caused some confusion: ""Let $X$ be a RV with distribution $X \sim P(X)$"" -- What exactly is meant? Should I think of $P$-robability here or is it a symbol which reads ""this denotes/represents the distribution of $X$""? ""$p(X,Y), p(X), p(X|Y)$ denote the joint, marginal, conditional probability density functions"" -- How should I understand this? I mean, they should be functions of values the RVs can take on but here they take the RVs itself as argument? "" Let $P(x,y)$ be an (unknown) joint probability distribution on instances and labels $X ร Y$. Given a training sample ${(x_i, y_i)}_{i=1}^n \overset{\text{iid}}{\sim} P(x,y)$ ..."" -- How to read this? Could someone help me out and shed some light upon above mentioned points? Sorry, if my questions are stupid. I just feel the notation gets far more sloppy when reading applied stuff and it would help me to pin down what actually is meant or to know that one needs to relax and learn how to sloppily-correctly read this.","This question is about notation for random variables (RVs), distributions and pdfs/pmfs and their common (ab)use as I recently got confused. Let $X,Y$ denote random variables. First, notations I usually encounter. Please correct me: values a RV takes on are usually denoted by small caps so that $P(X=x) \in [0,1]$ denotes the probability of the RV $X$ taking on the value $x$ $X_1,...,X_n \sim X$ means ""let X_1,...,X_n be RV with same distribution as $X$"" (often $\overset{\text{iid}}{\sim}$) if $X$ is discrete it's pmf is usually denoted by $p(x) = p_X(x) = P(X=x) \in [0,1]$ if $X$ is non-discrete it's pdf is usually denoted by $f(x) = f_X(x) \in [0,\infty)$ or $p(x) = p_X(x)$ to easily talk about discrete and non-discrete RVs at the same time the cdf is usually written as $F(x) = F_X(x) = P(X \leq x)$ which is a sum/integral using the pdf/pmf The following notations I've usually understood in an ""intuitive"" way or assumed to just be sloppy but caused some confusion: ""Let $X$ be a RV with distribution $X \sim P(X)$"" -- What exactly is meant? Should I think of $P$-robability here or is it a symbol which reads ""this denotes/represents the distribution of $X$""? ""$p(X,Y), p(X), p(X|Y)$ denote the joint, marginal, conditional probability density functions"" -- How should I understand this? I mean, they should be functions of values the RVs can take on but here they take the RVs itself as argument? "" Let $P(x,y)$ be an (unknown) joint probability distribution on instances and labels $X ร Y$. Given a training sample ${(x_i, y_i)}_{i=1}^n \overset{\text{iid}}{\sim} P(x,y)$ ..."" -- How to read this? Could someone help me out and shed some light upon above mentioned points? Sorry, if my questions are stupid. I just feel the notation gets far more sloppy when reading applied stuff and it would help me to pin down what actually is meant or to know that one needs to relax and learn how to sloppily-correctly read this.",,"['probability', 'probability-theory', 'probability-distributions', 'notation']"
51,"If half the population were murderers, and they could only kill once, how many would survive?","If half the population were murderers, and they could only kill once, how many would survive?",,"So here's the rules: Half the population are murderers Each murderer can only kill once We assume the nobody will fight back, and only murderers can murder Murderers can kill other murderers Only one murder can be committed at a time, no simultaneous murders No suicide - This means there will be at least one surviving murderer Everybody, including murderers, has an equal chance of being killed It should be obvious, but murderers cannot kill if they've already been killed Nobody is dying of old age or giving birth - it's an infertile and immortal (but not invincible) society Murders occur every second, or whatever measure of time suits your taste Murders are instant How many people should statistically survive? What proportion of them would be murderers? How would you go about working this out?","So here's the rules: Half the population are murderers Each murderer can only kill once We assume the nobody will fight back, and only murderers can murder Murderers can kill other murderers Only one murder can be committed at a time, no simultaneous murders No suicide - This means there will be at least one surviving murderer Everybody, including murderers, has an equal chance of being killed It should be obvious, but murderers cannot kill if they've already been killed Nobody is dying of old age or giving birth - it's an infertile and immortal (but not invincible) society Murders occur every second, or whatever measure of time suits your taste Murders are instant How many people should statistically survive? What proportion of them would be murderers? How would you go about working this out?",,"['probability', 'statistics']"
52,Is Hoeffding's bound tight in any way?,Is Hoeffding's bound tight in any way?,,The inequality: $$\Pr(\overline X - \mathrm{E}[\overline X] \geq t) \leq \exp \left( - \frac{2n^2t^2}{\sum_{i=1}^n (b_i - a_i)^2} \right) $$ Is this bound (or any other form of hoeffding) tight in any sense? e.g. does there exist a distribution for which the bound is no more than a constant multiple of the true probability for every $n$?,The inequality: $$\Pr(\overline X - \mathrm{E}[\overline X] \geq t) \leq \exp \left( - \frac{2n^2t^2}{\sum_{i=1}^n (b_i - a_i)^2} \right) $$ Is this bound (or any other form of hoeffding) tight in any sense? e.g. does there exist a distribution for which the bound is no more than a constant multiple of the true probability for every $n$?,,"['probability', 'probability-theory', 'inequality', 'random-variables']"
53,To show that $P(|X-Y| \leq 2) \leq 3P(|X-Y| \leq 1)$ [duplicate],To show that  [duplicate],P(|X-Y| \leq 2) \leq 3P(|X-Y| \leq 1),"This question already has answers here : Exercise 1.6.3 from Alon & Spencer's *The Probabilistic Method*: prove that $Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1]$ for i.i.d. real RVs $X$ and $Y$ (3 answers) Closed 4 years ago . I found this question while browsing through ""The Probabilistic Method"", by Noga Elon. Let X and Y be 2 independent and identically distributed real valued random variables. Prove that: $$P(|X-Y| \leq 2) \leq 3P(|X-Y| \leq 1)$$ So I tried the following: $$P\{|X-Y| \leq 2\} = P\{|X-Y| \leq 1\} + P\{X-Y \in (1,2]\cup[-2,-1)\}$$ $$= P\{|X-Y| \leq 1\} + P\{X-Y \in (1,2]\} + P\{X-Y \in [-2,-1)\}$$ $$= P\{|X-Y| \leq 1\} + 2P\{X-Y \in (1,2]\}$$ where the last step follows because $X-Y$ has a symmetric distribution. NB: A random variable Z has symmetric distribution if  $$P(Z \leq z) = P(Z \geq -z) \quad \forall z \in \mathbb{R}$$ Thus the problem boils down to showing $$P\{X-Y \in (1,2]\} \leq P(|X-Y| \leq 1)$$ and I would be done. Unfortunately, I don't know how to proceed from here. I appreciate any help, hints, useful comments etc. I receive.","This question already has answers here : Exercise 1.6.3 from Alon & Spencer's *The Probabilistic Method*: prove that $Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1]$ for i.i.d. real RVs $X$ and $Y$ (3 answers) Closed 4 years ago . I found this question while browsing through ""The Probabilistic Method"", by Noga Elon. Let X and Y be 2 independent and identically distributed real valued random variables. Prove that: $$P(|X-Y| \leq 2) \leq 3P(|X-Y| \leq 1)$$ So I tried the following: $$P\{|X-Y| \leq 2\} = P\{|X-Y| \leq 1\} + P\{X-Y \in (1,2]\cup[-2,-1)\}$$ $$= P\{|X-Y| \leq 1\} + P\{X-Y \in (1,2]\} + P\{X-Y \in [-2,-1)\}$$ $$= P\{|X-Y| \leq 1\} + 2P\{X-Y \in (1,2]\}$$ where the last step follows because $X-Y$ has a symmetric distribution. NB: A random variable Z has symmetric distribution if  $$P(Z \leq z) = P(Z \geq -z) \quad \forall z \in \mathbb{R}$$ Thus the problem boils down to showing $$P\{X-Y \in (1,2]\} \leq P(|X-Y| \leq 1)$$ and I would be done. Unfortunately, I don't know how to proceed from here. I appreciate any help, hints, useful comments etc. I receive.",,"['probability', 'inequality']"
54,"If a stick is broken at five random points, what is the probability that the pieces can form two triangles?","If a stick is broken at five random points, what is the probability that the pieces can form two triangles?",,"It is well-known that if a stick is broken at two random points, the probability that the pieces can form a triangle is $1/4$ ( proof ). My question is: If a stick is broken at five random points, what is the probability that the pieces can form two triangles? The random points are uniformly distributed along the stick. When the stick is broken at five points, there are $\frac12 \binom63=10$ ways to divide the six pieces into two groups of three pieces. In order for two triangles to be formed, there must be at least one way in which each group has three pieces, none of which is longer than the sum of the other two pieces. I used Excel to make a simulation with $100000$ trials, and the probability seems to be about $\color{red}{0.287}$ . (EDIT: There was a small mistake in my Excel sheet earlier, which caused my approximation to be slightly off; it has been corrected.) Some other questions about broken sticks have nice closed form answers (for example here and here ), and I wonder if this one does too.","It is well-known that if a stick is broken at two random points, the probability that the pieces can form a triangle is ( proof ). My question is: If a stick is broken at five random points, what is the probability that the pieces can form two triangles? The random points are uniformly distributed along the stick. When the stick is broken at five points, there are ways to divide the six pieces into two groups of three pieces. In order for two triangles to be formed, there must be at least one way in which each group has three pieces, none of which is longer than the sum of the other two pieces. I used Excel to make a simulation with trials, and the probability seems to be about . (EDIT: There was a small mistake in my Excel sheet earlier, which caused my approximation to be slightly off; it has been corrected.) Some other questions about broken sticks have nice closed form answers (for example here and here ), and I wonder if this one does too.",1/4 \frac12 \binom63=10 100000 \color{red}{0.287},"['probability', 'geometry', 'triangles', 'geometric-probability']"
55,Asymptotic behavior of piecewise recursive random variable.,Asymptotic behavior of piecewise recursive random variable.,,"I have sequence of random variables defined by the following recursion: $$X_{n+1} = X_n+\begin{cases} \alpha(S_n - X_n), \text{ if } S_n > X_n \\ \beta(S_n - X_n), \text{ if } S_n < X_n, \end{cases}$$ where $0<\beta < \alpha <1$ are constants, $(S_n)$ are i.i.d with known distributions. Also, $S_n$ independent of $\sigma(X_1, X_2,\dots, X_n)$ and $X_ 0 = 0.$ Initially, I asked about the convergence/limiting distribution of $X_n,$ but after doing some research, I realize that it is generally considered a very difficult problem - to obtain explicit distribution/asymptotics. Therefore, I want to ask following questions with increasing orders of difficulties (according to my very limited probability theory knowledge.) 1) Can we at least prove that it has a limiting distribution? It looks like one can formulate this as a general state space Markov Chain but there do not seem to be an abundance of sources on this topic. Probability by Durrett has a brief chapter on it and he mentions that discrete Orstein- Uhlehnbeck process: $$V_{n+1} = \theta V_n+\xi_n$$ is an example of a discrete time, general state space Markov Chain. However, most of the resources I could find on the internet refers to the continuous one and as such my hope of modifying proofs for OU did not pan out. 2) If there is a limiting distribution, what kind of qualitative results can I hope to achieve? For example, one has the following for the expected value: $$\mathbb{E}[X_{n+1}] = \mathbb{E}[X_n](1 - \beta ) + \beta\mu + ( \alpha - \beta)\mathbb{E}[\delta_n\mathbb{1}_{\delta_n >0}],$$ where $\delta_n = S_n - X_n,$ and $\mu = \mathbb{E}[S_n].$ But then, the issue I am having is manipulating: $$P(S_n - X_n > t|S_n > X_n)$$ , which will come from the last term. I will greatly appreciate if anyone has some ideas or point me to a helpful source. Simulation: I attach some simulations that seem to suggest that there is a bounded, limiting distribution.","I have sequence of random variables defined by the following recursion: where are constants, are i.i.d with known distributions. Also, independent of and Initially, I asked about the convergence/limiting distribution of but after doing some research, I realize that it is generally considered a very difficult problem - to obtain explicit distribution/asymptotics. Therefore, I want to ask following questions with increasing orders of difficulties (according to my very limited probability theory knowledge.) 1) Can we at least prove that it has a limiting distribution? It looks like one can formulate this as a general state space Markov Chain but there do not seem to be an abundance of sources on this topic. Probability by Durrett has a brief chapter on it and he mentions that discrete Orstein- Uhlehnbeck process: is an example of a discrete time, general state space Markov Chain. However, most of the resources I could find on the internet refers to the continuous one and as such my hope of modifying proofs for OU did not pan out. 2) If there is a limiting distribution, what kind of qualitative results can I hope to achieve? For example, one has the following for the expected value: where and But then, the issue I am having is manipulating: , which will come from the last term. I will greatly appreciate if anyone has some ideas or point me to a helpful source. Simulation: I attach some simulations that seem to suggest that there is a bounded, limiting distribution.","X_{n+1} = X_n+\begin{cases} \alpha(S_n - X_n), \text{ if } S_n > X_n \\
\beta(S_n - X_n), \text{ if } S_n < X_n,
\end{cases} 0<\beta < \alpha <1 (S_n) S_n \sigma(X_1, X_2,\dots, X_n) X_ 0 = 0. X_n, V_{n+1} = \theta V_n+\xi_n \mathbb{E}[X_{n+1}] = \mathbb{E}[X_n](1 - \beta ) + \beta\mu + ( \alpha - \beta)\mathbb{E}[\delta_n\mathbb{1}_{\delta_n >0}], \delta_n = S_n - X_n, \mu = \mathbb{E}[S_n]. P(S_n - X_n > t|S_n > X_n)","['probability', 'stochastic-processes', 'markov-chains', 'conditional-expectation', 'martingales']"
56,Sacred Geometry of Chance,Sacred Geometry of Chance,,"This problem is dedicated to Leon the professional . This question came to my mind when I was contemplating on the numbers 1-20 arranged interestingly around a regular dartboard: QUESTION: Can we divide a circle with radius of $\sqrt{3}\sigma$ on a plain into 3 optimal pieces with equal areas assigned by $1,2,3$ as score ,which an ambitious dart player with density probability function of $f(r;\sigma )={\frac {r}{\sigma^{2}}}e^{-r^{2}/(2\sigma ^{2})}$ (Rayleigh distribution) as probability of dart hitting in distance of $r$ from his aim point, achieves least score from the designed dartboard plane in his throw (guaranty getting minimum equal score from each point on the board he may aim to shoot)? Are the shapes of these pieces unique? what are they look like? Note1: if dart goes out of the board player will get $0$ score. $\sigma$ is standard deviation in Rayleigh distribution and dart hits in circle of radius $\sigma$ around player's aim point by probability of about $0.39$ . Note2: At first I proposed a generalized form of this problem stating to find $n$ connected regions on a plane which they totally shape a connected closed board without any hole, assigned by $n$ natural numbers as score and the goal was to find optimal shape of each number ,But I found this simpler state of the problem as hard as enough to contemplate. ---Another Generalization can be considered: Setting a desired predefined probability score function over the dartboard plane domain(a function that you give a point of dartboard to it as input and it gives you the probable score achieves by a player who aim to hit that point as the output) and the challenge is to design a dartboard which gives us that predefined function as score probability in each point, like to design a deceiving dartboard which the score probability be least for points of region assigned by score $3$ and be highest for points of region assigned by score $1$ . for easing the problem I have considered a constant probability score function with minimum value, which still finding its minimum value is challenging. Note3: there can be other variants and generalizations of this problem which are more applied and even I think they maybe discussed earlier but it is great to discuss here too, for example in a combinatorics way a question arises where there are quantitative numbers of valuable sources in each country and a comet threaten the planet Earth with the same hitting probability for each of its points, the question here is how to divide these sources among different countries which we loose least number of sources when the comet hits (all of the sources become inaccessible in the whole country which has been hit). However I hope this does not happen until we become advance enough in technology and facilities to eliminate such kind of threats by solving such these problems and also we human being be wise and united enough to use and benefit solutions in order to truly share our valuable sources. Ultimate Note: the song ""shape of my heart"" from the film leon the professional performed by Sting, which I like a lot, have also a very nice lyric. it says: ... He deals the cards to find the answer The sacred geometry of chance The hidden law of a probable outcome The numbers lead a dance ... I am listening and singing the song while I'm still thinking about the problem: Is this life designed by God in a way which its ""sacred geometry of chance"" ,""the hidden law of its probable outcome"",shapes our fate? what are the shapes look like? would it be shape of my heart?...","This problem is dedicated to Leon the professional . This question came to my mind when I was contemplating on the numbers 1-20 arranged interestingly around a regular dartboard: QUESTION: Can we divide a circle with radius of on a plain into 3 optimal pieces with equal areas assigned by as score ,which an ambitious dart player with density probability function of (Rayleigh distribution) as probability of dart hitting in distance of from his aim point, achieves least score from the designed dartboard plane in his throw (guaranty getting minimum equal score from each point on the board he may aim to shoot)? Are the shapes of these pieces unique? what are they look like? Note1: if dart goes out of the board player will get score. is standard deviation in Rayleigh distribution and dart hits in circle of radius around player's aim point by probability of about . Note2: At first I proposed a generalized form of this problem stating to find connected regions on a plane which they totally shape a connected closed board without any hole, assigned by natural numbers as score and the goal was to find optimal shape of each number ,But I found this simpler state of the problem as hard as enough to contemplate. ---Another Generalization can be considered: Setting a desired predefined probability score function over the dartboard plane domain(a function that you give a point of dartboard to it as input and it gives you the probable score achieves by a player who aim to hit that point as the output) and the challenge is to design a dartboard which gives us that predefined function as score probability in each point, like to design a deceiving dartboard which the score probability be least for points of region assigned by score and be highest for points of region assigned by score . for easing the problem I have considered a constant probability score function with minimum value, which still finding its minimum value is challenging. Note3: there can be other variants and generalizations of this problem which are more applied and even I think they maybe discussed earlier but it is great to discuss here too, for example in a combinatorics way a question arises where there are quantitative numbers of valuable sources in each country and a comet threaten the planet Earth with the same hitting probability for each of its points, the question here is how to divide these sources among different countries which we loose least number of sources when the comet hits (all of the sources become inaccessible in the whole country which has been hit). However I hope this does not happen until we become advance enough in technology and facilities to eliminate such kind of threats by solving such these problems and also we human being be wise and united enough to use and benefit solutions in order to truly share our valuable sources. Ultimate Note: the song ""shape of my heart"" from the film leon the professional performed by Sting, which I like a lot, have also a very nice lyric. it says: ... He deals the cards to find the answer The sacred geometry of chance The hidden law of a probable outcome The numbers lead a dance ... I am listening and singing the song while I'm still thinking about the problem: Is this life designed by God in a way which its ""sacred geometry of chance"" ,""the hidden law of its probable outcome"",shapes our fate? what are the shapes look like? would it be shape of my heart?...","\sqrt{3}\sigma 1,2,3 f(r;\sigma )={\frac {r}{\sigma^{2}}}e^{-r^{2}/(2\sigma ^{2})} r 0 \sigma \sigma 0.39 n n 3 1","['probability', 'geometry', 'optimization']"
57,Understanding proof of convergence,Understanding proof of convergence,,"I'm going through section 6.1 in this paper for the proof of Theorem 2.1. However, I can't seem to get the result, which I will explain below. Setup Let $T_i$, $1\leq i\leq m$ be independent Student's $t$ test statistics which are constructed as  $$ T_i=\frac{\bar{X}_i}{\hat{s}_{ni}/\sqrt{n}} $$ where  $$ \bar{X}_i=\frac{1}{n}\sum_{k=1}^n X_{ki},\hspace{5mm}\hat{s}^2_{ni}=\frac{1}{n-1}\sum_{k=1}^n (X_{ki}-\bar{X}_i)^2 $$ and $X_{ki}\stackrel{iid}{\sim} \mathcal{N}(\mu_i,\sigma_i^2)$, $1\leq k\leq n$, $1\leq i\leq m$. Problem Assumptions Suppose $\log m=o(n^{1/2})$. Assume that $\max_{1\leq i\leq m}EY_i^4\leq b_0$ for some constant $b_0>0$ and   \begin{equation} \text{Card}\left\{i: |\mu_i/\sigma_i|\geq 4\sqrt{\log m/n}  \right\}\to\infty \end{equation} Further suppose that for $0\leq t\leq o(n^{1/4})$,    \begin{equation} P(|T_i-\sqrt{n}\mu_i/\hat{s}_{ni}|\geq t)=\frac{1}{2}G(t)\left[\exp\left( -\frac{t^3}{3\sqrt{n}}\kappa_i\right)+\exp\left(\frac{t^3}{3\sqrt{n}}\kappa_i \right) \right](1+o(1)) \end{equation}   where $o(1)$ is uniform in $1\leq i\leq m$, $G(t)=2-2\Phi(t)$, $\Phi(t)$ is the normal cdf, and $\kappa_i=EY_i^3$. Finally, let $\mathcal{M}\subset\{1,2,\dots,m\}$ satisfying $\mathcal{M}\subset\{i:|\mu_i/\sigma_i|\geq 4\sqrt{\log m/n}\}$ and $\text{Card}(\mathcal{M})\leq\sqrt{n}$. Also for any $\epsilon>0$,   $$ P(\max_{i\in\mathcal{M}}|\hat{s}^2_{ni}/\sigma_i^2-1|\geq \epsilon)=O(1/\sqrt{n}) $$ Question I want to show equation (15) in section 6.1 which says that for some $c>\sqrt{2}$ and some $b_m\to \infty$ (the subscript means that the constant depends on $m$),    $$ P\left(\sum_{i=1}^m I\{|T_i|\geq c\sqrt{\log m} \}\geq b_{m} \right)\to 1 $$ I believe the idea is to split up the quantity for $i\in\mathcal{M}$ and $i\not\in\mathcal{M}$ and use the fact that  $$ P\left(\sum_{i\in\mathcal{M}} I\{|T_i|\geq c\sqrt{\log m} \}\geq b_{m} \right)\leq P\left(\sum_{i=1}^m I\{|T_i|\geq c\sqrt{\log m} \}\geq b_{m} \right) $$ Then if I show that the LHS goes to 1, I have the claim. However, I can't seem to get the inequalities needed to get the convergence to 1. Any hints or insights? What I have so far \begin{eqnarray} P\left(\sum_{i\in\mathcal{M}} I\{|T_i|> c\sqrt{\log m} \}\geq b_m\right) &=& 1- P\left( \sum_{i\in\mathcal{M}} I\{|T_i|> c\sqrt{\log m} \}< b_m \right)\\ &\geq& 1-P\left( \sup_{i\in\mathcal{M}} I\{|T_i|> c\sqrt{\log m} \}< b_m/\text{Card}(\mathcal{M}) \right)\\ &\geq&  1- \sum_{i\in\mathcal{M}} P\left(I\{|T_i|> c\sqrt{\log m} \}< b_m/\text{Card}(\mathcal{M}) \right)\\ &\geq&  1- \sum_{i\in\mathcal{M}} [1-P\left(I\{|T_i|> c\sqrt{\log m} \}\geq b_m/\sqrt{n} \right)]\\ \end{eqnarray} Now it suffices to show that $P\left(I\{|T_i|> c\sqrt{\log m} \}\geq b_m/\sqrt{n}\right)\to 1$, which I'm having trouble showing.","I'm going through section 6.1 in this paper for the proof of Theorem 2.1. However, I can't seem to get the result, which I will explain below. Setup Let $T_i$, $1\leq i\leq m$ be independent Student's $t$ test statistics which are constructed as  $$ T_i=\frac{\bar{X}_i}{\hat{s}_{ni}/\sqrt{n}} $$ where  $$ \bar{X}_i=\frac{1}{n}\sum_{k=1}^n X_{ki},\hspace{5mm}\hat{s}^2_{ni}=\frac{1}{n-1}\sum_{k=1}^n (X_{ki}-\bar{X}_i)^2 $$ and $X_{ki}\stackrel{iid}{\sim} \mathcal{N}(\mu_i,\sigma_i^2)$, $1\leq k\leq n$, $1\leq i\leq m$. Problem Assumptions Suppose $\log m=o(n^{1/2})$. Assume that $\max_{1\leq i\leq m}EY_i^4\leq b_0$ for some constant $b_0>0$ and   \begin{equation} \text{Card}\left\{i: |\mu_i/\sigma_i|\geq 4\sqrt{\log m/n}  \right\}\to\infty \end{equation} Further suppose that for $0\leq t\leq o(n^{1/4})$,    \begin{equation} P(|T_i-\sqrt{n}\mu_i/\hat{s}_{ni}|\geq t)=\frac{1}{2}G(t)\left[\exp\left( -\frac{t^3}{3\sqrt{n}}\kappa_i\right)+\exp\left(\frac{t^3}{3\sqrt{n}}\kappa_i \right) \right](1+o(1)) \end{equation}   where $o(1)$ is uniform in $1\leq i\leq m$, $G(t)=2-2\Phi(t)$, $\Phi(t)$ is the normal cdf, and $\kappa_i=EY_i^3$. Finally, let $\mathcal{M}\subset\{1,2,\dots,m\}$ satisfying $\mathcal{M}\subset\{i:|\mu_i/\sigma_i|\geq 4\sqrt{\log m/n}\}$ and $\text{Card}(\mathcal{M})\leq\sqrt{n}$. Also for any $\epsilon>0$,   $$ P(\max_{i\in\mathcal{M}}|\hat{s}^2_{ni}/\sigma_i^2-1|\geq \epsilon)=O(1/\sqrt{n}) $$ Question I want to show equation (15) in section 6.1 which says that for some $c>\sqrt{2}$ and some $b_m\to \infty$ (the subscript means that the constant depends on $m$),    $$ P\left(\sum_{i=1}^m I\{|T_i|\geq c\sqrt{\log m} \}\geq b_{m} \right)\to 1 $$ I believe the idea is to split up the quantity for $i\in\mathcal{M}$ and $i\not\in\mathcal{M}$ and use the fact that  $$ P\left(\sum_{i\in\mathcal{M}} I\{|T_i|\geq c\sqrt{\log m} \}\geq b_{m} \right)\leq P\left(\sum_{i=1}^m I\{|T_i|\geq c\sqrt{\log m} \}\geq b_{m} \right) $$ Then if I show that the LHS goes to 1, I have the claim. However, I can't seem to get the inequalities needed to get the convergence to 1. Any hints or insights? What I have so far \begin{eqnarray} P\left(\sum_{i\in\mathcal{M}} I\{|T_i|> c\sqrt{\log m} \}\geq b_m\right) &=& 1- P\left( \sum_{i\in\mathcal{M}} I\{|T_i|> c\sqrt{\log m} \}< b_m \right)\\ &\geq& 1-P\left( \sup_{i\in\mathcal{M}} I\{|T_i|> c\sqrt{\log m} \}< b_m/\text{Card}(\mathcal{M}) \right)\\ &\geq&  1- \sum_{i\in\mathcal{M}} P\left(I\{|T_i|> c\sqrt{\log m} \}< b_m/\text{Card}(\mathcal{M}) \right)\\ &\geq&  1- \sum_{i\in\mathcal{M}} [1-P\left(I\{|T_i|> c\sqrt{\log m} \}\geq b_m/\sqrt{n} \right)]\\ \end{eqnarray} Now it suffices to show that $P\left(I\{|T_i|> c\sqrt{\log m} \}\geq b_m/\sqrt{n}\right)\to 1$, which I'm having trouble showing.",,"['probability', 'probability-theory', 'statistics']"
58,"Should I join a group, or stay an individual?","Should I join a group, or stay an individual?",,"I have just taken part in a draw and it has left me wondering whether I made the right decision to enter the draw as an individual or whether I should have entered as a group, and if so, what size group would have been optimal. For this draw my partner and I signed up as individuals. Neither of us wanted to deprive the other of a place if we didn't get in, but since I got a place and she didn't, and I now know the mechanics of the draw, I'm prompted to question our choices. The set up is as follows. A game has 30 places for male players and 30 places for female players. โ 100 players have signed up for the game (half male and half female โ ), so not everyone can play. Players can either register as individuals, or register in a group, such as a couple, family or fraternity of friends. No-one can register more than once. Individuals are assigned a single draw number. If an individual is selected before all places for their gender are filled they get in the game, otherwise they are placed on a wait list. Groups are also assigned a single draw number. If a group is selected before all places required for that group are taken they all get in the game, otherwise they are all placed on a wait list. For example, let's say the distribution is as follows: 35 Male 35 Female 11 couples (FM) 2 fraternities of four (MFFM) This means that there are 83 draw numbers, but each draw could allocate 1, two or 4 places, or add that number of players to the wait list. As an individual, do I have the same chance of getting a place as I would if I were registered as a couple? What about if I registered as part of a larger group? Looking at this naively, I would assume that since there are 30 places for 50 players of each gender, both my partner and I would have a 60% chance of getting a place, a 36% chance that both of us would get a place and a 16% chance that neither of us would get a place. Even more naively I assumed that if we registered as a couple, we would still have a 60% chance of getting a place, and thus 40% chance of not getting a place, but is that true? โ This is a simplification, the actual draw also had a small number of gender neutral players and places.","I have just taken part in a draw and it has left me wondering whether I made the right decision to enter the draw as an individual or whether I should have entered as a group, and if so, what size group would have been optimal. For this draw my partner and I signed up as individuals. Neither of us wanted to deprive the other of a place if we didn't get in, but since I got a place and she didn't, and I now know the mechanics of the draw, I'm prompted to question our choices. The set up is as follows. A game has 30 places for male players and 30 places for female players. โ 100 players have signed up for the game (half male and half female โ ), so not everyone can play. Players can either register as individuals, or register in a group, such as a couple, family or fraternity of friends. No-one can register more than once. Individuals are assigned a single draw number. If an individual is selected before all places for their gender are filled they get in the game, otherwise they are placed on a wait list. Groups are also assigned a single draw number. If a group is selected before all places required for that group are taken they all get in the game, otherwise they are all placed on a wait list. For example, let's say the distribution is as follows: 35 Male 35 Female 11 couples (FM) 2 fraternities of four (MFFM) This means that there are 83 draw numbers, but each draw could allocate 1, two or 4 places, or add that number of players to the wait list. As an individual, do I have the same chance of getting a place as I would if I were registered as a couple? What about if I registered as part of a larger group? Looking at this naively, I would assume that since there are 30 places for 50 players of each gender, both my partner and I would have a 60% chance of getting a place, a 36% chance that both of us would get a place and a 16% chance that neither of us would get a place. Even more naively I assumed that if we registered as a couple, we would still have a 60% chance of getting a place, and thus 40% chance of not getting a place, but is that true? โ This is a simplification, the actual draw also had a small number of gender neutral players and places.",,['probability']
59,Probability of three events occurring given correlation?,Probability of three events occurring given correlation?,,"I am facing a problem that I cannot find the answer to. I have three variables, A, B and C. There are only two possibilities for each of these, A either happens or it does not, B happens or it does not and C happens or it does not. I know that if these events are independent that the probability of them all occurring is simply $P(A)\cdot P(B)\cdot P(C)$. So if the probability of each happening is 10% then all three have a $10\%ยท10\%ยท10\% = 0.1\%$ probability of occurring. But how would this formula change if the events were not independent but were instead positively correlated. I can solve this for just two variables with the formula: $P(A \cap B) = P(A)\cdot P(B) + \rho_{AB}\cdot \sqrt{P(A)\cdot (1-P(A))\cdot P(B)\cdot (1-P(B))} $, where $\rho_{AB}$ is the correlation coefficient between A and B. How would I change this formula to calculate the probability that A, B and C all occur? I.e. calculating $P(A \cap B \cap C)$ knowing $P(A)$, $P(B)$, $P(C)$, $\rho_{AB}$, $\rho_{AC}$, $\rho_{BC}$. Thanks in advance for the help!","I am facing a problem that I cannot find the answer to. I have three variables, A, B and C. There are only two possibilities for each of these, A either happens or it does not, B happens or it does not and C happens or it does not. I know that if these events are independent that the probability of them all occurring is simply $P(A)\cdot P(B)\cdot P(C)$. So if the probability of each happening is 10% then all three have a $10\%ยท10\%ยท10\% = 0.1\%$ probability of occurring. But how would this formula change if the events were not independent but were instead positively correlated. I can solve this for just two variables with the formula: $P(A \cap B) = P(A)\cdot P(B) + \rho_{AB}\cdot \sqrt{P(A)\cdot (1-P(A))\cdot P(B)\cdot (1-P(B))} $, where $\rho_{AB}$ is the correlation coefficient between A and B. How would I change this formula to calculate the probability that A, B and C all occur? I.e. calculating $P(A \cap B \cap C)$ knowing $P(A)$, $P(B)$, $P(C)$, $\rho_{AB}$, $\rho_{AC}$, $\rho_{BC}$. Thanks in advance for the help!",,"['probability', 'correlation']"
60,Two-sided hitting time of Brownian motion,Two-sided hitting time of Brownian motion,,"I am trying to compute the hitting time of a linear Brownian motion on a two-sided boundary. More specifically, let $W_t$ be a (one-dimensional) Wiener process. Let $T = \inf \{t: |W_t| = a \}$ for some $ a > 0$. I want to find $\mathbb{P}\{ T > t\}$. I know that probability distribution hitting time of a positive level, $\inf \, \{t: W_t = b\,, \  b > 0 \}$ can be computed quite easily, but I am not sure how to deal with it when dealing with the two-sided hitting time, i.e. with the absolute value. I am thinking of the minimum of hitting times of level $a$ and $-a$, but I can't get a promising conclusion.","I am trying to compute the hitting time of a linear Brownian motion on a two-sided boundary. More specifically, let $W_t$ be a (one-dimensional) Wiener process. Let $T = \inf \{t: |W_t| = a \}$ for some $ a > 0$. I want to find $\mathbb{P}\{ T > t\}$. I know that probability distribution hitting time of a positive level, $\inf \, \{t: W_t = b\,, \  b > 0 \}$ can be computed quite easily, but I am not sure how to deal with it when dealing with the two-sided hitting time, i.e. with the absolute value. I am thinking of the minimum of hitting times of level $a$ and $-a$, but I can't get a promising conclusion.",,"['probability', 'stochastic-processes']"
61,"Given n ranging from $1$ to $100$, find sum of digits equal to half of arithmetic sum of $1$ to $100$","Given n ranging from  to , find sum of digits equal to half of arithmetic sum of  to",1 100 1 100,"I have a number sequence from $1$ to $100$. Given $2$ bins, the numbers are randomly assigned to each bin. I know the total sum from $1$ to $100$ is $5050$. Thus, for both bins to have the same sum, each bin must sum up to $2525$. All the $100$ numbers must belong to either bin. I know there are a total of $2^{100}$ possible combinations. How do I find the number of combinations that sum to $2525$ in each bin? Thank you. EDIT: Just to clarify, a bin is just a collection of numbers. So essentially, I have collection $A$ and collection $B$. The sum in each collection must be equal and all $100$ numbers must belong to either collection. Think of them as buckets or whatever is convenient for explanation.","I have a number sequence from $1$ to $100$. Given $2$ bins, the numbers are randomly assigned to each bin. I know the total sum from $1$ to $100$ is $5050$. Thus, for both bins to have the same sum, each bin must sum up to $2525$. All the $100$ numbers must belong to either bin. I know there are a total of $2^{100}$ possible combinations. How do I find the number of combinations that sum to $2525$ in each bin? Thank you. EDIT: Just to clarify, a bin is just a collection of numbers. So essentially, I have collection $A$ and collection $B$. The sum in each collection must be equal and all $100$ numbers must belong to either collection. Think of them as buckets or whatever is convenient for explanation.",,['probability']
62,linearity of expectation in case of dependent events,linearity of expectation in case of dependent events,,"I could understand the linearity of expectation in case of independent events, but why does it work in case of dependent events too. It seems counter - intuitive. In case of dependent events, each outcome influences subsequent outcomes, hence they cannot be just summed up to get expectation without taking care of this inter dependence. Can anybody give an intuitive representation of why linearity works even in case of dependent events.","I could understand the linearity of expectation in case of independent events, but why does it work in case of dependent events too. It seems counter - intuitive. In case of dependent events, each outcome influences subsequent outcomes, hence they cannot be just summed up to get expectation without taking care of this inter dependence. Can anybody give an intuitive representation of why linearity works even in case of dependent events.",,"['probability', 'expectation']"
63,"Prove $\frac{Card\{X_1,\cdots,X_n\}}{\sqrt{n}}\rightarrow0$ in probability with i.i.d. $X_i\in\mathbb{N}, \ \mathbb{E}[X_1] < \infty$",Prove  in probability with i.i.d.,"\frac{Card\{X_1,\cdots,X_n\}}{\sqrt{n}}\rightarrow0 X_i\in\mathbb{N}, \ \mathbb{E}[X_1] < \infty","Let $\{X_n\}$ be a sequence of independent, identically distributed random variables taking values in $\mathbb{N}$ , the set of positive integers. Define $$R_n=Card\{X_1,\cdots,X_n\}$$ i.e., $R_n$ is the number of distinct integers in $\{X_1,\cdots,X_n\}$ . Suppose that $\mathbb{E}[X_1] < \infty$ . Prove that $\frac{R_n}{\sqrt{n}}\rightarrow0$ in probability. $$$$ I suppose that the $\mathbb{E}[X_1] < \infty$ condition is used in law of large numbers, but the answer seems not corresponding, for the $\frac{R_n}{\sqrt{n}}$ it looks like CLE, but the answer is $0$ other than normal distribution. So what could possibly be the way of approaching this problem? Thanks! Edit: I've a possible idea of approaching, assume that $\mathbb{E}[X_1]=T>0$ , then for any $\epsilon>0$ we have $\mathbb{P}[X_1\ge\epsilon\sqrt{n}]\le\frac{T}{\epsilon\sqrt{n}}$ , hence we have (in intuition, approximately) $Card\{X_1,\cdots,X_n\}\le\epsilon\sqrt{n}+\frac{T}{\epsilon\sqrt{n}}\cdot n=\sqrt{n}(\epsilon+\frac{T}{\epsilon})$ (we pick all integers $\le\epsilon\sqrt n$ ,and $X_i$ cannot be too large), so $\frac{R_n}{\sqrt{n}}$ definitely have an upper-bound $2T$ , a more accurate estimation can bound this upper-bound to $T$ , and I think this idea is not far from the solution. The problem is, how to reduce this upper-bound to $0$ ?","Let be a sequence of independent, identically distributed random variables taking values in , the set of positive integers. Define i.e., is the number of distinct integers in . Suppose that . Prove that in probability. I suppose that the condition is used in law of large numbers, but the answer seems not corresponding, for the it looks like CLE, but the answer is other than normal distribution. So what could possibly be the way of approaching this problem? Thanks! Edit: I've a possible idea of approaching, assume that , then for any we have , hence we have (in intuition, approximately) (we pick all integers ,and cannot be too large), so definitely have an upper-bound , a more accurate estimation can bound this upper-bound to , and I think this idea is not far from the solution. The problem is, how to reduce this upper-bound to ?","\{X_n\} \mathbb{N} R_n=Card\{X_1,\cdots,X_n\} R_n \{X_1,\cdots,X_n\} \mathbb{E}[X_1] < \infty \frac{R_n}{\sqrt{n}}\rightarrow0  \mathbb{E}[X_1] < \infty \frac{R_n}{\sqrt{n}} 0 \mathbb{E}[X_1]=T>0 \epsilon>0 \mathbb{P}[X_1\ge\epsilon\sqrt{n}]\le\frac{T}{\epsilon\sqrt{n}} Card\{X_1,\cdots,X_n\}\le\epsilon\sqrt{n}+\frac{T}{\epsilon\sqrt{n}}\cdot n=\sqrt{n}(\epsilon+\frac{T}{\epsilon}) \le\epsilon\sqrt n X_i \frac{R_n}{\sqrt{n}} 2T T 0","['probability', 'probability-theory', 'analysis', 'probability-distributions']"
64,Hard Question in Stochastic processes - variance Martingales,Hard Question in Stochastic processes - variance Martingales,,"I got some hard challenge to solve and I am looking for a small clue/help. My question goes like this: 10 Englishmen are trying to leave a pub in a rainy weather. They   do it in the following way. Initially they store all 10 umbrellas in a basket next to the exit from the pub. They enter and drink a pint each. Then they return to the basket and each one picks an umbrella at random (random permutation). Those who picked their own umbrellas leave upset, while those who did pick a wrong umbrella, put it back and return to the pub for another pint of ale. After that they return to the basket and try once again. And so on. Let $T$ be the number of rounds needed for all Englishmen to leave, and let $N$ be the total number of ales consumed during the procedure. (a) Compute $E(T)$. (b) Compute $E(N)$. Hint: For $n = 0, 1, 2, \dots$, set $X_n$ to be the number of Englishmen in the pub after $n$-th round, and consider $M_n = (X_n + n) 1_{\{n<T\}}.$  To solve (b) think about variance martingales. Any hint? Also, What are variance martingales and how they help here? Thanks a lot.","I got some hard challenge to solve and I am looking for a small clue/help. My question goes like this: 10 Englishmen are trying to leave a pub in a rainy weather. They   do it in the following way. Initially they store all 10 umbrellas in a basket next to the exit from the pub. They enter and drink a pint each. Then they return to the basket and each one picks an umbrella at random (random permutation). Those who picked their own umbrellas leave upset, while those who did pick a wrong umbrella, put it back and return to the pub for another pint of ale. After that they return to the basket and try once again. And so on. Let $T$ be the number of rounds needed for all Englishmen to leave, and let $N$ be the total number of ales consumed during the procedure. (a) Compute $E(T)$. (b) Compute $E(N)$. Hint: For $n = 0, 1, 2, \dots$, set $X_n$ to be the number of Englishmen in the pub after $n$-th round, and consider $M_n = (X_n + n) 1_{\{n<T\}}.$  To solve (b) think about variance martingales. Any hint? Also, What are variance martingales and how they help here? Thanks a lot.",,"['probability', 'stochastic-processes', 'martingales']"
65,The theory in probability,The theory in probability,,"Consider a real-life experiment (perhaps written as a problem in a textbook): A coin is continually tossed until two consecutive heads are observed. Assume that the results of the tosses are mutually independent and the coin is fair. What is the expected number of tosses before the experiment ends? Now, how would one solve this problem? First, we would need to define a probability space to model the experiment. The issue is that there are so many possibilities: We could define the sample space to be an uncountable set of all infinite-length strings of $H$ and $T$. This sample space already does not seem to fulfill the experiment's condition: that it terminates once two consecutive heads are observed. E.g. $HHTTTTT...$ and $HHHHHHH...$ are different outcomes in the sample space but are actually considered the same in the experiment (since we terminate after two heads). So to say that a sample space consists of all possible distinct outcomes of an experiment seem wrong to me. And yet, according to many sources, this is a natural space to use. Also, there can be infinitely many $\sigma$-algebras so there's the question of which one to use too. Lastly for the probability measure we can use the assumption that the coin is fair and the results of the tosses are independent so $P(\text{outcome starts with }TH) = P(\text{first toss is }T)P(\text{second toss is }H) = 0.25$, for example. We could take outcomes of the experiment to be the entire string of heads and tails from the start until termination of the experiment. So our sample space has all finite-length strings of $T$ and $H$ ending with $HH$, as well as infinite length strings that do not contain $HH$ as a substring. This space is uncountable, so again there are infinitely many $\sigma$-algebras. Now how do we define a probability measure? We should have $P(\text{outcome starts with }HHH) = P(\text{first toss is }H)P(\text{second toss is }H)P(\text{third toss is }H) = 0.125$ since the coins are fair and independent, but there are no outcomes starting with $HHH$ in this sample space, so this probability should actually be $0$. So my guess is that, instead we assume that $P(\text{$k$-th toss is heads | outcome starts with $s$}) = 0.5$, where $s$ is any $(k-1)$-length string containing no $HH$. Now this is stated nowhere in the given problem, and yet is very intuitive in the conventional sense of ""independence"" in the real world. Is this correct? We could only take the finite-length strings of $T$ and $H$ that end with $HH$, and ignore the infinite length strings. Now the question is: how do we know this is indeed the set of all outcomes? How do we know this is a valid assumption? Of course this simplifies a lot of things since the space is now discrete. We could even take the last 4 (or less) coin flips of finite runs as well as infinite runs as the sample space, so $$\Omega = \{HH, THH, \text{ends with }TTHH, \text{ends with }HTHH\}\cup \{s : s\text{ is an infinite string of $H$ and $T$}\}.$$ Now independence is defined only in the context of a probability space. So in this space we have $$\begin{eqnarray*}P(HH) &=& P(\text{last toss is }H \cap \text{2nd last toss is }H) \\&=& P(\text{last toss is }H)P(\text{2nd last toss is }H) \\&=& 0.25\\ P(THH) &=& 0.125\\ P(\text{ends with }TTHH) = P(\text{ends with }HTHH) &=& 0.0625.\end{eqnarray*}$$ So $P(\text{infinite string of $H$ and $T$}) = 1 - 0.25 - 0.125 - 0.0625 - 0.0625 = 0.5$. But clearly this does not conform to the above 3 models. So can we use this as a probability space? What is the issue here? Intuitively I can see how the probability spaces 1 to 3 all compute the same expectation. There are also countless other spaces that do too. The question is, is it possible to rigorize all this? It seems that each space above has some problems with it that raises the question of whether it is appropriate. Am I right to say that this portion relies completely on intuition and cannot possibly be rigorized? That is, the theory and mathematical rigor only starts after we have defined the probability space. Of course, then the question comes: how do we know our probability space ""works"" aside from intuition? Can we know that two different probability spaces will give us the same answer to a question? Also, am I right that there are actually way more assumptions in probability aside from the probability space? For instance: Independence in mathematical context is just $P(A \cap B) = P(A)P(B)$ but in real life we say that this means occurrence of $A$ does not affect probability of $B$ -- is this an assumption? $P(A | B) = P(A \cap B)/P(B)$ but in real life, we say $P(A | B)$ is the chance that $A$ occurs, given that $B$ has happened -- is this an assumption? The expected value of random variable $X$ is just defined as $E(X) = \sum_{\omega\in\Omega}P(\omega)X(\omega)$ in discrete spaces but in real life, we say it is the mean of $X$ if the experiment is repeated many many times -- is this an assumption? So all in all, there seems to be many assumptions in probability. So when does the theory start and end? EDIT: I've read a bit more about this issue and found that the reason why probability spaces give the same answer is likely due to them being extensions of each other. Terence Tao wrote about this once and if I'm not mistaken, the extension he talks about essentially shows the equivalence of the first 3 probability spaces I mentioned. Is this correct? According to this, independence should then be preserved under extension, so it doesn't make sense that independence ($P(A \cap B) = P(A)P(B)$) doesn't work under probability space 2 but works under 1. What I'm thinking might be the resolution is that when we state that ""the results of some coin tosses are mutually independent"", we are assuming that every single one of these independent coin tosses are performed in every single outcome . So in probability space 2, even though an outcome string might be of finite length, we assume that the other infinitely many coin tosses have also been performed (although their results are irrelevant for this outcome). Is this way of thinking correct? But now it seems strange that $P(\text{the $100$-th coin is heads}) = 0.5$, since after all the $100$-th coin is only tossed in the event that the $99$ coins before it do not contain consecutive heads. What is wrong here?","Consider a real-life experiment (perhaps written as a problem in a textbook): A coin is continually tossed until two consecutive heads are observed. Assume that the results of the tosses are mutually independent and the coin is fair. What is the expected number of tosses before the experiment ends? Now, how would one solve this problem? First, we would need to define a probability space to model the experiment. The issue is that there are so many possibilities: We could define the sample space to be an uncountable set of all infinite-length strings of $H$ and $T$. This sample space already does not seem to fulfill the experiment's condition: that it terminates once two consecutive heads are observed. E.g. $HHTTTTT...$ and $HHHHHHH...$ are different outcomes in the sample space but are actually considered the same in the experiment (since we terminate after two heads). So to say that a sample space consists of all possible distinct outcomes of an experiment seem wrong to me. And yet, according to many sources, this is a natural space to use. Also, there can be infinitely many $\sigma$-algebras so there's the question of which one to use too. Lastly for the probability measure we can use the assumption that the coin is fair and the results of the tosses are independent so $P(\text{outcome starts with }TH) = P(\text{first toss is }T)P(\text{second toss is }H) = 0.25$, for example. We could take outcomes of the experiment to be the entire string of heads and tails from the start until termination of the experiment. So our sample space has all finite-length strings of $T$ and $H$ ending with $HH$, as well as infinite length strings that do not contain $HH$ as a substring. This space is uncountable, so again there are infinitely many $\sigma$-algebras. Now how do we define a probability measure? We should have $P(\text{outcome starts with }HHH) = P(\text{first toss is }H)P(\text{second toss is }H)P(\text{third toss is }H) = 0.125$ since the coins are fair and independent, but there are no outcomes starting with $HHH$ in this sample space, so this probability should actually be $0$. So my guess is that, instead we assume that $P(\text{$k$-th toss is heads | outcome starts with $s$}) = 0.5$, where $s$ is any $(k-1)$-length string containing no $HH$. Now this is stated nowhere in the given problem, and yet is very intuitive in the conventional sense of ""independence"" in the real world. Is this correct? We could only take the finite-length strings of $T$ and $H$ that end with $HH$, and ignore the infinite length strings. Now the question is: how do we know this is indeed the set of all outcomes? How do we know this is a valid assumption? Of course this simplifies a lot of things since the space is now discrete. We could even take the last 4 (or less) coin flips of finite runs as well as infinite runs as the sample space, so $$\Omega = \{HH, THH, \text{ends with }TTHH, \text{ends with }HTHH\}\cup \{s : s\text{ is an infinite string of $H$ and $T$}\}.$$ Now independence is defined only in the context of a probability space. So in this space we have $$\begin{eqnarray*}P(HH) &=& P(\text{last toss is }H \cap \text{2nd last toss is }H) \\&=& P(\text{last toss is }H)P(\text{2nd last toss is }H) \\&=& 0.25\\ P(THH) &=& 0.125\\ P(\text{ends with }TTHH) = P(\text{ends with }HTHH) &=& 0.0625.\end{eqnarray*}$$ So $P(\text{infinite string of $H$ and $T$}) = 1 - 0.25 - 0.125 - 0.0625 - 0.0625 = 0.5$. But clearly this does not conform to the above 3 models. So can we use this as a probability space? What is the issue here? Intuitively I can see how the probability spaces 1 to 3 all compute the same expectation. There are also countless other spaces that do too. The question is, is it possible to rigorize all this? It seems that each space above has some problems with it that raises the question of whether it is appropriate. Am I right to say that this portion relies completely on intuition and cannot possibly be rigorized? That is, the theory and mathematical rigor only starts after we have defined the probability space. Of course, then the question comes: how do we know our probability space ""works"" aside from intuition? Can we know that two different probability spaces will give us the same answer to a question? Also, am I right that there are actually way more assumptions in probability aside from the probability space? For instance: Independence in mathematical context is just $P(A \cap B) = P(A)P(B)$ but in real life we say that this means occurrence of $A$ does not affect probability of $B$ -- is this an assumption? $P(A | B) = P(A \cap B)/P(B)$ but in real life, we say $P(A | B)$ is the chance that $A$ occurs, given that $B$ has happened -- is this an assumption? The expected value of random variable $X$ is just defined as $E(X) = \sum_{\omega\in\Omega}P(\omega)X(\omega)$ in discrete spaces but in real life, we say it is the mean of $X$ if the experiment is repeated many many times -- is this an assumption? So all in all, there seems to be many assumptions in probability. So when does the theory start and end? EDIT: I've read a bit more about this issue and found that the reason why probability spaces give the same answer is likely due to them being extensions of each other. Terence Tao wrote about this once and if I'm not mistaken, the extension he talks about essentially shows the equivalence of the first 3 probability spaces I mentioned. Is this correct? According to this, independence should then be preserved under extension, so it doesn't make sense that independence ($P(A \cap B) = P(A)P(B)$) doesn't work under probability space 2 but works under 1. What I'm thinking might be the resolution is that when we state that ""the results of some coin tosses are mutually independent"", we are assuming that every single one of these independent coin tosses are performed in every single outcome . So in probability space 2, even though an outcome string might be of finite length, we assume that the other infinitely many coin tosses have also been performed (although their results are irrelevant for this outcome). Is this way of thinking correct? But now it seems strange that $P(\text{the $100$-th coin is heads}) = 0.5$, since after all the $100$-th coin is only tossed in the event that the $99$ coins before it do not contain consecutive heads. What is wrong here?",,"['probability', 'probability-theory', 'mathematical-modeling', 'axioms', 'independence']"
66,Expected time to completely cover a square with randomly placed smaller squares,Expected time to completely cover a square with randomly placed smaller squares,,"Suppose I have the unit square $[0,1]^2$ and I choose a point $(x_1, y_1)$ randomly in a uniform manner inside $[0,1]^2$ and draw a filled in square of side length $1/N$ with center $(x_1, y_1)$. And suppose I do this again and again, picking points $(x_n, y_n)$ and filling in squares with side length $1/N$. What is the expected time $T(N)$ it takes to completely fill in the unit square? Restated somewhat more formally, if $S_N(x,y) = [x-2/N, x+2/N] \times [y-2/N, y+2/N]$, then I am asking for $X_i$, $Y_i$, I.I.D. and uniformly distributed and $T$ the minimal $n$ such that $[0,1]^2 \subseteq \cup_{i=1}^n S_N(x_i, y_i)$, what is the expected value of $T$? I'll probably be happier with a less technical answer at the expense of nailing down the exact function $E[T(N)]$. Clearly there is the lower bound $E[T(N)] \geq N^2$. But, this problem may be simple enough, compared to the circle problem mentioned in the comments, to get an exact solution. P.S. I was motivated to ask this question from some fooling around I have done with programming. Specifically, this image which is composed in the manner just described but using many, many circles. Notice the gaps in the circles even though there is a lot of overlap elsewhere.","Suppose I have the unit square $[0,1]^2$ and I choose a point $(x_1, y_1)$ randomly in a uniform manner inside $[0,1]^2$ and draw a filled in square of side length $1/N$ with center $(x_1, y_1)$. And suppose I do this again and again, picking points $(x_n, y_n)$ and filling in squares with side length $1/N$. What is the expected time $T(N)$ it takes to completely fill in the unit square? Restated somewhat more formally, if $S_N(x,y) = [x-2/N, x+2/N] \times [y-2/N, y+2/N]$, then I am asking for $X_i$, $Y_i$, I.I.D. and uniformly distributed and $T$ the minimal $n$ such that $[0,1]^2 \subseteq \cup_{i=1}^n S_N(x_i, y_i)$, what is the expected value of $T$? I'll probably be happier with a less technical answer at the expense of nailing down the exact function $E[T(N)]$. Clearly there is the lower bound $E[T(N)] \geq N^2$. But, this problem may be simple enough, compared to the circle problem mentioned in the comments, to get an exact solution. P.S. I was motivated to ask this question from some fooling around I have done with programming. Specifically, this image which is composed in the manner just described but using many, many circles. Notice the gaps in the circles even though there is a lot of overlap elsewhere.",,"['probability', 'geometry', 'geometric-probability', 'coupon-collector']"
67,What am I getting for Christmas? Secret Santa and Graph theory,What am I getting for Christmas? Secret Santa and Graph theory,,"I live with four people, who thankfully don't spend much time on maths.se. We decided this year that we'd do a Secret Santa. We can represent the arrangement of who's buying for whom using a directed graph $G = (V,E)$. $V = \{\alpha,\beta,\gamma,\delta,\varepsilon\}$ is our vertex set, and $(u,v) \in E$ iff $u$ is buying a present for $v$. We decided to produce this graph by writing our names on bits of paper, shuffling them around, and each picking one out. If the name we draw is invalid, then we draw another piece of paper. Our validation rules were as follows: No participant shall buy for themselves - so $(v,v) \notin E$ $\delta$ and $\varepsilon$ are a couple, who will be buying for each other separately from the secret santa. Rather than waste edges, they've decided to render each other invalid, so $(\delta,\varepsilon) \notin E$ and $(\varepsilon, \delta) \notin E$ Each person buys for exactly one other person - so $deg_{in}(v) = deg_{out}(v) = 1$ I know who I bought for. Can I deduce the entire structure of the graph from this information? I can reduce the graph to four possible structures, posted as a partial answer, which already gives me a pretty large amount of information. I don't think I can get any more information about the state of the graph simply from knowing who I'm buying for, but I have some information on the order in which names were drawn, and know that we never had to reshuffle. Based on information provided by the draw, how would I find the probability of each of the possible Secret Santa arrangements? Partial answer - the possible graphs of giving: In these graphs, the nodes labelled $\delta/\varepsilon$ or $\varepsilon/\delta$ will take on different values, leading to four possible graphs. In both situations, $\alpha$ has the most natural information. Can more be gained from knowledge of the draw?","I live with four people, who thankfully don't spend much time on maths.se. We decided this year that we'd do a Secret Santa. We can represent the arrangement of who's buying for whom using a directed graph $G = (V,E)$. $V = \{\alpha,\beta,\gamma,\delta,\varepsilon\}$ is our vertex set, and $(u,v) \in E$ iff $u$ is buying a present for $v$. We decided to produce this graph by writing our names on bits of paper, shuffling them around, and each picking one out. If the name we draw is invalid, then we draw another piece of paper. Our validation rules were as follows: No participant shall buy for themselves - so $(v,v) \notin E$ $\delta$ and $\varepsilon$ are a couple, who will be buying for each other separately from the secret santa. Rather than waste edges, they've decided to render each other invalid, so $(\delta,\varepsilon) \notin E$ and $(\varepsilon, \delta) \notin E$ Each person buys for exactly one other person - so $deg_{in}(v) = deg_{out}(v) = 1$ I know who I bought for. Can I deduce the entire structure of the graph from this information? I can reduce the graph to four possible structures, posted as a partial answer, which already gives me a pretty large amount of information. I don't think I can get any more information about the state of the graph simply from knowing who I'm buying for, but I have some information on the order in which names were drawn, and know that we never had to reshuffle. Based on information provided by the draw, how would I find the probability of each of the possible Secret Santa arrangements? Partial answer - the possible graphs of giving: In these graphs, the nodes labelled $\delta/\varepsilon$ or $\varepsilon/\delta$ will take on different values, leading to four possible graphs. In both situations, $\alpha$ has the most natural information. Can more be gained from knowledge of the draw?",,"['probability', 'graph-theory', 'recreational-mathematics']"
68,Voronoi cell volume inside the ball,Voronoi cell volume inside the ball,,"I have the following problem: Let us denote a ball with center $C$ and radius $R$ in $\mathbb{R}^d$ as $B(C, R)$ . Given a unit ball $B(0, 1)$ and vector $u$ has a uniform distribution inside the ball: $u \sim U(B(0, 1))$ . Then we sample $M$ points $v_1, \dots, v_M$ that are uniformly distributed in the ball $B(0, 1)$ and the distance between $u$ and $v_i$ is not greater than $r$ , that is $v_i$ are i.i.d. in $B(0, 1) \cap B(u, r)$ . How to estimate the volume of the Voronoi cell of $u$ inside the ball $B(0, 1)$ ? I need an upper bound here. I can obtain only very rough estimates which do not depend on the dimension of the space $d$ and radius $r$ . It is clear that the desired values are growing monotonically as $r$ growing and if we put $r \ge 2$ , then $v_1, \dots, v_M$ are uniformly distributed inside the ball $B(0, 1)$ . So, $u, v_1, \dots, v_M$ are i.i.d. and uniformly distributed in $B(0, 1)$ . The rigorous definition of the value that I need to estimate (up to a scaling factor of the volume of unit ball): $$ \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}) $$ It is clear that $\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}$ = $\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_i | q \sim U(B(0,1))\}$ , so the expectations of all volumes are equal and the sum of all volumes is equal to $1$ . Hence $$ \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}) = \frac{1}{M+1}$$ It remains only to multiply it by the volume of unit ball. But as $r$ becomes less than $2$ the volume decreases, so would like to obtain estimates which take it into account. Moreover, I performed numerical experiments which shows that the estimation also should depends on the dimension of the space $d$ . Here is normal and log scale plots ( $M = 10$ ): In the more general case when $r < 2$ we still have that $\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_j | q \sim U(B(0,1))\}$ = $\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_k | q \sim U(B(0,1))\}$ and the sum of such probabilities for $u$ and $v_1, \dots, v_M$ is equal to $1$ , so we have: $$ \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}) + M \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_1 | q \sim U(B(0,1))\}) = 1$$ If we were able to find another equation or estimation on the ratio of volumes, then the problem would be solved. I would very appreciate any your help, ideas, papers, books and so on. Thank you for your help! UPD: Also it is possible to directly write down the required value as an integral. It is easy to see that the probability $\mathbb{P}(\rho(q, u) < \rho(q, v_i))$ correspond to the volume of spherical cap , it only remains to find the height of this spherical cap. My calculations showed that if $\|u\| \le \|v\|$ then $$ h = 1 - \dfrac{\|v\|^2 - \|u\|^2}{2\|v-u\|} $$ $$ \mathbb{P} = 1 - \frac{1}{2} I_{2h - h^2}(\frac{d+1}{2}, \frac{1}{2}) $$ and if $\|u\| \ge \|v\|$ then $$ h = 1 - \dfrac{\|u\|^2 - \|v\|^2}{2\|v-u\|} $$ $$ \mathbb{P} = \frac{1}{2} I_{2h - h^2}(\frac{d+1}{2}, \frac{1}{2}) $$ where $I_x(a, b)$ is incomplete regularized beta function . One more observation is: $$\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u\} = \mathbb{P}(\rho(q, u) < \rho(q, v_i), i=1,\dots,M) = \prod\limits_{i=1}^{M}\mathbb{P}(\rho(q, u) < \rho(q, v_i)) = (\mathbb{P}(\rho(q, u) < \rho(q, v)))^M$$ since $v_1,\dots,v_M$ are i.i.d. So now we can integrate for $u$ and $v$ and obtain the desired value: $$ \frac{1}{Vol(B(0,1))} \int\limits_{u \in B(0,1)} \Big( \int\limits_{v \in B(0,1) \cap B(u, r), \|v\| \le \|u\|} (\frac{1}{2}I_{2h-h^2}(\frac{d+1}{2},\frac{1}{2}))^M \frac{1}{Vol(B(0,1) \cap B(u,r))}dv + \int\limits_{v \in B(0,1) \cap B(u, r), \|v\| \ge \|u\|} (1 - \frac{1}{2}I_{2h-h^2}(\frac{d+1}{2},\frac{1}{2}))^M \frac{1}{Vol(B(0,1) \cap B(u,r))}dv \Big) du,$$ where $h = 1 - \frac{| \|v\|^2 - \|u\|^2 |}{2\|v-u\|}$ The first summand here is about $\frac{1}{2^M}$ since regularized incomplete beta function is bounded by $1$ , so it remains only to estimate the second summand. If I was able to estimate the asymptotics of this integral, it would solve my problem!","I have the following problem: Let us denote a ball with center and radius in as . Given a unit ball and vector has a uniform distribution inside the ball: . Then we sample points that are uniformly distributed in the ball and the distance between and is not greater than , that is are i.i.d. in . How to estimate the volume of the Voronoi cell of inside the ball ? I need an upper bound here. I can obtain only very rough estimates which do not depend on the dimension of the space and radius . It is clear that the desired values are growing monotonically as growing and if we put , then are uniformly distributed inside the ball . So, are i.i.d. and uniformly distributed in . The rigorous definition of the value that I need to estimate (up to a scaling factor of the volume of unit ball): It is clear that = , so the expectations of all volumes are equal and the sum of all volumes is equal to . Hence It remains only to multiply it by the volume of unit ball. But as becomes less than the volume decreases, so would like to obtain estimates which take it into account. Moreover, I performed numerical experiments which shows that the estimation also should depends on the dimension of the space . Here is normal and log scale plots ( ): In the more general case when we still have that = and the sum of such probabilities for and is equal to , so we have: If we were able to find another equation or estimation on the ratio of volumes, then the problem would be solved. I would very appreciate any your help, ideas, papers, books and so on. Thank you for your help! UPD: Also it is possible to directly write down the required value as an integral. It is easy to see that the probability correspond to the volume of spherical cap , it only remains to find the height of this spherical cap. My calculations showed that if then and if then where is incomplete regularized beta function . One more observation is: since are i.i.d. So now we can integrate for and and obtain the desired value: where The first summand here is about since regularized incomplete beta function is bounded by , so it remains only to estimate the second summand. If I was able to estimate the asymptotics of this integral, it would solve my problem!","C R \mathbb{R}^d B(C, R) B(0, 1) u u \sim U(B(0, 1)) M v_1, \dots, v_M B(0, 1) u v_i r v_i B(0, 1) \cap B(u, r) u B(0, 1) d r r r \ge 2 v_1, \dots, v_M B(0, 1) u, v_1, \dots, v_M B(0, 1)  \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\})  \mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\} \mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_i | q \sim U(B(0,1))\} 1  \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}) = \frac{1}{M+1} r 2 d M = 10 r < 2 \mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_j | q \sim U(B(0,1))\} \mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_k | q \sim U(B(0,1))\} u v_1, \dots, v_M 1  \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u | q \sim U(B(0,1))\}) + M \mathbb{E}_{u, v_1, \dots, v_M} (\mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~v_1 | q \sim U(B(0,1))\}) = 1 \mathbb{P}(\rho(q, u) < \rho(q, v_i)) \|u\| \le \|v\|  h = 1 - \dfrac{\|v\|^2 - \|u\|^2}{2\|v-u\|}   \mathbb{P} = 1 - \frac{1}{2} I_{2h - h^2}(\frac{d+1}{2}, \frac{1}{2})  \|u\| \ge \|v\|  h = 1 - \dfrac{\|u\|^2 - \|v\|^2}{2\|v-u\|}   \mathbb{P} = \frac{1}{2} I_{2h - h^2}(\frac{d+1}{2}, \frac{1}{2})  I_x(a, b) \mathbb{P}\{ q~\text{belongs to the Voronoi cell of}~u\} = \mathbb{P}(\rho(q, u) < \rho(q, v_i), i=1,\dots,M) = \prod\limits_{i=1}^{M}\mathbb{P}(\rho(q, u) < \rho(q, v_i)) = (\mathbb{P}(\rho(q, u) < \rho(q, v)))^M v_1,\dots,v_M u v  \frac{1}{Vol(B(0,1))} \int\limits_{u \in B(0,1)} \Big( \int\limits_{v \in B(0,1) \cap B(u, r), \|v\| \le \|u\|} (\frac{1}{2}I_{2h-h^2}(\frac{d+1}{2},\frac{1}{2}))^M \frac{1}{Vol(B(0,1) \cap B(u,r))}dv + \int\limits_{v \in B(0,1) \cap B(u, r), \|v\| \ge \|u\|} (1 - \frac{1}{2}I_{2h-h^2}(\frac{d+1}{2},\frac{1}{2}))^M \frac{1}{Vol(B(0,1) \cap B(u,r))}dv \Big) du, h = 1 - \frac{| \|v\|^2 - \|u\|^2 |}{2\|v-u\|} \frac{1}{2^M} 1","['probability', 'geometry', 'stochastic-analysis', 'geometric-probability', 'voronoi-diagram']"
69,Randomly Generate Probability Mass Function With Specific Entropy,Randomly Generate Probability Mass Function With Specific Entropy,,"How can I randomly generate a probability mass function such that the entropy of a random variable that follows that probability mass function is a specific value $h$? Basically, I need to randomly generate a probability distribution over $n$ states with probability $p_i$ of being in state $i$. We can represent the distribution as a vector: $\vec{p}={p_1,p_2,p_3,...p_n}$ such that: $$\sum_{i=1}^n p_i\ =\ 1$$ and $$Entropy(\vec{p})=-\sum_{i=1}^n p_i\ log_2(p_i)\ =\ h$$ for a known $h$ between $0$ and $log_2(n)$. Specifically, I know $h$ and I want to randomly select $n$ values that satisfy the above conditions for that $h$. The set of values ${p_1,p_2,p_3,...p_n}$ should be uniformly distributed. In other words, the probability density function of a point should match the probability density function of a point uniformly distributed on a simplex. See this post about randomly generating points on a simplex. To put it in formal terms, the distribution should be uniform in the sense that it will be the same as though the point were generated through rejection sampling of points on the simplex where any point $\vec{p}$ is rejected if outside of the $Entropy(\vec{p})$ is outside the range range $[h-\epsilon,h+\epsilon]$ for an infinitesimally small $\epsilon$. Update: If we raise each element of $\vec p$ to a power $x$ and then normalize the result by scaling it so that it sums to one, then we can adjust the entropy arbitrarily (provided that $\vec p$ doesn't represent an exactly uniform distribution). Based on this, I think we can randomly generate a point on the simplex and then just raise it to a power to adjust the entropy to the desired value. Does anyone know how to prove that this won't lead to a bias when compared to rejection sampling?","How can I randomly generate a probability mass function such that the entropy of a random variable that follows that probability mass function is a specific value $h$? Basically, I need to randomly generate a probability distribution over $n$ states with probability $p_i$ of being in state $i$. We can represent the distribution as a vector: $\vec{p}={p_1,p_2,p_3,...p_n}$ such that: $$\sum_{i=1}^n p_i\ =\ 1$$ and $$Entropy(\vec{p})=-\sum_{i=1}^n p_i\ log_2(p_i)\ =\ h$$ for a known $h$ between $0$ and $log_2(n)$. Specifically, I know $h$ and I want to randomly select $n$ values that satisfy the above conditions for that $h$. The set of values ${p_1,p_2,p_3,...p_n}$ should be uniformly distributed. In other words, the probability density function of a point should match the probability density function of a point uniformly distributed on a simplex. See this post about randomly generating points on a simplex. To put it in formal terms, the distribution should be uniform in the sense that it will be the same as though the point were generated through rejection sampling of points on the simplex where any point $\vec{p}$ is rejected if outside of the $Entropy(\vec{p})$ is outside the range range $[h-\epsilon,h+\epsilon]$ for an infinitesimally small $\epsilon$. Update: If we raise each element of $\vec p$ to a power $x$ and then normalize the result by scaling it so that it sums to one, then we can adjust the entropy arbitrarily (provided that $\vec p$ doesn't represent an exactly uniform distribution). Based on this, I think we can randomly generate a point on the simplex and then just raise it to a power to adjust the entropy to the desired value. Does anyone know how to prove that this won't lead to a bias when compared to rejection sampling?",,"['probability', 'probability-distributions', 'information-theory', 'entropy']"
70,"Showing that $|A\cap B|/|A \cup B| + |B\cap C|/|B \cup C| - |A\cap C|/|A \cup C| \leq 1$ for finite sets $A,B,C$.",Showing that  for finite sets .,"|A\cap B|/|A \cup B| + |B\cap C|/|B \cup C| - |A\cap C|/|A \cup C| \leq 1 A,B,C","If $A$, $B$ and $C$ are finite sets, prove that   $$  \frac{|A\cap B|}{|A \cup B|}  + \frac{|B\cap C|}{|B \cup C|}  - \frac{|A\cap C|}{|A \cup C|}  \leq 1. $$ It seem's simple, but I tried it for a long time and cannot get it out. Maybe I can use some optimization methods to calculate it, but that's not what I want...","If $A$, $B$ and $C$ are finite sets, prove that   $$  \frac{|A\cap B|}{|A \cup B|}  + \frac{|B\cap C|}{|B \cup C|}  - \frac{|A\cap C|}{|A \cup C|}  \leq 1. $$ It seem's simple, but I tried it for a long time and cannot get it out. Maybe I can use some optimization methods to calculate it, but that's not what I want...",,"['probability', 'elementary-set-theory']"
71,Invariant measure of Euler-Maruyama Discretisation of an Ito diffusion,Invariant measure of Euler-Maruyama Discretisation of an Ito diffusion,,"Let $(X_t)_{t \geq 0}$ be a diffusion process with dynamics governed by the stochastic differential equation \begin{equation} dX_t = b(X_t)dt + \sigma(X_t)dW_t, ~~ X_0 = x_0, \end{equation} where $b,\sigma$ are Lipschitz and $(W_t)_{t \geq 0}$ is a standard $d$-dimensional Wiener process.  Assume $(X_t)_{t \geq 0}$ possesses a unique invariant probability measure $\mu(\cdot)$. The Euler-Maruayama approximation of this SDE with step size $h$ is a Markov chain defined recursively as $Y_0 = x_0$, and for $n \in \mathbb{Z}^+$ \begin{equation} Y_{(n+1)h}|Y_{nh} = Y_{nh} + b(Y_{nh})h + \sqrt{h}\sigma(Y_{nh})\varepsilon, ~~ \varepsilon \sim \mathcal{N}(0,I_{d \times d}). \end{equation} I can see that under certain conditions $\{Y_i\}_{i \in \mathbb{Z}^+}$ will also possess a unique invariant probability measure, $\mu^h(\cdot)$.  I've seen certain results discussing how the ergodicity properties of $(X_t)_{t \geq 0}$ and $\{Y_i\}_{i \in \mathbb{Z}^+}$ can differ (e.g. scenarios in which the first can be exponentially ergodic but the second transient, see: http://projecteuclid.org/euclid.bj/1178291835 ). What I've been unable to find are results discussing how $\mu^h(\cdot)$ and $\mu(\cdot)$ differ.  Can we make some statement about how 'close' the two measures are, in total variation \begin{equation} \| \mu^h(\cdot) - \mu(\cdot) \|_{TV} \end{equation} or some other appropriate distance.  And can we say anything about the distance \begin{equation} \|\mathbb{E}_{\mu^h}f - \mathbb{E}_{\mu}f\| \end{equation} for some suitable class of functions $f$, assuming both processes are defined on the same space which has norm $\|\cdot\|$?  I've searched around online a bit, the closest I've come is here http://www.newton.ac.uk/preprints/NI03065.pdf , where the result is alluded to, which makes me think it might be fairly well known.  So if anyone could point me in the right direction or explain why it's obvious then that would be great, thanks! Also asked on Math overflow here: https://mathoverflow.net/questions/163443/invariant-measure-of-euler-maruyama-discretisation-of-an-ito-diffusion/163489?noredirect=1#163489","Let $(X_t)_{t \geq 0}$ be a diffusion process with dynamics governed by the stochastic differential equation \begin{equation} dX_t = b(X_t)dt + \sigma(X_t)dW_t, ~~ X_0 = x_0, \end{equation} where $b,\sigma$ are Lipschitz and $(W_t)_{t \geq 0}$ is a standard $d$-dimensional Wiener process.  Assume $(X_t)_{t \geq 0}$ possesses a unique invariant probability measure $\mu(\cdot)$. The Euler-Maruayama approximation of this SDE with step size $h$ is a Markov chain defined recursively as $Y_0 = x_0$, and for $n \in \mathbb{Z}^+$ \begin{equation} Y_{(n+1)h}|Y_{nh} = Y_{nh} + b(Y_{nh})h + \sqrt{h}\sigma(Y_{nh})\varepsilon, ~~ \varepsilon \sim \mathcal{N}(0,I_{d \times d}). \end{equation} I can see that under certain conditions $\{Y_i\}_{i \in \mathbb{Z}^+}$ will also possess a unique invariant probability measure, $\mu^h(\cdot)$.  I've seen certain results discussing how the ergodicity properties of $(X_t)_{t \geq 0}$ and $\{Y_i\}_{i \in \mathbb{Z}^+}$ can differ (e.g. scenarios in which the first can be exponentially ergodic but the second transient, see: http://projecteuclid.org/euclid.bj/1178291835 ). What I've been unable to find are results discussing how $\mu^h(\cdot)$ and $\mu(\cdot)$ differ.  Can we make some statement about how 'close' the two measures are, in total variation \begin{equation} \| \mu^h(\cdot) - \mu(\cdot) \|_{TV} \end{equation} or some other appropriate distance.  And can we say anything about the distance \begin{equation} \|\mathbb{E}_{\mu^h}f - \mathbb{E}_{\mu}f\| \end{equation} for some suitable class of functions $f$, assuming both processes are defined on the same space which has norm $\|\cdot\|$?  I've searched around online a bit, the closest I've come is here http://www.newton.ac.uk/preprints/NI03065.pdf , where the result is alluded to, which makes me think it might be fairly well known.  So if anyone could point me in the right direction or explain why it's obvious then that would be great, thanks! Also asked on Math overflow here: https://mathoverflow.net/questions/163443/invariant-measure-of-euler-maruyama-discretisation-of-an-ito-diffusion/163489?noredirect=1#163489",,"['probability', 'numerical-methods', 'stochastic-processes', 'markov-chains', 'stochastic-calculus']"
72,"1D Random Walk, with different step sizes in each direction.","1D Random Walk, with different step sizes in each direction.",,"A walker starts at a defined position greater than $0$, say $A$, and then makes a ""decision"" to walk either ""$b$ steps to the right"" or walk ""$c$ steps to the left."" He will choose the first option with probability $p$, and the second option with probability $1-p$. If the walker gets to position $0$ he stops. I wish to calculate: the expectation value of the walker's position after a total of n decisions. what happens as n approaches infinite? Is there an existing formula/theory that can be used to get an analytic solution to this problem?","A walker starts at a defined position greater than $0$, say $A$, and then makes a ""decision"" to walk either ""$b$ steps to the right"" or walk ""$c$ steps to the left."" He will choose the first option with probability $p$, and the second option with probability $1-p$. If the walker gets to position $0$ he stops. I wish to calculate: the expectation value of the walker's position after a total of n decisions. what happens as n approaches infinite? Is there an existing formula/theory that can be used to get an analytic solution to this problem?",,"['probability', 'stochastic-processes']"
73,Does asymmetric fraction of finite groups tend to $0$?,Does asymmetric fraction of finite groups tend to ?,0,"Letโs define asymmetric fraction of a finite group $G$ as the number $af(G) = \frac{|\{(g, a) \in G \times Aut(G)| a(g) = g\}|}{|G||Aut(G)|}$ . Equivalently it can be defined as $P(A(X) = X)$ , where $A$ and $X$ are independent uniformly distributed random elements of $Aut(G)$ and $G$ respectively. Is it true, that $\forall \epsilon > 0 \exists N \in \mathbb{N} \forall G ((\lvert\,G\,\rvert > n) \to (af(G) < \epsilon))$ ? I know, that $af(C_{p^n}) = \dfrac{p^n + \Sigma_{i = 1}^n  p^ip^{n - 1 - i}(p - 1)}{p^{2n - 1}(p - 1)} = \dfrac{(np - n + 1)}{p^n(p - 1)}$ and, that $af(G) \leq \frac{1}{2} + \dfrac{|\{g \in G| \forall a \in Aut(G) \text{ } a(g) = g\}|}{2|G|}$ . However this is clearly not enough to prove the statement.","Letโs define asymmetric fraction of a finite group as the number . Equivalently it can be defined as , where and are independent uniformly distributed random elements of and respectively. Is it true, that ? I know, that and, that . However this is clearly not enough to prove the statement.","G af(G) = \frac{|\{(g, a) \in G \times Aut(G)| a(g) = g\}|}{|G||Aut(G)|} P(A(X) = X) A X Aut(G) G \forall \epsilon > 0 \exists N \in \mathbb{N} \forall G ((\lvert\,G\,\rvert > n) \to (af(G) < \epsilon)) af(C_{p^n}) = \dfrac{p^n + \Sigma_{i = 1}^n  p^ip^{n - 1 - i}(p - 1)}{p^{2n - 1}(p - 1)} = \dfrac{(np - n + 1)}{p^n(p - 1)} af(G) \leq \frac{1}{2} + \dfrac{|\{g \in G| \forall a \in Aut(G) \text{ } a(g) = g\}|}{2|G|}","['probability', 'group-theory', 'finite-groups', 'group-actions', 'automorphism-group']"
74,Is this question solvable? $2$ non-linear equations and the proof that the solution is unique,Is this question solvable?  non-linear equations and the proof that the solution is unique,2,"As mentioned in the title I want to show the uniqueness of the solution to $2$ non-linear equations. However, it seems that I can not solve this question with my current mathematical knowledge. More than this I am not aware about the difficulty of the problem. Is this question solvable by a very good mathematician at all? This is also what I wonder very much. Let me introduce my problem: I have orgininally $4$ equations as given below. $$\int_{-\infty}^{y_l}\frac{b}{eb^{\mu_1}}f_1(y)\mathrm{d}y+\int_{y_l}^{y_u}K_1 l(y)^{\frac{-\ln(b)}{\ln(a b)}}f_1(y)\mathrm{d}y+\int_{y_u}^{\infty}\frac{1}{eb^{\mu_1}}f_1(y)\mathrm{d}y=1$$ $$\int_{-\infty}^{y_l}\frac{1}{ea^{\mu_0}}f_0(y)\mathrm{d}y+\int_{y_l}^{y_u}K_0 l(y)^{\frac{\ln(a)}{\ln(a b)}}f_0(y)\mathrm{d}y+\int_{y_u}^{\infty}\frac{a}{ea^{\mu_0}}f_0(y)\mathrm{d}y=1$$ $$\small \int_{-\infty}^{y_l}\frac{b}{eb^{\mu_1}}\ln \left(\frac{b}{e b^{\mu_1}}\right)f_1(y)\mathrm{d}y+\int_{y_l}^{y_u}K_1 l(y)^{\frac{-\ln(b)}{\ln(a b)}}f_1(y) \ln \left( K_1 l(y)^{\frac{-\ln(b)}{\ln(a b)}}\right)\mathrm{d}y+\int_{y_u}^{\infty}\frac{1}{eb^{\mu_1}}\ln \left(\frac{1}{eb^{\mu_1}}\right)f_1(y)\mathrm{d}y=\epsilon_1$$ $$\small \int_{-\infty}^{y_l}\frac{1}{ea^{\mu_0}}\ln \left(\frac{1}{e a^{\mu_0}}\right)f_0(y)\mathrm{d}y+\int_{y_l}^{y_u}K_0 l(y)^{\frac{\ln(a)}{\ln(a b)}}f_0(y) \ln \left( K_0 l(y)^{\frac{\ln(a)}{\ln(a b)}}\right)\mathrm{d}y+\int_{y_u}^{\infty}\frac{a}{e a^{\mu_0}}\ln \left(\frac{a}{ea^{\mu_0}}\right)f_0(y)\mathrm{d}y=\epsilon_0$$ Given: $\rightarrow f_0$ and $f_1$ are some density functions $\rightarrow l(y)=\frac{f_1(y)}{f_0(y)}$ is an increasing function $\rightarrow  b=l(y_u),\quad a=\frac{1}{l(y_l)}$ $\rightarrow K_0=\frac{e^{\frac{\ln^2(a)}{\ln (ab)}}}{e a^{\mu_0}},\quad K_1=\frac{e^{\frac{\ln^2(b)}{\ln (ab)}}}{e b^{\mu_1}}$ As you can see the first two equations can be inserted into the third and fourth equation via $e a^{\mu_0}$ and $e b^{\mu_1}$. As a result we can obtain $$z_0=\int_{-\infty }^{y_l} f_0(y) \, \mathrm{d}y+\int _{y_l}^{y_u}e^{\frac{\text{ln}^2(a)}{\text{ln}(ab)}}l(y)^{\frac{\text{ln}[a]}{\text{ln}(ab)}}f_0(y)\mathrm{d}y+\int _{y_u}^{\infty }a f_0 (y)\mathrm{d}y$$ $$z_1=\int _{-\infty }^{y_l}b f_1(y)\mathrm{d}y+\int _{y_l}^{y_u}e^{\frac{\text{ln}^2(b)}{\text{ln}(ab)}}l(y)^{\frac{-\text{ln}[b]}{\ln (ab)}}f_1(y)\mathrm{d}y+\int_{y_u}^{\infty } f_1(y) \, \mathrm{d}y$$ $$h_0=-\text{ln}(z_0)+\frac{1}{z_0}\left(\int _{y_l}^{y_u}e^{\frac{\text{ln}^2(a)}{\text{ln}(ab)}}l(y)^{\frac{\text{ln}(a)}{\text{ln}(ab)}}\text{ln}\left(e^{\frac{\text{ln}^2(a)}{\text{ln}(ab)}}l(y)^{\frac{\text{ln}(a)}{\text{ln}(ab)}}\right)f_0(y)\mathrm{d}y+\int _{y_u}^{\infty }a\text{ln}(a)f_0 (y)\mathrm{d}y\right)=\epsilon_0$$ $$h_1=-\text{ln}(z_1)+\frac{1}{z_1}\left(\int _{y_l}^{y_u}e^{\frac{\text{ln}^2(b)}{\text{ln}(ab)}}l(y)^{-\frac{\text{ln}(b)}{\text{ln}(ab)}}\text{ln}\left(e^{\frac{\text{ln}^2(b)}{\text{ln}(ab)}}l(y)^{-\frac{\text{ln}(b)}{\text{ln}(ab)}}\right)f_1(y)\mathrm{d}y+\int _{-\infty}^{y_l }b\text{ln}(b)f_1 (y)\mathrm{d}y\right)=\epsilon_1$$ Now I have two functions $h_0(y_l,y_u)=\epsilon_0$ and $h_1(y_l,y_u)=\epsilon_1$. My conjecture: There exists a unique solution to $\{h_0(y_l,y_u)=\epsilon_0,\,h_1(y_l,y_u)=\epsilon_1\}$ with some $\{y_l,y_u\}\in\mathbb{R}$ for $\{\epsilon_0\in[0,h_0(y_l\rightarrow -\infty,y_u \rightarrow \infty)],\epsilon_1\in[0,h_1(y_l\rightarrow -\infty,y_u \rightarrow \infty)]\}$ My Question: Prove or disprove if my conjecture is correct. Extra Information: When $y_l\rightarrow -\infty$ and $y_u\rightarrow \infty$, the first $4$ equations above simplifies considerably. Then, for the equation $h_0$ we have a single parameter $0<x=\frac{\ln(a)}{\ln(a b)}<1$. If we take the derivative with respect to $x$, we can show that it is positive. The latter part of this proof (to show that it is positive) can be seen here Prove or disprove that the given expression is ""always"" positive , thanks to @julien. I havent done by my own but I would guess that the similar story also applies to $h_1$, and this determines the set $\{\epsilon_0\in[0,h_0(y_l\rightarrow -\infty,y_u \rightarrow \infty)],\epsilon_1\in[0,h_1(y_l\rightarrow -\infty,y_u \rightarrow \infty)]\}$ for which a unique solution is sought for.","As mentioned in the title I want to show the uniqueness of the solution to $2$ non-linear equations. However, it seems that I can not solve this question with my current mathematical knowledge. More than this I am not aware about the difficulty of the problem. Is this question solvable by a very good mathematician at all? This is also what I wonder very much. Let me introduce my problem: I have orgininally $4$ equations as given below. $$\int_{-\infty}^{y_l}\frac{b}{eb^{\mu_1}}f_1(y)\mathrm{d}y+\int_{y_l}^{y_u}K_1 l(y)^{\frac{-\ln(b)}{\ln(a b)}}f_1(y)\mathrm{d}y+\int_{y_u}^{\infty}\frac{1}{eb^{\mu_1}}f_1(y)\mathrm{d}y=1$$ $$\int_{-\infty}^{y_l}\frac{1}{ea^{\mu_0}}f_0(y)\mathrm{d}y+\int_{y_l}^{y_u}K_0 l(y)^{\frac{\ln(a)}{\ln(a b)}}f_0(y)\mathrm{d}y+\int_{y_u}^{\infty}\frac{a}{ea^{\mu_0}}f_0(y)\mathrm{d}y=1$$ $$\small \int_{-\infty}^{y_l}\frac{b}{eb^{\mu_1}}\ln \left(\frac{b}{e b^{\mu_1}}\right)f_1(y)\mathrm{d}y+\int_{y_l}^{y_u}K_1 l(y)^{\frac{-\ln(b)}{\ln(a b)}}f_1(y) \ln \left( K_1 l(y)^{\frac{-\ln(b)}{\ln(a b)}}\right)\mathrm{d}y+\int_{y_u}^{\infty}\frac{1}{eb^{\mu_1}}\ln \left(\frac{1}{eb^{\mu_1}}\right)f_1(y)\mathrm{d}y=\epsilon_1$$ $$\small \int_{-\infty}^{y_l}\frac{1}{ea^{\mu_0}}\ln \left(\frac{1}{e a^{\mu_0}}\right)f_0(y)\mathrm{d}y+\int_{y_l}^{y_u}K_0 l(y)^{\frac{\ln(a)}{\ln(a b)}}f_0(y) \ln \left( K_0 l(y)^{\frac{\ln(a)}{\ln(a b)}}\right)\mathrm{d}y+\int_{y_u}^{\infty}\frac{a}{e a^{\mu_0}}\ln \left(\frac{a}{ea^{\mu_0}}\right)f_0(y)\mathrm{d}y=\epsilon_0$$ Given: $\rightarrow f_0$ and $f_1$ are some density functions $\rightarrow l(y)=\frac{f_1(y)}{f_0(y)}$ is an increasing function $\rightarrow  b=l(y_u),\quad a=\frac{1}{l(y_l)}$ $\rightarrow K_0=\frac{e^{\frac{\ln^2(a)}{\ln (ab)}}}{e a^{\mu_0}},\quad K_1=\frac{e^{\frac{\ln^2(b)}{\ln (ab)}}}{e b^{\mu_1}}$ As you can see the first two equations can be inserted into the third and fourth equation via $e a^{\mu_0}$ and $e b^{\mu_1}$. As a result we can obtain $$z_0=\int_{-\infty }^{y_l} f_0(y) \, \mathrm{d}y+\int _{y_l}^{y_u}e^{\frac{\text{ln}^2(a)}{\text{ln}(ab)}}l(y)^{\frac{\text{ln}[a]}{\text{ln}(ab)}}f_0(y)\mathrm{d}y+\int _{y_u}^{\infty }a f_0 (y)\mathrm{d}y$$ $$z_1=\int _{-\infty }^{y_l}b f_1(y)\mathrm{d}y+\int _{y_l}^{y_u}e^{\frac{\text{ln}^2(b)}{\text{ln}(ab)}}l(y)^{\frac{-\text{ln}[b]}{\ln (ab)}}f_1(y)\mathrm{d}y+\int_{y_u}^{\infty } f_1(y) \, \mathrm{d}y$$ $$h_0=-\text{ln}(z_0)+\frac{1}{z_0}\left(\int _{y_l}^{y_u}e^{\frac{\text{ln}^2(a)}{\text{ln}(ab)}}l(y)^{\frac{\text{ln}(a)}{\text{ln}(ab)}}\text{ln}\left(e^{\frac{\text{ln}^2(a)}{\text{ln}(ab)}}l(y)^{\frac{\text{ln}(a)}{\text{ln}(ab)}}\right)f_0(y)\mathrm{d}y+\int _{y_u}^{\infty }a\text{ln}(a)f_0 (y)\mathrm{d}y\right)=\epsilon_0$$ $$h_1=-\text{ln}(z_1)+\frac{1}{z_1}\left(\int _{y_l}^{y_u}e^{\frac{\text{ln}^2(b)}{\text{ln}(ab)}}l(y)^{-\frac{\text{ln}(b)}{\text{ln}(ab)}}\text{ln}\left(e^{\frac{\text{ln}^2(b)}{\text{ln}(ab)}}l(y)^{-\frac{\text{ln}(b)}{\text{ln}(ab)}}\right)f_1(y)\mathrm{d}y+\int _{-\infty}^{y_l }b\text{ln}(b)f_1 (y)\mathrm{d}y\right)=\epsilon_1$$ Now I have two functions $h_0(y_l,y_u)=\epsilon_0$ and $h_1(y_l,y_u)=\epsilon_1$. My conjecture: There exists a unique solution to $\{h_0(y_l,y_u)=\epsilon_0,\,h_1(y_l,y_u)=\epsilon_1\}$ with some $\{y_l,y_u\}\in\mathbb{R}$ for $\{\epsilon_0\in[0,h_0(y_l\rightarrow -\infty,y_u \rightarrow \infty)],\epsilon_1\in[0,h_1(y_l\rightarrow -\infty,y_u \rightarrow \infty)]\}$ My Question: Prove or disprove if my conjecture is correct. Extra Information: When $y_l\rightarrow -\infty$ and $y_u\rightarrow \infty$, the first $4$ equations above simplifies considerably. Then, for the equation $h_0$ we have a single parameter $0<x=\frac{\ln(a)}{\ln(a b)}<1$. If we take the derivative with respect to $x$, we can show that it is positive. The latter part of this proof (to show that it is positive) can be seen here Prove or disprove that the given expression is ""always"" positive , thanks to @julien. I havent done by my own but I would guess that the similar story also applies to $h_1$, and this determines the set $\{\epsilon_0\in[0,h_0(y_l\rightarrow -\infty,y_u \rightarrow \infty)],\epsilon_1\in[0,h_1(y_l\rightarrow -\infty,y_u \rightarrow \infty)]\}$ for which a unique solution is sought for.",,"['probability', 'integration', 'probability-distributions', 'hilbert-spaces']"
75,How do Kolmogorov 0-1 law and CLT imply normalized sample mean doesn't converge in probability nor a.s.?,How do Kolmogorov 0-1 law and CLT imply normalized sample mean doesn't converge in probability nor a.s.?,,"From WIkipedia the central limit theorem states that the sums Sn scaled by the   factor $1/\sqrt{n}$ converge in distribution to a standard normal   distribution. Combined with Kolmogorov's zero-one law, this implies   that these quantities converge neither in probability nor almost   surely: $$      \frac{S_n}{\sqrt n} \ \stackrel{p}{\nrightarrow}\ \forall, \qquad \frac{S_n}{\sqrt n} \ \stackrel{a.s.}{\nrightarrow}\ \forall, \qquad  \text{as}\ \ n\to\infty. $$ How do Kolmogorov 0-1 law and CLT imply normalized sample mean doesn't converge in probability nor a.s.? Thanks!","From WIkipedia the central limit theorem states that the sums Sn scaled by the   factor $1/\sqrt{n}$ converge in distribution to a standard normal   distribution. Combined with Kolmogorov's zero-one law, this implies   that these quantities converge neither in probability nor almost   surely: $$      \frac{S_n}{\sqrt n} \ \stackrel{p}{\nrightarrow}\ \forall, \qquad \frac{S_n}{\sqrt n} \ \stackrel{a.s.}{\nrightarrow}\ \forall, \qquad  \text{as}\ \ n\to\infty. $$ How do Kolmogorov 0-1 law and CLT imply normalized sample mean doesn't converge in probability nor a.s.? Thanks!",,"['probability', 'central-limit-theorem']"
76,How do we understand 6 people trying something is not 6 times the success rate? [duplicate],How do we understand 6 people trying something is not 6 times the success rate? [duplicate],,"This question already has answers here : What's 4 times more likely than 80%? (6 answers) Closed 5 years ago . Let's say if a task has a success rate of $20\%$, or $0.2$, meaning if a person tries it, then there is a $20\%$ chance he can succeed. One example is, if we generate a random number from 1 to 10, and getting the number 9 or 10 is considered to be a success. Now, if we let 6 people try it, and one person succeeding is considered a success, we cannot say the success rate is $6$ times as much, because then the success rate is $20\% \times 6 = 120\%$, and probability cannot be greater than $100\%$.  So the success rate is not 6 times as much. However, if we let 1 person try it $1,000,000$ times, the Law of Large Numbers says that the number of times he will succeed is $200,000$. And if we let 6 people try $1,000,000$ times each, then the number of success is indeed $200,000 \times 6 = 1,200,000$ which is $6$ times.  How can we understand this? In a real life example, say, each time when we catch a Pokemon, let's say there is a special type of Pokemon that when you tap on it, it can be ""shiny"", and the probability is $1/256$.  Now if one player try to tap on $300$ Pokemon, the probability of getting at least one shiny is not $1$, but less than $1$.  If we let 6 people, each try to tap on $300$ Pokemon (and a Pokemon can be non-shiny for player 1 but is shiny for player 2, meaning it is independent), then the probability of getting at least one shiny is not $6$ times. Now, however, if we let all 6 players, each tap on $3,000,000$ Pokemon, then the number of shiny Pokemon they will get is in fact $6$ times  if we only allow 1 player to play.  How can we understand this ""6 times yes and no"" dilemma?","This question already has answers here : What's 4 times more likely than 80%? (6 answers) Closed 5 years ago . Let's say if a task has a success rate of $20\%$, or $0.2$, meaning if a person tries it, then there is a $20\%$ chance he can succeed. One example is, if we generate a random number from 1 to 10, and getting the number 9 or 10 is considered to be a success. Now, if we let 6 people try it, and one person succeeding is considered a success, we cannot say the success rate is $6$ times as much, because then the success rate is $20\% \times 6 = 120\%$, and probability cannot be greater than $100\%$.  So the success rate is not 6 times as much. However, if we let 1 person try it $1,000,000$ times, the Law of Large Numbers says that the number of times he will succeed is $200,000$. And if we let 6 people try $1,000,000$ times each, then the number of success is indeed $200,000 \times 6 = 1,200,000$ which is $6$ times.  How can we understand this? In a real life example, say, each time when we catch a Pokemon, let's say there is a special type of Pokemon that when you tap on it, it can be ""shiny"", and the probability is $1/256$.  Now if one player try to tap on $300$ Pokemon, the probability of getting at least one shiny is not $1$, but less than $1$.  If we let 6 people, each try to tap on $300$ Pokemon (and a Pokemon can be non-shiny for player 1 but is shiny for player 2, meaning it is independent), then the probability of getting at least one shiny is not $6$ times. Now, however, if we let all 6 players, each tap on $3,000,000$ Pokemon, then the number of shiny Pokemon they will get is in fact $6$ times  if we only allow 1 player to play.  How can we understand this ""6 times yes and no"" dilemma?",,['probability']
77,"Chances of rolling ""Snake Eyes"" at least once in a series of rolls.","Chances of rolling ""Snake Eyes"" at least once in a series of rolls.",,"So I know that if you roll a standard pair of dice, your chances of getting Snake Eyes (double 1s) is $1$ in $36$ . What I'm not sure of is how to do the math to figure out your chances of rolling Snake Eyes at least once during a series of rolls. I know if I roll the dice $36$ times it won't lead to a $100\%$ chance of rolling Snake Eyes, and while I imagine it's in the upper nineties, I'd like to figure out exactly how unlikely it is.","So I know that if you roll a standard pair of dice, your chances of getting Snake Eyes (double 1s) is in . What I'm not sure of is how to do the math to figure out your chances of rolling Snake Eyes at least once during a series of rolls. I know if I roll the dice times it won't lead to a chance of rolling Snake Eyes, and while I imagine it's in the upper nineties, I'd like to figure out exactly how unlikely it is.",1 36 36 100\%,"['probability', 'dice']"
78,What's the probability that Abe will win the dice game?,What's the probability that Abe will win the dice game?,,"Abe and Bill are playing a game.  A die is rolled each turn. If the die lands 1 or 2, then Abe wins. If the die lands 3, 4, or 5, then Bill wins. If the die lands 6, another turn occurs. What's the probability that Abe will win the game? I think that the probability is $\frac{2}{5}$ just by counting the number of ways for Abe to win. I'm not sure how to formalize this though in terms of a geometric distribution.","Abe and Bill are playing a game.  A die is rolled each turn. If the die lands 1 or 2, then Abe wins. If the die lands 3, 4, or 5, then Bill wins. If the die lands 6, another turn occurs. What's the probability that Abe will win the game? I think that the probability is $\frac{2}{5}$ just by counting the number of ways for Abe to win. I'm not sure how to formalize this though in terms of a geometric distribution.",,['probability']
79,What is the intuition behind $\mathbb{P} (A \text{ and }B) = \mathbb{P}(A) ยท \mathbb{P}(B)$ if they are independent events?,What is the intuition behind  if they are independent events?,\mathbb{P} (A \text{ and }B) = \mathbb{P}(A) ยท \mathbb{P}(B),I am unable to understand this formula intuitively.,I am unable to understand this formula intuitively.,,"['probability', 'intuition']"
80,A fair coin is flipped $100000$ times and you get $100000$ Heads in a row. What is the probability that you get Heads on $100001$th flip?,A fair coin is flipped  times and you get  Heads in a row. What is the probability that you get Heads on th flip?,100000 100000 100001,"My Answer: $1/2$ My Reasoning: Each coin flip is an independent event, outcome of which doesn't depend on preceding flips. So, even though the probability of $100000$ heads in a row is very low, the probability of next coin to be a head is $1/2$ itself. An answer by a peer: $1$ Their reasoning: Its very naรฏve to say that the probability will be $1/2$ without considering the Bayesian approach which considers the information of both data as well as the prior distribution of parameter, here one can easily check the posterior probability to be $1$ with simple Bayesian analysis. So, what is the correct acceptable answer? What is the correct reasoning here? If their answer is correct, please explain me how Bayesian approach is used here.","My Answer: My Reasoning: Each coin flip is an independent event, outcome of which doesn't depend on preceding flips. So, even though the probability of heads in a row is very low, the probability of next coin to be a head is itself. An answer by a peer: Their reasoning: Its very naรฏve to say that the probability will be without considering the Bayesian approach which considers the information of both data as well as the prior distribution of parameter, here one can easily check the posterior probability to be with simple Bayesian analysis. So, what is the correct acceptable answer? What is the correct reasoning here? If their answer is correct, please explain me how Bayesian approach is used here.",1/2 100000 1/2 1 1/2 1,"['probability', 'independence', 'bayesian']"
81,should I learn measure theory before learning probability?,should I learn measure theory before learning probability?,,I am currently looking to learn about probability and statistics since I am interested in actuarial science. I have some knowledge on real analysis(rudins book except the last 2 chapters) and linear algebra(axlers linear algebra done right). I have very little prior knowledge about prob/stat. When researching prob/stat books to order I encountered the distinction between books that use measure theory and those that don't. Anyway I am not really sure where to start and was wondering if someone could kindly recommend some books and which order to read them in.,I am currently looking to learn about probability and statistics since I am interested in actuarial science. I have some knowledge on real analysis(rudins book except the last 2 chapters) and linear algebra(axlers linear algebra done right). I have very little prior knowledge about prob/stat. When researching prob/stat books to order I encountered the distinction between books that use measure theory and those that don't. Anyway I am not really sure where to start and was wondering if someone could kindly recommend some books and which order to read them in.,,"['probability', 'measure-theory', 'book-recommendation']"
82,Intuition: Why chance of getting at least one ace when rolling a dice six times is not close to $1$?,Intuition: Why chance of getting at least one ace when rolling a dice six times is not close to ?,1,"So probability of getting $1$ ace (the one dot in dice) = $1/6$ i.e. in one out of six times we will get an ace. But when we calculate the probability of getting at least one ace in six rolls, we get $$= 1-\left(\frac{5}{6}\right)^6$$ $$= 0.665$$ I understand how the value is derived. But what is intuitive explanation for the same? Since it is so close to $68\%$ , the percentage of population within $1$ standard deviation of normal distribution, does it have any relationship with normal distribution?","So probability of getting ace (the one dot in dice) = i.e. in one out of six times we will get an ace. But when we calculate the probability of getting at least one ace in six rolls, we get I understand how the value is derived. But what is intuitive explanation for the same? Since it is so close to , the percentage of population within standard deviation of normal distribution, does it have any relationship with normal distribution?",1 1/6 = 1-\left(\frac{5}{6}\right)^6 = 0.665 68\% 1,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'dice']"
83,What is the probability that the digit sum of a randomly chosen integer between 0000 and 9999 is divisible by 5?,What is the probability that the digit sum of a randomly chosen integer between 0000 and 9999 is divisible by 5?,,"If I have a randomly selected integer between 0000 and 9999, what is the probability that the digit sum of that number is divisible by 5?  [E.g. 1234 = 1 + 2 + 3 + 4 = 10] I've started off with knowing that I have 2 options for the last integer, but I'm not sure where to go from there.","If I have a randomly selected integer between 0000 and 9999, what is the probability that the digit sum of that number is divisible by 5?  [E.g. 1234 = 1 + 2 + 3 + 4 = 10] I've started off with knowing that I have 2 options for the last integer, but I'm not sure where to go from there.",,"['probability', 'combinatorics', 'discrete-mathematics']"
84,Does every set have a power set?,Does every set have a power set?,,"While reading the probability space in Wikipedia, I'd found the usual formulation is a triplet, which is ${\displaystyle (\Omega ,{\mathcal {F}},P)}$. Upon my understanding, the middle ${\mathcal {F}}$ is a power set of $\Omega$ which will be allocated with real-valued probabiilty by $P$. If every set in this nature has power set, there might be no necessity of introduction of ${\mathcal {F}}$ I guess however, I've never thought of a set which doesn't have its power set. Is there any set that doesn't have power set? or if not, which means every set has its power set, is there any plausible reason that ${\mathcal {F}}$ is introduced in probability formulation?","While reading the probability space in Wikipedia, I'd found the usual formulation is a triplet, which is ${\displaystyle (\Omega ,{\mathcal {F}},P)}$. Upon my understanding, the middle ${\mathcal {F}}$ is a power set of $\Omega$ which will be allocated with real-valued probabiilty by $P$. If every set in this nature has power set, there might be no necessity of introduction of ${\mathcal {F}}$ I guess however, I've never thought of a set which doesn't have its power set. Is there any set that doesn't have power set? or if not, which means every set has its power set, is there any plausible reason that ${\mathcal {F}}$ is introduced in probability formulation?",,"['probability', 'elementary-set-theory']"
85,Math story: Ten marriage candidates and 'greatest of all time',Math story: Ten marriage candidates and 'greatest of all time',,"I remember a story about a famous mathematician who was offered ten marriage candidates and had to pick one of them, with the condition he had to meet them in turn and propose during that meeting, with no changing his mind to an earlier one. If he went through all ten without proposing then it was too bad for him. This caused him to develop a mathematical formula to maximise the odds of knowing when he met the best one based on how many times he met a 'best candidate so far', and he proposed to the seventh (I think). Could someone remind me who he was?","I remember a story about a famous mathematician who was offered ten marriage candidates and had to pick one of them, with the condition he had to meet them in turn and propose during that meeting, with no changing his mind to an earlier one. If he went through all ten without proposing then it was too bad for him. This caused him to develop a mathematical formula to maximise the odds of knowing when he met the best one based on how many times he met a 'best candidate so far', and he proposed to the seventh (I think). Could someone remind me who he was?",,"['probability', 'math-history']"
86,"Confusion with regards to the phrase ""exactly one of the events occurs""","Confusion with regards to the phrase ""exactly one of the events occurs""",,"Suppose we have events $A$ and $B$. We want to write the probability that exactly one of the events $A,B$ occurs in terms of $P(A),P(B)$ and $P(A \cap B)$ only My thought: Since I want only one occurring, $A$ or $B$, we must find $P(A \cup B)$ which equals $P(A) + P(B) - P(A \cap B)$.. However, on my answer sheet it says the answer is $P(A) + P(B) - 2P(A \cap B )$. Am I missing something?","Suppose we have events $A$ and $B$. We want to write the probability that exactly one of the events $A,B$ occurs in terms of $P(A),P(B)$ and $P(A \cap B)$ only My thought: Since I want only one occurring, $A$ or $B$, we must find $P(A \cup B)$ which equals $P(A) + P(B) - P(A \cap B)$.. However, on my answer sheet it says the answer is $P(A) + P(B) - 2P(A \cap B )$. Am I missing something?",,[]
87,Find the Mean for Non-Negative Integer-Valued Random Variable,Find the Mean for Non-Negative Integer-Valued Random Variable,,"Let $X$ be a non-negative integer-valued random variable with finite mean. Show that $$E(X)=\sum^\infty_{n=0}P(X>n)$$ This is the hint from my lecturer. ""Start with the definition $E(X)=\sum^\infty_{x=1}xP(X=x)$. Rewrite the series as double sum."" For my opinion. I think the double sum have the form of $\sum\sum f(x)$, but how to get this form? And how to continue?","Let $X$ be a non-negative integer-valued random variable with finite mean. Show that $$E(X)=\sum^\infty_{n=0}P(X>n)$$ This is the hint from my lecturer. ""Start with the definition $E(X)=\sum^\infty_{x=1}xP(X=x)$. Rewrite the series as double sum."" For my opinion. I think the double sum have the form of $\sum\sum f(x)$, but how to get this form? And how to continue?",,"['probability', 'random-variables', 'expected-value', 'faq']"
88,Conditional expectation for a sum of iid random variables: $E(\xi\mid\xi+\eta)=E(\eta\mid\xi+\eta)=\frac{\xi+\eta}{2}$,Conditional expectation for a sum of iid random variables:,E(\xi\mid\xi+\eta)=E(\eta\mid\xi+\eta)=\frac{\xi+\eta}{2},"I don't really know how to start proving this question. Let $\xi$ and $\eta$ be independent, identically distributed random variables with $E(|\xi|)$ finite. Show that $E(\xi\mid\xi+\eta)=E(\eta\mid\xi+\eta)=\frac{\xi+\eta}{2}$ Does anyone here have any idea for starting this question?","I don't really know how to start proving this question. Let $\xi$ and $\eta$ be independent, identically distributed random variables with $E(|\xi|)$ finite. Show that $E(\xi\mid\xi+\eta)=E(\eta\mid\xi+\eta)=\frac{\xi+\eta}{2}$ Does anyone here have any idea for starting this question?",,"['probability', 'probability-theory', 'conditional-expectation']"
89,"Sending a message in bit form, calculate the chance that the message is in its original form after transfer","Sending a message in bit form, calculate the chance that the message is in its original form after transfer",,"A message consists of 100 bits (either 0 or 1), of which every bit can change (from 0 to 1 or the other way around) during the data transfer with probability p = 0,001 (independently of other bits). What is the probability that a message is in its original form after 10 data transfers? Is my reasoning correct here (my answer): In order to calculate the probability that a message is in its original form after 10 data transfers we first have to calculate the probability of one bit being transferred correctly and then do that for the next 100 bits to lastly calculate the probability of doing this 9 more times (10 total). so: P(X=100) = (1-p)^100 = (0.999)^100 and for 10 total transfers we get P(X=10) = ((1-p)^100)^10 == (0.999)^1000 ~= 0.3677 so the probability that the message is received in its original form is 0.3677 (~36.8%)","A message consists of 100 bits (either 0 or 1), of which every bit can change (from 0 to 1 or the other way around) during the data transfer with probability p = 0,001 (independently of other bits). What is the probability that a message is in its original form after 10 data transfers? Is my reasoning correct here (my answer): In order to calculate the probability that a message is in its original form after 10 data transfers we first have to calculate the probability of one bit being transferred correctly and then do that for the next 100 bits to lastly calculate the probability of doing this 9 more times (10 total). so: P(X=100) = (1-p)^100 = (0.999)^100 and for 10 total transfers we get P(X=10) = ((1-p)^100)^10 == (0.999)^1000 ~= 0.3677 so the probability that the message is received in its original form is 0.3677 (~36.8%)",,['probability']
90,"The probability that A hits a target is $\frac14$ and that of B is $\frac13$. If they fire at once and one hits the target, find $P(\text{A hits})$","The probability that A hits a target is  and that of B is . If they fire at once and one hits the target, find",\frac14 \frac13 P(\text{A hits}),"The probability that A hits a target is 1/4 and the probability that B hits a target 1/3. They each fire once at the target. If the target is hit by only one of them, what is the probability that A hits the target? I know that this is an independent event. If I do P(A hitting) * P(B not hitting) then (1/4)(2/3) = 1/6 But when I look at the back of my book the answer is 2/5?  My book is known to give wrong answers because it is quite old; therefore, I am left with self doubt. Can anyone tell me if I have the correct answer or if I am actually making a mistake?","The probability that A hits a target is 1/4 and the probability that B hits a target 1/3. They each fire once at the target. If the target is hit by only one of them, what is the probability that A hits the target? I know that this is an independent event. If I do P(A hitting) * P(B not hitting) then (1/4)(2/3) = 1/6 But when I look at the back of my book the answer is 2/5?  My book is known to give wrong answers because it is quite old; therefore, I am left with self doubt. Can anyone tell me if I have the correct answer or if I am actually making a mistake?",,['probability']
91,Picking Multiples of 4,Picking Multiples of 4,,"I recently came up with and tried to solve the following problem: If you are randomly picking integers in the range $[1,30]$ out of a hat without replacement, on average, how many integers will you have to pick until you have picked all of the multiples of $4$? There are $7$ multiples of $4$ that can be chosen. I know that the expected value of picks until you pick a multiple of 4 is the smallest value of $n$ such that $1-\displaystyle\prod_{i=0}^{n-1}\dfrac{23-i}{30-i}>0.5$, which is $3$. However, I don't know how to figure out how many picks are needed until all multiples of $4$ have been chosen. Can I please have some assistance?","I recently came up with and tried to solve the following problem: If you are randomly picking integers in the range $[1,30]$ out of a hat without replacement, on average, how many integers will you have to pick until you have picked all of the multiples of $4$? There are $7$ multiples of $4$ that can be chosen. I know that the expected value of picks until you pick a multiple of 4 is the smallest value of $n$ such that $1-\displaystyle\prod_{i=0}^{n-1}\dfrac{23-i}{30-i}>0.5$, which is $3$. However, I don't know how to figure out how many picks are needed until all multiples of $4$ have been chosen. Can I please have some assistance?",,"['probability', 'combinatorics']"
92,Probability sum of 5 before sum of 7,Probability sum of 5 before sum of 7,,"Pair of fair die are rolled (independently I hope) infinitely. Find probability sum of 5 appears before sum of 7. 2 approaches: $$P(\text{sum of 5 appears before sum of 7})$$ $$= P(\text{roll 1 is 5})$$ $$+ P(\text{roll 2 is 5, roll 1 is not 7})$$ $$+ P(\text{roll 3 is 5, roll 1,2 are not 7})$$ $$+ P(\text{roll 4 is 5, roll 1,2,3 are not 7})$$ $$+ \ldots$$ $$P(\text{sum of 5 appears before sum of 7})$$ $$= P(\text{roll 1 is 5})$$ $$+ P(\text{roll 2 is 5, roll 1 is not 7}, \ \color{red}{\text{roll 1 is not 5}})$$ $$+ P(\text{roll 3 is 5, roll 1,2 are not 7}, \ \color{red}{\text{roll 1,2 are not 5}})$$ $$+ P(\text{roll 4 is 5, roll 1,2,3 are not 7}, \ \color{red}{\text{roll 1,2,3 are not 5}})$$ $$+ \ldots$$ Which if any is right? Mathematically: Let $n = 1,2,...$ Let $A_n$ be probability that sum of 5 appears on roll $n$ Let $B_n$ be probability that sum of 7 appears on roll $n$ Let $B_0^C = \Omega$ Observe that $A_n$ and $B_n$ are disjoint. Hence $A_n \subseteq B_n^C$ Approach 1 gives: $$\sum_{n=1}^{\infty} P(A_n \cap \bigcap_{m=0}^{n} B_m^C)$$ $$\sum_{n=1}^{\infty} P(A_n \cap \bigcap_{m=0}^{\color{red}{n-1}} B_m^C)$$ $$ = \frac{4}{36} \sum_{n=1}^{\infty} (\frac{30}{36})^{n-1}$$ Approach 2 gives: $$\sum_{n=1}^{\infty} P(A_n \cap \bigcap_{m=0}^{n} B_m^C \color{red}{\cap \bigcap_{m=0}^{n-1} A_m^C})$$ $$\sum_{n=1}^{\infty} P(A_n \cap \bigcap_{m=0}^{\color{red}{n-1}} B_m^C \color{red}{\cap \bigcap_{m=0}^{n-1} A_m^C})$$ $$ = \frac{4}{36} \sum_{n=1}^{\infty} (\frac{30}{36})^{n-1} \color{red}{(\frac{32}{36})^{n-1}}$$ What is the weakest independence assumption we need to make? For approach 1 it seems that we need to assume independence of $$A_n, B_1, B_2, ..., B_{n-1}$$. For approach 2 it seems that we need to assume independence of $$A_1, A_2, ..., A_n, B_1, B_2, ..., B_{n-1}$$. Is that right?","Pair of fair die are rolled (independently I hope) infinitely. Find probability sum of 5 appears before sum of 7. 2 approaches: $$P(\text{sum of 5 appears before sum of 7})$$ $$= P(\text{roll 1 is 5})$$ $$+ P(\text{roll 2 is 5, roll 1 is not 7})$$ $$+ P(\text{roll 3 is 5, roll 1,2 are not 7})$$ $$+ P(\text{roll 4 is 5, roll 1,2,3 are not 7})$$ $$+ \ldots$$ $$P(\text{sum of 5 appears before sum of 7})$$ $$= P(\text{roll 1 is 5})$$ $$+ P(\text{roll 2 is 5, roll 1 is not 7}, \ \color{red}{\text{roll 1 is not 5}})$$ $$+ P(\text{roll 3 is 5, roll 1,2 are not 7}, \ \color{red}{\text{roll 1,2 are not 5}})$$ $$+ P(\text{roll 4 is 5, roll 1,2,3 are not 7}, \ \color{red}{\text{roll 1,2,3 are not 5}})$$ $$+ \ldots$$ Which if any is right? Mathematically: Let $n = 1,2,...$ Let $A_n$ be probability that sum of 5 appears on roll $n$ Let $B_n$ be probability that sum of 7 appears on roll $n$ Let $B_0^C = \Omega$ Observe that $A_n$ and $B_n$ are disjoint. Hence $A_n \subseteq B_n^C$ Approach 1 gives: $$\sum_{n=1}^{\infty} P(A_n \cap \bigcap_{m=0}^{n} B_m^C)$$ $$\sum_{n=1}^{\infty} P(A_n \cap \bigcap_{m=0}^{\color{red}{n-1}} B_m^C)$$ $$ = \frac{4}{36} \sum_{n=1}^{\infty} (\frac{30}{36})^{n-1}$$ Approach 2 gives: $$\sum_{n=1}^{\infty} P(A_n \cap \bigcap_{m=0}^{n} B_m^C \color{red}{\cap \bigcap_{m=0}^{n-1} A_m^C})$$ $$\sum_{n=1}^{\infty} P(A_n \cap \bigcap_{m=0}^{\color{red}{n-1}} B_m^C \color{red}{\cap \bigcap_{m=0}^{n-1} A_m^C})$$ $$ = \frac{4}{36} \sum_{n=1}^{\infty} (\frac{30}{36})^{n-1} \color{red}{(\frac{32}{36})^{n-1}}$$ What is the weakest independence assumption we need to make? For approach 1 it seems that we need to assume independence of $$A_n, B_1, B_2, ..., B_{n-1}$$. For approach 2 it seems that we need to assume independence of $$A_1, A_2, ..., A_n, B_1, B_2, ..., B_{n-1}$$. Is that right?",,"['probability', 'summation', 'mathematical-modeling', 'dice', 'independence']"
93,Probability that sheepdog performs at least one task successfuly - Am I doing this problem right?,Probability that sheepdog performs at least one task successfuly - Am I doing this problem right?,,"What is the probability that a sheepdog performs at least $1$ of these tasks successfully? My approach is to subtract the probability of performing at most $1$ of these tasks successfully from the probability of performing all $4$ tasks successfully. $P(\text{fetch})=.9, P(\text{drive})=.7, P(\text{herd})=.84, P(\text{separate})=.75$ . The complement of these four probabilities is, $.1,.3,.16,$ and $,.25$ , respectively. So the probability that the sheepdog performs all four tasks successfully is simply, $(.9)(.7)(.84)(.75)$ . The probability that the sheepdog performs at most $1$ task successfully can be split into $4$ cases. Either the sheepdog performs the fetch task (and not the other 3) successfully, performs the drive task, performs the herd task, or performs the separate task. This would look like: $(.9)(.3)(.16)(.25)+(.1)(.7)(.16)(.25)+(.1)(.3)(.84)(.25)+(.1)(.3)(.16)(.75)$ Subtracting this from the case in which the sheepdog performs all four tasks would yield: $(.9)(.7)(.84)(.75)-[(.9)(.3)(.16)(.25)+(.1)(.7)(.16)(.25)+(.1)(.3)(.84)(.25)+(.1)(.3)(.16)(.75)]$ . Is this correct?","What is the probability that a sheepdog performs at least of these tasks successfully? My approach is to subtract the probability of performing at most of these tasks successfully from the probability of performing all tasks successfully. . The complement of these four probabilities is, and , respectively. So the probability that the sheepdog performs all four tasks successfully is simply, . The probability that the sheepdog performs at most task successfully can be split into cases. Either the sheepdog performs the fetch task (and not the other 3) successfully, performs the drive task, performs the herd task, or performs the separate task. This would look like: Subtracting this from the case in which the sheepdog performs all four tasks would yield: . Is this correct?","1 1 4 P(\text{fetch})=.9, P(\text{drive})=.7, P(\text{herd})=.84, P(\text{separate})=.75 .1,.3,.16, ,.25 (.9)(.7)(.84)(.75) 1 4 (.9)(.3)(.16)(.25)+(.1)(.7)(.16)(.25)+(.1)(.3)(.84)(.25)+(.1)(.3)(.16)(.75) (.9)(.7)(.84)(.75)-[(.9)(.3)(.16)(.25)+(.1)(.7)(.16)(.25)+(.1)(.3)(.84)(.25)+(.1)(.3)(.16)(.75)]","['probability', 'combinatorics']"
94,Random walk over a cube:Probability of returning back,Random walk over a cube:Probability of returning back,,"There is a cube and an ant is performing a random walk on the edges where it can select any of the 3 adjoining vertices with equal probability. What is the probability that ant is in the vertex it started with after N steps? What I tried-> Breaking problem to simpler one where we see distance from start vertex. So out of 8 vertices, we have 1 with distance 0(our start), 3 with distance 1, 3 with distance 2 and 1 with distance 3. Also, ant can only return back if N is even. So probability is 0 when N is odd.","There is a cube and an ant is performing a random walk on the edges where it can select any of the 3 adjoining vertices with equal probability. What is the probability that ant is in the vertex it started with after N steps? What I tried-> Breaking problem to simpler one where we see distance from start vertex. So out of 8 vertices, we have 1 with distance 0(our start), 3 with distance 1, 3 with distance 2 and 1 with distance 3. Also, ant can only return back if N is even. So probability is 0 when N is odd.",,"['probability', 'markov-chains']"
95,What's wrong with this equal probability solution for Monty Hall Problem?,What's wrong with this equal probability solution for Monty Hall Problem?,,"I'm confused about why we should change door in the Monty Hall Problem, when thinking from a different perspective  gives me equal probability. Think about this first: if we have two doors, and one car behind one of them, then we have a 50/50 chance of choosing the right door. Back to Monty Hall: after we pick a door, one door is opened and shows a goat, and the other door remains closed. Let's call the door we picked A and the  other closed door B. Now since 1 door has already been opened, our knowledge has changed such that the car can only be behind A or B. Therefore, the problem is equivalent to: given two closed doors (A and B) and one car, which door should be chosen (we know it's a 50/50 thing)? Then, not switching door = choosing A, and switching door = choosing B. Therefore, it seems that switching should be equally likely, instead of more likely. Another way to think: no matter which door we choose from the three, we know BEFOREHAND that we can definitely open a door with a goat in the remaining two. Therefore, showing an open door with a goat reveals nothing new about which door has the car. What's wrong with this thinking process? (Note that I know the argument why switching gives advantage, and I know experiments have been done to prove that. My question is why the above thinking, which seems legit, is actually wrong.) Thanks.","I'm confused about why we should change door in the Monty Hall Problem, when thinking from a different perspective  gives me equal probability. Think about this first: if we have two doors, and one car behind one of them, then we have a 50/50 chance of choosing the right door. Back to Monty Hall: after we pick a door, one door is opened and shows a goat, and the other door remains closed. Let's call the door we picked A and the  other closed door B. Now since 1 door has already been opened, our knowledge has changed such that the car can only be behind A or B. Therefore, the problem is equivalent to: given two closed doors (A and B) and one car, which door should be chosen (we know it's a 50/50 thing)? Then, not switching door = choosing A, and switching door = choosing B. Therefore, it seems that switching should be equally likely, instead of more likely. Another way to think: no matter which door we choose from the three, we know BEFOREHAND that we can definitely open a door with a goat in the remaining two. Therefore, showing an open door with a goat reveals nothing new about which door has the car. What's wrong with this thinking process? (Note that I know the argument why switching gives advantage, and I know experiments have been done to prove that. My question is why the above thinking, which seems legit, is actually wrong.) Thanks.",,"['probability', 'monty-hall']"
96,Is it unlikely to get the same number of heads/tails?,Is it unlikely to get the same number of heads/tails?,,"A question in probability by a non-mathematician: A fair coin is tossed $2N$ times. Is it unlikely that we get exactly $N$ heads and $N$ tails? From one side, this must be the most likely result! But intuitively, if someone reports to me that they threw 2,000,000 coins and got exactly 1,000,000 heads and 1,000,000 tails I would be a little suspicious. If this really is suspicious, how does it compare to biased results? Obviously, 2,000,000 heads is a much more suspicious result. But, for what value of $K$ is $N+K$ heads and $N-K$ tails as suspicious as $N$ heads and $N$ tails? Equations are very welcome, but please try to provide some aid in understanding them. ADDED : Henning Makholm's answer helped me understand better what I want to ask: I always assume a fair coin and would like to compare the probability of the split N/N with the probability of getting either more than more than N+K or less than N-K heads. By ncmathsadist's answer , the probability for the N/N split goes like 1 over the square root of N.  What about the probability to get more than either more than N+K or less than N-K heads? For what value of K (approximately) does it equal to 1/sqrt(n pi)? CLARIFICATION : If f(N) is the probability to get an N/N split in 2N tosses of a fair coin, and g(N,K) is the probability to get more that N+K heads or less than N-K heads in 2N tosses of a fair coin, then I am asking for a formula which, given N, approximates the values of K for each f(N) is closest to g(N,K). This is a formula that takes N and returns K so we can call it h(N)=K. Which kind of function is h? My guess from a little experementing with the online software in Brian M. Scott's answer is that the function h is apporximately the SQRT function, multiplied by some constant, or something like that.","A question in probability by a non-mathematician: A fair coin is tossed $2N$ times. Is it unlikely that we get exactly $N$ heads and $N$ tails? From one side, this must be the most likely result! But intuitively, if someone reports to me that they threw 2,000,000 coins and got exactly 1,000,000 heads and 1,000,000 tails I would be a little suspicious. If this really is suspicious, how does it compare to biased results? Obviously, 2,000,000 heads is a much more suspicious result. But, for what value of $K$ is $N+K$ heads and $N-K$ tails as suspicious as $N$ heads and $N$ tails? Equations are very welcome, but please try to provide some aid in understanding them. ADDED : Henning Makholm's answer helped me understand better what I want to ask: I always assume a fair coin and would like to compare the probability of the split N/N with the probability of getting either more than more than N+K or less than N-K heads. By ncmathsadist's answer , the probability for the N/N split goes like 1 over the square root of N.  What about the probability to get more than either more than N+K or less than N-K heads? For what value of K (approximately) does it equal to 1/sqrt(n pi)? CLARIFICATION : If f(N) is the probability to get an N/N split in 2N tosses of a fair coin, and g(N,K) is the probability to get more that N+K heads or less than N-K heads in 2N tosses of a fair coin, then I am asking for a formula which, given N, approximates the values of K for each f(N) is closest to g(N,K). This is a formula that takes N and returns K so we can call it h(N)=K. Which kind of function is h? My guess from a little experementing with the online software in Brian M. Scott's answer is that the function h is apporximately the SQRT function, multiplied by some constant, or something like that.",,['probability']
97,Flipping a set of unfair coins [closed],Flipping a set of unfair coins [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let's say I have $5$ unfair coins. Each with an independent, known, probability of landing on heads. I flip each coin once. How can I find the probability that I get $3$ or more heads? Example: $P(H_1) = .38$ $P(H_2) = .18$ $P(H_3) = .71$ $P(H_4) = .66$ $P(H_5) = .29$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let's say I have $5$ unfair coins. Each with an independent, known, probability of landing on heads. I flip each coin once. How can I find the probability that I get $3$ or more heads? Example: $P(H_1) = .38$ $P(H_2) = .18$ $P(H_3) = .71$ $P(H_4) = .66$ $P(H_5) = .29$",,"['probability', 'statistics', 'generating-functions']"
98,union of two independent probabilistic event,union of two independent probabilistic event,,I have following question: Suppose we have two independent events whose probability are the following: $P(A)=0.4$ and $P(B)=0.7$. We are asked to find $P(A \cap B)$ from probability theory. I know that $P(A \cup B)=P(A)+P(B)-P(A \cap B)$. But surely the last one is equal zero so it means that  result should be $P(A)+P(B)$ but it is more than $1$ (To be exact it is $1.1$). Please help me where i am wrong?,I have following question: Suppose we have two independent events whose probability are the following: $P(A)=0.4$ and $P(B)=0.7$. We are asked to find $P(A \cap B)$ from probability theory. I know that $P(A \cup B)=P(A)+P(B)-P(A \cap B)$. But surely the last one is equal zero so it means that  result should be $P(A)+P(B)$ but it is more than $1$ (To be exact it is $1.1$). Please help me where i am wrong?,,"['probability', 'independence']"
99,Probability of rolling a double $6$ with two dice,Probability of rolling a double  with two dice,6,"Two dice (with numbers 1 to 6 on the faces) are rolled. One die rolls a 6. What is the probability of rolling a double 6? One solution is to say that P(2 sixes) = $\frac{1}{6}$ since the first die gives a 6, so the only way to get a double six is by rolling a six on the other die (which has a 1 in 6 chance). Another solution is to say that there are 11 possible combinations if one die rolls a six i.e. (1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6), (6, 5), (6, 4), (6, 3), (6, 2) and (6, 1). So the probability of rolling a double six if one six has already been rolled is $\frac{1}{11}$. Which answer is correct and why?","Two dice (with numbers 1 to 6 on the faces) are rolled. One die rolls a 6. What is the probability of rolling a double 6? One solution is to say that P(2 sixes) = $\frac{1}{6}$ since the first die gives a 6, so the only way to get a double six is by rolling a six on the other die (which has a 1 in 6 chance). Another solution is to say that there are 11 possible combinations if one die rolls a six i.e. (1, 6), (2, 6), (3, 6), (4, 6), (5, 6), (6, 6), (6, 5), (6, 4), (6, 3), (6, 2) and (6, 1). So the probability of rolling a double six if one six has already been rolled is $\frac{1}{11}$. Which answer is correct and why?",,['probability']
