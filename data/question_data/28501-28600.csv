,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Four men, hats and probability","Four men, hats and probability",,"I encountered the four men in hats puzzle for the first time today. My question is about a realisation I (think I) had while arriving at the solution, but I have no idea whether I've made a mistake somewhere. Before I got to the actual answer, I was thinking about each man's chances of correctly guessing his hat colour. My thought process went something along these lines: At first blush, D has the best chances, as he can see the most. Hang on - D has only a 1 in 2 chance, the same as anyone else. Anyone else? No - C can see that B has a white hat, so he knows there's only one other. It can be on one of three heads, so if he guesses that his own is black, his chances of being right are 2 in 3. What threw me about this, assuming that last realisation isn't flawed in some way, is that D can also see that B has a white hat. Somehow, C has a better chance of being right, even though D (in some sense) has more knowledge, at least for this configuration of hats. What am I missing? UPDATE Thanks for the answers so far. I don't think I was very clear on what I was asking though: I did manage to solve the puzzle, but what confused me was the realisation I outlined above while getting there. Forgetting the original goal of the puzzle (how do the men reason about the solution) and only taking into consideration their chances of successfully guessing , how do I explain the fact that C's chances seem better than D's, even though D can see everything that C can, and more?","I encountered the four men in hats puzzle for the first time today. My question is about a realisation I (think I) had while arriving at the solution, but I have no idea whether I've made a mistake somewhere. Before I got to the actual answer, I was thinking about each man's chances of correctly guessing his hat colour. My thought process went something along these lines: At first blush, D has the best chances, as he can see the most. Hang on - D has only a 1 in 2 chance, the same as anyone else. Anyone else? No - C can see that B has a white hat, so he knows there's only one other. It can be on one of three heads, so if he guesses that his own is black, his chances of being right are 2 in 3. What threw me about this, assuming that last realisation isn't flawed in some way, is that D can also see that B has a white hat. Somehow, C has a better chance of being right, even though D (in some sense) has more knowledge, at least for this configuration of hats. What am I missing? UPDATE Thanks for the answers so far. I don't think I was very clear on what I was asking though: I did manage to solve the puzzle, but what confused me was the realisation I outlined above while getting there. Forgetting the original goal of the puzzle (how do the men reason about the solution) and only taking into consideration their chances of successfully guessing , how do I explain the fact that C's chances seem better than D's, even though D can see everything that C can, and more?",,"['probability', 'intuition', 'puzzle']"
1,43 cookies are randomly given to 10 children. What's the probability each child receives at least 2 cookies?,43 cookies are randomly given to 10 children. What's the probability each child receives at least 2 cookies?,,"I wanted to ask 1) if I've solved this puzzle problem correctly, and 2) if there is a shorter or more elegant approach. There are 43 cookies to be given out at random to 10 children. What is the probability that each child gets at least 2 cookies? First, notice that this is a classic multinomial setup. The multinomial distribution can be thought of as giving the probability of observing the outcome $i \in \{ 1, ..., k \}$ coming up $x_i$ times when rolling a $k$ -sided die $n$ times, and is a generalization of the Binomial distribution. We have that the probability of each outcome $i$ coming up on a single roll is given by $\pi_i$ . If the so-called die is fair, $\pi_i = \pi_{i'}\; \forall i, i' \in \{ 1, ..., k\}$ or the die is unfair and $\pi_i$ is not necessarily equal to $\pi_i'$ . In all cases, we assume $\sum \pi_i = 1$ . Let $X = (X_1, ..., X_k)$ be a $\text{Multinomial}(n, k, \pi)$ distributed where $\pi = (\pi_1, ..., \pi_k)$ . The density of the Multinomial distribution is \begin{align} P(X = x) & = {n \choose x_1,...,x_k!} \prod_{i=1}^k \pi_i^{x_i} \\\\ & = \frac{n!}{x_1!\cdots x_k!}\pi_1^{x_1} \cdots \pi_k^{x_k}. \end{align} Here, let $X_1, ..., X_{10}$ denote how many of the $n=43$ cookies each of the $k=10$ children received. Let $p_n$ denote the probability that all 10 children receive at least 2 cookies each given that $n$ are given out uniformly at random. Notice that $$ {\small X_1, ..., X_{10} \Bigg\vert \sum_{i=1}^{10} X_i = 43 \sim  \text{Multinomial}(n = 43, k = 10, \pi_i = 1/10),} $$ where $\pi_i = 1/10$ indicates that the distribution of cookies is uniformly random (e.g., equal probability) across the 10 children. The Poisson and Multinomial distributions have an interesting relationship. When the outcomes $X_1, ..., X_k$ are such that $X_i \sim \text{Poisson}(\lambda_i)$ , then $\sum_{i=1}^k X_i \sim \text{Poisson}(\sum_{i=1}^k \lambda_i).$ One can easily derive via the definition of conditional probability that $$(X_1, ..., X_k) {\Bigg\vert} \sum_{i=1}^k X_i = N = n \sim \text{Multinomial}(n, k, \pi),$$ where $\pi = \left(\frac{\lambda_1}{\sum \lambda_i}, ..., \frac{\lambda_k}{\sum \lambda_i}\right)$ . \begin{align} P(X = x \Big \vert N = n) & = \frac{P(X = x, N = n)}{P(N = n)}  \\\\  & = \frac{P(X = x)}{P(N = n)} \\\\  & = \left( \frac{e^{-\sum \lambda_i} \prod \lambda_i^{x_i}}{\prod x_i!} \right) \Bigg / \left( \frac{e^{-\sum \lambda_i} (\sum \lambda_i)^{n}}{n!} \right) \\\\  & = {n \choose x_1, ..., x_k} \frac{\prod \lambda_i^{x_i}}{\left( \sum \lambda_i \right)^n} \\\\  & = {n \choose x_1, ..., x_k} \left( \frac{\lambda_i}{\sum \lambda_i} \right)^{x_i} \\\\  & \sim \text{Multinomial}(n, k, \pi). \end{align} Since no information was given to us about how it came about that $n = 43$ cookies were given out, let's assume that it was the result of a $\text{Poisson}(\lambda)$ process. This implies that the $X_i$ are independently and identically distributed as $\text{Poisson}(\lambda/10)$ by a similar argument in the reverse direction. $$P(X = x \Bigg| \sum X_i = n) = \frac{P(X = x, \sum X_i = n)}{\underbrace{P(\sum X_i = n)}_{\text{Poisson}(\lambda)}},$$ and $X = x \implies \sum X_i = \sum x_i = n$ , so $P(X = x, \sum X_i = n) = P(X = x)$ as long as $n = \sum x_i$ . \begin{align} \therefore \;\; P(X = x) & = P(X = x \Bigg| \sum X_i = n) \cdot P(\sum X_i = n) \\\\  & = \left[ {n \choose \pi_1, ..., \pi_k} \prod \pi_i^{x_i} \right] \cdot \left( \frac{e^{-\lambda} \lambda^{\sum x_i}}{\sum x_i! } \right) \\\\  & = \frac{n!}{x_1!\cdots x_k!} \pi_1^{x_1}\cdots \pi_k^{x_k} \left( \frac{e^{-\lambda} \lambda^{n}}{n!} \right). \end{align} Assume as given in the problem that the cookies are uniformly randomly given out, and $\pi_i = \pi_{i'}\;  \forall i, i' \in \{ 1, ..., k \}$ ; this single probability must be $1/k$ (or in our case, $k = 10$ children). \begin{align} P(X = x) & = \frac{e^{-\lambda}}{x_1! \cdots x_k!} \left( \frac{\lambda}{k} \right)^{\sum x_i} \\\\ & = \prod_{i=1}^k \frac{e^{-\lambda/k} \left( \frac{\lambda}{k} \right)^{x_i}}{x_i!}, \\\\  \text{a product of the }&\text{density for $k$ iid Poisson}\left(\frac{\lambda}{k}\right) \text{ variables}. \end{align} We said that if $n$ cookies are given out, then there's a $p_n$ probability that the 10 children all receive 2+ cookies. Then without conditioning on the number of cookies given out, the probability that all kids receive 2+ cookies is given by $$\mathbb{E}\left[\mathbb{E}[p_n | N = n]\right] = \sum_{n=0}^\infty \frac{e^{-\lambda} \lambda^n}{n!} p_n.$$ On the other hand, since the $X_1, ..., X_k$ are iid Poisson, the probability that all 10 kids receive 2+ cookies is $P(X_1 \geq 2)^{10} = (1-P(X_1 \leq 1))^{10} =  (1-e^{-\frac{\lambda}{10}} - \frac{\lambda}{10}e^{-\frac{\lambda}{10}})^{10}$ . Now we have that $$ \sum_{n=0}^\infty \frac{e^{-\lambda} \lambda^n}{n!} p_n =  \left[1-e^{-\frac{\lambda}{10}} - \frac{\lambda}{10}e^{-\frac{\lambda}{10}}\right]^{10}. $$ Now, recall that $e^{x}$ has a series expansion. If we multiply both sides by $e^{\lambda}$ and by $43!$ , we should find that the coefficient on the left-hand-side series for $\lambda^{43}$ is just $p_n$ , and the right-hand-side series coefficient for $\lambda^{43}$ gives an expression we can evaluate for $p_{43}$ . They must be equal, because in order for two convergent power series to coincide on a non-empty interval, their coefficients must be equal. So what we're going to do is expand the function $e^{x} = \sum_{t=0}^\infty \frac{x^t}{t!}$ wherever we see it on the modified right-hand-side and use that to identify the coefficient of $\lambda^{43}$ , which is $p_{43}$ . However, this is a bit hard to do by hand, so we'll use the symbolic algebra library sympy in Python to do it for us. # Python code from sympy import symbols, exp, factorial, series, Pow  lambda_ = symbols('lambda')  inner_expression = 1 - exp(-lambda_/10) - (lambda_/10)*exp(-lambda_/10)  raised_expression = inner_expression**10   complete_expression = exp(lambda_) * raised_expression  expanded_series = series(complete_expression, x=lambda_, n=44).removeO()  coeff_lambda_43 = expanded_series.coeff(lambda_**43)  p_43 = factorial(43) * coeff_lambda_43 p_43 $$\frac{38360235213946776318553037176114920309}{78125000000000000000000000000000000000} \approx 0.491 $$ Thus we conclude that if 43 cookies are given out to 10 children uniformly at random, then the probability that each child receives at least 2 cookies is $\approx .491.$ Let's see if we can confirm that via a simple simulation in R: # R code set.seed(1234)  num_trials <- 100000  # Number of simulations num_children <- 10    # Number of children num_cookies <- 43     # Number of cookies  results <- replicate(num_trials, {   cookies <- sample(1:num_children, num_cookies, replace = TRUE)   counts <- table(factor(cookies, levels = 1:10))   all(counts >= 2) })  prob_estimate <- mean(results) var_estimate <- var(results) / num_trials  prob_estimate var_estimate > prob_estimate [1] 0.49178 > var_estimate [1] 2.499349e-06 The point-estimate is off by 0.0007689893. I'm not sure if the way I've calculated the variance is appropriate.","I wanted to ask 1) if I've solved this puzzle problem correctly, and 2) if there is a shorter or more elegant approach. There are 43 cookies to be given out at random to 10 children. What is the probability that each child gets at least 2 cookies? First, notice that this is a classic multinomial setup. The multinomial distribution can be thought of as giving the probability of observing the outcome coming up times when rolling a -sided die times, and is a generalization of the Binomial distribution. We have that the probability of each outcome coming up on a single roll is given by . If the so-called die is fair, or the die is unfair and is not necessarily equal to . In all cases, we assume . Let be a distributed where . The density of the Multinomial distribution is Here, let denote how many of the cookies each of the children received. Let denote the probability that all 10 children receive at least 2 cookies each given that are given out uniformly at random. Notice that where indicates that the distribution of cookies is uniformly random (e.g., equal probability) across the 10 children. The Poisson and Multinomial distributions have an interesting relationship. When the outcomes are such that , then One can easily derive via the definition of conditional probability that where . Since no information was given to us about how it came about that cookies were given out, let's assume that it was the result of a process. This implies that the are independently and identically distributed as by a similar argument in the reverse direction. and , so as long as . Assume as given in the problem that the cookies are uniformly randomly given out, and ; this single probability must be (or in our case, children). We said that if cookies are given out, then there's a probability that the 10 children all receive 2+ cookies. Then without conditioning on the number of cookies given out, the probability that all kids receive 2+ cookies is given by On the other hand, since the are iid Poisson, the probability that all 10 kids receive 2+ cookies is . Now we have that Now, recall that has a series expansion. If we multiply both sides by and by , we should find that the coefficient on the left-hand-side series for is just , and the right-hand-side series coefficient for gives an expression we can evaluate for . They must be equal, because in order for two convergent power series to coincide on a non-empty interval, their coefficients must be equal. So what we're going to do is expand the function wherever we see it on the modified right-hand-side and use that to identify the coefficient of , which is . However, this is a bit hard to do by hand, so we'll use the symbolic algebra library sympy in Python to do it for us. # Python code from sympy import symbols, exp, factorial, series, Pow  lambda_ = symbols('lambda')  inner_expression = 1 - exp(-lambda_/10) - (lambda_/10)*exp(-lambda_/10)  raised_expression = inner_expression**10   complete_expression = exp(lambda_) * raised_expression  expanded_series = series(complete_expression, x=lambda_, n=44).removeO()  coeff_lambda_43 = expanded_series.coeff(lambda_**43)  p_43 = factorial(43) * coeff_lambda_43 p_43 Thus we conclude that if 43 cookies are given out to 10 children uniformly at random, then the probability that each child receives at least 2 cookies is Let's see if we can confirm that via a simple simulation in R: # R code set.seed(1234)  num_trials <- 100000  # Number of simulations num_children <- 10    # Number of children num_cookies <- 43     # Number of cookies  results <- replicate(num_trials, {   cookies <- sample(1:num_children, num_cookies, replace = TRUE)   counts <- table(factor(cookies, levels = 1:10))   all(counts >= 2) })  prob_estimate <- mean(results) var_estimate <- var(results) / num_trials  prob_estimate var_estimate > prob_estimate [1] 0.49178 > var_estimate [1] 2.499349e-06 The point-estimate is off by 0.0007689893. I'm not sure if the way I've calculated the variance is appropriate.","i \in \{ 1, ..., k \} x_i k n i \pi_i \pi_i = \pi_{i'}\; \forall i, i' \in \{ 1, ..., k\} \pi_i \pi_i' \sum \pi_i = 1 X = (X_1, ..., X_k) \text{Multinomial}(n, k, \pi) \pi = (\pi_1, ..., \pi_k) \begin{align}
P(X = x) & = {n \choose x_1,...,x_k!} \prod_{i=1}^k \pi_i^{x_i} \\\\
& = \frac{n!}{x_1!\cdots x_k!}\pi_1^{x_1} \cdots \pi_k^{x_k}.
\end{align} X_1, ..., X_{10} n=43 k=10 p_n n 
{\small
X_1, ..., X_{10} \Bigg\vert \sum_{i=1}^{10} X_i = 43 \sim 
\text{Multinomial}(n = 43, k = 10, \pi_i = 1/10),}
 \pi_i = 1/10 X_1, ..., X_k X_i \sim \text{Poisson}(\lambda_i) \sum_{i=1}^k X_i \sim \text{Poisson}(\sum_{i=1}^k \lambda_i). (X_1, ..., X_k) {\Bigg\vert} \sum_{i=1}^k X_i = N = n \sim \text{Multinomial}(n, k, \pi), \pi = \left(\frac{\lambda_1}{\sum \lambda_i}, ..., \frac{\lambda_k}{\sum \lambda_i}\right) \begin{align}
P(X = x \Big \vert N = n) & = \frac{P(X = x, N = n)}{P(N = n)}  \\\\ 
& = \frac{P(X = x)}{P(N = n)} \\\\ 
& = \left( \frac{e^{-\sum \lambda_i} \prod \lambda_i^{x_i}}{\prod x_i!} \right) \Bigg / \left( \frac{e^{-\sum \lambda_i} (\sum \lambda_i)^{n}}{n!} \right) \\\\ 
& = {n \choose x_1, ..., x_k} \frac{\prod \lambda_i^{x_i}}{\left( \sum \lambda_i \right)^n} \\\\ 
& = {n \choose x_1, ..., x_k} \left( \frac{\lambda_i}{\sum \lambda_i} \right)^{x_i} \\\\ 
& \sim \text{Multinomial}(n, k, \pi).
\end{align} n = 43 \text{Poisson}(\lambda) X_i \text{Poisson}(\lambda/10) P(X = x \Bigg| \sum X_i = n) = \frac{P(X = x, \sum X_i = n)}{\underbrace{P(\sum X_i = n)}_{\text{Poisson}(\lambda)}}, X = x \implies \sum X_i = \sum x_i = n P(X = x, \sum X_i = n) = P(X = x) n = \sum x_i \begin{align}
\therefore \;\; P(X = x) & = P(X = x \Bigg| \sum X_i = n) \cdot P(\sum X_i = n) \\\\ 
& = \left[ {n \choose \pi_1, ..., \pi_k} \prod \pi_i^{x_i} \right] \cdot \left( \frac{e^{-\lambda} \lambda^{\sum x_i}}{\sum x_i! } \right) \\\\ 
& = \frac{n!}{x_1!\cdots x_k!} \pi_1^{x_1}\cdots \pi_k^{x_k} \left( \frac{e^{-\lambda} \lambda^{n}}{n!} \right).
\end{align} \pi_i = \pi_{i'}\;  \forall i, i' \in \{ 1, ..., k \} 1/k k = 10 \begin{align}
P(X = x) & = \frac{e^{-\lambda}}{x_1! \cdots x_k!} \left( \frac{\lambda}{k} \right)^{\sum x_i} \\\\
& = \prod_{i=1}^k \frac{e^{-\lambda/k} \left( \frac{\lambda}{k} \right)^{x_i}}{x_i!}, \\\\ 
\text{a product of the }&\text{density for k iid Poisson}\left(\frac{\lambda}{k}\right) \text{ variables}.
\end{align} n p_n \mathbb{E}\left[\mathbb{E}[p_n | N = n]\right] = \sum_{n=0}^\infty \frac{e^{-\lambda} \lambda^n}{n!} p_n. X_1, ..., X_k P(X_1 \geq 2)^{10} = (1-P(X_1 \leq 1))^{10} = 
(1-e^{-\frac{\lambda}{10}} - \frac{\lambda}{10}e^{-\frac{\lambda}{10}})^{10}  \sum_{n=0}^\infty \frac{e^{-\lambda} \lambda^n}{n!} p_n = 
\left[1-e^{-\frac{\lambda}{10}} - \frac{\lambda}{10}e^{-\frac{\lambda}{10}}\right]^{10}.
 e^{x} e^{\lambda} 43! \lambda^{43} p_n \lambda^{43} p_{43} e^{x} = \sum_{t=0}^\infty \frac{x^t}{t!} \lambda^{43} p_{43} \frac{38360235213946776318553037176114920309}{78125000000000000000000000000000000000} \approx 0.491
 \approx .491.","['probability', 'combinatorics', 'solution-verification', 'poisson-distribution', 'multinomial-distribution']"
2,"Possibility that all lights $\mathbf{X}=(X_1,X_2,\cdots)$ turn off again with every time turn a light with its number $n\sim\text{geom}(\frac{1}{2})$.",Possibility that all lights  turn off again with every time turn a light with its number .,"\mathbf{X}=(X_1,X_2,\cdots) n\sim\text{geom}(\frac{1}{2})","Problem: Let $\mathbf{X} = (\mathbb{Z}_2)^\mathbb N$ , i.e., $\mathbf{X} = (X_1,X_2,\cdots,X_N,\cdots)$ , $X_i\in \{0,1\} $ . It can be considered as countable lightbulbs. $0$ means off, $1$ means on. We start with $\mathbf{X}_0 = 0$ . Keep generating independent geometric random variables, whose distribution are $geom(1/2)$ . Denote them as $K_1, K_2,\cdots$ . Now let $\mathbf{X}_m$ (for $m \ge 1$ ) be as follows $$(\mathbf{X}_m-\mathbf{X}_{m-1})_k = \mathbf{1}(k = K_m), $$ i.e, in the $m$ -  th turn, we only change the status of the $K_m$ -th light bulb. Then what is the probability of all lights being off again, i.e., $$\mathbb P(\exists m>1, \mathbf{X}_m =0)$$ My first intuition below was wrong I’m afraid. My intuition is that since $1/4+1/16+1/64+\cdots=1/3$ , the final answer might be $1/2$ . Since all lights being off means all lights are encountered even times, I tried to use generating function but it doesn't work since it's hard to derive a correspondence between all lights are encountered even times and generating function coefficients, and brute force calculation seem also hard due to the same reason that there're too many cases to consider, and I'm stuck here. Are there any other thoughts to deal with this question? Thanks! New intuition: We may define a function $f(x_1,x_2,\cdots)$ as the probability that status $\mathbf{X}=(x_1,x_2,\cdots)$ will eventually become all $0$ , then our goal is to calculate $\sum_{n=1}^{\infty}\frac{1}{2^n}f(0,\cdots,0,1,0,\cdots)$ where $1$ only appears on $n$ -th term, and we can achieve all the transporting equations of $f$ , which is an uncountable dimensional equation system. We can see immediately that the equation system has a solution $f(x_1,x_2,\cdots)\equiv 1$ . Can we conclude that this solution is unique (Then the answer to this problem is $1$ )? Continue the intuition above, we define $$g(x_1,x_2,\cdots)=f(x_1,x_2,\cdots)-1,$$ moreover we define $g(0,0,\cdots,0,\cdots)=0$ . Obviously $f\le1$ , hence $g$ can achieve a maximum at $(0,0,0,\cdots,0,\cdots)$ . Note that after changing all the equations involving $f$ into $g$ , the constant term will be cancelled and the coefficients at the righthand side is strictly larger than $0$ and the sum of all coefficients are always $1$ . For example, the equation $$f(1,0,0,\cdots,0,\cdots)=\frac{1}{2}+\frac{1}{4}f(1,1,0,\cdots,0,\cdots)+\frac{1}{8}f(1,0,1,\cdots,0,\cdots)+\cdots$$ is changed into $$g(1,0,0,\cdots,0,\cdots)=\frac{1}{2}g(0,0,0,\cdots,0,\cdots)+\frac{1}{4}g(1,1,0,\cdots,0,\cdots)+\frac{1}{8}g(1,0,1,\cdots,0,\cdots)+\cdots$$ We want to use the maximum principle, but we lack an equation with $\text{LHS}=g(0,0,0,\cdots,0,\cdots)$ , are there any ways to supple this equation? Edit: Another possible intuition from here: ignore $g(0,0,0,\cdots,0,\cdots)$ , we only focus on the remaining term. We wish to discard the term that has infinity $1$ since the probability of getting this term is $0$ . If the maximum happens on one remaining element we're done, what we don't want is if the maximum happens on the limiting term, and we wish to prove that this won't happen because the limit is (somewhat?) decaying. (I don't know how to proceed here, but I'll post my intuitions these days anyway)","Problem: Let , i.e., , . It can be considered as countable lightbulbs. means off, means on. We start with . Keep generating independent geometric random variables, whose distribution are . Denote them as . Now let (for ) be as follows i.e, in the -  th turn, we only change the status of the -th light bulb. Then what is the probability of all lights being off again, i.e., My first intuition below was wrong I’m afraid. My intuition is that since , the final answer might be . Since all lights being off means all lights are encountered even times, I tried to use generating function but it doesn't work since it's hard to derive a correspondence between all lights are encountered even times and generating function coefficients, and brute force calculation seem also hard due to the same reason that there're too many cases to consider, and I'm stuck here. Are there any other thoughts to deal with this question? Thanks! New intuition: We may define a function as the probability that status will eventually become all , then our goal is to calculate where only appears on -th term, and we can achieve all the transporting equations of , which is an uncountable dimensional equation system. We can see immediately that the equation system has a solution . Can we conclude that this solution is unique (Then the answer to this problem is )? Continue the intuition above, we define moreover we define . Obviously , hence can achieve a maximum at . Note that after changing all the equations involving into , the constant term will be cancelled and the coefficients at the righthand side is strictly larger than and the sum of all coefficients are always . For example, the equation is changed into We want to use the maximum principle, but we lack an equation with , are there any ways to supple this equation? Edit: Another possible intuition from here: ignore , we only focus on the remaining term. We wish to discard the term that has infinity since the probability of getting this term is . If the maximum happens on one remaining element we're done, what we don't want is if the maximum happens on the limiting term, and we wish to prove that this won't happen because the limit is (somewhat?) decaying. (I don't know how to proceed here, but I'll post my intuitions these days anyway)","\mathbf{X} = (\mathbb{Z}_2)^\mathbb N \mathbf{X} = (X_1,X_2,\cdots,X_N,\cdots) X_i\in \{0,1\}  0 1 \mathbf{X}_0 = 0 geom(1/2) K_1, K_2,\cdots \mathbf{X}_m m \ge 1 (\mathbf{X}_m-\mathbf{X}_{m-1})_k = \mathbf{1}(k = K_m),  m K_m \mathbb P(\exists m>1, \mathbf{X}_m =0) 1/4+1/16+1/64+\cdots=1/3 1/2 f(x_1,x_2,\cdots) \mathbf{X}=(x_1,x_2,\cdots) 0 \sum_{n=1}^{\infty}\frac{1}{2^n}f(0,\cdots,0,1,0,\cdots) 1 n f f(x_1,x_2,\cdots)\equiv 1 1 g(x_1,x_2,\cdots)=f(x_1,x_2,\cdots)-1, g(0,0,\cdots,0,\cdots)=0 f\le1 g (0,0,0,\cdots,0,\cdots) f g 0 1 f(1,0,0,\cdots,0,\cdots)=\frac{1}{2}+\frac{1}{4}f(1,1,0,\cdots,0,\cdots)+\frac{1}{8}f(1,0,1,\cdots,0,\cdots)+\cdots g(1,0,0,\cdots,0,\cdots)=\frac{1}{2}g(0,0,0,\cdots,0,\cdots)+\frac{1}{4}g(1,1,0,\cdots,0,\cdots)+\frac{1}{8}g(1,0,1,\cdots,0,\cdots)+\cdots \text{LHS}=g(0,0,0,\cdots,0,\cdots) g(0,0,0,\cdots,0,\cdots) 1 0","['probability', 'probability-theory', 'analysis', 'markov-chains', 'markov-process']"
3,Let $X_1$ and $X_2$ be uniform on $n$-spheres. What is the distribution of $\| X_1+X_2\|$?,Let  and  be uniform on -spheres. What is the distribution of ?,X_1 X_2 n \| X_1+X_2\|,"Suppose we have two  independent random variables $X_1$ and $X_2$ distribution on $n-1$ -sphere of radius $r_1 $ and radius $r_2$ , respectivly. Assume $r_1>r_2$ . Recall, that the $n-1$ -sphere of radius $r$ is defined as \begin{align} S_{n-1}= \{ x \in \mathbb{R}^n : \|x\|=r \}. \end{align} We have to find the distribution of \begin{align} U=X_1+X_2 \end{align} We can see that $U$ will be distributed on an annulus \begin{align} A=\{ x:  r_1-r_2 \le \| x\|\le r_1+r_2  \} \end{align} It is not difficult to see that $U$ has a uniform spherical angle. Therefore, the question is what is the distribution of the magnitude of $U$ that is $\| U\|$ ? This question is an extension of the question previously asked here . For the bounty: I would like to see the exact expression for the distribution of $U$ .","Suppose we have two  independent random variables and distribution on -sphere of radius and radius , respectivly. Assume . Recall, that the -sphere of radius is defined as We have to find the distribution of We can see that will be distributed on an annulus It is not difficult to see that has a uniform spherical angle. Therefore, the question is what is the distribution of the magnitude of that is ? This question is an extension of the question previously asked here . For the bounty: I would like to see the exact expression for the distribution of .","X_1 X_2 n-1 r_1  r_2 r_1>r_2 n-1 r \begin{align}
S_{n-1}= \{ x \in \mathbb{R}^n : \|x\|=r \}.
\end{align} \begin{align}
U=X_1+X_2
\end{align} U \begin{align}
A=\{ x:  r_1-r_2 \le \| x\|\le r_1+r_2  \}
\end{align} U U \| U\| U","['probability', 'probability-theory']"
4,"A closet contains 10 pairs of shoes. If 8 shoes are randomly selected, what is the probability that there will be exactly 1 complete pair?","A closet contains 10 pairs of shoes. If 8 shoes are randomly selected, what is the probability that there will be exactly 1 complete pair?",,"What I am getting is that there are 10 ways of choosing the 1 pair of shoes from the 10. Since the remaining shoes can't match, there are $\left( \begin{matrix} 9\\ 6\end{matrix} \right) $ ways to choose pairs from which to select the remaining shoes, $2^6$ ways to select individual shoes from the 6 pairs, and divided by$ \left( \begin{matrix} 20\\ 8\end{matrix} \right) $ ways of selecting 8 shoes from 20. This gives us $\dfrac {\left( \begin{matrix} 9\\ 6\end{matrix} \right)\times 10 \times 2^6 } {\left( \begin{matrix} 20\\ 8\end{matrix} \right) }$ This gives a probability of $\dfrac {1792} {4199}$. But that doesn't seem quite right, I think I am missing something. Any help would be appreciated.","What I am getting is that there are 10 ways of choosing the 1 pair of shoes from the 10. Since the remaining shoes can't match, there are $\left( \begin{matrix} 9\\ 6\end{matrix} \right) $ ways to choose pairs from which to select the remaining shoes, $2^6$ ways to select individual shoes from the 6 pairs, and divided by$ \left( \begin{matrix} 20\\ 8\end{matrix} \right) $ ways of selecting 8 shoes from 20. This gives us $\dfrac {\left( \begin{matrix} 9\\ 6\end{matrix} \right)\times 10 \times 2^6 } {\left( \begin{matrix} 20\\ 8\end{matrix} \right) }$ This gives a probability of $\dfrac {1792} {4199}$. But that doesn't seem quite right, I think I am missing something. Any help would be appreciated.",,"['probability', 'combinatorics', 'permutations', 'combinations']"
5,How many books are in a library?,How many books are in a library?,,"My cousin is at elementary school and every week is given a book by his teacher.  He then reads it and returns it in time to get another one the next week. After a while we started noticing that he was getting books he had read before and this became gradually more common over time.   Naturally, I started to wonder how one could estimate the total number of books in their library. Say the true number of books in the library is $N$ and the teacher picks one uniformly at random (with replacement) to give to you each week.  If at week $t$ you have received a book you have read before $x$ times, is there an unbiased estimator for the total number of books in the library and what is the variance of this estimator? Is there another biased estimator with lower variance? In my cousin's case, in the first $30$ weeks he received a book he had received before $3$ times.","My cousin is at elementary school and every week is given a book by his teacher.  He then reads it and returns it in time to get another one the next week. After a while we started noticing that he was getting books he had read before and this became gradually more common over time.   Naturally, I started to wonder how one could estimate the total number of books in their library. Say the true number of books in the library is $N$ and the teacher picks one uniformly at random (with replacement) to give to you each week.  If at week $t$ you have received a book you have read before $x$ times, is there an unbiased estimator for the total number of books in the library and what is the variance of this estimator? Is there another biased estimator with lower variance? In my cousin's case, in the first $30$ weeks he received a book he had received before $3$ times.",,['probability']
6,Probability of an event happening N or more times,Probability of an event happening N or more times,,"I need to determine the probability of an event happening N or more times over M iterations. I know the probability of the event in question happening and its likelihood does not change over time. For example, say I am rolling a six-sided die and I want to know what is the probability that over the course of 100 rolls I'll roll a 1 or a 2 at least 75 times? Is there a nice and tidy formula for computing such probabilities? Thanks","I need to determine the probability of an event happening N or more times over M iterations. I know the probability of the event in question happening and its likelihood does not change over time. For example, say I am rolling a six-sided die and I want to know what is the probability that over the course of 100 rolls I'll roll a 1 or a 2 at least 75 times? Is there a nice and tidy formula for computing such probabilities? Thanks",,['probability']
7,When does a maximum likelihood estimate fail to exist?,When does a maximum likelihood estimate fail to exist?,,"I have been told that a maximum likelihood estimate (MLE) does not always actually exist.  Why is this the case?  It is clear that the MLE may not be unique, but there should always be a maximum, no?","I have been told that a maximum likelihood estimate (MLE) does not always actually exist.  Why is this the case?  It is clear that the MLE may not be unique, but there should always be a maximum, no?",,"['probability', 'machine-learning']"
8,What is Nassim Taleb's criticism of 538's election model?,What is Nassim Taleb's criticism of 538's election model?,,Nassim Taleb has tweeted criticism about 538's political predictions that I don't follow. He seems to be making a theoretical argument. I am very weak on stochastic modeling (though I know basic PDEs). Can someone help me understand at least the gist of what he is saying?,Nassim Taleb has tweeted criticism about 538's political predictions that I don't follow. He seems to be making a theoretical argument. I am very weak on stochastic modeling (though I know basic PDEs). Can someone help me understand at least the gist of what he is saying?,,"['probability', 'stochastic-processes', 'mathematical-modeling']"
9,Distribution of a difference of two Uniform random variables?,Distribution of a difference of two Uniform random variables?,,"Let $X$ and $Y$ both be distributed between $[1,2]$, what is the distribution of $Z=X-Y$?","Let $X$ and $Y$ both be distributed between $[1,2]$, what is the distribution of $Z=X-Y$?",,"['probability', 'probability-distributions']"
10,Is there any $F \in \mathscr{F}$ such that $\mu(F)=x$?,Is there any  such that ?,F \in \mathscr{F} \mu(F)=x,"Let $ (\Omega,\mathscr{F},\mu)$ be a probability space such that $\mu$ is non-atomic, and fix $x \in [0,1]$. Is it true that one can find $F \in \mathscr{F}$ for which $\mu(F)=x$? And what if $\mu$ is only finitely additive? Ps. Here we recall that $\mu$ is non-atomic if $\mu(X)>0$ for some $X \in \mathscr{F}$ implies that there exists $Y \in \mathscr{F}$ for which $0<\mu(Y)<\mu(X)$.","Let $ (\Omega,\mathscr{F},\mu)$ be a probability space such that $\mu$ is non-atomic, and fix $x \in [0,1]$. Is it true that one can find $F \in \mathscr{F}$ for which $\mu(F)=x$? And what if $\mu$ is only finitely additive? Ps. Here we recall that $\mu$ is non-atomic if $\mu(X)>0$ for some $X \in \mathscr{F}$ implies that there exists $Y \in \mathscr{F}$ for which $0<\mu(Y)<\mu(X)$.",,"['probability', 'probability-theory', 'measure-theory']"
11,Distribution for random harmonic series,Distribution for random harmonic series,,"Consider random variable $X$ formed by the following infinite series: $X = \pm 1 \pm \frac{1}{2} \pm \frac{1}{3} \pm ... \frac{1}{n} ...$, where $+$ or $-$ sign for every summand is chosen independently w.p. $1/2$. What is the distribution of $X$? If it is not some well-known distribution, does it have any interesting properties?","Consider random variable $X$ formed by the following infinite series: $X = \pm 1 \pm \frac{1}{2} \pm \frac{1}{3} \pm ... \frac{1}{n} ...$, where $+$ or $-$ sign for every summand is chosen independently w.p. $1/2$. What is the distribution of $X$? If it is not some well-known distribution, does it have any interesting properties?",,"['probability', 'probability-distributions']"
12,"Why are all subset sizes equiprobable if elements are independently included with probability uniform over $[0,1]$?",Why are all subset sizes equiprobable if elements are independently included with probability uniform over ?,"[0,1]","A probability $p$ is chosen uniformly randomly from $[0,1]$ , and then a subset of a set of $n$ elements is formed by including each element independently with probability $p$ . In answering Probability of an event if r out of n events were true. I realized that the probability $$ \int_0^1\binom nrp^r(1-p)^{n-r}\mathrm dp=\frac1{n+1} $$ of obtaining a subset of size $r$ is independent of $r$ ; so all $n+1$ subset sizes are equiprobable. This is a neat fact that I wasn’t aware of before. There must be a nicer, more insightful way to show this than to evaluate this integral (which can be done using integration by parts).","A probability is chosen uniformly randomly from , and then a subset of a set of elements is formed by including each element independently with probability . In answering Probability of an event if r out of n events were true. I realized that the probability of obtaining a subset of size is independent of ; so all subset sizes are equiprobable. This is a neat fact that I wasn’t aware of before. There must be a nicer, more insightful way to show this than to evaluate this integral (which can be done using integration by parts).","p [0,1] n p 
\int_0^1\binom nrp^r(1-p)^{n-r}\mathrm dp=\frac1{n+1}
 r r n+1","['probability', 'uniform-distribution', 'binomial-distribution']"
13,Simulating a fair coin toss using a biased coin in fixed number of tosses,Simulating a fair coin toss using a biased coin in fixed number of tosses,,"For which values of $p$ can we simulate a fair coin toss using a fixed number of tosses of a $p$-biased coin? Here are some positive and negative examples: When $p = 1/2$, this is trivially possible. When $p = 1/2 \pm 1/\sqrt{12}$, this is possible since $p^3 + (1-p)^3 = 1/2$. When $p = k/n$ for odd $n$ and integer $k$, this is impossible, since after tossing the coin $m$ times, the probability of any event is an integer multiple of $1/n^m$. In particular, Is there a rational $p \neq 1/2$ for which we can simulate a fair coin toss using a fixed number of tosses of a $p$-biased coin?","For which values of $p$ can we simulate a fair coin toss using a fixed number of tosses of a $p$-biased coin? Here are some positive and negative examples: When $p = 1/2$, this is trivially possible. When $p = 1/2 \pm 1/\sqrt{12}$, this is possible since $p^3 + (1-p)^3 = 1/2$. When $p = k/n$ for odd $n$ and integer $k$, this is impossible, since after tossing the coin $m$ times, the probability of any event is an integer multiple of $1/n^m$. In particular, Is there a rational $p \neq 1/2$ for which we can simulate a fair coin toss using a fixed number of tosses of a $p$-biased coin?",,['probability']
14,Great Book on Probability and Statistics (for Computer Scientists),Great Book on Probability and Statistics (for Computer Scientists),,"I'm a Computer Science sophomore and we're studying Probability and Statistics (fundamentals and all). The teacher recommends a book which I don't like since it does not even try and explain everything. So, can you recommend me a few great books on Probability and Statistics and if such exists, with an accent on Computer Science? Thanks!","I'm a Computer Science sophomore and we're studying Probability and Statistics (fundamentals and all). The teacher recommends a book which I don't like since it does not even try and explain everything. So, can you recommend me a few great books on Probability and Statistics and if such exists, with an accent on Computer Science? Thanks!",,"['probability', 'reference-request', 'statistics', 'computer-science']"
15,Probability that rectangle is inside a circle,Probability that rectangle is inside a circle,,"We randomly uniformly pick point $x$ on a unit circumference $\{x^2 + y^2 = 1\}$. Then we randomly uniformly pick point $y$ on a unit circle $\{x^2 + y^2 \leq 1\}$. Let $R$ be a rectangle with diagonal $xy$, which sides are parallel to coordinate axes. What is the probability that $R$ lies completely inside the unit circle? We see, that after $x$ is chosen we have a rectangle $A$, within which our point $y$ should fall to satisfy the condition of the task. The area of the rectangle $A$ equals $S_A(x) = 4 \sin{(2x)}$ and the probability $P(\{y \in A\}) = \frac{S_A}{S_{circle}} = \frac{S_A}{\pi}.$ How can I find this probability? The problem for me is that $S_A(x)$ is the transformation of random variable $x \sim unif(0, \frac{\pi}{2})$. For some reason I think that the answer is $\frac{\mathbb{E}[S_A(x)]}{\pi} = \frac{1}{\pi} \cdot \frac{1}{\pi/2 - 0} \cdot \int_0^{\pi/2}S_A(x)dx$, but I do not know why I think so.","We randomly uniformly pick point $x$ on a unit circumference $\{x^2 + y^2 = 1\}$. Then we randomly uniformly pick point $y$ on a unit circle $\{x^2 + y^2 \leq 1\}$. Let $R$ be a rectangle with diagonal $xy$, which sides are parallel to coordinate axes. What is the probability that $R$ lies completely inside the unit circle? We see, that after $x$ is chosen we have a rectangle $A$, within which our point $y$ should fall to satisfy the condition of the task. The area of the rectangle $A$ equals $S_A(x) = 4 \sin{(2x)}$ and the probability $P(\{y \in A\}) = \frac{S_A}{S_{circle}} = \frac{S_A}{\pi}.$ How can I find this probability? The problem for me is that $S_A(x)$ is the transformation of random variable $x \sim unif(0, \frac{\pi}{2})$. For some reason I think that the answer is $\frac{\mathbb{E}[S_A(x)]}{\pi} = \frac{1}{\pi} \cdot \frac{1}{\pi/2 - 0} \cdot \int_0^{\pi/2}S_A(x)dx$, but I do not know why I think so.",,['probability']
16,Toss a fair die until the cumulative sum is a perfect square-Expected Value,Toss a fair die until the cumulative sum is a perfect square-Expected Value,,"Suppose we keep tossing a fair dice until we want to stop, at which point the game ends and our score is the cumulative sum, or until the cumulative sum is a perfect square, in which case we lose and end up with a score of $0$. We can set up a Markov-style recurrence. Define $f(k)$ to be the expected value of the game if the current cumulative sum is $k$. Clearly, $f(k)$ is $0$ if $k$ is a perfect square. In addition, $f(k)=\text{max}\{k,\sum_{i=1}^6 f(k+i)\}$. How can we solve such a recurrence to find a good estimate/bounds of the expected score ($f(0)$) and the optimal strategy? Can these methods be extended to a game where we lose if the cumulative sum is an even number, or a perfect cube?","Suppose we keep tossing a fair dice until we want to stop, at which point the game ends and our score is the cumulative sum, or until the cumulative sum is a perfect square, in which case we lose and end up with a score of $0$. We can set up a Markov-style recurrence. Define $f(k)$ to be the expected value of the game if the current cumulative sum is $k$. Clearly, $f(k)$ is $0$ if $k$ is a perfect square. In addition, $f(k)=\text{max}\{k,\sum_{i=1}^6 f(k+i)\}$. How can we solve such a recurrence to find a good estimate/bounds of the expected score ($f(0)$) and the optimal strategy? Can these methods be extended to a game where we lose if the cumulative sum is an even number, or a perfect cube?",,"['probability', 'combinatorics', 'game-theory', 'dice']"
17,Passing a limit into expectation,Passing a limit into expectation,,"While reading about random walks, I started thinking about this and got a headache: Given a random process $\{X_n\}_{n\in \mathbb{Z}^+}$ with a real state space (i.e., $X_n$ takes on real numbers), what can you say about these two expressions? $$\begin{align*} \lim_{n\rightarrow\infty} \mathbb{E}\left[X_n\mathop{\big|}X_0=j\right] & \quad (1) \\ \mathbb{E}\left[\lim_{n\rightarrow\infty} X_n\mathop{\big|} X_0 = j\right] & \quad(2)  \end{align*}$$ (or also considering omitting the conditional statement on $X_0$... I'm not sure whether it matters or not). I did some Googling, and I found something called Fatou's lemma , but I have no background in measure theory, and most of the Wikipedia article is way over my head. My questions When can you pass the limit in and out (equality), and when is it an inequality (Fatou's lemma)? Does anything change if $\{X_n\}$ is a Markov chain? What if it was a continuous process $\{X_t\}_{t\in\mathbb{R}^+}$ instead? How do you interpret (explain in words) what those two expressions mean and what the difference is between them? Is there any causal relationship between existence of one limit and the other? For example, does the existence of the limit in $(1)$ imply that the limits in $(2)$ all exist? Besides measure theory and probability theory, are there any other foundational topics/subjects/fields that I could look into to learn more about this? I'm sorry if my questions don't make much sense or if I am using terminology incorrectly; I am not very familiar with this material, and would like to learn more about it. Any helpful information would be much appreciated.","While reading about random walks, I started thinking about this and got a headache: Given a random process $\{X_n\}_{n\in \mathbb{Z}^+}$ with a real state space (i.e., $X_n$ takes on real numbers), what can you say about these two expressions? $$\begin{align*} \lim_{n\rightarrow\infty} \mathbb{E}\left[X_n\mathop{\big|}X_0=j\right] & \quad (1) \\ \mathbb{E}\left[\lim_{n\rightarrow\infty} X_n\mathop{\big|} X_0 = j\right] & \quad(2)  \end{align*}$$ (or also considering omitting the conditional statement on $X_0$... I'm not sure whether it matters or not). I did some Googling, and I found something called Fatou's lemma , but I have no background in measure theory, and most of the Wikipedia article is way over my head. My questions When can you pass the limit in and out (equality), and when is it an inequality (Fatou's lemma)? Does anything change if $\{X_n\}$ is a Markov chain? What if it was a continuous process $\{X_t\}_{t\in\mathbb{R}^+}$ instead? How do you interpret (explain in words) what those two expressions mean and what the difference is between them? Is there any causal relationship between existence of one limit and the other? For example, does the existence of the limit in $(1)$ imply that the limits in $(2)$ all exist? Besides measure theory and probability theory, are there any other foundational topics/subjects/fields that I could look into to learn more about this? I'm sorry if my questions don't make much sense or if I am using terminology incorrectly; I am not very familiar with this material, and would like to learn more about it. Any helpful information would be much appreciated.",,"['probability', 'stochastic-processes']"
18,Multivariate Inverse Transformation Sampling,Multivariate Inverse Transformation Sampling,,"Summary Given a multivariate density distribution, I use inverse transformation sampling to sample points from this distribution. While the first dimension exhibits the correct distribution, all other dimensions contain a slight, stable error. Details My density distribution is given as a bilinear interpolation on the $([0-1], [0-1])$ rectangle. In the rest of this question, I use the following example: $$ d(x,y)=\frac{4}{11}(2+x+2y-3xy) $$ This results in the following density plot (brighter colors represent higher density): The cumulative density function is $$ cum(x,y)=\int_{0}^{x} \int_{0}^{y} d(px,py) dpy\ dpx = \frac{1}{11}(8xy+2x^2y+4xy^2-3x^2y^2) $$ In order to sample from this distribution, I draw two samples $ux$ and $uy$ from the uniform $[0, 1)$ distribution and transform them to $x$ and $y$ as follows: $$ cum(x, 1)=ux \\ x = 6-\sqrt{36-11ux} $$ and $$ cum(x, y)=ux \cdot uy \\ y = \frac{4+x-\sqrt{16+48uy+8x-40uy x+x^2+3 uy x^2}}{3x-4} $$ The samples resulting from this transformation look reasonable (5000 samples in the following figure): I tried to verify the result by approximating the cumulative density from the samples by simply counting how many of the samples have a smaller or equal x and y coordinate. Here are some results for 10 million samples. I report the analytic expected value and the results of two samplings. Digits are truncated: i : 0.0   0.1   0.2   0.3   0.4   0.5   0.6   0.7   0.8   0.9   1.0 ---------------------------------------------------------------------------------------   analytic cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.719 0.814 0.908 1.0 sampling 1 cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.718 0.814 0.908 1.0 sampling 2 cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.719 0.814 0.908 1.0 ---------------------------------------------------------------------------------------   analytic cum(1, i) : 0.0   0.091 0.185 0.280 0.378 0.477 0.578 0.680 0.785 0.891 1.0 sampling 1 cum(1, i) : 0.0   0.080 0.164 0.253 0.347 0.445 0.547 0.653 0.764 0.880 1.0 sampling 2 cum(1, i) : 0.0   0.080 0.164 0.253 0.347 0.445 0.547 0.653 0.764 0.880 1.0 Obviously, the cumulative density of the x-coordinates ($cum(i, 1)$) is almost exactly the analytic expression. On the other hand, there is a clear error in the y-coordinates ($cum(1, i)$). This error is stable across different samplings. I cannot explain this slight error. Both the theoretical fundamentals and the implementation (with Mathematica) look sound. Is there something I might have missed? Univariate sampling works perfectly as can be seen from the x-coordinates. However, multivariate sampling exhibits a slight error.","Summary Given a multivariate density distribution, I use inverse transformation sampling to sample points from this distribution. While the first dimension exhibits the correct distribution, all other dimensions contain a slight, stable error. Details My density distribution is given as a bilinear interpolation on the $([0-1], [0-1])$ rectangle. In the rest of this question, I use the following example: $$ d(x,y)=\frac{4}{11}(2+x+2y-3xy) $$ This results in the following density plot (brighter colors represent higher density): The cumulative density function is $$ cum(x,y)=\int_{0}^{x} \int_{0}^{y} d(px,py) dpy\ dpx = \frac{1}{11}(8xy+2x^2y+4xy^2-3x^2y^2) $$ In order to sample from this distribution, I draw two samples $ux$ and $uy$ from the uniform $[0, 1)$ distribution and transform them to $x$ and $y$ as follows: $$ cum(x, 1)=ux \\ x = 6-\sqrt{36-11ux} $$ and $$ cum(x, y)=ux \cdot uy \\ y = \frac{4+x-\sqrt{16+48uy+8x-40uy x+x^2+3 uy x^2}}{3x-4} $$ The samples resulting from this transformation look reasonable (5000 samples in the following figure): I tried to verify the result by approximating the cumulative density from the samples by simply counting how many of the samples have a smaller or equal x and y coordinate. Here are some results for 10 million samples. I report the analytic expected value and the results of two samplings. Digits are truncated: i : 0.0   0.1   0.2   0.3   0.4   0.5   0.6   0.7   0.8   0.9   1.0 ---------------------------------------------------------------------------------------   analytic cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.719 0.814 0.908 1.0 sampling 1 cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.718 0.814 0.908 1.0 sampling 2 cum(i, 1) : 0.0   0.108 0.214 0.319 0.421 0.522 0.621 0.719 0.814 0.908 1.0 ---------------------------------------------------------------------------------------   analytic cum(1, i) : 0.0   0.091 0.185 0.280 0.378 0.477 0.578 0.680 0.785 0.891 1.0 sampling 1 cum(1, i) : 0.0   0.080 0.164 0.253 0.347 0.445 0.547 0.653 0.764 0.880 1.0 sampling 2 cum(1, i) : 0.0   0.080 0.164 0.253 0.347 0.445 0.547 0.653 0.764 0.880 1.0 Obviously, the cumulative density of the x-coordinates ($cum(i, 1)$) is almost exactly the analytic expression. On the other hand, there is a clear error in the y-coordinates ($cum(1, i)$). This error is stable across different samplings. I cannot explain this slight error. Both the theoretical fundamentals and the implementation (with Mathematica) look sound. Is there something I might have missed? Univariate sampling works perfectly as can be seen from the x-coordinates. However, multivariate sampling exhibits a slight error.",,"['probability', 'statistics', 'probability-distributions', 'sampling']"
19,Conditional Probability and Division by Zero,Conditional Probability and Division by Zero,,"Suppose we are picking points uniformly at random from the surface of the Earth. I want to compute the probability that I pick a point in the Western hemisphere, given that I pick a point on the equator. The answer should clearly be $1/2$. From the definition, we have $$P(A|B)=\frac{P(A\cap B)}{P(B)},$$ where event $A$ is choosing a point in the Western hemisphere and $B$ is choosing a point on the equator. As the equator is a $1$-dimensional smooth line on a $2$-dimensional surface, it has measure $0$. So I compute $P(B)=0$. But using the conditional probability formula requires $P(B)>0$. In fact, this is the definition of conditional probability! So how do I make sense of $P(A|B)$? Clearly, it should work out to be $1/2$, but what is the rigorous way to compute it?","Suppose we are picking points uniformly at random from the surface of the Earth. I want to compute the probability that I pick a point in the Western hemisphere, given that I pick a point on the equator. The answer should clearly be $1/2$. From the definition, we have $$P(A|B)=\frac{P(A\cap B)}{P(B)},$$ where event $A$ is choosing a point in the Western hemisphere and $B$ is choosing a point on the equator. As the equator is a $1$-dimensional smooth line on a $2$-dimensional surface, it has measure $0$. So I compute $P(B)=0$. But using the conditional probability formula requires $P(B)>0$. In fact, this is the definition of conditional probability! So how do I make sense of $P(A|B)$? Clearly, it should work out to be $1/2$, but what is the rigorous way to compute it?",,"['probability', 'paradoxes']"
20,Asymptotic Expansion for $\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}$,Asymptotic Expansion for,\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k},"Prior Art The fact that $$ \lim_{n\to\infty}\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}=0\tag1 $$ is the topic of this question . An argument using a bit of probability theory gives a first order estimate of the size of the sum. Estimate of the Sum The binomial distribution has mean $\frac n2$ and variance $\frac n4$ , Chebyshev's Inequality says $$ \frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\ge x\right]\le\frac n{4x^2}\tag2 $$ Setting $x=n^{7/8}$ in $(2)$ gives $$ \frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\ge n^{7/8}\right]\le\frac1{4n^{3/4}}\tag3 $$ which means $$ \frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\lt n^{7/8}\right]\ge1-\frac1{4n^{3/4}}\tag4 $$ Note that when $\left|k-\frac n2\right|\le n^{7/8}$ , $$ \frac1{\sqrt{n/2+n^{7/8}}}\le\frac1{\sqrt{k}}\le\frac1{\sqrt{n/2-n^{7/8}}}\tag5 $$ and the width of this interval is $$ \begin{align} \frac1{\sqrt{n/2-n^{7/8}}}-\frac1{\sqrt{n/2+n^{7/8}}} &=\frac{\sqrt{n/2+n^{7/8}}-\sqrt{n/2-n^{7/8}}}{\sqrt{n^2/4-n^{7/4}}}\\ &=\frac{2n^{7/8}}{\sqrt{n^2/4-n^{7/4}}\left(\sqrt{n/2+n^{7/8}}+\sqrt{n/2-n^{7/8}}\right)}\\[6pt] &=O\!\left(n^{-5/8}\right)\tag6 \end{align} $$ Thus, when $\left|k-\frac n2\right|\le n^{7/8}$ , $$ \frac1{\sqrt{k}}=\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\tag7 $$ In any case, $\frac1{\sqrt{k}}\le1$ . Therefore, $$ \begin{align} \frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k} &=\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}\left[\left|k-\frac n2\right|\le x\right]\\ &+\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}\left[\left|k-\frac n2\right|\ge x\right]\\ &=\left(\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\right)\left(1+O\!\left(n^{-3/4}\right)\right)\\[6pt] &+O(1)\,O\!\left(n^{-3/4}\right)\\[6pt] &=\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\tag8 \end{align} $$ Question Using the approach above, it is hard to see how to get more terms of an asymptotic expansion. Chebyshev is not very precise and that might be a limitation. The Binomial distribution approaches a Normal distribution quite well and that might offer a better approach. Is there an approach that allows more terms of an asymptotic expansion to be determined?","Prior Art The fact that is the topic of this question . An argument using a bit of probability theory gives a first order estimate of the size of the sum. Estimate of the Sum The binomial distribution has mean and variance , Chebyshev's Inequality says Setting in gives which means Note that when , and the width of this interval is Thus, when , In any case, . Therefore, Question Using the approach above, it is hard to see how to get more terms of an asymptotic expansion. Chebyshev is not very precise and that might be a limitation. The Binomial distribution approaches a Normal distribution quite well and that might offer a better approach. Is there an approach that allows more terms of an asymptotic expansion to be determined?","
\lim_{n\to\infty}\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}=0\tag1
 \frac n2 \frac n4 
\frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\ge x\right]\le\frac n{4x^2}\tag2
 x=n^{7/8} (2) 
\frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\ge n^{7/8}\right]\le\frac1{4n^{3/4}}\tag3
 
\frac1{2^n}\sum_{k=1}^n\binom{n}{k}\left[\left|k-\frac n2\right|\lt n^{7/8}\right]\ge1-\frac1{4n^{3/4}}\tag4
 \left|k-\frac n2\right|\le n^{7/8} 
\frac1{\sqrt{n/2+n^{7/8}}}\le\frac1{\sqrt{k}}\le\frac1{\sqrt{n/2-n^{7/8}}}\tag5
 
\begin{align}
\frac1{\sqrt{n/2-n^{7/8}}}-\frac1{\sqrt{n/2+n^{7/8}}}
&=\frac{\sqrt{n/2+n^{7/8}}-\sqrt{n/2-n^{7/8}}}{\sqrt{n^2/4-n^{7/4}}}\\
&=\frac{2n^{7/8}}{\sqrt{n^2/4-n^{7/4}}\left(\sqrt{n/2+n^{7/8}}+\sqrt{n/2-n^{7/8}}\right)}\\[6pt]
&=O\!\left(n^{-5/8}\right)\tag6
\end{align}
 \left|k-\frac n2\right|\le n^{7/8} 
\frac1{\sqrt{k}}=\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\tag7
 \frac1{\sqrt{k}}\le1 
\begin{align}
\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}
&=\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}\left[\left|k-\frac n2\right|\le x\right]\\
&+\frac1{2^n}\sum_{k=1}^n\frac1{\sqrt{k}}\binom{n}{k}\left[\left|k-\frac n2\right|\ge x\right]\\
&=\left(\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\right)\left(1+O\!\left(n^{-3/4}\right)\right)\\[6pt]
&+O(1)\,O\!\left(n^{-3/4}\right)\\[6pt]
&=\sqrt{\frac2n}+O\!\left(n^{-5/8}\right)\tag8
\end{align}
","['probability', 'asymptotics', 'binomial-distribution']"
21,Does finite expectation imply bounded random variable?,Does finite expectation imply bounded random variable?,,"In general if I have that \begin{equation} \mathbb{E}(X)<\infty \end{equation} does this imply that $|X|<\infty$ a.s? An attempted proof: Let $(\Omega,\mathbb{F},\mathbb{P})$ be a probability space and $K>0$ be a constant, then \begin{equation} \mathbb{E}(X)=\int_{\Omega}XdP\,=\int_{\{|X|\leq K \}}XdP\,+\int_{\{|X|>K\}}XdP\, <\infty \end{equation} Taking the limit as $K\rightarrow \infty$ \begin{equation} \int_{\{|X|>K\}}XdP\, \rightarrow 0 \end{equation} Struggling how to finish from here or posssibly this isn't true?  Thanks!","In general if I have that \begin{equation} \mathbb{E}(X)<\infty \end{equation} does this imply that $|X|<\infty$ a.s? An attempted proof: Let $(\Omega,\mathbb{F},\mathbb{P})$ be a probability space and $K>0$ be a constant, then \begin{equation} \mathbb{E}(X)=\int_{\Omega}XdP\,=\int_{\{|X|\leq K \}}XdP\,+\int_{\{|X|>K\}}XdP\, <\infty \end{equation} Taking the limit as $K\rightarrow \infty$ \begin{equation} \int_{\{|X|>K\}}XdP\, \rightarrow 0 \end{equation} Struggling how to finish from here or posssibly this isn't true?  Thanks!",,"['probability', 'probability-theory']"
22,Probability of 20 consecutive success in 100 runs.,Probability of 20 consecutive success in 100 runs.,,"Suppose a chess player have a win rate equal 90%, what is the chance to have 20 consecutive wins (successes) playing 100 games? Consider that lose/draw = fail. I've studied basic statistics in college and it seems like a binomial distribution problem (right?), but honestly I can't figure out a way to solve this problem considering ""consecutive"" successes. Is there a statistical distribution for this kinda problem? Thanks very much! I really appreciate any thoughts!","Suppose a chess player have a win rate equal 90%, what is the chance to have 20 consecutive wins (successes) playing 100 games? Consider that lose/draw = fail. I've studied basic statistics in college and it seems like a binomial distribution problem (right?), but honestly I can't figure out a way to solve this problem considering ""consecutive"" successes. Is there a statistical distribution for this kinda problem? Thanks very much! I really appreciate any thoughts!",,['probability']
23,Notation for probability density,Notation for probability density,,"On one of my other questions here, I was criticized (and rightly so, as it was the source of my mistake) for using this notation for a continuous random variable $X$ with pdf $f(x)$: $$\mathbb{P}\{X\in dx\} = f(x) \mathop{dx} .$$ I was taught this notation by my teacher. The purpose of this notation is to stress the fact that technically, $\mathbb{P}\{X=x\}=0$ if $X$ is continuous. I believe the notation is shorthand for $\mathbb{P}\{X\in [x, x+dx)\} = f(x) \mathop{dx}$. As I am only familiar with this notation and didn't know that other people did not use it, I would really appreciate it if someone could give me a better sense of what notation is more accepted/used. Is the $f$ and $F$ notation of pdf and cdf respectively widely used? Given a pdf $f(x)$ for a continuous random variable $X$, its cdf is $F(x)=\int_{-\infty}^x f(t)dt=\mathbb{P}\{X<x\}$ (thanks for catching the typo, André!), which corresponds to the discrete case where $F(x) = \sum_{k=0}^x f(x) = \mathbb{P}\{X\le x\}$. Is there just no continuous analog for the discrete expression of $\mathbb{P}\{X=x\}=f(x)$? One piece of advice that I was given by another user was to deal primarily with cdfs and not with pdfs. Thank you in advance, and apologies if this was not the right place to ask this question.","On one of my other questions here, I was criticized (and rightly so, as it was the source of my mistake) for using this notation for a continuous random variable $X$ with pdf $f(x)$: $$\mathbb{P}\{X\in dx\} = f(x) \mathop{dx} .$$ I was taught this notation by my teacher. The purpose of this notation is to stress the fact that technically, $\mathbb{P}\{X=x\}=0$ if $X$ is continuous. I believe the notation is shorthand for $\mathbb{P}\{X\in [x, x+dx)\} = f(x) \mathop{dx}$. As I am only familiar with this notation and didn't know that other people did not use it, I would really appreciate it if someone could give me a better sense of what notation is more accepted/used. Is the $f$ and $F$ notation of pdf and cdf respectively widely used? Given a pdf $f(x)$ for a continuous random variable $X$, its cdf is $F(x)=\int_{-\infty}^x f(t)dt=\mathbb{P}\{X<x\}$ (thanks for catching the typo, André!), which corresponds to the discrete case where $F(x) = \sum_{k=0}^x f(x) = \mathbb{P}\{X\le x\}$. Is there just no continuous analog for the discrete expression of $\mathbb{P}\{X=x\}=f(x)$? One piece of advice that I was given by another user was to deal primarily with cdfs and not with pdfs. Thank you in advance, and apologies if this was not the right place to ask this question.",,"['probability', 'notation']"
24,"Does $ f(x, X) \overset{D}{=}h_1(x) + h_2(X)$ imply that $f$ is additive?",Does  imply that  is additive?," f(x, X) \overset{D}{=}h_1(x) + h_2(X) f","Let $X$ be a continuous random variable with full support on $\mathbb{R}$ . Let $f$ be a continuous function such that there exist $h_1, h_2$ functions satisfying $$ f(x, X) \overset{D}{=}h_1(x) + h_2(X), \,\,\,\,\,\,\,\,for\,\,all\,\,\,x\in\mathbb{R}.  $$ Does this necessary mean that there exist $\tilde{h}_1, \tilde{h}_2$ functions satisfying $$ f(x, y) \overset{}{=}\tilde{h}_1(x) + \tilde{h}_2(y), \,\,\,\,\,\,\,\,for\,\,all\,\,\,x,y\in\mathbb{R}? $$ Edit: Michael showed a valid counterexample. However it is the periodicity of $f$ that makes the counterexample exist. What is a non-trivial assumption of $f$ that makes the statement valid? If $f$ is Non-periodic? Surjective? Bijective?",Let be a continuous random variable with full support on . Let be a continuous function such that there exist functions satisfying Does this necessary mean that there exist functions satisfying Edit: Michael showed a valid counterexample. However it is the periodicity of that makes the counterexample exist. What is a non-trivial assumption of that makes the statement valid? If is Non-periodic? Surjective? Bijective?,"X \mathbb{R} f h_1, h_2 
f(x, X) \overset{D}{=}h_1(x) + h_2(X), \,\,\,\,\,\,\,\,for\,\,all\,\,\,x\in\mathbb{R}. 
 \tilde{h}_1, \tilde{h}_2 
f(x, y) \overset{}{=}\tilde{h}_1(x) + \tilde{h}_2(y), \,\,\,\,\,\,\,\,for\,\,all\,\,\,x,y\in\mathbb{R}?
 f f f","['probability', 'probability-theory', 'measure-theory', 'statistics', 'probability-distributions']"
25,A generalization of the airplane seating puzzle,A generalization of the airplane seating puzzle,,"Let me say immediately that this isn't my puzzle.  Someone posted it earlier, and I was working on it when it was deleted.  It seems to me to be an excellent puzzle, too good be deleted, so I'm reposting it.  If there's a good reason why I should delete this puzzle, please tell me. In some world, everyone has $k\geq1$ feet.  Everyone wears $k$ identical socks, but the socks vary from person.  Each person can easily identify his own socks.  When the people go to worship, they remove their socks and place them in a communal pile.  At the close of the service, each person removes his socks from the pile. One day, the first person to leave is in a hurry, and grabs $k$ socks uniformly at random.  After that, each person removes all of his own socks from the pile, and if any are missing, he randomly picks just enough so that he will have one for each foot. What is the probability that the last person to leave will find exactly $j$ of his own socks in the pile, for $0\leq j \leq k?$  (When $k=1,$ this is the airline seating puzzle.) I've done some experimenting by computer simulation for small $n$ and $k,$ and the results lead me to believe that for given $k,$ the answer is independent of the number of people $n\geq2.$  Of course, when $n=2$ the puzzle is trivial, so I guess that the answer is $$ {{k\choose k-j}{k\choose j}\over{2k\choose k}}, 0\leq j\leq k $$ I don't have a clue how to prove this, though.  Any ideas?","Let me say immediately that this isn't my puzzle.  Someone posted it earlier, and I was working on it when it was deleted.  It seems to me to be an excellent puzzle, too good be deleted, so I'm reposting it.  If there's a good reason why I should delete this puzzle, please tell me. In some world, everyone has $k\geq1$ feet.  Everyone wears $k$ identical socks, but the socks vary from person.  Each person can easily identify his own socks.  When the people go to worship, they remove their socks and place them in a communal pile.  At the close of the service, each person removes his socks from the pile. One day, the first person to leave is in a hurry, and grabs $k$ socks uniformly at random.  After that, each person removes all of his own socks from the pile, and if any are missing, he randomly picks just enough so that he will have one for each foot. What is the probability that the last person to leave will find exactly $j$ of his own socks in the pile, for $0\leq j \leq k?$  (When $k=1,$ this is the airline seating puzzle.) I've done some experimenting by computer simulation for small $n$ and $k,$ and the results lead me to believe that for given $k,$ the answer is independent of the number of people $n\geq2.$  Of course, when $n=2$ the puzzle is trivial, so I guess that the answer is $$ {{k\choose k-j}{k\choose j}\over{2k\choose k}}, 0\leq j\leq k $$ I don't have a clue how to prove this, though.  Any ideas?",,"['probability', 'puzzle']"
26,Expected number of people sitting in the right seats.,Expected number of people sitting in the right seats.,,"There was a popular interview question from a while back: there are $n$ people getting seated an airplane, and the first person comes in and sits at a random seat. Everyone else who comes in either sits in his seat, or if his seat has been taken, sits in a random unoccupied seat. What is the probability that the last person sits in his correct seat? The answer to this question is $1/2$ because everyone looking to sit on a random seat has an equal probability of sitting in the first person's seat as the last person's. My question is: what is the expected number of people sitting in their correct seat? My take: this would be $\sum_{i=1}^n p_i$ where $p_i$ is the probability that  person $i$ sits in the right seat.. $X_1 = 1/n$ $X_2 = 1 - 1/n$ $X_3 = 1 - (1/n + 1/n(n-1))$ $X_4 = 1 - (1/n + 2/n(n-1) + 1/n(n-1)(n-2))$ Is this correct? And does it generalize to $X_i$ having an $\max(0, i-1)$ term of $1/n(n-1)$, a $\max(0, i-2)$ term of $1/n(n-1)(n-2)$ etc? Thanks.","There was a popular interview question from a while back: there are $n$ people getting seated an airplane, and the first person comes in and sits at a random seat. Everyone else who comes in either sits in his seat, or if his seat has been taken, sits in a random unoccupied seat. What is the probability that the last person sits in his correct seat? The answer to this question is $1/2$ because everyone looking to sit on a random seat has an equal probability of sitting in the first person's seat as the last person's. My question is: what is the expected number of people sitting in their correct seat? My take: this would be $\sum_{i=1}^n p_i$ where $p_i$ is the probability that  person $i$ sits in the right seat.. $X_1 = 1/n$ $X_2 = 1 - 1/n$ $X_3 = 1 - (1/n + 1/n(n-1))$ $X_4 = 1 - (1/n + 2/n(n-1) + 1/n(n-1)(n-2))$ Is this correct? And does it generalize to $X_i$ having an $\max(0, i-1)$ term of $1/n(n-1)$, a $\max(0, i-2)$ term of $1/n(n-1)(n-2)$ etc? Thanks.",,"['probability', 'combinatorics']"
27,Is this graph based on rationals familiar?,Is this graph based on rationals familiar?,,"Has anyone come across a graph like this? The black circles represent rationals in $(0,1)$ and their heights are roughly proportional to the reciprocal of the square of their lowest terms denominator.  The red lines are drawn by eye on the pattern of the black dots. This came from trying to create a probability distribution on the rationals where $$\Pr\left(X = \frac{a}{b}\right) = \frac{\zeta(k)}{\zeta(k-1) - \zeta(k) } \left(\frac{1}{b}\right)^k$$ where $0 \lt a \lt b$ with $a$ and $b$ coprime and where $k \gt 2$. The red lines look somewhat like the left half of the Stern-Brocot Tree except that points with different denominators are at different heights.","Has anyone come across a graph like this? The black circles represent rationals in $(0,1)$ and their heights are roughly proportional to the reciprocal of the square of their lowest terms denominator.  The red lines are drawn by eye on the pattern of the black dots. This came from trying to create a probability distribution on the rationals where $$\Pr\left(X = \frac{a}{b}\right) = \frac{\zeta(k)}{\zeta(k-1) - \zeta(k) } \left(\frac{1}{b}\right)^k$$ where $0 \lt a \lt b$ with $a$ and $b$ coprime and where $k \gt 2$. The red lines look somewhat like the left half of the Stern-Brocot Tree except that points with different denominators are at different heights.",,"['probability', 'graphing-functions', 'rational-numbers']"
28,Fundamental Theorem of Poker,Fundamental Theorem of Poker,,"I've been doing an investigation into the mathematics behind poker, and I have stumbled upon this theorem called 'The Fundamental Theorem of Poker', which is as follows: ""Every time you play a hand differently from the way you would have   played it if you could see all your opponents' cards, they gain; and   every time you play your hand the same way you would have played it if   you could see all their cards, they lose."" There has been many different articles on this rule, and most state that there is 'a strong mathematical background' and 'a practical application' of the Law of Iterated Expectations/Law of Total Expectation: E(X) = E(E(X|Y)) However, I am yet to encounter an explanation HOW those two things are related, and I'm not sure why the two are related in the first place. To my understanding one is more or less common sense and the other is about expectations. Can someone please explain to me the Law of Iterated Expectations implicates or at least is related to the Fundamental Theorem of Poker? P.S Upon further search, I've also found another theorem called 'Morton's Theorem'. It states that: In multi-way pots, a player’s expectation may be maximized by an opponent making a correct decision."" It's a direct contrast to the fundamental theorem in the way that it's stating players win when the opponents make a correct decision. I'm not quite sure why the two theorems exist when they seem like they're literal polar opposites of each other. I understand that Morton's theorem is for several players while the Fundamental Theorem is only for two players, but I'm unclear on why more players would suddenly reverse what is described by the Fundamental Theorem. If you can, can you please explain why such is the case?","I've been doing an investigation into the mathematics behind poker, and I have stumbled upon this theorem called 'The Fundamental Theorem of Poker', which is as follows: ""Every time you play a hand differently from the way you would have   played it if you could see all your opponents' cards, they gain; and   every time you play your hand the same way you would have played it if   you could see all their cards, they lose."" There has been many different articles on this rule, and most state that there is 'a strong mathematical background' and 'a practical application' of the Law of Iterated Expectations/Law of Total Expectation: E(X) = E(E(X|Y)) However, I am yet to encounter an explanation HOW those two things are related, and I'm not sure why the two are related in the first place. To my understanding one is more or less common sense and the other is about expectations. Can someone please explain to me the Law of Iterated Expectations implicates or at least is related to the Fundamental Theorem of Poker? P.S Upon further search, I've also found another theorem called 'Morton's Theorem'. It states that: In multi-way pots, a player’s expectation may be maximized by an opponent making a correct decision."" It's a direct contrast to the fundamental theorem in the way that it's stating players win when the opponents make a correct decision. I'm not quite sure why the two theorems exist when they seem like they're literal polar opposites of each other. I understand that Morton's theorem is for several players while the Fundamental Theorem is only for two players, but I'm unclear on why more players would suddenly reverse what is described by the Fundamental Theorem. If you can, can you please explain why such is the case?",,"['probability', 'expectation', 'conditional-expectation', 'poker']"
29,Expected number of steps to finish all the cookies,Expected number of steps to finish all the cookies,,"Please help on this question: Steve has 256 cookies. Each cookie has a label that is a distinct subset of $\{1,2,3,4,5,6,7,8\}$. At each step, Steve chooses a cookie randomly and eats it as well as all othe cookies whose label is a subset of the chosen one. What is the expected number of steps Steve takes before finishing all the cookies? All I could find was that he should anyway eat the root cookie with the $\{1,2,3,4,5,6,7,8\}$ to finish the game. But the probability to choose it depends on what kind of cookies he has chosen before he grabs the final one, and I have no idea how to tackle it. Thanks. I tried to see what happens for a much simplified case. If Steve has 4 cookies that are subsets of {$1,2$}, the possible cases are: \begin{align} &\emptyset\rightarrow\{1\}\rightarrow\{2\}\rightarrow\{1,2\}&=4\times\frac14\times\frac13\times\frac12\\ &\emptyset\rightarrow\{2\}\rightarrow\{1\}\rightarrow\{1,2\}&=4\times\frac14\times\frac13\times\frac12\\ &\emptyset\rightarrow\{1\}\rightarrow\{1,2\}&=3\times\frac14\times\frac13\times\frac12\\ &\emptyset\rightarrow\{2\}\rightarrow\{1,2\}&=3\times\frac14\times\frac13\times\frac12\\ &\emptyset\rightarrow\{1,2\}&=2\times\frac14\times\frac13\\ &\{1\}\rightarrow\{2\}\rightarrow\{1,2\}&=3\times\frac14\times\frac12\\ &\{1\}\rightarrow\{1,2\}&=2\times\frac14\times\frac12\\ &\{2\}\rightarrow\{1\}\rightarrow\{1,2\}&=3\times\frac14\times\frac12\\ &\{2\}\rightarrow\{1,2\}&=2\times\frac14\times\frac12\\ &\{1,2\}&=1\times\frac14\\ \end{align} that sums up to $\cfrac94$.","Please help on this question: Steve has 256 cookies. Each cookie has a label that is a distinct subset of $\{1,2,3,4,5,6,7,8\}$. At each step, Steve chooses a cookie randomly and eats it as well as all othe cookies whose label is a subset of the chosen one. What is the expected number of steps Steve takes before finishing all the cookies? All I could find was that he should anyway eat the root cookie with the $\{1,2,3,4,5,6,7,8\}$ to finish the game. But the probability to choose it depends on what kind of cookies he has chosen before he grabs the final one, and I have no idea how to tackle it. Thanks. I tried to see what happens for a much simplified case. If Steve has 4 cookies that are subsets of {$1,2$}, the possible cases are: \begin{align} &\emptyset\rightarrow\{1\}\rightarrow\{2\}\rightarrow\{1,2\}&=4\times\frac14\times\frac13\times\frac12\\ &\emptyset\rightarrow\{2\}\rightarrow\{1\}\rightarrow\{1,2\}&=4\times\frac14\times\frac13\times\frac12\\ &\emptyset\rightarrow\{1\}\rightarrow\{1,2\}&=3\times\frac14\times\frac13\times\frac12\\ &\emptyset\rightarrow\{2\}\rightarrow\{1,2\}&=3\times\frac14\times\frac13\times\frac12\\ &\emptyset\rightarrow\{1,2\}&=2\times\frac14\times\frac13\\ &\{1\}\rightarrow\{2\}\rightarrow\{1,2\}&=3\times\frac14\times\frac12\\ &\{1\}\rightarrow\{1,2\}&=2\times\frac14\times\frac12\\ &\{2\}\rightarrow\{1\}\rightarrow\{1,2\}&=3\times\frac14\times\frac12\\ &\{2\}\rightarrow\{1,2\}&=2\times\frac14\times\frac12\\ &\{1,2\}&=1\times\frac14\\ \end{align} that sums up to $\cfrac94$.",,['probability']
30,Is there an intuitive way to see this property of random walks?,Is there an intuitive way to see this property of random walks?,,"For an $n$-step symmetric simple random walk (start at origin 0 and each step 1 unit towards left or right with equal probability,) an interesting fact is that the probability that you stop exactly at $r$ is equal to the probability that in the whole walk you've never reached $r+1$ but you've been to $r$. Is there a intuitive way to see this? Here, $n$ and $r$ are positive even numbers.","For an $n$-step symmetric simple random walk (start at origin 0 and each step 1 unit towards left or right with equal probability,) an interesting fact is that the probability that you stop exactly at $r$ is equal to the probability that in the whole walk you've never reached $r+1$ but you've been to $r$. Is there a intuitive way to see this? Here, $n$ and $r$ are positive even numbers.",,"['probability', 'random-walk']"
31,Probability that $3$ hands of a clock in the same semi-circle?,Probability that  hands of a clock in the same semi-circle?,3,"I am wondering how to calculate the probability that $3$ hands of a clock are in the same semi-circle ? I know a similar question is that if we randomly choose n points in a circle, then the probability that all of them in the same semi-circle will be $n/2^{(n-1)}$ with $n = 3$ . But when it comes to the dial hands, where I guess there are correlations between them, I am not sure whether my question is equivalent to the previous one. If they are not equivalent, and this question will be hard to calculate, then whether we can determinate this probability will be greater or smaller than $3/4$ ? Anyone can help? Thanks.","I am wondering how to calculate the probability that hands of a clock are in the same semi-circle ? I know a similar question is that if we randomly choose n points in a circle, then the probability that all of them in the same semi-circle will be with . But when it comes to the dial hands, where I guess there are correlations between them, I am not sure whether my question is equivalent to the previous one. If they are not equivalent, and this question will be hard to calculate, then whether we can determinate this probability will be greater or smaller than ? Anyone can help? Thanks.",3 n/2^{(n-1)} n = 3 3/4,"['probability', 'probability-theory']"
32,Concentration of measure bounds for multivariate Gaussian distributions (fixed),Concentration of measure bounds for multivariate Gaussian distributions (fixed),,"Let $\gamma_n$ denote the standard Gaussian measure on $\mathbb{R}^n$. It is known (see for example Cor 2.3 here: http://www.math.lsa.umich.edu/~barvinok/total710.pdf ) that $$\gamma_n\{x\in\mathbb{R}^n: \|x\|^2 \ge \frac{n}{1-\epsilon}\}\ge e^{-\epsilon n/4}$$and $$\gamma_n\{x\in\mathbb{R}^n: \|x\|^2 \le (1-\epsilon)n\}\le e^{-\epsilon n/4}.$$ Given a Gaussian distribution with covariance $\Sigma$, what can we say about the distribution of the norm? That is, what happens if rather than the standard Gaussian we consider the measure induced by $N(\vec{0},\Sigma)$, for some positive semidefinite $\Sigma$? I think we should get similar bounds along the lines of $$\gamma_n\{x\in\mathbb{R}^n: \|x\|^2 \ge \frac{\operatorname{Trace}(\Sigma)}{1-\epsilon}\}\ge e^{-\epsilon n/4}$$and $$\gamma_n\{x\in\mathbb{R}^n: \|x\|^2 \le (1-\epsilon)\cdot\operatorname{Trace}(\Sigma)\}\le e^{-\epsilon n/4}.$$ I think it should be the trace since Tr$(\frac1n\sum x_i x_i^T) = \frac1n\sum \|x_i\|^2\to\mathbb{E} \|x\|^2$. Is this true? If so, is the derivation straightforward given the standard normal tail bound? It doesn't seem trivial, though often these things are simple modifications of the $N(0,I)$ case. I believe one can reduce the problem to proving  $$\gamma_n\{x\in\mathbb{R}^n: x^t \Sigma^{-1} x \ge \frac{\operatorname{Trace}(\Sigma)}{1-\epsilon}\}\ge e^{-\epsilon n/4}$$and $$\gamma_n\{x\in\mathbb{R}^n: x^t \Sigma^{-1} x \le (1-\epsilon)\cdot\operatorname{Trace}(\Sigma)\}\le e^{-\epsilon n/4},$$ but as the transformed variable leads to a factor of $|\det\Sigma|$, it seems like I'm on the wrong track.","Let $\gamma_n$ denote the standard Gaussian measure on $\mathbb{R}^n$. It is known (see for example Cor 2.3 here: http://www.math.lsa.umich.edu/~barvinok/total710.pdf ) that $$\gamma_n\{x\in\mathbb{R}^n: \|x\|^2 \ge \frac{n}{1-\epsilon}\}\ge e^{-\epsilon n/4}$$and $$\gamma_n\{x\in\mathbb{R}^n: \|x\|^2 \le (1-\epsilon)n\}\le e^{-\epsilon n/4}.$$ Given a Gaussian distribution with covariance $\Sigma$, what can we say about the distribution of the norm? That is, what happens if rather than the standard Gaussian we consider the measure induced by $N(\vec{0},\Sigma)$, for some positive semidefinite $\Sigma$? I think we should get similar bounds along the lines of $$\gamma_n\{x\in\mathbb{R}^n: \|x\|^2 \ge \frac{\operatorname{Trace}(\Sigma)}{1-\epsilon}\}\ge e^{-\epsilon n/4}$$and $$\gamma_n\{x\in\mathbb{R}^n: \|x\|^2 \le (1-\epsilon)\cdot\operatorname{Trace}(\Sigma)\}\le e^{-\epsilon n/4}.$$ I think it should be the trace since Tr$(\frac1n\sum x_i x_i^T) = \frac1n\sum \|x_i\|^2\to\mathbb{E} \|x\|^2$. Is this true? If so, is the derivation straightforward given the standard normal tail bound? It doesn't seem trivial, though often these things are simple modifications of the $N(0,I)$ case. I believe one can reduce the problem to proving  $$\gamma_n\{x\in\mathbb{R}^n: x^t \Sigma^{-1} x \ge \frac{\operatorname{Trace}(\Sigma)}{1-\epsilon}\}\ge e^{-\epsilon n/4}$$and $$\gamma_n\{x\in\mathbb{R}^n: x^t \Sigma^{-1} x \le (1-\epsilon)\cdot\operatorname{Trace}(\Sigma)\}\le e^{-\epsilon n/4},$$ but as the transformed variable leads to a factor of $|\det\Sigma|$, it seems like I'm on the wrong track.",,"['probability', 'measure-theory', 'probability-distributions', 'normal-distribution', 'concentration-of-measure']"
33,Probability that the number of heads is coprime with the number of throws,Probability that the number of heads is coprime with the number of throws,,"Let's throw a coin $n$ times. Say that we have obtained heads $k$ times and tails $n-k$ times. I'm interested in the probability that the number of heads is coprime with the total number of throws. Obviously, this probability is described by the formula $$ P=\sum_{\substack{0<k<n,\\gcd(k, n)=1}}\binom{n}{k}p^k(1-p)^{n-k}, $$ where $p\in(0, 1)$ is a probability of throwing heads. The question. Is it true that this sum is lower bounded by some positive constant for all integers $n > 1$ ? My thoughts. I think that it should be true. Take $p=1/2$ for simplicity. Some computer calculations suggest that $P\ge 0.1875$ , and this bound is achieved for $n=6$ . But I don't know how to prove it. It's also easy to show that $P\ge c n^{-1/2}$ for some constant $c$ because we can always find such number $k$ , which is coprime with $n$ and close to $n/2$ . But this bound is too weak. Update. @donaastor made some interesting comments below and convinced me that for all constant $p$ the lower limit of the probability equals 0. Also, further computer calculations for $p=1/2$ showed that the probability for $n=30030$ is lower than for n=6 and equals $\approx 0.1828$ .","Let's throw a coin times. Say that we have obtained heads times and tails times. I'm interested in the probability that the number of heads is coprime with the total number of throws. Obviously, this probability is described by the formula where is a probability of throwing heads. The question. Is it true that this sum is lower bounded by some positive constant for all integers ? My thoughts. I think that it should be true. Take for simplicity. Some computer calculations suggest that , and this bound is achieved for . But I don't know how to prove it. It's also easy to show that for some constant because we can always find such number , which is coprime with and close to . But this bound is too weak. Update. @donaastor made some interesting comments below and convinced me that for all constant the lower limit of the probability equals 0. Also, further computer calculations for showed that the probability for is lower than for n=6 and equals .","n k n-k 
P=\sum_{\substack{0<k<n,\\gcd(k, n)=1}}\binom{n}{k}p^k(1-p)^{n-k},
 p\in(0, 1) n > 1 p=1/2 P\ge 0.1875 n=6 P\ge c n^{-1/2} c k n n/2 p p=1/2 n=30030 \approx 0.1828","['probability', 'number-theory']"
34,Survivor distribution following a zombie outbreak,Survivor distribution following a zombie outbreak,,"Suppose there is initially a population of $A$ humans and $B$ zombies. You are sitting on a nearby hill with a shotgun; however, you're not a very good shot, so each time you pull the trigger, one of the members of the population is hit uniformly at random. If you hit a zombie, the zombie dies. If you hit a human, the zombies pile onto the poor wounded human and turn them into a new zombie. Undeterred by your lack of skill, you continue to take shots into the population until there are no more zombies. At this point, what can be said about the distribution of the number of human survivors? For example, we can try to compute the probability $q(A,B)$ that there are no survivors at the end of the process. This quantity should satisfy the recurrence $$q(A,B) = \frac{A}{A+B} q(A-1, B+1) + \frac{B}{A+B} q(A, B-1)$$ with the initial conditions $q(0,k) = 1$ for $k\ge 0$ and $q(k,0) = 0$ for $k>0$ . Is there a simple formula for $q(A,B)$ or reasonable asymptotics? What can be said about the probability $q(k,A,B)$ that there are $k$ survivors for $1\le k \le A$ ? Also, looking at some data seems to suggest that we always have a ""reverse unimodal"" property $$q(0,A,B) > q(1,A,B) > \cdots < q(A-1, A, B) < q(A, A, B)$$ with $q(0,A, B) > q(A, A, B)$ , i.e. it is likeliest to have zero survivors. Is it possible to show this in general?","Suppose there is initially a population of humans and zombies. You are sitting on a nearby hill with a shotgun; however, you're not a very good shot, so each time you pull the trigger, one of the members of the population is hit uniformly at random. If you hit a zombie, the zombie dies. If you hit a human, the zombies pile onto the poor wounded human and turn them into a new zombie. Undeterred by your lack of skill, you continue to take shots into the population until there are no more zombies. At this point, what can be said about the distribution of the number of human survivors? For example, we can try to compute the probability that there are no survivors at the end of the process. This quantity should satisfy the recurrence with the initial conditions for and for . Is there a simple formula for or reasonable asymptotics? What can be said about the probability that there are survivors for ? Also, looking at some data seems to suggest that we always have a ""reverse unimodal"" property with , i.e. it is likeliest to have zero survivors. Is it possible to show this in general?","A B q(A,B) q(A,B) = \frac{A}{A+B} q(A-1, B+1) + \frac{B}{A+B} q(A, B-1) q(0,k) = 1 k\ge 0 q(k,0) = 0 k>0 q(A,B) q(k,A,B) k 1\le k \le A q(0,A,B) > q(1,A,B) > \cdots < q(A-1, A, B) < q(A, A, B) q(0,A, B) > q(A, A, B)","['probability', 'combinatorics', 'probability-theory']"
35,Prove Intersection of $\sigma$-algebras is a $\sigma$-algebra and the powerset is a $\sigma$-algebra,Prove Intersection of -algebras is a -algebra and the powerset is a -algebra,\sigma \sigma \sigma,"Fix a set $\Omega$. A $\sigma$-algebra on $\Omega$ is a non-empty collection of subsets of $\Omega$ closed under taking complements and countable unions. I'd like to prove that (1) for finite $\Omega$, $2^\Omega$ is a $\sigma$-algebra and that (2) the intersection of a family of $\sigma$-algebras is a $\sigma$-algebra. Are these proofs correct? The def. says ""non-empty collection"" so the collection contains something and the complement of that something hence the whole things $\Omega$. Since it contains the whole things, it contains its complement, hence the empty set $\emptyset$. This guarantees that $2^\Omega$ and $\bigcap \mathcal{A_i}$ of $\sigma$-algebras $\mathcal{A_i}$ are non-empty. (Stmt 1) Pf . $2^\Omega$ contains all subsets of $\Omega$. So it's closed under taking complements and countable unions. (Stmt 2) Pf . Let $\{\mathcal{A_i}\}$ be a family of $\sigma$-algebras. $A\in \bigcap \mathcal{A_i}\implies A\in \mathcal{A_i} \forall i\implies A^c \in\mathcal{A_i}\forall i\implies A^c\in \bigcap \mathcal{A_i}$ Let $A_j\in \bigcap \mathcal{A_i}$ for $j\in J$. Then $A_j\in \mathcal{A_i} \forall i \forall j$. Therefore $\bigcup A_j\in \mathcal{A_i} \forall i$. Hence $\bigcup A_j\in\bigcap\mathcal{A_i}$","Fix a set $\Omega$. A $\sigma$-algebra on $\Omega$ is a non-empty collection of subsets of $\Omega$ closed under taking complements and countable unions. I'd like to prove that (1) for finite $\Omega$, $2^\Omega$ is a $\sigma$-algebra and that (2) the intersection of a family of $\sigma$-algebras is a $\sigma$-algebra. Are these proofs correct? The def. says ""non-empty collection"" so the collection contains something and the complement of that something hence the whole things $\Omega$. Since it contains the whole things, it contains its complement, hence the empty set $\emptyset$. This guarantees that $2^\Omega$ and $\bigcap \mathcal{A_i}$ of $\sigma$-algebras $\mathcal{A_i}$ are non-empty. (Stmt 1) Pf . $2^\Omega$ contains all subsets of $\Omega$. So it's closed under taking complements and countable unions. (Stmt 2) Pf . Let $\{\mathcal{A_i}\}$ be a family of $\sigma$-algebras. $A\in \bigcap \mathcal{A_i}\implies A\in \mathcal{A_i} \forall i\implies A^c \in\mathcal{A_i}\forall i\implies A^c\in \bigcap \mathcal{A_i}$ Let $A_j\in \bigcap \mathcal{A_i}$ for $j\in J$. Then $A_j\in \mathcal{A_i} \forall i \forall j$. Therefore $\bigcup A_j\in \mathcal{A_i} \forall i$. Hence $\bigcup A_j\in\bigcap\mathcal{A_i}$",,"['probability', 'measure-theory', 'solution-verification']"
36,Probability of a winning consecutive $k$-subset out of $n$ coin flips,Probability of a winning consecutive -subset out of  coin flips,k n,"Assume we flip a coin $n$ times. A $k$-sequence is defined as any consecutive sequence of coin flips of length $k$. Call a $k$-sequence ""winning"" if there are strictly more heads than tails. What is the probability of there being a winning consecutive $k$-sequence in $n$ tosses? In order to clarify some of the definitions, here are some examples. Assume we have flipped the sequence $\rm HHTHT$. $2$-sequences: $\rm \underbrace{HH}THT, H\underbrace{HT}HT, HH\underbrace{TH}T, HHT\underbrace{HT}$, so $\rm HH, HT, TH, HT$ are consecutive $2$-sequences. Winning $2$-sequences: $\rm HH$. All $4$-flips with winning $2$-sequences highlighted, if there are multiples, I have selected the first one: $\rm \underbrace{HH}HH $ $\rm \underbrace{HH}HT $ $\rm \underbrace{HH}TH $ $\rm \underbrace{HH}TT $ $\rm HT\underbrace{HH} $ $\rm HTHT$ (no winning $2$-sequences) $\rm HTTH$ (no winning $2$-sequences) $\rm HTTT$ (no winning $2$-sequences) $\rm T\underbrace{HH}H$ $\rm T\underbrace{HH}T$ $\rm THTH$ (no winning $2$-sequences) $\rm THTT$ (no winning $2$-sequences) $\rm TT\underbrace{HH}$ $\rm TTHT$ (no winning $2$-sequences) $\rm TTTH$ (no winning $2$-sequences) $\rm TTTT$ (no winning $2$-sequences) Out of the $8$ combinations, there are $4$ which have winning $2$-sequences (we can choose $2$ consecutive flips from the sequence which have more heads than tails).  So $p(4, 2) = 8/16 = 1/2$.","Assume we flip a coin $n$ times. A $k$-sequence is defined as any consecutive sequence of coin flips of length $k$. Call a $k$-sequence ""winning"" if there are strictly more heads than tails. What is the probability of there being a winning consecutive $k$-sequence in $n$ tosses? In order to clarify some of the definitions, here are some examples. Assume we have flipped the sequence $\rm HHTHT$. $2$-sequences: $\rm \underbrace{HH}THT, H\underbrace{HT}HT, HH\underbrace{TH}T, HHT\underbrace{HT}$, so $\rm HH, HT, TH, HT$ are consecutive $2$-sequences. Winning $2$-sequences: $\rm HH$. All $4$-flips with winning $2$-sequences highlighted, if there are multiples, I have selected the first one: $\rm \underbrace{HH}HH $ $\rm \underbrace{HH}HT $ $\rm \underbrace{HH}TH $ $\rm \underbrace{HH}TT $ $\rm HT\underbrace{HH} $ $\rm HTHT$ (no winning $2$-sequences) $\rm HTTH$ (no winning $2$-sequences) $\rm HTTT$ (no winning $2$-sequences) $\rm T\underbrace{HH}H$ $\rm T\underbrace{HH}T$ $\rm THTH$ (no winning $2$-sequences) $\rm THTT$ (no winning $2$-sequences) $\rm TT\underbrace{HH}$ $\rm TTHT$ (no winning $2$-sequences) $\rm TTTH$ (no winning $2$-sequences) $\rm TTTT$ (no winning $2$-sequences) Out of the $8$ combinations, there are $4$ which have winning $2$-sequences (we can choose $2$ consecutive flips from the sequence which have more heads than tails).  So $p(4, 2) = 8/16 = 1/2$.",,"['probability', 'combinatorics']"
37,What's the probability that a sum of dice is prime?,What's the probability that a sum of dice is prime?,,"Prompted by today's Minute Math question on the MAA site ( http://amc.maa.org/mathclub/5-0,problems/T-problems/T-web,ia/2005web/tb05-12-ia.shtml ), I started thinking about the probability that the sum of the numbers rolled on a set of $n$ dice is prime, particularly the asymptotics as $n\rightarrow\infty$.  Heuristics strongly suggest that this is proportional to $1/\mathrm{ln}\ n$, and in fact, that it's $1/\mathrm{ln}\ n - O(1/\mathrm{ln}^2n)$, but I'm wondering how I would go about getting better asymptotics on the second term. For the record, the heuristic argument goes something like this: assume for concreteness' sake that we're rolling 6-sided dice.  Then the sum of the dice is closely approximated by a normal variable with mean $\mu=7n/2$ and variance $\sigma^2=35n/12$, and since the PNT says that the 'probability' of an integer $n$ being prime is roughly $1/\mathrm{ln}\ n$, we should be able to integrate that probability with respect to the normal distribution: $$p = {1\over \sqrt{2\pi\sigma^2}}\int_n^{6n} e^{-\left({(t-\mu)^2\over 2\sigma^2}\right)} {1\over\mathrm{ln}\ t} dt$$ And since $1/\mathrm{ln}\ t$ is monotonic, the value of the integral is bounded by the values we get by replacing its term in the integral with its maximum and minimum values on the integration interval: $${1\over\mathrm{ln}\ 6n} {1\over \sqrt{2\pi\sigma^2}}\int_n^{6n} e^{-\left({(t-\mu)^2\over 2\sigma^2}\right)} dt < p < {1\over\mathrm{ln}\ n} {1\over \sqrt{2\pi\sigma^2}}\int_n^{6n} e^{-\left({(t-\mu)^2\over 2\sigma^2}\right)} dt$$ Both of the integrals in the latter formula are essentially 1 (by definition), so we get ${1\over\mathrm{ln}\ 6n} < p < {1\over\mathrm{ln}\ n}$; replacing $\mathrm{ln}\ 6n$ by $(\mathrm{ln}\ 6 + \mathrm{ln}\ n)$ and using the binomial formula gives the heuristic approximation I alluded to above.  This leads me to a couple of questions: How safe is the heuristic argument above?  I know that the PNT gives good bounds on the number of primes in an interval (on the order of $n^{1/2}$ here, which in particular means that the error from the prime-counting would be $O(n^{-1/2})$ and so much smaller than the inverse-log terms above), but my analytic number theory isn't good enough to know whether 'weighting' by the normal distribution would throw off the classical proofs. How would I go about evaluating the integral above?  Obviously the bounds I use bring it in to a fairly small range, but it seems as though to get a second term in my asymptotics I'd need to be able to at least approximate the integral, and there aren't any obvious tricks that look like they'd handle it well...","Prompted by today's Minute Math question on the MAA site ( http://amc.maa.org/mathclub/5-0,problems/T-problems/T-web,ia/2005web/tb05-12-ia.shtml ), I started thinking about the probability that the sum of the numbers rolled on a set of $n$ dice is prime, particularly the asymptotics as $n\rightarrow\infty$.  Heuristics strongly suggest that this is proportional to $1/\mathrm{ln}\ n$, and in fact, that it's $1/\mathrm{ln}\ n - O(1/\mathrm{ln}^2n)$, but I'm wondering how I would go about getting better asymptotics on the second term. For the record, the heuristic argument goes something like this: assume for concreteness' sake that we're rolling 6-sided dice.  Then the sum of the dice is closely approximated by a normal variable with mean $\mu=7n/2$ and variance $\sigma^2=35n/12$, and since the PNT says that the 'probability' of an integer $n$ being prime is roughly $1/\mathrm{ln}\ n$, we should be able to integrate that probability with respect to the normal distribution: $$p = {1\over \sqrt{2\pi\sigma^2}}\int_n^{6n} e^{-\left({(t-\mu)^2\over 2\sigma^2}\right)} {1\over\mathrm{ln}\ t} dt$$ And since $1/\mathrm{ln}\ t$ is monotonic, the value of the integral is bounded by the values we get by replacing its term in the integral with its maximum and minimum values on the integration interval: $${1\over\mathrm{ln}\ 6n} {1\over \sqrt{2\pi\sigma^2}}\int_n^{6n} e^{-\left({(t-\mu)^2\over 2\sigma^2}\right)} dt < p < {1\over\mathrm{ln}\ n} {1\over \sqrt{2\pi\sigma^2}}\int_n^{6n} e^{-\left({(t-\mu)^2\over 2\sigma^2}\right)} dt$$ Both of the integrals in the latter formula are essentially 1 (by definition), so we get ${1\over\mathrm{ln}\ 6n} < p < {1\over\mathrm{ln}\ n}$; replacing $\mathrm{ln}\ 6n$ by $(\mathrm{ln}\ 6 + \mathrm{ln}\ n)$ and using the binomial formula gives the heuristic approximation I alluded to above.  This leads me to a couple of questions: How safe is the heuristic argument above?  I know that the PNT gives good bounds on the number of primes in an interval (on the order of $n^{1/2}$ here, which in particular means that the error from the prime-counting would be $O(n^{-1/2})$ and so much smaller than the inverse-log terms above), but my analytic number theory isn't good enough to know whether 'weighting' by the normal distribution would throw off the classical proofs. How would I go about evaluating the integral above?  Obviously the bounds I use bring it in to a fairly small range, but it seems as though to get a second term in my asymptotics I'd need to be able to at least approximate the integral, and there aren't any obvious tricks that look like they'd handle it well...",,"['probability', 'number-theory', 'prime-numbers', 'recreational-mathematics', 'dice']"
38,Rigorous graduate probability textbook for self-study.,Rigorous graduate probability textbook for self-study.,,"I have checked several answers that request graduate-level probability theory textbooks, but I have wanted to receive advice that fits my particular needs. My background is in mathematics and I am currently pursuing Ph.D. degree in statistics, but I am still more geared toward mathematics. In my first-year Ph.D. course for probability theory, we used Durrett's Probability Theory and Examples , but I found that the book is too terse for a first reading. I had no problem reading Terrace Tao's Introduction to Measure Theory and Folland's Real Analysis in my real analysis course, but the proofs in Durrett's book were often incomplete and most of the exercises were too hard to solve for someone who is studying the topic for the first time. Therefore, I am planning to use another textbook to supplement Durrett's, and I wanted to ask you advice on which books would be the best choice for me I wish the book is suitable for self-study, that is, it should have rather complete proofs to show each step especially in the earlier chapters. Since I have background in mathematics, I am looking for a book that is still rigorous so that it does not omit significant amount of proofs. Some of the alternatives I have found are Erhan Çinlar's Probability and Stochastics and Shiryaev's Probability 1, 2 . I have asked to my professor about the textbook and it seems like he approves of it, but I wanted to see other options as well. I would love to hear your recommendations and your rationales behind recommending the books. [Edited] Added Shiryaev's Probability series.","I have checked several answers that request graduate-level probability theory textbooks, but I have wanted to receive advice that fits my particular needs. My background is in mathematics and I am currently pursuing Ph.D. degree in statistics, but I am still more geared toward mathematics. In my first-year Ph.D. course for probability theory, we used Durrett's Probability Theory and Examples , but I found that the book is too terse for a first reading. I had no problem reading Terrace Tao's Introduction to Measure Theory and Folland's Real Analysis in my real analysis course, but the proofs in Durrett's book were often incomplete and most of the exercises were too hard to solve for someone who is studying the topic for the first time. Therefore, I am planning to use another textbook to supplement Durrett's, and I wanted to ask you advice on which books would be the best choice for me I wish the book is suitable for self-study, that is, it should have rather complete proofs to show each step especially in the earlier chapters. Since I have background in mathematics, I am looking for a book that is still rigorous so that it does not omit significant amount of proofs. Some of the alternatives I have found are Erhan Çinlar's Probability and Stochastics and Shiryaev's Probability 1, 2 . I have asked to my professor about the textbook and it seems like he approves of it, but I wanted to see other options as well. I would love to hear your recommendations and your rationales behind recommending the books. [Edited] Added Shiryaev's Probability series.",,"['probability', 'probability-theory', 'reference-request', 'book-recommendation']"
39,Gambling puzzle,Gambling puzzle,,A math friend of mine showed me this strange gambling puzzle.  There is a button in a casino and every time you press it you can win either $1$ or $0$ dollars. The probability of winning $1$ dollar depends on how many times you have pressed it so far.  If you press it for the $x$-th time you have probability $x/M$ of winning a dollar. If $x$ gets to $M$ or greater then you just win a dollar every time. How many button presses do you expect to have to press to win $N$ dollars?,A math friend of mine showed me this strange gambling puzzle.  There is a button in a casino and every time you press it you can win either $1$ or $0$ dollars. The probability of winning $1$ dollar depends on how many times you have pressed it so far.  If you press it for the $x$-th time you have probability $x/M$ of winning a dollar. If $x$ gets to $M$ or greater then you just win a dollar every time. How many button presses do you expect to have to press to win $N$ dollars?,,['probability']
40,Bound variance proxy of a subGaussian random variable by its variance,Bound variance proxy of a subGaussian random variable by its variance,,"If I know $X$ is a sub-Gaussian random variable, and I know it has finite variance $\sigma^2$. Can I assert that $\sigma^2$ is a valid variance proxy for $X$? Definition (sub-Gaussian Random Variable) A random variable $X$ is called sub-Gaussian with variance proxy $\sigma^2$, if $E[X] = 0$ $E[\exp(sX)] \leq \exp(s^2\sigma^2/2), \quad \forall s\in\mathbb{R}$ Note the variance proxy is not unique. Any larger number than a valid variance proxy is still a valid variance proxy. I can easily show using the moment generating function that the variance proxy of a sub-Gaussian random variable is greater than or equal to its variance . But I'm not sure about the inverse direction.","If I know $X$ is a sub-Gaussian random variable, and I know it has finite variance $\sigma^2$. Can I assert that $\sigma^2$ is a valid variance proxy for $X$? Definition (sub-Gaussian Random Variable) A random variable $X$ is called sub-Gaussian with variance proxy $\sigma^2$, if $E[X] = 0$ $E[\exp(sX)] \leq \exp(s^2\sigma^2/2), \quad \forall s\in\mathbb{R}$ Note the variance proxy is not unique. Any larger number than a valid variance proxy is still a valid variance proxy. I can easily show using the moment generating function that the variance proxy of a sub-Gaussian random variable is greater than or equal to its variance . But I'm not sure about the inverse direction.",,"['probability', 'probability-theory']"
41,Create the most 'stressful' tennis match ever!,Create the most 'stressful' tennis match ever!,,"Some sports, such as tennis, use a complicated points system (point, game, set, match; with deuces and tie-breaks) for what would otherwise be an extremely simple and monotonous sport. The main reason, I suppose, is to make the sport more stressful, by making some parts of the match more crucial than others. It should be possible to make it a lot more 'stressful' mathematically. Mathematical scenario: There is an event, played by 2 players, worth 1 point. The probability of winning the entire match, if they (a) win (b) lose the next point is calculated. The difference between these values is the 'stress' value of that point. The sum of all the stress values is called the 'total stress' value of the match, and this number divided by the number of points played is the 'average stress'. For players of equal skill, and stress-handling, the probability of either player winning any given point is $\frac12$. The 'skill' of a player is a randomly generated number from $0\%$ to $100\%$, and the probability of a player winning a point is given by $\frac{Skill(own)}{Skill(own)+Skill(opponent)}$ Your job is to create a points system, however simple or complicated, using any kind of conditions, limits, etc, that produces the maximum possible: (a) Total stress (b) Average stress for a match. You are allowed to create your own definitions of 'point', 'set' and so on, however, the 'points' I am referring to is a single valid serve (double faults to be ignored) with a single winner. The only constraint is that the total number of points played should be between $1000$ and $1500$ for at least $90\%$ of the scenarios (9 in every 10 matches should not have the players play less than $1000$ or more than $1500$ points).","Some sports, such as tennis, use a complicated points system (point, game, set, match; with deuces and tie-breaks) for what would otherwise be an extremely simple and monotonous sport. The main reason, I suppose, is to make the sport more stressful, by making some parts of the match more crucial than others. It should be possible to make it a lot more 'stressful' mathematically. Mathematical scenario: There is an event, played by 2 players, worth 1 point. The probability of winning the entire match, if they (a) win (b) lose the next point is calculated. The difference between these values is the 'stress' value of that point. The sum of all the stress values is called the 'total stress' value of the match, and this number divided by the number of points played is the 'average stress'. For players of equal skill, and stress-handling, the probability of either player winning any given point is $\frac12$. The 'skill' of a player is a randomly generated number from $0\%$ to $100\%$, and the probability of a player winning a point is given by $\frac{Skill(own)}{Skill(own)+Skill(opponent)}$ Your job is to create a points system, however simple or complicated, using any kind of conditions, limits, etc, that produces the maximum possible: (a) Total stress (b) Average stress for a match. You are allowed to create your own definitions of 'point', 'set' and so on, however, the 'points' I am referring to is a single valid serve (double faults to be ignored) with a single winner. The only constraint is that the total number of points played should be between $1000$ and $1500$ for at least $90\%$ of the scenarios (9 in every 10 matches should not have the players play less than $1000$ or more than $1500$ points).",,"['probability', 'probability-distributions', 'combinatorial-game-theory']"
42,"Cramér's Model - ""The Prime Numbers and Their Distribution"" - Part 1","Cramér's Model - ""The Prime Numbers and Their Distribution"" - Part 1",,"I was reading ""The Prime Numbers and Their Distribution"" by Gérald Tenenbaum and Michel Mendès France, the section about Cramér's Model, and I couldn't prove a couple of results. I would like to start with an introduction of the topic. Introduction: Cramér's Model consists in considering a sequence of independent random variables $\{X_n\}_{n=2}^\infty$ which take values 0 and 1, such that $\Bbb P (X_n=1)=1/\log n$ for $n \ge 3$. The definition of $\Bbb P (X_2=1)$ is considered irrelevant for the purposes of the model. The idea of this is to give a probabilistic model for the behaviour of prime numbers: according to the prime numbers theorem, the number of primes less or equal than $n$, with $n$ sufficiently large, is approximately $n/\log n$, so the ""probability that $n$ is prime"" would be $1/\log n$. Now we define $S:=\{n\ge2:X_n=1\}$. The usual way of working with this model seems to be, proving that some property holds almost surely for $S$, and then conjecturing that property holds for $\mathcal P$, the sequence of prime numbers. Question: By analogy to the usual notation, we define $\pi_S(x):=\sum_{n\le x} X_n$ (note that $\pi_\mathcal P(x)=\pi(x)$). We also define: $$\upsilon_S(x):=\frac{\pi_S(x)-\mathrm {li}(x)}{\sqrt{2x\frac{\log\log x}{\log x}}}$$ The book states that it's easy to show that $\upsilon_S(x)$ oscillates asymptotically between -1 and 1, but a paper by Cramér only states that it's shown in another paper (which I couldn't find) that $\limsup_{x\to \infty}|\upsilon_S(x)|=1$ holds almost surely. I understand that the statement of the book is that both, $\limsup_{x\to \infty}\upsilon_S(x)=1$ and $\liminf_{x\to \infty}\upsilon_S(x)=-1$, hold almost surely, but I could be wrong since I haven't found the definition of ""asymptotic oscillation"".","I was reading ""The Prime Numbers and Their Distribution"" by Gérald Tenenbaum and Michel Mendès France, the section about Cramér's Model, and I couldn't prove a couple of results. I would like to start with an introduction of the topic. Introduction: Cramér's Model consists in considering a sequence of independent random variables $\{X_n\}_{n=2}^\infty$ which take values 0 and 1, such that $\Bbb P (X_n=1)=1/\log n$ for $n \ge 3$. The definition of $\Bbb P (X_2=1)$ is considered irrelevant for the purposes of the model. The idea of this is to give a probabilistic model for the behaviour of prime numbers: according to the prime numbers theorem, the number of primes less or equal than $n$, with $n$ sufficiently large, is approximately $n/\log n$, so the ""probability that $n$ is prime"" would be $1/\log n$. Now we define $S:=\{n\ge2:X_n=1\}$. The usual way of working with this model seems to be, proving that some property holds almost surely for $S$, and then conjecturing that property holds for $\mathcal P$, the sequence of prime numbers. Question: By analogy to the usual notation, we define $\pi_S(x):=\sum_{n\le x} X_n$ (note that $\pi_\mathcal P(x)=\pi(x)$). We also define: $$\upsilon_S(x):=\frac{\pi_S(x)-\mathrm {li}(x)}{\sqrt{2x\frac{\log\log x}{\log x}}}$$ The book states that it's easy to show that $\upsilon_S(x)$ oscillates asymptotically between -1 and 1, but a paper by Cramér only states that it's shown in another paper (which I couldn't find) that $\limsup_{x\to \infty}|\upsilon_S(x)|=1$ holds almost surely. I understand that the statement of the book is that both, $\limsup_{x\to \infty}\upsilon_S(x)=1$ and $\liminf_{x\to \infty}\upsilon_S(x)=-1$, hold almost surely, but I could be wrong since I haven't found the definition of ""asymptotic oscillation"".",,"['probability', 'number-theory', 'prime-numbers']"
43,"""$n$-Yahtzee"" question","""-Yahtzee"" question",n,"Suppose that you have $n \geq 1$ standard 6-sided dice.  If all the dice display the same number, we call this an $n$-Yahtzee. Follow this algorithm: Roll all the dice.  Set aside those dice with the highest mode (Example, for 8 dice if I roll 1 2 4 4 4 5 6 6, set aside the 4s).  If two or more are tied, choose one of them.  This number will be fixed. For the remaining dice, roll them and set aside those dice matching the number from step 1. Repeat step 2 until you have obtained an $n$-Yahtzee. Question  : What is the average number of rolls (depending on $n$) that it takes to achieve an $n$-Yahtzee? There are many variants of this question I would also like to consider, judging from the interest received on this question.","Suppose that you have $n \geq 1$ standard 6-sided dice.  If all the dice display the same number, we call this an $n$-Yahtzee. Follow this algorithm: Roll all the dice.  Set aside those dice with the highest mode (Example, for 8 dice if I roll 1 2 4 4 4 5 6 6, set aside the 4s).  If two or more are tied, choose one of them.  This number will be fixed. For the remaining dice, roll them and set aside those dice matching the number from step 1. Repeat step 2 until you have obtained an $n$-Yahtzee. Question  : What is the average number of rolls (depending on $n$) that it takes to achieve an $n$-Yahtzee? There are many variants of this question I would also like to consider, judging from the interest received on this question.",,"['probability', 'recreational-mathematics', 'dice']"
44,Is there a Measure-Theoretic Proof of this new Result from Categorical Probability?,Is there a Measure-Theoretic Proof of this new Result from Categorical Probability?,,"Recently, I stumbled across a new paper in categorical probability . Interestingly, they prove a result which may be formulated in purely measure-theoretic terms about which they note that ""As far as we know, this strengthening is new, and in particular no measure-theoretic proof exists to date."" This makes me wonder about whether one can prove this in a measure-theoretic way, without the tools from categorical probability they developed. The point of this post is to state the result and explain the definitions from a viewpoint of measure theory. My question then is: Can we prove this Theorem with purely measure-theoretic tools, meaning without the tools of categorical probability used in the paper? Main Theorem Every idempotent Markov kernel between standard Borel spaces is balanced and splits. For further context, this Theorem is a stronger version of the more well-known Theorem due to Blackwell, which the authors formulate as follows: For a reference, see ""Idempotent Markoff Chains"" by Blackwell . Definitions Standard Borel Space: We say that $(X,\Sigma)$ is a standard Borel space if $X$ is metrizable with metric $d$ such that $\Sigma$ is the Borel- $\sigma$ -algebra generated by the topology of $(X,d)$ and $(X,d)$ is separable and complete. Markov Kernel: Let $(X,\mathcal A)$ and $(Y,\mathcal B)$ be measurable spaces. A Markov Kernel from $(X,\mathcal A)$ to $(Y,\mathcal B)$ is a map $\kappa:X\times\mathcal B\rightarrow [0,1]$ such that For every $B\in\mathcal B$ the map $x\mapsto \kappa(x,B)$ is $\mathcal A$ -measurable. For every $x\in X$ the map $B\mapsto \kappa(x,B)$ is a probability measure on $(Y,\mathcal B)$ . Example: If we consider Markov Chains on a discrete space, say $S:=\{1,2\}$ , usually described by a transition matrix $$e:=\begin{pmatrix}\frac{1}{4} & \frac{3}{4} \\ \frac{2}{5} & \frac{3}{5} \end{pmatrix}$$ then our spaces are $X=Y=S$ with their $\sigma$ -algebras being the power set of $S$ . The associated Markov Kernel $\kappa$ then is given by $$\begin{align*}\kappa(1,\{1\})&= \frac{1}{4}, \hspace{1cm}\kappa(1,\{2\})=\frac{3}{4} \\ \kappa(2,\{1\})&=\frac{2}{5}, \hspace{1cm}\kappa(2,\{2\})=\frac{3}{5}\end{align*}$$ where one may interpret $\kappa(x,B)$ as $\mathbb P[X_1\in B|X_0=x]$ if $(X_n)_{n\in\mathbb N}$ is a Markov Chain with transition matrix $e$ . Composition of Markov Kernels Let $(X,\mathcal A), (Y,\mathcal B), (Z,\mathcal C)$ be three measurable spaces and let $\kappa$ be a Markov Kernel from $X$ to $Y$ , let $\lambda$ be a Markov Kernel from $Y$ to $Z$ . We define the composition of the two kernels $\lambda\circ \kappa$ by $$(\lambda\circ \kappa)(x,dz):=\int_Y \lambda(y,dz)\kappa(x,dy)$$ Example: If we consider again the case of a discrete state space, we may represent Markov Kernels as stochastic matrices. Composition of two Kernels then equates to the product of the corresponding matrices. We may now view Markov Kernels as morphisms. Idempotence: We say an morphism $e:X\rightarrow X$ is idempotent if it satisfies $e\circ e = e$ . Example: Examples of  idempotent transition kernels on the state space $S:=\{1,2\}$ would be $$e_1=\begin{pmatrix}1 & 0  \\ 0 & 1\end{pmatrix},\hspace{1cm}e_2=\begin{pmatrix}\frac12 & \frac12  \\ \frac12 & \frac12\end{pmatrix}$$ Splitting: Given an idempotent $e:X\rightarrow X$ , we say that $e$ splits if there exists a $T$ and morphisms $$\iota:T\rightarrow X, \hspace{1cm} \pi:X\rightarrow T$$ such that $$\pi\circ \iota =\text{id}_T, \hspace{1cm} \iota\circ \pi=e$$ Example: (Example 4.1.4.) Consider the discrete state space $S:=\{1,2\}$ and define a Markov Chain on $S$ by the transition kernel $$e=\begin{pmatrix}\frac12 & \frac12 \\ \frac12 & \frac12\end{pmatrix}$$ Then for $$\iota:=\begin{pmatrix}\frac12 \\ \frac12 \end{pmatrix}, \hspace{1cm} \pi:=\begin{pmatrix} 1 & 1\end{pmatrix}$$ we see that $\pi\circ\iota =\text{id}$ as well as $\iota\circ \pi=e$ . (Here composition is considered as matrix-multiplication). Balanced: We say that $e$ is balanced if for every invariant distribution $\pi$ of $e$ , meaning $e\pi=\pi$ , we have that a Markov Chain with transition kernel $e$ and initial (stationary) distribution $\pi$ is reversible. (I am not entirely sure that I understood this definition correctly. Please take a look at Definition 4.1.1 and Proposition 4.1.10 in the paper and correct me if you feel like I am stating the wrong definition here)","Recently, I stumbled across a new paper in categorical probability . Interestingly, they prove a result which may be formulated in purely measure-theoretic terms about which they note that ""As far as we know, this strengthening is new, and in particular no measure-theoretic proof exists to date."" This makes me wonder about whether one can prove this in a measure-theoretic way, without the tools from categorical probability they developed. The point of this post is to state the result and explain the definitions from a viewpoint of measure theory. My question then is: Can we prove this Theorem with purely measure-theoretic tools, meaning without the tools of categorical probability used in the paper? Main Theorem Every idempotent Markov kernel between standard Borel spaces is balanced and splits. For further context, this Theorem is a stronger version of the more well-known Theorem due to Blackwell, which the authors formulate as follows: For a reference, see ""Idempotent Markoff Chains"" by Blackwell . Definitions Standard Borel Space: We say that is a standard Borel space if is metrizable with metric such that is the Borel- -algebra generated by the topology of and is separable and complete. Markov Kernel: Let and be measurable spaces. A Markov Kernel from to is a map such that For every the map is -measurable. For every the map is a probability measure on . Example: If we consider Markov Chains on a discrete space, say , usually described by a transition matrix then our spaces are with their -algebras being the power set of . The associated Markov Kernel then is given by where one may interpret as if is a Markov Chain with transition matrix . Composition of Markov Kernels Let be three measurable spaces and let be a Markov Kernel from to , let be a Markov Kernel from to . We define the composition of the two kernels by Example: If we consider again the case of a discrete state space, we may represent Markov Kernels as stochastic matrices. Composition of two Kernels then equates to the product of the corresponding matrices. We may now view Markov Kernels as morphisms. Idempotence: We say an morphism is idempotent if it satisfies . Example: Examples of  idempotent transition kernels on the state space would be Splitting: Given an idempotent , we say that splits if there exists a and morphisms such that Example: (Example 4.1.4.) Consider the discrete state space and define a Markov Chain on by the transition kernel Then for we see that as well as . (Here composition is considered as matrix-multiplication). Balanced: We say that is balanced if for every invariant distribution of , meaning , we have that a Markov Chain with transition kernel and initial (stationary) distribution is reversible. (I am not entirely sure that I understood this definition correctly. Please take a look at Definition 4.1.1 and Proposition 4.1.10 in the paper and correct me if you feel like I am stating the wrong definition here)","(X,\Sigma) X d \Sigma \sigma (X,d) (X,d) (X,\mathcal A) (Y,\mathcal B) (X,\mathcal A) (Y,\mathcal B) \kappa:X\times\mathcal B\rightarrow [0,1] B\in\mathcal B x\mapsto \kappa(x,B) \mathcal A x\in X B\mapsto \kappa(x,B) (Y,\mathcal B) S:=\{1,2\} e:=\begin{pmatrix}\frac{1}{4} & \frac{3}{4} \\ \frac{2}{5} & \frac{3}{5} \end{pmatrix} X=Y=S \sigma S \kappa \begin{align*}\kappa(1,\{1\})&= \frac{1}{4}, \hspace{1cm}\kappa(1,\{2\})=\frac{3}{4} \\ \kappa(2,\{1\})&=\frac{2}{5}, \hspace{1cm}\kappa(2,\{2\})=\frac{3}{5}\end{align*} \kappa(x,B) \mathbb P[X_1\in B|X_0=x] (X_n)_{n\in\mathbb N} e (X,\mathcal A), (Y,\mathcal B), (Z,\mathcal C) \kappa X Y \lambda Y Z \lambda\circ \kappa (\lambda\circ \kappa)(x,dz):=\int_Y \lambda(y,dz)\kappa(x,dy) e:X\rightarrow X e\circ e = e S:=\{1,2\} e_1=\begin{pmatrix}1 & 0  \\ 0 & 1\end{pmatrix},\hspace{1cm}e_2=\begin{pmatrix}\frac12 & \frac12  \\ \frac12 & \frac12\end{pmatrix} e:X\rightarrow X e T \iota:T\rightarrow X, \hspace{1cm} \pi:X\rightarrow T \pi\circ \iota =\text{id}_T, \hspace{1cm} \iota\circ \pi=e S:=\{1,2\} S e=\begin{pmatrix}\frac12 & \frac12 \\ \frac12 & \frac12\end{pmatrix} \iota:=\begin{pmatrix}\frac12 \\ \frac12 \end{pmatrix}, \hspace{1cm} \pi:=\begin{pmatrix} 1 & 1\end{pmatrix} \pi\circ\iota =\text{id} \iota\circ \pi=e e \pi e e\pi=\pi e \pi","['probability', 'category-theory', 'markov-chains', 'markov-process']"
45,"How many random real numbers are needed for sum to exceed $1$, if each number is uniformly distributed from $0$ to constant $\times$ previous number?","How many random real numbers are needed for sum to exceed , if each number is uniformly distributed from  to constant  previous number?",1 0 \times,"Let $u_1$ be a random real number uniformly distributed between $0$ and $1$ . Let $u_k$ be a random real number uniformly distributed between $0$ and $a\times{u_{k-1}}$ , for $k>1$ and fixed positive real number $a$ . What is the expected minimum value of $n$ such that $\sum\limits_{k=1}^n u_k>1$ , in terms of $a$ ? (In other words, on average how many $u$ 's are needed for their sum to exceed $1$ ?) I did simulations using Excel. For small values of $a$ (e.g. $4$ ), sometimes the sequence of $u$ 's gets ""stuck"" around very low values, so that many $u$ 's are required for their sum to exceed $1$ . I suspect the expectation is infinity for low values of $a$ , and possibly for all values of $a$ . This is a variation of a simpler question: On average, how many uniformly random real number between $0$ and $1$ are needed for their sum to exceed $1$ ? The answer to that question is $e$ . I tried to apply similar methods to my question, to no avail.","Let be a random real number uniformly distributed between and . Let be a random real number uniformly distributed between and , for and fixed positive real number . What is the expected minimum value of such that , in terms of ? (In other words, on average how many 's are needed for their sum to exceed ?) I did simulations using Excel. For small values of (e.g. ), sometimes the sequence of 's gets ""stuck"" around very low values, so that many 's are required for their sum to exceed . I suspect the expectation is infinity for low values of , and possibly for all values of . This is a variation of a simpler question: On average, how many uniformly random real number between and are needed for their sum to exceed ? The answer to that question is . I tried to apply similar methods to my question, to no avail.",u_1 0 1 u_k 0 a\times{u_{k-1}} k>1 a n \sum\limits_{k=1}^n u_k>1 a u 1 a 4 u u 1 a a 0 1 1 e,"['probability', 'sequences-and-series', 'random-variables', 'expected-value']"
46,"5 cards are chosen from a standard deck. What is the probability that we get all four aces, plus the king of spades?","5 cards are chosen from a standard deck. What is the probability that we get all four aces, plus the king of spades?",,"We have $\binom{52}{5}$ ways of doing this. This will be our denominator. We want to select all 4 aces, there are there are exactly $\binom{4}{4}$ ways of doing this. Now we have selected 4 cards, and we need to select one more. That one card has to be the king of spades. Out of the 48 remaining cards, only one of them is our wanted one. This can be chosen in $\binom{48}{1}$ ways. So is the answer: $$\dfrac{\binom{4}{4}\binom{48}{1}}{\binom{52}{5}}=\dfrac{1}{54145}?$$ Is this correct? If we look at it another way: Then then our probability for the aces and specific king are $(4/52)\times (3/51) \times (2/50) \times (1/49) \times (1/48)$ which is a completely different here. Which is the correct approach?","We have $\binom{52}{5}$ ways of doing this. This will be our denominator. We want to select all 4 aces, there are there are exactly $\binom{4}{4}$ ways of doing this. Now we have selected 4 cards, and we need to select one more. That one card has to be the king of spades. Out of the 48 remaining cards, only one of them is our wanted one. This can be chosen in $\binom{48}{1}$ ways. So is the answer: $$\dfrac{\binom{4}{4}\binom{48}{1}}{\binom{52}{5}}=\dfrac{1}{54145}?$$ Is this correct? If we look at it another way: Then then our probability for the aces and specific king are $(4/52)\times (3/51) \times (2/50) \times (1/49) \times (1/48)$ which is a completely different here. Which is the correct approach?",,"['probability', 'combinatorics', 'statistics', 'discrete-mathematics']"
47,Expected Sum of 30 sided die rolls,Expected Sum of 30 sided die rolls,,Roll a 30-sided die. Add up each consecutive outcome. Stop rolling when the sum >= 300. What's the most likely result of the sum?,Roll a 30-sided die. Add up each consecutive outcome. Stop rolling when the sum >= 300. What's the most likely result of the sum?,,['probability']
48,Why is observing 100 heads for a fair coin flips surprising?,Why is observing 100 heads for a fair coin flips surprising?,,"Assume that we have a fair coin. We flip it 100 times. The outcome is all heads. Why is it surprising? Doesn't all outcomes have the same probability? Any particular outcome, including irregular ones, would have the same very small probability. Why is it that observing an irregular outcome is less surprising to us than a regular one?","Assume that we have a fair coin. We flip it 100 times. The outcome is all heads. Why is it surprising? Doesn't all outcomes have the same probability? Any particular outcome, including irregular ones, would have the same very small probability. Why is it that observing an irregular outcome is less surprising to us than a regular one?",,"['probability', 'statistics']"
49,Minesweeper probability,Minesweeper probability,,I ran into the situation pictured in the minesweeper game below. Note that the picture is only a small section of the entire board. Note: The bottom right $1$ is the bottom right corner tile of the board and all other tiles have been marked/deemed safe. What we know: There are exactly $2$ bombs left on the board Bombs can't be: (A & B) || (A & C) || (B & D) || (C & D) Bombs can be: (A & D) || (B & C) Can anyone prove if there is a square that is more likely to be safe/unsafe or is every square equally likely to be safe/unsafe?,I ran into the situation pictured in the minesweeper game below. Note that the picture is only a small section of the entire board. Note: The bottom right is the bottom right corner tile of the board and all other tiles have been marked/deemed safe. What we know: There are exactly bombs left on the board Bombs can't be: (A & B) || (A & C) || (B & D) || (C & D) Bombs can be: (A & D) || (B & C) Can anyone prove if there is a square that is more likely to be safe/unsafe or is every square equally likely to be safe/unsafe?,1 2,"['probability', 'combinatorics', 'algebra-precalculus', 'algorithms', 'combinatorial-geometry']"
50,Expected number of turns for a rook to move to top right-most corner?,Expected number of turns for a rook to move to top right-most corner?,,"Suppose a rook starts on the lower left-most square of a standard $8 \times 8$ chess board. The board contains no other pieces. The rook randomly makes a legal chess move with every turn (directly vertical or horizontal). The rook cannot remain stationary during a turn. What is the expected number of moves for the rook to land on the upper right-most square? I understand the rook has 14 possible moves for every turn. The problem seems to fit the concept of Markov chains, as the probability distribution of any given move does not depend on the previous. However, I do not understand how to approach this calculation.","Suppose a rook starts on the lower left-most square of a standard $8 \times 8$ chess board. The board contains no other pieces. The rook randomly makes a legal chess move with every turn (directly vertical or horizontal). The rook cannot remain stationary during a turn. What is the expected number of moves for the rook to land on the upper right-most square? I understand the rook has 14 possible moves for every turn. The problem seems to fit the concept of Markov chains, as the probability distribution of any given move does not depend on the previous. However, I do not understand how to approach this calculation.",,"['probability', 'markov-chains']"
51,Probability: 10th ball is blue,Probability: 10th ball is blue,,"The following is a question I've made myself, but I need help in solving it: Suppose there are 100 balls in a box. 20 balls are blue, 30 balls are green and 50 balls are yellow. Now we randomly pick out 10 balls out of the box (one ball after the other) and we don't put the balls back in the box. What's the probability of the 10th ball being picked having color blue? I tried thinking of all the possibilities of the the 10th ball being blue, divided by all of the possible combinations. I tried for several hours and couldn't figure out neither of them. Help is appreciated!","The following is a question I've made myself, but I need help in solving it: Suppose there are 100 balls in a box. 20 balls are blue, 30 balls are green and 50 balls are yellow. Now we randomly pick out 10 balls out of the box (one ball after the other) and we don't put the balls back in the box. What's the probability of the 10th ball being picked having color blue? I tried thinking of all the possibilities of the the 10th ball being blue, divided by all of the possible combinations. I tried for several hours and couldn't figure out neither of them. Help is appreciated!",,['probability']
52,Notation of random variables,Notation of random variables,,"I am really confused about capitalization of variable names in statistics. When should a random variable be presented by uppercase letter, and when lower case? For a probability $P(X \leq x)$, what do $x$ and $X$ mean here?","I am really confused about capitalization of variable names in statistics. When should a random variable be presented by uppercase letter, and when lower case? For a probability $P(X \leq x)$, what do $x$ and $X$ mean here?",,"['probability', 'statistics', 'notation']"
53,Why square a constant when determining variance of a random variable?,Why square a constant when determining variance of a random variable?,,"If I want to calculate the sample variance such as below: Which becomes: $\left(\frac{1}{n}\right)^2 \cdot n(\sigma^2)= \frac{\sigma^2}{n} $... My question is WHY does it become $$\left(\frac{1}{n}\right)^2?$$ In other words, why does the $(1/n)$ inside the variance become $(1/n)^2$? I've read that this is because: When a random variable is multiplied by a constant, it's variance gets multiplied by the square of the constant. Again, though, I want to know why ? I've looked in multiple sources but they all seem to gloss over this point. I want to visually see why this is done. Could someone please demonstrate why the $1/n$ is squared using my example? Update : As @symplectomorphic points out in a comment under their answer , my confusion was the result of not realizing there was a difference between the variance of a set of data and the variance of a random variable . See @symplectomorphic's other comment for an explanation of the difference. @symplectomorphic's answer provides a good conceptual walkthrough, while user @Tryss's answer provides the correct mathematical explanation. Thanks to both of you!","If I want to calculate the sample variance such as below: Which becomes: $\left(\frac{1}{n}\right)^2 \cdot n(\sigma^2)= \frac{\sigma^2}{n} $... My question is WHY does it become $$\left(\frac{1}{n}\right)^2?$$ In other words, why does the $(1/n)$ inside the variance become $(1/n)^2$? I've read that this is because: When a random variable is multiplied by a constant, it's variance gets multiplied by the square of the constant. Again, though, I want to know why ? I've looked in multiple sources but they all seem to gloss over this point. I want to visually see why this is done. Could someone please demonstrate why the $1/n$ is squared using my example? Update : As @symplectomorphic points out in a comment under their answer , my confusion was the result of not realizing there was a difference between the variance of a set of data and the variance of a random variable . See @symplectomorphic's other comment for an explanation of the difference. @symplectomorphic's answer provides a good conceptual walkthrough, while user @Tryss's answer provides the correct mathematical explanation. Thanks to both of you!",,"['probability', 'means', 'constants', 'variance']"
54,Probability that a quadratic equation with random coefficients has real roots [duplicate],Probability that a quadratic equation with random coefficients has real roots [duplicate],,"This question already has answers here : Probability that a quadratic polynomial with random coefficients has real roots (6 answers) Closed 5 years ago . Consider quadratic equations $Ax^2 + Bx + C = 0$ in which $A$ , $B$ , and $C$ are   independently distributed $\mathsf{Unif}(0,1)$ . What is the probability that the roots of such an equation are real? This problem is from  Chapter 3 of Rice: Mathematical Statistics and Data Analysis (editions 1 through 3). Until recent printings of 3e, the incorrect answer 1/9 was given for this problem. However, Horton (2015) http://www3.amherst.edu/~nhorton/precursors/precursors.pdf points out that the correct answer is slightly above 1/4, as can be verified by a simple simulation. (Horton and his colleagues are concerned with elements of an undergraduate curriculum to prepare students in the mathematical sciences to cope with modern data science.) In a somewhat more practical setting, one might consider a discrete version of this problem. A program that produces random drill problems on quadratic equations $Ax^2 + Bx + C = 0,$ selects values for $A, B,$ and $C$ at random and independently from among the ten equally likely values $0.1, 0.2, \dots, 1.0$ . What proportion of such equations have real roots? And what proportion have only one root? The initial Answer sketches the exact analytic solution of the original problem and shows numerical and graphical results from simulation. A simulated result for the discrete version is also shown. Additional answers using other methods or discussing related topics are welcome.","This question already has answers here : Probability that a quadratic polynomial with random coefficients has real roots (6 answers) Closed 5 years ago . Consider quadratic equations in which , , and are   independently distributed . What is the probability that the roots of such an equation are real? This problem is from  Chapter 3 of Rice: Mathematical Statistics and Data Analysis (editions 1 through 3). Until recent printings of 3e, the incorrect answer 1/9 was given for this problem. However, Horton (2015) http://www3.amherst.edu/~nhorton/precursors/precursors.pdf points out that the correct answer is slightly above 1/4, as can be verified by a simple simulation. (Horton and his colleagues are concerned with elements of an undergraduate curriculum to prepare students in the mathematical sciences to cope with modern data science.) In a somewhat more practical setting, one might consider a discrete version of this problem. A program that produces random drill problems on quadratic equations selects values for and at random and independently from among the ten equally likely values . What proportion of such equations have real roots? And what proportion have only one root? The initial Answer sketches the exact analytic solution of the original problem and shows numerical and graphical results from simulation. A simulated result for the discrete version is also shown. Additional answers using other methods or discussing related topics are welcome.","Ax^2 + Bx + C = 0 A B C \mathsf{Unif}(0,1) Ax^2 + Bx + C = 0, A, B, C 0.1, 0.2, \dots, 1.0","['probability', 'simulation']"
55,Expected value of a non-negative random variable [duplicate],Expected value of a non-negative random variable [duplicate],,"This question already has answers here : Explain why $E(X) = \int_0^\infty (1-F_X (t)) \, dt$ for every nonnegative random variable $X$ (3 answers) Closed 4 years ago . How do I prove that $\int_0^\infty Pr(Y\geq y) dy = E[Y]$ if $Y$ is a non-negative random variable?","This question already has answers here : Explain why $E(X) = \int_0^\infty (1-F_X (t)) \, dt$ for every nonnegative random variable $X$ (3 answers) Closed 4 years ago . How do I prove that $\int_0^\infty Pr(Y\geq y) dy = E[Y]$ if $Y$ is a non-negative random variable?",,['probability']
56,P(tomorrow is the end of the world) =?,P(tomorrow is the end of the world) =?,,"Here we have $3$ prophets alpha, beta, gamma, they all predict that tomorrow is the end of the world. It's known that the accuracy of alpha's and beta's prediction is $90\%$, while that of gamma's is $4\%$. What is the probability that tomorrow is the end of the world? Here's my calculations. Let $A, B, C$ be alpha's, beta's and gamma's predictions. P(tomorrow is the end of the world) $= P(A) + P(B) + P(C) - P(AB) - P(BC) - P(AC) + P(ABC)$ $= 0.9 + 0.9 + 0.04 - 0.81 - 0.036 - 0.036 + 0.0324$ $= 0.9904$ But this seems a bit too high, is my calculation correct? Thanks.","Here we have $3$ prophets alpha, beta, gamma, they all predict that tomorrow is the end of the world. It's known that the accuracy of alpha's and beta's prediction is $90\%$, while that of gamma's is $4\%$. What is the probability that tomorrow is the end of the world? Here's my calculations. Let $A, B, C$ be alpha's, beta's and gamma's predictions. P(tomorrow is the end of the world) $= P(A) + P(B) + P(C) - P(AB) - P(BC) - P(AC) + P(ABC)$ $= 0.9 + 0.9 + 0.04 - 0.81 - 0.036 - 0.036 + 0.0324$ $= 0.9904$ But this seems a bit too high, is my calculation correct? Thanks.",,['probability']
57,Is $\frac{1}{\infty}$  equal zero?,Is   equal zero?,\frac{1}{\infty},"After reading this paragraph: A simpler version of this distinction might be more palatable: flip a   coin infinitely many times. The probability that you flip heads every   time is zero, but it isn't impossible (at least, it isn't more   impossible than flipping a coin infinitely many times to begin with!). From here: Is it generally accepted that if you throw a dart at a number line you will NEVER hit a rational number? I thought to myself, why is the probability of flipping heads every time zero? If we have a perfect coin and we flip it twice we get the probability to equal this: $$\frac 12 \times \frac 12 = \frac 14$$ or for four flips we get this: $$\frac 12 \times \frac 12 \times \frac 12 \times \frac 12 = \frac 1{16}$$ So as we approach an infinite amount of coin flips, the probability gets smaller and smaller, but it shouldn't ever reach zero, so the probability shouldn't be zero, it should be $1/+\infty$. Does this mean that $1/+\infty$ equals zero or have I misunderstood the question?","After reading this paragraph: A simpler version of this distinction might be more palatable: flip a   coin infinitely many times. The probability that you flip heads every   time is zero, but it isn't impossible (at least, it isn't more   impossible than flipping a coin infinitely many times to begin with!). From here: Is it generally accepted that if you throw a dart at a number line you will NEVER hit a rational number? I thought to myself, why is the probability of flipping heads every time zero? If we have a perfect coin and we flip it twice we get the probability to equal this: $$\frac 12 \times \frac 12 = \frac 14$$ or for four flips we get this: $$\frac 12 \times \frac 12 \times \frac 12 \times \frac 12 = \frac 1{16}$$ So as we approach an infinite amount of coin flips, the probability gets smaller and smaller, but it shouldn't ever reach zero, so the probability shouldn't be zero, it should be $1/+\infty$. Does this mean that $1/+\infty$ equals zero or have I misunderstood the question?",,"['probability', 'infinity']"
58,How many bins do random numbers fill?,How many bins do random numbers fill?,,"Given a tuple $\left(a_1,a_2,\ldots,a_n\right)$ over the alphabet $\\\{1,2,\ldots,m\}$ chosen uniformly at random among the $m^n$ possibilities. What is the expected size of the set $\{a_1,a_2,\ldots,a_n\}$ ? If $m=n$ it seems the answer tends to $(1-1/e)n$ as $n\to\infty$ , but I don't know why. I bumped into this while benchmarking some code for hashtables, so I wouldn't be surprised if it is a standard result in the hash world.","Given a tuple over the alphabet chosen uniformly at random among the possibilities. What is the expected size of the set ? If it seems the answer tends to as , but I don't know why. I bumped into this while benchmarking some code for hashtables, so I wouldn't be surprised if it is a standard result in the hash world.","\left(a_1,a_2,\ldots,a_n\right) \\\{1,2,\ldots,m\} m^n \{a_1,a_2,\ldots,a_n\} m=n (1-1/e)n n\to\infty","['combinatorics', 'probability', 'discrete-mathematics']"
59,Expected value problem with cars on a highway,Expected value problem with cars on a highway,,"There is a very long, straight highway with $N$ cars placed somewhere along it, randomly. The highway is only one lane, so the cars can’t pass each other. Each car is going in the same direction, and each driver has a distinct positive speed at which she prefers to travel. Each preferred speed is chosen at random. Each driver travels at her preferred speed unless she gets stuck behind a slower car, in which case she remains stuck behind the slower car. On average, how many groups of cars will eventually form? (A group is one or more cars traveling at the same speed.) A friend showed me this question and we didn't know how to go about it. I've taken a probability course so my mind immediately went to counting methods or expectation values, but I don't know if this is the wrong intuition. Anybody know how to solve this?","There is a very long, straight highway with cars placed somewhere along it, randomly. The highway is only one lane, so the cars can’t pass each other. Each car is going in the same direction, and each driver has a distinct positive speed at which she prefers to travel. Each preferred speed is chosen at random. Each driver travels at her preferred speed unless she gets stuck behind a slower car, in which case she remains stuck behind the slower car. On average, how many groups of cars will eventually form? (A group is one or more cars traveling at the same speed.) A friend showed me this question and we didn't know how to go about it. I've taken a probability course so my mind immediately went to counting methods or expectation values, but I don't know if this is the wrong intuition. Anybody know how to solve this?",N,"['probability', 'combinatorics', 'contest-math', 'expected-value']"
60,Probability of $\alpha\beta\gamma=\gamma\beta\alpha$ for random permutations of a finite set?,Probability of  for random permutations of a finite set?,\alpha\beta\gamma=\gamma\beta\alpha,"Following up on my previous question Probability that two random permutations of an $n$-set commute? , here's a related question for three elements. Q : If $\alpha,\beta,\gamma$ are chosen uniformly at random from the symmetric group on $n$ elements, what is the probability that $\alpha\beta\gamma=\gamma\beta\alpha$? For $n \leq 6$ we have the striking property $$\mathrm{Pr}[\alpha\beta=\beta\alpha]=\mathrm{Pr}[\alpha\beta\gamma=\gamma\beta\alpha].$$ as illustrated in the following table: \begin{array}{r|rr} n & \mathrm{Pr}[\alpha\beta\gamma=\gamma\beta\alpha] & \mathrm{Pr}[\alpha\beta=\beta\alpha] \\ \hline 1 & 1 & 1 \\ 2 & 1 & 1  \\ 3 & 108\ /\ 3!^3 = 0.5 & 18\ /\ 3!^2 = 0.5\\ 4 & 2880\ /\ 4!^3 \simeq 0.208 & 120\ /\ 4!^2 \simeq 0.208  \\ 5 & 100800\ /\ 5!^3 \simeq 0.058 & 840\ /\ 5!^2 \simeq 0.058 \\ 6 & 5702400\ /\ 6!^3 \simeq 0.015 & 7920\ /\ 6!^2 \simeq 0.015 \\ \end{array} computed using GAP .  Does this hold in general? Comments: The tools used in the previous question (e.g. the centralizer subgroup) do not seem to be usable here.  (Although, maybe I'm missing something important.) This doesn't seem to generalize: e.g. in $S_3$, we have $\mathrm{Pr}[\alpha\beta\gamma\delta=\delta\gamma\beta\alpha] \simeq 0.103$ which doesn't match. None of the permutations $(13),(23),(12) \in S_3$ commute, but $(13)(23)(12)=(23)=(12)(23)(13)$.","Following up on my previous question Probability that two random permutations of an $n$-set commute? , here's a related question for three elements. Q : If $\alpha,\beta,\gamma$ are chosen uniformly at random from the symmetric group on $n$ elements, what is the probability that $\alpha\beta\gamma=\gamma\beta\alpha$? For $n \leq 6$ we have the striking property $$\mathrm{Pr}[\alpha\beta=\beta\alpha]=\mathrm{Pr}[\alpha\beta\gamma=\gamma\beta\alpha].$$ as illustrated in the following table: \begin{array}{r|rr} n & \mathrm{Pr}[\alpha\beta\gamma=\gamma\beta\alpha] & \mathrm{Pr}[\alpha\beta=\beta\alpha] \\ \hline 1 & 1 & 1 \\ 2 & 1 & 1  \\ 3 & 108\ /\ 3!^3 = 0.5 & 18\ /\ 3!^2 = 0.5\\ 4 & 2880\ /\ 4!^3 \simeq 0.208 & 120\ /\ 4!^2 \simeq 0.208  \\ 5 & 100800\ /\ 5!^3 \simeq 0.058 & 840\ /\ 5!^2 \simeq 0.058 \\ 6 & 5702400\ /\ 6!^3 \simeq 0.015 & 7920\ /\ 6!^2 \simeq 0.015 \\ \end{array} computed using GAP .  Does this hold in general? Comments: The tools used in the previous question (e.g. the centralizer subgroup) do not seem to be usable here.  (Although, maybe I'm missing something important.) This doesn't seem to generalize: e.g. in $S_3$, we have $\mathrm{Pr}[\alpha\beta\gamma\delta=\delta\gamma\beta\alpha] \simeq 0.103$ which doesn't match. None of the permutations $(13),(23),(12) \in S_3$ commute, but $(13)(23)(12)=(23)=(12)(23)(13)$.",,"['probability', 'group-theory', 'finite-groups', 'permutations']"
61,Is conditional probability also probability?,Is conditional probability also probability?,,"Some pondering leads me to the question below, which prevents me from the reckless calculation of conditional probability... As defined, conditional probability is: $$ P(A|B)=P(A\cap B)/P(B). $$ So, we can see conditional probability is the ratio of 2 probabilities . If we consider conditional probability also as probability, we are literally saying some quantity describes the similar thing as its ratio. This is very bizarre because when we measure length, we can say something is 2 meters long and the other thing is 5 meters long. But we cannot consider 2/5 or 5/2 as the same thing as 2 or 5 because the ratio 2/5 or 5/2 is just another level of comparison as I understand， while the 2 or 5 is merely the comparison to the unit. So why do we still treat conditional probability just as the ordinary probability? I wish someone could shed some light on this thing. Or is there any other examples like this besides in probability theory? ADD 1 (Thanks for so many responses.) Almost all of the responses so far try to convince me that probability is a ratio itself. And both ratio and ratios' ratio are ratio. Personally, I haven't found any contradiction about the conditional probability definition as far as only ratio interpretation is concerned yet . And it seems ratio is the only realm where probability is mathematically possible. So I took it that people generalize this ratio-based theory to a much broader realm where probability issues also arise but no apparent mathematics is applicable (such as the degree-of-belief scenario.). The only thing I can find to support this for now, is the Principle of the Permanence of Equivalent Forms and the boldness of human nature for mathematical generalization . (I will not close this question as of now and more opinions are appreciated.)","Some pondering leads me to the question below, which prevents me from the reckless calculation of conditional probability... As defined, conditional probability is: $$ P(A|B)=P(A\cap B)/P(B). $$ So, we can see conditional probability is the ratio of 2 probabilities . If we consider conditional probability also as probability, we are literally saying some quantity describes the similar thing as its ratio. This is very bizarre because when we measure length, we can say something is 2 meters long and the other thing is 5 meters long. But we cannot consider 2/5 or 5/2 as the same thing as 2 or 5 because the ratio 2/5 or 5/2 is just another level of comparison as I understand， while the 2 or 5 is merely the comparison to the unit. So why do we still treat conditional probability just as the ordinary probability? I wish someone could shed some light on this thing. Or is there any other examples like this besides in probability theory? ADD 1 (Thanks for so many responses.) Almost all of the responses so far try to convince me that probability is a ratio itself. And both ratio and ratios' ratio are ratio. Personally, I haven't found any contradiction about the conditional probability definition as far as only ratio interpretation is concerned yet . And it seems ratio is the only realm where probability is mathematically possible. So I took it that people generalize this ratio-based theory to a much broader realm where probability issues also arise but no apparent mathematics is applicable (such as the degree-of-belief scenario.). The only thing I can find to support this for now, is the Principle of the Permanence of Equivalent Forms and the boldness of human nature for mathematical generalization . (I will not close this question as of now and more opinions are appreciated.)",,"['probability', 'probability-theory']"
62,"What is the difference between $p(a,b)$ and $p(a|b)$?",What is the difference between  and ?,"p(a,b) p(a|b)","I feel that $p(a,b)$ = the probability that event $a$ and $b$ happen at the same time. $p(a|b)$ = the probability that event $a$ happens due to the event $b$ happens. For me, I think the meaning is quite the same. So what is the difference?","I feel that = the probability that event and happen at the same time. = the probability that event happens due to the event happens. For me, I think the meaning is quite the same. So what is the difference?","p(a,b) a b p(a|b) a b","['probability', 'probability-theory', 'probability-distributions']"
63,"How to calculate the probability of rolling 6 at least 5 times in a row, out of 50 tries?","How to calculate the probability of rolling 6 at least 5 times in a row, out of 50 tries?",,"If I roll the dice 50 times, how do I calculate the chance that I will roll 6 at least 5 times in a row? Why this problem is hard With 5 tries this would be easy: take $(1/6)$ to fifth power. With 6 tries this is manageable; take the probability of rolling 6 the first five times, add the probability of rolling 6 the last five times, then subtract the overlap (all six results are 6). Given two overlapping sets of 5 rolls, the probability that one is all 6's is not independent from the probability that the other is all 6's. In principle this could be continued, but inclusion-exclusion gets out of hand. There has to be a better way; what is it?","If I roll the dice 50 times, how do I calculate the chance that I will roll 6 at least 5 times in a row? Why this problem is hard With 5 tries this would be easy: take to fifth power. With 6 tries this is manageable; take the probability of rolling 6 the first five times, add the probability of rolling 6 the last five times, then subtract the overlap (all six results are 6). Given two overlapping sets of 5 rolls, the probability that one is all 6's is not independent from the probability that the other is all 6's. In principle this could be continued, but inclusion-exclusion gets out of hand. There has to be a better way; what is it?",(1/6),['probability']
64,Count the possible ways to seat people at a round table,Count the possible ways to seat people at a round table,,"I have a very simple combinatorics problem, and I am (almost) sure I did this right. However, the smartest guy in my class thinks different and this made me doubt, so I will post our views to this problem and I would like to know who is right. In how many different ways can 10 people be seated around a round table, under the condition that there are 5 man and 5 women, and no two males or two females can be seated adjacently. My view We number the chairs in an arbitrary way, so the chair numbering is fixed. At chair $1$, there is seated either a man or a woman, which given $2$ possibilities. When we observe the gender of the person in the first chair, the division of the table over the two genders in given. Then there are $5!$ ways to seat the men over the $5$ male chairs and $5!$ ways to seat the women over the $5$ female chairs. So in total this gives $2.(5!)^2$ possibilities. My classmates view First all males are seated, which is possible in $5!$ ways. Because no males can sit adjacently and the people are seated in a circle, we can rotate the table and in this way we count all possibilities 5 times too much, so $5!/5=4!$ ways to seat the man. After this, the table division is fixed, but we still have to seat the women. This gives another $5!$ ways, so in total $5!4!$ ways. What I think is wrong with this view I don't think the argument about rotation of the table makes any sense. The argument can make sense though, if we use exactly my classmate's argument, but acknowledge that the first person to be seated can be any of the $10$ people, so giving an extra $10$ possibilities. Then proceed as my classmate, giving the same answer as me. However, my classmate does not agree. So who is right? Also, if we use our arguments to the same problem but a table of $2$ people, one male, one female, there are obviously $2$ possibilities. Then my method gives $2.(1!)^2=2$ possibilities, but my classmate's method gives only $1!0!=1$ possibility. EDIT I think the main problem is in different interpretations of the problem, where my interpretation is that it matters who sit at 'chair 1' while my classmates thinks that only the ordering of the people matters. However, given only the above problem, what would be the right interpretation, or is this ambiguous?","I have a very simple combinatorics problem, and I am (almost) sure I did this right. However, the smartest guy in my class thinks different and this made me doubt, so I will post our views to this problem and I would like to know who is right. In how many different ways can 10 people be seated around a round table, under the condition that there are 5 man and 5 women, and no two males or two females can be seated adjacently. My view We number the chairs in an arbitrary way, so the chair numbering is fixed. At chair $1$, there is seated either a man or a woman, which given $2$ possibilities. When we observe the gender of the person in the first chair, the division of the table over the two genders in given. Then there are $5!$ ways to seat the men over the $5$ male chairs and $5!$ ways to seat the women over the $5$ female chairs. So in total this gives $2.(5!)^2$ possibilities. My classmates view First all males are seated, which is possible in $5!$ ways. Because no males can sit adjacently and the people are seated in a circle, we can rotate the table and in this way we count all possibilities 5 times too much, so $5!/5=4!$ ways to seat the man. After this, the table division is fixed, but we still have to seat the women. This gives another $5!$ ways, so in total $5!4!$ ways. What I think is wrong with this view I don't think the argument about rotation of the table makes any sense. The argument can make sense though, if we use exactly my classmate's argument, but acknowledge that the first person to be seated can be any of the $10$ people, so giving an extra $10$ possibilities. Then proceed as my classmate, giving the same answer as me. However, my classmate does not agree. So who is right? Also, if we use our arguments to the same problem but a table of $2$ people, one male, one female, there are obviously $2$ possibilities. Then my method gives $2.(1!)^2=2$ possibilities, but my classmate's method gives only $1!0!=1$ possibility. EDIT I think the main problem is in different interpretations of the problem, where my interpretation is that it matters who sit at 'chair 1' while my classmates thinks that only the ordering of the people matters. However, given only the above problem, what would be the right interpretation, or is this ambiguous?",,"['probability', 'combinatorics', 'proof-verification']"
65,How many people would you need in a room to ensure with 100% probaility that three have the same birthday?,How many people would you need in a room to ensure with 100% probaility that three have the same birthday?,,"I am vaguely aware of the Pigeonhole principle and I understand that you would need 367 people to ensure that two people have the same birthday. I think that it may be required to have 734 people in a room to ensure 100% probability, since you can have 366 birthdays repeated and not have three people. Is this a correct assumption, and if so, how would you solve it without just guessing/checking?","I am vaguely aware of the Pigeonhole principle and I understand that you would need 367 people to ensure that two people have the same birthday. I think that it may be required to have 734 people in a room to ensure 100% probability, since you can have 366 birthdays repeated and not have three people. Is this a correct assumption, and if so, how would you solve it without just guessing/checking?",,"['probability', 'pigeonhole-principle']"
66,What's the probability that three points determine an acute triangle?,What's the probability that three points determine an acute triangle?,,"Three distinct points are chosen at random from the unit square. The goal is to find the probability that they form an acute triangle. I started working on this because I want to know how to approach a problem of this sort, where the sample space seems to be something like $[0,1]^2$. However I've had no experience dealing with pdf's on $[0,1]^2$, $\mathbb{R}^2$, etc. So far, given any two  points, I can find the probability that the third point will work via a simple geometry/area argument (see below). But then what to do with that? I suspect integration, but of what and over what domain? Suppose $(a,b)$ and $(c,d)$ are two points in the square. Construct a line containing $(a,b)$ and a line containing $(c,d)$ so that both are perpendicular to the segment joining the points. The probability that the third point will work is the area of the region between the two lines and inside the square, but outside the circle whose diameter is the segment joining the points. (If the third point is inside the circle then an obtuse triangle is formed, and if the  third point is on the circle a right triangle is formed.)","Three distinct points are chosen at random from the unit square. The goal is to find the probability that they form an acute triangle. I started working on this because I want to know how to approach a problem of this sort, where the sample space seems to be something like $[0,1]^2$. However I've had no experience dealing with pdf's on $[0,1]^2$, $\mathbb{R}^2$, etc. So far, given any two  points, I can find the probability that the third point will work via a simple geometry/area argument (see below). But then what to do with that? I suspect integration, but of what and over what domain? Suppose $(a,b)$ and $(c,d)$ are two points in the square. Construct a line containing $(a,b)$ and a line containing $(c,d)$ so that both are perpendicular to the segment joining the points. The probability that the third point will work is the area of the region between the two lines and inside the square, but outside the circle whose diameter is the segment joining the points. (If the third point is inside the circle then an obtuse triangle is formed, and if the  third point is on the circle a right triangle is formed.)",,"['probability', 'probability-distributions', 'geometric-probability']"
67,How do I show that the sum of two random variables is random variable?,How do I show that the sum of two random variables is random variable?,,"How do I prove the following? If $X$ and $Y$ are random variables on a probability space $(\Omega, F, \mathbb P)$, then so is $X+Y$. The definition of a random variable is a function $X: \Omega \to \mathbb R$, with the property that $\{\omega\in\Omega: X(\omega)\leq x\}\in F$, for each $x\in\mathbb R$. Furthermore, how to approach $X+Y$ and $\min\{X, Y\}$?","How do I prove the following? If $X$ and $Y$ are random variables on a probability space $(\Omega, F, \mathbb P)$, then so is $X+Y$. The definition of a random variable is a function $X: \Omega \to \mathbb R$, with the property that $\{\omega\in\Omega: X(\omega)\leq x\}\in F$, for each $x\in\mathbb R$. Furthermore, how to approach $X+Y$ and $\min\{X, Y\}$?",,"['probability', 'probability-theory', 'proof-writing']"
68,The frog puzzle,The frog puzzle,,"So here's the puzzle. You're poisoned in the jungle and the only way to save yourself is to lick a special kind of frog. To make matters worse, only the female of that species will do. Licking the male frog doesn't do anything. The male and female frogs look identical. The only difference is that the male frog makes a sound and the female is silent. So you run through the jungle and spot a frog in front of you. Before you could start running towards it you hear a sound behind you. You turn around and spot two frogs there. There's only time to run to one side. Now, the best course of action is to run towards the two frogs and lick both. The reasoning is that there are 4 possible combinations of two frogs and knowing that one of them is male eliminates only one of those possibilities. Of the remaining three, two of them have at least one female frog. This gives you a $\frac 2 3$ chance of survival as opposed to a $\frac 1 2$ with the single frog. Now here's my problem. The reason this works is because you don't know which frog made the sound. If you did, you'd have a $50\%$ chance with the other one. But wouldn't that imply that, if you for some reason turned around earlier to see which one made the sound, you would decrease your chances of survival? What's the explanation here?","So here's the puzzle. You're poisoned in the jungle and the only way to save yourself is to lick a special kind of frog. To make matters worse, only the female of that species will do. Licking the male frog doesn't do anything. The male and female frogs look identical. The only difference is that the male frog makes a sound and the female is silent. So you run through the jungle and spot a frog in front of you. Before you could start running towards it you hear a sound behind you. You turn around and spot two frogs there. There's only time to run to one side. Now, the best course of action is to run towards the two frogs and lick both. The reasoning is that there are 4 possible combinations of two frogs and knowing that one of them is male eliminates only one of those possibilities. Of the remaining three, two of them have at least one female frog. This gives you a $\frac 2 3$ chance of survival as opposed to a $\frac 1 2$ with the single frog. Now here's my problem. The reason this works is because you don't know which frog made the sound. If you did, you'd have a $50\%$ chance with the other one. But wouldn't that imply that, if you for some reason turned around earlier to see which one made the sound, you would decrease your chances of survival? What's the explanation here?",,"['probability', 'intuition', 'puzzle']"
69,A probability theory question about independent coin tosses by two players,A probability theory question about independent coin tosses by two players,,"Say Bob tosses his $n+1$ fair coins and Alice tosses her $n$ fair coins. Lets assume independent coin tosses. Now after all the $2n+1$ coin tosses one wants to know the probability that Bob has gotten more heads than Alice. The way I thought of it is this : if Bob gets $0$ heads then there is no way he can get more heads than Alice. Otherwise the number of heads Bob can get which allows him to win is anything in the set $\{1,2,\dots,n+1\}$. And if Bob gets $x$ heads then the number of heads that Alice can get is anything in the set $\{0,1,2,..,x-1\}$. So\begin{align}P(\text{Bob gets more heads than Alice})&= \sum_{x=1}^{n+1} \sum_{y=0}^{x-1} P( \text{Bob gets x heads }\cap \text{Alice gets y heads }) \\[0.2cm]&= \sum_{x=1}^{n+1} \sum_{y=0}^{x-1} \left(C^{n+1}_x \frac{1}{2}^{x} \frac{1}{2}^{n+1-x}\right)\left( C^n_y \frac{1}{2}^y \frac {1}{2}^{n-y}\right)\\[0.2cm]& = \sum_{x=1}^{n+1} \sum_{y=0}^{x-1} \frac{C^{n+1}_x C^n_y}{2^{2n+1}}\end{align} How does one simplify this? Apparently the answer is $\frac{1}{2}$ by an argument which looks like this, Since Bob tosses one more coin that Alice, it is impossible that they toss both the same number of heads and the same number of tails. So Bob tosses either more heads than Alice or more tails than Alice (but not both). Since the coins are fair, these events are equally likely by symmetry, so both events have probability 1/2.","Say Bob tosses his $n+1$ fair coins and Alice tosses her $n$ fair coins. Lets assume independent coin tosses. Now after all the $2n+1$ coin tosses one wants to know the probability that Bob has gotten more heads than Alice. The way I thought of it is this : if Bob gets $0$ heads then there is no way he can get more heads than Alice. Otherwise the number of heads Bob can get which allows him to win is anything in the set $\{1,2,\dots,n+1\}$. And if Bob gets $x$ heads then the number of heads that Alice can get is anything in the set $\{0,1,2,..,x-1\}$. So\begin{align}P(\text{Bob gets more heads than Alice})&= \sum_{x=1}^{n+1} \sum_{y=0}^{x-1} P( \text{Bob gets x heads }\cap \text{Alice gets y heads }) \\[0.2cm]&= \sum_{x=1}^{n+1} \sum_{y=0}^{x-1} \left(C^{n+1}_x \frac{1}{2}^{x} \frac{1}{2}^{n+1-x}\right)\left( C^n_y \frac{1}{2}^y \frac {1}{2}^{n-y}\right)\\[0.2cm]& = \sum_{x=1}^{n+1} \sum_{y=0}^{x-1} \frac{C^{n+1}_x C^n_y}{2^{2n+1}}\end{align} How does one simplify this? Apparently the answer is $\frac{1}{2}$ by an argument which looks like this, Since Bob tosses one more coin that Alice, it is impossible that they toss both the same number of heads and the same number of tails. So Bob tosses either more heads than Alice or more tails than Alice (but not both). Since the coins are fair, these events are equally likely by symmetry, so both events have probability 1/2.",,"['probability', 'probability-theory']"
70,How likely is it for a randomly picked number to be larger than all previously chosen numbers?,How likely is it for a randomly picked number to be larger than all previously chosen numbers?,,"Suppose we pick a uniformly distributed number on the range [a,b]. Then we continue to pick more numbers on the same range. Let n(t) be the number of times we have found a number bigger than any previously found, after sampling t total numbers. The initial number picked is not counted. Solve: $$\lim_{t\to\infty}\sqrt[n(t)]{t}$$ For reference, the problem I'm trying to solve is the geometric mean of the amount of time it takes to find the next bigger number, relative to the amount of time it took for the previous bigger number. So say it finds a new best value at the 4th try, 11th try, and 29th try, I get: $$\sqrt[3]{4*\dfrac{11}{4}*\dfrac{29}{11}}$$ which simplifies into the top equation. Experiments seem to indicate the amount of time it takes to find the next number multiples by about 3 for each number found, but I'm curious if there might be tools to solve this analytically. Interestingly, the value seems to be the same even if I take the randomly chosen number and plug it into a function (i.e. I'm checking to see if f(x) is greater than any previously seen f(x) for random values of x). Related questions: Is there any way to guess at the probability of finding a new biggest number? Can the geometric mean be shown to be a constant across all (or some) functions? Intuitively I feel like it should be. I don't have too extensive a background in math, so I'm hoping this isn't an unsolved problem.","Suppose we pick a uniformly distributed number on the range [a,b]. Then we continue to pick more numbers on the same range. Let n(t) be the number of times we have found a number bigger than any previously found, after sampling t total numbers. The initial number picked is not counted. Solve: $$\lim_{t\to\infty}\sqrt[n(t)]{t}$$ For reference, the problem I'm trying to solve is the geometric mean of the amount of time it takes to find the next bigger number, relative to the amount of time it took for the previous bigger number. So say it finds a new best value at the 4th try, 11th try, and 29th try, I get: $$\sqrt[3]{4*\dfrac{11}{4}*\dfrac{29}{11}}$$ which simplifies into the top equation. Experiments seem to indicate the amount of time it takes to find the next number multiples by about 3 for each number found, but I'm curious if there might be tools to solve this analytically. Interestingly, the value seems to be the same even if I take the randomly chosen number and plug it into a function (i.e. I'm checking to see if f(x) is greater than any previously seen f(x) for random values of x). Related questions: Is there any way to guess at the probability of finding a new biggest number? Can the geometric mean be shown to be a constant across all (or some) functions? Intuitively I feel like it should be. I don't have too extensive a background in math, so I'm hoping this isn't an unsolved problem.",,['probability']
71,Derivation of chi-squared pdf with one degree of freedom from normal distribution pdf,Derivation of chi-squared pdf with one degree of freedom from normal distribution pdf,,"How can we derive the chi-squared probability density function (pdf) using the pdf of normal distribution? I mean, I need to show that $$f(x)=\frac{1}{2^{r/2}\Gamma(r/2)}x^{r/2-1}e^{-x/2} \>, \qquad x > 0\>.$$","How can we derive the chi-squared probability density function (pdf) using the pdf of normal distribution? I mean, I need to show that $$f(x)=\frac{1}{2^{r/2}\Gamma(r/2)}x^{r/2-1}e^{-x/2} \>, \qquad x > 0\>.$$",,"['probability', 'statistics', 'probability-distributions']"
72,Rolling a die until two rolls sum to seven,Rolling a die until two rolls sum to seven,,"Here's the question: You have a standard six-sided die and you roll it repeatedly, writing   down the numbers that come up, and you win when two of your rolled   numbers add up to $7$. (You will almost surely win.) Necessarily, one of the   winning summands is the number rolled on the winning turn. A typical   game could go like this: $1, 1, 4, 5, 3$; you win on the 5 th turn   because $3 + 4 = 7$. How many turns do you expect to play? Here's what I've tried:  We seek $E(N)$ where $N$ is a random variable counting the number of turns it takes to win. Then $N \ge 2$, and $$E(N) = \sum_{n=2}^\infty n P(N=n) = \sum_{n=1}^\infty P(N > n).$$ I want to find either $P(N=n)$, the probability that I win on the $n$ th turn, or $P(N > n)$, the probability that after $n$ turns I still haven't won. Note that $P(N = 1) = 0$. Let $X_k$ be the number rolled on the $k$ th turn. Then $$P(N = 2) = P(X_1 + X_2 = 7) = \sum_{x=1}^6 P(X_1 = x)P(X_2 = 7-x) = 6\cdot \frac{1}{6}\cdot\frac{1}{6} = \frac{1}{6}.$$ So far so good. To compute $P(N > 3)$ I let $A_{i, j} = \{\omega \in \{1, \dotsc, 6\}^3 : w_i + w_j = 7\}$ and used the inclusion-exclusion principle and symmetry to find $$|A_{1,2} \cup A_{2,3} \cup A_{1,3}| = 3|A_{1,2}| - 3|A_{1,2}\cap A_{1,3}| = 90$$ so $P(N > 3) = \frac{126}{216} = \frac{7}{12}$. This is the probability that no two of three dice sum to seven. Similarly, I found $P(N > 4)$ to be $\frac{77}{216}$. I don't see how to generalize the above. I also thought that $$P(N > n) = P(X_i + X_j \ne 7 \text{ for all }1 \le i\ne j \le n) = (1 - P(X_i + X_j = 7))^{\binom{n}{2}} = \left(\frac{5}{6}\right)^{n(n-1)/2}$$  but that's false because the events are not independent. I also tried $$P(N = n) = P(X_n = 7 - X_k \text{ for some } 1 \le k < n \text{ and }N \ne n - 1)$$ where that last clause is shorthand for ""and the previous rolls did not secure your victory"".  This yields the recursion $p_n = (1-(5/6)^{n-1})(1-p_{n-1})$, $p_1 = 0$, which didn't agree with my previously computed probabilities. (Perhaps I made an error.)","Here's the question: You have a standard six-sided die and you roll it repeatedly, writing   down the numbers that come up, and you win when two of your rolled   numbers add up to $7$. (You will almost surely win.) Necessarily, one of the   winning summands is the number rolled on the winning turn. A typical   game could go like this: $1, 1, 4, 5, 3$; you win on the 5 th turn   because $3 + 4 = 7$. How many turns do you expect to play? Here's what I've tried:  We seek $E(N)$ where $N$ is a random variable counting the number of turns it takes to win. Then $N \ge 2$, and $$E(N) = \sum_{n=2}^\infty n P(N=n) = \sum_{n=1}^\infty P(N > n).$$ I want to find either $P(N=n)$, the probability that I win on the $n$ th turn, or $P(N > n)$, the probability that after $n$ turns I still haven't won. Note that $P(N = 1) = 0$. Let $X_k$ be the number rolled on the $k$ th turn. Then $$P(N = 2) = P(X_1 + X_2 = 7) = \sum_{x=1}^6 P(X_1 = x)P(X_2 = 7-x) = 6\cdot \frac{1}{6}\cdot\frac{1}{6} = \frac{1}{6}.$$ So far so good. To compute $P(N > 3)$ I let $A_{i, j} = \{\omega \in \{1, \dotsc, 6\}^3 : w_i + w_j = 7\}$ and used the inclusion-exclusion principle and symmetry to find $$|A_{1,2} \cup A_{2,3} \cup A_{1,3}| = 3|A_{1,2}| - 3|A_{1,2}\cap A_{1,3}| = 90$$ so $P(N > 3) = \frac{126}{216} = \frac{7}{12}$. This is the probability that no two of three dice sum to seven. Similarly, I found $P(N > 4)$ to be $\frac{77}{216}$. I don't see how to generalize the above. I also thought that $$P(N > n) = P(X_i + X_j \ne 7 \text{ for all }1 \le i\ne j \le n) = (1 - P(X_i + X_j = 7))^{\binom{n}{2}} = \left(\frac{5}{6}\right)^{n(n-1)/2}$$  but that's false because the events are not independent. I also tried $$P(N = n) = P(X_n = 7 - X_k \text{ for some } 1 \le k < n \text{ and }N \ne n - 1)$$ where that last clause is shorthand for ""and the previous rolls did not secure your victory"".  This yields the recursion $p_n = (1-(5/6)^{n-1})(1-p_{n-1})$, $p_1 = 0$, which didn't agree with my previously computed probabilities. (Perhaps I made an error.)",,"['probability', 'expectation', 'dice']"
73,Probability of winning in a die rolling game with six players,Probability of winning in a die rolling game with six players,,"There are 6 players numbered 1 to 6, 1 Player, Player 2, ..., Player 6. Player 1 rolls a die , if he gets a 1 wins and the game ends, otherwise the die passes to the player whose number matches the number that presents the die and the player makes a second pitch, if is obtained the number of the player who has thrown, he wins and the game ends, otherwise the given passes to the player whose number matches the number rolled, the player rolls the die, if is obtained the number of the player who has thrown, he wins and the game ends, otherwise the die passes to the player whose number matches the number that presents the die in this third release, and so on. Calculate the probability that player 1 wins.","There are 6 players numbered 1 to 6, 1 Player, Player 2, ..., Player 6. Player 1 rolls a die , if he gets a 1 wins and the game ends, otherwise the die passes to the player whose number matches the number that presents the die and the player makes a second pitch, if is obtained the number of the player who has thrown, he wins and the game ends, otherwise the given passes to the player whose number matches the number rolled, the player rolls the die, if is obtained the number of the player who has thrown, he wins and the game ends, otherwise the die passes to the player whose number matches the number that presents the die in this third release, and so on. Calculate the probability that player 1 wins.",,['probability']
74,"I pick a number n, if you guess it, I pay you $n. What is the fair value of the game?","I pick a number n, if you guess it, I pay you $n. What is the fair value of the game?",,"This is from Mark Joshi's classic book. The full question is: ""I pick a number n from 1 to 100. If you guess correctly, I pay you $n and zero otherwise. How much would you pay to play this game?"" Joshi offers a solution, but I am struggling with it. From what I understand, the person picking the number has incentive to pick lower numbers as this will result in lower payoffs. However, low numbers will likely be selected by the player so the number should not be too low. Joshi suggests the following as the expectation of the game: $$\Big(\sum_{i=1}^{100}\frac{1}{i}\Big)^{-1}$$ Not sure if anyone could with the intuition on how the solution was obtained. I guess it arises as the initial person picking the number should pick with decaying probability going from 1 to 100? Thanks","This is from Mark Joshi's classic book. The full question is: ""I pick a number n from 1 to 100. If you guess correctly, I pay you $n and zero otherwise. How much would you pay to play this game?"" Joshi offers a solution, but I am struggling with it. From what I understand, the person picking the number has incentive to pick lower numbers as this will result in lower payoffs. However, low numbers will likely be selected by the player so the number should not be too low. Joshi suggests the following as the expectation of the game: Not sure if anyone could with the intuition on how the solution was obtained. I guess it arises as the initial person picking the number should pick with decaying probability going from 1 to 100? Thanks",\Big(\sum_{i=1}^{100}\frac{1}{i}\Big)^{-1},"['probability', 'game-theory', 'expected-value']"
75,Is statistical dependence transitive?,Is statistical dependence transitive?,,"Take any three random variables $X_1$, $X_2$, and $X_3$. Is it possible for $X_1$ and $X_2$ to be dependent, $X_2$ and $X_3$ to be dependent, but $X_1$ and $X_3$ to be independent? Is it possible for $X_1$ and $X_2$ to be independent, $X_2$ and $X_3$ to be independent, but $X_1$ and $X_3$ to be dependent?","Take any three random variables $X_1$, $X_2$, and $X_3$. Is it possible for $X_1$ and $X_2$ to be dependent, $X_2$ and $X_3$ to be dependent, but $X_1$ and $X_3$ to be independent? Is it possible for $X_1$ and $X_2$ to be independent, $X_2$ and $X_3$ to be independent, but $X_1$ and $X_3$ to be dependent?",,"['probability', 'statistics', 'relations']"
76,Intuition behind the concept of indicator random variables.,Intuition behind the concept of indicator random variables.,,"I am studying Randomized Algorithms chapter in the book ""Introduction to Algorithms"" by Cormen et al. In this chapter the book introduces the concept of an indicator random variable and state that the expected value of an indicator random variable as : I am having difficulty understanding why this is called an indicator random variable , specifically why indicator and random and how this concept is useful in analyzing algorithm timings . It has been some time since I studied probability in school . However , I am aware of the concept behind probability. So you can base your answer on this premise. As you can see from the diagram all it is saying is that the expected value of an indicator random variable of an event  is equal to the probability of that event . We already have the concept of probability , why should we know about this new concept which happens to be the same value as the probability ?","I am studying Randomized Algorithms chapter in the book ""Introduction to Algorithms"" by Cormen et al. In this chapter the book introduces the concept of an indicator random variable and state that the expected value of an indicator random variable as : I am having difficulty understanding why this is called an indicator random variable , specifically why indicator and random and how this concept is useful in analyzing algorithm timings . It has been some time since I studied probability in school . However , I am aware of the concept behind probability. So you can base your answer on this premise. As you can see from the diagram all it is saying is that the expected value of an indicator random variable of an event  is equal to the probability of that event . We already have the concept of probability , why should we know about this new concept which happens to be the same value as the probability ?",,"['probability', 'probability-theory', 'algorithms']"
77,Baby Shower Problem. Too hard for 1st grader but got parents thinking,Baby Shower Problem. Too hard for 1st grader but got parents thinking,,"So our six year old son comes home from 1st grade with the following math puzzle. Your Aunt is having a baby. You have created a party game for a baby shower.  It is called pick the gender.  You put pink and blue tiles into a bag.  You ask two guests to pick one tile each out of the bag without looking. You tell your guests that if they are the same color, player A wins and if they are two different colors, then player B wins. How many tiles of which colors did you put into the bag to make sure that both players have an equal chance of winning? Putting aside the obvious fact that this seems way too hard for a 1st grader it got us thinking...  Is there a clever way to solve this problem that doesn't involve guessing lots of ugly combinations? Let $P$ = Number of Pink Balls, $B$ = Number of Blue balls. It seems to me that the probability of Player ""B"" winning is $$\left(\frac{P}{P+B}\right)\left(\frac{B}{P+B-1}\right) + \left(\frac{B}{P+B}\right)\left(\frac{P}{P+B-1}\right)$$ In a fair game this probability is 50%. $$\frac{2PB}{(P+B)(P+B-1)} = \frac{1}{2}$$ Or $$(P+B-1)(P+B)=4PB$$ At this point we're stuck.  We notice a few random facts but can't put it all together.  For example, either $(P+B)$ or $(P+B-1)$ is divisible by four and the other one is an odd number.  We can also rearrange the terms to show that $4PB+P+B$ is a square. Can anyone out in math exchange land help us with a solution that does not involve fancy-pants math and does not involve a lot of guessing, spraying and praying?  It just seems like there ought to be an elegant solution...","So our six year old son comes home from 1st grade with the following math puzzle. Your Aunt is having a baby. You have created a party game for a baby shower.  It is called pick the gender.  You put pink and blue tiles into a bag.  You ask two guests to pick one tile each out of the bag without looking. You tell your guests that if they are the same color, player A wins and if they are two different colors, then player B wins. How many tiles of which colors did you put into the bag to make sure that both players have an equal chance of winning? Putting aside the obvious fact that this seems way too hard for a 1st grader it got us thinking...  Is there a clever way to solve this problem that doesn't involve guessing lots of ugly combinations? Let = Number of Pink Balls, = Number of Blue balls. It seems to me that the probability of Player ""B"" winning is In a fair game this probability is 50%. Or At this point we're stuck.  We notice a few random facts but can't put it all together.  For example, either or is divisible by four and the other one is an odd number.  We can also rearrange the terms to show that is a square. Can anyone out in math exchange land help us with a solution that does not involve fancy-pants math and does not involve a lot of guessing, spraying and praying?  It just seems like there ought to be an elegant solution...",P B \left(\frac{P}{P+B}\right)\left(\frac{B}{P+B-1}\right) + \left(\frac{B}{P+B}\right)\left(\frac{P}{P+B-1}\right) \frac{2PB}{(P+B)(P+B-1)} = \frac{1}{2} (P+B-1)(P+B)=4PB (P+B) (P+B-1) 4PB+P+B,"['probability', 'combinatorics']"
78,$m$ balls $n$ boxes probability problem,balls  boxes probability problem,m n,"I encountered this problem in my probability class, and we weren't able to solve it, so I would like to know the answer. If you have $m$ balls and $n$ boxes, with $n < m$, and you insert the balls into the boxes randomly, what is the probability that all the boxes have at least one ball in it? The problem doesn't specify if the balls are distinguishable or not, so you may assume either, so another question would be, if you assume they are distinguishable will you get the same answer as assuming they are not distinguishable? (This would be great because I think the non-distinguishable case is easier). I appreciate any insight on the problem.","I encountered this problem in my probability class, and we weren't able to solve it, so I would like to know the answer. If you have $m$ balls and $n$ boxes, with $n < m$, and you insert the balls into the boxes randomly, what is the probability that all the boxes have at least one ball in it? The problem doesn't specify if the balls are distinguishable or not, so you may assume either, so another question would be, if you assume they are distinguishable will you get the same answer as assuming they are not distinguishable? (This would be great because I think the non-distinguishable case is easier). I appreciate any insight on the problem.",,['probability']
79,Expected number of steps before three counters reach N modulo 2N at the same time,Expected number of steps before three counters reach N modulo 2N at the same time,,"We have three counters, $i, j, k$, all initialized to zero. Each step consists of adding or subtracting one from one of the counters, so $(\Delta i, \Delta j, \Delta k)$ is selected among $(\pm1, 0, 0), (0, \pm1, 0), (0, 0, \pm1)$, each with probability 1/6. What is the expected number of steps before all the counters are N modulo 2N at the same time?","We have three counters, $i, j, k$, all initialized to zero. Each step consists of adding or subtracting one from one of the counters, so $(\Delta i, \Delta j, \Delta k)$ is selected among $(\pm1, 0, 0), (0, \pm1, 0), (0, 0, \pm1)$, each with probability 1/6. What is the expected number of steps before all the counters are N modulo 2N at the same time?",,['probability']
80,Do the vertical bar and semicolon denote the same thing in the context of conditional probability?,Do the vertical bar and semicolon denote the same thing in the context of conditional probability?,,"In the CMU Machine Learning Lecture , likelihood function is denoted by $P(D|\theta)$ In the Cornell lecture note , likelihood function is denoted by $P(D;\theta)$ are semicolon and vertical bar the same here?","In the CMU Machine Learning Lecture , likelihood function is denoted by In the Cornell lecture note , likelihood function is denoted by are semicolon and vertical bar the same here?",P(D|\theta) P(D;\theta),"['probability', 'notation']"
81,"What is the difference between root mean square, and standard deviation?","What is the difference between root mean square, and standard deviation?",,"I am currently working through the Feynman Lectures, chapter 6: Probability. I have reached his problem of the ""random walk"". After deriving this and getting some root mean square, wouldn't this just be the same as finding the standard deviation? The standard deviation is the root of the mean of the squared data. Isn't that also just the root mean square? Also, what exactly are the implications of the root mean square, what does it even mean in regards to our problem? http://www.feynmanlectures.caltech.edu/I_06.html","I am currently working through the Feynman Lectures, chapter 6: Probability. I have reached his problem of the ""random walk"". After deriving this and getting some root mean square, wouldn't this just be the same as finding the standard deviation? The standard deviation is the root of the mean of the squared data. Isn't that also just the root mean square? Also, what exactly are the implications of the root mean square, what does it even mean in regards to our problem? http://www.feynmanlectures.caltech.edu/I_06.html",,"['probability', 'standard-deviation', 'means']"
82,Deducing a probability distribution from its moment-generating function,Deducing a probability distribution from its moment-generating function,,"It's pretty trivial to get a moment-generating function from a p.d.f. (provided $\sum e^{tx}f(x)$ isn't too difficult to evaluate), but since moment-generating functions uniquely determine a probability distribution function, is there a way to ""back-generate"" the p.d.f from the m.g.f.? Edit: I'm talking about a discrete distribution.","It's pretty trivial to get a moment-generating function from a p.d.f. (provided $\sum e^{tx}f(x)$ isn't too difficult to evaluate), but since moment-generating functions uniquely determine a probability distribution function, is there a way to ""back-generate"" the p.d.f from the m.g.f.? Edit: I'm talking about a discrete distribution.",,"['probability', 'statistics']"
83,Are there well known lower bounds for the upper incomplete gamma function?,Are there well known lower bounds for the upper incomplete gamma function?,,"Let $a >0, b >0$, and $r \in \mathbb{R}$.  I am trying to find a lower bound for the integral  $$\int_a^\infty y^{-r} \exp\left( - b(y-a)^2\right) \,\mathrm dy.$$ After consulting the Wikipedia page for the incomplete gamma function and a couple of other websites I still have not been able to find a reference for a lower bound. Do there exist a standard or well-known lower bounds for the incomplete gamma function?","Let $a >0, b >0$, and $r \in \mathbb{R}$.  I am trying to find a lower bound for the integral  $$\int_a^\infty y^{-r} \exp\left( - b(y-a)^2\right) \,\mathrm dy.$$ After consulting the Wikipedia page for the incomplete gamma function and a couple of other websites I still have not been able to find a reference for a lower bound. Do there exist a standard or well-known lower bounds for the incomplete gamma function?",,"['probability', 'inequality', 'special-functions']"
84,Birthday problem- Adam and Eve,Birthday problem- Adam and Eve,,Question: Adam and Eve are in a room with $n − 2$ other people. Suppose you know that at least two of the people in the room celebrate their birthday on the same day. What is the probability that Adam and Eve celebrate their birthday on the same day? (Assume that a year has 365 days and that the distribution of births over a year is uniform.) MyApproach: I think it is knowing that at least two people have the same birthday that is confusing to me. Does it change anything to have this info?,Question: Adam and Eve are in a room with other people. Suppose you know that at least two of the people in the room celebrate their birthday on the same day. What is the probability that Adam and Eve celebrate their birthday on the same day? (Assume that a year has 365 days and that the distribution of births over a year is uniform.) MyApproach: I think it is knowing that at least two people have the same birthday that is confusing to me. Does it change anything to have this info?,n − 2,"['probability', 'birthday']"
85,How many flips of a fair coin does it take until you get N heads in a row? [duplicate],How many flips of a fair coin does it take until you get N heads in a row? [duplicate],,"This question already has answers here : Expected Number of Coin Tosses to Get Five Consecutive Heads (14 answers) Closed 11 years ago . The question is pretty much in the title. How many flips of a fair coin does it take until you get N heads in a row on expectation? I am curious how this is proven in terms of probability (no this is not for homework, just genuine curiosity as it's a question I've always wondered).","This question already has answers here : Expected Number of Coin Tosses to Get Five Consecutive Heads (14 answers) Closed 11 years ago . The question is pretty much in the title. How many flips of a fair coin does it take until you get N heads in a row on expectation? I am curious how this is proven in terms of probability (no this is not for homework, just genuine curiosity as it's a question I've always wondered).",,['probability']
86,how does expectation maximization work in coin flipping problem,how does expectation maximization work in coin flipping problem,,"joriki: Thanks for your answer regarding the expectation maximization work relating to the coin flipping problem ( how does expectation maximization work? ). You have explained how the probability of coin A or coin B are selected for each set of observations. For example, you have told us how to derive the 0.8,0.2 given the current bias estimates θA=0.6 and θB=0.5 in the 2nd row. Can you help me understand how how do we go from that probability distribution (0.8, 0.2) to the expectation (7.2H, 0.8T) for coin A in the 2nd row as well. Same as the question asked by Martin, the total number of tosses should be 10 rather than 7.2H + 0.8T = 8? Many thanks here.","joriki: Thanks for your answer regarding the expectation maximization work relating to the coin flipping problem ( how does expectation maximization work? ). You have explained how the probability of coin A or coin B are selected for each set of observations. For example, you have told us how to derive the 0.8,0.2 given the current bias estimates θA=0.6 and θB=0.5 in the 2nd row. Can you help me understand how how do we go from that probability distribution (0.8, 0.2) to the expectation (7.2H, 0.8T) for coin A in the 2nd row as well. Same as the question asked by Martin, the total number of tosses should be 10 rather than 7.2H + 0.8T = 8? Many thanks here.",,['probability']
87,Prove or disprove: There is a way to choose independent random chords in a circle so that their intersections are uniformly distributed in the circle.,Prove or disprove: There is a way to choose independent random chords in a circle so that their intersections are uniformly distributed in the circle.,,"Prove or disprove: There is a way to choose independent random chords in a circle so that their intersection points (given that they exist) are uniformly distributed in the circle. One common way to choose a random chord in a circle, is to connect two uniformly random points on the circle. Assume the circle has center at origin with radius $1$ : $x^2+y^2=1$ . Numerical investigation (using Excel) suggests that, when two such chords are chosen independently and they intersect, the probability that their intersection point lies inside the smaller circle having center at origin with radius $1/2$ : $x^2+y^2=\frac{1}{4}$ , is $\frac{1}{6}$ . But the smaller circle's area is $\frac{1}{4}$ the larger circle's area. So the intersection points are not uniformly distributed in the circle. So I wonder if there is some method of choosing independent random chord, that yields intersection points that are uniformly distributed in the circle. Context: I have been generally interested in questions about random chords, for example: cutting a pizza , a counter-intuitive result , and a possibly intuitive result .","Prove or disprove: There is a way to choose independent random chords in a circle so that their intersection points (given that they exist) are uniformly distributed in the circle. One common way to choose a random chord in a circle, is to connect two uniformly random points on the circle. Assume the circle has center at origin with radius : . Numerical investigation (using Excel) suggests that, when two such chords are chosen independently and they intersect, the probability that their intersection point lies inside the smaller circle having center at origin with radius : , is . But the smaller circle's area is the larger circle's area. So the intersection points are not uniformly distributed in the circle. So I wonder if there is some method of choosing independent random chord, that yields intersection points that are uniformly distributed in the circle. Context: I have been generally interested in questions about random chords, for example: cutting a pizza , a counter-intuitive result , and a possibly intuitive result .",1 x^2+y^2=1 1/2 x^2+y^2=\frac{1}{4} \frac{1}{6} \frac{1}{4},"['probability', 'geometry', 'numerical-methods', 'circles', 'random']"
88,Is the probability of picking an Ace as the second card of a deck the same if the deck is shuffled after the first card?,Is the probability of picking an Ace as the second card of a deck the same if the deck is shuffled after the first card?,,"Here's the situation: You have a deck of 52 cards that is already shuffled. You pick the first card, and the first card is not an Ace. Is the probability of drawing an Ace as second card the same if The second card is immediately drawn from the deck The remaining deck is first shuffled without adding the first card back in, and then the second card is drawn. For me, it is obvious that probability of drawing an Ace in the second case is 4/51, but I'm not entirely sure that the probability is the same in the first case. Also, what would be the probability of the first case if we have drawn n cards and none of these are aces?","Here's the situation: You have a deck of 52 cards that is already shuffled. You pick the first card, and the first card is not an Ace. Is the probability of drawing an Ace as second card the same if The second card is immediately drawn from the deck The remaining deck is first shuffled without adding the first card back in, and then the second card is drawn. For me, it is obvious that probability of drawing an Ace in the second case is 4/51, but I'm not entirely sure that the probability is the same in the first case. Also, what would be the probability of the first case if we have drawn n cards and none of these are aces?",,"['probability', 'combinatorics', 'card-games']"
89,How to get PDF from characteristic function,How to get PDF from characteristic function,,I would appreciate if anybody could explain to me with a simple example how to find PDF of a random variable from its characteristic function. Thank you.,I would appreciate if anybody could explain to me with a simple example how to find PDF of a random variable from its characteristic function. Thank you.,,"['probability', 'probability-theory', 'probability-distributions', 'self-learning', 'characteristic-functions']"
90,Probability - Interview Question - Hidden Assumptions and Phrasing Issues,Probability - Interview Question - Hidden Assumptions and Phrasing Issues,,"I’ve encountered the following seemingly simple probability interview question in my workplace: Two reviewers were tasked with finding errors in a book. The first had found 40 errors and the other had found 60. 20 of the found errors were found in common. Give an estimate on the number of errors in the book. A few clarifications were given: The errors are not false positives. The probability of the reviewers to find any error is independent of each other. (Problematic phrasing?) The lower bound is not required (i.e at least 80 errors). It was my opinion that this problem is not well defined and any answer would rely on hidden assumptions. My coworker said that the solution is easily calculable using the following method assigning to x the total number of errors: $$P(A) = \frac{40}{x}$$ $$P(B) = \frac{60}{x}$$ $$P(A\cap B) = \frac{20}{x}$$ $$P(A\cap B) = P(A) * P(B)$$ $$\frac{20}{x} = \frac{40}{x} * \frac{60}{x} $$ $$20x = 2400$$ $$x = 120$$ I found this answer unsatisfying, but I am struggling to coherently explain why. I believe there are various assumptions hidden in the above “solution”. I need help identifying these assumptions or phrasing issues with the question itself that make it not well defined. It could be that I’m mistaken and the problem is well defined and I’ve complicated it. I am also interested in alternative solutions that could be based on different assumptions but don’t negate the clarifications made.","I’ve encountered the following seemingly simple probability interview question in my workplace: Two reviewers were tasked with finding errors in a book. The first had found 40 errors and the other had found 60. 20 of the found errors were found in common. Give an estimate on the number of errors in the book. A few clarifications were given: The errors are not false positives. The probability of the reviewers to find any error is independent of each other. (Problematic phrasing?) The lower bound is not required (i.e at least 80 errors). It was my opinion that this problem is not well defined and any answer would rely on hidden assumptions. My coworker said that the solution is easily calculable using the following method assigning to x the total number of errors: I found this answer unsatisfying, but I am struggling to coherently explain why. I believe there are various assumptions hidden in the above “solution”. I need help identifying these assumptions or phrasing issues with the question itself that make it not well defined. It could be that I’m mistaken and the problem is well defined and I’ve complicated it. I am also interested in alternative solutions that could be based on different assumptions but don’t negate the clarifications made.",P(A) = \frac{40}{x} P(B) = \frac{60}{x} P(A\cap B) = \frac{20}{x} P(A\cap B) = P(A) * P(B) \frac{20}{x} = \frac{40}{x} * \frac{60}{x}  20x = 2400 x = 120,"['probability', 'statistics', 'statistical-inference', 'word-problem', 'philosophy']"
91,Probability and Combinatorial Group Theory.,Probability and Combinatorial Group Theory.,,"If this is too broad or is otherwise a poor question, I apologise. I learnt recently that the probability that two integers generate the additive group of integers is $\frac{6}{\pi^2}$ . What other results are there like this? I'm looking for any results of probability applied to group theory, preferably combinatorial group theory, in manner such as the one above.","If this is too broad or is otherwise a poor question, I apologise. I learnt recently that the probability that two integers generate the additive group of integers is . What other results are there like this? I'm looking for any results of probability applied to group theory, preferably combinatorial group theory, in manner such as the one above.",\frac{6}{\pi^2},"['probability', 'group-theory', 'big-list', 'combinatorial-group-theory']"
92,Random walk on natural number,Random walk on natural number,,"Problem: You are standing at the position $0$ on the line of natural numbers $0, 1, 2, ..., n$. From this position you go to $1$ with probability $1$, but from any other position $i$ you go to $i+1$ with probability $p$ and respectively to $i-1$ with probability $1-p$. What is the expected number of steps to go from 0 to n? Just to be clear. There is no way you can end up on the negative number. And once you reach $n$ the game stops, so you can not end up on any number bigger than $n$. Here is my approach to tackle this problem: Let $N_i$ is the expected number of steps to reach $n$ from a position $i$. It is obvious that $N_n = 0$. Also $N_0 = 1 + N_1$. And if we select any number $i$ from $1$ to $n-1$, then $N_i = (1 - p) \cdot N_{i-1} + p \cdot N_{i+1} = 1 + (1-p) \cdot N_{i-1} + p \cdot N_{i+1}$. Now I am trying to simplify things having these three equations: $$N_0 = 1 + N_1\\ N_i = 1 + (1-p) \cdot N_{i-1} + p \cdot N_{i+1}\\ N_n = 0$$ Approach 1 Putting $i = 1$ in equation (2) I found that $N_1 = 2/p - 1 + N_2$, which I later put in (1) to get $N_0 = 2/p + N_2$ Doing the same with $i = 2$ I got $N_2 = 1 - 2/p + 2/p^2 + N_3$ and $N_0 = 1 + 2/p^2 + N_3$. Just one more step with $i = 3$ gives me $N_3 = N_4 + 4/p - 4/p^2 + 2/p^3 - 1$ and $N_0 = 4/p - 2/p^2 + 2/p^3 + N_4$ I was doing all this in hope of finding some relationship which would allow me to guess what will be the relationship for the last or one before last step. But I fail to see any and therefore I gave up. Approach 2 I noticed that: $N_0 - N_1 = 1$ and $N_{i-1} - N_i = 1 + (1 - p) \cdot (N_{i-2} - N_i)$ Here if I will sum the left side, I will get $N_0 - N_n = N_0$ and this gave me hope that I can get some closed form expression if I will add the right side. But when I add them up I got $n + (1 - p)(N_0 + N_1 - N_{n-1} - N_{n})$. This gave me $N_0 = \frac{n + (N_1 - N_{n-1})(1-p)}{p}$ which leads me nowhere because of $N_1$ and $N_{n-1}$. Approach 3 (similar to approach 2, but I expand the first element, not the second). I will not write it completely, not because I have not thought about, but because I value your time and I think that the post is already too long. So $N_0 - N_1 = 1$ and $N_i - N_{i+1} = -1 + p (N_i - N_{i+2})$. After the same summation idea as in approach 2 I ended up with $N_1$, $N_2$ and $N_{n-1}$ elements. After this I gave up completely. Here I am not really sure that my starting idea Let $N_i$ is the expected number of steps to reach $n$ from a position   $i$. is correct or whether the close formula for expected value exist. So how should I approach this problem? P.S. I know that for $p = 0.5$ (go left and right with equal probability) the close formula exists and expected number of steps one need to take from $0$ to $n$ is $n^2$.","Problem: You are standing at the position $0$ on the line of natural numbers $0, 1, 2, ..., n$. From this position you go to $1$ with probability $1$, but from any other position $i$ you go to $i+1$ with probability $p$ and respectively to $i-1$ with probability $1-p$. What is the expected number of steps to go from 0 to n? Just to be clear. There is no way you can end up on the negative number. And once you reach $n$ the game stops, so you can not end up on any number bigger than $n$. Here is my approach to tackle this problem: Let $N_i$ is the expected number of steps to reach $n$ from a position $i$. It is obvious that $N_n = 0$. Also $N_0 = 1 + N_1$. And if we select any number $i$ from $1$ to $n-1$, then $N_i = (1 - p) \cdot N_{i-1} + p \cdot N_{i+1} = 1 + (1-p) \cdot N_{i-1} + p \cdot N_{i+1}$. Now I am trying to simplify things having these three equations: $$N_0 = 1 + N_1\\ N_i = 1 + (1-p) \cdot N_{i-1} + p \cdot N_{i+1}\\ N_n = 0$$ Approach 1 Putting $i = 1$ in equation (2) I found that $N_1 = 2/p - 1 + N_2$, which I later put in (1) to get $N_0 = 2/p + N_2$ Doing the same with $i = 2$ I got $N_2 = 1 - 2/p + 2/p^2 + N_3$ and $N_0 = 1 + 2/p^2 + N_3$. Just one more step with $i = 3$ gives me $N_3 = N_4 + 4/p - 4/p^2 + 2/p^3 - 1$ and $N_0 = 4/p - 2/p^2 + 2/p^3 + N_4$ I was doing all this in hope of finding some relationship which would allow me to guess what will be the relationship for the last or one before last step. But I fail to see any and therefore I gave up. Approach 2 I noticed that: $N_0 - N_1 = 1$ and $N_{i-1} - N_i = 1 + (1 - p) \cdot (N_{i-2} - N_i)$ Here if I will sum the left side, I will get $N_0 - N_n = N_0$ and this gave me hope that I can get some closed form expression if I will add the right side. But when I add them up I got $n + (1 - p)(N_0 + N_1 - N_{n-1} - N_{n})$. This gave me $N_0 = \frac{n + (N_1 - N_{n-1})(1-p)}{p}$ which leads me nowhere because of $N_1$ and $N_{n-1}$. Approach 3 (similar to approach 2, but I expand the first element, not the second). I will not write it completely, not because I have not thought about, but because I value your time and I think that the post is already too long. So $N_0 - N_1 = 1$ and $N_i - N_{i+1} = -1 + p (N_i - N_{i+2})$. After the same summation idea as in approach 2 I ended up with $N_1$, $N_2$ and $N_{n-1}$ elements. After this I gave up completely. Here I am not really sure that my starting idea Let $N_i$ is the expected number of steps to reach $n$ from a position   $i$. is correct or whether the close formula for expected value exist. So how should I approach this problem? P.S. I know that for $p = 0.5$ (go left and right with equal probability) the close formula exists and expected number of steps one need to take from $0$ to $n$ is $n^2$.",,"['probability', 'random-walk']"
93,Why is the expected value (mean) of a variable written using square brackets?,Why is the expected value (mean) of a variable written using square brackets?,,"My question is told in a few words: Why do you write $E[X]$ in square brackets instead of something like $E(X)$? Probably it is not a ""function"". How would you call it then? This question also applies for $Var[X]$.","My question is told in a few words: Why do you write $E[X]$ in square brackets instead of something like $E(X)$? Probably it is not a ""function"". How would you call it then? This question also applies for $Var[X]$.",,"['probability', 'statistics', 'notation', 'random-variables']"
94,Improving Von Neumann's Unfair Coin Solution,Improving Von Neumann's Unfair Coin Solution,,"If a cheat has altered a coin to prefer one side over another (a   biased coin), the coin can still be used for fair results by changing   the game slightly. John von Neumann gave the following   procedure: Toss the coin twice. If the results match, start over, forgetting both   results. If the results differ, use the first result, forgetting the   second. Are there ways of doing this (can we tweak this procedure) to reduce the number of expected flips needed (for a realization of heads or tails)?","If a cheat has altered a coin to prefer one side over another (a   biased coin), the coin can still be used for fair results by changing   the game slightly. John von Neumann gave the following   procedure: Toss the coin twice. If the results match, start over, forgetting both   results. If the results differ, use the first result, forgetting the   second. Are there ways of doing this (can we tweak this procedure) to reduce the number of expected flips needed (for a realization of heads or tails)?",,"['probability', 'puzzle', 'recreational-mathematics']"
95,SDE with no strong solutions and Euler-Maruyama,SDE with no strong solutions and Euler-Maruyama,,"Tanaka's SDE [see wikipedia article ] $\text{d}X_t = \operatorname{sgn}( X_t ) \; \text{d}B_t$ with $X_0 = 0$, where $\operatorname{sgn}(x) = 1$ if $ x\ge 0$ and $\operatorname{sgn}(x) = -1$ if $x<0$, is known to not admit strong solutions. I take this to mean that given a Brownian motion $\hat{B}_t$ upfront, it might be impossible to build $X_t$ adapted to the filtration generated by $\hat{B}_t$, which I take to mean that Euler-Maruyama would not converge to the solution of this SDE? If I am correct, how does one simulate processes satisfying SDE that do not admit strong solutions? But most likely I am wrong, and misunderstand the concept of strong/weak solutions.  Does existence/non-existence of strong solutions bear any consequences for numerical simulation ? Thanks.","Tanaka's SDE [see wikipedia article ] $\text{d}X_t = \operatorname{sgn}( X_t ) \; \text{d}B_t$ with $X_0 = 0$, where $\operatorname{sgn}(x) = 1$ if $ x\ge 0$ and $\operatorname{sgn}(x) = -1$ if $x<0$, is known to not admit strong solutions. I take this to mean that given a Brownian motion $\hat{B}_t$ upfront, it might be impossible to build $X_t$ adapted to the filtration generated by $\hat{B}_t$, which I take to mean that Euler-Maruyama would not converge to the solution of this SDE? If I am correct, how does one simulate processes satisfying SDE that do not admit strong solutions? But most likely I am wrong, and misunderstand the concept of strong/weak solutions.  Does existence/non-existence of strong solutions bear any consequences for numerical simulation ? Thanks.",,"['probability', 'ordinary-differential-equations', 'stochastic-processes']"
96,Best Strategy for a die game,Best Strategy for a die game,,"You are allowed to roll a die up to six times. Anytime you stop, you get the dollar amount of the face value of your last roll. Question: What is the best strategy? According to my calculation, for the strategy 6,5,5,4,4, the expected value is $142/27\approx 5.26$, which I consider quite high. So this might be the best strategy. Here,  6,5,5,4,4 means in the first roll you stop only when you get a 6; if you did not get a 6 in the first roll, then in the second roll you stop only when you roll a number 5 or higher (i.e. 5 or 6), etc.","You are allowed to roll a die up to six times. Anytime you stop, you get the dollar amount of the face value of your last roll. Question: What is the best strategy? According to my calculation, for the strategy 6,5,5,4,4, the expected value is $142/27\approx 5.26$, which I consider quite high. So this might be the best strategy. Here,  6,5,5,4,4 means in the first roll you stop only when you get a 6; if you did not get a 6 in the first roll, then in the second roll you stop only when you roll a number 5 or higher (i.e. 5 or 6), etc.",,"['probability', 'combinatorics', 'game-theory', 'dice']"
97,Nice proof that expected number of $k$-cycles in a permutation of $n$ is $\frac1k$ whenever $0<k\leq n$,Nice proof that expected number of -cycles in a permutation of  is  whenever,k n \frac1k 0<k\leq n,"Taking the combintorialist point of view that a cycle of a permutation $~\sigma$ of a finite set $S$ is an orbit of the action of the subgroup generated by $~\sigma$ in its (natural) action on $~S$ , it is known that whenever $S$ admits $k$ -cycles at all (so $0<k\leq n$ where $n$ is the size of $S$ ), the expected number of $k$ -cycles of $~\sigma$ where $\sigma$ is chosen uniformly at random among all permutations of $~S$ , is precisely $~\frac1k$ . Stated differently, the statistic ""number of $k$ -cycles"" takes an average value of $~\frac1k$ when $\sigma$ runs over all permutations of $~S$ . I am looking for nice, intuitive, transparent, proofs of this fact, notably where the fraction $~\frac1k$ comes about naturally, preferably as the probability of obtaining a specific value when choosing an element uniformly from a $k$ -element set. While I know a few easy computations that prove the result, none I've seen so far have achieved this highest standard, though some arrive at the fraction after some very basic cancellations. The cases $k=1$ (the expected number of fixed points of a permutation is precisely $1$ ) and $k=n$ (there are $(n-1)!$ distinct cyclic permutations of $S$ , which is $\frac1n$ of all permutations) are very well known and with easy proofs, but I would like a proof that covers all allowed values of $k$ in a uniform manner. I've seen quite a few questions on this site that come close to this one, but few state the result in isolation and none specifically ask for elegant arguments, so I don't feel this question is truly a duplicate of any of them. This question was inspired by watching this video (with a rather click-bait title) where the deduction of the case for $k=n$ (from 8:17 on) is followed by the irrefutable argument ""this is a general result"" (implying it's validity for all $k$ ) with no mention of expectation (for $k=n$ the only possible numbers of cycles are $0$ and $1$ , so the expected value is just a probability) and no explanation whatsoever.","Taking the combintorialist point of view that a cycle of a permutation of a finite set is an orbit of the action of the subgroup generated by in its (natural) action on , it is known that whenever admits -cycles at all (so where is the size of ), the expected number of -cycles of where is chosen uniformly at random among all permutations of , is precisely . Stated differently, the statistic ""number of -cycles"" takes an average value of when runs over all permutations of . I am looking for nice, intuitive, transparent, proofs of this fact, notably where the fraction comes about naturally, preferably as the probability of obtaining a specific value when choosing an element uniformly from a -element set. While I know a few easy computations that prove the result, none I've seen so far have achieved this highest standard, though some arrive at the fraction after some very basic cancellations. The cases (the expected number of fixed points of a permutation is precisely ) and (there are distinct cyclic permutations of , which is of all permutations) are very well known and with easy proofs, but I would like a proof that covers all allowed values of in a uniform manner. I've seen quite a few questions on this site that come close to this one, but few state the result in isolation and none specifically ask for elegant arguments, so I don't feel this question is truly a duplicate of any of them. This question was inspired by watching this video (with a rather click-bait title) where the deduction of the case for (from 8:17 on) is followed by the irrefutable argument ""this is a general result"" (implying it's validity for all ) with no mention of expectation (for the only possible numbers of cycles are and , so the expected value is just a probability) and no explanation whatsoever.",~\sigma S ~\sigma ~S S k 0<k\leq n n S k ~\sigma \sigma ~S ~\frac1k k ~\frac1k \sigma ~S ~\frac1k k k=1 1 k=n (n-1)! S \frac1n k k=n k k=n 0 1,"['probability', 'combinatorics', 'permutations']"
98,Sum of Bernoulli random variables with different success probabilities,Sum of Bernoulli random variables with different success probabilities,,"Let $X_{i} \in \{0,1\}$ be Bernouli random variable with probability of success $p_{i}$, i.e., $P(X_{i}=1) = p_{i}$ and $P(X_{i}=0) = 1-p_{i}$ and let $Y=\sum_{i=1}^{n}X_{i}$ for $n>0$. Is it relatively simple to estimate the pmf $P(Y=y)$ when $p_{i} \neq p_{j}$ for $i \neq j$?","Let $X_{i} \in \{0,1\}$ be Bernouli random variable with probability of success $p_{i}$, i.e., $P(X_{i}=1) = p_{i}$ and $P(X_{i}=0) = 1-p_{i}$ and let $Y=\sum_{i=1}^{n}X_{i}$ for $n>0$. Is it relatively simple to estimate the pmf $P(Y=y)$ when $p_{i} \neq p_{j}$ for $i \neq j$?",,"['probability', 'probability-distributions']"
99,Consistency and asymptotically unbiasedness?,Consistency and asymptotically unbiasedness?,,"Does consistency imply asymptotically unbiasedness? I know the statement doesn't work in the other direction. My guess is it does, although it obviously does not imply unbiasedness. I think it wouldn't be too hard if one digs into measure theory and makes use of convergence in measure. But I have a gut feeling that this could be proved with only elementary probability theory. But can anybody give me a proof? Thanks!","Does consistency imply asymptotically unbiasedness? I know the statement doesn't work in the other direction. My guess is it does, although it obviously does not imply unbiasedness. I think it wouldn't be too hard if one digs into measure theory and makes use of convergence in measure. But I have a gut feeling that this could be proved with only elementary probability theory. But can anybody give me a proof? Thanks!",,['probability']
