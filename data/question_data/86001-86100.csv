,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Random variables with the same distributions,Random variables with the same distributions,,"Let $K$ and $L$ be locally compact Hausdorff spaces. Also, let $P$ be a Radon probability measure on $K$ so that $(K,P)$ is a probability space. I want to know, whether two random variables $X,Y\colon K\to L$ (they might be assumed to be continuous) have the same distributions. Is it sufficient if I check that $$\int_K f(X(\omega))P(d\omega) = \int_K f(Y(\omega))P(d\omega)$$ for each $f\in V$, where $V$ is some dense subspace of the Banach space $C_0(L)$ of continuous functions on $L$ which vanish at infinity?","Let $K$ and $L$ be locally compact Hausdorff spaces. Also, let $P$ be a Radon probability measure on $K$ so that $(K,P)$ is a probability space. I want to know, whether two random variables $X,Y\colon K\to L$ (they might be assumed to be continuous) have the same distributions. Is it sufficient if I check that $$\int_K f(X(\omega))P(d\omega) = \int_K f(Y(\omega))P(d\omega)$$ for each $f\in V$, where $V$ is some dense subspace of the Banach space $C_0(L)$ of continuous functions on $L$ which vanish at infinity?",,"['functional-analysis', 'probability-theory', 'banach-spaces']"
1,Cancellation law for Minkowski sums,Cancellation law for Minkowski sums,,"Let $(X,\|\cdot\|)$ be a Banach space and $A,B,C\subset X$ closed bounded non-empty convex subsets. Let $+$ denote the Minkowski symbol for addition . Does the $+$ satisfy: $$A+C\subset B+C\implies A\subset B$$","Let $(X,\|\cdot\|)$ be a Banach space and $A,B,C\subset X$ closed bounded non-empty convex subsets. Let $+$ denote the Minkowski symbol for addition . Does the $+$ satisfy: $$A+C\subset B+C\implies A\subset B$$",,"['real-analysis', 'functional-analysis', 'banach-spaces', 'convex-analysis']"
2,Continuous with respect to weak convergence implies affine,Continuous with respect to weak convergence implies affine,,"Let $\phi : \mathbb R \rightarrow \mathbb R$ be a continuous function such that whenever $f_n \rightarrow f$ weakly in $L^2[0,1]$, we have $\phi\circ f_n \rightarrow \phi\circ f$ weakly in $L^2[0,1]$. I am trying to prove that $\phi$ must be an affine map, $\phi(x)  = ax+b$ for some $a,b \in \mathbb R$. So far I've tried proving the contrapositive, or trying to show that $\phi'$ exists and is constant, but have had no success. Any suggestions?","Let $\phi : \mathbb R \rightarrow \mathbb R$ be a continuous function such that whenever $f_n \rightarrow f$ weakly in $L^2[0,1]$, we have $\phi\circ f_n \rightarrow \phi\circ f$ weakly in $L^2[0,1]$. I am trying to prove that $\phi$ must be an affine map, $\phi(x)  = ax+b$ for some $a,b \in \mathbb R$. So far I've tried proving the contrapositive, or trying to show that $\phi'$ exists and is constant, but have had no success. Any suggestions?",,['functional-analysis']
3,Finding the topological complement of a finite dimensional subspace,Finding the topological complement of a finite dimensional subspace,,"I know that for any finite dimensional subspace $F$ of a banach space $X$, there is always a closed subspace $W$ such that $X=W\oplus F$, that is, any finite dimensional subspace of a banach space is topologically complemented. However, I wonder whether we can put some condition on the complemented subspace. The problem I am working on is the following: Let $X$ be an infinite dimensional subspace. Suppose we have \begin{equation*} X=\overline{F_1\oplus F_2\oplus F_3\oplus\cdots} \end{equation*}  where all $F_j$'s are finite dimensional subspaces of $X$ with dimensions larger than 1. Can we find a closed subspace $W$ such that $X=F_1\oplus W$ and $W\supset \overline{F_2\oplus F_3\oplus\cdots}$? Or equivalently, can we find a vector $x\in F_1$ such that it lies outside the closed linear span of $F_j$ $(j\neq 1)$? Thanks!","I know that for any finite dimensional subspace $F$ of a banach space $X$, there is always a closed subspace $W$ such that $X=W\oplus F$, that is, any finite dimensional subspace of a banach space is topologically complemented. However, I wonder whether we can put some condition on the complemented subspace. The problem I am working on is the following: Let $X$ be an infinite dimensional subspace. Suppose we have \begin{equation*} X=\overline{F_1\oplus F_2\oplus F_3\oplus\cdots} \end{equation*}  where all $F_j$'s are finite dimensional subspaces of $X$ with dimensions larger than 1. Can we find a closed subspace $W$ such that $X=F_1\oplus W$ and $W\supset \overline{F_2\oplus F_3\oplus\cdots}$? Or equivalently, can we find a vector $x\in F_1$ such that it lies outside the closed linear span of $F_j$ $(j\neq 1)$? Thanks!",,"['functional-analysis', 'banach-spaces', 'topological-vector-spaces']"
4,Spectrum of $\int\limits_0^x f(t) dt$ operator,Spectrum of  operator,\int\limits_0^x f(t) dt,"Let $A\colon E\to E$ definied by $A(f)(x)= \int\limits_0^x f(t) dt$. I have to find the spectrum of $A$ in the cases $E=C[0,1]$ and $E=L_2[0,1]$. I have proved that $A$ has no eigenvalues, but I can't find full spectrum.","Let $A\colon E\to E$ definied by $A(f)(x)= \int\limits_0^x f(t) dt$. I have to find the spectrum of $A$ in the cases $E=C[0,1]$ and $E=L_2[0,1]$. I have proved that $A$ has no eigenvalues, but I can't find full spectrum.",,['functional-analysis']
5,"Prove that $Af(x) = \frac 1x \int\limits_0^x f(t) dt$ isn't compact in $L_2[0,1]$",Prove that  isn't compact in,"Af(x) = \frac 1x \int\limits_0^x f(t) dt L_2[0,1]","I need to prove that operator $\displaystyle Af(x) = \frac 1x\int\limits_0^x\ f(t) dt$ isn't compact in $L_2[0,1]$. I have tried to calculate spectrum of $A$, but failed.","I need to prove that operator $\displaystyle Af(x) = \frac 1x\int\limits_0^x\ f(t) dt$ isn't compact in $L_2[0,1]$. I have tried to calculate spectrum of $A$, but failed.",,['functional-analysis']
6,The space of real sequences that are convergent in Cesàro means forms a Hilbert space?,The space of real sequences that are convergent in Cesàro means forms a Hilbert space?,,"Let $a=\{a_i\}$ and $b=\{b_i\}$ be  real sequences such that $\lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}a_i^2$ and $\lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}b_i^2$ exist and are finite. The first question is: does the limit $\lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}a_i b_i$ always exist? If it exists, then we can define a semi-inner product  $\langle a,b\rangle := \lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}a_i b_i$  on a linear space $Y:=\left\{a\in\mathbb{R}^{\mathbb{N}}: \lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}a_i^2 \text{ exists and is finite } \right\} $. (Note that  $\langle ,\rangle$ is not positive definite, as pointed out by Nate (see Comment 1 below).) Setting $W:=\{a \in Y: \langle a, a\rangle =0 \}$ and using the semi-inner product $\langle ,\rangle$, we construct an inner product $(,)$ on the quotient space $Y/ W$ through setting $(a+W, b+W):=\langle a, b\rangle$. Another question: does $\left(Y/W, (,)\right)$ form a Hilbert space?","Let $a=\{a_i\}$ and $b=\{b_i\}$ be  real sequences such that $\lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}a_i^2$ and $\lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}b_i^2$ exist and are finite. The first question is: does the limit $\lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}a_i b_i$ always exist? If it exists, then we can define a semi-inner product  $\langle a,b\rangle := \lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}a_i b_i$  on a linear space $Y:=\left\{a\in\mathbb{R}^{\mathbb{N}}: \lim\limits_{N \to \infty} \frac{1}{N}\sum\limits_{i=1}^{N}a_i^2 \text{ exists and is finite } \right\} $. (Note that  $\langle ,\rangle$ is not positive definite, as pointed out by Nate (see Comment 1 below).) Setting $W:=\{a \in Y: \langle a, a\rangle =0 \}$ and using the semi-inner product $\langle ,\rangle$, we construct an inner product $(,)$ on the quotient space $Y/ W$ through setting $(a+W, b+W):=\langle a, b\rangle$. Another question: does $\left(Y/W, (,)\right)$ form a Hilbert space?",,"['real-analysis', 'functional-analysis']"
7,Functions as integrals of basis functions,Functions as integrals of basis functions,,"I was wondering if there are spaces (function spaces) where the functions have an integral representation, i.e. can be written as an integral involving Fourier coefficients and basis functions, akin to the Fourier transform. If so, what are they called and where may I find more information about them? Edit: I will try to make this more specific: It is well known that a Hilbert space has an orthonormal basis such that every vector can be written as a series (which is always well defined even if the orthonormal basis is uncountable since only countably many of the Fourier coefficients are nonzero). What I'm looking for is a function space that behaves just like a Hilbert space except that instead of a series you have an integral , e.g. $L^1(\mathbf R)$ with the ""basis"" $\{\phi_x \mid x \in \mathbf R, \phi_x(t) = e^{itx}\}$ as used in the inverse Fourier transform.","I was wondering if there are spaces (function spaces) where the functions have an integral representation, i.e. can be written as an integral involving Fourier coefficients and basis functions, akin to the Fourier transform. If so, what are they called and where may I find more information about them? Edit: I will try to make this more specific: It is well known that a Hilbert space has an orthonormal basis such that every vector can be written as a series (which is always well defined even if the orthonormal basis is uncountable since only countably many of the Fourier coefficients are nonzero). What I'm looking for is a function space that behaves just like a Hilbert space except that instead of a series you have an integral , e.g. $L^1(\mathbf R)$ with the ""basis"" $\{\phi_x \mid x \in \mathbf R, \phi_x(t) = e^{itx}\}$ as used in the inverse Fourier transform.",,['functional-analysis']
8,Closedness of the image of the closed unit ball under a linear operator from a reflexive Banach space to an arbitrary Banach space,Closedness of the image of the closed unit ball under a linear operator from a reflexive Banach space to an arbitrary Banach space,,"Let $V$ be a reflexive banach space. If $W$ is a Banach space and if $T$ is in $L(V,W)$, show that $T(B)$ is closed in $W$ where $B$ is closed unit ball in $V$, the problem is in the chapter of weak and weak$^{\ast}$ topologies but I am not getting any hint what result I should use. please help.","Let $V$ be a reflexive banach space. If $W$ is a Banach space and if $T$ is in $L(V,W)$, show that $T(B)$ is closed in $W$ where $B$ is closed unit ball in $V$, the problem is in the chapter of weak and weak$^{\ast}$ topologies but I am not getting any hint what result I should use. please help.",,"['functional-analysis', 'banach-spaces']"
9,Hilbert Space - Norm of derivative,Hilbert Space - Norm of derivative,,If $H$ is a Hilbert space of entire functions with weighted norm $||f||^{2}=\int_{R} |\frac{f(t)}{g(t)}|^{2}dt$ for some entire function $g$ (not necessary in $H$). Can we find any relation between the norm of $f$ and the norm of it's derivative? Something like: $||f'||\leq C ||f||$ for some constant $C$. (Note: so far we don't know whether $f'$ belongs to $H$ or not).,If $H$ is a Hilbert space of entire functions with weighted norm $||f||^{2}=\int_{R} |\frac{f(t)}{g(t)}|^{2}dt$ for some entire function $g$ (not necessary in $H$). Can we find any relation between the norm of $f$ and the norm of it's derivative? Something like: $||f'||\leq C ||f||$ for some constant $C$. (Note: so far we don't know whether $f'$ belongs to $H$ or not).,,[]
10,Non-completeness of the space of bounded linear operators,Non-completeness of the space of bounded linear operators,,"If $X$ and $Y$ are normed spaces I know that the space $B(X,Y)$ of bounded linear functions from $X$ to $Y$,  is complete if $Y$ is complete.  Is there an example of a pair of normed spaces $X,Y$ s.t. $B(X,Y)$ is not complete?","If $X$ and $Y$ are normed spaces I know that the space $B(X,Y)$ of bounded linear functions from $X$ to $Y$,  is complete if $Y$ is complete.  Is there an example of a pair of normed spaces $X,Y$ s.t. $B(X,Y)$ is not complete?",,"['real-analysis', 'functional-analysis', 'normed-spaces']"
11,Difficulty Grasping Weak and Weak-* Topologies and Their Intuition,Difficulty Grasping Weak and Weak-* Topologies and Their Intuition,,"I've been wrestling with the concepts of weak and weak-* topologies and how they naturally arise in functional analysis. Despite my efforts, they seem to come out of nowhere for me, and I'm hoping to gain some clarity with your insights. Let’s talk about weak topology first. According to Folland( Real Analysis: Modern Techniques and Their Applications Page 168) One often wishes to study the operator $\frac{d}{dx} $ , or more complicated operators constructed from it, acting on various spaces of functions. Unfortunately, it is virtually impossible to define norms on most infinite-dimensional functions spaces so that $\frac{d}{dx}$ becomes a bounded operator."" This statement makes sense to me, but I'm struggling to piece everything together. For instance, the concept of a weak derivative kind of feels like we're saying, ""Since we're in a framework where we can't distinguish two functions when they coincide almost everywhere (a.e.), let's tweak the notion of derivative to respect this."" However, it's not clear to me how a weak derivative becomes bounded when the classical derivative doesn't. When it comes to different modes of convergence, I can somewhat visualize what's happening. For example, if $f_n \to f$ in $L^1([-1,1])$ , it's like saying the average distance between these functions is getting smaller, even though they may differ on a set of measure zero. This kind of intuition works for me for other types of convergence (like in measure, pointwise, almost everywhere pointwise, uniform, almost everywhere uniform, etc.). But when someone says $f_n \to f$ in the weak topology, I'm lost. I can't intuitively grasp what's actually happening. Moving on to weak-* convergence, I understand it as a way to naturally embed a Banach space $X$ (or make it isomorphic to a subset) into $X^{**}$ , its double dual. Sure, it's neat that $X$ lies within $X^{**}$ , aligning with our intuitions from finite-dimensional spaces, but I'm questioning if there's more to it. Is there a deeper insight I'm missing? I've been stuck on this for a while and would greatly appreciate any explanations or insights you could share. Thank you very much! P.S:I highly recommend you to use $d/dx$ as an example, especially in solving differential equations since it seems to me a key example.","I've been wrestling with the concepts of weak and weak-* topologies and how they naturally arise in functional analysis. Despite my efforts, they seem to come out of nowhere for me, and I'm hoping to gain some clarity with your insights. Let’s talk about weak topology first. According to Folland( Real Analysis: Modern Techniques and Their Applications Page 168) One often wishes to study the operator , or more complicated operators constructed from it, acting on various spaces of functions. Unfortunately, it is virtually impossible to define norms on most infinite-dimensional functions spaces so that becomes a bounded operator."" This statement makes sense to me, but I'm struggling to piece everything together. For instance, the concept of a weak derivative kind of feels like we're saying, ""Since we're in a framework where we can't distinguish two functions when they coincide almost everywhere (a.e.), let's tweak the notion of derivative to respect this."" However, it's not clear to me how a weak derivative becomes bounded when the classical derivative doesn't. When it comes to different modes of convergence, I can somewhat visualize what's happening. For example, if in , it's like saying the average distance between these functions is getting smaller, even though they may differ on a set of measure zero. This kind of intuition works for me for other types of convergence (like in measure, pointwise, almost everywhere pointwise, uniform, almost everywhere uniform, etc.). But when someone says in the weak topology, I'm lost. I can't intuitively grasp what's actually happening. Moving on to weak-* convergence, I understand it as a way to naturally embed a Banach space (or make it isomorphic to a subset) into , its double dual. Sure, it's neat that lies within , aligning with our intuitions from finite-dimensional spaces, but I'm questioning if there's more to it. Is there a deeper insight I'm missing? I've been stuck on this for a while and would greatly appreciate any explanations or insights you could share. Thank you very much! P.S:I highly recommend you to use as an example, especially in solving differential equations since it seems to me a key example.","\frac{d}{dx}  \frac{d}{dx} f_n \to f L^1([-1,1]) f_n \to f X X^{**} X X^{**} d/dx","['real-analysis', 'functional-analysis']"
12,On a property for normed spaces,On a property for normed spaces,,"I came upon the following specific property for a normed space $X$ , and I am looking for a characterization of the normed spaces where it holds true: If a sequence $x_n$ in $X$ satisfies $\displaystyle \lim_{n\to\infty}(\|x_n+y\|-\|x_n\|)=\|y\|$ for all $y\in X$ , then $\displaystyle \lim_{n\to\infty}x_n=0$ . This is not true in $l_1$ ; take $x_n=e_n$ , the unit vector basis. The same counterexample doesn't seem to work in $c_0$ , $l_\infty$ , and $l_p$ for $p\neq 1$ . Is this actually true in these spaces, or is this property, in fact, never satisfied?","I came upon the following specific property for a normed space , and I am looking for a characterization of the normed spaces where it holds true: If a sequence in satisfies for all , then . This is not true in ; take , the unit vector basis. The same counterexample doesn't seem to work in , , and for . Is this actually true in these spaces, or is this property, in fact, never satisfied?",X x_n X \displaystyle \lim_{n\to\infty}(\|x_n+y\|-\|x_n\|)=\|y\| y\in X \displaystyle \lim_{n\to\infty}x_n=0 l_1 x_n=e_n c_0 l_\infty l_p p\neq 1,"['functional-analysis', 'normed-spaces', 'banach-spaces']"
13,If G is discrete and amenable then $C^*(G)$ has the CPAP,If G is discrete and amenable then  has the CPAP,C^*(G),"I have a question about the proof of Propostion 4.1 of the paper ""On Nuclear C*-algebras"" by Christopher Lance, it reads Proposition 4.1. If G is an amenable discrete group then $C^*(G)$ has the CPAP. The definition of CPAP is in the paper: Definition 3.5 . A $C^* $ -algebra $A$ has the completely positive approximation property (CPAP) if the identity mapping on $A^* $ can be approximated in the topology of simple weak*-convergence by completely positive mappings of norm one and finite rank. Lets assume that $G$ is countable and call the operators $T_n$ . My first question is regarding this definition: Question 1 By simple weak*-convergence is meant that for every $f \in A^* $ , $T_nf \rightarrow f$ in the norm of $A^* $ , or that for every $f \in A^* $ and $a \in A$ , $(T_nf)(a) \rightarrow f(a)$ ? Regarding the proof, we start by using the existence of a sequence $\sigma_n$ of functions of positive type on $G$ with finite support such that $\sigma_n \rightarrow$ $1$ pointwise ( 1 is the function that is identically 1). Then it is said we can view each $\sigma_n$ as a state on $C^*(G)$ . Question 2 Is the way that $\sigma_n$ is viewed as a state by defining $$ \sigma_n: C^*(G) \rightarrow \mathbb C \, \space u_g \rightarrow \sigma_n(g)? $$ After that, for every $\sigma \in E(C^* (G) ) $ (the set of states in $C^* (G)$ ) they consider a map $$ T_\sigma: E(C^* (G) ) \rightarrow E(C^* (G) )   $$ $$ \rho \rightarrow \rho\sigma $$ which is then extended to an operator in $B(C^* (G)^* )$ . We can thus consider the family $T_{\sigma_n}$ and they prove that it is completely positive, has norm one and state that it is easy to show that they are of finite rank and tend to $1$ in the topology of weak*-convergence. Question 3 I think there is a typo and when they say ""tend to $1$ "", they mean ""tend to the identity on $C^* (G)^* $ "". Is it true that they made a typo? Question 4 This is the most important one, they claim that it is easy to show that $T_{\sigma_n}$ converge to the identity on $C^* (G)^* $ in the simple weak* topology but I am not being able to prove this. Sorry for the long post and thank you in advance!","I have a question about the proof of Propostion 4.1 of the paper ""On Nuclear C*-algebras"" by Christopher Lance, it reads Proposition 4.1. If G is an amenable discrete group then has the CPAP. The definition of CPAP is in the paper: Definition 3.5 . A -algebra has the completely positive approximation property (CPAP) if the identity mapping on can be approximated in the topology of simple weak*-convergence by completely positive mappings of norm one and finite rank. Lets assume that is countable and call the operators . My first question is regarding this definition: Question 1 By simple weak*-convergence is meant that for every , in the norm of , or that for every and , ? Regarding the proof, we start by using the existence of a sequence of functions of positive type on with finite support such that pointwise ( 1 is the function that is identically 1). Then it is said we can view each as a state on . Question 2 Is the way that is viewed as a state by defining After that, for every (the set of states in ) they consider a map which is then extended to an operator in . We can thus consider the family and they prove that it is completely positive, has norm one and state that it is easy to show that they are of finite rank and tend to in the topology of weak*-convergence. Question 3 I think there is a typo and when they say ""tend to "", they mean ""tend to the identity on "". Is it true that they made a typo? Question 4 This is the most important one, they claim that it is easy to show that converge to the identity on in the simple weak* topology but I am not being able to prove this. Sorry for the long post and thank you in advance!","C^*(G) C^*  A A^*  G T_n f \in A^*  T_nf \rightarrow f A^*  f \in A^*  a \in A (T_nf)(a) \rightarrow f(a) \sigma_n G \sigma_n \rightarrow 1 \sigma_n C^*(G) \sigma_n 
\sigma_n: C^*(G) \rightarrow \mathbb C \, \space u_g \rightarrow \sigma_n(g)?
 \sigma \in E(C^* (G) )  C^* (G) 
T_\sigma: E(C^* (G) ) \rightarrow E(C^* (G) )  
 
\rho \rightarrow \rho\sigma
 B(C^* (G)^* ) T_{\sigma_n} 1 1 C^* (G)^*  T_{\sigma_n} C^* (G)^* ","['functional-analysis', 'proof-explanation', 'operator-algebras', 'c-star-algebras', 'completely-positive-maps']"
14,Tensor Product Of $L^p$ Spaces Is Dense In The Product $L^p$ Space,Tensor Product Of  Spaces Is Dense In The Product  Space,L^p L^p,"I want to prove the following: Proposition: Let $(X,\mathcal{A},\mu)$ and $(Y, \mathcal{B}, \nu)$ be $\sigma$ -finite measure spaces and let $(X\times Y , \mathcal{A} \otimes  \mathcal{B} , \mathcal{\mu}\otimes \mathcal{\nu})$ be the product measure space. Further let $p \in [1, \infty) $ . Then $$\overline{L^p(X) \otimes L^p(Y)} =  L^p(X \times Y), $$ where the closure is with respect to the norm in $L^p(X \times Y)$ . Here $L^p(X) \otimes L^p(Y)$ is identified with a subspace of $L^p(X \times Y)$ through the natural embedding $f \otimes g  \mapsto \big( (x,y) \mapsto f(x) g(y) \big) $ . I have proven the statement in the special case when $\mu$ and $\nu$ are finite (not $\sigma$ -finite) and my question is: Is my proof of the finite measure case correct and if it is, how can i adapt it to the case where the measures are $\sigma$ -finite? My proof (of the finite case): It suffices to show that $\chi_C \in \overline{L^p(X) \otimes L^p(Y)} $ for every $C \in \mathcal{A} \otimes \mathcal{B}$ with $\mu \otimes \nu (C) < \infty$ . Here $\chi_C$ denotes the indicator function of the set $C$ . This is because the linear combinations of such indicators are dense in $L^p(X \times Y)$ . Now assume that $\mu$ and $\nu$ are finite (and hence also $\mu \otimes \nu$ ), then we can use the following theorem, which is proven here : Theorem: Let $(X,\mathcal B,\mu)$ be a finite measure space. Let $\mathcal A\subset \mathcal B$ be an algebra generating $\cal B$ . Then for all $B\in\cal B$ and $\varepsilon>0$ , we can find $A\in\cal A$ such that $$\mu(A\Delta B)<\varepsilon.$$ Here $\Delta$ is the symmetric difference: $A \Delta B = (A \setminus B ) \cup (B\setminus A) = (A \cup B) \setminus (A \cap B)$ . To use the theorem define $$\mathcal{E}_0 =  \{ A \times B : A \in \mathcal{A}, B \in \mathcal{B}  \}$$ and $$\mathcal{E} = \big \{ \bigcup_{i=1}^n C_i : C_i \in \mathcal{E}_0 , n \in \mathbb{N}  \big \}.$$ Then $\mathcal{E}$ is an algebra that generates $\mathcal{A} \otimes \mathcal{B}$ . Clearly the indicator functions of all elements of $\mathcal{E}_0 $ are in $L^p(X) \otimes L^p(Y)$ , because they have product form and finite measure. The indicator function $\chi_E$ of every member $E$ of $ \mathcal{E}$ is also in $L^p(X) \otimes L^p(Y)$ , because $E$ can be written as a finite and disjoint union of sets in $\mathcal{E}_0$ and then $\chi_E$ is just the sum of the indicator functions on these rectangle sets. Now let $ C \in \mathcal{A} \otimes \mathcal{B}$ . Then by the theorem there exist for every $\varepsilon >0$ an $E \in \mathcal{E}$ so that $ \mu \otimes \nu (C \Delta E )< \varepsilon $ and therefore $$ \| \chi_C - \chi_E \|= \| \chi_{C \Delta E} \| = \big( \mu \otimes \nu (C \Delta E ) \big)^{1/p} < \varepsilon^{1/p},$$ which concludes the proof. My idea to extend the proof to the $\sigma$ -finite case is that the $\sigma$ -finite case can perhaps be reduced to the finite case by restricting the product measure space in some suitable way to make it finite. But i could not come up with a suitable restriction.","I want to prove the following: Proposition: Let and be -finite measure spaces and let be the product measure space. Further let . Then where the closure is with respect to the norm in . Here is identified with a subspace of through the natural embedding . I have proven the statement in the special case when and are finite (not -finite) and my question is: Is my proof of the finite measure case correct and if it is, how can i adapt it to the case where the measures are -finite? My proof (of the finite case): It suffices to show that for every with . Here denotes the indicator function of the set . This is because the linear combinations of such indicators are dense in . Now assume that and are finite (and hence also ), then we can use the following theorem, which is proven here : Theorem: Let be a finite measure space. Let be an algebra generating . Then for all and , we can find such that Here is the symmetric difference: . To use the theorem define and Then is an algebra that generates . Clearly the indicator functions of all elements of are in , because they have product form and finite measure. The indicator function of every member of is also in , because can be written as a finite and disjoint union of sets in and then is just the sum of the indicator functions on these rectangle sets. Now let . Then by the theorem there exist for every an so that and therefore which concludes the proof. My idea to extend the proof to the -finite case is that the -finite case can perhaps be reduced to the finite case by restricting the product measure space in some suitable way to make it finite. But i could not come up with a suitable restriction.","(X,\mathcal{A},\mu) (Y, \mathcal{B}, \nu) \sigma (X\times Y , \mathcal{A} \otimes  \mathcal{B} , \mathcal{\mu}\otimes \mathcal{\nu}) p \in [1, \infty)  \overline{L^p(X) \otimes L^p(Y)} =  L^p(X \times Y),  L^p(X \times Y) L^p(X) \otimes L^p(Y) L^p(X \times Y) f \otimes g  \mapsto \big( (x,y) \mapsto f(x) g(y) \big)  \mu \nu \sigma \sigma \chi_C \in \overline{L^p(X) \otimes L^p(Y)}  C \in \mathcal{A} \otimes \mathcal{B} \mu \otimes \nu (C) < \infty \chi_C C L^p(X \times Y) \mu \nu \mu \otimes \nu (X,\mathcal B,\mu) \mathcal A\subset \mathcal B \cal B B\in\cal B \varepsilon>0 A\in\cal A \mu(A\Delta B)<\varepsilon. \Delta A \Delta B = (A \setminus B ) \cup (B\setminus A) = (A \cup B) \setminus (A \cap B) \mathcal{E}_0 =  \{ A \times B : A \in \mathcal{A}, B \in \mathcal{B}  \} \mathcal{E} = \big \{ \bigcup_{i=1}^n C_i : C_i \in \mathcal{E}_0 , n \in \mathbb{N}  \big \}. \mathcal{E} \mathcal{A} \otimes \mathcal{B} \mathcal{E}_0  L^p(X) \otimes L^p(Y) \chi_E E  \mathcal{E} L^p(X) \otimes L^p(Y) E \mathcal{E}_0 \chi_E  C \in \mathcal{A} \otimes \mathcal{B} \varepsilon >0 E \in \mathcal{E}  \mu \otimes \nu (C \Delta E )< \varepsilon   \| \chi_C - \chi_E \|= \| \chi_{C \Delta E} \| = \big( \mu \otimes \nu (C \Delta E ) \big)^{1/p} < \varepsilon^{1/p}, \sigma \sigma","['functional-analysis', 'measure-theory', 'solution-verification', 'tensor-products']"
15,Special case of chain rule,Special case of chain rule,,"Suppose $H$ is a Hilbert space, $I:H \to \mathbb{R}$ is a functional and $\eta_t:\mathbb{R} \to H$ . I want to understand why \begin{equation*} \frac{d}{d t} I\left(\eta_t\right)=\left(I^\prime\left[\eta_t\right],\frac{d}{d t}  (\eta_t)\right), \end{equation*} where $(.,.)$ is the inner product of $H$ . I know that the formula is true when $H$ is a finite dimensional space (for example, $\mathbb{R}^n$ ), for then you can write coordinates $x_1,\dots, x_n$ and with the chain rule the inner product naturally appears. My question is how to show this formula is true when $H$ is an arbitrary Hilbert space.","Suppose is a Hilbert space, is a functional and . I want to understand why where is the inner product of . I know that the formula is true when is a finite dimensional space (for example, ), for then you can write coordinates and with the chain rule the inner product naturally appears. My question is how to show this formula is true when is an arbitrary Hilbert space.","H I:H \to \mathbb{R} \eta_t:\mathbb{R} \to H \begin{equation*}
\frac{d}{d t} I\left(\eta_t\right)=\left(I^\prime\left[\eta_t\right],\frac{d}{d t}  (\eta_t)\right),
\end{equation*} (.,.) H H \mathbb{R}^n x_1,\dots, x_n H","['functional-analysis', 'hilbert-spaces', 'chain-rule']"
16,"Find a function $f$ with some constraints that maximize $E[(f(X)-f(X+Y))X]$, where $X$ and $Y$ are independent and normal","Find a function  with some constraints that maximize , where  and  are independent and normal",f E[(f(X)-f(X+Y))X] X Y,"I am faced with the following problem: Problem. $X$ and $Y$ are independent normal random variables both with zero mean, $\operatorname{Var}(X)=1,\operatorname{Var}(Y)<1$ (seems not crucial). Find $f$ maximizing $$E[(f(X)-f(X+Y))X], $$ where $f$ is nondecreasing, odd and smooth, satisfying $|f|\leq 1$ . The restriction ""smooth"" is added by me to make the problem seem simpler. It can also be replaced by other restrictions. If possible, can we find the target $f$ when it is only subject to nondecreasing, odd and bounded? I would be grateful if there is any hint because I am totally not familliar with finding function to optimize some target.","I am faced with the following problem: Problem. and are independent normal random variables both with zero mean, (seems not crucial). Find maximizing where is nondecreasing, odd and smooth, satisfying . The restriction ""smooth"" is added by me to make the problem seem simpler. It can also be replaced by other restrictions. If possible, can we find the target when it is only subject to nondecreasing, odd and bounded? I would be grateful if there is any hint because I am totally not familliar with finding function to optimize some target.","X Y \operatorname{Var}(X)=1,\operatorname{Var}(Y)<1 f E[(f(X)-f(X+Y))X],  f |f|\leq 1 f","['functional-analysis', 'probability-theory', 'statistics', 'probability-distributions', 'probability-limit-theorems']"
17,Calculate the norm of the functional $f(x)=\displaystyle\int_{-1}^1tx(t)dt$,Calculate the norm of the functional,f(x)=\displaystyle\int_{-1}^1tx(t)dt,"Find the norm of the functional $f(x)=\displaystyle\int_{-1}^1tx(t)dt$ in the space $C^1[-1,1]$ , where the norm is given by $\|x\|=\max\limits_{t\in[-1,1]}|x(t)|+\max\limits_{t\in[-1,1]}|x'(t)|$ . The best upper bound I managed to get: integrating by parts, we get $$f(x)=\displaystyle\int_{-1}^1\left(\dfrac{1}{2}-\dfrac{t^2}{2}\right)x'(t)dt.$$ Adding this to the original functional and dividing by two, we get: $$f(x)=\displaystyle\int _{-1}^1\left(\dfrac{t}{2}x(t)+\left(\dfrac{1}{4}-\dfrac{t^2}{4}\right)x'(t)\right)dt,$$ so $$|f(x)|\le\int_{-1}^1\left(\dfrac{|t|}{2}|x(t)|+\left|\dfrac{1}{4}-\dfrac{t^2}{4}\right||x'(t)|\right)dt\le\|x\|\cdot\int_{-1}^1\max\left\{\dfrac{|t|}{2},\left|\dfrac{1}{4}-\dfrac{t^2}{4}\right|\right\}dt=$$ $$=\frac{2\sqrt2-1}{3}\cdot\|x\|\approx0,609476\cdot\|x\|.$$ However, I can't find even numerical lower bound for $0,609476$ using $\dfrac{|f(x)|}{\|x\|}$ fractions. I have a feeling that received upper bound is overstated. I would be grateful for any comments and ideas, both on how to improve the upper bound, and how to get at least a numerical lower bound. Interestingly, the norm of the same functional under the condition that $\|x\|=\max\left\{\max\limits_{t\in[-1,1]}|x(t)|,\max\limits_{t\in[-1,1]}|x'(t)|\right\}$ is calculated trivially and is equal to $\dfrac{2}{3}$ . Thanks to Brifa's comment, we managed to improve the upper bound to $\|f\|\le0,4$ . For a while I thought that the norm is $\frac{1}{3}$ , but found the following example (see graph): The ""switch"" point is approximately $0.806$ , and $\dfrac{|f(x)|}{\|x\|}\approx0,35$ .","Find the norm of the functional in the space , where the norm is given by . The best upper bound I managed to get: integrating by parts, we get Adding this to the original functional and dividing by two, we get: so However, I can't find even numerical lower bound for using fractions. I have a feeling that received upper bound is overstated. I would be grateful for any comments and ideas, both on how to improve the upper bound, and how to get at least a numerical lower bound. Interestingly, the norm of the same functional under the condition that is calculated trivially and is equal to . Thanks to Brifa's comment, we managed to improve the upper bound to . For a while I thought that the norm is , but found the following example (see graph): The ""switch"" point is approximately , and .","f(x)=\displaystyle\int_{-1}^1tx(t)dt C^1[-1,1] \|x\|=\max\limits_{t\in[-1,1]}|x(t)|+\max\limits_{t\in[-1,1]}|x'(t)| f(x)=\displaystyle\int_{-1}^1\left(\dfrac{1}{2}-\dfrac{t^2}{2}\right)x'(t)dt. f(x)=\displaystyle\int
_{-1}^1\left(\dfrac{t}{2}x(t)+\left(\dfrac{1}{4}-\dfrac{t^2}{4}\right)x'(t)\right)dt, |f(x)|\le\int_{-1}^1\left(\dfrac{|t|}{2}|x(t)|+\left|\dfrac{1}{4}-\dfrac{t^2}{4}\right||x'(t)|\right)dt\le\|x\|\cdot\int_{-1}^1\max\left\{\dfrac{|t|}{2},\left|\dfrac{1}{4}-\dfrac{t^2}{4}\right|\right\}dt= =\frac{2\sqrt2-1}{3}\cdot\|x\|\approx0,609476\cdot\|x\|. 0,609476 \dfrac{|f(x)|}{\|x\|} \|x\|=\max\left\{\max\limits_{t\in[-1,1]}|x(t)|,\max\limits_{t\in[-1,1]}|x'(t)|\right\} \dfrac{2}{3} \|f\|\le0,4 \frac{1}{3} 0.806 \dfrac{|f(x)|}{\|x\|}\approx0,35","['real-analysis', 'functional-analysis']"
18,"Grafakos $5.2.1$: Show that directional Hilbert Transform maps $L^1(\mathbb{R}^n)$ to $L^{1,\infty}(\mathbb{R}^n)$",Grafakos : Show that directional Hilbert Transform maps  to,"5.2.1 L^1(\mathbb{R}^n) L^{1,\infty}(\mathbb{R}^n)","Show that directional Hilbert Transform maps $L^1(\mathbb{R}^n)$ to $L^{1,\infty}(\mathbb{R}^n)$ The definition of directional Hilbert Transform is: $$H_\theta(f)(x)= \frac{1}{\pi}p.v \int_{-\infty}^{\infty}f(x-t \theta) \frac{dt}{t} $$ To prove the statatement, first I need to show that Hilbert Transform is given by convolution with the distribution $\omega_\theta$ in $S'(\mathbb{R}^n)$ defined by $$\langle \omega_\theta, \phi\rangle =  \frac{1}{\pi}p.v \int_{-\infty}^{\infty} \frac{\phi(t\theta)}{t}dt $$ I would like to know how to prove the first step and then how to use it to prove the original statement.Any hint?","Show that directional Hilbert Transform maps to The definition of directional Hilbert Transform is: To prove the statatement, first I need to show that Hilbert Transform is given by convolution with the distribution in defined by I would like to know how to prove the first step and then how to use it to prove the original statement.Any hint?","L^1(\mathbb{R}^n) L^{1,\infty}(\mathbb{R}^n) H_\theta(f)(x)= \frac{1}{\pi}p.v \int_{-\infty}^{\infty}f(x-t \theta) \frac{dt}{t}  \omega_\theta S'(\mathbb{R}^n) \langle \omega_\theta, \phi\rangle =  \frac{1}{\pi}p.v \int_{-\infty}^{\infty} \frac{\phi(t\theta)}{t}dt ","['real-analysis', 'functional-analysis', 'fourier-analysis', 'harmonic-analysis']"
19,$\{T = A^*A - AA^*: A \in \mathcal B(\mathcal H)\}$ is closed in the norm topology but $\{T = A^*A-AA^*: A \in \mathcal K(\mathcal H)\}$ is not,is closed in the norm topology but  is not,\{T = A^*A - AA^*: A \in \mathcal B(\mathcal H)\} \{T = A^*A-AA^*: A \in \mathcal K(\mathcal H)\},"I would like to show that: The set of all self-commutators is closed under the norm-topology, while the set of all self-commutators of compact operators is not so. in the setting of infinite-dimensional, separable Hilbert spaces. Recall that an operator $T \in \mathcal B(\mathcal H)$ is said to be a self-commutator if there exists an operator $A \in \mathcal B(\mathcal H)$ such that $$T = [A^*,A] = A^*A- AA^*$$ Also, $[A^*,A]$ is called the self-commutator of $A$ . The norm topology is (clearly) metrizable, and so it is enough to check sequential closedness. For the first claim, i.e., $\{T = A^*A - AA^*: A \in \mathcal B(\mathcal H)\}$ is closed in the norm topology - consider sequences $\{T_n\}_{n\ge 1}$ and $\{A_n\}_{n\ge 1}$ in $\mathcal B(\mathcal H)$ , such that $T_n = [A_n^*,A_n]$ , and $T_n \xrightarrow{n\to\infty} T$ in the norm topology, i.e., $\|T_n - T\| \xrightarrow{n\to\infty} 0$ . What is a suitable candidate $A \in \mathcal B(\mathcal H)$ that may satisfy $T = [A^*,A]$ ? Even though the sequence $\{T_n\}_{n\ge 1}$ is assumed to converge in norm, it is not clear that $\{A_n\}_{n\ge 1}$ converges also. For the second claim, it is enough to find a counterexample, i.e., specific sequences $\{T_n\}_{n\ge 1}$ and $\{A_n\}_{n\ge 1}$ of compact operators, such that $T_n = [A_n^*,A_n]$ such that $T_n \xrightarrow{n\to\infty} T$ in the norm topology, but $T$ is not a self-commutator. I haven't made much progress beyond what's stated above, and I'll appreciate any help. Thanks!","I would like to show that: The set of all self-commutators is closed under the norm-topology, while the set of all self-commutators of compact operators is not so. in the setting of infinite-dimensional, separable Hilbert spaces. Recall that an operator is said to be a self-commutator if there exists an operator such that Also, is called the self-commutator of . The norm topology is (clearly) metrizable, and so it is enough to check sequential closedness. For the first claim, i.e., is closed in the norm topology - consider sequences and in , such that , and in the norm topology, i.e., . What is a suitable candidate that may satisfy ? Even though the sequence is assumed to converge in norm, it is not clear that converges also. For the second claim, it is enough to find a counterexample, i.e., specific sequences and of compact operators, such that such that in the norm topology, but is not a self-commutator. I haven't made much progress beyond what's stated above, and I'll appreciate any help. Thanks!","T \in \mathcal B(\mathcal H) A \in \mathcal B(\mathcal H) T = [A^*,A] = A^*A- AA^* [A^*,A] A \{T = A^*A - AA^*: A \in \mathcal B(\mathcal H)\} \{T_n\}_{n\ge 1} \{A_n\}_{n\ge 1} \mathcal B(\mathcal H) T_n = [A_n^*,A_n] T_n \xrightarrow{n\to\infty} T \|T_n - T\| \xrightarrow{n\to\infty} 0 A \in \mathcal B(\mathcal H) T = [A^*,A] \{T_n\}_{n\ge 1} \{A_n\}_{n\ge 1} \{T_n\}_{n\ge 1} \{A_n\}_{n\ge 1} T_n = [A_n^*,A_n] T_n \xrightarrow{n\to\infty} T T","['functional-analysis', 'analysis', 'operator-theory', 'hilbert-spaces']"
20,Is there a handy integrable test function with a polynomial decay and a compactly supported Fourier transform?,Is there a handy integrable test function with a polynomial decay and a compactly supported Fourier transform?,,"From what I am aware of, let the function $\varphi$ be $$\varphi(x)=\frac{\cos(x)}{\pi^2-4x^2}.$$ One can easily show that $\varphi\in L^1$ and its tail has a polynomial decay $\varphi\sim x^{-2}$ . Its Fourier transform is $$\hat\varphi(s)=c\cos(\pi s/2),\quad s\in(-1,1)$$ with a proper constant $c$ depending on the convention of Fourier transform. Also it is easily seen that $\hat\varphi$ has a compact support. My question is, is there a generalisation of this test function such that $\varphi_k\in L^1$ , $\hat\varphi_k$ has a compact support, and $\varphi_k$ decays like $x^{-k}$ for a fixed $k$ ? The previous one is like $\varphi_2$ .","From what I am aware of, let the function be One can easily show that and its tail has a polynomial decay . Its Fourier transform is with a proper constant depending on the convention of Fourier transform. Also it is easily seen that has a compact support. My question is, is there a generalisation of this test function such that , has a compact support, and decays like for a fixed ? The previous one is like .","\varphi \varphi(x)=\frac{\cos(x)}{\pi^2-4x^2}. \varphi\in L^1 \varphi\sim x^{-2} \hat\varphi(s)=c\cos(\pi s/2),\quad s\in(-1,1) c \hat\varphi \varphi_k\in L^1 \hat\varphi_k \varphi_k x^{-k} k \varphi_2","['real-analysis', 'functional-analysis', 'analysis', 'fourier-analysis', 'harmonic-analysis']"
21,A proper approach to learn Koopman Operator Theory,A proper approach to learn Koopman Operator Theory,,"Edit : Rephrasing my post to make my statement clearer. In $1931$ , Bernard Koopman known for his work in ergodic theory, proposed a linear operator that describes the evolution of scalar observables (i.e., measurement functions of the states) in an infinite dimensional Hilbert space. In other words, if we have a non-linear system then we can shoot it to an infinite-dimensional function space where the evolution of the original system becomes linear. This has now become known as Koopman Operator Theory (KOT) . This is a relatively new (for me) topic $80$ years later his work resurged and became an important contribution in the study of stability analysis and in providing alternative formalism for study of dynamical systems mainly in non-linear control systems with applications ranging in adaptive control, non-linear control, system identification, deep learning, reinforcement learning which is the source of my motivation (to model non-linear dynamics using advanced and rigorous mathematics). I myself have no rigorious understanding in much of functional analysis except from an engineering point of view in topics such as signal processing, control theory, but I questioned how can non-linear systems from an engineering perspective be dealt in an ""infinite""-dimensional space. With that being said, I am looking for a formal roadmap that can help me establish a proper and rigorous understanding of Koopman Operator Theory. While being obvious that this topic is just a fraction of what operator theory contains, I wish to know what concepts are needed in measure theory, functional analysis to reach the level of understanding required to deal with KOP from a mathematician perspective. I am asking this question due to my engineering background with a rich background in applied mathematics but limited knowledge in analysis. Therefore, this question targets individuals who have knowledge in functional analysis, hilbert space,... or individuals who are active in the research community in particular in KOP theory.","Edit : Rephrasing my post to make my statement clearer. In , Bernard Koopman known for his work in ergodic theory, proposed a linear operator that describes the evolution of scalar observables (i.e., measurement functions of the states) in an infinite dimensional Hilbert space. In other words, if we have a non-linear system then we can shoot it to an infinite-dimensional function space where the evolution of the original system becomes linear. This has now become known as Koopman Operator Theory (KOT) . This is a relatively new (for me) topic years later his work resurged and became an important contribution in the study of stability analysis and in providing alternative formalism for study of dynamical systems mainly in non-linear control systems with applications ranging in adaptive control, non-linear control, system identification, deep learning, reinforcement learning which is the source of my motivation (to model non-linear dynamics using advanced and rigorous mathematics). I myself have no rigorious understanding in much of functional analysis except from an engineering point of view in topics such as signal processing, control theory, but I questioned how can non-linear systems from an engineering perspective be dealt in an ""infinite""-dimensional space. With that being said, I am looking for a formal roadmap that can help me establish a proper and rigorous understanding of Koopman Operator Theory. While being obvious that this topic is just a fraction of what operator theory contains, I wish to know what concepts are needed in measure theory, functional analysis to reach the level of understanding required to deal with KOP from a mathematician perspective. I am asking this question due to my engineering background with a rich background in applied mathematics but limited knowledge in analysis. Therefore, this question targets individuals who have knowledge in functional analysis, hilbert space,... or individuals who are active in the research community in particular in KOP theory.",1931 80,"['functional-analysis', 'reference-request', 'operator-theory', 'dynamical-systems', 'koopman-operator']"
22,Minimum area bound by the function,Minimum area bound by the function,,"Let $f:[0,1]->[0,1]$ be a continous function such that $$f(f(x))=1$$ for all $x$ in the domain. Required is the minimum and maximum possible area bound by this function from $x=0$ to $x=1$ As the function is bounded , I start by taking some $\alpha$ as the $x$ corresponding to the max value. Then $f(f(\alpha))=1$ as well, and $1$ is the maximum possible value in itself, $$f(\alpha)=f(1)=1$$ But from here I could not proceed to find the minimum value of $\int_{0}^{1}f(x)$ . A hint on how to proceed from here is highly appreciated. Thank you.","Let be a continous function such that for all in the domain. Required is the minimum and maximum possible area bound by this function from to As the function is bounded , I start by taking some as the corresponding to the max value. Then as well, and is the maximum possible value in itself, But from here I could not proceed to find the minimum value of . A hint on how to proceed from here is highly appreciated. Thank you.","f:[0,1]->[0,1] f(f(x))=1 x x=0 x=1 \alpha x f(f(\alpha))=1 1 f(\alpha)=f(1)=1 \int_{0}^{1}f(x)","['functional-analysis', 'functions']"
23,"Can a norm on polynomials be ""almost multiplicative"", even for large degrees?","Can a norm on polynomials be ""almost multiplicative"", even for large degrees?",,"Definition: A norm on a real algebra is called almost multiplicative if there are positive constants $L$ and $U$ such that, for all $f$ and $g$ in the algebra, $$L\lVert f\rVert\cdot\lVert g\rVert\;\leq\;\lVert f\cdot g\rVert\;\leq\;U\lVert f\rVert\cdot\lVert g\rVert;$$ equivalently, if $$0\;<\;\inf_{f,g}\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\;\leq\;\sup_{f,g}\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\;<\;\infty.$$ Is there an almost multiplicative norm on $\mathbb R[x]$ ? The infimum (or supremum) is the same, whether the polynomials $f$ and $g$ have integer coefficients, or rational coefficients (just factor out a common denominator), or real coefficients (take limits of rationals). I don't know if it's the same for complex coefficients (given that the norm respects the complex absolute value: $\lVert e^{i\theta}f\rVert=\lVert f\rVert$ ). Denote by $\mathbb R[x]_n$ the space of polynomials of degree $n$ or less. This has finite dimension $n+1$ . If we consider multiplication $\mathbb R[x]_m\times\mathbb R[x]_n\to\mathbb R[x]_{m+n}$ , and take the infimum/supremum over these subspaces, then any norm is almost multiplicative. That is because the unit sphere in finite dimensions is compact; the infimum is actually a minimum, and the supremum is actually a maximum. The minimizing polynomials are non-zero, so their product is non-zero: $\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}>0$ . The maximizing polynomials have a defined product, which has finite norm: $\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}<\infty$ . Of course that argument doesn't work for the whole infinite-dimensional space $\mathbb R[x]$ . No norm on polynomials is actually multiplicative; the infimum is not equal to the supremum. Multiplicative norm on $\mathbb{R}[X]$. These bounds on norms of products are useful for factoring polynomials with integer coefficients. Suppose $f\cdot g\in\mathbb Z[x]_n\backslash\{0\}$ is known but $f$ and $g$ are not known. Let $L$ be a lower bound for products as described above. Let $\varepsilon>0$ be the minimum norm on $\mathbb Z[x]_n\backslash\{0\}$ ; this exists because $\mathbb Z[x]_n$ is a lattice in $\mathbb R[x]_n$ , and a lattice intersected with a ball is a finite set. Then there are only finitely many possible factors $f$ , because $$\lVert f\rVert\;\leq\;\frac{\lVert f\rVert\cdot\lVert g\rVert}{\varepsilon}\;\leq\;\frac{\lVert f\cdot g\rVert}{\varepsilon L}.$$ Relevant links: Bombieri Norm Bounds on Factors in $\mathbb Z[x]$ (Abbott) Global optimization: a model problem , or A Model Problem for Global optimization (Rump) I considered weighted $\infty$ -norms; norms of the form $$\Bigg\lVert\sum_ka_kx^k\Bigg\rVert_c=\max_k(c_k|a_k|)$$ where $c=(c_0,c_1,c_2,\cdots)$ is a sequence of positive numbers. The upper bound $\lVert f\cdot g\rVert\leq U\lVert f\rVert\lVert g\rVert$ then is saying that $$\max_l\left|c_l\sum_{j+k=l}a_jb_k\right|\leq U\max_j|c_ja_j|\max_k|c_kb_k|.$$ By scaling the coefficients, $a_j'=c_ja_j$ and $b_k'=c_kb_k$ , this is equivalent to $$\max_l\left|\sum_{j+k=l}\frac{c_l}{c_jc_k}a_j'b_k'\right|\leq U\max_j|a_j'|\max_k|b_k'|.$$ By applying the triangle inequality (for one direction, and by taking particular examples with $a_j',b_k'\in\{0,1\}$ for the other direction), this is equivalent to $$\sum_{j+k=l}\frac{c_l}{c_jc_k}\leq U$$ for every $l\in\mathbb N$ . For the constant weight $c_k=1$ , the $l$ 'th sum here is just $\sum_{j+k=l}(1)=l+1$ which is unbounded. For the factorial weights $c_k=k!$ , the $l$ 'th sum is $$\sum_{j+k=l}\frac{l!}{j!k!}=\sum_k\binom{l}{k}=2^l$$ which is also unbounded. For the inverse factorial weights $c_k=1/k!$ , the $l$ 'th sum is $\sum_k1/\binom lk$ , which has maximum $8/3$ (at $l=3$ or $4$ ) and limit $2$ (as $l\to\infty$ ). So we can take $U=8/3$ as an upper bound. But I think there is no lower bound $L>0$ , considering for example $f_n(x)=(x+1)^n$ and $g_n(x)=(x-1)^n$ (though I'm not sure the norm ratio actually converges to $0$ as $n\to\infty$ ). For the square weights $c_k=(k+1)^2$ , the $l$ 'th sum is $\sum_k\left(\frac{(l+1)}{(l-k+1)(k+1)}\right)^2$ , which seems to have maximum $3.5171$ (at $l=19$ ), and has limit $\pi^2/3$ . So there is an upper bound. It is harder to find lower bounds. I don't know if there's any norm on $\mathbb R[x]$ for which $\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\geq L>0$ . Even if there are norms with lower bounds as well as norms with upper bounds, there isn't necessarily a single norm which is bounded both ways.","Definition: A norm on a real algebra is called almost multiplicative if there are positive constants and such that, for all and in the algebra, equivalently, if Is there an almost multiplicative norm on ? The infimum (or supremum) is the same, whether the polynomials and have integer coefficients, or rational coefficients (just factor out a common denominator), or real coefficients (take limits of rationals). I don't know if it's the same for complex coefficients (given that the norm respects the complex absolute value: ). Denote by the space of polynomials of degree or less. This has finite dimension . If we consider multiplication , and take the infimum/supremum over these subspaces, then any norm is almost multiplicative. That is because the unit sphere in finite dimensions is compact; the infimum is actually a minimum, and the supremum is actually a maximum. The minimizing polynomials are non-zero, so their product is non-zero: . The maximizing polynomials have a defined product, which has finite norm: . Of course that argument doesn't work for the whole infinite-dimensional space . No norm on polynomials is actually multiplicative; the infimum is not equal to the supremum. Multiplicative norm on $\mathbb{R}[X]$. These bounds on norms of products are useful for factoring polynomials with integer coefficients. Suppose is known but and are not known. Let be a lower bound for products as described above. Let be the minimum norm on ; this exists because is a lattice in , and a lattice intersected with a ball is a finite set. Then there are only finitely many possible factors , because Relevant links: Bombieri Norm Bounds on Factors in (Abbott) Global optimization: a model problem , or A Model Problem for Global optimization (Rump) I considered weighted -norms; norms of the form where is a sequence of positive numbers. The upper bound then is saying that By scaling the coefficients, and , this is equivalent to By applying the triangle inequality (for one direction, and by taking particular examples with for the other direction), this is equivalent to for every . For the constant weight , the 'th sum here is just which is unbounded. For the factorial weights , the 'th sum is which is also unbounded. For the inverse factorial weights , the 'th sum is , which has maximum (at or ) and limit (as ). So we can take as an upper bound. But I think there is no lower bound , considering for example and (though I'm not sure the norm ratio actually converges to as ). For the square weights , the 'th sum is , which seems to have maximum (at ), and has limit . So there is an upper bound. It is harder to find lower bounds. I don't know if there's any norm on for which . Even if there are norms with lower bounds as well as norms with upper bounds, there isn't necessarily a single norm which is bounded both ways.","L U f g L\lVert f\rVert\cdot\lVert g\rVert\;\leq\;\lVert f\cdot g\rVert\;\leq\;U\lVert f\rVert\cdot\lVert g\rVert; 0\;<\;\inf_{f,g}\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\;\leq\;\sup_{f,g}\frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\;<\;\infty. \mathbb R[x] f g \lVert e^{i\theta}f\rVert=\lVert f\rVert \mathbb R[x]_n n n+1 \mathbb R[x]_m\times\mathbb R[x]_n\to\mathbb R[x]_{m+n} \frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}>0 \frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}<\infty \mathbb R[x] f\cdot g\in\mathbb Z[x]_n\backslash\{0\} f g L \varepsilon>0 \mathbb Z[x]_n\backslash\{0\} \mathbb Z[x]_n \mathbb R[x]_n f \lVert f\rVert\;\leq\;\frac{\lVert f\rVert\cdot\lVert g\rVert}{\varepsilon}\;\leq\;\frac{\lVert f\cdot g\rVert}{\varepsilon L}. \mathbb Z[x] \infty \Bigg\lVert\sum_ka_kx^k\Bigg\rVert_c=\max_k(c_k|a_k|) c=(c_0,c_1,c_2,\cdots) \lVert f\cdot g\rVert\leq U\lVert f\rVert\lVert g\rVert \max_l\left|c_l\sum_{j+k=l}a_jb_k\right|\leq U\max_j|c_ja_j|\max_k|c_kb_k|. a_j'=c_ja_j b_k'=c_kb_k \max_l\left|\sum_{j+k=l}\frac{c_l}{c_jc_k}a_j'b_k'\right|\leq U\max_j|a_j'|\max_k|b_k'|. a_j',b_k'\in\{0,1\} \sum_{j+k=l}\frac{c_l}{c_jc_k}\leq U l\in\mathbb N c_k=1 l \sum_{j+k=l}(1)=l+1 c_k=k! l \sum_{j+k=l}\frac{l!}{j!k!}=\sum_k\binom{l}{k}=2^l c_k=1/k! l \sum_k1/\binom lk 8/3 l=3 4 2 l\to\infty U=8/3 L>0 f_n(x)=(x+1)^n g_n(x)=(x-1)^n 0 n\to\infty c_k=(k+1)^2 l \sum_k\left(\frac{(l+1)}{(l-k+1)(k+1)}\right)^2 3.5171 l=19 \pi^2/3 \mathbb R[x] \frac{\lVert f\cdot g\rVert}{\lVert f\rVert\cdot\lVert g\rVert}\geq L>0","['functional-analysis', 'polynomials', 'normed-spaces', 'supremum-and-infimum', 'upper-lower-bounds']"
24,Compactness in sequence space,Compactness in sequence space,,"We have the vector space $X=\{\vec{x}=(x_1, x_2,\cdots) | x_n\in\mathbb{R} (n\in\mathbb{N}), \sum_{n=1}^{\infty}\frac{1}{n}|x_n|<\infty \}$ , and the norm $\|\vec{x}\|=\sum_{n=1}^{\infty}\frac{1}{n}|x_n|\ (\vec{x}=(x_1, x_2, \cdots))$ on it. This normed space is complete. The question is about the compactness of the following subset $A\subset X$ , $A=\{\vec{x}\in X|\sum_{n=1}^{\infty} |x_n|^2\leq 1\}$ . I know this subset $A$ is bounded and closed (the boundedness comes from the fact $|x_n|\leq\frac{1}{\sqrt{n}}$ assuming $\{|x_n|\}$ is monotonically decreasing). What I cannot tell is whether this subset $A$ is compact or not (in the Banach space $(X, \|\cdot\|)$ ). Can you help me with this problem?","We have the vector space , and the norm on it. This normed space is complete. The question is about the compactness of the following subset , . I know this subset is bounded and closed (the boundedness comes from the fact assuming is monotonically decreasing). What I cannot tell is whether this subset is compact or not (in the Banach space ). Can you help me with this problem?","X=\{\vec{x}=(x_1, x_2,\cdots) | x_n\in\mathbb{R} (n\in\mathbb{N}), \sum_{n=1}^{\infty}\frac{1}{n}|x_n|<\infty \} \|\vec{x}\|=\sum_{n=1}^{\infty}\frac{1}{n}|x_n|\ (\vec{x}=(x_1, x_2, \cdots)) A\subset X A=\{\vec{x}\in X|\sum_{n=1}^{\infty} |x_n|^2\leq 1\} A |x_n|\leq\frac{1}{\sqrt{n}} \{|x_n|\} A (X, \|\cdot\|)",['functional-analysis']
25,Fredholm Alternative for Compact Operators - Why isn't it so simple?,Fredholm Alternative for Compact Operators - Why isn't it so simple?,,"Let $\mathfrak{X}$ be a Banach space, and $K\in \mathcal{K}(\mathfrak{X})$ be a compact operator. Then given $\lambda\in\mathbb{C}\backslash\{0\}$ , we can show that $\operatorname{ker}(\lambda I - K)$ is finite dimensional $\operatorname{ran}(\lambda I - K)$ is closed Now, if $\mathfrak{M}\subseteq\mathfrak{X}$ is a finite-dimensional subspace, then $\mathfrak{M}$ is complemented in $\mathfrak{X}$ , so there exists a closed subspace $\mathfrak{N}\subseteq\mathfrak{X}$ such that $\mathfrak{X} = \mathfrak{M}\oplus\mathfrak{N}$ . Let $\mathfrak{R}$ be $\operatorname{ker}(\lambda I - K)$ 's complement in $\mathfrak{X}$ , and define $$ T : \mathfrak{R}\to \mathfrak{X},\qquad y\mapsto(\lambda I - K)y $$ or in other words $T = (\lambda I - K)|_{\mathfrak{R}}$ . It's easy to see that $T$ is injective, and surjective onto it's range, which is closed. Thus $T$ induces an isomorphism $\mathfrak{R}\cong\operatorname{ran}(\lambda I - K)$ , and so $$ \mathfrak{X}\cong\operatorname{ker}(\lambda I - K)\oplus\operatorname{ran}(\lambda I - K) $$ From this, hypothetically we should be able to obtain the Fredholm alternative : that $\lambda I - K$ is injective if and only if it is surjective. Actually, I suppose all this proves is that if $\lambda I - K$ is injective, then it must be surjective. However, it's totally possible that $\mathfrak{X}$ is isomorphic to the direct sum of the finite subspace $\operatorname{ker}(\lambda I - K)$ and the isomorphic copy of $\mathfrak{X}$ that is $\operatorname{ran}(\lambda I - K)$ , so we can't be sure that $\lambda I - K$ is injective. However, we can derive an additional factoid: $$ \dim(\mathfrak{X}/\operatorname{ran}(\lambda I - K)) = \dim\operatorname{ker}(\lambda I - K^*) $$ where $K^*\in\mathcal{K}(\mathfrak{X}^*)$ denotes the Banach space adjoint (which is also compact). I forget if this is true or not, but I seem to recall that if an operator is surjective, then it's adjoint is injective, so this would be enough to prove the other direction of the Fredholm alternative (assuming such a result exists, which I'll have to verify). Most Banach space theory texts go through the motion of showing that $\lambda I - K$ has both finite ascent and finite descent (the towers $\{\operatorname{ran}(\lambda I - K)^n\}_{n\in\mathbb{N}}$ and $\{\operatorname{ker}(\lambda I - K)^n\}_{n\in\mathbb{N}}$ both stabilize), and from this derive the Fredholm alternative. Question: is this extra rigmarole about ascent/descent necessary for deriving the Fredholm alternative? Is there anything wrong with my deduction above, other than the missing ""fact"" that a surjective operator has injective adjoint? Edit: Unless I'm just having an off day (I'm prone to those), it seems trivially true that if $T\in\mathcal{B}(\mathfrak{X}, \mathfrak{Y})$ is surjective then $T^*\in\mathcal{B}(\mathfrak{Y}^*, \mathfrak{X}^*)$ is injective. Indeed, supposing $T^*f = T^*g$ , then $\forall x\in\mathfrak{X}$ , $f(Tx) = g(Tx)$ , but since $Tx$ ranges over $\mathfrak{Y}$ , this implies $f(y) = g(y)$ for all $y\in\mathfrak{Y}$ , so $f = g$ . Thus, don't we have the Fredholm alternative?","Let be a Banach space, and be a compact operator. Then given , we can show that is finite dimensional is closed Now, if is a finite-dimensional subspace, then is complemented in , so there exists a closed subspace such that . Let be 's complement in , and define or in other words . It's easy to see that is injective, and surjective onto it's range, which is closed. Thus induces an isomorphism , and so From this, hypothetically we should be able to obtain the Fredholm alternative : that is injective if and only if it is surjective. Actually, I suppose all this proves is that if is injective, then it must be surjective. However, it's totally possible that is isomorphic to the direct sum of the finite subspace and the isomorphic copy of that is , so we can't be sure that is injective. However, we can derive an additional factoid: where denotes the Banach space adjoint (which is also compact). I forget if this is true or not, but I seem to recall that if an operator is surjective, then it's adjoint is injective, so this would be enough to prove the other direction of the Fredholm alternative (assuming such a result exists, which I'll have to verify). Most Banach space theory texts go through the motion of showing that has both finite ascent and finite descent (the towers and both stabilize), and from this derive the Fredholm alternative. Question: is this extra rigmarole about ascent/descent necessary for deriving the Fredholm alternative? Is there anything wrong with my deduction above, other than the missing ""fact"" that a surjective operator has injective adjoint? Edit: Unless I'm just having an off day (I'm prone to those), it seems trivially true that if is surjective then is injective. Indeed, supposing , then , , but since ranges over , this implies for all , so . Thus, don't we have the Fredholm alternative?","\mathfrak{X} K\in \mathcal{K}(\mathfrak{X}) \lambda\in\mathbb{C}\backslash\{0\} \operatorname{ker}(\lambda I - K) \operatorname{ran}(\lambda I - K) \mathfrak{M}\subseteq\mathfrak{X} \mathfrak{M} \mathfrak{X} \mathfrak{N}\subseteq\mathfrak{X} \mathfrak{X} = \mathfrak{M}\oplus\mathfrak{N} \mathfrak{R} \operatorname{ker}(\lambda I - K) \mathfrak{X} 
T : \mathfrak{R}\to \mathfrak{X},\qquad y\mapsto(\lambda I - K)y
 T = (\lambda I - K)|_{\mathfrak{R}} T T \mathfrak{R}\cong\operatorname{ran}(\lambda I - K) 
\mathfrak{X}\cong\operatorname{ker}(\lambda I - K)\oplus\operatorname{ran}(\lambda I - K)
 \lambda I - K \lambda I - K \mathfrak{X} \operatorname{ker}(\lambda I - K) \mathfrak{X} \operatorname{ran}(\lambda I - K) \lambda I - K 
\dim(\mathfrak{X}/\operatorname{ran}(\lambda I - K)) = \dim\operatorname{ker}(\lambda I - K^*)
 K^*\in\mathcal{K}(\mathfrak{X}^*) \lambda I - K \{\operatorname{ran}(\lambda I - K)^n\}_{n\in\mathbb{N}} \{\operatorname{ker}(\lambda I - K)^n\}_{n\in\mathbb{N}} T\in\mathcal{B}(\mathfrak{X}, \mathfrak{Y}) T^*\in\mathcal{B}(\mathfrak{Y}^*, \mathfrak{X}^*) T^*f = T^*g \forall x\in\mathfrak{X} f(Tx) = g(Tx) Tx \mathfrak{Y} f(y) = g(y) y\in\mathfrak{Y} f = g","['functional-analysis', 'banach-spaces']"
26,Inner product space that is not Hilbert - clarifications on the solution,Inner product space that is not Hilbert - clarifications on the solution,,"CONTEXT I am self studying Hilbert Space theory, and since I am still moving the first steps into the field, I am not quite sure of the conclusions I draw  while working on the exercises. The question is related to Exercise 4, Chapter 3 of Debnath and Mikusinski's ""Introduction to Hilbert Spaces"". STATEMENT OF THE PROBLEM Let $\mathcal C^1([a,b])$ be the set of all continuously differentiable complex-valued functions on $[a,b]$ and $\mathcal F = \{f \in \mathcal C^1([a,b]): \ f(a) = 0\}.$ I already showed that $\mathcal F$ is an inner product space with inner product defined by $$ \langle f,g \rangle = \int_a^b f'(x) \overline{g'(x)} dx.\tag{1}\label{1}$$ Now I need to show that this is not a Hilbert space . In order to do so, I considered, in the interval $[0,1]$ , the sequence of functions $$f_n(x) = \int_0^x g_n(t) dt,$$ where, in turn, for $n=1,2,\dots$ , $$g_n(x) = \begin{cases} 0 & \left(x \leq \frac12\right)\\ 2n\left(x-\frac12\right) & \left(\frac12 < x \leq \frac12 + \frac1{2n}\right)\\ 1 & \left(x > \frac12 + \frac1{2n}\right).\end{cases}$$ I want to show that this is a Cauchy sequence that does not converge to any function in $\mathcal F$ . MY QUESTIONS In order to show that $(f_n)$ is a Cauchy sequence, I explicitely determined, for $m>n>0$ , $$||f_m(x)-f_n(x)||^2 = \int_0^1 |g_m(x) - g_n(x)|^2 dx = \frac{(m-n)^2}{6m^2n}< \frac1{6n}.$$ But I have a feeling this is not really necessary. Can I use any convergence theorem, instead, even if I am not working in $L^1([0,1])$ ? Clearly $(f_n(x))$ converges pointwise to $$f(x) = \begin{cases}0 & \left(x \leq \frac12\right)\\ x-\frac12 & \left(x > \frac12\right),\end{cases}$$ which is not in $\mathcal C^1([0,1])$ and thus not in $\mathcal F$ . Is this sufficient to conclude that the sequence $(f_n)$ does not converge in $\mathcal F$ with the norm induced by \eqref{1}?","CONTEXT I am self studying Hilbert Space theory, and since I am still moving the first steps into the field, I am not quite sure of the conclusions I draw  while working on the exercises. The question is related to Exercise 4, Chapter 3 of Debnath and Mikusinski's ""Introduction to Hilbert Spaces"". STATEMENT OF THE PROBLEM Let be the set of all continuously differentiable complex-valued functions on and I already showed that is an inner product space with inner product defined by Now I need to show that this is not a Hilbert space . In order to do so, I considered, in the interval , the sequence of functions where, in turn, for , I want to show that this is a Cauchy sequence that does not converge to any function in . MY QUESTIONS In order to show that is a Cauchy sequence, I explicitely determined, for , But I have a feeling this is not really necessary. Can I use any convergence theorem, instead, even if I am not working in ? Clearly converges pointwise to which is not in and thus not in . Is this sufficient to conclude that the sequence does not converge in with the norm induced by \eqref{1}?","\mathcal C^1([a,b]) [a,b] \mathcal F = \{f \in \mathcal C^1([a,b]): \ f(a) = 0\}. \mathcal F  \langle f,g \rangle = \int_a^b f'(x) \overline{g'(x)} dx.\tag{1}\label{1} [0,1] f_n(x) = \int_0^x g_n(t) dt, n=1,2,\dots g_n(x) = \begin{cases}
0 & \left(x \leq \frac12\right)\\
2n\left(x-\frac12\right) & \left(\frac12 < x \leq \frac12 + \frac1{2n}\right)\\
1 & \left(x > \frac12 + \frac1{2n}\right).\end{cases} \mathcal F (f_n) m>n>0 ||f_m(x)-f_n(x)||^2 = \int_0^1 |g_m(x) - g_n(x)|^2 dx = \frac{(m-n)^2}{6m^2n}< \frac1{6n}. L^1([0,1]) (f_n(x)) f(x) = \begin{cases}0 & \left(x \leq \frac12\right)\\ x-\frac12 & \left(x > \frac12\right),\end{cases} \mathcal C^1([0,1]) \mathcal F (f_n) \mathcal F","['real-analysis', 'functional-analysis', 'solution-verification', 'hilbert-spaces', 'self-learning']"
27,How to show operator is compact [duplicate],How to show operator is compact [duplicate],,"This question already has an answer here : Show that $T$ is a compact operator (1 answer) Closed 2 years ago . Currently I'm self studying functional analysis, namely compact operators. In the text, the author gives the following example: Example 1 : Let $C_1$ and $C_2$ be positive constants and let $$ M:=\left\{x(t)\in C[a,b]:|x(t)|<C_1\text{ and }|x'(t)|<C_2\right\}.\tag{1} $$ Then $M$ is relatively compact. I completely understand Example 1 , it makes use of Arzela's theorem. Then the author gives the following example: Example 2 : The operator $$ Ax:=\int_0^tx(\tau)d\tau.\tag{2} $$ on $C[0,1]$ is a compact operator (use the previous example). My question is fairly straightforward: using Example 1 , how is this operator compact on $C[0,1]$ ? As of now I have the following two definitions of compact operators: Definition 1 : A linear operator $A\colon X\to Y$ is called a compact operator if and only if for every bounded sequence $x_n\in X$ the sequence $Ax_n$ has a Cauchy subsequence. Definition 2 : An linear operator $A\colon X\to Y$ is compact if and only if the image of the unit ball of $X$ is a relatively compact set in $Y$ . Just going off terminology, I would guess that Definition 2 should be used to solve Exercise 2 , but I'm not seeing it through all the way. Any help is appreciated!","This question already has an answer here : Show that $T$ is a compact operator (1 answer) Closed 2 years ago . Currently I'm self studying functional analysis, namely compact operators. In the text, the author gives the following example: Example 1 : Let and be positive constants and let Then is relatively compact. I completely understand Example 1 , it makes use of Arzela's theorem. Then the author gives the following example: Example 2 : The operator on is a compact operator (use the previous example). My question is fairly straightforward: using Example 1 , how is this operator compact on ? As of now I have the following two definitions of compact operators: Definition 1 : A linear operator is called a compact operator if and only if for every bounded sequence the sequence has a Cauchy subsequence. Definition 2 : An linear operator is compact if and only if the image of the unit ball of is a relatively compact set in . Just going off terminology, I would guess that Definition 2 should be used to solve Exercise 2 , but I'm not seeing it through all the way. Any help is appreciated!","C_1 C_2 
M:=\left\{x(t)\in C[a,b]:|x(t)|<C_1\text{ and }|x'(t)|<C_2\right\}.\tag{1}
 M 
Ax:=\int_0^tx(\tau)d\tau.\tag{2}
 C[0,1] C[0,1] A\colon X\to Y x_n\in X Ax_n A\colon X\to Y X Y",['functional-analysis']
28,Confusion over Continuous Functional Calculus,Confusion over Continuous Functional Calculus,,"I have the following problem:  As far as I understand, the continuous functional calculus gives an isomorphism from the continuous functions over the spectrum of a normal element to the $C^*$ -algebra that the normal element and the unit generate. More specifically, if $A$ is a unital $C^*$ -algebra and $a\in A$ is normal, then we have a star-isomorphism $\Gamma_A:C(\sigma_A(a))\cong C^*(a,1_A)$ so that $\Gamma_A(1)=1_A$ and $\Gamma_A(z)=a$ , where $z$ is the identity map. Suppose now that $B\subset A$ is another unital $C^*$ -algebra (with unit $1_B$ ) that contains the above element $a$ . Then we get ""another"" continuous functional calculus, a star isomorphism $\Gamma_B:C(\sigma_B(a))\cong C^*(a,1_B)$ with $\Gamma_B(1)=1_B$ and $\Gamma_B(z)=a$ . By spectral invariance, we have that $\sigma_A(a)\cup\{0\}=\sigma_B(a)\cup\{0\}$ . By the above, we have that if $p$ is a polynomial in $z,\bar{z}$ with constant term $0$ , then $\Gamma_A(p)=\Gamma_B(p)$ . Now if $f$ is a continuous function defined on $\sigma_A(a)\cup\{0\}$ satisfying $f(0)=0$ , then by Weierstrass approximation we can find a sequence of polynomials $(p_n)$ in $z,\bar{z}$ such that $p_n\to f$ uniformly on $\sigma_A(a)\cup\{0\}$ . Thus $\Gamma_A(f)=\Gamma_B(f)$ . In other words, the continuous functional calculus when performed on functions that fix the origin is independent of the $C^*$ -subalgebra we are working in. Is this correct? If not, what is wrong? If it is correct, please look at the following. I feel very awkward about this result: Suppose that we have $C^*$ -algebras $B\subset A$ and suppose that $B$ is unital with unit $1_B$ . Now let $b\in B$ be a positive element with $\varepsilon1_B\leq b$ , for some $\varepsilon>0$ . Then $\sigma_B(b)\subset[\varepsilon,\|b\|]$ , so $b$ is invertible in $B$ , since $0$ is not in the spectrum. Moreover, $\sigma_A(b)\cup\{0\}=\sigma_B(b)\cup\{0\}$ . If $0\not\in\sigma_A(b)$ (which implies that $A$ is unital and that $b$ is invertible in $A$ ) then $\sigma_A(b)=\sigma_B(b)\subset[\varepsilon,\|b\|]$ . We can define $f(t)=1/t$ on $\sigma_A(b)=\sigma_B(b)$ and set $f(0)=0$ . This defines a continuous function on $\sigma_A(b)\cup\{0\}=\sigma_B(b)\cup\{0\}$ and by the above, $\Gamma_A(f)=\Gamma_B(f)$ , i.e. the inverse of $b$ in $B$ is the same as the inverse of $b$ in $A$ . More specifically, $1_B=1_A$ , which seems odd to me. We just proved that: $B\subset A$ is an inclusion of unital $C^*$ -algebras (the units being $1_B$ and $1_A$ respectively) and we have an element $b\in B$ with $\varepsilon1_B\leq b$ and also $b$ is invertible in $A$ . Then $1_B=1_A$ . IF my understanding of the continuous functional calculus is correct, can you give me a more compelling argument to convince me that the reasoning in the above proof is not flawed?","I have the following problem:  As far as I understand, the continuous functional calculus gives an isomorphism from the continuous functions over the spectrum of a normal element to the -algebra that the normal element and the unit generate. More specifically, if is a unital -algebra and is normal, then we have a star-isomorphism so that and , where is the identity map. Suppose now that is another unital -algebra (with unit ) that contains the above element . Then we get ""another"" continuous functional calculus, a star isomorphism with and . By spectral invariance, we have that . By the above, we have that if is a polynomial in with constant term , then . Now if is a continuous function defined on satisfying , then by Weierstrass approximation we can find a sequence of polynomials in such that uniformly on . Thus . In other words, the continuous functional calculus when performed on functions that fix the origin is independent of the -subalgebra we are working in. Is this correct? If not, what is wrong? If it is correct, please look at the following. I feel very awkward about this result: Suppose that we have -algebras and suppose that is unital with unit . Now let be a positive element with , for some . Then , so is invertible in , since is not in the spectrum. Moreover, . If (which implies that is unital and that is invertible in ) then . We can define on and set . This defines a continuous function on and by the above, , i.e. the inverse of in is the same as the inverse of in . More specifically, , which seems odd to me. We just proved that: is an inclusion of unital -algebras (the units being and respectively) and we have an element with and also is invertible in . Then . IF my understanding of the continuous functional calculus is correct, can you give me a more compelling argument to convince me that the reasoning in the above proof is not flawed?","C^* A C^* a\in A \Gamma_A:C(\sigma_A(a))\cong C^*(a,1_A) \Gamma_A(1)=1_A \Gamma_A(z)=a z B\subset A C^* 1_B a \Gamma_B:C(\sigma_B(a))\cong C^*(a,1_B) \Gamma_B(1)=1_B \Gamma_B(z)=a \sigma_A(a)\cup\{0\}=\sigma_B(a)\cup\{0\} p z,\bar{z} 0 \Gamma_A(p)=\Gamma_B(p) f \sigma_A(a)\cup\{0\} f(0)=0 (p_n) z,\bar{z} p_n\to f \sigma_A(a)\cup\{0\} \Gamma_A(f)=\Gamma_B(f) C^* C^* B\subset A B 1_B b\in B \varepsilon1_B\leq b \varepsilon>0 \sigma_B(b)\subset[\varepsilon,\|b\|] b B 0 \sigma_A(b)\cup\{0\}=\sigma_B(b)\cup\{0\} 0\not\in\sigma_A(b) A b A \sigma_A(b)=\sigma_B(b)\subset[\varepsilon,\|b\|] f(t)=1/t \sigma_A(b)=\sigma_B(b) f(0)=0 \sigma_A(b)\cup\{0\}=\sigma_B(b)\cup\{0\} \Gamma_A(f)=\Gamma_B(f) b B b A 1_B=1_A B\subset A C^* 1_B 1_A b\in B \varepsilon1_B\leq b b A 1_B=1_A","['functional-analysis', 'spectral-theory', 'c-star-algebras']"
29,"Show that $W^{s_2, 2}(\mathbb{T}) \hookrightarrow W^{s_1,2} (\mathbb{T})$ is a compact operator",Show that  is a compact operator,"W^{s_2, 2}(\mathbb{T}) \hookrightarrow W^{s_1,2} (\mathbb{T})","How can one prove that for $0 \le s_1 < s_2$ , the embedding map $W^{s_2, 2}(\mathbb{T}) \hookrightarrow W^{s_1,2} (\mathbb{T})$ is a compact operator? My proof Let $f \in W^{s_2,2}(\mathbb{T})$ , then $f \in L^2(\mathbb{T})$ and $\sum_{n \in \mathbb{Z}} (1+ n^2)^{s_2} |\widehat{f}(n)| < \infty$ . Since $s_1 < s_2$ , then we have $$ \sum_{n \in \mathbb{Z}} (1+ n^2)^{s_1} |\widehat{f}(n)| \le \sum_{n \in \mathbb{Z}} (1+ n^2)^{s_2} |\widehat{f}(n)| < \infty.$$ Thus, $f \in W^{s_1,2}(\mathbb{T})$ . Consider the orthonormal basis $\{e_n \}_{n \in \mathbb{Z}}$ for $L^2(\mathbb{T})$ . Let $f \in W^{s_1,2}(\mathbb{T})$ . Since $f = \sum_{j \in \mathbb{Z}} \langle f, e_j \rangle e_j$ , $\sum_{n \in \mathbb{Z}} (1+n^2)^{s_1} \left| \widehat{f}(n) \right|^2<\infty$ , and $\widehat{f}(n) = \langle f, e_n \rangle$ . Then we have $\sum_{n \in \mathbb{Z}} (1+n^2)^{s_1} \left| \widehat{f}(n)  \right|^2  = \sum_{n \in \mathbb{Z}} (1+n^2)^{s_1} \langle f, e_n \rangle^2<\infty.$ Given $\epsilon >0$ , $\exists N >0$ such that $ \left| \sum_{|n| > N+1 } (1 + n^2)^{s_1} \langle f,e_n \rangle \right| < \epsilon$ . Since $(1+n^2)^{s_1}$ is never zero, then $\underset{n \to \infty}{\lim}\langle f,e_n \rangle =0, \forall |n| > N+1$ . Then for every $f \in W^{s_1,2}(\mathbb{T})$ , $f$ can be expressed as a finite dimensional orthonormal bases $\{ e_n\}_{|n| \le N}$ . Namely $f = \sum_{|n| \le \mathbb{Z}} \langle f, e_n \rangle e_n.$ Thus the embedding operator is compact. Added 2- If $m \in \mathbb{N}_0$ and $s  > m + \frac{1}{2}$ , then $W^{s,2}(T) \subset C^n (T) \subset W^{n,2}(T)$ . Where $T=\mathbb{R}/2 \pi \mathbb{Z}$ . Is my proof to (1) is ok?  could help me with the point (2). Edited I am thinking of using this theorem: Let $T \in B(H)$ be a diagonal operator, i.e; $\exists  \{ e_i \}_{i \in I}$ orthonormal basis of $H$ such that $Te_i = \lambda_i e_i$ , $\lambda_i \in \mathbb{C}$ . Then the following conditions are equivalent: 1- $T \in K(H)$ 2- $\lim_{i \to \infty} \lambda_i =0$ , i.e. $\forall \epsilon >0,  \exists F \subset I$ finite subset such that $\forall i \in I \subset F$ , $|\lambda_i|<\epsilon$","How can one prove that for , the embedding map is a compact operator? My proof Let , then and . Since , then we have Thus, . Consider the orthonormal basis for . Let . Since , , and . Then we have Given , such that . Since is never zero, then . Then for every , can be expressed as a finite dimensional orthonormal bases . Namely Thus the embedding operator is compact. Added 2- If and , then . Where . Is my proof to (1) is ok?  could help me with the point (2). Edited I am thinking of using this theorem: Let be a diagonal operator, i.e; orthonormal basis of such that , . Then the following conditions are equivalent: 1- 2- , i.e. finite subset such that ,","0 \le s_1 < s_2 W^{s_2, 2}(\mathbb{T}) \hookrightarrow W^{s_1,2} (\mathbb{T}) f \in W^{s_2,2}(\mathbb{T}) f \in L^2(\mathbb{T}) \sum_{n \in \mathbb{Z}} (1+ n^2)^{s_2} |\widehat{f}(n)| < \infty s_1 < s_2  \sum_{n \in \mathbb{Z}} (1+ n^2)^{s_1} |\widehat{f}(n)| \le \sum_{n \in \mathbb{Z}} (1+ n^2)^{s_2} |\widehat{f}(n)| < \infty. f \in W^{s_1,2}(\mathbb{T}) \{e_n \}_{n \in \mathbb{Z}} L^2(\mathbb{T}) f \in W^{s_1,2}(\mathbb{T}) f = \sum_{j \in \mathbb{Z}} \langle f, e_j \rangle e_j \sum_{n \in \mathbb{Z}} (1+n^2)^{s_1} \left| \widehat{f}(n) \right|^2<\infty \widehat{f}(n) = \langle f, e_n \rangle \sum_{n \in \mathbb{Z}} (1+n^2)^{s_1} \left| \widehat{f}(n) 
\right|^2  = \sum_{n \in \mathbb{Z}} (1+n^2)^{s_1} \langle f, e_n \rangle^2<\infty. \epsilon >0 \exists N >0  \left| \sum_{|n| > N+1 } (1 + n^2)^{s_1} \langle f,e_n \rangle \right| < \epsilon (1+n^2)^{s_1} \underset{n \to \infty}{\lim}\langle f,e_n \rangle =0, \forall |n| > N+1 f \in W^{s_1,2}(\mathbb{T}) f \{ e_n\}_{|n| \le N} f = \sum_{|n| \le \mathbb{Z}} \langle f, e_n \rangle e_n. m \in \mathbb{N}_0 s  > m + \frac{1}{2} W^{s,2}(T) \subset C^n (T) \subset W^{n,2}(T) T=\mathbb{R}/2 \pi \mathbb{Z} T \in B(H) \exists  \{ e_i \}_{i \in I} H Te_i = \lambda_i e_i \lambda_i \in \mathbb{C} T \in K(H) \lim_{i \to \infty} \lambda_i =0 \forall \epsilon >0, 
\exists F \subset I \forall i \in I \subset F |\lambda_i|<\epsilon","['functional-analysis', 'fourier-analysis', 'sobolev-spaces', 'compact-operators']"
30,Finite rank nilpotent operators,Finite rank nilpotent operators,,"Let $H$ be a separable complex Hilbert space Let $\mathcal{F(H)} =\{T \in \mathcal{B(H)}: \text{rank}(T) < \infty \}$ , and $\mathcal{N(H)} = \{ T \in \mathcal{F(H)}: T^k=0 \text{ for some }  k \in \mathbb{N} \}$ Find the norm closure $\overline{\mathcal{N(H)}}$ . Ideas: I know that $\overline{\mathcal{F(H)}} = \mathcal{K(H)}$ , where $\mathcal{K(H)}$ is the set of compact operators. So the closure will be some compact operators. And $\mathcal{N(H)} \subset \mathcal{K(H)} $ . Also, through some research, I've found that the quasinilpotnets are limits of nilpotent. So I'm suspecting the that the norm close of finite rank nilpotents will be compact and quasinilpotents. Any help will be appreciated! Thank you in advance!","Let be a separable complex Hilbert space Let , and Find the norm closure . Ideas: I know that , where is the set of compact operators. So the closure will be some compact operators. And . Also, through some research, I've found that the quasinilpotnets are limits of nilpotent. So I'm suspecting the that the norm close of finite rank nilpotents will be compact and quasinilpotents. Any help will be appreciated! Thank you in advance!",H \mathcal{F(H)} =\{T \in \mathcal{B(H)}: \text{rank}(T) < \infty \} \mathcal{N(H)} = \{ T \in \mathcal{F(H)}: T^k=0 \text{ for some }  k \in \mathbb{N} \} \overline{\mathcal{N(H)}} \overline{\mathcal{F(H)}} = \mathcal{K(H)} \mathcal{K(H)} \mathcal{N(H)} \subset \mathcal{K(H)} ,"['functional-analysis', 'operator-theory', 'operator-algebras', 'compact-operators']"
31,Why is it important that every (infinite) dimensional vector space has a (hamel) basis?,Why is it important that every (infinite) dimensional vector space has a (hamel) basis?,,"An argument often used in favor of the axiom of choice is that it is equivalent to every  infinite dimensional vector space having a hamel basis. However the article on wikipedia says that those basis are usually not very useful when they're uncountable, and that other concepts such as ""orthogonal basis"" are more important in these cases. So why does it matter whether infinite dimensional vector spaces have hamel basis?","An argument often used in favor of the axiom of choice is that it is equivalent to every  infinite dimensional vector space having a hamel basis. However the article on wikipedia says that those basis are usually not very useful when they're uncountable, and that other concepts such as ""orthogonal basis"" are more important in these cases. So why does it matter whether infinite dimensional vector spaces have hamel basis?",,"['functional-analysis', 'soft-question', 'hamel-basis']"
32,An interesting application of the Hahn-Banach Theorem.,An interesting application of the Hahn-Banach Theorem.,,"Let $X$ be a normed space and $x_1,x_2\in X$ nonzero elements. Show that there are functionals $F_1,F_2\in X'$ such that $F_1(x_1)F_2(x_2)=\lVert x_1\rVert \lVert x_2\rVert$ and $\lVert F_1\rVert \lVert x_1\rVert =\lVert F_2\rVert \lVert x_2\rVert$ . My attempt: My idea was to define a functional $f_1:\langle \{x_1\}\rangle\to \mathbb{R}$ , by $f_1(\alpha x_1)=\alpha \lVert x_2\rVert.$ Then, by using Hahn-Banach, I extend $f_1$ to a functional $F_1:X\to \mathbb{R}$ such that $F_1(x_1)=\lVert x_2\rVert$ and $\lVert F_1\rVert=\lVert f_1\rVert=\frac{\lVert x_2\rVert}{\lVert x_1\rVert}$ . After that, I tried to define a functional $F_2:X\to \mathbb{R}$ such that $F_2(x_2)=\lVert x_1\rVert$ and $\lVert F_2\rVert=1$ , but I coundn't do that.","Let be a normed space and nonzero elements. Show that there are functionals such that and . My attempt: My idea was to define a functional , by Then, by using Hahn-Banach, I extend to a functional such that and . After that, I tried to define a functional such that and , but I coundn't do that.","X x_1,x_2\in X F_1,F_2\in X' F_1(x_1)F_2(x_2)=\lVert x_1\rVert \lVert x_2\rVert \lVert F_1\rVert \lVert x_1\rVert =\lVert F_2\rVert \lVert x_2\rVert f_1:\langle \{x_1\}\rangle\to \mathbb{R} f_1(\alpha x_1)=\alpha \lVert x_2\rVert. f_1 F_1:X\to \mathbb{R} F_1(x_1)=\lVert x_2\rVert \lVert F_1\rVert=\lVert f_1\rVert=\frac{\lVert x_2\rVert}{\lVert x_1\rVert} F_2:X\to \mathbb{R} F_2(x_2)=\lVert x_1\rVert \lVert F_2\rVert=1",['functional-analysis']
33,"Does $L_1$ Convergence imply almost everywhere convergence for the Set of all increasing functions on $[0,1]$ to $[0,1]$?",Does  Convergence imply almost everywhere convergence for the Set of all increasing functions on  to ?,"L_1 [0,1] [0,1]","We know that $L_1$ convergence does not imply convergence a.e. in general. However, consider the following set $$S=\{f:[0,1] \rightarrow [0,1]\mid f(x)\geq f(y) \quad \forall x\geq y\}.$$ Take any  sequence $\{f_n\}_1^\infty\subset S$ that is converging to $f$ with respect to $L_1$ norm.  Is it possible that convergence in $L_1$ implies pointwise a.e.  convergence in this case? I just couldn't  find an example to show this is not true.","We know that convergence does not imply convergence a.e. in general. However, consider the following set Take any  sequence that is converging to with respect to norm.  Is it possible that convergence in implies pointwise a.e.  convergence in this case? I just couldn't  find an example to show this is not true.","L_1 S=\{f:[0,1] \rightarrow [0,1]\mid f(x)\geq f(y) \quad \forall x\geq y\}. \{f_n\}_1^\infty\subset S f L_1 L_1","['real-analysis', 'functional-analysis', 'measure-theory']"
34,Compact operators and orthonormal basis for separable Hilbert space,Compact operators and orthonormal basis for separable Hilbert space,,"Is my conjecture true or false?  It seems it may be true based on the given proof. Conjecture: Let $T:H_1\rightarrow H_2$ be a bounded linear operator between Hilbert spaces $H_1$ and $H_2$ .  Assume $H_1$ is separable.  Suppose there exists an orthonormal basis $\{e_j\}$ so that $Te_j\rightarrow 0$ in norm as $j\rightarrow \infty$ .  Then $T$ is compact. Here is my proof: Let $h_k\rightarrow 0$ weakly in $H_1$ as $k\rightarrow \infty$ .  Then write $h_k=\sum_{j=1}^{\infty}\langle h_k, e_j\rangle e_j$ .  And so let $\varepsilon>0$ .  Then there exists $j_{\varepsilon}\in \mathbb{N}$ and $j_{\varepsilon}>1$ so that for all $j\geq j_{\varepsilon}$ , $\|Te_j\|^2<\varepsilon $ .  Now we apply $T$ to the series representation for $h_k$ and split the series. \begin{align} \|Th_k\|^2&< \sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle |^2 \|Te_j\|^2+\varepsilon\sum_{j=j_{\varepsilon}}^{\infty}|\langle h_k, e_j\rangle|^2\\ &<\sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle |^2 \|T\|^2+\varepsilon\sup_{k\in \mathbb{N}}\|h_k\|^2 \end{align} for all $k\in \mathbb{N}$ .  Since $h_k\rightarrow 0$ weakly as $k\rightarrow \infty$ , one can show that $\|h_k\|^2$ is a bounded sequence using the uniform boundedness principle.  Thus it remains to show that $\sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle|^2$ can be made arbitrarily small for $k$ sufficiently large.  Because $h_k$ converges to $0$ weakly, for $\varepsilon>0$ and each $j\in \{1,2,..., j_{\varepsilon}-1\}$ there exists $k_{j,\varepsilon}\in \mathbb{N}$ so that $|\langle h_k, e_j\rangle |^2<\frac{\varepsilon}{j_{\varepsilon}-1}$ for $k\geq k_{j,\varepsilon}$ .  Then for $k\geq k_{\varepsilon}:=\max_{j\in \{1,2,...,j_{\varepsilon}-1\}}\{k_{j,\varepsilon}\}+1$ , we have $\sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle|^2<\varepsilon$ .  This shows that $Th_k$ is strongly convergent to $0$ for any sequence $h_k$ weakly converging to $0$ .  Hence $T$ is compact.","Is my conjecture true or false?  It seems it may be true based on the given proof. Conjecture: Let be a bounded linear operator between Hilbert spaces and .  Assume is separable.  Suppose there exists an orthonormal basis so that in norm as .  Then is compact. Here is my proof: Let weakly in as .  Then write .  And so let .  Then there exists and so that for all , .  Now we apply to the series representation for and split the series. for all .  Since weakly as , one can show that is a bounded sequence using the uniform boundedness principle.  Thus it remains to show that can be made arbitrarily small for sufficiently large.  Because converges to weakly, for and each there exists so that for .  Then for , we have .  This shows that is strongly convergent to for any sequence weakly converging to .  Hence is compact.","T:H_1\rightarrow H_2 H_1 H_2 H_1 \{e_j\} Te_j\rightarrow 0 j\rightarrow \infty T h_k\rightarrow 0 H_1 k\rightarrow \infty h_k=\sum_{j=1}^{\infty}\langle h_k, e_j\rangle e_j \varepsilon>0 j_{\varepsilon}\in \mathbb{N} j_{\varepsilon}>1 j\geq j_{\varepsilon} \|Te_j\|^2<\varepsilon  T h_k \begin{align}
\|Th_k\|^2&< \sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle |^2 \|Te_j\|^2+\varepsilon\sum_{j=j_{\varepsilon}}^{\infty}|\langle h_k, e_j\rangle|^2\\
&<\sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle |^2 \|T\|^2+\varepsilon\sup_{k\in \mathbb{N}}\|h_k\|^2
\end{align} k\in \mathbb{N} h_k\rightarrow 0 k\rightarrow \infty \|h_k\|^2 \sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle|^2 k h_k 0 \varepsilon>0 j\in \{1,2,..., j_{\varepsilon}-1\} k_{j,\varepsilon}\in \mathbb{N} |\langle h_k, e_j\rangle |^2<\frac{\varepsilon}{j_{\varepsilon}-1} k\geq k_{j,\varepsilon} k\geq k_{\varepsilon}:=\max_{j\in \{1,2,...,j_{\varepsilon}-1\}}\{k_{j,\varepsilon}\}+1 \sum_{j=1}^{j_{\varepsilon}-1}|\langle h_k, e_j\rangle|^2<\varepsilon Th_k 0 h_k 0 T","['functional-analysis', 'solution-verification', 'hilbert-spaces', 'compact-operators']"
35,$b^* a^* ab \leq \Vert a\Vert^2 b^* b$ in a $C^*$-algebra.,in a -algebra.,b^* a^* ab \leq \Vert a\Vert^2 b^* b C^*,"Let $A$ be a $C^*$ -algebra and $a,b \in A$ . In a proof I'm reading the following is claimed: $b^* a^* ab \leq \Vert a\Vert^2 b^* b$ . I want to understand this: Here is my reasoning: we view $A \subseteq \tilde{A}$ with $\tilde{A}$ the unitisation of $A$ . Then we know that $a^* a \leq \Vert a^* a \Vert 1$ since this holds in every unital $C^*$ -algebra (by a Gelfand-representation argument). Then $$b^* a^*a b \leq b^* \Vert a^* a \Vert 1 b = \Vert a \Vert ^2 b^* b$$ Is the above correct? I find arguments with unitisations always a bit tricky.",Let be a -algebra and . In a proof I'm reading the following is claimed: . I want to understand this: Here is my reasoning: we view with the unitisation of . Then we know that since this holds in every unital -algebra (by a Gelfand-representation argument). Then Is the above correct? I find arguments with unitisations always a bit tricky.,"A C^* a,b \in A b^* a^* ab \leq \Vert a\Vert^2 b^* b A \subseteq \tilde{A} \tilde{A} A a^* a \leq \Vert a^* a \Vert 1 C^* b^* a^*a b \leq b^* \Vert a^* a \Vert 1 b = \Vert a \Vert ^2 b^* b",['functional-analysis']
36,$q-p$ is a projection when $pq = p$,is a projection when,q-p pq = p,"Consider the following theorem in the book "" $C^*$ -algebras and operator theory"" written by Murphy. Questions : (1) Is the theorem talking about orthogonal projections? (as defined in the text above)? Or simply projections? (2) How to prove $(2) \implies (6)?$ I assume that the theorem talks about orthogonal projections, and then I have difficulties. I can prove that $(q-p)^2 = q-p$ but I do not succeed in proving that $q-p$ is orthogonal (when $p,q$ are).","Consider the following theorem in the book "" -algebras and operator theory"" written by Murphy. Questions : (1) Is the theorem talking about orthogonal projections? (as defined in the text above)? Or simply projections? (2) How to prove I assume that the theorem talks about orthogonal projections, and then I have difficulties. I can prove that but I do not succeed in proving that is orthogonal (when are).","C^* (2) \implies (6)? (q-p)^2 = q-p q-p p,q","['functional-analysis', 'operator-theory']"
37,Understanding the tensor product of functions/maps,Understanding the tensor product of functions/maps,,"Let $K^A = \{f \,|\, f\colon A \longrightarrow K\}$ be the set of functions from $A$ (some arbitrary set) to $K$ (a field, I guess, I want to be able to call $K^A$ a $K$ -vector space). Given some other set $A'$ I'd like to know when can we say $$K^A\otimes K^{A'} \subseteq K^{A\times A'}$$ and when can we say they're equal, or when is this true for subalgebras (like $C^\infty(A)$ , $L^2_\mu(A)$ or $A^* = \mathrm{Hom}(A;K)$ , for instance, depending on the structure $A$ has). The tensor product of functions would be define so that $$(f\otimes g)(x,y) = f(x)g(y).$$ I tried doing some research and piecing together what I've learnt so far. Most resources don't talk about purely algebraic vector spaces, though, and I don't know much about Banach spaces, functional analysis or real-variable analysis and it's being a little hard. For the case of linear forms (so $A,A'$ are $K$ -vector spaces) it is true that their tensor product yields a ""bilinear form"" $A\times A'\longrightarrow K$ , so $A^*\otimes A'^* \equiv \mathrm{Bil}(A,A';K)$ . It can't be true in general, because rank-1 elements of the tensor product correspond to (product-wise) separable functions and not every function is a linear combination of separable functions. For example, the function $\delta\colon \mathbb{R}\times\mathbb{R} \longrightarrow \mathbb{R}$ defined to be $0$ everywhere except $1$ wherever $x = y$ is not a linear combination of separable functions. For $L^2(A)$ , at least when $A\subseteq \mathbb{R}^n,A'\subseteq\mathbb{R}^m$ with the Lebesgue measure, it isn't true that $$L^2(A)\otimes L^2(A') = L^2(A\times A')$$ but it is true if we use the ""Hilbert"" tensor product (the closure of the usual tensor product with respect to the topology induced by the metric). This is because the topology of the Hilbert space allows for ""infinite linear combinations"" to make sense whenever they're convergent. I know this question might be too broad (sorry!), but I'm sure there's some concept to know or reference to read from which I could learn more about this.","Let be the set of functions from (some arbitrary set) to (a field, I guess, I want to be able to call a -vector space). Given some other set I'd like to know when can we say and when can we say they're equal, or when is this true for subalgebras (like , or , for instance, depending on the structure has). The tensor product of functions would be define so that I tried doing some research and piecing together what I've learnt so far. Most resources don't talk about purely algebraic vector spaces, though, and I don't know much about Banach spaces, functional analysis or real-variable analysis and it's being a little hard. For the case of linear forms (so are -vector spaces) it is true that their tensor product yields a ""bilinear form"" , so . It can't be true in general, because rank-1 elements of the tensor product correspond to (product-wise) separable functions and not every function is a linear combination of separable functions. For example, the function defined to be everywhere except wherever is not a linear combination of separable functions. For , at least when with the Lebesgue measure, it isn't true that but it is true if we use the ""Hilbert"" tensor product (the closure of the usual tensor product with respect to the topology induced by the metric). This is because the topology of the Hilbert space allows for ""infinite linear combinations"" to make sense whenever they're convergent. I know this question might be too broad (sorry!), but I'm sure there's some concept to know or reference to read from which I could learn more about this.","K^A = \{f \,|\, f\colon A \longrightarrow K\} A K K^A K A' K^A\otimes K^{A'} \subseteq K^{A\times A'} C^\infty(A) L^2_\mu(A) A^* = \mathrm{Hom}(A;K) A (f\otimes g)(x,y) = f(x)g(y). A,A' K A\times A'\longrightarrow K A^*\otimes A'^* \equiv \mathrm{Bil}(A,A';K) \delta\colon \mathbb{R}\times\mathbb{R} \longrightarrow \mathbb{R} 0 1 x = y L^2(A) A\subseteq \mathbb{R}^n,A'\subseteq\mathbb{R}^m L^2(A)\otimes L^2(A') = L^2(A\times A')","['functional-analysis', 'tensor-products', 'topological-vector-spaces', 'multilinear-algebra']"
38,Interchanging an integrand and a measure,Interchanging an integrand and a measure,,"Suppose that $f$ and $g$ are continuous functions on a compact set $K$ and $\mu$ is a (complex) measure. How does the equality $$\int_K f\ \mathrm dg \cdot \mu = \int_K fg\ \mathrm d \mu$$ can be justified, i.e., what does "" $\cdot$ "" mean here? I stumbled upon this issue when studying the proof of the auxiliary result d) here . What I already found is that it is possible to multiply a function with a measure, as explained in this question. Am I right that the above equality is a consequence of this?","Suppose that and are continuous functions on a compact set and is a (complex) measure. How does the equality can be justified, i.e., what does "" "" mean here? I stumbled upon this issue when studying the proof of the auxiliary result d) here . What I already found is that it is possible to multiply a function with a measure, as explained in this question. Am I right that the above equality is a consequence of this?",f g K \mu \int_K f\ \mathrm dg \cdot \mu = \int_K fg\ \mathrm d \mu \cdot,"['real-analysis', 'complex-analysis', 'functional-analysis', 'measure-theory', 'lebesgue-integral']"
39,invariance of a topological vector space under a semigroup,invariance of a topological vector space under a semigroup,,"Let $H$ be a Hilbert space and suppose that the densely defined linear operator $L:D(L) \subseteq H \to H$ is the generator of a $C_0$ semigroup $e^{Lt}:H \to H$ . Suppose further that $S \subseteq D(L)$ is a dense topological vector space such that $L$ maps $S$ continuously into itself. Is it true that if one takes $h \in S$ , then $e^{Lt}h \in S$ for all $t > 0$ ? A concrete version of the question would be something like: Does the heat semigroup map the Schwarz space into itself?","Let be a Hilbert space and suppose that the densely defined linear operator is the generator of a semigroup . Suppose further that is a dense topological vector space such that maps continuously into itself. Is it true that if one takes , then for all ? A concrete version of the question would be something like: Does the heat semigroup map the Schwarz space into itself?",H L:D(L) \subseteq H \to H C_0 e^{Lt}:H \to H S \subseteq D(L) L S h \in S e^{Lt}h \in S t > 0,"['functional-analysis', 'semigroup-of-operators', 'linear-pde']"
40,Linear Isometry on Positive Elements of a $C^{\ast}$-Algebra,Linear Isometry on Positive Elements of a -Algebra,C^{\ast},"I am trying to complete problem 2.5 from Murphy's $\textit{$C^{\ast}$-Algebras and Operator Theory}$ , which states the following Let $\varphi : A \rightarrow B$ be a linear isometry between unital $C^{\ast}$ -Algebras $A$ and $B$ such that $\varphi(a^\ast) = \varphi(a)^\ast$ ( $a \in A$ ) and $\varphi(1) = 1$ . Show that $\varphi(A^+) \subseteq B^+$ . Here, the notation $A^+$ denotes the set of positive elements of $A$ . I have made some progress on this problem. Let $a \in A^+$ . Evidently, $\varphi(a)$ is hermitian, so it suffices to show that every element of $\sigma(\varphi(a))$ is a positive real number. To this end, let $\lambda \in \mathbb{C}$ . Then, $$\varphi(a) - \lambda 1 \not \in \text{Inv}(B) \text{ iff } \varphi(a - \lambda 1) \not \in \text{Inv}(B).$$ My goal is to eventually use positivity of $a$ to show that $\lambda \in \mathbb{R}_{\geq 0}$ . I also haven't used the isometry property of $\varphi$ , and I'm unsure how to relate this property to some fact about spectrum to get what I want. Could someone point me in the right direction?","I am trying to complete problem 2.5 from Murphy's , which states the following Let be a linear isometry between unital -Algebras and such that ( ) and . Show that . Here, the notation denotes the set of positive elements of . I have made some progress on this problem. Let . Evidently, is hermitian, so it suffices to show that every element of is a positive real number. To this end, let . Then, My goal is to eventually use positivity of to show that . I also haven't used the isometry property of , and I'm unsure how to relate this property to some fact about spectrum to get what I want. Could someone point me in the right direction?",\textit{C^{\ast}-Algebras and Operator Theory} \varphi : A \rightarrow B C^{\ast} A B \varphi(a^\ast) = \varphi(a)^\ast a \in A \varphi(1) = 1 \varphi(A^+) \subseteq B^+ A^+ A a \in A^+ \varphi(a) \sigma(\varphi(a)) \lambda \in \mathbb{C} \varphi(a) - \lambda 1 \not \in \text{Inv}(B) \text{ iff } \varphi(a - \lambda 1) \not \in \text{Inv}(B). a \lambda \in \mathbb{R}_{\geq 0} \varphi,"['functional-analysis', 'operator-theory', 'spectral-theory', 'c-star-algebras']"
41,Understanding a Sobolev Embedding Theorem,Understanding a Sobolev Embedding Theorem,,"In my adv. Analysis course, we have studied the following Sobolev Embedding Theorem: Let $m\in\mathbb{N}$ and $s>m+d/2$ . Then $$H^s(\mathbb{R}^d)\hookrightarrow C_0^m(\mathbb{R}^d)$$ That is: $H^s(\mathbb{R}^d)$ embeds into $C_0^m(\mathbb{R}^d)$ The proof we've studied basically starts by noticing that the Schwartz space $\mathcal{S}(\mathbb{R}^d)$ is dense in $H^s$ , and then it goes on proving that the inclusion map $$i:H^s\overset{\mathrm{dense}}{\supseteq}\mathcal{S} \longrightarrow C_0^m$$ is continuous.  So by existence (and uniqueness) of an extended (injective) linear bounded operator, we have in fact an embedding from the Sobolev Space $H^s(\mathbb{R}^d)$ into $C_0^m(\mathbb{R}^d)$ . But I'm asking myself the nature of such extended embedding, more precisely: Does it mean that, under the hypotheses of the theorem, the Sobolev space $H^s$ is a ""subset"" of $C_0^m$ ? In the sense that every function in $H^s$ has a representative (of the a.e. equivalence class) in $C_0^m$ ? In other words, does the extension of the inclusion behaves as an inclusion? Thanks","In my adv. Analysis course, we have studied the following Sobolev Embedding Theorem: Let and . Then That is: embeds into The proof we've studied basically starts by noticing that the Schwartz space is dense in , and then it goes on proving that the inclusion map is continuous.  So by existence (and uniqueness) of an extended (injective) linear bounded operator, we have in fact an embedding from the Sobolev Space into . But I'm asking myself the nature of such extended embedding, more precisely: Does it mean that, under the hypotheses of the theorem, the Sobolev space is a ""subset"" of ? In the sense that every function in has a representative (of the a.e. equivalence class) in ? In other words, does the extension of the inclusion behaves as an inclusion? Thanks",m\in\mathbb{N} s>m+d/2 H^s(\mathbb{R}^d)\hookrightarrow C_0^m(\mathbb{R}^d) H^s(\mathbb{R}^d) C_0^m(\mathbb{R}^d) \mathcal{S}(\mathbb{R}^d) H^s i:H^s\overset{\mathrm{dense}}{\supseteq}\mathcal{S} \longrightarrow C_0^m H^s(\mathbb{R}^d) C_0^m(\mathbb{R}^d) H^s C_0^m H^s C_0^m,"['functional-analysis', 'sobolev-spaces']"
42,The composition space of $L^p$ spaces is complete.,The composition space of  spaces is complete.,L^p,"Here is a homework problem from real analysis class. We take as our underlying space as the product space $\{(x,t)\}=\mathbb R^d\times \mathbb R$ , with the product measure $dxdt$ , where $dx$ and $dt$ are Lebesgue measures on $\mathbb R^d$ and $\mathbb R$ , repectively. We define $L_t^r(L_x^p)=L^{p,r}$ with $1\leq p\leq\infty$ , $1\leq r\leq\infty$ , to be the space of equivalence class of jointly measurable functions $f(x,t)$ for which the norm $$\|f\|_{L^{p,r}}=\left(\int_\mathbb R\left(\int_{\mathbb R^d} |f(x,t)|^p\,dx\right)^{\frac rp}\right)^{\frac1r}$$ is finite when $p<\infty$ and $r<\infty$ and an obvious variant when $p=\infty$ and $r=\infty$ . What I need to do is to verify that $L^{p,r}$ with this norm is complete and hence is a Banach space. My attempt: Suppose $p<\infty$ and $r<\infty$ . Suppose $\{f_n(x,t)\}_1^\infty$ is a Cauchy sequence in $L^{p,r}$ . Let $g_n(t)=\|f_n(\cdot,t)\|_{L_x^p}$ for all $n\geq 1$ then $\{g_n\}_1^\infty\subset L_t^r$ and by Minkowski's inequality \begin{align*} \|g_n-g_m\|_{L_t^r}&=\left(\int_\mathbb R\left|\|f_n(\cdot,t)\|_{L_x^p}-\|f_m(\cdot,t)\|_{L_x^p}\right|^r\right)^{\frac1r}\\ &\leq \left(\int_\mathbb R\left|\|f_n(\cdot,t)-f_m(\cdot,t)\|_{L_x^p}\right|^r\right)^{\frac1r}\\ &=\|f_n-f_m\|_{L^{p,r}}, \end{align*} $\{g_n(t)\}_1^\infty$ is a Cauchy sequence in $L_t^r$ and thus there is $g(t)\in L_t^r$ such that $g_n\to g$ in $L_t^r$ . But how can we find the $L^{p,r}$ limit of $f_n$ from this? Another thought: I want to establish a quasi-Chebyshev's inequality under this norm and then we can deduce that $\{f_n\}$ is Cauchy in measure from the assumption that it is Cauchy in $L^{p,r}$ , and then find an a.s.-convergent subsequence of $\{f_n\}$ and go on from here. But I failed to establish the desired inequality. Any help will be appreciated.","Here is a homework problem from real analysis class. We take as our underlying space as the product space , with the product measure , where and are Lebesgue measures on and , repectively. We define with , , to be the space of equivalence class of jointly measurable functions for which the norm is finite when and and an obvious variant when and . What I need to do is to verify that with this norm is complete and hence is a Banach space. My attempt: Suppose and . Suppose is a Cauchy sequence in . Let for all then and by Minkowski's inequality is a Cauchy sequence in and thus there is such that in . But how can we find the limit of from this? Another thought: I want to establish a quasi-Chebyshev's inequality under this norm and then we can deduce that is Cauchy in measure from the assumption that it is Cauchy in , and then find an a.s.-convergent subsequence of and go on from here. But I failed to establish the desired inequality. Any help will be appreciated.","\{(x,t)\}=\mathbb R^d\times \mathbb R dxdt dx dt \mathbb R^d \mathbb R L_t^r(L_x^p)=L^{p,r} 1\leq p\leq\infty 1\leq r\leq\infty f(x,t) \|f\|_{L^{p,r}}=\left(\int_\mathbb R\left(\int_{\mathbb R^d} |f(x,t)|^p\,dx\right)^{\frac rp}\right)^{\frac1r} p<\infty r<\infty p=\infty r=\infty L^{p,r} p<\infty r<\infty \{f_n(x,t)\}_1^\infty L^{p,r} g_n(t)=\|f_n(\cdot,t)\|_{L_x^p} n\geq 1 \{g_n\}_1^\infty\subset L_t^r \begin{align*}
\|g_n-g_m\|_{L_t^r}&=\left(\int_\mathbb R\left|\|f_n(\cdot,t)\|_{L_x^p}-\|f_m(\cdot,t)\|_{L_x^p}\right|^r\right)^{\frac1r}\\
&\leq \left(\int_\mathbb R\left|\|f_n(\cdot,t)-f_m(\cdot,t)\|_{L_x^p}\right|^r\right)^{\frac1r}\\
&=\|f_n-f_m\|_{L^{p,r}},
\end{align*} \{g_n(t)\}_1^\infty L_t^r g(t)\in L_t^r g_n\to g L_t^r L^{p,r} f_n \{f_n\} L^{p,r} \{f_n\}","['real-analysis', 'functional-analysis', 'lp-spaces']"
43,Closed doesn't imply complete,Closed doesn't imply complete,,"Let $X$ be a norm  linear space.  If $X$ is banach space then subspace $Y$ is closed iff $Y$ is complete. But if $X$ is not banach space then $Y$ is closed need not imply $Y$ is complete. Can u give me such an example? I took a non-banach space $C[0, 1]$ with integration norm. But I am unable to find such an example here.",Let be a norm  linear space.  If is banach space then subspace is closed iff is complete. But if is not banach space then is closed need not imply is complete. Can u give me such an example? I took a non-banach space with integration norm. But I am unable to find such an example here.,"X X Y Y X Y Y C[0, 1]",['functional-analysis']
44,Embedding a Hilbert space into the bounded operators on a Hilbert space,Embedding a Hilbert space into the bounded operators on a Hilbert space,,Consider a norm-decreasing linear map from a Hilbert space $H$ to the bounded linear operators $B(H')$ on another Hilbert space $H'$ . Can it happen that the image of $H$ in $B(H')$ is not closed - can somebody please give an example.,Consider a norm-decreasing linear map from a Hilbert space to the bounded linear operators on another Hilbert space . Can it happen that the image of in is not closed - can somebody please give an example.,H B(H') H' H B(H'),"['functional-analysis', 'hilbert-spaces', 'operator-algebras', 'c-star-algebras']"
45,Intersection of all Sobolev spaces with negative order,Intersection of all Sobolev spaces with negative order,,"Call $H^{s}$ the usual $L^2$ -based Sobolev spaces on, say, a closed manifold, for $s \in \mathbb R$ . The intersection $\bigcap _{s<0} H^s $ contains $L^2$ . Is this intersection equal to $L^2$ ? Thank you.","Call the usual -based Sobolev spaces on, say, a closed manifold, for . The intersection contains . Is this intersection equal to ? Thank you.",H^{s} L^2 s \in \mathbb R \bigcap _{s<0} H^s  L^2 L^2,"['functional-analysis', 'sobolev-spaces']"
46,Derivative function continuous iff partial derivatives continuous,Derivative function continuous iff partial derivatives continuous,,"Let $f:\mathbb{R} ^{n}\rightarrow \mathbb{R} ^{m}$ be differentiable. The derivative function $Df:\mathbb{R} ^{n}\rightarrow L\left( \mathbb{R} ^{n},\mathbb{R} ^{m}\right)$ is continuous in respect to the operator norm $\left\| A \right\|_{L\left( \mathbb{R} ^{n},\mathbb{R} ^{m}\right)}:=\sup _{\left\| v\right\| =1}\left\| Av\right\|$ , iff the partial derivatives $\dfrac {\partial f_{i}}{\partial x_{j}}$ are continuous for all $i\in \left\{ 1,\ldots ,m\right\}$ and $j\in \left\{ 1,\ldots ,n\right\}$ . How can I show this?","Let be differentiable. The derivative function is continuous in respect to the operator norm , iff the partial derivatives are continuous for all and . How can I show this?","f:\mathbb{R} ^{n}\rightarrow \mathbb{R} ^{m} Df:\mathbb{R} ^{n}\rightarrow L\left( \mathbb{R} ^{n},\mathbb{R} ^{m}\right) \left\| A \right\|_{L\left( \mathbb{R} ^{n},\mathbb{R} ^{m}\right)}:=\sup _{\left\| v\right\| =1}\left\| Av\right\| \dfrac {\partial f_{i}}{\partial x_{j}} i\in \left\{ 1,\ldots ,m\right\} j\in \left\{ 1,\ldots ,n\right\}","['functional-analysis', 'derivatives', 'continuity']"
47,Converse of Schauder's Theorem about compactness of adjoint operator,Converse of Schauder's Theorem about compactness of adjoint operator,,"It is well known (also known as Schauder's Theorem) that if $X$ and $Y$ are normed spaces and $T:X\to Y$ is a linear and compact operator, then also $T^*:Y^*\to X^*$ is compact. The converse  is true if $Y$ is complete. So the natural question is: Is there an ""easy"" example that shows that we cannot drop the completeness of $Y$ for the converse implication? In order to prove the converse, one usually applies the first implication to the bidual. Thus, a counterexample should be rooted in the subtle difference between ""relatively compact"" and ""totally bounded"", but I cannot wrap my head around it. Any ideas are highly appreciated. Thank you in advance!","It is well known (also known as Schauder's Theorem) that if and are normed spaces and is a linear and compact operator, then also is compact. The converse  is true if is complete. So the natural question is: Is there an ""easy"" example that shows that we cannot drop the completeness of for the converse implication? In order to prove the converse, one usually applies the first implication to the bidual. Thus, a counterexample should be rooted in the subtle difference between ""relatively compact"" and ""totally bounded"", but I cannot wrap my head around it. Any ideas are highly appreciated. Thank you in advance!",X Y T:X\to Y T^*:Y^*\to X^* Y Y,"['functional-analysis', 'banach-spaces', 'compact-operators']"
48,Pointwise multiplication by unbounded function throws us out of $L^2(\mu)$,Pointwise multiplication by unbounded function throws us out of,L^2(\mu),"Let $(X,\mathcal{A},\mu)$ be a $\sigma$ -finite measure space and let $\phi$ be a measurable function that is not an element of $L^\infty(\mu)$ , i.e. $\phi\not\in L^\infty(\mu)$ . I am trying to construct a function $g\in L^2(\mu)$ such that $\phi\cdot g\not\in L^2(\mu)$ . I tried partitioning $X$ in the sets $A_k=\{k\leq|\phi|<k+1\}$ so i could somehow control the behavior of $g$ on those sets relative to $\phi$ , but I needed something more. I considered a partition of $X$ in disjoint sets of finite measure say $(X_n)$ and then I tried to take their co-partition. The problem arising is that I cannot determine which of the sets $A_k\cap X_n$ are of non-zero measure. I am really stuck here. Any ideas?","Let be a -finite measure space and let be a measurable function that is not an element of , i.e. . I am trying to construct a function such that . I tried partitioning in the sets so i could somehow control the behavior of on those sets relative to , but I needed something more. I considered a partition of in disjoint sets of finite measure say and then I tried to take their co-partition. The problem arising is that I cannot determine which of the sets are of non-zero measure. I am really stuck here. Any ideas?","(X,\mathcal{A},\mu) \sigma \phi L^\infty(\mu) \phi\not\in L^\infty(\mu) g\in L^2(\mu) \phi\cdot g\not\in L^2(\mu) X A_k=\{k\leq|\phi|<k+1\} g \phi X (X_n) A_k\cap X_n","['functional-analysis', 'measure-theory', 'lp-spaces']"
49,Are $c_0$ and $c$ duals of some spaces?,Are  and  duals of some spaces?,c_0 c,"The (continuous) dual of a normed vector space is always a Banach space, but the converse is not true.  That is, not all Banach spaces are isomorphic to the dual space of some normed vector space.  For instance $L^1$ is not isomorphic to any dual space. My question is, are the sequence spaces $c_0$ and $c$ isomorphic to the duals of any spaces?","The (continuous) dual of a normed vector space is always a Banach space, but the converse is not true.  That is, not all Banach spaces are isomorphic to the dual space of some normed vector space.  For instance is not isomorphic to any dual space. My question is, are the sequence spaces and isomorphic to the duals of any spaces?",L^1 c_0 c,"['functional-analysis', 'banach-spaces', 'lp-spaces', 'normed-spaces', 'dual-spaces']"
50,Is this multiplication operator bounded for this special norm?,Is this multiplication operator bounded for this special norm?,,"Consider $L_2[0,1]$ with the usual inner product $\langle f, g \rangle = \int_{0}^1 f(t)g(t) \, dt$ and define a new norm $$ \| f \|^2_{\star} = \sum_{i=1}^\infty \langle f, \phi_i\rangle^2 \lambda_i $$ where $\phi_1, \phi_2, \ldots$ are an orthonormal basis for $L_2[0,1]$ and $\lambda_n$ is a sequence of non increasing postitive numbers such that $\sum_{i=1}^\infty \lambda_i < \infty$ . For some $0<c<1$ the indicator function $I_{[0,c]}(t)$ and define the operator $T : L_2 \to L_2$ such that $T(f) = f I_{[0,c]}$ Is T a bounded operator under $\| \|_{\star}$ ?  (Does there exists $M >0$ such that $ \| T(f) \|_{\star} \leq M \|f\|_{\star}$ . I have tried bounding $\langle f I_{[0,c]} , \phi_i \rangle^2 = (\int_{0}^c f(t) \phi_i(t) \, dt )^2$ for each $i$ but failed.",Consider with the usual inner product and define a new norm where are an orthonormal basis for and is a sequence of non increasing postitive numbers such that . For some the indicator function and define the operator such that Is T a bounded operator under ?  (Does there exists such that . I have tried bounding for each but failed.,"L_2[0,1] \langle f, g \rangle = \int_{0}^1 f(t)g(t) \, dt  \| f \|^2_{\star} = \sum_{i=1}^\infty \langle f, \phi_i\rangle^2 \lambda_i  \phi_1, \phi_2, \ldots L_2[0,1] \lambda_n \sum_{i=1}^\infty \lambda_i < \infty 0<c<1 I_{[0,c]}(t) T : L_2 \to L_2 T(f) = f I_{[0,c]} \| \|_{\star} M >0  \| T(f) \|_{\star} \leq M \|f\|_{\star} \langle f I_{[0,c]} , \phi_i \rangle^2 = (\int_{0}^c f(t) \phi_i(t) \, dt )^2 i","['functional-analysis', 'linear-transformations', 'hilbert-spaces']"
51,Proving James' Theorem,Proving James' Theorem,,"I am reviewing the proof of James theorem, i.e. a Banach space is reflexive iff every continuous linear functional obtains its norm. Every thing I find online shows one direction ( $\Leftarrow$ ), but not ( $\Rightarrow$ ). I am having issues seeing it and any help would be appreciated.","I am reviewing the proof of James theorem, i.e. a Banach space is reflexive iff every continuous linear functional obtains its norm. Every thing I find online shows one direction ( ), but not ( ). I am having issues seeing it and any help would be appreciated.",\Leftarrow \Rightarrow,['functional-analysis']
52,Smooth basis of $L^2$ with uniformly controlled derivatives,Smooth basis of  with uniformly controlled derivatives,L^2,"Is there a basis $\{f_i\}_{i\in\mathbb{N}}$ of $L^2[0,1]$ , where each $f_i$ is smooth and the second derivative of $f_i$ is uniformly bounded in $i$ ? Thoughts: I have a vague feeling that the existence of such basis might make it impossible to approximate certain functions in $L^2[0,1]$ with rapid variation. However, I'm not able to give a rigorous proof of this (or give an example of such a basis if it does exist).","Is there a basis of , where each is smooth and the second derivative of is uniformly bounded in ? Thoughts: I have a vague feeling that the existence of such basis might make it impossible to approximate certain functions in with rapid variation. However, I'm not able to give a rigorous proof of this (or give an example of such a basis if it does exist).","\{f_i\}_{i\in\mathbb{N}} L^2[0,1] f_i f_i i L^2[0,1]","['functional-analysis', 'analysis', 'lebesgue-integral']"
53,"Second derivative operator closed on $AC^2[0,1]$",Second derivative operator closed on,"AC^2[0,1]","Consider the Hilbert space $\mathcal H=L^2(0,1)$ and let $D:=AC^2[0,1]$ be the space of functions $f\in C^1[0,1]$ such that $f'$ is absolutely continuous and the weak derivative $f''$ is in $ L^{2}(0,1)$ . Define the operator $$T:D\to \mathcal H; \, T= -\frac{d^2}{dx^2}.$$ I want to prove that $T$ is closed, i.e. the graph of $T, \Gamma(T)$ is closed. To that end, let $(\varphi, \psi) \in \overline{\Gamma(T)}$ and $(\varphi_n)_{n\in \mathbb N}$ such that $\varphi_n \stackrel{n\to \infty}{\longrightarrow} \varphi$ and $T\varphi_n  \stackrel{n\to \infty}{\longrightarrow} \psi$ in $L^2$ . I need to prove $\varphi \in D$ and $T\varphi = \psi$ . Here I am stuck. I tried a lot playing with integration by parts and other stuff. I am also not sure what I can say about the first derivative of $\varphi$ . Any help appreciated!","Consider the Hilbert space and let be the space of functions such that is absolutely continuous and the weak derivative is in . Define the operator I want to prove that is closed, i.e. the graph of is closed. To that end, let and such that and in . I need to prove and . Here I am stuck. I tried a lot playing with integration by parts and other stuff. I am also not sure what I can say about the first derivative of . Any help appreciated!","\mathcal H=L^2(0,1) D:=AC^2[0,1] f\in C^1[0,1] f' f''  L^{2}(0,1) T:D\to \mathcal H; \, T= -\frac{d^2}{dx^2}. T T, \Gamma(T) (\varphi, \psi) \in \overline{\Gamma(T)} (\varphi_n)_{n\in \mathbb N} \varphi_n \stackrel{n\to \infty}{\longrightarrow} \varphi T\varphi_n  \stackrel{n\to \infty}{\longrightarrow} \psi L^2 \varphi \in D T\varphi = \psi \varphi","['functional-analysis', 'operator-theory', 'mathematical-physics']"
54,Invertible elements in $l^1(\mathbb Z)$,Invertible elements in,l^1(\mathbb Z),"The vector space $l^1(\mathbb Z)$ with $\|x\| = \sum_{n \in \mathbb Z} |x_n|$ and $x * y(t) = \sum_{k \in \mathbb Z} x(k)y(t-k)$ forms a unital complex Banach algebra, with the unit being $\mathbf 1(0) = 1$ and $\mathbf 1(z) = 0$ for all $z \neq 1$ . I need to find the invertible elements of this Banach algebra. The first thing we do is note that if $\|h\| < 1$ then $1-h$ is invertible. Furthermore, $f$ is invertible if and only if $\alpha f$ is invertible for some scalar $\alpha$ non-zero. Therefore, combining these, if there is some non-zero $\alpha \in \mathbb C$ and $h \in l^1(\mathbb Z)$ with $\|h\| < 1$ such that $f = \frac{1}{\alpha} (\mathbf 1 - h)$ then $f$ is invertible. This simplifies to $\mathbf 1 - \alpha f$ being of norm $<1$ for some $\alpha$ non-zero. By definition of the norm , $$\sum_{k \in \mathbb Z} |(\mathbf 1(k) - \alpha f(k))| < 1 \iff |1-\alpha f(0)| + \sum_{k \neq 0\in \mathbb Z} |\alpha||f(k)| < 1 $$ It is not clear to me how I should proceed further on from this point : this gives some condition on $f$ in terms of $\alpha,h$ and I want to claim that this is sufficient, but no progress has been possible in the other direction because $f * g = \mathbf 1$ , from the assumption of $f$ being invertible is not workable because of too many equations in the unknowns $f(k)$ . I believe that this is down to which elements  in the Banach algebra don't have zero in their spectrum, so if there is any result in that direction (i.e. results about the spectrum) I would like to know about that as well.","The vector space with and forms a unital complex Banach algebra, with the unit being and for all . I need to find the invertible elements of this Banach algebra. The first thing we do is note that if then is invertible. Furthermore, is invertible if and only if is invertible for some scalar non-zero. Therefore, combining these, if there is some non-zero and with such that then is invertible. This simplifies to being of norm for some non-zero. By definition of the norm , It is not clear to me how I should proceed further on from this point : this gives some condition on in terms of and I want to claim that this is sufficient, but no progress has been possible in the other direction because , from the assumption of being invertible is not workable because of too many equations in the unknowns . I believe that this is down to which elements  in the Banach algebra don't have zero in their spectrum, so if there is any result in that direction (i.e. results about the spectrum) I would like to know about that as well.","l^1(\mathbb Z) \|x\| = \sum_{n \in \mathbb Z} |x_n| x * y(t) = \sum_{k \in \mathbb Z} x(k)y(t-k) \mathbf 1(0) = 1 \mathbf 1(z) = 0 z \neq 1 \|h\| < 1 1-h f \alpha f \alpha \alpha \in \mathbb C h \in l^1(\mathbb Z) \|h\| < 1 f = \frac{1}{\alpha} (\mathbf 1 - h) f \mathbf 1 - \alpha f <1 \alpha \sum_{k \in \mathbb Z} |(\mathbf 1(k) - \alpha f(k))| < 1 \iff |1-\alpha f(0)| + \sum_{k \neq 0\in \mathbb Z} |\alpha||f(k)| < 1  f \alpha,h f * g = \mathbf 1 f f(k)","['functional-analysis', 'spectral-theory', 'banach-algebras']"
55,Show compactness of an operator,Show compactness of an operator,,"Let $T: C^0[0,1] \rightarrow l^1$ , $(Tf)_n=a_n \int_0^{1/n} f(x)dx$ , for an $f$ in $C^0[0,1]$ . Prove that $T$ is compact when $\{\frac{a_n}{n} \}_n \in l^1$ . I know the definition of compact operator, but in this case I'd like to state that if $\{ \frac{a_n}{n} \} \in l^1$ , then $T$ is a finite rank operator. Indeed, $||(Tf)_n||_{l^1} = \sum_n |\frac{a_n}{n} \int_0^1 f(\frac{t}{n})dt|$ . But $f$ is continuous in $[0,1]$ , then this integral is finite, and, particularly, it's bounded from $||f||_{\infty}$ , thus the last sum is less or equal than $||f ||_{\infty} \sum_n |\frac{a_n}{n}|$ , thus it's convergent, and then $T$ has finite rank. Is it okay? EDIT Set $T_m(f)=(a_1 \int_0^1f(x)dx,\ldots,a_m \int_0^{1/m}f(x)dx, 0, 0, \ldots)$ . I want to show that $|| T_m-T|| \rightarrow _m 0$ in the operator norm. I have to compute $\sup \{ ||T_m(f) - T(f)||_{l^1}: ||f||_{\infty} \leq 1 \}=\sup \{ \sum_{k=m+1} |a_k \int_0^\frac{1}{k}f(x)dx|: ||f||_{\infty} \leq 1 \}$ Now, $\sum_{k=m+1} |a_k \int_0^\frac{1}{k}f(x)dx| \leq \sum_{k=1}^{\infty} \frac|{a_k}{k} \int_0^1 f(\frac{t}{n})dt| \leq ||f||_{\infty} \sum_k |\frac{a_k}{k}|$ . Thus, by taking the supremum I have that $||T-T_m|| = \sum_{k=m+1}^\infty |\frac{a_k}{k}|$ . But for $\{ \frac{a_k}{k} \} \in l^1$ , this is the remainder of a convergent series, and then the limit over $m$ goes to $0$ . So $T$ is compact, since it's limit of compact (they're finite rank) operators","Let , , for an in . Prove that is compact when . I know the definition of compact operator, but in this case I'd like to state that if , then is a finite rank operator. Indeed, . But is continuous in , then this integral is finite, and, particularly, it's bounded from , thus the last sum is less or equal than , thus it's convergent, and then has finite rank. Is it okay? EDIT Set . I want to show that in the operator norm. I have to compute Now, . Thus, by taking the supremum I have that . But for , this is the remainder of a convergent series, and then the limit over goes to . So is compact, since it's limit of compact (they're finite rank) operators","T: C^0[0,1] \rightarrow l^1 (Tf)_n=a_n \int_0^{1/n} f(x)dx f C^0[0,1] T \{\frac{a_n}{n} \}_n \in l^1 \{ \frac{a_n}{n} \} \in l^1 T ||(Tf)_n||_{l^1} = \sum_n |\frac{a_n}{n} \int_0^1 f(\frac{t}{n})dt| f [0,1] ||f||_{\infty} ||f ||_{\infty} \sum_n |\frac{a_n}{n}| T T_m(f)=(a_1 \int_0^1f(x)dx,\ldots,a_m \int_0^{1/m}f(x)dx, 0, 0, \ldots) || T_m-T|| \rightarrow _m 0 \sup \{ ||T_m(f) - T(f)||_{l^1}: ||f||_{\infty} \leq 1 \}=\sup \{ \sum_{k=m+1} |a_k \int_0^\frac{1}{k}f(x)dx|: ||f||_{\infty} \leq 1 \} \sum_{k=m+1} |a_k \int_0^\frac{1}{k}f(x)dx| \leq \sum_{k=1}^{\infty} \frac|{a_k}{k} \int_0^1 f(\frac{t}{n})dt| \leq ||f||_{\infty} \sum_k |\frac{a_k}{k}| ||T-T_m|| = \sum_{k=m+1}^\infty |\frac{a_k}{k}| \{ \frac{a_k}{k} \} \in l^1 m 0 T","['functional-analysis', 'operator-theory', 'compact-operators']"
56,"Convergence in $C([0,T_0],L^2)$ and uniform boundedness in $C([0,T_0],H^2)$ gives convergence in $C([0,T_0],H^1)$.",Convergence in  and uniform boundedness in  gives convergence in .,"C([0,T_0],L^2) C([0,T_0],H^2) C([0,T_0],H^1)","Let $\Omega$ be a compact set of $\mathbb{R}$ and $s\geq 1$ . Let $$ v_n\in C([0,T_0];H^{s+1}(\Omega)). $$ Also $\sup_{t\in[0,T_0]} ||v_n||_{H^{s+1}(\Omega)}\leq M$ , $M$ is a constant. We are also given that $$  v_n\longrightarrow v \quad\text{   in  }  \quad C([0,T_0];L^2(\Omega)). $$ How do I show that $$ v_n\longrightarrow v\quad\text{   in  }  \quad C([0,T_0];H^s(\Omega))? $$ Note : This problem is a portion of a paper I am reading. As an argument for this problem, the authors write ‘interpolating the given convergence with the uniform bound estimates’. I don’t know what they mean by this.","Let be a compact set of and . Let Also , is a constant. We are also given that How do I show that Note : This problem is a portion of a paper I am reading. As an argument for this problem, the authors write ‘interpolating the given convergence with the uniform bound estimates’. I don’t know what they mean by this.","\Omega \mathbb{R} s\geq 1 
v_n\in C([0,T_0];H^{s+1}(\Omega)).
 \sup_{t\in[0,T_0]} ||v_n||_{H^{s+1}(\Omega)}\leq M M  
v_n\longrightarrow v \quad\text{   in  }  \quad C([0,T_0];L^2(\Omega)).
 
v_n\longrightarrow v\quad\text{   in  }  \quad C([0,T_0];H^s(\Omega))?
","['functional-analysis', 'convergence-divergence', 'partial-differential-equations', 'sobolev-spaces']"
57,Dimension of kernel of a operator,Dimension of kernel of a operator,,"This question is simply applying a theorem. But I do not understand how . One can treat most of the content as black box. I will provide the definitions. The context: I want to show If $M$ is a compact $n$ -dimensional manifold, $P$ an ellipitic differential operator of order $k$ , then $P:W^{k+l} \rightarrow W^l$ has kernel whose dimension is independent of $l$ . Black box terminology explanation: Definition: Let $E_i \rightarrow M$ be two vector bundles, $P:\Gamma(M,E_0) \rightarrow \Gamma(M,E_1)$ is an elliptic differential operator of order $k$ , if locally $P$ can be written as $$ Pf = \sum_{|\alpha| \le k } A^\alpha(y) \frac{\partial^\alpha}{\partial x_\alpha} f(y).$$ Definition 2: Let $E \rightarrow M$ be a complex vector bundle over a compact $n$ -dimensional manifold. Then we can give the space of sections $\Gamma(M,E)$ a Sobolev norm . We denote $W^k$ be the completion of $\Gamma(M,E)$ with respect to this norm. Let us suppose $P:W^{k+l} \rightarrow W^k$ is well defined and: Theorem: Let $Pu=f$ , $f \in W^l$ , $u \in W^r$ for some integer $r$ , then $u \in W^{l+k}$ . It is claimed that then we have the kernel is independent of $l$ . How does this follow? Reference: Pg 48-49.","This question is simply applying a theorem. But I do not understand how . One can treat most of the content as black box. I will provide the definitions. The context: I want to show If is a compact -dimensional manifold, an ellipitic differential operator of order , then has kernel whose dimension is independent of . Black box terminology explanation: Definition: Let be two vector bundles, is an elliptic differential operator of order , if locally can be written as Definition 2: Let be a complex vector bundle over a compact -dimensional manifold. Then we can give the space of sections a Sobolev norm . We denote be the completion of with respect to this norm. Let us suppose is well defined and: Theorem: Let , , for some integer , then . It is claimed that then we have the kernel is independent of . How does this follow? Reference: Pg 48-49.","M n P k P:W^{k+l} \rightarrow W^l l E_i \rightarrow M P:\Gamma(M,E_0) \rightarrow \Gamma(M,E_1) k P  Pf = \sum_{|\alpha| \le k } A^\alpha(y) \frac{\partial^\alpha}{\partial x_\alpha} f(y). E \rightarrow M n \Gamma(M,E) W^k \Gamma(M,E) P:W^{k+l} \rightarrow W^k Pu=f f \in W^l u \in W^r r u \in W^{l+k} l","['functional-analysis', 'differential-geometry', 'sobolev-spaces', 'vector-bundles']"
58,Norms on Tensor Product of $C^*$- algebras,Norms on Tensor Product of - algebras,C^*,Suppose $A$ and $B$ are two $C^*$ -algebras. On the algebraic tensor product $A\otimes B$ we can define the maximal and minimal tensor norms which makes $A\otimes B$ a $C^*$ - algebra. what are other possible norms which one define on algebraic tensor product of $C^*-$ algebras to make it again a $C^*$ -algebra? The books I have seen only discusses these two norms while they do discuss many norms on tensor product of operator spaces.Why so?,Suppose and are two -algebras. On the algebraic tensor product we can define the maximal and minimal tensor norms which makes a - algebra. what are other possible norms which one define on algebraic tensor product of algebras to make it again a -algebra? The books I have seen only discusses these two norms while they do discuss many norms on tensor product of operator spaces.Why so?,A B C^* A\otimes B A\otimes B C^* C^*- C^*,"['functional-analysis', 'operator-theory', 'tensor-products', 'c-star-algebras']"
59,Using the Banach fixed point Theorem,Using the Banach fixed point Theorem,,"In Chapter 7, The Hille-Yosida Theorem, Functional Analysis,   Sobolev Spaces and Partial   Differential Equations - Brezis, 2011. Brezis showed the following claim (in Proposition 7.1). Claim : Suppose that $A$ is a maximal monotone operator, $(I+\lambda A): D(A) \to R(I+\lambda A)$ is a injective operator, and $|(I+\lambda A)^{-1}u| \leq |u| $ for all $u \in R(I+\lambda A)$ for all $\lambda >0$ . Then $R(I+\lambda A) = H$ . The proof of Brezis: We will prove that if $R(I+\lambda_{0} A) = H$ for some $\lambda_{0}>0$ then $R(I+\lambda A) = H$ for every $\lambda > \frac{1}{2}\lambda_{0}$ . For some $f \in H$ , we try to solve the equation $u+\lambda Au = f$ with $\lambda >0$ .  (1) Equation (1) may be written as $u+ \lambda_{0}Au = \frac{\lambda_{0}}{\lambda}f+ \big( 1- \frac{\lambda_{0}}{\lambda}u \big)$ or alternatively $u= (I+\lambda A)^{-1}\big[\frac{\lambda_{0}}{\lambda}f+ \big( 1- \frac{\lambda_{0}}{\lambda}u \big)\big]$ $(2)$ If $|1-\frac{\lambda_{0}}{\lambda}|< 1$ , i.e., $\lambda > \frac{1}{2}\lambda_{0}$ , we may apply the   contraction mapping principle (the Banach Fixed point Theorem) and deduce that (2) has a solution. My question:  how to prove that (2) has a solution using the the Banach Fixed point Theorem? Thanks Definitions: An unbounded linear operator $A: D(A)\subseteq H \to H$ is said to be monotone if it satisfies $\langle A u, u \rangle \geq 0$ for all $u\in D(A)$ . It is called maximal monotone if, in addition, $R(I+A)=H$ .","In Chapter 7, The Hille-Yosida Theorem, Functional Analysis,   Sobolev Spaces and Partial   Differential Equations - Brezis, 2011. Brezis showed the following claim (in Proposition 7.1). Claim : Suppose that is a maximal monotone operator, is a injective operator, and for all for all . Then . The proof of Brezis: We will prove that if for some then for every . For some , we try to solve the equation with .  (1) Equation (1) may be written as or alternatively If , i.e., , we may apply the   contraction mapping principle (the Banach Fixed point Theorem) and deduce that (2) has a solution. My question:  how to prove that (2) has a solution using the the Banach Fixed point Theorem? Thanks Definitions: An unbounded linear operator is said to be monotone if it satisfies for all . It is called maximal monotone if, in addition, .","A (I+\lambda A): D(A) \to R(I+\lambda A) |(I+\lambda A)^{-1}u| \leq |u|  u \in R(I+\lambda A) \lambda >0 R(I+\lambda A) = H R(I+\lambda_{0} A) = H \lambda_{0}>0 R(I+\lambda A) = H \lambda > \frac{1}{2}\lambda_{0} f \in H u+\lambda Au = f \lambda >0 u+ \lambda_{0}Au = \frac{\lambda_{0}}{\lambda}f+ \big( 1- \frac{\lambda_{0}}{\lambda}u \big) u= (I+\lambda A)^{-1}\big[\frac{\lambda_{0}}{\lambda}f+ \big( 1- \frac{\lambda_{0}}{\lambda}u \big)\big] (2) |1-\frac{\lambda_{0}}{\lambda}|< 1 \lambda > \frac{1}{2}\lambda_{0} A: D(A)\subseteq H \to H \langle A u, u \rangle \geq 0 u\in D(A) R(I+A)=H","['functional-analysis', 'partial-differential-equations']"
60,Is the $\sigma$-algebra generated by closed rectangles Borel $\sigma$-algebra?,Is the -algebra generated by closed rectangles Borel -algebra?,\sigma \sigma,"$\newcommand{\norm}[1]{\left\lVert#1\right\rVert}$ Suppose we have rectangles in the form $\{[a_1, b_1]\times[a_2,b_2]\times\cdots\times[a_n,b_n]\}\subset \mathbb{R}^n$ . Let $\mathcal{C}$ be the set of all such rectangles. Does $\mathcal{B}^n =\sigma(\mathcal{C})$ ? I'm also curious about balls. Let $\mathcal{D}$ be sets of balls in the form of $\{ x\in\mathbb{R}^n|\norm{x-a}<r^2 \}$ . Does $\mathcal{B}^n =\sigma(\mathcal{C})$ ? Let's say all $a,b,r$ are rationals. Also, is $\sigma(\mathcal{D})=\sigma(\mathcal{C})$ true? I think the proof could be done by saying balls can be represented by countably union/intersection of rectangles. But I don't know how to write it explicitly? An answer for the case in dimension $2$ would be appreciated.","Suppose we have rectangles in the form . Let be the set of all such rectangles. Does ? I'm also curious about balls. Let be sets of balls in the form of . Does ? Let's say all are rationals. Also, is true? I think the proof could be done by saying balls can be represented by countably union/intersection of rectangles. But I don't know how to write it explicitly? An answer for the case in dimension would be appreciated.","\newcommand{\norm}[1]{\left\lVert#1\right\rVert} \{[a_1, b_1]\times[a_2,b_2]\times\cdots\times[a_n,b_n]\}\subset \mathbb{R}^n \mathcal{C} \mathcal{B}^n =\sigma(\mathcal{C}) \mathcal{D} \{ x\in\mathbb{R}^n|\norm{x-a}<r^2 \} \mathcal{B}^n =\sigma(\mathcal{C}) a,b,r \sigma(\mathcal{D})=\sigma(\mathcal{C}) 2","['real-analysis', 'functional-analysis', 'probability-theory', 'measure-theory']"
61,Generalisation of the norm of bounded linear operators II,Generalisation of the norm of bounded linear operators II,,"Let $E$ be a complex Hilbert space, with inner product $\langle\cdot\;, \;\cdot\rangle$ and the norm $\|\cdot\|$ and let $\mathcal{L}(E)$ be the algebra of all bounded linear operators on $E$ . Let $M\in \mathcal{L}(E)^+$ (i.e. $\langle Mx\;, \;x\rangle \geq0,\;\forall x\in E$ ), we consider the following subspace of $\mathcal{L}(E)$ : $$\mathcal{L}_M(E)=\left\{A\in \mathcal{L}(E):\,\,\exists c>0 \quad \mbox{such that}\quad\|Ax\|_M \leq c \|x\|_M ,\;\forall x \in \overline{\mbox{Im}(M)}\right\},$$ with $\|x\|_M:=\|M^{1/2}x\|,\;\forall x \in E$ . If $A\in \mathcal{L}_M(E)$ , the $M$ -semi-norm of $A$ is defined us $$\|A\|_M:=\sup_{\substack{x\in \overline{\mbox{Im}(M)}\\ x\not=0}}\frac{\|Ax\|_M}{\|x\|_M}$$ According to this answer , for $A\in \mathcal{L}_M(E)$ , we have $$\|A\|_M=\displaystyle\sup_{\|x\|_M\leq1}\|Ax\|_M=\displaystyle\sup_{\|x\|_M=1}\|Ax\|_M.$$ Let $A\in \mathcal{L}_M(E)$ , I see in a paper that it is straightforward that $$\|A\|_M=\sup\left\{|\langle Ax, y\rangle_M|;\;x,y\in \overline{\mbox{Im}(M)} ,\;\|x\|_{M}\leq1,\|y\|_{M}\leq 1\right\},$$ where $\langle Ax, y\rangle_M=\langle MAx, y\rangle.$ How can I prove this result? Thank you everyone !!!","Let be a complex Hilbert space, with inner product and the norm and let be the algebra of all bounded linear operators on . Let (i.e. ), we consider the following subspace of : with . If , the -semi-norm of is defined us According to this answer , for , we have Let , I see in a paper that it is straightforward that where How can I prove this result? Thank you everyone !!!","E \langle\cdot\;, \;\cdot\rangle \|\cdot\| \mathcal{L}(E) E M\in \mathcal{L}(E)^+ \langle Mx\;, \;x\rangle \geq0,\;\forall x\in E \mathcal{L}(E) \mathcal{L}_M(E)=\left\{A\in \mathcal{L}(E):\,\,\exists c>0 \quad \mbox{such that}\quad\|Ax\|_M \leq c \|x\|_M ,\;\forall x \in \overline{\mbox{Im}(M)}\right\}, \|x\|_M:=\|M^{1/2}x\|,\;\forall x \in E A\in \mathcal{L}_M(E) M A \|A\|_M:=\sup_{\substack{x\in \overline{\mbox{Im}(M)}\\ x\not=0}}\frac{\|Ax\|_M}{\|x\|_M} A\in \mathcal{L}_M(E) \|A\|_M=\displaystyle\sup_{\|x\|_M\leq1}\|Ax\|_M=\displaystyle\sup_{\|x\|_M=1}\|Ax\|_M. A\in \mathcal{L}_M(E) \|A\|_M=\sup\left\{|\langle Ax, y\rangle_M|;\;x,y\in \overline{\mbox{Im}(M)} ,\;\|x\|_{M}\leq1,\|y\|_{M}\leq 1\right\}, \langle Ax, y\rangle_M=\langle MAx, y\rangle.","['functional-analysis', 'operator-theory']"
62,1 Dimensional ODE with solution in $L^2$,1 Dimensional ODE with solution in,L^2,"For part of a bigger question, I need either a solution or a counterexample to the following 1 dimensional ODE. Let $h\in L^2(0,\infty)$ (complex valued functions) and $r \in (0,\infty)$ . Under boundary conditions $w(0) = c_1a + c_2$ and $w'(0) = c_3a + c_4$ where the $c_i$ are complex constants and $a$ is a complex parameter, is there an $a \in \mathbb{C}$ for which there is a solution in $H^2(0,\infty)$ for: $$w''(t) = irw(t) - h(t) \ \ \ (t\in (0,\infty))?$$ The strange boundary conditions are just my way of saying that there is one parameter I want to solve for if a solution exists in order to couple this ODE with another one on the negative real line. If I use Laplace transforms, this is equivalent to asking if there exists $w \in H^2(0,\infty)$ such that $$\hat{w} = \frac{\hat{h}}{ir-s^2} - \frac{w(0)+sw'(0)}{ir - s^2}.$$ There is a solution to this ODE by taking the inverse Laplace transform of the above equation, namely $$ w(t) = -\frac{1}{\sqrt{ir}}\int_0^t h(u)\sinh(\sqrt{ir}(t-u))du + \frac{w(0)}{\sqrt{ir}}\sinh(\sqrt{ir}t) + w'(0)\cosh(\sqrt{ir}t).$$ However, this is not obvious to me whether or not there is an $a$ for which it's in $L^2(0,\infty)$ . Is there another solution to this ODE that is in $L^2(0,\infty)$ or if not, is there an explicit counterexample? In other words, given $h\in L^2(0,\infty)$ , are there nonhomogeneous boundary conditions of the form aforementioned that give me a solutions $w\in H^2(0,\infty)$ .","For part of a bigger question, I need either a solution or a counterexample to the following 1 dimensional ODE. Let (complex valued functions) and . Under boundary conditions and where the are complex constants and is a complex parameter, is there an for which there is a solution in for: The strange boundary conditions are just my way of saying that there is one parameter I want to solve for if a solution exists in order to couple this ODE with another one on the negative real line. If I use Laplace transforms, this is equivalent to asking if there exists such that There is a solution to this ODE by taking the inverse Laplace transform of the above equation, namely However, this is not obvious to me whether or not there is an for which it's in . Is there another solution to this ODE that is in or if not, is there an explicit counterexample? In other words, given , are there nonhomogeneous boundary conditions of the form aforementioned that give me a solutions .","h\in L^2(0,\infty) r \in (0,\infty) w(0) = c_1a + c_2 w'(0) = c_3a + c_4 c_i a a \in \mathbb{C} H^2(0,\infty) w''(t) = irw(t) - h(t) \ \ \ (t\in (0,\infty))? w \in H^2(0,\infty) \hat{w} = \frac{\hat{h}}{ir-s^2} - \frac{w(0)+sw'(0)}{ir - s^2}.  w(t) = -\frac{1}{\sqrt{ir}}\int_0^t h(u)\sinh(\sqrt{ir}(t-u))du + \frac{w(0)}{\sqrt{ir}}\sinh(\sqrt{ir}t) + w'(0)\cosh(\sqrt{ir}t). a L^2(0,\infty) L^2(0,\infty) h\in L^2(0,\infty) w\in H^2(0,\infty)","['functional-analysis', 'ordinary-differential-equations', 'analysis']"
63,Characterization of maximal monotone operators,Characterization of maximal monotone operators,,"I found the following theorem: Given $H$ Hilbert space and a monotone operator $A\colon H\rightarrow H$ , then A is maximal monotone if and only if $\operatorname{Range}(A+I)=H$ . Note that: $A$ monotone (multivalued) means that $\forall u,v \in H$ and $\forall f\in Au, g \in Av$ , then $(u-v,f-g) \geq 0$ . Moreover a monotone operator is said to be maximal in the sense of inclusion of graphs (i.e. the graph of A has no proper monotone extension). Where can I find a detailed proof of this fact? Thank you in advance, I'm really clueless.","I found the following theorem: Given Hilbert space and a monotone operator , then A is maximal monotone if and only if . Note that: monotone (multivalued) means that and , then . Moreover a monotone operator is said to be maximal in the sense of inclusion of graphs (i.e. the graph of A has no proper monotone extension). Where can I find a detailed proof of this fact? Thank you in advance, I'm really clueless.","H A\colon H\rightarrow H \operatorname{Range}(A+I)=H A \forall u,v \in H \forall f\in Au, g \in Av (u-v,f-g) \geq 0","['functional-analysis', 'hilbert-spaces', 'monotone-operator-theory']"
64,$BV(\Omega)$ is embedded compactly in $L^1 _{\mathrm{loc}} (\Omega)$,is embedded compactly in,BV(\Omega) L^1 _{\mathrm{loc}} (\Omega),"Definition: We say that a function $u: \Omega \rightarrow \mathbb{R}$ is a function of bounded variation iff $u\in L^1(\Omega)$ and $\sup\left\{\int\limits_{\Omega}u \operatorname{div}\phi : \phi \in C_c(\Omega, \mathbb{R}^d), ||\phi||_{\infty} \leq 1\right\} < +{\infty}$ . By definition it is clear that $\mathrm{BV}(\Omega)\subset L^1(\Omega)$ . How to show that this embedding is compact when $\Omega$ is bounded set? Seems like this is a very standard result, but I could not find the proof of this in many of the functional analysis book.","Definition: We say that a function is a function of bounded variation iff and . By definition it is clear that . How to show that this embedding is compact when is bounded set? Seems like this is a very standard result, but I could not find the proof of this in many of the functional analysis book.","u: \Omega \rightarrow \mathbb{R} u\in L^1(\Omega) \sup\left\{\int\limits_{\Omega}u \operatorname{div}\phi : \phi \in C_c(\Omega, \mathbb{R}^d), ||\phi||_{\infty} \leq 1\right\} < +{\infty} \mathrm{BV}(\Omega)\subset L^1(\Omega) \Omega","['functional-analysis', 'analysis', 'partial-differential-equations', 'bounded-variation', 'regularity-theory-of-pdes']"
65,Continuity of support functionals,Continuity of support functionals,,"Let $X$ be a normed space(not necessarily Banach) and let $G$ be a $w^*-$compact subset of $X^*,$ the dual space of $X.$ Consider the function $f:X\to \Bbb R$ defined by $$f(x)= \max_{g^*\in G}\{\langle g^*,x\rangle\}.$$ Is $f$ continuous? If not, what about lower semicontinuous? Could you present a example of a discontinuous $f$? I can prove that if $X$ is Banach the function is Lipschitz(by using the Uniform Boundedness Theorem). However, in the general case I am still curious.","Let $X$ be a normed space(not necessarily Banach) and let $G$ be a $w^*-$compact subset of $X^*,$ the dual space of $X.$ Consider the function $f:X\to \Bbb R$ defined by $$f(x)= \max_{g^*\in G}\{\langle g^*,x\rangle\}.$$ Is $f$ continuous? If not, what about lower semicontinuous? Could you present a example of a discontinuous $f$? I can prove that if $X$ is Banach the function is Lipschitz(by using the Uniform Boundedness Theorem). However, in the general case I am still curious.",,"['functional-analysis', 'optimization', 'continuity', 'convex-analysis', 'convex-optimization']"
66,"If $X$ is a Banach space, is $\ell^{p}(X) \cong \ell^{q}(X^{*})$?","If  is a Banach space, is ?",X \ell^{p}(X) \cong \ell^{q}(X^{*}),"Here's the problem that I have: ( $\frac{1}{p}+\frac{1}{q} =1$ ) Let $(X, ||\cdot||_{X})$ be a Banach space, and let $\ell^{p}(X) = \lbrace (x_{n})_{n=1}^{\infty} | \sum_{n=1}^{\infty} ||x_{n}||_{X}^p < +\infty \rbrace$ , for some $1 \leq p < +\infty$ . Prove that: $\ell^{p}(X)$ is a Banach space with respect to the norm $||(x_{n})_{n=1}^{\infty}||_{p} = \sqrt[p]{\sum_{n=1}^{\infty}||x_{n}||_{X}^{p}}$ ; Every functional $y^{*} \in \ell^{p}(X)$ can be written as $y^{*}((x_{n})_{n=1}^{\infty}) = \sum_{n=1}^{\infty}y_{n}^{*}(x_{n})$ , where $y_{n}^{*} \in X^{*}$ , $\sum_{n=1}^{\infty}||y_{n}^{*}||_{X^{*}}^{q} < +\infty$ and $||y^{*}|| = \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||_{X^{*}}^{q}}$ . A very similar question has been asked here: Banach valued sequence spaces $\ell^p(X)$ . However, it's not enough for me to work out the details of my problem. Here's what I have so far: I did not have any trouble with part 1, and I would like to omit my proof here because it's pretty standard, but I will type it out if someone requests it. For part 2: Given a functional $y^{*} \in \ell^{p}(X)^{*}$ , we define, for each $n \in \mathbb{N}$ , a functional $y_{n}^{*} \in X^{*}$ , $y_{n}^{*}(x) = y^{*}(0,0,...,0,x,0,...)$ , where $x$ is at the $n$ -th coordinate. $y_{n}^{*}$ are bounded because $y^{*}$ is bounded. Furthermore, for $x = (x_{n})_{n \geq 1}$ , $y^{*}(x) = y^{*}(\sum_{n=1}^{\infty} (0,...,0,x_{n},0,...))= \sum_{n=1}^{\infty}y^{*}(0,...,0,x_{n},0,...) = \sum_{n=1}^{\infty} y_{n}^{*}(x_{n})$ . By part 1, and because $X^{*}$ is also a Banach space with the operator norm, it follows that $\ell^{q}(X^{*})$ is also a Banach space with the corresponding norm. Now, let us define $Y = (y_{n}^{*})_{n \geq 1}$ . $||Y||_{q} = \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||^{q}} \in [0, +\infty]$ . I wish to prove that this norm cannot be infinity, and that $||Y||_{q} = ||y^{*}||$ . By Hölder's inequality, $$|y^{*}(x)| = |\sum_{n=1}^{\infty}y_{n}^{*}(x_{n})| \leq \sum_{n=1}^{\infty}|y_{n}^{*}(x_{n})| \leq \sum_{n=1}^{\infty} ||y_{n}^{*}|| \hspace{1mm} ||x_{n}|| \leq \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||^{q}} \sqrt[p]{\sum_{n=1}^{\infty} ||x_{n}||^{p}} = ||Y||_{q}||x||_{p},$$ so $||y^{*}|| \leq ||Y||_{q}$ . However, it seems (to me) pretty difficult to find an $x$ for which equality would hold in the previous inequality chain, and even more difficult to find a sequence of $x$ 's, $(x^{m})$ for which I could let $m \to \infty$ and achieve equality. Therefore, I'm having trouble proving $Y \in \ell^{q}(X^{*})$ and $||Y||_{q} \leq ||y^{*}||$ . The answer in the linked question says to proceed as in $(\ell^{p})^{*} \cong \ell^{q}$ , however, the proof that I know uses a very specific construction of a sequence of complex numbers, a luxury that I don't have in this case.","Here's the problem that I have: ( ) Let be a Banach space, and let , for some . Prove that: is a Banach space with respect to the norm ; Every functional can be written as , where , and . A very similar question has been asked here: Banach valued sequence spaces $\ell^p(X)$ . However, it's not enough for me to work out the details of my problem. Here's what I have so far: I did not have any trouble with part 1, and I would like to omit my proof here because it's pretty standard, but I will type it out if someone requests it. For part 2: Given a functional , we define, for each , a functional , , where is at the -th coordinate. are bounded because is bounded. Furthermore, for , . By part 1, and because is also a Banach space with the operator norm, it follows that is also a Banach space with the corresponding norm. Now, let us define . . I wish to prove that this norm cannot be infinity, and that . By Hölder's inequality, so . However, it seems (to me) pretty difficult to find an for which equality would hold in the previous inequality chain, and even more difficult to find a sequence of 's, for which I could let and achieve equality. Therefore, I'm having trouble proving and . The answer in the linked question says to proceed as in , however, the proof that I know uses a very specific construction of a sequence of complex numbers, a luxury that I don't have in this case.","\frac{1}{p}+\frac{1}{q} =1 (X, ||\cdot||_{X}) \ell^{p}(X) = \lbrace (x_{n})_{n=1}^{\infty} | \sum_{n=1}^{\infty} ||x_{n}||_{X}^p < +\infty \rbrace 1 \leq p < +\infty \ell^{p}(X) ||(x_{n})_{n=1}^{\infty}||_{p} = \sqrt[p]{\sum_{n=1}^{\infty}||x_{n}||_{X}^{p}} y^{*} \in \ell^{p}(X) y^{*}((x_{n})_{n=1}^{\infty}) = \sum_{n=1}^{\infty}y_{n}^{*}(x_{n}) y_{n}^{*} \in X^{*} \sum_{n=1}^{\infty}||y_{n}^{*}||_{X^{*}}^{q} < +\infty ||y^{*}|| = \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||_{X^{*}}^{q}} y^{*} \in \ell^{p}(X)^{*} n \in \mathbb{N} y_{n}^{*} \in X^{*} y_{n}^{*}(x) = y^{*}(0,0,...,0,x,0,...) x n y_{n}^{*} y^{*} x = (x_{n})_{n \geq 1} y^{*}(x) = y^{*}(\sum_{n=1}^{\infty} (0,...,0,x_{n},0,...))= \sum_{n=1}^{\infty}y^{*}(0,...,0,x_{n},0,...) = \sum_{n=1}^{\infty} y_{n}^{*}(x_{n}) X^{*} \ell^{q}(X^{*}) Y = (y_{n}^{*})_{n \geq 1} ||Y||_{q} = \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||^{q}} \in [0, +\infty] ||Y||_{q} = ||y^{*}|| |y^{*}(x)| = |\sum_{n=1}^{\infty}y_{n}^{*}(x_{n})| \leq \sum_{n=1}^{\infty}|y_{n}^{*}(x_{n})| \leq \sum_{n=1}^{\infty} ||y_{n}^{*}|| \hspace{1mm} ||x_{n}|| \leq \sqrt[q]{\sum_{n=1}^{\infty} ||y_{n}^{*}||^{q}} \sqrt[p]{\sum_{n=1}^{\infty} ||x_{n}||^{p}} = ||Y||_{q}||x||_{p}, ||y^{*}|| \leq ||Y||_{q} x x (x^{m}) m \to \infty Y \in \ell^{q}(X^{*}) ||Y||_{q} \leq ||y^{*}|| (\ell^{p})^{*} \cong \ell^{q}","['functional-analysis', 'linear-transformations', 'banach-spaces', 'lp-spaces']"
67,Open and Connectedness on the Topological Vector Space over $\mathbb{R}$ Implies Path-Connectedness,Open and Connectedness on the Topological Vector Space over  Implies Path-Connectedness,\mathbb{R},"I want to prove the following proposition (which is also the title). Open and connectedness of a subset G of the topological vector space X over $\mathbb{R}$ implies path-connectedness. I haven't proved this kind of proposition earlier, and I don't even know where to start. If $G$ is convex, then the proposition is trivial. But if $G$ is not convex, I have no idea how I can find the path between two arbitrary points. I suppose being a vector space over $\mathbb{R}$ is important, but I don't know how to use this fact. Should I instead prove that this is a locally path-connected space? Please give me any hints. Thanks in advance. Edit. Here is my another try. Fix $x\in G$ and let $U, V$ be  $$ U:=\{y\in G|y,x\textrm{ are path-connected.}\}\\ V:=\{y\in G|y,x\textrm{ are not path-connected.}\} $$  I claim that $U$ is open. If $G$ has a open convex neighborhood $W$ of $0$ (I am not sure about the existence of $W$ here), $y+\epsilon W \subset U$ when $y\in U$(again here I am not sure about the existence of $\epsilon$). Hence $U$ is open. Similarly, if $y\in U$, $y+\epsilon W\subset V$. $y\in U$ and $U\cap V=\emptyset$, but $U\cup V=G$ and since $G$ is connected, $U=G$. Thus $G$ is path-connected. There are some missing parts in the proof, and I don't know how I can complete it.","I want to prove the following proposition (which is also the title). Open and connectedness of a subset G of the topological vector space X over $\mathbb{R}$ implies path-connectedness. I haven't proved this kind of proposition earlier, and I don't even know where to start. If $G$ is convex, then the proposition is trivial. But if $G$ is not convex, I have no idea how I can find the path between two arbitrary points. I suppose being a vector space over $\mathbb{R}$ is important, but I don't know how to use this fact. Should I instead prove that this is a locally path-connected space? Please give me any hints. Thanks in advance. Edit. Here is my another try. Fix $x\in G$ and let $U, V$ be  $$ U:=\{y\in G|y,x\textrm{ are path-connected.}\}\\ V:=\{y\in G|y,x\textrm{ are not path-connected.}\} $$  I claim that $U$ is open. If $G$ has a open convex neighborhood $W$ of $0$ (I am not sure about the existence of $W$ here), $y+\epsilon W \subset U$ when $y\in U$(again here I am not sure about the existence of $\epsilon$). Hence $U$ is open. Similarly, if $y\in U$, $y+\epsilon W\subset V$. $y\in U$ and $U\cap V=\emptyset$, but $U\cup V=G$ and since $G$ is connected, $U=G$. Thus $G$ is path-connected. There are some missing parts in the proof, and I don't know how I can complete it.",,"['functional-analysis', 'connectedness', 'topological-vector-spaces', 'path-connected']"
68,the upper bound of the supremums of the sequence,the upper bound of the supremums of the sequence,,"Let $f_{n}:S\to R$ be the sequence of uniformly continuous non-negative functions, $S$ is some normed space, such that for every $n$ $$ \underset{s\in C}{\sup} f_{n}(s) < \infty. $$ Next, assume that for every $s$ in some subset $C \subset S$, with $S$ compact or only bounded)  $$ \underset{n\to\infty}{\limsup}f_{n} (s) \leq g(s), $$ where $g(s)$ is continuous and assume $\underset{s\in C}{\sup} g(s) < \infty$, if $S$ is not compact. Is the following true $$ \underset{n\to\infty}{\limsup} \underset{s\in C}{\sup} f_{n} (s) < \infty $$ ?","Let $f_{n}:S\to R$ be the sequence of uniformly continuous non-negative functions, $S$ is some normed space, such that for every $n$ $$ \underset{s\in C}{\sup} f_{n}(s) < \infty. $$ Next, assume that for every $s$ in some subset $C \subset S$, with $S$ compact or only bounded)  $$ \underset{n\to\infty}{\limsup}f_{n} (s) \leq g(s), $$ where $g(s)$ is continuous and assume $\underset{s\in C}{\sup} g(s) < \infty$, if $S$ is not compact. Is the following true $$ \underset{n\to\infty}{\limsup} \underset{s\in C}{\sup} f_{n} (s) < \infty $$ ?",,"['calculus', 'functional-analysis', 'measure-theory', 'convergence-divergence', 'uniform-convergence']"
69,"Showing that if the limit of norms converges, then the sequence converges","Showing that if the limit of norms converges, then the sequence converges",,"Let $H$ be a hilbert space, and $C \subset H$ a convex set. Let $(x_n)_{n\in \mathbb{N}}$ be a sequence in $C$ with $\lim_{n\to \infty}||x_n|| = \inf_{x\in C}||x||$. Show $x_n$ converges in $H$. So far I have: Let $P_C(0) = \{x \in C: ||x|| = \inf_{x \in C}||x||\}$ be the projection of $0$ onto $C$. If we consider $\bar{C}$ (the closure of $C$), then there is a theorem that tells us since $\bar{C}$ is closed and convex, there is exactly one $y \in \bar{C}$ with $y=P_{\bar{C}}(0)$, i.e., $||y|| = \inf_{x\in \bar{C}}||x||$. Since the infimum of a set's closure equals the infimum of the set, we also have $||y|| = \inf_{x\in C} ||x||$. Now, I need to show that since the norms converge to the norm of a unique element ($y$), the sequence itself must converge to this element. This makes sense intuitively, but I can't make it rigorous! Any hints would be appreciated.","Let $H$ be a hilbert space, and $C \subset H$ a convex set. Let $(x_n)_{n\in \mathbb{N}}$ be a sequence in $C$ with $\lim_{n\to \infty}||x_n|| = \inf_{x\in C}||x||$. Show $x_n$ converges in $H$. So far I have: Let $P_C(0) = \{x \in C: ||x|| = \inf_{x \in C}||x||\}$ be the projection of $0$ onto $C$. If we consider $\bar{C}$ (the closure of $C$), then there is a theorem that tells us since $\bar{C}$ is closed and convex, there is exactly one $y \in \bar{C}$ with $y=P_{\bar{C}}(0)$, i.e., $||y|| = \inf_{x\in \bar{C}}||x||$. Since the infimum of a set's closure equals the infimum of the set, we also have $||y|| = \inf_{x\in C} ||x||$. Now, I need to show that since the norms converge to the norm of a unique element ($y$), the sequence itself must converge to this element. This makes sense intuitively, but I can't make it rigorous! Any hints would be appreciated.",,"['functional-analysis', 'convergence-divergence', 'hilbert-spaces']"
70,"Dual of the fractional Sobolev space $W^{s,p}(\mathbb{R}^n)$",Dual of the fractional Sobolev space,"W^{s,p}(\mathbb{R}^n)","For $s\in\mathbb{R}$ and $1<p<\infty$, one can define the fractional Sobolev space $W^{s,p}(\mathbb{R}^n)$. Every element $f$ in $W^{s,p}(\mathbb{R}^d)$ is a tempered distribution such that the inverse Fourier transform of  $$\widehat{f_s}(\xi):=(1+|\xi|^2)^{\frac{s}{2}}\hat{f}(\xi)$$  is an element of $L^p(\mathbb{R}^d)$ and we define  $$\|f\|_{W^{s,p}}:=\|f_s\|_{L^p}.$$  Note that the function $(1+|\xi|^2)^{\frac{s}{2}}$ has at most polynomial order growth, thus $(1+|\xi|^2)^{\frac{s}{2}}\hat{f}(\xi)$ is in fact a well defined tempered distribution and so is its inverse Fourier transform. I'm looking for refrences which deal with the dual space of $W^{s,p}(\mathbb{R}^n)$. I have seen huge literatures on the case $p=2$, in which case the space $W^{s,2}(\mathbb{R}^n)$ is a Hilbert space with inner product $$\langle f,g\rangle_{W^{s,2}}=\frac{1}{2\pi}\int_{\mathbb{R}^d}\hat{f}(\xi)\overline{\hat{g}(\xi)}(1+|\xi|^2)^sd\xi.$$ And the dual space of $W^{s,2}(\mathbb{R}^n)$ is precisely $W^{-s,2}(\mathbb{R}^d)$. Unlike the case $p=2$, I didn't find any resources which discuss the duality when $p\neq 2$. I've seen some resources mentioned that the dual of $W^{s,p}(\mathbb{R}^n)$ is $W^{-s,q}(\mathbb{R}^n)$, where $\frac{1}{p}+\frac{1}{q}=1$. Intuitively this makes sense from the duality of $L^p$ spaces. But I didn't see any proof of this. Could someone provide me some references related to this quesiton? Or maybe explain to me in details if applicable? Thanks in advance! P.S. I saw some resources which define the Sobolev spaces of negative powers to be the dual of Soboleve spaces of positive powers, i.e., they define $$W^{-s,q}(\mathbb{R}^n):=(W^{s,p}(\mathbb{R}^n))'$$ when $s>0$ and $\frac{1}{p}+\frac{1}{q}=1$. I would like to see whether this coincides with the definition I provided above.","For $s\in\mathbb{R}$ and $1<p<\infty$, one can define the fractional Sobolev space $W^{s,p}(\mathbb{R}^n)$. Every element $f$ in $W^{s,p}(\mathbb{R}^d)$ is a tempered distribution such that the inverse Fourier transform of  $$\widehat{f_s}(\xi):=(1+|\xi|^2)^{\frac{s}{2}}\hat{f}(\xi)$$  is an element of $L^p(\mathbb{R}^d)$ and we define  $$\|f\|_{W^{s,p}}:=\|f_s\|_{L^p}.$$  Note that the function $(1+|\xi|^2)^{\frac{s}{2}}$ has at most polynomial order growth, thus $(1+|\xi|^2)^{\frac{s}{2}}\hat{f}(\xi)$ is in fact a well defined tempered distribution and so is its inverse Fourier transform. I'm looking for refrences which deal with the dual space of $W^{s,p}(\mathbb{R}^n)$. I have seen huge literatures on the case $p=2$, in which case the space $W^{s,2}(\mathbb{R}^n)$ is a Hilbert space with inner product $$\langle f,g\rangle_{W^{s,2}}=\frac{1}{2\pi}\int_{\mathbb{R}^d}\hat{f}(\xi)\overline{\hat{g}(\xi)}(1+|\xi|^2)^sd\xi.$$ And the dual space of $W^{s,2}(\mathbb{R}^n)$ is precisely $W^{-s,2}(\mathbb{R}^d)$. Unlike the case $p=2$, I didn't find any resources which discuss the duality when $p\neq 2$. I've seen some resources mentioned that the dual of $W^{s,p}(\mathbb{R}^n)$ is $W^{-s,q}(\mathbb{R}^n)$, where $\frac{1}{p}+\frac{1}{q}=1$. Intuitively this makes sense from the duality of $L^p$ spaces. But I didn't see any proof of this. Could someone provide me some references related to this quesiton? Or maybe explain to me in details if applicable? Thanks in advance! P.S. I saw some resources which define the Sobolev spaces of negative powers to be the dual of Soboleve spaces of positive powers, i.e., they define $$W^{-s,q}(\mathbb{R}^n):=(W^{s,p}(\mathbb{R}^n))'$$ when $s>0$ and $\frac{1}{p}+\frac{1}{q}=1$. I would like to see whether this coincides with the definition I provided above.",,"['functional-analysis', 'reference-request', 'fourier-analysis', 'dual-spaces', 'fractional-sobolev-spaces']"
71,The positive net of a weak* convergent net is weak* convergent.,The positive net of a weak* convergent net is weak* convergent.,,"Suppose $X$ is a unital $C^*$-algebra, $i:X\to X^{**}$ is the natural isometric inclusion as Banach space. Denote $S_X=\{x\in X:\|x\|=1\}$, $S_{X,+}=\{x\in X:\|x\|=1,x\ge 0\}$, so does $S_{X^{**},+}$. I need to prove that $i(S_{X,+})$ is weak* dense in $S_{X^{**},+}$. The following is my idea: Suppose $\pi\in S_{X^{**},+}$, by Goldstein theorem, there exists a net $(x_\lambda)\subset S_{X}$ such that $i(x_\lambda)\to \pi$ weak*. Can we prove that $i(|x_\lambda|)\to \pi$ weak*? If $X=\ell^1\Gamma$, actually, the above idea works, but I don't know whether it is correct generally.","Suppose $X$ is a unital $C^*$-algebra, $i:X\to X^{**}$ is the natural isometric inclusion as Banach space. Denote $S_X=\{x\in X:\|x\|=1\}$, $S_{X,+}=\{x\in X:\|x\|=1,x\ge 0\}$, so does $S_{X^{**},+}$. I need to prove that $i(S_{X,+})$ is weak* dense in $S_{X^{**},+}$. The following is my idea: Suppose $\pi\in S_{X^{**},+}$, by Goldstein theorem, there exists a net $(x_\lambda)\subset S_{X}$ such that $i(x_\lambda)\to \pi$ weak*. Can we prove that $i(|x_\lambda|)\to \pi$ weak*? If $X=\ell^1\Gamma$, actually, the above idea works, but I don't know whether it is correct generally.",,"['functional-analysis', 'banach-spaces', 'c-star-algebras', 'weak-convergence', 'amenability']"
72,Why does the sup norm make the results of approximation theory independent from the unknown distribution of the input data?,Why does the sup norm make the results of approximation theory independent from the unknown distribution of the input data?,,"I was reading the paper "" Why and When Can Deep – but Not Shallow – Networks Avoid the Curse of Dimensionality: a Review "" and I was trying to understand the following statement in section 3.1: On the other hand, our main results on compositionality require the   sup norm in order to be independent from the unknown distribution of   the inputa data. This is important for machine learning. my questions are: what does it mean that the sup norm $\| f \|_{\infty} = \sup_{x \in X} |f(x)|$ make the results of the respective paper independent of the input distribution? additionally, why does the sup norm $\| f \|_{\infty} = \sup_{x \in X} |f(x)|$ make the results of the respective paper independent of the input distribution? Why is that important for machine learning? I don't know the answers, maybe because of my lack of experience in functional analysis and approximation theory but my guesses what the answer might be are: I think what it means is that since the paper is concerned with proving bounds on the smallest distance between a target function and a space of functions (space of Neural Networks) denoted by the degree of approximation $dist(f,V_N) = \inf_{P \in V_N} \|f - P \|_{\infty}$, then what I assume it claims is that upper bounds on this quantity are independent (not a function of) the probability distribution of the input space $X$ where $f:X \to Y$. Does it matter because it means it applies to any distribution of $X$? I guess the reason I find this confusing is that I don't particularly see an issue with it dependent on the data distribution. I think what matters more is that the bound on the degree of approximation is not vacuous.i i.e. that its not infinity. If it is infinity for some distribution then the results are useless. However, I don't see why independence on the distribution would matter, I'd assume that boundedness or compactness rather than distribution is what matters (since its what makes things not explode). I don't understand why the sup norm make things not explode. The reason things should not explode should be due to boundedness or compactness, not anything to do with the sup norm. I guess obviously the sup norm implies things don't explode if its bounded, but that happens because of a apriori boundedness/compactness assumption, not due to the sup norm, right? I guess its important for machine learning because they care things hold for any probability/data distribution. But as I've said before, I don't understand how talking about data distribution matters. In my opinion it doesn't matter, since thats not what makes things explode, what matters is the boundedness/compactness of $X$, $f(x)$ and $Y$ Is this on the right track? Or am I misunderstanding the paper a lot?","I was reading the paper "" Why and When Can Deep – but Not Shallow – Networks Avoid the Curse of Dimensionality: a Review "" and I was trying to understand the following statement in section 3.1: On the other hand, our main results on compositionality require the   sup norm in order to be independent from the unknown distribution of   the inputa data. This is important for machine learning. my questions are: what does it mean that the sup norm $\| f \|_{\infty} = \sup_{x \in X} |f(x)|$ make the results of the respective paper independent of the input distribution? additionally, why does the sup norm $\| f \|_{\infty} = \sup_{x \in X} |f(x)|$ make the results of the respective paper independent of the input distribution? Why is that important for machine learning? I don't know the answers, maybe because of my lack of experience in functional analysis and approximation theory but my guesses what the answer might be are: I think what it means is that since the paper is concerned with proving bounds on the smallest distance between a target function and a space of functions (space of Neural Networks) denoted by the degree of approximation $dist(f,V_N) = \inf_{P \in V_N} \|f - P \|_{\infty}$, then what I assume it claims is that upper bounds on this quantity are independent (not a function of) the probability distribution of the input space $X$ where $f:X \to Y$. Does it matter because it means it applies to any distribution of $X$? I guess the reason I find this confusing is that I don't particularly see an issue with it dependent on the data distribution. I think what matters more is that the bound on the degree of approximation is not vacuous.i i.e. that its not infinity. If it is infinity for some distribution then the results are useless. However, I don't see why independence on the distribution would matter, I'd assume that boundedness or compactness rather than distribution is what matters (since its what makes things not explode). I don't understand why the sup norm make things not explode. The reason things should not explode should be due to boundedness or compactness, not anything to do with the sup norm. I guess obviously the sup norm implies things don't explode if its bounded, but that happens because of a apriori boundedness/compactness assumption, not due to the sup norm, right? I guess its important for machine learning because they care things hold for any probability/data distribution. But as I've said before, I don't understand how talking about data distribution matters. In my opinion it doesn't matter, since thats not what makes things explode, what matters is the boundedness/compactness of $X$, $f(x)$ and $Y$ Is this on the right track? Or am I misunderstanding the paper a lot?",,"['real-analysis', 'functional-analysis', 'machine-learning', 'approximation-theory', 'neural-networks']"
73,If $B$ is a subset of a Banach space is it true that if $\operatorname{span} B$ is closed then $\operatorname{span} B$ is finite dimensional,If  is a subset of a Banach space is it true that if  is closed then  is finite dimensional,B \operatorname{span} B \operatorname{span} B,"Let $V$ be a separable Banach space Let $B \subset V$ be a linearly independent, closed and bounded subset of $V$ I would like to know if is it true that $$ \operatorname{span} B \text{ is closed } \Longrightarrow  \operatorname{span} B \text { is finite dimensional} $$ thanks","Let $V$ be a separable Banach space Let $B \subset V$ be a linearly independent, closed and bounded subset of $V$ I would like to know if is it true that $$ \operatorname{span} B \text{ is closed } \Longrightarrow  \operatorname{span} B \text { is finite dimensional} $$ thanks",,"['functional-analysis', 'banach-spaces']"
74,Commuting Operator,Commuting Operator,,"If we consider the operator $T(f) = \int_0^x f(t)dt$ on the Banach space $C[0,1]$, is it possible to classify all linear operators $A$ such that $AT=TA$? Intutively, I feel like $AT=TA$, then it must be the case that either $A=T$ or $A$ is given by covolution.  Does anyone have any ideas if my hunch might be true?","If we consider the operator $T(f) = \int_0^x f(t)dt$ on the Banach space $C[0,1]$, is it possible to classify all linear operators $A$ such that $AT=TA$? Intutively, I feel like $AT=TA$, then it must be the case that either $A=T$ or $A$ is given by covolution.  Does anyone have any ideas if my hunch might be true?",,"['functional-analysis', 'analysis', 'operator-theory', 'compact-operators']"
75,Showing that the dual of a (general) product of normed spaces is isomorphically isometric to the product of the duals,Showing that the dual of a (general) product of normed spaces is isomorphically isometric to the product of the duals,,"This is Problem III.5.4 in Conway's $\textit{Functional Analysis}$: Let $\{X_i\}_{i\in I}$ be a collection of normed spaces. If $1 \leq p < \infty$ and $q$ is the conjugate exponent to $p$, then $\left( \oplus_p X_i \right)^*$ is isometrically isomorphic to $\oplus_q X_i^*$. Here, $\oplus_p X_i = \left\{ \textbf{x} \in \prod\limits_{i \in I}X_i : \lVert \textbf{x} \rVert := \left[ \sum\limits_{i\in I} \lVert x_i\rVert^p \right]^{1/p} < \infty  \right\}$. I'm fairly certain that I have to do this directly by producing a candidate operator $$T : \left( \oplus_p X_i \right)^* \to \oplus_q X_i^*$$ then showing it satisfies what I need, but I'm having difficulty doing so. Any help would be appreciated!","This is Problem III.5.4 in Conway's $\textit{Functional Analysis}$: Let $\{X_i\}_{i\in I}$ be a collection of normed spaces. If $1 \leq p < \infty$ and $q$ is the conjugate exponent to $p$, then $\left( \oplus_p X_i \right)^*$ is isometrically isomorphic to $\oplus_q X_i^*$. Here, $\oplus_p X_i = \left\{ \textbf{x} \in \prod\limits_{i \in I}X_i : \lVert \textbf{x} \rVert := \left[ \sum\limits_{i\in I} \lVert x_i\rVert^p \right]^{1/p} < \infty  \right\}$. I'm fairly certain that I have to do this directly by producing a candidate operator $$T : \left( \oplus_p X_i \right)^* \to \oplus_q X_i^*$$ then showing it satisfies what I need, but I'm having difficulty doing so. Any help would be appreciated!",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
76,"Non-equivalence $p$-norm on $\ell_p$, $L_p(X, \mu)$ to any inner product norm","Non-equivalence -norm on ,  to any inner product norm","p \ell_p L_p(X, \mu)","Show that the norm on the spaces $\ell_p$ , $L_p(X, \mu)$ (where $(X, \mu)$ is a measure space containing infinitely many disjoint measurable sets of positive measure) is not equivalent to a norm generated by an inner product (unless $p = 2$ ). I have trouble with this exercise. I don't know what to start from. In previous exercises I showed that the norm on the spaces $(\Bbb C^n, ∥ · ∥_p)$ , $\ell_p$ , $(C [a, b], ∥ · ∥_p)$ , $L_p (X, \mu)$ is not generated by an inner product (unless $n = 1$ , $p = 2$ ). I also generalized the inequality of the parallelogram on $n$ vectors. I think it's necessary. It is possible to construct many different inner products, but how to show non-equivalence?","Show that the norm on the spaces , (where is a measure space containing infinitely many disjoint measurable sets of positive measure) is not equivalent to a norm generated by an inner product (unless ). I have trouble with this exercise. I don't know what to start from. In previous exercises I showed that the norm on the spaces , , , is not generated by an inner product (unless , ). I also generalized the inequality of the parallelogram on vectors. I think it's necessary. It is possible to construct many different inner products, but how to show non-equivalence?","\ell_p L_p(X, \mu) (X, \mu) p = 2 (\Bbb C^n, ∥ · ∥_p) \ell_p (C [a, b], ∥ · ∥_p) L_p (X, \mu) n = 1 p = 2 n","['functional-analysis', 'measure-theory', 'banach-spaces', 'normed-spaces']"
77,On Hahn-Banach Theorem,On Hahn-Banach Theorem,,"The following is the first part of a proof for Hahn-Banach Theorem (Extension of linear functionals) from Kreyszig's book of Functional Analysis: I don't undertsand the blue-underlined sentence of the text above. My questions are: 1- How each $D(g)$ is a vector space? Suppose $x_1, \ x_2 \in D(g)$ then $g(x_1) \le p(x_1)$ and $g(x_2) \le p(x_2)$. Then $g(x_1+x_2) = g(x_1)+g(x_2) \le p(x_1)+p(x_2)$ does not imply $g(x_1+x_2) \le p(x_1+x_2)$, because we have $p(x_1+x_2)\le p(x_1+x_2)$ by definition. So How $x_1+x_2 \in D(g)$?! The book has considered $a \ge 0$, so $g(ax) = ag(x) \ge ap(x)$. So the problem is just the sum inequality. 2- How $\bigcup D(g)$ is a vector space because ""$C$ is a chain""? I can't see a coonection.","The following is the first part of a proof for Hahn-Banach Theorem (Extension of linear functionals) from Kreyszig's book of Functional Analysis: I don't undertsand the blue-underlined sentence of the text above. My questions are: 1- How each $D(g)$ is a vector space? Suppose $x_1, \ x_2 \in D(g)$ then $g(x_1) \le p(x_1)$ and $g(x_2) \le p(x_2)$. Then $g(x_1+x_2) = g(x_1)+g(x_2) \le p(x_1)+p(x_2)$ does not imply $g(x_1+x_2) \le p(x_1+x_2)$, because we have $p(x_1+x_2)\le p(x_1+x_2)$ by definition. So How $x_1+x_2 \in D(g)$?! The book has considered $a \ge 0$, so $g(ax) = ag(x) \ge ap(x)$. So the problem is just the sum inequality. 2- How $\bigcup D(g)$ is a vector space because ""$C$ is a chain""? I can't see a coonection.",,['functional-analysis']
78,"For a complex Banach space $X$ and an open $U\subset\Bbb C$, is a ""weakly holomorphic"" $f:U\to X$ also strongly holomorphic?","For a complex Banach space  and an open , is a ""weakly holomorphic""  also strongly holomorphic?",X U\subset\Bbb C f:U\to X,"For any complex Banach space $X$ and any open $U\subset\Bbb C$, we say that a function $f:U\to X$ is holomorphic at a point $z_0\in U$ if for $|z-z_0|$ sufficiently small, we can express $f$ as $$f(z)=\sum_{k=0}^\infty a_k (z-z_0)^k$$ where $a_k\in X$ for all $k$, and where the sum converges absolutely. We say that $f:U\to X$ is (strongly) holomorphic if it is holomorphic at every point in $U$. Meanwhile, we say that a function $f:U\to X$ is weakly holomorphic if for every $x'\in X'$, the function $$\langle x',f\rangle:U\to\Bbb C$$ is holomorphic. Now, it's easy to see that any holomorphic function is weakly holomorphic, but does the converse hold?","For any complex Banach space $X$ and any open $U\subset\Bbb C$, we say that a function $f:U\to X$ is holomorphic at a point $z_0\in U$ if for $|z-z_0|$ sufficiently small, we can express $f$ as $$f(z)=\sum_{k=0}^\infty a_k (z-z_0)^k$$ where $a_k\in X$ for all $k$, and where the sum converges absolutely. We say that $f:U\to X$ is (strongly) holomorphic if it is holomorphic at every point in $U$. Meanwhile, we say that a function $f:U\to X$ is weakly holomorphic if for every $x'\in X'$, the function $$\langle x',f\rangle:U\to\Bbb C$$ is holomorphic. Now, it's easy to see that any holomorphic function is weakly holomorphic, but does the converse hold?",,"['complex-analysis', 'functional-analysis', 'banach-spaces']"
79,"A linear operator $Tx=(x_1,x_1+x_2,x_1+x_3,\dots)$ between $c_0$ and $c$ and its norm",A linear operator  between  and  and its norm,"Tx=(x_1,x_1+x_2,x_1+x_3,\dots) c_0 c","The operator $T$ is for $x=(x_n)_{n=1}^\infty \in c_0$ given by $$ Tx=(x_1,x_1+x_2,x_1+x_3,\dots).$$   Show that $T$ is a bounded linear operator between $c_0$ and $c$ and calculate $||T||$. Is $T$ injective, surjective? First I would like you to have a look at my answer to the second question. It is indeed injective as for each two distinct $x$ and $y$ the images are also distinct: if $x_1 \ne y_1$ (possibly some other coordinates are different too), then $Tx$ surely differs from $Ty$ in the first coordinate and if $x_1=y_1$ and there are differences between the two in some elements $n \ge2$, than $n$th coordinates of $Tx$ and $Ty$ are not equal. As for surjectivity, I reckon $\lim_{n \rightarrow \infty} (x_1+x_n)=x_1+\lim_{n \rightarrow \infty}x_n=x_1$ and since $x_1$ is an arbitrary number then every number can be obtained as a limit but I feel I'm missing something here. As far as $||T||$ goes, firstly let's take $ x=(1,1,0,0,0,\dots) \in c_0, ||x||=1$ and the definition $||T||=\sup_{||x||=1}||Tx||$ yields $||T|| \ge 2$. On the other hand, $||Tx||=\sup_{n\ge2}\{|x_1|,|x_1+x_n|\} \le 2\sup_n|x_n|=2||x||$, hence $||T|| \le 2$. All in all, $||T||=2$. I'd appreciate any remarks on the correctness of my solution.","The operator $T$ is for $x=(x_n)_{n=1}^\infty \in c_0$ given by $$ Tx=(x_1,x_1+x_2,x_1+x_3,\dots).$$   Show that $T$ is a bounded linear operator between $c_0$ and $c$ and calculate $||T||$. Is $T$ injective, surjective? First I would like you to have a look at my answer to the second question. It is indeed injective as for each two distinct $x$ and $y$ the images are also distinct: if $x_1 \ne y_1$ (possibly some other coordinates are different too), then $Tx$ surely differs from $Ty$ in the first coordinate and if $x_1=y_1$ and there are differences between the two in some elements $n \ge2$, than $n$th coordinates of $Tx$ and $Ty$ are not equal. As for surjectivity, I reckon $\lim_{n \rightarrow \infty} (x_1+x_n)=x_1+\lim_{n \rightarrow \infty}x_n=x_1$ and since $x_1$ is an arbitrary number then every number can be obtained as a limit but I feel I'm missing something here. As far as $||T||$ goes, firstly let's take $ x=(1,1,0,0,0,\dots) \in c_0, ||x||=1$ and the definition $||T||=\sup_{||x||=1}||Tx||$ yields $||T|| \ge 2$. On the other hand, $||Tx||=\sup_{n\ge2}\{|x_1|,|x_1+x_n|\} \le 2\sup_n|x_n|=2||x||$, hence $||T|| \le 2$. All in all, $||T||=2$. I'd appreciate any remarks on the correctness of my solution.",,"['functional-analysis', 'operator-theory', 'normed-spaces']"
80,Gelfand Triples / Rigged Hilbert Spaces - Reflexivity necessary?,Gelfand Triples / Rigged Hilbert Spaces - Reflexivity necessary?,,"There have been several questions asked on various aspects of Gelfand triples. However, I have not yet found an answer to the following question: Let $V$ be a Banach space, $H$ be a Hilbert space such that we have a dense embedding $$ i :V \hookrightarrow H. $$ We then consider the ""adjoint map"" $$ i^{*} : H^{*} \rightarrow V^{*} $$ which is defined via $$ _{V^{*}}\langle i^{*}(\phi), v \rangle_{V} :=~ _{H^{*}} \langle \phi, i(v) \rangle_{H} $$ (intuitively, if $V \subset H$ as sets, one can think of the action of $i^{*}$ as being the restriction of a functional on $H$ to a functional on $V$). We would like this map $i^{*}$ to have three properties: continuous injective with dense image, i.e. $i^{*}(H^{*}) \subset V^{*}$ is a dense subset w.r.t. the norm on $V^{*}$. If we have established this, we can proceed to find the Gelfand triple  $$ V \hookrightarrow H \equiv H^{*} \hookrightarrow V^{*} $$  with dense embeddings. The first property is easy to check, the second follows from the density of $i$. However, for the third property, one needs (or rather: seems to need) something more. Brezis, in his functional analysis book, for example, assumes reflexivity (Rem. 5.2.3 on p. 136 in the 2011 edition) and so do Liu/Röckner ( SPDEs: An Introduction , Ch. 4.1, p. 69), Zeidler ( Linear Monotone Operators , Ch. 23.4, p. 416) and all other books I could get my hands on. As I will show below, reflexivity is sufficient indeed, but here is my question : Is reflexivity also necessary for property 3? That it works if $V$ is assumed to be reflexive can be seen as follows: Let $c$ denote the canonical map $$ c : V \rightarrow V^{**}, ~ v \mapsto \psi_{v}, ~ \psi_{v}(v^{*}) := v^{*}(v), $$ i.e. $c(v)(v^{*}) := v^{*}(v)$. If $V$ is reflexive, $c$ is surjective. Now to prove the density of $i^{*}(H^{*}) \subset V^{*}$ we need to check that if a continuous functional $\psi$ on $V^{*}$, i.e. $\psi \in V^{**}$, is zero on the image, then it must already be the zero functional, i.e. $\psi = 0$. So the condition we need to check is $$ _{V^{**}} \langle \psi, i^{*}(\phi) \rangle_{V^{*}} = 0 \quad \forall \phi \in H^{*} \quad \Rightarrow \quad \psi = 0. $$ By reflexivity, $\psi = c(v)$ for a $v \in V$. So let $\phi \in H^{*}  $ be arbitrary. By the definition of $c$ and $i^{*}$ we get \begin{align*} 0 &= ~_{V^{**}} \langle \psi, i^{*}(\phi) \rangle_{V^{*}} = ~_{V^{**}} \langle c(v), i^{*}(\phi) \rangle_{V^{*}} = ~_{V^{*}} \langle i^{*}(\phi), v \rangle_{V} \\ &= ~_{H^{*}} \langle \phi, i(v) \rangle_{H}. \end{align*} Since this holds true for every $\phi \in H^{*}$, by Hahn-Banach (or rather, since $H^{*}$ separates points on $H$), this implies $i(v) = 0$ which by the injectivity of $i$ yields $v = 0$ and hence by linearity of $c$ that $\psi = c(v) = 0$.","There have been several questions asked on various aspects of Gelfand triples. However, I have not yet found an answer to the following question: Let $V$ be a Banach space, $H$ be a Hilbert space such that we have a dense embedding $$ i :V \hookrightarrow H. $$ We then consider the ""adjoint map"" $$ i^{*} : H^{*} \rightarrow V^{*} $$ which is defined via $$ _{V^{*}}\langle i^{*}(\phi), v \rangle_{V} :=~ _{H^{*}} \langle \phi, i(v) \rangle_{H} $$ (intuitively, if $V \subset H$ as sets, one can think of the action of $i^{*}$ as being the restriction of a functional on $H$ to a functional on $V$). We would like this map $i^{*}$ to have three properties: continuous injective with dense image, i.e. $i^{*}(H^{*}) \subset V^{*}$ is a dense subset w.r.t. the norm on $V^{*}$. If we have established this, we can proceed to find the Gelfand triple  $$ V \hookrightarrow H \equiv H^{*} \hookrightarrow V^{*} $$  with dense embeddings. The first property is easy to check, the second follows from the density of $i$. However, for the third property, one needs (or rather: seems to need) something more. Brezis, in his functional analysis book, for example, assumes reflexivity (Rem. 5.2.3 on p. 136 in the 2011 edition) and so do Liu/Röckner ( SPDEs: An Introduction , Ch. 4.1, p. 69), Zeidler ( Linear Monotone Operators , Ch. 23.4, p. 416) and all other books I could get my hands on. As I will show below, reflexivity is sufficient indeed, but here is my question : Is reflexivity also necessary for property 3? That it works if $V$ is assumed to be reflexive can be seen as follows: Let $c$ denote the canonical map $$ c : V \rightarrow V^{**}, ~ v \mapsto \psi_{v}, ~ \psi_{v}(v^{*}) := v^{*}(v), $$ i.e. $c(v)(v^{*}) := v^{*}(v)$. If $V$ is reflexive, $c$ is surjective. Now to prove the density of $i^{*}(H^{*}) \subset V^{*}$ we need to check that if a continuous functional $\psi$ on $V^{*}$, i.e. $\psi \in V^{**}$, is zero on the image, then it must already be the zero functional, i.e. $\psi = 0$. So the condition we need to check is $$ _{V^{**}} \langle \psi, i^{*}(\phi) \rangle_{V^{*}} = 0 \quad \forall \phi \in H^{*} \quad \Rightarrow \quad \psi = 0. $$ By reflexivity, $\psi = c(v)$ for a $v \in V$. So let $\phi \in H^{*}  $ be arbitrary. By the definition of $c$ and $i^{*}$ we get \begin{align*} 0 &= ~_{V^{**}} \langle \psi, i^{*}(\phi) \rangle_{V^{*}} = ~_{V^{**}} \langle c(v), i^{*}(\phi) \rangle_{V^{*}} = ~_{V^{*}} \langle i^{*}(\phi), v \rangle_{V} \\ &= ~_{H^{*}} \langle \phi, i(v) \rangle_{H}. \end{align*} Since this holds true for every $\phi \in H^{*}$, by Hahn-Banach (or rather, since $H^{*}$ separates points on $H$), this implies $i(v) = 0$ which by the injectivity of $i$ yields $v = 0$ and hence by linearity of $c$ that $\psi = c(v) = 0$.",,"['functional-analysis', 'partial-differential-equations', 'hilbert-spaces', 'banach-spaces', 'adjoint-operators']"
81,Sobolev Embeddings (reference request),Sobolev Embeddings (reference request),,"The following two results are often used in research papers: $$W^{2,1}_p(J\times \Omega)\hookrightarrow L^\infty(J\times\Omega)\qquad\text{and}\qquad \|u^2\|_{L^p(J\times\Omega)}\le \|u\|^2_{W^{2,1}_p(J\times \Omega)},$$   where $$W^{2,1}_p(J\times \Omega):=L^p(J,W^2_p(\Omega))\cap W^1_p(J,L^p(\Omega)),\qquad J\subset\mathbb{R},\quad \Omega\subset\mathbb{R}^n\quad\text{bounded, smooth}$$ However, I could not find a book/article/proof I could use as a reference for these embeddings. It is not clear to me why these results hold and for which $p$ it holds. I suppose that there is a lower bound for $p$?","The following two results are often used in research papers: $$W^{2,1}_p(J\times \Omega)\hookrightarrow L^\infty(J\times\Omega)\qquad\text{and}\qquad \|u^2\|_{L^p(J\times\Omega)}\le \|u\|^2_{W^{2,1}_p(J\times \Omega)},$$   where $$W^{2,1}_p(J\times \Omega):=L^p(J,W^2_p(\Omega))\cap W^1_p(J,L^p(\Omega)),\qquad J\subset\mathbb{R},\quad \Omega\subset\mathbb{R}^n\quad\text{bounded, smooth}$$ However, I could not find a book/article/proof I could use as a reference for these embeddings. It is not clear to me why these results hold and for which $p$ it holds. I suppose that there is a lower bound for $p$?",,"['real-analysis', 'functional-analysis', 'reference-request', 'sobolev-spaces', 'book-recommendation']"
82,Non-compact operator with compact derivative,Non-compact operator with compact derivative,,"Let $T:X \to Y$ be a nonlinear operator between Hilbert spaces. Is it possible for $h \mapsto T'(x)[h]$ to be a compact mapping from $X$ to $Y$ even if $T$ is not compact?  Here $T'(x)[h]$ is the directional derivative of $T$ at $x$ in the direction $h$. If so, is it possible to classify all such $T$?","Let $T:X \to Y$ be a nonlinear operator between Hilbert spaces. Is it possible for $h \mapsto T'(x)[h]$ to be a compact mapping from $X$ to $Y$ even if $T$ is not compact?  Here $T'(x)[h]$ is the directional derivative of $T$ at $x$ in the direction $h$. If so, is it possible to classify all such $T$?",,"['functional-analysis', 'derivatives', 'operator-theory', 'compact-operators']"
83,Is the property of being an inner product space a topological notion?,Is the property of being an inner product space a topological notion?,,"Let $(E,\lVert\cdot\rVert)$ denote a normed vector space. Recall that an inner product space $E$ is a NVS with an additional gadget, namely an inner product that induces the norm. But, a NVS space $E$ is an IPS if and only if the norm satisfies the parallelogram law, i.e. if for all $x,y\in E$, $$\lVert x+y\rVert^2 + \lVert x-y\rVert^2 = 2\lVert x\rVert^2 + 2\lVert y\rVert^2$$ which allows us to define an inner product by letting $$\langle x,y\rangle = \frac12\left(\lVert x+y\rVert^2-\lVert x\rVert^2 - \lVert y\rVert^2\right).$$ Now, this tells us that the inner product is uniquely determined by the NVS structure. Can we take this further? Can we say that the IPS structure on $E$ is uniquely defined by the structure of $E$ as a topological vector space? Or do there exist non isomorphic IPS's that are isomorphic as topological vector spaces?","Let $(E,\lVert\cdot\rVert)$ denote a normed vector space. Recall that an inner product space $E$ is a NVS with an additional gadget, namely an inner product that induces the norm. But, a NVS space $E$ is an IPS if and only if the norm satisfies the parallelogram law, i.e. if for all $x,y\in E$, $$\lVert x+y\rVert^2 + \lVert x-y\rVert^2 = 2\lVert x\rVert^2 + 2\lVert y\rVert^2$$ which allows us to define an inner product by letting $$\langle x,y\rangle = \frac12\left(\lVert x+y\rVert^2-\lVert x\rVert^2 - \lVert y\rVert^2\right).$$ Now, this tells us that the inner product is uniquely determined by the NVS structure. Can we take this further? Can we say that the IPS structure on $E$ is uniquely defined by the structure of $E$ as a topological vector space? Or do there exist non isomorphic IPS's that are isomorphic as topological vector spaces?",,['functional-analysis']
84,Suppose $f\in\mathbf{C^2}(\mathbb{R})$ and is periodic with period $2\pi$. Prove the Fourier series of $f$ converges uniformly in any finite interval.,Suppose  and is periodic with period . Prove the Fourier series of  converges uniformly in any finite interval.,f\in\mathbf{C^2}(\mathbb{R}) 2\pi f,"Suppose $f\in\mathbf{C^2}(\mathbb{R})$ and is periodic with period $2\pi$. Prove that the Fourier series of $f$ converges uniformly in any finite interval. My attempt: $|a_n~\cos(nx)+b_n~\sin(nx)|\le|a_n|+|b_n|$. So, by M-test, we just need to show $\displaystyle\sum_{n=1}^\infty |a_n|+|b_n|$ converges. $$\begin{equation}\begin{aligned} a_n=\frac{1}{\pi} \int_{-\pi}^\pi~f(x)~\cos(nx)~dx &= -\frac{1}{n\pi}\int_{-\pi}^{\pi}~ f'(x)~\sin(nx)~dx \\ &=\frac{1}{n^2\pi}~ f'(x)~\cos(nx)~dx\Bigg|_{-\pi}^{\pi}-\frac{1}{n^2\pi}~f''(x)~\cos(nx)~dx\\ \end{aligned}\end{equation}$$ $$=\frac{1}{n^2\pi}[f(\pi)~\cos(nx)-f(-\pi)~\sin(nx)]+\frac{1}{n^2\pi}\int_{-\pi}^{\pi} f''(x)~\cos(nx)dx$$ $f\in\mathbf{C^2}(\mathbb{R})\Rightarrow |f|,|f''|\leq K$ on $[-\pi,\pi]$ for some $K$. We can get $a_n\leq \frac{4K}{n^2}$.  Similarly, $b_n\leq\frac{4M}{n^2}$. So, $M_n=\displaystyle\sum_{n=1}^\infty |a_n|+|b_n|$ converges. So, the Fourier series $\displaystyle\sum_{n=1}^\infty [a_n~\cos(nx)+b_n~\sin(nx)]$  converges unifomly. Is my proof correct? It seems that for any $x\in \mathbb{R}$, the Fourier series converges uniformly. Why we cannot conclude that the Fourier series of $f$ converges uniformly on $\mathbb{R}?$","Suppose $f\in\mathbf{C^2}(\mathbb{R})$ and is periodic with period $2\pi$. Prove that the Fourier series of $f$ converges uniformly in any finite interval. My attempt: $|a_n~\cos(nx)+b_n~\sin(nx)|\le|a_n|+|b_n|$. So, by M-test, we just need to show $\displaystyle\sum_{n=1}^\infty |a_n|+|b_n|$ converges. $$\begin{equation}\begin{aligned} a_n=\frac{1}{\pi} \int_{-\pi}^\pi~f(x)~\cos(nx)~dx &= -\frac{1}{n\pi}\int_{-\pi}^{\pi}~ f'(x)~\sin(nx)~dx \\ &=\frac{1}{n^2\pi}~ f'(x)~\cos(nx)~dx\Bigg|_{-\pi}^{\pi}-\frac{1}{n^2\pi}~f''(x)~\cos(nx)~dx\\ \end{aligned}\end{equation}$$ $$=\frac{1}{n^2\pi}[f(\pi)~\cos(nx)-f(-\pi)~\sin(nx)]+\frac{1}{n^2\pi}\int_{-\pi}^{\pi} f''(x)~\cos(nx)dx$$ $f\in\mathbf{C^2}(\mathbb{R})\Rightarrow |f|,|f''|\leq K$ on $[-\pi,\pi]$ for some $K$. We can get $a_n\leq \frac{4K}{n^2}$.  Similarly, $b_n\leq\frac{4M}{n^2}$. So, $M_n=\displaystyle\sum_{n=1}^\infty |a_n|+|b_n|$ converges. So, the Fourier series $\displaystyle\sum_{n=1}^\infty [a_n~\cos(nx)+b_n~\sin(nx)]$  converges unifomly. Is my proof correct? It seems that for any $x\in \mathbb{R}$, the Fourier series converges uniformly. Why we cannot conclude that the Fourier series of $f$ converges uniformly on $\mathbb{R}?$",,"['real-analysis', 'functional-analysis', 'analysis', 'fourier-analysis']"
85,Example of a linear operator whose graph is not closed but it takes a closed set to a closed set,Example of a linear operator whose graph is not closed but it takes a closed set to a closed set,,"I want an example of a linear operator $T:X\to Y$, where $X$ and $Y$ are normed linear spaces, such that graph of $T$ is not closed but $T$ maps closed sets of $X$ to closed sets in $Y$. For functions other than linear operators it is not that difficult. If we consider $f:\mathbb R\to \mathbb R$ by $f(0)=0$ and $f(x)=1$ for all $x\in \mathbb R\setminus \{0\}$, then $f$ maps every subset of $\mathbb R$ to a closed set in $\mathbb R$ but grapf of $f$ is not closed. Any help will be appreciated. We know that there always exists a discontinuous linear functional $f:X\to \mathbb R$, where $X$ is an infinite dimensional normed linear space. If $f:c_0\to \mathbb R$ is a discontinuous linear functional then for every $n>0$, there exists $x^{(n)}\in c_0$ such that $|f(x^{(n)})|>n\|x^{(n)}\|_{\infty}$. Now we define $T:c_0\to c_0$ by $T(x)=(f(x),x_1,x_2,\ldots)$ for all $x\in c_0$. Then $\|T(x^{(n)})\|_{\infty}=\sup\{|f(x^{(n)})|,|x_1|,|x_2|,\ldots\}>n\|x^{(n)}\|_{\infty}$. Thus $T$ is a discontinuous linear operator. Since $c_0$ is a Banach space, therefore graph of $T$ is not closed. Is the function $T$ maps every closed set in $c_0$ to a closed subset of $c_0$?","I want an example of a linear operator $T:X\to Y$, where $X$ and $Y$ are normed linear spaces, such that graph of $T$ is not closed but $T$ maps closed sets of $X$ to closed sets in $Y$. For functions other than linear operators it is not that difficult. If we consider $f:\mathbb R\to \mathbb R$ by $f(0)=0$ and $f(x)=1$ for all $x\in \mathbb R\setminus \{0\}$, then $f$ maps every subset of $\mathbb R$ to a closed set in $\mathbb R$ but grapf of $f$ is not closed. Any help will be appreciated. We know that there always exists a discontinuous linear functional $f:X\to \mathbb R$, where $X$ is an infinite dimensional normed linear space. If $f:c_0\to \mathbb R$ is a discontinuous linear functional then for every $n>0$, there exists $x^{(n)}\in c_0$ such that $|f(x^{(n)})|>n\|x^{(n)}\|_{\infty}$. Now we define $T:c_0\to c_0$ by $T(x)=(f(x),x_1,x_2,\ldots)$ for all $x\in c_0$. Then $\|T(x^{(n)})\|_{\infty}=\sup\{|f(x^{(n)})|,|x_1|,|x_2|,\ldots\}>n\|x^{(n)}\|_{\infty}$. Thus $T$ is a discontinuous linear operator. Since $c_0$ is a Banach space, therefore graph of $T$ is not closed. Is the function $T$ maps every closed set in $c_0$ to a closed subset of $c_0$?",,"['functional-analysis', 'banach-spaces', 'linear-transformations', 'closed-graph', 'closed-map']"
86,Spectrum of Diagonal Operator in $\ell^2$,Spectrum of Diagonal Operator in,\ell^2,"This question is from Kreyszig 7.3, #4-6: Let $T: \ell^2 \rightarrow \ell^2$ be defined by $y = Tx, x = (x_i), y = (y_i), y_i = a_ix_i$ where $(a_i)$ are dense in [0,1]. Find $\sigma_p(T)$ and $\sigma(T)$. Moreover, show that if $\lambda \in \sigma-\sigma_p$ then $R_\lambda(T)$ is unbounded. (The definitions of spectrum can be found here ) Extending the foregoing problem: Find a linear operator $T: \ell^2 \rightarrow \ell^2$ whose eigenvalues are dense in a given compact set $K \subset \mathbf{C}$ and $\sigma(T) = K$. So far: My only steps so far were recognizing that $(a_i)$ should be in $\sigma_p$. I'm having trouble exhibiting a sequence that's in the spectrum but not in the point spectrum. I tried to use the second part of the first question by thinking about what would make $(T-\lambda I)$ unbounded but to no avail. Any thoughts? Thanks!","This question is from Kreyszig 7.3, #4-6: Let $T: \ell^2 \rightarrow \ell^2$ be defined by $y = Tx, x = (x_i), y = (y_i), y_i = a_ix_i$ where $(a_i)$ are dense in [0,1]. Find $\sigma_p(T)$ and $\sigma(T)$. Moreover, show that if $\lambda \in \sigma-\sigma_p$ then $R_\lambda(T)$ is unbounded. (The definitions of spectrum can be found here ) Extending the foregoing problem: Find a linear operator $T: \ell^2 \rightarrow \ell^2$ whose eigenvalues are dense in a given compact set $K \subset \mathbf{C}$ and $\sigma(T) = K$. So far: My only steps so far were recognizing that $(a_i)$ should be in $\sigma_p$. I'm having trouble exhibiting a sequence that's in the spectrum but not in the point spectrum. I tried to use the second part of the first question by thinking about what would make $(T-\lambda I)$ unbounded but to no avail. Any thoughts? Thanks!",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
87,"Does the ""2nd isomorphism theorem"" hold for Banach spaces, when one of the subspaces is finite-dimensional?","Does the ""2nd isomorphism theorem"" hold for Banach spaces, when one of the subspaces is finite-dimensional?",,"Let $X$ be a Banach space. Let $Y, F \subseteq X$ be subspaces with $Y$ closed and $F$ finite-dimensional. It follows that $F + Y$ is also a closed subspace of $X$. Question: Is there an isometric isomorphism of finite-dimensional Banach spaces between $\frac{F+Y}{Y}$ and $\frac{F}{F \cap Y}$?","Let $X$ be a Banach space. Let $Y, F \subseteq X$ be subspaces with $Y$ closed and $F$ finite-dimensional. It follows that $F + Y$ is also a closed subspace of $X$. Question: Is there an isometric isomorphism of finite-dimensional Banach spaces between $\frac{F+Y}{Y}$ and $\frac{F}{F \cap Y}$?",,"['functional-analysis', 'banach-spaces']"
88,Continuity of a linear operator in Schwartz Space,Continuity of a linear operator in Schwartz Space,,"Let $f: \mathbb{R}\rightarrow\mathbb{R}$ be a $\mathbb{C}^{\infty}$ function which is bounded. Define $A:\mathcal{S}(\mathbb{R})\rightarrow\mathcal{S}(\mathbb{R})$ as $A(\phi)=f\phi$. Is $A$ continuous? Intuitively, I think this should not be true. If we take a function $f$ which is bounded but has an unbounded derivative then for a sequence $\{\phi_n\}\rightarrow0$ in $\mathcal{S}(\mathbb{R})$, $\{f\phi_n\}\nrightarrow0$ in $\mathcal{S}(\mathbb{R})$. I thought of taking,  $f=\sin(x^2)$. However, I'm unable to find a suitable $\{\phi_n\}$. Note: $\mathcal{S}(\mathbb{R})$ is the Schwartz space.","Let $f: \mathbb{R}\rightarrow\mathbb{R}$ be a $\mathbb{C}^{\infty}$ function which is bounded. Define $A:\mathcal{S}(\mathbb{R})\rightarrow\mathcal{S}(\mathbb{R})$ as $A(\phi)=f\phi$. Is $A$ continuous? Intuitively, I think this should not be true. If we take a function $f$ which is bounded but has an unbounded derivative then for a sequence $\{\phi_n\}\rightarrow0$ in $\mathcal{S}(\mathbb{R})$, $\{f\phi_n\}\nrightarrow0$ in $\mathcal{S}(\mathbb{R})$. I thought of taking,  $f=\sin(x^2)$. However, I'm unable to find a suitable $\{\phi_n\}$. Note: $\mathcal{S}(\mathbb{R})$ is the Schwartz space.",,"['functional-analysis', 'fourier-analysis', 'sobolev-spaces', 'distribution-theory', 'schwartz-space']"
89,"$\lambda\in\sigma(A)\Leftrightarrow P_{(\lambda-\epsilon,\lambda+\epsilon)}\neq 0\;\forall \epsilon>0$",,"\lambda\in\sigma(A)\Leftrightarrow P_{(\lambda-\epsilon,\lambda+\epsilon)}\neq 0\;\forall \epsilon>0","I would be grateful for a proof of a proposition in Reed Simon I, Chapter VII.3. It states that for a bounded self-adjoint operator $A$ a point $\lambda$ is in the spectrum of $A$ if and only if for every $\epsilon>0$ the spectral projection $P_{(\lambda-\epsilon,\lambda+\epsilon)}$ is nonzero. As a hint they say that the main ingredient in the proof is the equality $\|(A-\lambda)^{-1}\|=\operatorname{dist}(\lambda,\sigma(A))^{-1}$, but I've got no clue how to use this.","I would be grateful for a proof of a proposition in Reed Simon I, Chapter VII.3. It states that for a bounded self-adjoint operator $A$ a point $\lambda$ is in the spectrum of $A$ if and only if for every $\epsilon>0$ the spectral projection $P_{(\lambda-\epsilon,\lambda+\epsilon)}$ is nonzero. As a hint they say that the main ingredient in the proof is the equality $\|(A-\lambda)^{-1}\|=\operatorname{dist}(\lambda,\sigma(A))^{-1}$, but I've got no clue how to use this.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
90,"If $(\mathcal D(A),A)$ is a linear operator, then $\mathcal D(A)\subseteq\mathcal D(A^{1/2})$","If  is a linear operator, then","(\mathcal D(A),A) \mathcal D(A)\subseteq\mathcal D(A^{1/2})","Let $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a $\mathbb R$-Hilbert space. We say that $(\mathcal D(A),A)$ is a linear operator , if $\mathcal D(A)$ is a subspace of $H$ and $A:\mathcal D(A)\to H$ is linear. Assume $(e_n)_{n\in\mathbb N}\subseteq\mathcal D(A)$ is an orthonormal basis of $H$ with $$Ae_n=\lambda_ne_n\;\;\;\text{for all }n\in\mathbb N\tag 1$$ for some $(\lambda_n)_{n\in\mathbb N}\subseteq(0,\infty)$ with $$\lambda_{n+1}\ge\lambda_n\;\;\;\text{for all }n\in\mathbb N\;.\tag 2$$ Let $\alpha\in\mathbb R$, $$\mathcal D(A^\alpha):=\left\{x\in H:\sum_{n\in\mathbb N}\lambda_n^{2\alpha}\left|\langle x,e_n\rangle_H\right|^2<\infty\right\}$$ and $$A^\alpha x:=\sum_{n\in\mathbb N}\lambda_n^\alpha\langle x,e_n\rangle_He_n\;\;\;\text{for }x\in\mathcal D(A^\alpha)\;.$$ How can we show that $\mathcal D(A^1)\subseteq\mathcal D(A^{1/2})$?$^1$ I would prove the claim in the following way: Let $x\in\mathcal D(A^1)$ and $$\lambda_{\text{sup}}:=\sup_{n\in\mathbb N}\lambda_n\;.$$ Case 1: $\lambda_{\text{sup}}<\infty$ and hence $$\sum_{n=1}^N\lambda_n\left|\langle x,e_n\rangle\right|^2\le\lambda_{\text{sup}}\sum_{n=1}^N\left|\langle x,e_n\rangle\right|^2\xrightarrow{N\to\infty}\lambda_{\text{sup}}\left\|x\right\|^2\tag 3$$ by Parseval's identity Case 2: $\lambda_{\text{sup}}=\infty$, hence $$\lambda_n\ge 1\;\;\;\text{for all }n\ge n_1\tag 4$$ for some $n_1\in\mathbb N$ and thereby $$\sum_{n=1}^N\lambda_n\left|\langle x,e_n\rangle\right|^2\le\sum_{n=1}^{n_1-1}\left|\langle x,e_n\rangle\right|^2+\sum_{n=n_1}^n\lambda_n^2\left|\langle x,e_n\rangle\right|^2\tag 5$$ where the second sum on the right-hand side of $(4)$ is convergent for $N\to\infty$ by definition of $\mathcal D(A^1)$ In both cases, we obtain $x\in\mathcal D(A^{1/2})$. However, for some reason I think that my argumentation is too complicated. Is there a simpler one? $^1$ Note that I've explicitly written $\mathcal D(A^1)$; not $\mathcal D(A)$. However, it should be clear that $A$ can be extended to $\mathcal D(A^1)$ if $\mathcal D(A)$ is a proper subset of $\mathcal D(A^1)$.","Let $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a $\mathbb R$-Hilbert space. We say that $(\mathcal D(A),A)$ is a linear operator , if $\mathcal D(A)$ is a subspace of $H$ and $A:\mathcal D(A)\to H$ is linear. Assume $(e_n)_{n\in\mathbb N}\subseteq\mathcal D(A)$ is an orthonormal basis of $H$ with $$Ae_n=\lambda_ne_n\;\;\;\text{for all }n\in\mathbb N\tag 1$$ for some $(\lambda_n)_{n\in\mathbb N}\subseteq(0,\infty)$ with $$\lambda_{n+1}\ge\lambda_n\;\;\;\text{for all }n\in\mathbb N\;.\tag 2$$ Let $\alpha\in\mathbb R$, $$\mathcal D(A^\alpha):=\left\{x\in H:\sum_{n\in\mathbb N}\lambda_n^{2\alpha}\left|\langle x,e_n\rangle_H\right|^2<\infty\right\}$$ and $$A^\alpha x:=\sum_{n\in\mathbb N}\lambda_n^\alpha\langle x,e_n\rangle_He_n\;\;\;\text{for }x\in\mathcal D(A^\alpha)\;.$$ How can we show that $\mathcal D(A^1)\subseteq\mathcal D(A^{1/2})$?$^1$ I would prove the claim in the following way: Let $x\in\mathcal D(A^1)$ and $$\lambda_{\text{sup}}:=\sup_{n\in\mathbb N}\lambda_n\;.$$ Case 1: $\lambda_{\text{sup}}<\infty$ and hence $$\sum_{n=1}^N\lambda_n\left|\langle x,e_n\rangle\right|^2\le\lambda_{\text{sup}}\sum_{n=1}^N\left|\langle x,e_n\rangle\right|^2\xrightarrow{N\to\infty}\lambda_{\text{sup}}\left\|x\right\|^2\tag 3$$ by Parseval's identity Case 2: $\lambda_{\text{sup}}=\infty$, hence $$\lambda_n\ge 1\;\;\;\text{for all }n\ge n_1\tag 4$$ for some $n_1\in\mathbb N$ and thereby $$\sum_{n=1}^N\lambda_n\left|\langle x,e_n\rangle\right|^2\le\sum_{n=1}^{n_1-1}\left|\langle x,e_n\rangle\right|^2+\sum_{n=n_1}^n\lambda_n^2\left|\langle x,e_n\rangle\right|^2\tag 5$$ where the second sum on the right-hand side of $(4)$ is convergent for $N\to\infty$ by definition of $\mathcal D(A^1)$ In both cases, we obtain $x\in\mathcal D(A^{1/2})$. However, for some reason I think that my argumentation is too complicated. Is there a simpler one? $^1$ Note that I've explicitly written $\mathcal D(A^1)$; not $\mathcal D(A)$. However, it should be clear that $A$ can be extended to $\mathcal D(A^1)$ if $\mathcal D(A)$ is a proper subset of $\mathcal D(A^1)$.",,"['functional-analysis', 'proof-verification', 'operator-theory']"
91,Does the form domain of the Friedrichs extension of an unbounded operator compactly embed?,Does the form domain of the Friedrichs extension of an unbounded operator compactly embed?,,"Say we have a Hilbert space $H$ and a positive symmetric operator $T$ with domain $D$. Define a norm $\|u\|_T = \langle Tu, u\rangle$ for $u\in D$ and take the completion of $D$ with respect to this norm to obtain a new Hilbert space $V$. Part of the construction of the Friedrichs extension of $T$ is that the inclusion map $D\hookrightarrow H$ extends to an injective bounded map $V\hookrightarrow H$. If $T$ is unbounded in $H$, is the inclusion $V\hookrightarrow H$ a compact embedding?","Say we have a Hilbert space $H$ and a positive symmetric operator $T$ with domain $D$. Define a norm $\|u\|_T = \langle Tu, u\rangle$ for $u\in D$ and take the completion of $D$ with respect to this norm to obtain a new Hilbert space $V$. Part of the construction of the Friedrichs extension of $T$ is that the inclusion map $D\hookrightarrow H$ extends to an injective bounded map $V\hookrightarrow H$. If $T$ is unbounded in $H$, is the inclusion $V\hookrightarrow H$ a compact embedding?",,['functional-analysis']
92,Basis for a vector space and normed space,Basis for a vector space and normed space,,While defining the basis for a vector space we impose two conditions (linearly independence and spaning) for the basis set. I am unable to see the condition of linearly independence in the case of schauder basis for a normed space. Can any body explain it to me why there is no need of being linearly independence for basis set in case of normed spaces and what is the role of linearly independence in case of vector space?,While defining the basis for a vector space we impose two conditions (linearly independence and spaning) for the basis set. I am unable to see the condition of linearly independence in the case of schauder basis for a normed space. Can any body explain it to me why there is no need of being linearly independence for basis set in case of normed spaces and what is the role of linearly independence in case of vector space?,,"['functional-analysis', 'normed-spaces', 'schauder-basis']"
93,Version of Hille-Yosida Theorem for non contractive semigroups,Version of Hille-Yosida Theorem for non contractive semigroups,,"We say that a semigroup $\{T(t)\}_{t\geq 0}$ of bounded linear operators on a Banach space $X$ is of type $(M,\omega)$ if there are constants $\omega\geq0$ and $M\geq 1$ such that $$\|T(t)\|_{\mathcal{L}}\leq M\mathrm{e}^{\omega t},\qquad\forall\ t\geq 0.$$ Let $A:D(A)\subset X\to X$ be a linear operator. The Hille-Yosida Theorem states: The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{1},0)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(0,\infty)\subseteq\rho(A)$ and   $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{1}}{\lambda},\quad\forall\ \lambda>0. $$ By considering the rescaled semigroup $S(t)=\mathrm{e}^{-\omega t}T(t)$, we get the version below. The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{1},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and   $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{1}}{\lambda-\omega},\quad\forall\ \lambda>\omega. $$ Concerning to Pazy's proof, it seems to me that the argument also works with $\color{red}{1}$ replaced by $\color{red}{M}$. So, I'd like to confirm if the following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{M},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and   $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{M}}{\lambda-\omega},\quad\forall\ \lambda>\omega.\tag{A}$$ I've never seen this version in any book. The usual generalization states: The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{M},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and   $$ \|(\lambda-A)^{-\color{red}{n}}\|_{\mathcal{L}}\leq\frac{\color{red}{M}}{(\lambda-\omega)^{\color{red}{n}}},\quad\forall\ \lambda>\omega,\;\color{red}{\forall\ n\in\mathbb{N}}. \tag{B}$$ The Wikipedia says that this version ""is mainly of theoretical importance since the estimates on the powers of the resolvent operator that appear in $(B)$ can usually not be checked in concrete examples"". On the other hand, it seems to me that if ""$5.\Leftrightarrow 6.$"" were true, then it would be of practical importance (because $(A)$ can be checked). So, if it is true, why it is not in the books? if it is not true, where the Pazy's argument fails?","We say that a semigroup $\{T(t)\}_{t\geq 0}$ of bounded linear operators on a Banach space $X$ is of type $(M,\omega)$ if there are constants $\omega\geq0$ and $M\geq 1$ such that $$\|T(t)\|_{\mathcal{L}}\leq M\mathrm{e}^{\omega t},\qquad\forall\ t\geq 0.$$ Let $A:D(A)\subset X\to X$ be a linear operator. The Hille-Yosida Theorem states: The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{1},0)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(0,\infty)\subseteq\rho(A)$ and   $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{1}}{\lambda},\quad\forall\ \lambda>0. $$ By considering the rescaled semigroup $S(t)=\mathrm{e}^{-\omega t}T(t)$, we get the version below. The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{1},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and   $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{1}}{\lambda-\omega},\quad\forall\ \lambda>\omega. $$ Concerning to Pazy's proof, it seems to me that the argument also works with $\color{red}{1}$ replaced by $\color{red}{M}$. So, I'd like to confirm if the following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{M},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and   $$ \|(\lambda-A)^{-1}\|_{\mathcal{L}}\leq\frac{\color{red}{M}}{\lambda-\omega},\quad\forall\ \lambda>\omega.\tag{A}$$ I've never seen this version in any book. The usual generalization states: The following conditions are equivalent: $A$ is the infinitesimal generator of a $C_0$-semigroup of type $(\color{red}{M},\omega)$ on $X$. $A$ is closed, $D(A)$ is dense in $X$, $(\omega,\infty)\subseteq\rho(A)$ and   $$ \|(\lambda-A)^{-\color{red}{n}}\|_{\mathcal{L}}\leq\frac{\color{red}{M}}{(\lambda-\omega)^{\color{red}{n}}},\quad\forall\ \lambda>\omega,\;\color{red}{\forall\ n\in\mathbb{N}}. \tag{B}$$ The Wikipedia says that this version ""is mainly of theoretical importance since the estimates on the powers of the resolvent operator that appear in $(B)$ can usually not be checked in concrete examples"". On the other hand, it seems to me that if ""$5.\Leftrightarrow 6.$"" were true, then it would be of practical importance (because $(A)$ can be checked). So, if it is true, why it is not in the books? if it is not true, where the Pazy's argument fails?",,"['functional-analysis', 'partial-differential-equations', 'semigroup-of-operators']"
94,spectrum of the multiplication operator for general measure spaces,spectrum of the multiplication operator for general measure spaces,,"Suppose $(X, \mu)$ is a measure space. If we additionally assume that $X$ is $\sigma$-finite, then for $f\in L^\infty(X, \mu)$, the spectrum of the multiplication operator $M_f$ on $L^2$ equals the essential range of $f$. Although $\sigma$-finiteness plays a role in the proof that I know for this statement, I'm not sure if the assumption can be dropped with a different proof. I wonder if anyone can provide a proof or a counterexample for this. (My feeling is that a counterexample should exist if $X$ is not $\sigma$-finite.) Thanks!","Suppose $(X, \mu)$ is a measure space. If we additionally assume that $X$ is $\sigma$-finite, then for $f\in L^\infty(X, \mu)$, the spectrum of the multiplication operator $M_f$ on $L^2$ equals the essential range of $f$. Although $\sigma$-finiteness plays a role in the proof that I know for this statement, I'm not sure if the assumption can be dropped with a different proof. I wonder if anyone can provide a proof or a counterexample for this. (My feeling is that a counterexample should exist if $X$ is not $\sigma$-finite.) Thanks!",,"['functional-analysis', 'operator-theory']"
95,Functional Taylor series,Functional Taylor series,,"The functional Taylor series of the functinal $f$ about the function $g$ is defined as $f[g+\epsilon\lambda(x)]=f[g_0]+\int dx \frac{\delta f[g_0]}{\delta g(x)}\lambda(x)+\frac{1}{2!}\int dx dx^\prime \frac{\delta^2f[g_0]}{\delta g(x^\prime)\delta g(x)}\lambda(x)\lambda(x') + ... $ (it is assumed that $\lambda(x)=0$ outside the interval in question) but in what sense does this converge? Usually this means that the derivatives of both sides are the same. Following the text here . How does the author derive $D_{\lambda_1}D_{\lambda_2}(f(g))=\int dx dx^\prime \frac{\delta^2f[g_0]}{\delta g(x^\prime)\delta g(x)}\lambda(x)\lambda(x') $ I know how to compute derivatives by definition as described here , or by a way similar to the derivation of Euler-Lagrange equations. Where does the double integral come from in the equation above? I have my own way (maybe it's wrong) to construct such integrals as limiting differentials $$\Delta g=g+\epsilon\lambda-g=\epsilon\lambda$$ $$df=\sum_{i=0}^n\frac{\partial f}{\partial g_i}\Delta g=\sum_{i=0}^n\frac{\partial f}{\partial g(x_0+\epsilon i)}\epsilon\lambda(x_0+\epsilon i)$$ Taking the limit, treating each point as a separate variable, we get $$df=\int \frac{\partial f}{\partial g(x)}\lambda(x) dx$$ Similarly for second order. But I fail to deduce, how this implies convergence of the Taylor series (first equation). How, or which derivatives match comparing left side with the right side of the equality? I would greatly appreciate any clarification. Please forgive any lapses, I am an amateur exploring his interest.","The functional Taylor series of the functinal $f$ about the function $g$ is defined as $f[g+\epsilon\lambda(x)]=f[g_0]+\int dx \frac{\delta f[g_0]}{\delta g(x)}\lambda(x)+\frac{1}{2!}\int dx dx^\prime \frac{\delta^2f[g_0]}{\delta g(x^\prime)\delta g(x)}\lambda(x)\lambda(x') + ... $ (it is assumed that $\lambda(x)=0$ outside the interval in question) but in what sense does this converge? Usually this means that the derivatives of both sides are the same. Following the text here . How does the author derive $D_{\lambda_1}D_{\lambda_2}(f(g))=\int dx dx^\prime \frac{\delta^2f[g_0]}{\delta g(x^\prime)\delta g(x)}\lambda(x)\lambda(x') $ I know how to compute derivatives by definition as described here , or by a way similar to the derivation of Euler-Lagrange equations. Where does the double integral come from in the equation above? I have my own way (maybe it's wrong) to construct such integrals as limiting differentials $$\Delta g=g+\epsilon\lambda-g=\epsilon\lambda$$ $$df=\sum_{i=0}^n\frac{\partial f}{\partial g_i}\Delta g=\sum_{i=0}^n\frac{\partial f}{\partial g(x_0+\epsilon i)}\epsilon\lambda(x_0+\epsilon i)$$ Taking the limit, treating each point as a separate variable, we get $$df=\int \frac{\partial f}{\partial g(x)}\lambda(x) dx$$ Similarly for second order. But I fail to deduce, how this implies convergence of the Taylor series (first equation). How, or which derivatives match comparing left side with the right side of the equality? I would greatly appreciate any clarification. Please forgive any lapses, I am an amateur exploring his interest.",,"['functional-analysis', 'calculus-of-variations', 'functional-calculus']"
96,Attempt to construct a family of cut off functions satisfying certain conditions,Attempt to construct a family of cut off functions satisfying certain conditions,,"Let be $\Omega\subset \mathbb{R}^n $ an open bounded set of class $C^1$ and let be $\Omega'\subset \subset \Omega ''\subset \subset \Omega$. I'm trying to construct a function $\varphi\in C^\infty (\Omega)$such that: $0\leq\varphi\leq1$ $\varphi\equiv 1$ in $\Omega'$ $\varphi\equiv 0$ in $\Omega \setminus \Omega''$ $||\nabla \varphi ||_{L^{\infty}(\Omega, \mathbb{R}^n)}\leq \dfrac{2}{{\rm dist}(\Omega',\partial \Omega'')}$ My attempt: My idea is to use the distance function ${\rm dist }$ and the mollifiers. Let be $\alpha={\rm dist}(\Omega',\partial \Omega'')$. I have in mind this function: $$\varphi(x)=\big [\dfrac {2}{\alpha} {\rm dist}(x,\tilde{\Omega}^c)\wedge 1\big ]*\rho_\epsilon$$ where $\tilde{\Omega}=\big \{ x\in \Omega \;| \;{\rm dist}(x,\Omega')<\dfrac{\alpha}{2} \big \}$, $\rho_\epsilon$ is the standard mollifier (I use the convolution in order to have a $C^\infty$ function) and $\wedge$ is the minimum operator. Is my example correct? My main concern is about the last point. I've constructed this function thinking of the domains as balls and for them the  distance function is linear with respect to the radius. Does my function satisfy the last request? Edit What can I say about the gradient of the function  $x \mapsto {\rm dist  }(x,\tilde{\Omega}^c)$? Can I say that it is linear or can I do some estimations? Thanks for the help!","Let be $\Omega\subset \mathbb{R}^n $ an open bounded set of class $C^1$ and let be $\Omega'\subset \subset \Omega ''\subset \subset \Omega$. I'm trying to construct a function $\varphi\in C^\infty (\Omega)$such that: $0\leq\varphi\leq1$ $\varphi\equiv 1$ in $\Omega'$ $\varphi\equiv 0$ in $\Omega \setminus \Omega''$ $||\nabla \varphi ||_{L^{\infty}(\Omega, \mathbb{R}^n)}\leq \dfrac{2}{{\rm dist}(\Omega',\partial \Omega'')}$ My attempt: My idea is to use the distance function ${\rm dist }$ and the mollifiers. Let be $\alpha={\rm dist}(\Omega',\partial \Omega'')$. I have in mind this function: $$\varphi(x)=\big [\dfrac {2}{\alpha} {\rm dist}(x,\tilde{\Omega}^c)\wedge 1\big ]*\rho_\epsilon$$ where $\tilde{\Omega}=\big \{ x\in \Omega \;| \;{\rm dist}(x,\Omega')<\dfrac{\alpha}{2} \big \}$, $\rho_\epsilon$ is the standard mollifier (I use the convolution in order to have a $C^\infty$ function) and $\wedge$ is the minimum operator. Is my example correct? My main concern is about the last point. I've constructed this function thinking of the domains as balls and for them the  distance function is linear with respect to the radius. Does my function satisfy the last request? Edit What can I say about the gradient of the function  $x \mapsto {\rm dist  }(x,\tilde{\Omega}^c)$? Can I say that it is linear or can I do some estimations? Thanks for the help!",,"['real-analysis', 'functional-analysis', 'calculus-of-variations']"
97,The completeness relation from QM in terms of inner products,The completeness relation from QM in terms of inner products,,"I remember from QM that the completeness relation says $$ \sum_{n=1}^\infty |e_n\rangle \langle e_n | = I$$ so that $\langle x\mid y\rangle =\sum_{n=1}^\infty \langle x\mid e_n\rangle \langle e_n \mid y\rangle$. I was recently trying to prove a result on Trace operators and one calculation was $$\sum_{k=1}^n \langle A g_k ,  h_k \rangle = \sum_{k=1}^n \operatorname{tr}(A(g_k\otimes h_k))$$ Where apparently if $f\in X^*$ and $y\in Y$ we define $y\otimes f:X\to Y$ by $(y\otimes f)(x) = f(x)y$; my attempt at this: $$\sum_{k=1}^n \operatorname{tr}(A(g_k\otimes h_k)) = \sum_{k=1}^n\sum_{i=1}^\infty \langle A(g_k \otimes h_k) e_i, e_i\rangle$$ $$= \sum_{k=1}^n\sum_{i=1}^\infty \langle A(\langle e_i,h_k\rangle g_k), e_i\rangle = \sum_{k=1}^n\sum_{i=1}^\infty \langle Ag_k,e_i\rangle\langle e_i,h_k\rangle$$ So using my naive approach from quantum mechanics I just conclude that the last term is $\sum_{k=1}^n \langle A g_k ,  h_k \rangle $. However, I feel uneasy about this because $\langle \cdot , \cdot \rangle$ is an inner product, while $\langle \cdot \mid \cdot \rangle$ is the bra-ket notation... whatever that means. 1) Can I apply the completeness relation to make my conclusion? 2) Is there a canonical relation between $\langle \cdot, \cdot \rangle$ and $\langle \cdot \mid \cdot \rangle$? 3) How can I prove the completeness relation (I believe it's an axiom in QM, but I reckon its equivalence (in functional analysis (if it exists)) is a theorem).","I remember from QM that the completeness relation says $$ \sum_{n=1}^\infty |e_n\rangle \langle e_n | = I$$ so that $\langle x\mid y\rangle =\sum_{n=1}^\infty \langle x\mid e_n\rangle \langle e_n \mid y\rangle$. I was recently trying to prove a result on Trace operators and one calculation was $$\sum_{k=1}^n \langle A g_k ,  h_k \rangle = \sum_{k=1}^n \operatorname{tr}(A(g_k\otimes h_k))$$ Where apparently if $f\in X^*$ and $y\in Y$ we define $y\otimes f:X\to Y$ by $(y\otimes f)(x) = f(x)y$; my attempt at this: $$\sum_{k=1}^n \operatorname{tr}(A(g_k\otimes h_k)) = \sum_{k=1}^n\sum_{i=1}^\infty \langle A(g_k \otimes h_k) e_i, e_i\rangle$$ $$= \sum_{k=1}^n\sum_{i=1}^\infty \langle A(\langle e_i,h_k\rangle g_k), e_i\rangle = \sum_{k=1}^n\sum_{i=1}^\infty \langle Ag_k,e_i\rangle\langle e_i,h_k\rangle$$ So using my naive approach from quantum mechanics I just conclude that the last term is $\sum_{k=1}^n \langle A g_k ,  h_k \rangle $. However, I feel uneasy about this because $\langle \cdot , \cdot \rangle$ is an inner product, while $\langle \cdot \mid \cdot \rangle$ is the bra-ket notation... whatever that means. 1) Can I apply the completeness relation to make my conclusion? 2) Is there a canonical relation between $\langle \cdot, \cdot \rangle$ and $\langle \cdot \mid \cdot \rangle$? 3) How can I prove the completeness relation (I believe it's an axiom in QM, but I reckon its equivalence (in functional analysis (if it exists)) is a theorem).",,"['functional-analysis', 'operator-theory', 'trace', 'quantum-mechanics']"
98,"Relationship between $C_c^\infty(\Omega,\mathbb R^d)'$ and $H_0^1(\Omega,\mathbb R^d)'$",Relationship between  and,"C_c^\infty(\Omega,\mathbb R^d)' H_0^1(\Omega,\mathbb R^d)'","Let $d\in\mathbb N$ $\Omega\subseteq\mathbb R^d$ be open $\langle\;\cdot\;,\;\cdot\;\rangle$ denote the inner product on $L^2(\Omega,\mathbb R^d)$ $\mathcal D:=C_c^\infty(\Omega,\mathbb R^d)$ and $$H:=\overline{\mathcal D}^{\langle\;\cdot\;,\;\cdot\;\rangle_H}\color{blue}{=H_0^1(\Omega,\mathbb R^d)}$$ with $$\langle\phi,\psi\rangle_H:=\langle\phi,\psi\rangle+\sum_{i=1}^d\langle\nabla\phi_i,\nabla\psi_i\rangle\;\;\;\text{for }\phi,\psi\in\mathcal D$$ How are the topological dual spaces $\mathcal D'$ and $H'$ of $\mathcal D$ and $H$ related? Let me share my thoughts and please correct me, if I'm wrong somewhere (and feel free to leave a comment, if everything is correct): Let $f\in\mathcal D'$. If we equip $\mathcal D$ with the restriction $\left\|\;\cdot\;\right\|_{\mathcal D}$ of the norm induced by $\langle\;\cdot\;,\;\cdot\;\rangle_H$, then $f$ is a bounded, linear operator from $(\mathcal D,\left\|\;\cdot\;\right\|_{\mathcal D})$ to $\mathbb R$. Thus, since $\mathcal D$ is a dense subspace of $(H,\langle\;\cdot\;,\;\cdot\;\rangle_H)$, we can apply the bounded linear transform theorem and obtain the existence of a unique bounded, linear operator $F:(H,\langle\;\cdot\;,\;\cdot\;\rangle_H)\to\mathbb R$ (i.e. $F\in H'$) with $$\left.F\right|_{\mathcal D}=f\tag 1$$ and $$\left\|F\right\|_{H'}=\left\|f\right\|_{\mathcal D'}\tag 2$$ where $\left\|\;\cdot\;\right\|_{\mathcal D'}$ denotes the operator norm on $(\mathcal D,\left\|\;\cdot\;\right\|_{\mathcal D})'$. On the other hand, if $F\in H'$ and $$f:=\left.F\right|_{\mathcal D}\;,$$ then we can show that $f\in\mathcal D'$ where $\mathcal D'$ is equipped with the usual topology . It's clear that $(2)$ is verified too. Is there any mistake in my argumentation? And what's meant if $\nabla\pi$ with $\pi\in C_c^\infty(\Omega)'$ is claimed to be an element of $H$?","Let $d\in\mathbb N$ $\Omega\subseteq\mathbb R^d$ be open $\langle\;\cdot\;,\;\cdot\;\rangle$ denote the inner product on $L^2(\Omega,\mathbb R^d)$ $\mathcal D:=C_c^\infty(\Omega,\mathbb R^d)$ and $$H:=\overline{\mathcal D}^{\langle\;\cdot\;,\;\cdot\;\rangle_H}\color{blue}{=H_0^1(\Omega,\mathbb R^d)}$$ with $$\langle\phi,\psi\rangle_H:=\langle\phi,\psi\rangle+\sum_{i=1}^d\langle\nabla\phi_i,\nabla\psi_i\rangle\;\;\;\text{for }\phi,\psi\in\mathcal D$$ How are the topological dual spaces $\mathcal D'$ and $H'$ of $\mathcal D$ and $H$ related? Let me share my thoughts and please correct me, if I'm wrong somewhere (and feel free to leave a comment, if everything is correct): Let $f\in\mathcal D'$. If we equip $\mathcal D$ with the restriction $\left\|\;\cdot\;\right\|_{\mathcal D}$ of the norm induced by $\langle\;\cdot\;,\;\cdot\;\rangle_H$, then $f$ is a bounded, linear operator from $(\mathcal D,\left\|\;\cdot\;\right\|_{\mathcal D})$ to $\mathbb R$. Thus, since $\mathcal D$ is a dense subspace of $(H,\langle\;\cdot\;,\;\cdot\;\rangle_H)$, we can apply the bounded linear transform theorem and obtain the existence of a unique bounded, linear operator $F:(H,\langle\;\cdot\;,\;\cdot\;\rangle_H)\to\mathbb R$ (i.e. $F\in H'$) with $$\left.F\right|_{\mathcal D}=f\tag 1$$ and $$\left\|F\right\|_{H'}=\left\|f\right\|_{\mathcal D'}\tag 2$$ where $\left\|\;\cdot\;\right\|_{\mathcal D'}$ denotes the operator norm on $(\mathcal D,\left\|\;\cdot\;\right\|_{\mathcal D})'$. On the other hand, if $F\in H'$ and $$f:=\left.F\right|_{\mathcal D}\;,$$ then we can show that $f\in\mathcal D'$ where $\mathcal D'$ is equipped with the usual topology . It's clear that $(2)$ is verified too. Is there any mistake in my argumentation? And what's meant if $\nabla\pi$ with $\pi\in C_c^\infty(\Omega)'$ is claimed to be an element of $H$?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'sobolev-spaces', 'distribution-theory']"
99,Why are there no finitely additive measures on $\ell_\infty$ for which the measure of every ball is positive and finite?,Why are there no finitely additive measures on  for which the measure of every ball is positive and finite?,\ell_\infty,"As the question title suggests, why are there no finitely additive measures on $\ell_\infty$ for which the measure of every ball is positive and finite? Here, we do not assume that the measure is translation invariant.","As the question title suggests, why are there no finitely additive measures on $\ell_\infty$ for which the measure of every ball is positive and finite? Here, we do not assume that the measure is translation invariant.",,"['real-analysis', 'functional-analysis']"
