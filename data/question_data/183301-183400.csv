,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Ordinary functions vs. first-order language functions,Ordinary functions vs. first-order language functions,,"Several books introduce functions as non-logical symbols of languages of first-order logic.  They then introduce again functions as ordered pairs, where for each $x$ there is a unique pair $\langle x, f(x)\rangle$ . I wonder whether the two are different notions which happen to have the same name and notation or the second is an instance of the first, that is,  in $\langle x, f(x)\rangle$ , $ f(x)$ can be thought as a special case, where variables are set (elements). Finally, what is a good way to address the two types of functions to avoid ambiguities? UPDATE As per request of Rob Arthan , I give two book references. This is Kunen, K. (2013). Set theory. Elsevier. [O]ne must distinguish between the logical symbols and nonlogical symbols. The logical symbols are fixed,  [...] The nonlogical symbols vary with context. Each application of logic will specify a set $\mathcal{L}$ of nonlogical symbols. [...] Each symbol in $\mathcal{L}$ has a specified arity , which is some natural number, and a specified type , which is either ''predicate symbol"" or ""function symbol"". If we are discussing ZFC, then $\mathcal{L} = \left\{ \in\right\}$ , where $\in$ is a predicate symbol. Definition 1.6.3 $\;$ $R$ is a function iff $R$ is a relation and for every $x$ , there is at most one $y$ such that $(x,y) \in R$ . If $\exists y [xRy]$ , then $R(x)$ denotes that unique $y$ . And now Enderton, H. B. (2001). A mathematical introduction to logic. Elsevier. A function is a relation $F$ with the property of being single-valued . For each $x$ in dom $F$ there is only one $y$ such that $x, y \in F$ . We assume henceforth that we have been given inﬁnitely many distinct objects (which we call symbols), arranged as follows: A. Logical symbols $\;$ 0. Parentheses: $($ , $)$ . $\;$ 1. Sentential connective symbols: $\rightarrow$ , $\neg$ . $\;$ 2. Variables (one for each positive integer n): $\; v_1 , v_2 , \ldots$ $\;$ 3. Equality symbol (optional): =. B. Parameters $\;$ 0. Quantifier symbol: $\forall$ . $\;$ 1. Predicate symbols: For each positive integer $n$ , some set (possibly empty) of symbols, called $n$ -place predicate symbols. $\;$ 2. Constant symbols: Some set (possibly empty) of symbols. $\;$ 3. Function symbols: For each positive integer $n$ , some set (possibly empty) of symbols, called $n$ -place function symbols.","Several books introduce functions as non-logical symbols of languages of first-order logic.  They then introduce again functions as ordered pairs, where for each there is a unique pair . I wonder whether the two are different notions which happen to have the same name and notation or the second is an instance of the first, that is,  in , can be thought as a special case, where variables are set (elements). Finally, what is a good way to address the two types of functions to avoid ambiguities? UPDATE As per request of Rob Arthan , I give two book references. This is Kunen, K. (2013). Set theory. Elsevier. [O]ne must distinguish between the logical symbols and nonlogical symbols. The logical symbols are fixed,  [...] The nonlogical symbols vary with context. Each application of logic will specify a set of nonlogical symbols. [...] Each symbol in has a specified arity , which is some natural number, and a specified type , which is either ''predicate symbol"" or ""function symbol"". If we are discussing ZFC, then , where is a predicate symbol. Definition 1.6.3 is a function iff is a relation and for every , there is at most one such that . If , then denotes that unique . And now Enderton, H. B. (2001). A mathematical introduction to logic. Elsevier. A function is a relation with the property of being single-valued . For each in dom there is only one such that . We assume henceforth that we have been given inﬁnitely many distinct objects (which we call symbols), arranged as follows: A. Logical symbols 0. Parentheses: , . 1. Sentential connective symbols: , . 2. Variables (one for each positive integer n): 3. Equality symbol (optional): =. B. Parameters 0. Quantifier symbol: . 1. Predicate symbols: For each positive integer , some set (possibly empty) of symbols, called -place predicate symbols. 2. Constant symbols: Some set (possibly empty) of symbols. 3. Function symbols: For each positive integer , some set (possibly empty) of symbols, called -place function symbols.","x \langle x, f(x)\rangle \langle x, f(x)\rangle  f(x) \mathcal{L} \mathcal{L} \mathcal{L} = \left\{ \in\right\} \in \; R R x y (x,y) \in R \exists y [xRy] R(x) y F x F y x, y \in F \; ( ) \; \rightarrow \neg \; \; v_1 , v_2 , \ldots \; \; \forall \; n n \; \; n n","['functions', 'logic', 'set-theory', 'first-order-logic']"
1,"Solving for the value of $a,b$ in $f(x)=(ax+b)(x^5+1)-(5x+1)$ s.t. $(x^2+1)|f(x)$",Solving for the value of  in  s.t.,"a,b f(x)=(ax+b)(x^5+1)-(5x+1) (x^2+1)|f(x)","$Q.$ If $f(x)=(ax+b)(x^5+1)-5x-1$ is divisible by $x^2+1$ . Then the value of $2a+3b$ $?$ MY APPROACH : We have , $(x^2+1)|f(x)$ then $(x-i)|f(x)$ and $(x+i)|f(x)$ . So by Factor Theorem we have $f(-i)=0$ and $f(i)=0$ $$f(i)=-a+bi+(a-5)i+b-1=0$$ $$f(-i)=-a-bi-(a-5)i+b-1=0$$ By this I concluded that $a-b=-1$ . But this is not enough information to solve the problem .","If is divisible by . Then the value of MY APPROACH : We have , then and . So by Factor Theorem we have and By this I concluded that . But this is not enough information to solve the problem .",Q. f(x)=(ax+b)(x^5+1)-5x-1 x^2+1 2a+3b ? (x^2+1)|f(x) (x-i)|f(x) (x+i)|f(x) f(-i)=0 f(i)=0 f(i)=-a+bi+(a-5)i+b-1=0 f(-i)=-a-bi-(a-5)i+b-1=0 a-b=-1,"['functions', 'polynomials']"
2,How to show that a given set is an vector space?,How to show that a given set is an vector space?,,"I have the following set: $$ \mathcal{V} = \left\{f: \int_{-\infty}^{\infty}f(x)^2 e^{-x^2}\,dx < \infty\right\} $$ To show it is a vector space I need to show that: addition and subtraction are defined The set is closed under linear combinations There is a zero vector. However, I'm not sure how to show these properties with an integral.","I have the following set: To show it is a vector space I need to show that: addition and subtraction are defined The set is closed under linear combinations There is a zero vector. However, I'm not sure how to show these properties with an integral.","
\mathcal{V} = \left\{f: \int_{-\infty}^{\infty}f(x)^2 e^{-x^2}\,dx < \infty\right\}
","['functions', 'vector-spaces', 'improper-integrals']"
3,Find all functions that satisfy the functional equation: $ \exp\big(f(\log x)\big)=\log\big(f(\exp x)\big) $,Find all functions that satisfy the functional equation:, \exp\big(f(\log x)\big)=\log\big(f(\exp x)\big) ,"Find all functions that satisfy the functional equation: $$ \exp\big(f(\log x)\big)=\log\big(f(\exp x)\big) $$ I found that $f(x)=\log x, \exp x$ are solutions. And I think $\exp(x+1)$ also works. I think there are infinitely many solutions: $f(x+s)$ and $f(x)+s$ for $s \in \Bbb R.$ Are these all the solutions?",Find all functions that satisfy the functional equation: I found that are solutions. And I think also works. I think there are infinitely many solutions: and for Are these all the solutions?," \exp\big(f(\log x)\big)=\log\big(f(\exp x)\big)  f(x)=\log x, \exp x \exp(x+1) f(x+s) f(x)+s s \in \Bbb R.","['functions', 'solution-verification', 'functional-equations']"
4,Integral of functions of several variables,Integral of functions of several variables,,"The function is defined from $[-1,1]\times[-1,1]$ to $\Bbb R$ , given by $f(x,y)=\frac{x^2-y^2}{(x^2+y^2)^2}$ when $(x,y)≠0$ and $f(0,0)=0$ . I could find that the function is not continuous at origin, so not differentiable  and also partial derivatives does not exist at origin. But how do we evaluate the integral of the function over the given domain. Being function of several variable how do we deal with the point of discontinuity? Can we convert it to polar coordinates and apply residue theorem? Do we have any other methods? Any help would be appreciated. Thanks in advance.","The function is defined from to , given by when and . I could find that the function is not continuous at origin, so not differentiable  and also partial derivatives does not exist at origin. But how do we evaluate the integral of the function over the given domain. Being function of several variable how do we deal with the point of discontinuity? Can we convert it to polar coordinates and apply residue theorem? Do we have any other methods? Any help would be appreciated. Thanks in advance.","[-1,1]\times[-1,1] \Bbb R f(x,y)=\frac{x^2-y^2}{(x^2+y^2)^2} (x,y)≠0 f(0,0)=0","['real-analysis', 'functions']"
5,Relation between $f(x)$ and $f(\sqrt{x})$,Relation between  and,f(x) f(\sqrt{x}),"This might be silly, but if $f(\sqrt{x})=\frac{0.1}{a}x$ , is $f(x)=\frac{0.1}{a}x^2$ ?","This might be silly, but if , is ?",f(\sqrt{x})=\frac{0.1}{a}x f(x)=\frac{0.1}{a}x^2,['functions']
6,Prove that $f(x_0)>\frac{2}{3}$,Prove that,f(x_0)>\frac{2}{3},"It's a problem found with the help of Geogebra. Let $0<x$ be a real number then define the function: $$f(x)=\Big(\frac{x}{x+1}\Big)^{\Gamma(x)}$$ Then let $x_0$ be the maximum of the function on $(0,\infty)$ and  then prove that: $$f(x_0)>\frac{2}{3}$$ See here to compare Well to solve it I have tried logically the use of derivative we have: $$f'(x)=\Big(\frac{x}{x+1}\Big)^{\Gamma(x)} \Bigg(\frac{(x + 1) \Big(\frac{1}{(x + 1)} - \frac{x}{(x + 1)^2}\Big) Γ(x)}{x} + \log\Big(\frac{x}{x + 1}\Big) Γ(x) \psi^{(0)} (x)\Bigg)$$ Where we have the $n^{th}$ derivative of the digamma function. I think that this derivative is not really useful only theoretically, but we can use the Newton's method numerically . I have tried some inequality on the this wiki page notably an inquality due to  Kečkić and Vasić without success. On the other hand the problem with Taylor series is : we get a lot of constant as Euler-Mascheroni constant wich needs to be evaluate with an series or something like that. So it's a little bit make problem on another problem. Maybe spline cubic is the way I don't know... Finally taking the logarithm on both side the derivative is a little bit less tedious. See here Well if you have an issue thanks in advance ...","It's a problem found with the help of Geogebra. Let be a real number then define the function: Then let be the maximum of the function on and  then prove that: See here to compare Well to solve it I have tried logically the use of derivative we have: Where we have the derivative of the digamma function. I think that this derivative is not really useful only theoretically, but we can use the Newton's method numerically . I have tried some inequality on the this wiki page notably an inquality due to  Kečkić and Vasić without success. On the other hand the problem with Taylor series is : we get a lot of constant as Euler-Mascheroni constant wich needs to be evaluate with an series or something like that. So it's a little bit make problem on another problem. Maybe spline cubic is the way I don't know... Finally taking the logarithm on both side the derivative is a little bit less tedious. See here Well if you have an issue thanks in advance ...","0<x f(x)=\Big(\frac{x}{x+1}\Big)^{\Gamma(x)} x_0 (0,\infty) f(x_0)>\frac{2}{3} f'(x)=\Big(\frac{x}{x+1}\Big)^{\Gamma(x)} \Bigg(\frac{(x + 1) \Big(\frac{1}{(x + 1)} - \frac{x}{(x + 1)^2}\Big) Γ(x)}{x} + \log\Big(\frac{x}{x + 1}\Big) Γ(x) \psi^{(0)} (x)\Bigg) n^{th}","['functions', 'derivatives', 'inequality', 'numerical-methods', 'gamma-function']"
7,Find the maximum value of $\sin (A) + \sin( 2A )+ \sin (3A)$,Find the maximum value of,\sin (A) + \sin( 2A )+ \sin (3A),"From the graph, it seems that the answer is 2.5. Can someone please help me to solve this problem manually by using trigonometric equations.","From the graph, it seems that the answer is 2.5. Can someone please help me to solve this problem manually by using trigonometric equations.",,['functions']
8,Solve the equation $\cos^{-1}\frac{x^2-1}{x^2+1}+\tan^{-1}\frac{2x}{x^2-1}=\frac{2\pi}{3}$,Solve the equation,\cos^{-1}\frac{x^2-1}{x^2+1}+\tan^{-1}\frac{2x}{x^2-1}=\frac{2\pi}{3},"$\cos^{-1}\dfrac{x^2-1}{x^2+1}+\tan^{-1}\dfrac{2x}{x^2-1}=\dfrac{2\pi}{3}$ Let's first find the domain $$-1<=\dfrac{x^2-1}{x^2+1}<=1$$ $$\dfrac{x^2-1}{x^2+1}>=-1 \text { and } \dfrac{x^2-1}{x^2+1}<=1$$ $$\dfrac{x^2-1+x^2+1}{x^2+1}>=0 \text { and } \dfrac{x^2-1-x^2-1}{x^2+1}<=0$$ $$\dfrac{2x^2}{x^2+1}>=0 \text { and } \dfrac{-2}{1+x^2}<=0$$ $$x\in R$$ $$x^2-1\ne0$$ $$x\ne\pm1$$ $$\cos^{-1}\dfrac{x^2-1}{x^2+1}+\tan^{-1}\dfrac{2x}{x^2-1}=\dfrac{2\pi}{3}$$ $$\pi-\cos^{-1}\dfrac{1-x^2}{1+x^2}-\tan^{-1}\dfrac{2x}{1-x^2}=\dfrac{2\pi}{3}$$ $$\dfrac{\pi}{3}=\cos^{-1}\dfrac{1-x^2}{1+x^2}+\tan^{-1}\dfrac{2x}{1-x^2}$$ Substituting $x$ by $\tan\theta$ $$x=\tan\theta$$ $$\tan^{-1}x=\theta$$ $$\theta\in \left(-\dfrac{\pi}{2},\dfrac{\pi}{2}\right)-\{-\dfrac{\pi}{4},\dfrac{\pi}{4}\}$$ $$\dfrac{\pi}{3}=\cos^{-1}\dfrac{1-\tan^2\theta}{1+\tan^2\theta}+\tan^{-1}\dfrac{2\tan\theta}{1-\tan^2\theta}$$ $$\dfrac{\pi}{3}=\cos^{-1}(\cos2\theta)+\tan^{-1}(\tan2\theta)$$ $$2\theta\in(-\pi,\pi)-\{-\dfrac{\pi}{2},\dfrac{\pi}{2}\}$$ Now we break the range of $2\theta$ into various parts:- Case $1$ : $2\theta\in\left(-\pi,-\dfrac{\pi}{2}\right)$ , $\theta\in\left(-\dfrac{\pi}{2},-\dfrac{\pi}{4}\right)$ $$\dfrac{\pi}{3}=2\pi+2\theta+\pi+2\theta$$ $$-\dfrac{8\pi}{3}=4\theta$$ $$-\dfrac{2\pi}{3}=\theta$$ But it is not the range of $\theta$ we assumed Case $2$ : $2\theta\in\left(-\dfrac{\pi}{2},0\right]$ , $\theta\in\left(-\dfrac{\pi}{4},0\right]$ $$\dfrac{\pi}{3}=-2\theta+2\theta$$ $$\dfrac{\pi}{3}=0 \text { not possible }$$ Case $3$ : $2\theta\in\left(0,\dfrac{\pi}{2}\right)$ , $\theta\in\left(0,\dfrac{\pi}{4}\right)$ $$\dfrac{\pi}{3}=2\theta+2\theta$$ $$\dfrac{\pi}{12}=\theta$$ It is coming in the range of $\theta$ , so its a valid solution. $$\tan^{-1}x=\dfrac{\pi}{12}$$ $$x=\tan\dfrac{\pi}{12}$$ $$x=2-\sqrt{3}$$ Case $4$ : $2\theta\in\left(\dfrac{\pi}{2},\pi\right)$ , $\theta\in\left(\dfrac{\pi}{4},\dfrac{\pi}{2}\right)$ $$\dfrac{\pi}{3}=2\pi-2\theta+2\theta-\pi$$ $$\dfrac{\pi}{3}=\pi \text { not possible }$$ So only solution is $2-\sqrt{3}$ , but actual answer is $2-\sqrt{3}, \sqrt{3}$","Let's first find the domain Substituting by Now we break the range of into various parts:- Case : , But it is not the range of we assumed Case : , Case : , It is coming in the range of , so its a valid solution. Case : , So only solution is , but actual answer is","\cos^{-1}\dfrac{x^2-1}{x^2+1}+\tan^{-1}\dfrac{2x}{x^2-1}=\dfrac{2\pi}{3} -1<=\dfrac{x^2-1}{x^2+1}<=1 \dfrac{x^2-1}{x^2+1}>=-1 \text { and } \dfrac{x^2-1}{x^2+1}<=1 \dfrac{x^2-1+x^2+1}{x^2+1}>=0 \text { and } \dfrac{x^2-1-x^2-1}{x^2+1}<=0 \dfrac{2x^2}{x^2+1}>=0 \text { and } \dfrac{-2}{1+x^2}<=0 x\in R x^2-1\ne0 x\ne\pm1 \cos^{-1}\dfrac{x^2-1}{x^2+1}+\tan^{-1}\dfrac{2x}{x^2-1}=\dfrac{2\pi}{3} \pi-\cos^{-1}\dfrac{1-x^2}{1+x^2}-\tan^{-1}\dfrac{2x}{1-x^2}=\dfrac{2\pi}{3} \dfrac{\pi}{3}=\cos^{-1}\dfrac{1-x^2}{1+x^2}+\tan^{-1}\dfrac{2x}{1-x^2} x \tan\theta x=\tan\theta \tan^{-1}x=\theta \theta\in \left(-\dfrac{\pi}{2},\dfrac{\pi}{2}\right)-\{-\dfrac{\pi}{4},\dfrac{\pi}{4}\} \dfrac{\pi}{3}=\cos^{-1}\dfrac{1-\tan^2\theta}{1+\tan^2\theta}+\tan^{-1}\dfrac{2\tan\theta}{1-\tan^2\theta} \dfrac{\pi}{3}=\cos^{-1}(\cos2\theta)+\tan^{-1}(\tan2\theta) 2\theta\in(-\pi,\pi)-\{-\dfrac{\pi}{2},\dfrac{\pi}{2}\} 2\theta 1 2\theta\in\left(-\pi,-\dfrac{\pi}{2}\right) \theta\in\left(-\dfrac{\pi}{2},-\dfrac{\pi}{4}\right) \dfrac{\pi}{3}=2\pi+2\theta+\pi+2\theta -\dfrac{8\pi}{3}=4\theta -\dfrac{2\pi}{3}=\theta \theta 2 2\theta\in\left(-\dfrac{\pi}{2},0\right] \theta\in\left(-\dfrac{\pi}{4},0\right] \dfrac{\pi}{3}=-2\theta+2\theta \dfrac{\pi}{3}=0 \text { not possible } 3 2\theta\in\left(0,\dfrac{\pi}{2}\right) \theta\in\left(0,\dfrac{\pi}{4}\right) \dfrac{\pi}{3}=2\theta+2\theta \dfrac{\pi}{12}=\theta \theta \tan^{-1}x=\dfrac{\pi}{12} x=\tan\dfrac{\pi}{12} x=2-\sqrt{3} 4 2\theta\in\left(\dfrac{\pi}{2},\pi\right) \theta\in\left(\dfrac{\pi}{4},\dfrac{\pi}{2}\right) \dfrac{\pi}{3}=2\pi-2\theta+2\theta-\pi \dfrac{\pi}{3}=\pi \text { not possible } 2-\sqrt{3} 2-\sqrt{3}, \sqrt{3}","['functions', 'trigonometry']"
9,Number of rational roots,Number of rational roots,,"Let $f(x) = a_0 + a_1 x + ...... + a_n x^n$ be a polynomial of degree n with integral coefficients. If $f(1), a_0, a_n$ are odd then number of rational roots are. My Try: Let $f(x)=(x-\alpha)g(x), \alpha \in \mathbb I$ $f(0)=(0-\alpha)g(x)$ is odd, therefore both $\alpha$ and $g(0)$ must be odd, hence $(1-\alpha)$ must be even but $f(1)$ is odd. Therefore it won't have any integral root. How to prove for rational root?","Let be a polynomial of degree n with integral coefficients. If are odd then number of rational roots are. My Try: Let is odd, therefore both and must be odd, hence must be even but is odd. Therefore it won't have any integral root. How to prove for rational root?","f(x) = a_0 + a_1 x + ...... + a_n x^n f(1), a_0, a_n f(x)=(x-\alpha)g(x), \alpha \in \mathbb I f(0)=(0-\alpha)g(x) \alpha g(0) (1-\alpha) f(1)","['functions', 'polynomials', 'roots']"
10,"is there any maping from $S^1$ to $S^1$ of odd degree, which is not an odd function?","is there any maping from  to  of odd degree, which is not an odd function?",S^1 S^1,"I want to prove for every continous function from $s^n$ to $s^n$ of odd degree there exists $x$ such that $f(-x)=-f(x)$ so I used this ""that the sum of two functions of odd degree must be odd"" but I don't know if this is really true or not. I just know that sum of two odd functions is odd but I don't think every function of odd degree has to be an odd function, so I'm trying to find an example for this using a function from $s^1$ to  $s^1$. thanks for any help","I want to prove for every continous function from $s^n$ to $s^n$ of odd degree there exists $x$ such that $f(-x)=-f(x)$ so I used this ""that the sum of two functions of odd degree must be odd"" but I don't know if this is really true or not. I just know that sum of two odd functions is odd but I don't think every function of odd degree has to be an odd function, so I'm trying to find an example for this using a function from $s^1$ to  $s^1$. thanks for any help",,"['functions', 'algebraic-topology', 'even-and-odd-functions']"
11,"Terminology: Semigroups, only their ""binary operations"" aren't closed.","Terminology: Semigroups, only their ""binary operations"" aren't closed.",,"Motivation: Consider $\mathcal{X}=(X, +)$ , where $X=\{-1, 0, 1\}$ and $+$ is standard addition. Then $\mathcal{X}$ is associative (where defined) but not closed. NB: There is an identity element in $X$ and inverses exist in $X$ all with respect to $+$ . This example is taken from here . The Question: This question seems difficult to pose due to certain subtleties so, to make life easier, here's the rough idea first. What d'you call a ""magma"" that's associative but not closed? An attempt at refining the question: What do you call the mathematical objects $\mathcal{S}=(S, T, \ast)$ for which $S$ is a set and $\ast$ is some function with domain $S\times S$ and codomain some set $T$ with $S\subset T$ , such that for all $s,t,u\in S$ we have $$s\ast (t\ast u)=(s\ast t)\ast u$$ whenever $t\ast u, s\ast t\in S$ (or $T$ if that's necessary to keep the question in spirit) and there exist $x, y\in S$ such that $x\ast y\in T\setminus S$ ? (Please disregard this attempt if it complicates the idea of the question needlessly.) Thoughts: I'm not sure whether naming these things is necessary. I'm interested in them out of curiosity. Whether the question even makes sense, I don't know. Are they simply subsets of semigroups? I made sure to say function and not binary operation above, since the latter implies closure by definition.","Motivation: Consider , where and is standard addition. Then is associative (where defined) but not closed. NB: There is an identity element in and inverses exist in all with respect to . This example is taken from here . The Question: This question seems difficult to pose due to certain subtleties so, to make life easier, here's the rough idea first. What d'you call a ""magma"" that's associative but not closed? An attempt at refining the question: What do you call the mathematical objects for which is a set and is some function with domain and codomain some set with , such that for all we have whenever (or if that's necessary to keep the question in spirit) and there exist such that ? (Please disregard this attempt if it complicates the idea of the question needlessly.) Thoughts: I'm not sure whether naming these things is necessary. I'm interested in them out of curiosity. Whether the question even makes sense, I don't know. Are they simply subsets of semigroups? I made sure to say function and not binary operation above, since the latter implies closure by definition.","\mathcal{X}=(X, +) X=\{-1, 0, 1\} + \mathcal{X} X X + \mathcal{S}=(S, T, \ast) S \ast S\times S T S\subset T s,t,u\in S s\ast (t\ast u)=(s\ast t)\ast u t\ast u, s\ast t\in S T x, y\in S x\ast y\in T\setminus S","['functions', 'terminology', 'semigroups', 'binary-operations', 'magma']"
12,How many real function are there?,How many real function are there?,,"There are more numbers in $\mathbb{R}$ than in $\mathbb{N}$. There are as many vectors in $\mathbb{R}^n, n \in \mathbb{N}$ as numbers in $\mathbb{R}$. How many real functions are there? If I denote $\{f,f: \mathbb{R} \rightarrow \mathbb{R}\}=\mathbb{R}^\mathbb{R}$ I get another quite.. very big, infinite, uncountable set, right? Is $|\mathbb{R}^\mathbb{R}| > |\mathbb{R}|$?.. another uncountable infinite beyond continuity? What about $\left|(\mathbb{R}^\mathbb{R})^{(\mathbb{R}^\mathbb{R})}\right|$ then? How far can we build huge sets in this direction? Is the number of various infinites itself countable ? $\left\{|\mathbb{N}|,|\mathbb{R}|,|\mathbb{R}^\mathbb{R}|,\left|(\mathbb{R}^\mathbb{R})^{(\mathbb{R}^\mathbb{R})}\right|,\dots\right\}$ would be, right? Or maybe $|\mathbb{R}^\mathbb{R}| = |\mathbb{R}|$ and we fall back on our feet?","There are more numbers in $\mathbb{R}$ than in $\mathbb{N}$. There are as many vectors in $\mathbb{R}^n, n \in \mathbb{N}$ as numbers in $\mathbb{R}$. How many real functions are there? If I denote $\{f,f: \mathbb{R} \rightarrow \mathbb{R}\}=\mathbb{R}^\mathbb{R}$ I get another quite.. very big, infinite, uncountable set, right? Is $|\mathbb{R}^\mathbb{R}| > |\mathbb{R}|$?.. another uncountable infinite beyond continuity? What about $\left|(\mathbb{R}^\mathbb{R})^{(\mathbb{R}^\mathbb{R})}\right|$ then? How far can we build huge sets in this direction? Is the number of various infinites itself countable ? $\left\{|\mathbb{N}|,|\mathbb{R}|,|\mathbb{R}^\mathbb{R}|,\left|(\mathbb{R}^\mathbb{R})^{(\mathbb{R}^\mathbb{R})}\right|,\dots\right\}$ would be, right? Or maybe $|\mathbb{R}^\mathbb{R}| = |\mathbb{R}|$ and we fall back on our feet?",,"['functions', 'continuity', 'compactness', 'infinity', 'first-countable']"
13,"What is the set $g^{-1}([-1,1])$?",What is the set ?,"g^{-1}([-1,1])","Let $g(x,y)=xy$ for $xy\in \mathbb R$. What is $g^{-1}([-1,1])$? I know that $g^{-1}([-1,1])=\{{(x,y) \,:\    g(x,y)\in [-1,1]}\}$. But finding all values $(x,y)$ is somewhat confusing.","Let $g(x,y)=xy$ for $xy\in \mathbb R$. What is $g^{-1}([-1,1])$? I know that $g^{-1}([-1,1])=\{{(x,y) \,:\    g(x,y)\in [-1,1]}\}$. But finding all values $(x,y)$ is somewhat confusing.",,"['calculus', 'functions']"
14,"$ \ f: \mathbb{N} \times \mathbb{N} \to \mathbb{R}$ via $ \ f(a,b) = a + b. \sqrt{11}$",via," \ f: \mathbb{N} \times \mathbb{N} \to \mathbb{R}  \ f(a,b) = a + b. \sqrt{11}","Question: Let $ \ f: \mathbb{N} \times \mathbb{N} \to \mathbb{R}$ via $ \ f(a,b) = a + b. \sqrt{11}$ Is $ \ f$ an injection? Is it a surjection? My attempt: It is injective. $ f(a,b) = f(c,d) \implies a + b. \sqrt{11} = c + d. \sqrt{11} \implies (a-c) + \sqrt{11}(b-d) = 0 \implies a -c = 0$ and $ \ \sqrt{11}(b-d) = 0 \implies a = c$ and $ \ b = d$. It is not surjective. Notice that $ \ f(a,b) \neq 1\  \forall \ a,b \in \mathbb{N}$. That is $ \ a+ b.\sqrt{11} \neq 1\  \forall \ a,b \in \mathbb{N}$. So $ \ 1 \notin $ image(f). Hence not surjective. Is my approach and reasoning correct?","Question: Let $ \ f: \mathbb{N} \times \mathbb{N} \to \mathbb{R}$ via $ \ f(a,b) = a + b. \sqrt{11}$ Is $ \ f$ an injection? Is it a surjection? My attempt: It is injective. $ f(a,b) = f(c,d) \implies a + b. \sqrt{11} = c + d. \sqrt{11} \implies (a-c) + \sqrt{11}(b-d) = 0 \implies a -c = 0$ and $ \ \sqrt{11}(b-d) = 0 \implies a = c$ and $ \ b = d$. It is not surjective. Notice that $ \ f(a,b) \neq 1\  \forall \ a,b \in \mathbb{N}$. That is $ \ a+ b.\sqrt{11} \neq 1\  \forall \ a,b \in \mathbb{N}$. So $ \ 1 \notin $ image(f). Hence not surjective. Is my approach and reasoning correct?",,['functions']
15,When can you take the nth root of a negative number?,When can you take the nth root of a negative number?,,"For this problem I'm only concerned with real solution, not complex ones. You can't take the square root of a negative number, but you can take the cube root of a negative. For fraction, as long as the power is a reduced fraction and the denominator is odd, you can take the power of a negative number. What about for an irrational power, such as $\sqrt{2}$? Is there a real answer to $(-2)^{\sqrt{2}}$. I can't tell because you can't rewrite it as a reduced fraction.","For this problem I'm only concerned with real solution, not complex ones. You can't take the square root of a negative number, but you can take the cube root of a negative. For fraction, as long as the power is a reduced fraction and the denominator is odd, you can take the power of a negative number. What about for an irrational power, such as $\sqrt{2}$? Is there a real answer to $(-2)^{\sqrt{2}}$. I can't tell because you can't rewrite it as a reduced fraction.",,"['functions', 'recreational-mathematics']"
16,The functional equation $f\bigl(x+yf(x)\bigr)+f\bigl(xf(y)-y\bigr) = f(x)-f(y)+2xy^2$,The functional equation,f\bigl(x+yf(x)\bigr)+f\bigl(xf(y)-y\bigr) = f(x)-f(y)+2xy^2,"Let $f:\mathbb{R} \to \mathbb{R}$ such that: $$f\bigl(x+yf(x)\bigr)+f\bigl(xf(y)-y\bigr) = f(x)-f(y)+2xy^2$$ I don't know how to solve this functional equation. Yet here is what I've noticed so far: $f(0) = 0$ after the substitution: $(x,y) = (0,0)$ $f(-x) = -f(x)$ after the substitution: $(x,y) = (0,x)$ $f\bigl(x+xf(x)\bigr)+f\bigl(xf(x)-x\bigr) = 2x^3$ after the substitution: $(x,y) = (x,x)$ $f\bigl(-x-xf(x)\bigr) = -f(x)-x^3$ after the substitution: $(x,y) = (-x, x)$ Moreover I don't think this equation has any solutions...",Let such that: I don't know how to solve this functional equation. Yet here is what I've noticed so far: after the substitution: after the substitution: after the substitution: after the substitution: Moreover I don't think this equation has any solutions...,"f:\mathbb{R} \to \mathbb{R} f\bigl(x+yf(x)\bigr)+f\bigl(xf(y)-y\bigr) = f(x)-f(y)+2xy^2 f(0) = 0 (x,y) = (0,0) f(-x) = -f(x) (x,y) = (0,x) f\bigl(x+xf(x)\bigr)+f\bigl(xf(x)-x\bigr) = 2x^3 (x,y) = (x,x) f\bigl(-x-xf(x)\bigr) = -f(x)-x^3 (x,y) = (-x, x)","['functions', 'functional-equations']"
17,Trying to understand the math behind backpropagation in neural nets,Trying to understand the math behind backpropagation in neural nets,,"I am currently trying to understand the math used training neural network, in which gradient descent is used to minimize the error between the target and extracted. I currently following/reading this tutorial So an example: Given a network like this: We wish to minimize the error function being for one training set (x,y) \begin{align} J(W,b; x,y) = \frac{1}{2} \left\| h_{W,b}(x) - y \right\|^2. \end{align} ( question :  Why multiplying a half?) Which for M training sets would become \begin{align} J(W,b) &= \left[ \frac{1}{m} \sum_{i=1}^m \left( \frac{1}{2} \left\| h_{W,b}(x^{(i)}) - y^{(i)} \right\|^2 \right) \right]                        + \frac{\lambda}{2} \sum_{l=1}^{n_l-1} \; \sum_{i=1}^{s_l} \; \sum_{j=1}^{s_{l+1}} \left( W^{(l)}_{ji} \right)^2 \end{align} ( question : Why the second term?  and why computing the average of the error than the exact error, and try to minimize it) Using partial the partial derivative on the cost function, one can compute the gradient in which the weight and bias has to descent to minimize it. \begin{align} W_{ij}^{(l)} &= W_{ij}^{(l)} - \alpha \frac{\partial}{\partial W_{ij}^{(l)}} J(W,b) \\ b_{i}^{(l)} &= b_{i}^{(l)} - \alpha \frac{\partial}{\partial b_{i}^{(l)}} J(W,b) \end{align} Where $\alpha$ the determine the amount of the gradient to be used. As far is backpropagation being most usefull here as it provides an efficient way for computing the partial probabilities as such. \begin{align} \frac{\partial}{\partial W_{ij}^{(l)}} J(W,b) &= \left[ \frac{1}{m} \sum_{i=1}^m \frac{\partial}{\partial W_{ij}^{(l)}} J(W,b; x^{(i)}, y^{(i)}) \right] + \lambda W_{ij}^{(l)} \\ \frac{\partial}{\partial b_{i}^{(l)}} J(W,b) &= \frac{1}{m}\sum_{i=1}^m \frac{\partial}{\partial b_{i}^{(l)}} J(W,b; x^{(i)}, y^{(i)}) \end{align} ( question : Again why average and the second term?) They they futher explain how one can get derivative for  a training set (x,y) First they define an error term $\delta^{(l)}_i$ which contains the information ""how much of the error in the output was caused by node $i$ in layer $l$"". The error seen in the output node $\delta^{(l)}_i$, can easily be computed as: \begin{align} \delta^{(n_l)}_i = \frac{\partial}{\partial z^{(n_l)}_i} \;\; \frac{1}{2} \left\|y - h_{W,b}(x)\right\|^2 = - (y_i - a^{(n_l)}_i) \cdot f'(z^{(n_l)}_i) \end{align} in which $z^{(l)}_i$ is denote the total weighted sum of inputs to unit $i$ in layer $l$, including the bias term. Example: $\textstyle z_i^{(2)} = \sum_{j=1}^n W^{(1)}_{ij} x_j + b^{(1)}_i$  and $a_{i}^(l)$ is the activation of node $i$ in layer $l$ $a^{(l)}_i = f(z^{(l)}_i)$. ( question : Not sure i understand how they derived partial derivative.. I understand why they do that - don't understand the result though) This is where things begin become weird and my intuition is not following whats going on... The error term of each node $i$ and layer $l$ can be defined as $$\delta^{(l)}_i = \left( \sum_{j=1}^{s_{l+1}} W^{(l)}_{ji} \delta^{(l+1)}_j \right) f'(z^{(l)}_i)$$ Which then by some magic give the wanted partial derivatives.. \begin{align} \frac{\partial}{\partial W_{ij}^{(l)}} J(W,b; x, y) &= a^{(l)}_j \delta_i^{(l+1)} \\ \frac{\partial}{\partial b_{i}^{(l)}} J(W,b; x, y) &= \delta_i^{(l+1)}. \end{align}","I am currently trying to understand the math used training neural network, in which gradient descent is used to minimize the error between the target and extracted. I currently following/reading this tutorial So an example: Given a network like this: We wish to minimize the error function being for one training set (x,y) \begin{align} J(W,b; x,y) = \frac{1}{2} \left\| h_{W,b}(x) - y \right\|^2. \end{align} ( question :  Why multiplying a half?) Which for M training sets would become \begin{align} J(W,b) &= \left[ \frac{1}{m} \sum_{i=1}^m \left( \frac{1}{2} \left\| h_{W,b}(x^{(i)}) - y^{(i)} \right\|^2 \right) \right]                        + \frac{\lambda}{2} \sum_{l=1}^{n_l-1} \; \sum_{i=1}^{s_l} \; \sum_{j=1}^{s_{l+1}} \left( W^{(l)}_{ji} \right)^2 \end{align} ( question : Why the second term?  and why computing the average of the error than the exact error, and try to minimize it) Using partial the partial derivative on the cost function, one can compute the gradient in which the weight and bias has to descent to minimize it. \begin{align} W_{ij}^{(l)} &= W_{ij}^{(l)} - \alpha \frac{\partial}{\partial W_{ij}^{(l)}} J(W,b) \\ b_{i}^{(l)} &= b_{i}^{(l)} - \alpha \frac{\partial}{\partial b_{i}^{(l)}} J(W,b) \end{align} Where $\alpha$ the determine the amount of the gradient to be used. As far is backpropagation being most usefull here as it provides an efficient way for computing the partial probabilities as such. \begin{align} \frac{\partial}{\partial W_{ij}^{(l)}} J(W,b) &= \left[ \frac{1}{m} \sum_{i=1}^m \frac{\partial}{\partial W_{ij}^{(l)}} J(W,b; x^{(i)}, y^{(i)}) \right] + \lambda W_{ij}^{(l)} \\ \frac{\partial}{\partial b_{i}^{(l)}} J(W,b) &= \frac{1}{m}\sum_{i=1}^m \frac{\partial}{\partial b_{i}^{(l)}} J(W,b; x^{(i)}, y^{(i)}) \end{align} ( question : Again why average and the second term?) They they futher explain how one can get derivative for  a training set (x,y) First they define an error term $\delta^{(l)}_i$ which contains the information ""how much of the error in the output was caused by node $i$ in layer $l$"". The error seen in the output node $\delta^{(l)}_i$, can easily be computed as: \begin{align} \delta^{(n_l)}_i = \frac{\partial}{\partial z^{(n_l)}_i} \;\; \frac{1}{2} \left\|y - h_{W,b}(x)\right\|^2 = - (y_i - a^{(n_l)}_i) \cdot f'(z^{(n_l)}_i) \end{align} in which $z^{(l)}_i$ is denote the total weighted sum of inputs to unit $i$ in layer $l$, including the bias term. Example: $\textstyle z_i^{(2)} = \sum_{j=1}^n W^{(1)}_{ij} x_j + b^{(1)}_i$  and $a_{i}^(l)$ is the activation of node $i$ in layer $l$ $a^{(l)}_i = f(z^{(l)}_i)$. ( question : Not sure i understand how they derived partial derivative.. I understand why they do that - don't understand the result though) This is where things begin become weird and my intuition is not following whats going on... The error term of each node $i$ and layer $l$ can be defined as $$\delta^{(l)}_i = \left( \sum_{j=1}^{s_{l+1}} W^{(l)}_{ji} \delta^{(l+1)}_j \right) f'(z^{(l)}_i)$$ Which then by some magic give the wanted partial derivatives.. \begin{align} \frac{\partial}{\partial W_{ij}^{(l)}} J(W,b; x, y) &= a^{(l)}_j \delta_i^{(l+1)} \\ \frac{\partial}{\partial b_{i}^{(l)}} J(W,b; x, y) &= \delta_i^{(l+1)}. \end{align}",,"['functions', 'partial-derivative', 'neural-networks', 'gradient-descent']"
18,"How many boolean functions of $F(x,y,z) = F(x',y,z') + F(x,y',z)$?",How many boolean functions of ?,"F(x,y,z) = F(x',y,z') + F(x,y',z)","How to find total number of boolean functions of the equation : $F(x,y,z) = F(x',y,z') + F(x,y',z)$ Is there any procedure for this ?","How to find total number of boolean functions of the equation : $F(x,y,z) = F(x',y,z') + F(x,y',z)$ Is there any procedure for this ?",,"['functions', 'discrete-mathematics', 'boolean-algebra']"
19,Reverse of the statement of uniform continuity on a compact,Reverse of the statement of uniform continuity on a compact,,"If a set $C$ is compact, then all continuous functions on a set $C$ are uniformly continuous. Does the reverse hold? Question If all continuous functions on a set $C$ are uniformly continuous, then $C$ is compact?","If a set $C$ is compact, then all continuous functions on a set $C$ are uniformly continuous. Does the reverse hold? Question If all continuous functions on a set $C$ are uniformly continuous, then $C$ is compact?",,"['functions', 'compactness', 'uniform-continuity']"
20,A question on an inequality relating a function and its derivative,A question on an inequality relating a function and its derivative,,"Let $f:[0,1]\to \Bbb R$ be a differentiable function such that $f(0)=0$ and $|f'(x)| \le k|f(x)|\;\forall x \in [0,1]$ ,( $k>0$ ), then which of the following is always true? (A) $f(x)=0 \; \forall \; x \in \Bbb R$ (B) $f(x)=0 \; \forall \; x \in [0,1]$ (C) $f(x) \ne 0 \; \forall \; x \in [0,1]$ (D) $f(1) = k$ This question appeared in a test I gave today (its obviously completed). I would love a hint on how to approach this question, and also some insight on how I should have thought about it from the beginning. Since mean value theorems were on syllabus (Lagrange's mean value theorem, Rolle's theorem) so I suspect their use is required, though I don't see how. Thank you!","Let be a differentiable function such that and ,( ), then which of the following is always true? (A) (B) (C) (D) This question appeared in a test I gave today (its obviously completed). I would love a hint on how to approach this question, and also some insight on how I should have thought about it from the beginning. Since mean value theorems were on syllabus (Lagrange's mean value theorem, Rolle's theorem) so I suspect their use is required, though I don't see how. Thank you!","f:[0,1]\to \Bbb R f(0)=0 |f'(x)| \le k|f(x)|\;\forall x \in [0,1] k>0 f(x)=0 \; \forall \; x \in \Bbb R f(x)=0 \; \forall \; x \in [0,1] f(x) \ne 0 \; \forall \; x \in [0,1] f(1) = k","['calculus', 'functions']"
21,Find the Taylor series of $f^{\circ n}=\underset{n\text{ times}}{\underbrace{f\circ f \circ f\ldots \circ f}}$,Find the Taylor series of,f^{\circ n}=\underset{n\text{ times}}{\underbrace{f\circ f \circ f\ldots \circ f}},"Define $f(x)=ln(1+x)$. Then $f^{\circ 2}(x)=ln(1+ln(1+x))$, and $f^{\circ 3}(x)=ln(1+ln(1+ln(1+x)))$, etc. Find the Taylor series of $f^{\circ n}=\underset{n\text{ times}}{\underbrace{f\circ f \circ f\ldots \circ f}}$ about $x=0$ up to order $x^2$. How am I supposed to take a derivative of this function? If I use the chain rule the derivatives gets unwieldy very fast, unless I'm mistaken. Furthermore, how do I go about finding the Taylor series expansion for this composition?","Define $f(x)=ln(1+x)$. Then $f^{\circ 2}(x)=ln(1+ln(1+x))$, and $f^{\circ 3}(x)=ln(1+ln(1+ln(1+x)))$, etc. Find the Taylor series of $f^{\circ n}=\underset{n\text{ times}}{\underbrace{f\circ f \circ f\ldots \circ f}}$ about $x=0$ up to order $x^2$. How am I supposed to take a derivative of this function? If I use the chain rule the derivatives gets unwieldy very fast, unless I'm mistaken. Furthermore, how do I go about finding the Taylor series expansion for this composition?",,['real-analysis']
22,How to measure asymmetry of a function?,How to measure asymmetry of a function?,,"Let $f(x) = x^{2}$, so $f(x)$ is an upward symmetric parabola. It is a perfectly symmetric function since $f(x) = f(-x)$ for any value of $x$. Now, suppose $f$ is just some function. How would one measure how symmetric it is? I would like to arrive at something that I could use to compare two (or more) functions and make statements such as $f$ is more symmetric than $g$.","Let $f(x) = x^{2}$, so $f(x)$ is an upward symmetric parabola. It is a perfectly symmetric function since $f(x) = f(-x)$ for any value of $x$. Now, suppose $f$ is just some function. How would one measure how symmetric it is? I would like to arrive at something that I could use to compare two (or more) functions and make statements such as $f$ is more symmetric than $g$.",,"['calculus', 'functions', 'symmetry']"
23,"Show that the metric space C[a,b] is complete. [duplicate]","Show that the metric space C[a,b] is complete. [duplicate]",,"This question already has answers here : How to show that $C=C[0,1]$ is a Banach space (3 answers) Closed 9 years ago . Prove that the metric space $C[a,b]$ is complete. Where $C[a,b]$ is the collection of continuous $f:[a,b] → R$ and $||f|| = sup_{x \in [a,b]} |f(x)|$, such that $\rho (f,g) = ||f - g||$ is a metric on $C[a,b]$. attempt in proof: Recall that a metric space X is said to be complete if and only if every Cauchy sequence $x_n \in X$ converges to some point in $X$. Let $f_n$ be a Cauchy sequence in $ C[a,b]$, then $\forall \epsilon > 0,$ there is $N$ such that $||f_n - f_m|| < \epsilon$ for $n , m \geq N$ implies $||f_n - f_m || = sup |f_n - f_m | < \epsilon$. Now for $x \in [a,b]$, $|f_n - f_m | \leq sup_{x \in [a,b]} |f_n(x) - f_m(x)| < \epsilon$ for $n \geq N$. Thus $f_n(x)$ converges uniformly to $f(x)$ . And each $f_n$ is continous on $[a,b]$, and $f_n → f$ uniformly on $[a,b]$. Thus, $f \in C[a,b]$. So $C[a,b]$ is complete. Can someone please give some feedback? I don't know if I can conclude that $f_n$ converges uniformly to $f$. Can someone please help? Thank you in advance.","This question already has answers here : How to show that $C=C[0,1]$ is a Banach space (3 answers) Closed 9 years ago . Prove that the metric space $C[a,b]$ is complete. Where $C[a,b]$ is the collection of continuous $f:[a,b] → R$ and $||f|| = sup_{x \in [a,b]} |f(x)|$, such that $\rho (f,g) = ||f - g||$ is a metric on $C[a,b]$. attempt in proof: Recall that a metric space X is said to be complete if and only if every Cauchy sequence $x_n \in X$ converges to some point in $X$. Let $f_n$ be a Cauchy sequence in $ C[a,b]$, then $\forall \epsilon > 0,$ there is $N$ such that $||f_n - f_m|| < \epsilon$ for $n , m \geq N$ implies $||f_n - f_m || = sup |f_n - f_m | < \epsilon$. Now for $x \in [a,b]$, $|f_n - f_m | \leq sup_{x \in [a,b]} |f_n(x) - f_m(x)| < \epsilon$ for $n \geq N$. Thus $f_n(x)$ converges uniformly to $f(x)$ . And each $f_n$ is continous on $[a,b]$, and $f_n → f$ uniformly on $[a,b]$. Thus, $f \in C[a,b]$. So $C[a,b]$ is complete. Can someone please give some feedback? I don't know if I can conclude that $f_n$ converges uniformly to $f$. Can someone please help? Thank you in advance.",,"['real-analysis', 'functions', 'metric-spaces', 'uniform-continuity']"
24,"$f:\mathbb R \to \mathbb R$ is a differentiable function such that $f'(x)\le r<1 $ , does $f$ necessarily have a fixed point ? [duplicate]","is a differentiable function such that  , does  necessarily have a fixed point ? [duplicate]",f:\mathbb R \to \mathbb R f'(x)\le r<1  f,"This question already has answers here : Number of Fixed Point(s) of a Differentiable Function (2 answers) Closed 9 years ago . Let $f:\mathbb R \to \mathbb R$ be a differentiable function . If $\exists r \in \mathbb R $ such that $|f'(x)|\le r<1 , \forall x \in \mathbb R$ then using Lagrange's theorem one can show $f$ is a Lipscitz contraction and then use Banach contraction principle to conclude $f$ has a unique fixed-point. My question is what happens if $f'(x)\le r<1 , \forall x \in \mathbb R$ ? Then does $f$ even have a fixed point ?","This question already has answers here : Number of Fixed Point(s) of a Differentiable Function (2 answers) Closed 9 years ago . Let $f:\mathbb R \to \mathbb R$ be a differentiable function . If $\exists r \in \mathbb R $ such that $|f'(x)|\le r<1 , \forall x \in \mathbb R$ then using Lagrange's theorem one can show $f$ is a Lipscitz contraction and then use Banach contraction principle to conclude $f$ has a unique fixed-point. My question is what happens if $f'(x)\le r<1 , \forall x \in \mathbb R$ ? Then does $f$ even have a fixed point ?",,"['real-analysis', 'functions']"
25,Why do we focus so much in math on functions (as a subclass of relations)?,Why do we focus so much in math on functions (as a subclass of relations)?,,"Why is it that math so focuses on the subclass of relations known as functions? I.e. why is it so useful for us in nearly all branches of mathematics to focus on relations which are left-total and left-unique? Left- (or even right-) totality seem to be intuitive, since if an element doesn't appear in the domain, we might throw it out. But why left-uniqueness? I'm looking for something like a ""moral explanation"" of why they would be the most useful subclass of relations. My apologies if this is a previous question; I looked and didn't find much.","Why is it that math so focuses on the subclass of relations known as functions? I.e. why is it so useful for us in nearly all branches of mathematics to focus on relations which are left-total and left-unique? Left- (or even right-) totality seem to be intuitive, since if an element doesn't appear in the domain, we might throw it out. But why left-uniqueness? I'm looking for something like a ""moral explanation"" of why they would be the most useful subclass of relations. My apologies if this is a previous question; I looked and didn't find much.",,"['functions', 'soft-question', 'definition', 'philosophy']"
26,A Characterization of the Tangent Function?,A Characterization of the Tangent Function?,,"The tangent function has the amazing property that if $\alpha+\beta+\gamma=\pi$  with $\alpha,\beta,\gamma\in (0,\frac{\pi}{2})\cup(\frac{\pi}{2},\pi)$ then $$\tan\alpha+\tan\beta+\tan\gamma=\tan\alpha \tan\beta \tan\gamma$$ If we add a few additional criteria such that the function is non-constant, does this property already characterize the tangent, i.e. are there any other functions with this property besides the trivial solution $f=0$?","The tangent function has the amazing property that if $\alpha+\beta+\gamma=\pi$  with $\alpha,\beta,\gamma\in (0,\frac{\pi}{2})\cup(\frac{\pi}{2},\pi)$ then $$\tan\alpha+\tan\beta+\tan\gamma=\tan\alpha \tan\beta \tan\gamma$$ If we add a few additional criteria such that the function is non-constant, does this property already characterize the tangent, i.e. are there any other functions with this property besides the trivial solution $f=0$?",,['calculus']
27,Intersection of inverse images [duplicate],Intersection of inverse images [duplicate],,"This question already has answers here : how to prove $f^{-1}(B_1 \cap B_2) = f^{-1}(B_1) \cap f^{-1}(B_2)$ (2 answers) Closed 7 years ago . Given $A$ and $B$ is the subset of $C$ and $f:C\mapsto D$, $$f(A\cap B)\subseteq f(A) \cap f(B)$$ and the equality holds if the function is injective. But why for the inverse, suppose that $E$ and $F$ is the subset of $D$, $$f^{-1}(E \cap F) = f^{-1}(E) \cap f^{-1}(F)$$ without saying that the inverse function is injective. So if  $$x\in f^{-1}(E) \cap f^{-1}(F)$$ $$x\in f^{-1}(E) \text{ and } x\in f^{-1}(F)$$ This means that there exists elements $y_1 \in E$ and $y_2 \in F$. So here how do we know that these two elements are equal. I am independent learner so I hope I can get an explaination in more details.","This question already has answers here : how to prove $f^{-1}(B_1 \cap B_2) = f^{-1}(B_1) \cap f^{-1}(B_2)$ (2 answers) Closed 7 years ago . Given $A$ and $B$ is the subset of $C$ and $f:C\mapsto D$, $$f(A\cap B)\subseteq f(A) \cap f(B)$$ and the equality holds if the function is injective. But why for the inverse, suppose that $E$ and $F$ is the subset of $D$, $$f^{-1}(E \cap F) = f^{-1}(E) \cap f^{-1}(F)$$ without saying that the inverse function is injective. So if  $$x\in f^{-1}(E) \cap f^{-1}(F)$$ $$x\in f^{-1}(E) \text{ and } x\in f^{-1}(F)$$ This means that there exists elements $y_1 \in E$ and $y_2 \in F$. So here how do we know that these two elements are equal. I am independent learner so I hope I can get an explaination in more details.",,"['functions', 'elementary-set-theory']"
28,Another functional equation: $f(x) + f(2x) + f(4x) = \lfloor 7x \rfloor$,Another functional equation:,f(x) + f(2x) + f(4x) = \lfloor 7x \rfloor,"I would like to find all continuous functions $f \, : \, \mathbb{R} \, \longrightarrow \, \mathbb{R}$ such that : $$ \forall x \in \mathbb{R}, \; f(x) + f(2x) + f(4x) = \lfloor 7x \rfloor \tag{1}$$ Follow-up : Now that I know there are no continuous functions satisfying $(1)$, I would like to find all functions $f \, : \, \mathbb{R} \, \longrightarrow \, \mathbb{R}$, continuous at $0$, such that : $$ \forall x \in \mathbb{R}, \; f(x) + f(2x) + f(4x) = x \varphi(x) \tag{2} $$ where $\displaystyle \forall x \in \mathbb{R}, \; \varphi(x) = \begin{cases} 1 & \text{if } x \in \mathbb{Q} \\ 0 & \text{if } x \notin \mathbb{Q} \end{cases}$. I feel like there exist no such functions (but I might be mistaken). Here, both RHS and LHS are continuous at $x=0$. My try : It is clear that $f(0)=0$. Since $\varphi(qx)=\varphi(x)$ for all $x \in \mathbb{R}$ and all $q \in \mathbb{Q}$, I think the following is true : $$ f(8x) - f(x) = x \varphi(x) $$ which leads to : $$ f(x) - f \Big( \frac{x}{8} \Big) = \frac{x}{8} \varphi(x) $$ which would lead to $$ f(x) - f \Big( \frac{x}{2^{3k}} \Big) = \frac{x}{2^{3k}} \varphi(x) $$ Am I on the right track or is there an easier way ?","I would like to find all continuous functions $f \, : \, \mathbb{R} \, \longrightarrow \, \mathbb{R}$ such that : $$ \forall x \in \mathbb{R}, \; f(x) + f(2x) + f(4x) = \lfloor 7x \rfloor \tag{1}$$ Follow-up : Now that I know there are no continuous functions satisfying $(1)$, I would like to find all functions $f \, : \, \mathbb{R} \, \longrightarrow \, \mathbb{R}$, continuous at $0$, such that : $$ \forall x \in \mathbb{R}, \; f(x) + f(2x) + f(4x) = x \varphi(x) \tag{2} $$ where $\displaystyle \forall x \in \mathbb{R}, \; \varphi(x) = \begin{cases} 1 & \text{if } x \in \mathbb{Q} \\ 0 & \text{if } x \notin \mathbb{Q} \end{cases}$. I feel like there exist no such functions (but I might be mistaken). Here, both RHS and LHS are continuous at $x=0$. My try : It is clear that $f(0)=0$. Since $\varphi(qx)=\varphi(x)$ for all $x \in \mathbb{R}$ and all $q \in \mathbb{Q}$, I think the following is true : $$ f(8x) - f(x) = x \varphi(x) $$ which leads to : $$ f(x) - f \Big( \frac{x}{8} \Big) = \frac{x}{8} \varphi(x) $$ which would lead to $$ f(x) - f \Big( \frac{x}{2^{3k}} \Big) = \frac{x}{2^{3k}} \varphi(x) $$ Am I on the right track or is there an easier way ?",,"['real-analysis', 'functions', 'continuity', 'functional-equations', 'ceiling-and-floor-functions']"
29,Can a multivariate function be represented as finite combination of one-variable functions?,Can a multivariate function be represented as finite combination of one-variable functions?,,"Suppose we have a function $f\colon \mathbb{R}^n\to\mathbb{R}$, which is analytic almost everywhere. Can one say that there exists a finite sequence of operations, which will evaluate $f$ for any argument, if the operations are limited to: arbitrary (piecewise-) analytic single-variable functions $g_i\colon \mathbb{R}\to\mathbb{R}$ arithmetic ? How can this be (dis)proved?","Suppose we have a function $f\colon \mathbb{R}^n\to\mathbb{R}$, which is analytic almost everywhere. Can one say that there exists a finite sequence of operations, which will evaluate $f$ for any argument, if the operations are limited to: arbitrary (piecewise-) analytic single-variable functions $g_i\colon \mathbb{R}\to\mathbb{R}$ arithmetic ? How can this be (dis)proved?",,['functions']
30,"Recursion, multiplication and exponential","Recursion, multiplication and exponential",,"The set $F_{n}$ of primitive recursive function symbols of arty $n$ can be defined inductively as \begin{array}[lr] & Z, \text{Succ} \in F_{1} & \\ \pi_{j}^{n} \in F_{n} \quad \text{for each} \quad j=1,\dots, n \\ &\text{if} \quad f \in F_{n} \quad \text{and} g_{1},\dots, g_{n} \in F_{m}, \text{then} \circ_{n}^{m}[f,g_{1},\dots,g_{n}]\in F_{m} & \\ &\text{if} \quad f \in F_{n+2} \quad \text{and} \quad g \in F_{n}, \text{then} \quad \text{Rec}^{n}[f,g]\in F_{n} & \end{array} Given the interpretation $f \in F_{n}$, $[[f]]:\mathbb{N}^{n} \to \mathbb{N}$ \begin{array}[lr] [[Z]](k)&=& 0 \\ [[\text{Succ}]](k) &= &k+1 \\ [[\pi_{j}^{n}]](k_{1},\dots,k_{n}) &= &k_{j} \\ [[\circ_{n}^{m}[f,g_{1},\dots,g_{n}]]](k_{1},\dots,k_{m}) &= &[[f]]([[g_{1}]](k_{1},\dots,k_{m}),\dots, [[g_{n}]](k_{1},\dots, k_{m})) \\ [[\text{Rec}^{n}[f,g]]](k_{1},\dots,k_{n},0) &= & [[g]](k_{1},\dots,k_{n}) \\ [[\text{Rec}^{n}[f,g]]](k_{1},\dots,k_{n},m+1) &= & [[f]](k_{1},\dots,k_{n},m,[[\text{Rec}^{n}[f,g]]](k_{1},\dots,k_{n},m) \end{array} find functions $A,B \in F_{2}$ that yields $[[A]](x,y)=xy$ and $[[B]](x,y)=x^{y}$. Note $[[0]]=0$,$[[S(a)]]=[[a]]+1$, and $[[f(a_{1},\dots,a_{n})]]=[[f]]([[a_{1}]],\dots,[[a_{n}]])$ for $f \in F_{n}$","The set $F_{n}$ of primitive recursive function symbols of arty $n$ can be defined inductively as \begin{array}[lr] & Z, \text{Succ} \in F_{1} & \\ \pi_{j}^{n} \in F_{n} \quad \text{for each} \quad j=1,\dots, n \\ &\text{if} \quad f \in F_{n} \quad \text{and} g_{1},\dots, g_{n} \in F_{m}, \text{then} \circ_{n}^{m}[f,g_{1},\dots,g_{n}]\in F_{m} & \\ &\text{if} \quad f \in F_{n+2} \quad \text{and} \quad g \in F_{n}, \text{then} \quad \text{Rec}^{n}[f,g]\in F_{n} & \end{array} Given the interpretation $f \in F_{n}$, $[[f]]:\mathbb{N}^{n} \to \mathbb{N}$ \begin{array}[lr] [[Z]](k)&=& 0 \\ [[\text{Succ}]](k) &= &k+1 \\ [[\pi_{j}^{n}]](k_{1},\dots,k_{n}) &= &k_{j} \\ [[\circ_{n}^{m}[f,g_{1},\dots,g_{n}]]](k_{1},\dots,k_{m}) &= &[[f]]([[g_{1}]](k_{1},\dots,k_{m}),\dots, [[g_{n}]](k_{1},\dots, k_{m})) \\ [[\text{Rec}^{n}[f,g]]](k_{1},\dots,k_{n},0) &= & [[g]](k_{1},\dots,k_{n}) \\ [[\text{Rec}^{n}[f,g]]](k_{1},\dots,k_{n},m+1) &= & [[f]](k_{1},\dots,k_{n},m,[[\text{Rec}^{n}[f,g]]](k_{1},\dots,k_{n},m) \end{array} find functions $A,B \in F_{2}$ that yields $[[A]](x,y)=xy$ and $[[B]](x,y)=x^{y}$. Note $[[0]]=0$,$[[S(a)]]=[[a]]+1$, and $[[f(a_{1},\dots,a_{n})]]=[[f]]([[a_{1}]],\dots,[[a_{n}]])$ for $f \in F_{n}$",,"['functions', 'logic', 'self-learning', 'recursive-algorithms', 'recursion']"
31,Solve $g(g(x))=f(x)$,Solve,g(g(x))=f(x),"If $f(x)$ is a continuous and monotonically increasing function on an interval $(0,∞)$ and $f(x)>0$ for every $x>0$, then does there always exist a continuous and monotonically increasing function $g(x)$ on $(0,∞)$ so that for every $x\in (0,∞),g(x)\in (0,∞)$ and $g(g(x))=f(x)$? If $f(x)=c~x^k~(c>0,k>0),$and $g(x)=r~x^{\sqrt{k}},$where $c=r^{\sqrt{k}+1},$then $g(g(x))=f(x)~(x>0).$ But how to solve it in general conditions?Thanks in advance!","If $f(x)$ is a continuous and monotonically increasing function on an interval $(0,∞)$ and $f(x)>0$ for every $x>0$, then does there always exist a continuous and monotonically increasing function $g(x)$ on $(0,∞)$ so that for every $x\in (0,∞),g(x)\in (0,∞)$ and $g(g(x))=f(x)$? If $f(x)=c~x^k~(c>0,k>0),$and $g(x)=r~x^{\sqrt{k}},$where $c=r^{\sqrt{k}+1},$then $g(g(x))=f(x)~(x>0).$ But how to solve it in general conditions?Thanks in advance!",,"['real-analysis', 'functions']"
32,Is the variant direct image mathematically significant?,Is the variant direct image mathematically significant?,,"Preimages have the property that for an arbitrary function $f : X \rightarrow Y$ and all $B \subseteq Y$ it holds that $$f^{-1}(B^c)=[f^{-1}(B)]^c.$$ However, the analogous statement for direct images is false. Thus, we have two definitions of direct image; the usual one, and a variant. $$f_*(A) = \{b \mid \exists a \in X : a \in A \,\wedge\, f(a)=b\}$$ $$f_\diamond(A) = \{b \mid \forall a \in X : a \in A \,\vee\, f(a) \neq b\}$$ Now I think (though I have not proved it) that, for all functions $f$, it holds that $f_* = f_\diamond$ iff $f$ is an injection bijection. Note also that, under these definitions, we have $$f_*(A^c) = [f_\diamond(A)]^c, \quad f_\diamond(A^c)=[f_*(A)]^c.$$ Here's another observation. If $X$ and $Y$ are topological spaces, then we have that $f_*$ preserves openness iff $f_\diamond$ preserves closedness, and vice versa. Okay, but does $f_\diamond$ have any real mathematical significance? Like, does it show up naturally in any interesting theorems etc.? If so, what's the standard terminology/notation, and where can I learn more? Addendum . Two related maps are $f_\cap(A) := f_*(A) \cap f_\diamond(A)$ and $f_\cup(A) := f_*(A) \cup f_\diamond(A).$ If anyone knows where I can learn more, please leave a comment! Note that all four concepts coincide in the case of bijections.","Preimages have the property that for an arbitrary function $f : X \rightarrow Y$ and all $B \subseteq Y$ it holds that $$f^{-1}(B^c)=[f^{-1}(B)]^c.$$ However, the analogous statement for direct images is false. Thus, we have two definitions of direct image; the usual one, and a variant. $$f_*(A) = \{b \mid \exists a \in X : a \in A \,\wedge\, f(a)=b\}$$ $$f_\diamond(A) = \{b \mid \forall a \in X : a \in A \,\vee\, f(a) \neq b\}$$ Now I think (though I have not proved it) that, for all functions $f$, it holds that $f_* = f_\diamond$ iff $f$ is an injection bijection. Note also that, under these definitions, we have $$f_*(A^c) = [f_\diamond(A)]^c, \quad f_\diamond(A^c)=[f_*(A)]^c.$$ Here's another observation. If $X$ and $Y$ are topological spaces, then we have that $f_*$ preserves openness iff $f_\diamond$ preserves closedness, and vice versa. Okay, but does $f_\diamond$ have any real mathematical significance? Like, does it show up naturally in any interesting theorems etc.? If so, what's the standard terminology/notation, and where can I learn more? Addendum . Two related maps are $f_\cap(A) := f_*(A) \cap f_\diamond(A)$ and $f_\cup(A) := f_*(A) \cup f_\diamond(A).$ If anyone knows where I can learn more, please leave a comment! Note that all four concepts coincide in the case of bijections.",,"['reference-request', 'functions', 'notation', 'terminology']"
33,How to show $f(x) \leq 1+\frac{\pi}{4}$ for every $x \geq 1$,How to show  for every,f(x) \leq 1+\frac{\pi}{4} x \geq 1,"Suppose $f$ is a real-valued differentiable function  defined on $[ 1,\infty)$ with $f(1)=1$. Suppose , moreover , that $f$ satisfies     $$f'(x)=\frac{1}{x^2+f^2(x)}$$   Show that $f(x) \leq 1+\frac{\pi}{4}$ for every $x \geq 1$ . Trial: I try to find the maximum value of $f(x)$ but here $f'(x)=0$ has no solution.","Suppose $f$ is a real-valued differentiable function  defined on $[ 1,\infty)$ with $f(1)=1$. Suppose , moreover , that $f$ satisfies     $$f'(x)=\frac{1}{x^2+f^2(x)}$$   Show that $f(x) \leq 1+\frac{\pi}{4}$ for every $x \geq 1$ . Trial: I try to find the maximum value of $f(x)$ but here $f'(x)=0$ has no solution.",,"['functions', 'inequality']"
34,convex relaxations,convex relaxations,,"Is there a notion of ""best"" convex relaxation of a particular function in a normed vector space? For example, the $\ell^0$ pseudo-norm can be relaxed into the $\ell^1$ norm, and that allows us to solve sparse recovery problems. Is there a general recipe to construct such relaxations given an arbitrary function? Specifically, I have a function of the form $f(x) = \|x\|_2\|x\|_1$, which is non convex. How would I go about relaxing this? Any resources/links I should look into?","Is there a notion of ""best"" convex relaxation of a particular function in a normed vector space? For example, the $\ell^0$ pseudo-norm can be relaxed into the $\ell^1$ norm, and that allows us to solve sparse recovery problems. Is there a general recipe to construct such relaxations given an arbitrary function? Specifically, I have a function of the form $f(x) = \|x\|_2\|x\|_1$, which is non convex. How would I go about relaxing this? Any resources/links I should look into?",,"['functions', 'convex-analysis']"
35,How can I guarantee that $f$ applied to the mean of all $x$'s is equal to the mean of $f$ applied to all $x$'s?,How can I guarantee that  applied to the mean of all 's is equal to the mean of  applied to all 's?,f x f x,"I would like to know which properties a function $f:\mathbb{R}\rightarrow\mathbb{R}$ must have so that I can say: $$f(\overline{x}) = \overline{f(x)}$$ with $\overline{x}$ being the mean of the $x$'s. Or, more explicitly written: $$f \left(\frac{x_1 + x_2 + \cdots + x_n}{n}\right) = \frac{f(x_1) + f(x_2) + \cdots + f(x_n)}{n}$$ Thanks in advance.","I would like to know which properties a function $f:\mathbb{R}\rightarrow\mathbb{R}$ must have so that I can say: $$f(\overline{x}) = \overline{f(x)}$$ with $\overline{x}$ being the mean of the $x$'s. Or, more explicitly written: $$f \left(\frac{x_1 + x_2 + \cdots + x_n}{n}\right) = \frac{f(x_1) + f(x_2) + \cdots + f(x_n)}{n}$$ Thanks in advance.",,['functions']
36,Mathematical function for weighting results,Mathematical function for weighting results,,"I am trying to find a mathematical function that would provide certain weighting to the values of my algorithm. Namely, having two values, x,y, I would like to provide a function that would favour big differences between x and y. Ideally, it would return 1, if x = -inf and y = +inf (or vice versa) and 0, if they are equal. On top of that, I would like it to be non-linear in growth. I hope the above makes sense. Thank you very much in advance for your comments and answers.","I am trying to find a mathematical function that would provide certain weighting to the values of my algorithm. Namely, having two values, x,y, I would like to provide a function that would favour big differences between x and y. Ideally, it would return 1, if x = -inf and y = +inf (or vice versa) and 0, if they are equal. On top of that, I would like it to be non-linear in growth. I hope the above makes sense. Thank you very much in advance for your comments and answers.",,['functions']
37,Olympic question about functions,Olympic question about functions,,"I have been trying to solve the following question: Let $f: \left \{ 1,2,... \right \}\rightarrow \mathbb{R}$ be a function such that $f(n) - f(n+1) = f(n)f(n+1)$ . If $f(2020) = \frac{1}{4040}$ , find $f(1)$ The answer is f(1) = $\frac{1}{2021}$ . Using a simple algebraic manipulation, I found that if $f(2020) = \frac{1}{4040}$ then $f(2019) = \frac{1}{4039}$ , what is interesting for the problem considering the answer... How can i progress? Or there a trick way in these question","I have been trying to solve the following question: Let be a function such that . If , find The answer is f(1) = . Using a simple algebraic manipulation, I found that if then , what is interesting for the problem considering the answer... How can i progress? Or there a trick way in these question","f: \left \{ 1,2,... \right \}\rightarrow \mathbb{R} f(n) - f(n+1) = f(n)f(n+1) f(2020) = \frac{1}{4040} f(1) \frac{1}{2021} f(2020) = \frac{1}{4040} f(2019) = \frac{1}{4039}","['functions', 'contest-math', 'problem-solving']"
38,"If $f:\mathbb R\to\mathbb R$ is continuous and $f(x)f(x+2)+f(x+1)=0$ for all $x$, prove $f(x)=0$ for infinitely many $x$","If  is continuous and  for all , prove  for infinitely many",f:\mathbb R\to\mathbb R f(x)f(x+2)+f(x+1)=0 x f(x)=0 x,"Let $f:\mathbb{R}\to\mathbb{R}$ be a continuous function such that $f(x)f(x+2)+f(x+1)=0$ for all $x\in\mathbb{R}$ . Prove that there are infinitely many real values of $x$ such that $f(x)=0$ . Here is my approach (by inspection): For $x=0$ we have $f(0)f(2)+f(1)=0$ (Eq1). Now, if $f(0)=0$ , then $f(1)=0$ . From $f(1)f(3)+f(2)=0$ for $x=1$ we can also conclude that $f(2)=0$ . In this case it's not hard to prove that $f(n)=0\ \ \forall n\in\mathbb{N}$ . On the other hand, if $f(0)>0$ , then Eq1 let us conclude that $f(1)$ and $f(2)$ have opposite signs, say $f(1)<0<f(2)$ . In this case, the IVT guarantes that there exists a $c\in (1,2)$ such that $f(c)=0$ . Again, it's not hard to prove that $f(n+c)=0\ \ \forall n\in\mathbb{N}$ . I am stuck with the case where $f(0)<0$ . In this case $f(1)$ and $f(2)$ have the same sign and I couldn't figure out what to do next. Any hint to this case or a different approach would be great. Thanks in advance.","Let be a continuous function such that for all . Prove that there are infinitely many real values of such that . Here is my approach (by inspection): For we have (Eq1). Now, if , then . From for we can also conclude that . In this case it's not hard to prove that . On the other hand, if , then Eq1 let us conclude that and have opposite signs, say . In this case, the IVT guarantes that there exists a such that . Again, it's not hard to prove that . I am stuck with the case where . In this case and have the same sign and I couldn't figure out what to do next. Any hint to this case or a different approach would be great. Thanks in advance.","f:\mathbb{R}\to\mathbb{R} f(x)f(x+2)+f(x+1)=0 x\in\mathbb{R} x f(x)=0 x=0 f(0)f(2)+f(1)=0 f(0)=0 f(1)=0 f(1)f(3)+f(2)=0 x=1 f(2)=0 f(n)=0\ \ \forall n\in\mathbb{N} f(0)>0 f(1) f(2) f(1)<0<f(2) c\in (1,2) f(c)=0 f(n+c)=0\ \ \forall n\in\mathbb{N} f(0)<0 f(1) f(2)","['real-analysis', 'functions', 'continuity', 'functional-equations']"
39,How can the Loss Functions of Neural Networks be Non-Convex?,How can the Loss Functions of Neural Networks be Non-Convex?,,"I have heard the following argument being made regarding Neural Networks: A Neural Network is a composition of several Activation Functions Sigmoid Activation Functions are Non-Convex Functions The composition of Non-Convex Functions can produce a Non-Convex Function Thus, Loss Functions for Neural Networks that contain several Sigmoid Activation Functions can be Non-Convex Using the R programming language, I plotted the second derivative of the Sigmoid Function and we can see that it fails the Convexity Test (i.e. the second derivative can take both positive and negative values): e = 2.718  eq = function(x){ (-e^-x)* (1+e^-x)^-2  + (e^-x)*(-2*(1+e^-x)^-3 *(-e^-x))}  plot(eq(-100:100), type='l', main = ""Plot of Second Derivative of the Sigmoid Function"") My Question: (If the above argument is in fact true) Can the same argument be extended to lack of Convexity of Loss Functions of Neural Networks containing several ""RELU Activation Functions"" ? On it's own, the ReLU function is said to be Convex. Mathematically, we can show that compositions of Convex Functions can only produce a Convex Function ( The composition of two convex functions is convex ). I understand that the composition of two Convex functions can produce a Concave Function - but still, the composition of two Convex Functions can not produce a ""classic type of Non-Convex Function"" (e.g. a function with several local minima and saddle points). However, Neural Networks that contain compositions of (only) ReLU Activation functions make it unclear to me how a Loss Functions that contains (only) ""RELU Activation Functions"" would a Non-Convex. (The only thing I can think of is that the Loss Function in Neural Networks is made of linear combinations of function compositions - and even though compositions of convex functions are always convex, pe rhaps the linear combination of compositions for convex functions might not necessarily be convex ... but I am not sure about this ) Can someone please comment on this? If compositions of Convex Functions can only produce Convex Functions - does this mean that the Loss Function of a Neural Network containing only containing ReLU Activation Functions can never be Non-Convex? Thanks! References: https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html Note: Using some informal logic, I do not think that the Loss Functions of Neural Networks containing RELU Activation Functions are generally Convex. This is because RELU (style) Activation Functions are generally some of the most common types of activation functions being used - yet the same difficulties concerning mon-convex optimization still remain. Thus, I would like to think that Neural Networks with RELU Activation Functions are still generally non-convex. For example, below we can see the Loss Surfaces of (Modern) Neural Networks that clearly look Non-Convex: ( https://www.cs.umd.edu/~tomg/projects/landscapes/ )","I have heard the following argument being made regarding Neural Networks: A Neural Network is a composition of several Activation Functions Sigmoid Activation Functions are Non-Convex Functions The composition of Non-Convex Functions can produce a Non-Convex Function Thus, Loss Functions for Neural Networks that contain several Sigmoid Activation Functions can be Non-Convex Using the R programming language, I plotted the second derivative of the Sigmoid Function and we can see that it fails the Convexity Test (i.e. the second derivative can take both positive and negative values): e = 2.718  eq = function(x){ (-e^-x)* (1+e^-x)^-2  + (e^-x)*(-2*(1+e^-x)^-3 *(-e^-x))}  plot(eq(-100:100), type='l', main = ""Plot of Second Derivative of the Sigmoid Function"") My Question: (If the above argument is in fact true) Can the same argument be extended to lack of Convexity of Loss Functions of Neural Networks containing several ""RELU Activation Functions"" ? On it's own, the ReLU function is said to be Convex. Mathematically, we can show that compositions of Convex Functions can only produce a Convex Function ( The composition of two convex functions is convex ). I understand that the composition of two Convex functions can produce a Concave Function - but still, the composition of two Convex Functions can not produce a ""classic type of Non-Convex Function"" (e.g. a function with several local minima and saddle points). However, Neural Networks that contain compositions of (only) ReLU Activation functions make it unclear to me how a Loss Functions that contains (only) ""RELU Activation Functions"" would a Non-Convex. (The only thing I can think of is that the Loss Function in Neural Networks is made of linear combinations of function compositions - and even though compositions of convex functions are always convex, pe rhaps the linear combination of compositions for convex functions might not necessarily be convex ... but I am not sure about this ) Can someone please comment on this? If compositions of Convex Functions can only produce Convex Functions - does this mean that the Loss Function of a Neural Network containing only containing ReLU Activation Functions can never be Non-Convex? Thanks! References: https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html Note: Using some informal logic, I do not think that the Loss Functions of Neural Networks containing RELU Activation Functions are generally Convex. This is because RELU (style) Activation Functions are generally some of the most common types of activation functions being used - yet the same difficulties concerning mon-convex optimization still remain. Thus, I would like to think that Neural Networks with RELU Activation Functions are still generally non-convex. For example, below we can see the Loss Surfaces of (Modern) Neural Networks that clearly look Non-Convex: ( https://www.cs.umd.edu/~tomg/projects/landscapes/ )",,"['functions', 'convex-analysis', 'machine-learning', 'neural-networks']"
40,Continuity & Domain: What Is Their Relationship?,Continuity & Domain: What Is Their Relationship?,,"It's hard for me to formulate this into a specific question, so I'll split this into two sub-questions that will hopefully explain my confusion. Say I have the function $\frac{x}{x}$ . As far as my understanding goes, this guy is discontinuous at $x=0$ , but is continuous at any other point on the real line (with both limits & function values being $1$ ); the limit is $1$ at $x=0$ as well, but the function's value is not (nor is it anything, seeing as it is not defined there), which is why it's not continuous at that point. Assuming the above is true, I can look at $\frac{x}{x}$ as the product of, for instance, $f(x)=x$ and $g(x)=x^{-1}$ , and say that it is discontinuous at $x=0$ simply because the domain of $g$ (and therefore, the domain of the product) does not include $0$ . A discussion I was reading seemed to conclude that, for a function $g(x)$ discontinuous at point $a$ and a continuous function $f(x)$ , the product $f(x) \cdot g(x)$ is discontinuous at $a$ if neither $f(x)$ nor $g(x)$ are $0$ , but is continuous $\forall x \in \mathbb{R}$ (incl. a) if, e.g, $f(x)=0$ for all $x \in R$ . Though, to my understanding, this is only true if the discontinuity isn't caused by a point in which either function is undefined. For example, if $f(x)=0$ and $g(x)=\frac{1}{x}$ , then it would still be wrong of me to say that $f(x) \cdot g(x)$ is continuous at $0$ , because $0$ should be out of its domain. Is this right? And for the second part of the question: I initially began this question with ""Say I have the function $\frac{x}{x}$ over $\mathbb{R}$ "", but then felt extremely unsure about whether I could even say that, seeing as it is not defined at $x=0$ and a function needs to be defined over the entirety of its own domain. In the case of the function mentioned above, the domain must therefore not include $0$ , so it could, for example, be $\mathbb{R} \setminus \{0\}$ . But then this raises another question: I saw a mention of the Dirichlet function being continuous over the rationals; but if this is the case then continuity is domain-dependent, and so if I define $\frac{x}{x}$ over $\mathbb{R} \setminus \{0\}$ , then it is continuous. I can tell there's a difference here: the function is continuous over the entirety of its own domain; but it then gets a bit more confusing when I have a product of two different functions with different domains. Please help me understand the relationship between domain & continuity, and/or point out any inconsistencies in my understanding described above.","It's hard for me to formulate this into a specific question, so I'll split this into two sub-questions that will hopefully explain my confusion. Say I have the function . As far as my understanding goes, this guy is discontinuous at , but is continuous at any other point on the real line (with both limits & function values being ); the limit is at as well, but the function's value is not (nor is it anything, seeing as it is not defined there), which is why it's not continuous at that point. Assuming the above is true, I can look at as the product of, for instance, and , and say that it is discontinuous at simply because the domain of (and therefore, the domain of the product) does not include . A discussion I was reading seemed to conclude that, for a function discontinuous at point and a continuous function , the product is discontinuous at if neither nor are , but is continuous (incl. a) if, e.g, for all . Though, to my understanding, this is only true if the discontinuity isn't caused by a point in which either function is undefined. For example, if and , then it would still be wrong of me to say that is continuous at , because should be out of its domain. Is this right? And for the second part of the question: I initially began this question with ""Say I have the function over "", but then felt extremely unsure about whether I could even say that, seeing as it is not defined at and a function needs to be defined over the entirety of its own domain. In the case of the function mentioned above, the domain must therefore not include , so it could, for example, be . But then this raises another question: I saw a mention of the Dirichlet function being continuous over the rationals; but if this is the case then continuity is domain-dependent, and so if I define over , then it is continuous. I can tell there's a difference here: the function is continuous over the entirety of its own domain; but it then gets a bit more confusing when I have a product of two different functions with different domains. Please help me understand the relationship between domain & continuity, and/or point out any inconsistencies in my understanding described above.",\frac{x}{x} x=0 1 1 x=0 \frac{x}{x} f(x)=x g(x)=x^{-1} x=0 g 0 g(x) a f(x) f(x) \cdot g(x) a f(x) g(x) 0 \forall x \in \mathbb{R} f(x)=0 x \in R f(x)=0 g(x)=\frac{1}{x} f(x) \cdot g(x) 0 0 \frac{x}{x} \mathbb{R} x=0 0 \mathbb{R} \setminus \{0\} \frac{x}{x} \mathbb{R} \setminus \{0\},"['real-analysis', 'functions', 'continuity']"
41,"Show that $x^\frac{1}{n}$ is continuous at all $a \in [0,\infty)$",Show that  is continuous at all,"x^\frac{1}{n} a \in [0,\infty)","I have to show $x^\frac{1}{n}$ is continuous using: $|x-a| = |(x^\frac{1}{n})^n - (a^\frac{1}{n})^n| = |x^\frac{1}{n} - a^\frac{1}{n}||\displaystyle \sum_{k=1}^{n-1} (x^\frac{1}{n})^{n-1-k} + (a^\frac{1}{n})^{k} |$ Here's what I did: $a=0$ : $|x^\frac{1}{n}| < \epsilon => |x| < \epsilon^n$ Pick $\delta = \epsilon^n$ , and we have $f(x)$ is continuous at $x=0$ $a>0$ : $|x-a| = |x^\frac{1}{n} - a^\frac{1}{n}||\displaystyle\sum_{k=1}^{n-1} (x^\frac{1}{n})^{n-1-k} + (a^\frac{1}{n})^{k}| < \epsilon \cdot |\displaystyle\sum_{k=1}^{n-1} (x^\frac{1}{n})^{n-1-k} + (a^\frac{1}{n})^{k}|$ Since this sum evaluates to a real number $R > 0$ , we can pick $\delta = R\epsilon $ and we get: $0<|x-a| < \delta => |x^\frac{1}{n} - a^\frac{1}{n}| < \epsilon$ Is this correct or is there anything else I need to show? Also, this is my first time formatting with MathJax, so if there are any errors please let me know!","I have to show is continuous using: Here's what I did: : Pick , and we have is continuous at : Since this sum evaluates to a real number , we can pick and we get: Is this correct or is there anything else I need to show? Also, this is my first time formatting with MathJax, so if there are any errors please let me know!",x^\frac{1}{n} |x-a| = |(x^\frac{1}{n})^n - (a^\frac{1}{n})^n| = |x^\frac{1}{n} - a^\frac{1}{n}||\displaystyle \sum_{k=1}^{n-1} (x^\frac{1}{n})^{n-1-k} + (a^\frac{1}{n})^{k} | a=0 |x^\frac{1}{n}| < \epsilon => |x| < \epsilon^n \delta = \epsilon^n f(x) x=0 a>0 |x-a| = |x^\frac{1}{n} - a^\frac{1}{n}||\displaystyle\sum_{k=1}^{n-1} (x^\frac{1}{n})^{n-1-k} + (a^\frac{1}{n})^{k}| < \epsilon \cdot |\displaystyle\sum_{k=1}^{n-1} (x^\frac{1}{n})^{n-1-k} + (a^\frac{1}{n})^{k}| R > 0 \delta = R\epsilon  0<|x-a| < \delta => |x^\frac{1}{n} - a^\frac{1}{n}| < \epsilon,"['real-analysis', 'calculus', 'functions', 'continuity']"
42,"Proof: For $n \in \mathbb{Z_+}$, the set of all functions $f: \{1,...,n\} \to \mathbb{Z_+}$ is countable","Proof: For , the set of all functions  is countable","n \in \mathbb{Z_+} f: \{1,...,n\} \to \mathbb{Z_+}","(citation: Munkres Topology 7.5 b) Backgound (from Munkres Topology Chapter 7): Theorem 7.1: $B$ is a nonempty countable set $\Leftarrow\Rightarrow$ there is an injective function $g: B \to \mathbb{Z_+}$ Theorem 7.6: a finite product of countable sets is countable PROOF Let $B_n = \{f | f: \{1,...n\} \to \mathbb{Z_+}\}$ and let $\mathbb{Z_+^n} = \{(z_1, z_2,...,z_n)|z_1, z_2,...,z_n\in \mathbb{Z_+}\}$ . Define the function $g_n: B_n \to \mathbb{Z_+^n}$ such that $g_n(f) = (f(1), f(2),...,f(n))$ , where $f\in B_n$ . Let $z = z' \in \mathbb{Z_+^n}$ , such that $z = g_n(f), z' = g_n(f')$ for $f,f'\in B_n$ . Then $z = (f(1),f(2),...,f(n)) = (f'(1),f'(2),...,f'(n)) = z'$ , which holds iff $f(1)=f'(1), f(2)=f'(2),...,f(n)=f'(n)$ . This implies that $f = f'$ , hence $g_n$ is an injection from $B_n$ into $\mathbb{Z_+^n}$ . $\mathbb{Z_+^n}$ is countable by Theorem 7.6, as $\mathbb{Z_+}$ is countable.  Thus, by Theorem 7.1, $\exists$ an injective function $h: \mathbb{Z_+^n}\to \mathbb{Z_+}$ .  Then, $h \circ g_n: B_n\to \mathbb{Z_+}$ is injective. Therefore, by Theorem 7.1, $B_n$ is countable. I believe this is sufficient, but please let me know, if it may be corrected or improved.","(citation: Munkres Topology 7.5 b) Backgound (from Munkres Topology Chapter 7): Theorem 7.1: is a nonempty countable set there is an injective function Theorem 7.6: a finite product of countable sets is countable PROOF Let and let . Define the function such that , where . Let , such that for . Then , which holds iff . This implies that , hence is an injection from into . is countable by Theorem 7.6, as is countable.  Thus, by Theorem 7.1, an injective function .  Then, is injective. Therefore, by Theorem 7.1, is countable. I believe this is sufficient, but please let me know, if it may be corrected or improved.","B \Leftarrow\Rightarrow g: B \to \mathbb{Z_+} B_n = \{f | f: \{1,...n\} \to \mathbb{Z_+}\} \mathbb{Z_+^n} = \{(z_1, z_2,...,z_n)|z_1, z_2,...,z_n\in \mathbb{Z_+}\} g_n: B_n \to \mathbb{Z_+^n} g_n(f) = (f(1), f(2),...,f(n)) f\in B_n z = z' \in \mathbb{Z_+^n} z = g_n(f), z' = g_n(f') f,f'\in B_n z = (f(1),f(2),...,f(n)) = (f'(1),f'(2),...,f'(n)) = z' f(1)=f'(1), f(2)=f'(2),...,f(n)=f'(n) f = f' g_n B_n \mathbb{Z_+^n} \mathbb{Z_+^n} \mathbb{Z_+} \exists h: \mathbb{Z_+^n}\to \mathbb{Z_+} h \circ g_n: B_n\to \mathbb{Z_+} B_n","['functions', 'solution-verification']"
43,Find all continuous $f$ that $f(xy) = xf(y) + yf(x)$.,Find all continuous  that .,f f(xy) = xf(y) + yf(x),Determine all continuous $f : \mathbb R \rightarrow \mathbb R$ that satisfies $$f(xy) = xf(y) + yf(x)$$ I tried rewrite the equation as $f(xy) + f(x)f(y) + xy = (f(x) + x)(f(y) + y)$ and I know that $f(0) = f(1) = 0$ . Thanks in advance!,Determine all continuous that satisfies I tried rewrite the equation as and I know that . Thanks in advance!,f : \mathbb R \rightarrow \mathbb R f(xy) = xf(y) + yf(x) f(xy) + f(x)f(y) + xy = (f(x) + x)(f(y) + y) f(0) = f(1) = 0,"['functions', 'continuity', 'contest-math', 'functional-equations']"
44,"Interesting question about finding a quadratic polynomial such that $h(\alpha)=\beta, \ h(\beta)=\gamma, \ h(\gamma)=\alpha$",Interesting question about finding a quadratic polynomial such that,"h(\alpha)=\beta, \ h(\beta)=\gamma, \ h(\gamma)=\alpha","$f(x)=x^3-3x^2+1, \forall x\in\mathbb R$ , $g(x)=1-\frac{1}{x} ,\forall x\in\mathbb R, x \neq 0$ . i) Show that $f(x)$ has $3$ distinct and real roots. ii) It is given $\gamma < \beta < \alpha$ , where $\gamma, \alpha, \beta$ are the roots of $f(x)$ . Show that $g(\alpha)=\beta, \ g(\beta)=\gamma, \ g(\gamma)=\alpha$ . iii) Given $h(x)$ is a quadratic function such that $h(\alpha)=\beta, \ h(\beta)=\gamma, \ h(\gamma)=\alpha$ . Part (i) and (ii) are quite easy to show. (i): \begin{align} D(f)&=−27𝐴^2𝐷^2+18𝐴𝐵𝐶𝐷−4𝐴𝐶^3−4𝐵^3𝐷+𝐵^2𝐶^2 \\ &=-27(1)(1)-4(-3^3)(1)>0.  \end{align} (ii): $g'(x)=\frac{1}{x^2} \implies g(x)$ is strictly increasing from the interval $(-\infty, 0)$ & $(0, \infty)$ . We also know that $f(g(\alpha))=f(\beta)=0$ . Similarly for $g(\beta)$ & $g(\gamma)$ . So $g(\beta), g(\gamma), g(\alpha)$ are roots to $f(x)$ . Consider $g(\gamma)$ which now can either equal $\alpha, \beta$ or $\gamma$ . Since the function is strictly increasing and not monotonically increasing, we conclude $g(\gamma) \neq \gamma$ . So $g(\alpha)=\gamma,  \beta$ | $g(\beta)=\alpha, \gamma$ | $g(\gamma)=\alpha, \beta$ . We use the fact that $g(x)$ is one to one to conclude that $g(\gamma) \neq g(\alpha)$ . Thus only one of these 2 possible solutions are true. Suppose $g(\alpha)=\gamma$ , $g(\beta)=\alpha$ , $g(\gamma)=\beta$ . Since $g(x)$ is strictly increasing, then it implies that one of the roots must lie within the negative interval and that root is $\gamma$ . We can show then that $\beta>1$ which would make $\alpha<1$ , which is a contradiction, so the other possibility must be true, proving $g(\alpha)=\beta, \ g(\beta)=\gamma, \ g(\gamma)=\alpha$ . (iii): This part is the part I'm stuck at. This is what I've tried. $f(g(x))= -\frac{1}{x^3}+3(\frac{1}{x})-1$ . So if $g(\alpha)$ is a root to $f(x)$ , it implies $\frac{1}{\alpha}$ is a root for $x^3-3x+1=0$ . $\gamma=\frac{1}{1-\alpha}, \beta=\frac{1}{1-\gamma}, \alpha=\frac{1}{1-\beta}$ . $g^2(x)=\frac{1}{1-x}$ which potentially could be easier to work with. That the distance between the roots can be modelled by the distance between the $g(x)$ and $g^2(x)$ graphs. The coloured segments are lines of the same length: That the following are true: $$(\alpha - \beta)(\gamma) = \gamma - \beta$$ $$(\alpha - \gamma)(\beta) = \alpha - \beta$$ $$(\beta - \gamma)(\alpha) = \alpha - \gamma$$ But after this I'm stuck. How can I proceed?",", . i) Show that has distinct and real roots. ii) It is given , where are the roots of . Show that . iii) Given is a quadratic function such that . Part (i) and (ii) are quite easy to show. (i): (ii): is strictly increasing from the interval & . We also know that . Similarly for & . So are roots to . Consider which now can either equal or . Since the function is strictly increasing and not monotonically increasing, we conclude . So | | . We use the fact that is one to one to conclude that . Thus only one of these 2 possible solutions are true. Suppose , , . Since is strictly increasing, then it implies that one of the roots must lie within the negative interval and that root is . We can show then that which would make , which is a contradiction, so the other possibility must be true, proving . (iii): This part is the part I'm stuck at. This is what I've tried. . So if is a root to , it implies is a root for . . which potentially could be easier to work with. That the distance between the roots can be modelled by the distance between the and graphs. The coloured segments are lines of the same length: That the following are true: But after this I'm stuck. How can I proceed?","f(x)=x^3-3x^2+1, \forall x\in\mathbb R g(x)=1-\frac{1}{x} ,\forall x\in\mathbb R, x \neq 0 f(x) 3 \gamma < \beta < \alpha \gamma, \alpha, \beta f(x) g(\alpha)=\beta, \ g(\beta)=\gamma, \ g(\gamma)=\alpha h(x) h(\alpha)=\beta, \ h(\beta)=\gamma, \ h(\gamma)=\alpha \begin{align} D(f)&=−27𝐴^2𝐷^2+18𝐴𝐵𝐶𝐷−4𝐴𝐶^3−4𝐵^3𝐷+𝐵^2𝐶^2 \\
&=-27(1)(1)-4(-3^3)(1)>0. 
\end{align} g'(x)=\frac{1}{x^2} \implies g(x) (-\infty, 0) (0, \infty) f(g(\alpha))=f(\beta)=0 g(\beta) g(\gamma) g(\beta), g(\gamma), g(\alpha) f(x) g(\gamma) \alpha, \beta \gamma g(\gamma) \neq \gamma g(\alpha)=\gamma,  \beta g(\beta)=\alpha, \gamma g(\gamma)=\alpha, \beta g(x) g(\gamma) \neq g(\alpha) g(\alpha)=\gamma g(\beta)=\alpha g(\gamma)=\beta g(x) \gamma \beta>1 \alpha<1 g(\alpha)=\beta, \ g(\beta)=\gamma, \ g(\gamma)=\alpha f(g(x))= -\frac{1}{x^3}+3(\frac{1}{x})-1 g(\alpha) f(x) \frac{1}{\alpha} x^3-3x+1=0 \gamma=\frac{1}{1-\alpha}, \beta=\frac{1}{1-\gamma}, \alpha=\frac{1}{1-\beta} g^2(x)=\frac{1}{1-x} g(x) g^2(x) (\alpha - \beta)(\gamma) = \gamma - \beta (\alpha - \gamma)(\beta) = \alpha - \beta (\beta - \gamma)(\alpha) = \alpha - \gamma","['functions', 'polynomials']"
45,About a lemma to prove the Cantor-Bernstein-Schroeder theorem.,About a lemma to prove the Cantor-Bernstein-Schroeder theorem.,,"I am reading ""Logic in mathematics and set theory"" by Kazuyuki Tanaka and Toshio Suzuki. In this book, there is a lemma to prove the Cantor-Bernstein-Schroeder theorem. I cannot understand why the equality $$A_0 = (A_0 - B_0) \cup (B_0 - A_1) \cup (A_1 - B_1) \cup (B_1 - A_2) \cup \cdots \cup (A_n - B_n) \cup (B_n - A_{n+1}) \cup \cdots$$ holds. Maybe there exists an element $x$ such that $x \in A_i$ (and $x \in B_i)$ for all $i$ . For example I think if $A_0 = B = A_1$ and $f = id$ , then $x \in A_i$ for all $i$ if $x \in A_0$ . Lemma 1.12 Let $A_0, B, A_1$ be sets such that $A_1 \subset B \subset A_0$ and $A_0 \sim A_1$ . Then, $A_0 \sim B$ . Proof: Let $f : A_0 \to A_1$ be a bijection. Let $B_0 := B$ . Let $A_{n+1} := f[A_n], B_{n+1} := f[B_n]$ for $n \in \{0, 1, 2, \cdots \}$ . Then, $A_0 = (A_0 - B_0) \cup (B_0 - A_1) \cup (A_1 - B_1) \cup (B_1 - A_2) \cup \cdots \cup (A_n - B_n) \cup (B_n - A_{n+1}) \cup \cdots.$ Let $g : A_0 \to B_0$ be a mapping such that $g(x) = f(x)$ if $x \in A_n - B_n$ for some $n$ and $g(x) = x$ for $x \in B_n - A_{n+1}$ for some $n$ . Then, it is easy to prove $g : A_0 \to B_0$ is a bijection. So, $A_0 \sim B$ .","I am reading ""Logic in mathematics and set theory"" by Kazuyuki Tanaka and Toshio Suzuki. In this book, there is a lemma to prove the Cantor-Bernstein-Schroeder theorem. I cannot understand why the equality holds. Maybe there exists an element such that (and for all . For example I think if and , then for all if . Lemma 1.12 Let be sets such that and . Then, . Proof: Let be a bijection. Let . Let for . Then, Let be a mapping such that if for some and for for some . Then, it is easy to prove is a bijection. So, .","A_0 = (A_0 - B_0) \cup (B_0 - A_1) \cup (A_1 - B_1) \cup (B_1 - A_2) \cup \cdots \cup (A_n - B_n) \cup (B_n - A_{n+1}) \cup \cdots x x \in A_i x \in B_i) i A_0 = B = A_1 f = id x \in A_i i x \in A_0 A_0, B, A_1 A_1 \subset B \subset A_0 A_0 \sim A_1 A_0 \sim B f : A_0 \to A_1 B_0 := B A_{n+1} := f[A_n], B_{n+1} := f[B_n] n \in \{0, 1, 2, \cdots \} A_0 = (A_0 - B_0) \cup (B_0 - A_1) \cup (A_1 - B_1) \cup (B_1 - A_2) \cup \cdots \cup (A_n - B_n) \cup (B_n - A_{n+1}) \cup \cdots. g : A_0 \to B_0 g(x) = f(x) x \in A_n - B_n n g(x) = x x \in B_n - A_{n+1} n g : A_0 \to B_0 A_0 \sim B","['functions', 'elementary-set-theory']"
46,Finding an inverse function (sum of non-integer powers),Finding an inverse function (sum of non-integer powers),,"I have a function: $$f(x)=x^{2.2} + (1-x)^{2.2}$$ It is defined on the interval $[0,1]$ . Minimum: $x=0.5, y=2*0.5^{2.2} = 2^{-1.2}$ . I want to find an inverse for it. Since the function has two ""wings"", inverse will be a family of two functions. After some tinkering, I crafted something that looks like a very good approximation of an inverse function: $$ g(x)=\frac{1}{2} \left( 1 \pm \left(\frac{x-2^{-1.2}}{1-2^{-1.2}}\right)^{0.504288} \right) $$ The number $0.504288 \approx 1 / 1.9829939 $ was found experimentally by substituting $g(x)$ into $f(x)$ and tweaking it to make it look as straight as possible: $$ p(x) = f(g(x)) \approx x $$ Illustration: https://www.geogebra.org/graphing/zgzafsk4 (Might be a bit slow. Image substitute just in case.) And now it bothers me if I'm just one step away from the exact solution. So the question is: is it possible to express the exact power in $g(x)$ to get the equality $p(x) = x$ and what that value will be? Update: OK, people seem to focus on using usual numeric tools to get an arbitrarily close approximation. But this is not what the question was about. I have an approximation that is good enough for my purposes. The question is about this particular special case. There is a power function added to reversed and shifted copy of itself. Inverse function for a power function $y = x^{2.2}$ will be just the power reversed $x = y^{1/2.2}$ . Since we adding an increasing and a decreasing function, the resulting curvature has changed. And it raises the suspicion that there might even be an exact power value, smaller than the original 2.2... After writing this, I realized that the problem can be expressed in a different way. What I actually did is that I made an inverse function for an approximation of $f(x)$ : $$f_{approx}(x) = 2^{-1.2}+ (1-2^{-1.2}) (2x-1)^{1.983}$$ Now I made a different illustration: https://www.geogebra.org/graphing/msfzaqah ( image ). There is also $h(x) = \frac{f_{approx}(x)}{f(x)}$ on the illustration. It clearly has some extremes, and changing the power just pushes them around. So the answer to the original question must be: this approximation doesn't fit the function exactly, so there is no exact number to put in there. Now the question is: can the original function be expressed as something invertible? Same shape functions with an integer power are invertible. What stands in the way for a function with non-integer (fractional) power to be invertible too? Note: For powers 2 and 3, similar functions can be expressed in a clearly invertible form: $$x^2+(1-x)^2 = \frac{1}{2} + \frac{1}{2}(2x - 1)^2$$ $$x^3+(1-x)^3 = \frac{1}{4} + \frac{3}{4}(2x - 1)^2$$ For the power of 4 and above WolframAlpha doesn't provide a form like this (single power), but still able to construct inverse functions, albeit more and more complicated. Interesting that for powers of 2 and 3 the resulting function has the power of 2. And this fact seems to persist for higher powers - a sum of (2n+1) power functions will be a (2n) power function. But that's a digression. Update 2: I really appreciate the answers about Tailor series expansion. But I'm still concerned: is it the best we can do?","I have a function: It is defined on the interval . Minimum: . I want to find an inverse for it. Since the function has two ""wings"", inverse will be a family of two functions. After some tinkering, I crafted something that looks like a very good approximation of an inverse function: The number was found experimentally by substituting into and tweaking it to make it look as straight as possible: Illustration: https://www.geogebra.org/graphing/zgzafsk4 (Might be a bit slow. Image substitute just in case.) And now it bothers me if I'm just one step away from the exact solution. So the question is: is it possible to express the exact power in to get the equality and what that value will be? Update: OK, people seem to focus on using usual numeric tools to get an arbitrarily close approximation. But this is not what the question was about. I have an approximation that is good enough for my purposes. The question is about this particular special case. There is a power function added to reversed and shifted copy of itself. Inverse function for a power function will be just the power reversed . Since we adding an increasing and a decreasing function, the resulting curvature has changed. And it raises the suspicion that there might even be an exact power value, smaller than the original 2.2... After writing this, I realized that the problem can be expressed in a different way. What I actually did is that I made an inverse function for an approximation of : Now I made a different illustration: https://www.geogebra.org/graphing/msfzaqah ( image ). There is also on the illustration. It clearly has some extremes, and changing the power just pushes them around. So the answer to the original question must be: this approximation doesn't fit the function exactly, so there is no exact number to put in there. Now the question is: can the original function be expressed as something invertible? Same shape functions with an integer power are invertible. What stands in the way for a function with non-integer (fractional) power to be invertible too? Note: For powers 2 and 3, similar functions can be expressed in a clearly invertible form: For the power of 4 and above WolframAlpha doesn't provide a form like this (single power), but still able to construct inverse functions, albeit more and more complicated. Interesting that for powers of 2 and 3 the resulting function has the power of 2. And this fact seems to persist for higher powers - a sum of (2n+1) power functions will be a (2n) power function. But that's a digression. Update 2: I really appreciate the answers about Tailor series expansion. But I'm still concerned: is it the best we can do?","f(x)=x^{2.2} + (1-x)^{2.2} [0,1] x=0.5, y=2*0.5^{2.2} = 2^{-1.2}  g(x)=\frac{1}{2} \left( 1 \pm \left(\frac{x-2^{-1.2}}{1-2^{-1.2}}\right)^{0.504288} \right)  0.504288 \approx 1 / 1.9829939  g(x) f(x)  p(x) = f(g(x)) \approx x  g(x) p(x) = x y = x^{2.2} x = y^{1/2.2} f(x) f_{approx}(x) = 2^{-1.2}+ (1-2^{-1.2}) (2x-1)^{1.983} h(x) = \frac{f_{approx}(x)}{f(x)} x^2+(1-x)^2 = \frac{1}{2} + \frac{1}{2}(2x - 1)^2 x^3+(1-x)^3 = \frac{1}{4} + \frac{3}{4}(2x - 1)^2","['functions', 'exponentiation', 'inverse', 'inverse-function']"
47,$x^\alpha$ as an example of an $\alpha$-Hölder continuous function,as an example of an -Hölder continuous function,x^\alpha \alpha,"I saw the following statement by user Mark Joshi in response to the question : Non-trivial exemple of Hölder continuous function. $x^\alpha$ for $x > 0$ and $0$ otherwise for $0 < \alpha < 1$ is Holder continuous of order $\alpha$ I cannot seem to prove this statement. How do I proceed to show that the function $f(x) = x^{\alpha}$ is Holder continuous of order $\alpha<1$ , i.e., $|f(x_1) - f(x_2)| \leq c |x_1-x_2|^{\alpha}$ for all $x_1, x_2 \in (0, \infty)$ , and some $c>0$ .","I saw the following statement by user Mark Joshi in response to the question : Non-trivial exemple of Hölder continuous function. for and otherwise for is Holder continuous of order I cannot seem to prove this statement. How do I proceed to show that the function is Holder continuous of order , i.e., for all , and some .","x^\alpha x > 0 0 0 < \alpha < 1 \alpha f(x) = x^{\alpha} \alpha<1 |f(x_1) - f(x_2)| \leq c |x_1-x_2|^{\alpha} x_1, x_2 \in (0, \infty) c>0","['real-analysis', 'functions', 'continuity', 'holder-spaces']"
48,"There is no function $f:\Bbb R\to \Bbb R$ such that $f(y)\le a f(x)-b\ln{(y-x)},\forall x<y$",There is no function  such that,"f:\Bbb R\to \Bbb R f(y)\le a f(x)-b\ln{(y-x)},\forall x<y","Let $a>1,b>0$ . Prove that there is no function $f:\Bbb R\to\Bbb R$ such that $$f(y)\le af(x)-b\ln{(y-x)},\forall x<y$$ Some of my thoughts：Let $y=x+1$ ,then we have $$f(x+1)\le af(x)$$ so we have $$f(x+n)\le af(x+n-1)\le a^2f(x+n-2)\le\cdots \le a^{n}f(x)$$","Let . Prove that there is no function such that Some of my thoughts：Let ,then we have so we have","a>1,b>0 f:\Bbb R\to\Bbb R f(y)\le af(x)-b\ln{(y-x)},\forall x<y y=x+1 f(x+1)\le af(x) f(x+n)\le af(x+n-1)\le a^2f(x+n-2)\le\cdots \le a^{n}f(x)","['real-analysis', 'functions']"
49,The number of polynomial functions $f:A\to A$ is $|A|^2$ if and only if $x^2=x$ for all $x\in A$.,The number of polynomial functions  is  if and only if  for all .,f:A\to A |A|^2 x^2=x x\in A,"Let $A$ be a commutative ring with $n$ elements, $n\ge2$ . Prove that the next statements are equivalent: $(\forall x\in A)(x^2=x)$ . The number of polynomial functions $f:A\to A$ is $n^2$ . I managed to do only the implication $a\implies b)$ : $f(x)=a_kx^k+a_{k-1}x^{k-1}+\cdots+a_1x+a_0=(a_k+\cdots+a_1)x+a_0=bx+a_0$ $b$ and $a_0$ are arbitrary in $A$ , so the number of polynomial functions is $n^2$ . Can somebody give me some ideas for $b)\implies a)$ ?","Let be a commutative ring with elements, . Prove that the next statements are equivalent: . The number of polynomial functions is . I managed to do only the implication : and are arbitrary in , so the number of polynomial functions is . Can somebody give me some ideas for ?",A n n\ge2 (\forall x\in A)(x^2=x) f:A\to A n^2 a\implies b) f(x)=a_kx^k+a_{k-1}x^{k-1}+\cdots+a_1x+a_0=(a_k+\cdots+a_1)x+a_0=bx+a_0 b a_0 A n^2 b)\implies a),"['functions', 'polynomials', 'ring-theory', 'commutative-algebra', 'finite-rings']"
50,Proof that composition of two permutations is again a permutation.,Proof that composition of two permutations is again a permutation.,,"Permutations are symmetries of a (not necessarily finite) set $X$ , often denoted as Sym(T). That is, a permutation $p: X\to X$ is a bijective map from a set $X$ to itself. I wish to prove the following and wish to check my approach: The composition of two permutations is again a permutation. Approach: Proof 1 Given two permutations $p_1$ and $p_2$ we know that these are bijective , therefore by definition of a bijection: $$\forall y \in X \quad  \exists ! x\in X: p(x)=y$$ In English : Every element in the codomain, corresponds to a unique element in the domain. It thus uniquely pairs elements in the codomain to elements in the domain. We now consider the composition of these two permutations and show it is bijection from $X$ to itself. To prove bijectivity one can prove that there exists one unique element in the domain, for every element in the codomain. Consider an arbitrary $z\in X$ , we then know since $p_1$ is permutation (bijection), so there is some unique $y$ , such that $$ p_1(y)=z$$ Now since $y\in X$ , by there must exist a unique element $x$ , such that we can write: $$ p_2 (x)=y $$ We conclude that: $$ p_1(p_2(x))=p_1(y)=z$$ Since for every element $z$ in the codomain $X$ , there exists a unique element $x$ in the domain, we have a bijective map. This means that the composition $p_1 \circ p_2$ is again a permutation on $X$ . $\square$ Proof 2: Canonical approach: Let $f$ and $g$ be bijective maps from a set $X$ to itself. We will prove that the composition $f \circ g$ is bijective. Injectivity: (each element that is reached is reached once) Consider arbitrary $a, b \in X$ such that: $$ f(g(a))=f(g(b))$$ by injectivity of $f$ we know that $g(a)=g(b)$ . Now by injectivity of $g$ we have that $a=b$ , hence the composition $f \circ g$ is injective. surjectivity: (each element is reached) We have to prove that for every element $b \in X$ , there exists some element $a$ sucht that $f(g(a))=b$ . Indeed we have bijective maps so the inverse map is a well-defined bijective map for each of these maps $f, g$ . Consider the element $a=g^{-1}( f^{-1}(b))$ and observe: $$ f(g(a))=f(g(g^{-1}( f^{-1}(b))))=f(f^{-1}(b))=b$$ By the associativity property of maps (and the fact that composition of a map with its inverse yields the identity). Injectivity and surjectivity both hold therefore the composition is bijective. (every element is reached exactly once) Proof 3 Alternatively, by the pigeonhole principle we have that for finite sets of the same cardinality a map is surjective if and only if it is injective. Consider arbitrary $a, b \in X$ such that: $$ f(g(a))=f(g(b))$$ by injectivity of $f$ we know that $g(a)=g(b)$ . Now by injectivity of $g$ we have that $a=b$ , hence the composition $f \circ g$ is injective. Now we also know the composition is surjective and therefore bijective.","Permutations are symmetries of a (not necessarily finite) set , often denoted as Sym(T). That is, a permutation is a bijective map from a set to itself. I wish to prove the following and wish to check my approach: The composition of two permutations is again a permutation. Approach: Proof 1 Given two permutations and we know that these are bijective , therefore by definition of a bijection: In English : Every element in the codomain, corresponds to a unique element in the domain. It thus uniquely pairs elements in the codomain to elements in the domain. We now consider the composition of these two permutations and show it is bijection from to itself. To prove bijectivity one can prove that there exists one unique element in the domain, for every element in the codomain. Consider an arbitrary , we then know since is permutation (bijection), so there is some unique , such that Now since , by there must exist a unique element , such that we can write: We conclude that: Since for every element in the codomain , there exists a unique element in the domain, we have a bijective map. This means that the composition is again a permutation on . Proof 2: Canonical approach: Let and be bijective maps from a set to itself. We will prove that the composition is bijective. Injectivity: (each element that is reached is reached once) Consider arbitrary such that: by injectivity of we know that . Now by injectivity of we have that , hence the composition is injective. surjectivity: (each element is reached) We have to prove that for every element , there exists some element sucht that . Indeed we have bijective maps so the inverse map is a well-defined bijective map for each of these maps . Consider the element and observe: By the associativity property of maps (and the fact that composition of a map with its inverse yields the identity). Injectivity and surjectivity both hold therefore the composition is bijective. (every element is reached exactly once) Proof 3 Alternatively, by the pigeonhole principle we have that for finite sets of the same cardinality a map is surjective if and only if it is injective. Consider arbitrary such that: by injectivity of we know that . Now by injectivity of we have that , hence the composition is injective. Now we also know the composition is surjective and therefore bijective.","X p: X\to X X p_1 p_2 \forall y \in X \quad  \exists ! x\in X: p(x)=y X z\in X p_1 y  p_1(y)=z y\in X x  p_2 (x)=y   p_1(p_2(x))=p_1(y)=z z X x p_1 \circ p_2 X \square f g X f \circ g a, b \in X  f(g(a))=f(g(b)) f g(a)=g(b) g a=b f \circ g b \in X a f(g(a))=b f, g a=g^{-1}( f^{-1}(b))  f(g(a))=f(g(g^{-1}( f^{-1}(b))))=f(f^{-1}(b))=b a, b \in X  f(g(a))=f(g(b)) f g(a)=g(b) g a=b f \circ g",['functions']
51,Determining the domain of a polynomial with rational exponents,Determining the domain of a polynomial with rational exponents,,"I've completely confused myself as to determining the domain of polynomial expressions that have rational powers, e.g. $$y = x^{2/3} \qquad \text{or} \qquad y_2 = (x^2-1)^{2/ 3}.$$ A calculus textbook I've consulted asserts that the domain of $y_2$ is all real values of $x$ ; however, when I plot the function using Grapher or Wolframalpha, it excludes the values for $-1 \leq x \leq 1$ : Similarly, when I try to use Wolfram to evaluate $(-4)^{2/ 3}$ it returns a complex number, whereas I would've expected a real value (because I thought we could think of this as $(-4)^{2/ 3} = \big((-4)^2\big)^{1/ 3} = (16)^{1/ 3} = \sqrt[3]{16}$ , which I thought was the same as $\big( (-4)^{1/ 3} \big)^{2} = (-\sqrt[3]{4})^{2} = \sqrt[3]{4}^2$ I consulted this question , which clarified that the property $a^{bc} = (a^b)^c$ only applies to all $a$ , if $b$ $c$ are integers (otherwise, we must assume $a > 0$ ), but I'm still unclear as to how I can determine the domain of these functions, given the disagreement between my textbook and what I'm finding with graphing apps. Any clarification would be greatly appreciated! ps. I could not determine which of the ""domain"" tags was appropriate, I did not see anything like ""domain of a function,"" and most say not to use for this purpose. Edit I just consulted a 3rd textbook that includes the following statement: For all real numbers $a$ for which the indicated roots exist, and for any rational number $m/n$ , $$a^{m/n} = (a^{1/n})^m$$ . This prompted me to try graphing the function as $y_2 = \big((x^2-1)^{1 /3}\big)^2$ ; however, this yielded the same result as before (ie excluding -1 < x < 1). On Wolfram, I tried y = (cube-root(x^2-1))^2 and this yielded the same graph as the one provided by my textbook. I must admit, I'm a bit at a loss as to why $y_2 = \big((x^2-1)^{1 /3}\big)^2$ didn't resolve the issue. If that had worked, it would've made (some) sense to me.","I've completely confused myself as to determining the domain of polynomial expressions that have rational powers, e.g. A calculus textbook I've consulted asserts that the domain of is all real values of ; however, when I plot the function using Grapher or Wolframalpha, it excludes the values for : Similarly, when I try to use Wolfram to evaluate it returns a complex number, whereas I would've expected a real value (because I thought we could think of this as , which I thought was the same as I consulted this question , which clarified that the property only applies to all , if are integers (otherwise, we must assume ), but I'm still unclear as to how I can determine the domain of these functions, given the disagreement between my textbook and what I'm finding with graphing apps. Any clarification would be greatly appreciated! ps. I could not determine which of the ""domain"" tags was appropriate, I did not see anything like ""domain of a function,"" and most say not to use for this purpose. Edit I just consulted a 3rd textbook that includes the following statement: For all real numbers for which the indicated roots exist, and for any rational number , . This prompted me to try graphing the function as ; however, this yielded the same result as before (ie excluding -1 < x < 1). On Wolfram, I tried y = (cube-root(x^2-1))^2 and this yielded the same graph as the one provided by my textbook. I must admit, I'm a bit at a loss as to why didn't resolve the issue. If that had worked, it would've made (some) sense to me.",y = x^{2/3} \qquad \text{or} \qquad y_2 = (x^2-1)^{2/ 3}. y_2 x -1 \leq x \leq 1 (-4)^{2/ 3} (-4)^{2/ 3} = \big((-4)^2\big)^{1/ 3} = (16)^{1/ 3} = \sqrt[3]{16} \big( (-4)^{1/ 3} \big)^{2} = (-\sqrt[3]{4})^{2} = \sqrt[3]{4}^2 a^{bc} = (a^b)^c a b c a > 0 a m/n a^{m/n} = (a^{1/n})^m y_2 = \big((x^2-1)^{1 /3}\big)^2 y_2 = \big((x^2-1)^{1 /3}\big)^2,"['functions', 'graphing-functions']"
52,"Show that the space of increasing, bounded function is not totally bounded w.r.t. $\sup$-norm","Show that the space of increasing, bounded function is not totally bounded w.r.t. -norm",\sup,"Here is the exercise that I got. Verify that the class $\mathcal{G} = \left\{ g: \mathbb{R} \to [0,1], g \text{ is increasing}\right\}$ is not totally bounded for the supremum norm on $\mathbb{R}$ . I am trying to prove this by constructing a counterexample (for a given $\epsilon > 0$ and some functions $g_1,\cdots,g_n$ ), but I don't know how. The rough idea I have is that, to construct $f$ such that $\|f - g_i\|_\infty > \epsilon$ for all $g_i$ 's. So maybe only at one point $x_i$ , $f$ and $g_i$ are far away. For example, maybe at point $x_1$ , $f$ is only close to $\max_i g_i$ and far away from $\min_i g_i$ , but at another point $x_2$ , $f$ is only close to $\min_i g_i$ but far away from $\max_i g_i$ , but I don't know how to formalize this, partly because I don't know how far is $\max_i g_i$ from $\min_i g_i$ . The picture in my head is that, if $g_i$ is like a increasing straight line, then I can consider $f = \frac{1}{2}$ , so $f$ and $g$ will be far away when $x$ is big or small. If $g$ is quite flat, I can take $f$ to be an increasing line. I am not sure if I am thinking correctly and how to proceed. Could someone give me a hint?","Here is the exercise that I got. Verify that the class is not totally bounded for the supremum norm on . I am trying to prove this by constructing a counterexample (for a given and some functions ), but I don't know how. The rough idea I have is that, to construct such that for all 's. So maybe only at one point , and are far away. For example, maybe at point , is only close to and far away from , but at another point , is only close to but far away from , but I don't know how to formalize this, partly because I don't know how far is from . The picture in my head is that, if is like a increasing straight line, then I can consider , so and will be far away when is big or small. If is quite flat, I can take to be an increasing line. I am not sure if I am thinking correctly and how to proceed. Could someone give me a hint?","\mathcal{G} = \left\{ g: \mathbb{R} \to [0,1], g \text{ is increasing}\right\} \mathbb{R} \epsilon > 0 g_1,\cdots,g_n f \|f - g_i\|_\infty > \epsilon g_i x_i f g_i x_1 f \max_i g_i \min_i g_i x_2 f \min_i g_i \max_i g_i \max_i g_i \min_i g_i g_i f = \frac{1}{2} f g x g f","['real-analysis', 'functions', 'metric-spaces']"
53,Constructing a Bijective function via an injective and surjective one.,Constructing a Bijective function via an injective and surjective one.,,"Suppose that $\;f_1,\;f_2:\;A\to B$ such that $f_1$ is injective and $f_2$ is surjective. I was trying to find out whether there exists $f_3:\;A\to B$ such that $f_3$ is bijective. Is it possible to construct it from $f_1$ and $f_2$ ? I tried proving the statement non-constructively via a cardinality argument, but ended up hand-waving a lot (i.e., since the cardinality is the same, there exists a bijection, a bit of circular reasoning). But, I'd be more interested in a construction based argument, as I can't think of one.","Suppose that such that is injective and is surjective. I was trying to find out whether there exists such that is bijective. Is it possible to construct it from and ? I tried proving the statement non-constructively via a cardinality argument, but ended up hand-waving a lot (i.e., since the cardinality is the same, there exists a bijection, a bit of circular reasoning). But, I'd be more interested in a construction based argument, as I can't think of one.","\;f_1,\;f_2:\;A\to B f_1 f_2 f_3:\;A\to B f_3 f_1 f_2","['functions', 'elementary-set-theory']"
54,What is the domain of the function $f(x)=\sin^{-1}\left(\frac{8(3)^{x-2}}{1-3^{2(x-1)}}\right)$?,What is the domain of the function ?,f(x)=\sin^{-1}\left(\frac{8(3)^{x-2}}{1-3^{2(x-1)}}\right),"What is the domain of the function   $f(x)=\sin^{-1}\left(\frac{8(3)^{x-2}}{1-3^{2(x-1)}}\right)$? I started using the fact  $-\frac{\pi}{2}\le f(x) \le \frac{\pi}{2}\implies-1 \le\frac{8(3)^{x-2}}{1-3^{2(x-1)}}\le1$.Now,on dissecting it into two  cases. $CASE (1): -1 \le\frac{8(3)^{x-2}}{1-3^{2(x-1)}}$ $CASE (2): \frac{8(3)^{x-2}}{1-3^{2(x-1)}}\le1$ The calculations is inboth cases are bewidering,that's why i'm not showing it. I need someone who can help me in solving this.","What is the domain of the function   $f(x)=\sin^{-1}\left(\frac{8(3)^{x-2}}{1-3^{2(x-1)}}\right)$? I started using the fact  $-\frac{\pi}{2}\le f(x) \le \frac{\pi}{2}\implies-1 \le\frac{8(3)^{x-2}}{1-3^{2(x-1)}}\le1$.Now,on dissecting it into two  cases. $CASE (1): -1 \le\frac{8(3)^{x-2}}{1-3^{2(x-1)}}$ $CASE (2): \frac{8(3)^{x-2}}{1-3^{2(x-1)}}\le1$ The calculations is inboth cases are bewidering,that's why i'm not showing it. I need someone who can help me in solving this.",,"['functions', 'trigonometry', 'inequality']"
55,If there is a surjection $A\to B $ and another $B\to A$ then $A $ and $B$ are in bijection [duplicate],If there is a surjection  and another  then  and  are in bijection [duplicate],A\to B  B\to A A  B,"This question already has answers here : Is there a Cantor-Schroder-Bernstein statement about surjective maps? (2 answers) Closed 6 years ago . I am trying to prove this (it looks true to me) : Let $A,B $ be two sets. If there is a surjection $A\to B $ and a surjection $B\to A$ then $A $ and $B $ are in bijection. I showed that is it equivalent to the following statement : If there is an injection $A\to B $ and an injection $B\to A$ then $A $ and $B $ are in bijection. But I am stuck, I don't see how to prove either.","This question already has answers here : Is there a Cantor-Schroder-Bernstein statement about surjective maps? (2 answers) Closed 6 years ago . I am trying to prove this (it looks true to me) : Let $A,B $ be two sets. If there is a surjection $A\to B $ and a surjection $B\to A$ then $A $ and $B $ are in bijection. I showed that is it equivalent to the following statement : If there is an injection $A\to B $ and an injection $B\to A$ then $A $ and $B $ are in bijection. But I am stuck, I don't see how to prove either.",,"['functions', 'set-theory']"
56,Does $f(a)=1$ and $f'(x)=g\big(f(x)+x\big)f(x)$ imply that $f$ has no roots? (Proof verification),Does  and  imply that  has no roots? (Proof verification),f(a)=1 f'(x)=g\big(f(x)+x\big)f(x) f,"Let $f: I \to \Bbb R$ be differentiable, where $I$ is an open interval in $\Bbb R$. Let $a \in I$. Let $g: \Bbb R \to \Bbb R$ be continuous. If $f(a)=1$ and $f'(x) = g\big(f(x)+x\big) f(x)$, then prove that $f(x)=0$ does not have any solutions in $I$. Is the following correct? Let's say we have a $t$ that belongs in $I$ so that $f(t)=0$, then: $$\lim_{x\to t}f'(x) = \lim_{x \to t} g\big(f(x)+x\big)f(x) \tag1$$ We know that $\displaystyle \lim_{x \to t} g\big(f(x)+x\big) = b$ where $b \in \Bbb R$, so $(1)$ becomes $\frac{\mathrm dy}{\mathrm dx} = b \ \mathrm dy$. Then, $b=\frac1{\mathrm dx}$, which is false because $b$ cannot tend to $\infty$. Can I cancel out $\mathrm dy$?","Let $f: I \to \Bbb R$ be differentiable, where $I$ is an open interval in $\Bbb R$. Let $a \in I$. Let $g: \Bbb R \to \Bbb R$ be continuous. If $f(a)=1$ and $f'(x) = g\big(f(x)+x\big) f(x)$, then prove that $f(x)=0$ does not have any solutions in $I$. Is the following correct? Let's say we have a $t$ that belongs in $I$ so that $f(t)=0$, then: $$\lim_{x\to t}f'(x) = \lim_{x \to t} g\big(f(x)+x\big)f(x) \tag1$$ We know that $\displaystyle \lim_{x \to t} g\big(f(x)+x\big) = b$ where $b \in \Bbb R$, so $(1)$ becomes $\frac{\mathrm dy}{\mathrm dx} = b \ \mathrm dy$. Then, $b=\frac1{\mathrm dx}$, which is false because $b$ cannot tend to $\infty$. Can I cancel out $\mathrm dy$?",,"['calculus', 'real-analysis', 'functions', 'proof-verification']"
57,Characteristics of parallel parabola (offset curve) and the formula to find the equation,Characteristics of parallel parabola (offset curve) and the formula to find the equation,,What are the characteristics of parallel parabola? And is there any formula to find the equation of parallel parabola if we know the equation of one parabola?,What are the characteristics of parallel parabola? And is there any formula to find the equation of parallel parabola if we know the equation of one parabola?,,['functions']
58,"If domain of $f(x)$ is $[-1,2]$ then what will be the domain of $f([x]-x^2+4)$ $?$",If domain of  is  then what will be the domain of,"f(x) [-1,2] f([x]-x^2+4) ?","If domain of $f(x)$ is $[-1,2]$ then what will be the domain of $f([x]-x^2+4)$ $?$ Here $[.]$ is for greatest integer function. Attempt: since domain of $f(x)$ is $[-1,2]$ therefore for $f([x]-x^2+4)$ $-1\le[x]-x^2+4\le2$ $\Rightarrow x^2\le[x]+5$ and $x^2\ge[x]+2$ solving first inequality, as $x^2$ is always positive so $x\ge-5$ Now I can start taking intervals of $x$ and solve them but this brute force method is not taking me anywhere near to the correct answer.  Can someone explain me how is this problem solved? Please give an elaborate solution.","If domain of $f(x)$ is $[-1,2]$ then what will be the domain of $f([x]-x^2+4)$ $?$ Here $[.]$ is for greatest integer function. Attempt: since domain of $f(x)$ is $[-1,2]$ therefore for $f([x]-x^2+4)$ $-1\le[x]-x^2+4\le2$ $\Rightarrow x^2\le[x]+5$ and $x^2\ge[x]+2$ solving first inequality, as $x^2$ is always positive so $x\ge-5$ Now I can start taking intervals of $x$ and solve them but this brute force method is not taking me anywhere near to the correct answer.  Can someone explain me how is this problem solved? Please give an elaborate solution.",,['functions']
59,"Homeomorphism from $S^1\setminus(0,1)$ to $\mathbb{R}$",Homeomorphism from  to,"S^1\setminus(0,1) \mathbb{R}","I am trying to derive a bijection between $S^1\setminus\{(0,1)\}$ and the real line, but I am stuck on using the most obvious way Let the top point of the circle be $(0,1)$ , and the blue line hits some point $x = \begin{bmatrix} w \\h \end{bmatrix}$ on the circle and touches the real line at $f(x)$ Find a bijection between $S^1\setminus\{(0,1)\}$ and $\mathbb{R}$ Let $c$ be the length of the blue line, then by Pythagorean $1^2+f(x)^2 = c^2$ The hypothenus of the small triangle $I$ is given by $(f(x)-w)^2 + h^2 = c_1^2$ And the hypothenus of the small triangle $II$ is given by $(1-h)^2 + w^2 = c_2^2$ $c = c_1 + c_2$ It seems proceeding this way I will have $1+f^2(x)  = (\sqrt{(f(x)-w)^2 + h^2} + \sqrt{(1-h)^2 + w^2})^2$ But I need to some how extract the $f(x)$ from the RHS... Does anyone see how to proceed?","I am trying to derive a bijection between and the real line, but I am stuck on using the most obvious way Let the top point of the circle be , and the blue line hits some point on the circle and touches the real line at Find a bijection between and Let be the length of the blue line, then by Pythagorean The hypothenus of the small triangle is given by And the hypothenus of the small triangle is given by It seems proceeding this way I will have But I need to some how extract the from the RHS... Does anyone see how to proceed?","S^1\setminus\{(0,1)\} (0,1) x = \begin{bmatrix} w \\h \end{bmatrix} f(x) S^1\setminus\{(0,1)\} \mathbb{R} c 1^2+f(x)^2 = c^2 I (f(x)-w)^2 + h^2 = c_1^2 II (1-h)^2 + w^2 = c_2^2 c = c_1 + c_2 1+f^2(x)  = (\sqrt{(f(x)-w)^2 + h^2} + \sqrt{(1-h)^2 + w^2})^2 f(x)","['real-analysis', 'functions', 'trigonometry', 'euclidean-geometry', 'problem-solving']"
60,Range of function $f(x) = \sqrt{x+27}+\sqrt{13-x}+\sqrt{x}$,Range of function,f(x) = \sqrt{x+27}+\sqrt{13-x}+\sqrt{x},"Range of function $f(x) = \sqrt{x+27}+\sqrt{13-x}+\sqrt{x}$ $\bf{My\; Try::}$ For $\min$ of $f(x)$ $$\left(\sqrt{13-x}+\sqrt{x}\right)^2=13-x+x+2\sqrt{x}\sqrt{13-x}= 13+2\sqrt{x}\sqrt{13-x}\geq 13$$ Now $$\sqrt{x+27} + \sqrt{13-x}+\sqrt{x} \geq \sqrt{27} + \sqrt{13}$$ and equality hold at $x=0$ Now How can i calculate $\max$ of $f(x)\;,$ Help required, Thanks","Range of function $f(x) = \sqrt{x+27}+\sqrt{13-x}+\sqrt{x}$ $\bf{My\; Try::}$ For $\min$ of $f(x)$ $$\left(\sqrt{13-x}+\sqrt{x}\right)^2=13-x+x+2\sqrt{x}\sqrt{13-x}= 13+2\sqrt{x}\sqrt{13-x}\geq 13$$ Now $$\sqrt{x+27} + \sqrt{13-x}+\sqrt{x} \geq \sqrt{27} + \sqrt{13}$$ and equality hold at $x=0$ Now How can i calculate $\max$ of $f(x)\;,$ Help required, Thanks",,['functions']
61,Would such a function be of any importance (primality test)?,Would such a function be of any importance (primality test)?,,"While experimenting with some Maths, I came up with a really cool function. Let's call this function  $\space \beta \space$. Which is a function of a real variable $\space r \space $. Here is the function: $$\beta (r) = \tan \Bigg({\pi \over 2 } - {{4 \pi \Gamma(r)} \over r} \Bigg)$$ Where $\space \Gamma(r) \space $ is the Gamma Function . Here is why this function is cool. Let's take $\space \beta (z) \space$ where $\space z \space$ is a positive integer. Well, $\space \beta (z) \space$ is only well defined IF AND ONLY IF $\space z \space$ is a prime GREATER than $\space 2$ (I have a proof for this, I didn't just assume it). So when $\space z \space$ is not prime, $\space \beta (z) \space$ is undefined. Would this serve ANY importance at all? Is it worth mentioning? Either way, I found it pretty cool and I hope you do too :).","While experimenting with some Maths, I came up with a really cool function. Let's call this function  $\space \beta \space$. Which is a function of a real variable $\space r \space $. Here is the function: $$\beta (r) = \tan \Bigg({\pi \over 2 } - {{4 \pi \Gamma(r)} \over r} \Bigg)$$ Where $\space \Gamma(r) \space $ is the Gamma Function . Here is why this function is cool. Let's take $\space \beta (z) \space$ where $\space z \space$ is a positive integer. Well, $\space \beta (z) \space$ is only well defined IF AND ONLY IF $\space z \space$ is a prime GREATER than $\space 2$ (I have a proof for this, I didn't just assume it). So when $\space z \space$ is not prime, $\space \beta (z) \space$ is undefined. Would this serve ANY importance at all? Is it worth mentioning? Either way, I found it pretty cool and I hope you do too :).",,"['functions', 'prime-numbers']"
62,"Is it wrong to call all math operators, functionals and other things that take input and provide output just ""functions""?","Is it wrong to call all math operators, functionals and other things that take input and provide output just ""functions""?",,"I am more of a programmer than a mathematician, so in my mind a functions can take any type of input and can produce any kind of output. For example I see the derivative operator $\frac{d}{dx}$ as a function that takes a function as its argument and returns a function. Is this wrong in math?","I am more of a programmer than a mathematician, so in my mind a functions can take any type of input and can produce any kind of output. For example I see the derivative operator $\frac{d}{dx}$ as a function that takes a function as its argument and returns a function. Is this wrong in math?",,['functions']
63,Domain and range of composite functions,Domain and range of composite functions,,"Would I be correct in assuming that the domain of the composite function $(f∘g)(x)$ is the intersection of the range of $g$ and the domain of $x$? If not, how do I find the domain of a composite function? Would I find the range of $(f∘g)$ as I would find the range of a non-composite function, or do I need to use the components $g$ and $f$? P.S.: Are $D_f$ and $R_f$ accepted notations for the domain and range of $f$ respectively?","Would I be correct in assuming that the domain of the composite function $(f∘g)(x)$ is the intersection of the range of $g$ and the domain of $x$? If not, how do I find the domain of a composite function? Would I find the range of $(f∘g)$ as I would find the range of a non-composite function, or do I need to use the components $g$ and $f$? P.S.: Are $D_f$ and $R_f$ accepted notations for the domain and range of $f$ respectively?",,"['functions', 'function-and-relation-composition']"
64,Injections with power sets,Injections with power sets,,Let $X$ and $Y$ be two non-empty sets and $f: X \to Y$ is a function then we can define $f^{\rightarrow}: \mathcal P(X) \to \mathcal P(Y)$ and $f^{\leftarrow}: \mathcal P(Y) \to \mathcal P(X)$ where $\mathcal P$ is notation for supersets: $\begin{align*} f^{\rightarrow}(A) & = \{ f(x) \in Y : x \in A\} & A\in \mathcal P(X)  \\[1ex] f^{\leftarrow}(B) & = \{ x \in X : f(x) \in B\} & B\in \mathcal P(Y) \end{align*}$ Show that if $f$ is an injection $f^{\leftarrow}(f^{\rightarrow}(A)) =A\;\;\forall A \subset X$ and that if $f$ is not an injection there exists a set $A \subset X$ so that $f^{\leftarrow}(f^{\rightarrow}(A)) \neq A$. So for the first we have to show that $A \subset f^{\leftarrow}(f^{\rightarrow}(A))$ and $f^{\leftarrow}(f^{\rightarrow}(A))\subset A$. $$A \subset f^{\leftarrow}(\{ f(x) \in Y : x \in A\})$$ $A$ is in superset of $X$ and because the function is injective the elements from the domain are mapped to at most one element of the co domain. $$A \subset \{ x \in X : f(x) \in A\}$$ And now we map the range back to a set of elements that is a subset of $A$. Then the next case should be done with same logic? I don't quite follow how the proof should be done for the non-injective case? Any help & hints are welcome.,Let $X$ and $Y$ be two non-empty sets and $f: X \to Y$ is a function then we can define $f^{\rightarrow}: \mathcal P(X) \to \mathcal P(Y)$ and $f^{\leftarrow}: \mathcal P(Y) \to \mathcal P(X)$ where $\mathcal P$ is notation for supersets: $\begin{align*} f^{\rightarrow}(A) & = \{ f(x) \in Y : x \in A\} & A\in \mathcal P(X)  \\[1ex] f^{\leftarrow}(B) & = \{ x \in X : f(x) \in B\} & B\in \mathcal P(Y) \end{align*}$ Show that if $f$ is an injection $f^{\leftarrow}(f^{\rightarrow}(A)) =A\;\;\forall A \subset X$ and that if $f$ is not an injection there exists a set $A \subset X$ so that $f^{\leftarrow}(f^{\rightarrow}(A)) \neq A$. So for the first we have to show that $A \subset f^{\leftarrow}(f^{\rightarrow}(A))$ and $f^{\leftarrow}(f^{\rightarrow}(A))\subset A$. $$A \subset f^{\leftarrow}(\{ f(x) \in Y : x \in A\})$$ $A$ is in superset of $X$ and because the function is injective the elements from the domain are mapped to at most one element of the co domain. $$A \subset \{ x \in X : f(x) \in A\}$$ And now we map the range back to a set of elements that is a subset of $A$. Then the next case should be done with same logic? I don't quite follow how the proof should be done for the non-injective case? Any help & hints are welcome.,,"['functions', 'elementary-set-theory']"
65,Is there another function with a property like the log?,Is there another function with a property like the log?,,"Is there another differentiable monotone increasing (or decreasing) function $ f:\mathbb{R} \rightarrow \mathbb{R} $ with a property that $ f(xy) = f(x) + f(y) $, like the log-function has it?","Is there another differentiable monotone increasing (or decreasing) function $ f:\mathbb{R} \rightarrow \mathbb{R} $ with a property that $ f(xy) = f(x) + f(y) $, like the log-function has it?",,"['functions', 'logarithms']"
66,$A$ subset $B$ implies $f(A)$ subset $f(B)$,subset  implies  subset,A B f(A) f(B),"prove: let $f:X\rightarrow Y$. Then for any subset $A$ and $B$ of $X$, a) $$f(A\cap B) \subset f(A)\cap f(B)$$ b) $$A\subset B \Rightarrow f(A)\subset f(B)$$ proof of a): Let $y\in f(A\cap B)$, then there is an $x\in A\cap B$ so that $$f(x) = y$$ But $x\in A$ so $f(x)\in f(A)$ and $x\in B$ so $f(x)\in f(B)$. Therefore, $$f(x)\in f(A)\cap f(B) \ \   i.e. \  y\in f(A)\cap f(B) $$ proof of b): Take an arbitrary element $x\in f(A)$, then there exists a $y\in A$ so that $$f(y) = x$$ Now, take an arbitrary element $x\in f(B)$, then there exists a $y\in B$ so that $$f(y)= x$$ So, for every $y\in A$ and $y\in B$, $f(y)\in f(A)$ and $f(y)\in f(B)$ also for any $x\in f(A)$, $x\in f(B)$. Therefore, $f(A)\subset f(B)$ Are my proofs correct? If not, can you provide reasoning and if the proof is not complete please show me what I need to further add","prove: let $f:X\rightarrow Y$. Then for any subset $A$ and $B$ of $X$, a) $$f(A\cap B) \subset f(A)\cap f(B)$$ b) $$A\subset B \Rightarrow f(A)\subset f(B)$$ proof of a): Let $y\in f(A\cap B)$, then there is an $x\in A\cap B$ so that $$f(x) = y$$ But $x\in A$ so $f(x)\in f(A)$ and $x\in B$ so $f(x)\in f(B)$. Therefore, $$f(x)\in f(A)\cap f(B) \ \   i.e. \  y\in f(A)\cap f(B) $$ proof of b): Take an arbitrary element $x\in f(A)$, then there exists a $y\in A$ so that $$f(y) = x$$ Now, take an arbitrary element $x\in f(B)$, then there exists a $y\in B$ so that $$f(y)= x$$ So, for every $y\in A$ and $y\in B$, $f(y)\in f(A)$ and $f(y)\in f(B)$ also for any $x\in f(A)$, $x\in f(B)$. Therefore, $f(A)\subset f(B)$ Are my proofs correct? If not, can you provide reasoning and if the proof is not complete please show me what I need to further add",,"['functions', 'elementary-set-theory', 'proof-verification']"
67,Find the functions,Find the functions,,"Find all the functions $ f : \mathbb{Q} \rightarrow \mathbb{Q} $ with the following property: $$ f(x + 3f(y)) = f(x) + f(y) + 2y, \: \forall x, y \in \mathbb{Q} $$","Find all the functions $ f : \mathbb{Q} \rightarrow \mathbb{Q} $ with the following property: $$ f(x + 3f(y)) = f(x) + f(y) + 2y, \: \forall x, y \in \mathbb{Q} $$",,"['functions', 'functional-equations', 'rational-numbers']"
68,What does implicit differentiation really mean,What does implicit differentiation really mean,,"What does dy/dx really mean in the context of implicit differentiation The problem is that I can't relate it back to the limit definition.  If you can't write y explicitly as a function of x, often y approaches multiple values as x approach some value, or at some x , y has multiple values hence the limit does not exist and therefore the derivative will not exist","What does dy/dx really mean in the context of implicit differentiation The problem is that I can't relate it back to the limit definition.  If you can't write y explicitly as a function of x, often y approaches multiple values as x approach some value, or at some x , y has multiple values hence the limit does not exist and therefore the derivative will not exist",,"['calculus', 'functions']"
69,"Is $f: \mathcal{P}(\omega) \to \omega \cup \lbrace \omega \rbrace, \ x \mapsto \bigcup \lbrace n \in \omega: n \subset x \rbrace $ surjective?",Is  surjective?,"f: \mathcal{P}(\omega) \to \omega \cup \lbrace \omega \rbrace, \ x \mapsto \bigcup \lbrace n \in \omega: n \subset x \rbrace ","Intro : I am currently preparing for an exam and I have found this particular question in a previous exam of the same class. It is a 'simple' question where you only have to write the answer without justifying it, i.e. no proof is required, but I'd like to understand the problem better. Please note : $\omega$ is the set of 'natural numbers' as constructed by the axioms of ZFC. My Professor told us to prefer this notation because it is not possible to show that $\omega = \mathbb{N}$. So for this course it happens to be that: $$\omega = \lbrace 0,1,2,3, \dots \rbrace = \lbrace \emptyset, \lbrace \emptyset \rbrace, \lbrace \emptyset, \lbrace \emptyset \rbrace \rbrace , \dots \rbrace $$ Problem : Consider the function:  $$f: \mathcal{P}(\omega) \to \omega \cup \lbrace \omega \rbrace, \ x \mapsto \bigcup \lbrace n \in \omega: n \subset x \rbrace $$   Is $f$ injective, surjective, both? My solution : It does not surprise me that $f$ cannot be injective, because we have $\emptyset, \lbrace \emptyset \rbrace \in \mathcal{P}(\omega)$ and for both we have $$f(\emptyset) = f( \lbrace \emptyset \rbrace)= \emptyset = 0 \text{ but } \emptyset \neq \lbrace \emptyset\rbrace $$ So $f$ is not injective and therefore not bijective. The solution however suggest that $f$ has to be surjective and I am having trouble understanding that. For every element $x$ in $$ \omega \cup \lbrace \omega \rbrace = \lbrace 0,1,2,3, \dots , \omega \rbrace $$ I want to find an element $y$ in $\mathcal{P}(\omega)$ such that $f(x)=y$. I can see how that works for all $n \in \omega$ but I also have $\omega \in (\omega \cup \lbrace \omega \rbrace)$ to map and I can't wrap my head around the idea of $$f(?)= \omega $$ It would have made sense to me to say $f( \omega) = \omega$ but that would mean that $\omega \in \omega$ by the definition of $f$ and that is forbidden by the Axiom of regularity .","Intro : I am currently preparing for an exam and I have found this particular question in a previous exam of the same class. It is a 'simple' question where you only have to write the answer without justifying it, i.e. no proof is required, but I'd like to understand the problem better. Please note : $\omega$ is the set of 'natural numbers' as constructed by the axioms of ZFC. My Professor told us to prefer this notation because it is not possible to show that $\omega = \mathbb{N}$. So for this course it happens to be that: $$\omega = \lbrace 0,1,2,3, \dots \rbrace = \lbrace \emptyset, \lbrace \emptyset \rbrace, \lbrace \emptyset, \lbrace \emptyset \rbrace \rbrace , \dots \rbrace $$ Problem : Consider the function:  $$f: \mathcal{P}(\omega) \to \omega \cup \lbrace \omega \rbrace, \ x \mapsto \bigcup \lbrace n \in \omega: n \subset x \rbrace $$   Is $f$ injective, surjective, both? My solution : It does not surprise me that $f$ cannot be injective, because we have $\emptyset, \lbrace \emptyset \rbrace \in \mathcal{P}(\omega)$ and for both we have $$f(\emptyset) = f( \lbrace \emptyset \rbrace)= \emptyset = 0 \text{ but } \emptyset \neq \lbrace \emptyset\rbrace $$ So $f$ is not injective and therefore not bijective. The solution however suggest that $f$ has to be surjective and I am having trouble understanding that. For every element $x$ in $$ \omega \cup \lbrace \omega \rbrace = \lbrace 0,1,2,3, \dots , \omega \rbrace $$ I want to find an element $y$ in $\mathcal{P}(\omega)$ such that $f(x)=y$. I can see how that works for all $n \in \omega$ but I also have $\omega \in (\omega \cup \lbrace \omega \rbrace)$ to map and I can't wrap my head around the idea of $$f(?)= \omega $$ It would have made sense to me to say $f( \omega) = \omega$ but that would mean that $\omega \in \omega$ by the definition of $f$ and that is forbidden by the Axiom of regularity .",,"['functions', 'elementary-set-theory', 'ordinals']"
70,Range of $f(x)=\frac{\sin x -1}{\sqrt{3-2\cos x-2\sin x}}$ for a specified domain,Range of  for a specified domain,f(x)=\frac{\sin x -1}{\sqrt{3-2\cos x-2\sin x}},"We are asked to find the range of the function $$f(x)=\frac{\sin x -1}{\sqrt{3-2\cos x-2\sin x}}, \;\;\text{for}\;0\le x\le2\pi$$ I tried to find the range of each basic function of cos and sin then see if I can use properties of inequality and algebraic combination of the basic functions to find the range of $f(x)$, but it turns out it is not that straightforward. It is not very hard to see that $f(x)\le0$, but I failed to find its minimum value. Then I tried several values of $x$ and guess that the range is [-1,0]. I have little clue how to find the range ""rigorously"". Is there any quicker or smarter way to find the range of this kind of functions? (without calculus?) Many thanks for any help!","We are asked to find the range of the function $$f(x)=\frac{\sin x -1}{\sqrt{3-2\cos x-2\sin x}}, \;\;\text{for}\;0\le x\le2\pi$$ I tried to find the range of each basic function of cos and sin then see if I can use properties of inequality and algebraic combination of the basic functions to find the range of $f(x)$, but it turns out it is not that straightforward. It is not very hard to see that $f(x)\le0$, but I failed to find its minimum value. Then I tried several values of $x$ and guess that the range is [-1,0]. I have little clue how to find the range ""rigorously"". Is there any quicker or smarter way to find the range of this kind of functions? (without calculus?) Many thanks for any help!",,"['functions', 'trigonometry', 'inequality']"
71,How to calculate the range of $x\sin\frac{1}{x}$?,How to calculate the range of ?,x\sin\frac{1}{x},"I want to find the range of $f(x)=x\sin\frac{1}{x}$ . It is clearly that its upper boundary is $$\lim_{x\to\infty}x\sin\frac{1}{x}=1$$ but what is its lower boundary? I used software to obtain the result $y\in[0.217234, 1]$ and the figure is How to calculate the value '0.217234'? Thank you!",I want to find the range of . It is clearly that its upper boundary is but what is its lower boundary? I used software to obtain the result and the figure is How to calculate the value '0.217234'? Thank you!,"f(x)=x\sin\frac{1}{x} \lim_{x\to\infty}x\sin\frac{1}{x}=1 y\in[0.217234, 1]","['calculus', 'functions', 'trigonometry']"
72,"Show that $f(x)={x\over2}+c$, where $c$ is a constant","Show that , where  is a constant",f(x)={x\over2}+c c,"Let $f:\mathbb{R}\to\mathbb{R}$ be a function satisfying $|f(x+y)-f(x-y)-y|$$\le y^2$ for all $x,y\in\mathbb{R}$. Show that $f(x)={x\over2}+c$, where $c$ is a constant.","Let $f:\mathbb{R}\to\mathbb{R}$ be a function satisfying $|f(x+y)-f(x-y)-y|$$\le y^2$ for all $x,y\in\mathbb{R}$. Show that $f(x)={x\over2}+c$, where $c$ is a constant.",,['functions']
73,Are all continuous functions from a closed interval to $\mathbb R$ bounded?,Are all continuous functions from a closed interval to  bounded?,\mathbb R,"For all continuous functions it is true that $f:[a,b] \mapsto \mathbb{R}$ (with $a < b$) is bounded from above. The question is to use the opposite position of that statement as well as to use the Weierstrass Interval technique for a suitable sequence. Could somebody please provide a nice explanation/proof as well as the general idea?","For all continuous functions it is true that $f:[a,b] \mapsto \mathbb{R}$ (with $a < b$) is bounded from above. The question is to use the opposite position of that statement as well as to use the Weierstrass Interval technique for a suitable sequence. Could somebody please provide a nice explanation/proof as well as the general idea?",,['functions']
74,Obtaining function's extreme values without derivate,Obtaining function's extreme values without derivate,,"What is other method to obtain a function min/max value without any use of derivative?  For example in this function: $f(x) = 4x + \dfrac{9\pi^2}{x} + \sin(x)$ My teacher used a method that goes something like this: $a = 4x$, $\ \ \ $ $b = \dfrac{9\pi^2}{x}$, $\ \ \ \min = 2\sqrt{a \cdot b} - \sin(x)$. Can anyone tell me name of such method?","What is other method to obtain a function min/max value without any use of derivative?  For example in this function: $f(x) = 4x + \dfrac{9\pi^2}{x} + \sin(x)$ My teacher used a method that goes something like this: $a = 4x$, $\ \ \ $ $b = \dfrac{9\pi^2}{x}$, $\ \ \ \min = 2\sqrt{a \cdot b} - \sin(x)$. Can anyone tell me name of such method?",,"['calculus', 'functions', 'trigonometry']"
75,A question regarding the Power set,A question regarding the Power set,,"In the proofs that I have seen so far for showing that the power set $2^X$ of a set $X$ cannot be in bijection to $X$, the common idea is to assume that there exists a surjection $f \colon X \to 2^X$ and then consider the set $$ B = \{ x \in X \mid x \notin f(x)\} $$ Then the argument proceeds by saying that this set is contradictory, because its pre-image (say $y \in X$, i.e. $f(y) = B$) satisfies both $y \in B$ and $y \notin B$. On Wikipedia, this method is said to be analogous to Cantor's diagonal argument that is used to show that the interval $(0,1)$ of real numbers between $0$ and $1$ is uncountable. Here we assume that there exists an enumeration. Representing a number $x \in (0,1)$ in its unique decimal expansion, we obtain a list  \begin{align} x_1 &= 0.a_{11}a_{12}a_{13}... \\ x_2 &= 0.a_{21}a_{22}a_{23}... \\ x_2 &= 0.a_{31}a_{32}a_{33}... \\ x_2 &=0.a_{11}a_{12}a_{13}... \\ \vdots \end{align} where $a_{ij} \in \{0,1,\dots,9\}$ for each $i \in \mathbb{N}$ and $j \in \mathbb{N}$. Then one constructs an element from $(0,1)$ that is not in this list. For example, one can take the number $x = 0.b_{1}b_{2}b_{3}\dots$ where \begin{equation} b_i = \begin{cases} 1 & \text{if } a_{ii} = 5 \\ 5 & \text{if } a_{ii} \ne 5  \end{cases} \end{equation} Here, the number $x$ that is generated is well defined as an element of $(0,1)$, and it does not appear in the list above so we've reached a contradiction. On the other hand, for the argument above regarding the power set, assuming $f$ exists implies the object $B$ is not well defined as an element of $2^X$ since it is not the image of a function from $X$ to the set $\{0,1\}$ (it is multi-valued, namely the preimage of $B$ evaluates both to $0$ and $1$). In other words, I cannot use this object $B$ to derive a contradiction. What I can derive is that, if $f$ exists then $B$ is not a set, and if $B$ is a set for each function $f \colon 2^X \to X$ then no such $f$ can be surjective. The latter is what the proofs claim to be the only option, in other words this object $B$ must be a well defined set by some other reason - what am I missing?","In the proofs that I have seen so far for showing that the power set $2^X$ of a set $X$ cannot be in bijection to $X$, the common idea is to assume that there exists a surjection $f \colon X \to 2^X$ and then consider the set $$ B = \{ x \in X \mid x \notin f(x)\} $$ Then the argument proceeds by saying that this set is contradictory, because its pre-image (say $y \in X$, i.e. $f(y) = B$) satisfies both $y \in B$ and $y \notin B$. On Wikipedia, this method is said to be analogous to Cantor's diagonal argument that is used to show that the interval $(0,1)$ of real numbers between $0$ and $1$ is uncountable. Here we assume that there exists an enumeration. Representing a number $x \in (0,1)$ in its unique decimal expansion, we obtain a list  \begin{align} x_1 &= 0.a_{11}a_{12}a_{13}... \\ x_2 &= 0.a_{21}a_{22}a_{23}... \\ x_2 &= 0.a_{31}a_{32}a_{33}... \\ x_2 &=0.a_{11}a_{12}a_{13}... \\ \vdots \end{align} where $a_{ij} \in \{0,1,\dots,9\}$ for each $i \in \mathbb{N}$ and $j \in \mathbb{N}$. Then one constructs an element from $(0,1)$ that is not in this list. For example, one can take the number $x = 0.b_{1}b_{2}b_{3}\dots$ where \begin{equation} b_i = \begin{cases} 1 & \text{if } a_{ii} = 5 \\ 5 & \text{if } a_{ii} \ne 5  \end{cases} \end{equation} Here, the number $x$ that is generated is well defined as an element of $(0,1)$, and it does not appear in the list above so we've reached a contradiction. On the other hand, for the argument above regarding the power set, assuming $f$ exists implies the object $B$ is not well defined as an element of $2^X$ since it is not the image of a function from $X$ to the set $\{0,1\}$ (it is multi-valued, namely the preimage of $B$ evaluates both to $0$ and $1$). In other words, I cannot use this object $B$ to derive a contradiction. What I can derive is that, if $f$ exists then $B$ is not a set, and if $B$ is a set for each function $f \colon 2^X \to X$ then no such $f$ can be surjective. The latter is what the proofs claim to be the only option, in other words this object $B$ must be a well defined set by some other reason - what am I missing?",,"['elementary-set-theory', 'functions', 'cardinals']"
76,Prove that $-\frac{\sqrt{x}}{1+x}\log{x} \leq \log{2}$ for $0 < x < 1$,Prove that  for,-\frac{\sqrt{x}}{1+x}\log{x} \leq \log{2} 0 < x < 1,"Graphically and numerically it is obvious but I'm looking for an analytical reasoning. Just maximizing the left hand side does not yield an analytical expression for the maximum. I also tried some known bounds for $\log$, but all of them had ""overshoot"".","Graphically and numerically it is obvious but I'm looking for an analytical reasoning. Just maximizing the left hand side does not yield an analytical expression for the maximum. I also tried some known bounds for $\log$, but all of them had ""overshoot"".",,"['functions', 'inequality']"
77,A question about uniform continuity,A question about uniform continuity,,Let $F$ be a continuous function on the real set $\mathbb R$ such that the function $x \mapsto xF(x)$ is uniformly continuous on  $\mathbb R$ . Prove that $F$ is also uniformly continuous on  $\mathbb R$ .,Let $F$ be a continuous function on the real set $\mathbb R$ such that the function $x \mapsto xF(x)$ is uniformly continuous on  $\mathbb R$ . Prove that $F$ is also uniformly continuous on  $\mathbb R$ .,,"['real-analysis', 'functions', 'continuity']"
78,Is there a function like this?,Is there a function like this?,,"Let $A=[0,1]$ and $C=\{0\}\cup\{\frac{1}{n},\ n\in\mathbb{N}\}$. i) Is there a function $f:A\rightarrow\mathbb{R}$ such that $f\in C^{r}(A)$, $r\geq 2$ and the set of critical ""Values"" of $f$ is $C$? ii) Is there a function $f:A\rightarrow\mathbb{R}$ such that $f\in C^{1}(A)$ and the set of critical ""Values"" of $f$ is $-C\cup C$? This is a problem from a course of differential topology that i did last year. Is related with Morse theory. I couldn't figure out any good solution for it. I appreciate some help. EDIT: A critical value is image of a critical point, i.e. if $f'(x)=0$ then $f(x)$ is a critical value. Thanks","Let $A=[0,1]$ and $C=\{0\}\cup\{\frac{1}{n},\ n\in\mathbb{N}\}$. i) Is there a function $f:A\rightarrow\mathbb{R}$ such that $f\in C^{r}(A)$, $r\geq 2$ and the set of critical ""Values"" of $f$ is $C$? ii) Is there a function $f:A\rightarrow\mathbb{R}$ such that $f\in C^{1}(A)$ and the set of critical ""Values"" of $f$ is $-C\cup C$? This is a problem from a course of differential topology that i did last year. Is related with Morse theory. I couldn't figure out any good solution for it. I appreciate some help. EDIT: A critical value is image of a critical point, i.e. if $f'(x)=0$ then $f(x)$ is a critical value. Thanks",,"['functions', 'morse-theory']"
79,"What function $f$ such that $a_1 \oplus\, \cdots\,\oplus a_n = 0$ implies $f(a_1) \oplus\, \cdots\,\oplus f(a_n) \neq 0$",What function  such that  implies,"f a_1 \oplus\, \cdots\,\oplus a_n = 0 f(a_1) \oplus\, \cdots\,\oplus f(a_n) \neq 0","For a certain algorithm, I need a function $f$ on integers such that $a_1 \oplus a_2 \oplus \, \cdots\,\oplus a_n = 0 \implies f(a_1) \oplus f(a_2) \oplus \, \cdots\,\oplus f(a_n) \neq 0$ (where the $a_i$ are pairwise distinct, non-negative integers and $\oplus$ is the bitwise XOR operation) The function $f$ should be computable in $O(m)$, where $m$ is the maximum number of digits of the $a_i$. Of course the simpler the function is, the better. Preferrably the output of the function would fit into $m$ digits as well. Is there something like this? It would also be okay to have a family of finitely many functions $f_n$ such that for one of the functions the result of the above operation will be $\neq 0$. My own considerations so far were the following: If we choose the ones' complement as $f$, we can rule out all cases where $n$ is odd. If $n$ is even, this means that for every bit, an even number of the $a_i$ has the bit set and the rest has not, therefore taking the ones' complement before XORing doesn't change the result. So the harder part seems to be the case where $n$ is even.","For a certain algorithm, I need a function $f$ on integers such that $a_1 \oplus a_2 \oplus \, \cdots\,\oplus a_n = 0 \implies f(a_1) \oplus f(a_2) \oplus \, \cdots\,\oplus f(a_n) \neq 0$ (where the $a_i$ are pairwise distinct, non-negative integers and $\oplus$ is the bitwise XOR operation) The function $f$ should be computable in $O(m)$, where $m$ is the maximum number of digits of the $a_i$. Of course the simpler the function is, the better. Preferrably the output of the function would fit into $m$ digits as well. Is there something like this? It would also be okay to have a family of finitely many functions $f_n$ such that for one of the functions the result of the above operation will be $\neq 0$. My own considerations so far were the following: If we choose the ones' complement as $f$, we can rule out all cases where $n$ is odd. If $n$ is even, this means that for every bit, an even number of the $a_i$ has the bit set and the rest has not, therefore taking the ones' complement before XORing doesn't change the result. So the harder part seems to be the case where $n$ is even.",,"['functions', 'algorithms', 'discrete-mathematics', 'binary']"
80,Linear functions with rounding,Linear functions with rounding,,"If I convert 47°F to Celsius, rounding to the nearest integer, I get 8°C. If I then convert back to Fahrenheit, again rounding, I get 46°F. Back to Celsius, 8°C. Now of course if I continue this process it will remain stable, going back and forth between 8°C and 46°F. Will it always stabilize, for any given starting value? More generally, suppose I have an arbitrary linear function, $f(x) = ax + b$ , with inverse $f^{-1}(x) = \frac {x - b} a$ . Using the rounding function $r(x) = \lfloor x + \frac 1 2 \rfloor$ , define the round-trip function $g = r \circ f^{-1} \circ r \circ f$ . Then the question is, does $g = g \circ g$ ? If not, is there always some $n$ for which $g^n = g^{n+1}$ ? Empirically, it seems that $g$ is idempotent, but the proof has defied my meagre abilities. Also, are there any more general things we can say? For instance if $f$ isn't necessarily linear, but strictly monotone, does the process of repeatedly applying, rounding, inverting, and rounding again always converge? PS: Please feel free to add meaningful tags to this... I'm not sure what would be appropriate for this question. Edit Vlad has found a counterexample, so let me amend the definition of rounding to be that if the fractional part is exactly .5, it yields the adjacent even number...","If I convert 47°F to Celsius, rounding to the nearest integer, I get 8°C. If I then convert back to Fahrenheit, again rounding, I get 46°F. Back to Celsius, 8°C. Now of course if I continue this process it will remain stable, going back and forth between 8°C and 46°F. Will it always stabilize, for any given starting value? More generally, suppose I have an arbitrary linear function, , with inverse . Using the rounding function , define the round-trip function . Then the question is, does ? If not, is there always some for which ? Empirically, it seems that is idempotent, but the proof has defied my meagre abilities. Also, are there any more general things we can say? For instance if isn't necessarily linear, but strictly monotone, does the process of repeatedly applying, rounding, inverting, and rounding again always converge? PS: Please feel free to add meaningful tags to this... I'm not sure what would be appropriate for this question. Edit Vlad has found a counterexample, so let me amend the definition of rounding to be that if the fractional part is exactly .5, it yields the adjacent even number...",f(x) = ax + b f^{-1}(x) = \frac {x - b} a r(x) = \lfloor x + \frac 1 2 \rfloor g = r \circ f^{-1} \circ r \circ f g = g \circ g n g^n = g^{n+1} g f,['functions']
81,Solution of a function: Why is it the point where it crosses zero?,Solution of a function: Why is it the point where it crosses zero?,,"This is my first question here ever (not sure how basic this might be): Ive been studying set theory on my own (I have a couple of books and a lot of youtube videos). I understand that a function is ""something"" that relates the elements from one set to another. Therefore, a function will ""link"" an $x_1$ to a given $f(x_1)$ . I know there are certain functions that don't allow certain $x_n$ 's to be inputted and/or some $f(x_n)$ 's that will not be outputted. I got curious regarding the graphic representation of a function. Let's say we have the function $f(x)=x^2-1$ which has the following graphic representation: (I want to highlight where it crosses the x-axis, given it is a second order equation, it crosses it in two points. If it were $f(x)=x^2+1$ I know that the solution is in the complex realm.) I've always been taught that the ""solution"" of a function is where it crosses the $x$ -axis. In this case the function will have those $2$ solutions. My question/confusion is: What does the ""solution"" of a function mean, like...why is the relationship with zero important? Because if I think of it from the set theory approach, there is no ""solution"" (not sure about this though, I'm literally sharing my mind right now) it is just a relationship. I saw something regarding that ""...it is the  of the function"" I've googled that term but didn't quite found something that was clear enough for me. Why is the ""solution"" of a function where the $f(x)$ equals zero? Thanks for reading, responses and patience :)","This is my first question here ever (not sure how basic this might be): Ive been studying set theory on my own (I have a couple of books and a lot of youtube videos). I understand that a function is ""something"" that relates the elements from one set to another. Therefore, a function will ""link"" an to a given . I know there are certain functions that don't allow certain 's to be inputted and/or some 's that will not be outputted. I got curious regarding the graphic representation of a function. Let's say we have the function which has the following graphic representation: (I want to highlight where it crosses the x-axis, given it is a second order equation, it crosses it in two points. If it were I know that the solution is in the complex realm.) I've always been taught that the ""solution"" of a function is where it crosses the -axis. In this case the function will have those solutions. My question/confusion is: What does the ""solution"" of a function mean, like...why is the relationship with zero important? Because if I think of it from the set theory approach, there is no ""solution"" (not sure about this though, I'm literally sharing my mind right now) it is just a relationship. I saw something regarding that ""...it is the  of the function"" I've googled that term but didn't quite found something that was clear enough for me. Why is the ""solution"" of a function where the equals zero? Thanks for reading, responses and patience :)",x_1 f(x_1) x_n f(x_n) f(x)=x^2-1 f(x)=x^2+1 x 2 f(x),"['functions', 'elementary-set-theory']"
82,Confusion on the definition of the inverse function,Confusion on the definition of the inverse function,,"I am currently trying to prove the equivalence of two definitions of enumerability (one involving a surjective function, the other involving an injective one). In doing so, I wanted to consider the inverse of a function, but then it occurred to me that I can't just assume that any function has an inverse. I looked in my lecture notes and got the following definition Let $f: a \rightarrow b$ be $1$ - $1$ . Then the inverse function of $f$ is $f^{-1}: Ran(f) \rightarrow \text{Dom}(f)$ such that: $$\forall \ \ x \in \text{Ran}(f) \ \ \forall \ \ y \in \text{Dom}(f) (f^{-1} = y \leftrightarrow f(y) = x)$$ Where a function $1$ - $1$ function is a injective function. i.e.: $f: a \rightarrow b$ is injective ( $1$ - $1$ ) iff $$\forall \ \ x,y \in a (f(x) = f(y) \rightarrow x = y)$$ But everywhere else I am reading that only a bijective function has an inverse . Now, unless I am mistaken, being an injective function does not imply being a surjective function, so injective functions are not necessarily bijective. But in this case there is a palpable disagreement between these two definitions, and that affects my proof. So, I wonder: have my notes got it wrong, or have I made a mistake? Thank you for any help.","I am currently trying to prove the equivalence of two definitions of enumerability (one involving a surjective function, the other involving an injective one). In doing so, I wanted to consider the inverse of a function, but then it occurred to me that I can't just assume that any function has an inverse. I looked in my lecture notes and got the following definition Let be - . Then the inverse function of is such that: Where a function - function is a injective function. i.e.: is injective ( - ) iff But everywhere else I am reading that only a bijective function has an inverse . Now, unless I am mistaken, being an injective function does not imply being a surjective function, so injective functions are not necessarily bijective. But in this case there is a palpable disagreement between these two definitions, and that affects my proof. So, I wonder: have my notes got it wrong, or have I made a mistake? Thank you for any help.","f: a \rightarrow b 1 1 f f^{-1}: Ran(f) \rightarrow \text{Dom}(f) \forall \ \ x \in \text{Ran}(f) \ \ \forall \ \ y \in \text{Dom}(f) (f^{-1} = y \leftrightarrow f(y) = x) 1 1 f: a \rightarrow b 1 1 \forall \ \ x,y \in a (f(x) = f(y) \rightarrow x = y)","['functions', 'elementary-set-theory', 'definition']"
83,"When $y=f(x)+ax+b$ for some trig function $f$, is there a name (like ""oblique asymptote"") for the line $y=ax+b$?","When  for some trig function , is there a name (like ""oblique asymptote"") for the line ?",y=f(x)+ax+b f y=ax+b,"Let $f$ be a trig function, and let $y:=ax+b$ be a linear function. Every time you have $f(x)+y$ as one function, you get a graph where $(C_f)$ follows the line $y=ax+b$ , but we don't have the known limit for an oblique asymptote ( $\lim_{x \rightarrow \infty} f(x)-y \neq 0 $ ). Can we still call the line $y:=ax+b$ an oblique asymptote, or does this line have another name? An example with the function $f(x):=\sin(x)+x$ :","Let be a trig function, and let be a linear function. Every time you have as one function, you get a graph where follows the line , but we don't have the known limit for an oblique asymptote ( ). Can we still call the line an oblique asymptote, or does this line have another name? An example with the function :",f y:=ax+b f(x)+y (C_f) y=ax+b \lim_{x \rightarrow \infty} f(x)-y \neq 0  y:=ax+b f(x):=\sin(x)+x,"['functions', 'trigonometry', 'terminology']"
84,Twice differentiable function related problem [duplicate],Twice differentiable function related problem [duplicate],,"This question already has answers here : If $f(x)=f'(x)+f''(x)$ then show that $f(x)=0$ (4 answers) Closed 2 years ago . Let $f(x)$ be a real valued twice differentiable function on interval $[1,5]$ such that $f(1) = f(5) = 0$ and $f(x) = f'(x) + f''(x)$ , $\forall x \in \left[ {1,5} \right]$ , then $(f(2)+f(4)–f'(3))$ is equal to___________________. I am not able to approach this problem. Initially I thought of using Rolle's Theorem but function needs to be continuous in the closed interval $[1,5]$ and differentiable in the open interval $(1,5)$ . How do I perform the mathematical operation on these numbers","This question already has answers here : If $f(x)=f'(x)+f''(x)$ then show that $f(x)=0$ (4 answers) Closed 2 years ago . Let be a real valued twice differentiable function on interval such that and , , then is equal to___________________. I am not able to approach this problem. Initially I thought of using Rolle's Theorem but function needs to be continuous in the closed interval and differentiable in the open interval . How do I perform the mathematical operation on these numbers","f(x) [1,5] f(1) = f(5) = 0 f(x) = f'(x) + f''(x) \forall x \in \left[ {1,5} \right] (f(2)+f(4)–f'(3)) [1,5] (1,5)","['real-analysis', 'calculus', 'functions']"
85,"Prove that $f(n)=n$, $\forall n \in \mathbb N$ for the strictly increasing multiplicative function [duplicate]","Prove that ,  for the strictly increasing multiplicative function [duplicate]",f(n)=n \forall n \in \mathbb N,"This question already has answers here : Let $(a_n)$ be a strictly increasing sequence of positive integers such that: $a_2 = 2$, $a_{mn} = a_m a_n$ for $m, n$ relatively prime. (2 answers) Closed 2 years ago . Problem Let $f : \mathbb{N}\to\mathbb{N}$ be a strictly increasing function such that $f(2) = 2$ and $f(mn) = f(m) \cdot f(n)$ for every relatively prime pair of positive integers $m$ and $n$ . Prove that $f(n) = n$ for every positive integer $n$ . My approach I tried to prove this using induction. For the base case, we need to find $f(3)$ . We have $$f(3) \cdot f(5)<2f(9)<4f(5)$$ $$\implies f(3)<4$$ And since $f(3)>f(2)=2$ , we have $f(3)=3$ . Now, we assume that $f(k-1)=k-1$ and $f(k)=k$ . Since $k$ and $k-1$ are relatively prime, we have $f(k(k-1))=f(k)f(k-1)=k(k-1)$ . But this does not prove. So, how do I complete the proof?","This question already has answers here : Let $(a_n)$ be a strictly increasing sequence of positive integers such that: $a_2 = 2$, $a_{mn} = a_m a_n$ for $m, n$ relatively prime. (2 answers) Closed 2 years ago . Problem Let be a strictly increasing function such that and for every relatively prime pair of positive integers and . Prove that for every positive integer . My approach I tried to prove this using induction. For the base case, we need to find . We have And since , we have . Now, we assume that and . Since and are relatively prime, we have . But this does not prove. So, how do I complete the proof?",f : \mathbb{N}\to\mathbb{N} f(2) = 2 f(mn) = f(m) \cdot f(n) m n f(n) = n n f(3) f(3) \cdot f(5)<2f(9)<4f(5) \implies f(3)<4 f(3)>f(2)=2 f(3)=3 f(k-1)=k-1 f(k)=k k k-1 f(k(k-1))=f(k)f(k-1)=k(k-1),"['elementary-number-theory', 'functions', 'induction', 'contest-math', 'functional-equations']"
86,Why does a spiral structure appear for this function?,Why does a spiral structure appear for this function?,,"Consider the following 2D vector field on the $xy$ -plane $$\vec{V}=\begin{pmatrix} -(m^2-md+x^2)\cos{2d\,t}+xy\sin{2d\,t} \\ -xy\cos{2d\,t}+(m^2-md+y^2)\sin{2d\,t} \end{pmatrix}$$ where $d=\sqrt{x^2+y^2+m^2}$ and a constant $m\geq0$ . When plotting the vector's angle $\arctan(V_x,V_y)\in[0,2\pi]$ by color on the $xy$ -plane, it always clearly shows a spiral pattern ( $t=15,m=0.3$ in the plot below). How can I understand the appearance of the spiral?","Consider the following 2D vector field on the -plane where and a constant . When plotting the vector's angle by color on the -plane, it always clearly shows a spiral pattern ( in the plot below). How can I understand the appearance of the spiral?","xy \vec{V}=\begin{pmatrix}
-(m^2-md+x^2)\cos{2d\,t}+xy\sin{2d\,t} \\
-xy\cos{2d\,t}+(m^2-md+y^2)\sin{2d\,t}
\end{pmatrix} d=\sqrt{x^2+y^2+m^2} m\geq0 \arctan(V_x,V_y)\in[0,2\pi] xy t=15,m=0.3","['functions', 'trigonometry', 'vectors', 'vector-fields', 'visualization']"
87,What are examples of Antiset?,What are examples of Antiset?,,A set which transforms via converse functions is called antiset . Antisets usually arise in the context of Chu spaces . I couldn't understand the notion of antiset and its examples.,A set which transforms via converse functions is called antiset . Antisets usually arise in the context of Chu spaces . I couldn't understand the notion of antiset and its examples.,,"['functions', 'elementary-set-theory', 'set-theory']"
88,Inequality concerning a function :${(f(x))}^2=1+xf(x+1)$,Inequality concerning a function :,{(f(x))}^2=1+xf(x+1),"If $f:[0,\infty]\rightarrow [0,\infty]$ is such that for all $x\in [0,\infty]$ : $${(f(x))}^2=1+xf(x+1)$$ Prove that for all $x\ge 1$ $$\frac{x+1}{2}\le f(x)\le  2(x+1)$$ First of all I have never had experience proving such inequalities and since nothing is said about the differentiability I don't know whether calculus would be a good approach. We can however draw the following conclusions for all $x\ge 1$ As $f(x)\ge 1$ we have $$f(x)^2=1+xf(x+1)\ge 1+x \implies f(x)\ge \sqrt{x+1}$$ By Bernoulli's inequality $$f(x)=\sqrt{1+xf(x+1)}\le 1+\frac{xf(x+1)}{2}$$ As $f(x+1)\le f^2(x+1)$ and $x\le x^2$ $$f(x)^2=1+xf(x+1)\le 1+x^2f^2(x+1)$$ $$(f(x)-xf(x+1))(f(x)+xf(x+1))\le 1$$ That's it, I couldn't get any more ideas ... P.S. The problem is from here .","If is such that for all : Prove that for all First of all I have never had experience proving such inequalities and since nothing is said about the differentiability I don't know whether calculus would be a good approach. We can however draw the following conclusions for all As we have By Bernoulli's inequality As and That's it, I couldn't get any more ideas ... P.S. The problem is from here .","f:[0,\infty]\rightarrow [0,\infty] x\in [0,\infty] {(f(x))}^2=1+xf(x+1) x\ge 1 \frac{x+1}{2}\le f(x)\le  2(x+1) x\ge 1 f(x)\ge 1 f(x)^2=1+xf(x+1)\ge 1+x \implies f(x)\ge \sqrt{x+1} f(x)=\sqrt{1+xf(x+1)}\le 1+\frac{xf(x+1)}{2} f(x+1)\le f^2(x+1) x\le x^2 f(x)^2=1+xf(x+1)\le 1+x^2f^2(x+1) (f(x)-xf(x+1))(f(x)+xf(x+1))\le 1","['functions', 'inequality', 'contest-math', 'functional-equations']"
89,Maclaurin of $f(x)=\ln\left(\sum_{k=0}^{1000}\frac{x^k}{k!}\right)$,Maclaurin of,f(x)=\ln\left(\sum_{k=0}^{1000}\frac{x^k}{k!}\right),"The 1001st order is required. Here is how I went about the question: We know that near $x=0$ : $$e^x=\sum_{k=0}^{1000}\frac{x^k}{k!}+\frac{x^{1001}}{1001!}+o(x^{1001})$$ So, $$e^x-\frac{x^{1001}}{1001!}+o(x^{1001})=\sum_{k=0}^{1000}\frac{x^k}{k!}$$ And after taking the logarithm of both sides, $$f(x)=\ln\left(e^x-\frac{x^{1001}}{1001!}+o(x^{1001})\right)$$ But what do I do next? I intuitively understand that the answer should be: $$f(x)=x-\frac{x^{1001}}{1001!}+o(x^{1001})$$ But how do I prove it rigorously? Thank you!","The 1001st order is required. Here is how I went about the question: We know that near : So, And after taking the logarithm of both sides, But what do I do next? I intuitively understand that the answer should be: But how do I prove it rigorously? Thank you!",x=0 e^x=\sum_{k=0}^{1000}\frac{x^k}{k!}+\frac{x^{1001}}{1001!}+o(x^{1001}) e^x-\frac{x^{1001}}{1001!}+o(x^{1001})=\sum_{k=0}^{1000}\frac{x^k}{k!} f(x)=\ln\left(e^x-\frac{x^{1001}}{1001!}+o(x^{1001})\right) f(x)=x-\frac{x^{1001}}{1001!}+o(x^{1001}),"['real-analysis', 'calculus', 'functions', 'taylor-expansion']"
90,Value of $n$ for which the function $x^n \sin {\frac{1}{x}}$ is continuous at $x=0$,Value of  for which the function  is continuous at,n x^n \sin {\frac{1}{x}} x=0,"The question is as follows, Determine the values of $n$ for which the function, $$f(x) = \begin{cases}x^n\sin\left(\frac1x\right) & ,x\neq 0 \\ 0 & ,x=0\end{cases}$$ is continuous at $x=0$ The way I tried to solve it is by using inequalities, starting with, $$-1 \leq \sin \left(\frac1x\right) \leq 1$$ $$-x^n \leq x^n\sin \left(\frac1x\right) \leq x^n$$ $$\lim_{x\rightarrow 0} -x^n \leq \lim _{x\rightarrow0} f(x) \leq \lim_{x\rightarrow 0} x^n $$ Which gives us, continuity $\forall \;n$ This seems right but I'm not sure, could someone confirm it and also is there a better method?","The question is as follows, Determine the values of for which the function, is continuous at The way I tried to solve it is by using inequalities, starting with, Which gives us, continuity This seems right but I'm not sure, could someone confirm it and also is there a better method?","n f(x) = \begin{cases}x^n\sin\left(\frac1x\right) & ,x\neq 0 \\ 0 & ,x=0\end{cases} x=0 -1 \leq \sin \left(\frac1x\right) \leq 1 -x^n \leq x^n\sin \left(\frac1x\right) \leq x^n \lim_{x\rightarrow 0} -x^n \leq \lim _{x\rightarrow0} f(x) \leq \lim_{x\rightarrow 0} x^n  \forall \;n","['functions', 'continuity']"
91,"Find all functions $f \colon \mathbb R \to \mathbb R$ such that $f(f(x) - y) = f(f(x)) - 2f(x)y + f(y), \forall x, y \in \mathbb R$.",Find all functions  such that .,"f \colon \mathbb R \to \mathbb R f(f(x) - y) = f(f(x)) - 2f(x)y + f(y), \forall x, y \in \mathbb R","Find all functions $f \colon \mathbb R \to \mathbb R$ such that $$\large f(f(x) - y) = f(f(x)) - 2f(x)y + f(y), \forall x, y \in \mathbb R$$ It can be deduced that the solutions are $f(x) = 0, \forall x \in \mathbb R$ and $f(x) = x^2, \forall x \in \mathbb R$ Here's an attempt. Let $P(x, y)$ be the assertion $f(f(x) - y) = f(f(x)) - 2f(x)y + f(y)$ . We have that for $P(0, 0)$ , $f(f(0)) = f(f(0)) + f(0) \iff f(0) = 0$ . Furthermore, for $P(x, f(x))$ , we have that $$f(f(x) - f(x)) = f(f(x)) - 2[f(x)]^2 + f(f(x)), \forall x, y \in \mathbb R$$ $$\iff f(0) = 2f(f(x)) - 2[f(x)]^2, \forall x, y \in \mathbb R \iff f(f(x)) = [f(x)]^2, \forall x, y \in \mathbb R$$ $(\implies f(f(0)) = [f(0)]^2 = 0)$ $$\iff f(f(x) - y) = [f(x)]^2 - 2f(x)y + f(y), \forall x, y \in \mathbb R$$ $$\iff f(f(x) - y) - (f(x) - y)^2 = f(y) - y^2, \forall x, y \in \mathbb R$$ Replacing $y$ and $f(y)$ , we have that $f(f(x) - f(y)) = (f(x) - f(y))^2$ For $P(0, x), f(f(0) - x) = f(f(0)) - 2f(0)x + f(x), \forall x, y \in \mathbb R \iff f(x) = f(-x), \forall x, y \in \mathbb R$ $\iff f(x)$ is an even function. Then I don't what to do next.","Find all functions such that It can be deduced that the solutions are and Here's an attempt. Let be the assertion . We have that for , . Furthermore, for , we have that Replacing and , we have that For is an even function. Then I don't what to do next.","f \colon \mathbb R \to \mathbb R \large f(f(x) - y) = f(f(x)) - 2f(x)y + f(y), \forall x, y \in \mathbb R f(x) = 0, \forall x \in \mathbb R f(x) = x^2, \forall x \in \mathbb R P(x, y) f(f(x) - y) = f(f(x)) - 2f(x)y + f(y) P(0, 0) f(f(0)) = f(f(0)) + f(0) \iff f(0) = 0 P(x, f(x)) f(f(x) - f(x)) = f(f(x)) - 2[f(x)]^2 + f(f(x)), \forall x, y \in \mathbb R \iff f(0) = 2f(f(x)) - 2[f(x)]^2, \forall x, y \in \mathbb R \iff f(f(x)) = [f(x)]^2, \forall x, y \in \mathbb R (\implies f(f(0)) = [f(0)]^2 = 0) \iff f(f(x) - y) = [f(x)]^2 - 2f(x)y + f(y), \forall x, y \in \mathbb R \iff f(f(x) - y) - (f(x) - y)^2 = f(y) - y^2, \forall x, y \in \mathbb R y f(y) f(f(x) - f(y)) = (f(x) - f(y))^2 P(0, x), f(f(0) - x) = f(f(0)) - 2f(0)x + f(x), \forall x, y \in \mathbb R \iff f(x) = f(-x), \forall x, y \in \mathbb R \iff f(x)",['functions']
92,Is there a 1-1 function $f: \mathbb{N} \rightarrow A$?,Is there a 1-1 function ?,f: \mathbb{N} \rightarrow A,"Assume $g: A \rightarrow A $ is a 1-1 but not onto function. What does that tell us about an injective function $f$ from $\mathbb{N}$ to $A$ ? In this case, $A$ would have to be an infinite set since if the set were finite, such a $g$ could not exist. It seems as though such a 1-1 function $f$ exists, but any suggestions on how to proceed from here to show that there is one?","Assume is a 1-1 but not onto function. What does that tell us about an injective function from to ? In this case, would have to be an infinite set since if the set were finite, such a could not exist. It seems as though such a 1-1 function exists, but any suggestions on how to proceed from here to show that there is one?",g: A \rightarrow A  f \mathbb{N} A A g f,['functions']
93,Terminology for the property $f(2x) = 2f(x)$,Terminology for the property,f(2x) = 2f(x),"The property $$f(2x) = 2f(x)$$ is strictly weaker than linearity: linearity implies it, but if e.g. $f : \mathbb{N} \to \mathbb{N}$ then $f$ can satisfy this property without being linear, as exemplified by OEIS A006519 : $x \to 2^{\nu_2(x)}$ . Does this property have a name?","The property is strictly weaker than linearity: linearity implies it, but if e.g. then can satisfy this property without being linear, as exemplified by OEIS A006519 : . Does this property have a name?",f(2x) = 2f(x) f : \mathbb{N} \to \mathbb{N} f x \to 2^{\nu_2(x)},"['functions', 'terminology']"
94,Existence of a global involution extension.,Existence of a global involution extension.,,"I'm studying the paper ""Local and simultaneous structural stability of certain diffeomorphisms. - Marco Antonio Teixeira"". At the beginning of the paper, the author gives the following definition Besides that, the author states the following lemma: However, he does not demonstrate such a result, just saying ""the lemma is easy to proof"". I know how to find an extension $\omega:\mathbb{R}^2\to \mathbb{R}^2$ of $\left. \varphi \right|_{U}$ such that $\varphi'(0) + \beta$ where $\beta \in \mathcal C_b^0 (\mathbb{R}^2)$ is Lipschitz with bounded constant by $\varepsilon$ . However, I don't have the faintest idea how to guarantee $\omega\circ \omega= \mathrm{Id}.$ Can anyone help me? How do I constructed the function $\omega$ Define $F= \varphi$ and $L = \mathrm{d} \varphi(0)$ . First, choose a $\mathcal{C}^\infty$ real function $\beta:\mathbb{R} \to \mathbb{R}$ satisfying: $\beta(x) = 0 $ , $\forall$ $x$ $\in$ $\mathbb{R} \setminus [-1,1]$ . $\beta(x) =1$ , $\forall$ $x$ $\in$ $ \left[-\frac{1}{2},\frac{1}{2}\right].$ $\beta (x)$ is a increasing function in $\left[-1,-\frac{1}{2}\right]$ and $\beta(x)$ is a decreasing function in $\left[\frac{1}{2}, 1\right]$ . Note that, $\beta$ is compact support $\mathcal{C}^\infty$ , so, there exists $M$ $\in$ $\mathbb{R}$ , such that, $M = \sup \{|D\beta(x)|; \hspace{0.1cm} x \in \mathbb{R}\} $ . We define $\phi: U \rightarrow \mathbb{R}^2$ as $\phi(x) = F(x) - Lx$ . Observe that the function $\phi$ is a $\mathcal{C}^\infty$ , moreover, $D\phi(0) = 0$ . Therefore, for the real number $\widetilde{\varepsilon} = \min\left\{ \frac{\varepsilon}{2M} , \frac{\varepsilon}{2}\right\} > 0$ there exists $1 \geq r >0$ such that $$x \in B_r (0) \subset U \Rightarrow \Vert D\phi(x) \Vert < \widetilde{\varepsilon} $$ implying, by the mean value theoream that, if $x \in B_r (0)  \Rightarrow \Vert \phi(x) \Vert < \widetilde{\varepsilon}\Vert x\Vert $ . Now, consider $\omega: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ defined as: $$\omega(x) = \left\{\begin{array}{l} 	Lx + \beta\left(\frac{\Vert x \Vert}{r}\right)\phi(x), \hspace{0.1cm} \text{if} \hspace{0.1cm} x \in U,\\      Lx, \hspace{0.1cm} \text{if} \hspace{0.1cm} x \in \mathbb{R}^n \setminus U. \end{array} \right. $$ Thus, defining $r_1 = r$ and $r_2 = \frac{r}{2}$ . It is easy to verify that $\omega = F$ in $B_{r_2} (0)$ . $\omega = L$ outside $B_{r_1}(0)$ . The function $\alpha = G - L$ is bounded by $\varepsilon$ . $\alpha$ is $\varepsilon$ -Lipschitz. Once $\omega = L +\alpha$ , we constructed such an extension. However, $\omega \circ \omega $ is not necessarily equal to $\mathrm{Id}$ .","I'm studying the paper ""Local and simultaneous structural stability of certain diffeomorphisms. - Marco Antonio Teixeira"". At the beginning of the paper, the author gives the following definition Besides that, the author states the following lemma: However, he does not demonstrate such a result, just saying ""the lemma is easy to proof"". I know how to find an extension of such that where is Lipschitz with bounded constant by . However, I don't have the faintest idea how to guarantee Can anyone help me? How do I constructed the function Define and . First, choose a real function satisfying: , . , is a increasing function in and is a decreasing function in . Note that, is compact support , so, there exists , such that, . We define as . Observe that the function is a , moreover, . Therefore, for the real number there exists such that implying, by the mean value theoream that, if . Now, consider defined as: Thus, defining and . It is easy to verify that in . outside . The function is bounded by . is -Lipschitz. Once , we constructed such an extension. However, is not necessarily equal to .","\omega:\mathbb{R}^2\to \mathbb{R}^2 \left. \varphi \right|_{U} \varphi'(0) + \beta \beta \in \mathcal C_b^0 (\mathbb{R}^2) \varepsilon \omega\circ \omega= \mathrm{Id}. \omega F= \varphi L = \mathrm{d} \varphi(0) \mathcal{C}^\infty \beta:\mathbb{R} \to \mathbb{R} \beta(x) = 0  \forall x \in \mathbb{R} \setminus [-1,1] \beta(x) =1 \forall x \in  \left[-\frac{1}{2},\frac{1}{2}\right]. \beta (x) \left[-1,-\frac{1}{2}\right] \beta(x) \left[\frac{1}{2}, 1\right] \beta \mathcal{C}^\infty M \in \mathbb{R} M = \sup \{|D\beta(x)|; \hspace{0.1cm} x \in \mathbb{R}\}  \phi: U \rightarrow \mathbb{R}^2 \phi(x) = F(x) - Lx \phi \mathcal{C}^\infty D\phi(0) = 0 \widetilde{\varepsilon} = \min\left\{ \frac{\varepsilon}{2M} , \frac{\varepsilon}{2}\right\} > 0 1 \geq r >0 x \in B_r (0) \subset U \Rightarrow \Vert D\phi(x) \Vert < \widetilde{\varepsilon}  x \in B_r (0)  \Rightarrow \Vert \phi(x) \Vert < \widetilde{\varepsilon}\Vert x\Vert  \omega: \mathbb{R}^2 \rightarrow \mathbb{R}^2 \omega(x) = \left\{\begin{array}{l}
	Lx + \beta\left(\frac{\Vert x \Vert}{r}\right)\phi(x), \hspace{0.1cm} \text{if} \hspace{0.1cm} x \in U,\\ 
    Lx, \hspace{0.1cm} \text{if} \hspace{0.1cm} x \in \mathbb{R}^n \setminus U. \end{array} \right.  r_1 = r r_2 = \frac{r}{2} \omega = F B_{r_2} (0) \omega = L B_{r_1}(0) \alpha = G - L \varepsilon \alpha \varepsilon \omega = L +\alpha \omega \circ \omega  \mathrm{Id}","['real-analysis', 'functions', 'differential-topology', 'dynamical-systems', 'germs']"
95,Functions that converge when repeatedly applied to itself,Functions that converge when repeatedly applied to itself,,"Suppose a function $f: \mathbb{R}\rightarrow\mathbb{R}$ with the property $$ \lim_{n\rightarrow\infty}\; \underbrace{f\circ f\circ \dots \circ f}_{\mathrm{n \;times}}(x) = c = \mathrm{const.} $$ i.e. it converges in the limit to a finite number when repeatedly applied to itself. Also $\exists\, a, b \in \mathbb{R}, s.t. \; f(a)\neq f(b)$ should hold (i.e. only non-constant functions). As pointed out in the comments $f(x) = \sqrt{|x|}$ is not a valid example. So I don't have any example function with that property but $f(x) = \frac{1}{x}$ on the other hand is bound though it doesn't converge. Now I am interested in the following aspects: Can one identify a subset of all functions for which this property is present (for any value of $c$ )? Do such functions have other specific properties that are perhaps common among all of them (and related to the value of $c$ )? Do functions exist for which $c = 0$ (perhaps $f(x) = \sin(x)$ but I'm not sure how to approach this)? Do functions exist for which $c \neq 0$ ? I am particularly interested in the case $c = 0$ .",Suppose a function with the property i.e. it converges in the limit to a finite number when repeatedly applied to itself. Also should hold (i.e. only non-constant functions). As pointed out in the comments is not a valid example. So I don't have any example function with that property but on the other hand is bound though it doesn't converge. Now I am interested in the following aspects: Can one identify a subset of all functions for which this property is present (for any value of )? Do such functions have other specific properties that are perhaps common among all of them (and related to the value of )? Do functions exist for which (perhaps but I'm not sure how to approach this)? Do functions exist for which ? I am particularly interested in the case .,"f: \mathbb{R}\rightarrow\mathbb{R} 
\lim_{n\rightarrow\infty}\; \underbrace{f\circ f\circ \dots \circ f}_{\mathrm{n \;times}}(x) = c = \mathrm{const.}
 \exists\, a, b \in \mathbb{R}, s.t. \; f(a)\neq f(b) f(x) = \sqrt{|x|} f(x) = \frac{1}{x} c c c = 0 f(x) = \sin(x) c \neq 0 c = 0","['functions', 'convergence-divergence']"
96,What's the difference between $f(x)=\sqrt{x^2+9}$ and $k(x^2+9)=\sqrt{x^2+9}$?,What's the difference between  and ?,f(x)=\sqrt{x^2+9} k(x^2+9)=\sqrt{x^2+9},"Let's say we 've got a function $f(x)=\sqrt{x^2+9}$ , which is a composite function. $f(x)=\sqrt{g(x)}$ and $g(x)=x^2+9$ . When we have a function like $h(x)=x$ , we are allowed to set $x$ to $x+9$ and have $h(x+9)=x+9$ . So why do we need $g(x)$ and can't just set $x=x^2+9$ , which with a function like $k(x)=\sqrt{x}$ leads to $k(x^2+9)=\sqrt{x^2+9}$ (same as f(x) above)? Where's the difference between these two ( $f(x),k(x)$ )? Is $x^2+9$ even a valid argument for $k(x)$ ?","Let's say we 've got a function , which is a composite function. and . When we have a function like , we are allowed to set to and have . So why do we need and can't just set , which with a function like leads to (same as f(x) above)? Where's the difference between these two ( )? Is even a valid argument for ?","f(x)=\sqrt{x^2+9} f(x)=\sqrt{g(x)} g(x)=x^2+9 h(x)=x x x+9 h(x+9)=x+9 g(x) x=x^2+9 k(x)=\sqrt{x} k(x^2+9)=\sqrt{x^2+9} f(x),k(x) x^2+9 k(x)",['functions']
97,Beta reduction for expression,Beta reduction for expression,,"I'm given the following where: TRUE = λxy.x FALSE = λxy.y  IF = λbtf. b t f OR = λxy. IF x TRUE y and I'm trying to evaluate: OR FALSE TRUE using Beta reduction. Since beta reduction is left associative, i started from the left but I'm having difficulties with the OR where there contains IF and TRUE inside it's expression. So i tried: OR FALSE TRUE (λxy. IF x TRUE y) (λxy.y) (λxy.x) (λxy. (λbtf. b t f) x (λxy.x) y) (λxy.y) (λxy.x) #i substituted btf with x here but I'm not fully sure if it's valid (λxy. x (λxy.x) y) (λxy.y) (λxy.x) (λxy. x x) (λxy.y) (λxy.x) (λxy.y) (λxy.y) (λxy.x) (y) (λxy.x) But I'm pretty sure I messed up somewhere along way as evaluating the OR was confusing enough. I'm not certain if I beta reduced correctly so I would appreciate some help on this. I gave it another go so here's what I did: OR FALSE TRUE (λxy. IF x TRUE y) FALSE TRUE IF FALSE TRUE FALSE TRUE (λbtf. btf) FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE (λxy.y) TRUE FALSE TRUE (λx.TRUE) FALSE TRUE TRUE TRUE (λxy.x) TRUE λy.TRUE Again I'm still uncertain if it's correct this way too. Some help needed.","I'm given the following where: TRUE = λxy.x FALSE = λxy.y  IF = λbtf. b t f OR = λxy. IF x TRUE y and I'm trying to evaluate: OR FALSE TRUE using Beta reduction. Since beta reduction is left associative, i started from the left but I'm having difficulties with the OR where there contains IF and TRUE inside it's expression. So i tried: OR FALSE TRUE (λxy. IF x TRUE y) (λxy.y) (λxy.x) (λxy. (λbtf. b t f) x (λxy.x) y) (λxy.y) (λxy.x) #i substituted btf with x here but I'm not fully sure if it's valid (λxy. x (λxy.x) y) (λxy.y) (λxy.x) (λxy. x x) (λxy.y) (λxy.x) (λxy.y) (λxy.y) (λxy.x) (y) (λxy.x) But I'm pretty sure I messed up somewhere along way as evaluating the OR was confusing enough. I'm not certain if I beta reduced correctly so I would appreciate some help on this. I gave it another go so here's what I did: OR FALSE TRUE (λxy. IF x TRUE y) FALSE TRUE IF FALSE TRUE FALSE TRUE (λbtf. btf) FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE (λxy.y) TRUE FALSE TRUE (λx.TRUE) FALSE TRUE TRUE TRUE (λxy.x) TRUE λy.TRUE Again I'm still uncertain if it's correct this way too. Some help needed.",,"['functions', 'computer-science', 'lambda-calculus']"
98,For which $a$ is this function increasing? $ f(x) = \left( \frac {a-2}{a-4}\right) ^{-x} $,For which  is this function increasing?,a  f(x) = \left( \frac {a-2}{a-4}\right) ^{-x} ,"For which $a$ is this function increasing? $$  f(x) = \left( \frac {a-2}{a-4}\right) ^{-x} $$ So first I would rewrite this as: $$  f(x) = \left( \frac {a-4}{a-2}\right) ^{x} $$ I was thinking that in order for the function to be increasing the whole fraction has to be bigger than $1$ or smaller than $-1$ So I devided that into two conditions: $   \frac {a-4}{a-2}> 1 $ and $   \frac {a-4}{a-2} < -1 $ I solved both inequalities and the result should be: for the first inequality: $(   -\infty, 2) $ fot the other one: $( 2, 3) $ ANd now for the final  result I should combine both so that would be $K =\left\{( -\infty, 2) U ( 2, 3) \right\} $ Is this corrrect? I have no idea how else I should find out .. But my intuition tells me that something is not correct .. Thanks for help",For which is this function increasing? So first I would rewrite this as: I was thinking that in order for the function to be increasing the whole fraction has to be bigger than or smaller than So I devided that into two conditions: and I solved both inequalities and the result should be: for the first inequality: fot the other one: ANd now for the final  result I should combine both so that would be Is this corrrect? I have no idea how else I should find out .. But my intuition tells me that something is not correct .. Thanks for help,"a   f(x) = \left( \frac {a-2}{a-4}\right) ^{-x}    f(x) = \left( \frac {a-4}{a-2}\right) ^{x}  1 -1    \frac {a-4}{a-2}> 1     \frac {a-4}{a-2} < -1  (   -\infty, 2)  ( 2, 3)  K =\left\{( -\infty, 2) U ( 2, 3) \right\} ",['functions']
99,Neural Networks - Are these functions Lipschitz continuous?,Neural Networks - Are these functions Lipschitz continuous?,,"Assuming for simplicity a neural network with 1 parameter. Let $x \in R$ be a training pattern, $t \in R$ the target variable, $w \in R$ the parameter and $g: R \rightarrow R$ the activation function. Given the regularized loss function: $$ f(x;w)  = \frac{1}{2}(t - g(xw))^2 + \frac{1}{2} \lambda w^2$$ The activation function $g$ can be linear , sigmoid , tanh or ReLU . Depending on the choice of $g$, are $f$, $\nabla f$ and $\nabla^2 f$ Lipschitz-continuous? ps: I need to check whether some assumptions of optimization algorithms are true, so I think they require global Lipschitz continuity.","Assuming for simplicity a neural network with 1 parameter. Let $x \in R$ be a training pattern, $t \in R$ the target variable, $w \in R$ the parameter and $g: R \rightarrow R$ the activation function. Given the regularized loss function: $$ f(x;w)  = \frac{1}{2}(t - g(xw))^2 + \frac{1}{2} \lambda w^2$$ The activation function $g$ can be linear , sigmoid , tanh or ReLU . Depending on the choice of $g$, are $f$, $\nabla f$ and $\nabla^2 f$ Lipschitz-continuous? ps: I need to check whether some assumptions of optimization algorithms are true, so I think they require global Lipschitz continuity.",,"['functions', 'lipschitz-functions']"
