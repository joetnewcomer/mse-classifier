,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Continuity of maximum eigenvalue function,Continuity of maximum eigenvalue function,,"Let $f:S^n_{+}(\mathbb{R})\rightarrow \mathbb{R}_+$ be defined as $$f(A)=\lambda_{\max}(A),$$ where $S^n_{+}(\mathbb{R})$ is set of all positive definite $n\times n$ matrices. What can we say about the continuity and differentiability of $f$ ? Intuitively, I feel that it is continuous because if we perturb a matrix, its eigenvalues do not change abruptly. But I don't know how to approach it.","Let be defined as where is set of all positive definite matrices. What can we say about the continuity and differentiability of ? Intuitively, I feel that it is continuous because if we perturb a matrix, its eigenvalues do not change abruptly. But I don't know how to approach it.","f:S^n_{+}(\mathbb{R})\rightarrow \mathbb{R}_+ f(A)=\lambda_{\max}(A), S^n_{+}(\mathbb{R}) n\times n f","['real-analysis', 'functional-analysis', 'functions', 'matrix-calculus']"
1,"Finding $\int_{0}^{1} [x-(1-x^k)^{1/k}]^{2n} dx, k>0, n\in N$",Finding,"\int_{0}^{1} [x-(1-x^k)^{1/k}]^{2n} dx, k>0, n\in N","We invoke a very interesting property of definite integrals given in MSE If $f(f(x)) = x$ and $f(0) = 1$ then what is the value of $\int_0^1 (x - f(x)) ^{2n} dx$ if $f(f(x))=x, f(0)=1$ , then $\int_{0}^1 (x-f(x))^{2n}dx=\frac{1}{2n+1}.$ Here, we choose a rare self inverse function: $f:[0,1] \to [0,1], f(x)=(1-x^k)^{1/k},k>0$ to get a very interesting result as $$\int_{0}^{1} [x-(1-x^k)^{1/k}]^{2n} dx=\frac{1}{2n+1}, k>0, n\in N \dots (*)$$ The question is: How else this integral (*) can be obtained?","We invoke a very interesting property of definite integrals given in MSE If $f(f(x)) = x$ and $f(0) = 1$ then what is the value of $\int_0^1 (x - f(x)) ^{2n} dx$ if , then Here, we choose a rare self inverse function: to get a very interesting result as The question is: How else this integral (*) can be obtained?","f(f(x))=x, f(0)=1 \int_{0}^1 (x-f(x))^{2n}dx=\frac{1}{2n+1}. f:[0,1] \to [0,1], f(x)=(1-x^k)^{1/k},k>0 \int_{0}^{1} [x-(1-x^k)^{1/k}]^{2n} dx=\frac{1}{2n+1}, k>0, n\in N \dots (*)","['integration', 'functions', 'definite-integrals']"
2,Why do we use dx when X is not a function?,Why do we use dx when X is not a function?,,"I know what a differential is, to the extent of Riemann sums. But when differentiating a function, say y=f(x), then oftentimes I see dy = f'(x)dx by the chain rule, which makes sense. But X isn't a function, it's the base variable, so how does it's derivative matter? On any case, if X is understood as the axis, wouldn't it's derivative simply be 1?","I know what a differential is, to the extent of Riemann sums. But when differentiating a function, say y=f(x), then oftentimes I see dy = f'(x)dx by the chain rule, which makes sense. But X isn't a function, it's the base variable, so how does it's derivative matter? On any case, if X is understood as the axis, wouldn't it's derivative simply be 1?",,"['calculus', 'functions', 'derivatives', 'differential', 'chain-rule']"
3,linear function composition,linear function composition,,"Find all functions mapping the positive integers to the positive integers such that $f^5(x)=kx$ for a positive integer $k$ . My approach to this problem consisted of trying out functions, as I cannot figure out a methodical way to approach such a problem. An example is when I tried functions such as $f(x)=x\sqrt[5]{k}$ and $f(x)=k/x$ , these do not give positive integers for all values of $x$ .","Find all functions mapping the positive integers to the positive integers such that for a positive integer . My approach to this problem consisted of trying out functions, as I cannot figure out a methodical way to approach such a problem. An example is when I tried functions such as and , these do not give positive integers for all values of .",f^5(x)=kx k f(x)=x\sqrt[5]{k} f(x)=k/x x,"['functions', 'functional-equations']"
4,Alternative proofs of this Inequality,Alternative proofs of this Inequality,,"So I was reading a paper which made the claim ""It is easy to see that $\frac{1-e^{-\alpha}}{\alpha} > 1-\frac{\alpha}{2} > \frac{1}{1+\alpha}$ when $0 < \alpha < 1$ ."" Verifying that $1-\frac{\alpha}{2} > \frac{1}{1+\alpha}$ only involves some simple algebra, but in order to prove that $\frac{1-e^{-\alpha}}{\alpha} > 1-\frac{\alpha}{2}$ I had to use what I have only seen referred to as the ""racetrack theorem\principle"" from elementary calculus twice. Namely, if $f(0) = g(0)$ and $f'(x) \geq g'(x)$ for all $x \geq 0$ , then $f(x) \geq g(x)$ for all $x \geq 0$ . Taking derivatives involving the quotient rule is somewhat of a pain in the ass, so I was wondering if there were any slick ways of proving this inequality? Or maybe I missed a far simpler way of proving this inequality?","So I was reading a paper which made the claim ""It is easy to see that when ."" Verifying that only involves some simple algebra, but in order to prove that I had to use what I have only seen referred to as the ""racetrack theorem\principle"" from elementary calculus twice. Namely, if and for all , then for all . Taking derivatives involving the quotient rule is somewhat of a pain in the ass, so I was wondering if there were any slick ways of proving this inequality? Or maybe I missed a far simpler way of proving this inequality?",\frac{1-e^{-\alpha}}{\alpha} > 1-\frac{\alpha}{2} > \frac{1}{1+\alpha} 0 < \alpha < 1 1-\frac{\alpha}{2} > \frac{1}{1+\alpha} \frac{1-e^{-\alpha}}{\alpha} > 1-\frac{\alpha}{2} f(0) = g(0) f'(x) \geq g'(x) x \geq 0 f(x) \geq g(x) x \geq 0,"['analysis', 'functions', 'inequality', 'exponential-function', 'alternative-proof']"
5,Behaviour of the function satisfying $f(x)+f(\frac{x-1}{x})=x+1$,Behaviour of the function satisfying,f(x)+f(\frac{x-1}{x})=x+1,"Question: Let $f:\mathbb R-\{0,1\}\to \mathbb R$ be a function satisfying $f(x)+f(\frac{x-1}{x})=x+1$ , then both $f$ and $f'$ are not injective. (True or False) I tried forming patterns and deduced that $f(x)=\frac{x^3-x^2-1}{2x(x-1)},x\ne0,1.$ To comment on whether $f,f'$ are injective, we have that $f'(x)=\frac{x^4-2x^3+x^2+2x-1}{2(x-1)^2x^2}$ , need not be strictly increasing unless $x^4-2x^3+x^2+2x-1\geq0,x\in\mathbb R-\{0,1\}$ . Let $h(x)=x^4-2x^3+x^2+2x-1$ , using Descartes' rule of sign $h(x)$ can have atmost $3$ positive real roots and $1$ negative real root. Observe that $h(0)=-1,h(1)=1$ although they are not in the domain but they will help determine in the roots, so this particular $h(x)$ must have atleast $1$ root in $(0,1)$ . Also $h'(x)=4x^3-6x^2+2x+2$ such that $h'(0)=2,h'(1)=2$ here the condition of Rolle's Theorem is applicable on $(0,1)$ as the assumed $h(x)$ is continuous on $[0,1]$ then $\exists c\in(0,1)$ such that $h''(c)=0\implies12c^2-12c+2=0$ . This will give the existence of $2$ real $c\in(0,1)$ . I lost my track after this, since if $f$ vanishes twice in the domain $\implies$ $f'$ vanishes atleast once, but $f'$ will not make us comment anything on the behaviour of $f$ as the converse of Rolle's need not help. Any hint would be appreciated The thing that created the doubt is as: $h'(x)$ is a cubic polynomial so it need not guarantee the existence of $3$ real roots, I used $h''$ to comment on the same and $h'$ has no root in $(0,1)$ but it is not one-one there as ell. I request not to use the graphing calculators to depict the behaviour of this function. I am looking for a simpler way to do this question . Thanks.","Question: Let be a function satisfying , then both and are not injective. (True or False) I tried forming patterns and deduced that To comment on whether are injective, we have that , need not be strictly increasing unless . Let , using Descartes' rule of sign can have atmost positive real roots and negative real root. Observe that although they are not in the domain but they will help determine in the roots, so this particular must have atleast root in . Also such that here the condition of Rolle's Theorem is applicable on as the assumed is continuous on then such that . This will give the existence of real . I lost my track after this, since if vanishes twice in the domain vanishes atleast once, but will not make us comment anything on the behaviour of as the converse of Rolle's need not help. Any hint would be appreciated The thing that created the doubt is as: is a cubic polynomial so it need not guarantee the existence of real roots, I used to comment on the same and has no root in but it is not one-one there as ell. I request not to use the graphing calculators to depict the behaviour of this function. I am looking for a simpler way to do this question . Thanks.","f:\mathbb R-\{0,1\}\to \mathbb R f(x)+f(\frac{x-1}{x})=x+1 f f' f(x)=\frac{x^3-x^2-1}{2x(x-1)},x\ne0,1. f,f' f'(x)=\frac{x^4-2x^3+x^2+2x-1}{2(x-1)^2x^2} x^4-2x^3+x^2+2x-1\geq0,x\in\mathbb R-\{0,1\} h(x)=x^4-2x^3+x^2+2x-1 h(x) 3 1 h(0)=-1,h(1)=1 h(x) 1 (0,1) h'(x)=4x^3-6x^2+2x+2 h'(0)=2,h'(1)=2 (0,1) h(x) [0,1] \exists c\in(0,1) h''(c)=0\implies12c^2-12c+2=0 2 c\in(0,1) f \implies f' f' f h'(x) 3 h'' h' (0,1)","['functions', 'roots']"
6,Find a permutation $X \in S_6$ which satisfies the equation,Find a permutation  which satisfies the equation,X \in S_6,"$\begin{pmatrix}1&2&3&4&5&6\\ 4&3&1&5&2&6\end{pmatrix} \circ X = \begin{pmatrix}1&2&3&4&5&6\\ 3&2&4&5&1&6\end{pmatrix}$ I've tried this solution and checked this website , but none of them were helpful or my problem is little bit different and may require more steps to get the solution. Could anybody help me sort this out?","I've tried this solution and checked this website , but none of them were helpful or my problem is little bit different and may require more steps to get the solution. Could anybody help me sort this out?",\begin{pmatrix}1&2&3&4&5&6\\ 4&3&1&5&2&6\end{pmatrix} \circ X = \begin{pmatrix}1&2&3&4&5&6\\ 3&2&4&5&1&6\end{pmatrix},"['functions', 'permutations', 'permutation-cycles', 'permutation-matrices']"
7,"Function for ""active users"" over time, given a constant ""new users per day"", and an exponential decay of new users who keep the app after ""x"" days","Function for ""active users"" over time, given a constant ""new users per day"", and an exponential decay of new users who keep the app after ""x"" days",,"Forgive me if this is basic, it has been a while since I have used maths like this. Given: $install\ rate= 1\ new\ user\ per\ day$ $retention\ rate = 0.85^x$ The ""retention rate"" is percentage of new users who keep the app after ""x"" days. In my example, about 30% of the users keep the app after 7 days: $0.85^7 = 0.32$ and basically no one keeps using it after 30 days. It decays towards zero because this app isn't used long term. How would I create a function for active users over time, and will this function approach a positive finite limit? How would I calculate this steady-state value? And a follow up question: My ""retention rate"" model isn't very good, I tried to fit my data to an exponential equation, but I only had one parameter to play with and $0.85^x$ is the best I could do. The actual data looks like exponential decay going towards zero, but 30% of users keeps the app after 1 day, 10% after 7 days, 3% after 30 days, and close to 0% after 90 days. I'm guessing I need a polynomial model to fit this data with, but I do not know how to do this. What is an equation that fits this data, and how does the answer to the first question change when using this new model?","Forgive me if this is basic, it has been a while since I have used maths like this. Given: The ""retention rate"" is percentage of new users who keep the app after ""x"" days. In my example, about 30% of the users keep the app after 7 days: and basically no one keeps using it after 30 days. It decays towards zero because this app isn't used long term. How would I create a function for active users over time, and will this function approach a positive finite limit? How would I calculate this steady-state value? And a follow up question: My ""retention rate"" model isn't very good, I tried to fit my data to an exponential equation, but I only had one parameter to play with and is the best I could do. The actual data looks like exponential decay going towards zero, but 30% of users keeps the app after 1 day, 10% after 7 days, 3% after 30 days, and close to 0% after 90 days. I'm guessing I need a polynomial model to fit this data with, but I do not know how to do this. What is an equation that fits this data, and how does the answer to the first question change when using this new model?",install\ rate= 1\ new\ user\ per\ day retention\ rate = 0.85^x 0.85^7 = 0.32 0.85^x,['functions']
8,Analytic continuation of the sum of the reciprocals of the $n$-bonacci sequences.,Analytic continuation of the sum of the reciprocals of the -bonacci sequences.,n,"In a previous question , I asked for an approximation of the sum of the reciprocals of the Tribonacci numbers. So I was wondering if there is a function for the sum of the reciprocals of the $n$ -bonacci numbers. This would look like this: $$\varkappa(n)=\sum_{k=1}^\infty\frac{1}{N_{n_k}}$$ Where $N_n$ gives the $n$ -bonacci sequence ( $n=1$ gives $1, 1, 1, ...$ , $n=2$ gives the fibonacci sequence, $n=3$ gives the tribonacci sequence, and so on). I graphed the first four points in this desmos graph . So what function could connect these points? And additionally, does $\varkappa$ have a lower bound? What is it? (I suspect it is $1.5$ or something near but I couldn't prove this.","In a previous question , I asked for an approximation of the sum of the reciprocals of the Tribonacci numbers. So I was wondering if there is a function for the sum of the reciprocals of the -bonacci numbers. This would look like this: Where gives the -bonacci sequence ( gives , gives the fibonacci sequence, gives the tribonacci sequence, and so on). I graphed the first four points in this desmos graph . So what function could connect these points? And additionally, does have a lower bound? What is it? (I suspect it is or something near but I couldn't prove this.","n \varkappa(n)=\sum_{k=1}^\infty\frac{1}{N_{n_k}} N_n n n=1 1, 1, 1, ... n=2 n=3 \varkappa 1.5","['sequences-and-series', 'functions', 'graphing-functions', 'fibonacci-numbers', 'analytic-continuation']"
9,A Taylor expansion,A Taylor expansion,,I have asked a similar question elsewhere but there has remained a small gap for me: How can I derive this approximate equation via the Taylor expansion: $$\frac{y(x+h)-y(x-h)}{2}-\frac{2h}{12}(y'(x+h)+4y'(x)+y'(x-h))=-\frac{1}{80}h^5y^{(5)}(x)+O(h^7) \ ?$$ Do we have to assume that $$y(x+h)-y(x-h)=2hy'(x)+\frac{1}{3}h^3y^{'''}(x)+\frac{1}{360}h^5y^{(5)}(x)+O(h^7)$$ or does this follow ? I think that it is too trivial to ask but the calculation doesn't follow for me.,I have asked a similar question elsewhere but there has remained a small gap for me: How can I derive this approximate equation via the Taylor expansion: Do we have to assume that or does this follow ? I think that it is too trivial to ask but the calculation doesn't follow for me.,\frac{y(x+h)-y(x-h)}{2}-\frac{2h}{12}(y'(x+h)+4y'(x)+y'(x-h))=-\frac{1}{80}h^5y^{(5)}(x)+O(h^7) \ ? y(x+h)-y(x-h)=2hy'(x)+\frac{1}{3}h^3y^{'''}(x)+\frac{1}{360}h^5y^{(5)}(x)+O(h^7),"['real-analysis', 'functions', 'derivatives', 'taylor-expansion']"
10,Find all the solutions for $f\left(x\right)	=2f\left(\frac{1}{x}\right)-\frac{2x^{2}-1}{x^{2}+1}$,Find all the solutions for,f\left(x\right)	=2f\left(\frac{1}{x}\right)-\frac{2x^{2}-1}{x^{2}+1},"The function is $f:\left(0,\infty\right)\rightarrow\mathbb{R}$ , I tried to do it like that, first I saw that: $$f\left(x\right)	=2f\left(\frac{1}{x}\right)-\frac{2x^{2}-1}{x^{2}+1}$$ and then decided to try to put $\frac{1}{x}\in\left(0,\infty\right) $ and came out with: $$f\left(\frac{1}{x}\right)	=2f\left(x\right)-\frac{2\frac{1}{x^{2}}-1}{\frac{1}{x^{2}}+1} 	=2f\left(x\right)-\frac{\frac{2-x^{2}}{x^{2}}}{\frac{1+x^{2}}{x^{2}}} 	=2f\left(x\right)-\frac{2-x^{2}}{1+x^{2}}$$ i used it at the last equation and it came out that: $$f\left(x\right)=\frac{5-4x^{2}}{3\left(1+x^{2}\right)}$$ now i get $f\left(1\right)=\frac{1}{6}$ but i know it should equal 1/2... I have now idea how to move forward, and why it doesn't work, any tips?","The function is , I tried to do it like that, first I saw that: and then decided to try to put and came out with: i used it at the last equation and it came out that: now i get but i know it should equal 1/2... I have now idea how to move forward, and why it doesn't work, any tips?","f:\left(0,\infty\right)\rightarrow\mathbb{R} f\left(x\right)	=2f\left(\frac{1}{x}\right)-\frac{2x^{2}-1}{x^{2}+1} \frac{1}{x}\in\left(0,\infty\right)  f\left(\frac{1}{x}\right)	=2f\left(x\right)-\frac{2\frac{1}{x^{2}}-1}{\frac{1}{x^{2}}+1}
	=2f\left(x\right)-\frac{\frac{2-x^{2}}{x^{2}}}{\frac{1+x^{2}}{x^{2}}}
	=2f\left(x\right)-\frac{2-x^{2}}{1+x^{2}} f\left(x\right)=\frac{5-4x^{2}}{3\left(1+x^{2}\right)} f\left(1\right)=\frac{1}{6}",['functions']
11,Odd Polynomial approximation of $\frac{1}{x}$ as a polynomial around $0$,Odd Polynomial approximation of  as a polynomial around,\frac{1}{x} 0,"The taylor approximation of $\frac{1}{x}$ does not exist centered at $x = 0$ , as the function is not continuous there. However, there does exist a formula: $$ \frac{1}{1-x} = \sum_{n=0}^\infty x^n\\ \Rightarrow \frac{1}{1 - (1 - x)} = \sum_{n=0}^\infty (1 - x)^n = \frac{1}{x} $$ However, this function is not of a definite parity (i.e.) $f(-x) \neq -f(x)$ and $f(x) \neq f(-x)$ . This is a characteristic of the original function $\frac{1}{x}$ . Is there a polynomial approximation, that maybe looks something like the below sketch? This functions is odd and seems plausible to make. I just cannot find it online. Is there any function like what I drew? Again, I am not looking for a taylor approximation, as it won't exist. But perhaps an ad-hoc solution has been made?","The taylor approximation of does not exist centered at , as the function is not continuous there. However, there does exist a formula: However, this function is not of a definite parity (i.e.) and . This is a characteristic of the original function . Is there a polynomial approximation, that maybe looks something like the below sketch? This functions is odd and seems plausible to make. I just cannot find it online. Is there any function like what I drew? Again, I am not looking for a taylor approximation, as it won't exist. But perhaps an ad-hoc solution has been made?","\frac{1}{x} x = 0 
\frac{1}{1-x} = \sum_{n=0}^\infty x^n\\
\Rightarrow \frac{1}{1 - (1 - x)} = \sum_{n=0}^\infty (1 - x)^n = \frac{1}{x}
 f(-x) \neq -f(x) f(x) \neq f(-x) \frac{1}{x}","['functions', 'polynomials', 'continuity', 'approximation', 'approximation-theory']"
12,Remainder Theorem vs. Factor Theorem,Remainder Theorem vs. Factor Theorem,,"Is it right to say that the remainder theorem and the factor theorem are similar, but not the same processes? For context, this was a question on a homework sheet provided to me by my advanced functions teacher. The question asked for a way other than remainder theorem to determine if a binomial was a factor of a polynomial. I argued that factor theorem was a way, but she said that the two were basically the same and that synthetic division would be the correct answer. My train of thought was: Remainder Theorem - for any polynomial f(x), if you divide it by the binomial x−a, the remainder is equal to the value of f(a). Factor Theorem - if a is a zero of a polynomial f(x), then (x−a) is a factor of f(x) I concluded, with the help of an online resource, that the remainder theorem links the remainder of division by a binomial with the value of a function at a point, while the factor theorem links the factors of a polynomial to its zeros. While they may seem the same, mathematically, they are different, right? That's why they are two distinct theorems and not one. I also thought that if the ""remainder theorem and factor theorem are basically the same"" then the remainder theorem and synthetic division are also the same because you are using the rational zeroes theorem in both cases. Any mathematical or logical help to prove the difference between the remainder theorem and the factor theorem would be greatly appreciated. Thanks","Is it right to say that the remainder theorem and the factor theorem are similar, but not the same processes? For context, this was a question on a homework sheet provided to me by my advanced functions teacher. The question asked for a way other than remainder theorem to determine if a binomial was a factor of a polynomial. I argued that factor theorem was a way, but she said that the two were basically the same and that synthetic division would be the correct answer. My train of thought was: Remainder Theorem - for any polynomial f(x), if you divide it by the binomial x−a, the remainder is equal to the value of f(a). Factor Theorem - if a is a zero of a polynomial f(x), then (x−a) is a factor of f(x) I concluded, with the help of an online resource, that the remainder theorem links the remainder of division by a binomial with the value of a function at a point, while the factor theorem links the factors of a polynomial to its zeros. While they may seem the same, mathematically, they are different, right? That's why they are two distinct theorems and not one. I also thought that if the ""remainder theorem and factor theorem are basically the same"" then the remainder theorem and synthetic division are also the same because you are using the rational zeroes theorem in both cases. Any mathematical or logical help to prove the difference between the remainder theorem and the factor theorem would be greatly appreciated. Thanks",,"['algebra-precalculus', 'functions', 'factoring']"
13,"Solving for $x$ such that $x^2 \log(\alpha/x) \leq \beta$ where $\alpha, \beta >0$.",Solving for  such that  where .,"x x^2 \log(\alpha/x) \leq \beta \alpha, \beta >0","I am trying to solve the following inequality for $x$ . Essentially it suffices even if I can find one value of $x$ which satisfies this: $$x^2 \log\left(\frac{\alpha}{x}\right) \leq \beta,$$ where $\alpha, \beta >0$ . How can I approach it? Some background on where the problem is coming from: Basically, I have the following inequality: $$\beta\left(cH\sqrt{d\log\left(\frac{Hkd}{\beta\delta\delta_1}\right)}+\frac{4}{3}\right) \leq \frac{1}{4}$$ and I need to find a positive value for $\beta$ for which the inequality satisfies. Here $c,H,d, k,\delta, \delta_1$ are positive constants.","I am trying to solve the following inequality for . Essentially it suffices even if I can find one value of which satisfies this: where . How can I approach it? Some background on where the problem is coming from: Basically, I have the following inequality: and I need to find a positive value for for which the inequality satisfies. Here are positive constants.","x x x^2 \log\left(\frac{\alpha}{x}\right) \leq \beta, \alpha, \beta >0 \beta\left(cH\sqrt{d\log\left(\frac{Hkd}{\beta\delta\delta_1}\right)}+\frac{4}{3}\right) \leq \frac{1}{4} \beta c,H,d, k,\delta, \delta_1","['real-analysis', 'functions', 'inequality', 'logarithms']"
14,Determine the parameters so that the function is continuous in R,Determine the parameters so that the function is continuous in R,,I got this problem i've tried to solve but i don't know how to proceed. $$\begin{cases} 3\sin(4x)&&\text{if }x\leq 0 \\ mx+q&&\text{if }x>0 \end{cases}$$ Find the value of $m$ and $q$ so that the function is continuos in R. I've tried this $$\lim_{x\to 0^-} 3\sin(4x) = \lim_{x\to 0^+}mx+q$$ So that the $q$ value equals to $0$ but I don't know.,I got this problem i've tried to solve but i don't know how to proceed. Find the value of and so that the function is continuos in R. I've tried this So that the value equals to but I don't know.,\begin{cases} 3\sin(4x)&&\text{if }x\leq 0 \\ mx+q&&\text{if }x>0 \end{cases} m q \lim_{x\to 0^-} 3\sin(4x) = \lim_{x\to 0^+}mx+q q 0,"['limits', 'analysis', 'functions']"
15,Proving the existence of a left-inverse for every injective function,Proving the existence of a left-inverse for every injective function,,"Trying to prove the theorem that for every injective function there exists a left-inverse of that function, I have conjured up the following proof: Assume that $f$ indeed, is a function, chance, from $A$ to $B$ ; and that $f$ is injective. From this I am trying to prove the existence of a function, chance, $g$ from $B$ to $A$ such that $g\circ f(x) = x$ . The existence of this function could be shown with a constructive proof. We may construct our left-inverse $g$ by defining its mapping such that if $y$ is an element of $B$ , and $y$ belongs to $ranf$ , then $g(y) = f^{-1}(y)$ ; and else, if $y$ does not belong to $ranf$ then $g(y) = a$ where $a$ is some arbitrary value in $A$ . Therefore we have constructively defined the existence of this function $g$ for when $f$ is injective. Notice that that is all I needed for I have no intention in proving the converse (namely that the existence of the left-inverse proves that $f$ is injective). Now I have three concerns pertaining to this proof. The first of which is if this proof is even valid. I ask of this for I am still new to formulating proofs, hence I require affirmation from those more advanced. Second, in constructing this function $g$ , I have defined a part of it using $f^{-1}$ . How is this permissable since I have not proved the existence of $f^{-1}$ in the first place; and so how am I using it to define but another function? Thirdly, is this kind of proof considered as a ""constructive proof"" as I have been calling it so far? Since I assumed we're proving the existence of a mathematical object by providing a construction for it, I have been calling it so. And would you also care to explain why this type of proof is valid (in addition to my first question) since all we have done is provided a way to construct this function $g$ . Does the ability of being able to construct it properly prove its existence ? Thank you in advance","Trying to prove the theorem that for every injective function there exists a left-inverse of that function, I have conjured up the following proof: Assume that indeed, is a function, chance, from to ; and that is injective. From this I am trying to prove the existence of a function, chance, from to such that . The existence of this function could be shown with a constructive proof. We may construct our left-inverse by defining its mapping such that if is an element of , and belongs to , then ; and else, if does not belong to then where is some arbitrary value in . Therefore we have constructively defined the existence of this function for when is injective. Notice that that is all I needed for I have no intention in proving the converse (namely that the existence of the left-inverse proves that is injective). Now I have three concerns pertaining to this proof. The first of which is if this proof is even valid. I ask of this for I am still new to formulating proofs, hence I require affirmation from those more advanced. Second, in constructing this function , I have defined a part of it using . How is this permissable since I have not proved the existence of in the first place; and so how am I using it to define but another function? Thirdly, is this kind of proof considered as a ""constructive proof"" as I have been calling it so far? Since I assumed we're proving the existence of a mathematical object by providing a construction for it, I have been calling it so. And would you also care to explain why this type of proof is valid (in addition to my first question) since all we have done is provided a way to construct this function . Does the ability of being able to construct it properly prove its existence ? Thank you in advance",f A B f g B A g\circ f(x) = x g y B y ranf g(y) = f^{-1}(y) y ranf g(y) = a a A g f f g f^{-1} f^{-1} g,"['functions', 'elementary-set-theory']"
16,What is the formula for winding and unwinding a spool with changing radius due to the strap thickness being wound.,What is the formula for winding and unwinding a spool with changing radius due to the strap thickness being wound.,,"I have a servo motor and I'm trying to come up with a formula that relates the angle of the motor to the length of a strap that is wound on it. Since the radius at <360 degrees is the radius of the motor shaft (r1) and at 360<theta<720 the radius is now r1 + Ct (cable thickness) and after 720 degrees, the new radius r2 = r1 + 2*Ct. Consider the thickness to be uniform. So the circumference is growing every 360 degrees when a new layer of cable is wound. Any ideas? The cable goes only on top of its previous layer, it does not move to the side. The ""spool"" is cylindrical ie. servo motor shaft. I want to treat each layer as a concentric circle, not a spiral. Thanks! rough work of what I've tried","I have a servo motor and I'm trying to come up with a formula that relates the angle of the motor to the length of a strap that is wound on it. Since the radius at <360 degrees is the radius of the motor shaft (r1) and at 360<theta<720 the radius is now r1 + Ct (cable thickness) and after 720 degrees, the new radius r2 = r1 + 2*Ct. Consider the thickness to be uniform. So the circumference is growing every 360 degrees when a new layer of cable is wound. Any ideas? The cable goes only on top of its previous layer, it does not move to the side. The ""spool"" is cylindrical ie. servo motor shaft. I want to treat each layer as a concentric circle, not a spiral. Thanks! rough work of what I've tried",,"['geometry', 'functions', 'mathematical-physics']"
17,"Theorem about fractional iterated functions : is it true, and if yes has it already been discovered?","Theorem about fractional iterated functions : is it true, and if yes has it already been discovered?",,"So, I've been playing with tetration for quite a while now, and I've noticed the method I've been using can possibly be used in any other iteration of a function that satisfy this condition : $f(+\infty)$ converges to a finite value. For clarification, $f^n(x) = f(f(f(...x)))$ n times. So here's the theorem : for any function $f$ where $f^n(x)$ equals the nth iteration of $f(x)$ , where $n$ is a integer, and that the infinite iteration of $f$ equals a finite value $\tau$ , $$f^k(x) = \lim_{n\rightarrow+\infty}(f^{-n}((f^n(x)-\tau)f'(\tau)^k +\tau))$$ for any complex number $k$ if $f'(\tau)$ doesn't equal $1$ or $0$ . I've noticed that in this case, the ratio between $\frac{f^{n+1}(x)-\tau}{f^{n}(x)-\tau}$ ALWAYS approaches $f'(\tau)$ when $n$ approaches $+\infty$ , no matter what. So because we have a ratio, we can then calculate the $(n+k)$ th iteration of the function, and by taking the proper amount of time the inverse function, we can have the nth iteration of the function. If the function approaches $\tau$ from the top or bottom, the ratio is positive, if it ocilates around $\tau$ , it's negative, meaning the kth iteration will often result in complex results. So is this true? (I'm unable to demonstrate it), and if it is, has it already been discovered?","So, I've been playing with tetration for quite a while now, and I've noticed the method I've been using can possibly be used in any other iteration of a function that satisfy this condition : converges to a finite value. For clarification, n times. So here's the theorem : for any function where equals the nth iteration of , where is a integer, and that the infinite iteration of equals a finite value , for any complex number if doesn't equal or . I've noticed that in this case, the ratio between ALWAYS approaches when approaches , no matter what. So because we have a ratio, we can then calculate the th iteration of the function, and by taking the proper amount of time the inverse function, we can have the nth iteration of the function. If the function approaches from the top or bottom, the ratio is positive, if it ocilates around , it's negative, meaning the kth iteration will often result in complex results. So is this true? (I'm unable to demonstrate it), and if it is, has it already been discovered?",f(+\infty) f^n(x) = f(f(f(...x))) f f^n(x) f(x) n f \tau f^k(x) = \lim_{n\rightarrow+\infty}(f^{-n}((f^n(x)-\tau)f'(\tau)^k +\tau)) k f'(\tau) 1 0 \frac{f^{n+1}(x)-\tau}{f^{n}(x)-\tau} f'(\tau) n +\infty (n+k) \tau \tau,"['limits', 'functions']"
18,Examples of functions with linearity that are not polynomials or derivatives?,Examples of functions with linearity that are not polynomials or derivatives?,,"Derivatives, integral and limits have this linearity feature right? Where $f(x+y) = f(x) + f(y)$ (I’m not sure if ‘linearity’ is the proper term). Can someone give examples of more types of functions with this feature? Because the only ones I could think of were linear polynomials or something like sums. Thank you!","Derivatives, integral and limits have this linearity feature right? Where (I’m not sure if ‘linearity’ is the proper term). Can someone give examples of more types of functions with this feature? Because the only ones I could think of were linear polynomials or something like sums. Thank you!",f(x+y) = f(x) + f(y),"['real-analysis', 'calculus', 'linear-algebra', 'functions', 'functional-equations']"
19,Are derivatives defined on functions or variables?,Are derivatives defined on functions or variables?,,"My question is, is differentiation done on functions or on variables/values? For example take $z=f(x,y)$ , in this case we can 'fix' one of the variables to the value $y_0$ , the question then becomes, is the derivative of $z_0=f_y(x,y)$ defined here? $y$ is now constant, however if our derivative is defined on $f$ the partial derivative should exist. Does it make sense to talk about the rate that $f(x,y_0)$ is changing? can we for example write $\frac{dz_0}{dx}$ ? or $\frac{d(f(x,y0))}{dx}$ ? to talk about the rate the value $f(x,y_0)$ changes? Or can we only discuss the function 's partial derivatives $f_x'(x,y_0)$ and $f_y'(x,y_0)$ ? Another thing is that if we apply $f$ to two arguments who depend on each other, we provide the total derivative, which is actually different depending on their relation, if the function is defined independently how can this be the total derivative of a function? If we take $\frac{df(x^2)}{dx}$ , it seems we take the 'derivative' of the value $f(x^2)$ , but perhaps this notation can be seen as the 'derivative of the function whose value is $f(x^2)$ ', but seems a bit strange. Do we take the derivative of a 'value' or variable or is it better to keep Euler 'notation'.","My question is, is differentiation done on functions or on variables/values? For example take , in this case we can 'fix' one of the variables to the value , the question then becomes, is the derivative of defined here? is now constant, however if our derivative is defined on the partial derivative should exist. Does it make sense to talk about the rate that is changing? can we for example write ? or ? to talk about the rate the value changes? Or can we only discuss the function 's partial derivatives and ? Another thing is that if we apply to two arguments who depend on each other, we provide the total derivative, which is actually different depending on their relation, if the function is defined independently how can this be the total derivative of a function? If we take , it seems we take the 'derivative' of the value , but perhaps this notation can be seen as the 'derivative of the function whose value is ', but seems a bit strange. Do we take the derivative of a 'value' or variable or is it better to keep Euler 'notation'.","z=f(x,y) y_0 z_0=f_y(x,y) y f f(x,y_0) \frac{dz_0}{dx} \frac{d(f(x,y0))}{dx} f(x,y_0) f_x'(x,y_0) f_y'(x,y_0) f \frac{df(x^2)}{dx} f(x^2) f(x^2)","['calculus', 'functions', 'derivatives', 'partial-derivative']"
20,Cardinality of Image of Injection equals Cardinality of its Domain?,Cardinality of Image of Injection equals Cardinality of its Domain?,,"Preliminaries: (1) I know that a mapping is bijective if and only if it is injective and surjective. (2) I also know that a mapping $f:X\rightarrow Y$ is surjective if and only if $f(X)=Y$ , where $f(X)$ denotes the image of $X$ under $f$ . (3) I've defined two sets $X$ and $Y$ to be equinumerous, written $X\sim Y$ , iff there is a bijective mapping $f:X\rightarrow Y$ . Question: In my notes I have the following statement (I can't remember where it's coming from, it's been a while...). Let $A$ and $B$ be sets. A Mapping $f:A\rightarrow B$ is injective if and only if for all subsets $X\subseteq A$ we have $X\sim f(X)$ , i.e., if for all $X\subseteq A$ there is a bijective map $g:X\rightarrow f(X)$ , where $f(X)$ denotes the image of $X$ under $f$ . I've tried to come up with a proof for this statement but so far I didn't really succeed and so I've started to wonder if that theorem is actually true or not. I think I can proof the implication "" $f$ is injective $\Longrightarrow$ $X\sim f(X)$ "", though. Proof $(\Longrightarrow)$ Let $f:A\rightarrow B$ be injective. Then because of (2) $\tilde{f}:X\rightarrow f(X)$ is surjective and therefore, because of (1), bijective. Then, from definition (3), it follows that $X\sim f(X)$ . I'm not quite sure about the first step in my proof though. When $f$ is injective, why is a map $\tilde{f}$ injective too? Furthermore, what about the $(\Leftarrow)$ direction of the proof? Anyone got an idea or should I rewrite the Theorem and make it an implication instead of an equivalence?","Preliminaries: (1) I know that a mapping is bijective if and only if it is injective and surjective. (2) I also know that a mapping is surjective if and only if , where denotes the image of under . (3) I've defined two sets and to be equinumerous, written , iff there is a bijective mapping . Question: In my notes I have the following statement (I can't remember where it's coming from, it's been a while...). Let and be sets. A Mapping is injective if and only if for all subsets we have , i.e., if for all there is a bijective map , where denotes the image of under . I've tried to come up with a proof for this statement but so far I didn't really succeed and so I've started to wonder if that theorem is actually true or not. I think I can proof the implication "" is injective "", though. Proof Let be injective. Then because of (2) is surjective and therefore, because of (1), bijective. Then, from definition (3), it follows that . I'm not quite sure about the first step in my proof though. When is injective, why is a map injective too? Furthermore, what about the direction of the proof? Anyone got an idea or should I rewrite the Theorem and make it an implication instead of an equivalence?",f:X\rightarrow Y f(X)=Y f(X) X f X Y X\sim Y f:X\rightarrow Y A B f:A\rightarrow B X\subseteq A X\sim f(X) X\subseteq A g:X\rightarrow f(X) f(X) X f f \Longrightarrow X\sim f(X) (\Longrightarrow) f:A\rightarrow B \tilde{f}:X\rightarrow f(X) X\sim f(X) f \tilde{f} (\Leftarrow),"['functions', 'cardinals']"
21,Question about solution of wave equation in traveling wave.,Question about solution of wave equation in traveling wave.,,"I have a question about pg.10 from Stein and Shakarchi's fourier analysis. We must now connect this result with our original problem, that is, the physical motion of a string. There, we imposed the restrictions $0 \leq x \leq \pi$ , the initial shape of the string $u(x, 0) = f (x)$ , and also the fact that the string has fixed end points, namely $u(0, t) = u(\pi, t) = 0$ for all $t$ . To use the simple observation above, we first extend $f$ to all of $\mathbb{R}$ by making it odd on $[−\pi,\pi]$ , and then periodic in $x$ of period $2\pi$ , and similarly for $u(x, t)$ , the solution of our problem. Then the extension $u$ solves the wave equation on all of $\mathbb{R}$ , and $u(x, 0) = f(x)$ for all $x \in \mathbb{R}$ . Therefore, $u(x, t) = F (x + t) + G(x − t)$ , and setting $t = 0$ we find that $$F(x) + G(x) = f(x).$$ Since many choices of $F$ and $G$ will satisfy this identity, this suggests imposing another initial condition on $u$ (similar to the two initial conditions in the case of simple harmonic motion), namely the initial velocity of the string which we denote by $g(x)$ : $$\frac{\partial u}{\partial t}(x,0) = g(x),$$ where of course $g(0) = g(\pi) = 0$ . Again, we extend $g$ to $\mathbb{R}$ first by making it odd over $[−\pi,\pi]$ , and then periodic of period $2\pi$ . The two initial conditions of position and velocity now translate into the following system: $$F(x) + G(x) = f(x), \quad F'(x) − G'(x) = g(x).$$ It seemed okay to me when it first assumed $f(x)$ to be odd (although I'm not sure why this is allowed), when it assumed the velocity $g(x)$ to be also odd, I don't understand why this can be assumed. Just by assuming $f(x,t)=\sin(x+t)$ it tells me $g(x,t)$ has to be even. Can I get more explanation on why these assumptions are valid? Thank you.","I have a question about pg.10 from Stein and Shakarchi's fourier analysis. We must now connect this result with our original problem, that is, the physical motion of a string. There, we imposed the restrictions , the initial shape of the string , and also the fact that the string has fixed end points, namely for all . To use the simple observation above, we first extend to all of by making it odd on , and then periodic in of period , and similarly for , the solution of our problem. Then the extension solves the wave equation on all of , and for all . Therefore, , and setting we find that Since many choices of and will satisfy this identity, this suggests imposing another initial condition on (similar to the two initial conditions in the case of simple harmonic motion), namely the initial velocity of the string which we denote by : where of course . Again, we extend to first by making it odd over , and then periodic of period . The two initial conditions of position and velocity now translate into the following system: It seemed okay to me when it first assumed to be odd (although I'm not sure why this is allowed), when it assumed the velocity to be also odd, I don't understand why this can be assumed. Just by assuming it tells me has to be even. Can I get more explanation on why these assumptions are valid? Thank you.","0 \leq x \leq \pi u(x, 0) = f (x) u(0, t) = u(\pi, t) = 0 t f \mathbb{R} [−\pi,\pi] x 2\pi u(x, t) u \mathbb{R} u(x, 0) = f(x) x \in \mathbb{R} u(x, t) = F (x + t) + G(x − t) t = 0 F(x) + G(x) = f(x). F G u g(x) \frac{\partial u}{\partial t}(x,0) = g(x), g(0) = g(\pi) = 0 g \mathbb{R} [−\pi,\pi] 2\pi F(x) + G(x) = f(x), \quad F'(x) − G'(x) = g(x). f(x) g(x) f(x,t)=\sin(x+t) g(x,t)","['functions', 'partial-differential-equations', 'fourier-analysis', 'functional-equations', 'wave-equation']"
22,Approximation to transcendental function by polynomial,Approximation to transcendental function by polynomial,,"UPDATE: It is well known that for any irrational number $\alpha$ , given a $\epsilon > 0$ , the inequation : $$|\alpha -\frac{p}{q}|< \frac{1}{q^{2+\epsilon}}$$ , if $\alpha$ is algebraic, the inequation has finite solutions, if the inequation has infinite solutions, $\alpha$ is transcendental. This is what called Roth's Theorem. Given an irrational  function, and suppose it is approximated by polynomials, is there any theorem like the Roth's Theorem?","UPDATE: It is well known that for any irrational number , given a , the inequation : , if is algebraic, the inequation has finite solutions, if the inequation has infinite solutions, is transcendental. This is what called Roth's Theorem. Given an irrational  function, and suppose it is approximated by polynomials, is there any theorem like the Roth's Theorem?",\alpha \epsilon > 0 |\alpha -\frac{p}{q}|< \frac{1}{q^{2+\epsilon}} \alpha \alpha,"['functions', 'approximation']"
23,Multiple Graph Transformations,Multiple Graph Transformations,,"$y = x^n $ is transformed to $0.5(3x+2)^n - 1$ . Describe the transformations. Not too sure on this one, but I factorised $3x+2$ to $3(x+2/3)$ , giving me a translation $-2/3$ to the left followed by a stretch scale factor $1/3$ parallel to x-axis. After that, it would be stretch scale factor $1/2$ parallel to y-axis followed by a translation 1 unit down. This definitely doesn't seem right though. My only other thought would be to find the inverse of $3x+2$ which is $(x-2)/3$ . Cheers guys","is transformed to . Describe the transformations. Not too sure on this one, but I factorised to , giving me a translation to the left followed by a stretch scale factor parallel to x-axis. After that, it would be stretch scale factor parallel to y-axis followed by a translation 1 unit down. This definitely doesn't seem right though. My only other thought would be to find the inverse of which is . Cheers guys",y = x^n  0.5(3x+2)^n - 1 3x+2 3(x+2/3) -2/3 1/3 1/2 3x+2 (x-2)/3,"['functions', 'solution-verification']"
24,Smallest algebra containing a function,Smallest algebra containing a function,,"The question Let $f: X \to \Bbb C$ , then what is the smallest algebra $\mathcal{A}$ containing $f$ ? My attempt I claim that: $$\mathcal{A} = \{\sum \limits_{i=1}^{n} a_i f^i : [n \in \Bbb N, a_i \in \Bbb C]\}$$ In fact, it is clear that the set thus defined is an algebra (closure under addition and multiplication by a scalar can be proved directly while closure under multiplication may be proved considering two sums of degrees $m$ and $n$ and by proceeding by induction on $n$ , after having fixed $m$ ). Moreover, every function in $\mathcal{A}$ can be constructed using only $f$ , therefore every algebra containing $f$ must also include $\mathcal{A}$ . I would like to know if this answer is correct and satisfactory. As always, any comment or answer is welcome and let me know if I can explain myself clearer!","The question Let , then what is the smallest algebra containing ? My attempt I claim that: In fact, it is clear that the set thus defined is an algebra (closure under addition and multiplication by a scalar can be proved directly while closure under multiplication may be proved considering two sums of degrees and and by proceeding by induction on , after having fixed ). Moreover, every function in can be constructed using only , therefore every algebra containing must also include . I would like to know if this answer is correct and satisfactory. As always, any comment or answer is welcome and let me know if I can explain myself clearer!","f: X \to \Bbb C \mathcal{A} f \mathcal{A} = \{\sum \limits_{i=1}^{n} a_i f^i : [n \in \Bbb N, a_i \in \Bbb C]\} m n n m \mathcal{A} f f \mathcal{A}","['real-analysis', 'functions', 'solution-verification']"
25,Proof that there is no injection from $\mathcal{P}(A)$ to $A$ [duplicate],Proof that there is no injection from  to  [duplicate],\mathcal{P}(A) A,"This question already has answers here : There exists an injection from $X$ to $Y$ if and only if there exists a surjection from $Y$ to $X$. (3 answers) Closed 1 year ago . I am trying to follow the proof from Munkres that for any set $A$ , there is no injection from $\mathcal{P}(A)$ to $A$ . Munkres's approach is to note that for any nonempty set $B$ , the result is equivalent to the statement that there is no surjection from $B$ to $\mathcal{P}(B)$ . I am very comfortable with the proof of Cantor's theorem, so I'm trying to prove only two things: (a) this result still holds when $A = \emptyset$ and (b) that for $A \neq \emptyset$ , the result is implied by the lack of a surjection from $A$ to $\mathcal{P}(A)$ . Here are my attempts. I am a bit puzzled by (a). If $A = \emptyset$ , then $\mathcal{P}(A) = \{\emptyset\}$ . There is no function from $\mathcal{P}(A)$ to $A$ in that case and therefore no injection. Is it as simple as that? Munkres doesn't treat this case. I'm assuming because it is considered ""trivial"" and an edge case. As for (b): I'll try to prove the exact statement Munkres quoted. The statement is: Suppose $B \neq \emptyset$ and there exists no surjection from $B$ to $C$ . Then there exists no injection from $C$ to $B$ . I think the standard proof is by contraposition, or at least that's my intuition. So let's suppose there exists an injection $f: C \to B$ . It follows that $f$ admits a left inverse $g: B \to C$ so that $g \circ f = \mathrm{id}_C$ . But then $g$ admits a right inverse, $f$ , so $g$ is surjective. By contraposition, if there is no such surjection $g$ , then there is no injection $f$ . I'm taking for granted the fact that a function admits a left inverse if and only if it is injective and a right inverse if and only if it is surjective. How do these proofs look?","This question already has answers here : There exists an injection from $X$ to $Y$ if and only if there exists a surjection from $Y$ to $X$. (3 answers) Closed 1 year ago . I am trying to follow the proof from Munkres that for any set , there is no injection from to . Munkres's approach is to note that for any nonempty set , the result is equivalent to the statement that there is no surjection from to . I am very comfortable with the proof of Cantor's theorem, so I'm trying to prove only two things: (a) this result still holds when and (b) that for , the result is implied by the lack of a surjection from to . Here are my attempts. I am a bit puzzled by (a). If , then . There is no function from to in that case and therefore no injection. Is it as simple as that? Munkres doesn't treat this case. I'm assuming because it is considered ""trivial"" and an edge case. As for (b): I'll try to prove the exact statement Munkres quoted. The statement is: Suppose and there exists no surjection from to . Then there exists no injection from to . I think the standard proof is by contraposition, or at least that's my intuition. So let's suppose there exists an injection . It follows that admits a left inverse so that . But then admits a right inverse, , so is surjective. By contraposition, if there is no such surjection , then there is no injection . I'm taking for granted the fact that a function admits a left inverse if and only if it is injective and a right inverse if and only if it is surjective. How do these proofs look?",A \mathcal{P}(A) A B B \mathcal{P}(B) A = \emptyset A \neq \emptyset A \mathcal{P}(A) A = \emptyset \mathcal{P}(A) = \{\emptyset\} \mathcal{P}(A) A B \neq \emptyset B C C B f: C \to B f g: B \to C g \circ f = \mathrm{id}_C g f g g f,"['functions', 'solution-verification']"
26,Finding all functions satisfying $f(x f(x+y))+f(f(y) f(x+y))=(x+y)^{2}$,Finding all functions satisfying,f(x f(x+y))+f(f(y) f(x+y))=(x+y)^{2},"Determine all functions $f:\mathbb{R} \to \mathbb{R}$ such that $$f(x f(x+y))+f(f(y) f(x+y))=(x+y)^{2}, \forall x,y \in \mathbb{R} \tag1)$$ My approach: Let $x=0$ , we get $$f(0)+f\left((f(y))^2\right)=y^2$$ $\Rightarrow$ $$f\left((f(y))^2\right)=y^2-f(0)\tag2 $$ Let us assume $f(0)=k \ne 0$ Put $y=0$ above, we get $$f(k^2)=-k$$ Also put $y=-x$ in $(1)$ , we get $$f(kf(x))+f(kf(-x))=0, \forall x \in \mathbb{R}$$ Put $x=0$ above we get $$f(k^2)=0$$ $\Rightarrow$ $f(k^2)$ has two different images $0,-k$ which contradicts that $f$ is a function. Hence $k=0 \Rightarrow f(0)=0$ . So from $(2)$ we get: $$f\left((f(y))^2\right)=y^2 \cdots (3)$$ Now put $y=0, x=f(x)$ in $(1)$ , and use the fact $f(0)=0$ ,we get $$f\left((f(x))^2\right)=(f(x))^2$$ Since $x$ is dummy variable, we get $$f\left((f(y))^2\right)=(f(y))^2 \cdots (4)$$ From $(3),(4)$ , we get $$f(x)=\pm x$$ I just want to ask, is my approach fine? If not where is the flaw? Also other approaches are welcomed.","Determine all functions such that My approach: Let , we get Let us assume Put above, we get Also put in , we get Put above we get has two different images which contradicts that is a function. Hence . So from we get: Now put in , and use the fact ,we get Since is dummy variable, we get From , we get I just want to ask, is my approach fine? If not where is the flaw? Also other approaches are welcomed.","f:\mathbb{R} \to \mathbb{R} f(x f(x+y))+f(f(y) f(x+y))=(x+y)^{2}, \forall x,y \in \mathbb{R} \tag1) x=0 f(0)+f\left((f(y))^2\right)=y^2 \Rightarrow f\left((f(y))^2\right)=y^2-f(0)\tag2  f(0)=k \ne 0 y=0 f(k^2)=-k y=-x (1) f(kf(x))+f(kf(-x))=0, \forall x \in \mathbb{R} x=0 f(k^2)=0 \Rightarrow f(k^2) 0,-k f k=0 \Rightarrow f(0)=0 (2) f\left((f(y))^2\right)=y^2 \cdots (3) y=0, x=f(x) (1) f(0)=0 f\left((f(x))^2\right)=(f(x))^2 x f\left((f(y))^2\right)=(f(y))^2 \cdots (4) (3),(4) f(x)=\pm x","['functions', 'contest-math', 'functional-equations']"
27,Finding the number of intersections of a function and $y = x$,Finding the number of intersections of a function and,y = x,"Let $f(x)$ be a real valued function defined for all real numbers $x$ such that $|f(x) -f(y)| \leq \frac{1}{2} |x-y|$ for all x,y. Then the number of points of intersection of the graph of $y = f(x)$ and the line $y = x$ is A) $0$ $\boxed{B)1}$ C) $2$ D)none of the foregoing numbers. My Method: Consider $x = y + h$ , We have: $|f(y+h) - f(y)| \leq \frac{1}{2} |h|$ $\implies \frac{|f(y+h) - f(y)|}{|h|} \leq \frac{1}{2}$ $\implies \lim_{h \rightarrow 0} \frac{|f(y+h) - f(y)|}{|h|} \leq \frac{1}{2}  \hspace{2cm}     \ldots (1)$ $\implies |f'(y)| \leq \frac{1}{2}$ $\implies \frac{-1}{2} \leq f'(y) \leq \frac{1}{2}$ $\implies \frac{-y}{2} \leq f(y) \leq \frac{y}{2}  \hspace{2cm} \ldots (2)$ Thus we have, $ f(x) \in [\frac{-x}{2} , \frac{x}{2}]$ for $x \in \mathbb{R}$ , The graph of $f(x)$ must lie within the shaded portion and thus we have no solutions for $x>0$ but from the bounds it is clear that $f(0) = 0$ and we have one intersection at $(0,0)$ . The shaded portion is $ \frac{-x}{2} \leq y \leq \frac{x}{2}$ and the green line is $y = x$ , Which gives us a total of $1$ intersection. But would limit in $(1)$ necessarily exist and can $(2)$ be directly written from the previous step. Would be glad if the community could come up with any alternative approaches (using elementary methods).","Let be a real valued function defined for all real numbers such that for all x,y. Then the number of points of intersection of the graph of and the line is A) C) D)none of the foregoing numbers. My Method: Consider , We have: Thus we have, for , The graph of must lie within the shaded portion and thus we have no solutions for but from the bounds it is clear that and we have one intersection at . The shaded portion is and the green line is , Which gives us a total of intersection. But would limit in necessarily exist and can be directly written from the previous step. Would be glad if the community could come up with any alternative approaches (using elementary methods).","f(x) x |f(x) -f(y)| \leq \frac{1}{2} |x-y| y = f(x) y = x 0 \boxed{B)1} 2 x = y + h |f(y+h) - f(y)| \leq \frac{1}{2} |h| \implies \frac{|f(y+h) - f(y)|}{|h|} \leq \frac{1}{2} \implies \lim_{h \rightarrow 0} \frac{|f(y+h) - f(y)|}{|h|} \leq \frac{1}{2}  \hspace{2cm}     \ldots (1) \implies |f'(y)| \leq \frac{1}{2} \implies \frac{-1}{2} \leq f'(y) \leq \frac{1}{2} \implies \frac{-y}{2} \leq f(y) \leq \frac{y}{2}  \hspace{2cm} \ldots (2)  f(x) \in [\frac{-x}{2} , \frac{x}{2}] x \in \mathbb{R} f(x) x>0 f(0) = 0 (0,0)  \frac{-x}{2} \leq y \leq \frac{x}{2} y = x 1 (1) (2)","['calculus', 'functions', 'solution-verification']"
28,Comparing the growth of two functions,Comparing the growth of two functions,,This is my almost final result for comparing two functions. $$\lim\limits_{x\to \infty} =\frac{f(x)}{g(x)}=\frac{4x}{2x}=2$$ From here can we say which one of these functions grows faster?,This is my almost final result for comparing two functions. From here can we say which one of these functions grows faster?,\lim\limits_{x\to \infty} =\frac{f(x)}{g(x)}=\frac{4x}{2x}=2,"['limits', 'functions']"
29,"If we know the graph of $f(x)$ and of $g(x)$, is there a way to graph their composition $f(g(x))$?","If we know the graph of  and of , is there a way to graph their composition ?",f(x) g(x) f(g(x)),"My question is that if we know the graph of $f(x)$ and of $g(x)$ , s there a way to graph $f(g(x))$ Example: $\sin (\ln (x))$ How do we reach this graph? How does this graph relate to its parent functions?","My question is that if we know the graph of and of , s there a way to graph Example: How do we reach this graph? How does this graph relate to its parent functions?",f(x) g(x) f(g(x)) \sin (\ln (x)),"['functions', 'graphing-functions', 'function-and-relation-composition']"
30,Find all values of $m$ such that the equation $3^{x^2 + 2mx + 4m - 3} - 2 = \left|\dfrac{m - 2}{x + m}\right|$ has two distinct roots on $[-4; 0]$.,Find all values of  such that the equation  has two distinct roots on .,m 3^{x^2 + 2mx + 4m - 3} - 2 = \left|\dfrac{m - 2}{x + m}\right| [-4; 0],"Consider the equation $3^{x^2 + 2mx + 4m - 3} - 2 = \left|\dfrac{m - 2}{x + m}\right|$ . All values of $m$ such that the above equation has two distinct roots on $[-4; 0]$ are $$\begin{aligned} &&A. \, m \in [1; 3] &&B. \, m \in (1; 3)\\ &&C. \, m \in [1; 3] \setminus \{2\} &&D. \, m \in (-\infty; 1] \cup [3; +\infty) \end{aligned}$$ [For context, this question is taken from an exam whose format consists of 50 multiple-choice questions with a time limit of 90 minutes. Calculators are the only electronic device allowed in the testing room. (You know those scientific calculators sold at stationery stores and sometimes bookstores? They are the goods.) I need a solution that works within these constraints. Thanks for your cooperation, as always. (Do I need to sound this professional?) By the way, if the wording of the problem sounds rough, sorry for that. I'm not an expert at translating documents.] Let's do this question by process of elimination first. For $m = 2$ , the equation becomes $$3^{x^2 + 4x + 5} - 2 = 0 \implies x^2 + 4x + (5 - \log_32) = 0$$ And since the simplified discriminant (that's what it's called here) is $\Delta = 2^2 - (5 - \log_32) = \log_32 - 1 < 0$ , the above equation doesn't have any roots for $m = 2$ , which means we can eliminate choices $A$ and $B$ . Next up, for $m = 0$ , the equation becomes $$\begin{aligned} 3^{x^2 - 3} - 2 = \left|\dfrac{-2}{x}\right| &\iff \dfrac{3^{x^2}}{27} = 2 \times \left(1 + \dfrac{1}{|x|}\right) \iff \dfrac{3^{x^2}}{54} = \dfrac{|x| + 1}{|x|}\\ &\iff 3^{x^2}|x| = 54(|x| + 1) \iff (3^{x^2} - 54)|x| - 54 = 0 \end{aligned}$$ Consider function $f(x) = (3^{x^2} - 54)|x| - 54, x \in [-4; 0]$ . Using the TABLE function of my calculator, (isn't technology amazing?) we have this table below, (who could have guessed?) It seems that there's only one root on $[-4; 0]$ , which is $x = -2$ . Therefore, $m = 0$ is not one of the viable values. It can be concluded that the correct answer is $C. m \in [1; 3] \setminus \{2\}$ . ""You already found the correct answer. What're you asking then?"" You might think. Well, of course, I want to know how to actually solve this problem, still within the time limit required. Do I actually know what to do first? Uhhh, hmmm~ I wish... Anyhow, thanks for reading, (and even more so if you could help), have a great tomorrow, everyone~","Consider the equation . All values of such that the above equation has two distinct roots on are [For context, this question is taken from an exam whose format consists of 50 multiple-choice questions with a time limit of 90 minutes. Calculators are the only electronic device allowed in the testing room. (You know those scientific calculators sold at stationery stores and sometimes bookstores? They are the goods.) I need a solution that works within these constraints. Thanks for your cooperation, as always. (Do I need to sound this professional?) By the way, if the wording of the problem sounds rough, sorry for that. I'm not an expert at translating documents.] Let's do this question by process of elimination first. For , the equation becomes And since the simplified discriminant (that's what it's called here) is , the above equation doesn't have any roots for , which means we can eliminate choices and . Next up, for , the equation becomes Consider function . Using the TABLE function of my calculator, (isn't technology amazing?) we have this table below, (who could have guessed?) It seems that there's only one root on , which is . Therefore, is not one of the viable values. It can be concluded that the correct answer is . ""You already found the correct answer. What're you asking then?"" You might think. Well, of course, I want to know how to actually solve this problem, still within the time limit required. Do I actually know what to do first? Uhhh, hmmm~ I wish... Anyhow, thanks for reading, (and even more so if you could help), have a great tomorrow, everyone~","3^{x^2 + 2mx + 4m - 3} - 2 = \left|\dfrac{m - 2}{x + m}\right| m [-4; 0] \begin{aligned} &&A. \, m \in [1; 3] &&B. \, m \in (1; 3)\\ &&C. \, m \in [1; 3] \setminus \{2\} &&D. \, m \in (-\infty; 1] \cup [3; +\infty) \end{aligned} m = 2 3^{x^2 + 4x + 5} - 2 = 0 \implies x^2 + 4x + (5 - \log_32) = 0 \Delta = 2^2 - (5 - \log_32) = \log_32 - 1 < 0 m = 2 A B m = 0 \begin{aligned} 3^{x^2 - 3} - 2 = \left|\dfrac{-2}{x}\right| &\iff \dfrac{3^{x^2}}{27} = 2 \times \left(1 + \dfrac{1}{|x|}\right) \iff \dfrac{3^{x^2}}{54} = \dfrac{|x| + 1}{|x|}\\ &\iff 3^{x^2}|x| = 54(|x| + 1) \iff (3^{x^2} - 54)|x| - 54 = 0 \end{aligned} f(x) = (3^{x^2} - 54)|x| - 54, x \in [-4; 0] [-4; 0] x = -2 m = 0 C. m \in [1; 3] \setminus \{2\}","['functions', 'exponential-function', 'exponentiation']"
31,"Number of critical points of $f(x)=(x+\ln x)^x$ on $[1,\infty)$",Number of critical points of  on,"f(x)=(x+\ln x)^x [1,\infty)","How many critical points does the function $f(x)=(x+\ln x)^x$ has on $[1,\infty)$ ? Here Since $x$ and $\ln x$ and $a^x$ (for $a>0$ ) are strictly increasing, we can conclude that $f(x)$ is strictly increasing on $[1,\infty)$ and I thought it is enough to conclude $f'(x)=0$ has no solution but as a counterexample $g(x)=x^3$ is also strictly increasing but $g'(0)=0$ . But I'm wondering is it possible to prove it has no critical point without calculating derivative? By the way derivative is $f'(x)=(x+\ln x)^x\times (\ln(x+\ln x)+\frac{x+1}{x+\ln x})$ and it is not hard to recognize it has no critical points from it.","How many critical points does the function has on ? Here Since and and (for ) are strictly increasing, we can conclude that is strictly increasing on and I thought it is enough to conclude has no solution but as a counterexample is also strictly increasing but . But I'm wondering is it possible to prove it has no critical point without calculating derivative? By the way derivative is and it is not hard to recognize it has no critical points from it.","f(x)=(x+\ln x)^x [1,\infty) x \ln x a^x a>0 f(x) [1,\infty) f'(x)=0 g(x)=x^3 g'(0)=0 f'(x)=(x+\ln x)^x\times (\ln(x+\ln x)+\frac{x+1}{x+\ln x})","['calculus', 'functions', 'derivatives']"
32,Proving the function $f(x) = x^2 + ax + b$ is not injective. Does my proof make sense?,Proving the function  is not injective. Does my proof make sense?,f(x) = x^2 + ax + b,"The question I’ve been working on is: Let $f:\mathbb{R} \rightarrow \mathbb{R}$ be the function defined by $f(x)=x^2+ax+b$ , where $a,b\in\mathbb{R}$ . Prove that $f$ is not injective. Here's what I've come up with. I'm hoping someone can tell me if I messed up somewhere. (I'm not sure whether the last part is clear enough, or whether makes sense or not). Also this isn't for a homework assignment--this is just for me. $\text{Let } m,n\in\mathbb{R} \text{ such that } f(m) = f(n).$ We consider two cases: Case 1: $a=0.$ Then, substituting, we have $$ m^2 +b=n^2+b\\m^2=n^2\\\text{either }m=n \text{ or }m=-n$$ Therefore, we can have $f(n)=f(-n) \text{ but } n\neq -n$ . Therefore, $f$ is not injective. Case 2: $a\neq0.$ Then, we have $$m^2+am+b=n^2+an+b\\m^2+am=n^2+an\\ m^2-n^2=a(n-m)\\(m+n)(m-n)=a(n-m)\\(1/a)(m+n)(m-n)=(n-m)\\-(1/a)(m+n)(m-n)=(m-n)$$ This means that either $m=n$ , or, $-(1/a)(m+n)=1$ . We will consider the latter equation. Or, in other words, $a=-(m+n)$ . Consequently, $n=-m-a$ . Therefore it is possible for $m\neq n$ . Thus, $f$ is not injective.","The question I’ve been working on is: Let be the function defined by , where . Prove that is not injective. Here's what I've come up with. I'm hoping someone can tell me if I messed up somewhere. (I'm not sure whether the last part is clear enough, or whether makes sense or not). Also this isn't for a homework assignment--this is just for me. We consider two cases: Case 1: Then, substituting, we have Therefore, we can have . Therefore, is not injective. Case 2: Then, we have This means that either , or, . We will consider the latter equation. Or, in other words, . Consequently, . Therefore it is possible for . Thus, is not injective.","f:\mathbb{R} \rightarrow \mathbb{R} f(x)=x^2+ax+b a,b\in\mathbb{R} f \text{Let } m,n\in\mathbb{R} \text{ such that } f(m) = f(n). a=0.  m^2 +b=n^2+b\\m^2=n^2\\\text{either }m=n \text{ or }m=-n f(n)=f(-n) \text{ but } n\neq -n f a\neq0. m^2+am+b=n^2+an+b\\m^2+am=n^2+an\\
m^2-n^2=a(n-m)\\(m+n)(m-n)=a(n-m)\\(1/a)(m+n)(m-n)=(n-m)\\-(1/a)(m+n)(m-n)=(m-n) m=n -(1/a)(m+n)=1 a=-(m+n) n=-m-a m\neq n f","['functions', 'solution-verification', 'proof-writing']"
33,Limit of an integral as $x\to 0$,Limit of an integral as,x\to 0,"Given an integral function $\displaystyle F(x) = \int_{0}^{x}f(t)dt$ with $f(0)=3$ and $f$ continuous, determine the limit: $$\lim_{x\to 0}\frac{\displaystyle \int_{0}^{x}f(t)dt}{x}.$$ I know I could apply L'Hôpital's rule or the mean value theorem, but can I state simply that since $F'(x)=f(x)$ and then $F'(0)=3$ , so $$\displaystyle F(x) \;=\; \int_{0}^{x}f(t)dt \;=\; 0+3x+o(x),$$ as $x\to 0$ , and so $$\lim_{x\to 0}\frac{\displaystyle \int_{0}^{x}f(t)dt}{x^3} \;=\; \lim_{x\to 0}\frac{2x}{x} \;=\; 2\;?$$","Given an integral function with and continuous, determine the limit: I know I could apply L'Hôpital's rule or the mean value theorem, but can I state simply that since and then , so as , and so","\displaystyle F(x) = \int_{0}^{x}f(t)dt f(0)=3 f \lim_{x\to 0}\frac{\displaystyle \int_{0}^{x}f(t)dt}{x}. F'(x)=f(x) F'(0)=3 \displaystyle F(x) \;=\; \int_{0}^{x}f(t)dt \;=\; 0+3x+o(x), x\to 0 \lim_{x\to 0}\frac{\displaystyle \int_{0}^{x}f(t)dt}{x^3} \;=\; \lim_{x\to 0}\frac{2x}{x} \;=\; 2\;?","['real-analysis', 'calculus', 'integration', 'limits', 'functions']"
34,Sums of ratios of a set’s sums to its products,Sums of ratios of a set’s sums to its products,,"Let $S = \{1, 2, 3, ..., 8\}$ . Let $A \subseteq S$ and $A \neq \varnothing$ . $F(X) = \text{sum of all elements in } X.$ $G(X) = \text{product of all elements in }X$ . Calculate $\left\lfloor{\sum_{A ⊆ S}^\  \frac {F(A)} {G(A)}}\right\rfloor$ . My approach was looking for a pattern, so I calculated the first three terms and found out the sum could be $\frac {N^3-(N-1)^2} N$ . Can someone help me finding the real solution? Thanks in advance.","Let . Let and . . Calculate . My approach was looking for a pattern, so I calculated the first three terms and found out the sum could be . Can someone help me finding the real solution? Thanks in advance.","S = \{1, 2, 3, ..., 8\} A \subseteq S A \neq \varnothing F(X) = \text{sum of all elements in } X. G(X) = \text{product of all elements in }X \left\lfloor{\sum_{A ⊆ S}^\  \frac {F(A)} {G(A)}}\right\rfloor \frac {N^3-(N-1)^2} N","['sequences-and-series', 'combinatorics', 'number-theory', 'functions']"
35,all functions $f:A \rightarrow Y$ can be extended to $F$ if $i$ is injective.,all functions  can be extended to  if  is injective.,f:A \rightarrow Y F i,"Given sets $A, X, Y$ and functions $i: A \rightarrow X$ . We say that $f:A \rightarrow Y$ extends to $F:X \rightarrow Y$ if for all $a \in A$ $$F(i(a)) = f(a)$$ We want to show that all functions $f:A \rightarrow Y$ can be extended to $F$ if $i$ is injective. $i$ being injective has the consequence as all $a \in A$ are mapped to distinct $X \in X$ . So the image set of $i$ contains some distinct subset of $X$ . I believe I have to break this up into three cases namely $f$ being surjective, injective. (I don't think I have to consider the bijective case since bijection is injective + surjective) Case $1$ : when $f$ is injective . $\Rightarrow$ If $f$ is injective then it maps all $a \in A$ to distinct $y \in Y$ hence the $F$ exists. Case $2$ : When $f$ is surjective $$$$ $\Rightarrow$ When $f$ is surjective it has the property that for every $y \in Y$ there is a $a \in A$ such that $f(a) = y$ So if there exists $a_1 \neq a_2 \in A$ such that $f(a_1) = f(a_2) = y_0$ (because elsewise it's the same thing as the earlier case.) But since $a_1,a_2$ are mapped to $x \in X$ for some $x_1,x_2$ by $i$ , $F$ can map them both to $y_0$ hence such a $F$ exists Is this proof correct? Are there different (and easier) ways to prove this?","Given sets and functions . We say that extends to if for all We want to show that all functions can be extended to if is injective. being injective has the consequence as all are mapped to distinct . So the image set of contains some distinct subset of . I believe I have to break this up into three cases namely being surjective, injective. (I don't think I have to consider the bijective case since bijection is injective + surjective) Case : when is injective . If is injective then it maps all to distinct hence the exists. Case : When is surjective When is surjective it has the property that for every there is a such that So if there exists such that (because elsewise it's the same thing as the earlier case.) But since are mapped to for some by , can map them both to hence such a exists Is this proof correct? Are there different (and easier) ways to prove this?","A, X, Y i: A \rightarrow X f:A \rightarrow Y F:X \rightarrow Y a \in A F(i(a)) = f(a) f:A \rightarrow Y F i i a \in A X \in X i X f 1 f \Rightarrow f a \in A y \in Y F 2 f  \Rightarrow f y \in Y a \in A f(a) = y a_1 \neq a_2 \in A f(a_1) = f(a_2) = y_0 a_1,a_2 x \in X x_1,x_2 i F y_0 F","['functions', 'elementary-set-theory']"
36,"Finding the minimum value of $\frac{p}{q-r}$, where $(-1,p)$, $(0,q)$, $(1,r)$ lie on parabola $y=ax^2+bx+c$, with certain conditions","Finding the minimum value of , where , ,  lie on parabola , with certain conditions","\frac{p}{q-r} (-1,p) (0,q) (1,r) y=ax^2+bx+c","If the vertex of the parabola $$y=ax^2+bx+c \qquad (0<2a<-b)$$ is not below the x-axis.  Let there be three points on the parabola: $A(-1,p), B(0,q)$ and $C(1,r)$ . Then what is the minimum value of $\dfrac{p}{q-r}$ ? Hint: the answer is $3$ . My thoughts: Since the axis of symmetry of the function is $x=-\dfrac{b}{2a}>1$ and $\Delta=b^2-4ac<0$ , $\dfrac{p}{q-r}=-\dfrac{a-b+c}{a+b}$ ,  I thought of solving it by the image of the function. But it seems difficult to find the answer only through the limited conditions.","If the vertex of the parabola is not below the x-axis.  Let there be three points on the parabola: and . Then what is the minimum value of ? Hint: the answer is . My thoughts: Since the axis of symmetry of the function is and , ,  I thought of solving it by the image of the function. But it seems difficult to find the answer only through the limited conditions.","y=ax^2+bx+c \qquad (0<2a<-b) A(-1,p), B(0,q) C(1,r) \dfrac{p}{q-r} 3 x=-\dfrac{b}{2a}>1 \Delta=b^2-4ac<0 \dfrac{p}{q-r}=-\dfrac{a-b+c}{a+b}","['algebra-precalculus', 'functions', 'maxima-minima']"
37,Level curves representable by real-valued functions on $\mathbb{R}$,Level curves representable by real-valued functions on,\mathbb{R},"EDIT: I incorrectly interpreted the original question. The bounty has been awarded based on the (incorrect) interpretation I wrote here. The final version is posted here . Consider the function $u : \mathbb{R}^2 \to \mathbb{R}$ that the following properties are satisfied: Every level curve is a function from $\mathbb{R}$ to $\mathbb{R}$ . (That is, a level curve $U(x,y)= c$ can be written as $y = f(x)$ for some $f : \mathbb{R} \to \mathbb{R}$ .) $\forall$ $p \in \mathbb{R}^2$ , the sets $L(p)$ and $U(p)$ are closed. (Definition below.) Definition: For $p \in \mathbb{R}^2$ , define the lower contour of $p$ as $L(p) := \{(x,y) \in \mathbb{R}^2 : u(x,y) \leq u(p)\}$ and the upper contour of $p$ as $U(p) := \{(x,y) \in \mathbb{R}^2 : u(x,y) \geq u(p)\}$ . Question: Let $X = \mathbb{R}^2$ . Given $u(\cdot, \cdot)$ such that one of the level curves $y = f(x)$ is discontinuous at $x = t$ , construct (or show the existence of) two points $p, l \in X$ such that $l$ is a limit point of both $L(p)$ and $U(p)$ but is contained in exactly one of the two (contour sets). (The other level curves may or may not be discontinuous.) I posted a question on Economics SE that I could solve only partially. This is essentially the same question presented in a different manner. Here's the original question: Let $X = \mathbb{R}^2$ . Suppose $\succeq$ denotes a continuous preference relation. If every indifference curve can be represented by functions from $\mathbb{R}$ to $\mathbb{R}$ , will it mean the ICs will be continuous functions? If you want to see my attempt (and/or post an answer), please click on this .","EDIT: I incorrectly interpreted the original question. The bounty has been awarded based on the (incorrect) interpretation I wrote here. The final version is posted here . Consider the function that the following properties are satisfied: Every level curve is a function from to . (That is, a level curve can be written as for some .) , the sets and are closed. (Definition below.) Definition: For , define the lower contour of as and the upper contour of as . Question: Let . Given such that one of the level curves is discontinuous at , construct (or show the existence of) two points such that is a limit point of both and but is contained in exactly one of the two (contour sets). (The other level curves may or may not be discontinuous.) I posted a question on Economics SE that I could solve only partially. This is essentially the same question presented in a different manner. Here's the original question: Let . Suppose denotes a continuous preference relation. If every indifference curve can be represented by functions from to , will it mean the ICs will be continuous functions? If you want to see my attempt (and/or post an answer), please click on this .","u : \mathbb{R}^2 \to \mathbb{R} \mathbb{R} \mathbb{R} U(x,y)= c y = f(x) f : \mathbb{R} \to \mathbb{R} \forall p \in \mathbb{R}^2 L(p) U(p) p \in \mathbb{R}^2 p L(p) := \{(x,y) \in \mathbb{R}^2 : u(x,y) \leq u(p)\} p U(p) := \{(x,y) \in \mathbb{R}^2 : u(x,y) \geq u(p)\} X = \mathbb{R}^2 u(\cdot, \cdot) y = f(x) x = t p, l \in X l L(p) U(p) X = \mathbb{R}^2 \succeq \mathbb{R} \mathbb{R}","['real-analysis', 'functions', 'economics']"
38,Is this function monotonically increasing as $x_2$ increases?,Is this function monotonically increasing as  increases?,x_2,"Suppose I have a differentiable and continuous function $f(x)>0$ , the monotonicity of $f(x)$ is unknown. Assume that $x_1< x_2< x_3 \in \mathcal{S}$ , $\mathcal{S}$ is the domain of $f(x)$ . let $g(x)$ be \begin{equation} g(x_2)=2x_2-\frac{\int_{x_1}^{x_2}xf(x)dx}{\int_{x_1}^{x_2}f(x)dx}-\frac{\int_{x_2}^{x_3}xf(x)dx}{\int_{x_2}^{x_3}f(x)dx} \end{equation} Actually, $g(x_2)$ is the $2x_2$ minus the sum of centroids in $(x_1,x_2)$ and in $(x_2,x_3)$ . My question is : Is $g(x_2)$ is monotonically increasing as $x_2$ increases? Some MatLab simulation results show that $g(x_2)$ seems to be a monotonically increasing of $x_2$ . But, can we theoretically show this? I have tried to see if the derivation of $g(x_2)$ is always large than $0$ , but the result is not explicit. ------------------------------------------------------------------------------------------------------------------- Thanks for the answer from @Greg Martin . Actually, in my problem, $f(x)$ is an asymmetrical probability density function with $x\geq 0$ . Now, I still have a question: Does $g(x)=0$ have and only have one root? Thanks for any helpful answers!","Suppose I have a differentiable and continuous function , the monotonicity of is unknown. Assume that , is the domain of . let be Actually, is the minus the sum of centroids in and in . My question is : Is is monotonically increasing as increases? Some MatLab simulation results show that seems to be a monotonically increasing of . But, can we theoretically show this? I have tried to see if the derivation of is always large than , but the result is not explicit. ------------------------------------------------------------------------------------------------------------------- Thanks for the answer from @Greg Martin . Actually, in my problem, is an asymmetrical probability density function with . Now, I still have a question: Does have and only have one root? Thanks for any helpful answers!","f(x)>0 f(x) x_1< x_2< x_3 \in \mathcal{S} \mathcal{S} f(x) g(x) \begin{equation}
g(x_2)=2x_2-\frac{\int_{x_1}^{x_2}xf(x)dx}{\int_{x_1}^{x_2}f(x)dx}-\frac{\int_{x_2}^{x_3}xf(x)dx}{\int_{x_2}^{x_3}f(x)dx}
\end{equation} g(x_2) 2x_2 (x_1,x_2) (x_2,x_3) g(x_2) x_2 g(x_2) x_2 g(x_2) 0 f(x) x\geq 0 g(x)=0","['integration', 'functions', 'monotone-functions', 'centroid']"
39,How many monotonic functions on sets of naturals are there?,How many monotonic functions on sets of naturals are there?,,"A function $f\colon P(\mathbb{N}) \to P(\mathbb{N})$ is monotonic iff $x \subseteq y \implies f(x) \subseteq f(y)$ . What is the cardinality of the set $F$ of all such functions? What I have tried: I know the cardinality is either $2^\mathbb{N}$ or $(2^{\mathbb{N}})^{2^\mathbb{N}} = 2^{\mathbb{N}\cdot 2^\mathbb{N}} = 2^{2^\mathbb{N}}$ . I know that if I asked the question about natural numbers and not sets of them, the answer would be the (analogue of the) greater possibility, and if I asked about real numbers, the answer would be the (analogue of the) lesser possibility. (So as far as I know, there is a kind of ""precedent"" for both.) I tried proving it is $2^{\mathbb{N}}$ by finding a bijection between $P(\mathbb{N})$ and $F$ , but I couldn't come up with anything. I tried proving it is $2^{2^\mathbb{N}}$ in two ways. I tried finding a bijection between $P(\mathbb{N}) \to P(\mathbb{N})$ and $F$ . For functions on naturals, this is easy, (and has been asked before ): $$g(f) = n \mapsto \begin{cases} f(0) & n = 0\\ f(n) + f(n-1) & \text{else} \end{cases}$$ I tried to generalize this trick by defining $g'(f)$ similarly, in terms of sets containing one fewer element. However, such a definition would not be well-founded, because the set of sets of natural numbers is not well-ordered (take the family $\{ n \mid n > c \}$ for some $c$ ). I also tried a diagonalization proof by contradiction: assume there is a bijection $$g\colon P(\mathbb{N}) \to F\,,$$ then $$x \mapsto P(\mathbb{N}) \setminus g(x)(x)$$ or something similar fails to be a monotonic function not in $g$ 's image, because it fails to be (necessarily) monotonic, and I don't think this can be fixed.","A function is monotonic iff . What is the cardinality of the set of all such functions? What I have tried: I know the cardinality is either or . I know that if I asked the question about natural numbers and not sets of them, the answer would be the (analogue of the) greater possibility, and if I asked about real numbers, the answer would be the (analogue of the) lesser possibility. (So as far as I know, there is a kind of ""precedent"" for both.) I tried proving it is by finding a bijection between and , but I couldn't come up with anything. I tried proving it is in two ways. I tried finding a bijection between and . For functions on naturals, this is easy, (and has been asked before ): I tried to generalize this trick by defining similarly, in terms of sets containing one fewer element. However, such a definition would not be well-founded, because the set of sets of natural numbers is not well-ordered (take the family for some ). I also tried a diagonalization proof by contradiction: assume there is a bijection then or something similar fails to be a monotonic function not in 's image, because it fails to be (necessarily) monotonic, and I don't think this can be fixed.","f\colon P(\mathbb{N}) \to P(\mathbb{N}) x \subseteq y \implies f(x) \subseteq f(y) F 2^\mathbb{N} (2^{\mathbb{N}})^{2^\mathbb{N}} =
2^{\mathbb{N}\cdot 2^\mathbb{N}} = 2^{2^\mathbb{N}} 2^{\mathbb{N}} P(\mathbb{N}) F 2^{2^\mathbb{N}} P(\mathbb{N}) \to P(\mathbb{N}) F g(f) = n \mapsto \begin{cases}
f(0) & n = 0\\
f(n) + f(n-1) & \text{else}
\end{cases} g'(f) \{ n \mid n > c \} c g\colon P(\mathbb{N}) \to F\,, x \mapsto P(\mathbb{N}) \setminus g(x)(x) g","['functions', 'cardinals', 'monotone-functions']"
40,how to calculate a variable royalty number based on sold units,how to calculate a variable royalty number based on sold units,,"First thing please accept my apologies for the way i'm explaining my question - I'm not a math or econ major. I have a product that another company want to sell for me and pay me royalty in cents per unit sold. now I need a formula that as number of sold units are going up, the royalty per unit decreases at the same time my income keep increase to make it interesting for both me and the sellers to keep working with each other. what that formula be so my income look like a square root graph.","First thing please accept my apologies for the way i'm explaining my question - I'm not a math or econ major. I have a product that another company want to sell for me and pay me royalty in cents per unit sold. now I need a formula that as number of sold units are going up, the royalty per unit decreases at the same time my income keep increase to make it interesting for both me and the sellers to keep working with each other. what that formula be so my income look like a square root graph.",,"['calculus', 'functions', 'derivatives', 'mathematical-modeling']"
41,Confusion about an answer - why does this element have to be unique?,Confusion about an answer - why does this element have to be unique?,,"I'm reading this answer , and I'm stuck at ""... the unique element that some elements of the chain map it to"". Why does this element have to be unique? For example, consider the chain of functions $\mathbb N\to \mathbb N$ under the order described in the answer the first few  elements of which are described as follows: $f_1$ has fixed points $0,1,2,3$ (and only them) $f_2$ has fixed points $0,1,3$ (and only them) $f_3$ has fixed point $1$ (and only them) The condition $f_2\leq f_3$ means $\{1\}\subseteq \{0,1,3\}$ and the restriction of $f_2$ to $\mathbb N\setminus \{0,1,3\}$ equals the restriction of $f_3$ to the same set. In particular, it might be the case that $f_3(0)=15$ whereas $f_2(0)=0$ . If I call the function that is being constructed in the answer $L$ , what should be $L(0)$ ? Should it be $f_3(0)$ or should it be $f_2(0)$ , or something else? Also, just to make sure I understand the other part of the definition of $L$ correctly, the fixed points of $L$ in my example should just contain $1$ (since it's the only point where ""all elements of the chain have fixed points"")?","I'm reading this answer , and I'm stuck at ""... the unique element that some elements of the chain map it to"". Why does this element have to be unique? For example, consider the chain of functions under the order described in the answer the first few  elements of which are described as follows: has fixed points (and only them) has fixed points (and only them) has fixed point (and only them) The condition means and the restriction of to equals the restriction of to the same set. In particular, it might be the case that whereas . If I call the function that is being constructed in the answer , what should be ? Should it be or should it be , or something else? Also, just to make sure I understand the other part of the definition of correctly, the fixed points of in my example should just contain (since it's the only point where ""all elements of the chain have fixed points"")?","\mathbb N\to \mathbb N f_1 0,1,2,3 f_2 0,1,3 f_3 1 f_2\leq f_3 \{1\}\subseteq \{0,1,3\} f_2 \mathbb N\setminus \{0,1,3\} f_3 f_3(0)=15 f_2(0)=0 L L(0) f_3(0) f_2(0) L L 1","['functions', 'elementary-set-theory', 'proof-explanation', 'examples-counterexamples']"
42,A high school calculus exercise on function continuity.,A high school calculus exercise on function continuity.,,"Suppose $f:\mathbb{R}\to\mathbb{R}$ is a continuous function and $f(f(x))+3f(x)=12-2x, \hspace{.2cm} \forall x \in \mathbb{R}$ . $a$ . Prove that there is $x_0 \in \mathbb{R}$ such that $f(x_0)=x_0$ $b.$ Find $f(2)$ $c.$ If $$\lim_{x \to +\infty}\frac{f(x)}{x}=\lim_{x \to -\infty}\frac{f(x)}{x}=\mathcal{L} \in (-2, 0),$$ Find $\mathcal{L}$ My work so far: Suppose that $f(x_1)=f(x_2)\Rightarrow f(f(x_1))=f(f(x_1))\Rightarrow f(f(x_1))+3f(x_1)=f(f(x_2))+3f(x_2)\Rightarrow 12-2x_1=12-2x_2\Rightarrow \\ x_1=x_2$ . So we have concluded that $f$ is one-to-one. Now, for part $a$ , suppose that $\nexists \hspace{.1cm} x_0$ such that $f(x_0)=x_0$ , so $f(x_0)\neq x_0\hspace{.1cm} (1) \forall x_0 \in \mathbb{R}$ $(1)\Rightarrow f(f(x_0))\neq f(x_0)\overset{+3f(x_0)}\Rightarrow 12-2x_0\neq  4f(x_0)\Rightarrow 2f(x_0)+x_0-6\neq 0$ . The idea was to suppose some $g(x)=2f(x)+x-6$ and try to check its signs, to show that it may have a solution. Honestly, I'm at a loss. If I could prove $a.$ , part $b$ would be so easy. Because then $f(x_0)=x_0$ for some $x_0$ and with the first equation, $x_0=2$ . I haven't even tried part $c$ , obviously because I can't even do part $a$ . The question was taken from a Greek book printed in 1995 and no longer in the market. I doubt it will help listing it.","Suppose is a continuous function and . . Prove that there is such that Find If Find My work so far: Suppose that . So we have concluded that is one-to-one. Now, for part , suppose that such that , so . The idea was to suppose some and try to check its signs, to show that it may have a solution. Honestly, I'm at a loss. If I could prove , part would be so easy. Because then for some and with the first equation, . I haven't even tried part , obviously because I can't even do part . The question was taken from a Greek book printed in 1995 and no longer in the market. I doubt it will help listing it.","f:\mathbb{R}\to\mathbb{R} f(f(x))+3f(x)=12-2x, \hspace{.2cm} \forall x \in \mathbb{R} a x_0 \in \mathbb{R} f(x_0)=x_0 b. f(2) c. \lim_{x \to +\infty}\frac{f(x)}{x}=\lim_{x \to -\infty}\frac{f(x)}{x}=\mathcal{L} \in (-2, 0), \mathcal{L} f(x_1)=f(x_2)\Rightarrow f(f(x_1))=f(f(x_1))\Rightarrow f(f(x_1))+3f(x_1)=f(f(x_2))+3f(x_2)\Rightarrow 12-2x_1=12-2x_2\Rightarrow \\ x_1=x_2 f a \nexists \hspace{.1cm} x_0 f(x_0)=x_0 f(x_0)\neq x_0\hspace{.1cm} (1) \forall x_0 \in \mathbb{R} (1)\Rightarrow f(f(x_0))\neq f(x_0)\overset{+3f(x_0)}\Rightarrow 12-2x_0\neq  4f(x_0)\Rightarrow 2f(x_0)+x_0-6\neq 0 g(x)=2f(x)+x-6 a. b f(x_0)=x_0 x_0 x_0=2 c a","['calculus', 'limits', 'functions', 'continuity']"
43,"If I have two periodic functions so that $X = X(t)$ and $Y = X(t+\alpha)$, with $\alpha$ unknown is there a way to extract 𝛼 from $X-Y$?","If I have two periodic functions so that  and , with  unknown is there a way to extract 𝛼 from ?",X = X(t) Y = X(t+\alpha) \alpha X-Y,"If I have two periodic functions so that $X = X(t)$ and $Y = X(t+\alpha)$ , with $\alpha$ unknown is there a way to extract the value of $\alpha$ just from the difference of the two functions $X-Y$ ? $X$ and $Y$ are not necessarily sine or cosine, but whatever periodic function.","If I have two periodic functions so that and , with unknown is there a way to extract the value of just from the difference of the two functions ? and are not necessarily sine or cosine, but whatever periodic function.",X = X(t) Y = X(t+\alpha) \alpha \alpha X-Y X Y,['functions']
44,Proving Tietze's theorem on metric spaces,Proving Tietze's theorem on metric spaces,,"Let $(X,d)$ be a metric space and $A$ be a non-empty closed subset of $X$ . If $f\colon A\to \mathbb{R}$ is an application continuous and bounded, then there exists a continuous map $g\colon X\to \mathbb{R}$ such that $g(x)=f(x)$ for all $x\in A$ and $$\inf_{x\in X}g(x)=\inf_{y\in A}f(y) \quad \text{ y } \quad \sup_{x\in X}g(x)=\sup_{ y\in A}f(y).$$ My attempt We can decompose $X = A^{\circ} \cup (X\smallsetminus A) \cup \partial A$ . Let $m=\inf_{y\in A}f(y)$ and $M = \sup_{y\in A}f(y)$ . I first consider the case when $m=1$ and $M=2$ . Let us define $h\colon X\smallsetminus A \to \mathbb{R}$ by $h(x)=\inf\{f(y)d(x,y)\colon y\in A\}$ and $g\colon X\to \mathbb{R}$ by \begin{equation}\label{def1} g(x)= \left\{ \begin{array}{ccl} \dfrac{h(x)}{d(x,A)} & \text{si} & x\in X\smallsetminus A,\\ f(x) & \text{if} & x \in A. \end{array} \right. \end{equation} It is easy to prove that $1 \leq g(x) \leq 2$ for all $x \in X\smallsetminus A$ and $g$ extends $f$ to all $X$ . It remains for me to prove that $g$ is continuous on $X$ ; however, I have proven that $g$ is continuous on $A^{\circ}$ and on $X\smallsetminus A$ . It only remains for me to show that it is continuous on $\partial A$ . To do this, suppose $x_0\in \partial A=A\cap \overline{X\smallsetminus A}$ and let $\varepsilon \in (0,1)$ ; since $f$ is continuous on $A$ and $x_0\in A$ , there exists $\eta>0$ such that \begin{equation}  y\in A\cap B(x_0, \eta) \quad \text{implies} \quad |f(y)-f(x_0)|\le \varepsilon. \quad (*) \end{equation} Let $\delta\colon=\eta/3$ and $x\in B(x_0, \delta)$ . There are two cases. Case 1: If $x\in A$ , it follows from $(*)$ that $|g(x)-g(x_0)|=|f(x)-f(x_0)|\le \varepsilon$ . Case 2: If $x\notin A$ . Choose $a\in A$ such that $d\left(x,a\right)\leq 2d\left(x,A\right)$ , and note that $$ d\left(a,x_{0}\right)\leq d\left(a,x\right)+d\left(x,x_{0}\right)\leq2 d\left(x,A\right)+d\left(x,x_{0}\right)\leq3\cdot d\left(x,x_{0}\right)\leq\eta. $$ Therefore, $\left|f\left(a\right)-f\left(x_{0}\right)\right|\leq\frac{\varepsilon}{2}$ , and thus $$ g\left(x\right)\leq \dfrac{f(a)d(x,a)}{d(x,A)} \leq \dfrac{(\frac{\varepsilon}{2}+f(x_0))d(x,a)}{d(x,A)} \leq \dfrac{(\frac{\varepsilon}{2}+f(x_0))2d(x,A)}{d(x,A)} = 2f(x_0) + \varepsilon. $$ Precisely here is my mistake, because I need to prove that $ g(x) \leq f(x_0) + \varepsilon$ but I got $ g(x) \leq 2f(x_0) + \varepsilon$ . So I want to know where I am failing. I think if I can show this, the inequality $f(x_0) -\varepsilon \leq g(x) $ would be analogous. Finally, for the general case $m<M$ , I suspect that I should define the function $F(x) = \alpha f(x) + \beta$ , but I'm not sure. I need help with this exercise, please. Any help is appreciated.","Let be a metric space and be a non-empty closed subset of . If is an application continuous and bounded, then there exists a continuous map such that for all and My attempt We can decompose . Let and . I first consider the case when and . Let us define by and by It is easy to prove that for all and extends to all . It remains for me to prove that is continuous on ; however, I have proven that is continuous on and on . It only remains for me to show that it is continuous on . To do this, suppose and let ; since is continuous on and , there exists such that Let and . There are two cases. Case 1: If , it follows from that . Case 2: If . Choose such that , and note that Therefore, , and thus Precisely here is my mistake, because I need to prove that but I got . So I want to know where I am failing. I think if I can show this, the inequality would be analogous. Finally, for the general case , I suspect that I should define the function , but I'm not sure. I need help with this exercise, please. Any help is appreciated.","(X,d) A X f\colon A\to \mathbb{R} g\colon X\to \mathbb{R} g(x)=f(x) x\in A \inf_{x\in X}g(x)=\inf_{y\in A}f(y) \quad \text{ y } \quad \sup_{x\in X}g(x)=\sup_{ y\in A}f(y). X = A^{\circ} \cup (X\smallsetminus A) \cup \partial A m=\inf_{y\in A}f(y) M = \sup_{y\in A}f(y) m=1 M=2 h\colon X\smallsetminus A \to \mathbb{R} h(x)=\inf\{f(y)d(x,y)\colon y\in
A\} g\colon X\to \mathbb{R} \begin{equation}\label{def1}
g(x)=
\left\{
\begin{array}{ccl}
\dfrac{h(x)}{d(x,A)} & \text{si} & x\in X\smallsetminus A,\\
f(x) & \text{if} & x \in A.
\end{array}
\right.
\end{equation} 1 \leq g(x) \leq 2 x \in X\smallsetminus A g f X g X g A^{\circ} X\smallsetminus A \partial A x_0\in \partial A=A\cap \overline{X\smallsetminus A} \varepsilon \in (0,1) f A x_0\in A \eta>0 \begin{equation}
 y\in A\cap B(x_0, \eta) \quad \text{implies} \quad |f(y)-f(x_0)|\le \varepsilon. \quad (*)
\end{equation} \delta\colon=\eta/3 x\in B(x_0, \delta) x\in A (*) |g(x)-g(x_0)|=|f(x)-f(x_0)|\le \varepsilon x\notin A a\in A d\left(x,a\right)\leq 2d\left(x,A\right) 
d\left(a,x_{0}\right)\leq d\left(a,x\right)+d\left(x,x_{0}\right)\leq2 d\left(x,A\right)+d\left(x,x_{0}\right)\leq3\cdot d\left(x,x_{0}\right)\leq\eta.
 \left|f\left(a\right)-f\left(x_{0}\right)\right|\leq\frac{\varepsilon}{2} 
g\left(x\right)\leq \dfrac{f(a)d(x,a)}{d(x,A)} \leq \dfrac{(\frac{\varepsilon}{2}+f(x_0))d(x,a)}{d(x,A)} \leq \dfrac{(\frac{\varepsilon}{2}+f(x_0))2d(x,A)}{d(x,A)} = 2f(x_0) + \varepsilon.
  g(x) \leq f(x_0) + \varepsilon  g(x) \leq 2f(x_0) + \varepsilon f(x_0) -\varepsilon \leq g(x)  m<M F(x) = \alpha f(x) + \beta","['functions', 'continuity', 'metric-spaces']"
45,How do I show that the following map is surjective?,How do I show that the following map is surjective?,,"Helly I have the following problem. We have $f:T\rightarrow S$ a map an $\mathfrak{R}$ a relation on $S$ . We define a relation $\mathfrak{P}$ with $$x~\mathfrak{P}~y \Leftrightarrow f(x)~\mathfrak{R}~f(y)$$ Now we assume that $\mathfrak{R}$ is an equivalence relation and we define $$g:T/\mathfrak{P}\rightarrow S/\mathfrak{R};~~~~~T\supset B\mapsto A\subset S~~~s.t.~~~f(B)\subset A$$ I just know that $g$ is always injective and I know want to show that if $f$ is surjective then $g$ is bijective. So my Idea was the following. I remarked that it is enough to show that if $f$ is surjective then $g$ is surjective. I wanted to assume that $g$ is not surjective then $$\exists A\in S/\mathfrak{R}~~~s.t.~~~\forall B\in T/\mathfrak{P}~~~g(B)\neq A \Rightarrow f(B)\not\subset A$$ In my opinion this shows that $f$ is not surjective and thus the claim follows by contraposition, but I'm not really sure if this is correct so? Could someone take a look and help me? Thank you a lot.","Helly I have the following problem. We have a map an a relation on . We define a relation with Now we assume that is an equivalence relation and we define I just know that is always injective and I know want to show that if is surjective then is bijective. So my Idea was the following. I remarked that it is enough to show that if is surjective then is surjective. I wanted to assume that is not surjective then In my opinion this shows that is not surjective and thus the claim follows by contraposition, but I'm not really sure if this is correct so? Could someone take a look and help me? Thank you a lot.",f:T\rightarrow S \mathfrak{R} S \mathfrak{P} x~\mathfrak{P}~y \Leftrightarrow f(x)~\mathfrak{R}~f(y) \mathfrak{R} g:T/\mathfrak{P}\rightarrow S/\mathfrak{R};~~~~~T\supset B\mapsto A\subset S~~~s.t.~~~f(B)\subset A g f g f g g \exists A\in S/\mathfrak{R}~~~s.t.~~~\forall B\in T/\mathfrak{P}~~~g(B)\neq A \Rightarrow f(B)\not\subset A f,"['linear-algebra', 'functions', 'equivalence-relations']"
46,Central limit theorem with Limits?,Central limit theorem with Limits?,,"Let $X_1,X_2, . . .$ be an i.i.d. sequence of random variables with $E[X_1] = 1/2$ and $\operatorname{Var}[X_i] = 2$ . I want to Compute: $$P\left(\lim_{n\to\infty} (X_1+X_2+...+X_n)/n > 1\right)$$ My try: $P(\lim_{n->\infty} (X1+X2+...)/n > 1) = 1-P(\lim_{n->\infty} (X1+X2+...)/n \leq 1) = 1-P(\lim_{n->\infty} ((X1+X2+...)/n-1/2)\sqrt{2/n} \leq (1/2)/\sqrt{2/n})$ as I know that: $((X1+X2+...)/n-1/2)\sqrt{2/n}~N(0,1)$ From Central limit theorem. But my problem is the limit inside. My Questions: How can I continue from here Is there a way to solve this exactly without using Central limit theorem?",Let be an i.i.d. sequence of random variables with and . I want to Compute: My try: as I know that: From Central limit theorem. But my problem is the limit inside. My Questions: How can I continue from here Is there a way to solve this exactly without using Central limit theorem?,"X_1,X_2, . . . E[X_1] = 1/2 \operatorname{Var}[X_i] = 2 P\left(\lim_{n\to\infty} (X_1+X_2+...+X_n)/n > 1\right) P(\lim_{n->\infty} (X1+X2+...)/n > 1) = 1-P(\lim_{n->\infty} (X1+X2+...)/n \leq 1) = 1-P(\lim_{n->\infty} ((X1+X2+...)/n-1/2)\sqrt{2/n} \leq (1/2)/\sqrt{2/n}) ((X1+X2+...)/n-1/2)\sqrt{2/n}~N(0,1)","['probability', 'limits', 'probability-theory', 'functions', 'probability-distributions']"
47,Examples of inner product on the space of continous functions.,Examples of inner product on the space of continous functions.,,"Let $C([a,b], \mathbb{R})$ be the space of continous functions $f:[a,b] \to \mathbb{R}$ . I am looking for examples of inner products on this space. I know the inner product $\langle f,g \rangle = \int_a^b fg$ which can be generalized to $\langle f,g \rangle = \int_a^b fgh$ where $h \in C([a,b], \mathbb{R})$ is a non negative function. I haven't been able to find more examples for the space of continuous functions. I'd be especially interested in an inner product that doesn't depend on integration. Does anyone know more examples or a reference? Thanks.",Let be the space of continous functions . I am looking for examples of inner products on this space. I know the inner product which can be generalized to where is a non negative function. I haven't been able to find more examples for the space of continuous functions. I'd be especially interested in an inner product that doesn't depend on integration. Does anyone know more examples or a reference? Thanks.,"C([a,b], \mathbb{R}) f:[a,b] \to \mathbb{R} \langle f,g \rangle = \int_a^b fg \langle f,g \rangle = \int_a^b fgh h \in C([a,b], \mathbb{R})","['linear-algebra', 'functional-analysis', 'functions']"
48,Find $f$ such that $xf(x)+x^2f(x-1)=f(x^2)$,Find  such that,f xf(x)+x^2f(x-1)=f(x^2),I found this functional equation: $$xf(x)+x^2f(x-1)=f(x^2)\tag1$$ for all $x\in\mathbb{R}$ . I tried to solve it (that is: find all functions $f:\mathbb{R}\to\mathbb{R}$ such that (1) is true); but I only found that $f(0)=0$ and classical substitution $x-1\mapsto x$ doesn't give me any information. What do you think that can be a good approach?,I found this functional equation: for all . I tried to solve it (that is: find all functions such that (1) is true); but I only found that and classical substitution doesn't give me any information. What do you think that can be a good approach?,xf(x)+x^2f(x-1)=f(x^2)\tag1 x\in\mathbb{R} f:\mathbb{R}\to\mathbb{R} f(0)=0 x-1\mapsto x,"['functions', 'functional-equations']"
49,Show that $f(x) = x^3 + 3\sin x + 2\cos x$ is one-to-one.,Show that  is one-to-one.,f(x) = x^3 + 3\sin x + 2\cos x,"How would I show that $f(x) = x^3 + 3\sin x + 2\cos x$ is one to one? Showing that the function is strictly increasing seemed to be the way to go, but then I need to show that $f'(x) = 3x^2 + 3\cos x - 2\sin x > 0$ . I graphed the derivative function and it is indeed strictly positive. Thoughts?","How would I show that is one to one? Showing that the function is strictly increasing seemed to be the way to go, but then I need to show that . I graphed the derivative function and it is indeed strictly positive. Thoughts?",f(x) = x^3 + 3\sin x + 2\cos x f'(x) = 3x^2 + 3\cos x - 2\sin x > 0,"['calculus', 'functions']"
50,An inequality involving the Laplacian and the norm of the gradient,An inequality involving the Laplacian and the norm of the gradient,,"For any given probability density function $p$ (with finite second moments) on $\mathbb{R}^d$ I want to show that the following integral is bigger than $\textit{(or equal to)}$ zero $$ \int_{\mathbb{R}^d} \Big(\Delta\Psi(x)-\|\nabla \Psi(x)\|^2\Big) p(x)dx. $$ Obviously here I need to impose some assumptions on the function $\Psi$ . Since this needs to hold for any probability density $p$ , I think the easiest thing to ask is : Are there any conditions I can impose on a function $\Psi :\mathbb{R}^d \to \mathbb{R}$ such that $$ \Delta\Psi(x)-\|\nabla \Psi(x)\|^2 \geq 0, ~~\text{for}~a.e~x\in\mathbb{R}^d. $$","For any given probability density function (with finite second moments) on I want to show that the following integral is bigger than zero Obviously here I need to impose some assumptions on the function . Since this needs to hold for any probability density , I think the easiest thing to ask is : Are there any conditions I can impose on a function such that","p \mathbb{R}^d \textit{(or equal to)}  \int_{\mathbb{R}^d} \Big(\Delta\Psi(x)-\|\nabla \Psi(x)\|^2\Big) p(x)dx.  \Psi p \Psi :\mathbb{R}^d \to \mathbb{R}  \Delta\Psi(x)-\|\nabla \Psi(x)\|^2 \geq 0, ~~\text{for}~a.e~x\in\mathbb{R}^d. ","['functions', 'inequality', 'harmonic-functions', 'laplacian', 'functional-inequalities']"
51,"$f(x)=3x-\sin(\frac{\pi x}{2})$, $\quad$ $g(x)=x^3+2x-\sin(\frac{\pi x}{2})$",",",f(x)=3x-\sin(\frac{\pi x}{2}) \quad g(x)=x^3+2x-\sin(\frac{\pi x}{2}),"$f:\mathbb R \rightarrow\mathbb R$ and $g:\mathbb R \rightarrow\mathbb R$ are two functions such that $f(x)=3x-\sin(\frac{\pi x}{2})$ , $\quad$ $g(x)=x^3+2x-\sin(\frac{\pi x}{2})$ then choose the correct statements (A) $\frac{d}{dx}(f^{-1}(g^{-1}(x)))$ at $x=-12$ is $\frac{2}{3(28+\pi)}$ (B) $\frac{d}{dx}(f^{-1}(g^{-1}(x)))$ at $x=-12$ is $\frac{2}{3(28-\pi)}$ (C) Area bounded by $y=f^{-1}(x)$ and $y=g^{-1}(x)$ is $1$ (D) Area bounded by $y=f^{-1}(x)$ and $y=g^{-1}(x)$ is $\frac{1}{2}$ My Method: $(f^{-1}(g^{-1}(x)))=(g(f(x)))^{-1}$ $\implies$ $\frac{d}{dx}(f^{-1}(g^{-1}(x)))=\frac{d}{dx}(g(f(x)))^{-1}$ $\implies$ $\frac{d}{dx}(f^{-1}(g^{-1}(x)))=\frac{-g'(f(x))f'(x)}{(g(f(x))^{2}}$ But now I'm stuck. For Option (C) Because intersection points are $x=-1,x=0,x=1$ So area will be $\int_{-1}^{1}|g(x)-f(x)|dx$ Solution to Option (A) given in my Solution Image is as follow: $\frac{d}{dx}(f^{-1}(g^{-1}(x)))=\frac{1}{\frac{d}{dx}(g(f(x)))_{x=-1}}$ It seem to me that they must have used $f(g(x))=x$ if $f(x)$ and $g(x)$ are Inverse of each other. But I am not sure how did they use in above problem Please Help me in this question.","and are two functions such that , then choose the correct statements (A) at is (B) at is (C) Area bounded by and is (D) Area bounded by and is My Method: But now I'm stuck. For Option (C) Because intersection points are So area will be Solution to Option (A) given in my Solution Image is as follow: It seem to me that they must have used if and are Inverse of each other. But I am not sure how did they use in above problem Please Help me in this question.","f:\mathbb R \rightarrow\mathbb R g:\mathbb R \rightarrow\mathbb R f(x)=3x-\sin(\frac{\pi x}{2}) \quad g(x)=x^3+2x-\sin(\frac{\pi x}{2}) \frac{d}{dx}(f^{-1}(g^{-1}(x))) x=-12 \frac{2}{3(28+\pi)} \frac{d}{dx}(f^{-1}(g^{-1}(x))) x=-12 \frac{2}{3(28-\pi)} y=f^{-1}(x) y=g^{-1}(x) 1 y=f^{-1}(x) y=g^{-1}(x) \frac{1}{2} (f^{-1}(g^{-1}(x)))=(g(f(x)))^{-1} \implies \frac{d}{dx}(f^{-1}(g^{-1}(x)))=\frac{d}{dx}(g(f(x)))^{-1} \implies \frac{d}{dx}(f^{-1}(g^{-1}(x)))=\frac{-g'(f(x))f'(x)}{(g(f(x))^{2}} x=-1,x=0,x=1 \int_{-1}^{1}|g(x)-f(x)|dx \frac{d}{dx}(f^{-1}(g^{-1}(x)))=\frac{1}{\frac{d}{dx}(g(f(x)))_{x=-1}} f(g(x))=x f(x) g(x)","['integration', 'functions', 'derivatives', 'area', 'inverse-function']"
52,Why is this (image) function transformation not logical?,Why is this (image) function transformation not logical?,,"I am taking MIT 6.003 course from OCW and came upon the following problem from lecture 1: For the above image $f(x, y)$ , does the below image represent the transformation $f(-x-250, y)$ ? The correct answer is no but my answer was yes and the reasoning was as follows: First, we apply the image transformation using $f(-x, y)$ which will result in the original image being flipped about the vertical axis passing through x=0. Next, we apply the image transformation using $f(x-250, y)$ which will result in the flipped image to translate to the right. In total, intuitively speaking, applying $f(-x, y)$ followed by $f(x-250, y)$ should result in the 2nd image shown. Can anyone tell me what is the flaw in my logic? I can't figure out why this reasoning shouldn't work.","I am taking MIT 6.003 course from OCW and came upon the following problem from lecture 1: For the above image , does the below image represent the transformation ? The correct answer is no but my answer was yes and the reasoning was as follows: First, we apply the image transformation using which will result in the original image being flipped about the vertical axis passing through x=0. Next, we apply the image transformation using which will result in the flipped image to translate to the right. In total, intuitively speaking, applying followed by should result in the 2nd image shown. Can anyone tell me what is the flaw in my logic? I can't figure out why this reasoning shouldn't work.","f(x, y) f(-x-250, y) f(-x, y) f(x-250, y) f(-x, y) f(x-250, y)","['functions', 'coordinate-systems', 'transformation']"
53,How do I evaluate this definite integral?,How do I evaluate this definite integral?,,"Given a function $y=f(x)$ satisfying $xf(x^2)+3f(x)=3x^5+9x^2+x+3$ with domain $\mathbb{R}$ , evaluate $\int_{-1}^0 f(x).$ The method I have tried is to integrate both side: $$\int_{-1}^0xf(x^2)dx+3\int_{-1}^0f(x)dx=\int_{-1}^0(3x^5+9x^2+x+3)dx$$ With the integrand $\int_{-1}^0xf(x^2)dx$ , I substituted: $u=x^2→du=2xdx→xdx=\dfrac{du}{2}$ Which gave me: $$\dfrac{1}{2}\int_{1}^0f(u)du$$ therefore: $$\dfrac{1}{2}\int_{1}^0f(x)dx$$ I was struggling because the lower bound is $1$ and what I wanted is $-1$ , did I make any mistakes? And are there any better way to solve this?","Given a function satisfying with domain , evaluate The method I have tried is to integrate both side: With the integrand , I substituted: Which gave me: therefore: I was struggling because the lower bound is and what I wanted is , did I make any mistakes? And are there any better way to solve this?",y=f(x) xf(x^2)+3f(x)=3x^5+9x^2+x+3 \mathbb{R} \int_{-1}^0 f(x). \int_{-1}^0xf(x^2)dx+3\int_{-1}^0f(x)dx=\int_{-1}^0(3x^5+9x^2+x+3)dx \int_{-1}^0xf(x^2)dx u=x^2→du=2xdx→xdx=\dfrac{du}{2} \dfrac{1}{2}\int_{1}^0f(u)du \dfrac{1}{2}\int_{1}^0f(x)dx 1 -1,"['calculus', 'integration', 'functions', 'definite-integrals']"
54,Confused about the domain of this function,Confused about the domain of this function,,"The textbook seeks the domain of $f/g$ , where $ f(x)= \sqrt {x }$ and $g(x) = |x-3|$ . The answer stated is $(0,\infty]$ . I have two questions here: Shouldn't $3$ be excluded from the domain as one can't divide by zero? Is it okay to use square brackets for infinity? I have never seen infinity included in the domain of any function before, and my teacher clearly stated that infinity is always followed by a parenthesis, not a square bracket. The answer to a similar problem seeking the domain of $g(x) = |x-3|$ is (- $\infty$ , $\infty$ ]. How? Please explain this as well.","The textbook seeks the domain of , where and . The answer stated is . I have two questions here: Shouldn't be excluded from the domain as one can't divide by zero? Is it okay to use square brackets for infinity? I have never seen infinity included in the domain of any function before, and my teacher clearly stated that infinity is always followed by a parenthesis, not a square bracket. The answer to a similar problem seeking the domain of is (- , ]. How? Please explain this as well.","f/g  f(x)= \sqrt {x } g(x) = |x-3| (0,\infty] 3 g(x) = |x-3| \infty \infty",['functions']
55,"For a continuous function going through $(-1,0),(1,0),(2,3)$, show there are two distinct fixed points","For a continuous function going through , show there are two distinct fixed points","(-1,0),(1,0),(2,3)","Let $f : \mathbb{R}→\mathbb{R}$ be a continuous function such that $f(−1) = f(1) = 0, f(2) = 3$ . Show that there are distinct $a,b \in\mathbb{R}$ such that $f(a) = a$ and $f(b) = b$ . I'm pretty sure I use the Intermediate Value Theorem here, and to ensure $a \not = b$ , I think I would divide this problem up into two intervals $ [-1,1]$ and $[1,2]$ . But I have no idea how to do the proof.","Let be a continuous function such that . Show that there are distinct such that and . I'm pretty sure I use the Intermediate Value Theorem here, and to ensure , I think I would divide this problem up into two intervals and . But I have no idea how to do the proof.","f : \mathbb{R}→\mathbb{R} f(−1) = f(1) = 0, f(2) = 3 a,b \in\mathbb{R} f(a) = a f(b) = b a \not = b  [-1,1] [1,2]","['real-analysis', 'functions', 'continuity']"
56,"How is ""$f(x)$ is the set of all children of $x$"" a function?","How is "" is the set of all children of "" a function?",f(x) x,"How is this a function? $f(x)$ is the set of all children of $x$ On my slides it says that: Though this f is a function, it is NOT a $H \to H$ function, because each person is associated with a set of people rather than one person. (This $f$ is a $H \to P(H)$ function.) I have some questions I thought a function associates each element from the domain to exactly one element in the codomain but I have never seen this kind of function where each element in the domain is mapped to a set of elements. How is this a function? How would that work? If someone could show me visually through a diagram that would be fantastic Some people don't have children, so that means elements in the domain wouldn't be mapped, so how would this be a function? How is the power set of $H$ going to be the set of children? Why are we using the domain elements to create the codomain (since we're taking the power set of $H$ ...our domain)? Thanks in advance","How is this a function? is the set of all children of On my slides it says that: Though this f is a function, it is NOT a function, because each person is associated with a set of people rather than one person. (This is a function.) I have some questions I thought a function associates each element from the domain to exactly one element in the codomain but I have never seen this kind of function where each element in the domain is mapped to a set of elements. How is this a function? How would that work? If someone could show me visually through a diagram that would be fantastic Some people don't have children, so that means elements in the domain wouldn't be mapped, so how would this be a function? How is the power set of going to be the set of children? Why are we using the domain elements to create the codomain (since we're taking the power set of ...our domain)? Thanks in advance",f(x) x H \to H f H \to P(H) H H,['functions']
57,Finding all functions $f:\mathbb R\to\mathbb R$ which satisfy $f(xy)=yf(x)+x+f\bigl(f(y)-f(x)\bigr)$,Finding all functions  which satisfy,f:\mathbb R\to\mathbb R f(xy)=yf(x)+x+f\bigl(f(y)-f(x)\bigr),"-Closed: It has a solution in AOPS. - Find all functions $f:\mathbb R\to\mathbb R$ which satisfy $$f(xy)=yf(x)+x+f\bigl(f(y)-f(x)\bigr)$$ for all $x,y\in\mathbb R$ . My attempt: \begin{align} &P(x, x): f\left(x^2\right)=xf(x)+x+f(0). \\ &x=1; \ f(0)=-1. \\ \\ &P(x, 0): -1=x+f\bigl(-1-f(x)\bigr). \implies f\bigl(-f(x)-1\bigr)=-x-1. \\ &x=-1; f\bigl(-f(-1)-1\bigr)=0. \implies \exists t \ \text{ s.t. } f(t)=0. \\ \\ &P(t, 0): -1=t+f(-1). \\ &P(0, t): -1=-t+f(-1). \\ &\therefore 2t=f(1)-f(-1). \ \\ &P(-1, 1): f(-1)=-f(1)+1+f(-2t). \\ &f(-1)+f(1)-2+f(2t)-f(-2t)=0. \end{align}",-Closed: It has a solution in AOPS. - Find all functions which satisfy for all . My attempt:,"f:\mathbb R\to\mathbb R f(xy)=yf(x)+x+f\bigl(f(y)-f(x)\bigr) x,y\in\mathbb R \begin{align}
&P(x, x): f\left(x^2\right)=xf(x)+x+f(0). \\
&x=1; \ f(0)=-1. \\
\\
&P(x, 0): -1=x+f\bigl(-1-f(x)\bigr). \implies f\bigl(-f(x)-1\bigr)=-x-1. \\
&x=-1; f\bigl(-f(-1)-1\bigr)=0. \implies \exists t \ \text{ s.t. } f(t)=0. \\
\\
&P(t, 0): -1=t+f(-1). \\
&P(0, t): -1=-t+f(-1). \\
&\therefore 2t=f(1)-f(-1).
\ \\
&P(-1, 1): f(-1)=-f(1)+1+f(-2t). \\
&f(-1)+f(1)-2+f(2t)-f(-2t)=0.
\end{align}","['functions', 'functional-equations']"
58,Difference between increasing function and strictly increasing function in terms of derivatives?,Difference between increasing function and strictly increasing function in terms of derivatives?,,"Consider the following theorem and remarks from the Application of Derivatives chapter in p. 201 of the NCERT textbook . Theorem: Let $f$ be continuous on $[a, b]$ and differentiable on the open interval $(a,b)$ . Then (a) $f$ is increasing in $[a,b]$ if $f′(x) > 0$ for each $x \in (a,  b)$ (b) $f$ is decreasing in $[a,b]$ if $f′(x) < 0$ for each $x \in (a,  b)$ (c) $f$ is a constant function in $[a,b]$ if $f′(x) = 0$ for each $x  \in (a, b)$ Remarks: (i) $f$ is strictly increasing in $(a, b)$ if $f′(x) > 0$ for each $x  \in (a, b)$ (ii) $f$ is strictly decreasing in $(a, b)$ if $f′(x) < 0$ for each $x  \in (a, b)$ (iii) A function will be increasing (decreasing) in R if it is so in every interval of R. I am thinking that the theorem is incomplete and the remarks are correct. That theorem has to be as follows: (a) $f$ is increasing in $[a,b]$ if $f′(x) \ge 0$ for each $x \in (a,  b)$ (b) $f$ is decreasing in $[a,b]$ if $f′(x) \le 0$ for each $x \in (a,  b)$ Since there is a difference between increasing function and strictly increasing function, I am feeling that the theorem given in the textbook is faulty. Am I correct, or where am I going wrong?","Consider the following theorem and remarks from the Application of Derivatives chapter in p. 201 of the NCERT textbook . Theorem: Let be continuous on and differentiable on the open interval . Then (a) is increasing in if for each (b) is decreasing in if for each (c) is a constant function in if for each Remarks: (i) is strictly increasing in if for each (ii) is strictly decreasing in if for each (iii) A function will be increasing (decreasing) in R if it is so in every interval of R. I am thinking that the theorem is incomplete and the remarks are correct. That theorem has to be as follows: (a) is increasing in if for each (b) is decreasing in if for each Since there is a difference between increasing function and strictly increasing function, I am feeling that the theorem given in the textbook is faulty. Am I correct, or where am I going wrong?","f [a, b] (a,b) f [a,b] f′(x) > 0 x \in (a,
 b) f [a,b] f′(x) < 0 x \in (a,
 b) f [a,b] f′(x) = 0 x
 \in (a, b) f (a, b) f′(x) > 0 x
 \in (a, b) f (a, b) f′(x) < 0 x
 \in (a, b) f [a,b] f′(x) \ge 0 x \in (a,
 b) f [a,b] f′(x) \le 0 x \in (a,
 b)","['calculus', 'functions', 'derivatives']"
59,How to tell if a complex function has this property,How to tell if a complex function has this property,,"Suppose we have a complex function of a complex variable $f(z)$ . How can we know if it satisfies (I don't know how to name this or type it in latex) $$ \overline{f(z)}=f(\bar z) $$ I tried linear functions, polynomials, exponentials and I got yes for some and no for others. For polynomials, all the coefficients must be real, for exponentials, the power has to be real and so on. So I came up with this idea: If you can write down the formula of the function without having to type $i$ then you get this property. If not, the LHS and the RHS of the equation above disagree. Any one have the answer to that? I guess It should be some kind of theorem, no? All help greatly appreciated.","Suppose we have a complex function of a complex variable . How can we know if it satisfies (I don't know how to name this or type it in latex) I tried linear functions, polynomials, exponentials and I got yes for some and no for others. For polynomials, all the coefficients must be real, for exponentials, the power has to be real and so on. So I came up with this idea: If you can write down the formula of the function without having to type then you get this property. If not, the LHS and the RHS of the equation above disagree. Any one have the answer to that? I guess It should be some kind of theorem, no? All help greatly appreciated.","f(z) 
\overline{f(z)}=f(\bar z)
 i","['complex-analysis', 'functions']"
60,What are the visual properties that make a function linear?,What are the visual properties that make a function linear?,,"I am currently studying linear algebra and we came across the definition of a scalar-valued linear function which is a mapping from a vector to a scalar (real in our case). I also watched 3B1B's video on linear transformations (mappings) in which he introduced two key properties for explaining why a mapping was linear:  all lines in the grid space must remain lines and the origin must remain fixed in place. Is there a similar intuition about what properties scalar-valued functions need to have to be linear. I understand that they must exhibit superposition: $$f(\alpha x+\beta y)=\alpha f(x)+\beta f(y)$$ for all numbers $\alpha, \beta$ and all $n$ -vectors $x,y$ But what does this mean visually? Thanks!",I am currently studying linear algebra and we came across the definition of a scalar-valued linear function which is a mapping from a vector to a scalar (real in our case). I also watched 3B1B's video on linear transformations (mappings) in which he introduced two key properties for explaining why a mapping was linear:  all lines in the grid space must remain lines and the origin must remain fixed in place. Is there a similar intuition about what properties scalar-valued functions need to have to be linear. I understand that they must exhibit superposition: for all numbers and all -vectors But what does this mean visually? Thanks!,"f(\alpha x+\beta y)=\alpha f(x)+\beta f(y) \alpha, \beta n x,y","['linear-algebra', 'functions', 'linear-transformations']"
61,Zeros of a polynomial in a simple form,Zeros of a polynomial in a simple form,,"Let $m\geq 3$ be a natural number and define $$f(x)=1-x^m-(1-x)(1+x)^{m-1}.$$ Then, if $m$ is even, the only real roots of $f$ are $x=-1,0,1$ and if $m$ is odd, the roots are $x=0,1$ . My work: for the case where $m$ is even, i proved that $$f(x)=\sum_{k=0}^{m-2}\left(\begin{pmatrix}       m-1\\       k+1     \end{pmatrix}-     \begin{pmatrix}       m-1\\       k     \end{pmatrix}\right)x^{m-k-1}$$ on one hand. Decomposing it as $f(x)=(x-1)x(x+1)P(x)$ , where \begin{align*}     P(x)=\sum_{k=0}^{m-4}b_kx^{m-k-4}, \end{align*} I get an alternative representation \begin{align*}     f(x)=\sum_{k=0}^{m-2}(b_k-b_{k-2})x^{m-k-1}, \end{align*} with $b_{-2}=b_{-1}=b_{m-2}=b_{m-1}=0$ . Combining both I get \begin{align*}     b_k-b_{k-2}=\begin{pmatrix}       m-1\\       k+1     \end{pmatrix}-     \begin{pmatrix}       m-1\\       k     \end{pmatrix}. \end{align*} From here I can clearly see that $b_k\geq 0$ , however this does not imply that $P>0$ as intended. I don't know how to proceed, any suggestions please? It is entirely possible that I approached the problem from the wrong perspective...","Let be a natural number and define Then, if is even, the only real roots of are and if is odd, the roots are . My work: for the case where is even, i proved that on one hand. Decomposing it as , where I get an alternative representation with . Combining both I get From here I can clearly see that , however this does not imply that as intended. I don't know how to proceed, any suggestions please? It is entirely possible that I approached the problem from the wrong perspective...","m\geq 3 f(x)=1-x^m-(1-x)(1+x)^{m-1}. m f x=-1,0,1 m x=0,1 m f(x)=\sum_{k=0}^{m-2}\left(\begin{pmatrix}
      m-1\\
      k+1
    \end{pmatrix}-
    \begin{pmatrix}
      m-1\\
      k
    \end{pmatrix}\right)x^{m-k-1} f(x)=(x-1)x(x+1)P(x) \begin{align*}
    P(x)=\sum_{k=0}^{m-4}b_kx^{m-k-4},
\end{align*} \begin{align*}
    f(x)=\sum_{k=0}^{m-2}(b_k-b_{k-2})x^{m-k-1},
\end{align*} b_{-2}=b_{-1}=b_{m-2}=b_{m-1}=0 \begin{align*}
    b_k-b_{k-2}=\begin{pmatrix}
      m-1\\
      k+1
    \end{pmatrix}-
    \begin{pmatrix}
      m-1\\
      k
    \end{pmatrix}.
\end{align*} b_k\geq 0 P>0","['real-analysis', 'functions', 'polynomials']"
62,"proof of injection, surjection and bijection of identity functions","proof of injection, surjection and bijection of identity functions",,"Suppose there are two functions $$ f: X \to Y $$ and $$ g: Y \to X$$ and $ g \circ f = id_{X}$ Proof or disproof the following: a) f is injectiv b) f is surjectiv c) g is injective d) g is surjective e) $f\circ g = id_{Y}$ After some research i was able to do a and b myself, however i stuck on c and d because in my head we can just use the answers from a and b and change the domain and codomain and some symbols to get the answers, basically should be the same as a and b. But i thought if it were that easy why would the professor give us the questions to do....So could someone tell me how to proceed or if there is a trick at all? Would be really great if you could give me one example proof of c and d so that i can check whether my answers are correct!! NEW EDIT: I just found some older posts with similar questions where people said f is injective and g is surjective...i thought they were both bijective???? completely confused,,,would really appreciate some help clearing this thing. Thanks a lot","Suppose there are two functions and and Proof or disproof the following: a) f is injectiv b) f is surjectiv c) g is injective d) g is surjective e) After some research i was able to do a and b myself, however i stuck on c and d because in my head we can just use the answers from a and b and change the domain and codomain and some symbols to get the answers, basically should be the same as a and b. But i thought if it were that easy why would the professor give us the questions to do....So could someone tell me how to proceed or if there is a trick at all? Would be really great if you could give me one example proof of c and d so that i can check whether my answers are correct!! NEW EDIT: I just found some older posts with similar questions where people said f is injective and g is surjective...i thought they were both bijective???? completely confused,,,would really appreciate some help clearing this thing. Thanks a lot", f: X \to Y   g: Y \to X  g \circ f = id_{X} f\circ g = id_{Y},"['functions', 'elementary-set-theory', 'proof-explanation']"
63,periodic function of x with period 2 and f(x) =|x|−x for −1<x≤1.,periodic function of x with period 2 and f(x) =|x|−x for −1<x≤1.,,"Let $f(x)$ be a periodic function in $x$ with period 2, and $f(x) =|x|−x$ for $−1< x≤1$ .  Sketch the graph of the curve $y=f(x)$ in the interval $[−3,3]$ . $f(x) =|x|−x$ seems not to be a periodic function, though, so how can I solve the question? Thank you!","Let be a periodic function in with period 2, and for .  Sketch the graph of the curve in the interval . seems not to be a periodic function, though, so how can I solve the question? Thank you!","f(x) x f(x) =|x|−x −1< x≤1 y=f(x) [−3,3] f(x) =|x|−x","['functions', 'graphing-functions', 'absolute-value']"
64,Higher Level Mathematics & Piecewise [closed],Higher Level Mathematics & Piecewise [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 years ago . Improve this question Apologies if this isn't the right place to enquire about this; I'm really looking for potential connections to what I've been doing as opposed to having a maths question answered. With that being said, I would heavily appreciate tips and advice as to potential techniques as well as connections. Background: I'm currently a first year university student (about three-quarters of the way through first year) so I'm not well-versed in higher topics in mathematics. Currently doing multivariable calculus and differential equations, and have had a rudimentary introduction to linear algebra (and plans to do real analysis and linear algebra next year). With that being said, the whole point of me asking here is to get answers as to where I can go in relation to some of the stuff I've been doing. I have a bit of an unnatural obsession with piecewise objects in general, and I've been told that some of the stuff I do has the potential to dive into various areas like topology, etc. So I run a site plainly called Piecewise where I really sort of explore and post some of the stuff to do with piecewise. More or less - I'm looking for places to go with some of the stuff I have been (and have not been) doing with piecewise objects. Even more specifically, I base a lot of the stuff I do on the foundation that the cases within piecewise objects aren't independent of one another; i.e. operations you perform on one case you perform on others in order to relate each case to one another. Current work : The above idea has yielded some interesting derivations, including the ability to interpolate a set of points as polynomials (with quite-flexible ideas), which was entirely accidental and had been a goal, that is, turning a set of points into a polynomial without solving a system of equations. That was one of my goals a couple of years ago during VCE which ended up going nowhere till more recently, when I was told that what I had derived appeared to be a lagrange-form polynomial; a polynomial derived as a consequence of lagrange interpolation. Later, I also rederived interpolation as newton-form polynomials using a similar method. Other things I've been able to do have largely been geometric and graphical in nature; deriving a continuous batman equation/relation from the original, equations of hollow hypercubes in n-dimensions, a formula for the sticking together of several functions along a given axis (I keep hearing things about the gluing lemma in this regard?) which can be extended into higher dimensions on surfaces, but takes on a far more ugly and restrictive formula. Obviously a lot of these things are fairly rudimentary in their approach and nature. Problem/Question : Naturally, I'm absolutely curious about where I can go with these ideas and potential connections to higher-level mathematics, not necessarily geometric in nature (although it seems to be a recurring theme). It furthermore seems to be an issue that with my peers, the line of thinking I'm on takes time to understand, so I have found it difficult to communicate my ideas a lot of the time - but have had occasional assistance. Specifically , what areas of maths might be the most relevant to what I'm doing, and, what potential subtopics could have some potential relevance to these piecewise objects, if any? Additionally, from what I can see, no one else has really approached piecewise in this way before that I can find, which has led my friends and I to a few hypotheses: Exploring piecewise in this way is largely redundant and ultimately leads to very little that generalises to higher mathematics. It has been explored, and all exploration that has been done has ultimately been integrated into other things (wherein perhaps piecewise was used as a scaffolding that was later removed). It genuinely hasn't been explored before (and imho the least likely option). Naturally, I am also curious as to (1) whether I'm expending my time that on something will yield little or is 'useless', and (2) did I miss something? Has this been done before? Thanks in advance - and apologies if this isn't specific enough (also had no idea what to tag this post with).","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 years ago . Improve this question Apologies if this isn't the right place to enquire about this; I'm really looking for potential connections to what I've been doing as opposed to having a maths question answered. With that being said, I would heavily appreciate tips and advice as to potential techniques as well as connections. Background: I'm currently a first year university student (about three-quarters of the way through first year) so I'm not well-versed in higher topics in mathematics. Currently doing multivariable calculus and differential equations, and have had a rudimentary introduction to linear algebra (and plans to do real analysis and linear algebra next year). With that being said, the whole point of me asking here is to get answers as to where I can go in relation to some of the stuff I've been doing. I have a bit of an unnatural obsession with piecewise objects in general, and I've been told that some of the stuff I do has the potential to dive into various areas like topology, etc. So I run a site plainly called Piecewise where I really sort of explore and post some of the stuff to do with piecewise. More or less - I'm looking for places to go with some of the stuff I have been (and have not been) doing with piecewise objects. Even more specifically, I base a lot of the stuff I do on the foundation that the cases within piecewise objects aren't independent of one another; i.e. operations you perform on one case you perform on others in order to relate each case to one another. Current work : The above idea has yielded some interesting derivations, including the ability to interpolate a set of points as polynomials (with quite-flexible ideas), which was entirely accidental and had been a goal, that is, turning a set of points into a polynomial without solving a system of equations. That was one of my goals a couple of years ago during VCE which ended up going nowhere till more recently, when I was told that what I had derived appeared to be a lagrange-form polynomial; a polynomial derived as a consequence of lagrange interpolation. Later, I also rederived interpolation as newton-form polynomials using a similar method. Other things I've been able to do have largely been geometric and graphical in nature; deriving a continuous batman equation/relation from the original, equations of hollow hypercubes in n-dimensions, a formula for the sticking together of several functions along a given axis (I keep hearing things about the gluing lemma in this regard?) which can be extended into higher dimensions on surfaces, but takes on a far more ugly and restrictive formula. Obviously a lot of these things are fairly rudimentary in their approach and nature. Problem/Question : Naturally, I'm absolutely curious about where I can go with these ideas and potential connections to higher-level mathematics, not necessarily geometric in nature (although it seems to be a recurring theme). It furthermore seems to be an issue that with my peers, the line of thinking I'm on takes time to understand, so I have found it difficult to communicate my ideas a lot of the time - but have had occasional assistance. Specifically , what areas of maths might be the most relevant to what I'm doing, and, what potential subtopics could have some potential relevance to these piecewise objects, if any? Additionally, from what I can see, no one else has really approached piecewise in this way before that I can find, which has led my friends and I to a few hypotheses: Exploring piecewise in this way is largely redundant and ultimately leads to very little that generalises to higher mathematics. It has been explored, and all exploration that has been done has ultimately been integrated into other things (wherein perhaps piecewise was used as a scaffolding that was later removed). It genuinely hasn't been explored before (and imho the least likely option). Naturally, I am also curious as to (1) whether I'm expending my time that on something will yield little or is 'useless', and (2) did I miss something? Has this been done before? Thanks in advance - and apologies if this isn't specific enough (also had no idea what to tag this post with).",,"['general-topology', 'geometry', 'functions', 'soft-question', 'advice']"
65,Geometry of the map $\vec{u}\times(\vec{r}\times\vec{u})$,Geometry of the map,\vec{u}\times(\vec{r}\times\vec{u}),A linear map $f\colon \mathbb{R}^3 \to \mathbb{R}^3$ is defined as $\vec{u}\times(\vec{r}\times\vec{u})$ where $\vec{u}$ is a unit vector. What would its geometry look like? I know that I can rewrite this map as $(\vec{u}\cdot\vec{u})\vec{r}-(\vec{u}\cdot\vec{r})\vec{u} = \vec{r} - (\vec{u}\cdot\vec{r})\vec{u}$ However I am not sure what to do from here.,A linear map is defined as where is a unit vector. What would its geometry look like? I know that I can rewrite this map as However I am not sure what to do from here.,f\colon \mathbb{R}^3 \to \mathbb{R}^3 \vec{u}\times(\vec{r}\times\vec{u}) \vec{u} (\vec{u}\cdot\vec{u})\vec{r}-(\vec{u}\cdot\vec{r})\vec{u} = \vec{r} - (\vec{u}\cdot\vec{r})\vec{u},"['linear-algebra', 'functions', 'vectors']"
66,How it is possible that left side oscillation of function be 0 but left side limit does not exist?,How it is possible that left side oscillation of function be 0 but left side limit does not exist?,,"Let A be domain of function. The oscillation of function defined as: $$\Omega_{A} f:=\sup _{A} f-\inf _{A}=\sup _{x, y \in A}|f(x)-f(y)|$$ And oscillation of function at point defined as: $$\omega_{f}(c):=\lim _{h \rightarrow 0+} \Omega_{] c-h, c+h[\cap A} f$$ Show that if $$\lim _{x \rightarrow c-} f(x)$$ exsists  and is finite then $$ \lim _{x \rightarrow c-}\omega_{f}(x)=0 $$ Show that converse is false. Okey forward direction I understood. but I can't find any example that converse is false.",Let A be domain of function. The oscillation of function defined as: And oscillation of function at point defined as: Show that if exsists  and is finite then Show that converse is false. Okey forward direction I understood. but I can't find any example that converse is false.,"\Omega_{A} f:=\sup _{A} f-\inf _{A}=\sup _{x, y \in A}|f(x)-f(y)| \omega_{f}(c):=\lim _{h \rightarrow 0+} \Omega_{] c-h, c+h[\cap A} f \lim _{x \rightarrow c-} f(x) 
\lim _{x \rightarrow c-}\omega_{f}(x)=0 ","['real-analysis', 'calculus', 'limits', 'functions']"
67,Graph of negative exponential function,Graph of negative exponential function,,"Is it possible to graph a function $Y = (-2)^x$ where $x \geq 1$ It is written in my text that exponential functions are only defined for positive bases, but why not negative bases having restriction on domain ( $x$ ) of function  which would not give minus sign under square root. I am new to this stuff so please help me even if it looks silly.","Is it possible to graph a function where It is written in my text that exponential functions are only defined for positive bases, but why not negative bases having restriction on domain ( ) of function  which would not give minus sign under square root. I am new to this stuff so please help me even if it looks silly.",Y = (-2)^x x \geq 1 x,"['functions', 'exponential-function']"
68,How to come up with formula to get minimum sell price to profit on commodity exchange,How to come up with formula to get minimum sell price to profit on commodity exchange,,"I'm stuck trying to come up with an equation that will calculate the minimum sale price of a commodity (such as Bitcoin) in order to at least break even. That in it of itself is no problem, sell for same price it was purchased for at the minimum. The issue I'm running into is, based on my several searches, one variable is dependent on another variable. To be specific, if I purchase something for $100, with .5% of the purchase being a fee, how do I figure out what my sale price of that same quantity will need to be in order to break even? If I'm thinking about this correctly, my independent variable is sale price, while the dependent variable is the sale fee. I've tried different things, but I can't seem to get the result I'm looking for. I'll use the following variables: a =  purchase price b =  purchase fee (constant, 0.5% or 0.005) c =  sale price d =  sale fee (constant, 0.5% or 0.005) The first equation I come up with, and with the help of online formula solver to simplify: $$c = (a * (1 + b)) / (1 + d).$$ But the fee is not supposed to be additive, this comes out of the purchase and sale prices $$(c - (c * .005)) - (a - (a * .005)).$$ But I don't even know what c is. So if I use the online formula solver to solve for c, I get: $$ c = a.$$ I can trial and error in a spreadsheet until I get my profit to show $0.00 so I know what my minimum sale price is. But trying to convert that into a C# program is proving to test my limited knowledge in math. Can anybody point me in the right direction on how to logic this out to the point I can program it?","I'm stuck trying to come up with an equation that will calculate the minimum sale price of a commodity (such as Bitcoin) in order to at least break even. That in it of itself is no problem, sell for same price it was purchased for at the minimum. The issue I'm running into is, based on my several searches, one variable is dependent on another variable. To be specific, if I purchase something for $100, with .5% of the purchase being a fee, how do I figure out what my sale price of that same quantity will need to be in order to break even? If I'm thinking about this correctly, my independent variable is sale price, while the dependent variable is the sale fee. I've tried different things, but I can't seem to get the result I'm looking for. I'll use the following variables: a =  purchase price b =  purchase fee (constant, 0.5% or 0.005) c =  sale price d =  sale fee (constant, 0.5% or 0.005) The first equation I come up with, and with the help of online formula solver to simplify: But the fee is not supposed to be additive, this comes out of the purchase and sale prices But I don't even know what c is. So if I use the online formula solver to solve for c, I get: I can trial and error in a spreadsheet until I get my profit to show $0.00 so I know what my minimum sale price is. But trying to convert that into a C# program is proving to test my limited knowledge in math. Can anybody point me in the right direction on how to logic this out to the point I can program it?",c = (a * (1 + b)) / (1 + d). (c - (c * .005)) - (a - (a * .005)).  c = a.,"['functions', 'graphing-functions']"
69,How to shorten this rational function?,How to shorten this rational function?,,"Determine a value for the constant b so that we can shorten the expression for the function $f\left(x\right)=\frac{2x^2+bx-30}{x+3}$ . Shorten the expression. Here is the step by step solution we got: The zero point for the denominator $x+3$ is $x=-3$ The function $f$ is defined when $x\ne-3$ We can shorten the expression only if the denominator and numerator have a common factor. The numerator has the factor $x+3$ only if $-3$ is the zero point in the numerator. We determine the constant b: The numerators value is zero for the variable value $-3$ . $2\cdot\left(-3\right)^2+b\cdot\left(-3\right)-30=0$ $b=-4$ Now I don't understand why x is replaced with $-3$ above. What is the reason behind it, why can't it be for example be $-4$ ? edit: need an easy explanation, I'm not too good at math.","Determine a value for the constant b so that we can shorten the expression for the function . Shorten the expression. Here is the step by step solution we got: The zero point for the denominator is The function is defined when We can shorten the expression only if the denominator and numerator have a common factor. The numerator has the factor only if is the zero point in the numerator. We determine the constant b: The numerators value is zero for the variable value . Now I don't understand why x is replaced with above. What is the reason behind it, why can't it be for example be ? edit: need an easy explanation, I'm not too good at math.",f\left(x\right)=\frac{2x^2+bx-30}{x+3} x+3 x=-3 f x\ne-3 x+3 -3 -3 2\cdot\left(-3\right)^2+b\cdot\left(-3\right)-30=0 b=-4 -3 -4,"['calculus', 'algebra-precalculus', 'functions', 'derivatives', 'rational-functions']"
70,Proving that the range of two functions is disjoint and the union of the ranges is the entire set of natural numbers.,Proving that the range of two functions is disjoint and the union of the ranges is the entire set of natural numbers.,,"Define, where $x$ and $y$ are non-negative integers: $f(x,y)=x^2 + 2x(y + 1) + y^2 + y + 1$ $g(x,y)=x^2 + 2x(y + 1) + y^2 + 3y + 2$ Prove that the range of $f(x,y)$ is disjoint from the range of $g(x,y)$ and that the union of the ranges is the entire set of natural numbers. What I have attempted so far: To prove that the ranges are disjoint, I tried to find when $f(x,y)=g(x,y)$ . This only occurs when $y=-\frac{1}{2}$ , which is not a non-negative integer. However, I don't think it proves the ranges are disjoint, as it only shows there isn't an ordered pair which gives the same value for both functions, not that the two functions never output the same value. For the second part of the problem (and possibly the first part) re-writing both formulas using some clever factorisation might reveal something. For example, $f(x,y)=(x+y+1)^2-y$ and $g(x,y)=(x+y+1)^2+y+1$ . However, I am not quite sure how to utilise this. Any hints for either part of the problem?","Define, where and are non-negative integers: Prove that the range of is disjoint from the range of and that the union of the ranges is the entire set of natural numbers. What I have attempted so far: To prove that the ranges are disjoint, I tried to find when . This only occurs when , which is not a non-negative integer. However, I don't think it proves the ranges are disjoint, as it only shows there isn't an ordered pair which gives the same value for both functions, not that the two functions never output the same value. For the second part of the problem (and possibly the first part) re-writing both formulas using some clever factorisation might reveal something. For example, and . However, I am not quite sure how to utilise this. Any hints for either part of the problem?","x y f(x,y)=x^2 + 2x(y + 1) + y^2 + y + 1 g(x,y)=x^2 + 2x(y + 1) + y^2 + 3y + 2 f(x,y) g(x,y) f(x,y)=g(x,y) y=-\frac{1}{2} f(x,y)=(x+y+1)^2-y g(x,y)=(x+y+1)^2+y+1","['algebra-precalculus', 'functions']"
71,Proving that $g(x) = \operatorname{sup}_{j}f_{j}(x)$ is measurable,Proving that  is measurable,g(x) = \operatorname{sup}_{j}f_{j}(x),"I'm studying the proof that $g(x) = \operatorname{sup}_{j}f_{j}(x)$ is measurable. Here, $\{f_{j}\}_{j\in \mathbb{N}}$ is a sequence of functions $f_{j}: X \to \overline{\mathbb{R}}$ , where $X$ is equipped with the $\sigma$ -algebra $\mathbb{X}$ . The proof uses: $$g^{-1}((a,\infty]) = \bigcup_{j=1}^{\infty}f_{j}^{-1}((a,\infty]) \tag{1}\label{1}$$ Why does (\ref{1}) hold? If $g$ was defined by $g_{k}(x) = \operatorname{sup}_{j \ge k}f_{j}(x)$ , would (\ref{1}) become $$g^{-1}((a,\infty]) = \bigcup_{j=k}^{\infty}f_{j}^{-1}((a,\infty])$$ instead?","I'm studying the proof that is measurable. Here, is a sequence of functions , where is equipped with the -algebra . The proof uses: Why does (\ref{1}) hold? If was defined by , would (\ref{1}) become instead?","g(x) = \operatorname{sup}_{j}f_{j}(x) \{f_{j}\}_{j\in \mathbb{N}} f_{j}: X \to \overline{\mathbb{R}} X \sigma \mathbb{X} g^{-1}((a,\infty]) = \bigcup_{j=1}^{\infty}f_{j}^{-1}((a,\infty]) \tag{1}\label{1} g g_{k}(x) = \operatorname{sup}_{j \ge k}f_{j}(x) g^{-1}((a,\infty]) = \bigcup_{j=k}^{\infty}f_{j}^{-1}((a,\infty])","['real-analysis', 'measure-theory', 'functions']"
72,Understanding and Solving Trigonometric Functions by Hand [closed],Understanding and Solving Trigonometric Functions by Hand [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . Improve this question I have heard of people who can do trigonometric functions by hand, without a calculator. I know that, for example, $\sin(\theta)=\text{opposite}/\text{hypotenuse}$ , but calculators can also do $\sin(64.5)$ , and I don't understand how that works. What really is a trigonometric function besides its ratio and how can you solve it by hand? I know that the ratio mentioned above can be used to create relationships between sides and angles, but what is the core definition of the function $\sin(x)$ ? I also know that if you graph $\sin(x)$ , you get the wavy sinusoid but again, what is the function definition?","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 2 years ago . Improve this question I have heard of people who can do trigonometric functions by hand, without a calculator. I know that, for example, , but calculators can also do , and I don't understand how that works. What really is a trigonometric function besides its ratio and how can you solve it by hand? I know that the ratio mentioned above can be used to create relationships between sides and angles, but what is the core definition of the function ? I also know that if you graph , you get the wavy sinusoid but again, what is the function definition?",\sin(\theta)=\text{opposite}/\text{hypotenuse} \sin(64.5) \sin(x) \sin(x),"['functions', 'trigonometry', 'definition']"
73,Prove that there is a number that is not square-free,Prove that there is a number that is not square-free,,"How do I prove that for any polynomial $f(x) \in \mathbb{Z}[x], \operatorname{deg} f \geq 1$ , there are infinitely many $n$ , such that $f(n)$ is not squarefree? I have two solutions, one of them is good, correct and quite ""straightforward"", but the second is very controversial, and I want you to explain to me why it does not work. $1)$ For large $n, f(n)$ becomes a large integer so is divisible by some prime $p$ say. This means that the polynomial $f(X)$ modulo $p$ factors as $f(X) \equiv(X-n) g(X) \bmod p$ . There are two cases to consider. $f(n) \equiv 0 \bmod p^{2}$ $f(n) \not \equiv 0 \bmod p^{2}$ which means that $g(n) \not \equiv 0 \bmod p$ . In the first case $f(n)$ is not square free. In the second case, the derivative $f^{\prime}(x)$ satisfies $f^{\prime}(n) \not \equiv 0 \bmod p$ , so we can use Hensel's lemma to find an $n^{\prime} \equiv n \bmod p$ for which $f\left(n^{\prime}\right) \equiv 0 \bmod p^{2}$ . This means that $f\left(n^{\prime}\right)$ is not square free. I liked this solution, I also have a question: is it necessary to add a restriction on the number $p$ here, it must be taken large enough so that the derivative of the polynomial modulo $p$ does not become identically zero, then everything works? $2)$ Consider the polynomial $f(x)=c_{k} x^{k}+c_{k-1} x^{k-1}+\ldots+c_{1} x^{1}+c_{0}$ , where $f(x) \in \mathbb{Z}[x], \operatorname{deg} f \geq 1$ . For any non-squarefree $f(n)$ there are exactly $\operatorname{deg} f$ such $n$ that $f(n)=c_{k} n^{k}+c_{k-1} n^{k-1}+\ldots+c_{1} n^{1}+c_{0}$ - this equality is true (by the fundamental theorem of algebra). This means that since there are infinitely many non-square-free $f(n)$ , there also exist infinitely many $n$ , that the number $f(n)$ is not square-free.","How do I prove that for any polynomial , there are infinitely many , such that is not squarefree? I have two solutions, one of them is good, correct and quite ""straightforward"", but the second is very controversial, and I want you to explain to me why it does not work. For large becomes a large integer so is divisible by some prime say. This means that the polynomial modulo factors as . There are two cases to consider. which means that . In the first case is not square free. In the second case, the derivative satisfies , so we can use Hensel's lemma to find an for which . This means that is not square free. I liked this solution, I also have a question: is it necessary to add a restriction on the number here, it must be taken large enough so that the derivative of the polynomial modulo does not become identically zero, then everything works? Consider the polynomial , where . For any non-squarefree there are exactly such that - this equality is true (by the fundamental theorem of algebra). This means that since there are infinitely many non-square-free , there also exist infinitely many , that the number is not square-free.","f(x) \in \mathbb{Z}[x], \operatorname{deg} f \geq 1 n f(n) 1) n, f(n) p f(X) p f(X) \equiv(X-n) g(X) \bmod p f(n) \equiv 0 \bmod p^{2} f(n) \not \equiv 0 \bmod p^{2} g(n) \not \equiv 0 \bmod p f(n) f^{\prime}(x) f^{\prime}(n) \not \equiv 0 \bmod p n^{\prime} \equiv n \bmod p f\left(n^{\prime}\right) \equiv 0 \bmod p^{2} f\left(n^{\prime}\right) p p 2) f(x)=c_{k} x^{k}+c_{k-1} x^{k-1}+\ldots+c_{1} x^{1}+c_{0} f(x) \in \mathbb{Z}[x], \operatorname{deg} f \geq 1 f(n) \operatorname{deg} f n f(n)=c_{k} n^{k}+c_{k-1} n^{k-1}+\ldots+c_{1} n^{1}+c_{0} f(n) n f(n)","['elementary-number-theory', 'functions', 'polynomials']"
74,A question on the equivalent statements of countable sets in How to Prove it.,A question on the equivalent statements of countable sets in How to Prove it.,,"In the textbook, it says that given any set $A$ , the following statements are equivalent: A is countable (the author defines a countable set as either being finite or being countably infinite). Either $ A $ is empty or there's a function $ f:\mathbb{Z}^+ \to A$ that is onto. It seems to me that the statement "" $ A $ is empty"" is redundant. If $A$ is empty, isn't the condition ""for every element a in $A$ , there exists an $n \in \mathbb{Z}^+$ with $f(n) = a$ "" (i.e. $f$ is onto) automatically satisfied?? Correct me if I'm wrong. Thanks.","In the textbook, it says that given any set , the following statements are equivalent: A is countable (the author defines a countable set as either being finite or being countably infinite). Either is empty or there's a function that is onto. It seems to me that the statement "" is empty"" is redundant. If is empty, isn't the condition ""for every element a in , there exists an with "" (i.e. is onto) automatically satisfied?? Correct me if I'm wrong. Thanks.",A  A   f:\mathbb{Z}^+ \to A  A  A A n \in \mathbb{Z}^+ f(n) = a f,"['calculus', 'functions', 'solution-verification', 'proof-explanation']"
75,Difference between using max function over functions and over values,Difference between using max function over functions and over values,,"I was wondering if someone could explain what is the difference between the max of a finite number of functions and the max of a finite number of function values. For instance, as shown here , given real-valued continuous functions $f,g$ , the following inequality holds. $\max(f+g)(z)\leq \max f(z)+\max g(z), \forall z \in Z$ . However, if I define the functions $ g= \max_{i \in I}\{g_i\}$ , $ h= \max_{j \in J}\{h_j\}$ , and let $f= g+h$ , then $f$ can be represented as $ f = \max_{i \in I,j \in J}\{g_i+h_j\}$ rather than writing as $f = \max_{i \in I}\{g_i\} + \max_{j \in J}\{h_j\} \leq   \max_{i \in I,j \in J}\{g_i+h_j\}$ . My question is why equality holds when we work with indices. What exactly am I misinterpreting?","I was wondering if someone could explain what is the difference between the max of a finite number of functions and the max of a finite number of function values. For instance, as shown here , given real-valued continuous functions , the following inequality holds. . However, if I define the functions , , and let , then can be represented as rather than writing as . My question is why equality holds when we work with indices. What exactly am I misinterpreting?","f,g \max(f+g)(z)\leq \max f(z)+\max g(z), \forall z \in Z  g= \max_{i \in I}\{g_i\}  h= \max_{j \in J}\{h_j\} f= g+h f  f = \max_{i \in I,j \in J}\{g_i+h_j\} f = \max_{i \in I}\{g_i\} + \max_{j \in J}\{h_j\} \leq   \max_{i \in I,j \in J}\{g_i+h_j\}",['functions']
76,Create a function such that...,Create a function such that...,,"I'm reading Kevin Houston's book ""How to Think Like a Mathematician"" and I came across this stumper: Find an example of a non-polynomial function $f:    \mathbb{R}    \rightarrow \mathbb{R}$ such that $f'(x)$ is negative for $x <0$ and positive for $x \ge 0.$ Some functions that immediately came to mind were $f(x)=|x|$ and $f(x)=-\frac{1}{x^2}$ , but in both of these cases $f'$ is undefined at $x=0$ . It seems to me that a graph of $f'$ will have to include a point at the origin extending into the first (NE) quadrant and contain an piece in the third (SW) quadrant that is asymptotic to the y-axis. We $\textit could$ make a piecewise definition and split $f$ into two parts, but this seems to go against the spirit of the question. Ideas?","I'm reading Kevin Houston's book ""How to Think Like a Mathematician"" and I came across this stumper: Find an example of a non-polynomial function such that is negative for and positive for Some functions that immediately came to mind were and , but in both of these cases is undefined at . It seems to me that a graph of will have to include a point at the origin extending into the first (NE) quadrant and contain an piece in the third (SW) quadrant that is asymptotic to the y-axis. We make a piecewise definition and split into two parts, but this seems to go against the spirit of the question. Ideas?",f:    \mathbb{R}    \rightarrow \mathbb{R} f'(x) x <0 x \ge 0. f(x)=|x| f(x)=-\frac{1}{x^2} f' x=0 f' \textit could f,"['functions', 'derivatives']"
77,Using Monotonicity to find the value of a required variable,Using Monotonicity to find the value of a required variable,,"Given $f(x) = \log_c\frac{x-2}{x+2}$ , is defined $\forall \; x \in [a,b]$ and the function is monotonically decreasing. We have to find the value (or range of values) of $c$ such that there exists $a$ and $b$ , where $(2 < a < b)$ , and the range of the function over $[a,b]$ is $[\log_cc(b-1), \log_cc(a-1)]$ . I have concluded the following: $c \in (0,1)$ Since the function is monotonically decreasing $$f(a) = \log_cc(a-1) \implies \frac{a-2}{a+2} = c(a-1)$$ and $$f(b) = \log_cc(b-1) \implies \frac{b-2}{b+2} = c(b-1)$$ I thought that subtracting the two equations or taking their ratio might help me find some helpful inequality, but unfortunately couldn't find anything. Your help is appreciated. Thanks UPDATE $1$ : We know that $c \in (0,1)$ and $\frac{x-2}{x+2} \in (0,1) \; \forall \; x \in (2, \infty)$ . Hence, the value attained by the function is positive. Thus, $$\log_cc(a-1) > 0 \implies c(a-1) < 1 \implies a < \frac{1}{c} + 1$$ and a similar inequality for $b$ .","Given , is defined and the function is monotonically decreasing. We have to find the value (or range of values) of such that there exists and , where , and the range of the function over is . I have concluded the following: Since the function is monotonically decreasing and I thought that subtracting the two equations or taking their ratio might help me find some helpful inequality, but unfortunately couldn't find anything. Your help is appreciated. Thanks UPDATE : We know that and . Hence, the value attained by the function is positive. Thus, and a similar inequality for .","f(x) = \log_c\frac{x-2}{x+2} \forall \; x \in [a,b] c a b (2 < a < b) [a,b] [\log_cc(b-1), \log_cc(a-1)] c \in (0,1) f(a) = \log_cc(a-1) \implies \frac{a-2}{a+2} = c(a-1) f(b) = \log_cc(b-1) \implies \frac{b-2}{b+2} = c(b-1) 1 c \in (0,1) \frac{x-2}{x+2} \in (0,1) \; \forall \; x \in (2, \infty) \log_cc(a-1) > 0 \implies c(a-1) < 1 \implies a < \frac{1}{c} + 1 b","['functions', 'derivatives', 'monotone-functions']"
78,How do I deal with finding a partition for a specific epsilon?,How do I deal with finding a partition for a specific epsilon?,,"Hello everyone my name is Alice and I am new to this website. Here is the problem I am working on: Let the function f : [0, 1] → R be defined by f(x) = x. Find a partition P of the interval [0, 1] such that the upper sum U(f, P) and the lower sum L(f, P) satisfy the inequality $U\left(f,\:P\right)-L\left(f,P\right)\:<\:\frac{1}{3}$ and I have to show that how I compute or estimate $U(f, P) − L(f, P)$ . Here is my attempt: Let $P = \{x_0, ..., x_i\}$ be any partition of $[0, 1]$ Using the definition of upper sum and lower sum: $ L(f,P) = \sum^n_{i=1}m_i(x_i - x_{i-1})$ here $m_i$ is the infimum of $f(x)$ in the interval $[x_{i-1}, x_i].$ And same thing for upper sum but we have supremum instead. Since we have $f(x) = x$ , which is a increasing function, so the infimum of the interval $[x_{i-1}, x_i]$ will always be $x_{i-1}$ and the supremum of the interval will always be $x_i$ so rewriting the definition of the upper sum and the lower sum, I get: $ L(f,P) = \sum^n_{i=1} x_{i-1}(x_i - x_{i-1})$ $ U(f,P) = \sum^n_{i=1} x_i(x_i - x_{i-1})$ $ U(f,P) - L(f,P) = \sum^n_{i=1} x_i(x_i - x_{i-1}) - \sum^n_{i=1} x_{i-1}(x_i - x_{i-1})$ here I am allowed to factor out the summation symbol right? $= \sum^n_{i=1}(x_i - x_{i-1})(x_i - x_{i-1})$ This is where I am stuck, I need to show that this expression is less than $\frac{1}{3}$ but I am not sure how to create an inequality. Maybe I need this: $ 0 < x_0 < x_i < x_n = 1$ ? I am not sure. It will be really nice if someone can help me tq- Alice","Hello everyone my name is Alice and I am new to this website. Here is the problem I am working on: Let the function f : [0, 1] → R be defined by f(x) = x. Find a partition P of the interval [0, 1] such that the upper sum U(f, P) and the lower sum L(f, P) satisfy the inequality and I have to show that how I compute or estimate . Here is my attempt: Let be any partition of Using the definition of upper sum and lower sum: here is the infimum of in the interval And same thing for upper sum but we have supremum instead. Since we have , which is a increasing function, so the infimum of the interval will always be and the supremum of the interval will always be so rewriting the definition of the upper sum and the lower sum, I get: here I am allowed to factor out the summation symbol right? This is where I am stuck, I need to show that this expression is less than but I am not sure how to create an inequality. Maybe I need this: ? I am not sure. It will be really nice if someone can help me tq- Alice","U\left(f,\:P\right)-L\left(f,P\right)\:<\:\frac{1}{3} U(f, P) − L(f, P) P = \{x_0, ..., x_i\} [0, 1] 
L(f,P) = \sum^n_{i=1}m_i(x_i - x_{i-1}) m_i f(x) [x_{i-1}, x_i]. f(x) = x [x_{i-1}, x_i] x_{i-1} x_i  L(f,P) = \sum^n_{i=1} x_{i-1}(x_i - x_{i-1})  U(f,P) = \sum^n_{i=1} x_i(x_i - x_{i-1})  U(f,P) - L(f,P) = \sum^n_{i=1} x_i(x_i - x_{i-1}) - \sum^n_{i=1} x_{i-1}(x_i - x_{i-1}) = \sum^n_{i=1}(x_i - x_{i-1})(x_i - x_{i-1}) \frac{1}{3}  0 < x_0 < x_i < x_n = 1","['real-analysis', 'functions', 'solution-verification']"
79,About a family of functions that are linearly independent,About a family of functions that are linearly independent,,"For an integer $k$ , define a function $f_k :  \Bbb R\to \Bbb R$ to take any value on $(k,k+1)$ (not all zero) and $0$ on $\Bbb R\setminus(k,k+1).$ Let $\mathcal F=\{f_k : k\in\mathbb Z\}$ be a family of these functions. Note that the functions in $\mathcal F$ are linearly independent. Now, let $D=\{A_i : i\in \mathbb Z\}$ be collection of subsets of $\mathbb Z$ such that each $A_ i$ is infinite and $|A_i\cap A_j|<\infty$ . Let $$B={\left\{\sum_{k\in A} f_k: A\in D \right\}}.$$ Question: Is B linearly independent? To see that $B$ is linearly independent, by using the definition, we need to show if $$c_1\sum_{k\in A_1} f_k+c_2\sum_{k\in A_2} f_k+\cdots+c_n\sum_{k\in A_n} f_k=0,\tag {1}$$ then $c_1=c_2=\cdots=c_n=0.$ As in the assumption about elements in $D,$ we may have like $A_1\cap A_2=\{1,2,\dots, m\}.$ So, the first two terms can be written like that $$(c_1+c_2)(f_1+f_2+\cdots+f_m)+ c_1\sum_{k\in A_1\setminus(A_1\cap A_2)} f_k+c_2\sum_{k\in A_2\setminus(A_1\cap A_2)} f_k.$$ Here is where I got stuck. Should I consider cases for each $A_i$ ? I might be making it more difficult than it could be. Any help would be greatly appreciated.","For an integer , define a function to take any value on (not all zero) and on Let be a family of these functions. Note that the functions in are linearly independent. Now, let be collection of subsets of such that each is infinite and . Let Question: Is B linearly independent? To see that is linearly independent, by using the definition, we need to show if then As in the assumption about elements in we may have like So, the first two terms can be written like that Here is where I got stuck. Should I consider cases for each ? I might be making it more difficult than it could be. Any help would be greatly appreciated.","k f_k :  \Bbb R\to \Bbb R (k,k+1) 0 \Bbb R\setminus(k,k+1). \mathcal F=\{f_k : k\in\mathbb Z\} \mathcal F D=\{A_i : i\in \mathbb Z\} \mathbb Z A_ i |A_i\cap A_j|<\infty B={\left\{\sum_{k\in A} f_k: A\in D \right\}}. B c_1\sum_{k\in A_1} f_k+c_2\sum_{k\in A_2} f_k+\cdots+c_n\sum_{k\in A_n} f_k=0,\tag {1} c_1=c_2=\cdots=c_n=0. D, A_1\cap A_2=\{1,2,\dots, m\}. (c_1+c_2)(f_1+f_2+\cdots+f_m)+ c_1\sum_{k\in A_1\setminus(A_1\cap A_2)} f_k+c_2\sum_{k\in A_2\setminus(A_1\cap A_2)} f_k. A_i","['linear-algebra', 'functions', 'vector-spaces']"
80,Question on Taylor theorem (for $n+1$ differentiable function),Question on Taylor theorem (for  differentiable function),n+1,"Taylor's theorem says the following: Let $f:\mathbb{R}\to \mathbb{R}$ $n+1$ times differentiable on $]a,b[$ and $x_0 \in ]a,b[$ . Then, $\forall x \in ]a,b[ \ \exists y \in ]x_0,x[$ s.t $f(x)=\sum_{k=0}^{n}\frac{f^{(k)}(x_0)}{k!}(x-x_0)^k+\frac{f^{(n+1)}(y)}{(n+1)!}(x-x_0)^{n+1}$ where $\frac{f^{(n+1)}(y)}{(n+1)!}(x-x_0)^{n+1}$ is the rest. Moreover, if $f^{(n+1)}$ is continuous on $[a,b]$ , we have that $\frac{f^{(n+1)}(y)}{(n+1)!}(x-x_0)^{n+1}=o(|x-x_0|^n)$ . So, now i have a question: In one of my exercices I have a function $f \in C^3$ such that at $x_0$ the function has a minimum and $f''(x_0)=0$ (the goal is to show then that $f'''(x_0)=0$ or not, but It is not my question). In corrections the function $f$ in a neighborhood of $x_0$ is written as the following (we put $x=x_0+h$ ) $f(x_0+h)=f(x_0)+\frac{1}{6}f'''(x_0)h^3+o(h^3)$ What I don't understand, is how we get the previous equality. By Taylor's theorem, we can express $f$ as the following: $f(x_0+h)=f(x_0)+\frac{f'''(y)}{3!}(x-x_0)^{n+1} $ for some $y \in ]x_0,x[$ . I don't understand how to get the same equality as before. Thank you in advance for help.","Taylor's theorem says the following: Let times differentiable on and . Then, s.t where is the rest. Moreover, if is continuous on , we have that . So, now i have a question: In one of my exercices I have a function such that at the function has a minimum and (the goal is to show then that or not, but It is not my question). In corrections the function in a neighborhood of is written as the following (we put ) What I don't understand, is how we get the previous equality. By Taylor's theorem, we can express as the following: for some . I don't understand how to get the same equality as before. Thank you in advance for help.","f:\mathbb{R}\to \mathbb{R} n+1 ]a,b[ x_0 \in ]a,b[ \forall x \in ]a,b[ \ \exists y \in ]x_0,x[ f(x)=\sum_{k=0}^{n}\frac{f^{(k)}(x_0)}{k!}(x-x_0)^k+\frac{f^{(n+1)}(y)}{(n+1)!}(x-x_0)^{n+1} \frac{f^{(n+1)}(y)}{(n+1)!}(x-x_0)^{n+1} f^{(n+1)} [a,b] \frac{f^{(n+1)}(y)}{(n+1)!}(x-x_0)^{n+1}=o(|x-x_0|^n) f \in C^3 x_0 f''(x_0)=0 f'''(x_0)=0 f x_0 x=x_0+h f(x_0+h)=f(x_0)+\frac{1}{6}f'''(x_0)h^3+o(h^3) f f(x_0+h)=f(x_0)+\frac{f'''(y)}{3!}(x-x_0)^{n+1}  y \in ]x_0,x[","['functions', 'derivatives', 'polynomials', 'taylor-expansion']"
81,How to show a function $f$ defined on $\mathbb{R}$ is constant if it satisfies $f(x) + 3f(1-x) = 5$,How to show a function  defined on  is constant if it satisfies,f \mathbb{R} f(x) + 3f(1-x) = 5,"Let f be a real valued function on $\mathbb{R}$ . If for all real $x$ ,it satisfies $$ f(x) + 3f(1-x) = 5$$ Then show that f is a constant function. I tried it like this but not sure whether it is true or not. $$ f(x) + 3f(1-x) = 5\tag 1$$ replace $x$ with $1-x$ , $$f(1-x) + 3f(x) = 5\tag 2$$ Then solving (1) and (2) we get $f(x) = \frac{5}{4}$ for all $x\in \mathbb{R}$ . Hence $f$ is a constant function.","Let f be a real valued function on . If for all real ,it satisfies Then show that f is a constant function. I tried it like this but not sure whether it is true or not. replace with , Then solving (1) and (2) we get for all . Hence is a constant function.",\mathbb{R} x  f(x) + 3f(1-x) = 5  f(x) + 3f(1-x) = 5\tag 1 x 1-x f(1-x) + 3f(x) = 5\tag 2 f(x) = \frac{5}{4} x\in \mathbb{R} f,['functions']
82,Partially inverting a function,Partially inverting a function,,"Say I had a function $f:\mathbb{R}_x\rightarrow\mathbb{R}_z$ with $z=f(x)=x+1$ (the subscripts on the $\mathbb{R}$ are just there to indicate which variable corresponds to which space). Since $f$ is bijective, I could define the inverse as $f^{-1}:\mathbb{R}_z\rightarrow\mathbb{R}_x$ with $x=f^{-1}(z)=z-1$ . The key property of an inverse is that $\forall x \in \mathbb{R}_x\,,\ f^{-1}(f(x))=x$ . Now suppose I had a function $f:\mathbb{R}_x\times\mathbb{R}_y\rightarrow\mathbb{R}_z$ with $z=f(x,y)=x+y$ . I can't really have an inverse because the map is not bijective, e.g. both $f(1,0)$ and $f(0,1)$ map to $1$ . However, for a project I'm working on, it would be useful to talk about a ""partial"" or ""weak"" inverse. For instance, with just $z$ I can't recover any inputs, but with both $z$ and $x$ I could recover $y$ . So I could think of a partial/weak inverse as a function $f^{-1}_{\mathbb{R}_x}:\mathbb{R}_x\times\mathbb{R}_z\rightarrow\mathbb{R}_y$ with $y=f^{-1}_{\mathbb{R}_x}(z,x) = z-x$ . This function is bijective, and $\forall x \in \mathbb{R}_x$ and $\forall y \in \mathbb{R}_y$ , $f^{-1}_{\mathbb{R}_x}(f(x,y),x)=(x+y)-x=y$ , which is not exactly the inverse property, but useful (for us at least) nonetheless. Is there an existing name and notation for this kind of partial/weak inverse? Or is it something we'll just have to make up and define?","Say I had a function with (the subscripts on the are just there to indicate which variable corresponds to which space). Since is bijective, I could define the inverse as with . The key property of an inverse is that . Now suppose I had a function with . I can't really have an inverse because the map is not bijective, e.g. both and map to . However, for a project I'm working on, it would be useful to talk about a ""partial"" or ""weak"" inverse. For instance, with just I can't recover any inputs, but with both and I could recover . So I could think of a partial/weak inverse as a function with . This function is bijective, and and , , which is not exactly the inverse property, but useful (for us at least) nonetheless. Is there an existing name and notation for this kind of partial/weak inverse? Or is it something we'll just have to make up and define?","f:\mathbb{R}_x\rightarrow\mathbb{R}_z z=f(x)=x+1 \mathbb{R} f f^{-1}:\mathbb{R}_z\rightarrow\mathbb{R}_x x=f^{-1}(z)=z-1 \forall x \in \mathbb{R}_x\,,\ f^{-1}(f(x))=x f:\mathbb{R}_x\times\mathbb{R}_y\rightarrow\mathbb{R}_z z=f(x,y)=x+y f(1,0) f(0,1) 1 z z x y f^{-1}_{\mathbb{R}_x}:\mathbb{R}_x\times\mathbb{R}_z\rightarrow\mathbb{R}_y y=f^{-1}_{\mathbb{R}_x}(z,x) = z-x \forall x \in \mathbb{R}_x \forall y \in \mathbb{R}_y f^{-1}_{\mathbb{R}_x}(f(x,y),x)=(x+y)-x=y","['functions', 'notation', 'inverse', 'inverse-function']"
83,"How to draw a graph f(x,y) in (x,y) plane","How to draw a graph f(x,y) in (x,y) plane",,"Is there possible way to  draw function $\vec{f}: R^2 \to R^2 $ such as like $\vec{f}(x,y) = \sin x+ \sin y, y+\sin x\ $ and other $\vec{f}(x,y)$ in $xy$ -corordinate instead of $xyz$ plane. Is it okay to do it on some online graphers like symbolab and desmos? Thank a lot!",Is there possible way to  draw function such as like and other in -corordinate instead of plane. Is it okay to do it on some online graphers like symbolab and desmos? Thank a lot!,"\vec{f}: R^2 \to R^2  \vec{f}(x,y) = \sin x+ \sin y, y+\sin x\  \vec{f}(x,y) xy xyz","['functions', 'vectors', 'visualization']"
84,How is this function surjective? (Double Counting),How is this function surjective? (Double Counting),,"We call a positive integer $n$ ""good"" if and only if , in a $6 \cdot 6$ checkerboard , no matter how we put $n$ $1 \cdot 2$ dominoes in the board, there will be a space for another domino (There will be a $1 \cdot 2$ or $2 \cdot 1$ space). Find the maximum ""good"" integer. I think the answer is $11$ . Here's my work. Section 1 : 12 isn't ""good"" . As you can see, this is a figure that shows $12$ isn't ""good"". Section 2 : 11 is ""good"" (Where I'm stuck) So, I learn this and my teacher solution is as follows, First, assume some counterexample exists. Let $A$ be sets of all spaces in the upper $5 \cdot 6$ board. Let $B$ be sets of all spaces in the lower $1 \cdot 6$ board. If $|B| \geq 4$ ; there will be two spaces that are connected , a contradiction. So, $|B| \leq 3$ Since there are a total of $36 - 2(11) = 14$ spaces. Hence, $|A| \geq 11$ . Let $C$ be sets of all dominoes that are fully included in the lower $5 \cdot 6$ board. Now, assume that , there exists some space in $A$ that there is no domino below it. This will create a $1 \cdot 2$ space which we can put another domino. A contradiction. So, there will always be a domino below a space in $A$ . We define a function $f : A \rightarrow C$ such that $f(t) = $ domino below $t$ $\space$ $\forall t \in A$ Now, my teacher says that this function is bijective , so $|C| = |A| \geq 11$ . But maximum number of dominos is $11$ , $|C| = 11$ . But if we consider the upper $1 \cdot 6$ board, we can easily put a domino in it. Hence, a contradiction. So, $11$ is ""good"". My question From Section 2, I think I can show the injective part, Let $f(a_1) = f(a_2) =$ domino ""m"" Case I : ""m"" is horizontal. Now, if $a_1$ is the left space above ""m"" and $a_2$ is the right space of ""m"" , we can put another domino above ""m"", a contradiction. So, $a_1 = a_2$ . Case II : ""m"" is vertical. This case is obvious. Thus, $f$ is injective. I know we can finish the problem using only injectivity and change $|C| = |A|$ to $|C| \geq |A|$ and finish the problem. But I can't figure out how $f$ is surjective. Can anyone give me a hint or a solution. Thanks in advance.","We call a positive integer ""good"" if and only if , in a checkerboard , no matter how we put dominoes in the board, there will be a space for another domino (There will be a or space). Find the maximum ""good"" integer. I think the answer is . Here's my work. Section 1 : 12 isn't ""good"" . As you can see, this is a figure that shows isn't ""good"". Section 2 : 11 is ""good"" (Where I'm stuck) So, I learn this and my teacher solution is as follows, First, assume some counterexample exists. Let be sets of all spaces in the upper board. Let be sets of all spaces in the lower board. If ; there will be two spaces that are connected , a contradiction. So, Since there are a total of spaces. Hence, . Let be sets of all dominoes that are fully included in the lower board. Now, assume that , there exists some space in that there is no domino below it. This will create a space which we can put another domino. A contradiction. So, there will always be a domino below a space in . We define a function such that domino below Now, my teacher says that this function is bijective , so . But maximum number of dominos is , . But if we consider the upper board, we can easily put a domino in it. Hence, a contradiction. So, is ""good"". My question From Section 2, I think I can show the injective part, Let domino ""m"" Case I : ""m"" is horizontal. Now, if is the left space above ""m"" and is the right space of ""m"" , we can put another domino above ""m"", a contradiction. So, . Case II : ""m"" is vertical. This case is obvious. Thus, is injective. I know we can finish the problem using only injectivity and change to and finish the problem. But I can't figure out how is surjective. Can anyone give me a hint or a solution. Thanks in advance.",n 6 \cdot 6 n 1 \cdot 2 1 \cdot 2 2 \cdot 1 11 12 A 5 \cdot 6 B 1 \cdot 6 |B| \geq 4 |B| \leq 3 36 - 2(11) = 14 |A| \geq 11 C 5 \cdot 6 A 1 \cdot 2 A f : A \rightarrow C f(t) =  t \space \forall t \in A |C| = |A| \geq 11 11 |C| = 11 1 \cdot 6 11 f(a_1) = f(a_2) = a_1 a_2 a_1 = a_2 f |C| = |A| |C| \geq |A| f,"['combinatorics', 'functions', 'chessboard']"
85,Is there a standard name for this definition?,Is there a standard name for this definition?,,"Consider an n-ary function from a set $S$ to itself. For a specific example consider the function from $\mathbb{R}^2$ to $\mathbb{R}$ defined by the formula $xy^2$ . I define a reduction of that function to be a function where you hold zero or more variables constant. So for example, the reductions of that function are $xy^2$ , $cx^2$ (where $c$ is an arbitrary real number), $px$ (where $p$ is an arbitrary non-negative number), and nullary functions $r$ , where $r$ is an arbitrary real number. Is there a standard name for this definition?","Consider an n-ary function from a set to itself. For a specific example consider the function from to defined by the formula . I define a reduction of that function to be a function where you hold zero or more variables constant. So for example, the reductions of that function are , (where is an arbitrary real number), (where is an arbitrary non-negative number), and nullary functions , where is an arbitrary real number. Is there a standard name for this definition?",S \mathbb{R}^2 \mathbb{R} xy^2 xy^2 cx^2 c px p r r,"['functions', 'terminology']"
86,Find a bijection $g:\mathbb{R} \longrightarrow \mathbb{R}\setminus \{0\}$,Find a bijection,g:\mathbb{R} \longrightarrow \mathbb{R}\setminus \{0\},"Find an explicit bijection $g:\mathbb{R} \longrightarrow \mathbb{R}\setminus \{0\}$ . I'm sure I'm close to figuring this one out, but not quite there yet. My first idea was $g(x) =          \begin{cases}         x+1, \text{if } x\geq0 \\         x, \text{if } x<0\\         \end{cases}$ , but this is not surjective (eg. 1/2) I think I'm getting mixed up when creating this map because since I can't map 0 to itself, I have to map it to something else, which means that I can't map that thing to itself either lest the function be noninjective, and so on. To fix this problem I was also thinking along the lines of $g(x) =          \begin{cases}         x+1, \text{ if } x \in \mathbb{N} \\         x, \text{if } x \in \mathbb{R} \setminus \mathbb{N}\\         \end{cases}$ where $\mathbb{N}$ denotes the non-negative integers.","Find an explicit bijection . I'm sure I'm close to figuring this one out, but not quite there yet. My first idea was , but this is not surjective (eg. 1/2) I think I'm getting mixed up when creating this map because since I can't map 0 to itself, I have to map it to something else, which means that I can't map that thing to itself either lest the function be noninjective, and so on. To fix this problem I was also thinking along the lines of where denotes the non-negative integers.","g:\mathbb{R} \longrightarrow \mathbb{R}\setminus \{0\} g(x) = 
        \begin{cases}
        x+1, \text{if } x\geq0 \\
        x, \text{if } x<0\\
        \end{cases} g(x) = 
        \begin{cases}
        x+1, \text{ if } x \in \mathbb{N} \\
        x, \text{if } x \in \mathbb{R} \setminus \mathbb{N}\\
        \end{cases} \mathbb{N}","['calculus', 'functions']"
87,"Bijections $f: \mathcal{P}(S) \to \{0,1\}^S$",Bijections,"f: \mathcal{P}(S) \to \{0,1\}^S","I'm trying to understand my professor's lecture notes, but I can't tell whether he's defining two bijective functions in both directions or two injective maps and invoking Shroder Bernstein. Let $S$ be a set, $\mathcal{P}(S)$ its power set, and $\{0,1\}^S$ the set of functions from $S \to \{0,1\}$ . Define two maps: \begin{align*} & f \colon \mathcal{P}(S) \to \{0,1\}^S, \; A \mapsto I_A \\ & g \colon \{0,1\}^S \to \mathcal{P}(S), \; f \to f^{-1} (1), \end{align*} where $I_A$ is the indicator function that sends $x \in A$ to $1$ and $x \not \in A$ to $0$ . I believe both $f$ and $g$ are bijective. We show $f$ is bijective. Given a function, call it $h: S \to \{0,1\}$ . define $A = h^{-1} (1)$ . It's clear that $h = I_A$ ; indeed, for $x \in S$ , we have $h(x) = I_A (x) = 1$ and for $x \not \in S$ , we have $h(x) = I_A (x) = 0$ , so $h(x) = I_A (x)$ for all $x \in S$ , so $f$ is surjective. Second, given $A,B$ for which $f(A) = f(B)$ , we have $I_A = I_B$ . I claim $A = B$ . If $x \in A$ , then we have $I_A (x) = I_B (x) = 1$ , so $x \in B$ . Similarly, if $x \in B$ , we have $I_A (x) = I_B (x) = 1$ , so $x \in A$ , so $A = B$ . So $f$ is injective, and hence bijective. Now for $g$ . We show that $g$ is bijective. Let $A \in \mathcal{P}(S)$ . Then $g\left(I_A\right) = A$ , so $g$ is surjective. If $f,g \in \{0,1\}^S$ have the property that $f^{-1} (1) = g^{-1} (1)$ , then $f^{-1} (0) = g^{-1} (0)$ since the domain of $f,g$ is $\{0,1\}$ , so $f = g$ , so $g$ is bijective. I can't tell if $f$ and $g$ are inverses of each other, though they both seem to be bijective.","I'm trying to understand my professor's lecture notes, but I can't tell whether he's defining two bijective functions in both directions or two injective maps and invoking Shroder Bernstein. Let be a set, its power set, and the set of functions from . Define two maps: where is the indicator function that sends to and to . I believe both and are bijective. We show is bijective. Given a function, call it . define . It's clear that ; indeed, for , we have and for , we have , so for all , so is surjective. Second, given for which , we have . I claim . If , then we have , so . Similarly, if , we have , so , so . So is injective, and hence bijective. Now for . We show that is bijective. Let . Then , so is surjective. If have the property that , then since the domain of is , so , so is bijective. I can't tell if and are inverses of each other, though they both seem to be bijective.","S \mathcal{P}(S) \{0,1\}^S S \to \{0,1\} \begin{align*}
& f \colon \mathcal{P}(S) \to \{0,1\}^S, \; A \mapsto I_A \\
& g \colon \{0,1\}^S \to \mathcal{P}(S), \; f \to f^{-1} (1),
\end{align*} I_A x \in A 1 x \not \in A 0 f g f h: S \to \{0,1\} A = h^{-1} (1) h = I_A x \in S h(x) = I_A (x) = 1 x \not \in S h(x) = I_A (x) = 0 h(x) = I_A (x) x \in S f A,B f(A) = f(B) I_A = I_B A = B x \in A I_A (x) = I_B (x) = 1 x \in B x \in B I_A (x) = I_B (x) = 1 x \in A A = B f g g A \in \mathcal{P}(S) g\left(I_A\right) = A g f,g \in \{0,1\}^S f^{-1} (1) = g^{-1} (1) f^{-1} (0) = g^{-1} (0) f,g \{0,1\} f = g g f g","['functions', 'solution-verification']"
88,Function of at most polynomial growth and its derivative,Function of at most polynomial growth and its derivative,,"I consider a function $f:\mathbb{R}^{+} \rightarrow \mathbb{R}$ which is continuous and differentiable. I know moreover that both $f$ and $f'$ are of at most polynomial growth, i.e. I use the following definition: The function $g$ is of at most polynomial growth if there exist constants $m$ and $C$ such that $$ |g(x)|\leq C (x^{-m} + x^m) $$ for all $x \in \mathbb{R}^{+}$ . My question is: Is there any relation in the degree of polynomial $m$ occuring in the above equation for $f$ and $f'$ if we know that that both are of at most polynomial growth? My intuition is that if $f$ is bounded by a polynomial of degree $m$ , then $f'$ is bounded by a polynomial of degree $m-1$ . Is this statement true?","I consider a function which is continuous and differentiable. I know moreover that both and are of at most polynomial growth, i.e. I use the following definition: The function is of at most polynomial growth if there exist constants and such that for all . My question is: Is there any relation in the degree of polynomial occuring in the above equation for and if we know that that both are of at most polynomial growth? My intuition is that if is bounded by a polynomial of degree , then is bounded by a polynomial of degree . Is this statement true?","f:\mathbb{R}^{+} \rightarrow \mathbb{R} f f' g m C 
|g(x)|\leq C (x^{-m} + x^m)
 x \in \mathbb{R}^{+} m f f' f m f' m-1","['functions', 'polynomials', 'asymptotics']"
89,How to show this function is bijective?,How to show this function is bijective?,,"I want to show $$ (0,1)\sim(0,1)∩(R-Q) $$ And after reading and thinking about this answer : (1) Choose an infinite countable set of irrational numbers in $(0,1)$ , call them $(r_n)_{n\geqslant0}$ . (2) Enumerate the rational numbers in $(0,1)$ as $(q_n)_{n\geqslant0}$ . (3) Define $f$ by $f(q_n)=r_{2n+1}$ for every $n\geqslant0$ , $f(r_n)=r_{2n}$ for every $n\geqslant0$ , >and $f(x)=x$ for every irrational number $x$ which does not appear in the sequence  > $(r_n)_{n\geqslant0}$ . Let me suggest you take it from here and show that $f$ is a bijection between $(0,1)$ and $(0,1)\setminus\mathbb Q$ . I wanted to show f is bijection (injective + surjective) ,and first I tried to show thats injective: I must show : $$(r_{2n+1}=r_{2n+1}')~→~(q_n=q_n')$$ And: $$(r_{2n}=r_{2n}')~→~(r_n=r_n')$$ And third one is obvious. But I stucked here because this function is new to me...and I cannot show the relation between $r_{2n+1}$ and $q_n$ in order to conclude injection statements . And moreover , because of this problem(relation understanding) I cannot show thats a surjection too... Could someone help me please?","I want to show And after reading and thinking about this answer : (1) Choose an infinite countable set of irrational numbers in , call them . (2) Enumerate the rational numbers in as . (3) Define by for every , for every , >and for every irrational number which does not appear in the sequence  > . Let me suggest you take it from here and show that is a bijection between and . I wanted to show f is bijection (injective + surjective) ,and first I tried to show thats injective: I must show : And: And third one is obvious. But I stucked here because this function is new to me...and I cannot show the relation between and in order to conclude injection statements . And moreover , because of this problem(relation understanding) I cannot show thats a surjection too... Could someone help me please?"," (0,1)\sim(0,1)∩(R-Q)  (0,1) (r_n)_{n\geqslant0} (0,1) (q_n)_{n\geqslant0} f f(q_n)=r_{2n+1} n\geqslant0 f(r_n)=r_{2n} n\geqslant0 f(x)=x x (r_n)_{n\geqslant0} f (0,1) (0,1)\setminus\mathbb Q (r_{2n+1}=r_{2n+1}')~→~(q_n=q_n') (r_{2n}=r_{2n}')~→~(r_n=r_n') r_{2n+1} q_n","['functions', 'elementary-set-theory', 'solution-verification']"
90,"Is any proof of ""If $f:[a,b] \to \mathbb{Q}$ is a continuous function then it is constant"" that appeals to the Intermediate Value Theorem incorrect?","Is any proof of ""If  is a continuous function then it is constant"" that appeals to the Intermediate Value Theorem incorrect?","f:[a,b] \to \mathbb{Q}","It seems to me that any proof of If $I\subseteq \mathbb{R}$ is an interval and $h:I\to\mathbb{Q}$ is continuous, then it is constant $\hspace{4mm}$ ( $\ast$ ) or variants thereof that invokes the Intermediate Value Theorem (IVT) is incorrect because (as far as I'm aware) the proofs I've seen of the IVT relies on the fact that the image of $f$ must be connected. However if the codomain of $f$ is already restricted to $\mathbb{Q}$ (or if we stipulate the image of $f$ to only rational values) then we cannot apply the IVT. Is it just me or am I missing something here? The highest voted answers for these questions below uses the IVT where the first question has been an accepted as an answer. Prove that if $f: \mathbb{R} \to \mathbb{Q}$ is continuous then $f$ is constant Is a rational-valued continuous function $f\colon[0,1]\to\mathbb{R}$ constant? Addendum: Statement of the IVT that I am using: Let $I$ be an interval and suppose $f:I\to\mathbb{R}$ is continuous. If $a,b\in I$ and $y\in\mathbb{R}$ satisfies $f(a)<y<f(b)$ then there is a $c\in (a,b)$ such that $f(c)=y$ I have resolved my confusion and it comes down to the assumption of $f$ having codomain $\mathbb{R}$ in the statement of the IVT. I was thinking that if we had a function, say the one in ( $\ast$ ) where the codomain is $\mathbb{Q}$ then we cannot apply the IVT because it does not meet the assumptions of the theorem, so then I had to look at the proof of the theorem to see if the codomain really had to be $\mathbb{R}$ . In all the proofs I have seen (and I'm sure that almost every proof of the IVT would have this step) there is this step where we suppose that "" $y\in \mathbb{R}$ such that $f(a) < y < f(b)$ "" that caused me to conclude that the codomain had to be $\mathbb{R}$ in order for the IVT to work because $y$ can be irrational, and if $f:I\to\mathbb{Q}$ then how can we conclude that there is a $c\in (a,b)$ such that $f(c)=y$ because $f$ can only take rational values? That erroneously caused me to conclude that the assumption that the function has codomain $\mathbb{R}$ had to be the case. However, this is exactly the flaw in my thinking because as stated in the comments, the codomain does not exactly have to be $\mathbb{R}$ but as long as it is a subset of $\mathbb{R}$ . Thus, the IVT should really be of the form Let $I$ be an interval and $S\subseteq \mathbb{R}$ . Suppose $f:I\to S$ is continuous. If $a,b\in I$ and $y\in\mathbb{R}$ satisfies $f(a)<y<f(b)$ then there is a $c\in (a,b)$ such that $f(c)=y$ . Hence, $S$ is just some arbitrary subset of $\mathbb{R}$ and in proving the theorem we conclude that $S$ had to in fact be an interval. That's why I had my qualm as to why we can use the IVT to prove ( $\ast$ ) since $h$ does not meet the assumptions of the theorem since the codomain of $h$ is $\mathbb{Q}$ . Now some may ask, but since $\mathbb{Q} \subseteq \mathbb{R}$ then surely the IVT can still be applied to any function who's codomain is a subset of $\mathbb{R}$ . I'm not sure if in general we can do this even though in the case of the IVT it happens to be fine?","It seems to me that any proof of If is an interval and is continuous, then it is constant ( ) or variants thereof that invokes the Intermediate Value Theorem (IVT) is incorrect because (as far as I'm aware) the proofs I've seen of the IVT relies on the fact that the image of must be connected. However if the codomain of is already restricted to (or if we stipulate the image of to only rational values) then we cannot apply the IVT. Is it just me or am I missing something here? The highest voted answers for these questions below uses the IVT where the first question has been an accepted as an answer. Prove that if $f: \mathbb{R} \to \mathbb{Q}$ is continuous then $f$ is constant Is a rational-valued continuous function $f\colon[0,1]\to\mathbb{R}$ constant? Addendum: Statement of the IVT that I am using: Let be an interval and suppose is continuous. If and satisfies then there is a such that I have resolved my confusion and it comes down to the assumption of having codomain in the statement of the IVT. I was thinking that if we had a function, say the one in ( ) where the codomain is then we cannot apply the IVT because it does not meet the assumptions of the theorem, so then I had to look at the proof of the theorem to see if the codomain really had to be . In all the proofs I have seen (and I'm sure that almost every proof of the IVT would have this step) there is this step where we suppose that "" such that "" that caused me to conclude that the codomain had to be in order for the IVT to work because can be irrational, and if then how can we conclude that there is a such that because can only take rational values? That erroneously caused me to conclude that the assumption that the function has codomain had to be the case. However, this is exactly the flaw in my thinking because as stated in the comments, the codomain does not exactly have to be but as long as it is a subset of . Thus, the IVT should really be of the form Let be an interval and . Suppose is continuous. If and satisfies then there is a such that . Hence, is just some arbitrary subset of and in proving the theorem we conclude that had to in fact be an interval. That's why I had my qualm as to why we can use the IVT to prove ( ) since does not meet the assumptions of the theorem since the codomain of is . Now some may ask, but since then surely the IVT can still be applied to any function who's codomain is a subset of . I'm not sure if in general we can do this even though in the case of the IVT it happens to be fine?","I\subseteq \mathbb{R} h:I\to\mathbb{Q} \hspace{4mm} \ast f f \mathbb{Q} f I f:I\to\mathbb{R} a,b\in I y\in\mathbb{R} f(a)<y<f(b) c\in (a,b) f(c)=y f \mathbb{R} \ast \mathbb{Q} \mathbb{R} y\in \mathbb{R} f(a) < y < f(b) \mathbb{R} y f:I\to\mathbb{Q} c\in (a,b) f(c)=y f \mathbb{R} \mathbb{R} \mathbb{R} I S\subseteq \mathbb{R} f:I\to S a,b\in I y\in\mathbb{R} f(a)<y<f(b) c\in (a,b) f(c)=y S \mathbb{R} S \ast h h \mathbb{Q} \mathbb{Q} \subseteq \mathbb{R} \mathbb{R}","['real-analysis', 'functions', 'continuity', 'connectedness']"
91,Necessary and sufficient conditions for a function of a specific type on the complement of the Cantor set,Necessary and sufficient conditions for a function of a specific type on the complement of the Cantor set,,"The following is an exercise from Bruckner's Real Analysis: For (a) right limit and left limit must be equal and equals $f(c_n)$ I think this is necessary and also sufficient. For (b) because each $f_n(x)$ must be continuous be definition so the limit is of type mentioned in (a). For (c) $\sum_1^∞ |f(c_n)| < ∞ $ is sufficient and necessary as for all $a_n$ , $b_n$ we have $f(a_n)=f(b_n)=0$ . Is my explanation rigorous enough? A detailed explanation for all parts of the question would be much appreciated.","The following is an exercise from Bruckner's Real Analysis: For (a) right limit and left limit must be equal and equals I think this is necessary and also sufficient. For (b) because each must be continuous be definition so the limit is of type mentioned in (a). For (c) is sufficient and necessary as for all , we have . Is my explanation rigorous enough? A detailed explanation for all parts of the question would be much appreciated.",f(c_n) f_n(x) \sum_1^∞ |f(c_n)| < ∞  a_n b_n f(a_n)=f(b_n)=0,"['measure-theory', 'functions']"
92,How do I find the length attained by a bullet when fired by a rifle?,How do I find the length attained by a bullet when fired by a rifle?,,"The problem is as follows: The horizontal range of a bullet fired by a rifle from a certain height above sea level is given by the minimum value of the function presented below: $$f(x)=2\sec\left(\pi x-\frac{\pi}{4}\right)+1$$ in kilometers when, $-\frac{1}{12}\leq x \leq \frac{5}{12}$ With the given information, find the length attained by the bullet. The alternatives given in my workbook are as follows: $\begin{array}{ll} 1.&\textrm{4 km}\\ 2.&\textrm{1 km}\\ 3.&\textrm{3 km}\\ 4.&\textrm{2 km}\\ \end{array}$ What I attempted to do in order to solve this problem was to use the given domain to reconstruct the function and hence having the range, and with that minimum value I can get what it is being asked. In other words the horizontal range of that bullet. Since the domain is in this: $-\frac{1}{12}\leq x \leq \frac{5}{12}$ Then: $-\frac{\pi}{12}\leq \pi x \leq \frac{5\pi}{12}$ $-\frac{\pi}{12}\leq \pi x \leq \frac{5\pi}{12}$ $-\frac{\pi}{12}-\frac{\pi}{4}\leq \pi x - \frac{\pi}{4} \leq \frac{5\pi}{12}-\frac{\pi}{4}$ $-\frac{4\pi}{12}\leq \pi x - \frac{\pi}{4} \leq \frac{2\pi}{12}$ $-\frac{\pi}{3}\leq \pi x - \frac{\pi}{4} \leq \frac{\pi}{6}$ Now here's where it comes the source of controversy. I'm assuming that I can ""take the secant function"" to that interval in order to get the range. Which would yield. $\sec\left(-\frac{\pi}{3}\right)\leq \sec \left(\pi x - \frac{\pi}{4}\right) \leq \sec \left(\frac{\pi}{6}\right)$ Since the negative sign is absorved by the secant function this will generate: $2 \leq \sec \left(\pi x - \frac{\pi}{4}\right) \leq \frac{2}{\sqrt{3}}$ $4 \leq 2\sec \left(\pi x - \frac{\pi}{4}\right) \leq 2\frac{2}{\sqrt{3}}$ $4 +1  \leq 2\sec \left(\pi x - \frac{\pi}{4}\right)+1 \leq \frac{2 \cdot 2}{\sqrt{3}}+1$ The finally: $5  \leq 2\sec \left(\pi x - \frac{\pi}{4}\right)+1 \leq \frac{4}{\sqrt{3}}+1$ But rewritting this doing the rationalization it would be: $5 \leq f(x) \geq \frac{4\sqrt{3}+3}{3}$ Now: $\frac{4\sqrt{3}+3}{3} \approx 3.3094$ But looking at the orientation of the signs it doesn't make sense. How it can possibly be that this result is greater than $4$ ? What went wrong here?. Can someone help me here?. Or is it just that I did not got the right picture?. I can spot that $4\,km$ appears in one of the choices But I have no idea if whether I got to the right answer or some critical concept I missunderstood here. Thus I require help to settle down this contradiction. Help please?. I'd also like to know that since I got this problem in my precalculus workbook I'd like that the answer would follow the similar approach given here and not use derivatives.","The problem is as follows: The horizontal range of a bullet fired by a rifle from a certain height above sea level is given by the minimum value of the function presented below: in kilometers when, With the given information, find the length attained by the bullet. The alternatives given in my workbook are as follows: What I attempted to do in order to solve this problem was to use the given domain to reconstruct the function and hence having the range, and with that minimum value I can get what it is being asked. In other words the horizontal range of that bullet. Since the domain is in this: Then: Now here's where it comes the source of controversy. I'm assuming that I can ""take the secant function"" to that interval in order to get the range. Which would yield. Since the negative sign is absorved by the secant function this will generate: The finally: But rewritting this doing the rationalization it would be: Now: But looking at the orientation of the signs it doesn't make sense. How it can possibly be that this result is greater than ? What went wrong here?. Can someone help me here?. Or is it just that I did not got the right picture?. I can spot that appears in one of the choices But I have no idea if whether I got to the right answer or some critical concept I missunderstood here. Thus I require help to settle down this contradiction. Help please?. I'd also like to know that since I got this problem in my precalculus workbook I'd like that the answer would follow the similar approach given here and not use derivatives.","f(x)=2\sec\left(\pi x-\frac{\pi}{4}\right)+1 -\frac{1}{12}\leq x \leq \frac{5}{12} \begin{array}{ll}
1.&\textrm{4 km}\\
2.&\textrm{1 km}\\
3.&\textrm{3 km}\\
4.&\textrm{2 km}\\
\end{array} -\frac{1}{12}\leq x \leq \frac{5}{12} -\frac{\pi}{12}\leq \pi x \leq \frac{5\pi}{12} -\frac{\pi}{12}\leq \pi x \leq \frac{5\pi}{12} -\frac{\pi}{12}-\frac{\pi}{4}\leq \pi x - \frac{\pi}{4} \leq \frac{5\pi}{12}-\frac{\pi}{4} -\frac{4\pi}{12}\leq \pi x - \frac{\pi}{4} \leq \frac{2\pi}{12} -\frac{\pi}{3}\leq \pi x - \frac{\pi}{4} \leq \frac{\pi}{6} \sec\left(-\frac{\pi}{3}\right)\leq \sec \left(\pi x - \frac{\pi}{4}\right) \leq \sec \left(\frac{\pi}{6}\right) 2 \leq \sec \left(\pi x - \frac{\pi}{4}\right) \leq \frac{2}{\sqrt{3}} 4 \leq 2\sec \left(\pi x - \frac{\pi}{4}\right) \leq 2\frac{2}{\sqrt{3}} 4 +1  \leq 2\sec \left(\pi x - \frac{\pi}{4}\right)+1 \leq \frac{2 \cdot 2}{\sqrt{3}}+1 5  \leq 2\sec \left(\pi x - \frac{\pi}{4}\right)+1 \leq \frac{4}{\sqrt{3}}+1 5 \leq f(x) \geq \frac{4\sqrt{3}+3}{3} \frac{4\sqrt{3}+3}{3} \approx 3.3094 4 4\,km","['algebra-precalculus', 'functions', 'trigonometry', 'maxima-minima']"
93,"Uniform convergence of $\sum\limits_{n=1}^{\infty} (-1)^n \frac{\arctan(x^n)}{\sqrt{n+1}}$ , $x \in[0,\infty)$","Uniform convergence of  ,","\sum\limits_{n=1}^{\infty} (-1)^n \frac{\arctan(x^n)}{\sqrt{n+1}} x \in[0,\infty)","I have a problem with checking the uniform convergence of $\sum\limits_{n=1}^{\infty} (-1)^n \frac{\arctan(x^n)}{\sqrt{n+1}}$ , $x \in[0,\infty)$ . I suppose that using Abel-Dirichlet criterion should help, but I only know, that $\sum\limits_{n=1}^{\infty} \frac{1}{\sqrt{n+1}}$ is monotonically decreasing, non negative and bounded. And that the function $\frac{1}{\sqrt{n+1}}$ converges locally uniformly to $0$ on $(0,\infty)$ (I am also not sure, whether locally uniform convergence is enough for Dirichlet test, or if the uniform convergence on given interval is necessary) . But I am not able to show, that $\sum\limits_{n=1}^{\infty}(-1)^n \arctan(x^n)$ is uniformly convergent on $[0,\infty)$ (Abel) or that it has uniformly bounded partial sums (Dirichlet). Or should I use completely different approach? Thanks for any help.","I have a problem with checking the uniform convergence of , . I suppose that using Abel-Dirichlet criterion should help, but I only know, that is monotonically decreasing, non negative and bounded. And that the function converges locally uniformly to on (I am also not sure, whether locally uniform convergence is enough for Dirichlet test, or if the uniform convergence on given interval is necessary) . But I am not able to show, that is uniformly convergent on (Abel) or that it has uniformly bounded partial sums (Dirichlet). Or should I use completely different approach? Thanks for any help.","\sum\limits_{n=1}^{\infty} (-1)^n \frac{\arctan(x^n)}{\sqrt{n+1}} x \in[0,\infty) \sum\limits_{n=1}^{\infty} \frac{1}{\sqrt{n+1}} \frac{1}{\sqrt{n+1}} 0 (0,\infty) \sum\limits_{n=1}^{\infty}(-1)^n \arctan(x^n) [0,\infty)","['real-analysis', 'sequences-and-series', 'functions', 'convergence-divergence', 'uniform-convergence']"
94,Fourier Sine Series and Fourier Cosine Series,Fourier Sine Series and Fourier Cosine Series,,"A regular Fourier Series will turn out to contain only sine terms if the target function is odd, only cosine terms if the target function is even, and both sine terms and cosine terms if the target function is neither even nor odd. By contrast, my understanding is that Fourier Sine Series and Fourier Cosine Series are completely different animals, and that the mathematician can choose to represent their target function using a regular Fourier Series, a Fourier Sine Series, or a Fourier Cosine Series at their discretion by temporarily introducing a regular extension, odd extension, or even extension, respectively, regardless of the target function's actual even or odd status.  It is perhaps natural to use regular Fourier Series to represent functions within intervals centered around $0$ , and Fourier Sine Series or Fourier Cosine Series to represent functions within intervals whose left boundary is $0$ , but it should be possible to simply $u$ -substitute any finite interval function into either of these forms, do the Fourier Series/Fourier Sine Series/Fourier Cosine Series in $u$ , and then revert the substitution. On the other hand, this would mean that any function (continuous or piecewise smooth, a.k.a., any function that could be represented by a regular Fourier Series) could be represented by a single family of sinusoids, either sines or cosines, which seems to be at odds with the Linear Algebra terminology often associated with Fourier Series.  For example, thinking of the sines and cosines in a Fourier Series as a basis leads me to believe that you should expect to require both to represent an arbitrary function, not just one or the other. Is it always possible to represent any function that could be represented by a regular Fourier Series by your choice of Fourier Sine Series or Fourier Cosine Series?  If so, how is this in concord with the Linear Algebraic explanation of Fourier Series?","A regular Fourier Series will turn out to contain only sine terms if the target function is odd, only cosine terms if the target function is even, and both sine terms and cosine terms if the target function is neither even nor odd. By contrast, my understanding is that Fourier Sine Series and Fourier Cosine Series are completely different animals, and that the mathematician can choose to represent their target function using a regular Fourier Series, a Fourier Sine Series, or a Fourier Cosine Series at their discretion by temporarily introducing a regular extension, odd extension, or even extension, respectively, regardless of the target function's actual even or odd status.  It is perhaps natural to use regular Fourier Series to represent functions within intervals centered around , and Fourier Sine Series or Fourier Cosine Series to represent functions within intervals whose left boundary is , but it should be possible to simply -substitute any finite interval function into either of these forms, do the Fourier Series/Fourier Sine Series/Fourier Cosine Series in , and then revert the substitution. On the other hand, this would mean that any function (continuous or piecewise smooth, a.k.a., any function that could be represented by a regular Fourier Series) could be represented by a single family of sinusoids, either sines or cosines, which seems to be at odds with the Linear Algebra terminology often associated with Fourier Series.  For example, thinking of the sines and cosines in a Fourier Series as a basis leads me to believe that you should expect to require both to represent an arbitrary function, not just one or the other. Is it always possible to represent any function that could be represented by a regular Fourier Series by your choice of Fourier Sine Series or Fourier Cosine Series?  If so, how is this in concord with the Linear Algebraic explanation of Fourier Series?",0 0 u u,"['linear-algebra', 'functions', 'fourier-analysis', 'fourier-series', 'substitution']"
95,Composition $f^n$ is a contraction $\implies f$ possesses a fix point.,Composition  is a contraction  possesses a fix point.,f^n \implies f,"Definition. $x \in \mathbb{R}^n$ is called a fixpoint of the function $f:\mathbb{R}^n \to \mathbb{R}^n$ , if $f(x)=x$ . Notation. $f^n(x) := \underbrace{(f \circ f \circ \cdots \circ f)}_{\text{$n$ times}}(x)$ Definition. A function $f:\mathbb{R}^n \to \mathbb{R}^m$ is called a contraction, if there exists a positive constant $L<1$ such that for all $x,y \in \mathbb{R}^n$ the inequality $$\|f(x)-f(y)\|_{\mathbb{R}^m} \leq L \cdot \|x-y\|_{\mathbb{R}^n} $$ holds. Let $A \subseteq \mathbb{R}$ be a closed subset and $f : A \to A$ . Assume, there exists an $n \in \mathbb{N}$ , such that the $n$ -fold composition $f^n:A \to A$ is a contraction. Can it be shown, that there exists a fixpoint $x^* \in A$ for $f$ ?","Definition. is called a fixpoint of the function , if . Notation. Definition. A function is called a contraction, if there exists a positive constant such that for all the inequality holds. Let be a closed subset and . Assume, there exists an , such that the -fold composition is a contraction. Can it be shown, that there exists a fixpoint for ?","x \in \mathbb{R}^n f:\mathbb{R}^n \to \mathbb{R}^n f(x)=x f^n(x) := \underbrace{(f \circ f \circ \cdots \circ f)}_{\text{n times}}(x) f:\mathbb{R}^n \to \mathbb{R}^m L<1 x,y \in \mathbb{R}^n \|f(x)-f(y)\|_{\mathbb{R}^m} \leq L \cdot \|x-y\|_{\mathbb{R}^n}  A \subseteq \mathbb{R} f : A \to A n \in \mathbb{N} n f^n:A \to A x^* \in A f","['real-analysis', 'functions', 'fixed-point-theorems']"
96,Is the following a Bijective Function?,Is the following a Bijective Function?,,In a bijective function is it necessary that all the elements of the domain correspond to a value in the range? Like for example can the following be a bijective function - If not then what type of function is it?,In a bijective function is it necessary that all the elements of the domain correspond to a value in the range? Like for example can the following be a bijective function - If not then what type of function is it?,,['functions']
97,Symbol for very small variable,Symbol for very small variable,,"Is there any representation to state that a variable is close to (not equal) zero? Let me give you an example. Consider the function $u(x)=\alpha (e^{i\omega \delta t}-1) f(x)$ I am interested in the function $u(x)$ when $\delta t$ is very small. For this case, it should be easy to see that $u(x)|_{\text{small }\delta t} \approx i \alpha \omega \delta t f(x)$ Is there any ""nice"" notation to represent such an equation (without having to write small)? I thought that I could use the limit notation for that [for example, $\lim_{\delta t \to 0} u(t)$ ], but then I realized that if $\delta t$ goes to zero, then $u(x)=0$ . Therefore, it is not what I need. I found this link in the same forum, but it did not help.","Is there any representation to state that a variable is close to (not equal) zero? Let me give you an example. Consider the function I am interested in the function when is very small. For this case, it should be easy to see that Is there any ""nice"" notation to represent such an equation (without having to write small)? I thought that I could use the limit notation for that [for example, ], but then I realized that if goes to zero, then . Therefore, it is not what I need. I found this link in the same forum, but it did not help.",u(x)=\alpha (e^{i\omega \delta t}-1) f(x) u(x) \delta t u(x)|_{\text{small }\delta t} \approx i \alpha \omega \delta t f(x) \lim_{\delta t \to 0} u(t) \delta t u(x)=0,"['limits', 'functions', 'notation']"
98,Finding extremum of quadratic function using factorisation as symmetry operation.,Finding extremum of quadratic function using factorisation as symmetry operation.,,"In this book in Section 3.2.3, the author shows how to find extremum of a quadratic function using an invariant quality and symmetry operation, which preserves it. E.g. to find the extremum of $f(x)=6x-x^2$ we can notice that $f(x)=6x-x^2 = x(6-x) = (6-x)x$ . This operation maps every value $x$ to $6-x$ through the axis of symmetry and vice-versa (e.g. 0 is mapped to 6 and 6 mapped to 0). This operation preserves symmetry for $x=3$ - the axis of symmetry and hence the extremum of the function. What about the function $f(x)=6x+x^2 = x(6+x) = (6+x)x$ ? We know that the minimum of this function is at $x=-3$ but $6+(-3)=3$ . Also this operation maps e.g $4$ to $10$ , but $10$ to $16$ ! Hence, this approach fails with this example (symmetry is not preserved). Why is that so? Why is this approach not working for all the quadratic functions?","In this book in Section 3.2.3, the author shows how to find extremum of a quadratic function using an invariant quality and symmetry operation, which preserves it. E.g. to find the extremum of we can notice that . This operation maps every value to through the axis of symmetry and vice-versa (e.g. 0 is mapped to 6 and 6 mapped to 0). This operation preserves symmetry for - the axis of symmetry and hence the extremum of the function. What about the function ? We know that the minimum of this function is at but . Also this operation maps e.g to , but to ! Hence, this approach fails with this example (symmetry is not preserved). Why is that so? Why is this approach not working for all the quadratic functions?",f(x)=6x-x^2 f(x)=6x-x^2 = x(6-x) = (6-x)x x 6-x x=3 f(x)=6x+x^2 = x(6+x) = (6+x)x x=-3 6+(-3)=3 4 10 10 16,"['algebra-precalculus', 'functions', 'quadratics', 'symmetry']"
99,Need a function that measure the proximity of a given value to a target value,Need a function that measure the proximity of a given value to a target value,,"Like the title says, I'm looking for a function that take a given value, and returns a value between 0 and 1 which measures how much the given value is near to a target value. Ideally, the returned value should increase faster when the target value is almost reached. For example, if the target is 10: Input = 5; output = 0.5 Input = 8; output = 0.85 (more than 0.8 because we are near to the target) Input = 10; output = 1 (of course) Input = 15; output = 0.5 (because we have exceed the target) Any help? EDIT 1 The function only takes non negative numbers. The input number can be at most twice the target number EDIT 2 This is what have I done so far: if (amount <= target)     return amount / target; else if (amount >= 2 * target)     return 0; else     return 1 - ( amount % target ) / target; It's very rudimental, and it doesn't implement the concept of ""speed"". EDIT 3 The goal is to use the function for an automatic optimizer. I have a set of features, and the idea behind is to assign a score to the value assigned to each feature. The more the assigned value is near to the target value, the merrier. I'm using a maximizer to maximize the sum of the scores.","Like the title says, I'm looking for a function that take a given value, and returns a value between 0 and 1 which measures how much the given value is near to a target value. Ideally, the returned value should increase faster when the target value is almost reached. For example, if the target is 10: Input = 5; output = 0.5 Input = 8; output = 0.85 (more than 0.8 because we are near to the target) Input = 10; output = 1 (of course) Input = 15; output = 0.5 (because we have exceed the target) Any help? EDIT 1 The function only takes non negative numbers. The input number can be at most twice the target number EDIT 2 This is what have I done so far: if (amount <= target)     return amount / target; else if (amount >= 2 * target)     return 0; else     return 1 - ( amount % target ) / target; It's very rudimental, and it doesn't implement the concept of ""speed"". EDIT 3 The goal is to use the function for an automatic optimizer. I have a set of features, and the idea behind is to assign a score to the value assigned to each feature. The more the assigned value is near to the target value, the merrier. I'm using a maximizer to maximize the sum of the scores.",,"['functions', 'elementary-functions']"
