,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Prove that $f'(x) = \lim_{h\to 0^+ \\k\to 0^+} \frac{f(x+h) - f(x-k)}{h+k}$,Prove that,f'(x) = \lim_{h\to 0^+ \\k\to 0^+} \frac{f(x+h) - f(x-k)}{h+k},"In the book of Calculus by Spivak, at page 152, question 22, it is asked that Suppose that $f$ is differentiable at $x$. Prove that $$f'(x) = \lim_{h\to 0^+ \\k\to 0^+} \frac{f(x+h) - f(x-k)}{h+k}$$ I have tried some algebraic trics & take a look at this , question, but couldn't find the exact derivation, so I would appreciate any help or hint. I mean it is clear that this is a more general case of  $$f'(x) = \lim_{h\to 0} \frac{f(x+h) - f(x-h)}{2h},$$ and we are going to use similar ideas.","In the book of Calculus by Spivak, at page 152, question 22, it is asked that Suppose that $f$ is differentiable at $x$. Prove that $$f'(x) = \lim_{h\to 0^+ \\k\to 0^+} \frac{f(x+h) - f(x-k)}{h+k}$$ I have tried some algebraic trics & take a look at this , question, but couldn't find the exact derivation, so I would appreciate any help or hint. I mean it is clear that this is a more general case of  $$f'(x) = \lim_{h\to 0} \frac{f(x+h) - f(x-h)}{2h},$$ and we are going to use similar ideas.",,"['calculus', 'real-analysis', 'limits', 'epsilon-delta']"
1,Prove that $\lim\limits_{x\to\infty}\frac1x=0$,Prove that,\lim\limits_{x\to\infty}\frac1x=0,"So I had to explain to someone about limits and I got asked: how do you prove that $\lim\limits_{x\to\infty}\frac1x=0$ without intuition. After a while I answered: Let's construct a sequence $(a_n)$ where $a_n=\frac1n$(the sequence starts from $n=1$) now, $\left[\frac1x\right]'=-\frac1{x^2}$ thus $a_n>a_{n+1}$. Now let's assume that there is a value, say $k$, such that $a_n>k>0,\forall n\in\Bbb Z^+$. If $k$ is a rational number then $k=\frac qp\ge\frac1p=a_p>a_{p+1}$ which is contradiction If $k$ is irrational then: $k=\cdots +b_2+b_1+b_0+b_{-1}+b_{-2}+\cdots$ where $b_i=c\times 10^i, c\in\{0,1,2,3,4,5,6,7,8,9\}$. Now I can construct a number $k'=\max\{\,b_i\ne0\}$. $k'$ is rational, hence $k>k'=\frac qp\ge\frac1p=a_p>a_{p+1}$ which is contradiction. This implies that there is no $k$ such that $a_n>k>0,\forall n\in\Bbb Z^+$ which implies that $\inf\{a_n\}=0$ and because $a_n>a_{n+1}$ I also know that  $\inf\{a_n\}=\lim\limits_{x\to\infty}\frac1x$ hence $\lim\limits_{x\to\infty}\frac1x=0$. My question is, is my proof okay? I don't think that I have any problems but I am not completely sure. And if yes. Is there a easier way to prove that for any positive irrational number there is always smaller positive rational number?","So I had to explain to someone about limits and I got asked: how do you prove that $\lim\limits_{x\to\infty}\frac1x=0$ without intuition. After a while I answered: Let's construct a sequence $(a_n)$ where $a_n=\frac1n$(the sequence starts from $n=1$) now, $\left[\frac1x\right]'=-\frac1{x^2}$ thus $a_n>a_{n+1}$. Now let's assume that there is a value, say $k$, such that $a_n>k>0,\forall n\in\Bbb Z^+$. If $k$ is a rational number then $k=\frac qp\ge\frac1p=a_p>a_{p+1}$ which is contradiction If $k$ is irrational then: $k=\cdots +b_2+b_1+b_0+b_{-1}+b_{-2}+\cdots$ where $b_i=c\times 10^i, c\in\{0,1,2,3,4,5,6,7,8,9\}$. Now I can construct a number $k'=\max\{\,b_i\ne0\}$. $k'$ is rational, hence $k>k'=\frac qp\ge\frac1p=a_p>a_{p+1}$ which is contradiction. This implies that there is no $k$ such that $a_n>k>0,\forall n\in\Bbb Z^+$ which implies that $\inf\{a_n\}=0$ and because $a_n>a_{n+1}$ I also know that  $\inf\{a_n\}=\lim\limits_{x\to\infty}\frac1x$ hence $\lim\limits_{x\to\infty}\frac1x=0$. My question is, is my proof okay? I don't think that I have any problems but I am not completely sure. And if yes. Is there a easier way to prove that for any positive irrational number there is always smaller positive rational number?",,"['calculus', 'limits', 'proof-verification']"
2,Express this limit as a definite integral. No interval given. $\lim\limits_{n\to\infty}\sum_{k=1}^n \left(1+\frac{2k}{n}\right)\cdot \frac{2}{n}$,Express this limit as a definite integral. No interval given.,\lim\limits_{n\to\infty}\sum_{k=1}^n \left(1+\frac{2k}{n}\right)\cdot \frac{2}{n},"I am having trouble trying to convert a limit to a definite integral. I am unsure about how to go about this. I have already tried googling this but can not find anything that is comprehensive enough for me to learn from. Here's the limit: $$\lim_{n\rightarrow \infty}\sum_{k=1}^n \left(1+\frac{2k}{n}\right)\cdot \frac{2}{n}$$ I need to express this as a definite integral but cannot figure out how. My textbook is not clear and doesn't include an example, and my professor did not explain this. Thank you!","I am having trouble trying to convert a limit to a definite integral. I am unsure about how to go about this. I have already tried googling this but can not find anything that is comprehensive enough for me to learn from. Here's the limit: $$\lim_{n\rightarrow \infty}\sum_{k=1}^n \left(1+\frac{2k}{n}\right)\cdot \frac{2}{n}$$ I need to express this as a definite integral but cannot figure out how. My textbook is not clear and doesn't include an example, and my professor did not explain this. Thank you!",,"['calculus', 'limits', 'definite-integrals', 'riemann-sum']"
3,"Use Cauchy's Theorem to find $\lim_{(x,y)\to(0,0)} \frac{\cos(x) - \cos(y)}{x^2 - y^2}$.",Use Cauchy's Theorem to find .,"\lim_{(x,y)\to(0,0)} \frac{\cos(x) - \cos(y)}{x^2 - y^2}","I'm starting with Cauchy's theorem and I have this exercise... I don't understand how the theorem would help me in finding the limit. $$f(x,y)=\left\{ \begin{array}{ll}       \lim_{(x,y)\to(0,0)} \frac{\cos(x) - \cos(y)}{x^2 - y^2} & x \neq y \\       -\frac{1}{2} &  x=y\\ \end{array}  \right.$$ Suggestions? Perhaps I just need to see how what the theorem states is applicable to this situation... thanks!","I'm starting with Cauchy's theorem and I have this exercise... I don't understand how the theorem would help me in finding the limit. $$f(x,y)=\left\{ \begin{array}{ll}       \lim_{(x,y)\to(0,0)} \frac{\cos(x) - \cos(y)}{x^2 - y^2} & x \neq y \\       -\frac{1}{2} &  x=y\\ \end{array}  \right.$$ Suggestions? Perhaps I just need to see how what the theorem states is applicable to this situation... thanks!",,"['calculus', 'analysis', 'limits', 'multivariable-calculus', 'derivatives']"
4,Parametric integration problem,Parametric integration problem,,"If $$I_n = \int_0^1{x^n\sqrt{1-x^2}}\, \mathrm{d}x,$$ then find $$\lim_{n\to\infty}\frac{I_n}{I_{n-2}}.$$","If $$I_n = \int_0^1{x^n\sqrt{1-x^2}}\, \mathrm{d}x,$$ then find $$\lim_{n\to\infty}\frac{I_n}{I_{n-2}}.$$",,"['limits', 'definite-integrals']"
5,Limit $\lim_{x \to 0} \frac{\sin[x]}{[x]}$,Limit,\lim_{x \to 0} \frac{\sin[x]}{[x]},"I am trying to find the limit  of  $$\lim_{x \to 0} \frac{\sin[x]}{[x]}$$ where [.] represents the greatest integer function. I tried to take up an infinitesimally small number $h$ and took up the  Right Hand Limit and Left Hand limit $$\lim_{x \to 0^+}\frac{\sin[x]}{[x]}$$ $$\Rightarrow \lim_{h \to 0} \frac{\sin[h]}{[h]}$$ I am stuck over here, though I know that $$\lim_{x \to 0}\frac{\sin x}{x}=1$$ But here I see that since $h$ is a very small positive number$[h]$ itself becomes zero and we get $$\Rightarrow  \frac{\sin 0}{0}.$$ Does this shows that the RHL doesn't exist or am I at fault somewhere?","I am trying to find the limit  of  $$\lim_{x \to 0} \frac{\sin[x]}{[x]}$$ where [.] represents the greatest integer function. I tried to take up an infinitesimally small number $h$ and took up the  Right Hand Limit and Left Hand limit $$\lim_{x \to 0^+}\frac{\sin[x]}{[x]}$$ $$\Rightarrow \lim_{h \to 0} \frac{\sin[h]}{[h]}$$ I am stuck over here, though I know that $$\lim_{x \to 0}\frac{\sin x}{x}=1$$ But here I see that since $h$ is a very small positive number$[h]$ itself becomes zero and we get $$\Rightarrow  \frac{\sin 0}{0}.$$ Does this shows that the RHL doesn't exist or am I at fault somewhere?",,"['limits', 'trigonometry', 'ceiling-and-floor-functions']"
6,How to compute $\lim_{t \to \infty} \int_0^1 \sqrt{1+t^2 x^{2t-2}} dx$ without using arclength?,How to compute  without using arclength?,\lim_{t \to \infty} \int_0^1 \sqrt{1+t^2 x^{2t-2}} dx,"In computing $$\lim_{t \to \infty} \int_0^1 \sqrt{1+t^2 x^{2t-2}} dx,$$ realizing the integral is of the form $\int_0^1 \sqrt{1+f'(x)^2}dx$ with $f(x)=x^t$ allows one to use the triangle inequality to make estimates on the arclength of $f(x)=x^t$ as $t \to \infty$. From this one can conclude the limit is 2. How can I do this without thinking of this as an arclength? What are other methods of evaluation?","In computing $$\lim_{t \to \infty} \int_0^1 \sqrt{1+t^2 x^{2t-2}} dx,$$ realizing the integral is of the form $\int_0^1 \sqrt{1+f'(x)^2}dx$ with $f(x)=x^t$ allows one to use the triangle inequality to make estimates on the arclength of $f(x)=x^t$ as $t \to \infty$. From this one can conclude the limit is 2. How can I do this without thinking of this as an arclength? What are other methods of evaluation?",,"['limits', 'definite-integrals']"
7,Evaluate $\lim_{x\to0}\frac{e-(1+x)^\frac1x}{x}$ [duplicate],Evaluate  [duplicate],\lim_{x\to0}\frac{e-(1+x)^\frac1x}{x},This question already has answers here : Limit as $x\to 0$ of $\frac{(1+x)^{1/x}-e}{x}$ (6 answers) Closed 4 years ago . Somebody asked this and I think it's quite interesting as I couldn't figure out how to evaluate this but the Wolfram Alpha says its limit is $\frac e2$. $$\lim_{x\to0}\frac{e-(1+x)^\frac1x}{x}$$ Could someone help here?,This question already has answers here : Limit as $x\to 0$ of $\frac{(1+x)^{1/x}-e}{x}$ (6 answers) Closed 4 years ago . Somebody asked this and I think it's quite interesting as I couldn't figure out how to evaluate this but the Wolfram Alpha says its limit is $\frac e2$. $$\lim_{x\to0}\frac{e-(1+x)^\frac1x}{x}$$ Could someone help here?,,"['calculus', 'limits']"
8,Solving $\lim \limits _{x \to \infty} (\sqrt[n]{(x+a_1) (x+a_2) \dots (x+a_n)}-x)$ [duplicate],Solving  [duplicate],\lim \limits _{x \to \infty} (\sqrt[n]{(x+a_1) (x+a_2) \dots (x+a_n)}-x),This question already has answers here : How to find $\lim_{n \rightarrow +\infty } \left(\sqrt[m]{\prod_{i=1}^{m}(n+{a}_{i})}-n\right)$? (3 answers) Closed 8 years ago . $$\lim \limits _{x \to \infty}\bigg(\sqrt[n]{(x+a_1) (x+a_2) \dots (x+a_n)}-x\bigg)$$ We can see the limit is of type $\infty-\infty$. I don't see anything I could do here. I can only see the geometric mean which is the $n$-th root term. Can I do anything with it? Any tips on solving this?,This question already has answers here : How to find $\lim_{n \rightarrow +\infty } \left(\sqrt[m]{\prod_{i=1}^{m}(n+{a}_{i})}-n\right)$? (3 answers) Closed 8 years ago . $$\lim \limits _{x \to \infty}\bigg(\sqrt[n]{(x+a_1) (x+a_2) \dots (x+a_n)}-x\bigg)$$ We can see the limit is of type $\infty-\infty$. I don't see anything I could do here. I can only see the geometric mean which is the $n$-th root term. Can I do anything with it? Any tips on solving this?,,"['calculus', 'limits']"
9,Limit $\lim_{x\to0^-}{(1+\tan(9x))^{\frac{1}{\arcsin(5x)}}}$,Limit,\lim_{x\to0^-}{(1+\tan(9x))^{\frac{1}{\arcsin(5x)}}},"I have a limit: $$\lim_{x\to0^-}{(1+\tan(9x))^{\frac{1}{\arcsin(5x)}}}$$ Are these steps correct? Substitution: $x = n$, $n\to\infty$: $$\lim_{n\to\infty}=(1+\frac{\sin(9n)}{\cos(9n)})^{\frac{1}{\arcsin(5n)}}$$ $$\lim_{n\to\infty}=e^{\frac{\sin(9n)}{\cos(9n)\arcsin(5n)}}$$ Back from substitution: $n = x$, $x\to0^-$: $$\lim_{x\to0^-}=e^{\frac{\sin(9x)}{\cos(9x)\arcsin(5x)}}$$ $$\lim_{x\to0^-}=e^{\frac{\sin(9x)}{\cos(9n)\arcsin(5x)}\cdot\frac{9x5x}{9x5x}}$$ $$\lim_{x\to0^-}=e^{\frac{9x}{5x\cos(9x)}}$$ $$\lim_{x\to0^-}=e^{\frac{9}{5\cos(9\cdot0^-)}}$$ $$\lim_{x\to0^-}=e^{\frac{9}{5}}$$","I have a limit: $$\lim_{x\to0^-}{(1+\tan(9x))^{\frac{1}{\arcsin(5x)}}}$$ Are these steps correct? Substitution: $x = n$, $n\to\infty$: $$\lim_{n\to\infty}=(1+\frac{\sin(9n)}{\cos(9n)})^{\frac{1}{\arcsin(5n)}}$$ $$\lim_{n\to\infty}=e^{\frac{\sin(9n)}{\cos(9n)\arcsin(5n)}}$$ Back from substitution: $n = x$, $x\to0^-$: $$\lim_{x\to0^-}=e^{\frac{\sin(9x)}{\cos(9x)\arcsin(5x)}}$$ $$\lim_{x\to0^-}=e^{\frac{\sin(9x)}{\cos(9n)\arcsin(5x)}\cdot\frac{9x5x}{9x5x}}$$ $$\lim_{x\to0^-}=e^{\frac{9x}{5x\cos(9x)}}$$ $$\lim_{x\to0^-}=e^{\frac{9}{5\cos(9\cdot0^-)}}$$ $$\lim_{x\to0^-}=e^{\frac{9}{5}}$$",,['limits']
10,Finding the limit $\lim_{x\rightarrow \infty} \sqrt[3]{x+1}-\sqrt[3]{x}$,Finding the limit,\lim_{x\rightarrow \infty} \sqrt[3]{x+1}-\sqrt[3]{x},I am trying to  find this limit $$\lim_{x\rightarrow \infty} \sqrt[3]{x+1}-\sqrt[3]{x}$$ My so far method is this $f(x)>0.$ $f^{\prime}(x)=\frac{1}{3\sqrt[3]{(x+1)^2}}-\frac{1}{3\sqrt[3]{x^2}}<0.$ For every $0<y<1$ the equation $f(x)=y$ has a unique solution(found in maple): $$x=\frac{1}{3}\cdot \frac{\frac{1}{3}y^2(3y^2+\sqrt{-3y^4+12y})+\frac{1}{6}\frac{3y^2+\sqrt{-3y^4+12y}}{y}-y^4-2y}{y}$$ The previous facts implies that the limit is $0$. I am wondering if there is any way easier than this to find the limite. thanks in advance.,I am trying to  find this limit $$\lim_{x\rightarrow \infty} \sqrt[3]{x+1}-\sqrt[3]{x}$$ My so far method is this $f(x)>0.$ $f^{\prime}(x)=\frac{1}{3\sqrt[3]{(x+1)^2}}-\frac{1}{3\sqrt[3]{x^2}}<0.$ For every $0<y<1$ the equation $f(x)=y$ has a unique solution(found in maple): $$x=\frac{1}{3}\cdot \frac{\frac{1}{3}y^2(3y^2+\sqrt{-3y^4+12y})+\frac{1}{6}\frac{3y^2+\sqrt{-3y^4+12y}}{y}-y^4-2y}{y}$$ The previous facts implies that the limit is $0$. I am wondering if there is any way easier than this to find the limite. thanks in advance.,,"['analysis', 'limits']"
11,Prove $\lim_{x \to 0} \frac{e^{\sin(x)} - e^{\tan (x)}}{e^{\sin (2x)}-e^{\tan (2x)}} = \frac{1}{8}$,Prove,\lim_{x \to 0} \frac{e^{\sin(x)} - e^{\tan (x)}}{e^{\sin (2x)}-e^{\tan (2x)}} = \frac{1}{8},"Here's a nice little problem. $$\lim_{x \to 0} \frac{e^{\sin(x)} - e^{\tan (x)}}{e^{\sin (2x)}-e^{\tan (2x)}}$$ What's the quickest way to do this? One line solutions will be applauded :D Cheers, my jolly people :D","Here's a nice little problem. $$\lim_{x \to 0} \frac{e^{\sin(x)} - e^{\tan (x)}}{e^{\sin (2x)}-e^{\tan (2x)}}$$ What's the quickest way to do this? One line solutions will be applauded :D Cheers, my jolly people :D",,['limits']
12,"If $\lim_{n\rightarrow\infty} f(n+1) - f(n) = L$, prove that $\lim_{n\rightarrow\infty} f(n)/n = L$","If , prove that",\lim_{n\rightarrow\infty} f(n+1) - f(n) = L \lim_{n\rightarrow\infty} f(n)/n = L,"Here's the problem in full. I've stared at it for hours and can't get anywhere, so a hint would be nice. Suppose that $f:\mathbb N\rightarrow\mathbb R$. If $$\lim_{n\rightarrow\infty}f(n+1)-f(n) = L$$ prove that $\lim_{n\rightarrow\infty}f(n)/n$ exists and equals $L$. This problem is marked with the word ""Cauchy"", so I'm guessing Cauchy sequences or something related to them will be necessary, but I can't figure out what. Edit: It appears as if the Stolz-Cesaro Theorem makes this quite easy. Unfortunately though, we have not discussed this, so I won't be able to use this.","Here's the problem in full. I've stared at it for hours and can't get anywhere, so a hint would be nice. Suppose that $f:\mathbb N\rightarrow\mathbb R$. If $$\lim_{n\rightarrow\infty}f(n+1)-f(n) = L$$ prove that $\lim_{n\rightarrow\infty}f(n)/n$ exists and equals $L$. This problem is marked with the word ""Cauchy"", so I'm guessing Cauchy sequences or something related to them will be necessary, but I can't figure out what. Edit: It appears as if the Stolz-Cesaro Theorem makes this quite easy. Unfortunately though, we have not discussed this, so I won't be able to use this.",,['limits']
13,How do I find this limit without using L'Hôpital's rule?,How do I find this limit without using L'Hôpital's rule?,,"Finding this limit using  L'Hôpital's rule is easy, but how to do it without using L'Hôpital's rule? $$\lim_{x \rightarrow 0} \frac{(1+\sin x)^{\csc x}-e^{x+1}}{\sin (3x)}$$","Finding this limit using  L'Hôpital's rule is easy, but how to do it without using L'Hôpital's rule? $$\lim_{x \rightarrow 0} \frac{(1+\sin x)^{\csc x}-e^{x+1}}{\sin (3x)}$$",,"['calculus', 'limits']"
14,Limit of $\frac{\tan^{-1}(\sin^{-1}(x))-\sin^{-1}(\tan^{-1}(x))}{\tan(\sin(x))-\sin(\tan(x))}$ as $x \rightarrow 0$,Limit of  as,\frac{\tan^{-1}(\sin^{-1}(x))-\sin^{-1}(\tan^{-1}(x))}{\tan(\sin(x))-\sin(\tan(x))} x \rightarrow 0,"Find $\lim_{x \to 0} \dfrac{\tan^{-1}(\sin^{-1}(x))-\sin^{-1}(\tan^{-1}(x))}{\tan(\sin(x))-\sin(\tan(x))}$ I came across this limit a long time ago and could easily obtain a straightforward solution by finding the asymptotic expansion. But since the limit turns out to be nice despite the messy coefficients, I'm just curious if there is some reason other than just coincidental coefficients.","Find $\lim_{x \to 0} \dfrac{\tan^{-1}(\sin^{-1}(x))-\sin^{-1}(\tan^{-1}(x))}{\tan(\sin(x))-\sin(\tan(x))}$ I came across this limit a long time ago and could easily obtain a straightforward solution by finding the asymptotic expansion. But since the limit turns out to be nice despite the messy coefficients, I'm just curious if there is some reason other than just coincidental coefficients.",,"['limits', 'trigonometry', 'taylor-expansion']"
15,Find this limit without using L'Hospital's rule,Find this limit without using L'Hospital's rule,,I have to find this limit without using l'Hôspital's rule: $$\lim_{x\to 0} \frac{\alpha \sin \beta x - \beta \sin \alpha x}{x^2 \sin \alpha x}$$ Using L'Hôspital's rule gives: $$\frac{\beta}{6(\alpha^2 - \beta^2)}$$ I am stuck where to begin without using the rule.,I have to find this limit without using l'Hôspital's rule: $$\lim_{x\to 0} \frac{\alpha \sin \beta x - \beta \sin \alpha x}{x^2 \sin \alpha x}$$ Using L'Hôspital's rule gives: $$\frac{\beta}{6(\alpha^2 - \beta^2)}$$ I am stuck where to begin without using the rule.,,"['calculus', 'limits', 'trigonometry', 'limits-without-lhopital']"
16,How to evaluate indeterminate form of a limit,How to evaluate indeterminate form of a limit,,I can't evaluate indeterminate form of a limit like this: $$\lim \limits_{x\to \infty} \left (\frac {x-1}{x+4}\right)^{3x+2}$$ I tried to solve this problem by multiplying fractions' top and bottom by the conjugate of the denominator. I did it many times but I don't have any success and I even don't know if this way right or wrong. How this limit can be solved?,I can't evaluate indeterminate form of a limit like this: $$\lim \limits_{x\to \infty} \left (\frac {x-1}{x+4}\right)^{3x+2}$$ I tried to solve this problem by multiplying fractions' top and bottom by the conjugate of the denominator. I did it many times but I don't have any success and I even don't know if this way right or wrong. How this limit can be solved?,,"['real-analysis', 'limits']"
17,Evaluating the limit of multivariable equation $\frac{x^2y}{x^2+y^2}$ [duplicate],Evaluating the limit of multivariable equation  [duplicate],\frac{x^2y}{x^2+y^2},"This question already has answers here : Finding multivariable limits for the function $\frac{3x^2y}{x^2+y^2}$ (2 answers) Closed 7 years ago . $$ \lim_{(x,y)\to(0,0)}{\frac{x^2y}{x^2+y^2}} $$ If you substitute in $(0,0)$ for $x$ and $y$. It becomes $$ \frac{0}{0} $$ usually you would apply the L'Hopital's rule. However, I think it is not possible with the multivariable equation. If I cannot apply the L'Hopital's rule here, what should be my first step in solving this limit?","This question already has answers here : Finding multivariable limits for the function $\frac{3x^2y}{x^2+y^2}$ (2 answers) Closed 7 years ago . $$ \lim_{(x,y)\to(0,0)}{\frac{x^2y}{x^2+y^2}} $$ If you substitute in $(0,0)$ for $x$ and $y$. It becomes $$ \frac{0}{0} $$ usually you would apply the L'Hopital's rule. However, I think it is not possible with the multivariable equation. If I cannot apply the L'Hopital's rule here, what should be my first step in solving this limit?",,"['limits', 'multivariable-calculus']"
18,Find the limit of: $\lim_{n\to\infty} \frac{1}{\sqrt[n+1]{(n+1)!} - \sqrt[n]{(n)!}}$ [duplicate],Find the limit of:  [duplicate],\lim_{n\to\infty} \frac{1}{\sqrt[n+1]{(n+1)!} - \sqrt[n]{(n)!}},"This question already has an answer here : Limit of the sequence $a_n=\sqrt[n+1]{(n+1)!}-\sqrt[n]{n!}$ (1 answer) Closed 4 years ago . Could be the following limit computed without using Stirling's approximation formula? $$\lim_{n\to\infty} \frac{1}{\sqrt[n+1]{(n+1)!} - \sqrt[n]{(n)!}}$$ I know that the limit is $e$, but I'm looking for some alternative ways that doesn't require to resort to the use of Stirling's approximation. I really appreciate any support at this limit. Thanks.","This question already has an answer here : Limit of the sequence $a_n=\sqrt[n+1]{(n+1)!}-\sqrt[n]{n!}$ (1 answer) Closed 4 years ago . Could be the following limit computed without using Stirling's approximation formula? $$\lim_{n\to\infty} \frac{1}{\sqrt[n+1]{(n+1)!} - \sqrt[n]{(n)!}}$$ I know that the limit is $e$, but I'm looking for some alternative ways that doesn't require to resort to the use of Stirling's approximation. I really appreciate any support at this limit. Thanks.",,"['real-analysis', 'limits', 'exponential-function', 'radicals']"
19,Solve $\lim_{x \rightarrow 0} (a^x + b^x - c^x)^\frac{1}{x}$,Solve,\lim_{x \rightarrow 0} (a^x + b^x - c^x)^\frac{1}{x},"I need to solve the limit $$\lim_{x \rightarrow 0} (a^x + b^x - c^x)^\frac{1}{x}$$ when $a,b,c \gt 0$. I'm looking for ways to avoid $\frac{1}{x}$ power.","I need to solve the limit $$\lim_{x \rightarrow 0} (a^x + b^x - c^x)^\frac{1}{x}$$ when $a,b,c \gt 0$. I'm looking for ways to avoid $\frac{1}{x}$ power.",,"['calculus', 'limits']"
20,Find $\lim\limits_{n \to \infty}\frac1{n^3}\sum\limits_{k=0}^{n-1}k^2e^{-\frac{k}{n}}$,Find,\lim\limits_{n \to \infty}\frac1{n^3}\sum\limits_{k=0}^{n-1}k^2e^{-\frac{k}{n}},"Can you help me find $$\lim_{n \to \infty}\frac1{n^3}\sum_{k=0}^{n-1}k^2e^{-\frac{k}{n}} \ \ ?$$ Using Riemann sums, I found it is equal to $2-\frac3{e}$.  Is that correct ? Thank you in advance.","Can you help me find $$\lim_{n \to \infty}\frac1{n^3}\sum_{k=0}^{n-1}k^2e^{-\frac{k}{n}} \ \ ?$$ Using Riemann sums, I found it is equal to $2-\frac3{e}$.  Is that correct ? Thank you in advance.",,['calculus']
21,Techniques for intuitively determining whether or not a function's limit exists?,Techniques for intuitively determining whether or not a function's limit exists?,,"On one of my past calculus tests, I struggled with a multi-part question that asked to ""Evaluate the limits that exist, or prove that they don't"", as I would often be plagued by doubt wondering if each limit exists, and wound up wasting time changing my answers. Now with my final upcoming later this week, the last thing I want to do is spend any time second-guessing myself as to whether or not the limit exists. What sort of techniques can I use to intuitively determine the existence of a limit of a function before delving into evaluation or a proof of non-existence? I'm in a first year single variable Calculus course; here are a few limits. $$\lim_{x \to 0} \frac{\tan(3x^2) + \sin^2(5x)}{x^2}$$ $$\lim_{x \to 3^+} \frac{\sqrt{x - 3}}{|x - 3|}$$ $$\lim_{x \to 1} \frac{x^2 - \sqrt{x}}{x - 1}$$","On one of my past calculus tests, I struggled with a multi-part question that asked to ""Evaluate the limits that exist, or prove that they don't"", as I would often be plagued by doubt wondering if each limit exists, and wound up wasting time changing my answers. Now with my final upcoming later this week, the last thing I want to do is spend any time second-guessing myself as to whether or not the limit exists. What sort of techniques can I use to intuitively determine the existence of a limit of a function before delving into evaluation or a proof of non-existence? I'm in a first year single variable Calculus course; here are a few limits. $$\lim_{x \to 0} \frac{\tan(3x^2) + \sin^2(5x)}{x^2}$$ $$\lim_{x \to 3^+} \frac{\sqrt{x - 3}}{|x - 3|}$$ $$\lim_{x \to 1} \frac{x^2 - \sqrt{x}}{x - 1}$$",,"['calculus', 'limits']"
22,Find $\lim_{x \rightarrow \infty} \frac{\arctan (x^{3/2})}{\sqrt x}$.,Find .,\lim_{x \rightarrow \infty} \frac{\arctan (x^{3/2})}{\sqrt x},"$$\lim_{x \rightarrow \infty} \frac{\arctan \left(x^\frac{3}{2}\right)}{\sqrt x}.$$ My method was that as the numerator can never exceed $\pi/2$ , some finite value/infinity tends to $0$ , but is there a proper way of doing it? As such it's not $\infty/\infty$ or $0/0$ form so l'hopital will not work, so does any other way exist?","My method was that as the numerator can never exceed , some finite value/infinity tends to , but is there a proper way of doing it? As such it's not or form so l'hopital will not work, so does any other way exist?",\lim_{x \rightarrow \infty} \frac{\arctan \left(x^\frac{3}{2}\right)}{\sqrt x}. \pi/2 0 \infty/\infty 0/0,"['calculus', 'limits']"
23,$\lim_{x \to a} x^2 = a^2$.,.,\lim_{x \to a} x^2 = a^2,"As per the definition of limits if $\lim_{x \to a} f(x)= L$ , then $$\forall \varepsilon \gt 0 \ \exists \delta \gt 0 \ s.t 0\lt\lvert x-a \rvert \lt \delta \ \implies \ 0\lt \lvert f(x)- L\rvert \lt \varepsilon $$ I want to prove that $\lim_{x \to a} x^2 = a^2$ . As per the definition $$\lvert f(x)- L\rvert = \lvert x^2- a^2\rvert = \lvert (x-a)(x+a)\rvert =\lvert x-a\rvert \lvert x+a \rvert$$ As per definition $$\lvert x-a \rvert \lt \delta \implies -\delta \lt x-a \lt \delta \implies a-\delta \lt x <a+\delta \implies 2a-\delta \lt x+a <2a+\delta $$ I'm stuck beyond this. I cannot find a suitable $\varepsilon$ to satisfy my condition here.","As per the definition of limits if , then I want to prove that . As per the definition As per definition I'm stuck beyond this. I cannot find a suitable to satisfy my condition here.",\lim_{x \to a} f(x)= L \forall \varepsilon \gt 0 \ \exists \delta \gt 0 \ s.t 0\lt\lvert x-a \rvert \lt \delta \ \implies \ 0\lt \lvert f(x)- L\rvert \lt \varepsilon  \lim_{x \to a} x^2 = a^2 \lvert f(x)- L\rvert = \lvert x^2- a^2\rvert = \lvert (x-a)(x+a)\rvert =\lvert x-a\rvert \lvert x+a \rvert \lvert x-a \rvert \lt \delta \implies -\delta \lt x-a \lt \delta \implies a-\delta \lt x <a+\delta \implies 2a-\delta \lt x+a <2a+\delta  \varepsilon,"['calculus', 'limits']"
24,"Where is the fallacy in this ""proof"" of $\lim_{x \to a} x^2 = a^2$? [duplicate]","Where is the fallacy in this ""proof"" of ? [duplicate]",\lim_{x \to a} x^2 = a^2,"This question already has answers here : Spivak's Calculus (Chapter 5, Problem 41): Proof that $\lim_{x \to a} x^2 = a^2$ (3 answers) Closed 2 years ago . I just started reading Michael Spivak's Calculus and I am at Chapter 5 - Limits now. I tried doing the problems, and at the very end is an interesting and hard problem (problem 41) which I really can't see the solution: (This problem is in Spivak's personal view.) 41. After sending the manuscript for the first edition of this book off to the printer, I thought of a much simpler way to prove that $\lim_{x \to a} x^2 = a^2$ and $\lim_{x \to a} x^3 = a^3$ without going through all the factoring tricks on page 95. Suppose, for example, that we want to prove that $\lim_{x \to a} x^2 = a^2$ , where $a > 0.$ Given $\epsilon > 0$ , we simply let $\delta$ be the minimum of $\sqrt{a^2 + \epsilon}  -a$ and $a - \sqrt{a^2 - \epsilon}$ (see Figure 19); then $|x - a| < \delta$ implies that $\sqrt{a^2 - \epsilon} < x < \sqrt{a^2 + \epsilon}$ , so $a^2 - \epsilon < x^2 < a^2 + \epsilon$ , or $|x^2 - a^2| < \epsilon$ . It is fortunate these pages had already been set, so I couldn't make these changes, because this ""proof"" is completely fallacious. Wherein lies the fallacy? I don't know where the fallacy is, but either way, the ""proof"" that he gave was very promising and for me, it's hard to find the error. So what is the fallacy in Spivak's ""proof""?","This question already has answers here : Spivak's Calculus (Chapter 5, Problem 41): Proof that $\lim_{x \to a} x^2 = a^2$ (3 answers) Closed 2 years ago . I just started reading Michael Spivak's Calculus and I am at Chapter 5 - Limits now. I tried doing the problems, and at the very end is an interesting and hard problem (problem 41) which I really can't see the solution: (This problem is in Spivak's personal view.) 41. After sending the manuscript for the first edition of this book off to the printer, I thought of a much simpler way to prove that and without going through all the factoring tricks on page 95. Suppose, for example, that we want to prove that , where Given , we simply let be the minimum of and (see Figure 19); then implies that , so , or . It is fortunate these pages had already been set, so I couldn't make these changes, because this ""proof"" is completely fallacious. Wherein lies the fallacy? I don't know where the fallacy is, but either way, the ""proof"" that he gave was very promising and for me, it's hard to find the error. So what is the fallacy in Spivak's ""proof""?",\lim_{x \to a} x^2 = a^2 \lim_{x \to a} x^3 = a^3 \lim_{x \to a} x^2 = a^2 a > 0. \epsilon > 0 \delta \sqrt{a^2 + \epsilon}  -a a - \sqrt{a^2 - \epsilon} |x - a| < \delta \sqrt{a^2 - \epsilon} < x < \sqrt{a^2 + \epsilon} a^2 - \epsilon < x^2 < a^2 + \epsilon |x^2 - a^2| < \epsilon,['calculus']
25,Derivative of Arctangent with definition of derivative,Derivative of Arctangent with definition of derivative,,"I can't find the derivative of arctangent with definition of derivative. Here's my way: $\displaystyle\lim_{\Delta x\to\ 0} \frac{f(x+\Delta x)-f(x)}{\Delta x}$ is a definition of derivative with limit. If we define $f(x)=\arctan(x)$ , then we get: $$\left[\lim_{\Delta x\to\ 0} \frac{\arctan(x+\Delta x)-\arctan(x)}{\Delta x}\right]=\left[\lim_{\Delta x\to\ 0} \frac{\arctan\left(\dfrac{\Delta x}{1+x(x+\Delta x)}\right)}{\Delta x}\right].$$ But I don't know how to continue. Thanks.","I can't find the derivative of arctangent with definition of derivative. Here's my way: is a definition of derivative with limit. If we define , then we get: But I don't know how to continue. Thanks.",\displaystyle\lim_{\Delta x\to\ 0} \frac{f(x+\Delta x)-f(x)}{\Delta x} f(x)=\arctan(x) \left[\lim_{\Delta x\to\ 0} \frac{\arctan(x+\Delta x)-\arctan(x)}{\Delta x}\right]=\left[\lim_{\Delta x\to\ 0} \frac{\arctan\left(\dfrac{\Delta x}{1+x(x+\Delta x)}\right)}{\Delta x}\right].,"['limits', 'derivatives', 'definition']"
26,How can we relate the two informal definitions of the limit with each other?,How can we relate the two informal definitions of the limit with each other?,,"Informal definition $1$ : This is the way in which I studied it, and it makes sense to me . As $x$ gets closer and closer to $a$ , $f(x)$ gets closer and closer to $l$ . Informal definition $2$ : $f(x)$ can get arbitrarily close to $l$ , by taking $x$ sufficiently close to $a$ . I am not able to relate these two informal definitions. How do we relate these definitions?","Informal definition : This is the way in which I studied it, and it makes sense to me . As gets closer and closer to , gets closer and closer to . Informal definition : can get arbitrarily close to , by taking sufficiently close to . I am not able to relate these two informal definitions. How do we relate these definitions?",1 x a f(x) l 2 f(x) l x a,"['limits', 'epsilon-delta']"
27,"How to find $\lim_{n \to \infty}\int_{0}^{1}\sin^2\left(\frac{1}{ny^2}\right)\,\mathrm{d}y$ if it exists?",How to find  if it exists?,"\lim_{n \to \infty}\int_{0}^{1}\sin^2\left(\frac{1}{ny^2}\right)\,\mathrm{d}y","For hours I have been trying to determine whether or not the following limit exists: $$\displaystyle{ \lim_{n \to \infty} }\displaystyle\int_{0}^{1}\sin^2\left(\dfrac{1}{ny^2}\right)\mathrm{d}y$$ My first attempt was to try and solve it as an indefinite integral, hoping a nice closed form would result: Starting with integration by parts gave $${\displaystyle\int_{0}^{1}}\sin^2\left(\dfrac{1}{ny^2}\right)\mathrm{d}y = y\cdot \sin^2\left( \dfrac{1}{ny^2} \right) + 2\displaystyle\int_{0}^{1} \dfrac{\sin\left(\dfrac{2}{ny^2}\right)}{ny^3}\mathrm{d}y$$ Which was not much help. Thus, I tried to see how far I could get with a series of substitutions, treating it as an indefinite integral: $$ v=\dfrac{1}{y} \implies {\displaystyle\int_{}^{}}\sin^2\left(\dfrac{1}{ny^2}\right)\mathrm{d}y =-{\displaystyle\int}\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v^2} \space \mathrm{d}v$$ Then, integrating by parts: $$ = -\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v}-{\displaystyle\int}-\dfrac{4\cos\left(\frac{v^2}{n}\right)\sin\left(\frac{v^2}{n}\right)}{n}\,\mathrm{d}v = -\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v} + \dfrac{4}{n}{\displaystyle\int}\cos\left(\dfrac{v^2}{n}\right)\sin\left(\dfrac{v^2}{n}\right)\space \mathrm{d}v $$ Which simplifies to $$-\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v} + \dfrac4n{\displaystyle\int}\dfrac{\sin\left(\frac{2v^2}{n}\right)}{2}\space\mathrm{d}v \tag{$\ast$}$$ At this point, I realised that the initial substitution $v = 1/y$ will lead to problems at zero when determining the new limits so I modified the problem like this: $$ v= \dfrac{1}{y} \implies \lim_{n \to \infty} {\displaystyle\int_{0}^{1}}\sin^2\left(\dfrac{1}{ny^2}\right)\mathrm{d}y =  \lim_{n \to \infty} \left(  \lim_{c \to 0}{\displaystyle\int_{c}^{1}}\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v^2} \space \mathrm{d}v \right) $$ I am still stuck at this point. However, referring back to ( $\ast$ ), I have a few conjectures about the convergence of the individual terms: Firstly, for a fixed $v$ $$\lim_{n \to \infty} -\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v} = 0$$ And secondly, $${\displaystyle\int}\dfrac{\sin\left(\frac{2v^2}{n}\right)}{2}\space\mathrm{d}v$$ is bounded above thus $$\lim_{n \to \infty}\dfrac4n{\displaystyle\int_{0}^{1}}\dfrac{\sin\left(\frac{2v^2}{n}\right)}{2}\space\mathrm{d}v = 0$$ Therefore the initial integral is indeed convergent. Right now I am trying to find the limit but no success yet. Any thoughts and ideas will be appreciated.","For hours I have been trying to determine whether or not the following limit exists: My first attempt was to try and solve it as an indefinite integral, hoping a nice closed form would result: Starting with integration by parts gave Which was not much help. Thus, I tried to see how far I could get with a series of substitutions, treating it as an indefinite integral: Then, integrating by parts: Which simplifies to At this point, I realised that the initial substitution will lead to problems at zero when determining the new limits so I modified the problem like this: I am still stuck at this point. However, referring back to ( ), I have a few conjectures about the convergence of the individual terms: Firstly, for a fixed And secondly, is bounded above thus Therefore the initial integral is indeed convergent. Right now I am trying to find the limit but no success yet. Any thoughts and ideas will be appreciated.","\displaystyle{ \lim_{n \to \infty} }\displaystyle\int_{0}^{1}\sin^2\left(\dfrac{1}{ny^2}\right)\mathrm{d}y {\displaystyle\int_{0}^{1}}\sin^2\left(\dfrac{1}{ny^2}\right)\mathrm{d}y = y\cdot \sin^2\left( \dfrac{1}{ny^2} \right) + 2\displaystyle\int_{0}^{1} \dfrac{\sin\left(\dfrac{2}{ny^2}\right)}{ny^3}\mathrm{d}y  v=\dfrac{1}{y} \implies {\displaystyle\int_{}^{}}\sin^2\left(\dfrac{1}{ny^2}\right)\mathrm{d}y =-{\displaystyle\int}\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v^2} \space \mathrm{d}v  = -\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v}-{\displaystyle\int}-\dfrac{4\cos\left(\frac{v^2}{n}\right)\sin\left(\frac{v^2}{n}\right)}{n}\,\mathrm{d}v = -\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v} + \dfrac{4}{n}{\displaystyle\int}\cos\left(\dfrac{v^2}{n}\right)\sin\left(\dfrac{v^2}{n}\right)\space \mathrm{d}v  -\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v} + \dfrac4n{\displaystyle\int}\dfrac{\sin\left(\frac{2v^2}{n}\right)}{2}\space\mathrm{d}v \tag{\ast} v = 1/y  v= \dfrac{1}{y} \implies \lim_{n \to \infty} {\displaystyle\int_{0}^{1}}\sin^2\left(\dfrac{1}{ny^2}\right)\mathrm{d}y =  \lim_{n \to \infty} \left(  \lim_{c \to 0}{\displaystyle\int_{c}^{1}}\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v^2} \space \mathrm{d}v \right)  \ast v \lim_{n \to \infty} -\dfrac{\sin^2\left(\frac{v^2}{n}\right)}{v} = 0 {\displaystyle\int}\dfrac{\sin\left(\frac{2v^2}{n}\right)}{2}\space\mathrm{d}v \lim_{n \to \infty}\dfrac4n{\displaystyle\int_{0}^{1}}\dfrac{\sin\left(\frac{2v^2}{n}\right)}{2}\space\mathrm{d}v = 0","['real-analysis', 'limits', 'multivariable-calculus', 'improper-integrals', 'lebesgue-integral']"
28,Evaluating $\lim\limits_{x \to \infty}\frac{4^{x+2}+3^x}{4^{x-2}}$,Evaluating,\lim\limits_{x \to \infty}\frac{4^{x+2}+3^x}{4^{x-2}},"$$\lim_{x→∞}\frac{4^{x+2}+3^x}{4^{x-2}}.$$ I have solved it like below: $$\lim_{x→∞}\left(\frac{4^{x+2}}{4^{x-2}}+\frac{3^x}{4^{x-2}}\right)=\lim_{x→∞}\left(4^4+\frac{3^x}{4^x}·4^2\right).$$ Since, as $x → ∞$ , $3^x → ∞$ , $\dfrac{3^x}{4^x} → 0$ , the limit is equal to $4^4=256$ . Have I solved it correctly? This was a practice test question and the given solution was wrong. So, I solved it and I am preparing alone, no friend to discuss, so I posted it here.","I have solved it like below: Since, as , , , the limit is equal to . Have I solved it correctly? This was a practice test question and the given solution was wrong. So, I solved it and I am preparing alone, no friend to discuss, so I posted it here.",\lim_{x→∞}\frac{4^{x+2}+3^x}{4^{x-2}}. \lim_{x→∞}\left(\frac{4^{x+2}}{4^{x-2}}+\frac{3^x}{4^{x-2}}\right)=\lim_{x→∞}\left(4^4+\frac{3^x}{4^x}·4^2\right). x → ∞ 3^x → ∞ \dfrac{3^x}{4^x} → 0 4^4=256,"['calculus', 'limits']"
29,Show that $\lim_{k\to\infty}\lim_{j\to\infty}\cos^{2j}k!\pi x=0$ [duplicate],Show that  [duplicate],\lim_{k\to\infty}\lim_{j\to\infty}\cos^{2j}k!\pi x=0,"This question already has answers here : Double limit of $\cos^{2n}(m! \pi x)$ at rationals and irrationals (3 answers) Closed 5 years ago . The Dirichlet function is defined as the indicator function of rational numbers. I have also seen this function described by: $$f(x)=\lim_{k\to\infty}\lim_{j\to\infty}\cos^{2j}k!\pi x$$ How does this limit act as the indicator, and how does it yield an answer if cosine is limited to Infinity?","This question already has answers here : Double limit of $\cos^{2n}(m! \pi x)$ at rationals and irrationals (3 answers) Closed 5 years ago . The Dirichlet function is defined as the indicator function of rational numbers. I have also seen this function described by: How does this limit act as the indicator, and how does it yield an answer if cosine is limited to Infinity?",f(x)=\lim_{k\to\infty}\lim_{j\to\infty}\cos^{2j}k!\pi x,"['limits', 'irrational-numbers', 'rational-numbers', 'rationality-testing']"
30,Limits and convergence - selecting the right epsilon for proofs,Limits and convergence - selecting the right epsilon for proofs,,"Show that if limit of sequence $x_n$ goes to $x$ as $n$ goes to $ \infty$ and $ x > a$, then $x_n > a$ all but finitely many $ n$. I have started it like this: $x_n > x - \epsilon$ (as  $|x_n- x| < \epsilon$ for all $\epsilon$) $x_n > a - \epsilon$ From here on, how does one chose the right epsilon to show that $x_n > a$?","Show that if limit of sequence $x_n$ goes to $x$ as $n$ goes to $ \infty$ and $ x > a$, then $x_n > a$ all but finitely many $ n$. I have started it like this: $x_n > x - \epsilon$ (as  $|x_n- x| < \epsilon$ for all $\epsilon$) $x_n > a - \epsilon$ From here on, how does one chose the right epsilon to show that $x_n > a$?",,"['real-analysis', 'limits', 'convergence-divergence']"
31,Limit of a two variable function involving arcsin and arctan,Limit of a two variable function involving arcsin and arctan,,"I recently came across this problem of finding the limit of a function in two variables as we approach the origin, defined as follows: $$\lim_{(x,y)\to (0,0)} \frac{\arcsin(x+2y)}{\arctan(2x+4y)}$$ This was on the mid-term test on our course of Multivariable Calculus. While, all the paths that pass through the origin I have tested, seems to give the limit $\frac{1}{2}$, which seems reasonable through recognizing the fact that the argument of arctan is twice as that of arcsin and the logic of single variable limit: $\lim_{x\to 0} \frac{\arcsin(x)}{\arctan(2x)}$. It is, however, not sufficient to prove that the limit is indeed, $\frac{1}{2}$ since the two-path test is a test for the non-existence of limit and not the existence of one. I have even tried Sandwich Theorem and evaluating the limit by converting to polar coordinates but have reached to no conclusion, of course. I am wondering if setting (x+2y) as some parameter t followed by tending t to zero would work, but then again that would be the same as testing along the path x=-2y. I am truly dumbfounded by this problem and after long efforts at solving it, I have no answer. Any kind of hint towards which direction I should be proceeding or a solution would be highly appreciated.","I recently came across this problem of finding the limit of a function in two variables as we approach the origin, defined as follows: $$\lim_{(x,y)\to (0,0)} \frac{\arcsin(x+2y)}{\arctan(2x+4y)}$$ This was on the mid-term test on our course of Multivariable Calculus. While, all the paths that pass through the origin I have tested, seems to give the limit $\frac{1}{2}$, which seems reasonable through recognizing the fact that the argument of arctan is twice as that of arcsin and the logic of single variable limit: $\lim_{x\to 0} \frac{\arcsin(x)}{\arctan(2x)}$. It is, however, not sufficient to prove that the limit is indeed, $\frac{1}{2}$ since the two-path test is a test for the non-existence of limit and not the existence of one. I have even tried Sandwich Theorem and evaluating the limit by converting to polar coordinates but have reached to no conclusion, of course. I am wondering if setting (x+2y) as some parameter t followed by tending t to zero would work, but then again that would be the same as testing along the path x=-2y. I am truly dumbfounded by this problem and after long efforts at solving it, I have no answer. Any kind of hint towards which direction I should be proceeding or a solution would be highly appreciated.",,"['calculus', 'limits', 'multivariable-calculus', 'trigonometry', 'inverse-function']"
32,How to evaluate $\lim_{x\to0}\frac{\sin^2\left(\frac x2\right)-\frac{x^2}4}{e^{x^2}+e^{-x^2}-2}$?,How to evaluate ?,\lim_{x\to0}\frac{\sin^2\left(\frac x2\right)-\frac{x^2}4}{e^{x^2}+e^{-x^2}-2},"$$\begin{align*} \lim_{x \to 0} \frac{\sin^2 \left(\frac{x}{2}\right) - \frac{x^2}{4}}{e^{x^{2}} + e^{-x^{2}} - 2} &\overset{L}{=} \lim_{x \to 0} \frac{\sin \frac{x}{2} \cos \frac{x}{2} - \frac{1}{2}x}{2xe^{x^{2}} + (-2x)e^{-x^{2}}} \\ &= \lim_{x \to 0} \frac{\sin \frac{x}{2} \cos \frac{x}{2} - \frac{1}{2}x}{2xe^{x^{2}} -2xe^{-x^{2}}} \\ &\overset{L}{=} \lim_{x \to 0} \frac{\frac{1}{2}\cos^2 \frac{x}{2} - \frac{1}{2}\sin^2 \frac{x}{2} - \frac{1}{2}}{(2x)(2x)e^{x^{2}} - (2x)(-2x)(e^{-x^{2}})} \\ &= \lim_{x \to 0} \frac{\frac{1}{2}\cos^2 \frac{x}{2} - \frac{1}{2}\sin^2 \frac{x}{2} - \frac{1}{2}}{4x^2 e^{x^{2}} + 4x^2 e^{-x^{2}}} \\ &\overset{L}{=} \lim_{x \to 0} \frac{\frac{1}{2}\left( -\sin \frac{x}{2} \cos \frac{x}{2} \right) - \frac{1}{2} \left( \sin \frac{x}{2} \cos \frac{x}{2} \right)}{(4x^2)(2x)e^{x^{2}} + (4x^2)(-2x)(e^{-x^{2}})} \\ &= \lim_{x \to 0} \frac{-\sin \frac{x}{2} \cos \frac{x}{2}}{8x^3e^{x^{2}} - 8x^3 e^{-x^{2}}} \\ \end{align*}$$ After evaluating the limit as $x \to 0$, I noticed that the problem comes up to be in an indeterminate form of $0/0$. I immediately utilized the L'Hospital Rule by differentiating both the numerator and denominator. However, after using L'Hospital rule for 5-6 times, I noticed that the question will go through a loop of $0/0$ indeterminants. In my second attempt, I have tried multiplying $\exp(x^2)$ in both the numerator and denominator with hopes to balance out the $\exp(x^{-2})$. However, an indeterminant is $0/0$ still resulting. Any help would be appreciated, thank you all!","$$\begin{align*} \lim_{x \to 0} \frac{\sin^2 \left(\frac{x}{2}\right) - \frac{x^2}{4}}{e^{x^{2}} + e^{-x^{2}} - 2} &\overset{L}{=} \lim_{x \to 0} \frac{\sin \frac{x}{2} \cos \frac{x}{2} - \frac{1}{2}x}{2xe^{x^{2}} + (-2x)e^{-x^{2}}} \\ &= \lim_{x \to 0} \frac{\sin \frac{x}{2} \cos \frac{x}{2} - \frac{1}{2}x}{2xe^{x^{2}} -2xe^{-x^{2}}} \\ &\overset{L}{=} \lim_{x \to 0} \frac{\frac{1}{2}\cos^2 \frac{x}{2} - \frac{1}{2}\sin^2 \frac{x}{2} - \frac{1}{2}}{(2x)(2x)e^{x^{2}} - (2x)(-2x)(e^{-x^{2}})} \\ &= \lim_{x \to 0} \frac{\frac{1}{2}\cos^2 \frac{x}{2} - \frac{1}{2}\sin^2 \frac{x}{2} - \frac{1}{2}}{4x^2 e^{x^{2}} + 4x^2 e^{-x^{2}}} \\ &\overset{L}{=} \lim_{x \to 0} \frac{\frac{1}{2}\left( -\sin \frac{x}{2} \cos \frac{x}{2} \right) - \frac{1}{2} \left( \sin \frac{x}{2} \cos \frac{x}{2} \right)}{(4x^2)(2x)e^{x^{2}} + (4x^2)(-2x)(e^{-x^{2}})} \\ &= \lim_{x \to 0} \frac{-\sin \frac{x}{2} \cos \frac{x}{2}}{8x^3e^{x^{2}} - 8x^3 e^{-x^{2}}} \\ \end{align*}$$ After evaluating the limit as $x \to 0$, I noticed that the problem comes up to be in an indeterminate form of $0/0$. I immediately utilized the L'Hospital Rule by differentiating both the numerator and denominator. However, after using L'Hospital rule for 5-6 times, I noticed that the question will go through a loop of $0/0$ indeterminants. In my second attempt, I have tried multiplying $\exp(x^2)$ in both the numerator and denominator with hopes to balance out the $\exp(x^{-2})$. However, an indeterminant is $0/0$ still resulting. Any help would be appreciated, thank you all!",,['limits']
33,$\lim_{n \to \infty}\left(\frac{\sqrt[n]a}{n+1}+\frac{\sqrt[n]{a^2}}{n+\frac12}+\cdots+\frac{\sqrt[n]{a^n}}{n+\frac1n}\right)=?$,,\lim_{n \to \infty}\left(\frac{\sqrt[n]a}{n+1}+\frac{\sqrt[n]{a^2}}{n+\frac12}+\cdots+\frac{\sqrt[n]{a^n}}{n+\frac1n}\right)=?,"What is the value of limit $$\lim_{n \to \infty}\left(\frac{\sqrt[n]a}{n+1}+\frac{\sqrt[n]{a^2}}{n+\frac12}+\frac{\sqrt[n]{a^3}}{n+\frac13}+\cdots+\frac{\sqrt[n]{a^n}}{n+\frac1n}\right)$$ If we know that $a>0$? I get stuck on this, it seems to be Riemann sum but I can't find relation. I am thankful if someone could guide me.","What is the value of limit $$\lim_{n \to \infty}\left(\frac{\sqrt[n]a}{n+1}+\frac{\sqrt[n]{a^2}}{n+\frac12}+\frac{\sqrt[n]{a^3}}{n+\frac13}+\cdots+\frac{\sqrt[n]{a^n}}{n+\frac1n}\right)$$ If we know that $a>0$? I get stuck on this, it seems to be Riemann sum but I can't find relation. I am thankful if someone could guide me.",,"['calculus', 'limits', 'summation', 'riemann-sum']"
34,Calculating the limit of $\frac{\cos(x)-1}{x}$ as $x \rightarrow 0$,Calculating the limit of  as,\frac{\cos(x)-1}{x} x \rightarrow 0,"Show that the $\lim \limits_{x \to 0}\frac{\cos(x)-1}{x}=0$ My attempt $$\begin{align} \lim \limits_{x \to 0}\frac{\cos(x)-1}{x}*\frac{\cos(x)+1}{\cos(x)+1}&=\lim \limits_{x \to 0}\frac{1-\cos^2(x)}{x(1+\cos(x))}\\\\ &=\lim \limits_{x \to 0}\frac{\sin^2(x)}{x(1+\cos(x))}\\\\ &=\lim \limits_{x \to 0}\frac{\sin(x)}{x}*\frac{\sin(x)}{1+\cos(x)}\\\\ &=1*\frac{0}{2}\\\\ &=0 \end{align}$$ $$QED$$ Since $\lim \limits_{x \to 0}\frac{\sin(x)}{x}=1$ by the sandwich theorem. i know this is correct however i would like it if anyone could show me the natural argument of using power series instead. Recall the definition of the cosine function by the power series: $$\sum_{n=0}^\infty\frac{(-1)^n}{(2n)!}x^{2n}, \forall x \in \mathbb R$$ Also can anyone show me how to show that the radius of convergence of the cosine power series is $$\infty$$","Show that the $\lim \limits_{x \to 0}\frac{\cos(x)-1}{x}=0$ My attempt $$\begin{align} \lim \limits_{x \to 0}\frac{\cos(x)-1}{x}*\frac{\cos(x)+1}{\cos(x)+1}&=\lim \limits_{x \to 0}\frac{1-\cos^2(x)}{x(1+\cos(x))}\\\\ &=\lim \limits_{x \to 0}\frac{\sin^2(x)}{x(1+\cos(x))}\\\\ &=\lim \limits_{x \to 0}\frac{\sin(x)}{x}*\frac{\sin(x)}{1+\cos(x)}\\\\ &=1*\frac{0}{2}\\\\ &=0 \end{align}$$ $$QED$$ Since $\lim \limits_{x \to 0}\frac{\sin(x)}{x}=1$ by the sandwich theorem. i know this is correct however i would like it if anyone could show me the natural argument of using power series instead. Recall the definition of the cosine function by the power series: $$\sum_{n=0}^\infty\frac{(-1)^n}{(2n)!}x^{2n}, \forall x \in \mathbb R$$ Also can anyone show me how to show that the radius of convergence of the cosine power series is $$\infty$$",,['real-analysis']
35,Give an indeterminate limit of a function that is always indeterminate with iterated attempts at l'Hopital's Rule.,Give an indeterminate limit of a function that is always indeterminate with iterated attempts at l'Hopital's Rule.,,"I am freshening up on differential calculus, and I came up with a thought experiment in the context of using l'Hopital's rule. Is there a limit of a function that will always give an indeterminate form regardless of the number of times the numerator and denominator are differentiated? Answerers can choose any value to be approached, and any function. Single-variable and multi-variable are fine. I also don't mind which indeterminate forms are involved.","I am freshening up on differential calculus, and I came up with a thought experiment in the context of using l'Hopital's rule. Is there a limit of a function that will always give an indeterminate form regardless of the number of times the numerator and denominator are differentiated? Answerers can choose any value to be approached, and any function. Single-variable and multi-variable are fine. I also don't mind which indeterminate forms are involved.",,"['limits', 'derivatives']"
36,Proving $\frac{d}{dx}x^2=2x$ by definition,Proving  by definition,\frac{d}{dx}x^2=2x,"I did the following proof earlier and just wanted conformation as to whether it works. The question was to show $$\frac{d}{dx}x^2=2x$$ by the difference-quotient definition of a derivative, and then prove that limit with the $\epsilon$, $\delta$ definition for limits. I said that $$\frac{d}{dx}x^2=\lim_{h\to0}\frac{(x+h)^2-x^2}{h}=\lim_{h\to0}\frac{h^2+2xh}{h}$$ Then we assert that this is equal to $2x$ which we show is true using the $\epsilon$, $\delta$ definition. We must show that for all $\epsilon > 0$, there exists $\delta>0$ such that for all $|h-0|<\delta$ we have $$\left|2x-\frac{h^2+2xh}{h}\right|<\epsilon$$ Assuming $h\neq 0$ this simplifies to $$\left|2x-h-2x\right|=|-h|=|h|<\epsilon$$ So we're left with that for all $|h|<\delta$ we must have $|h|<\epsilon$, which is true for all $\epsilon$ if $\delta=\epsilon$. Hence we can conclude the limit does equal $2x$ and $$\frac{d}{dx}x^2=2x$$ I know its kind of a dull question, so if you have any cool insights or tips to share that'd be appreciated!","I did the following proof earlier and just wanted conformation as to whether it works. The question was to show $$\frac{d}{dx}x^2=2x$$ by the difference-quotient definition of a derivative, and then prove that limit with the $\epsilon$, $\delta$ definition for limits. I said that $$\frac{d}{dx}x^2=\lim_{h\to0}\frac{(x+h)^2-x^2}{h}=\lim_{h\to0}\frac{h^2+2xh}{h}$$ Then we assert that this is equal to $2x$ which we show is true using the $\epsilon$, $\delta$ definition. We must show that for all $\epsilon > 0$, there exists $\delta>0$ such that for all $|h-0|<\delta$ we have $$\left|2x-\frac{h^2+2xh}{h}\right|<\epsilon$$ Assuming $h\neq 0$ this simplifies to $$\left|2x-h-2x\right|=|-h|=|h|<\epsilon$$ So we're left with that for all $|h|<\delta$ we must have $|h|<\epsilon$, which is true for all $\epsilon$ if $\delta=\epsilon$. Hence we can conclude the limit does equal $2x$ and $$\frac{d}{dx}x^2=2x$$ I know its kind of a dull question, so if you have any cool insights or tips to share that'd be appreciated!",,"['calculus', 'limits', 'derivatives', 'proof-verification', 'epsilon-delta']"
37,Finding limit of $\lim_{x\to 0^+}⁡\{[(1+x)^{1/x}]/e\}^{1/x}$ [closed],Finding limit of  [closed],\lim_{x\to 0^+}⁡\{[(1+x)^{1/x}]/e\}^{1/x},"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question This is a question given in our weekly test. $$f = \lim_{x\to 0^+}⁡\{[(1+x)^{1/x}]/e\}^{1/x}.$$ Find the value of $f$. I tried to use 1^ infinity form but I didn't get it. So anybody please help me.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question This is a question given in our weekly test. $$f = \lim_{x\to 0^+}⁡\{[(1+x)^{1/x}]/e\}^{1/x}.$$ Find the value of $f$. I tried to use 1^ infinity form but I didn't get it. So anybody please help me.",,['limits']
38,How to solve $\lim\limits_{x \to -\infty} \left(x\left(\sqrt{x^2-x}-\sqrt{x^2-1}\right)\right)$?,How to solve ?,\lim\limits_{x \to -\infty} \left(x\left(\sqrt{x^2-x}-\sqrt{x^2-1}\right)\right),"I have a problem with this limit, i have no idea how to compute it. Can you explain the method and the steps used? $$\lim\limits_{x \to -\infty} \left(x\left(\sqrt{x^2-x}-\sqrt{x^2-1}\right)\right)$$","I have a problem with this limit, i have no idea how to compute it. Can you explain the method and the steps used? $$\lim\limits_{x \to -\infty} \left(x\left(\sqrt{x^2-x}-\sqrt{x^2-1}\right)\right)$$",,"['calculus', 'limits']"
39,Evaluate $\lim_{n\to \infty}{\sqrt[n]\frac{(2n)!}{n^n\times{n!}}}$,Evaluate,\lim_{n\to \infty}{\sqrt[n]\frac{(2n)!}{n^n\times{n!}}},$$\lim_{n\to \infty}{\sqrt[n]\frac{(2n)!}{n^n\times{n!}}}$$ It is a sequence and n is natural It looks like I should use $\lim_{n\to \infty}{\sqrt[n]{a_n}}=x$ but I don't know how. Does it mean that $a_n=\frac{(2n)!}{n^n\times{n!}}$ and then do it from there or is $a_n=\sqrt[n]\frac{(2n)!}{n^n\times{n!}}$ I have never used this before and I am not sure what to do,$$\lim_{n\to \infty}{\sqrt[n]\frac{(2n)!}{n^n\times{n!}}}$$ It is a sequence and n is natural It looks like I should use $\lim_{n\to \infty}{\sqrt[n]{a_n}}=x$ but I don't know how. Does it mean that $a_n=\frac{(2n)!}{n^n\times{n!}}$ and then do it from there or is $a_n=\sqrt[n]\frac{(2n)!}{n^n\times{n!}}$ I have never used this before and I am not sure what to do,,['limits']
40,Calculus (Limits) Doubt: $\theta - \cfrac{\theta^3}{3!} < \sin \theta < \theta$ use to solve limit.,Calculus (Limits) Doubt:  use to solve limit.,\theta - \cfrac{\theta^3}{3!} < \sin \theta < \theta,"Following is the question I've been trying to work on but can't get enough of it: $$\lim_{n\rightarrow \infty} \sin\left(\cfrac{n}{n^2+1^2}\right) + \sin\left(\cfrac{n}{n^2+2^2}\right) + \cdots + \sin\left({\cfrac{n}{n^2+n^2}}\right) $$ I'm required to find the value of the above limit. All I could think about is to take $n^2$ common from numerator and denominator of each term. $$\lim_{n\rightarrow \infty} \sin\left(\cfrac{1/n}{1+1^2/n^2}\right) + \sin\left(\cfrac{1/n}{1+2^2/n^2}\right) + \cdots + \sin\left({\cfrac{1/n}{1+n^2/n^2}}\right) $$ Now since $n \to \infty$ then shouldn't each term inside the sine function be zero and thus value of limit be zero? Where am I going wrong in this approach? Also, I found a trick for this question specified in my book as: To use the following inequality : $$\color{blue}{\theta - \cfrac{\theta^3}{3!} < \sin \theta < \theta }$$ And then to replace $\theta$ with $\cfrac{n}{n^2+k^2}$. I've never seen this inequality before, can anyone refer to the proof of this inequality? (or give the proof). EDIT : After working with the suggestions posted in the comments and answers: (and the link of the duplicate post) I do get the following equation: $$ \lim_{n \to \infty} \sum_{k=1}^{n} \cfrac{1}{n} \left(\cfrac{1}{1+(k/n)^2}\right)$$ How can I convert this into Integral now?","Following is the question I've been trying to work on but can't get enough of it: $$\lim_{n\rightarrow \infty} \sin\left(\cfrac{n}{n^2+1^2}\right) + \sin\left(\cfrac{n}{n^2+2^2}\right) + \cdots + \sin\left({\cfrac{n}{n^2+n^2}}\right) $$ I'm required to find the value of the above limit. All I could think about is to take $n^2$ common from numerator and denominator of each term. $$\lim_{n\rightarrow \infty} \sin\left(\cfrac{1/n}{1+1^2/n^2}\right) + \sin\left(\cfrac{1/n}{1+2^2/n^2}\right) + \cdots + \sin\left({\cfrac{1/n}{1+n^2/n^2}}\right) $$ Now since $n \to \infty$ then shouldn't each term inside the sine function be zero and thus value of limit be zero? Where am I going wrong in this approach? Also, I found a trick for this question specified in my book as: To use the following inequality : $$\color{blue}{\theta - \cfrac{\theta^3}{3!} < \sin \theta < \theta }$$ And then to replace $\theta$ with $\cfrac{n}{n^2+k^2}$. I've never seen this inequality before, can anyone refer to the proof of this inequality? (or give the proof). EDIT : After working with the suggestions posted in the comments and answers: (and the link of the duplicate post) I do get the following equation: $$ \lim_{n \to \infty} \sum_{k=1}^{n} \cfrac{1}{n} \left(\cfrac{1}{1+(k/n)^2}\right)$$ How can I convert this into Integral now?",,"['calculus', 'limits']"
41,"Existence of $x \in [0, 2]$ such that $f(x) = x^2$",Existence of  such that,"x \in [0, 2] f(x) = x^2","Let $f : [0, 2] → \mathbb R$ be continuous and $f(2) = 0$. If $\lim \limits _{x \to 1} \frac {f(x) − 2} {\sqrt x − 1} = 1$, then prove that there exists $x \in [0, 2]$ such that $f(x) = x^2$. I tried to use L'Hopital's rule to get $f'(1)=\frac 1 2$. But for the foolwing steps I have no idea. Please help!!","Let $f : [0, 2] → \mathbb R$ be continuous and $f(2) = 0$. If $\lim \limits _{x \to 1} \frac {f(x) − 2} {\sqrt x − 1} = 1$, then prove that there exists $x \in [0, 2]$ such that $f(x) = x^2$. I tried to use L'Hopital's rule to get $f'(1)=\frac 1 2$. But for the foolwing steps I have no idea. Please help!!",,"['limits', 'continuity']"
42,Proof of the Product Limit Law,Proof of the Product Limit Law,,"Theorem: $$\lim_{x \to a} f(x) = L$$ $$\lim_{x \to a} g(x) = M$$ Then: $$\lim_{x \to a} f(x) g(x) = LM$$ Obviously, $$|f(x) - L| < \epsilon$$ $$|g(x) - M| < \epsilon$$ But multiplying these together doesnt get the desired: $$|f(x)g(x) - LM| < \epsilon$$ Please, HINTS only!","Theorem: $$\lim_{x \to a} f(x) = L$$ $$\lim_{x \to a} g(x) = M$$ Then: $$\lim_{x \to a} f(x) g(x) = LM$$ Obviously, $$|f(x) - L| < \epsilon$$ $$|g(x) - M| < \epsilon$$ But multiplying these together doesnt get the desired: $$|f(x)g(x) - LM| < \epsilon$$ Please, HINTS only!",,"['calculus', 'real-analysis', 'limits', 'proof-writing', 'epsilon-delta']"
43,"If $x>0$, $\,x^{1/n}$ tends to $1$ as $n\to\infty$","If ,  tends to  as","x>0 \,x^{1/n} 1 n\to\infty",I am looking for a proof possibly using the sandwich theorem and/or Bernoulli's inequality for proving the following statement: If $x>0$ then $x^{1/n}$ tends to $1$.,I am looking for a proof possibly using the sandwich theorem and/or Bernoulli's inequality for proving the following statement: If $x>0$ then $x^{1/n}$ tends to $1$.,,"['calculus', 'limits']"
44,Is my proof that $\lim\limits_{n\to +\infty}\frac{u_{n+1}}{u_n}=1$ correct?,Is my proof that  correct?,\lim\limits_{n\to +\infty}\frac{u_{n+1}}{u_n}=1,"I'm doing an exercise where $(u_n)$ is a numerical sequence which is decreasing and strictly positive.While $(u_n)$ is a numerical sequence which is decreasing and strictly positive, then $(u_n)$ is convergent and its limit is positive which we symbolise by $l$ . Assume that $l\ne 0$ . I have to prove that $\lim\limits_{n\to +\infty}\dfrac{u_{n+1}}{u_n}=1$ . I'm not sure if my proof is correct or not. Can you please check it? Thank you very much! Please excuse my English. We don't study Maths in English. Let $\varepsilon\in ]0;l[$ . So $\exists N\in\mathbb{N},\,\forall n\in\mathbb{N},\,n>N\Longrightarrow |u_n-l|<\varepsilon$ Let $n\in\mathbb{N}$ such as $n>N$ . We also have $n+1>n>N$ . Then: $|u_{n+1}-u_n|=|(u_{n+1}-l)-(u_n-l)|\le |u_{n+1}-l|+|u_n-l|<2\varepsilon$ $(1)$ And we have $|u_n-l|<\varepsilon$ so $0<l-\varepsilon<u_n<l+\varepsilon$ and so whe have $0<\dfrac{1}{u_n}<\dfrac{1}{l-\varepsilon}$ $(2)$ Then $(1)\times (2)$ gives: $\left|\dfrac{u_{n+1}}{u_n}-1\right|<\dfrac{2\varepsilon}{l-\varepsilon}$ We put $\varepsilon '=\dfrac{2\varepsilon}{l-\varepsilon}>0$ . Then $\varepsilon=\dfrac{l\varepsilon '}{2+\varepsilon '}>0$ . While $\varepsilon '>0$ then $\dfrac{\varepsilon '}{2+\varepsilon '}<1$ and because $l>0$ we have then $\varepsilon=\dfrac{l\varepsilon '}{2+\varepsilon '}<l$ And so $\forall\varepsilon '\in\mathbb{R}^{+*},\,\exists\varepsilon\in ]0,l[,\,\varepsilon=\dfrac{l\varepsilon '}{2+\varepsilon '}$ and so $\varepsilon '$ covers $\mathbb{R}^{+*}$ where $\mathbb{R}^{+*}$ is the set of strictly positive real numbers. As a result we have then: $$\forall\varepsilon '\in\mathbb{R}^{+*},\,\exists N\in\mathbb{N},\,\forall n\in\mathbb{N},\, n>N\Longrightarrow\left|\dfrac{u_{n+1}}{u_n}-1\right| <\varepsilon '$$ And so $\lim\limits_{n\to +\infty}\dfrac{u_{n+1}}{u_n}=1$ Edit : $\mathbb{R}^{+*}$ is the set of strictly positive real numbers. Edit2 : Assume that $l\ne 0$ .","I'm doing an exercise where is a numerical sequence which is decreasing and strictly positive.While is a numerical sequence which is decreasing and strictly positive, then is convergent and its limit is positive which we symbolise by . Assume that . I have to prove that . I'm not sure if my proof is correct or not. Can you please check it? Thank you very much! Please excuse my English. We don't study Maths in English. Let . So Let such as . We also have . Then: And we have so and so whe have Then gives: We put . Then . While then and because we have then And so and so covers where is the set of strictly positive real numbers. As a result we have then: And so Edit : is the set of strictly positive real numbers. Edit2 : Assume that .","(u_n) (u_n) (u_n) l l\ne 0 \lim\limits_{n\to +\infty}\dfrac{u_{n+1}}{u_n}=1 \varepsilon\in ]0;l[ \exists N\in\mathbb{N},\,\forall n\in\mathbb{N},\,n>N\Longrightarrow |u_n-l|<\varepsilon n\in\mathbb{N} n>N n+1>n>N |u_{n+1}-u_n|=|(u_{n+1}-l)-(u_n-l)|\le |u_{n+1}-l|+|u_n-l|<2\varepsilon (1) |u_n-l|<\varepsilon 0<l-\varepsilon<u_n<l+\varepsilon 0<\dfrac{1}{u_n}<\dfrac{1}{l-\varepsilon} (2) (1)\times (2) \left|\dfrac{u_{n+1}}{u_n}-1\right|<\dfrac{2\varepsilon}{l-\varepsilon} \varepsilon '=\dfrac{2\varepsilon}{l-\varepsilon}>0 \varepsilon=\dfrac{l\varepsilon '}{2+\varepsilon '}>0 \varepsilon '>0 \dfrac{\varepsilon '}{2+\varepsilon '}<1 l>0 \varepsilon=\dfrac{l\varepsilon '}{2+\varepsilon '}<l \forall\varepsilon '\in\mathbb{R}^{+*},\,\exists\varepsilon\in ]0,l[,\,\varepsilon=\dfrac{l\varepsilon '}{2+\varepsilon '} \varepsilon ' \mathbb{R}^{+*} \mathbb{R}^{+*} \forall\varepsilon '\in\mathbb{R}^{+*},\,\exists N\in\mathbb{N},\,\forall n\in\mathbb{N},\, n>N\Longrightarrow\left|\dfrac{u_{n+1}}{u_n}-1\right| <\varepsilon ' \lim\limits_{n\to +\infty}\dfrac{u_{n+1}}{u_n}=1 \mathbb{R}^{+*} l\ne 0","['real-analysis', 'limits', 'solution-verification', 'epsilon-delta']"
45,Limit $ \lim_{n \to \infty} \sum_{k=1}^n\frac 1 { \sqrt{n^2+k} } $,Limit, \lim_{n \to \infty} \sum_{k=1}^n\frac 1 { \sqrt{n^2+k} } ,(1) $$ \lim_{n \to \infty} \sum_{k=1}^n \frac 1 { \sqrt{n^2+k} }    $$ (2) $$ \lim_{n\to\infty} \frac {1+\sqrt[n]2 + \sqrt[n]3 + ... \sqrt[n]n} {n}  $$ The answers should both be 1.. any hints?,(1) $$ \lim_{n \to \infty} \sum_{k=1}^n \frac 1 { \sqrt{n^2+k} }    $$ (2) $$ \lim_{n\to\infty} \frac {1+\sqrt[n]2 + \sqrt[n]3 + ... \sqrt[n]n} {n}  $$ The answers should both be 1.. any hints?,,"['limits', 'summation']"
46,Is it trivial to say $\mathop {\lim }\limits_{n \to \infty } {(1 + {k \over n})^n} = e^{k}$,Is it trivial to say,\mathop {\lim }\limits_{n \to \infty } {(1 + {k \over n})^n} = e^{k},"Is it trivial to say  $$\mathop {\lim }\limits_{n \to \infty } {(1 + {k \over n})^n} = e^{k},$$ considering the fact that we know $$\mathop {\lim }\limits_{n \to \infty } {(1 + {1 \over n})^n} = e?$$","Is it trivial to say  $$\mathop {\lim }\limits_{n \to \infty } {(1 + {k \over n})^n} = e^{k},$$ considering the fact that we know $$\mathop {\lim }\limits_{n \to \infty } {(1 + {1 \over n})^n} = e?$$",,"['calculus', 'limits', 'exponential-function']"
47,How do I take the limit with invoking L'Hospital's rule? $\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{\ln(x)}\right)$,How do I take the limit with invoking L'Hospital's rule?,\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{\ln(x)}\right),Need to take the limit: $$\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{\ln(x)}\right) = \lim_{x \to 1}\left(\frac{x\cdot \ln(x)-x+1}{(x-1)\cdot \ln(x)}\right)=(0/0)$$ Now I can use L'Hospital's rule: $$\lim_{x \to 1}\left(\frac{1\cdot \ln(x)+x\cdot \frac{1}{x}-1}{1\cdot \ln(x)+(x-1)\cdot\frac{1}{x}}\right)= \lim_{x \to 1}\left(\frac{\ln(x)+1-1}{\ln(x)+\frac{(x-1)}{x}}\right)=\lim_{x \to 1}\left(\frac{\ln(x)}{\frac{(x-1)+x \cdot \ln(x)}{x}}\right)=\lim_{x \to 1}\frac{x\cdot \ln(x)}{x-1+x\cdot \ln(x)}=\frac{1\cdot 0}{1-1+0}=(0/0)$$ As you can see I came to $(0/0)$ again. So what I have to do to solve this problem?,Need to take the limit: $$\lim_{x \to 1}\left(\frac{x}{x-1}-\frac{1}{\ln(x)}\right) = \lim_{x \to 1}\left(\frac{x\cdot \ln(x)-x+1}{(x-1)\cdot \ln(x)}\right)=(0/0)$$ Now I can use L'Hospital's rule: $$\lim_{x \to 1}\left(\frac{1\cdot \ln(x)+x\cdot \frac{1}{x}-1}{1\cdot \ln(x)+(x-1)\cdot\frac{1}{x}}\right)= \lim_{x \to 1}\left(\frac{\ln(x)+1-1}{\ln(x)+\frac{(x-1)}{x}}\right)=\lim_{x \to 1}\left(\frac{\ln(x)}{\frac{(x-1)+x \cdot \ln(x)}{x}}\right)=\lim_{x \to 1}\frac{x\cdot \ln(x)}{x-1+x\cdot \ln(x)}=\frac{1\cdot 0}{1-1+0}=(0/0)$$ As you can see I came to $(0/0)$ again. So what I have to do to solve this problem?,,"['real-analysis', 'limits', 'derivatives']"
48,"Evaluation of $\lim_{n\to\infty} \int_0^1 \frac{e^{\displaystyle x^{n}}}{1+x^2}\,\mathrm{d}x$",Evaluation of,"\lim_{n\to\infty} \int_0^1 \frac{e^{\displaystyle x^{n}}}{1+x^2}\,\mathrm{d}x","Evaluation of $$\lim_{n\to\infty} \int_0^1 \frac{e^{\displaystyle x^{n}}}{1+x^2}\,\mathrm{d}x$$ Sis.","Evaluation of $$\lim_{n\to\infty} \int_0^1 \frac{e^{\displaystyle x^{n}}}{1+x^2}\,\mathrm{d}x$$ Sis.",,"['calculus', 'real-analysis', 'limits', 'definite-integrals', 'contest-math']"
49,Evaluating $\lim_{x \to 0+} \left[ \sin(x)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin(x)}\right] $?,Evaluating ?,\lim_{x \to 0+} \left[ \sin(x)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin(x)}\right] ,"For $x>0$, $$\lim_{x \rightarrow 0} \left[ \sin(x)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin(x)}\right] $$These are two forms of $0^\infty$ and $\infty^0$. I know these are to be evaluated separately and then added. But how do I start?","For $x>0$, $$\lim_{x \rightarrow 0} \left[ \sin(x)^{\frac{1}{x}}+\left(\frac{1}{x}\right)^{\sin(x)}\right] $$These are two forms of $0^\infty$ and $\infty^0$. I know these are to be evaluated separately and then added. But how do I start?",,"['calculus', 'limits']"
50,Help understanding proof of l'Hospital's rule from Rudin,Help understanding proof of l'Hospital's rule from Rudin,,"This is the entire proof for the 0/0 case and I am very lost. I understand choosing $r>A$, but I don't understand why we're choosing $q$. I can see why 18 is true, but I do not understand how the strict inequality becomes a weak inequality going from (18) to (19). Finally, and perhaps most importantly, I don't understand how (19) shows that $f(x)/g(x)\rightarrow A$ as $x\rightarrow a$. Can someone help me follow this through?","This is the entire proof for the 0/0 case and I am very lost. I understand choosing $r>A$, but I don't understand why we're choosing $q$. I can see why 18 is true, but I do not understand how the strict inequality becomes a weak inequality going from (18) to (19). Finally, and perhaps most importantly, I don't understand how (19) shows that $f(x)/g(x)\rightarrow A$ as $x\rightarrow a$. Can someone help me follow this through?",,"['calculus', 'real-analysis', 'limits', 'derivatives', 'proof-explanation']"
51,Show $\lim_{x\to0}\frac{\Gamma(x)}{\psi(x)}=-1$,Show,\lim_{x\to0}\frac{\Gamma(x)}{\psi(x)}=-1,How to show that $$ \lim_{x\to0}\frac{\Gamma(x)}{\psi(x)}=-1 $$ where $\psi(x)$ is the digamma function.,How to show that $$ \lim_{x\to0}\frac{\Gamma(x)}{\psi(x)}=-1 $$ where $\psi(x)$ is the digamma function.,,"['limits', 'special-functions']"
52,How to rigorously prove that $\sum\limits_{n=1}^ \infty( \frac{1}{4n-1} - \frac{1}{4n} )=\frac{\ln(64)- \pi}{8}$?,How to rigorously prove that ?,\sum\limits_{n=1}^ \infty( \frac{1}{4n-1} - \frac{1}{4n} )=\frac{\ln(64)- \pi}{8},"How to rigorously prove that $\sum\limits_{n=1}^ \infty\left( \frac{1}{4n-1} - \frac{1}{4n}\right) =\frac{\ln(64)- \pi}{8}$ ? My attempt $$f_N(x):= \sum_{n=1}^ N \left(\frac{x^{4n-1}}{4n-1} - \frac{x^{4n}}{4n}\right)$$ $$f_N'(x) = \sum_{n=1}^ N( x^{4n-2}- x^{4n-1})= x^{4}\left(\frac{1-x}{x^2}  \right)\frac{x^{4N+4}-1 }{x^4-1}$$ I need to show that $x^{4}\left(\frac{1-x}{x^2}  \right)\frac{x^{4N+4}-1 }{x^4-1}$ converges uniformly to be able to interchange the derivative and the summation, but I don't think $f_N'$ converges uniformly because $$f_N'(x) = \frac{-x^2}{(1+x)(1+x^2)}\cdot (x^{4N+4}-1)  $$ and $(x^{4N+4}-1)$ doesn't converge uniformly on $[0,1 )$ . Here I got stuck but for some reason it works, i.e., $\int_0 ^1 \frac{x^2}{(1+x)(1+x^2)}= \frac{\ln(64)- \pi}{8} $ so the derivative could be interchanged with the summation here, but how ?","How to rigorously prove that ? My attempt I need to show that converges uniformly to be able to interchange the derivative and the summation, but I don't think converges uniformly because and doesn't converge uniformly on . Here I got stuck but for some reason it works, i.e., so the derivative could be interchanged with the summation here, but how ?","\sum\limits_{n=1}^ \infty\left( \frac{1}{4n-1} - \frac{1}{4n}\right) =\frac{\ln(64)- \pi}{8} f_N(x):= \sum_{n=1}^ N \left(\frac{x^{4n-1}}{4n-1} - \frac{x^{4n}}{4n}\right) f_N'(x) = \sum_{n=1}^ N( x^{4n-2}- x^{4n-1})= x^{4}\left(\frac{1-x}{x^2}  \right)\frac{x^{4N+4}-1 }{x^4-1} x^{4}\left(\frac{1-x}{x^2}  \right)\frac{x^{4N+4}-1 }{x^4-1} f_N' f_N'(x) = \frac{-x^2}{(1+x)(1+x^2)}\cdot (x^{4N+4}-1)   (x^{4N+4}-1) [0,1 ) \int_0 ^1 \frac{x^2}{(1+x)(1+x^2)}= \frac{\ln(64)- \pi}{8} ","['real-analysis', 'limits', 'derivatives', 'summation', 'uniform-convergence']"
53,If $\lim\limits_{x\to0}f(x)=0$ and $\lim\limits_{x \to 0}\frac{f(2x)-f(x)}{x}=0$ how to rigorously prove that $\lim\limits_{x \to 0}\frac{f(x)}{x}=0$? [duplicate],If  and  how to rigorously prove that ? [duplicate],\lim\limits_{x\to0}f(x)=0 \lim\limits_{x \to 0}\frac{f(2x)-f(x)}{x}=0 \lim\limits_{x \to 0}\frac{f(x)}{x}=0,"This question already has answers here : If $f(x)$ and $\frac{f(2x)-f(x)}{x}$ have limit $0$ as $x\to 0$, then $\frac{f(x)}{x}\to 0$ (3 answers) Closed 4 months ago . I saw this problem on my problem book: IF $\lim\limits_{x\to0 }f(x)=0$ and $\lim\limits_{x \to 0 }\frac{f(2x)- f(x)}{x} =0$ prove that $\lim_{x \to 0} \frac{f(x)}{x}=0 $ . I tried to solve it but failed the only thing that I was able to prove its that if $\lim_{x \to 0} \frac{f(x)}{x}$ exist in $\overline {\mathbb{R}}$ it it either $0$ or $\pm \infty$ and that it east to show $$\lim_{x \to 0} \frac{f(x)}{x}= \lim_{x \to 0} \frac{f(x)-f(2x)}{x}   + 2\lim_{x \to 0} \frac{f(2x)}{2x}$$ i.e $L = 2L$ But I was not able to prove that the limit exist .","This question already has answers here : If $f(x)$ and $\frac{f(2x)-f(x)}{x}$ have limit $0$ as $x\to 0$, then $\frac{f(x)}{x}\to 0$ (3 answers) Closed 4 months ago . I saw this problem on my problem book: IF and prove that . I tried to solve it but failed the only thing that I was able to prove its that if exist in it it either or and that it east to show i.e But I was not able to prove that the limit exist .",\lim\limits_{x\to0 }f(x)=0 \lim\limits_{x \to 0 }\frac{f(2x)- f(x)}{x} =0 \lim_{x \to 0} \frac{f(x)}{x}=0  \lim_{x \to 0} \frac{f(x)}{x} \overline {\mathbb{R}} 0 \pm \infty \lim_{x \to 0} \frac{f(x)}{x}= \lim_{x \to 0} \frac{f(x)-f(2x)}{x}   + 2\lim_{x \to 0} \frac{f(2x)}{2x} L = 2L,"['real-analysis', 'calculus', 'limits', 'limits-without-lhopital', 'epsilon-delta']"
54,Is the equation $\sec (\pi/2)$= $\tan (\pi/2)$ true?,Is the equation =  true?,\sec (\pi/2) \tan (\pi/2),"While both $\sec (\pi/2)$ and $\tan (\pi/2)$ are undefined they are both basically $1/0$ . In case anyone is unaware of how they equal $1/0$ what we can do is represent $\sec (\pi/2)$ as $\dfrac {1}{\cos (\pi/2)}$ and $\tan (\pi/2)$ as $\dfrac {\sin \pi/2}{\cos \pi/2}$ and once you put in the value they both become $\dfrac {1}{0}$ . The problem is that if $\sec (\pi/2)$ does equal $\tan (\pi/2)$ then the following should be true as well: $\sec (\pi/2)$ = $\tan (\pi/2)$ $\sec^2 (\pi/2) = \tan^2 (\pi/2)$ [By squaring both sides] $\sec^2 (\pi/2) - \tan^2 (\pi/2)$ = 0 [By subtracting $\tan^2 \pi/2$ from both sides] $1 = 0$ [By using the formula $\sec^2 \phi - \tan^2 \phi$ = 1] This is obviously false and from my understanding the problem is either - (i) As I first said, maybe $\sec \pi/2 \neq \tan \pi/2$ (ii) We cannot use the formula $\sec^2 \phi - \tan^2 \phi$ for $\phi = k \pi  + \pi/2$ (where $k \in \mathbb {Z}$ ). This is all from my side, I would still like to mention that I am an highschool kid and might be unaware of rules as school only teaches very limited things and I don't have an consistent method of self studying topics like trigonometry, calculus (please suggest beginner books for calculus if you can), etc. Also this was my first ever question so if there is something that could be changed in the way I am submitting the question please suggest that. Thank you.","While both and are undefined they are both basically . In case anyone is unaware of how they equal what we can do is represent as and as and once you put in the value they both become . The problem is that if does equal then the following should be true as well: = [By squaring both sides] = 0 [By subtracting from both sides] [By using the formula = 1] This is obviously false and from my understanding the problem is either - (i) As I first said, maybe (ii) We cannot use the formula for (where ). This is all from my side, I would still like to mention that I am an highschool kid and might be unaware of rules as school only teaches very limited things and I don't have an consistent method of self studying topics like trigonometry, calculus (please suggest beginner books for calculus if you can), etc. Also this was my first ever question so if there is something that could be changed in the way I am submitting the question please suggest that. Thank you.",\sec (\pi/2) \tan (\pi/2) 1/0 1/0 \sec (\pi/2) \dfrac {1}{\cos (\pi/2)} \tan (\pi/2) \dfrac {\sin \pi/2}{\cos \pi/2} \dfrac {1}{0} \sec (\pi/2) \tan (\pi/2) \sec (\pi/2) \tan (\pi/2) \sec^2 (\pi/2) = \tan^2 (\pi/2) \sec^2 (\pi/2) - \tan^2 (\pi/2) \tan^2 \pi/2 1 = 0 \sec^2 \phi - \tan^2 \phi \sec \pi/2 \neq \tan \pi/2 \sec^2 \phi - \tan^2 \phi \phi = k \pi  + \pi/2 k \in \mathbb {Z},"['limits', 'trigonometry']"
55,Find $C$ such that $\frac{1}{n}\prod_{k=1}^{n}C\left(\cos{\frac{k\pi}{2(n+1)}}+\sin{\frac{k\pi}{2(n+1)}}-1\right)$ converges to a positive number.,Find  such that  converges to a positive number.,C \frac{1}{n}\prod_{k=1}^{n}C\left(\cos{\frac{k\pi}{2(n+1)}}+\sin{\frac{k\pi}{2(n+1)}}-1\right),"I'm looking for the value of $C$ such that $L=\lim\limits_{n\to\infty}\frac{1}{n}\prod\limits_{k=1}^{n}C\left(\cos{\frac{k\pi}{2(n+1)}}+\sin{\frac{k\pi}{2(n+1)}}-1\right)$ equals a positive real number. Desmos suggests $C\approx 4.5395$ . I'm looking for a closed form. (I'm not so interested in the value of $L$ , but I wouldn't mind knowing that also; desmos suggests $L\approx 0.8817$ .) Context: This question is related to another question about an infinite product involving a quarter-circle inscribed in a square. ( $C$ in this question seems to equal $\frac{\pi}{4}A$ in the other question.) I think this question is interesting by itself, so I'm asking it here. My attempt: I have tried to take the log of the product and relate the resulting sum to an integral, but I do not know how to deal with the $\frac{1}{n}$ and also the $(n+1)$ . I have considered using complex numbers, but I do not know how that could be done.","I'm looking for the value of such that equals a positive real number. Desmos suggests . I'm looking for a closed form. (I'm not so interested in the value of , but I wouldn't mind knowing that also; desmos suggests .) Context: This question is related to another question about an infinite product involving a quarter-circle inscribed in a square. ( in this question seems to equal in the other question.) I think this question is interesting by itself, so I'm asking it here. My attempt: I have tried to take the log of the product and relate the resulting sum to an integral, but I do not know how to deal with the and also the . I have considered using complex numbers, but I do not know how that could be done.",C L=\lim\limits_{n\to\infty}\frac{1}{n}\prod\limits_{k=1}^{n}C\left(\cos{\frac{k\pi}{2(n+1)}}+\sin{\frac{k\pi}{2(n+1)}}-1\right) C\approx 4.5395 L L\approx 0.8817 C \frac{\pi}{4}A \frac{1}{n} (n+1),"['limits', 'closed-form', 'infinite-product']"
56,$I_n = \int_1^e (\ln x)^n dx$. Compute $\lim_{n\to\infty} nI_n$,. Compute,I_n = \int_1^e (\ln x)^n dx \lim_{n\to\infty} nI_n,"If $$I_n = \int_1^e (\ln x)^n dx$$ Compute $$\lim_{n\to\infty} nI_n$$ One solution would be to determine the recurrence relation of $I_n$ (using integration by parts), namely $$I_{n+1} + (n+1)I_n = e$$ From the recurrence relation and from the fact that $I_n$ is decreasing we can determine that $$e = I_{n+1} + (n+1)I_n \ge I_{n+1} + (n+1)I_{n+1} = (n+2)I_{n+1}$$ which means that $$I_{n+1} \le \frac{e}{n+2}$$ so $$\lim_{n \to \infty} I_n = 0\tag{1}\label{1}$$ The recurrence relation can be rewritten as $$nI_n = e - I_{n+1} - I_{n}$$ and using $\eqref{1}$ we can conclude that $$\lim_{n\to\infty} nI_n = e$$ Is there another ""more elegant"" solution to this problem? Thank you!","If Compute One solution would be to determine the recurrence relation of (using integration by parts), namely From the recurrence relation and from the fact that is decreasing we can determine that which means that so The recurrence relation can be rewritten as and using we can conclude that Is there another ""more elegant"" solution to this problem? Thank you!",I_n = \int_1^e (\ln x)^n dx \lim_{n\to\infty} nI_n I_n I_{n+1} + (n+1)I_n = e I_n e = I_{n+1} + (n+1)I_n \ge I_{n+1} + (n+1)I_{n+1} = (n+2)I_{n+1} I_{n+1} \le \frac{e}{n+2} \lim_{n \to \infty} I_n = 0\tag{1}\label{1} nI_n = e - I_{n+1} - I_{n} \eqref{1} \lim_{n\to\infty} nI_n = e,"['limits', 'definite-integrals']"
57,Computing the limit at infinity for multivariable function,Computing the limit at infinity for multivariable function,,"I seem to be having problems understanding the epsilon-N definition of limits when the function takes multiple variables. For example, consider the limit $\lim_{(x,y) \rightarrow (\infty, \infty)} xe^{-y}$ , which has come up in my stats homework. My hunch is that this limit should converge to $0$ , as this yields the correct answer and the graph seems to ""flatten out"" in general when looking far away in the first quadrant. Yet, I can neither confirm nor disprove this guess since I cannot find the definition of limits of multivariable functions at infinity. The only definition I could find are those at finite points, in which case a direct generalization of $\epsilon-\delta$ definition for single variable functions could be applied. Could somebody please explain the rigorous definition of limits at infinity? Also, if possible, could you confirm or disprove my guess about $\lim_{(x,y) \rightarrow (\infty, \infty)} xe^{-y}$ ? Thanks very much.","I seem to be having problems understanding the epsilon-N definition of limits when the function takes multiple variables. For example, consider the limit , which has come up in my stats homework. My hunch is that this limit should converge to , as this yields the correct answer and the graph seems to ""flatten out"" in general when looking far away in the first quadrant. Yet, I can neither confirm nor disprove this guess since I cannot find the definition of limits of multivariable functions at infinity. The only definition I could find are those at finite points, in which case a direct generalization of definition for single variable functions could be applied. Could somebody please explain the rigorous definition of limits at infinity? Also, if possible, could you confirm or disprove my guess about ? Thanks very much.","\lim_{(x,y) \rightarrow (\infty, \infty)} xe^{-y} 0 \epsilon-\delta \lim_{(x,y) \rightarrow (\infty, \infty)} xe^{-y}","['limits', 'multivariable-calculus', 'definition', 'epsilon-delta']"
58,How to find a condition for when a multivariable limit exists,How to find a condition for when a multivariable limit exists,,"If I have the multivariable limit $$ \lim_{(x,y) \to (0,0)} \frac{x^ay^b}{(x+y)^c} $$ How do I find a general relationship/condition for $a$ , $b$ , $c$ that results in the limit existing? I've found various specific examples of $a$ , $b$ , $c$ that make the limit exist, but I don't know what the relationship between them is.","If I have the multivariable limit How do I find a general relationship/condition for , , that results in the limit existing? I've found various specific examples of , , that make the limit exist, but I don't know what the relationship between them is."," \lim_{(x,y) \to (0,0)} \frac{x^ay^b}{(x+y)^c}  a b c a b c","['real-analysis', 'limits', 'multivariable-calculus']"
59,How do I know if this limit even converges?,How do I know if this limit even converges?,,"So, there is this question which I found quite new according to my experience, and it is as follows. Assuming that interchange of limit and integration is permissible, evaluate the following: $$\lim_{n \to \infty} {\int_0^1 \frac{nx^{n -1}}{1 + x}dx}, \quad 0 < x < 1$$ Now, I first tried integration by parts, and it doesn't give me more than an expression which is also nearly impossible to evaluate (maybe I'm doing it wrong, though) - $$\lim_{n \to \infty} \left|\frac{1}{1+x}\int nx^{n - 1}dx  +  \int\frac{x^n}{(1 + x)^2}dx\right|_0^1$$ I'm not sure how to proceed from there, so I tried this instead: $$\lim_{n \to \infty} {\int_0^1 {nx^{n - 1}(1 + x)^{-1}}dx}$$ Expanding $(1 + x)^{-1}$ using Taylor Series: $$\lim_{n \to \infty} {\int_0^1 {nx^{n - 1}(1 - x + x^2 - x^3 + x^4 - x^5 \ldots)}dx}$$ $$ = \lim_{n \to \infty} {\int_0^1 {(nx^{n - 1} - nx^n + nx^{n + 1} - nx^{n + 2} + nx^{n + 3} - n^{x + 4} \ldots)}dx}$$ $$\lim_{n \to \infty} \left(1 - \frac{n}{n+1} + \frac{n}{n+2} - \frac{n}{n +3} + \frac{n}{n +4} - \frac{n}{n + 5}\ldots\right)$$ I think that diverges. Then, I tried putting the expression in Desmos and increased the $n$ value slowly upto $500$ , $1000$ and similar big numbers - which all returned values around $0.5$ . The question was an multiple-choice based and there were both of them listed as options. I'm not sure who is correct, the calculator, or me. It would be a huge help if someone looks into this. Thank you in advance.","So, there is this question which I found quite new according to my experience, and it is as follows. Assuming that interchange of limit and integration is permissible, evaluate the following: Now, I first tried integration by parts, and it doesn't give me more than an expression which is also nearly impossible to evaluate (maybe I'm doing it wrong, though) - I'm not sure how to proceed from there, so I tried this instead: Expanding using Taylor Series: I think that diverges. Then, I tried putting the expression in Desmos and increased the value slowly upto , and similar big numbers - which all returned values around . The question was an multiple-choice based and there were both of them listed as options. I'm not sure who is correct, the calculator, or me. It would be a huge help if someone looks into this. Thank you in advance.","\lim_{n \to \infty} {\int_0^1 \frac{nx^{n -1}}{1 + x}dx}, \quad 0 < x < 1 \lim_{n \to \infty} \left|\frac{1}{1+x}\int nx^{n - 1}dx  +  \int\frac{x^n}{(1 + x)^2}dx\right|_0^1 \lim_{n \to \infty} {\int_0^1 {nx^{n - 1}(1 + x)^{-1}}dx} (1 + x)^{-1} \lim_{n \to \infty} {\int_0^1 {nx^{n - 1}(1 - x + x^2 - x^3 + x^4 - x^5 \ldots)}dx}  = \lim_{n \to \infty} {\int_0^1 {(nx^{n - 1} - nx^n + nx^{n + 1} - nx^{n + 2} + nx^{n + 3} - n^{x + 4} \ldots)}dx} \lim_{n \to \infty} \left(1 - \frac{n}{n+1} + \frac{n}{n+2} - \frac{n}{n +3} + \frac{n}{n +4} - \frac{n}{n + 5}\ldots\right) n 500 1000 0.5","['calculus', 'limits', 'definite-integrals']"
60,"Calculate $ \lim_{\left(x,y\right)\to\left(0,0\right)}\frac{\sin\left(x^{3}+y^{3}\right)}{\sin\left(x^{2}+y^{2}\right)} $",Calculate," \lim_{\left(x,y\right)\to\left(0,0\right)}\frac{\sin\left(x^{3}+y^{3}\right)}{\sin\left(x^{2}+y^{2}\right)} ","I have to calculate $ \lim_{\left(x,y\right)\to\left(0,0\right)}\frac{\sin\left(x^{3}+y^{3}\right)}{\sin\left(x^{2}+y^{2}\right)} $ From wolfram calculator I know the limit is $ 0 $ . The onl way I cant think of proving it is switch to polar, and to show that $ \lim_{r\to0}\frac{\sin\left(r^{3}\left(\cos^{3}\theta+\sin^{3}\theta\right)\right)}{\sin\left(r^{2}\right)} $ is $ 0$ . If I'll treat $ \theta $ as a constant and I'll get that the limit is zero, is that mean that from any direction that the function getting closer to zero, the limit is zero? If so, I could show it using l'Hospital's rule and I guess it would be easy, but I'm not sure its legit. Thanks in advance","I have to calculate From wolfram calculator I know the limit is . The onl way I cant think of proving it is switch to polar, and to show that is . If I'll treat as a constant and I'll get that the limit is zero, is that mean that from any direction that the function getting closer to zero, the limit is zero? If so, I could show it using l'Hospital's rule and I guess it would be easy, but I'm not sure its legit. Thanks in advance"," \lim_{\left(x,y\right)\to\left(0,0\right)}\frac{\sin\left(x^{3}+y^{3}\right)}{\sin\left(x^{2}+y^{2}\right)}   0   \lim_{r\to0}\frac{\sin\left(r^{3}\left(\cos^{3}\theta+\sin^{3}\theta\right)\right)}{\sin\left(r^{2}\right)}   0  \theta ","['limits', 'multivariable-calculus']"
61,Limit related to $ f(x) = \prod_{i = 1}^x \left( \sin\left( i \frac{\pi}{n}\right) + \frac{5}{4}\right) $?,Limit related to ?, f(x) = \prod_{i = 1}^x \left( \sin\left( i \frac{\pi}{n}\right) + \frac{5}{4}\right) ,Let $n$ be a positive integer. Let $b = 2 n - 1$ . Let $x$ be a positive integer. Define $f(x)$ as : $$ f(x) = \prod_{i = 1}^x \left( \sin\left( i \frac{\pi}{n}\right) + \frac{5}{4}\right) $$ Then it appears that $$ f(b) = \frac{4}{5} + C(n)$$ And $C(n)$ is close to zero. In fact $$ \lim_{n \to \infty} C(n) = 0 $$ How do we prove this ??,Let be a positive integer. Let . Let be a positive integer. Define as : Then it appears that And is close to zero. In fact How do we prove this ??,n b = 2 n - 1 x f(x)  f(x) = \prod_{i = 1}^x \left( \sin\left( i \frac{\pi}{n}\right) + \frac{5}{4}\right)   f(b) = \frac{4}{5} + C(n) C(n)  \lim_{n \to \infty} C(n) = 0 ,"['real-analysis', 'limits', 'trigonometry', 'asymptotics', 'products']"
62,Prove $\lim_{x \to a} \cos{x} = \cos{a}$ using a $\varepsilon$-$\delta$ argument,Prove  using a - argument,\lim_{x \to a} \cos{x} = \cos{a} \varepsilon \delta,Prove $\lim\limits_{x \to a} \cos{x} = \cos{a}$ with $\varepsilon$ - $\delta$ . Is proving $|\cos{x}-\cos{a}| \leq |x-a|$ with MVT the only way possible?,Prove with - . Is proving with MVT the only way possible?,\lim\limits_{x \to a} \cos{x} = \cos{a} \varepsilon \delta |\cos{x}-\cos{a}| \leq |x-a|,"['real-analysis', 'limits', 'epsilon-delta']"
63,Prove that $\lim n\int_1^a\frac{1}{1+x^n}dx=\ln 2$,Prove that,\lim n\int_1^a\frac{1}{1+x^n}dx=\ln 2,"My problem is that for a given $a>1$ , we have that $$\lim_{n\to\infty}n\int_{1}^{a}\frac{1}{1+x^n}dx=\ln 2$$ The natural idea seems to be to add and substract $x^n$ from the numerator and we obtain easily that $$n\int_{1}^{a}\frac{1}{1+x^n}dx=n(a-1)-a\ln(1+a^n)+\ln2+\int_1^a\ln(1+x^n)dx$$ which would sort of explain the $\ln 2$ result but I can't continue from here.","My problem is that for a given , we have that The natural idea seems to be to add and substract from the numerator and we obtain easily that which would sort of explain the result but I can't continue from here.",a>1 \lim_{n\to\infty}n\int_{1}^{a}\frac{1}{1+x^n}dx=\ln 2 x^n n\int_{1}^{a}\frac{1}{1+x^n}dx=n(a-1)-a\ln(1+a^n)+\ln2+\int_1^a\ln(1+x^n)dx \ln 2,"['real-analysis', 'limits', 'definite-integrals']"
64,How to evaluate: $\lim\limits_{n\to\infty} \frac{1^{p-1}+2^{p-1}+...+n^{p-1}}{n^p}$,How to evaluate:,\lim\limits_{n\to\infty} \frac{1^{p-1}+2^{p-1}+...+n^{p-1}}{n^p},"How to evaluate: $$\lim_{n\to\infty} \dfrac{1^{p-1}+2^{p-1}+...+n^{p-1}}{n^p}$$ when $i)$ $p\in\mathbb R,p\neq0$ $ii)\space p=0$ So for $i)$ I tried using Stolz–Cesàro theorem and Binomial theorem and If I didn't mess up I got $1$ . But I'm unsure about it, but for $ii)$ and I don't have a clue where to begin with.","How to evaluate: when So for I tried using Stolz–Cesàro theorem and Binomial theorem and If I didn't mess up I got . But I'm unsure about it, but for and I don't have a clue where to begin with.","\lim_{n\to\infty} \dfrac{1^{p-1}+2^{p-1}+...+n^{p-1}}{n^p} i) p\in\mathbb R,p\neq0 ii)\space p=0 i) 1 ii)","['calculus', 'limits', 'analysis', 'limits-without-lhopital']"
65,Compute $\lim_{x\to 1^+} \lim_{n\to\infty}\frac{\ln(n!)}{n^x} $,Compute,\lim_{x\to 1^+} \lim_{n\to\infty}\frac{\ln(n!)}{n^x} ,May someone give me a hand on this double limit? Does the order of limits impact the result? $$\lim_{x\to 1^+} \lim_{n\to\infty}\frac{\ln(n!)}{n^x} $$ I showed that the interior of the limits is inferior to the following expression: $$  \frac{\ln(n)}{{n^{x-1}}} $$ Thanks in advance :),May someone give me a hand on this double limit? Does the order of limits impact the result? $$\lim_{x\to 1^+} \lim_{n\to\infty}\frac{\ln(n!)}{n^x} $$ I showed that the interior of the limits is inferior to the following expression: $$  \frac{\ln(n)}{{n^{x-1}}} $$ Thanks in advance :),,['limits']
66,Derivative of $\frac{1}{\sqrt{x-5}}$ via definition of derivative,Derivative of  via definition of derivative,\frac{1}{\sqrt{x-5}},"A high school student has asked me to help with a limit. The teacher wants them to calculate the derivative of $$\frac{1}{\sqrt{x-5}}$$ at the point $x=9$ using the definition of the derivative. AND! They don't know $(1+x)^\alpha \approx 1 + \alpha x$. I'm puzzled since don't know how to proceed without it. $$\left.\left(\dfrac{1}{\sqrt{x-5}}\right)'\,\right|_{x=9}  = \lim_{h\to 0} \dfrac{1}{h}\left(\dfrac{1}{\sqrt{4+h}}-\dfrac{1}{2}\right)= \lim_{h\to 0} \dfrac{1}{2h}\left((1+h/4)^{-1/2}-1\right)\color{red}{{\bf=}}-1/16 $$ Is there really a way to walk around?.. BTW, what is the easiest way to derive $(1+x)^\alpha \approx 1 + \alpha x$ for $\alpha \in \mathbb{R}$? I forgot how we did this in school.","A high school student has asked me to help with a limit. The teacher wants them to calculate the derivative of $$\frac{1}{\sqrt{x-5}}$$ at the point $x=9$ using the definition of the derivative. AND! They don't know $(1+x)^\alpha \approx 1 + \alpha x$. I'm puzzled since don't know how to proceed without it. $$\left.\left(\dfrac{1}{\sqrt{x-5}}\right)'\,\right|_{x=9}  = \lim_{h\to 0} \dfrac{1}{h}\left(\dfrac{1}{\sqrt{4+h}}-\dfrac{1}{2}\right)= \lim_{h\to 0} \dfrac{1}{2h}\left((1+h/4)^{-1/2}-1\right)\color{red}{{\bf=}}-1/16 $$ Is there really a way to walk around?.. BTW, what is the easiest way to derive $(1+x)^\alpha \approx 1 + \alpha x$ for $\alpha \in \mathbb{R}$? I forgot how we did this in school.",,"['calculus', 'limits']"
67,Proof that Rényi divergence = KL divergence when $\alpha \rightarrow 1$,Proof that Rényi divergence = KL divergence when,\alpha \rightarrow 1,Kullback–Leibler divergence between two parametrized distributions is defined as: $$ D_{KL}(q(\theta) || p(\theta)) = \int q(\theta) \log \frac{q(\theta)}{p(\theta)} d\theta $$ Rényi divergence is defined as: $$ D_{\alpha}(q(\theta) || p(\theta)) = \frac{1}{\alpha-1} \log\int p(\theta)^\alpha q(\theta)^{1-\alpha} d\theta $$ It is known that the KL divergence is a particular case of Rényi divergence when $\alpha \rightarrow 1$. But what is the proof for that?,Kullback–Leibler divergence between two parametrized distributions is defined as: $$ D_{KL}(q(\theta) || p(\theta)) = \int q(\theta) \log \frac{q(\theta)}{p(\theta)} d\theta $$ Rényi divergence is defined as: $$ D_{\alpha}(q(\theta) || p(\theta)) = \frac{1}{\alpha-1} \log\int p(\theta)^\alpha q(\theta)^{1-\alpha} d\theta $$ It is known that the KL divergence is a particular case of Rényi divergence when $\alpha \rightarrow 1$. But what is the proof for that?,,"['limits', 'statistics', 'divergence-operator']"
68,Why is $\lim_{n \rightarrow \infty} \bigg( \bigg| \frac{n^{n^2} (n+2)^{(n+1)^2}}{(n+1)^{2n^2+2n+1}} \bigg| \bigg)=e$? [closed],Why is ? [closed],\lim_{n \rightarrow \infty} \bigg( \bigg| \frac{n^{n^2} (n+2)^{(n+1)^2}}{(n+1)^{2n^2+2n+1}} \bigg| \bigg)=e,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I know that the following is the correct limit, but I have difficulties in seeing just why this is. $$\lim_{n\to\infty}\left| \frac{n^{n^2} (n+2)^{(n+1)^2}}{(n+1)^{2n^2+2n+1}}\right|=e$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question I know that the following is the correct limit, but I have difficulties in seeing just why this is. $$\lim_{n\to\infty}\left| \frac{n^{n^2} (n+2)^{(n+1)^2}}{(n+1)^{2n^2+2n+1}}\right|=e$$",,"['limits', 'exponential-function']"
69,$\lim_{x\rightarrow 0}\frac{1-\cos a_{1}x \cdot \cos a_{2}x\cdot \cos a_{3}x\cdot \cdot \cdot \cdot \cdot \cos a_{n}x}{x^2}$,,\lim_{x\rightarrow 0}\frac{1-\cos a_{1}x \cdot \cos a_{2}x\cdot \cos a_{3}x\cdot \cdot \cdot \cdot \cdot \cos a_{n}x}{x^2},$\displaystyle \lim_{x\rightarrow 0}\frac{1-\cos a_{1}x \cdot \cos a_{2}x\cdot \cos a_{3}x\cdot \cdot \cdot \cdot \cdot \cos a_{n}x}{x^2}$ without D l hospital rule and series expansion. i have solved it series expansion of $\cos x$ but want be able to go  further without series expansion,$\displaystyle \lim_{x\rightarrow 0}\frac{1-\cos a_{1}x \cdot \cos a_{2}x\cdot \cos a_{3}x\cdot \cdot \cdot \cdot \cdot \cos a_{n}x}{x^2}$ without D l hospital rule and series expansion. i have solved it series expansion of $\cos x$ but want be able to go  further without series expansion,,['limits']
70,Uniform convergence of sequence of function necessary for switching limits,Uniform convergence of sequence of function necessary for switching limits,,"If a sequence of function $f_n(x)$ converges to $f(x)$ uniformly, we know that we have $$\lim_{t\to x}\lim_{n\to\infty}f_n(t)=\lim_{n\to\infty}\lim_{t\to x}f_n(t)$$ My question is: Is uniformly convergence necessary for the above to hold?","If a sequence of function $f_n(x)$ converges to $f(x)$ uniformly, we know that we have $$\lim_{t\to x}\lim_{n\to\infty}f_n(t)=\lim_{n\to\infty}\lim_{t\to x}f_n(t)$$ My question is: Is uniformly convergence necessary for the above to hold?",,"['real-analysis', 'limits', 'uniform-convergence']"
71,$\lim_{x\to \infty} \ln x=\infty$,,\lim_{x\to \infty} \ln x=\infty,I'm reading the following reasoning: Since $\underset{n\to \infty}{\lim}\ln 2^n=\underset{n \to \infty}{\lim}n\cdot(\ln 2)=\infty$ then necessarily $\underset{x\to \infty}{\lim}\ln x =\infty$. I don't understand how the generalisation was done from $\lim_{n\to \infty}\ln 2^n=\infty$ to $\lim_{x\to \infty} \ln x=\infty$. Thank you for your help!,I'm reading the following reasoning: Since $\underset{n\to \infty}{\lim}\ln 2^n=\underset{n \to \infty}{\lim}n\cdot(\ln 2)=\infty$ then necessarily $\underset{x\to \infty}{\lim}\ln x =\infty$. I don't understand how the generalisation was done from $\lim_{n\to \infty}\ln 2^n=\infty$ to $\lim_{x\to \infty} \ln x=\infty$. Thank you for your help!,,"['calculus', 'limits', 'logarithms']"
72,"Is it allowed to ""ignore"" $\lim$ in this case?","Is it allowed to ""ignore""  in this case?",\lim,"I have to prove $\lim_{x\to0}(1+x)^{1/x}=e$. Now I would like to perform the following operations: $$\lim_{x\to0}(1+x)^{1/x}=e$$$$\lim_{x\to0}\ln(1+x)^{1/x}=1$$$$\lim_{x\to0}\frac{\ln(1+x)}x=1$$   And then using L'Hôpital's rule   $$\lim_{x\to0}\frac{1}{1+x}=1$$ But the first step doesn't seem kosher, as I'm taking the logarithm ""over"" the limit, is there some way to justify that?","I have to prove $\lim_{x\to0}(1+x)^{1/x}=e$. Now I would like to perform the following operations: $$\lim_{x\to0}(1+x)^{1/x}=e$$$$\lim_{x\to0}\ln(1+x)^{1/x}=1$$$$\lim_{x\to0}\frac{\ln(1+x)}x=1$$   And then using L'Hôpital's rule   $$\lim_{x\to0}\frac{1}{1+x}=1$$ But the first step doesn't seem kosher, as I'm taking the logarithm ""over"" the limit, is there some way to justify that?",,['limits']
73,Trigonometric limit $\lim_{x\to\pi/4}\frac{1-\tan x}{1-\sqrt{2}\sin x}$,Trigonometric limit,\lim_{x\to\pi/4}\frac{1-\tan x}{1-\sqrt{2}\sin x},The limit is $$\lim_{x\to\pi/4}\frac{1-\tan x}{1-\sqrt{2}\sin x}$$ I was able to solve it using L'hopital and the answer that I got was $2$. Can you please confirm if the answer is right and suggest some other way to evaluate the limit without using L'hopital?,The limit is $$\lim_{x\to\pi/4}\frac{1-\tan x}{1-\sqrt{2}\sin x}$$ I was able to solve it using L'hopital and the answer that I got was $2$. Can you please confirm if the answer is right and suggest some other way to evaluate the limit without using L'hopital?,,"['calculus', 'limits', 'limits-without-lhopital']"
74,If $\tan x$ is not a differentiable function then why does its differentiation $\sec^2(x)$ exists?,If  is not a differentiable function then why does its differentiation  exists?,\tan x \sec^2(x),"$\tan x$ is not differentiable at $(2n + 1)90$ points, which means function itself is not differentiable. So, why does its differentiation $\sec^2(x)$ exists?","$\tan x$ is not differentiable at $(2n + 1)90$ points, which means function itself is not differentiable. So, why does its differentiation $\sec^2(x)$ exists?",,"['calculus', 'limits', 'trigonometry', 'derivatives']"
75,Prove that if $\lim_{n\to \infty}{\frac{a_{n+1}}{a_n}}=x$ then $\lim_{n\to \infty}{\sqrt[n]{a_n}}=x$,Prove that if  then,\lim_{n\to \infty}{\frac{a_{n+1}}{a_n}}=x \lim_{n\to \infty}{\sqrt[n]{a_n}}=x,"Prove that if $\lim_{n\to \infty}{\frac{a_{n+1}}{a_n}}=x$ then $\lim_{n\to \infty}{\sqrt[n]{a_n}}=x$ My proposed solution uses the following prepositions: Proposition 4.7. Let $a_n$ be a sequence of real numbers such that ${\sqrt[n]{a_n}}$ converges to L. If L < 1 the sequence converges to zero, if L > 1 the sequence is divergent, if L = 1 the test is inconclusive. Proposition 4.8. Let $a_n$ be a sequence of real numbers such that $\frac{a_{n+1}}{a_n}$ converges to L. If L < 1 the sequence converges to zero, if L > 1 the sequence is divergent, if L = 1 the test is inconclusive. These tests are perfectly equivalent and so their limits must be the same. That is my solution but we were given the hint that we could use the result $\lim_{n\to \infty}{a_n^s}=x^s$ where s is rational and I have not used this hint which makes me think my solution is wrong. Also my solution seems too simple.","Prove that if $\lim_{n\to \infty}{\frac{a_{n+1}}{a_n}}=x$ then $\lim_{n\to \infty}{\sqrt[n]{a_n}}=x$ My proposed solution uses the following prepositions: Proposition 4.7. Let $a_n$ be a sequence of real numbers such that ${\sqrt[n]{a_n}}$ converges to L. If L < 1 the sequence converges to zero, if L > 1 the sequence is divergent, if L = 1 the test is inconclusive. Proposition 4.8. Let $a_n$ be a sequence of real numbers such that $\frac{a_{n+1}}{a_n}$ converges to L. If L < 1 the sequence converges to zero, if L > 1 the sequence is divergent, if L = 1 the test is inconclusive. These tests are perfectly equivalent and so their limits must be the same. That is my solution but we were given the hint that we could use the result $\lim_{n\to \infty}{a_n^s}=x^s$ where s is rational and I have not used this hint which makes me think my solution is wrong. Also my solution seems too simple.",,['limits']
76,How to prove that if the one sided limits are equal the general limit is that value?,How to prove that if the one sided limits are equal the general limit is that value?,,"My teacher proposed this question as a challenge proof to do on our own and I can't seem to get it. Was Wondering if anyone could give me a hint or help me on the process to completing it. Let $a \in \mathbb{R}$. Let $f$ be a function defined, at least, on an interval  centred at $a$, except possibly at $a$. Let $L \in \mathbb{R}$. If $\lim\limits_{ x→a-} f(x) = \lim\limits_{ x→a+} f(x) = L$   then $\lim\limits_{ x→a} f(x) $ = $L$. We are supposed to prove this using the ""delta-epsilon"" proof style. Thanks in advance!!","My teacher proposed this question as a challenge proof to do on our own and I can't seem to get it. Was Wondering if anyone could give me a hint or help me on the process to completing it. Let $a \in \mathbb{R}$. Let $f$ be a function defined, at least, on an interval  centred at $a$, except possibly at $a$. Let $L \in \mathbb{R}$. If $\lim\limits_{ x→a-} f(x) = \lim\limits_{ x→a+} f(x) = L$   then $\lim\limits_{ x→a} f(x) $ = $L$. We are supposed to prove this using the ""delta-epsilon"" proof style. Thanks in advance!!",,"['calculus', 'analysis', 'limits']"
77,Compute $\lim_{x \to 0} x \lfloor x - \frac{1}{x} \rfloor$,Compute,\lim_{x \to 0} x \lfloor x - \frac{1}{x} \rfloor,"Let $f: \mathbb{R} \to \mathbb{R}$ be the following function: $f(x) = x \lfloor x - \frac{1}{x} \rfloor$ Show that $f(x)$ admits a limit at zero, and compute its value. Using epsilon delta, I can prove that $\lim_{x \to 0} x \lfloor x - \frac{1}{x} \rfloor = - 1$: $|x \lfloor x - \frac{1}{x} \rfloor + 1|$ $\leq |x \lfloor x - \frac{1}{x} \rfloor| + |1|$ $\leq |x| |\lfloor x - \frac{1}{x} \rfloor| + |1|$ $\leq |x| |x| + |1|$ $\leq |x|^2 + |1| < \epsilon$ if $|x| < \delta = \sqrt{\epsilon - 1}$ Is that right? If not, how can I do prove it? But how do I show that $\lim_{x \to 0} x \lfloor x - \frac{1}{x} \rfloor$ exists?","Let $f: \mathbb{R} \to \mathbb{R}$ be the following function: $f(x) = x \lfloor x - \frac{1}{x} \rfloor$ Show that $f(x)$ admits a limit at zero, and compute its value. Using epsilon delta, I can prove that $\lim_{x \to 0} x \lfloor x - \frac{1}{x} \rfloor = - 1$: $|x \lfloor x - \frac{1}{x} \rfloor + 1|$ $\leq |x \lfloor x - \frac{1}{x} \rfloor| + |1|$ $\leq |x| |\lfloor x - \frac{1}{x} \rfloor| + |1|$ $\leq |x| |x| + |1|$ $\leq |x|^2 + |1| < \epsilon$ if $|x| < \delta = \sqrt{\epsilon - 1}$ Is that right? If not, how can I do prove it? But how do I show that $\lim_{x \to 0} x \lfloor x - \frac{1}{x} \rfloor$ exists?",,"['calculus', 'limits']"
78,Limit proof of $\big(e^x-1\big)\big/\big(e^{2x}-1\big)$ by epsilon-delta,Limit proof of  by epsilon-delta,\big(e^x-1\big)\big/\big(e^{2x}-1\big),"I'm struggling to derive estimates for delta to prove the following limit, $$\lim_{x\rightarrow 0}\frac{e^x-1}{e^{2x}-1}=\frac{1}{2}$$ What I've got: $$\forall \varepsilon >0, \exists \delta >0 \text{ such that } |x-0|<\delta \Rightarrow \left|\frac{e^x-1}{e^{2x}-1}-\frac{1}{2}\right|<\varepsilon.$$ Observe $$\frac{e^x-1}{e^{2x}-1}=\frac{1}{e^x+1}$$ and so we have $$\left|\frac{1}{e^x+1}-\frac{1}{2}\right|=\left|\frac{e^x-1}{2(e^x+1)}\right|$$ Since the exponential function is increasing for all $x$ we have $$|x|<\delta \\ \Rightarrow e^{-\delta}<e^x<e^\delta \\ \Rightarrow e^{-\delta}-1<e^x-1<e^\delta-1$$ and also $$\frac{e^\delta}{e^\delta+1}>\frac{1}{e^x+1}>\frac{1}{e^\delta+1}.$$ This is all I've gotten up to at the moment and clearly it becomes quite messy when I try to find an explicit form for $\delta(\varepsilon)$. Have I made a mistake somewhere? Thanks","I'm struggling to derive estimates for delta to prove the following limit, $$\lim_{x\rightarrow 0}\frac{e^x-1}{e^{2x}-1}=\frac{1}{2}$$ What I've got: $$\forall \varepsilon >0, \exists \delta >0 \text{ such that } |x-0|<\delta \Rightarrow \left|\frac{e^x-1}{e^{2x}-1}-\frac{1}{2}\right|<\varepsilon.$$ Observe $$\frac{e^x-1}{e^{2x}-1}=\frac{1}{e^x+1}$$ and so we have $$\left|\frac{1}{e^x+1}-\frac{1}{2}\right|=\left|\frac{e^x-1}{2(e^x+1)}\right|$$ Since the exponential function is increasing for all $x$ we have $$|x|<\delta \\ \Rightarrow e^{-\delta}<e^x<e^\delta \\ \Rightarrow e^{-\delta}-1<e^x-1<e^\delta-1$$ and also $$\frac{e^\delta}{e^\delta+1}>\frac{1}{e^x+1}>\frac{1}{e^\delta+1}.$$ This is all I've gotten up to at the moment and clearly it becomes quite messy when I try to find an explicit form for $\delta(\varepsilon)$. Have I made a mistake somewhere? Thanks",,"['real-analysis', 'limits', 'epsilon-delta']"
79,Root of $(x+a)^{x+a}=x^{x+2a}$ and $e$,Root of  and,(x+a)^{x+a}=x^{x+2a} e,"Let us denote solution to the equation $$(x+a)^{x+a}=x^{x+2a}$$ with $X_a$. ($a$ is a non-zero real number) Prove that: $$\lim_ {a \to 0} X_a = e$$ This is something that I noticed while making numerical experiments for another problem. The statement looks interesting, I couldn't find anything close to it on the internet. I don't have the idea how to prove it, but numerical methods confirm the statement.","Let us denote solution to the equation $$(x+a)^{x+a}=x^{x+2a}$$ with $X_a$. ($a$ is a non-zero real number) Prove that: $$\lim_ {a \to 0} X_a = e$$ This is something that I noticed while making numerical experiments for another problem. The statement looks interesting, I couldn't find anything close to it on the internet. I don't have the idea how to prove it, but numerical methods confirm the statement.",,"['limits', 'exponential-function', 'roots']"
80,Computing a limit similar to the exponential function,Computing a limit similar to the exponential function,,"I want to show the following limit: $$ \lim_{n \to \infty} n \left[     \left( 1 - \frac{1}{n} \right)^{2n}     - \left( 1 - \frac{2}{n} \right)^{n} \right]     = \frac{1}{e^{2}}. $$ I got the answer using WolframAlpha, and it seems to be correct numerically, but I am having trouble proving the result. My first instinct was to write the limit as $$ \lim_{n \to \infty} \frac {     \left( 1 - \frac{1}{n} \right)^{2n}     - \left( 1 - \frac{2}{n} \right)^{n} } {1/n}. $$ Then, I tried applying l'Hopital's rule, and I got $$ \lim_{n \to \infty} \frac {     \left( 1 - \frac{1}{n} \right)^{2n}     \left( 2 \log\left( 1 - \frac{1}{n} \right) + \frac{2}{n-1} \right)     -     \left( 1 - \frac{2}{n} \right)^{n}     \left( \log\left( 1 - \frac{2}{n} \right) + \frac{2}{n-2} \right) } {-1/n^{2}}. $$ This does not seem to have gotten me anywhere. My second attempt was to use the binomial theorem: $$ \begin{align*} n \left[     \left( 1 - \frac{1}{n} \right)^{2n}   - \left( 1 - \frac{2}{n} \right)^{n} \right] & = n \left[     \sum_{k=0}^{2n} \binom{2n}{k} \frac{(-1)^{k}}{n^{k}}   - \sum_{k=0}^{n} \binom{n}{k} \frac{(-1)^{k} 2^{k}}{n^{k}} \right] \\ & = \sum_{k=2}^{n} \left[ \binom{2n}{k} - \binom{n}{k} 2^{k} \right] \frac{(-1)^{k}}{n^{k-1}} + \sum_{k=n+1}^{2n} \binom{2n}{k} \frac{(-1)^{k}}{n^{k-1}}. \end{align*} $$ At this point I got stuck again.","I want to show the following limit: $$ \lim_{n \to \infty} n \left[     \left( 1 - \frac{1}{n} \right)^{2n}     - \left( 1 - \frac{2}{n} \right)^{n} \right]     = \frac{1}{e^{2}}. $$ I got the answer using WolframAlpha, and it seems to be correct numerically, but I am having trouble proving the result. My first instinct was to write the limit as $$ \lim_{n \to \infty} \frac {     \left( 1 - \frac{1}{n} \right)^{2n}     - \left( 1 - \frac{2}{n} \right)^{n} } {1/n}. $$ Then, I tried applying l'Hopital's rule, and I got $$ \lim_{n \to \infty} \frac {     \left( 1 - \frac{1}{n} \right)^{2n}     \left( 2 \log\left( 1 - \frac{1}{n} \right) + \frac{2}{n-1} \right)     -     \left( 1 - \frac{2}{n} \right)^{n}     \left( \log\left( 1 - \frac{2}{n} \right) + \frac{2}{n-2} \right) } {-1/n^{2}}. $$ This does not seem to have gotten me anywhere. My second attempt was to use the binomial theorem: $$ \begin{align*} n \left[     \left( 1 - \frac{1}{n} \right)^{2n}   - \left( 1 - \frac{2}{n} \right)^{n} \right] & = n \left[     \sum_{k=0}^{2n} \binom{2n}{k} \frac{(-1)^{k}}{n^{k}}   - \sum_{k=0}^{n} \binom{n}{k} \frac{(-1)^{k} 2^{k}}{n^{k}} \right] \\ & = \sum_{k=2}^{n} \left[ \binom{2n}{k} - \binom{n}{k} 2^{k} \right] \frac{(-1)^{k}}{n^{k-1}} + \sum_{k=n+1}^{2n} \binom{2n}{k} \frac{(-1)^{k}}{n^{k-1}}. \end{align*} $$ At this point I got stuck again.",,['limits']
81,limit involving rational function and square root,limit involving rational function and square root,,"When working some exercise problems in my calc book, I came across this limit in which I do not know how to tackle.  It is $$\lim_{x\to\infty}\frac{1-\frac{x}{x-1}}{1-\sqrt{\frac{x}{x-1}}}$$ I feel like there is a trick to this one, maybe use L'Hopital's rule or something.  I tried to multiplying by the conjugate but it turned ugly real fast.  Any tips will be helpful.","When working some exercise problems in my calc book, I came across this limit in which I do not know how to tackle.  It is $$\lim_{x\to\infty}\frac{1-\frac{x}{x-1}}{1-\sqrt{\frac{x}{x-1}}}$$ I feel like there is a trick to this one, maybe use L'Hopital's rule or something.  I tried to multiplying by the conjugate but it turned ugly real fast.  Any tips will be helpful.",,"['calculus', 'limits']"
82,Computing two variables limit,Computing two variables limit,,"I'm trying to compute the following limit: $$\lim_{(x,y)\to (\infty,\infty)} \frac{x^2+y^2}{x^2+y^4}$$ I think that the limit is actually path dependent, thus does not exist. If we are looking on the path $(x,y)=(t^2,k^2 t)$ for some $k\in \Bbb R$ we get that $$\lim_{(x,y)\to(\infty,\infty)}\frac{x^2+y^2}{x^2+y^4}=\lim_{t\to\infty}\frac{t^4+k^2t^2}{t^4+k^8t^4}=\lim_{t\to\infty}\frac{1+\frac{k^2}{t^2}}{1+k^8}=\frac{1}{1+k^8}$$ Hence, the limit is path dependent, so it does not exist. W|A claims that the limit is 0. What is wrong with my reasoning?","I'm trying to compute the following limit: $$\lim_{(x,y)\to (\infty,\infty)} \frac{x^2+y^2}{x^2+y^4}$$ I think that the limit is actually path dependent, thus does not exist. If we are looking on the path $(x,y)=(t^2,k^2 t)$ for some $k\in \Bbb R$ we get that $$\lim_{(x,y)\to(\infty,\infty)}\frac{x^2+y^2}{x^2+y^4}=\lim_{t\to\infty}\frac{t^4+k^2t^2}{t^4+k^8t^4}=\lim_{t\to\infty}\frac{1+\frac{k^2}{t^2}}{1+k^8}=\frac{1}{1+k^8}$$ Hence, the limit is path dependent, so it does not exist. W|A claims that the limit is 0. What is wrong with my reasoning?",,['limits']
83,Find the value of $\lim_{n \rightarrow \infty} \Big( 1-\frac{1}{\sqrt 2} \Big) \cdots \Big(1-\frac{1}{\sqrt {n+1}} \Big)$ [duplicate],Find the value of  [duplicate],\lim_{n \rightarrow \infty} \Big( 1-\frac{1}{\sqrt 2} \Big) \cdots \Big(1-\frac{1}{\sqrt {n+1}} \Big),This question already has answers here : How can I find $\lim_{n\to \infty} a_n$ [duplicate] (2 answers) Closed 5 years ago . $$\lim_{n \rightarrow \infty} \Big( 1-\dfrac{1}{\sqrt 2} \Big) \cdots  \Big(1-\dfrac{1}{\sqrt {n+1}}  \Big)$$ Attempt: Let $y = \lim_{n \rightarrow \infty} \Big( 1-\dfrac{1}{\sqrt 2} \Big) \cdots  \Big(1-\dfrac{1}{\sqrt {n+1}}  \Big)$ $\ln y = \lim_{n \rightarrow \infty} \ln \Big( 1-\dfrac{1}{\sqrt 2} \Big)+ \cdots  + \ln \Big(1-\dfrac{1}{\sqrt {n+1}}  \Big)$ I am not able to move ahead really from here. Could someone give me an hint on how to move forward with this problem. Thank you very much for your help in this regard.,This question already has answers here : How can I find $\lim_{n\to \infty} a_n$ [duplicate] (2 answers) Closed 5 years ago . $$\lim_{n \rightarrow \infty} \Big( 1-\dfrac{1}{\sqrt 2} \Big) \cdots  \Big(1-\dfrac{1}{\sqrt {n+1}}  \Big)$$ Attempt: Let $y = \lim_{n \rightarrow \infty} \Big( 1-\dfrac{1}{\sqrt 2} \Big) \cdots  \Big(1-\dfrac{1}{\sqrt {n+1}}  \Big)$ $\ln y = \lim_{n \rightarrow \infty} \ln \Big( 1-\dfrac{1}{\sqrt 2} \Big)+ \cdots  + \ln \Big(1-\dfrac{1}{\sqrt {n+1}}  \Big)$ I am not able to move ahead really from here. Could someone give me an hint on how to move forward with this problem. Thank you very much for your help in this regard.,,"['calculus', 'limits']"
84,Proving uniqueness of $e$ [duplicate],Proving uniqueness of  [duplicate],e,"This question already has answers here : Proving that a definition of e is unique (3 answers) Closed 9 years ago . Let's define $e$ as the number $a$ such that $\frac {d}{dx} a^x = a^x$.  I'm trying to prove that this $a$ has to be $e$.  I don't see any way of proceeding from here except by the limit definition (I'm not assuming I know what the $\ln$ function is, or else there'd be a much easier definition of $e$ to be had). $$\frac {d}{dx} a^x=\lim_{h\to 0} \frac {a^{x+h}-a^x}{h}=\lim_{h\to 0} a^x\frac{a^h-1}{h}=a^x\left(\lim_{h\to 0} \frac{a^h-1}{h}\right)$$ So clearly $e$ must be the number that makes that limit on the far right equal to $1$.  I'm not sure how to evaluate this. Using L'Hopital's rule, I just get $\lim_{h\to 0} \frac {d}{dh} a^h$, which doesn't particularly help. So my question: How can I prove that there is a unique number such that $\lim_{h\to 0} \frac {a^h-1}{h}=1$?","This question already has answers here : Proving that a definition of e is unique (3 answers) Closed 9 years ago . Let's define $e$ as the number $a$ such that $\frac {d}{dx} a^x = a^x$.  I'm trying to prove that this $a$ has to be $e$.  I don't see any way of proceeding from here except by the limit definition (I'm not assuming I know what the $\ln$ function is, or else there'd be a much easier definition of $e$ to be had). $$\frac {d}{dx} a^x=\lim_{h\to 0} \frac {a^{x+h}-a^x}{h}=\lim_{h\to 0} a^x\frac{a^h-1}{h}=a^x\left(\lim_{h\to 0} \frac{a^h-1}{h}\right)$$ So clearly $e$ must be the number that makes that limit on the far right equal to $1$.  I'm not sure how to evaluate this. Using L'Hopital's rule, I just get $\lim_{h\to 0} \frac {d}{dh} a^h$, which doesn't particularly help. So my question: How can I prove that there is a unique number such that $\lim_{h\to 0} \frac {a^h-1}{h}=1$?",,"['limits', 'exponential-function']"
85,Evaluating limit of $0/0$ form,Evaluating limit of  form,0/0,"I am given a quadric equation such that $ax^2 + bx +c=0$ whose roots are $\alpha$ and $\beta$ then what would be value $$\lim\limits_{x \to \alpha} \frac{1-\cos( ax^2 + bx +c) }{(x-\alpha)^2}$$ Now since $x$ is tending to root of input in $\cos$ so my limits become $0/0$ form so I applied L'Hospital Rule hence my limit becomes $$\lim\limits_{x \to \alpha} \frac{\sin( ax^2 + bx +c).2ax +b }{2(x-\alpha)}$$ now since $\alpha$ and $\beta$ are roots hence my expression can be written as $$\lim\limits_{x \to \alpha} \frac{ (x-\beta ) \sin( (x-\alpha)(x-\beta))(2ax +b)}{2(x-\alpha) (x-\beta ) }$$ now it becomes of form $\frac{\sin x}{x}$ when $x$ approaches $0$  so finally I reach $$\lim\limits_{x \to \alpha} \frac{(2ax +b)(x-\beta )}{2}$$ which finally becomes   $$ \frac{(2a\alpha +b)(\alpha-\beta )}{2}$$ But my answer does not matches , what did I do wrong?","I am given a quadric equation such that $ax^2 + bx +c=0$ whose roots are $\alpha$ and $\beta$ then what would be value $$\lim\limits_{x \to \alpha} \frac{1-\cos( ax^2 + bx +c) }{(x-\alpha)^2}$$ Now since $x$ is tending to root of input in $\cos$ so my limits become $0/0$ form so I applied L'Hospital Rule hence my limit becomes $$\lim\limits_{x \to \alpha} \frac{\sin( ax^2 + bx +c).2ax +b }{2(x-\alpha)}$$ now since $\alpha$ and $\beta$ are roots hence my expression can be written as $$\lim\limits_{x \to \alpha} \frac{ (x-\beta ) \sin( (x-\alpha)(x-\beta))(2ax +b)}{2(x-\alpha) (x-\beta ) }$$ now it becomes of form $\frac{\sin x}{x}$ when $x$ approaches $0$  so finally I reach $$\lim\limits_{x \to \alpha} \frac{(2ax +b)(x-\beta )}{2}$$ which finally becomes   $$ \frac{(2a\alpha +b)(\alpha-\beta )}{2}$$ But my answer does not matches , what did I do wrong?",,['limits']
86,Exactly How Does This Proof Mean That The Cosine Function Is Continuous,Exactly How Does This Proof Mean That The Cosine Function Is Continuous,,"The question is: Prove that cosine is a continuous function. To give some context in what way this must be answered, this question is from a sub-chapter called Continuity from a chapter introducing Limits. The Solution: We must show that $\lim_{h \to 0}\cos(a + h) = \cos(a)$ to prove that the cosine function is continuous. $\lim_{h \to 0}\cos(a + h) = \lim_{h \to 0}(\cos(a)\cos(h)-\sin(a)\sin(h)$ which after applying the limit laws $= \cos(a)(1) - \sin(a)(0) = \cos(a)$ Now how I understand how this shows that the cosine function is continuous, is that a can be any number and the cosine function is defined for any number a , thus the proof shows that the cosine function is continuous. But now why use $\cos(a+h)$? I feel slightly uncomfortable with the way I understand this proof as I feel it's almost too elaborate to show something that I have taken to be true without question. Could anybody explain to me in words how this proof shows that the cosine function is continuous?","The question is: Prove that cosine is a continuous function. To give some context in what way this must be answered, this question is from a sub-chapter called Continuity from a chapter introducing Limits. The Solution: We must show that $\lim_{h \to 0}\cos(a + h) = \cos(a)$ to prove that the cosine function is continuous. $\lim_{h \to 0}\cos(a + h) = \lim_{h \to 0}(\cos(a)\cos(h)-\sin(a)\sin(h)$ which after applying the limit laws $= \cos(a)(1) - \sin(a)(0) = \cos(a)$ Now how I understand how this shows that the cosine function is continuous, is that a can be any number and the cosine function is defined for any number a , thus the proof shows that the cosine function is continuous. But now why use $\cos(a+h)$? I feel slightly uncomfortable with the way I understand this proof as I feel it's almost too elaborate to show something that I have taken to be true without question. Could anybody explain to me in words how this proof shows that the cosine function is continuous?",,"['calculus', 'limits']"
87,Limit of $\frac1n\left(1+\frac1{\sqrt[n]{2}}+\frac1{\sqrt[n]{3}}+\dotsb+\frac1{\sqrt[n]{n}}\right)$ when $n\to\infty$,Limit of  when,\frac1n\left(1+\frac1{\sqrt[n]{2}}+\frac1{\sqrt[n]{3}}+\dotsb+\frac1{\sqrt[n]{n}}\right) n\to\infty,"Calculate this limit   $$\lim\limits_{n \to \infty} \frac{1}{n}\left(1+\frac{1}{\sqrt[n]{2}}+\frac{1}{\sqrt[n]{3}}+\dotsb+\frac{1}{\sqrt[n]{n}}\right).$$ I think inside the parentheses, each limit is $1$, and there are $n$ of them, so their sum is limited to $n$. Also, $$\lim\limits_{n \to \infty}\frac{1}{n}=0.$$ Therefore I think, $$\lim\limits_{n \to \infty} \frac{1}{n}\left(1+\frac{1}{\sqrt[n]{2}}+\frac{1}{\sqrt[n]{3}}+\dotsb+\frac{1}{\sqrt[n]{n}}\right) = 0.$$ Is this solution correct? If so, how to prove it?","Calculate this limit   $$\lim\limits_{n \to \infty} \frac{1}{n}\left(1+\frac{1}{\sqrt[n]{2}}+\frac{1}{\sqrt[n]{3}}+\dotsb+\frac{1}{\sqrt[n]{n}}\right).$$ I think inside the parentheses, each limit is $1$, and there are $n$ of them, so their sum is limited to $n$. Also, $$\lim\limits_{n \to \infty}\frac{1}{n}=0.$$ Therefore I think, $$\lim\limits_{n \to \infty} \frac{1}{n}\left(1+\frac{1}{\sqrt[n]{2}}+\frac{1}{\sqrt[n]{3}}+\dotsb+\frac{1}{\sqrt[n]{n}}\right) = 0.$$ Is this solution correct? If so, how to prove it?",,"['analysis', 'limits', 'radicals']"
88,Prove that $\lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4} $.,Prove that .,\lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4} ,"My attempt: We prove that $$\displaystyle \lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4} $$ It is sufficient to show that for an arbitrary  real number  $\epsilon\gt0$, there is a $K$  such that for all $n\gt K$, $$\left| \frac{23n+2}{4n+1} - \frac{23}{4}  \right| < \epsilon.  $$ Note that $$ \displaystyle\left| \frac{23n+2}{4n+1} - \frac{23}{4} \right| = \left| \frac{-15}{16n+4} \right|  $$ and for $ n > 1 $ $$ \displaystyle \left| \frac{-15}{16n+4} \right| = \frac{15}{16n+4} < \frac{1}{n}. $$ Suppose $ \epsilon \in \textbf{R} $ and $ \epsilon > 0  $.  Consider $ K = \displaystyle \frac{1}{\epsilon} $.  Allow that $ n > K $.  Then $ n > \displaystyle \frac{1}{\epsilon} $.  So $ \epsilon >\displaystyle \frac{1}{n} $. Thus $$ \displaystyle\left| \frac{23n+2}{4n+1} - \frac{23}{4} \right| = \left| \frac{-15}{16n+4} \right| = \frac{15}{16n+4} < \frac{1}{n} < \epsilon. $$  Thus $$ \displaystyle \lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4}. $$ Is this proof correct? What are some other ways of proving this? Thanks!","My attempt: We prove that $$\displaystyle \lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4} $$ It is sufficient to show that for an arbitrary  real number  $\epsilon\gt0$, there is a $K$  such that for all $n\gt K$, $$\left| \frac{23n+2}{4n+1} - \frac{23}{4}  \right| < \epsilon.  $$ Note that $$ \displaystyle\left| \frac{23n+2}{4n+1} - \frac{23}{4} \right| = \left| \frac{-15}{16n+4} \right|  $$ and for $ n > 1 $ $$ \displaystyle \left| \frac{-15}{16n+4} \right| = \frac{15}{16n+4} < \frac{1}{n}. $$ Suppose $ \epsilon \in \textbf{R} $ and $ \epsilon > 0  $.  Consider $ K = \displaystyle \frac{1}{\epsilon} $.  Allow that $ n > K $.  Then $ n > \displaystyle \frac{1}{\epsilon} $.  So $ \epsilon >\displaystyle \frac{1}{n} $. Thus $$ \displaystyle\left| \frac{23n+2}{4n+1} - \frac{23}{4} \right| = \left| \frac{-15}{16n+4} \right| = \frac{15}{16n+4} < \frac{1}{n} < \epsilon. $$  Thus $$ \displaystyle \lim\limits_{n \rightarrow \infty} \left(\frac{23n+2}{4n+1}\right) = \frac{23}{4}. $$ Is this proof correct? What are some other ways of proving this? Thanks!",,"['real-analysis', 'limits', 'proof-verification', 'alternative-proof']"
89,How to show that $\lim_{n\rightarrow \infty }{a_n}^{b_n}=\alpha ^\beta $?,How to show that ?,\lim_{n\rightarrow \infty }{a_n}^{b_n}=\alpha ^\beta ,"If $\lim_{n\rightarrow \infty }{a_n}=\alpha (\neq 0) $ and $\lim_{n\rightarrow \infty }{b_n}=\beta$, then $\lim_{n\rightarrow \infty }{a_n}^{b_n}=\alpha ^\beta $? I unconsciously used this but I realized I'd never seen this theorem before. Is it true?","If $\lim_{n\rightarrow \infty }{a_n}=\alpha (\neq 0) $ and $\lim_{n\rightarrow \infty }{b_n}=\beta$, then $\lim_{n\rightarrow \infty }{a_n}^{b_n}=\alpha ^\beta $? I unconsciously used this but I realized I'd never seen this theorem before. Is it true?",,['limits']
90,How find this limit $I=\lim_{x\to\infty}\left(\sin{\frac{2}{x}}+\cos{\frac{1}{x}}\right)^x$,How find this limit,I=\lim_{x\to\infty}\left(\sin{\frac{2}{x}}+\cos{\frac{1}{x}}\right)^x,"Find this limit : $$I=\displaystyle\lim_{x\to\infty}\left(\sin{\frac{2}{x}}+\cos{\frac{1}{x}}\right)^x$$ note $x=e^{\ln{x}}$ $$I=\exp\left(\lim_{x\to\infty}x\ln{\left(\sin{\frac{2}{x}}+\cos{\frac{1}{x}}\right)}\right)$$ and let $\frac{1}{x}=t$,then  $$\lim_{t\to 0}\frac{\ln{(\sin{2t}+\cos{t})}}{t}=\lim_{t\to 0}\dfrac{2\cos{2t}-\sin{t}}{\sin{2t}+\cos{t}}=2$$ so $$I=e^2$$ My question: have other methods? Thank you","Find this limit : $$I=\displaystyle\lim_{x\to\infty}\left(\sin{\frac{2}{x}}+\cos{\frac{1}{x}}\right)^x$$ note $x=e^{\ln{x}}$ $$I=\exp\left(\lim_{x\to\infty}x\ln{\left(\sin{\frac{2}{x}}+\cos{\frac{1}{x}}\right)}\right)$$ and let $\frac{1}{x}=t$,then  $$\lim_{t\to 0}\frac{\ln{(\sin{2t}+\cos{t})}}{t}=\lim_{t\to 0}\dfrac{2\cos{2t}-\sin{t}}{\sin{2t}+\cos{t}}=2$$ so $$I=e^2$$ My question: have other methods? Thank you",,[]
91,Prove that $\lim f(x) =0$ and $\lim (f(2x)-f(x))/x =0$ imply $\lim f(x)/x =0$,Prove that  and  imply,\lim f(x) =0 \lim (f(2x)-f(x))/x =0 \lim f(x)/x =0,"$$\displaystyle \lim_{x\to 0}f(x)=0$$ $$\displaystyle \lim_{x\to 0}\frac{f(2x)-f(x)}{x}=0$$ Prove, that $$\lim_{x\to 0}\frac{f(x)}{x}=0$$ So, I have some ideas: Do $\lim_{x\to 0}\frac{f(x+x)-f(x)}{x+x-x}=0$ and $\lim_{x\to 0}f(x)=0$ imply that $f'(0)$ exist and $f'(0)=0$? If yes, than $lim_{x\to 0}\frac{f(x)}{x}=f'(x)=0$. But I'm in doubts, because the definition of derivative include h and I want to get the difference between them. Other way to look: $$f(2x)-f(x)=\gamma(x)x$$ $$f(\frac{x}{2^{n-1}})-f(\frac{x}{2^{n}})=\gamma(\frac{x}{2^{n}})\frac{x}{2^{n}}$$ $$f(\frac{x}{2^{n-2}})-f(\frac{x}{2^{n-1}})=\gamma(\frac{x}{2^{n-1}})\frac{x}{2^{n-1}}$$ $$f(\frac{x}{2^{n-3}})-f(\frac{x}{2^{n-2}})=\gamma(\frac{x}{2^{n-2}})\frac{x}{2^{n-2}}$$ $$f(\frac{x}{2^{n-4}})-f(\frac{x}{2^{n-3}})=\gamma(\frac{x}{2^{n-3}})\frac{x}{2^{n-3}}$$ $$\dots$$ $$f(\frac{x}{2^{n-(n-1)-1}})-f(\frac{x}{2^{n-(n-1)}})=\gamma(\frac{x}{2^{n-(n-1)}})\frac{x}{2^{n-(n-1)}}=f(x)-f(\frac{x}{2})=\gamma(\frac{x}{2})\frac{x}{2}$$ Sum and get  $f(x)-f(\frac{x}{2^n})=\sum_{k=0}^{n-1}\gamma(\frac{x}{2^{n-k}})\frac{x}{2^{n-k}}$ $f(x)=f(\frac{x}{2^n})+x\sum_{k=0}^{n-1}\gamma(\frac{x}{2^{n-k}})\frac{1}{2^{n-k}}$","$$\displaystyle \lim_{x\to 0}f(x)=0$$ $$\displaystyle \lim_{x\to 0}\frac{f(2x)-f(x)}{x}=0$$ Prove, that $$\lim_{x\to 0}\frac{f(x)}{x}=0$$ So, I have some ideas: Do $\lim_{x\to 0}\frac{f(x+x)-f(x)}{x+x-x}=0$ and $\lim_{x\to 0}f(x)=0$ imply that $f'(0)$ exist and $f'(0)=0$? If yes, than $lim_{x\to 0}\frac{f(x)}{x}=f'(x)=0$. But I'm in doubts, because the definition of derivative include h and I want to get the difference between them. Other way to look: $$f(2x)-f(x)=\gamma(x)x$$ $$f(\frac{x}{2^{n-1}})-f(\frac{x}{2^{n}})=\gamma(\frac{x}{2^{n}})\frac{x}{2^{n}}$$ $$f(\frac{x}{2^{n-2}})-f(\frac{x}{2^{n-1}})=\gamma(\frac{x}{2^{n-1}})\frac{x}{2^{n-1}}$$ $$f(\frac{x}{2^{n-3}})-f(\frac{x}{2^{n-2}})=\gamma(\frac{x}{2^{n-2}})\frac{x}{2^{n-2}}$$ $$f(\frac{x}{2^{n-4}})-f(\frac{x}{2^{n-3}})=\gamma(\frac{x}{2^{n-3}})\frac{x}{2^{n-3}}$$ $$\dots$$ $$f(\frac{x}{2^{n-(n-1)-1}})-f(\frac{x}{2^{n-(n-1)}})=\gamma(\frac{x}{2^{n-(n-1)}})\frac{x}{2^{n-(n-1)}}=f(x)-f(\frac{x}{2})=\gamma(\frac{x}{2})\frac{x}{2}$$ Sum and get  $f(x)-f(\frac{x}{2^n})=\sum_{k=0}^{n-1}\gamma(\frac{x}{2^{n-k}})\frac{x}{2^{n-k}}$ $f(x)=f(\frac{x}{2^n})+x\sum_{k=0}^{n-1}\gamma(\frac{x}{2^{n-k}})\frac{1}{2^{n-k}}$",,"['calculus', 'limits']"
92,How Find the $f(x)$ such $\lim_{x\to 1^{-}}\frac{\sum_{n=0}^{\infty}x^{n^2}}{f(x)}=1$,How Find the  such,f(x) \lim_{x\to 1^{-}}\frac{\sum_{n=0}^{\infty}x^{n^2}}{f(x)}=1,"find the value $f(x)$ such $$\lim_{x\to 1^{-}}\dfrac{\displaystyle\sum_{n=0}^{\infty}x^{n^2}}{f(x)}=1$$ This problem is china (2009College students' mathematical contest   comption)  I have consider sometimes, and we know  we can't find this sum $$\sum_{n=0}^{\infty}x^{n^2}$$ Thank you someone have nice methods","find the value $f(x)$ such $$\lim_{x\to 1^{-}}\dfrac{\displaystyle\sum_{n=0}^{\infty}x^{n^2}}{f(x)}=1$$ This problem is china (2009College students' mathematical contest   comption)  I have consider sometimes, and we know  we can't find this sum $$\sum_{n=0}^{\infty}x^{n^2}$$ Thank you someone have nice methods",,['limits']
93,"I need a better explanation of $(\epsilon,\delta)$-definition of limit",I need a better explanation of -definition of limit,"(\epsilon,\delta)","I am reading the $\epsilon$-$\delta$ definition of a limit here on Wikipedia . It says that $f(x)$ can be made as close as desired to $L$ by making the independent variable $x$ close enough, but not equal, to the value $c$. So this means that $f(x)$ defines $y$ or the output of the function. So when I say $f(x)$ close as desired to $L$, I actually mean the result of the calculation that has taken place and produced a $y$ close to $L$ which sits on the $y$-axis? How close is ""close enough to $c$"" depends on how close one wants to make $f(x)$ to $L$. So $c$ is actually the $x$'s that I am putting into my $f$ function. So one is picking $c$'s that are $x$'s and entering them into the function, and he actually is picking those $c$'s (sorry, $x$'s) to make his result closer to $L$, which is the limit of an approaching value of $y$? It also of course depends on which function $f$ is, and on which number $c$ is. Therefore let the positive number $\epsilon$ be how close one wishes to make $f(x)$ to $L$; OK, so now one picks a letter $\epsilon$ which means error, and that letter is the value of ""how much one needs to be close to $L$"". So it is actually the $y$ value, or the result of the function again, that needs to be close of the limit which is the $y$-coordinate again? strictly one wants the distance to be less than $\epsilon$. Further, if the positive number $\delta$ is how close one will make $x$ to $c$, Er, this means $\delta=x$, or the value that will be entered into $f$? and if the distance from $x$ to $c$ is less than $\delta$ (but not zero), then the distance from $f(x)$ to $L$ will be less than $\epsilon$. Therefore $\delta$ depends on $\epsilon$. The limit statement means that no matter how small $\epsilon$ is made, $\delta$ can be made small enough. So essentially the $\epsilon$-$\delta$ definition of the limit is the corresponding $y$, $x$ definition of the function that we use to limit it around a value? Are my conclusions wrong? I am sorry but it seams like an "" Amazing Three Cup Shuffle Magic Trick"" to me on how my teacher is trying to explain this to me. I always get lost to what letters mean $\epsilon$, $\delta$, $c$, $y$, and $x$, when the function has $x$ and $y$ only.","I am reading the $\epsilon$-$\delta$ definition of a limit here on Wikipedia . It says that $f(x)$ can be made as close as desired to $L$ by making the independent variable $x$ close enough, but not equal, to the value $c$. So this means that $f(x)$ defines $y$ or the output of the function. So when I say $f(x)$ close as desired to $L$, I actually mean the result of the calculation that has taken place and produced a $y$ close to $L$ which sits on the $y$-axis? How close is ""close enough to $c$"" depends on how close one wants to make $f(x)$ to $L$. So $c$ is actually the $x$'s that I am putting into my $f$ function. So one is picking $c$'s that are $x$'s and entering them into the function, and he actually is picking those $c$'s (sorry, $x$'s) to make his result closer to $L$, which is the limit of an approaching value of $y$? It also of course depends on which function $f$ is, and on which number $c$ is. Therefore let the positive number $\epsilon$ be how close one wishes to make $f(x)$ to $L$; OK, so now one picks a letter $\epsilon$ which means error, and that letter is the value of ""how much one needs to be close to $L$"". So it is actually the $y$ value, or the result of the function again, that needs to be close of the limit which is the $y$-coordinate again? strictly one wants the distance to be less than $\epsilon$. Further, if the positive number $\delta$ is how close one will make $x$ to $c$, Er, this means $\delta=x$, or the value that will be entered into $f$? and if the distance from $x$ to $c$ is less than $\delta$ (but not zero), then the distance from $f(x)$ to $L$ will be less than $\epsilon$. Therefore $\delta$ depends on $\epsilon$. The limit statement means that no matter how small $\epsilon$ is made, $\delta$ can be made small enough. So essentially the $\epsilon$-$\delta$ definition of the limit is the corresponding $y$, $x$ definition of the function that we use to limit it around a value? Are my conclusions wrong? I am sorry but it seams like an "" Amazing Three Cup Shuffle Magic Trick"" to me on how my teacher is trying to explain this to me. I always get lost to what letters mean $\epsilon$, $\delta$, $c$, $y$, and $x$, when the function has $x$ and $y$ only.",,"['limits', 'functions']"
94,Evaluating $\lim_{n \to \infty} (1 + 1/n)^{n}$ [duplicate],Evaluating  [duplicate],\lim_{n \to \infty} (1 + 1/n)^{n},"This question already has answers here : How to prove $\lim\limits_{n \to \infty} (1+\frac1n)^n = e$? (4 answers) Closed 10 years ago . I was recently thinking about how I could evaluate the famous limit of 'e' as I haven't ever seen a proof. I can't really find anything online so I've tried to evaluate the limit myself. And I was also thinking it would be nonsensical to use L'Hopital's rule, am I right? So I did the following: $$\lim_{n \to \infty} \left(1 + \frac{1}{n} \right)^{n} = \exp \left(\lim_{n \to \infty} n \cdot \ln \left(1 + \frac{1}{n} \right) \right)$$ $$=\lim_{n \to \infty} \exp \left( n \cdot \left( \frac{1}{n} - \frac{(1/n)^{2}}{2} + \cdots \right) \right)$$ $$= \lim_{n \to \infty} \exp \left( 1 - \frac{(1/n)}{2} + \cdots \right)$$ $$= e$$ I am not sure, is my logic correct or does it create circularity by taking logarithms and assuming $$f(x) = \exp \left( \ln f(x) \right)$$ ?","This question already has answers here : How to prove $\lim\limits_{n \to \infty} (1+\frac1n)^n = e$? (4 answers) Closed 10 years ago . I was recently thinking about how I could evaluate the famous limit of 'e' as I haven't ever seen a proof. I can't really find anything online so I've tried to evaluate the limit myself. And I was also thinking it would be nonsensical to use L'Hopital's rule, am I right? So I did the following: $$\lim_{n \to \infty} \left(1 + \frac{1}{n} \right)^{n} = \exp \left(\lim_{n \to \infty} n \cdot \ln \left(1 + \frac{1}{n} \right) \right)$$ $$=\lim_{n \to \infty} \exp \left( n \cdot \left( \frac{1}{n} - \frac{(1/n)^{2}}{2} + \cdots \right) \right)$$ $$= \lim_{n \to \infty} \exp \left( 1 - \frac{(1/n)}{2} + \cdots \right)$$ $$= e$$ I am not sure, is my logic correct or does it create circularity by taking logarithms and assuming $$f(x) = \exp \left( \ln f(x) \right)$$ ?",,"['limits', 'proof-verification']"
95,How to find the limit of $\dfrac{\ln(\ln(\frac{n}{n-1}))}{\ln(n)}$?,How to find the limit of ?,\dfrac{\ln(\ln(\frac{n}{n-1}))}{\ln(n)},"How do you find $$\lim_{n \to\infty} \dfrac{\ln(\ln(\frac{n}{n-1}))}{\ln(n)}$$ I know it's $-1$, but I had to plot it.","How do you find $$\lim_{n \to\infty} \dfrac{\ln(\ln(\frac{n}{n-1}))}{\ln(n)}$$ I know it's $-1$, but I had to plot it.",,"['analysis', 'limits', 'logarithms']"
96,How to prove $\lim_{n \to \infty} \cos \frac {\pi}{2^2}\cos \frac {\pi}{2^3}\cos \frac {\pi}{2^4}......\cos \frac {\pi}{2^n}=\frac {2}{\pi}$,How to prove,\lim_{n \to \infty} \cos \frac {\pi}{2^2}\cos \frac {\pi}{2^3}\cos \frac {\pi}{2^4}......\cos \frac {\pi}{2^n}=\frac {2}{\pi},"I came across the following problem that says: prove that $$\lim_{n \to \infty} \cos \dfrac {\pi}{2^2}\cos \dfrac {\pi}{2^3}\cos \dfrac {\pi}{2^4}......\cos \dfrac {\pi}{2^n}=\dfrac {2}{\pi}$$. My Attempt:  Let $$P=\lim_{n \to \infty} [\cos \dfrac {\pi}{2^2}\cos \dfrac {\pi}{2^3}\cos \dfrac {\pi}{2^4}......\cos \dfrac {\pi}{2^n}] \implies \log P=\lim_{n \to \infty} \sum_{r=2}^{n}\log (\cos \dfrac {\pi}{2^r})$$. Now,I am stuck and not sure which way to go. Can  someone point me in the right direction?  Thanks in advance for your time.","I came across the following problem that says: prove that $$\lim_{n \to \infty} \cos \dfrac {\pi}{2^2}\cos \dfrac {\pi}{2^3}\cos \dfrac {\pi}{2^4}......\cos \dfrac {\pi}{2^n}=\dfrac {2}{\pi}$$. My Attempt:  Let $$P=\lim_{n \to \infty} [\cos \dfrac {\pi}{2^2}\cos \dfrac {\pi}{2^3}\cos \dfrac {\pi}{2^4}......\cos \dfrac {\pi}{2^n}] \implies \log P=\lim_{n \to \infty} \sum_{r=2}^{n}\log (\cos \dfrac {\pi}{2^r})$$. Now,I am stuck and not sure which way to go. Can  someone point me in the right direction?  Thanks in advance for your time.",,"['real-analysis', 'limits']"
97,"Proof that if $s_n \leq t_n$ for $n \geq N$, then $\liminf_{n \rightarrow \infty} s_n \leq \liminf_{n \rightarrow \infty} t_n$","Proof that if  for , then",s_n \leq t_n n \geq N \liminf_{n \rightarrow \infty} s_n \leq \liminf_{n \rightarrow \infty} t_n,"This is half of Theorem 3.19 from Baby Rudin. Rudin claims the proof is trivial. What I've come up with so far doesn't seem trivial, however, and is probably also wrong (my problem with it is pointed out below). This makes me wonder whether I'm overlooking some useful fact and/or using an unprofitable approach. Theorem. If $s_n \leq t_n$ for $n \geq N$, where $N$ is fixed, then $$ \liminf_{n \rightarrow \infty} s_n \leq \liminf_{n \rightarrow \infty} t_n. $$ Proof. Suppose that $s_n \leq t_n$ if $n \geq N$, but that $$ \liminf_{n \rightarrow \infty} s_n > \liminf_{n \rightarrow \infty} t_n. $$ Let $E_s$ denote the set of all subsequential limits of $\{s_n\}$, and let $E_t$ denote the set of all subsequential limits of $\{t_n\}$. Then $$ \inf E_s > \inf E_t. $$ This implies that there exists some $x \in E_t$ such that $\inf E_s > x > \inf E_t$, since otherwise $\inf E_t$ would not be the greatest lower bound of $E_t$. Hence some subsequence of $\{t_n\}$, say $\{t_{n_i}\}$, converges to $x < \inf E_s$. Lemma. (from Rudin) If $x < \liminf_{n \rightarrow \infty} s_n$, then there exists an integer $N$ such that if $n \geq N$, then $s_n > x$. By the lemma, there exists an integer $N_0$ such that if $n \geq N_0$, then $s_n > x$. Now, let $\epsilon = \inf_{n \geq N_0} \{s_n - x\}$. This is where I think my proof breaks down. Can't $\epsilon$ be zero? Then, since $\{t_{n_i}\}$ converges to $x$, there exists an integer $N_1$ such that if $n_i \geq N_1$, then $|t_{n_i} - x| < \epsilon$. But this means that, if $n_i \geq \max\{N, N_0, N_1\}$, we have both $$ s_{n_i} > t_{n_i}, $$ as well as $s_{n_i} \geq t_{n_i}$, a contradiction.","This is half of Theorem 3.19 from Baby Rudin. Rudin claims the proof is trivial. What I've come up with so far doesn't seem trivial, however, and is probably also wrong (my problem with it is pointed out below). This makes me wonder whether I'm overlooking some useful fact and/or using an unprofitable approach. Theorem. If $s_n \leq t_n$ for $n \geq N$, where $N$ is fixed, then $$ \liminf_{n \rightarrow \infty} s_n \leq \liminf_{n \rightarrow \infty} t_n. $$ Proof. Suppose that $s_n \leq t_n$ if $n \geq N$, but that $$ \liminf_{n \rightarrow \infty} s_n > \liminf_{n \rightarrow \infty} t_n. $$ Let $E_s$ denote the set of all subsequential limits of $\{s_n\}$, and let $E_t$ denote the set of all subsequential limits of $\{t_n\}$. Then $$ \inf E_s > \inf E_t. $$ This implies that there exists some $x \in E_t$ such that $\inf E_s > x > \inf E_t$, since otherwise $\inf E_t$ would not be the greatest lower bound of $E_t$. Hence some subsequence of $\{t_n\}$, say $\{t_{n_i}\}$, converges to $x < \inf E_s$. Lemma. (from Rudin) If $x < \liminf_{n \rightarrow \infty} s_n$, then there exists an integer $N$ such that if $n \geq N$, then $s_n > x$. By the lemma, there exists an integer $N_0$ such that if $n \geq N_0$, then $s_n > x$. Now, let $\epsilon = \inf_{n \geq N_0} \{s_n - x\}$. This is where I think my proof breaks down. Can't $\epsilon$ be zero? Then, since $\{t_{n_i}\}$ converges to $x$, there exists an integer $N_1$ such that if $n_i \geq N_1$, then $|t_{n_i} - x| < \epsilon$. But this means that, if $n_i \geq \max\{N, N_0, N_1\}$, we have both $$ s_{n_i} > t_{n_i}, $$ as well as $s_{n_i} \geq t_{n_i}$, a contradiction.",,"['real-analysis', 'limits', 'inequality', 'limsup-and-liminf']"
98,"Limits defined for negative factorials (i.e. $(-n)!,\space n\in\mathbb{N}$)",Limits defined for negative factorials (i.e. ),"(-n)!,\space n\in\mathbb{N}","I apoligize if this is a stupid/obvious question, but last night I was wondering how we can compute limits for factorials of negative integers, for instance, how do we evaluate: $$\lim_{x\to-3}\frac{x!}{(2x)!}=-120$$ Neither $x!$, nor $(2x)!$ are defined for $x\in\mathbb{Z}^{-}$, and indeed, both are singularities according to the graph of $\Gamma(x+1)$. The book I am reading calculates this using a previously shown identity that: $$F\left(\left.{1-c-2n,-2n \atop c}\right|-1\right)=(-1)^{n}\frac{(2n)!}{n!}\frac{(c-1)!}{(c+n-1)!},\space\forall n\in\mathbb{Z}^{*}$$ And then, the more general Kummer's Formula: $$F\left(\left.{a,b \atop 1+b-a}\right|-1\right)=\frac{(b/2)!}{b!}(b-a)^{\underline{b/2}}$$ It then shows that they would only produce consistent results if: $$(-1)^{n}\frac{(2n)!}{n!}=\lim_{b\to-2n}{\frac{(b/2)!}{b!}}=\lim_{x\to-n}{\frac{x!}{(2x)!}},\space n\in\mathbb{Z}^{*}$$ It then gives the example of $n=3$, proving that: $$\lim_{x\to-3}{\frac{x!}{(2x)!}}=-\frac{6!}{3!}=-120$$ However, using Wolfram|Alpha, I can see that there are other such limits defined (such as $\lim_{x\to-3}{\frac{x!}{(8x)!}}=-103408066955539906560000$. Without using the hypergeometric series, how could we evaluate limits such as these? Again, sorry if this is a stupid question, thanks in advance!","I apoligize if this is a stupid/obvious question, but last night I was wondering how we can compute limits for factorials of negative integers, for instance, how do we evaluate: $$\lim_{x\to-3}\frac{x!}{(2x)!}=-120$$ Neither $x!$, nor $(2x)!$ are defined for $x\in\mathbb{Z}^{-}$, and indeed, both are singularities according to the graph of $\Gamma(x+1)$. The book I am reading calculates this using a previously shown identity that: $$F\left(\left.{1-c-2n,-2n \atop c}\right|-1\right)=(-1)^{n}\frac{(2n)!}{n!}\frac{(c-1)!}{(c+n-1)!},\space\forall n\in\mathbb{Z}^{*}$$ And then, the more general Kummer's Formula: $$F\left(\left.{a,b \atop 1+b-a}\right|-1\right)=\frac{(b/2)!}{b!}(b-a)^{\underline{b/2}}$$ It then shows that they would only produce consistent results if: $$(-1)^{n}\frac{(2n)!}{n!}=\lim_{b\to-2n}{\frac{(b/2)!}{b!}}=\lim_{x\to-n}{\frac{x!}{(2x)!}},\space n\in\mathbb{Z}^{*}$$ It then gives the example of $n=3$, proving that: $$\lim_{x\to-3}{\frac{x!}{(2x)!}}=-\frac{6!}{3!}=-120$$ However, using Wolfram|Alpha, I can see that there are other such limits defined (such as $\lim_{x\to-3}{\frac{x!}{(8x)!}}=-103408066955539906560000$. Without using the hypergeometric series, how could we evaluate limits such as these? Again, sorry if this is a stupid question, thanks in advance!",,"['real-analysis', 'limits', 'factorial', 'gamma-function']"
99,Calculating Limit $ \lim\limits_{x\to 0} \frac{\mathrm d^2}{\mathrm dx^2} \frac{f(x)}{x} $,Calculating Limit, \lim\limits_{x\to 0} \frac{\mathrm d^2}{\mathrm dx^2} \frac{f(x)}{x} ,"Today I had an exam and the following problem came up. I have absolutely no idea how to approach this. Any help in solving this is appreciated! $$ \lim_{x\to 0} \frac{\mathrm d^2}{\mathrm dx^2} \frac{f(x)}{x},\qquad f(0) = 0$$","Today I had an exam and the following problem came up. I have absolutely no idea how to approach this. Any help in solving this is appreciated! $$ \lim_{x\to 0} \frac{\mathrm d^2}{\mathrm dx^2} \frac{f(x)}{x},\qquad f(0) = 0$$",,"['calculus', 'limits']"
