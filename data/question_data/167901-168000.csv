,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Variance of random walk model?,Variance of random walk model?,,"I'm taking my second term of statistics, and I find myself obsessed with an unnecessary detail...again. As follows: $$Y_t=\rho Y_{t-1}+u_t$$ That is to say, we are working with a time series. We assume our present value depends on our previous value. $\rho$ is assumed to be $<1$, so effects of values close in time is greater than the effects of values in the distant past. $u_t$ is assumed to be a purely random term.The $u_i$s are all assumed to be normally distributed, with zero mean and unit variance. $Y_0$ (our starting value) is assumed to be 0. My textbook then claims (out of nowhere)that the variance of this expression is equal to: $$\frac {1}{1-\rho^2}$$ That's what my question is all about, I am trying to figure out how to reach this expression. Below, I will describe my (so far unsuccessful) attempt at doing so. Our first formula is $$Y_t=\rho Y_{t-1}+u_t$$ This can be rewritten as: $$Y_t=\sum {\rho^{n-t}u_t}$$ This way the $\rho$ is raised to the power of 0 at $u_n$, 1 at $u_{n-1}$, 2 at $u_{n-2}$ and so forth. $\rho$ will be raised to the power of n-1 at our starting value. Using the formula for geometric sums, this can be rewritten as: $$Y_t=\frac{u_t-\rho^n u_t}{1-\rho}$$ Assuming that n approaches infinity (knowing that $|\rho|<1$),we can rewrite this as: $$Y_t=\frac{u_t}{1-\rho}$$ We take the variance of this expression: $$V(Y_t)=\frac{\sigma^2}{(1-\rho)^2}$$ Finally, according to the text we have unit variance. I think this means that the variance of each $u_t$ should equal 1. This would leave us with: $$V(Y_t)=\frac{1}{(1-\rho)^2}$$ This still isn't equal to $\frac {1}{1-\rho^2}$! Could someone please tell me what I'm doing wrong?","I'm taking my second term of statistics, and I find myself obsessed with an unnecessary detail...again. As follows: $$Y_t=\rho Y_{t-1}+u_t$$ That is to say, we are working with a time series. We assume our present value depends on our previous value. $\rho$ is assumed to be $<1$, so effects of values close in time is greater than the effects of values in the distant past. $u_t$ is assumed to be a purely random term.The $u_i$s are all assumed to be normally distributed, with zero mean and unit variance. $Y_0$ (our starting value) is assumed to be 0. My textbook then claims (out of nowhere)that the variance of this expression is equal to: $$\frac {1}{1-\rho^2}$$ That's what my question is all about, I am trying to figure out how to reach this expression. Below, I will describe my (so far unsuccessful) attempt at doing so. Our first formula is $$Y_t=\rho Y_{t-1}+u_t$$ This can be rewritten as: $$Y_t=\sum {\rho^{n-t}u_t}$$ This way the $\rho$ is raised to the power of 0 at $u_n$, 1 at $u_{n-1}$, 2 at $u_{n-2}$ and so forth. $\rho$ will be raised to the power of n-1 at our starting value. Using the formula for geometric sums, this can be rewritten as: $$Y_t=\frac{u_t-\rho^n u_t}{1-\rho}$$ Assuming that n approaches infinity (knowing that $|\rho|<1$),we can rewrite this as: $$Y_t=\frac{u_t}{1-\rho}$$ We take the variance of this expression: $$V(Y_t)=\frac{\sigma^2}{(1-\rho)^2}$$ Finally, according to the text we have unit variance. I think this means that the variance of each $u_t$ should equal 1. This would leave us with: $$V(Y_t)=\frac{1}{(1-\rho)^2}$$ This still isn't equal to $\frac {1}{1-\rho^2}$! Could someone please tell me what I'm doing wrong?",,"['statistics', 'time-series', 'variance']"
1,How much of a statistical anomaly would be sufficient to raise suspicion that a probability game is unfair?,How much of a statistical anomaly would be sufficient to raise suspicion that a probability game is unfair?,,"It concerns me that nothing is actually impossible in gambling. Even a one in a billion possibility is not impossible. So it makes me wonder how one could analyse data and say that something is so unlikely that there may be an issue with whatever produced the data. How unlikely does something have to be before it can be said that it shouldn't have happened? I'm guessing it would need to be a series of unlikely events in quick succession? I'm far from an expert on statistics but I would like to learn more, have been studying variance, standard deviation and probability with a statistician recently, but many years to go before I can answer this myself.","It concerns me that nothing is actually impossible in gambling. Even a one in a billion possibility is not impossible. So it makes me wonder how one could analyse data and say that something is so unlikely that there may be an issue with whatever produced the data. How unlikely does something have to be before it can be said that it shouldn't have happened? I'm guessing it would need to be a series of unlikely events in quick succession? I'm far from an expert on statistics but I would like to learn more, have been studying variance, standard deviation and probability with a statistician recently, but many years to go before I can answer this myself.",,"['probability', 'statistics', 'hypothesis-testing']"
2,Quartiles when all numbers are same,Quartiles when all numbers are same,,"I understand quartiles are to be used in large data sets. But for pedagogical purposes, What would be the Quartile1,Median and Quartile3 for a set consisting of same numbers? What would be the quartiles of 7 times 3?","I understand quartiles are to be used in large data sets. But for pedagogical purposes, What would be the Quartile1,Median and Quartile3 for a set consisting of same numbers? What would be the quartiles of 7 times 3?",,['statistics']
3,How to calculate the cumulative distribution function of discrete distribution?,How to calculate the cumulative distribution function of discrete distribution?,,"Let $f(x)=\frac{1}{3}$, for $x=-1,0,1$. How to calculate the cumulative distribution function $F(x)$. I know that if this is a continuous distribution then we just integrate from $-1$ to $x$. However, what to do in the case of a discrete distribution?","Let $f(x)=\frac{1}{3}$, for $x=-1,0,1$. How to calculate the cumulative distribution function $F(x)$. I know that if this is a continuous distribution then we just integrate from $-1$ to $x$. However, what to do in the case of a discrete distribution?",,"['probability', 'statistics', 'probability-distributions']"
4,"How can we use characteristic functions to show that if $E[Xf(X)] = E[f'(X)]$ for all differentiable functions $f$, then $X$ is standard normal?","How can we use characteristic functions to show that if  for all differentiable functions , then  is standard normal?",E[Xf(X)] = E[f'(X)] f X,"I am trying to use the characteristic function, defined as $\phi(t) = E[e^{itX}] = E[\cos(tX)+i\sin(tX)]$, to show that if $E[Xf(X)] = E[f'(X)]$ for all differentiable functions $f: \mathbb{R} \to \mathbb{R}$, with $X$ a real valued random variable, then $X$ is standard normal? My approach was that since the equation holds for all $f$, then I set $f(X) = \phi_X(t) = E[e^{itX}]$. However, that didn't seem to work. Is there a way to do this without resorting to integration? Thanks.","I am trying to use the characteristic function, defined as $\phi(t) = E[e^{itX}] = E[\cos(tX)+i\sin(tX)]$, to show that if $E[Xf(X)] = E[f'(X)]$ for all differentiable functions $f: \mathbb{R} \to \mathbb{R}$, with $X$ a real valued random variable, then $X$ is standard normal? My approach was that since the equation holds for all $f$, then I set $f(X) = \phi_X(t) = E[e^{itX}]$. However, that didn't seem to work. Is there a way to do this without resorting to integration? Thanks.",,"['probability', 'statistics']"
5,Central limit problem. Calculate the probability that the flight will be overbooked.,Central limit problem. Calculate the probability that the flight will be overbooked.,,"The problem said: An airplane has 120 seats. The probability that a ticketed passenger   will show up for a flight is 0.95. Assume that all passengers act   independently and that the airline has sold 130 tickets for a   particular flight. Using the Normal approximation to the Binomial   (with appropriate continuity correction), compute the approximate   probability that the flight will be overbooked. I know I need to use the central limit theorem, and I start by defining indicator variables: Xi= 1 if passanger i show up for a fligth, 0 otherwise. Then the approximate probability that the flight will overbooked, defined by even OB is: P(OB)=P(sum from 1 to 130 of Xi > 120) I know also that P(xi)=0.95 But I'm missing something to finish this problem, and found the correct solution wich the book said is: 0.886 or 88.6%. Thanks for your help.","The problem said: An airplane has 120 seats. The probability that a ticketed passenger   will show up for a flight is 0.95. Assume that all passengers act   independently and that the airline has sold 130 tickets for a   particular flight. Using the Normal approximation to the Binomial   (with appropriate continuity correction), compute the approximate   probability that the flight will be overbooked. I know I need to use the central limit theorem, and I start by defining indicator variables: Xi= 1 if passanger i show up for a fligth, 0 otherwise. Then the approximate probability that the flight will overbooked, defined by even OB is: P(OB)=P(sum from 1 to 130 of Xi > 120) I know also that P(xi)=0.95 But I'm missing something to finish this problem, and found the correct solution wich the book said is: 0.886 or 88.6%. Thanks for your help.",,"['probability', 'statistics']"
6,"28 Crayons , 4 kinds, 4 kids and an specific requirement.","28 Crayons , 4 kinds, 4 kids and an specific requirement.",,"I'm pretty confuse how to solve the following problem, 28 crayons of which four are red are divided randomly between four   toddlers: Bobby, Suzy, Tommy, and Andy. Each child gets seven crayons.   If Bobby has one red crayon, what is the probability that Andy has the   remaining three? I know that they asked to me to find the probability of  P(Andy has the $3$ red | Bobby has $1$) And the total outcome is : denominator =>  $\dfrac{28!}{7! 7! 7! 7!} = 4.7251 \times  10^{14} $ But I have no clue to continue this problem. If someone can help me I will be apreciatted. Thanks! Book final answer said: $0.0263$","I'm pretty confuse how to solve the following problem, 28 crayons of which four are red are divided randomly between four   toddlers: Bobby, Suzy, Tommy, and Andy. Each child gets seven crayons.   If Bobby has one red crayon, what is the probability that Andy has the   remaining three? I know that they asked to me to find the probability of  P(Andy has the $3$ red | Bobby has $1$) And the total outcome is : denominator =>  $\dfrac{28!}{7! 7! 7! 7!} = 4.7251 \times  10^{14} $ But I have no clue to continue this problem. If someone can help me I will be apreciatted. Thanks! Book final answer said: $0.0263$",,"['probability', 'statistics']"
7,How can I calculate p(x=0 or y=0) when the variance is maximized?,How can I calculate p(x=0 or y=0) when the variance is maximized?,,"The random variables $X$ and $Y$ have join probability mass function $p(x,y)$ for $x\in\{0, 1\}$ and $y\in\{0,1,2\}$.   Suppose that $3p(1,1) = p(1,2)$ and $p(1,1)$ maximises the variance of $XY$.   Calculate the probability that $X$ or $Y$ is zero. Then I proceed to make the table; $P(0,0)+P(0,1)+P(0,2)+P(1,0)+P(1,1)+ 3P(1,2) = 1$ $P(X=0)+P(Y=0)-P(X=0 , Y=0)+ 4 P(1,1)=1$ Therefore, $P(X=0 \cup Y=0)=1-4 P(1,1)$ My question is how can I calculate the probability that X or Y is zero when I maximizes the variance of XY? I post the graph: Extra question: Why is no 0(cero) the correct answer? if x=0.13 maximize the variance? Thanks.","The random variables $X$ and $Y$ have join probability mass function $p(x,y)$ for $x\in\{0, 1\}$ and $y\in\{0,1,2\}$.   Suppose that $3p(1,1) = p(1,2)$ and $p(1,1)$ maximises the variance of $XY$.   Calculate the probability that $X$ or $Y$ is zero. Then I proceed to make the table; $P(0,0)+P(0,1)+P(0,2)+P(1,0)+P(1,1)+ 3P(1,2) = 1$ $P(X=0)+P(Y=0)-P(X=0 , Y=0)+ 4 P(1,1)=1$ Therefore, $P(X=0 \cup Y=0)=1-4 P(1,1)$ My question is how can I calculate the probability that X or Y is zero when I maximizes the variance of XY? I post the graph: Extra question: Why is no 0(cero) the correct answer? if x=0.13 maximize the variance? Thanks.",,"['calculus', 'probability', 'statistics']"
8,Fisher Information for Exponential RV,Fisher Information for Exponential RV,,"Let $X \sim exp(\lambda_0)$; i.e, an exponential random variable with true parameter $\lambda_0 > 0$.  The density is then $f(x;\lambda_0) = \lambda_0 e^{-\lambda_0 x}$.  For a given $\lambda > 0$, the Fisher information is defined as \begin{align*} I(\lambda) & := E\left( \left(\frac{\partial \log f(X; \lambda)}{\partial \lambda}\right)^2\right) \\ & = \int_0^\infty \left(\frac{\partial \log f(x; \lambda)}{\partial \lambda}\right)^2 \, f(x; \lambda) \, dx \\ & = \int_0^\infty \left(\frac{1}{\lambda^2} - \frac{2x}{\lambda} + x^2\right) \, \lambda e^{-\lambda x} \, dx \\ & = \frac{1}{\lambda^2}. \end{align*} Here's a plot of $I(\lambda)$: What exactly is the Fisher information telling me?  As I understand it, the larger the Fisher information, the ""more information"" the random variable $X$ is giving me about my MLE estimate of $\lambda$.  How am I supposed to use this here?  I guess if my MLE estimate is $\hat{\lambda} = 0.1$, then $I(0.1) = 100$.  Is this good?  Is this the correct usage of Fisher information?  But, I don't see how the actual value of the random variable $X$ affects this at all, nor do I see how the true parameter $\lambda_0$ affects this.  Have I misinterpreted Fisher information?","Let $X \sim exp(\lambda_0)$; i.e, an exponential random variable with true parameter $\lambda_0 > 0$.  The density is then $f(x;\lambda_0) = \lambda_0 e^{-\lambda_0 x}$.  For a given $\lambda > 0$, the Fisher information is defined as \begin{align*} I(\lambda) & := E\left( \left(\frac{\partial \log f(X; \lambda)}{\partial \lambda}\right)^2\right) \\ & = \int_0^\infty \left(\frac{\partial \log f(x; \lambda)}{\partial \lambda}\right)^2 \, f(x; \lambda) \, dx \\ & = \int_0^\infty \left(\frac{1}{\lambda^2} - \frac{2x}{\lambda} + x^2\right) \, \lambda e^{-\lambda x} \, dx \\ & = \frac{1}{\lambda^2}. \end{align*} Here's a plot of $I(\lambda)$: What exactly is the Fisher information telling me?  As I understand it, the larger the Fisher information, the ""more information"" the random variable $X$ is giving me about my MLE estimate of $\lambda$.  How am I supposed to use this here?  I guess if my MLE estimate is $\hat{\lambda} = 0.1$, then $I(0.1) = 100$.  Is this good?  Is this the correct usage of Fisher information?  But, I don't see how the actual value of the random variable $X$ affects this at all, nor do I see how the true parameter $\lambda_0$ affects this.  Have I misinterpreted Fisher information?",,"['statistics', 'statistical-inference']"
9,UMVUE for $\theta^2$,UMVUE for,\theta^2,"Let $X_1,...X_n$ be a random sample with distribution $\text{Normal}(\theta,1)$. Find the UMVUE for $\theta^2$ What I´ve done so far: I have already shown that $T=\sum_{i=1}^nX_i$ is a complete sufficient statistic for $\theta$. Let $\widehat{\theta^2}=\bar {X}^2-\frac{1}{n}$ be an estimator for $\theta^2$ $$E[\widehat{\theta^2}]=E[\bar {X}^2-\frac{1}{n}]=E[\bar{X}^2]-E^2[\bar X]+E^2[\bar X]+\frac{1}{n}=Var(\bar X)+E^2[\bar X]+\frac{1}{n}$$ I know that $\bar X$ has distribution $\text{Normal}(\theta, \frac{1}{n})$ It follows that :$$E[\widehat{\theta^2}]=\theta^2$$ Hence $\widehat{\theta^2}=\bar {X}^2-\frac{1}{n}$ is unbiased estimator Know I have to compute $g(T)=E[\widehat{\theta^2}|T]$ and by Lehmann-Scheffé this will be the UMVUE for $\theta^2$ but the problem is how can I compute $$E[\widehat{\theta^2}|T]=E[\bar {X}^2-\frac{1}{n}|\sum_{i=1}^nX_i]$$ I know I need to find the joint density of $\bar {X}^2-\frac{1}{n}$ and $\sum_{i=1}^nX_i$ but is there an easy way to do it? Or is there another way to find the UMVUE? I would really appreciate if you can help me with this problem","Let $X_1,...X_n$ be a random sample with distribution $\text{Normal}(\theta,1)$. Find the UMVUE for $\theta^2$ What I´ve done so far: I have already shown that $T=\sum_{i=1}^nX_i$ is a complete sufficient statistic for $\theta$. Let $\widehat{\theta^2}=\bar {X}^2-\frac{1}{n}$ be an estimator for $\theta^2$ $$E[\widehat{\theta^2}]=E[\bar {X}^2-\frac{1}{n}]=E[\bar{X}^2]-E^2[\bar X]+E^2[\bar X]+\frac{1}{n}=Var(\bar X)+E^2[\bar X]+\frac{1}{n}$$ I know that $\bar X$ has distribution $\text{Normal}(\theta, \frac{1}{n})$ It follows that :$$E[\widehat{\theta^2}]=\theta^2$$ Hence $\widehat{\theta^2}=\bar {X}^2-\frac{1}{n}$ is unbiased estimator Know I have to compute $g(T)=E[\widehat{\theta^2}|T]$ and by Lehmann-Scheffé this will be the UMVUE for $\theta^2$ but the problem is how can I compute $$E[\widehat{\theta^2}|T]=E[\bar {X}^2-\frac{1}{n}|\sum_{i=1}^nX_i]$$ I know I need to find the joint density of $\bar {X}^2-\frac{1}{n}$ and $\sum_{i=1}^nX_i$ but is there an easy way to do it? Or is there another way to find the UMVUE? I would really appreciate if you can help me with this problem",,"['probability', 'statistics', 'statistical-inference', 'conditional-expectation']"
10,Empirical quantile definition?,Empirical quantile definition?,,"Suppose we have an order set of data $\mathcal X=\{x^{(1)},x^{(2)},...,x^{(n)}\}$ such that $x^{(1)}\le x^{(2)}\le ...\le x^{(n)}$. For some reason in my course's definition of empirical quantile, we write the probability of getting a value less than $x^{(i)}$ as: $$ p_i=\frac{i}{n+1} $$ I don't understand why we divide by $n+1$ instead of $n$, because it means that the probability $p_n$ of getting a value less than the highest value in our data set is less than 1 (i.e. $p_n=\frac{n}{n+1}<1$). But clearly we should have $p_n=1$? So how come this definition is used for the empirical quantile? Thanks a lot!","Suppose we have an order set of data $\mathcal X=\{x^{(1)},x^{(2)},...,x^{(n)}\}$ such that $x^{(1)}\le x^{(2)}\le ...\le x^{(n)}$. For some reason in my course's definition of empirical quantile, we write the probability of getting a value less than $x^{(i)}$ as: $$ p_i=\frac{i}{n+1} $$ I don't understand why we divide by $n+1$ instead of $n$, because it means that the probability $p_n$ of getting a value less than the highest value in our data set is less than 1 (i.e. $p_n=\frac{n}{n+1}<1$). But clearly we should have $p_n=1$? So how come this definition is used for the empirical quantile? Thanks a lot!",,"['probability', 'statistics', 'descriptive-statistics', 'quantile']"
11,Rigorous definition of sum of two random variables?,Rigorous definition of sum of two random variables?,,"I've looked everywhere, but I seem unable to find a rigorous definition (in the set-theoretical sense of a random variable being a mapping from a sample space to the real number line) of the sum of two random variables (X + Y). How do you rigorously define the sum of two random variables X + Y?","I've looked everywhere, but I seem unable to find a rigorous definition (in the set-theoretical sense of a random variable being a mapping from a sample space to the real number line) of the sum of two random variables (X + Y). How do you rigorously define the sum of two random variables X + Y?",,"['probability', 'statistics', 'random-variables']"
12,Difference between $\sigma^2\{\text{pred}\}$ and $\sigma^2\{\hat Y_h\}$?,Difference between  and ?,\sigma^2\{\text{pred}\} \sigma^2\{\hat Y_h\},"Can someone explain this to me? I've read the relevant section of the text about a million times, and it was even explained in class, but I can't seem to wrap my head around it. The Statement of the Problem: Can $\sigma^2\{\text{pred}\}$ be brought increasingly close to $0$ as $n$ becomes large? Is this also the case for $\sigma^2\{\hat Y_h\}$? What is the implication of this difference? Here $$ \hat Y_h = \text{the point estimator of }E\{Y_h\}= b_0 + b_1X_h $$ $$ \text{and} $$ $$\sigma^2\{\hat Y_h\}=\text{the variability of the sampling distribution of  }\hat Y_h=\sigma^2\left[ \frac{1}{n}+\frac{(X_h-\bar X )^2}{\sum (X_i - \bar X)^2} \right] $$ $$\text{and} $$ $$\sigma^2\{\text{pred}\} = \text{the variance of the prediction error}\\ =\sigma^2\{Y_{h(new)}-\hat Y_h\}=\sigma^2\{Y_{h(new)}\}+\sigma^2\{\hat Y_h\}=\sigma^2+\sigma^2\{\hat Y_h\}.$$ I know why, mathematically , it is the case that, as $n$ becomes large, $\sigma^2\{\hat Y_h\}$ approaches $0$, and $\sigma^2\{\text{pred}\}$ does not (it approaches $1$ instead, I believe). However, I'm looking for a more intuitive, conceptual understanding here. If someone could explain a little, or even just point me towards an explanation elsewhere on the web, I'd appreciate it. Thanks. Also, if any other notation is unclear, let me know.","Can someone explain this to me? I've read the relevant section of the text about a million times, and it was even explained in class, but I can't seem to wrap my head around it. The Statement of the Problem: Can $\sigma^2\{\text{pred}\}$ be brought increasingly close to $0$ as $n$ becomes large? Is this also the case for $\sigma^2\{\hat Y_h\}$? What is the implication of this difference? Here $$ \hat Y_h = \text{the point estimator of }E\{Y_h\}= b_0 + b_1X_h $$ $$ \text{and} $$ $$\sigma^2\{\hat Y_h\}=\text{the variability of the sampling distribution of  }\hat Y_h=\sigma^2\left[ \frac{1}{n}+\frac{(X_h-\bar X )^2}{\sum (X_i - \bar X)^2} \right] $$ $$\text{and} $$ $$\sigma^2\{\text{pred}\} = \text{the variance of the prediction error}\\ =\sigma^2\{Y_{h(new)}-\hat Y_h\}=\sigma^2\{Y_{h(new)}\}+\sigma^2\{\hat Y_h\}=\sigma^2+\sigma^2\{\hat Y_h\}.$$ I know why, mathematically , it is the case that, as $n$ becomes large, $\sigma^2\{\hat Y_h\}$ approaches $0$, and $\sigma^2\{\text{pred}\}$ does not (it approaches $1$ instead, I believe). However, I'm looking for a more intuitive, conceptual understanding here. If someone could explain a little, or even just point me towards an explanation elsewhere on the web, I'd appreciate it. Thanks. Also, if any other notation is unclear, let me know.",,"['statistics', 'statistical-inference', 'regression']"
13,Expected value of trials to obtain a red ball in a box of white balls.,Expected value of trials to obtain a red ball in a box of white balls.,,"I have a problem that involves a box containg N balls, one of which is red and the rest of which (N-1) are white. The question involves finding the expected value and variance for the number of trials to obtain the red ball in the case that (a) the balls are replaced and the case (b) the balls are not replaced. For (a) I said that $$P(X=1) = \frac{1}{n}$$ $$P(X=2) = \frac{n-1}{n}\cdot\frac{1}{n}=\frac{n-1}{n^2}$$ $$P(X=3) = \frac{n-1}{n}\cdot\frac{n-1}{n}\cdot\frac{1}{n}=\frac{(n-1)^2}{n^3}$$ etc. So that: $$E(X) = \sum xP(X=x) = \sum_{k=1}^{n} k\frac{(n-1)^{k-1}}{n^{k}}$$ For (b) I said that: $$P(X=1) = \frac{1}{n}$$ $$P(X=2) = \frac{n-1}{n}\cdot\frac{1}{n-1} = \frac{1}{n}$$ $$P(X=3) = \frac{n-1}{n}\cdot\frac{n-2}{n-1}\cdot\frac{1}{n-2} = \frac{1}{n}$$ etc. So that: $$E(X) = \sum xP(X=x) = \sum_{k=1}^n k\frac{1}{n}$$ So originally when I was writing this question I had obtained the same result for both but then found an error in my ways. Instead I'll ask is this working correct? Any assistance is appreciated, thank you.","I have a problem that involves a box containg N balls, one of which is red and the rest of which (N-1) are white. The question involves finding the expected value and variance for the number of trials to obtain the red ball in the case that (a) the balls are replaced and the case (b) the balls are not replaced. For (a) I said that $$P(X=1) = \frac{1}{n}$$ $$P(X=2) = \frac{n-1}{n}\cdot\frac{1}{n}=\frac{n-1}{n^2}$$ $$P(X=3) = \frac{n-1}{n}\cdot\frac{n-1}{n}\cdot\frac{1}{n}=\frac{(n-1)^2}{n^3}$$ etc. So that: $$E(X) = \sum xP(X=x) = \sum_{k=1}^{n} k\frac{(n-1)^{k-1}}{n^{k}}$$ For (b) I said that: $$P(X=1) = \frac{1}{n}$$ $$P(X=2) = \frac{n-1}{n}\cdot\frac{1}{n-1} = \frac{1}{n}$$ $$P(X=3) = \frac{n-1}{n}\cdot\frac{n-2}{n-1}\cdot\frac{1}{n-2} = \frac{1}{n}$$ etc. So that: $$E(X) = \sum xP(X=x) = \sum_{k=1}^n k\frac{1}{n}$$ So originally when I was writing this question I had obtained the same result for both but then found an error in my ways. Instead I'll ask is this working correct? Any assistance is appreciated, thank you.",,"['probability', 'statistics', 'expectation', 'balls-in-bins']"
14,Example of a distribution with mode undefined,Example of a distribution with mode undefined,,Is there any distribution with an undefined mode? If all the elements of the data set have frequency 1 is the mode undefined or all the elements are modes of the distribution?,Is there any distribution with an undefined mode? If all the elements of the data set have frequency 1 is the mode undefined or all the elements are modes of the distribution?,,['statistics']
15,Strategy for selecting the optimal time to check a cooldown timer,Strategy for selecting the optimal time to check a cooldown timer,,"This is a hard problem for me to word in the title, so I'll try to do better now. Consider the following ""game"": You are sitting in a room beside a table. In the middle of the table there exists a box containing a very large sum of money. The box will only open if you've waited long enough (the time to wait is a random value between $0$ and $MAX$ seconds inclusive). So, there is a chance that the box will be unlocked immediately, or it very well might not unlock until MAX seconds have elapsed. Here is the tricky part. The act of CHECKING the box to see if its open resets the timer back to zero. So say we have $MAX = 100$ seconds, $MIN = 0$ seconds, and the ACTUAL timer on the box is $25$ seconds. If we wait at least $25$ seconds, the box will be open. However, if we open at any time before 25 seconds, we have to wait at least $25$ seconds from THEN before the box will be open. So you might ask ""Who cares if I have to wait MAX seconds? Im guaranteed to be able to open it after MAX seconds"". Well what if we add the twist that each elapsed second since you sat down will decrease the value inside the box by $\frac{3}{4*MAX}$ of the original value. If we use that, then that means if you wait MAX seconds, you will get a quarter the money $\frac{money - 3*MAX}{4*MAX} = 0.25*money$. If you open it at $25$ seconds (max seconds is $100$ remember), then you get $\frac{money - (3*25)}{(4*100)*money} = \frac{325}{400}$ of the money, or 81.25%. This is the BEST you can do, you just don't know that. So, what is the optimal strategy to get the most money out of the box? If the actual timer was $0$ seconds, you could immediately take 100%. However if it's $10$ seconds and you first check $1s$, then $2s$, then $3s$... you're quickly losing value since the penalty is based on TOTAL ELAPSED TIME. So checking at 1, 2, 3 would be 6 elapsed seconds. Another key piece of information is that the actual timer value is EQUALLY LIKELY to be any time between 0 and MAX seconds. I think that this fact and the penalty equation ($\frac{3}{4*MAX}$ for example) are the main keys to solving this puzzle. Obviously you can guarantee yourself $25%$ money by just waiting MAX seconds, but we are greedy and want the most we can possibly get (On AVERAGE). What is our strategy? As for my thoughts... I think the answer is that you check every k seconds... maybe $\sqrt(MAX)$ or something. It would be something that I could easily play with and simulate in a programming sandbox, trying all sorts of different stepping schemes for a bunch of random actual values between 0 and some max. Eventually I may be able to pull out some sort of general solution. It would be more interesting to me though if anyone recognizes this problem and knows an analytical optimal solution based on the penalty amount and the fact that the chances are uniform. Any ideas are welcome, this is just for fun! PS. I thought of this because I was recently playing a game and got banned for joining and leaving too many games too quickly. You are banned for a time between MIN and MAX seconds (based on offense though, not equally likely) and every time you try to login your penalty timer resets. So you don't know what the penalty timer is, you just know the time you waited since your last try wasn't long enough. Goal of course is to play again in the quickest amount of time. But this should be pretty much identical to what I've described above. EDIT: SOLUTION Thanks to the derivation of the optimization function by Bey, I was able to solve this problem. I noticed that with a few tests,  $\sum_{i=1}^{N-2}t_i > \sum_{i=1}^{N-2}t_i*t_{i+1}$ Consider N = 3, which gives us: $t_1 > \dfrac {1}{M} * (t_1*t_2)$ Which is the same as: $t_1(1 - \dfrac{t_2}{M}) > 0$ This is always true since  $t_2 \leq {M}, t_1 \geq 0$ Or, in general... $t_1 + t_2 +...+t_{N-2} > \dfrac {t_1t_2 + t_2t_3 +...+ t_{N-2}t_{N-1}} {M}$ because: $t_1(1 - \dfrac{t_2}{M}) + t_2(1 - \dfrac{t_3}{M}) +...+t_{N-2}(1 - \dfrac{t_{N-1}}{M}) > 0$ Thus, our best solution is to simple use N = 1 guess, where $t_1 = t_n = M$, because the cost function is zero there. So unfortunately not an exciting result, but it seems in such circumstances as this, you cannot do better on average than just making one choice which is the max time. If you don't know the maximum time? That's a different problem!","This is a hard problem for me to word in the title, so I'll try to do better now. Consider the following ""game"": You are sitting in a room beside a table. In the middle of the table there exists a box containing a very large sum of money. The box will only open if you've waited long enough (the time to wait is a random value between $0$ and $MAX$ seconds inclusive). So, there is a chance that the box will be unlocked immediately, or it very well might not unlock until MAX seconds have elapsed. Here is the tricky part. The act of CHECKING the box to see if its open resets the timer back to zero. So say we have $MAX = 100$ seconds, $MIN = 0$ seconds, and the ACTUAL timer on the box is $25$ seconds. If we wait at least $25$ seconds, the box will be open. However, if we open at any time before 25 seconds, we have to wait at least $25$ seconds from THEN before the box will be open. So you might ask ""Who cares if I have to wait MAX seconds? Im guaranteed to be able to open it after MAX seconds"". Well what if we add the twist that each elapsed second since you sat down will decrease the value inside the box by $\frac{3}{4*MAX}$ of the original value. If we use that, then that means if you wait MAX seconds, you will get a quarter the money $\frac{money - 3*MAX}{4*MAX} = 0.25*money$. If you open it at $25$ seconds (max seconds is $100$ remember), then you get $\frac{money - (3*25)}{(4*100)*money} = \frac{325}{400}$ of the money, or 81.25%. This is the BEST you can do, you just don't know that. So, what is the optimal strategy to get the most money out of the box? If the actual timer was $0$ seconds, you could immediately take 100%. However if it's $10$ seconds and you first check $1s$, then $2s$, then $3s$... you're quickly losing value since the penalty is based on TOTAL ELAPSED TIME. So checking at 1, 2, 3 would be 6 elapsed seconds. Another key piece of information is that the actual timer value is EQUALLY LIKELY to be any time between 0 and MAX seconds. I think that this fact and the penalty equation ($\frac{3}{4*MAX}$ for example) are the main keys to solving this puzzle. Obviously you can guarantee yourself $25%$ money by just waiting MAX seconds, but we are greedy and want the most we can possibly get (On AVERAGE). What is our strategy? As for my thoughts... I think the answer is that you check every k seconds... maybe $\sqrt(MAX)$ or something. It would be something that I could easily play with and simulate in a programming sandbox, trying all sorts of different stepping schemes for a bunch of random actual values between 0 and some max. Eventually I may be able to pull out some sort of general solution. It would be more interesting to me though if anyone recognizes this problem and knows an analytical optimal solution based on the penalty amount and the fact that the chances are uniform. Any ideas are welcome, this is just for fun! PS. I thought of this because I was recently playing a game and got banned for joining and leaving too many games too quickly. You are banned for a time between MIN and MAX seconds (based on offense though, not equally likely) and every time you try to login your penalty timer resets. So you don't know what the penalty timer is, you just know the time you waited since your last try wasn't long enough. Goal of course is to play again in the quickest amount of time. But this should be pretty much identical to what I've described above. EDIT: SOLUTION Thanks to the derivation of the optimization function by Bey, I was able to solve this problem. I noticed that with a few tests,  $\sum_{i=1}^{N-2}t_i > \sum_{i=1}^{N-2}t_i*t_{i+1}$ Consider N = 3, which gives us: $t_1 > \dfrac {1}{M} * (t_1*t_2)$ Which is the same as: $t_1(1 - \dfrac{t_2}{M}) > 0$ This is always true since  $t_2 \leq {M}, t_1 \geq 0$ Or, in general... $t_1 + t_2 +...+t_{N-2} > \dfrac {t_1t_2 + t_2t_3 +...+ t_{N-2}t_{N-1}} {M}$ because: $t_1(1 - \dfrac{t_2}{M}) + t_2(1 - \dfrac{t_3}{M}) +...+t_{N-2}(1 - \dfrac{t_{N-1}}{M}) > 0$ Thus, our best solution is to simple use N = 1 guess, where $t_1 = t_n = M$, because the cost function is zero there. So unfortunately not an exciting result, but it seems in such circumstances as this, you cannot do better on average than just making one choice which is the max time. If you don't know the maximum time? That's a different problem!",,"['statistics', 'optimization', 'algorithms', 'algorithmic-game-theory']"
16,Function with Multiple Periods,Function with Multiple Periods,,"Basically I'm trying to fit some data with seasonal effects to a periodic function, and the problem I'm running into is that the local minima usually occur around April, and the local maxima usually occur around December. So the distance from peak to trough is 4 months, but the distance from trough to peak is twice that. I'm wondering what the general form of a function with that behavior looks like. Thank you!","Basically I'm trying to fit some data with seasonal effects to a periodic function, and the problem I'm running into is that the local minima usually occur around April, and the local maxima usually occur around December. So the distance from peak to trough is 4 months, but the distance from trough to peak is twice that. I'm wondering what the general form of a function with that behavior looks like. Thank you!",,"['algebra-precalculus', 'statistics', 'periodic-functions']"
17,"What does ""2- place real function"" mean?","What does ""2- place real function"" mean?",,"What does ""2-place real function"" mean? This comes up in the context of copulas, as here .","What does ""2-place real function"" mean? This comes up in the context of copulas, as here .",,"['statistics', 'functions', 'terminology']"
18,Expected value of geometric distribution,Expected value of geometric distribution,,"I watched $\text{Statistics} \space 110$ from Harvard University through YouTube. From lecture 9, the expected value of the geometric distribution is: $$\sum\limits_{k=0}^{\infty} kpq^k=p\sum\limits_{k=1}^{\infty}kq^k=\frac{pq}{p^2}=\frac{q}{p}$$ where $X$ = number of failures before the 1st success But I cannot understand the derivation below intuitively - what is the meaning of $0$, $p$, $q$ and $(1+c)$: $$ c=E(X)=0\times p+(1+c)\times q =q+cq=\frac{q}{p} $$","I watched $\text{Statistics} \space 110$ from Harvard University through YouTube. From lecture 9, the expected value of the geometric distribution is: $$\sum\limits_{k=0}^{\infty} kpq^k=p\sum\limits_{k=1}^{\infty}kq^k=\frac{pq}{p^2}=\frac{q}{p}$$ where $X$ = number of failures before the 1st success But I cannot understand the derivation below intuitively - what is the meaning of $0$, $p$, $q$ and $(1+c)$: $$ c=E(X)=0\times p+(1+c)\times q =q+cq=\frac{q}{p} $$",,['statistics']
19,How do correlation and causality effect this scenario?,How do correlation and causality effect this scenario?,,"I came up with a real world problem that I don't need to solve, but was intrigued by nonetheless. Imagine I was trying to figure out if a supermarket chain took credit as well as cash.  My wife had been to the market yesterday and they didn't take credit.  That leads both of us to believe they won't take credit today (seems like a safe assumption). Assume the following: The supermarket has not announced that they will accept credit soon - nor have they said they wouldn't. For this question - let's say it takes no real time  to implement a credit card system - they could implement it at the drop of a hat. We have no other reasons to think they will or will not decide to do this. The fact that they didn't accept credit yesterday seems to increase the likelihood that they won't today (if we had been there last 1 year ago - we would be less likely to assume that they still didn't take credit cards).  But the fact that she was there yesterday is completely irrelevant to the stores credit card plans.  If they ever choose to implement credit card processing then it will have to happen one day - and that day could be any day - but it still seems we are grounded in our assumption that they won't accept them today. My question is: Does the fact that we knew that they didn't accept credit cards yesterday have any statistical correlation to whether they will accept them today?  And if so; why?","I came up with a real world problem that I don't need to solve, but was intrigued by nonetheless. Imagine I was trying to figure out if a supermarket chain took credit as well as cash.  My wife had been to the market yesterday and they didn't take credit.  That leads both of us to believe they won't take credit today (seems like a safe assumption). Assume the following: The supermarket has not announced that they will accept credit soon - nor have they said they wouldn't. For this question - let's say it takes no real time  to implement a credit card system - they could implement it at the drop of a hat. We have no other reasons to think they will or will not decide to do this. The fact that they didn't accept credit yesterday seems to increase the likelihood that they won't today (if we had been there last 1 year ago - we would be less likely to assume that they still didn't take credit cards).  But the fact that she was there yesterday is completely irrelevant to the stores credit card plans.  If they ever choose to implement credit card processing then it will have to happen one day - and that day could be any day - but it still seems we are grounded in our assumption that they won't accept them today. My question is: Does the fact that we knew that they didn't accept credit cards yesterday have any statistical correlation to whether they will accept them today?  And if so; why?",,"['probability', 'statistics', 'word-problem']"
20,Probability of dice with a cumulative successes,Probability of dice with a cumulative successes,,"Needing some Math help! I'm working out part of a system for a game I'm working on, and I need to know if I need to tweak some things, so I'm checking to see if it all adds up (no pun intended). defender has a base of 1, 3, 5, 7, or 11 for the target successes that the attacker has to roll; if the attacker achieves the # of successes required the attacker wins the roll, otherwise the defender wins. the attacker rolls 1, 2, 3, 4, or 5 10-sided dice based on his/her increasing skill, however only 8-10 count as a success, and each 9-10 granting an additional die to add to the pool. That means, there is a 3/10 chance of at least one success, and 1/5 chance to add another die, to increase the chance for the attacker to hit the defender's number. I feel like this should be really easy, but I can't figure out how to get started... What is the chance (expressed as a ratio please...) for the attacker to win the roll against a defender with a target of 1? a target of 3, 5, 7, 11?","Needing some Math help! I'm working out part of a system for a game I'm working on, and I need to know if I need to tweak some things, so I'm checking to see if it all adds up (no pun intended). defender has a base of 1, 3, 5, 7, or 11 for the target successes that the attacker has to roll; if the attacker achieves the # of successes required the attacker wins the roll, otherwise the defender wins. the attacker rolls 1, 2, 3, 4, or 5 10-sided dice based on his/her increasing skill, however only 8-10 count as a success, and each 9-10 granting an additional die to add to the pool. That means, there is a 3/10 chance of at least one success, and 1/5 chance to add another die, to increase the chance for the attacker to hit the defender's number. I feel like this should be really easy, but I can't figure out how to get started... What is the chance (expressed as a ratio please...) for the attacker to win the roll against a defender with a target of 1? a target of 3, 5, 7, 11?",,"['probability', 'statistics', 'dice']"
21,Show that MLE of $\lambda = \frac{n-T_n}{S_n+cT_n}$,Show that MLE of,\lambda = \frac{n-T_n}{S_n+cT_n},"$X_i$ are i.i.d exponential, mean $\lambda^{-1}$ for $1 \leq i \leq n$ and, the values are measured such that $X_i = c$ if $X_i \geq c$ and $X_i$ otherwise. Show that MLE of $\lambda = \frac{n-T_n}{S_n+cT_n}$ where $S_n= \sum_{j=1}^n X_jI(X_j < c)$ and $T_n = \sum_{j=1}^n I(X_j \geq c)$ Attempt: The likelihood function is given by $L(\lambda | x_i, x_2, \ldots x_n) = \lambda^n e^{-\lambda \sum x_i} = \lambda^n e^{-\lambda(S_n+cT_n)}$ $\implies$ $log L = n log \lambda -\lambda(S_n+cT_n) $ and hence $\hat\lambda=\frac{n}{S_n+cT_n}$ which is different from the expected answer.","$X_i$ are i.i.d exponential, mean $\lambda^{-1}$ for $1 \leq i \leq n$ and, the values are measured such that $X_i = c$ if $X_i \geq c$ and $X_i$ otherwise. Show that MLE of $\lambda = \frac{n-T_n}{S_n+cT_n}$ where $S_n= \sum_{j=1}^n X_jI(X_j < c)$ and $T_n = \sum_{j=1}^n I(X_j \geq c)$ Attempt: The likelihood function is given by $L(\lambda | x_i, x_2, \ldots x_n) = \lambda^n e^{-\lambda \sum x_i} = \lambda^n e^{-\lambda(S_n+cT_n)}$ $\implies$ $log L = n log \lambda -\lambda(S_n+cT_n) $ and hence $\hat\lambda=\frac{n}{S_n+cT_n}$ which is different from the expected answer.",,"['probability', 'statistics', 'expectation', 'estimation', 'parameter-estimation']"
22,Subgame perfect Nash equilibrium & perfect Bayesian Nash equilibrium - Game theory,Subgame perfect Nash equilibrium & perfect Bayesian Nash equilibrium - Game theory,,"For a week or so I have been struggling with the topics around the concept of subgame perfect Nash equilibrium (SPNE) and the perfect Bayesian Nash equilibrium (BNE). Namely: Is it possible to apply backward induction (to obtain SPNEs) in dynamic games of complete but imperfect information? According to $\textit{Game Theory for Applied Economists}$ by $\textit{Robert Gibbons}$ it is possible. Or atleast, that what I understand from the text on page 128-129. But, then the SPNE would be implausible, since the player at the nonsingleton information set has no knowledge at which decision node he is. How is it then possible to apply backward induction to games of imperfect information? On page 129 of the book of $\textit{Gibbons}$ it is mentioned that there is a second method to obtain an optimal solution/strategy profile by specifying a probability to each node in the nonsingleton information set. And (this is what confuses me) this yields a perfect Bayesian equilibrium. But wait a minute... the perfect Bayesian equilibrium occurs in games of incomplete information, so how would we solve games of imperfect information by regarding games of incomplete information? I thought that we could solve games of incomplete information with the help of solution concepts applicable in games of imperfect information, but the above tells the reverse (right?). Hopefully one can help me out!  Have a nice day.","For a week or so I have been struggling with the topics around the concept of subgame perfect Nash equilibrium (SPNE) and the perfect Bayesian Nash equilibrium (BNE). Namely: Is it possible to apply backward induction (to obtain SPNEs) in dynamic games of complete but imperfect information? According to $\textit{Game Theory for Applied Economists}$ by $\textit{Robert Gibbons}$ it is possible. Or atleast, that what I understand from the text on page 128-129. But, then the SPNE would be implausible, since the player at the nonsingleton information set has no knowledge at which decision node he is. How is it then possible to apply backward induction to games of imperfect information? On page 129 of the book of $\textit{Gibbons}$ it is mentioned that there is a second method to obtain an optimal solution/strategy profile by specifying a probability to each node in the nonsingleton information set. And (this is what confuses me) this yields a perfect Bayesian equilibrium. But wait a minute... the perfect Bayesian equilibrium occurs in games of incomplete information, so how would we solve games of imperfect information by regarding games of incomplete information? I thought that we could solve games of incomplete information with the help of solution concepts applicable in games of imperfect information, but the above tells the reverse (right?). Hopefully one can help me out!  Have a nice day.",,"['probability', 'statistics', 'game-theory', 'nash-equilibrium']"
23,How can I calculate Index of Coincidence of Vigenère cipher?,How can I calculate Index of Coincidence of Vigenère cipher?,,"I have computed the letter frequency of the cipher text. However, I don't know how to apply Friedman Test to Vigenère cipher. I couldn't calculate the Index of Coincidence. Does anyone can help to me ? Letters' frequencies : $f_{0} = 0.059 \qquad f_{14} = 0.031 \\ f_{1} =0.055 \qquad f_{15} = 0.064 \\ f_{2} = 0.030 \qquad f_{16} = 0.029 \\ f_{3} = 0.018 \qquad f_{17} = 0.026 \\ f_{4} = 0.029 \qquad f_{18} = 0.027 \\ f_{5} = 0.040 \qquad f_{19} = 0.042 \\ f_{6} = 0.070 \qquad f_{20} = 0.046 \\ f_{7} = 0.030 \qquad f_{21} = 0.046 \\ f_{8} = 0.032 \qquad f_{22} = 0.017 \\ f_{9} = 0.023 \qquad f_{23} = 0.027 \\ f_{10} = 0.046 \qquad f_{24} = 0.036 \\ f_{11} = 0.059 \qquad f_{25} = 0.032 \\ f_{12} = 0.046 \\ f_{13} = 0.039 $ By using these frequencies, how can I calculate Index of Coincidence ?","I have computed the letter frequency of the cipher text. However, I don't know how to apply Friedman Test to Vigenère cipher. I couldn't calculate the Index of Coincidence. Does anyone can help to me ? Letters' frequencies : $f_{0} = 0.059 \qquad f_{14} = 0.031 \\ f_{1} =0.055 \qquad f_{15} = 0.064 \\ f_{2} = 0.030 \qquad f_{16} = 0.029 \\ f_{3} = 0.018 \qquad f_{17} = 0.026 \\ f_{4} = 0.029 \qquad f_{18} = 0.027 \\ f_{5} = 0.040 \qquad f_{19} = 0.042 \\ f_{6} = 0.070 \qquad f_{20} = 0.046 \\ f_{7} = 0.030 \qquad f_{21} = 0.046 \\ f_{8} = 0.032 \qquad f_{22} = 0.017 \\ f_{9} = 0.023 \qquad f_{23} = 0.027 \\ f_{10} = 0.046 \qquad f_{24} = 0.036 \\ f_{11} = 0.059 \qquad f_{25} = 0.032 \\ f_{12} = 0.046 \\ f_{13} = 0.039 $ By using these frequencies, how can I calculate Index of Coincidence ?",,"['linear-algebra', 'statistics', 'discrete-mathematics', 'cryptography']"
24,Finding moment generating function of $f(x)= \frac 1 {\theta^2} xe^{-x/\theta}$,Finding moment generating function of,f(x)= \frac 1 {\theta^2} xe^{-x/\theta},"I've been stuck on this question for a while now and my exam is coming up so,any hints/comments etc. would be greatly appreciated. Question: Find the moment generating function of the probability density function with parameter $\theta > 0$ , $$f(x)= \frac 1 {\theta^2} xe^{-x/\theta}$$ I've tried the Gamma function and Integration by Parts but I'm still stuck. The answer key gives this answer (I've attached a photo), but I'm not sure how they got to last step... Thanks so much.","I've been stuck on this question for a while now and my exam is coming up so,any hints/comments etc. would be greatly appreciated. Question: Find the moment generating function of the probability density function with parameter , I've tried the Gamma function and Integration by Parts but I'm still stuck. The answer key gives this answer (I've attached a photo), but I'm not sure how they got to last step... Thanks so much.",\theta > 0 f(x)= \frac 1 {\theta^2} xe^{-x/\theta},"['probability', 'integration', 'statistics', 'gamma-function', 'moment-generating-functions']"
25,Is it possible to have two lines of best fit?,Is it possible to have two lines of best fit?,,Could you rig a data set to have two lines of equally good (and best) fit? Or is it impossible?,Could you rig a data set to have two lines of equally good (and best) fit? Or is it impossible?,,"['statistics', 'regression']"
26,how to calculate what I need for final exam,how to calculate what I need for final exam,,"Evaluation: A final mark out of 100 will be calculated as follows: Clicker Questions: 5% WeBWorK Assignments: 10% Midterm Tests (25% of the higher mark + 10% of the lower): 35% Test 1 – Saturday, February 7, 10:30-11:50 a.m. Test 2 – Friday, March 13, 6:00-7:20 p.m. Final Examination (2.5 hours – date and time TBA): 50% I have a 80% for Webwork, first midterm I got 39%, second one I got a 26%, and thus the only evaluation I have left is the final exam. Does anyone here know what I need to get on the final to atleast pass the course with a 50% average? In addition I have 0 for Clicker Questions. Thank you.","Evaluation: A final mark out of 100 will be calculated as follows: Clicker Questions: 5% WeBWorK Assignments: 10% Midterm Tests (25% of the higher mark + 10% of the lower): 35% Test 1 – Saturday, February 7, 10:30-11:50 a.m. Test 2 – Friday, March 13, 6:00-7:20 p.m. Final Examination (2.5 hours – date and time TBA): 50% I have a 80% for Webwork, first midterm I got 39%, second one I got a 26%, and thus the only evaluation I have left is the final exam. Does anyone here know what I need to get on the final to atleast pass the course with a 50% average? In addition I have 0 for Clicker Questions. Thank you.",,"['statistics', 'percentages', 'means']"
27,Equation for calculating percentile of data point on normal curve,Equation for calculating percentile of data point on normal curve,,"I'm taking pre-calculus right now, and I'm trying to make a statistics program, so I want to calculate the percentile of a score on a normal curve without using a ""standard normal table."" I can calculate the z-score easily and correctly, but the equation printed in my textbook doesn't seem to work. y = e^(-x²/2)/√(2π) (x is the z-score) Is this the right equation for calculating the percentile of a score on a normal curve? For a z-score of 2.1, I find the solution to be: y=e^(-2.1²/2)/√(2π) =e^(-2.205)/√(2π) =e^(-2.205)/2.507 =0.11/2.507 =4.398E-2 On the standard normal table, the answer is clearly 0.9821. What am I doing wrong?","I'm taking pre-calculus right now, and I'm trying to make a statistics program, so I want to calculate the percentile of a score on a normal curve without using a ""standard normal table."" I can calculate the z-score easily and correctly, but the equation printed in my textbook doesn't seem to work. y = e^(-x²/2)/√(2π) (x is the z-score) Is this the right equation for calculating the percentile of a score on a normal curve? For a z-score of 2.1, I find the solution to be: y=e^(-2.1²/2)/√(2π) =e^(-2.205)/√(2π) =e^(-2.205)/2.507 =0.11/2.507 =4.398E-2 On the standard normal table, the answer is clearly 0.9821. What am I doing wrong?",,"['algebra-precalculus', 'statistics', 'percentile']"
28,Integrating the log-normal function,Integrating the log-normal function,,"Compute $$F(t)=\int_0^t \frac{1}{\sqrt{2\pi}\sigma t} \exp\left[-\frac{1}{2}\left(\frac{\log t-\mu}{\sigma}\right)^2\right]\,dt; t>0$$ My Attempt: $u=\frac{1}{t}\Rightarrow du=-\frac{1}{t^2}dt$ and $$dv=\exp\left[-\frac{1}{2}\left(\frac{\log t-\mu}{\sigma}\right)^2\right] \, dt\Rightarrow v=\text{ ?}$$ Integration by parts formula : $$\int u \, dv=uv-\int v \, du$$",Compute My Attempt: and Integration by parts formula :,"F(t)=\int_0^t \frac{1}{\sqrt{2\pi}\sigma t} \exp\left[-\frac{1}{2}\left(\frac{\log t-\mu}{\sigma}\right)^2\right]\,dt; t>0 u=\frac{1}{t}\Rightarrow du=-\frac{1}{t^2}dt dv=\exp\left[-\frac{1}{2}\left(\frac{\log t-\mu}{\sigma}\right)^2\right] \, dt\Rightarrow v=\text{ ?} \int u \, dv=uv-\int v \, du","['calculus', 'integration', 'algebra-precalculus', 'statistics', 'definite-integrals']"
29,"To calculate variance, given conditional distribution","To calculate variance, given conditional distribution",,"Let Y be an exponential random variable with mean $\frac{1}{\theta}$, where $\theta>0$. The conditional distribution of X given Y has Poisson distribution with mean Y. Then, the variance of X is (A)$\dfrac{1}{\theta^2}$ (B) $\dfrac{\theta+1}{\theta}$  (C) $\dfrac{\theta^2+1}{\theta^2}$ (D) $\dfrac{\theta+1}{\theta^2}$ My Attempt: $\!f(x; \lambda|Y)= \Pr(X{=}x)= \frac{\lambda^x e^{-\lambda}}{x!}$ $E(X|Y)=\displaystyle\sum xf(x; \lambda|Y)=\lambda=\frac{1}{\theta}$ Variance(X)=$E[X^2]-(E[X])^2$ Now, $E(X^2)=\displaystyle\sum x^2\frac{\lambda^x e^{-\lambda}}{x!}=(1+\lambda)=1+\frac{1}{\theta}$ Because $(1+x)e^x= \sum^\infty_{n=0}{n+1\over n!}x^n$ Hence, Var(X)=$1+\frac{1}{\theta}-\frac{1}{\theta^2}$ Where did I go wrong ? Please advise.","Let Y be an exponential random variable with mean $\frac{1}{\theta}$, where $\theta>0$. The conditional distribution of X given Y has Poisson distribution with mean Y. Then, the variance of X is (A)$\dfrac{1}{\theta^2}$ (B) $\dfrac{\theta+1}{\theta}$  (C) $\dfrac{\theta^2+1}{\theta^2}$ (D) $\dfrac{\theta+1}{\theta^2}$ My Attempt: $\!f(x; \lambda|Y)= \Pr(X{=}x)= \frac{\lambda^x e^{-\lambda}}{x!}$ $E(X|Y)=\displaystyle\sum xf(x; \lambda|Y)=\lambda=\frac{1}{\theta}$ Variance(X)=$E[X^2]-(E[X])^2$ Now, $E(X^2)=\displaystyle\sum x^2\frac{\lambda^x e^{-\lambda}}{x!}=(1+\lambda)=1+\frac{1}{\theta}$ Because $(1+x)e^x= \sum^\infty_{n=0}{n+1\over n!}x^n$ Hence, Var(X)=$1+\frac{1}{\theta}-\frac{1}{\theta^2}$ Where did I go wrong ? Please advise.",,"['statistics', 'statistical-inference', 'conditional-expectation']"
30,"UMVUE for pdf $f_{\theta}(x) = \theta e^{-\theta x}, x>0$",UMVUE for pdf,"f_{\theta}(x) = \theta e^{-\theta x}, x>0","Let $X_1,\ldots,X_n$ be a random sample from a pdf  $f_{\theta}(x) = \begin{cases} \theta e^{-\theta x},  & x>0 \\ 0, & \text{otherwise} \end{cases}$, where $\theta>0$ is an unknown parameter. Then, the uniform minimum variance unbiased estimator for $\dfrac{1}{\theta}$ is (A)$\dfrac{1}{\bar{X_n}}$ (B) $\displaystyle\sum_{i=1}^{n}X_i$ (C) $\bar{X_n}$ (D) $\dfrac{1}{\displaystyle\sum_{i=1}^{n}X_i}$ MY STEPS: Taking the Expectation, $E_\theta(X)=\displaystyle\int_{0}^{\infty}xf(x)\;dx$ $$E_\theta(X)=\theta\int_0^\infty x e^{-\theta x}\;dx=\dfrac{1}{\theta}=\bar{X_n}$$ Hence, option (C) should be correct. Did I solve this correctly ? Please help me confirm my solution.","Let $X_1,\ldots,X_n$ be a random sample from a pdf  $f_{\theta}(x) = \begin{cases} \theta e^{-\theta x},  & x>0 \\ 0, & \text{otherwise} \end{cases}$, where $\theta>0$ is an unknown parameter. Then, the uniform minimum variance unbiased estimator for $\dfrac{1}{\theta}$ is (A)$\dfrac{1}{\bar{X_n}}$ (B) $\displaystyle\sum_{i=1}^{n}X_i$ (C) $\bar{X_n}$ (D) $\dfrac{1}{\displaystyle\sum_{i=1}^{n}X_i}$ MY STEPS: Taking the Expectation, $E_\theta(X)=\displaystyle\int_{0}^{\infty}xf(x)\;dx$ $$E_\theta(X)=\theta\int_0^\infty x e^{-\theta x}\;dx=\dfrac{1}{\theta}=\bar{X_n}$$ Hence, option (C) should be correct. Did I solve this correctly ? Please help me confirm my solution.",,"['statistics', 'statistical-inference', 'parameter-estimation']"
31,What does saying that an estimator is robust mean?,What does saying that an estimator is robust mean?,,"In statistics, how can you tell whether an estimator is robust or not? I need to discuss whether the maximum likelihood estimators (MLE) of the normal distribution are robust or not. The MLE are $$\hat{\mu} = \begin{pmatrix} \sum_{i=1}^n x_i/n \\ \sum_{i=1}^n y_i/n \end{pmatrix}$$ and for the variances $$\hat{\sigma^2}=\begin{pmatrix} \sum_{i=1}^n (x_i-\mu_X)^2/n \\ \sum_{i=1}^n (y_i-\mu_Y)^2/n \end{pmatrix}$$ Do this has anything to do with that the estimator is unbiased/biased? Thanks in advance.","In statistics, how can you tell whether an estimator is robust or not? I need to discuss whether the maximum likelihood estimators (MLE) of the normal distribution are robust or not. The MLE are $$\hat{\mu} = \begin{pmatrix} \sum_{i=1}^n x_i/n \\ \sum_{i=1}^n y_i/n \end{pmatrix}$$ and for the variances $$\hat{\sigma^2}=\begin{pmatrix} \sum_{i=1}^n (x_i-\mu_X)^2/n \\ \sum_{i=1}^n (y_i-\mu_Y)^2/n \end{pmatrix}$$ Do this has anything to do with that the estimator is unbiased/biased? Thanks in advance.",,"['statistics', 'normal-distribution', 'estimation', 'robust-statistics']"
32,calculate expectation of MLE,calculate expectation of MLE,,"It's a question about whether $\hat{\theta _{MLE}}$ is an unbiased estimator of $\theta$. n independent pairs $(X_{1},Y_{1}), (X_{2},Y_{2}),....(X_{n},Y_{n}), n\geq 3$, where $Y_{i}=\theta X_{i}+\epsilon _{i}, i=1,2,...,n. \theta \in \mathbb{R}$ and $X_{i}'s$ and $\epsilon _{i}'s$ are iid random variables with N(0,1,) distribution. My thought: the likelihood function is $L(X,Y;\theta )=(2\pi )^{-n}e^{\frac{-1}{2}\sum x_{i}^{2}-\frac{1}{2}\sum {(Y_{i}-\theta X_{i})}^{2}}$ and the log-likelihood function is $l(X,Y;\theta )=-nln(2\pi ) -\frac{1}{2}\sum x_{i}^{2}-\frac{1}{2}\sum {(Y_{i}-\theta X_{i})}^{2}$ $\hat{\theta _{MLE}}=\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}}$. I think the MLE should be correct. To calculate its expected value, I first have MLE simplified as: $\hat{\theta _{MLE}}=\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}}=\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}}=\frac{\sum x_{i}(\theta x_{i}+\epsilon _{i})}{\sum x_{i}^{2}}=\theta +\frac{\sum x_{i}\epsilon _{i}}{\sum x_{i}^{2}}$ $E(\hat{\theta _{MLE}})=E(\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}})=\theta +E(\frac{\sum x_{i}\epsilon _{i}}{\sum x_{i}^{2}})$. And I got stuck here, got no clue to continue the work. Thanks for helping me out.","It's a question about whether $\hat{\theta _{MLE}}$ is an unbiased estimator of $\theta$. n independent pairs $(X_{1},Y_{1}), (X_{2},Y_{2}),....(X_{n},Y_{n}), n\geq 3$, where $Y_{i}=\theta X_{i}+\epsilon _{i}, i=1,2,...,n. \theta \in \mathbb{R}$ and $X_{i}'s$ and $\epsilon _{i}'s$ are iid random variables with N(0,1,) distribution. My thought: the likelihood function is $L(X,Y;\theta )=(2\pi )^{-n}e^{\frac{-1}{2}\sum x_{i}^{2}-\frac{1}{2}\sum {(Y_{i}-\theta X_{i})}^{2}}$ and the log-likelihood function is $l(X,Y;\theta )=-nln(2\pi ) -\frac{1}{2}\sum x_{i}^{2}-\frac{1}{2}\sum {(Y_{i}-\theta X_{i})}^{2}$ $\hat{\theta _{MLE}}=\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}}$. I think the MLE should be correct. To calculate its expected value, I first have MLE simplified as: $\hat{\theta _{MLE}}=\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}}=\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}}=\frac{\sum x_{i}(\theta x_{i}+\epsilon _{i})}{\sum x_{i}^{2}}=\theta +\frac{\sum x_{i}\epsilon _{i}}{\sum x_{i}^{2}}$ $E(\hat{\theta _{MLE}})=E(\frac{\sum x_{i}y_{i}}{\sum x_{i}^{2}})=\theta +E(\frac{\sum x_{i}\epsilon _{i}}{\sum x_{i}^{2}})$. And I got stuck here, got no clue to continue the work. Thanks for helping me out.",,"['statistics', 'statistical-inference']"
33,Population mean and expected value = µ?,Population mean and expected value = µ?,,"What is the difference between µ when being the population mean, and µ when being the mean or the expected value? What confuses me is that the same letter is being used to describe two different metrics- or are they? I am solely basing this question on their equation which isn't the same, so where am I missing the point?","What is the difference between µ when being the population mean, and µ when being the mean or the expected value? What confuses me is that the same letter is being used to describe two different metrics- or are they? I am solely basing this question on their equation which isn't the same, so where am I missing the point?",,"['statistics', 'means']"
34,How can I recursively approximate a moving average and standard deviation?,How can I recursively approximate a moving average and standard deviation?,,"Consider a sequence of measurements $(x_1, x_2, ...)$. Let $\mu_n$ be the $p$-period moving average defined by $$\mu_n = \frac{1}{p}\sum_{i=n-p+1}^nx_i$$ and $\sigma_n$ be the $p$-period moving standard deviation defined by $$\sigma_n=\sqrt{\frac{1}{p}\sum_{i=n-p+1}^n (x_i - \mu_n)^2}$$ I would like to find the best approximation of $\mu_{n+1}$ and $\sigma_{n+1}$, given only $\mu_n$, $\sigma_n$, and $x_{n+1}$. I believe that the (a?) best approximation for $\mu_n$ would be $$\mu_{n+1}\approx \frac{(p-1)\mu_{n} + x_{n+1}}{p}$$ Call this (or whatever other approximation you use if there is a better one) $\tilde{\mu}_{n+1}$. How well could you approximate $\sigma_{n+1}$? Would $$\sigma_{n+1}\approx \sqrt{\frac{(p-1)\sigma_n^2 + (x_{n+1}-\mu_n)^2}{p}}$$ work? Also, is it possible to quantify how well these approximations would perform recursively? Suppose I begin with a good estimate of the moving average and set those as $\tilde{\mu}_0,\tilde{\sigma}_0$. Now, using these approximations recursively, would the approximations be good?","Consider a sequence of measurements $(x_1, x_2, ...)$. Let $\mu_n$ be the $p$-period moving average defined by $$\mu_n = \frac{1}{p}\sum_{i=n-p+1}^nx_i$$ and $\sigma_n$ be the $p$-period moving standard deviation defined by $$\sigma_n=\sqrt{\frac{1}{p}\sum_{i=n-p+1}^n (x_i - \mu_n)^2}$$ I would like to find the best approximation of $\mu_{n+1}$ and $\sigma_{n+1}$, given only $\mu_n$, $\sigma_n$, and $x_{n+1}$. I believe that the (a?) best approximation for $\mu_n$ would be $$\mu_{n+1}\approx \frac{(p-1)\mu_{n} + x_{n+1}}{p}$$ Call this (or whatever other approximation you use if there is a better one) $\tilde{\mu}_{n+1}$. How well could you approximate $\sigma_{n+1}$? Would $$\sigma_{n+1}\approx \sqrt{\frac{(p-1)\sigma_n^2 + (x_{n+1}-\mu_n)^2}{p}}$$ work? Also, is it possible to quantify how well these approximations would perform recursively? Suppose I begin with a good estimate of the moving average and set those as $\tilde{\mu}_0,\tilde{\sigma}_0$. Now, using these approximations recursively, would the approximations be good?",,"['statistics', 'approximation', 'recursive-algorithms']"
35,Statistics: Odd Moments,Statistics: Odd Moments,,Need help with this stat question. I know you start by integrating $z^k f(z)$ from $-\infty$ to $0 +$ integral of $z^k f(z)$ from $0$ to $\infty$. After that I'm stuck.,Need help with this stat question. I know you start by integrating $z^k f(z)$ from $-\infty$ to $0 +$ integral of $z^k f(z)$ from $0$ to $\infty$. After that I'm stuck.,,"['statistics', 'normal-distribution', 'order-statistics', 'moment-generating-functions']"
36,Ranking system that factors in both positioning and clustering?,Ranking system that factors in both positioning and clustering?,,"I'm not sure how to express my problem in proper semantic terms, so please forgive me if I am unclear, waffling or use the wrong terminology anywhere here!  I'm trying to find a ranking system that will not only take into account the relative position of the data points, but also somehow factor in where their scores lie on a normal distribution.  So for example, given the following data set, which we'll say represents the KPAs of 11 of my employees: Name        Position        Score ----        --------        ----- Alf         1               97 Bert        2               95 Charlie     2               95 Dan         4               80 Ed          5               77 Frank       6               44 Gary        7               43 Hank        8               42 Ian         9               41 John        10              5 Kevin       11              4 If I just look at the order in which everyone appears, all that I have is a set of ranks from 1-11.  It doesn't tell me if they're all flying high or all in deep trouble.  We could say I should be rewarding anyone over a certain KPA score, arranging training for people in a certain band, and/or firing people below a certain score, but for the purposes of this exercise, let's say we're continually tweaking the KPA formulas, so we'll only really know what a ""good"", ""mediocre"" or ""bad"" score is when we see how people perform relative to each other.  To give you an idea of what I'm going for: in the data set here, we have 3 high-flyers, 2 doing OK, 4 under-performers and 2 guys who probably need to be fired.  I don't much care that Frank is in 6th position and Ian is 9th; their respective performance levels don't have much between them, and they both need to pick up their act. Is there some formula or ranking system that would be able to rank these people as well as group them into bands or clusters of performance levels?","I'm not sure how to express my problem in proper semantic terms, so please forgive me if I am unclear, waffling or use the wrong terminology anywhere here!  I'm trying to find a ranking system that will not only take into account the relative position of the data points, but also somehow factor in where their scores lie on a normal distribution.  So for example, given the following data set, which we'll say represents the KPAs of 11 of my employees: Name        Position        Score ----        --------        ----- Alf         1               97 Bert        2               95 Charlie     2               95 Dan         4               80 Ed          5               77 Frank       6               44 Gary        7               43 Hank        8               42 Ian         9               41 John        10              5 Kevin       11              4 If I just look at the order in which everyone appears, all that I have is a set of ranks from 1-11.  It doesn't tell me if they're all flying high or all in deep trouble.  We could say I should be rewarding anyone over a certain KPA score, arranging training for people in a certain band, and/or firing people below a certain score, but for the purposes of this exercise, let's say we're continually tweaking the KPA formulas, so we'll only really know what a ""good"", ""mediocre"" or ""bad"" score is when we see how people perform relative to each other.  To give you an idea of what I'm going for: in the data set here, we have 3 high-flyers, 2 doing OK, 4 under-performers and 2 guys who probably need to be fired.  I don't much care that Frank is in 6th position and Ian is 9th; their respective performance levels don't have much between them, and they both need to pick up their act. Is there some formula or ranking system that would be able to rank these people as well as group them into bands or clusters of performance levels?",,['statistics']
37,How to count importance of bought rate?,How to count importance of bought rate?,,We are presenting lists of products to our users. Users can buy products. We have about 100 000 products. Users are watching only two or three pages of products. It's important to show best products on the first two pages. We are saving to database that user saw product and bought it. So we can count something like bought rate: BR = (how many times product was bought) / (how many times product was seen) The higher BR the higer product is on products list so more users will see it. Everyday we are integrating new products and very often we are showing on the first page products bought once and seen once. We know that other products for example bought 10 times and seen 10 000 times are match better. It is rather coincidence that product has BR ~= 1 and BR will be much worst within few days. How to count how important is BR? Now we know that 1/1 is not very important but we are looking for more mature solution how to count it. It would be great if we could get some help with this.,We are presenting lists of products to our users. Users can buy products. We have about 100 000 products. Users are watching only two or three pages of products. It's important to show best products on the first two pages. We are saving to database that user saw product and bought it. So we can count something like bought rate: BR = (how many times product was bought) / (how many times product was seen) The higher BR the higer product is on products list so more users will see it. Everyday we are integrating new products and very often we are showing on the first page products bought once and seen once. We know that other products for example bought 10 times and seen 10 000 times are match better. It is rather coincidence that product has BR ~= 1 and BR will be much worst within few days. How to count how important is BR? Now we know that 1/1 is not very important but we are looking for more mature solution how to count it. It would be great if we could get some help with this.,,['statistics']
38,Expected run in a run test.,Expected run in a run test.,,The run test is used to know whether the given data is random or not.  How can we derive the formula for the expected run with $n_1$ ups and $n_2$ downs.,The run test is used to know whether the given data is random or not.  How can we derive the formula for the expected run with $n_1$ ups and $n_2$ downs.,,"['probability', 'statistics']"
39,Interesting identity arising from fractional factorial design of resolution III,Interesting identity arising from fractional factorial design of resolution III,,"I am learning about statistical design of experiments, and in the process of mathematically rigorizing the concepts behind fractional factorial designs of resolution III, I derived an interesting equation: $$k = \sum_{i=1}^{3}{\lceil{\log_2{k}}\rceil \choose i},$$ for which the solutions $k$ are the Mersenne primes. How can I show this? Is the above equation algebraic? Is it even solvable analytically?","I am learning about statistical design of experiments, and in the process of mathematically rigorizing the concepts behind fractional factorial designs of resolution III, I derived an interesting equation: $$k = \sum_{i=1}^{3}{\lceil{\log_2{k}}\rceil \choose i},$$ for which the solutions $k$ are the Mersenne primes. How can I show this? Is the above equation algebraic? Is it even solvable analytically?",,['statistics']
40,Rearranging equation with algebra,Rearranging equation with algebra,,"I'm having a difficult time showing that the two are equivalent: $2(x_1-\theta)(1+(x_2-\theta)^2)+2(x_2-\theta)(1+(x_1-\theta)^2) = 2(\bar{x}-\theta)(1+(x_1-\theta)(x_2-\theta))$ I have multiplied out the first part of the right hand equation, and I have: $2(x_1+x_1x_2^2-2x_1x_2\theta+x_1\theta^2-\theta-x_2^2\theta+2x_2\theta^2-\theta^3)$ However, I'm not sure how to rearrange the equation so that I can pull out a $(\bar{x}-\theta)$.","I'm having a difficult time showing that the two are equivalent: $2(x_1-\theta)(1+(x_2-\theta)^2)+2(x_2-\theta)(1+(x_1-\theta)^2) = 2(\bar{x}-\theta)(1+(x_1-\theta)(x_2-\theta))$ I have multiplied out the first part of the right hand equation, and I have: $2(x_1+x_1x_2^2-2x_1x_2\theta+x_1\theta^2-\theta-x_2^2\theta+2x_2\theta^2-\theta^3)$ However, I'm not sure how to rearrange the equation so that I can pull out a $(\bar{x}-\theta)$.",,"['calculus', 'probability', 'algebra-precalculus', 'statistics']"
41,Can regression to the mean explain the unexpected underperformance (per player-rating) of girls against boys on chess?,Can regression to the mean explain the unexpected underperformance (per player-rating) of girls against boys on chess?,,"I'm somewhat mathematically illiterate, I'd appreciate some help in order to satisfy a curiosity. Concise summary attempt: chess ratings are derived from past performance and therefore thought to be good predictors of future performance, odds of the match according to the ratings of the opponent. Men are ""on average"", better chess players than women, but it would still be ""predicted"" that odds of a match between a man and a woman would be ""dictated"" only by their ratings. But a psychological finding was that girls underperformed in matches against boys. The hypothesized psychological explanation is that girls, being stereotypically worse than boys (and, in fact, worse on average), are excessively stressed, intimidated in such matches, and perform worse than when competing against other girls. A commenter on a blog suggested that this explanation isn't needed, that the finding can be explained just by regression towards the mean. This explanation doesn't seem to make sense to me, just as (intuitively, and I could be wrong) I wouldn't expect a similar finding in a random small group of chess players which also had a smaller average score -- the individual ratings would still be more predictive than ""belonging"" to this group, I'd bet. I also think I've read once that regression towards the mean could the explanation in the opposite direction, that women aren't ""really"" worse than men on average, that it's just a mathematical artifact of there being way fewer female chess players. It couldn't work both ways, could it? Not so concise. :-/ Following there's the post I wrote before, with perhaps some still relevant points, additional explanation of my ""reasoning"", and hopefully not terrible to read. Chess has a fairly interesting rating system, that is roughly (perhaps ""roughly"" underscores it) an estimate of performance, and that ""predicts"" odds of next performance, according to the rating of the opponent. Chess players gain or lose points according to the rating difference of the adversary, and the result. The higher are the odds against the winner (per higher rating of the adversary), the higher the winner's ratings are increased. One can even score points by drawing with a significantly stronger opponent (perhaps with ""any"" stronger opponent, but only a negligible increase the closer the ratings are). And likewise, the higher were the odds favoring someone who loses, the more the loser's rating is decreased. A psychological study has found that girls, in gender-mixed tournaments (which I guess are the majority[*]) underperform when playing against boys, according to this system. The theoretical psychological explanation is ""stereotype threat"", that psychological stress makes people perform significantly worse in situations that evoke stereotypes about the inferior performance of their group, like ""girls aren't good at chess"", or even mildly improve, in positive stereotypes. http://bps-research-digest.blogspot.com/2014/01/girls-underperform-when-they-play-chess.html One of the commenters on the blog suggested that it's just the expected from regression towards the mean, given that women, in general, have lower ratings than men (that's a fact, not questioned here). But can it really explain this finding? Would it also be expected that by sorting random groups of players (can be all men, compared only against men, or computers/chess engines), only adding up to a similar a lower average rating of that group (or perhaps preferably a similar rating distribution ), and looking at their matches, find that individuals on this group are ""more likely"" to have underperformed, as expected from their ratings? It strikes me just as odd as saying that somehow Kasparov has a ""higher chance"" of underperforming if I, a weak chess non-player, enter the same tournament, and we're wearing the same shirt color. And at the same time I'd not play any better, even if everybody with other shirt colors are bad enough to have together a lower average than the embarrassing ""Kasparov and I"" average. That is, a random, smaller group, only with a lower average rating wouldn't obviously affect the performance of any individual player (good or bad). But would it somehow be saying anything about odds of individuals within that group? Perhaps something like boys, heavy-metal fans only, would be expected to still often have shorter hair length when compared to girls? While that doesn't seem that unlikely, I'm not sure it's quite analogous with the expectations of the rating mechanism. [*] the proportion can have a role explaining the disparity, as the ratings of female-only tournaments could be inflated. But again I'm not sure it's that much significative, I think it would be similar for any proportionally weak ""beginner/weaker player tournaments"". And there would be many more weaker boys than girls in absolute numbers, if that levels things up. I'm not sure of anything really. I just think that such think would have an effect at national levels, that is, weak countries with inflated endogenous ratings, but I've never heard of that. It's also perhaps worth mentioning that the full range of potential explanations isn't in question here (it even sort of goes against the site's rules), the scope should be whether just random below-average groupings would allow us to predict a lower average performance for individuals within that group, even when that wouldn't be expected without such grouping, somehow. Or whether somehow these are mathematically different propositions, an invalid analogy. For me it's just utterly counter intuitive, seems plain wrong, but in the other hand, like many other people, I also thought that it wouldn't make a difference to chose the other door or not on the Monty Hall dilemma. I'm sorry for the length of the post.","I'm somewhat mathematically illiterate, I'd appreciate some help in order to satisfy a curiosity. Concise summary attempt: chess ratings are derived from past performance and therefore thought to be good predictors of future performance, odds of the match according to the ratings of the opponent. Men are ""on average"", better chess players than women, but it would still be ""predicted"" that odds of a match between a man and a woman would be ""dictated"" only by their ratings. But a psychological finding was that girls underperformed in matches against boys. The hypothesized psychological explanation is that girls, being stereotypically worse than boys (and, in fact, worse on average), are excessively stressed, intimidated in such matches, and perform worse than when competing against other girls. A commenter on a blog suggested that this explanation isn't needed, that the finding can be explained just by regression towards the mean. This explanation doesn't seem to make sense to me, just as (intuitively, and I could be wrong) I wouldn't expect a similar finding in a random small group of chess players which also had a smaller average score -- the individual ratings would still be more predictive than ""belonging"" to this group, I'd bet. I also think I've read once that regression towards the mean could the explanation in the opposite direction, that women aren't ""really"" worse than men on average, that it's just a mathematical artifact of there being way fewer female chess players. It couldn't work both ways, could it? Not so concise. :-/ Following there's the post I wrote before, with perhaps some still relevant points, additional explanation of my ""reasoning"", and hopefully not terrible to read. Chess has a fairly interesting rating system, that is roughly (perhaps ""roughly"" underscores it) an estimate of performance, and that ""predicts"" odds of next performance, according to the rating of the opponent. Chess players gain or lose points according to the rating difference of the adversary, and the result. The higher are the odds against the winner (per higher rating of the adversary), the higher the winner's ratings are increased. One can even score points by drawing with a significantly stronger opponent (perhaps with ""any"" stronger opponent, but only a negligible increase the closer the ratings are). And likewise, the higher were the odds favoring someone who loses, the more the loser's rating is decreased. A psychological study has found that girls, in gender-mixed tournaments (which I guess are the majority[*]) underperform when playing against boys, according to this system. The theoretical psychological explanation is ""stereotype threat"", that psychological stress makes people perform significantly worse in situations that evoke stereotypes about the inferior performance of their group, like ""girls aren't good at chess"", or even mildly improve, in positive stereotypes. http://bps-research-digest.blogspot.com/2014/01/girls-underperform-when-they-play-chess.html One of the commenters on the blog suggested that it's just the expected from regression towards the mean, given that women, in general, have lower ratings than men (that's a fact, not questioned here). But can it really explain this finding? Would it also be expected that by sorting random groups of players (can be all men, compared only against men, or computers/chess engines), only adding up to a similar a lower average rating of that group (or perhaps preferably a similar rating distribution ), and looking at their matches, find that individuals on this group are ""more likely"" to have underperformed, as expected from their ratings? It strikes me just as odd as saying that somehow Kasparov has a ""higher chance"" of underperforming if I, a weak chess non-player, enter the same tournament, and we're wearing the same shirt color. And at the same time I'd not play any better, even if everybody with other shirt colors are bad enough to have together a lower average than the embarrassing ""Kasparov and I"" average. That is, a random, smaller group, only with a lower average rating wouldn't obviously affect the performance of any individual player (good or bad). But would it somehow be saying anything about odds of individuals within that group? Perhaps something like boys, heavy-metal fans only, would be expected to still often have shorter hair length when compared to girls? While that doesn't seem that unlikely, I'm not sure it's quite analogous with the expectations of the rating mechanism. [*] the proportion can have a role explaining the disparity, as the ratings of female-only tournaments could be inflated. But again I'm not sure it's that much significative, I think it would be similar for any proportionally weak ""beginner/weaker player tournaments"". And there would be many more weaker boys than girls in absolute numbers, if that levels things up. I'm not sure of anything really. I just think that such think would have an effect at national levels, that is, weak countries with inflated endogenous ratings, but I've never heard of that. It's also perhaps worth mentioning that the full range of potential explanations isn't in question here (it even sort of goes against the site's rules), the scope should be whether just random below-average groupings would allow us to predict a lower average performance for individuals within that group, even when that wouldn't be expected without such grouping, somehow. Or whether somehow these are mathematically different propositions, an invalid analogy. For me it's just utterly counter intuitive, seems plain wrong, but in the other hand, like many other people, I also thought that it wouldn't make a difference to chose the other door or not on the Monty Hall dilemma. I'm sorry for the length of the post.",,['statistics']
42,Second moment of chi squared distribution,Second moment of chi squared distribution,,"I've got difficulties in computing the second momentum of chi squared. Chi squared distribution with $n$ degrees of freedom is the sum of $n$ independent distributions $X^2$, where $X \sim N(0;1)$. We know that the fourth momentum of each $X_i$ is $3$. So, mark $\chi^2 = C$, and  $$E(C^2) = E\left[ \left(\sum X^2\right)^2 \right] = \sum E\left[X^4\right] = 3n$$ where the penultimate equality is due to $X$s being iid and linearity of E-operator. The correct answer is $n^2 +2n$, so there is something wrong with the above calculation, but I just can't spot what it is. (Please note that I'm not claiming that $\left(\sum x^2 \right)^ 2 = \sum x^4$ in general. Here it should hold however, since the $X$s are independent, right?)","I've got difficulties in computing the second momentum of chi squared. Chi squared distribution with $n$ degrees of freedom is the sum of $n$ independent distributions $X^2$, where $X \sim N(0;1)$. We know that the fourth momentum of each $X_i$ is $3$. So, mark $\chi^2 = C$, and  $$E(C^2) = E\left[ \left(\sum X^2\right)^2 \right] = \sum E\left[X^4\right] = 3n$$ where the penultimate equality is due to $X$s being iid and linearity of E-operator. The correct answer is $n^2 +2n$, so there is something wrong with the above calculation, but I just can't spot what it is. (Please note that I'm not claiming that $\left(\sum x^2 \right)^ 2 = \sum x^4$ in general. Here it should hold however, since the $X$s are independent, right?)",,['statistics']
43,What is the joint probability distribution of number of balls after $n$ draws?,What is the joint probability distribution of number of balls after  draws?,n,"The following problem came into my mind when I am studying the Polya Urn Model . At the beginning, from a bin containing $c_1$ balls labeled $1$, $c_2$ balls labeled $2$, … , $c_m$ balls labeled $m$, a ball is drawn at random ( $c_i>0, \, 1\leqslant i\leqslant m$, $m>2$ ). Its label is noted and the ball is put back to the bin along with addition $r>0$ balls with the same label. Then always starting with the newly constituted bin, the experiment is continued $n\geqslant 0$ times. Let $B_1$, $B_2$, … , $B_m$ denote the numbers of balls of different labels after $n$ draws. What is the joint probability distribution $$f_n(B_1=c_1+r\cdot k_1, B_2=c_2+r\cdot k_2,..., B_{m}=c_m+r\cdot(n-\sum\nolimits_{i=1}^{m-1}k_i)),$$ where $k_i$ is a nonnegative integer? I have found that $$f_0(B_1=c_1, B_2=c_2,..., B_{m}=c_m)=1,$$  and $$f_1(B_1=c_1, B_2=c_2…, B_i=c_i+r,..., B_{m}=c_m)=\frac{c_i}{\sum\nolimits_{j=1}^{m}c_j}$$ for $1\leqslant i\leqslant m$. But this recursive formula gets very complicate when $n>2$. Is there any easier way to give this distribution? I feel like this problem has been solved, but I’m having trouble finding sources. Any help or references would be greatly appreciated!","The following problem came into my mind when I am studying the Polya Urn Model . At the beginning, from a bin containing $c_1$ balls labeled $1$, $c_2$ balls labeled $2$, … , $c_m$ balls labeled $m$, a ball is drawn at random ( $c_i>0, \, 1\leqslant i\leqslant m$, $m>2$ ). Its label is noted and the ball is put back to the bin along with addition $r>0$ balls with the same label. Then always starting with the newly constituted bin, the experiment is continued $n\geqslant 0$ times. Let $B_1$, $B_2$, … , $B_m$ denote the numbers of balls of different labels after $n$ draws. What is the joint probability distribution $$f_n(B_1=c_1+r\cdot k_1, B_2=c_2+r\cdot k_2,..., B_{m}=c_m+r\cdot(n-\sum\nolimits_{i=1}^{m-1}k_i)),$$ where $k_i$ is a nonnegative integer? I have found that $$f_0(B_1=c_1, B_2=c_2,..., B_{m}=c_m)=1,$$  and $$f_1(B_1=c_1, B_2=c_2…, B_i=c_i+r,..., B_{m}=c_m)=\frac{c_i}{\sum\nolimits_{j=1}^{m}c_j}$$ for $1\leqslant i\leqslant m$. But this recursive formula gets very complicate when $n>2$. Is there any easier way to give this distribution? I feel like this problem has been solved, but I’m having trouble finding sources. Any help or references would be greatly appreciated!",,"['probability', 'combinatorics', 'statistics', 'probability-distributions']"
44,Interesting Problem - Computing CDF,Interesting Problem - Computing CDF,,"A rv X is an exponential distribution with parameter 1 and Y is a uniform distribution between 0 and 1. X and Y are independent. Define Z = min {X, Y}. Compute the CDF of Z ? I really have no idea about this question. My thought is that you need to use integration but how exactly ? Can any experts shed some light on this one ?","A rv X is an exponential distribution with parameter 1 and Y is a uniform distribution between 0 and 1. X and Y are independent. Define Z = min {X, Y}. Compute the CDF of Z ? I really have no idea about this question. My thought is that you need to use integration but how exactly ? Can any experts shed some light on this one ?",,"['probability', 'integration', 'statistics', 'probability-distributions']"
45,"What is the distribution of $|X-Y|$ if both $X$ and $Y$ are $U(0,1)$?",What is the distribution of  if both  and  are ?,"|X-Y| X Y U(0,1)","I am trying to find the distribution of $Z = |X-Y|$ if both $X$ and $Y$ are uniform over $(0, 1)$ and independent. The answer I am getting is very close to the one given but I can't figure out why they're different at all. My method is as follows: $$ Z = \left\{\begin{aligned} &X-Y &&\text{if }  X \ge Y \\ &Y-X &&\text{if }  X \lt Y \\ \end{aligned} \right.$$ If $Z = X - Y$ then $Y = X-Z$ and so $$f_z = \int_a^bf_x(x)f_y(x-z)dx $$ To determine $a$ and $b$: $$0 \le x \le 1 \text{ and } z \le x \le 1+z$$ Since $Z$ is always bigger  than 0, the bounds for the integral are $z$ and $1$. $$f_z = \int_z^1dx = 1-z$$ Repeating the same process for $Z = Y-X$, $$f_z = \int_a^bf_x(x)f_y(x+z)dx$$ $$0\le x \le 1 \text{ and }-z \le x \le 1-z $$ Again since $Z$ is always positive, the integral becomes $$f_z = \int_0^{1-z}dx = 1-z$$ Putting everything together, $$ f_z = \left\{\begin{aligned} &1-z &&\text{if }  X \ge Y \\ &1-z &&\text{if }  X \lt Y \\ \end{aligned} \right.$$ ...or just $1-z$. However the answer provided states that $f_z = -2(z-1)$, which is just $2$ times what I have. Where did I go wrong? Thanks!","I am trying to find the distribution of $Z = |X-Y|$ if both $X$ and $Y$ are uniform over $(0, 1)$ and independent. The answer I am getting is very close to the one given but I can't figure out why they're different at all. My method is as follows: $$ Z = \left\{\begin{aligned} &X-Y &&\text{if }  X \ge Y \\ &Y-X &&\text{if }  X \lt Y \\ \end{aligned} \right.$$ If $Z = X - Y$ then $Y = X-Z$ and so $$f_z = \int_a^bf_x(x)f_y(x-z)dx $$ To determine $a$ and $b$: $$0 \le x \le 1 \text{ and } z \le x \le 1+z$$ Since $Z$ is always bigger  than 0, the bounds for the integral are $z$ and $1$. $$f_z = \int_z^1dx = 1-z$$ Repeating the same process for $Z = Y-X$, $$f_z = \int_a^bf_x(x)f_y(x+z)dx$$ $$0\le x \le 1 \text{ and }-z \le x \le 1-z $$ Again since $Z$ is always positive, the integral becomes $$f_z = \int_0^{1-z}dx = 1-z$$ Putting everything together, $$ f_z = \left\{\begin{aligned} &1-z &&\text{if }  X \ge Y \\ &1-z &&\text{if }  X \lt Y \\ \end{aligned} \right.$$ ...or just $1-z$. However the answer provided states that $f_z = -2(z-1)$, which is just $2$ times what I have. Where did I go wrong? Thanks!",,"['probability', 'statistics']"
46,Show that $Var(\theta_1)>Var(\theta_2)$.,Show that .,Var(\theta_1)>Var(\theta_2),"I calculated that     $$ Var(\theta_1)=\frac{2\sigma^2}{(x_n-x_1)^2},~~~~~Var(\theta_2)=\frac{\sigma^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}. $$     Now I have to show that for $\sigma^2 >0$ and $\overline{x}\neq\frac{(x_1+x_n)}{2}$ it is     $$ Var(\theta_1) > Var(\theta_2). $$ I have to show that it is $$ \frac{2\sigma^2}{(x_n-x_1)^2} > \frac{\sigma^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}. $$ Do you have an idea how to show that? Unfortunately, I have not. Edit: I've already tried to show that $$ Var(\theta_2)/Var(\theta_1)<1, $$ i.e. that $$ \frac{(x_n-x_1)^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}=\frac{x_1^2+x_n^2-2x_1x_n}{\sum_{i=1}^{n}x_i^2-n\overline{x}^2}<1 $$ but with no success.","I calculated that     $$ Var(\theta_1)=\frac{2\sigma^2}{(x_n-x_1)^2},~~~~~Var(\theta_2)=\frac{\sigma^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}. $$     Now I have to show that for $\sigma^2 >0$ and $\overline{x}\neq\frac{(x_1+x_n)}{2}$ it is     $$ Var(\theta_1) > Var(\theta_2). $$ I have to show that it is $$ \frac{2\sigma^2}{(x_n-x_1)^2} > \frac{\sigma^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}. $$ Do you have an idea how to show that? Unfortunately, I have not. Edit: I've already tried to show that $$ Var(\theta_2)/Var(\theta_1)<1, $$ i.e. that $$ \frac{(x_n-x_1)^2}{\sum_{i=1}^{n}(x_i-\overline{x})^2}=\frac{x_1^2+x_n^2-2x_1x_n}{\sum_{i=1}^{n}x_i^2-n\overline{x}^2}<1 $$ but with no success.",,['statistics']
47,Non-i.i.d Empirical Risk Minimization,Non-i.i.d Empirical Risk Minimization,,"I'm not a statisticians so please forgive me if I posed a silly question, but it's a real problem for me in my research. Suppose we have defined risk in a regression problem as $R(f)=\int l(f(x),y) p(x) dx$ in which we want to estimate $f$ based on the data.The function $l$ is loss functions which measures the discrepancy between output of the function $f$ and provided label $y$ for every $x$. If we sample i.i.d then it's possible that we substitute $p(x)={1/n} \Sigma^n_{i=1} \delta(x-x_i)$. The function $\delta$ is the delta Kronecker function. Result will be Empirical Risk minimization. i.e. $R(f)={1/n} \Sigma^n_{i=1} l(f(x_i),y_i) $. But if our samples are not i.i.d, then it's not possible to write $p(x)$ as above, so ERM in this simple form is not possible. The problem is what can we can do in the case of non-i.i.d samples. More specifically, if our samples are not independent, what can be done? how to write $p(x)$ similar to the one above that considers the effect of non-i.i.d samples? If I have any miss-understanding or if I posed the questions wrongly please comment. Also, is there any source or material directly related to this problem in literature.","I'm not a statisticians so please forgive me if I posed a silly question, but it's a real problem for me in my research. Suppose we have defined risk in a regression problem as $R(f)=\int l(f(x),y) p(x) dx$ in which we want to estimate $f$ based on the data.The function $l$ is loss functions which measures the discrepancy between output of the function $f$ and provided label $y$ for every $x$. If we sample i.i.d then it's possible that we substitute $p(x)={1/n} \Sigma^n_{i=1} \delta(x-x_i)$. The function $\delta$ is the delta Kronecker function. Result will be Empirical Risk minimization. i.e. $R(f)={1/n} \Sigma^n_{i=1} l(f(x_i),y_i) $. But if our samples are not i.i.d, then it's not possible to write $p(x)$ as above, so ERM in this simple form is not possible. The problem is what can we can do in the case of non-i.i.d samples. More specifically, if our samples are not independent, what can be done? how to write $p(x)$ similar to the one above that considers the effect of non-i.i.d samples? If I have any miss-understanding or if I posed the questions wrongly please comment. Also, is there any source or material directly related to this problem in literature.",,"['probability', 'statistics', 'sampling']"
48,Need to check if a t- test should be used instead of a z -test here! [closed],Need to check if a t- test should be used instead of a z -test here! [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question For this question shouldn't they be using a t test and the test statistic should be t and not z as the sample is small? Is this a mistake in the mark scheme?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 10 years ago . Improve this question For this question shouldn't they be using a t test and the test statistic should be t and not z as the sample is small? Is this a mistake in the mark scheme?",,['statistics']
49,Deck Building Probability Stats for Fun/Beginners (HEX tcg),Deck Building Probability Stats for Fun/Beginners (HEX tcg),,"EDIT Given the amount of time spent on the problem I eventually solved it, so below I leave the structure of the original problem and the answer I came up with. I will be writing it up over the next few days, as I want to explain it clearly and share for opinions, if you have any. Hello mathematical community. I picked up a deck building game (HEX TCG) and set out to find out the inner workings of resource management without more than the bare bones of and engineer's knowledge of statistics. I came to my solution after a week and below is the explanation of the problem and how I attacked it applying principles of probabilities, please enjoy and share your views. Please take note that I may use terminologies in a slightly personal way as that is my relationship with statistical maths, though I am making my best effort to describe it with the correct terms. Intro: A deck is constituted by 60 cards . There are several types of cards but for this problem we only need focus on 2 types of cards, type 1: resource cards and, type 2: non-resource cards . Resources are needed to play cards. How the cards are played: On the opening turn of the game the player draws 7 cards from the deck into their hand. Which player goes first is decided by a coin flip. The player that goes second only is allowed to draw an extra card on the opening turn. During each turn (including the opening turn) the player is allowed to play only 1 resource from their hand, if they possess one. Once played it stays on the field. At the beginning of each new turn each player draws 1 card from the remaining deck. The problem: The objective of a player building their deck is to build it with enough resources to give them the best chance of playing a minimum number of resources to the field as fast as possible. This minimum number of resources the player should aim to play as fast as possible is dictated by the highest costing cards in the player's deck (cards can cost up to 7 resources). It is obvious that if you had 100% resources this would maximise the probabilities but then the player wouldn't be able to do anything so the objective is to draw up a relationship to calculate the optimal number and its associated probability of being playable. For the sake of keeping the problem simple I analysed the maths and the effect on the initial 10 turns , read ahead. The Stats The first part of the problem consisted in describing the probability of drawing a specific number of resources into the players hands in the opening turn based on whether the player draws 7 or 8 or whether the player Mulligans (decides to redraw their hand, but in doing so draw 1 card less). Drawing The First Hand I first of all calculated how many permutation (without repetitions) the probability tree yields for each drawn amount of cards using equation: $$\frac{n!}{r!\,(n-r)!} \tag{1}\label{1}$$ where $n=$Total drawn cards ($1\leq n\leq8$) $r=$Total drawn resource cards ($0\leq r\leq7$) This yields the amount of different combinations in which a given number of $r$ can be drawn into the players hand below is the case for $r=7$: Resources drawn (r)   0    1     2     3     4     5    6    7 No. of permutations   1    7    21    35    35    21    7    1 This is to be multiplied by the probability of drawing that number of resource cards into the players hand which I worked out as the following equation: $$\left(\frac{\frac{T_{R}!}{(T_{R}-r)!}\times\frac{T_{N}!}{(T_{N}-(n-r))!}}{\frac{T!}{(T-n)!}}\right) \tag{2}\label{2}$$ Where (as above $n=$Total drawn cards and $r=$Drawn resources) and: $T_{R}=$Total resources in initial deck. $T_{N}=$ Total non-resources in initial deck. $T=$Total initial deck cards. It follows that that $T_{R}+T_{N}=T=60$. Below is the calculated example for the case$T_{R}=23$ and $r=3$ resources drawn for $n=7$ cards drawn into hand. $$\left(\frac{\frac{23!}{(23-3)!}\times\frac{37!}{(37-(7-3))!}}{\frac{60!}{(60-7)!}}\right)=\left(\frac{(23\cdot22\cdot21)\times(37\cdot36\cdot35\cdot34)}{60\cdot59\cdot58\cdot57\cdot56\cdot55\cdot54}\right)=0.008653\dots$$ The final probability, which I will call $P(n,r)$, for any given value of $n$ and $r$, is simply equation $\eqref{1}\times$ equation $\eqref{2}$ as follows: $$\left(\frac{n!}{r!\,(n-r)!}\right)\times\left(\frac{\frac{T_{R}!}{(T_{R}-r)!}\times\frac{T_{N}!}{(T_{N}-(n-r))!}}{\frac{T!}{(T-n)!}}\right)=P(n,r) \tag{3}\label{3}$$ So once again for the above case where $T_{R}=23$ $$P(n=7,r=3)=0.008653\dots\times35=30.29\%$$ I could hence at this point graph the probability curves for all values of drawn resources $r$ (when drawing $n=7$ cards for the below image) for all values of possible $T_{R}$ resources in the deck: Resources in a deck vs probability of drawing $r$ resources into an $n=7$ hand Drawing Each Turn The next step involved the same maths but applied to the situation of drawing resources with each turn. This yields a second probability tree and a formula identical to equation $\eqref{1}$ to calculate the amount of permutations (again without repetition) for the amount of resources drawn and turns played: $$\left(\frac{n_{2}!}{r_{2}!\,(n_{2}-r_{2})!}\right) \tag{4}\label{4}$$ Where: $n_{2}=$Number of turns after drawing turn. $r_{2}=$Number of resources drawn in the turns $n_{2}$. The second part for the formula to describe this situation is the same as equation $\eqref{2}$ but this time with the $r_{2}$ and $n_{2}$ terms added to the factorials as follows: $$\left(\frac{\frac{(T_{R}-r)!}{(T_{R}-r-r_{2})!}\times\frac{(T_{N}-(n-r))!}{(T_{N}-(n-r)-(n_{2}-r_{2}))!}}{\frac{(T-n)!}{(T-n-n_{2})!}}\right) \tag{5}\label{5}$$ Where (as above $n_{2}=$Number of turns and $r_{2}=$Drawn resources in those turns) and: $T_{R}=$Total resources in initial deck. $T_{N}=$ Total non-resources in initial deck. $T=$Total initial deck cards. Once again multiply the number of permutations based on $r_{2}$ (equation $\eqref{4}$ by equation $\eqref{5}$: $$\left(\frac{n_{2}!}{r_{2}!\,(n_{2}-r_{2})!}\right)\times\left(\frac{\frac{(T_{R}-r)!}{(T_{R}-r-r_{2})!}\times\frac{(T_{N}-(n-r))!}{(T_{N}-(n-r)-(n_{2}-r_{2}))!}}{\frac{(T-n)!}{(T-n-n_{2})!}}\right)=P(n_{2},r_{2}) \tag{6}\label{6}$$ to get probability $P(n_{2},r_{2})$. The graph of which looks as below: Resources in deck vs the probability of drawing $r_{2}=5$ resources in $n_{2}=10$ turns given the amount of resourced already drawn into hand in the opening phase ($n=1$) Intercept Probability Now if we take equation $\eqref{3}$ as being equal to $P(A)$ and $\eqref{6}$ as being equal to $P(B|A)$ then: $$P(A\cap B)=P(A)\times P(B|A)$$ Meaning: $$P(A\cap B)=\left(\frac{n!}{r!\,(n-r)!}\right)\times\left(\frac{\frac{T_{R}!}{(T_{R}-r)!}\times\frac{T_{N}!}{(T_{N}-(n-r))!}}{\frac{T!}{(T-n)!}}\right)\times\left(\frac{n_{2}!}{r_{2}!\,(n_{2}-r_{2})!}\right)\times\left(\frac{\frac{(T_{R}-r)!}{(T_{R}-r-r_{2})!}\times\frac{(T_{N}-(n-r))!}{(T_{N}-(n-r)-(n_{2}-r_{2}))!}}{\frac{(T-n)!}{(T-n-n_{2})!}}\right) \tag{7}\label{7}$$ Which finally gives the probability of drawing $r_{2}$ resource cards over a period of $n_{2}$ turns, based on the probability of having drawn $r$ resources into a hand of size $n$! For the same case as shown just above of $P(B|A)$ where $n_{2}=10$ and $r_{2}=5$, the $P(A\cap B)$ gives the following graph: Resources in a deck vs the probability of drawing $r_{2}=5$ resources within $n_{2}=10$ turns given the player has drawn $r$ resources in an opening hand of size $n=7$ Limits of the Equations It is important at this point to note the limits within which these equations don't break. The cases which return non-computable values are associated to factorials of negative numbers. These arise in the following cases and corresponding IF statements should be included as advised: For equation $\eqref{3}$: IF $T_{N}<(n-r)$ is TRUE then set $\left(\frac{T_{N}!}{(T_{N}-(n-r))!}\right)=0$ otherwise it would be an invalid number. IF $(T_{R}-r)<0$ is TRUE then set $\left(\frac{T_{R}!}{(T_{R}-r)!}\right)=0$ otherwise it will be an invalid number. For equation $\eqref{6}$: IF $(T_{N}-(n-r))<(n_{2}-r_{2})$ is TRUE then set $\left(\frac{(T_{N}-(n-r))!}{(T_{N}-(n-r)-(n_{2}-r_{2})!}\right)=0$ otherwise it will be an invalid number. IF $(T_{R}-r-r_{2})<0$ is TRUE then set $\left(\frac{(T_{R}-r)!}{(T_{R}-r-r_{2})!}\right)=0$ otherwise it will be an invalid number. Conclusion So above I have described the formulation of the equations associated with being able to solve the issue associated with resource optimisation in a deck, now how do we apply it to give us a usable number? Check out the answer.","EDIT Given the amount of time spent on the problem I eventually solved it, so below I leave the structure of the original problem and the answer I came up with. I will be writing it up over the next few days, as I want to explain it clearly and share for opinions, if you have any. Hello mathematical community. I picked up a deck building game (HEX TCG) and set out to find out the inner workings of resource management without more than the bare bones of and engineer's knowledge of statistics. I came to my solution after a week and below is the explanation of the problem and how I attacked it applying principles of probabilities, please enjoy and share your views. Please take note that I may use terminologies in a slightly personal way as that is my relationship with statistical maths, though I am making my best effort to describe it with the correct terms. Intro: A deck is constituted by 60 cards . There are several types of cards but for this problem we only need focus on 2 types of cards, type 1: resource cards and, type 2: non-resource cards . Resources are needed to play cards. How the cards are played: On the opening turn of the game the player draws 7 cards from the deck into their hand. Which player goes first is decided by a coin flip. The player that goes second only is allowed to draw an extra card on the opening turn. During each turn (including the opening turn) the player is allowed to play only 1 resource from their hand, if they possess one. Once played it stays on the field. At the beginning of each new turn each player draws 1 card from the remaining deck. The problem: The objective of a player building their deck is to build it with enough resources to give them the best chance of playing a minimum number of resources to the field as fast as possible. This minimum number of resources the player should aim to play as fast as possible is dictated by the highest costing cards in the player's deck (cards can cost up to 7 resources). It is obvious that if you had 100% resources this would maximise the probabilities but then the player wouldn't be able to do anything so the objective is to draw up a relationship to calculate the optimal number and its associated probability of being playable. For the sake of keeping the problem simple I analysed the maths and the effect on the initial 10 turns , read ahead. The Stats The first part of the problem consisted in describing the probability of drawing a specific number of resources into the players hands in the opening turn based on whether the player draws 7 or 8 or whether the player Mulligans (decides to redraw their hand, but in doing so draw 1 card less). Drawing The First Hand I first of all calculated how many permutation (without repetitions) the probability tree yields for each drawn amount of cards using equation: $$\frac{n!}{r!\,(n-r)!} \tag{1}\label{1}$$ where $n=$Total drawn cards ($1\leq n\leq8$) $r=$Total drawn resource cards ($0\leq r\leq7$) This yields the amount of different combinations in which a given number of $r$ can be drawn into the players hand below is the case for $r=7$: Resources drawn (r)   0    1     2     3     4     5    6    7 No. of permutations   1    7    21    35    35    21    7    1 This is to be multiplied by the probability of drawing that number of resource cards into the players hand which I worked out as the following equation: $$\left(\frac{\frac{T_{R}!}{(T_{R}-r)!}\times\frac{T_{N}!}{(T_{N}-(n-r))!}}{\frac{T!}{(T-n)!}}\right) \tag{2}\label{2}$$ Where (as above $n=$Total drawn cards and $r=$Drawn resources) and: $T_{R}=$Total resources in initial deck. $T_{N}=$ Total non-resources in initial deck. $T=$Total initial deck cards. It follows that that $T_{R}+T_{N}=T=60$. Below is the calculated example for the case$T_{R}=23$ and $r=3$ resources drawn for $n=7$ cards drawn into hand. $$\left(\frac{\frac{23!}{(23-3)!}\times\frac{37!}{(37-(7-3))!}}{\frac{60!}{(60-7)!}}\right)=\left(\frac{(23\cdot22\cdot21)\times(37\cdot36\cdot35\cdot34)}{60\cdot59\cdot58\cdot57\cdot56\cdot55\cdot54}\right)=0.008653\dots$$ The final probability, which I will call $P(n,r)$, for any given value of $n$ and $r$, is simply equation $\eqref{1}\times$ equation $\eqref{2}$ as follows: $$\left(\frac{n!}{r!\,(n-r)!}\right)\times\left(\frac{\frac{T_{R}!}{(T_{R}-r)!}\times\frac{T_{N}!}{(T_{N}-(n-r))!}}{\frac{T!}{(T-n)!}}\right)=P(n,r) \tag{3}\label{3}$$ So once again for the above case where $T_{R}=23$ $$P(n=7,r=3)=0.008653\dots\times35=30.29\%$$ I could hence at this point graph the probability curves for all values of drawn resources $r$ (when drawing $n=7$ cards for the below image) for all values of possible $T_{R}$ resources in the deck: Resources in a deck vs probability of drawing $r$ resources into an $n=7$ hand Drawing Each Turn The next step involved the same maths but applied to the situation of drawing resources with each turn. This yields a second probability tree and a formula identical to equation $\eqref{1}$ to calculate the amount of permutations (again without repetition) for the amount of resources drawn and turns played: $$\left(\frac{n_{2}!}{r_{2}!\,(n_{2}-r_{2})!}\right) \tag{4}\label{4}$$ Where: $n_{2}=$Number of turns after drawing turn. $r_{2}=$Number of resources drawn in the turns $n_{2}$. The second part for the formula to describe this situation is the same as equation $\eqref{2}$ but this time with the $r_{2}$ and $n_{2}$ terms added to the factorials as follows: $$\left(\frac{\frac{(T_{R}-r)!}{(T_{R}-r-r_{2})!}\times\frac{(T_{N}-(n-r))!}{(T_{N}-(n-r)-(n_{2}-r_{2}))!}}{\frac{(T-n)!}{(T-n-n_{2})!}}\right) \tag{5}\label{5}$$ Where (as above $n_{2}=$Number of turns and $r_{2}=$Drawn resources in those turns) and: $T_{R}=$Total resources in initial deck. $T_{N}=$ Total non-resources in initial deck. $T=$Total initial deck cards. Once again multiply the number of permutations based on $r_{2}$ (equation $\eqref{4}$ by equation $\eqref{5}$: $$\left(\frac{n_{2}!}{r_{2}!\,(n_{2}-r_{2})!}\right)\times\left(\frac{\frac{(T_{R}-r)!}{(T_{R}-r-r_{2})!}\times\frac{(T_{N}-(n-r))!}{(T_{N}-(n-r)-(n_{2}-r_{2}))!}}{\frac{(T-n)!}{(T-n-n_{2})!}}\right)=P(n_{2},r_{2}) \tag{6}\label{6}$$ to get probability $P(n_{2},r_{2})$. The graph of which looks as below: Resources in deck vs the probability of drawing $r_{2}=5$ resources in $n_{2}=10$ turns given the amount of resourced already drawn into hand in the opening phase ($n=1$) Intercept Probability Now if we take equation $\eqref{3}$ as being equal to $P(A)$ and $\eqref{6}$ as being equal to $P(B|A)$ then: $$P(A\cap B)=P(A)\times P(B|A)$$ Meaning: $$P(A\cap B)=\left(\frac{n!}{r!\,(n-r)!}\right)\times\left(\frac{\frac{T_{R}!}{(T_{R}-r)!}\times\frac{T_{N}!}{(T_{N}-(n-r))!}}{\frac{T!}{(T-n)!}}\right)\times\left(\frac{n_{2}!}{r_{2}!\,(n_{2}-r_{2})!}\right)\times\left(\frac{\frac{(T_{R}-r)!}{(T_{R}-r-r_{2})!}\times\frac{(T_{N}-(n-r))!}{(T_{N}-(n-r)-(n_{2}-r_{2}))!}}{\frac{(T-n)!}{(T-n-n_{2})!}}\right) \tag{7}\label{7}$$ Which finally gives the probability of drawing $r_{2}$ resource cards over a period of $n_{2}$ turns, based on the probability of having drawn $r$ resources into a hand of size $n$! For the same case as shown just above of $P(B|A)$ where $n_{2}=10$ and $r_{2}=5$, the $P(A\cap B)$ gives the following graph: Resources in a deck vs the probability of drawing $r_{2}=5$ resources within $n_{2}=10$ turns given the player has drawn $r$ resources in an opening hand of size $n=7$ Limits of the Equations It is important at this point to note the limits within which these equations don't break. The cases which return non-computable values are associated to factorials of negative numbers. These arise in the following cases and corresponding IF statements should be included as advised: For equation $\eqref{3}$: IF $T_{N}<(n-r)$ is TRUE then set $\left(\frac{T_{N}!}{(T_{N}-(n-r))!}\right)=0$ otherwise it would be an invalid number. IF $(T_{R}-r)<0$ is TRUE then set $\left(\frac{T_{R}!}{(T_{R}-r)!}\right)=0$ otherwise it will be an invalid number. For equation $\eqref{6}$: IF $(T_{N}-(n-r))<(n_{2}-r_{2})$ is TRUE then set $\left(\frac{(T_{N}-(n-r))!}{(T_{N}-(n-r)-(n_{2}-r_{2})!}\right)=0$ otherwise it will be an invalid number. IF $(T_{R}-r-r_{2})<0$ is TRUE then set $\left(\frac{(T_{R}-r)!}{(T_{R}-r-r_{2})!}\right)=0$ otherwise it will be an invalid number. Conclusion So above I have described the formulation of the equations associated with being able to solve the issue associated with resource optimisation in a deck, now how do we apply it to give us a usable number? Check out the answer.",,"['probability', 'statistics', 'conditional-probability']"
50,I need help with this review question. Business Calculus/Statistics,I need help with this review question. Business Calculus/Statistics,,"The question is: The scores on a test have a mean of 100 and a standard deviation of 8. A personnel manager wishes to select the top 60% of applicants. Find the cutoff score. Assume the variable is normally distributed. What I don't know: I don't know how to set up this problem.  I know z = (x - mean) / Standard deviation so its z = (x - 100) / 8 and I am looking for x, the cutoff score. How should z look like? Its looking for the top 60% so the answer will be less than the mean because its the same as looking for the cutoff score for the bottom 40%. Is 95.2 = x the correct answer (I used -.6 as z to get that), or is 96.8 (-.4 used as z) the correct answer? or are neither of those correct? This is the only problem I missed and I'm just not sure what z needs to be set as. Thanks for any help.","The question is: The scores on a test have a mean of 100 and a standard deviation of 8. A personnel manager wishes to select the top 60% of applicants. Find the cutoff score. Assume the variable is normally distributed. What I don't know: I don't know how to set up this problem.  I know z = (x - mean) / Standard deviation so its z = (x - 100) / 8 and I am looking for x, the cutoff score. How should z look like? Its looking for the top 60% so the answer will be less than the mean because its the same as looking for the cutoff score for the bottom 40%. Is 95.2 = x the correct answer (I used -.6 as z to get that), or is 96.8 (-.4 used as z) the correct answer? or are neither of those correct? This is the only problem I missed and I'm just not sure what z needs to be set as. Thanks for any help.",,"['statistics', 'standard-deviation']"
51,"If $X$ ~$Uni(-1,1)$ show that $X$ and $X^2$ are not independent",If  ~ show that  and  are not independent,"X Uni(-1,1) X X^2","I provide my approach in solving this but I amd not entirely sure whether I am correct. Since X~uni(-1,1) $f_X(x)=1/2$ and $F_X(x)=(x+1)/2$. $F_{X^2}(x)$=$Pr[X^2≤x]$=$2F_X(√x)$=$(√x+1)/2$. Hence $f_{X^2}(x)$=$1/(4√x)$. Now $f_X(x).f_{X^2}(x)$=$1/(8√x)$. Now what I need is to find $F_{X^2,X}(x)$ which is the part I am struggling to derive. Is $F_{X^2,X}(x)$=$F_{X^2}(x)$ ? I would appreciate any assistance and answers and hope that the steps I have shown are enough. Thanks in advance","I provide my approach in solving this but I amd not entirely sure whether I am correct. Since X~uni(-1,1) $f_X(x)=1/2$ and $F_X(x)=(x+1)/2$. $F_{X^2}(x)$=$Pr[X^2≤x]$=$2F_X(√x)$=$(√x+1)/2$. Hence $f_{X^2}(x)$=$1/(4√x)$. Now $f_X(x).f_{X^2}(x)$=$1/(8√x)$. Now what I need is to find $F_{X^2,X}(x)$ which is the part I am struggling to derive. Is $F_{X^2,X}(x)$=$F_{X^2}(x)$ ? I would appreciate any assistance and answers and hope that the steps I have shown are enough. Thanks in advance",,"['probability', 'statistics', 'uniform-distribution']"
52,iid random variables (vectors),iid random variables (vectors),,"If $(X_{1},Y_{1}), (X_{2}, Y_{2}),...,(X_{n}, Y_{n})$ denote a sequence of iid random variables from $(X,Y)$, can I say that each $X_{i}$ is independent from each $Y_{i}$? Or is it just for the vector, i.e. that each $(X_{i},Y_{i})$ is independent from each $(X_{j},Y_{j})$ for $i \neq j$?","If $(X_{1},Y_{1}), (X_{2}, Y_{2}),...,(X_{n}, Y_{n})$ denote a sequence of iid random variables from $(X,Y)$, can I say that each $X_{i}$ is independent from each $Y_{i}$? Or is it just for the vector, i.e. that each $(X_{i},Y_{i})$ is independent from each $(X_{j},Y_{j})$ for $i \neq j$?",,"['statistics', 'random-variables']"
53,LR Test for Exponential Family of Distributions,LR Test for Exponential Family of Distributions,,"LR Test for Exponential Family of Distributions: The exponential family of distributions, both  discrete and continuous, based on a parameter θ is defined by: f (x |theta) = c(x)d(theta)exp[a(theta)b(x)] Show that N(μ,1) is a special case of this family. That is, determine the values for the  functions a, b, c, and d.","LR Test for Exponential Family of Distributions: The exponential family of distributions, both  discrete and continuous, based on a parameter θ is defined by: f (x |theta) = c(x)d(theta)exp[a(theta)b(x)] Show that N(μ,1) is a special case of this family. That is, determine the values for the  functions a, b, c, and d.",,"['probability', 'statistics', 'probability-distributions']"
54,Expectation by conditioning,Expectation by conditioning,,"Problem: Independent trials, each of which is a success with probability $p$, are performed until there are $k$ consecutive successes. What is the mean number of necessary trials? Start on solution. Let $N_k$ denote the number of necessary trials to obtain $k$ consecutive successes, and let $M_k$ denote its mean. We will obtain a recursive equation for $M_k$ by conditioning on $N_{k−1}$, the number of trials needed for $k − 1$ consecutive successes. This yields $$M_k = {\rm E}[N_k] = {\rm E}[{\rm E}[N_k|N_{k−1}]].$$ I do not understand that equation.","Problem: Independent trials, each of which is a success with probability $p$, are performed until there are $k$ consecutive successes. What is the mean number of necessary trials? Start on solution. Let $N_k$ denote the number of necessary trials to obtain $k$ consecutive successes, and let $M_k$ denote its mean. We will obtain a recursive equation for $M_k$ by conditioning on $N_{k−1}$, the number of trials needed for $k − 1$ consecutive successes. This yields $$M_k = {\rm E}[N_k] = {\rm E}[{\rm E}[N_k|N_{k−1}]].$$ I do not understand that equation.",,"['probability', 'statistics']"
55,Change in single observation of data set and how it will affect sample variance,Change in single observation of data set and how it will affect sample variance,,"Q/ Consider the sample of size n=10, where the sample mean is 6 and the sample variance is 12. Consider a second sample that is exactly the same as the first except that there is an additional observation, that takes on the value of 6. What is the sample variance for this larger sample with n=11 observations? any help would be appreciated :) Thanks!","Q/ Consider the sample of size n=10, where the sample mean is 6 and the sample variance is 12. Consider a second sample that is exactly the same as the first except that there is an additional observation, that takes on the value of 6. What is the sample variance for this larger sample with n=11 observations? any help would be appreciated :) Thanks!",,"['statistics', 'descriptive-statistics']"
56,"The minimal sufficient statistic is not unique, but the minimal sufficient partition is unique, what does this mean?","The minimal sufficient statistic is not unique, but the minimal sufficient partition is unique, what does this mean?",,Can anyone help to illustrate the statement with some examples?,Can anyone help to illustrate the statement with some examples?,,"['probability', 'statistics']"
57,Correlation between complex random variables,Correlation between complex random variables,,"I am struggling to find the correlation between two complex r.vs; X and 1/ Y i.e. E{ X*/Y }, where '*' denotes the conjugation operator. The complex r.s X and Y are correlated with each other with known covariance matrix. Moreover, E{ X/Y } is also known. can anyone help?","I am struggling to find the correlation between two complex r.vs; X and 1/ Y i.e. E{ X*/Y }, where '*' denotes the conjugation operator. The complex r.s X and Y are correlated with each other with known covariance matrix. Moreover, E{ X/Y } is also known. can anyone help?",,"['probability', 'statistics', 'correlation']"
58,What am I doing wrong in calculating Fisher Information of Triangular Distribution?,What am I doing wrong in calculating Fisher Information of Triangular Distribution?,,"I am trying to find Jeffrey's prior for the Triangular distribution which has the following probability density function: $$f(x\mid \theta) =       \begin{cases}        \dfrac{2x}{\theta} & : x \leq \theta , x\in[0,1], \theta \in [0,1] \\[6pt]        \dfrac{2(1-x)}{1-\theta} & : x > \theta , x\in[0,1], \theta \in [0,1]      \end{cases}     $$ Jeffrey's prior is given by $\pi(\theta) \propto \sqrt{I(\theta)}$ where $I(\theta)$ is the Fisher Information for parameter $\theta$. My professor said that the Jeffrey's prior should be $\beta(1/2,1/2)$. So, essentially I need $I(\theta) \propto \frac{1}{\theta(1-\theta)}$ since the kernel of $\beta(1/2,1/2)$ is $\frac{1}{\theta^{1/2}(1-\theta)^{1/2}}$ So, I begin to calculate $I(\theta) = \mathbb{E}_\theta[(\frac{\partial}{\partial \theta}\log(f(x\mid \theta))^2]$. $\log(f(x\mid \theta)) = \left\{      \begin{array}{lr}        \log{2x} - \log{\theta} & : x \leq \theta , x\in[0,1], \theta \in [0,1] \\        \log{2(1-x)} - \log(1-\theta) & : x > \theta , x\in[0,1], \theta \in [0,1]      \end{array}    \right. $ $\Rightarrow \frac{\partial}{\partial \theta}\log(f(x\mid \theta) = \left\{      \begin{array}{lr}        -\frac{1}{\theta} : x \leq \theta , x\in[0,1], \theta \in [0,1] \\        \frac{1}{(1-\theta)} : x > \theta , x\in[0,1], \theta \in [0,1]      \end{array}    \right. $ $\Rightarrow \mathbb{E}_\theta[(\frac{\partial}{\partial \theta}\log(f(x\mid\theta))^2] = \left\{      \begin{array}{lr}        \frac{1}{\theta^2} : x \leq \theta , x\in[0,1], \theta \in [0,1] \\        \frac{1}{(1-\theta)^2} : x > \theta , x\in[0,1], \theta \in [0,1]      \end{array}    \right. $ which is certainly not proportional to $\frac{1}{\theta(1-\theta)}$ for all $\theta$. What am I doing wrong?","I am trying to find Jeffrey's prior for the Triangular distribution which has the following probability density function: $$f(x\mid \theta) =       \begin{cases}        \dfrac{2x}{\theta} & : x \leq \theta , x\in[0,1], \theta \in [0,1] \\[6pt]        \dfrac{2(1-x)}{1-\theta} & : x > \theta , x\in[0,1], \theta \in [0,1]      \end{cases}     $$ Jeffrey's prior is given by $\pi(\theta) \propto \sqrt{I(\theta)}$ where $I(\theta)$ is the Fisher Information for parameter $\theta$. My professor said that the Jeffrey's prior should be $\beta(1/2,1/2)$. So, essentially I need $I(\theta) \propto \frac{1}{\theta(1-\theta)}$ since the kernel of $\beta(1/2,1/2)$ is $\frac{1}{\theta^{1/2}(1-\theta)^{1/2}}$ So, I begin to calculate $I(\theta) = \mathbb{E}_\theta[(\frac{\partial}{\partial \theta}\log(f(x\mid \theta))^2]$. $\log(f(x\mid \theta)) = \left\{      \begin{array}{lr}        \log{2x} - \log{\theta} & : x \leq \theta , x\in[0,1], \theta \in [0,1] \\        \log{2(1-x)} - \log(1-\theta) & : x > \theta , x\in[0,1], \theta \in [0,1]      \end{array}    \right. $ $\Rightarrow \frac{\partial}{\partial \theta}\log(f(x\mid \theta) = \left\{      \begin{array}{lr}        -\frac{1}{\theta} : x \leq \theta , x\in[0,1], \theta \in [0,1] \\        \frac{1}{(1-\theta)} : x > \theta , x\in[0,1], \theta \in [0,1]      \end{array}    \right. $ $\Rightarrow \mathbb{E}_\theta[(\frac{\partial}{\partial \theta}\log(f(x\mid\theta))^2] = \left\{      \begin{array}{lr}        \frac{1}{\theta^2} : x \leq \theta , x\in[0,1], \theta \in [0,1] \\        \frac{1}{(1-\theta)^2} : x > \theta , x\in[0,1], \theta \in [0,1]      \end{array}    \right. $ which is certainly not proportional to $\frac{1}{\theta(1-\theta)}$ for all $\theta$. What am I doing wrong?",,"['probability', 'statistics', 'bayesian']"
59,Binomial thinning of geometric distribution,Binomial thinning of geometric distribution,,"I need to show that a random variable follows a specific law, how could I do that? Let $\{A_{i,j}\}$ be an infinite iid array of Bernouilli($\psi$) variables and $\eta_1,\ldots,\eta_n$ be iid geometric($p$) random variables. Let $X_1,\ldots, X_n$ be iid random variables defined by: $$X_j=\sum_{i=1}^{\eta_j}A_{i,j}, \quad j=1,\ldots, n.$$ How could I show that $$X\sim \mbox{geometric}\left(\frac{p}{\psi(1-p)+p}\right).$$ Thanks a lot!","I need to show that a random variable follows a specific law, how could I do that? Let $\{A_{i,j}\}$ be an infinite iid array of Bernouilli($\psi$) variables and $\eta_1,\ldots,\eta_n$ be iid geometric($p$) random variables. Let $X_1,\ldots, X_n$ be iid random variables defined by: $$X_j=\sum_{i=1}^{\eta_j}A_{i,j}, \quad j=1,\ldots, n.$$ How could I show that $$X\sim \mbox{geometric}\left(\frac{p}{\psi(1-p)+p}\right).$$ Thanks a lot!",,"['probability', 'statistics', 'probability-distributions']"
60,How to show that estimator is unbiased,How to show that estimator is unbiased,,"Let $f(x;\theta) = (1/\theta)x^{(1-\theta)/\theta} $$\hspace{20 mm}$ $   0 <x <1 ,\hspace{5 mm} 0 <\theta<\infty$ The maximum likelihood estimator of $\theta $ is $\hat{\theta}$ = $-(1/n) \sum ln  X_i$ How can I show that this estimator is unbiased?","Let $f(x;\theta) = (1/\theta)x^{(1-\theta)/\theta} $$\hspace{20 mm}$ $   0 <x <1 ,\hspace{5 mm} 0 <\theta<\infty$ The maximum likelihood estimator of $\theta $ is $\hat{\theta}$ = $-(1/n) \sum ln  X_i$ How can I show that this estimator is unbiased?",,['statistics']
61,(Second) derivation of J.R. Gott's probability distribution,(Second) derivation of J.R. Gott's probability distribution,,"I'm trying to digest J.R. Gott's 1993 Nature paper describing how the Copernican principle can be applied to estimate the duration of our species (and many other neat things). The paper opens with a section he calls the ""Delta t"" argument which I found very straightforward. Then he restates the problem more formally in the next section, rederiving the same result as before. I'm not able to follow his math in equation 6. Because of the publication firewall, I'll copy the relevant lines here. Let $r_1$ and $r_2$ be independent random numbers each distributed uniformly over the interval [0, 1]. For a given species alive today,   $$ r_1^{t_f/t_p} = r_2 $$   Let $Y>0$ be a constant   $$ P\left( [ t_f/t_p] > Y \right) = \int_0^1 r_1^Y\,dr_1$$ Clearly statistics is not my strong suit, but I have the impression that this calculation would involve finding $P\left( r_1^Y - r_2 > 0 \right)$ and don't see the connection to the integral given. I thought I could calculate this by applying this information that if $X$ has a standard uniform distribution, then $Z=X^n$ also has a standard uniform distribution, to calculate $P\left( r_1^Y - r_2 > 0 \right)$ using summation of two independent random variables, but I am obviously bungling it because in that case the $Y$ seems to disappear. Any help appreciated!","I'm trying to digest J.R. Gott's 1993 Nature paper describing how the Copernican principle can be applied to estimate the duration of our species (and many other neat things). The paper opens with a section he calls the ""Delta t"" argument which I found very straightforward. Then he restates the problem more formally in the next section, rederiving the same result as before. I'm not able to follow his math in equation 6. Because of the publication firewall, I'll copy the relevant lines here. Let $r_1$ and $r_2$ be independent random numbers each distributed uniformly over the interval [0, 1]. For a given species alive today,   $$ r_1^{t_f/t_p} = r_2 $$   Let $Y>0$ be a constant   $$ P\left( [ t_f/t_p] > Y \right) = \int_0^1 r_1^Y\,dr_1$$ Clearly statistics is not my strong suit, but I have the impression that this calculation would involve finding $P\left( r_1^Y - r_2 > 0 \right)$ and don't see the connection to the integral given. I thought I could calculate this by applying this information that if $X$ has a standard uniform distribution, then $Z=X^n$ also has a standard uniform distribution, to calculate $P\left( r_1^Y - r_2 > 0 \right)$ using summation of two independent random variables, but I am obviously bungling it because in that case the $Y$ seems to disappear. Any help appreciated!",,"['probability', 'statistics']"
62,How to find $P(X=r)$ from probability generating function of $X$?,How to find  from probability generating function of ?,P(X=r) X,"I have a probability generating function $$G_X(s) = \frac{p+ps}{1-s+p+ps}$$ and I need to find $P(X=r)$. How do I get this from the probability generating function? I was thinking about finding the Mac Laurin expansion of $G_X(s)$ and finding the general formula for the coefficient of $s^r$, but that's proving very difficult. Thanks","I have a probability generating function $$G_X(s) = \frac{p+ps}{1-s+p+ps}$$ and I need to find $P(X=r)$. How do I get this from the probability generating function? I was thinking about finding the Mac Laurin expansion of $G_X(s)$ and finding the general formula for the coefficient of $s^r$, but that's proving very difficult. Thanks",,"['probability', 'statistics', 'probability-distributions']"
63,Uniformly distributed points over the surface of the standard simplex,Uniformly distributed points over the surface of the standard simplex,,"I would like to generate points that are uniformly distributed over the SURFACE of a standard $k$-simplex ($k$ dimensions, $k+1$ vertices). One way to efficiently generate points that are uniformly distributed over the ENTIRETY of the $k$-simplex is to generate samples of $k$ iid exponential random variables, $E_i$, $i\in \left[1,k\right]$, then normalize, and $\vec{X}=\frac{\left\langle E_1,E_2,\dots,E_k\right\rangle}{\sum_{i=1}^k E_i}$, will be uniformly distributed over the entire $k$-simplex. My problem is that the probability that one of these points lands on the surface (i.e. at a vertex, or along a hyper-edge, or on hyper-face, etc.) is nearly $0$, so that in practice all of the points end up being in the INTERIOR of the $k$-simplex. In an attempt to sample the SURFACE of the $k$-simplex I have considered each hyper-edge, hyper-face, etc. separately and generated uniformly distributed samples on each (since they are themselves lower dimensional simplices). However, the problem becomes computationally unfeasible as $k$ increases because the number of hyper-edges, hyper-faces, etc. blows up. Does anyone know of a method to explicitly generate samples that are uniformly distributed over the SURFACE (or BOUNDARY) of a standard $k$-simplex?","I would like to generate points that are uniformly distributed over the SURFACE of a standard $k$-simplex ($k$ dimensions, $k+1$ vertices). One way to efficiently generate points that are uniformly distributed over the ENTIRETY of the $k$-simplex is to generate samples of $k$ iid exponential random variables, $E_i$, $i\in \left[1,k\right]$, then normalize, and $\vec{X}=\frac{\left\langle E_1,E_2,\dots,E_k\right\rangle}{\sum_{i=1}^k E_i}$, will be uniformly distributed over the entire $k$-simplex. My problem is that the probability that one of these points lands on the surface (i.e. at a vertex, or along a hyper-edge, or on hyper-face, etc.) is nearly $0$, so that in practice all of the points end up being in the INTERIOR of the $k$-simplex. In an attempt to sample the SURFACE of the $k$-simplex I have considered each hyper-edge, hyper-face, etc. separately and generated uniformly distributed samples on each (since they are themselves lower dimensional simplices). However, the problem becomes computationally unfeasible as $k$ increases because the number of hyper-edges, hyper-faces, etc. blows up. Does anyone know of a method to explicitly generate samples that are uniformly distributed over the SURFACE (or BOUNDARY) of a standard $k$-simplex?",,"['probability', 'statistics', 'probability-distributions', 'sampling', 'simplex']"
64,Probability of choosing a integer between 1-100 is in the interval $68<X\leq 85$,Probability of choosing a integer between 1-100 is in the interval,68<X\leq 85,I am coming out with 0.17 and I KNOW that there are 17 integers between 69 and 85 (counting 69) book says 0.16. Is the book wrong?,I am coming out with 0.17 and I KNOW that there are 17 integers between 69 and 85 (counting 69) book says 0.16. Is the book wrong?,,"['probability', 'statistics']"
65,Stats is not maths?,Stats is not maths?,,"How mainstream is the claim that stats is not maths? And if it's right, how many people don't agree? Given that it's all numbers, taught by maths departments and you get maths credits for it, I wonder whether the claim is just half-jokingly meant, like saying it's a minor part of maths, or just applied maths.","How mainstream is the claim that stats is not maths? And if it's right, how many people don't agree? Given that it's all numbers, taught by maths departments and you get maths credits for it, I wonder whether the claim is just half-jokingly meant, like saying it's a minor part of maths, or just applied maths.",,"['statistics', 'soft-question', 'meta-math']"
66,Confused about notation: difference between $\prod_{i=1}^np(x_i)$ and $\prod_{i=1}^np(x)$,Confused about notation: difference between  and,\prod_{i=1}^np(x_i) \prod_{i=1}^np(x),"In my information theory book by Cover and Thomas, at the beginning of the channel coding theorem, it's written: ""Each entry in this matrix"" (the matrix of the randomly generated code) ""is generated i.i.d according to p(x). Thus, the probability that we generate a particular code $C$ is "" $Pr(C)=\prod_{w=1}^{2^{nR}} \prod_{i=1}^np(x_i(w))$ Now, I get what they're saying, but the notation is very confusing to me. $1-$First of all, since we are generating entries i.i.d why can't we simplify $\prod_{i=1}^np(x_i)$ to $\prod_{i=1}^np(x)=p(x)^n?$ $2-$Also, instead of writing $p(x_i(w))$ couldn't we just write $p(x_{i,w})$? It seems as if there's something about the notation that's crucial that I'm not getting.. Any help would really be appreciated!! Thanks in advance","In my information theory book by Cover and Thomas, at the beginning of the channel coding theorem, it's written: ""Each entry in this matrix"" (the matrix of the randomly generated code) ""is generated i.i.d according to p(x). Thus, the probability that we generate a particular code $C$ is "" $Pr(C)=\prod_{w=1}^{2^{nR}} \prod_{i=1}^np(x_i(w))$ Now, I get what they're saying, but the notation is very confusing to me. $1-$First of all, since we are generating entries i.i.d why can't we simplify $\prod_{i=1}^np(x_i)$ to $\prod_{i=1}^np(x)=p(x)^n?$ $2-$Also, instead of writing $p(x_i(w))$ couldn't we just write $p(x_{i,w})$? It seems as if there's something about the notation that's crucial that I'm not getting.. Any help would really be appreciated!! Thanks in advance",,"['probability', 'statistics', 'information-theory']"
67,normal distribution question?,normal distribution question?,,"I was wondering if anyone could explain how to use the mean and standard deviation of a normal distribution to determine the top 5% of population? -It is for homework, but I wont post the actual questions since I want to do them myself. Just needing an explanation that isn't a mathbook that I can understand, thanks","I was wondering if anyone could explain how to use the mean and standard deviation of a normal distribution to determine the top 5% of population? -It is for homework, but I wont post the actual questions since I want to do them myself. Just needing an explanation that isn't a mathbook that I can understand, thanks",,['statistics']
68,Why use Euclidean distance in linear model?,Why use Euclidean distance in linear model?,,"The method of least squares is the most basic method in statistical linear models. For the simplest linear model$$Y_i=\beta_0+X_i\beta_1+\epsilon_i$$we are looking for $\beta_0$ and $\beta_1$ that minimizes the Euclidean distance $\sum\limits_{i=1}^n|Y_i-\beta_0-X_i\beta_1|^2$. I learned statistics and an engineering student asked me why not use  $\sum\limits_{i=1}^n|Y_i-\beta_0-X_i\beta_1|$ or things like $\sum\limits_{i=1}^n|Y_i-\beta_0-X_i\beta_1|^4$, I got stuck...... Is there any convincing answer for this question?","The method of least squares is the most basic method in statistical linear models. For the simplest linear model$$Y_i=\beta_0+X_i\beta_1+\epsilon_i$$we are looking for $\beta_0$ and $\beta_1$ that minimizes the Euclidean distance $\sum\limits_{i=1}^n|Y_i-\beta_0-X_i\beta_1|^2$. I learned statistics and an engineering student asked me why not use  $\sum\limits_{i=1}^n|Y_i-\beta_0-X_i\beta_1|$ or things like $\sum\limits_{i=1}^n|Y_i-\beta_0-X_i\beta_1|^4$, I got stuck...... Is there any convincing answer for this question?",,['statistics']
69,Minimization of Sum of Squares Error Function,Minimization of Sum of Squares Error Function,,"Given that $y(x,{\bf w}) = w_0 + w_1x + w_2x^2 + \ldots + w_mx^m = 	\sum_{j=0}^{m} w_jx^j$ and there exists an error function defined as $E({\bf w})=\frac{1}{2} \sum_{n=1}^{N} \{y(x_n, w)-t_n\}^2$ (where $t_n$ represents the target value). I'm having trouble making sense of a passage in my textbook. (Note: ${\bf w}$ represents a vector of the polynomial's coefficients.) I've listed the passage below: We can solve the curve fitting problem by choosing the value of ${\bf w}$ for which $E({\bf w})$ is as small as possible. Because the error function is a quadratic function of the coefficients ${\bf w}$,   its derivatives with respect to the coefficients will be linear in the elements of ${\bf w}$, and so the minimization of the error function has a unique solution, denoted by ${\bf w^*}$, which can be found in closed form. How do we know that the minimal solution exists and is unique? What guarantees this? Any help understanding this would be appreciated.","Given that $y(x,{\bf w}) = w_0 + w_1x + w_2x^2 + \ldots + w_mx^m = 	\sum_{j=0}^{m} w_jx^j$ and there exists an error function defined as $E({\bf w})=\frac{1}{2} \sum_{n=1}^{N} \{y(x_n, w)-t_n\}^2$ (where $t_n$ represents the target value). I'm having trouble making sense of a passage in my textbook. (Note: ${\bf w}$ represents a vector of the polynomial's coefficients.) I've listed the passage below: We can solve the curve fitting problem by choosing the value of ${\bf w}$ for which $E({\bf w})$ is as small as possible. Because the error function is a quadratic function of the coefficients ${\bf w}$,   its derivatives with respect to the coefficients will be linear in the elements of ${\bf w}$, and so the minimization of the error function has a unique solution, denoted by ${\bf w^*}$, which can be found in closed form. How do we know that the minimal solution exists and is unique? What guarantees this? Any help understanding this would be appreciated.",,"['statistics', 'polynomials', 'optimization']"
70,Which is the better estimator for the mean?,Which is the better estimator for the mean?,,"measurements x1, x2, x3 from three independent runs of an experiment with variance sigma-squared. Which is the better estimator for the mean? (x1+x2+x3)/3 or (x1+2x2+x3)/4 I am having trouble with this homework problem. I think the first one would be the better estimator because it is an actual mean. I have learned that the best point estimator for a sample population mean would be µ. Now I need to justify this answer and I am stuck. Please help!","measurements x1, x2, x3 from three independent runs of an experiment with variance sigma-squared. Which is the better estimator for the mean? (x1+x2+x3)/3 or (x1+2x2+x3)/4 I am having trouble with this homework problem. I think the first one would be the better estimator because it is an actual mean. I have learned that the best point estimator for a sample population mean would be µ. Now I need to justify this answer and I am stuck. Please help!",,['statistics']
71,The Birthday Problem (n>30),The Birthday Problem (n>30),,I am trying to figure out that what is the probability that at least 40 people share the same birthday out of 350? Calculator gives an error when I try to calculate $^{365}P_{40}$. Please help!,I am trying to figure out that what is the probability that at least 40 people share the same birthday out of 350? Calculator gives an error when I try to calculate $^{365}P_{40}$. Please help!,,"['probability', 'statistics', 'birthday']"
72,Characteristic Function of Inverse Gaussian Distribution,Characteristic Function of Inverse Gaussian Distribution,,"The pdf of Inverse  Gaussian distribution, IG$(\mu,\lambda)$, is : $$p_X(x)=\sqrt\frac{\lambda}{2\pi x^3}\exp\left[\frac{-\lambda}{2\mu^2x}(x-\mu)^2\right];\quad x>0,\lambda,\mu>0$$ I have to compute the Characteristic Function, $\phi_X(t)$. $$\phi_X(t)=\mathbb E(e^{itX})=\int_0^\infty e^{itx}\sqrt\frac{\lambda}{2\pi x^3}\exp\left[\frac{-\lambda}{2\mu^2x}(x-\mu)^2\right] \, dx$$ I tried to fall it under Gamma function. $$\phi_X(t)=\sqrt\frac{\lambda}{2\pi}e^{\lambda/\mu}\int_0^\infty x^{\frac{-3}{2}}\exp\left[-\left(\frac{\lambda}{2\mu^2}+\frac{\lambda}{2x^2}-it\right)x\right]dx$$ $$ = \sqrt\frac{\lambda}{2\pi}e^{\lambda/\mu}\int_0^\infty x^{\frac{-3}{2}}\exp\left[\left(it-\frac{\lambda}{2\mu^2}\right)x-\frac{\lambda}{2x}\right]dx  $$","The pdf of Inverse  Gaussian distribution, IG$(\mu,\lambda)$, is : $$p_X(x)=\sqrt\frac{\lambda}{2\pi x^3}\exp\left[\frac{-\lambda}{2\mu^2x}(x-\mu)^2\right];\quad x>0,\lambda,\mu>0$$ I have to compute the Characteristic Function, $\phi_X(t)$. $$\phi_X(t)=\mathbb E(e^{itX})=\int_0^\infty e^{itx}\sqrt\frac{\lambda}{2\pi x^3}\exp\left[\frac{-\lambda}{2\mu^2x}(x-\mu)^2\right] \, dx$$ I tried to fall it under Gamma function. $$\phi_X(t)=\sqrt\frac{\lambda}{2\pi}e^{\lambda/\mu}\int_0^\infty x^{\frac{-3}{2}}\exp\left[-\left(\frac{\lambda}{2\mu^2}+\frac{\lambda}{2x^2}-it\right)x\right]dx$$ $$ = \sqrt\frac{\lambda}{2\pi}e^{\lambda/\mu}\int_0^\infty x^{\frac{-3}{2}}\exp\left[\left(it-\frac{\lambda}{2\mu^2}\right)x-\frac{\lambda}{2x}\right]dx  $$",,"['probability', 'statistics', 'probability-distributions', 'definite-integrals', 'normal-distribution']"
73,Probability and Stats,Probability and Stats,,"I need some help with the following question: In the game of ""odd man out"" each player tosses a fair coin. If all the coins turn up the same except for one, the player tossing the different coin is declared the odd man out and is eliminated from the contest. Suppose that three people are playing. What is the probability that someone will be eliminated on the first round? Hint: use the complement.","I need some help with the following question: In the game of ""odd man out"" each player tosses a fair coin. If all the coins turn up the same except for one, the player tossing the different coin is declared the odd man out and is eliminated from the contest. Suppose that three people are playing. What is the probability that someone will be eliminated on the first round? Hint: use the complement.",,['probability']
74,Elementary statistics problem,Elementary statistics problem,,"Suppose that a data set $ \{x_n: n = 1,\dots,N\} $, with $ N = 500,000 $ has average   \begin{equation} <x> = \frac{1}{N}\sum\limits_{n=1}^{N}x_n=13.06 \end{equation}   and root mean square   \begin{equation} \sigma = \sqrt{\frac{1}{N}\sum\limits_{n=1}^{N}x_n^2}=13.67 \end{equation}   Using this information, derive the best upper bound you can, for the number of measurements that are greater than $ 17.1 $. Intuition says that we should determine such $ k \in \mathbb{N}, l_0 \in \mathbb{R} $ so that exactly k measurements would be equal to $ 17.1 $, and exactly $ N - k $ measurements would be equal to $ l_0 $ (so that $ <x> $ and $ \sigma $ would be as given - obviously, it is very easy). But I can't even prove that $ k $ $ is $ an upper boundary, let alone the best one. can anybody hint, is there a well-known formula for this case?","Suppose that a data set $ \{x_n: n = 1,\dots,N\} $, with $ N = 500,000 $ has average   \begin{equation} <x> = \frac{1}{N}\sum\limits_{n=1}^{N}x_n=13.06 \end{equation}   and root mean square   \begin{equation} \sigma = \sqrt{\frac{1}{N}\sum\limits_{n=1}^{N}x_n^2}=13.67 \end{equation}   Using this information, derive the best upper bound you can, for the number of measurements that are greater than $ 17.1 $. Intuition says that we should determine such $ k \in \mathbb{N}, l_0 \in \mathbb{R} $ so that exactly k measurements would be equal to $ 17.1 $, and exactly $ N - k $ measurements would be equal to $ l_0 $ (so that $ <x> $ and $ \sigma $ would be as given - obviously, it is very easy). But I can't even prove that $ k $ $ is $ an upper boundary, let alone the best one. can anybody hint, is there a well-known formula for this case?",,['combinatorics']
75,How can I sample a bivariate Gaussian distribution using Gibbs sampling?,How can I sample a bivariate Gaussian distribution using Gibbs sampling?,,"I'm trying to sample a bivariate Gaussian distribution using Gibbs sampling, but I think I don't have the correct conditional probabilities. According to this lecture slides , the conditional expectation and variance of the bivariate Gaussian distribution are: $E[X|Y=y]=\mu_X+\sigma_X\rho(\frac{\displaystyle y-\mu_Y}{\displaystyle \sigma_Y})$ and $Var[X|Y=y]={{\sigma}_X}^2(1-{\rho}^2)$ So I'm sampling the bivariate Gaussian distribution using the standard normal distribution as follows: $f(X|Y=y)=\mu_X+\sigma_X\rho(\frac{\displaystyle y-\mu_Y}{\displaystyle \sigma_Y})+{{\sigma}_X}^2(1-{\rho}^2)\mathcal{N}(0,1)$ $f(Y|X=x)=\mu_Y+\sigma_Y\rho(\frac{\displaystyle x-\mu_X}{\displaystyle \sigma_X})+{{\sigma}_Y}^2(1-{\rho}^2)\mathcal{N}(0,1)$ Are these equations ok to sample the bivariate Gaussian?","I'm trying to sample a bivariate Gaussian distribution using Gibbs sampling, but I think I don't have the correct conditional probabilities. According to this lecture slides , the conditional expectation and variance of the bivariate Gaussian distribution are: $E[X|Y=y]=\mu_X+\sigma_X\rho(\frac{\displaystyle y-\mu_Y}{\displaystyle \sigma_Y})$ and $Var[X|Y=y]={{\sigma}_X}^2(1-{\rho}^2)$ So I'm sampling the bivariate Gaussian distribution using the standard normal distribution as follows: $f(X|Y=y)=\mu_X+\sigma_X\rho(\frac{\displaystyle y-\mu_Y}{\displaystyle \sigma_Y})+{{\sigma}_X}^2(1-{\rho}^2)\mathcal{N}(0,1)$ $f(Y|X=x)=\mu_Y+\sigma_Y\rho(\frac{\displaystyle x-\mu_X}{\displaystyle \sigma_X})+{{\sigma}_Y}^2(1-{\rho}^2)\mathcal{N}(0,1)$ Are these equations ok to sample the bivariate Gaussian?",,"['statistics', 'sampling']"
76,Derivation of Poisson from Binomial,Derivation of Poisson from Binomial,,"I am not very well versed in statistics so any clarification would be appreciated. I understand the mathematical derivation of Poisson from Binomial. I can see just from plotting various Binomial distributions where I keep p constant and increase n, that Binomial will eventually converge to a Poisson. That fits with the derivation where n approaches infinity, but I don't see why p has to be very small? What is the intuition behind p approaching 0?","I am not very well versed in statistics so any clarification would be appreciated. I understand the mathematical derivation of Poisson from Binomial. I can see just from plotting various Binomial distributions where I keep p constant and increase n, that Binomial will eventually converge to a Poisson. That fits with the derivation where n approaches infinity, but I don't see why p has to be very small? What is the intuition behind p approaching 0?",,"['statistics', 'probability-distributions']"
77,Probability mass function [duplicate],Probability mass function [duplicate],,"This question already has answers here : Probability density function vs. probability mass function (4 answers) Closed 2 years ago . Why is the probability function of a discrete random variable called a probability ""mass"" function? What does the word ""mass"" mean here?","This question already has answers here : Probability density function vs. probability mass function (4 answers) Closed 2 years ago . Why is the probability function of a discrete random variable called a probability ""mass"" function? What does the word ""mass"" mean here?",,"['statistics', 'probability-distributions']"
78,How to combine covariance matrices?,How to combine covariance matrices?,,"I have a data set of points in three dimensions. I'm calculating the barycenter (mean) and $3\times3$ covariance matrix from this data set. I store the average, the $3\times3$ matrix (where really only 6 elements are unique) and the number of points that went into this calculation. Let's call this a ""measure."" Now, I do the same for a second set of points. After doing this, I want to combine the two ""measures"" into one measure that's as close as possible to what I would get if I were to calculate one big ""measure"" based on the union of all the data points. What's the right (or least wrong) way of doing this? I know how to accurately update the mean by calculating a weighted average based on the number of points in each of the measures, but it feels wrong to do the same thing with the covariance matrix.","I have a data set of points in three dimensions. I'm calculating the barycenter (mean) and $3\times3$ covariance matrix from this data set. I store the average, the $3\times3$ matrix (where really only 6 elements are unique) and the number of points that went into this calculation. Let's call this a ""measure."" Now, I do the same for a second set of points. After doing this, I want to combine the two ""measures"" into one measure that's as close as possible to what I would get if I were to calculate one big ""measure"" based on the union of all the data points. What's the right (or least wrong) way of doing this? I know how to accurately update the mean by calculating a weighted average based on the number of points in each of the measures, but it feels wrong to do the same thing with the covariance matrix.",,"['matrices', 'statistics']"
79,Model for stock market changes over the day,Model for stock market changes over the day,,"A common model for stock returns is as follows: the number of trades $N$ of stock XXX in a given day has a Poisson distribution with parameter $\lambda$. At each trade, say the $i$’th trade, the change in the price of the stock is $X_i$ and has a normal distribution with mean $0$ and variance $\sigma^2$ , say and these changes are independent of one another and independent of $N$. Find the moment generating function of the total change in stock price over the day. Is this a distribution that you recognise? What is its mean and variance? My textbook is quite terse and actually does not have any detailed examples on deriving mgf's, let along (apparently) messy ones like a huge sum of poissons and normals. How would I approach this question?","A common model for stock returns is as follows: the number of trades $N$ of stock XXX in a given day has a Poisson distribution with parameter $\lambda$. At each trade, say the $i$’th trade, the change in the price of the stock is $X_i$ and has a normal distribution with mean $0$ and variance $\sigma^2$ , say and these changes are independent of one another and independent of $N$. Find the moment generating function of the total change in stock price over the day. Is this a distribution that you recognise? What is its mean and variance? My textbook is quite terse and actually does not have any detailed examples on deriving mgf's, let along (apparently) messy ones like a huge sum of poissons and normals. How would I approach this question?",,"['probability', 'statistics']"
80,"Interpreting $\mathrm{Var}(\overline{X}) = \mathrm{Cov}(X_i, \overline{X})$",Interpreting,"\mathrm{Var}(\overline{X}) = \mathrm{Cov}(X_i, \overline{X})","Let $X_i$ be pairwise-uncorrelated random variables, $\forall\,i \in \mathbf{n} \equiv \{0,\dots,n-1\}$, with identical expectation value $\mathbb{E}(X_i)=\mu$, and identical variance $\mathrm{Var}(X_i)=\sigma^2$.  Also, let $\overline{X}$ be their average, $\frac{1}{n}\sum_{i\in \mathbf{n}} X_i$. Then, as shown below, $$ \mathrm{Var}(\overline{X}) = \mathrm{Cov}(X_i, \overline{X}) \tag{1} $$ What seems uncanny to me about this equality is that each side ""arrives"" at its value, $\sigma^2/n$, by what look to me like entirely unrelated paths! On the LHS, this value comes from $$\mathrm{Var}(\overline{X})=\mathrm{Var}\left( \frac{1}{n}\sum_{i\in \mathbf{n}} X_i \right)=\frac{1}{n^2}\sum_{i\in \mathbf{n}}\mathrm{Var}(X_i)=\frac{1}{n^2}\sum_{i\in \mathbf{n}}\sigma^2=\frac{\sigma^2}{n}$$ IOW, each summand contributes equally to the final value. On the RHS, it comes from $$ \begin{align} \mathrm{Cov}(X_i, \overline{X})=\mathrm{Cov}\left(X_i, \frac{1}{n}\sum_{j\in \mathbf{n}} X_j\right) & = \frac{1}{n} \sum_{j\in \mathbf{n}} \mathrm{Cov}(X_i, X_j) \\ & = \frac{1}{n}\left( \mathrm{Var}(X_i) + \sum_{j\in \mathbf{n}\backslash\{i\}} \mathrm{Cov}(X_i, X_j) \right) \\ & = \frac{1}{n} ( \sigma^2 + 0 ) \\ & = \frac{\sigma^2}{n} \\ \end{align} $$ In this case, only the summand for $j = i$ contributes to the final value; the remaining ones are zero, by assumption. I'm missing an interpretation of the covariance that would help me decide what to make of $(1)$: i.e. is it remarkable? is it uncanny? is it fortuitous? is it trivial?....  Is there an interpretation of the covariance that will put $(1)$ in the right perspective? PS: I know, of course, that the covariance of two random variables $X$ and $Y$ is the difference between the expected value of their product and the product of their expected values.  Alternatively, it is the expected value of the product of the ""errors"", $(X - \mathbb{E}(X))(Y - \mathbb{E}(Y))$.  But neither interpretation tells me what to make of $(1)$ above. EDIT: If I understand Henry's answer correctly, one can cast each side so that they have a similar-looking form, namely, for the LHS: $$ \begin{align} \mathrm{Var}(\overline{X}) = \mathrm{Var}\left(\sum_{j\in\mathbf{n}}\frac{X_j}{n}\right)  &= \sum_{j\in\mathbf{n}} \sum_{k\in\mathbf{n}}\mathrm{Cov}\left(\frac{X_j}{n}, \frac{X_k}{n}\right) \\ &= \sum_{j\in\mathbf{n}} \mathrm{Var}\left(\frac{X_j}{n}\right) + \sum_{j\in\mathbf{n}}\sum_{k\in\mathbf{n}\backslash\{j\}}\mathrm{Cov}\left(\frac{X_j}{n}, \frac{X_k}{n}\right), \tag{2} \end{align} $$ and on the RHS (using the trick of expressing $X_i$ as $\sum_{k\in\mathbf{n}}X_i/n$): $$ \begin{align} \mathrm{Cov}(X_i, \overline{X}) = \mathrm{Cov}(\overline{X}, X_i) &= \mathrm{Cov}\left( \sum_{j\in\mathbf{n}}\frac{X_j}{n} , \sum_{k\in\mathbf{n}} \frac{X_i}{n}\right)\\ &= \sum_{j\in\mathbf{n}} \sum_{k\in\mathbf{n}}\mathrm{Cov}\left(\frac{X_j}{n}, \frac{X_i}{n}\right) \\ &= \sum_{k\in\mathbf{n}}\mathrm{Var}\left(\frac{X_i}{n}\right) + \sum_{j\in\mathbf{n}\backslash\{i\}} \sum_{k\in\mathbf{n}}\mathrm{Cov}\left(\frac{X_j}{n}, \frac{X_i}{n}\right) \tag{3}\\ \end{align} $$ Now each side consists indeed of a sum of $n$ terms with value $\sigma^2/n^2$ plus a sum of $n(n-1)$ terms with value $0$. But I think this maneuver just ""smears out"" the difference I originally pointed out, and makes it harder to notice.  If one pays attention to the indices in each of the final expressions in $(2)$ and $(3)$, one can see that they are semantically different after all. Then again, at heart, what this manipulation boils down to is to re-express $(1)$ as $$ \mathrm{Cov}(\overline{X}, \overline{X}) = \mathrm{Cov}(\overline{X}, X_i) \tag{$1^\prime$} $$ or even as $$ \mathrm{Cov}\left(\sum_{k\in\mathbf{n}}X_k, \sum_{k\in\mathbf{n}}X_k\right) = \mathrm{Cov}\left(\sum_{k\in\mathbf{n}}X_k, \sum_{k\in\mathbf{n}}X_i\right) \tag{$1^{\prime\prime}$}, $$ which, I admit, does make the equality look a little less uncanny.","Let $X_i$ be pairwise-uncorrelated random variables, $\forall\,i \in \mathbf{n} \equiv \{0,\dots,n-1\}$, with identical expectation value $\mathbb{E}(X_i)=\mu$, and identical variance $\mathrm{Var}(X_i)=\sigma^2$.  Also, let $\overline{X}$ be their average, $\frac{1}{n}\sum_{i\in \mathbf{n}} X_i$. Then, as shown below, $$ \mathrm{Var}(\overline{X}) = \mathrm{Cov}(X_i, \overline{X}) \tag{1} $$ What seems uncanny to me about this equality is that each side ""arrives"" at its value, $\sigma^2/n$, by what look to me like entirely unrelated paths! On the LHS, this value comes from $$\mathrm{Var}(\overline{X})=\mathrm{Var}\left( \frac{1}{n}\sum_{i\in \mathbf{n}} X_i \right)=\frac{1}{n^2}\sum_{i\in \mathbf{n}}\mathrm{Var}(X_i)=\frac{1}{n^2}\sum_{i\in \mathbf{n}}\sigma^2=\frac{\sigma^2}{n}$$ IOW, each summand contributes equally to the final value. On the RHS, it comes from $$ \begin{align} \mathrm{Cov}(X_i, \overline{X})=\mathrm{Cov}\left(X_i, \frac{1}{n}\sum_{j\in \mathbf{n}} X_j\right) & = \frac{1}{n} \sum_{j\in \mathbf{n}} \mathrm{Cov}(X_i, X_j) \\ & = \frac{1}{n}\left( \mathrm{Var}(X_i) + \sum_{j\in \mathbf{n}\backslash\{i\}} \mathrm{Cov}(X_i, X_j) \right) \\ & = \frac{1}{n} ( \sigma^2 + 0 ) \\ & = \frac{\sigma^2}{n} \\ \end{align} $$ In this case, only the summand for $j = i$ contributes to the final value; the remaining ones are zero, by assumption. I'm missing an interpretation of the covariance that would help me decide what to make of $(1)$: i.e. is it remarkable? is it uncanny? is it fortuitous? is it trivial?....  Is there an interpretation of the covariance that will put $(1)$ in the right perspective? PS: I know, of course, that the covariance of two random variables $X$ and $Y$ is the difference between the expected value of their product and the product of their expected values.  Alternatively, it is the expected value of the product of the ""errors"", $(X - \mathbb{E}(X))(Y - \mathbb{E}(Y))$.  But neither interpretation tells me what to make of $(1)$ above. EDIT: If I understand Henry's answer correctly, one can cast each side so that they have a similar-looking form, namely, for the LHS: $$ \begin{align} \mathrm{Var}(\overline{X}) = \mathrm{Var}\left(\sum_{j\in\mathbf{n}}\frac{X_j}{n}\right)  &= \sum_{j\in\mathbf{n}} \sum_{k\in\mathbf{n}}\mathrm{Cov}\left(\frac{X_j}{n}, \frac{X_k}{n}\right) \\ &= \sum_{j\in\mathbf{n}} \mathrm{Var}\left(\frac{X_j}{n}\right) + \sum_{j\in\mathbf{n}}\sum_{k\in\mathbf{n}\backslash\{j\}}\mathrm{Cov}\left(\frac{X_j}{n}, \frac{X_k}{n}\right), \tag{2} \end{align} $$ and on the RHS (using the trick of expressing $X_i$ as $\sum_{k\in\mathbf{n}}X_i/n$): $$ \begin{align} \mathrm{Cov}(X_i, \overline{X}) = \mathrm{Cov}(\overline{X}, X_i) &= \mathrm{Cov}\left( \sum_{j\in\mathbf{n}}\frac{X_j}{n} , \sum_{k\in\mathbf{n}} \frac{X_i}{n}\right)\\ &= \sum_{j\in\mathbf{n}} \sum_{k\in\mathbf{n}}\mathrm{Cov}\left(\frac{X_j}{n}, \frac{X_i}{n}\right) \\ &= \sum_{k\in\mathbf{n}}\mathrm{Var}\left(\frac{X_i}{n}\right) + \sum_{j\in\mathbf{n}\backslash\{i\}} \sum_{k\in\mathbf{n}}\mathrm{Cov}\left(\frac{X_j}{n}, \frac{X_i}{n}\right) \tag{3}\\ \end{align} $$ Now each side consists indeed of a sum of $n$ terms with value $\sigma^2/n^2$ plus a sum of $n(n-1)$ terms with value $0$. But I think this maneuver just ""smears out"" the difference I originally pointed out, and makes it harder to notice.  If one pays attention to the indices in each of the final expressions in $(2)$ and $(3)$, one can see that they are semantically different after all. Then again, at heart, what this manipulation boils down to is to re-express $(1)$ as $$ \mathrm{Cov}(\overline{X}, \overline{X}) = \mathrm{Cov}(\overline{X}, X_i) \tag{$1^\prime$} $$ or even as $$ \mathrm{Cov}\left(\sum_{k\in\mathbf{n}}X_k, \sum_{k\in\mathbf{n}}X_k\right) = \mathrm{Cov}\left(\sum_{k\in\mathbf{n}}X_k, \sum_{k\in\mathbf{n}}X_i\right) \tag{$1^{\prime\prime}$}, $$ which, I admit, does make the equality look a little less uncanny.",,"['linear-algebra', 'probability', 'statistics']"
81,Simple random sample without replacement,Simple random sample without replacement,,"I have a data file from which I wish to create a uniformly distributed simple random sample, without replacement. Will the following algorithm give me an unbiased result? 1 Set T = total number of records in the file. 2 Set S = number of samples required. 3 For each record in the file, in order:   i    Set X = a random uniformly distributed number between 0 and 1.   ii.  If X < S/T, select the record and decrement S.   iii. Decrement T.","I have a data file from which I wish to create a uniformly distributed simple random sample, without replacement. Will the following algorithm give me an unbiased result? 1 Set T = total number of records in the file. 2 Set S = number of samples required. 3 For each record in the file, in order:   i    Set X = a random uniformly distributed number between 0 and 1.   ii.  If X < S/T, select the record and decrement S.   iii. Decrement T.",,"['statistics', 'algorithms', 'random']"
82,Chi-Square goodness-of-fit test on sample space or quantiles?,Chi-Square goodness-of-fit test on sample space or quantiles?,,"I think there are two ways to perform the chi-Square goodness-of-fit test: Divide the sample space into bins of equal size and see how many observed values fall in each bin. where the expected per bin depends on the fit. Divide the cdf of the fit into B bins of equal size (e.g., five bins of size .2 each, or 8 bins of width .125 each) and see where each observed value would belong into. -> count observed values per bin of size  > calculate the chi square statistic ( where the expected nr per bin is n/B or observations/bins , since the quantiles are distributed uniformly) Is 2. a valid approach? And is there anything noteworthy about the second approach?","I think there are two ways to perform the chi-Square goodness-of-fit test: Divide the sample space into bins of equal size and see how many observed values fall in each bin. where the expected per bin depends on the fit. Divide the cdf of the fit into B bins of equal size (e.g., five bins of size .2 each, or 8 bins of width .125 each) and see where each observed value would belong into. -> count observed values per bin of size  > calculate the chi square statistic ( where the expected nr per bin is n/B or observations/bins , since the quantiles are distributed uniformly) Is 2. a valid approach? And is there anything noteworthy about the second approach?",,['statistics']
83,biased coin tossing where each pair of heads is separated by at least l tails.,biased coin tossing where each pair of heads is separated by at least l tails.,,"Suppose that I have a biased coin where $\Pr[head] = p$ is very small. Let's say I tossed this coin $n$ times and I saw $h$ heads. Then what is the probability that each pair of heads is separated by at least $\ell$ tails? For example, let's say $(n, h, \ell) = (10, 2, 5)$. 'Yes': T H T T T T T T H T There are two heads at location 1 and 9, but they are separated by 6 tails. 'No': T T T T T H T H T T There are two heads at location 6 and 8, but they are separated by only one tail. One possible approach is summing up all the probabilities of 'yes' events. Is there any closed form for this probability?","Suppose that I have a biased coin where $\Pr[head] = p$ is very small. Let's say I tossed this coin $n$ times and I saw $h$ heads. Then what is the probability that each pair of heads is separated by at least $\ell$ tails? For example, let's say $(n, h, \ell) = (10, 2, 5)$. 'Yes': T H T T T T T T H T There are two heads at location 1 and 9, but they are separated by 6 tails. 'No': T T T T T H T H T T There are two heads at location 6 and 8, but they are separated by only one tail. One possible approach is summing up all the probabilities of 'yes' events. Is there any closed form for this probability?",,"['probability', 'statistics']"
84,Show that $\hat\theta=\frac{2 \bar Y- 1}{1- \bar Y}$ is a consistent estimator for $\theta$,Show that  is a consistent estimator for,\hat\theta=\frac{2 \bar Y- 1}{1- \bar Y} \theta,"Let $Y_1,Y_2,...,Y_n$ denote a random sample from the probability density function $$f(y| \theta)= \begin{cases} ( \theta +1)y^{ \theta}, & 0 < y<1 , \theta> -1 \\ 0, & \mbox{elsewhere},   \end{cases}$$ Find an Estimator for $\theta$ by using the method of moments and show that it is consistent. I have found the estimator but unsure how to show that it is consistent. $\mathbb{E}Y=\frac{\theta +1}{\theta +2}$ and $m_1'(u)= \frac{1}{n} \sum_{i=1}^{n}Y_i= \bar Y$ Now,  $$\mathbb{E}Y=\frac{ \theta +1}{ \theta +2}=m_1'(u)= \frac{1}{n} \sum_{i=1}^{n}Y_i= \bar Y$$ So $$\bar{Y}=\frac{ \theta +1}{ \theta +2} \to \hat{\theta}=\frac{2 \bar Y- 1}{1- \bar Y} $$ Now I am unsure how to show that $\hat\theta=\frac{2 \bar Y- 1}{1- \bar Y}$ is a consistent estimator for $\theta$ Can someone please guide me?","Let $Y_1,Y_2,...,Y_n$ denote a random sample from the probability density function $$f(y| \theta)= \begin{cases} ( \theta +1)y^{ \theta}, & 0 < y<1 , \theta> -1 \\ 0, & \mbox{elsewhere},   \end{cases}$$ Find an Estimator for $\theta$ by using the method of moments and show that it is consistent. I have found the estimator but unsure how to show that it is consistent. $\mathbb{E}Y=\frac{\theta +1}{\theta +2}$ and $m_1'(u)= \frac{1}{n} \sum_{i=1}^{n}Y_i= \bar Y$ Now,  $$\mathbb{E}Y=\frac{ \theta +1}{ \theta +2}=m_1'(u)= \frac{1}{n} \sum_{i=1}^{n}Y_i= \bar Y$$ So $$\bar{Y}=\frac{ \theta +1}{ \theta +2} \to \hat{\theta}=\frac{2 \bar Y- 1}{1- \bar Y} $$ Now I am unsure how to show that $\hat\theta=\frac{2 \bar Y- 1}{1- \bar Y}$ is a consistent estimator for $\theta$ Can someone please guide me?",,['statistics']
85,"I don't think I'm doing this function mapping question correctly, could anyone offer advice?","I don't think I'm doing this function mapping question correctly, could anyone offer advice?",,"We were given the following question in class: Let A = {1, 2, 3, 4, 5} and B = {a, b, c, d, e, f}. How many functions  from A to B are there:  (a) which are a surjection?  (b) which are an injection  (c) which are a bijection,  (d) which have f(1) = a,  (e) for which ∃x ∈ A, f(x) = b,  (f) for which 1 and 5 have the same image,  (g) for which two elements of A have the image c, and three elements have the image e. I was just wondering if someone could give me a little advice with how I'm working through these, and some tips on how to go through the question. For (a) I treated it like a Stars and Bars question, where the size was 6 (size of B) and the amount of gaps was 5 (size of A) and you could have ones where certain ones in A didn't do anything, so the formula would be $\binom{5 + 6 - 1}{5 - 1}$. Is that right? For (b) I was confused with whether or not injection means ALL of the ones in the domain must match to unique ones in the codomain, or if for instance, one matching to one in the codomain counts as a separate one, such as f(1) = b, and f(1) = a count as two separate functions. How would I tackle this one? c) I figured 0, because $|B| > |A|$ d) I figured 1 was a mandatory option now, so that left us with 4 other numbers to match with (to 6 different letters). Considering that something else could still equal a, just 1 couldn't, I considered it another Stars and Bars question and said $\binom{4 + 6 - 1}{4 - 1}$ e) I know this means that b will always have a value in the domain linking to it, but I'm not sure how to tackle it. f) and g) I'm not sure how to tackle either. For the ones I think I did well at solving, the numbers seem really low for my understanding of injective, surjective and bijective functions. Could anyone offer some insight/help into how I'd go about solving these? Many thanks, just looking for some help.","We were given the following question in class: Let A = {1, 2, 3, 4, 5} and B = {a, b, c, d, e, f}. How many functions  from A to B are there:  (a) which are a surjection?  (b) which are an injection  (c) which are a bijection,  (d) which have f(1) = a,  (e) for which ∃x ∈ A, f(x) = b,  (f) for which 1 and 5 have the same image,  (g) for which two elements of A have the image c, and three elements have the image e. I was just wondering if someone could give me a little advice with how I'm working through these, and some tips on how to go through the question. For (a) I treated it like a Stars and Bars question, where the size was 6 (size of B) and the amount of gaps was 5 (size of A) and you could have ones where certain ones in A didn't do anything, so the formula would be $\binom{5 + 6 - 1}{5 - 1}$. Is that right? For (b) I was confused with whether or not injection means ALL of the ones in the domain must match to unique ones in the codomain, or if for instance, one matching to one in the codomain counts as a separate one, such as f(1) = b, and f(1) = a count as two separate functions. How would I tackle this one? c) I figured 0, because $|B| > |A|$ d) I figured 1 was a mandatory option now, so that left us with 4 other numbers to match with (to 6 different letters). Considering that something else could still equal a, just 1 couldn't, I considered it another Stars and Bars question and said $\binom{4 + 6 - 1}{4 - 1}$ e) I know this means that b will always have a value in the domain linking to it, but I'm not sure how to tackle it. f) and g) I'm not sure how to tackle either. For the ones I think I did well at solving, the numbers seem really low for my understanding of injective, surjective and bijective functions. Could anyone offer some insight/help into how I'd go about solving these? Many thanks, just looking for some help.",,"['probability', 'statistics', 'discrete-mathematics', 'permutations']"
86,Why is there a linear relationship between the quantiles of a generic normal distribution and those of the standard normal distribution?,Why is there a linear relationship between the quantiles of a generic normal distribution and those of the standard normal distribution?,,"I don't understand why a quantile-quantile plot is linear. That is, if you plot quantiles of the normal distribution with mean $\mu$ and standard deviation $\sigma$ (on the vertical axis) against quantiles of the standard normal distribution (on the horizontal axis), you get a line. Can someone gently explain the linear relationship? What is the slope of that line?","I don't understand why a quantile-quantile plot is linear. That is, if you plot quantiles of the normal distribution with mean $\mu$ and standard deviation $\sigma$ (on the vertical axis) against quantiles of the standard normal distribution (on the horizontal axis), you get a line. Can someone gently explain the linear relationship? What is the slope of that line?",,['statistics']
87,Is this proof correct? Textbook has no solution.,Is this proof correct? Textbook has no solution.,,"Most of the problems in my textbook have numeric solutions in the back of the book except the proofs. Is this proof correct? Prove that if $A \cup B$ and $A \cap B$ are independent events, then either $P(A \cap B)=0$ or $P(A \cup B) = 0)$. $P((A \cup B) \cap (A \cap B)) = P(A \cup B)P(A \cap B)$ (definition of independence) $P(A \cap B)=P(A \cup B)P(A \cap B)$ (properties of sets and intersections) Either $P(AB)=0$ or $P(A\cup B)=1$. In the first case we already proved the proposition. In the second case $P(A\cup B)=1\implies P(\bar{A} \cap \bar{B})=0$. $\square$","Most of the problems in my textbook have numeric solutions in the back of the book except the proofs. Is this proof correct? Prove that if $A \cup B$ and $A \cap B$ are independent events, then either $P(A \cap B)=0$ or $P(A \cup B) = 0)$. $P((A \cup B) \cap (A \cap B)) = P(A \cup B)P(A \cap B)$ (definition of independence) $P(A \cap B)=P(A \cup B)P(A \cap B)$ (properties of sets and intersections) Either $P(AB)=0$ or $P(A\cup B)=1$. In the first case we already proved the proposition. In the second case $P(A\cup B)=1\implies P(\bar{A} \cap \bar{B})=0$. $\square$",,"['probability', 'statistics']"
88,Can anyone shed some light on the below statistical theory questions?,Can anyone shed some light on the below statistical theory questions?,,"Can anyone shed some light on the below: Consider a set with $N$ distinct members, and a function $f$ defined on $\mathbb Q$ that takes the values $0$, $1$ such that $\frac1N\sum_{x\in\mathbb Q} f(x) = p$. For a subset $S$ of $\mathbb Q$ of size $n$, define the sample proportion $$p = p(S) = \frac1N\sum_{x\in S} f(x)$$ If each subset of size $n$ is chosen with equal probability, calculate the expectation and standard deviation of the random variable $p$. Let $X\sim \mathcal N(0, 1)$ be a normally distributed random variable with mean 0 and variance 1. Suppose that $x \in \mathbb R, x > 0$. Find upper and lower bounds for the conditional expectation $E(X \mid X >x)$ Now suppose that $X$ has a power law distribution, $P(X >x) = ax^{-b}$, for $x>x_0>0$, and some $a> 0, b> 1$. Calculate the conditional expectation $E(X\mid X>x), x >x_0$ Many thanks in advance.","Can anyone shed some light on the below: Consider a set with $N$ distinct members, and a function $f$ defined on $\mathbb Q$ that takes the values $0$, $1$ such that $\frac1N\sum_{x\in\mathbb Q} f(x) = p$. For a subset $S$ of $\mathbb Q$ of size $n$, define the sample proportion $$p = p(S) = \frac1N\sum_{x\in S} f(x)$$ If each subset of size $n$ is chosen with equal probability, calculate the expectation and standard deviation of the random variable $p$. Let $X\sim \mathcal N(0, 1)$ be a normally distributed random variable with mean 0 and variance 1. Suppose that $x \in \mathbb R, x > 0$. Find upper and lower bounds for the conditional expectation $E(X \mid X >x)$ Now suppose that $X$ has a power law distribution, $P(X >x) = ax^{-b}$, for $x>x_0>0$, and some $a> 0, b> 1$. Calculate the conditional expectation $E(X\mid X>x), x >x_0$ Many thanks in advance.",,['statistics']
89,Probability question involving a dice,Probability question involving a dice,,You roll a dice $6$ times. What is the probability of rolling at least one $5$ AND at least one $6$? The answer in the book is $1 - (5/6)^6 - (5/6)^6 + (4/6)^6$.  Would someone please explain why that is? $(1 - (5/6)^6 - (5/6)^6)$ : This is the probability of rolling a $5$ OR $6$ for six rolls of the dice. Correct? What is $(+ (4/6)^6)$? Isn't that the probability of not rolling a $5$ or $6$? Why do I need to add it.,You roll a dice $6$ times. What is the probability of rolling at least one $5$ AND at least one $6$? The answer in the book is $1 - (5/6)^6 - (5/6)^6 + (4/6)^6$.  Would someone please explain why that is? $(1 - (5/6)^6 - (5/6)^6)$ : This is the probability of rolling a $5$ OR $6$ for six rolls of the dice. Correct? What is $(+ (4/6)^6)$? Isn't that the probability of not rolling a $5$ or $6$? Why do I need to add it.,,['statistics']
90,Data Type Classification in Statistics,Data Type Classification in Statistics,,"It is my understanding that in statistics one has 4 basic data types: nominal, ordinal, ratio, and interval. I see cases where people refer to ""count data"" (which is a random variable whose range is the set of whole numbers, such as the number of accidents in a week or the number of passengers on a plane), which brings me to my question: is ""count data"" is really data . It seems to me that it is a statistic computed from nominal data for two reasons. First, it doesn't seem to fall into one of the four data type categories. Secondly, it is obtained not from a measurement or recording of single events but rather from an arithmetic operation (i.e. addition). So for example, the number of passengers in a plane is a statistic whch would be computed from the nominal data associated with each seat in the plane (""1"" = occupied, ""0"" = unoccupied). Matt","It is my understanding that in statistics one has 4 basic data types: nominal, ordinal, ratio, and interval. I see cases where people refer to ""count data"" (which is a random variable whose range is the set of whole numbers, such as the number of accidents in a week or the number of passengers on a plane), which brings me to my question: is ""count data"" is really data . It seems to me that it is a statistic computed from nominal data for two reasons. First, it doesn't seem to fall into one of the four data type categories. Secondly, it is obtained not from a measurement or recording of single events but rather from an arithmetic operation (i.e. addition). So for example, the number of passengers in a plane is a statistic whch would be computed from the nominal data associated with each seat in the plane (""1"" = occupied, ""0"" = unoccupied). Matt",,"['statistics', 'data-analysis']"
91,Why does this covariance matrix have additional symmetry along the anti-diagonals?,Why does this covariance matrix have additional symmetry along the anti-diagonals?,,"In my self study of a statistics book, I came across a page that has confused me somewhat. I am already familiar with covariance matricies, (or maybe not!), and the author's explanation leaves me a little confused. Here is the page in question: My question is simply, why is that bottom right entry into the covariance equal to 1, when it fact it seems to me that it should be $a^2 + \sigma_n^2$. So, I follow everything he is doing, but the bottom right entry to me, seems wrong. The bottom right entry is $var(z_2)$. Thus, by my estimates: $$ cov(z_2,z_2) = var(z_2) = \mathbb{E}(z_2^2) - (\mathbb{E}(z_2))^2 $$ Thus, (assuming noise is zero mean, but not that I think it makes a difference anyway): $$ \begin{align} var(z_2) &= \mathbb{E}( (az_1 + n)^2) - 0 \\ &= \mathbb{E}( a^2z_1^2 + 2az_1 + n^2) \\ &= a^2 + \sigma_n^2 \end{align} $$ (Sorry about the alignment I am not sure how to make the allignment of the equations nice). Anyway, to me that should be the answer to the bottom right entry of the covariance matrix. Am I missing something?","In my self study of a statistics book, I came across a page that has confused me somewhat. I am already familiar with covariance matricies, (or maybe not!), and the author's explanation leaves me a little confused. Here is the page in question: My question is simply, why is that bottom right entry into the covariance equal to 1, when it fact it seems to me that it should be $a^2 + \sigma_n^2$. So, I follow everything he is doing, but the bottom right entry to me, seems wrong. The bottom right entry is $var(z_2)$. Thus, by my estimates: $$ cov(z_2,z_2) = var(z_2) = \mathbb{E}(z_2^2) - (\mathbb{E}(z_2))^2 $$ Thus, (assuming noise is zero mean, but not that I think it makes a difference anyway): $$ \begin{align} var(z_2) &= \mathbb{E}( (az_1 + n)^2) - 0 \\ &= \mathbb{E}( a^2z_1^2 + 2az_1 + n^2) \\ &= a^2 + \sigma_n^2 \end{align} $$ (Sorry about the alignment I am not sure how to make the allignment of the equations nice). Anyway, to me that should be the answer to the bottom right entry of the covariance matrix. Am I missing something?",,"['matrices', 'statistics', 'random-variables']"
92,Difference between Chi-Square Test (goodness of fit) and binomial?,Difference between Chi-Square Test (goodness of fit) and binomial?,,"This is probably an unnecessary question, but how would I know given a problem when it's appropriate to use a chi-square test vs. binomial or normal distribution in a problem? Let's say that the example is dice and which numbers it lands on.","This is probably an unnecessary question, but how would I know given a problem when it's appropriate to use a chi-square test vs. binomial or normal distribution in a problem? Let's say that the example is dice and which numbers it lands on.",,"['probability', 'statistics', 'probability-distributions']"
93,Hypothesis testing for Variance - choosing a null hypothesis.,Hypothesis testing for Variance - choosing a null hypothesis.,,"A gun-like apparatus has recently been designed to replace needles in administering vaccines. The apparatus can be set to inject different amounts of the serum, but    because of random fluctuations the actual amount injected is normally distributed with a mean    equal to the setting and with an unknown variance $\sigma^2$. It has been decided that the apparatus    would be too dangerous to use if $σ$ exceeds $0.10$. If a random sample of $50$ injections resulted in a sample standard deviation of $0.08$, should use of the new apparatus be discontinued? Comment on the appropriate choice of a significance level    for this problem, as well as the appropriate choice of the null hypothesis I approached this question as follows: null hypothsis $H_0: \sigma \le 0.10 $ and alternate hypothesis $H_1: \sigma > 0.10 $. Then I used Chi square:  $\chi_0^2 = \frac{(n-1)(s^2)}{\sigma^2} = \frac{(49)(.0064)}{.01} = 31.36$. I calculated the probability that a Chi Square variable with $49$ degrees of freedom would have a $97.6513\%$ chance of being above $31.36$: $P\{\chi_{49}^2 > 31.36\} = .976513$. What exactly does this mean? Does it mean that if $\sigma$ was to equal $.10$, there would be a $97.6513\%$ of finding a sample of 50 that would give you a sample standard deviation of $.08$? Also, I'm having doubts that I used the correct null hypothesis since this question seems too obvious as it stands.","A gun-like apparatus has recently been designed to replace needles in administering vaccines. The apparatus can be set to inject different amounts of the serum, but    because of random fluctuations the actual amount injected is normally distributed with a mean    equal to the setting and with an unknown variance $\sigma^2$. It has been decided that the apparatus    would be too dangerous to use if $σ$ exceeds $0.10$. If a random sample of $50$ injections resulted in a sample standard deviation of $0.08$, should use of the new apparatus be discontinued? Comment on the appropriate choice of a significance level    for this problem, as well as the appropriate choice of the null hypothesis I approached this question as follows: null hypothsis $H_0: \sigma \le 0.10 $ and alternate hypothesis $H_1: \sigma > 0.10 $. Then I used Chi square:  $\chi_0^2 = \frac{(n-1)(s^2)}{\sigma^2} = \frac{(49)(.0064)}{.01} = 31.36$. I calculated the probability that a Chi Square variable with $49$ degrees of freedom would have a $97.6513\%$ chance of being above $31.36$: $P\{\chi_{49}^2 > 31.36\} = .976513$. What exactly does this mean? Does it mean that if $\sigma$ was to equal $.10$, there would be a $97.6513\%$ of finding a sample of 50 that would give you a sample standard deviation of $.08$? Also, I'm having doubts that I used the correct null hypothesis since this question seems too obvious as it stands.",,"['statistics', 'standard-deviation']"
94,Sample Range and order statistics?,Sample Range and order statistics?,,"Let a random sample of size $n$ from an exponential distribution $X_i \sim EXP(1)$. Give the pdf of (1) The sample range, $R = Y_n - Y_1$ (2) The first r order statistics The answers are supposed to be (1) $f_R(r) = (n-1)e^{-r}(1 - e^{-r})^{n-2}$ and (2) $g(y_1, \dots, y_r) = \frac{n}{(n-r)!}\exp\left ( -\sum_{i=1}^{r} y_i -(n-r)y_r\right)$ I have absolute no idea how they got -2 in the first answer and I don't know how in the second answer, they got a sum EDIT : I figured out the sum part. They basically just put everything together into the exponent EDIT#2 . The largest order statistic $Y_n$ is $n e^{-y_n}(1 - e^{y_n})^{n-1}$.","Let a random sample of size $n$ from an exponential distribution $X_i \sim EXP(1)$. Give the pdf of (1) The sample range, $R = Y_n - Y_1$ (2) The first r order statistics The answers are supposed to be (1) $f_R(r) = (n-1)e^{-r}(1 - e^{-r})^{n-2}$ and (2) $g(y_1, \dots, y_r) = \frac{n}{(n-r)!}\exp\left ( -\sum_{i=1}^{r} y_i -(n-r)y_r\right)$ I have absolute no idea how they got -2 in the first answer and I don't know how in the second answer, they got a sum EDIT : I figured out the sum part. They basically just put everything together into the exponent EDIT#2 . The largest order statistic $Y_n$ is $n e^{-y_n}(1 - e^{y_n})^{n-1}$.",,"['probability', 'statistics', 'probability-distributions', 'exponential-distribution']"
95,What sample size do I need to justify my suspicions?,What sample size do I need to justify my suspicions?,,"I  have been told that an event occurs about once in 50 times. In my experience, it is more like once in 40 or 45, which would not be insignificant (if correct). However because this event does not happen very often I cannot be sure. What sample size would be sufficient for me to state that it's once in 40 , ofr example ?","I  have been told that an event occurs about once in 50 times. In my experience, it is more like once in 40 or 45, which would not be insignificant (if correct). However because this event does not happen very often I cannot be sure. What sample size would be sufficient for me to state that it's once in 40 , ofr example ?",,['statistics']
96,Rao-Cramer lower bound for Rician distribution,Rao-Cramer lower bound for Rician distribution,,"I derived ML estimator for Rician distributed data and I am trying to show Rao-Cramer lower bound of $\hat{A}$ estimator variance. $$f(x_k|A,\sigma) = \frac{x_k}{\sigma^2}\exp\left(-\frac{x^2_k+A^2}{2\sigma^2}\right)I_0\left(\frac{xA}{\sigma^2}\right) \tag{Rician distribution}$$ where $I_n(x) = \left( {1 \over 2}x \right )^{n} \sum_{k=0}^{\infty} \frac{\left( {1 \over 4}x^2 \right )^k}{k! (n+k)!}$ is modified Bessel function of the first kind of $n$-th order ($n \in N$) The ML estimator, that I derived: $$\hat{A} = \frac{1}{N} \sum_{k=1}^{N} x_k  \frac{  I_1 \left( \frac{x_k A}{\sigma^2} \right )}{   I_0 \left( \frac{x_k A}{\sigma^2} \right )}$$ Unfortunately, variance derivation looks like challenging problem. Anyone could suggest a trial? $$\operatorname{Var}_\hat{A} = \frac{1}{N^2}E_{\hat{A}} \left( \sum_{k,l=1}^N\left( x_k-E_{\hat{A}}\left(x_k\frac{I_1}{I_0}\right) \right) \left( x_l-E_{\hat{A}}\left(x_l\frac{I_1}{I_0}\right) \right) \right)$$ where $I_0, I_1$ is of course $I_0 \left( \frac{x_k A }{\sigma^2} \right )$, $I_1 \left( \frac{x_k A }{\sigma^2} \right )$, respectively.","I derived ML estimator for Rician distributed data and I am trying to show Rao-Cramer lower bound of $\hat{A}$ estimator variance. $$f(x_k|A,\sigma) = \frac{x_k}{\sigma^2}\exp\left(-\frac{x^2_k+A^2}{2\sigma^2}\right)I_0\left(\frac{xA}{\sigma^2}\right) \tag{Rician distribution}$$ where $I_n(x) = \left( {1 \over 2}x \right )^{n} \sum_{k=0}^{\infty} \frac{\left( {1 \over 4}x^2 \right )^k}{k! (n+k)!}$ is modified Bessel function of the first kind of $n$-th order ($n \in N$) The ML estimator, that I derived: $$\hat{A} = \frac{1}{N} \sum_{k=1}^{N} x_k  \frac{  I_1 \left( \frac{x_k A}{\sigma^2} \right )}{   I_0 \left( \frac{x_k A}{\sigma^2} \right )}$$ Unfortunately, variance derivation looks like challenging problem. Anyone could suggest a trial? $$\operatorname{Var}_\hat{A} = \frac{1}{N^2}E_{\hat{A}} \left( \sum_{k,l=1}^N\left( x_k-E_{\hat{A}}\left(x_k\frac{I_1}{I_0}\right) \right) \left( x_l-E_{\hat{A}}\left(x_l\frac{I_1}{I_0}\right) \right) \right)$$ where $I_0, I_1$ is of course $I_0 \left( \frac{x_k A }{\sigma^2} \right )$, $I_1 \left( \frac{x_k A }{\sigma^2} \right )$, respectively.",,"['statistics', 'information-geometry']"
97,Introduction to Mathematical Statistics,Introduction to Mathematical Statistics,,"Let $X_1$, $X_2$, $X_3$, $X_4$ have the joint pdf $f(X_1,X_2,X_3,X_4) = 24$ , $0 < X_l < X_2 < X_3 < X_4 < 1$ , $0$ elsewhere. Find the joint pdf of $Y_1 = X_1/X_2$, $Y_2 = X_2/X_3$ , $Y_3 = X_3/X_4$, $Y_4 = X_4$ and show that they are mutually independent. I know they joint pdf is $24y_2(y_3^2)(y_4^2)$ but how do I show they are mutually independent?","Let $X_1$, $X_2$, $X_3$, $X_4$ have the joint pdf $f(X_1,X_2,X_3,X_4) = 24$ , $0 < X_l < X_2 < X_3 < X_4 < 1$ , $0$ elsewhere. Find the joint pdf of $Y_1 = X_1/X_2$, $Y_2 = X_2/X_3$ , $Y_3 = X_3/X_4$, $Y_4 = X_4$ and show that they are mutually independent. I know they joint pdf is $24y_2(y_3^2)(y_4^2)$ but how do I show they are mutually independent?",,['statistics']
98,Inverse of itinerary function,Inverse of itinerary function,,Let $S^{-1}:\Sigma \to \Lambda$ be inverse of itinerary function. I showed that $S$ is continuous and bijective. How to show that $S^{-1}$ is continuous?,Let $S^{-1}:\Sigma \to \Lambda$ be inverse of itinerary function. I showed that $S$ is continuous and bijective. How to show that $S^{-1}$ is continuous?,,"['statistics', 'dynamical-systems', 'mathematical-modeling']"
99,Dependent chances using Bayes' rule,Dependent chances using Bayes' rule,,"The chance that somebody get's mad cow disease is 0.01 (1%). If someone visits the USA this chance becomes 0.05 (5%). The chance that somebody goes to the USA is 0.01 (1%). If someone goes to the USA, he'll most likely buy the flag as a souvenir, the chance that somebody does this is 0.7 (70%). Because the flag is well known, people who never have been to the USA have a chance of 0.3 (30%) to have the flag. Now given that somebody has the mad cow disease and he has the flag of the USA, what are the chances he has visited the USA? Thus: P(USA) = 0.01 P(MCD) = 0.01 P(MCD|USA) = 0.05 P(flag|!USA) = 0.3 P(flag|USA) = 0.7 Following bayes' rule we can calculate the chance that somebody has been to america given the knowledge this person has MCD: P(USA|MCD) = P(MCD|USA)*P(USA)/P(MCD) = 0.05 *0.01 / 0.01 = 0.05. Now the problem is how do we calculate the chance that someone has visited the USA given he has the american flag, and after that given somebody has and mad cow disease and the american flag the chance he has been to america. How does one does this? Cheers!","The chance that somebody get's mad cow disease is 0.01 (1%). If someone visits the USA this chance becomes 0.05 (5%). The chance that somebody goes to the USA is 0.01 (1%). If someone goes to the USA, he'll most likely buy the flag as a souvenir, the chance that somebody does this is 0.7 (70%). Because the flag is well known, people who never have been to the USA have a chance of 0.3 (30%) to have the flag. Now given that somebody has the mad cow disease and he has the flag of the USA, what are the chances he has visited the USA? Thus: P(USA) = 0.01 P(MCD) = 0.01 P(MCD|USA) = 0.05 P(flag|!USA) = 0.3 P(flag|USA) = 0.7 Following bayes' rule we can calculate the chance that somebody has been to america given the knowledge this person has MCD: P(USA|MCD) = P(MCD|USA)*P(USA)/P(MCD) = 0.05 *0.01 / 0.01 = 0.05. Now the problem is how do we calculate the chance that someone has visited the USA given he has the american flag, and after that given somebody has and mad cow disease and the american flag the chance he has been to america. How does one does this? Cheers!",,"['probability', 'statistics']"
