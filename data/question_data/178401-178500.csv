,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Determine if $\lim_{(x,y)\to(0,0)} \frac{x^3y^4}{(x^4 + y^2)^2}$ exist",Determine if  exist,"\lim_{(x,y)\to(0,0)} \frac{x^3y^4}{(x^4 + y^2)^2}","What I tried: Let $$\ f(x,y) = \frac{x^3y^4}{(x^4 + y^2)^2}$$ For points of the form$\ (x,0)$ then $\ f(x,0)=0$, similarly, for$\ (0,y)$ then $\ f(0,y)=0$, so lets suppose that: $$\lim_{(x,y)\to(0,0)} \frac{x^3y^4}{(x^4 + y^2)^2} =0$$ So, for$\ ε>0$ if$\ δ=ε$ we have to prove that: $$ |\frac{x^3y^4}{(x^4 + y^2)^2} -0|<ε$$ But I'm having a hard time trying to prove the last part, I tried: $$ |\frac{x^3y^4}{(x^4 + y^2)^2} -0|=|\frac{x^3y^4}{(x^4 + y^2)^2}| ≤ |\frac{(x^3y^4)(x^4 + y^2)^2}{(x^4 + y^2)^2}|=|(x^3y^4)|$$","What I tried: Let $$\ f(x,y) = \frac{x^3y^4}{(x^4 + y^2)^2}$$ For points of the form$\ (x,0)$ then $\ f(x,0)=0$, similarly, for$\ (0,y)$ then $\ f(0,y)=0$, so lets suppose that: $$\lim_{(x,y)\to(0,0)} \frac{x^3y^4}{(x^4 + y^2)^2} =0$$ So, for$\ ε>0$ if$\ δ=ε$ we have to prove that: $$ |\frac{x^3y^4}{(x^4 + y^2)^2} -0|<ε$$ But I'm having a hard time trying to prove the last part, I tried: $$ |\frac{x^3y^4}{(x^4 + y^2)^2} -0|=|\frac{x^3y^4}{(x^4 + y^2)^2}| ≤ |\frac{(x^3y^4)(x^4 + y^2)^2}{(x^4 + y^2)^2}|=|(x^3y^4)|$$",,['multivariable-calculus']
1,Polar Coordinates as a Definitive Technique for Evaluating Limits,Polar Coordinates as a Definitive Technique for Evaluating Limits,,"A lot of questions say ""use polar coordinates"" to calculate limits when they approach $0$. But is using polar coordinates the best way to evaluate limits, moreover, prove that they exist? Do they account for every single possible direction to approach a limit, for example, along a parabola. Specifically, if I were to show that  $$\lim_{(x,y)\rightarrow (0,0)} f(x,y)=L$$ using polar coordinates, is that enough to asser that the limit is indeed, $L$. ?","A lot of questions say ""use polar coordinates"" to calculate limits when they approach $0$. But is using polar coordinates the best way to evaluate limits, moreover, prove that they exist? Do they account for every single possible direction to approach a limit, for example, along a parabola. Specifically, if I were to show that  $$\lim_{(x,y)\rightarrow (0,0)} f(x,y)=L$$ using polar coordinates, is that enough to asser that the limit is indeed, $L$. ?",,['multivariable-calculus']
2,Is $\frac{\nabla{u(\mathbf{x})}}{(\nabla{u(\mathbf{x})})\cdot\mathbf{x}}$ the gradient of any function?,Is  the gradient of any function?,\frac{\nabla{u(\mathbf{x})}}{(\nabla{u(\mathbf{x})})\cdot\mathbf{x}},"Suppose $$\mathbf{p}(\mathbf{x})=\frac{\nabla{u(\mathbf{x})}}{(\nabla{u(\mathbf{x})})\cdot\mathbf{x}},$$ where $\mathbf{x} \in \mathbb{R}^n$, $\mathbf{p}:  \mathbb{R}^n \to \mathbb{R}^n$ and $u:\mathbb{R}^n \to \mathbb{R}$. Assume $\mathbf{p}$ and $u$ are convex and defined and differentiable for all $\mathbb{R}^n > \mathbf{0}$. I would like to show that $\mathbf{p}(\mathbf{x})$ is the gradient of some function $B: \mathbb{R}^n \to \mathbb{R}$, although I don't necessarily need to know the form of the function. What I really need to do is calculate $B(\mathbf{x_1})-B(\mathbf{x_0})$ for arbitrary values of $\mathbf{x_1}$ and $\mathbf{x_0}$. I can already calculate $\mathbf{p}(\mathbf{x})$ as needed, and if I can show that it is a valid gradient, I think the gradient theorem says that $B(\mathbf{x_1})-B(\mathbf{x_0})$ = $\int^\mathbf{x_1}_\mathbf{x_0}{\mathbf{p}(\mathbf{x}) \cdot d\mathbf{x}}$, which I can calculate numerically. However, if $\mathbf{p}(\mathbf{x})$ is not a valid gradient of any function, then the line integral is path-dependent and $B$ is ill-defined. So my question is, is it possible to show that $\mathbf{p}(\mathbf{x})$ as defined here is a valid gradient? Or are there conditions that I could apply to guarantee that it is? I've spent a couple of days trying out variations on the chain rule, substituting terms, etc., but haven't made much headway.","Suppose $$\mathbf{p}(\mathbf{x})=\frac{\nabla{u(\mathbf{x})}}{(\nabla{u(\mathbf{x})})\cdot\mathbf{x}},$$ where $\mathbf{x} \in \mathbb{R}^n$, $\mathbf{p}:  \mathbb{R}^n \to \mathbb{R}^n$ and $u:\mathbb{R}^n \to \mathbb{R}$. Assume $\mathbf{p}$ and $u$ are convex and defined and differentiable for all $\mathbb{R}^n > \mathbf{0}$. I would like to show that $\mathbf{p}(\mathbf{x})$ is the gradient of some function $B: \mathbb{R}^n \to \mathbb{R}$, although I don't necessarily need to know the form of the function. What I really need to do is calculate $B(\mathbf{x_1})-B(\mathbf{x_0})$ for arbitrary values of $\mathbf{x_1}$ and $\mathbf{x_0}$. I can already calculate $\mathbf{p}(\mathbf{x})$ as needed, and if I can show that it is a valid gradient, I think the gradient theorem says that $B(\mathbf{x_1})-B(\mathbf{x_0})$ = $\int^\mathbf{x_1}_\mathbf{x_0}{\mathbf{p}(\mathbf{x}) \cdot d\mathbf{x}}$, which I can calculate numerically. However, if $\mathbf{p}(\mathbf{x})$ is not a valid gradient of any function, then the line integral is path-dependent and $B$ is ill-defined. So my question is, is it possible to show that $\mathbf{p}(\mathbf{x})$ as defined here is a valid gradient? Or are there conditions that I could apply to guarantee that it is? I've spent a couple of days trying out variations on the chain rule, substituting terms, etc., but haven't made much headway.",,"['calculus', 'multivariable-calculus', 'proof-writing', 'vector-analysis', 'line-integrals']"
3,Find $\int_{\mathbb{R}^n}e^{-\frac{\| x- a\|^2+\| x- b\|^2}{2}} dx$,Find,\int_{\mathbb{R}^n}e^{-\frac{\| x- a\|^2+\| x- b\|^2}{2}} dx,"How to integrate \begin{align} \int_{\mathbb{R}^n}e^{-\frac{\| x- a\|^2+\| x- b\|^2}{2}} dx \end{align} where $\| \cdot \|$ is the euclidean distance. I did this for the case of $n=1$ (scalar} and got \begin{align} \int_{\mathbb{R}}e^{-\frac{ ( x- a)^2+ ( x- b)^2}{2}} dx=\sqrt{\pi} e^{-\frac{(a-b)^2}{4}} \end{align} However, I am having trouble doing this for any $n$.","How to integrate \begin{align} \int_{\mathbb{R}^n}e^{-\frac{\| x- a\|^2+\| x- b\|^2}{2}} dx \end{align} where $\| \cdot \|$ is the euclidean distance. I did this for the case of $n=1$ (scalar} and got \begin{align} \int_{\mathbb{R}}e^{-\frac{ ( x- a)^2+ ( x- b)^2}{2}} dx=\sqrt{\pi} e^{-\frac{(a-b)^2}{4}} \end{align} However, I am having trouble doing this for any $n$.",,"['calculus', 'integration', 'multivariable-calculus']"
4,Volume of Solid of revolution of some body in a ball,Volume of Solid of revolution of some body in a ball,,"Calculate the Volume of Solid of revolution of $D$,which is subset of the ball $\{x^2+y^2+(z-\frac{1}{2})^2\le(\frac{1}{2})^2\}$ and is above the cone $\{z=\surd(x^2+y^2)\}$. My question - I'm not sure, how can I find which substitution should I do/use here? How can I find which is the best?","Calculate the Volume of Solid of revolution of $D$,which is subset of the ball $\{x^2+y^2+(z-\frac{1}{2})^2\le(\frac{1}{2})^2\}$ and is above the cone $\{z=\surd(x^2+y^2)\}$. My question - I'm not sure, how can I find which substitution should I do/use here? How can I find which is the best?",,"['calculus', 'integration', 'multivariable-calculus']"
5,Symmetry of the domain?,Symmetry of the domain?,,"For the tiple integral  $$\iiint_D (z^2+z) \,dx\,dy\,dz$$ over the domain $D:x^2+y^2+z^2\leq4,\quad z^2\leq x^2+y^2$ The textbook states that by symmetry of the domain the integral simplifies to $$\iiint_D z^2 \,dx\,dy\,dz.$$ How exactly do they arrive at that conclusion?","For the tiple integral  $$\iiint_D (z^2+z) \,dx\,dy\,dz$$ over the domain $D:x^2+y^2+z^2\leq4,\quad z^2\leq x^2+y^2$ The textbook states that by symmetry of the domain the integral simplifies to $$\iiint_D z^2 \,dx\,dy\,dz.$$ How exactly do they arrive at that conclusion?",,['multivariable-calculus']
6,Problem studying stationary points,Problem studying stationary points,,"I have this function:$$f(x,y)=\frac{10+x^2y^2}{e^{x^2+y^2} }$$ I have found that the only stationary point is $(0,0)$ but I don't know ho to classify it as a max, min or saddle point. Can someone help me? (I could study it using the determinant of the Hessian but I'm looking for another solution)","I have this function:$$f(x,y)=\frac{10+x^2y^2}{e^{x^2+y^2} }$$ I have found that the only stationary point is $(0,0)$ but I don't know ho to classify it as a max, min or saddle point. Can someone help me? (I could study it using the determinant of the Hessian but I'm looking for another solution)",,"['calculus', 'multivariable-calculus', 'maxima-minima']"
7,Implicit function theorem exercise with higher derivatives,Implicit function theorem exercise with higher derivatives,,"Consider the equation $e^{xz}+y-z=e$. Using the implicit function theorem shows $z$ is a smooth function of $x,y$ about $(1,1,1)$. I needed to calculate a directional derivative of $z$ at $(1,1)$ and managed that using the implicit function theorem to recover the gradient of $z$. Now I'm asked whether the partial derivatives of $z$ are symmetric about $(1,1)$ and furthermore, I need to calculate them. I think the partial derivatives are symmetric because the original function $e^{xz}+y-z=e$ is smooth, which means so is $z=z(x,y)$. I don't understand however how to find second order derivatives. The ""formula"" $$\frac{\partial z}{\partial x}=-\frac{\frac{\partial f}{\partial x}}{\frac{\partial f}{\partial z}}$$ (read with matrix inverse instead of quotient in matrix case) does not really make sense before it's evaluated at a point, since the RHS has additional variables. So how to find $\frac{\partial ^2z}{\partial x\partial y}(1,1)$?","Consider the equation $e^{xz}+y-z=e$. Using the implicit function theorem shows $z$ is a smooth function of $x,y$ about $(1,1,1)$. I needed to calculate a directional derivative of $z$ at $(1,1)$ and managed that using the implicit function theorem to recover the gradient of $z$. Now I'm asked whether the partial derivatives of $z$ are symmetric about $(1,1)$ and furthermore, I need to calculate them. I think the partial derivatives are symmetric because the original function $e^{xz}+y-z=e$ is smooth, which means so is $z=z(x,y)$. I don't understand however how to find second order derivatives. The ""formula"" $$\frac{\partial z}{\partial x}=-\frac{\frac{\partial f}{\partial x}}{\frac{\partial f}{\partial z}}$$ (read with matrix inverse instead of quotient in matrix case) does not really make sense before it's evaluated at a point, since the RHS has additional variables. So how to find $\frac{\partial ^2z}{\partial x\partial y}(1,1)$?",,"['calculus', 'multivariable-calculus', 'implicit-differentiation', 'implicit-function-theorem']"
8,Derivative of $ \frac{\partial A^{T} X^{-1}A}{\partial X}$,Derivative of, \frac{\partial A^{T} X^{-1}A}{\partial X},I looked at matrix cook book  and found an expression that is close $ \frac{\partial a^{T} X^{-1}b}{\partial X}=-X^{-T}ab^{T}X^{-T}$ . But it seems a and b are vectors. While in my case I have matrices. Any help is appreciated.,I looked at matrix cook book  and found an expression that is close $ \frac{\partial a^{T} X^{-1}b}{\partial X}=-X^{-T}ab^{T}X^{-T}$ . But it seems a and b are vectors. While in my case I have matrices. Any help is appreciated.,,"['matrices', 'multivariable-calculus', 'derivatives', 'matrix-calculus']"
9,Tangent plane equation of an implicit equation of a surface,Tangent plane equation of an implicit equation of a surface,,"How am I supposed to find the equation of a tangent plane on a surface that its equation is not explicit defined in terms of z? The equation of the surface is: $$ x^{2} -y^{2} -z^{2} = 1 $$ And I need to find all the points where the tangent plane is parallel to the plane: $$z = x + y $$ How can I do that? My approach at the moment was to think about the gradient vector of the function as being the normal vector of the plane... But the gradient vector of that surface has only two components (partial x and y), and the vector the normal vector of the plane has three components (1,1,-1)...","How am I supposed to find the equation of a tangent plane on a surface that its equation is not explicit defined in terms of z? The equation of the surface is: $$ x^{2} -y^{2} -z^{2} = 1 $$ And I need to find all the points where the tangent plane is parallel to the plane: $$z = x + y $$ How can I do that? My approach at the moment was to think about the gradient vector of the function as being the normal vector of the plane... But the gradient vector of that surface has only two components (partial x and y), and the vector the normal vector of the plane has three components (1,1,-1)...",,"['multivariable-calculus', 'implicit-differentiation']"
10,Estimate $\int_{\|x\|\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x$ without spherical coordinates.,Estimate  without spherical coordinates.,\int_{\|x\|\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x,"Is it possible to estimate the following Lebesgue integral ($\|\cdot\|$ is the 2-norm) $$\int_{\|x\|\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x, \, x\in\Bbb R^d$$ in terms of $\delta$ when $\delta\to 0$? That is to say, to bound it by $O(\frac1{\delta^\alpha})$. I know spherical coordinate transform may be a way to do it or even better yet - to give the exact value. But coordinate transform itself is quite troublesome to justify. What's more, I'm not interested in the exact value anyway, all I want is a best big O bound. So is there any good alternative, without spherical coordinate system? What I tried, the integral is equivalent to a slightly modified one interms of the big O asymptotic of $\delta$: $$\int_{\|x\|_\infty\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x,$$ since  $$\|x\|_2\ge\delta\implies \|x\|_\infty\ge \frac{\delta}{d^\frac12}\implies \|x\|_2\ge \frac{\delta}{d^\frac12}. $$ So the original integral over the space minus a ball is replaced by one over the space minus a cube - the sum of several rectangles. In dimension as low as $d=1,2$ the integral can be easily carried out over each of the rectangle to be summed up, since there are not many rectangles, but as the dimension goes higher there are as many as $3^d-1$ ones, impossible to be listed one by one. So I couldn't get any further following this seemingly hopeful thread of thought.","Is it possible to estimate the following Lebesgue integral ($\|\cdot\|$ is the 2-norm) $$\int_{\|x\|\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x, \, x\in\Bbb R^d$$ in terms of $\delta$ when $\delta\to 0$? That is to say, to bound it by $O(\frac1{\delta^\alpha})$. I know spherical coordinate transform may be a way to do it or even better yet - to give the exact value. But coordinate transform itself is quite troublesome to justify. What's more, I'm not interested in the exact value anyway, all I want is a best big O bound. So is there any good alternative, without spherical coordinate system? What I tried, the integral is equivalent to a slightly modified one interms of the big O asymptotic of $\delta$: $$\int_{\|x\|_\infty\ge\delta}\frac1{\|x\|^{d+1}}\mathrm d x,$$ since  $$\|x\|_2\ge\delta\implies \|x\|_\infty\ge \frac{\delta}{d^\frac12}\implies \|x\|_2\ge \frac{\delta}{d^\frac12}. $$ So the original integral over the space minus a ball is replaced by one over the space minus a cube - the sum of several rectangles. In dimension as low as $d=1,2$ the integral can be easily carried out over each of the rectangle to be summed up, since there are not many rectangles, but as the dimension goes higher there are as many as $3^d-1$ ones, impossible to be listed one by one. So I couldn't get any further following this seemingly hopeful thread of thought.",,"['real-analysis', 'multivariable-calculus', 'lebesgue-integral', 'multiple-integral']"
11,Derivative of projection's norm squared with respect to a matrix,Derivative of projection's norm squared with respect to a matrix,,"Background: Let $M^{n\times k}(\mathbb{R})$ denote the $n\times k$ matrices with real entries. For any smooth function $f: M^{n\times k}(\mathbb{R}) \to \mathbb{R}$, define the derivative $\frac{\partial f}{\partial A}$ by $$\left(\frac{\partial f}{\partial A}\right)_{i,j}:= \frac{\partial f}{\partial a_{ij}},$$ where $a_{i,j}$ is the entry of $A$ at the $i$-th row and $j$-th column. For any smooth curve $c:(-\epsilon,\epsilon)\to M^{n\times k}(\mathbb{R})$ with $c(0) = A, \dot c(0) = v$, $\frac{\partial f}{\partial A}$ satisfies: $$\frac{d}{dt}|_{t=0}f(c(t)) = \text{trace}\left(v^T \frac{\partial f}{\partial A}\right).$$ Question: Let $f: M^{n\times k}(\mathbb{R}) \to \mathbb{R}$ be defined by $$f(A):= \|(I - A(A^TA)^{-1}A^T) z\|^2,$$ where $z \in \mathbb{R}^n$ is a fixed vector and $\|\cdot\|$ denotes the Euclidean norm. I would like to compute $\frac{\partial f}{\partial A}$, at least at any $A$ which is full rank . Are there any tricks that can simplify this process, or is the easiest thing simply to compute each $\frac{\partial f}{\partial a_{i,j}}$ by ""brute force""? My attempt at a simpler solution: Let $c:(-\epsilon,\epsilon)\to M^{n\times k}(\mathbb{R})$ be a smooth curve with $c(0) = A, \dot c(0) = v$. I will assume that $A$ is full rank. By the chain and product rules, we have $$\frac{d}{dt}|_{t=0}f(c(t)) = 2 z^T(I-A(A^TA)^{-1}A)\left[-v (A^TA)^{-1}A^T + A(A^TA)^{-1}(v^TA + A^Tv)(A^TA)^{-1}A^T - A(A^TA)^{-1}v^T\right]z, $$  where I have used the fact that for any smooth curve $b:(-\epsilon,\epsilon)\to GL(n,\mathbb{R})$, $\frac{d}{dt}|_{t=0}b^{-1}(t) = -b^{-1}(0)\dot b(0) b^{-1}(0)$. To simplify notation, let $A^\dagger:= (A^T A)^{-1} A^T$ denote the Moore-Penrose pseudoinverse of $A$ and let $\Pi_{A_\perp}:= I - AA^\dagger$ be the orthogonal projection onto the orthogonal complement of the range of $A$. Substitution of this new notation yields: $$\frac{d}{dt}|_{t=0}f(c(t)) = 2 z^T\Pi_{A_\perp}\left[-v A^\dagger + (A^\dagger)^T(v^TA + A^Tv)A^\dagger - (A^\dagger)^T v^T\right]z. $$ Now, the kernel of $A^\dagger$ is equal to the orthogonal complement to the range of $A$, so the range of $(A^\dagger)^T$ is equal to the range of $A$. It follows that $\Pi_{A_\perp} (A^\dagger)^T = 0$. Thus we now have a simpler expression: $$\frac{d}{dt}|_{t=0}f(c(t)) = -2 z^T\Pi_{A_\perp}v A^\dagger z = -2\text{trace}\left(z^T(A^\dagger)^Tv^T\Pi_{A_\perp}z\right) = -2\text{trace}\left(v^T \Pi_{A_{\perp}}zz^T(A^\dagger)^T\right).$$ Since $v \in M^{n\times k}(\mathbb{R})$ was arbitrary, it follows that $$\frac{\partial f}{\partial A}(A) = -2 \Pi_{A_\perp} zz^T(A^\dagger)^T.$$","Background: Let $M^{n\times k}(\mathbb{R})$ denote the $n\times k$ matrices with real entries. For any smooth function $f: M^{n\times k}(\mathbb{R}) \to \mathbb{R}$, define the derivative $\frac{\partial f}{\partial A}$ by $$\left(\frac{\partial f}{\partial A}\right)_{i,j}:= \frac{\partial f}{\partial a_{ij}},$$ where $a_{i,j}$ is the entry of $A$ at the $i$-th row and $j$-th column. For any smooth curve $c:(-\epsilon,\epsilon)\to M^{n\times k}(\mathbb{R})$ with $c(0) = A, \dot c(0) = v$, $\frac{\partial f}{\partial A}$ satisfies: $$\frac{d}{dt}|_{t=0}f(c(t)) = \text{trace}\left(v^T \frac{\partial f}{\partial A}\right).$$ Question: Let $f: M^{n\times k}(\mathbb{R}) \to \mathbb{R}$ be defined by $$f(A):= \|(I - A(A^TA)^{-1}A^T) z\|^2,$$ where $z \in \mathbb{R}^n$ is a fixed vector and $\|\cdot\|$ denotes the Euclidean norm. I would like to compute $\frac{\partial f}{\partial A}$, at least at any $A$ which is full rank . Are there any tricks that can simplify this process, or is the easiest thing simply to compute each $\frac{\partial f}{\partial a_{i,j}}$ by ""brute force""? My attempt at a simpler solution: Let $c:(-\epsilon,\epsilon)\to M^{n\times k}(\mathbb{R})$ be a smooth curve with $c(0) = A, \dot c(0) = v$. I will assume that $A$ is full rank. By the chain and product rules, we have $$\frac{d}{dt}|_{t=0}f(c(t)) = 2 z^T(I-A(A^TA)^{-1}A)\left[-v (A^TA)^{-1}A^T + A(A^TA)^{-1}(v^TA + A^Tv)(A^TA)^{-1}A^T - A(A^TA)^{-1}v^T\right]z, $$  where I have used the fact that for any smooth curve $b:(-\epsilon,\epsilon)\to GL(n,\mathbb{R})$, $\frac{d}{dt}|_{t=0}b^{-1}(t) = -b^{-1}(0)\dot b(0) b^{-1}(0)$. To simplify notation, let $A^\dagger:= (A^T A)^{-1} A^T$ denote the Moore-Penrose pseudoinverse of $A$ and let $\Pi_{A_\perp}:= I - AA^\dagger$ be the orthogonal projection onto the orthogonal complement of the range of $A$. Substitution of this new notation yields: $$\frac{d}{dt}|_{t=0}f(c(t)) = 2 z^T\Pi_{A_\perp}\left[-v A^\dagger + (A^\dagger)^T(v^TA + A^Tv)A^\dagger - (A^\dagger)^T v^T\right]z. $$ Now, the kernel of $A^\dagger$ is equal to the orthogonal complement to the range of $A$, so the range of $(A^\dagger)^T$ is equal to the range of $A$. It follows that $\Pi_{A_\perp} (A^\dagger)^T = 0$. Thus we now have a simpler expression: $$\frac{d}{dt}|_{t=0}f(c(t)) = -2 z^T\Pi_{A_\perp}v A^\dagger z = -2\text{trace}\left(z^T(A^\dagger)^Tv^T\Pi_{A_\perp}z\right) = -2\text{trace}\left(v^T \Pi_{A_{\perp}}zz^T(A^\dagger)^T\right).$$ Since $v \in M^{n\times k}(\mathbb{R})$ was arbitrary, it follows that $$\frac{\partial f}{\partial A}(A) = -2 \Pi_{A_\perp} zz^T(A^\dagger)^T.$$",,"['matrices', 'multivariable-calculus', 'differential-geometry', 'matrix-calculus']"
12,"Find $\lim_{(x,y)\to(0,0)} g \left(\frac{x^4 + y^4}{x^2 + y^2}\right)$ where $\lim_{z\to 0}\frac{g(z)}{z}=2.$",Find  where,"\lim_{(x,y)\to(0,0)} g \left(\frac{x^4 + y^4}{x^2 + y^2}\right) \lim_{z\to 0}\frac{g(z)}{z}=2.","This limit seems different to me than all the other multi variable limits already asked on this site. Let $g \colon \mathbb R \to \mathbb R $ be such that $$ \lim_{z\to  0}\frac{g(z)}{z}=2. $$   Evaluate if the limit $$\lim_{(x,y)\to(0,0)} g \left(\frac{x^4 +  y^4}{x^2 + y^2}\right)$$ exists, and if it does, determine it. I tried to approach the limit with for example $x=0$, $y=0$ etcetera, but I'm not even sure where for example $g(x^2)$ so $g(z)$ goes to.  Also, polar coordinates does not seem the way to go here.","This limit seems different to me than all the other multi variable limits already asked on this site. Let $g \colon \mathbb R \to \mathbb R $ be such that $$ \lim_{z\to  0}\frac{g(z)}{z}=2. $$   Evaluate if the limit $$\lim_{(x,y)\to(0,0)} g \left(\frac{x^4 +  y^4}{x^2 + y^2}\right)$$ exists, and if it does, determine it. I tried to approach the limit with for example $x=0$, $y=0$ etcetera, but I'm not even sure where for example $g(x^2)$ so $g(z)$ goes to.  Also, polar coordinates does not seem the way to go here.",,"['real-analysis', 'limits', 'multivariable-calculus']"
13,Finding the volume of the region bounded by $z=\sqrt{\frac{x^2}{4}+y^2}$and $x+4z=a$. Cylindrical coordinates.,Finding the volume of the region bounded by and . Cylindrical coordinates.,z=\sqrt{\frac{x^2}{4}+y^2} x+4z=a,"I would like the answer to preferably be done using either using a surface integral, or an integral with substitutions. But anything other than this is alright, if nothing else exists. I have to find the volume of the region bounded by $z=\sqrt{\frac{x^2}{4}+y^2}$and $x+4z=a$. So, here we have a cone and a plane ""cutting"" it. I definitely must do this using some some of coordinate substitution. When doing a problem in class, that is, the area to be found being bounded in between $(z-1)^2=x^2+y^2$ and $z=0.$ the substitution was made, (which would be logical here to do aswell): $$x=r\cos\varphi \\ y=r \sin\varphi \\ z=z$$ and I also understand that the bounderies being $0\leq r\leq 1,0\leq\varphi\leq2\pi,0\leq z\leq 1-r.$ But in the problem I give that is a lot more difficult to do, I know that the bounderies for $\varphi$ should be the same,but with $z$ and $r$ I find it impossible. Should I find these conditional extreme points on the cone with the plane equation or am I not seeing something quite obvious here?","I would like the answer to preferably be done using either using a surface integral, or an integral with substitutions. But anything other than this is alright, if nothing else exists. I have to find the volume of the region bounded by $z=\sqrt{\frac{x^2}{4}+y^2}$and $x+4z=a$. So, here we have a cone and a plane ""cutting"" it. I definitely must do this using some some of coordinate substitution. When doing a problem in class, that is, the area to be found being bounded in between $(z-1)^2=x^2+y^2$ and $z=0.$ the substitution was made, (which would be logical here to do aswell): $$x=r\cos\varphi \\ y=r \sin\varphi \\ z=z$$ and I also understand that the bounderies being $0\leq r\leq 1,0\leq\varphi\leq2\pi,0\leq z\leq 1-r.$ But in the problem I give that is a lot more difficult to do, I know that the bounderies for $\varphi$ should be the same,but with $z$ and $r$ I find it impossible. Should I find these conditional extreme points on the cone with the plane equation or am I not seeing something quite obvious here?",,"['calculus', 'integration', 'multivariable-calculus', 'volume']"
14,Solving multiple integrals,Solving multiple integrals,,"I need to integrate $\displaystyle f(x,y)=\frac{x^2-y^2}{(x^2+y^2)^2}$ on $R=[0,1]\times [0,1]$ If I take $u=x^2+y^2,$ then $\int_0^1\int_{y^2}^{1+y^2}\frac{u-2y^2}{u^2}du$. I do not know how to proceed from here. Any help would be appreciated! Thanks in advance!","I need to integrate $\displaystyle f(x,y)=\frac{x^2-y^2}{(x^2+y^2)^2}$ on $R=[0,1]\times [0,1]$ If I take $u=x^2+y^2,$ then $\int_0^1\int_{y^2}^{1+y^2}\frac{u-2y^2}{u^2}du$. I do not know how to proceed from here. Any help would be appreciated! Thanks in advance!",,"['calculus', 'integration', 'multivariable-calculus']"
15,Can any smooth function be written in this form?,Can any smooth function be written in this form?,,"Can any smooth function $F: \mathbb{R}^n \to \mathbb{R}$ be written in the form$$F(x) = F(a) + \sum_{\mu = 1}^n (x^\mu - a^\mu)H_\mu(x),$$where $a = (a^1, \dots, a^n) \in \mathbb{R}^n$ and the $H_\mu$ are $C^\infty$ functions?","Can any smooth function $F: \mathbb{R}^n \to \mathbb{R}$ be written in the form$$F(x) = F(a) + \sum_{\mu = 1}^n (x^\mu - a^\mu)H_\mu(x),$$where $a = (a^1, \dots, a^n) \in \mathbb{R}^n$ and the $H_\mu$ are $C^\infty$ functions?",,"['calculus', 'real-analysis', 'multivariable-calculus', 'differential-geometry', 'differential-topology']"
16,Change of variables from multiple to single,Change of variables from multiple to single,,"Consider the following limit calculation: $$ \lim_{(x,y)\to (0,0)} \frac{\sin(x^2+y^2)}{x^2+y^2} = \lim_{t\to 0} \frac{\sin t}{t} = 1$$ How can one justify this change of variables from multiple to single? When can we do it (and when can't we?) Thanks.","Consider the following limit calculation: $$ \lim_{(x,y)\to (0,0)} \frac{\sin(x^2+y^2)}{x^2+y^2} = \lim_{t\to 0} \frac{\sin t}{t} = 1$$ How can one justify this change of variables from multiple to single? When can we do it (and when can't we?) Thanks.",,"['calculus', 'limits', 'multivariable-calculus']"
17,"How do I prove that $\lim_{(x,y) \to (0,0)} \frac{2y^2}{\sqrt{x^2+xy}}$ exists?",How do I prove that  exists?,"\lim_{(x,y) \to (0,0)} \frac{2y^2}{\sqrt{x^2+xy}}","Now I have learnt that to prove a function of 2 variables exists we must have the both the repeated limits as equal, which is $\lim_{(x=0,y\to0)}f(x,y) = \lim_{(x\to0,y=0)}f(x,y)$ , now in this case $f(x,y)= \frac{2y^2}{\sqrt{x^2+xy}}$ so $\lim_{(x=0,y\to0)}f(x,y) = \lim_{(x=0,y\to0)} 2y^2/\infty$ which is not defined ,while for $\lim_{(x\to0,y=0)}f(x,y) = 0$ which is I think is enough to prove that this function( $\frac{2y^2}{\sqrt{x^2+xy}}$) does not exist as $(x,y) \to (0,0)$ Yet my book says it does exist , and I really can't find here where I go wrong , so I decided to ask here. (P S : I guess i would be ridiculous to add this but at point $(0,y)$ my function is undefined ! doesn't that mean I simply don't need the point $(x,0)$ at all to prove it exists because its undefined and that straight off finishes the matter)","Now I have learnt that to prove a function of 2 variables exists we must have the both the repeated limits as equal, which is $\lim_{(x=0,y\to0)}f(x,y) = \lim_{(x\to0,y=0)}f(x,y)$ , now in this case $f(x,y)= \frac{2y^2}{\sqrt{x^2+xy}}$ so $\lim_{(x=0,y\to0)}f(x,y) = \lim_{(x=0,y\to0)} 2y^2/\infty$ which is not defined ,while for $\lim_{(x\to0,y=0)}f(x,y) = 0$ which is I think is enough to prove that this function( $\frac{2y^2}{\sqrt{x^2+xy}}$) does not exist as $(x,y) \to (0,0)$ Yet my book says it does exist , and I really can't find here where I go wrong , so I decided to ask here. (P S : I guess i would be ridiculous to add this but at point $(0,y)$ my function is undefined ! doesn't that mean I simply don't need the point $(x,0)$ at all to prove it exists because its undefined and that straight off finishes the matter)",,"['limits', 'multivariable-calculus', 'functions']"
18,Finding the Maximum value.,Finding the Maximum value.,,"Maximize $xy^2$ on the ellipse $b^2x^2 +a^2y^2= a^2b^2$ The steps I tried to solve: $$\nabla f = (y^2,2yx)\lambda\qquad g = (2xb^2,2y^2a^2)\lambda$$ $$y^2= 2xb^2\lambda$$ $$2yx= 2y^2a^2\lambda$$ $$ \left. \begin{array}{l} \text{}&y^2= 2xb^2\lambda\\ \text{}& \end{array} \right\} *a^2y $$ $$ \left. \begin{array}{l} \text{}&2yx= 2y^2a^2\lambda\\ \text{}& \end{array} \right\} *b^2x $$ $$y^3a^2= 2yxa^2b^2 \lambda$$ $$2yx^2b^2 = 2y^2a^2b^2x\lambda$$ $\color{maroon}{\mathbf{Equalize}}$ $$2a^2b^2xy = 2a^2b^2xy^2$$ $$y=1$$ My main problem is which equations does one set each equal to. If anyone knows which one equals the other this will lead me to the right place in finding the solution.","Maximize $xy^2$ on the ellipse $b^2x^2 +a^2y^2= a^2b^2$ The steps I tried to solve: $$\nabla f = (y^2,2yx)\lambda\qquad g = (2xb^2,2y^2a^2)\lambda$$ $$y^2= 2xb^2\lambda$$ $$2yx= 2y^2a^2\lambda$$ $$ \left. \begin{array}{l} \text{}&y^2= 2xb^2\lambda\\ \text{}& \end{array} \right\} *a^2y $$ $$ \left. \begin{array}{l} \text{}&2yx= 2y^2a^2\lambda\\ \text{}& \end{array} \right\} *b^2x $$ $$y^3a^2= 2yxa^2b^2 \lambda$$ $$2yx^2b^2 = 2y^2a^2b^2x\lambda$$ $\color{maroon}{\mathbf{Equalize}}$ $$2a^2b^2xy = 2a^2b^2xy^2$$ $$y=1$$ My main problem is which equations does one set each equal to. If anyone knows which one equals the other this will lead me to the right place in finding the solution.",,"['calculus', 'multivariable-calculus', 'lagrange-multiplier']"
19,"Prove that the map $f(x,y) = (e^x\cos y,e^x\sin y)$ is not injective in the plane",Prove that the map  is not injective in the plane,"f(x,y) = (e^x\cos y,e^x\sin y)","Let $f : \mathbb{R}^2 \rightarrow \mathbb{R}^2$ given by $f(x,y) = (e^x\cos y,e^x\sin y)$ a) Prove that if $\det f'(x,y) \neq 0$ $\forall (x,y) \in \mathbb{R}^2$. b) Show that for any $u = (x,y) \in \mathbb{R}^2$ there exists a $\delta > 0$ such that $f$ is invertible in $B(u,\delta)$. c) Prove that $f$ is not injective. So, I've already proven a, and I can use that, given that the partial derivatives are continuous they are derivable, so $f$ is a at least $C^1$ (one time derivable) so there exists a $B(u,\delta)$ where the function is injective then it's invertible (I'm not sure with that last part, I'm having trouble there, any hints?) For c, I guess I've to show that as it may be injective in a $B(u,\delta)$ it is not injective for $f's$ whole domain but I have no clue there.","Let $f : \mathbb{R}^2 \rightarrow \mathbb{R}^2$ given by $f(x,y) = (e^x\cos y,e^x\sin y)$ a) Prove that if $\det f'(x,y) \neq 0$ $\forall (x,y) \in \mathbb{R}^2$. b) Show that for any $u = (x,y) \in \mathbb{R}^2$ there exists a $\delta > 0$ such that $f$ is invertible in $B(u,\delta)$. c) Prove that $f$ is not injective. So, I've already proven a, and I can use that, given that the partial derivatives are continuous they are derivable, so $f$ is a at least $C^1$ (one time derivable) so there exists a $B(u,\delta)$ where the function is injective then it's invertible (I'm not sure with that last part, I'm having trouble there, any hints?) For c, I guess I've to show that as it may be injective in a $B(u,\delta)$ it is not injective for $f's$ whole domain but I have no clue there.",,"['calculus', 'multivariable-calculus', 'partial-derivative']"
20,Calculate $\int_{\mathbb{R}^3} e^{-\left \| x \right \|}d^3x$,Calculate,\int_{\mathbb{R}^3} e^{-\left \| x \right \|}d^3x,"I've tried to find and similar question like this but I couldn't. So, I need to calculate the following integral: $$\int_{\mathbb{R}^3} e^{-\left \| x \right \|}d^3x$$ I need a hint to proceed...","I've tried to find and similar question like this but I couldn't. So, I need to calculate the following integral: $$\int_{\mathbb{R}^3} e^{-\left \| x \right \|}d^3x$$ I need a hint to proceed...",,['multivariable-calculus']
21,"Given 3 spheres, find the equation of the plane that touches each of the spheres on the same side..?","Given 3 spheres, find the equation of the plane that touches each of the spheres on the same side..?",,"I have a problem I am trying to solve, but I have no idea how to solve it. If I have 3 spheres, $A(1, 2, 0), B(4, 5, 0), \text{ and } C(1, 3, 2)$ of radius 1, how would I go about finding the equation of the form $ax + by +cz = d$ of the plane which touches each of the spheres on the same side..? I have been racking my brain all day, but I can't seem to figure it out. If someone wouldnt mind lending a hand, It would be much appreciated.. Thanks Corey","I have a problem I am trying to solve, but I have no idea how to solve it. If I have 3 spheres, $A(1, 2, 0), B(4, 5, 0), \text{ and } C(1, 3, 2)$ of radius 1, how would I go about finding the equation of the form $ax + by +cz = d$ of the plane which touches each of the spheres on the same side..? I have been racking my brain all day, but I can't seem to figure it out. If someone wouldnt mind lending a hand, It would be much appreciated.. Thanks Corey",,"['geometry', 'multivariable-calculus', 'conic-sections']"
22,Does the concept of a derivative a rate of change work for n dimensions?,Does the concept of a derivative a rate of change work for n dimensions?,,"I am trying to understand what exactly a derivative is. I understand the total derivative is a linear map. But I don't understand what happens to the idea of a rate. In high school calc, one is taught the derivative is a rate of change. For example,  $$\frac{dx}{dt}$$ But for a vector function like $$f(x,y) = xy^2 \mathbf{\hat{i}} + x^5 \mathbf{\hat{j}} + \sqrt{y}\mathbf{\hat{k}}$$ What does rate of change mean if I take the total or partial derivative of this? Should I think of a partial and total derivative like a collection of rates?","I am trying to understand what exactly a derivative is. I understand the total derivative is a linear map. But I don't understand what happens to the idea of a rate. In high school calc, one is taught the derivative is a rate of change. For example,  $$\frac{dx}{dt}$$ But for a vector function like $$f(x,y) = xy^2 \mathbf{\hat{i}} + x^5 \mathbf{\hat{j}} + \sqrt{y}\mathbf{\hat{k}}$$ What does rate of change mean if I take the total or partial derivative of this? Should I think of a partial and total derivative like a collection of rates?",,['multivariable-calculus']
23,Does this weird series converge?,Does this weird series converge?,,"$\sum_{n\in S}$$\frac{1}{n}$, where S consists of those positive integers whose decimal expansion does not contain the digit 1. This was a part(b) question. Part (a) was an evaluation of the double integral $\int \int_S$ $(x^2 + y^2)d\sigma$, where S is the unit sphere centered at (0,0,0), and $\sigma$ is surface area.  The answer is $\frac{8\pi}{3}$. I don't see how part(a) can be used to solve part(b). For the series evaluation, if we are summing over the positive integers that don't contain the digit 1, then I'm thinking we exclude integers such as 1, which has decimal expansion .99999.. or 1.0000, or 10, which has expansion 9.9999... or 10.0000, etc, and we sum over numbers such as 2, 3, 4, 5, ... Not sure where I can go with this idea, though. Thanks,","$\sum_{n\in S}$$\frac{1}{n}$, where S consists of those positive integers whose decimal expansion does not contain the digit 1. This was a part(b) question. Part (a) was an evaluation of the double integral $\int \int_S$ $(x^2 + y^2)d\sigma$, where S is the unit sphere centered at (0,0,0), and $\sigma$ is surface area.  The answer is $\frac{8\pi}{3}$. I don't see how part(a) can be used to solve part(b). For the series evaluation, if we are summing over the positive integers that don't contain the digit 1, then I'm thinking we exclude integers such as 1, which has decimal expansion .99999.. or 1.0000, or 10, which has expansion 9.9999... or 10.0000, etc, and we sum over numbers such as 2, 3, 4, 5, ... Not sure where I can go with this idea, though. Thanks,",,"['calculus', 'real-analysis', 'sequences-and-series', 'multivariable-calculus', 'decimal-expansion']"
24,Prove the Jacobian identity,Prove the Jacobian identity,,"How to prove that these Jacobians are equal? $$\dfrac{\partial (x,y)}{\partial(\alpha, \beta)} \cdot \dfrac{\partial(\alpha, \beta)}{\partial(z,w)} = \dfrac{\partial (x,y)}{\partial(z,w)}$$ I don't find it staightforward to cancel $\partial(\alpha, \beta)$ out, as it is operator but not a fraction. But I have tried to express them following the definition, without success though. Thanks.","How to prove that these Jacobians are equal? $$\dfrac{\partial (x,y)}{\partial(\alpha, \beta)} \cdot \dfrac{\partial(\alpha, \beta)}{\partial(z,w)} = \dfrac{\partial (x,y)}{\partial(z,w)}$$ I don't find it staightforward to cancel $\partial(\alpha, \beta)$ out, as it is operator but not a fraction. But I have tried to express them following the definition, without success though. Thanks.",,"['multivariable-calculus', 'partial-derivative']"
25,How can I prove that any ball in $\mathbb{R}^n$ is connected?,How can I prove that any ball in  is connected?,\mathbb{R}^n,"As the title follows, how can I prove that any ball in $\mathbb{R}^n$ is connected? or can you give me a hint? I have some ideas but I'm not sure about them. I thank any help you can give me! Regards","As the title follows, how can I prove that any ball in $\mathbb{R}^n$ is connected? or can you give me a hint? I have some ideas but I'm not sure about them. I thank any help you can give me! Regards",,"['real-analysis', 'multivariable-calculus']"
26,Finding the intersection of a line and hyperplane,Finding the intersection of a line and hyperplane,,"Taking the hyperplane P = $\{ $x$ :3x^1-3x^2-3x^3-x^4=0\}$ and the line $t(e_1-e_2)+(1-t)e_4$ I do not know how to solve for t, where t is the intersection of the two. This is problem 2b from Fleming's Functions of Several Variables. I am self-studying. There isn't any point within the book that prepares one for this problem. The method I know for solving this type of problem isn't useful for this version see Lang's (Intro)/Linear Algebra. e.g., (X-Q) $\cdot$ N = O where N is the normal and Q is some point in the plane and we have the parametric line X=P+tA for some point on the line P, and the line is in the direction of the vector A, for all t. When trying to use this method of solution I run into the issue of the parametric line and its original counterpart and failure during conversion. Could you please offer hints as to where to start because I do not think I am doing this the most effective way.","Taking the hyperplane P = $\{ $x$ :3x^1-3x^2-3x^3-x^4=0\}$ and the line $t(e_1-e_2)+(1-t)e_4$ I do not know how to solve for t, where t is the intersection of the two. This is problem 2b from Fleming's Functions of Several Variables. I am self-studying. There isn't any point within the book that prepares one for this problem. The method I know for solving this type of problem isn't useful for this version see Lang's (Intro)/Linear Algebra. e.g., (X-Q) $\cdot$ N = O where N is the normal and Q is some point in the plane and we have the parametric line X=P+tA for some point on the line P, and the line is in the direction of the vector A, for all t. When trying to use this method of solution I run into the issue of the parametric line and its original counterpart and failure during conversion. Could you please offer hints as to where to start because I do not think I am doing this the most effective way.",,"['linear-algebra', 'multivariable-calculus']"
27,What's an intuition behind $\lambda=1$ for $dx\;dy = \lambda r\;dr\;d\theta$?,What's an intuition behind  for ?,\lambda=1 dx\;dy = \lambda r\;dr\;d\theta,"I've read a bunch of articles here on converting between rectangular and polar coordinates in integrals. I get the intuition about how the natural infinitesimal area segment in rectangular coordinates is an infinitesimal square (ergo $dx\;dy$) but is an infinitesimal chunk of an annulus in polar coordinates (ergo $r\;d\theta\cdot dr$). What I don't get is why we can just swap the two out without some kind of scaling factor. That is, why is it that if we write $dx\;dy = \lambda{}r\;dr\;d\theta$, we have $\lambda=1$? E.g., when I imagine making $\theta$ infinitesimal first, the infinitesimally thin sector in polar coordinates has area $\frac{1}{2}r^{2}\theta$ whereas the rectangle with infinitesimal height has area $xy \approx r^2\theta$ since the part of the sector falling outside the rectangle vanishes and what we're left with is practically a triangle within the rectangle. In other words, the rectangular coordinate area is twice that of the polar coordinate area. If we look at the infinitesimal band of the annulus at the end (i.e., looking at the ""crust"" of the ""pie slice""), won't that cause the part of the sector falling outside the rectangle to play a dominant role again? Why would that just happen to have the same area as a rectangle with the same infinitesimal width? I've read that this is ""explained"" by using the Jacobian in converting between rectangular and polar coordinates since the determinant of the Jacobian is $r$ and not $\lambda r$ for some $\lambda \neq 1$. But this doesn't really inform my intuition. I get that the Jacobian of a function $f$ at $p$ is $f$'s best linear approximation at $p$, but I don't get why the thing to do here is to take its determinant and inject that into an integral when you're switching between coordinate systems. And that seems so much more general than what I'm looking for here. Is it actually necessary to understand all square Jacobians to get why the infinitesimal areas of rectangular and polar coordinates just happen to be equal? So$\ldots$ why is $\lambda=1$?","I've read a bunch of articles here on converting between rectangular and polar coordinates in integrals. I get the intuition about how the natural infinitesimal area segment in rectangular coordinates is an infinitesimal square (ergo $dx\;dy$) but is an infinitesimal chunk of an annulus in polar coordinates (ergo $r\;d\theta\cdot dr$). What I don't get is why we can just swap the two out without some kind of scaling factor. That is, why is it that if we write $dx\;dy = \lambda{}r\;dr\;d\theta$, we have $\lambda=1$? E.g., when I imagine making $\theta$ infinitesimal first, the infinitesimally thin sector in polar coordinates has area $\frac{1}{2}r^{2}\theta$ whereas the rectangle with infinitesimal height has area $xy \approx r^2\theta$ since the part of the sector falling outside the rectangle vanishes and what we're left with is practically a triangle within the rectangle. In other words, the rectangular coordinate area is twice that of the polar coordinate area. If we look at the infinitesimal band of the annulus at the end (i.e., looking at the ""crust"" of the ""pie slice""), won't that cause the part of the sector falling outside the rectangle to play a dominant role again? Why would that just happen to have the same area as a rectangle with the same infinitesimal width? I've read that this is ""explained"" by using the Jacobian in converting between rectangular and polar coordinates since the determinant of the Jacobian is $r$ and not $\lambda r$ for some $\lambda \neq 1$. But this doesn't really inform my intuition. I get that the Jacobian of a function $f$ at $p$ is $f$'s best linear approximation at $p$, but I don't get why the thing to do here is to take its determinant and inject that into an integral when you're switching between coordinate systems. And that seems so much more general than what I'm looking for here. Is it actually necessary to understand all square Jacobians to get why the infinitesimal areas of rectangular and polar coordinates just happen to be equal? So$\ldots$ why is $\lambda=1$?",,"['multivariable-calculus', 'infinitesimals']"
28,How to differentiate the function $f(\mathbf x) = \|\mathbf x\|^2 \mathbf x$?,How to differentiate the function ?,f(\mathbf x) = \|\mathbf x\|^2 \mathbf x,"Let $f:\mathbb R^n\to\mathbb R^n$ be given by the equation $f(\mathbf x)=\|\mathbf x\|^2 \mathbf x$. Show that $f$ is of class $C^\infty$ and that $f$ carries the unit ball $B(\mathbf 0;1)$ onto itself in a one-to-one fashion. Show, however, that the inverse function is not differentiable at $\mathbf 0$. How does one differentiate a function involving the Euclidean norm? It's simple enough if it was just the norm itself, but multiplied by a vector I'm not sure how to go about it.","Let $f:\mathbb R^n\to\mathbb R^n$ be given by the equation $f(\mathbf x)=\|\mathbf x\|^2 \mathbf x$. Show that $f$ is of class $C^\infty$ and that $f$ carries the unit ball $B(\mathbf 0;1)$ onto itself in a one-to-one fashion. Show, however, that the inverse function is not differentiable at $\mathbf 0$. How does one differentiate a function involving the Euclidean norm? It's simple enough if it was just the norm itself, but multiplied by a vector I'm not sure how to go about it.",,"['multivariable-calculus', 'derivatives', 'matrix-calculus', 'jacobian']"
29,How does algebra on differential forms work?,How does algebra on differential forms work?,,"Let $\omega$ be a 1-form such that: $\omega = a\,dx + b\,dy$ and $\eta$ is a 0-form. I've seen a lot of times where $\eta \wedge \omega$ is written as $\eta \omega$... which kind of makes sense as $\eta \wedge \omega = (\eta a)\,dx  + (\eta b)\,dy$. But is the first term, $(\eta a)\,dx$, the same thing as $\eta (a\,dx)$? Also, is $a\,dx = a \wedge dx$? Is $dx$ a 1-form? In general, if $\eta$ is a 0-form, does that mean $\eta \wedge \omega = \eta \omega$? I'm just really confused about the algebraic structure of differential forms, and this notation doesn't really help. I've been told to treat the wedge product of two forms like multiplying polynomials with the $dx_i$ being ""wedged"" and the ""coefficients"" simply being multiplied together, so: $$(a\,dx+b\,dy) \wedge (e\,dx+f\,dy) = ae \,dx \wedge dx + af\, dx \wedge dy + be\, dy \wedge dx + bf\, dy \wedge dy$$ Can't we derive this somehow by considering $a\,dx$ as $a \wedge dx$ along with anticommutativity and associativity, instead of defining this case separately? What exactly is the interplay between this multiplication implicit in $a\,dx$ and the wedge product? Is $dx$ itself a 1-form, or do we just treat it as just some ""thing""? Does it really make a difference in anything? Also, if someone could give me a reference to any text regarding this, that would be great.","Let $\omega$ be a 1-form such that: $\omega = a\,dx + b\,dy$ and $\eta$ is a 0-form. I've seen a lot of times where $\eta \wedge \omega$ is written as $\eta \omega$... which kind of makes sense as $\eta \wedge \omega = (\eta a)\,dx  + (\eta b)\,dy$. But is the first term, $(\eta a)\,dx$, the same thing as $\eta (a\,dx)$? Also, is $a\,dx = a \wedge dx$? Is $dx$ a 1-form? In general, if $\eta$ is a 0-form, does that mean $\eta \wedge \omega = \eta \omega$? I'm just really confused about the algebraic structure of differential forms, and this notation doesn't really help. I've been told to treat the wedge product of two forms like multiplying polynomials with the $dx_i$ being ""wedged"" and the ""coefficients"" simply being multiplied together, so: $$(a\,dx+b\,dy) \wedge (e\,dx+f\,dy) = ae \,dx \wedge dx + af\, dx \wedge dy + be\, dy \wedge dx + bf\, dy \wedge dy$$ Can't we derive this somehow by considering $a\,dx$ as $a \wedge dx$ along with anticommutativity and associativity, instead of defining this case separately? What exactly is the interplay between this multiplication implicit in $a\,dx$ and the wedge product? Is $dx$ itself a 1-form, or do we just treat it as just some ""thing""? Does it really make a difference in anything? Also, if someone could give me a reference to any text regarding this, that would be great.",,['multivariable-calculus']
30,Find absolute maximum and minimum with domain,Find absolute maximum and minimum with domain,,"Find absolute maximum and minimum of the function $f(x,y)=3-x^2+y^2$ on the region $R = \{(x,y):1≥x≥0, 2≥y≥0\}$ I found that the gradient is $∇f(x,y)=(2x,2y)$ and that the critical point inside the domain is (0,0) and it is a local minimum. I know I have to check the boundary, and I know how to do it for a fixed equation like $x^2+y^2=1$ but not for the domain I'm given. Can someone explain how this type of problem is to be solved? I don't seem to understand this problem logically or intuitively.","Find absolute maximum and minimum of the function $f(x,y)=3-x^2+y^2$ on the region $R = \{(x,y):1≥x≥0, 2≥y≥0\}$ I found that the gradient is $∇f(x,y)=(2x,2y)$ and that the critical point inside the domain is (0,0) and it is a local minimum. I know I have to check the boundary, and I know how to do it for a fixed equation like $x^2+y^2=1$ but not for the domain I'm given. Can someone explain how this type of problem is to be solved? I don't seem to understand this problem logically or intuitively.",,"['calculus', 'multivariable-calculus', 'optimization']"
31,"Limit of $\frac{x^2-y^2}{x^2+y^2}\sin(x-3y)$ when $(x,y) \to (0,0)$",Limit of  when,"\frac{x^2-y^2}{x^2+y^2}\sin(x-3y) (x,y) \to (0,0)","Show that $$\lim_{(x,y)\to (0,0)}\frac{x^2-y^2}{x^2+y^2}\sin(x-3y)$$ Does not exists I've tried the traditional patches, but I always find zero as answer. Any hint? Thanks in advance!","Show that $$\lim_{(x,y)\to (0,0)}\frac{x^2-y^2}{x^2+y^2}\sin(x-3y)$$ Does not exists I've tried the traditional patches, but I always find zero as answer. Any hint? Thanks in advance!",,"['limits', 'multivariable-calculus']"
32,continuity single and multivariable function simple question,continuity single and multivariable function simple question,,"Why $$f(x,y) =\begin{cases} \frac{xy^2}{x^2 +y^2} \mbox{ for } (x,y)\neq (0,0) \\ 0  \mbox{ for } (x,y)= (0,0)\end{cases}$$ is continuous and $$f(x) =\begin{cases} 2 \mbox{ for } 0>=x>10 \\ 5  \mbox{ for } x>=10\end{cases}$$ seem to be discontinuity? Or am I wrong? This is related to my previous question continuity single variable function and multivariable funtion and its parcial derivatives","Why $$f(x,y) =\begin{cases} \frac{xy^2}{x^2 +y^2} \mbox{ for } (x,y)\neq (0,0) \\ 0  \mbox{ for } (x,y)= (0,0)\end{cases}$$ is continuous and $$f(x) =\begin{cases} 2 \mbox{ for } 0>=x>10 \\ 5  \mbox{ for } x>=10\end{cases}$$ seem to be discontinuity? Or am I wrong? This is related to my previous question continuity single variable function and multivariable funtion and its parcial derivatives",,"['multivariable-calculus', 'continuity']"
33,Direction of Greatest Increase,Direction of Greatest Increase,,"Problem: Find the direction of greatest increase at $P$. $$f(x,y)=4x^2+y^2+2y$$ $$P=(1,2,12)$$ Solution: The greatest increase in $f(x,y)$ at $P$ can be attained by moving in the direction of $$\nabla f(1,2)= \langle 8, 6 \rangle$$ Can someone explain how they got this solution? I know it will involve partial derivatives, but I don't know where to go from there. Thanks.","Problem: Find the direction of greatest increase at $P$. $$f(x,y)=4x^2+y^2+2y$$ $$P=(1,2,12)$$ Solution: The greatest increase in $f(x,y)$ at $P$ can be attained by moving in the direction of $$\nabla f(1,2)= \langle 8, 6 \rangle$$ Can someone explain how they got this solution? I know it will involve partial derivatives, but I don't know where to go from there. Thanks.",,"['multivariable-calculus', 'derivatives']"
34,A limit two variables,A limit two variables,,"How can I compute or prove that $\displaystyle\lim_{(x,y)\to(0,0)}\dfrac{\mathrm{e}^{xy}-1}{\sqrt{x^2+y^2}}=0$?","How can I compute or prove that $\displaystyle\lim_{(x,y)\to(0,0)}\dfrac{\mathrm{e}^{xy}-1}{\sqrt{x^2+y^2}}=0$?",,"['calculus', 'limits', 'multivariable-calculus']"
35,Confusion about Spherical Coordinates Transformation,Confusion about Spherical Coordinates Transformation,,"We have a function $$f(x,y,z) = \frac{e^{-x^2 -y^2 -z^2}}{\sqrt{x^2+y^2+z^2}}$$ and we want to integrate it over the whole $\mathbb{R}^3$. Then what i got is the following: $$\int_{\mathbb{R}^3}^ \! \frac{e^{-x^2 -y^2 -z^2}}{\sqrt{x^2+y^2+z^2}} \, \mathrm{d}x\mathrm{d}y\mathrm{d}z$$  $$=\int_0^{\infty} \! \!\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \! \int_0^{2\pi} \! \frac{e^{-r^2(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi) }}{\sqrt{r^2(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi)}}r^2cos\theta \, \mathrm{d}\phi\mathrm{d}\theta\mathrm{d}r, $$ my textbook says that the integral over the whole $\mathbb{R}^3$ is equal to $$\int_0^{\infty} \! \!\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \! \int_0^{2\pi} \! \frac{e^{-r^2}}{\sqrt{r^2}}r^2cos\theta \, \mathrm{d}\phi\mathrm{d}\theta\mathrm{d}r. $$ What i dont quite understand - did i go wrong or does $(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi)$ somehow equal 1 here (the integration of the final integral is not necessary for the answer)?","We have a function $$f(x,y,z) = \frac{e^{-x^2 -y^2 -z^2}}{\sqrt{x^2+y^2+z^2}}$$ and we want to integrate it over the whole $\mathbb{R}^3$. Then what i got is the following: $$\int_{\mathbb{R}^3}^ \! \frac{e^{-x^2 -y^2 -z^2}}{\sqrt{x^2+y^2+z^2}} \, \mathrm{d}x\mathrm{d}y\mathrm{d}z$$  $$=\int_0^{\infty} \! \!\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \! \int_0^{2\pi} \! \frac{e^{-r^2(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi) }}{\sqrt{r^2(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi)}}r^2cos\theta \, \mathrm{d}\phi\mathrm{d}\theta\mathrm{d}r, $$ my textbook says that the integral over the whole $\mathbb{R}^3$ is equal to $$\int_0^{\infty} \! \!\int_{-\frac{\pi}{2}}^{\frac{\pi}{2}} \! \int_0^{2\pi} \! \frac{e^{-r^2}}{\sqrt{r^2}}r^2cos\theta \, \mathrm{d}\phi\mathrm{d}\theta\mathrm{d}r. $$ What i dont quite understand - did i go wrong or does $(cos^2\theta cos^2\phi +cos^2\theta sin^2\phi + sin^2\phi)$ somehow equal 1 here (the integration of the final integral is not necessary for the answer)?",,"['integration', 'multivariable-calculus']"
36,"Using Green's theorem, with holes in region","Using Green's theorem, with holes in region",,"I've just learned Green's theorem and I need a little help in solving a problem! I need to calculate  $\oint_c  \vec{F} d \vec{r}  $, when the vector field $ \vec{F} =( \frac{y}{x^2+y^2}+ \frac{y}{(x-2)^2+y^2})\hat{i}-(\frac{x}{x^2+y^2}+ \frac{x-2}{(x-2)^2+y^2})  \hat{j}$ . Curve $C$ has origin at $(0,0)$, and has radius of 10, and circulates counterclockwise. My professor taught how to solve this, but I didn't quite get it. She told us to use Green's theorem. However, the circle with radius 10 has two holes- at (0,0) and at (2,0). So I'm not sure how to solve this. She said to divide the circle into parts, with the holes circulating clockwise.... but how do I do this???And also that I should think of  $\vec{F}=\vec{F}_1+\vec{F}_2$, so $\vec{F}_1=\frac{y}{x^2+y^2}\hat{i}-\frac{x}{x^2+y^2}\hat{j}$ and $\vec{F}_2=\frac{y}{(x-2)^2+y^2}\hat{i}-\frac{x-2}{(x-2)^2+y^2}  \hat{j}$ I know that if I use Green's theorem, the answer would be $0$ anyways because $\frac{\partial N}{\partial x}- \frac{\partial M}{\partial y}= 0$ but I would like to know how to use Green's theorem when the region has holes...","I've just learned Green's theorem and I need a little help in solving a problem! I need to calculate  $\oint_c  \vec{F} d \vec{r}  $, when the vector field $ \vec{F} =( \frac{y}{x^2+y^2}+ \frac{y}{(x-2)^2+y^2})\hat{i}-(\frac{x}{x^2+y^2}+ \frac{x-2}{(x-2)^2+y^2})  \hat{j}$ . Curve $C$ has origin at $(0,0)$, and has radius of 10, and circulates counterclockwise. My professor taught how to solve this, but I didn't quite get it. She told us to use Green's theorem. However, the circle with radius 10 has two holes- at (0,0) and at (2,0). So I'm not sure how to solve this. She said to divide the circle into parts, with the holes circulating clockwise.... but how do I do this???And also that I should think of  $\vec{F}=\vec{F}_1+\vec{F}_2$, so $\vec{F}_1=\frac{y}{x^2+y^2}\hat{i}-\frac{x}{x^2+y^2}\hat{j}$ and $\vec{F}_2=\frac{y}{(x-2)^2+y^2}\hat{i}-\frac{x-2}{(x-2)^2+y^2}  \hat{j}$ I know that if I use Green's theorem, the answer would be $0$ anyways because $\frac{\partial N}{\partial x}- \frac{\partial M}{\partial y}= 0$ but I would like to know how to use Green's theorem when the region has holes...",,"['calculus', 'multivariable-calculus']"
37,Find the gradient of $\frac{x}{x-y}$,Find the gradient of,\frac{x}{x-y},"It seems simple on the face of it, but I cannot figure out how to actually do this. I know that you have to find the partial with respect to $x$ and also with respect to $y$, but that's where I get lost.","It seems simple on the face of it, but I cannot figure out how to actually do this. I know that you have to find the partial with respect to $x$ and also with respect to $y$, but that's where I get lost.",,"['multivariable-calculus', 'partial-derivative']"
38,Proving $ \frac{x^3y^2}{x^4+y^4}$ is continuous. [duplicate],Proving  is continuous. [duplicate], \frac{x^3y^2}{x^4+y^4},"This question already has answers here : Continuity of $\frac{x^3y^2}{x^4+y^4}$ at $(0,0)$? [duplicate] (3 answers) Closed 7 years ago . The problem asks to show that $$f(x,y) = \left\{ \begin{align} \frac{x^3y^2}{x^4+y^4}, & (x,y) \neq (0,0), \\ 0, & (x,y) = (0,0), \end{align} \right.$$ is continuous at the origin, however it has resisted my bravest efforts. I have attempted using $x^4+y^4 \geq y^4$ and therefore $$\left\vert \frac{x^3y^2}{x^4+y^4} \right\vert \leq \left\vert \frac{x^3}{y^2} \right\vert$$ and similar strategies but they have failed. Trying to disprove it and see if it's discontinuous has only strengthened the belief that it's continuous.","This question already has answers here : Continuity of $\frac{x^3y^2}{x^4+y^4}$ at $(0,0)$? [duplicate] (3 answers) Closed 7 years ago . The problem asks to show that $$f(x,y) = \left\{ \begin{align} \frac{x^3y^2}{x^4+y^4}, & (x,y) \neq (0,0), \\ 0, & (x,y) = (0,0), \end{align} \right.$$ is continuous at the origin, however it has resisted my bravest efforts. I have attempted using $x^4+y^4 \geq y^4$ and therefore $$\left\vert \frac{x^3y^2}{x^4+y^4} \right\vert \leq \left\vert \frac{x^3}{y^2} \right\vert$$ and similar strategies but they have failed. Trying to disprove it and see if it's discontinuous has only strengthened the belief that it's continuous.",,"['real-analysis', 'analysis', 'limits', 'multivariable-calculus']"
39,Showing that $\phi:\Bbb R^2 \to \Bbb R^2$ is injective,Showing that  is injective,\phi:\Bbb R^2 \to \Bbb R^2,"I need to show that $$\phi:(x,y)\to(\sin\frac{y}{2}-x, \sin\frac{x}{2}-y)$$ Is a $C^1$-diffeomorphism. So, I need to show it's injective. How can I do this? Just explicitly setting $\phi(x, y)=\phi(x', y')$ just leads to a non-linear system that I can't even begin to solve. Is there some trick for showing that a multivariable function is injective?","I need to show that $$\phi:(x,y)\to(\sin\frac{y}{2}-x, \sin\frac{x}{2}-y)$$ Is a $C^1$-diffeomorphism. So, I need to show it's injective. How can I do this? Just explicitly setting $\phi(x, y)=\phi(x', y')$ just leads to a non-linear system that I can't even begin to solve. Is there some trick for showing that a multivariable function is injective?",,['multivariable-calculus']
40,Does the Poisson kernel give a unique harmonic function with given boundary data?,Does the Poisson kernel give a unique harmonic function with given boundary data?,,"In the answer to this question, a helpful Stack user said that the Poisson kernel does not necessarily give a unique harmonic function, given certain boundary data (in particular on the upper half-plane). I had learned that it did, based on the following argument: take the Green's identity $$\int_D u\Delta v - v\Delta u \,\,dV = \int_{\partial D} u \frac{\partial v}{\partial \nu} - v \frac{\partial u}{\partial \nu}d\sigma.$$ Now take $v(x,y)$ to be such that $\Delta_y v = -\delta_x$ and $v(x,y) = 0$ for $y \in \partial D$, and $\forall x \in D$. Suppose $u$ is a harmonic function with (integrable) boundary data $f$. Then the above gives $$u(x) = -\int_{\partial D}f\frac{\partial v}{\partial \nu}.$$ So $u$ is the unique such function, and altering $f$ on a set of measure zero should make no difference. Is this argument correct? This arose from trying to show that an analytic function defined on an infinite wedge in $\mathbb{C}$, for which we knew the real part on the boundary (except for two points), is unique up to an additive imaginary constant.","In the answer to this question, a helpful Stack user said that the Poisson kernel does not necessarily give a unique harmonic function, given certain boundary data (in particular on the upper half-plane). I had learned that it did, based on the following argument: take the Green's identity $$\int_D u\Delta v - v\Delta u \,\,dV = \int_{\partial D} u \frac{\partial v}{\partial \nu} - v \frac{\partial u}{\partial \nu}d\sigma.$$ Now take $v(x,y)$ to be such that $\Delta_y v = -\delta_x$ and $v(x,y) = 0$ for $y \in \partial D$, and $\forall x \in D$. Suppose $u$ is a harmonic function with (integrable) boundary data $f$. Then the above gives $$u(x) = -\int_{\partial D}f\frac{\partial v}{\partial \nu}.$$ So $u$ is the unique such function, and altering $f$ on a set of measure zero should make no difference. Is this argument correct? This arose from trying to show that an analytic function defined on an infinite wedge in $\mathbb{C}$, for which we knew the real part on the boundary (except for two points), is unique up to an additive imaginary constant.",,"['multivariable-calculus', 'harmonic-functions', 'potential-theory']"
41,How to integrate this double integral?,How to integrate this double integral?,,"$$\iint \limits_D 2x^2e^{x^2+y^2}-2y^2e^{x^2+y^2} dydx $$ where D is the region $x^2+y^2=4$ I tried changing it to polar, but it didn't make any use. $\iint \limits_{D(r,\theta)}2r^3\cos2\theta e^{r^2} drd\theta$  This integral also seems difficult to integrate.","$$\iint \limits_D 2x^2e^{x^2+y^2}-2y^2e^{x^2+y^2} dydx $$ where D is the region $x^2+y^2=4$ I tried changing it to polar, but it didn't make any use. $\iint \limits_{D(r,\theta)}2r^3\cos2\theta e^{r^2} drd\theta$  This integral also seems difficult to integrate.",,"['calculus', 'integration', 'multivariable-calculus']"
42,How to find the integral by changing the coordinates?,How to find the integral by changing the coordinates?,,"Let R be the region in the first quadrant where $$3 \geq y-x \geq 0$$ $$5 \geq xy \geq2$$ Compute $$\int_A (x^2-y^2)\,dx\,dy.$$ I tried to use $ u= y-x, v= xy$ as my change of coordinates, but then I don't know how to solve it. Can someone help me?","Let R be the region in the first quadrant where $$3 \geq y-x \geq 0$$ $$5 \geq xy \geq2$$ Compute $$\int_A (x^2-y^2)\,dx\,dy.$$ I tried to use $ u= y-x, v= xy$ as my change of coordinates, but then I don't know how to solve it. Can someone help me?",,"['integration', 'multivariable-calculus', 'coordinate-systems']"
43,Double integral over circular surface,Double integral over circular surface,,"I've decided to finish my education through completing my last exam (I've been working for 5 years). The exam is in multivariable calculus and I took the classes 6 years ago so I am very rusty. Will ask a bunch of questions over the following weeks and I love you all for helping me. I got this from an exam answer: $$\iint\limits_S F\cdot dS=\iint\limits_{x^2+y^2\le1}F(x,y,2)\cdot (0,0,1)dxdy= 2\pi$$ I presume it goes $$..\iint\limits_{x^2+y^2\le1}F(x,y,2)\cdot (0,0,1)dxdy=\iint\limits_{x^2+y^2\le1}0x+0y+2dxdy=\iint\limits_{x^2+y^2\le1}2dxdy=..$$ But how to think for that last step to get $2\pi$ ? I have never solved a double integral over a joined surface like that. I relise that $2\pi$ is a full circle, but I would like to know exactly why I get that answer in this case.","I've decided to finish my education through completing my last exam (I've been working for 5 years). The exam is in multivariable calculus and I took the classes 6 years ago so I am very rusty. Will ask a bunch of questions over the following weeks and I love you all for helping me. I got this from an exam answer: $$\iint\limits_S F\cdot dS=\iint\limits_{x^2+y^2\le1}F(x,y,2)\cdot (0,0,1)dxdy= 2\pi$$ I presume it goes $$..\iint\limits_{x^2+y^2\le1}F(x,y,2)\cdot (0,0,1)dxdy=\iint\limits_{x^2+y^2\le1}0x+0y+2dxdy=\iint\limits_{x^2+y^2\le1}2dxdy=..$$ But how to think for that last step to get $2\pi$ ? I have never solved a double integral over a joined surface like that. I relise that $2\pi$ is a full circle, but I would like to know exactly why I get that answer in this case.",,"['integration', 'multivariable-calculus']"
44,Length of a curve given by an equation $ r(t)$,Length of a curve given by an equation, r(t),"Find the length of the space curve given by $$r(t) = 2t\,\mathbf{i} + 5\cos(t)\,\mathbf{j} + 5\sin(t)\,\mathbf{k}$$ over the interval $[0,2]$. I did this and I got the answer as 10.77 Did I get the right answer? please help me i'm not very good at this.","Find the length of the space curve given by $$r(t) = 2t\,\mathbf{i} + 5\cos(t)\,\mathbf{j} + 5\sin(t)\,\mathbf{k}$$ over the interval $[0,2]$. I did this and I got the answer as 10.77 Did I get the right answer? please help me i'm not very good at this.",,['multivariable-calculus']
45,Prove this vector identity using vector identities,Prove this vector identity using vector identities,,"Let $f$, $g$ and $h$ be any $C^{2}$ scalar functions. Using the standard identities of vector calculus, prove that; $$ \nabla \cdot \left( f\nabla g \times \nabla h \right) = \nabla f \cdot \left(\nabla g \times \nabla h \right)$$ Here is my working out so far;    using identity 8    $$ \nabla \cdot \left( f\nabla g \times \nabla h \right) = \nabla h \cdot \left(\nabla  \times f\nabla h \right) - f\nabla g \cdot \left( \nabla \cdot \nabla h \right)  $$ and the div of a scalar is a vector hence $$  = \overrightarrow H \cdot \left(\nabla  \times f\nabla \overrightarrow G \right) - f\nabla \overrightarrow G \cdot \left( \nabla \cdot \overrightarrow H \right) $$ and then using vector identity 10 gives me $$= \overrightarrow H \cdot \left(f\nabla  \times \overrightarrow G +\nabla f  \times \overrightarrow G\right) - f\nabla \overrightarrow G \cdot \left( \nabla \cdot \overrightarrow H \right) $$  and now I don't know whats next? Here are the vector identities listed below","Let $f$, $g$ and $h$ be any $C^{2}$ scalar functions. Using the standard identities of vector calculus, prove that; $$ \nabla \cdot \left( f\nabla g \times \nabla h \right) = \nabla f \cdot \left(\nabla g \times \nabla h \right)$$ Here is my working out so far;    using identity 8    $$ \nabla \cdot \left( f\nabla g \times \nabla h \right) = \nabla h \cdot \left(\nabla  \times f\nabla h \right) - f\nabla g \cdot \left( \nabla \cdot \nabla h \right)  $$ and the div of a scalar is a vector hence $$  = \overrightarrow H \cdot \left(\nabla  \times f\nabla \overrightarrow G \right) - f\nabla \overrightarrow G \cdot \left( \nabla \cdot \overrightarrow H \right) $$ and then using vector identity 10 gives me $$= \overrightarrow H \cdot \left(f\nabla  \times \overrightarrow G +\nabla f  \times \overrightarrow G\right) - f\nabla \overrightarrow G \cdot \left( \nabla \cdot \overrightarrow H \right) $$  and now I don't know whats next? Here are the vector identities listed below",,"['multivariable-calculus', 'vector-analysis']"
46,Calculating partial derivatives,Calculating partial derivatives,,"Let f and g be functions of one real variable and define $F(x,y)=f[x+g(y)]$. Find formulas for all the partial derivatives of F of first and second order. For the first order, I think we have: $\frac{\partial F}{\partial x}=\frac{\partial f}{\partial x}+ \frac{\partial f}{\partial y}$ $\frac{\partial F}{\partial y}=\frac{\partial f}{\partial x}g'(x)+ \frac{\partial f}{\partial y}g'(y)$ Is it correct? What are the second order derivatives? Thank you","Let f and g be functions of one real variable and define $F(x,y)=f[x+g(y)]$. Find formulas for all the partial derivatives of F of first and second order. For the first order, I think we have: $\frac{\partial F}{\partial x}=\frac{\partial f}{\partial x}+ \frac{\partial f}{\partial y}$ $\frac{\partial F}{\partial y}=\frac{\partial f}{\partial x}g'(x)+ \frac{\partial f}{\partial y}g'(y)$ Is it correct? What are the second order derivatives? Thank you",,['multivariable-calculus']
47,How to prove limit of $2$ variables?,How to prove limit of  variables?,2,"I know that the following limit exists, and is $1$, but I don't know how to prove it. I know of the definition of a limit ""If $0 < (x^2 + y^2)^{1/2} < \delta$ Then $f-L < \epsilon$"" but I am finding it difficult to grasp that concept to a point where I can put it to use. Any help would be greatly appreciated. $$ \lim_{(x,y)\to(0,0)} \frac{e^{x^2+y^2}-1}{x^2+y^2} $$","I know that the following limit exists, and is $1$, but I don't know how to prove it. I know of the definition of a limit ""If $0 < (x^2 + y^2)^{1/2} < \delta$ Then $f-L < \epsilon$"" but I am finding it difficult to grasp that concept to a point where I can put it to use. Any help would be greatly appreciated. $$ \lim_{(x,y)\to(0,0)} \frac{e^{x^2+y^2}-1}{x^2+y^2} $$",,"['calculus', 'limits', 'multivariable-calculus']"
48,Using triple integral to find the volume of a sphere with cylindrical coordinates,Using triple integral to find the volume of a sphere with cylindrical coordinates,,"I'm reviewing for my Calculus 3 midterm, and one of the practice problems I'm going over asks to find the volume of the below solid 1. by using a triple integral with spherical coordinates, and 2. by using a triple integral with cylindrical coordinates. I'm able to do the integral with spherical coordinates, but I'm getting confused on the one with cylindrical coordinates.  In my notes I have written that the cylindrical volume should be: $$dv = r\ dr\ d\theta\ dz$$ Looking at the solution to this problem, it is integrated in the order: $dz\ dr\ d \theta$ , I'm not sure what the point is of changing the integration order? Also, the bounds in the solution for the integral with respect to $z$ are from $0$ to $\sqrt{4-r^2}$, and I'm not sure where that is coming from either? Any help would be greatly appreciated.","I'm reviewing for my Calculus 3 midterm, and one of the practice problems I'm going over asks to find the volume of the below solid 1. by using a triple integral with spherical coordinates, and 2. by using a triple integral with cylindrical coordinates. I'm able to do the integral with spherical coordinates, but I'm getting confused on the one with cylindrical coordinates.  In my notes I have written that the cylindrical volume should be: $$dv = r\ dr\ d\theta\ dz$$ Looking at the solution to this problem, it is integrated in the order: $dz\ dr\ d \theta$ , I'm not sure what the point is of changing the integration order? Also, the bounds in the solution for the integral with respect to $z$ are from $0$ to $\sqrt{4-r^2}$, and I'm not sure where that is coming from either? Any help would be greatly appreciated.",,"['calculus', 'multivariable-calculus']"
49,A Few Questions Concerning Vectors,A Few Questions Concerning Vectors,,"In my textbook, they provide a theorem to calculate the angle between two vectors: $\cos\theta = \Large\frac{\vec{u} \cdot \vec{v}}{\|\vec{u}\|\|\vec{v}\|}$ My questions are, why does the angle have to be $0 \le \theta \le \pi$; and why do the vectors have to be in standard position? Also, on the next page, the author writes, ""the zero vector is orthogonal to every vector because $0 \cdot \vec{u} = 0$;"" why is that so?","In my textbook, they provide a theorem to calculate the angle between two vectors: $\cos\theta = \Large\frac{\vec{u} \cdot \vec{v}}{\|\vec{u}\|\|\vec{v}\|}$ My questions are, why does the angle have to be $0 \le \theta \le \pi$; and why do the vectors have to be in standard position? Also, on the next page, the author writes, ""the zero vector is orthogonal to every vector because $0 \cdot \vec{u} = 0$;"" why is that so?",,"['calculus', 'multivariable-calculus']"
50,Parametric equation of a cone,Parametric equation of a cone,,"I usually use the following parametric equation to find the surface area of a regular cone $z=\sqrt{x^2+y^2}$: $$x=r\cos\theta$$ $$y=r\sin\theta$$ $$z=r$$ And make $0\leq r \leq 2\pi$, $0 \leq \theta \leq 2\pi$. I've now have a cone $z=\sqrt{2x^2+2y^2}$ and I think the parametric equation I normally use won't work anymore. Which would be a more suitable one in this case? Is there any generic parametric equation for cones, because one of the form $z=\sqrt{4x^2+y^2}$ would also have a different one.","I usually use the following parametric equation to find the surface area of a regular cone $z=\sqrt{x^2+y^2}$: $$x=r\cos\theta$$ $$y=r\sin\theta$$ $$z=r$$ And make $0\leq r \leq 2\pi$, $0 \leq \theta \leq 2\pi$. I've now have a cone $z=\sqrt{2x^2+2y^2}$ and I think the parametric equation I normally use won't work anymore. Which would be a more suitable one in this case? Is there any generic parametric equation for cones, because one of the form $z=\sqrt{4x^2+y^2}$ would also have a different one.",,"['multivariable-calculus', 'conic-sections', 'parametric']"
51,double integral with change of variables,double integral with change of variables,,"I try to understand change of variables for double integrals. For this reason I try to calculate $\int_0^{\pi/2}\int_0^{\pi/2}\cos\theta\cos{\phi}\,d\theta d\phi$ by using this change $\alpha=\theta+\phi$, $\beta=\theta-\phi$ and $\cos\theta\cos\phi=\frac{1}{2}(\cos\alpha+\cos\beta)$. I repeat I know how to calculate the first integral and this is just an exercise for me. I found that the Jacobian is $J=-\frac{1}{2}$ but I even don't found on which surface I have to integrate! Does somebody have an idea?","I try to understand change of variables for double integrals. For this reason I try to calculate $\int_0^{\pi/2}\int_0^{\pi/2}\cos\theta\cos{\phi}\,d\theta d\phi$ by using this change $\alpha=\theta+\phi$, $\beta=\theta-\phi$ and $\cos\theta\cos\phi=\frac{1}{2}(\cos\alpha+\cos\beta)$. I repeat I know how to calculate the first integral and this is just an exercise for me. I found that the Jacobian is $J=-\frac{1}{2}$ but I even don't found on which surface I have to integrate! Does somebody have an idea?",,"['calculus', 'integration', 'multivariable-calculus']"
52,Partial Derivatives and Linear Map,Partial Derivatives and Linear Map,,"Proposition: Suppose that $T : R^n \to R^m$ is the linear transformation defined by $T(x) = Mx$ for some m × n matrix $M$. Then $DT(x) = M$ for all points $x \in R^n$ where $D$ is the partial derivative matrix. (Jacobian?) Question: I don't understand what is being said. $T(x)$ is a linear transformation on $x$. How does the partial derivative of $T(x)$ lead to the transformation matrix. Neither do I have an algebraic intuition nor a geometric one. Further, How is the total derivative of $g(x,y,z)$ equal to $ Dg(x,y,z) \begin{pmatrix} x \\ y\\ z \end{pmatrix}$? This is stated without proof. There is a chance, I made a wrong interpretation so I am pasting the portion of the text where it appears. Is it that the change in $x$ in all dimensions of the output of $g(x,y,z)$ multiplied by $x$ and similar for y and z gives a total derivative. I don't seem to understand.I know the total derivative is a derivative taking into account that other variables are not constant during differentiation by one variable.","Proposition: Suppose that $T : R^n \to R^m$ is the linear transformation defined by $T(x) = Mx$ for some m × n matrix $M$. Then $DT(x) = M$ for all points $x \in R^n$ where $D$ is the partial derivative matrix. (Jacobian?) Question: I don't understand what is being said. $T(x)$ is a linear transformation on $x$. How does the partial derivative of $T(x)$ lead to the transformation matrix. Neither do I have an algebraic intuition nor a geometric one. Further, How is the total derivative of $g(x,y,z)$ equal to $ Dg(x,y,z) \begin{pmatrix} x \\ y\\ z \end{pmatrix}$? This is stated without proof. There is a chance, I made a wrong interpretation so I am pasting the portion of the text where it appears. Is it that the change in $x$ in all dimensions of the output of $g(x,y,z)$ multiplied by $x$ and similar for y and z gives a total derivative. I don't seem to understand.I know the total derivative is a derivative taking into account that other variables are not constant during differentiation by one variable.",,"['linear-algebra', 'multivariable-calculus']"
53,Examine function extreme values,Examine function extreme values,,"I am studying for multivariable calculus exam and in homework we always had specific task regarding extreme values: find absolute minima, find local maxima, etc. In real exam questions are more like ""Examine function extreme values"". What are the steps that should be done for complete examination of function $f(x,y)$ extreme values?","I am studying for multivariable calculus exam and in homework we always had specific task regarding extreme values: find absolute minima, find local maxima, etc. In real exam questions are more like ""Examine function extreme values"". What are the steps that should be done for complete examination of function $f(x,y)$ extreme values?",,"['multivariable-calculus', 'optimization']"
54,A double integral (differentiation under the integral sign),A double integral (differentiation under the integral sign),,"While working on a physics problem, I got the following double integral that depends on the parameter $a$ : $$I(a)=\int_{0}^{L}\int_{0}^{L}\sqrt{a}e^{-a(x-y+b)^2}dxdy$$ where $L$ and $b$ are constants. Now, this integral obviously has no closed form in terms of elementary functions. However, it follows from physical considerations that the derivative of this integral $\frac{dI}{da}$ has a closed form solution in terms of exponential functions. Unfortunately, my mathematical abilities are not good enough to get this result directly from the integral. So, how does a mathematician solve this problem?","While working on a physics problem, I got the following double integral that depends on the parameter : where and are constants. Now, this integral obviously has no closed form in terms of elementary functions. However, it follows from physical considerations that the derivative of this integral has a closed form solution in terms of exponential functions. Unfortunately, my mathematical abilities are not good enough to get this result directly from the integral. So, how does a mathematician solve this problem?",a I(a)=\int_{0}^{L}\int_{0}^{L}\sqrt{a}e^{-a(x-y+b)^2}dxdy L b \frac{dI}{da},"['integration', 'multivariable-calculus', 'closed-form']"
55,Find the Jacobian,Find the Jacobian,,"Find the Jacobian $$\frac{\partial(x,y)}{\partial(u,v)}$$ for $x=u^2+v^2$, $y=u^2-v^2$. My solution: I tried solving it as it is by using the Jacobian matrix (determinant?) and got my answer to be $-8uv$. I think the answer is wrong since the answers in my book are all purely numerical. Is there something that I have to do to these equations to make them non-polynomials ?","Find the Jacobian $$\frac{\partial(x,y)}{\partial(u,v)}$$ for $x=u^2+v^2$, $y=u^2-v^2$. My solution: I tried solving it as it is by using the Jacobian matrix (determinant?) and got my answer to be $-8uv$. I think the answer is wrong since the answers in my book are all purely numerical. Is there something that I have to do to these equations to make them non-polynomials ?",,[]
56,Source of the definition of integrating a form along a curve in a manifold,Source of the definition of integrating a form along a curve in a manifold,,"Suppose that $M$ is a smooth manifold. Let $\omega$ be an $n-$ form on $M$ with compact support. Then we define $\int_M\omega$ using partitions of unity. If $M$ is covered by a single chart $h:M\to \mathbb R^n$ , then we define $\int_M\omega:= \int_{\mathbb R^n} (h^{-1})^\ast \omega$ , where $\ast$ denotes pullback. $\tag 1$ But often the following definition is stated: $\int_{\gamma} \omega := \int_{[0,1]} \gamma^\ast \omega$ , where $\gamma:[0,1]\to M$ is a smooth curve and $\omega$ is a $1$ - form on $M$ . $\tag 2$ My questions are: $(a)$ what is the source of the definition in $(2)$ ? $(b)$ Does this somehow follow from the definition in $(1)$ ? I think the answer to $(b)$ is no because taking the definition in $(1)$ to be a general definition, the term $\int_{\gamma} \omega$ makes sense iff $\gamma[0,1]$ is a $1$ - manifold but that's not the case in general: Smooth image of a $1$ - manifold is not necessarily a manifold. That brings me back to $(a)$ . I didn't find the definition $(2)$ neither in Tu's book nor in Lee's book nor in Spivak's. Can anyone please direct me to where the definition $(2)$ has been stated?","Suppose that is a smooth manifold. Let be an form on with compact support. Then we define using partitions of unity. If is covered by a single chart , then we define , where denotes pullback. But often the following definition is stated: , where is a smooth curve and is a - form on . My questions are: what is the source of the definition in ? Does this somehow follow from the definition in ? I think the answer to is no because taking the definition in to be a general definition, the term makes sense iff is a - manifold but that's not the case in general: Smooth image of a - manifold is not necessarily a manifold. That brings me back to . I didn't find the definition neither in Tu's book nor in Lee's book nor in Spivak's. Can anyone please direct me to where the definition has been stated?","M \omega n- M \int_M\omega M h:M\to \mathbb R^n \int_M\omega:= \int_{\mathbb R^n} (h^{-1})^\ast \omega \ast \tag 1 \int_{\gamma} \omega := \int_{[0,1]} \gamma^\ast \omega \gamma:[0,1]\to M \omega 1 M \tag 2 (a) (2) (b) (1) (b) (1) \int_{\gamma} \omega \gamma[0,1] 1 1 (a) (2) (2)","['integration', 'multivariable-calculus', 'differential-geometry', 'algebraic-topology', 'reference-request']"
57,How to minimize an expression to show the norm,How to minimize an expression to show the norm,,"I'm quite surprised I can't solve this problem. Given the following function : $\forall\left(x,y\right)\in\mathbb{R}^{2},\quad f(x,y)=x^{4}+y^{4}-2(x-y)^{2}$ show that $\forall\left(x,y\right)\in\mathbb{R}^{2} \quad f(x,y)\geq{\frac{1}{2}}(x^{2}+y^{2})^{2}-4(x^{2}+y^{2})$ I show that $2(x-y)^{2} \leq 4(x^{2}+y^{2})$ Then I want to show that $x^{4}+y^{4} \geq  \frac{1}{2}(x^{2}+y^{2})^{2}$ But it's here that I'm struggling, I can only show that $x^{4}+y^{4} \geq 2x^{2}y^{2}$ And I can't go further. I know that you can solve the exercice the other way around, by maximizing $\frac{1}{2}(x^{2}+y^{2})^{2}$ , but I want to understand, how you can do it without knowing the result, in the case I have to show in the future that a function is infinite. Thanks everyone","I'm quite surprised I can't solve this problem. Given the following function : show that I show that Then I want to show that But it's here that I'm struggling, I can only show that And I can't go further. I know that you can solve the exercice the other way around, by maximizing , but I want to understand, how you can do it without knowing the result, in the case I have to show in the future that a function is infinite. Thanks everyone","\forall\left(x,y\right)\in\mathbb{R}^{2},\quad f(x,y)=x^{4}+y^{4}-2(x-y)^{2} \forall\left(x,y\right)\in\mathbb{R}^{2} \quad f(x,y)\geq{\frac{1}{2}}(x^{2}+y^{2})^{2}-4(x^{2}+y^{2}) 2(x-y)^{2} \leq 4(x^{2}+y^{2}) x^{4}+y^{4} \geq  \frac{1}{2}(x^{2}+y^{2})^{2} x^{4}+y^{4} \geq 2x^{2}y^{2} \frac{1}{2}(x^{2}+y^{2})^{2}","['calculus', 'multivariable-calculus', 'inequality']"
58,Power of a laser beam,Power of a laser beam,,"I have the following function $$u(x,y,z)=\frac{Ak_0w_0^2}{2iz+k_0w_0^2}\exp\left(-k_0\frac{x^2+y^2}{2iz+k_0w_0^2}\right),$$ where $A,k_0,w_0$ are constants. I want to compute the following quantity $$P=\int\int_{\mathbb{R}^2}|u(x,y,z)|^2dxdy,$$ showing that it does not depend on $z$ . I dont really know how to deal with $|u(x,y,z)|$ . I tried to separate $$\frac{1}{2iz+k_0w_0^2},$$ into real and imaginary part but i don't end up with something manageable. Any help will be very appreciated! EDITED: Asuming $z>0$ , from @K.dfaoite answer $$G(z)=\iint_{\mathbb R^2}|u(x,y;z)|^2\mathrm dx\mathrm dy \\ =\left|\frac{Ak_0{\omega_0}^2}{2\mathrm iz+k_0{\omega_0}^2}\right|^2\iint_{\mathbb R^2}\exp\left[-2 \mathfrak R\left(\frac{k_0}{2\mathrm iz+k_0{\omega_0}^2}\right)~(x^2+y^2)\right]\mathrm dx\mathrm dy.$$ Since $$\frac{1}{2iz+k_0w_0^2}=\frac{k_0w_0^2-2iz}{(k_0w_0^2)^2-4z^2}.$$ we have that $$-2 \mathfrak R\left(\frac{k_0}{2\mathrm iz+k_0{\omega_0}^2}\right)=-\frac{2k_0^2w_0^2}{k_0^2w_0^4-4z^2},$$ so $$\iint_{\mathbb R^2}\exp\left[-2 \mathfrak R\left(\frac{k_0}{2\mathrm iz+k_0{\omega_0}^2}\right)~(x^2+y^2)\right]\mathrm dx\mathrm dy=\pi\frac{k_0^2w_0^4-4z^2}{2k_0^2w_0^2}.$$ On the other hand $$\left|\frac{Ak_0{\omega_0}^2}{2\mathrm iz+k_0{\omega_0}^2}\right|^2=A^2k_0^4w_0^4\left|\frac{1}{2iz+k_0w_0^2}\right|^2=\frac{A^2k_0^2w_0^4}{(k_0^2w_0^4-4z^2)^2}(k_0^2w_0^4+4z^2),$$ using both thins we clearly see that the power $P$ does depend on $z$ , $$P=\frac{\pi A^2w_0^2}{2}\frac{k_0^2w_0^4+4z^2}{k_0^2w_0^4-4z^2},$$ which is not the result that should be... I don't see any mistake. Any help will be very appreciated!!","I have the following function where are constants. I want to compute the following quantity showing that it does not depend on . I dont really know how to deal with . I tried to separate into real and imaginary part but i don't end up with something manageable. Any help will be very appreciated! EDITED: Asuming , from @K.dfaoite answer Since we have that so On the other hand using both thins we clearly see that the power does depend on , which is not the result that should be... I don't see any mistake. Any help will be very appreciated!!","u(x,y,z)=\frac{Ak_0w_0^2}{2iz+k_0w_0^2}\exp\left(-k_0\frac{x^2+y^2}{2iz+k_0w_0^2}\right), A,k_0,w_0 P=\int\int_{\mathbb{R}^2}|u(x,y,z)|^2dxdy, z |u(x,y,z)| \frac{1}{2iz+k_0w_0^2}, z>0 G(z)=\iint_{\mathbb R^2}|u(x,y;z)|^2\mathrm dx\mathrm dy \\ =\left|\frac{Ak_0{\omega_0}^2}{2\mathrm iz+k_0{\omega_0}^2}\right|^2\iint_{\mathbb R^2}\exp\left[-2 \mathfrak R\left(\frac{k_0}{2\mathrm iz+k_0{\omega_0}^2}\right)~(x^2+y^2)\right]\mathrm dx\mathrm dy. \frac{1}{2iz+k_0w_0^2}=\frac{k_0w_0^2-2iz}{(k_0w_0^2)^2-4z^2}. -2 \mathfrak R\left(\frac{k_0}{2\mathrm iz+k_0{\omega_0}^2}\right)=-\frac{2k_0^2w_0^2}{k_0^2w_0^4-4z^2}, \iint_{\mathbb R^2}\exp\left[-2 \mathfrak R\left(\frac{k_0}{2\mathrm iz+k_0{\omega_0}^2}\right)~(x^2+y^2)\right]\mathrm dx\mathrm dy=\pi\frac{k_0^2w_0^4-4z^2}{2k_0^2w_0^2}. \left|\frac{Ak_0{\omega_0}^2}{2\mathrm iz+k_0{\omega_0}^2}\right|^2=A^2k_0^4w_0^4\left|\frac{1}{2iz+k_0w_0^2}\right|^2=\frac{A^2k_0^2w_0^4}{(k_0^2w_0^4-4z^2)^2}(k_0^2w_0^4+4z^2), P z P=\frac{\pi A^2w_0^2}{2}\frac{k_0^2w_0^4+4z^2}{k_0^2w_0^4-4z^2},","['complex-analysis', 'multivariable-calculus', 'definite-integrals']"
59,How do we prove that $(x^2 + y^2)^2 + x^2 + y^2 < 1$ is a disk?,How do we prove that  is a disk?,(x^2 + y^2)^2 + x^2 + y^2 < 1,"How do I see that $(x^2 + y^2)^2 + x^2 + y^2 < 1$ is a disk? I plotted it in wolfram alpha and it looks like a disk, but I don't know how to show it algebraically. Even if we write in polar coordinates, $r^4 + r^2 < 1$ , I don't know why this is a disk. Isn't a disk $r^2 < 1$ ?","How do I see that is a disk? I plotted it in wolfram alpha and it looks like a disk, but I don't know how to show it algebraically. Even if we write in polar coordinates, , I don't know why this is a disk. Isn't a disk ?",(x^2 + y^2)^2 + x^2 + y^2 < 1 r^4 + r^2 < 1 r^2 < 1,"['algebra-precalculus', 'multivariable-calculus']"
60,Is a vector field irrotational iff its Jacobian is symmetric?,Is a vector field irrotational iff its Jacobian is symmetric?,,"Let $F: \mathbb R^n \to \mathbb R^n$ be a smooth vector field.  I conjecture that $F$ is irrotational iff its Jacobian is a symmetric matrix. In two and three dimensions, this seems clear from Green and Stokes theorem.  I conjecture this is true for any $n$ dimensions. Is this true? If so, it raises a few additional questions: We normally use curl to describe a vector field.  Can we use curl, or at least its magnitude, to describe matrices? That is, can we use the magnitude of curl to measure how much a matrix rotates, or how non symmetric it is? Can we use the components of curl to tell us the nature of this asymmetry / rotation? Would it be correct to say that for any two distinct dimensions $i, j$ , that the measure of asymmetry $A_{ij} - A_{ji}$ is a measure of how much the matrix rotates a vector in the $i,j$ plane? There are many well known types of matrices with interesting properties (e.g. orthogonal).  If the Jacobian of $F$ is an ""interesting"" matrix, what does it tell us about $F$ ? For example, if $J(F)$ is orthogonal?","Let be a smooth vector field.  I conjecture that is irrotational iff its Jacobian is a symmetric matrix. In two and three dimensions, this seems clear from Green and Stokes theorem.  I conjecture this is true for any dimensions. Is this true? If so, it raises a few additional questions: We normally use curl to describe a vector field.  Can we use curl, or at least its magnitude, to describe matrices? That is, can we use the magnitude of curl to measure how much a matrix rotates, or how non symmetric it is? Can we use the components of curl to tell us the nature of this asymmetry / rotation? Would it be correct to say that for any two distinct dimensions , that the measure of asymmetry is a measure of how much the matrix rotates a vector in the plane? There are many well known types of matrices with interesting properties (e.g. orthogonal).  If the Jacobian of is an ""interesting"" matrix, what does it tell us about ? For example, if is orthogonal?","F: \mathbb R^n \to \mathbb R^n F n i, j A_{ij} - A_{ji} i,j F F J(F)","['calculus', 'linear-algebra', 'geometry', 'multivariable-calculus', 'vector-analysis']"
61,A limit in two variables with absolute value,A limit in two variables with absolute value,,"I have to calculate (if it exists) the following limit: $$\lim_{(x,y)\rightarrow(0,0)}\frac{\ln(1+|xy|)}{x^{2}+y^{2}}.$$ What I did is simply to consider that $\ln(1+\theta)\sim\theta$ as $\theta\rightarrow 0$ . So I have the limit: $$\lim_{(x,y)\rightarrow(0,0)}\frac{|xy|}{x^{2}+y^{2}}.$$ I know the inequality: $$|x|+|y|\ge \sqrt{x^{2}+y^{2}}$$ which I used in the previous exercises, but here there is a product of absolute values and not a sum, so I think it is not useful. How should I proceed?","I have to calculate (if it exists) the following limit: What I did is simply to consider that as . So I have the limit: I know the inequality: which I used in the previous exercises, but here there is a product of absolute values and not a sum, so I think it is not useful. How should I proceed?","\lim_{(x,y)\rightarrow(0,0)}\frac{\ln(1+|xy|)}{x^{2}+y^{2}}. \ln(1+\theta)\sim\theta \theta\rightarrow 0 \lim_{(x,y)\rightarrow(0,0)}\frac{|xy|}{x^{2}+y^{2}}. |x|+|y|\ge \sqrt{x^{2}+y^{2}}",['multivariable-calculus']
62,Solving System of Equations Issue,Solving System of Equations Issue,,$$ \begin{aligned}  x^2+4y^2+9z^2 &= 1 \\  8yz+2ax &=0 \\  8zx+8ay &= 0\\   8xy+18az &= 0 \end{aligned}$$ How would I solve these equations? I tried making $a$ the subject of the final $3$ but struggling to solve it.,How would I solve these equations? I tried making the subject of the final but struggling to solve it.," \begin{aligned}
 x^2+4y^2+9z^2 &= 1 \\
 8yz+2ax &=0 \\
 8zx+8ay &= 0\\ 
 8xy+18az &= 0
\end{aligned} a 3","['real-analysis', 'linear-algebra', 'algebra-precalculus', 'multivariable-calculus', 'systems-of-equations']"
63,Need help evaluating double integral,Need help evaluating double integral,,"I need help calculating $I$ where: $$I = \iint_R\frac{dxdy}{\sqrt{1-x^2-y^2}}  ,\qquad R = \left\{ (x,y) \in \Bbb R^2 : x^2 + y^2 -x \le 0 , y \ge 0  \right\}$$ The possible answers are $\:\pi$ $\:2\pi-1$ $\:2\pi+2$ $\:\pi +1$ I have converted it to polar where I ended up with the integral: $$I = \int_0^\pi\int_0^{cos{\theta}}\frac{r}{\sqrt{1-r^2}}\:dr\:d\theta$$ I have tried evauluating it but the answer I get is: $\:\pi -2$ I took the following steps: $\int_0^{\cos\theta}\frac{r}{\sqrt{1-r^2}} ,\:u = 1-r^2,\: dr = \frac{-1}{2r}du$ $\int_0^{\cos\theta}\frac{r}{\sqrt{1-r^2}} =\int \frac{r}{\sqrt{u}}\frac{-1}{2r}du = \frac{-1}{2}\int\frac{1}{\sqrt{u}}du  = \frac{-1}{2}\left[2\sqrt{1-r^2} \right]_0^{\cos\theta} = -\sqrt{1-\cos^2\theta} \:\:+ 1 $ $-\sqrt{1-\cos^2\theta} \:\:+ 1  = 1 - \sin\theta$ $\int_0^\pi 1- \sin\theta \:d\theta = \int_0^\pi1\:d\theta + \int_0^\pi -\sin\theta \:d\theta$ $\int_0^\pi1\:d\theta = \pi$ $\int_0^\pi -\sin\theta \:d\theta = \left[ \cos\theta\right]_0^\pi = \cos(\pi) - \cos(0) = -2$ From steps 4, 5 and 6 we get $\:I = \pi -2$ Somewhere along these steps I have made a mistake and I can't find it.","I need help calculating where: The possible answers are I have converted it to polar where I ended up with the integral: I have tried evauluating it but the answer I get is: I took the following steps: From steps 4, 5 and 6 we get Somewhere along these steps I have made a mistake and I can't find it.","I I = \iint_R\frac{dxdy}{\sqrt{1-x^2-y^2}} 
,\qquad R = \left\{ (x,y) \in \Bbb R^2 : x^2 + y^2 -x \le 0 , y \ge 0  \right\} \:\pi \:2\pi-1 \:2\pi+2 \:\pi +1 I = \int_0^\pi\int_0^{cos{\theta}}\frac{r}{\sqrt{1-r^2}}\:dr\:d\theta \:\pi -2 \int_0^{\cos\theta}\frac{r}{\sqrt{1-r^2}} ,\:u = 1-r^2,\: dr = \frac{-1}{2r}du \int_0^{\cos\theta}\frac{r}{\sqrt{1-r^2}} =\int \frac{r}{\sqrt{u}}\frac{-1}{2r}du = \frac{-1}{2}\int\frac{1}{\sqrt{u}}du  = \frac{-1}{2}\left[2\sqrt{1-r^2} \right]_0^{\cos\theta} = -\sqrt{1-\cos^2\theta} \:\:+ 1  -\sqrt{1-\cos^2\theta} \:\:+ 1  = 1 - \sin\theta \int_0^\pi 1- \sin\theta \:d\theta = \int_0^\pi1\:d\theta + \int_0^\pi -\sin\theta \:d\theta \int_0^\pi1\:d\theta = \pi \int_0^\pi -\sin\theta \:d\theta = \left[ \cos\theta\right]_0^\pi = \cos(\pi) - \cos(0) = -2 \:I = \pi -2","['integration', 'multivariable-calculus', 'definite-integrals']"
64,"Supremum of the function $f(x,y,z,u)=\frac{x(1-x)y(1-y)z(1-u)}{1-(1-xy)z}$",Supremum of the function,"f(x,y,z,u)=\frac{x(1-x)y(1-y)z(1-u)}{1-(1-xy)z}","Consider a function $$f(x,y,z,u)=\frac{x(1-x)y(1-y)z(1-u)}{1-(1-xy)z} $$ where $x,y,z,u\in (0,1)$ I need the supremum of $f(x,y,z,u)$ for $x,y,z,u\in (0,1)$ We have $1-(1-xy)z=1-z+xyz$ Now since $x,y,z\in(0,1)$ , so we have $1-z>0$ and by AM-GM inequality $$1-(1-xy)z=1-z+xyz\geq 2\sqrt{(1-z)xyz}$$ So we have $$f(x,y,z,u)\leq \frac{1}{2} \frac{\sqrt{x}(1-x)\sqrt{y}(1-y)z(1-u)}{\sqrt{z(1-z)}} $$ Now if $G(x)=\sqrt{x}(1-x)$ and we put $t=\sqrt{x}$ then the supremum of $G(x)=t(1-t^2)$ occurs when $1-3t^3=0$ so at $t=\frac{1}{\sqrt{3}}$ so we have $$f(x,y,z,u)<\frac{1}{2}(\frac{\frac{1}{\sqrt{3}}(1-\frac{1}{3})\frac{1}{\sqrt{3}}(1-\frac{1}{3})z(1-u)}{\sqrt{z(1-z)}}) $$ So $$f(x,y,z,u)<\frac{2}{27}\frac{z(1-u)}{\sqrt{z(1-z)}}$$ Please solve this question.","Consider a function where I need the supremum of for We have Now since , so we have and by AM-GM inequality So we have Now if and we put then the supremum of occurs when so at so we have So Please solve this question.","f(x,y,z,u)=\frac{x(1-x)y(1-y)z(1-u)}{1-(1-xy)z}  x,y,z,u\in (0,1) f(x,y,z,u) x,y,z,u\in (0,1) 1-(1-xy)z=1-z+xyz x,y,z\in(0,1) 1-z>0 1-(1-xy)z=1-z+xyz\geq 2\sqrt{(1-z)xyz} f(x,y,z,u)\leq \frac{1}{2} \frac{\sqrt{x}(1-x)\sqrt{y}(1-y)z(1-u)}{\sqrt{z(1-z)}}  G(x)=\sqrt{x}(1-x) t=\sqrt{x} G(x)=t(1-t^2) 1-3t^3=0 t=\frac{1}{\sqrt{3}} f(x,y,z,u)<\frac{1}{2}(\frac{\frac{1}{\sqrt{3}}(1-\frac{1}{3})\frac{1}{\sqrt{3}}(1-\frac{1}{3})z(1-u)}{\sqrt{z(1-z)}})  f(x,y,z,u)<\frac{2}{27}\frac{z(1-u)}{\sqrt{z(1-z)}}","['real-analysis', 'calculus', 'multivariable-calculus', 'functions', 'supremum-and-infimum']"
65,Stokes' theorem on a triangle,Stokes' theorem on a triangle,,"I've been given a question that I'm having trouble figuring out: Calculate \begin{equation} \oint_{T} xydx + yzdy + zxdz \end{equation} using Stokes' theorem, where $T$ is the triangle with vertices on $(3,0,0)$ , $(0,-1,0)$ and $(0,0,-2)$ , oriented counter-clockwise from $(0,0,0)$ . Verify your answer by calculating the line integral directly. I have calculated the integral with Stokes' theorem by doing the following: The triangle $T$ lies on a plane \begin{equation} \frac{1}{3}x -y - \frac{1}{2}z = 1 \end{equation} which gives a normal unit vector $\vec{N}$ of \begin{equation} \vec{N} = \frac{2\vec{i} - 6\vec{j} - 3\vec{k}}{7} \end{equation} F the curl or $\vec{F}$ we have: \begin{equation} curl(\vec{F}) = -y\vec{i} -z\vec{j} -x\vec{k} \end{equation} Now for the integral: \begin{equation} \iint_{T}curl(\vec{F}) \cdot \vec{N}dS = \frac{1}{7}\iint_{T}-2y-6z-3xdS \end{equation} Using the previous plane for triangle $T$ we can get $z = -2 +\frac{2}{3}x -2y$ , making the integral \begin{equation} \frac{1}{7}\iint_{T}10y-7x+12dS \end{equation} My thought was that for the integration limits we have $0 \leq x \leq 3$ and $0 \leq y \leq -\frac{1}{3}x$ , but I'm not sure about the limits for $y$ . Filling all this in would give: \begin{equation} \frac{1}{7} \int_{x = 0}^{3}\int_{y=0}^{-\frac{1}{3}x}10y-7x+12dydx = \frac{8}{7} \end{equation} But now to verify this by calculating the line integral directly I don't know what to do, despite it sounding like it should be quite simple. For previous problems where I had to verify Stokes' theorem I could use a parametrization for the direct calculation, but I don't see how I can parameterize this triangle. I've thought about using Green's theorem, but that seems to work for integrals with a $dx$ and $dy$ part and not also a $dz$ part. I also can't find a single example in my book of a similar problem where they do this direct calculation","I've been given a question that I'm having trouble figuring out: Calculate using Stokes' theorem, where is the triangle with vertices on , and , oriented counter-clockwise from . Verify your answer by calculating the line integral directly. I have calculated the integral with Stokes' theorem by doing the following: The triangle lies on a plane which gives a normal unit vector of F the curl or we have: Now for the integral: Using the previous plane for triangle we can get , making the integral My thought was that for the integration limits we have and , but I'm not sure about the limits for . Filling all this in would give: But now to verify this by calculating the line integral directly I don't know what to do, despite it sounding like it should be quite simple. For previous problems where I had to verify Stokes' theorem I could use a parametrization for the direct calculation, but I don't see how I can parameterize this triangle. I've thought about using Green's theorem, but that seems to work for integrals with a and part and not also a part. I also can't find a single example in my book of a similar problem where they do this direct calculation","\begin{equation}
\oint_{T} xydx + yzdy + zxdz
\end{equation} T (3,0,0) (0,-1,0) (0,0,-2) (0,0,0) T \begin{equation}
\frac{1}{3}x -y - \frac{1}{2}z = 1
\end{equation} \vec{N} \begin{equation}
\vec{N} = \frac{2\vec{i} - 6\vec{j} - 3\vec{k}}{7}
\end{equation} \vec{F} \begin{equation}
curl(\vec{F}) = -y\vec{i} -z\vec{j} -x\vec{k}
\end{equation} \begin{equation}
\iint_{T}curl(\vec{F}) \cdot \vec{N}dS = \frac{1}{7}\iint_{T}-2y-6z-3xdS
\end{equation} T z = -2 +\frac{2}{3}x -2y \begin{equation}
\frac{1}{7}\iint_{T}10y-7x+12dS
\end{equation} 0 \leq x \leq 3 0 \leq y \leq -\frac{1}{3}x y \begin{equation}
\frac{1}{7} \int_{x = 0}^{3}\int_{y=0}^{-\frac{1}{3}x}10y-7x+12dydx = \frac{8}{7}
\end{equation} dx dy dz","['integration', 'multivariable-calculus', 'line-integrals', 'stokes-theorem']"
66,"Path dependence of $\lim\limits_{(n,m)\to(\infty, \infty)}\left(\sum_{i=1}^n \frac{1}{2^i}\right)^m$",Path dependence of,"\lim\limits_{(n,m)\to(\infty, \infty)}\left(\sum_{i=1}^n \frac{1}{2^i}\right)^m","I was wondering if $$\lim\limits_{n\to\infty} \left(1+\frac{1}{n}\right)^n =e$$ and the geometric series : $$\lim_{n\to∞}\sum_{i=1}^n \frac{1}{2^i}$$ will converge to 1 so  what will happen if i do this $$\lim\limits_{(n, m)\to (\infty, \infty)}\left(\sum\limits_{i=1}^n \frac{1}{2^i}\right)^m$$ will the answer will be $1$ or $e$ or will depend on the path of $n$ , $m$ ?","I was wondering if and the geometric series : will converge to 1 so  what will happen if i do this will the answer will be or or will depend on the path of , ?","\lim\limits_{n\to\infty} \left(1+\frac{1}{n}\right)^n =e \lim_{n\to∞}\sum_{i=1}^n \frac{1}{2^i} \lim\limits_{(n, m)\to (\infty, \infty)}\left(\sum\limits_{i=1}^n \frac{1}{2^i}\right)^m 1 e n m","['real-analysis', 'calculus', 'limits', 'multivariable-calculus']"
67,Compute $\int^2_0\int^2_y \frac{28}{3}(x^2+xy)dxdy$,Compute,\int^2_0\int^2_y \frac{28}{3}(x^2+xy)dxdy,"\begin{align*} \int^2_0\int^2_y \frac{28}{3}(x^2+xy)dxdy&=\frac{28}{3}\int^2_0\int^2_y x^2dxdy+\frac{28}{3}\int^2_0\int^2_y xydxdy\\ &=\frac{28}{3}\int^2_0\left[\frac{x^3}{3}\right]^2_ydx+\frac{28}{3}\times \int^2_0y \int^2_yx dxdy\\\ &=\frac{28}{3}\int^2_0\left(\frac{8-y^3}{3}\right)dy+\frac{28}{3} \times \int^2_0 y \times \left[\frac{x^2}{2}\right]^2_y dx \\ &=\frac{28}{3}\times\frac{1}{3}\int^2_08dy-\int^2_0y^3dy+\frac{28}{3}\times \int^2_0 y\left(2-\frac{y^2}{2}\right)dy\\ &=\frac{28}{3}\times\frac{1}{3}\times\left[8y\right]^2_0-\left[\frac{y^4}{4}\right]^2_0+\frac{28}{3}\times\int^2_0 y\times2\left(1-\frac{\frac{y^2}{2}}{2}\right)dy\\ &=\frac{28}{3}\times\frac{1}{3}(16-4)+\frac{28}{3}\times2\times \int^2_0 y\times\left(1-\frac{\frac{y^2}{2}}{2}\right)dy\\ &=\frac{28}{3}\times\frac{12}{3}+\frac{28}{3}\times2\times\int^2_0y\times\left(1-\frac{y^3}{4}\right)dy\\ &=\frac{28}{3}\times4+\frac{28}{3}\times2\times\int^2_0ydy-\frac{y^3}{4}dy\\ &=\frac{28}{3}\times4+\frac{28}{3}\times2\times\int^2_0y-\frac{1}{4}\times\int^2_0y^3dy\\ &=\frac{28}{3}\times4+\frac{28}{3}\times2\times \left[\frac{y^2}{2}\right]^2_0-\frac{1}{4}\times\left[\frac{y^4}{4}\right]^2_0\\ &=\frac{28}{3}\times4+\frac{28}{3}\times2\left(\frac{4}{2}-\frac{1}{4}\times\frac{16}{4}\right)\\ &=\frac{28}{3}\times4+\frac{28}{3}\times2\left(2-1\right)\\ &=\frac{28}{3}\times4+\frac{28}{3}\times2\\ &=56\\ \end{align*} I double-checked the solution in wolfram alpha and it's a match. However, would this be the best method in deriving the solution? Is there a more succinct method?","I double-checked the solution in wolfram alpha and it's a match. However, would this be the best method in deriving the solution? Is there a more succinct method?","\begin{align*}
\int^2_0\int^2_y \frac{28}{3}(x^2+xy)dxdy&=\frac{28}{3}\int^2_0\int^2_y x^2dxdy+\frac{28}{3}\int^2_0\int^2_y xydxdy\\
&=\frac{28}{3}\int^2_0\left[\frac{x^3}{3}\right]^2_ydx+\frac{28}{3}\times \int^2_0y \int^2_yx dxdy\\\
&=\frac{28}{3}\int^2_0\left(\frac{8-y^3}{3}\right)dy+\frac{28}{3} \times \int^2_0 y \times \left[\frac{x^2}{2}\right]^2_y dx \\
&=\frac{28}{3}\times\frac{1}{3}\int^2_08dy-\int^2_0y^3dy+\frac{28}{3}\times \int^2_0 y\left(2-\frac{y^2}{2}\right)dy\\
&=\frac{28}{3}\times\frac{1}{3}\times\left[8y\right]^2_0-\left[\frac{y^4}{4}\right]^2_0+\frac{28}{3}\times\int^2_0 y\times2\left(1-\frac{\frac{y^2}{2}}{2}\right)dy\\
&=\frac{28}{3}\times\frac{1}{3}(16-4)+\frac{28}{3}\times2\times \int^2_0 y\times\left(1-\frac{\frac{y^2}{2}}{2}\right)dy\\
&=\frac{28}{3}\times\frac{12}{3}+\frac{28}{3}\times2\times\int^2_0y\times\left(1-\frac{y^3}{4}\right)dy\\
&=\frac{28}{3}\times4+\frac{28}{3}\times2\times\int^2_0ydy-\frac{y^3}{4}dy\\
&=\frac{28}{3}\times4+\frac{28}{3}\times2\times\int^2_0y-\frac{1}{4}\times\int^2_0y^3dy\\
&=\frac{28}{3}\times4+\frac{28}{3}\times2\times \left[\frac{y^2}{2}\right]^2_0-\frac{1}{4}\times\left[\frac{y^4}{4}\right]^2_0\\
&=\frac{28}{3}\times4+\frac{28}{3}\times2\left(\frac{4}{2}-\frac{1}{4}\times\frac{16}{4}\right)\\
&=\frac{28}{3}\times4+\frac{28}{3}\times2\left(2-1\right)\\
&=\frac{28}{3}\times4+\frac{28}{3}\times2\\
&=56\\
\end{align*}","['integration', 'multivariable-calculus', 'solution-verification']"
68,(When) does $\text{body force}=\text{pressure gradient}=0\neq\text{fluid velocity}\implies0<\text{drag}$?,(When) does ?,\text{body force}=\text{pressure gradient}=0\neq\text{fluid velocity}\implies0<\text{drag},"I'm working on an unassessed course problem, A cylinder with radius $a_1$ moves parallel to its axis with constant positive velocity $U$ inside a stationary coaxial cylinder with radius $a_2(> a_1)$ . The region between the cylinders is filled with incompressible fluid. Assume that body forces can be ignored and that the pressure gradient in the direction parallel to the axis is zero. If the velocity in the fluid is in the direction of the axis, determine how it varies in the radial direction. I'm used to solving problems where (in)viscidity and/or steadiness are given, but here neither is. It would be convenient if I could reason as follows. Does this make sense? \begin{align} & \begin{aligned} \text{Let}&\\ & \vec{F}\text{ be body force per unit mass,} \\ & \vec{F}_D\text{ be drag per unit area,} \\ & \vec{u}\text{ be fluid velocity,} \\ & p\text{ be pressure,} \\ & \mu\text{ be viscosity;} \end{aligned} \\[1em] & \text{we have }\vec{F}=\vec{0},\;\frac{\partial p}{\partial z}=0\text{, but }0<u_z \\ \therefore\;&\text{we must have }\vec{F}_D\neq\vec{0}\text{ on the cylinder wall(s)} \tag{$\ast$} \\ \therefore\;&\text{we must have }0<\mu \\ \therefore\;&\text{by the no-slip condition, we must have } (u_z)_{r=a_1}=U\text{, a constant} \\ \therefore\;&\text{we must have }\frac{\partial u_z}{\partial t}=0 \\ \therefore\;&\text{by Navier-Stokes, (etc.)} \end{align} It's mainly $(\ast)$ I'm wondering about.","I'm working on an unassessed course problem, A cylinder with radius moves parallel to its axis with constant positive velocity inside a stationary coaxial cylinder with radius . The region between the cylinders is filled with incompressible fluid. Assume that body forces can be ignored and that the pressure gradient in the direction parallel to the axis is zero. If the velocity in the fluid is in the direction of the axis, determine how it varies in the radial direction. I'm used to solving problems where (in)viscidity and/or steadiness are given, but here neither is. It would be convenient if I could reason as follows. Does this make sense? It's mainly I'm wondering about.","a_1 U a_2(> a_1) \begin{align}
& \begin{aligned}
\text{Let}&\\
& \vec{F}\text{ be body force per unit mass,} \\
& \vec{F}_D\text{ be drag per unit area,} \\
& \vec{u}\text{ be fluid velocity,} \\
& p\text{ be pressure,} \\
& \mu\text{ be viscosity;}
\end{aligned} \\[1em]
& \text{we have }\vec{F}=\vec{0},\;\frac{\partial p}{\partial z}=0\text{, but }0<u_z \\
\therefore\;&\text{we must have }\vec{F}_D\neq\vec{0}\text{ on the cylinder wall(s)} \tag{\ast} \\
\therefore\;&\text{we must have }0<\mu \\
\therefore\;&\text{by the no-slip condition, we must have } (u_z)_{r=a_1}=U\text{, a constant} \\
\therefore\;&\text{we must have }\frac{\partial u_z}{\partial t}=0 \\
\therefore\;&\text{by Navier-Stokes, (etc.)}
\end{align} (\ast)","['multivariable-calculus', 'physics', 'classical-mechanics', 'fluid-dynamics']"
69,"What is the relationship among $a, b$ and $c$ for $\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\left(ax^2+2bxy+cy^2\right)}dx dy=1$",What is the relationship among  and  for,"a, b c \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}e^{-\left(ax^2+2bxy+cy^2\right)}dx dy=1","What relationship must hold between the constants $a, b$ and $c$ to make: $$ \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}{\rm e}^{-\left(\, ax^{2}\ +\ 2bxy\ +\ cy^2\,\right)}\phantom{A\,}{\rm d}x\,{\rm d}y = 1 $$ I am absolutely clueless on how to proceed with this question. I found a solution to this question on this website but the initial steps where it uses the transformation with the constraints on $\alpha, \beta, \gamma$ and $\delta$ is not clear to me. Like what was the intuition behind this transformation $?$ . I understand that the end result is somewhat similar to the initial assumptions, but how am I supposed to think of this particular transformation in an exam? I would appreciate any alternate answers/techniques to this question. Explanation(s) to the external linked solution are also welcome. Edit #1: As mentioned by fellow users in the comments, the link is hidden behind a paywall. Here's the crux of what was given as the solution: They used the transformation $$s=\alpha x+\beta y$$ $$t=\gamma x+\delta y$$ where $\left(\alpha\delta-\beta\gamma\right)^2=ac-b^2$ . Then they solved for $x$ and $y$ and proceeded with the Jacobian of the transformation and hence the given integral to obtain the required condition.","What relationship must hold between the constants and to make: I am absolutely clueless on how to proceed with this question. I found a solution to this question on this website but the initial steps where it uses the transformation with the constraints on and is not clear to me. Like what was the intuition behind this transformation . I understand that the end result is somewhat similar to the initial assumptions, but how am I supposed to think of this particular transformation in an exam? I would appreciate any alternate answers/techniques to this question. Explanation(s) to the external linked solution are also welcome. Edit #1: As mentioned by fellow users in the comments, the link is hidden behind a paywall. Here's the crux of what was given as the solution: They used the transformation where . Then they solved for and and proceeded with the Jacobian of the transformation and hence the given integral to obtain the required condition.","a, b c 
\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}{\rm e}^{-\left(\, ax^{2}\ +\ 2bxy\ +\ cy^2\,\right)}\phantom{A\,}{\rm d}x\,{\rm d}y = 1
 \alpha, \beta, \gamma \delta ? s=\alpha x+\beta y t=\gamma x+\delta y \left(\alpha\delta-\beta\gamma\right)^2=ac-b^2 x y","['calculus', 'integration', 'multivariable-calculus', 'multiple-integral', 'jacobian']"
70,Multivariable chain rule to solve a third order derivative,Multivariable chain rule to solve a third order derivative,,"I came across this problem and I don't know how I should go about solving it: ""Express $\frac{\partial^3f}{\partial x^2\partial y}f(4x^2 + y, x + 1)$ in terms of partial derivatives of the function f"" I'm having a hard time grasping how these multivariable partial derivatives work. Earlier I had $f(x, y) = g(u(x,y), v(x,y))$ For which i had to express $\frac{\partial ^2f}{\partial x\partial y}$ In terms of partial derivatives of g, u and v and I got the following result: $\frac{\partial ^2g}{\partial x\partial u} \frac{\partial ^2u}{\partial x\partial y} + \frac{\partial ^2g}{\partial x\partial v}\frac{\partial ^2v}{\partial x\partial y}$ But I'm very much doubting that this is correct, considering that I dont really understand this topic yet and my Calculus book doesn't seem to help me understand it.","I came across this problem and I don't know how I should go about solving it: ""Express in terms of partial derivatives of the function f"" I'm having a hard time grasping how these multivariable partial derivatives work. Earlier I had For which i had to express In terms of partial derivatives of g, u and v and I got the following result: But I'm very much doubting that this is correct, considering that I dont really understand this topic yet and my Calculus book doesn't seem to help me understand it.","\frac{\partial^3f}{\partial x^2\partial y}f(4x^2 + y, x + 1) f(x, y) = g(u(x,y), v(x,y)) \frac{\partial ^2f}{\partial x\partial y} \frac{\partial ^2g}{\partial x\partial u} \frac{\partial ^2u}{\partial x\partial y} + \frac{\partial ^2g}{\partial x\partial v}\frac{\partial ^2v}{\partial x\partial y}","['multivariable-calculus', 'derivatives', 'partial-derivative', 'chain-rule']"
71,Double integral exercise - check answer,Double integral exercise - check answer,,"I need to calculate $$\mathop{\iint}_{R} (x^2 + y^2) \,dx \,dy $$ where $R$ is the region (in the plane) bounded by the lines $y=x$ , $x=2$ and the hyperbola $xy=1$ . To calculate this integral I broke $R$ into two regions. $R_1:0 \le x \le 1,   0 \le y \le x$ $R_2:1 \le x \le 2,   0 \le y \le 1/x$ And I calculated the integral of $(x^2 + y^2)$ over both of them. At the end I got this answer 47/24 but my book says the answer is 27/8 Which one is correct?","I need to calculate where is the region (in the plane) bounded by the lines , and the hyperbola . To calculate this integral I broke into two regions. And I calculated the integral of over both of them. At the end I got this answer 47/24 but my book says the answer is 27/8 Which one is correct?","\mathop{\iint}_{R} (x^2 + y^2) \,dx \,dy  R y=x x=2 xy=1 R R_1:0 \le x \le 1,   0 \le y \le x R_2:1 \le x \le 2,   0 \le y \le 1/x (x^2 + y^2)","['calculus', 'integration', 'multivariable-calculus']"
72,Basic questions in Real Analysis,Basic questions in Real Analysis,,"I started studying Real Analysis 3 and stumbled on the new definition of differentiability, approximation by line/plane. It seems easy to digest but I have some questions about it. Is $f(x,y)=x$ differentiable at $(0,0)$ ? I think it should be differentiable but I keep getting, it's not differentiable: $f(h_a,h_b)=f(0,0)+\alpha0+\beta0+g(0,0,h_a,h_b)$ gives that $g(0,0,h_a,h_b)=h_a$ and $g(0,0,h_a,h_b)$ divided by norm of $h$ approaches $\frac{1}{\sqrt{2}}$ if I take $h_a=h_b$ . Here, $g(a,b,h_a,h_b)$ is the error term and $f(a,b)+\alpha h_a+\beta h_b$ represents my plane for approximating the value of $f(a+h_a,b+h_b)$ . Is it not differentiable? --- This has been answered. Another question, let's say the partial derivative of a function w.r.t. $x$ and $y$ is $0$ . Based on my knowledge and physics background, I see that function is not changing along the $x$ and $y$ -axis. Doesn't it imply our particle at origin is not moving at all? If it changes in any direction then it must have components along the $x$ and $y$ -axis but there are no changes in those directions. Doesn't it imply that the function must be differential at the origin if partial derivatives are $0$ ? I know, there exist some continuous functions with partial derivatives $0$ at origin and are non-differentiable.","I started studying Real Analysis 3 and stumbled on the new definition of differentiability, approximation by line/plane. It seems easy to digest but I have some questions about it. Is differentiable at ? I think it should be differentiable but I keep getting, it's not differentiable: gives that and divided by norm of approaches if I take . Here, is the error term and represents my plane for approximating the value of . Is it not differentiable? --- This has been answered. Another question, let's say the partial derivative of a function w.r.t. and is . Based on my knowledge and physics background, I see that function is not changing along the and -axis. Doesn't it imply our particle at origin is not moving at all? If it changes in any direction then it must have components along the and -axis but there are no changes in those directions. Doesn't it imply that the function must be differential at the origin if partial derivatives are ? I know, there exist some continuous functions with partial derivatives at origin and are non-differentiable.","f(x,y)=x (0,0) f(h_a,h_b)=f(0,0)+\alpha0+\beta0+g(0,0,h_a,h_b) g(0,0,h_a,h_b)=h_a g(0,0,h_a,h_b) h \frac{1}{\sqrt{2}} h_a=h_b g(a,b,h_a,h_b) f(a,b)+\alpha h_a+\beta h_b f(a+h_a,b+h_b) x y 0 x y x y 0 0","['real-analysis', 'multivariable-calculus']"
73,Why isn't the directional derivative with respect to $-\vec v$ the same as the directional derivative with respect to $\vec v$?,Why isn't the directional derivative with respect to  the same as the directional derivative with respect to ?,-\vec v \vec v,"Suppose $f$ is a differentiable function from $\mathbb R^2$ to $\mathbb R$ , $\vec v$ is a unit vector in $\mathbb R^2$ , and $\vec a$ is a point in $\mathbb R^2$ . Then, visually, taking the directional derivative of $f$ with respect to $\vec v$ at $\vec a$ represents taking the vertical plane containing $\vec v$ , translating it to $\vec a$ , intersecting it with the graph of $f$ to obtain a curve, and then finding the slope of the tangent line to that curve at $\vec a$ . But vertical plane containing $\vec v$ is the same as the vertical plane containing $-\vec v$ , so why isn't the directional derivative of $f$ with respect to $-\vec v$ at $\vec a$ equal to the directional derivative of $f$ with respect to $\vec v$ at $\vec a$ ?","Suppose is a differentiable function from to , is a unit vector in , and is a point in . Then, visually, taking the directional derivative of with respect to at represents taking the vertical plane containing , translating it to , intersecting it with the graph of to obtain a curve, and then finding the slope of the tangent line to that curve at . But vertical plane containing is the same as the vertical plane containing , so why isn't the directional derivative of with respect to at equal to the directional derivative of with respect to at ?",f \mathbb R^2 \mathbb R \vec v \mathbb R^2 \vec a \mathbb R^2 f \vec v \vec a \vec v \vec a f \vec a \vec v -\vec v f -\vec v \vec a f \vec v \vec a,"['multivariable-calculus', 'derivatives', 'partial-derivative']"
74,Surface Flux Integral Across a Circular Surface,Surface Flux Integral Across a Circular Surface,,"I need to calculate $$ \iint_S \textbf{J}\cdot\hat{\textbf{n}}\; dS $$ Where S is the circular surface centered at the origin, area $A$ , in the $yz$ -plane, with unit normal having a negative $x$ -component. $$\textbf{J} = -\sigma\nabla\phi(\textbf{r}), \;\; \phi(\textbf{r}) = V(1-x/L)$$ What I'm struggling with here is getting a parametric representation of this surface for this integral in terms of u and v. I can very easily parametrise the curve of the boundary of this surface but obviously for this integral I need a representation of the surface. I tried: $$ S:\; (u,v) \rightarrow \; \left(v, \sqrt\frac{A}{\pi}\cos(u), \sqrt\frac{A}{\pi}\sin(u)\right) \;\; 0\leq u\leq 2\pi, \; v = 0 $$ But then calculating the normal, $\textbf{v}_{u} \times \textbf{v}_{u}$ , I get a normal to the cylinder with this circle as it's end. I know I need to get $(-1, 0, 0)$ as my unit normal vector. Any help would be much appreciated!","I need to calculate Where S is the circular surface centered at the origin, area , in the -plane, with unit normal having a negative -component. What I'm struggling with here is getting a parametric representation of this surface for this integral in terms of u and v. I can very easily parametrise the curve of the boundary of this surface but obviously for this integral I need a representation of the surface. I tried: But then calculating the normal, , I get a normal to the cylinder with this circle as it's end. I know I need to get as my unit normal vector. Any help would be much appreciated!","
\iint_S \textbf{J}\cdot\hat{\textbf{n}}\; dS
 A yz x \textbf{J} = -\sigma\nabla\phi(\textbf{r}), \;\; \phi(\textbf{r}) = V(1-x/L) 
S:\; (u,v) \rightarrow \; \left(v, \sqrt\frac{A}{\pi}\cos(u), \sqrt\frac{A}{\pi}\sin(u)\right) \;\;
0\leq u\leq 2\pi, \; v = 0
 \textbf{v}_{u} \times \textbf{v}_{u} (-1, 0, 0)","['multivariable-calculus', 'surfaces', 'surface-integrals']"
75,"Why is $f(x,y)$ discontinuous at $(x,y)=0$",Why is  discontinuous at,"f(x,y) (x,y)=0","$\displaystyle f(x,y)=\begin{cases} \displaystyle\frac{x^3+y^3}{x-y},  x\ne y \\ 0, x=y\end{cases}$ The questions is to check continuity at $(x,y)=(0,0)$ for $f(x,y)$ My attempt: $f(x,y)$ is continuous at $(0,0)$ iff $\displaystyle \lim_{(x,y) \to(0,0)} f(x,y) = f(0,0)$ Now for $y=mx,m\ne 1$ $\displaystyle \lim_{{(x,y) \to(0,0)}_{y=mx}} f(x,y) = \lim_{{(x,y) \to(0,0)}_{y=mx}} \frac{x^3+y^3}{x-y} =\lim_{x \to 0} \frac{x^3+m^3x^3}{x-mx}= \lim_{x \to 0} x^2\left(\frac{1+m^3}{1-m}\right)=0$ Now for $y=x$ $\displaystyle \lim_{{(x,y) \to(0,0)}_{y=x}} f(x,y) = \lim_{{(x,y) \to(0,0)}_{y=x}} 0 = 0$ From the above we can say $\displaystyle \lim_{(x,y) \to(0,0)} f(x,y)=0$ $\implies \displaystyle \lim_{(x,y) \to(0,0)} f(x,y)=f(0,0)$ So that means $f(x,y)$ is continuous at $(0,0)$ But the source from which I got this question says it's discontinuous at $(0,0)$ I am not able to find my mistake Although I can verify limit using $\epsilon,\delta$ method but I couldn't So I need your help to prove me correct/wrong Also using $\epsilon,\delta$ method would be apreciated",The questions is to check continuity at for My attempt: is continuous at iff Now for Now for From the above we can say So that means is continuous at But the source from which I got this question says it's discontinuous at I am not able to find my mistake Although I can verify limit using method but I couldn't So I need your help to prove me correct/wrong Also using method would be apreciated,"\displaystyle f(x,y)=\begin{cases} \displaystyle\frac{x^3+y^3}{x-y},
 x\ne y \\ 0, x=y\end{cases} (x,y)=(0,0) f(x,y) f(x,y) (0,0) \displaystyle \lim_{(x,y) \to(0,0)} f(x,y) = f(0,0) y=mx,m\ne 1 \displaystyle \lim_{{(x,y) \to(0,0)}_{y=mx}} f(x,y) = \lim_{{(x,y) \to(0,0)}_{y=mx}} \frac{x^3+y^3}{x-y} =\lim_{x \to 0} \frac{x^3+m^3x^3}{x-mx}= \lim_{x \to 0} x^2\left(\frac{1+m^3}{1-m}\right)=0 y=x \displaystyle \lim_{{(x,y) \to(0,0)}_{y=x}} f(x,y) = \lim_{{(x,y) \to(0,0)}_{y=x}} 0 = 0 \displaystyle \lim_{(x,y) \to(0,0)} f(x,y)=0 \implies \displaystyle \lim_{(x,y) \to(0,0)} f(x,y)=f(0,0) f(x,y) (0,0) (0,0) \epsilon,\delta \epsilon,\delta","['limits', 'multivariable-calculus']"
76,Why define norm of linear map as $\sup_{\|x\|=1}\|Ax\|=\|A\|$?,Why define norm of linear map as ?,\sup_{\|x\|=1}\|Ax\|=\|A\|,"I studied basic topology and abstract algebra(junior course) before studying multivariable analysis. In abstract algebra, we saw $\mathbb R$ -vector space $\mathfrak M(m, n)=\{A\mid A\text{ is }m\times n\text{ matrix over }\mathbb R\}$ as $\mathfrak L(\mathbb R^n, \mathbb R^m)=\{L:\mathbb R^n\to \mathbb R^m\mid L \text{ is }\mathbb R\text{-linear map}\}$ and subset(subring) of $\mathbb R^{mn}$ . Then, in this case, norm of $m\times n$ matrix $A$ would be $\|A\|=\sqrt{\sum_{1\le i, j\le n}a_{ij}^2}$ , as element of Euclidean space. But, in PMA, Rudin says norm of linear map $L$ as $\|L\|=\sup_{\|x\|=1}\|Lx\|$ . Why should it be defined like this? Is this because the matrix acts as an operator acting on Euclidean space, not as an element of a simple set?","I studied basic topology and abstract algebra(junior course) before studying multivariable analysis. In abstract algebra, we saw -vector space as and subset(subring) of . Then, in this case, norm of matrix would be , as element of Euclidean space. But, in PMA, Rudin says norm of linear map as . Why should it be defined like this? Is this because the matrix acts as an operator acting on Euclidean space, not as an element of a simple set?","\mathbb R \mathfrak M(m, n)=\{A\mid A\text{ is }m\times n\text{ matrix over }\mathbb R\} \mathfrak L(\mathbb R^n, \mathbb R^m)=\{L:\mathbb R^n\to \mathbb R^m\mid L \text{ is }\mathbb R\text{-linear map}\} \mathbb R^{mn} m\times n A \|A\|=\sqrt{\sum_{1\le i, j\le n}a_{ij}^2} L \|L\|=\sup_{\|x\|=1}\|Lx\|","['analysis', 'multivariable-calculus']"
77,Solution verification of a Double Integral,Solution verification of a Double Integral,,"This question was left as an exercise in class of multivariable calculus of my brother and I am not sure about my solution of it when he asked me the same. Question: Compute the integral $\displaystyle I=\iint \limits _R\frac{y}{x+1}\,dA$ , $R=[0,2]\times [0,4]$ . Attempt: $dA=dx\times dy$ and I thought that $[0,2]$ is limit of $x$ and $[0,4]$ is the limit of $y$ . \begin{align*}I & =\int \limits _0^2\int \limits _0^4\frac{y}{x+1}\,dy\,dx \\ & =\int \limits _0^28\frac{1}{x+1}\,dx \\ & =8\log (x+1)|_0^2 \\ & =8\log 3. \end{align*} I was confused in what $R=[0,2]\times [0,4]$ means here and that's why I thought on asking a second opinion. Can you please confirm it to me? Also, as I was looking at this question another time, I found that as $A=xy$ , so $dA=d(xy)=y\,dx+x\,dy$ and so my attempt is not right. Can you please confirm it too? So, a new solution will be $\displaystyle \int \limits _0^2\int \limits _0^4\frac{y}{x+1}(y\,dx+x\,dy)$ but now I am getting $\displaystyle \int \limits _0^2\int \limits _0^4\frac{y^2}{x+1}\,dx+\frac{xy}{x+1}\,dy$ . Now, I am confused that in the first integral there is only $dx$ and there are $2$ limits (i.e. of both $x$ and $y$ ) and so is the case for second integral. This seems to be mistake and so I think I am doing something wrong. So, can you please point it out? Thanks!","This question was left as an exercise in class of multivariable calculus of my brother and I am not sure about my solution of it when he asked me the same. Question: Compute the integral , . Attempt: and I thought that is limit of and is the limit of . I was confused in what means here and that's why I thought on asking a second opinion. Can you please confirm it to me? Also, as I was looking at this question another time, I found that as , so and so my attempt is not right. Can you please confirm it too? So, a new solution will be but now I am getting . Now, I am confused that in the first integral there is only and there are limits (i.e. of both and ) and so is the case for second integral. This seems to be mistake and so I think I am doing something wrong. So, can you please point it out? Thanks!","\displaystyle I=\iint \limits _R\frac{y}{x+1}\,dA R=[0,2]\times [0,4] dA=dx\times dy [0,2] x [0,4] y \begin{align*}I & =\int \limits _0^2\int \limits _0^4\frac{y}{x+1}\,dy\,dx \\
& =\int \limits _0^28\frac{1}{x+1}\,dx \\
& =8\log (x+1)|_0^2 \\
& =8\log 3.
\end{align*} R=[0,2]\times [0,4] A=xy dA=d(xy)=y\,dx+x\,dy \displaystyle \int \limits _0^2\int \limits _0^4\frac{y}{x+1}(y\,dx+x\,dy) \displaystyle \int \limits _0^2\int \limits _0^4\frac{y^2}{x+1}\,dx+\frac{xy}{x+1}\,dy dx 2 x y","['real-analysis', 'integration']"
78,Integral of $\frac1{|x|^3}$ on a circular segment,Integral of  on a circular segment,\frac1{|x|^3},"How can I evaluate $$\int \int _C |(x,y)|^{-3} dx dy$$ Where $C$ is the part between the chord $AB$ and the arc $AB$ , and $|(x,y)| = \sqrt{x^2 + y^2}$ ? The radius of the circle is $R$ . I tried using polar coordinates, but I can’t find a way to represent $C$ with polar coordinates.","How can I evaluate Where is the part between the chord and the arc , and ? The radius of the circle is . I tried using polar coordinates, but I can’t find a way to represent with polar coordinates.","\int \int _C |(x,y)|^{-3} dx dy C AB AB |(x,y)| = \sqrt{x^2 + y^2} R C","['integration', 'multivariable-calculus', 'polar-coordinates']"
79,What is the cartesian equivalent of $r=0$?,What is the cartesian equivalent of ?,r=0,"The question I have asks to convert $$\int_{\pi/4}^{\pi/2} \int_{0}^{2/\sin{\theta}} r^{3/2} dr d\theta$$ I think I understand how to do most of it: $r=\frac{2}{\sin{\theta}}\implies r\sin\theta=2 \implies y=2$ $\theta=\frac{\pi}{4} \implies y=x$ $\theta=\frac{\pi}{2} \implies x=0$ I just want to know what happens with the lower bound for $r$ , does this automatically mean $x=0, y=0$ ? I graphed the lines $y=2, y=x$ And I can see that the integral converted to cartesian becomes $\int_{0}^{2}\int_{x}^{2} (x^2+y^2)^{1/4} dydx$ or $\int_{0}^{2}\int_{0}^{y} (x^2+y^2)^{1/4} dxdy$ Essentially my question is how do I convert the lower bound $r=0$ into something cartesian that I can use? Do I just need to graph all the other lines first and see what they give? Does $r=0$ even give any important information?","The question I have asks to convert I think I understand how to do most of it: I just want to know what happens with the lower bound for , does this automatically mean ? I graphed the lines And I can see that the integral converted to cartesian becomes or Essentially my question is how do I convert the lower bound into something cartesian that I can use? Do I just need to graph all the other lines first and see what they give? Does even give any important information?","\int_{\pi/4}^{\pi/2} \int_{0}^{2/\sin{\theta}} r^{3/2} dr d\theta r=\frac{2}{\sin{\theta}}\implies r\sin\theta=2 \implies y=2 \theta=\frac{\pi}{4} \implies y=x \theta=\frac{\pi}{2} \implies x=0 r x=0, y=0 y=2, y=x \int_{0}^{2}\int_{x}^{2} (x^2+y^2)^{1/4} dydx \int_{0}^{2}\int_{0}^{y} (x^2+y^2)^{1/4} dxdy r=0 r=0","['multivariable-calculus', 'polar-coordinates']"
80,What is the derivation for the fluid dynamics continuity equation,What is the derivation for the fluid dynamics continuity equation,,"In my Fluid Dynamics module I have begun learning about mass flux. In my most recent lecture I have been presented with the following text and equation: For a general fluid in some volume $V$ , enclosed by the surface $S$ , the conservation of mass is expressed through the continuity equation (integral form): $$\iiint_V \frac{\partial\rho}{\partial t}\text{d}V=-\iint_S \rho\vec{v}\cdot\hat{n}\text{d}S$$ where $\rho(\vec{x})=\rho$ . I do not understand how these two integrals are equal to one another and would appreciate if anybody would be able to help me understand.","In my Fluid Dynamics module I have begun learning about mass flux. In my most recent lecture I have been presented with the following text and equation: For a general fluid in some volume , enclosed by the surface , the conservation of mass is expressed through the continuity equation (integral form): where . I do not understand how these two integrals are equal to one another and would appreciate if anybody would be able to help me understand.",V S \iiint_V \frac{\partial\rho}{\partial t}\text{d}V=-\iint_S \rho\vec{v}\cdot\hat{n}\text{d}S \rho(\vec{x})=\rho,"['calculus', 'integration', 'multivariable-calculus', 'vector-analysis', 'fluid-dynamics']"
81,"Evaluating $\lim_{(x,y)\to(0,0)}\dfrac{x^2+y^2}{x^4+y^4}$ [duplicate]",Evaluating  [duplicate],"\lim_{(x,y)\to(0,0)}\dfrac{x^2+y^2}{x^4+y^4}","This question already has answers here : Limit $(x,y) \to (0,0)$ (2 answers) Closed 2 years ago . Evaluate the limit: $\displaystyle\lim_{(x,y)\to(0,0)}\dfrac{x^2+y^2}{x^4+y^4}$ To solve this, I converted it to polar coordinate and got: $\displaystyle\lim _{r\to0}\left(\frac{1}{r^2(\sin^4\theta+cos^4\theta)}\right)=\infty$ But after putting this on WolframAlpha, it tells me that this limit does not exist. Who is wrong here?","This question already has answers here : Limit $(x,y) \to (0,0)$ (2 answers) Closed 2 years ago . Evaluate the limit: To solve this, I converted it to polar coordinate and got: But after putting this on WolframAlpha, it tells me that this limit does not exist. Who is wrong here?","\displaystyle\lim_{(x,y)\to(0,0)}\dfrac{x^2+y^2}{x^4+y^4} \displaystyle\lim _{r\to0}\left(\frac{1}{r^2(\sin^4\theta+cos^4\theta)}\right)=\infty","['limits', 'multivariable-calculus']"
82,Differentiating vector function-matrix-vector function products,Differentiating vector function-matrix-vector function products,,"Consider the following scalar which is the result of a vector-matrix-vector product: $$ h( \bf{x} ) = \bf{f}( \bf{x} ) A \bf{g}(\bf{x})^T$$ where $\bf{x} = (x_1, x_2, \ldots, x_k)$ is an input vector $\bf{f}(\bf{x}) = (f_1(\bf{x}), f_2(\bf{x}), \ldots, f_p(\bf{x}))$ is a $p$ vector of simple, known functions $\bf{g}(\bf{x}) = (g_1(\bf{x}), g_2(\bf{x}), \ldots, g_q(\bf{x}))$ is a $q$ vector of simple, known functions $A$ is a $p \times q$ matrix of (known) constants. Denote the $i$ th row of $A$ by $\bf{a}_i$ and the $j$ th column by $\bf{a}_{(j)}$ . What I require is $\frac{\partial h(\bf{x})}{\partial \bf{x}}$ . I am relatively un-familiar with matrix and vector type calculus. I studied some vector-calculus some years ago but the introduction of matrices makes this fiddly for me. but this is what I tried to use the fact that the final result is just a double sum to help me: $$\frac{\partial}{\partial \bf{x} } h(\bf{x}) = \sum_{i=1}^p \sum_{j=1}^q \frac{\partial}{\partial \bf{x}}f_i a_{ij} g_j$$ (dropping dependence on $\bf{x}$ in $f_i$ and $g_j$ ) $$= \sum_{i=1}^p \sum_{j=1}^q \frac{\partial f_i}{\partial \bf{x}} a_{ij} g_j + \sum_{i=1}^p \sum_{j=1}^qf_i a_{ij} \frac{\partial g_i}{\partial \bf{x}}$$ (product rule for partial derivatives + break up the sum) Now in principle this is enough, however, I'd like to write the final result as a matrix-vector product for (a) consiseness and (b) I'd like to use the matrix-vector product rather than the double sum for computation. Ploughing ahead gives us $$= \sum_{i=1}^p \frac{\partial f_i}{\partial \bf{x}}\sum_{j=1}^q  a_{ij} g_j + \sum_{j=1}^q\frac{\partial g_j}{\partial \bf{x}} \sum_{i=p}^q a_{ij}f_i $$ (re-order the sum) $$= \sum_{i=1}^p \frac{\partial f_i}{\partial \bf{x}} \bf{a}_{i} \bf{g}^T + \sum_{j=1}^q\frac{\partial g_j}{\partial \bf{x}} \bf{a}_{(j)}^T \bf{f}^T $$ (collecting the ""2nd sums"" into vector products). Now here is where I am stumped. The dimension of the result so far is correct (dim = $1 \times k$ ) but I'm struggling to write this as a vector-matrix product. The result looks a bit like $\frac{\partial \bf{f}}{\partial \bf{x}} A \bf{g}^T + \frac{\partial \bf{g}}{\partial \bf{x}} A^T \bf{f}^T$ but clearly the dimensions are incorrect. Dimension of $\frac{\partial{h}}{\partial \bf{x}}$ are $1 \times k$ whereas I think the dimension of my guess is $(p \times k)(p \times q)(q \times 1) + (q \times k)(q \times p)(q \times 1)$ . These dimensions are not compatible in $2$ ways!","Consider the following scalar which is the result of a vector-matrix-vector product: where is an input vector is a vector of simple, known functions is a vector of simple, known functions is a matrix of (known) constants. Denote the th row of by and the th column by . What I require is . I am relatively un-familiar with matrix and vector type calculus. I studied some vector-calculus some years ago but the introduction of matrices makes this fiddly for me. but this is what I tried to use the fact that the final result is just a double sum to help me: (dropping dependence on in and ) (product rule for partial derivatives + break up the sum) Now in principle this is enough, however, I'd like to write the final result as a matrix-vector product for (a) consiseness and (b) I'd like to use the matrix-vector product rather than the double sum for computation. Ploughing ahead gives us (re-order the sum) (collecting the ""2nd sums"" into vector products). Now here is where I am stumped. The dimension of the result so far is correct (dim = ) but I'm struggling to write this as a vector-matrix product. The result looks a bit like but clearly the dimensions are incorrect. Dimension of are whereas I think the dimension of my guess is . These dimensions are not compatible in ways!"," h( \bf{x} ) = \bf{f}( \bf{x} ) A \bf{g}(\bf{x})^T \bf{x} = (x_1, x_2, \ldots, x_k) \bf{f}(\bf{x}) = (f_1(\bf{x}), f_2(\bf{x}), \ldots, f_p(\bf{x})) p \bf{g}(\bf{x}) = (g_1(\bf{x}), g_2(\bf{x}), \ldots, g_q(\bf{x})) q A p \times q i A \bf{a}_i j \bf{a}_{(j)} \frac{\partial h(\bf{x})}{\partial \bf{x}} \frac{\partial}{\partial \bf{x} } h(\bf{x}) = \sum_{i=1}^p \sum_{j=1}^q \frac{\partial}{\partial \bf{x}}f_i a_{ij} g_j \bf{x} f_i g_j = \sum_{i=1}^p \sum_{j=1}^q \frac{\partial f_i}{\partial \bf{x}} a_{ij} g_j + \sum_{i=1}^p \sum_{j=1}^qf_i a_{ij} \frac{\partial g_i}{\partial \bf{x}} = \sum_{i=1}^p \frac{\partial f_i}{\partial \bf{x}}\sum_{j=1}^q  a_{ij} g_j + \sum_{j=1}^q\frac{\partial g_j}{\partial \bf{x}} \sum_{i=p}^q a_{ij}f_i  = \sum_{i=1}^p \frac{\partial f_i}{\partial \bf{x}} \bf{a}_{i} \bf{g}^T + \sum_{j=1}^q\frac{\partial g_j}{\partial \bf{x}} \bf{a}_{(j)}^T \bf{f}^T  1 \times k \frac{\partial \bf{f}}{\partial \bf{x}} A \bf{g}^T + \frac{\partial \bf{g}}{\partial \bf{x}} A^T \bf{f}^T \frac{\partial{h}}{\partial \bf{x}} 1 \times k (p \times k)(p \times q)(q \times 1) + (q \times k)(q \times p)(q \times 1) 2","['matrices', 'multivariable-calculus', 'derivatives']"
83,How would I find the equation of f(x) in terms of x and y?,How would I find the equation of f(x) in terms of x and y?,,"The function $f(x)$ was rotated along the x-axis to form a surface. $$  \int_{-4}^{4} \int_{y=-\sqrt{16-x^{2}}}^{y=\sqrt{16-x^{2}}} \int_{-f(x)}^{f(x)} dzdydx$$ This is what i thought it would be however, I am not sure what I should be integrating... I have my limits for my integrals however, I do not have the equation of this cylinder to integrate into (which I think I need). If anyone can either fix my integration (if it is wrong) or/and provide me with the equation of a cylinder that would be great.  Or if someone can find my f(x) as f(x,y).","The function was rotated along the x-axis to form a surface. This is what i thought it would be however, I am not sure what I should be integrating... I have my limits for my integrals however, I do not have the equation of this cylinder to integrate into (which I think I need). If anyone can either fix my integration (if it is wrong) or/and provide me with the equation of a cylinder that would be great.  Or if someone can find my f(x) as f(x,y).",f(x)   \int_{-4}^{4} \int_{y=-\sqrt{16-x^{2}}}^{y=\sqrt{16-x^{2}}} \int_{-f(x)}^{f(x)} dzdydx,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
84,Limit of multivariare function at the origin,Limit of multivariare function at the origin,,"Consider the function $f:\mathbb{R}^2\to \mathbb{R}$ defined as: $$ f(x,y)= \begin{cases} \frac{|x|^{\frac{5}{2}}y}{(x^2+y^4)\sqrt{x^2+y^2}}.\quad&\text{ if } (x,y)\neq 0\\ 0\quad& \text{ if }(x,y)= 0\,. \end{cases} $$ Is this function continuous at the origin? If the limit exists it has to be $0$ since, for example, if we take the restriction $x=y$ we obtain: $$ \lim_{x\to0}\frac{|x|^{\frac{5}{2}}x}{\sqrt{2}(x^2+x^4)|x|}=0 $$ Restrictions to any kind of powers seem to give the same result suggesting that the function has to be continuous at the origin (as the graph also seems to confirm) but I'm not able to find an estimate for $f$ to use the squeeze theorem and actually prove continuity. Any help will be greatly appreciated.","Consider the function defined as: Is this function continuous at the origin? If the limit exists it has to be since, for example, if we take the restriction we obtain: Restrictions to any kind of powers seem to give the same result suggesting that the function has to be continuous at the origin (as the graph also seems to confirm) but I'm not able to find an estimate for to use the squeeze theorem and actually prove continuity. Any help will be greatly appreciated.","f:\mathbb{R}^2\to \mathbb{R} 
f(x,y)=
\begin{cases}
\frac{|x|^{\frac{5}{2}}y}{(x^2+y^4)\sqrt{x^2+y^2}}.\quad&\text{ if } (x,y)\neq 0\\
0\quad& \text{ if }(x,y)= 0\,.
\end{cases}
 0 x=y 
\lim_{x\to0}\frac{|x|^{\frac{5}{2}}x}{\sqrt{2}(x^2+x^4)|x|}=0
 f","['real-analysis', 'calculus', 'limits', 'multivariable-calculus', 'continuity']"
85,"Use Green's theorem to calculate $\int_{\gamma}y\,dx+x^2dy$",Use Green's theorem to calculate,"\int_{\gamma}y\,dx+x^2dy","Use greens theorem to calculate $\int_{\gamma}y\,dx+x^2dy$ where $\gamma$ is the following closed path: (a) The circle given by $g(t) = (\cos(t), \sin(t)), 0 \le t \le 2\pi$ . What I have tried: Using the following $$\int_\gamma P\,dx+Q\,dy = \int_D\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y} \right)$$ I have that $$\frac{\partial (x^2)}{\partial x}-\frac{\partial (y)}{\partial y} = 2x-1$$ Replacing $x = \cos(t)$ I then have: $$\int_0^{2\pi}(2\cos(t)-1)\,dt=-2\pi$$ But the answer in my book show $-\pi$ , so I have tried replacing $x = \cos(t), y = \sin(t), dx = -\sin(t), dy = \cos(t)$ in the integral but that gives me $\pi$ . Have I made a mistake?","Use greens theorem to calculate where is the following closed path: (a) The circle given by . What I have tried: Using the following I have that Replacing I then have: But the answer in my book show , so I have tried replacing in the integral but that gives me . Have I made a mistake?","\int_{\gamma}y\,dx+x^2dy \gamma g(t) = (\cos(t), \sin(t)), 0 \le t \le 2\pi \int_\gamma P\,dx+Q\,dy = \int_D\left(\frac{\partial Q}{\partial x}-\frac{\partial P}{\partial y} \right) \frac{\partial (x^2)}{\partial x}-\frac{\partial (y)}{\partial y} = 2x-1 x = \cos(t) \int_0^{2\pi}(2\cos(t)-1)\,dt=-2\pi -\pi x = \cos(t), y = \sin(t), dx = -\sin(t), dy = \cos(t) \pi",['multivariable-calculus']
86,"Prove the limit $\lim_{(x,y)\to(0,0)} \frac{x^4+y^4}{xy}=0$.",Prove the limit .,"\lim_{(x,y)\to(0,0)} \frac{x^4+y^4}{xy}=0","Prove the limit $\lim_{(x,y)\to(0,0)} \frac{x^4+y^4}{xy}=0$ . Attempt. I tried to work with squeeze theorem, i.e. to find a function $h(x,y)$ (with limit $0$ at $(0,0)$ ) such that $|\frac{x^4+y^4}{xy}|\leqslant h(x,y)$ for all $(x,y)$ : $xy\neq 0$ , but it didn't work. Any suggestions for the upper bound? Thank you.","Prove the limit . Attempt. I tried to work with squeeze theorem, i.e. to find a function (with limit at ) such that for all : , but it didn't work. Any suggestions for the upper bound? Thank you.","\lim_{(x,y)\to(0,0)} \frac{x^4+y^4}{xy}=0 h(x,y) 0 (0,0) |\frac{x^4+y^4}{xy}|\leqslant h(x,y) (x,y) xy\neq 0","['limits', 'multivariable-calculus']"
87,Differentiating real valued vector functions.,Differentiating real valued vector functions.,,"If $v(a,b,c): \mathbb{R}^3 \to \mathbb{R}^3 $ and $ f: \mathbb{R}^3 \to \mathbb{R}$ by $f(v) = v \cdot v $ (dot product) , what is $\frac{\partial f}{\partial a}$ ? Chain rule attempt: $\frac{df}{dv} = 2v$ and so $\frac{\partial f}{\partial a} = 2v \cdot \frac{\partial v}{\partial a} $ ? I dont think this is correct unfortunately. Could someone give me some pointers please :)","If and by (dot product) , what is ? Chain rule attempt: and so ? I dont think this is correct unfortunately. Could someone give me some pointers please :)","v(a,b,c): \mathbb{R}^3 \to \mathbb{R}^3   f: \mathbb{R}^3 \to \mathbb{R} f(v) = v \cdot v  \frac{\partial f}{\partial a} \frac{df}{dv} = 2v \frac{\partial f}{\partial a} = 2v \cdot \frac{\partial v}{\partial a} ","['real-analysis', 'multivariable-calculus', 'derivatives', 'vector-analysis']"
88,Derivative of a Lyapunov function for a nonlinear system,Derivative of a Lyapunov function for a nonlinear system,,"Let $$\begin{aligned}\begin{cases}\dot{x}_{1}=-\left( 2x_{1}-x_{2}\right)^3+\left( x_{1}-x_{2}\right)  \\ \dot{x}_{2}= -\left( 2x_{1}-x_{2}\right) ^{3}+2\left( x_{1}-x_{2}\right)\end{cases}\\  \end{aligned}$$ Given $$V\left( \mathbb{x}\right) =\mathbb{x}^{T}P\mathbb{x} \qquad P=\begin{bmatrix} 5 & -3 \\ -3 & 2 \end{bmatrix}$$ Answer: $\dot V\left( x_{1},x_{2}\right) =-2\left[ \left( 2x_{1}-x_{2}\right) ^{4}+\left( x_{1}-x_{2}\right) ^{2}\right]$ My attempt: We can write $V(\mathbb{x})$ as $$\begin{aligned}V\left( x_1,x_2\right) &=5x_{1}^{2}-6x_{1}x_{2}+2x_{2}^{2}\\ &=\left( 2x_{1}-x_{2}\right) ^{2}+\left( x_{1}-x_{2}\right) ^{2}\end{aligned}$$ and defining the change of variables $z_{1}=2x_{1}-x_{2}$ and $z_{2}=x_{1}-x_{2}$ we obtain $$V(z_1,z_2)=z_1^2+z_2^2$$ and $$\begin{cases}\dot{z}_{1}=-z_{1}^{3}+z_{2}\\ \dot{z}_{2}=-z_{1}^{3}+2z_{2}\end{cases}$$ Now we can calculate $\dot V(z_1,z_2)$ as $$\begin{aligned}\dot V\left( z_{1},z_{2}\right) &=\dfrac{\partial V}{\partial z_{1}}\left( z_{1},z_{2}\right) \dot{z}_{1}+\dfrac{\partial V}{\partial z_{2}}\dot{z}_{2}\\ &=2z_{1}\left( -z_{1}^{3}+z_{2}\right) +2z_{2}\left( -z_{1}^{3}+2z_{2}\right) \end{aligned}$$",Let Given Answer: My attempt: We can write as and defining the change of variables and we obtain and Now we can calculate as,"\begin{aligned}\begin{cases}\dot{x}_{1}=-\left( 2x_{1}-x_{2}\right)^3+\left( x_{1}-x_{2}\right)  \\
\dot{x}_{2}= -\left( 2x_{1}-x_{2}\right) ^{3}+2\left( x_{1}-x_{2}\right)\end{cases}\\
 \end{aligned} V\left( \mathbb{x}\right) =\mathbb{x}^{T}P\mathbb{x} \qquad P=\begin{bmatrix}
5 & -3 \\
-3 & 2
\end{bmatrix} \dot V\left( x_{1},x_{2}\right) =-2\left[ \left( 2x_{1}-x_{2}\right) ^{4}+\left( x_{1}-x_{2}\right) ^{2}\right] V(\mathbb{x}) \begin{aligned}V\left( x_1,x_2\right) &=5x_{1}^{2}-6x_{1}x_{2}+2x_{2}^{2}\\
&=\left( 2x_{1}-x_{2}\right) ^{2}+\left( x_{1}-x_{2}\right) ^{2}\end{aligned} z_{1}=2x_{1}-x_{2} z_{2}=x_{1}-x_{2} V(z_1,z_2)=z_1^2+z_2^2 \begin{cases}\dot{z}_{1}=-z_{1}^{3}+z_{2}\\
\dot{z}_{2}=-z_{1}^{3}+2z_{2}\end{cases} \dot V(z_1,z_2) \begin{aligned}\dot V\left( z_{1},z_{2}\right) &=\dfrac{\partial V}{\partial z_{1}}\left( z_{1},z_{2}\right) \dot{z}_{1}+\dfrac{\partial V}{\partial z_{2}}\dot{z}_{2}\\
&=2z_{1}\left( -z_{1}^{3}+z_{2}\right) +2z_{2}\left( -z_{1}^{3}+2z_{2}\right) \end{aligned}","['multivariable-calculus', 'stability-in-odes', 'stability-theory', 'lyapunov-functions']"
89,Evaluating $\int (1-2x^2y^2)e^{-x^2y^2}dx$,Evaluating,\int (1-2x^2y^2)e^{-x^2y^2}dx,"I have the following integral, $$\int (1-2x^2y^2)e^{-x^2y^2}dx$$ It seems expanding the integrand and separating the integral is not a good idea since $\int e^{-x^2}dx$ has no elementary solution based on this post . I'm not sure how to proceed evaluating this integral. I know the answer is $xe^{-x^2y^2}+C$ and I checked it by taking derivative  ( moving backward) hoping some idea comes to my mind. But I'm not sure which integral technique should I use to get this result.","I have the following integral, It seems expanding the integrand and separating the integral is not a good idea since has no elementary solution based on this post . I'm not sure how to proceed evaluating this integral. I know the answer is and I checked it by taking derivative  ( moving backward) hoping some idea comes to my mind. But I'm not sure which integral technique should I use to get this result.",\int (1-2x^2y^2)e^{-x^2y^2}dx \int e^{-x^2}dx xe^{-x^2y^2}+C,"['integration', 'multivariable-calculus']"
90,"Prove or Disprove that $f(x,y)$ is differentiable in $(0,0)$? (Limit).",Prove or Disprove that  is differentiable in ? (Limit).,"f(x,y) (0,0)","Let $f(x,y)=\frac{x^4y}{x^4+y^2}$ whenever $(x,y)\ne(0,0)$ . and $f(x,y)=(0,0)$ otherwise. Prove or disprove: $f$ is differentiable in $(0,0)$ . My attempt: I am trying to prove it by showing that $\epsilon \to 0$ when $\Delta x,\Delta y \to 0$ in this definition: $f(x+\Delta x, y+\Delta y)-f(x,y)=f_x(x,y)\Delta x+f_y \Delta y + \epsilon\sqrt{(\Delta x)^2+(\Delta y)^2}$ . I have checked by definition that $f_x(0,0)=f_y(0,0)=0$ . And so $f(\Delta x, \Delta y)=\epsilon\sqrt{\Delta x^2+ \Delta y^2}$ Which gives me: $$\frac{(\Delta x)^4(\Delta y)}{[(\Delta x)^4 + (\Delta y)^2]\sqrt{(\Delta x)^2+ (\Delta y)^2}}=\epsilon$$ But now  I got stuck trying to show that $\epsilon \to 0$ , I am not sure how to deal with this limit and would appreciate any help and explanations on your thoughts (What did you think when you saw this limit, like did you know it converges to $0$ just by looking at it? What I'm trying to say is I would appreciate explanations on your thoughts ""behind the scenes"" that led you to use your method). Thanks in advance!","Let whenever . and otherwise. Prove or disprove: is differentiable in . My attempt: I am trying to prove it by showing that when in this definition: . I have checked by definition that . And so Which gives me: But now  I got stuck trying to show that , I am not sure how to deal with this limit and would appreciate any help and explanations on your thoughts (What did you think when you saw this limit, like did you know it converges to just by looking at it? What I'm trying to say is I would appreciate explanations on your thoughts ""behind the scenes"" that led you to use your method). Thanks in advance!","f(x,y)=\frac{x^4y}{x^4+y^2} (x,y)\ne(0,0) f(x,y)=(0,0) f (0,0) \epsilon \to 0 \Delta x,\Delta y \to 0 f(x+\Delta x, y+\Delta y)-f(x,y)=f_x(x,y)\Delta x+f_y \Delta y + \epsilon\sqrt{(\Delta x)^2+(\Delta y)^2} f_x(0,0)=f_y(0,0)=0 f(\Delta x, \Delta y)=\epsilon\sqrt{\Delta x^2+ \Delta y^2} \frac{(\Delta x)^4(\Delta y)}{[(\Delta x)^4 + (\Delta y)^2]\sqrt{(\Delta x)^2+ (\Delta y)^2}}=\epsilon \epsilon \to 0 0","['limits', 'multivariable-calculus', 'derivatives']"
91,Triple integral - cylindrical coordinates problem,Triple integral - cylindrical coordinates problem,,"I have to figure out this here integral: $$\iiint \sqrt{x^2+y^2} dxdydz$$ in the boundaries $x^2+y^2=z^2$ , $z=1$ , $z=2$ Now, I know that the intersection of the two planes and the conic are circles. The area itself is the area between those planes. Now, if I introduce cylindrical coordinates: $x=r\cos\phi$ $y=r\sin\phi$ $z=z$ If I plug this in, I get that $r^2 = z^2$ , which after substituting the two values of $z$ I get that $r \in [1,2]$ $\phi \in [0, 2\pi]$ But what about the boundaries for $z$ ? Surely they can't be $z \in [1,2]$ ! I'm at a loss here, because if I express the boundaries for $z$ to be $ \in [1,2]$ , what about $r$ ? Could anyone help?","I have to figure out this here integral: in the boundaries , , Now, I know that the intersection of the two planes and the conic are circles. The area itself is the area between those planes. Now, if I introduce cylindrical coordinates: If I plug this in, I get that , which after substituting the two values of I get that But what about the boundaries for ? Surely they can't be ! I'm at a loss here, because if I express the boundaries for to be , what about ? Could anyone help?","\iiint \sqrt{x^2+y^2} dxdydz x^2+y^2=z^2 z=1 z=2 x=r\cos\phi y=r\sin\phi z=z r^2 = z^2 z r \in [1,2] \phi \in [0, 2\pi] z z \in [1,2] z  \in [1,2] r","['multivariable-calculus', 'multiple-integral', 'cylindrical-coordinates']"
92,Double integral polar coordinates - boundaries problem,Double integral polar coordinates - boundaries problem,,"I need to calculate the surface of the area between $$\frac{(x-2)^2}{9} + \frac{(y+1)^2}{4} \le 1$$ and $$y \ge 0$$ Let's introduce polar coordinates: $$x-2 = 3r\cos(\phi)$$ $$y+1 = 2r\sin(\phi)$$ $$|J| = 6r$$ Substituting this in the first inequality we get that $r^2 \le 1$ , which means $r \in [0,1]$ for now. Now here's the problem. In the second inequality we have: $$r\sin(\phi) \ge 0$$ As $r$ is already greater or equal to zero, we have that $\sin(\phi) \ge 0$ , and thus that $\phi \in [0, \pi]$ One can also see this by drawing a picture, the line $y=0$ is the x axis and we get that it's greater than zero above the x axis, which is from $0$ to $\pi$ Substituting this, I get the following double integral: $$ \int_{0}^{\pi}\int_{0}^{1} 6rdrd\phi$$ and when I solve it I get that the solution is $3\pi$ . However, my workbook states that the solution is $2\pi - \frac{3\sqrt{3}}{2}$ Can anyone help me understand where I might be wrong?","I need to calculate the surface of the area between and Let's introduce polar coordinates: Substituting this in the first inequality we get that , which means for now. Now here's the problem. In the second inequality we have: As is already greater or equal to zero, we have that , and thus that One can also see this by drawing a picture, the line is the x axis and we get that it's greater than zero above the x axis, which is from to Substituting this, I get the following double integral: and when I solve it I get that the solution is . However, my workbook states that the solution is Can anyone help me understand where I might be wrong?","\frac{(x-2)^2}{9} + \frac{(y+1)^2}{4} \le 1 y \ge 0 x-2 = 3r\cos(\phi) y+1 = 2r\sin(\phi) |J| = 6r r^2 \le 1 r \in [0,1] r\sin(\phi) \ge 0 r \sin(\phi) \ge 0 \phi \in [0, \pi] y=0 0 \pi  \int_{0}^{\pi}\int_{0}^{1} 6rdrd\phi 3\pi 2\pi - \frac{3\sqrt{3}}{2}","['integration', 'multivariable-calculus', 'multiple-integral']"
93,Calculating this line integral (Finding the intersection curve and which parametrization to choose).,Calculating this line integral (Finding the intersection curve and which parametrization to choose).,,"Let $C$ be part of the intersection curve of the Paraboloid $z=x^2+y^2$ with the plane $2x+2y-z+2=0$ that starts from point $(3,1,10)$ and ends in $(1,3,10)$ . We define $f(x,y,z)=z-y^2-2x-1$ . Calculate $\int_{C}f dl$ . My work: Finding $C$ : from the plane equation: $z=2x+2y+2$ . Substituting that into the paraboloid equation: $2x+2y+2=x^2+y^2 \Longrightarrow x^2-2x+y^2-2y=2 \Longrightarrow (x-1)^2+(y-1)^2=4$ . I find this result of getting a circle very weird, because the plane isn't parallel to $z=0$ plane, so I can't see why I received a circle, I expected an ellipse or something. The only thing I can think about is that I received the ""Shadow"" of the ellipse on the $xy$ plane, but I would appreciate any help understanding what have happened here! Anyway, I also got stuck here on which parametrization should I choose, if it's $x=r\cos(t), y=r\sin(t),z=r^2$ OR $x=1+r\cos(t),y=1+r\sin(t),z=?$ Then if I substitute it in the circle's equation I can find $z$ . But I'm not sure if I can do that since $C$ isn't all the circle, it's just part of it. I would appreciate any help, thanks in advance! Edit After the help from answers: If I define $\vec r(t)=(1+2cos(t), 1+2sin(t), 4cos(t)+4sin(t)+6)$ to be the vector that draws the circle. Then $\vec r'(t) = (-2sin(t), -2cos(t), 4cos(t)-4sin(t))$ . Where $\frac{\pi}{2} \ge t \ge 0$ . $f(x,y,z)=z-y^2-2x-1=2x+2y+2-y^2-2x-1=-y^2+2y+1 = 2 - (y-1)^2$ And so my integral: $$ \begin{split} \int_C f dl  &= \int_0^{\pi/2}          2\cos(2t)          \sqrt{(2\sin(t))^2 + (2\cos(t))^2 + (4\cos(t)-4\sin(t))^2} dt \\  &= \int_0^{\pi/2}          2\cos(2t)          \sqrt{8 + (16\cos(t)^2 - 16\sin(2t) + 16\sin(t)^2)} dt \\  &= \int_0^{\pi/2} 2\cos(2t)\sqrt{24-16\sin(2t)} dt \end{split} $$ I'm having some difficult times deciding how to do this integral","Let be part of the intersection curve of the Paraboloid with the plane that starts from point and ends in . We define . Calculate . My work: Finding : from the plane equation: . Substituting that into the paraboloid equation: . I find this result of getting a circle very weird, because the plane isn't parallel to plane, so I can't see why I received a circle, I expected an ellipse or something. The only thing I can think about is that I received the ""Shadow"" of the ellipse on the plane, but I would appreciate any help understanding what have happened here! Anyway, I also got stuck here on which parametrization should I choose, if it's OR Then if I substitute it in the circle's equation I can find . But I'm not sure if I can do that since isn't all the circle, it's just part of it. I would appreciate any help, thanks in advance! Edit After the help from answers: If I define to be the vector that draws the circle. Then . Where . And so my integral: I'm having some difficult times deciding how to do this integral","C z=x^2+y^2 2x+2y-z+2=0 (3,1,10) (1,3,10) f(x,y,z)=z-y^2-2x-1 \int_{C}f dl C z=2x+2y+2 2x+2y+2=x^2+y^2 \Longrightarrow x^2-2x+y^2-2y=2 \Longrightarrow (x-1)^2+(y-1)^2=4 z=0 xy x=r\cos(t), y=r\sin(t),z=r^2 x=1+r\cos(t),y=1+r\sin(t),z=? z C \vec r(t)=(1+2cos(t), 1+2sin(t), 4cos(t)+4sin(t)+6) \vec r'(t) = (-2sin(t), -2cos(t), 4cos(t)-4sin(t)) \frac{\pi}{2} \ge t \ge 0 f(x,y,z)=z-y^2-2x-1=2x+2y+2-y^2-2x-1=-y^2+2y+1 = 2 - (y-1)^2 
\begin{split}
\int_C f dl
 &= \int_0^{\pi/2}
         2\cos(2t)
         \sqrt{(2\sin(t))^2 + (2\cos(t))^2 + (4\cos(t)-4\sin(t))^2} dt \\
 &= \int_0^{\pi/2}
         2\cos(2t)
         \sqrt{8 + (16\cos(t)^2 - 16\sin(2t) + 16\sin(t)^2)} dt \\
 &= \int_0^{\pi/2} 2\cos(2t)\sqrt{24-16\sin(2t)} dt
\end{split}
","['integration', 'multivariable-calculus', 'line-integrals']"
94,The shortest distance (not duplicated),The shortest distance (not duplicated),,"This is not the same question as this Consider the ellipse defined by $$x^2+4y^2=4$$ and the line $$x+y=4$$ find the shortest distance from a point on the ellipse to the line. In other words, we want to find a function $D(x,y)$ , you plug into it a point on the ellipse and it will tell you what is the closest point to this point on the line. This last line wasn't in the original question, so you may try to parametrize the ellipse and the line and try to find some connection, but this method didn't work for me ( $E$ is the ellipse and $L$ is the line): $$E(t)=\langle2\cos t,\sin t\rangle,  \text{  }L(t)=\langle t, 4-t \rangle$$ $$\implies D(t)=\langle t-2\cos t, 4-t-\sin t\rangle$$ but this curve doesn't work, it just tells you what is the path between two points on the ellipse and the line.","This is not the same question as this Consider the ellipse defined by and the line find the shortest distance from a point on the ellipse to the line. In other words, we want to find a function , you plug into it a point on the ellipse and it will tell you what is the closest point to this point on the line. This last line wasn't in the original question, so you may try to parametrize the ellipse and the line and try to find some connection, but this method didn't work for me ( is the ellipse and is the line): but this curve doesn't work, it just tells you what is the path between two points on the ellipse and the line.","x^2+4y^2=4 x+y=4 D(x,y) E L E(t)=\langle2\cos t,\sin t\rangle,  \text{  }L(t)=\langle t, 4-t \rangle \implies D(t)=\langle t-2\cos t, 4-t-\sin t\rangle","['multivariable-calculus', 'vectors', 'curves']"
95,Is positive definite function (dynamical systems) always convex?,Is positive definite function (dynamical systems) always convex?,,"Let $f : \mathbb{R}^n \to \mathbb{R}$ , $n \in \mathbb{N}$ , be such that $f \in C^1(\mathbb{R}^n)$ , $f(0) = 0$ , $f(x) > 0$ for all $x \in \mathbb{R}^n \setminus\{0\}$ . Is it true that such function must be convex on a neighborhood of the origin? If not, can you come up with a counterexample? Considering the simplest scenario when $n = 1$ , I expect that a smooth function with infinite amount of minima approaching the origin should serve as a counterexample. But I am unable to construct an explicit formula for the function.","Let , , be such that , , for all . Is it true that such function must be convex on a neighborhood of the origin? If not, can you come up with a counterexample? Considering the simplest scenario when , I expect that a smooth function with infinite amount of minima approaching the origin should serve as a counterexample. But I am unable to construct an explicit formula for the function.",f : \mathbb{R}^n \to \mathbb{R} n \in \mathbb{N} f \in C^1(\mathbb{R}^n) f(0) = 0 f(x) > 0 x \in \mathbb{R}^n \setminus\{0\} n = 1,"['real-analysis', 'multivariable-calculus', 'convex-analysis']"
96,Calculate arc length of $\sqrt[3]{x^2} + \sqrt[3]{y^2} = \sqrt[3]{9}$,Calculate arc length of,\sqrt[3]{x^2} + \sqrt[3]{y^2} = \sqrt[3]{9},"It is necessary to calculate the length of the arc of the  curve below. There  have been attempts to raise to the 3rd power, a complex derivative and integral are obtained $$\sqrt[3]{x^2} + \sqrt[3]{y^2} = \sqrt[3]{9}$$","It is necessary to calculate the length of the arc of the  curve below. There  have been attempts to raise to the 3rd power, a complex derivative and integral are obtained",\sqrt[3]{x^2} + \sqrt[3]{y^2} = \sqrt[3]{9},"['calculus', 'integration', 'multivariable-calculus', 'line-integrals', 'arc-length']"
97,"Double Integration in region $A=\{ (x,y)\in \mathbb{R}^{2} : x^{2}+y^{2}\le 1, x+y \ge 1, y \le x\}$.",Double Integration in region .,"A=\{ (x,y)\in \mathbb{R}^{2} : x^{2}+y^{2}\le 1, x+y \ge 1, y \le x\}","Calculate $$\iint _{A} (x^{2}+y^{2})^{-3/2} \,dx\,dy\,,$$ where $A=\{ (x,y)\in \mathbb{R}^{2} : x^{2}+y^{2}\le 1, x+y \ge 1, y \le x\}$ . I first found the intersection points that are $(1,0)$ , $\left(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}\right)$ and $\left(\frac{1}{2}, \frac{1}{2}\right)$ . And the determined the regions \begin{split} D & =\left\{(x,y)\in \mathbb{R}^{2}: x^{2}+y^{2}, y \le x\} = \{(r,\theta)\in \mathbb{R}^{2}: 0 \le r \le 1, 0 \le \theta \le \frac{\pi}{4} \right\}\\ B & =\left\{(x,y)\in \mathbb{R}^{2}: 0 \le x \le \frac{1}{\sqrt{2}}, 0 \le y \le x\right\}\\ C & =\left\{(x,y)\in \mathbb{R}^{2}: \frac{1}{\sqrt{2}} \le x \le 1,  \frac{1}{\sqrt{2}} \le y \le 1-x \right\} \end{split} Then, $$\iint _{A} (x^{2}+y^{2})^{-3/2} \,dx\,dy = \iint_{D} (x^{2}+y^{2})^{-3/2} \,dx\,dy - \iint_{B} (x^{2}+y^{2})^{-3/2} \,dx\,dy - \iint_{C} (x^{2}+y^{2})^{-3/2} \,dx\,dy$$ Is this right? Or is there any other easiest way?","Calculate where . I first found the intersection points that are , and . And the determined the regions Then, Is this right? Or is there any other easiest way?","\iint _{A} (x^{2}+y^{2})^{-3/2} \,dx\,dy\,, A=\{ (x,y)\in \mathbb{R}^{2} : x^{2}+y^{2}\le 1, x+y \ge 1, y \le x\} (1,0) \left(\frac{1}{\sqrt{2}}, \frac{1}{\sqrt{2}}\right) \left(\frac{1}{2}, \frac{1}{2}\right) \begin{split}
D & =\left\{(x,y)\in \mathbb{R}^{2}: x^{2}+y^{2}, y \le x\} = \{(r,\theta)\in \mathbb{R}^{2}: 0 \le r \le 1, 0 \le \theta \le \frac{\pi}{4} \right\}\\
B & =\left\{(x,y)\in \mathbb{R}^{2}: 0 \le x \le \frac{1}{\sqrt{2}}, 0 \le y \le x\right\}\\
C & =\left\{(x,y)\in \mathbb{R}^{2}: \frac{1}{\sqrt{2}} \le x \le 1,  \frac{1}{\sqrt{2}} \le y \le 1-x \right\}
\end{split} \iint _{A} (x^{2}+y^{2})^{-3/2} \,dx\,dy = \iint_{D} (x^{2}+y^{2})^{-3/2} \,dx\,dy - \iint_{B} (x^{2}+y^{2})^{-3/2} \,dx\,dy - \iint_{C} (x^{2}+y^{2})^{-3/2} \,dx\,dy","['integration', 'multivariable-calculus', 'definite-integrals', 'multiple-integral']"
98,Help with continuity of a multivariable piecewise function,Help with continuity of a multivariable piecewise function,,"I need help finding if the limit of $g(x,y)$ at $(0,0)$ and at $(2,0)$ to see if it is continuous on these points. I get confused, because normally these piecewise functions are defined such that $(x,y)$ different than some $(a,b)$ but here I have no idea how to do it because I can approach $(0,0)$ or $(2,0)$ from both pieces of the function... And if I wanted to see the differentiability as well, what should I do? I would really appreciate if you could explain this to me. Thank you !","I need help finding if the limit of at and at to see if it is continuous on these points. I get confused, because normally these piecewise functions are defined such that different than some but here I have no idea how to do it because I can approach or from both pieces of the function... And if I wanted to see the differentiability as well, what should I do? I would really appreciate if you could explain this to me. Thank you !","g(x,y) (0,0) (2,0) (x,y) (a,b) (0,0) (2,0)","['calculus', 'limits', 'multivariable-calculus', 'functions', 'piecewise-continuity']"
99,Help finding partial derivative with chain rule,Help finding partial derivative with chain rule,,"I'm having trouble finding the partial derivative of $z$ with respect to $x$ of this function: $$z(x,y) = f(x + y) + f(x - y)$$ I saw this exercise online, but I can't figure it out. How can I solve it? Because the functions $f(x + y)$ and $f(x - y)$ only depend on one variable, but I don't understand why their input is an expression involving $x$ and $y$ . Thank you!","I'm having trouble finding the partial derivative of with respect to of this function: I saw this exercise online, but I can't figure it out. How can I solve it? Because the functions and only depend on one variable, but I don't understand why their input is an expression involving and . Thank you!","z x z(x,y) = f(x + y) + f(x - y) f(x + y) f(x - y) x y","['calculus', 'multivariable-calculus', 'derivatives', 'chain-rule']"
