,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Does an irreducible operator generate a nuclear $C^{*}$-algebra?,Does an irreducible operator generate a nuclear -algebra?,C^{*},"Let $H$ be an infinite dimensional separable Hilbert space and $B(H)$ the algebra of bounded operators. Definition : An operator $T \in B(H)$ is irreducible ( Halmos 1968 ) if its commutant $\{ T\}'$ does not contain projections other than $0$ and $I$ (i.e., $T \ne T_{1} \oplus T_{2}$ , or equivalently, $\{T,T^{*}\}''=B(H)$ ). Definition : A $C^{*}$ -algebra $\mathcal{A}$ is nuclear if and only if its enveloping von Neumann algebra $\pi_{U}(\mathcal{A})''$ (with $\pi_{U}$ its universal representation )  is hyperfinite . Let $T \in B(H)$ be an irreducible operator, and let $\mathcal{A} = C^{*}(T)$ .   Now $W^{*}(T) = \mathcal{A}''$ is the von Neumann algebra generated by $\mathcal{A}$ ( a priori , it's not its enveloping von Neumann algebra).   Now by definition of irreducibility, $W^{*}(T) = B(H)$ , which is the hyperfinite $I_{\infty}$ factor. Is $\pi_{U}(\mathcal{A})''$ also hyperfinite ? Does an irreducible operator generate a nuclear $C^{*}$ -algebra ? If no, is it nevertheless an exact $C^{*}$ -algebra ? Remark : All nuclear $C^{*}$ -algebras and their $C^{*}$ -subalgebras are exact.","Let be an infinite dimensional separable Hilbert space and the algebra of bounded operators. Definition : An operator is irreducible ( Halmos 1968 ) if its commutant does not contain projections other than and (i.e., , or equivalently, ). Definition : A -algebra is nuclear if and only if its enveloping von Neumann algebra (with its universal representation )  is hyperfinite . Let be an irreducible operator, and let .   Now is the von Neumann algebra generated by ( a priori , it's not its enveloping von Neumann algebra).   Now by definition of irreducibility, , which is the hyperfinite factor. Is also hyperfinite ? Does an irreducible operator generate a nuclear -algebra ? If no, is it nevertheless an exact -algebra ? Remark : All nuclear -algebras and their -subalgebras are exact.","H B(H) T \in B(H) \{ T\}' 0 I T \ne T_{1} \oplus T_{2} \{T,T^{*}\}''=B(H) C^{*} \mathcal{A} \pi_{U}(\mathcal{A})'' \pi_{U} T \in B(H) \mathcal{A} = C^{*}(T) W^{*}(T) = \mathcal{A}'' \mathcal{A} W^{*}(T) = B(H) I_{\infty} \pi_{U}(\mathcal{A})'' C^{*} C^{*} C^{*} C^{*}","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras', 'von-neumann-algebras']"
1,Codimension in the completion,Codimension in the completion,,Let $X$ be a normed space and let $Y\subset X$ be a subspace of codimension 1. Let $\operatorname{cl}_{\widehat{X}}(Y)$ be the closure of $Y$ in the completion $\widehat{X}$ of $X$. Is still the dimension of $\widehat{X}/\operatorname{cl}_{\widehat{X}}(Y)$ equal to one?,Let $X$ be a normed space and let $Y\subset X$ be a subspace of codimension 1. Let $\operatorname{cl}_{\widehat{X}}(Y)$ be the closure of $Y$ in the completion $\widehat{X}$ of $X$. Is still the dimension of $\widehat{X}/\operatorname{cl}_{\widehat{X}}(Y)$ equal to one?,,['functional-analysis']
2,Question on a functional analysis exercise.,Question on a functional analysis exercise.,,"These days I am doing some independent study of functional analysis. While solving problems, I could not handle the following part of an exercise (exercise 13, chapter 1 of Rudin's Functional Analysis). Let $C$ be the vector space of all complex continuous functions on $[0,1]$. Define $$d(f,g)=\int_0^1 \frac{|f(x)-g(x)|}{1+|f(x)-g(x)|}dx.$$ Let $(C,\sigma)$ be $C$ with the topology induced by this metric. Let $(C,\tau)$ be the topological vector space defined by the seminorms $$p_x(f)=|f(x)| \quad (0\le x \le 1).$$ Prove that every $\tau-$bounded set in $C$ is also $\sigma-$bounded and that the identity map  $id:(C,\tau)\to (C,\sigma)$ therefore carries bounded sets into bounded sets. *Because of the definition of our seminorm, a set $E$ is $\tau-$bounded if and only if for each $x\in [0,1]$ there exists $M_x \ge 0$ such that $p_x(f)=|f(x)| \le M_x$ for all $f\in E$. To show that $E$ is $\sigma-$bounded, I tried to prove that for any $\delta>0$, $B(0,\delta)$ absorbs $E$, i.e. there exists $t>0$ such that $\frac{1}{t} E \subset B(0,\delta)$, but I am stuck here. I would really appreciate it if you could give me some sketches or hints on this. Thank you.","These days I am doing some independent study of functional analysis. While solving problems, I could not handle the following part of an exercise (exercise 13, chapter 1 of Rudin's Functional Analysis). Let $C$ be the vector space of all complex continuous functions on $[0,1]$. Define $$d(f,g)=\int_0^1 \frac{|f(x)-g(x)|}{1+|f(x)-g(x)|}dx.$$ Let $(C,\sigma)$ be $C$ with the topology induced by this metric. Let $(C,\tau)$ be the topological vector space defined by the seminorms $$p_x(f)=|f(x)| \quad (0\le x \le 1).$$ Prove that every $\tau-$bounded set in $C$ is also $\sigma-$bounded and that the identity map  $id:(C,\tau)\to (C,\sigma)$ therefore carries bounded sets into bounded sets. *Because of the definition of our seminorm, a set $E$ is $\tau-$bounded if and only if for each $x\in [0,1]$ there exists $M_x \ge 0$ such that $p_x(f)=|f(x)| \le M_x$ for all $f\in E$. To show that $E$ is $\sigma-$bounded, I tried to prove that for any $\delta>0$, $B(0,\delta)$ absorbs $E$, i.e. there exists $t>0$ such that $\frac{1}{t} E \subset B(0,\delta)$, but I am stuck here. I would really appreciate it if you could give me some sketches or hints on this. Thank you.",,"['analysis', 'functional-analysis']"
3,"If $U$ has $0$ intersection with the nonnegative orthant, why does $U^\perp$ contain a strongly positive vector?","If  has  intersection with the nonnegative orthant, why does  contain a strongly positive vector?",U 0 U^\perp,"In my book, I'm doing an exercise that says I can use the fact that if $U$ is a subspace of $\mathbb{R}^n$, and $U\cap\mathbb{R}_+^n=\{0\}$, where $$ \mathbb{R}_+^n=\{(a_1,\dots,a_n)\mid a_i\geq 0\}, $$ then $U^\perp$ contains a strongly positive vector, that is, a vector whose coordinates are all positive. I could do the exercise, but I don't like using a fact I can't prove. Is there a reference or proof of this fact available?","In my book, I'm doing an exercise that says I can use the fact that if $U$ is a subspace of $\mathbb{R}^n$, and $U\cap\mathbb{R}_+^n=\{0\}$, where $$ \mathbb{R}_+^n=\{(a_1,\dots,a_n)\mid a_i\geq 0\}, $$ then $U^\perp$ contains a strongly positive vector, that is, a vector whose coordinates are all positive. I could do the exercise, but I don't like using a fact I can't prove. Is there a reference or proof of this fact available?",,"['linear-algebra', 'functional-analysis', 'reference-request']"
4,A question concerning the Stokes operator and its powers.,A question concerning the Stokes operator and its powers.,,"Let $\Omega\subset \mathbb{R}^N$ wehre $N=2,3$ be a Lipschitz domain. Define $$H=\{u\in L^2(\Omega)^N:\ \operatorname{div}u=0\ \mbox{and}\ \ \gamma(u)=0 \}$$ $$V=\{u\in H_0^1(\Omega):\ \operatorname{div}u=0\}$$ where $\gamma$ is defined as in this answer . It is knows that $V\subset H\subset V^\star$ is a Hilbert triple. The Stokes operator $A:D(A)\to H$ is defined by $$\langle Au,v\rangle_{V^\star,V}=\int\nabla u\cdot\nabla v$$ where $D(A)=\{u\in V:\ Au\in H\}$. It is well know that the Stokes operator (see here chapter IV) satisfies all hypothesis of Spectral Theorem for unbounded operators, hence, it possess a sequence of positive (because $A$ is positive) eigenvalues $\lambda_k$ which tends to $\infty$. Therefore it is possible to define $D(A^s)$ for all $s\geq 0$, in fact $$D(A^s)=\{u\in H:\ \sum\lambda_k^{2s}(u,w_k)^2_H<\infty\}$$ where $w_k$ are the eigenfunctions and $A^s u=\sum \lambda_k^s(u,w_k)w_k$. Define $V_{s}= D(A^{s/2})$ and we take on $V_s$ the norm $\|u\|=\|A^s u\|_2$. If $\Omega\in C^{1,1}$, then the authors of the last citation show in Proposition IV.5.10 that $V_s= V\cap H^s(\Omega)^N$ for $s\in [1,2]$. On the other hand, in this book page 161, the authors define $V^s$ (for $s\in [1,2]$) as the closure of $\{u\in C_0^\infty (\Omega):\ \operatorname{div}(u)=0 \}$ in $H_0^1(\Omega)\cap H^s(\Omega)$ with the norm $\sqrt{\|\cdot\|^2_{H_0^1}+\|\cdot\|^2_{H^s}}$. Now, I have two questions: I - Is $V^s=V_s$? II - If $I$ is false, can I have at least $V_s\subset H_0^1(\Omega)\cap H^s(\Omega)$ continuously embedded? Thank you","Let $\Omega\subset \mathbb{R}^N$ wehre $N=2,3$ be a Lipschitz domain. Define $$H=\{u\in L^2(\Omega)^N:\ \operatorname{div}u=0\ \mbox{and}\ \ \gamma(u)=0 \}$$ $$V=\{u\in H_0^1(\Omega):\ \operatorname{div}u=0\}$$ where $\gamma$ is defined as in this answer . It is knows that $V\subset H\subset V^\star$ is a Hilbert triple. The Stokes operator $A:D(A)\to H$ is defined by $$\langle Au,v\rangle_{V^\star,V}=\int\nabla u\cdot\nabla v$$ where $D(A)=\{u\in V:\ Au\in H\}$. It is well know that the Stokes operator (see here chapter IV) satisfies all hypothesis of Spectral Theorem for unbounded operators, hence, it possess a sequence of positive (because $A$ is positive) eigenvalues $\lambda_k$ which tends to $\infty$. Therefore it is possible to define $D(A^s)$ for all $s\geq 0$, in fact $$D(A^s)=\{u\in H:\ \sum\lambda_k^{2s}(u,w_k)^2_H<\infty\}$$ where $w_k$ are the eigenfunctions and $A^s u=\sum \lambda_k^s(u,w_k)w_k$. Define $V_{s}= D(A^{s/2})$ and we take on $V_s$ the norm $\|u\|=\|A^s u\|_2$. If $\Omega\in C^{1,1}$, then the authors of the last citation show in Proposition IV.5.10 that $V_s= V\cap H^s(\Omega)^N$ for $s\in [1,2]$. On the other hand, in this book page 161, the authors define $V^s$ (for $s\in [1,2]$) as the closure of $\{u\in C_0^\infty (\Omega):\ \operatorname{div}(u)=0 \}$ in $H_0^1(\Omega)\cap H^s(\Omega)$ with the norm $\sqrt{\|\cdot\|^2_{H_0^1}+\|\cdot\|^2_{H^s}}$. Now, I have two questions: I - Is $V^s=V_s$? II - If $I$ is false, can I have at least $V_s\subset H_0^1(\Omega)\cap H^s(\Omega)$ continuously embedded? Thank you",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
5,Prove that the limit exist,Prove that the limit exist,,"Let  $T : H \rightarrow H$ is a linear continuous unitary ($T^*=T^{-1}$) operator, $H$ is a Hilbert space (not necessary). Suppose that $\forall h \in H \Rightarrow Th=h$ $T_n$ - a sequence of linear operators $T_n \underset{n\rightarrow \infty}{\longrightarrow}  T$, $|| T_n - T||\rightarrow 0$. So the sequence $T_n$ tends to $T$ in the norm and we have $\forall h \in H \ \ || T_n h - T h|| \leq || T_n - T|| \ ||h||\rightarrow 0$. Can we prove that there exists a limit of the sum $S_n= \frac{1}{n}\left( T_1 h + T_1 T_2 h + \dots + T_1 \dots T_n h \right)$ where $n \rightarrow \infty$?","Let  $T : H \rightarrow H$ is a linear continuous unitary ($T^*=T^{-1}$) operator, $H$ is a Hilbert space (not necessary). Suppose that $\forall h \in H \Rightarrow Th=h$ $T_n$ - a sequence of linear operators $T_n \underset{n\rightarrow \infty}{\longrightarrow}  T$, $|| T_n - T||\rightarrow 0$. So the sequence $T_n$ tends to $T$ in the norm and we have $\forall h \in H \ \ || T_n h - T h|| \leq || T_n - T|| \ ||h||\rightarrow 0$. Can we prove that there exists a limit of the sum $S_n= \frac{1}{n}\left( T_1 h + T_1 T_2 h + \dots + T_1 \dots T_n h \right)$ where $n \rightarrow \infty$?",,['functional-analysis']
6,Sum of Closed Operators,Sum of Closed Operators,,"If $A$ and $B$ are two closed operators on a Hilbert space (not defined everywhere), is their sum closed as well? I think not, but cannot construct a counterexample. Some posts on this site do address this but they are not complete. For example, Sum of Closed Operators Closable? gives two operators and shows that their sum is not cloasable, but does not show that the operators themselves are closed. There is another post saying the same thing Counterexample for ""the sum of closed operators is closable"" but the question is still unresolved. Could someone give a different, simpler counterexample?","If $A$ and $B$ are two closed operators on a Hilbert space (not defined everywhere), is their sum closed as well? I think not, but cannot construct a counterexample. Some posts on this site do address this but they are not complete. For example, Sum of Closed Operators Closable? gives two operators and shows that their sum is not cloasable, but does not show that the operators themselves are closed. There is another post saying the same thing Counterexample for ""the sum of closed operators is closable"" but the question is still unresolved. Could someone give a different, simpler counterexample?",,"['functional-analysis', 'operator-theory']"
7,Measurable function of a transformation still measurable,Measurable function of a transformation still measurable,,"I'm looking for a maybe simpler or more elemental proof of the following statement: Let $f:\mathbb{R^n}\to \mathbb{R}$ be (Lebesgue-)measurable. Then $F:\mathbb{R^{2n}}\to \mathbb{R}$ such that $F(x,y)=f(x-y)$ is (Lebesgue-)measurable. The proof I know works in the following way: First show that $f$ is measurable on $\mathbb{R^{2n}}$. Then $T(x,y)=(x-y)$ is Lipschitz and hence $f\circ T$ is measurable (by a theorem ). Can one somehow argue without the Lipschitz continuity in the last step or with a different ansatz? Several books I've seen introduce the convolution using that $f(x-y)$ is measurable but proof that Lipschitz $T$ maps measurable sets onto measurable sets later in the text.","I'm looking for a maybe simpler or more elemental proof of the following statement: Let $f:\mathbb{R^n}\to \mathbb{R}$ be (Lebesgue-)measurable. Then $F:\mathbb{R^{2n}}\to \mathbb{R}$ such that $F(x,y)=f(x-y)$ is (Lebesgue-)measurable. The proof I know works in the following way: First show that $f$ is measurable on $\mathbb{R^{2n}}$. Then $T(x,y)=(x-y)$ is Lipschitz and hence $f\circ T$ is measurable (by a theorem ). Can one somehow argue without the Lipschitz continuity in the last step or with a different ansatz? Several books I've seen introduce the convolution using that $f(x-y)$ is measurable but proof that Lipschitz $T$ maps measurable sets onto measurable sets later in the text.",,"['functional-analysis', 'measure-theory']"
8,$C^k_b$ with sup-norm not complete,with sup-norm not complete,C^k_b,"Let $C^n_b=\{ f : I\rightarrow \mathbb{C}: f~n\textrm{-times continuously differentiable and } \|f\|_{n,\infty} < \infty\}$, where $\emptyset\neq I\subseteq\mathbb{R}$ denotes an open interval and $\|f\|_{n,\infty}=\Sigma_{k=0}^n\|f^{(k)}\|_\infty$ be the function space of our concern. Equipped with the supremum norm this should not be complete. Does anyone have a (classic) example of a Cauchy sequence for proving the noncompletness?","Let $C^n_b=\{ f : I\rightarrow \mathbb{C}: f~n\textrm{-times continuously differentiable and } \|f\|_{n,\infty} < \infty\}$, where $\emptyset\neq I\subseteq\mathbb{R}$ denotes an open interval and $\|f\|_{n,\infty}=\Sigma_{k=0}^n\|f^{(k)}\|_\infty$ be the function space of our concern. Equipped with the supremum norm this should not be complete. Does anyone have a (classic) example of a Cauchy sequence for proving the noncompletness?",,"['calculus', 'real-analysis', 'functional-analysis']"
9,The $QC$ functions described by Sarason.,The  functions described by Sarason.,QC,"I'm reading one of the articles written by Sarason. He define the space $QC$ as the  $C^*$algebra generated by $H^{\infty} + C$, that is, $QC=(H^{\infty} + C) \cap (\bar{H}^{\infty} + C)$. I'm using the fact that $QC\neq C$ but  i need an explicit example of this. All that I have is this: if $f$ is a conformal maping between the unit disk and a ""suitable"" domain, then, the boundary function is in $QC$. Another possibility is to find a continuous real value function $u$ such that its conjugate $v$ (the function $v$ such that $u+iv$ is analytic) is discontinuous at one point. I really appreciate your help. Thanks in advance.","I'm reading one of the articles written by Sarason. He define the space $QC$ as the  $C^*$algebra generated by $H^{\infty} + C$, that is, $QC=(H^{\infty} + C) \cap (\bar{H}^{\infty} + C)$. I'm using the fact that $QC\neq C$ but  i need an explicit example of this. All that I have is this: if $f$ is a conformal maping between the unit disk and a ""suitable"" domain, then, the boundary function is in $QC$. Another possibility is to find a continuous real value function $u$ such that its conjugate $v$ (the function $v$ such that $u+iv$ is analytic) is discontinuous at one point. I really appreciate your help. Thanks in advance.",,"['complex-analysis', 'analysis', 'functional-analysis']"
10,Poincaré inequality and Rellich Theorem in one dimensional weighted Sobolev space,Poincaré inequality and Rellich Theorem in one dimensional weighted Sobolev space,,"Consider the weighted Sobolev space $W^{1,2}\big((0,R),r^{N-1}\big)$, $N=2,3,\ldots$ and its subspace $W_0^{1,2}\big((0,R),r^{N-1}\big)$. Anyone knows if the Poincaré inequality is true in this case? And if the $W^{1,2}\big((0,R),r^{N-1}\big)$ is compactly embedded in $L^2\big((0,R),r^{N-1}\big)$?","Consider the weighted Sobolev space $W^{1,2}\big((0,R),r^{N-1}\big)$, $N=2,3,\ldots$ and its subspace $W_0^{1,2}\big((0,R),r^{N-1}\big)$. Anyone knows if the Poincaré inequality is true in this case? And if the $W^{1,2}\big((0,R),r^{N-1}\big)$ is compactly embedded in $L^2\big((0,R),r^{N-1}\big)$?",,"['functional-analysis', 'inequality', 'sobolev-spaces', 'compactness']"
11,Existence of a non zero element in the dual,Existence of a non zero element in the dual,,"Let $S$ a vector subspace  of a normed vector space $X$ such that $\overline{S} \neq X$. Show that, with the Hahn-Banach Theorem (Geometric Version) , that there is $F\in X^{\prime}$ such that $\|F\|\neq 0$ and $F(x) = 0$ for all $x\in S$. I know how to prove it, using a consequence of the Hahn-Banach Theorem with the distance function, but I don't know how do it without that result. Please help me and thanx in advance.","Let $S$ a vector subspace  of a normed vector space $X$ such that $\overline{S} \neq X$. Show that, with the Hahn-Banach Theorem (Geometric Version) , that there is $F\in X^{\prime}$ such that $\|F\|\neq 0$ and $F(x) = 0$ for all $x\in S$. I know how to prove it, using a consequence of the Hahn-Banach Theorem with the distance function, but I don't know how do it without that result. Please help me and thanx in advance.",,['functional-analysis']
12,"Simple proof that $z\mapsto \exp(i\langle \omega,z\rangle)$ are linearly independent",Simple proof that  are linearly independent,"z\mapsto \exp(i\langle \omega,z\rangle)","I am interested in proving that the family of functions $$\{f_{\omega}: \mathbb{C}^n\rightarrow\mathbb{C}, f_\omega(z) = \exp(i\langle \omega, z \rangle): \omega \in \mathbb{C}^n\},$$ where $\langle \cdot,\cdot\rangle$ is the usual hermitian dot product, is $\mathbb{C}$-linearly independent. In the case $n=1$ an expeditive argument consists in remarking that these functions are eigenfunctions with distinct eigenvalues of the complex derivation operator. Is there a somewhat similar argument, or a simple way to prove the result in dimension $n$ ?","I am interested in proving that the family of functions $$\{f_{\omega}: \mathbb{C}^n\rightarrow\mathbb{C}, f_\omega(z) = \exp(i\langle \omega, z \rangle): \omega \in \mathbb{C}^n\},$$ where $\langle \cdot,\cdot\rangle$ is the usual hermitian dot product, is $\mathbb{C}$-linearly independent. In the case $n=1$ an expeditive argument consists in remarking that these functions are eigenfunctions with distinct eigenvalues of the complex derivation operator. Is there a somewhat similar argument, or a simple way to prove the result in dimension $n$ ?",,['functional-analysis']
13,Measuring Vitali sets,Measuring Vitali sets,,"If $V$ is a vector space and $m$ is the counting measure, then $$\dim(V) = \inf \{m(U) : U \subset V, \text{ span}(U) = V\}.$$ Given a measure space $(V, \mathcal M, \mu)$ such that $V$ is a vector space, have people considered the following definition? $$\dim_\mu(V) := \inf \{\mu(U) : U \in \mathcal M, \text{ span}(U) = V\}$$ In particular, considering $\mathbb R$ as a $\mathbb Q$-vector space, is there a measure $\mu$ such that $0 < \dim_\mu(\mathbb R/\mathbb Q) < \infty$ ?","If $V$ is a vector space and $m$ is the counting measure, then $$\dim(V) = \inf \{m(U) : U \subset V, \text{ span}(U) = V\}.$$ Given a measure space $(V, \mathcal M, \mu)$ such that $V$ is a vector space, have people considered the following definition? $$\dim_\mu(V) := \inf \{\mu(U) : U \in \mathcal M, \text{ span}(U) = V\}$$ In particular, considering $\mathbb R$ as a $\mathbb Q$-vector space, is there a measure $\mu$ such that $0 < \dim_\mu(\mathbb R/\mathbb Q) < \infty$ ?",,"['real-analysis', 'analysis', 'functional-analysis', 'measure-theory', 'dimension-theory-analysis']"
14,"Prove that the polynomial $P(x_1,x_2...,x_n)=0$ given a set of conditions.",Prove that the polynomial  given a set of conditions.,"P(x_1,x_2...,x_n)=0","Let $P(x_1,...,x_n)\in\mathbb{R}[x_1,...,x_n]$ (i.e. $P$ is a polynomial of real coefficients in $x_1,..,x_n$). We are given that $\left(\frac{\partial^2}{\partial x_1^2}+...+\frac{\partial^2}{\partial x_n^2}\right)P(x_1,..,x_n)\equiv 0$ and $(x_1^2+x_2^2+...+x_n^2)|P(x_1,...,x_n)$, Please prove that $P\equiv0$.","Let $P(x_1,...,x_n)\in\mathbb{R}[x_1,...,x_n]$ (i.e. $P$ is a polynomial of real coefficients in $x_1,..,x_n$). We are given that $\left(\frac{\partial^2}{\partial x_1^2}+...+\frac{\partial^2}{\partial x_n^2}\right)P(x_1,..,x_n)\equiv 0$ and $(x_1^2+x_2^2+...+x_n^2)|P(x_1,...,x_n)$, Please prove that $P\equiv0$.",,"['real-analysis', 'analysis', 'functional-analysis', 'polynomials', 'contest-math']"
15,Cohomology with Coefficients in the sheaf of distributions,Cohomology with Coefficients in the sheaf of distributions,,It just occurred to me that one could form the sheaf of distributions $F$ on any manifold where for an open set $U$ we have $F(U)$ is the algebra of distributions on $U.$ What does cohomology with coefficients in $F$ represent? Is there a good interpretation using differential forms or differential operators?,It just occurred to me that one could form the sheaf of distributions $F$ on any manifold where for an open set $U$ we have $F(U)$ is the algebra of distributions on $U.$ What does cohomology with coefficients in $F$ represent? Is there a good interpretation using differential forms or differential operators?,,"['functional-analysis', 'differential-geometry']"
16,Extension of a premeasure to a measure,Extension of a premeasure to a measure,,"Let $X$ be any set containing more than one point and $A$ a proper nonempty subset of $X$ . Define $S= \{A, X\}$ and the set function $\mu: S \rightarrow [0, \infty]$ by $\mu(A) = 1$ and $\mu(X) = 2$ . Show that $\mu: S \rightarrow [0, \infty]$ is a premeasure. Can $\mu$ be extended to a measure? What are the subsets of $X$ that are measurable with respect to the outer measure $\mu^*$ induced by $\mu$ ? How would these change if instead we considered the collection $S = \{\emptyset, [0, 1], [0, 3], [2, 3]\}$ of subsets of $R$ and define $\mu(\emptyset)=0$ , $\mu([0, 1])=1$ , $\mu([0, 3])=1$ , $\mu([2, 3])=1$ ? Solution 1: Take $a \in A$ , then $\mu^*(\{a\}) = \inf \sum_{k=1}^\infty \mu(E_k)$ , $\{a\} \subset\bigcup_{k=1}^\infty E_k$ , where $E_k \in S$ , then $\mu^*(\{a\}) = 1$ , and, similarly, $\mu^*(\{b\}) = 2$ where $b \in X$ . Let $\emptyset \neq C \subset A$ . Then, $\mu^*(C) = 1$ . Suppose, $D \cap (X\sim  A) \neq \emptyset$ , then $\mu^*(D)=2$ . Show that $\mu: S \rightarrow [0, \infty]$ is a premeasure. Using the definition of premeasure: Let $S$ be a collection of subsets of a set $X$ and $\mu: S \rightarrow [0, \infty]$ a set function. Then, $\mu$ is called a premeasure provided $\mu$ is both finitely additive and countably monotone, and if $\emptyset$ belongs to $S$ , then $\mu(\emptyset)=0$ . Should I proceed the same way as in Lebesgue Measure? Finitely Additive: So, show $\mu(\bigcup_{k=1}^n E_k) \leq \sum_{k=1}^n \mu (E_k)$ (by subadditivity) and then, $\mu(\bigcup_{k=1}^n E_k) \geq \sum_{k=1}^n \mu (E_k)$ . Countably Monotone: $\mu(E) \leq \sum_{k=1}^\infty \mu(E_k)$ or should I do something else in general measure? Lastly: Since $\emptyset \notin S$ , this isn't necessary. Can $\mu$ be extended to a measure? Is $A$ measurable? If so, then $\mu^*(B) = \mu^*(B \cap A) + \mu^*(B \cap A^c)$ . Let $B = \{a, b\}$ . $\mu^*(B) = 2$ (from before). $\{a\} \in B \cap A \subset A$ , $\mu^*(A \cap B) = 1$ . $\{b\} \in B \cap A^c$ , $\mu^*(B \cap A^c) = 2$ $2 \neq 1 + 2$ Is this enough to show that A is not measurable and that $\mu$ cannot be extended to measure? Which subsets of $X$ are measurable with respect to the outer measure $\mu^*$ induced by $\mu$ ? So, we need to find the $\mu^*$ measurable sets. $E$ is measurable with respect to $\mu^*$ if and only if $\forall B \subset X$ . $$\mu^*(B) = \mu^*(B \cap E) + \mu^*(B \cap E^c)$$ Then, $\emptyset, X$ are measurable because $$\mu^*(B \cap\emptyset) + \mu^*(B \cap S) = \mu^*(\emptyset) + \mu^*(B) = \mu^*(B)$$ and $$\mu^*(B \cap X) + \mu^*(B \cap (S \sim B)) = \mu^*(B) + \mu^*(\emptyset) = \mu^*(B)$$ Solution 2: I won't go into anything because it seems like it will basically be the same thing.  Are there any major differences that I should know about?","Let be any set containing more than one point and a proper nonempty subset of . Define and the set function by and . Show that is a premeasure. Can be extended to a measure? What are the subsets of that are measurable with respect to the outer measure induced by ? How would these change if instead we considered the collection of subsets of and define , , , ? Solution 1: Take , then , , where , then , and, similarly, where . Let . Then, . Suppose, , then . Show that is a premeasure. Using the definition of premeasure: Let be a collection of subsets of a set and a set function. Then, is called a premeasure provided is both finitely additive and countably monotone, and if belongs to , then . Should I proceed the same way as in Lebesgue Measure? Finitely Additive: So, show (by subadditivity) and then, . Countably Monotone: or should I do something else in general measure? Lastly: Since , this isn't necessary. Can be extended to a measure? Is measurable? If so, then . Let . (from before). , . , Is this enough to show that A is not measurable and that cannot be extended to measure? Which subsets of are measurable with respect to the outer measure induced by ? So, we need to find the measurable sets. is measurable with respect to if and only if . Then, are measurable because and Solution 2: I won't go into anything because it seems like it will basically be the same thing.  Are there any major differences that I should know about?","X A X S= \{A, X\} \mu: S \rightarrow [0, \infty] \mu(A) = 1 \mu(X) = 2 \mu: S \rightarrow [0, \infty] \mu X \mu^* \mu S = \{\emptyset, [0, 1], [0, 3], [2, 3]\} R \mu(\emptyset)=0 \mu([0, 1])=1 \mu([0, 3])=1 \mu([2, 3])=1 a \in A \mu^*(\{a\}) = \inf \sum_{k=1}^\infty \mu(E_k) \{a\} \subset\bigcup_{k=1}^\infty E_k E_k \in S \mu^*(\{a\}) = 1 \mu^*(\{b\}) = 2 b \in X \emptyset \neq C \subset A \mu^*(C) = 1 D \cap (X\sim  A) \neq \emptyset \mu^*(D)=2 \mu: S \rightarrow [0, \infty] S X \mu: S \rightarrow [0, \infty] \mu \mu \emptyset S \mu(\emptyset)=0 \mu(\bigcup_{k=1}^n E_k) \leq \sum_{k=1}^n \mu (E_k) \mu(\bigcup_{k=1}^n E_k) \geq \sum_{k=1}^n \mu (E_k) \mu(E) \leq \sum_{k=1}^\infty \mu(E_k) \emptyset \notin S \mu A \mu^*(B) = \mu^*(B \cap A) + \mu^*(B \cap A^c) B = \{a, b\} \mu^*(B) = 2 \{a\} \in B \cap A \subset A \mu^*(A \cap B) = 1 \{b\} \in B \cap A^c \mu^*(B \cap A^c) = 2 2 \neq 1 + 2 \mu X \mu^* \mu \mu^* E \mu^* \forall B \subset X \mu^*(B) = \mu^*(B \cap E) + \mu^*(B \cap E^c) \emptyset, X \mu^*(B \cap\emptyset) + \mu^*(B \cap S) = \mu^*(\emptyset) + \mu^*(B) = \mu^*(B) \mu^*(B \cap X) + \mu^*(B \cap (S \sim B)) = \mu^*(B) + \mu^*(\emptyset) = \mu^*(B)","['real-analysis', 'functional-analysis', 'measure-theory']"
17,Lewy's example: solution with nowhere Hölder derivatives,Lewy's example: solution with nowhere Hölder derivatives,,"Hans Lewy shows in his 1957 example that a certain linear PDE with polynomial coefficients cannot have a solution with Hölder derivatives in any open subset of $\mathbb{R}^3$. I find this example cited everywhere as a ""linear equation without solution""; however that is not what appears to be shown in the paper, since (if I recall correctly) there are $C^1$ functions that are nowhere Hölder. Is a (hypothetical) ""solution"" with non-Hölder derivatives simply not considered ""well-behaved"" enough to be called a solution? Are there other results related to that paper that go further? What is the point I am missing here?","Hans Lewy shows in his 1957 example that a certain linear PDE with polynomial coefficients cannot have a solution with Hölder derivatives in any open subset of $\mathbb{R}^3$. I find this example cited everywhere as a ""linear equation without solution""; however that is not what appears to be shown in the paper, since (if I recall correctly) there are $C^1$ functions that are nowhere Hölder. Is a (hypothetical) ""solution"" with non-Hölder derivatives simply not considered ""well-behaved"" enough to be called a solution? Are there other results related to that paper that go further? What is the point I am missing here?",,"['functional-analysis', 'partial-differential-equations']"
18,Absolute norms and 1-unconditional sums,Absolute norms and 1-unconditional sums,,"Absolute norm Let $X$ and $Y$ be Banach spaces. Let $Z=X\times Y$ a norm $\|\cdot\|_N$ on $Z$ is called absolute if there is a function $N\colon R^2\rightarrow R$ such that $$ \|(x,y)\|_N=N((\|x\|, \|y\|)) \qquad \text{ for all } z=(x,y)\in Z. $$ For example, the $\ell_p$-norms are absolute norms. 1-unconditional sum Let $E$ be a Banach space with a 1-unconditional normalized Schauder basis. We can think of the elements of $E$ as sequences with the property that $$ \|(a_1,a_2,\dots)\|_E=\|(|a_1|,|a_2|,...\|_E \qquad \text{ for all } (a_j)\in E. $$ Note that $E$ is naturally endowed with the structure of a Banach lattice with respect to the pointwise operations. Suppose that $X_1, X_2,\dots$ are Banach spaces. Their $E$-sum $X=(X_1, X_2, \dots)_E$ consists of all sequences $(x_j)$ with $x_j\in X_j$ and $(\|{x_j}\|)\in E$ with the norm $\|(x_j)\|=\|(\|x_j\|)\|_E$. Question Let $Z=X_1\times X_2\times...$. Can I equip $Z$ with an absolute norm? If so is this norm equivalent to equipping $Z$ with an 1-unconditional norm? Thanks in advance!","Absolute norm Let $X$ and $Y$ be Banach spaces. Let $Z=X\times Y$ a norm $\|\cdot\|_N$ on $Z$ is called absolute if there is a function $N\colon R^2\rightarrow R$ such that $$ \|(x,y)\|_N=N((\|x\|, \|y\|)) \qquad \text{ for all } z=(x,y)\in Z. $$ For example, the $\ell_p$-norms are absolute norms. 1-unconditional sum Let $E$ be a Banach space with a 1-unconditional normalized Schauder basis. We can think of the elements of $E$ as sequences with the property that $$ \|(a_1,a_2,\dots)\|_E=\|(|a_1|,|a_2|,...\|_E \qquad \text{ for all } (a_j)\in E. $$ Note that $E$ is naturally endowed with the structure of a Banach lattice with respect to the pointwise operations. Suppose that $X_1, X_2,\dots$ are Banach spaces. Their $E$-sum $X=(X_1, X_2, \dots)_E$ consists of all sequences $(x_j)$ with $x_j\in X_j$ and $(\|{x_j}\|)\in E$ with the norm $\|(x_j)\|=\|(\|x_j\|)\|_E$. Question Let $Z=X_1\times X_2\times...$. Can I equip $Z$ with an absolute norm? If so is this norm equivalent to equipping $Z$ with an 1-unconditional norm? Thanks in advance!",,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
19,question about the definition of linear functions/operators (domains),question about the definition of linear functions/operators (domains),,"Suppose $\Omega_s \subset \mathbb{R}^n$ is a compact subset for each $s \in [0,T]$. I have a linear operator  $$p_t^s:H^1(\Omega_t) \to H^1(\Omega_s)$$ which maps functions on $\Omega_t$ to functions on $\Omega_s$, and $p_t^s$ is continuous with continuous inverse $p_s^t$. It does this via a diffeomorphism $P_t^s:\Omega_s \to \Omega_t$ with $p_t^s f = f \circ P_t^s$. Question We can define (the Levi-Civita connection) a modified gradient on $\Omega_t$ by $$\nabla_{\Omega_t} f := (\nabla f)^T := \nabla f - (\nabla f \cdot N)N$$ where the superscript $T$ denotes projection onto the tangent space of $\Omega_t$ and $N$ is the normal vector on $\Omega_t$. My question is for functions $g \in C^1(\Omega_s)$, is it true that $$\nabla_{\Omega_t} (fg) =g\nabla_{\Omega_t} (f)?$$ So can I take it out as a constant? Essentially, I want to use this condition in an integral over $\Omega_t$. I tried writing everything out in coordinates (eg. $x$ on $\Omega_t$ and $y$ on $\Omega_s$) and used the diffeomorphism but I am very confused.","Suppose $\Omega_s \subset \mathbb{R}^n$ is a compact subset for each $s \in [0,T]$. I have a linear operator  $$p_t^s:H^1(\Omega_t) \to H^1(\Omega_s)$$ which maps functions on $\Omega_t$ to functions on $\Omega_s$, and $p_t^s$ is continuous with continuous inverse $p_s^t$. It does this via a diffeomorphism $P_t^s:\Omega_s \to \Omega_t$ with $p_t^s f = f \circ P_t^s$. Question We can define (the Levi-Civita connection) a modified gradient on $\Omega_t$ by $$\nabla_{\Omega_t} f := (\nabla f)^T := \nabla f - (\nabla f \cdot N)N$$ where the superscript $T$ denotes projection onto the tangent space of $\Omega_t$ and $N$ is the normal vector on $\Omega_t$. My question is for functions $g \in C^1(\Omega_s)$, is it true that $$\nabla_{\Omega_t} (fg) =g\nabla_{\Omega_t} (f)?$$ So can I take it out as a constant? Essentially, I want to use this condition in an integral over $\Omega_t$. I tried writing everything out in coordinates (eg. $x$ on $\Omega_t$ and $y$ on $\Omega_s$) and used the diffeomorphism but I am very confused.",,"['functional-analysis', 'functions']"
20,Limit at infinity,Limit at infinity,,"I really want help in this problem: given a sequence of pairs $(x,y)$ in the $xy$-plane $$S=\left\{\left(n, \frac{-1}{\sqrt{n}}\right)\right\}_{n=1}^{\infty}\;,$$  how to find  $$\lim_{x\to \infty} \frac{1}{\sqrt{1+|x|}} \, \frac{1}{\big(\operatorname{dist}(x,S)\big)^{2}}$$ where ''$\operatorname{dist}(x,S)$'' means the distance between the point $x$ and the set $S$, defined by $\operatorname{dist}(x,S)=\inf\limits_{a_{n}\in S}\operatorname{dist} (x,a_{n})$. And as it is known, the distance between any two points $P=(x_{1},y_{1})$, and $Q=(x_{2},y_{2})$ is  $\operatorname{dist}(P,Q)=\sqrt{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}$. I know that the limit of the first term is zero and the limit of the second term is $\infty$, but this does't help!! Any idea? EDIT : it was just a typo, a square should be on the distance.","I really want help in this problem: given a sequence of pairs $(x,y)$ in the $xy$-plane $$S=\left\{\left(n, \frac{-1}{\sqrt{n}}\right)\right\}_{n=1}^{\infty}\;,$$  how to find  $$\lim_{x\to \infty} \frac{1}{\sqrt{1+|x|}} \, \frac{1}{\big(\operatorname{dist}(x,S)\big)^{2}}$$ where ''$\operatorname{dist}(x,S)$'' means the distance between the point $x$ and the set $S$, defined by $\operatorname{dist}(x,S)=\inf\limits_{a_{n}\in S}\operatorname{dist} (x,a_{n})$. And as it is known, the distance between any two points $P=(x_{1},y_{1})$, and $Q=(x_{2},y_{2})$ is  $\operatorname{dist}(P,Q)=\sqrt{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}$. I know that the limit of the first term is zero and the limit of the second term is $\infty$, but this does't help!! Any idea? EDIT : it was just a typo, a square should be on the distance.",,"['real-analysis', 'sequences-and-series', 'functional-analysis', 'limits']"
21,How is it useful to know what the dual of a space is isomorphic to?,How is it useful to know what the dual of a space is isomorphic to?,,"Wikipedia has a neat spaces and their duals . For example, it lists that the dual of $c_0$ is $l_1$. But how can I use that knowledge? I'm trying to prove something for all functions of the dual of $c_0$, and figured that I could use my familiarity of $l_1$ to get some properties of those functions. But I don't know how. For example, which element of $l_1$ corresponds to which functional of $c_0$? I suppose their ""scalar product"" (multiply $x\in c_0$ with $y\in l_1$ element-wise and sum the products) would be such a functional. If that's true, I could probably prove it. But I only came up with it because that was my intuition. Is there a more mechanical way? I realize that it's hard to answer the question without knowing exactly which problem I'm trying to solve, but perhaps there are some general strategies? Sorry if the question seems confused and ""ranty""; I'm having a hard time sorting this out.","Wikipedia has a neat spaces and their duals . For example, it lists that the dual of $c_0$ is $l_1$. But how can I use that knowledge? I'm trying to prove something for all functions of the dual of $c_0$, and figured that I could use my familiarity of $l_1$ to get some properties of those functions. But I don't know how. For example, which element of $l_1$ corresponds to which functional of $c_0$? I suppose their ""scalar product"" (multiply $x\in c_0$ with $y\in l_1$ element-wise and sum the products) would be such a functional. If that's true, I could probably prove it. But I only came up with it because that was my intuition. Is there a more mechanical way? I realize that it's hard to answer the question without knowing exactly which problem I'm trying to solve, but perhaps there are some general strategies? Sorry if the question seems confused and ""ranty""; I'm having a hard time sorting this out.",,['functional-analysis']
22,Showing boundedness and a coercivity condition for a bilinear form,Showing boundedness and a coercivity condition for a bilinear form,,"Suppose $\Omega \subset \mathbb{R}^n$ is a compact domain. Let $f$ and $J$ (and also $\frac 1J$) be $C^1$ functions on $\Omega$. Consider the bilinear form $a:H^1(\Omega) \times H^1(\Omega) \to \mathbb{R}$ $$a(u,v) = \int_\Omega uvf + \int_\Omega \nabla u MM^T\nabla v - \int_\Omega \nabla u MM^T\nabla J \frac{v}{J}$$ where $M = D\Phi$ is the matrix representation of the derivative of a diffeomorphism $\Phi$ between two compact hypersurfaces in $\mathbb{R}^n$ (so $\Phi$ and its derivatives are bounded). 1) How do I show that $a(u,v)$ is a bounded bilinear form? 2) How do I show that there exists a $C$ such that $$a(u,u) + C\lVert u \rVert^2_{L^2(\Omega)} \geq K\lVert u \rVert^2_{H^1(\Omega)}$$ for some $K$. (i.e. that $a$ satisfies a coercivity condition). My main problem for boundedness is I don't know how to deal with the matrix terms. I can't just say that, eg. $|vMM^Tv| \leq |vM|^2 \leq |v|^2|M|^2$ and use the fact that $\Phi$ is bounded, for example, since I can't split the vector and matrix (or can I?). For the coercivity condition, how do I deal with the last term in $a$, which has a minus sign? Also I don't know how to deal with the matrix terms in that last term. The second term is fine since it becomes $|\nabla u M|^2 > 0$ since $M$ represents derivative of the diffeomorphism $\Phi$ and has full rank.","Suppose $\Omega \subset \mathbb{R}^n$ is a compact domain. Let $f$ and $J$ (and also $\frac 1J$) be $C^1$ functions on $\Omega$. Consider the bilinear form $a:H^1(\Omega) \times H^1(\Omega) \to \mathbb{R}$ $$a(u,v) = \int_\Omega uvf + \int_\Omega \nabla u MM^T\nabla v - \int_\Omega \nabla u MM^T\nabla J \frac{v}{J}$$ where $M = D\Phi$ is the matrix representation of the derivative of a diffeomorphism $\Phi$ between two compact hypersurfaces in $\mathbb{R}^n$ (so $\Phi$ and its derivatives are bounded). 1) How do I show that $a(u,v)$ is a bounded bilinear form? 2) How do I show that there exists a $C$ such that $$a(u,u) + C\lVert u \rVert^2_{L^2(\Omega)} \geq K\lVert u \rVert^2_{H^1(\Omega)}$$ for some $K$. (i.e. that $a$ satisfies a coercivity condition). My main problem for boundedness is I don't know how to deal with the matrix terms. I can't just say that, eg. $|vMM^Tv| \leq |vM|^2 \leq |v|^2|M|^2$ and use the fact that $\Phi$ is bounded, for example, since I can't split the vector and matrix (or can I?). For the coercivity condition, how do I deal with the last term in $a$, which has a minus sign? Also I don't know how to deal with the matrix terms in that last term. The second term is fine since it becomes $|\nabla u M|^2 > 0$ since $M$ represents derivative of the diffeomorphism $\Phi$ and has full rank.",,"['functional-analysis', 'partial-differential-equations', 'banach-spaces', 'bilinear-form']"
23,$L^2$ norm inequality,norm inequality,L^2,"I need some help with this homework question. I was asked to provide an example of a $n$-dimensional subspace $W$ of $L^2[0,1]$ such that all functions in that subspace with $L^2$ norm equal to $1$ satisfy that $\Vert f\Vert_\infty\le\sqrt{n}$. I think I'll have to find an example such that the above is true for all $n$. I don't know where to start. I'm not sure if this helps, but in previous questions in the homework I showed that if $S$ is a subspace of $C[0,1]$ (which is closed at subspace of $L^2[0,1]$) then $\Vert f\Vert_{\infty}\le M\Vert f\Vert_2$ for all $f\in S$. In the second part of this question, I will need to show that if $W$ is a $n$-dimensional subspace of $L^2[0,1]$, and all elements of $W$ are continuous functions, then there exists $f\in W$ s.t. $\Vert f\Vert_2=1$ and $\Vert f\Vert_\infty\ge\sqrt{n}$.","I need some help with this homework question. I was asked to provide an example of a $n$-dimensional subspace $W$ of $L^2[0,1]$ such that all functions in that subspace with $L^2$ norm equal to $1$ satisfy that $\Vert f\Vert_\infty\le\sqrt{n}$. I think I'll have to find an example such that the above is true for all $n$. I don't know where to start. I'm not sure if this helps, but in previous questions in the homework I showed that if $S$ is a subspace of $C[0,1]$ (which is closed at subspace of $L^2[0,1]$) then $\Vert f\Vert_{\infty}\le M\Vert f\Vert_2$ for all $f\in S$. In the second part of this question, I will need to show that if $W$ is a $n$-dimensional subspace of $L^2[0,1]$, and all elements of $W$ are continuous functions, then there exists $f\in W$ s.t. $\Vert f\Vert_2=1$ and $\Vert f\Vert_\infty\ge\sqrt{n}$.",,"['real-analysis', 'functional-analysis', 'inequality', 'lp-spaces']"
24,Inner product and infinite sum,Inner product and infinite sum,,"Let $\{f_{n}\}_{n=1}^{\infty}$ be an orthogonal sequence of nonzero functions in a Hilbert space $H$ with inner product $\langle f,g\rangle_{H}=\int_{-\infty}^{\infty}f(x)g(x)dx$. Show that for any sequence of numbers $\{a_{n}\}$, with $\sum_{n}|a_{n}|^{2}<\infty$ and $\sum_{n}a_{n}f_{n}=0$ then $a_{n}=0$ for all $n$. I tried the following:  Let $\{a_{n}\}$ be a sequence, with $\sum_{n}|a_{n}|^{2}<\infty$ and $\sum_{n}a_{n}f_{n}=0$. Then pick any $f_{m}$, and take inner product with the sum: $$0=\langle f_{m}, \sum_{n}a_{n}f_{n} \rangle= \sum_{n}a_{n}\langle f_{m}, f_{n} \rangle=a_{m}\langle f_{m}, f_{m} \rangle $$ wich implies that $a_{m}=0$ for all $m$. But I'm a little worry about taking the sum out the inner product, it is like interchanging order of sum and integral, since $$\langle f_{m}, \sum_{n}a_{n}f_{n} \rangle= \int_{-\infty}^{\infty} \sum_{n}a_{n}f_{m}(x)f_{n}(x)dx=\sum_{n}a_{n} \int_{-\infty}^{\infty} f_{m}(x)f_{n}(x)dx=\sum_{n}a_{n} \langle f_{m}, f_{n} \rangle $$ Did I miss anything? Do I need to worry about this? I think I should use that $\sum_{n}|a_{n}|^{2}<\infty$ somewhere!","Let $\{f_{n}\}_{n=1}^{\infty}$ be an orthogonal sequence of nonzero functions in a Hilbert space $H$ with inner product $\langle f,g\rangle_{H}=\int_{-\infty}^{\infty}f(x)g(x)dx$. Show that for any sequence of numbers $\{a_{n}\}$, with $\sum_{n}|a_{n}|^{2}<\infty$ and $\sum_{n}a_{n}f_{n}=0$ then $a_{n}=0$ for all $n$. I tried the following:  Let $\{a_{n}\}$ be a sequence, with $\sum_{n}|a_{n}|^{2}<\infty$ and $\sum_{n}a_{n}f_{n}=0$. Then pick any $f_{m}$, and take inner product with the sum: $$0=\langle f_{m}, \sum_{n}a_{n}f_{n} \rangle= \sum_{n}a_{n}\langle f_{m}, f_{n} \rangle=a_{m}\langle f_{m}, f_{m} \rangle $$ wich implies that $a_{m}=0$ for all $m$. But I'm a little worry about taking the sum out the inner product, it is like interchanging order of sum and integral, since $$\langle f_{m}, \sum_{n}a_{n}f_{n} \rangle= \int_{-\infty}^{\infty} \sum_{n}a_{n}f_{m}(x)f_{n}(x)dx=\sum_{n}a_{n} \int_{-\infty}^{\infty} f_{m}(x)f_{n}(x)dx=\sum_{n}a_{n} \langle f_{m}, f_{n} \rangle $$ Did I miss anything? Do I need to worry about this? I think I should use that $\sum_{n}|a_{n}|^{2}<\infty$ somewhere!",,"['real-analysis', 'sequences-and-series', 'functional-analysis', 'convergence-divergence']"
25,Inverse mapping theorem over a complete non-archimedean field,Inverse mapping theorem over a complete non-archimedean field,,"Let $K$ be a complete field with respect to a non-trivial non-archimedean absolute value $|\cdot|$. Let $E$ be a vector space over $K$. A norm $||\cdot||$ on $E$ is a map $E \rightarrow \mathbb{R}$ satisfying the following properties. 1) $||x|| = 0$ if and only if $x = 0$. 2) $||\alpha x|| = |\alpha|||x||$ for all $\alpha \in K$ and all $x \in E$. 3) $||x + y|| \le max(||x||, ||y||)$ for all $x, y \in E$. Clearly $||x - y||$ defines a metric on $E$. A vector space over $K$ equipped with a norm is called a normed vector space. If $E$ is complete with respect to this metric, $E$ is called a Banach space. Let $E, F$ be normed vector spaces over $K$. Let $U$ be an open subset of $E$. Let $a \in U$. Let $f\colon U \rightarrow F$ be a map. Suppose there exists a continuous linear map $L\colon E \rightarrow F$ such that $$\frac {||f(x) - f(y) - L(x - y)||}{||x - y||} \rightarrow 0$$ when $(x, y) \rightarrow (a, a)$. Then $f$ is called strictly differentiable at $a$. It is easy to see that $L$ is uniquely determined by $f$ and $a$. We denote $L$ by $Df(a)$. The following proposition is stated without a proof in Bourbaki, Variete differentielles et analytiques. How do we prove it? Proposition Let $E, F$ be Banach spaces over $K$. Let $U$ be an open subset of $E$. Let $a \in U$. Let $f\colon U \rightarrow F$ be a map. Suppose $f$ is strictly differentiable at $a$ and $Df(a)$ is an isomorphism $E \rightarrow F$. Then there exist an open neighborhood $U_0$ of $a$ such that $U_0 \subset U$ and an open neighborhood $V_0$ of $f(a)$ with the following properties. 1) $f|U_0$ is a homeomorphism $U_0 \rightarrow V_0$. 2) Let $g$ be the inverse of $f|U_0$. Then $g$ is strictly differentiable at $f(a)$. 3) $Dg(f(a)) = Df(a)^{-1}$.","Let $K$ be a complete field with respect to a non-trivial non-archimedean absolute value $|\cdot|$. Let $E$ be a vector space over $K$. A norm $||\cdot||$ on $E$ is a map $E \rightarrow \mathbb{R}$ satisfying the following properties. 1) $||x|| = 0$ if and only if $x = 0$. 2) $||\alpha x|| = |\alpha|||x||$ for all $\alpha \in K$ and all $x \in E$. 3) $||x + y|| \le max(||x||, ||y||)$ for all $x, y \in E$. Clearly $||x - y||$ defines a metric on $E$. A vector space over $K$ equipped with a norm is called a normed vector space. If $E$ is complete with respect to this metric, $E$ is called a Banach space. Let $E, F$ be normed vector spaces over $K$. Let $U$ be an open subset of $E$. Let $a \in U$. Let $f\colon U \rightarrow F$ be a map. Suppose there exists a continuous linear map $L\colon E \rightarrow F$ such that $$\frac {||f(x) - f(y) - L(x - y)||}{||x - y||} \rightarrow 0$$ when $(x, y) \rightarrow (a, a)$. Then $f$ is called strictly differentiable at $a$. It is easy to see that $L$ is uniquely determined by $f$ and $a$. We denote $L$ by $Df(a)$. The following proposition is stated without a proof in Bourbaki, Variete differentielles et analytiques. How do we prove it? Proposition Let $E, F$ be Banach spaces over $K$. Let $U$ be an open subset of $E$. Let $a \in U$. Let $f\colon U \rightarrow F$ be a map. Suppose $f$ is strictly differentiable at $a$ and $Df(a)$ is an isomorphism $E \rightarrow F$. Then there exist an open neighborhood $U_0$ of $a$ such that $U_0 \subset U$ and an open neighborhood $V_0$ of $f(a)$ with the following properties. 1) $f|U_0$ is a homeomorphism $U_0 \rightarrow V_0$. 2) Let $g$ be the inverse of $f|U_0$. Then $g$ is strictly differentiable at $f(a)$. 3) $Dg(f(a)) = Df(a)^{-1}$.",,"['functional-analysis', 'p-adic-number-theory']"
26,Do spectrum change on a maximal sub algebra?,Do spectrum change on a maximal sub algebra?,,"Can anyone help me to solve the following problem. We know if $B$ is a unital sub-algebra  of a unital Banach algebra $A$ and if $a\in B$, then $\sigma _{A}[a] \subset \sigma _{B}[a] $(Here $\sigma _{T}$ denotes the spectrum with respect to the algebra $T$). What happens if we choose $B$ as an maximal sub-algebra. Can we say that corresponding spectrum will be equal?","Can anyone help me to solve the following problem. We know if $B$ is a unital sub-algebra  of a unital Banach algebra $A$ and if $a\in B$, then $\sigma _{A}[a] \subset \sigma _{B}[a] $(Here $\sigma _{T}$ denotes the spectrum with respect to the algebra $T$). What happens if we choose $B$ as an maximal sub-algebra. Can we say that corresponding spectrum will be equal?",,['functional-analysis']
27,The relation between bounded invertible and surjective operators,The relation between bounded invertible and surjective operators,,"Please, answer me that how is the set of all  bounded invertible operators (for example on a Hilbert space) clopen (closed and open) in the set of all bounded surjective operators? In fact, which topology do imply this?","Please, answer me that how is the set of all  bounded invertible operators (for example on a Hilbert space) clopen (closed and open) in the set of all bounded surjective operators? In fact, which topology do imply this?",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
28,Convergence in the space of convergent sequences,Convergence in the space of convergent sequences,,"$\newcommand{\F}{\mathbb{F}}$ $\newcommand{\N}{\mathbb{N}}$ Let $\F$ be the field of real/complex numbers and define $$c(\F)=\{s\colon\N\to\F|~\exists t\in\F~\text{such that }\lim_{i\to\infty}|s(i)-t|=0\}.$$ I want to prove that this space is complete w.r.t. the norm $\|s\|=\sup_{i\in\N}|s(i)|$. I've found another post with a similar question and I followed the hints, but I got stuck in the proof. This is how far I've gotten: Let $(s_n)$ be Cauchy and fix $i\in\N$. Then the Cauchy property implies that $\{s_n(i)\}_n$ is Cauchy in $\F$. By completeness of $\F$, there is a limit, say $s(i)$. Define $s=(s(1), s(2), \ldots)$. I have successfully shown $$\lim_{n\to\infty}\|s_n-s\|=0\implies s\in c(\F).$$ How can I prove $\lim\limits_{n\to\infty}\|s_n-s\|=0$ (straight from the definitions)? Thanks in advance.","$\newcommand{\F}{\mathbb{F}}$ $\newcommand{\N}{\mathbb{N}}$ Let $\F$ be the field of real/complex numbers and define $$c(\F)=\{s\colon\N\to\F|~\exists t\in\F~\text{such that }\lim_{i\to\infty}|s(i)-t|=0\}.$$ I want to prove that this space is complete w.r.t. the norm $\|s\|=\sup_{i\in\N}|s(i)|$. I've found another post with a similar question and I followed the hints, but I got stuck in the proof. This is how far I've gotten: Let $(s_n)$ be Cauchy and fix $i\in\N$. Then the Cauchy property implies that $\{s_n(i)\}_n$ is Cauchy in $\F$. By completeness of $\F$, there is a limit, say $s(i)$. Define $s=(s(1), s(2), \ldots)$. I have successfully shown $$\lim_{n\to\infty}\|s_n-s\|=0\implies s\in c(\F).$$ How can I prove $\lim\limits_{n\to\infty}\|s_n-s\|=0$ (straight from the definitions)? Thanks in advance.",,"['functional-analysis', 'banach-spaces']"
29,Compactness of unit ball in $\ell_\infty$ with a different norm,Compactness of unit ball in  with a different norm,\ell_\infty,"Consider the normed spaces (over the field of real numbers) $X=(\ell_\infty,\|\cdot\|_\infty)$ and $Y=(\ell_\infty,\|\cdot\|)$ where $$\|x\|=\sup_{n\in\mathbf{N}}\frac{|x_n|}{2^n}.$$ How can I show that the closed unit ball in $X$ is compact in $Y$?","Consider the normed spaces (over the field of real numbers) $X=(\ell_\infty,\|\cdot\|_\infty)$ and $Y=(\ell_\infty,\|\cdot\|)$ where $$\|x\|=\sup_{n\in\mathbf{N}}\frac{|x_n|}{2^n}.$$ How can I show that the closed unit ball in $X$ is compact in $Y$?",,"['functional-analysis', 'banach-spaces', 'compactness']"
30,Show different limits under different mode of convergence equals almost everywhere,Show different limits under different mode of convergence equals almost everywhere,,"Suppose that a sequence of bounded and continuous functions $f_n$ converges uniformly to $f_1$ and $f_n$ converges to $f_2$ in $L^2$ sense, then how to show $f_1= f_2$ a.e.? I tried the following: let $A_\epsilon = \{x:|f_1(x)-f_2(x)|>\epsilon\}$, then $m(A_\epsilon) < m(|f_n - f_1|>\epsilon) + m(|f_n - f_2|>\epsilon)$. Let $n$ go to infinity, then the first part of RHS goes to zero by uniform convergence, but I cannot do anything to $L^2$-convergence. Can anyone show me how to solve this question? Thanks in advance .","Suppose that a sequence of bounded and continuous functions $f_n$ converges uniformly to $f_1$ and $f_n$ converges to $f_2$ in $L^2$ sense, then how to show $f_1= f_2$ a.e.? I tried the following: let $A_\epsilon = \{x:|f_1(x)-f_2(x)|>\epsilon\}$, then $m(A_\epsilon) < m(|f_n - f_1|>\epsilon) + m(|f_n - f_2|>\epsilon)$. Let $n$ go to infinity, then the first part of RHS goes to zero by uniform convergence, but I cannot do anything to $L^2$-convergence. Can anyone show me how to solve this question? Thanks in advance .",,"['real-analysis', 'functional-analysis']"
31,Completion of $C_c(X)$ with respect to $\|\cdot\|_\infty$,Completion of  with respect to,C_c(X) \|\cdot\|_\infty,"Notation: All functions here are from $X$ to $\mathbb R$. $C_c(X)$ = compactly supported continuous functions. $C_b(X)$ = bounded continuous functions. $B(X)$ = bounded functions. $C_0(X)$ = continuous functions that tend to zero ( so $X$ has to be locally compact and Hausdorff ) Today I proved that $C_c(\mathbb R)$ is not complete with respect to $\|\cdot\|_\infty$. One can do this by taking $g_n$ to be the function that is zero on $(-\infty,-n]$, linear on $[-n, -n+1]$, $1$ on $[-n+1, n-1]$ and symmetric with respect to the $y$-axis. For $f(x) = e^{-x^2}$ one can show that $\|fg_n - f\|_\infty \to 0$ but $f \notin C_c(\mathbb R)$. Then I read about completions and wanted to work out the completion of $C_c$(X). (I did this all for $X = \mathbb R$). In any case, my thoughts were as follows: $C_c(X)$ is contained in $B(X)$. But it is a proper subset because the uniform limit of continuous functions is continuous but there are discontinuous bounded functions. The next candidate then seems to be $C_b(X)$ but $f(x) = 1$ is in there and not the uniform limit of $f_n$ in $C_c$. (cannot be because if $f_n$ is zero outside a compact set then $\|f_n - 1\|_\infty = 1$ for all $n$ so this doesn't converge in norm). The next candidate then is $C_0(X)$ and I'm quite sure that that's the completion of $C_c$ with respect to $\|\cdot\|_\infty$ in $B(X)$. But now I need to show this by showing that $C_0(X)$ is isomorphic to the space of Cauchy sequences in $C_c(X)$ quotient Cauchy sequences that tend to the zero function and I don't really know how to think about this. Can someone please show me how to prove this? Thank you. I want to see this quotient construction and an isomorphism but if there are other ways to show that $C_0$ is the completion of $C_c$ then go ahead and post it, I will upvote it.","Notation: All functions here are from $X$ to $\mathbb R$. $C_c(X)$ = compactly supported continuous functions. $C_b(X)$ = bounded continuous functions. $B(X)$ = bounded functions. $C_0(X)$ = continuous functions that tend to zero ( so $X$ has to be locally compact and Hausdorff ) Today I proved that $C_c(\mathbb R)$ is not complete with respect to $\|\cdot\|_\infty$. One can do this by taking $g_n$ to be the function that is zero on $(-\infty,-n]$, linear on $[-n, -n+1]$, $1$ on $[-n+1, n-1]$ and symmetric with respect to the $y$-axis. For $f(x) = e^{-x^2}$ one can show that $\|fg_n - f\|_\infty \to 0$ but $f \notin C_c(\mathbb R)$. Then I read about completions and wanted to work out the completion of $C_c$(X). (I did this all for $X = \mathbb R$). In any case, my thoughts were as follows: $C_c(X)$ is contained in $B(X)$. But it is a proper subset because the uniform limit of continuous functions is continuous but there are discontinuous bounded functions. The next candidate then seems to be $C_b(X)$ but $f(x) = 1$ is in there and not the uniform limit of $f_n$ in $C_c$. (cannot be because if $f_n$ is zero outside a compact set then $\|f_n - 1\|_\infty = 1$ for all $n$ so this doesn't converge in norm). The next candidate then is $C_0(X)$ and I'm quite sure that that's the completion of $C_c$ with respect to $\|\cdot\|_\infty$ in $B(X)$. But now I need to show this by showing that $C_0(X)$ is isomorphic to the space of Cauchy sequences in $C_c(X)$ quotient Cauchy sequences that tend to the zero function and I don't really know how to think about this. Can someone please show me how to prove this? Thank you. I want to see this quotient construction and an isomorphism but if there are other ways to show that $C_0$ is the completion of $C_c$ then go ahead and post it, I will upvote it.",,"['functional-analysis', 'normed-spaces']"
32,Compute operator norm by image on orthonormal basis,Compute operator norm by image on orthonormal basis,,"Let $e_n$ a orthonormal basis for a Hilbert space and $T$ a bounded linear operator. Is the following correct? $$\lVert T \lVert^2 \leq \sup_{n \in \mathbb{N}} \sum_{k \in \mathbb{N}} |\langle e_n,Te_k\rangle|^2$$","Let $e_n$ a orthonormal basis for a Hilbert space and $T$ a bounded linear operator. Is the following correct? $$\lVert T \lVert^2 \leq \sup_{n \in \mathbb{N}} \sum_{k \in \mathbb{N}} |\langle e_n,Te_k\rangle|^2$$",,"['functional-analysis', 'hilbert-spaces', 'operator-theory']"
33,separation theorem for probability measures,separation theorem for probability measures,,"Suppose I have a probability measure $\nu$ and a set of probability measures $S$ (all defined on the same $\sigma$-algebra).  Are the following two statements equivalent? (1) $\nu$ is not a mixture of the elements of $S$. (2) There is a random variable $X$ such that the expectation of $X$ under $\nu$ is less than 0, and the expectation of $X$ under all of the members of $S$ is greater than 0. If not, is something similar true, or true in a special case? Is the situation the same for merely finitely additive probability measures?","Suppose I have a probability measure $\nu$ and a set of probability measures $S$ (all defined on the same $\sigma$-algebra).  Are the following two statements equivalent? (1) $\nu$ is not a mixture of the elements of $S$. (2) There is a random variable $X$ such that the expectation of $X$ under $\nu$ is less than 0, and the expectation of $X$ under all of the members of $S$ is greater than 0. If not, is something similar true, or true in a special case? Is the situation the same for merely finitely additive probability measures?",,"['measure-theory', 'functional-analysis', 'probability-theory']"
34,"When the set $\{(S_{i_1}\circ\cdots\circ S_{i_n})(x): n\in \mathbb{N},\;\; i_1,\ldots,i_n\in I\}$ is relatively compact?",When the set  is relatively compact?,"\{(S_{i_1}\circ\cdots\circ S_{i_n})(x): n\in \mathbb{N},\;\; i_1,\ldots,i_n\in I\}","Let $(X,\rho)$ be a metric space and let $S_1,\ldots,S_N:X\rightarrow X$ be continuous transformations. Denote $I=\{1,\ldots,N\}$. Is it possible to find some minimal assumptions on $S_i$ which would ensure relative compactness of the set $\{(S_{i_1}\circ\cdots\circ S_{i_n})(x): n\in \mathbb{N},\;\; i_1,\ldots,i_n\in I\}$ at any point $x\in X$? I know it is a general  question and perhaps it is known. It is important for me, so I will be grateful for any propositions.","Let $(X,\rho)$ be a metric space and let $S_1,\ldots,S_N:X\rightarrow X$ be continuous transformations. Denote $I=\{1,\ldots,N\}$. Is it possible to find some minimal assumptions on $S_i$ which would ensure relative compactness of the set $\{(S_{i_1}\circ\cdots\circ S_{i_n})(x): n\in \mathbb{N},\;\; i_1,\ldots,i_n\in I\}$ at any point $x\in X$? I know it is a general  question and perhaps it is known. It is important for me, so I will be grateful for any propositions.",,"['real-analysis', 'functional-analysis', 'metric-spaces']"
35,Characterization of linearity in terms of metric,Characterization of linearity in terms of metric,,"At least in Euclidean geometry and the upper half plane model of hyperbolic geometry, the statements '$y$ lies on the line segment determined by $x$ and $z$ ' and '$d(x,y)+d(y,z)=d(x,z) $' are equivalent. I wonder whether this characterization holds in other geometries and whether it has a name to it. Do geometries with this relation have some special properties? I also think it is somehow related to the notion of uniform convexity in Banach spaces, but that is a different problem since we don't ask for vector space sturcture here. Any insight or reference would be helpful! Thanks!","At least in Euclidean geometry and the upper half plane model of hyperbolic geometry, the statements '$y$ lies on the line segment determined by $x$ and $z$ ' and '$d(x,y)+d(y,z)=d(x,z) $' are equivalent. I wonder whether this characterization holds in other geometries and whether it has a name to it. Do geometries with this relation have some special properties? I also think it is somehow related to the notion of uniform convexity in Banach spaces, but that is a different problem since we don't ask for vector space sturcture here. Any insight or reference would be helpful! Thanks!",,"['geometry', 'functional-analysis', 'euclidean-geometry', 'hyperbolic-geometry']"
36,Understanding an example of a Distribution,Understanding an example of a Distribution,,"Whilst reading the article about restrictions of distributions (generalized functions) on Wikipedia ( here ) I had trouble understanding the example of a distribution defined on the subset  $V = (0,2) \subset \mathbb{R}$ that admits no extension to the space of Distributions on $U = \mathbb{R}$. The example I am referring to is the distribution \begin{equation} S(x) = \sum_{n = 1}^\infty n \delta \left(x - \frac{1}{n}\right) \end{equation} Now, my question is how does this example act on test functions ? If I take a smooth function $\psi$ whith supp $\psi \subset V$,  how do I apply $S$ to it ? I understand that $S$ is a modification of the Dirac delta distribution \begin{equation} \langle \delta , \psi \rangle = \psi (0) \end{equation} Below is my guess : \begin{equation} \langle S , \psi \rangle = \sum^{\infty}_{n = 1} n \psi (\frac{1}{n}) \end{equation} Is that correct ? If yes, I am still not sure how this is well defined, given only the restriction that $\psi$ is zero outside $(0,2)$. Tanks a lot for your help!","Whilst reading the article about restrictions of distributions (generalized functions) on Wikipedia ( here ) I had trouble understanding the example of a distribution defined on the subset  $V = (0,2) \subset \mathbb{R}$ that admits no extension to the space of Distributions on $U = \mathbb{R}$. The example I am referring to is the distribution \begin{equation} S(x) = \sum_{n = 1}^\infty n \delta \left(x - \frac{1}{n}\right) \end{equation} Now, my question is how does this example act on test functions ? If I take a smooth function $\psi$ whith supp $\psi \subset V$,  how do I apply $S$ to it ? I understand that $S$ is a modification of the Dirac delta distribution \begin{equation} \langle \delta , \psi \rangle = \psi (0) \end{equation} Below is my guess : \begin{equation} \langle S , \psi \rangle = \sum^{\infty}_{n = 1} n \psi (\frac{1}{n}) \end{equation} Is that correct ? If yes, I am still not sure how this is well defined, given only the restriction that $\psi$ is zero outside $(0,2)$. Tanks a lot for your help!",,"['functional-analysis', 'operator-theory', 'distribution-theory']"
37,Reference request on vector-valued integration,Reference request on vector-valued integration,,"I'm looking for some nice, neat text which discusses the Bochner and Pettis approaches to integration of vector-valued functions. I'm not interested in the most general case, so the less technical the text the better. To be precise, the level of generality I'm interested in is integration of functions defined on some measure space $(X,\mathcal{M},\mu)$ taking values in some Banach space $V$, w.r.t. the measure $\mu$.","I'm looking for some nice, neat text which discusses the Bochner and Pettis approaches to integration of vector-valued functions. I'm not interested in the most general case, so the less technical the text the better. To be precise, the level of generality I'm interested in is integration of functions defined on some measure space $(X,\mathcal{M},\mu)$ taking values in some Banach space $V$, w.r.t. the measure $\mu$.",,"['measure-theory', 'functional-analysis', 'integration']"
38,A question about the coercivity of a lsc and convex function.,A question about the coercivity of a lsc and convex function.,,"I was doing a proof and I need to show a result to conclude it: $X$ is a reflexive Banach space with a norm, $\|\cdot\|$, of class $\mathcal{C}^1$. $f:X\to\overline{\mathbb{R}}$ is lower semicontinuous and convex. If $\lambda>0$ and $x\in X$ are prefixed, I define $\Phi:X\to\overline{\mathbb{R}}$ such that $\Phi(y)=f(y)+\frac{1}{2\lambda}\|x-y\|^2$. Then I need to show that $\Phi$ is coercive, this is: $\displaystyle\lim_{\|y\|\to\infty} \Phi(y)=+\infty$. Maybe the result isn't true... Thanks.","I was doing a proof and I need to show a result to conclude it: $X$ is a reflexive Banach space with a norm, $\|\cdot\|$, of class $\mathcal{C}^1$. $f:X\to\overline{\mathbb{R}}$ is lower semicontinuous and convex. If $\lambda>0$ and $x\in X$ are prefixed, I define $\Phi:X\to\overline{\mathbb{R}}$ such that $\Phi(y)=f(y)+\frac{1}{2\lambda}\|x-y\|^2$. Then I need to show that $\Phi$ is coercive, this is: $\displaystyle\lim_{\|y\|\to\infty} \Phi(y)=+\infty$. Maybe the result isn't true... Thanks.",,"['functional-analysis', 'banach-spaces', 'approximation', 'convex-analysis']"
39,Product of Sidon sets,Product of Sidon sets,,Let $G$ be a compact abelian group with dual $\Gamma$. Let $\Lambda \subset \Gamma$ a Sidon set (see the book of Rudin: Fourier Analysis on Groups for the definition). Consider the set $\Lambda\times\Lambda$. Is it a Sidon set of $\Gamma\times \Gamma$?,Let $G$ be a compact abelian group with dual $\Gamma$. Let $\Lambda \subset \Gamma$ a Sidon set (see the book of Rudin: Fourier Analysis on Groups for the definition). Consider the set $\Lambda\times\Lambda$. Is it a Sidon set of $\Gamma\times \Gamma$?,,"['functional-analysis', 'fourier-analysis', 'abelian-groups', 'harmonic-analysis']"
40,Radon Nikodym derivative proof,Radon Nikodym derivative proof,,"Theorem: Let $\mu$ and $\nu$ be two $\sigma$-finite measures on a measurable space $(X, B)$. Then $\nu$ can be decomposed as  $$ \nu = \nu_\mathrm{abs} + \nu_\mathrm{sing}$$ into the sum of two $\sigma$-finite measures with $\nu_\mathrm{abs} \ll \mu$ being absolutely continuous with respect to $\mu$ and $\nu_\mathrm{sing} \bot \mu$ being singular to each other. Remark: We only prove the theorem for finite measures. a) Define a measure $m = \mu + \nu $ and define on the real Hilbert space $H = L_m^2(X)$ a linear functional $\Phi(g) := \int g \; d\nu $. First restrict it to simple functions and show that the operator is bounded on the space of simple functions in $L^2$. Extend it to $H$ and prove that $\exists k \in H : \Phi (g) = \int g k \; d m$. I've done the first two parts of part a) and now  I'm stuck with proving that $\exists k \in H : \Phi (g) = \int g k \; d m$. I was thinking something like this: $$ \begin{align}  \Phi g = \int_X g \; d \nu = \int_X g \; d \nu_\mathrm{abs} + \int_X g \; d \nu_\mathrm{sing} = \int_X fg \; d \mu + \int_{X_1} g \; d \nu + \int_{X_2} g \; d \nu = \int_X fg \; d \mu +  \int_{X_2} g \; d \nu \end{align}$$ But then I don't know how to proceed. Am I on the right track? Many thanks for your help. b) Prove that $k$ takes values in $[0,1]$ $m$-almost surely. Can you tell me if the following is correct: $  \begin{align} P(\{ x | k(x) \in [0,1]\}) = m(k^{-1}([0,1])) = \int_{k^{-1}([0,1])} 1 dm = \\  \int_{k^{-1}([0,1])} (1 \circ k) dm = \int_{k^{-1}([0,1])} 1 \cdot (1 \circ k) dm = \int_{k^{-1}([0,1])} (1 \circ k) d\nu = \int_{[0,1]} 1 d k(\nu) \end{align} $ And then I want this to be $1$ but I don't know $\nu$ and I don't know $d k(\nu)$ so I think I'm stuck here. Edit a) OK, using t.b.'s comment the answer to ta) is: Using the Riesz representation theorem for Hilbert spaces the existence of $k $ follows immediately. Thanks for your help!","Theorem: Let $\mu$ and $\nu$ be two $\sigma$-finite measures on a measurable space $(X, B)$. Then $\nu$ can be decomposed as  $$ \nu = \nu_\mathrm{abs} + \nu_\mathrm{sing}$$ into the sum of two $\sigma$-finite measures with $\nu_\mathrm{abs} \ll \mu$ being absolutely continuous with respect to $\mu$ and $\nu_\mathrm{sing} \bot \mu$ being singular to each other. Remark: We only prove the theorem for finite measures. a) Define a measure $m = \mu + \nu $ and define on the real Hilbert space $H = L_m^2(X)$ a linear functional $\Phi(g) := \int g \; d\nu $. First restrict it to simple functions and show that the operator is bounded on the space of simple functions in $L^2$. Extend it to $H$ and prove that $\exists k \in H : \Phi (g) = \int g k \; d m$. I've done the first two parts of part a) and now  I'm stuck with proving that $\exists k \in H : \Phi (g) = \int g k \; d m$. I was thinking something like this: $$ \begin{align}  \Phi g = \int_X g \; d \nu = \int_X g \; d \nu_\mathrm{abs} + \int_X g \; d \nu_\mathrm{sing} = \int_X fg \; d \mu + \int_{X_1} g \; d \nu + \int_{X_2} g \; d \nu = \int_X fg \; d \mu +  \int_{X_2} g \; d \nu \end{align}$$ But then I don't know how to proceed. Am I on the right track? Many thanks for your help. b) Prove that $k$ takes values in $[0,1]$ $m$-almost surely. Can you tell me if the following is correct: $  \begin{align} P(\{ x | k(x) \in [0,1]\}) = m(k^{-1}([0,1])) = \int_{k^{-1}([0,1])} 1 dm = \\  \int_{k^{-1}([0,1])} (1 \circ k) dm = \int_{k^{-1}([0,1])} 1 \cdot (1 \circ k) dm = \int_{k^{-1}([0,1])} (1 \circ k) d\nu = \int_{[0,1]} 1 d k(\nu) \end{align} $ And then I want this to be $1$ but I don't know $\nu$ and I don't know $d k(\nu)$ so I think I'm stuck here. Edit a) OK, using t.b.'s comment the answer to ta) is: Using the Riesz representation theorem for Hilbert spaces the existence of $k $ follows immediately. Thanks for your help!",,"['measure-theory', 'functional-analysis']"
41,Balls in the space of bounded operators on a Hilbert space,Balls in the space of bounded operators on a Hilbert space,,Suppose $\mathsf{H}$ is an infinite-dimensional (non-separable preferably) Hilbert space. Consider the space $L(\mathsf{H})$ of all bounded operators on it. Is there $0\neq W\in L(\mathsf{H})$ such that the set $$\left\{ T\in L(\mathsf{H} )\colon \|W-T\| = \|W+T\| \right\}$$ contains an open ball? Is this set a linear subspace of $L(\mathsf{H})$?,Suppose $\mathsf{H}$ is an infinite-dimensional (non-separable preferably) Hilbert space. Consider the space $L(\mathsf{H})$ of all bounded operators on it. Is there $0\neq W\in L(\mathsf{H})$ such that the set $$\left\{ T\in L(\mathsf{H} )\colon \|W-T\| = \|W+T\| \right\}$$ contains an open ball? Is this set a linear subspace of $L(\mathsf{H})$?,,"['functional-analysis', 'banach-spaces', 'hilbert-spaces']"
42,"Spectrum of a ""quasi"" right shift operator","Spectrum of a ""quasi"" right shift operator",,"Let $\mathcal{H}$ be a Hilbert space and let {$e_j$}$_{j\in \mathbb{Z}}$ be an orthonormal basis for $\mathcal{H}$. Define a linear operator $T$ on $\mathcal{H}$ by $T(e_0) = 0$ and $T(e_j) = e_{j+1}$ for $j \neq$ 0. Define another linear operator on $\mathcal{H}$ by $A(e_0) = e_1$ and $A(e_j) = 0$ for $j \neq 0$. For $z \in \mathbb{C}$, define $T_z = T +zA$. I'm being asked to find $\sigma(T_z)$ and to say what happens when $z \to 0$ (which I imagine is obvious if I can find $\sigma(T_z)$). I've tried finding $\sigma(T_z)$ for certain values of $z$ with little success. I know that $\sigma(A)$ = {$0$} since the spectral radius of $A$ is $0$ ($A^n$ for $n>1$ is just going to be the trivial operator) and so $\sigma(zA)$ = {$0$}; I'm not sure if this will be useful. Correct me if I'm wrong, but $||T_z||$ = $1$ $\lor$ $||z||$ so $\sigma(T_z) \subset \overline{B}_{1 \lor ||z||}(0)$. I believe that the point spectrum of $T_z$ will be empty for $z \neq 0$ which doesn't help me either. For context, the previous part of this problem asked for $\sigma(T)$. Any pointers in the right direction would be great.","Let $\mathcal{H}$ be a Hilbert space and let {$e_j$}$_{j\in \mathbb{Z}}$ be an orthonormal basis for $\mathcal{H}$. Define a linear operator $T$ on $\mathcal{H}$ by $T(e_0) = 0$ and $T(e_j) = e_{j+1}$ for $j \neq$ 0. Define another linear operator on $\mathcal{H}$ by $A(e_0) = e_1$ and $A(e_j) = 0$ for $j \neq 0$. For $z \in \mathbb{C}$, define $T_z = T +zA$. I'm being asked to find $\sigma(T_z)$ and to say what happens when $z \to 0$ (which I imagine is obvious if I can find $\sigma(T_z)$). I've tried finding $\sigma(T_z)$ for certain values of $z$ with little success. I know that $\sigma(A)$ = {$0$} since the spectral radius of $A$ is $0$ ($A^n$ for $n>1$ is just going to be the trivial operator) and so $\sigma(zA)$ = {$0$}; I'm not sure if this will be useful. Correct me if I'm wrong, but $||T_z||$ = $1$ $\lor$ $||z||$ so $\sigma(T_z) \subset \overline{B}_{1 \lor ||z||}(0)$. I believe that the point spectrum of $T_z$ will be empty for $z \neq 0$ which doesn't help me either. For context, the previous part of this problem asked for $\sigma(T)$. Any pointers in the right direction would be great.",,"['functional-analysis', 'operator-theory', 'spectral-theory']"
43,Hamel basis and orthonormal basis for Hilbert spaces,Hamel basis and orthonormal basis for Hilbert spaces,,My question : why don't we get a Hamel basis (a maximal linearly independent set)  instead of a maximal orthonormal set for a Hilbert space. In what dimension can we use a Hamel basis and in which we can't?,My question : why don't we get a Hamel basis (a maximal linearly independent set)  instead of a maximal orthonormal set for a Hilbert space. In what dimension can we use a Hamel basis and in which we can't?,,"['functional-analysis', 'hilbert-spaces']"
44,One more predual space of the space of measures?,One more predual space of the space of measures?,,"I am considering the Banach space $A$ with $\sup$-norm, which is the uniform closure of functions on a segment that are continuous but a finite collection of jump points, where they have limits from the left and from the right. It looks like any finite complex measure on the segment naturally generates a functional on $A$: on the dense set of piecewise continuous functions one can take the usual integral (if a jump point has a point mass, we may split this mass into two equal parts for the left and right parts of the function). Is it true that the space of measures is dual to $A$? My own comment : I see that the answer is negative: fix a point of the segment and take a number $c$, consider the functional that assigns to a function whose left and right limits at this point are $a_+$ and $a_-$ the number $c\cdot a_+ + (1-c)a_-$. On continuous functions this functional does not depend on $c$. I would like to extend my question as follows: describe the space dual to $A$.","I am considering the Banach space $A$ with $\sup$-norm, which is the uniform closure of functions on a segment that are continuous but a finite collection of jump points, where they have limits from the left and from the right. It looks like any finite complex measure on the segment naturally generates a functional on $A$: on the dense set of piecewise continuous functions one can take the usual integral (if a jump point has a point mass, we may split this mass into two equal parts for the left and right parts of the function). Is it true that the space of measures is dual to $A$? My own comment : I see that the answer is negative: fix a point of the segment and take a number $c$, consider the functional that assigns to a function whose left and right limits at this point are $a_+$ and $a_-$ the number $c\cdot a_+ + (1-c)a_-$. On continuous functions this functional does not depend on $c$. I would like to extend my question as follows: describe the space dual to $A$.",,"['functional-analysis', 'banach-spaces']"
45,Something connected with Arzelà-Ascoli theorem,Something connected with Arzelà-Ascoli theorem,,"Let $X$ be a Polish space. Assume that $(C_m)_{m\in\mathbb{N}}$ is an increasing sequence of compact subsets of $X$ and denote $C=\bigcup_{m}C_m$. Let  $\{f_n:n\in\mathbb{N}\}$ be a family of functions from $X$ in $\left[0,1\right]$, which is equicontinuous on compact subsets of $X$. By  the Arzelà-Ascoli theorem we can find  a subsequence $(f_{k_n})_{n\in\mathbb{N}}$ convergent to a function $f$ uniformly on the set $C_m$, for any $m \in \mathbb{N}$. Naturally $f$ is continuous on each set $C_m$, but a function with this property need not to be continuous on the set $C$. Can one choose a subsequence in such a way that the limit be a continuous function on $C$? As for me, this concept is too optimistic, but it was used in the paper Remarks on Ergodic Conditions for Markov Processes on Polish Spaces by Stettner (page 110, step 3).","Let $X$ be a Polish space. Assume that $(C_m)_{m\in\mathbb{N}}$ is an increasing sequence of compact subsets of $X$ and denote $C=\bigcup_{m}C_m$. Let  $\{f_n:n\in\mathbb{N}\}$ be a family of functions from $X$ in $\left[0,1\right]$, which is equicontinuous on compact subsets of $X$. By  the Arzelà-Ascoli theorem we can find  a subsequence $(f_{k_n})_{n\in\mathbb{N}}$ convergent to a function $f$ uniformly on the set $C_m$, for any $m \in \mathbb{N}$. Naturally $f$ is continuous on each set $C_m$, but a function with this property need not to be continuous on the set $C$. Can one choose a subsequence in such a way that the limit be a continuous function on $C$? As for me, this concept is too optimistic, but it was used in the paper Remarks on Ergodic Conditions for Markov Processes on Polish Spaces by Stettner (page 110, step 3).",,"['real-analysis', 'functional-analysis', 'metric-spaces']"
46,Derivative of convolution of non differentiable functions,Derivative of convolution of non differentiable functions,,"Given differentiable functions $f,g$, one can make the following statement about the derivatives of their convolution: $(f \star g)' = f' \star g = f \star g'$ Suppose I pick $g$ as a non differentiable function such as $g(x) = |x|$, does this property still hold? (plotting $(|x| \star |x|)'$ and $(|x|' \star |x|)$ in Matlab shows different functions) If the above property is true then by definition of convolution  $f \star g' (x) = \int f(y) g'(x-y) dy$ So when can we say the convolution is not differentiable whenever $g'(x-y)$ is not differentiable?","Given differentiable functions $f,g$, one can make the following statement about the derivatives of their convolution: $(f \star g)' = f' \star g = f \star g'$ Suppose I pick $g$ as a non differentiable function such as $g(x) = |x|$, does this property still hold? (plotting $(|x| \star |x|)'$ and $(|x|' \star |x|)$ in Matlab shows different functions) If the above property is true then by definition of convolution  $f \star g' (x) = \int f(y) g'(x-y) dy$ So when can we say the convolution is not differentiable whenever $g'(x-y)$ is not differentiable?",,"['real-analysis', 'functional-analysis']"
47,Rudin theorem $6.19$.,Rudin theorem .,6.19,"There is theorem $6.12$ : Let $\mu$ be a complex measure on $\sigma$ -algebra $\mathfrak {M}$ in $X$ . Then there is a measurable function $h$ such that $|h(x)| = 1$ for all $x \in X$ and such that $$ d \mu = h d |\mu|.$$ There is the definition of $C_0(X)$ : A complex function $f$ on a locally compact Hausdorff space $X$ is said to vanish at infinity if to every $\epsilon \gt 0 $ there exists a compact set $K \subset X$ such that $|f(x)| < \epsilon $ for all $x$ not in $K$ . The class of all continuous $f$ on $X$ which vanish at infinity is called $C_0(X)$ . There is our theorem: If $X$ is a locally compact Hausdorff space, then every bounded linear function $\Phi$ on $C_0(X)$ is represented by a unique regular complex Boreal measure $\mu$ , in the sense that $$ \Phi f = \int_X f d\mu $$ for every $f \in C_0(X)$ . Moreover, the norm of $\Phi$ is the total variation of $\mu$ : $$ || \Phi || = |\mu|(X).$$ There is the proof: We first settle the uniqueness question. Suppose $\mu$ is a regular complex Borel measure on $X$ and $\int f d\mu = 0 $ for all $f \in C_0(X)$ . By Theorem $6.12$ there is a Borel function $h$ , with $|h| = 1 $ , such that $ d \mu = h d |\mu|.$ For any sequence $\{f_n\}$ in $C_0(X)$ we then have $$ | \mu |(X) = \int_X (\bar{h} - f_n) h d |\mu| \leq \int_X | \bar{h} - f_n| d |\mu|$$ , and since $C_c(X)$ is dense in $L^{1}(|\mu|)$ , $\{f_n\}$ can be so chosen that the last expression tends to $0$ as $n \to \infty$ . I don't understand why is $|\mu|(X)$ equal to $\int_X  (\bar{h} - f_n) h d |\mu| $ . Any help would be appreciated.","There is theorem : Let be a complex measure on -algebra in . Then there is a measurable function such that for all and such that There is the definition of : A complex function on a locally compact Hausdorff space is said to vanish at infinity if to every there exists a compact set such that for all not in . The class of all continuous on which vanish at infinity is called . There is our theorem: If is a locally compact Hausdorff space, then every bounded linear function on is represented by a unique regular complex Boreal measure , in the sense that for every . Moreover, the norm of is the total variation of : There is the proof: We first settle the uniqueness question. Suppose is a regular complex Borel measure on and for all . By Theorem there is a Borel function , with , such that For any sequence in we then have , and since is dense in , can be so chosen that the last expression tends to as . I don't understand why is equal to . Any help would be appreciated.",6.12 \mu \sigma \mathfrak {M} X h |h(x)| = 1 x \in X  d \mu = h d |\mu|. C_0(X) f X \epsilon \gt 0  K \subset X |f(x)| < \epsilon  x K f X C_0(X) X \Phi C_0(X) \mu  \Phi f = \int_X f d\mu  f \in C_0(X) \Phi \mu  || \Phi || = |\mu|(X). \mu X \int f d\mu = 0  f \in C_0(X) 6.12 h |h| = 1   d \mu = h d |\mu|. \{f_n\} C_0(X)  | \mu |(X) = \int_X (\bar{h} - f_n) h d |\mu| \leq \int_X | \bar{h} - f_n| d |\mu| C_c(X) L^{1}(|\mu|) \{f_n\} 0 n \to \infty |\mu|(X) \int_X  (\bar{h} - f_n) h d |\mu| ,"['real-analysis', 'functional-analysis', 'complex-analysis', 'analysis', 'measure-theory']"
48,"Curvature of ""music-scale""","Curvature of ""music-scale""",,"Lately I am thinking about music from a mathematical point of view. Let us consider $\mathbb{H} =\mathcal{L}^2([0,T])$ as the Hilbert space of functions that represents the time-intensity plot of a sound. Quite tautologically, playing together sounds amount to sum them. So, up to scale volumes, the chords one can produce with $n$ sounds $f_1, \ldots, f_n \in \mathbb{H}$ lives in the convex envelope of $f_1, \ldots, f_n$ . Now let us restrict to simple wave sounds $f_{\lambda}(t) := e^{i \lambda t} \in \mathcal{L}^2([0,T])$ . If I consider $n$ different frequencies $\lambda_1, \ldots, \lambda_n$ , the functions $f_{\lambda_i}$ will be linearly independent (and orthogonal actually), so that their convex envelope is just the simplex $\Delta^{n-1}$ . This approach unfortunately does not shed light on the underlying geometry. My second approach is more differential. Let us consider $f: (0,\Lambda) \to \mathbb{H}$ defined as $f \mapsto f_{\lambda}(\bullet)$ for some big $\Lambda$ . This is a curve in $\mathbb{H}$ , and I'd like to understand if there is some way to compute its ""curvature"" even though we have infinite dimensions. Trying to remember differential geometry from University and reading off Wikipedia, there should be infinitely many ""curvatures"" associated to a ""Frenet orthonormal system"", but I have not been able to generalize the latter. On the other hand, the simple definition for a curvature in two dimensions generalize easily. We can compute the norm of the ""second-derivative"" along $\lambda$ , obtaining $$ || \partial_{\lambda}^2 f_{\lambda} || = \frac{1}{T} \int_0^{T} ((it)^2 e^{i \lambda t}) (-it)^2 e^{-i \lambda t } dt = \frac{1}{T} \frac{T^5}{5} = \frac{T^4}{5}  $$ Quite nicely, it does not depend on the frequency (but unfortunately it does depend on the length of the interval that is arbitrary). However, I am not really sure about how I should interpret a measure of curvature in $(\textrm{seconds})^4$ . Does any of the latter make sense? Is there a way to compute the curvature in infinite dimensions? One could then look for a curve in the space that has similar features and get a grasp of the geometry of $f_{\lambda}$ ! As a last intuition, note that at each fixed time $t$ the function $f_{\bullet}(t)$ draws a circle at a speed proportional to $t$ . It does make sense then that the curvature does not depend on the frequency since the circle has constant curvature. The method based on the inner product integrates all the contributes at fixed time.","Lately I am thinking about music from a mathematical point of view. Let us consider as the Hilbert space of functions that represents the time-intensity plot of a sound. Quite tautologically, playing together sounds amount to sum them. So, up to scale volumes, the chords one can produce with sounds lives in the convex envelope of . Now let us restrict to simple wave sounds . If I consider different frequencies , the functions will be linearly independent (and orthogonal actually), so that their convex envelope is just the simplex . This approach unfortunately does not shed light on the underlying geometry. My second approach is more differential. Let us consider defined as for some big . This is a curve in , and I'd like to understand if there is some way to compute its ""curvature"" even though we have infinite dimensions. Trying to remember differential geometry from University and reading off Wikipedia, there should be infinitely many ""curvatures"" associated to a ""Frenet orthonormal system"", but I have not been able to generalize the latter. On the other hand, the simple definition for a curvature in two dimensions generalize easily. We can compute the norm of the ""second-derivative"" along , obtaining Quite nicely, it does not depend on the frequency (but unfortunately it does depend on the length of the interval that is arbitrary). However, I am not really sure about how I should interpret a measure of curvature in . Does any of the latter make sense? Is there a way to compute the curvature in infinite dimensions? One could then look for a curve in the space that has similar features and get a grasp of the geometry of ! As a last intuition, note that at each fixed time the function draws a circle at a speed proportional to . It does make sense then that the curvature does not depend on the frequency since the circle has constant curvature. The method based on the inner product integrates all the contributes at fixed time.","\mathbb{H} =\mathcal{L}^2([0,T]) n f_1, \ldots, f_n \in \mathbb{H} f_1, \ldots, f_n f_{\lambda}(t) := e^{i \lambda t} \in \mathcal{L}^2([0,T]) n \lambda_1, \ldots, \lambda_n f_{\lambda_i} \Delta^{n-1} f: (0,\Lambda) \to \mathbb{H} f \mapsto f_{\lambda}(\bullet) \Lambda \mathbb{H} \lambda  || \partial_{\lambda}^2 f_{\lambda} || = \frac{1}{T} \int_0^{T} ((it)^2 e^{i \lambda t}) (-it)^2 e^{-i \lambda t } dt = \frac{1}{T} \frac{T^5}{5} = \frac{T^4}{5}   (\textrm{seconds})^4 f_{\lambda} t f_{\bullet}(t) t","['functional-analysis', 'hilbert-spaces', 'riemannian-geometry', 'curvature', 'music-theory']"
49,"For a vector-valued $f,$ is there a convex $\varphi$ such that $\nabla \varphi = f?$",For a vector-valued  is there a convex  such that,"f, \varphi \nabla \varphi = f?","Let $U \subset \mathbb{R}^d$ be a convex open set. Suppose a continuously differentiable vector-valued function $f : U \to \mathbb{R}^d$ satisfies that its derivative $D f : U \to \mathbb{R}^{d \times d}$ is symmetric and positive semidefinite. Is there a convex function $\varphi : U \to \mathbb{R}$ such that $\nabla \varphi = f$ ? I guess the answer is yes. I attempted to show that $f$ is cyclically monotone, but I could show only the monotonicity as follows. Let $x_1, \dots, x_k \in U.$ Then, Taylor's theorem says $$ f(x_{i+1}) = f(x_i) + \left( \int_0^1 D f ((1 - s) x_i + s x_{i+1})  d s \right) (x_{i+1} - x_i) . $$ Thus, we have $$ (x_{i+1} - x_i)^\prime (f(x_{i+1}) - f(x_i)) = (x_{i+1} - x_i)^\prime \left( \int_0^1 D f ((1 - s) x_i + s x_{i+1})  d s \right) (x_{i+1} - x_i) \geq 0 $$ by the positive semidefiniteness of $D f.$ In this proof, the symmetry of $D f$ is not used, but I am not sure how it helps. EDIT: If $f$ is the gradient of some function, the monotonicity implies that the antiderivative is convex, but I am not assuming that $f$ is a gradient. Also, if $f$ is linear, p.240 of Rockafellar's book claims the answer is yes. I would like to know what happens if $f$ is nonlinear.","Let be a convex open set. Suppose a continuously differentiable vector-valued function satisfies that its derivative is symmetric and positive semidefinite. Is there a convex function such that ? I guess the answer is yes. I attempted to show that is cyclically monotone, but I could show only the monotonicity as follows. Let Then, Taylor's theorem says Thus, we have by the positive semidefiniteness of In this proof, the symmetry of is not used, but I am not sure how it helps. EDIT: If is the gradient of some function, the monotonicity implies that the antiderivative is convex, but I am not assuming that is a gradient. Also, if is linear, p.240 of Rockafellar's book claims the answer is yes. I would like to know what happens if is nonlinear.","U \subset \mathbb{R}^d f : U \to \mathbb{R}^d D f : U \to \mathbb{R}^{d \times d} \varphi : U \to \mathbb{R} \nabla \varphi = f f x_1, \dots, x_k \in U. 
f(x_{i+1})
=
f(x_i)
+
\left(
\int_0^1
D f ((1 - s) x_i + s x_{i+1}) 
d s
\right)
(x_{i+1} - x_i)
.
 
(x_{i+1} - x_i)^\prime
(f(x_{i+1}) - f(x_i))
=
(x_{i+1} - x_i)^\prime
\left(
\int_0^1
D f ((1 - s) x_i + s x_{i+1}) 
d s
\right)
(x_{i+1} - x_i)
\geq
0
 D f. D f f f f f","['real-analysis', 'functional-analysis', 'analysis', 'partial-differential-equations', 'convex-analysis']"
50,How is the tensor exponential map defined over a generic Banach space?,How is the tensor exponential map defined over a generic Banach space?,,"Given some vector $x = (x_1,...,x_d)$ in $\mathbb{R}^d$ we may embed it in the tensor algebra $T(\mathbb{R}):= \prod_{n=0}^\infty (\mathbb{R}^d)^{\otimes n}$ via the tensor exponential map $\exp_\otimes$ . Specifically, we have that $$\exp_\otimes(x) := \sum_{n=0}^\infty \frac{x^{\otimes n}}{n!}:= \sum_{n=0}^\infty \frac{1}{n!} \sum_{i_1,...,i_n=1}^d x_{i_1}...x_{i_n} e_{i_1} \otimes ... \otimes e_{i_n},$$ where $\{e_1,...,e_d\}$ denotes the canonical basis of $\mathbb{R}^d$ . Now, if we consider a generic Banach space $V$ (possibly infinite dimensional), how is $\exp_\otimes $ defined? This is a fairly common map in the context of Rough Path Theory, but I haven't found any reference where $\exp_\otimes$ is properly defined. Thanks in advance for any insight. Also, a reference would suffice.","Given some vector in we may embed it in the tensor algebra via the tensor exponential map . Specifically, we have that where denotes the canonical basis of . Now, if we consider a generic Banach space (possibly infinite dimensional), how is defined? This is a fairly common map in the context of Rough Path Theory, but I haven't found any reference where is properly defined. Thanks in advance for any insight. Also, a reference would suffice.","x = (x_1,...,x_d) \mathbb{R}^d T(\mathbb{R}):= \prod_{n=0}^\infty (\mathbb{R}^d)^{\otimes n} \exp_\otimes \exp_\otimes(x) := \sum_{n=0}^\infty \frac{x^{\otimes n}}{n!}:= \sum_{n=0}^\infty \frac{1}{n!} \sum_{i_1,...,i_n=1}^d x_{i_1}...x_{i_n} e_{i_1} \otimes ... \otimes e_{i_n}, \{e_1,...,e_d\} \mathbb{R}^d V \exp_\otimes  \exp_\otimes","['abstract-algebra', 'functional-analysis', 'reference-request', 'tensor-products', 'rough-path-theory']"
51,$L^1- L^\infty$ estimate for the semi group of wave equations,estimate for the semi group of wave equations,L^1- L^\infty,"I am looking for a proof of the following lemma for the case where: $y= (y_1,\cdots, y_n)\mapsto  P(y) = \|y\|_2= \sqrt{y_1^2+ \cdots + y_n^2}.$ In this case the rank of the mentioned matrix is $n-1$ for $y\neq 0$ ${\rm supp}(v)= \{y \in \mathbb{R}^n , 1<\|y\|_2 <2 \}$ The author referred to the following paper for the proof in the general case as stated above where It was done in the frame of Fourier transform of surface carried measures and its behaviour at the infinity. I wonder if there is another (more direct) proof which uses the usual techniques of functional analysis ( $L^p$ estimates, interpolation estimates ...etc.) Thank you for any hint. EDIT: Here is what I found in the literature for the general proof: In the following paper (see picture below): the Lemma 2.1 seems to have a result of the same nature where the author referred again the this paper from which I took a screenshot of the main result I wonder what the role of the assumption on the Hessian and the parameter $t$ is.","I am looking for a proof of the following lemma for the case where: In this case the rank of the mentioned matrix is for The author referred to the following paper for the proof in the general case as stated above where It was done in the frame of Fourier transform of surface carried measures and its behaviour at the infinity. I wonder if there is another (more direct) proof which uses the usual techniques of functional analysis ( estimates, interpolation estimates ...etc.) Thank you for any hint. EDIT: Here is what I found in the literature for the general proof: In the following paper (see picture below): the Lemma 2.1 seems to have a result of the same nature where the author referred again the this paper from which I took a screenshot of the main result I wonder what the role of the assumption on the Hessian and the parameter is.","y= (y_1,\cdots, y_n)\mapsto  P(y) = \|y\|_2= \sqrt{y_1^2+ \cdots + y_n^2}. n-1 y\neq 0 {\rm supp}(v)= \{y \in \mathbb{R}^n , 1<\|y\|_2 <2 \} L^p t","['functional-analysis', 'differential-geometry', 'fourier-analysis', 'lp-spaces']"
52,Oddity in definition(s) of quasi compact operator,Oddity in definition(s) of quasi compact operator,,"I was wondering about the general definition of a quasicompact operator. There seem to be two main ones floating around in the literature, and I am not sure they are equivalent. The first, and seemingly most prevalent one is that an operator $T:B \to B$ is quasi-compact, if there exists a natural number $n$ , and a compact operator $K$ , so that $$ \|T^n-K\|<1 $$ The second definition says that $T$ is quasi-compact, if there exists two closed, invariant subspaces $F, H$ , so that $$ B=F\oplus H $$ with $dim(F) <\infty$ , so that the spectral radius of $T$ restricted to $H$ is strictly less than the spectral radius of $T$ , $r(T)$ , and any eigenvalue of $T$ restricted to $F$ has magnitude $r(T)$ . My main query is that, whilst these definitions seem to be equivalent in the special case when $r(T) = 1$ , the second definition seems to imply that the class of quasi-compact operators is stable under scalar multiplication, whilst the first does not. I believe I came up with an example which I will put at the end of the question. A seemingly simple fix would be to require that $\|T^n-K\| < r(T)^n$ , but I haven't seen it used anywhere. I guess since these operators mainly show up in ergodic theory, having unit norm is very natural, and so perhaps this is how the convention was born. Nevertheless, having read quite a few papers now which use definition 1 in the form I stated, I was still wondering if perhaps I had perhaps missed something. $\textbf{Example:}$ Let $B$ be a Hilbert space with orthonormal basis $e_i$ . Define now an operator $T:B \to B$ by $Te_i=e_i$ for $i >1$ , and $Te_1=2e_1$ . This operator is quasi-compact in the sense of definition 2 (take $F=span\{e_1\}$ , $H=\overline{span\{e_i:i\geq 2\}}$ ), but not the sense of definition 1. However, $\frac{T}{\|T\|}$ is again quasi-compact in the sense of definition 1. To see $T$ is not quasicompact in the sense of definition 1,  note that $T^n$ still agrees with $T$ on any $e_i$ with $i \geq 2$ . Thus, if $K$ is compact and $\|T^n-K\|<1$ , there must exists a constant $a>0$ so that for all $i \geq 2$ , it holds $$ |1-\langle e_i,Ke_i\rangle|\leq \|T^ne_i-Ke_i\|\leq 1-a $$ so that $a \leq |\langle e_i,Ke_i\rangle|$ . By the compactness assumption, since the sequence $\{e_i\}$ converges weakly to zero, $Ke_i$ must converge to zero in norm. But then $\|Ke_i\|\geq a$ for any $i \geq 2$ , so this cannot be.","I was wondering about the general definition of a quasicompact operator. There seem to be two main ones floating around in the literature, and I am not sure they are equivalent. The first, and seemingly most prevalent one is that an operator is quasi-compact, if there exists a natural number , and a compact operator , so that The second definition says that is quasi-compact, if there exists two closed, invariant subspaces , so that with , so that the spectral radius of restricted to is strictly less than the spectral radius of , , and any eigenvalue of restricted to has magnitude . My main query is that, whilst these definitions seem to be equivalent in the special case when , the second definition seems to imply that the class of quasi-compact operators is stable under scalar multiplication, whilst the first does not. I believe I came up with an example which I will put at the end of the question. A seemingly simple fix would be to require that , but I haven't seen it used anywhere. I guess since these operators mainly show up in ergodic theory, having unit norm is very natural, and so perhaps this is how the convention was born. Nevertheless, having read quite a few papers now which use definition 1 in the form I stated, I was still wondering if perhaps I had perhaps missed something. Let be a Hilbert space with orthonormal basis . Define now an operator by for , and . This operator is quasi-compact in the sense of definition 2 (take , ), but not the sense of definition 1. However, is again quasi-compact in the sense of definition 1. To see is not quasicompact in the sense of definition 1,  note that still agrees with on any with . Thus, if is compact and , there must exists a constant so that for all , it holds so that . By the compactness assumption, since the sequence converges weakly to zero, must converge to zero in norm. But then for any , so this cannot be.","T:B \to B n K 
\|T^n-K\|<1
 T F, H 
B=F\oplus H
 dim(F) <\infty T H T r(T) T F r(T) r(T) = 1 \|T^n-K\| < r(T)^n \textbf{Example:} B e_i T:B \to B Te_i=e_i i >1 Te_1=2e_1 F=span\{e_1\} H=\overline{span\{e_i:i\geq 2\}} \frac{T}{\|T\|} T T^n T e_i i \geq 2 K \|T^n-K\|<1 a>0 i \geq 2 
|1-\langle e_i,Ke_i\rangle|\leq \|T^ne_i-Ke_i\|\leq 1-a
 a \leq |\langle e_i,Ke_i\rangle| \{e_i\} Ke_i \|Ke_i\|\geq a i \geq 2","['real-analysis', 'functional-analysis', 'probability-theory', 'ergodic-theory']"
53,$\rho(T)=\rho(T^*) $ if $T$ is defined between Banach Spaces.,if  is defined between Banach Spaces.,\rho(T)=\rho(T^*)  T,"Let $T:E\rightarrow E$ be a continuous linear map between Banach spaces. We define $T^*:E^*\rightarrow E^*$ by $T^*(e^*)(e)=e^*(T(e))$ . Under these conditions prove that the resolvent set $\rho(T)=\{\lambda \:| T-\lambda I \: \text{ is invertible}\}$ satisfies $\rho(T)=\rho(T^*)$ . That $\rho(T)\subseteq \rho(T^*)$ is straightforward from the definition. Indeed, if $T-\lambda I $ is invertible, then in particular it is surjective and this implies that: $$f_1((T-\lambda)(x))=f_2((T-\lambda)(x))\: \forall x\in E\Rightarrow f_1=f_2$$ But this implies $T^*-\lambda I^*$ is injective. For surjectivity it is enough to consider $g=f\circ (T-\lambda I)^{-1}\in E^*$ , because $(T^*-\lambda I^*)(g)=f$ . For the other inclusion I am having trouble. Suppose we have $\lambda \in \rho(T^*)$ , then $T^*-\lambda I^*$ is invertible. Take $x\in \ker(T-\lambda I)$ , then $(T-\lambda I)(x)=0$ and so $(T^*-\lambda I^*)(f)(x)=0$ for all $f\in E^*$ . But because of surjectivity, this means $f(x)=0$ for all $f\in E^*$ and so by Hahn Banach, $\lVert x \rVert=0$ which implies $x=0$ . Hence, $T-\lambda I$ is injective. So far I haven't been able to prove $T-\lambda I$ is surjective.  I wanted to suppose by way of contradiction $E\setminus (T-\lambda I)(E)\not=\emptyset$ and build a nonzero function which is zero in $(T-\lambda I)(E)$ , but I cannot use geometric Hahn-Banach, because $(T-\lambda I)(E)$ is not necessarily closed.","Let be a continuous linear map between Banach spaces. We define by . Under these conditions prove that the resolvent set satisfies . That is straightforward from the definition. Indeed, if is invertible, then in particular it is surjective and this implies that: But this implies is injective. For surjectivity it is enough to consider , because . For the other inclusion I am having trouble. Suppose we have , then is invertible. Take , then and so for all . But because of surjectivity, this means for all and so by Hahn Banach, which implies . Hence, is injective. So far I haven't been able to prove is surjective.  I wanted to suppose by way of contradiction and build a nonzero function which is zero in , but I cannot use geometric Hahn-Banach, because is not necessarily closed.",T:E\rightarrow E T^*:E^*\rightarrow E^* T^*(e^*)(e)=e^*(T(e)) \rho(T)=\{\lambda \:| T-\lambda I \: \text{ is invertible}\} \rho(T)=\rho(T^*) \rho(T)\subseteq \rho(T^*) T-\lambda I  f_1((T-\lambda)(x))=f_2((T-\lambda)(x))\: \forall x\in E\Rightarrow f_1=f_2 T^*-\lambda I^* g=f\circ (T-\lambda I)^{-1}\in E^* (T^*-\lambda I^*)(g)=f \lambda \in \rho(T^*) T^*-\lambda I^* x\in \ker(T-\lambda I) (T-\lambda I)(x)=0 (T^*-\lambda I^*)(f)(x)=0 f\in E^* f(x)=0 f\in E^* \lVert x \rVert=0 x=0 T-\lambda I T-\lambda I E\setminus (T-\lambda I)(E)\not=\emptyset (T-\lambda I)(E) (T-\lambda I)(E),['functional-analysis']
54,Is this supremum finite?,Is this supremum finite?,,"Let $\mathcal F := \{f_\theta\mid\theta\in\mathbb R^p\}$ be a parametric family of real-valued, continuous functions defined on $[0,1]^d $ , such that for all $\theta\in\mathbb R^p$ , $$|f_\theta(x)| \le F<\infty \,\,\forall x\in[0,1]^d, $$ for some $F>0$ . Now let $\rho$ be a probability distribution on $[0,1]^d\times \{-1,1\} $ , $(x_i,y_i)_{i=1}^\infty$ a sequence of i.i.d. random variables with distribution $\rho$ and define for all $n\ge 1$ : $$\hat R_n(\theta):=\frac1n\sum_{i=1}^n (f_\theta(x_i)-y_i)^2 $$ and the corresponding minimum-norm solution set : $$\hat\Theta_n := \arg\min_{\theta\in\arg\min\hat R_n}\|\theta\|_2$$ Lastly, let $B$ be the supremum of all of these vectors' magnitude : $$B:=\sup_{n\ge 1}\ \{\|\theta\|_2\mid \theta\in\hat\Theta_n\} $$ Question : is B finite ? If so, how to prove it ? If not, what assumptions would be sufficient to ensure its finiteness ? (Bonus : can it be upper bounded by a non-random quantity ?) My idea was to proceed by contradiction : if we assume that $B=\infty$ then we can construct (passing to a subsequence if necessary) a sequence $\hat\theta_1,\hat\theta_2,\ldots $ of minimizers of respectively $\hat R_1,\hat R_2,\ldots $ with norm going to $\infty$ . However, if we assume that the Rademacher complexity of $\mathcal F$ vanishes as $n\to\infty$ , we get by the uniform law of large numbers that $(\hat R_n)$ (as a sequence of real-valued functions defined on $\mathbb R^p$ ) converges uniformly to $R:\theta\mapsto \mathbb E_{(x,y)\sim\rho}\left[f_\theta(x)-y)^2\right]$ . I'm not sure of how to go on from here. I thought I could adapt the argument given here , to find a sequence of minimizers of $\hat R_n$ which converges to a minimizer of $R$ , but it doesn't seem to work ( $\mathbb R^p$ is not compact)... I'll be grateful for any help.","Let be a parametric family of real-valued, continuous functions defined on , such that for all , for some . Now let be a probability distribution on , a sequence of i.i.d. random variables with distribution and define for all : and the corresponding minimum-norm solution set : Lastly, let be the supremum of all of these vectors' magnitude : Question : is B finite ? If so, how to prove it ? If not, what assumptions would be sufficient to ensure its finiteness ? (Bonus : can it be upper bounded by a non-random quantity ?) My idea was to proceed by contradiction : if we assume that then we can construct (passing to a subsequence if necessary) a sequence of minimizers of respectively with norm going to . However, if we assume that the Rademacher complexity of vanishes as , we get by the uniform law of large numbers that (as a sequence of real-valued functions defined on ) converges uniformly to . I'm not sure of how to go on from here. I thought I could adapt the argument given here , to find a sequence of minimizers of which converges to a minimizer of , but it doesn't seem to work ( is not compact)... I'll be grateful for any help.","\mathcal F := \{f_\theta\mid\theta\in\mathbb R^p\} [0,1]^d  \theta\in\mathbb R^p |f_\theta(x)| \le F<\infty \,\,\forall x\in[0,1]^d,  F>0 \rho [0,1]^d\times \{-1,1\}  (x_i,y_i)_{i=1}^\infty \rho n\ge 1 \hat R_n(\theta):=\frac1n\sum_{i=1}^n (f_\theta(x_i)-y_i)^2  \hat\Theta_n := \arg\min_{\theta\in\arg\min\hat R_n}\|\theta\|_2 B B:=\sup_{n\ge 1}\ \{\|\theta\|_2\mid \theta\in\hat\Theta_n\}  B=\infty \hat\theta_1,\hat\theta_2,\ldots  \hat R_1,\hat R_2,\ldots  \infty \mathcal F n\to\infty (\hat R_n) \mathbb R^p R:\theta\mapsto \mathbb E_{(x,y)\sim\rho}\left[f_\theta(x)-y)^2\right] \hat R_n R \mathbb R^p","['real-analysis', 'functional-analysis', 'probability-theory', 'statistics', 'optimization']"
55,"To what extent does the ""Cauchy-Schwarz inequality"" hold for a normed vector space not inner product space?","To what extent does the ""Cauchy-Schwarz inequality"" hold for a normed vector space not inner product space?",,"It is known to all that for inner product space $H$ , Cauchy-Schwarz inequality hold: $| \langle x,y \rangle | \leq \| x \| \cdot \| y \| \ \forall x,y\in H$ , and for a normed space $X$ without inner product structure, we have two similar ""Cauchy inequality"":1. real case (use some algebraic substitution); 2. complex case My question is that for a normed space but not inner product space $X$ , noting that $$f(x,y)=\sum_{k=1}^{n} a_k(\|x+b_k y\|^2-\|x\|^2-\|b_k y\|^2) \ (a_k,b_k\ne 0,k=1,2,···,n )$$ which satisfy that $$\sum_{k=1}^{n}a_k\overline{b_k}=1; \ \sum_{k=1}^{n}a_kb_k=0 $$ in complex case,or $$\sum_{k=1}^{n}a_kb_k=\frac{1}{2}$$ in real case, (In summary, for an inner product space there is $f(x,y)=\langle x,y \rangle$ ) then in addition to the two examples mentioned above, what conditions are satisfied by sequence $\{a_k\},\{b_k\},\{c_k\}$ that enable inequality $|f(x,y)|\le\|x\|\|y\| \ \forall x,y\in X$ to hold? ----2023.12.17 Okay, I admit that I asked the question in order to find the condition that makes the normed space $X$ isometric isomorphic to the inner product space, here's the link to the question I asked on MathOverFlow . Thank if you can give me any help. ----2024.02.02 I'm now focus on a particular case about this problem: $$f(x,y)=\frac{1}{2}\sum_{k=1}^{n}a_{k}(\|x+b_{k}y\|^2-\|x-b_{k}y\|^2)$$ where $\sum_{k=1}^{n}a_{k}b_{k}=\frac{1}{2}$ , is $|f(x,y)|\le \|x\| \|y\|$ hold? Anyone who can give a proof of this case might be instructive. ----2024.02.28","It is known to all that for inner product space , Cauchy-Schwarz inequality hold: , and for a normed space without inner product structure, we have two similar ""Cauchy inequality"":1. real case (use some algebraic substitution); 2. complex case My question is that for a normed space but not inner product space , noting that which satisfy that in complex case,or in real case, (In summary, for an inner product space there is ) then in addition to the two examples mentioned above, what conditions are satisfied by sequence that enable inequality to hold? ----2023.12.17 Okay, I admit that I asked the question in order to find the condition that makes the normed space isometric isomorphic to the inner product space, here's the link to the question I asked on MathOverFlow . Thank if you can give me any help. ----2024.02.02 I'm now focus on a particular case about this problem: where , is hold? Anyone who can give a proof of this case might be instructive. ----2024.02.28","H | \langle x,y \rangle | \leq \| x \| \cdot \| y \| \ \forall x,y\in H X X f(x,y)=\sum_{k=1}^{n} a_k(\|x+b_k y\|^2-\|x\|^2-\|b_k y\|^2) \ (a_k,b_k\ne 0,k=1,2,···,n ) \sum_{k=1}^{n}a_k\overline{b_k}=1; \ \sum_{k=1}^{n}a_kb_k=0  \sum_{k=1}^{n}a_kb_k=\frac{1}{2} f(x,y)=\langle x,y \rangle \{a_k\},\{b_k\},\{c_k\} |f(x,y)|\le\|x\|\|y\| \ \forall x,y\in X X f(x,y)=\frac{1}{2}\sum_{k=1}^{n}a_{k}(\|x+b_{k}y\|^2-\|x-b_{k}y\|^2) \sum_{k=1}^{n}a_{k}b_{k}=\frac{1}{2} |f(x,y)|\le \|x\| \|y\|","['functional-analysis', 'inequality', 'normed-spaces', 'cauchy-schwarz-inequality']"
56,Subspaces of tensor products of Hilbert spaces,Subspaces of tensor products of Hilbert spaces,,"Let $H$ be a Hilbert space, and let $A,B,C,D\subset H$ be closed subspaces that intersect trivially. Consider the subspaces $A\otimes B$ , $C\otimes D$ , viewed as closed subspaces of the Hilbert space $H\otimes H$ . (Note that these are all Hilbert space tensor products, i.e. the closure of the algebraic tensor product with respect to the usual inner product on $H\otimes H$ ). Is it true that $A\otimes B$ and $C\otimes D$ once again intersect trivially? This seems to be true in the case where all the spaces are finite dimensional, since then the Hilbert tensor product agrees with the algebraic one. However I have had trouble showing that the trivial intersection is maintained upon taking the closure of the algebraic tensor products in infinite dimensions.","Let be a Hilbert space, and let be closed subspaces that intersect trivially. Consider the subspaces , , viewed as closed subspaces of the Hilbert space . (Note that these are all Hilbert space tensor products, i.e. the closure of the algebraic tensor product with respect to the usual inner product on ). Is it true that and once again intersect trivially? This seems to be true in the case where all the spaces are finite dimensional, since then the Hilbert tensor product agrees with the algebraic one. However I have had trouble showing that the trivial intersection is maintained upon taking the closure of the algebraic tensor products in infinite dimensions.","H A,B,C,D\subset H A\otimes B C\otimes D H\otimes H H\otimes H A\otimes B C\otimes D","['real-analysis', 'functional-analysis']"
57,Question about uniqueness of a specific Hahn-Banach extension,Question about uniqueness of a specific Hahn-Banach extension,,"Let $X = C([0,1])$ , and $L = Span(t)$ . Defining the functional $f(x):= \lambda$ when $x \in L$ is $\lambda t$ . Clearly, $||f||_{L^*} = 1$ . From Hahn-Banach, it can be extended to $F \in X^*$ , with $||F||_{X^*} = 1$ . The functional $\phi$ defined by $\phi(z) = z(1)$ works as a norm-preserving extension. My question is, is this extension unique, or is there another one? In case it is unique, how would one go on about proving it? EDIT: By $t$ I mean the identity in $[0,1]$","Let , and . Defining the functional when is . Clearly, . From Hahn-Banach, it can be extended to , with . The functional defined by works as a norm-preserving extension. My question is, is this extension unique, or is there another one? In case it is unique, how would one go on about proving it? EDIT: By I mean the identity in","X = C([0,1]) L = Span(t) f(x):= \lambda x \in L \lambda t ||f||_{L^*} = 1 F \in X^* ||F||_{X^*} = 1 \phi \phi(z) = z(1) t [0,1]","['functional-analysis', 'hahn-banach-theorem']"
58,What is the fundamental property of the Fourier operator?,What is the fundamental property of the Fourier operator?,,"It is well-known that the Fourier transform satisfies the following translation property: $$[\mathcal{F}(\mathcal{T}_hf)](\xi) = \text{e}^{2 \pi \text{i} \xi h} \cdot [\mathcal{F}(f)](\xi),$$ where $\mathcal{T}_h$ is the translation operator defined by $f(x) \mapsto f(x + h)$ . By further defining the derivative operator as $$\mathcal{D} = \lim_{h \to 0} \frac{\mathcal{T}_h - \mathcal{I}}{h},$$ one can show that $$ [\mathcal{F}(\mathcal{Df})](\xi) = 2 \pi \text{i} \xi \cdot [\mathcal{F}(f)](\xi) $$ by linearity and continuity arguments. I'm wondering if it's also possible to prove the convolution theorem, just using the translation property of the Fourier transform? I know that in the finite dimensional case, a (circluar) convolution can be represented by a circulant matrix, which can in turn be written as a polynomial in simple translation matrices. More generally, my question is: Is the fundamental property of the Fourier operator that it diagonalizes translations? That is, if we define $(\mathcal M_h \varphi)(\xi) = \text{e}^{2 \pi \text{i} \xi h} \cdot \varphi(\xi)$ , is the Fourier operator $\mathcal{F}$ fundamentally characterized by $$ \mathcal{F} \circ \mathcal{T}_h = \mathcal M_h \circ \mathcal{F} \ ? $$","It is well-known that the Fourier transform satisfies the following translation property: where is the translation operator defined by . By further defining the derivative operator as one can show that by linearity and continuity arguments. I'm wondering if it's also possible to prove the convolution theorem, just using the translation property of the Fourier transform? I know that in the finite dimensional case, a (circluar) convolution can be represented by a circulant matrix, which can in turn be written as a polynomial in simple translation matrices. More generally, my question is: Is the fundamental property of the Fourier operator that it diagonalizes translations? That is, if we define , is the Fourier operator fundamentally characterized by","[\mathcal{F}(\mathcal{T}_hf)](\xi) = \text{e}^{2 \pi \text{i} \xi h} \cdot [\mathcal{F}(f)](\xi), \mathcal{T}_h f(x) \mapsto f(x + h) \mathcal{D} = \lim_{h \to 0} \frac{\mathcal{T}_h - \mathcal{I}}{h}, 
[\mathcal{F}(\mathcal{Df})](\xi) = 2 \pi \text{i} \xi \cdot [\mathcal{F}(f)](\xi)
 (\mathcal M_h \varphi)(\xi) = \text{e}^{2 \pi \text{i} \xi h} \cdot \varphi(\xi) \mathcal{F} 
\mathcal{F} \circ \mathcal{T}_h = \mathcal M_h \circ \mathcal{F} \ ?
","['linear-algebra', 'functional-analysis', 'fourier-analysis', 'operator-theory', 'diagonalization']"
59,Norm on $H^1/2(\partial\Omega)$ by first isomorphism theorem.,Norm on  by first isomorphism theorem.,H^1/2(\partial\Omega),"I want to show that $\operatorname{ran}(T)$ equipped with \begin{equation*} \lVert v\rVert:=\inf\{u\in H^1(\Omega):Tu=v\} \end{equation*} is a Hilbert-Space. I have seen that the definition of the norm is motivated by the norm on quotient spaces. It was suggested to show that $\hat{T}:x+\ker(T)\mapsto T(x)$ is an isomorphism form $H^1(\Omega)/\ker(T)$ to $H^{1/2}(\partial\Omega)$ , by applying the first Isomorphism Theorem. How do I apply the Theorem without knowing that $\operatorname{ran}(T)$ is closed. I know that $\hat{T}$ is linear, bijective and continuous, how do I continue?","I want to show that equipped with is a Hilbert-Space. I have seen that the definition of the norm is motivated by the norm on quotient spaces. It was suggested to show that is an isomorphism form to , by applying the first Isomorphism Theorem. How do I apply the Theorem without knowing that is closed. I know that is linear, bijective and continuous, how do I continue?","\operatorname{ran}(T) \begin{equation*}
\lVert v\rVert:=\inf\{u\in H^1(\Omega):Tu=v\}
\end{equation*} \hat{T}:x+\ker(T)\mapsto T(x) H^1(\Omega)/\ker(T) H^{1/2}(\partial\Omega) \operatorname{ran}(T) \hat{T}","['functional-analysis', 'hilbert-spaces', 'sobolev-spaces', 'quotient-spaces', 'fractional-sobolev-spaces']"
60,Is a non-differentiable function Lipschitz continuous if and only if its subgradient is bounded?,Is a non-differentiable function Lipschitz continuous if and only if its subgradient is bounded?,,"It's well known that a differentiale continuous function is Lipschitz if and only if its gradient is bounded. ( Is a function Lipschitz if and only if its derivative is bounded? ) Can this result be generalized to non-differential case? The tricky thing here is to replace the gradient with Clarke subgradient ( https://en.wikipedia.org/wiki/Clarke_generalized_derivative ). In other word, is the following statement correct? Consider a continuous function $f(x)$ whose Clarke subgradient is $\partial f(x)$ on $x$ . $f(x)$ is $L$ -Lipschitz continous, i.e. $$\|f(x)-f(y)\|\le L\|x-y\|, \forall x, y\in{\rm dom}(f)$$ if and only if $\|g\|\le L$ for all $g\in\partial f(x)$ and $x\in{\rm int}({\rm dom}(f))$ , where ${\rm int}({\rm dom}(f))$ represents the interior of ${\rm dom}(f)$ .","It's well known that a differentiale continuous function is Lipschitz if and only if its gradient is bounded. ( Is a function Lipschitz if and only if its derivative is bounded? ) Can this result be generalized to non-differential case? The tricky thing here is to replace the gradient with Clarke subgradient ( https://en.wikipedia.org/wiki/Clarke_generalized_derivative ). In other word, is the following statement correct? Consider a continuous function whose Clarke subgradient is on . is -Lipschitz continous, i.e. if and only if for all and , where represents the interior of .","f(x) \partial f(x) x f(x) L \|f(x)-f(y)\|\le L\|x-y\|, \forall x, y\in{\rm dom}(f) \|g\|\le L g\in\partial f(x) x\in{\rm int}({\rm dom}(f)) {\rm int}({\rm dom}(f)) {\rm dom}(f)","['calculus', 'functional-analysis', 'lipschitz-functions', 'subgradient']"
61,"Does Banach space $C^{n}[0,1]$ contains isometric copy of $c_0$?",Does Banach space  contains isometric copy of ?,"C^{n}[0,1] c_0","Consider Banach space $C^{1}[0,1]$ of continuously differentiable functions provided with the norm $$ ||f|| = \sup_{x \in [0,1]} |f(x)| + \sup_{x \in [0,1]} |f'(x)|.$$ Similarly we define space $C^{n}[0,1]$ of $n$ times continuously differentiable functions. $\textbf{My question}$ : Does $C^{1}[0,1]$ contains a subspace which is isometrically isomorphic to the Banach space $c_0$ of all sequences converging to zero? What about $C^{n}[0,1]$ ? $\textbf{My thoughts}$ : I know that Banach space C[0,1] of all continuous functions equipped with norm $||f|| = \sup_{x \in [0,1]} |f(x)|$ contains isometric copy of $c_0$ . To produce such copy one chooses any sequence $(f_n) \subset C[0,1]$ of disjointly supported functions of norm one and considers space $X = \overline{span}(f_n: n \in \mathbf{N})$ . Then $\sum \alpha_n f_n$ converges iff $\alpha_n \rightarrow 0$ or, in other words, $(\alpha_n) \in c_0$ . Consequently, mapping $$c_0 \ni (\alpha_n) \mapsto \sum \alpha_n f_n \in X $$ is isometric isomorphism and $X$ is copy of $c_0$ sitting inside $C[0,1]$ . Example of sequence $(f_n) \subset C[0,1]$ satisfying the above properties is easy to define: put $f_n(t) = 0$ for $t \in [0,1] \setminus \Bigl(\frac{1}{2^{n+1}},\frac{1}{2^{n}}\Bigr)$ and $f_n\Bigl( \frac{3}{2^{n+2}} \Bigr) = 1$ and let $f_n$ be linear elsewhere. Let us pass to the space $C^{1}[0,1]$ with the norm defined at the beginning. I think the above procedure will also work in this case i.e. in order to find copy of $c_0$ inside this space one only needs to find a sequence $(f_n) \subset C^{1}[0,1]$ of smooth disjointly supported functions such that $\|f_n\| = 1$ for all $n$ .  However I'm having troubles to construct explicitly such a sequence.","Consider Banach space of continuously differentiable functions provided with the norm Similarly we define space of times continuously differentiable functions. : Does contains a subspace which is isometrically isomorphic to the Banach space of all sequences converging to zero? What about ? : I know that Banach space C[0,1] of all continuous functions equipped with norm contains isometric copy of . To produce such copy one chooses any sequence of disjointly supported functions of norm one and considers space . Then converges iff or, in other words, . Consequently, mapping is isometric isomorphism and is copy of sitting inside . Example of sequence satisfying the above properties is easy to define: put for and and let be linear elsewhere. Let us pass to the space with the norm defined at the beginning. I think the above procedure will also work in this case i.e. in order to find copy of inside this space one only needs to find a sequence of smooth disjointly supported functions such that for all .  However I'm having troubles to construct explicitly such a sequence.","C^{1}[0,1]  ||f|| = \sup_{x \in [0,1]} |f(x)| + \sup_{x \in [0,1]} |f'(x)|. C^{n}[0,1] n \textbf{My question} C^{1}[0,1] c_0 C^{n}[0,1] \textbf{My thoughts} ||f|| = \sup_{x \in [0,1]} |f(x)| c_0 (f_n) \subset C[0,1] X = \overline{span}(f_n: n \in \mathbf{N}) \sum \alpha_n f_n \alpha_n \rightarrow 0 (\alpha_n) \in c_0 c_0 \ni (\alpha_n) \mapsto \sum \alpha_n f_n \in X  X c_0 C[0,1] (f_n) \subset C[0,1] f_n(t) = 0 t \in [0,1] \setminus \Bigl(\frac{1}{2^{n+1}},\frac{1}{2^{n}}\Bigr) f_n\Bigl( \frac{3}{2^{n+2}} \Bigr) = 1 f_n C^{1}[0,1] c_0 (f_n) \subset C^{1}[0,1] \|f_n\| = 1 n","['functional-analysis', 'banach-spaces', 'smooth-functions']"
62,What is the relationship between Hölder spaces and differentiability?,What is the relationship between Hölder spaces and differentiability?,,"Let $C^{k,\alpha}$ be a Hölder space where $0 \leq \alpha \leq 1$ . I have seen various sources informally describe these spaces as functions having at least "" $k + \alpha$ "" derivatives. How does some sense of fractional differentiability follow from the definition of the Hölder norm?","Let be a Hölder space where . I have seen various sources informally describe these spaces as functions having at least "" "" derivatives. How does some sense of fractional differentiability follow from the definition of the Hölder norm?","C^{k,\alpha} 0 \leq \alpha \leq 1 k + \alpha","['real-analysis', 'functional-analysis', 'derivatives', 'holder-spaces', 'fractional-calculus']"
63,The set of homomorphism on $C_\infty(X)$ for a locally compact $X$,The set of homomorphism on  for a locally compact,C_\infty(X) X,"Let $X$ be a locally compact Hausdorff space, which is not compact. $C_b(X)$ is a Banach algebra of all bounded continuous functions with the sup norm. Let $C_\infty(X)$ be the Banach algebra of continuous functions such that for every $f \in C_\infty(X)$ , for every $\epsilon >0$ there exists a compact subset $K$ such that if $x \notin K, |f(x)|_\infty < \epsilon$ . Let $p \notin X$ and define $\tilde{X} = X \cup p$ . Topology on $\tilde{X}$ is topology on $X$ plus all complements of compact subsets of $X$ . Notice that $\tilde{X}$ is compact Hausdorff. Set $\mathcal{B} = C(\tilde{X})$ . $\mathcal{B}$ can be identified with the closed subalgebra of $C_b(X)$ generated by all $f \in C_\infty(X)$ and the constant function 1. Let $\mathcal{A} = C_\infty(X)$ . It is Banach algebra without unit. I need to determine $\hat{\mathcal{A}}$ , a set of homomorphisms into R that are not identically zero. Using the fact that any homomorphism on $C(\tilde{X})$ is of the form $\phi(f) = f(y)$ for some $y \in \tilde{X}$ , I figured any homomorphism in $\widehat{C_\infty(X)}$ is also of the form $\phi(g) = g(x)$ for some $x \in X$ . Is this correct?","Let be a locally compact Hausdorff space, which is not compact. is a Banach algebra of all bounded continuous functions with the sup norm. Let be the Banach algebra of continuous functions such that for every , for every there exists a compact subset such that if . Let and define . Topology on is topology on plus all complements of compact subsets of . Notice that is compact Hausdorff. Set . can be identified with the closed subalgebra of generated by all and the constant function 1. Let . It is Banach algebra without unit. I need to determine , a set of homomorphisms into R that are not identically zero. Using the fact that any homomorphism on is of the form for some , I figured any homomorphism in is also of the form for some . Is this correct?","X C_b(X) C_\infty(X) f \in C_\infty(X) \epsilon >0 K x \notin K, |f(x)|_\infty < \epsilon p \notin X \tilde{X} = X \cup p \tilde{X} X X \tilde{X} \mathcal{B} = C(\tilde{X}) \mathcal{B} C_b(X) f \in C_\infty(X) \mathcal{A} = C_\infty(X) \hat{\mathcal{A}} C(\tilde{X}) \phi(f) = f(y) y \in \tilde{X} \widehat{C_\infty(X)} \phi(g) = g(x) x \in X","['functional-analysis', 'group-homomorphism', 'banach-algebras']"
64,Sharp constant in the $L^p$ regularity estimate?,Sharp constant in the  regularity estimate?,L^p,"Problem : Let us denote $\mathbb{W}^{2,p}(\mathbb{R}^2)$ the space of Sobolev functions in the plane. Let us denote with $\Delta$ the classic Laplacian operator. We know that there exists a constant $C>0$ , depending only on $p$ and $d$ , such that if $f \in \mathbb{L}^p(\mathbb{R}^2)$ , $u \in \mathbb{W}^{2,p}(\mathbb{R}^2)$ and: $$ -\Delta u = f $$ in the weak sense, then it holds: $$ \|\partial_i \partial_j u \|_{\mathbb{L}^{p}(\mathbb{R}^2)} \leq C \|f \|_{\mathbb{W}^{2,p}(\mathbb{R}^2)} \quad \text{ for all } i,j \in \{1,2\} $$ I want to find the sharp constant $C$ with this property. In other words I want to find the least possible constant $C$ such that the property above holds. Attempt: I tried using Fourier theory and the Hardy–Littlewood–Sobolev theorem but this does not work if $\alpha=2$ is equal to the dimension $d=2$ , where $\alpha$ is the power associated to the $\Delta$ operator seen as a Fourier multiplier. Any help or any reference will be appreciated.","Problem : Let us denote the space of Sobolev functions in the plane. Let us denote with the classic Laplacian operator. We know that there exists a constant , depending only on and , such that if , and: in the weak sense, then it holds: I want to find the sharp constant with this property. In other words I want to find the least possible constant such that the property above holds. Attempt: I tried using Fourier theory and the Hardy–Littlewood–Sobolev theorem but this does not work if is equal to the dimension , where is the power associated to the operator seen as a Fourier multiplier. Any help or any reference will be appreciated.","\mathbb{W}^{2,p}(\mathbb{R}^2) \Delta C>0 p d f \in \mathbb{L}^p(\mathbb{R}^2) u \in \mathbb{W}^{2,p}(\mathbb{R}^2) 
-\Delta u = f
 
\|\partial_i \partial_j u \|_{\mathbb{L}^{p}(\mathbb{R}^2)} \leq C \|f \|_{\mathbb{W}^{2,p}(\mathbb{R}^2)} \quad \text{ for all } i,j \in \{1,2\}
 C C \alpha=2 d=2 \alpha \Delta","['functional-analysis', 'fourier-analysis', 'sobolev-spaces', 'laplacian', 'poissons-equation']"
65,Change of variables $s^2=r^2+b^2$,Change of variables,s^2=r^2+b^2,"I am trying to understand why this change of variables breaks down. Let $f$ be a smooth continuous function on an interval $[0,a]$ with $a>0$ , and let $b>0$ . I want to compute $$\int_0^af(r^2+b^2)\,dr.$$ I want to use the change of variables $s^2=r^2+b^2$ , $2s\,ds=2r\,dr$ so $dr=\frac{s}{\sqrt{s^2-b^2}}ds.$ Therefore $$\int_0^af(r^2+b^2)\,dr=\int_{b}^{\sqrt{a^2+b^2}}f(s^2)\frac{s}{\sqrt{s^2-b^2}}\,ds.$$ But this integral does not converge as $s\rightarrow b^+$ . I am confused because a smooth continuous function on a closed interval should be finite.","I am trying to understand why this change of variables breaks down. Let be a smooth continuous function on an interval with , and let . I want to compute I want to use the change of variables , so Therefore But this integral does not converge as . I am confused because a smooth continuous function on a closed interval should be finite.","f [0,a] a>0 b>0 \int_0^af(r^2+b^2)\,dr. s^2=r^2+b^2 2s\,ds=2r\,dr dr=\frac{s}{\sqrt{s^2-b^2}}ds. \int_0^af(r^2+b^2)\,dr=\int_{b}^{\sqrt{a^2+b^2}}f(s^2)\frac{s}{\sqrt{s^2-b^2}}\,ds. s\rightarrow b^+","['real-analysis', 'integration', 'functional-analysis', 'analysis', 'lebesgue-integral']"
66,Question on compactness of generator of unitary group,Question on compactness of generator of unitary group,,"Let $\mathcal{H}$ be complex Hilbert space. Suppose we have a unitary group $\{U_t\},t\in\mathbb{R}$ and by Stone's Theorem we have a unique infinitesimal generator $A:\mathcal{D}(A)\rightarrow\mathcal{H}$ , which is a self-adjoint operator: $$U_t = e^{itA} \quad t\in\mathbb{R}.$$ So, I wonder is this operator $A$ compact or not? The reason why I ask this is that in P.Walter's Spectral Theorem for Unitary Operators he said ""there exists a unique finite Borel measure $\mu_f$ "", however, in other materials, the term ""spectral measure"" is used. I noticed that the Borel measure is a spectral measure if there exists an orthogonal basis formed by spectrum of $A$ , but then I also see here that the compact self-adjoint operator $A$ can have such result. So, can someone explain me more about the details here why P.Walters theorem is different from others?","Let be complex Hilbert space. Suppose we have a unitary group and by Stone's Theorem we have a unique infinitesimal generator , which is a self-adjoint operator: So, I wonder is this operator compact or not? The reason why I ask this is that in P.Walter's Spectral Theorem for Unitary Operators he said ""there exists a unique finite Borel measure "", however, in other materials, the term ""spectral measure"" is used. I noticed that the Borel measure is a spectral measure if there exists an orthogonal basis formed by spectrum of , but then I also see here that the compact self-adjoint operator can have such result. So, can someone explain me more about the details here why P.Walters theorem is different from others?","\mathcal{H} \{U_t\},t\in\mathbb{R} A:\mathcal{D}(A)\rightarrow\mathcal{H} U_t = e^{itA} \quad t\in\mathbb{R}. A \mu_f A A","['real-analysis', 'functional-analysis', 'operator-theory', 'compact-operators', 'functional-calculus']"
67,"Book suggestion on ""Banach space geometry for machine learning""","Book suggestion on ""Banach space geometry for machine learning""",,"Is there any book for a Mathematics student who can learn Machine learning in the aspect of Banach space geometry? Or, one can understand the connection between Geometry of Banach spaces and Machine learning? Any suggestions in terms of article, note, book regarding the development of such study is always welcomed. It will be very much helpful if anyone can suggest a good book which contains the discussion about the topic of Geometry of banach spaces that is required for Machine learning, Neural network such things. Thank you in advance.","Is there any book for a Mathematics student who can learn Machine learning in the aspect of Banach space geometry? Or, one can understand the connection between Geometry of Banach spaces and Machine learning? Any suggestions in terms of article, note, book regarding the development of such study is always welcomed. It will be very much helpful if anyone can suggest a good book which contains the discussion about the topic of Geometry of banach spaces that is required for Machine learning, Neural network such things. Thank you in advance.",,"['functional-analysis', 'operator-theory', 'banach-spaces', 'machine-learning']"
68,Does derivative assigns diffrential?,Does derivative assigns diffrential?,,"So there are 3 main definitions of derivation in 3 different contexts. Calculus of one variable real functions. Say we have an everywhere differentiable function $f: \mathbb{R} \to \mathbb{R}$ . Then its derivative is function $f': \mathbb{R} \to \mathbb{R}$ . Its differential is linear map $df: \mathbb{R} \to \mathbb{R}$ . Functional analysis. Say we have a Banach spaces $E$ and $F$ , and a function $f: E \to F$ . Then for each point $x \in X$ we can define a Frechet derivative $f'(x)$ which is a continuous linear map $E \to F$ . So we have an assignment $x \mapsto B(E, F)$ . Manifolds. Say we have manifolds $M$ and $N$ and a morphism $f: M \to N$ . Then for each point $x \in M$ we can assign a differential $df_x$ which is a linear map of tangent spaces $df_x: T_x M \to T_{f(x)} N$ . Is it true that all of these definitions coincide in the context of calculus? To be more precise: So is it true that a derivative is in fact an assignment of differential to each point? Where differential is morphism of tangent spaces? I use term assignment to emphasize that tangent spaces may be different for each point. It would be beautiful if there is a functor of some sort, but I can't figure it out. Here are my thoughts: There is a distinct notion of derivative and differential in the context of calculus, but no differential of function of Banach spaces, nor derivative of morphism of manifolds. Frechet derivative can be identified with usual derivative because $B(\mathbb{R}, F) \cong F$ (isometric isomorphism). Differential of morphisms coincide with usual differential because $T_x \mathbb{R} \cong \mathbb{R}$ . So $T_x E \cong E$ for Banach spaces? (Some kind of synthetic-algebraic definition needed here.) Is there a notion of differential forms on Banach spaces, e.g. when doing integrals? Is there some geometric structure on tangent spaces? I mean from algebraic view they all have same dimension $T_x M \cong T_y M \cong \mathbb{R}^m$ , so we may define a function $f': M \to L(\mathbb{R}^m, \mathbb{R}^n)$ ? (Here $\dim M = m, \dim N = n$ .) Bonus: what about TVS?","So there are 3 main definitions of derivation in 3 different contexts. Calculus of one variable real functions. Say we have an everywhere differentiable function . Then its derivative is function . Its differential is linear map . Functional analysis. Say we have a Banach spaces and , and a function . Then for each point we can define a Frechet derivative which is a continuous linear map . So we have an assignment . Manifolds. Say we have manifolds and and a morphism . Then for each point we can assign a differential which is a linear map of tangent spaces . Is it true that all of these definitions coincide in the context of calculus? To be more precise: So is it true that a derivative is in fact an assignment of differential to each point? Where differential is morphism of tangent spaces? I use term assignment to emphasize that tangent spaces may be different for each point. It would be beautiful if there is a functor of some sort, but I can't figure it out. Here are my thoughts: There is a distinct notion of derivative and differential in the context of calculus, but no differential of function of Banach spaces, nor derivative of morphism of manifolds. Frechet derivative can be identified with usual derivative because (isometric isomorphism). Differential of morphisms coincide with usual differential because . So for Banach spaces? (Some kind of synthetic-algebraic definition needed here.) Is there a notion of differential forms on Banach spaces, e.g. when doing integrals? Is there some geometric structure on tangent spaces? I mean from algebraic view they all have same dimension , so we may define a function ? (Here .) Bonus: what about TVS?","f: \mathbb{R} \to \mathbb{R} f': \mathbb{R} \to \mathbb{R} df: \mathbb{R} \to \mathbb{R} E F f: E \to F x \in X f'(x) E \to F x \mapsto B(E, F) M N f: M \to N x \in M df_x df_x: T_x M \to T_{f(x)} N B(\mathbb{R}, F) \cong F T_x \mathbb{R} \cong \mathbb{R} T_x E \cong E T_x M \cong T_y M \cong \mathbb{R}^m f': M \to L(\mathbb{R}^m, \mathbb{R}^n) \dim M = m, \dim N = n","['calculus', 'functional-analysis', 'differential-geometry', 'differential-forms', 'frechet-derivative']"
69,Intuition behind the spectral theorem in infinite dimensions,Intuition behind the spectral theorem in infinite dimensions,,"I would like to verify my intuition behind the spectral theorem in infinite dimensions. For the moment I am putting bounded/unbounded and domain issues aside. In finite dimensions the spectral theorem says that for any self-adjoint/Hermitian matrix $A$ , $$A = U^{-1}\Lambda U $$ where $\Lambda$ is a diagonal matrix consisting of the eigenvalues of $A$ and $U$ is a change of basis matrix. The interpretation here is that $U$ maps to a basis that is a direct sum of eigenspaces. In each eigenspace the the action of $A$ is multiplication by the appropriate eigenvalue. Thus we may write $$A = \sum_i^n \lambda_i P_i \tag{1}$$ where $P_i$ is the projection onto the eigenspace corresponding to $\lambda_i$ . Moving to infinite dimensions, let $A$ be a self-adjoint operator on some Hilbert space $H$ . Unlike the finite dimensional case, in general the spectrum of $A$ : Is no longer countable. Contains elements that are not eigenvalues (i.e. the continuous part of the spectrum). To address the first point, the sum in (1) is now made into an integral: $$A = \int_{\sigma(A)} \lambda dP_\lambda. \tag{2}$$ For points in the spectrum of $A$ that are eigenvalues, the integral (2) is to be interpreted similarly to (1). That is, we project onto the eigenspace spanned by $\lambda$ and the action of $A$ on this subspace is to multiply by $\lambda$ . Making sense of (2) for points in the continuous spectrum addresses the second point above. The operator $P_\lambda$ for $\lambda$ in the continuous spectrum is the zero projector. To account for the contribution of the continuous spectrum we make sense of (2) in a limiting sense similar to how the Lebesgue integral is constructed. That is, we consider Borel sets $\Omega$ containing an approximate eigenvalue and interpret $P_\Omega$ as projecting onto an approximate eigenspace where the action of $A$ is approximately multiplication by $\lambda$ . Its contribution to (2) is obtained as $\Omega \rightarrow \{\lambda\}$ in some sense, again similar to how we use simple functions to construct the Lebesgue integral and then take a limit. I know the above is a bit handwav and can be made more precise using distribution functions $P_\lambda = P((-\infty, \lambda])$ to define a Stieltjes integral, but my goal is to build an intuition for now. Is my intuition of the spectral theorem and the integral (2) correct?","I would like to verify my intuition behind the spectral theorem in infinite dimensions. For the moment I am putting bounded/unbounded and domain issues aside. In finite dimensions the spectral theorem says that for any self-adjoint/Hermitian matrix , where is a diagonal matrix consisting of the eigenvalues of and is a change of basis matrix. The interpretation here is that maps to a basis that is a direct sum of eigenspaces. In each eigenspace the the action of is multiplication by the appropriate eigenvalue. Thus we may write where is the projection onto the eigenspace corresponding to . Moving to infinite dimensions, let be a self-adjoint operator on some Hilbert space . Unlike the finite dimensional case, in general the spectrum of : Is no longer countable. Contains elements that are not eigenvalues (i.e. the continuous part of the spectrum). To address the first point, the sum in (1) is now made into an integral: For points in the spectrum of that are eigenvalues, the integral (2) is to be interpreted similarly to (1). That is, we project onto the eigenspace spanned by and the action of on this subspace is to multiply by . Making sense of (2) for points in the continuous spectrum addresses the second point above. The operator for in the continuous spectrum is the zero projector. To account for the contribution of the continuous spectrum we make sense of (2) in a limiting sense similar to how the Lebesgue integral is constructed. That is, we consider Borel sets containing an approximate eigenvalue and interpret as projecting onto an approximate eigenspace where the action of is approximately multiplication by . Its contribution to (2) is obtained as in some sense, again similar to how we use simple functions to construct the Lebesgue integral and then take a limit. I know the above is a bit handwav and can be made more precise using distribution functions to define a Stieltjes integral, but my goal is to build an intuition for now. Is my intuition of the spectral theorem and the integral (2) correct?","A A = U^{-1}\Lambda U  \Lambda A U U A A = \sum_i^n \lambda_i P_i \tag{1} P_i \lambda_i A H A A = \int_{\sigma(A)} \lambda dP_\lambda. \tag{2} A \lambda A \lambda P_\lambda \lambda \Omega P_\Omega A \lambda \Omega \rightarrow \{\lambda\} P_\lambda = P((-\infty, \lambda])","['functional-analysis', 'operator-theory', 'spectral-theory']"
70,Is the Essential Spectrum the same as the Continuous Spectrum and Residual Spectrum,Is the Essential Spectrum the same as the Continuous Spectrum and Residual Spectrum,,"Given a linear operator $A:D(A)\rightarrow X$ (where $D(A)$ is a dense subset of $X$ and $X$ is a Banach space or Hilbert Space), we define the spectrum to be $$ \sigma(A)=\{\lambda\in\mathbb{C}: A-\lambda \text{is not invertible}\} $$ We note that $\sigma(A)$ will be a closed subset of $\mathbb{C}$ . Now there are a few ways that one may break up the spectrum. Firstly, we can decompose it into the discrete spectrum and the essential spectrum that is $\sigma(A)=\sigma_d(A)\cup \sigma_{ess}(A)$ . Where we have that the discrete spectrum, $\sigma_d(A)$ , consists of all eigenvalues of $A$ such that $A-\lambda$ has finite algebraic multiplicity. Then we define the essential spectrum $\sigma_{ess}(A)$ to be the complement of $\sigma_d(A)$ inside of $\sigma(A)$ . It is clear that this is a partition of the spectrum. Now there is another way in which we may break up the spectrum. We can decompose it as $\sigma(A)=\sigma_{eigenvalues}(A)\cup \sigma_{cont}(A)\cup\sigma_{res}(A)$ . In this decomposition, we have that $\sigma_{eigenvalues}(A)$ are the eigenvalues of $A$ consisting of those $\lambda\in\mathbb{C}$ such that $\ker(A-\lambda)\neq 0$ . Thus, the remaining cases what happens if $\ker(A-\lambda)=0$ , then this splits up into two cases depending upon the range of $A-\lambda$ . If $\text{Ran}(A-\lambda)$ is a dense subset of $X$ , then we have that $A-\lambda$ will have a densely defined inverse (which necessarily must be unbounded since if it were bounded then $A-\lambda$ would be invertible and $\lambda$ would not be in the spectrum) such $\lambda$ are a part of the continuous spectrum $\sigma_{cont}(A)$ . Then the last case is if $\ker(A-\lambda)=0$ , but $\text{Ran}(A-\lambda)$ is not dense, then put such $\lambda$ in the residual spectrum $\sigma_{res}(A)$ . Thus, we have these two different decompositions of the spectrum. My question is how related are these two decompositions? Since intuitively I would like to say that $\sigma_{eigenvalues}(A)=\sigma_d(A)$ , and then $\sigma_{ess}(A)=\sigma_{cont}(A)\cup\sigma_{res}(A)$ , but this seems wrong after thinking about it since there may be an eigenvalue with infinite algebraic multiplicity, so is all that we can say is that $\sigma_d(A)\subset\sigma_{eigenvalues}(A)$ and hence $\sigma_{cont}(A)\cup\sigma_{res}(A)\subset\sigma_{ess}(A)$ , or is there some sort of further decomposition relating these? Or maybe there is some property of $A$ (like maybe being normal or self-adjoint or something like that) which might make this true?","Given a linear operator (where is a dense subset of and is a Banach space or Hilbert Space), we define the spectrum to be We note that will be a closed subset of . Now there are a few ways that one may break up the spectrum. Firstly, we can decompose it into the discrete spectrum and the essential spectrum that is . Where we have that the discrete spectrum, , consists of all eigenvalues of such that has finite algebraic multiplicity. Then we define the essential spectrum to be the complement of inside of . It is clear that this is a partition of the spectrum. Now there is another way in which we may break up the spectrum. We can decompose it as . In this decomposition, we have that are the eigenvalues of consisting of those such that . Thus, the remaining cases what happens if , then this splits up into two cases depending upon the range of . If is a dense subset of , then we have that will have a densely defined inverse (which necessarily must be unbounded since if it were bounded then would be invertible and would not be in the spectrum) such are a part of the continuous spectrum . Then the last case is if , but is not dense, then put such in the residual spectrum . Thus, we have these two different decompositions of the spectrum. My question is how related are these two decompositions? Since intuitively I would like to say that , and then , but this seems wrong after thinking about it since there may be an eigenvalue with infinite algebraic multiplicity, so is all that we can say is that and hence , or is there some sort of further decomposition relating these? Or maybe there is some property of (like maybe being normal or self-adjoint or something like that) which might make this true?","A:D(A)\rightarrow X D(A) X X 
\sigma(A)=\{\lambda\in\mathbb{C}: A-\lambda \text{is not invertible}\}
 \sigma(A) \mathbb{C} \sigma(A)=\sigma_d(A)\cup \sigma_{ess}(A) \sigma_d(A) A A-\lambda \sigma_{ess}(A) \sigma_d(A) \sigma(A) \sigma(A)=\sigma_{eigenvalues}(A)\cup \sigma_{cont}(A)\cup\sigma_{res}(A) \sigma_{eigenvalues}(A) A \lambda\in\mathbb{C} \ker(A-\lambda)\neq 0 \ker(A-\lambda)=0 A-\lambda \text{Ran}(A-\lambda) X A-\lambda A-\lambda \lambda \lambda \sigma_{cont}(A) \ker(A-\lambda)=0 \text{Ran}(A-\lambda) \lambda \sigma_{res}(A) \sigma_{eigenvalues}(A)=\sigma_d(A) \sigma_{ess}(A)=\sigma_{cont}(A)\cup\sigma_{res}(A) \sigma_d(A)\subset\sigma_{eigenvalues}(A) \sigma_{cont}(A)\cup\sigma_{res}(A)\subset\sigma_{ess}(A) A","['functional-analysis', 'spectral-theory']"
71,Can the Stinespring Dilation Theorem extend to *unbounded* operators?,Can the Stinespring Dilation Theorem extend to *unbounded* operators?,,"I have some (possibly basic) questions about $C^*$ -algebras, the Stinespring Theorem (Theorem 3.6 in Takesaki's book ), and unbounded operators. This is motivated by quantum mechanics, where unbounded operators are common. For example, the momentum operator $\hat{p}$ (which is related to $-i \partial^{\,}_x$ ), or the boson number operator $\hat{n}$ , whose eigenvalues are $n \in \mathbb{N}^{\,}_0$ . For reference, I have come across these two works from 2008 and from 2020 , which seem relevant, though I lack the background to understand them fully in finite time. Do the two references above generically extend the Stinespring Theorem to unbounded operators? In other words, if a Hilbert space $\mathcal{H}$ admits unbounded operators, and I replace the usual set of bounded operators $\mathcal{B}(\mathcal{H})$ with the set  End( $\mathcal{H}$ ) of all (possibly self-adjoint) linear operators on $\mathcal{H}$ , does the following aspect of the Stinespring Theorem still hold: Let $\mathcal{H}$ and $\mathcal{K}$ be Hilbert spaces, with corresponding operator sets ${\rm End}(\mathcal{H})$ and ${\rm End}(\mathcal{K})$ . If the adjoint map $\psi^* = \phi: \mathcal{A} \to {\rm End}(\mathcal{H})$ is completely positive and unital, then there exists a unital *-homomorphism $\pi : \mathcal{A} \to {\rm End} (\mathcal{K})$ and an isometry $V : \mathcal{H} \to \mathcal{K}$ such that, $ \forall A \in \mathcal{A}$ , $\phi (A) = V^* \pi (A) V$ , up to multiplication by a unitary. The statement above is the part of the Theorem relevant to me, and please correct me if I've been sloppy. For quantum mechanics, the $C^*$ -algebra $\mathcal{A}$ is unital, the map $\psi$ and its adjoint $\phi$ are generally completely positive and trace preserving (CPTP), we can restrict to self-adjoint operators in End( $\mathcal{H}$ ), and/or require that dim( $\mathcal{K}$ ) ≥ dim( $\mathcal{H}$ ), if helpful. If these papers are not familiar—and because I am new to *-algebras—it would also be helpful to me to know, e.g., what goes wrong in trying to construct $C^*$ -algebras with unbounded operators, if anything? If there are issues, do they persist if we restrict to unital algebras / CPTP maps / self-adjoint operators? Or, are things like ""completely positive"" or other aspects of $C^*$ -algebras difficult to define with unbounded operators? Lastly, do unbounded operators pose a particular obstacle to proving the Stinespring Theorem beyond the considerations above? If this is a bad question in any respect, please let me know how I could improve it / what is missing. I did not find any similar questions while searching Stack, and my more general search came up with the two papers referenced above. Still, if you think another answer might be relevant, please comment with a link.","I have some (possibly basic) questions about -algebras, the Stinespring Theorem (Theorem 3.6 in Takesaki's book ), and unbounded operators. This is motivated by quantum mechanics, where unbounded operators are common. For example, the momentum operator (which is related to ), or the boson number operator , whose eigenvalues are . For reference, I have come across these two works from 2008 and from 2020 , which seem relevant, though I lack the background to understand them fully in finite time. Do the two references above generically extend the Stinespring Theorem to unbounded operators? In other words, if a Hilbert space admits unbounded operators, and I replace the usual set of bounded operators with the set  End( ) of all (possibly self-adjoint) linear operators on , does the following aspect of the Stinespring Theorem still hold: Let and be Hilbert spaces, with corresponding operator sets and . If the adjoint map is completely positive and unital, then there exists a unital *-homomorphism and an isometry such that, , , up to multiplication by a unitary. The statement above is the part of the Theorem relevant to me, and please correct me if I've been sloppy. For quantum mechanics, the -algebra is unital, the map and its adjoint are generally completely positive and trace preserving (CPTP), we can restrict to self-adjoint operators in End( ), and/or require that dim( ) ≥ dim( ), if helpful. If these papers are not familiar—and because I am new to *-algebras—it would also be helpful to me to know, e.g., what goes wrong in trying to construct -algebras with unbounded operators, if anything? If there are issues, do they persist if we restrict to unital algebras / CPTP maps / self-adjoint operators? Or, are things like ""completely positive"" or other aspects of -algebras difficult to define with unbounded operators? Lastly, do unbounded operators pose a particular obstacle to proving the Stinespring Theorem beyond the considerations above? If this is a bad question in any respect, please let me know how I could improve it / what is missing. I did not find any similar questions while searching Stack, and my more general search came up with the two papers referenced above. Still, if you think another answer might be relevant, please comment with a link.","C^* \hat{p} -i \partial^{\,}_x \hat{n} n \in \mathbb{N}^{\,}_0 \mathcal{H} \mathcal{B}(\mathcal{H}) \mathcal{H} \mathcal{H} \mathcal{H} \mathcal{K} {\rm End}(\mathcal{H}) {\rm End}(\mathcal{K}) \psi^* = \phi: \mathcal{A} \to {\rm End}(\mathcal{H}) \pi : \mathcal{A} \to {\rm End} (\mathcal{K}) V : \mathcal{H} \to \mathcal{K}  \forall A \in \mathcal{A} \phi (A) = V^* \pi (A) V C^* \mathcal{A} \psi \phi \mathcal{H} \mathcal{K} \mathcal{H} C^* C^*","['linear-algebra', 'functional-analysis', 'c-star-algebras', 'unbounded-operators']"
72,Brezis' exercise 6.15.2: $\|I + \lambda (T-\lambda I)^{-1}\| \le \frac{\|T\|}{|\lambda|- \|T\|}$,Brezis' exercise 6.15.2:,\|I + \lambda (T-\lambda I)^{-1}\| \le \frac{\|T\|}{|\lambda|- \|T\|},"I'm trying to solve an exercise in Brezis' Functional Analysis , i.e., Let $(E, |\cdot|)$ be a real Banach space. Let $T \in \mathcal L(E)$ , i.e., $T:E \to E$ is a bounded linear operator. Let $I:E \to E$ be the identity map. Let $\rho(T)$ be the resolvent set of $T$ . Let $\sigma(T)$ be the spectrum of $T$ , i.e., $\sigma(T) := \mathbb R \setminus \rho(T)$ . Let $\lambda \in \mathbb R$ such that $\|T\| < |\lambda|$ . Prove that $$ \|I + \lambda (T-\lambda I)^{-1}\| \le \frac{\|T\|}{|\lambda|- \|T\|}. $$ Let $\lambda \in \rho(T)$ . Check that $(T-\lambda I)^{-1} T = T (T-\lambda I)^{-1}$ and prove that $$ d(\lambda, \sigma(T)) := \inf_{h \in \sigma(T)} |\lambda-h| \ge \frac{1}{\| (T-\lambda I)^{-1} \|}. $$ There are possibly subtle mistakes that I could not recognize in below attempt. Could you please have a check on it? I'm also happy to see other approaches. We need a result from the same book, i.e., Exercise 6.14 Assume that $\|T\| < 1$ . Prove that $(I-T)$ is bijective and that $$ \|(I-T)^{-1}\| \le \frac{1}{1- \|T\|}. $$ Let $S_n := I+T+\cdots+T^{n-1}$ . Prove that $$ \|S_n-(I-T)^{-1}\| \le \frac{\|T\|^n}{1- \|T\|}. $$ Clearly, $\lambda \neq 0$ . Let $K:= \frac{T}{\lambda}$ . Then $\|K\| < 1$ . By exercise 6.14.2 , we get $$ \|I-(I-K)^{-1}\| \le \frac{\|K\|}{1- \|K\|}. $$ The claim then follows. 2. Let $A := (T-\lambda I)^{-1} T$ and $B:=T (T-\lambda I)^{-1}$ . Then $(T-\lambda I) A= T$ . Because $(T-\lambda I)$ is bijective, it suffices to prove that $(T-\lambda I) B= T$ . First, we have $$ \begin{align*} B - \lambda I(T-\lambda I)^{-1} &= T (T-\lambda I)^{-1} - \lambda I (T-\lambda I)^{-1} \\ &= (T-\lambda I) (T-\lambda I)^{-1}= I. \end{align*} $$ Then $B= I + \lambda I(T-\lambda I)^{-1}$ and thus $$ \begin{align*} (T-\lambda I) B &= (T-\lambda I)  + (T-\lambda I) \lambda I(T-\lambda I)^{-1} \\ &= (T-\lambda I) + \lambda I= T. \end{align*} $$ By Proposition 6.7 (in the same book), $\sigma(T)$ is compact and $\sigma(T) \subset [-\|T\|, \|T\|]$ . Then $\rho(T)$ is open. Let $r:= \frac{1}{\| (T-\lambda I)^{-1} \|}$ . As in the proof of Proposition 6.7 , $B(\lambda, r) :=\{h \in \mathbb R : |h-\lambda| < r\} \subset \rho(T)$ . The claim then follows.","I'm trying to solve an exercise in Brezis' Functional Analysis , i.e., Let be a real Banach space. Let , i.e., is a bounded linear operator. Let be the identity map. Let be the resolvent set of . Let be the spectrum of , i.e., . Let such that . Prove that Let . Check that and prove that There are possibly subtle mistakes that I could not recognize in below attempt. Could you please have a check on it? I'm also happy to see other approaches. We need a result from the same book, i.e., Exercise 6.14 Assume that . Prove that is bijective and that Let . Prove that Clearly, . Let . Then . By exercise 6.14.2 , we get The claim then follows. 2. Let and . Then . Because is bijective, it suffices to prove that . First, we have Then and thus By Proposition 6.7 (in the same book), is compact and . Then is open. Let . As in the proof of Proposition 6.7 , . The claim then follows.","(E, |\cdot|) T \in \mathcal L(E) T:E \to E I:E \to E \rho(T) T \sigma(T) T \sigma(T) := \mathbb R \setminus \rho(T) \lambda \in \mathbb R \|T\| < |\lambda| 
\|I + \lambda (T-\lambda I)^{-1}\| \le \frac{\|T\|}{|\lambda|- \|T\|}.
 \lambda \in \rho(T) (T-\lambda I)^{-1} T = T (T-\lambda I)^{-1} 
d(\lambda, \sigma(T)) := \inf_{h \in \sigma(T)} |\lambda-h| \ge \frac{1}{\| (T-\lambda I)^{-1} \|}.
 \|T\| < 1 (I-T) 
\|(I-T)^{-1}\| \le \frac{1}{1- \|T\|}.
 S_n := I+T+\cdots+T^{n-1} 
\|S_n-(I-T)^{-1}\| \le \frac{\|T\|^n}{1- \|T\|}.
 \lambda \neq 0 K:= \frac{T}{\lambda} \|K\| < 1 
\|I-(I-K)^{-1}\| \le \frac{\|K\|}{1- \|K\|}.
 A := (T-\lambda I)^{-1} T B:=T (T-\lambda I)^{-1} (T-\lambda I) A= T (T-\lambda I) (T-\lambda I) B= T 
\begin{align*}
B - \lambda I(T-\lambda I)^{-1} &= T (T-\lambda I)^{-1} - \lambda I (T-\lambda I)^{-1} \\
&= (T-\lambda I) (T-\lambda I)^{-1}= I.
\end{align*}
 B= I + \lambda I(T-\lambda I)^{-1} 
\begin{align*}
(T-\lambda I) B &= (T-\lambda I)  + (T-\lambda I) \lambda I(T-\lambda I)^{-1} \\
&= (T-\lambda I) + \lambda I= T.
\end{align*}
 \sigma(T) \sigma(T) \subset [-\|T\|, \|T\|] \rho(T) r:= \frac{1}{\| (T-\lambda I)^{-1} \|} B(\lambda, r) :=\{h \in \mathbb R : |h-\lambda| < r\} \subset \rho(T)","['functional-analysis', 'solution-verification', 'operator-theory', 'banach-spaces', 'spectral-theory']"
73,Regularity of functions in weighted Sobolev spaces,Regularity of functions in weighted Sobolev spaces,,"I am interested in a version of Morrey's inequality but for a weighted Sobolev space. The classical Morrey inequality states, Let $p>N$ , then for all $u \in W^{1,p}(\mathbb{R}^N)$ , $$ |u(x)-u(y)|\leq C|x-y|^{\alpha} \cdot\|\nabla u\|_{L_p}, $$ with $\alpha=1-\frac{N}{p}$ . My question is does a similar result hold if we are working in a weighted Sobolev space, i.e let, $$ W_\omega^{1,p}(\mathbb{R}^N)=\{ u:\int_\mathbb{R}|u|^p\omega_1dx + \int_{\mathbb{R}}|\nabla u|^p\omega_2dx < \infty \}, $$ with $\omega_1$ and $\omega_2$ are positive weight functions. I have tried to prove a result like this on my own but with no avail, approximating the function $u$ by it's derivative becomes more delicate. Any references would be greatly appreciated.","I am interested in a version of Morrey's inequality but for a weighted Sobolev space. The classical Morrey inequality states, Let , then for all , with . My question is does a similar result hold if we are working in a weighted Sobolev space, i.e let, with and are positive weight functions. I have tried to prove a result like this on my own but with no avail, approximating the function by it's derivative becomes more delicate. Any references would be greatly appreciated.","p>N u \in W^{1,p}(\mathbb{R}^N) 
|u(x)-u(y)|\leq C|x-y|^{\alpha} \cdot\|\nabla u\|_{L_p},
 \alpha=1-\frac{N}{p} 
W_\omega^{1,p}(\mathbb{R}^N)=\{ u:\int_\mathbb{R}|u|^p\omega_1dx + \int_{\mathbb{R}}|\nabla u|^p\omega_2dx < \infty \},
 \omega_1 \omega_2 u","['functional-analysis', 'lp-spaces', 'sobolev-spaces']"
74,Show that the fractional Laplacian operator is closed,Show that the fractional Laplacian operator is closed,,"Consider the fractional Laplacian defined by $$(-\Delta)^s u(x) = P.V. \int_{\mathbb{R}^N} \frac{u(x) - u(y)}{|x - y|^{N + 2s}}dy, \ s \in (0,1).$$ Also consider that $$D((-\Delta)^s) = \{u \in H^s(\Omega); (-\Delta)^su \in L^2(\Omega)\},$$ for some $s \in (0,1)$ . I want to show that the operator $(-\Delta)^s : D((-\Delta)^s) \subset L^2(\Omega) \to L^2(\Omega)$ is closed. Here, $\Omega \subset \mathbb{R}^N$ is a bounded and smooth domain with $u = 0$ in $\mathbb{R}^N \backslash \Omega$ . Attempt: Let $(u_n) \subset D((-\Delta)^s) $ with $u_n\to u$ in $L^2(\Omega)$ and $(-\Delta)^su_n \to v$ in $L^2(\Omega)$ . By Fatou's Lemma, I was able to show that $u \in H^s(\Omega)$ , where $$H^s(\Omega) = \left\{u \in L^2(\Omega); \int \int_{\Omega \times \Omega}\frac{|u(x) - u(y)|^2}{|x - y|^{(N + 2s)}}\right\}.$$ Now, I need to show that $\int_{\Omega}|(-\Delta)^su(x)|^2 dx < \infty$ . I have tried in different ways, but without success. For example, the most I can do is show, by Fatou's Lemma, that $\int_{\Omega}|(-\Delta)^su(x)|^2 dx \geqslant \|v\|^2_{L^2(\Omega)}$ .","Consider the fractional Laplacian defined by Also consider that for some . I want to show that the operator is closed. Here, is a bounded and smooth domain with in . Attempt: Let with in and in . By Fatou's Lemma, I was able to show that , where Now, I need to show that . I have tried in different ways, but without success. For example, the most I can do is show, by Fatou's Lemma, that .","(-\Delta)^s u(x) = P.V. \int_{\mathbb{R}^N} \frac{u(x) - u(y)}{|x - y|^{N + 2s}}dy, \ s \in (0,1). D((-\Delta)^s) = \{u \in H^s(\Omega); (-\Delta)^su \in L^2(\Omega)\}, s \in (0,1) (-\Delta)^s : D((-\Delta)^s) \subset L^2(\Omega) \to L^2(\Omega) \Omega \subset \mathbb{R}^N u = 0 \mathbb{R}^N \backslash \Omega (u_n) \subset D((-\Delta)^s)  u_n\to u L^2(\Omega) (-\Delta)^su_n \to v L^2(\Omega) u \in H^s(\Omega) H^s(\Omega) = \left\{u \in L^2(\Omega); \int \int_{\Omega \times \Omega}\frac{|u(x) - u(y)|^2}{|x - y|^{(N + 2s)}}\right\}. \int_{\Omega}|(-\Delta)^su(x)|^2 dx < \infty \int_{\Omega}|(-\Delta)^su(x)|^2 dx \geqslant \|v\|^2_{L^2(\Omega)}","['functional-analysis', 'measure-theory', 'fractional-calculus', 'fractional-sobolev-spaces']"
75,"When I can truncate a function space to a subspace, in a way that non-negative functions stay non-negative?","When I can truncate a function space to a subspace, in a way that non-negative functions stay non-negative?",,"When I can truncate a function space to a subspace, in a way that non-negative functions stay non-negative? How I got here (a simple concrete example): I was working with point-process intensity functions $\rho(x)$ on $x\in\mathbb R^n$ . I wanted to find some ""nice"" convolutional filters $f(x)$ that: Send all Fourier frequencies $\omega \in \mathcal \Omega$ above $\omega_0$ to identically zero, that is $\|\omega\|>\omega_0 \Rightarrow \{\hat f\cdot \hat \rho\}(\omega)=0$ (to not worry about high-frequency details). Are themselves non-negative $f(x)\ge 0$ (to interpret $f*\rho$ as the PDF resulting from addition of improper random variables). $f(x)$ and $\hat f(\omega)$ are ""as nice as possible"" in any interesting sense. Probably things like ""unimodal"", and ""peak at zero"" ""as concentrated as possible near zero"". You can get some very nice low-pass $f(x)$ with compact support on $\|\omega\|\ge\omega_0$ , achieve their maximum at $x=0$ , are reasonably concentrated near $x=0$ , and have $\nabla f(x)=0$ for $x=0$ . For example, $f(x) \propto \operatorname{sinc}(\alpha x)^4$ is nice. I wasn't able to find any such $f(x)$ that decayed monotonically from $x=0$ ; Can such a function exist? I realized I didn't have the tools to reason about this. My attempts to generalize This seemed like a special case of something that may have relevant results in functional analysis. Here is my best-attempt at generalizing the problem: Let $\rho \in \mathcal R:\mathcal X\mapsto \mathbb R_{\ge 0}$ be non-negative functions on $x \in \mathcal X$ . Let $f \in \mathcal F:\mathcal X\mapsto \mathbb R$ be scalar functions on $x \in \mathcal X$ . Let $\mathcal M$ a function space contining $\mathcal R$ and $\mathcal F$ . Let $U:\mathcal M\mapsto \mathcal M$ be operators that preserve non-negativity: $U\rho \subseteq \mathcal R$ Let $K:\mathcal M\mapsto \mathcal M$ be operators that send a non-trivial subspace of $\mathcal M$ to zero (have a nontrivial kernel). Q: How can we find operators that are in both $U$ and $K$ ? The definitions above should be considered ""purely formal"", ""vague"", or ""confused, please help me fix it"". I'm interested in keywords, the names of mathematical objects, well-known results, topics and sub-fields that I can search for to learn more? What theorems, concepts, and results on this topic might I find empowering?","When I can truncate a function space to a subspace, in a way that non-negative functions stay non-negative? How I got here (a simple concrete example): I was working with point-process intensity functions on . I wanted to find some ""nice"" convolutional filters that: Send all Fourier frequencies above to identically zero, that is (to not worry about high-frequency details). Are themselves non-negative (to interpret as the PDF resulting from addition of improper random variables). and are ""as nice as possible"" in any interesting sense. Probably things like ""unimodal"", and ""peak at zero"" ""as concentrated as possible near zero"". You can get some very nice low-pass with compact support on , achieve their maximum at , are reasonably concentrated near , and have for . For example, is nice. I wasn't able to find any such that decayed monotonically from ; Can such a function exist? I realized I didn't have the tools to reason about this. My attempts to generalize This seemed like a special case of something that may have relevant results in functional analysis. Here is my best-attempt at generalizing the problem: Let be non-negative functions on . Let be scalar functions on . Let a function space contining and . Let be operators that preserve non-negativity: Let be operators that send a non-trivial subspace of to zero (have a nontrivial kernel). Q: How can we find operators that are in both and ? The definitions above should be considered ""purely formal"", ""vague"", or ""confused, please help me fix it"". I'm interested in keywords, the names of mathematical objects, well-known results, topics and sub-fields that I can search for to learn more? What theorems, concepts, and results on this topic might I find empowering?",\rho(x) x\in\mathbb R^n f(x) \omega \in \mathcal \Omega \omega_0 \|\omega\|>\omega_0 \Rightarrow \{\hat f\cdot \hat \rho\}(\omega)=0 f(x)\ge 0 f*\rho f(x) \hat f(\omega) f(x) \|\omega\|\ge\omega_0 x=0 x=0 \nabla f(x)=0 x=0 f(x) \propto \operatorname{sinc}(\alpha x)^4 f(x) x=0 \rho \in \mathcal R:\mathcal X\mapsto \mathbb R_{\ge 0} x \in \mathcal X f \in \mathcal F:\mathcal X\mapsto \mathbb R x \in \mathcal X \mathcal M \mathcal R \mathcal F U:\mathcal M\mapsto \mathcal M U\rho \subseteq \mathcal R K:\mathcal M\mapsto \mathcal M \mathcal M U K,"['linear-algebra', 'functional-analysis', 'hilbert-spaces', 'banach-spaces', 'reproducing-kernel-hilbert-spaces']"
76,Numerical computation of the continuous Fourier transform,Numerical computation of the continuous Fourier transform,,"Let $$\varphi(x):=\frac1{2\pi\sigma^2}e^{-\frac12\left(\frac{\|x\|}\sigma\right)^2}\;\;\;\text{for }x\in\mathbb R^2$$ for some $\sigma>0$ . I want to numerically compute $$p(\omega):=\left|\hat\varphi(\omega)\right|^2\;\;\;\text{for }\omega\in[-1,1)^2.$$ Shouldn't be too complicated, I thought. For the numerical integration, I'm using $$[-a,a)=\bigcup_{i_1=-k_1}^{k_1-1}\bigcup_{i_2=-k_2}^{k_2-1}\left(\left[\frac{i_1}{k_1}a_1,\frac{i_1+1}{k_1}a_1\right)\times\left[\frac{i_2}{k_2}a_2,\frac{i_2+1}{k_2}a_2\right)\right)$$ for suitable chosen $a_1,a_2>0$ and $k_1,k_2\in\mathbb N$ . This gives me the scheme $$\hat\varphi(\omega)\approx\frac{a_1a_2}{k_1k_2}\sum_{i_1=-k_1}^{k_1-1}\sum_{i_2=-k_2}^{k_2-1}e^{-{\rm i}2\pi\langle\omega,\left(\frac{i_1}{k_1}a_1,\:\frac{i_2}{k_2}a_2\right)}\varphi\left(\frac{i_1}{k_1}a_1,\frac{i_2}{k_2}a_2\right).$$ Plotting $p$ using this scheme and $a_1=a_2=k_1=k_2=100$ , I obtain the following result: Now, I already know that the analytical form of $\hat\varphi$ is $$\hat\varphi(\omega)=e^{-2\left(\pi\sigma\|\omega\|\right)^2}\;\;\;\text{for all }\omega\in\mathbb R^d,$$ where $d=2$ in our case. Plotting $p$ using this analytical form, I obtain this result: They are obviously different. I think I should expect that the ""spectrum is replicated"" in the first result (can I somehow obtain the distance from the center until when the replication begins?). However, even if I cut out the centered spectrum, it doesn't match the one in the second result. So, is there anything wrong with the way I estimated $\hat\varphi$ in the numerical integration? All plots show $\sigma=1$ .","Let for some . I want to numerically compute Shouldn't be too complicated, I thought. For the numerical integration, I'm using for suitable chosen and . This gives me the scheme Plotting using this scheme and , I obtain the following result: Now, I already know that the analytical form of is where in our case. Plotting using this analytical form, I obtain this result: They are obviously different. I think I should expect that the ""spectrum is replicated"" in the first result (can I somehow obtain the distance from the center until when the replication begins?). However, even if I cut out the centered spectrum, it doesn't match the one in the second result. So, is there anything wrong with the way I estimated in the numerical integration? All plots show .","\varphi(x):=\frac1{2\pi\sigma^2}e^{-\frac12\left(\frac{\|x\|}\sigma\right)^2}\;\;\;\text{for }x\in\mathbb R^2 \sigma>0 p(\omega):=\left|\hat\varphi(\omega)\right|^2\;\;\;\text{for }\omega\in[-1,1)^2. [-a,a)=\bigcup_{i_1=-k_1}^{k_1-1}\bigcup_{i_2=-k_2}^{k_2-1}\left(\left[\frac{i_1}{k_1}a_1,\frac{i_1+1}{k_1}a_1\right)\times\left[\frac{i_2}{k_2}a_2,\frac{i_2+1}{k_2}a_2\right)\right) a_1,a_2>0 k_1,k_2\in\mathbb N \hat\varphi(\omega)\approx\frac{a_1a_2}{k_1k_2}\sum_{i_1=-k_1}^{k_1-1}\sum_{i_2=-k_2}^{k_2-1}e^{-{\rm i}2\pi\langle\omega,\left(\frac{i_1}{k_1}a_1,\:\frac{i_2}{k_2}a_2\right)}\varphi\left(\frac{i_1}{k_1}a_1,\frac{i_2}{k_2}a_2\right). p a_1=a_2=k_1=k_2=100 \hat\varphi \hat\varphi(\omega)=e^{-2\left(\pi\sigma\|\omega\|\right)^2}\;\;\;\text{for all }\omega\in\mathbb R^d, d=2 p \hat\varphi \sigma=1","['functional-analysis', 'numerical-methods', 'fourier-analysis', 'fourier-transform']"
77,"Finding a conditionally convergent series of functions in $C[0,1]$ with supremum norm w.r.t Faber-Schauder system.",Finding a conditionally convergent series of functions in  with supremum norm w.r.t Faber-Schauder system.,"C[0,1]","Let, \begin{align*}         \alpha(x) &= 1 \\         \beta(x) &= x\\         s_{n,k}(x) &= \max\{1-|2(2^nx-k)-1|, 0\} \text{   for  } 0 \le n \text{ and } 0 \le k \le 2^{n}-1     \end{align*} We define the Faber-Schauder system \begin{equation*}     S := \{ \alpha, \beta \} \cup \{ s_{n,k} \}_{n \ge 0, 2^{n}-1 \ge k \ge 0 } \end{equation*} $s_{n,k}$ denotes the hat function supported on the interval $[\frac{k}{2^n},\frac{k+1}{2^n}]$ and whose peak is 1 and attained at $\frac{2k+1}{2^{n+1}}$ . S is a basis for $C[0,1]$ with the supremum norm. It is known that any basis for $C[0,1]$ is conditional. I am trying to find a concrete example of a series of functions which converges conditionally. My strategy is to use some sort of linear combinations of the basis functions i.e, $g_M = \sum_{n = 0}^{M} \sum_{k = 0}^{2^{n}-1} c_{n,k} s_{n,k}$ . I will show that $g_M$ uniformly converges(show that it is uniformly cauchy). Then I show that $(-1)^n g_M$ doesn't uniformly converge(ideally goes to infinity). Vice versa is fine too, i.e, $(-1)^n g_M$ uniformly converges and $(-1)^n g_M$ doesn't uniformly converge. This shows that $g_M$ (or $(-1)^n g_M$ ) is conditionally convergent. Or maybe, I could use another characterization of conditional convergence. I tried couple of linear combinatons to construct $g_M$ . For example, $g_M = \sum_{n = 0}^{M} s_{n,0}$ which didn't work.  Another example is constructed by firs considering interval $[0,1]$ and its corresponding function $t_0 = s_{0,0}$ then diveding it by half and taking the left part, $[0,\frac{1}{2}]$ , which corresponds to $t_1 = s_{1,0}$ then divide half and take the right part, $[\frac{1}{4},\frac{1}{2}]$ , which correspond to $t_2 = s_{2,1}$ and so on. We always halve the current interval and alternate between taking the left part and right part with its corresponding function. $g_M = \sum_{n=0}^{M} t_n$ .In this case, $g_M$ goes to infinity which is good. But I don't think $(-1)^ng_{M}$ uniformly converges. I am looking forward for your ideas.","Let, We define the Faber-Schauder system denotes the hat function supported on the interval and whose peak is 1 and attained at . S is a basis for with the supremum norm. It is known that any basis for is conditional. I am trying to find a concrete example of a series of functions which converges conditionally. My strategy is to use some sort of linear combinations of the basis functions i.e, . I will show that uniformly converges(show that it is uniformly cauchy). Then I show that doesn't uniformly converge(ideally goes to infinity). Vice versa is fine too, i.e, uniformly converges and doesn't uniformly converge. This shows that (or ) is conditionally convergent. Or maybe, I could use another characterization of conditional convergence. I tried couple of linear combinatons to construct . For example, which didn't work.  Another example is constructed by firs considering interval and its corresponding function then diveding it by half and taking the left part, , which corresponds to then divide half and take the right part, , which correspond to and so on. We always halve the current interval and alternate between taking the left part and right part with its corresponding function. .In this case, goes to infinity which is good. But I don't think uniformly converges. I am looking forward for your ideas.","\begin{align*}
        \alpha(x) &= 1 \\
        \beta(x) &= x\\
        s_{n,k}(x) &= \max\{1-|2(2^nx-k)-1|, 0\} \text{   for  } 0 \le n \text{ and } 0 \le k \le 2^{n}-1
    \end{align*} \begin{equation*}
    S := \{ \alpha, \beta \} \cup \{ s_{n,k} \}_{n \ge 0, 2^{n}-1 \ge k \ge 0 }
\end{equation*} s_{n,k} [\frac{k}{2^n},\frac{k+1}{2^n}] \frac{2k+1}{2^{n+1}} C[0,1] C[0,1] g_M = \sum_{n = 0}^{M} \sum_{k = 0}^{2^{n}-1} c_{n,k} s_{n,k} g_M (-1)^n g_M (-1)^n g_M (-1)^n g_M g_M (-1)^n g_M g_M g_M = \sum_{n = 0}^{M} s_{n,0} [0,1] t_0 = s_{0,0} [0,\frac{1}{2}] t_1 = s_{1,0} [\frac{1}{4},\frac{1}{2}] t_2 = s_{2,1} g_M = \sum_{n=0}^{M} t_n g_M (-1)^ng_{M}","['real-analysis', 'sequences-and-series', 'functional-analysis', 'metric-spaces', 'conditional-convergence']"
78,Does the exponential operator $e^{tA}$ defined via functional calculus and via semi group coincide?,Does the exponential operator  defined via functional calculus and via semi group coincide?,e^{tA},"Given $X$ is a Hilbert space and consider the operator $A$ on $X$ . Functional calculus: given an unbounded operator $A$ (densely defined, closed and self-adjoint), we can define $e^{tA}$ by the spectral measure. Semi-group: given an unbounded operator $A$ (densely defined, closed) which generates a continuous semi-group, we can define $e^{tA}$ by the Laplace transform of the resolvent operator. Question: Do these two approaches give the same definition in the case where $A$ is densely defined, closed, self-adjoint and generates a continuous semi-group? Trivial case: if $A$ is bounded or $A$ has compact resolvent, I think this question is rather trivial in view of the behavior of the point spectrum.","Given is a Hilbert space and consider the operator on . Functional calculus: given an unbounded operator (densely defined, closed and self-adjoint), we can define by the spectral measure. Semi-group: given an unbounded operator (densely defined, closed) which generates a continuous semi-group, we can define by the Laplace transform of the resolvent operator. Question: Do these two approaches give the same definition in the case where is densely defined, closed, self-adjoint and generates a continuous semi-group? Trivial case: if is bounded or has compact resolvent, I think this question is rather trivial in view of the behavior of the point spectrum.",X A X A e^{tA} A e^{tA} A A A,"['functional-analysis', 'operator-theory', 'spectral-theory', 'semigroup-of-operators', 'functional-calculus']"
79,Pointwise Convergence of Convolutions,Pointwise Convergence of Convolutions,,"While reading chapter 4 of ""Deep Learning Architectures, A Mathematical Approach"" by Ovidiu Calin, I stumbled upon the following statement: Using the fact that the Gaussian tends to Dirac measure, $\lim_{\sigma \to +0}G_\sigma(x) \to \delta(x)$ , we have $$ \lim_{\sigma \to +0} f_\sigma(x) = \lim_{\sigma \to +0} (f*G_\sigma)(x) = (f*\delta)(x) = f(x), $$ where $f(x)$ is an integrable function on $\mathbb{R}$ and $G_\sigma(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{x^2}{2\sigma^2})$ and $f_\sigma(x) = (f*G_\sigma)(x) = \int f(u)G_\sigma(x-u)du$ . From what I know, I wasn't very sure about this result. Unfortunately, the proof is omitted from the book so I tried to verify the claim by myself. It is not exactly the same but I was able to confirm the results below by following argument in Chapter 9 of ""Real and Complex Analysis"" by Walter Rudin. Result 1: If $f$ is bounded and continuous at point $x$ , then $$ \lim_{\sigma\to +0}f_\sigma(x) = f(x). $$ Result 2: If $1\leq p < \infty$ and $f\in L^p$ , then $f_\sigma$ converges to $f$ in $L^p$ as $\sigma \to +0$ . From the second result, it follows that there exists a sequence $\sigma_n \to +0$ such that $f_{\sigma_n}(x) \to f(x)$ almost surely. But it does not extend to pointwise almost sure convergence of $f_\sigma \to f$ . It doesn't seem to be possible to show pointwise almost sure convergence $f_\sigma \to f$ without assumptions like in the result 1. But I'm not sure if there is something special about gaussian or if there is a counterexample to it. I appreciate it if anyone could prove the claim or provide a counterexample to it. You don't have to write full solution, if you know a good reference, then just a reference is fine. Update: As Jochen pointed out, by following the argument here , we can show almost sure pointwise convergence if $f \in L^\infty$ . So, the question really is whether we can relax it to $f \in L^1$ .","While reading chapter 4 of ""Deep Learning Architectures, A Mathematical Approach"" by Ovidiu Calin, I stumbled upon the following statement: Using the fact that the Gaussian tends to Dirac measure, , we have where is an integrable function on and and . From what I know, I wasn't very sure about this result. Unfortunately, the proof is omitted from the book so I tried to verify the claim by myself. It is not exactly the same but I was able to confirm the results below by following argument in Chapter 9 of ""Real and Complex Analysis"" by Walter Rudin. Result 1: If is bounded and continuous at point , then Result 2: If and , then converges to in as . From the second result, it follows that there exists a sequence such that almost surely. But it does not extend to pointwise almost sure convergence of . It doesn't seem to be possible to show pointwise almost sure convergence without assumptions like in the result 1. But I'm not sure if there is something special about gaussian or if there is a counterexample to it. I appreciate it if anyone could prove the claim or provide a counterexample to it. You don't have to write full solution, if you know a good reference, then just a reference is fine. Update: As Jochen pointed out, by following the argument here , we can show almost sure pointwise convergence if . So, the question really is whether we can relax it to .","\lim_{\sigma \to +0}G_\sigma(x) \to \delta(x) 
\lim_{\sigma \to +0} f_\sigma(x) = \lim_{\sigma \to +0} (f*G_\sigma)(x) = (f*\delta)(x) = f(x),
 f(x) \mathbb{R} G_\sigma(x) = \frac{1}{\sqrt{2\pi}\sigma}\exp(-\frac{x^2}{2\sigma^2}) f_\sigma(x) = (f*G_\sigma)(x) = \int f(u)G_\sigma(x-u)du f x 
\lim_{\sigma\to +0}f_\sigma(x) = f(x).
 1\leq p < \infty f\in L^p f_\sigma f L^p \sigma \to +0 \sigma_n \to +0 f_{\sigma_n}(x) \to f(x) f_\sigma \to f f_\sigma \to f f \in L^\infty f \in L^1","['real-analysis', 'functional-analysis', 'normal-distribution', 'convolution', 'weak-convergence']"
80,Spacial regularity of heat equation with zero initial condition,Spacial regularity of heat equation with zero initial condition,,"Consider the heat equation with zero Dirichlet boundary condition and zero initial data in time interval $[0,T]$ : $$ \partial_t u-\Delta u=f\;\;\text{in $\Omega$};\quad u(0)=0;\quad u|_{\partial \Omega}=0 $$ If we assume that $f\in L^2H^2(\Omega)$ (where $L^2H^2(\Omega)$ is an abbreviation of the Bochner space norm $L^2(0,T;H^2(\Omega)$ ) and $f(t)\in H^1_0(\Omega)$ for almost every $t$ , can we conclude the following estimate? $$ \|\partial_t u\|_{L^2H^2(\Omega)}\leq C\|f\|_{L^2H^2(\Omega)}. $$ My idea is to intuitively take operator $\Delta$ on the both side of the original heat equation, thus consider the solution $v$ of the following heat equation $$ \partial_t v-\Delta v=\Delta f\;\;\text{in $\Omega$};\quad v(0)=0;\quad v|_{\partial \Omega}=0 $$ then let $u=(\Delta)^{-1} v$ , $u$ seems to be the solution of the original heat equation and satisfies the estimate above. But it seems something went wrong here, could you help with me with finding the mistake?","Consider the heat equation with zero Dirichlet boundary condition and zero initial data in time interval : If we assume that (where is an abbreviation of the Bochner space norm ) and for almost every , can we conclude the following estimate? My idea is to intuitively take operator on the both side of the original heat equation, thus consider the solution of the following heat equation then let , seems to be the solution of the original heat equation and satisfies the estimate above. But it seems something went wrong here, could you help with me with finding the mistake?","[0,T] 
\partial_t u-\Delta u=f\;\;\text{in \Omega};\quad u(0)=0;\quad u|_{\partial \Omega}=0
 f\in L^2H^2(\Omega) L^2H^2(\Omega) L^2(0,T;H^2(\Omega) f(t)\in H^1_0(\Omega) t 
\|\partial_t u\|_{L^2H^2(\Omega)}\leq C\|f\|_{L^2H^2(\Omega)}.
 \Delta v 
\partial_t v-\Delta v=\Delta f\;\;\text{in \Omega};\quad v(0)=0;\quad v|_{\partial \Omega}=0
 u=(\Delta)^{-1} v u","['functional-analysis', 'partial-differential-equations', 'heat-equation', 'semigroup-of-operators']"
81,Intersection of $C^*$-algebras under addition,Intersection of -algebras under addition,C^*,"Let $\mathcal{B}\subset\mathcal{A}$ be an inclusion of unital $C^*$ -algebras. Let $\mathcal{C}$ be an unital simple subalgebra of $\mathcal{A}$ which is under the image of a faithful conditional expectation from $\mathcal{A}$ , i.e., there exists a unital completely positive projection $\Phi: \mathcal{A}\to\mathcal{C}$ . Moreover, $\Phi(\mathcal{B})\subsetneq \mathcal{C}$ . Suppose that $I\triangleleft\mathcal{A}$ is a non-trivial two sided closed ideal in $\mathcal{A}$ . Standing assumption: $\mathcal{A}$ is generated as a $C^*$ -algebra by $\mathcal{B}$ and $\mathcal{C}$ . Claim: $\mathcal{B}\subsetneq\mathcal{B}+I\subsetneq \mathcal{A}$ . Attempt: Since $I\triangleleft\mathcal{A}$ is an ideal of $\mathcal{A}$ , it follows that $I+\mathcal{B}$ is a $C^*$ -subalgebra of $\mathcal{A}$ . Now, $\Phi(I)\triangleleft\mathcal{C}$ is an ideal of $\mathcal{C}$ . Since $\mathcal{C}$ is simple, it follows that $\Phi(I)=0$ or $\Phi(I)=\mathcal{C}$ . Since $\Phi$ is faithful, it must be the case that $\Phi(I)=\mathcal{C}$ . Since $\Phi(\mathcal{B})\subsetneq \mathcal{C}$ , it follows that $\mathcal{B}\subsetneq \mathcal{B}+I$ . Now, $I\cap\mathcal{C}$ is an ideal of $\mathcal{C}$ . Since $\mathcal{C}$ is simple and $I$ is non-trivial, it must be the case that $I\cap\mathcal{C}=0$ . Here, I am using the assumption that $\mathcal{A}$ is generated by $\mathcal{B}$ and $\mathcal{C}$ . All that remains to be shown is that $\mathcal{B}+I\subsetneq \mathcal{A}$ . I am trying to show that $\left(\mathcal{B}+I\right)\cap \mathcal{C}=\mathcal{B}\cap\mathcal{C}$ . Once this is establishes, we shall have that $\mathcal{B}\cap\mathcal{C}\subset \Phi(\mathcal{B})\subsetneq\mathcal{C}$ which will ensure that $\mathcal{B}+I\subsetneq \mathcal{A}$ . I am unable to do it. I need to use that $I\cap\mathcal{C}=0$ . How do I do it? Thank you for your time.","Let be an inclusion of unital -algebras. Let be an unital simple subalgebra of which is under the image of a faithful conditional expectation from , i.e., there exists a unital completely positive projection . Moreover, . Suppose that is a non-trivial two sided closed ideal in . Standing assumption: is generated as a -algebra by and . Claim: . Attempt: Since is an ideal of , it follows that is a -subalgebra of . Now, is an ideal of . Since is simple, it follows that or . Since is faithful, it must be the case that . Since , it follows that . Now, is an ideal of . Since is simple and is non-trivial, it must be the case that . Here, I am using the assumption that is generated by and . All that remains to be shown is that . I am trying to show that . Once this is establishes, we shall have that which will ensure that . I am unable to do it. I need to use that . How do I do it? Thank you for your time.",\mathcal{B}\subset\mathcal{A} C^* \mathcal{C} \mathcal{A} \mathcal{A} \Phi: \mathcal{A}\to\mathcal{C} \Phi(\mathcal{B})\subsetneq \mathcal{C} I\triangleleft\mathcal{A} \mathcal{A} \mathcal{A} C^* \mathcal{B} \mathcal{C} \mathcal{B}\subsetneq\mathcal{B}+I\subsetneq \mathcal{A} I\triangleleft\mathcal{A} \mathcal{A} I+\mathcal{B} C^* \mathcal{A} \Phi(I)\triangleleft\mathcal{C} \mathcal{C} \mathcal{C} \Phi(I)=0 \Phi(I)=\mathcal{C} \Phi \Phi(I)=\mathcal{C} \Phi(\mathcal{B})\subsetneq \mathcal{C} \mathcal{B}\subsetneq \mathcal{B}+I I\cap\mathcal{C} \mathcal{C} \mathcal{C} I I\cap\mathcal{C}=0 \mathcal{A} \mathcal{B} \mathcal{C} \mathcal{B}+I\subsetneq \mathcal{A} \left(\mathcal{B}+I\right)\cap \mathcal{C}=\mathcal{B}\cap\mathcal{C} \mathcal{B}\cap\mathcal{C}\subset \Phi(\mathcal{B})\subsetneq\mathcal{C} \mathcal{B}+I\subsetneq \mathcal{A} I\cap\mathcal{C}=0,"['functional-analysis', 'operator-theory', 'ideals', 'operator-algebras', 'c-star-algebras']"
82,Brezis' exercise 5.19,Brezis' exercise 5.19,,"I'm trying to solve below exercise in Brezis' Functional Analysis Let $(H, \langle \cdot, \cdot \rangle)$ be a real Hilbert space and $|\cdot|$ its induced norm. Let $u_n, u \in H$ such that $u_n \to u$ in the weak topology $\sigma (H, H^*)$ and that $\limsup_n |u_n| \le |u|$ . Then $u_n \to u$ in norm topology. Could you verify my below attempt? We have $|u_n-u|^2 = |u_n|^2- 2 \langle u_n, u \rangle +|u|^2$ , so $$ \limsup_n |u_n-u|^2 \le \limsup_n  |u_n|^2 -2 \liminf_n \langle u_n, u \rangle + |u|^2. $$ We have $\limsup_n |u_n| \le |u|$ implies $\limsup_n  |u_n|^2 \le |u|^2$ . We have $u_n \to u$ in $\sigma (H, H^*)$ implies $\liminf_n \langle u_n, u \rangle =|u|^2$ . It follows that $$ \limsup_n |u_n-u|^2 \le 0. $$ This completes the proof.","I'm trying to solve below exercise in Brezis' Functional Analysis Let be a real Hilbert space and its induced norm. Let such that in the weak topology and that . Then in norm topology. Could you verify my below attempt? We have , so We have implies . We have in implies . It follows that This completes the proof.","(H, \langle \cdot, \cdot \rangle) |\cdot| u_n, u \in H u_n \to u \sigma (H, H^*) \limsup_n |u_n| \le |u| u_n \to u |u_n-u|^2 = |u_n|^2- 2 \langle u_n, u \rangle +|u|^2 
\limsup_n |u_n-u|^2 \le \limsup_n  |u_n|^2 -2 \liminf_n \langle u_n, u \rangle + |u|^2.
 \limsup_n |u_n| \le |u| \limsup_n  |u_n|^2 \le |u|^2 u_n \to u \sigma (H, H^*) \liminf_n \langle u_n, u \rangle =|u|^2 
\limsup_n |u_n-u|^2 \le 0.
","['functional-analysis', 'hilbert-spaces', 'weak-convergence', 'weak-topology']"
83,"Norm of the adjoint operator of an operator of the form $\int_{0}^{1} k(t,s)f(s)ds$",Norm of the adjoint operator of an operator of the form,"\int_{0}^{1} k(t,s)f(s)ds","I am asked to compute the adjoint of the operator $A: L^2[0,1] \longrightarrow L^2[0,1] $ defined by $$ Af(t)=\int_{t}^{1} t (s-1/2) f(s) ds $$ and then to compute its norm, that is $\lVert A^* \rVert$ . My attempt: For the first part, we have that for all $f,g \in L^2[0,1]$ : \begin{align*} \langle Af,g \rangle&= \int_{0}^{1} Af(t)g(t) dt= \int_{0}^{1} \left(\int_t^1  t (s-1/2) f(s) ds \right) g(t) dt\\ &= \int_{0}^{1} \int_{0}^{s} t (s-1/2) f(s) g(t) dt\, ds= \int_{0}^{1} f(s) \left( \int_{0}^{s} t(s-1/2)g(t)dt \right) ds \end{align*} and therefore $$ A^{*}g(s)= \int_{0}^{s} t(s-1/2)g(t)dt $$ Now, since $A$ is bounded (by $\lVert k \rVert_{2}$ , where $k(t,s)=1_{[t,1]}(s)t(s-1/2) \in L^2([0,1]\times[0,1])$ for example) I know that $\lVert A^* \rVert=\lVert A \rVert$ which led me to trying to compute $\lVert A \rVert$ . One natural candidate for $\lVert A \rVert$ is precisely $\lVert k \rVert_{2}=\frac{\sqrt{7}}{ \sqrt{720} }$ . I tried to find $f \in L^2[0,1]$ such that $\lVert  f \rVert_2=1$ and $\lVert  Af \rVert_2=\lVert  k \rVert_2=1$ but it wasn't such a good idea and consequently my approach is probably wrong. Any help or suggestion? In advance thank you.","I am asked to compute the adjoint of the operator defined by and then to compute its norm, that is . My attempt: For the first part, we have that for all : and therefore Now, since is bounded (by , where for example) I know that which led me to trying to compute . One natural candidate for is precisely . I tried to find such that and but it wasn't such a good idea and consequently my approach is probably wrong. Any help or suggestion? In advance thank you.","A: L^2[0,1] \longrightarrow L^2[0,1]  
Af(t)=\int_{t}^{1} t (s-1/2) f(s) ds
 \lVert A^* \rVert f,g \in L^2[0,1] \begin{align*}
\langle Af,g \rangle&= \int_{0}^{1} Af(t)g(t) dt= \int_{0}^{1} \left(\int_t^1  t (s-1/2) f(s) ds \right) g(t) dt\\
&= \int_{0}^{1} \int_{0}^{s} t (s-1/2) f(s) g(t) dt\, ds= \int_{0}^{1} f(s) \left( \int_{0}^{s} t(s-1/2)g(t)dt \right) ds
\end{align*} 
A^{*}g(s)= \int_{0}^{s} t(s-1/2)g(t)dt
 A \lVert k \rVert_{2} k(t,s)=1_{[t,1]}(s)t(s-1/2) \in L^2([0,1]\times[0,1]) \lVert A^* \rVert=\lVert A \rVert \lVert A \rVert \lVert A \rVert \lVert k \rVert_{2}=\frac{\sqrt{7}}{ \sqrt{720} } f \in L^2[0,1] \lVert  f \rVert_2=1 \lVert  Af \rVert_2=\lVert  k \rVert_2=1","['functional-analysis', 'operator-theory', 'adjoint-operators']"
84,Is the set of linear transformations without unit norm eigenvalues dense?,Is the set of linear transformations without unit norm eigenvalues dense?,,"Let $E$ be a Banach space and $$H_p=\{f\in\mathcal L(E): f(v)=\lambda v\ (v \neq 0)\implies |\lambda|\neq 1\}$$ be the set of linear operators which don't have an eigenvalue with norm $1$ . Is $H_p$ dense in $\mathcal L(E)$ ? This is false if we consider the set of hyperbolic transformations $$H=\{f\in\mathcal L(E):\lambda \in \sigma(f)\implies |\lambda|\neq 1\}$$ as José Alves shows in these lecture notes , on example 5.3. The space $H_p$ feels much bigger than $H$ , plus the proof that the hyperbolic matrices in a finite dimensional space are dense by perturbing the eigenvalues makes me think that this is true.","Let be a Banach space and be the set of linear operators which don't have an eigenvalue with norm . Is dense in ? This is false if we consider the set of hyperbolic transformations as José Alves shows in these lecture notes , on example 5.3. The space feels much bigger than , plus the proof that the hyperbolic matrices in a finite dimensional space are dense by perturbing the eigenvalues makes me think that this is true.",E H_p=\{f\in\mathcal L(E): f(v)=\lambda v\ (v \neq 0)\implies |\lambda|\neq 1\} 1 H_p \mathcal L(E) H=\{f\in\mathcal L(E):\lambda \in \sigma(f)\implies |\lambda|\neq 1\} H_p H,"['functional-analysis', 'spectral-theory']"
85,$\underset{n\rightarrow\infty }{\lim}\Vert \underset{i\geq 0}{\sum }\lambda _{i}^{n}x_{i}\Vert^{\frac{1}{n}}\not=0$ if $\lambda _{i}\not=0$?,if ?,\underset{n\rightarrow\infty }{\lim}\Vert \underset{i\geq 0}{\sum }\lambda _{i}^{n}x_{i}\Vert^{\frac{1}{n}}\not=0 \lambda _{i}\not=0,"Let $H$ be a Hilbert space. Suppose we have a basis $\left( x_{i}\right) _{i\geq 0}$ for $H$ (not necessarily orthonormal) and a sequence $\left( \lambda _{i}\right) _{i\geq 0}$ in $\mathbb{C}$ , such that $\underset{i\geq 0}{\sum }x_{i}$ converges to a non-zero vector, $\underset{% n\rightarrow \infty }{\lim }\lambda _{i}=0$ and $\lambda _{i}\not=0$ for all $i\geq 0$ . Do we have $\underset{n\rightarrow \infty }{\lim }\Vert  \underset{i\geq 0}{\sum }\lambda _{i}^{n}x_{i}\Vert ^{\frac{1}{n}% }\not=0$ ? If not, what additionally condition we should make on $\left( \lambda _{i}\right) _{i\geq 0}$ to have this conclusion. I am not familiar with this type of problem when the basis is not orthogonal, and I think that the answer would be very complex. To be more precise, I am facing this problem for a Riesz operator when $\left( x_{i}\right) _{i\geq 0}$ represents a sequence of eigen vectors and $\left( \lambda _{i}\right) _{i\geq 0}$ a sequence of corresponding non-zero eigen values.","Let be a Hilbert space. Suppose we have a basis for (not necessarily orthonormal) and a sequence in , such that converges to a non-zero vector, and for all . Do we have ? If not, what additionally condition we should make on to have this conclusion. I am not familiar with this type of problem when the basis is not orthogonal, and I think that the answer would be very complex. To be more precise, I am facing this problem for a Riesz operator when represents a sequence of eigen vectors and a sequence of corresponding non-zero eigen values.","H \left( x_{i}\right)
_{i\geq 0} H \left(
\lambda _{i}\right) _{i\geq 0} \mathbb{C} \underset{i\geq 0}{\sum }x_{i} \underset{%
n\rightarrow \infty }{\lim }\lambda _{i}=0 \lambda _{i}\not=0 i\geq 0 \underset{n\rightarrow \infty }{\lim }\Vert 
\underset{i\geq 0}{\sum }\lambda _{i}^{n}x_{i}\Vert ^{\frac{1}{n}%
}\not=0 \left(
\lambda _{i}\right) _{i\geq 0} \left(
x_{i}\right) _{i\geq 0} \left(
\lambda _{i}\right) _{i\geq 0}","['sequences-and-series', 'functional-analysis', 'eigenvalues-eigenvectors', 'hilbert-spaces']"
86,"Weak convergence in $W^{1,2}$ implies strong convergence under extra condition?",Weak convergence in  implies strong convergence under extra condition?,"W^{1,2}","Suppose $U \subset \mathbb{R}^d$ is a smooth bounded domain. Let $(u_n)_{n\geq 1}$ be a sequence in the Sobolev space $W^{1,2}(U)$ such that it weakly converges to zero: $u_n \rightharpoonup 0$ as $n \to \infty$ . Also assume that for any bounded sequence of test functions $$(\phi_n)_{n\geq 1} \subset W^{1,2}_0(U)$$ we have the convergence $$\int_U \nabla u_n(x) \cdot \nabla \phi_n(x) dx \to 0$$ Can I conclude that $\nabla u_n \to 0$ in $L^2(U)$ ? Clearly I cannot take that test function $\phi_n = u_n$ because of the zero boundary condition.",Suppose is a smooth bounded domain. Let be a sequence in the Sobolev space such that it weakly converges to zero: as . Also assume that for any bounded sequence of test functions we have the convergence Can I conclude that in ? Clearly I cannot take that test function because of the zero boundary condition.,"U \subset \mathbb{R}^d (u_n)_{n\geq 1} W^{1,2}(U) u_n \rightharpoonup 0 n \to \infty (\phi_n)_{n\geq 1} \subset W^{1,2}_0(U) \int_U \nabla u_n(x) \cdot \nabla \phi_n(x) dx \to 0 \nabla u_n \to 0 L^2(U) \phi_n = u_n","['functional-analysis', 'sobolev-spaces', 'weak-convergence']"
87,Minkowski's integral inequality for other norms,Minkowski's integral inequality for other norms,,"In my measure theory course we studied norms $L_p$ and no other norms. For proofs we used exclusively the trick known as Hoelder's inequality which works only on $L_p$ norms. I disliked it very much so I found a proof for Minkowski's integral inequality which (slightly longer but) works for all norms that are monotone in this sense: $f\le g\;\;\;\text{a.e.}\;\Rightarrow\;|f|\le|g|\;\;\;\;\;$ (also, $\;\;f=g\;\;\;\text{a.e.}\;\Rightarrow\;|f|=|g|$ ), $\{f_n\}_{n\in\mathbb{N}}\;\;\text{is non-decreasing w.r.t. the relation above}\;\Rightarrow\;\lim|f_n|=|\lim f_n|$ , $\{f_n\}_{n\in\mathbb{N}}\;\;\text{is non-increasing w.r.t. the relation above}\;\;\land\;\;|f_1|<\infty\;\Rightarrow\;\lim|f_n|=|\lim f_n|$ . Unfortunately, I couldn't prove it for all norms, but this was as general as I could imagine a norm be. Then, the total variation norm was substantially different, so I proved that case too: Let $f:[0,1]^2\rightarrow\mathbb{R}$ be a Lipschitz continuous function (it also holds for more general functions, but let's keep it simple). Let $H:\mathbb{R}^{[0,1]}\rightarrow\mathbb{R}$ be the norm that maps (Lipschitz continuous) functions $f\in\mathbb{R}^{[0,1]}$ into $|f(0)|+\text{Var}_f[0,1]$ . Let $f_x:[0,1]\rightarrow\mathbb{R}:y\mapsto f(x,y)$ and let $f^y:[0,1]\rightarrow\mathbb{R}:x\mapsto f(x,y)$ and let $\lambda$ be the Lebesgue measure. Then we have: $$H\bigg(x\mapsto\int f_xd\lambda\bigg)\le\int\Big(y\mapsto H(f^y)\Big)d\lambda.$$ On the other hand, I could not find any norm for which this inequality doesn't hold. The question: Is there any simple norm for which the Minkowski's integral inequality doesn't hold? What is the more precise relationship with the integral operator that the norm has to have in order to satisfy this inequality? ( The ""definition"" of the Minkowski's integral ""inequality"" in case of the general norm is like the one I gave for the total variation norm. )","In my measure theory course we studied norms and no other norms. For proofs we used exclusively the trick known as Hoelder's inequality which works only on norms. I disliked it very much so I found a proof for Minkowski's integral inequality which (slightly longer but) works for all norms that are monotone in this sense: (also, ), , . Unfortunately, I couldn't prove it for all norms, but this was as general as I could imagine a norm be. Then, the total variation norm was substantially different, so I proved that case too: Let be a Lipschitz continuous function (it also holds for more general functions, but let's keep it simple). Let be the norm that maps (Lipschitz continuous) functions into . Let and let and let be the Lebesgue measure. Then we have: On the other hand, I could not find any norm for which this inequality doesn't hold. The question: Is there any simple norm for which the Minkowski's integral inequality doesn't hold? What is the more precise relationship with the integral operator that the norm has to have in order to satisfy this inequality? ( The ""definition"" of the Minkowski's integral ""inequality"" in case of the general norm is like the one I gave for the total variation norm. )","L_p L_p f\le g\;\;\;\text{a.e.}\;\Rightarrow\;|f|\le|g|\;\;\;\;\; \;\;f=g\;\;\;\text{a.e.}\;\Rightarrow\;|f|=|g| \{f_n\}_{n\in\mathbb{N}}\;\;\text{is non-decreasing w.r.t. the relation above}\;\Rightarrow\;\lim|f_n|=|\lim f_n| \{f_n\}_{n\in\mathbb{N}}\;\;\text{is non-increasing w.r.t. the relation above}\;\;\land\;\;|f_1|<\infty\;\Rightarrow\;\lim|f_n|=|\lim f_n| f:[0,1]^2\rightarrow\mathbb{R} H:\mathbb{R}^{[0,1]}\rightarrow\mathbb{R} f\in\mathbb{R}^{[0,1]} |f(0)|+\text{Var}_f[0,1] f_x:[0,1]\rightarrow\mathbb{R}:y\mapsto f(x,y) f^y:[0,1]\rightarrow\mathbb{R}:x\mapsto f(x,y) \lambda H\bigg(x\mapsto\int f_xd\lambda\bigg)\le\int\Big(y\mapsto H(f^y)\Big)d\lambda.","['functional-analysis', 'measure-theory', 'integral-inequality']"
88,Proof verification that the Hahn Banach theorem equivalent to existence of a finitely additive measure for boolean algebra over ZF,Proof verification that the Hahn Banach theorem equivalent to existence of a finitely additive measure for boolean algebra over ZF,,"Exercise 2.6.19 of Jech's Axiom of choice asks to show that the Hahn Banach theorem is equivalent to the existence of a real valued measure for all Boolean algebras over $ZF$ . This is a sketch at my attempt: Assuming the Hahn Banach theorem holds. And let $B$ be a boolean algebra, without choice we have that there is some set $S$ and a subalgebra $P\subseteq \mathcal{P}(S)$ such that there is a surjective homomorphism $h:P\rightarrow B$ . Consider the space $\ell^\infty(S)$ then I have that $g:\mathcal{P}(S)\rightarrow \ell^\infty(S)$ where each set is sent to its characteristic function. We can consider the subspace generated by $E=\text{span}(g(P))$ and it's subspace $H=\text{span}(g(\text{ker}(h)))$ Then we have a space $E/H$ which is a vector space and there is an inclusion of $B$ in $E/H$ . Consider the map that sends $1+H$ (the quotient class of the constant 1) to $1\in \mathbb{R}$ then by Hahn Banach it is extended to all of $E/H$ . We need to assure that the function it extends to is a measure so we need the image of $B$ to be sent to $[0,1]$ to this end I define $p(f)$ to be $0$ if $f\in -\text{span}(B)$ and $p(f)=\|f\|_{\infty,E/H}$ otherwise. This function is subadditive and any extension that is dominated by $p$ will induce a finitely additive measure on $B$ . As for the other direction we have that over $ZF$ the Hahn Banach theorem is equivalent to showing every Banach space has a non $0$ functional. I believe every Banach space can be embedded in some $L^\infty(X,\mathcal{A},\mu)$ . The dual of $L^\infty(X,\mathcal{A},\mu)$ is the set of finitely additive signed measures on $\mathcal{A}$ that are absolutely continuous with respect to $\mu$ but by assumption $\mathcal{A}/null(\mu)$ is a Boolean algebra and it will have a finitely additive measure which is non trivial. Is this correct? Edit: The second part is not correct since the embedding into $L^\infty $ requires Hahn Banach from what I recall Edit: I actually managed to find a proof out there which is different than mine. I will add it to this question for completeness. Let $B$ be a boolean algebra and consider the meet semilattice of the partitions of $B$ where $Q\leq P$ if $Q$ refines $P$ . Observe that a function $f:P\rightarrow \mathbb{R}$ can be extended to $f_Q:Q\rightarrow \mathbb{R}$ naturaly by setting $f_Q(q)=f(p)$ where $p\in P$ is the unique element such that $q\leq p$ . We define $S(B)=\{f:P\rightarrow \mathbb{R}: P \text{ is a partition of } B\}/\sim$ where $\sim$ is the relation where given $f:P\rightarrow \mathbb{R}$ and $g:Q\rightarrow \mathbb{R}$ we set $f\sim g$ iff $f_{Q\wedge P}=g_{Q\wedge P}$ . This has a natural structure as a vector space. We can endow $S(B)$ with the upper limit norm or $\|f\|=\sup_{p\in P}f(p)$ which is easy to verify is well defined on the equivalence classes. We can identify $b\in B$ to the function $f:\{b,b^c\}\rightarrow \mathbb{R}$ where $f(b)=1$ and $f(b^c)=0$ . We see that a finitely additive measure $m$ on $A\subseteq B$ will define on $E=\{f\in S(B): \text{dom}(f)\subseteq A \}$ (to be more precise the classes that have a representative with domain contained in $A$ ) we define $\varphi:E\rightarrow \mathbb{R}$ to be the function $\varphi(f)=\sum_{p\in \text{dom}(f)}f(p)m(p)$ since $m$ is finitely additive it is easy to verify that its well defined on the equivalence classes. We can extend such a function to all of $S(B)$ by Hahn Banach so that it is still of norm $1$ and it will define on $B\subseteq S(B)$ a finitely additive measure. Source: ""EL TEOREMA DE HAHN-BANACH COMO PRINCIPIO DE ELECCIÓN"" by Xavier Caicedo & Germán Enciso","Exercise 2.6.19 of Jech's Axiom of choice asks to show that the Hahn Banach theorem is equivalent to the existence of a real valued measure for all Boolean algebras over . This is a sketch at my attempt: Assuming the Hahn Banach theorem holds. And let be a boolean algebra, without choice we have that there is some set and a subalgebra such that there is a surjective homomorphism . Consider the space then I have that where each set is sent to its characteristic function. We can consider the subspace generated by and it's subspace Then we have a space which is a vector space and there is an inclusion of in . Consider the map that sends (the quotient class of the constant 1) to then by Hahn Banach it is extended to all of . We need to assure that the function it extends to is a measure so we need the image of to be sent to to this end I define to be if and otherwise. This function is subadditive and any extension that is dominated by will induce a finitely additive measure on . As for the other direction we have that over the Hahn Banach theorem is equivalent to showing every Banach space has a non functional. I believe every Banach space can be embedded in some . The dual of is the set of finitely additive signed measures on that are absolutely continuous with respect to but by assumption is a Boolean algebra and it will have a finitely additive measure which is non trivial. Is this correct? Edit: The second part is not correct since the embedding into requires Hahn Banach from what I recall Edit: I actually managed to find a proof out there which is different than mine. I will add it to this question for completeness. Let be a boolean algebra and consider the meet semilattice of the partitions of where if refines . Observe that a function can be extended to naturaly by setting where is the unique element such that . We define where is the relation where given and we set iff . This has a natural structure as a vector space. We can endow with the upper limit norm or which is easy to verify is well defined on the equivalence classes. We can identify to the function where and . We see that a finitely additive measure on will define on (to be more precise the classes that have a representative with domain contained in ) we define to be the function since is finitely additive it is easy to verify that its well defined on the equivalence classes. We can extend such a function to all of by Hahn Banach so that it is still of norm and it will define on a finitely additive measure. Source: ""EL TEOREMA DE HAHN-BANACH COMO PRINCIPIO DE ELECCIÓN"" by Xavier Caicedo & Germán Enciso","ZF B S P\subseteq \mathcal{P}(S) h:P\rightarrow B \ell^\infty(S) g:\mathcal{P}(S)\rightarrow \ell^\infty(S) E=\text{span}(g(P)) H=\text{span}(g(\text{ker}(h))) E/H B E/H 1+H 1\in \mathbb{R} E/H B [0,1] p(f) 0 f\in -\text{span}(B) p(f)=\|f\|_{\infty,E/H} p B ZF 0 L^\infty(X,\mathcal{A},\mu) L^\infty(X,\mathcal{A},\mu) \mathcal{A} \mu \mathcal{A}/null(\mu) L^\infty  B B Q\leq P Q P f:P\rightarrow \mathbb{R} f_Q:Q\rightarrow \mathbb{R} f_Q(q)=f(p) p\in P q\leq p S(B)=\{f:P\rightarrow \mathbb{R}: P \text{ is a partition of } B\}/\sim \sim f:P\rightarrow \mathbb{R} g:Q\rightarrow \mathbb{R} f\sim g f_{Q\wedge P}=g_{Q\wedge P} S(B) \|f\|=\sup_{p\in P}f(p) b\in B f:\{b,b^c\}\rightarrow \mathbb{R} f(b)=1 f(b^c)=0 m A\subseteq B E=\{f\in S(B): \text{dom}(f)\subseteq A
\} A \varphi:E\rightarrow \mathbb{R} \varphi(f)=\sum_{p\in \text{dom}(f)}f(p)m(p) m S(B) 1 B\subseteq S(B)","['functional-analysis', 'solution-verification', 'axiom-of-choice', 'hahn-banach-theorem']"
89,"If $X$ is normed space, $V \subset X$ is closed, and $W \subset X$ is finite-dimensional with $V \cap W = \{0\}$, then $\pi(V) \subset X/W$ is closed","If  is normed space,  is closed, and  is finite-dimensional with , then  is closed",X V \subset X W \subset X V \cap W = \{0\} \pi(V) \subset X/W,"Let $X$ be a normed space, let $V \subset X$ be a closed subspace, and let $W \subset X$ be a finite-dimensional subspace with $V \cap W = \{0\}$ . I would like to show that $\pi(V) \subset X/W$ is closed, where $\pi : X \to X/W$ is the quotient map. I was able to show with a proof by contradiction that there is some $C > 0$ such that $$\forall x \in V, \forall y \in W : \|x \| + \|y\| \leq C \|x - y\|. $$ But I don't see how to use the above norm estimate to show that $\pi(V)$ is closed. The estimate above implies that $$\forall x \in V : \|\pi(x)\|_{X/W} \geq \frac{1}{C}\|x\|, $$ and with the additional fact that $\pi$ is bounded, we have $$\forall x \in V: \frac{1}{C}\|x\| \leq \|\pi(x)\|_{X/W} \leq \|x\|, $$ but I cannot conclude that $\pi(V)$ is closed without knowing that $V$ is complete, which a priori is not.","Let be a normed space, let be a closed subspace, and let be a finite-dimensional subspace with . I would like to show that is closed, where is the quotient map. I was able to show with a proof by contradiction that there is some such that But I don't see how to use the above norm estimate to show that is closed. The estimate above implies that and with the additional fact that is bounded, we have but I cannot conclude that is closed without knowing that is complete, which a priori is not.","X V \subset X W \subset X V \cap W = \{0\} \pi(V) \subset X/W \pi : X \to X/W C > 0 \forall x \in V, \forall y \in W : \|x \| + \|y\| \leq C \|x - y\|.  \pi(V) \forall x \in V : \|\pi(x)\|_{X/W} \geq \frac{1}{C}\|x\|,  \pi \forall x \in V: \frac{1}{C}\|x\| \leq \|\pi(x)\|_{X/W} \leq \|x\|,  \pi(V) V",['functional-analysis']
90,Finding radius of convergence on a Banach space,Finding radius of convergence on a Banach space,,"Let $(\phi_m)$ be the sequence of coordinate functionals on $\ell^p$ where $1\leq p <\infty.$ Then the power series $\sum_{m=0}^\infty (\phi_m(x))^m$ is absolutely convergent for any $x\in\ell^p$ but the radius of convergence is $1$ . Here, the definition of power series is : A power series from the Banach space $X$ to $\mathbb C$ is a series of the form $\sum_{m=0}^\infty P_m(x-a)$ where $(P_m)$ is a sequence of polynomials from $X^m$ to $\mathbb C$ . Radius of convergence for this series is defined as $R=\frac{1}{\limsup_{m \to\infty}\|P_m\|^{1/m}}$ by the Cauchy-Hadamard formula. I also have the following lemma : Let $X$ be a Banach space and $\phi \in X^*$ with $\|\phi\|=1$ . Then $P:=\phi^m$ is a polynomial from $X^m$ to $\mathbb C$ with $\|P\|=1$ . Absolute convergence is ok. I am trying to see that it is a power series (please note that it is not a classical power series, I added my definition above) and also state its radius of convergence. My thoughts : Since coordinate functionals are linear and continuous, we have $(\phi_m)\subset {\ell^p}^*$ . Also, I showed $\|\phi_m\|=1$ for each $m$ . Then by the previous lemma each $P_m:=\phi_m^m$ is a polynomial from ${(\ell^p)}^m$ to $\mathbb C$ and $\|P_m\|=1$ . Hence, given series is a power series and by the Cauchy-Hadamard formula, its radius of convergence is $R=\frac{1}{\limsup_{m \to\infty}\|P_m\|^{1/m}}=\frac{1}{\limsup_{m \to\infty}1^{1/m}}=1$ . I am not sure about whether my thoughts are true. I appreciate any correction or suggestion. Thank you and merry xmas Edit : Definition of a polynomial from $X$ to $\mathbb C$ : A mapping $P:X\to\mathbb C$ is a polynomial if there exists a multi-linear map from $X^m$ to $\mathbb C$ such that $P(x)=Ax^m$ for every $x\in X$ . ( $x^m$ is a notation here, it means that $x^m=(x,x,\dots, x)$ -m times $x$ )","Let be the sequence of coordinate functionals on where Then the power series is absolutely convergent for any but the radius of convergence is . Here, the definition of power series is : A power series from the Banach space to is a series of the form where is a sequence of polynomials from to . Radius of convergence for this series is defined as by the Cauchy-Hadamard formula. I also have the following lemma : Let be a Banach space and with . Then is a polynomial from to with . Absolute convergence is ok. I am trying to see that it is a power series (please note that it is not a classical power series, I added my definition above) and also state its radius of convergence. My thoughts : Since coordinate functionals are linear and continuous, we have . Also, I showed for each . Then by the previous lemma each is a polynomial from to and . Hence, given series is a power series and by the Cauchy-Hadamard formula, its radius of convergence is . I am not sure about whether my thoughts are true. I appreciate any correction or suggestion. Thank you and merry xmas Edit : Definition of a polynomial from to : A mapping is a polynomial if there exists a multi-linear map from to such that for every . ( is a notation here, it means that -m times )","(\phi_m) \ell^p 1\leq p <\infty. \sum_{m=0}^\infty (\phi_m(x))^m x\in\ell^p 1 X \mathbb C \sum_{m=0}^\infty P_m(x-a) (P_m) X^m \mathbb C R=\frac{1}{\limsup_{m \to\infty}\|P_m\|^{1/m}} X \phi \in X^* \|\phi\|=1 P:=\phi^m X^m \mathbb C \|P\|=1 (\phi_m)\subset {\ell^p}^* \|\phi_m\|=1 m P_m:=\phi_m^m {(\ell^p)}^m \mathbb C \|P_m\|=1 R=\frac{1}{\limsup_{m \to\infty}\|P_m\|^{1/m}}=\frac{1}{\limsup_{m \to\infty}1^{1/m}}=1 X \mathbb C P:X\to\mathbb C X^m \mathbb C P(x)=Ax^m x\in X x^m x^m=(x,x,\dots, x) x","['complex-analysis', 'functional-analysis', 'solution-verification', 'power-series', 'banach-spaces']"
91,C* algebras with no nilpotent elements are commutative,C* algebras with no nilpotent elements are commutative,,I am currently following my first course in operator algebras and I heard my teacher say that a C* algebra is commutative if and only its only nilpotent element is zero. The first implication is obvious but I really cant figure out the second one. Thanks for any help!,I am currently following my first course in operator algebras and I heard my teacher say that a C* algebra is commutative if and only its only nilpotent element is zero. The first implication is obvious but I really cant figure out the second one. Thanks for any help!,,"['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras']"
92,"If $X$ is infinite-dimensional normed vector space, then $\mathcal C_c(X) = \{0\}$","If  is infinite-dimensional normed vector space, then",X \mathcal C_c(X) = \{0\},"Let $(X, |\cdot|)$ be a normed vector space. For $f:X \to \mathbb R$ , the support of $f$ is defined as the closure of $\{x \in X : f(x) \neq 0\}$ . Let $\mathcal C_c(X)$ be the space of all real-valued continuous functions on $X$ with compact supports. Theorem If $X$ is infinite-dimensional, then $\mathcal C_c(X) = \{0\}$ . I'm trying to prove this well-known result. Could you have a check on my attempt? My attempt: Fix $f \in \mathcal C_b(X)$ . If $\{x \in X : f(x) \neq 0\} = \emptyset$ then we are done. Assume the contrary that there is $a \in X$ such that $f(a) \neq 0$ . By continuity of $f$ , there is an open ball $B(a, r)$ centered at $a$ with radius $r>0$ such that $f(x) \neq 0$ for all $x \in B(a, r)$ . We have $\overline{B(a, r)} \subset \operatorname{supp} f$ , so $\overline{B(a, r)}$ is compact. Lemma Let $(X, |\cdot|)$ be a normed vectpr space and $B:= \{x \in X \mid |x|\le1\}$ the closed unit ball. Then $B$ is compact if and only if $X$ is finite-dimensional. Notice that the closed unit ball $B$ is homeomorphic to a closed subset of $\overline{B(a, r)}$ , so $B$ is compact. By our Lemma , $X$ is finite-dimensional, which is a contradiction. This completes the proof.","Let be a normed vector space. For , the support of is defined as the closure of . Let be the space of all real-valued continuous functions on with compact supports. Theorem If is infinite-dimensional, then . I'm trying to prove this well-known result. Could you have a check on my attempt? My attempt: Fix . If then we are done. Assume the contrary that there is such that . By continuity of , there is an open ball centered at with radius such that for all . We have , so is compact. Lemma Let be a normed vectpr space and the closed unit ball. Then is compact if and only if is finite-dimensional. Notice that the closed unit ball is homeomorphic to a closed subset of , so is compact. By our Lemma , is finite-dimensional, which is a contradiction. This completes the proof.","(X, |\cdot|) f:X \to \mathbb R f \{x \in X : f(x) \neq 0\} \mathcal C_c(X) X X \mathcal C_c(X) = \{0\} f \in \mathcal C_b(X) \{x \in X : f(x) \neq 0\} = \emptyset a \in X f(a) \neq 0 f B(a, r) a r>0 f(x) \neq 0 x \in B(a, r) \overline{B(a, r)} \subset \operatorname{supp} f \overline{B(a, r)} (X, |\cdot|) B:= \{x \in X \mid |x|\le1\} B X B \overline{B(a, r)} B X","['functional-analysis', 'normed-spaces']"
93,When is a sequentially closed subspace the kernel of a sequentially continuous linear functional?,When is a sequentially closed subspace the kernel of a sequentially continuous linear functional?,,"Let $E$ be a Banach space with continuous dual $E'$ , endowed with the weak $^*$ topology. Let $V\subseteq E'$ be a (weak $^*$ -)dense subspace of $E'$ . If $V$ is also sequentially closed (with respect to the weak $^*$ topology on $E'$ ), does there exist a weak $^*$ sequentially continuous linear functional $\phi:E'\longrightarrow\mathbb{R}$ , such that $\textsf{ker}(\phi)=V$ ?","Let be a Banach space with continuous dual , endowed with the weak topology. Let be a (weak -)dense subspace of . If is also sequentially closed (with respect to the weak topology on ), does there exist a weak sequentially continuous linear functional , such that ?",E E' ^* V\subseteq E' ^* E' V ^* E' ^* \phi:E'\longrightarrow\mathbb{R} \textsf{ker}(\phi)=V,"['functional-analysis', 'continuity', 'banach-spaces', 'weak-topology']"
94,Writing a formal proof about infimum and supremum,Writing a formal proof about infimum and supremum,,"Let the function $\Phi : [0,\infty) \rightarrow [0,\infty)$ be a convex bijection, $$ \|f\|_{L^{\Phi}}:=\inf\left\{\lambda>0:\int_{\mathbb{R}^n}\Phi\Big(\frac{|f(x)|}{\lambda}\Big)dx\leq 1\right\}, $$ and $$ \Vert f\Vert_{WL^{\Phi}}:=\inf\left\{\lambda>0\ :\ \sup_{t>0}\Phi(t)|\{x\in\mathbb{R}^n: \frac{|f(x)|}{\lambda}>t\}|\ \leq 1\right\}. $$ I want to show that $$ \Vert f\Vert_{WL^{\Phi}}=\sup_{t>0}\|t\chi_{\{|f|>t\}}\|_{L^{\Phi}}, $$ where $\chi$ denotes the characteristic function. My attempt: First note that $$ \Vert f\Vert_{WL^{\Phi}}=\inf\left\{\lambda>0\ :\ \sup_{t>0}\Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1\right\}=:\inf B. $$ If we write $\sup_{t>0}\|t\chi_{\{|f|>t\}}\|_{L^{\Phi}}$ explicitly, we get $$ \sup_{t>0}\|t\chi_{\{|f|>t\}}\|_{L^{\Phi}}=\sup_{t>0}\inf\left\{\lambda>0:\Phi\Big(\frac{t}{\lambda}\Big)\int_{\{x\in\mathbb{R}^n: |f(x)|>t\}}dx\leq 1\right\}=:\sup_{t>0}\inf A_t. $$ If $\lambda\in B$ then $\sup_{t>0}\Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1$ . Therefore $\Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1,\, \forall t>0$ which means $\lambda \in A_t$ for all $t>0$ . Hence $B\subset A_t,\, \forall t>0$ and this imply $\inf B\geq \inf A_t,\, \forall t>0$ and consequently $\inf B\geq \sup_{t>0}\inf A_t$ . Now let $t$ be fixed and $\lambda \in A_t$ . Then $\Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1$ . I think that i can not write $\sup_{t>0}\Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1$ since $t$ is not arbitrary? Am i right? How can i continue? I am very confused.","Let the function be a convex bijection, and I want to show that where denotes the characteristic function. My attempt: First note that If we write explicitly, we get If then . Therefore which means for all . Hence and this imply and consequently . Now let be fixed and . Then . I think that i can not write since is not arbitrary? Am i right? How can i continue? I am very confused.","\Phi : [0,\infty) \rightarrow [0,\infty) 
\|f\|_{L^{\Phi}}:=\inf\left\{\lambda>0:\int_{\mathbb{R}^n}\Phi\Big(\frac{|f(x)|}{\lambda}\Big)dx\leq 1\right\},
 
\Vert f\Vert_{WL^{\Phi}}:=\inf\left\{\lambda>0\ :\ \sup_{t>0}\Phi(t)|\{x\in\mathbb{R}^n: \frac{|f(x)|}{\lambda}>t\}|\ \leq 1\right\}.
 
\Vert f\Vert_{WL^{\Phi}}=\sup_{t>0}\|t\chi_{\{|f|>t\}}\|_{L^{\Phi}},
 \chi 
\Vert f\Vert_{WL^{\Phi}}=\inf\left\{\lambda>0\ :\ \sup_{t>0}\Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1\right\}=:\inf B.
 \sup_{t>0}\|t\chi_{\{|f|>t\}}\|_{L^{\Phi}} 
\sup_{t>0}\|t\chi_{\{|f|>t\}}\|_{L^{\Phi}}=\sup_{t>0}\inf\left\{\lambda>0:\Phi\Big(\frac{t}{\lambda}\Big)\int_{\{x\in\mathbb{R}^n: |f(x)|>t\}}dx\leq 1\right\}=:\sup_{t>0}\inf A_t.
 \lambda\in B \sup_{t>0}\Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1 \Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1,\, \forall t>0 \lambda \in A_t t>0 B\subset A_t,\, \forall t>0 \inf B\geq \inf A_t,\, \forall t>0 \inf B\geq \sup_{t>0}\inf A_t t \lambda \in A_t \Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1 \sup_{t>0}\Phi(\frac{t}{\lambda})|\{x\in\mathbb{R}^n: |f(x)|>t\}|\ \leq 1 t","['real-analysis', 'calculus', 'functional-analysis', 'supremum-and-infimum']"
95,Continuous functional calculus of multiplication operator,Continuous functional calculus of multiplication operator,,"Let $A$ be an unbounded operator on $L^2(\mathbb{R}^d)$ unitarily equivalent to a multiplication operator $UAU^*= B $ . One thus has $$UAU^*f(x) = B(x)f(x)$$ for a suitable subset of $L^2(\mathbb{R}^d)$ . Now, one may define functions of $A$ via the functional calculus. I am interested in continuous $f$ . My question is the following: Can one conclude that $Uf(A)U^*$ is again a multiplication operator acting like $$Uf(A)U^* g(x) = f(B(x))g(x) \text{?}$$ I think it's easy to show for polynomials. Unfortunately, I don't see how I can extend this to general (possibly unbounded over $\mathbb{R}^d$ ) continuous $f$ , since the $L^2$ space is over $\mathbb{R}^d$ and I dont know how to do an approximation result here. Is approximation the wrong approach? I saw something about uniqueness of spectral measures on polynomials ( Absolutely continuous spectrum invariant under unitary equivalence ), but I don't understand the argument. Other questions I found were only dealing with bounded $f$ . Edit: I think one possibility is the following: One can restrict $g \in L^2$ with compact support. For such $g$ the equality also holds, especially for an arbitrary continuous $f$ . Then, use the denseness of such functions to show equality in the Operatornorm. That's it. I will post a full argument tomorrow.","Let be an unbounded operator on unitarily equivalent to a multiplication operator . One thus has for a suitable subset of . Now, one may define functions of via the functional calculus. I am interested in continuous . My question is the following: Can one conclude that is again a multiplication operator acting like I think it's easy to show for polynomials. Unfortunately, I don't see how I can extend this to general (possibly unbounded over ) continuous , since the space is over and I dont know how to do an approximation result here. Is approximation the wrong approach? I saw something about uniqueness of spectral measures on polynomials ( Absolutely continuous spectrum invariant under unitary equivalence ), but I don't understand the argument. Other questions I found were only dealing with bounded . Edit: I think one possibility is the following: One can restrict with compact support. For such the equality also holds, especially for an arbitrary continuous . Then, use the denseness of such functions to show equality in the Operatornorm. That's it. I will post a full argument tomorrow.",A L^2(\mathbb{R}^d) UAU^*= B  UAU^*f(x) = B(x)f(x) L^2(\mathbb{R}^d) A f Uf(A)U^* Uf(A)U^* g(x) = f(B(x))g(x) \text{?} \mathbb{R}^d f L^2 \mathbb{R}^d f g \in L^2 g f,"['functional-analysis', 'spectral-theory', 'functional-calculus']"
96,Direct sum of two Hilbert spaces is a inner product.,Direct sum of two Hilbert spaces is a inner product.,,"Today I am working with Functional Analysis regarding Hilbert Spaces from the notes. Let $H_1$ and $H_2$ be Hilbert Spaces. The direct sum $H_1\oplus H_2$ is the vector spaces $H_1\times H_2$ with the following inner product, $$\langle (x,y)|(x',y')\rangle:=\langle x|x' \rangle_{H_1}+\langle y|y' \rangle_{H_2} ,$$ where $(x,y),(x',y')\in H_1\times H_2 $ . Well I know the definition of an inner product, i.e. linearity, symmetry, and positive definiteness however I cannot see how to do it with this direct sum. Anyone who can give me a hint or maybe show one of them and then I can try to work the rest out. Thanks in advance. Notice this is NOT homework. It is just me that wants to convince myself that this is a inner product. Edit: I've shown that this indeed defines an inner product. How about norm? Is it true that the norm of $H_1\oplus H_2$ is $ \|\langle x,x'\rangle,\langle y,y'\rangle\|=(\|\langle  x,x' \rangle\|^2+\|\langle y,y' \rangle\|^2)^\frac{1}{2}$","Today I am working with Functional Analysis regarding Hilbert Spaces from the notes. Let and be Hilbert Spaces. The direct sum is the vector spaces with the following inner product, where . Well I know the definition of an inner product, i.e. linearity, symmetry, and positive definiteness however I cannot see how to do it with this direct sum. Anyone who can give me a hint or maybe show one of them and then I can try to work the rest out. Thanks in advance. Notice this is NOT homework. It is just me that wants to convince myself that this is a inner product. Edit: I've shown that this indeed defines an inner product. How about norm? Is it true that the norm of is","H_1 H_2 H_1\oplus H_2 H_1\times H_2 \langle (x,y)|(x',y')\rangle:=\langle x|x' \rangle_{H_1}+\langle y|y' \rangle_{H_2} , (x,y),(x',y')\in H_1\times H_2  H_1\oplus H_2  \|\langle x,x'\rangle,\langle y,y'\rangle\|=(\|\langle  x,x' \rangle\|^2+\|\langle y,y' \rangle\|^2)^\frac{1}{2}","['functional-analysis', 'hilbert-spaces', 'operator-algebras', 'direct-sum']"
97,"""Entanglement"" of continuous functions via Mercer's theorem","""Entanglement"" of continuous functions via Mercer's theorem",,"In quantum mechanics, the Schmidt decomposition of a vector $\vert \psi\rangle \in \mathbb{C}^n\otimes \mathbb{C}^m$ is $$ \vert \psi\rangle = \sum_{i=1}^{\min\{n,m\}} \lambda_i \vert e_i\rangle \otimes \vert f_i\rangle$$ where $\{\vert e_i\rangle\}$ are an orthonormal set of vectors in $\mathbb{C}^n$ , $\{\vert f_i\rangle\}$ are orthonormal in $\mathbb{C}^m$ , and each $\lambda_i\geq 0$ Mercer's theorem states that for a continuous symmetric non-negative function $K:[a,b]\times [a,b]\rightarrow \mathbb{R}$ , there is a sequence of functions $\{e_i\in L^2[a,b]\}_i$ and non-negative eigenvalues $\lambda_i$ such that $$ K(s,t) = \sum_{i=1}^\infty \lambda_i e_i(s)e_i(t)$$ These look so similar, and the proofs seem to be identical if you use the right measure on $\mathbb{C}^n$ . In quantum mechanics, entanglement is important and the coefficients in the Schmidt decomposition quantify it: an unentangled state has only one non-zero $\lambda_i$ , and we can even define ""entanglement entropy"" as the entropy of $\{\lambda_i^2\}$ (which adds up to $1$ if we start with a unit vector). Is there a similar notion of ""entanglement"" for continuous functions? If only one $\lambda_i$ is non-zero, it splits in a sense, but I'm wondering if this concept has a name and some applications or theory.","In quantum mechanics, the Schmidt decomposition of a vector is where are an orthonormal set of vectors in , are orthonormal in , and each Mercer's theorem states that for a continuous symmetric non-negative function , there is a sequence of functions and non-negative eigenvalues such that These look so similar, and the proofs seem to be identical if you use the right measure on . In quantum mechanics, entanglement is important and the coefficients in the Schmidt decomposition quantify it: an unentangled state has only one non-zero , and we can even define ""entanglement entropy"" as the entropy of (which adds up to if we start with a unit vector). Is there a similar notion of ""entanglement"" for continuous functions? If only one is non-zero, it splits in a sense, but I'm wondering if this concept has a name and some applications or theory.","\vert \psi\rangle \in \mathbb{C}^n\otimes \mathbb{C}^m  \vert \psi\rangle = \sum_{i=1}^{\min\{n,m\}} \lambda_i \vert e_i\rangle \otimes \vert f_i\rangle \{\vert e_i\rangle\} \mathbb{C}^n \{\vert f_i\rangle\} \mathbb{C}^m \lambda_i\geq 0 K:[a,b]\times [a,b]\rightarrow \mathbb{R} \{e_i\in L^2[a,b]\}_i \lambda_i  K(s,t) = \sum_{i=1}^\infty \lambda_i e_i(s)e_i(t) \mathbb{C}^n \lambda_i \{\lambda_i^2\} 1 \lambda_i","['functional-analysis', 'quantum-information', 'reproducing-kernel-hilbert-spaces']"
98,A series of questions on the subspace generated in a Hilbert space.,A series of questions on the subspace generated in a Hilbert space.,,"Let $H$ be a Hilbert space. Note. Where it is not subject to definition with the overline we indicate the closure of the set. Claim 1. Prove that the set $$\overline{\text{sp}}(A):=\bigcap\left\{M\;|\; M\;\text{is closed subspace such that}\; M\supseteq A\right\}$$ is a closed subspace of $H$ . proof. Clearly $0\in \overline{\text{sp}}(A)$ . Let $x,y\in \overline{\text{sp}}(A)$ and $\alpha.\beta\in \mathbb{R}$ , then $x$ and $y$ are in all closed subspaces $M$ that contain $A$ and therefore $\alpha x+\beta y\in \overline{\text{sp}}(A)$ . It remains to show that $\overline{\text{sp}}(A)$ is closed. Let $\{x_n\}\subseteq \overline{\text{sp}}(A)$ a sequence such that $x_n\to x$ . Since $\{x_n\}$ is, in particular, a sequence in every closed subspace $M$ that contains $A$ , results that $x$ is in every closed subspace $M$ that contain $A$ and so $x\in \overline{\text{sp}}(A)$ . Claim 2. Let $A\subseteq H$ be a set we denote with $\text{sp}(A)$ the subspace generated by $A$ : $$\text{sp}(A)=\left\{\sum_{k=1}^nc_kx_k\;|\; n\ge 1, c_k\in\mathbb{R}, x_k\in A\right\}.$$ I must prove that $$\overline{\text{sp}}(A)=\overline{\text{sp}(A)}$$ proof. Since $\overline{\text{sp}(A)}$ is a closed subspace that contains $A$ , from definition of $\overline{\text{sp}}(A)$ we deduce that $\overline{\text{sp}}(A)\subseteq\overline{\text{sp}(A)}$ . Let now $M$ a closed subspace such that $M\supseteq A$ , since $M$ is closed with respect sum and product result that $\text{sp}(A)\subseteq M$ , therefore $$\text{sp}(A)\subseteq M,\quad\text{for all closed subspace}; M\supseteq A,$$ from which it is deduced that $\text{sp}(A)\subseteq \overline{\text{sp}}(A)$ , so using the claim $1$ we have that $\overline{\text{sp}(A)}\subseteq \overline{\text{sp}}(A)$ . Claim 3. Let $L$ a subspace of $H$ , we prove that $$\overline{L}=\overline{\text{sp}}(L)$$ proof. Since $\overline{L}$ is a closed subspace that contains $L$ , from definition we have that $\overline{\text{sp}}(L)\subseteq \overline{L}$ . On the other hand, $L\subseteq \text{sp}(L)$ and therefore using the claim $2$ we have $\overline{L}\subseteq \overline{\text{sp}(L)}=\overline{\text{sp}}(L)$ . Question. Are the proposed proofs correct?","Let be a Hilbert space. Note. Where it is not subject to definition with the overline we indicate the closure of the set. Claim 1. Prove that the set is a closed subspace of . proof. Clearly . Let and , then and are in all closed subspaces that contain and therefore . It remains to show that is closed. Let a sequence such that . Since is, in particular, a sequence in every closed subspace that contains , results that is in every closed subspace that contain and so . Claim 2. Let be a set we denote with the subspace generated by : I must prove that proof. Since is a closed subspace that contains , from definition of we deduce that . Let now a closed subspace such that , since is closed with respect sum and product result that , therefore from which it is deduced that , so using the claim we have that . Claim 3. Let a subspace of , we prove that proof. Since is a closed subspace that contains , from definition we have that . On the other hand, and therefore using the claim we have . Question. Are the proposed proofs correct?","H \overline{\text{sp}}(A):=\bigcap\left\{M\;|\; M\;\text{is closed subspace such that}\; M\supseteq A\right\} H 0\in \overline{\text{sp}}(A) x,y\in \overline{\text{sp}}(A) \alpha.\beta\in \mathbb{R} x y M A \alpha x+\beta y\in \overline{\text{sp}}(A) \overline{\text{sp}}(A) \{x_n\}\subseteq \overline{\text{sp}}(A) x_n\to x \{x_n\} M A x M A x\in \overline{\text{sp}}(A) A\subseteq H \text{sp}(A) A \text{sp}(A)=\left\{\sum_{k=1}^nc_kx_k\;|\; n\ge 1, c_k\in\mathbb{R}, x_k\in A\right\}. \overline{\text{sp}}(A)=\overline{\text{sp}(A)} \overline{\text{sp}(A)} A \overline{\text{sp}}(A) \overline{\text{sp}}(A)\subseteq\overline{\text{sp}(A)} M M\supseteq A M \text{sp}(A)\subseteq M \text{sp}(A)\subseteq M,\quad\text{for all closed subspace}; M\supseteq A, \text{sp}(A)\subseteq \overline{\text{sp}}(A) 1 \overline{\text{sp}(A)}\subseteq \overline{\text{sp}}(A) L H \overline{L}=\overline{\text{sp}}(L) \overline{L} L \overline{\text{sp}}(L)\subseteq \overline{L} L\subseteq \text{sp}(L) 2 \overline{L}\subseteq \overline{\text{sp}(L)}=\overline{\text{sp}}(L)","['real-analysis', 'functional-analysis', 'solution-verification', 'hilbert-spaces']"
99,"Can the fact ""If $\phi$ is a Hermitian linear functional on a $C^*$-algebra $A$ then $||\phi|| = \sup\{\phi(x):x = x^*, ||x|| = 1\}$"" be generalized?","Can the fact ""If  is a Hermitian linear functional on a -algebra  then "" be generalized?","\phi C^* A ||\phi|| = \sup\{\phi(x):x = x^*, ||x|| = 1\}","This is Proposition 13.3 on Page 78 in An Introduction to Operator Algebras by Kehe Zhu. The statement is as follows: Proposition 13.3. If $\varphi$ is a Hermitian linear functional on a $C^*$ -algebra $A$ , then $\Vert \varphi \Vert = \sup\{\varphi(x):x = x^*, \Vert x\Vert \leq 1\}.$ where a linear functional $\varphi: A \rightarrow \mathbb{C}$ on a $C^*$ -algebra $A$ is Hermitian if $\varphi(x^*) = \overline{\varphi(x)}$ . I wonder whether this can be generalized to the case that the ""target"" of the linear map $\varphi$ is a general $C^*$ -algebra, say, $B$ ? I give the definition below: A linear map $\varphi: A \rightarrow B$ between two $C^*$ -algebras $A$ and $B$ is said to be Hermitian if $\varphi(x^*) = \varphi(x)^*$ . and I guess Proposition 13.3 can be generalized as the following statement: If $\varphi: A \rightarrow B$ is a Hermitian linear map between two $C^*$ -algebras $A$ and $B$ , then $\Vert \varphi \Vert = \sup\{\Vert\varphi(x)\Vert:x = x^*, \Vert x\Vert \leq 1\}$ . It is evident that in the above statement, the right-hand side is less than or equal to the left-hand side, because by definition $\Vert\varphi\Vert = \sup\{\Vert\varphi(x)\Vert: \Vert x\Vert \leq 1\} $ (without the extra limitation $x = x^*$ ). However, I have no idea how to obtain the inequality in the reverse direction , because in Zhu's book he involved the properties of complex numbers such as rotations, etc. Could anyone present a proof of this statement or a counterexample to disprove this statement (although I may feel a bit disappointed)? Any help is appreciated.","This is Proposition 13.3 on Page 78 in An Introduction to Operator Algebras by Kehe Zhu. The statement is as follows: Proposition 13.3. If is a Hermitian linear functional on a -algebra , then where a linear functional on a -algebra is Hermitian if . I wonder whether this can be generalized to the case that the ""target"" of the linear map is a general -algebra, say, ? I give the definition below: A linear map between two -algebras and is said to be Hermitian if . and I guess Proposition 13.3 can be generalized as the following statement: If is a Hermitian linear map between two -algebras and , then . It is evident that in the above statement, the right-hand side is less than or equal to the left-hand side, because by definition (without the extra limitation ). However, I have no idea how to obtain the inequality in the reverse direction , because in Zhu's book he involved the properties of complex numbers such as rotations, etc. Could anyone present a proof of this statement or a counterexample to disprove this statement (although I may feel a bit disappointed)? Any help is appreciated.","\varphi C^* A \Vert \varphi \Vert = \sup\{\varphi(x):x = x^*, \Vert x\Vert \leq 1\}. \varphi: A \rightarrow \mathbb{C} C^* A \varphi(x^*) = \overline{\varphi(x)} \varphi C^* B \varphi: A \rightarrow B C^* A B \varphi(x^*) = \varphi(x)^* \varphi: A \rightarrow B C^* A B \Vert \varphi \Vert = \sup\{\Vert\varphi(x)\Vert:x = x^*, \Vert x\Vert \leq 1\} \Vert\varphi\Vert = \sup\{\Vert\varphi(x)\Vert: \Vert x\Vert \leq 1\}  x = x^*","['functional-analysis', 'operator-theory', 'operator-algebras', 'c-star-algebras', 'functional-calculus']"
