,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,On the proof of Asymptotic Normality of GLM-Estimator: understanding some $o_p(1)$ statements,On the proof of Asymptotic Normality of GLM-Estimator: understanding some  statements,o_p(1),"Also the framework is kind of annoying, my questions at the end of the text should be rather standard: Framework I am trying to understand the proof for the asymptotical normality of the maximum likelihood estimator in a GLM-setting, which is given in the Book From Finite Sample to Asymptotic Methods in Statistics by de Lima, Singer and Sen in chapter 10.5 and have some problems following their arguments. For the exponential family of distributions they derived  \begin{align*} -\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta) & = \sum_{i=1}^N \{g'(\mu_i(\beta))\}^{-2}[v_i(\beta)]^{-1} x_ix_i'\\ &\quad + \sum_{i=1}^N(Y_i-\mu_i(\beta))\{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}x_ix_i' \\ = I_n(\beta)+r_n(\beta) \end{align*} where $\log L_n(\beta)$ is the log-Likelihood and $$I_n(\beta) =\sum_{i=1}^N \{g'(\mu_i(\beta)\}^{-2}[v_i(\beta)]^{-1} x_ix_i'=\mathbb{E}(-\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta) ) $$ is the Information matrix. They then note that $r_n(\beta)$ is a sum of independent centered random variables with finite variances $v_i(\mu_i(\beta))$ and nonstochastic matrix coefficients $G_i := \{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}x_ix_i'$ Among other things they assume (I already corrected some obvious mistakes): (10.5.31) $$\lim_{n\to \infty}\frac{1}{n^2}\sum_{i=1}^n v_i(\mu_i(\beta))trace(G_iG_i')=0$$ Define  $B(\delta)= \{\beta^*\in \mathbb{R}^q : ||\beta^*-\beta||<\delta\}$, $w_{1i}:= \{g'(\mu_i(\beta)\}^{-2}[v_i(\beta)]^{-1}$ and $w_{2i}:=\mu_i(\beta)\{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}$ we then assume that we have as $\delta\to 0$: (10.5.33) $$\sup_{\beta^*\in B(\delta)}n^{-1}\sum_{i=1}^N || [w_{ki}(\beta^*)-w_{ki}(\beta)] x_ix_i'|| \to 0, \quad k=1,2$$ (10.5.34) $$\mathbb{E}\{\sup_{\beta^*\in B(\delta)}n^{-1}\sum_{i=1}^n|Y_i|||[w_{2i}(\beta^*)-w_{2i}(\beta)] x_ix_i'||\} \to 0$$ Questions: They say that it follows from (10.5.31) and the Chebyshev inequality, that $$n^{-1}r_n(\beta) = o_p(1)$$ How can I see this?! In their proof, at (10.5.38), they claim that it follows from (10.5.33) and (10.5.34) that $$\sup_{\beta^* \in B(K/\sqrt{n})} || \frac{1}{n} \frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta)|_{\beta^*} - \frac{1}{n}\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta)|_{\beta}||=o_p(1)$$ I am not able to see this neither. Any help is greatly appreciated.","Also the framework is kind of annoying, my questions at the end of the text should be rather standard: Framework I am trying to understand the proof for the asymptotical normality of the maximum likelihood estimator in a GLM-setting, which is given in the Book From Finite Sample to Asymptotic Methods in Statistics by de Lima, Singer and Sen in chapter 10.5 and have some problems following their arguments. For the exponential family of distributions they derived  \begin{align*} -\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta) & = \sum_{i=1}^N \{g'(\mu_i(\beta))\}^{-2}[v_i(\beta)]^{-1} x_ix_i'\\ &\quad + \sum_{i=1}^N(Y_i-\mu_i(\beta))\{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}x_ix_i' \\ = I_n(\beta)+r_n(\beta) \end{align*} where $\log L_n(\beta)$ is the log-Likelihood and $$I_n(\beta) =\sum_{i=1}^N \{g'(\mu_i(\beta)\}^{-2}[v_i(\beta)]^{-1} x_ix_i'=\mathbb{E}(-\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta) ) $$ is the Information matrix. They then note that $r_n(\beta)$ is a sum of independent centered random variables with finite variances $v_i(\mu_i(\beta))$ and nonstochastic matrix coefficients $G_i := \{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}x_ix_i'$ Among other things they assume (I already corrected some obvious mistakes): (10.5.31) $$\lim_{n\to \infty}\frac{1}{n^2}\sum_{i=1}^n v_i(\mu_i(\beta))trace(G_iG_i')=0$$ Define  $B(\delta)= \{\beta^*\in \mathbb{R}^q : ||\beta^*-\beta||<\delta\}$, $w_{1i}:= \{g'(\mu_i(\beta)\}^{-2}[v_i(\beta)]^{-1}$ and $w_{2i}:=\mu_i(\beta)\{\frac{g''(\mu_i(\beta)}{[g'(\mu_i(\beta)]^2}+\frac{b'''(h(x_i'\beta))}{[g'(\mu_i(\beta)]^2[v_i(\beta)]^3}\}$ we then assume that we have as $\delta\to 0$: (10.5.33) $$\sup_{\beta^*\in B(\delta)}n^{-1}\sum_{i=1}^N || [w_{ki}(\beta^*)-w_{ki}(\beta)] x_ix_i'|| \to 0, \quad k=1,2$$ (10.5.34) $$\mathbb{E}\{\sup_{\beta^*\in B(\delta)}n^{-1}\sum_{i=1}^n|Y_i|||[w_{2i}(\beta^*)-w_{2i}(\beta)] x_ix_i'||\} \to 0$$ Questions: They say that it follows from (10.5.31) and the Chebyshev inequality, that $$n^{-1}r_n(\beta) = o_p(1)$$ How can I see this?! In their proof, at (10.5.38), they claim that it follows from (10.5.33) and (10.5.34) that $$\sup_{\beta^* \in B(K/\sqrt{n})} || \frac{1}{n} \frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta)|_{\beta^*} - \frac{1}{n}\frac{\partial^2 }{\partial \beta \partial \beta'} \log L_n(\beta)|_{\beta}||=o_p(1)$$ I am not able to see this neither. Any help is greatly appreciated.",,"['statistics', 'convergence-divergence', 'maximum-likelihood']"
1,Basic Quantile Calculation,Basic Quantile Calculation,,"I have a slight confusion with the current method of calculation of a quantile for a give ungrouped distribution. To give you an example, i shall refer to calculation of a Quartile, but this doubt applies to any quantile. Let's take a distribution as follows: 0,2,4,9,10 n=5 The formulae to calculate the lower quartile and upper quartile are as follows: Q1=(n+1)/4 Q3=3*(n+1)/4 So as per these formulae, the upper and lower quartile should appear at positions 1.5 and 4.5 We can all agree here that the median of the distribution is 4 (i.e., position 3) However, to derive the upper and lower quartile values, we have to assume that the end point values of the range are 0 and 10 (i.e, position 1 and 5). Hence by this logic, and assuming the end point values of the range are 0 and 10 (position 1 and 5) and the median as 4 (position 3), we should get the upper and lower quartile positions as 2 (i.e. (1+3)/2) and 4 (i.e. (5+3)/2) respectively. However, going by the accepted formula we see that we see that the lower quartile 1.5 is a median position between a non-existant position 0 and 3, and the upper quartile 4.5 is a median position between position 3 and a non-existant position 6. Can anyone please clarify why the non-existant positions are assumed? Perhaps I'm looking at it from a wrong angle, so please let me know.","I have a slight confusion with the current method of calculation of a quantile for a give ungrouped distribution. To give you an example, i shall refer to calculation of a Quartile, but this doubt applies to any quantile. Let's take a distribution as follows: 0,2,4,9,10 n=5 The formulae to calculate the lower quartile and upper quartile are as follows: Q1=(n+1)/4 Q3=3*(n+1)/4 So as per these formulae, the upper and lower quartile should appear at positions 1.5 and 4.5 We can all agree here that the median of the distribution is 4 (i.e., position 3) However, to derive the upper and lower quartile values, we have to assume that the end point values of the range are 0 and 10 (i.e, position 1 and 5). Hence by this logic, and assuming the end point values of the range are 0 and 10 (position 1 and 5) and the median as 4 (position 3), we should get the upper and lower quartile positions as 2 (i.e. (1+3)/2) and 4 (i.e. (5+3)/2) respectively. However, going by the accepted formula we see that we see that the lower quartile 1.5 is a median position between a non-existant position 0 and 3, and the upper quartile 4.5 is a median position between position 3 and a non-existant position 6. Can anyone please clarify why the non-existant positions are assumed? Perhaps I'm looking at it from a wrong angle, so please let me know.",,"['statistics', 'quantile']"
2,In how many ways can I fill a list of lists,In how many ways can I fill a list of lists,,"I have 220 items to fill a list of lists with, where, the outer list consists of 45 inner lists. Each of the 45 inner lists can have: Maximum of 10 items. Can be empty. So, the list of lists can have up to a maximum of 450 items, but we only need to fill 220 spots and the rest will be empty. The order of the items inside the inner list does not matter. An item can only be used once throughout the all 45 lists. The order of the inner lists matters. [[3,4], [1,2]] is not equal [[1,2], [3,4]] E.g: [[1,2],[9,7,55,66,77,99], [], [23,42,51,11], ...]","I have 220 items to fill a list of lists with, where, the outer list consists of 45 inner lists. Each of the 45 inner lists can have: Maximum of 10 items. Can be empty. So, the list of lists can have up to a maximum of 450 items, but we only need to fill 220 spots and the rest will be empty. The order of the items inside the inner list does not matter. An item can only be used once throughout the all 45 lists. The order of the inner lists matters. [[3,4], [1,2]] is not equal [[1,2], [3,4]] E.g: [[1,2],[9,7,55,66,77,99], [], [23,42,51,11], ...]",,"['probability', 'statistics']"
3,"Likelihood Ratio Test: Uniform Distribution, Change of Inequality in Alternative Hypothesis","Likelihood Ratio Test: Uniform Distribution, Change of Inequality in Alternative Hypothesis",,"Thanks, in advance. I would really appreciate any help here. Problem:  Let $X_1, \ldots, X_n$ be a random sample from a $\operatorname{Uniform}(0,\theta)$ population.  Let $$H_0 : \theta = \theta_0 \quad \text{and} \quad H_A : \theta < \theta_0.$$  The unrestricted MLE of $\theta$ is $X_{(n)}$ (the maximum). (a) Show that for a likelihood ratio test of size $\alpha$ that the rejection region is $$\frac{X_{(n)}}{\theta_0} < \alpha^{1/n}.$$ Solution :  This question I was able to do.  We know that the rejection region for any GLRT is of the form $$RR = \{\Lambda(X_1, \ldots, X_n) < c\}.$$  So, $$\begin{align*} \Pr[\text{reject } H_0 \mid H_0 \text{ true}] &= \Pr[\Lambda(X_1, \ldots, X_n) < c \mid \theta = \theta_0] \\ &= \Pr[(X_{(n)}/\theta_0)^n < c \mid \theta = \theta_0 ] \\ &= \Pr[X_{(n)} < c^{1/n} \theta_0 \mid \theta = \theta_0 ] \\ &= \Pr[X_1 < c^{1/n} \theta_0 \mid \theta = \theta_0]^n \\ &= \biggl( \int_{x=0}^{c^{1/n} \theta_0} \frac{1}{\theta_0} \, dx \biggr)^{\! n} \\ &= (c^{1/n})^n = c \\ &= \alpha \end{align*}$$ Thus, $$RR = \{\Lambda(X_1, \ldots, X_n) < c\} = \left\{ \left(\frac{X_{(n)}}{\theta_0}\right)^{\! n} < \alpha \right\} = \left\{ \frac{X_{(n)}}{\theta_0} < \alpha^{1/n} \right\}.$$ (b) Now, let $$H_0 : \theta = \theta_0 \quad \text{and} \quad H_A : \theta > \theta_0.$$  Show that the LRT is simple in the sense that if $X_{(n)} < \theta_0$ we accept $H_0$ and if $X_{(n)} > \theta_0$ we reject $H_0$ for all $\alpha$. Attempt at this question :  So in this case would the rejection region of the LRT switch to this:  $$RR = \{ \Lambda(X_1, \ldots, X_n) > c \}?$$  My reasoning is that if $\Lambda(X_1, \ldots, X_n) = (X_{(n)}/\theta_0)^n$, then $H_A$ implies that $\theta > \theta_0 = X_{(n)} > \theta_0$ and so we would expect $(X_{(n)}/\theta_0)^n$ to be a number larger than one if $H_A$ is true.  And so, doing the same process as (a) for all $\alpha$ it would follow that if $X_{(n)}/\theta_0 > 1$ (as long as $X_{(n)} > \theta_0$) then we would always reject for all $\alpha$ since we end up with $(X_{(n)}/\theta_0)^n > \alpha \rightarrow X_{(n)}/\theta_0 > \alpha^{1/n}$ and $0 < \alpha \le 1$.  Of course, the bound could be lower for different $\alpha$ that aren't one, but $X_{(n)}/\theta_0 > 1$ will always be a stronger condition. Basically, this whole idea revolves around the RR being different from what I am used to seeing.  What is wrong with my reasoning? EDIT: I believe I have figured out this problem. Here was my solution in case anyone cares: Since $\Lambda_r = (\frac {X_{(n)}}{\theta_0})^n$ , we know that if $H_A : \theta > \theta_0$ then this implies that $H_A : X_{(n)} > \theta_0$. So, we want to find c such that again, $Pr[reject \ H_0 | H_0 \ is \ true] =Pr[\Lambda_r < c \ \ | \theta = \theta_0]$=$Pr[\ (\frac {X_{(n)}}{\theta_0})^n < c \ \ | \ \ \theta = \theta_0] = \alpha$. If indeed $H_A : X_{(n)} > \theta_0$ is true then this would imply (as I originally stated) that $\Lambda_r > 1$. In other words,  $RR = \{ \Lambda_r > 1\} $. However, if $X  \sim Uniform(0, \theta)$ distributed random variable then under $H_0$ it is impossible for the maximum $X_{(n)}$ to be greater than $\theta_0$ and so it is impossible for $\Lambda_r > 1$, since under the null $X  \sim Uniform(0, \theta_0)$ and thus $Pr[ X_{(n)} > \theta_0 | \theta = \theta_0] = 0 $ . Thus, $Pr[reject \ H_0 | H_0 \ is \ true] = Pr[\ \Lambda_r > 1\ | \theta = \theta_0] = Pr[X_{(n)} > \theta_0 | \theta = \theta_0] =  0.$ Thus, it follows that if we observe a maximum value that is greater than $\theta_0$ that the null hypothesis cannot be true (ie. the alternative hypothesis must be true), since under the null hypothesis the probability of observing a maximum value greater than $\theta_0$ is zero, regardless of $\alpha$.","Thanks, in advance. I would really appreciate any help here. Problem:  Let $X_1, \ldots, X_n$ be a random sample from a $\operatorname{Uniform}(0,\theta)$ population.  Let $$H_0 : \theta = \theta_0 \quad \text{and} \quad H_A : \theta < \theta_0.$$  The unrestricted MLE of $\theta$ is $X_{(n)}$ (the maximum). (a) Show that for a likelihood ratio test of size $\alpha$ that the rejection region is $$\frac{X_{(n)}}{\theta_0} < \alpha^{1/n}.$$ Solution :  This question I was able to do.  We know that the rejection region for any GLRT is of the form $$RR = \{\Lambda(X_1, \ldots, X_n) < c\}.$$  So, $$\begin{align*} \Pr[\text{reject } H_0 \mid H_0 \text{ true}] &= \Pr[\Lambda(X_1, \ldots, X_n) < c \mid \theta = \theta_0] \\ &= \Pr[(X_{(n)}/\theta_0)^n < c \mid \theta = \theta_0 ] \\ &= \Pr[X_{(n)} < c^{1/n} \theta_0 \mid \theta = \theta_0 ] \\ &= \Pr[X_1 < c^{1/n} \theta_0 \mid \theta = \theta_0]^n \\ &= \biggl( \int_{x=0}^{c^{1/n} \theta_0} \frac{1}{\theta_0} \, dx \biggr)^{\! n} \\ &= (c^{1/n})^n = c \\ &= \alpha \end{align*}$$ Thus, $$RR = \{\Lambda(X_1, \ldots, X_n) < c\} = \left\{ \left(\frac{X_{(n)}}{\theta_0}\right)^{\! n} < \alpha \right\} = \left\{ \frac{X_{(n)}}{\theta_0} < \alpha^{1/n} \right\}.$$ (b) Now, let $$H_0 : \theta = \theta_0 \quad \text{and} \quad H_A : \theta > \theta_0.$$  Show that the LRT is simple in the sense that if $X_{(n)} < \theta_0$ we accept $H_0$ and if $X_{(n)} > \theta_0$ we reject $H_0$ for all $\alpha$. Attempt at this question :  So in this case would the rejection region of the LRT switch to this:  $$RR = \{ \Lambda(X_1, \ldots, X_n) > c \}?$$  My reasoning is that if $\Lambda(X_1, \ldots, X_n) = (X_{(n)}/\theta_0)^n$, then $H_A$ implies that $\theta > \theta_0 = X_{(n)} > \theta_0$ and so we would expect $(X_{(n)}/\theta_0)^n$ to be a number larger than one if $H_A$ is true.  And so, doing the same process as (a) for all $\alpha$ it would follow that if $X_{(n)}/\theta_0 > 1$ (as long as $X_{(n)} > \theta_0$) then we would always reject for all $\alpha$ since we end up with $(X_{(n)}/\theta_0)^n > \alpha \rightarrow X_{(n)}/\theta_0 > \alpha^{1/n}$ and $0 < \alpha \le 1$.  Of course, the bound could be lower for different $\alpha$ that aren't one, but $X_{(n)}/\theta_0 > 1$ will always be a stronger condition. Basically, this whole idea revolves around the RR being different from what I am used to seeing.  What is wrong with my reasoning? EDIT: I believe I have figured out this problem. Here was my solution in case anyone cares: Since $\Lambda_r = (\frac {X_{(n)}}{\theta_0})^n$ , we know that if $H_A : \theta > \theta_0$ then this implies that $H_A : X_{(n)} > \theta_0$. So, we want to find c such that again, $Pr[reject \ H_0 | H_0 \ is \ true] =Pr[\Lambda_r < c \ \ | \theta = \theta_0]$=$Pr[\ (\frac {X_{(n)}}{\theta_0})^n < c \ \ | \ \ \theta = \theta_0] = \alpha$. If indeed $H_A : X_{(n)} > \theta_0$ is true then this would imply (as I originally stated) that $\Lambda_r > 1$. In other words,  $RR = \{ \Lambda_r > 1\} $. However, if $X  \sim Uniform(0, \theta)$ distributed random variable then under $H_0$ it is impossible for the maximum $X_{(n)}$ to be greater than $\theta_0$ and so it is impossible for $\Lambda_r > 1$, since under the null $X  \sim Uniform(0, \theta_0)$ and thus $Pr[ X_{(n)} > \theta_0 | \theta = \theta_0] = 0 $ . Thus, $Pr[reject \ H_0 | H_0 \ is \ true] = Pr[\ \Lambda_r > 1\ | \theta = \theta_0] = Pr[X_{(n)} > \theta_0 | \theta = \theta_0] =  0.$ Thus, it follows that if we observe a maximum value that is greater than $\theta_0$ that the null hypothesis cannot be true (ie. the alternative hypothesis must be true), since under the null hypothesis the probability of observing a maximum value greater than $\theta_0$ is zero, regardless of $\alpha$.",,"['probability', 'statistics', 'hypothesis-testing']"
4,Independence of two F-distributed random variables,Independence of two F-distributed random variables,,"Suppose that $U$ and $W$ are subspaces of $\mathbb{R}^n$ such that $U \subseteq W$, with respective dimensions $m = \dim(U)$, $s=\dim(W)$. Denote the (perpendicular) projection matrices onto $U$ and $W$ as ${\bf P}_U$ and ${\bf P}_W$, respectively. Let us also define the orthogonal complement $W^\perp$, with projection matrix ${\bf P}_W^\perp = {\bf I} - {\bf P}_W$. Then the subspace $Z = W \cap U^\perp$ has projection matrix ${\bf P}_Z = {\bf P}_W - {\bf P}_U$. Let ${\bf x} \in \mathbb{R}^n$ be normally distributed with zero mean and covariance ${\bf I}_n$. One has  $$ \|{\bf x} \|^2 =  \|{\bf P}_U {\bf x} \|^2 + \|{\bf P}_Z{\bf x} \|^2 + \|{\bf P}_W^\perp{\bf x} \|^2,$$ and each of the three terms in the right-hand side is chi-square distributed with $m$, $s-m$ and $n-s$ degrees of freedom, respectively; moreover, they are statistically independent (as per Cochran's Theorem). Intuitively, this is due to the fact that the subspaces $U$, $Z$ and $W^\perp$ are pairwise orthogonal. My question is the following. Consider the random variables $$ r_1 = \frac{ \|{\bf P}_W{\bf x} \|^2}{\|{\bf P}_W^\perp {\bf x} \|^2} \sim F_{s,n-s}  \qquad \mbox{and} \qquad r_2 = \frac{ \|{\bf P}_U{\bf x} \|^2}{\|{\bf P}_Z{\bf x} \|^2} \sim F_{m,s-m}. $$ Are they statistically independent? Empirical evidence is supportive, and I conjecture that they are,  but I have been unable to obtain a formal proof. Note that $r_1$ is the ratio of the energy of $\bf x$ in $W$ to that in $W^\perp$ (its orthogonal complement in  $\mathbb{R}^n$), whereas $r_2$ is the ratio of the energy of $\bf x$ in $U\subseteq W$ to that in $Z$, which is its orthogonal complement in  $W$. I think the question is of independent interest, but in any case, I arrived at this from a hypothesis testing problemin which, on one hand, I test $H_0: {\bf x} \in W$ vs. $H_1: {\bf x} \notin W$ (with test statistic $r_1$) and on the other, $H_0': {\bf P}_W{\bf x} \in U$ vs. $H_1': {\bf P}_W{\bf x} \notin U$ (with test statistic $r_2$). Thanks in advance!","Suppose that $U$ and $W$ are subspaces of $\mathbb{R}^n$ such that $U \subseteq W$, with respective dimensions $m = \dim(U)$, $s=\dim(W)$. Denote the (perpendicular) projection matrices onto $U$ and $W$ as ${\bf P}_U$ and ${\bf P}_W$, respectively. Let us also define the orthogonal complement $W^\perp$, with projection matrix ${\bf P}_W^\perp = {\bf I} - {\bf P}_W$. Then the subspace $Z = W \cap U^\perp$ has projection matrix ${\bf P}_Z = {\bf P}_W - {\bf P}_U$. Let ${\bf x} \in \mathbb{R}^n$ be normally distributed with zero mean and covariance ${\bf I}_n$. One has  $$ \|{\bf x} \|^2 =  \|{\bf P}_U {\bf x} \|^2 + \|{\bf P}_Z{\bf x} \|^2 + \|{\bf P}_W^\perp{\bf x} \|^2,$$ and each of the three terms in the right-hand side is chi-square distributed with $m$, $s-m$ and $n-s$ degrees of freedom, respectively; moreover, they are statistically independent (as per Cochran's Theorem). Intuitively, this is due to the fact that the subspaces $U$, $Z$ and $W^\perp$ are pairwise orthogonal. My question is the following. Consider the random variables $$ r_1 = \frac{ \|{\bf P}_W{\bf x} \|^2}{\|{\bf P}_W^\perp {\bf x} \|^2} \sim F_{s,n-s}  \qquad \mbox{and} \qquad r_2 = \frac{ \|{\bf P}_U{\bf x} \|^2}{\|{\bf P}_Z{\bf x} \|^2} \sim F_{m,s-m}. $$ Are they statistically independent? Empirical evidence is supportive, and I conjecture that they are,  but I have been unable to obtain a formal proof. Note that $r_1$ is the ratio of the energy of $\bf x$ in $W$ to that in $W^\perp$ (its orthogonal complement in  $\mathbb{R}^n$), whereas $r_2$ is the ratio of the energy of $\bf x$ in $U\subseteq W$ to that in $Z$, which is its orthogonal complement in  $W$. I think the question is of independent interest, but in any case, I arrived at this from a hypothesis testing problemin which, on one hand, I test $H_0: {\bf x} \in W$ vs. $H_1: {\bf x} \notin W$ (with test statistic $r_1$) and on the other, $H_0': {\bf P}_W{\bf x} \in U$ vs. $H_1': {\bf P}_W{\bf x} \notin U$ (with test statistic $r_2$). Thanks in advance!",,"['probability', 'statistics', 'random-variables', 'normal-distribution']"
5,How to determine if the dataset is large enough?,How to determine if the dataset is large enough?,,"We are given a dataset $X=(x_1,\ldots,x_n)$ of words (it could be duplicates). We assume each $x_i$ was generated by a probability distribution with probability  $p_i$ (we do not know this values, we have to estimate them from the dataset). Define the metric $d_k=\sum_{j=1}^k p_{i_j}$, which sums up the biggest $k$ values of $p_{i_j}$. The question is: How will you determine whether the dataset $X$ is large enough to allow a good estimation of $d_k$? I can estimate the probabilities from the dataset $X$, $\overline{p_{i_j}}$ = $\frac{f_{i_j}}{|X|}$, where $f_{i_j}$ is frequency of $x_{i_j}$ in dataset $X$. Therefore, I have an estimation for my metric $d_k$ by taking the first $k$ highest values of $\overline{p_{i_j}}$ We know that $MSE=bias^2 + variance$, then I can decide whether $d_k$ is a good estimation by taking a look on $MSE$ value and comparing it with a threshold. If it is smaller than $X$ is large enough. Otherwise it is not. Is it a good approach?","We are given a dataset $X=(x_1,\ldots,x_n)$ of words (it could be duplicates). We assume each $x_i$ was generated by a probability distribution with probability  $p_i$ (we do not know this values, we have to estimate them from the dataset). Define the metric $d_k=\sum_{j=1}^k p_{i_j}$, which sums up the biggest $k$ values of $p_{i_j}$. The question is: How will you determine whether the dataset $X$ is large enough to allow a good estimation of $d_k$? I can estimate the probabilities from the dataset $X$, $\overline{p_{i_j}}$ = $\frac{f_{i_j}}{|X|}$, where $f_{i_j}$ is frequency of $x_{i_j}$ in dataset $X$. Therefore, I have an estimation for my metric $d_k$ by taking the first $k$ highest values of $\overline{p_{i_j}}$ We know that $MSE=bias^2 + variance$, then I can decide whether $d_k$ is a good estimation by taking a look on $MSE$ value and comparing it with a threshold. If it is smaller than $X$ is large enough. Otherwise it is not. Is it a good approach?",,"['probability', 'statistics']"
6,Expected Value for conditional chosen with repetition problem,Expected Value for conditional chosen with repetition problem,,"I am thinking of this for more than two weeks now and did not find any help in the literature: I have this experiment: There is an urn with 9 balls inside, numbered 1-9. You draw a ball and record the number. After that you put the ball back inside the urn. You do this until you have drawn one number 8 times (it does not matter, which one). How many draws do you expect to do until you get one number 8 times? The minimum number of draws is obviously 8 and the maximum is 64, but i did not find any distribution for this kind of problem. The only thing I know from simulation is, that the expected value is about 39.309.  Any Ideas?","I am thinking of this for more than two weeks now and did not find any help in the literature: I have this experiment: There is an urn with 9 balls inside, numbered 1-9. You draw a ball and record the number. After that you put the ball back inside the urn. You do this until you have drawn one number 8 times (it does not matter, which one). How many draws do you expect to do until you get one number 8 times? The minimum number of draws is obviously 8 and the maximum is 64, but i did not find any distribution for this kind of problem. The only thing I know from simulation is, that the expected value is about 39.309.  Any Ideas?",,"['probability', 'statistics', 'combinations']"
7,Large-value approximation of (real) error function series expansion,Large-value approximation of (real) error function series expansion,,"I want to compute an approximation of the error function in order to compute probabilities for very extreme events (> 20 standard deviations), and I fail to reconcile results from different sources. The standard power series expansion of the error function for small x is given by (wikipedia): $$ erf(x) = \frac{2}{\sqrt{\pi}} \sum_{n=1}^{\infty} \frac{(-1)^n x^{2n-1}}{n!(2n+1)}$$ Now according to some sources (eq x12) there is an approximation for large x: $$ erf(x) \approx 1 - \frac{e^{-x^2}}{\sqrt{\pi}x} \left( 1 - \sum_{n=1}^{\infty} \frac{\prod_{k=1}^{n}2k-1}{(2x^2)^n} \right) $$ Whereas according to other sources (eq 1.15) it's: $$ erf(x) \approx 1 - \frac{e^{-x^2}}{\sqrt{\pi}x} \left( 1 - \sum_{n=1}^{\infty} (-1)^{n+1} \frac{\prod_{k=1}^{n}2k-1}{(2x^2)^n} \right) $$ Basically, the difference (if I haven't made any mistakes this late at night) is just the flipping signs. Can someone explain to me what I'm missing here, or what the right approximation is?","I want to compute an approximation of the error function in order to compute probabilities for very extreme events (> 20 standard deviations), and I fail to reconcile results from different sources. The standard power series expansion of the error function for small x is given by (wikipedia): $$ erf(x) = \frac{2}{\sqrt{\pi}} \sum_{n=1}^{\infty} \frac{(-1)^n x^{2n-1}}{n!(2n+1)}$$ Now according to some sources (eq x12) there is an approximation for large x: $$ erf(x) \approx 1 - \frac{e^{-x^2}}{\sqrt{\pi}x} \left( 1 - \sum_{n=1}^{\infty} \frac{\prod_{k=1}^{n}2k-1}{(2x^2)^n} \right) $$ Whereas according to other sources (eq 1.15) it's: $$ erf(x) \approx 1 - \frac{e^{-x^2}}{\sqrt{\pi}x} \left( 1 - \sum_{n=1}^{\infty} (-1)^{n+1} \frac{\prod_{k=1}^{n}2k-1}{(2x^2)^n} \right) $$ Basically, the difference (if I haven't made any mistakes this late at night) is just the flipping signs. Can someone explain to me what I'm missing here, or what the right approximation is?",,"['probability', 'statistics']"
8,Is Bayesian probability at odds with traditional theories?,Is Bayesian probability at odds with traditional theories?,,"I am studying conditional probability, and I came across this Bayes theorem. Though I am no statistician, I kinda get the idea of the theorem, that probabilities can be updated using newly given informations. What I am curious about is: I heard that Bayesian statistics was a ""new"" approach to statistics, and therefore was met with many objections and criticisms. But I learned that the Bayesian theorem $$P(B|A)=\frac{P(A|B)P(B)}{P(A)}$$ can be derived from the definition of conditional probability. I can't understand why this was met with criticisms.  I heard that they were due to different views about the meaning of probability and inference (like frequentists and propensitists), but I don't really see any difference between these. Would someone please explain how Bayesians were at odds with other views about statistics, and why Bayesian approach aroused numerous arguments and confusions (with some examples if possible)? Now my question might sound a bit vague, but I have almost no background information about advanced statistics, so this is the best I can give. Thank you in advance!","I am studying conditional probability, and I came across this Bayes theorem. Though I am no statistician, I kinda get the idea of the theorem, that probabilities can be updated using newly given informations. What I am curious about is: I heard that Bayesian statistics was a ""new"" approach to statistics, and therefore was met with many objections and criticisms. But I learned that the Bayesian theorem $$P(B|A)=\frac{P(A|B)P(B)}{P(A)}$$ can be derived from the definition of conditional probability. I can't understand why this was met with criticisms.  I heard that they were due to different views about the meaning of probability and inference (like frequentists and propensitists), but I don't really see any difference between these. Would someone please explain how Bayesians were at odds with other views about statistics, and why Bayesian approach aroused numerous arguments and confusions (with some examples if possible)? Now my question might sound a bit vague, but I have almost no background information about advanced statistics, so this is the best I can give. Thank you in advance!",,"['probability', 'statistics', 'bayesian', 'bayes-theorem']"
9,Conditional probability of spam,Conditional probability of spam,,"I got that $P(A_1) = 0.07875, P(A_2) = 0.008, P(A_3) = 0.0625$, we know that $$P(\text{Spam} \mid A_1A_2A_3) = \frac{P(\text{Spam} \cap A_1A_2A_3)}{P(A_1A_2A_3)}$$ We know that $\{A_1, A_2, A_3\}$ is an independent set., so $P(A_1A_2A_3) = 0.00039375$ I cant figure out $P(\text{spam} \times A_1A_2A_3)$? But I'm not sure of numerator?","I got that $P(A_1) = 0.07875, P(A_2) = 0.008, P(A_3) = 0.0625$, we know that $$P(\text{Spam} \mid A_1A_2A_3) = \frac{P(\text{Spam} \cap A_1A_2A_3)}{P(A_1A_2A_3)}$$ We know that $\{A_1, A_2, A_3\}$ is an independent set., so $P(A_1A_2A_3) = 0.00039375$ I cant figure out $P(\text{spam} \times A_1A_2A_3)$? But I'm not sure of numerator?",,"['probability', 'statistics']"
10,"Is that possible to change any gamma distribution to $\Gamma(k=0,\theta=1)$",Is that possible to change any gamma distribution to,"\Gamma(k=0,\theta=1)","If a random variable $x$ follows a Gamma distribution $\Gamma(k,\theta)$, is it possible to transform the variable and make it follows $\Gamma(k=0,\theta=1)$, like we transfer the variable which follows a Gaussian distribution to Normal distribution through $(x-\mu)/\sigma$ ($\mu$ is the mean and $\sigma$ is the standard deviation)? Many thanks.","If a random variable $x$ follows a Gamma distribution $\Gamma(k,\theta)$, is it possible to transform the variable and make it follows $\Gamma(k=0,\theta=1)$, like we transfer the variable which follows a Gaussian distribution to Normal distribution through $(x-\mu)/\sigma$ ($\mu$ is the mean and $\sigma$ is the standard deviation)? Many thanks.",,['statistics']
11,replace the worst $20\%$ in normal distribution- exercise,replace the worst  in normal distribution- exercise,20\%,"Here is an exercise, I tried to solve. It is a long since, I study statistics, so I would really appreciate if someone could check the answer/solution I give below. Exercise: Assume we are given a sample of $160$ cows. The mean value of the milk production is $ \mu= 100 \textrm{kg},$ and the standard deviation is $ \sigma= 30 \textrm{kg}.$ We wish to replace the $20\%$ of the cows with the minimum production of milk. Find the quantity of milk the these cows produce. Solution: We denote by $X$ the random variable of the amount of milk. By the central limit theorem, we can assume that $ X \sim N(100, 30^2) ,$ and thus $$ \frac{ X - 100}{30} \sim N(0,1)$$ follows the standard normal distribution. Put $ c$ for the maximum quantity of milk, produced by cows that belong to the worst $20 \%.$ Then we have: $$ P( X \leq c ) =0.2= 1-0.8=1- \Phi(0.84)= \Phi(-0.84)$$ $$ \Longrightarrow P(Z \leq \frac{ c-100}{30})= \Phi(-0.84) ,$$ where $ \Phi$ is the probability density function of the standard normal distribution. Therefore we obtain $$ \frac{c-100}{30} = -0.84 \Longleftrightarrow c=74,8 .$$ In conclusion, the cows that we should replace, are these that produce milk less than $ 74.8 \textrm{kg}. \quad  \square$ Could someone check this attempt of solution ? Thank you in advance!","Here is an exercise, I tried to solve. It is a long since, I study statistics, so I would really appreciate if someone could check the answer/solution I give below. Exercise: Assume we are given a sample of $160$ cows. The mean value of the milk production is $ \mu= 100 \textrm{kg},$ and the standard deviation is $ \sigma= 30 \textrm{kg}.$ We wish to replace the $20\%$ of the cows with the minimum production of milk. Find the quantity of milk the these cows produce. Solution: We denote by $X$ the random variable of the amount of milk. By the central limit theorem, we can assume that $ X \sim N(100, 30^2) ,$ and thus $$ \frac{ X - 100}{30} \sim N(0,1)$$ follows the standard normal distribution. Put $ c$ for the maximum quantity of milk, produced by cows that belong to the worst $20 \%.$ Then we have: $$ P( X \leq c ) =0.2= 1-0.8=1- \Phi(0.84)= \Phi(-0.84)$$ $$ \Longrightarrow P(Z \leq \frac{ c-100}{30})= \Phi(-0.84) ,$$ where $ \Phi$ is the probability density function of the standard normal distribution. Therefore we obtain $$ \frac{c-100}{30} = -0.84 \Longleftrightarrow c=74,8 .$$ In conclusion, the cows that we should replace, are these that produce milk less than $ 74.8 \textrm{kg}. \quad  \square$ Could someone check this attempt of solution ? Thank you in advance!",,"['statistics', 'proof-verification', 'proof-writing', 'statistical-inference']"
12,Proof that $\mathbb{E}(S_n ^2) = \sigma ^2$,Proof that,\mathbb{E}(S_n ^2) = \sigma ^2,"If $X_i$ iid with variance $\sigma$ then I want to prove that $S_n^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i -\bar X_n )^2$ is an unbiased estimate of the variance $\sigma$. So here I go: \begin{equation} \begin{aligned} \mathbb{E}(S_n ^2)&= \frac{1}{n-1}\sum_{i=1} ^{n} \mathbb{E}(X_i -\bar X_n )^2\\ &= \frac{1}{n-1}\sum_{i=1} ^{n} \mathbb{E}(X_i^2  -2X_i\bar X_n + \bar X_n^2) \\ &= \frac{1}{n-1}\sum_{i=1} ^{n}  \mathbb{E}(X_i^2  -\frac{2}{n}X_i ^2  -\frac{2}{n}\sum_{j\neq i} X_i X_j + \bar X_n^2)\\ &= \frac{1}{n-1}\left\{ (n-2)\mathbb{E}(X_1 ^2) -\frac{2}{n}\sum_{i=1} ^{n}\sum_{j\neq i}\mathbb{E}(X_i)\mathbb{E}(X_j) + \sigma ^2 + \mathbb{E}(X_1)^2 \right\} \end{aligned} \end{equation} where I used the fact that for $X_i$, $X_j$ independent we have $\mathbb{E}(X_i X_j) = \mathbb{E}(X_i)\mathbb{E}X_j)$ and that $\mathbb{E}(\bar X_n ^2) = \frac{\sigma^2 + \mathbb{E}(X_1)^2}{n}$. Finally, after rearranging the first and last terms: \begin{equation} \begin{aligned} \mathbb{E}(S_n ^2) &=  \frac{1}{n-1}\left\{ (n-1)\mathbb{E}(X_1 ^2) -\frac{2}{n}n(n-1)\mathbb{E}(X_1)^2  \right\}\\ &= \mathbb{E}(X_1 ^2) -2\mathbb{E}(X_1)^2\\ &\neq \mathbb{E}(X_1 ^2) -\mathbb{E}(X_1)^2 \end{aligned} \end{equation} I'm off by a factor $2$. Can someone help me point out my mistake?","If $X_i$ iid with variance $\sigma$ then I want to prove that $S_n^2 = \frac{1}{n-1}\sum_{i=1}^{n}(X_i -\bar X_n )^2$ is an unbiased estimate of the variance $\sigma$. So here I go: \begin{equation} \begin{aligned} \mathbb{E}(S_n ^2)&= \frac{1}{n-1}\sum_{i=1} ^{n} \mathbb{E}(X_i -\bar X_n )^2\\ &= \frac{1}{n-1}\sum_{i=1} ^{n} \mathbb{E}(X_i^2  -2X_i\bar X_n + \bar X_n^2) \\ &= \frac{1}{n-1}\sum_{i=1} ^{n}  \mathbb{E}(X_i^2  -\frac{2}{n}X_i ^2  -\frac{2}{n}\sum_{j\neq i} X_i X_j + \bar X_n^2)\\ &= \frac{1}{n-1}\left\{ (n-2)\mathbb{E}(X_1 ^2) -\frac{2}{n}\sum_{i=1} ^{n}\sum_{j\neq i}\mathbb{E}(X_i)\mathbb{E}(X_j) + \sigma ^2 + \mathbb{E}(X_1)^2 \right\} \end{aligned} \end{equation} where I used the fact that for $X_i$, $X_j$ independent we have $\mathbb{E}(X_i X_j) = \mathbb{E}(X_i)\mathbb{E}X_j)$ and that $\mathbb{E}(\bar X_n ^2) = \frac{\sigma^2 + \mathbb{E}(X_1)^2}{n}$. Finally, after rearranging the first and last terms: \begin{equation} \begin{aligned} \mathbb{E}(S_n ^2) &=  \frac{1}{n-1}\left\{ (n-1)\mathbb{E}(X_1 ^2) -\frac{2}{n}n(n-1)\mathbb{E}(X_1)^2  \right\}\\ &= \mathbb{E}(X_1 ^2) -2\mathbb{E}(X_1)^2\\ &\neq \mathbb{E}(X_1 ^2) -\mathbb{E}(X_1)^2 \end{aligned} \end{equation} I'm off by a factor $2$. Can someone help me point out my mistake?",,"['statistics', 'estimation', 'variance']"
13,Best unbiased estimator of $P(Y_n>a)$,Best unbiased estimator of,P(Y_n>a),"I'm trying to solve an exercise in mathematical statistics. The problem is : If $X_1,...,X_n$ are $i.i.d$ random variables from $N(\mu,1)$, and if $Y_n$ is the maximum order statistics then what is the best unbiased estimator of $P(Y_n >a)$ for real $a$? I'm trying to use the Lehmann-Scheffe theorem. Since $T=\sum_1^n X_i$ is a complete sufficient statistic for $\mu$ so I want to compute the conditional expectation $E(U|T)$with some nice unbiased estimator $U$. I tried $U=1$  if  $Y_n>a$ and $U=0$   otherwise. But in this case I cannot compute the conditional expectation explicitly. Is my approach valid? Any hint or answer would be appreciated.","I'm trying to solve an exercise in mathematical statistics. The problem is : If $X_1,...,X_n$ are $i.i.d$ random variables from $N(\mu,1)$, and if $Y_n$ is the maximum order statistics then what is the best unbiased estimator of $P(Y_n >a)$ for real $a$? I'm trying to use the Lehmann-Scheffe theorem. Since $T=\sum_1^n X_i$ is a complete sufficient statistic for $\mu$ so I want to compute the conditional expectation $E(U|T)$with some nice unbiased estimator $U$. I tried $U=1$  if  $Y_n>a$ and $U=0$   otherwise. But in this case I cannot compute the conditional expectation explicitly. Is my approach valid? Any hint or answer would be appreciated.",,"['statistics', 'order-statistics']"
14,Comparing the variances of two distributions,Comparing the variances of two distributions,,"$X$ and $Y$ are discrete random variables with means $x$ and $y$ and variances $V_x$ and $V_y$, respectively. Does the ratio $V_x / V_y$ have meaning, and, if so, what is it?","$X$ and $Y$ are discrete random variables with means $x$ and $y$ and variances $V_x$ and $V_y$, respectively. Does the ratio $V_x / V_y$ have meaning, and, if so, what is it?",,['statistics']
15,Evaluating a probability density function using polar coordinates,Evaluating a probability density function using polar coordinates,,"I'm looking at the following probability density function: $$\sqrt{5+x^2+y^2}$$ where $$ 1 \le x^2+y^2 \le 4 $$ I'm trying to find the $P(0<X<3Y)$ and to do this I've converted this to polar coordinates and am trying to take the integral to get the probability: $$ \int\int \sqrt{1+r^2}*r*drd\theta $$ I'm really unsure how to assign the bounds for this, and if anyone could point me in the right direction I'd appreciate it","I'm looking at the following probability density function: $$\sqrt{5+x^2+y^2}$$ where $$ 1 \le x^2+y^2 \le 4 $$ I'm trying to find the $P(0<X<3Y)$ and to do this I've converted this to polar coordinates and am trying to take the integral to get the probability: $$ \int\int \sqrt{1+r^2}*r*drd\theta $$ I'm really unsure how to assign the bounds for this, and if anyone could point me in the right direction I'd appreciate it",,"['probability', 'statistics']"
16,Confusion - Am I on the right track on this power computation?,Confusion - Am I on the right track on this power computation?,,"So the question asks: It has been generally believed that average daily caffeine consumption, $μ$, is at most $200$ mg with $σ^2 = 225$.  To examine whether at present time $μ$ is greater than $200$ mg, it is agreed that daily caffeine consumption of a random sample of $100$ adults be examined.  If the sample mean is greater than $203.50$, the decision will be to reject the null hypothesis. The following information may be useful: pnorm(0.67) $=0.75$, pnorm(1) $=0.84,$ pnorm(1.56) $=0.94$, pnorm(2.33) $=0.99$ (a) What are the null and alternative hypotheses? (b) What is the test statistic and what is it distribution? (c) What is the probability of a Type 1 error? (d) What is the power of the test if the true mean is 205mg? (e) Is the assumption that the population distribution of daily caffeine consumption is normal necessary for the hypothesis test? Explain your reasoning. My answers: (a) $H_0: μ \le 200$ (average daily caffeine consumption is at most $200mg$) $H_1: μ > 200$ (average daily caffeine consumption is more than $200mg$) (b) For large sample, and known population standard deviation, use 1-sample $Z$ test. Distribution: Normal. $$Z=\frac{\bar X-μ}{\sigma/\sqrt{n}} =\frac{203.50-200}{15/10} =2.3333.$$ (c) probability of Type I error, $\alpha=0.05$ (d) Since it is a right-tailed test, therefore, one commits a Type II error (fail to reject $H_0$), when one gets a test statistic less than 1.645. Compute $X_\text{critical}$ by substituting the value in following Z score formula $Z =1.64=\frac{X_\text{critical}-\mu}{\sigma/\sqrt{n}}=\frac{X_\text{critical}-200}{1.5}$ $X_\text{critical}=202.46$ $$P(\bar X<202.46)=P\left(Z<\frac{202.46-205}{1.5}\right)=P(Z<-1.69333333)=0.0455.$$ Power of test: $1-0.0455 =0.9545.$ (e) Not necessary because the sample size is sufficiently large. So I am not sure about my answers in d and e. Should I calculate the new x, then use z-test to get the power of the test? And in e, does my answer sound reasonable enough?","So the question asks: It has been generally believed that average daily caffeine consumption, $μ$, is at most $200$ mg with $σ^2 = 225$.  To examine whether at present time $μ$ is greater than $200$ mg, it is agreed that daily caffeine consumption of a random sample of $100$ adults be examined.  If the sample mean is greater than $203.50$, the decision will be to reject the null hypothesis. The following information may be useful: pnorm(0.67) $=0.75$, pnorm(1) $=0.84,$ pnorm(1.56) $=0.94$, pnorm(2.33) $=0.99$ (a) What are the null and alternative hypotheses? (b) What is the test statistic and what is it distribution? (c) What is the probability of a Type 1 error? (d) What is the power of the test if the true mean is 205mg? (e) Is the assumption that the population distribution of daily caffeine consumption is normal necessary for the hypothesis test? Explain your reasoning. My answers: (a) $H_0: μ \le 200$ (average daily caffeine consumption is at most $200mg$) $H_1: μ > 200$ (average daily caffeine consumption is more than $200mg$) (b) For large sample, and known population standard deviation, use 1-sample $Z$ test. Distribution: Normal. $$Z=\frac{\bar X-μ}{\sigma/\sqrt{n}} =\frac{203.50-200}{15/10} =2.3333.$$ (c) probability of Type I error, $\alpha=0.05$ (d) Since it is a right-tailed test, therefore, one commits a Type II error (fail to reject $H_0$), when one gets a test statistic less than 1.645. Compute $X_\text{critical}$ by substituting the value in following Z score formula $Z =1.64=\frac{X_\text{critical}-\mu}{\sigma/\sqrt{n}}=\frac{X_\text{critical}-200}{1.5}$ $X_\text{critical}=202.46$ $$P(\bar X<202.46)=P\left(Z<\frac{202.46-205}{1.5}\right)=P(Z<-1.69333333)=0.0455.$$ Power of test: $1-0.0455 =0.9545.$ (e) Not necessary because the sample size is sufficiently large. So I am not sure about my answers in d and e. Should I calculate the new x, then use z-test to get the power of the test? And in e, does my answer sound reasonable enough?",,"['probability', 'statistics', 'probability-distributions', 'normal-distribution', 'hypothesis-testing']"
17,Geometry behind least squares under constraints,Geometry behind least squares under constraints,,"I'm trying to solve the following minimisation problem by Lagrange multipliers. My questions is: How to interpret the solutions geometrically? Given a dataset $x_1, \dots, x_n \in \mathbb R^d$, a parameter vector $\theta \in \mathbb R^d$ and some $b \in \mathbb R^d$, I want to minimise $$J(\theta) = \sum_{k=1}^n \lVert \theta - x_k \rVert^2$$ with respect to $\theta$ under the constraints $\theta^T b = 0$, $\lVert \theta - c \rVert^2 = 1$. For 1., I put $\mathcal L(\theta,\lambda) = J(\theta) - \lambda \theta^T b$, $\lambda \in \mathbb R$, and set $$\frac{\partial}{\partial \theta}\mathcal L(\theta,\lambda) =\sum_{k=1}^n \frac{\partial}{\partial \theta} \lVert \theta - x_k \rVert^2 - \frac{\partial}{\partial \theta} \lambda \theta^T b =\sum_{k=1}^n 2(\theta-x_k) - \lambda b = 0.$$ I'm somewhat shaky about the vector calculus, but I hope it's correct? Anyway, this is equivalent to $n \theta - n \bar x = \frac{1}{2} \lambda b$  and gives $\theta_0 = \frac{1}{2n} \lambda b + \frac{1}{n} \bar x $ where $\bar x$ is the sample mean. $\theta_0$ satisfies $\nabla J(\theta) = \lambda \nabla \theta^T b$. By the constraint ${\theta_0}^T b = 0$ we get $\lambda = -2 {\bar x}^T \frac{b}{\lVert b \rVert}$. Finally, this yields $$\theta_0 = \frac{1}{n} \bar x \left(1-\frac{b}{\lVert b \rVert}\right).$$ For 2. I get $$\frac{\partial}{\partial \theta}\mathcal L(\theta,\lambda) =\sum_{k=1}^n \frac{\partial}{\partial \theta} \lVert \theta - x_k \rVert^2 - \frac{\partial}{\partial \theta} \lVert \theta - c \rVert^2 - 1 =\sum_{k=1}^n 2(\theta-x_k) - 2 \lambda (\theta - c)b.$$ Setting this equal to zero gives $$\theta_0 = \frac{1}{n-\lambda}\left(n \bar x + \lambda c\right).$$ It looks rather messy to feed this into the constraint to compute $\lambda$. Is there some trick I'm missing? Anyway, my problem is that the exercise suggested a geometric meaning behind all of this and I have no clue. Could someone explain to me what's going on?","I'm trying to solve the following minimisation problem by Lagrange multipliers. My questions is: How to interpret the solutions geometrically? Given a dataset $x_1, \dots, x_n \in \mathbb R^d$, a parameter vector $\theta \in \mathbb R^d$ and some $b \in \mathbb R^d$, I want to minimise $$J(\theta) = \sum_{k=1}^n \lVert \theta - x_k \rVert^2$$ with respect to $\theta$ under the constraints $\theta^T b = 0$, $\lVert \theta - c \rVert^2 = 1$. For 1., I put $\mathcal L(\theta,\lambda) = J(\theta) - \lambda \theta^T b$, $\lambda \in \mathbb R$, and set $$\frac{\partial}{\partial \theta}\mathcal L(\theta,\lambda) =\sum_{k=1}^n \frac{\partial}{\partial \theta} \lVert \theta - x_k \rVert^2 - \frac{\partial}{\partial \theta} \lambda \theta^T b =\sum_{k=1}^n 2(\theta-x_k) - \lambda b = 0.$$ I'm somewhat shaky about the vector calculus, but I hope it's correct? Anyway, this is equivalent to $n \theta - n \bar x = \frac{1}{2} \lambda b$  and gives $\theta_0 = \frac{1}{2n} \lambda b + \frac{1}{n} \bar x $ where $\bar x$ is the sample mean. $\theta_0$ satisfies $\nabla J(\theta) = \lambda \nabla \theta^T b$. By the constraint ${\theta_0}^T b = 0$ we get $\lambda = -2 {\bar x}^T \frac{b}{\lVert b \rVert}$. Finally, this yields $$\theta_0 = \frac{1}{n} \bar x \left(1-\frac{b}{\lVert b \rVert}\right).$$ For 2. I get $$\frac{\partial}{\partial \theta}\mathcal L(\theta,\lambda) =\sum_{k=1}^n \frac{\partial}{\partial \theta} \lVert \theta - x_k \rVert^2 - \frac{\partial}{\partial \theta} \lVert \theta - c \rVert^2 - 1 =\sum_{k=1}^n 2(\theta-x_k) - 2 \lambda (\theta - c)b.$$ Setting this equal to zero gives $$\theta_0 = \frac{1}{n-\lambda}\left(n \bar x + \lambda c\right).$$ It looks rather messy to feed this into the constraint to compute $\lambda$. Is there some trick I'm missing? Anyway, my problem is that the exercise suggested a geometric meaning behind all of this and I have no clue. Could someone explain to me what's going on?",,"['statistics', 'multivariable-calculus', 'optimization', 'least-squares']"
18,A non-existence example of a sufficient statistic,A non-existence example of a sufficient statistic,,"In parametric statistical inference, a statistic $T$ of some variable $X$ (thought of as experimental or observational data) is sufficient for the parameter $\theta$ if is captures the essential information in the data $X$ about the parameter $\theta$ (there are several equivalent definitions for this). It is implicitly understood that the random variable $X$ has a probability distribution $f(x;\theta)$, where the parameter $\theta$ is of course unknown. Related is the concept of a minimal sufficient statistic , which captures nothing more than the essential. Is it true that any random variable $X$ as above has a sufficient statistic? Suppose $X$ has a sufficient statistic $T$. Must it also have a minimal sufficient statistic? I'd be glad to have either a concise proof or a simple counter-example for each of these two.","In parametric statistical inference, a statistic $T$ of some variable $X$ (thought of as experimental or observational data) is sufficient for the parameter $\theta$ if is captures the essential information in the data $X$ about the parameter $\theta$ (there are several equivalent definitions for this). It is implicitly understood that the random variable $X$ has a probability distribution $f(x;\theta)$, where the parameter $\theta$ is of course unknown. Related is the concept of a minimal sufficient statistic , which captures nothing more than the essential. Is it true that any random variable $X$ as above has a sufficient statistic? Suppose $X$ has a sufficient statistic $T$. Must it also have a minimal sufficient statistic? I'd be glad to have either a concise proof or a simple counter-example for each of these two.",,"['statistics', 'statistical-inference']"
19,Probability - long-run proportion,Probability - long-run proportion,,"So the problem asks: A zoo owns a population of rare Galapagos turtles. The turtles bring in a lot of visitors but unfortunately do not breed in captivity. To maintain the population, new turtles are brought in at a rate of 0.3/year. The scientists are still not sure about the mortality of these species, so for simplicity the zookeeper assumes that the longevity of each turtle has exponential distribution with mean $30$ years. Find the long-run proportion of time when there are two or fewer turtles in the zoo. My approach: from the given information, the longevity of each turtle has exponential distribution with mean = 1/$\theta$ = $30$ yrs Therefore, the longevity follows exponential distribution with parameter $\theta$ $= 1/30=0.033yrs $ By the probability distribution of exponential distribution,  $p(x≤2)=p(x=0)+p(x=1)+p(x=2)$ $=0.033e^{-0.033*0}+0.033e^{-0.033*1}+0.033e^{-0.033*2}$ $=0.0639$ Is this the right approach to do these kinds of problems?","So the problem asks: A zoo owns a population of rare Galapagos turtles. The turtles bring in a lot of visitors but unfortunately do not breed in captivity. To maintain the population, new turtles are brought in at a rate of 0.3/year. The scientists are still not sure about the mortality of these species, so for simplicity the zookeeper assumes that the longevity of each turtle has exponential distribution with mean $30$ years. Find the long-run proportion of time when there are two or fewer turtles in the zoo. My approach: from the given information, the longevity of each turtle has exponential distribution with mean = 1/$\theta$ = $30$ yrs Therefore, the longevity follows exponential distribution with parameter $\theta$ $= 1/30=0.033yrs $ By the probability distribution of exponential distribution,  $p(x≤2)=p(x=0)+p(x=1)+p(x=2)$ $=0.033e^{-0.033*0}+0.033e^{-0.033*1}+0.033e^{-0.033*2}$ $=0.0639$ Is this the right approach to do these kinds of problems?",,"['probability', 'statistics', 'probability-distributions', 'exponential-distribution']"
20,Is it possible to quantify the quality of a probability estimator?,Is it possible to quantify the quality of a probability estimator?,,"Given a number of sources of probability estimates, what is the best way to quantify the ""best"" source. For example, let's say I have two sources of estimates, A and B. If A says the probabilities are [.3, .5, .4, .9, .8] and B says the probabilities are [.7, .9, .5, .5, .6] and the event results are [false, false, true, true, false], how does one generally establish whether A or B was ""better?"" I've been asked to clarify the specifics of the question, but my question is less about a specific solution and more that I'm interested in all the angles from which this problem is attacked. If I were pressed into providing specifics, I'd point to a pair of thoughts I've had about this. First, when I hear people say, ""I'm 30% sure that...."" or, ""There's only a 10% chance of that ever happening,"" I have wondered how you could gauge that person's skill at guessing probabilities. Clearly, I could collect a few hundred samples from that individual and see if the stuff he labels at 10% happens roughly 10% of the time, his 20s 20% of the time, 30s 30%, etc. But if the sample set is, say, a dozen different estimates covering the range from 0.0 to 1.0, how do you assess the quality of those estimates? This is a question that's been tickling the back of my mind for years. Second, I might be writing a genetic algorithm that will look at current, highly local, weather patterns and guess the probability of the wind switching to 15-20MPH between SW and NW. I have decades of historical data, taken every few minutes, to train with, but analyzing the fitness of an individual in the gene pool hinges on that individual's accuracy in guessing probabilities.","Given a number of sources of probability estimates, what is the best way to quantify the ""best"" source. For example, let's say I have two sources of estimates, A and B. If A says the probabilities are [.3, .5, .4, .9, .8] and B says the probabilities are [.7, .9, .5, .5, .6] and the event results are [false, false, true, true, false], how does one generally establish whether A or B was ""better?"" I've been asked to clarify the specifics of the question, but my question is less about a specific solution and more that I'm interested in all the angles from which this problem is attacked. If I were pressed into providing specifics, I'd point to a pair of thoughts I've had about this. First, when I hear people say, ""I'm 30% sure that...."" or, ""There's only a 10% chance of that ever happening,"" I have wondered how you could gauge that person's skill at guessing probabilities. Clearly, I could collect a few hundred samples from that individual and see if the stuff he labels at 10% happens roughly 10% of the time, his 20s 20% of the time, 30s 30%, etc. But if the sample set is, say, a dozen different estimates covering the range from 0.0 to 1.0, how do you assess the quality of those estimates? This is a question that's been tickling the back of my mind for years. Second, I might be writing a genetic algorithm that will look at current, highly local, weather patterns and guess the probability of the wind switching to 15-20MPH between SW and NW. I have decades of historical data, taken every few minutes, to train with, but analyzing the fitness of an individual in the gene pool hinges on that individual's accuracy in guessing probabilities.",,"['probability', 'statistics', 'machine-learning', 'estimation']"
21,Linear regression using mean absolute error,Linear regression using mean absolute error,,"Is the regression using the mean squared error any different if the absolute error is used? Assuming the formula is $Y = ax + b$ and both a and b are found using the mean squared error, would they be different than with the other method? Should I take the formula of the mean abs error and minimize it?","Is the regression using the mean squared error any different if the absolute error is used? Assuming the formula is $Y = ax + b$ and both a and b are found using the mean squared error, would they be different than with the other method? Should I take the formula of the mean abs error and minimize it?",,"['statistics', 'regression']"
22,Expected number of rejected null hypotheses using FDR,Expected number of rejected null hypotheses using FDR,,"Problem: Let $X_1, X_2, \dots, X_{500}$ be independently identically distributed. For a constant $a$, suppose we know the probability $$P(X_i\leq k*a)\ \forall k = 1,\dots , 500.$$ We now sort the $X$'s so that $X_{(1)}\leq X_{(2)}\leq \dots\leq X_{(500)}$. Find the expectation $E(K)$, $K = \max(k)$ where $k$ satisfies $X_{(k)}\leq k*a.$ My attempt: I don't really have any rigorous proof, but I simply think of this as an ""average"" problem, and so the answer would be $$E(K) = \sum_{k=1}^{500}P(X_i\leq k*a).$$ Note: You may notice that this problem relates to false discovery rate. I have been banging my head against the wall for couple days and can't seem to get anywhere. Any help/suggestions/ideas are much appreciated!","Problem: Let $X_1, X_2, \dots, X_{500}$ be independently identically distributed. For a constant $a$, suppose we know the probability $$P(X_i\leq k*a)\ \forall k = 1,\dots , 500.$$ We now sort the $X$'s so that $X_{(1)}\leq X_{(2)}\leq \dots\leq X_{(500)}$. Find the expectation $E(K)$, $K = \max(k)$ where $k$ satisfies $X_{(k)}\leq k*a.$ My attempt: I don't really have any rigorous proof, but I simply think of this as an ""average"" problem, and so the answer would be $$E(K) = \sum_{k=1}^{500}P(X_i\leq k*a).$$ Note: You may notice that this problem relates to false discovery rate. I have been banging my head against the wall for couple days and can't seem to get anywhere. Any help/suggestions/ideas are much appreciated!",,"['probability', 'statistics', 'expectation', 'hypothesis-testing']"
23,Is it possible to derive the equation for the arithmetic mean?,Is it possible to derive the equation for the arithmetic mean?,,"As I understand it, the arithmetic mean is a measure of central tendency , i.e. it is a value that quantifies the location of the centre of a distribution of data points (the point about which the data tends to cluster). My question is, is it possible to derive the formula for the arithmetic mean, $\bar{x}$ of a discrete set of data: $$\bar{x}=\frac{1}{N}\sum_{i=1}^{N}x_{i}$$ where $N$ is the total number of data points and $\lbrace x_{i}\rbrace$ are the data points. I have attempted a derivation, but I'm unsure whether it is valid: Suppose one has a finite , discrete set of $N$ data points $\lbrace x_{i}\rbrace_{i=1,\ldots N}$. Assuming this set has a central value (i.e. a mean value), then by definition, the sum of positive deviations should be equal to the sum of negative deviations from this central value (where by positive deviation , we mean that a given data point $x_{i}$ is deviated from the central value $\bar{x}$ by an amount $x_{i}-\bar{x}$ and by negative deviation , that a given data point is deviated from the central value by an amount $\bar{x}-x_{i}$). Now, if we rearrange the set of data points into two subsets, one containing all points each of whose value is less than the central value, i.e. $x_{1},x_{2},\ldots,x_{i}<\bar{x}$, and the other containing all points each of whose value is greater than, or equal to the central value, i.e. $x_{i+1},x_{i+2},\ldots,x_{N}\geq\bar{x}$. It follows that, $$\left(x_{N}-\bar{x}\right)+\left(x_{N-1}-\bar{x}\right)+\cdots +\left(x_{i+1}-\bar{x}\right)-\left(\bar{x}-x_{i}\right)-\left(\bar{x}-x_{i-1}\right)-\cdots -\left(\bar{x}-x_{1}\right)=0$$ Which, upon rearranging terms, gives $$x_{1}+x_{2}+\cdots +x_{i-1}+x_{i}+x_{i+1}+\cdots +x_{N-1}+x_{N}-N\bar{x}=\sum_{i=1}^{N}x_{i}-N\bar{x}=0\\ \Rightarrow\qquad\bar{x}=\frac{1}{N}\sum_{i=1}^{N}x_{i}\;\;.$$","As I understand it, the arithmetic mean is a measure of central tendency , i.e. it is a value that quantifies the location of the centre of a distribution of data points (the point about which the data tends to cluster). My question is, is it possible to derive the formula for the arithmetic mean, $\bar{x}$ of a discrete set of data: $$\bar{x}=\frac{1}{N}\sum_{i=1}^{N}x_{i}$$ where $N$ is the total number of data points and $\lbrace x_{i}\rbrace$ are the data points. I have attempted a derivation, but I'm unsure whether it is valid: Suppose one has a finite , discrete set of $N$ data points $\lbrace x_{i}\rbrace_{i=1,\ldots N}$. Assuming this set has a central value (i.e. a mean value), then by definition, the sum of positive deviations should be equal to the sum of negative deviations from this central value (where by positive deviation , we mean that a given data point $x_{i}$ is deviated from the central value $\bar{x}$ by an amount $x_{i}-\bar{x}$ and by negative deviation , that a given data point is deviated from the central value by an amount $\bar{x}-x_{i}$). Now, if we rearrange the set of data points into two subsets, one containing all points each of whose value is less than the central value, i.e. $x_{1},x_{2},\ldots,x_{i}<\bar{x}$, and the other containing all points each of whose value is greater than, or equal to the central value, i.e. $x_{i+1},x_{i+2},\ldots,x_{N}\geq\bar{x}$. It follows that, $$\left(x_{N}-\bar{x}\right)+\left(x_{N-1}-\bar{x}\right)+\cdots +\left(x_{i+1}-\bar{x}\right)-\left(\bar{x}-x_{i}\right)-\left(\bar{x}-x_{i-1}\right)-\cdots -\left(\bar{x}-x_{1}\right)=0$$ Which, upon rearranging terms, gives $$x_{1}+x_{2}+\cdots +x_{i-1}+x_{i}+x_{i+1}+\cdots +x_{N-1}+x_{N}-N\bar{x}=\sum_{i=1}^{N}x_{i}-N\bar{x}=0\\ \Rightarrow\qquad\bar{x}=\frac{1}{N}\sum_{i=1}^{N}x_{i}\;\;.$$",,"['statistics', 'intuition', 'means']"
24,Convergence of the 2-sample Kolmogorov-Smirnov,Convergence of the 2-sample Kolmogorov-Smirnov,,"Here is my problem, I have two empirical distribution functions $F_n(x)$ and $G_n(x)$ constructed from two data sets with $n$ points each and I estimate their 2-sample Kolmogorov-Smirnov (2-KS) statistic as $D_n \equiv \sup_x \{F_n(x) - G_n(x) \}$. By the Glivenko-Cantelli theorem, the sequence $D_n$ converges uniformly to a value $D_{\infty}$ almost surely. If $F_n$ and $G_n$ are realisations of the same underlying distribution, then $D_{\infty} = 0$ otherwise we have $D_{\infty} > 0$. My problem is to know whether I can say anything about $D_{\infty}$ if I know only the values of $D_n$ for $n \in I = [1,n_{max}]$...because in practice I cannot generate infinite amount of data. In particular, I had the (possibly wrong) ""feeling"" that if $D_n \leq a$ for almost all $n \in I$ and if $D_n$ has a decreasing trend on $I$, then I could say that $D_{\infty} \leq a$ in some sense or with some confidence. I have no problem if this is only true with some probability but I do not know how to formulate such a statement rigorously, if it has any chance of holding at all of course.","Here is my problem, I have two empirical distribution functions $F_n(x)$ and $G_n(x)$ constructed from two data sets with $n$ points each and I estimate their 2-sample Kolmogorov-Smirnov (2-KS) statistic as $D_n \equiv \sup_x \{F_n(x) - G_n(x) \}$. By the Glivenko-Cantelli theorem, the sequence $D_n$ converges uniformly to a value $D_{\infty}$ almost surely. If $F_n$ and $G_n$ are realisations of the same underlying distribution, then $D_{\infty} = 0$ otherwise we have $D_{\infty} > 0$. My problem is to know whether I can say anything about $D_{\infty}$ if I know only the values of $D_n$ for $n \in I = [1,n_{max}]$...because in practice I cannot generate infinite amount of data. In particular, I had the (possibly wrong) ""feeling"" that if $D_n \leq a$ for almost all $n \in I$ and if $D_n$ has a decreasing trend on $I$, then I could say that $D_{\infty} \leq a$ in some sense or with some confidence. I have no problem if this is only true with some probability but I do not know how to formulate such a statement rigorously, if it has any chance of holding at all of course.",,"['probability', 'statistics', 'convergence-divergence']"
25,Multivariate mean value theorem in statistics context,Multivariate mean value theorem in statistics context,,"I am trying to understand the proof of the following theorem. As first step, he uses the mean value theorem for a multivariate function. After research online, it seems that this theorem does not generalize to such functions. Could anyone guide me to what the author really says? Thanks,the theorem is below.","I am trying to understand the proof of the following theorem. As first step, he uses the mean value theorem for a multivariate function. After research online, it seems that this theorem does not generalize to such functions. Could anyone guide me to what the author really says? Thanks,the theorem is below.",,"['calculus', 'real-analysis', 'statistics', 'multivariable-calculus']"
26,Uniform Integrability - proof,Uniform Integrability - proof,,"I came across a proof for the following proposition. However, there is one part of the proof which I don't understand. The proposition and proof are as follow. Proposition: A nonempty family $\mathcal{X} ⊆ L^0$ is uniformly integrable if and only if there exists a test function of uniform integrability $ϕ$ such that $\sup_{ X∈\mathcal{X}} \mathbb{E}[ϕ(|X|)] < ∞$. Moreover, if it exists, the function ϕ can be chosen in the class of nondecreasing convex functions. Proof (partial): Suppose, first, that this condition holds for some test function of uniform integrability and that the value of the supremum is $0 ≤ M < ∞$. For $n > 0$, there exists $C_n ∈ \mathbb{R}$ such that $ϕ(x) ≥ nMx$, for $x ≥ C_n$. Therefore,  $$M ≥ \mathbb{E}[ϕ(|X|)] ≥ \mathbb{E}[ϕ(|X|)\textbf{1}_{{|X|≥C_n}}] ≥ nM\mathbb{E}[|X| \textbf{1}_{{|X|≥C_n}}],$$ for all $X ∈ \mathcal{X}$ . Hence, $$\sup_{X∈\mathcal{X}} \mathbb{E}[|X| \textbf{1}_{{|X|≥C_n}}] ≤ 1/n$$  and the uniform integrability of X follows. In the above proof, can someone explain to me the part ""For $n > 0$, there exists $C_n ∈ \mathbb{R}$ such that $ϕ(x) ≥ nMx$, for $x ≥ C_n$.""?","I came across a proof for the following proposition. However, there is one part of the proof which I don't understand. The proposition and proof are as follow. Proposition: A nonempty family $\mathcal{X} ⊆ L^0$ is uniformly integrable if and only if there exists a test function of uniform integrability $ϕ$ such that $\sup_{ X∈\mathcal{X}} \mathbb{E}[ϕ(|X|)] < ∞$. Moreover, if it exists, the function ϕ can be chosen in the class of nondecreasing convex functions. Proof (partial): Suppose, first, that this condition holds for some test function of uniform integrability and that the value of the supremum is $0 ≤ M < ∞$. For $n > 0$, there exists $C_n ∈ \mathbb{R}$ such that $ϕ(x) ≥ nMx$, for $x ≥ C_n$. Therefore,  $$M ≥ \mathbb{E}[ϕ(|X|)] ≥ \mathbb{E}[ϕ(|X|)\textbf{1}_{{|X|≥C_n}}] ≥ nM\mathbb{E}[|X| \textbf{1}_{{|X|≥C_n}}],$$ for all $X ∈ \mathcal{X}$ . Hence, $$\sup_{X∈\mathcal{X}} \mathbb{E}[|X| \textbf{1}_{{|X|≥C_n}}] ≤ 1/n$$  and the uniform integrability of X follows. In the above proof, can someone explain to me the part ""For $n > 0$, there exists $C_n ∈ \mathbb{R}$ such that $ϕ(x) ≥ nMx$, for $x ≥ C_n$.""?",,['statistics']
27,How does the parameters of F-Test affects its power?,How does the parameters of F-Test affects its power?,,"Suppose we have $z = \frac{u/p}{v/q} \sim F(p, q, \lambda)$ whereby u is distributed as a non-central chi-square with parameters p and $\lambda$. The power of an F-Test is the probability of rejecting $H_0$ for a given value of $\lambda$. If $F_\alpha$ is the upper $\alpha$ percentage point of the central $F$ distribution, then the power, $P(p,q,\alpha,\lambda)$ can be defined as $P(p,q,\alpha, \lambda) = Prob(z\geq F_\alpha)$. According to my textbook, if p increases, $P(p,q,\alpha, \lambda)$ decrease, and if $q, \alpha \text{ or } \lambda$ increases, $P(p,q, \alpha, \lambda)$ increases. How to understand the effects of the change in parameters value on the power of F-test? What is the proof for it?","Suppose we have $z = \frac{u/p}{v/q} \sim F(p, q, \lambda)$ whereby u is distributed as a non-central chi-square with parameters p and $\lambda$. The power of an F-Test is the probability of rejecting $H_0$ for a given value of $\lambda$. If $F_\alpha$ is the upper $\alpha$ percentage point of the central $F$ distribution, then the power, $P(p,q,\alpha,\lambda)$ can be defined as $P(p,q,\alpha, \lambda) = Prob(z\geq F_\alpha)$. According to my textbook, if p increases, $P(p,q,\alpha, \lambda)$ decrease, and if $q, \alpha \text{ or } \lambda$ increases, $P(p,q, \alpha, \lambda)$ increases. How to understand the effects of the change in parameters value on the power of F-test? What is the proof for it?",,['statistics']
28,Model Selection property between AIC and Mallow's $C_p$,Model Selection property between AIC and Mallow's,C_p,"Let us consider a set of linear models defined by the function $Y_i = \beta X_i + \epsilon_i, \epsilon_i \sim N(0,\sigma^2).$ Take a model $S$, and define the training error of a given model as $\hat{R}_\text{tr}(S) = \sum_{i=1}^n (\hat{Y}_i(S) - Y_i)^2.$ We define Mallow's $C_p$ statistic as $$\hat{R}(S) = \hat{R}_\text{tr}(S) + 2|S|\hat{\sigma}^2,$$ where $|S|$ denotes the number of terms in the model $S$ and $\hat{\sigma}^2$ is the estimate of $\sigma^2$ obtained for the full model. Consider the AIC function of a model to be $AIC(S) = l_S - |S|,$ where $l_S$  is the log-likelihood of the model evaluated at the MLE. I would like to show that, given $\sigma$ as known, that $\arg\max_S AIC(S) = \arg\min_S \hat{R}(S).$ I was having some trouble showing this statement using general unconstrained optimization, in particular because I am not entirely sure how to handle the derivative of the function for Mallow's $C_p$ given that we have $|S|$ in the second term of that function. Is there a better way to show this particular statement?","Let us consider a set of linear models defined by the function $Y_i = \beta X_i + \epsilon_i, \epsilon_i \sim N(0,\sigma^2).$ Take a model $S$, and define the training error of a given model as $\hat{R}_\text{tr}(S) = \sum_{i=1}^n (\hat{Y}_i(S) - Y_i)^2.$ We define Mallow's $C_p$ statistic as $$\hat{R}(S) = \hat{R}_\text{tr}(S) + 2|S|\hat{\sigma}^2,$$ where $|S|$ denotes the number of terms in the model $S$ and $\hat{\sigma}^2$ is the estimate of $\sigma^2$ obtained for the full model. Consider the AIC function of a model to be $AIC(S) = l_S - |S|,$ where $l_S$  is the log-likelihood of the model evaluated at the MLE. I would like to show that, given $\sigma$ as known, that $\arg\max_S AIC(S) = \arg\min_S \hat{R}(S).$ I was having some trouble showing this statement using general unconstrained optimization, in particular because I am not entirely sure how to handle the derivative of the function for Mallow's $C_p$ given that we have $|S|$ in the second term of that function. Is there a better way to show this particular statement?",,['statistics']
29,How to use Roberto Frucht Formula to find permutations with limited repitition,How to use Roberto Frucht Formula to find permutations with limited repitition,,"I asked a question at this Number of arrangements of red, blue, and green balls in which a maximum of three balls of the same color are placed in the five slots . Now the scenario is the same I have a bag of three balls (look at the link) red blue green and I have 5 slots.. Every time I pull a ball from the bag I placed it in a slot. I keep randomly pulling balls from the bag and fill five slots..when all five slots are filled, repeat the process I still want to number of arrangements of red, blue, and green balls in which a maximum of three balls of the same color are placed in the five slots I found an interesting article by Roberto Frucht (1966), Permutations with limited repetitions that derives a formula to do this. I want to find the results using this breakthrough formula: for ""the number of $r$-permutations (called variations, r at a time in the older literature) with limited repetition, where each one of the $n$ different things to be permuted may appear at most $s$ times."" Note: In the professor's research he gives an example that shows how many permutations can be computed if 4 items are chosen from 7 items where only a maximum of two items and repeat itself in the arrangement. Note the formula shows that Bell polynomials and Stirling Strings of the second kind play a significant role in deriving the formula. I am requesting some practical help as to how to use this formula.Specifically, plugging values in and getting the expected results.","I asked a question at this Number of arrangements of red, blue, and green balls in which a maximum of three balls of the same color are placed in the five slots . Now the scenario is the same I have a bag of three balls (look at the link) red blue green and I have 5 slots.. Every time I pull a ball from the bag I placed it in a slot. I keep randomly pulling balls from the bag and fill five slots..when all five slots are filled, repeat the process I still want to number of arrangements of red, blue, and green balls in which a maximum of three balls of the same color are placed in the five slots I found an interesting article by Roberto Frucht (1966), Permutations with limited repetitions that derives a formula to do this. I want to find the results using this breakthrough formula: for ""the number of $r$-permutations (called variations, r at a time in the older literature) with limited repetition, where each one of the $n$ different things to be permuted may appear at most $s$ times."" Note: In the professor's research he gives an example that shows how many permutations can be computed if 4 items are chosen from 7 items where only a maximum of two items and repeat itself in the arrangement. Note the formula shows that Bell polynomials and Stirling Strings of the second kind play a significant role in deriving the formula. I am requesting some practical help as to how to use this formula.Specifically, plugging values in and getting the expected results.",,"['combinatorics', 'statistics']"
30,Derive a UMP test,Derive a UMP test,,"Let $F$ and $G$ be two known absolutely continous c.d.f's on the real line with p.d.f's $f$ and $ g$. Assume we have a single observation $X$ drawn from the c.d.f: $$\theta F(x)+(1-\theta)G(x),~~\theta\in(0,1)$$ Given $0<\theta_{0}<1$, how to derive a UMP test of size $\alpha$ for testing: $$H_0:\theta\leq\theta_0~~vs.~~H_1:\theta>\theta_0$$ My thought was to find a LRT, or to use Karlin–Rubin theorem, but didn't see a way to work it out.","Let $F$ and $G$ be two known absolutely continous c.d.f's on the real line with p.d.f's $f$ and $ g$. Assume we have a single observation $X$ drawn from the c.d.f: $$\theta F(x)+(1-\theta)G(x),~~\theta\in(0,1)$$ Given $0<\theta_{0}<1$, how to derive a UMP test of size $\alpha$ for testing: $$H_0:\theta\leq\theta_0~~vs.~~H_1:\theta>\theta_0$$ My thought was to find a LRT, or to use Karlin–Rubin theorem, but didn't see a way to work it out.",,"['probability', 'statistics', 'hypothesis-testing']"
31,Integrate squared sum,Integrate squared sum,,"This is a mathematical question, but with a statistical flavour. A little background: I have $N$ IID observations denoted by $w[n]$, from a uniform distribution $\mathcal{U}[0,\beta]$. Now, I know an unbiased estimator of $\beta$: $$\hat{\beta} = \frac{2}{N}\sum_{n=0}^{N-1}w[n]$$ and the variance of a uniform distribution is $\frac{\beta}{12}$ so a method to compute an estimator of $E[\hat{\sigma^2}]$ is to do this: $$E[\hat{\beta^2}] = E[\hat{\beta}]^2 + \operatorname{Var}(w[n])$$ It's simpler because I know the variance of the sum is the sum of the variances. But I'm trying to prove it using the expectation integral, and then I must solve: $$\frac{1}{12}E[\hat{\beta^2}]=\frac{2}{12N^2\beta} \int_0^\beta \left(\sum_{n=0}^{N-1}w[n]\right)^2 \, dw$$ where $\beta$ is a constant. How does one integrate a squared sum like this? The substitution method didn't seem to work very well. I tried to set $u=\sum_{n=0}^{N-1}w[n]$ such that $du=N$, and I integrate, and get the anti-integral $\frac{1}{3}\Big(\sum_{n=0}^{N-1}w[n]\Big)^3$. This gives a solution: $E[\hat{\beta^2}]=\frac{2N\beta^2}{36}$, but the answer is supposed to be $$E[\hat{\beta^2}]=\frac{1}{12}\Big(\beta^2+\frac{\beta^2}{36N}\Big)$$ Has anyone solved this before?","This is a mathematical question, but with a statistical flavour. A little background: I have $N$ IID observations denoted by $w[n]$, from a uniform distribution $\mathcal{U}[0,\beta]$. Now, I know an unbiased estimator of $\beta$: $$\hat{\beta} = \frac{2}{N}\sum_{n=0}^{N-1}w[n]$$ and the variance of a uniform distribution is $\frac{\beta}{12}$ so a method to compute an estimator of $E[\hat{\sigma^2}]$ is to do this: $$E[\hat{\beta^2}] = E[\hat{\beta}]^2 + \operatorname{Var}(w[n])$$ It's simpler because I know the variance of the sum is the sum of the variances. But I'm trying to prove it using the expectation integral, and then I must solve: $$\frac{1}{12}E[\hat{\beta^2}]=\frac{2}{12N^2\beta} \int_0^\beta \left(\sum_{n=0}^{N-1}w[n]\right)^2 \, dw$$ where $\beta$ is a constant. How does one integrate a squared sum like this? The substitution method didn't seem to work very well. I tried to set $u=\sum_{n=0}^{N-1}w[n]$ such that $du=N$, and I integrate, and get the anti-integral $\frac{1}{3}\Big(\sum_{n=0}^{N-1}w[n]\Big)^3$. This gives a solution: $E[\hat{\beta^2}]=\frac{2N\beta^2}{36}$, but the answer is supposed to be $$E[\hat{\beta^2}]=\frac{1}{12}\Big(\beta^2+\frac{\beta^2}{36N}\Big)$$ Has anyone solved this before?",,"['calculus', 'statistics']"
32,What is the average distance of two points chosen uniformly on a unit square? [duplicate],What is the average distance of two points chosen uniformly on a unit square? [duplicate],,"This question already has an answer here : Average distance between two random points in a square (1 answer) Closed 4 years ago . What is the average distance of two points chosen uniformly on a unit square? What I am asking is how to calculate $E\left(\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}\right)$ for $x_1, x_2, y_1, y_2$ spread uniformly on $[0,1]$.","This question already has an answer here : Average distance between two random points in a square (1 answer) Closed 4 years ago . What is the average distance of two points chosen uniformly on a unit square? What I am asking is how to calculate $E\left(\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}\right)$ for $x_1, x_2, y_1, y_2$ spread uniformly on $[0,1]$.",,"['probability', 'statistics']"
33,"Build skew normal distribution knowing the mean, max, and min","Build skew normal distribution knowing the mean, max, and min",,"Say I have a data point with included errors and I want to build some continuous distribution around it.  Normally this might be a Gaussian because one knows the sigma and mean right off the bat.  However, if you have asymmetric errors it becomes a lot harder.  It seems like you should be able to model a Gaussian about a data point with such errors using a skewed normal distribution, let me know if I am wrong. Essentially, I would like to know if there is a way to generate a standard normal distribution if you know the mean, max, and min?  The mean being the data point, max being the data point plus the upper bound, and min being the data point minus the lower bound.","Say I have a data point with included errors and I want to build some continuous distribution around it.  Normally this might be a Gaussian because one knows the sigma and mean right off the bat.  However, if you have asymmetric errors it becomes a lot harder.  It seems like you should be able to model a Gaussian about a data point with such errors using a skewed normal distribution, let me know if I am wrong. Essentially, I would like to know if there is a way to generate a standard normal distribution if you know the mean, max, and min?  The mean being the data point, max being the data point plus the upper bound, and min being the data point minus the lower bound.",,"['statistics', 'normal-distribution']"
34,Variance of sum of linear combination,Variance of sum of linear combination,,"I want to calculate the variance of a sum of linear combinations, so $$\operatorname{Var}\left(w'R_1 +  w'R_2\right)$$ where $w$ is a $N\times 1$ vector and both $R_1$ and $R_2$ are $N\times 1$ vectors as well. I have a cross autocorrelation matrix $Q$ which is a $N\times N$ matrix. Now the covariance matrix of $R_i$ is denoted by $\Sigma_i$. Uhm I guess $\operatorname{Var}(w'R_i)=w'\Sigma_iw$. Here is the thing $R_1$ and $R_2$ are correlated, hence the $Q$ matrix. How to calculate the above mentioned variance component?","I want to calculate the variance of a sum of linear combinations, so $$\operatorname{Var}\left(w'R_1 +  w'R_2\right)$$ where $w$ is a $N\times 1$ vector and both $R_1$ and $R_2$ are $N\times 1$ vectors as well. I have a cross autocorrelation matrix $Q$ which is a $N\times N$ matrix. Now the covariance matrix of $R_i$ is denoted by $\Sigma_i$. Uhm I guess $\operatorname{Var}(w'R_i)=w'\Sigma_iw$. Here is the thing $R_1$ and $R_2$ are correlated, hence the $Q$ matrix. How to calculate the above mentioned variance component?",,"['probability', 'statistics', 'random-variables', 'correlation']"
35,Derive the Hat Matrix to map actual response to estimated resposne,Derive the Hat Matrix to map actual response to estimated resposne,,"In order to measure the quality of a regression we can calculate the Hat Matrix. Using it we can estimate the response variable as if we used the predictor variables to regress them. For linear regression we can use $\hat{Y} = X \hat{\beta} = X(X^TX)^{-1}X^TY = P Y $ In order to calculate the Hat Matrix for the Nadaraya-Watson kernel regression regress we used following procedure in the lecture. Each column of the Hat Matrix is the predicted values for predictors x = (1, 2, ... n) and responses y = (0, ... 0, 1, 0, ... 0). Where 1 is at the position of the column index. I cannot connect these two methods to find the Hat Matrix. Is it correct that the Hat Matrix of the second case corresponds to the Hat Matrix of the first case, if the rows of X are x = (1, 2, ... n) like in the second case?","In order to measure the quality of a regression we can calculate the Hat Matrix. Using it we can estimate the response variable as if we used the predictor variables to regress them. For linear regression we can use $\hat{Y} = X \hat{\beta} = X(X^TX)^{-1}X^TY = P Y $ In order to calculate the Hat Matrix for the Nadaraya-Watson kernel regression regress we used following procedure in the lecture. Each column of the Hat Matrix is the predicted values for predictors x = (1, 2, ... n) and responses y = (0, ... 0, 1, 0, ... 0). Where 1 is at the position of the column index. I cannot connect these two methods to find the Hat Matrix. Is it correct that the Hat Matrix of the second case corresponds to the Hat Matrix of the first case, if the rows of X are x = (1, 2, ... n) like in the second case?",,"['linear-algebra', 'statistics', 'regression']"
36,Estimator bias and consistency,Estimator bias and consistency,,"Let $x_1, x_2, \ldots,x_n$ be a simple random sample from a random variable $X$ with support $\{0,1,2,3,4\}$ and probability function $p(0)=\frac{5}{12}(1-\lambda)^2$, $p(1)=\lambda$, $p(2)=\lambda(1-\lambda)$, $p(3)=\frac{1}{3}(1-\lambda)^2$ and $p(4)=\frac{1}{4}(1-\lambda)^2$, where $\lambda$ is a parameter $\in(0,1)$. Is this estimator   $$\hat \lambda=1+\frac{n}{n+1}-\bar X$$ unbiased and consistent for $\lambda$? $\bar X$ is sample mean. The expectation of $X$ is: $$\mathbb{E}(X)=0\cdot\frac{5}{12}(1-\lambda)^2+1\cdot\lambda+2\cdot\lambda(1-\lambda)+3\cdot\frac{1}{3}(1-\lambda)^2+4\cdot\frac{1}{4}(1-\lambda)^2=2-\lambda$$ Now, the expectation of $\hat \lambda$ should be: $$\mathbb{E}(\hat \lambda)=\mathbb{E}\left(1+\frac{n}{n+1}-\bar X\right)=1+\frac{n}{n+1}-(2-\lambda)$$ thus the estimator is biased. For consistency we need $\lim_{n \to \infty}\mathbb{E}(\hat \lambda)=\lambda$ and $\lim_{n \to \infty}\mathbb{Var}(\hat \lambda)=0$, so: $$\lim_{n \to \infty}\mathbb{E}(\hat \lambda)=\lim_{n \to \infty}\left(1+\frac{n}{n+1}-(2-\lambda)\right)=\lambda$$ How can I find $\mathbb{Var}(\hat \lambda)$? First edit Based on Michael's suggestion: $\mathbb{Var}(X)=\mathbb{E}(X^2)-(\mathbb{E}(X))^2=\left(0\cdot\frac{5}{12}(1-\lambda)^2+1^2\cdot\lambda+2^2\cdot\lambda(1-\lambda)+3^2\cdot\frac{1}{3}(1-\lambda)^2+4^2\cdot\frac{1}{4}(1-\lambda)^2\right)-(2-\lambda)^2=3-5\lambda+2\lambda^2$. $\mathbb{Var}(\widehat\lambda)=\dfrac{3-5\lambda+2\lambda^2}{n}$ so $\lim_{n \to \infty}\mathbb{Var}(\hat \lambda)=0$","Let $x_1, x_2, \ldots,x_n$ be a simple random sample from a random variable $X$ with support $\{0,1,2,3,4\}$ and probability function $p(0)=\frac{5}{12}(1-\lambda)^2$, $p(1)=\lambda$, $p(2)=\lambda(1-\lambda)$, $p(3)=\frac{1}{3}(1-\lambda)^2$ and $p(4)=\frac{1}{4}(1-\lambda)^2$, where $\lambda$ is a parameter $\in(0,1)$. Is this estimator   $$\hat \lambda=1+\frac{n}{n+1}-\bar X$$ unbiased and consistent for $\lambda$? $\bar X$ is sample mean. The expectation of $X$ is: $$\mathbb{E}(X)=0\cdot\frac{5}{12}(1-\lambda)^2+1\cdot\lambda+2\cdot\lambda(1-\lambda)+3\cdot\frac{1}{3}(1-\lambda)^2+4\cdot\frac{1}{4}(1-\lambda)^2=2-\lambda$$ Now, the expectation of $\hat \lambda$ should be: $$\mathbb{E}(\hat \lambda)=\mathbb{E}\left(1+\frac{n}{n+1}-\bar X\right)=1+\frac{n}{n+1}-(2-\lambda)$$ thus the estimator is biased. For consistency we need $\lim_{n \to \infty}\mathbb{E}(\hat \lambda)=\lambda$ and $\lim_{n \to \infty}\mathbb{Var}(\hat \lambda)=0$, so: $$\lim_{n \to \infty}\mathbb{E}(\hat \lambda)=\lim_{n \to \infty}\left(1+\frac{n}{n+1}-(2-\lambda)\right)=\lambda$$ How can I find $\mathbb{Var}(\hat \lambda)$? First edit Based on Michael's suggestion: $\mathbb{Var}(X)=\mathbb{E}(X^2)-(\mathbb{E}(X))^2=\left(0\cdot\frac{5}{12}(1-\lambda)^2+1^2\cdot\lambda+2^2\cdot\lambda(1-\lambda)+3^2\cdot\frac{1}{3}(1-\lambda)^2+4^2\cdot\frac{1}{4}(1-\lambda)^2\right)-(2-\lambda)^2=3-5\lambda+2\lambda^2$. $\mathbb{Var}(\widehat\lambda)=\dfrac{3-5\lambda+2\lambda^2}{n}$ so $\lim_{n \to \infty}\mathbb{Var}(\hat \lambda)=0$",,"['statistics', 'self-learning', 'estimation']"
37,Moments based on a Bootstrapped Mean,Moments based on a Bootstrapped Mean,,"Take $X_1,\ldots,X_n$ to be distinct observations, and let $X_1^*,\ldots,X_n^*$ be a bootstrapped sample (given a uniform resampling of cases with replacement) and let $\bar{X_n}^{*} = \frac{1}{n}  \sum_{i=1}^n X_i^*$ (i.e. the mean of the bootstrapped sample). I would like to solve for the first moment of the distribution for $\bar{X_n}^{*}$ i.e. $E(\bar{X_n}^*)$. I can see that $$E(\bar{X_n}^* \mid X_1,\ldots,X_n) = E\left(\frac{1}{n}\sum_{i=1}^n X_i^*     \mid X_1,\ldots,X_n\right)$$ $$= \frac{1}{n} \sum_{i=1}^n E(X_i^* \mid X_1,\ldots,X_n) = \frac{1}{n} \sum_{i=1}^n \left( \sum_{i=1}^n X_i P(X_i^* = X_i)\right) =\frac{1}{n} \sum_{i=1}^n \left( \sum_{i=1}^n \frac{X_i}{n} \right)$$ $$=\frac{1}{n} \sum_{i=1}^n \left( \bar{X}\right) =\frac{1}{n} n\bar{X} = \bar{X}.$$ However, I am having an issue solving for it unconditionally, i.e. $E(\bar{X_n}^*)$. Any recommendation on how to use the conditional distribution to solve for this?","Take $X_1,\ldots,X_n$ to be distinct observations, and let $X_1^*,\ldots,X_n^*$ be a bootstrapped sample (given a uniform resampling of cases with replacement) and let $\bar{X_n}^{*} = \frac{1}{n}  \sum_{i=1}^n X_i^*$ (i.e. the mean of the bootstrapped sample). I would like to solve for the first moment of the distribution for $\bar{X_n}^{*}$ i.e. $E(\bar{X_n}^*)$. I can see that $$E(\bar{X_n}^* \mid X_1,\ldots,X_n) = E\left(\frac{1}{n}\sum_{i=1}^n X_i^*     \mid X_1,\ldots,X_n\right)$$ $$= \frac{1}{n} \sum_{i=1}^n E(X_i^* \mid X_1,\ldots,X_n) = \frac{1}{n} \sum_{i=1}^n \left( \sum_{i=1}^n X_i P(X_i^* = X_i)\right) =\frac{1}{n} \sum_{i=1}^n \left( \sum_{i=1}^n \frac{X_i}{n} \right)$$ $$=\frac{1}{n} \sum_{i=1}^n \left( \bar{X}\right) =\frac{1}{n} n\bar{X} = \bar{X}.$$ However, I am having an issue solving for it unconditionally, i.e. $E(\bar{X_n}^*)$. Any recommendation on how to use the conditional distribution to solve for this?",,['statistics']
38,Exponential smoothing and variance,Exponential smoothing and variance,,"I have a time series, let's denote it as $X_t$ (a series of prices). We exponentially smooth the data to obtain another time series, an exponential moving average: $EMA_t$. My question is how do I calculate the moving variance $\sigma^2_t$ of $EMA_t$? I'm pretty sure the standard sample variance $\frac{1}{N}\sum_i (y_i - \hat{\mu})^2$ is not the way to go about calculating the rolling variance. I'm doing this in excel, so I have an actual list of prices that I exponentially smoothed and would like to calculate a rolling variance for. From here we have that the basic form of exponential smoothing is $$s_t = \alpha x_t + (1-\alpha) s_{t-1} $$ Is there a way to manipulate the recurrence such that I can obtain the moving variance? Does anyone have any ideas? Could it be related to finding the variance of an AR(1) model? I think the answer is $EMSD_t = \alpha (s_t - x_t)^2+ (1-\alpha)s_{t-1}^2$.","I have a time series, let's denote it as $X_t$ (a series of prices). We exponentially smooth the data to obtain another time series, an exponential moving average: $EMA_t$. My question is how do I calculate the moving variance $\sigma^2_t$ of $EMA_t$? I'm pretty sure the standard sample variance $\frac{1}{N}\sum_i (y_i - \hat{\mu})^2$ is not the way to go about calculating the rolling variance. I'm doing this in excel, so I have an actual list of prices that I exponentially smoothed and would like to calculate a rolling variance for. From here we have that the basic form of exponential smoothing is $$s_t = \alpha x_t + (1-\alpha) s_{t-1} $$ Is there a way to manipulate the recurrence such that I can obtain the moving variance? Does anyone have any ideas? Could it be related to finding the variance of an AR(1) model? I think the answer is $EMSD_t = \alpha (s_t - x_t)^2+ (1-\alpha)s_{t-1}^2$.",,"['statistics', 'average', 'time-series', 'variance']"
39,Distribution on number of revisits in past $k$ steps of Markov chain,Distribution on number of revisits in past  steps of Markov chain,k,"Consider a finite-state Markov chain with transition matrix $P$. The chain starts in a state chosen uniformly over all the states and runs indefinitely from there. We're going to examine only the $k ≥ 0$ most recent steps of the chain. In particular, we will consider the number of states that appear $0, 1,\ldots, k$ times in those most recent $k$ steps. Let's define a vector $C = [c_0, c_1, \ldots,c_k]$ whose $i$-th element is the number of states that have been visited $i$ times within the past $k$ steps. For example, if $k = 4$, if the state space is $1, 2, \ldots, 10$, and if the chain is $$1, 2, 1, 4, 3, 2, 4, 3, 3, 2, 4, 5, 5, 3, 2, 1, 2, 3$$ then $c = [7, 2, 1, 0, 0]$. What is the expected value of $C$ and, ideally, how is $C$ distributed?","Consider a finite-state Markov chain with transition matrix $P$. The chain starts in a state chosen uniformly over all the states and runs indefinitely from there. We're going to examine only the $k ≥ 0$ most recent steps of the chain. In particular, we will consider the number of states that appear $0, 1,\ldots, k$ times in those most recent $k$ steps. Let's define a vector $C = [c_0, c_1, \ldots,c_k]$ whose $i$-th element is the number of states that have been visited $i$ times within the past $k$ steps. For example, if $k = 4$, if the state space is $1, 2, \ldots, 10$, and if the chain is $$1, 2, 1, 4, 3, 2, 4, 3, 3, 2, 4, 5, 5, 3, 2, 1, 2, 3$$ then $c = [7, 2, 1, 0, 0]$. What is the expected value of $C$ and, ideally, how is $C$ distributed?",,"['probability', 'statistics', 'markov-chains', 'markov-process']"
40,Is this an exponential family of distributions? from casella and berger 6.20,Is this an exponential family of distributions? from casella and berger 6.20,,"I am trying to do 6.20 in Casella and Berger part d. The solutions manual says that the order statistics are minimal sufficient and not complete. I understand their logic, but why doesn't this work? The distribution is $$f(x)=e^{-(x-\theta)}e^{-e^{-(x-\theta)}}$$ The range is $-\infty<x<\infty$  $-\infty<\theta<\infty$ I think this breaks into an exponential family with $$f(x)=e^{-x}e^{\theta}e^{-e^{-x}e^{\theta}}$$ And this would imply $\sum{e^{-x}}$ is complete sufficient. A quick computation makes me think its minimal as well. Am I correct? The sample is $X_1, X_2....X_n$ iid from this distribution.","I am trying to do 6.20 in Casella and Berger part d. The solutions manual says that the order statistics are minimal sufficient and not complete. I understand their logic, but why doesn't this work? The distribution is $$f(x)=e^{-(x-\theta)}e^{-e^{-(x-\theta)}}$$ The range is $-\infty<x<\infty$  $-\infty<\theta<\infty$ I think this breaks into an exponential family with $$f(x)=e^{-x}e^{\theta}e^{-e^{-x}e^{\theta}}$$ And this would imply $\sum{e^{-x}}$ is complete sufficient. A quick computation makes me think its minimal as well. Am I correct? The sample is $X_1, X_2....X_n$ iid from this distribution.",,"['probability', 'statistics', 'probability-distributions', 'statistical-inference']"
41,Statistics $X_{(1)}$ complete for a Uniform Distribution?,Statistics  complete for a Uniform Distribution?,X_{(1)},"Someone had asked this earlier, but since it was good practice for my qualifying exam coming up, I figured I would ask and share my work on the problem. The problem is: Suppose $X$ is Unif$(0,\theta)$. Let $T = X_{(1)}$ (minimum order statistic). Is $T$ complete? My initial thought was no since usually lectures show $X_{(n)}$ is, but here was my attempt: I assume that $E[g(T)]=0$ for some function $g$ and want to find if $P(g  =0)=1$. $$P(T \leq t) = 1 - P(T > t) = 1-\left(1-\frac{t}{n} \right)^n$$ So taking derivatives to get the pdf: $$f_T(t) = \left(1-\frac{t}{n}\right)^{n-1}$$ So now working with expectations: $$0=E[g(T)] = \int_0^\theta g(t)\left(1-\frac{t}{n}\right)^{n-1} dt$$ This integral is differentiable, and since the integral is $0$, then the derivative is $0$, so taking the derivative with respect to $\theta$: $$0= g(\theta)\left(1-\frac{\theta}{n}\right)^{n-1}$$ Hence $g(\theta) =0$, so $T$ is a complete statistics. Does this argument work? I basically modeled it after the proof of showing the max order statistic is complete. If $X_{(1)}$ is not complete, where does the proof go wrong?","Someone had asked this earlier, but since it was good practice for my qualifying exam coming up, I figured I would ask and share my work on the problem. The problem is: Suppose $X$ is Unif$(0,\theta)$. Let $T = X_{(1)}$ (minimum order statistic). Is $T$ complete? My initial thought was no since usually lectures show $X_{(n)}$ is, but here was my attempt: I assume that $E[g(T)]=0$ for some function $g$ and want to find if $P(g  =0)=1$. $$P(T \leq t) = 1 - P(T > t) = 1-\left(1-\frac{t}{n} \right)^n$$ So taking derivatives to get the pdf: $$f_T(t) = \left(1-\frac{t}{n}\right)^{n-1}$$ So now working with expectations: $$0=E[g(T)] = \int_0^\theta g(t)\left(1-\frac{t}{n}\right)^{n-1} dt$$ This integral is differentiable, and since the integral is $0$, then the derivative is $0$, so taking the derivative with respect to $\theta$: $$0= g(\theta)\left(1-\frac{\theta}{n}\right)^{n-1}$$ Hence $g(\theta) =0$, so $T$ is a complete statistics. Does this argument work? I basically modeled it after the proof of showing the max order statistic is complete. If $X_{(1)}$ is not complete, where does the proof go wrong?",,"['statistics', 'uniform-distribution', 'order-statistics']"
42,"Simple example of ""Spike-and-Slab Prior"" for Bayesian Inference","Simple example of ""Spike-and-Slab Prior"" for Bayesian Inference",,"I would really like to understand how Spike-and-Slab Priors work in relation to Linearized Models . Can somebody provide a toy example of a Spike-and-Slab Prior with a Bernoulli spike and a Gaussian slab? Here's my generic Linear Model : $$ y = \mathbf{\beta*x} + \epsilon $$ or written as $$ y = \sum_{j=1}^{k}\beta_j*x_j + \epsilon $$ I understand in Bayesian Inference , one has a posterior distribution that  $$\mathbf{\theta} = [\beta_1, \beta_2, ..., \beta_j]$$ $$P(\theta|x) = \frac{P(x|\theta)*P(\theta)}{P(x)}$$ which is essentially Likelihood * Prior / Normalizer . In this, each parameter (i.e. each $\beta_j$) has it's own distribution and I would like to fit the parameters ($\theta$) to the data ($x$) while the data is fixed and the parameters are random variables of their own distributions (btw, is that the same as $P(\theta_j)=P(x|\theta_j)*P(\theta_j)/P(x)$ with indicies?). If any of this is incorrect, please correct me :) It would be greatly appreciated My reference: The paper I am reading uses Bayesian Model Averaging with a Spike-and-Slab Prior .  The Spike-and-Slab Prior uses ""consists of a Bernoulli distribution that specifies whether or not a variable is selected as influential. The slab prior is a Gaussian distribution that models the effect sizes of the variables, conditional on their being chosen as influential"" Shankar et al. BMC Bioinformatics (2015) 16:31 DOI 10.1186/s12859-015-0467-6 .  To figure out what a Spike-and-Slab Prior was, so I can use this w/o any black-box R package, I checked out: https://www2.stat.duke.edu/courses/Fall05/sta395/joelucas1.pdf where the description of the algorithm is below. My confusion: I don't understand how this is related to Bernoulli and Gaussian distributions.  Is the $h_{0j}$ a random variable following Bernoulli distribution and $h_{1j}$ following Gaussian ? If $f$ has to be extremely large, does the value of it matter and why does their need to be a separate value for every index $f_j$?  I found this resource on the stats stackexchange ( https://stats.stackexchange.com/questions/142818/is-a-spike-and-slab-prior-a-proper-prior ) but I'm not sure what $F(x)$ is in the figure; it's definitely not a p.d.f. since it doesn't integrate to 1. My apologies if this is long, but I've been looking up resources for over a week and it's explained a little differently everywhere I've looked; it's difficult to piece together the pieces w/o a toy example.","I would really like to understand how Spike-and-Slab Priors work in relation to Linearized Models . Can somebody provide a toy example of a Spike-and-Slab Prior with a Bernoulli spike and a Gaussian slab? Here's my generic Linear Model : $$ y = \mathbf{\beta*x} + \epsilon $$ or written as $$ y = \sum_{j=1}^{k}\beta_j*x_j + \epsilon $$ I understand in Bayesian Inference , one has a posterior distribution that  $$\mathbf{\theta} = [\beta_1, \beta_2, ..., \beta_j]$$ $$P(\theta|x) = \frac{P(x|\theta)*P(\theta)}{P(x)}$$ which is essentially Likelihood * Prior / Normalizer . In this, each parameter (i.e. each $\beta_j$) has it's own distribution and I would like to fit the parameters ($\theta$) to the data ($x$) while the data is fixed and the parameters are random variables of their own distributions (btw, is that the same as $P(\theta_j)=P(x|\theta_j)*P(\theta_j)/P(x)$ with indicies?). If any of this is incorrect, please correct me :) It would be greatly appreciated My reference: The paper I am reading uses Bayesian Model Averaging with a Spike-and-Slab Prior .  The Spike-and-Slab Prior uses ""consists of a Bernoulli distribution that specifies whether or not a variable is selected as influential. The slab prior is a Gaussian distribution that models the effect sizes of the variables, conditional on their being chosen as influential"" Shankar et al. BMC Bioinformatics (2015) 16:31 DOI 10.1186/s12859-015-0467-6 .  To figure out what a Spike-and-Slab Prior was, so I can use this w/o any black-box R package, I checked out: https://www2.stat.duke.edu/courses/Fall05/sta395/joelucas1.pdf where the description of the algorithm is below. My confusion: I don't understand how this is related to Bernoulli and Gaussian distributions.  Is the $h_{0j}$ a random variable following Bernoulli distribution and $h_{1j}$ following Gaussian ? If $f$ has to be extremely large, does the value of it matter and why does their need to be a separate value for every index $f_j$?  I found this resource on the stats stackexchange ( https://stats.stackexchange.com/questions/142818/is-a-spike-and-slab-prior-a-proper-prior ) but I'm not sure what $F(x)$ is in the figure; it's definitely not a p.d.f. since it doesn't integrate to 1. My apologies if this is long, but I've been looking up resources for over a week and it's explained a little differently everywhere I've looked; it's difficult to piece together the pieces w/o a toy example.",,"['linear-algebra', 'statistics', 'probability-distributions', 'mathematical-modeling', 'bayesian']"
43,Sample median of sample from uniform distribution.,Sample median of sample from uniform distribution.,,"I'm trying to determine the distribution of the sample median of a sample of size $n$ from the uniform distribution (on the interval $(0,1)$). If $n$ is odd and $m=(n+1)/2$, then the sample median is just one of the order statistics and it has a beta distribution whose both parameters are $m$. But I am having some problems finding its distribution when the size of the sample is even. I proceeded in the obvious way: given a sample from a population with density $f$ and distribution $F$, the joint distribution of the order statistics $(X_{(j)},X_{(k)})$, $1\leq j<k\leq n$ is $$ f_{X_{(j)},X_{(k)}}(x,y)=\frac{n!}{(j-1)!(k-j-1)!(n-k)!}[F(x)]^{j-1}[F(y)-F(x)]^{k-1-j}[1-F(y)]^{n-k}f(x)f(y), $$ where $x<y$. If $m=n/2$, the sample median is given by $(X_{(m)},X_{(m+1)})/2$, and using the above formula, the density of the sample median must be given by $$ g(z)=2\int_{-\infty}^{\infty}f_{X_{(m)},X_{(m+1)}}(2z-x,x)dx\\ =\frac{2n!}{(m-1)!^2}\int_{-\infty}^{\infty}(2z-x)^{m-1}(1-x)^{m-1}1_{(0,1)}(2z-x)1_{(0,1)}(x)1_{(0,x)}(2z-x)dx $$ And, after some simplifications, I arrive to the following formula $$ g(z)=\frac{2n!}{m(m-1)!^2}\Big(\frac{(1-z)^m}{2z-1}(z^m-(1-z)^m)\\-\frac{(1-\min{(1,2z)})^m}{2z-1}((2z-\min{(1,2z)})^m-(1-\min{(1,2z)})^m)\Big)1_{(0,1)}(z) $$ But for $n=4$ this function integrates to 5, which clearly is not possible. I have checked this procedure twice and I keep getting the same formula. In my computations, I found that $1_{(0,1)}(2z-x)1_{(0,1)}(x)1_{(0,x)}(2z-x)=1_{(0,1)}(z)1_{(z,\min{(1,2z)})}(x)$ and I think this may be where I'm wrong, since everything else is just standard integration. Thanks for any any help in advance.","I'm trying to determine the distribution of the sample median of a sample of size $n$ from the uniform distribution (on the interval $(0,1)$). If $n$ is odd and $m=(n+1)/2$, then the sample median is just one of the order statistics and it has a beta distribution whose both parameters are $m$. But I am having some problems finding its distribution when the size of the sample is even. I proceeded in the obvious way: given a sample from a population with density $f$ and distribution $F$, the joint distribution of the order statistics $(X_{(j)},X_{(k)})$, $1\leq j<k\leq n$ is $$ f_{X_{(j)},X_{(k)}}(x,y)=\frac{n!}{(j-1)!(k-j-1)!(n-k)!}[F(x)]^{j-1}[F(y)-F(x)]^{k-1-j}[1-F(y)]^{n-k}f(x)f(y), $$ where $x<y$. If $m=n/2$, the sample median is given by $(X_{(m)},X_{(m+1)})/2$, and using the above formula, the density of the sample median must be given by $$ g(z)=2\int_{-\infty}^{\infty}f_{X_{(m)},X_{(m+1)}}(2z-x,x)dx\\ =\frac{2n!}{(m-1)!^2}\int_{-\infty}^{\infty}(2z-x)^{m-1}(1-x)^{m-1}1_{(0,1)}(2z-x)1_{(0,1)}(x)1_{(0,x)}(2z-x)dx $$ And, after some simplifications, I arrive to the following formula $$ g(z)=\frac{2n!}{m(m-1)!^2}\Big(\frac{(1-z)^m}{2z-1}(z^m-(1-z)^m)\\-\frac{(1-\min{(1,2z)})^m}{2z-1}((2z-\min{(1,2z)})^m-(1-\min{(1,2z)})^m)\Big)1_{(0,1)}(z) $$ But for $n=4$ this function integrates to 5, which clearly is not possible. I have checked this procedure twice and I keep getting the same formula. In my computations, I found that $1_{(0,1)}(2z-x)1_{(0,1)}(x)1_{(0,x)}(2z-x)=1_{(0,1)}(z)1_{(z,\min{(1,2z)})}(x)$ and I think this may be where I'm wrong, since everything else is just standard integration. Thanks for any any help in advance.",,"['probability', 'statistics']"
44,Monte Carlo with non uniform weighting,Monte Carlo with non uniform weighting,,"So, I just want to check if what is in my mind is in fact true. Assume, that we have are given a distribution $p_{z}(k)$ over the whole $\mathbb{Z}^+$. We are interested in approximating $p_v(v)$ over some observed variable $v$. However, we are not given $p_v$ directly, but rather a joint $p(v,h) = p(h)p(v|h)$ such that the marginal $p_v(v)$ is intractable. Thus we seek to approximate $p_v(v)$ via importance sampling - e.g. taking sample from some $q(h)$ and using the fact that $$p_v(v) = \mathbb{E}\left[\frac{p(v,h)}{q(h)}\right]_q$$ Thus usually what is done is to use MC to approximate p(v) via: $$p_v(v) \approx \sum_{k=1}^K \frac{1}{K} \frac{p(v,h_k)}{q(h_k)}$$ According to the strong law of large numbers, the approximation will be exact when $K \to \infty$, under some mild conditions, which we assume are true. However, I can re write this as: $$ p_v(v) \approx \sum_{k=1}^K \frac{p_z(k)}{\sum_{i=1}^K p_z(i)}  \frac{p(v,h_k)}{q(h_k)}$$ Where in the MC case $p_z(k)$ is a degenerate uniform distribution, however the limit still exists and converges, assuming we define appropriately $\frac{p_z(k)}{\sum_{i=1}^K p_z(i)}$. Now in the limit of infinite examples essentially we have: $$ \lim_{K \to \infty} \sum_{k=1}^K \frac{p_z(k)}{\sum_{i=1}^K p_z(i)}  \frac{p(v,h_k)}{q(h_k)} = \mathbb{E}\left[\frac{p(v,h)}{q(h)}\right]_{p_z* q} = p_v(v)$$ Thus I have two questions. First, is my reasoning correct or is there some major flaw? Secondly, if there is no mistake, is it possible to pick better weights for the MC sampling (I think not) and why?","So, I just want to check if what is in my mind is in fact true. Assume, that we have are given a distribution $p_{z}(k)$ over the whole $\mathbb{Z}^+$. We are interested in approximating $p_v(v)$ over some observed variable $v$. However, we are not given $p_v$ directly, but rather a joint $p(v,h) = p(h)p(v|h)$ such that the marginal $p_v(v)$ is intractable. Thus we seek to approximate $p_v(v)$ via importance sampling - e.g. taking sample from some $q(h)$ and using the fact that $$p_v(v) = \mathbb{E}\left[\frac{p(v,h)}{q(h)}\right]_q$$ Thus usually what is done is to use MC to approximate p(v) via: $$p_v(v) \approx \sum_{k=1}^K \frac{1}{K} \frac{p(v,h_k)}{q(h_k)}$$ According to the strong law of large numbers, the approximation will be exact when $K \to \infty$, under some mild conditions, which we assume are true. However, I can re write this as: $$ p_v(v) \approx \sum_{k=1}^K \frac{p_z(k)}{\sum_{i=1}^K p_z(i)}  \frac{p(v,h_k)}{q(h_k)}$$ Where in the MC case $p_z(k)$ is a degenerate uniform distribution, however the limit still exists and converges, assuming we define appropriately $\frac{p_z(k)}{\sum_{i=1}^K p_z(i)}$. Now in the limit of infinite examples essentially we have: $$ \lim_{K \to \infty} \sum_{k=1}^K \frac{p_z(k)}{\sum_{i=1}^K p_z(i)}  \frac{p(v,h_k)}{q(h_k)} = \mathbb{E}\left[\frac{p(v,h)}{q(h)}\right]_{p_z* q} = p_v(v)$$ Thus I have two questions. First, is my reasoning correct or is there some major flaw? Secondly, if there is no mistake, is it possible to pick better weights for the MC sampling (I think not) and why?",,"['statistics', 'convergence-divergence', 'monte-carlo', 'law-of-large-numbers']"
45,Rolling a die until we have all the numbers- variance,Rolling a die until we have all the numbers- variance,,"We roll a die until we obtain all numbers from $1$ to $6$ . I found the expected value of rolls computing it like $X = X_1 + \dots + X_6$ where $X_i$ is number of rolls needed to obtain a result different from previous $i-1$ and using a geometric distribution. And my result is correct. But then I wanted to find a variance. Firstly I thought of doing it this way: $$\text{Var} (X_1 + \dots + X_6) = \text{Var}(X_1) + \dots + \text{Var}(X_6) + 2 \sum_{1\le i<j\le6} \text{Cov}(X_i, X_j),$$ but covariance is not easy to find here. Can somebody please show me how to find a variance of number of dice rolls?",We roll a die until we obtain all numbers from to . I found the expected value of rolls computing it like where is number of rolls needed to obtain a result different from previous and using a geometric distribution. And my result is correct. But then I wanted to find a variance. Firstly I thought of doing it this way: but covariance is not easy to find here. Can somebody please show me how to find a variance of number of dice rolls?,"1 6 X = X_1 + \dots + X_6 X_i i-1 \text{Var} (X_1 + \dots + X_6) = \text{Var}(X_1) + \dots + \text{Var}(X_6) + 2 \sum_{1\le i<j\le6} \text{Cov}(X_i, X_j),","['probability', 'dice', 'coupon-collector']"
46,Stochastic modeling. A bidding Model,Stochastic modeling. A bidding Model,,"The Question:  Let $U_1,U_2,...$ be independent RVs, each uniformly distributed over $(0,1]$. These random variables represent successive bids on an asset that you're trying to sell, and that you must sell by time $t = 1$. As a strategy you adopt a secret number $θ$, and you will accept the first offer that is greater than $θ$. For example, you accept the second offer if $U_1≤θ$ while $U_2>θ$. Suppose that the offers arrive according to a unit rate Poisson process ($λ=1$). What is the probability that you sell the asset by time $t=1$? What is the value for $θ$ that maximizes your expected return? (You get nothing if you don't sell the asset by $t = 1$). To improve your return you adopt a new strategy, which is to accept an offer at time $t$ if it exceeds $θ(t)=(1−t)/(3−t)$. What are your new chances of selling the asset, and what is your new expected return? Just for the first part (1) I'm still quite unsure what to do. What seems somewhat reasonable to me is to calculate $$Pr[X_T(t)>θ|X(t)>0]$$ where $T=\max(U_1,...,U_T>θ)$.  I'm not sure how to calculate this probability either though. Hints and clarifications would be very much appreciated thanks.","The Question:  Let $U_1,U_2,...$ be independent RVs, each uniformly distributed over $(0,1]$. These random variables represent successive bids on an asset that you're trying to sell, and that you must sell by time $t = 1$. As a strategy you adopt a secret number $θ$, and you will accept the first offer that is greater than $θ$. For example, you accept the second offer if $U_1≤θ$ while $U_2>θ$. Suppose that the offers arrive according to a unit rate Poisson process ($λ=1$). What is the probability that you sell the asset by time $t=1$? What is the value for $θ$ that maximizes your expected return? (You get nothing if you don't sell the asset by $t = 1$). To improve your return you adopt a new strategy, which is to accept an offer at time $t$ if it exceeds $θ(t)=(1−t)/(3−t)$. What are your new chances of selling the asset, and what is your new expected return? Just for the first part (1) I'm still quite unsure what to do. What seems somewhat reasonable to me is to calculate $$Pr[X_T(t)>θ|X(t)>0]$$ where $T=\max(U_1,...,U_T>θ)$.  I'm not sure how to calculate this probability either though. Hints and clarifications would be very much appreciated thanks.",,"['statistics', 'stochastic-processes']"
47,Getting a feel for the Normal-Inverse-Wishart conjugate prior to multivariate normal distribution,Getting a feel for the Normal-Inverse-Wishart conjugate prior to multivariate normal distribution,,"I am trying to get a feel for the Normal-Inverse-Wishart conjugate prior, which I have started to use, sparingly, in my work, where I am trying to cluster multivariate normal data. As Wikipedia helpfully points out the NIW is the conjugate prior to the MVN distribution. What I am trying to get a feel for is how the hyperparameters of the $\mathcal{NIW}(\mu, \lambda, \Psi,\nu)$ affect the cluster properties. E.g. Here is some MVN data with some clusters: What I am wondering is; if e.g. I were to use a Dirichlet-process mixture model to do some good old clustering, how do my choices of hyperparameters affect my clusters? What makes them highly discriminative (i.e. lots of them with strict boundaries)? What makes them smooth A LOT (i.e. having just say three clusters which between them classify all the data, regardless if this is correct or not)? $\mu$: I understand that it is common to set this to the sample mean, but what if you don't? $\lambda$: apparently this is the mean fraction which works as a smoothing parameter (I do not know what this means) $\Psi$: is the degrees of freedom which is set to the number of dimensions of the data (but what if I set it higher, I cannot go lower, I know that, but higher? $\nu$: is the pairwise deviation product which is set to the $D \times D$ identity matrix multiplied by a constant . But how does the choice of constant affect my clustering? Naturally I know that I could have found all of this out empirically, but I have horrendous amounts of data, so would very much appreciate some intuition about the hyperparameter set $\theta  =\{\mu, \lambda, \Psi,\nu\}$. Equally, running through the maths is obviously possible too, and I am doing that, but as the title says; I just want some advise from more experienced users.","I am trying to get a feel for the Normal-Inverse-Wishart conjugate prior, which I have started to use, sparingly, in my work, where I am trying to cluster multivariate normal data. As Wikipedia helpfully points out the NIW is the conjugate prior to the MVN distribution. What I am trying to get a feel for is how the hyperparameters of the $\mathcal{NIW}(\mu, \lambda, \Psi,\nu)$ affect the cluster properties. E.g. Here is some MVN data with some clusters: What I am wondering is; if e.g. I were to use a Dirichlet-process mixture model to do some good old clustering, how do my choices of hyperparameters affect my clusters? What makes them highly discriminative (i.e. lots of them with strict boundaries)? What makes them smooth A LOT (i.e. having just say three clusters which between them classify all the data, regardless if this is correct or not)? $\mu$: I understand that it is common to set this to the sample mean, but what if you don't? $\lambda$: apparently this is the mean fraction which works as a smoothing parameter (I do not know what this means) $\Psi$: is the degrees of freedom which is set to the number of dimensions of the data (but what if I set it higher, I cannot go lower, I know that, but higher? $\nu$: is the pairwise deviation product which is set to the $D \times D$ identity matrix multiplied by a constant . But how does the choice of constant affect my clustering? Naturally I know that I could have found all of this out empirically, but I have horrendous amounts of data, so would very much appreciate some intuition about the hyperparameter set $\theta  =\{\mu, \lambda, \Psi,\nu\}$. Equally, running through the maths is obviously possible too, and I am doing that, but as the title says; I just want some advise from more experienced users.",,"['statistics', 'machine-learning', 'bayesian', 'data-analysis', 'sampling']"
48,Deriving the q-Gaussian PDF,Deriving the q-Gaussian PDF,,"Ok it may sound a bit too simple but I am quite confused here. While studying generalized entropic forms, in my case that of $S_q$ or in another words the Tsallis Entropy , I reach a point where I have to derive the maximal distribution that corresponds to $S_q$. In order for that to be done, one has to impose some constraints and follow the Lagrange parameters method. In this particular case the constraints required would be: \begin{align} & \int_{0}^{\infty}p(x)dx=1 \quad \text{(Normalization Constraint)} \\ & \langle x_q \rangle=\int_{0}^{\infty}xP(x)dx=X_q \quad \text{(q-mean value)} \end{align} where $P(x)$ is called the Escort Distribution and is defined as: \begin{align} P(x)=\frac{[p(x)]^q}{\int_{0}^{\infty}[p(k)]^qdk} \end{align} Now we define the quantity: \begin{equation} Φ(x;p;q)=\frac{1-\int_{0}^{\infty}[p(x)]^qdx}{q-1}-α \int_{0}^{\infty}p(x)dx-\beta_q \frac{\int_{0}^{\infty}x[p(x)]^qdx}{\int_{0}^{\infty}[p(x)]^qdx} \end{equation} and demand that $\partial{Φ}/\partial{p}=0$. By solving that, one ends up with the pdf: \begin{equation} p_{opt}(x)=\frac{e_q^{-\beta_q(x-X_q)}}{\int_{0}^{\infty} e_q^{-\beta_q (x'-X_q)}dx'} \end{equation}  where $e_q^x$ are the q-expodentials. This $p_{opt}(x)$ is also known as q-Gaussian pdf. My problem in deriving the pdf, is that I am not able to see how to calculate the quantity: \begin{equation} \frac{\partial{}}{\partial{p}}\left( \frac{\int_{0}^{\infty}x[p(x)]^qdx}{\int_{0}^{\infty}[p(x)]^qdx}\right) \end{equation} Perhaps treating it like a function of the form $h(x)=f(x)/g(x)$? Am I making a mistake thinking of it in this way? Because I am not able to reach the final formula of the pdf. Also, I am not able to find any paper where the derivation of $p_{opt}$ is worked out. I would really appreciate your help. Thank you!","Ok it may sound a bit too simple but I am quite confused here. While studying generalized entropic forms, in my case that of $S_q$ or in another words the Tsallis Entropy , I reach a point where I have to derive the maximal distribution that corresponds to $S_q$. In order for that to be done, one has to impose some constraints and follow the Lagrange parameters method. In this particular case the constraints required would be: \begin{align} & \int_{0}^{\infty}p(x)dx=1 \quad \text{(Normalization Constraint)} \\ & \langle x_q \rangle=\int_{0}^{\infty}xP(x)dx=X_q \quad \text{(q-mean value)} \end{align} where $P(x)$ is called the Escort Distribution and is defined as: \begin{align} P(x)=\frac{[p(x)]^q}{\int_{0}^{\infty}[p(k)]^qdk} \end{align} Now we define the quantity: \begin{equation} Φ(x;p;q)=\frac{1-\int_{0}^{\infty}[p(x)]^qdx}{q-1}-α \int_{0}^{\infty}p(x)dx-\beta_q \frac{\int_{0}^{\infty}x[p(x)]^qdx}{\int_{0}^{\infty}[p(x)]^qdx} \end{equation} and demand that $\partial{Φ}/\partial{p}=0$. By solving that, one ends up with the pdf: \begin{equation} p_{opt}(x)=\frac{e_q^{-\beta_q(x-X_q)}}{\int_{0}^{\infty} e_q^{-\beta_q (x'-X_q)}dx'} \end{equation}  where $e_q^x$ are the q-expodentials. This $p_{opt}(x)$ is also known as q-Gaussian pdf. My problem in deriving the pdf, is that I am not able to see how to calculate the quantity: \begin{equation} \frac{\partial{}}{\partial{p}}\left( \frac{\int_{0}^{\infty}x[p(x)]^qdx}{\int_{0}^{\infty}[p(x)]^qdx}\right) \end{equation} Perhaps treating it like a function of the form $h(x)=f(x)/g(x)$? Am I making a mistake thinking of it in this way? Because I am not able to reach the final formula of the pdf. Also, I am not able to find any paper where the derivation of $p_{opt}$ is worked out. I would really appreciate your help. Thank you!",,"['statistics', 'partial-derivative', 'entropy', 'chain-rule', 'statistical-mechanics']"
49,What can Jensen's inequality tell me about bias of an estimator?,What can Jensen's inequality tell me about bias of an estimator?,,"What can Jensen's inequality tell me about bias of an estimator? I don't really get how to use it and I would like someone to explain what convexity and Jensen's inequality has to do with bias. In particular, I am trying to learn to use Jensen's inequality to decide whether the MLE of an exponential distribution is biased. I don't really understand how the inequality works. I couldn't really find anything that explained it easily, so I decided to work backwards by guessing how to use it and see if I learned something. So far my current thinking is as follows. Let $g(x) = \theta e^{-\theta x}$. Then $$\Bbb E[g(x)] = \frac{1}{\theta}$$ Also, $$ g(\Bbb E[X]) = \theta e^{-\theta \Bbb E[X]}$$ So then Jensen's inequality says if $X$ is a rv and $g$ is a convex function, then  $$\frac{1}{\theta} \geq \theta e^{-\theta \Bbb E[X]}$$ But I'm not really sure what this has to do with the bias of the MLE for an exponential distribution. I can also rearrange this to get $$e^{\theta \Bbb E[X]} \geq \theta^2 $$ $$\theta \Bbb E[X] \geq ln(\theta^2) $$ $$\Bbb E[X] \geq \frac{ln(\theta^2)}{\theta} $$ I don't know if that gets me anything.","What can Jensen's inequality tell me about bias of an estimator? I don't really get how to use it and I would like someone to explain what convexity and Jensen's inequality has to do with bias. In particular, I am trying to learn to use Jensen's inequality to decide whether the MLE of an exponential distribution is biased. I don't really understand how the inequality works. I couldn't really find anything that explained it easily, so I decided to work backwards by guessing how to use it and see if I learned something. So far my current thinking is as follows. Let $g(x) = \theta e^{-\theta x}$. Then $$\Bbb E[g(x)] = \frac{1}{\theta}$$ Also, $$ g(\Bbb E[X]) = \theta e^{-\theta \Bbb E[X]}$$ So then Jensen's inequality says if $X$ is a rv and $g$ is a convex function, then  $$\frac{1}{\theta} \geq \theta e^{-\theta \Bbb E[X]}$$ But I'm not really sure what this has to do with the bias of the MLE for an exponential distribution. I can also rearrange this to get $$e^{\theta \Bbb E[X]} \geq \theta^2 $$ $$\theta \Bbb E[X] \geq ln(\theta^2) $$ $$\Bbb E[X] \geq \frac{ln(\theta^2)}{\theta} $$ I don't know if that gets me anything.",,['statistics']
50,Confidence interval of $p$ based on two random variables,Confidence interval of  based on two random variables,p,"Let $f(x;p) = p\cdot f_{X_1}(x) + (1-p)\cdot f_{X_2}(x)$ where $X_1 \sim N(1,1)$ and $X_2 \sim N(0,1)$. Based on a sample of size $n = 1$ from $f(x;p)$, derive a one-sided lower $100\lambda\%$ confidence limit of $p$ I tried to find pdf of $f(x;p)$ to see if it belongs to any regular distribution but I failed. I kinda don't know any other way to approach this problem.","Let $f(x;p) = p\cdot f_{X_1}(x) + (1-p)\cdot f_{X_2}(x)$ where $X_1 \sim N(1,1)$ and $X_2 \sim N(0,1)$. Based on a sample of size $n = 1$ from $f(x;p)$, derive a one-sided lower $100\lambda\%$ confidence limit of $p$ I tried to find pdf of $f(x;p)$ to see if it belongs to any regular distribution but I failed. I kinda don't know any other way to approach this problem.",,"['statistics', 'confidence-interval']"
51,Find the population size that maximizes the probability that two random samples of size $20$ will have exactly $2$ members in common,Find the population size that maximizes the probability that two random samples of size  will have exactly  members in common,20 2,"Ten fish are caught in a lake, marked, and then returned to the lake. Two days later 20 fish are again caught, 2 of which have been marked. (a) Find the probability of 2 of the 20 fish being marked if the lake has $k$ fish (assuming the fish are caught at random). (b) What value of k maximizes the probability? Progress :     I got the (a), $$\binom{10}{2}\binom{k-10}{18}\bigg/ \binom{k}{20}$$ But how do I get part (b) where $k$ is to maximize the probability?","Ten fish are caught in a lake, marked, and then returned to the lake. Two days later 20 fish are again caught, 2 of which have been marked. (a) Find the probability of 2 of the 20 fish being marked if the lake has $k$ fish (assuming the fish are caught at random). (b) What value of k maximizes the probability? Progress :     I got the (a), $$\binom{10}{2}\binom{k-10}{18}\bigg/ \binom{k}{20}$$ But how do I get part (b) where $k$ is to maximize the probability?",,"['probability', 'permutations', 'combinations']"
52,Determinant of $\vert A' C A\vert$,Determinant of,\vert A' C A\vert,"Let $X$ be an $n\times p$ real matrix with column rank $k$, where $0<k<p<n$, and let $A$ be a semi-orthogonal matrix (the columns are orthonormal) such that $A'X=0$, i.e. the column space of $A$ is the orthogonal complement to the column space of $X$. Let $C$ be an arbitrary positive definite $n\times n$ matrix. Question: Can the determinant $\vert A'CA \vert $ be expressed as a function of $X$ and $C$? When $p=k$ so that $X$ is full column rank, the answer is yes and one can write $\vert A'CA\vert = \vert A'A\vert\vert C\vert\vert X'C^{-1}X\vert/\vert X'X\vert$. This is equation (9) in LaMotte . I have thought about relating the non-zero singular values of $X$ and $C$ to those of $A'CA$ but haven't succeeded. This question is related to a question of more statistical nature posted on stats.stackexchange in the sense than an answer to the present question may be a help on the way to finding an answer to the statistical question.","Let $X$ be an $n\times p$ real matrix with column rank $k$, where $0<k<p<n$, and let $A$ be a semi-orthogonal matrix (the columns are orthonormal) such that $A'X=0$, i.e. the column space of $A$ is the orthogonal complement to the column space of $X$. Let $C$ be an arbitrary positive definite $n\times n$ matrix. Question: Can the determinant $\vert A'CA \vert $ be expressed as a function of $X$ and $C$? When $p=k$ so that $X$ is full column rank, the answer is yes and one can write $\vert A'CA\vert = \vert A'A\vert\vert C\vert\vert X'C^{-1}X\vert/\vert X'X\vert$. This is equation (9) in LaMotte . I have thought about relating the non-zero singular values of $X$ and $C$ to those of $A'CA$ but haven't succeeded. This question is related to a question of more statistical nature posted on stats.stackexchange in the sense than an answer to the present question may be a help on the way to finding an answer to the statistical question.",,"['matrices', 'statistics', 'determinant']"
53,Method of standardization of essay grades from a number of graders,Method of standardization of essay grades from a number of graders,,"Basically, there is a group of us grading a few hundred essays. We divided the number up so each of us grade 50, assigning a score 0-100 given a rubric. However, there is still subjectivity in the rubric, so we would like to normalize the grades. By this I mean if I am grading hard and someone else is grading easy, we want the final grades to be in the middle for the sake of equality. Here was my initial thought: Each grader will assign grades to a sample of essays (n=50), and the population will be the combination of all of the samples (n=400). The ""normalized"" grade would be: Normalized grade = (original grade)+((population average) - (sample average)) Where the sample average is the average grade of whatever sample that specific essay was part of. This seemed a little rudimentary, but that is also what we are looking for. However, is this statistically appropriate? Would using z-scores be more appropriate? If so, how would that be used in this context, provided multiple samples? My concern with z-scores is that our scale and units are the same, some folks are just grading harder than others. Any thoughts are appreciated, thanks! Edit: Another idea Normalized grade = (original grade)*((population mean)/(sample mean)) This produced similar but not the same results, resulting in round differences when rounded to a whole number. So... which method is the most appropriate for this application? Thanks again!","Basically, there is a group of us grading a few hundred essays. We divided the number up so each of us grade 50, assigning a score 0-100 given a rubric. However, there is still subjectivity in the rubric, so we would like to normalize the grades. By this I mean if I am grading hard and someone else is grading easy, we want the final grades to be in the middle for the sake of equality. Here was my initial thought: Each grader will assign grades to a sample of essays (n=50), and the population will be the combination of all of the samples (n=400). The ""normalized"" grade would be: Normalized grade = (original grade)+((population average) - (sample average)) Where the sample average is the average grade of whatever sample that specific essay was part of. This seemed a little rudimentary, but that is also what we are looking for. However, is this statistically appropriate? Would using z-scores be more appropriate? If so, how would that be used in this context, provided multiple samples? My concern with z-scores is that our scale and units are the same, some folks are just grading harder than others. Any thoughts are appreciated, thanks! Edit: Another idea Normalized grade = (original grade)*((population mean)/(sample mean)) This produced similar but not the same results, resulting in round differences when rounded to a whole number. So... which method is the most appropriate for this application? Thanks again!",,"['statistics', 'standard-deviation']"
54,How many rolls do I need to determine if my dice are fair?,How many rolls do I need to determine if my dice are fair?,,"Roughly how many times do I need to roll a 6-sided die to feel confident that it's giving ""fair"" results? What about a 10-sided or 20-sided die? Note that I will be actually manually rolling physical dice, this isn't just a textbook exercise. I'd like to minimize how long it takes me to perform this experiment with each die :) I know this depends on my expected ""confidence level"" (95%? 99%?) If I choose a 95% confidence, for example, does that imply that 1 out of 20 fair dice will fail this test? Or that a single fair dice would fail the test 1 out of 20 times? If so, that sounds fairly high. Are there standard techniques for doing this kind of a test? Edit: It is beyond the scope of the math-focused question I've asked here, but I've explained more about the overall testing scenario over on the stats site here: https://stats.stackexchange.com/questions/14301/designing-a-test-for-a-psychic-who-says-he-can-influence-dice-rolls/14302#14302","Roughly how many times do I need to roll a 6-sided die to feel confident that it's giving ""fair"" results? What about a 10-sided or 20-sided die? Note that I will be actually manually rolling physical dice, this isn't just a textbook exercise. I'd like to minimize how long it takes me to perform this experiment with each die :) I know this depends on my expected ""confidence level"" (95%? 99%?) If I choose a 95% confidence, for example, does that imply that 1 out of 20 fair dice will fail this test? Or that a single fair dice would fail the test 1 out of 20 times? If so, that sounds fairly high. Are there standard techniques for doing this kind of a test? Edit: It is beyond the scope of the math-focused question I've asked here, but I've explained more about the overall testing scenario over on the stats site here: https://stats.stackexchange.com/questions/14301/designing-a-test-for-a-psychic-who-says-he-can-influence-dice-rolls/14302#14302",,"['probability', 'statistics', 'dice']"
55,How to determine if a probability problem has a binomial distribution or not?,How to determine if a probability problem has a binomial distribution or not?,,"I'm studying for my Stats midterm and I am confused about the binomial distribution concept. Among these 2 problems, why does the second question have a binomial distribution and not the first question? 1) In a large 2 lb bag of candies, 15% of the candies are green. The chances of pulling out at least one green candy in three tries is... 2) An owner suspects that only 5% of the customers buy a magazine and thinks that he might be able to use the display space to sell something more profitable. What is the probability that exactly 2 of the first 10 customers buy magazines? We already know about SPIN: S(Success/Failure) P(Probability) I(Independent) N(Fixed number of trials) and I'm curious as to why SPIN doesn't apply to the first problem as well? Any help would be appreciated. Thank you.","I'm studying for my Stats midterm and I am confused about the binomial distribution concept. Among these 2 problems, why does the second question have a binomial distribution and not the first question? 1) In a large 2 lb bag of candies, 15% of the candies are green. The chances of pulling out at least one green candy in three tries is... 2) An owner suspects that only 5% of the customers buy a magazine and thinks that he might be able to use the display space to sell something more profitable. What is the probability that exactly 2 of the first 10 customers buy magazines? We already know about SPIN: S(Success/Failure) P(Probability) I(Independent) N(Fixed number of trials) and I'm curious as to why SPIN doesn't apply to the first problem as well? Any help would be appreciated. Thank you.",,"['statistics', 'probability-distributions']"
56,Should I round a R-Squared to fit with significant figures?,Should I round a R-Squared to fit with significant figures?,,"I have experimental data that I used to plot a calibration curve. If I have 2 significant figures in my data and a R-squared of 0.9959, is it correct to round the R-Squared to 1.0? How I think about it is that, since Excel must have used my data to find that R-squared value, significant figures should apply to it too. However I was wondering if determination coefficient was some special case where everybody leaves all the digits no matter what.","I have experimental data that I used to plot a calibration curve. If I have 2 significant figures in my data and a R-squared of 0.9959, is it correct to round the R-Squared to 1.0? How I think about it is that, since Excel must have used my data to find that R-squared value, significant figures should apply to it too. However I was wondering if determination coefficient was some special case where everybody leaves all the digits no matter what.",,['statistics']
57,Can principal component scores be expressed in terms of linear regression parameters?,Can principal component scores be expressed in terms of linear regression parameters?,,"Suppose that I have a matrix $X \in \mathbb{R}^{n \times f}$, which I interpret as a dataset where $n$ is the number of samples and $f$ is the number of features.  For simplicity, suppose $f=2$, and let $f_1$ and $f_2$ represent the first and second columns of X (and so the first and second features), respectively. Suppose we have a positive correlation between the features: $r(f_1,f_2)>0$.  So then we can regress $f_2$ on $f_1$ to find $f_2 = \beta f_1 + \epsilon$ for some regression weight $\beta >0$ and where we may assume, if we'd like, that $\epsilon \sim N(0,\sigma^2)$. Now consider the first principal component scores for this dataset -- or, roughly speaking, the ""projection"" of the data onto the first principal component.  By this I mean that if we perform a singular value decomposition on $X$ to obtain $X=UDV'$, then we take the first column of $UD$ to be the score of each sample with respect to the first principal component.   We can refer to the first column as $d_1 \vec{u_1}$. Is it possible to express these first principal component scores, $d_1 \vec{u_1}$, -- mathematically, in closed form -- as a function of the original features and regression parameters (so, in terms of the collection {$f_1,f_2,\beta,\epsilon$})?","Suppose that I have a matrix $X \in \mathbb{R}^{n \times f}$, which I interpret as a dataset where $n$ is the number of samples and $f$ is the number of features.  For simplicity, suppose $f=2$, and let $f_1$ and $f_2$ represent the first and second columns of X (and so the first and second features), respectively. Suppose we have a positive correlation between the features: $r(f_1,f_2)>0$.  So then we can regress $f_2$ on $f_1$ to find $f_2 = \beta f_1 + \epsilon$ for some regression weight $\beta >0$ and where we may assume, if we'd like, that $\epsilon \sim N(0,\sigma^2)$. Now consider the first principal component scores for this dataset -- or, roughly speaking, the ""projection"" of the data onto the first principal component.  By this I mean that if we perform a singular value decomposition on $X$ to obtain $X=UDV'$, then we take the first column of $UD$ to be the score of each sample with respect to the first principal component.   We can refer to the first column as $d_1 \vec{u_1}$. Is it possible to express these first principal component scores, $d_1 \vec{u_1}$, -- mathematically, in closed form -- as a function of the original features and regression parameters (so, in terms of the collection {$f_1,f_2,\beta,\epsilon$})?",,"['linear-algebra', 'statistics']"
58,Linear Combination of variables from the exponential family,Linear Combination of variables from the exponential family,,"As pointed out in this question , linear combinations of normal distributed variables are normal distributed: If $X$ is distributed normally as $N_p(\mu, \Sigma)$ then any linear combination of variables $a'X = a_1X_1 + a_2X_2 + \cdots + a_pX_p$ is distributed as $N(a'\mu, a'\Sigma a)$. Also, if $a'X$ is distributed as $N(a'\mu, a'\Sigma a)$ for every $a$, then $X$ must be $N_p(\mu, \Sigma)$. Can this result be generalized to broader classes of probability distributions as the exponential family?","As pointed out in this question , linear combinations of normal distributed variables are normal distributed: If $X$ is distributed normally as $N_p(\mu, \Sigma)$ then any linear combination of variables $a'X = a_1X_1 + a_2X_2 + \cdots + a_pX_p$ is distributed as $N(a'\mu, a'\Sigma a)$. Also, if $a'X$ is distributed as $N(a'\mu, a'\Sigma a)$ for every $a$, then $X$ must be $N_p(\mu, \Sigma)$. Can this result be generalized to broader classes of probability distributions as the exponential family?",,"['statistics', 'normal-distribution', 'linear-transformations']"
59,A probability of receiving k emergency calls in an hour is given by a function. Find m if you know that expected number of phone calls is 3 [closed],A probability of receiving k emergency calls in an hour is given by a function. Find m if you know that expected number of phone calls is 3 [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Got stuck with this one. Please help A probability of receiving k emergency calls in an hour is given by the probability function: $$P(k)=\dfrac{\mathsf e^{-m} ~ m^k}{k!}$$ Find $m$ if you know that expected number of phone calls is $3$ . Do it by calculating the expected number of phone calls for specific m. For example try m=1, 1.5, 2, 2.5,… . Do it as many times as you need to figure out formula.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Got stuck with this one. Please help A probability of receiving k emergency calls in an hour is given by the probability function: Find if you know that expected number of phone calls is . Do it by calculating the expected number of phone calls for specific m. For example try m=1, 1.5, 2, 2.5,… . Do it as many times as you need to figure out formula.",P(k)=\dfrac{\mathsf e^{-m} ~ m^k}{k!} m 3,"['probability', 'statistics', 'probability-distributions', 'expectation']"
60,Combinatorics/Probability Insurance accident,Combinatorics/Probability Insurance accident,,An insurance company classifies people as normal or accident prone. Suppose that the probability that a normal person has an accident in a specified year is 0.2 and that for an accident prone person this probability is 0.6. Further suppose that 18% of the policyholders are accident prone. A policyholder had no accidents in a specified year. What is the probability that he or she is accident prone? What I did: $P(\text{Normal&NoAccident}) = 0.82 \times 0.80 = 0.6560$ $P(\text{Accident Prone & No Accident} ) = 0.18 \times 0.94 = 0.1692$ $P(\text{No Accident}) = 0.6560 + 0.1692 = 0.8252$ $P(\text{Accident Prone} | \text{No Accident}) = P(\text{Accident Prone & No Accient}) / P(\text{No Accident}) = 0.2050$ I feel like this is too simple for a probability class. Is there something I am missing?,An insurance company classifies people as normal or accident prone. Suppose that the probability that a normal person has an accident in a specified year is 0.2 and that for an accident prone person this probability is 0.6. Further suppose that 18% of the policyholders are accident prone. A policyholder had no accidents in a specified year. What is the probability that he or she is accident prone? What I did: $P(\text{Normal&NoAccident}) = 0.82 \times 0.80 = 0.6560$ $P(\text{Accident Prone & No Accident} ) = 0.18 \times 0.94 = 0.1692$ $P(\text{No Accident}) = 0.6560 + 0.1692 = 0.8252$ $P(\text{Accident Prone} | \text{No Accident}) = P(\text{Accident Prone & No Accient}) / P(\text{No Accident}) = 0.2050$ I feel like this is too simple for a probability class. Is there something I am missing?,,"['probability', 'combinatorics', 'statistics', 'permutations']"
61,Estimate ratio of two expectations by sample means,Estimate ratio of two expectations by sample means,,"I have a question about the estimation of a ratio of two expectations. Suppose $X_{i}$ and $Y_{i}$ are two random variables with $i=1,\cdots,N$. We seek to estimate $\mathbb{E}X_{i}/\mathbb{E}Y_{i}$ by replacing $\mathbb{E}\left(\cdot\right)  $ with the sample mean. This will introduce a bias, as $$ \mathbb{E}\frac{\frac{1}{N}\sum_{i}X_{i}}{\frac{1}{N}\sum_{i}Y_{i}}\neq \frac{\mathbb{E}X_{i}}{\mathbb{E}Y_{i}}\text{.}% $$ I was wondering if this can be solved, to some required (stochastic) order, by some analytical method (i.e. not jackknife or bootstrap).","I have a question about the estimation of a ratio of two expectations. Suppose $X_{i}$ and $Y_{i}$ are two random variables with $i=1,\cdots,N$. We seek to estimate $\mathbb{E}X_{i}/\mathbb{E}Y_{i}$ by replacing $\mathbb{E}\left(\cdot\right)  $ with the sample mean. This will introduce a bias, as $$ \mathbb{E}\frac{\frac{1}{N}\sum_{i}X_{i}}{\frac{1}{N}\sum_{i}Y_{i}}\neq \frac{\mathbb{E}X_{i}}{\mathbb{E}Y_{i}}\text{.}% $$ I was wondering if this can be solved, to some required (stochastic) order, by some analytical method (i.e. not jackknife or bootstrap).",,"['probability', 'statistics', 'statistical-inference']"
62,Limiting Distribution $\Delta-$method,Limiting Distribution method,\Delta-,"Let $Y_n\sim \chi^2(n)$. What is the limiting distribution of $U_n= \dfrac{\sqrt{Y_n}-\sqrt{n}}{\sqrt{2}}?$. What I know is that if $X_i\sim \chi^2(1)$, I can write $Y_n = \sum\limits_{i=1}^n X_i$. Then the Central Limit Theorem implies that  $$\dfrac{Y_n-n}{\sqrt{2n}/\sqrt{n}}=\dfrac{Y_n-n}{\sqrt{2}} \dot{\sim} N(0,1).$$ This is close to the form required for $U_n$ but not exact. I'm having trouble seeing how to make them fit. I also know, by the $\Delta-$method theorem that $$\sqrt{n}(\sqrt{Y_n}-\sqrt{n})\overset{d}\to N(0,\sigma^2g'(\mu)^2),$$ where $\sigma^2$ is the variance of $Y_n-n$ and $g(t) = \sqrt{t}$. I guess I need help connecting these pieces to determine conclusively what $U_n$ has as its limiting distribution.","Let $Y_n\sim \chi^2(n)$. What is the limiting distribution of $U_n= \dfrac{\sqrt{Y_n}-\sqrt{n}}{\sqrt{2}}?$. What I know is that if $X_i\sim \chi^2(1)$, I can write $Y_n = \sum\limits_{i=1}^n X_i$. Then the Central Limit Theorem implies that  $$\dfrac{Y_n-n}{\sqrt{2n}/\sqrt{n}}=\dfrac{Y_n-n}{\sqrt{2}} \dot{\sim} N(0,1).$$ This is close to the form required for $U_n$ but not exact. I'm having trouble seeing how to make them fit. I also know, by the $\Delta-$method theorem that $$\sqrt{n}(\sqrt{Y_n}-\sqrt{n})\overset{d}\to N(0,\sigma^2g'(\mu)^2),$$ where $\sigma^2$ is the variance of $Y_n-n$ and $g(t) = \sqrt{t}$. I guess I need help connecting these pieces to determine conclusively what $U_n$ has as its limiting distribution.",,"['statistics', 'probability-distributions']"
63,higher-order (3+) Taylor expansion of a likelihood function,higher-order (3+) Taylor expansion of a likelihood function,,"I was wondering what is the effect if I replace the second derivative of the log-likelihood (""Likelihood"" hereafter) function with its expectation in a higher-order Taylor expansion of the likelihood function. Let the observations be i.i.d., $\ell(\theta)$ be the sample mean of individual likelihood over $N$ observations, and l{r}(theta) be the r-th derivative of l(theta) w.r.t. theta . A Taylor expansion of the likelihood around the truth ( theta_0 , scalar) and evaluated at the estimate ( theta_hat , scalar) gives l(theta_hat) = l(theta_0) + l{1}(theta_0)(theta_hat-theta_0) + 1/2 l{2}(theta_0)(theta_hat-theta_0)^2 + ... + 1/k! l{k}(theta_0)(theta_hat-theta_0)^k + Op[N^(-k-1/2)] . $$ \ell(\hat\theta) = \ell(\theta_0) + \ell'(\theta_0)(\hat\theta-\theta_0) + \frac 1 2 \ell''(\theta_0)(\hat\theta - \theta_0)^2 + \cdots + \frac 1 {k!} \ell^{(k)}(\hat\theta - \theta_0)^k + O_p(N^{-k-1/2}) $$ If k were 2, we could l{2}(theta_0) with E[l{2}(theta_0)] with no problem. Now let k>2 and I want the expansion to be correct in expectation. Can I still replace l{2}(theta_0) with E[l{2}(theta_0)] ? I understand that, typically, $$ \ell^{(2)}(\theta_0) = E\left[ \ell^{(2)}(\theta_0) \right] + O_p(N^{-1/2}) $$ such that, in some applications, replacing E[l{2}(theta_0)] with l{2}(theta_0) will introduce a nonneglectable bias to the order of Op(N^-1/2) . But what is the effect, to what I want, of the replacement that I explained above? I'm sorry that you are seeing this in such a bad format. I'm new to this place and they don't let me upload pictures....","I was wondering what is the effect if I replace the second derivative of the log-likelihood (""Likelihood"" hereafter) function with its expectation in a higher-order Taylor expansion of the likelihood function. Let the observations be i.i.d., $\ell(\theta)$ be the sample mean of individual likelihood over $N$ observations, and l{r}(theta) be the r-th derivative of l(theta) w.r.t. theta . A Taylor expansion of the likelihood around the truth ( theta_0 , scalar) and evaluated at the estimate ( theta_hat , scalar) gives l(theta_hat) = l(theta_0) + l{1}(theta_0)(theta_hat-theta_0) + 1/2 l{2}(theta_0)(theta_hat-theta_0)^2 + ... + 1/k! l{k}(theta_0)(theta_hat-theta_0)^k + Op[N^(-k-1/2)] . $$ \ell(\hat\theta) = \ell(\theta_0) + \ell'(\theta_0)(\hat\theta-\theta_0) + \frac 1 2 \ell''(\theta_0)(\hat\theta - \theta_0)^2 + \cdots + \frac 1 {k!} \ell^{(k)}(\hat\theta - \theta_0)^k + O_p(N^{-k-1/2}) $$ If k were 2, we could l{2}(theta_0) with E[l{2}(theta_0)] with no problem. Now let k>2 and I want the expansion to be correct in expectation. Can I still replace l{2}(theta_0) with E[l{2}(theta_0)] ? I understand that, typically, $$ \ell^{(2)}(\theta_0) = E\left[ \ell^{(2)}(\theta_0) \right] + O_p(N^{-1/2}) $$ such that, in some applications, replacing E[l{2}(theta_0)] with l{2}(theta_0) will introduce a nonneglectable bias to the order of Op(N^-1/2) . But what is the effect, to what I want, of the replacement that I explained above? I'm sorry that you are seeing this in such a bad format. I'm new to this place and they don't let me upload pictures....",,"['statistics', 'asymptotics', 'taylor-expansion', 'maximum-likelihood']"
64,calculation of median of grouped data,calculation of median of grouped data,,"While calculating the median of grouped data of total frequency $N$ , in order to find the median class which value should be taken into consideration to match against cumulative frequency : $\frac N2$ or $\frac{N+1}{2}$ (it seems both are used)? I think $\frac{N+1}{2}$ should be taken since in case of list of values (i.e. ungrouped data), its fractional value indicates that the average of $\frac N2 th$ and $(\frac N2 + 1) th$ values should give the median. And then comes the second part of my question -- while calculating the median of grouped data, if the value of $\frac{N+1}{2}$ ( or $\frac N2$ ) is a fraction, say 50.5, and there is a cumulative frequency 50, then what should we do? Should we take two median classes, one having cumulative frequency 50 and another coming next to it, and calculate two medians considering each of the median class using the formula: $L + \frac {\frac N2 - C}{f} \times w$ and take their average as the ultimate median? Or do something else? I mean what is the correct procedure in this kind of situation? EDIT: So, here is a specific problem regarding the second part of my question- We have to find out the median score from the following frequency distribution table: Score                :  0-10    10-20    20-30    30-40    40-50 Number of students   :   4        3        5        6        7 Cumulative frequency :   4        7        12       18       25 Here intervals are of type (,] . Now, $N=25 \implies  \frac N2 = 12.5$ , which means that we have to look for the interval which covers 12th item and 13th item. Looking at the cumulative frequencies, we see that the 3rd interval(i.e. 20-30) covers the 12th item,while 4th interval(i.e. 30-40) covers the 13th item. If we are supposed to take both the intervals as median class for the sake of using the formula: $median=L + \frac {\frac N2 - C}{f} \times w$ , then we will end up with two medians. We can take the average of these as the required median, though. I want to know the correct procedure here. Note 1: I am only concerned with using the above formula and not any other method of finding median of grouped data. There is a variation of the above formula where $\frac{N+1}{2}$ is used instead of $\frac N2$ , the first part of my question refers to this confusion as well. Note 2: In the formula, L = lower boundary of the median class N = total frequency C = cumulative frequency of the class preceding the median class f = frequency of the median class w = width of the median class i.e. upper boundary - lower boundary Note 3: If we consider the interval 20-30 as the median class and use the above formula, then the median will be $20 + \frac{\frac{25}{2} - 7}{5} \times 10 = 31$ Interestingly , considering the interval 30-40 as the median class, we would get the same median using the above formula. Though, I am not sure if this will be the case for every problem of this type. In that case we can take any of the two interval as the median class. Note 4: I don't know whether there is any rule for such kind of situation saying that we have to select that cumulative frequency (and hence the corresponding interval as the median class) which is nearer to the value of $\frac N2$ , in that case we have to take the interval 20-30 in this example as median class. It will be great and enough if anyone can confirm such a rule.","While calculating the median of grouped data of total frequency , in order to find the median class which value should be taken into consideration to match against cumulative frequency : or (it seems both are used)? I think should be taken since in case of list of values (i.e. ungrouped data), its fractional value indicates that the average of and values should give the median. And then comes the second part of my question -- while calculating the median of grouped data, if the value of ( or ) is a fraction, say 50.5, and there is a cumulative frequency 50, then what should we do? Should we take two median classes, one having cumulative frequency 50 and another coming next to it, and calculate two medians considering each of the median class using the formula: and take their average as the ultimate median? Or do something else? I mean what is the correct procedure in this kind of situation? EDIT: So, here is a specific problem regarding the second part of my question- We have to find out the median score from the following frequency distribution table: Score                :  0-10    10-20    20-30    30-40    40-50 Number of students   :   4        3        5        6        7 Cumulative frequency :   4        7        12       18       25 Here intervals are of type (,] . Now, , which means that we have to look for the interval which covers 12th item and 13th item. Looking at the cumulative frequencies, we see that the 3rd interval(i.e. 20-30) covers the 12th item,while 4th interval(i.e. 30-40) covers the 13th item. If we are supposed to take both the intervals as median class for the sake of using the formula: , then we will end up with two medians. We can take the average of these as the required median, though. I want to know the correct procedure here. Note 1: I am only concerned with using the above formula and not any other method of finding median of grouped data. There is a variation of the above formula where is used instead of , the first part of my question refers to this confusion as well. Note 2: In the formula, L = lower boundary of the median class N = total frequency C = cumulative frequency of the class preceding the median class f = frequency of the median class w = width of the median class i.e. upper boundary - lower boundary Note 3: If we consider the interval 20-30 as the median class and use the above formula, then the median will be Interestingly , considering the interval 30-40 as the median class, we would get the same median using the above formula. Though, I am not sure if this will be the case for every problem of this type. In that case we can take any of the two interval as the median class. Note 4: I don't know whether there is any rule for such kind of situation saying that we have to select that cumulative frequency (and hence the corresponding interval as the median class) which is nearer to the value of , in that case we have to take the interval 20-30 in this example as median class. It will be great and enough if anyone can confirm such a rule.",N \frac N2 \frac{N+1}{2} \frac{N+1}{2} \frac N2 th (\frac N2 + 1) th \frac{N+1}{2} \frac N2 L + \frac {\frac N2 - C}{f} \times w N=25 \implies  \frac N2 = 12.5 median=L + \frac {\frac N2 - C}{f} \times w \frac{N+1}{2} \frac N2 20 + \frac{\frac{25}{2} - 7}{5} \times 10 = 31 \frac N2,"['statistics', 'data-analysis', 'median']"
65,Normal Approximation formula - Why 12?,Normal Approximation formula - Why 12?,,"I've recently begun learning the Mann-Whitney U test and have had to use normal approximation. The formula is straight forward, but I find myself wondering why you use 12 as the denominator in the square root portion. I enjoying knowing where numbers come from where possible, especially when they are a very unusual number like 12. I attempted to google around to find the answer, but all I could find was places that could tell me the formula but not the WHY behind it.","I've recently begun learning the Mann-Whitney U test and have had to use normal approximation. The formula is straight forward, but I find myself wondering why you use 12 as the denominator in the square root portion. I enjoying knowing where numbers come from where possible, especially when they are a very unusual number like 12. I attempted to google around to find the answer, but all I could find was places that could tell me the formula but not the WHY behind it.",,['statistics']
66,cumulant of infinite sum of random variables,cumulant of infinite sum of random variables,,"Could you help me the following question? Let $X_i$ are identical independent random variables. Putting $Z:=\sum_{i=1}^{\infty}X_i$. Which conditions do we have $$k_n(Z)=\sum_{i=1}^{\infty}k_n(X_i),$$ where $k_n(Z)$ is the $n$-th cumulant of $Z$. How to prove this identity or any book mentions to this result? Thank you very much!","Could you help me the following question? Let $X_i$ are identical independent random variables. Putting $Z:=\sum_{i=1}^{\infty}X_i$. Which conditions do we have $$k_n(Z)=\sum_{i=1}^{\infty}k_n(X_i),$$ where $k_n(Z)$ is the $n$-th cumulant of $Z$. How to prove this identity or any book mentions to this result? Thank you very much!",,"['probability', 'statistics', 'stochastic-analysis']"
67,Generating probability distribution function from continuous data,Generating probability distribution function from continuous data,,"We have a continuous function $F(x,y)$ defined on a bounded domain $(x, y) \in [0, L_x] \times [0, L_y]$ . Suppose the function $F$ (the explicit form is irrelevant here) is defined such that $F(x,y)$ always lies between, say, 0 and 1. By varying $x$ and $y$ continuously over the finite region, we obtain a set of corresponding (continuous) values for $F$ . Now, I would like to find the PDF of the values assumed by $F$ itself. In other words, what I am looking for is the probability $P\, [F = \zeta;\,\, 0 \le \zeta \le 1]$ as a function of $\zeta$ . This answer suggests a numerical prescription for such a situation as follows: Way of generate a PDF from discrete / continuous data: Find a continuous equation that models the collected data, let say normal distribution equation Calculate the parameters required in the equation from the collected data.For example, parameters for normal distribution equation are mean and standard deviation. Calculate them from collected data Based on the parameters, plot the equation with continuous x-value --> that is called PDF However, I was wondering if there is a method to obtain the PDF analytically, given that we know the exact functional form of $F$ . I would greatly appreciate any help in this regard. Many thanks!","We have a continuous function defined on a bounded domain . Suppose the function (the explicit form is irrelevant here) is defined such that always lies between, say, 0 and 1. By varying and continuously over the finite region, we obtain a set of corresponding (continuous) values for . Now, I would like to find the PDF of the values assumed by itself. In other words, what I am looking for is the probability as a function of . This answer suggests a numerical prescription for such a situation as follows: Way of generate a PDF from discrete / continuous data: Find a continuous equation that models the collected data, let say normal distribution equation Calculate the parameters required in the equation from the collected data.For example, parameters for normal distribution equation are mean and standard deviation. Calculate them from collected data Based on the parameters, plot the equation with continuous x-value --> that is called PDF However, I was wondering if there is a method to obtain the PDF analytically, given that we know the exact functional form of . I would greatly appreciate any help in this regard. Many thanks!","F(x,y) (x, y) \in [0, L_x] \times [0, L_y] F F(x,y) x y F F P\, [F = \zeta;\,\, 0 \le \zeta \le 1] \zeta F","['probability', 'statistics', 'probability-distributions']"
68,Justifying the Normal Approx to the Binomial Distribution through MGFs,Justifying the Normal Approx to the Binomial Distribution through MGFs,,"Would absolutely love if someone could help me with this question, in a step by step way to help those who are uninitiated to Statistics and Mathematics. So, I am trying to ""prove/justify"" through MGFs how as n(the sample size) increases and goes to infinity, a standardized binomial distribution converges to the Standard Normal Distribution. So in the beginning we have $X_n $~$ Bin(n,p)$ then we standardize this $R.V.$ by subtracting the mean $E(X_n)=np$ and dividing by the $SD$ which is $np(1-p)$. After doing this, we get a new $R.V.$ with $mean=1$ and $variance=SD=1$. It is the distribution of this standardized quantity that converges to a fixed distribution, correct? Namely the Standard Normal Distribution. Let's call the standardized version of $X_n$, $Z_n$. I think what we need to do is to find the MGF of $Z_n$ and show that this MGF becomes the Standard Normal Distribution's MGF as the sample size $(n)$ heads toward infinity. Now $Z_n$ is a function of $X_n$ which we know the MGF of which is $(1-p+pe^t)^n$. Now I know that $Z_n$ is a linear transform and that we should be able to use this to simply the MGF but I don't understand how the course notes do it, mostly because they skip a lot of steps and it is difficult to follow. There is also a Taylor Series Expansion for the exponential that I am confused about although I do understand the concept of the series expansion. Help would be greatly appreciated! I would love assistant in exactly how we can prove this via MGF. Thanks so much in advance :)","Would absolutely love if someone could help me with this question, in a step by step way to help those who are uninitiated to Statistics and Mathematics. So, I am trying to ""prove/justify"" through MGFs how as n(the sample size) increases and goes to infinity, a standardized binomial distribution converges to the Standard Normal Distribution. So in the beginning we have $X_n $~$ Bin(n,p)$ then we standardize this $R.V.$ by subtracting the mean $E(X_n)=np$ and dividing by the $SD$ which is $np(1-p)$. After doing this, we get a new $R.V.$ with $mean=1$ and $variance=SD=1$. It is the distribution of this standardized quantity that converges to a fixed distribution, correct? Namely the Standard Normal Distribution. Let's call the standardized version of $X_n$, $Z_n$. I think what we need to do is to find the MGF of $Z_n$ and show that this MGF becomes the Standard Normal Distribution's MGF as the sample size $(n)$ heads toward infinity. Now $Z_n$ is a function of $X_n$ which we know the MGF of which is $(1-p+pe^t)^n$. Now I know that $Z_n$ is a linear transform and that we should be able to use this to simply the MGF but I don't understand how the course notes do it, mostly because they skip a lot of steps and it is difficult to follow. There is also a Taylor Series Expansion for the exponential that I am confused about although I do understand the concept of the series expansion. Help would be greatly appreciated! I would love assistant in exactly how we can prove this via MGF. Thanks so much in advance :)",,"['calculus', 'statistics', 'statistical-inference', 'moment-generating-functions']"
69,"If X,Y and Z are independent, are X and YZ independent?","If X,Y and Z are independent, are X and YZ independent?",,"If yes: I know that f(X) and g(Y) are independent if X and Y are independent and f and g are ""measurable"".* If that is to be used, is g(Y) = YZ measurable? If not, how else to approach this? If no: Counterexample please? ^-^ Possibly related: How do you prove that if $ X_t \sim^{iid} (0,1) $, then $ E(X_t^{2}X_{t-j}^{2}) = E(X_t^{2})E(X_{t-j}^{2})$? Prove that $f(X)$ and $g(Y)$ are independent if $X$ and $Y$ are independent If $X$ and $Y$ are independent then $f(X)$ and $g(Y)$ are also independent.","If yes: I know that f(X) and g(Y) are independent if X and Y are independent and f and g are ""measurable"".* If that is to be used, is g(Y) = YZ measurable? If not, how else to approach this? If no: Counterexample please? ^-^ Possibly related: How do you prove that if $ X_t \sim^{iid} (0,1) $, then $ E(X_t^{2}X_{t-j}^{2}) = E(X_t^{2})E(X_{t-j}^{2})$? Prove that $f(X)$ and $g(Y)$ are independent if $X$ and $Y$ are independent If $X$ and $Y$ are independent then $f(X)$ and $g(Y)$ are also independent.",,"['probability-theory', 'random-variables', 'independence']"
70,Maximizing the Parameters of a Function,Maximizing the Parameters of a Function,,"I am currently in an assistant student research position (I am working directly with a, for sake of privacy, Dr. R, on developmental Toxicity Dose-Response Modeling simulation). I am currently using R trying to maximize and estimate using the 'mle' function (maximum likelihood estimate). Having trouble with this question before I have asked questions on sister sites found here: Trouble With MLE! The function with parameters I want to estimate is, $$L\varpropto \sum_{i=1}^g\sum_{j=1}^{m_i}\{\sum_{k=0}^{x_{ij} -1}log(\mu_i +k*\theta_i )+\sum_{k=0}^{n_{ij}-x_{ij}-1}log(1-\mu_i+k*\theta_i)-\sum_{k=0}^{n_{ij}-1}log(1+k*\theta_i)\}$$ where, $g, m_i, x_{ij},and \space n_{ij}$ are already known. This means the parameters i want to estimate and maximize are $\mu_1...\mu_g$ and $\theta_1...\theta_g$ . I have initial values for both $\mu\space and\space\theta$ . My Question is: What methods can I use to maximize and estimate these parameters? Though I have been using the mle function as shown in the above link, I was curious to see if there were other methods since I could not get the mle function to work. The research i have done online points me to other statistical software or R, which i am obviously having trouble with. Any help would be appreciated!","I am currently in an assistant student research position (I am working directly with a, for sake of privacy, Dr. R, on developmental Toxicity Dose-Response Modeling simulation). I am currently using R trying to maximize and estimate using the 'mle' function (maximum likelihood estimate). Having trouble with this question before I have asked questions on sister sites found here: Trouble With MLE! The function with parameters I want to estimate is, where, are already known. This means the parameters i want to estimate and maximize are and . I have initial values for both . My Question is: What methods can I use to maximize and estimate these parameters? Though I have been using the mle function as shown in the above link, I was curious to see if there were other methods since I could not get the mle function to work. The research i have done online points me to other statistical software or R, which i am obviously having trouble with. Any help would be appreciated!","L\varpropto \sum_{i=1}^g\sum_{j=1}^{m_i}\{\sum_{k=0}^{x_{ij} -1}log(\mu_i +k*\theta_i )+\sum_{k=0}^{n_{ij}-x_{ij}-1}log(1-\mu_i+k*\theta_i)-\sum_{k=0}^{n_{ij}-1}log(1+k*\theta_i)\} g, m_i, x_{ij},and \space n_{ij} \mu_1...\mu_g \theta_1...\theta_g \mu\space and\space\theta","['statistics', 'optimization', 'parameter-estimation']"
71,conditional weak convergence almost surely and joint unconditional weak convergence,conditional weak convergence almost surely and joint unconditional weak convergence,,"Sorry for the confusing title! Consider random variables $\{X_n, Y_n:n\geq 1\}$, defined on the same probability space $(\Omega, \mathcal{A}, P)$. Suppose, (i) $X_n \stackrel{d}{\rightarrow} Z$, (ii) $Y_n\mid X_n \stackrel{d}{\rightarrow} Z$, almost surely $(P)$. This is the same random variable $Z$ as considered in (i). Assume $Z_1,Z_2$ are iid with the same d.f. as $Z$. Then, I need to show that, unconditionally,  $$ (X_n, Y_n) \stackrel{d}{\rightarrow} (Z_1, Z_2). $$ Also, will this be true if almost surely is replaced with in probability $(P)$ in part (ii) above. Any references, ideas will be highly appreciated. This is mentioned as a statement in page 475 of the book by Dasgupta (Asymp. Theory of Stat and Prob.). Thanks!","Sorry for the confusing title! Consider random variables $\{X_n, Y_n:n\geq 1\}$, defined on the same probability space $(\Omega, \mathcal{A}, P)$. Suppose, (i) $X_n \stackrel{d}{\rightarrow} Z$, (ii) $Y_n\mid X_n \stackrel{d}{\rightarrow} Z$, almost surely $(P)$. This is the same random variable $Z$ as considered in (i). Assume $Z_1,Z_2$ are iid with the same d.f. as $Z$. Then, I need to show that, unconditionally,  $$ (X_n, Y_n) \stackrel{d}{\rightarrow} (Z_1, Z_2). $$ Also, will this be true if almost surely is replaced with in probability $(P)$ in part (ii) above. Any references, ideas will be highly appreciated. This is mentioned as a statement in page 475 of the book by Dasgupta (Asymp. Theory of Stat and Prob.). Thanks!",,"['probability', 'statistics']"
72,Describing a linear predictor for a stationary process with a set of equations,Describing a linear predictor for a stationary process with a set of equations,,"In some exam review I received the following question Assume that $\{X_{t}\}$ is a stationary time series, with mean $\mu$ and acvf $\gamma(h)$. Let $P_{n}X_{n+h}$ be the optimal (in terms of MSE) linear prediction of $X_{n+h}$ based on $X_{1},...,X_{n}$. Show explicitly how to write down a set of equations which define $P_{n}X_{n+h}$ in the case $n=2$ and $h=1$. Now I know that the best linear predictor of $X_{n+h}$ given the set $X_{n}, \text{...} , X_{1}$ is  \begin{equation*}Pred(X_{n+h}|X_{n}, \text{...}, X_{1}) = \mu + (a_{1}, \text{...}, a_{n})^{T} \begin{pmatrix} X_{n}-\mu \\ X_{n-1}-\mu \\ . \\ . \\ X_{1} - \mu \end{pmatrix} \end{equation*} where $\mathbf{a}$ satisfies the avcf equation. I also know the MSE is given by $$\gamma(0) - \mathbf{a}^{T}\gamma(n,h)$$. What I'm unsure about is what exactly a set of equations defining my optimal predictor would look like. Do I simply plug in $n=2$ and $h=1$ to rewrite the definition I've given, or is there something more to it?","In some exam review I received the following question Assume that $\{X_{t}\}$ is a stationary time series, with mean $\mu$ and acvf $\gamma(h)$. Let $P_{n}X_{n+h}$ be the optimal (in terms of MSE) linear prediction of $X_{n+h}$ based on $X_{1},...,X_{n}$. Show explicitly how to write down a set of equations which define $P_{n}X_{n+h}$ in the case $n=2$ and $h=1$. Now I know that the best linear predictor of $X_{n+h}$ given the set $X_{n}, \text{...} , X_{1}$ is  \begin{equation*}Pred(X_{n+h}|X_{n}, \text{...}, X_{1}) = \mu + (a_{1}, \text{...}, a_{n})^{T} \begin{pmatrix} X_{n}-\mu \\ X_{n-1}-\mu \\ . \\ . \\ X_{1} - \mu \end{pmatrix} \end{equation*} where $\mathbf{a}$ satisfies the avcf equation. I also know the MSE is given by $$\gamma(0) - \mathbf{a}^{T}\gamma(n,h)$$. What I'm unsure about is what exactly a set of equations defining my optimal predictor would look like. Do I simply plug in $n=2$ and $h=1$ to rewrite the definition I've given, or is there something more to it?",,"['statistics', 'time-series', 'stationary-processes']"
73,What is the Edgeworth Expansion of the binomial distribution?,What is the Edgeworth Expansion of the binomial distribution?,,"For a standardized binomial distributed random variable $\tilde B_n$ we have $$P(\tilde B_n\le x) = \Phi(x) + \frac {q-p}{6\sqrt{npq}}  (1-x^2) \phi(x) + \frac{R_1\left(np+x\sqrt{npq}\right)}{\sqrt{npq}}\phi(x) + O\left(\frac 1n\right)$$ with $R_1(x)=\lfloor x \rfloor -x +\frac 12$ [1] . Question: What is the Edgeworth Expension for $P( a \le \tilde B_n \le b)$? Is it true, that it is $$\begin{align} P( a \le \tilde B_n \le b) &=   \Phi(b)-\Phi(a) + \frac {q-p}{6\sqrt{npq}}  (1-b^2) \phi(b) - \frac {q-p}{6\sqrt{npq}}  (1-a^2) \phi(a) \\ & + \frac{R_1\left(np+b\sqrt{npq}\right)}{\sqrt{npq}}\phi(b)-\frac{R_2\left(np+a\sqrt{npq}\right)}{\sqrt{npq}}\phi(a) + O\left(\frac 1n\right) \end{align}$$ with $R_2(x)=\lceil x \rceil -x -\frac 12$ ?","For a standardized binomial distributed random variable $\tilde B_n$ we have $$P(\tilde B_n\le x) = \Phi(x) + \frac {q-p}{6\sqrt{npq}}  (1-x^2) \phi(x) + \frac{R_1\left(np+x\sqrt{npq}\right)}{\sqrt{npq}}\phi(x) + O\left(\frac 1n\right)$$ with $R_1(x)=\lfloor x \rfloor -x +\frac 12$ [1] . Question: What is the Edgeworth Expension for $P( a \le \tilde B_n \le b)$? Is it true, that it is $$\begin{align} P( a \le \tilde B_n \le b) &=   \Phi(b)-\Phi(a) + \frac {q-p}{6\sqrt{npq}}  (1-b^2) \phi(b) - \frac {q-p}{6\sqrt{npq}}  (1-a^2) \phi(a) \\ & + \frac{R_1\left(np+b\sqrt{npq}\right)}{\sqrt{npq}}\phi(b)-\frac{R_2\left(np+a\sqrt{npq}\right)}{\sqrt{npq}}\phi(a) + O\left(\frac 1n\right) \end{align}$$ with $R_2(x)=\lceil x \rceil -x -\frac 12$ ?",,"['probability', 'statistics', 'asymptotics', 'normal-distribution', 'binomial-distribution']"
74,"What does $W_{1}$ and $(W_{1},W_{2})$ mean under the context of Brownian motion $W_{t}$?",What does  and  mean under the context of Brownian motion ?,"W_{1} (W_{1},W_{2}) W_{t}","As part of some practice questions for a course I'm taking, I was given the definition of a Brownian motion $W_{t}$ as  a unique continous-time stochastic process satisfying: $W_{0}=0$ The function $t \rightarrow W_{t}$ is almost surely everywhere continous. The increments $W_{t_{1}} - W_{s_{1}}W_{t_{2}}-W_{s_{2}}$ are independent when $0 \leq s_{1} < t_{1} \leq s_{2}<t_{2}$ The increment $W_{t} - W_{s}$ has a $N(0, t-s)$ distribution for $0 \leq s < t$. This seems to make sense and I did some further research into Brownian motions, however then I was asked what the distribution of $W_{1}$ and $(W_{1},W_{2})$ would be. I don't really know what this means, as I don't know how to express either as any more than some function that is almost everywhere continuous.. it feels like my given definition isn't exactly enough to go off of...","As part of some practice questions for a course I'm taking, I was given the definition of a Brownian motion $W_{t}$ as  a unique continous-time stochastic process satisfying: $W_{0}=0$ The function $t \rightarrow W_{t}$ is almost surely everywhere continous. The increments $W_{t_{1}} - W_{s_{1}}W_{t_{2}}-W_{s_{2}}$ are independent when $0 \leq s_{1} < t_{1} \leq s_{2}<t_{2}$ The increment $W_{t} - W_{s}$ has a $N(0, t-s)$ distribution for $0 \leq s < t$. This seems to make sense and I did some further research into Brownian motions, however then I was asked what the distribution of $W_{1}$ and $(W_{1},W_{2})$ would be. I don't really know what this means, as I don't know how to express either as any more than some function that is almost everywhere continuous.. it feels like my given definition isn't exactly enough to go off of...",,"['statistics', 'brownian-motion']"
75,measuring the regularity of a grid,measuring the regularity of a grid,,"I'd like to find a method for scoring the difference in regularity of points in grids - there are two examples below (left) a relatively well ordered grid and (right) a relatively disordered grid. I have a brutish method which analyses nearest neighbours, finds approximate orientations (rotation and shear) and then attempts to fit a modelled grid (and computes the score of the model compared with the real data). It seems that there must be a more elegant solution, maybe by calculating an entropic value for each grid (I only want to know which is more regular, and maybe by how much). Thanks in advance, Dan","I'd like to find a method for scoring the difference in regularity of points in grids - there are two examples below (left) a relatively well ordered grid and (right) a relatively disordered grid. I have a brutish method which analyses nearest neighbours, finds approximate orientations (rotation and shear) and then attempts to fit a modelled grid (and computes the score of the model compared with the real data). It seems that there must be a more elegant solution, maybe by calculating an entropic value for each grid (I only want to know which is more regular, and maybe by how much). Thanks in advance, Dan",,['statistics']
76,Which correlation coefficient indicates the strongest relationship between two variables?,Which correlation coefficient indicates the strongest relationship between two variables?,,"I'm trying to understand correlation coefficients, and seem to be missing something. For example, Correlation coefficient: Indicates the direction, positively or negatively of the relationship, and how strongly the 2 variables are related. I understand that the strength can vary from 0-1 and I thought I understood that positive or negative simply had to do with the direction of the correlation. This question is part of my review and I don't understand why my answer is incorrect... Which correlation coefficient indicates the strongest relationship between two variables? a) -0.85 - This was my answer which I thought was the closest to one (meaning strongest b)1.94 c)0.58 - This is what the textbook says is the correct answer, but why? d)0.19 Thanks for your help!","I'm trying to understand correlation coefficients, and seem to be missing something. For example, Correlation coefficient: Indicates the direction, positively or negatively of the relationship, and how strongly the 2 variables are related. I understand that the strength can vary from 0-1 and I thought I understood that positive or negative simply had to do with the direction of the correlation. This question is part of my review and I don't understand why my answer is incorrect... Which correlation coefficient indicates the strongest relationship between two variables? a) -0.85 - This was my answer which I thought was the closest to one (meaning strongest b)1.94 c)0.58 - This is what the textbook says is the correct answer, but why? d)0.19 Thanks for your help!",,['statistics']
77,"100 coin flips, expect to see 7 heads in a row","100 coin flips, expect to see 7 heads in a row",,"So a random piece of information in a video I watched ages ago popped in my head tonight and I started thinking about it.  I believe I am remembering this video properly... They flipped a coin 100 times you saw the ratio of head and tails to be 50/50.  They created a diagram of all the flips.  There was a lot of flip-flopping between heads and tail.  There were even some strings of 4 or 5 heads/tails in a row.  At one point in the chart there were 7 heads in a row.  They said in a sample this size, that was expected. That is where my question is, is there a mathematical formula or something that allows us to compute, in a sample size of 100, where the outcome can go 50% one way or the other, the probability of getting 7 of one outcome in a row?","So a random piece of information in a video I watched ages ago popped in my head tonight and I started thinking about it.  I believe I am remembering this video properly... They flipped a coin 100 times you saw the ratio of head and tails to be 50/50.  They created a diagram of all the flips.  There was a lot of flip-flopping between heads and tail.  There were even some strings of 4 or 5 heads/tails in a row.  At one point in the chart there were 7 heads in a row.  They said in a sample this size, that was expected. That is where my question is, is there a mathematical formula or something that allows us to compute, in a sample size of 100, where the outcome can go 50% one way or the other, the probability of getting 7 of one outcome in a row?",,"['probability', 'statistics']"
78,Chi-Squared distribution as an Exponential Family Distribution,Chi-Squared distribution as an Exponential Family Distribution,,"I'm trying to write the chi-squared distribution in the form of: $$\exp\big\{(y\theta-b(\theta))/(\phi/w)-c(y,\phi)\big\}.$$ Using a shape-mean paramatization of the gamma distribution (i.e. taking shape parameter $\alpha$ and rate $\beta$, then re-parametrizing the $\beta$ parameter with $\mu=\alpha/\beta$, I was able to write the gamma distribution in this form, with: $$\theta=-1/\mu,\  b(\theta) = -\log(-\theta),\ \phi=1/\alpha,\ w=1,$$ and $$c(y,\phi) = \log(\Gamma(\alpha))-\alpha \log(\alpha)-(\alpha-1)\log(y).$$ As the chi-square is a special case of the gamma distribution with shape $\alpha=k/2$ and rate $\beta=1/2$, I initially tried using this. However I end up with $\theta=-1/k$ and $\phi=2/k$. In other words, the top and bottom of the first term in the exponential pdf form are literally just multiplied by $1/k$ in order to force a canonical parameter in there. This seems a bit weird to me - especially as if $\phi$ is a function of $\theta$, then $c(y,\phi)$ is a function of $\theta$ too, which it shouldn't be. Other than that, I get a canonical parameter of $\theta=-1$. However, the $b()$ function is not meant to rely upon $\phi$, so there is no way of having $b'(\theta)=k$. tldr: how do I go about expressing the chi-square pdf in the form of the exponential family of probability distribution? Sorry if it's a bit hard to read! thanks!","I'm trying to write the chi-squared distribution in the form of: $$\exp\big\{(y\theta-b(\theta))/(\phi/w)-c(y,\phi)\big\}.$$ Using a shape-mean paramatization of the gamma distribution (i.e. taking shape parameter $\alpha$ and rate $\beta$, then re-parametrizing the $\beta$ parameter with $\mu=\alpha/\beta$, I was able to write the gamma distribution in this form, with: $$\theta=-1/\mu,\  b(\theta) = -\log(-\theta),\ \phi=1/\alpha,\ w=1,$$ and $$c(y,\phi) = \log(\Gamma(\alpha))-\alpha \log(\alpha)-(\alpha-1)\log(y).$$ As the chi-square is a special case of the gamma distribution with shape $\alpha=k/2$ and rate $\beta=1/2$, I initially tried using this. However I end up with $\theta=-1/k$ and $\phi=2/k$. In other words, the top and bottom of the first term in the exponential pdf form are literally just multiplied by $1/k$ in order to force a canonical parameter in there. This seems a bit weird to me - especially as if $\phi$ is a function of $\theta$, then $c(y,\phi)$ is a function of $\theta$ too, which it shouldn't be. Other than that, I get a canonical parameter of $\theta=-1$. However, the $b()$ function is not meant to rely upon $\phi$, so there is no way of having $b'(\theta)=k$. tldr: how do I go about expressing the chi-square pdf in the form of the exponential family of probability distribution? Sorry if it's a bit hard to read! thanks!",,"['probability', 'statistics', 'probability-distributions']"
79,Is the chance of a variable also a parameter for a probability distribution?,Is the chance of a variable also a parameter for a probability distribution?,,I'm new to statistics and I'm a bit confused about the concepts of 'chance of a variable' and 'parameters of a probability distribition'. Is chance also a parameter? And if so: can computing the chance of a variable be considered as an estimation for the parameters?,I'm new to statistics and I'm a bit confused about the concepts of 'chance of a variable' and 'parameters of a probability distribition'. Is chance also a parameter? And if so: can computing the chance of a variable be considered as an estimation for the parameters?,,"['statistics', 'probability-distributions', 'parameter-estimation']"
80,Finding the expected value and variance of ${X^3}$,Finding the expected value and variance of,{X^3},"For a random variable $X$, $(X^3-1)$ is uniformly distributed in the interval $[0,7]$ I need to find the expected value and variance of $\color{blue}{X^3}$ and I know that: cumulative distribution function: $$F_{X}(x)= \begin{cases} 0&;x < 1\\ \frac{x^3-1}{7}&;1\leq x \leq 2\\ 1&;x>2\\ \end{cases}$$ probability density function: $$f_{X}(t)= \begin{cases} 0&;t \not\in (1,2)\\ \frac{3x^2}{7}&; t \in (1,2)\\ \end{cases}$$ My attempt: $X^3-1 \sim U(0,7)$ $X^3 \sim U(1,8)$ $E(X^3)=\frac{1+8}{2}=4.5$ $\text{Var}(X^3)=\frac{(b-a)^2}{12}=\frac{(8-1)^2}{12}\approx4.083$ Is it correct?","For a random variable $X$, $(X^3-1)$ is uniformly distributed in the interval $[0,7]$ I need to find the expected value and variance of $\color{blue}{X^3}$ and I know that: cumulative distribution function: $$F_{X}(x)= \begin{cases} 0&;x < 1\\ \frac{x^3-1}{7}&;1\leq x \leq 2\\ 1&;x>2\\ \end{cases}$$ probability density function: $$f_{X}(t)= \begin{cases} 0&;t \not\in (1,2)\\ \frac{3x^2}{7}&; t \in (1,2)\\ \end{cases}$$ My attempt: $X^3-1 \sim U(0,7)$ $X^3 \sim U(1,8)$ $E(X^3)=\frac{1+8}{2}=4.5$ $\text{Var}(X^3)=\frac{(b-a)^2}{12}=\frac{(8-1)^2}{12}\approx4.083$ Is it correct?",,"['statistics', 'proof-verification']"
81,I have some questions related to Fisher's book 1925.,I have some questions related to Fisher's book 1925.,,"I was studying Fisher 1925 and while reading i had some trouble with this part. Fitting the Normal Distribution From a sample of $n$ individuals of a normal population the mean and the standard deviation of the population may be estimated by using two easily calculated statistics. The best estimate of $m$ is $x$ where $$\overline{x} = \frac{1}{n} \, S(x),$$ while for the best estimate of sigma , we calculate s from $$S^2= \left(\frac{1}{n-1}\right)(X-\overline{X})^2$$ these two statistics are calculated from the sums of the first two powers of the observations (see Appendix, p. 73), and are specially related to the normal distribution, in that they summarise the whole of the information which the sample provides as to the distribution from which it was drawn, provided the latter was normal. Fitting by sums of powers, and especially by the particular system of statistics known as moments, has also been widely applied to skew (asymmetrical) distributions, and others which are not normal. On the other hand, on page 73 he writes: A. Statistics derived from sums of powers. If we have $n$ observations of a variate $x$, it is easy to calculate for the sample the sums of the simpler powers of the values observed, these we may write \begin{align} s_l &= S(x) \\ s_2 &= S(X^2) \\ s_3 &= S(X^3) \\ s_4 &= S(X^4) \end{align} and so on. It is convenient arithmetically to calculate from these the sums of powers of deviations from the mean defined by the equations  \begin{align} S_2 &= s_2- \frac{1}{n} \cdot s_1^2 \\ S_3 &= s_3 - \frac{3}{n} \cdot s_2\cdot s_1 + \frac{2}{n^2} \cdot s_1^3 \\ S_4 &= s_4 - \frac{4}{n} \cdot s_3 \cdot s_1 + \frac{6}{n^2} \cdot s_2 \cdot s_1^2 - \frac{3}{n^3} \cdot s_1^4 \end{align} Many statistics in frequent use are derived from these values. (i) Moments about the arbitrary origin, $x = 0$; these are derived simply by dividing the corresponding sum by the number in the sample; in general if $p$ stand for $p= I, 2, 3, 4, \ldots$, they are defined by the formula $$m'p = \frac{1}{n} \cdot sp,$$ where  ($p$ is index). Clearly m'l is the arithmetic mean, usually written $\overline{x}$ (ii) In order to obtain values independent of the arbitrary origin, and more closely related to the intrinsic characteristics of the 'population sampled, values called"" moments about the mean"" are widely used, which are found by dividing the sums of powers about the mean by the sample number; thus if $p=2, 3, 4, \ldots$ $$mp= \frac{1}{n}\cdot S p$$ (again $p$ is the index) My question are:  1) which is the intuition behind moment ( i searched on google but it was a bit complicated to get the point.) Pls try to explain the logic and not so many equations.  2) Where are these equations coming from?  \begin{align} S_2 &= s_2 - \frac{1}{n}\cdot s_1^2 \\ S_3 &= s_3 - \frac{3}{n}\cdot s_2\cdot s_1 + \frac{2}{n^2}\cdot s_1^3 \\ S_4 &= s_4 - \frac{4}{n}\cdot s_3\cdot s_1 + \frac{6}{n^2}\cdot s_2 \cdot s_1^2 - \frac{3}{n^3}\cdot s_1^4 \text{ ?}  \end{align} 3) Why in the case of normal distribution,  sums of first and second power they summarise the whole of the information which the sample provides as to the distribution from which it was drawn, provided the latter was normal, and in other distributions you have to calculate greater power sums? Thanks in advance!","I was studying Fisher 1925 and while reading i had some trouble with this part. Fitting the Normal Distribution From a sample of $n$ individuals of a normal population the mean and the standard deviation of the population may be estimated by using two easily calculated statistics. The best estimate of $m$ is $x$ where $$\overline{x} = \frac{1}{n} \, S(x),$$ while for the best estimate of sigma , we calculate s from $$S^2= \left(\frac{1}{n-1}\right)(X-\overline{X})^2$$ these two statistics are calculated from the sums of the first two powers of the observations (see Appendix, p. 73), and are specially related to the normal distribution, in that they summarise the whole of the information which the sample provides as to the distribution from which it was drawn, provided the latter was normal. Fitting by sums of powers, and especially by the particular system of statistics known as moments, has also been widely applied to skew (asymmetrical) distributions, and others which are not normal. On the other hand, on page 73 he writes: A. Statistics derived from sums of powers. If we have $n$ observations of a variate $x$, it is easy to calculate for the sample the sums of the simpler powers of the values observed, these we may write \begin{align} s_l &= S(x) \\ s_2 &= S(X^2) \\ s_3 &= S(X^3) \\ s_4 &= S(X^4) \end{align} and so on. It is convenient arithmetically to calculate from these the sums of powers of deviations from the mean defined by the equations  \begin{align} S_2 &= s_2- \frac{1}{n} \cdot s_1^2 \\ S_3 &= s_3 - \frac{3}{n} \cdot s_2\cdot s_1 + \frac{2}{n^2} \cdot s_1^3 \\ S_4 &= s_4 - \frac{4}{n} \cdot s_3 \cdot s_1 + \frac{6}{n^2} \cdot s_2 \cdot s_1^2 - \frac{3}{n^3} \cdot s_1^4 \end{align} Many statistics in frequent use are derived from these values. (i) Moments about the arbitrary origin, $x = 0$; these are derived simply by dividing the corresponding sum by the number in the sample; in general if $p$ stand for $p= I, 2, 3, 4, \ldots$, they are defined by the formula $$m'p = \frac{1}{n} \cdot sp,$$ where  ($p$ is index). Clearly m'l is the arithmetic mean, usually written $\overline{x}$ (ii) In order to obtain values independent of the arbitrary origin, and more closely related to the intrinsic characteristics of the 'population sampled, values called"" moments about the mean"" are widely used, which are found by dividing the sums of powers about the mean by the sample number; thus if $p=2, 3, 4, \ldots$ $$mp= \frac{1}{n}\cdot S p$$ (again $p$ is the index) My question are:  1) which is the intuition behind moment ( i searched on google but it was a bit complicated to get the point.) Pls try to explain the logic and not so many equations.  2) Where are these equations coming from?  \begin{align} S_2 &= s_2 - \frac{1}{n}\cdot s_1^2 \\ S_3 &= s_3 - \frac{3}{n}\cdot s_2\cdot s_1 + \frac{2}{n^2}\cdot s_1^3 \\ S_4 &= s_4 - \frac{4}{n}\cdot s_3\cdot s_1 + \frac{6}{n^2}\cdot s_2 \cdot s_1^2 - \frac{3}{n^3}\cdot s_1^4 \text{ ?}  \end{align} 3) Why in the case of normal distribution,  sums of first and second power they summarise the whole of the information which the sample provides as to the distribution from which it was drawn, provided the latter was normal, and in other distributions you have to calculate greater power sums? Thanks in advance!",,"['statistics', 'moment-generating-functions']"
82,"How Kriging, Bochner theorem and Positive definite (PD) function are related?","How Kriging, Bochner theorem and Positive definite (PD) function are related?",,"This question referes to the link: https://en.wikipedia.org/wiki/Kriging I can understand the relation between Bochner's theorem and PD function. But could not properly understand and connect all three elements namely, Kriging, Bochner's theorem and PD function. I would love to know a clear connection between these three. May be these three are related through Fourier transform, my wild guess; any clarification would be appreciated.","This question referes to the link: https://en.wikipedia.org/wiki/Kriging I can understand the relation between Bochner's theorem and PD function. But could not properly understand and connect all three elements namely, Kriging, Bochner's theorem and PD function. I would love to know a clear connection between these three. May be these three are related through Fourier transform, my wild guess; any clarification would be appreciated.",,"['linear-algebra', 'functional-analysis', 'statistics', 'soft-question', 'definition']"
83,Comparing two percentages when one is negative,Comparing two percentages when one is negative,,"I am having trouble comparing two percent values to show the change in one compared to the change in another. For all stores looking at all sales: The average sales growth for week 1 this year compared to last year = 8% The average sales growth for week 2 this year compared to last year = 7% Change: $\frac{7\%}{8\%}-1=-12\%$ For all stores looking at only food sales: The average sales growth for week 1 this year compared to last year = 25% The average sales growth for week 2 this year compared to last year = 32% Change: $\frac{32\%}{25\%}-1=27.8\%$ So these values are the average total sales growth and total food sales growth this year compared to last for all stores. I want to compare a specific store to these averages: For Store A looking at all sales: The average sales growth for week 1 this year compared to last year = 33% The average sales growth for week 2 this year compared to last year = 41% Change: $\frac{41\%}{33\%}-1=22.5\%$ For Store A looking at only food sales: The average sales growth for week 1 this year compared to last year = 21% The average sales growth for week 2 this year compared to last year = 47% Change: $\frac{47\%}{21\%}-1=122.5\%$ To summarize this all All sales growth Store A: 22.5% All stores: -12% Food sales growth Store A: 122.5% All stores: 27.8% How do I compare the growth of store A compared to all stores for all sales and only food sales? What percentage of food sales make up all sales? My first approach is the relative change formula: (new value - old value)/|(old value) $\frac{22.5\%-(-12\%)}{\left |-12\%  \right |}$ but since the base percent is negative the signs don't make sense What about, $-(\frac{22.5\%}{-12\%})+1 = 2.8x$? The values for food only $\frac{122.5\%}{27.8\%} = 4.4x$ Does this make sense? Is the growth of food at this store compared to other stores 4.4x more? Is the growth of all sales 2.8x more at store A compared to other stores? Knowing this information, is it possible to look at what percentage of food makes up all sales?","I am having trouble comparing two percent values to show the change in one compared to the change in another. For all stores looking at all sales: The average sales growth for week 1 this year compared to last year = 8% The average sales growth for week 2 this year compared to last year = 7% Change: $\frac{7\%}{8\%}-1=-12\%$ For all stores looking at only food sales: The average sales growth for week 1 this year compared to last year = 25% The average sales growth for week 2 this year compared to last year = 32% Change: $\frac{32\%}{25\%}-1=27.8\%$ So these values are the average total sales growth and total food sales growth this year compared to last for all stores. I want to compare a specific store to these averages: For Store A looking at all sales: The average sales growth for week 1 this year compared to last year = 33% The average sales growth for week 2 this year compared to last year = 41% Change: $\frac{41\%}{33\%}-1=22.5\%$ For Store A looking at only food sales: The average sales growth for week 1 this year compared to last year = 21% The average sales growth for week 2 this year compared to last year = 47% Change: $\frac{47\%}{21\%}-1=122.5\%$ To summarize this all All sales growth Store A: 22.5% All stores: -12% Food sales growth Store A: 122.5% All stores: 27.8% How do I compare the growth of store A compared to all stores for all sales and only food sales? What percentage of food sales make up all sales? My first approach is the relative change formula: (new value - old value)/|(old value) $\frac{22.5\%-(-12\%)}{\left |-12\%  \right |}$ but since the base percent is negative the signs don't make sense What about, $-(\frac{22.5\%}{-12\%})+1 = 2.8x$? The values for food only $\frac{122.5\%}{27.8\%} = 4.4x$ Does this make sense? Is the growth of food at this store compared to other stores 4.4x more? Is the growth of all sales 2.8x more at store A compared to other stores? Knowing this information, is it possible to look at what percentage of food makes up all sales?",,"['algebra-precalculus', 'statistics', 'percentages']"
84,Regression with many discrete and continuous predictors and few rows,Regression with many discrete and continuous predictors and few rows,,"I want to do regression on a dataset. It has one continuous dependent variable that I want to predict. It has many categorical and some continuous predictors. It only has a few rows. A simplified example might look like this (Dx means discrete predictor, Cx means continuous predictor, IV is the independent variable I'm trying to predict.): +----+-------+---------+-----+---------+---------+-----+-----+ | IV |  D1   |   D2    | D3  |   D4    |   D5    | C1  | C2  | +----+-------+---------+-----+---------+---------+-----+-----+ |  5 | 1,2,3 | 1,2     | 1   | 1       | 1       | 2   | 3.5 | |  4 | 2,3,4 | 1,3     | 2   | 2,3     | 1,2     | 2.5 | -2  | | -2 | 1,3,5 | 2,3     | 3,4 | 2       | 1,3     | 2.2 | 50  | |  4 | 4,6,7 | 4,5,6,7 | 4,5 | 3,4,5,6 | 1,2,3,4 | 2.2 | 50  | +----+-------+---------+-----+---------+---------+-----+-----+ You can see that the categorical variables can have multiple discrete values for each row, so I can dummy code it like this to simplify the data: +----+------+------+------+------+------+------+------+-----+ | IV | D1-1 | D1-2 | D1-3 | D1-4 | D1-5 | D1-6 | D1-7 | ... | +----+------+------+------+------+------+------+------+-----+ |  5 |    1 |    1 |    1 |    0 |    0 |    0 |    0 | ... | |  4 |    0 |    1 |    1 |    1 |    0 |    0 |    0 | ... | | -2 |    1 |    0 |    1 |    0 |    1 |    0 |    0 | ... | |  4 |    0 |    0 |    0 |    1 |    0 |    1 |    1 | ... | +----+------+------+------+------+------+------+------+-----+ Now the key is: I can't do multiple linear regression because the number of rows is less than the number of columns, and I don't want to remove any of the predictors. One way (Method A) I thought could work is to do individual linear regression for each predictor and combine the linear models into one. However I don't really know how to combine them. One possible way is to use the correlation coefficient (r^2/sum of all r^2) as the weight for each predictor, but I don't know whether there's a better way. Another way (Method B) - I feel is better - is to use individual linear regression for the continuous variables, and just a mean/variance analysis for the discrete variables (like ANOVA), then combine the models using the some transform of the standard variation f(sigma) as the weight for each discrete variable, and f(r^2) as the weight for the continuous variable. Therefore, my questions are: If I use method B, what should be the f(sigma) and f(r^2)? (How should I combine the individual models?) Is there a better way?","I want to do regression on a dataset. It has one continuous dependent variable that I want to predict. It has many categorical and some continuous predictors. It only has a few rows. A simplified example might look like this (Dx means discrete predictor, Cx means continuous predictor, IV is the independent variable I'm trying to predict.): +----+-------+---------+-----+---------+---------+-----+-----+ | IV |  D1   |   D2    | D3  |   D4    |   D5    | C1  | C2  | +----+-------+---------+-----+---------+---------+-----+-----+ |  5 | 1,2,3 | 1,2     | 1   | 1       | 1       | 2   | 3.5 | |  4 | 2,3,4 | 1,3     | 2   | 2,3     | 1,2     | 2.5 | -2  | | -2 | 1,3,5 | 2,3     | 3,4 | 2       | 1,3     | 2.2 | 50  | |  4 | 4,6,7 | 4,5,6,7 | 4,5 | 3,4,5,6 | 1,2,3,4 | 2.2 | 50  | +----+-------+---------+-----+---------+---------+-----+-----+ You can see that the categorical variables can have multiple discrete values for each row, so I can dummy code it like this to simplify the data: +----+------+------+------+------+------+------+------+-----+ | IV | D1-1 | D1-2 | D1-3 | D1-4 | D1-5 | D1-6 | D1-7 | ... | +----+------+------+------+------+------+------+------+-----+ |  5 |    1 |    1 |    1 |    0 |    0 |    0 |    0 | ... | |  4 |    0 |    1 |    1 |    1 |    0 |    0 |    0 | ... | | -2 |    1 |    0 |    1 |    0 |    1 |    0 |    0 | ... | |  4 |    0 |    0 |    0 |    1 |    0 |    1 |    1 | ... | +----+------+------+------+------+------+------+------+-----+ Now the key is: I can't do multiple linear regression because the number of rows is less than the number of columns, and I don't want to remove any of the predictors. One way (Method A) I thought could work is to do individual linear regression for each predictor and combine the linear models into one. However I don't really know how to combine them. One possible way is to use the correlation coefficient (r^2/sum of all r^2) as the weight for each predictor, but I don't know whether there's a better way. Another way (Method B) - I feel is better - is to use individual linear regression for the continuous variables, and just a mean/variance analysis for the discrete variables (like ANOVA), then combine the models using the some transform of the standard variation f(sigma) as the weight for each discrete variable, and f(r^2) as the weight for the continuous variable. Therefore, my questions are: If I use method B, what should be the f(sigma) and f(r^2)? (How should I combine the individual models?) Is there a better way?",,"['statistics', 'regression']"
85,Uniform Sampling on Intersection of Simplices,Uniform Sampling on Intersection of Simplices,,"I'm trying to sample uniformly on the intersections of faces of several simplicies, with all coordinates being non-negative. That is, given constraints $$A\vec{w}=\vec{b} \ \ and \ \ \vec{w} \geq \vec{0} \ \ and \ \ \sum w_i = 1,$$ I want to sample $\vec{w}$ uniformly. $A$'s dimension is about $100 \times 10000$. A concrete example will be:  $$A = \begin{bmatrix}      1 & 1 & 1 \\     0 & 1 & 2 \end{bmatrix}, \  b=\begin{bmatrix}      1  \\     0.7 \end{bmatrix}$$, sample $\vec{w}$ uniformly from $Aw=b$ subject to $\vec{w} \geq \vec{0}$ and $\sum w_i = 1$ (This makes the sampling space bounded). Below is a graphical representation of the problem -- to sample uniformly from the red intersection line. I am well aware that rejection-sampling and MCMC sampling can theoretically solve this problem. However, I have already implemented both approaches in programming, and neither of these two methods performs well enough. This is because the dimension of my sampling space usually goes up to 10000, and rejection sampling simply throws away too many points and MCMC is taking forever to converge. Therefore, I'm desperate to try new methods. Many thanks in advance!! (please do not provide answers using rejection sampling; methods that already have open-source programming implementations are favored)","I'm trying to sample uniformly on the intersections of faces of several simplicies, with all coordinates being non-negative. That is, given constraints $$A\vec{w}=\vec{b} \ \ and \ \ \vec{w} \geq \vec{0} \ \ and \ \ \sum w_i = 1,$$ I want to sample $\vec{w}$ uniformly. $A$'s dimension is about $100 \times 10000$. A concrete example will be:  $$A = \begin{bmatrix}      1 & 1 & 1 \\     0 & 1 & 2 \end{bmatrix}, \  b=\begin{bmatrix}      1  \\     0.7 \end{bmatrix}$$, sample $\vec{w}$ uniformly from $Aw=b$ subject to $\vec{w} \geq \vec{0}$ and $\sum w_i = 1$ (This makes the sampling space bounded). Below is a graphical representation of the problem -- to sample uniformly from the red intersection line. I am well aware that rejection-sampling and MCMC sampling can theoretically solve this problem. However, I have already implemented both approaches in programming, and neither of these two methods performs well enough. This is because the dimension of my sampling space usually goes up to 10000, and rejection sampling simply throws away too many points and MCMC is taking forever to converge. Therefore, I'm desperate to try new methods. Many thanks in advance!! (please do not provide answers using rejection sampling; methods that already have open-source programming implementations are favored)",,"['linear-algebra', 'geometry', 'statistics', 'convex-analysis', 'uniform-distribution']"
86,Confidence interval for sample,Confidence interval for sample,,"I have a sample of size $n=19593$ of count data 1      2     3    4    5   6   7   8   9   10  11  12  13  14  15  16  17  18  19 20 21 22 23 24 25 26 27   18890  3032  1542  727  599 530 409 363 298 266 261 273 231 268 129 131 145 120 119 29 62 48 0  18 0  38 10 I want to find a confidence interval for the center of the data, specifically in the form $n \mu$. Do I have enough data to estimate $\sigma$ and use the central limit theorem. The negative binomial seems to be the best fit among known distributions, but I  don't think it is the right fit because of the long tail in the data, so would bootstrapping be a better approach and using the median instead of the mean to measure the center of the data.","I have a sample of size $n=19593$ of count data 1      2     3    4    5   6   7   8   9   10  11  12  13  14  15  16  17  18  19 20 21 22 23 24 25 26 27   18890  3032  1542  727  599 530 409 363 298 266 261 273 231 268 129 131 145 120 119 29 62 48 0  18 0  38 10 I want to find a confidence interval for the center of the data, specifically in the form $n \mu$. Do I have enough data to estimate $\sigma$ and use the central limit theorem. The negative binomial seems to be the best fit among known distributions, but I  don't think it is the right fit because of the long tail in the data, so would bootstrapping be a better approach and using the median instead of the mean to measure the center of the data.",,"['statistics', 'statistical-inference', 'estimation']"
87,Clustering elements according to covariance matrix,Clustering elements according to covariance matrix,,"I'm doing a little bit of topic modelling (which is not really my area) with twitter tweets. The situation is the following: I have a (sort of) covariance matrix where the entrie $C_{ij}$ corresponds to the frequency of the words $i$ and $j$ occuring together in a tweet. Given this Matrix $C$ I would like to automatically cluster words into different topics. However, since my background isn't statistics nor data analysis, I think I might need the correct terms to search for. I'm not sure if k-means or PCA is what I need. In the optimal case, I end up with a not prior specified number of topics, that gathers that combines only the words that really correlated. Especially, I don't want all words to be assigned, given that some words only correlate very little.","I'm doing a little bit of topic modelling (which is not really my area) with twitter tweets. The situation is the following: I have a (sort of) covariance matrix where the entrie $C_{ij}$ corresponds to the frequency of the words $i$ and $j$ occuring together in a tweet. Given this Matrix $C$ I would like to automatically cluster words into different topics. However, since my background isn't statistics nor data analysis, I think I might need the correct terms to search for. I'm not sure if k-means or PCA is what I need. In the optimal case, I end up with a not prior specified number of topics, that gathers that combines only the words that really correlated. Especially, I don't want all words to be assigned, given that some words only correlate very little.",,"['statistics', 'reference-request', 'data-analysis', 'data-mining']"
88,Behavior of MGF of Quadratic Combination of Dependent Multivariate Gaussians,Behavior of MGF of Quadratic Combination of Dependent Multivariate Gaussians,,"Sorry if the formatting is poor, this is my first time asking a question.  I'm investigating how squared gaussians behave, using the techniques provided here , which are giving me inconsistent results.  Here's the (simplified) setup:  I have four random variables, $Q_1, Q_2, Q_3, Q_4$, which are distributed as follows: $$ \left[ \begin{array}{c} Q_1\\ Q_2\\ Q_3\\ Q_4\\ \end{array} \right] \sim  N_4\left(\left[\begin{array}{c} 0\\ 0\\ 0\\ 0 \end{array} \right], \left[ \begin{array}{cccc} 1&0&\alpha&0\\ 0&1&0&\beta\\ \alpha&0&1&0\\ 0&\beta&0&1\\ \end{array} \right]\right)\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \alpha,\beta \in [0,1] $$ I'm dealing with the distribution $BQ_1^2 + CQ_2^2 - 2Q_1Q_2$ (D1) where $B,C$ are constants.  Furthermore I want to contrast the behavior of that distribution to distribution $\frac{1}{2}(BQ_1^2 + CQ_2^2 - 2Q_1Q_2 + BQ_3^2 + CQ_4^2 - 2Q_3Q_4)$ (D2), under the circumstances where $\alpha = \beta = 1$.  Ideally, and as I understand it, they are distributed the same way under that correlation assumption, as the repeated terms are perfectly correlated.    Using the techniques mentioned in the linked question, and an ""A"" matrix (again, see the question I linked to above) that looks like $$ \left[ \begin{array}{cccc} B&-1&0&0\\ -1&C&0&0\\ 0&0&B&-1\\ 0&0&-1&C\\ \end{array} \right] $$ I get that (D2) as above is distributed according to $$\frac{1}{2}\left(\left(\frac{\sqrt{1 - \alpha}}{2} + \frac{\sqrt{1 + \alpha}}{2}\right)^2 BT_1 + \left(\frac{\sqrt{1 - \beta}}{2} + \frac{\sqrt{1 + \beta}}{2}\right)^2 CT_2 + \left(\frac{\sqrt{1 - \alpha}}{2} + \frac{\sqrt{1 + \alpha}}{2}\right)^2 BT_3 + \left(\frac{\sqrt{1 - \beta}}{2} + \frac{\sqrt{1 + \beta}}{2}\right)^2 CT_4\right)$$ where each $T_i$ is an independent chi square random variable with d.o.f. 1.  Under the assumption that $\alpha = \beta = 1$, this becomes $$\frac{1}{2}\left(\frac{1}{2}BT_1 + \frac{1}{2}CT_2 + \frac{1}{2}BT_3 + \frac{1}{2}CT_4\right)$$   However, using a truncated $A$ matrix to discern the distribution of $D1$, $$ \left[ \begin{array}{cc} B&-1\\ -1&C\\ \end{array} \right] $$ And similarly a truncated covariance matrix that is just the 2X2 identity, I get that $(D1)$ is distributed according to  $$\frac{1}{2}(B + C - \sqrt{4 + B^2 - 2 B C + C^2})Y_1 + \frac{1}{2}(B + C + \sqrt{4 + B^2 - 2 B C + C^2})Y_2$$ Where $Y_i$ are again independent chi square random variables with d.o.f. 1. My issue is that $\frac{1}{2}(B + C - \sqrt{4 + B^2 - 2 B C + C^2})Y_1 + \frac{1}{2}(B + C + \sqrt{4 + B^2 - 2 B C + C^2})Y_2$ doesn't particularly look like $\frac{1}{2}\left(\frac{1}{2}BT_1 + \frac{1}{2}CT_2 + \frac{1}{2}BT_3 + \frac{1}{2}CT_4\right)$, even though we would expect that $BQ_1^2 + CQ_2^2 - 2Q_1Q_2 = \frac{1}{2}(BQ_1^2 + CQ_2^2 - 2Q_1Q_2 + BQ_3^2 + CQ_4^2 - 2Q_3Q_4)$ when $Q_1 = Q_3$ and $Q_2 = Q_4$.  I've tried massaging them to work out the same to no avail; it turns out the rest of my mathematics not shown here allows me to put these ""into"" moment generating functions. The relevant term for $(D1)$ becomes $$(1- (B + C - \sqrt{4 + B^2 - 2 B C + C^2}))^\frac{1}{2}(1-(B + C + \sqrt{4 + B^2 - 2 B C + C^2}))^\frac{1}{2}$$ and the relevant term for (D2) becomes $$(1-\frac{1}{2}B)^\frac{1}{2}(1-\frac{1}{2}C)^\frac{1}{2}(1-\frac{1}{2}B)^\frac{1}{2}(1-\frac{1}{2}C)^\frac{1}{2}$$ $$=(1-\frac{1}{2}B)(1-\frac{1}{2}C)$$ which appears to have no hope of being equal just by virtue of dimensionality. What am I doing wrong?  I am fairly convinced that these things should be equal in the perfectly correlated case, and yet here I am, and they are not at all equal. Something else I noted was that the distribution for (D2) isn't sensitive to adjustments in the off diagonal values of the $A$ matrix, but the distribution for (D1) is.  That is to say, if we replace all the values of $-1$ in the matrices by $-\sqrt{2}$, the chi squared decomposition for (D2) remains the same but is different for (D1). As I said at the top, I left some things out.  I can include them if this picture is not clear enough.","Sorry if the formatting is poor, this is my first time asking a question.  I'm investigating how squared gaussians behave, using the techniques provided here , which are giving me inconsistent results.  Here's the (simplified) setup:  I have four random variables, $Q_1, Q_2, Q_3, Q_4$, which are distributed as follows: $$ \left[ \begin{array}{c} Q_1\\ Q_2\\ Q_3\\ Q_4\\ \end{array} \right] \sim  N_4\left(\left[\begin{array}{c} 0\\ 0\\ 0\\ 0 \end{array} \right], \left[ \begin{array}{cccc} 1&0&\alpha&0\\ 0&1&0&\beta\\ \alpha&0&1&0\\ 0&\beta&0&1\\ \end{array} \right]\right)\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; \alpha,\beta \in [0,1] $$ I'm dealing with the distribution $BQ_1^2 + CQ_2^2 - 2Q_1Q_2$ (D1) where $B,C$ are constants.  Furthermore I want to contrast the behavior of that distribution to distribution $\frac{1}{2}(BQ_1^2 + CQ_2^2 - 2Q_1Q_2 + BQ_3^2 + CQ_4^2 - 2Q_3Q_4)$ (D2), under the circumstances where $\alpha = \beta = 1$.  Ideally, and as I understand it, they are distributed the same way under that correlation assumption, as the repeated terms are perfectly correlated.    Using the techniques mentioned in the linked question, and an ""A"" matrix (again, see the question I linked to above) that looks like $$ \left[ \begin{array}{cccc} B&-1&0&0\\ -1&C&0&0\\ 0&0&B&-1\\ 0&0&-1&C\\ \end{array} \right] $$ I get that (D2) as above is distributed according to $$\frac{1}{2}\left(\left(\frac{\sqrt{1 - \alpha}}{2} + \frac{\sqrt{1 + \alpha}}{2}\right)^2 BT_1 + \left(\frac{\sqrt{1 - \beta}}{2} + \frac{\sqrt{1 + \beta}}{2}\right)^2 CT_2 + \left(\frac{\sqrt{1 - \alpha}}{2} + \frac{\sqrt{1 + \alpha}}{2}\right)^2 BT_3 + \left(\frac{\sqrt{1 - \beta}}{2} + \frac{\sqrt{1 + \beta}}{2}\right)^2 CT_4\right)$$ where each $T_i$ is an independent chi square random variable with d.o.f. 1.  Under the assumption that $\alpha = \beta = 1$, this becomes $$\frac{1}{2}\left(\frac{1}{2}BT_1 + \frac{1}{2}CT_2 + \frac{1}{2}BT_3 + \frac{1}{2}CT_4\right)$$   However, using a truncated $A$ matrix to discern the distribution of $D1$, $$ \left[ \begin{array}{cc} B&-1\\ -1&C\\ \end{array} \right] $$ And similarly a truncated covariance matrix that is just the 2X2 identity, I get that $(D1)$ is distributed according to  $$\frac{1}{2}(B + C - \sqrt{4 + B^2 - 2 B C + C^2})Y_1 + \frac{1}{2}(B + C + \sqrt{4 + B^2 - 2 B C + C^2})Y_2$$ Where $Y_i$ are again independent chi square random variables with d.o.f. 1. My issue is that $\frac{1}{2}(B + C - \sqrt{4 + B^2 - 2 B C + C^2})Y_1 + \frac{1}{2}(B + C + \sqrt{4 + B^2 - 2 B C + C^2})Y_2$ doesn't particularly look like $\frac{1}{2}\left(\frac{1}{2}BT_1 + \frac{1}{2}CT_2 + \frac{1}{2}BT_3 + \frac{1}{2}CT_4\right)$, even though we would expect that $BQ_1^2 + CQ_2^2 - 2Q_1Q_2 = \frac{1}{2}(BQ_1^2 + CQ_2^2 - 2Q_1Q_2 + BQ_3^2 + CQ_4^2 - 2Q_3Q_4)$ when $Q_1 = Q_3$ and $Q_2 = Q_4$.  I've tried massaging them to work out the same to no avail; it turns out the rest of my mathematics not shown here allows me to put these ""into"" moment generating functions. The relevant term for $(D1)$ becomes $$(1- (B + C - \sqrt{4 + B^2 - 2 B C + C^2}))^\frac{1}{2}(1-(B + C + \sqrt{4 + B^2 - 2 B C + C^2}))^\frac{1}{2}$$ and the relevant term for (D2) becomes $$(1-\frac{1}{2}B)^\frac{1}{2}(1-\frac{1}{2}C)^\frac{1}{2}(1-\frac{1}{2}B)^\frac{1}{2}(1-\frac{1}{2}C)^\frac{1}{2}$$ $$=(1-\frac{1}{2}B)(1-\frac{1}{2}C)$$ which appears to have no hope of being equal just by virtue of dimensionality. What am I doing wrong?  I am fairly convinced that these things should be equal in the perfectly correlated case, and yet here I am, and they are not at all equal. Something else I noted was that the distribution for (D2) isn't sensitive to adjustments in the off diagonal values of the $A$ matrix, but the distribution for (D1) is.  That is to say, if we replace all the values of $-1$ in the matrices by $-\sqrt{2}$, the chi squared decomposition for (D2) remains the same but is different for (D1). As I said at the top, I left some things out.  I can include them if this picture is not clear enough.",,"['linear-algebra', 'statistics', 'moment-generating-functions']"
89,Rao-Blackwell theorem and conditional distribution,Rao-Blackwell theorem and conditional distribution,,"Let $X_1,..,X_n$ random sample of $X\sim\text{Exp}(\lambda)$ with   $f(x;\lambda)=\frac{1}{\lambda}e^{-\frac{1}{\lambda}x}I_{[0,\infty]}(x)$ i) Find a unbiased estimator of $\lambda$ based only in   $X_{(1)}=\min(X_i)$ ii) Apply the Rao-Blackwell theorem for find a   estimator better that you find in i) For i) I find that $\hat{\lambda}=nX_{(1)}$ is unbiased estimator for $\lambda$. Now for the part ii) that is the problem. I know that $f(x;\lambda)\in$ the exponential family and $T=\sum X_i$ is a complete and sufficient statistic. Then since $\phi_T=E[nX_{(1)}|\sum X_i]$ produces a unbiased estimator, then it needs to be UMVUE. So I calculated the Cramer-Rao Lower Bound and find $\text{var}_\lambda\geq \frac{\lambda^2}{n}$, finally I just take $\phi_T=\frac{\sum X_i}{n}$ Now my doubts are: i)My reasoning is correct? ii)I always need to calculate conditional distribution? iii)Is there any simple way to find this conditional? iv)How could I find the conditional in this case? I am unable to find that conditional","Let $X_1,..,X_n$ random sample of $X\sim\text{Exp}(\lambda)$ with   $f(x;\lambda)=\frac{1}{\lambda}e^{-\frac{1}{\lambda}x}I_{[0,\infty]}(x)$ i) Find a unbiased estimator of $\lambda$ based only in   $X_{(1)}=\min(X_i)$ ii) Apply the Rao-Blackwell theorem for find a   estimator better that you find in i) For i) I find that $\hat{\lambda}=nX_{(1)}$ is unbiased estimator for $\lambda$. Now for the part ii) that is the problem. I know that $f(x;\lambda)\in$ the exponential family and $T=\sum X_i$ is a complete and sufficient statistic. Then since $\phi_T=E[nX_{(1)}|\sum X_i]$ produces a unbiased estimator, then it needs to be UMVUE. So I calculated the Cramer-Rao Lower Bound and find $\text{var}_\lambda\geq \frac{\lambda^2}{n}$, finally I just take $\phi_T=\frac{\sum X_i}{n}$ Now my doubts are: i)My reasoning is correct? ii)I always need to calculate conditional distribution? iii)Is there any simple way to find this conditional? iv)How could I find the conditional in this case? I am unable to find that conditional",,"['probability', 'statistics', 'statistical-inference', 'conditional-expectation']"
90,Validity of conditional CDF proof via PDF integral,Validity of conditional CDF proof via PDF integral,,"Given the question: $$\text{Show that}\ F_X(x\mid A) = \dfrac{\Pr(A\mid X\leq x)}{\Pr(A)}\cdot F_X(x)$$ I have seen the solution via probabilities 'directly'. My question is whether the following method was (unnecessary extra work, but nonetheless) valid: \begin{align} & F_X(x\mid A) = \int_{-\infty}^x f_X(t\mid A)\, dt \\[8pt] = {} & \int_{-\infty}^x \dfrac{\Pr(A\mid X=t)}{\Pr(A)} f_X(t)\, dt \\[8pt] = {} & \dfrac{\Pr(A\mid X\leq x)}{\Pr(A)} \int_{-\infty}^x f_X(t)\, dt \\[8pt] = {} & \dfrac{\Pr(A\mid X\leq x)}{\Pr(A)}\cdot F_X(x) \end{align} I suppose my doubts lie in the original formulation as integral of $f_X(x\mid A)$, and also the extraction of $\Pr(X=x)$ to be $\Pr(X\leq x)$ outside the integral - which seems to intuitively make sense, but I'm not sure that's actually sound?","Given the question: $$\text{Show that}\ F_X(x\mid A) = \dfrac{\Pr(A\mid X\leq x)}{\Pr(A)}\cdot F_X(x)$$ I have seen the solution via probabilities 'directly'. My question is whether the following method was (unnecessary extra work, but nonetheless) valid: \begin{align} & F_X(x\mid A) = \int_{-\infty}^x f_X(t\mid A)\, dt \\[8pt] = {} & \int_{-\infty}^x \dfrac{\Pr(A\mid X=t)}{\Pr(A)} f_X(t)\, dt \\[8pt] = {} & \dfrac{\Pr(A\mid X\leq x)}{\Pr(A)} \int_{-\infty}^x f_X(t)\, dt \\[8pt] = {} & \dfrac{\Pr(A\mid X\leq x)}{\Pr(A)}\cdot F_X(x) \end{align} I suppose my doubts lie in the original formulation as integral of $f_X(x\mid A)$, and also the extraction of $\Pr(X=x)$ to be $\Pr(X\leq x)$ outside the integral - which seems to intuitively make sense, but I'm not sure that's actually sound?",,"['probability', 'statistics', 'bayes-theorem']"
91,"Sufficient statistics and UMVUE for joint poisson, bernoulli","Sufficient statistics and UMVUE for joint poisson, bernoulli",,"Given a pair $(X,Y)$ of r.v.s such that: $$X \sim  \text{Poisson}(\lambda)\quad \text{and}\quad Y \sim  B(\frac{\lambda}{1+\lambda})$$ with $X,Y$ independent, determine a   one-dimensional sufficient statistic for $\lambda$ and the UMVUE   (uniformly minimum variance unbiased estimator) for $\lambda$ . Attempt: $$P(X,Y\mid(x_1,x_2,\dots, x_n, y_1,y_2,\dots y_n)) =  P(X\mid(x_1,x_2, \dots x_n))\times P(Y|(y_1,y_2, \dots y_n)) = \prod_{i=1}^n\frac{\lambda^{x_i}e^{-\lambda}}{x_i!} \times \frac{\lambda^{y_i}}{1+\lambda} = \frac{\lambda^{\sum (x_i+y_i)} e^{-n\lambda}}{(1+\lambda)^n \prod x_i!} $$ Using the factorisation theorem, $\sum(x_i+y_i)$ is a sufficient statistic. It is however not an unbiased estimator of $\lambda$ because: $$E\left(\sum(x_i+y_i)\right) = n\left(\lambda + \frac{\lambda}{1+\lambda}\right)$$ A trivial unbiased estimator would be $\frac{\sum x_i}{n}$ , but then it is not sufficient. To utilise Rao-Blackwell Theorem, $\sum x_i$ should be conditioned on $\sum x_i + y_i$ . I am not able to proceed further.","Given a pair of r.v.s such that: with independent, determine a   one-dimensional sufficient statistic for and the UMVUE   (uniformly minimum variance unbiased estimator) for . Attempt: Using the factorisation theorem, is a sufficient statistic. It is however not an unbiased estimator of because: A trivial unbiased estimator would be , but then it is not sufficient. To utilise Rao-Blackwell Theorem, should be conditioned on . I am not able to proceed further.","(X,Y) X \sim
 \text{Poisson}(\lambda)\quad \text{and}\quad Y \sim
 B(\frac{\lambda}{1+\lambda}) X,Y \lambda \lambda P(X,Y\mid(x_1,x_2,\dots, x_n, y_1,y_2,\dots y_n)) =  P(X\mid(x_1,x_2, \dots x_n))\times P(Y|(y_1,y_2, \dots y_n)) = \prod_{i=1}^n\frac{\lambda^{x_i}e^{-\lambda}}{x_i!} \times \frac{\lambda^{y_i}}{1+\lambda} = \frac{\lambda^{\sum (x_i+y_i)} e^{-n\lambda}}{(1+\lambda)^n \prod x_i!}
 \sum(x_i+y_i) \lambda E\left(\sum(x_i+y_i)\right) = n\left(\lambda + \frac{\lambda}{1+\lambda}\right) \frac{\sum x_i}{n} \sum x_i \sum x_i + y_i","['probability', 'statistics', 'probability-distributions', 'estimation']"
92,Personal Experiences with Probability Simulation,Personal Experiences with Probability Simulation,,"Simulations methods are increasingly used in theoretical and (especially) applied probability. Personally, I have used simulation for purposes that range from recreational Q&A to applications of considerable practical importance. Examples include (a) discovering that 'solutions' to combinatorial problems are clearly wrong, (b) checking the practical usefulness of bounds, and (c) multidimensional integration with MCMC methods where it seems simulation is the only feasible path to an answer. For teaching simulation, I would very much like to have a collection of specific applications of probability simulation methods from people at various mathematical levels and in various areas of the mathematical and other sciences. Your personal accounts of specific, actual uses of probability simulation would be much appreciated. Some applications might be bootstrap, permutation test, MCMC, Gibbs sampling, Metropolis-Hastings, but many others. (I am not especially interested here in philosophical comments on the nature of randomness, the quality of PRNGs, or uses of software for exact probability computations that don't involve simulation--all perhaps useful discussion for another venue.)","Simulations methods are increasingly used in theoretical and (especially) applied probability. Personally, I have used simulation for purposes that range from recreational Q&A to applications of considerable practical importance. Examples include (a) discovering that 'solutions' to combinatorial problems are clearly wrong, (b) checking the practical usefulness of bounds, and (c) multidimensional integration with MCMC methods where it seems simulation is the only feasible path to an answer. For teaching simulation, I would very much like to have a collection of specific applications of probability simulation methods from people at various mathematical levels and in various areas of the mathematical and other sciences. Your personal accounts of specific, actual uses of probability simulation would be much appreciated. Some applications might be bootstrap, permutation test, MCMC, Gibbs sampling, Metropolis-Hastings, but many others. (I am not especially interested here in philosophical comments on the nature of randomness, the quality of PRNGs, or uses of software for exact probability computations that don't involve simulation--all perhaps useful discussion for another venue.)",,"['probability', 'statistics', 'mathematical-physics', 'economics', 'simulation']"
93,Why Laplace transform equals zero if and only if $f(x)=0$?,Why Laplace transform equals zero if and only if ?,f(x)=0,"The question is how to show the Laplace transform of $L(f(x))=\int_0^{ + \infty } {f(x){e^{ - sx}}dx}  = 0$ if and only if $f(x)=0$? The question arises when I watch this video https://www.youtube.com/watch?v=Z1cmSOaEak8&index=14&list=PLbMVogVj5nJRkNUH5v9qNEJvW7r2A7rEY at 57:00, when the professor tries to prove normal distribution $N(\mu,1)$ is complete by stating $\int_{ - \infty }^{ + \infty } {g(x){e^{ - \frac{{{x^2}}}{2}}}{e^{\mu x}}dx}  = 0$ if and only if $g(x)=0$. The following is a scree capture. Thank you!","The question is how to show the Laplace transform of $L(f(x))=\int_0^{ + \infty } {f(x){e^{ - sx}}dx}  = 0$ if and only if $f(x)=0$? The question arises when I watch this video https://www.youtube.com/watch?v=Z1cmSOaEak8&index=14&list=PLbMVogVj5nJRkNUH5v9qNEJvW7r2A7rEY at 57:00, when the professor tries to prove normal distribution $N(\mu,1)$ is complete by stating $\int_{ - \infty }^{ + \infty } {g(x){e^{ - \frac{{{x^2}}}{2}}}{e^{\mu x}}dx}  = 0$ if and only if $g(x)=0$. The following is a scree capture. Thank you!",,"['calculus', 'statistics']"
94,"If I remove a remove a subset of a uniform distribution, will it remain uniform?","If I remove a remove a subset of a uniform distribution, will it remain uniform?",,"suppose that I have a long sequence of random numbers coming from a uniform distribution. If I remove a small subset from the sequence (either part of the sequence, or randomly pick some elements), will the remaining sequence still be a uniform distribution? Thank you! edit: all of the elements are generated from the same distribution. For example generate 10,000 values randomly from a uniform distribution with a range of [0,1]","suppose that I have a long sequence of random numbers coming from a uniform distribution. If I remove a small subset from the sequence (either part of the sequence, or randomly pick some elements), will the remaining sequence still be a uniform distribution? Thank you! edit: all of the elements are generated from the same distribution. For example generate 10,000 values randomly from a uniform distribution with a range of [0,1]",,"['statistics', 'probability-distributions']"
95,Covariance of absolute value of variables,Covariance of absolute value of variables,,"I have some relatively complicated variables I am working with. I need to find the covariance: $\text{cov}(\left|x\right|,\left|y\right|)$, is there a simplification of $\text{cov}(\left|x\right|,\left|y\right|)$ in terms of $\text{cov}(x,y)$?","I have some relatively complicated variables I am working with. I need to find the covariance: $\text{cov}(\left|x\right|,\left|y\right|)$, is there a simplification of $\text{cov}(\left|x\right|,\left|y\right|)$ in terms of $\text{cov}(x,y)$?",,"['probability', 'statistics', 'expectation', 'covariance']"
96,Can one player win more games while scoring fewer points over multiple trials a simple probabilistic game?,Can one player win more games while scoring fewer points over multiple trials a simple probabilistic game?,,"The Game Two players $P_{1}$ and $P_{2}$ will play the following game: Three non-negative numbers $a$, $b$, and $c$ will be selected at random from a distribution unknown to either player. The players know only that the numbers will be non-negative. Player $P_{1}$ will be given a choice of two options, after they make their selection the values of $a$, $b$, and $c$ will be revealed, and $P_1$ and $P_2$ will score points depending on the values of $a$, $b$, and $c$ as described below. ($P_2$ makes no choices.) Player $P_{1}$'s two options are: Option 1: Score points equal to $a+b$. Option 2: Score points equal to the maximum value of $a$, $b$, or $c$. Note: Neither player knows the values of $a$, $b$, or $c$ at the time this choice is made. Whichever option $P_{1}$ selects, $P_{2}$ will score the points of the other unselected option. For example, if: $P_1$ selects Option 2 $a$, $b$, and $c$ turn out to be $1$, $17$, and $\pi$ respectively Then: $P_1$ scores $17$ points (e.g. the maximum of $1$, $17$, and $\pi$) $P_2$ scores $18$ points (e.g. $a+b = 1+17 = 18$) The player who scores the most points wins the game. (Ties are also possible.) The Scenario Let's assume: The game will be played some number $N$ times, with the unknown distribution from which $a$, $b$, and $c$ are selected remaining fixed over these $N$ games. $P_1$ must select the same choice of Option 1 or 2 in each of the $N$ games. (e.g. they make only one choice at the beginning of Option 1 or 2, which is then applied in every game.) We tabulate both: The number of times each player wins The cumulative points scored by each player over the $N$ games The Question Does there exist: A distribution of numbers from which $a$, $b$, and $c$ are selected A choice by $P_1$, and Sufficiently large $N$ Such that both: $P_1$ is expected to win at least as many games as $P_2$, and $P_1$ is also expected to score no more points than $P_2$ ? (Thanks to Marcus M for answering this with a clear example!) Does the answer change if all values must be positive, as opposed to non-zero? My sense is that there is no such distribution possible when $a$, $b$, and $c$ are positive - but I'm not sure how to go about proving that ? It's fairly easy to construct distributions such that Option 1 or Option 2 both lead to $P_1$ expecting to win more games and scoring more points , for example: If $a$, $b$, and $c$ are always some permutation of 0, 0, and 1 then as $N$ approaches infinity: Option 2 ties 2 games out of 3 and wins 1 game out of 3 Option 2 scores 1 point per game whereas Option 1 expects to score $2/3$ points per game If $a$, $b$, and $c$ are selected over a uniform continuous distribution then as $N$ approaches infinity: Option 1 expects to win 5 games out of 6, and score $4/3$rds as many points as Option 2. However I'm interested if it's possible to have distribution where there is a split outcome of winning more while also scoring less overall. Thanks for reading!","The Game Two players $P_{1}$ and $P_{2}$ will play the following game: Three non-negative numbers $a$, $b$, and $c$ will be selected at random from a distribution unknown to either player. The players know only that the numbers will be non-negative. Player $P_{1}$ will be given a choice of two options, after they make their selection the values of $a$, $b$, and $c$ will be revealed, and $P_1$ and $P_2$ will score points depending on the values of $a$, $b$, and $c$ as described below. ($P_2$ makes no choices.) Player $P_{1}$'s two options are: Option 1: Score points equal to $a+b$. Option 2: Score points equal to the maximum value of $a$, $b$, or $c$. Note: Neither player knows the values of $a$, $b$, or $c$ at the time this choice is made. Whichever option $P_{1}$ selects, $P_{2}$ will score the points of the other unselected option. For example, if: $P_1$ selects Option 2 $a$, $b$, and $c$ turn out to be $1$, $17$, and $\pi$ respectively Then: $P_1$ scores $17$ points (e.g. the maximum of $1$, $17$, and $\pi$) $P_2$ scores $18$ points (e.g. $a+b = 1+17 = 18$) The player who scores the most points wins the game. (Ties are also possible.) The Scenario Let's assume: The game will be played some number $N$ times, with the unknown distribution from which $a$, $b$, and $c$ are selected remaining fixed over these $N$ games. $P_1$ must select the same choice of Option 1 or 2 in each of the $N$ games. (e.g. they make only one choice at the beginning of Option 1 or 2, which is then applied in every game.) We tabulate both: The number of times each player wins The cumulative points scored by each player over the $N$ games The Question Does there exist: A distribution of numbers from which $a$, $b$, and $c$ are selected A choice by $P_1$, and Sufficiently large $N$ Such that both: $P_1$ is expected to win at least as many games as $P_2$, and $P_1$ is also expected to score no more points than $P_2$ ? (Thanks to Marcus M for answering this with a clear example!) Does the answer change if all values must be positive, as opposed to non-zero? My sense is that there is no such distribution possible when $a$, $b$, and $c$ are positive - but I'm not sure how to go about proving that ? It's fairly easy to construct distributions such that Option 1 or Option 2 both lead to $P_1$ expecting to win more games and scoring more points , for example: If $a$, $b$, and $c$ are always some permutation of 0, 0, and 1 then as $N$ approaches infinity: Option 2 ties 2 games out of 3 and wins 1 game out of 3 Option 2 scores 1 point per game whereas Option 1 expects to score $2/3$ points per game If $a$, $b$, and $c$ are selected over a uniform continuous distribution then as $N$ approaches infinity: Option 1 expects to win 5 games out of 6, and score $4/3$rds as many points as Option 2. However I'm interested if it's possible to have distribution where there is a split outcome of winning more while also scoring less overall. Thanks for reading!",,"['probability', 'statistics', 'game-theory']"
97,What is the appropriate statistical test to see if a quantity has been distributed differently into discrete bins?,What is the appropriate statistical test to see if a quantity has been distributed differently into discrete bins?,,"Say I have $10^6$ balls, $3$ bins $A,B,C$, and $2$ machines $X$ and $Y$ that distribute the balls into the bins according to an internal set of rules (i.e. a probability distribution). If I run both machines multiple times and get the following averages-- $X$: $80$% of balls into bin $A$, $12$% into $B$, $8$% into $C$; $Y$: $82$% into $A$, $12$% into $B$, $10$% into $C$-- My intuition says that $X$ and $Y$ follow the same probability distribution. However, if I get-- $X$: same as above; $Y$: $30$% into $A$, $30$% into $B$, $40$% into $C$-- the probability distribution is likely to be different. How do I verify this statistically? A student's t-test between $X$ and $Y$ for individual bins seems too simplistic and doesn't account for the fact that $A$, $B$, and $C$ are not independent, but I can't dig up anything else from my very limited stats background. Also, would the test be the same if instead of discrete balls I had a continuous quantity that could be partitioned into the bins in arbitrary fractions?","Say I have $10^6$ balls, $3$ bins $A,B,C$, and $2$ machines $X$ and $Y$ that distribute the balls into the bins according to an internal set of rules (i.e. a probability distribution). If I run both machines multiple times and get the following averages-- $X$: $80$% of balls into bin $A$, $12$% into $B$, $8$% into $C$; $Y$: $82$% into $A$, $12$% into $B$, $10$% into $C$-- My intuition says that $X$ and $Y$ follow the same probability distribution. However, if I get-- $X$: same as above; $Y$: $30$% into $A$, $30$% into $B$, $40$% into $C$-- the probability distribution is likely to be different. How do I verify this statistically? A student's t-test between $X$ and $Y$ for individual bins seems too simplistic and doesn't account for the fact that $A$, $B$, and $C$ are not independent, but I can't dig up anything else from my very limited stats background. Also, would the test be the same if instead of discrete balls I had a continuous quantity that could be partitioned into the bins in arbitrary fractions?",,"['probability', 'statistics', 'probability-distributions', 'statistical-inference']"
98,Why not use always a binomial exact test to compare two proportions instead of chi square?,Why not use always a binomial exact test to compare two proportions instead of chi square?,,"I am trying to figure out what test I should use in the following scenario: I know that there is a lot of room for improvement in a specific area at work - being extremely critical, let's say that sampling $52$ observations, $31$ could be improved. After instituting an improvement / QA program for six months, let me assume that out of a sample of $55$ cases, there are only $11$ with residual flaws. The two samples are independent. Although the numbers are exaggerated, I still want to see if the two proportions are statistically different, and I think I have a couple of options: I can run an exact binomial test to calculate the probability that the new proportion of flawed observations, $11/55$, would occur if the actual underlying probability remained $31/52$. Alternatively, I can run a chi-square test. The chi-square is an approximation, and what I have read is that it is to be applied when the total number of observations is too high. This is clearly not the case in the example; however, playing with the numbers in R, I couldn't see any delay or problems with the results even after using numbers $> 10,000$. And there was no indication of any normal approximation being used. So, if this is all true, why shouldn't we always opt for an exact binomial test, rather than a chi square? The code in R would be: binom.test(c(11, 55 - 11), p = 31/52, alternative =""less"") versus: prop.test(c(31, 11), c(52, 55), correct = FALSE, alternative = 'greater') Thank you.","I am trying to figure out what test I should use in the following scenario: I know that there is a lot of room for improvement in a specific area at work - being extremely critical, let's say that sampling $52$ observations, $31$ could be improved. After instituting an improvement / QA program for six months, let me assume that out of a sample of $55$ cases, there are only $11$ with residual flaws. The two samples are independent. Although the numbers are exaggerated, I still want to see if the two proportions are statistically different, and I think I have a couple of options: I can run an exact binomial test to calculate the probability that the new proportion of flawed observations, $11/55$, would occur if the actual underlying probability remained $31/52$. Alternatively, I can run a chi-square test. The chi-square is an approximation, and what I have read is that it is to be applied when the total number of observations is too high. This is clearly not the case in the example; however, playing with the numbers in R, I couldn't see any delay or problems with the results even after using numbers $> 10,000$. And there was no indication of any normal approximation being used. So, if this is all true, why shouldn't we always opt for an exact binomial test, rather than a chi square? The code in R would be: binom.test(c(11, 55 - 11), p = 31/52, alternative =""less"") versus: prop.test(c(31, 11), c(52, 55), correct = FALSE, alternative = 'greater') Thank you.",,"['statistics', 'statistical-inference']"
99,ML estimation for Weibull,ML estimation for Weibull,,"What are the maximum likelihood estimators of $\eta$ and $\beta$ ( $\eta>0$ and $\beta>0$ ) for an i.i.d. sample of size $n$ from the following density: $f(x_i)=\frac{\beta x_i^{\beta-1} }{\eta ^ {\beta} } \cdot \exp\left(-(x_i/{\eta})^{\beta}\right)$ ? Ps. According to Forbes et al 2011, p.196 , they are the solution to the following equation system, but I don't manage to get the same result... $$\eta=\left[\frac{\sum_{i=1}^n{x_i^{\beta}}}{n}\right]^{1/\beta}, \beta=\frac{n}{\frac{1}{\eta}\sum_{i=1}^{n}{x_i^{\beta} \cdot \log(x_i)}-\sum_{i=1}^{n}{\log(x_i)}}.$$ Is there an error in the book, or am I making a mistake?","What are the maximum likelihood estimators of and ( and ) for an i.i.d. sample of size from the following density: ? Ps. According to Forbes et al 2011, p.196 , they are the solution to the following equation system, but I don't manage to get the same result... Is there an error in the book, or am I making a mistake?","\eta \beta \eta>0 \beta>0 n f(x_i)=\frac{\beta x_i^{\beta-1} }{\eta ^ {\beta} } \cdot \exp\left(-(x_i/{\eta})^{\beta}\right) \eta=\left[\frac{\sum_{i=1}^n{x_i^{\beta}}}{n}\right]^{1/\beta}, \beta=\frac{n}{\frac{1}{\eta}\sum_{i=1}^{n}{x_i^{\beta} \cdot \log(x_i)}-\sum_{i=1}^{n}{\log(x_i)}}.","['statistics', 'probability-distributions', 'maximum-likelihood', 'parameter-estimation']"
