,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Is $1$ raised to any complex power equal to $1$?,Is  raised to any complex power equal to ?,1 1,"I just saw a solution that says it is since,  for any complex number $z$ $$1^z = e^{z\log1} = e^{z(0)} = 1$$ However, isn't this only true for the principle branch of $1^z$, since by definiton, (letting capital L denote the princple value of log $$\log1 = \operatorname{Log}1 +  i2\pi k$$ for any $k \in \mathbb{Z}$?","I just saw a solution that says it is since,  for any complex number $z$ $$1^z = e^{z\log1} = e^{z(0)} = 1$$ However, isn't this only true for the principle branch of $1^z$, since by definiton, (letting capital L denote the princple value of log $$\log1 = \operatorname{Log}1 +  i2\pi k$$ for any $k \in \mathbb{Z}$?",,"['complex-analysis', 'complex-numbers']"
1,Normal Families,Normal Families,,Suppose $\mathcal{F}$ is a famliy of analytic functions of the unit disc.   Suppose also that $( Re(f(z)) )^2 \ne ( Im(f(z)) ) $for all $|z|<1$ and all $f \in \mathcal{F}$. It follows from the Fundamental Normality test that $\mathcal{F}$ is a normal family. Is there a for elementary way of showing $\mathcal{F}$ is a normal family without invoking the Fundamental Normality Test?,Suppose $\mathcal{F}$ is a famliy of analytic functions of the unit disc.   Suppose also that $( Re(f(z)) )^2 \ne ( Im(f(z)) ) $for all $|z|<1$ and all $f \in \mathcal{F}$. It follows from the Fundamental Normality test that $\mathcal{F}$ is a normal family. Is there a for elementary way of showing $\mathcal{F}$ is a normal family without invoking the Fundamental Normality Test?,,['complex-analysis']
2,Is a rational function which maps all circles/lines to circles/lines a Möbius transformation?,Is a rational function which maps all circles/lines to circles/lines a Möbius transformation?,,"It is well-known that Möbius transformations map circles and lines to circles and lines. (Here and in the following, “line” means a line in the extended complex plane $\hat{\Bbb C}$ , including the point at infinity.) My question is if that property characterizes Möbius transformations, i.e. if the following converse statement is true: Let $f$ be a rational function which maps circles and lines to circles and lines. Then $f$ is a Möbius transformation. Just to be clear: The property is that if $C$ is a circle or a line then $f(C)$ is also a circle or a line. If we consider $f$ as a mapping of the Riemann sphere onto itself then it means that circles on the sphere are mapped to circles. Context In a now deleted question the following was asked: Suppose $f$ is a continuous function on the extended complex plane which is analytic except possibly at one point and maps lines and circles to lines and circles. Does it follow that $f$ is necessarily a Möbius transformation? It is not difficult to see that under those conditions, $f$ has a removable singularity at the possible exception point, so that it is analytic in all of the extended complex plane, and therefore a rational function. That leads to the above question. This is posted as a self-answered question because I figured out a solution which seems not to be posted before. Of course other answers are most welcome. A previous related questions is Is a function that maps circles to circles necessarily a Möbius transformation? where the following examples are given: a finite Blaschke product maps the unit circle onto itself. The functions $z \mapsto z^p$ map all lines through the origin to lines, and all circles with center at the origin to circles. That are not counterexamples to the above conjecture because not all circles and lines are mapped to circles and lines.","It is well-known that Möbius transformations map circles and lines to circles and lines. (Here and in the following, “line” means a line in the extended complex plane , including the point at infinity.) My question is if that property characterizes Möbius transformations, i.e. if the following converse statement is true: Let be a rational function which maps circles and lines to circles and lines. Then is a Möbius transformation. Just to be clear: The property is that if is a circle or a line then is also a circle or a line. If we consider as a mapping of the Riemann sphere onto itself then it means that circles on the sphere are mapped to circles. Context In a now deleted question the following was asked: Suppose is a continuous function on the extended complex plane which is analytic except possibly at one point and maps lines and circles to lines and circles. Does it follow that is necessarily a Möbius transformation? It is not difficult to see that under those conditions, has a removable singularity at the possible exception point, so that it is analytic in all of the extended complex plane, and therefore a rational function. That leads to the above question. This is posted as a self-answered question because I figured out a solution which seems not to be posted before. Of course other answers are most welcome. A previous related questions is Is a function that maps circles to circles necessarily a Möbius transformation? where the following examples are given: a finite Blaschke product maps the unit circle onto itself. The functions map all lines through the origin to lines, and all circles with center at the origin to circles. That are not counterexamples to the above conjecture because not all circles and lines are mapped to circles and lines.",\hat{\Bbb C} f f C f(C) f f f f z \mapsto z^p,"['complex-analysis', 'mobius-transformation']"
3,complex polynomial has zeroes only in the upper half plane,complex polynomial has zeroes only in the upper half plane,,"Let $f(z)=z^{n}+a_{1}z^{n-1}+...+a_{n}$ be a polynomial with complex coefficients and suppose it has $n$ zeros in the upper half plane, that is $\operatorname{Im} z>0$, and let $\alpha_ {k}$ be the real part of $a_{k}$. Show that $\alpha(x)=x^{n}+\alpha_{1}x^{n-1}+...+\alpha_{n}$ has $n$ real distinct roots.","Let $f(z)=z^{n}+a_{1}z^{n-1}+...+a_{n}$ be a polynomial with complex coefficients and suppose it has $n$ zeros in the upper half plane, that is $\operatorname{Im} z>0$, and let $\alpha_ {k}$ be the real part of $a_{k}$. Show that $\alpha(x)=x^{n}+\alpha_{1}x^{n-1}+...+\alpha_{n}$ has $n$ real distinct roots.",,"['complex-analysis', 'polynomials']"
4,How does the metric on the Poincaré half plane model work?,How does the metric on the Poincaré half plane model work?,,"Let $\mathbb{H} = \{ z = x+iy \in \mathbb{C} | \Im(z)=y>0\}$ be the upper half plane. I often see that $\mathbb{H}$ is endowed with a metric which is written as $$ ds^2 = \frac{dx^2+dy^2}{y^2}. $$ I do not understand what $s, d(\cdot)$ mean and how one can measure the distance of the points on $\mathbb{H}$ with that formula. And why do we have to take squares? It seems like there is some background to that which I do not have. And I also do not know where to start. Could someone please explain me what all these things mean? Thank you!","Let $\mathbb{H} = \{ z = x+iy \in \mathbb{C} | \Im(z)=y>0\}$ be the upper half plane. I often see that $\mathbb{H}$ is endowed with a metric which is written as $$ ds^2 = \frac{dx^2+dy^2}{y^2}. $$ I do not understand what $s, d(\cdot)$ mean and how one can measure the distance of the points on $\mathbb{H}$ with that formula. And why do we have to take squares? It seems like there is some background to that which I do not have. And I also do not know where to start. Could someone please explain me what all these things mean? Thank you!",,"['complex-analysis', 'geometry', 'metric-spaces', 'hyperbolic-geometry']"
5,"if $|az^2+bz+c|\le 1$, find the maximum of $|a|+|b|$","if , find the maximum of",|az^2+bz+c|\le 1 |a|+|b|,"Let $a,b,c$ be complex numbers, and $f(z)=az^2+bz+c$, such that if the complex number $|z|\le 1$, then we have $|f(z)|\le 1$. Find the maximum of $|a|+|b|$. if we $a,b,c$ be real and $z$ be real, I can find the maximum is $2$,because $f(z)=2z^2-1$ such  it. and $$a=\dfrac{1}{2}[f(1)+f(-1)]-f(0),b=\dfrac{1}{2}[f(1)-f(-1)]$$ so $$|a|+|b|=\dfrac{1}{2}|f(1)+f(-1)-2f(0)|+\dfrac{1}{2}|f(1)-f(-1)|\le 2$$But for complex, maybe this answer is also $2?$,I'm not sure.","Let $a,b,c$ be complex numbers, and $f(z)=az^2+bz+c$, such that if the complex number $|z|\le 1$, then we have $|f(z)|\le 1$. Find the maximum of $|a|+|b|$. if we $a,b,c$ be real and $z$ be real, I can find the maximum is $2$,because $f(z)=2z^2-1$ such  it. and $$a=\dfrac{1}{2}[f(1)+f(-1)]-f(0),b=\dfrac{1}{2}[f(1)-f(-1)]$$ so $$|a|+|b|=\dfrac{1}{2}|f(1)+f(-1)-2f(0)|+\dfrac{1}{2}|f(1)-f(-1)|\le 2$$But for complex, maybe this answer is also $2?$,I'm not sure.",,"['complex-analysis', 'inequality', 'contest-math']"
6,Entire function doesn't cut real axis.,Entire function doesn't cut real axis.,,"Let be $ f : \mathbb{C} \rightarrow \mathbb{C} $ a entire function. If it verifies that $ f(\mathbb{C}) \cap \mathbb{R} = \emptyset $ then we cand deduce that $ f $ is constant* (see below to proof), but my question is, the same statement is true if $ f( \mathbb{C} ) \cap [0, \infty) = \emptyset $? And generally, if $ f(\mathbb{C}) \cap [a,b] = \emptyset $ then $ f $ must be constant? I have test some entire functions for the case $ [0, \infty) $ like $ \sin(z) $ and $ \cos(z) $ but I haven't found a conterexpample. I haven't found any similar way to proced like in the case $ f(\mathbb{C}) \cap \mathbb{R} $. *Proof: From $ f( \mathbb{C}) \cap \mathbb{R} = \emptyset $ we deduce that $ \Im(f(z)) > 0 \ \forall z \in \mathbb{C} \ $ or $ \ \Im(f(z)) < 0 \ \forall z \in \mathbb{C} $, because $ f $ is continuous and then $ f( \mathbb{C} ) $ must be a connected subset of $ \mathbb{C} $. Now we consider the compositions $ e^{if} = e^{-v + iu} $ and $ e^{-if} = e^{v - iu} $ where $ f = u + iv $. This functions must be also entire, and we have $$ | e^{if} |= |e^{-v + iu}| = e^{-v} \ \ \mbox{ and } \ \ | e^{-if} |= |e^{v - iu}| = e^{v} $$ So, if $ v(z) = \Im(f(z)) > 0 \ \forall z \in \mathbb{C} $, the first equality gives that $ |e^{if(z)}| \leq 1 $. In the same way, if $ v(z) = \Im(f(z)) < 0 $, the second equality gives that $ |e^{-if(z)}| \leq 1 $. As $ e^{if} $ and $ e^{-if} $ are entire bounded functions, they must be constant. So we deduce $ f $ is a constant function.","Let be $ f : \mathbb{C} \rightarrow \mathbb{C} $ a entire function. If it verifies that $ f(\mathbb{C}) \cap \mathbb{R} = \emptyset $ then we cand deduce that $ f $ is constant* (see below to proof), but my question is, the same statement is true if $ f( \mathbb{C} ) \cap [0, \infty) = \emptyset $? And generally, if $ f(\mathbb{C}) \cap [a,b] = \emptyset $ then $ f $ must be constant? I have test some entire functions for the case $ [0, \infty) $ like $ \sin(z) $ and $ \cos(z) $ but I haven't found a conterexpample. I haven't found any similar way to proced like in the case $ f(\mathbb{C}) \cap \mathbb{R} $. *Proof: From $ f( \mathbb{C}) \cap \mathbb{R} = \emptyset $ we deduce that $ \Im(f(z)) > 0 \ \forall z \in \mathbb{C} \ $ or $ \ \Im(f(z)) < 0 \ \forall z \in \mathbb{C} $, because $ f $ is continuous and then $ f( \mathbb{C} ) $ must be a connected subset of $ \mathbb{C} $. Now we consider the compositions $ e^{if} = e^{-v + iu} $ and $ e^{-if} = e^{v - iu} $ where $ f = u + iv $. This functions must be also entire, and we have $$ | e^{if} |= |e^{-v + iu}| = e^{-v} \ \ \mbox{ and } \ \ | e^{-if} |= |e^{v - iu}| = e^{v} $$ So, if $ v(z) = \Im(f(z)) > 0 \ \forall z \in \mathbb{C} $, the first equality gives that $ |e^{if(z)}| \leq 1 $. In the same way, if $ v(z) = \Im(f(z)) < 0 $, the second equality gives that $ |e^{-if(z)}| \leq 1 $. As $ e^{if} $ and $ e^{-if} $ are entire bounded functions, they must be constant. So we deduce $ f $ is a constant function.",,"['complex-analysis', 'entire-functions']"
7,Analytic Functions - why 2 dimensions?,Analytic Functions - why 2 dimensions?,,"Having just learned the definition of analytic functions, I found it surprising and somewhat counterintuitive that the set of functions over the complex plane whose real and imaginary parts each satisfy Laplace's Equation $\nabla^{2} = 0$ should have such incredible significance, since this is basically a set of two harmonic functions over $\mathbb{R}$.  Does this extend to higher dimensions of hypercomplex numbers such as quaternions? More formally, is there some generalization of the space of analytic functions to higher dimensions $ 2^n | n \in \mathbb{N}, n > 1$ where each component function individually satisfies Laplace's Equation? Do these functional spaces yield similar properties to that enumerated in the field of complex analysis, or are there any salient differences?","Having just learned the definition of analytic functions, I found it surprising and somewhat counterintuitive that the set of functions over the complex plane whose real and imaginary parts each satisfy Laplace's Equation $\nabla^{2} = 0$ should have such incredible significance, since this is basically a set of two harmonic functions over $\mathbb{R}$.  Does this extend to higher dimensions of hypercomplex numbers such as quaternions? More formally, is there some generalization of the space of analytic functions to higher dimensions $ 2^n | n \in \mathbb{N}, n > 1$ where each component function individually satisfies Laplace's Equation? Do these functional spaces yield similar properties to that enumerated in the field of complex analysis, or are there any salient differences?",,"['complex-analysis', 'harmonic-functions', 'quaternions']"
8,Motivation for Mobius Transformation,Motivation for Mobius Transformation,,"Let $S$ denote the Riemann Sphere. Recall that a Mobius transformation is a function $f:S \to S$ defines as $z \to \frac {az+b}{cz+d}$ where $a,b,c,d \in \mathbb C$ with $ad-bc=1$. What is the motivation to study Mobius Transformation? Why should one look at the map defined in the above way?","Let $S$ denote the Riemann Sphere. Recall that a Mobius transformation is a function $f:S \to S$ defines as $z \to \frac {az+b}{cz+d}$ where $a,b,c,d \in \mathbb C$ with $ad-bc=1$. What is the motivation to study Mobius Transformation? Why should one look at the map defined in the above way?",,"['complex-analysis', 'riemann-surfaces', 'mobius-transformation']"
9,Q: Find all functions that are analytic and satisfy $(\operatorname{Re}(f(z)))^2 = \operatorname{Im}(f(z))$,Q: Find all functions that are analytic and satisfy,(\operatorname{Re}(f(z)))^2 = \operatorname{Im}(f(z)),"I've been trying to find all functions $f(z):\Bbb{C}\longrightarrow\Bbb{C}$ that are analytic and satisfy $$(\operatorname{Re}(f(z)))^2 = \operatorname{Im}(f(z))$$ After plugging in $f(z)=x+iy$, I got $f(z)=x+ix^2$. These kind of functions never satisfy Cauchy-Riemann equations, since $\mathcal u_x=1 \neq 0=v_y$. Does it follow from this argumentation that no such analytic $f(z)$ exists?","I've been trying to find all functions $f(z):\Bbb{C}\longrightarrow\Bbb{C}$ that are analytic and satisfy $$(\operatorname{Re}(f(z)))^2 = \operatorname{Im}(f(z))$$ After plugging in $f(z)=x+iy$, I got $f(z)=x+ix^2$. These kind of functions never satisfy Cauchy-Riemann equations, since $\mathcal u_x=1 \neq 0=v_y$. Does it follow from this argumentation that no such analytic $f(z)$ exists?",,['complex-analysis']
10,Is this a Morera´s Theorem Application?,Is this a Morera´s Theorem Application?,,"Let $G \subset \mathbb C$ be a domain and $f: G \to \mathbb C$ a continuous function such that for any closed and rectifiable path $\gamma \subset G$,  $$ \left| \oint_\gamma f(z)dz \right|\leq \left( L(\gamma)\right)^3. $$ Where $L(\gamma)$ denote the arc length of the path $\gamma$, that is $L(\gamma)=\int_\gamma |dz|$. Prove that $f$ is holomorphic in $G$. My Ideas: This looks like a good candidate to use the powerful result of Morera´s Theorem, which tells us that is enough to prove that $\oint_\gamma f(z)dz$ vanishes for any closed path $\gamma \subset G$. However I don't seem to put together a good argument and I am starting to believe this may be prove in another way. Why 3? Why use the $3$ in ""$\leq \left( L(\gamma)\right)^3$""? I guess I would know that if I could prove it but do the assertion still holds if we replace $3$ by $2$, $5$, $8$ or any other whole number? Any help on how proving this or hints will be very appreciated.","Let $G \subset \mathbb C$ be a domain and $f: G \to \mathbb C$ a continuous function such that for any closed and rectifiable path $\gamma \subset G$,  $$ \left| \oint_\gamma f(z)dz \right|\leq \left( L(\gamma)\right)^3. $$ Where $L(\gamma)$ denote the arc length of the path $\gamma$, that is $L(\gamma)=\int_\gamma |dz|$. Prove that $f$ is holomorphic in $G$. My Ideas: This looks like a good candidate to use the powerful result of Morera´s Theorem, which tells us that is enough to prove that $\oint_\gamma f(z)dz$ vanishes for any closed path $\gamma \subset G$. However I don't seem to put together a good argument and I am starting to believe this may be prove in another way. Why 3? Why use the $3$ in ""$\leq \left( L(\gamma)\right)^3$""? I guess I would know that if I could prove it but do the assertion still holds if we replace $3$ by $2$, $5$, $8$ or any other whole number? Any help on how proving this or hints will be very appreciated.",,"['complex-analysis', 'contour-integration', 'analyticity']"
11,Why all composite numbers have this property?,Why all composite numbers have this property?,,"Define $f(n)=\sum\limits_{A \in S} f_{1}(n,A),\ n>2,\ n \in  \mathbb{Z}$, where $S$ is the power set of $\{\frac{1}{2},\cdots ,\frac{1}{n-1}\}$. Define $\ f_1(n,\varnothing)=1,\ f_{1}(n,A)=(-1)^{\#A-2n\Sigma(A)}$, where $\#A$ is the size of the set $A$ and $\Sigma(A)$ is the sum of the elements of A. Let's take $n = 5$, for example: $$ \begin{align*}  S = \{\\ & \varnothing,\\ &  \{\frac{1}{2}\},\  \{\frac{1}{3}\},\  \{\frac{1}{4}\},\\  &  \{\frac{1}{2},\frac{1}{3}\},\   \{\frac{1}{2},\frac{1}{4}\},\  \{\frac{1}{3},\frac{1}{4}\},\\ &  \{\frac{1}{2},\frac{1}{3},\frac{1}{4}\}\\ \} \end{align*} $$ $f(5)=1+(-1)^{1-2 \cdot 5 \cdot (\frac{1}{2})}+ \cdots +(-1)^{2-2 \cdot 5 \cdot (\frac{1}{2}+\frac{1}{3})} + \cdots + (-1)^{3-2 \cdot 5 \cdot (\frac{1}{2}+\frac{1}{3}+\frac{1}{4})}=4.7320508075688767+1.2679491924311326i$ My question is: Why for every composite number $n$ is the real part of $f(n)$ approximately $0$, while prime numbers do not have this property?  Examples: $$ \begin{align*}  f(4) & = 1.887379141862766e-15-1.1102230246251565e-15i\\ f(22) & = -8.325340417059124e-12-7.568612403474617e-1i \end{align*} $$ Source: http://mymathforum.com/number-theory/43341-prime-prime.html P.S. Python code for $f(n),f_{1}(n,A)$: import itertools  def f_1(n,A):     return (-1) ** (len(A) - 2 * n * (sum(A))) def f(n):     l = [itertools.combinations([1/x for x in range(2,n)], x) for x in range(1,n-1)]     return round(sum([f_1(n,y) for x in l for y in x]).real) + 1  print(f(4))  # Output: 0","Define $f(n)=\sum\limits_{A \in S} f_{1}(n,A),\ n>2,\ n \in  \mathbb{Z}$, where $S$ is the power set of $\{\frac{1}{2},\cdots ,\frac{1}{n-1}\}$. Define $\ f_1(n,\varnothing)=1,\ f_{1}(n,A)=(-1)^{\#A-2n\Sigma(A)}$, where $\#A$ is the size of the set $A$ and $\Sigma(A)$ is the sum of the elements of A. Let's take $n = 5$, for example: $$ \begin{align*}  S = \{\\ & \varnothing,\\ &  \{\frac{1}{2}\},\  \{\frac{1}{3}\},\  \{\frac{1}{4}\},\\  &  \{\frac{1}{2},\frac{1}{3}\},\   \{\frac{1}{2},\frac{1}{4}\},\  \{\frac{1}{3},\frac{1}{4}\},\\ &  \{\frac{1}{2},\frac{1}{3},\frac{1}{4}\}\\ \} \end{align*} $$ $f(5)=1+(-1)^{1-2 \cdot 5 \cdot (\frac{1}{2})}+ \cdots +(-1)^{2-2 \cdot 5 \cdot (\frac{1}{2}+\frac{1}{3})} + \cdots + (-1)^{3-2 \cdot 5 \cdot (\frac{1}{2}+\frac{1}{3}+\frac{1}{4})}=4.7320508075688767+1.2679491924311326i$ My question is: Why for every composite number $n$ is the real part of $f(n)$ approximately $0$, while prime numbers do not have this property?  Examples: $$ \begin{align*}  f(4) & = 1.887379141862766e-15-1.1102230246251565e-15i\\ f(22) & = -8.325340417059124e-12-7.568612403474617e-1i \end{align*} $$ Source: http://mymathforum.com/number-theory/43341-prime-prime.html P.S. Python code for $f(n),f_{1}(n,A)$: import itertools  def f_1(n,A):     return (-1) ** (len(A) - 2 * n * (sum(A))) def f(n):     l = [itertools.combinations([1/x for x in range(2,n)], x) for x in range(1,n-1)]     return round(sum([f_1(n,y) for x in l for y in x]).real) + 1  print(f(4))  # Output: 0",,"['complex-analysis', 'number-theory', 'elementary-number-theory', 'complex-numbers', 'prime-numbers']"
12,How to find a conformal mapping of the first quadrant.,How to find a conformal mapping of the first quadrant.,,"Find a conformal mapping of the first quadrant onto the unit disc mapping the points $1+i$ and $0$ onto the points $0$ and $i$ respectively. I think that i need to use ""the change of variables $w=z^k$"" but how? And why do we apply this? Please can someone explain thisstep by step?  Thanks alot:)","Find a conformal mapping of the first quadrant onto the unit disc mapping the points $1+i$ and $0$ onto the points $0$ and $i$ respectively. I think that i need to use ""the change of variables $w=z^k$"" but how? And why do we apply this? Please can someone explain thisstep by step?  Thanks alot:)",,"['complex-analysis', 'analysis', 'self-learning', 'conformal-geometry']"
13,Characterization of Harmonic Functions on the Punctured Disk,Characterization of Harmonic Functions on the Punctured Disk,,"The following is an old qual problem I came across. If $h$ is harmonic on $D-\{0\}$, where $D$ is the unit disk, show that $h(z) = \Re(f(z)) + c \log|z|$ for where $f$ is analytic on $D- \{0\}$. This is obvious (with $c=0$) if $h$ extends to a harmonic function on $D$ but I don't how to treat the case where $h$ is not extendable.","The following is an old qual problem I came across. If $h$ is harmonic on $D-\{0\}$, where $D$ is the unit disk, show that $h(z) = \Re(f(z)) + c \log|z|$ for where $f$ is analytic on $D- \{0\}$. This is obvious (with $c=0$) if $h$ extends to a harmonic function on $D$ but I don't how to treat the case where $h$ is not extendable.",,['complex-analysis']
14,A result similar to Schwarz lemma,A result similar to Schwarz lemma,,"Suppose $f$ is a holomorphic map on the unit disc. Let $d$ be the diameter of the image of $f$ . If $ 2|f'(0)|=d $ , please show that $f$ is a linear function. I think maybe I can prove it by using Schwarz lemma, but I failed.","Suppose is a holomorphic map on the unit disc. Let be the diameter of the image of . If , please show that is a linear function. I think maybe I can prove it by using Schwarz lemma, but I failed.",f d f  2|f'(0)|=d  f,['complex-analysis']
15,Using the Residue Theorem for a contour integral along the Riemann sphere,Using the Residue Theorem for a contour integral along the Riemann sphere,,"Given the integral $\int_{-\infty}^{\infty}\frac{x}{x^2+1}dx,$ we can clearly see this is the integral of an odd function with limits which are symmetric about the origin, and thus its integral is zero. However, if I treat this as a curve along the real axis on the Riemann sphere (since the function is zero at infinity), then I can consider the interior of the curve to be the upper-half of the complex plane where it has a single singularity of order $1$ at $i$.  Thus, applying the residue theorem, I obtain: $$\int_{-\infty}^{\infty}\frac{x}{x^2+1}dx = 2\pi i\lim_{x\rightarrow i}(x-i)\frac{x}{(x-i)(x+i)} = 2\pi i\frac{i}{2i} = \pi i\neq 0.$$ Clearly I'm doing something wrong, can someone explain to me my misconception(s)? Thanks","Given the integral $\int_{-\infty}^{\infty}\frac{x}{x^2+1}dx,$ we can clearly see this is the integral of an odd function with limits which are symmetric about the origin, and thus its integral is zero. However, if I treat this as a curve along the real axis on the Riemann sphere (since the function is zero at infinity), then I can consider the interior of the curve to be the upper-half of the complex plane where it has a single singularity of order $1$ at $i$.  Thus, applying the residue theorem, I obtain: $$\int_{-\infty}^{\infty}\frac{x}{x^2+1}dx = 2\pi i\lim_{x\rightarrow i}(x-i)\frac{x}{(x-i)(x+i)} = 2\pi i\frac{i}{2i} = \pi i\neq 0.$$ Clearly I'm doing something wrong, can someone explain to me my misconception(s)? Thanks",,"['complex-analysis', 'residue-calculus']"
16,finding $\int_0^\infty \dfrac{dx}{1+x^4}$ through complex analysis,finding  through complex analysis,\int_0^\infty \dfrac{dx}{1+x^4},I am trying to find $\int_0^\infty \dfrac{dx}{1+x^4}$ by setting it equal to $\dfrac{1}{2}\oint_C \dfrac{dz}{1+z^4}$ and solving that. By a computer program I've calculated it to be $\approx 1.11072$; I am not getting that answer though. I factor it into $\dfrac{1}{2}\oint_C \dfrac{dz}{(z-1)(z+1)(z^2 + 1)}$; there is a simple pole at $z = 1$ and a 4th order pole at $z = i$; I find the residue at 1 to be $\dfrac{1}{4}$ and at $i$ to be $\dfrac{-1}{4}$; the second pole is found by L'Hopital's rule. Could someone tell me what I'm missing? Thanks,I am trying to find $\int_0^\infty \dfrac{dx}{1+x^4}$ by setting it equal to $\dfrac{1}{2}\oint_C \dfrac{dz}{1+z^4}$ and solving that. By a computer program I've calculated it to be $\approx 1.11072$; I am not getting that answer though. I factor it into $\dfrac{1}{2}\oint_C \dfrac{dz}{(z-1)(z+1)(z^2 + 1)}$; there is a simple pole at $z = 1$ and a 4th order pole at $z = i$; I find the residue at 1 to be $\dfrac{1}{4}$ and at $i$ to be $\dfrac{-1}{4}$; the second pole is found by L'Hopital's rule. Could someone tell me what I'm missing? Thanks,,"['complex-analysis', 'residue-calculus', 'complex-integration']"
17,Proving an Entire Function is a Polynomial,Proving an Entire Function is a Polynomial,,"I had this question on last semesters qualifying exam in complex analysis, and I've attempted it several times since to little result. Let $f$ be an entire function with $|f(z)|\geq 1$ for all $|z|\geq 1$.  Prove that $f$ is a polynomial. I was trying to use something about $f$ being uniformly convergent to a power series, but I can't get it to go anywhere.","I had this question on last semesters qualifying exam in complex analysis, and I've attempted it several times since to little result. Let $f$ be an entire function with $|f(z)|\geq 1$ for all $|z|\geq 1$.  Prove that $f$ is a polynomial. I was trying to use something about $f$ being uniformly convergent to a power series, but I can't get it to go anywhere.",,['complex-analysis']
18,"Entire function constant, where $f(z)=f(z+1)$ and $|f(z)|< e^{|z|}$.","Entire function constant, where  and .",f(z)=f(z+1) |f(z)|< e^{|z|},"I came across this old exam problem. Suppose $f(z)$ is entire and $|f(z)|< e^{|z|}$, and also $f(z)=f(z+1)$. Show $f(z)$ is a constant. I am able to show the singularity at infinity is not a pole.   But I can't rule out it being an essential singularity.","I came across this old exam problem. Suppose $f(z)$ is entire and $|f(z)|< e^{|z|}$, and also $f(z)=f(z+1)$. Show $f(z)$ is a constant. I am able to show the singularity at infinity is not a pole.   But I can't rule out it being an essential singularity.",,['complex-analysis']
19,How should one think of non-projective compact manifolds and Moishezon manifolds?,How should one think of non-projective compact manifolds and Moishezon manifolds?,,"A Moishezon manifold $M$ is a compact connected complex manifold such that the field of meromorphic functions on $M$ has transcendence degree equal to the complex dimension of $M$. There exists a Moishezon manifold which is not projective for example and I believe that Moishezon manifold form a good class of manifolds. The existence of the non-projective Moishezon manifold surprised me because there are lots of meromorphic functions on it; in my understanding (it turns out to be incorrect), a non-projective compact complex manifold has very few meromorphic functions and very few complex submanifolds. My question is how should one think of the difference among projective manifolds, non-projective manifolds, and Moishezon manifold? Are there any good idea about how these three classes of manifolds are characterized heuristically?","A Moishezon manifold $M$ is a compact connected complex manifold such that the field of meromorphic functions on $M$ has transcendence degree equal to the complex dimension of $M$. There exists a Moishezon manifold which is not projective for example and I believe that Moishezon manifold form a good class of manifolds. The existence of the non-projective Moishezon manifold surprised me because there are lots of meromorphic functions on it; in my understanding (it turns out to be incorrect), a non-projective compact complex manifold has very few meromorphic functions and very few complex submanifolds. My question is how should one think of the difference among projective manifolds, non-projective manifolds, and Moishezon manifold? Are there any good idea about how these three classes of manifolds are characterized heuristically?",,"['complex-analysis', 'algebraic-geometry', 'complex-geometry']"
20,Complex differentiation,Complex differentiation,,Is differentiation in the complex plane the same as that in the reals? In particular do the normal differentiation rules apply in the complex case such that I can just treat a complex map as a real map? Thanks.,Is differentiation in the complex plane the same as that in the reals? In particular do the normal differentiation rules apply in the complex case such that I can just treat a complex map as a real map? Thanks.,,['complex-analysis']
21,Number of disjoint circles in half plane minus a disk that touch both boundary components,Number of disjoint circles in half plane minus a disk that touch both boundary components,,"Let $\Omega \subset \mathbb{C}$ be right half-plane, with the disc $D$ removed, where $D$ is the disk of radius $r=3$ centered at $z_0=5$. What is the maximum number of disjoint open disks in $\Omega$ whose boundary touch both boundary components of $\Omega$? This is a question I had on my qualifying exam years ago; I couldn't solve it then, and today I stumbled upon it again and it nags me that I can't find a solution. Or at least, one without using any table or any map that I couldn't come up with on my own during an exam. What I did (then and now) is to transform conformally the right half plane into the unit circle, and then see where the disk $D$ is mapped. Then my idea was to count the number of circles in this scenario. If the circles are not those coming from vertical lines in the right half plane, then they will come from circles in the original domain $\Omega$ (a simple test for a circle not to be a ""bad"" circle, is not to be centered on the real line, for example). That is,  $$ f(z)=\frac{z-1}{z+1} $$ maps $\Omega$ to the unit disk with the disk $\tilde{D}$ removed, where $\tilde{D}$ is the disk centered at $w_0=\frac{11}{15}$ of radius $\frac{2}{15}$ (this follows from some elementary but tedious computations which I won't include in the question). Now, I don't know how many disjoint circles touching both boundary components of $f(\Omega)$ I can fit in it, nor do I know how to guarantee that the answer is invariant under $f^{-1}$.","Let $\Omega \subset \mathbb{C}$ be right half-plane, with the disc $D$ removed, where $D$ is the disk of radius $r=3$ centered at $z_0=5$. What is the maximum number of disjoint open disks in $\Omega$ whose boundary touch both boundary components of $\Omega$? This is a question I had on my qualifying exam years ago; I couldn't solve it then, and today I stumbled upon it again and it nags me that I can't find a solution. Or at least, one without using any table or any map that I couldn't come up with on my own during an exam. What I did (then and now) is to transform conformally the right half plane into the unit circle, and then see where the disk $D$ is mapped. Then my idea was to count the number of circles in this scenario. If the circles are not those coming from vertical lines in the right half plane, then they will come from circles in the original domain $\Omega$ (a simple test for a circle not to be a ""bad"" circle, is not to be centered on the real line, for example). That is,  $$ f(z)=\frac{z-1}{z+1} $$ maps $\Omega$ to the unit disk with the disk $\tilde{D}$ removed, where $\tilde{D}$ is the disk centered at $w_0=\frac{11}{15}$ of radius $\frac{2}{15}$ (this follows from some elementary but tedious computations which I won't include in the question). Now, I don't know how many disjoint circles touching both boundary components of $f(\Omega)$ I can fit in it, nor do I know how to guarantee that the answer is invariant under $f^{-1}$.",,"['complex-analysis', 'conformal-geometry', 'mobius-transformation']"
22,Evaluate $\int_0^\infty \frac{\sqrt{x}}{x^2+1}\log\left(\frac{x+1}{2\sqrt{x}}\right)\;dx$,Evaluate,\int_0^\infty \frac{\sqrt{x}}{x^2+1}\log\left(\frac{x+1}{2\sqrt{x}}\right)\;dx,"Prove that $$\int_0^\infty \frac{\sqrt{x}}{x^2+1}\log\left(\frac{x+1}{2\sqrt{x}}\right)\;dx=\frac{\pi\sqrt{2}}{2}\log\left(1+\frac{\sqrt{2}}{2}\right).$$ I managed to prove this result with some rather roundabout complex analysis (writing the log term as an infinite sum involving nested logs), but I am hoping for a more direct solution via complex or real methods. The log term seems to require a rather complicated branch cut, so I am unsure as to how to solve the problem with a different technique.","Prove that $$\int_0^\infty \frac{\sqrt{x}}{x^2+1}\log\left(\frac{x+1}{2\sqrt{x}}\right)\;dx=\frac{\pi\sqrt{2}}{2}\log\left(1+\frac{\sqrt{2}}{2}\right).$$ I managed to prove this result with some rather roundabout complex analysis (writing the log term as an infinite sum involving nested logs), but I am hoping for a more direct solution via complex or real methods. The log term seems to require a rather complicated branch cut, so I am unsure as to how to solve the problem with a different technique.",,"['complex-analysis', 'definite-integrals', 'contour-integration']"
23,Prove that the Mandelbrot Set Is A Closed Set,Prove that the Mandelbrot Set Is A Closed Set,,"The Problem: Suppose we define the Mandelbrot Set as the following For  $c \in \mathbb{C}$  , $\mathbb{M}$ = $({c:|c| \leq 2}) \cap ({c: |c^2 + c| \leq 2}) \cap ({c: |(c^2+c)^2 + c| \leq 2})       \cap ...$ Carefully argue that each set in this intersection of sets is a closed subset of the Complex Plane. By this, show that the Mandelbrot Set is closed. The attempt - So for each $i \in \mathbb{N} $, we can write this set as the following: $\mathbb{M}= (c \in \mathbb{C} : |Q_{c}^{n} (0)| \leq 2)$, for $i \geq 1$,  which $Q_{c} (z) = z^2+c$. Now if we are going to show the set is closed, we can show that the complement of each set is open, which it is for each $i$, $\mathbb{M}^{c}= (c \in \mathbb{C} : |Q_{c}^{n} (0)| > 2)$, for $i \geq 1$. To show each set is open, we can find an ε-neighborhood of any point, $z_{0} \in \mathbb{M^c}$ for which $N(z_{0}, ε) \subseteq \mathbb{M} ^{c}$. I can define $ε = max ({2, |z_{0}|})$ and that is all I got so far. I am not sure if I am on the right track. However, there was a hint to this problem which I do not know what it means (Hint: If $F : \mathbb{C} \mapsto \mathbb{R}$, is a continuous function, then for every $b \in \mathbb{R}$,  the set $(c \in \mathbb{C} : F(c) \leq b)$. Is this the neighborhood I was supposed to be defining? Thank you very much for your help!","The Problem: Suppose we define the Mandelbrot Set as the following For  $c \in \mathbb{C}$  , $\mathbb{M}$ = $({c:|c| \leq 2}) \cap ({c: |c^2 + c| \leq 2}) \cap ({c: |(c^2+c)^2 + c| \leq 2})       \cap ...$ Carefully argue that each set in this intersection of sets is a closed subset of the Complex Plane. By this, show that the Mandelbrot Set is closed. The attempt - So for each $i \in \mathbb{N} $, we can write this set as the following: $\mathbb{M}= (c \in \mathbb{C} : |Q_{c}^{n} (0)| \leq 2)$, for $i \geq 1$,  which $Q_{c} (z) = z^2+c$. Now if we are going to show the set is closed, we can show that the complement of each set is open, which it is for each $i$, $\mathbb{M}^{c}= (c \in \mathbb{C} : |Q_{c}^{n} (0)| > 2)$, for $i \geq 1$. To show each set is open, we can find an ε-neighborhood of any point, $z_{0} \in \mathbb{M^c}$ for which $N(z_{0}, ε) \subseteq \mathbb{M} ^{c}$. I can define $ε = max ({2, |z_{0}|})$ and that is all I got so far. I am not sure if I am on the right track. However, there was a hint to this problem which I do not know what it means (Hint: If $F : \mathbb{C} \mapsto \mathbb{R}$, is a continuous function, then for every $b \in \mathbb{R}$,  the set $(c \in \mathbb{C} : F(c) \leq b)$. Is this the neighborhood I was supposed to be defining? Thank you very much for your help!",,['complex-analysis']
24,Show that the map $\epsilon \to z_{\epsilon}$ is continuous,Show that the map  is continuous,\epsilon \to z_{\epsilon},"Suppose that $f$ and $g$ are holomorphic in a domain containing the unit disc $D=\{z| |z| \le 1 \}$. Suppose that $f$ has a simple zero at $z=0$ and vanishes nowhere in the unit disc. Let $f_{\epsilon}(z)=f(z)+ \epsilon g(z)$. Show that if $\epsilon$ is sufficiently small then a) $f_{\epsilon}(z)$ has a unique zero in the unit disc. b) Show that the map $\epsilon \to z_{\epsilon}$ is continuous My try: For (a): Since  $f$ has a simple zero at $z=0$ and vanishes nowhere in the unit disc, on $|z|=1$ ,$f$ attains the minimum value (say $\delta \gt 0$). Since $g$ is holomorphic on $D$, $g$ attains its maximum (say $M$). Then we have $$|f_{\epsilon}(z)-f(z)|=| \epsilon g(z)| \lt \epsilon M$$ For $\epsilon \lt \frac{\delta}{M}$, on $|z|=1$, we have $$|f_{\epsilon}(z)-f(z)| \lt \delta \le |f(z)|$$ . The conclusion follows by Rouche's theorem. For (b)    I have no idea on how to proceed. Thanks for the help!!","Suppose that $f$ and $g$ are holomorphic in a domain containing the unit disc $D=\{z| |z| \le 1 \}$. Suppose that $f$ has a simple zero at $z=0$ and vanishes nowhere in the unit disc. Let $f_{\epsilon}(z)=f(z)+ \epsilon g(z)$. Show that if $\epsilon$ is sufficiently small then a) $f_{\epsilon}(z)$ has a unique zero in the unit disc. b) Show that the map $\epsilon \to z_{\epsilon}$ is continuous My try: For (a): Since  $f$ has a simple zero at $z=0$ and vanishes nowhere in the unit disc, on $|z|=1$ ,$f$ attains the minimum value (say $\delta \gt 0$). Since $g$ is holomorphic on $D$, $g$ attains its maximum (say $M$). Then we have $$|f_{\epsilon}(z)-f(z)|=| \epsilon g(z)| \lt \epsilon M$$ For $\epsilon \lt \frac{\delta}{M}$, on $|z|=1$, we have $$|f_{\epsilon}(z)-f(z)| \lt \delta \le |f(z)|$$ . The conclusion follows by Rouche's theorem. For (b)    I have no idea on how to proceed. Thanks for the help!!",,"['complex-analysis', 'analysis', 'continuity']"
25,How to evaluate residue of $\cot z/z^4$ at $z=0$?,How to evaluate residue of  at ?,\cot z/z^4 z=0,How to evaluate residue of $\cot z/z^4$ at $z=0$? As we know : $$f(x)=f(0)+f'(0)x+f''(0)x^2/2+...$$ but $\cot(0)\to\infty$ or is undefined? I know that: $$\tan x=x+x^3/3+2x^5/15+...$$,How to evaluate residue of $\cot z/z^4$ at $z=0$? As we know : $$f(x)=f(0)+f'(0)x+f''(0)x^2/2+...$$ but $\cot(0)\to\infty$ or is undefined? I know that: $$\tan x=x+x^3/3+2x^5/15+...$$,,['complex-analysis']
26,Is it possible that $|z+\sum_{i\not=1} a_i z^i| <1$ for some $a_i \in \mathbb{C}$ and for all $|z|=1$?,Is it possible that  for some  and for all ?,|z+\sum_{i\not=1} a_i z^i| <1 a_i \in \mathbb{C} |z|=1,"I wonder that whether there exists a complex polynomial of the form $$ P(z)= z+\sum_{i\not=1} a_iz^i, a_i,z\in \mathbb{C},$$ (i.e. its first order term has coefficient 1) s.t. its modulus is less than 1 on $|z|\leq 1$, i.e. $$ |P(z)|<1,\forall |z|\leq 1. $$ I know by modulus maximum  principle, we only need to find $$ |P(z)| <1, \forall |z|=1.$$ Does there  exist such polynomial? I have tried the chebyshev polynomial but didn't get through. Any ideas? Any help would be appreciated!","I wonder that whether there exists a complex polynomial of the form $$ P(z)= z+\sum_{i\not=1} a_iz^i, a_i,z\in \mathbb{C},$$ (i.e. its first order term has coefficient 1) s.t. its modulus is less than 1 on $|z|\leq 1$, i.e. $$ |P(z)|<1,\forall |z|\leq 1. $$ I know by modulus maximum  principle, we only need to find $$ |P(z)| <1, \forall |z|=1.$$ Does there  exist such polynomial? I have tried the chebyshev polynomial but didn't get through. Any ideas? Any help would be appreciated!",,"['complex-analysis', 'polynomials']"
27,Prove using contour integration that $\int_0^\infty \frac{\log x}{x^3-1}\operatorname d\!x=\frac{4\pi^2}{27}$,Prove using contour integration that,\int_0^\infty \frac{\log x}{x^3-1}\operatorname d\!x=\frac{4\pi^2}{27},"Prove using contour integration that $\displaystyle \int_0^\infty \frac{\log x}{x^3-1}\operatorname d\!x=\frac{4\pi^2}{27}$ I am at a loss at how to start this problem and which contour to pick. I have been trying to get the sector with angle $2\pi/3$ to work with a bump around the pole at $e^{i2\pi/3}$ and the origin, but I am getting 5 or 6 different integrals and it is not really getting me anywhere.","Prove using contour integration that $\displaystyle \int_0^\infty \frac{\log x}{x^3-1}\operatorname d\!x=\frac{4\pi^2}{27}$ I am at a loss at how to start this problem and which contour to pick. I have been trying to get the sector with angle $2\pi/3$ to work with a bump around the pole at $e^{i2\pi/3}$ and the origin, but I am getting 5 or 6 different integrals and it is not really getting me anywhere.",,"['complex-analysis', 'definite-integrals', 'contour-integration']"
28,$f^2$ and $f^3$ are holomorphic implies $f$ is holomorphic.,and  are holomorphic implies  is holomorphic.,f^2 f^3 f,"Suppose $f$ is a continuous complex valued function on a domain $\Omega$. Suppose $f^2$ and $f^3$ are holomorphic in $\Omega$. Show that $f$ is also holomorphic in $\Omega$. Assume $f=u+iv$. I see that if $u,v$ are in $C^1$ then $f^2$ is holomorphic can imply $f$ is holomorphic considering Cauchy-Riemann equations. But I don't know how to get $u,v$ are in $C^1$ by the adding condition $f^3$ is holomorphic. (I can't get $u,v$ from some combinations of real and imaginary part of $f^2$ and $f^3$). Do someone know how to do this?","Suppose $f$ is a continuous complex valued function on a domain $\Omega$. Suppose $f^2$ and $f^3$ are holomorphic in $\Omega$. Show that $f$ is also holomorphic in $\Omega$. Assume $f=u+iv$. I see that if $u,v$ are in $C^1$ then $f^2$ is holomorphic can imply $f$ is holomorphic considering Cauchy-Riemann equations. But I don't know how to get $u,v$ are in $C^1$ by the adding condition $f^3$ is holomorphic. (I can't get $u,v$ from some combinations of real and imaginary part of $f^2$ and $f^3$). Do someone know how to do this?",,['complex-analysis']
29,Conformal maps from the upper half-plane to the unit disc has the form,Conformal maps from the upper half-plane to the unit disc has the form,,"Prove that the conformal maps from the upper half-plane $\mathbb{H}$ to the unit disc $\mathbb{D}$ has the form $$e^{i\theta}\dfrac{z-\beta}{z-\overline{\beta}},\quad\theta \in \mathbb{R} \text { and }\beta \in \mathbb{H}.$$ Any hints?","Prove that the conformal maps from the upper half-plane $\mathbb{H}$ to the unit disc $\mathbb{D}$ has the form $$e^{i\theta}\dfrac{z-\beta}{z-\overline{\beta}},\quad\theta \in \mathbb{R} \text { and }\beta \in \mathbb{H}.$$ Any hints?",,"['complex-analysis', 'conformal-geometry']"
30,Why are two directions enough for the Cauchy-Riemann equations to imply differentiability?,Why are two directions enough for the Cauchy-Riemann equations to imply differentiability?,,"If the complex function $f(z)$ is complex differentiable $\Rightarrow$ the Cauchy Riemann equations hold. $($This is because if $f'(z)$ is the same no matter in what direction $\delta z\rightarrow 0$. Choosing the special case of $\delta z\rightarrow 0$ along the real, then the imaginary, line yields the Cauchy Riemann equations, so it is obvious that any differentiable function will satisfy them$)$. However, how is demonstrating that $f'(z)$ is the same for two perpendicular paths enough to show that $f'(z)$ is the same for all paths (i.e. how does one go from $\Rightarrow$ to $\Leftrightarrow$)? I have tried explicitly calculating the directional derivatives, but the mess that ensued did not enlighten whatsoever. I do not know much about linear algebra if that helps in writing answers. Any geometric intuition would be greatly appreciated!","If the complex function $f(z)$ is complex differentiable $\Rightarrow$ the Cauchy Riemann equations hold. $($This is because if $f'(z)$ is the same no matter in what direction $\delta z\rightarrow 0$. Choosing the special case of $\delta z\rightarrow 0$ along the real, then the imaginary, line yields the Cauchy Riemann equations, so it is obvious that any differentiable function will satisfy them$)$. However, how is demonstrating that $f'(z)$ is the same for two perpendicular paths enough to show that $f'(z)$ is the same for all paths (i.e. how does one go from $\Rightarrow$ to $\Leftrightarrow$)? I have tried explicitly calculating the directional derivatives, but the mess that ensued did not enlighten whatsoever. I do not know much about linear algebra if that helps in writing answers. Any geometric intuition would be greatly appreciated!",,['complex-analysis']
31,Integrate: $\int_0^1 \frac{1}{\sqrt[3]{x^2 - x^3}}dx$,Integrate:,\int_0^1 \frac{1}{\sqrt[3]{x^2 - x^3}}dx,"How to integrate using Residue theorem. $$\int_0^1 \frac{1}{\sqrt[3]{x^2 - x^3}}dx$$ How do I choose my branch-cut particularly? I was reading this article on wikiepdia and I think it is related. What I don't understand is ""The cut of $z^{3/4}$ is therefore $(−∞, 0]$ and the cut of $(3−z)^{1/4}$ is $(−∞, 3]$. It is easy to see that the cut of the product of the two, i.e. $f(z)$, is $[0, 3]$"" . What is this product? Is it $(-\infty, 3]\setminus (-\infty, 0] \cup {0}$ ? Why is $0\le\arg((3-z)^{(1/4)}) \le 2\pi$? the start of angle is taken at negative $x$ axis (counterclockwise) while $0\le\arg(z^{(3/4)}) \le 2\pi$ is taken along positive axis (counterclockwise)? Also in my integral, I think I don't have residue outside the contour, do I? Thanks for your help in advance!! ADDED:: My given hint says to use this contour but this quite different from the one in Wikipedia?","How to integrate using Residue theorem. $$\int_0^1 \frac{1}{\sqrt[3]{x^2 - x^3}}dx$$ How do I choose my branch-cut particularly? I was reading this article on wikiepdia and I think it is related. What I don't understand is ""The cut of $z^{3/4}$ is therefore $(−∞, 0]$ and the cut of $(3−z)^{1/4}$ is $(−∞, 3]$. It is easy to see that the cut of the product of the two, i.e. $f(z)$, is $[0, 3]$"" . What is this product? Is it $(-\infty, 3]\setminus (-\infty, 0] \cup {0}$ ? Why is $0\le\arg((3-z)^{(1/4)}) \le 2\pi$? the start of angle is taken at negative $x$ axis (counterclockwise) while $0\le\arg(z^{(3/4)}) \le 2\pi$ is taken along positive axis (counterclockwise)? Also in my integral, I think I don't have residue outside the contour, do I? Thanks for your help in advance!! ADDED:: My given hint says to use this contour but this quite different from the one in Wikipedia?",,"['complex-analysis', 'contour-integration']"
32,Show that analytic function $f$ cannot be conformal when $f'(z) = 0$,Show that analytic function  cannot be conformal when,f f'(z) = 0,"I am reading over Rudin's discussion of conformal mappings in ""Real and Complex Analysis."" Rudin states that ""no analytic function preserves angles at any point where its derivative is zero. We omit the easy proof of this."" So I am trying to fill in the proof. Suppose $\Omega \subseteq \mathbb{C}$ is open and connnected, and that we are given $z_0 \in \mathbb{C}$ and $f: \Omega \to \mathbb{C}$. Futhermore, suppose that there is some punctured disk $D(z_0, r) \setminus \{z_0\} \subseteq \Omega$ on which $f(z) \neq f(z_0)$. Then Rudin defines $f$ to be angle preserving at $z_0$ iff $$\lim_{r \to 0} e^{-i\theta}\frac{f(z_0 + re^{i\theta}) - f(z_0)}{|f(z_0 + re^{i\theta}) - f(z_0)|}$$ exists and is independent of $\theta$. So, with the additional assumption that $f'(z_0) = 0$, I want to suppose that the limit above exists (and is independent of $\theta$), and then arrive at some contradiction. Hints or solutions are greatly appreciated.","I am reading over Rudin's discussion of conformal mappings in ""Real and Complex Analysis."" Rudin states that ""no analytic function preserves angles at any point where its derivative is zero. We omit the easy proof of this."" So I am trying to fill in the proof. Suppose $\Omega \subseteq \mathbb{C}$ is open and connnected, and that we are given $z_0 \in \mathbb{C}$ and $f: \Omega \to \mathbb{C}$. Futhermore, suppose that there is some punctured disk $D(z_0, r) \setminus \{z_0\} \subseteq \Omega$ on which $f(z) \neq f(z_0)$. Then Rudin defines $f$ to be angle preserving at $z_0$ iff $$\lim_{r \to 0} e^{-i\theta}\frac{f(z_0 + re^{i\theta}) - f(z_0)}{|f(z_0 + re^{i\theta}) - f(z_0)|}$$ exists and is independent of $\theta$. So, with the additional assumption that $f'(z_0) = 0$, I want to suppose that the limit above exists (and is independent of $\theta$), and then arrive at some contradiction. Hints or solutions are greatly appreciated.",,['complex-analysis']
33,Linear Transformations mapping four points,Linear Transformations mapping four points,,"Problem: Show that any four distinct points can be carried by a linear transformation to positions $1, -1, k, -k$, where the value of $k$ depends on the points. How many solutions are there, and how are they related? Attempt at a solution: So I know that given any three points $z_2, z_3, z_4$ I can find a linear transformation that carries these points to some other points $w_2, w_3, w_4$ this can be done since the ratio is preserved; that is $$(w, w_2, w_3, w_4)=(z, z_2, z_3,z_4).---(1)$$ So, in our case we have $w_2=-1, w_3=k$ and $w_4=-k$, and we want this transformation to be such that it will also take $z_1$ to $1$. After performing the necessary algebraic steps in $(1)$ I found $$w(z)=\frac{(1+k)(z-z_3)(z_2-z_4)+(1-k)(z-z_4)(z_2-z_3)}{(1-k)(z-z_4)(z_2-z_3)-(1+k)(z-z_3)(z_2-z_4)}k$$ This transformation takes the $z_2$ to $-1$, $z_3$ to $k$ and $z_4$ to $-k.$ So now, do I just force the transformation so that $w(z_1)=1$? I am not sure how the whole $k$ being dependent on the points we choose is coming into play? Any hints?? Thanks!","Problem: Show that any four distinct points can be carried by a linear transformation to positions $1, -1, k, -k$, where the value of $k$ depends on the points. How many solutions are there, and how are they related? Attempt at a solution: So I know that given any three points $z_2, z_3, z_4$ I can find a linear transformation that carries these points to some other points $w_2, w_3, w_4$ this can be done since the ratio is preserved; that is $$(w, w_2, w_3, w_4)=(z, z_2, z_3,z_4).---(1)$$ So, in our case we have $w_2=-1, w_3=k$ and $w_4=-k$, and we want this transformation to be such that it will also take $z_1$ to $1$. After performing the necessary algebraic steps in $(1)$ I found $$w(z)=\frac{(1+k)(z-z_3)(z_2-z_4)+(1-k)(z-z_4)(z_2-z_3)}{(1-k)(z-z_4)(z_2-z_3)-(1+k)(z-z_3)(z_2-z_4)}k$$ This transformation takes the $z_2$ to $-1$, $z_3$ to $k$ and $z_4$ to $-k.$ So now, do I just force the transformation so that $w(z_1)=1$? I am not sure how the whole $k$ being dependent on the points we choose is coming into play? Any hints?? Thanks!",,['complex-analysis']
34,A complex valued continuous function which is holomorphic outside of its zeros,A complex valued continuous function which is holomorphic outside of its zeros,,Let $D$ be a non-empty connected open subset of $\mathbb{C}^n$. Let $f$ be a complex valued continuous function on $D$. Let $Z$ be the set of zeros of $f$. Suppose $f$ is holomoprphic on $D - Z$. Is $f$ holomorphic on $D$?,Let $D$ be a non-empty connected open subset of $\mathbb{C}^n$. Let $f$ be a complex valued continuous function on $D$. Let $Z$ be the set of zeros of $f$. Suppose $f$ is holomoprphic on $D - Z$. Is $f$ holomorphic on $D$?,,"['complex-analysis', 'several-complex-variables']"
35,How can I show this statement.,How can I show this statement.,,Show that there is no holomorphic fuction $f$ in the unit disc $D$ that  extends continuously to boundary of $D$ such that $f(z)=\frac{1}{z} ~for~ z\in \partial( D) $. I tried to apply maximum principle but I couln't find the way to prove it. Help me please. I just update the full statement and I think it probably assume it is not constant fuction. Thank you.,Show that there is no holomorphic fuction $f$ in the unit disc $D$ that  extends continuously to boundary of $D$ such that $f(z)=\frac{1}{z} ~for~ z\in \partial( D) $. I tried to apply maximum principle but I couln't find the way to prove it. Help me please. I just update the full statement and I think it probably assume it is not constant fuction. Thank you.,,['complex-analysis']
36,Showing that an entire function is a polynomial,Showing that an entire function is a polynomial,,"Let $f(z)$ be an entire function, $R_n$ a sequence of positive real numbers tending to $\infty$ such that $f(z) \neq 0$ on $|z|=R_n$ and there exists $M>0$ such that $$\int_{|z|=R_n} \left|\frac{f'(z)}{f(z)}\right| ~dz<M$$ for all $n$. Show that $f$ is a polynomial. What came to my mind is to consider that $f(z)=a_0+a_1z+\cdots \;\;\forall z\in\mathbb{C}$, and to try proving that $a_k=0$ from a certain $k$, maybe using the Cauchy formula for these coefficients, but I can't use the hypotesis on that bounded integral. Is observing that there is a logarithmic derivative of any use?","Let $f(z)$ be an entire function, $R_n$ a sequence of positive real numbers tending to $\infty$ such that $f(z) \neq 0$ on $|z|=R_n$ and there exists $M>0$ such that $$\int_{|z|=R_n} \left|\frac{f'(z)}{f(z)}\right| ~dz<M$$ for all $n$. Show that $f$ is a polynomial. What came to my mind is to consider that $f(z)=a_0+a_1z+\cdots \;\;\forall z\in\mathbb{C}$, and to try proving that $a_k=0$ from a certain $k$, maybe using the Cauchy formula for these coefficients, but I can't use the hypotesis on that bounded integral. Is observing that there is a logarithmic derivative of any use?",,['complex-analysis']
37,Showing $\int_{0}^{\infty} \frac{1}{(x^2+1)^2(x^2+4)}=\frac{\pi}{18}$ via contour integration,Showing  via contour integration,\int_{0}^{\infty} \frac{1}{(x^2+1)^2(x^2+4)}=\frac{\pi}{18},"I want to show that: $$\int_{0}^{\infty} \frac{1}{(x^2+1)^2(x^2+4)}=\frac{\pi}{18}$$  so considering: $$\int_{\gamma} \frac{1}{(z^2+1)^2(z^2+4)}$$ where gamma is the curve going from $0$ to $-R$ along the real axis, from $-R$ to R via a semi-circle in the upper plane and then from $R$ to 0 along the real axis. Using the residue theorem we have that: $$\int_{\gamma} \frac{1}{(z^2+1)^2(z^2+4)}=2\pi i \sum Res$$ so re-writing the integrand as $\displaystyle\frac{1}{(z-2i)(z+2i)(z+i)^2(z-i)^2}$ we can see that there is two simple poles at $2i$,$-2i$ and two poles of order 2 at $i$,$-i$.  Calculating the residues: $$Res_{z=2i}=\lim_{z\rightarrow 2i} \displaystyle\frac{1}{(z+2i)(z+i)^2(z-i)^2}=\frac{1}{36i}$$ $$Res_{z=-2i}=\lim_{z\rightarrow 2i} \displaystyle\frac{1}{(z-2i)(z+i)^2(z-i)^2}=\frac{-1}{36i}$$ $$Res_{z=i}\lim_{z\rightarrow i} \frac{d}{dz} \frac{1}{(z-2i)(z+2i)(z+i)^2}=\frac{2i}{36}+\frac{2}{24i}$$ $$Res_{z=-i}\lim_{z\rightarrow -i} \frac{d}{dz} \frac{1}{(z-2i)(z+2i)(z-i)^2}=\frac{-2i}{36}+\frac{-2}{24i}$$ But now the sum of the residues is 0 and so when I integrate over my curve letting R go to $\infty$ (and the integral over top semi-circle goes to 0) I will just get 0? Not sure what I've done wrong? Thanks very much for any help","I want to show that: $$\int_{0}^{\infty} \frac{1}{(x^2+1)^2(x^2+4)}=\frac{\pi}{18}$$  so considering: $$\int_{\gamma} \frac{1}{(z^2+1)^2(z^2+4)}$$ where gamma is the curve going from $0$ to $-R$ along the real axis, from $-R$ to R via a semi-circle in the upper plane and then from $R$ to 0 along the real axis. Using the residue theorem we have that: $$\int_{\gamma} \frac{1}{(z^2+1)^2(z^2+4)}=2\pi i \sum Res$$ so re-writing the integrand as $\displaystyle\frac{1}{(z-2i)(z+2i)(z+i)^2(z-i)^2}$ we can see that there is two simple poles at $2i$,$-2i$ and two poles of order 2 at $i$,$-i$.  Calculating the residues: $$Res_{z=2i}=\lim_{z\rightarrow 2i} \displaystyle\frac{1}{(z+2i)(z+i)^2(z-i)^2}=\frac{1}{36i}$$ $$Res_{z=-2i}=\lim_{z\rightarrow 2i} \displaystyle\frac{1}{(z-2i)(z+i)^2(z-i)^2}=\frac{-1}{36i}$$ $$Res_{z=i}\lim_{z\rightarrow i} \frac{d}{dz} \frac{1}{(z-2i)(z+2i)(z+i)^2}=\frac{2i}{36}+\frac{2}{24i}$$ $$Res_{z=-i}\lim_{z\rightarrow -i} \frac{d}{dz} \frac{1}{(z-2i)(z+2i)(z-i)^2}=\frac{-2i}{36}+\frac{-2}{24i}$$ But now the sum of the residues is 0 and so when I integrate over my curve letting R go to $\infty$ (and the integral over top semi-circle goes to 0) I will just get 0? Not sure what I've done wrong? Thanks very much for any help",,['complex-analysis']
38,Question regarding infinite Blaschke product,Question regarding infinite Blaschke product,,"According to Gamelin's $\textit{Complex Analysis}$, a finite Blaschke product is a rational function of the form $B(z)= e^{i \varphi} (\frac{z-a_1}{1-\bar{a_1} z} \cdots \frac{z-a_n}{1-\bar{a_n} z})$ where $a_1, ..., a_n \in \mathbb{D}$ and $0 \leq \varphi \leq 2\pi$. Similarly, I would guess that an infinite Blaschke product would be of the form $e^{i \varphi} \prod_{n=1}^\infty\frac{z-a_n}{1-\bar{a_n} z}$. I believe this is supposed to satisfy what is known as the Blaschke condition, i.e. $\sum_{n=1}^\infty (1-|a_n|) < \infty$, but how is that so? Can this be verified using the log function on the infinite product?","According to Gamelin's $\textit{Complex Analysis}$, a finite Blaschke product is a rational function of the form $B(z)= e^{i \varphi} (\frac{z-a_1}{1-\bar{a_1} z} \cdots \frac{z-a_n}{1-\bar{a_n} z})$ where $a_1, ..., a_n \in \mathbb{D}$ and $0 \leq \varphi \leq 2\pi$. Similarly, I would guess that an infinite Blaschke product would be of the form $e^{i \varphi} \prod_{n=1}^\infty\frac{z-a_n}{1-\bar{a_n} z}$. I believe this is supposed to satisfy what is known as the Blaschke condition, i.e. $\sum_{n=1}^\infty (1-|a_n|) < \infty$, but how is that so? Can this be verified using the log function on the infinite product?",,['complex-analysis']
39,Liouville's theorem problem,Liouville's theorem problem,,Hi i need some hints and help with this problem. Let $f\in\mathcal O(\mathbb C)$ and assume that $\Re f(z)\geq M$ for all $z\in\mathbb C$. Use Liouville´s theorem to prove that $f$ is constant function. I am really stuck on this problem.,Hi i need some hints and help with this problem. Let $f\in\mathcal O(\mathbb C)$ and assume that $\Re f(z)\geq M$ for all $z\in\mathbb C$. Use Liouville´s theorem to prove that $f$ is constant function. I am really stuck on this problem.,,"['complex-analysis', 'analyticity']"
40,Analytic functions of absolute value 1 on the boundary of the unit disc,Analytic functions of absolute value 1 on the boundary of the unit disc,,"Is there a characterization of analytic functions $f$ on the unit disc such that $|f(z)|=1$ for $|z|=1$? If $f$ only has a zero $a\in D(0,1)$ of order $n$, then $f(z)=\phi_a(cz^n)$ for some constant $|c|=1$ where $\phi_a$ is the Möbius transformation at $a$. One can iterate this process in the case when $f$ has distinct zeroes, but is there a cleaner formula than something that looks like $\phi_{a_1}(c_1z^{n_1}\phi_{a_2}(c_2 z^{n_2}\cdots \phi_{a_N}( c_N z^{n_N})\cdots)$? Thanks!","Is there a characterization of analytic functions $f$ on the unit disc such that $|f(z)|=1$ for $|z|=1$? If $f$ only has a zero $a\in D(0,1)$ of order $n$, then $f(z)=\phi_a(cz^n)$ for some constant $|c|=1$ where $\phi_a$ is the Möbius transformation at $a$. One can iterate this process in the case when $f$ has distinct zeroes, but is there a cleaner formula than something that looks like $\phi_{a_1}(c_1z^{n_1}\phi_{a_2}(c_2 z^{n_2}\cdots \phi_{a_N}( c_N z^{n_N})\cdots)$? Thanks!",,['complex-analysis']
41,Behaviour of a holomorphic function near a pole,Behaviour of a holomorphic function near a pole,,"Apparently, the following statement is true: ""Let $D\subseteq \mathbb{C}$ be open and connected and $f:D\setminus \{a\}\longrightarrow \mathbb{C}$ holomorphic with a pole of arbitrary order at $a\in D$. For any $\epsilon > 0$ with $B_\epsilon(a)\setminus\{a\} \subseteq D$, there exists $r > 0$ so that $\{z \in \mathbb{C}: |z| > r\} \subseteq f(B_\epsilon(a)\setminus\{a\})$."" So far, I have been unsuccessful in proving this. I know that $f(B_\epsilon(a)\setminus\{a\})$ must be open and connected (open mapping theorem), as well as that for any  $r > 0$ there exists an $x \in B_\epsilon(a)$ so that $f(x) > r$ (because $\lim_{z\rightarrow a}|f(z)| = \infty)$, but I don't see how this would imply the statement in question. Any help would be appreciated.","Apparently, the following statement is true: ""Let $D\subseteq \mathbb{C}$ be open and connected and $f:D\setminus \{a\}\longrightarrow \mathbb{C}$ holomorphic with a pole of arbitrary order at $a\in D$. For any $\epsilon > 0$ with $B_\epsilon(a)\setminus\{a\} \subseteq D$, there exists $r > 0$ so that $\{z \in \mathbb{C}: |z| > r\} \subseteq f(B_\epsilon(a)\setminus\{a\})$."" So far, I have been unsuccessful in proving this. I know that $f(B_\epsilon(a)\setminus\{a\})$ must be open and connected (open mapping theorem), as well as that for any  $r > 0$ there exists an $x \in B_\epsilon(a)$ so that $f(x) > r$ (because $\lim_{z\rightarrow a}|f(z)| = \infty)$, but I don't see how this would imply the statement in question. Any help would be appreciated.",,['complex-analysis']
42,An integral using residue calculus,An integral using residue calculus,,"This integral is surprisingly difficult to evaluate, and I have looked in several references and none contain a single integral of this type. Any help would be greatly appreciated. Evaluate $\displaystyle \int_0^\infty \frac{\sin(z)}{1 + z^2}dz$.","This integral is surprisingly difficult to evaluate, and I have looked in several references and none contain a single integral of this type. Any help would be greatly appreciated. Evaluate $\displaystyle \int_0^\infty \frac{\sin(z)}{1 + z^2}dz$.",,['complex-analysis']
43,Is there an identity for $\sum_{k=0}^{n-1}\csc\left(x+ k \frac{\pi}{n}\right)\csc\left(y+ k \frac{\pi}{n}\right)$?,Is there an identity for ?,\sum_{k=0}^{n-1}\csc\left(x+ k \frac{\pi}{n}\right)\csc\left(y+ k \frac{\pi}{n}\right),"What I'd like to find is an identity for $$\sum_{k=0}^{n-1}\csc\left(x+ k \frac{\pi}{n}\right)\csc\left(y+ k \frac{\pi}{n}\right)$$ here it can be shown that where $x=y$ , $$n^2 \csc^2(nx) = \sum_{k=0}^{n-1}\csc^2\left(x+ k \frac{\pi}{n}\right)$$ I also looked at possible residue methods involving csc I thought I could use $\left(  \sum^{n-1}_{j=0}Z_j\right)^2 = \sum^{n-1}_{j=0} Z_j^2 +\sum^{n-1}_{j=0}\sum^{n-1}_{i\neq j} Z_jZ_i$ but I have had no luck so far.","What I'd like to find is an identity for here it can be shown that where , I also looked at possible residue methods involving csc I thought I could use but I have had no luck so far.",\sum_{k=0}^{n-1}\csc\left(x+ k \frac{\pi}{n}\right)\csc\left(y+ k \frac{\pi}{n}\right) x=y n^2 \csc^2(nx) = \sum_{k=0}^{n-1}\csc^2\left(x+ k \frac{\pi}{n}\right) \left(  \sum^{n-1}_{j=0}Z_j\right)^2 = \sum^{n-1}_{j=0} Z_j^2 +\sum^{n-1}_{j=0}\sum^{n-1}_{i\neq j} Z_jZ_i,"['complex-analysis', 'trigonometry', 'summation', 'trigonometric-series', 'summation-method']"
44,"How to prove $a_0 + a_1 \cos \theta + a_2 \cos 2\theta + \cdots + a_n \cos n \theta$ has $2n$ different zeros, $\theta \in (0,2\pi)$.","How to prove  has  different zeros, .","a_0 + a_1 \cos \theta + a_2 \cos 2\theta + \cdots + a_n \cos n \theta 2n \theta \in (0,2\pi)","$0 < a_0 < a_1 < \cdots < a_n$. Prove that $a_0 + a_1 \cos \theta + a_2 \cos 2\theta + \cdots + a_n \cos n \theta$ has $2n$ different zeros, $\theta \in (0,2\pi)$. [Hint: First prove that $P_n(z)=a_o+a_1z+a_2z^2+\cdots+a_nz^n$ has $n$ zeros in unit ball $B(0,1)$.] This is an assignment I copied from my textbook. It's in the section ""The Argument Principle & Rouche Theorem"". Though I followed this hint, I still can't see how this would imply the desired conclusion. Help needed.","$0 < a_0 < a_1 < \cdots < a_n$. Prove that $a_0 + a_1 \cos \theta + a_2 \cos 2\theta + \cdots + a_n \cos n \theta$ has $2n$ different zeros, $\theta \in (0,2\pi)$. [Hint: First prove that $P_n(z)=a_o+a_1z+a_2z^2+\cdots+a_nz^n$ has $n$ zeros in unit ball $B(0,1)$.] This is an assignment I copied from my textbook. It's in the section ""The Argument Principle & Rouche Theorem"". Though I followed this hint, I still can't see how this would imply the desired conclusion. Help needed.",,['complex-analysis']
45,Residue of $f'/f$ is equal to $m$.,Residue of  is equal to .,f'/f m,"So I know that if $f$ is analytic and has a zero of order $m$ at its center, then $f'$ has a zero of order of $m-1$, which can be easily proved. However, I'm not sure, which is stated in the question, how this is related to residues, and how to prove that the residue of $f'/f$ is equal to $m$ if $f$ is analytic and has a zero of order $m$.  Any help would be much appreciated, thank you. If $f$ is analytic in $|z - z_0| < R$ and has a zero of order $m$ at $z_0$, show that $$Res\left( \frac{f'}{f} ; z_0 \right) = m.$$","So I know that if $f$ is analytic and has a zero of order $m$ at its center, then $f'$ has a zero of order of $m-1$, which can be easily proved. However, I'm not sure, which is stated in the question, how this is related to residues, and how to prove that the residue of $f'/f$ is equal to $m$ if $f$ is analytic and has a zero of order $m$.  Any help would be much appreciated, thank you. If $f$ is analytic in $|z - z_0| < R$ and has a zero of order $m$ at $z_0$, show that $$Res\left( \frac{f'}{f} ; z_0 \right) = m.$$",,"['complex-analysis', 'complex-numbers']"
46,Solving $e^{e^z}=1$: am I missing something?,Solving : am I missing something?,e^{e^z}=1,"I solved the equation $e^{e^z}=1$ and it seemed to easy so I suspect I must be missing something. Would someone please check my answer? My original answer: $e^{e^z}=1$ if and only if $e^z = 2\pi i k$ for $k\in \mathbb Z$ if and only if $z=\ln(2\pi i k)$ for $k\in \mathbb Z$. Edit After reading the comments and answers I tried to do it again. Unfortunately, I still do not get the same result as in the answers. My second attempt: We have $$ e^x = 1 \iff x = 2 \pi i k$$ hence $$ e^z = 2 \pi i k$$ for some $k$ in $\mathbb Z$. Letting $e^z = e^x (\cos y + i \sin y)$ we get $$ e^x \cos y + i e^x \sin y = 2 \pi k i$$ which implies that $\cos y = 0$ which happens if and only if $y_j = {\pi \over 2} + \pi j$ where $j\in \mathbb Z$. At $y_j$ we have $\sin y = \pm 1$ hence if $j$ is even $$ e^x = 2 \pi i k$$ and if $j$ is odd $$ e^x = -2 \pi i k$$ Hence if $j$ is even, $$ x = {\pi \over 2} + \ln(2 \pi k)$$ and if $j$ is odd, $$ x = {3\pi \over 2} + \ln(2 \pi k)$$ So we see that the solutions are $$ z_{t,k}=\begin{cases}  {\pi \over 2} + \ln(2 \pi k) + i ({\pi \over 2} + 2t \pi )\\   {3\pi \over 2} + \ln(2 \pi k) + i({\pi \over 2} + (2 +1)t \pi ) \end{cases}  $$ for $k,t \in \mathbb Z$. What am I doing wrong?","I solved the equation $e^{e^z}=1$ and it seemed to easy so I suspect I must be missing something. Would someone please check my answer? My original answer: $e^{e^z}=1$ if and only if $e^z = 2\pi i k$ for $k\in \mathbb Z$ if and only if $z=\ln(2\pi i k)$ for $k\in \mathbb Z$. Edit After reading the comments and answers I tried to do it again. Unfortunately, I still do not get the same result as in the answers. My second attempt: We have $$ e^x = 1 \iff x = 2 \pi i k$$ hence $$ e^z = 2 \pi i k$$ for some $k$ in $\mathbb Z$. Letting $e^z = e^x (\cos y + i \sin y)$ we get $$ e^x \cos y + i e^x \sin y = 2 \pi k i$$ which implies that $\cos y = 0$ which happens if and only if $y_j = {\pi \over 2} + \pi j$ where $j\in \mathbb Z$. At $y_j$ we have $\sin y = \pm 1$ hence if $j$ is even $$ e^x = 2 \pi i k$$ and if $j$ is odd $$ e^x = -2 \pi i k$$ Hence if $j$ is even, $$ x = {\pi \over 2} + \ln(2 \pi k)$$ and if $j$ is odd, $$ x = {3\pi \over 2} + \ln(2 \pi k)$$ So we see that the solutions are $$ z_{t,k}=\begin{cases}  {\pi \over 2} + \ln(2 \pi k) + i ({\pi \over 2} + 2t \pi )\\   {3\pi \over 2} + \ln(2 \pi k) + i({\pi \over 2} + (2 +1)t \pi ) \end{cases}  $$ for $k,t \in \mathbb Z$. What am I doing wrong?",,"['complex-analysis', 'proof-verification']"
47,$\bar{z}$ cannot be uniformly approximated by polynomials in $z$ on the closed unit disc in $\mathbb{C}$.,cannot be uniformly approximated by polynomials in  on the closed unit disc in .,\bar{z} z \mathbb{C},"In reference to this question, I tried to prove that $\bar{z}$ cannot be uniformly approximated by complex polynomials in $z$ on the closed unit disc $D$. I came up with a proof, but I'm not entirely sure whether it's correct. Here's how the proof goes: Assume it can be done. Pick an $\varepsilon < 0.1$ and then you'll have a polynomial $p$ such that $|p(z) - \bar{z}| < \varepsilon$ for all $z \in D$. Multiply both sides by $z$ to get: $$|zp(z) - z\bar{z}| < |z|\varepsilon$$ Now if we just look at the points where $|z| = 1$, the inequation becomes: $$|zp(z) - 1| < \varepsilon$$ Now I'll show on some point on the unit circle $C$, $zp(z)$ has a non-positive real part, which will lead to a contradiction because then $|zp(z) - 1| > 1 > \varepsilon$. Notice that $zp(z)$ is of the form: $$zp(z) = a_nz^n + \cdots + a_1z$$ Pick $2(n!)$ points on the circle such that the angle between two adjacent points is $\frac{\pi}{n!}$. The sum of $zp(z)$ over these points will be $0$. Here's why: For each point, there exists a point $\pi$ radians away, so the $z$ term in $zp(z)$ goes to $0$. Similarly, the $z^2$, $z^3$ and so on terms also add up to $0$ hence the polynomial adds up to $0$. Which means at one of those points, the real part of $zp(z) \leq 0$. This leads to the contradiction mentioned above and completes the proof. Is this proof correct? And if it is correct, this only works for sets containing a neighbourhood of $0$. But you'd expect a proof a global property (i.e. uniform approximation) to not depend on any local properties (i.e. a neighbourhood of $0$). It'd be nice if someone could explain how to extend this proof to any compact set in $\mathbb{C}$.","In reference to this question, I tried to prove that $\bar{z}$ cannot be uniformly approximated by complex polynomials in $z$ on the closed unit disc $D$. I came up with a proof, but I'm not entirely sure whether it's correct. Here's how the proof goes: Assume it can be done. Pick an $\varepsilon < 0.1$ and then you'll have a polynomial $p$ such that $|p(z) - \bar{z}| < \varepsilon$ for all $z \in D$. Multiply both sides by $z$ to get: $$|zp(z) - z\bar{z}| < |z|\varepsilon$$ Now if we just look at the points where $|z| = 1$, the inequation becomes: $$|zp(z) - 1| < \varepsilon$$ Now I'll show on some point on the unit circle $C$, $zp(z)$ has a non-positive real part, which will lead to a contradiction because then $|zp(z) - 1| > 1 > \varepsilon$. Notice that $zp(z)$ is of the form: $$zp(z) = a_nz^n + \cdots + a_1z$$ Pick $2(n!)$ points on the circle such that the angle between two adjacent points is $\frac{\pi}{n!}$. The sum of $zp(z)$ over these points will be $0$. Here's why: For each point, there exists a point $\pi$ radians away, so the $z$ term in $zp(z)$ goes to $0$. Similarly, the $z^2$, $z^3$ and so on terms also add up to $0$ hence the polynomial adds up to $0$. Which means at one of those points, the real part of $zp(z) \leq 0$. This leads to the contradiction mentioned above and completes the proof. Is this proof correct? And if it is correct, this only works for sets containing a neighbourhood of $0$. But you'd expect a proof a global property (i.e. uniform approximation) to not depend on any local properties (i.e. a neighbourhood of $0$). It'd be nice if someone could explain how to extend this proof to any compact set in $\mathbb{C}$.",,"['complex-analysis', 'weierstrass-approximation']"
48,prove conjecture; the limit of iterating is $\sqrt{z^2 - 2}$,prove conjecture; the limit of iterating is,\sqrt{z^2 - 2},"$$\lim_{n \to \infty} f_n(x)=x-\frac{1}{nx}\;\;\; g(x)=f_n^{on}(x)$$ The conjecture is for values of $|x|>\sqrt{2}$: $g(x) = \sqrt{z^2 - 2}$ This question comes from another matstack question/answer . If $n=2^m$, then convergence is much quicker by starting with $f_n(x)=x-\frac{1}{nx}$ and then iterating the Taylor/Laurent series for $f(x) \mapsto f(f(x))$ m times.  I start by generating the formal Taylor series after moving the fixed point from infinity to zero, $1/f(\frac{1}{x})\;$.  Then we start iterating with $f_n$ $$f_n(x) = \frac{x}{1 - x^2/n} =  x + \frac{x^3}{n} + \frac{x^5}{n^2} + \frac{x^7}{n^3} + \frac{x^9}{n^4} + \frac{x^{11}}{n^5} ...$$ Using this speedup with $m=\log_2(n)$, one can iterate the Taylor series for $f(x) \mapsto f(f(x))$ m times, rather then iterating $f^{on}$, but the two are of course identical.  Its just that otherwise convergence is pretty slow, with n iterations to get accuracy to 1/n. The formal Taylor series coefficients of $1/g(\frac{1}{x}) = \sqrt{z^2/(1-2z^2)}$ are: $x + x^3 + \frac{3        x^5    }{2     } + \frac{5        x^7    }{2     } + \frac{35       x^9    }{8     } + \frac{63       x^{11} }{8     } + \frac{231      x^{13} }{16    } + \frac{429      x^{15} }{16    } + \frac{6435     x^{17} }{128   } + \frac{12155    x^{19} }{128   } + \frac{46189    x^{21} }{256   } ...$ Empirically, for the $2^n$th iteration starting with $f_n$ in the limit above, the Taylor coefficients are accurate to approximately $O 2^{-n}$, so there is pretty good numerical computation evidence for the conjecture, but I have no idea how to prove it. EDIT I ( https://math.stackexchange.com/users/39261/mick ) will place a bounty for the following problem : Basicly the inverse : Suppose we are given $g(x)=\sqrt{x^2-2}$ and we are asked to find $f_n$ such that : $$\lim_{n \to \infty} \;\;\; g(x)=f_n^{on}(x)$$ How do we solve such problems ?? EDIT EDIT 2 As Sheldon's comment says $f_n(x)=\sqrt{x^2-\frac{2}{n}}$ is also a solution but I want to find the $f_n$ from the OP : $x - \frac{1}{nx}$ or another $f_n$ that is real-meromorphic on the entire complex plane. EDIT 2","$$\lim_{n \to \infty} f_n(x)=x-\frac{1}{nx}\;\;\; g(x)=f_n^{on}(x)$$ The conjecture is for values of $|x|>\sqrt{2}$: $g(x) = \sqrt{z^2 - 2}$ This question comes from another matstack question/answer . If $n=2^m$, then convergence is much quicker by starting with $f_n(x)=x-\frac{1}{nx}$ and then iterating the Taylor/Laurent series for $f(x) \mapsto f(f(x))$ m times.  I start by generating the formal Taylor series after moving the fixed point from infinity to zero, $1/f(\frac{1}{x})\;$.  Then we start iterating with $f_n$ $$f_n(x) = \frac{x}{1 - x^2/n} =  x + \frac{x^3}{n} + \frac{x^5}{n^2} + \frac{x^7}{n^3} + \frac{x^9}{n^4} + \frac{x^{11}}{n^5} ...$$ Using this speedup with $m=\log_2(n)$, one can iterate the Taylor series for $f(x) \mapsto f(f(x))$ m times, rather then iterating $f^{on}$, but the two are of course identical.  Its just that otherwise convergence is pretty slow, with n iterations to get accuracy to 1/n. The formal Taylor series coefficients of $1/g(\frac{1}{x}) = \sqrt{z^2/(1-2z^2)}$ are: $x + x^3 + \frac{3        x^5    }{2     } + \frac{5        x^7    }{2     } + \frac{35       x^9    }{8     } + \frac{63       x^{11} }{8     } + \frac{231      x^{13} }{16    } + \frac{429      x^{15} }{16    } + \frac{6435     x^{17} }{128   } + \frac{12155    x^{19} }{128   } + \frac{46189    x^{21} }{256   } ...$ Empirically, for the $2^n$th iteration starting with $f_n$ in the limit above, the Taylor coefficients are accurate to approximately $O 2^{-n}$, so there is pretty good numerical computation evidence for the conjecture, but I have no idea how to prove it. EDIT I ( https://math.stackexchange.com/users/39261/mick ) will place a bounty for the following problem : Basicly the inverse : Suppose we are given $g(x)=\sqrt{x^2-2}$ and we are asked to find $f_n$ such that : $$\lim_{n \to \infty} \;\;\; g(x)=f_n^{on}(x)$$ How do we solve such problems ?? EDIT EDIT 2 As Sheldon's comment says $f_n(x)=\sqrt{x^2-\frac{2}{n}}$ is also a solution but I want to find the $f_n$ from the OP : $x - \frac{1}{nx}$ or another $f_n$ that is real-meromorphic on the entire complex plane. EDIT 2",,"['complex-analysis', 'dynamical-systems', 'complex-dynamics']"
49,Representation of Dirac Delta Function in complex plane,Representation of Dirac Delta Function in complex plane,,I am stuck on a representation of the Dirac Delta function that is used in several books I am reading. They state: $\begin{equation} \delta^{(2)} = \frac{1}{2\pi} \partial_{\bar{z}} \frac{1}{z} = \frac{1}{2\pi} \partial_{z} \frac{1}{\bar{z}}. \end{equation} $ They all either do not give a proof or I am not understanding the short motivations they give for this. Does anyone know how to understand this? Do you have some references where I can read on this? Help is greatly appreciated.,I am stuck on a representation of the Dirac Delta function that is used in several books I am reading. They state: $\begin{equation} \delta^{(2)} = \frac{1}{2\pi} \partial_{\bar{z}} \frac{1}{z} = \frac{1}{2\pi} \partial_{z} \frac{1}{\bar{z}}. \end{equation} $ They all either do not give a proof or I am not understanding the short motivations they give for this. Does anyone know how to understand this? Do you have some references where I can read on this? Help is greatly appreciated.,,"['complex-analysis', 'dirac-delta']"
50,Proving that a Function is Analytic Given that it is Equal to the Complex Conjugate of an analytic Function,Proving that a Function is Analytic Given that it is Equal to the Complex Conjugate of an analytic Function,,"So I'm working a problem that states: A function $f$ is analytic in an open set $U$. Define $g$ by $g(z)=\overline{f(\overline{z})}$ (just because the notation can be hard to read, this is the the complex conjugate of the function $f$ defined at the complex conjugate of $z$). Show that $g$ is analytic in the oopen set $U^{\star}=\{z:\overline{z}\in{U}\}$ and that $g^{\prime}(z)=\overline{f^{\prime}(\overline{z})}$ (this is the complex conjugate of the derivative of $f$ evaluated at the complex conjugate of $z$) for $z\in{U^{\star}}$ Now, my book gives the definition of an analytic function as one that is a function defined over an open set on which it is differentiable at every point of that set and that every derivative of that function satisfying the preceeding properties has derivatives that are analytic on that domain as well. So, I know that being differentiable at a point means that a function is continuous at that point, so I see straight away that this means $\forall{\epsilon}>0$ there exists a $\delta>0$ such that if $|z-z_0|<\delta$ then $|f(z)-f(z_0)|<\epsilon$. Since $U$ is an open set, it follows that $U\cap{z_0}$ is non-empty. Because $f$ is analytic in $U$, I can choose two elements $z$ and $z_0$ of $U$ that satisfy $|z-z_0|=|\overline{z}-\overline{z_0}|<\delta$ and  $|f(z)-f(z_0)|<\epsilon$. Since $|\overline{z}-\overline{z_0}|<\delta$, this means that $|f(\overline{z})-f(\overline{z_0})|<\epsilon$. Observing that $|f(\overline{z})-f(\overline{z_0})|=|\overline{f(\overline{z})-f(\overline{z_0})}|$, I conclude that $\overline{f(\overline{z})}$ is continuous. This being the case, then (and I think I've done this part correct) I can compute the derivative by using the limit definition as: $g'(z)=\lim\limits_{h\rightarrow{0}}\frac{\overline{f(\overline{z}+\overline{h})}-\overline{f(\overline{z})}}{h}=\lim\limits_{\overline{h}\rightarrow{0}}\overline{({f(\overline{z}+\overline{h})-f(\overline{z})})\ \  /\ \ {\overline{h}}}$, as I know that as $h\rightarrow{0}$, so does $\overline{h}\rightarrow{0}$. Since the function $f$ is analytic for all complex numbers in $U$, its derivative there, as given above, is the complex conjugate of the limit which is $\overline{f'(\overline{z})}$. That's what I'm concerned about, however, because I haven't actually shown yet that $\overline{f(\overline{z})}$ is, in fact, analytic on its domain, all I know is that it is continuous on its domain. My thought is that it might only be analytic for the set $U$ if $U$ is a subset of the real numbers, since that is the only place that $\overline{z}$ is analytic and thus the composition $(a\circ{b})(z)$ for $b(z)=f(\overline{z})$ (analytic for $\overline{z}\in{U}$) and $a(z)=\overline{z}$, so the composition would be analytic on the set given by the intersection of the real numbers with $U$ but I don't believe that is right? I've tried considering an equivalent case given by the conjugation $\overline{g(z)}=\overline{\overline{f(\overline{z})}}=f(\overline{z})$ to no avail. Essentially, I'm asking to see if anyone can point me in the right direction and tell me if what I've done so far is on the right track. I should add that these problems are from a section in the book preceeding the discussion about the Cauchy-Riemann Equations, so while I'm not sure if they will help, I don't want to use them. I'm tagging this as homework although it's not 'homework' in the sense that I'm taking a class, but the problem is from a book, so I feel it is appropriate to tag it as such. I invite any admins to remove the tag if they feel it is unnecessary.","So I'm working a problem that states: A function $f$ is analytic in an open set $U$. Define $g$ by $g(z)=\overline{f(\overline{z})}$ (just because the notation can be hard to read, this is the the complex conjugate of the function $f$ defined at the complex conjugate of $z$). Show that $g$ is analytic in the oopen set $U^{\star}=\{z:\overline{z}\in{U}\}$ and that $g^{\prime}(z)=\overline{f^{\prime}(\overline{z})}$ (this is the complex conjugate of the derivative of $f$ evaluated at the complex conjugate of $z$) for $z\in{U^{\star}}$ Now, my book gives the definition of an analytic function as one that is a function defined over an open set on which it is differentiable at every point of that set and that every derivative of that function satisfying the preceeding properties has derivatives that are analytic on that domain as well. So, I know that being differentiable at a point means that a function is continuous at that point, so I see straight away that this means $\forall{\epsilon}>0$ there exists a $\delta>0$ such that if $|z-z_0|<\delta$ then $|f(z)-f(z_0)|<\epsilon$. Since $U$ is an open set, it follows that $U\cap{z_0}$ is non-empty. Because $f$ is analytic in $U$, I can choose two elements $z$ and $z_0$ of $U$ that satisfy $|z-z_0|=|\overline{z}-\overline{z_0}|<\delta$ and  $|f(z)-f(z_0)|<\epsilon$. Since $|\overline{z}-\overline{z_0}|<\delta$, this means that $|f(\overline{z})-f(\overline{z_0})|<\epsilon$. Observing that $|f(\overline{z})-f(\overline{z_0})|=|\overline{f(\overline{z})-f(\overline{z_0})}|$, I conclude that $\overline{f(\overline{z})}$ is continuous. This being the case, then (and I think I've done this part correct) I can compute the derivative by using the limit definition as: $g'(z)=\lim\limits_{h\rightarrow{0}}\frac{\overline{f(\overline{z}+\overline{h})}-\overline{f(\overline{z})}}{h}=\lim\limits_{\overline{h}\rightarrow{0}}\overline{({f(\overline{z}+\overline{h})-f(\overline{z})})\ \  /\ \ {\overline{h}}}$, as I know that as $h\rightarrow{0}$, so does $\overline{h}\rightarrow{0}$. Since the function $f$ is analytic for all complex numbers in $U$, its derivative there, as given above, is the complex conjugate of the limit which is $\overline{f'(\overline{z})}$. That's what I'm concerned about, however, because I haven't actually shown yet that $\overline{f(\overline{z})}$ is, in fact, analytic on its domain, all I know is that it is continuous on its domain. My thought is that it might only be analytic for the set $U$ if $U$ is a subset of the real numbers, since that is the only place that $\overline{z}$ is analytic and thus the composition $(a\circ{b})(z)$ for $b(z)=f(\overline{z})$ (analytic for $\overline{z}\in{U}$) and $a(z)=\overline{z}$, so the composition would be analytic on the set given by the intersection of the real numbers with $U$ but I don't believe that is right? I've tried considering an equivalent case given by the conjugation $\overline{g(z)}=\overline{\overline{f(\overline{z})}}=f(\overline{z})$ to no avail. Essentially, I'm asking to see if anyone can point me in the right direction and tell me if what I've done so far is on the right track. I should add that these problems are from a section in the book preceeding the discussion about the Cauchy-Riemann Equations, so while I'm not sure if they will help, I don't want to use them. I'm tagging this as homework although it's not 'homework' in the sense that I'm taking a class, but the problem is from a book, so I feel it is appropriate to tag it as such. I invite any admins to remove the tag if they feel it is unnecessary.",,"['complex-analysis', 'analysis']"
51,Find $\displaystyle \sum_{k=1}^{\infty}\frac{1}{z_k^2}$,Find,\displaystyle \sum_{k=1}^{\infty}\frac{1}{z_k^2},"Let $z_1, z_2,\dots, z_k,\dots$ be all the roots of $e^z=z$ . Let $C_N$ be the square in the plane centered at the origin with siden parallel to the axis and each of length $2\pi N$ . Assume that $$\lim_{N\to \infty} \int\limits_{\displaystyle C_N}\frac{e^z-1}{z^2(e^z-z)}dz=0$$ Find $$\sum_{k=1}^{\infty}\frac{1}{z_k^2}$$ My solution attempt is too trivial. So I didn't write it here. Please, solve the question more explicitly. Thank you.","Let be all the roots of . Let be the square in the plane centered at the origin with siden parallel to the axis and each of length . Assume that Find My solution attempt is too trivial. So I didn't write it here. Please, solve the question more explicitly. Thank you.","z_1, z_2,\dots, z_k,\dots e^z=z C_N 2\pi N \lim_{N\to \infty} \int\limits_{\displaystyle C_N}\frac{e^z-1}{z^2(e^z-z)}dz=0 \sum_{k=1}^{\infty}\frac{1}{z_k^2}","['complex-analysis', 'analysis', 'self-learning']"
52,(solution verification) the series $\sum z^{n!}$ has the unit circle as a natural boundary,(solution verification) the series  has the unit circle as a natural boundary,\sum z^{n!},"I've tried to solve the following problem from Ahlfors' complex analysis text: If a function element $(f,\Omega)$ has no direct analytic continuations other than the ones obtained by restricting $f$ to a smaller region, then the boundary of $\Omega$ is called a natural boundary for $f$. Prove that the series   $\sum_{n=0}^\infty z^{n!}$ has the unit circle as a natural boundary. Hint: Show that the function tends to infinity on every radius whose argument is a rational multiple of $\pi$. My attempt: Let $q \in \mathbb Q$ be a rational number, with reduced form $a/b$ where $a \in \mathbb Z,b \in \mathbb N$. For $r<1$ we have $$f\left(r e^{i q \pi}\right)=\sum_{n=0}^\infty r^{n!} e^{i q n! \pi}= \sum_{n=0}^{b+1} r^{n!} e^{i q n! \pi}+\sum_{n=b+2}^\infty r^{n!} e^{i \frac{a}{b} n! \pi}  $$ In the last sum we have $e^{i \frac{a}{b} n! \pi}=1$ for $n \geq b+2$, since the exponent is an even multiple of $\pi i$. Thus using the reverse triangle inequality $$\left|f \left( r e^{i q \pi} \right) \right|=\left|\sum_{n=0}^{b+1} r^{n!} e^{i q n! \pi}+\sum_{n=b+2}^\infty r^{n!} \right| \geq \left| \sum_{n=b+2}^\infty r^{n!}- \left| \sum_{n=0}^{b+1} r^{n!} e^{i q n! \pi} \right| \right|.$$ Taking $r$ sufficiently close to $1$ the series $\sum_{n=b+2}^\infty r^{n!}$ can be made arbitrarily large. Indeed, if $r \geq \sqrt[N!]{1/2}$ with $N$ large the series contains at least $N-b-1$ terms which are $\geq 1/2$. It follows that for $r$ sufficiently close to $1$ the sum $\sum_{n=b+2}^\infty r^{n!}$ can be made larger than  $$M:= \max_{r \in [0,1]} \left|  \sum_{n=0}^{b+1} r^{n!} e^{i q n! \pi} \right|<\infty ,$$ making the external absolute value redundant. For all such sufficiently close numbers $r$ we have $$\left| f \left( r e^{i q \pi} \right) \right| \geq \sum_{n=b+2}^\infty r^{n!}-M $$ which tends to $\infty$ as $r \to 1^-$. Since $\left\{ e^{i q \pi} : q \in \mathbb Q \right\}$ is a dense subset of the unit circle the above prevents the existence of direct analytic continuation by function elements $(g,\Omega')$, unless $\Omega' \subseteq \Omega$. This is true since if $\Omega'$ leaves $\Omega$ it must contain a boundary point whose corresponding radius has an argument which is a rational multiple of $\pi$. Since $f=g$ on $\Omega \cap \Omega'$ it follows that $g$ has infinity as the radial limit towards that boundary point - which contradicts the analyticity of $g$ there. Is the above correct? If not please help me fix it. Thanks!","I've tried to solve the following problem from Ahlfors' complex analysis text: If a function element $(f,\Omega)$ has no direct analytic continuations other than the ones obtained by restricting $f$ to a smaller region, then the boundary of $\Omega$ is called a natural boundary for $f$. Prove that the series   $\sum_{n=0}^\infty z^{n!}$ has the unit circle as a natural boundary. Hint: Show that the function tends to infinity on every radius whose argument is a rational multiple of $\pi$. My attempt: Let $q \in \mathbb Q$ be a rational number, with reduced form $a/b$ where $a \in \mathbb Z,b \in \mathbb N$. For $r<1$ we have $$f\left(r e^{i q \pi}\right)=\sum_{n=0}^\infty r^{n!} e^{i q n! \pi}= \sum_{n=0}^{b+1} r^{n!} e^{i q n! \pi}+\sum_{n=b+2}^\infty r^{n!} e^{i \frac{a}{b} n! \pi}  $$ In the last sum we have $e^{i \frac{a}{b} n! \pi}=1$ for $n \geq b+2$, since the exponent is an even multiple of $\pi i$. Thus using the reverse triangle inequality $$\left|f \left( r e^{i q \pi} \right) \right|=\left|\sum_{n=0}^{b+1} r^{n!} e^{i q n! \pi}+\sum_{n=b+2}^\infty r^{n!} \right| \geq \left| \sum_{n=b+2}^\infty r^{n!}- \left| \sum_{n=0}^{b+1} r^{n!} e^{i q n! \pi} \right| \right|.$$ Taking $r$ sufficiently close to $1$ the series $\sum_{n=b+2}^\infty r^{n!}$ can be made arbitrarily large. Indeed, if $r \geq \sqrt[N!]{1/2}$ with $N$ large the series contains at least $N-b-1$ terms which are $\geq 1/2$. It follows that for $r$ sufficiently close to $1$ the sum $\sum_{n=b+2}^\infty r^{n!}$ can be made larger than  $$M:= \max_{r \in [0,1]} \left|  \sum_{n=0}^{b+1} r^{n!} e^{i q n! \pi} \right|<\infty ,$$ making the external absolute value redundant. For all such sufficiently close numbers $r$ we have $$\left| f \left( r e^{i q \pi} \right) \right| \geq \sum_{n=b+2}^\infty r^{n!}-M $$ which tends to $\infty$ as $r \to 1^-$. Since $\left\{ e^{i q \pi} : q \in \mathbb Q \right\}$ is a dense subset of the unit circle the above prevents the existence of direct analytic continuation by function elements $(g,\Omega')$, unless $\Omega' \subseteq \Omega$. This is true since if $\Omega'$ leaves $\Omega$ it must contain a boundary point whose corresponding radius has an argument which is a rational multiple of $\pi$. Since $f=g$ on $\Omega \cap \Omega'$ it follows that $g$ has infinity as the radial limit towards that boundary point - which contradicts the analyticity of $g$ there. Is the above correct? If not please help me fix it. Thanks!",,"['complex-analysis', 'analyticity']"
53,To calculate residue of the function $f(z) = \frac{z^2 + \sin z}{\cos z - 1}$.,To calculate residue of the function .,f(z) = \frac{z^2 + \sin z}{\cos z - 1},"I was trying to find the residue of the function $$f(z) = \frac{z^2 + \sin z}{\cos z - 1}.$$ Here is the my attempt: The given function has a pole of order two at $z = 2n\pi$. So, we use the following formula to calculate residue of a function when it has a pole of order m at $z=z_0$. $$\mathrm{Res}(f(z))_{z=z_0}=\frac{1}{(m-1)!}\lim_{z\to z_0}\left[\frac{d^{m-1}}{dz^{m-1}}(z-z_0)^m f(z)\right]$$ But I am not able to apply this formula as I am getting zero in the denominator while I am taking limit $z\to 2n\pi$. Any help or suggestions will be very helpful for me. Thanks","I was trying to find the residue of the function $$f(z) = \frac{z^2 + \sin z}{\cos z - 1}.$$ Here is the my attempt: The given function has a pole of order two at $z = 2n\pi$. So, we use the following formula to calculate residue of a function when it has a pole of order m at $z=z_0$. $$\mathrm{Res}(f(z))_{z=z_0}=\frac{1}{(m-1)!}\lim_{z\to z_0}\left[\frac{d^{m-1}}{dz^{m-1}}(z-z_0)^m f(z)\right]$$ But I am not able to apply this formula as I am getting zero in the denominator while I am taking limit $z\to 2n\pi$. Any help or suggestions will be very helpful for me. Thanks",,"['complex-analysis', 'limits', 'complex-numbers', 'residue-calculus', 'complex-integration']"
54,"Complex analysis : If $z =re^{i\theta}$, then prove that $|e^{iz}| =e^{-r\sin\theta}$","Complex analysis : If , then prove that",z =re^{i\theta} |e^{iz}| =e^{-r\sin\theta},"Problem : If $z =re^{i\theta}$, then prove that $|e^{iz} | =e^{-r\sin\theta}$ My working : $z = re^{i\theta} = r(\cos\theta + i\sin\theta)$ $\Rightarrow iz = ir(\cos\theta +\sin\theta) $ = $-r\sin\theta +ir\cos\theta $ $\Rightarrow e^{iz} =e^{(-r\sin\theta +ir\cos\theta)} = e^{-\sin\theta} e^{ir\cos\theta} $ $\Rightarrow |e^{iz}| = |e^{-r\sin\theta}||e^{ri\cos\theta}|$ Now please guide how to proceed further to get the result... thanks.","Problem : If $z =re^{i\theta}$, then prove that $|e^{iz} | =e^{-r\sin\theta}$ My working : $z = re^{i\theta} = r(\cos\theta + i\sin\theta)$ $\Rightarrow iz = ir(\cos\theta +\sin\theta) $ = $-r\sin\theta +ir\cos\theta $ $\Rightarrow e^{iz} =e^{(-r\sin\theta +ir\cos\theta)} = e^{-\sin\theta} e^{ir\cos\theta} $ $\Rightarrow |e^{iz}| = |e^{-r\sin\theta}||e^{ri\cos\theta}|$ Now please guide how to proceed further to get the result... thanks.",,"['complex-analysis', 'complex-numbers']"
55,Harmonic function on an annulus,Harmonic function on an annulus,,"I have stumbled across the following fact in complex analysis and I was trying to prove it, but didn't get anywhere: Let $R=\{r<|z|<R\}\subset\mathbb{C}$ where $0<r<R<\infty$ be an annulus in the complex plane and $u$ a harmonic function on $R$. Then there exists a constant $C\in\mathbb{R}$ and a holomorphic function $f$ on $R$ such that $$u(z)=\mathrm{Re}f(z)+C\log|z|$$ The problem arises because $R$ is not simply connected (on simply connected domains this is clearly true for $C=0$ by the CR equations). I just don't see where that $\log$ should come from. Can somebody help me and provide an easy proof? Any potentially useful approaches/hints are welcome.","I have stumbled across the following fact in complex analysis and I was trying to prove it, but didn't get anywhere: Let $R=\{r<|z|<R\}\subset\mathbb{C}$ where $0<r<R<\infty$ be an annulus in the complex plane and $u$ a harmonic function on $R$. Then there exists a constant $C\in\mathbb{R}$ and a holomorphic function $f$ on $R$ such that $$u(z)=\mathrm{Re}f(z)+C\log|z|$$ The problem arises because $R$ is not simply connected (on simply connected domains this is clearly true for $C=0$ by the CR equations). I just don't see where that $\log$ should come from. Can somebody help me and provide an easy proof? Any potentially useful approaches/hints are welcome.",,['complex-analysis']
56,Behavior of $|\Gamma(z)|$ as $\text{Im} (z) \to \pm \infty$,Behavior of  as,|\Gamma(z)| \text{Im} (z) \to \pm \infty,"Let $\Gamma(z)$ be the gamma function. In a paper I'm reading, the author states that $$ |\Gamma(z)| = |\Gamma(a+ib)|  \sim \sqrt{2 \pi} |b|^{a-\frac{1}{2}} e^{-|b|\frac{\pi}{2}}$$ as $|b| \to \infty$ . Can this asymptotic behavior be derived from Stirling's formula? EDIT : I think I have something. Assume that $a,b >0$ and that $b$ is very large. Then it would seem that $$ \begin{align}|\Gamma(a+ib)|  &\sim \left|\sqrt{\frac{2 \pi}{a+ib}} \Big(\frac{a+ib}{e}\Big)^{a+ib} \right| \\ &= \sqrt{2 \pi}  \left|(a+ib)^{a-\frac{1}{2}} \right| \left| (a+ib)^{ib} \right| \left|e^{-a-ib} \right| \\ &= \sqrt{2 \pi} \left(\sqrt{a^{2}+b^{2}} \right)^{a- \frac{1}{2}} \ \left|\left(\sqrt{a^{2}+b^{2}} e^{i \arg \left(\frac{b}{a}\right)} \right)^{ib} \right| e^{-a} \\ &= \sqrt{2 \pi} \left(\sqrt{a^{2}+b^{2}} \right)^{a- \frac{1}{2}} e^{-b \arg \left(\frac{b}{a} \right)} e^{-a} \\   &\sim \sqrt{2 \pi} \, b^{a - \frac{1}{2}} e^{-b \frac{\pi}{2}} {\color{red}{e^{-a}}}. \end{align}$$ But apparently this is not quite correct.","Let be the gamma function. In a paper I'm reading, the author states that as . Can this asymptotic behavior be derived from Stirling's formula? EDIT : I think I have something. Assume that and that is very large. Then it would seem that But apparently this is not quite correct.","\Gamma(z)  |\Gamma(z)| = |\Gamma(a+ib)|  \sim \sqrt{2 \pi} |b|^{a-\frac{1}{2}} e^{-|b|\frac{\pi}{2}} |b| \to \infty a,b >0 b  \begin{align}|\Gamma(a+ib)|  &\sim \left|\sqrt{\frac{2 \pi}{a+ib}} \Big(\frac{a+ib}{e}\Big)^{a+ib} \right| \\ &= \sqrt{2 \pi}  \left|(a+ib)^{a-\frac{1}{2}} \right| \left| (a+ib)^{ib} \right| \left|e^{-a-ib} \right| \\ &= \sqrt{2 \pi} \left(\sqrt{a^{2}+b^{2}} \right)^{a- \frac{1}{2}} \ \left|\left(\sqrt{a^{2}+b^{2}} e^{i \arg \left(\frac{b}{a}\right)} \right)^{ib} \right| e^{-a} \\ &= \sqrt{2 \pi} \left(\sqrt{a^{2}+b^{2}} \right)^{a- \frac{1}{2}} e^{-b \arg \left(\frac{b}{a} \right)} e^{-a} \\   &\sim \sqrt{2 \pi} \, b^{a - \frac{1}{2}} e^{-b \frac{\pi}{2}} {\color{red}{e^{-a}}}. \end{align}","['complex-analysis', 'asymptotics', 'gamma-function']"
57,Application of Runge's theorem,Application of Runge's theorem,,"Runge's theorem states: Let $K$ be a compact subset of $\mathbb C$ and let $S\subset \overline{\mathbb C}\setminus K$, such that $S$ contains at least one   point in each connected component of $\overline{\mathbb C}\setminus K$. Then any function holomorphic in an open set containing $K$ can be   uniformly approximated by rational functions whose poles lie in $S$. I want to solve the following exercise: Prove that there is a sequence $\{p_k\}_{k=1}^\infty $ of polynomials   such that : $$\lim\limits_{k\rightarrow \infty }p_k(z)=\begin{cases}1 &,Re(z)>0\\0&,Re(z)=0\\-1&,Re(z)<0\end{cases}$$ I think we should find a sequence of holomorphic functions which converges to the desired function, and then approximate each function in the sequence by a polynomial ( which was its poles at $\infty $ , therefore Runge's theorem applies) . Any hints would be appreciated. Maybe try something else?","Runge's theorem states: Let $K$ be a compact subset of $\mathbb C$ and let $S\subset \overline{\mathbb C}\setminus K$, such that $S$ contains at least one   point in each connected component of $\overline{\mathbb C}\setminus K$. Then any function holomorphic in an open set containing $K$ can be   uniformly approximated by rational functions whose poles lie in $S$. I want to solve the following exercise: Prove that there is a sequence $\{p_k\}_{k=1}^\infty $ of polynomials   such that : $$\lim\limits_{k\rightarrow \infty }p_k(z)=\begin{cases}1 &,Re(z)>0\\0&,Re(z)=0\\-1&,Re(z)<0\end{cases}$$ I think we should find a sequence of holomorphic functions which converges to the desired function, and then approximate each function in the sequence by a polynomial ( which was its poles at $\infty $ , therefore Runge's theorem applies) . Any hints would be appreciated. Maybe try something else?",,"['complex-analysis', 'approximation', 'self-learning']"
58,"Prove if $|z| < 1$ and $ |w| < 1$, then $|1-zw^*| \neq 0$ and $| {{z-w} \over {1-zw^*}}| < 1$ [duplicate]","Prove if  and , then  and  [duplicate]",|z| < 1  |w| < 1 |1-zw^*| \neq 0 | {{z-w} \over {1-zw^*}}| < 1,"This question already has answers here : Show that $\left|\frac{\alpha - \beta}{1-\bar{\alpha}\beta}\right| < 1$ when $|\alpha|,|\beta| < 1$ (4 answers) Closed 5 years ago . Prove if $|z| < 1$ and  $ |w| < 1$, then $|1-zw^*| \neq 0$ and $| {{z-w} \over {1-zw^*}}| < 1$ Given that $|1-zw^*|^2 - |z-w|^2 = (1-|z|^2)(1-|w|^2)$ I think the first part can be proven by saying $|1-zw^*| = 0$ if and only if $zw^*$ = 1. And given the conditions that cannot be true. However I don't know if this part is right.","This question already has answers here : Show that $\left|\frac{\alpha - \beta}{1-\bar{\alpha}\beta}\right| < 1$ when $|\alpha|,|\beta| < 1$ (4 answers) Closed 5 years ago . Prove if $|z| < 1$ and  $ |w| < 1$, then $|1-zw^*| \neq 0$ and $| {{z-w} \over {1-zw^*}}| < 1$ Given that $|1-zw^*|^2 - |z-w|^2 = (1-|z|^2)(1-|w|^2)$ I think the first part can be proven by saying $|1-zw^*| = 0$ if and only if $zw^*$ = 1. And given the conditions that cannot be true. However I don't know if this part is right.",,"['complex-analysis', 'complex-numbers']"
59,Proving $f$ has at least one zero inside unit disk,Proving  has at least one zero inside unit disk,f,"Let $f$ be a non-constant and analytic on a neighborhood of closure of the unit disk such that $|f(z)|=\text{constant}$ for $|z|=1$. Prove $f$ has at least one zero inside unit disk. I thought of using Rouche's somehow. Using $f(z)-z$, and taking constant is less than $1$, I can actually conclude from Rouche's theorem that the equation $f(z)-z=0$ have a fixed point inside the unit disk. I am stuck for other constants greater than equals to one and exactly zero. I hope there should be a little trick I am missing here. It will be awesome to see if maximum principle can be applied to conclude the result.","Let $f$ be a non-constant and analytic on a neighborhood of closure of the unit disk such that $|f(z)|=\text{constant}$ for $|z|=1$. Prove $f$ has at least one zero inside unit disk. I thought of using Rouche's somehow. Using $f(z)-z$, and taking constant is less than $1$, I can actually conclude from Rouche's theorem that the equation $f(z)-z=0$ have a fixed point inside the unit disk. I am stuck for other constants greater than equals to one and exactly zero. I hope there should be a little trick I am missing here. It will be awesome to see if maximum principle can be applied to conclude the result.",,['complex-analysis']
60,Showing that infinite product $\prod{(1+\frac{i}{k})}$ diverges,Showing that infinite product  diverges,\prod{(1+\frac{i}{k})},"In Bak and Newman's Complex Analysis they ask to show that the infinite product $\prod_{k \ge 1}{(1+\frac{i}{k})}$ diverges (with $i$ being the imaginary unit). My intuition is that it does not diverge to $0$, but rather just kind of oscillates randomly around the origin for large partial products. However, I am having a hard time proving this. If I break it down into two products of $r$ and $e^{i\theta}$ this doesn't help, because $\theta \rightarrow 0$ pretty clearly, and then I do not get my desired result of perpetual rotation. The $r$ term, $\prod_{k \ge 1}{\sqrt{1+\frac{1}{k^2}}}$ is not very informative either. I guess I have two questions: is my assumption that it oscillates kind of randomly at $\infty$ incorrect? If it is correct, how might I go about showing that this is the behavior?","In Bak and Newman's Complex Analysis they ask to show that the infinite product $\prod_{k \ge 1}{(1+\frac{i}{k})}$ diverges (with $i$ being the imaginary unit). My intuition is that it does not diverge to $0$, but rather just kind of oscillates randomly around the origin for large partial products. However, I am having a hard time proving this. If I break it down into two products of $r$ and $e^{i\theta}$ this doesn't help, because $\theta \rightarrow 0$ pretty clearly, and then I do not get my desired result of perpetual rotation. The $r$ term, $\prod_{k \ge 1}{\sqrt{1+\frac{1}{k^2}}}$ is not very informative either. I guess I have two questions: is my assumption that it oscillates kind of randomly at $\infty$ incorrect? If it is correct, how might I go about showing that this is the behavior?",,"['complex-analysis', 'elementary-number-theory', 'infinite-product']"
61,Conformal mapping from triangle to upper half plane in terms of Weierstrass $\wp$,Conformal mapping from triangle to upper half plane in terms of Weierstrass,\wp,"I'm trying to explicitly compute a conformal map $f:\Delta \rightarrow \mathbb{H}$ where $\Delta$ is a triangle and $\mathbb{H}$ is the upper half plane, in terms of the Weierstrass $\wp$ function. I know that the function should be the inverse of a Schwarz triangle function, and there should be a relation to $\wp$ by elliptic integrals, but I'm a bit lost as to finding one explicitly. For example, how would one go about for finding such a map for the triangle with vertices, say, $(0,i,1)$? Examples or suggestions would be greatly appreciated! Wolfram gives an explicit function for another triangle here: http://functions.wolfram.com/EllipticFunctions/WeierstrassPPrime/31/01/ , but I'd like to how how they computed it.","I'm trying to explicitly compute a conformal map $f:\Delta \rightarrow \mathbb{H}$ where $\Delta$ is a triangle and $\mathbb{H}$ is the upper half plane, in terms of the Weierstrass $\wp$ function. I know that the function should be the inverse of a Schwarz triangle function, and there should be a relation to $\wp$ by elliptic integrals, but I'm a bit lost as to finding one explicitly. For example, how would one go about for finding such a map for the triangle with vertices, say, $(0,i,1)$? Examples or suggestions would be greatly appreciated! Wolfram gives an explicit function for another triangle here: http://functions.wolfram.com/EllipticFunctions/WeierstrassPPrime/31/01/ , but I'd like to how how they computed it.",,"['complex-analysis', 'special-functions', 'elliptic-functions']"
62,Define square root function over the complex numbers.,Define square root function over the complex numbers.,,"Define a holomorphic function $f\colon\mathbb{C}\setminus[-1,1] \longrightarrow \mathbb{C}$ such that $\forall z \in \mathbb{C}\setminus[-1,1] \ \left( (f(z))^{2} = z^{2} - 1\right)$ and $f(2)=\sqrt{3}$.","Define a holomorphic function $f\colon\mathbb{C}\setminus[-1,1] \longrightarrow \mathbb{C}$ such that $\forall z \in \mathbb{C}\setminus[-1,1] \ \left( (f(z))^{2} = z^{2} - 1\right)$ and $f(2)=\sqrt{3}$.",,['complex-analysis']
63,Best possible approximation by holomorphic functions,Best possible approximation by holomorphic functions,,"Let $D$ denote the closed complex unit disk and let $f:D \rightarrow \mathbb C$ be any continuous function. Suppose we wish to approximate $f$ by a holomorphic function $g$ in the uniform metric: we seek to minimize $\sup\{z\in D : |g(z) - f(z)|\}$, subject to the condition that $g$ be holomorphic on the interior of the disk. The uniform limit of holomorphic functions is holomorphic, so this quantity cannot be zero if $f$ is not holomorphic. Is there any general result about how small it can be for some class of choices of $f$? In particular, how closely can we approximate the conjugate function $z \mapsto \bar z$ by a holomorphic function?","Let $D$ denote the closed complex unit disk and let $f:D \rightarrow \mathbb C$ be any continuous function. Suppose we wish to approximate $f$ by a holomorphic function $g$ in the uniform metric: we seek to minimize $\sup\{z\in D : |g(z) - f(z)|\}$, subject to the condition that $g$ be holomorphic on the interior of the disk. The uniform limit of holomorphic functions is holomorphic, so this quantity cannot be zero if $f$ is not holomorphic. Is there any general result about how small it can be for some class of choices of $f$? In particular, how closely can we approximate the conjugate function $z \mapsto \bar z$ by a holomorphic function?",,['complex-analysis']
64,Calculating the residues of $f(z)=\frac{e^{az}}{1+e^z}$,Calculating the residues of,f(z)=\frac{e^{az}}{1+e^z},"Let $$f(z)=\frac{e^{az}}{1+e^z}$$ where $0<a<1$ Can anyone help me find the residues of this function? So $$e^z+1=0 \Rightarrow z=i\pi(1+2k)$$ where $k\in \mathbb{Z}$, so these are simple poles (if someone could explain a simple way of showing this that'd be great, other than expansion) $$\lim_{z\rightarrow i\pi(1+2k)}\frac{(z-i\pi(1+2k))e^{az}}{1+e^z}=\lim_{z\rightarrow i\pi(1+2k)}\frac{a(z-i\pi(1+2k))e^{az}+e^{az}}{e^z}=e^a$$ So i'm trying to evaluate $\int_{\infty}^\infty f(z)$ you see, so will I need to pick a contour with fixed height otherwise the integral around the contour will be equal to $2\pi i \sum_{n=0}^\infty e^a$","Let $$f(z)=\frac{e^{az}}{1+e^z}$$ where $0<a<1$ Can anyone help me find the residues of this function? So $$e^z+1=0 \Rightarrow z=i\pi(1+2k)$$ where $k\in \mathbb{Z}$, so these are simple poles (if someone could explain a simple way of showing this that'd be great, other than expansion) $$\lim_{z\rightarrow i\pi(1+2k)}\frac{(z-i\pi(1+2k))e^{az}}{1+e^z}=\lim_{z\rightarrow i\pi(1+2k)}\frac{a(z-i\pi(1+2k))e^{az}+e^{az}}{e^z}=e^a$$ So i'm trying to evaluate $\int_{\infty}^\infty f(z)$ you see, so will I need to pick a contour with fixed height otherwise the integral around the contour will be equal to $2\pi i \sum_{n=0}^\infty e^a$",,"['complex-analysis', 'contour-integration']"
65,Complex Analysis and Algebra,Complex Analysis and Algebra,,"There are two results in Complex Analysis that have a counterpart in Algebra: -If we consider the ring of holomorphic functions in an open set $\mathcal H(U)$ with the usual sum and product, every finitely generated ideal is principal. In fact it is generated by any holomorphic function that vanishes exactly where the ideal $I$ and with the same multiplicitiy. This is the same as in $\mathbb C[X]$ (although here all the ideals are finitely generated), where every ideal is characterized by the zeroes and the multiplicities. -In several complex variables, a function which is holomorphic in $U\setminus\{p\}$ is holomorphic in $U$. If we restricted to rational functions $\displaystyle \frac{p(z)}{q(z)}$, this would be a corrolary from the fact that $q(z)=0$ has codimension $1$. Hence it can't be a point. My question is if it is a coincidence that in these two cases, holomorphic functions act somewhat similar to polynomials, or if it is an instance of a more general phenomenon?","There are two results in Complex Analysis that have a counterpart in Algebra: -If we consider the ring of holomorphic functions in an open set $\mathcal H(U)$ with the usual sum and product, every finitely generated ideal is principal. In fact it is generated by any holomorphic function that vanishes exactly where the ideal $I$ and with the same multiplicitiy. This is the same as in $\mathbb C[X]$ (although here all the ideals are finitely generated), where every ideal is characterized by the zeroes and the multiplicities. -In several complex variables, a function which is holomorphic in $U\setminus\{p\}$ is holomorphic in $U$. If we restricted to rational functions $\displaystyle \frac{p(z)}{q(z)}$, this would be a corrolary from the fact that $q(z)=0$ has codimension $1$. Hence it can't be a point. My question is if it is a coincidence that in these two cases, holomorphic functions act somewhat similar to polynomials, or if it is an instance of a more general phenomenon?",,"['complex-analysis', 'big-picture']"
66,"What does $\int_f f(z, \bar{z}) \sqrt{dz d\bar{z}}$ mean?",What does  mean?,"\int_f f(z, \bar{z}) \sqrt{dz d\bar{z}}","Just a quick question, I am going through some books on complex analysis and I'm wondering what an integral like $\int_f f(z,\bar{z}) \sqrt{dz d\bar{z}}$ means. How is one supposed to take that notation to mean something?? I have not come across things that have roots over the $dz's$ and $d\bar{z}'s$. Besides, the integral here is a single integral, but there are two variables involved? I am assuming I can do that as perhaps I can parametrise $f$ in terms of some parameter $t$. Thanks","Just a quick question, I am going through some books on complex analysis and I'm wondering what an integral like $\int_f f(z,\bar{z}) \sqrt{dz d\bar{z}}$ means. How is one supposed to take that notation to mean something?? I have not come across things that have roots over the $dz's$ and $d\bar{z}'s$. Besides, the integral here is a single integral, but there are two variables involved? I am assuming I can do that as perhaps I can parametrise $f$ in terms of some parameter $t$. Thanks",,[]
67,"Entire function bounded in every horizontal line, and has limit along the positive real line","Entire function bounded in every horizontal line, and has limit along the positive real line",,"Let $f(z)$ be an entire function (holomorphic function on $\mathbb{C}$ ) satifying the following condition: $$|f(z)|\leq \max (e^{\text{im}(z)},1 ),\ \forall z\in\mathbb{C}$$ $$\lim_{\mathbb{R}\ni t\rightarrow+\infty} f(t)=0$$ My question is: can we prove that the following limit exists? $$\lim_{\mathbb{R}\ni t\rightarrow-\infty} f(t)$$ Maybe we can even prove $f(z)=0$ . But I do not know how to prove it. My trying: if $f(z)$ has finitely many zeros, then by Hadamard factorization theorem, $f(x)=e^{az+b}P(z)$ where $P(z)$ is a polynomial. such a function can not be bounded by $\max(e^{\text{im}(z)},1)$ , unless $P(z)\in\mathbb{C}$ and $ia\in\mathbb{R}$ . Then we know $f(z)$ has to be $0$ . But if $f(z)=0$ has infinitely many solution, then I do not know how to proceed.","Let be an entire function (holomorphic function on ) satifying the following condition: My question is: can we prove that the following limit exists? Maybe we can even prove . But I do not know how to prove it. My trying: if has finitely many zeros, then by Hadamard factorization theorem, where is a polynomial. such a function can not be bounded by , unless and . Then we know has to be . But if has infinitely many solution, then I do not know how to proceed.","f(z) \mathbb{C} |f(z)|\leq \max (e^{\text{im}(z)},1 ),\ \forall z\in\mathbb{C} \lim_{\mathbb{R}\ni t\rightarrow+\infty} f(t)=0 \lim_{\mathbb{R}\ni t\rightarrow-\infty} f(t) f(z)=0 f(z) f(x)=e^{az+b}P(z) P(z) \max(e^{\text{im}(z)},1) P(z)\in\mathbb{C} ia\in\mathbb{R} f(z) 0 f(z)=0","['complex-analysis', 'harmonic-functions', 'entire-functions']"
68,An inequality of a complex polynomial,An inequality of a complex polynomial,,"Let $$P(z)=c_nz^n+...+c_1z+c_0$$ be a polynomial with complex coefficients, where $c_n\neq 0$ . For each $r>0$ , define $$M(r):=\sup_{|z|=r}|P(z)|.$$ Prove that for any $K>1$ , the following inequlity holds $$M(Kr)\le K^nM(r).$$ I believe a proper use of the Hadamard’s three-circles theorem will solve it, but I couldn't find the right annulus(the right choice of $r_1$ , $r_2$ and $t$ in the theorem). Also I tried to use induction on $n$ but again didn't get nowhere. I also tried to calculate it by using triangle inequality: \begin{align*}         M(Kr)&=\sup_{|z|=Kr}|c_nz^n+...+c_1z+c_0|\\         &\le |c_n||K|^n|r|^n+...+|c_1||K||r|+|c_0|\\         &< K^n(|c_n||r|^n+...+|c_1||r|+|c_0|)\\ \end{align*} But then I don't know where to go from there. So I'm curious about the solution to this problem. Any comment or hint are appreciated.","Let be a polynomial with complex coefficients, where . For each , define Prove that for any , the following inequlity holds I believe a proper use of the Hadamard’s three-circles theorem will solve it, but I couldn't find the right annulus(the right choice of , and in the theorem). Also I tried to use induction on but again didn't get nowhere. I also tried to calculate it by using triangle inequality: But then I don't know where to go from there. So I'm curious about the solution to this problem. Any comment or hint are appreciated.","P(z)=c_nz^n+...+c_1z+c_0 c_n\neq 0 r>0 M(r):=\sup_{|z|=r}|P(z)|. K>1 M(Kr)\le K^nM(r). r_1 r_2 t n \begin{align*}
        M(Kr)&=\sup_{|z|=Kr}|c_nz^n+...+c_1z+c_0|\\
        &\le |c_n||K|^n|r|^n+...+|c_1||K||r|+|c_0|\\
        &< K^n(|c_n||r|^n+...+|c_1||r|+|c_0|)\\
\end{align*}","['complex-analysis', 'inequality', 'polynomials']"
69,Unified explanation for parametrization independence,Unified explanation for parametrization independence,,"Let $\gamma:[a,b]\rightarrow\mathbb{R}^n$ be a $C^1$ curve. We have the following different kinds of line integrals: (i) $\displaystyle\int_a^bf(\gamma(t))|\gamma'(t)|dt$ where $f:\mathbb{R}^n\rightarrow\mathbb{R}$ is a scalar field; (ii) $\displaystyle\int_a^bF(\gamma(t))\cdot\gamma'(t)dt$ where $F:\mathbb{R}^n\rightarrow\mathbb{R}^n$ is a vector field; (iii) $\displaystyle\int_a^bf(\gamma(t))\gamma'(t)dt$ where $n=2$ and $f:\mathbb{C}\rightarrow\mathbb{C}$ is a complex function (identify $\mathbb{C}$ with $\mathbb{R}^2$ ). These are all parametrization independent, in the sense that if we replace $\gamma$ by $\eta=\gamma\circ\alpha$ , where $\alpha:[c,d]\rightarrow[a,b]$ is a $C^1$ increasing diffeomorphism, then the integral does not change. I wonder if there is some ""high-tech"" way to explain them all at once. My attempt: both the dot product $\mathbb{R}^n\times\mathbb{R}^n\rightarrow\mathbb{R}$ and complex multiplication $\mathbb{R}^2\times\mathbb{R}^2\rightarrow\mathbb{R}^2$ are bi-linear. I feel like the following general form is true. If $B:\mathbb{R}^m\times\mathbb{R}^n\rightarrow\mathbb{R}^k$ is a bi-linear map, then $\displaystyle\int_a^bB(f(\gamma(t)),\gamma'(t))dt$ is parametrization independent for $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$ ; actually if $G:[a,b]\rightarrow\mathcal{L}(\mathbb{R}^n;\mathbb{R}^k)$ is continuous, then $\displaystyle\int_a^bG(t)(\gamma'(t))dt$ is parametrization independent . If this works then it unifies (ii) and (iii), but I don't see how to also cover (i). Could this be explained using differential form and density (I am still trying to understand their definitions)? Are there generalizations to higher dimensions?","Let be a curve. We have the following different kinds of line integrals: (i) where is a scalar field; (ii) where is a vector field; (iii) where and is a complex function (identify with ). These are all parametrization independent, in the sense that if we replace by , where is a increasing diffeomorphism, then the integral does not change. I wonder if there is some ""high-tech"" way to explain them all at once. My attempt: both the dot product and complex multiplication are bi-linear. I feel like the following general form is true. If is a bi-linear map, then is parametrization independent for ; actually if is continuous, then is parametrization independent . If this works then it unifies (ii) and (iii), but I don't see how to also cover (i). Could this be explained using differential form and density (I am still trying to understand their definitions)? Are there generalizations to higher dimensions?","\gamma:[a,b]\rightarrow\mathbb{R}^n C^1 \displaystyle\int_a^bf(\gamma(t))|\gamma'(t)|dt f:\mathbb{R}^n\rightarrow\mathbb{R} \displaystyle\int_a^bF(\gamma(t))\cdot\gamma'(t)dt F:\mathbb{R}^n\rightarrow\mathbb{R}^n \displaystyle\int_a^bf(\gamma(t))\gamma'(t)dt n=2 f:\mathbb{C}\rightarrow\mathbb{C} \mathbb{C} \mathbb{R}^2 \gamma \eta=\gamma\circ\alpha \alpha:[c,d]\rightarrow[a,b] C^1 \mathbb{R}^n\times\mathbb{R}^n\rightarrow\mathbb{R} \mathbb{R}^2\times\mathbb{R}^2\rightarrow\mathbb{R}^2 B:\mathbb{R}^m\times\mathbb{R}^n\rightarrow\mathbb{R}^k \displaystyle\int_a^bB(f(\gamma(t)),\gamma'(t))dt f:\mathbb{R}^n\rightarrow\mathbb{R}^m G:[a,b]\rightarrow\mathcal{L}(\mathbb{R}^n;\mathbb{R}^k) \displaystyle\int_a^bG(t)(\gamma'(t))dt","['complex-analysis', 'analysis', 'differential-geometry']"
70,Prove $P(z)=z^4+2z^3+3z^2+z+2$ has exactly two zeros in the right half plane,Prove  has exactly two zeros in the right half plane,P(z)=z^4+2z^3+3z^2+z+2,"NOTE: The answer found here is not what I'm looking for. The question is: Prove $P(z)=z^4+2z^3+3z^2+z+2$ has exactly two zeros in the right half plane. [Hint: Write $P(iy)=(y^2-2)(y^2-1)+iy(1-2y^2)$ , and show that $\lim_{R\to\infty}arg\{P(iy)\}\Biggr|_{-R}^{R}=0$ .] I need to prove this (preferably using Rouche's theorem. Any other method involving the hint may also be accepted). Now, this can be shown to be true by taking two functions $f(z)=(z-1)^2(z+2)^2$ and $h(z)=z^4+2z^3-3z^2-4z+4$ which are analytic on and inside a closed semi-circular contour (radius $R$ ) encapsulating the right half-plane, and by showing that $|f(z)|>|h(z)|$ on the boundary of it. Then by Rouche's theorem, it is easy to verify that $P(z)$ has only 2 zeros (same as $f(z)$ ) in the right half-plane. What I'm looking for is a solution involving the Hint! I know the Hint says that the imaginary axis of the domain gets mapped to the right half-plane (more precisely to the positive real numbers as $R\to\infty$ ). But I'm not sure how to use it in getting a solution. Thanks in advance.","NOTE: The answer found here is not what I'm looking for. The question is: Prove has exactly two zeros in the right half plane. [Hint: Write , and show that .] I need to prove this (preferably using Rouche's theorem. Any other method involving the hint may also be accepted). Now, this can be shown to be true by taking two functions and which are analytic on and inside a closed semi-circular contour (radius ) encapsulating the right half-plane, and by showing that on the boundary of it. Then by Rouche's theorem, it is easy to verify that has only 2 zeros (same as ) in the right half-plane. What I'm looking for is a solution involving the Hint! I know the Hint says that the imaginary axis of the domain gets mapped to the right half-plane (more precisely to the positive real numbers as ). But I'm not sure how to use it in getting a solution. Thanks in advance.",P(z)=z^4+2z^3+3z^2+z+2 P(iy)=(y^2-2)(y^2-1)+iy(1-2y^2) \lim_{R\to\infty}arg\{P(iy)\}\Biggr|_{-R}^{R}=0 f(z)=(z-1)^2(z+2)^2 h(z)=z^4+2z^3-3z^2-4z+4 R |f(z)|>|h(z)| P(z) f(z) R\to\infty,"['complex-analysis', 'complex-numbers', 'complex-integration', 'singularity', 'rouches-theorem']"
71,Why do we care about Cauchy principal value?,Why do we care about Cauchy principal value?,,"Question is in the title, basically. I don't understand the motivation behind assigning the Cauchy principal value to otherwise divergent integrals. I'm more comfortable with things like Abel summation that assign values to divergent series, because in my (limited) experience, all the reasonable ways you can do this lead to the same values. But Cauchy p.v. isn't compatible with substitutions, which are normally one of the fundamental tools for evaluating integrals. So why do we care about Cauchy principal value?","Question is in the title, basically. I don't understand the motivation behind assigning the Cauchy principal value to otherwise divergent integrals. I'm more comfortable with things like Abel summation that assign values to divergent series, because in my (limited) experience, all the reasonable ways you can do this lead to the same values. But Cauchy p.v. isn't compatible with substitutions, which are normally one of the fundamental tools for evaluating integrals. So why do we care about Cauchy principal value?",,"['complex-analysis', 'cauchy-principal-value']"
72,Show that there does not exist a holomorphic function $h(z)$ such that $\exp(h(z)) = z$ on the punctured plane without using complex integration?,Show that there does not exist a holomorphic function  such that  on the punctured plane without using complex integration?,h(z) \exp(h(z)) = z,"We must show that there does not exist a holomorphic function $h(z)$ on the domain $\mathbb C - \{0 \}$ such that $\exp(h(z)) = z$ on the complex plane. Can we do this without using complex integration? I know the proof of the fact that there exists no function whose exponential is the identity function $id(z) = z$ on the complex plane which uses complex analysis. We proceed by assuming such a  holomorphic $h(z)$ exists. This means that $e^{h(z)} = z$ . Differentiating, we get $1 = e^{h(z)} h'(z) = z h'(z)$ . This means that $1 = z h'(z)$ , or $h'(z) = 1/z$ . Now we compute $\oint h'(z)$ around the countour $c(t) = e^{2 \pi i t}$ in two different ways: $\oint h'(z) = h(1) - h(1) = 0$ , by using FTC and that the countor starts and ends at the same point: $1$ . $\oint h'(z) = \oint 1/z = 2 \pi i$ by the Residue Theorem Thus, we get $0 = 2 \pi i$ which is absurd. However, this proof seems to rely on a lot of the machinery of complex integration to get things done. Is there no ""simpler"" proof? Can we show that to prove this fact, we somehow ""need to"" invoke facts about complex integrals? Ideally, I would want an answer that only uses elementary properties of complex numbers, and properties of the complex exponential, and complex differentiation, but not complex integration .","We must show that there does not exist a holomorphic function on the domain such that on the complex plane. Can we do this without using complex integration? I know the proof of the fact that there exists no function whose exponential is the identity function on the complex plane which uses complex analysis. We proceed by assuming such a  holomorphic exists. This means that . Differentiating, we get . This means that , or . Now we compute around the countour in two different ways: , by using FTC and that the countor starts and ends at the same point: . by the Residue Theorem Thus, we get which is absurd. However, this proof seems to rely on a lot of the machinery of complex integration to get things done. Is there no ""simpler"" proof? Can we show that to prove this fact, we somehow ""need to"" invoke facts about complex integrals? Ideally, I would want an answer that only uses elementary properties of complex numbers, and properties of the complex exponential, and complex differentiation, but not complex integration .",h(z) \mathbb C - \{0 \} \exp(h(z)) = z id(z) = z h(z) e^{h(z)} = z 1 = e^{h(z)} h'(z) = z h'(z) 1 = z h'(z) h'(z) = 1/z \oint h'(z) c(t) = e^{2 \pi i t} \oint h'(z) = h(1) - h(1) = 0 1 \oint h'(z) = \oint 1/z = 2 \pi i 0 = 2 \pi i,['complex-analysis']
73,Maximum Modulus Principle Intuition [duplicate],Maximum Modulus Principle Intuition [duplicate],,"This question already has answers here : Intuition Behind Maximum Principle (Complex Analysis) (3 answers) Closed 5 years ago . I understand that the Maximum Modulus Principle works, but I'm a little baffled as to why. To be more precise, the picture I have in my head is something like this: for a compact set $K \subset \mathbb{C}$, since $|f|$ (for $f$ holomorphic) can only attain its maximum on the boundary $\partial K$, if you consider a disk centered on the origin, no matter what value $|f|$ obtains on the boundary of this disc, you can just increase the radius of the disc a little bit and find a higher value of $|f|$; in other words, the absolute value of function just keeps growing without bound. What exactly is driving/forcing this growth? I'm looking for some kind of explanation, geometric or otherwise, that could aid my intuition. In particular, why does $\mathbb{C}$ behave so differently from $\mathbb{R}$ here? EDIT. In response to the ""duplicate"" tag: I am looking for something a little deeper than the answers there. As mentioned above, an explanation of the difference in behaviours of $\mathbb{C}$ and $\mathbb{R}$ in this regard, perhaps with a tie-in to the Cauchy-Riemann equations...it seems like there's something that causes functions to behave fundamentally differently over $\mathbb{C}$, and I would like to understand why, with the Maxiumum Modulus Principle as a concrete example.","This question already has answers here : Intuition Behind Maximum Principle (Complex Analysis) (3 answers) Closed 5 years ago . I understand that the Maximum Modulus Principle works, but I'm a little baffled as to why. To be more precise, the picture I have in my head is something like this: for a compact set $K \subset \mathbb{C}$, since $|f|$ (for $f$ holomorphic) can only attain its maximum on the boundary $\partial K$, if you consider a disk centered on the origin, no matter what value $|f|$ obtains on the boundary of this disc, you can just increase the radius of the disc a little bit and find a higher value of $|f|$; in other words, the absolute value of function just keeps growing without bound. What exactly is driving/forcing this growth? I'm looking for some kind of explanation, geometric or otherwise, that could aid my intuition. In particular, why does $\mathbb{C}$ behave so differently from $\mathbb{R}$ here? EDIT. In response to the ""duplicate"" tag: I am looking for something a little deeper than the answers there. As mentioned above, an explanation of the difference in behaviours of $\mathbb{C}$ and $\mathbb{R}$ in this regard, perhaps with a tie-in to the Cauchy-Riemann equations...it seems like there's something that causes functions to behave fundamentally differently over $\mathbb{C}$, and I would like to understand why, with the Maxiumum Modulus Principle as a concrete example.",,['complex-analysis']
74,Calculating Laurent series expansion,Calculating Laurent series expansion,,"I have to calculate the Laurent series expansion of   $$f(z) = \frac {2z−2}{(z+1)(z−2)}$$ in $1 < |z| < 2$ and $|z| > 3$. For first annulus, I know I must manipulate the given expression to contain terms $1/z$ and $z/2$ so that some expansion is valid for $|\frac1{z}|<1$ and $|\frac z{2}|<1$, so I try doing that. Decomposing into partial fractions, $$f(z) = \frac 4{3} (\frac 1{z+1}) + \frac 2{3}(\frac 1{z-2})$$ $$= \frac4{3z} \frac1{1-\frac {(-1)}{z}}  - \frac1{3} \frac 1{1 - \frac z{2}}$$ So can I now expand the $2$ terms by a G.P. for $|\frac1{z}|<1$ and $|\frac z{2}|<1$  to get the Laurent series? For second case of $|\frac 3{z}|<1 $, how should I proceed?","I have to calculate the Laurent series expansion of   $$f(z) = \frac {2z−2}{(z+1)(z−2)}$$ in $1 < |z| < 2$ and $|z| > 3$. For first annulus, I know I must manipulate the given expression to contain terms $1/z$ and $z/2$ so that some expansion is valid for $|\frac1{z}|<1$ and $|\frac z{2}|<1$, so I try doing that. Decomposing into partial fractions, $$f(z) = \frac 4{3} (\frac 1{z+1}) + \frac 2{3}(\frac 1{z-2})$$ $$= \frac4{3z} \frac1{1-\frac {(-1)}{z}}  - \frac1{3} \frac 1{1 - \frac z{2}}$$ So can I now expand the $2$ terms by a G.P. for $|\frac1{z}|<1$ and $|\frac z{2}|<1$  to get the Laurent series? For second case of $|\frac 3{z}|<1 $, how should I proceed?",,"['complex-analysis', 'power-series', 'laurent-series']"
75,Independence of $z$ and $\bar{z}$,Independence of  and,z \bar{z},"I am teaching complex analysis to physics students next semester and I would like to discuss the fact that $z$ and $\bar{z}$ are functionally(?)/algebraically(?) (what is the correct terminology, anyway?) independent as early as possible in a course. Ideally, after I introduce complex numbers $z$ as a pair of real numbers and develop the basic complex algebra, I would like to define the complex conjugate $\bar{z}$ and then prove that $\bar{z}$ cannot be obtained from $z$ using algebra, i.e. using $+,-,\times,\div$. Now, my question is, what is the strongest statement of independence of $z$ and $\bar{z}$ that I can prove using basic complex algebra? Rephrasing the question: how can I prove that $z$ and $\bar{z}$ are algebraically independent in the ordinary sense of the word? I want to prove there exists no nontrivial polynomial $P_n(z,\bar{z})$ with complex constants so that $P_n(z,\bar{z}) = 0$ for any $n \in \mathbb{N}$ (including $n \to \infty$).","I am teaching complex analysis to physics students next semester and I would like to discuss the fact that $z$ and $\bar{z}$ are functionally(?)/algebraically(?) (what is the correct terminology, anyway?) independent as early as possible in a course. Ideally, after I introduce complex numbers $z$ as a pair of real numbers and develop the basic complex algebra, I would like to define the complex conjugate $\bar{z}$ and then prove that $\bar{z}$ cannot be obtained from $z$ using algebra, i.e. using $+,-,\times,\div$. Now, my question is, what is the strongest statement of independence of $z$ and $\bar{z}$ that I can prove using basic complex algebra? Rephrasing the question: how can I prove that $z$ and $\bar{z}$ are algebraically independent in the ordinary sense of the word? I want to prove there exists no nontrivial polynomial $P_n(z,\bar{z})$ with complex constants so that $P_n(z,\bar{z}) = 0$ for any $n \in \mathbb{N}$ (including $n \to \infty$).",,['complex-analysis']
76,Stuck on Exercise in Stein and Sharkarchi Complex Analysis,Stuck on Exercise in Stein and Sharkarchi Complex Analysis,,"I'm currently self-studying Stein and Sharkarchi's complex analysis book, and I'm stuck on the following exercise from chapter 2: Let $\Omega$ be a bounded open subset of $\mathbb{C}$ , and $\varphi:\Omega \rightarrow \Omega$ a holomorphic function. Prove that if there exists a point $z_0 \in \Omega$ such that ${\varphi}(z_0)=z_0$ and ${\varphi}'(z_0)=1$ then $\varphi$ is linear. The following hint is provided: Why can one assume that $z_0 = 0$ ? Write ${\varphi}(z) = z + a_nz^n + O(z^{n+1})$ near $0$ , and prove that if ${\varphi}_k = \varphi \circ\cdots\circ \varphi$ (where $\varphi$ appears $k$ times), then ${\varphi}_k(z) = z + ka_nz^n + O(z^{n+1})$ . Apply the Cauchy inequalities and let $k \to\infty$ to conclude the proof. I've verified that one can indeed assume that $z_0=0$ and that ${\varphi}_k(z) = z + ka_nz^n + O(z^{n+1})$ , but I'm totally at a loss as to how the Cauchy inequalities are relevant here. Any help would be greatly appreciated! EDIT: The Cauchy inequality referenced here is that if $f(z)=\sum _{ n=0 }^{ \infty  }{ a_nz^n } $ is holomorphic in $\left| z \right|<R$ , then $\left| a_{ n } \right| \le r^{-n}\underset { \left| z \right| =R }{ \sup } \left| f(x) \right| $ .","I'm currently self-studying Stein and Sharkarchi's complex analysis book, and I'm stuck on the following exercise from chapter 2: Let be a bounded open subset of , and a holomorphic function. Prove that if there exists a point such that and then is linear. The following hint is provided: Why can one assume that ? Write near , and prove that if (where appears times), then . Apply the Cauchy inequalities and let to conclude the proof. I've verified that one can indeed assume that and that , but I'm totally at a loss as to how the Cauchy inequalities are relevant here. Any help would be greatly appreciated! EDIT: The Cauchy inequality referenced here is that if is holomorphic in , then .","\Omega \mathbb{C} \varphi:\Omega \rightarrow \Omega z_0 \in \Omega {\varphi}(z_0)=z_0 {\varphi}'(z_0)=1 \varphi z_0 = 0 {\varphi}(z) = z + a_nz^n + O(z^{n+1}) 0 {\varphi}_k = \varphi \circ\cdots\circ \varphi \varphi k {\varphi}_k(z) =
z + ka_nz^n + O(z^{n+1}) k \to\infty z_0=0 {\varphi}_k(z) = z + ka_nz^n + O(z^{n+1}) f(z)=\sum _{ n=0 }^{ \infty  }{ a_nz^n }  \left| z \right|<R \left| a_{ n } \right| \le r^{-n}\underset { \left| z \right| =R }{ \sup } \left| f(x) \right| ","['complex-analysis', 'cauchy-integral-formula']"
77,Holomorphic 1-forms on a smooth affine plane curve,Holomorphic 1-forms on a smooth affine plane curve,,"I'm looking at Miranda's Algebraic Curves and Riemann Surfaces. In particular, Chapter IV.I, question C : Let $X$ be a smooth affine plane curve defined by $f(u,v) =0$. Show that $du$ and $dv$ define holomorphic 1-forms on $X$, as do $p(u,v)du$ and $p(u,v)dv$ for any polynomial $p(u,v)$. Show that if $r(u,v)$ is any rational function, then $r(u,v)du$ and $r(u,v)dv$ are meromorphic 1-forms on $X$. Show that $(\partial f/\partial u)du = -(\partial f/\partial v)dv$ as holomorphic 1-forms on $X$. I understand what a holomorphic 1-form is, but I'm not sure how I'm supposed to show that these particular examples are 1-forms on $X$. The reason for this mainly is that I'm unsure of when something fails to be a holomorphic 1-form.","I'm looking at Miranda's Algebraic Curves and Riemann Surfaces. In particular, Chapter IV.I, question C : Let $X$ be a smooth affine plane curve defined by $f(u,v) =0$. Show that $du$ and $dv$ define holomorphic 1-forms on $X$, as do $p(u,v)du$ and $p(u,v)dv$ for any polynomial $p(u,v)$. Show that if $r(u,v)$ is any rational function, then $r(u,v)du$ and $r(u,v)dv$ are meromorphic 1-forms on $X$. Show that $(\partial f/\partial u)du = -(\partial f/\partial v)dv$ as holomorphic 1-forms on $X$. I understand what a holomorphic 1-form is, but I'm not sure how I'm supposed to show that these particular examples are 1-forms on $X$. The reason for this mainly is that I'm unsure of when something fails to be a holomorphic 1-form.",,"['complex-analysis', 'algebraic-geometry']"
78,Proof using Cauchy Integral Theorem,Proof using Cauchy Integral Theorem,,"Suppose that I have the following integral: $$ \int_L \frac {dz}{z^2+1} $$ I need to show that this is equal to $0$ if $L$ is any closed rectifiable simple curve in the outside of the closed unit disc. Simply put, this is where $|z| > 1$. Initially, I thought that because ""closed rectifiable simple curve"" is a crucial part of the Cauchy Integral Theorem, the best way to go about this is to show that the rest of theorem must hold. That is, the domain, $|z|>1$, is a simply connected domain, and that $f(z)$ is analytic in this domain. However, the domain does not appear to be a simply connected domain, as everything on the inside of the unit disc would prevent it from being so. By definition, a simply connected domain is one where any simple curve in that domain can be shrunk to a point that's also in the domain, so therefore, it may be possible to shrink a curve in this domain to the inside of the circle! I must be missing a key part to this proof, because as of now, this contradicting statement has me stumped. Any thoughts/ideas?","Suppose that I have the following integral: $$ \int_L \frac {dz}{z^2+1} $$ I need to show that this is equal to $0$ if $L$ is any closed rectifiable simple curve in the outside of the closed unit disc. Simply put, this is where $|z| > 1$. Initially, I thought that because ""closed rectifiable simple curve"" is a crucial part of the Cauchy Integral Theorem, the best way to go about this is to show that the rest of theorem must hold. That is, the domain, $|z|>1$, is a simply connected domain, and that $f(z)$ is analytic in this domain. However, the domain does not appear to be a simply connected domain, as everything on the inside of the unit disc would prevent it from being so. By definition, a simply connected domain is one where any simple curve in that domain can be shrunk to a point that's also in the domain, so therefore, it may be possible to shrink a curve in this domain to the inside of the circle! I must be missing a key part to this proof, because as of now, this contradicting statement has me stumped. Any thoughts/ideas?",,"['complex-analysis', 'complex-integration']"
79,Does logging infinitely converge?,Does logging infinitely converge?,,"Trying to evaluate $$\ln(\ln(\ln(\ln(\cdots\ln(x)\cdots))))$$For some fixed $x$ produces a complex answer that appears to converge, at least sometimes. So I want a proof that this converges for either some $x$, no $x$, or all $x$. If it converges for all $x$ or some $x$, what does it converge to? If it diverges, is there a way we can evaluate it like we evaluate diverging sums? And after all of that, does it appear to converge to the same value, no matter what $x$ value we start with? I know $\ln(z)=\ln(|z|)+i\arg(z)$, but I can't repeat this process without a given $z$.  (where $z$ is complex). A similar post of mine found here does not answer my question and focuses more on the limits, calculus, and infinites. This question asks for consideration from a complex-analysis point of view, considering convergence of value in the complex plane.","Trying to evaluate $$\ln(\ln(\ln(\ln(\cdots\ln(x)\cdots))))$$For some fixed $x$ produces a complex answer that appears to converge, at least sometimes. So I want a proof that this converges for either some $x$, no $x$, or all $x$. If it converges for all $x$ or some $x$, what does it converge to? If it diverges, is there a way we can evaluate it like we evaluate diverging sums? And after all of that, does it appear to converge to the same value, no matter what $x$ value we start with? I know $\ln(z)=\ln(|z|)+i\arg(z)$, but I can't repeat this process without a given $z$.  (where $z$ is complex). A similar post of mine found here does not answer my question and focuses more on the limits, calculus, and infinites. This question asks for consideration from a complex-analysis point of view, considering convergence of value in the complex plane.",,"['complex-analysis', 'complex-numbers', 'logarithms']"
80,How to make $\log x^a = a\log x$ work using multivalued complex approach,How to make  work using multivalued complex approach,\log x^a = a\log x,"The following identity holds for all $a$ and $x$ using the principal branch: $$     \log x^a = a\log x         + 2\pi i \left\lfloor \pi-\Im (a\log x) \over 2\pi \right\rfloor $$ e.g. for $a=2$, $x=-1$: LHS = $\log (-1)^2 = \log 1 = 0$ RHS = $2\log(-1)+ 2\pi i \left\lfloor \pi-\Im (2\log (-1)) \over 2\pi \right\rfloor$ =$2\pi i+ 2\pi i \left\lfloor \pi-\Im (2\pi i) \over 2\pi \right\rfloor = 2\pi i - 2\pi i = 0$ Everything is single valued and there is no problem. How can I perform the same calculation using multivalued logarithms? In other words, I want to use the (multivalued) identity: $$\log x^a = a\log x$$ for $a=2$, $x=-1$. I pick the same branch for both LHS and RHS, let's pick the principal branch (so that we can reuse the values calculated above), and then I add the $2\pi i n$ term for each logarithm and get: LHS = $\log (-1)^2 + 2\pi i n = 2\pi i n$ RHS = $2\log(-1) + 2\pi i \left\lfloor \pi-\Im (2\log (-1)) \over 2\pi \right\rfloor + 2\cdot 2\pi i m = 4\pi i m$ And we can see that LHS is not equal to RHS, otherwise $m$ would have to be half-integer. Where did I make the mistake? How can I make LHS equal to RHS using the multivalued approach?","The following identity holds for all $a$ and $x$ using the principal branch: $$     \log x^a = a\log x         + 2\pi i \left\lfloor \pi-\Im (a\log x) \over 2\pi \right\rfloor $$ e.g. for $a=2$, $x=-1$: LHS = $\log (-1)^2 = \log 1 = 0$ RHS = $2\log(-1)+ 2\pi i \left\lfloor \pi-\Im (2\log (-1)) \over 2\pi \right\rfloor$ =$2\pi i+ 2\pi i \left\lfloor \pi-\Im (2\pi i) \over 2\pi \right\rfloor = 2\pi i - 2\pi i = 0$ Everything is single valued and there is no problem. How can I perform the same calculation using multivalued logarithms? In other words, I want to use the (multivalued) identity: $$\log x^a = a\log x$$ for $a=2$, $x=-1$. I pick the same branch for both LHS and RHS, let's pick the principal branch (so that we can reuse the values calculated above), and then I add the $2\pi i n$ term for each logarithm and get: LHS = $\log (-1)^2 + 2\pi i n = 2\pi i n$ RHS = $2\log(-1) + 2\pi i \left\lfloor \pi-\Im (2\log (-1)) \over 2\pi \right\rfloor + 2\cdot 2\pi i m = 4\pi i m$ And we can see that LHS is not equal to RHS, otherwise $m$ would have to be half-integer. Where did I make the mistake? How can I make LHS equal to RHS using the multivalued approach?",,"['complex-analysis', 'complex-numbers']"
81,Explicit fractional linear transformations which rotate the Riemann sphere about the $x$-axis,Explicit fractional linear transformations which rotate the Riemann sphere about the -axis,x,"Background: Let $S^2$ denote the unit sphere in $\mathbb{R}^3$. By ""stereographic projection"", I mean the mapping from $S^2$ (remove the north pole) to the complex plane  which sends  \begin{align*} \begin{bmatrix} x \\ y \\ t \end{bmatrix} \in S^2  \mapsto z = \frac{x+iy}{1-t} \in \mathbb{C}. \end{align*} The inverse mapping, from the complex plane to the sphere, is then given by  \begin{align*}z = x+iy \in \mathbb{C} \mapsto \frac{2}{|z|^2+1} \cdot \begin{bmatrix} x \\ y \\ 0 \end{bmatrix}  + \left(1 - \frac{2}{|z|^2 + 1}\right) \cdot \begin{bmatrix} 0 \\0 \\ 1 \end{bmatrix} \in S^2. \end{align*} Using the above correspondences, we can view a transformation of $\mathbb{C}$ as a transformation of $S^2$, or vice versa. I was especially interested to learn from this question that rotations of the $2$-sphere, i.e. the transformations corresponding to matrices in $SO(3)$, actually correspond to a subset of the fractional linear transformations $z \mapsto \frac{az + b}{cz + d}$. Precisely, $z \mapsto \frac{az + b}{cz + d}$ corresponds to a rotation of $S^2$ if and only if $\begin{bmatrix} a & b \\ c & d \\ \end{bmatrix}$ belongs (up to scalar multiple, I guess) to $U(2)$, the group of $2 \times 2$ unitary matrices. In particular, $z \mapsto \frac{1}{z}$ corresponds to rotating $S^2$ by $180$ degrees about the $x$-axis. Upon learning the above fact, I wondered whether I could write down a unitary matrix whose fractional linear transformation corresponds to rotation by a given angle about the $x$-axis. After a while I was able to convince myself that the fractional linear transformation corresponding to  $$ U_\theta = \begin{bmatrix} \cos \theta & i \sin \theta \\ i \sin \theta & \cos \theta \\ \end{bmatrix} \in SU(2)$$ i.e. the mapping $$f_\theta(z) =  \frac{\cos \theta z + i \sin \theta}{i \sin \theta z + \cos \theta}$$ corresponds to rotation of $S^2$ through an angle of $\theta$ degrees about the $x$-axis, i.e. to the transformation given by the matrix $$R_{2 \theta} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & \cos(2 \theta) & - \sin( 2 \theta) \\ 0 & \sin(2 \theta) & \cos(2 \theta) \\ \end{bmatrix}.$$ The fact that the sphere spins around twice as $\theta : 0 \to 2 \pi$ I guess has something to do with the fact that $SU(2)$ is supposed to double-cover $SO(3)$. Question: How can I efficiently prove that $f_\theta$ and $R_{2 \theta}$ really are the same transformation in different representations? To be sure, one can take a generic point $(x,y,t) \in S^2$ and check that the result of applying stereographic projection and then $f_\theta$ agrees with result of applying $R_{2 \theta}$ and then stereographic projection. However, doing this for specific points $(x,y,t)$ is more or less how I came up with the above formulae, and even then the algebra seemed to get pretty involved. Can somebody provide a more enlightening proof?","Background: Let $S^2$ denote the unit sphere in $\mathbb{R}^3$. By ""stereographic projection"", I mean the mapping from $S^2$ (remove the north pole) to the complex plane  which sends  \begin{align*} \begin{bmatrix} x \\ y \\ t \end{bmatrix} \in S^2  \mapsto z = \frac{x+iy}{1-t} \in \mathbb{C}. \end{align*} The inverse mapping, from the complex plane to the sphere, is then given by  \begin{align*}z = x+iy \in \mathbb{C} \mapsto \frac{2}{|z|^2+1} \cdot \begin{bmatrix} x \\ y \\ 0 \end{bmatrix}  + \left(1 - \frac{2}{|z|^2 + 1}\right) \cdot \begin{bmatrix} 0 \\0 \\ 1 \end{bmatrix} \in S^2. \end{align*} Using the above correspondences, we can view a transformation of $\mathbb{C}$ as a transformation of $S^2$, or vice versa. I was especially interested to learn from this question that rotations of the $2$-sphere, i.e. the transformations corresponding to matrices in $SO(3)$, actually correspond to a subset of the fractional linear transformations $z \mapsto \frac{az + b}{cz + d}$. Precisely, $z \mapsto \frac{az + b}{cz + d}$ corresponds to a rotation of $S^2$ if and only if $\begin{bmatrix} a & b \\ c & d \\ \end{bmatrix}$ belongs (up to scalar multiple, I guess) to $U(2)$, the group of $2 \times 2$ unitary matrices. In particular, $z \mapsto \frac{1}{z}$ corresponds to rotating $S^2$ by $180$ degrees about the $x$-axis. Upon learning the above fact, I wondered whether I could write down a unitary matrix whose fractional linear transformation corresponds to rotation by a given angle about the $x$-axis. After a while I was able to convince myself that the fractional linear transformation corresponding to  $$ U_\theta = \begin{bmatrix} \cos \theta & i \sin \theta \\ i \sin \theta & \cos \theta \\ \end{bmatrix} \in SU(2)$$ i.e. the mapping $$f_\theta(z) =  \frac{\cos \theta z + i \sin \theta}{i \sin \theta z + \cos \theta}$$ corresponds to rotation of $S^2$ through an angle of $\theta$ degrees about the $x$-axis, i.e. to the transformation given by the matrix $$R_{2 \theta} = \begin{bmatrix} 1 & 0 & 0 \\ 0 & \cos(2 \theta) & - \sin( 2 \theta) \\ 0 & \sin(2 \theta) & \cos(2 \theta) \\ \end{bmatrix}.$$ The fact that the sphere spins around twice as $\theta : 0 \to 2 \pi$ I guess has something to do with the fact that $SU(2)$ is supposed to double-cover $SO(3)$. Question: How can I efficiently prove that $f_\theta$ and $R_{2 \theta}$ really are the same transformation in different representations? To be sure, one can take a generic point $(x,y,t) \in S^2$ and check that the result of applying stereographic projection and then $f_\theta$ agrees with result of applying $R_{2 \theta}$ and then stereographic projection. However, doing this for specific points $(x,y,t)$ is more or less how I came up with the above formulae, and even then the algebra seemed to get pretty involved. Can somebody provide a more enlightening proof?",,"['complex-analysis', 'rotations', 'stereographic-projections']"
82,Residues of $z^2\sin(\frac{1}{z})$,Residues of,z^2\sin(\frac{1}{z}),"I must find the residues of $z^2\sin(\frac{1}{z})$ at $z = 0$. Since $z = 0$ seems to be an Essential Singularity, i'm not sure how I can continue to find the residue of the function. Usually I am able to apply the Taylor Series and then find the $z^{-1}$ coefficient, but in this case I do not get a $z^{-1}$ term.","I must find the residues of $z^2\sin(\frac{1}{z})$ at $z = 0$. Since $z = 0$ seems to be an Essential Singularity, i'm not sure how I can continue to find the residue of the function. Usually I am able to apply the Taylor Series and then find the $z^{-1}$ coefficient, but in this case I do not get a $z^{-1}$ term.",,['complex-analysis']
83,Integrate using Cauchy Integral Theorem,Integrate using Cauchy Integral Theorem,,"Evaluate the integral I=$\int_0^\infty \sin(x^3)dx$ I already know that the answer is $(1/2)\Gamma(4/3)$. So far I have considered the integral $\int_0^\infty e^{-x^3}dx=\Gamma(4/3)$ which I have already shown to be true, I'm not really sure how to proceed. I am told to consider the integral $\oint_C e^{-z^3}dz$ along the contour C, being simply the contour in the first quadrant. Unfortunately, this is from a math methods for physics course, basically the professor just rambles and writes out sparse solutions to everything on the board (including this one) but I don't really get it since I've never studied complex variables at all before and he never bothered to really go through it (it's not a prerequisite for the course).","Evaluate the integral I=$\int_0^\infty \sin(x^3)dx$ I already know that the answer is $(1/2)\Gamma(4/3)$. So far I have considered the integral $\int_0^\infty e^{-x^3}dx=\Gamma(4/3)$ which I have already shown to be true, I'm not really sure how to proceed. I am told to consider the integral $\oint_C e^{-z^3}dz$ along the contour C, being simply the contour in the first quadrant. Unfortunately, this is from a math methods for physics course, basically the professor just rambles and writes out sparse solutions to everything on the board (including this one) but I don't really get it since I've never studied complex variables at all before and he never bothered to really go through it (it's not a prerequisite for the course).",,['complex-analysis']
84,Injectivity of sine on complex domain?,Injectivity of sine on complex domain?,,"So the problem is : let $R$ be region $[{z\in \mathbb{C} : -\cfrac{\pi}{2}<Re(z)<\cfrac{\pi}{2}}]$. Show that sine function is injective in R. I could think about two starting points: i) we have $\sin(z) = \cfrac{e^{iz}-e^{-iz}}{2i}$. So if, say for $z_1,z_2 \in R$, $\sin(z_1)=\sin(z_2)$, then we have $e^{iz_1}-e^{-iz_1}=e^{iz_2}-e^{-iz_2}$ but I have no idea how to continue from this. Since region $R$ mentions real part of the complex number, I will need to refer to it at some point but I dont seem to find how. I tried to put $z_1$ and $z_2$ into the form $x+iy$ but it only seemed to complicate things. ii) So after above attempt, maybe I thought it was better to consider imaginary part and real part separately: $\sin(x+iy)=\sin(x) \cosh(y)+i\cos(x) \sinh(y)$ so I proceeded in exactly same way, but in the end I had to relate two equations arising from equating real/imaginary parts somehow, but that actually made attept too complicated. I have a feeling that it shouldn't be this hard... any hints are appreciated!","So the problem is : let $R$ be region $[{z\in \mathbb{C} : -\cfrac{\pi}{2}<Re(z)<\cfrac{\pi}{2}}]$. Show that sine function is injective in R. I could think about two starting points: i) we have $\sin(z) = \cfrac{e^{iz}-e^{-iz}}{2i}$. So if, say for $z_1,z_2 \in R$, $\sin(z_1)=\sin(z_2)$, then we have $e^{iz_1}-e^{-iz_1}=e^{iz_2}-e^{-iz_2}$ but I have no idea how to continue from this. Since region $R$ mentions real part of the complex number, I will need to refer to it at some point but I dont seem to find how. I tried to put $z_1$ and $z_2$ into the form $x+iy$ but it only seemed to complicate things. ii) So after above attempt, maybe I thought it was better to consider imaginary part and real part separately: $\sin(x+iy)=\sin(x) \cosh(y)+i\cos(x) \sinh(y)$ so I proceeded in exactly same way, but in the end I had to relate two equations arising from equating real/imaginary parts somehow, but that actually made attept too complicated. I have a feeling that it shouldn't be this hard... any hints are appreciated!",,['complex-analysis']
85,Find roots of $3z^{100} - e^z$ in the unit disc.,Find roots of  in the unit disc.,3z^{100} - e^z,"This question was given in an exam in complex analysis: Let $f \left( z \right) = 3z^{100} - e^z$. Find all of $f$'s roots in $D \left ( 0,1 \right)$ and show that they are simple roots. I've seen these types of questions with polynomials and the usual technique is to use Rouche's Theorem but it seems that the conditions are not satisfied here. Neither function $3z^{100}$ nor $e^z$ is strictly greater than the other in the unit disc. EDIT: I've misinterpreted the conditions for Rouche's theorem. As mentioned in the comments, the theorem only requires that one function be strictly greater than the other on the boundary of the compact domain (in this case, the unit circle) and indeed that condition is met.","This question was given in an exam in complex analysis: Let $f \left( z \right) = 3z^{100} - e^z$. Find all of $f$'s roots in $D \left ( 0,1 \right)$ and show that they are simple roots. I've seen these types of questions with polynomials and the usual technique is to use Rouche's Theorem but it seems that the conditions are not satisfied here. Neither function $3z^{100}$ nor $e^z$ is strictly greater than the other in the unit disc. EDIT: I've misinterpreted the conditions for Rouche's theorem. As mentioned in the comments, the theorem only requires that one function be strictly greater than the other on the boundary of the compact domain (in this case, the unit circle) and indeed that condition is met.",,"['complex-analysis', 'roots']"
86,Deﬁne a branch of $(z^2 − 1)^{1/2}$ which is analytic in the unit disk.,Deﬁne a branch of  which is analytic in the unit disk.,(z^2 − 1)^{1/2},"Hint: $z^2 − 1 = (z + 1)(z − 1)$. I'm really struggling with this question. I understand that for this function to be analytic it has to be differentiable in some neighbourhood, but I have no idea where to start or even how to find/pick a branch.","Hint: $z^2 − 1 = (z + 1)(z − 1)$. I'm really struggling with this question. I understand that for this function to be analytic it has to be differentiable in some neighbourhood, but I have no idea where to start or even how to find/pick a branch.",,"['complex-analysis', 'analysis', 'functions', 'analyticity', 'branch-cuts']"
87,Question regarding usage of residue theorem in a specific case,Question regarding usage of residue theorem in a specific case,,"I'm looking over the solution of an exercise in a course I'm taking and there's something I simply don't understand. Let $f(z)=\pi\cot(\pi z)$ and $\varphi(z) = \frac{1}{z^2}$.  $f$ has poles of order $1$ in the points $k\in\mathbb{Z}$ and $\varphi$ has a pole of order $2$ at $0$. Now in the solution of the exercise it is written that from the residue theorem the following holds: $$\frac{1}{2\pi i} \int_\gamma f\cdot\varphi \, dz=\operatorname{Res} (f\varphi,0) + \sum\varphi(k)\operatorname{Res}(f,k)$$ where $\gamma$ is a simple positively oriented close curve and the sum extends over the values of $k\in\mathbb{Z}$ contained in the interior of $\gamma$. Now the standard form of the theorem would be: $$\frac{1}{2\pi i} \int_\gamma f\cdot\varphi \, dz = \sum \operatorname{Res} (f\cdot\varphi,k)$$ So for some reason for $k\neq0$ it holds that $\operatorname{Res}(\varphi f,k) = \varphi(k) \operatorname{Res} (f,k)$, why is that? Is it more generally true that if $f,g$ are functions such that $z_0$ is a singularity of $f$ but not of $g$ then $\operatorname{Res}(f\cdot g,z_0) = g (z_0) \cdot \operatorname{Res} (f,z_0)$. Is it maybe necessary to assume that $z_0$ is not a zero of $g$ for this to be true? Help would be appreciated.","I'm looking over the solution of an exercise in a course I'm taking and there's something I simply don't understand. Let $f(z)=\pi\cot(\pi z)$ and $\varphi(z) = \frac{1}{z^2}$.  $f$ has poles of order $1$ in the points $k\in\mathbb{Z}$ and $\varphi$ has a pole of order $2$ at $0$. Now in the solution of the exercise it is written that from the residue theorem the following holds: $$\frac{1}{2\pi i} \int_\gamma f\cdot\varphi \, dz=\operatorname{Res} (f\varphi,0) + \sum\varphi(k)\operatorname{Res}(f,k)$$ where $\gamma$ is a simple positively oriented close curve and the sum extends over the values of $k\in\mathbb{Z}$ contained in the interior of $\gamma$. Now the standard form of the theorem would be: $$\frac{1}{2\pi i} \int_\gamma f\cdot\varphi \, dz = \sum \operatorname{Res} (f\cdot\varphi,k)$$ So for some reason for $k\neq0$ it holds that $\operatorname{Res}(\varphi f,k) = \varphi(k) \operatorname{Res} (f,k)$, why is that? Is it more generally true that if $f,g$ are functions such that $z_0$ is a singularity of $f$ but not of $g$ then $\operatorname{Res}(f\cdot g,z_0) = g (z_0) \cdot \operatorname{Res} (f,z_0)$. Is it maybe necessary to assume that $z_0$ is not a zero of $g$ for this to be true? Help would be appreciated.",,['complex-analysis']
88,Holomorphic in small disk with polynomial power,Holomorphic in small disk with polynomial power,,"Let $f(z)$ be holomorphic in $|z|<R$, $f'(z)\neq 0$, and $n>0$ is an integer. Show that there exists $r>0$ and $g(z)$ holomorphic in $|z|<r$ such that $f(z^n)=f(0)+g(z)^n$. The local mapping theorem says that if $f(z)-f(0)$ has a zero of order $n$ at $0$, then we can choose $r$ so that there exists $\epsilon$ such that for all $a$ with $|a-f(0)|<\epsilon$, the equation $f(z)=a$ has exactly $n$ roots in the disk $|z|<r$. Here, $f(z^n)-f(0)$ has a zero of order at least $1$, since $f(0)-f(0)=0$, but do we know exactly what order it has?","Let $f(z)$ be holomorphic in $|z|<R$, $f'(z)\neq 0$, and $n>0$ is an integer. Show that there exists $r>0$ and $g(z)$ holomorphic in $|z|<r$ such that $f(z^n)=f(0)+g(z)^n$. The local mapping theorem says that if $f(z)-f(0)$ has a zero of order $n$ at $0$, then we can choose $r$ so that there exists $\epsilon$ such that for all $a$ with $|a-f(0)|<\epsilon$, the equation $f(z)=a$ has exactly $n$ roots in the disk $|z|<r$. Here, $f(z^n)-f(0)$ has a zero of order at least $1$, since $f(0)-f(0)=0$, but do we know exactly what order it has?",,['complex-analysis']
89,Rational functions with absolute value $1$ on $\mathbb{S}^1$,Rational functions with absolute value  on,1 \mathbb{S}^1,This is a question in Complex Analysis . It should not be too difficult but I am missing the trick. The question asks us to find general form of rational functions $R:\mathbb{C}\to\mathbb{C}$ such that $|R(z)|=1$ for all $|z|=1$. It then asks us to find a relation between poles and zeros of such functions. I have not made much progress. But I know all $z^{k} (k\in\mathbb{Z})$ satisfies the condition. Their zeros are $0$ (or $\infty$)  inverse to their poles $\infty$ (or $0$). Another direction I thought about was that if $R(z)$ is such a function then so is $R(1/z)$. Thanks very much!,This is a question in Complex Analysis . It should not be too difficult but I am missing the trick. The question asks us to find general form of rational functions $R:\mathbb{C}\to\mathbb{C}$ such that $|R(z)|=1$ for all $|z|=1$. It then asks us to find a relation between poles and zeros of such functions. I have not made much progress. But I know all $z^{k} (k\in\mathbb{Z})$ satisfies the condition. Their zeros are $0$ (or $\infty$)  inverse to their poles $\infty$ (or $0$). Another direction I thought about was that if $R(z)$ is such a function then so is $R(1/z)$. Thanks very much!,,"['complex-analysis', 'analysis']"
90,If $f^2$ and $f^3$ are analytic prove that $f$ is analytic at every point of $\mathbb{C}$. [duplicate],If  and  are analytic prove that  is analytic at every point of . [duplicate],f^2 f^3 f \mathbb{C},"This question already has answers here : Proving that if $f: \mathbb{C} \to \mathbb{C} $ is a continuous function with $f^2, f^3$ analytic, then $f$ is also analytic (2 answers) Closed 11 years ago . Let $f : \mathbb{C} \to \mathbb{C}$ be continuous. If $f^2$ and $f^3$ are analytic prove that $f$ is analytic at every point of $\mathbb{C}$. if $f^2$ has no zero then $f=f^3/f^2$ and then it is analytic.but if $f^2$ has zero then how can I able to proceed.help me please.","This question already has answers here : Proving that if $f: \mathbb{C} \to \mathbb{C} $ is a continuous function with $f^2, f^3$ analytic, then $f$ is also analytic (2 answers) Closed 11 years ago . Let $f : \mathbb{C} \to \mathbb{C}$ be continuous. If $f^2$ and $f^3$ are analytic prove that $f$ is analytic at every point of $\mathbb{C}$. if $f^2$ has no zero then $f=f^3/f^2$ and then it is analytic.but if $f^2$ has zero then how can I able to proceed.help me please.",,['complex-analysis']
91,Solutions of $f(f(z)) = e^z$,Solutions of,f(f(z)) = e^z,"It is my impression that if we find a function f(z) that satisfies $$f(f(z)) = e^z $$ there is only one point z that satisfies the relation. This dawned on me when I noticed that the pesky z that kept popping up in my attempts to look at the problem was the one my book proposed I start with, to wit: $z_o = 0.318 + 1.337i.$ So the joke was on me. Now I would like to prove this. I would instinctively begin by assuming there was a $z \neq z_o$ and deriving a contradiction. Hopefully I will make some progress before an answer is posted but I am sure I will miss nuances. Maybe it's as simple as showing that $\log^nz$ has a fixed point, which I don't know to be true. Thanks for any insights.","It is my impression that if we find a function f(z) that satisfies $$f(f(z)) = e^z $$ there is only one point z that satisfies the relation. This dawned on me when I noticed that the pesky z that kept popping up in my attempts to look at the problem was the one my book proposed I start with, to wit: $z_o = 0.318 + 1.337i.$ So the joke was on me. Now I would like to prove this. I would instinctively begin by assuming there was a $z \neq z_o$ and deriving a contradiction. Hopefully I will make some progress before an answer is posted but I am sure I will miss nuances. Maybe it's as simple as showing that $\log^nz$ has a fixed point, which I don't know to be true. Thanks for any insights.",,"['complex-analysis', 'tetration']"
92,Multiple choice question about an entire function $f:\Bbb{C}\to\Bbb{C}$ and the function $g :\Bbb{C}\to\Bbb{C} $ defined by $ g(z)= f(z) - f(z+1)$,Multiple choice question about an entire function  and the function  defined by,f:\Bbb{C}\to\Bbb{C} g :\Bbb{C}\to\Bbb{C}   g(z)= f(z) - f(z+1),"Let $ f: \mathbb{C} \rightarrow  \mathbb{C} $ be an entire function and let $g : \mathbb{C} \rightarrow \mathbb{C} $ be defined by  $$g(z)= f(z) - f(z+1)$$ for all $ z\in \mathbb{C}$. Which of the options are correct : if $ f(\frac{1}{n}) = 0 $ for all positive integers n, then $f$ is a constant function. if $ f(n) = 0 $ for all positive integers n, then $f$ is a constant function. if $ f(\frac{1}{n}) = f(\frac{1}{n}+1)$ for all positive integers n, then $g$ is a constant function. $ f(n) = f(n+1) $  for all positive integers $n$, then $g$ is a constant function Please suggest which of the options are correct. Using the Identity theorem, the options 1 and 3 seem to be correct as in both cases, the sequence of zeros for $\,f\,$ and $\,g\,$  is $ < \frac{1}{n} >$ that converges to zero which belongs to $\Bbb C$. Therefore, in both cases $\,f\,$ and $\,g\,$ are identically equal to zero.  But in (2) and (4), we arrive for both $\,f\,$ and $\,g\,$, at the zeros sequence $ <{n}>$ diverges to infinity which does not ensure the required conclusion.","Let $ f: \mathbb{C} \rightarrow  \mathbb{C} $ be an entire function and let $g : \mathbb{C} \rightarrow \mathbb{C} $ be defined by  $$g(z)= f(z) - f(z+1)$$ for all $ z\in \mathbb{C}$. Which of the options are correct : if $ f(\frac{1}{n}) = 0 $ for all positive integers n, then $f$ is a constant function. if $ f(n) = 0 $ for all positive integers n, then $f$ is a constant function. if $ f(\frac{1}{n}) = f(\frac{1}{n}+1)$ for all positive integers n, then $g$ is a constant function. $ f(n) = f(n+1) $  for all positive integers $n$, then $g$ is a constant function Please suggest which of the options are correct. Using the Identity theorem, the options 1 and 3 seem to be correct as in both cases, the sequence of zeros for $\,f\,$ and $\,g\,$  is $ < \frac{1}{n} >$ that converges to zero which belongs to $\Bbb C$. Therefore, in both cases $\,f\,$ and $\,g\,$ are identically equal to zero.  But in (2) and (4), we arrive for both $\,f\,$ and $\,g\,$, at the zeros sequence $ <{n}>$ diverges to infinity which does not ensure the required conclusion.",,['complex-analysis']
93,Zeros of a holomorphic function on the boundary of a closed region,Zeros of a holomorphic function on the boundary of a closed region,,"Is there a holomorphic nonzero function on a closed bounded connected subset of $\mathbb{C}$ which has infinitely many zeros on the boundary and at most a finitely many zeros in the interior (open connected subset of the closed set)? If there are infinitely many zeros in the interior, I am not certain whether the function reduces identically to zero by using limit point compactness and constructing a sequence of points with an accumulation point which is certainly in the closure but may not be in the interior. For clarity : By ""holomorphic on a closed bounded connected subset"", I mean holomorphic in the interior and continuous on the boundary since holomorphicity is defined only over open sets. For e.g., consider a nonzero function continuous on the closed unit disc and holomorphic on the open unit disc. Can it have only finitely many zeros on the open disc and infinitely many zeros on the boundary? Thanks.","Is there a holomorphic nonzero function on a closed bounded connected subset of $\mathbb{C}$ which has infinitely many zeros on the boundary and at most a finitely many zeros in the interior (open connected subset of the closed set)? If there are infinitely many zeros in the interior, I am not certain whether the function reduces identically to zero by using limit point compactness and constructing a sequence of points with an accumulation point which is certainly in the closure but may not be in the interior. For clarity : By ""holomorphic on a closed bounded connected subset"", I mean holomorphic in the interior and continuous on the boundary since holomorphicity is defined only over open sets. For e.g., consider a nonzero function continuous on the closed unit disc and holomorphic on the open unit disc. Can it have only finitely many zeros on the open disc and infinitely many zeros on the boundary? Thanks.",,['complex-analysis']
94,A question from Conway's Complex Functions textbook,A question from Conway's Complex Functions textbook,,"the question is from Conway's Functions of One Complex Variable , volume I ,second edition, chapter VI section 1, exercise 7. Let $f$ be analytic in the disk $B(0,R)$ and for $0 \leq r \leq R$ define $$A(r)=\max\{\operatorname{Re} f(z) : |z|=r\}.$$ Show that unless $f$ is constant, $A(r)$ is strictly increasing function of $r$. Now obviously from the maximum modulus we must have for any $r_1< r_2$ and $|z|=r_1$,$|\zeta|=r_2$, $|f(z)|\geq |f(\zeta)|\geq \operatorname{Re} f(\zeta)$, but don't see how use for the real parts here. Only hints if you can. Thanks.","the question is from Conway's Functions of One Complex Variable , volume I ,second edition, chapter VI section 1, exercise 7. Let $f$ be analytic in the disk $B(0,R)$ and for $0 \leq r \leq R$ define $$A(r)=\max\{\operatorname{Re} f(z) : |z|=r\}.$$ Show that unless $f$ is constant, $A(r)$ is strictly increasing function of $r$. Now obviously from the maximum modulus we must have for any $r_1< r_2$ and $|z|=r_1$,$|\zeta|=r_2$, $|f(z)|\geq |f(\zeta)|\geq \operatorname{Re} f(\zeta)$, but don't see how use for the real parts here. Only hints if you can. Thanks.",,['complex-analysis']
95,Latest known result on Lindelöf hypothesis,Latest known result on Lindelöf hypothesis,,"The Phragmén–Lindelöf theorem gives a consequence of the Riemann hypothesis, viz., the Lindelöf hypothesis . As such this is weaker than Riemann hypothesis; but it is still considered that even a proof of this weaker result will be a breakthrough. Question: What is the strongest known result yet on the Lindelöf hypothesis?","The Phragmén–Lindelöf theorem gives a consequence of the Riemann hypothesis, viz., the Lindelöf hypothesis . As such this is weaker than Riemann hypothesis; but it is still considered that even a proof of this weaker result will be a breakthrough. Question: What is the strongest known result yet on the Lindelöf hypothesis?",,['number-theory']
96,$\int_C \frac{f(z)}{(z-1)^{2020}}dz$,,\int_C \frac{f(z)}{(z-1)^{2020}}dz,"Let $f(z)=u(x,y)+iv(x,y)$ be an entire function such that $au+bv\ge \ln(ab), a>1,b>1.$ Then evaluate $$\int_C \frac{f(z)}{(z-1)^{2020}}dz,$$ where $C$ is an equilateral triangle of side $1$ with centroid at $z=1.$ It seems that I can use the Cauchy's Integral formula here and by doing so the integral would be $$\frac{2\pi i}{2019!}f^{(2019)}(1)$$ I have no idea how to connect the first part of the question in solving this problem. Help please",Let be an entire function such that Then evaluate where is an equilateral triangle of side with centroid at It seems that I can use the Cauchy's Integral formula here and by doing so the integral would be I have no idea how to connect the first part of the question in solving this problem. Help please,"f(z)=u(x,y)+iv(x,y) au+bv\ge \ln(ab), a>1,b>1. \int_C \frac{f(z)}{(z-1)^{2020}}dz, C 1 z=1. \frac{2\pi i}{2019!}f^{(2019)}(1)",['complex-analysis']
97,Struggling to Understand Algorithm for Displaying Polynomial Matings with Julia Sets,Struggling to Understand Algorithm for Displaying Polynomial Matings with Julia Sets,,"I'm working on creating a program that visualizes projected Julia Sets on a Riemann Sphere (such as my video here ) when I came across this website visualizing matings between Julia Sets, and I want to recreate them for my own program (such as this video ). However, with any resource that I've read that explains the process, I can't seem to wrap my mind around what's going on... I'm not sure if I simply don't yet have the formal education required (my knowledge of complex analysis is only limited to visualizing iterated fractals), or if these sources are just hard to understand. What I want to learn specifically about is what is described here (from the previous website - what's in bold is what I want to learn, and what's italicized is what I have a hard time conceptually understanding): ""A progressive interpolation was introduced, between the two polynomial Julia sets and their mating. It consists in gluing equipotentials together and gives a holomorphic dynamical system between different spheres (this was observed by Milnor). This dynamical systems gives an easy method for drawing a conformally correct picture of the deformation of the polynomial Julia sets under the equipotential gluing: this method was explained to me by Buff. The result is an image which depends on the potential. This is what the movies show: the potential starts high and slowly approaches 0 ."" Essentially, what I'm looking for is given: some point z on the complex plane (I already know how to project this onto the Riemann Sphere) two filled Julia Set coordinates $c_1$ and $c_2$ (for example, the Basilica and Rabbit - eventually I hope to move beyond two) some value t that represents the value of the potential that decreases to 0 (for the mating animation) some value n that represents the maximum escape-time iterations some value b that represents the bailout value ... do some math that calculates the color for that point (just like the escape-time algorithm - though this is the limit of my understanding, so I'm hoping that I can visualize the matings in the same way) when it's projected on the Riemann Sphere. Is this possible? I would be grateful for anything to help my understanding with this! If I'm in too far in over my head with this kind of math, then I'd also be satisfied with a copy-and-paste solution for my particular goal here. I already tried reading these papers: Pasting Together Julia Sets: A Worked Out Example of Mating The Medusa Algorithm for Polynomial Matings The Thurston Algorithm for Quadratic Matings Slow mating and equipotential gluing Slow mating of quadratic Julia sets I did consider putting this on StackOverflow instead, but I think this is more of a math question than a programming one. EDIT: After a week of going through Claude's code , I finally figured out an algorithm to which I can display the slow mating in real time! Its implementation in my project is not without a couple of bugs, but I was able to get the basic animation working (I've made some videos to show the mating of Basilica vs. Rabbit , its inverse , and its projection on the Riemann Sphere). The algorithm is as follows: INITIALIZATION Constants R1 >= 5 R2 = R1 * R1 R4 = R2 * R2 Variables # the two Julia Sets to slow mate Complex p Complex q  # mating presets int mating_iterations int intermediate_steps  # Julia Set presets int julia_iterations float bailout  # image presets int width int height      # intermediate path segments Complex x [mating_iterations * intermediate_steps] Complex y [mating_iterations * intermediate_steps]  # store inverse of pullback function (https://mathr.co.uk/blog/2020-01-16_slow_mating_of_quadratic_julia_sets.html) Complex ma [mating_iterations * intermediate_steps] Complex mb [mating_iterations * intermediate_steps] Complex mc [mating_iterations * intermediate_steps] Complex md [mating_iterations * intermediate_steps]  # what's sent to the GPU Complex ma_frame [mating_iterations]; Complex mb_frame [mating_iterations]; Complex mc_frame [mating_iterations]; Complex md_frame [mating_iterations];  # Compute potentials and potential radii float t[intermediate_steps] float R[intermediate_steps]  for s: the count of intermediate segments {     t[s] = (s + .5) / intermediate_steps          R[s] = exp(pow(2, 1 - t[s]) * log(R1)) }   p_i = 0     # nth iteration of the p Julia Set q_i = 0     # nth iteration of the q Julia Set  # Calculate path arrays (Wolf Jung's equations 20 and 21) for i: each frame in mating_iterations*intermediate_steps {     # i = intermediate_steps * n + s     # for each n:     #     for each s     int s = i % intermediate_steps;     int n = (i - s) / intermediate_steps;    # this is not needed here           # Equation 20            1 + ((1 - t[s]) * q / R2)                p_i / R[s]     x[i] = ------------------------- * -------------------------------------            1 + ((1 - t[s]) * p / R2)   1 + ((1 - t[s]) * q / R4 * (p_i - p))      # Alternatively, if R1 = 1e10     x[i] = p_i / R[s]        # Equation 21            1 + (1 - t[s]) * q / R2   R[s]     y[i] = ----------------------- * ---- * (1 + ((1 - t[s]) * p / R4 * (q_i - q)))            1 + (1 - t[s]) * p / R2   q_i      # Alternatively, if R1 = 1e10     y[i] = R[s] / q_i                      if (s == intermediate_steps - 1)    # last 's' before new 'n'     {         p_i = p_i^2 + p         q_i = q_i^2 + q     } } Prior to point calculation (CPU Render Loop) # This could've be done using a nested for loop, but I needed to be consistent with my notation so I could understand the algorithm easier  for i: each frame in mating_iterations*intermediate_steps {     # i = intermediate_steps * n + s     # for each n:     #     for each s     int s = i % intermediate_steps;     int n = (i- s) / intermediate_steps;              int first = intermediate_steps + s     int s_prev = (s + intermediate_steps - 1) % intermediate_steps              if (n > 0)     {         // Pull back x and y (Wolf Jung's Equation 22)         for k: count of total mating iterations - current mating iteration (n)         {             int k_next = k + 1             int next = intermediate_steps * k_next + s             int prev = intermediate_steps * k + s_prev                            (  1 - y[first]     x[next] - x[first]  )             z_x[k] = sqrt(  ------------  *  ------------------  )                          (  1 - x[first]     x[next] - y[first]  )                                                                                                                                            x[first]                                                  1 - --------                          (  (1 - y[first])           y[next]   )             z_y[k] = sqrt(  --------------  *  --------------  )                          (  (1 - x[first])           y[first]  )                                                  1 - --------                                                                                                                       y[next]                      // choose sign by continuity             if (length(-z_x[k] - x[prev]) < length(z_x[k] - x[prev]))             {                 z_x[k] = -z_x[k]             }             if (length(-z_y[k] - y[prev]) < length(z_y[k] - y[prev]))             {                 z_y[k] = -z_y[k]             }         }                  // copy results into path arrays         for k: count of total mating iterations - current iteration (n)         {             x[intermediate_steps * k + s] = z_x[k]             y[intermediate_steps * k + s] = z_y[k]         }     }          a = x[intermediate_steps + s]     b = y[intermediate_steps + s]     ma[i] = b * (1 - a)     mb[i] = a * (b - 1)     mc[i] = 1 - a     md[i] = b - 1          for k: 0 to current mating iteration (n)     {         ma_frame[k] = ma[intermediate_steps * k + s]         mb_frame[k] = mb[intermediate_steps * k + s]         mc_frame[k] = mc[intermediate_steps * k + s]         md_frame[k] = md[intermediate_steps * k + s]     }      # SEND VARIABLES TO GPU         julia_iterations         bailout         p         q         R (taken from 'R[s]')         current_mating_iteration (taken from 'n')         ma_frame         mb_frame         mc_frame         md_frame } Apply for each point on the complex plane (GPU Fragment Shader: for each pixel on the screen) z = point on complex plane  for k: starting from current_mating_iteration and decreasing to zero {         ma_frame[k] * z + mb_frame[k]     z = -----------------------------         mc_frame[k] * z + md_frame[k] }      if (length(z) < 1) {     c = p     w = R * z } else {     c = q     w = R / z    # note: this is complex division }   for i: the rest of the regular Julia Set iterations (julia_iterations - n) {     break if (length(z) > bailout)          w = w^2 + c }  pixel_color = based on w","I'm working on creating a program that visualizes projected Julia Sets on a Riemann Sphere (such as my video here ) when I came across this website visualizing matings between Julia Sets, and I want to recreate them for my own program (such as this video ). However, with any resource that I've read that explains the process, I can't seem to wrap my mind around what's going on... I'm not sure if I simply don't yet have the formal education required (my knowledge of complex analysis is only limited to visualizing iterated fractals), or if these sources are just hard to understand. What I want to learn specifically about is what is described here (from the previous website - what's in bold is what I want to learn, and what's italicized is what I have a hard time conceptually understanding): ""A progressive interpolation was introduced, between the two polynomial Julia sets and their mating. It consists in gluing equipotentials together and gives a holomorphic dynamical system between different spheres (this was observed by Milnor). This dynamical systems gives an easy method for drawing a conformally correct picture of the deformation of the polynomial Julia sets under the equipotential gluing: this method was explained to me by Buff. The result is an image which depends on the potential. This is what the movies show: the potential starts high and slowly approaches 0 ."" Essentially, what I'm looking for is given: some point z on the complex plane (I already know how to project this onto the Riemann Sphere) two filled Julia Set coordinates and (for example, the Basilica and Rabbit - eventually I hope to move beyond two) some value t that represents the value of the potential that decreases to 0 (for the mating animation) some value n that represents the maximum escape-time iterations some value b that represents the bailout value ... do some math that calculates the color for that point (just like the escape-time algorithm - though this is the limit of my understanding, so I'm hoping that I can visualize the matings in the same way) when it's projected on the Riemann Sphere. Is this possible? I would be grateful for anything to help my understanding with this! If I'm in too far in over my head with this kind of math, then I'd also be satisfied with a copy-and-paste solution for my particular goal here. I already tried reading these papers: Pasting Together Julia Sets: A Worked Out Example of Mating The Medusa Algorithm for Polynomial Matings The Thurston Algorithm for Quadratic Matings Slow mating and equipotential gluing Slow mating of quadratic Julia sets I did consider putting this on StackOverflow instead, but I think this is more of a math question than a programming one. EDIT: After a week of going through Claude's code , I finally figured out an algorithm to which I can display the slow mating in real time! Its implementation in my project is not without a couple of bugs, but I was able to get the basic animation working (I've made some videos to show the mating of Basilica vs. Rabbit , its inverse , and its projection on the Riemann Sphere). The algorithm is as follows: INITIALIZATION Constants R1 >= 5 R2 = R1 * R1 R4 = R2 * R2 Variables # the two Julia Sets to slow mate Complex p Complex q  # mating presets int mating_iterations int intermediate_steps  # Julia Set presets int julia_iterations float bailout  # image presets int width int height      # intermediate path segments Complex x [mating_iterations * intermediate_steps] Complex y [mating_iterations * intermediate_steps]  # store inverse of pullback function (https://mathr.co.uk/blog/2020-01-16_slow_mating_of_quadratic_julia_sets.html) Complex ma [mating_iterations * intermediate_steps] Complex mb [mating_iterations * intermediate_steps] Complex mc [mating_iterations * intermediate_steps] Complex md [mating_iterations * intermediate_steps]  # what's sent to the GPU Complex ma_frame [mating_iterations]; Complex mb_frame [mating_iterations]; Complex mc_frame [mating_iterations]; Complex md_frame [mating_iterations];  # Compute potentials and potential radii float t[intermediate_steps] float R[intermediate_steps]  for s: the count of intermediate segments {     t[s] = (s + .5) / intermediate_steps          R[s] = exp(pow(2, 1 - t[s]) * log(R1)) }   p_i = 0     # nth iteration of the p Julia Set q_i = 0     # nth iteration of the q Julia Set  # Calculate path arrays (Wolf Jung's equations 20 and 21) for i: each frame in mating_iterations*intermediate_steps {     # i = intermediate_steps * n + s     # for each n:     #     for each s     int s = i % intermediate_steps;     int n = (i - s) / intermediate_steps;    # this is not needed here           # Equation 20            1 + ((1 - t[s]) * q / R2)                p_i / R[s]     x[i] = ------------------------- * -------------------------------------            1 + ((1 - t[s]) * p / R2)   1 + ((1 - t[s]) * q / R4 * (p_i - p))      # Alternatively, if R1 = 1e10     x[i] = p_i / R[s]        # Equation 21            1 + (1 - t[s]) * q / R2   R[s]     y[i] = ----------------------- * ---- * (1 + ((1 - t[s]) * p / R4 * (q_i - q)))            1 + (1 - t[s]) * p / R2   q_i      # Alternatively, if R1 = 1e10     y[i] = R[s] / q_i                      if (s == intermediate_steps - 1)    # last 's' before new 'n'     {         p_i = p_i^2 + p         q_i = q_i^2 + q     } } Prior to point calculation (CPU Render Loop) # This could've be done using a nested for loop, but I needed to be consistent with my notation so I could understand the algorithm easier  for i: each frame in mating_iterations*intermediate_steps {     # i = intermediate_steps * n + s     # for each n:     #     for each s     int s = i % intermediate_steps;     int n = (i- s) / intermediate_steps;              int first = intermediate_steps + s     int s_prev = (s + intermediate_steps - 1) % intermediate_steps              if (n > 0)     {         // Pull back x and y (Wolf Jung's Equation 22)         for k: count of total mating iterations - current mating iteration (n)         {             int k_next = k + 1             int next = intermediate_steps * k_next + s             int prev = intermediate_steps * k + s_prev                            (  1 - y[first]     x[next] - x[first]  )             z_x[k] = sqrt(  ------------  *  ------------------  )                          (  1 - x[first]     x[next] - y[first]  )                                                                                                                                            x[first]                                                  1 - --------                          (  (1 - y[first])           y[next]   )             z_y[k] = sqrt(  --------------  *  --------------  )                          (  (1 - x[first])           y[first]  )                                                  1 - --------                                                                                                                       y[next]                      // choose sign by continuity             if (length(-z_x[k] - x[prev]) < length(z_x[k] - x[prev]))             {                 z_x[k] = -z_x[k]             }             if (length(-z_y[k] - y[prev]) < length(z_y[k] - y[prev]))             {                 z_y[k] = -z_y[k]             }         }                  // copy results into path arrays         for k: count of total mating iterations - current iteration (n)         {             x[intermediate_steps * k + s] = z_x[k]             y[intermediate_steps * k + s] = z_y[k]         }     }          a = x[intermediate_steps + s]     b = y[intermediate_steps + s]     ma[i] = b * (1 - a)     mb[i] = a * (b - 1)     mc[i] = 1 - a     md[i] = b - 1          for k: 0 to current mating iteration (n)     {         ma_frame[k] = ma[intermediate_steps * k + s]         mb_frame[k] = mb[intermediate_steps * k + s]         mc_frame[k] = mc[intermediate_steps * k + s]         md_frame[k] = md[intermediate_steps * k + s]     }      # SEND VARIABLES TO GPU         julia_iterations         bailout         p         q         R (taken from 'R[s]')         current_mating_iteration (taken from 'n')         ma_frame         mb_frame         mc_frame         md_frame } Apply for each point on the complex plane (GPU Fragment Shader: for each pixel on the screen) z = point on complex plane  for k: starting from current_mating_iteration and decreasing to zero {         ma_frame[k] * z + mb_frame[k]     z = -----------------------------         mc_frame[k] * z + md_frame[k] }      if (length(z) < 1) {     c = p     w = R * z } else {     c = q     w = R / z    # note: this is complex division }   for i: the rest of the regular Julia Set iterations (julia_iterations - n) {     break if (length(z) > bailout)          w = w^2 + c }  pixel_color = based on w",c_1 c_2,"['complex-analysis', 'recreational-mathematics', 'fractals', 'complex-dynamics']"
98,$f$ is analytic if $f$ agrees with some holomorphic function on every triplet,is analytic if  agrees with some holomorphic function on every triplet,f f,"I came across the following problem asked in a prelim exam. Let $f$ be a function defined on the unit disk with the property that for every triplet $a, b, c$ there exists a holomorphic function $g$ such that $g$ is bounded by $1$ on the unit disk and $g(a)=f(a), g(b)=f(b)$ and $g(c)=f(c).$ Show that $f$ is holomorphic on disk and bounded by $1$ . The fact that $f$ is bounded by $1$ is trivial. Because at every point it agrees with a function which is in turn bounded by 1. But I am trying to prove the differentiablity of $f$ and I am not able to. I was thinking to show that $f$ is differentiable at $0$ and showing that is enough to do so. I first assume that $f(0)=0.$ To prove that $f$ is differentiable at zero, I take a sequence of points $z_n\to 0$ and obtain a sequence of holomorphic functions $g_n$ such that $f(z_n)=g_n(z_n)$ . I can see that $g_n$ is normal, and hence has a convergent subsequence. I choose such a subsequence, and denote the limit by $g$ . I want to show that $f’(0)=g’(0).$ I am having problem because I can get the convergence of $g_n$ only along a subsequence, and along different subsequence I may possibly have different limits. Any suggestion is welcome.","I came across the following problem asked in a prelim exam. Let be a function defined on the unit disk with the property that for every triplet there exists a holomorphic function such that is bounded by on the unit disk and and Show that is holomorphic on disk and bounded by . The fact that is bounded by is trivial. Because at every point it agrees with a function which is in turn bounded by 1. But I am trying to prove the differentiablity of and I am not able to. I was thinking to show that is differentiable at and showing that is enough to do so. I first assume that To prove that is differentiable at zero, I take a sequence of points and obtain a sequence of holomorphic functions such that . I can see that is normal, and hence has a convergent subsequence. I choose such a subsequence, and denote the limit by . I want to show that I am having problem because I can get the convergence of only along a subsequence, and along different subsequence I may possibly have different limits. Any suggestion is welcome.","f a, b, c g g 1 g(a)=f(a), g(b)=f(b) g(c)=f(c). f 1 f 1 f f 0 f(0)=0. f z_n\to 0 g_n f(z_n)=g_n(z_n) g_n g f’(0)=g’(0). g_n",['complex-analysis']
99,Inverse Laplace transform from a power series with finite radius of convergence,Inverse Laplace transform from a power series with finite radius of convergence,,"Suppose we are given some function $f(t)$ define on $t\in [0,\infty)$ .   Then, the Laplace of this function is given by \begin{align} F(s)= \int_0^\infty e^{-st} f(t) dt \end{align} where $s=\sigma+i\omega$ , and the inverst Laplace transform is given by \begin{align} L^{-1}[F(s)](t)=\frac{1}{ 2 \pi i} \lim_{T \to \infty} \oint_{c-iT}^{c+iT} e^{ts} F(s) ds, \end{align} where $c$ is some real constant in the region of convergnce of $F(s)$ . My question Suppose that we are given a Laplace transform in the form of a power series only: \begin{align} F(s)=\sum_{n=0}^\infty a_n s^n \end{align} where the radius of convergence is given by $|s|<r$ . How can we invert $F(s)$ from this the power series representation?   The issue I have here is that contour integration needs to be from $c-iT$ to $c+iT$ but the radius of convergence is finite. Can the inversion be done here in some way? Edit: Here is a concrete example. Consider \begin{align} F(s)=\sum_{n=0}^\infty a_n s^n \end{align} where $a_n=2^{-n-2} (i(1+i)^{n+1}+(i-1)^n) $ .  This power series has a radis of convergence $r=\sqrt{2}$ . In fact, the above power series corepsonds to a function \begin{align} F(s)= \frac{1}{1+(1+s)^2}, \end{align} which has an inverse trasform given by \begin{align} f(t)= e^{-t} \sin(t) u(t) \end{align} where $u(t)$ is the step function. However, if we don't know what the actual function is, how would we use the power series representation to find the inverse.","Suppose we are given some function define on .   Then, the Laplace of this function is given by where , and the inverst Laplace transform is given by where is some real constant in the region of convergnce of . My question Suppose that we are given a Laplace transform in the form of a power series only: where the radius of convergence is given by . How can we invert from this the power series representation?   The issue I have here is that contour integration needs to be from to but the radius of convergence is finite. Can the inversion be done here in some way? Edit: Here is a concrete example. Consider where .  This power series has a radis of convergence . In fact, the above power series corepsonds to a function which has an inverse trasform given by where is the step function. However, if we don't know what the actual function is, how would we use the power series representation to find the inverse.","f(t) t\in [0,\infty) \begin{align}
F(s)= \int_0^\infty e^{-st} f(t) dt
\end{align} s=\sigma+i\omega \begin{align}
L^{-1}[F(s)](t)=\frac{1}{ 2 \pi i} \lim_{T \to \infty} \oint_{c-iT}^{c+iT} e^{ts} F(s) ds,
\end{align} c F(s) \begin{align}
F(s)=\sum_{n=0}^\infty a_n s^n
\end{align} |s|<r F(s) c-iT c+iT \begin{align}
F(s)=\sum_{n=0}^\infty a_n s^n
\end{align} a_n=2^{-n-2} (i(1+i)^{n+1}+(i-1)^n)  r=\sqrt{2} \begin{align}
F(s)= \frac{1}{1+(1+s)^2},
\end{align} \begin{align}
f(t)= e^{-t} \sin(t) u(t)
\end{align} u(t)","['complex-analysis', 'power-series', 'laplace-transform']"
