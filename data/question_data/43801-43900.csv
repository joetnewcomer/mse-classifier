,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Rings such that every module is a direct sum of generator modules,Rings such that every module is a direct sum of generator modules,,"Is there a classification of those rings $R$ for which the category of left $R$ -modules $\mathbf{Mod}(R)$ is generated by a small set of left $R$ -modules under direct sums? For example, every semisimple ring has this property, since every left $R$ -module is a direct sum of simple modules, which in turn are isomorphic to $R/I$ for some maximal left ideal $I \subseteq R$ . More generally, every Artinian principal ideal ring has the property that every left $R$ -module is a direct sum of cyclic modules. But in my question I don't require the generator modules to be cyclic.","Is there a classification of those rings for which the category of left -modules is generated by a small set of left -modules under direct sums? For example, every semisimple ring has this property, since every left -module is a direct sum of simple modules, which in turn are isomorphic to for some maximal left ideal . More generally, every Artinian principal ideal ring has the property that every left -module is a direct sum of cyclic modules. But in my question I don't require the generator modules to be cyclic.",R R \mathbf{Mod}(R) R R R/I I \subseteq R R,"['abstract-algebra', 'ring-theory', 'modules', 'direct-sum', 'semi-simple-rings']"
1,Find an element of order $p$ in a non-abelian group $G$ of order $p^3$ where $p$ is an odd prime,Find an element of order  in a non-abelian group  of order  where  is an odd prime,p G p^3 p,"Problem. Let $p$ be an odd prime and $G$ be a non-abelian group of order $p^3$ . Suppose there exists an element $x\in G$ of order $p^2$ . Find an element $y\in G\setminus\langle x\rangle$ of order $p$ . It is true, by Cauchy's theorem or some other theorems, that $G$ has an element of order $p$ . However, we are not sure whether it lies in $\langle x\rangle$ because $x^p,x^{2p},\ldots,x^{(p-1)p}$ all have order $p$ . I tried another approach: The number of element in $G$ of order $p^2$ must be a power of $$\varphi(p^2)=p(p-1),$$ where $\varphi$ is the Euler's totient function. There are $p^3-1$ non-identity elements in $G$ . We have $$p^3-1=p(p-1)(p+1)+p-1=(p+1)\varphi(p^2)+p-1.$$ This also implies that $G$ has an element of order $p$ , but the remainder $p-1$ is problematic as we already have $p-1$ elements of order $p$ above. Does anyone have good ideas on this question?","Problem. Let be an odd prime and be a non-abelian group of order . Suppose there exists an element of order . Find an element of order . It is true, by Cauchy's theorem or some other theorems, that has an element of order . However, we are not sure whether it lies in because all have order . I tried another approach: The number of element in of order must be a power of where is the Euler's totient function. There are non-identity elements in . We have This also implies that has an element of order , but the remainder is problematic as we already have elements of order above. Does anyone have good ideas on this question?","p G p^3 x\in G p^2 y\in G\setminus\langle x\rangle p G p \langle x\rangle x^p,x^{2p},\ldots,x^{(p-1)p} p G p^2 \varphi(p^2)=p(p-1), \varphi p^3-1 G p^3-1=p(p-1)(p+1)+p-1=(p+1)\varphi(p^2)+p-1. G p p-1 p-1 p","['abstract-algebra', 'group-theory', 'finite-groups']"
2,Does existence of free submonoid implies free subgroup,Does existence of free submonoid implies free subgroup,,"Suppose that we have group $G$ that, regarded as a monoid, has a submonoid $M$ , which is free with $r$ generators. Does it imply that is has a subgroup $H$ , free and with $r$ generators? For $r=1$ it is clear, and the case $r=2$ will be, I think, the only interesting one. The first approach might be that $H=\langle M \rangle$ works, but that's not true: for $$ A=\begin{pmatrix}1&0\\1&1 \end{pmatrix}, \textrm{ and }B=\begin{pmatrix}1&1\\0&1 \end{pmatrix} $$ it's not hard to check that they generate a free submonoid, but we have $(A B^{-1} A)^4 = I$ . However, $\langle A^2,B^2 \rangle$ is free, so it isn't a counterexample.","Suppose that we have group that, regarded as a monoid, has a submonoid , which is free with generators. Does it imply that is has a subgroup , free and with generators? For it is clear, and the case will be, I think, the only interesting one. The first approach might be that works, but that's not true: for it's not hard to check that they generate a free submonoid, but we have . However, is free, so it isn't a counterexample.","G M r H r r=1 r=2 H=\langle M \rangle  A=\begin{pmatrix}1&0\\1&1 \end{pmatrix}, \textrm{ and }B=\begin{pmatrix}1&1\\0&1 \end{pmatrix}  (A B^{-1} A)^4 = I \langle A^2,B^2 \rangle","['abstract-algebra', 'group-theory']"
3,Calculating intersection multiplicities explicitly with Serre's formula,Calculating intersection multiplicities explicitly with Serre's formula,,"Let's say I want to explicitly calculate the intersection multiplicity of two subvarieties of $\Bbb A^n_k$ using Serre's Tor-formula (involving as little homological algebra as possible). A typical example [Hartshorne, p.428] consists of two planes in $\Bbb A^4_k$ (we can assume $k$ algebraically closed, if needed) meeting at a point, $X=V(I)$ , with $$I=(x,y)\cap(z,w)=(x,y)(z,w)=(xz,xw,yz,yw)\subset R=k[x,y,z,w],$$ intersecting with a third plane $Y=V(J)$ , with $J=(x-z,y-w)$ . The ""naive"", scheme-theoretic intersection is given by $$\frac{R}{I+J}=\frac{k[x,y,z,w]}{(xz,xw,yz,yw,x-z,y-w)}\cong \frac{k[x,y]}{(x^2,xy,y^2)},$$ which has length 3 (while, clearly, we expect the intersection multiplicity to be 2). Serre's formula gives us the correct multiplicity by defining $$i(X,Y)=\sum_i (-1)^i \operatorname{length} \operatorname{Tor}^R_i(R/I,R/J).$$ We know that for $i=1$ , $\operatorname{Tor}^R_1(R/I,R/J)=(I\cap J)/{IJ}$ . How do we compute this quotient conveniently? (Embarassingly enough, I'm having some trouble calculating generators for $I\cap J$ .) What do we know about $\operatorname{Tor}_i$ for $i\geq 2$ ?","Let's say I want to explicitly calculate the intersection multiplicity of two subvarieties of using Serre's Tor-formula (involving as little homological algebra as possible). A typical example [Hartshorne, p.428] consists of two planes in (we can assume algebraically closed, if needed) meeting at a point, , with intersecting with a third plane , with . The ""naive"", scheme-theoretic intersection is given by which has length 3 (while, clearly, we expect the intersection multiplicity to be 2). Serre's formula gives us the correct multiplicity by defining We know that for , . How do we compute this quotient conveniently? (Embarassingly enough, I'm having some trouble calculating generators for .) What do we know about for ?","\Bbb A^n_k \Bbb A^4_k k X=V(I) I=(x,y)\cap(z,w)=(x,y)(z,w)=(xz,xw,yz,yw)\subset R=k[x,y,z,w], Y=V(J) J=(x-z,y-w) \frac{R}{I+J}=\frac{k[x,y,z,w]}{(xz,xw,yz,yw,x-z,y-w)}\cong \frac{k[x,y]}{(x^2,xy,y^2)}, i(X,Y)=\sum_i (-1)^i \operatorname{length} \operatorname{Tor}^R_i(R/I,R/J). i=1 \operatorname{Tor}^R_1(R/I,R/J)=(I\cap J)/{IJ} I\cap J \operatorname{Tor}_i i\geq 2","['abstract-algebra', 'algebraic-geometry', 'homological-algebra', 'intersection-theory']"
4,"If $A$ and $B$ are subgroups of $G$ such that $[[A, B], B] = 1$, then $[A, B]$ is abelian.","If  and  are subgroups of  such that , then  is abelian.","A B G [[A, B], B] = 1 [A, B]","I am stuck on the following question: If $A$ and $B$ are subgroups of $G$ such that $[[A, B], B] = 1$ , then $[A, B]$ is abelian, where $[X, Y]$ denotes the commutator subgroup of $X$ and $Y$ as usual. I have seen that $[A, B]$ is in the intersection of all the centralizer of each $b\in B$ . And I am trying to show that $B$ is a normal subgroup of $G$ , then it follows that $[A, B] \subseteq Z(B)$ , where $Z(B)$ denotes for the centre of $B$ . Then the result follows. But I have no idea how to show that $B$ is normal in $G$ or maybe I am completely on the wrong way. Anyone can help?","I am stuck on the following question: If and are subgroups of such that , then is abelian, where denotes the commutator subgroup of and as usual. I have seen that is in the intersection of all the centralizer of each . And I am trying to show that is a normal subgroup of , then it follows that , where denotes for the centre of . Then the result follows. But I have no idea how to show that is normal in or maybe I am completely on the wrong way. Anyone can help?","A B G [[A, B], B] = 1 [A, B] [X, Y] X Y [A, B] b\in B B G [A, B] \subseteq Z(B) Z(B) B B G","['abstract-algebra', 'group-theory', 'abelian-groups', 'normal-subgroups']"
5,Splitting field of a polynomial over Z_5,Splitting field of a polynomial over Z_5,,"Find the splitting field of the polynomial $$x^3+x+1$$ over $\mathbb{Z}_5$ . I can see that the given polynomial is irreducible over $\mathbb{Z}_5$ So, $$\dfrac{\mathbb{Z}_5 [x]}{(x^3+x+1)}$$ is a field and isomorphic to $\mathbb{Z}_5(\alpha)$ where $\alpha$ is the image of $x$ under the canonical map $$\pi \colon \mathbb{Z}_5[x]\to \dfrac{\mathbb{Z}_5 [x]}{(x^3+x+1)}.$$ So, $\alpha$ is a root of the polynomial over $\mathbb{Z}_5(\alpha)$ and it factorizes as $$x^3+x+1=(x-\alpha)(x^2+\alpha x+\alpha^2+1)$$ over $\mathbb{Z}_5(\alpha)$ . But now I can't conclude anything about $x^2+\alpha x+\alpha^2+1$ . Any help will be highly appreciated. Thank you!","Find the splitting field of the polynomial over . I can see that the given polynomial is irreducible over So, is a field and isomorphic to where is the image of under the canonical map So, is a root of the polynomial over and it factorizes as over . But now I can't conclude anything about . Any help will be highly appreciated. Thank you!",x^3+x+1 \mathbb{Z}_5 \mathbb{Z}_5 \dfrac{\mathbb{Z}_5 [x]}{(x^3+x+1)} \mathbb{Z}_5(\alpha) \alpha x \pi \colon \mathbb{Z}_5[x]\to \dfrac{\mathbb{Z}_5 [x]}{(x^3+x+1)}. \alpha \mathbb{Z}_5(\alpha) x^3+x+1=(x-\alpha)(x^2+\alpha x+\alpha^2+1) \mathbb{Z}_5(\alpha) x^2+\alpha x+\alpha^2+1,"['abstract-algebra', 'field-theory', 'galois-theory']"
6,Are inverse unique in unital algebra?,Are inverse unique in unital algebra?,,"Let $A$ be a unital algebra over a field $F$ with unity $1$ . If $a,b,c\in A$ such that $ab=ba=1=ac=ca$ , does this imply that $b=c$ ? We have $c(ab)=c$ . However, algebras are not necessarily associative so we can't conclude $c=c(ab)=(ca)b=b$ . Are there examples of algebras over a field with elements having multiple inverses?","Let be a unital algebra over a field with unity . If such that , does this imply that ? We have . However, algebras are not necessarily associative so we can't conclude . Are there examples of algebras over a field with elements having multiple inverses?","A F 1 a,b,c\in A ab=ba=1=ac=ca b=c c(ab)=c c=c(ab)=(ca)b=b","['abstract-algebra', 'ring-theory']"
7,"To what ring is $\mathbb{Z}[X,Y,Z]/(X-Y, X^3-Z)$ isomorphic?",To what ring is  isomorphic?,"\mathbb{Z}[X,Y,Z]/(X-Y, X^3-Z)","The problem: Let $(\mathbb{Z}[x,y,z],+,\cdot)$ be the ring of polynomials with coefficients in $\mathbb{Z}$ in the variables $x$ , $y$ and $z$ and the obvious operations $+$ and $\cdot$ . Let $(x-y, x^3-z)$ be the ideal generated by $x-y$ and $x^3-z$ . Find the ring to which $\mathbb{Z}[x,y,z]/(x-y,x^3-z)$ is isomorphic. A similar question has been asked before: Which ring is $R[X,Y,Z,T]/(X-Y^2,T-Y^4,T^3-Z)$ isomorphic to? . Using the same approach, we set $x=y$ and $x^3=z$ and substitute for $y$ and $z$ . Then we find $\mathbb{Z}[x,x,x^3]$ which is just $\mathbb{Z}[x]$ . I'm trying to find out why this approach would work, i.e., formalise it in a proper proof. My idea is to use the first isomorphism theorem, but I get stuck near the end. I would very much appreciate if someone could help fill in this gap, check my proof for mistakes or provide additional (intuitive) information as to why the above method works. My proof: Consider the map $\varphi : \mathbb{Z}[x,y,z] \to \mathbb{Z}[x] : p(x,y,z) \mapsto p(x,x,x^3)$ . This is a homomorphism, since it obeys the relations $\varphi(p) + \varphi(q) = \varphi(p+q)$ and $\varphi(p) \cdot \varphi(q) = \varphi(p \cdot q)$ for all $p,q \in \mathbb{Z}[x,y,z]$ (verifying these is quite trivial). Now take any $q \in \mathbb{Z}[x]$ and define a $p \in \mathbb{Z}[x,y,z]$ such that $p(x,y,z) = q(x)$ . Since $\varphi(p(x,y,z)) = p(x,x,x^3) = q(x)$ , $\varphi$ is surjective and it follows that $\mathbb{Z}[x] \subseteq \varphi(\mathbb{Z}[x,y,z])$ . It is obvious that $\varphi(\mathbb{Z}[x,y,z]) \subseteq \mathbb{Z}[x]$ and, therefore, we must have $\varphi(\mathbb{Z}[x,y,z]) = \mathbb{Z}[x]$ . Lastly, we must show that $\ker(\varphi) = (x-y, x^3-z)$ . For brevity's sake I will denote $I := (x-y,x^3-z).$ Let $p \in I$ . Then there must exist $q_1, q_2 \in \mathbb{Z}[x,y,z]$ such that $p = q_1(x-y) + q_2(x^3-z)$ . It follows that: \begin{align*}\varphi(p(x,y,z)) &= \varphi(q_1(x,y,z)(x-y) + q_2(x,y,z)(x^3-z))\\ &= q_1(x,x,x^3)(x-x) + q_2(x,x,x^3)(x^3-x^3) = 0.\end{align*} Thus $p \in \ker(\varphi)$ and $I \subseteq \ker(\varphi)$ , since $p$ was chosen arbitrarily in $I$ . Now, take a $q \in \ker(\varphi)$ . Then $\varphi(q(x,y,z)) = q(x,x,x^3) = 0$ . Somehow we must get that $q \in I$ so that we can conclude $\ker(\varphi) \subseteq I$ and thus $I = \ker(\varphi)$ , but I seem to get stuck on every path. Proof by contradiction or by contraposition also seems fruitless. What am I missing? With all of the above, we may apply the first isomorphism theorem to conclude that: $$\mathbb{Z}[x,y,z]/I = \mathbb{Z}[x,y,z]/\ker(\varphi) \cong \varphi(\mathbb{Z}[x,y,z]) = \mathbb{Z}[x]$$","The problem: Let be the ring of polynomials with coefficients in in the variables , and and the obvious operations and . Let be the ideal generated by and . Find the ring to which is isomorphic. A similar question has been asked before: Which ring is $R[X,Y,Z,T]/(X-Y^2,T-Y^4,T^3-Z)$ isomorphic to? . Using the same approach, we set and and substitute for and . Then we find which is just . I'm trying to find out why this approach would work, i.e., formalise it in a proper proof. My idea is to use the first isomorphism theorem, but I get stuck near the end. I would very much appreciate if someone could help fill in this gap, check my proof for mistakes or provide additional (intuitive) information as to why the above method works. My proof: Consider the map . This is a homomorphism, since it obeys the relations and for all (verifying these is quite trivial). Now take any and define a such that . Since , is surjective and it follows that . It is obvious that and, therefore, we must have . Lastly, we must show that . For brevity's sake I will denote Let . Then there must exist such that . It follows that: Thus and , since was chosen arbitrarily in . Now, take a . Then . Somehow we must get that so that we can conclude and thus , but I seem to get stuck on every path. Proof by contradiction or by contraposition also seems fruitless. What am I missing? With all of the above, we may apply the first isomorphism theorem to conclude that:","(\mathbb{Z}[x,y,z],+,\cdot) \mathbb{Z} x y z + \cdot (x-y, x^3-z) x-y x^3-z \mathbb{Z}[x,y,z]/(x-y,x^3-z) x=y x^3=z y z \mathbb{Z}[x,x,x^3] \mathbb{Z}[x] \varphi : \mathbb{Z}[x,y,z] \to \mathbb{Z}[x] : p(x,y,z) \mapsto p(x,x,x^3) \varphi(p) + \varphi(q) = \varphi(p+q) \varphi(p) \cdot \varphi(q) = \varphi(p \cdot q) p,q \in \mathbb{Z}[x,y,z] q \in \mathbb{Z}[x] p \in \mathbb{Z}[x,y,z] p(x,y,z) = q(x) \varphi(p(x,y,z)) = p(x,x,x^3) = q(x) \varphi \mathbb{Z}[x] \subseteq \varphi(\mathbb{Z}[x,y,z]) \varphi(\mathbb{Z}[x,y,z]) \subseteq \mathbb{Z}[x] \varphi(\mathbb{Z}[x,y,z]) = \mathbb{Z}[x] \ker(\varphi) = (x-y, x^3-z) I := (x-y,x^3-z). p \in I q_1, q_2 \in \mathbb{Z}[x,y,z] p = q_1(x-y) + q_2(x^3-z) \begin{align*}\varphi(p(x,y,z)) &= \varphi(q_1(x,y,z)(x-y) + q_2(x,y,z)(x^3-z))\\ &= q_1(x,x,x^3)(x-x) + q_2(x,x,x^3)(x^3-x^3) = 0.\end{align*} p \in \ker(\varphi) I \subseteq \ker(\varphi) p I q \in \ker(\varphi) \varphi(q(x,y,z)) = q(x,x,x^3) = 0 q \in I \ker(\varphi) \subseteq I I = \ker(\varphi) \mathbb{Z}[x,y,z]/I = \mathbb{Z}[x,y,z]/\ker(\varphi) \cong \varphi(\mathbb{Z}[x,y,z]) = \mathbb{Z}[x]","['abstract-algebra', 'polynomial-rings', 'ring-isomorphism']"
8,Constructively embedding $\mathbb{Q}^\mathbb{N}$ into $\mathbb{R}$,Constructively embedding  into,\mathbb{Q}^\mathbb{N} \mathbb{R},"Using the axiom of choice it is provable that $\mathbb{R}$ is isomorphic to $\mathbb{Q}^\mathbb{N}$ as a vector space over $\mathbb{Q}$ . (Assuming AC, both spaces have a Hamel basis over $\mathbb{Q}$ of the same cardinality and are thus isomorphic.) So my question is whether such an isomorphism between $\mathbb{R}$ and $\mathbb{Q}^\mathbb{N}$ can be constructed without AC or, at least, whether we can embed $\mathbb{Q}^\mathbb{N}$ into $\mathbb{R}$ without AC. (By embedding I mean constructing an injective $\mathbb{Q}$ -linear map from one space into the other.) The latter is equivalent to asking whether we can construct a subspace of $\mathbb{R}$ that has a schauder-basis over $\mathbb{Q}$ , as such a subspace should automatically be isomorphic to $\mathbb{Q}^\mathbb{N}$ . Thanks for the help!","Using the axiom of choice it is provable that is isomorphic to as a vector space over . (Assuming AC, both spaces have a Hamel basis over of the same cardinality and are thus isomorphic.) So my question is whether such an isomorphism between and can be constructed without AC or, at least, whether we can embed into without AC. (By embedding I mean constructing an injective -linear map from one space into the other.) The latter is equivalent to asking whether we can construct a subspace of that has a schauder-basis over , as such a subspace should automatically be isomorphic to . Thanks for the help!",\mathbb{R} \mathbb{Q}^\mathbb{N} \mathbb{Q} \mathbb{Q} \mathbb{R} \mathbb{Q}^\mathbb{N} \mathbb{Q}^\mathbb{N} \mathbb{R} \mathbb{Q} \mathbb{R} \mathbb{Q} \mathbb{Q}^\mathbb{N},"['abstract-algebra', 'logic', 'vector-spaces', 'axiom-of-choice', 'schauder-basis']"
9,Weird patterns in order of sums of elements in cyclic groups,Weird patterns in order of sums of elements in cyclic groups,,"this is my first time posting so if I make mistakes, I'm very sorry. For my homework in abstract algebra I was asked to basically calculate the order of elements $a$ and $b$ , and then the order of $a+b$ in $\mathbb{Z}_{12}$ . After doing the homework, I got curious about patterns in this, and noticed that $$Q\equiv\frac{\operatorname{lcm}(|a|,|b|)}{|a+b|}\in\mathbb{N}$$ Basically, not only is it a whole number, it seems to always divide the order of the group, so if we are in $\mathbb{Z}_n$ , then $Q$ divides $n$ . I'm not sure why this is. I got more curious and decided to make a heat map of all of the values of $Q$ for any combination of elements $a$ and $b$ in the group. I let the order be $144$ , and this is what I got: Q144 In this, black is equivalent to 1, the lowest number. The higher the value, the hotter. White is equal to the order of the group. It's worth noting that this is very composite, so I wondered what happened when the order was prime, and here's what I got for order 53: Q53 Very strange patterns I'm seeing, any ideas why this is? I don't know much about group theory (since I'm taking a class in it), so any insight would be much appreciated :)","this is my first time posting so if I make mistakes, I'm very sorry. For my homework in abstract algebra I was asked to basically calculate the order of elements and , and then the order of in . After doing the homework, I got curious about patterns in this, and noticed that Basically, not only is it a whole number, it seems to always divide the order of the group, so if we are in , then divides . I'm not sure why this is. I got more curious and decided to make a heat map of all of the values of for any combination of elements and in the group. I let the order be , and this is what I got: Q144 In this, black is equivalent to 1, the lowest number. The higher the value, the hotter. White is equal to the order of the group. It's worth noting that this is very composite, so I wondered what happened when the order was prime, and here's what I got for order 53: Q53 Very strange patterns I'm seeing, any ideas why this is? I don't know much about group theory (since I'm taking a class in it), so any insight would be much appreciated :)","a b a+b \mathbb{Z}_{12} Q\equiv\frac{\operatorname{lcm}(|a|,|b|)}{|a+b|}\in\mathbb{N} \mathbb{Z}_n Q n Q a b 144","['abstract-algebra', 'group-theory', 'elementary-number-theory', 'cyclic-groups']"
10,Relationship between two Galois Theorems.,Relationship between two Galois Theorems.,,"The classical Galois theorem states that For $K\subset L$ a finite Galois extension of fields, any intermediate extension $K\subset M\subset L$ satisfies $\mathrm{Fix}(\mathrm{Hom}_M(L,L))\subset M$ and any subgroups $H$ of $\mathrm{Hom}_K(L,L)$ satisfies $\mathrm{Hom}_{\mathrm{Fix}(H)}(L,L)\subset H$ , where $\mathrm{Hom}_M$ means the $M$ -algebra morphisms. Another version of the theorem, which in the book Galois Theories , chapter 2, is a generalization according to the authors: First define the category $\mathrm{Split}_K(L)$ to be the $K$ -algebra $A$ with the property that $A$ is finite over $K$ and the minimal polynomial of any $a\in A$ splits to linear factors in $L$ . As usual let $K\subset L$ be a finite Galois extension. The book states that The contravariant functor $F: \mathrm{Split}_K(L)\to \mathrm{Hom}_K(L,L)\mathrm{-Sets}$ defines by $F(A)=\mathrm{Hom}_K(A,L)$ induces a categorical equivalence. But how does this equivalence contains the classical version of Galois theorem? Let $G= \mathrm{Hom}_K(L,L)$ . Taking $H$ a subgroup of $G$ then the quotient $G/H$ as $G\mathrm{-Set}$ is isomorphic to some $\mathrm{Hom}_K(A,L)$ so we have a surjective homomorphism from $\mathrm{Hom}_K(L,L)$ to $\mathrm{Hom}_K(A,L)$ which by the categorical equivalence corresponds exactly to one mono arrow $A\to L$ . But does it mean that I need to show every mono is injective in the category $\mathrm{Split}_K(L)$ ? I have attempted to prove this using varies results in integral extensions but can not obtain anything. It seems to be trivial but I am lacking the background of categorical language. Any help would be appreciated.","The classical Galois theorem states that For a finite Galois extension of fields, any intermediate extension satisfies and any subgroups of satisfies , where means the -algebra morphisms. Another version of the theorem, which in the book Galois Theories , chapter 2, is a generalization according to the authors: First define the category to be the -algebra with the property that is finite over and the minimal polynomial of any splits to linear factors in . As usual let be a finite Galois extension. The book states that The contravariant functor defines by induces a categorical equivalence. But how does this equivalence contains the classical version of Galois theorem? Let . Taking a subgroup of then the quotient as is isomorphic to some so we have a surjective homomorphism from to which by the categorical equivalence corresponds exactly to one mono arrow . But does it mean that I need to show every mono is injective in the category ? I have attempted to prove this using varies results in integral extensions but can not obtain anything. It seems to be trivial but I am lacking the background of categorical language. Any help would be appreciated.","K\subset L K\subset M\subset L \mathrm{Fix}(\mathrm{Hom}_M(L,L))\subset M H \mathrm{Hom}_K(L,L) \mathrm{Hom}_{\mathrm{Fix}(H)}(L,L)\subset H \mathrm{Hom}_M M \mathrm{Split}_K(L) K A A K a\in A L K\subset L F: \mathrm{Split}_K(L)\to \mathrm{Hom}_K(L,L)\mathrm{-Sets} F(A)=\mathrm{Hom}_K(A,L) G= \mathrm{Hom}_K(L,L) H G G/H G\mathrm{-Set} \mathrm{Hom}_K(A,L) \mathrm{Hom}_K(L,L) \mathrm{Hom}_K(A,L) A\to L \mathrm{Split}_K(L)","['abstract-algebra', 'category-theory', 'galois-theory', 'galois-extensions']"
11,"Question from Mac Lane and Birkoff (Chapter II, section 3, problem 9) -- $\operatorname{Aut} (\mathbb{Z}_6) \cong \mathbb{Z}_2$","Question from Mac Lane and Birkoff (Chapter II, section 3, problem 9) --",\operatorname{Aut} (\mathbb{Z}_6) \cong \mathbb{Z}_2,"I'm working my way through Mac Lane and Birkhoff Algebra and I have a question about one of their exercises. We are asked to show that certain automorphism groups are isomorphic (as groups) to a given group. For example, one part is to show that $\operatorname{Aut} (\mathbb{Z}_6) \cong \mathbb{Z}_2$ . I'm fairly confident that I can write out all of the automorphisms and show that they are the only ones and show that they form a cyclic group of order (which we know from the reading is isomorphic to $\mathbb{Z}_2$ ). But, I'd like to argue this in a different way, that might save some time for the other parts of the problem. I'm curious if my solution is valid, or if I am missing something(s). Here it goes. From a prior problem (coincidentally that I asked about a few days ago), we know that if $\phi: G \rightarrow H$ is an morphism between groups, then the image of $\phi$ forms a subgroup, $\operatorname{Im}(\phi) \subseteq H$ . Next, since subgroups of cyclic groups are cyclic, we know that $\operatorname{Im}(\phi) = \langle a \rangle$ , for some $a\in H$ . Finally, if we are talking about automorphisms then, in particular, $\phi$ is an epimorphism. So, $\langle a \rangle =\operatorname{Im}(\phi) = H$ . ( Does this imply that generators of $G$ must be mapped to generator(s) of $H$ ? ) Thus, this problem reduces to finding the number of distinct generators of each group in question. For example, $\mathbb{Z}_6$ has two generators, $1$ and $5$ . Hence, there are two distinct automorphisms, implying that the order of $\operatorname{Aut} (\mathbb{Z}_6) $ is two. The first is the identity automorphism, call it $\phi_{1}$ and the second, call it $\phi_2$ sends: $$ \begin{align} 1 &\mapsto 5\\ 2 &\mapsto 2\\ 3 &\mapsto 3\\ 4 &\mapsto 4\\ 5 &\mapsto 1\\ \end{align} $$ From this, $\phi_2 \circ \phi_2 = \phi_1$ . So, $\operatorname{Aut} (\mathbb{Z}_6) = \left\{ \phi_1, \phi_2 \, | \, \phi_2^2 = \phi_1\right\} \cong \mathbb{Z}_2$ . ( Could we not get another automrphism by taking $\phi_2$ and instead of sending $2 \mapsto 2$ and $4 \mapsto 4$ , send $2 \mapsto 4$ and $4 \mapsto 2$ ? ) As you can see, this solution/these ideas are not fully baked, so any assistance would be greatly appreciated. Thanks in advance.","I'm working my way through Mac Lane and Birkhoff Algebra and I have a question about one of their exercises. We are asked to show that certain automorphism groups are isomorphic (as groups) to a given group. For example, one part is to show that . I'm fairly confident that I can write out all of the automorphisms and show that they are the only ones and show that they form a cyclic group of order (which we know from the reading is isomorphic to ). But, I'd like to argue this in a different way, that might save some time for the other parts of the problem. I'm curious if my solution is valid, or if I am missing something(s). Here it goes. From a prior problem (coincidentally that I asked about a few days ago), we know that if is an morphism between groups, then the image of forms a subgroup, . Next, since subgroups of cyclic groups are cyclic, we know that , for some . Finally, if we are talking about automorphisms then, in particular, is an epimorphism. So, . ( Does this imply that generators of must be mapped to generator(s) of ? ) Thus, this problem reduces to finding the number of distinct generators of each group in question. For example, has two generators, and . Hence, there are two distinct automorphisms, implying that the order of is two. The first is the identity automorphism, call it and the second, call it sends: From this, . So, . ( Could we not get another automrphism by taking and instead of sending and , send and ? ) As you can see, this solution/these ideas are not fully baked, so any assistance would be greatly appreciated. Thanks in advance.","\operatorname{Aut} (\mathbb{Z}_6) \cong \mathbb{Z}_2 \mathbb{Z}_2 \phi: G \rightarrow H \phi \operatorname{Im}(\phi) \subseteq H \operatorname{Im}(\phi) = \langle a \rangle a\in H \phi \langle a \rangle =\operatorname{Im}(\phi) = H G H \mathbb{Z}_6 1 5 \operatorname{Aut} (\mathbb{Z}_6)  \phi_{1} \phi_2 
\begin{align}
1 &\mapsto 5\\
2 &\mapsto 2\\
3 &\mapsto 3\\
4 &\mapsto 4\\
5 &\mapsto 1\\
\end{align}
 \phi_2 \circ \phi_2 = \phi_1 \operatorname{Aut} (\mathbb{Z}_6) = \left\{ \phi_1, \phi_2 \, | \, \phi_2^2 = \phi_1\right\} \cong \mathbb{Z}_2 \phi_2 2 \mapsto 2 4 \mapsto 4 2 \mapsto 4 4 \mapsto 2","['abstract-algebra', 'group-theory', 'cyclic-groups', 'automorphism-group']"
12,"Does $p \mid \frac{|{\rm{Stab}}(Q)|}{|\bigcap_{P\in {\rm{Syl}}_p(G)}{\rm{Stab}}(P)|}, \space\forall Q \in \operatorname{Syl}_p(G)$?",Does ?,"p \mid \frac{|{\rm{Stab}}(Q)|}{|\bigcap_{P\in {\rm{Syl}}_p(G)}{\rm{Stab}}(P)|}, \space\forall Q \in \operatorname{Syl}_p(G)","Ancillary to the main problem I'm trying to solve, I've come up to a partial result whose generalization would read as follows: Let $G$ be a finite group, $p$ a prime divisor of $|G|$ and $\operatorname{Syl}_p(G)$ the set of the Sylow $p$ -subgroups of $G$ . Assume further that $|\operatorname{Syl}_p(G)|>1$ . With reference to the transitive action of $G$ by conjugacy on $\operatorname{Syl}_p(G)$ , the following holds: $$p \mid \frac{|{\rm{Stab}}(Q)|}{|\bigcap_{P\in {\rm{Syl}}_p(G)}{\rm{Stab}}(P)|}, \space\forall Q \in \operatorname{Syl}_p(G) \tag 1$$ So far I couldn't prove it nor find a counterexample. Just for the records, I'm using $(1)$ to prove that, if $G$ has eight $7$ -Sylow subgroups, then $G$ has a normal subgroup $N$ such that $56$ divides $[G:N]$ .","Ancillary to the main problem I'm trying to solve, I've come up to a partial result whose generalization would read as follows: Let be a finite group, a prime divisor of and the set of the Sylow -subgroups of . Assume further that . With reference to the transitive action of by conjugacy on , the following holds: So far I couldn't prove it nor find a counterexample. Just for the records, I'm using to prove that, if has eight -Sylow subgroups, then has a normal subgroup such that divides .","G p |G| \operatorname{Syl}_p(G) p G |\operatorname{Syl}_p(G)|>1 G \operatorname{Syl}_p(G) p \mid \frac{|{\rm{Stab}}(Q)|}{|\bigcap_{P\in {\rm{Syl}}_p(G)}{\rm{Stab}}(P)|}, \space\forall Q \in \operatorname{Syl}_p(G) \tag 1 (1) G 7 G N 56 [G:N]","['abstract-algebra', 'group-theory']"
13,Is this proof that the ring of integers of an algebraic number field is a free Z-module incorrect?,Is this proof that the ring of integers of an algebraic number field is a free Z-module incorrect?,,"The theorem and proof in question are from Evan Chen's An Infinitely Large Napkin . I've tried to include the relevant part here, but if you wish to view it in context please see Theorem 47.2.12 from the PDF here . Theorem : Let $K$ be a number field of degree $n$ .     Then its ring of integers $O_K$ is a free $\mathbb{Z}$ -module of rank $n$ ,     i.e. $O_K \cong \mathbb{Z}^{\oplus n}$ as an abelian group.     In other words, $O_K$ has a $\mathbb{Z}$ -basis of $n$ elements as $$ O_K = \left\{ c_1\alpha_1 + \dots 			+ c_{n-1}\alpha_{n-1} + c_n\alpha_n \mid c_i \in \mathbb{Z} \right\} $$ where $\alpha_i$ are algebraic integers in $O_K$ . Proof: Pick a $\mathbb{Q}$ -basis of $\alpha_1$ , ..., $\alpha_n$ of $K$ and WLOG the $\alpha_i$ are in $O_K$ by scaling. Consider $\alpha \in O_K$ , and write $\alpha = c_1\alpha_1 + \dots + c_n\alpha_n$ . We will try to bound the denominators of $c_i$ . Look at $N(\alpha) = N(c_1\alpha_1 + \dots + c_n\alpha_n)$ . If we do a giant norm computation, we find that $N(\alpha)$ is a polynomial in the $c_i$ with fixed coefficients. (For example, $N(c_1 + c_2\sqrt 2) = c_1^2 - 2c_2^2$ , say.) But $N(\alpha)$ is an integer , so the denominators of the $c_i$ have to be bounded by some very large integer $N$ . Thus $$ \bigoplus_i \mathbb{Z} \cdot \alpha_i \subseteq O_K 	\subseteq \frac 1N \bigoplus_i \mathbb{Z} \cdot \alpha_i.  $$ The latter inclusion shows that $O_K$ is a subgroup of a free group, and hence it is itself free. On the other hand, the first inclusion shows it's rank $n$ . My issue is with the conclusion that the denominators of the $c_i$ are bounded. Consider for instance the polynomial $c_1 + c_2$ . Surely this can take integer values with arbitrarily small denominators, for instance with $\frac{1}{x} + \frac{x-1}{x}$ ? Is this a flaw in the proof, and if so, is the proof rescuable (for instance, using some more properties of the polynomial) or entirely wrong? (While the source is an informal document, I've yet to find any other major errors and am not exactly a math expert, so at the moment I'm leaning towards the proof being correct and me doing something obviously stupid.) Thanks!","The theorem and proof in question are from Evan Chen's An Infinitely Large Napkin . I've tried to include the relevant part here, but if you wish to view it in context please see Theorem 47.2.12 from the PDF here . Theorem : Let be a number field of degree .     Then its ring of integers is a free -module of rank ,     i.e. as an abelian group.     In other words, has a -basis of elements as where are algebraic integers in . Proof: Pick a -basis of , ..., of and WLOG the are in by scaling. Consider , and write . We will try to bound the denominators of . Look at . If we do a giant norm computation, we find that is a polynomial in the with fixed coefficients. (For example, , say.) But is an integer , so the denominators of the have to be bounded by some very large integer . Thus The latter inclusion shows that is a subgroup of a free group, and hence it is itself free. On the other hand, the first inclusion shows it's rank . My issue is with the conclusion that the denominators of the are bounded. Consider for instance the polynomial . Surely this can take integer values with arbitrarily small denominators, for instance with ? Is this a flaw in the proof, and if so, is the proof rescuable (for instance, using some more properties of the polynomial) or entirely wrong? (While the source is an informal document, I've yet to find any other major errors and am not exactly a math expert, so at the moment I'm leaning towards the proof being correct and me doing something obviously stupid.) Thanks!","K n O_K \mathbb{Z} n O_K \cong \mathbb{Z}^{\oplus n} O_K \mathbb{Z} n  O_K = \left\{ c_1\alpha_1 + \dots
			+ c_{n-1}\alpha_{n-1} + c_n\alpha_n \mid c_i \in \mathbb{Z} \right\}  \alpha_i O_K \mathbb{Q} \alpha_1 \alpha_n K \alpha_i O_K \alpha \in O_K \alpha = c_1\alpha_1 + \dots + c_n\alpha_n c_i N(\alpha) = N(c_1\alpha_1 + \dots + c_n\alpha_n) N(\alpha) c_i N(c_1 + c_2\sqrt 2) = c_1^2 - 2c_2^2 N(\alpha) c_i N  \bigoplus_i \mathbb{Z} \cdot \alpha_i \subseteq O_K
	\subseteq \frac 1N \bigoplus_i \mathbb{Z} \cdot \alpha_i.   O_K n c_i c_1 + c_2 \frac{1}{x} + \frac{x-1}{x}","['abstract-algebra', 'commutative-algebra', 'modules', 'algebraic-number-theory']"
14,Number of invertible elements in quotient ring,Number of invertible elements in quotient ring,,"I want to find an analog of Euler function $\varphi_{R}(a)$ that determines the number of invertible elements in the quotient ring $$R = \mathbb{F}_p[x]/(a), \text{ for } a \in \mathbb{F}_p[x]$$ where $\mathbb{F}_p[x]$ is a Euclidian domain with standard norm $N(f(x)) := \deg f(x)$ . UPD: I tried the following: Case 1: $a$ is prime $\Rightarrow \mathbb{F}_p[x]/(a)$ is field then $$\varphi_R(a) = |\mathbb{F}_p[x]/(a) \setminus \{0\}| = p^{deg(a)} - 1$$ Case 2 : take factorization $a = a_1^{e_1} \dots a_n^{e_n}$ then $$R \simeq \mathbb{F}_p[x]/(a_1^{e_1}) \oplus \mathbb{F}_p[x]/(a_2^{e_2}) \oplus \cdots\oplus\mathbb{F}_p[x]/(a_n^{e_n})$$ R is finite ring then $$\forall g \in R((g \text{ is zero divisor}) \vee (g \text{ is invertible}))$$ $$(g \text{ is zero divisor}) \iff \vee_{i = 1}^n(a_i | g)$$ Every element $g \in R$ now can be represented as following: $$g = (g (\text{mod } a_1^{e_1}),\dots,g(\text{mod } a_n^{e_n}))$$ $$a_i | g \iff \exists i =1\dots n : g (\text{mod }a_i^{e_i}) = 0$$ So we can conclude $$\varphi_R(a) = p^{deg(a)} - \prod_{i = 1}^n(p^{c_i} - 1), \text{ where } c_i = \deg(a_i^{e_i})$$ Is this answer correct?",I want to find an analog of Euler function that determines the number of invertible elements in the quotient ring where is a Euclidian domain with standard norm . UPD: I tried the following: Case 1: is prime is field then Case 2 : take factorization then R is finite ring then Every element now can be represented as following: So we can conclude Is this answer correct?,"\varphi_{R}(a) R = \mathbb{F}_p[x]/(a), \text{ for } a \in \mathbb{F}_p[x] \mathbb{F}_p[x] N(f(x)) := \deg f(x) a \Rightarrow \mathbb{F}_p[x]/(a) \varphi_R(a) = |\mathbb{F}_p[x]/(a) \setminus \{0\}| = p^{deg(a)} - 1 a = a_1^{e_1} \dots a_n^{e_n} R \simeq \mathbb{F}_p[x]/(a_1^{e_1}) \oplus \mathbb{F}_p[x]/(a_2^{e_2}) \oplus \cdots\oplus\mathbb{F}_p[x]/(a_n^{e_n}) \forall g \in R((g \text{ is zero divisor}) \vee (g \text{ is invertible})) (g \text{ is zero divisor}) \iff \vee_{i = 1}^n(a_i | g) g \in R g = (g (\text{mod } a_1^{e_1}),\dots,g(\text{mod } a_n^{e_n})) a_i | g \iff \exists i =1\dots n : g (\text{mod }a_i^{e_i}) = 0 \varphi_R(a) = p^{deg(a)} - \prod_{i = 1}^n(p^{c_i} - 1), \text{ where } c_i = \deg(a_i^{e_i})","['abstract-algebra', 'ring-theory', 'finite-fields', 'euclidean-domain']"
15,Prove that every group of order $4$ is abelian as follows.,Prove that every group of order  is abelian as follows.,4,"Can you please check my logic and maybe suggest some other strategies for the following problem: Prove that every group of order $4$ is abelian as follows: Let $G$ be any group of order $ 4$ , i.e., $|G| = 4$ . (1) Suppose there exists $a \in G$ such that $o(a) = 4$ . Prove that $G$ is abelian. (2) Suppose that no element of $G$ has order 4. Prove that $\forall x\in G$ , $x^2 = 1$ . (3) Suppose that no element of $G$ has order 4. Prove   that $G$ is abelian. What I got so far: (1) If there exists $a \in G$ such that $o(a) = 4$ , Case 1: $a\cdot a=b$ . Then $a\cdot a\cdot a=c$ and $a\cdot a\cdot a\cdot a=1$ . Algebra... G is abelian. Case 2: $a\cdot a=c$ ... $G$ is abelian. (2) Let $x\in G$ . If $o(x) \neq 4$ , we can clarify that an element cannot have an order greater than $4$ in a group of order $4$ and that the only element that has an order of $1$ is $1$ . Therefore the other three elements must have an order of $2$ , so $x^2=2$ for all $x \in G$ . (3) No ideas yet :(","Can you please check my logic and maybe suggest some other strategies for the following problem: Prove that every group of order is abelian as follows: Let be any group of order , i.e., . (1) Suppose there exists such that . Prove that is abelian. (2) Suppose that no element of has order 4. Prove that , . (3) Suppose that no element of has order 4. Prove   that is abelian. What I got so far: (1) If there exists such that , Case 1: . Then and . Algebra... G is abelian. Case 2: ... is abelian. (2) Let . If , we can clarify that an element cannot have an order greater than in a group of order and that the only element that has an order of is . Therefore the other three elements must have an order of , so for all . (3) No ideas yet :(",4 G  4 |G| = 4 a \in G o(a) = 4 G G \forall x\in G x^2 = 1 G G a \in G o(a) = 4 a\cdot a=b a\cdot a\cdot a=c a\cdot a\cdot a\cdot a=1 a\cdot a=c G x\in G o(x) \neq 4 4 4 1 1 2 x^2=2 x \in G,"['abstract-algebra', 'group-theory', 'abelian-groups']"
16,Introducing a mathematical structure.,Introducing a mathematical structure.,,"Most of the times, introducing a new mathematical structure is done in the following path. Start with a set/collection, name it as $X$ . It is possible that $X$ already have a structure with it, namely the structure of topological  space/manifold/vector space etc. Define a structure on $X$ , denote it by $\mathcal{A}$ . So, a structure is a pair $(X,\mathcal{A})$ . Define what does it mean to say a substructure of $(X,\mathcal{A})$ . Giving names to well-behaved substructures. Define what are maps between two structures, say $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ . Giving names to well-behaved maps between two structures. Define what does it mean to say two structures $(X,\mathcal{A})$ and $(Y,\mathcal{B})$ are ""equivalent"". Construct new structures from old structures. This step 6 differs drastically from one structure to another structure. Some ways to produce new structures from old structures are Quotients. Pullbacks. Products (direct). Sums (direct). Limits (Injective/Projective). ... ... For example, defining the notion of structure of a group on a set, we follow the same procedure. Defining a group, defining what does it mean to say a group morphism, what it means to say a subgroup (a normal subgroup), quotients of subgroup, (direct) sum, (direct) product of groups, (Injective/Projective) limit of (a collection) of groups and so on. In this post, I want to collect this procedure for most of the structures introduced in undergraduate or beginning graduate courses in Mathematics.","Most of the times, introducing a new mathematical structure is done in the following path. Start with a set/collection, name it as . It is possible that already have a structure with it, namely the structure of topological  space/manifold/vector space etc. Define a structure on , denote it by . So, a structure is a pair . Define what does it mean to say a substructure of . Giving names to well-behaved substructures. Define what are maps between two structures, say and . Giving names to well-behaved maps between two structures. Define what does it mean to say two structures and are ""equivalent"". Construct new structures from old structures. This step 6 differs drastically from one structure to another structure. Some ways to produce new structures from old structures are Quotients. Pullbacks. Products (direct). Sums (direct). Limits (Injective/Projective). ... ... For example, defining the notion of structure of a group on a set, we follow the same procedure. Defining a group, defining what does it mean to say a group morphism, what it means to say a subgroup (a normal subgroup), quotients of subgroup, (direct) sum, (direct) product of groups, (Injective/Projective) limit of (a collection) of groups and so on. In this post, I want to collect this procedure for most of the structures introduced in undergraduate or beginning graduate courses in Mathematics.","X X X \mathcal{A} (X,\mathcal{A}) (X,\mathcal{A}) (X,\mathcal{A}) (Y,\mathcal{B}) (X,\mathcal{A}) (Y,\mathcal{B})","['abstract-algebra', 'differential-geometry', 'category-theory', 'big-list']"
17,On Cayley representation of groups,On Cayley representation of groups,,"Suppose $G$ is a group. Let’s define Cayley representation of $G$ as the homomorphism $\operatorname{Cay}$ from $G$ to $\operatorname{Sym}(G)$ that maps every element $a$ to the permutation $\phi_a: g \mapsto ag$ . Is it always true, that $\frac{N_{\operatorname{Sym}(G)}(\operatorname{Cay}(G))}{C_{\operatorname{Sym}(G)}(\operatorname{Cay}(G))} \cong \operatorname{Aut}(G)$ ? Here $N$ stands for normalizer and $C$ for centralizer. For all finite groups of order up to $4$ this seems to be true, but what for other groups?","Suppose is a group. Let’s define Cayley representation of as the homomorphism from to that maps every element to the permutation . Is it always true, that ? Here stands for normalizer and for centralizer. For all finite groups of order up to this seems to be true, but what for other groups?",G G \operatorname{Cay} G \operatorname{Sym}(G) a \phi_a: g \mapsto ag \frac{N_{\operatorname{Sym}(G)}(\operatorname{Cay}(G))}{C_{\operatorname{Sym}(G)}(\operatorname{Cay}(G))} \cong \operatorname{Aut}(G) N C 4,"['abstract-algebra', 'group-theory', 'symmetric-groups', 'automorphism-group']"
18,Discriminant of homogeneous polynomials,Discriminant of homogeneous polynomials,,"Let $f$ be a homogeneous polynomial in variables $x,y,z$ . Suppose that the sum of coefficients of $\frac{\partial^i f}{\partial x^i}$ is $0$ for each $0 \leq i \leq r$ . I believe that, in this situation, $(y-z)^r$ must divide $\textrm{Disc}_x(f)$ . Let us give you a simple example. Let $f=x^2-2xy+z^2$ . Then $\frac{\partial f}{\partial x}=2x-2y$ and $$ \textrm{Disc}_x(f)=4y^2-4z^2=4(y-z)(y+z). $$ There are many examples which I computed using program. Why this happens? Is there any reference which mention on this situation?","Let be a homogeneous polynomial in variables . Suppose that the sum of coefficients of is for each . I believe that, in this situation, must divide . Let us give you a simple example. Let . Then and There are many examples which I computed using program. Why this happens? Is there any reference which mention on this situation?","f x,y,z \frac{\partial^i f}{\partial x^i} 0 0 \leq i \leq r (y-z)^r \textrm{Disc}_x(f) f=x^2-2xy+z^2 \frac{\partial f}{\partial x}=2x-2y 
\textrm{Disc}_x(f)=4y^2-4z^2=4(y-z)(y+z).
","['abstract-algebra', 'algebraic-geometry', 'algebraic-curves', 'computational-algebra', 'discriminant']"
19,Prove no zero divisors of a ring with a radical in $\mathbb{Z}_7$,Prove no zero divisors of a ring with a radical in,\mathbb{Z}_7,"When having the ring $$R:= \{a+b\sqrt{6}:\, a,b\in \mathbb{Z}_7\}$$ I have to prove the ring has no zero divisors. I want to proceed to prove with contradiction. So I know you can rewrite this to $N(xy) = N(x) N(y)$ so we can rewrite it to: $$N(a+b\sqrt{6}) = (a+b\sqrt{6})(a-b\sqrt{6})$$ First, let's assume $xy = 0$ for some $x\neq 0$ and $y\in \mathbb{Z}_7$ . So $N(xy)=N(x)N(y)=0$ . So either $N(x)=0$ or $N(y)=0$ . If we assume $N(x)=0$ , then we get: $a^2 -6b^2=0$ for some $a,b\in \mathbb{Z}_7$ . Now I'm stuck at the contradiction part, why can't there be any zero divisors in $\mathbb{Z}_7$ ?","When having the ring I have to prove the ring has no zero divisors. I want to proceed to prove with contradiction. So I know you can rewrite this to so we can rewrite it to: First, let's assume for some and . So . So either or . If we assume , then we get: for some . Now I'm stuck at the contradiction part, why can't there be any zero divisors in ?","R:= \{a+b\sqrt{6}:\, a,b\in \mathbb{Z}_7\} N(xy) = N(x) N(y) N(a+b\sqrt{6}) = (a+b\sqrt{6})(a-b\sqrt{6}) xy = 0 x\neq 0 y\in \mathbb{Z}_7 N(xy)=N(x)N(y)=0 N(x)=0 N(y)=0 N(x)=0 a^2 -6b^2=0 a,b\in \mathbb{Z}_7 \mathbb{Z}_7","['abstract-algebra', 'ring-theory', 'algebraic-number-theory', 'normed-spaces', 'integral-domain']"
20,"$x^a+ y^b + z^c$ is irreducible in $\mathbb C[x,y,z]$",is irreducible in,"x^a+ y^b + z^c \mathbb C[x,y,z]","Let $a,b,c$ be positive integers. Then $f = x^a + y^b + z^c$ is irreducible in $\mathbb{C}[x,y,z]$ . By Gauss, $f$ is irreducible in $\mathbb{C}[x,y,z]$ iff is so in $\mathbb{C}(z)[x,y]$ , and so iff in $\mathbb{C}(y, z)[x]$ . So by Eisenstein, it is sufficient to show that $y^b + z^c$ has a single prime factor. If $b=c$ , this factors through $\Pi(y + \zeta ^i z)$ for some primitive root of unity $\zeta$ , so ok. But if $b\neq c$ ? This question is related to this post . Thank you very much!","Let be positive integers. Then is irreducible in . By Gauss, is irreducible in iff is so in , and so iff in . So by Eisenstein, it is sufficient to show that has a single prime factor. If , this factors through for some primitive root of unity , so ok. But if ? This question is related to this post . Thank you very much!","a,b,c f = x^a + y^b + z^c \mathbb{C}[x,y,z] f \mathbb{C}[x,y,z] \mathbb{C}(z)[x,y] \mathbb{C}(y, z)[x] y^b + z^c b=c \Pi(y + \zeta ^i z) \zeta b\neq c","['abstract-algebra', 'polynomials', 'complex-numbers', 'irreducible-polynomials', 'multivariate-polynomial']"
21,Solve $x^7=e$ in a group,Solve  in a group,x^7=e,"Let $(G,\cdot)$ be a group having the property that $\exists a \in G$ such that $\forall x \in G$ , $ax=x^4a$ . Solve the equation $x^7=e$ . I started by observing that for $x=a$ we have that $a^2=a^5$ , so $a^3=e$ . Then I tried to left multiply the relation in the hypothesis by $x^3$ , but it didn't help and now I am stuck. EDIT: This is what the answer key says ""take $a=x^7$ to get that $x^8=x^{11} \implies x^3=e$ . Hence, $a=x^7=(x^3)^2 x=x \implies x=a$ , which satisfies $x^7=e$ "". To me, this seems blatantly wrong. Firstly, I don't think we can set $a$ to be equal to anything because we are only told that it exists, nothing more. Secondly, $a^7=a$ since $a^3=e$ . Could it be possible that this problem is wrong and the equation in fact has no solution?","Let be a group having the property that such that , . Solve the equation . I started by observing that for we have that , so . Then I tried to left multiply the relation in the hypothesis by , but it didn't help and now I am stuck. EDIT: This is what the answer key says ""take to get that . Hence, , which satisfies "". To me, this seems blatantly wrong. Firstly, I don't think we can set to be equal to anything because we are only told that it exists, nothing more. Secondly, since . Could it be possible that this problem is wrong and the equation in fact has no solution?","(G,\cdot) \exists a \in G \forall x \in G ax=x^4a x^7=e x=a a^2=a^5 a^3=e x^3 a=x^7 x^8=x^{11} \implies x^3=e a=x^7=(x^3)^2 x=x \implies x=a x^7=e a a^7=a a^3=e","['abstract-algebra', 'group-theory']"
22,how many abelian transitive subgroups of $S_{n}$,how many abelian transitive subgroups of,S_{n},"It's well-known that any abelian transitive subgroup A of a symmetric group $S_{n}$ has order $n$ . Moreover, does anyone know how many abelian transitive subgroups of $S_{n}$ and what do they look like?","It's well-known that any abelian transitive subgroup A of a symmetric group has order . Moreover, does anyone know how many abelian transitive subgroups of and what do they look like?",S_{n} n S_{n},"['abstract-algebra', 'combinatorics', 'group-theory', 'finite-groups', 'symmetric-groups']"
23,On Hopfian modules over commutative Noetherian rings,On Hopfian modules over commutative Noetherian rings,,"Let $R$ be a commutative Noetherian ring with unity. Let us call an $R$ -module $M$ to be Hopfian if every surjective endomorphism $M \to M $ is injective. 1) If $M_1$ and $M_2$ are Hopfian modules, then is $M_1 \oplus M_2$ necessarily Hopfian ? 2) If we have an exact sequence $0\to M_1 \to M\to M_2\to 0$ with $M$ Hopfian, then are $M_1$ and $M_2$ necessarily Hopfian ? If these are not true in general, are there any additional conditions on $R$ that would make it true ?","Let be a commutative Noetherian ring with unity. Let us call an -module to be Hopfian if every surjective endomorphism is injective. 1) If and are Hopfian modules, then is necessarily Hopfian ? 2) If we have an exact sequence with Hopfian, then are and necessarily Hopfian ? If these are not true in general, are there any additional conditions on that would make it true ?",R R M M \to M  M_1 M_2 M_1 \oplus M_2 0\to M_1 \to M\to M_2\to 0 M M_1 M_2 R,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'modules']"
24,Show that $m\mathbb{Z}$ is a subgroup of $n\mathbb{Z} \iff m|n $,Show that  is a subgroup of,m\mathbb{Z} n\mathbb{Z} \iff m|n ,"Show that $m\mathbb{Z}$ is a subgroup of $n\mathbb{Z} \iff n|m $ I think my solution for one way of this is correct: $\Rightarrow$ Suppose $m \mathbb{Z}$ is a subgroup of $n\mathbb{Z}$ , then $m \mathbb{Z}$ is a subset of $n\mathbb{Z}$ Therefore $m$ is an element of $n\mathbb{Z}$ , $m=nz$ for some $z$ in $\mathbb{Z}$ And so $n|m$ as required. For the converse, am I allowed to do these steps in reverse or is there more I  must do?","Show that is a subgroup of I think my solution for one way of this is correct: Suppose is a subgroup of , then is a subset of Therefore is an element of , for some in And so as required. For the converse, am I allowed to do these steps in reverse or is there more I  must do?",m\mathbb{Z} n\mathbb{Z} \iff n|m  \Rightarrow m \mathbb{Z} n\mathbb{Z} m \mathbb{Z} n\mathbb{Z} m n\mathbb{Z} m=nz z \mathbb{Z} n|m,"['abstract-algebra', 'group-theory', 'divisibility']"
25,Lubin-Tate formal groups are $p$-divisible groups,Lubin-Tate formal groups are -divisible groups,p,"I am trying to understand how to see whether a given formal group is $p$ -divisible. Let $A$ be a complete noetherian local ring with maximal ideal $\mathfrak{m}$ and residue field $k$ of characteristic $p$ and let $F \in A[[X,Y]]$ be a formal group law. Is there a nice criterion to see whether the map $$[p]^* \colon A[[X]] \to A[[X]], f(X) \mapsto f([p](X))$$ is injective and makes $A[[X]]$ into a finite free module over $A[[X]]$ ? (This is the definition of $F$ being $p$ -divisible.) My main case of interest is when $A=\mathfrak{o}$ is the ring of integers in a finite extension of $\mathbb Q_p$ . Lubin's answer to the question How is the $p$-adic Tate module of a formal group defined? seems to imply that $$F \,\,\text{    is } p\text{ -divisible } \iff [p] \text{  mod } \pi \neq 0 \text{ in } k[[X]]$$ where $\pi$ denotes a uniformizer of $\mathfrak o$ . Is this true? I would very much be thankful for a proof of this!",I am trying to understand how to see whether a given formal group is -divisible. Let be a complete noetherian local ring with maximal ideal and residue field of characteristic and let be a formal group law. Is there a nice criterion to see whether the map is injective and makes into a finite free module over ? (This is the definition of being -divisible.) My main case of interest is when is the ring of integers in a finite extension of . Lubin's answer to the question How is the $p$-adic Tate module of a formal group defined? seems to imply that where denotes a uniformizer of . Is this true? I would very much be thankful for a proof of this!,"p A \mathfrak{m} k p F \in A[[X,Y]] [p]^* \colon A[[X]] \to A[[X]], f(X) \mapsto f([p](X)) A[[X]] A[[X]] F p A=\mathfrak{o} \mathbb Q_p F \,\,\text{    is } p\text{ -divisible } \iff [p] \text{  mod } \pi \neq 0 \text{ in } k[[X]] \pi \mathfrak o","['abstract-algebra', 'algebraic-geometry', 'power-series', 'algebraic-number-theory', 'p-adic-number-theory']"
26,Conceptual explanation for the identity of Hochschild about derivations,Conceptual explanation for the identity of Hochschild about derivations,,"When reading Katz's paper ""Algebraic Solutions of Differential Equations (p-Curvature and the Hodge Filtration)"", he mentioned a mysterious identity about derivations in char $p$ commutative algebras at Page $3$ : Namely, If $A$ is a commutative algebra over $\Bbb F_p$ , $D$ is a derivation of $A$ (i.e linear and satisfying Leibniz rules ), then $D^{p-1}(X^{p-1} DX)+(D(X))^p=X^{p-1}D^p(X)$ for any $X \in A$ . I check it for polynomial rings, why does it hold in such generality? Hochschild's original paper does not state this as a lemma but only regard it as a technical identity. How to prove it in modern language?","When reading Katz's paper ""Algebraic Solutions of Differential Equations (p-Curvature and the Hodge Filtration)"", he mentioned a mysterious identity about derivations in char commutative algebras at Page : Namely, If is a commutative algebra over , is a derivation of (i.e linear and satisfying Leibniz rules ), then for any . I check it for polynomial rings, why does it hold in such generality? Hochschild's original paper does not state this as a lemma but only regard it as a technical identity. How to prove it in modern language?",p 3 A \Bbb F_p D A D^{p-1}(X^{p-1} DX)+(D(X))^p=X^{p-1}D^p(X) X \in A,"['abstract-algebra', 'commutative-algebra']"
27,Graph algebra with addition and multiplication,Graph algebra with addition and multiplication,,"First of all apologies if this sounds like a stupid question to some. I read a month ago a presentation about how graphs could be endowed with addition and multiplication in some interesting ways and I can't find anything about it by googling, so I am resorting to your knowledge. Basically, and out of my memory so I might be wrong, starting from $G = (E,V), G' = (E',V')$ : addition was simply $G + G' = (E + E', V + V')$ , with obvious meanings for edges and vertices addition (union of sets) multiplication was $G \times G' = (E + E' + V \times V', V + V')$ . Basically, for each vertex $v$ of $V$ , for any vertex $v'$ in $V'$ , you add $(v, v')$ edge to $G + G'$ . also if I remember well there was some distributivity law, maybe a(b+c) = ab + ac + bc Does that ring any bell to anybody? Sorry again for the shallowness of the question. I am looking for the name of that particular algebra so I can google it and find more about it.","First of all apologies if this sounds like a stupid question to some. I read a month ago a presentation about how graphs could be endowed with addition and multiplication in some interesting ways and I can't find anything about it by googling, so I am resorting to your knowledge. Basically, and out of my memory so I might be wrong, starting from : addition was simply , with obvious meanings for edges and vertices addition (union of sets) multiplication was . Basically, for each vertex of , for any vertex in , you add edge to . also if I remember well there was some distributivity law, maybe a(b+c) = ab + ac + bc Does that ring any bell to anybody? Sorry again for the shallowness of the question. I am looking for the name of that particular algebra so I can google it and find more about it.","G = (E,V), G' = (E',V') G + G' = (E + E', V + V') G \times G' = (E + E' + V \times V', V + V') v V v' V' (v, v') G + G'","['abstract-algebra', 'graph-theory', 'reference-request']"
28,Show that no group of order 48 is simple,Show that no group of order 48 is simple,,"Show that no group of order 48 is simple I was wondering if I was allowed to do something along this line of thinking: Let $n_2$ be the number of $2$ -Sylow groups. $n_2$ is limited to $1$ and $3$ since these are the only divisors of 48 that are equivalent to $1 \mod 2$ . $n_2=3$ (since if $n_2=1$ the group is definitely not simple) Each $n_2$ subgroup contains 1 distinct element and there are 3 of these subgroups hence there are 3 distinct elements. We have $48-3=45$ elements to account for. At this point, can I assume that these 45 elements form a subgroup and then solve this proof by proving a group of 45 elements form a p-Sylow normal subgroup?","Show that no group of order 48 is simple I was wondering if I was allowed to do something along this line of thinking: Let be the number of -Sylow groups. is limited to and since these are the only divisors of 48 that are equivalent to . (since if the group is definitely not simple) Each subgroup contains 1 distinct element and there are 3 of these subgroups hence there are 3 distinct elements. We have elements to account for. At this point, can I assume that these 45 elements form a subgroup and then solve this proof by proving a group of 45 elements form a p-Sylow normal subgroup?",n_2 2 n_2 1 3 1 \mod 2 n_2=3 n_2=1 n_2 48-3=45,"['abstract-algebra', 'group-theory', 'sylow-theory', 'simple-groups']"
29,Show group of order $4563=3^3\cdot13^2$ is not simple.,Show group of order  is not simple.,4563=3^3\cdot13^2,"Show a group of order $4563=3^3\cdot13^2$ is not simple. I am confused when dealing with these Sylow's game. Especially when the order becomes large. It seems there is no common rules to solve this kind problems. My try : $n_{13}=1+13t$ and $n_{13}$ divides $3^3=27$ , hence $t=0,2$ . If $t=0$ then we are done. If $t=2$ , There are $27$ 13-subgroups of order 169. Then consider the conjugation action of G on the set of 13-subgroups. Prove it induced a homomorphism between $G$ and $S_{27}$ . And want to claim a contradiction by $|G|$ does not divide $27!$ . But sadly it does divide. Any other method can get this figured out?","Show a group of order is not simple. I am confused when dealing with these Sylow's game. Especially when the order becomes large. It seems there is no common rules to solve this kind problems. My try : and divides , hence . If then we are done. If , There are 13-subgroups of order 169. Then consider the conjugation action of G on the set of 13-subgroups. Prove it induced a homomorphism between and . And want to claim a contradiction by does not divide . But sadly it does divide. Any other method can get this figured out?","4563=3^3\cdot13^2 n_{13}=1+13t n_{13} 3^3=27 t=0,2 t=0 t=2 27 G S_{27} |G| 27!","['abstract-algebra', 'group-theory', 'sylow-theory']"
30,Can a field be canonically reconstructed from its multiplicative group?,Can a field be canonically reconstructed from its multiplicative group?,,"I understand that there are a lot of restrictions on which abelian groups arise as the multiplicative groups of fields. My question is kind of the adjoint: Suppose I pick a field $k$ , but I do not tell you what it is. I give you an abelian group $G$ and tell you that $G\cong k^\times$ . But you only receive $G$ as an abstract group; that is, $G$ does not come with the natural action on $(k, +)$ or any other information inherited    from $k$ . Given $G$ , can you canonically define a field $\hat k$ such that $\hat k \cong k$ ? I would not be surprised at all if the answer were ""no."" But as I'm not convinced either way, I optimistically attempted a natural construction. I first observed that even though we don't know anything about $k$ as a set, we have a 1-1 correspondence between $G$ and the nonzero elements of $k$ . We need to invent a additive neutral element and also somehow produce an addition operation compatible with multiplication. Let $(\Sigma, +)$ be the free abelian group generated by the elements of $G$ ; $\sigma: G\to \Sigma$ is the identification of $g \in G$ as $\sigma(g) \in \Sigma$ . At this point $\Sigma$ contains the desired $(k, +)$ as a subgroup, although it is way too big. Continuing in the freest possible way, define: $R = G \otimes_\mathbb{Z} \Sigma$ . $R$ is naturally distributive, but it is far from having the full additive structure of $k$ . Let $P$ be the ideal generated by all elements $\left\{g\otimes\sigma(g')-gg'\otimes\sigma(1)\mid g, g \in G\right\}$ . Set $S=R/P$ . By allowing natural distributivity and 0 compatible with $\otimes$ , $S$ is a ring with multiplication defined by $(g\otimes 1)(g'\otimes 1) = gg'\otimes 1$ . And obviously $S$ contains $k$ , but it also has so much other contents and structure that I think it's not even a field. Can I get any pointers on what to do next (quotient? localize?)? Or if my objective is impossible, I'd like to see where this attempt breaks down.","I understand that there are a lot of restrictions on which abelian groups arise as the multiplicative groups of fields. My question is kind of the adjoint: Suppose I pick a field , but I do not tell you what it is. I give you an abelian group and tell you that . But you only receive as an abstract group; that is, does not come with the natural action on or any other information inherited    from . Given , can you canonically define a field such that ? I would not be surprised at all if the answer were ""no."" But as I'm not convinced either way, I optimistically attempted a natural construction. I first observed that even though we don't know anything about as a set, we have a 1-1 correspondence between and the nonzero elements of . We need to invent a additive neutral element and also somehow produce an addition operation compatible with multiplication. Let be the free abelian group generated by the elements of ; is the identification of as . At this point contains the desired as a subgroup, although it is way too big. Continuing in the freest possible way, define: . is naturally distributive, but it is far from having the full additive structure of . Let be the ideal generated by all elements . Set . By allowing natural distributivity and 0 compatible with , is a ring with multiplication defined by . And obviously contains , but it also has so much other contents and structure that I think it's not even a field. Can I get any pointers on what to do next (quotient? localize?)? Or if my objective is impossible, I'd like to see where this attempt breaks down.","k G G\cong k^\times G G (k, +) k G \hat k \hat k \cong k k G k (\Sigma, +) G \sigma: G\to \Sigma g \in G \sigma(g) \in \Sigma \Sigma (k, +) R = G \otimes_\mathbb{Z} \Sigma R k P \left\{g\otimes\sigma(g')-gg'\otimes\sigma(1)\mid g, g \in G\right\} S=R/P \otimes S (g\otimes 1)(g'\otimes 1) = gg'\otimes 1 S k","['abstract-algebra', 'vector-spaces', 'field-theory', 'abelian-groups', 'adjoint-functors']"
31,A group of order $36$ has either a normal Sylow $2$-subgroup or a normal Sylow $3$-subgroup,A group of order  has either a normal Sylow -subgroup or a normal Sylow -subgroup,36 2 3,Let $G$ be a group of order $36$ and given that $G$ has $4$ Sylow $3$-subgroups. Then  I have to  show that Sylow $2$-subgroup is unique. So far we proved that $G$ has a normal subgroup of order $3$. Couldn't solve that it has a unique Sylow $2$-subgroup. Help me. Thanks.,Let $G$ be a group of order $36$ and given that $G$ has $4$ Sylow $3$-subgroups. Then  I have to  show that Sylow $2$-subgroup is unique. So far we proved that $G$ has a normal subgroup of order $3$. Couldn't solve that it has a unique Sylow $2$-subgroup. Help me. Thanks.,,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory']"
32,"Is it possible that $\text{lcm}(zx, zy)$ exists but $\text{lcm}(x, y)$ not?",Is it possible that  exists but  not?,"\text{lcm}(zx, zy) \text{lcm}(x, y)","Is it possible to find an example of an integral domain $D$ and a pair of non-zero elements $x$ and $y$ in $D$ such that $\text{lcm}(zx, zy)$ exists for some non-zero element $z$ in $D$ but $\text{lcm}(x, y)$ does not? Definition of least common divisor (lcm): Let $a$ and $b$ be elements of a commutative ring $R$. A common multiple of $a$ and $b$ is an element $m$ of $R$ such that there exist elements $x$ and $y$ of $R$ such that $ax = by = m$. A least common multiple of $a$ and $b$ is a common multiple $m$ of $a$ and $b$ that is minimal in the sense that for any other common multiple $n$ of $a$ and $b$, $n=zm$ for some $z$ in $R$.","Is it possible to find an example of an integral domain $D$ and a pair of non-zero elements $x$ and $y$ in $D$ such that $\text{lcm}(zx, zy)$ exists for some non-zero element $z$ in $D$ but $\text{lcm}(x, y)$ does not? Definition of least common divisor (lcm): Let $a$ and $b$ be elements of a commutative ring $R$. A common multiple of $a$ and $b$ is an element $m$ of $R$ such that there exist elements $x$ and $y$ of $R$ such that $ax = by = m$. A least common multiple of $a$ and $b$ is a common multiple $m$ of $a$ and $b$ that is minimal in the sense that for any other common multiple $n$ of $a$ and $b$, $n=zm$ for some $z$ in $R$.",,['abstract-algebra']
33,"What is the maximal $m$, such that $\mathbb{Z}_2^m \leq GL(n, 2)$?","What is the maximal , such that ?","m \mathbb{Z}_2^m \leq GL(n, 2)","Is there any closed formula for the function $m(n)$, that is defined as the maximal $m$, such that there is $GL(n, 2)$ has a subgroup isomorphic to $\mathbb{Z}_2^m$? The only things I know currently, is that $m(1) = 0$ (as $GL(1, 2)$ is trivial) and $m(2) = 1$ (as $GL(2, 2)$ is isomorphic to $S_3$). With $GL(3, 2)$ the things become very complicated (as it is a simple group of order 168), so $m(3)$ or any other $m(n)$ with $3 \leq n$ is unknown to me currently. Any help will be appreciated.","Is there any closed formula for the function $m(n)$, that is defined as the maximal $m$, such that there is $GL(n, 2)$ has a subgroup isomorphic to $\mathbb{Z}_2^m$? The only things I know currently, is that $m(1) = 0$ (as $GL(1, 2)$ is trivial) and $m(2) = 1$ (as $GL(2, 2)$ is isomorphic to $S_3$). With $GL(3, 2)$ the things become very complicated (as it is a simple group of order 168), so $m(3)$ or any other $m(n)$ with $3 \leq n$ is unknown to me currently. Any help will be appreciated.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'linear-groups']"
34,"$|\mathbb{Q}(a):\mathbb{Q}|=n,|\mathbb{Q}(b):\mathbb{Q}| =m$ and $\gcd(m,n)=1 \implies|\mathbb{Q}(ab):\mathbb{Q}|=mn$",and,"|\mathbb{Q}(a):\mathbb{Q}|=n,|\mathbb{Q}(b):\mathbb{Q}| =m \gcd(m,n)=1 \implies|\mathbb{Q}(ab):\mathbb{Q}|=mn","I'm working with field extensions (all with characteristic 0) and I need to show that: $|\mathbb{Q}(a):\mathbb{Q}|=n,|\mathbb{Q}(b):\mathbb{Q}| =m$ and $\gcd(m,n)=1 \implies|\mathbb{Q}(ab):\mathbb{Q}|=mn$ Here's what I thought: We know that $\mathbb{Q}(a,b) = \mathbb{Q}(ab,a) = \mathbb{Q}(ab,b)$, and $|\mathbb{Q}(a,b):\mathbb{Q}|=mn$ so,  $$|\mathbb{Q}(a,b):\mathbb{Q}| = |\mathbb{Q}(ab,b):\mathbb{Q}| = |\mathbb{Q}(ab)(a):\mathbb{Q}(ab)|\cdot |\mathbb{Q}(ab):\mathbb{Q}|= n\cdot m $$ $\implies 1 = \frac{|\mathbb{Q}(a,b):\mathbb{Q}|}{|\mathbb{Q}(ab,a):\mathbb{Q}|} = \frac{n\cdot m}{|\mathbb{Q}(ab,a):\mathbb{Q}(ab)|\cdot |\mathbb{Q}(ab):\mathbb{Q}|}\implies |Q(ab):\mathbb{Q}| = \frac{n\cdot m}{|\mathbb{Q}(ab,a):\mathbb{Q}(ab)|}$ Now, as $$|\mathbb{Q}(a):\mathbb{Q}|=n \implies \deg(\operatorname{irr}(a,\mathbb{Q}))=n$$ we have that $$\deg(\operatorname{irr}(a,\mathbb{Q}(ab)))\leq n\implies |\mathbb{Q}(ab,a):\mathbb{Q}(ab)|\leq n$$ Therefore $|\mathbb{Q}(ab):\mathbb{Q}| = m\cdot \frac{n}{|\mathbb{Q}(ab,a):\mathbb{Q}(ab)|}= m \cdot k$, with $k \in \mathbb{Z}$. By the same logic $|\mathbb{Q}(ab):\mathbb{Q}| = n \cdot t$, with $t \in \mathbb{Z}$ So $|\mathbb{Q}(a,b):\mathbb{Q}|$ is a multiple of $m$ and $n$, but as they are coprimes, the least commom multiple of them is their product, which is $mn = |\mathbb{Q}(a,b):\mathbb{Q}|$, and as $\mathbb{Q}(ab) \subset \mathbb{Q}(a,b), |\mathbb{Q}(ab):\mathbb{Q}|\leq|\mathbb{Q}(a,b):\mathbb{Q}|$, so we have that $|\mathbb{Q}(ab):\mathbb{Q}|=mn$ $\blacksquare$ Are there any mistakes?","I'm working with field extensions (all with characteristic 0) and I need to show that: $|\mathbb{Q}(a):\mathbb{Q}|=n,|\mathbb{Q}(b):\mathbb{Q}| =m$ and $\gcd(m,n)=1 \implies|\mathbb{Q}(ab):\mathbb{Q}|=mn$ Here's what I thought: We know that $\mathbb{Q}(a,b) = \mathbb{Q}(ab,a) = \mathbb{Q}(ab,b)$, and $|\mathbb{Q}(a,b):\mathbb{Q}|=mn$ so,  $$|\mathbb{Q}(a,b):\mathbb{Q}| = |\mathbb{Q}(ab,b):\mathbb{Q}| = |\mathbb{Q}(ab)(a):\mathbb{Q}(ab)|\cdot |\mathbb{Q}(ab):\mathbb{Q}|= n\cdot m $$ $\implies 1 = \frac{|\mathbb{Q}(a,b):\mathbb{Q}|}{|\mathbb{Q}(ab,a):\mathbb{Q}|} = \frac{n\cdot m}{|\mathbb{Q}(ab,a):\mathbb{Q}(ab)|\cdot |\mathbb{Q}(ab):\mathbb{Q}|}\implies |Q(ab):\mathbb{Q}| = \frac{n\cdot m}{|\mathbb{Q}(ab,a):\mathbb{Q}(ab)|}$ Now, as $$|\mathbb{Q}(a):\mathbb{Q}|=n \implies \deg(\operatorname{irr}(a,\mathbb{Q}))=n$$ we have that $$\deg(\operatorname{irr}(a,\mathbb{Q}(ab)))\leq n\implies |\mathbb{Q}(ab,a):\mathbb{Q}(ab)|\leq n$$ Therefore $|\mathbb{Q}(ab):\mathbb{Q}| = m\cdot \frac{n}{|\mathbb{Q}(ab,a):\mathbb{Q}(ab)|}= m \cdot k$, with $k \in \mathbb{Z}$. By the same logic $|\mathbb{Q}(ab):\mathbb{Q}| = n \cdot t$, with $t \in \mathbb{Z}$ So $|\mathbb{Q}(a,b):\mathbb{Q}|$ is a multiple of $m$ and $n$, but as they are coprimes, the least commom multiple of them is their product, which is $mn = |\mathbb{Q}(a,b):\mathbb{Q}|$, and as $\mathbb{Q}(ab) \subset \mathbb{Q}(a,b), |\mathbb{Q}(ab):\mathbb{Q}|\leq|\mathbb{Q}(a,b):\mathbb{Q}|$, so we have that $|\mathbb{Q}(ab):\mathbb{Q}|=mn$ $\blacksquare$ Are there any mistakes?",,"['abstract-algebra', 'proof-verification', 'galois-theory', 'extension-field']"
35,Doubt in proof of Theorem 3.19 from Patrick Morandi's *Field and Galois Theory*,Doubt in proof of Theorem 3.19 from Patrick Morandi's *Field and Galois Theory*,,"Relevant notations and results Let $K / F$ be a field extension and let $\alpha \in K$ be algebraic over $F$. We denote the minimal polynomial of $\alpha$ over $F$ by $\min(F,\alpha)$. If $\sigma : F \to F'$ is a field homomorphism, then there is an induced ring homomorphism $F[x] \to F'[x]$, which we also denote by $\sigma$, given by $\sigma\left( \sum a_i x^i \right) = \sum \sigma(a_i) x^i$. Lemma 3.17. Let $\sigma : F \to F'$ be a field isomorphism. Let $f(x) \in F[x]$ be irreducible, let $\alpha$ be a root of $f$ in some extension field $K$ of $F$, and let $\alpha'$ be a root of $\sigma(f)$ in some extension $K'$ of $F'$. Then there is an isomorphism $\tau : F(\alpha) \to F'(\alpha')$ with $\tau(\alpha) = \alpha'$ and $\tau |_F = \sigma$. I am reading Patrick Morandi's Field and Galois Theory , and on page 34, he states and proves the following theorem, which is a special case of the Isomorphism Extension Theorem. Theorem 3.19. Let $\sigma : F \to F'$ be a field isomorphism, let $f(x) \in F[x]$ and let $\sigma(f) \in F'[x]$ be the corresponding polynomial over $F'$. Let $K$ be a splitting field of $f$ over $F$, and let $K'$ be a splitting field of $\sigma(f)$ over $F'$. Then there is an isomorphism $\tau : K \to K'$ with $\tau|_F = \sigma$. Furthermore, if $\alpha \in K$ and if $\alpha'$ is any root of $\sigma(\min(F,\alpha))$ in $K'$, then $\tau$ can be chosen so that $\tau(\alpha) = \alpha'$. Proof: We prove this by induction on $n = [K:F]$. If $n = 1$, then $f$ splits over $F$, and the result is trivial in this case. So, suppose that $n > 1$ and that the result is true for splitting fields of degree less than $n$. $\color{red}{\text{If $f$ splits over $F$, then the result is clear.}}$ If not, let $p(x)$ be a nonlinear irreducible factor of $f(x)$, $\color{blue}{\text{let $\alpha$ be a root of $p$,}}$ and let $\alpha'$ be a root of $\sigma(p)$. Set $L = F(\alpha)$ and $L' = F'(\alpha')$. Then $[L:F] > 1$, so $[K:L] < n$. By Lemma 3.17, there is a field isomorphism $\rho : L \to L'$ with $\rho(\alpha) = \alpha'$. Since $K$ is a splitting field over $L$ for $f(x)$ and $K'$ is a splitting field over $L'$ for $\sigma(f)$, by induction the isomorphism $\rho$ extends to an isomorphism $\tau : K \to K'$. The isomorphism $\tau$ is then an extension of $\sigma$ (and $\rho$), and $\tau(\alpha) = \rho(\alpha) = \alpha'$. $$\tag*{$\blacksquare$}$$ My doubts are related to the highlighted parts in the proof: Upon assuming that $n = [K:F] > 1$, it is certain that $f$ cannot split over $F$, because then we would have $K = F \implies [K:F] = 1$. So, isn't the statement highlighted in red redundant? In the proof, $\alpha$ is taken to be a root of (an irreducible factor of) $f$, and $\alpha'$ a root of the corresponding polynomial. But in the statement of the theorem $\alpha$ is an arbitrary element of $K$. It doesn't seem to be obvious how to use the given proof to construct an isomorphism $K \to K'$ which sends this arbitrary $\alpha$ to an $\alpha'$. What am I missing here?","Relevant notations and results Let $K / F$ be a field extension and let $\alpha \in K$ be algebraic over $F$. We denote the minimal polynomial of $\alpha$ over $F$ by $\min(F,\alpha)$. If $\sigma : F \to F'$ is a field homomorphism, then there is an induced ring homomorphism $F[x] \to F'[x]$, which we also denote by $\sigma$, given by $\sigma\left( \sum a_i x^i \right) = \sum \sigma(a_i) x^i$. Lemma 3.17. Let $\sigma : F \to F'$ be a field isomorphism. Let $f(x) \in F[x]$ be irreducible, let $\alpha$ be a root of $f$ in some extension field $K$ of $F$, and let $\alpha'$ be a root of $\sigma(f)$ in some extension $K'$ of $F'$. Then there is an isomorphism $\tau : F(\alpha) \to F'(\alpha')$ with $\tau(\alpha) = \alpha'$ and $\tau |_F = \sigma$. I am reading Patrick Morandi's Field and Galois Theory , and on page 34, he states and proves the following theorem, which is a special case of the Isomorphism Extension Theorem. Theorem 3.19. Let $\sigma : F \to F'$ be a field isomorphism, let $f(x) \in F[x]$ and let $\sigma(f) \in F'[x]$ be the corresponding polynomial over $F'$. Let $K$ be a splitting field of $f$ over $F$, and let $K'$ be a splitting field of $\sigma(f)$ over $F'$. Then there is an isomorphism $\tau : K \to K'$ with $\tau|_F = \sigma$. Furthermore, if $\alpha \in K$ and if $\alpha'$ is any root of $\sigma(\min(F,\alpha))$ in $K'$, then $\tau$ can be chosen so that $\tau(\alpha) = \alpha'$. Proof: We prove this by induction on $n = [K:F]$. If $n = 1$, then $f$ splits over $F$, and the result is trivial in this case. So, suppose that $n > 1$ and that the result is true for splitting fields of degree less than $n$. $\color{red}{\text{If $f$ splits over $F$, then the result is clear.}}$ If not, let $p(x)$ be a nonlinear irreducible factor of $f(x)$, $\color{blue}{\text{let $\alpha$ be a root of $p$,}}$ and let $\alpha'$ be a root of $\sigma(p)$. Set $L = F(\alpha)$ and $L' = F'(\alpha')$. Then $[L:F] > 1$, so $[K:L] < n$. By Lemma 3.17, there is a field isomorphism $\rho : L \to L'$ with $\rho(\alpha) = \alpha'$. Since $K$ is a splitting field over $L$ for $f(x)$ and $K'$ is a splitting field over $L'$ for $\sigma(f)$, by induction the isomorphism $\rho$ extends to an isomorphism $\tau : K \to K'$. The isomorphism $\tau$ is then an extension of $\sigma$ (and $\rho$), and $\tau(\alpha) = \rho(\alpha) = \alpha'$. $$\tag*{$\blacksquare$}$$ My doubts are related to the highlighted parts in the proof: Upon assuming that $n = [K:F] > 1$, it is certain that $f$ cannot split over $F$, because then we would have $K = F \implies [K:F] = 1$. So, isn't the statement highlighted in red redundant? In the proof, $\alpha$ is taken to be a root of (an irreducible factor of) $f$, and $\alpha'$ a root of the corresponding polynomial. But in the statement of the theorem $\alpha$ is an arbitrary element of $K$. It doesn't seem to be obvious how to use the given proof to construct an isomorphism $K \to K'$ which sends this arbitrary $\alpha$ to an $\alpha'$. What am I missing here?",,"['abstract-algebra', 'field-theory']"
36,Ring of integers modulo $n$ with a property for the zero divisors.,Ring of integers modulo  with a property for the zero divisors.,n,"This is a follow-up of Is $a+b$ a unit if $a,b,a-b$ are zero divisors? Let $n$ be a natural number such that the ring $R:=\mathbb{Z}/(n \mathbb{Z})$ has the following property: $$a,b,a-b\in Z \implies a+b \in Z$$ where $Z$ are the zero-divisors of $\mathbb{Z}/(n \mathbb{Z})$. User @lhf made the observation that $R$ seems to have this property exactly when $n$ has less than three prime divisors. I am interested if this can be made into a proof. Edit : Here is a partial result if $\omega(n)=1$, hence $n=p^\alpha$  is a prime power: If $a,b,a-b\in Z$ then we must have: $p^{a_0} = \gcd(a,n)>1$,$p^{b_0} = \gcd(b,n)>1$,$p^{c_0} = \gcd(a-b,n)>1$ for $a_0,b_0,c_0\ge 1$. From this it follows that: $$a = x p^{a_0}, b = y p^{b_0}, a-b=zp^{c_0}$$ and we get: $$a+b = (a-b)+2b = zp^{c_0} + 2yp^{b_0} = p^{d_0}(zp^{c_0-d_0}+2yp^{b_0-d_0})$$  with $d_0 = \min(c_0,b_0) \ge 1$ since $b_0,c_0 \ge 1$. Hence $\gcd(a+b,n)>1$ and $a+b \in Z$.","This is a follow-up of Is $a+b$ a unit if $a,b,a-b$ are zero divisors? Let $n$ be a natural number such that the ring $R:=\mathbb{Z}/(n \mathbb{Z})$ has the following property: $$a,b,a-b\in Z \implies a+b \in Z$$ where $Z$ are the zero-divisors of $\mathbb{Z}/(n \mathbb{Z})$. User @lhf made the observation that $R$ seems to have this property exactly when $n$ has less than three prime divisors. I am interested if this can be made into a proof. Edit : Here is a partial result if $\omega(n)=1$, hence $n=p^\alpha$  is a prime power: If $a,b,a-b\in Z$ then we must have: $p^{a_0} = \gcd(a,n)>1$,$p^{b_0} = \gcd(b,n)>1$,$p^{c_0} = \gcd(a-b,n)>1$ for $a_0,b_0,c_0\ge 1$. From this it follows that: $$a = x p^{a_0}, b = y p^{b_0}, a-b=zp^{c_0}$$ and we get: $$a+b = (a-b)+2b = zp^{c_0} + 2yp^{b_0} = p^{d_0}(zp^{c_0-d_0}+2yp^{b_0-d_0})$$  with $d_0 = \min(c_0,b_0) \ge 1$ since $b_0,c_0 \ge 1$. Hence $\gcd(a+b,n)>1$ and $a+b \in Z$.",,['abstract-algebra']
37,How many non-abelian groups of order $lpq$ are there?,How many non-abelian groups of order  are there?,lpq,"If $l,p,q$ are primes with $l<p<q$, such that $$p\nmid (q-1)\hspace{1cm} l\mid (p-1)\hspace{1cm} l\mid (q-1) $$ I want to show that there are at least $1$ and at most $(l+1)$   non-abelian groups of order $lpq$. I already showed (using Sylow theorems) that in this case, if $G$ is a group with order $lpq$ then $$ G \cong C_{pq}\rtimes C_l .$$ The fact that there is at least one non-abelian group I showed the following way: we know that $|\text{Aut}(C_{pq})| = (p-1)(q-1)$, so $l$ divides its order, and as a consequence of the Sylow theorems we know that $C_l\hookrightarrow \text{Aut}(C_{pq})$, thus there is a non-trivial homomorphism which gives us a non-abelian group $C_{pq}\rtimes C_l$. The problem I'm having is showing that $\text{Aut}(C_{pq})$ can have at most $(l+1)$ copies of $C_l$ in it. Any hints?","If $l,p,q$ are primes with $l<p<q$, such that $$p\nmid (q-1)\hspace{1cm} l\mid (p-1)\hspace{1cm} l\mid (q-1) $$ I want to show that there are at least $1$ and at most $(l+1)$   non-abelian groups of order $lpq$. I already showed (using Sylow theorems) that in this case, if $G$ is a group with order $lpq$ then $$ G \cong C_{pq}\rtimes C_l .$$ The fact that there is at least one non-abelian group I showed the following way: we know that $|\text{Aut}(C_{pq})| = (p-1)(q-1)$, so $l$ divides its order, and as a consequence of the Sylow theorems we know that $C_l\hookrightarrow \text{Aut}(C_{pq})$, thus there is a non-trivial homomorphism which gives us a non-abelian group $C_{pq}\rtimes C_l$. The problem I'm having is showing that $\text{Aut}(C_{pq})$ can have at most $(l+1)$ copies of $C_l$ in it. Any hints?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'sylow-theory', 'semidirect-product']"
38,What is the history of the homomorphism concept?,What is the history of the homomorphism concept?,,"What is the history of the homomorphism concept and who coined the term? I seem to be thinking it arose in abstract algebra and groups/rings/fields, but at what time and by whom? People like Galois and Cauchy pioneered these fields but I understand the concept of function itself wasn't even that precise until Dedekind who was much later than them.","What is the history of the homomorphism concept and who coined the term? I seem to be thinking it arose in abstract algebra and groups/rings/fields, but at what time and by whom? People like Galois and Cauchy pioneered these fields but I understand the concept of function itself wasn't even that precise until Dedekind who was much later than them.",,"['abstract-algebra', 'soft-question', 'math-history']"
39,A finite ring of matrices is a finite field,A finite ring of matrices is a finite field,,"i have a prime number $p$ and an irreducible polynomial $R(x)$ of degree $n$ , $\alpha$ a root of $R$ then it's known that the field $\mathbb{F}_{p^n}$ is isomorphic to the field $\mathbb{F}_{p}[\alpha]$. let $M$ be the companion matrix of $R$ in particular . i wish to proof that $\mathbb{F}_{p}[M]$ is a field isomorphic to $\mathbb{F}_{p^n}$. i've noticed that $R(M)=O$ (Carley-Hamilton theorem) but i don't know whether or not $M$ lies in the algebraic closure of $\mathbb{F}_{p}$ if it dose that will give the result by construction of finite fields so i got stuck there... Next i tried to give an explicit isomorphism (ring isomorphism) \begin{array}{ccccc} \psi : & \mathbb{F}_{p^{n}} & \rightarrow  & \mathbb{F}_{p}[M] &  \\  & 0 & \rightarrow  & O &  \\  & \alpha ^{i} & \rightarrow  & M^{i} & 0<i<q^{n}-1% \end{array} with the assumption that $\alpha$ is a primitive element of  $\mathbb{F}_{p^{n}}$ it's easy to poof that $\psi(a*b)=\psi(a)*\psi(b)$ but i couldent proof that $\psi(a+b)=\psi(a)+\psi(b)$ UPDATE: can i say that $M$ is algebraic over  $\mathbb{F}_{p}$ ?","i have a prime number $p$ and an irreducible polynomial $R(x)$ of degree $n$ , $\alpha$ a root of $R$ then it's known that the field $\mathbb{F}_{p^n}$ is isomorphic to the field $\mathbb{F}_{p}[\alpha]$. let $M$ be the companion matrix of $R$ in particular . i wish to proof that $\mathbb{F}_{p}[M]$ is a field isomorphic to $\mathbb{F}_{p^n}$. i've noticed that $R(M)=O$ (Carley-Hamilton theorem) but i don't know whether or not $M$ lies in the algebraic closure of $\mathbb{F}_{p}$ if it dose that will give the result by construction of finite fields so i got stuck there... Next i tried to give an explicit isomorphism (ring isomorphism) \begin{array}{ccccc} \psi : & \mathbb{F}_{p^{n}} & \rightarrow  & \mathbb{F}_{p}[M] &  \\  & 0 & \rightarrow  & O &  \\  & \alpha ^{i} & \rightarrow  & M^{i} & 0<i<q^{n}-1% \end{array} with the assumption that $\alpha$ is a primitive element of  $\mathbb{F}_{p^{n}}$ it's easy to poof that $\psi(a*b)=\psi(a)*\psi(b)$ but i couldent proof that $\psi(a+b)=\psi(a)+\psi(b)$ UPDATE: can i say that $M$ is algebraic over  $\mathbb{F}_{p}$ ?",,['abstract-algebra']
40,"Short exact sequence of functors which splits, but not naturally (revisited, motivated by the Universal Coefficient Theorem)","Short exact sequence of functors which splits, but not naturally (revisited, motivated by the Universal Coefficient Theorem)",,"I already took a look at this and this post, but I still don't really understand what the definition of a naturally split sequence is (which is mentioned in the Universal Coefficient Theorem ). I tried to figure it out by myself, but it seems like I found something contradictory in my thoughts. Let me elaborate these: Let $A,B,C: R\text{-MOD} \to R\text{-MOD}$ be covariant functors such that $ 0 \xrightarrow{} A \xrightarrow{\eta} B \xrightarrow{\psi} C \xrightarrow{} 0 $ forms a natural short exact sequence and a (not necessarily naturally) split exact sequence . Furthermore, let $f:X\to Y$ be an $R$-module homomorphism. We can take a look at the diagram $$ \newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex} \newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex} \newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}} \newcommand{\ua}[1]{\bigg\uparrow\raise.5ex\rlap{\scriptstyle#1}} \newcommand{\id}{\operatorname{id}} \begin{array}{c} 0 & \ra{} & A(X) & \ra{i_X} & A(X) \oplus C(X) & \ra{p_X} & C(X) & \ra{} & 0 \\ & & \ua{\id_{A(X)}} & & \ua{\theta_X} & & \ua{\id_{C(X)}} \\ 0 & \ra{} & A(X) & \ra{\eta_X} & B(X) & \ra{\psi_X} & C(X) & \ra{} & 0 \\ & & \da{A(f)} & & \da{B(f)} & & \da{C(f)} &  \\ 0 & \ras{} & A(Y) & \ras{\eta_Y} & B(Y) & \ras{\psi_Y} & C(Y) & \ras{} & 0 \\ & & \da{\id_{A(Y)}} & & \da{\theta_Y} & & \da{\id_{C(Y)}} \\ 0 & \ra{} & A(Y) & \ra{i_Y} & A(Y) \oplus C(Y) & \ra{p_Y} & C(Y) & \ra{} & 0 \\ \end{array} $$ where $i$ denotes the natural embedding and $p$ denotes the natural projection. The upper and lower part of this diagram commutes because of 2. and the middle part is commutative because of 1. Hence, the whole diagram commutes. Since this diagram commutes, we get a commutative diagram $$ \newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex} \newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex} \newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}} \newcommand{\ua}[1]{\bigg\uparrow\raise.5ex\rlap{\scriptstyle#1}} \newcommand{\id}{\operatorname{id}} \begin{array}{c}  A(X) & \ra{i_X} & A(X) \oplus C(X) & \ra{p_X} & C(X)   \\  \da{A(f)} & & \da{\theta_Y \circ B(f) \circ \theta_X^{-1}} & & \da{C(f)} \\  A(Y) & \ra{i_Y} & A(Y) \oplus C(Y) & \ra{p_Y} & C(Y)   \\ \end{array}. $$ One can show that such a commutative diagram must lead to $\theta_Y \circ B(f) \circ \theta_X^{-1} = A(f) \oplus C(f)$, so $\theta_Y \circ B(f)  = \left(A(f) \oplus C(f)\right) \circ \theta_X$. But this shows that $\theta: B \to A \oplus C$ is a natural isomorphism which is the definition of naturally split, isn't it? But this seems to be wrong since the Universal Coefficient Theorem states that there is a split exact sequence which does not split naturally. Could you explain me what's wrong with my reasoning? Thank you.","I already took a look at this and this post, but I still don't really understand what the definition of a naturally split sequence is (which is mentioned in the Universal Coefficient Theorem ). I tried to figure it out by myself, but it seems like I found something contradictory in my thoughts. Let me elaborate these: Let $A,B,C: R\text{-MOD} \to R\text{-MOD}$ be covariant functors such that $ 0 \xrightarrow{} A \xrightarrow{\eta} B \xrightarrow{\psi} C \xrightarrow{} 0 $ forms a natural short exact sequence and a (not necessarily naturally) split exact sequence . Furthermore, let $f:X\to Y$ be an $R$-module homomorphism. We can take a look at the diagram $$ \newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex} \newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex} \newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}} \newcommand{\ua}[1]{\bigg\uparrow\raise.5ex\rlap{\scriptstyle#1}} \newcommand{\id}{\operatorname{id}} \begin{array}{c} 0 & \ra{} & A(X) & \ra{i_X} & A(X) \oplus C(X) & \ra{p_X} & C(X) & \ra{} & 0 \\ & & \ua{\id_{A(X)}} & & \ua{\theta_X} & & \ua{\id_{C(X)}} \\ 0 & \ra{} & A(X) & \ra{\eta_X} & B(X) & \ra{\psi_X} & C(X) & \ra{} & 0 \\ & & \da{A(f)} & & \da{B(f)} & & \da{C(f)} &  \\ 0 & \ras{} & A(Y) & \ras{\eta_Y} & B(Y) & \ras{\psi_Y} & C(Y) & \ras{} & 0 \\ & & \da{\id_{A(Y)}} & & \da{\theta_Y} & & \da{\id_{C(Y)}} \\ 0 & \ra{} & A(Y) & \ra{i_Y} & A(Y) \oplus C(Y) & \ra{p_Y} & C(Y) & \ra{} & 0 \\ \end{array} $$ where $i$ denotes the natural embedding and $p$ denotes the natural projection. The upper and lower part of this diagram commutes because of 2. and the middle part is commutative because of 1. Hence, the whole diagram commutes. Since this diagram commutes, we get a commutative diagram $$ \newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex} \newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex} \newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}} \newcommand{\ua}[1]{\bigg\uparrow\raise.5ex\rlap{\scriptstyle#1}} \newcommand{\id}{\operatorname{id}} \begin{array}{c}  A(X) & \ra{i_X} & A(X) \oplus C(X) & \ra{p_X} & C(X)   \\  \da{A(f)} & & \da{\theta_Y \circ B(f) \circ \theta_X^{-1}} & & \da{C(f)} \\  A(Y) & \ra{i_Y} & A(Y) \oplus C(Y) & \ra{p_Y} & C(Y)   \\ \end{array}. $$ One can show that such a commutative diagram must lead to $\theta_Y \circ B(f) \circ \theta_X^{-1} = A(f) \oplus C(f)$, so $\theta_Y \circ B(f)  = \left(A(f) \oplus C(f)\right) \circ \theta_X$. But this shows that $\theta: B \to A \oplus C$ is a natural isomorphism which is the definition of naturally split, isn't it? But this seems to be wrong since the Universal Coefficient Theorem states that there is a split exact sequence which does not split naturally. Could you explain me what's wrong with my reasoning? Thank you.",,"['abstract-algebra', 'algebraic-topology', 'category-theory', 'homological-algebra']"
41,Composite of fields of the form $\sigma(K)$ is precisely $L$,Composite of fields of the form  is precisely,\sigma(K) L,I'm trying to understand the proof of lemma 38 in chapter 14 of Dummit and Foote. Suppose $K/F$ is a root extension and $L$ is the Galois closure of $K$ over $F$. Then the composite field of $\sigma(K)$ for all $\sigma \in \operatorname{Gal}(L/F)$ is precisely $L$. Could someone please explain to me why this is true? Thanks in advance!,I'm trying to understand the proof of lemma 38 in chapter 14 of Dummit and Foote. Suppose $K/F$ is a root extension and $L$ is the Galois closure of $K$ over $F$. Then the composite field of $\sigma(K)$ for all $\sigma \in \operatorname{Gal}(L/F)$ is precisely $L$. Could someone please explain to me why this is true? Thanks in advance!,,"['abstract-algebra', 'galois-theory']"
42,Extending morphisms via Zorn's Lemma,Extending morphisms via Zorn's Lemma,,"In the linked question here, the user demonstrates two examples of extension of morphisms using Zorn's Lemma arguments, and I've seen the same pattern to extend morphisms before in other sources. However, none of them contain a verification of the condition of Zorn's lemma that every totally ordered subset has an upper bound. They jump straight from establishing the order relation to the existence of a maximal element. Presumably this is because the verification follows a routine pattern that is obvious if you have seen it before. But supposing I haven't, how do we know that these posets meet the upper bound condition of Zorn's Lemma?","In the linked question here, the user demonstrates two examples of extension of morphisms using Zorn's Lemma arguments, and I've seen the same pattern to extend morphisms before in other sources. However, none of them contain a verification of the condition of Zorn's lemma that every totally ordered subset has an upper bound. They jump straight from establishing the order relation to the existence of a maximal element. Presumably this is because the verification follows a routine pattern that is obvious if you have seen it before. But supposing I haven't, how do we know that these posets meet the upper bound condition of Zorn's Lemma?",,"['abstract-algebra', 'field-theory', 'set-theory', 'order-theory']"
43,"Is $\operatorname{Hom}_R(R,G)\cong G$?",Is ?,"\operatorname{Hom}_R(R,G)\cong G","In this question ( How to show that for any abelian group $G$, $\text{Hom}(\mathbb{Z},G)$ is isomorphic to $G$ ), it is shown that $\operatorname{Hom}_\mathbb{Z}(\mathbb{Z},G)\cong G$, where $G$ is an abelian group (i.e. $\mathbb{Z}$-module). When we generalize to $R$-modules, can we still say $$\operatorname{Hom}_R(R,G)\cong G ?$$ (isomorphic as $R$-modules) ($R$ is a commutative ring with 1, $G$ is an $R$-module). I tried using the same isomorphism $\phi: \operatorname{Hom}_R(R,G)\to G$ defined by $f\mapsto f(1)$. It seems to work out; $\phi$ is an $R$-module homomorphism. It is injective since if $f(1)=0$, then $f(r)=rf(1)=0$ for all $r\in R$, so $f$ is the zero homomorphism. It is surjective since any for any $g\in g$, we can define a $f\in \operatorname{Hom}_R(R,G)$ such that $f(1)=g$, and then $f(r)=rf(1)=rg$ for any $r\in R$. Is the above reasoning correct? Thanks.","In this question ( How to show that for any abelian group $G$, $\text{Hom}(\mathbb{Z},G)$ is isomorphic to $G$ ), it is shown that $\operatorname{Hom}_\mathbb{Z}(\mathbb{Z},G)\cong G$, where $G$ is an abelian group (i.e. $\mathbb{Z}$-module). When we generalize to $R$-modules, can we still say $$\operatorname{Hom}_R(R,G)\cong G ?$$ (isomorphic as $R$-modules) ($R$ is a commutative ring with 1, $G$ is an $R$-module). I tried using the same isomorphism $\phi: \operatorname{Hom}_R(R,G)\to G$ defined by $f\mapsto f(1)$. It seems to work out; $\phi$ is an $R$-module homomorphism. It is injective since if $f(1)=0$, then $f(r)=rf(1)=0$ for all $r\in R$, so $f$ is the zero homomorphism. It is surjective since any for any $g\in g$, we can define a $f\in \operatorname{Hom}_R(R,G)$ such that $f(1)=g$, and then $f(r)=rf(1)=rg$ for any $r\in R$. Is the above reasoning correct? Thanks.",,"['abstract-algebra', 'modules']"
44,Are all elements of order $2$ in $\mathrm{Gal}(\overline{\Bbb Q} / \Bbb Q)$ conjugate?,Are all elements of order  in  conjugate?,2 \mathrm{Gal}(\overline{\Bbb Q} / \Bbb Q),"Let $G$ be the absolute Galois group of $\Bbb Q$. Is it true that any two elements of order $2$ in $G$ are conjugate (in $G$) ? I've seen this question , but the answer only shows that any element of finite order in $G$ has order $≤2$. Apparently, Artin answered positively to my question, but I found no reference for this result. Any help would be appreciated.","Let $G$ be the absolute Galois group of $\Bbb Q$. Is it true that any two elements of order $2$ in $G$ are conjugate (in $G$) ? I've seen this question , but the answer only shows that any element of finite order in $G$ has order $≤2$. Apparently, Artin answered positively to my question, but I found no reference for this result. Any help would be appreciated.",,"['abstract-algebra', 'field-theory', 'galois-theory']"
45,Prime and primary ideals in $\mathbb{Z}[\sqrt{5}]$,Prime and primary ideals in,\mathbb{Z}[\sqrt{5}],"Let $R=\mathbb{Z}[\sqrt{5}]$. The ideal $(2, 1-\sqrt{5})$ is prime in $R$, right (as $R/(2, 1-\sqrt{5})=\mathbb{F}_2$)? 1. Is then $(2^n, 1-\sqrt{5})$ primary for some $n\geq2$? 2. Are $(2)$ and $(3)$ prime ideals and $(2^n)$ and $(3^k)$ primary ideals in $R$? I was thinking that at least $(2^n)$ should be primary as the zero divisors of $R/(2^n)$ are $2, 1+\sqrt{5}, 1-\sqrt{5}$, i.e. nilpotent... Or are there some problems as $-4=(1+\sqrt{5})(1-\sqrt{5})$...","Let $R=\mathbb{Z}[\sqrt{5}]$. The ideal $(2, 1-\sqrt{5})$ is prime in $R$, right (as $R/(2, 1-\sqrt{5})=\mathbb{F}_2$)? 1. Is then $(2^n, 1-\sqrt{5})$ primary for some $n\geq2$? 2. Are $(2)$ and $(3)$ prime ideals and $(2^n)$ and $(3^k)$ primary ideals in $R$? I was thinking that at least $(2^n)$ should be primary as the zero divisors of $R/(2^n)$ are $2, 1+\sqrt{5}, 1-\sqrt{5}$, i.e. nilpotent... Or are there some problems as $-4=(1+\sqrt{5})(1-\sqrt{5})$...",,"['abstract-algebra', 'commutative-algebra', 'algebraic-number-theory', 'ideals']"
46,Is $\mathbb{Z}[x]/(x^2+2x+1)$ isomorphic to a product of non-trivial rings?,Is  isomorphic to a product of non-trivial rings?,\mathbb{Z}[x]/(x^2+2x+1),"As in the title: is there an isomorphism from $R=\mathbb{Z}[x]/(x^2+2x+1)$ to a non-trivial product of rings? I know already that there will be such an isomorphism if and only if there exist non-trivial idempotents in $R$. My thoughts so far have been: try to rearrange the generator of the ideal $x^2+2x+1=0$ to something of the form $a^2=a$, thus finding a non-trivial idempotent. I can't seem to do this. show somehow that no such element can exist. I'm not at all sure how I'd go about this.","As in the title: is there an isomorphism from $R=\mathbb{Z}[x]/(x^2+2x+1)$ to a non-trivial product of rings? I know already that there will be such an isomorphism if and only if there exist non-trivial idempotents in $R$. My thoughts so far have been: try to rearrange the generator of the ideal $x^2+2x+1=0$ to something of the form $a^2=a$, thus finding a non-trivial idempotent. I can't seem to do this. show somehow that no such element can exist. I'm not at all sure how I'd go about this.",,"['abstract-algebra', 'ring-theory', 'idempotents', 'ring-isomorphism']"
47,"Difference between rings of continuous functions on $[0,1]$ and $(0,1)$.",Difference between rings of continuous functions on  and .,"[0,1] (0,1)","Consider $X=[0,1],Y=(0,1)$. Denote $C(W)=$set of real-valued continuous functions on $W$. Here $X$ and $Y$ are inherited the standard topology from $R$. What is the difference between two rings $C(X),C(Y)$? Clearly $C(Y)$ has functions which are not considered continuous on $X$ as $\frac{1}{(x-1)^r},\frac{1}{x^r}$ for $r\in R_{>0}$. But I can always restrict the functions on $X$ to $Y$ to obtain a continuous map by considering $Y$ as a subspace of $X$. So I have $C(X)\xrightarrow{Res^X_Y}C(Y)$ and this should be mono. The compactness of $[0,1]$ requires the function bounded whereas $C(Y)$ does not have this property. How does the ring structure recognize topological difference or do we pass the topological difference through the ring structure like what we have done in sheaf of regular functions through some sort of localization technique? Is there a generic recipe to construct the structure of these rings from $X$ or $Y$?","Consider $X=[0,1],Y=(0,1)$. Denote $C(W)=$set of real-valued continuous functions on $W$. Here $X$ and $Y$ are inherited the standard topology from $R$. What is the difference between two rings $C(X),C(Y)$? Clearly $C(Y)$ has functions which are not considered continuous on $X$ as $\frac{1}{(x-1)^r},\frac{1}{x^r}$ for $r\in R_{>0}$. But I can always restrict the functions on $X$ to $Y$ to obtain a continuous map by considering $Y$ as a subspace of $X$. So I have $C(X)\xrightarrow{Res^X_Y}C(Y)$ and this should be mono. The compactness of $[0,1]$ requires the function bounded whereas $C(Y)$ does not have this property. How does the ring structure recognize topological difference or do we pass the topological difference through the ring structure like what we have done in sheaf of regular functions through some sort of localization technique? Is there a generic recipe to construct the structure of these rings from $X$ or $Y$?",,"['abstract-algebra', 'functional-analysis', 'algebraic-geometry', 'ring-theory', 'sheaf-theory']"
48,Proof for elements of $\textbf{Z}[\sqrt{3}]$ regarding the existence of the norm.,Proof for elements of  regarding the existence of the norm.,\textbf{Z}[\sqrt{3}],"Prove that if there exists elements $z$ and $x$ of $\textbf{Z}[\sqrt{3}]$ such that $N(z)=ab$ and $N(x)=a$ where $a$ and $b$ are integers, then there exists a $y \in \textbf{Z}[\sqrt{3}]$ such that $N(y)=b$ . Background statements: The norm of an element of $\textbf{Z}[\sqrt{3}]$ referred to as $z = a+b\sqrt{3}$ where $a$ and $b$ are integers is defined to be $N(z) = a^2 - 3b^2$ . We already proved that the norm is always an integer.","Prove that if there exists elements and of such that and where and are integers, then there exists a such that . Background statements: The norm of an element of referred to as where and are integers is defined to be . We already proved that the norm is always an integer.",z x \textbf{Z}[\sqrt{3}] N(z)=ab N(x)=a a b y \in \textbf{Z}[\sqrt{3}] N(y)=b \textbf{Z}[\sqrt{3}] z = a+b\sqrt{3} a b N(z) = a^2 - 3b^2,"['abstract-algebra', 'elementary-number-theory', 'polynomials', 'algebraic-number-theory']"
49,Proof of Fundamental Theorem of Finite Abelian Groups,Proof of Fundamental Theorem of Finite Abelian Groups,,"Statement: Let G be an Abelian group of prime-power order and let a be an element of maximum order in G. Then G can be written in the form $a \times K$. Proof: We denote |G| by p^n and induct on n. If n = 1, then G = $\langle a \rangle \times \langle e \rangle$. Now assume that the statement is true for all Abelian groups of order $p^k$, where $k < n$.  Among all elements of G, choose $a$ of maximum order $p^m$. [Question: Why are we picking any random m for the order of a? For Abelian groups, isn't the converse of Lagrange always true? So shouldn't the element a have order $p^{k-1}$?] Then $x^{p^m} = e$ for all $x$ in G. [Question: How, if |G| = p^k?] We assume that $G \neq \langle a \rangle$, as there would be nothing left to prove then.  Now among all elements of G, choose $b$ of smallest order such does $b \not\in \langle a \rangle$.  We claim that $\langle b \rangle \cap \langle a \rangle = e$ Since $|b^p| = |b|/p$, we know that $b^p \in \langle a \rangle$ by the manner in which b is chosen. [Question: What does he mean by the manner in which b is chosen? Why does b^p lie in the set generated by a? Is it because the group with the minimum order has to have order p according to Lagrange and this straightaway implies b^p = e?] Say $b^p = a^i$. Notice that $e=b^{p^m}=(b^p)^{p^{m-1}} = (a^i)^{p^{m-1}}$, so $|a^i| \leq p^{m-1}$.  Thus, $a^i$ is not a generator of . Therefore, $gcd(p^m,i) \neq 1$. This proves that $p$ divides $i$. Let $i = pj$. Then $b^p = a^i = a^{pj}$. Consider the element $c = a^{-j}b$. $c$ is not in .  $c^p = a^{-jp}b^p$. Thus $c$ is an element of order p such that c is not in . Since b was chosen to have minimal order, we can finally say that b has an order of p.  It now follows that $\langle a \rangle \cap \langle b \rangle = {e}$, because any non-identity element of the intersection would generate $\langle b \rangle$ and thus contradict that b lies in . Consider the factor group $\overline{G} = G/\langle b \rangle$. Let $\overline{x}=x\langle b \rangle$ in G.  If $|\overline{a}| < |a| = p^m$, then $\overline{a}^{p^{m-1}} = \overline{e}$. [Question: here we have picked $p^{m-1}$ just as any arbitrary number less than $p^m$, but still a power of $p$, right?] This means that $(a\langle b \rangle)^{p^{m-1}} = a^{p^{m-1}}\langle b \rangle = \langle b \rangle$. This implies that the order of a is $p^{m-1}$, which is absurd. So order of a-bar is equal to order of a which is $p^m$.  Therefore $\overline{a}$ is an element of maximum order in $\overline{G}$. By induction, we know that $\overline{G} = \langle a \rangle \times \overline{K}$. [Question: ??? What induction? What is the basis of this step? What even is K? How are we even defining K in the steps below?] Let K be the pullback of $\overline{K}$ under the natural homomorphism from G to G-bar. We claim that $\langle a \rangle \cap K = {e}$. For if $x \in \langle \overline{a} \rangle \cap \overline{K} = {e} = \langle b \rangle$ and $x \in \langle a \rangle \cap \langle b \rangle = {e}$. It now follows from an order argument (???) that $G = <a>K$, and therefore $G = \langle a \rangle \times K$. I am currently teaching myself abstract algebra and real analysis and this proof has be confused for a while now. I apologize for the length of the post, but I could not think of any other way to convey my doubts in any concise manner.","Statement: Let G be an Abelian group of prime-power order and let a be an element of maximum order in G. Then G can be written in the form $a \times K$. Proof: We denote |G| by p^n and induct on n. If n = 1, then G = $\langle a \rangle \times \langle e \rangle$. Now assume that the statement is true for all Abelian groups of order $p^k$, where $k < n$.  Among all elements of G, choose $a$ of maximum order $p^m$. [Question: Why are we picking any random m for the order of a? For Abelian groups, isn't the converse of Lagrange always true? So shouldn't the element a have order $p^{k-1}$?] Then $x^{p^m} = e$ for all $x$ in G. [Question: How, if |G| = p^k?] We assume that $G \neq \langle a \rangle$, as there would be nothing left to prove then.  Now among all elements of G, choose $b$ of smallest order such does $b \not\in \langle a \rangle$.  We claim that $\langle b \rangle \cap \langle a \rangle = e$ Since $|b^p| = |b|/p$, we know that $b^p \in \langle a \rangle$ by the manner in which b is chosen. [Question: What does he mean by the manner in which b is chosen? Why does b^p lie in the set generated by a? Is it because the group with the minimum order has to have order p according to Lagrange and this straightaway implies b^p = e?] Say $b^p = a^i$. Notice that $e=b^{p^m}=(b^p)^{p^{m-1}} = (a^i)^{p^{m-1}}$, so $|a^i| \leq p^{m-1}$.  Thus, $a^i$ is not a generator of . Therefore, $gcd(p^m,i) \neq 1$. This proves that $p$ divides $i$. Let $i = pj$. Then $b^p = a^i = a^{pj}$. Consider the element $c = a^{-j}b$. $c$ is not in .  $c^p = a^{-jp}b^p$. Thus $c$ is an element of order p such that c is not in . Since b was chosen to have minimal order, we can finally say that b has an order of p.  It now follows that $\langle a \rangle \cap \langle b \rangle = {e}$, because any non-identity element of the intersection would generate $\langle b \rangle$ and thus contradict that b lies in . Consider the factor group $\overline{G} = G/\langle b \rangle$. Let $\overline{x}=x\langle b \rangle$ in G.  If $|\overline{a}| < |a| = p^m$, then $\overline{a}^{p^{m-1}} = \overline{e}$. [Question: here we have picked $p^{m-1}$ just as any arbitrary number less than $p^m$, but still a power of $p$, right?] This means that $(a\langle b \rangle)^{p^{m-1}} = a^{p^{m-1}}\langle b \rangle = \langle b \rangle$. This implies that the order of a is $p^{m-1}$, which is absurd. So order of a-bar is equal to order of a which is $p^m$.  Therefore $\overline{a}$ is an element of maximum order in $\overline{G}$. By induction, we know that $\overline{G} = \langle a \rangle \times \overline{K}$. [Question: ??? What induction? What is the basis of this step? What even is K? How are we even defining K in the steps below?] Let K be the pullback of $\overline{K}$ under the natural homomorphism from G to G-bar. We claim that $\langle a \rangle \cap K = {e}$. For if $x \in \langle \overline{a} \rangle \cap \overline{K} = {e} = \langle b \rangle$ and $x \in \langle a \rangle \cap \langle b \rangle = {e}$. It now follows from an order argument (???) that $G = <a>K$, and therefore $G = \langle a \rangle \times K$. I am currently teaching myself abstract algebra and real analysis and this proof has be confused for a while now. I apologize for the length of the post, but I could not think of any other way to convey my doubts in any concise manner.",,"['abstract-algebra', 'abelian-groups']"
50,number of subgroups of order $ n $ in $S_n$,number of subgroups of order  in, n  S_n,"How can we find the number of subgroups of order $n$, where $n$ is prime, in the symmetric group $S_n$? Typically, I am interested in, say $S_{17}$. I am stuck at this problem. I think it has something to do with the conjugacy classes of the symmetric group. Any ideas. Thanks beforehand.","How can we find the number of subgroups of order $n$, where $n$ is prime, in the symmetric group $S_n$? Typically, I am interested in, say $S_{17}$. I am stuck at this problem. I think it has something to do with the conjugacy classes of the symmetric group. Any ideas. Thanks beforehand.",,"['abstract-algebra', 'group-theory', 'symmetric-groups']"
51,Gauss prime divides exactly one integer prime in $\mathbb{Z}[i]$,Gauss prime divides exactly one integer prime in,\mathbb{Z}[i],"I am asked to show that a Gauss prime $\pi$ divides exactly one integer prime in $\mathbb{Z}[i]$. To show existence, I have tried to use the fact that the product $\pi \overline{\pi}$ is equal to either an integer prime $p$ or the square of integer prime $p^2$. If $\pi$ satisfies the first case, then the statement is immediate. How about when $\pi \overline{\pi}=p^2$? Also, how do we show that $\pi$ divides no other integer primes (i.e. uniqueness)?","I am asked to show that a Gauss prime $\pi$ divides exactly one integer prime in $\mathbb{Z}[i]$. To show existence, I have tried to use the fact that the product $\pi \overline{\pi}$ is equal to either an integer prime $p$ or the square of integer prime $p^2$. If $\pi$ satisfies the first case, then the statement is immediate. How about when $\pi \overline{\pi}=p^2$? Also, how do we show that $\pi$ divides no other integer primes (i.e. uniqueness)?",,"['abstract-algebra', 'algebraic-number-theory']"
52,"Neutral element in $\hom_C(A, B)$",Neutral element in,"\hom_C(A, B)","Let $C$ be an abelian category. Assuming that $\hom_C(A,B)$ has an abelian group structure, prove that the zero map $0_{AB}:A\to B$ is the neutral element of this group. I know that the group operation can be defined as $f+g:=\nabla_B\circ(f\oplus g)\circ \Delta_A$ for every $f, g\in\hom_C(A, B)$, where $\oplus$ is the biproduct, $\Delta_X:X\to X\oplus X$ is the diagonal map and $\nabla_X:X\oplus X\to X$ is the codiagonal map. Defining $\varphi:=(f\oplus 0_{AB})\circ \Delta_A$, I've shown that $\pi_1\circ\varphi=f$ and that $\pi_2\circ\varphi=0_{AB}$ (where $\pi_1$, $\pi_2$ are the natural projections), which intuitively means that $f+0_{AB}=\nabla_B\circ \varphi=f$, but I don't know how to formalize this. How do I show this formaly?","Let $C$ be an abelian category. Assuming that $\hom_C(A,B)$ has an abelian group structure, prove that the zero map $0_{AB}:A\to B$ is the neutral element of this group. I know that the group operation can be defined as $f+g:=\nabla_B\circ(f\oplus g)\circ \Delta_A$ for every $f, g\in\hom_C(A, B)$, where $\oplus$ is the biproduct, $\Delta_X:X\to X\oplus X$ is the diagonal map and $\nabla_X:X\oplus X\to X$ is the codiagonal map. Defining $\varphi:=(f\oplus 0_{AB})\circ \Delta_A$, I've shown that $\pi_1\circ\varphi=f$ and that $\pi_2\circ\varphi=0_{AB}$ (where $\pi_1$, $\pi_2$ are the natural projections), which intuitively means that $f+0_{AB}=\nabla_B\circ \varphi=f$, but I don't know how to formalize this. How do I show this formaly?",,"['abstract-algebra', 'commutative-algebra', 'category-theory', 'abelian-categories']"
53,Why is $L=\mathbb{Q}(\sqrt[1]{2})\cup\mathbb{Q}(\sqrt[2]{2})\cup\mathbb{Q}(\sqrt[3]{2})\cup\cdots$ a field?,Why is  a field?,L=\mathbb{Q}(\sqrt[1]{2})\cup\mathbb{Q}(\sqrt[2]{2})\cup\mathbb{Q}(\sqrt[3]{2})\cup\cdots,"The title sais it already: Why is $L=\mathbb{Q}(\sqrt[1]{2})\cup\mathbb{Q}(\sqrt[2]{2})\cup\mathbb{Q}(\sqrt[3]{2})\cup\cdots$ a field? The hint provided in my textbook is: $\mathbb{Q}(\sqrt[n]{2})\cup\mathbb{Q}(\sqrt[m]{2})\subset\mathbb{Q}(\sqrt[mn]{2})$, but this doesn't really get me anywhere. Actually, I have no idea what to do whatsoever. Could anyone clarify or give some hint please?","The title sais it already: Why is $L=\mathbb{Q}(\sqrt[1]{2})\cup\mathbb{Q}(\sqrt[2]{2})\cup\mathbb{Q}(\sqrt[3]{2})\cup\cdots$ a field? The hint provided in my textbook is: $\mathbb{Q}(\sqrt[n]{2})\cup\mathbb{Q}(\sqrt[m]{2})\subset\mathbb{Q}(\sqrt[mn]{2})$, but this doesn't really get me anywhere. Actually, I have no idea what to do whatsoever. Could anyone clarify or give some hint please?",,"['abstract-algebra', 'field-theory']"
54,Is it true that cyclic subgroups are always normal?,Is it true that cyclic subgroups are always normal?,,"There is a proposition that I'm supposed to ""prove"", but it doesn't sound true to me. It says that if $H$ is a cyclic subgroup of a group $G$ (notation $H<G$), then every $K <H$ is normal in $G$. If that were the case, since $H<H$, we'd have a corollary: If $H$ is cyclic, then $H$ is normal in $G$. But is that even true?","There is a proposition that I'm supposed to ""prove"", but it doesn't sound true to me. It says that if $H$ is a cyclic subgroup of a group $G$ (notation $H<G$), then every $K <H$ is normal in $G$. If that were the case, since $H<H$, we'd have a corollary: If $H$ is cyclic, then $H$ is normal in $G$. But is that even true?",,"['abstract-algebra', 'group-theory', 'cyclic-groups', 'normal-subgroups']"
55,Factorization of $X^{p^n}-X-c$ over $\mathbb{F}_{p^n}$,Factorization of  over,X^{p^n}-X-c \mathbb{F}_{p^n},"When looking through some old exercises, I have found one which stumped me a bit, and which has been bugging me for quite a few days. The question is how the polynomial $X^{p^n}-X-c$ factorizes over $\mathbb{F}_{p^n}$ (with $c \in \mathbb{F}_{p^n}$). The case when $n=1$ is easy, we find that the polynomial is irreducible. However in the more general case, it gets quite hard! I can't (I think) easily generalize the argument I used for when $n=1$, there I just used that if $r$ is a root of the polynomial in question we also find that $r \notin \mathbb{F}_{p}$ and that $r+i$ is a root for all $i \in \mathbb{F}_p$. The rest follows by looking at the explicit factorization over $\overline{\mathbb{F}_{p}}$ However when $n \neq 1$, I can't easily use the fact that $r \notin \mathbb{F}_{p^n}$. So my earlier arguments stops working, there's a hint that I could look at how the Frobenius automorphism acts on the roots of our polynomial, so i think I could use something about our polynomial being separable, however I didn't really see how. Any hints or answers would be greatly appreciated!","When looking through some old exercises, I have found one which stumped me a bit, and which has been bugging me for quite a few days. The question is how the polynomial $X^{p^n}-X-c$ factorizes over $\mathbb{F}_{p^n}$ (with $c \in \mathbb{F}_{p^n}$). The case when $n=1$ is easy, we find that the polynomial is irreducible. However in the more general case, it gets quite hard! I can't (I think) easily generalize the argument I used for when $n=1$, there I just used that if $r$ is a root of the polynomial in question we also find that $r \notin \mathbb{F}_{p}$ and that $r+i$ is a root for all $i \in \mathbb{F}_p$. The rest follows by looking at the explicit factorization over $\overline{\mathbb{F}_{p}}$ However when $n \neq 1$, I can't easily use the fact that $r \notin \mathbb{F}_{p^n}$. So my earlier arguments stops working, there's a hint that I could look at how the Frobenius automorphism acts on the roots of our polynomial, so i think I could use something about our polynomial being separable, however I didn't really see how. Any hints or answers would be greatly appreciated!",,"['abstract-algebra', 'polynomials', 'field-theory', 'galois-theory', 'finite-fields']"
56,Number of units in a commutative ring,Number of units in a commutative ring,,"In our Abstract Algebra class, we have just discussed the idea of a unit in a general ring and has posed the following question: ""Prove that there cannot be a commutative ring with $1$ (the multiplicative identity) and $5$ units"". My assumption was that there are no commutative rings that have an odd amount of units. This is because if $a$ is a unit, then there is a $b \in R$ such that $ab = ba = 1$. But, wouldn't this imply that $b$ would have to be a unit as well? And also, I know that if $a$ is a unit, then $-a$ is a unit as well. So, this would imply that units have to come in pairs and thus, we can never have an odd amount of units. However, this person has constructed a ring with an odd amount of units. So, I guess my question is why can I not have $5$ units in a commutative ring? What about the commutativity gives me the fact that I cannot have $5$ units?","In our Abstract Algebra class, we have just discussed the idea of a unit in a general ring and has posed the following question: ""Prove that there cannot be a commutative ring with $1$ (the multiplicative identity) and $5$ units"". My assumption was that there are no commutative rings that have an odd amount of units. This is because if $a$ is a unit, then there is a $b \in R$ such that $ab = ba = 1$. But, wouldn't this imply that $b$ would have to be a unit as well? And also, I know that if $a$ is a unit, then $-a$ is a unit as well. So, this would imply that units have to come in pairs and thus, we can never have an odd amount of units. However, this person has constructed a ring with an odd amount of units. So, I guess my question is why can I not have $5$ units in a commutative ring? What about the commutativity gives me the fact that I cannot have $5$ units?",,"['abstract-algebra', 'ring-theory']"
57,What is the decomposition of the ring $\mathbb{F}_p[x]/(x^n-1)$?,What is the decomposition of the ring ?,\mathbb{F}_p[x]/(x^n-1),"Let $p$ be a prime, and $n\ge 1$ an integer. I'd like to decompose the ring $\mathbb{F}_p[x]/(x^n-1)$ into a direct product of artinian local rings. I know we can write $x^n-1 = \prod_{d\mid n}\Phi_d(x)$, but how do the cyclotomic polynomials $\Phi_d(x)$ decompose mod $p$? I know their irreducible factors should have degree equal to the order of $p$ modulo $d$. Can $\Phi_d(x)$ have distinct irreducible factors (or do they always decompose as a power of an irreducible?)? Can $\Phi_d(x),\Phi_{d'}(x)$ share irreducible factors for $d\ne d'$? Is there a nice way to write this decomposition?","Let $p$ be a prime, and $n\ge 1$ an integer. I'd like to decompose the ring $\mathbb{F}_p[x]/(x^n-1)$ into a direct product of artinian local rings. I know we can write $x^n-1 = \prod_{d\mid n}\Phi_d(x)$, but how do the cyclotomic polynomials $\Phi_d(x)$ decompose mod $p$? I know their irreducible factors should have degree equal to the order of $p$ modulo $d$. Can $\Phi_d(x)$ have distinct irreducible factors (or do they always decompose as a power of an irreducible?)? Can $\Phi_d(x),\Phi_{d'}(x)$ share irreducible factors for $d\ne d'$? Is there a nice way to write this decomposition?",,"['abstract-algebra', 'group-theory']"
58,$x^p-a$ irreducible?,irreducible?,x^p-a,"Assume $F$ is a subfield of the complex numbers containing the $p$-th roots of unity. If $\alpha$ is a root of $x^p-a$ for some $a\in F$, and $\alpha \not\in F$ then $x^p-a$ is irreducible. To me it seems obvious that the polynomial $f$ of smallest degree in $F[x]$ such $f(\alpha)=0$ is $x^p-a$. Proving that however has been a challenge. Given another polynomial $g(x)\in F[x]$ with $deg(g)<p$ and $g(\alpha)=0$ what contradiction could I arrive at?","Assume $F$ is a subfield of the complex numbers containing the $p$-th roots of unity. If $\alpha$ is a root of $x^p-a$ for some $a\in F$, and $\alpha \not\in F$ then $x^p-a$ is irreducible. To me it seems obvious that the polynomial $f$ of smallest degree in $F[x]$ such $f(\alpha)=0$ is $x^p-a$. Proving that however has been a challenge. Given another polynomial $g(x)\in F[x]$ with $deg(g)<p$ and $g(\alpha)=0$ what contradiction could I arrive at?",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
59,What are the good books or lecture notes for learning field extension and Galois theory?,What are the good books or lecture notes for learning field extension and Galois theory?,,I am a undergraduate student with some knowledge of group theory and ring theory. May I ask how should I do to  get start to field theory? Could someone tell me what are good to read? Thanks in advance!,I am a undergraduate student with some knowledge of group theory and ring theory. May I ask how should I do to  get start to field theory? Could someone tell me what are good to read? Thanks in advance!,,"['abstract-algebra', 'field-theory', 'galois-theory', 'extension-field', 'big-list']"
60,Clarifying maps in algebraic number theory,Clarifying maps in algebraic number theory,,"Let $K$ be a quadratic imaginary number field. I wonder why, something which seems to be standard (yet by no means clear for me) is a natural map: $$\mathbf{Z}/\mathfrak{m} \cap \mathbf{Z} \longrightarrow \mathcal{O}_K/\mathfrak{m}$$ Do we know explicitly what this map is? I am more precisely interested in determining whether or not a given element is in the image, but I feel totally lost. It is often mentionned the following exact sequence: $$1 \to \mathbf{C}^\times \times \hat{\mathcal{O}}^\times \to \mathbf{A}(K)^\times/K^\times \to Cl(K) \to 1$$ But I do not see the relation... Do someone has any idea or source? It will be of great help!","Let $K$ be a quadratic imaginary number field. I wonder why, something which seems to be standard (yet by no means clear for me) is a natural map: $$\mathbf{Z}/\mathfrak{m} \cap \mathbf{Z} \longrightarrow \mathcal{O}_K/\mathfrak{m}$$ Do we know explicitly what this map is? I am more precisely interested in determining whether or not a given element is in the image, but I feel totally lost. It is often mentionned the following exact sequence: $$1 \to \mathbf{C}^\times \times \hat{\mathcal{O}}^\times \to \mathbf{A}(K)^\times/K^\times \to Cl(K) \to 1$$ But I do not see the relation... Do someone has any idea or source? It will be of great help!",,"['abstract-algebra', 'number-theory', 'ring-theory', 'algebraic-number-theory', 'ideals']"
61,How many irreducibles in $\mathbb Z[\sqrt - 5]$?,How many irreducibles in ?,\mathbb Z[\sqrt - 5],"Finding and counting irreducibles in non-UFD's seems harder to me than finding and counting primes in UFD's. The number of primes in the UFD $\mathbb Z[\sqrt -1]$ (the gaussian integers) is about $\pi(n)$ where $\pi$ is the usual prime counting function and $n$ is the norm. In other words, the number of gaussian primes with norm at most $n$ is almost equal to $\pi(n)$. To see this notice primes that are the Sum of 2 squares are $ 1 \mod 4$. Let the counting function of such primes be $\pi_2(n)$. It is Well known that $\pi_2(n) $ ~ $ \pi(n)/2$.  The number of gaussian primes is ( ignore unit multiples ) thus $2  \pi_2(n) $ ~ $\pi(n)$. A similar thing happens for Eisenstein integers. How many irreducibles are there in the integral domain $\mathbb Z[\sqrt - 5]$ ? Is it asymptotic to $$ T_5 \pi(n) $$ Where $n$ is again the norm and $T_5$ is rational ? Does a non-UFD imply more irreducibles than a UFD or less ... Or neither ? Are the number of irreducibles in $\mathbb Z[\sqrt - p]$ for $p$ a prime always asymptotic of the form $$ T_p \pi(n) $$ Where again $T_p$ is rational. Is $T_p$ the class number ??? If so why ??","Finding and counting irreducibles in non-UFD's seems harder to me than finding and counting primes in UFD's. The number of primes in the UFD $\mathbb Z[\sqrt -1]$ (the gaussian integers) is about $\pi(n)$ where $\pi$ is the usual prime counting function and $n$ is the norm. In other words, the number of gaussian primes with norm at most $n$ is almost equal to $\pi(n)$. To see this notice primes that are the Sum of 2 squares are $ 1 \mod 4$. Let the counting function of such primes be $\pi_2(n)$. It is Well known that $\pi_2(n) $ ~ $ \pi(n)/2$.  The number of gaussian primes is ( ignore unit multiples ) thus $2  \pi_2(n) $ ~ $\pi(n)$. A similar thing happens for Eisenstein integers. How many irreducibles are there in the integral domain $\mathbb Z[\sqrt - 5]$ ? Is it asymptotic to $$ T_5 \pi(n) $$ Where $n$ is again the norm and $T_5$ is rational ? Does a non-UFD imply more irreducibles than a UFD or less ... Or neither ? Are the number of irreducibles in $\mathbb Z[\sqrt - p]$ for $p$ a prime always asymptotic of the form $$ T_p \pi(n) $$ Where again $T_p$ is rational. Is $T_p$ the class number ??? If so why ??",,"['abstract-algebra', 'asymptotics', 'algebraic-number-theory', 'unique-factorization-domains']"
62,Nilpotent or non-Nilpotent Jacobson Radical,Nilpotent or non-Nilpotent Jacobson Radical,,"Let $R$ be a ring with identity element such that every ideal of which is idempotent or nilpotent. Is it true that the Jacobson radical $J(R)$ of $R$ is nilpotent? If $R$ is Noetherian and $J(R)$ is idempotent the Nakayama lemma yields $J(R)=0$. So, for Noetherian rings whose Jacobson radicals are nonzero we have an affirmative answer to the raised question. Thanks for any help or suggestion!","Let $R$ be a ring with identity element such that every ideal of which is idempotent or nilpotent. Is it true that the Jacobson radical $J(R)$ of $R$ is nilpotent? If $R$ is Noetherian and $J(R)$ is idempotent the Nakayama lemma yields $J(R)=0$. So, for Noetherian rings whose Jacobson radicals are nonzero we have an affirmative answer to the raised question. Thanks for any help or suggestion!",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'ideals', 'noncommutative-algebra']"
63,Minimal polynomial of $\alpha$ over $\mathbb{Q}$ and $\mathbb{Q}(\sqrt{2})$,Minimal polynomial of  over  and,\alpha \mathbb{Q} \mathbb{Q}(\sqrt{2}),"I have been working on these two minimal polynomial questions and am particularly concerned about (b) Find the minimal polynomial for $\sqrt[3]{4}+\sqrt[3]{2}$ (a) over $\mathbb{Q}$ By setting $\alpha=\sqrt[3]{4}+\sqrt[3]{2}$ , I found the minimal polynomial to be $\alpha^3-6\alpha-6=0$ ( edited ). This method involved just squaring out terms and was fairly lengthy - is this the standard procedure? (b) over $\mathbb{Q}(\sqrt{2})$ What does it mean to be the minimal polynomial over $\mathbb{Q}(\sqrt{2})$ ? Over $\mathbb{Q}$ , I see the minimal polynomial as the polynomial of lowest degree such that $\alpha$ is a root but I cannot see what is going on here. From (a) , we know that $[\mathbb{Q}(\alpha) : \mathbb{Q}]=3$ . So: $$[\mathbb{Q}(\alpha, \sqrt{2}) : \mathbb{Q}]=[\mathbb{Q}(\alpha, \sqrt{2}) : \mathbb{Q}(\alpha)][\mathbb{Q}(\alpha) : \mathbb{Q}]=3[\mathbb{Q}(\alpha, \sqrt{2}) : \mathbb{Q}(\alpha)]$$ So since the degree is a multiple of $3$ , the degree of the minimal polynomial of $\alpha$ over $\sqrt{2}$ is also a multiple of $3$ . Can we automatically conclude it is $3$ ? I do not believe so since we are considering a larger field ( $\mathbb{Q}(\sqrt{2}) \subset \mathbb{Q}$","I have been working on these two minimal polynomial questions and am particularly concerned about (b) Find the minimal polynomial for (a) over By setting , I found the minimal polynomial to be ( edited ). This method involved just squaring out terms and was fairly lengthy - is this the standard procedure? (b) over What does it mean to be the minimal polynomial over ? Over , I see the minimal polynomial as the polynomial of lowest degree such that is a root but I cannot see what is going on here. From (a) , we know that . So: So since the degree is a multiple of , the degree of the minimal polynomial of over is also a multiple of . Can we automatically conclude it is ? I do not believe so since we are considering a larger field (","\sqrt[3]{4}+\sqrt[3]{2} \mathbb{Q} \alpha=\sqrt[3]{4}+\sqrt[3]{2} \alpha^3-6\alpha-6=0 \mathbb{Q}(\sqrt{2}) \mathbb{Q}(\sqrt{2}) \mathbb{Q} \alpha [\mathbb{Q}(\alpha) : \mathbb{Q}]=3 [\mathbb{Q}(\alpha, \sqrt{2}) : \mathbb{Q}]=[\mathbb{Q}(\alpha, \sqrt{2}) : \mathbb{Q}(\alpha)][\mathbb{Q}(\alpha) : \mathbb{Q}]=3[\mathbb{Q}(\alpha, \sqrt{2}) : \mathbb{Q}(\alpha)] 3 \alpha \sqrt{2} 3 3 \mathbb{Q}(\sqrt{2}) \subset \mathbb{Q}","['abstract-algebra', 'galois-theory', 'extension-field', 'minimal-polynomials']"
64,How do I prove the uniqueness of additive identity?,How do I prove the uniqueness of additive identity?,,"First, suppose $i_1$ and $i_2$ are additive identity in ring R. From the definition of ""additive identity"" $a+i_1=a$ such that there is $a$ $\in$ $R$, including for $a=i_2$, so $i_2+i_1=i_2$. But $i_2$ is also an additive identity, so there $a \in R$ making $a+i_2=a$. Then $a=i_1$. Then $i_1+i_2=i_1$. Since this is a ring, addition is commutative, so $i_1+i_2=i_2+i_1$. Thus, $i_2+i_1=i_1$. Since $i_2+i_1=i_2$ and $i_2+i_1=i_1$, $i_2+i_1$ is the same element of $i_2$ and is the same as $i_1$, making $i_2=i_1$. Is this how you show it's unique? If not, can someone show me how to prove it's unique.","First, suppose $i_1$ and $i_2$ are additive identity in ring R. From the definition of ""additive identity"" $a+i_1=a$ such that there is $a$ $\in$ $R$, including for $a=i_2$, so $i_2+i_1=i_2$. But $i_2$ is also an additive identity, so there $a \in R$ making $a+i_2=a$. Then $a=i_1$. Then $i_1+i_2=i_1$. Since this is a ring, addition is commutative, so $i_1+i_2=i_2+i_1$. Thus, $i_2+i_1=i_1$. Since $i_2+i_1=i_2$ and $i_2+i_1=i_1$, $i_2+i_1$ is the same element of $i_2$ and is the same as $i_1$, making $i_2=i_1$. Is this how you show it's unique? If not, can someone show me how to prove it's unique.",,"['abstract-algebra', 'ring-theory']"
65,Maximal ideal containing functions with compact support,Maximal ideal containing functions with compact support,,"I recently proved the following statement: Let $M$ be a smooth manifold and let $I \subseteq C^\infty(M)$ be an ideal such that $C^\infty(M)/I \cong \mathbb{R}$ (such an ideal is clearly maximal, since $\mathbb{R}$ is a field). Then $I= \mathfrak{m}_p$ for some $p \in M$, where $\mathfrak{m}_p= \left\{f \in C^\infty(M): f(p)=0 \right\}$. This is fairly easy to prove for compact $M$. The case for non-compact $M$ requires a bit more work. Now, take $M=\mathbb{R}$ and $I$ the ideal of functions with compact support. $I \nsubseteq \mathfrak{m}_p$ for any $p \in \mathbb{R}$, but there must exist a maximal ideal $I' \subseteq C^\infty(\mathbb{R})$ containing $I$. Clearly $I' \neq \mathfrak{m}_p$, so if $C^\infty(\mathbb{R})/I' \cong \mathbb{F}$ for a field $\mathbb{F}$, which must be the case since $I'$ is maximal, $\mathbb{F} \neq \mathbb{R}$. I have two questions: Does anyone have an explicit example of such an $I'$? Also, does anyone know what $\mathbb{F}$ is or could be?","I recently proved the following statement: Let $M$ be a smooth manifold and let $I \subseteq C^\infty(M)$ be an ideal such that $C^\infty(M)/I \cong \mathbb{R}$ (such an ideal is clearly maximal, since $\mathbb{R}$ is a field). Then $I= \mathfrak{m}_p$ for some $p \in M$, where $\mathfrak{m}_p= \left\{f \in C^\infty(M): f(p)=0 \right\}$. This is fairly easy to prove for compact $M$. The case for non-compact $M$ requires a bit more work. Now, take $M=\mathbb{R}$ and $I$ the ideal of functions with compact support. $I \nsubseteq \mathfrak{m}_p$ for any $p \in \mathbb{R}$, but there must exist a maximal ideal $I' \subseteq C^\infty(\mathbb{R})$ containing $I$. Clearly $I' \neq \mathfrak{m}_p$, so if $C^\infty(\mathbb{R})/I' \cong \mathbb{F}$ for a field $\mathbb{F}$, which must be the case since $I'$ is maximal, $\mathbb{F} \neq \mathbb{R}$. I have two questions: Does anyone have an explicit example of such an $I'$? Also, does anyone know what $\mathbb{F}$ is or could be?",,"['abstract-algebra', 'differential-geometry', 'ideals']"
66,"For ideal $m$ maximal and principal, there's no ideal between $m^2$ and $m$. Prove that this can be false when $m$ is not principal or maximal.","For ideal  maximal and principal, there's no ideal between  and . Prove that this can be false when  is not principal or maximal.",m m^2 m m,"Prove that for ideal $m$ maximal and principal, there's no ideal $I$ such that  $m^2 \subsetneq I \subsetneq m$. Show that this can be false when $m$ is not principal or maximal. Suppose $\mathfrak m=(a)$, and $a\notin I$. Let's show that $I\subseteq\mathfrak m^2$. Pick $x\in I$. Then $x=ay$, $y\in R$. If $y\in\mathfrak m$, then $y=az$ and thus $x=a^2z\in\mathfrak m^2$. Otherwise, $\mathfrak m+(y)=R$, so $1=am+yn$. Then $a=a^2m+ayn$, so $a=a^2m+xn\in I$, a contradiction. This proves the first part but I don't know how to do the second.","Prove that for ideal $m$ maximal and principal, there's no ideal $I$ such that  $m^2 \subsetneq I \subsetneq m$. Show that this can be false when $m$ is not principal or maximal. Suppose $\mathfrak m=(a)$, and $a\notin I$. Let's show that $I\subseteq\mathfrak m^2$. Pick $x\in I$. Then $x=ay$, $y\in R$. If $y\in\mathfrak m$, then $y=az$ and thus $x=a^2z\in\mathfrak m^2$. Otherwise, $\mathfrak m+(y)=R$, so $1=am+yn$. Then $a=a^2m+ayn$, so $a=a^2m+xn\in I$, a contradiction. This proves the first part but I don't know how to do the second.",,"['abstract-algebra', 'ring-theory', 'ideals', 'maximal-and-prime-ideals']"
67,Is noetherianity really about cardinals or ordinals?,Is noetherianity really about cardinals or ordinals?,,"If $\kappa$ is any cardinal, then one may define a ""$\kappa$-Noetherian"" ring as a ring such that for any module that has a generating set $S$ satisfying $|S|< \kappa$, then any submodule also has such a generating set. Then a Noetherian ring is just a $\aleph_0$-Noetherian ring with this definition (and a principal ring is a $2$-Noetherian domain, but I think that probably only infinite cardinals are really meaningful in this setup). I you prefer non-commutative rings, you may add ""left"" and ""right"" wherever needed. Question 1a: Does such a notion exist somewhere ? Is it interesting, or even useful ? My main question is based on the following observation : if on the other hand you want to generalize the ascending chain condition, then you will naturally get a condition on ordinals , since it is formulated in terms of an order. Namely, you can ask wether there are chains of ideals having the order structure of a given ordinal : if $\alpha$ is an ordinal, a ring $R$ will be said to satisfy $\alpha$-$(AC)$ if there is no strictly increasing function $\alpha \to I(R)$ where $I(R)$ is the set of ideals, given the inclusion order. Then a Noetherian ring is just a ring satisfying $\omega$-$(AC)$. Again, you can add ""left"" or ""right"" if you want to. Question 1b: Same as question 1, for this other notion. So then there are two quite objectively natural notions that generalize Noetherian rings, but one is based on cardinals, and the other on ordinals. There is a sort of ""coincidence"" in the fact that $\omega$ and $\aleph_0$ are pretty much equivalent in the sense that finite ordinals and finite cardinals are really the same thing (same objects, same operations, etc.). But this will no longer be true for higher cardinals and ordinals. Question 2: Should one be considered the right one ? If so, which one and why ?","If $\kappa$ is any cardinal, then one may define a ""$\kappa$-Noetherian"" ring as a ring such that for any module that has a generating set $S$ satisfying $|S|< \kappa$, then any submodule also has such a generating set. Then a Noetherian ring is just a $\aleph_0$-Noetherian ring with this definition (and a principal ring is a $2$-Noetherian domain, but I think that probably only infinite cardinals are really meaningful in this setup). I you prefer non-commutative rings, you may add ""left"" and ""right"" wherever needed. Question 1a: Does such a notion exist somewhere ? Is it interesting, or even useful ? My main question is based on the following observation : if on the other hand you want to generalize the ascending chain condition, then you will naturally get a condition on ordinals , since it is formulated in terms of an order. Namely, you can ask wether there are chains of ideals having the order structure of a given ordinal : if $\alpha$ is an ordinal, a ring $R$ will be said to satisfy $\alpha$-$(AC)$ if there is no strictly increasing function $\alpha \to I(R)$ where $I(R)$ is the set of ideals, given the inclusion order. Then a Noetherian ring is just a ring satisfying $\omega$-$(AC)$. Again, you can add ""left"" or ""right"" if you want to. Question 1b: Same as question 1, for this other notion. So then there are two quite objectively natural notions that generalize Noetherian rings, but one is based on cardinals, and the other on ordinals. There is a sort of ""coincidence"" in the fact that $\omega$ and $\aleph_0$ are pretty much equivalent in the sense that finite ordinals and finite cardinals are really the same thing (same objects, same operations, etc.). But this will no longer be true for higher cardinals and ordinals. Question 2: Should one be considered the right one ? If so, which one and why ?",,"['abstract-algebra', 'ring-theory', 'commutative-algebra', 'cardinals', 'ordinals']"
68,"Modules over associative algebras are just special cases of ""ordinary"" modules over rings?","Modules over associative algebras are just special cases of ""ordinary"" modules over rings?",,"By module over a ring, I mean always a right-module. All rings are supposed to be unital, and the module fulfills $m\cdot 1 = m$. If $R$ is commutative and $M$ a right-module, we can define $rx := xr$ and get also a left-module. In this situation we call $M$ a bimodule, and if not otherwise said this natural definition is applied if I speak of bimodules. An algebra $A$ over a commutative ring $R$ is itself a ring with $1$, which is also a $R$-module, and such that for all $r \in R$ and $x,y \in A$ we have $$  (rx)y = r(xy) = x(ry). $$ As the ring is assumed to be commutative, we essentially have a bimodul over $R$ as written above. A module $M$ over an algebra $A$ which is defined over some ring $R$ is itself an $R$-module, for which we have an operation $M \times A \to M$ such that for each $u, v \in M$ and $x,y \in A$ and $r \in R$ we have (1) $(u+v)x = ux + vx$ (2) $v(x+y) = vx + vy$ (3) $(vx)y = v(xy)$ (4) $v1 = v$ (5) $(rv)x = r(vx) = v(rx)$. This is the standard definition I see everywhere. But I guess I observed the following. For an algebra we can embed $R$ into $A$ by identifying it with $R\cdot 1$ for $1 \in A$. So the assertion that $A$ must be an $R$-module is implied by (1), (2), (3) and (4). So we can just define a module over an algebra as an ordinary module over $A$ seen as a ring with $1$. As $A$ is in general not commutative, this is just a right-module. But by the embedding, and the additional requirement for an algebra, every element of $R$ is in the center $Z(A) = \{ x : xy = yx \mbox{ for all y} \in A \}$, restricted to $R$ everything is fine and we again have a bimodule. So the only thing that makes modules over algebras special here is (5). But here we have \begin{align*}  (rv)x & = (vr)x & \mbox{definition of $M$ as bimodul over $R$} \\        & = v(rx) & \mbox{by (3)} \\        & = v(xr) & \mbox{$R$ is central in $A$} \\        & = (vx)r & \mbox{by (3)} \\        & = r(vx) & \mbox{definition of $M$ as bimodul over $R$} \end{align*} so we see that in the third and last line we have recovered everything from (5). So as I see it, a module over an algebra is just an ordinary module over the algebra seen as a ring, so why bother with these extra definition? I guess if we generalise further, for example look at non-associative algebras, then they are no longer rings and we cannot define modules over them as special cases of modules over rings. But most of the time (and in the textbooks I am reading right now) such generalizations are not considered, but nevertheless most of the time modules over algebras are defined separately to modules over rings. So why that? Or have I overlooked something and my computations are wrong? Remark: These modules over algebras come from the representation theory of (finite) groups.","By module over a ring, I mean always a right-module. All rings are supposed to be unital, and the module fulfills $m\cdot 1 = m$. If $R$ is commutative and $M$ a right-module, we can define $rx := xr$ and get also a left-module. In this situation we call $M$ a bimodule, and if not otherwise said this natural definition is applied if I speak of bimodules. An algebra $A$ over a commutative ring $R$ is itself a ring with $1$, which is also a $R$-module, and such that for all $r \in R$ and $x,y \in A$ we have $$  (rx)y = r(xy) = x(ry). $$ As the ring is assumed to be commutative, we essentially have a bimodul over $R$ as written above. A module $M$ over an algebra $A$ which is defined over some ring $R$ is itself an $R$-module, for which we have an operation $M \times A \to M$ such that for each $u, v \in M$ and $x,y \in A$ and $r \in R$ we have (1) $(u+v)x = ux + vx$ (2) $v(x+y) = vx + vy$ (3) $(vx)y = v(xy)$ (4) $v1 = v$ (5) $(rv)x = r(vx) = v(rx)$. This is the standard definition I see everywhere. But I guess I observed the following. For an algebra we can embed $R$ into $A$ by identifying it with $R\cdot 1$ for $1 \in A$. So the assertion that $A$ must be an $R$-module is implied by (1), (2), (3) and (4). So we can just define a module over an algebra as an ordinary module over $A$ seen as a ring with $1$. As $A$ is in general not commutative, this is just a right-module. But by the embedding, and the additional requirement for an algebra, every element of $R$ is in the center $Z(A) = \{ x : xy = yx \mbox{ for all y} \in A \}$, restricted to $R$ everything is fine and we again have a bimodule. So the only thing that makes modules over algebras special here is (5). But here we have \begin{align*}  (rv)x & = (vr)x & \mbox{definition of $M$ as bimodul over $R$} \\        & = v(rx) & \mbox{by (3)} \\        & = v(xr) & \mbox{$R$ is central in $A$} \\        & = (vx)r & \mbox{by (3)} \\        & = r(vx) & \mbox{definition of $M$ as bimodul over $R$} \end{align*} so we see that in the third and last line we have recovered everything from (5). So as I see it, a module over an algebra is just an ordinary module over the algebra seen as a ring, so why bother with these extra definition? I guess if we generalise further, for example look at non-associative algebras, then they are no longer rings and we cannot define modules over them as special cases of modules over rings. But most of the time (and in the textbooks I am reading right now) such generalizations are not considered, but nevertheless most of the time modules over algebras are defined separately to modules over rings. So why that? Or have I overlooked something and my computations are wrong? Remark: These modules over algebras come from the representation theory of (finite) groups.",,"['abstract-algebra', 'group-theory', 'finite-groups', 'modules', 'representation-theory']"
69,Proper ideal $I \implies \exists $ prime ideals $P_i$ such that $P_1 \cdots P_n \subset I$.,Proper ideal  prime ideals  such that .,I \implies \exists  P_i P_1 \cdots P_n \subset I,"Let the below ideals be in a commutative Noetherian ring $R$. Corollary 22.  (3) There are prime ideals $P_1, \dots, P_n$ (not necc. distinct) $\supset I$ such that $P_1\cdots P_n \subset I$. (Out of D&F) Prove (3) of Corollary 22 directly by considering the coll. $\mathcal{S}$ of ideals that do not contain a finite product of prime ideals.  [If $I$ is a maximal element in $\mathcal{S}$, show that since $I$ is not prime there are ideals $J, K$ properly containing $I$ (hence not in $\mathcal{S}$) with $JK \subset I$.] I know: $I$ is not prime $\implies \exists$ ideals $J,K$ such that $JK \subset I$ yet $J \not\subset I$ and $K \not\subset I$. $I$ is not prime $\implies$ in particular not maximal $\implies$ $I$ properly contained in some maximal ideal $J$. From examining proof to Proposition 20 the proof of this would go something like if $\mathcal{S}$ were not empty, then since $R$ is Noetherian, all chains in $\mathcal{S}$ are upper bounded and so $\mathcal{S}$ contains a maximal element $I$. I can't piece it together from these facts alone, what am I missing?","Let the below ideals be in a commutative Noetherian ring $R$. Corollary 22.  (3) There are prime ideals $P_1, \dots, P_n$ (not necc. distinct) $\supset I$ such that $P_1\cdots P_n \subset I$. (Out of D&F) Prove (3) of Corollary 22 directly by considering the coll. $\mathcal{S}$ of ideals that do not contain a finite product of prime ideals.  [If $I$ is a maximal element in $\mathcal{S}$, show that since $I$ is not prime there are ideals $J, K$ properly containing $I$ (hence not in $\mathcal{S}$) with $JK \subset I$.] I know: $I$ is not prime $\implies \exists$ ideals $J,K$ such that $JK \subset I$ yet $J \not\subset I$ and $K \not\subset I$. $I$ is not prime $\implies$ in particular not maximal $\implies$ $I$ properly contained in some maximal ideal $J$. From examining proof to Proposition 20 the proof of this would go something like if $\mathcal{S}$ were not empty, then since $R$ is Noetherian, all chains in $\mathcal{S}$ are upper bounded and so $\mathcal{S}$ contains a maximal element $I$. I can't piece it together from these facts alone, what am I missing?",,"['abstract-algebra', 'commutative-algebra', 'ideals', 'noetherian', 'maximal-and-prime-ideals']"
70,dihedral group and its generators,dihedral group and its generators,,"I try to improve my understanding of the dihedral group. One way of presentation of the dihedral group $D_n$ of order $2n$ is $$\langle a,b : a^2=b^2=(ab)^n=1 \rangle.$$ After a moment of thought it seemed pretty 'obvious' to me that the set of all group elements could be written as $G= \lbrace (ab)^k, (ab)^ka:k=0,...,n-1  \rbrace$. It was easy to show that G is a group. Unfortunately I could not prove that the set $G$ indeed represents the full group $D_n$. Mor precisely I have trouble to show that all elements in the above set $G$ are pairwise different and that there are no other elements of $D_n$ not contained in G. E.g. why is it not possible that $(ab)^k=1$ for some $k=1,...,n-1$?","I try to improve my understanding of the dihedral group. One way of presentation of the dihedral group $D_n$ of order $2n$ is $$\langle a,b : a^2=b^2=(ab)^n=1 \rangle.$$ After a moment of thought it seemed pretty 'obvious' to me that the set of all group elements could be written as $G= \lbrace (ab)^k, (ab)^ka:k=0,...,n-1  \rbrace$. It was easy to show that G is a group. Unfortunately I could not prove that the set $G$ indeed represents the full group $D_n$. Mor precisely I have trouble to show that all elements in the above set $G$ are pairwise different and that there are no other elements of $D_n$ not contained in G. E.g. why is it not possible that $(ab)^k=1$ for some $k=1,...,n-1$?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'group-presentation', 'combinatorial-group-theory']"
71,Idea behind the definition of different ideal,Idea behind the definition of different ideal,,"Let $L/K$ be an extension of number fields. Let $I$ be a fractional ideal in $L$ and $$I^*:=\{x\in L \mid \text{Tr}_{L/K}(xI)\subset \mathcal{O}_K\}.$$ The different of $I$ is the following fractional ideal $$\mathcal{D}_{L/K}(I):=(I^*)^{-1}.$$ I understand the importance of the different ideal in the study of ramification. For example, we know that if $P$ is a prime in $\mathcal{O}_K$ and $P\mathcal{O}_L=Q^eI$, with $(Q, I)=1$, then $Q^{e-1}\mid \mathcal{D}_{L/K}(\mathcal{O}_L)$.  But I don't understand what is the idea behind its definition. What (historically) led to that definition?","Let $L/K$ be an extension of number fields. Let $I$ be a fractional ideal in $L$ and $$I^*:=\{x\in L \mid \text{Tr}_{L/K}(xI)\subset \mathcal{O}_K\}.$$ The different of $I$ is the following fractional ideal $$\mathcal{D}_{L/K}(I):=(I^*)^{-1}.$$ I understand the importance of the different ideal in the study of ramification. For example, we know that if $P$ is a prime in $\mathcal{O}_K$ and $P\mathcal{O}_L=Q^eI$, with $(Q, I)=1$, then $Q^{e-1}\mid \mathcal{D}_{L/K}(\mathcal{O}_L)$.  But I don't understand what is the idea behind its definition. What (historically) led to that definition?",,"['abstract-algebra', 'algebraic-number-theory', 'ideals', 'ramification', 'integer-rings']"
72,Artin's Algebra exercise special case of some theorem/problem?,Artin's Algebra exercise special case of some theorem/problem?,,"The following exercise is from Artin's Algebra Text: Show that there is a one to one correspondence between maximal ideals of $ \bf R$$[x]$ and complex upper half plane. Solution: Follows from the fact that $ \bf R$$[x]$ is a PID,and any irreducible polynomial of  $ \bf R$$[x]$ is either of degree $1$ or of degree $2$. Is the above problem a special case of some theorem/Problem? In the case of algebraically closed field $k$ It's well known that maximal ideals of polynomial ring in $n$ variable over $k$ corresponds to points of affine space $ \bf A_k^n$.","The following exercise is from Artin's Algebra Text: Show that there is a one to one correspondence between maximal ideals of $ \bf R$$[x]$ and complex upper half plane. Solution: Follows from the fact that $ \bf R$$[x]$ is a PID,and any irreducible polynomial of  $ \bf R$$[x]$ is either of degree $1$ or of degree $2$. Is the above problem a special case of some theorem/Problem? In the case of algebraically closed field $k$ It's well known that maximal ideals of polynomial ring in $n$ variable over $k$ corresponds to points of affine space $ \bf A_k^n$.",,"['abstract-algebra', 'ring-theory', 'ideals', 'irreducible-polynomials', 'maximal-and-prime-ideals']"
73,Example of two subvarieties of $\mathbb{P}^2$ that are isomorphic but not projectively equivalent.,Example of two subvarieties of  that are isomorphic but not projectively equivalent.,\mathbb{P}^2,"Two curves $C_1$, $C_2 \subset \mathbb{P}^2$ are called projectively equivalent if there is a projective change of coordinates $\phi: \mathbb{P}^2 \to \mathbb{P}^2$ so that $\phi(C_1) = C_2$. What is an example of $C_1$, $C_2 \subset \mathbb{P}^2$ so that $C_1$ is isomorphic to $C_2$ as a projective variety, but $C_1$ and $C_2$ are not projectively equivalent?","Two curves $C_1$, $C_2 \subset \mathbb{P}^2$ are called projectively equivalent if there is a projective change of coordinates $\phi: \mathbb{P}^2 \to \mathbb{P}^2$ so that $\phi(C_1) = C_2$. What is an example of $C_1$, $C_2 \subset \mathbb{P}^2$ so that $C_1$ is isomorphic to $C_2$ as a projective variety, but $C_1$ and $C_2$ are not projectively equivalent?",,"['abstract-algebra', 'geometry']"
74,Finding the commutator subgroup of $S_3$ and the commutator subgroup of that commutator subgroup.,Finding the commutator subgroup of  and the commutator subgroup of that commutator subgroup.,S_3,"I'm finding this idea very frustrating. I need to find the commutator subgroup of $S_3$ (call it $S_3'$) and the commutator subgroup of that commutator subgroup (call it $S_3 ''$). So, I have that, for $S_3$, the commutator of $a,b \in S_3$ is given by $$ [a,b] :=aba^{-1}b^{-1}. $$ And the commutator subgroup is the subgroup generated by all such $[a,b]$, i.e., $$ S_3 ' = <[a,b]:a,b, \in S_3> .$$ Ok, I have read about everything I can on this and watched every single YouTube video on the subject I can find, and have yet to see it just worked out explicitly in a way that makes sense to me. For example: these elements $a,b$. Do they need to be distinct from one another?! Is this an ordered pair, or not?! I know that I only need to check the normal subgroups, of which there are only three, but that's still a lot of things to check if they do not need to be distinct and need to be ordered. I just feel like there are a lot of basic questions here that I'm not seeing addressed anywhere in the literature, which makes me feel like I'm ""missing the point,"" in a way. EDIT: for $S_3 ' = \{e, (123), (132) \}$ here are all of my computations in an attempt to determine $S_3 ''$: $$ [e, (123)] = e \\    [e, (132)] = e \\ [(123, (132)] = e \\ [(132), (123)] = e \\ [(123), e] = e \\ [(132), e] = e \\    $$ Ok. So, certainly the subgroup generated by $e$ is simply $e$, which means we get to conclude that $S_ 3 '$ is abelian? Is that it?","I'm finding this idea very frustrating. I need to find the commutator subgroup of $S_3$ (call it $S_3'$) and the commutator subgroup of that commutator subgroup (call it $S_3 ''$). So, I have that, for $S_3$, the commutator of $a,b \in S_3$ is given by $$ [a,b] :=aba^{-1}b^{-1}. $$ And the commutator subgroup is the subgroup generated by all such $[a,b]$, i.e., $$ S_3 ' = <[a,b]:a,b, \in S_3> .$$ Ok, I have read about everything I can on this and watched every single YouTube video on the subject I can find, and have yet to see it just worked out explicitly in a way that makes sense to me. For example: these elements $a,b$. Do they need to be distinct from one another?! Is this an ordered pair, or not?! I know that I only need to check the normal subgroups, of which there are only three, but that's still a lot of things to check if they do not need to be distinct and need to be ordered. I just feel like there are a lot of basic questions here that I'm not seeing addressed anywhere in the literature, which makes me feel like I'm ""missing the point,"" in a way. EDIT: for $S_3 ' = \{e, (123), (132) \}$ here are all of my computations in an attempt to determine $S_3 ''$: $$ [e, (123)] = e \\    [e, (132)] = e \\ [(123, (132)] = e \\ [(132), (123)] = e \\ [(123), e] = e \\ [(132), e] = e \\    $$ Ok. So, certainly the subgroup generated by $e$ is simply $e$, which means we get to conclude that $S_ 3 '$ is abelian? Is that it?",,"['abstract-algebra', 'group-theory']"
75,Prove $[L:\mathbb{F_p}]=n$,Prove,[L:\mathbb{F_p}]=n,"Let $f(x) \in \mathbb{F_p}[x] $ be an irreducible polynomial of degree $n$. Let $L$ be the splitting field of $f$. Prove $[L:\mathbb{F_p}]=n$. If $a_1,...,a_n$ are the roots of $f(x)$, then $L=\mathbb{F_p}(a_1,...,a_n)$. It is obvious that $[L:\mathbb{F_p}] \le [\mathbb{F_p}(a_1,...,a_n):\mathbb{F_p}(a_1,...,a_{n-1})]...[\mathbb{F_p}(a_1):\mathbb{F_p}] \le n^n$. Hence $L/\mathbb{F_p}$ is a finite extension of a finite field - thus separable, and simple,So $L=\mathbb{F_p}(\alpha)$, and $L$ is a finite field. We can also see that it is the splitting field of $x^{p^m}-x$ ($m$ is such that $|L|=p^m$), so this is a Galois Extension and $[L:\mathbb{F_p}]=|Gal(L/\mathbb{F_p})$|. So if I could find the size of the galois group... I would be done... I don't know how to find it though :) Please help","Let $f(x) \in \mathbb{F_p}[x] $ be an irreducible polynomial of degree $n$. Let $L$ be the splitting field of $f$. Prove $[L:\mathbb{F_p}]=n$. If $a_1,...,a_n$ are the roots of $f(x)$, then $L=\mathbb{F_p}(a_1,...,a_n)$. It is obvious that $[L:\mathbb{F_p}] \le [\mathbb{F_p}(a_1,...,a_n):\mathbb{F_p}(a_1,...,a_{n-1})]...[\mathbb{F_p}(a_1):\mathbb{F_p}] \le n^n$. Hence $L/\mathbb{F_p}$ is a finite extension of a finite field - thus separable, and simple,So $L=\mathbb{F_p}(\alpha)$, and $L$ is a finite field. We can also see that it is the splitting field of $x^{p^m}-x$ ($m$ is such that $|L|=p^m$), so this is a Galois Extension and $[L:\mathbb{F_p}]=|Gal(L/\mathbb{F_p})$|. So if I could find the size of the galois group... I would be done... I don't know how to find it though :) Please help",,"['abstract-algebra', 'field-theory', 'galois-theory', 'finite-fields', 'extension-field']"
76,Artin's Algebra Exercise: Characterize all rings $R$ which contains $\mathbb C$ and has dimension $2$ as a vector space over $\mathbb C$.,Artin's Algebra Exercise: Characterize all rings  which contains  and has dimension  as a vector space over .,R \mathbb C 2 \mathbb C,"Here is a problem from Artin's Algebra text: Characterize all rings $R$ which contains $\mathbb C$ and has dimension $2$ as a vector space over $\mathbb C$. Here is my idea : Suppose $\{1, \alpha\}$ is a basis of $R$ as a $\mathbb C$-vectorspace, then as $\alpha^2 \in R$ so there exist $a,b \in \mathbb C$ such that $\alpha^2=a\alpha + b$. Now the whole multiplication is defined, since $(s\alpha + t)(u\alpha+v) = su\alpha^2 + (sv+tu)\alpha + tv = (sua + sv + tu)\alpha + (sub + tv)$, for generic elements $s\alpha + t, u\alpha+v \in R$. Such a ring is clearly commutative. Is this solution correct ? Moreover, What can be said more about ring $R$ ?   How can we find all rings which contains $\mathbb C$ has dimensions $n$ as a vector space Over $\mathbb C$ ? Any ideas?","Here is a problem from Artin's Algebra text: Characterize all rings $R$ which contains $\mathbb C$ and has dimension $2$ as a vector space over $\mathbb C$. Here is my idea : Suppose $\{1, \alpha\}$ is a basis of $R$ as a $\mathbb C$-vectorspace, then as $\alpha^2 \in R$ so there exist $a,b \in \mathbb C$ such that $\alpha^2=a\alpha + b$. Now the whole multiplication is defined, since $(s\alpha + t)(u\alpha+v) = su\alpha^2 + (sv+tu)\alpha + tv = (sua + sv + tu)\alpha + (sub + tv)$, for generic elements $s\alpha + t, u\alpha+v \in R$. Such a ring is clearly commutative. Is this solution correct ? Moreover, What can be said more about ring $R$ ?   How can we find all rings which contains $\mathbb C$ has dimensions $n$ as a vector space Over $\mathbb C$ ? Any ideas?",,"['abstract-algebra', 'ring-theory', 'vector-spaces']"
77,"Suppose that elements $a, b$ and $a+b$ are units in a commutative ring $R$. Show that $a^{-1} + b^{-1}$ is also a unit.",Suppose that elements  and  are units in a commutative ring . Show that  is also a unit.,"a, b a+b R a^{-1} + b^{-1}","Suppose that elements $a, b$ and $a+b$ are units in a commutative ring $R$. Show that $a^{-1} + b^{-1}$ is also a unit. Here is what I have: $a+b =b+a$ since $R$ is commutative. Now, $$(b+a) \cdot b^{-1} = 1+ab^{-1} \\ a^{-1} \cdot (1+ab^{-1}) = a^{-1} + b^{-1} $$ Thus, $a^{-1} + b^{-1} =a^{-1} \cdot (a+b) \cdot b^{-1}$ Therefore, $(a^{-1} + b^{-1})^{-1} = b \cdot (a+b)^{-1} \cdot a$ And thus, $a^{-1} + b^{-1}$ is a unit in $R$ as well. Does my answer sound logical. Or are there errors in it?","Suppose that elements $a, b$ and $a+b$ are units in a commutative ring $R$. Show that $a^{-1} + b^{-1}$ is also a unit. Here is what I have: $a+b =b+a$ since $R$ is commutative. Now, $$(b+a) \cdot b^{-1} = 1+ab^{-1} \\ a^{-1} \cdot (1+ab^{-1}) = a^{-1} + b^{-1} $$ Thus, $a^{-1} + b^{-1} =a^{-1} \cdot (a+b) \cdot b^{-1}$ Therefore, $(a^{-1} + b^{-1})^{-1} = b \cdot (a+b)^{-1} \cdot a$ And thus, $a^{-1} + b^{-1}$ is a unit in $R$ as well. Does my answer sound logical. Or are there errors in it?",,['abstract-algebra']
78,A finite von Neumann regular ring is unital and has $ab = 1$ if $ba = 1$,A finite von Neumann regular ring is unital and has  if,ab = 1 ba = 1,"Let $R$ be a finite ring such that for any $x \in R$ there exists $y \in R$ with $xyx = x$ . Show that $R$ is unital and that if $ab = 1$ , then $ba = 1$ . Thoughts so far: If I can show that the Jacobson radical is trivial, then I see how to get the result (since then it would be semi-simple, therefore equal to a direct product of matrix rings over division rings, hence equal to a direct product of matrix rings over fields (since the division rings would be finite), and this satisfies the property. So I'm wondering about how to prove that $J(R)$ is trivial. Any hints?","Let be a finite ring such that for any there exists with . Show that is unital and that if , then . Thoughts so far: If I can show that the Jacobson radical is trivial, then I see how to get the result (since then it would be semi-simple, therefore equal to a direct product of matrix rings over division rings, hence equal to a direct product of matrix rings over fields (since the division rings would be finite), and this satisfies the property. So I'm wondering about how to prove that is trivial. Any hints?",R x \in R y \in R xyx = x R ab = 1 ba = 1 J(R),"['abstract-algebra', 'ring-theory', 'finite-rings']"
79,Factor rings $R/R$ and $R/0$,Factor rings  and,R/R R/0,"Let $R$ be a ring. I want to describe the factor rings $R/R$ and $R/0$. So $R/R = \{[r]| r+R, \forall r\in R \}$ and since $r+R=R$, we get $R/ R =\{[0]\}$. And for $R/0 = \{[r]| r+0,\forall r\in R\}$ we get something isomorphic to $R$ right? Like a coset form of $R$ so $R/0 \cong R$. Is that right?","Let $R$ be a ring. I want to describe the factor rings $R/R$ and $R/0$. So $R/R = \{[r]| r+R, \forall r\in R \}$ and since $r+R=R$, we get $R/ R =\{[0]\}$. And for $R/0 = \{[r]| r+0,\forall r\in R\}$ we get something isomorphic to $R$ right? Like a coset form of $R$ so $R/0 \cong R$. Is that right?",,"['abstract-algebra', 'ring-theory']"
80,"In a ring: If every non-zero and non-unit element factors into prime elements, is factorization over irreducible elements unique?","In a ring: If every non-zero and non-unit element factors into prime elements, is factorization over irreducible elements unique?",,Why (not)? I came up with this question while trying to understand the definition of a UFD.,Why (not)? I came up with this question while trying to understand the definition of a UFD.,,"['abstract-algebra', 'ring-theory', 'unique-factorization-domains']"
81,"General notions of ""basis"" in algebra/model theory","General notions of ""basis"" in algebra/model theory",,"Free groups, free abelian groups, and vector spaces all have a notion of 'basis': a subset $B$ of the structure such that everything in the structure can be written uniquely as a finite combination of elements of $B$. What is the most general (model theoretic) structure for which it makes sense to think about a basis? Do all of these structures have theorems along the lines of ""if $S$ is a structure with a basis and $T$ is a substructure, then $T$ must also have a basis""? This certainly is true for free (abelian) groups and vector spaces.","Free groups, free abelian groups, and vector spaces all have a notion of 'basis': a subset $B$ of the structure such that everything in the structure can be written uniquely as a finite combination of elements of $B$. What is the most general (model theoretic) structure for which it makes sense to think about a basis? Do all of these structures have theorems along the lines of ""if $S$ is a structure with a basis and $T$ is a substructure, then $T$ must also have a basis""? This certainly is true for free (abelian) groups and vector spaces.",,"['abstract-algebra', 'model-theory']"
82,Proving that disjoint unions of presentations are coproducts of groups,Proving that disjoint unions of presentations are coproducts of groups,,"I'm working through Aluffi's Algrebra: Chapter 0 and I need some assistance with an excercise. Aluffi, Ex. II.8.7 Let $(A|R)$, resp. $(A'|R')$, be a presentation for a group $G$ in Grp , resp. $G'$; we may assume that $A, A'$ are disjoint. Prove that the group $G \ast G'$ presented by   \begin{equation} (A \cup A'|R \cup R') \end{equation}   satisfies the universal property for the coproduct of $G$ and $G'$ in Grp . (Use the universal properties of both free groups and quotients to construct natural homomorphisms $G \to G \ast G', G' \to G \ast G'.$) What I have done so far: First off, we have natural set-functions $A,A' \to F(A \cup A')$. Hence we have unique homomorphisms $F(A),F(A') \to F(A \cup A')$ whose restrictions to $A,A'$ are equal to the functions $A,A' \to F(A \cup A')$, by the universal property of free groups. By combining these homomorphisms with the natural projection $F(A \cup A') \to F(A \cup A')/(R \cup R')$, we get homomorphisms $F(A),F(A') \to F(A \cup A')/(R \cup R')$. Since $a(R) = b(R) \Rightarrow a(R \cup R') = b(R \cup R')$, we get a natural homomorphism $\pi_1:G \cong F(A)/(R) \to F(A \cup A')/(R \cup R')$, by the universal property of quotients. Similarly, we get a natural homomorphism $\pi_2:G' \cong F(A')/(R') \to F(A \cup A')/(R \cup R') = G \ast G'$. If I'm not mistaken, these homomorphisms simply map $a(R) \mapsto a(R \cup R')$, for all $a(R) \in G$, and similarly for elements of $G'$. If we have a group $H$ and homomorphisms $f:G \to H, g:G' \to H$, then the only function $\varphi:G \ast G' \to H$ s.t. $\varphi \circ \pi_1 = f, \varphi \circ \pi_2 = g$, must map $a(R \cup R') \mapsto f(a(R))$ for all $a \in F(A)$, and similarly for all $b \in F(A'), b(R \cup R') \mapsto g(b(R'))$. All that is left, is to show that this defines a function $\psi$. So, we need to show that $ab^{-1} \in (R \cup R') \Rightarrow \psi (ab^{-1}(R \cup R')) = e_H$, for any $a,b \in F(A \cup A')$. This is what I can't do. How do I go about showing this, or am I going in a wrong direction? Edit: Note that (R) stands for the normal closure of R in F(A). One answer: Note that $(R \cup R') := \langle \{ghg^{-1} \mid g \in F(A \cup A'), h \in R \cup R'\} \rangle$. Now, for any $h \in R \cup R', g \in F(A \cup A')$, we have  \begin{align} \psi (ghg^{-1}(R \cup R'))  & = \psi (g(R \cup R')) \psi (h(R \cup R')) \psi (g^{-1}(R \cup R')) \\ & =  \psi (g(R \cup R')) \psi (g^{-1}(R \cup R')) \\ & =  \psi (gg^{-1}(R \cup R')) \\ & = e_H. \end{align} Hence, for any $a \in (R \cup R')$, we have $\psi (a) = e_H$, which completes the proof.","I'm working through Aluffi's Algrebra: Chapter 0 and I need some assistance with an excercise. Aluffi, Ex. II.8.7 Let $(A|R)$, resp. $(A'|R')$, be a presentation for a group $G$ in Grp , resp. $G'$; we may assume that $A, A'$ are disjoint. Prove that the group $G \ast G'$ presented by   \begin{equation} (A \cup A'|R \cup R') \end{equation}   satisfies the universal property for the coproduct of $G$ and $G'$ in Grp . (Use the universal properties of both free groups and quotients to construct natural homomorphisms $G \to G \ast G', G' \to G \ast G'.$) What I have done so far: First off, we have natural set-functions $A,A' \to F(A \cup A')$. Hence we have unique homomorphisms $F(A),F(A') \to F(A \cup A')$ whose restrictions to $A,A'$ are equal to the functions $A,A' \to F(A \cup A')$, by the universal property of free groups. By combining these homomorphisms with the natural projection $F(A \cup A') \to F(A \cup A')/(R \cup R')$, we get homomorphisms $F(A),F(A') \to F(A \cup A')/(R \cup R')$. Since $a(R) = b(R) \Rightarrow a(R \cup R') = b(R \cup R')$, we get a natural homomorphism $\pi_1:G \cong F(A)/(R) \to F(A \cup A')/(R \cup R')$, by the universal property of quotients. Similarly, we get a natural homomorphism $\pi_2:G' \cong F(A')/(R') \to F(A \cup A')/(R \cup R') = G \ast G'$. If I'm not mistaken, these homomorphisms simply map $a(R) \mapsto a(R \cup R')$, for all $a(R) \in G$, and similarly for elements of $G'$. If we have a group $H$ and homomorphisms $f:G \to H, g:G' \to H$, then the only function $\varphi:G \ast G' \to H$ s.t. $\varphi \circ \pi_1 = f, \varphi \circ \pi_2 = g$, must map $a(R \cup R') \mapsto f(a(R))$ for all $a \in F(A)$, and similarly for all $b \in F(A'), b(R \cup R') \mapsto g(b(R'))$. All that is left, is to show that this defines a function $\psi$. So, we need to show that $ab^{-1} \in (R \cup R') \Rightarrow \psi (ab^{-1}(R \cup R')) = e_H$, for any $a,b \in F(A \cup A')$. This is what I can't do. How do I go about showing this, or am I going in a wrong direction? Edit: Note that (R) stands for the normal closure of R in F(A). One answer: Note that $(R \cup R') := \langle \{ghg^{-1} \mid g \in F(A \cup A'), h \in R \cup R'\} \rangle$. Now, for any $h \in R \cup R', g \in F(A \cup A')$, we have  \begin{align} \psi (ghg^{-1}(R \cup R'))  & = \psi (g(R \cup R')) \psi (h(R \cup R')) \psi (g^{-1}(R \cup R')) \\ & =  \psi (g(R \cup R')) \psi (g^{-1}(R \cup R')) \\ & =  \psi (gg^{-1}(R \cup R')) \\ & = e_H. \end{align} Hence, for any $a \in (R \cup R')$, we have $\psi (a) = e_H$, which completes the proof.",,"['abstract-algebra', 'group-theory', 'category-theory']"
83,tensor product of Hopf algebras and coalgebraic structure on the dual algebra,tensor product of Hopf algebras and coalgebraic structure on the dual algebra,,"I am learning Hopf algebras, and there are two questions as follows: Is the tensor product of two Hopf algebras still a Hopf algebra? Let $A$ be an infinite dimensional algebra. Is the dual $A^*$ a coalgebra? (In the case of the dimension of $A$ is finite the answer is positive.) If they are, where can I find the proofs? Thanks for your help.","I am learning Hopf algebras, and there are two questions as follows: Is the tensor product of two Hopf algebras still a Hopf algebra? Let be an infinite dimensional algebra. Is the dual a coalgebra? (In the case of the dimension of is finite the answer is positive.) If they are, where can I find the proofs? Thanks for your help.",A A^* A,"['abstract-algebra', 'reference-request', 'hopf-algebras', 'coalgebras']"
84,Group ring of a cyclic group over a finite field,Group ring of a cyclic group over a finite field,,Suppose $ p $ a prime integer and $ n $ a positive integer. Does anyone know off the top of their heads if the group ring $ \mathbb{F}_{p}[\mathbb{Z}/n] $ (perhaps regarding $ \mathbb{Z}/n $ as the $ n^{\mathrm{th}} $ roots of unity is helpful) is isomorphic to $ \mathbb{F}_{p^n} $ in general?,Suppose $ p $ a prime integer and $ n $ a positive integer. Does anyone know off the top of their heads if the group ring $ \mathbb{F}_{p}[\mathbb{Z}/n] $ (perhaps regarding $ \mathbb{Z}/n $ as the $ n^{\mathrm{th}} $ roots of unity is helpful) is isomorphic to $ \mathbb{F}_{p^n} $ in general?,,"['abstract-algebra', 'finite-fields']"
85,Degree of a splitting field over $ \mathbb{Q}$,Degree of a splitting field over, \mathbb{Q},"I'm trying to solve the following problem:  Let \begin{equation*} f(x) = x^4 - 2x^2 - 2 \in \mathbb{Q}[x]  \end{equation*} and $ E $ be its splitting field. What is the degree $ [E: \mathbb{Q}] $? First of all, the roots of this polynomial are $ \pm \sqrt{1 + \sqrt{3}}, \pm \sqrt{1 - \sqrt{3}} $. The first two are real and the other two are complex. It looks as if $ E $ was equal to $ \mathbb{Q}(\sqrt{1 + \sqrt{3}}, \sqrt{1 - \sqrt{3}}) $. The degree of these elements over $ \mathbb{Q} $ is $ 4 $ since $ f(x) $ is irreducible by Eistenstein's criterion. However, I can't tell what the degree of $ \sqrt{1 - \sqrt{3}} $ over $ \mathbb{Q}(\sqrt{1 + \sqrt{3}}) $ is, since I don't know how to check whether $ f $ is irreducible over this field. I'd appreciate any ideas on how to get to that","I'm trying to solve the following problem:  Let \begin{equation*} f(x) = x^4 - 2x^2 - 2 \in \mathbb{Q}[x]  \end{equation*} and $ E $ be its splitting field. What is the degree $ [E: \mathbb{Q}] $? First of all, the roots of this polynomial are $ \pm \sqrt{1 + \sqrt{3}}, \pm \sqrt{1 - \sqrt{3}} $. The first two are real and the other two are complex. It looks as if $ E $ was equal to $ \mathbb{Q}(\sqrt{1 + \sqrt{3}}, \sqrt{1 - \sqrt{3}}) $. The degree of these elements over $ \mathbb{Q} $ is $ 4 $ since $ f(x) $ is irreducible by Eistenstein's criterion. However, I can't tell what the degree of $ \sqrt{1 - \sqrt{3}} $ over $ \mathbb{Q}(\sqrt{1 + \sqrt{3}}) $ is, since I don't know how to check whether $ f $ is irreducible over this field. I'd appreciate any ideas on how to get to that",,"['abstract-algebra', 'field-theory']"
86,Subgroups of free products of cyclic groups,Subgroups of free products of cyclic groups,,"Consider the free product $\mathbb{Z}_{3} \star \mathbb{Z}_{3}$. How would one determine the number of subgroups of this product up to isomorphism? It is routine for the case of the product $\mathbb{Z}_{2} \star \mathbb{Z}_{2}$ either by considering the combinations of elements from each group separately or the number of covering spaces of the wedge product of projective spaces. I feel that the easiest way would be to consider the subgroups from the group directly without resorting to topology, but how would one do this?","Consider the free product $\mathbb{Z}_{3} \star \mathbb{Z}_{3}$. How would one determine the number of subgroups of this product up to isomorphism? It is routine for the case of the product $\mathbb{Z}_{2} \star \mathbb{Z}_{2}$ either by considering the combinations of elements from each group separately or the number of covering spaces of the wedge product of projective spaces. I feel that the easiest way would be to consider the subgroups from the group directly without resorting to topology, but how would one do this?",,"['abstract-algebra', 'group-theory', 'algebraic-topology', 'finite-groups']"
87,Isotypic components are just simple two-sided ideals,Isotypic components are just simple two-sided ideals,,"I'm trying to show that when we decompose a semisimple ring $R$ into isotypic components $$ R \overset{_R\mathsf{Mod}}{\cong}\bigoplus_{j=1}^{k_1}{I^{(1)}_j} \bigoplus \dotsb \bigoplus \left( \bigoplus_{j=1}^{k_n}I_j^{(n)} \right) \\ = R^{(1)} \oplus \dotsb \oplus R^{(n)} $$ we have actually decomposed it into the simple two-sided ideals. (I.e. the simple two-sided ideals of $R$ are precisely the sums of all simple left ideals of the same isomorphism type.) I understand why the isotypic components are two-sided ideals. To show that any two-sided ideal is of this form, I was looking on this page, and their explanation is ...characteristic left ideals are precisely two-sided ideals. Thus   two-sided ideals are sums of isotypic components. I don't understand what this means, nor do I know what a ""characteristic ideal"" is (is it an ideal $I$ such that any $R$ left-linear automorphism acts trivially on $I$?). Can someone help, or just point me to another proof of what I'm trying to prove?","I'm trying to show that when we decompose a semisimple ring $R$ into isotypic components $$ R \overset{_R\mathsf{Mod}}{\cong}\bigoplus_{j=1}^{k_1}{I^{(1)}_j} \bigoplus \dotsb \bigoplus \left( \bigoplus_{j=1}^{k_n}I_j^{(n)} \right) \\ = R^{(1)} \oplus \dotsb \oplus R^{(n)} $$ we have actually decomposed it into the simple two-sided ideals. (I.e. the simple two-sided ideals of $R$ are precisely the sums of all simple left ideals of the same isomorphism type.) I understand why the isotypic components are two-sided ideals. To show that any two-sided ideal is of this form, I was looking on this page, and their explanation is ...characteristic left ideals are precisely two-sided ideals. Thus   two-sided ideals are sums of isotypic components. I don't understand what this means, nor do I know what a ""characteristic ideal"" is (is it an ideal $I$ such that any $R$ left-linear automorphism acts trivially on $I$?). Can someone help, or just point me to another proof of what I'm trying to prove?",,"['abstract-algebra', 'ring-theory', 'ideals']"
88,"If there is a bijection $f: X\rightarrow Y$, prove that there exists an isomorphism $\phi :S_X\rightarrow S_Y$","If there is a bijection , prove that there exists an isomorphism",f: X\rightarrow Y \phi :S_X\rightarrow S_Y,"If there is a bijection $f: X\rightarrow Y$, prove that there exists an isomorphism $\phi :S_X\rightarrow S_Y$. Here $S_X$ denotes the group of all permutations of $X$, i.e., the bijections $X\to X$ and the group operation is composition. I know that $X$ and $Y$ have the same cardinality because of the bijection. I define $\phi:S_X \rightarrow S_Y$ by $\phi : a \rightarrow f\circ a\circ f^{-1}$ Then I suppose $\phi^{-1}$ can be defined as $b\rightarrow f^{-1} \circ b\circ f$. I think this is close but I haven't showed that $\phi$ is a homomorphism. But once I do I can show isomorphism.","If there is a bijection $f: X\rightarrow Y$, prove that there exists an isomorphism $\phi :S_X\rightarrow S_Y$. Here $S_X$ denotes the group of all permutations of $X$, i.e., the bijections $X\to X$ and the group operation is composition. I know that $X$ and $Y$ have the same cardinality because of the bijection. I define $\phi:S_X \rightarrow S_Y$ by $\phi : a \rightarrow f\circ a\circ f^{-1}$ Then I suppose $\phi^{-1}$ can be defined as $b\rightarrow f^{-1} \circ b\circ f$. I think this is close but I haven't showed that $\phi$ is a homomorphism. But once I do I can show isomorphism.",,"['abstract-algebra', 'group-theory', 'permutations', 'group-isomorphism']"
89,The normaliser of the left regular image [D&F],The normaliser of the left regular image [D&F],,"I want to solve the following problem from Dummit & Foote's Abstract Algebra text (p. 186): Let $H$ be a group of order $n$, let $K=\text{Aut}(H)$ and form $G=\text{Hol}(H)=H \rtimes K$ (where $\varphi$ is the identity homomorphism). Let $G$ act by left multiplication on the left cosets of $K$ in $G$ and let $\pi$ be the associated permutation representation $\pi:G \to S_n$. (a) prove that the elements of $H$ are coset representatives for the left cosets of $K$ in $G$ and with this choice of coset representatives $\pi$ restricted to $H$ is the left regular representation of $H$. (b) Prove $\pi(G)$ is the normalizer in $S_n$ of $\pi(H)$. Deduce that under the regular representation of any finite group $H$ of order $n$, the normalizer in $S_n$ of the image of $H$ is isomorphic to $\text{Hol}(H)$. [Show $|G|=|N_{S_n}(\pi(H))|$ using Exercises 1 and 2 above.] (c) Deduce that the normalizer of the group generated by an $n$-cycle in $S_n$ is isomorphic to $\text{Hol}(Z_n)$ and has order $n \varphi(n)$. My attempt: (a) We know that there are $|G|/|K|=|H|=n$ left cosets of $K$ in $G$. If $h_1K=h_2K$ are the same coset, where $h_1,h_2 \in H$ then $h_1^{-1}h_2 \in K$. Since $h_1^{-1}h_2 \in H$ as well we find $h_1^{-1}h_2=1$ or $h_1=h_2$. Thus the $n$ distinct elements of $H$ give rise to $n$ distinct left cosets of $K$ in $G$, which are all such cosets. Moreover, $\pi \big|_H(h)(h'K)=hh'K$, so that working with the representatives from $H$, $\pi \big|_H$ coincides with the left regular representation of $H$. (b) I could prove one inclusion: Let $\pi(g) \in \pi(G)$. We have $$\pi(g) \pi(H) \pi(g)^{-1}=\pi(gHg^{-1})=\pi(H),$$ hence $\pi(G) \leq N_{S_n}(\pi(H))$. I can't see how to use Exercises 1 and 2 (which I will quote below) to follow the hint. (c) Once I have part $(b)$ right, this is easy. My questions: Is my partial solution correct so far? If not, please help me fix it. How can I prove part (b) by following the hint in the brackets. For reference, Exercises 1 and 2 state that for a semi-direct product $G=H \rtimes_\varphi K$ we have $C_K(H)=\ker  \varphi$ and $C_H(K)=N_H(K)$. Thank you!","I want to solve the following problem from Dummit & Foote's Abstract Algebra text (p. 186): Let $H$ be a group of order $n$, let $K=\text{Aut}(H)$ and form $G=\text{Hol}(H)=H \rtimes K$ (where $\varphi$ is the identity homomorphism). Let $G$ act by left multiplication on the left cosets of $K$ in $G$ and let $\pi$ be the associated permutation representation $\pi:G \to S_n$. (a) prove that the elements of $H$ are coset representatives for the left cosets of $K$ in $G$ and with this choice of coset representatives $\pi$ restricted to $H$ is the left regular representation of $H$. (b) Prove $\pi(G)$ is the normalizer in $S_n$ of $\pi(H)$. Deduce that under the regular representation of any finite group $H$ of order $n$, the normalizer in $S_n$ of the image of $H$ is isomorphic to $\text{Hol}(H)$. [Show $|G|=|N_{S_n}(\pi(H))|$ using Exercises 1 and 2 above.] (c) Deduce that the normalizer of the group generated by an $n$-cycle in $S_n$ is isomorphic to $\text{Hol}(Z_n)$ and has order $n \varphi(n)$. My attempt: (a) We know that there are $|G|/|K|=|H|=n$ left cosets of $K$ in $G$. If $h_1K=h_2K$ are the same coset, where $h_1,h_2 \in H$ then $h_1^{-1}h_2 \in K$. Since $h_1^{-1}h_2 \in H$ as well we find $h_1^{-1}h_2=1$ or $h_1=h_2$. Thus the $n$ distinct elements of $H$ give rise to $n$ distinct left cosets of $K$ in $G$, which are all such cosets. Moreover, $\pi \big|_H(h)(h'K)=hh'K$, so that working with the representatives from $H$, $\pi \big|_H$ coincides with the left regular representation of $H$. (b) I could prove one inclusion: Let $\pi(g) \in \pi(G)$. We have $$\pi(g) \pi(H) \pi(g)^{-1}=\pi(gHg^{-1})=\pi(H),$$ hence $\pi(G) \leq N_{S_n}(\pi(H))$. I can't see how to use Exercises 1 and 2 (which I will quote below) to follow the hint. (c) Once I have part $(b)$ right, this is easy. My questions: Is my partial solution correct so far? If not, please help me fix it. How can I prove part (b) by following the hint in the brackets. For reference, Exercises 1 and 2 state that for a semi-direct product $G=H \rtimes_\varphi K$ we have $C_K(H)=\ker  \varphi$ and $C_H(K)=N_H(K)$. Thank you!",,"['abstract-algebra', 'group-theory', 'permutations', 'semidirect-product']"
90,Mixed Boolean Arithmetic Identity,Mixed Boolean Arithmetic Identity,,"I'm trying to prove/derive the equivalence of the following formula: $$ x*y = (x \land y) *  (x \lor y) + (x \land \neg y) * (\neg x \land y) $$ whereas $(\land, \lor, \neg)$ correspond to bitwise operations over Boolean algebra ($B^n, \land , \lor, \neg)$ and arithmetic operations are in integer modular ring $Z/(2^n)$. Rearranging by using DeMorgan rules gives me: $x * (x \lor y) \land y * (x \lor y)$. However, I cannot simply factor out $(x \lor y)$ so I'm stuck at that point. The issue seems to be, that this whole thing is a non-linear expression . I came across this identity in this paper and was wondering how one could derive/generate such identities. Similar identities can be found in Hackers Delight chapter 2 (and are much simpler, i.e., linear combinations of the 16 boolean functions). Is it because the last term always equals to zero? How would one prove that? The last term isn't always zero (e.g. $1*524288$). Example in $Z/2^{32}$ $$ 4 * 5 = (4 \land 5) * (4 \lor 5) + (4 \land \lnot 5) * (\lnot 4 \land 5) \equiv (4) * (5) + (4 \land 4294967290) * (4294967291 \land 5) \equiv (4) * (5) + (0) * (0) \equiv 20 $$ Update: Let's split the formula into the two parts for easier reference: $$ t0 = (x \land y) *  (x \lor y) \\ t1 = (x \land \neg y) * (\neg x \land y) $$ I've used an SMT solver (z3) to prove that for all values of $x,y$ either $t0$ or $t1$ can be $\neq 0$, but not both at the same time. Counter example: $x = 1431655427, y = 427$","I'm trying to prove/derive the equivalence of the following formula: $$ x*y = (x \land y) *  (x \lor y) + (x \land \neg y) * (\neg x \land y) $$ whereas $(\land, \lor, \neg)$ correspond to bitwise operations over Boolean algebra ($B^n, \land , \lor, \neg)$ and arithmetic operations are in integer modular ring $Z/(2^n)$. Rearranging by using DeMorgan rules gives me: $x * (x \lor y) \land y * (x \lor y)$. However, I cannot simply factor out $(x \lor y)$ so I'm stuck at that point. The issue seems to be, that this whole thing is a non-linear expression . I came across this identity in this paper and was wondering how one could derive/generate such identities. Similar identities can be found in Hackers Delight chapter 2 (and are much simpler, i.e., linear combinations of the 16 boolean functions). Is it because the last term always equals to zero? How would one prove that? The last term isn't always zero (e.g. $1*524288$). Example in $Z/2^{32}$ $$ 4 * 5 = (4 \land 5) * (4 \lor 5) + (4 \land \lnot 5) * (\lnot 4 \land 5) \equiv (4) * (5) + (4 \land 4294967290) * (4294967291 \land 5) \equiv (4) * (5) + (0) * (0) \equiv 20 $$ Update: Let's split the formula into the two parts for easier reference: $$ t0 = (x \land y) *  (x \lor y) \\ t1 = (x \land \neg y) * (\neg x \land y) $$ I've used an SMT solver (z3) to prove that for all values of $x,y$ either $t0$ or $t1$ can be $\neq 0$, but not both at the same time. Counter example: $x = 1431655427, y = 427$",,"['abstract-algebra', 'boolean-algebra', 'nonlinear-system']"
91,Proof of the properties of tensor product,Proof of the properties of tensor product,,"On page 25 of Atiyah-Macdonald ""Introduction to commutative algebra"", the author says that ""We shall never again need to use the construction of the tensor product given above and the reader may safely forget it if he prefers. What is essential to keep in mind is the defining property of the tensor product."" I am not sure whether I understand that part well. When we prove some properties tensor product, we typically use the generators (pure tensors). It seems to me that that kind of step makes use of the construction of tensor product. So my question is, is there a purely categorical proof (without mentioning elements, only using universal property) for various properties of tensor product? (Even for the simplest one like $M\otimes N$ $\cong N\otimes M$, all the proofs I have seen involve elements when checking the two maps made from universal property are inverses to each other.) If it is, is it possible to use these kind of method to the other categories than the category of modules? (For example, for the tensor product of sheaves.)","On page 25 of Atiyah-Macdonald ""Introduction to commutative algebra"", the author says that ""We shall never again need to use the construction of the tensor product given above and the reader may safely forget it if he prefers. What is essential to keep in mind is the defining property of the tensor product."" I am not sure whether I understand that part well. When we prove some properties tensor product, we typically use the generators (pure tensors). It seems to me that that kind of step makes use of the construction of tensor product. So my question is, is there a purely categorical proof (without mentioning elements, only using universal property) for various properties of tensor product? (Even for the simplest one like $M\otimes N$ $\cong N\otimes M$, all the proofs I have seen involve elements when checking the two maps made from universal property are inverses to each other.) If it is, is it possible to use these kind of method to the other categories than the category of modules? (For example, for the tensor product of sheaves.)",,"['abstract-algebra', 'modules', 'tensor-products']"
92,"Proving that if the semigroup (A, *) is a group, then the relation is an equivalence relation.","Proving that if the semigroup (A, *) is a group, then the relation is an equivalence relation.",,"I'm aware that posting exam questions is probably frowned upon, but this isn't homework, I think I'm genuinely misunderstanding some part of the algebra. The question is this: Throughout this question, we shall denote by $\neg$ the relation on a semigroup $(A, * )$ defined so that elements x and y of the semigroup satisfy the relation $x \neg y$ if and only if there exists some element $s$ of the semigroup $A$ such that $s * x = y * s$ Prove the relation $\neg$ is a transitive relation on $A$ for all semigroups $(A, *)$. Prove that the relation $\neg$ is a reflexive relation on $A$ for all semigroups $(A, *)$. Prove that if the semigroup $(A, *)$ is a group, then the relation $\neg$ on $A$ is an equivalence relation. Prove that if $(A, *)$ is a group, and if the relation $\neg$ is a partial order on $A$, then the binary operation $*$ of the group $A$ is commutative. I've proven it's transitive and reflexive without too much hassle, but can't get past 3. My approach was such that I'd start with some $s$ such that $s * x = y * s$, and then play around with this equation until I'd get some new term, in terms of $x^{-1}$ and $y^{-1}$ such that (some term) * y = x * (some term), but I keep running around in circles. Then I thought $s * x = y * s$ doesn't capture enough information about the problem in order to be molded into the solution, but I can't see what else I can add into it. Thanks in advance, sorry about posting an exam question, but I figure this should expose something I'm missing in all similar problems.","I'm aware that posting exam questions is probably frowned upon, but this isn't homework, I think I'm genuinely misunderstanding some part of the algebra. The question is this: Throughout this question, we shall denote by $\neg$ the relation on a semigroup $(A, * )$ defined so that elements x and y of the semigroup satisfy the relation $x \neg y$ if and only if there exists some element $s$ of the semigroup $A$ such that $s * x = y * s$ Prove the relation $\neg$ is a transitive relation on $A$ for all semigroups $(A, *)$. Prove that the relation $\neg$ is a reflexive relation on $A$ for all semigroups $(A, *)$. Prove that if the semigroup $(A, *)$ is a group, then the relation $\neg$ on $A$ is an equivalence relation. Prove that if $(A, *)$ is a group, and if the relation $\neg$ is a partial order on $A$, then the binary operation $*$ of the group $A$ is commutative. I've proven it's transitive and reflexive without too much hassle, but can't get past 3. My approach was such that I'd start with some $s$ such that $s * x = y * s$, and then play around with this equation until I'd get some new term, in terms of $x^{-1}$ and $y^{-1}$ such that (some term) * y = x * (some term), but I keep running around in circles. Then I thought $s * x = y * s$ doesn't capture enough information about the problem in order to be molded into the solution, but I can't see what else I can add into it. Thanks in advance, sorry about posting an exam question, but I figure this should expose something I'm missing in all similar problems.",,"['abstract-algebra', 'group-theory', 'semigroups']"
93,Natural isomorphisms of the forgetful functor,Natural isomorphisms of the forgetful functor,,Let $U: \mathbf{Groups} \rightarrow \mathbf{Sets}$ be the forgetful functor. Must every natural transformation $\eta: U \rightarrow U$ be a natural isomorphism?,Let $U: \mathbf{Groups} \rightarrow \mathbf{Sets}$ be the forgetful functor. Must every natural transformation $\eta: U \rightarrow U$ be a natural isomorphism?,,"['abstract-algebra', 'category-theory']"
94,$G \cong G \times H$ does not imply $H$ is trivial.,does not imply  is trivial.,G \cong G \times H H,"In Aluffi's Algebra: Chapter $0$ there is a question asking to give a counterexample to the claim $G \cong G \times H$ implies $H$ is trivial. I am looking for a hint.  Obviously, at least one of $G$ or $H$ needs to be infinite.  Doing something with $\mathbb{Z}$ seems to be the natural thing.  I tried showing $\mathbb{Z} \cong \mathbb{Z} \times (\mathbb{Z}/2\mathbb{Z})$ by an ``interlacing evens and odds'' argument, but the ""odd + odd"" case killed my homomorphism... Am I on the right track? Thanks.","In Aluffi's Algebra: Chapter $0$ there is a question asking to give a counterexample to the claim $G \cong G \times H$ implies $H$ is trivial. I am looking for a hint.  Obviously, at least one of $G$ or $H$ needs to be infinite.  Doing something with $\mathbb{Z}$ seems to be the natural thing.  I tried showing $\mathbb{Z} \cong \mathbb{Z} \times (\mathbb{Z}/2\mathbb{Z})$ by an ``interlacing evens and odds'' argument, but the ""odd + odd"" case killed my homomorphism... Am I on the right track? Thanks.",,"['abstract-algebra', 'group-theory']"
95,Suppose that $f(x)$ and $g(x)$ are irreducible over $F$ and that $\deg f(x)$ and $\deg g(x)$ are relatively prime.,Suppose that  and  are irreducible over  and that  and  are relatively prime.,f(x) g(x) F \deg f(x) \deg g(x),"Suppose that $f(x)$ and $g(x)$ are irreducible over $F$ and that $\gcd(~\deg g(x),\deg f(x)~)=1$. If $a$ is a zero of $f(x)$ in some extension of $F$, show that $g(x)$ is irreducible over $F(a)$ Attempt: Let $b$ denote a zero of $g(x)$ in some extension of $F$. We have : $[F(a,b):F(a)][F(a):F]=[F(a,b):F] = [F(a,b):F(b)][F(b):F] ~~~~..... (1)$ $\deg f(x) = [F(a):F ] ~~~~...... (2)$ $\deg g(x) = [F(b):F ] ~~~~......(3)$ Since, $\deg g(x)$ and $ \deg f(x)$ are prime to each other $\implies [F(b):F]$ divides $[F(a,b):F(a)][F(a):F] \implies [F(b):F]$ divides $[F(a,b):F(a)]$ How do I move ahead? Let $a,b \in \mathbb Q~~|~~b \neq 0$. Show that $\mathbb Q(\sqrt a) = \mathbb Q(\sqrt b)$ if and only if there exists some $c \in \mathbb Q$ such that $a = bc^2$ Attempt: Case $1$: When $ a = {p_1}^2/{q_1}^2$ where $p_1,q_1 \in \mathbb Z,\gcd(p_1,q_1)=1$ Then : $\mathbb Q(\sqrt a) = \mathbb Q(p_1/q_1) =\mathbb Q = \mathbb Q(\sqrt b)$ only if $\sqrt b = \dfrac {p_2}{q_2}$ or $b=\dfrac {{p_2}^2}{{q_2}^2} $ In such a case : $\dfrac {{p_1}^2}{{q_1}^2}=   \dfrac {{p_2}^2}{{q_2}^2} {(\dfrac {q_2 p_1}{p_2q_1})}^2$. Hence $c = (\dfrac {q_2 p_1}{p_2q_1})$ Did I do this correctly? How do i move ahead? Thank you for your help..","Suppose that $f(x)$ and $g(x)$ are irreducible over $F$ and that $\gcd(~\deg g(x),\deg f(x)~)=1$. If $a$ is a zero of $f(x)$ in some extension of $F$, show that $g(x)$ is irreducible over $F(a)$ Attempt: Let $b$ denote a zero of $g(x)$ in some extension of $F$. We have : $[F(a,b):F(a)][F(a):F]=[F(a,b):F] = [F(a,b):F(b)][F(b):F] ~~~~..... (1)$ $\deg f(x) = [F(a):F ] ~~~~...... (2)$ $\deg g(x) = [F(b):F ] ~~~~......(3)$ Since, $\deg g(x)$ and $ \deg f(x)$ are prime to each other $\implies [F(b):F]$ divides $[F(a,b):F(a)][F(a):F] \implies [F(b):F]$ divides $[F(a,b):F(a)]$ How do I move ahead? Let $a,b \in \mathbb Q~~|~~b \neq 0$. Show that $\mathbb Q(\sqrt a) = \mathbb Q(\sqrt b)$ if and only if there exists some $c \in \mathbb Q$ such that $a = bc^2$ Attempt: Case $1$: When $ a = {p_1}^2/{q_1}^2$ where $p_1,q_1 \in \mathbb Z,\gcd(p_1,q_1)=1$ Then : $\mathbb Q(\sqrt a) = \mathbb Q(p_1/q_1) =\mathbb Q = \mathbb Q(\sqrt b)$ only if $\sqrt b = \dfrac {p_2}{q_2}$ or $b=\dfrac {{p_2}^2}{{q_2}^2} $ In such a case : $\dfrac {{p_1}^2}{{q_1}^2}=   \dfrac {{p_2}^2}{{q_2}^2} {(\dfrac {q_2 p_1}{p_2q_1})}^2$. Hence $c = (\dfrac {q_2 p_1}{p_2q_1})$ Did I do this correctly? How do i move ahead? Thank you for your help..",,"['abstract-algebra', 'ring-theory', 'field-theory', 'extension-field']"
96,Using resultants to check if multivariate polynomials have a common factor - is my proof correct?,Using resultants to check if multivariate polynomials have a common factor - is my proof correct?,,"Proposition: Let $f, g \in \mathbb R[x,y,z]$. Then the condition that $f, g$ have a common polynomial factor is an algebraic condition on their coefficients. By algebraic condition, I mean there is a finite set of algebraic (polynomial) expressions in the coefficients, such that all expressions are zero if and only if $f, g$ have a common factor. My proof: Let $\operatorname{Res}_x(f,g)$ be the resultant of $f, g$ when viewed as univariate polynomials in $(\mathbb R[y,z])[x]$. Then $\operatorname{Res}_x(f,g) \in \mathbb R[y,z]$ is zero if and only if $f, g$ have a common factor that depends on $x$. As a polynomial in $y,z$, it is zero if and only if all of its coefficients are zero. But the coefficients of the resultant are simply polynomial expressions in the coefficients of $f, g$. Therefore there is an algebraic condition on the coefficients of $f,g$ that determines when $f,g$ have a common factor that depends on $x$ . Repeating the argument, there are two more algebraic conditions on the coefficients of $f,g$, which determine when they have a common factor that depends on $y$ and when they have one that depends on $z$. The union of all 3 conditions is what we're after. Questions: Is my proof correct? I'm especially concerned about the claim that the resultant is the zero polynomial if and only if there is a common factor that depends on $x$. (Does the resultant behave ok for polynomials over rings instead of over fields?) Do you have comments or suggestions for improvement? Any recommended books on this subject?","Proposition: Let $f, g \in \mathbb R[x,y,z]$. Then the condition that $f, g$ have a common polynomial factor is an algebraic condition on their coefficients. By algebraic condition, I mean there is a finite set of algebraic (polynomial) expressions in the coefficients, such that all expressions are zero if and only if $f, g$ have a common factor. My proof: Let $\operatorname{Res}_x(f,g)$ be the resultant of $f, g$ when viewed as univariate polynomials in $(\mathbb R[y,z])[x]$. Then $\operatorname{Res}_x(f,g) \in \mathbb R[y,z]$ is zero if and only if $f, g$ have a common factor that depends on $x$. As a polynomial in $y,z$, it is zero if and only if all of its coefficients are zero. But the coefficients of the resultant are simply polynomial expressions in the coefficients of $f, g$. Therefore there is an algebraic condition on the coefficients of $f,g$ that determines when $f,g$ have a common factor that depends on $x$ . Repeating the argument, there are two more algebraic conditions on the coefficients of $f,g$, which determine when they have a common factor that depends on $y$ and when they have one that depends on $z$. The union of all 3 conditions is what we're after. Questions: Is my proof correct? I'm especially concerned about the claim that the resultant is the zero polynomial if and only if there is a common factor that depends on $x$. (Does the resultant behave ok for polynomials over rings instead of over fields?) Do you have comments or suggestions for improvement? Any recommended books on this subject?",,"['abstract-algebra', 'polynomials', 'proof-verification']"
97,Showing the Weyl algebra is simple.,Showing the Weyl algebra is simple.,,"Let $R$ be a ring with $1$, which contains $\mathbb{Q}$, and generated over $\mathbb{Q}$ by two elements $x,y$ such that $yx-xy=1$. Show that $R$ is simple. What i did? Certainly $x, y \in R$ as $1\in R$. Consider $0\neq I$ to be a two-sided ideal of $R$. If one among $x,y\in I$, say $x\in I$ then $yx\in I$ and $xy\in I$ so $1=yx-xy\in I$ thus $I=R$. If $x,y\notin I$ then for any $0\neq r\in I$ and $\frac{yx}{r}, \frac{xy}{r} \in R$ we have $1 = \frac{yx}{r} r - \frac{xy}{r} r\in I$ then $I=R$ as $1\in I$. Can i use the rationals in this way? Please suggest me. Thank you.","Let $R$ be a ring with $1$, which contains $\mathbb{Q}$, and generated over $\mathbb{Q}$ by two elements $x,y$ such that $yx-xy=1$. Show that $R$ is simple. What i did? Certainly $x, y \in R$ as $1\in R$. Consider $0\neq I$ to be a two-sided ideal of $R$. If one among $x,y\in I$, say $x\in I$ then $yx\in I$ and $xy\in I$ so $1=yx-xy\in I$ thus $I=R$. If $x,y\notin I$ then for any $0\neq r\in I$ and $\frac{yx}{r}, \frac{xy}{r} \in R$ we have $1 = \frac{yx}{r} r - \frac{xy}{r} r\in I$ then $I=R$ as $1\in I$. Can i use the rationals in this way? Please suggest me. Thank you.",,"['abstract-algebra', 'ring-theory', 'noncommutative-algebra']"
98,$F/K$ algebraic and every nonconstant polynomial in $K[X]$ has a root in $F$ implies $F$ is algebraically closed.,algebraic and every nonconstant polynomial in  has a root in  implies  is algebraically closed.,F/K K[X] F F,"Let $F/K$ be an algebraic extension of fields in characteristic zero.  If $F/K$ is normal, and every nonconstant polynomial $f \in K[X]$ has a root in $F$, then $F$ is algebraically closed.  This is obvious, because if $u$ is algebraic over $F$ (let us agree to fix some algebraic closure $\overline{K}$ of $K$ containing $F$ with $u \in \overline{K}$), then it is algebraic over $K$ with minimal polynomial $f \in K[X]$, which by hypothesis must have one and therefore all of its roots in $F$.  In particular $u \in F$. I have heard that the above assertion remains true if we drop the assumption that $F/K$ is normal.  But it seems to be a nontrivial result.  Can anyone get me started on how to prove this? Thoughts so far: It's enough to show that every algebraic extension of $K$ is $K$-isomorphic to a subfield of $F$.  Certainly this is true for every finite extension $E$ of $K$; we're in characteristic zero, so $E = K(v)$ for some $v \in E$.  If $f \in K[X]$ is the minimal polynomial of $v$ over $K$, then $f$ has some root $u \in F$, whence $E$ is $K$-isomorphic to the subfield $K(u)$ of $F$. So, I'm thinking next use some kind of Zorn's Lemma argument?","Let $F/K$ be an algebraic extension of fields in characteristic zero.  If $F/K$ is normal, and every nonconstant polynomial $f \in K[X]$ has a root in $F$, then $F$ is algebraically closed.  This is obvious, because if $u$ is algebraic over $F$ (let us agree to fix some algebraic closure $\overline{K}$ of $K$ containing $F$ with $u \in \overline{K}$), then it is algebraic over $K$ with minimal polynomial $f \in K[X]$, which by hypothesis must have one and therefore all of its roots in $F$.  In particular $u \in F$. I have heard that the above assertion remains true if we drop the assumption that $F/K$ is normal.  But it seems to be a nontrivial result.  Can anyone get me started on how to prove this? Thoughts so far: It's enough to show that every algebraic extension of $K$ is $K$-isomorphic to a subfield of $F$.  Certainly this is true for every finite extension $E$ of $K$; we're in characteristic zero, so $E = K(v)$ for some $v \in E$.  If $f \in K[X]$ is the minimal polynomial of $v$ over $K$, then $f$ has some root $u \in F$, whence $E$ is $K$-isomorphic to the subfield $K(u)$ of $F$. So, I'm thinking next use some kind of Zorn's Lemma argument?",,"['abstract-algebra', 'field-theory', 'extension-field']"
99,Ring Sandwiched between PIDs,Ring Sandwiched between PIDs,,"If I have three commutative rings $R \subset S \subset T$, such that $R$ and $T$ are principal ideal domains, will this imply that $S$ itself is a principal ideal domain?","If I have three commutative rings $R \subset S \subset T$, such that $R$ and $T$ are principal ideal domains, will this imply that $S$ itself is a principal ideal domain?",,['abstract-algebra']
