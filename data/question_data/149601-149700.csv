,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Can $\ln(x)=\lim_{n\to\infty} n\left(x^{\frac1{n}}-1 \right)$ be expressed as an infinite telescoping product?,Can  be expressed as an infinite telescoping product?,\ln(x)=\lim_{n\to\infty} n\left(x^{\frac1{n}}-1 \right),"Concerning this question of mine which involves telescoping in the solution, I was wondering if it is possible to express $$\ln(x)=\lim_{n\to\infty}n\left(x^{\frac1{n}}-1\right)$$ and $$e^x=\lim_{n\to\infty}\left(1+\frac{x}{n}\right)^n$$ as infinite telescoping products. Is it possible? Thanks. EDIT: The infinite product $$\ln(x)=(x-1)\prod_{k=1}^{\infty}\frac{2}{x^{2^{-k}}+1}$$ given bellow by @Zarrax, was first published by Ludwig von Seidel . See Theorem 4 in "" The Logarithmic Constant: log(2) "" by Xavier Gourdon and Pascal Sebah.","Concerning this question of mine which involves telescoping in the solution, I was wondering if it is possible to express $$\ln(x)=\lim_{n\to\infty}n\left(x^{\frac1{n}}-1\right)$$ and $$e^x=\lim_{n\to\infty}\left(1+\frac{x}{n}\right)^n$$ as infinite telescoping products. Is it possible? Thanks. EDIT: The infinite product $$\ln(x)=(x-1)\prod_{k=1}^{\infty}\frac{2}{x^{2^{-k}}+1}$$ given bellow by @Zarrax, was first published by Ludwig von Seidel . See Theorem 4 in "" The Logarithmic Constant: log(2) "" by Xavier Gourdon and Pascal Sebah.",,"['real-analysis', 'analysis']"
1,"$f:X \rightarrow Y$. What are the conditions on $f$,$X$,$Y$ in order for an integral of $f$ to be defined?",". What are the conditions on ,, in order for an integral of  to be defined?",f:X \rightarrow Y f X Y f,"Let's assume $X,Y$ are arbitrary sets, and $f$ is a function between them. What must those sets, and $f$, satisfy, in order for us to be able to define an integral of $f$ in a way that ""makes sense""?","Let's assume $X,Y$ are arbitrary sets, and $f$ is a function between them. What must those sets, and $f$, satisfy, in order for us to be able to define an integral of $f$ in a way that ""makes sense""?",,"['analysis', 'functions', 'integration']"
2,Is there a non trivial smooth function that has uncountably many roots?,Is there a non trivial smooth function that has uncountably many roots?,,(on a bounded domain). I believe that such a function could not exist since every $C^\infty$ function can be approximated by a sequence of polynomials and every polynomial has a finite number of roots so it would not be possible for something that vanishes countably often to converge to something that vanishes uncountably often.,(on a bounded domain). I believe that such a function could not exist since every function can be approximated by a sequence of polynomials and every polynomial has a finite number of roots so it would not be possible for something that vanishes countably often to converge to something that vanishes uncountably often.,C^\infty,['analysis']
3,How to prove $(1 + x)^{n} \leq 1 + 2nx$,How to prove,(1 + x)^{n} \leq 1 + 2nx,"I am currently working on a math problem, and it boils down to proving $(1 + x)^{n} \leq 1 + 2nx$ , for a small $x$ By the Binomial expansion, it is clear that $$(1 + x)^n= 1+ nx + \frac{n(n-1)}{ 2!}x^2 + \frac{n(n-1)(n-2)}{3!}x^3 + \cdots$$ However, how can we prove that $$nx \geq \frac{n(n-1)}{ 2!}x^2 + \frac{n(n-1)(n-2)}{3!}x^3 + \cdots $$ which would prove my claim. Any ideas?","I am currently working on a math problem, and it boils down to proving , for a small By the Binomial expansion, it is clear that However, how can we prove that which would prove my claim. Any ideas?",(1 + x)^{n} \leq 1 + 2nx x (1 + x)^n= 1+ nx + \frac{n(n-1)}{ 2!}x^2 + \frac{n(n-1)(n-2)}{3!}x^3 + \cdots nx \geq \frac{n(n-1)}{ 2!}x^2 + \frac{n(n-1)(n-2)}{3!}x^3 + \cdots ,"['real-analysis', 'analysis', 'inequality', 'polynomials', 'taylor-expansion']"
4,Convergence of $\sum_{n=0}^{\infty} \frac{4^n}{3^n+7^n}$,Convergence of,\sum_{n=0}^{\infty} \frac{4^n}{3^n+7^n},"I need help with this. $\sum_{n=0}^{\infty}  \frac{4^n}{3^n+7^n}$ I know that it converges but i can not proove why. I tried to rewrite it, it seems to be a geometric serie. I tried to do a common factor between $3^n+7^n  \rightarrow 3^n(1+\frac{7^n}{3^n})$ So I have $\sum_{n=0}^{\infty} (\frac{4}{3})^n \frac{1}{1+(\frac{7}{3})^n}$ And I do not know if that helps. I can also make different the common factor and I would have $\sum_{n=0}^{\infty} (\frac{4}{7})^n \frac{1}{1+(\frac{3}{7})^n}$","I need help with this. I know that it converges but i can not proove why. I tried to rewrite it, it seems to be a geometric serie. I tried to do a common factor between So I have And I do not know if that helps. I can also make different the common factor and I would have",\sum_{n=0}^{\infty}  \frac{4^n}{3^n+7^n} 3^n+7^n  \rightarrow 3^n(1+\frac{7^n}{3^n}) \sum_{n=0}^{\infty} (\frac{4}{3})^n \frac{1}{1+(\frac{7}{3})^n} \sum_{n=0}^{\infty} (\frac{4}{7})^n \frac{1}{1+(\frac{3}{7})^n},"['calculus', 'sequences-and-series', 'analysis', 'convergence-divergence', 'summation']"
5,Proving that a function is not a contraction,Proving that a function is not a contraction,,"I am solving the following problem and its parts. Let (C[0,1], $d_\infty$ ) be the metric space of continuous functions on [0,1] where the distance function is defined by $d_\infty(f,g)=\sup_{x∈[0,1]}|f(x)−g(x)|. $ Let $T : (C[0, 1], d_\infty)\to (C[0, 1],d_\infty$ ) be defined by $(Tf)(x)=\int_0^xf(t)dt$ Prove that: T is not a contraction, i.e. there does not exist 0 < K <    1 such that $d_\infty(T f, T g)\leq K · d_\infty(f, g)$ holds for any $f,g ∈ C[0,1]$ . Ive tried an example but I haven't really got anywhere. My work is as follows: $$f'(t)=\int_0^xtdt=\frac{x^2}{2}=F(x)-F(0)$$ so we pick $t$ & $t^2$ such that $d$ ( $t$ , $t^2$ )=sup[ $t$ - $t^2$ ] with max value = $\frac{1}{4}$ and $d$ (T $t$ ,T $t^2$ )=sup[ $\frac{t^2}{2}-\frac{t^3}{3}$ ] with max value =.167","I am solving the following problem and its parts. Let (C[0,1], ) be the metric space of continuous functions on [0,1] where the distance function is defined by Let ) be defined by Prove that: T is not a contraction, i.e. there does not exist 0 < K <    1 such that holds for any . Ive tried an example but I haven't really got anywhere. My work is as follows: so we pick & such that ( , )=sup[ - ] with max value = and (T ,T )=sup[ ] with max value =.167","d_\infty d_\infty(f,g)=\sup_{x∈[0,1]}|f(x)−g(x)|.  T : (C[0, 1], d_\infty)\to (C[0, 1],d_\infty (Tf)(x)=\int_0^xf(t)dt d_\infty(T f, T g)\leq K · d_\infty(f, g) f,g ∈ C[0,1] f'(t)=\int_0^xtdt=\frac{x^2}{2}=F(x)-F(0) t t^2 d t t^2 t t^2 \frac{1}{4} d t t^2 \frac{t^2}{2}-\frac{t^3}{3}",['analysis']
6,Paradox in indefinite integral,Paradox in indefinite integral,,"Today,I met a problem about calculating such an indefinite integral $$ I=\int \frac{1}{(1+x^2)(1+x^{2019})}$$ My thought is as follows $$ \begin{aligned} I & = \int \frac { 1 } { \left( 1 + x ^ { 2 } \right) \left( 1 + x ^ { 2019} \right) } d x \\ & = \int \frac { 1 } { \left( 1 + x ^ { - 2 } \right) \left( 1 + x ^ { - 2019} \right) } \left( - \frac { 1 } { x ^ { 2 } } \right) d x \\ & = \int \frac { - x ^ { 2019 } } { \left( 1 + x ^ { 2 } \right) \left( 1 + x ^ { 2019} \right) } d x \\ & = I - \int \frac { 1 } { 1 + x ^ { 2 } } d x \end{aligned} $$ No doubt,it is wrong.However, I don’t know how to illustrate this paradox?","Today,I met a problem about calculating such an indefinite integral My thought is as follows No doubt,it is wrong.However, I don’t know how to illustrate this paradox?"," I=\int \frac{1}{(1+x^2)(1+x^{2019})} 
\begin{aligned} I & = \int \frac { 1 } { \left( 1 + x ^ { 2 } \right) \left( 1 + x ^ { 2019} \right) } d x \\ & = \int \frac { 1 } { \left( 1 + x ^ { - 2 } \right) \left( 1 + x ^ { - 2019} \right) } \left( - \frac { 1 } { x ^ { 2 } } \right) d x \\ & = \int \frac { - x ^ { 2019 } } { \left( 1 + x ^ { 2 } \right) \left( 1 + x ^ { 2019} \right) } d x \\ & = I - \int \frac { 1 } { 1 + x ^ { 2 } } d x \end{aligned}
","['calculus', 'integration', 'analysis']"
7,Prove $\mathbb{Q}$ is a path-connected topological space,Prove  is a path-connected topological space,\mathbb{Q},"I am trying to comprehend how path-connectedness of a topological space is proved in essence to solve another problem (to prove the plane $\mathbb{R}^2$ without a line is not path-connected) and have troubles with it. There is a quite intuitive definition of path-connectedness: a topological space is path-connected if for any two points in that space there exists a continuous function from a compact $[a,b]$ to that space such that its $f(a)$ and $f(b)$ are equal to those points respectively. Now, I've made this simple problem (stated in the title) for myself to understand how it's proved. The way I think (although it's a hand-waving proof, I do not understand the flaw I've made): Let's split a closet interval $[0,1]$ into semi-intervals like $(x_1,x_2]$ with $x_2 > x_1$ (and keep the first one starting from 0 to be a closed interval for the sake of symmetry, i.e. the first one is $[0,x]$ ). Obviously, I can split this interval into countable amount of such semi-intervals. Therefore, since between any two rational points $a$ and $b$ there're countable amount of rationals, I can construct a function mapping these semi-intervals to points in $[a,b]\cap\mathbb{Q}$ (e.g. I can identify each semi-interval with a rational point enclosed in between to get an enumeration and that match each semi-interval to each point in enumerated set of points in $[a,b]\cap\mathbb{Q}$ with some bijection $f:\mathbb{N}\to\mathbb{N}$ ). A function constructed as such is continuous because for any rational point in $[a,b]\cap\mathbb{Q}$ there exists a whole neighbourhood mapped to this single point. And since we can construct such a continuous function for any two rational points, Q is path-connected. Thank you!","I am trying to comprehend how path-connectedness of a topological space is proved in essence to solve another problem (to prove the plane without a line is not path-connected) and have troubles with it. There is a quite intuitive definition of path-connectedness: a topological space is path-connected if for any two points in that space there exists a continuous function from a compact to that space such that its and are equal to those points respectively. Now, I've made this simple problem (stated in the title) for myself to understand how it's proved. The way I think (although it's a hand-waving proof, I do not understand the flaw I've made): Let's split a closet interval into semi-intervals like with (and keep the first one starting from 0 to be a closed interval for the sake of symmetry, i.e. the first one is ). Obviously, I can split this interval into countable amount of such semi-intervals. Therefore, since between any two rational points and there're countable amount of rationals, I can construct a function mapping these semi-intervals to points in (e.g. I can identify each semi-interval with a rational point enclosed in between to get an enumeration and that match each semi-interval to each point in enumerated set of points in with some bijection ). A function constructed as such is continuous because for any rational point in there exists a whole neighbourhood mapped to this single point. And since we can construct such a continuous function for any two rational points, Q is path-connected. Thank you!","\mathbb{R}^2 [a,b] f(a) f(b) [0,1] (x_1,x_2] x_2 > x_1 [0,x] a b [a,b]\cap\mathbb{Q} [a,b]\cap\mathbb{Q} f:\mathbb{N}\to\mathbb{N} [a,b]\cap\mathbb{Q}","['general-topology', 'analysis', 'connectedness']"
8,Prove that $\frac{\arccos(x)}{\sqrt{1-x}}$ is decreasing,Prove that  is decreasing,\frac{\arccos(x)}{\sqrt{1-x}},"I want to show that $$f(x):=\frac{\arccos(x)}{\sqrt{1-x}}$$ is a decreasing function. I tried to differentiate but than I have to show that $$\arccos(x)\sqrt{1+x} \leq 2 \sqrt{1-x}.$$ Everytime I tried something I ended up with a even more complex problem or in general something like finding roots of some nonlinear functions. E.g. I could transform the above inequality to $$\int_{-1}^x2\arccos(y)\mathop{}\!\mathrm{d}y +(1-x)\arccos(x)\leq 2\pi,$$ but it didn't helped me a lot. Is there a way to prove analytically that the function $f$ is decreasing? EDIT: The domain is $-1\leq x\leq 1$ . This is valid, since $$ \lim_{x\to 1^{-}}f(x)=\sqrt{2}.$$","I want to show that is a decreasing function. I tried to differentiate but than I have to show that Everytime I tried something I ended up with a even more complex problem or in general something like finding roots of some nonlinear functions. E.g. I could transform the above inequality to but it didn't helped me a lot. Is there a way to prove analytically that the function is decreasing? EDIT: The domain is . This is valid, since","f(x):=\frac{\arccos(x)}{\sqrt{1-x}} \arccos(x)\sqrt{1+x} \leq 2 \sqrt{1-x}. \int_{-1}^x2\arccos(y)\mathop{}\!\mathrm{d}y +(1-x)\arccos(x)\leq 2\pi, f -1\leq x\leq 1  \lim_{x\to 1^{-}}f(x)=\sqrt{2}.","['real-analysis', 'calculus', 'analysis', 'trigonometry', 'inequality']"
9,A scary looking relationship between Euler constant $\gamma$ and $\pi$,A scary looking relationship between Euler constant  and,\gamma \pi,"I saw this scary looking relation between the Euler constant $\gamma$ , the Gamma function and $\pi$ in Peter Luschny blog . Any proofs? $$  \left({{\frac {\Gamma (\gamma )}{\Gamma (2\gamma )\Gamma (1/2-\gamma )}}+{\frac {2\Gamma (1-2\gamma )}{\Gamma (1-\gamma )\Gamma (1/2-\gamma )}}}\right)^{2}\left({\frac {\Gamma (\gamma )\Gamma (1/2-\gamma /2)}{\Gamma (\gamma /2)}}\right)^{4}=\pi  $$","I saw this scary looking relation between the Euler constant , the Gamma function and in Peter Luschny blog . Any proofs?","\gamma \pi  
\left({{\frac {\Gamma (\gamma )}{\Gamma (2\gamma )\Gamma (1/2-\gamma )}}+{\frac {2\Gamma (1-2\gamma )}{\Gamma (1-\gamma )\Gamma (1/2-\gamma )}}}\right)^{2}\left({\frac {\Gamma (\gamma )\Gamma (1/2-\gamma /2)}{\Gamma (\gamma /2)}}\right)^{4}=\pi 
","['analysis', 'gamma-function', 'pi', 'euler-mascheroni-constant']"
10,"If two functions are equal almost everywhere, the first is continuous a.e., is the second?","If two functions are equal almost everywhere, the first is continuous a.e., is the second?",,"If $f = g$ a.e. in $E \in \mathfrak{M}$ (the Lebesgue measurable sets)   and $f$ is continuous a.e. in $E$ , is $g$ continuous a.e. in $E$ ? I think this is true. My “proof”: Let us denote $D_1 = \{ x \in E: f(x) \text{ discontinuous}\}$ , $m(D_1) = 0$ and $D_2 = \{ x \in E: f(x) \neq g(x)\}$ , $m(D_2) = 0$ . Define $D_3 = \{ x \in E: g(x) \text{ discontinuous}\}$ . If $f$ is identically $g$ , then it is clear that the result follows as $D_3 = D_1$ . Otherwise, we have $D_3 \subseteq D_1 \cup D_2$ , and so $m^*(D_3) \leq m^*(D_1 \cup D_2) \leq m^*(D_1) + m^*(D_2) = 0$ . So, $m(D_3) = 0$ and hence $g$ is continuous almost everywhere. Does this proof work? Thanks! Edit: for clarity, $m$ denotes the Lebesgue measure and $m^*$ the Lebesgue outer measure.","If a.e. in (the Lebesgue measurable sets)   and is continuous a.e. in , is continuous a.e. in ? I think this is true. My “proof”: Let us denote , and , . Define . If is identically , then it is clear that the result follows as . Otherwise, we have , and so . So, and hence is continuous almost everywhere. Does this proof work? Thanks! Edit: for clarity, denotes the Lebesgue measure and the Lebesgue outer measure.",f = g E \in \mathfrak{M} f E g E D_1 = \{ x \in E: f(x) \text{ discontinuous}\} m(D_1) = 0 D_2 = \{ x \in E: f(x) \neq g(x)\} m(D_2) = 0 D_3 = \{ x \in E: g(x) \text{ discontinuous}\} f g D_3 = D_1 D_3 \subseteq D_1 \cup D_2 m^*(D_3) \leq m^*(D_1 \cup D_2) \leq m^*(D_1) + m^*(D_2) = 0 m(D_3) = 0 g m m^*,"['real-analysis', 'analysis', 'measure-theory']"
11,"Exist $f : \mathbb { R } \rightarrow \mathbb { R }$ such that $f (x)f (y) = f (x+ y) \forall x , y \in \mathbb { R }$ , but $f$ is not continuous?","Exist  such that  , but  is not continuous?","f : \mathbb { R } \rightarrow \mathbb { R } f (x)f (y) = f (x+ y) \forall x , y \in \mathbb { R } f","Does there exist a function $f : \mathbb { R } \rightarrow \mathbb { R }$ such that $f ( x ) \cdot f ( y ) = f ( x + y )$ $\forall$ $x , y \in \mathbb { R }$ , but such that $f$ is not everywhere continuous? I have this problem for my undergraduate Real Analysis class and have not been able to make any progress whatsoever. I have talked to postdocs and PhD students and none of them have been able to help. I was thinking that it might be something like $f(x) = a^x$ if $x\in\mathbb{Q}$ and $f(x) = 0$ if $x\in\mathbb{I}$ , but then I realized that this did not work due to cases like $x=\pi$ and $y=-\pi$ . Does anyone have any input on this problem?","Does there exist a function such that , but such that is not everywhere continuous? I have this problem for my undergraduate Real Analysis class and have not been able to make any progress whatsoever. I have talked to postdocs and PhD students and none of them have been able to help. I was thinking that it might be something like if and if , but then I realized that this did not work due to cases like and . Does anyone have any input on this problem?","f : \mathbb { R } \rightarrow \mathbb { R } f ( x ) \cdot f ( y ) = f ( x + y ) \forall x , y \in \mathbb { R } f f(x) = a^x x\in\mathbb{Q} f(x) = 0 x\in\mathbb{I} x=\pi y=-\pi","['real-analysis', 'analysis', 'continuity']"
12,Complex result or solution of an improper integral,Complex result or solution of an improper integral,,"The indefinite integral $\displaystyle \int \frac{\ln (x)}{x^2-2 x+1} \, dx$ has the solution $\ln (1-x)+\frac{x \ln (x)}{1-x} +C$ Taking the limit as $x$ approaches infinity $\displaystyle \lim_{x\to \infty } \, \left(\ln (1-x)+\frac{x \ln (x)}{1-x}\right)= i \pi$ Also $\displaystyle \lim_{x\to 0 } \, \left(\ln (1-x)+\frac{x \ln (x)}{1-x}\right)= 0$ This means that $\displaystyle \int_0^{\infty } \frac{\ln (x)}{x^2-2 x+1} \, dx = i \pi$ However there is the argument that the integration is over the real plane, the limit does not exist as $x$ approaches zero, and a complex solution was found, so there might be a contradiction. How can this be explained or resolved?","The indefinite integral $\displaystyle \int \frac{\ln (x)}{x^2-2 x+1} \, dx$ has the solution $\ln (1-x)+\frac{x \ln (x)}{1-x} +C$ Taking the limit as $x$ approaches infinity $\displaystyle \lim_{x\to \infty } \, \left(\ln (1-x)+\frac{x \ln (x)}{1-x}\right)= i \pi$ Also $\displaystyle \lim_{x\to 0 } \, \left(\ln (1-x)+\frac{x \ln (x)}{1-x}\right)= 0$ This means that $\displaystyle \int_0^{\infty } \frac{\ln (x)}{x^2-2 x+1} \, dx = i \pi$ However there is the argument that the integration is over the real plane, the limit does not exist as $x$ approaches zero, and a complex solution was found, so there might be a contradiction. How can this be explained or resolved?",,"['calculus', 'integration', 'analysis']"
13,A identity which looks like the binomial identity,A identity which looks like the binomial identity,,"Let $f_0(x)=1$, $f_k(x)=x(x-1)\cdots(x-k+1)$, $\forall k\geq1$. For any positive integer $n$, how to prove the following identity: $$f_n(x+y)=\sum_{k=0}^n\binom{n}{k}f_k(x)f_{n-k}(y)?$$","Let $f_0(x)=1$, $f_k(x)=x(x-1)\cdots(x-k+1)$, $\forall k\geq1$. For any positive integer $n$, how to prove the following identity: $$f_n(x+y)=\sum_{k=0}^n\binom{n}{k}f_k(x)f_{n-k}(y)?$$",,"['linear-algebra', 'analysis']"
14,Does $\sum_k \frac{a_k-a_{k-1}}{a_k^2}$ converge if $a_k \uparrow \infty$?,Does  converge if ?,\sum_k \frac{a_k-a_{k-1}}{a_k^2} a_k \uparrow \infty,"Let $a_n$ be a sequence of strictly increasing postive numbers such that $a_n \uparrow \infty$. Does $$\sum_{k=1}^\infty \frac{a_k-a_{k-1}}{a_k^2}$$ converge? My guess is that it converges. I tried with $a_n=n, n^2, \log n$. For all of them the series converges. My try: I was thinking of using Cauchy–Schwarz inequality, like $$\sum_{k=1}^\infty \frac{a_k-a_{k-1}}{a_k^2} \le \sum_{k=1}^\infty \frac1{a_k^2}\sum_{k=1}^\infty \frac{(a_k-a_{k-1})^2}{a_k^2}$$ or some other variants. But none of them works. Then I tried to show that the series is Cauchy, i.e., for $p<q$ $$\sum_{k=p+1}^q \frac{a_k-a_{k-1}}{a_k^2} \le \sum_{k=p+1}^q \frac{a_k-a_{k-1}}{a_{p+1}^2}=\frac{a_q-a_p}{a_{p+1}^2}$$ but the right hand estimate does not necessarily go to zero for large $p$ and $q$. Take $a_n=n^n$ for example. But the original series converges with $a_n=n^n$. Any help/suggestions?","Let $a_n$ be a sequence of strictly increasing postive numbers such that $a_n \uparrow \infty$. Does $$\sum_{k=1}^\infty \frac{a_k-a_{k-1}}{a_k^2}$$ converge? My guess is that it converges. I tried with $a_n=n, n^2, \log n$. For all of them the series converges. My try: I was thinking of using Cauchy–Schwarz inequality, like $$\sum_{k=1}^\infty \frac{a_k-a_{k-1}}{a_k^2} \le \sum_{k=1}^\infty \frac1{a_k^2}\sum_{k=1}^\infty \frac{(a_k-a_{k-1})^2}{a_k^2}$$ or some other variants. But none of them works. Then I tried to show that the series is Cauchy, i.e., for $p<q$ $$\sum_{k=p+1}^q \frac{a_k-a_{k-1}}{a_k^2} \le \sum_{k=p+1}^q \frac{a_k-a_{k-1}}{a_{p+1}^2}=\frac{a_q-a_p}{a_{p+1}^2}$$ but the right hand estimate does not necessarily go to zero for large $p$ and $q$. Take $a_n=n^n$ for example. But the original series converges with $a_n=n^n$. Any help/suggestions?",,"['real-analysis', 'sequences-and-series', 'analysis', 'divergent-series', 'cauchy-sequences']"
15,Prove that the integral $\int_0^1 f(t) P(t - x)dt$ is a polynomial in $x$,Prove that the integral  is a polynomial in,\int_0^1 f(t) P(t - x)dt x,"So suppose $f$ is a generally complex, continuous function on $[0,1]$ and $P$ is a polynomial defined on the real numbers. Evidently $$ \int_0^1 f(t)P(t - x)\,dt $$ is a polynomial in $x$ but that this is the case is not obvious to me. How might one go about proving this? Note that $f$ is continuous and so is integrable but it may not have a nice anti-derivative.","So suppose $f$ is a generally complex, continuous function on $[0,1]$ and $P$ is a polynomial defined on the real numbers. Evidently $$ \int_0^1 f(t)P(t - x)\,dt $$ is a polynomial in $x$ but that this is the case is not obvious to me. How might one go about proving this? Note that $f$ is continuous and so is integrable but it may not have a nice anti-derivative.",,"['real-analysis', 'analysis']"
16,"Continuous increasing bounded function, derivative","Continuous increasing bounded function, derivative",,"Is it true that a differentiable (and hence continuous) increasing bounded function $f:\mathbb{R} \to \mathbb{R}$ has derivative $f'$ that must go to zero as $x \to \infty$. If it is, could someone supply a proof? This is just something I wanted to prove another result with, I discovered the original thing I wanted to prove was false, but I am still interested in this.","Is it true that a differentiable (and hence continuous) increasing bounded function $f:\mathbb{R} \to \mathbb{R}$ has derivative $f'$ that must go to zero as $x \to \infty$. If it is, could someone supply a proof? This is just something I wanted to prove another result with, I discovered the original thing I wanted to prove was false, but I am still interested in this.",,"['calculus', 'analysis']"
17,"In a metric space with a countable base, how does every open cover have a countable subcover?","In a metric space with a countable base, how does every open cover have a countable subcover?",,"Let $X$ be a mertic space, and let $\left\{ V_{\alpha} \right\}$ be a collection of open subsets of $X$ such that, for every $x \in X$ and for every open set $G \subset X$ with $x\in G$ , there is some $V_\alpha$ such that $$x \in V_\alpha \subset G.$$ Then the collection $\left\{ V_\alpha \right\}$ is said to be a base for $X$ . Now suppose $X$ has a countable base $\left\{ V_1, V_2, V_3, \ldots \right\}$ , and let $\left\{O_\beta \right\}$ be an open cover of $X$ ; that is, let $\left\{O_\beta \right\}$ be some collection of open sets such that $$ X \subset \bigcup_{\beta} O_\beta. $$ Then how to show that some countable subcollection of $\left\{ O_\beta \right\}$ also covers $X$ ? Of course, every element $x \in X$ is in some $O_\beta$ , which in turn is a union of some subcollection of the countable collection $\left\{V_1, V_2, V_3, \ldots \right\}$ . What next? How to obtain a countable subcollection of $\{O_\beta\}$ ?","Let be a mertic space, and let be a collection of open subsets of such that, for every and for every open set with , there is some such that Then the collection is said to be a base for . Now suppose has a countable base , and let be an open cover of ; that is, let be some collection of open sets such that Then how to show that some countable subcollection of also covers ? Of course, every element is in some , which in turn is a union of some subcollection of the countable collection . What next? How to obtain a countable subcollection of ?","X \left\{ V_{\alpha} \right\} X x \in X G \subset X x\in G V_\alpha x \in V_\alpha \subset G. \left\{ V_\alpha \right\} X X \left\{ V_1, V_2, V_3, \ldots \right\} \left\{O_\beta \right\} X \left\{O_\beta \right\}  X \subset \bigcup_{\beta} O_\beta.  \left\{ O_\beta \right\} X x \in X O_\beta \left\{V_1, V_2, V_3, \ldots \right\} \{O_\beta\}","['real-analysis', 'general-topology', 'analysis', 'metric-spaces']"
18,Why is $\int |e^{ix}|^2 dx = x + C$?,Why is ?,\int |e^{ix}|^2 dx = x + C,Quick question: Wolfram Alpha tells me that $$\int |e^{ix}|^2 dx = x + C$$ Why is that?,Quick question: Wolfram Alpha tells me that $$\int |e^{ix}|^2 dx = x + C$$ Why is that?,,"['real-analysis', 'integration', 'analysis', 'complex-numbers']"
19,Precise definition of epsilon-ball,Precise definition of epsilon-ball,,"My textbook gives the following definition: ""For each $\epsilon>0$, the $\epsilon$-ball about a point $x$ in a metric space $M$ is the set $\{y\in M:d(x,y)<\epsilon\}$."" Is this correct? Because this sounds as if $\epsilon$ is just a dummy variable, and that there is such a thing as, say, a ""5-ball"" meaning $\{y\in M:d(x,y)<5\}$. Shouldn't the correct definition be something along the lines of ""The $\epsilon$-ball about a point $x$ in a metric space $M$ is the set $\{y\in M:$ for each $\epsilon >0, d(x,y)<\epsilon\}$."" ?","My textbook gives the following definition: ""For each $\epsilon>0$, the $\epsilon$-ball about a point $x$ in a metric space $M$ is the set $\{y\in M:d(x,y)<\epsilon\}$."" Is this correct? Because this sounds as if $\epsilon$ is just a dummy variable, and that there is such a thing as, say, a ""5-ball"" meaning $\{y\in M:d(x,y)<5\}$. Shouldn't the correct definition be something along the lines of ""The $\epsilon$-ball about a point $x$ in a metric space $M$ is the set $\{y\in M:$ for each $\epsilon >0, d(x,y)<\epsilon\}$."" ?",,"['general-topology', 'analysis', 'metric-spaces', 'terminology']"
20,Prove that $\int_{I}f=0 \iff$ the function $f\colon I\to \Bbb R$ is identically $0$.,Prove that  the function  is identically .,\int_{I}f=0 \iff f\colon I\to \Bbb R 0,"Let $I$ be a generalized rectangle in $\Bbb R^n$ Suppose that the function $f\colon I\to \Bbb R$ is continuous. Assume that $f(x)\ge 0$, $\forall x \in I$ Prove that $\int_{I}f=0 \iff$ the function $f\colon I\to \Bbb R$ is identically $0$. My idea is that For $(\impliedby)$ Since $f\colon I\to \Bbb R$ is identically zero, $$f(I)=0$$ Then $$\int_{I}f=\int 0=0$$ For $(\implies)$, Since $f$ is continuous, the function is integrable. i.e $\int _{I} f $ exists. I need the show that $\int f=0$ but how? Hopefully, other solution is true. Please check this. And how to continue this? Thank you:)","Let $I$ be a generalized rectangle in $\Bbb R^n$ Suppose that the function $f\colon I\to \Bbb R$ is continuous. Assume that $f(x)\ge 0$, $\forall x \in I$ Prove that $\int_{I}f=0 \iff$ the function $f\colon I\to \Bbb R$ is identically $0$. My idea is that For $(\impliedby)$ Since $f\colon I\to \Bbb R$ is identically zero, $$f(I)=0$$ Then $$\int_{I}f=\int 0=0$$ For $(\implies)$, Since $f$ is continuous, the function is integrable. i.e $\int _{I} f $ exists. I need the show that $\int f=0$ but how? Hopefully, other solution is true. Please check this. And how to continue this? Thank you:)",,"['calculus', 'real-analysis', 'analysis', 'integration']"
21,Illustration Proof that every sequence of real numbers has monotone subsequence,Illustration Proof that every sequence of real numbers has monotone subsequence,,"While proving every sequence of real numbers has a monotone subsequence, we take two cases, either there are infinitely many ""peaks"" or else ""finitely many"" peaks. However, I am unable to grasp from mere definition what ""peaks"" mean. Though I know that they are defined as $a_i$ is peak if $a_i\le a_j$ for all $i> j$. Is it related to infimum? It does not make sense to have infinitely or even finitely many ""peaks"". Further by explaining using peaks, did we not already assume the sequence as monotone  decreasing? I would appreciate if you can illustrate sequences where there are finitely many peaks and infinitely many peaks. and illustrate with them how they are monotone subsequence.","While proving every sequence of real numbers has a monotone subsequence, we take two cases, either there are infinitely many ""peaks"" or else ""finitely many"" peaks. However, I am unable to grasp from mere definition what ""peaks"" mean. Though I know that they are defined as $a_i$ is peak if $a_i\le a_j$ for all $i> j$. Is it related to infimum? It does not make sense to have infinitely or even finitely many ""peaks"". Further by explaining using peaks, did we not already assume the sequence as monotone  decreasing? I would appreciate if you can illustrate sequences where there are finitely many peaks and infinitely many peaks. and illustrate with them how they are monotone subsequence.",,"['real-analysis', 'analysis']"
22,I can't find the contradiction in this proof,I can't find the contradiction in this proof,,"The problem is ""You have a function $f:(a,b) \rightarrow \mathbb{R}$. $\exists u \in$ $\mathbb{R}$ such that $f(x) < u \forall x \in (a,b)$. Prove that if the limit of f(x) as x approaches b exists, then the limit must be $\leq$ $u$."" Proof: We proceed by contradiction. Assume that the limit exists and call it $L$. Also assume that $L > u$. Then we know that $f(x) < u < L$. Here is where I don't understand what my friend is doing: ""Since $f(x) < L,$ we can pick an $N \in \mathbb{N}$ such that $\forall  n \in \mathbb{N}$ with $n > N$, $f(n) > f(x)$, which is a contradiction."" How is that a contradiction? The definition of convergence states that a function f(x) converges to L if for all epsilon greater than zero, there is an N such that for all n > N, |f(x) - L| < e. It seems to me that this supposed contradiction could be rearranged as $f(x) - f(n) < 0$, which seems allowable. Where am I going wrong? Thanks","The problem is ""You have a function $f:(a,b) \rightarrow \mathbb{R}$. $\exists u \in$ $\mathbb{R}$ such that $f(x) < u \forall x \in (a,b)$. Prove that if the limit of f(x) as x approaches b exists, then the limit must be $\leq$ $u$."" Proof: We proceed by contradiction. Assume that the limit exists and call it $L$. Also assume that $L > u$. Then we know that $f(x) < u < L$. Here is where I don't understand what my friend is doing: ""Since $f(x) < L,$ we can pick an $N \in \mathbb{N}$ such that $\forall  n \in \mathbb{N}$ with $n > N$, $f(n) > f(x)$, which is a contradiction."" How is that a contradiction? The definition of convergence states that a function f(x) converges to L if for all epsilon greater than zero, there is an N such that for all n > N, |f(x) - L| < e. It seems to me that this supposed contradiction could be rearranged as $f(x) - f(n) < 0$, which seems allowable. Where am I going wrong? Thanks",,"['real-analysis', 'analysis', 'proof-writing']"
23,Points of a Measure Zero Sets Covered by Intervals Infinitely Many Times,Points of a Measure Zero Sets Covered by Intervals Infinitely Many Times,,"Given a measure zero set $E$, by definition we have forall $\varepsilon > 0$, a covering of $E$ by intervals whose lengths sum to $< \varepsilon$. I want to prove that we can cover $E$ in intervals such that the sum of the lengths the intervals is $< 1$ and each point in $E$ is contained in infinitely many of the intervals. Do you know how to prove this? Thank you","Given a measure zero set $E$, by definition we have forall $\varepsilon > 0$, a covering of $E$ by intervals whose lengths sum to $< \varepsilon$. I want to prove that we can cover $E$ in intervals such that the sum of the lengths the intervals is $< 1$ and each point in $E$ is contained in infinitely many of the intervals. Do you know how to prove this? Thank you",,"['analysis', 'measure-theory']"
24,Is this $\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|$ bounded?,Is this  bounded?,\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|,"Let $0.5<a<1$ and let $b=1-a$. Let $n\in \mathbb{N}$. $\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|\le C$. Is $\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|\le C$ bounded by a constant $C$ for all $n$? If so, how would I show it/explain it?","Let $0.5<a<1$ and let $b=1-a$. Let $n\in \mathbb{N}$. $\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|\le C$. Is $\left|\left(\frac{a}{b}\right)^n-\left(\frac{a}{b}\right)^{n-1}\right|\le C$ bounded by a constant $C$ for all $n$? If so, how would I show it/explain it?",,['analysis']
25,"Showing that $\cos(x)$ is a contraction mapping on $[0,\pi]$",Showing that  is a contraction mapping on,"\cos(x) [0,\pi]","How do I show that $\cos(x)$ is a contraction mapping on $[0,\pi]$? I would normally use the mean value theorem and find $\max|-\sin(x)|$ on $(0,\pi)$ but I dont think this will work here. So I think I need to look at $|\cos(x)-\cos(y)|$ but I can't see what to do to get this of the form $|\cos(x)-\cos(y)|\leq\alpha|x-y|$? Thanks for any help","How do I show that $\cos(x)$ is a contraction mapping on $[0,\pi]$? I would normally use the mean value theorem and find $\max|-\sin(x)|$ on $(0,\pi)$ but I dont think this will work here. So I think I need to look at $|\cos(x)-\cos(y)|$ but I can't see what to do to get this of the form $|\cos(x)-\cos(y)|\leq\alpha|x-y|$? Thanks for any help",,"['analysis', 'trigonometry', 'metric-spaces']"
26,Discontinuous function at an uncountable set with not rationals,Discontinuous function at an uncountable set with not rationals,,"Does there exists a function $f:[0,1]\to\mathbb{R}$ such that $D(f)$ (its points of discontinuity) is an uncountable set containing no rational number? First thing I thought of was $\mathbb{R}\setminus\mathbb{Q}$ (uncountable, with no rational), but it won't work, since it's not an $F_\sigma.$ So there is no function whose points of discontinuity is precisely $\mathbb{R}\setminus\mathbb{Q}$.","Does there exists a function $f:[0,1]\to\mathbb{R}$ such that $D(f)$ (its points of discontinuity) is an uncountable set containing no rational number? First thing I thought of was $\mathbb{R}\setminus\mathbb{Q}$ (uncountable, with no rational), but it won't work, since it's not an $F_\sigma.$ So there is no function whose points of discontinuity is precisely $\mathbb{R}\setminus\mathbb{Q}$.",,"['real-analysis', 'analysis']"
27,ratio vs. root test for $\sum_{n=1}^\infty \frac{n^n}{(n!)^2}z^n$,ratio vs. root test for,\sum_{n=1}^\infty \frac{n^n}{(n!)^2}z^n,"I am trying to calculate the radius of convergence of $\sum_{n=1}^\infty \frac{n^n}{(n!)^2}z^n$ with $z \in \mathbb{C}$. According to WolframAlpha, both the root and the ratio test are conclusive, indicating convergence. However at the root test, I am stuck at: (For convenience I drop the limes superior in the following equations, but it should be in front of every expression.) $\sqrt[n]{\frac{n^n}{(n!)^2}}=\frac{n}{\sqrt[n]{n!}\sqrt[n]{n!}}$ Is there some estimate of $\sqrt[n]{n!}$ I should know of? For the ratio test, I think I get a reasonable solution: $\frac{\frac{(n+1)^{n+1}}{(n+1)!^2}}{\frac{n^n}{n!^2}}=\frac{(n+1)^{n+1}n!^2}{(n+1)!^2n^n} = \frac{(n+1)^{n-1}}{n^n} = \frac{1}{n}(1+\frac{1}{n})^n = \frac{e}{n}$ which results in a radius of convergence of $\infty$. I should get the same result with the root test, shouldn't I? After all the root test is stronger. Hopefully someone can point out of how to continue with the root test. Thanks in advance ftiaronsem","I am trying to calculate the radius of convergence of $\sum_{n=1}^\infty \frac{n^n}{(n!)^2}z^n$ with $z \in \mathbb{C}$. According to WolframAlpha, both the root and the ratio test are conclusive, indicating convergence. However at the root test, I am stuck at: (For convenience I drop the limes superior in the following equations, but it should be in front of every expression.) $\sqrt[n]{\frac{n^n}{(n!)^2}}=\frac{n}{\sqrt[n]{n!}\sqrt[n]{n!}}$ Is there some estimate of $\sqrt[n]{n!}$ I should know of? For the ratio test, I think I get a reasonable solution: $\frac{\frac{(n+1)^{n+1}}{(n+1)!^2}}{\frac{n^n}{n!^2}}=\frac{(n+1)^{n+1}n!^2}{(n+1)!^2n^n} = \frac{(n+1)^{n-1}}{n^n} = \frac{1}{n}(1+\frac{1}{n})^n = \frac{e}{n}$ which results in a radius of convergence of $\infty$. I should get the same result with the root test, shouldn't I? After all the root test is stronger. Hopefully someone can point out of how to continue with the root test. Thanks in advance ftiaronsem",,"['analysis', 'sequences-and-series']"
28,"Showing the existence of $\int_0^1\sqrt{x}\ln (x)\, dx$ and calculating it",Showing the existence of  and calculating it,"\int_0^1\sqrt{x}\ln (x)\, dx","Show that the integral $$\int_0^1\sqrt{x}\log (x)\, dx$$ exists and calculate that. To calculate that integral I have done the following : We substitute $z=\ln (x) \Rightarrow x=e^z$ . When $x=0$ then $z=-\infty$ When $x=1$ then $z=0$ We have that $\frac{dz}{dx}=\frac{1}{x} \Rightarrow dx=xdz=e^zdz$ Then we get $$\int_0^1\sqrt{x}\ln (x)\, dx=\int_{-\infty}^0\sqrt{e^z}z\, e^zdz=\int_{-\infty}^0e^{z/3}z\, dz$$ Is that the correct way to calculate the integral? At the beginning where we have to show the existence, do we show that just by calculating the integral or is there also an other way to show the existence?","Show that the integral exists and calculate that. To calculate that integral I have done the following : We substitute . When then When then We have that Then we get Is that the correct way to calculate the integral? At the beginning where we have to show the existence, do we show that just by calculating the integral or is there also an other way to show the existence?","\int_0^1\sqrt{x}\log (x)\, dx z=\ln (x) \Rightarrow x=e^z x=0 z=-\infty x=1 z=0 \frac{dz}{dx}=\frac{1}{x} \Rightarrow dx=xdz=e^zdz \int_0^1\sqrt{x}\ln (x)\, dx=\int_{-\infty}^0\sqrt{e^z}z\, e^zdz=\int_{-\infty}^0e^{z/3}z\, dz","['calculus', 'integration', 'analysis', 'improper-integrals']"
29,A clarification regarding maximal linearly ordered subsets and the Hausdorff maximal principle,A clarification regarding maximal linearly ordered subsets and the Hausdorff maximal principle,,"I am currently beginning to read Folland after finishing chapters 1 - 6 in baby Rudin. I am a little confused about the section on partially ordered sets. Firstly, I think I know the answer to this, but if $x \leq y$ is false, then that doesn't necessarily imply $y < x$ i.e. $y < x$ isn't necessarily the negation of $x \leq y$ . Clearly, this will imply in the Real numbers, which I am used to. Also, I am a bit confused about the Hausdorff maximal principle, which is ""Every partially ordered set has a maximal linearly ordered subset"". When it's saying maximal linearly ordered subset does that mean that it has an element that is maximal to the entire set or specifically for the subset?","I am currently beginning to read Folland after finishing chapters 1 - 6 in baby Rudin. I am a little confused about the section on partially ordered sets. Firstly, I think I know the answer to this, but if is false, then that doesn't necessarily imply i.e. isn't necessarily the negation of . Clearly, this will imply in the Real numbers, which I am used to. Also, I am a bit confused about the Hausdorff maximal principle, which is ""Every partially ordered set has a maximal linearly ordered subset"". When it's saying maximal linearly ordered subset does that mean that it has an element that is maximal to the entire set or specifically for the subset?",x \leq y y < x y < x x \leq y,"['analysis', 'set-theory', 'order-theory']"
30,If every metric on a set X is equivalent to the discrete metric then can we say X is a finite set?,If every metric on a set X is equivalent to the discrete metric then can we say X is a finite set?,,I know the result and the proof of the statement that If X is a finite set then any two metrics are equivalent and every metric on X is equivalent to the discrete metric on X. But I don't know whether the above result characterize finite sets?,I know the result and the proof of the statement that If X is a finite set then any two metrics are equivalent and every metric on X is equivalent to the discrete metric on X. But I don't know whether the above result characterize finite sets?,,"['real-analysis', 'general-topology', 'analysis', 'metric-spaces']"
31,"Inverting Jacobian trick: does it always work, or did professor get lucky?","Inverting Jacobian trick: does it always work, or did professor get lucky?",,"I am tutoring a multivariable calculus student, and his teacher was solving $$\int_R f(x, y) dA$$ using the Change of Variable Theorem, where $f$ is an unimportant function and $R$ is the region bounded by $$\begin{align*} x^2-y^2 &= -1\\ x^2 - y^2 &= 1\\ x+y &= 1\\ x+y &= 3 \end{align*}$$ The he made the change of variable $$(s, t) = F(x, y) = (x+y, x^2 - y^2)$$ For change of variables, we need $\det J_{F^{-1}}(s, t)$ . However, the professor found $$\det J_F(x, y) = -2x - 2y = -2s$$ and proclaimed that $$\det J_{F^{-1}}(s, t) = -\frac {1}{2s}.$$ I think this shouldn't work, because the inverse function theorem says that in general, $$J_{F^{-1}}(s, t) = [J_F(F^{-1}(s, t))]^{-1}$$ and to me it seems like the professor did $$J_{f^{-1}}(x) = [J_f((x))]^{-1}.$$ However, I calculated $$F^{-1}(s, t) = \left(\frac 12s + \frac {t}{2s}, \frac {12}s - \frac{t}{2s} \right)$$ and used this to calculate $\det J^{-1}(s, t)$ , and I also got $-\frac {1}{2s}$ . Was the professor wrong but lucky, or am I misunderstanding something?","I am tutoring a multivariable calculus student, and his teacher was solving using the Change of Variable Theorem, where is an unimportant function and is the region bounded by The he made the change of variable For change of variables, we need . However, the professor found and proclaimed that I think this shouldn't work, because the inverse function theorem says that in general, and to me it seems like the professor did However, I calculated and used this to calculate , and I also got . Was the professor wrong but lucky, or am I misunderstanding something?","\int_R f(x, y) dA f R \begin{align*}
x^2-y^2 &= -1\\ x^2 - y^2 &= 1\\ x+y &= 1\\ x+y &= 3
\end{align*} (s, t) = F(x, y) = (x+y, x^2 - y^2) \det J_{F^{-1}}(s, t) \det J_F(x, y) = -2x - 2y = -2s \det J_{F^{-1}}(s, t) = -\frac {1}{2s}. J_{F^{-1}}(s, t) = [J_F(F^{-1}(s, t))]^{-1} J_{f^{-1}}(x) = [J_f((x))]^{-1}. F^{-1}(s, t) = \left(\frac 12s + \frac {t}{2s}, \frac {12}s - \frac{t}{2s} \right) \det J^{-1}(s, t) -\frac {1}{2s}","['real-analysis', 'analysis', 'multivariable-calculus', 'inverse-function-theorem']"
32,Integral $\int_0^\infty \frac{\sin{t}}{e^t-1}dt$?,Integral ?,\int_0^\infty \frac{\sin{t}}{e^t-1}dt,"Is it possible to compute $I=\int_0^\infty \frac{\sin{t}}{e^t-1}dt$ ? I encountered this problem while calculating sum $\sum_{n=1}^\infty \frac{1}{n^2+1}$ . This integral converges $I=\int_0^\varepsilon+\int_\varepsilon^\infty$ , first integral is finite since $\sin{t}/(e^t-1)\tilde{} 1$ and the second is finite since $\sin{t}/(e^t-1)<e^{-t}$ . Any help is welcome. Thanks in advance.","Is it possible to compute ? I encountered this problem while calculating sum . This integral converges , first integral is finite since and the second is finite since . Any help is welcome. Thanks in advance.",I=\int_0^\infty \frac{\sin{t}}{e^t-1}dt \sum_{n=1}^\infty \frac{1}{n^2+1} I=\int_0^\varepsilon+\int_\varepsilon^\infty \sin{t}/(e^t-1)\tilde{} 1 \sin{t}/(e^t-1)<e^{-t},"['integration', 'analysis', 'definite-integrals']"
33,$f\in L^1\implies \lim_{n\rightarrow\infty}f(n^2 x)=0$ a.e. $x\in\mathbb{R}$?,a.e. ?,f\in L^1\implies \lim_{n\rightarrow\infty}f(n^2 x)=0 x\in\mathbb{R},"Can someone provide a hint for the following: $f\in L^1(\mathbb{R})\implies \lim_{n\rightarrow\infty}f(n^2 x)=0$ a.e. $x\in\mathbb{R}$ I can't really make heads or tails of it. Something makes me think convergence in measure; or even a duality argument, but the quantification on $x$ for which this is satisfied is throwing me. I am not sure how it arises. This is from an old qualifying exam.","Can someone provide a hint for the following: a.e. I can't really make heads or tails of it. Something makes me think convergence in measure; or even a duality argument, but the quantification on for which this is satisfied is throwing me. I am not sure how it arises. This is from an old qualifying exam.",f\in L^1(\mathbb{R})\implies \lim_{n\rightarrow\infty}f(n^2 x)=0 x\in\mathbb{R} x,"['real-analysis', 'analysis', 'measure-theory', 'lp-spaces']"
34,Evaluate $ \sum_{k=1}^\infty ( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6})$,Evaluate, \sum_{k=1}^\infty ( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6}),"I need to evaluate the sum given by: $$\displaystyle \sum_{k=1}^\infty \left( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6} \right)$$ I know that: for $k = 1$ I get: $\frac{1}{7}+\frac{1}{9}+\frac{1}{11}-\frac{1}{8}-\frac{1}{10}-\frac{1}{12}\mathbf{-\frac{1}{14}}$ for $k = 2$ I get: $\frac{1}{13}+\frac{1}{15}+\frac{1}{17}-\frac{1}{16}-\frac{1}{18} \mathbf{-\frac{1}{20}-\frac{1}{22}}$ for $k = 3$ I get: $\frac{1}{19}+\frac{1}{21}+\frac{1}{23}-\frac{1}{24} \mathbf{-\frac{1}{26}-\frac{1}{28}-\frac{1}{30}}$ for $k = 4$ I get: $\frac{1}{25}+\frac{1}{27}+\frac{1}{29} \mathbf{ -\frac{1}{32}-\frac{1}{34}-\frac{1}{36}-\frac{1}{38}}$ I can write that sum for $k = 4$ as: $$ \frac{1}{7}-\frac{1}{8}+\frac{1}{9}-\frac{1}{10}+\frac{1}{11}-\frac{1}{12}+\frac{1}{13} -\frac{1}{14}+\frac{1}{15}-\frac{1}{16}+\frac{1}{17}-\frac{1}{18}+\frac{1}{19}-\frac{1}{20}+\frac{1}{21}-\frac{1}{22}+\frac{1}{23}-\frac{1}{24}+\frac{1}{25}-\frac{1}{26}+\frac{1}{27}-\frac{1}{28}+\frac{1}{29} -\frac{1}{30} \mathbf{ -\frac{1}{32}-\frac{1}{34}-\frac{1}{36}-\frac{1}{38}}$$ And I can write that sum for $k = 8$ as: $$ \frac{1}{7}-\frac{1}{8}+\frac{1}{9}-\frac{1}{10}+\frac{1}{11}-\frac{1}{12}+\frac{1}{13} -\frac{1}{14}+\frac{1}{15}-\frac{1}{16}+\frac{1}{17}-\frac{1}{18}+\frac{1}{19}-\frac{1}{20}+\frac{1}{21}-\frac{1}{22}+\frac{1}{23}-\frac{1}{24}+\frac{1}{25}-\frac{1}{26}+\frac{1}{27}-\frac{1}{28}+\frac{1}{29} -\frac{1}{30} + \frac{1}{31}-\frac{1}{32}+\frac{1}{33}-\frac{1}{43}+\frac{1}{35}-\frac{1}{36}+\frac{1}{37} -\frac{1}{38}+\frac{1}{39}-\frac{1}{40}+\frac{1}{41}-\frac{1}{42}+\frac{1}{43}-\frac{1}{44}+\frac{1}{45}-\frac{1}{46}+\frac{1}{47}-\frac{1}{48}+\frac{1}{49}-\frac{1}{50}+\frac{1}{51}-\frac{1}{52}+\frac{1}{53} -\frac{1}{54} \mathbf{ -\frac{1}{56}-\frac{1}{58} -\frac{1}{60}-\frac{1}{62}-\frac{1}{64}-\frac{1}{66}-\frac{1}{68} -\frac{1}{70}}$$ I see that for every k I get $1$ extra negative element at the end of the sum. I had an idea to rewrite it that way: $$\displaystyle \sum_{k=1}^\infty \left( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6} \right) = $$ $$\displaystyle \sum_{k=1}^\infty \left( (-1)^{n+1}\frac{1}{n} \right) -1+\frac{1}{2}-\frac{1}{3}+\frac{1}{4}-\frac{1}{5}+\frac{1}{6} - \displaystyle \sum_{k=1}^\infty X$$ That way I know that the first sum converges (Dirichlet), but still I don't know how to evaluate that expression. I don't know how to evaluate $\displaystyle \sum_{k=1}^\infty ( (-1)^{n+1}\frac{1}{n}$ ) and I don't know how to include those negative elements in my sum (those are marked as X).","I need to evaluate the sum given by: I know that: for I get: for I get: for I get: for I get: I can write that sum for as: And I can write that sum for as: I see that for every k I get extra negative element at the end of the sum. I had an idea to rewrite it that way: That way I know that the first sum converges (Dirichlet), but still I don't know how to evaluate that expression. I don't know how to evaluate ) and I don't know how to include those negative elements in my sum (those are marked as X).",\displaystyle \sum_{k=1}^\infty \left( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6} \right) k = 1 \frac{1}{7}+\frac{1}{9}+\frac{1}{11}-\frac{1}{8}-\frac{1}{10}-\frac{1}{12}\mathbf{-\frac{1}{14}} k = 2 \frac{1}{13}+\frac{1}{15}+\frac{1}{17}-\frac{1}{16}-\frac{1}{18} \mathbf{-\frac{1}{20}-\frac{1}{22}} k = 3 \frac{1}{19}+\frac{1}{21}+\frac{1}{23}-\frac{1}{24} \mathbf{-\frac{1}{26}-\frac{1}{28}-\frac{1}{30}} k = 4 \frac{1}{25}+\frac{1}{27}+\frac{1}{29} \mathbf{ -\frac{1}{32}-\frac{1}{34}-\frac{1}{36}-\frac{1}{38}} k = 4  \frac{1}{7}-\frac{1}{8}+\frac{1}{9}-\frac{1}{10}+\frac{1}{11}-\frac{1}{12}+\frac{1}{13} -\frac{1}{14}+\frac{1}{15}-\frac{1}{16}+\frac{1}{17}-\frac{1}{18}+\frac{1}{19}-\frac{1}{20}+\frac{1}{21}-\frac{1}{22}+\frac{1}{23}-\frac{1}{24}+\frac{1}{25}-\frac{1}{26}+\frac{1}{27}-\frac{1}{28}+\frac{1}{29} -\frac{1}{30} \mathbf{ -\frac{1}{32}-\frac{1}{34}-\frac{1}{36}-\frac{1}{38}} k = 8  \frac{1}{7}-\frac{1}{8}+\frac{1}{9}-\frac{1}{10}+\frac{1}{11}-\frac{1}{12}+\frac{1}{13} -\frac{1}{14}+\frac{1}{15}-\frac{1}{16}+\frac{1}{17}-\frac{1}{18}+\frac{1}{19}-\frac{1}{20}+\frac{1}{21}-\frac{1}{22}+\frac{1}{23}-\frac{1}{24}+\frac{1}{25}-\frac{1}{26}+\frac{1}{27}-\frac{1}{28}+\frac{1}{29} -\frac{1}{30} + \frac{1}{31}-\frac{1}{32}+\frac{1}{33}-\frac{1}{43}+\frac{1}{35}-\frac{1}{36}+\frac{1}{37} -\frac{1}{38}+\frac{1}{39}-\frac{1}{40}+\frac{1}{41}-\frac{1}{42}+\frac{1}{43}-\frac{1}{44}+\frac{1}{45}-\frac{1}{46}+\frac{1}{47}-\frac{1}{48}+\frac{1}{49}-\frac{1}{50}+\frac{1}{51}-\frac{1}{52}+\frac{1}{53} -\frac{1}{54} \mathbf{ -\frac{1}{56}-\frac{1}{58} -\frac{1}{60}-\frac{1}{62}-\frac{1}{64}-\frac{1}{66}-\frac{1}{68} -\frac{1}{70}} 1 \displaystyle \sum_{k=1}^\infty \left( \frac{1}{6k+1}+\frac{1}{6k+3}+\frac{1}{6k+5}-\frac{1}{8k}-\frac{1}{8k+2}-\frac{1}{8k+4}-\frac{1}{8k+6} \right) =  \displaystyle \sum_{k=1}^\infty \left( (-1)^{n+1}\frac{1}{n} \right) -1+\frac{1}{2}-\frac{1}{3}+\frac{1}{4}-\frac{1}{5}+\frac{1}{6} - \displaystyle \sum_{k=1}^\infty X \displaystyle \sum_{k=1}^\infty ( (-1)^{n+1}\frac{1}{n},"['real-analysis', 'analysis']"
35,elementary proof that sum of algebraic numbers is algebraic(Real Analysis and Foundations),elementary proof that sum of algebraic numbers is algebraic(Real Analysis and Foundations),,"How can one prove that the sum of two algebraic numbers is an algebraic number without using theories of algebra? I don't know about (abstract) algebra. Actually, this is an exercise of an analysis book(Real Analysis and Foundations, 4th edition, Steven G.Krantz, p67 exercise 6), so there must be a way of solving this in a relatively simple manner. (Proof Verification) Prove that the sum of two algebraic numbers is algebraic. and Elementary proof for the theorem that field of algebraic numbers is closed use theories of algebra, How to prove that the sum and product of two algebraic numbers is algebraic? uses algebra and tensor product(which I don't know). What I know is calculus, linear algebra, and a little set theory and analysis.","How can one prove that the sum of two algebraic numbers is an algebraic number without using theories of algebra? I don't know about (abstract) algebra. Actually, this is an exercise of an analysis book(Real Analysis and Foundations, 4th edition, Steven G.Krantz, p67 exercise 6), so there must be a way of solving this in a relatively simple manner. (Proof Verification) Prove that the sum of two algebraic numbers is algebraic. and Elementary proof for the theorem that field of algebraic numbers is closed use theories of algebra, How to prove that the sum and product of two algebraic numbers is algebraic? uses algebra and tensor product(which I don't know). What I know is calculus, linear algebra, and a little set theory and analysis.",,"['real-analysis', 'analysis', 'polynomials', 'roots']"
36,application of Lebesgue differentiation theorem,application of Lebesgue differentiation theorem,,"Let $f\in \mathbb{L^1{\mathbb(R)}}$ and define for a fixed $h>0$ , $f_h(x)=\frac{1}{2h}\int_{x-h}^{x+h} f(t)dt$ . Prove that $\int_\mathbb{R}{|f_h(x)|}dx\leq \int_\mathbb{R}{|f(x)|}dx$ . Hint: Prove $f_h(x)=\int_\mathbb{R}f(x-t)\psi_h (t)dt$ , where $\psi_h (t)=\frac{1}{2h}\mathbb{1}_{[-h,h]}$ . I think I will have to use Lebesgue differentiation theorem along with the dominated convergence theorem. Any help on how to proceed?","Let and define for a fixed , . Prove that . Hint: Prove , where . I think I will have to use Lebesgue differentiation theorem along with the dominated convergence theorem. Any help on how to proceed?","f\in \mathbb{L^1{\mathbb(R)}} h>0 f_h(x)=\frac{1}{2h}\int_{x-h}^{x+h} f(t)dt \int_\mathbb{R}{|f_h(x)|}dx\leq \int_\mathbb{R}{|f(x)|}dx f_h(x)=\int_\mathbb{R}f(x-t)\psi_h (t)dt \psi_h (t)=\frac{1}{2h}\mathbb{1}_{[-h,h]}","['analysis', 'measure-theory']"
37,Find $\lim_{n \rightarrow \infty} \int_{0}^{1} \frac{n^3 x^{3/4}}{ 1 + n^4 x^2}.$,Find,\lim_{n \rightarrow \infty} \int_{0}^{1} \frac{n^3 x^{3/4}}{ 1 + n^4 x^2}.,"Find $$\lim_{n \rightarrow \infty} \int_{0}^{1} \frac{n^3 x^{3/4}}{ 1 + n^4 x^2}.$$ My attempt: 1-I am thinking about using monotone convergence theorem. but I do not understand what is the meaning of uniformly in the statement of the bounded convergence theorem given below? Could anyone explains this for me, please? 2- For my check for the conditions of The bounded convergence theorem : First: I know that $\{ f_{n} = \frac{n^3 x^{3/4}}{ 1 + n^4 x^2}\}$ is measurable as it is continuous on its domain and as the domain is the set $[0,1]$ which is measurable and its measure is 1, hence this set has a finite measure. Second: and I know also that $\{f_{n}\}$ is bounded by 1 on $[0,1]$ for all $n.$ Third: I know that the pointwise limit is $o$ , then $$\lim_{n \rightarrow \infty} \int_{0}^{1} \frac{n^3 x^{3/4}}{ 1 + n^4 x^2} = \int_{[0,1]} o. $$ And now $f$ is a simple function as it is measurable and of one finite value, which is $0$ and since $m{[0,1]}=1 $ then $\int_{[0,1]} f = o.1 =0. $ Is my checking for the conditions of the theorem correct? and is my final answer correct?","Find My attempt: 1-I am thinking about using monotone convergence theorem. but I do not understand what is the meaning of uniformly in the statement of the bounded convergence theorem given below? Could anyone explains this for me, please? 2- For my check for the conditions of The bounded convergence theorem : First: I know that is measurable as it is continuous on its domain and as the domain is the set which is measurable and its measure is 1, hence this set has a finite measure. Second: and I know also that is bounded by 1 on for all Third: I know that the pointwise limit is , then And now is a simple function as it is measurable and of one finite value, which is and since then Is my checking for the conditions of the theorem correct? and is my final answer correct?","\lim_{n \rightarrow \infty} \int_{0}^{1} \frac{n^3 x^{3/4}}{ 1 + n^4 x^2}. \{ f_{n} = \frac{n^3 x^{3/4}}{ 1 + n^4 x^2}\} [0,1] \{f_{n}\} [0,1] n. o \lim_{n \rightarrow \infty} \int_{0}^{1} \frac{n^3 x^{3/4}}{ 1 + n^4 x^2} = \int_{[0,1]} o.  f 0 m{[0,1]}=1  \int_{[0,1]} f = o.1 =0. ","['real-analysis', 'analysis']"
38,Alternative proof of Abel's Theorem for Uniform convergence of series of functions,Alternative proof of Abel's Theorem for Uniform convergence of series of functions,,"The following is the Abel's Theorem. I proved it my own way. Let $g_n(x)$ be a sequence of real-valued functions such that $g_{n+1}(x)\leq g_{n}(x),\forall \,x\in T$ and $n\in\Bbb{N}.$ If $\{g_{n}\}$ is uniformly bounded on $T$, and if $\sum f_n(x)$ converges uniformly, then $\sum f_n(x)g_n(x)$ converges uniformly on $T.$ MY TRIAL Let \begin{align}F_n(x)=\sum^{n}_{i=1} f_n(x),\forall \,x\in T,\;n\in\Bbb{N}\end{align} Let $N>M,$ then  \begin{align} \left|S_N(x)-S_M(x) \right| &=\left|\sum^{N}_{n=1} f_n(x)g_n(x)-\sum^{M}_{n=1} f_n(x)g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1} f_n(x)g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1} \left[F_n(x)-F_{n-1}(x)\right]g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1}F_n(x)g_n(x)-\sum^{N}_{n=M+1}F_{n-1}(x)g_n(x)\right|\\&=\left| \left[F_{M+1}(x)-F_{M}(x)\right]g_{M+1}(x)+\sum^{N}_{n=M+2}\left[F_n(x)-F_{n-1}(x)\right]g_n(x)\right|\\&\leq \left|F_{M+1}(x)-F_{M}(x)\right| \left| g_{M+1}(x)\right|+\sum^{N}_{n=M+2}\left|F_n(x)-F_{n-1}(x)\right|\left|g_n(x)\right|\end{align} Since $g_n$ is uniformly bounded, there exists $M>0$ such that  \begin{align} \left|g_n(x)\right|\leq M_{1},\forall \,x\in T\end{align} Also, by uniform convergence of $\sum f_n(x)$, the sequence of partial sums is uniformly Cauchy. Let $\epsilon>0.$ Then, there exists $N_1=N(\epsilon)$ such that $\forall\,N>M\geq N_1,\;\forall\,x\in T$ \begin{align} \left|F_{N}(x)-F_{M}(x)\right|<\frac{\epsilon}{M_{1}+1}\end{align} Hence, $\forall\,N>M\geq N_1,\;\forall\,x\in T$ \begin{align} \left|S_N(x)-S_M(x) \right|& \leq \left|F_{M+1}(x)-F_{M}(x)\right| M_{1}+M_{1}\sum^{N}_{n=M+2}\left|F_n(x)-F_{n-1}(x)\right|\\&< \frac{M_{1}\epsilon}{M_{1}+1}+\frac{M_{1}\epsilon}{M_{1}+1}<\epsilon\end{align} And we are done! Please, can you help check if my proof is correct? Constructive criticisms are welcome! Thanks!","The following is the Abel's Theorem. I proved it my own way. Let $g_n(x)$ be a sequence of real-valued functions such that $g_{n+1}(x)\leq g_{n}(x),\forall \,x\in T$ and $n\in\Bbb{N}.$ If $\{g_{n}\}$ is uniformly bounded on $T$, and if $\sum f_n(x)$ converges uniformly, then $\sum f_n(x)g_n(x)$ converges uniformly on $T.$ MY TRIAL Let \begin{align}F_n(x)=\sum^{n}_{i=1} f_n(x),\forall \,x\in T,\;n\in\Bbb{N}\end{align} Let $N>M,$ then  \begin{align} \left|S_N(x)-S_M(x) \right| &=\left|\sum^{N}_{n=1} f_n(x)g_n(x)-\sum^{M}_{n=1} f_n(x)g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1} f_n(x)g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1} \left[F_n(x)-F_{n-1}(x)\right]g_n(x)\right|\\&=\left|\sum^{N}_{n=M+1}F_n(x)g_n(x)-\sum^{N}_{n=M+1}F_{n-1}(x)g_n(x)\right|\\&=\left| \left[F_{M+1}(x)-F_{M}(x)\right]g_{M+1}(x)+\sum^{N}_{n=M+2}\left[F_n(x)-F_{n-1}(x)\right]g_n(x)\right|\\&\leq \left|F_{M+1}(x)-F_{M}(x)\right| \left| g_{M+1}(x)\right|+\sum^{N}_{n=M+2}\left|F_n(x)-F_{n-1}(x)\right|\left|g_n(x)\right|\end{align} Since $g_n$ is uniformly bounded, there exists $M>0$ such that  \begin{align} \left|g_n(x)\right|\leq M_{1},\forall \,x\in T\end{align} Also, by uniform convergence of $\sum f_n(x)$, the sequence of partial sums is uniformly Cauchy. Let $\epsilon>0.$ Then, there exists $N_1=N(\epsilon)$ such that $\forall\,N>M\geq N_1,\;\forall\,x\in T$ \begin{align} \left|F_{N}(x)-F_{M}(x)\right|<\frac{\epsilon}{M_{1}+1}\end{align} Hence, $\forall\,N>M\geq N_1,\;\forall\,x\in T$ \begin{align} \left|S_N(x)-S_M(x) \right|& \leq \left|F_{M+1}(x)-F_{M}(x)\right| M_{1}+M_{1}\sum^{N}_{n=M+2}\left|F_n(x)-F_{n-1}(x)\right|\\&< \frac{M_{1}\epsilon}{M_{1}+1}+\frac{M_{1}\epsilon}{M_{1}+1}<\epsilon\end{align} And we are done! Please, can you help check if my proof is correct? Constructive criticisms are welcome! Thanks!",,"['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence', 'uniform-convergence']"
39,Bounding $(x^n-y^n)/(x-y)$?,Bounding ?,(x^n-y^n)/(x-y),"Let $x,y \in [0,1]$ it follows then from the binomial theorem that for integers $n \ge 1:$ $$\sup_{x,y} \left\lvert \frac{x^n-y^n}{x-y} \right\rvert \le n.$$ Is this also true if $q \in [1,\infty)$: $$\sup_{x,y} \left\lvert \frac{x^q-y^q}{x-y} \right\rvert \le q?$$","Let $x,y \in [0,1]$ it follows then from the binomial theorem that for integers $n \ge 1:$ $$\sup_{x,y} \left\lvert \frac{x^n-y^n}{x-y} \right\rvert \le n.$$ Is this also true if $q \in [1,\infty)$: $$\sup_{x,y} \left\lvert \frac{x^q-y^q}{x-y} \right\rvert \le q?$$",,"['real-analysis', 'linear-algebra']"
40,Examples of the Carathéodory extension theorem,Examples of the Carathéodory extension theorem,,What are examples of the Carathéodory Extension Theorem that is not Lebesgue measure or Hausdorff measure?,What are examples of the Carathéodory Extension Theorem that is not Lebesgue measure or Hausdorff measure?,,"['real-analysis', 'analysis', 'measure-theory']"
41,Deriving the closed form of $M_{n+1} =\frac{2^{2n+1}}{M_n}\left(\sqrt{1+ 2^{-2n}M^2_{n}}-1\right)$,Deriving the closed form of,M_{n+1} =\frac{2^{2n+1}}{M_n}\left(\sqrt{1+ 2^{-2n}M^2_{n}}-1\right),"I have the sequence, let $M_0=1$ $$M_{n+1} =\frac{2^{2n+1}}{M_n}\left(\sqrt{1+ 2^{-2n}M^2_{n}}-1\right)$$ Which I would like first to study the convergence and fine the closed form.   I failed  to show that $M_n$ is bounded and  monotone. This could be easy if have the explicit expression of it. Question: Is there a closed a form of this sequence? does anyone has an idea? FYI In the book it is mentioned that this sequence is used to approximate the area of the unit circle. may be some else has a more clever explanation to this connection","I have the sequence, let $M_0=1$ $$M_{n+1} =\frac{2^{2n+1}}{M_n}\left(\sqrt{1+ 2^{-2n}M^2_{n}}-1\right)$$ Which I would like first to study the convergence and fine the closed form.   I failed  to show that $M_n$ is bounded and  monotone. This could be easy if have the explicit expression of it. Question: Is there a closed a form of this sequence? does anyone has an idea? FYI In the book it is mentioned that this sequence is used to approximate the area of the unit circle. may be some else has a more clever explanation to this connection",,"['real-analysis', 'sequences-and-series', 'analysis', 'closed-form']"
42,Positivity result from the strong maximum principle,Positivity result from the strong maximum principle,,"In Evans PDE textbook(page 27), it said if $U$ is connected and $u \in C^2(U)\cap C(\bar U)$ satisfies:$\Delta u = 0$ in $U$ and $u=g$ on $\partial U$, where $g \geq 0$. Then, $u$ is positive everywhere in $U$ if $g$ is positive somewhere on $\partial U$. I don't see why. I know the maximum is always achived on the boundary unless it's constant within $U$, but I don't see how they are related here.","In Evans PDE textbook(page 27), it said if $U$ is connected and $u \in C^2(U)\cap C(\bar U)$ satisfies:$\Delta u = 0$ in $U$ and $u=g$ on $\partial U$, where $g \geq 0$. Then, $u$ is positive everywhere in $U$ if $g$ is positive somewhere on $\partial U$. I don't see why. I know the maximum is always achived on the boundary unless it's constant within $U$, but I don't see how they are related here.",,"['real-analysis', 'analysis', 'partial-differential-equations']"
43,The set of normal numbers is uncountable [closed],The set of normal numbers is uncountable [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I'm a grad student tutoring for undergrad math majors and one of them asked this question, I got stuck trying to solve it: Say a real number in (0,1) is normal if its ternary expansion contains every finite string made up from 0,1,2. Prove the set of normal numbers is uncountable.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question I'm a grad student tutoring for undergrad math majors and one of them asked this question, I got stuck trying to solve it: Say a real number in (0,1) is normal if its ternary expansion contains every finite string made up from 0,1,2. Prove the set of normal numbers is uncountable.",,"['real-analysis', 'general-topology', 'analysis']"
44,Fourier Series of a Constant Function,Fourier Series of a Constant Function,,"My question is kinda dumb, but here I go: I'm studying Fourier Series on my own for my next semester. I needed to calculate the Fourier Series of the function $f(x) = 5$ defined in $[-4,4]$. In this case, using the standard notation, $L = 4$ are the coefficients are $a_{0} = \dfrac{1}{L} \displaystyle \int_{-L}^{L} f(x) \ dx$; $a_{n} = \dfrac{1}{L} \displaystyle \int_{-L}^{L} f(x) \cdot \cos\bigg(\dfrac{n\pi x}{L}\bigg) \ dx$ and $b_{n} = \dfrac{1}{L} \displaystyle \int_{-L}^{L} f(x) \cdot \sin\bigg(\dfrac{n\pi x}{L}\bigg) \ dx$, correct? Since the function is constant the sines and cosines must have no contribution to the Fourier series at all, i.e., $a_{n} = b_{n} = 0$, but when I'm doing the calculations I'm getting $a_{n} = \dfrac{10}{\pi n} \sin(\pi n)$. It must be a pretty dumb mistake I'm not seeing, I'm kinda new at this subject. Thanks for the help :]","My question is kinda dumb, but here I go: I'm studying Fourier Series on my own for my next semester. I needed to calculate the Fourier Series of the function $f(x) = 5$ defined in $[-4,4]$. In this case, using the standard notation, $L = 4$ are the coefficients are $a_{0} = \dfrac{1}{L} \displaystyle \int_{-L}^{L} f(x) \ dx$; $a_{n} = \dfrac{1}{L} \displaystyle \int_{-L}^{L} f(x) \cdot \cos\bigg(\dfrac{n\pi x}{L}\bigg) \ dx$ and $b_{n} = \dfrac{1}{L} \displaystyle \int_{-L}^{L} f(x) \cdot \sin\bigg(\dfrac{n\pi x}{L}\bigg) \ dx$, correct? Since the function is constant the sines and cosines must have no contribution to the Fourier series at all, i.e., $a_{n} = b_{n} = 0$, but when I'm doing the calculations I'm getting $a_{n} = \dfrac{10}{\pi n} \sin(\pi n)$. It must be a pretty dumb mistake I'm not seeing, I'm kinda new at this subject. Thanks for the help :]",,['analysis']
45,"Theorem 6.12 (b) in Baby Rudin: If $f_1 \leq f_2$ on $[a, b]$, then $\int_a^b f_1 d\alpha \leq \int_a^b f_2 d\alpha$","Theorem 6.12 (b) in Baby Rudin: If  on , then","f_1 \leq f_2 [a, b] \int_a^b f_1 d\alpha \leq \int_a^b f_2 d\alpha","Suppose $f_1$ and $f_2$ are Riemann-integrable with respect to $\alpha$ over $[a, b]$. If $f_1(x) \leq f_2(x)$ on $[a, b]$, then    $$ \int_a^b f_1 d \alpha \leq \int_a^b f_2 d \alpha. $$ This is (essentially) Theorem 6.12 (b) in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition. Here is my proof: As $f_1 \leq f_2$ on $[a, b]$, so, for any partition $P = \left\{ \ x_0, \ldots, x_n \right\}$ of $[a, b]$, we have    $$ \inf_{x_{i-1} \leq x \leq x_i } f_1(x) \leq  \inf_{x_{i-1} \leq x \leq x_i } f_2(x), \   \mbox{ and } \ \sup_{x_{i-1} \leq x \leq x_i } f_1(x) \leq  \sup_{x_{i-1} \leq x \leq x_i } f_2(x)$$    for each $ i = 1, \ldots, n$, and therefore    $$ L \left( P, f_1, \alpha \right) \leq L \left( P, f_2, \alpha \right), \ \mbox{ and } \ U \left( P, f_1, \alpha \right) \leq U \left( P, f_2, \alpha \right) \tag{0} $$   for every partition $P$ of $[a, b]$. Now as $f_1 \in \mathscr{R}(\alpha)$ and $f_2 \in \mathscr{R}(\alpha)$, so, for $j = 1, 2$, we have $$ \sup \left\{ \ L \left( P, f_j, \alpha \right) \ \colon \ P \mbox{ is a partition of } [a, b] \ \right\} = \int_a^b f_j d \alpha = \inf \left\{ \ U \left( P, f_j, \alpha \right) \ \colon \ P \mbox{ is a partition of } [a, b] \ \right\}. $$    Therefore, for $j = 1, 2$, we have    $$ L \left( P, f_j, \alpha \right) \leq \int_a^b f_j d \alpha \leq U \left( P, f_j, \alpha \right) \tag{1}$$   for every partition $P$ of $[a, b]$; moreover, for every real number $\delta > 0$, there exist partitions $P_j$, $Q_j$ of $[a, b]$ such that    $$ \int_a^b f_j d \alpha - \delta  < L \left( P_j, f_j, \alpha \right), \mbox{ and } U \left( Q_j, f_j, \alpha \right) < \int_a^b f_j d \alpha + \delta, \tag{2} $$   and, hence if $S_j$ is any partition of $[a, b]$ such that $S_j \supset P_j$ and $S_j \supset Q_j$, then (by Theorem 6.4 in Baby Rudin, 3rd edition) we must have    $$ L \left( P_j, f_j, \alpha \right) \leq L \left( S_j, f_j, \alpha \right) \leq U \left( S_j, f_j, \alpha \right) \leq U \left( Q_j, f_j, \alpha \right). \tag{3} $$   From (2) and (3) we can conclude that, for each $j = 1, 2$, there exists a partition $S_j$ of $[a, b]$ such that    $$  \int_a^b f_j d \alpha - \delta < L \left( S_j, f_j, \alpha \right) \leq U \left( S_j, f_j, \alpha \right) <  \int_a^b f_j d \alpha + \delta. \tag{4} $$   Now let $P$ be any partition of $[a, b]$ such that $P \supset S_1$ and $P \supset S_2$. Then (again by Theorem 6.4 in Baby Rudin, 3rd edition) we have for each $j = 1, 2$, $$ L \left( S_j, f_j, \alpha \right) \leq L \left( P, f_j, \alpha \right) \leq U \left( P, f_j, \alpha \right) \leq U \left( S_j, f_j, \alpha \right). \tag{5}  $$ Thus, for every real number $\delta > 0$, we see that    $$  \begin{align} \int_a^b f_1 d\alpha &\leq U \left( P, f_1, \alpha \right) \qquad \mbox{ [ by (1) above ] } \\ &\leq U \left( P, f_2, \alpha \right) \qquad \mbox{ [ by (0) above ] } \\ & \leq U \left( S_2, f_2, \alpha \right) \qquad \mbox{ [ by (5) ] } \\ & < \int_a^b f_2 d \alpha + \delta \qquad \mbox{ [ by (4) ] },  \end{align} $$   which implies that    $$ \int_a^b f_1 d \alpha \leq \int_a^b f_2 d \alpha, $$   as required. Is this proof correct? If so, then is my presentation clear and optimal enough? If not, then where lie the pitfalls in my reasoning? Have I superfluously used any of the partitions $P_j$, $Q_j$, $S_j$ for $j = 1, 2$, or the partition $P$ at the end?","Suppose $f_1$ and $f_2$ are Riemann-integrable with respect to $\alpha$ over $[a, b]$. If $f_1(x) \leq f_2(x)$ on $[a, b]$, then    $$ \int_a^b f_1 d \alpha \leq \int_a^b f_2 d \alpha. $$ This is (essentially) Theorem 6.12 (b) in the book Principles of Mathematical Analysis by Walter Rudin, 3rd edition. Here is my proof: As $f_1 \leq f_2$ on $[a, b]$, so, for any partition $P = \left\{ \ x_0, \ldots, x_n \right\}$ of $[a, b]$, we have    $$ \inf_{x_{i-1} \leq x \leq x_i } f_1(x) \leq  \inf_{x_{i-1} \leq x \leq x_i } f_2(x), \   \mbox{ and } \ \sup_{x_{i-1} \leq x \leq x_i } f_1(x) \leq  \sup_{x_{i-1} \leq x \leq x_i } f_2(x)$$    for each $ i = 1, \ldots, n$, and therefore    $$ L \left( P, f_1, \alpha \right) \leq L \left( P, f_2, \alpha \right), \ \mbox{ and } \ U \left( P, f_1, \alpha \right) \leq U \left( P, f_2, \alpha \right) \tag{0} $$   for every partition $P$ of $[a, b]$. Now as $f_1 \in \mathscr{R}(\alpha)$ and $f_2 \in \mathscr{R}(\alpha)$, so, for $j = 1, 2$, we have $$ \sup \left\{ \ L \left( P, f_j, \alpha \right) \ \colon \ P \mbox{ is a partition of } [a, b] \ \right\} = \int_a^b f_j d \alpha = \inf \left\{ \ U \left( P, f_j, \alpha \right) \ \colon \ P \mbox{ is a partition of } [a, b] \ \right\}. $$    Therefore, for $j = 1, 2$, we have    $$ L \left( P, f_j, \alpha \right) \leq \int_a^b f_j d \alpha \leq U \left( P, f_j, \alpha \right) \tag{1}$$   for every partition $P$ of $[a, b]$; moreover, for every real number $\delta > 0$, there exist partitions $P_j$, $Q_j$ of $[a, b]$ such that    $$ \int_a^b f_j d \alpha - \delta  < L \left( P_j, f_j, \alpha \right), \mbox{ and } U \left( Q_j, f_j, \alpha \right) < \int_a^b f_j d \alpha + \delta, \tag{2} $$   and, hence if $S_j$ is any partition of $[a, b]$ such that $S_j \supset P_j$ and $S_j \supset Q_j$, then (by Theorem 6.4 in Baby Rudin, 3rd edition) we must have    $$ L \left( P_j, f_j, \alpha \right) \leq L \left( S_j, f_j, \alpha \right) \leq U \left( S_j, f_j, \alpha \right) \leq U \left( Q_j, f_j, \alpha \right). \tag{3} $$   From (2) and (3) we can conclude that, for each $j = 1, 2$, there exists a partition $S_j$ of $[a, b]$ such that    $$  \int_a^b f_j d \alpha - \delta < L \left( S_j, f_j, \alpha \right) \leq U \left( S_j, f_j, \alpha \right) <  \int_a^b f_j d \alpha + \delta. \tag{4} $$   Now let $P$ be any partition of $[a, b]$ such that $P \supset S_1$ and $P \supset S_2$. Then (again by Theorem 6.4 in Baby Rudin, 3rd edition) we have for each $j = 1, 2$, $$ L \left( S_j, f_j, \alpha \right) \leq L \left( P, f_j, \alpha \right) \leq U \left( P, f_j, \alpha \right) \leq U \left( S_j, f_j, \alpha \right). \tag{5}  $$ Thus, for every real number $\delta > 0$, we see that    $$  \begin{align} \int_a^b f_1 d\alpha &\leq U \left( P, f_1, \alpha \right) \qquad \mbox{ [ by (1) above ] } \\ &\leq U \left( P, f_2, \alpha \right) \qquad \mbox{ [ by (0) above ] } \\ & \leq U \left( S_2, f_2, \alpha \right) \qquad \mbox{ [ by (5) ] } \\ & < \int_a^b f_2 d \alpha + \delta \qquad \mbox{ [ by (4) ] },  \end{align} $$   which implies that    $$ \int_a^b f_1 d \alpha \leq \int_a^b f_2 d \alpha, $$   as required. Is this proof correct? If so, then is my presentation clear and optimal enough? If not, then where lie the pitfalls in my reasoning? Have I superfluously used any of the partitions $P_j$, $Q_j$, $S_j$ for $j = 1, 2$, or the partition $P$ at the end?",,"['real-analysis', 'integration', 'analysis', 'proof-verification', 'definite-integrals']"
46,"If $(a_n)$ is any real sequence , then $(\frac{a_n}{1+|a_n|})$ has a convergent subsequence","If  is any real sequence , then  has a convergent subsequence",(a_n) (\frac{a_n}{1+|a_n|}),"Consider the following two statements : $S_1$: If $(a_n)$ is any real sequence , then $(\frac{a_n}{1+|a_n|})$ has a convergent subsequence . $S_2$ : If every subseqeunce of $(a_n) $ has convergent subsequence , then $(a_n)$ is bounded . Which is of the follwoing statement is true ? (A) Both $S_1$ and $S_2$ are true . (B) Both $S_1$ and $S_2$ are false . (c) $S_1 $ is false but $S_2$ is true . (D) $S_2$ is false and $S_1$ is true . My work : $1+|a_n|\geq 1+a_n>a_n$ . So $|(\frac{a_n}{1+|a_n|})|\leq 1$ . So it is a bounded sequence and via Bolzano-wietrass theorem it has a convergent subsequence . $a_{2n}$ and $a_{2n-1}$ are convergent . So they are bounded . Let the bounds be $M $ and $L$ respectively . Hence $a_n \leq M+L $ .So $a_n$ is bounded . So both $S_1$ and $S_2$ are true .","Consider the following two statements : $S_1$: If $(a_n)$ is any real sequence , then $(\frac{a_n}{1+|a_n|})$ has a convergent subsequence . $S_2$ : If every subseqeunce of $(a_n) $ has convergent subsequence , then $(a_n)$ is bounded . Which is of the follwoing statement is true ? (A) Both $S_1$ and $S_2$ are true . (B) Both $S_1$ and $S_2$ are false . (c) $S_1 $ is false but $S_2$ is true . (D) $S_2$ is false and $S_1$ is true . My work : $1+|a_n|\geq 1+a_n>a_n$ . So $|(\frac{a_n}{1+|a_n|})|\leq 1$ . So it is a bounded sequence and via Bolzano-wietrass theorem it has a convergent subsequence . $a_{2n}$ and $a_{2n-1}$ are convergent . So they are bounded . Let the bounds be $M $ and $L$ respectively . Hence $a_n \leq M+L $ .So $a_n$ is bounded . So both $S_1$ and $S_2$ are true .",,"['calculus', 'real-analysis', 'sequences-and-series', 'analysis', 'proof-verification']"
47,Distance between sets with one closed set and one compact set,Distance between sets with one closed set and one compact set,,"I would like to prove the following statement. Let A and B be nonempty disjoint subsets of $\mathbb{R}$ where A is closed and B is compact. Then there exists $a \in A$ and $b \in B$ such that $inf${$|a-b|$:$a \in A, b \in B$}=$|a-b|$ A and B disjoint, A compact, and B closed implies there is positive distance between both sets I read a similar question above where the concept of ""limit point"" and others were used, but my class (Introduction to Analysis) has not gone that far; most of all, I would like to prove the statement from the knowledge that the class covered. So far, I have learned definition of limit of a sequence, Bolzano-Weierstrass Theorem. Also, I just learned (and proved) that there exists a sequence ${a_n}$ in E such that $\lim{a_n} = \inf{E}$ if E is a nonempty subset of $\mathbb{R}$ (whether E is bounded below or not due to the extended real numbers). From the things that I learned, first, I constructed a set $E$={$|a-b|$:$a\in{A}, b\in{B}$} and I know that there exists a sequence ${x_{n}}$ in E such that $\lim{x_{n}}=infE$. Since ${x_{n}} \in{E}, x_{n}=a_{n}-b_{n}$ where $a_{n} \in A, b_{n} \in B$. Let $infE = \beta$. Then, this leads to $\lim{(a_{n}-b_{n})}=\beta$. Then, for any $\epsilon$>0, there exists $N \in$ $\mathbb{N}$ such that $|a_{n}-b_{n}-\beta|<\epsilon$ for all n $\ge$ N. Then, I could not proceed. I should use conditions that A and B are disjoint, A is closed, and B is compact. Could anyone help me proceed? I had a feeling that using contradiction might work from the link above, but it is quite tough. Since I am a novice (just started taking Introduction to Analysis), I would very much appreciate it if you could help me prove this at the beginner level.","I would like to prove the following statement. Let A and B be nonempty disjoint subsets of $\mathbb{R}$ where A is closed and B is compact. Then there exists $a \in A$ and $b \in B$ such that $inf${$|a-b|$:$a \in A, b \in B$}=$|a-b|$ A and B disjoint, A compact, and B closed implies there is positive distance between both sets I read a similar question above where the concept of ""limit point"" and others were used, but my class (Introduction to Analysis) has not gone that far; most of all, I would like to prove the statement from the knowledge that the class covered. So far, I have learned definition of limit of a sequence, Bolzano-Weierstrass Theorem. Also, I just learned (and proved) that there exists a sequence ${a_n}$ in E such that $\lim{a_n} = \inf{E}$ if E is a nonempty subset of $\mathbb{R}$ (whether E is bounded below or not due to the extended real numbers). From the things that I learned, first, I constructed a set $E$={$|a-b|$:$a\in{A}, b\in{B}$} and I know that there exists a sequence ${x_{n}}$ in E such that $\lim{x_{n}}=infE$. Since ${x_{n}} \in{E}, x_{n}=a_{n}-b_{n}$ where $a_{n} \in A, b_{n} \in B$. Let $infE = \beta$. Then, this leads to $\lim{(a_{n}-b_{n})}=\beta$. Then, for any $\epsilon$>0, there exists $N \in$ $\mathbb{N}$ such that $|a_{n}-b_{n}-\beta|<\epsilon$ for all n $\ge$ N. Then, I could not proceed. I should use conditions that A and B are disjoint, A is closed, and B is compact. Could anyone help me proceed? I had a feeling that using contradiction might work from the link above, but it is quite tough. Since I am a novice (just started taking Introduction to Analysis), I would very much appreciate it if you could help me prove this at the beginner level.",,['analysis']
48,Question on $\mu$-measurable function,Question on -measurable function,\mu,"I hope you can help me with this question: Let ($\Omega,\Sigma,\mu$) be a measurable space. Let $f:\Omega\rightarrow \mathbb{R}$ be a real-function. I would like to know: If $\vert f \vert$ is $\mu$-measurable, is $f$ $\mu$-measurable too? Thanks in advance!","I hope you can help me with this question: Let ($\Omega,\Sigma,\mu$) be a measurable space. Let $f:\Omega\rightarrow \mathbb{R}$ be a real-function. I would like to know: If $\vert f \vert$ is $\mu$-measurable, is $f$ $\mu$-measurable too? Thanks in advance!",,"['analysis', 'measure-theory']"
49,"Why $I = [0,1]$ is a $1$-manifold and $I^2$ not?",Why  is a -manifold and  not?,"I = [0,1] 1 I^2","I am stuck in this, I have no idea why! $[0,1]$ is a manifold with boundary, how to justify? Which are the charts? And how about $[0,1]^2?$ Why it is not a manifold? My definition of topological manifold with or without boundary is the usual.","I am stuck in this, I have no idea why! $[0,1]$ is a manifold with boundary, how to justify? Which are the charts? And how about $[0,1]^2?$ Why it is not a manifold? My definition of topological manifold with or without boundary is the usual.",,"['real-analysis', 'general-topology', 'analysis', 'manifolds']"
50,"Integral inequality $\int_0^1 f(x)\,dx \ge 4 \int_0^{1\over2} f(x)\,dx$?",Integral inequality ?,"\int_0^1 f(x)\,dx \ge 4 \int_0^{1\over2} f(x)\,dx","If $f: [0, 1] \to \mathbb{R}$ is a convex and integrable function with $f(0) = 0$, does it necessarily follow that$$\int_0^1 f(x)\,dx \ge 4 \int_0^{1\over2} f(x)\,dx?$$","If $f: [0, 1] \to \mathbb{R}$ is a convex and integrable function with $f(0) = 0$, does it necessarily follow that$$\int_0^1 f(x)\,dx \ge 4 \int_0^{1\over2} f(x)\,dx?$$",,"['calculus', 'real-analysis', 'integration', 'analysis', 'inequality']"
51,Convergence of improper integral $\int_{0}^{\frac{\pi}{6}}\dfrac{x}{\sqrt{1-2\sin x}}dx$,Convergence of improper integral,\int_{0}^{\frac{\pi}{6}}\dfrac{x}{\sqrt{1-2\sin x}}dx,"I'm trying to determine whether the following improper integral is convergent or divergent. $$ \int_{0}^{\pi/6}\frac{x}{\sqrt{1-2\sin x}}dx $$ At first, I substituted $t=\dfrac{\pi}{2} - x $ and then I used $1-\dfrac{1}{2}x^2  \le \cos x$. But I couldn't determine. :-( $$$$ Second attempt, I used $\sin x\le x $ on $[ 0, \frac{\pi}{6} ]$. But I couldn't determine. :-[ Could you give me some advice? Thanks in advance.","I'm trying to determine whether the following improper integral is convergent or divergent. $$ \int_{0}^{\pi/6}\frac{x}{\sqrt{1-2\sin x}}dx $$ At first, I substituted $t=\dfrac{\pi}{2} - x $ and then I used $1-\dfrac{1}{2}x^2  \le \cos x$. But I couldn't determine. :-( $$$$ Second attempt, I used $\sin x\le x $ on $[ 0, \frac{\pi}{6} ]$. But I couldn't determine. :-[ Could you give me some advice? Thanks in advance.",,"['real-analysis', 'analysis', 'improper-integrals']"
52,Is supremum part of the set or it is the bigest element out of it?,Is supremum part of the set or it is the bigest element out of it?,,"""If $\sup A$ is in $A$, then is $\sup A$  called also Maximum: $\max A$."" So that means that $\sup A$ can be outside the set $A$? And lastly the upper barrier(or bound, not sure) is from $A$, right?","""If $\sup A$ is in $A$, then is $\sup A$  called also Maximum: $\max A$."" So that means that $\sup A$ can be outside the set $A$? And lastly the upper barrier(or bound, not sure) is from $A$, right?",,"['analysis', 'real-numbers', 'supremum-and-infimum']"
53,Integrate $\int_0^{\infty } \frac{\cos x}{x} dx$,Integrate,\int_0^{\infty } \frac{\cos x}{x} dx,"Although I have known that $\displaystyle\int_0^\infty {{\sin x} \over x} \, dx = {\pi  \over 2}$, I have no idea how to work out $\displaystyle\int_0^{ + \infty } {{\cos x} \over x} \, dx$. How can I?","Although I have known that $\displaystyle\int_0^\infty {{\sin x} \over x} \, dx = {\pi  \over 2}$, I have no idea how to work out $\displaystyle\int_0^{ + \infty } {{\cos x} \over x} \, dx$. How can I?",,"['calculus', 'real-analysis', 'integration', 'analysis', 'definite-integrals']"
54,"Is the set $\left\{\frac{1}{n} \mid n = 2,3,4,\ldots\right\}$ a countable infinite set?",Is the set  a countable infinite set?,"\left\{\frac{1}{n} \mid n = 2,3,4,\ldots\right\}","I'm trying to answer a homework question and I need to know if the set $E = \left\{\frac{1}{n} \mid n = 2,3,4,\ldots\right\}$ is countable or not.  So $E=\left\{\frac{1}{2}, \frac{1}{3}, \frac{1}{4},\ldots\right\}$. I think it is a countable infinite set because we have a bijection from the set $E$ to the natural numbers correct? So $E$ and $N$ have the same orders and so $E$ is countable. Is this right?","I'm trying to answer a homework question and I need to know if the set $E = \left\{\frac{1}{n} \mid n = 2,3,4,\ldots\right\}$ is countable or not.  So $E=\left\{\frac{1}{2}, \frac{1}{3}, \frac{1}{4},\ldots\right\}$. I think it is a countable infinite set because we have a bijection from the set $E$ to the natural numbers correct? So $E$ and $N$ have the same orders and so $E$ is countable. Is this right?",,['analysis']
55,"If $a$ is a limit point of $f^{-1}(b)$, then the linear mapping $f'(a)$ is not injective.","If  is a limit point of , then the linear mapping  is not injective.",a f^{-1}(b) f'(a),"Let $U\subset\mathbb{R}^m$ be an open set and $f:U\to\mathbb{R}^n$ a differentiable function. Suppose that there exists $b\in\mathbb{R}^n$ and $a\in U$ such that $a$ is an accumulation point of $f^{-1}(b)=\{x\in U;\;f(x)=b\}$. The problem is to show that $f'(a):\mathbb{R}^m\to\mathbb{R}^n$ is not injective. Since $a$ is an accumulation point of $f^{-1}(b)$, there exists a sequence $(x_k)$ in $f^{-1}(b)$ such that $x_k\neq a$ for all $k\in\mathbb{N}$ and $\lim x_k=a$. By continuity of $f$, it follows that $f(a)=\lim f(x_k)=b$. We know that, if $t_k\to 0$ in $\mathbb{R}$ and $v_k\to v$ in $\mathbb{R}^m$, then $$f'(a)\cdot v=\lim \frac{f(a+t_kv_k)-f(a)}{t_k}=\lim_{t\to 0}\frac{f(a+tv)-f(a)}{t}=\frac{\partial f}{\partial v}(a).$$ If $m=n=1$ we can take $t_k=x_k-a$, $v_k=1$ and conclude that $$f'(a)\cdot 1=\lim \frac{f(a+t_k)-f(a)}{t_k}=\lim \frac{f(x_k)-f(a)}{x_k-a}=\lim\frac{0}{x_k-a}=0.$$ So, $f'(a)$ is not injective because $1\in \operatorname{Ker} f'(a)$. How can we deal with the general case? Thanks.","Let $U\subset\mathbb{R}^m$ be an open set and $f:U\to\mathbb{R}^n$ a differentiable function. Suppose that there exists $b\in\mathbb{R}^n$ and $a\in U$ such that $a$ is an accumulation point of $f^{-1}(b)=\{x\in U;\;f(x)=b\}$. The problem is to show that $f'(a):\mathbb{R}^m\to\mathbb{R}^n$ is not injective. Since $a$ is an accumulation point of $f^{-1}(b)$, there exists a sequence $(x_k)$ in $f^{-1}(b)$ such that $x_k\neq a$ for all $k\in\mathbb{N}$ and $\lim x_k=a$. By continuity of $f$, it follows that $f(a)=\lim f(x_k)=b$. We know that, if $t_k\to 0$ in $\mathbb{R}$ and $v_k\to v$ in $\mathbb{R}^m$, then $$f'(a)\cdot v=\lim \frac{f(a+t_kv_k)-f(a)}{t_k}=\lim_{t\to 0}\frac{f(a+tv)-f(a)}{t}=\frac{\partial f}{\partial v}(a).$$ If $m=n=1$ we can take $t_k=x_k-a$, $v_k=1$ and conclude that $$f'(a)\cdot 1=\lim \frac{f(a+t_k)-f(a)}{t_k}=\lim \frac{f(x_k)-f(a)}{x_k-a}=\lim\frac{0}{x_k-a}=0.$$ So, $f'(a)$ is not injective because $1\in \operatorname{Ker} f'(a)$. How can we deal with the general case? Thanks.",,"['real-analysis', 'general-topology', 'analysis', 'multivariable-calculus']"
56,"For $b \gt 2$ , verify that $\sum_{n=1}^{\infty}\frac{n!}{b(b+1)...(b+n-1)}=\frac{1}{b-2}$.","For  , verify that .",b \gt 2 \sum_{n=1}^{\infty}\frac{n!}{b(b+1)...(b+n-1)}=\frac{1}{b-2},"For $b \gt 2$ , verify that $$\sum_{n=1}^{\infty}\frac{n!}{b(b+1)...(b+n-1)}=\frac{1}{b-2}$$ This is how I tried.. $$\sum_{n=1}^{\infty}\frac{n!(b-2)}{(b-2)b(b+1)...(b+n-1)}=\sum_{n=1}^{\infty}\frac{n!(b+n-1-2+1-n)}{(b-2)b(b+1)...(b+n-1)}=\sum_{n=1}^{\infty}\frac{n!(b+n-1)-(1+n)}{(b-2)b(b+1)...(b+n-1)}=\sum_{n=1}^{\infty}\frac{n!(b+n-1)}{(b-2)b(b+1)...(b+n-1)}-\frac{n!(1+n)}{(b-2)b(b+1)...(b+n-1)}=\frac{1}{b-2}\left(\frac{b-2}{b}+\sum_{n=2}^{\infty}\frac{n!}{b(b+1)...(b+n-2)}-\frac{(n+1)!}{b(b+1)....(b+n-1)}\right)$$ Now $$S_n=\frac{1}{b-2}\left[\frac{b-2}{b}+\left(\frac{2}{b}-\frac{3!}{b(b+1)}\right)+\left(\frac{3!}{b(b+1)}-\frac{4!}{b(b+1)(b+2)}\right)+...+\left(\frac{n!}{b(b+1)..(b+n-2)}-\frac{(n+1)!}{b(b+1)...(b+n-1)}\right)\right]=\frac{1}{b-2}\left[1-\frac{(n+1)!}{b(b+1)..(b+n-1)}\right]$$ All I need to show is that $$\lim\limits_{n\to \infty}\frac{(n+1)!}{b(b+1)..(b+n-1)}=0$$ which I am unable to show. Thanks for the help!!","For $b \gt 2$ , verify that $$\sum_{n=1}^{\infty}\frac{n!}{b(b+1)...(b+n-1)}=\frac{1}{b-2}$$ This is how I tried.. $$\sum_{n=1}^{\infty}\frac{n!(b-2)}{(b-2)b(b+1)...(b+n-1)}=\sum_{n=1}^{\infty}\frac{n!(b+n-1-2+1-n)}{(b-2)b(b+1)...(b+n-1)}=\sum_{n=1}^{\infty}\frac{n!(b+n-1)-(1+n)}{(b-2)b(b+1)...(b+n-1)}=\sum_{n=1}^{\infty}\frac{n!(b+n-1)}{(b-2)b(b+1)...(b+n-1)}-\frac{n!(1+n)}{(b-2)b(b+1)...(b+n-1)}=\frac{1}{b-2}\left(\frac{b-2}{b}+\sum_{n=2}^{\infty}\frac{n!}{b(b+1)...(b+n-2)}-\frac{(n+1)!}{b(b+1)....(b+n-1)}\right)$$ Now $$S_n=\frac{1}{b-2}\left[\frac{b-2}{b}+\left(\frac{2}{b}-\frac{3!}{b(b+1)}\right)+\left(\frac{3!}{b(b+1)}-\frac{4!}{b(b+1)(b+2)}\right)+...+\left(\frac{n!}{b(b+1)..(b+n-2)}-\frac{(n+1)!}{b(b+1)...(b+n-1)}\right)\right]=\frac{1}{b-2}\left[1-\frac{(n+1)!}{b(b+1)..(b+n-1)}\right]$$ All I need to show is that $$\lim\limits_{n\to \infty}\frac{(n+1)!}{b(b+1)..(b+n-1)}=0$$ which I am unable to show. Thanks for the help!!",,"['real-analysis', 'sequences-and-series', 'analysis']"
57,Question concerning L'Hospital's rule,Question concerning L'Hospital's rule,,"I know that L'Hospital's rule is applied when $\lim \frac{f'(x)}{g'(x)}$ must exist. Then, is there an example that $\lim \frac{f'(x)}{g'(x)}$ does not exist but other conditions of L'Hospital's rule hold ? i.e. for example) Are there functions $f$ and $g$ such that $\lim f(x) = \lim g(x) = + \infty$ and $f$, $g$ are differentiable but $\lim \frac{f'(x)}{g'(x)}$ does not exist? I don't speak english very well. I'm Sorry if you don't understand.","I know that L'Hospital's rule is applied when $\lim \frac{f'(x)}{g'(x)}$ must exist. Then, is there an example that $\lim \frac{f'(x)}{g'(x)}$ does not exist but other conditions of L'Hospital's rule hold ? i.e. for example) Are there functions $f$ and $g$ such that $\lim f(x) = \lim g(x) = + \infty$ and $f$, $g$ are differentiable but $\lim \frac{f'(x)}{g'(x)}$ does not exist? I don't speak english very well. I'm Sorry if you don't understand.",,['analysis']
58,Stuck with a tricky existence proof,Stuck with a tricky existence proof,,"Show that there exists a continuous function $f: [-1, 1] \rightarrow \mathbb{R}$ such $f(0) = 1$ and $f(x) = \frac{2-x^2}{2} \cdot f(\frac{x^2}{2-x^2})$ $\forall x \in [-1, 1]$ I tried putting in $x = 1$ and $x = -1$ in the second condition to find that $f(1) = f(-1) = 0$.  I also took the derivative of the second equation to find that: $f'(x) = x (f'(\frac{x^2}{2-x^2})\frac{2}{2-x^2}-f(\frac{x^2}{2-x^2}))$ This gives me $f'(0) = f'(1) = f'(-1) = 0$ but now I'm stuck. Anybody see a way?","Show that there exists a continuous function $f: [-1, 1] \rightarrow \mathbb{R}$ such $f(0) = 1$ and $f(x) = \frac{2-x^2}{2} \cdot f(\frac{x^2}{2-x^2})$ $\forall x \in [-1, 1]$ I tried putting in $x = 1$ and $x = -1$ in the second condition to find that $f(1) = f(-1) = 0$.  I also took the derivative of the second equation to find that: $f'(x) = x (f'(\frac{x^2}{2-x^2})\frac{2}{2-x^2}-f(\frac{x^2}{2-x^2}))$ This gives me $f'(0) = f'(1) = f'(-1) = 0$ but now I'm stuck. Anybody see a way?",,"['calculus', 'real-analysis', 'analysis', 'proof-writing']"
59,Some questions about Weierstrass approximation theorem,Some questions about Weierstrass approximation theorem,,"Im reading chapter11 of Carothers' Real Analysis, 1ed talking about Weierstrass Approximation Theorem. Here is an introduction, How to explain the ""how"" there? Since q is the polynomial approximating f with rational coefficients, that is to say there exist two approximation methods(precisely, one is p containing at leat one irrational coefficient and the other is q) or in other words, Weierstrass approximation theorem guarantee the existence of polynomial but not its coefficients being rational?","Im reading chapter11 of Carothers' Real Analysis, 1ed talking about Weierstrass Approximation Theorem. Here is an introduction, How to explain the ""how"" there? Since q is the polynomial approximating f with rational coefficients, that is to say there exist two approximation methods(precisely, one is p containing at leat one irrational coefficient and the other is q) or in other words, Weierstrass approximation theorem guarantee the existence of polynomial but not its coefficients being rational?",,"['real-analysis', 'analysis']"
60,Is there any non-translation invariant but homogeneous metric linear space?,Is there any non-translation invariant but homogeneous metric linear space?,,"A metric linear space is a metric space and vector space, and linear operation is continuous regarding to the metric. I know that a homogeneous, translation invariant metric $d$ can be used to define a norm, and vice versa. So there must exist a non-translation invariant but homogeneous metric linear space. However, I have tried my best to think about it, but gained nothing. Please help me. The related interpretation can be found here .","A metric linear space is a metric space and vector space, and linear operation is continuous regarding to the metric. I know that a homogeneous, translation invariant metric $d$ can be used to define a norm, and vice versa. So there must exist a non-translation invariant but homogeneous metric linear space. However, I have tried my best to think about it, but gained nothing. Please help me. The related interpretation can be found here .",,"['analysis', 'vector-spaces', 'metric-spaces']"
61,Prove: The infinite series $x_n$ converges if and only if the infinite series $2^nx_{2^n}$ converges.,Prove: The infinite series  converges if and only if the infinite series  converges.,x_n 2^nx_{2^n},I am in desperate need for hints to get me in the right direction for this proof. Let $(x_n)_{n\in \mathbb {N}}$ be a monotone decreasing null sequence. Prove that: $$\sum_{n=1}^\infty x_n \text{ converges } \ \iff \sum_{n=0}^\infty 2^nx_{2^n} \text{  converges}$$ Thanks.,I am in desperate need for hints to get me in the right direction for this proof. Let be a monotone decreasing null sequence. Prove that: Thanks.,(x_n)_{n\in \mathbb {N}} \sum_{n=1}^\infty x_n \text{ converges } \ \iff \sum_{n=0}^\infty 2^nx_{2^n} \text{  converges},"['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence']"
62,A closed ball in $l^{\infty}$ is not compact,A closed ball in  is not compact,l^{\infty},"Definition of compact in Real Analysis, Carothers, 1ed said that: In Example 8.1 (c), he claimed that closed ball $\{x: \|x\| \leq 1\}$ in $l^{\infty}$ is not compact. Why?","Definition of compact in Real Analysis, Carothers, 1ed said that: In Example 8.1 (c), he claimed that closed ball $\{x: \|x\| \leq 1\}$ in $l^{\infty}$ is not compact. Why?",,"['real-analysis', 'analysis']"
63,"Use mathematical induction to prove that for any $k \in\mathbb N , \lim (1+k/n)^n = e^k$.",Use mathematical induction to prove that for any .,"k \in\mathbb N , \lim (1+k/n)^n = e^k","Use mathematical induction to prove that for any $k \in \mathbb N, \lim (1+k/n)^n = e^k$. I already used monotone Convergence Theorem to prove $k=1$ case. Do I just need to go through the same process to show $k$? If not, could you please help? Thanks","Use mathematical induction to prove that for any $k \in \mathbb N, \lim (1+k/n)^n = e^k$. I already used monotone Convergence Theorem to prove $k=1$ case. Do I just need to go through the same process to show $k$? If not, could you please help? Thanks",,"['real-analysis', 'sequences-and-series', 'analysis']"
64,proof by induction : $n^n \ge 2^{n-1} n!$,proof by induction :,n^n \ge 2^{n-1} n!,"I am trying to show that  $$\begin{matrix} n^n \ge 2^{n-1} n! & \text{(1)} \end{matrix}$$ I tried to solve it for n=n+1 $$(n+1)^{n+1}=(n+1)^n(n+1) \ge n^n(n+1) \ge 2^{n-1}n!(n+1)= 2^{n-1}(n+1)!$$ So I ended up having $2^{n-1}$, but I wanted $2^n$. How can I prove $\text{(1)}$?","I am trying to show that  $$\begin{matrix} n^n \ge 2^{n-1} n! & \text{(1)} \end{matrix}$$ I tried to solve it for n=n+1 $$(n+1)^{n+1}=(n+1)^n(n+1) \ge n^n(n+1) \ge 2^{n-1}n!(n+1)= 2^{n-1}(n+1)!$$ So I ended up having $2^{n-1}$, but I wanted $2^n$. How can I prove $\text{(1)}$?",,"['analysis', 'induction']"
65,Continuity on a neighbourhood of a point,Continuity on a neighbourhood of a point,,"If a function $f$ is continuous at $x$, then there exists a neighbourhood of $x$, on which $f$ is continuous. Is it true of false?","If a function $f$ is continuous at $x$, then there exists a neighbourhood of $x$, on which $f$ is continuous. Is it true of false?",,"['general-topology', 'analysis', 'continuity']"
66,Open sets in $\Bbb{R}^2$ and $\Bbb{R}^3$,Open sets in  and,\Bbb{R}^2 \Bbb{R}^3,"In $\Bbb{R}^2$ and $\Bbb{R}^3$ are all open sets in the form of an open ball of some positive radius? In other words, do open sets look like anything else except balls/spheres? I know any union of open sets is again open, but that doesn't really help me picture the possibility of anything else, just a union of open balls.","In $\Bbb{R}^2$ and $\Bbb{R}^3$ are all open sets in the form of an open ball of some positive radius? In other words, do open sets look like anything else except balls/spheres? I know any union of open sets is again open, but that doesn't really help me picture the possibility of anything else, just a union of open balls.",,['analysis']
67,If the derivative approaches zero then the limit exists,If the derivative approaches zero then the limit exists,,"I have a homework question, looks simple but I can't figure out a way to solve it. Any clue or help will be helpful. Let $f: [0,\infty)\rightarrow\mathbb R$ be a differentiable function such that $\lim_{x\rightarrow\infty}f'(x)=0$. Prove or disprove: $\lim_{x\rightarrow\infty}f(x)$ exists ( infinite limit is also considered as a limit ). Thanks a lot!","I have a homework question, looks simple but I can't figure out a way to solve it. Any clue or help will be helpful. Let $f: [0,\infty)\rightarrow\mathbb R$ be a differentiable function such that $\lim_{x\rightarrow\infty}f'(x)=0$. Prove or disprove: $\lim_{x\rightarrow\infty}f(x)$ exists ( infinite limit is also considered as a limit ). Thanks a lot!",,"['calculus', 'real-analysis', 'analysis']"
68,Cantor set on the circle,Cantor set on the circle,,Draw a Cantor set C on the circle and consider the set A of all the chords between points of C. Prove that A is compact.,Draw a Cantor set C on the circle and consider the set A of all the chords between points of C. Prove that A is compact.,,"['general-topology', 'analysis']"
69,Cauchy but not fast cauchy,Cauchy but not fast cauchy,,"As the title indicates, I am trying to find a Cauchy sequence that is not fast (or rapidly) Cauchy. Could anyone suggest something? A sequence $\{a_n\}_{n \in \Bbb N}$is termed fast (or rapidly) Cauchy if there is a convergent series or positive numbers $\sum_{k \in \Bbb N} \epsilon_k^2$ for which $$\|a_k - a_{k+1}\| \le \epsilon_k^2 \ \forall k $$","As the title indicates, I am trying to find a Cauchy sequence that is not fast (or rapidly) Cauchy. Could anyone suggest something? A sequence $\{a_n\}_{n \in \Bbb N}$is termed fast (or rapidly) Cauchy if there is a convergent series or positive numbers $\sum_{k \in \Bbb N} \epsilon_k^2$ for which $$\|a_k - a_{k+1}\| \le \epsilon_k^2 \ \forall k $$",,"['calculus', 'real-analysis']"
70,How does an Indefinite Integral = Definite Integral with Variable as Upper Limit?,How does an Indefinite Integral = Definite Integral with Variable as Upper Limit?,,"Source: P36 of Elementary Differential Equations, 9th Ed by Boyce, DiPrima et al. $${\int{f(t)\text{ }dt} = \int_{t_0}^t f(s) \text{ } ds \quad \text{ where $t_0$ is some convenient lower limit of integration.}}  \tag{$*$}$$ $\Large{\text{1.}}$ I now know:  $ \int{f(t)\text{ }dt} \qquad$ is $\color{green}{\text{  a set of functions $\qquad$ (**)}} $ and  $  \int_{t_0}^t f(s) \text{ } ds \qquad$ is $\color{#B53389}{\text{ an element of set (**) above.}} \quad $ So how and why is $(*)$ true? How can a $\color{green}{\text{  a set of functions}}$ = $\color{#B53389}{\text{ an element of the same set}}  $  ? Supplementary to William Stagner's answer and Peter Tamaroff's comment Thanks to your explanations, I now know that:  $\int{f(t)}\text{ }dt = g(t) + C \qquad \forall \ C \in \mathbb{R}\ \tag{$\natural$}$ $\int_{t_0}^t f(s) \text{ } ds = g(t) - g(t_0) \tag{$\blacklozenge$}$ Since $g(t)$ is one function and $t_0$ is one arbitrarily chosen argument/number, thus $-g\left(t_0\right)$ is ONE FIXED number. In contrast, $C$ is ANY real number. $\Large{\text{3.}}$ So $(\natural) \mathop{=}^{?} \, (\blacklozenge) \iff C \mathop{=}^{?} -g(t_0).$ But how and why is : $ C \mathop{=}^{?} -g\left(t_0\right) \; $?","Source: P36 of Elementary Differential Equations, 9th Ed by Boyce, DiPrima et al. $${\int{f(t)\text{ }dt} = \int_{t_0}^t f(s) \text{ } ds \quad \text{ where $t_0$ is some convenient lower limit of integration.}}  \tag{$*$}$$ $\Large{\text{1.}}$ I now know:  $ \int{f(t)\text{ }dt} \qquad$ is $\color{green}{\text{  a set of functions $\qquad$ (**)}} $ and  $  \int_{t_0}^t f(s) \text{ } ds \qquad$ is $\color{#B53389}{\text{ an element of set (**) above.}} \quad $ So how and why is $(*)$ true? How can a $\color{green}{\text{  a set of functions}}$ = $\color{#B53389}{\text{ an element of the same set}}  $  ? Supplementary to William Stagner's answer and Peter Tamaroff's comment Thanks to your explanations, I now know that:  $\int{f(t)}\text{ }dt = g(t) + C \qquad \forall \ C \in \mathbb{R}\ \tag{$\natural$}$ $\int_{t_0}^t f(s) \text{ } ds = g(t) - g(t_0) \tag{$\blacklozenge$}$ Since $g(t)$ is one function and $t_0$ is one arbitrarily chosen argument/number, thus $-g\left(t_0\right)$ is ONE FIXED number. In contrast, $C$ is ANY real number. $\Large{\text{3.}}$ So $(\natural) \mathop{=}^{?} \, (\blacklozenge) \iff C \mathop{=}^{?} -g(t_0).$ But how and why is : $ C \mathop{=}^{?} -g\left(t_0\right) \; $?",,['calculus']
71,Convergence of $ u_{n}=\sqrt [n]{\frac{(a+1)(a+2)...(a+n)}{n!}} $,Convergence of, u_{n}=\sqrt [n]{\frac{(a+1)(a+2)...(a+n)}{n!}} ,I would like study the convergence of the following sequence: $$ u_{n}=\sqrt [n]{\frac{(a+1)(a+2)...(a+n)}{n!}} $$ where $a>0$ We have: $$ \ln(u_{n})=\frac{1}{n}\sum_{k=1}^n \ln(1+\frac{a}{k})$$ And : $$ \ln(u_{n+1})-\ln(u_{n})=\frac{1}{n+1}\sum_{k=1}^{n+1} \ln(1+\frac{a}{k})-\frac{1}{n}\sum_{k=1}^n \ln(1+\frac{a}{k})$$ So I have to study the convergence of $$ \sum \ln(u_{n+1})-\ln(u_{n})$$ Using integrals:  $$ \sum_{k=1}^n \ln(1+\frac{a}{k}) \sim a\ln(n)$$ Thus: $$ \ln(u_{n+1})-\ln(u_{n})= \frac{1}{n}a\ln(n)-\frac{1}{n}a\ln(n)+o(\frac{\ln(n)}{n})=o(\frac{\ln(n)}{n}) $$ which is not enough to determine the convergence or divergence of $ \sum \ln(u_{n+1})-\ln(u_{n})$ So how can I find a more precise approximation of $ \ln(u_{n+1})-\ln(u_{n})$? Or is there a simple equivalent of $$ \prod_{k=1}^n {(a+k)}$$ ?,I would like study the convergence of the following sequence: $$ u_{n}=\sqrt [n]{\frac{(a+1)(a+2)...(a+n)}{n!}} $$ where $a>0$ We have: $$ \ln(u_{n})=\frac{1}{n}\sum_{k=1}^n \ln(1+\frac{a}{k})$$ And : $$ \ln(u_{n+1})-\ln(u_{n})=\frac{1}{n+1}\sum_{k=1}^{n+1} \ln(1+\frac{a}{k})-\frac{1}{n}\sum_{k=1}^n \ln(1+\frac{a}{k})$$ So I have to study the convergence of $$ \sum \ln(u_{n+1})-\ln(u_{n})$$ Using integrals:  $$ \sum_{k=1}^n \ln(1+\frac{a}{k}) \sim a\ln(n)$$ Thus: $$ \ln(u_{n+1})-\ln(u_{n})= \frac{1}{n}a\ln(n)-\frac{1}{n}a\ln(n)+o(\frac{\ln(n)}{n})=o(\frac{\ln(n)}{n}) $$ which is not enough to determine the convergence or divergence of $ \sum \ln(u_{n+1})-\ln(u_{n})$ So how can I find a more precise approximation of $ \ln(u_{n+1})-\ln(u_{n})$? Or is there a simple equivalent of $$ \prod_{k=1}^n {(a+k)}$$ ?,,"['sequences-and-series', 'analysis']"
72,"A converse of sorts to the intermediate value theorem, with an additional property","A converse of sorts to the intermediate value theorem, with an additional property",,"I need to solve the following problem: Suppose $f$ has the intermediate value property, i.e. if $f(a)<c<f(b)$, then there exists a value $d$ between $a$ and $b$ for which $f(d)=c$, and also has the additional property that $f^{-1}(a)$ is closed for every $a$ in a dense subset of $\mathbb{R}$, then $f$ is continuous. I can see plenty of counterexamples when the second property is not added, but I can't seem to bridge the gap between adding the property and proving $f$ is continuous. I can't get there either directly or by contradiction, because the additional property doesn't seem directly relevant to the property of continuity, so could anyone please tell me how to go about doing this? Thanks!","I need to solve the following problem: Suppose $f$ has the intermediate value property, i.e. if $f(a)<c<f(b)$, then there exists a value $d$ between $a$ and $b$ for which $f(d)=c$, and also has the additional property that $f^{-1}(a)$ is closed for every $a$ in a dense subset of $\mathbb{R}$, then $f$ is continuous. I can see plenty of counterexamples when the second property is not added, but I can't seem to bridge the gap between adding the property and proving $f$ is continuous. I can't get there either directly or by contradiction, because the additional property doesn't seem directly relevant to the property of continuity, so could anyone please tell me how to go about doing this? Thanks!",,['real-analysis']
73,Why can we not write the reals as a countable union of sets,Why can we not write the reals as a countable union of sets,,"I understand that the reals are not countable, what goes wrong with this? $$\mathbb{R} = \bigcup_{n=1}^\infty (-n,n) $$","I understand that the reals are not countable, what goes wrong with this?","\mathbb{R} = \bigcup_{n=1}^\infty (-n,n) ","['real-analysis', 'analysis', 'elementary-set-theory', 'real-numbers']"
74,Does this sum converge? Does it converge absolutely? $\sum_{n=1}^{\infty} \frac{(-1)^n}{n-\sqrt{n-1}}$,Does this sum converge? Does it converge absolutely?,\sum_{n=1}^{\infty} \frac{(-1)^n}{n-\sqrt{n-1}},"Does this sum converge? Does it converge absolutely? $$\sum_{n=1}^{\infty} \frac{(-1)^n}{n-\sqrt{n-1}}$$ I first checked absolute convergence. Taking the absolute value of the term, we get $\frac{1}{n-\sqrt{n-1}}$ We know $n-\sqrt{n-1} < n \implies \frac{1}{n - \sqrt{n-1}} > \frac{1}{n}$ We know the harmonic series diverges, so our series will also diverge. So it does not converge absolutely. But for the convergence, I’m stuck. Computing $\lim_{n \to \infty} {a_{n+1}\over a_n}$ gives $1$ , so the the series can either converge or diverge, so it doesn’t seem to help. What else should I do?","Does this sum converge? Does it converge absolutely? I first checked absolute convergence. Taking the absolute value of the term, we get We know We know the harmonic series diverges, so our series will also diverge. So it does not converge absolutely. But for the convergence, I’m stuck. Computing gives , so the the series can either converge or diverge, so it doesn’t seem to help. What else should I do?",\sum_{n=1}^{\infty} \frac{(-1)^n}{n-\sqrt{n-1}} \frac{1}{n-\sqrt{n-1}} n-\sqrt{n-1} < n \implies \frac{1}{n - \sqrt{n-1}} > \frac{1}{n} \lim_{n \to \infty} {a_{n+1}\over a_n} 1,"['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence', 'summation']"
75,"Is $\mathbb{R}\cup\{-\infty,+\infty\}$ the categorical co-completion of $\mathbb{Q}$",Is  the categorical co-completion of,"\mathbb{R}\cup\{-\infty,+\infty\} \mathbb{Q}","Seeing $\mathbb{Q}$ as an ordered set, the colimit of a diagram $D:\mathcal{I} \to \mathbb{Q}$ , when it exists, is just $\operatorname{colim}D \cong \operatorname{sup}_iD(i)$ . It seems to me that given any diagram $D:\mathbb{Q} \to \mathcal{E}$ into a cocomplete category $\mathcal{E}$ , it extends to a functor $L:\mathbb{R}\cup\{-\infty,+\infty\} \to \mathcal{E}$ given by $L(r)=\operatorname{colim}\{D(q):q \leq r, q\in \mathbb{Q}\}\in \mathcal{E}$ . This establishes $\mathbb{R}\cup\{-\infty,+\infty\}$ as the free co-completion of $\mathbb{Q}$ . Moreover, we obtain the density result asserting that every real number is the sup of all smaller rational numbers as a corollary of the fact that every presheaf is a colimit of representables. Proof: $L$ is a functor preserving colimits and extending $D$ by construction. Given another $L'$ with these properties, since every $r$ is the colimit (= sup) of all its smaller rational numbers, it must be $L \cong L'$ . Am I stating something wrong here? I just thought about it, and it seems a nice and elementary example, but I have not seen it stated anywhere, which is very strange, and makes me suspect I am missing something and there's something wrong?","Seeing as an ordered set, the colimit of a diagram , when it exists, is just . It seems to me that given any diagram into a cocomplete category , it extends to a functor given by . This establishes as the free co-completion of . Moreover, we obtain the density result asserting that every real number is the sup of all smaller rational numbers as a corollary of the fact that every presheaf is a colimit of representables. Proof: is a functor preserving colimits and extending by construction. Given another with these properties, since every is the colimit (= sup) of all its smaller rational numbers, it must be . Am I stating something wrong here? I just thought about it, and it seems a nice and elementary example, but I have not seen it stated anywhere, which is very strange, and makes me suspect I am missing something and there's something wrong?","\mathbb{Q} D:\mathcal{I} \to \mathbb{Q} \operatorname{colim}D \cong \operatorname{sup}_iD(i) D:\mathbb{Q} \to \mathcal{E} \mathcal{E} L:\mathbb{R}\cup\{-\infty,+\infty\} \to \mathcal{E} L(r)=\operatorname{colim}\{D(q):q \leq r, q\in \mathbb{Q}\}\in \mathcal{E} \mathbb{R}\cup\{-\infty,+\infty\} \mathbb{Q} L D L' r L \cong L'","['real-analysis', 'analysis', 'category-theory', 'real-numbers', 'limits-colimits']"
76,Computing an integral on the unit sphere,Computing an integral on the unit sphere,,"I am having trouble, trying to compute the integral \begin{align*} I(a)= \int_{\mathbb{S}^{d-1}} (1-\cos(a w_1)) \, d \sigma_{d-1}(w)\qquad a>1  \end{align*} where $w= (w_1,\cdots, w_d)$ and $\mathbb{S}^{d-1}=\{w\in \mathbb{R}^{d}\,:\, w_1^2+\cdots+w_d^2=1\}$ . 1- Can the explicit value of $I(a)$ be computed? 2- How can prove that there is $c>0$ such that $I(a)\geq c$ for all $a>1$ ? PS: The second question is a conjecture.","I am having trouble, trying to compute the integral where and . 1- Can the explicit value of be computed? 2- How can prove that there is such that for all ? PS: The second question is a conjecture.","\begin{align*}
I(a)= \int_{\mathbb{S}^{d-1}} (1-\cos(a w_1)) \, d \sigma_{d-1}(w)\qquad a>1 
\end{align*} w= (w_1,\cdots, w_d) \mathbb{S}^{d-1}=\{w\in \mathbb{R}^{d}\,:\, w_1^2+\cdots+w_d^2=1\} I(a) c>0 I(a)\geq c a>1","['real-analysis', 'integration', 'analysis']"
77,"Question about the proof in ""Understanding Analysis"" by Stephen Abbot","Question about the proof in ""Understanding Analysis"" by Stephen Abbot",,"My question is rather simple and involves a step that is taken when proving that there is a number squared that equals two. He uses the least upper bound theorem. The first few steps make sense, but how he gets between these two highlighted steps confuses me. I do not know how he derives that second inequality that I have highlighted. Thank you in advance for your help.","My question is rather simple and involves a step that is taken when proving that there is a number squared that equals two. He uses the least upper bound theorem. The first few steps make sense, but how he gets between these two highlighted steps confuses me. I do not know how he derives that second inequality that I have highlighted. Thank you in advance for your help.",,"['real-analysis', 'analysis']"
78,"If $f:\mathbb{R} \to \mathbb{C}$ is a Borel function such that $|f|=1,$ then there exist $\alpha<\beta$ such that $\int_{\alpha}^{\beta}f(x)dx \neq 0$",If  is a Borel function such that  then there exist  such that,"f:\mathbb{R} \to \mathbb{C} |f|=1, \alpha<\beta \int_{\alpha}^{\beta}f(x)dx \neq 0",Let $f:\mathbb{R} \to \mathbb{C}$ be a Borel function such that $|f|=1.$ Is it true that there exist $\alpha<\beta$ such that $\int_{\alpha}^{\beta}f(x)dx \neq 0$ ? Of course if $f$ was continuous then this follows immediately since there exists $\delta>0$ such that $$\left|\left|\int_{0}^\delta f(x)dx\right|-\delta\right| \leq \int_0^{\delta}|f(x)-1|dx \leq \frac{1}{2}\delta$$ so that $\int_0^{\delta}f(x)dx \neq 0.$,Let be a Borel function such that Is it true that there exist such that ? Of course if was continuous then this follows immediately since there exists such that so that,f:\mathbb{R} \to \mathbb{C} |f|=1. \alpha<\beta \int_{\alpha}^{\beta}f(x)dx \neq 0 f \delta>0 \left|\left|\int_{0}^\delta f(x)dx\right|-\delta\right| \leq \int_0^{\delta}|f(x)-1|dx \leq \frac{1}{2}\delta \int_0^{\delta}f(x)dx \neq 0.,"['real-analysis', 'integration', 'analysis', 'measure-theory', 'lebesgue-integral']"
79,"$f(x)>0, f''(x)>0$. Prove: $\int_a^b f(x) dx > (b-a) f(\frac{a+b}{2})$",. Prove:,"f(x)>0, f''(x)>0 \int_a^b f(x) dx > (b-a) f(\frac{a+b}{2})","On $[a,b]$ function $f$ is differentiable for arbitrary order, and $f(x)>0, f''(x)>0$ . Prove: $\int_a^b f(x) dx > (b-a) f(\frac{a+b}{2})$ . I first try Taylor expansion at $x_0=\frac{a+b}{2}$ , and drop higher order term ( $(x-x_0)^3$ terms). But this works only locally at the neighborhood of $x_0$ . How to prove this inequality on a finite interval? Thank you.","On function is differentiable for arbitrary order, and . Prove: . I first try Taylor expansion at , and drop higher order term ( terms). But this works only locally at the neighborhood of . How to prove this inequality on a finite interval? Thank you.","[a,b] f f(x)>0, f''(x)>0 \int_a^b f(x) dx > (b-a) f(\frac{a+b}{2}) x_0=\frac{a+b}{2} (x-x_0)^3 x_0",['analysis']
80,Can we always pick an integer power of $e^{i \theta}$ such that its difference with $1$ has rational argument?,Can we always pick an integer power of  such that its difference with  has rational argument?,e^{i \theta} 1,"Let $z = e^{i\theta}, \theta \in \mathbb{R}$ . Then, does there exist $n \in \mathbb{N}$ such that: $$1 - z^n  = re^{2 \pi i \tau}$$ for some $\tau \in \mathbb{Q}$ ? Naturally, this exists if $\theta$ is a rational multiple of $\pi$ . However, does this hold for any $\theta$ ? Although this question appears quite simple, I have no idea how I would approach it, and I suspect that its proof or disproof would be very difficult. Link to motivation (it may appear entirely unrelated (it almost is); I wish to show that $\mathbb{C}$ has a certain property that I defined on fields with the addition of some analysis.)","Let . Then, does there exist such that: for some ? Naturally, this exists if is a rational multiple of . However, does this hold for any ? Although this question appears quite simple, I have no idea how I would approach it, and I suspect that its proof or disproof would be very difficult. Link to motivation (it may appear entirely unrelated (it almost is); I wish to show that has a certain property that I defined on fields with the addition of some analysis.)","z = e^{i\theta}, \theta \in \mathbb{R} n \in \mathbb{N} 1 - z^n  = re^{2 \pi i \tau} \tau \in \mathbb{Q} \theta \pi \theta \mathbb{C}","['analysis', 'complex-numbers', 'rational-numbers']"
81,Function equal to its own arclength.,Function equal to its own arclength.,,"Does there exist a differentiable function $f(x)$ such that $$f(x) = \int_0^x \sqrt{1+[f'(t)]^2}dt?$$ I'm quite interested in finding if there is such a function, as its value at any point $t$ would be the length of the curve from $x=0$ to $x=t$ and I think such a function must necessarily be beautiful in some way. Any help is appreciated!","Does there exist a differentiable function such that I'm quite interested in finding if there is such a function, as its value at any point would be the length of the curve from to and I think such a function must necessarily be beautiful in some way. Any help is appreciated!",f(x) f(x) = \int_0^x \sqrt{1+[f'(t)]^2}dt? t x=0 x=t,"['calculus', 'analysis', 'arc-length']"
82,"Evaluate the integral $\int_0^{\pi/2}\frac{\tan x}{\tan(\frac{x}{2})} \, dx$",Evaluate the integral,"\int_0^{\pi/2}\frac{\tan x}{\tan(\frac{x}{2})} \, dx","Evaluate the integral. $$\int_0^{\frac{\pi}{2}}\frac{\tan{x}}{\tan(\frac{x}{2})}\,dx$$ I tried to solve it with $u = \tan{x/2}$ , but i got divergent part of the solution. How can I integrate it, such that, when boundaries are plugged in, the result will be able to be calculated.","Evaluate the integral. I tried to solve it with , but i got divergent part of the solution. How can I integrate it, such that, when boundaries are plugged in, the result will be able to be calculated.","\int_0^{\frac{\pi}{2}}\frac{\tan{x}}{\tan(\frac{x}{2})}\,dx u = \tan{x/2}","['real-analysis', 'integration', 'analysis', 'definite-integrals', 'indefinite-integrals']"
83,Induction Inequality Proof,Induction Inequality Proof,,"Given a sequence $(a_{n})$ where $a_{0}=1, a_{n+1} = \sqrt{a_{n}+2}$ I'm trying to show using induction that $1 \leq a_{n} \leq 2$ , for all $n$ . (I've shown the limit is actually $2$ ). I've never actually done an inequality induction before, but an attempt is below: Base case: For $a_{0}$ we clearly have $1\leq a_{0} \leq 2$ Inductive step: Assume the result holds for $n=k$ i.e. $1\leq a_{k} \leq 2$ Then I need to show that $1 \leq a_{k+1} \leq 2$ . Because this is a sequence I'm not sure if I can say $a_{k+1} = a_{k}+a_{1}$ (I'm assuming not). I think the recursion is confusing me for some reason. Any hints on how to proceed would be helpful. Thanks.","Given a sequence where I'm trying to show using induction that , for all . (I've shown the limit is actually ). I've never actually done an inequality induction before, but an attempt is below: Base case: For we clearly have Inductive step: Assume the result holds for i.e. Then I need to show that . Because this is a sequence I'm not sure if I can say (I'm assuming not). I think the recursion is confusing me for some reason. Any hints on how to proceed would be helpful. Thanks.","(a_{n}) a_{0}=1, a_{n+1} = \sqrt{a_{n}+2} 1 \leq a_{n} \leq 2 n 2 a_{0} 1\leq a_{0} \leq 2 n=k 1\leq a_{k} \leq 2 1 \leq a_{k+1} \leq 2 a_{k+1} = a_{k}+a_{1}","['real-analysis', 'calculus', 'sequences-and-series', 'analysis', 'inequality']"
84,Find integral area with respect to x,Find integral area with respect to x,,"The question is finding the area enclosed by the curves x= $y^2$ and x+2y=8 using both x and y integrals Graph for reference Purple is x+2y=8, red is x= $y^2$ First I found the limits by letting x=8-2y. This gave the equation $y^2$ +2y-8 which gave y=-4 and y=2. Putting back into equation gives x=4 and x=16 I calculated with y integral being $$\int_4^2 (8-2y)-y^2 \,$$ ( lower integral is -4, I can't seem to express) Now I would like to ask how would you calculate using the x integral I had a think about this and got but the answers x and y integrals are different so I think theres a mistake somewhere but I don't know what I did wrong.","The question is finding the area enclosed by the curves x= and x+2y=8 using both x and y integrals Graph for reference Purple is x+2y=8, red is x= First I found the limits by letting x=8-2y. This gave the equation +2y-8 which gave y=-4 and y=2. Putting back into equation gives x=4 and x=16 I calculated with y integral being ( lower integral is -4, I can't seem to express) Now I would like to ask how would you calculate using the x integral I had a think about this and got but the answers x and y integrals are different so I think theres a mistake somewhere but I don't know what I did wrong.","y^2 y^2 y^2 \int_4^2 (8-2y)-y^2 \,","['integration', 'analysis', 'definite-integrals', 'area']"
85,Value of $\prod_{n>1} \frac{1}{1-\frac{1}{n^s}}$ or $-\sum_{n=2}^{\infty} \log(1-\frac{1}{n^s} )$,Value of  or,\prod_{n>1} \frac{1}{1-\frac{1}{n^s}} -\sum_{n=2}^{\infty} \log(1-\frac{1}{n^s} ),"I know \begin{align} \prod_{p~is~ prime} \frac{1}{1-\frac{1}{p^2}} = \zeta(2) = \frac{\pi^2}{6} \end{align} which has a convergent number. actually I can even generalized this to \begin{align} \prod_{p ~is~ prime} \frac{1}{1-\frac{1}{p^s}} = \zeta(s)   \end{align} For $s>1$ [consider $s\in \mathbb{R}$ ] we know zeta function converges, so this   has a convergent number. How about generalization to arbitrary integers? [i.e., I want to replace $p$ with arbitrary integer $n$ .] For example $s=2$ , we have \begin{align}  \prod_{n>1} \frac{1}{1-\frac{1}{n^2}} \end{align} taking log we need to show \begin{align} - \sum_{n=2} \log\left(1-\frac{1}{n^2} \right)  \end{align} is convergent or not. simply by telescope method I can see this value converges to $\log(2)$ , that means $ \prod_{n>1} \frac{1}{1-\frac{1}{n^2}} = 2$ . Now consider $s>1$ . \begin{align} -\sum_{n>1} \log\left(1-\frac{1}{n^s}\right) \end{align} This is convergent from comparison test. Simply take $a_n = -\log(1-\frac{1}{n^s})$ and $b_n = \frac{1}{n^s}$ , then \begin{align} \lim_{n\rightarrow \infty} \frac{a_n}{b_n} = \lim_{x\rightarrow 0} \frac{-\log(1-x)}{x} = 1 >0 \end{align} and since $\sum_{n=1}^{\infty} b_n = \zeta(s)$ is convergent for $s>1$ , $\sum_{n=2}^{\infty} a_n$ also converges. What I want to obtain is the value of such convergent series, first i tried telescope method, but it seems difficult even for $s=3$ . Is there a way to compute exact value of those products? How and what is the values of those products?","I know which has a convergent number. actually I can even generalized this to For [consider ] we know zeta function converges, so this   has a convergent number. How about generalization to arbitrary integers? [i.e., I want to replace with arbitrary integer .] For example , we have taking log we need to show is convergent or not. simply by telescope method I can see this value converges to , that means . Now consider . This is convergent from comparison test. Simply take and , then and since is convergent for , also converges. What I want to obtain is the value of such convergent series, first i tried telescope method, but it seems difficult even for . Is there a way to compute exact value of those products? How and what is the values of those products?","\begin{align}
\prod_{p~is~ prime} \frac{1}{1-\frac{1}{p^2}} = \zeta(2) = \frac{\pi^2}{6}
\end{align} \begin{align}
\prod_{p ~is~ prime} \frac{1}{1-\frac{1}{p^s}} = \zeta(s)  
\end{align} s>1 s\in \mathbb{R} p n s=2 \begin{align}
 \prod_{n>1} \frac{1}{1-\frac{1}{n^2}}
\end{align} \begin{align}
- \sum_{n=2} \log\left(1-\frac{1}{n^2} \right) 
\end{align} \log(2)  \prod_{n>1} \frac{1}{1-\frac{1}{n^2}} = 2 s>1 \begin{align}
-\sum_{n>1} \log\left(1-\frac{1}{n^s}\right)
\end{align} a_n = -\log(1-\frac{1}{n^s}) b_n = \frac{1}{n^s} \begin{align}
\lim_{n\rightarrow \infty} \frac{a_n}{b_n} = \lim_{x\rightarrow 0} \frac{-\log(1-x)}{x} = 1 >0
\end{align} \sum_{n=1}^{\infty} b_n = \zeta(s) s>1 \sum_{n=2}^{\infty} a_n s=3","['calculus', 'analysis', 'convergence-divergence', 'products', 'zeta-functions']"
86,"Let $f: U\subseteq \mathbb{R}^n \to \mathbb{R}^m$ be $C^1$ s.t. $n \leq m$, $U$ open, $\mathrm{rank}{D_pf}=n$. Prove $f$ is locally injective at $p$.","Let  be  s.t. ,  open, . Prove  is locally injective at .",f: U\subseteq \mathbb{R}^n \to \mathbb{R}^m C^1 n \leq m U \mathrm{rank}{D_pf}=n f p,"I was trying to solve a problem in differential geometry that I realized the following statement is the core of my argument Let $f: U\subseteq \mathbb{R}^n \to \mathbb{R}^m$ be a $C^1$ function on an open set $U$ where $n \leqslant m$ such that $\mathrm{rank}{Df}=n$ at some $p\in U$ . Show that $f$ is injective in a neighborhood of $p$ . After thinking about it, I think that it can be proven using the constant rank theorem. Firstly, since $f$ is $C^1$ , we have $\mathrm{rank}Df\geq n$ in a neighborhood of $p$ . Since $n$ is the maximum possible rank, we have $\mathrm{rank}Df = n$ near $p$ . So, the constant rank theorem applies. Now the constant rank theorem says that I can find two open sets $V \subseteq U$ and $W\subseteq \mathbb{R}^m$ such that $f(V) \subseteq W$ and two diffeomorphisms $\psi:\mathbb{R}^n \to V$ and $\varphi:\mathbb{R}^m \to W$ such that $\varphi^{-1}\circ f\circ \psi: \mathbb{R}^n \to \mathbb{R}^m$ has the canonical form $(x_1,\cdots,x_n) \mapsto (x_1,\cdots,x_n,0,\cdots,0)$ . Since $\varphi^{-1}\circ f\circ \psi$ is clearly injective, and $\varphi$ and $\psi$ are diffeomorphisms, $f = \varphi \circ \big(\varphi^{-1}\circ f\circ \psi \big) \circ \psi^{-1}$ is injective on $V$ . Assuming my proof is correct (well, is it?) I still think it's overkill. Is there a proof that is more elementary? Ideally, a proof without using the Inverse Function Theorem. Or if it uses the Inverse Function Theorem, it should not be longer than this one since the constant rank theorem can be proven using the Inverse Function Theorem and hence, it's obvious that a longer proof exists.","I was trying to solve a problem in differential geometry that I realized the following statement is the core of my argument Let be a function on an open set where such that at some . Show that is injective in a neighborhood of . After thinking about it, I think that it can be proven using the constant rank theorem. Firstly, since is , we have in a neighborhood of . Since is the maximum possible rank, we have near . So, the constant rank theorem applies. Now the constant rank theorem says that I can find two open sets and such that and two diffeomorphisms and such that has the canonical form . Since is clearly injective, and and are diffeomorphisms, is injective on . Assuming my proof is correct (well, is it?) I still think it's overkill. Is there a proof that is more elementary? Ideally, a proof without using the Inverse Function Theorem. Or if it uses the Inverse Function Theorem, it should not be longer than this one since the constant rank theorem can be proven using the Inverse Function Theorem and hence, it's obvious that a longer proof exists.","f: U\subseteq \mathbb{R}^n \to \mathbb{R}^m C^1 U n \leqslant m \mathrm{rank}{Df}=n p\in U f p f C^1 \mathrm{rank}Df\geq n p n \mathrm{rank}Df = n p V \subseteq U W\subseteq \mathbb{R}^m f(V) \subseteq W \psi:\mathbb{R}^n \to V \varphi:\mathbb{R}^m \to W \varphi^{-1}\circ f\circ \psi: \mathbb{R}^n \to \mathbb{R}^m (x_1,\cdots,x_n) \mapsto (x_1,\cdots,x_n,0,\cdots,0) \varphi^{-1}\circ f\circ \psi \varphi \psi f = \varphi \circ \big(\varphi^{-1}\circ f\circ \psi \big) \circ \psi^{-1} V","['real-analysis', 'analysis', 'multivariable-calculus', 'differential-geometry', 'manifolds']"
87,Picking the correct Ansatz for valid solutions in Asymptotic Methods,Picking the correct Ansatz for valid solutions in Asymptotic Methods,,"I am trying to find the solution to the following equation, $\epsilon x^3 -x^2 +x-\epsilon^{\frac{1}{2}}=0$ , for the first two non-zero solutions as $\epsilon \to 0^+$ . I have used the principal of dominant balance (by a Kruskal Newton Graph) to find that my ansatz should be of the form $x(\epsilon)=\dfrac{z(\epsilon)}{\epsilon^\alpha}$ where $\alpha=0,\dfrac{1}{2},1$ . Now if we substitute these into our equation we get, for each $\alpha$ : $\alpha=0 : \ \epsilon x^3 -x^2 +x-\epsilon^{\frac{1}{2}}=0 $ - noting $x=z$ ; $\alpha=\dfrac{1}{2}: z\epsilon^{\frac{1}{2}}-z^2+z\epsilon^\frac{1}{2}-\epsilon^\frac{3}{2}$ ; $\alpha=1: \ z^3-z^2+z\epsilon-\epsilon^\frac{1}{2}$ . Now it is clear that if we perturb our equations in the form $z(\epsilon)=z_0+\epsilon z_1 +...$ then we have, for $\alpha=0 \ \& \ 1$ , an $\epsilon^\frac{1}{2}$ term which can only be equated to zero. Does this mean that we do not have a valid solution for these choices of $\alpha$ ? Whereas, if we consider $\alpha=\dfrac{1}{2}$ then we have an equation of the form: $(z_0+\epsilon z_1)^3\epsilon^\frac{1}{2} -(z_0+\epsilon z_1)^2 +(z_0+\epsilon z_1)\epsilon^\frac{1}{2}-\epsilon^\frac{3}{2}=0$ whose coefficients can all be equated, thus valid solutions. As a result is the only case where we can find solutions at $\alpha=\dfrac{1}{2}$ ?","I am trying to find the solution to the following equation, , for the first two non-zero solutions as . I have used the principal of dominant balance (by a Kruskal Newton Graph) to find that my ansatz should be of the form where . Now if we substitute these into our equation we get, for each : - noting ; ; . Now it is clear that if we perturb our equations in the form then we have, for , an term which can only be equated to zero. Does this mean that we do not have a valid solution for these choices of ? Whereas, if we consider then we have an equation of the form: whose coefficients can all be equated, thus valid solutions. As a result is the only case where we can find solutions at ?","\epsilon x^3 -x^2 +x-\epsilon^{\frac{1}{2}}=0 \epsilon \to 0^+ x(\epsilon)=\dfrac{z(\epsilon)}{\epsilon^\alpha} \alpha=0,\dfrac{1}{2},1 \alpha \alpha=0 : \ \epsilon x^3 -x^2 +x-\epsilon^{\frac{1}{2}}=0  x=z \alpha=\dfrac{1}{2}: z\epsilon^{\frac{1}{2}}-z^2+z\epsilon^\frac{1}{2}-\epsilon^\frac{3}{2} \alpha=1: \ z^3-z^2+z\epsilon-\epsilon^\frac{1}{2} z(\epsilon)=z_0+\epsilon z_1 +... \alpha=0 \ \& \ 1 \epsilon^\frac{1}{2} \alpha \alpha=\dfrac{1}{2} (z_0+\epsilon z_1)^3\epsilon^\frac{1}{2} -(z_0+\epsilon z_1)^2 +(z_0+\epsilon z_1)\epsilon^\frac{1}{2}-\epsilon^\frac{3}{2}=0 \alpha=\dfrac{1}{2}","['analysis', 'numerical-methods', 'asymptotics', 'approximation', 'perturbation-theory']"
88,"Proving that a sequence $a_n: n\in\mathbb{N}$ is (not) monotonic, bounded and converging","Proving that a sequence  is (not) monotonic, bounded and converging",a_n: n\in\mathbb{N},"$$a_n = \left(\dfrac{n^2+3}{(n+1)^2}\right)\text{ with } \forall n\in \mathbb{N}$$ $(0\in\mathbb{N})$ Monotonicity: To prove, that a sequence is monotonic, I can use the following inequalities: \begin{align} a_n \leq a_{n+1}; a_n < a_{n+1}\\ a_n \geq a_{n+1}; a_n > a_{n+1} \end{align} I inserted some $n$ 's to get an idea on how the sequence is going to look like. I got: \begin{align} a_0&=3\\ a_1&=1\\ a_2&=\frac{7}{9}\approx 0.\overline{7}\\ a_3&=\frac{3}{4}=0.75 \end{align} Assumption: The sequence is monotonic for $\forall n\in \mathbb{N}$ Therefore, I show that \begin{align} a_n \leq a_{n+1}; a_n < a_{n+1}\\ a_n \geq a_{n+1}; a_n > a_{n+1} \end{align} I am having problems when trying to prove the inequalities above: \begin{align} & a_n \geq a_{n+1}\Longleftrightarrow \left|\frac{a_{n+1}}{a_n}\right |\leq 1\\ & = \left|\dfrac{\dfrac{(n+1)^2+3}{(n+2)^2}}{\dfrac{n^2+3}{(n+1)^2}}\right|\\ & = \frac{4 + 10 n + 9 n^2 + 4 n^3 + n^4}{12 + 12 n + 7 n^2 + 4 n^3 + n^4}\\ & = \cdots \text{ not sure what steps I could do now} \end{align} Boundedness: The upper bound with $a_n<s_o;\; s_o \in \mathbb{N}$ is obviously the first number of $\mathbb{N}$ : \begin{align} a_0=s_o&=\frac{0^2+3}{(0+1)^2}\\ &=3 \end{align} The lower bound $a_n>s_u;\; s_u \in \mathbb{N}$ $s_u$ should be $1$ , because ${n^2+3}$ will expand similar to ${n^2+2n+1}$ when approaching infinity. I don't know how to prove that formally. Convergence Assumption (s.a) $\lim_{ n \to \infty} a_n =1$ Let $\varepsilon$ contain some value, so that $\forall \varepsilon > 0\, \exists N\in\mathbb{N}\, \forall n\ge N: |a_n-a| < \varepsilon$ : \begin{align} \mid a_n -a\mid&=\left|\frac{n^2+3}{(n+1)^2}-1\right|\\ &= \left|\frac{n^2+3}{(n+1)^2}-\left(\frac{n+1}{n+1}\right)^2\right|\\ &= \left|\frac{n^2+3-(n+1)^2}{(n+1)^2}\right|\\ &= \left|\frac{n^2+3-(n^2+2n+1)}{(n+1)^2}\right|\\ &= \left|\frac{2-2n}{(n+1)^2}\right|\\ &= \cdots \text{(how to go on?)} \end{align}","Monotonicity: To prove, that a sequence is monotonic, I can use the following inequalities: I inserted some 's to get an idea on how the sequence is going to look like. I got: Assumption: The sequence is monotonic for Therefore, I show that I am having problems when trying to prove the inequalities above: Boundedness: The upper bound with is obviously the first number of : The lower bound should be , because will expand similar to when approaching infinity. I don't know how to prove that formally. Convergence Assumption (s.a) Let contain some value, so that :","a_n = \left(\dfrac{n^2+3}{(n+1)^2}\right)\text{ with } \forall n\in \mathbb{N} (0\in\mathbb{N}) \begin{align}
a_n \leq a_{n+1}; a_n < a_{n+1}\\
a_n \geq a_{n+1}; a_n > a_{n+1}
\end{align} n \begin{align}
a_0&=3\\
a_1&=1\\
a_2&=\frac{7}{9}\approx 0.\overline{7}\\
a_3&=\frac{3}{4}=0.75
\end{align} \forall n\in \mathbb{N} \begin{align}
a_n \leq a_{n+1}; a_n < a_{n+1}\\
a_n \geq a_{n+1}; a_n > a_{n+1}
\end{align} \begin{align}
& a_n \geq a_{n+1}\Longleftrightarrow \left|\frac{a_{n+1}}{a_n}\right |\leq 1\\
& = \left|\dfrac{\dfrac{(n+1)^2+3}{(n+2)^2}}{\dfrac{n^2+3}{(n+1)^2}}\right|\\
& = \frac{4 + 10 n + 9 n^2 + 4 n^3 + n^4}{12 + 12 n + 7 n^2 + 4 n^3 + n^4}\\
& = \cdots \text{ not sure what steps I could do now}
\end{align} a_n<s_o;\; s_o \in \mathbb{N} \mathbb{N} \begin{align}
a_0=s_o&=\frac{0^2+3}{(0+1)^2}\\
&=3
\end{align} a_n>s_u;\; s_u \in \mathbb{N} s_u 1 {n^2+3} {n^2+2n+1} \lim_{ n \to \infty} a_n =1 \varepsilon \forall \varepsilon > 0\, \exists N\in\mathbb{N}\, \forall n\ge N: |a_n-a| < \varepsilon \begin{align}
\mid a_n -a\mid&=\left|\frac{n^2+3}{(n+1)^2}-1\right|\\
&= \left|\frac{n^2+3}{(n+1)^2}-\left(\frac{n+1}{n+1}\right)^2\right|\\
&= \left|\frac{n^2+3-(n+1)^2}{(n+1)^2}\right|\\
&= \left|\frac{n^2+3-(n^2+2n+1)}{(n+1)^2}\right|\\
&= \left|\frac{2-2n}{(n+1)^2}\right|\\
&= \cdots \text{(how to go on?)}
\end{align}","['real-analysis', 'sequences-and-series', 'analysis', 'convergence-divergence', 'upper-lower-bounds']"
89,If $abcd=1$ then $a^4b+b^4c+c^4d+d^4a\geq a+b+c+d$,If  then,abcd=1 a^4b+b^4c+c^4d+d^4a\geq a+b+c+d,"I want to prove that for all $a>0$, $b>0$, $c>0$ and $d>0$ with $abcd=1$:  $$a^4b+b^4c+c^4d+d^4a\geq a+b+c+d.$$ I think that this should be provable by AM-GM inequality, but I could not manage to prove it. Can you give me a hint? Best wishes","I want to prove that for all $a>0$, $b>0$, $c>0$ and $d>0$ with $abcd=1$:  $$a^4b+b^4c+c^4d+d^4a\geq a+b+c+d.$$ I think that this should be provable by AM-GM inequality, but I could not manage to prove it. Can you give me a hint? Best wishes",,"['analysis', 'inequality', 'radicals', 'a.m.-g.m.-inequality', 'cauchy-schwarz-inequality']"
90,Root of the quintic $x^5 − 5x^4 + 30x^3 − 50x^2 + 55x − 21=0$,Root of the quintic,x^5 − 5x^4 + 30x^3 − 50x^2 + 55x − 21=0,"What is real root of the quintic $x^5 − 5x^4 + 30x^3 − 50x^2 + 55x − 21=0$? Some remarks: I saw this quintic in wikipedia Real root is given $x=1+{\sqrt[ {5}]{2}}-\left({\sqrt[ {5}]{2}}\right)^{2}+\left({\sqrt[ {5}]{2}}\right)^{3}-\left({\sqrt[ {5}]{2}}\right)^{4}$ in wikipedia. I used the transformation $x=y+1$ (Tschirnhaus transformation) and $y^5 + 20 y^3 + 20 y^2 + 30 y + 10=0$. (We can remove the term of degree four.) Therefore, we have to solve $x^5 + 20 x^3 + 20 x^2 + 30 x + 10=0$ and we have to find $x={\sqrt[ {5}]{2}}-\left({\sqrt[ {5}]{2}}\right)^{2}+\left({\sqrt[ {5}]{2}}\right)^{3}-\left({\sqrt[ {5}]{2}}\right)^{4}$. But, I want to know how to solve this without plugging it in and verifying an already known root. Can the depressed quintic be solved? Or does one need to use another method to solve this polynomial?","What is real root of the quintic $x^5 − 5x^4 + 30x^3 − 50x^2 + 55x − 21=0$? Some remarks: I saw this quintic in wikipedia Real root is given $x=1+{\sqrt[ {5}]{2}}-\left({\sqrt[ {5}]{2}}\right)^{2}+\left({\sqrt[ {5}]{2}}\right)^{3}-\left({\sqrt[ {5}]{2}}\right)^{4}$ in wikipedia. I used the transformation $x=y+1$ (Tschirnhaus transformation) and $y^5 + 20 y^3 + 20 y^2 + 30 y + 10=0$. (We can remove the term of degree four.) Therefore, we have to solve $x^5 + 20 x^3 + 20 x^2 + 30 x + 10=0$ and we have to find $x={\sqrt[ {5}]{2}}-\left({\sqrt[ {5}]{2}}\right)^{2}+\left({\sqrt[ {5}]{2}}\right)^{3}-\left({\sqrt[ {5}]{2}}\right)^{4}$. But, I want to know how to solve this without plugging it in and verifying an already known root. Can the depressed quintic be solved? Or does one need to use another method to solve this polynomial?",,"['analysis', 'polynomials', 'galois-theory']"
91,Prove $2\int_0^1 \frac{\ln^2(1-x)}{1+x^2}dx+\int_0^1 \frac{\ln^2(1+x)}{1+x^2}dx=\frac{3}{16}\pi\ln^22-2G\ln2+\frac{7}{64}\pi^3$ [closed],Prove  [closed],2\int_0^1 \frac{\ln^2(1-x)}{1+x^2}dx+\int_0^1 \frac{\ln^2(1+x)}{1+x^2}dx=\frac{3}{16}\pi\ln^22-2G\ln2+\frac{7}{64}\pi^3,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How prove that  $$2\int_0^1 \dfrac{(\ln(1-x))^2}{1+x^2}dx+\int_0^1 \dfrac{(\ln(1+x))^2}{1+x^2}dx=\dfrac{3}{16}\pi\left(\ln2\right)^2-2G\ln2+\dfrac{7}{64}\pi^3$$  Where G is the Catalan's Constant.  $$ \int_0^1 \dfrac{(\ln(1+x))^2}{1+x^2}dx=\Big[\arctan x\left(\ln\left(1+x\right)\right)^2\Big]_0^1-2\int_0^1 \dfrac{\arctan x\ln(1+x)}{1+x}dx=\dfrac{1}{4}\pi\left(\ln2\right)^2-2J$$ see users FDP about Evaluating $$\int_0^1 \frac{x \arctan x \log \left( 1-x^2\right)}{1+x^2}dx$$","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question How prove that  $$2\int_0^1 \dfrac{(\ln(1-x))^2}{1+x^2}dx+\int_0^1 \dfrac{(\ln(1+x))^2}{1+x^2}dx=\dfrac{3}{16}\pi\left(\ln2\right)^2-2G\ln2+\dfrac{7}{64}\pi^3$$  Where G is the Catalan's Constant.  $$ \int_0^1 \dfrac{(\ln(1+x))^2}{1+x^2}dx=\Big[\arctan x\left(\ln\left(1+x\right)\right)^2\Big]_0^1-2\int_0^1 \dfrac{\arctan x\ln(1+x)}{1+x}dx=\dfrac{1}{4}\pi\left(\ln2\right)^2-2J$$ see users FDP about Evaluating $$\int_0^1 \frac{x \arctan x \log \left( 1-x^2\right)}{1+x^2}dx$$",,"['integration', 'analysis', 'definite-integrals']"
92,Prove $\partial (A \cup B)\subset \partial A\cup\partial B$,Prove,\partial (A \cup B)\subset \partial A\cup\partial B,"How to use this definition of boundary: ""any open ball centered at a boundary point of a set $A$ intersects both $A$ and $A^C$"" to prove $\partial (A \cup B)\subset \partial A\cup\partial B$? I tried by arguing that it is equivalent to: $\partial (A \cup B)\subset \partial A$ or  $\partial (A \cup B)\subset \partial B$. And assume  $\partial (A \cup B)\not\subset \partial A$ then we need to show $\partial (A \cup B)\subset \partial B$ must hold. I don't know how to use the definition to prove this.","How to use this definition of boundary: ""any open ball centered at a boundary point of a set $A$ intersects both $A$ and $A^C$"" to prove $\partial (A \cup B)\subset \partial A\cup\partial B$? I tried by arguing that it is equivalent to: $\partial (A \cup B)\subset \partial A$ or  $\partial (A \cup B)\subset \partial B$. And assume  $\partial (A \cup B)\not\subset \partial A$ then we need to show $\partial (A \cup B)\subset \partial B$ must hold. I don't know how to use the definition to prove this.",,"['real-analysis', 'general-topology', 'analysis']"
93,How can I prove that the argument of a transcendental function must be dimensionless?,How can I prove that the argument of a transcendental function must be dimensionless?,,"We all know from school that arguments of transcendental functions such as exponential, trigonometric and logarithmic functions, or to inhomogeneous polynomials, must be dimensionless quantities. But is there a simple way to prove it?","We all know from school that arguments of transcendental functions such as exponential, trigonometric and logarithmic functions, or to inhomogeneous polynomials, must be dimensionless quantities. But is there a simple way to prove it?",,['analysis']
94,Recommend book Taylor expansions,Recommend book Taylor expansions,,"I've taken up self-study of math and i start using the book called : Mathematical Analysis I Authors: Canuto, Claudio, Tabacco, Anita I would like to start from zero  to understand taylor expansion and i'm looking about  some textbook with homework problems with step-by-step math answers if possible and cover specialy those subjects: Local comparison of functions. Taylor expansions and applications I would appreciate any book recommendations. Thanks in advance.","I've taken up self-study of math and i start using the book called : Mathematical Analysis I Authors: Canuto, Claudio, Tabacco, Anita I would like to start from zero  to understand taylor expansion and i'm looking about  some textbook with homework problems with step-by-step math answers if possible and cover specialy those subjects: Local comparison of functions. Taylor expansions and applications I would appreciate any book recommendations. Thanks in advance.",,"['analysis', 'soft-question', 'self-learning', 'book-recommendation', 'big-list']"
95,Why are all k-cells convex?,Why are all k-cells convex?,,"Reading through the first half of Baby Rudin again before taking an Analysis class, I came across the assertion that ""it is also easy to show that k-cells are convex"". Previously it gave the example of open/closed balls being convex, and the proof is obvious and easy to understand.  That being said, and it's probably very easy, but I can't for the life of me produce something that shows that all k-cells are convex as well. I understand convex to sort of say ""all points 'between' two points in a given set are also in the set"" in Layman's terms, but I'm not sure where to proceed from there.  I either got this on my first read and can't remember for the life of me, or I took it for granted and went with it. Any help leading me in the right direction?","Reading through the first half of Baby Rudin again before taking an Analysis class, I came across the assertion that ""it is also easy to show that k-cells are convex"". Previously it gave the example of open/closed balls being convex, and the proof is obvious and easy to understand.  That being said, and it's probably very easy, but I can't for the life of me produce something that shows that all k-cells are convex as well. I understand convex to sort of say ""all points 'between' two points in a given set are also in the set"" in Layman's terms, but I'm not sure where to proceed from there.  I either got this on my first read and can't remember for the life of me, or I took it for granted and went with it. Any help leading me in the right direction?",,"['real-analysis', 'general-topology', 'analysis']"
96,Solving the functional equation $2f(x)-f(1/x)=3x$,Solving the functional equation,2f(x)-f(1/x)=3x,If $$2f(x)-f(1/x)=3x$$ how would I find $f(x)$? I have tried various linear and other functions but I do not know how to start this,If $$2f(x)-f(1/x)=3x$$ how would I find $f(x)$? I have tried various linear and other functions but I do not know how to start this,,"['analysis', 'functions', 'functional-equations']"
97,Show that $\frac{(x^2 + y^2 )}{4} \leq e^{x+y-2}$,Show that,\frac{(x^2 + y^2 )}{4} \leq e^{x+y-2},"Show that  \begin{equation} \frac{x^2 + y^2}{4} \leq e^{x+y-2} \end{equation} is true for $x,y \geq 0$. As far, I have prove that  \begin{equation} x^2 + y^2 \leq e^{x}e^{y}\leq e^{x+y} \end{equation} since $e^{x}\geq x^2$ and $e^{y}\geq y^2$. If someone can give some aid it would be nice!","Show that  \begin{equation} \frac{x^2 + y^2}{4} \leq e^{x+y-2} \end{equation} is true for $x,y \geq 0$. As far, I have prove that  \begin{equation} x^2 + y^2 \leq e^{x}e^{y}\leq e^{x+y} \end{equation} since $e^{x}\geq x^2$ and $e^{y}\geq y^2$. If someone can give some aid it would be nice!",,"['analysis', 'inequality', 'exponential-function']"
98,Show that $\sum_{n\le x} \mu ^2(n)=\frac{x}{\zeta(2)}+o(\sqrt{x}) \; (x\to \infty)$,Show that,\sum_{n\le x} \mu ^2(n)=\frac{x}{\zeta(2)}+o(\sqrt{x}) \; (x\to \infty),"Show that $$\sum_{n\le x} \mu ^2(n)=\frac{x}{\zeta(2)}+o(\sqrt{x}) \; (x\to \infty)$$ I've proven so far that $\sum_{n\le x} \mu ^2(n)=\frac{x}{\zeta(2)}+O(\sqrt{x})$. I want to reduce this error term $O(\sqrt{x})$ to $o(\sqrt{x})$, and I'm thinking of using the relation $M(x)=\sum_{n\le x}\mu(n)=o(x)$ which is equivalent to the Prime Number Theorem. How can I use this relation to reduce the error term? I would greatly appreciate any help.","Show that $$\sum_{n\le x} \mu ^2(n)=\frac{x}{\zeta(2)}+o(\sqrt{x}) \; (x\to \infty)$$ I've proven so far that $\sum_{n\le x} \mu ^2(n)=\frac{x}{\zeta(2)}+O(\sqrt{x})$. I want to reduce this error term $O(\sqrt{x})$ to $o(\sqrt{x})$, and I'm thinking of using the relation $M(x)=\sum_{n\le x}\mu(n)=o(x)$ which is equivalent to the Prime Number Theorem. How can I use this relation to reduce the error term? I would greatly appreciate any help.",,"['analysis', 'number-theory', 'asymptotics', 'analytic-number-theory']"
99,"Show that: $\int_{0}^{\infty} \frac{\sin{x^{q}}}{x^{q}} dx = \frac{\Gamma{\frac{1}{q}}}{q-1}\cos{\frac{\pi}{2q}} \mbox{, q > 1}$",Show that:,"\int_{0}^{\infty} \frac{\sin{x^{q}}}{x^{q}} dx = \frac{\Gamma{\frac{1}{q}}}{q-1}\cos{\frac{\pi}{2q}} \mbox{, q > 1}","How do you show that:   $$ \int_{0}^{\infty} \frac{\sin{x^{q}}}{x^{q}} dx = \frac{\Gamma{\frac{1}{q}}}{q-1}\cos{\frac{\pi}{2q}} \mbox{, q > 1} $$   Without using Gamma function?","How do you show that:   $$ \int_{0}^{\infty} \frac{\sin{x^{q}}}{x^{q}} dx = \frac{\Gamma{\frac{1}{q}}}{q-1}\cos{\frac{\pi}{2q}} \mbox{, q > 1} $$   Without using Gamma function?",,"['calculus', 'integration']"
