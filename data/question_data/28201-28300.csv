,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probability on entering direction of a simple random walk,Probability on entering direction of a simple random walk,,"Let $X(n)$ be a simple random walk on $\Bbb{Z}^2$. Also we define $S_{R} = \inf\{n > 0 : X(n) \notin [-R, R]^2 \} $ : the exit time of the square $[-R, R]^2$, $T_{v} = \inf\{n > 0 : X(n) = v\}$ : the hitting time of the lattice point $v \in \Bbb{Z}^2$, I want to consider two conditional probability $$ p(w \to v) := \Bbb{P}(X(T_v-1) = w \mid T_{v} < S_{R}). \tag{1} $$ In other words, I want to track the entering direction of my random walk when it hits $v$ before it hits the boundary. Now fix $x = (a, b)$ in the open square $(-1, 1)^2$. Then $v = v(R) = (\lfloor aR \rfloor, \lfloor bR \rfloor) \in \Bbb{Z}^2$ and we can consider $$ P(x, e) = p(v+e \to v) \quad \text{for} \quad e \in \{(0, 1), (0, -1), (1, 0), (-1, 0)\} $$ Question. Does $P(x, e)$ converge to $1/4$ as $R \to \infty$ for any $e$? If this is the case, how fast the convergence takes place? An ideal situation for my case would be that we have $$ P(x, e) = \tfrac{1}{4} + \mathcal{O}_x (R^{-1}), \tag{2} $$ where the bound for $\mathcal{O}_x$ behaves quite well away from the origin and the boundary of the square. But my Monte-Carlo simulation seems to suggest that convergence would be slower, so I wonder if we have any tool to analyze this probability. Postscript. I am also interested in the probability of 'last exit direction' $$ q(v \to w) := \Bbb{P}^{v}(X(1) = w \mid T_{v} > S_{R}), \tag{2} $$ but this is easy to analyze for at least two reasons: it does not depend on the history, and the conditioning event holds with high probability. So I omitted this from my question. Addendun. From numerical simulations with $R = 500, 1000, 2000, 4000$ and $x = (0, 0.5)$, I obtained the following log-plot for $$(R, \textstyle \max_e |P(x, e) - 1/4|)$$ as follows: So it seems not pessimistic to expect that (2) is actually true.","Let $X(n)$ be a simple random walk on $\Bbb{Z}^2$. Also we define $S_{R} = \inf\{n > 0 : X(n) \notin [-R, R]^2 \} $ : the exit time of the square $[-R, R]^2$, $T_{v} = \inf\{n > 0 : X(n) = v\}$ : the hitting time of the lattice point $v \in \Bbb{Z}^2$, I want to consider two conditional probability $$ p(w \to v) := \Bbb{P}(X(T_v-1) = w \mid T_{v} < S_{R}). \tag{1} $$ In other words, I want to track the entering direction of my random walk when it hits $v$ before it hits the boundary. Now fix $x = (a, b)$ in the open square $(-1, 1)^2$. Then $v = v(R) = (\lfloor aR \rfloor, \lfloor bR \rfloor) \in \Bbb{Z}^2$ and we can consider $$ P(x, e) = p(v+e \to v) \quad \text{for} \quad e \in \{(0, 1), (0, -1), (1, 0), (-1, 0)\} $$ Question. Does $P(x, e)$ converge to $1/4$ as $R \to \infty$ for any $e$? If this is the case, how fast the convergence takes place? An ideal situation for my case would be that we have $$ P(x, e) = \tfrac{1}{4} + \mathcal{O}_x (R^{-1}), \tag{2} $$ where the bound for $\mathcal{O}_x$ behaves quite well away from the origin and the boundary of the square. But my Monte-Carlo simulation seems to suggest that convergence would be slower, so I wonder if we have any tool to analyze this probability. Postscript. I am also interested in the probability of 'last exit direction' $$ q(v \to w) := \Bbb{P}^{v}(X(1) = w \mid T_{v} > S_{R}), \tag{2} $$ but this is easy to analyze for at least two reasons: it does not depend on the history, and the conditioning event holds with high probability. So I omitted this from my question. Addendun. From numerical simulations with $R = 500, 1000, 2000, 4000$ and $x = (0, 0.5)$, I obtained the following log-plot for $$(R, \textstyle \max_e |P(x, e) - 1/4|)$$ as follows: So it seems not pessimistic to expect that (2) is actually true.",,"['probability', 'probability-theory', 'random-walk']"
1,The problem of the most visited point.,The problem of the most visited point.,,"Represent the set $R_{n\times n}=\{1,2,\ldots, n\}\times\{1,2,\ldots, n\} $ as a rectangle of $n$ by $n$ points as in the figures below for example. How to calculate the number of circuits that visit a chosen point in this rectangle? What is the most visited point on this rectangle? Making the question more precise we fix the settings below. A circuitc $c$ in rectangle $R_{n\times n}$ is defined as a sequence of distinct points $x_{i_1j_1}, x_{i_2j_2},x_{i_2j_2},\ldots, x_{i_{m-1}j_{m-1}}$ and a point $x_{i_{m}j_{m}}=x_{i_{1}j_{1}}$  in $R_{n\times n}$ such that $|i_{k}-i_{k+1}|+|j_{k}-j_{k+1}|=1$ for $k=1,\ldots, m-1$. A circuit $c=\{x_{i_1j_1}, x_{i_2j_2},x_{i_2j_2},\ldots, x_{i_{m-1}j_{m-1}},x_{i_{m}j_{m}}\}$ visit a point $x_{ij}$ if $x_{ij}\in c$. Let $N_n(x_{ij})$ the total circuits in $R_{n\times n}$ who visit the point $x_{ij}$ . Question. How to calculate the value of $N_n(x_{ij})$? If we draw a circuit randomly     which  point $x_{ij}$ has the highest probability to be visited? Calculations case $n = 1,2,3$ are trivial. I'm trying to calculate the number $N_n(x_{ij})$ by a recursive procedure which reduces the calculation for the case $n$ to $n-1$. But I think the use of this recursion depends on some well-crafted trick that escaped my attempts.","Represent the set $R_{n\times n}=\{1,2,\ldots, n\}\times\{1,2,\ldots, n\} $ as a rectangle of $n$ by $n$ points as in the figures below for example. How to calculate the number of circuits that visit a chosen point in this rectangle? What is the most visited point on this rectangle? Making the question more precise we fix the settings below. A circuitc $c$ in rectangle $R_{n\times n}$ is defined as a sequence of distinct points $x_{i_1j_1}, x_{i_2j_2},x_{i_2j_2},\ldots, x_{i_{m-1}j_{m-1}}$ and a point $x_{i_{m}j_{m}}=x_{i_{1}j_{1}}$  in $R_{n\times n}$ such that $|i_{k}-i_{k+1}|+|j_{k}-j_{k+1}|=1$ for $k=1,\ldots, m-1$. A circuit $c=\{x_{i_1j_1}, x_{i_2j_2},x_{i_2j_2},\ldots, x_{i_{m-1}j_{m-1}},x_{i_{m}j_{m}}\}$ visit a point $x_{ij}$ if $x_{ij}\in c$. Let $N_n(x_{ij})$ the total circuits in $R_{n\times n}$ who visit the point $x_{ij}$ . Question. How to calculate the value of $N_n(x_{ij})$? If we draw a circuit randomly     which  point $x_{ij}$ has the highest probability to be visited? Calculations case $n = 1,2,3$ are trivial. I'm trying to calculate the number $N_n(x_{ij})$ by a recursive procedure which reduces the calculation for the case $n$ to $n-1$. But I think the use of this recursion depends on some well-crafted trick that escaped my attempts.",,"['probability', 'combinatorics', 'probability-theory', 'recursion', 'percolation']"
2,"Choosing two random numbers in $(0,1)$ what is the probability that sum of them is more than $1$?",Choosing two random numbers in  what is the probability that sum of them is more than ?,"(0,1) 1","Choosing two random numbers in $(0,1)$ what is the probability that sum of them is more than $1$? Also what is probability of sum of them being less than $1$? I think the answer should be $\frac{1}{2}$, but I have no idea. EDIT : I should mention that the question is about a general distribution, and the numbers selected are independent.","Choosing two random numbers in $(0,1)$ what is the probability that sum of them is more than $1$? Also what is probability of sum of them being less than $1$? I think the answer should be $\frac{1}{2}$, but I have no idea. EDIT : I should mention that the question is about a general distribution, and the numbers selected are independent.",,"['probability', 'random']"
3,Probability that Ken and John set next to each other,Probability that Ken and John set next to each other,,"A group of ten people sits down, uniformly at random, around a table. Ken   and John are part of this group. Determine the probability that Ken and John sit   next to each other. There are $10!$ ways to arrange the seating for everyone, there are 10 possible ways for John and Ken to sit together. $$\operatorname{Pr}(J\ \&\ K ) = \frac{10}{10!} = \frac{1}{9!}$$ Am I correct?","A group of ten people sits down, uniformly at random, around a table. Ken   and John are part of this group. Determine the probability that Ken and John sit   next to each other. There are $10!$ ways to arrange the seating for everyone, there are 10 possible ways for John and Ken to sit together. $$\operatorname{Pr}(J\ \&\ K ) = \frac{10}{10!} = \frac{1}{9!}$$ Am I correct?",,['probability']
4,When the roulette has hit 5 reds why shouldn't I bet to black?,When the roulette has hit 5 reds why shouldn't I bet to black?,,"First some context, I'm not a mathematician, not even close (as you will soon see) I do grasp some things about it but in a need to know basis, so plain english answers are appreciated (too). I can't figure out this one even though some have tried very hard to explain/convince me. So let's say I'm on a roulette (let's leave out the zero, or make it a coin for that matter). The roulette hits 5 (or any amount of) times red on a row . My question is why should't I bet to black (or better said why it is the same the one I pick). I DO UNDERSTAND THE BASIC PRINCIPLE, that there is a material reality which makes the ball randomly fall on any of the two colors (which gives the options a 50-50 chance). But, I also understand that if you ""say"": I bet red will come out six times on a row, you do have a very low probability of that happening so: How is it that if you have seen the ball fall 5 times on a row on red, and you bet on red, you are NOT betting on 6 times on a row on red (that does have lower probability). Thanks in advance! I hope I was clear enough with my question, if not, please ask for any clarifications needed. Sorry for the VERY plain English, feel free to modify or suggest a change to anything that may be misleading.","First some context, I'm not a mathematician, not even close (as you will soon see) I do grasp some things about it but in a need to know basis, so plain english answers are appreciated (too). I can't figure out this one even though some have tried very hard to explain/convince me. So let's say I'm on a roulette (let's leave out the zero, or make it a coin for that matter). The roulette hits 5 (or any amount of) times red on a row . My question is why should't I bet to black (or better said why it is the same the one I pick). I DO UNDERSTAND THE BASIC PRINCIPLE, that there is a material reality which makes the ball randomly fall on any of the two colors (which gives the options a 50-50 chance). But, I also understand that if you ""say"": I bet red will come out six times on a row, you do have a very low probability of that happening so: How is it that if you have seen the ball fall 5 times on a row on red, and you bet on red, you are NOT betting on 6 times on a row on red (that does have lower probability). Thanks in advance! I hope I was clear enough with my question, if not, please ask for any clarifications needed. Sorry for the VERY plain English, feel free to modify or suggest a change to anything that may be misleading.",,"['probability', 'recreational-mathematics']"
5,What is the expected value of the number of die rolls necessary to get a specific number?,What is the expected value of the number of die rolls necessary to get a specific number?,,"Given a discrete random number generator, such as a six-sided die, what is the expected value of the number of rolls necessary to roll a specific number (e.g. a six)? I think the result should be given by E$\langle$rolls$\rangle$ = $\frac{1}{6}\sum_{n=0}^\infty{(\frac{5}{6})^n(n+1)}$, but I don't know how to calculate the convergence of that sum. Also, how do I calculate the variance?","Given a discrete random number generator, such as a six-sided die, what is the expected value of the number of rolls necessary to roll a specific number (e.g. a six)? I think the result should be given by E$\langle$rolls$\rangle$ = $\frac{1}{6}\sum_{n=0}^\infty{(\frac{5}{6})^n(n+1)}$, but I don't know how to calculate the convergence of that sum. Also, how do I calculate the variance?",,"['probability', 'sequences-and-series']"
6,"If the gambler's fallacy is false, how do notions of ""expected number"" of events work?","If the gambler's fallacy is false, how do notions of ""expected number"" of events work?",,"Imagine there is a fair spinner that could land on any number $1$ through $100$ . I understand that the chance of any number appearing on the next spin is $\frac{1}{100}$ , and if you spin the spinner $100$ times then the expected number of $5$ 's, for example, is $1$ . However, I have the following questions: If the spinner does not land on $5$ in the first spin then this does not make the chance of getting a $5$ on the second spin any more or less likely (to assume otherwise would imply the gambler's fallacy). This means that we now must spin the spinner a total of $101$ times in order to expect exactly one $5$ . Doesn't this cause some kind of infinite regress? If we never expect a $5$ on any given spin, and no $5$ 's have come up thus far in the first $n$ spins, then won't it take $n+100$ spins to expect a 5? I know that at some point if we examine a group of spins then we can expect something with low probability like spinning a $5$ to occur, but it seems strange and counter-intuitive to me that though we expect a $5$ to come up in a sufficiently large group of spins, on each individual spin we do not expect a $5$ . Furthermore, we do not expect any number to come up on the first spin (in that the probability of any particular number appearing is low), and yet we know for certain that some number will still come up. For there to be a greater than $50\%$ chance of spinning a $5$ , we must spin the spinner $69$ times according to the following calculation: $$P(\text{Not rolling a 5 in } n \text{ spins})=\left(\frac{99}{100}\right)^n \\ \left(\frac{99}{100}\right)^n < 0.5 \\ \log_{0.99}0.5=68.967... $$ Hence, it must be spun $69$ times for there to be a greater than $50\%$ chance of there being a $5$ . Why is this not $50$ spins, as we expect $0.5$ $5$ 's to come up in this period? Also, I have the same question that once a $5$ does not come up, don't we have to spin it $70$ times for there to a greater than $50\%$ probability, and can't this cause the same infinite regress as described above?","Imagine there is a fair spinner that could land on any number through . I understand that the chance of any number appearing on the next spin is , and if you spin the spinner times then the expected number of 's, for example, is . However, I have the following questions: If the spinner does not land on in the first spin then this does not make the chance of getting a on the second spin any more or less likely (to assume otherwise would imply the gambler's fallacy). This means that we now must spin the spinner a total of times in order to expect exactly one . Doesn't this cause some kind of infinite regress? If we never expect a on any given spin, and no 's have come up thus far in the first spins, then won't it take spins to expect a 5? I know that at some point if we examine a group of spins then we can expect something with low probability like spinning a to occur, but it seems strange and counter-intuitive to me that though we expect a to come up in a sufficiently large group of spins, on each individual spin we do not expect a . Furthermore, we do not expect any number to come up on the first spin (in that the probability of any particular number appearing is low), and yet we know for certain that some number will still come up. For there to be a greater than chance of spinning a , we must spin the spinner times according to the following calculation: Hence, it must be spun times for there to be a greater than chance of there being a . Why is this not spins, as we expect 's to come up in this period? Also, I have the same question that once a does not come up, don't we have to spin it times for there to a greater than probability, and can't this cause the same infinite regress as described above?",1 100 \frac{1}{100} 100 5 1 5 5 101 5 5 5 n n+100 5 5 5 50\% 5 69 P(\text{Not rolling a 5 in } n \text{ spins})=\left(\frac{99}{100}\right)^n \\ \left(\frac{99}{100}\right)^n < 0.5 \\ \log_{0.99}0.5=68.967...  69 50\% 5 50 0.5 5 5 70 50\%,"['probability', 'definition']"
7,Random point uniform on a sphere,Random point uniform on a sphere,,"If $X=(x,y,z)$ is a random point uniform on the unit sphere in $\mathbb{R}^3$,  Are the  coordinates $x$, $y$, $z$ uniform in interval $(-1,1)$?","If $X=(x,y,z)$ is a random point uniform on the unit sphere in $\mathbb{R}^3$,  Are the  coordinates $x$, $y$, $z$ uniform in interval $(-1,1)$?",,"['probability', 'probability-distributions']"
8,Why is there this strange contradiction between the language of logic and that of set theory?,Why is there this strange contradiction between the language of logic and that of set theory?,,"In standard probability theory events are represented by sets consisting of elementary events. Consider two events for which (as sets) $A \subset B$ . If an elementary event $x \in A$ takes places then we say that $B$ takes place as well. Since $A \subset B$ , $x \in A$ implies that $B$ takes place too. It seems that when for sets (representing events) $$A \subset B$$ $$then \ A \ implies \ B .$$ On the other hand, if we use the language of logic for the events then $$A \supset B$$ $$ \ means\  that \ A\  implies\ B .$$ Why is this strange virtual contradiction between the language of sets and the language of logic? (In order to avoid down votes and unplesant comments I reveal that I happen to know that the true translation of the sentence $A \supset B$ of logic to the language of sets (representing events) is $\overline{A \cap \overline B}$ .)","In standard probability theory events are represented by sets consisting of elementary events. Consider two events for which (as sets) . If an elementary event takes places then we say that takes place as well. Since , implies that takes place too. It seems that when for sets (representing events) On the other hand, if we use the language of logic for the events then Why is this strange virtual contradiction between the language of sets and the language of logic? (In order to avoid down votes and unplesant comments I reveal that I happen to know that the true translation of the sentence of logic to the language of sets (representing events) is .)",A \subset B x \in A B A \subset B x \in A B A \subset B then \ A \ implies \ B . A \supset B  \ means\  that \ A\  implies\ B . A \supset B \overline{A \cap \overline B},"['probability', 'elementary-set-theory', 'logic', 'notation']"
9,"Roll a dice infinitely many times, what is the probability of getting a 5 before a 6","Roll a dice infinitely many times, what is the probability of getting a 5 before a 6",,"My proof: For all possible events, based on the order of appearance between 5 and 6.l, they can be categorised into 2 groups. $A:$ event with 5 appear before 6 $A^{c}:$ event with 6 appear before 5 And the union of $A$ and $A^{c}$ should be all possible events. So $P(A) + P(A^{c}) = 1$ The last step: by symmetry, number of events that have 5 before 6 is the same as that for 6 before 5. So $P(A) = P(A^{c}) = 0.5$ However, this last step I am not sure  how to write out a formal proof to support my intuition for the symmetry. I think I need to evaluate the cardinality $A$ and $A^{c}$ but not sure how to. So I need help here.","My proof: For all possible events, based on the order of appearance between 5 and 6.l, they can be categorised into 2 groups. event with 5 appear before 6 event with 6 appear before 5 And the union of and should be all possible events. So The last step: by symmetry, number of events that have 5 before 6 is the same as that for 6 before 5. So However, this last step I am not sure  how to write out a formal proof to support my intuition for the symmetry. I think I need to evaluate the cardinality and but not sure how to. So I need help here.",A: A^{c}: A A^{c} P(A) + P(A^{c}) = 1 P(A) = P(A^{c}) = 0.5 A A^{c},"['probability', 'probability-theory', 'dice']"
10,Difference of two binomial random variables,Difference of two binomial random variables,,"Could anyone guide me to a document where they derive the distribution of the difference between two binomial random variables. So $X \sim \mathrm{Bin}(n_1, p_1) $ and $Y \sim \mathrm{Bin}(n_2, p_2) $, what is the distribution of $|X-Y|$. thank you. (Also $X$ and $Y$ are independent)","Could anyone guide me to a document where they derive the distribution of the difference between two binomial random variables. So $X \sim \mathrm{Bin}(n_1, p_1) $ and $Y \sim \mathrm{Bin}(n_2, p_2) $, what is the distribution of $|X-Y|$. thank you. (Also $X$ and $Y$ are independent)",,"['probability', 'random-variables']"
11,Odd order moments of a symmetrical distribution,Odd order moments of a symmetrical distribution,,"Is it true that for every symmetrical distribution all odd-order moments are equal to zero? If yes, how would I be able to prove such a thing?","Is it true that for every symmetrical distribution all odd-order moments are equal to zero? If yes, how would I be able to prove such a thing?",,"['probability', 'probability-distributions', 'symmetry']"
12,Probability that a character kills the boss in a 3 versus 1 fight,Probability that a character kills the boss in a 3 versus 1 fight,,"In a RPG game, your three characters A, B and C fight a boss. The boss has $1000$ hp. The attacks are sequential: A attacks then B attacks then C attacks then A attacks again, etc. Character A can do any integral amount of damage between $25$ and $50$ with equal probability. Character B can do any integral amount of damage between $30$ and $70$ with equal probability. Character C can do any integral amount of damage between $10$ and $80$ with equal probability. Assuming that the boss is not strong enough to kill any of the characters before it dies, what is the probability that player A will be the one to deliver the final blow and kill the boss? Same question for players B and C. Unfortunately I don't even know how to get started on this problem, any hint would be helpful.","In a RPG game, your three characters A, B and C fight a boss. The boss has hp. The attacks are sequential: A attacks then B attacks then C attacks then A attacks again, etc. Character A can do any integral amount of damage between and with equal probability. Character B can do any integral amount of damage between and with equal probability. Character C can do any integral amount of damage between and with equal probability. Assuming that the boss is not strong enough to kill any of the characters before it dies, what is the probability that player A will be the one to deliver the final blow and kill the boss? Same question for players B and C. Unfortunately I don't even know how to get started on this problem, any hint would be helpful.",1000 25 50 30 70 10 80,['probability']
13,Is there a significance to the asymptotic probability of at least one occurrence of an event in n attempts?,Is there a significance to the asymptotic probability of at least one occurrence of an event in n attempts?,,"Let's look at the set of the probabilities of having at least one occurrence of an event if we make $n$ attempts, where the probability of the event occurring is $1/n$. For example, if we are looking at the probability of the occurrence of rolling a $4$ on a die ($1/6$ chance), we will actually make $6$ attempts. The probability of success in that case (at least one occurrence of a $4$ in the $6$ attempts) is $1-(5/6)^{6} = 0.6651$ (I have rounded the results.) If we make $15$ attempts at something with a probability of its happening (on each separate occasion) being $1/15$, then the probability of its occurring at least once in those $15$ attempts is $1-(14/15)^{15} = 0.6447$.  If we use $n=1,000,000$ then we get $0.63212$. So, we see that we have an asymptotic situation. I have always wondered if there was any other known mathematical significance to this specific approximate number/asymptote. Thanks in advance for reading and for all responses!","Let's look at the set of the probabilities of having at least one occurrence of an event if we make $n$ attempts, where the probability of the event occurring is $1/n$. For example, if we are looking at the probability of the occurrence of rolling a $4$ on a die ($1/6$ chance), we will actually make $6$ attempts. The probability of success in that case (at least one occurrence of a $4$ in the $6$ attempts) is $1-(5/6)^{6} = 0.6651$ (I have rounded the results.) If we make $15$ attempts at something with a probability of its happening (on each separate occasion) being $1/15$, then the probability of its occurring at least once in those $15$ attempts is $1-(14/15)^{15} = 0.6447$.  If we use $n=1,000,000$ then we get $0.63212$. So, we see that we have an asymptotic situation. I have always wondered if there was any other known mathematical significance to this specific approximate number/asymptote. Thanks in advance for reading and for all responses!",,['probability']
14,Question on the 'Hat check' problem,Question on the 'Hat check' problem,,"The famous 'Hat Check Problem' goes like this, 'n' men enter the restaurant and put their hats at the reception. Each man gets a random hat back when going back after having dinner. The goal is to find the expected number of men who get their right hat back. To calculate the expected value from is definition, we have to compute the probability with which 'k' men would get their correct hat back. How to compute this probablity? I know that this problem can be solved by using 'Linearity of Expectation' in a much simpler way, but i would like to know the way to compute this probablity.","The famous 'Hat Check Problem' goes like this, 'n' men enter the restaurant and put their hats at the reception. Each man gets a random hat back when going back after having dinner. The goal is to find the expected number of men who get their right hat back. To calculate the expected value from is definition, we have to compute the probability with which 'k' men would get their correct hat back. How to compute this probablity? I know that this problem can be solved by using 'Linearity of Expectation' in a much simpler way, but i would like to know the way to compute this probablity.",,"['probability', 'probability-theory', 'random-variables', 'expectation']"
15,"In probabilistic questions with ""real life"" context, why can we ignore defining the sample space?","In probabilistic questions with ""real life"" context, why can we ignore defining the sample space?",,"Consider, for the sake of argument, the following question: we are coloring every side and every diagonal of a regular hexagon with one of three colours (say white $W$ , red $R$ and black $B$ ). Everytime each colour is equally probably and colorings are independent. Let $X$ denote number of triangles in one colour. Compute $E(X)$ . I'd be satisfied with a solution going like: enumerate all 15 considerated edges with numbers from $1$ to $15$ and all 20 triangles with numbers from $1$ to $20$ . Step 1: define a ""compelling"" sample space, like a product space of 15 spaces $\Omega=\{W, R, B\}$ with $\frac{1}{3}$ probability for every singleton. Step 2: define random variables $X_{1}, X_{2}, \dots, X_{20}$ setting values $1$ if corresponding triangle is in one colour, $0$ otherwise. Then $X=X_{1}+\dots X_{20}$ and we proceed from here. Usually we ignore step $1$ and go directly to step $2$ . I'd kindly ask you to tell me why is it considered as as good of a solution. When dealing with similar questions, do we start by assuming that there is some ""compelling"" (what would that even mean?) sample space? How else would one be able to define random variables? Does one usually postulate anything when begins to model using probability theory? Also, in the usual way we continue by kind of guessing (without explicit sample space isn't that so? Or maybe it is arbitrary and equivalent to defining sample space?) distributions of defined random variables and say things like: $P(X_{i}=1)=\frac{1}{3} \cdot \frac{1}{3}$ because u fix one colour of one edge and then other two edges have $\frac{1}{3}$ probability of having this colour and those two colorings are independent, so we multiply. Why are those kind of solutions correct, formally? With sample space defined it seems so much more elegant and precise to me. Is it just my lack of practice? Why should i solve problems that way? Any help would be much appreciated. I'd like the answers to be as technical as it is necessary. My knowledge exclude things like Markov chains, martingales, stochastic processes (i.e. Kolmogorov's existence theorem) and statistics, but please use it if it's helpful, i'll then just get back to it again in the future.","Consider, for the sake of argument, the following question: we are coloring every side and every diagonal of a regular hexagon with one of three colours (say white , red and black ). Everytime each colour is equally probably and colorings are independent. Let denote number of triangles in one colour. Compute . I'd be satisfied with a solution going like: enumerate all 15 considerated edges with numbers from to and all 20 triangles with numbers from to . Step 1: define a ""compelling"" sample space, like a product space of 15 spaces with probability for every singleton. Step 2: define random variables setting values if corresponding triangle is in one colour, otherwise. Then and we proceed from here. Usually we ignore step and go directly to step . I'd kindly ask you to tell me why is it considered as as good of a solution. When dealing with similar questions, do we start by assuming that there is some ""compelling"" (what would that even mean?) sample space? How else would one be able to define random variables? Does one usually postulate anything when begins to model using probability theory? Also, in the usual way we continue by kind of guessing (without explicit sample space isn't that so? Or maybe it is arbitrary and equivalent to defining sample space?) distributions of defined random variables and say things like: because u fix one colour of one edge and then other two edges have probability of having this colour and those two colorings are independent, so we multiply. Why are those kind of solutions correct, formally? With sample space defined it seems so much more elegant and precise to me. Is it just my lack of practice? Why should i solve problems that way? Any help would be much appreciated. I'd like the answers to be as technical as it is necessary. My knowledge exclude things like Markov chains, martingales, stochastic processes (i.e. Kolmogorov's existence theorem) and statistics, but please use it if it's helpful, i'll then just get back to it again in the future.","W R B X E(X) 1 15 1 20 \Omega=\{W, R, B\} \frac{1}{3} X_{1}, X_{2}, \dots, X_{20} 1 0 X=X_{1}+\dots X_{20} 1 2 P(X_{i}=1)=\frac{1}{3} \cdot \frac{1}{3} \frac{1}{3}","['probability', 'probability-theory']"
16,Average distance between two random points in a square,Average distance between two random points in a square,,"A square with side $a$ is given. What is the average distance between two uniformly-distributed random points inside the square? For more general ""rectangle"" case, see here . The proof found there is fairly complex, and I am looking for a simpler proof for this special case. I expect it could be significantly simpler. See also ""line"" case .","A square with side is given. What is the average distance between two uniformly-distributed random points inside the square? For more general ""rectangle"" case, see here . The proof found there is fairly complex, and I am looking for a simpler proof for this special case. I expect it could be significantly simpler. See also ""line"" case .",a,"['probability', 'geometry', 'average']"
17,Hard combinatorics and probability question.,Hard combinatorics and probability question.,,"A large white cube is painted red, and then cut into $27$ identical smaller cubes. These smaller cubes are shuffled randomly. A blind man (who also cannot feel the paint) reassembles the small cubes into a large one. What is the probability that the outside of this large cube is completely red?","A large white cube is painted red, and then cut into $27$ identical smaller cubes. These smaller cubes are shuffled randomly. A blind man (who also cannot feel the paint) reassembles the small cubes into a large one. What is the probability that the outside of this large cube is completely red?",,"['probability', 'combinatorics', 'combinations']"
18,"Show that the multinomial distribution has covariances ${\rm Cov}(X_i,X_j)=-r p_i p_j$",Show that the multinomial distribution has covariances,"{\rm Cov}(X_i,X_j)=-r p_i p_j","If $(X_1,\cdots, X_n)$ is a vector with multinomial distribution, proof that $\text{Cov}(X_i,X_j)=-rp_ip_j$, $i\neq j$ where $r$ is the number of trials of the experiment, $p_i$ is the probability of success for the variable $X_i$. $$fdp=f(x_1,...x_n)={r!\over{x_1!x_2!\cdots x_n!}}p_1^{x_1}\cdots p_n^{x_n} $$ if $ x_1+x_2+\cdots +x_n=r$ I'm trying to use the property: $\text{Cov}(X_i,X_j)=E[X_iX_j]-E[X_i]E[X_j]$ and find that $E[X_i]=rp_i$, but I don´t know the efficient way to calculate $E[X_iX_j].$","If $(X_1,\cdots, X_n)$ is a vector with multinomial distribution, proof that $\text{Cov}(X_i,X_j)=-rp_ip_j$, $i\neq j$ where $r$ is the number of trials of the experiment, $p_i$ is the probability of success for the variable $X_i$. $$fdp=f(x_1,...x_n)={r!\over{x_1!x_2!\cdots x_n!}}p_1^{x_1}\cdots p_n^{x_n} $$ if $ x_1+x_2+\cdots +x_n=r$ I'm trying to use the property: $\text{Cov}(X_i,X_j)=E[X_iX_j]-E[X_i]E[X_j]$ and find that $E[X_i]=rp_i$, but I don´t know the efficient way to calculate $E[X_iX_j].$",,"['probability', 'combinatorics', 'statistics', 'covariance', 'multinomial-distribution']"
19,Expected number of die rolls to get 6 given that all rolls are even.,Expected number of die rolls to get 6 given that all rolls are even.,,A fair 6-sided die is rolled repeatedly in till a 6 is obtained. Find the expected number of rolls conditioned on the event that none of the rolls yielded an odd number I had tried to figure out what will be the conditional distribution of $\frac{X}{Y}$ but I can't solved it yet Where $X $ is the face numbered 6 is obtained and $Y$ is the event only even number is occured,A fair 6-sided die is rolled repeatedly in till a 6 is obtained. Find the expected number of rolls conditioned on the event that none of the rolls yielded an odd number I had tried to figure out what will be the conditional distribution of $\frac{X}{Y}$ but I can't solved it yet Where $X $ is the face numbered 6 is obtained and $Y$ is the event only even number is occured,,"['probability', 'expectation', 'conditional-expectation']"
20,Probability of circle given by randomly chosen diameter falling inside a square,Probability of circle given by randomly chosen diameter falling inside a square,,Two dots are thrown into a square with side length 1 cm. The line ending in these two dots is the diameter of a circle. What is the probability that the circle lies in the square?,Two dots are thrown into a square with side length 1 cm. The line ending in these two dots is the diameter of a circle. What is the probability that the circle lies in the square?,,"['probability', 'geometry', 'geometric-probability']"
21,Why do we need (the abstract concept of) random variables (in discrete probability models)?,Why do we need (the abstract concept of) random variables (in discrete probability models)?,,"What we defined : Suppose we have a (discrete) probability model $\left(\Omega,P\right)$, where $P$ is the probability function (at least, that was the way it was introduced in a course I took; that means only that $\Omega$ is at most countable, that $P\left(\bigcup_{i}A_{i}\right)=\sum P\left(A_{i}\right)$, for all (at most countable and disjoint) events $A_{i}$ and that of course $P\left(\Omega\right)=1$). We defined a random variable (rd from now on) $X$ to be a mapping $X:\Omega\rightarrow\mathbb{R}$ and then discussed some aspects of $P\left(X=k\right)$ for some $k\in\mathbb{R}$ . What bothers me : To me, this definition seems rather artificial: Why define a mapping like that, if there is no apparent need for it (at least in this probability model) ? Since if we have an event $A\subseteq\Omega$, that depends on some parameter $k\in\mathbb{R}$, (for example the sum of the faces of dice be $k$) then we could just as easily define a collection of events $A_{k}$ - one for each parameter - and discuss aspects of $P\left(A_{k}\right)$, instead of the above way by using $X$. Of course one could now argue, that $A$ does not always need to depend on some parameter $k$, so one in some cases really has to ""convert""  probabilities to numbers via $X$, but of all examples that I have seen until now, even in $\Omega$ isn't made up out of numbers, somewhere a parameter $k$ does sneak in, so we could equivalently work with $P\left(A_{k}\right)$ instead of $P\left(X=k\right)$, since defining the subsets of $\Omega$ whose elements we want to count (to establish the probability of the subset) always amounts to using some $k$ in the definition of those subsets (this reasoning extends of course also to other cases like when we consider $P\left(X\leq k\right)$, since this can also be circumvented by considering an appropriate $P\left(\cup_{j\leq k}A_{j}\right)$). Thus, introducing rd's seems to me to be a superfluous definition of  events without specifying $k$""","What we defined : Suppose we have a (discrete) probability model $\left(\Omega,P\right)$, where $P$ is the probability function (at least, that was the way it was introduced in a course I took; that means only that $\Omega$ is at most countable, that $P\left(\bigcup_{i}A_{i}\right)=\sum P\left(A_{i}\right)$, for all (at most countable and disjoint) events $A_{i}$ and that of course $P\left(\Omega\right)=1$). We defined a random variable (rd from now on) $X$ to be a mapping $X:\Omega\rightarrow\mathbb{R}$ and then discussed some aspects of $P\left(X=k\right)$ for some $k\in\mathbb{R}$ . What bothers me : To me, this definition seems rather artificial: Why define a mapping like that, if there is no apparent need for it (at least in this probability model) ? Since if we have an event $A\subseteq\Omega$, that depends on some parameter $k\in\mathbb{R}$, (for example the sum of the faces of dice be $k$) then we could just as easily define a collection of events $A_{k}$ - one for each parameter - and discuss aspects of $P\left(A_{k}\right)$, instead of the above way by using $X$. Of course one could now argue, that $A$ does not always need to depend on some parameter $k$, so one in some cases really has to ""convert""  probabilities to numbers via $X$, but of all examples that I have seen until now, even in $\Omega$ isn't made up out of numbers, somewhere a parameter $k$ does sneak in, so we could equivalently work with $P\left(A_{k}\right)$ instead of $P\left(X=k\right)$, since defining the subsets of $\Omega$ whose elements we want to count (to establish the probability of the subset) always amounts to using some $k$ in the definition of those subsets (this reasoning extends of course also to other cases like when we consider $P\left(X\leq k\right)$, since this can also be circumvented by considering an appropriate $P\left(\cup_{j\leq k}A_{j}\right)$). Thus, introducing rd's seems to me to be a superfluous definition of  events without specifying $k$""",,"['probability', 'intuition', 'motivation']"
22,probability textbooks,probability textbooks,,"Has anyone compiled a moderately comprehensive list on the web or elsewhere of textbooks on probability For students who have not been introduced to the subject before That introduce both discrete and continuous probability distributions and their cumulative distribution functions, and include things like the Poisson limit theorem, the central limit theorem (say the former with proof and the latter not necessarily), and That perhaps cover the simplest stochastic processes like the Poisson process or infinite sequences of Bernoulli trials?","Has anyone compiled a moderately comprehensive list on the web or elsewhere of textbooks on probability For students who have not been introduced to the subject before That introduce both discrete and continuous probability distributions and their cumulative distribution functions, and include things like the Poisson limit theorem, the central limit theorem (say the former with proof and the latter not necessarily), and That perhaps cover the simplest stochastic processes like the Poisson process or infinite sequences of Bernoulli trials?",,"['probability', 'reference-request']"
23,What's objectionable about the Axiom of Countable Additivity?,What's objectionable about the Axiom of Countable Additivity?,,"Casella & Berger (2001) write: the Axiom of Countable Additivity, is not universally accepted among statisticians. ...  [It] is rejected by a school of statisticians led by deFinetti (1972), who chooses to replace this axiom with the Axiom of Finite Additivity. What might possibly be wrong or objectionable about the Axiom of Countable Additivity? (Simple examples would be helpful!) The Axiom of Countable Additivity is the 3rd condition below:","Casella & Berger (2001) write: the Axiom of Countable Additivity, is not universally accepted among statisticians. ...  [It] is rejected by a school of statisticians led by deFinetti (1972), who chooses to replace this axiom with the Axiom of Finite Additivity. What might possibly be wrong or objectionable about the Axiom of Countable Additivity? (Simple examples would be helpful!) The Axiom of Countable Additivity is the 3rd condition below:",,['probability']
24,What is the Probability that a Knight stays on chessboard after N hops?,What is the Probability that a Knight stays on chessboard after N hops?,,"Say a $8 \times 8$ chessboard as per picture. A position is represented here by co-ordinates $(x,y)$. A move is aslo considered as valid, where the Knight lands outside the chessboard  [   For eg. from $(3,2)$ towards $(3,1)$ but ends up outside chess-board.  ] But once outside, it can't come back. Question: Knight starts from $(0,0)$.  What is the Probability that a Knight stays on chessboard after N hops? Expected Solution: I don't want exact result like $ \frac{12}{64} $  but need your help on a. the thought/procedure/methodology to find it with b. A concluding formulae in terms of permutation/combination, Well my thought: After $(N-1)$th move, if the Kngiht is between $(x,y)$ where $3 \le x \le 6$ and $3 \le y \le 6$ then next move i.e $n$th move must ensure the knight will be within chessboard. Might be my thought is entirely wrong as it tries to find ""must be within chessboard"" In any $5 \times 5$ sub part with Knight in middle, it has $8$ possible moves. If initial position is $(0,0)$ out of those $8$ it has choice of $2$ only satisfying ""within chessboard"" constraint. Next move I am lost! Please help me think . Why cant we treat it like: a. The question is valid only if N-1 moves already done with the Knight on board.    b. Now to find Nth move s.t Knight hops out of board - say probability P(out)    c. 1 - P(out) now gives the answer { In Case b above we can use some stats like the following: Legal moves -> L      Illegal moves -> I 1. for 16 positions enclosed by {3c - 3f - 6c -6f} : 16 x 8 L 2. for each 4 positions {2b,2g,7b,7g} : 4L, 4I  =>  16L , 16I  3. for each 16 positions  {7c-7f ,  2c-2f, 3b-6b, 3g-6g } : 6L,2I => 96L,32I 4. for each 4 corners: 2L,6I => 8L, 24I 5. for each 8 positions {7a,8b , 8g,7h , 2h,1g , 1b,2a} : 3L,5I => 24L,40I 6. for each 16 positions  {3a-6a ,  3h-6h, 8c-8f, 1c-1f } : 4L,4I => 64L,64I }","Say a $8 \times 8$ chessboard as per picture. A position is represented here by co-ordinates $(x,y)$. A move is aslo considered as valid, where the Knight lands outside the chessboard  [   For eg. from $(3,2)$ towards $(3,1)$ but ends up outside chess-board.  ] But once outside, it can't come back. Question: Knight starts from $(0,0)$.  What is the Probability that a Knight stays on chessboard after N hops? Expected Solution: I don't want exact result like $ \frac{12}{64} $  but need your help on a. the thought/procedure/methodology to find it with b. A concluding formulae in terms of permutation/combination, Well my thought: After $(N-1)$th move, if the Kngiht is between $(x,y)$ where $3 \le x \le 6$ and $3 \le y \le 6$ then next move i.e $n$th move must ensure the knight will be within chessboard. Might be my thought is entirely wrong as it tries to find ""must be within chessboard"" In any $5 \times 5$ sub part with Knight in middle, it has $8$ possible moves. If initial position is $(0,0)$ out of those $8$ it has choice of $2$ only satisfying ""within chessboard"" constraint. Next move I am lost! Please help me think . Why cant we treat it like: a. The question is valid only if N-1 moves already done with the Knight on board.    b. Now to find Nth move s.t Knight hops out of board - say probability P(out)    c. 1 - P(out) now gives the answer { In Case b above we can use some stats like the following: Legal moves -> L      Illegal moves -> I 1. for 16 positions enclosed by {3c - 3f - 6c -6f} : 16 x 8 L 2. for each 4 positions {2b,2g,7b,7g} : 4L, 4I  =>  16L , 16I  3. for each 16 positions  {7c-7f ,  2c-2f, 3b-6b, 3g-6g } : 6L,2I => 96L,32I 4. for each 4 corners: 2L,6I => 8L, 24I 5. for each 8 positions {7a,8b , 8g,7h , 2h,1g , 1b,2a} : 3L,5I => 24L,40I 6. for each 16 positions  {3a-6a ,  3h-6h, 8c-8f, 1c-1f } : 4L,4I => 64L,64I }",,"['probability', 'combinatorics', 'statistics', 'recreational-mathematics']"
25,What is the most unfair set of three nontransitive dice?,What is the most unfair set of three nontransitive dice?,,"In a set nontransitive dice , each die is superior to another die, but is inferior to a third.  It is similar to the game of rock-paper-scissors.  Here is one example: die A has sides: 2, 2, 4, 4, 9, 9 die B has sides: 1, 1, 6, 6, 8, 8 die C has sides: 3, 3, 5, 5, 7, 7 Die A has a 5/9ths chance of rolling a higher number than B, which itself has a 5/9ths chance of rolling a higher number than C, which itself has a 5/9ths chance of rolling a higher number than A.  It is a circle with no overall winner. Suppose there is a simple dice game where one person picks a die from the set of three nontransitive dice. A second person then picks another die from the set.  The players then roll their dice, and the person who rolls the higher number wins.  If there is a tie, the players simply roll again until there is a winner. If this game is played with the above set of dice, then the second player will always be able to pick a superior die, and will win the game 5/9ths of the time. What is one possible set of nontransitive dice that maximizes the unfairness of this game?  One additional requirement is that the second player's odds of winning must not be affected by the first player's choice of die.","In a set nontransitive dice , each die is superior to another die, but is inferior to a third.  It is similar to the game of rock-paper-scissors.  Here is one example: die A has sides: 2, 2, 4, 4, 9, 9 die B has sides: 1, 1, 6, 6, 8, 8 die C has sides: 3, 3, 5, 5, 7, 7 Die A has a 5/9ths chance of rolling a higher number than B, which itself has a 5/9ths chance of rolling a higher number than C, which itself has a 5/9ths chance of rolling a higher number than A.  It is a circle with no overall winner. Suppose there is a simple dice game where one person picks a die from the set of three nontransitive dice. A second person then picks another die from the set.  The players then roll their dice, and the person who rolls the higher number wins.  If there is a tie, the players simply roll again until there is a winner. If this game is played with the above set of dice, then the second player will always be able to pick a superior die, and will win the game 5/9ths of the time. What is one possible set of nontransitive dice that maximizes the unfairness of this game?  One additional requirement is that the second player's odds of winning must not be affected by the first player's choice of die.",,"['probability', 'recreational-mathematics', 'dice']"
26,Probability of a random $n \times n$ matrix over $\mathbb F_2$ being nonsingular,Probability of a random  matrix over  being nonsingular,n \times n \mathbb F_2,"Given a random square matrix of size $n\times n$ in the field $\mathbb F_2$, what is the probability that its determinant is $1$? (This is also the probability that the matrix is non-singular, since $\mathbb F_2$ only has the elements $0$ and $1$.)","Given a random square matrix of size $n\times n$ in the field $\mathbb F_2$, what is the probability that its determinant is $1$? (This is also the probability that the matrix is non-singular, since $\mathbb F_2$ only has the elements $0$ and $1$.)",,"['probability', 'combinatorics', 'matrices', 'finite-fields', 'determinant']"
27,Probability of Sisyphus laboring forever,Probability of Sisyphus laboring forever,,"Zeus has decreed that Sisyphus must spend each day removing all the rocks in a certain valley and transferring them to Mount Olympus. Each night, each rock Sisyphus places on Mount Olympus is subject to the whims of Zeus: it will either be vaporized (with probability 10%), be rolled back down into the valley (with probability 50% ), or be split by a thunderbolt into two rocks that are both rolled down into the valley (with probability 40%). When the sun rises, Sisyphus returns to work, delivering rocks to Olympus. At sunrise on the first day of his punishment, there is only one rock in the valley and there are no rocks on Mount Olympus. What is the probability that Sisyphus must labor forever? I tried approaching this problem as a random walk, but the fact that if Sisyphus has more than one rock in the valley then there is a chance of increasing the number of rocks by more than one is throwing me off. Does anyone have any insight as to how to approch this kind of problem? Thanks!","Zeus has decreed that Sisyphus must spend each day removing all the rocks in a certain valley and transferring them to Mount Olympus. Each night, each rock Sisyphus places on Mount Olympus is subject to the whims of Zeus: it will either be vaporized (with probability 10%), be rolled back down into the valley (with probability 50% ), or be split by a thunderbolt into two rocks that are both rolled down into the valley (with probability 40%). When the sun rises, Sisyphus returns to work, delivering rocks to Olympus. At sunrise on the first day of his punishment, there is only one rock in the valley and there are no rocks on Mount Olympus. What is the probability that Sisyphus must labor forever? I tried approaching this problem as a random walk, but the fact that if Sisyphus has more than one rock in the valley then there is a chance of increasing the number of rocks by more than one is throwing me off. Does anyone have any insight as to how to approch this kind of problem? Thanks!",,"['probability', 'markov-process', 'random-walk']"
28,Coin Tossing Game Optimal Strategy,Coin Tossing Game Optimal Strategy,,"I was recently asked this question in an interview, but was completely stumped as to how to even begin answering it - it's been bugging me ever since, and I thought it was quite a nice question, so hopefully someone on here can help me out. Any help would be appreciated! Here goes: You start off with £100 and you toss a coin 100 times. Before each toss you choose a stake $S$ which cannot be more than your current balance $x$ (so your maximum stake for the first toss is £100). If the coin comes up heads, you win $2S$ and your new balance is $x+2S$. If it comes up tails, you lose your stake and have $x-S$. How do you choose your stake so as to maximise your expected winnings from the game, not including the initial balance? Cheers, Boris","I was recently asked this question in an interview, but was completely stumped as to how to even begin answering it - it's been bugging me ever since, and I thought it was quite a nice question, so hopefully someone on here can help me out. Any help would be appreciated! Here goes: You start off with £100 and you toss a coin 100 times. Before each toss you choose a stake $S$ which cannot be more than your current balance $x$ (so your maximum stake for the first toss is £100). If the coin comes up heads, you win $2S$ and your new balance is $x+2S$. If it comes up tails, you lose your stake and have $x-S$. How do you choose your stake so as to maximise your expected winnings from the game, not including the initial balance? Cheers, Boris",,['probability']
29,concentration of maximum of gaussians,concentration of maximum of gaussians,,"Let $X=(X_1,\ldots,X_n)$, where $X_i \sim N(0,1)$ are iid. I'm looking for a result (and a proof outline) on the concentration of the max abs value of these Gaussians, $\|X\|_\infty$. That is, some result of the form $P(\bigl | \|X\|_\infty -\sqrt{2\log (2n)}\bigr |>t)<o(t)$, where $o(t)$ is any reasonable function that goes to $0$ as $t$ gets large. I know these results: $E \|X\|_\infty \leq \sqrt{2 \log (2n)}$, $P(\|X\|_\infty \geq \sqrt{2 \log (2n)}+t)\leq 2\exp(-t^2 /2)$, which seems to be the ""right tail"" of the result I'm looking for.","Let $X=(X_1,\ldots,X_n)$, where $X_i \sim N(0,1)$ are iid. I'm looking for a result (and a proof outline) on the concentration of the max abs value of these Gaussians, $\|X\|_\infty$. That is, some result of the form $P(\bigl | \|X\|_\infty -\sqrt{2\log (2n)}\bigr |>t)<o(t)$, where $o(t)$ is any reasonable function that goes to $0$ as $t$ gets large. I know these results: $E \|X\|_\infty \leq \sqrt{2 \log (2n)}$, $P(\|X\|_\infty \geq \sqrt{2 \log (2n)}+t)\leq 2\exp(-t^2 /2)$, which seems to be the ""right tail"" of the result I'm looking for.",,"['probability', 'statistics', 'normal-distribution']"
30,Distribution of Difference of Chi-squared Variables,Distribution of Difference of Chi-squared Variables,,"I am trying to get the probability distribution function of $Z=X-Y$. Given that $f_X(x)$ and $f_Y(y)$ are known, and both variables are chi-square distributed, $X\in\mathbb{R}$, $X\ge 0$, and similarly $Y\in\mathbb{R}$, $Y\ge 0$. So how can I get $f_Z(z)$.","I am trying to get the probability distribution function of $Z=X-Y$. Given that $f_X(x)$ and $f_Y(y)$ are known, and both variables are chi-square distributed, $X\in\mathbb{R}$, $X\ge 0$, and similarly $Y\in\mathbb{R}$, $Y\ge 0$. So how can I get $f_Z(z)$.",,"['probability', 'probability-distributions']"
31,Powers of random matrices,Powers of random matrices,,"Let $M$ be an $n \times n$ matrix whose elements are random reals in [0,1]. Two questions. What is the growth rate of the magnitude of the elements of $M^k$ as a function of $k$?  It is definitely exponential, but maybe the exponent is known? Is it the case that eventually one element of $M^k$ dominates, as $k \rightarrow \infty$? I have some ambiguous experimental evidence that this is the case, but because of the exponential growth, exact computation is difficult, rendering my ""evidence"" tenuous at best and perhaps worthless. One can ask the same question for matrices whose elements are random reals in [-1,1], or random 0's and 1's, or random choices among $\lbrace -1, 0, 1\rbrace$, ... These question have likely been studied.  Thanks for pointers and/or ideas!","Let $M$ be an $n \times n$ matrix whose elements are random reals in [0,1]. Two questions. What is the growth rate of the magnitude of the elements of $M^k$ as a function of $k$?  It is definitely exponential, but maybe the exponent is known? Is it the case that eventually one element of $M^k$ dominates, as $k \rightarrow \infty$? I have some ambiguous experimental evidence that this is the case, but because of the exponential growth, exact computation is difficult, rendering my ""evidence"" tenuous at best and perhaps worthless. One can ask the same question for matrices whose elements are random reals in [-1,1], or random 0's and 1's, or random choices among $\lbrace -1, 0, 1\rbrace$, ... These question have likely been studied.  Thanks for pointers and/or ideas!",,"['probability', 'reference-request', 'matrices', 'random']"
32,What's the difference between marginal distribution and conditional probability distribution?,What's the difference between marginal distribution and conditional probability distribution?,,"My understanding of both starts with this model: which has two random variables whose individual distributions are shown in red and blue, and their join distribution shown in green. I'm comfortable with the idea of using discrete math to take subsets of the tuples in the joint distribution, then using those subsets as the domain for various functions ( vis. functions that give probabilities and calculate statistics ). Then, amongst those functions we have two kinds in particular that have names: the marginal distribution functions and conditional probability distribution functions. My current understanding is that conditional probability distribution functions take a subset of tuples that range over both features of the tuple--x and y, say. You'll use conditional probability distribution functions to calculate probabilities given some subset of x and some subset of y. Then, my current understanding of marginal distribution functions is that they do the same thing as conditional probability distribution functions, but lock one of the features down to a specific value. Is that correct? I know I'm not using the standard set of jargon, but--I'm coming to statistics from pure math and computer science. So, forgive me while I try to connect one domain to another in my head.","My understanding of both starts with this model: which has two random variables whose individual distributions are shown in red and blue, and their join distribution shown in green. I'm comfortable with the idea of using discrete math to take subsets of the tuples in the joint distribution, then using those subsets as the domain for various functions ( vis. functions that give probabilities and calculate statistics ). Then, amongst those functions we have two kinds in particular that have names: the marginal distribution functions and conditional probability distribution functions. My current understanding is that conditional probability distribution functions take a subset of tuples that range over both features of the tuple--x and y, say. You'll use conditional probability distribution functions to calculate probabilities given some subset of x and some subset of y. Then, my current understanding of marginal distribution functions is that they do the same thing as conditional probability distribution functions, but lock one of the features down to a specific value. Is that correct? I know I'm not using the standard set of jargon, but--I'm coming to statistics from pure math and computer science. So, forgive me while I try to connect one domain to another in my head.",,"['probability', 'statistics', 'multivariable-calculus', 'probability-distributions']"
33,Convergence in law and uniformly integrability,Convergence in law and uniformly integrability,,"I'm looking for an elementary way of showing the following. If $(X_n)$ and $X$ are random variables such that $X_n \to X$ in distribution and such that $\{X_n\mid n\geq 1\}$ are uniformly integrable, then $E[X_n]\to E[X]$. I've seen another topic on this, but the solution given there is using Skorokhod's theorem stating that convergence in distribution is equivalent to almost-sure convergence of copies of the random variables in some abstract probability space. I would like to do without that if possible. Thanks in advance!","I'm looking for an elementary way of showing the following. If $(X_n)$ and $X$ are random variables such that $X_n \to X$ in distribution and such that $\{X_n\mid n\geq 1\}$ are uniformly integrable, then $E[X_n]\to E[X]$. I've seen another topic on this, but the solution given there is using Skorokhod's theorem stating that convergence in distribution is equivalent to almost-sure convergence of copies of the random variables in some abstract probability space. I would like to do without that if possible. Thanks in advance!",,"['probability', 'probability-theory']"
34,Default positive/(non-negative) probability distribution,Default positive/(non-negative) probability distribution,,"So if you have a random variable that corresponds to a natural phenomenon and you don't know how it is distributed, you often assume it is normally distributed. Now I have a random value that I know is strictly positive, what is the ""default"" assumed probability distribution for these kind of variables? My specific case is the volume of air that a human breathes per a random unit of time, which fluctuates from time to time, thus being random if I don't know how it fluctuates. One can easily conclude this number to be strictly positive, since zero means you would be dead, and negative values would be some sort of reverse breathing (photosynthesis maybe? Hehe).","So if you have a random variable that corresponds to a natural phenomenon and you don't know how it is distributed, you often assume it is normally distributed. Now I have a random value that I know is strictly positive, what is the ""default"" assumed probability distribution for these kind of variables? My specific case is the volume of air that a human breathes per a random unit of time, which fluctuates from time to time, thus being random if I don't know how it fluctuates. One can easily conclude this number to be strictly positive, since zero means you would be dead, and negative values would be some sort of reverse breathing (photosynthesis maybe? Hehe).",,"['probability', 'statistics', 'probability-distributions']"
35,What is the expected value of this game for large N?,What is the expected value of this game for large N?,,"For a given even $N$ , I have $N/2$ red cards and $N/2$ black cards. Each time I draw a black card I win a dollar, each time I draw a red card I lose a dollar.  I can stop at any time I like (and choose to do so in such a way that would maximize my expected winnings). What is the expected value of the game for large $N$ ? For a simple example, when $N=2$ - I would draw a card and if it's red, I would draw again (to get value of $0$ ), and if it's black I would stop, resulting in expected value of $0.5$ . To clarify, I know how to compute this numerically. I'm interested in the functional form for large $N$ . For what it is worth, from simulations it appears to be ${\cal O}(\sqrt{N})$ .","For a given even , I have red cards and black cards. Each time I draw a black card I win a dollar, each time I draw a red card I lose a dollar.  I can stop at any time I like (and choose to do so in such a way that would maximize my expected winnings). What is the expected value of the game for large ? For a simple example, when - I would draw a card and if it's red, I would draw again (to get value of ), and if it's black I would stop, resulting in expected value of . To clarify, I know how to compute this numerically. I'm interested in the functional form for large . For what it is worth, from simulations it appears to be .",N N/2 N/2 N N=2 0 0.5 N {\cal O}(\sqrt{N}),"['probability', 'asymptotics', 'expected-value']"
36,Find the area of the region enclosed by $\frac{\sin x}{\sin y}=\frac{\sin x+\sin y}{\sin(x+y)}$ and the $x$-axis.,Find the area of the region enclosed by  and the -axis.,\frac{\sin x}{\sin y}=\frac{\sin x+\sin y}{\sin(x+y)} x,"Here is the graph of $\dfrac{\sin x}{\sin y}=\dfrac{\sin x+\sin y}{\sin(x+y)}$ . Find the area of the region enclosed by the curve and the $x$ -axis, from $x=0$ to $x=\pi$ . Where the question came from, and why I think the answer is $\dfrac{\pi^2}{8}$ This question arose when I asked myself: ""A triangle's vertices are three uniformly random points on a circle. The side lengths are, in random order, $a,b,c$ . The triangle inequality tells us that $P(a+b<c)=0$ . But  what is $P\left(a+b<\left(\frac{a}{b}\right)c\right)$ , given that $\frac{a}{b}>1$ ?"" (These kinds of questions often have rational probabilities, for example $P(ab<c^2)=\frac35$ as shown here ; $P(\frac1a+\frac1b<\frac1c)=\frac15$ as shown here ; for a unit circle $P(ab<c)=\frac12$ as shown here .) I assumed that the circle is centred at the origin, and the vertices of the triangle are: $A\space(\cos(-2y),\sin(-2y))$ where $0\le y<\pi$ $B\space(\cos(2x),\sin(2x))$ where $0\le x<\pi$ $C\space(1,0)$ I let: $a=BC=2\sin x$ $b=AC=2\sin y$ $c=AB=|2\sin(x+y)|$ By symmetry, we only need to consider the region where $x+y<\pi$ , so we can drop the modulus signs. $P\left(a+b<\left(\frac{a}{b}\right)c\right)=P\left(\color{red}{\dfrac{\sin x}{\sin y}>\dfrac{\sin x+\sin y}{\sin(x+y)}}\right)$ Then I tried to express $y$ in terms of $x$ , or $x$ in terms of $y$ (so that I could get an integral), but I failed. Wolfram is not helpful . I rotated the graph $45^\circ$ by letting $x\to x-y$ and $y\to x+y$ , which gives $\frac{\tan x}{\tan y}=\frac{\cos x+\cos y}{\cos x-\cos y}$ , but I still couldn't isolate $x$ or $y$ . Wolfram is still not helpful . A simulation of $10^7$ random triangles yielded a proportion of $0.49998$ satisfying $a+b<\frac{ac}{b}$ given that $\frac{a}{b}>1$ , suggesting that the probability is $\frac12$ . If so, then the area of the shaded region should be $\frac12\times\frac{\pi^2}{4}=\color{red}{\frac{\pi^2}{8}}\approx1.2337$ . (Now I am more interested in this area question, than the probability question.) Update 1 Using the Wolfram link in @Masd's answer, I made a desmos graph of $y$ as a function of $x$ . It looks just like the original curve, except it has gaps that I have been unable to bridge. Here is the link to my desmos graph. If someone can bridge the gaps, then we can use desmos to integrate from $x=0$ to $x=\pi$ , and see if the area could be $\frac{\pi^2}{8}$ . Update 2 @Masd's answer now reports a numerical integral of $1.23370055014$ , which matches $\frac{\pi^2}{8}$ to $11$ decimal places. Is there a proof that the area is exactly $\frac{\pi^2}{8}$ ?","Here is the graph of . Find the area of the region enclosed by the curve and the -axis, from to . Where the question came from, and why I think the answer is This question arose when I asked myself: ""A triangle's vertices are three uniformly random points on a circle. The side lengths are, in random order, . The triangle inequality tells us that . But  what is , given that ?"" (These kinds of questions often have rational probabilities, for example as shown here ; as shown here ; for a unit circle as shown here .) I assumed that the circle is centred at the origin, and the vertices of the triangle are: where where I let: By symmetry, we only need to consider the region where , so we can drop the modulus signs. Then I tried to express in terms of , or in terms of (so that I could get an integral), but I failed. Wolfram is not helpful . I rotated the graph by letting and , which gives , but I still couldn't isolate or . Wolfram is still not helpful . A simulation of random triangles yielded a proportion of satisfying given that , suggesting that the probability is . If so, then the area of the shaded region should be . (Now I am more interested in this area question, than the probability question.) Update 1 Using the Wolfram link in @Masd's answer, I made a desmos graph of as a function of . It looks just like the original curve, except it has gaps that I have been unable to bridge. Here is the link to my desmos graph. If someone can bridge the gaps, then we can use desmos to integrate from to , and see if the area could be . Update 2 @Masd's answer now reports a numerical integral of , which matches to decimal places. Is there a proof that the area is exactly ?","\dfrac{\sin x}{\sin y}=\dfrac{\sin x+\sin y}{\sin(x+y)} x x=0 x=\pi \dfrac{\pi^2}{8} a,b,c P(a+b<c)=0 P\left(a+b<\left(\frac{a}{b}\right)c\right) \frac{a}{b}>1 P(ab<c^2)=\frac35 P(\frac1a+\frac1b<\frac1c)=\frac15 P(ab<c)=\frac12 A\space(\cos(-2y),\sin(-2y)) 0\le y<\pi B\space(\cos(2x),\sin(2x)) 0\le x<\pi C\space(1,0) a=BC=2\sin x b=AC=2\sin y c=AB=|2\sin(x+y)| x+y<\pi P\left(a+b<\left(\frac{a}{b}\right)c\right)=P\left(\color{red}{\dfrac{\sin x}{\sin y}>\dfrac{\sin x+\sin y}{\sin(x+y)}}\right) y x x y 45^\circ x\to x-y y\to x+y \frac{\tan x}{\tan y}=\frac{\cos x+\cos y}{\cos x-\cos y} x y 10^7 0.49998 a+b<\frac{ac}{b} \frac{a}{b}>1 \frac12 \frac12\times\frac{\pi^2}{4}=\color{red}{\frac{\pi^2}{8}}\approx1.2337 y x x=0 x=\pi \frac{\pi^2}{8} 1.23370055014 \frac{\pi^2}{8} 11 \frac{\pi^2}{8}","['probability', 'integration', 'definite-integrals', 'triangles', 'geometric-probability']"
37,Probability questions that have answer $\frac{1}{2}$ but resist intuitive explanation.,Probability questions that have answer  but resist intuitive explanation.,\frac{1}{2},"My question is: What are some examples of probability questions that have answer $\frac{1}{2}$ but resist intuitive explanation? Context Some probability questions have answer $\frac{1}{2}$ , and - as you might expect - have an intuitive explanation, i.e. an explanation that requires little calculation, instead utilizing a clever framing of the question that makes the answer obvious. For example: ""Flip seven unbiased coins; what is the probability of getting at least four heads?"" Some people will calculate $P=\frac{\binom{7}{4}+\binom{7}{5}+\binom{7}{6}+\binom{7}{7}}{2^7}=\frac{35+21+7+1}{128}=\frac{64}{128}=\frac{1}{2}$ , but there is an intuitive explanation: getting at least four heads means getting more heads than tails, which, by symmetry, has probability $\frac{1}{2}$ . Another example: Taking Seats on a Plane and its intuitive explanation . Another example, this one about geometric probability: ""Break a stick at two random points. The probability that the longest piece is at least twice as long as each of the other pieces is $\frac{1}{2}$ . Why?"" Here is a (somewhat) intuitive explanation. On the other hand, I have found that some probability questions have answer $\frac{1}{2}$ but do not seem to have an intuitive explanation . For example: The vertices of a triangle are three random points on a unit circle. The side lengths are $a,b,c$ . Show that $P(ab>c)=\frac{1}{2}$ . ( Update : Several explanations, of varying degrees of intuitiveness, have been given here . Draw tangents at 3 random points on a circle to form a triangle. Show that the probability that a random side is shorter than the diameter is $\frac{1}{2}$ . ( Update : An intuitive explanation has been given here .) Intuition is silent: Find the probability that the smallest circle enclosing $n$ random points on a disk lies completely on the disk, as $n\to\infty$ . Break a stick at $n$ random points. What is the probability that the three shortest pieces can form a triangle, as $n\to\infty$ ? I find these later kinds of questions interesting, because the answer, $\frac{1}{2}$ , is the simplest probability of all (unless you count $0$ or $1$ , but those are sort of degenerate), but there does not seem to be a simple explanation. It's as if the question is making fun of us: ""You can't find an elegant solution!"" Or maybe there is no elegant solution, and the answer is $\frac12$ by coincidence. I would be interested in more of these kinds of questions (they don't have to be related to geometry). Remarks I require that the answer is exactly $\frac{1}{2}$ , not any other number, to avoid a slippery slope of what numbers are acceptable. Let's avoid ad hoc questions, for example: ""Find the probability that two uniformly random points inside a unit square are within $d$ distance of each other, where $d$ is the smallest positive root of $\frac12x^4-\frac83x^3+\pi x^2-\frac12=0$ ( $d\approx0.5120$ )."" The answer is $\frac12$ because $d$ is the median distance. Obviously anyone asking this question already knows that the answer is $\frac12$ . I am using the ""big-list"" tag, whose description reads ""Questions asking for a ""big list"" of examples, illustrations, etc. Ask only when the topic is compelling..."" I think my question might provide some insight on probability and intuition.","My question is: What are some examples of probability questions that have answer but resist intuitive explanation? Context Some probability questions have answer , and - as you might expect - have an intuitive explanation, i.e. an explanation that requires little calculation, instead utilizing a clever framing of the question that makes the answer obvious. For example: ""Flip seven unbiased coins; what is the probability of getting at least four heads?"" Some people will calculate , but there is an intuitive explanation: getting at least four heads means getting more heads than tails, which, by symmetry, has probability . Another example: Taking Seats on a Plane and its intuitive explanation . Another example, this one about geometric probability: ""Break a stick at two random points. The probability that the longest piece is at least twice as long as each of the other pieces is . Why?"" Here is a (somewhat) intuitive explanation. On the other hand, I have found that some probability questions have answer but do not seem to have an intuitive explanation . For example: The vertices of a triangle are three random points on a unit circle. The side lengths are . Show that . ( Update : Several explanations, of varying degrees of intuitiveness, have been given here . Draw tangents at 3 random points on a circle to form a triangle. Show that the probability that a random side is shorter than the diameter is . ( Update : An intuitive explanation has been given here .) Intuition is silent: Find the probability that the smallest circle enclosing random points on a disk lies completely on the disk, as . Break a stick at random points. What is the probability that the three shortest pieces can form a triangle, as ? I find these later kinds of questions interesting, because the answer, , is the simplest probability of all (unless you count or , but those are sort of degenerate), but there does not seem to be a simple explanation. It's as if the question is making fun of us: ""You can't find an elegant solution!"" Or maybe there is no elegant solution, and the answer is by coincidence. I would be interested in more of these kinds of questions (they don't have to be related to geometry). Remarks I require that the answer is exactly , not any other number, to avoid a slippery slope of what numbers are acceptable. Let's avoid ad hoc questions, for example: ""Find the probability that two uniformly random points inside a unit square are within distance of each other, where is the smallest positive root of ( )."" The answer is because is the median distance. Obviously anyone asking this question already knows that the answer is . I am using the ""big-list"" tag, whose description reads ""Questions asking for a ""big list"" of examples, illustrations, etc. Ask only when the topic is compelling..."" I think my question might provide some insight on probability and intuition.","\frac{1}{2} \frac{1}{2} P=\frac{\binom{7}{4}+\binom{7}{5}+\binom{7}{6}+\binom{7}{7}}{2^7}=\frac{35+21+7+1}{128}=\frac{64}{128}=\frac{1}{2} \frac{1}{2} \frac{1}{2} \frac{1}{2} a,b,c P(ab>c)=\frac{1}{2} \frac{1}{2} n n\to\infty n n\to\infty \frac{1}{2} 0 1 \frac12 \frac{1}{2} d d \frac12x^4-\frac83x^3+\pi x^2-\frac12=0 d\approx0.5120 \frac12 d \frac12","['probability', 'intuition', 'big-list', 'geometric-probability']"
38,Examples of universal constructions in probability theory,Examples of universal constructions in probability theory,,"I am looking for more examples of universal constructions in probability theory. Like the construction a of Gaussian space from a real Hilbert space, or a Poisson jump process from a measurable space with a $\sigma$-finite measure. There must be tons of examples, even though their universality (in the sense of category theory) is probably not commonly emphasized.","I am looking for more examples of universal constructions in probability theory. Like the construction a of Gaussian space from a real Hilbert space, or a Poisson jump process from a measurable space with a $\sigma$-finite measure. There must be tons of examples, even though their universality (in the sense of category theory) is probably not commonly emphasized.",,"['probability', 'category-theory', 'examples-counterexamples']"
39,How exactly are the beta and gamma distributions related?,How exactly are the beta and gamma distributions related?,,"According to Wikipedia, the Beta distribution is related to the gamma distribution by the following relation: $$\lim_{n\to\infty}n B(k, n) = \Gamma(k, 1)$$ Can you point me to a derivation of this fact? Can it be generalized? For example, is there a similar relation that results in something other than a constant 1 for the Gamma second parameter? What if we have $$\lim_{n\to\infty,m\to\infty,n=mb}n B(k, m) $$ That is, the two variables go to infinity while maintaining a constant ratio b. The reason I'm asking is because I'm trying to figure out how to simplify a hieraerchical bayesian model involving the beta distribution. (This is my first post; sorry for the math notation, the MathJaX syntax was too daunting, but I'll try to learn)","According to Wikipedia, the Beta distribution is related to the gamma distribution by the following relation: $$\lim_{n\to\infty}n B(k, n) = \Gamma(k, 1)$$ Can you point me to a derivation of this fact? Can it be generalized? For example, is there a similar relation that results in something other than a constant 1 for the Gamma second parameter? What if we have $$\lim_{n\to\infty,m\to\infty,n=mb}n B(k, m) $$ That is, the two variables go to infinity while maintaining a constant ratio b. The reason I'm asking is because I'm trying to figure out how to simplify a hieraerchical bayesian model involving the beta distribution. (This is my first post; sorry for the math notation, the MathJaX syntax was too daunting, but I'll try to learn)",,"['probability', 'probability-distributions']"
40,"1/1000 chance of a reaction. If you do the action 1000 times, whats the new chance the reaction occurs?","1/1000 chance of a reaction. If you do the action 1000 times, whats the new chance the reaction occurs?",,"A hypothetical example: You have a 1/1000 chance of being hit by a bus when crossing the street.   However, if you perform the action of crossing the street 1000 times, then your chance of being hit by a bus increases to about 60% because every time you do the action, the probability of it happening again increases. What is the math behind this to support this? Just curious.","A hypothetical example: You have a 1/1000 chance of being hit by a bus when crossing the street.   However, if you perform the action of crossing the street 1000 times, then your chance of being hit by a bus increases to about 60% because every time you do the action, the probability of it happening again increases. What is the math behind this to support this? Just curious.",,"['probability', 'statistics', 'percentages']"
41,$66$ points in $100$ shots.,points in  shots.,66 100,"I just received a probability problem from a friend via a text and by the time I took to read it, I was sent a solution as well - which is confusing.. The question goes like this.. A person shoots basketball 100 times. First time he scores a point and second time he misses it. For the following shots, the probability of him scoring a point is equal to number of points scored before this shot divided by number of shots taken before this shot, for ex: if he is into his 21st shot and he has scored 13 points in the first 20 shots then the probability of him scoring in 21st shot is 13/20. What is the probability of scoring 66 points in the 100 shots (including the first two) The confusing solution: $\dfrac1{(n-1)} \ge \dfrac1{99}$ Can someone please explain the logic behind this?","I just received a probability problem from a friend via a text and by the time I took to read it, I was sent a solution as well - which is confusing.. The question goes like this.. A person shoots basketball 100 times. First time he scores a point and second time he misses it. For the following shots, the probability of him scoring a point is equal to number of points scored before this shot divided by number of shots taken before this shot, for ex: if he is into his 21st shot and he has scored 13 points in the first 20 shots then the probability of him scoring in 21st shot is 13/20. What is the probability of scoring 66 points in the 100 shots (including the first two) The confusing solution: $\dfrac1{(n-1)} \ge \dfrac1{99}$ Can someone please explain the logic behind this?",,"['probability', 'probability-distributions', 'recreational-mathematics']"
42,Expectation on 1/X,Expectation on 1/X,,In general can one say that for a random variable X: $E[\frac{1}{X}] = \frac{1}{E[X]}$ ? I've worked out a few examples where this works but I'm not sure how widely this is useful...,In general can one say that for a random variable X: $E[\frac{1}{X}] = \frac{1}{E[X]}$ ? I've worked out a few examples where this works but I'm not sure how widely this is useful...,,['probability']
43,Sum of $4$ dice rolls greater than the product,Sum of  dice rolls greater than the product,4,"Let us roll a fair die $4$ independent times, and denote the outcomes as $X_1, X_2, X_3$ and $X_4$. What is the probability of $X_1+X_2+ X_3+X_4 > X_1X_2 X_3X_4$? My try: I could get the answer for $2$ rolling case by enumerating possibilities, but couldn't get this larger problem. Can someone help me with this? Thanks in advance for any help!","Let us roll a fair die $4$ independent times, and denote the outcomes as $X_1, X_2, X_3$ and $X_4$. What is the probability of $X_1+X_2+ X_3+X_4 > X_1X_2 X_3X_4$? My try: I could get the answer for $2$ rolling case by enumerating possibilities, but couldn't get this larger problem. Can someone help me with this? Thanks in advance for any help!",,"['probability', 'combinatorics', 'dice']"
44,Probability notation two numbers stacked inside brackets,Probability notation two numbers stacked inside brackets,,I have a very simple question. Could someone elaborate on the notation of two numbers stacked inside brackets? Such as: $$         \begin{pmatrix}         5 \\         1 \\         \end{pmatrix} $$,I have a very simple question. Could someone elaborate on the notation of two numbers stacked inside brackets? Such as: $$         \begin{pmatrix}         5 \\         1 \\         \end{pmatrix} $$,,"['probability', 'combinatorics', 'notation', 'binomial-coefficients']"
45,Book on combinatorial identities,Book on combinatorial identities,,"Do you know any good book that deals extensively with identities obtained using combinatorial and/or probabilistic arguments (e.g., by solving the same combinatorial or probability problem in two different ways)?","Do you know any good book that deals extensively with identities obtained using combinatorial and/or probabilistic arguments (e.g., by solving the same combinatorial or probability problem in two different ways)?",,"['probability', 'combinatorics', 'reference-request', 'book-recommendation']"
46,Probability: Are disjoint events independent? [duplicate],Probability: Are disjoint events independent? [duplicate],,"This question already has answers here : Independence of disjoint events with strictly positive probability (2 answers) Closed 7 years ago . I just read that disjoint events, A, B, if, $\mathbb{P}(AB) = 0$ are independent. This really frustrates me. My teacher stated otherwise - $\mathbb{P}(AB) = 0 \iff A \cap B = \emptyset \implies \mathbb{P}(AB) = 0 \ne \mathbb{P}(A)\mathbb{P}(B)$ because $\mathbb{P}(A)$ and $\mathbb{P}(B)$ are not empty (does the latter come from the definition of independent events?). Could somebody clear this for me?","This question already has answers here : Independence of disjoint events with strictly positive probability (2 answers) Closed 7 years ago . I just read that disjoint events, A, B, if, are independent. This really frustrates me. My teacher stated otherwise - because and are not empty (does the latter come from the definition of independent events?). Could somebody clear this for me?",\mathbb{P}(AB) = 0 \mathbb{P}(AB) = 0 \iff A \cap B = \emptyset \implies \mathbb{P}(AB) = 0 \ne \mathbb{P}(A)\mathbb{P}(B) \mathbb{P}(A) \mathbb{P}(B),['probability']
47,Why can 2 uncorrelated random variables be dependent?,Why can 2 uncorrelated random variables be dependent?,,"I recently learned that two independent random variables $X$ and $Y$ must have a covariance of $0$ . That means that the correlation between them is also $0$ . However, apparently, the converse is not true. 2 random variables $X$ and $Y$ can have a correlation of $0$ , yet still be dependent. I don't understand why this is. Doesn't a correlation of $0$ imply that the random variables do not affect each other?","I recently learned that two independent random variables and must have a covariance of . That means that the correlation between them is also . However, apparently, the converse is not true. 2 random variables and can have a correlation of , yet still be dependent. I don't understand why this is. Doesn't a correlation of imply that the random variables do not affect each other?",X Y 0 0 X Y 0 0,['probability']
48,The Marginal Distribution of a Multinomial,The Marginal Distribution of a Multinomial,,"The binomial distribution is generalized by the multinomial distribution, which follows: \begin{align} f(x_1,\ldots,x_k;n,p_1,\ldots,p_k) & {} = \Pr(X_1 = x_1\mbox{ and }\dots\mbox{ and }X_k = x_k) \\  \\ & {} = \begin{cases} { \displaystyle {n! \over x_1!\cdots x_k!}p_1^{x_1}\cdots p_k^{x_k}}, \quad & \mbox{when } \sum_{i=1}^k x_i=n \\  \\ 0 & \mbox{otherwise,} \end{cases} \end{align} In particular, the ""three""nomial distribution follows: $${n! \over x_1! x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}p_3^{n-x_1-x_2}$$ I am not able to show why the marginal probability of this distribution, with respect to either $x_1$ or $x_2$ follows $b(n, p_1)$ or $b(n, p_2)$, respectively. Please help!","The binomial distribution is generalized by the multinomial distribution, which follows: \begin{align} f(x_1,\ldots,x_k;n,p_1,\ldots,p_k) & {} = \Pr(X_1 = x_1\mbox{ and }\dots\mbox{ and }X_k = x_k) \\  \\ & {} = \begin{cases} { \displaystyle {n! \over x_1!\cdots x_k!}p_1^{x_1}\cdots p_k^{x_k}}, \quad & \mbox{when } \sum_{i=1}^k x_i=n \\  \\ 0 & \mbox{otherwise,} \end{cases} \end{align} In particular, the ""three""nomial distribution follows: $${n! \over x_1! x_2!(n-x_1-x_2)!}p_1^{x_1}p_2^{x_2}p_3^{n-x_1-x_2}$$ I am not able to show why the marginal probability of this distribution, with respect to either $x_1$ or $x_2$ follows $b(n, p_1)$ or $b(n, p_2)$, respectively. Please help!",,"['probability', 'probability-distributions']"
49,Is probability determined by perspective?,Is probability determined by perspective?,,"My question: is probability determined by perspective? The scenario that raised the question for me: Initial condition: The Monty Hall problem.  We know the contestant’s original choice of door #1 (of 3 total) is only correct 33% of the time.  After Monty Hall reveals door #3 is incorrect the contestant is asked if he would like to switch his answer to door #2.  We know he should choose to change his answer to the other unopened door (#2) which has a 66% chance of being correct.  He does so. However, let’s say once he decided to switch to door #2, and before either door is revealed, another contestant enters the room.  She does not have any knowledge of what has just transpired on stage.  She is offered a choice to pick which door the car behind of the 2 remains closed doors and also randomly chooses door #2. Are the probabilities of being correct different for each contestant?  Seemingly they are.  Contestant 1 had 3 doors to choose from, giving him a probability of 33% that door #1 is the answer.  Contestant 2 only had 2 doors to choose from, giving her a probability of 50% after choosing the same door contestant #1 choose. If we repeat the experiment 1000 times, what will the numbers turn out to be for door #1?  333 or 500?","My question: is probability determined by perspective? The scenario that raised the question for me: Initial condition: The Monty Hall problem.  We know the contestant’s original choice of door #1 (of 3 total) is only correct 33% of the time.  After Monty Hall reveals door #3 is incorrect the contestant is asked if he would like to switch his answer to door #2.  We know he should choose to change his answer to the other unopened door (#2) which has a 66% chance of being correct.  He does so. However, let’s say once he decided to switch to door #2, and before either door is revealed, another contestant enters the room.  She does not have any knowledge of what has just transpired on stage.  She is offered a choice to pick which door the car behind of the 2 remains closed doors and also randomly chooses door #2. Are the probabilities of being correct different for each contestant?  Seemingly they are.  Contestant 1 had 3 doors to choose from, giving him a probability of 33% that door #1 is the answer.  Contestant 2 only had 2 doors to choose from, giving her a probability of 50% after choosing the same door contestant #1 choose. If we repeat the experiment 1000 times, what will the numbers turn out to be for door #1?  333 or 500?",,['probability']
50,Prove complements of independent events are independent.,Prove complements of independent events are independent.,,"Given a finite set of events $\{A_i\}$ which are mutually independent, i.e., for every subset $\{A_n\}$,  $$\mathrm{P}\left(\bigcap_{i=1}^n A_i\right)=\prod_{i=1}^n \mathrm{P}(A_i).$$ show that the set $\{A_i^c\}$, that is the set of complements of the original events, is also mutually independent. I can prove this, but my proof relies on the Inclusion-Exclusion principle (as does the proof given in this question ). I'm hoping there is a more concise proof. Can this statement be proved without the use of the Inclusion-Exclusion principle?","Given a finite set of events $\{A_i\}$ which are mutually independent, i.e., for every subset $\{A_n\}$,  $$\mathrm{P}\left(\bigcap_{i=1}^n A_i\right)=\prod_{i=1}^n \mathrm{P}(A_i).$$ show that the set $\{A_i^c\}$, that is the set of complements of the original events, is also mutually independent. I can prove this, but my proof relies on the Inclusion-Exclusion principle (as does the proof given in this question ). I'm hoping there is a more concise proof. Can this statement be proved without the use of the Inclusion-Exclusion principle?",,['probability']
51,Calculating the probability that at least one of a series of events will happen,Calculating the probability that at least one of a series of events will happen,,"I want to calculate the probability of at least one event happening in a series of multiple events. For example, let's say the probability of each event happening are: Event 1: 2/21 Event 2: 1/10 Event 3: 7/15 Event 4: 9/16 Event 5: 3/10 What is the probability that at least one of these events will happen? EDIT: Assume all events are independent.","I want to calculate the probability of at least one event happening in a series of multiple events. For example, let's say the probability of each event happening are: Event 1: 2/21 Event 2: 1/10 Event 3: 7/15 Event 4: 9/16 Event 5: 3/10 What is the probability that at least one of these events will happen? EDIT: Assume all events are independent.",,['probability']
52,Finding expected number of distinct values selected from a set of integers [duplicate],Finding expected number of distinct values selected from a set of integers [duplicate],,"This question already has answers here : How many bins do random numbers fill? (2 answers) Closed last year . I have a set of $n$ integers $\{1, . . . , n\}$, and I select three values with replacement. How can I find the expected number of distinct values? Note each value is chosen uniformly and independently.","This question already has answers here : How many bins do random numbers fill? (2 answers) Closed last year . I have a set of $n$ integers $\{1, . . . , n\}$, and I select three values with replacement. How can I find the expected number of distinct values? Note each value is chosen uniformly and independently.",,"['probability', 'statistics']"
53,What does the $-\log[P(X)]$ term mean in the calculation of entropy?,What does the  term mean in the calculation of entropy?,-\log[P(X)],"The entropy (self information) of a discrete random variable X is calculated as: $$ H(x)=E(-\log[P(X)]) $$ What does the $-\log[P(X)]$ mean? It seems to be something like """" the self information of each possible outcome of the random variable X "". And why do we use log function to calculate it? ADD 1 Well, below is my reasoning: The root motivation is to quantify/measure the uncertainty contained in a random variable. Intuitively , people tend to agree that there's some connection between uncertainty and probability . And still intuitively , people shall agree that: the more probability an outcome has, the less uncertainty it has. thus , the less probability an outcome has, the more uncertainty it has. So, I think if we want to measure the uncertainty for an outcome of a random variable, the measure function should satisfy: the value of uncertainty measure should be positive ( human instinct when counting ) the value of this measure for the uncertainty of an outcome should be monotonic decreasing function of the probability of that outcome. for outcomes of independent experiments, the uncertainty should be additive. That is for P(A)*P(B), the total uncertainty should be the sum of A's and B's. ( This is kind of instinctive, too. ) Then I come to the choice of -log[p(i)] as the measure of uncertainty of each possible outcome , or self-information of each outcome. Then I treat the entropy as the weighted average of the self-information of all possible outcomes. I just read the book < Information Theory, Inference and Learning Algorithms > by MacKay. The author indeed gives a similar explanation to mine. And he name it the information content of each outcome . It is not difficult to see that entropy better describes a random variable than the information content . And it is coincidental that the formula we intuitively found to measure the average information content of a random variable has a similar form to the one of entropy in thermodynamics . Thus comes the name information entropy ... BTW I want to quote some words from Einstein... ""It is not so important where one settles down. The best thing is to follow your instincts without too much reflection."" --Einstein to Max Born, March 3, 1920. AEA 8-146 ADD 2 Following my above reasoning, I tried to derive the calculation of entropy for a continuous random variable Y in a similar way. But I was blocked . Details below. Let Y's p.d.f be: $$f(y)$$ Then, if we strictly follow my previous reasoning, then we should pick up a small interval of I , and the probability of Y within interval I is given by: $$P(y\ within\ I)=\int_If(y)dy$$ Then the measure of uncertainty for Y to fall in interval I should be: $$m(y\ within\ I) = -log\int_If(y)dy$$ Then, to get the entropy, we should get the expectation/average of this measure m , which is essentially: $$E[m(y\ within\ I)]$$ and it can be expanded as below: $$ \int{P(y\ within\ I)*m(y\ within\ I)}dI =\int{(\int_I{f(y)dy}*{(-log\int_If(y)dy)})dI} $$ I found myself stuck here because the interval I is not strictly defined. Then I find from here the authoritative definition of entropy of continuous random variable: $$ H(Y)=-\int{f(y)log[f(y)]dy} $$ The p.d.f. $f(y)$ can certainly be $> 1$ , so the $H(Y)$ can be negative , while in discrete scenario, the $H(X)$ is always non-negative . I cannot explain the why this in-consistence is happening. For now, I can only consider it as a philosophical difficulty regarding continuity and discreteness . Some of my personal feeling (can be safely ignored): In the discrete scenario, the concrete countable outcome provide the foothold for us to carry out our calculation. But in the continuous scenario, there's no such ready-made foothold (unless we can somehow make one). Without such foothold, it feels like we just keep falling into the endless hollowness of mind. Anyone could shed some light? ADD 3 - 4:23 PM 2/21/2022 We created mathematics to quantify the world. And here in probability we even try to quantify our mentality, while our mentality created mathematics in the first place. It's like an endless recursive fall. And it's really hard for one to settle down ...","The entropy (self information) of a discrete random variable X is calculated as: What does the mean? It seems to be something like """" the self information of each possible outcome of the random variable X "". And why do we use log function to calculate it? ADD 1 Well, below is my reasoning: The root motivation is to quantify/measure the uncertainty contained in a random variable. Intuitively , people tend to agree that there's some connection between uncertainty and probability . And still intuitively , people shall agree that: the more probability an outcome has, the less uncertainty it has. thus , the less probability an outcome has, the more uncertainty it has. So, I think if we want to measure the uncertainty for an outcome of a random variable, the measure function should satisfy: the value of uncertainty measure should be positive ( human instinct when counting ) the value of this measure for the uncertainty of an outcome should be monotonic decreasing function of the probability of that outcome. for outcomes of independent experiments, the uncertainty should be additive. That is for P(A)*P(B), the total uncertainty should be the sum of A's and B's. ( This is kind of instinctive, too. ) Then I come to the choice of -log[p(i)] as the measure of uncertainty of each possible outcome , or self-information of each outcome. Then I treat the entropy as the weighted average of the self-information of all possible outcomes. I just read the book < Information Theory, Inference and Learning Algorithms > by MacKay. The author indeed gives a similar explanation to mine. And he name it the information content of each outcome . It is not difficult to see that entropy better describes a random variable than the information content . And it is coincidental that the formula we intuitively found to measure the average information content of a random variable has a similar form to the one of entropy in thermodynamics . Thus comes the name information entropy ... BTW I want to quote some words from Einstein... ""It is not so important where one settles down. The best thing is to follow your instincts without too much reflection."" --Einstein to Max Born, March 3, 1920. AEA 8-146 ADD 2 Following my above reasoning, I tried to derive the calculation of entropy for a continuous random variable Y in a similar way. But I was blocked . Details below. Let Y's p.d.f be: Then, if we strictly follow my previous reasoning, then we should pick up a small interval of I , and the probability of Y within interval I is given by: Then the measure of uncertainty for Y to fall in interval I should be: Then, to get the entropy, we should get the expectation/average of this measure m , which is essentially: and it can be expanded as below: I found myself stuck here because the interval I is not strictly defined. Then I find from here the authoritative definition of entropy of continuous random variable: The p.d.f. can certainly be , so the can be negative , while in discrete scenario, the is always non-negative . I cannot explain the why this in-consistence is happening. For now, I can only consider it as a philosophical difficulty regarding continuity and discreteness . Some of my personal feeling (can be safely ignored): In the discrete scenario, the concrete countable outcome provide the foothold for us to carry out our calculation. But in the continuous scenario, there's no such ready-made foothold (unless we can somehow make one). Without such foothold, it feels like we just keep falling into the endless hollowness of mind. Anyone could shed some light? ADD 3 - 4:23 PM 2/21/2022 We created mathematics to quantify the world. And here in probability we even try to quantify our mentality, while our mentality created mathematics in the first place. It's like an endless recursive fall. And it's really hard for one to settle down ...","
H(x)=E(-\log[P(X)])
 -\log[P(X)] f(y) P(y\ within\ I)=\int_If(y)dy m(y\ within\ I) = -log\int_If(y)dy E[m(y\ within\ I)] 
\int{P(y\ within\ I)*m(y\ within\ I)}dI
=\int{(\int_I{f(y)dy}*{(-log\int_If(y)dy)})dI}
 
H(Y)=-\int{f(y)log[f(y)]dy}
 f(y) > 1 H(Y) H(X)","['probability', 'probability-theory', 'information-theory']"
54,Show that two states in the same communicating class of a Markov chain must have the same period,Show that two states in the same communicating class of a Markov chain must have the same period,,How would you go about showing that two states in the same communicating class of a Markov chain must have the same period? Any help would be greatly appreciated.,How would you go about showing that two states in the same communicating class of a Markov chain must have the same period? Any help would be greatly appreciated.,,"['probability', 'markov-chains']"
55,Probability of dice sum just greater than 100,Probability of dice sum just greater than 100,,"Can someone please guide me to a way by which I can solve the following problem. There is a die and 2 players. Rolling stops as soon as some exceeds 100(not including 100 itself). Hence you have the following choices: 101, 102, 103, 104, 105, 106.  Which should I choose given first choice.  I'm thinking Markov chains, but is there a simpler way? Thanks. EDIT: I wrote dice instead of die. There is just one die being rolled","Can someone please guide me to a way by which I can solve the following problem. There is a die and 2 players. Rolling stops as soon as some exceeds 100(not including 100 itself). Hence you have the following choices: 101, 102, 103, 104, 105, 106.  Which should I choose given first choice.  I'm thinking Markov chains, but is there a simpler way? Thanks. EDIT: I wrote dice instead of die. There is just one die being rolled",,"['probability', 'game-theory']"
56,Interpretation for the determinant of a stochastic matrix?,Interpretation for the determinant of a stochastic matrix?,,Is there a probabilistic interpretation for the determinant of a stochastic matrix (i.e. an $n \times n$ matrix whose columns sum to unity)?,Is there a probabilistic interpretation for the determinant of a stochastic matrix (i.e. an $n \times n$ matrix whose columns sum to unity)?,,"['probability', 'matrices', 'stochastic-processes', 'markov-chains', 'markov-process']"
57,maximum of two uniform distributions,maximum of two uniform distributions,,"I have a question. Let's suppose that the two random variables $X1$ and $X2$ follow two Uniform distributions that are independent but have different parameters: $X1 \sim Uniform(l1, u1)$ $X2 \sim Uniform(l2,u2)$ If we define X3 as the maximum of X1, and X2, i.e., $X3 = max(X1, X2)$, what kind of distribution would it be? It is certainly not a uniform and I can calculate the cumulative probability, i.e., $p(X3 <= a)$, because $p(X3 <= a) = p(X1 <= a) p(X2 <= a)$. But, I wonder if there exists any density function that can model X3.","I have a question. Let's suppose that the two random variables $X1$ and $X2$ follow two Uniform distributions that are independent but have different parameters: $X1 \sim Uniform(l1, u1)$ $X2 \sim Uniform(l2,u2)$ If we define X3 as the maximum of X1, and X2, i.e., $X3 = max(X1, X2)$, what kind of distribution would it be? It is certainly not a uniform and I can calculate the cumulative probability, i.e., $p(X3 <= a)$, because $p(X3 <= a) = p(X1 <= a) p(X2 <= a)$. But, I wonder if there exists any density function that can model X3.",,"['probability', 'probability-distributions']"
58,Kolmogorov's probability axioms,Kolmogorov's probability axioms,,"Why Kolmogorov's axioms are considered such a breakthrough in probability theory? They are just 3 simple statements everyone can agree with. When creating a system of axioms like this it's necessary the list of the axioms is complete. Suppose we forget about the 3rd Kolmogorov's axiom. Then we would have 2 axioms everyone could agree with when thinking about probability. Does it mean the 2 axioms are enough to claim this is a good axiomatic system of probability? We know it's not, because there's the 3rd axiom left out. But maybe these 3 axioms are not sufficient as well in a similar manner. Look at Euclid's fifth axiom (parallel postulate). If we ommit fifth postulate, we get hyperbolic geometry, which is certainly no what we wanted to have. A similar question arises here - are those axioms sufficient? Are we sure we won't get any unintended results just following these 3 axioms? Or maybe the statement that a given set of axioms agrees with our intuition of, let's say, probability must itself be treated as an axiom. We cannot prove it. Kolmogorov axioms survived so many years with no major complaints, then they are believed to match our intuition regarding what probability is accurately. But there are areas where it doesn't work (like quantum mechanics, which is well known for being weird and counter-intuitive). But why those axioms apparently do work in our 'common' and 'everyday' probability problems? Maybe we haven't discovered a case where they fail? Quoting The Logico-Algebraic Approach to Quantum Mechanics Volume I: Historical Evolution , C.A. Hooker Editor, page 172 : It is obvious that since the Kolmogorov axioms are rooted in empirical   experience, any change in the theory, if by such change one wants to   extend its applications to the physical world, should spring directly   from some phenomenological considerations. Anticipating our   discussions in the subsequent sections one might say that the point of   departure for the contemplated change in the model can be traced to   the remarkable discovery that the physical systems arising in quantum   physics are of such nature that one is no longer entitled to make the   assumption that the associated experimental proposition constitute a   Boolean sigma-algebra. As a consequence, the conventional i.e. the   Kolmogorov formalism of probability theory is inadequate for a precise   description of these systems. As a spectacular instance of such   failure we may mention the facts that the notion of disjoint events is   at a somewhat deeper level and that the identity   $P(A+B)=P(A)+P(B)-P(AB)$ is not always true (the examples of Feynman are   concerned with this failure among other things).","Why Kolmogorov's axioms are considered such a breakthrough in probability theory? They are just 3 simple statements everyone can agree with. When creating a system of axioms like this it's necessary the list of the axioms is complete. Suppose we forget about the 3rd Kolmogorov's axiom. Then we would have 2 axioms everyone could agree with when thinking about probability. Does it mean the 2 axioms are enough to claim this is a good axiomatic system of probability? We know it's not, because there's the 3rd axiom left out. But maybe these 3 axioms are not sufficient as well in a similar manner. Look at Euclid's fifth axiom (parallel postulate). If we ommit fifth postulate, we get hyperbolic geometry, which is certainly no what we wanted to have. A similar question arises here - are those axioms sufficient? Are we sure we won't get any unintended results just following these 3 axioms? Or maybe the statement that a given set of axioms agrees with our intuition of, let's say, probability must itself be treated as an axiom. We cannot prove it. Kolmogorov axioms survived so many years with no major complaints, then they are believed to match our intuition regarding what probability is accurately. But there are areas where it doesn't work (like quantum mechanics, which is well known for being weird and counter-intuitive). But why those axioms apparently do work in our 'common' and 'everyday' probability problems? Maybe we haven't discovered a case where they fail? Quoting The Logico-Algebraic Approach to Quantum Mechanics Volume I: Historical Evolution , C.A. Hooker Editor, page 172 : It is obvious that since the Kolmogorov axioms are rooted in empirical   experience, any change in the theory, if by such change one wants to   extend its applications to the physical world, should spring directly   from some phenomenological considerations. Anticipating our   discussions in the subsequent sections one might say that the point of   departure for the contemplated change in the model can be traced to   the remarkable discovery that the physical systems arising in quantum   physics are of such nature that one is no longer entitled to make the   assumption that the associated experimental proposition constitute a   Boolean sigma-algebra. As a consequence, the conventional i.e. the   Kolmogorov formalism of probability theory is inadequate for a precise   description of these systems. As a spectacular instance of such   failure we may mention the facts that the notion of disjoint events is   at a somewhat deeper level and that the identity   $P(A+B)=P(A)+P(B)-P(AB)$ is not always true (the examples of Feynman are   concerned with this failure among other things).",,"['probability', 'axioms']"
59,Expected area of triangle formed by three random points inside unit circle,Expected area of triangle formed by three random points inside unit circle,,Motivated by the discussion in The expected area of a triangle formed by three points randomly chosen from the unit square I tried to find an expression for the expected area of a triangle formed by three randomly chosen points inside the unit circle. I could not find one. Perhaps this is one of those problems which look easy but are difficult to solve analytically.,Motivated by the discussion in The expected area of a triangle formed by three points randomly chosen from the unit square I tried to find an expression for the expected area of a triangle formed by three randomly chosen points inside the unit circle. I could not find one. Perhaps this is one of those problems which look easy but are difficult to solve analytically.,,['probability']
60,"Bayes, two tests in a row","Bayes, two tests in a row",,"I came up with a standard Bayesian example as to point out my confusion. There is an epidemic. A person has a probability $\frac{1}{100}$ to have the disease. The authorities decide to test the population, but the test is not completely reliable: the test generally gives $\frac{1}{110}$ people a positive result but given that you have the disease the probability of getting a positive result is $\frac{80}{100}$. I am interested in what happens after a person takes another test, specifically how much more information we would gain. Probability after one test Let $D$ denote the event of having the disease, let $T$ denote event of a positive outcome of a test. If we are interested in finding $P(D|T)$ then we can just go and apply Bayes rule: $$ P(D|T) = \frac{P(T|D)P(D)}{P(T)} = \frac{0.8 \times 0.01}{0.009} = 0.88 $$ This feels about right. Probability after two tests This is where I think I misunderstand Bayes rule somewhat. Let $TT$ denote the outcome of two positive tests. We are now interested in calculating; $$ P(D|TT) = \frac{P(TT|D)P(D)}{P(TT)} $$ The prior $P(D)$ is still $\frac{1}{100}$. $P(TT|D)$ would now be $0.8 \times 0.8$ because the two test can be assumed to be independent. But I seem to not know how to deal with $P(TT)$ ... it cannot be $\frac{1}{110} \times \frac{1}{110}$ because then; $$ \frac{P(TT|D)P(D)}{P(TT)} = \frac{0.64 \times 0.01}{0.009^2} > 1 $$ What is the right approach to the two-test Bayesian case?","I came up with a standard Bayesian example as to point out my confusion. There is an epidemic. A person has a probability $\frac{1}{100}$ to have the disease. The authorities decide to test the population, but the test is not completely reliable: the test generally gives $\frac{1}{110}$ people a positive result but given that you have the disease the probability of getting a positive result is $\frac{80}{100}$. I am interested in what happens after a person takes another test, specifically how much more information we would gain. Probability after one test Let $D$ denote the event of having the disease, let $T$ denote event of a positive outcome of a test. If we are interested in finding $P(D|T)$ then we can just go and apply Bayes rule: $$ P(D|T) = \frac{P(T|D)P(D)}{P(T)} = \frac{0.8 \times 0.01}{0.009} = 0.88 $$ This feels about right. Probability after two tests This is where I think I misunderstand Bayes rule somewhat. Let $TT$ denote the outcome of two positive tests. We are now interested in calculating; $$ P(D|TT) = \frac{P(TT|D)P(D)}{P(TT)} $$ The prior $P(D)$ is still $\frac{1}{100}$. $P(TT|D)$ would now be $0.8 \times 0.8$ because the two test can be assumed to be independent. But I seem to not know how to deal with $P(TT)$ ... it cannot be $\frac{1}{110} \times \frac{1}{110}$ because then; $$ \frac{P(TT|D)P(D)}{P(TT)} = \frac{0.64 \times 0.01}{0.009^2} > 1 $$ What is the right approach to the two-test Bayesian case?",,"['probability', 'bayesian']"
61,Definitions for an exponential family to be curved or flat?,Definitions for an exponential family to be curved or flat?,,"I was wondering how a curved exponential family is defined? Also how is a flat exponential family  defined? Is ""curved"" or ""flat"" defined for a family of probability distributions, or for a parametrization of a family of probability distributions? By the latter, I mean if it is possible that, for two parametrizations of the same family of probability distributions, a parametrization is ""curved"" while the other parametrization isn't? I searched in some books, but their definitions aren't the same, and I am wondering if they are equivalent and why? From Casella and Berger's Statistical Inference, p115: From Casella and Berger's Statistical Inference, again, p137~138: is this a definition of ""curved""? From Bickle and Doksum's Mathematical Statistics Vol I, p56~57 From a note by Charles J. Geyer An exponential family is convex (also called flat) if its natural   parameter space is a convex subset of the full natural parameter space   (dom c, where c is the cumulant function). An exponential family is curved if it is a smooth submodel of a full   exponential family that is not itself a flat exponential family,   where smooth means the natural parameter space is specified as the   image of a twice continuously differentiable function from Rp for   some p into the full natural parameter space. Thanks and regards!","I was wondering how a curved exponential family is defined? Also how is a flat exponential family  defined? Is ""curved"" or ""flat"" defined for a family of probability distributions, or for a parametrization of a family of probability distributions? By the latter, I mean if it is possible that, for two parametrizations of the same family of probability distributions, a parametrization is ""curved"" while the other parametrization isn't? I searched in some books, but their definitions aren't the same, and I am wondering if they are equivalent and why? From Casella and Berger's Statistical Inference, p115: From Casella and Berger's Statistical Inference, again, p137~138: is this a definition of ""curved""? From Bickle and Doksum's Mathematical Statistics Vol I, p56~57 From a note by Charles J. Geyer An exponential family is convex (also called flat) if its natural   parameter space is a convex subset of the full natural parameter space   (dom c, where c is the cumulant function). An exponential family is curved if it is a smooth submodel of a full   exponential family that is not itself a flat exponential family,   where smooth means the natural parameter space is specified as the   image of a twice continuously differentiable function from Rp for   some p into the full natural parameter space. Thanks and regards!",,"['probability', 'statistics', 'probability-theory']"
62,Probability of questions being on an exam,Probability of questions being on an exam,,"My girlfriend has an exam in her international development class tomorrow.  She's been given $60$ terms to study (each takes a long time to learn thoroughly).  Of those $60$ terms, $10$ will be on the exam, and she must discuss $3$ of them.  Now, she's been spending a lot of time trying to figure out the probability of knowing $x$ of the $3$ questions, time that could be spent studying. Funnily enough, I actually have a probability and statistics for computer science final coming up next week and I have no idea how to figure out this probability. Given that she studied $n$ of $60$ terms, what is the probability that she will know (a) $0$, (b) $1$, (c) $2$, (d) $3$ of the $10$ terms that appear on the exam?","My girlfriend has an exam in her international development class tomorrow.  She's been given $60$ terms to study (each takes a long time to learn thoroughly).  Of those $60$ terms, $10$ will be on the exam, and she must discuss $3$ of them.  Now, she's been spending a lot of time trying to figure out the probability of knowing $x$ of the $3$ questions, time that could be spent studying. Funnily enough, I actually have a probability and statistics for computer science final coming up next week and I have no idea how to figure out this probability. Given that she studied $n$ of $60$ terms, what is the probability that she will know (a) $0$, (b) $1$, (c) $2$, (d) $3$ of the $10$ terms that appear on the exam?",,['probability']
63,What exactly is the Probability Integral Transform?,What exactly is the Probability Integral Transform?,,"I've been going back over my notes from Stats class and came across the Probability Integral Transform.  From my limited understanding, the basic idea is that a cdf in terms of one variable can be transformed into another cdf in terms of different variable: i.e. from $F_x(x)$ to --> $F_y(y)$ Is this understanding correct?  What is the purpose behind this?  Finally, is there a general procedure in performing the transformation?","I've been going back over my notes from Stats class and came across the Probability Integral Transform.  From my limited understanding, the basic idea is that a cdf in terms of one variable can be transformed into another cdf in terms of different variable: i.e. from to --> Is this understanding correct?  What is the purpose behind this?  Finally, is there a general procedure in performing the transformation?",F_x(x) F_y(y),"['probability', 'statistics', 'integral-transforms']"
64,"Prove: if $a,b\in G$ commute with probability $>5/8$, then $G$ is abelian","Prove: if  commute with probability , then  is abelian","a,b\in G >5/8 G","Suppose that $G$ is a finite group. If $P( ab=ba ) >5/8$, prove $G$ is abelian.","Suppose that $G$ is a finite group. If $P( ab=ba ) >5/8$, prove $G$ is abelian.",,"['probability', 'abstract-algebra', 'group-theory', 'finite-groups']"
65,Expected value of repeatedly betting on a coin flip?,Expected value of repeatedly betting on a coin flip?,,"Edit - I just stumbled across this YouTube video that explained this phenomenon very well so thought I'd include it here for future readers Consider the following game: You start with $1000 Flip a fair coin If it's heads gain 21% , if it's tails lose 20% You can play as many times as you want My question is: How would you calculate the expected amount of money you have after N games? How many times should you play? If I consider playing a single round, the expected value would be: $$ \begin{aligned} E[1] &= 1000 \cdot ( 0.5 \cdot 1.21  + 0.5 \cdot 0.8 ) \\ &=1005 \end{aligned} $$ It seems to me like the rational decision would be to play the game, because you expect to end up with more money. And then after your first coin toss, the same reasoning should apply for the decision about whether to play a second time, and so on... So then it seems like you should play as many times as possible and that your amount of money should approach infinity as N does. However when I simulate this in Python I am finding that the final amount of money always tends toward zero with enough flips. How can a game where each round has a positive expected return end up giving a negative return when played many times? I read about the Kelly Criterion and think it might apply here. Calculating the geometric growth rate: $$ \begin{aligned} r &= (1 + f \cdot b)^p \cdot (1 - f \cdot f )^{1-p} \\ &= (1 + 1 \cdot 0.21)^{0.5} \cdot (1 - 1 \cdot 0.2 )^{0.5} \\ &= 0.983870  \end{aligned} $$ This seems to indicate that I should not play, because the geometric growth rate is below 1. But how do I reconcile that with my reasoning above and the fact that the expected gain of playing any individual round is positive?","Edit - I just stumbled across this YouTube video that explained this phenomenon very well so thought I'd include it here for future readers Consider the following game: You start with $1000 Flip a fair coin If it's heads gain 21% , if it's tails lose 20% You can play as many times as you want My question is: How would you calculate the expected amount of money you have after N games? How many times should you play? If I consider playing a single round, the expected value would be: It seems to me like the rational decision would be to play the game, because you expect to end up with more money. And then after your first coin toss, the same reasoning should apply for the decision about whether to play a second time, and so on... So then it seems like you should play as many times as possible and that your amount of money should approach infinity as N does. However when I simulate this in Python I am finding that the final amount of money always tends toward zero with enough flips. How can a game where each round has a positive expected return end up giving a negative return when played many times? I read about the Kelly Criterion and think it might apply here. Calculating the geometric growth rate: This seems to indicate that I should not play, because the geometric growth rate is below 1. But how do I reconcile that with my reasoning above and the fact that the expected gain of playing any individual round is positive?","
\begin{aligned}
E[1] &= 1000 \cdot ( 0.5 \cdot 1.21  + 0.5 \cdot 0.8 ) \\
&=1005
\end{aligned}
 
\begin{aligned}
r &= (1 + f \cdot b)^p \cdot (1 - f \cdot f )^{1-p} \\
&= (1 + 1 \cdot 0.21)^{0.5} \cdot (1 - 1 \cdot 0.2 )^{0.5} \\
&= 0.983870 
\end{aligned}
","['probability', 'gambling']"
66,Broken stick probability problem,Broken stick probability problem,,"We have all heard the old problem about forming a triangle from breaking a stick into three pieces, with the breaks randomly distributed. Some variations make the second break contingent on the first in some way. I present a new variation (not original to me). Problem: Take a stick and break it at a location selected with uniform density along its length. Throw away the left-hand piece and break the right-hand one at a location selected with uniform density along its length. Continue forever. What is the probability that one of the discarded left-hand pieces is more than half as long as the original stick? I do not have a particularly elegant to solution to this one, and was wondering if one exists. Of course, any answers that solve the problem are welcome.","We have all heard the old problem about forming a triangle from breaking a stick into three pieces, with the breaks randomly distributed. Some variations make the second break contingent on the first in some way. I present a new variation (not original to me). Problem: Take a stick and break it at a location selected with uniform density along its length. Throw away the left-hand piece and break the right-hand one at a location selected with uniform density along its length. Continue forever. What is the probability that one of the discarded left-hand pieces is more than half as long as the original stick? I do not have a particularly elegant to solution to this one, and was wondering if one exists. Of course, any answers that solve the problem are welcome.",,['probability']
67,Expected Ratio of Coin Flips,Expected Ratio of Coin Flips,,"If you flip a coin until you decide to stop and you want to maximize   the ratio of heads to total flips, what is that expected ratio? Assuming that you want to maximize the ratio, meaning whether you flip again or not depends on the chances of whether you will risk more than you gain, I have gotten that: if the probability is 50/50 (same number of heads and tails so far), you flip again if there are more tails than heads you flip again if you have more heads then tails you don't flip How do you put this into an equation form to solve for expected ratio? Thanks","If you flip a coin until you decide to stop and you want to maximize   the ratio of heads to total flips, what is that expected ratio? Assuming that you want to maximize the ratio, meaning whether you flip again or not depends on the chances of whether you will risk more than you gain, I have gotten that: if the probability is 50/50 (same number of heads and tails so far), you flip again if there are more tails than heads you flip again if you have more heads then tails you don't flip How do you put this into an equation form to solve for expected ratio? Thanks",,"['probability', 'recreational-mathematics', 'problem-solving']"
68,Glass Bridge Game in Squid Game (Episode 7/ Game 5),Glass Bridge Game in Squid Game (Episode 7/ Game 5),,"Spoilers for Squid Game . In the show, there is a game where people try to cross a bridge, made of $n=18$ rows of 2 side by side glass panes, which they must cross one row at a time. One glass pane can support a person while the other  will break, causing the person to fall and get eliminated. Each person must select which glass pane to jump onto, from one row to the next, and try to reach the other side without falling through. In the show, some people cross the same bridge later than others, so they can tell which of the steps already crossed are sturdy or not. Assume that the selection of the sturdy and weak glass panes are random, that later players take the same steps that previous players took up to the point that they fall through (i.e. no forgetting which pane is sturdy or guessing again on an already solved pane). Ignore all human elements, like people trying to force others to fail to figure out future panes, or being able to tell the difference between tempered sturdy panes and weaker panes (i.e. guessing is random). Given $n$ rows of glass panes, how many players would it take until there is a player with a $>50\% $ chance of crossing the bridge? In the show there are 16 players and $n=18$ rows of glass, so what is the most likely outcome, in terms of number of people being able to cross the bridge?","Spoilers for Squid Game . In the show, there is a game where people try to cross a bridge, made of rows of 2 side by side glass panes, which they must cross one row at a time. One glass pane can support a person while the other  will break, causing the person to fall and get eliminated. Each person must select which glass pane to jump onto, from one row to the next, and try to reach the other side without falling through. In the show, some people cross the same bridge later than others, so they can tell which of the steps already crossed are sturdy or not. Assume that the selection of the sturdy and weak glass panes are random, that later players take the same steps that previous players took up to the point that they fall through (i.e. no forgetting which pane is sturdy or guessing again on an already solved pane). Ignore all human elements, like people trying to force others to fail to figure out future panes, or being able to tell the difference between tempered sturdy panes and weaker panes (i.e. guessing is random). Given rows of glass panes, how many players would it take until there is a player with a chance of crossing the bridge? In the show there are 16 players and rows of glass, so what is the most likely outcome, in terms of number of people being able to cross the bridge?",n=18 n >50\%  n=18,['probability']
69,Independence of disjoint events with strictly positive probability,Independence of disjoint events with strictly positive probability,,"I'm taking a class in Probability Theory, and I was asked this question in class today: Given disjoint events $A$ and $B$ for which $$ P(A)>0\\ P(B)>0 $$ Can $A$   and $B$ be independent? My answer was: $A$ and $B$ are disjoint, so $P(A\cap B)=0$. $P(A)>0$ and $P(B)>0$, so $P(A)P(B)>0$. $P(A\cap B)\not =P(A)P(B)$, so $A$ and $B$ are not independent. However, I was told that I am wrong and we cannot know whether or not $A$ and $B$ are independent from the given information, but I did not receive a satisfactory explanation. Is my argument valid? If not, where do I go wrong?","I'm taking a class in Probability Theory, and I was asked this question in class today: Given disjoint events $A$ and $B$ for which $$ P(A)>0\\ P(B)>0 $$ Can $A$   and $B$ be independent? My answer was: $A$ and $B$ are disjoint, so $P(A\cap B)=0$. $P(A)>0$ and $P(B)>0$, so $P(A)P(B)>0$. $P(A\cap B)\not =P(A)P(B)$, so $A$ and $B$ are not independent. However, I was told that I am wrong and we cannot know whether or not $A$ and $B$ are independent from the given information, but I did not receive a satisfactory explanation. Is my argument valid? If not, where do I go wrong?",,"['probability', 'independence']"
70,"Solution to Locomotive Problem (Mosteller, Fifty Challenging Problems in Probability)","Solution to Locomotive Problem (Mosteller, Fifty Challenging Problems in Probability)",,"My question concerns the solution Professor Mosteller gives for the Locomotive Problem in his book, Fifty Challenging Problems in Probability. The problem is as follows: A railroad numbers its locomotives in order 1, 2, ..., N. One day you see a locomotive and its number is 60. Guess how many locomotives the company has. Mosteller's solution uses the ""symmetry principle"". That is, if you select a point at random on a line, on average the point you select will be halfway between the two ends. Based on this, Mosteller argues that the best guess for the number of locomotives is 119 (locomotive #60, plus an equal number on either ""side"" of 60 gives 59 + 59 + 1 = 119. While I feel a bit nervous about challenging the judgment of a mathematician of Mosteller's stature, his answer doesn't seem right to me. I've picked a locomotive at random and it happens to be number 60. Given this datum, what number of locomotives has the maximum likelihood? It seems to me that the best answer (if you have to choose a single value) is that there are 60 locomotives. If there are 60 locomotives, then the probability of my selecting the 60th locomotive at random is 1/60. Every other total number of locomotives gives a lower probability for selecting #60. For example, if there are 70 locomotives, I have only a 1/70 probability of selecting #60 (and similarly, the probability is 1/n for any n >= 60). Thus, while it's not particularly likely that there are exactly 60 locomotives, this conclusion is more likely than any other. Have I missed something, or is my analysis correct?","My question concerns the solution Professor Mosteller gives for the Locomotive Problem in his book, Fifty Challenging Problems in Probability. The problem is as follows: A railroad numbers its locomotives in order 1, 2, ..., N. One day you see a locomotive and its number is 60. Guess how many locomotives the company has. Mosteller's solution uses the ""symmetry principle"". That is, if you select a point at random on a line, on average the point you select will be halfway between the two ends. Based on this, Mosteller argues that the best guess for the number of locomotives is 119 (locomotive #60, plus an equal number on either ""side"" of 60 gives 59 + 59 + 1 = 119. While I feel a bit nervous about challenging the judgment of a mathematician of Mosteller's stature, his answer doesn't seem right to me. I've picked a locomotive at random and it happens to be number 60. Given this datum, what number of locomotives has the maximum likelihood? It seems to me that the best answer (if you have to choose a single value) is that there are 60 locomotives. If there are 60 locomotives, then the probability of my selecting the 60th locomotive at random is 1/60. Every other total number of locomotives gives a lower probability for selecting #60. For example, if there are 70 locomotives, I have only a 1/70 probability of selecting #60 (and similarly, the probability is 1/n for any n >= 60). Thus, while it's not particularly likely that there are exactly 60 locomotives, this conclusion is more likely than any other. Have I missed something, or is my analysis correct?",,"['probability', 'recreational-mathematics']"
71,Minimizing the probability of a draw in a democratic poll,Minimizing the probability of a draw in a democratic poll,,"A group of $k$ people wants to choose democratically between $n$ possible options . They arrange a poll in which every person votes for $r$ out of the $n$ options without repetition , meaning there are $n \choose r$ possible choices per person. The highest scoring option will be the winning choice - unless there's a draw of course... Question: Assuming each person chooses $r$ out of $n$ options with uniform probability. What is the value of $r$ for which the probability of the poll ending in a draw is minimal? Hopefully the answer will be unique and in a closed form $r=f(k,n)$. Sadly beyond trivial remarks about the extreme cases (like $r=n$ implies draw will happen with full probability and $r,k << n$ implies draw will be pretty likely because of sparse voting) I have nothing valuable to say about my attempts so far. Edit: To anyone who downvotes this - please explain what you think is wrong with the question. To make things clear: This is not a homework problem! . Still, if you think this is a trivial problem please explain your solution - if not then please reconsider the downvote.","A group of $k$ people wants to choose democratically between $n$ possible options . They arrange a poll in which every person votes for $r$ out of the $n$ options without repetition , meaning there are $n \choose r$ possible choices per person. The highest scoring option will be the winning choice - unless there's a draw of course... Question: Assuming each person chooses $r$ out of $n$ options with uniform probability. What is the value of $r$ for which the probability of the poll ending in a draw is minimal? Hopefully the answer will be unique and in a closed form $r=f(k,n)$. Sadly beyond trivial remarks about the extreme cases (like $r=n$ implies draw will happen with full probability and $r,k << n$ implies draw will be pretty likely because of sparse voting) I have nothing valuable to say about my attempts so far. Edit: To anyone who downvotes this - please explain what you think is wrong with the question. To make things clear: This is not a homework problem! . Still, if you think this is a trivial problem please explain your solution - if not then please reconsider the downvote.",,"['probability', 'combinatorics', 'voting-theory']"
72,"Prove that the maximum of $n$ independent standard normal random variables, is asymptotically equivalent to $\sqrt{2\log n}$ almost surely.","Prove that the maximum of  independent standard normal random variables, is asymptotically equivalent to  almost surely.",n \sqrt{2\log n},"Lets $(X_n)_{n\in\mathbb{N}}$ be an iid sequence of standard normal random variables. Define $$M_n=\max_{1\leq i\leq n} X_i.$$ Prove that $$\lim_{n\rightarrow\infty} \frac{M_n}{\sqrt{2\log n}}=1\quad\text{a.s.}$$ I used the fact that $$\left(\frac{1}{x}-\frac{1}{x^3}\right)e^{-\frac{x^2}{2}}\leq\mathbb P(X_n>x)\leq \frac{1}{x}e^{-\frac{x^2}{2}},$$ and the Borel Cantelli lemmas to prove that   $$\limsup_{n\rightarrow\infty} \frac{X_n}{\sqrt{2\log n}}=1\quad\text{a.s.}$$ I used Davide Giraudo's comment to show $$\limsup_n \frac{M_n}{\sqrt{2\log n}}=1\quad \text{a.s.}$$ I have no idea how to compute the $\liminf$. Borel-Cantelli give us tools to compute the $\limsup$ of sets, I am unsure of how to argue almost sure convergence. Any help would be appreciated.","Lets $(X_n)_{n\in\mathbb{N}}$ be an iid sequence of standard normal random variables. Define $$M_n=\max_{1\leq i\leq n} X_i.$$ Prove that $$\lim_{n\rightarrow\infty} \frac{M_n}{\sqrt{2\log n}}=1\quad\text{a.s.}$$ I used the fact that $$\left(\frac{1}{x}-\frac{1}{x^3}\right)e^{-\frac{x^2}{2}}\leq\mathbb P(X_n>x)\leq \frac{1}{x}e^{-\frac{x^2}{2}},$$ and the Borel Cantelli lemmas to prove that   $$\limsup_{n\rightarrow\infty} \frac{X_n}{\sqrt{2\log n}}=1\quad\text{a.s.}$$ I used Davide Giraudo's comment to show $$\limsup_n \frac{M_n}{\sqrt{2\log n}}=1\quad \text{a.s.}$$ I have no idea how to compute the $\liminf$. Borel-Cantelli give us tools to compute the $\limsup$ of sets, I am unsure of how to argue almost sure convergence. Any help would be appreciated.",,"['probability', 'probability-theory', 'probability-distributions', 'probability-limit-theorems']"
73,Cat dead or alive?,Cat dead or alive?,,"You put a cat into a toxic box, it might be dead or alive after an   hour. Two witches $A$ and $B$ have the ability to predict the status of the cat   with the accuracy of $p_1$ and $p_2$, respectively.Suppose their prediction are independent. Both of them claim   that they ""see"" the cat is still alive in the future. Question: from   their words, can you calculate the probability that the cat is still   alive after an hour? I have two solutions, I am so confused about them, especially the second one, please have patience and feel my confusion. Solution 1 Two possibilities: $A$ right, $B$ right, so cat is alive $A$ wrong, $B$ wrong, so cat is dead One right and one wrong is impossible, therefore the probability that the cat is alive $p_1p_2/(p_1p_2+(1-p_1)(1-p_2))$ Solution 2 I will translate A has the accuracy of $p_1$ to $$ p_1 = P(L)P(A_L|L)+P(D)P(A_D|D) $$ above formula says if the cat is alive, $A$ predict it is alive; if the cat is dead, $A$ predict it is dead. Similarly: $$ p_2 = P(L)P(B_L|L)+P(D)P(B_D|D) $$ Because the cat is either alive or dead, so $P(L)+P(D)=1$ We want to calculate the probability that the cat is alive based on the words of $A$ and $B$: $$ P(L|A_L,B_L) = \frac{P(A_L,B_L|L)P(L)}{P(A_L,B_L)} = \frac{P(A_L,B_L|L)P(L)}{P(A_L,B_L|L)P(L)+P(A_L,B_L|D)P(D)} $$ which seems not the same as solution 1 as far as I can tell. This solution makes me very uncomfortable about the meaning of $P(D)$ and $P(L)$ , are they the unknown probability of the cat is dead or alive if I have no witches words? Edit I found the solution 1 is the result of explaining the accuracy of prediction differently than solution 2. Explicitly, it explain $p_1=P(D|A_D)=P(L|A_L)$, which means, when $A$ says the cat is dead, the probability that the cat turn out to be dead is $p_1$; when $A$ says the cat is alive, the probability that the cat turn out to be alive is also $p_1$. Therefore, $$ P(L|A_L,B_L)=\frac{P(L|A_L,B_L)}{P(L|A_L,B_L)+ P(D|A_L,B_L)}= \frac{p_1p_2}{p_1p_2+(1-p_1)(1-p_2)} $$ Edit2 As discussed, I think the most confusing part is how to properly define the accuracy of the witches, do you think there are ambiguities in the definition of this quantity? At least three candidates make some sense to me: $p_1=P(A_L|L)=P(A_D|D)$ This says: if the cat is alive, then the witch predict it as alive with probability $p_1$; if the cat is dead, then witch predict it as dead with probability $p_1$; $p_1 = P(L|A_L) = P(D|A_D)$ This says: if the witch says the cat is alive, then the probability that the cat turn out to be alive with probability $p_1$; same as when the witch says the cat is dead. $p_1 = P(A_L|L)P(L) + P(A_D|D)P(D)$ This says: the cat is either dead or alive, if it is alive, the witch predict it as alive; if it is dead, the witch predict it as dead; the sum of them should be the accuracy of the witch. As pointed out by one answer, this definition allows that $P(A_L|L)\neq P(A_D|D)$, but is this a big problem? Which of the above three make most sense to you, which is nonsense and which make some sense?","You put a cat into a toxic box, it might be dead or alive after an   hour. Two witches $A$ and $B$ have the ability to predict the status of the cat   with the accuracy of $p_1$ and $p_2$, respectively.Suppose their prediction are independent. Both of them claim   that they ""see"" the cat is still alive in the future. Question: from   their words, can you calculate the probability that the cat is still   alive after an hour? I have two solutions, I am so confused about them, especially the second one, please have patience and feel my confusion. Solution 1 Two possibilities: $A$ right, $B$ right, so cat is alive $A$ wrong, $B$ wrong, so cat is dead One right and one wrong is impossible, therefore the probability that the cat is alive $p_1p_2/(p_1p_2+(1-p_1)(1-p_2))$ Solution 2 I will translate A has the accuracy of $p_1$ to $$ p_1 = P(L)P(A_L|L)+P(D)P(A_D|D) $$ above formula says if the cat is alive, $A$ predict it is alive; if the cat is dead, $A$ predict it is dead. Similarly: $$ p_2 = P(L)P(B_L|L)+P(D)P(B_D|D) $$ Because the cat is either alive or dead, so $P(L)+P(D)=1$ We want to calculate the probability that the cat is alive based on the words of $A$ and $B$: $$ P(L|A_L,B_L) = \frac{P(A_L,B_L|L)P(L)}{P(A_L,B_L)} = \frac{P(A_L,B_L|L)P(L)}{P(A_L,B_L|L)P(L)+P(A_L,B_L|D)P(D)} $$ which seems not the same as solution 1 as far as I can tell. This solution makes me very uncomfortable about the meaning of $P(D)$ and $P(L)$ , are they the unknown probability of the cat is dead or alive if I have no witches words? Edit I found the solution 1 is the result of explaining the accuracy of prediction differently than solution 2. Explicitly, it explain $p_1=P(D|A_D)=P(L|A_L)$, which means, when $A$ says the cat is dead, the probability that the cat turn out to be dead is $p_1$; when $A$ says the cat is alive, the probability that the cat turn out to be alive is also $p_1$. Therefore, $$ P(L|A_L,B_L)=\frac{P(L|A_L,B_L)}{P(L|A_L,B_L)+ P(D|A_L,B_L)}= \frac{p_1p_2}{p_1p_2+(1-p_1)(1-p_2)} $$ Edit2 As discussed, I think the most confusing part is how to properly define the accuracy of the witches, do you think there are ambiguities in the definition of this quantity? At least three candidates make some sense to me: $p_1=P(A_L|L)=P(A_D|D)$ This says: if the cat is alive, then the witch predict it as alive with probability $p_1$; if the cat is dead, then witch predict it as dead with probability $p_1$; $p_1 = P(L|A_L) = P(D|A_D)$ This says: if the witch says the cat is alive, then the probability that the cat turn out to be alive with probability $p_1$; same as when the witch says the cat is dead. $p_1 = P(A_L|L)P(L) + P(A_D|D)P(D)$ This says: the cat is either dead or alive, if it is alive, the witch predict it as alive; if it is dead, the witch predict it as dead; the sum of them should be the accuracy of the witch. As pointed out by one answer, this definition allows that $P(A_L|L)\neq P(A_D|D)$, but is this a big problem? Which of the above three make most sense to you, which is nonsense and which make some sense?",,"['probability', 'probability-theory', 'bayesian']"
74,How is the distance of two random points in a unit hypercube distributed?,How is the distance of two random points in a unit hypercube distributed?,,"Let $p_1, p_2 \sim U([0, 1]^n)$ with $n \in \mathbb{N}$ be two points in the $n$-dimensional unit hypercube which are uniform randomly independently sampled. How is the distance $d(p_1, p_2) = \sqrt{\sum_{i=1}^n { \left (p_1^{(i)} - p_2^{(i)} \right )}^2}$ distributed? Similar questions There are questions on math.SE which cover the average distance question for $n=1$ and $n =2$ (the one for $n=2$ also explains how to ) One dimension : $\frac{1}{3}$ Two dimensions : about $0.521...$ (this makes me guess that the distribution is noting ""standard"", because then the average distance question should be easy to answer. Can one make a statement like ""the distribution of the distance of two points is 'almost' ...""?)","Let $p_1, p_2 \sim U([0, 1]^n)$ with $n \in \mathbb{N}$ be two points in the $n$-dimensional unit hypercube which are uniform randomly independently sampled. How is the distance $d(p_1, p_2) = \sqrt{\sum_{i=1}^n { \left (p_1^{(i)} - p_2^{(i)} \right )}^2}$ distributed? Similar questions There are questions on math.SE which cover the average distance question for $n=1$ and $n =2$ (the one for $n=2$ also explains how to ) One dimension : $\frac{1}{3}$ Two dimensions : about $0.521...$ (this makes me guess that the distribution is noting ""standard"", because then the average distance question should be easy to answer. Can one make a statement like ""the distribution of the distance of two points is 'almost' ...""?)",,"['probability', 'geometry', 'probability-distributions']"
75,What is the distribution of this random series?,What is the distribution of this random series?,,"Let $\xi_n$ be iid and uniformly distributed on the three numbers $\{-1,0,1\}$.  Set $$X = \sum_{n=1}^\infty \frac{\xi_n}{2^n}.$$ It is clear that the sum converges (surely) and the limit has $-1 \le X \le 1$.. What is the distribution of $X$? Does it have a name?  Can we find an explicit formula?  What else can we say about it (for instance, is it absolutely continuous)? We can immediately see that $X$ is symmetric (i.e. $X \overset{d}{=} -X$).  Also, if $\xi$ is uniformly distributed on $\{-1,0,1\}$ and independent of $X$, we have $X \overset{d}{=} \frac{1}{2}(X+\xi)$.  It follows that for the cdf $F(x) = \mathbb{P}(X \le x)$, we have $$F(x) = \frac{1}{3}(F(2x+1) + F(2x) + F(2x-1)). \quad (*)$$ The cdf of $\sum_{n=1}^{12} \frac{\xi_n}{2^n}$ looks like this: It looks something like $\frac{1}{2}(1+\sin(\frac{\pi}{2}x))$ but that doesn't quite work (it doesn't satisfy (*)). I'd be interested if anything is known about this.  Thanks!","Let $\xi_n$ be iid and uniformly distributed on the three numbers $\{-1,0,1\}$.  Set $$X = \sum_{n=1}^\infty \frac{\xi_n}{2^n}.$$ It is clear that the sum converges (surely) and the limit has $-1 \le X \le 1$.. What is the distribution of $X$? Does it have a name?  Can we find an explicit formula?  What else can we say about it (for instance, is it absolutely continuous)? We can immediately see that $X$ is symmetric (i.e. $X \overset{d}{=} -X$).  Also, if $\xi$ is uniformly distributed on $\{-1,0,1\}$ and independent of $X$, we have $X \overset{d}{=} \frac{1}{2}(X+\xi)$.  It follows that for the cdf $F(x) = \mathbb{P}(X \le x)$, we have $$F(x) = \frac{1}{3}(F(2x+1) + F(2x) + F(2x-1)). \quad (*)$$ The cdf of $\sum_{n=1}^{12} \frac{\xi_n}{2^n}$ looks like this: It looks something like $\frac{1}{2}(1+\sin(\frac{\pi}{2}x))$ but that doesn't quite work (it doesn't satisfy (*)). I'd be interested if anything is known about this.  Thanks!",,"['probability', 'probability-theory', 'probability-distributions']"
76,"Probability of rolling a 1 before you roll two 2's, three 3's, etc","Probability of rolling a 1 before you roll two 2's, three 3's, etc",,"This is a question my father-in-law asked. I found it interesting but haven't been able to answer it. Suppose you have an $N$ sided die. You conduct an experiment as follows: roll the die until the first time you have rolled one 1, two 2's, three 3's etc. For example, you roll 2,3,4,3,6,5,3 the experiment ends because you have rolled three 3's. Of course, the most times you can roll the die is $1+\sum_{k=1}^{N-1}k = 1 + \frac{(N-1)N}{2}$. This is because the maximum number of rolls you can do is to roll one 2, two 3's, three 4's and so on, and then one more roll to complete the experiment. In particular, the experiment always ends in a finite number of rolls. Observe that the experiment ends when you roll a $1$. If you have a one-sided die the experiment always ends after the first roll and so you end on $1$ with probability 1. If you have a two sided die (i.e. a coin) then the probability of rolling a $1$ on the first roll is $1/2$; the probability of rolling a 2 first and a 1 second is $1/4$ and so the probability of ending the experiment on a $1$ is $3/4$. Let $P_N$ be the probability that you end the experiment on a $1$. What is $\lim_{N\to\infty}P_N$? $P_N$ is decreasing and of course $0\leq P_N$ so the limit exists. I tried taking the limit along ``easy'' sequences like $2^N$ hoping the the extra structure would lend itself to easier analysis, but I couldn't. I imagine I am not the first to ask this question, but I couldn't find it on MSE any other place. Any references to similar questions are also appreciated.","This is a question my father-in-law asked. I found it interesting but haven't been able to answer it. Suppose you have an $N$ sided die. You conduct an experiment as follows: roll the die until the first time you have rolled one 1, two 2's, three 3's etc. For example, you roll 2,3,4,3,6,5,3 the experiment ends because you have rolled three 3's. Of course, the most times you can roll the die is $1+\sum_{k=1}^{N-1}k = 1 + \frac{(N-1)N}{2}$. This is because the maximum number of rolls you can do is to roll one 2, two 3's, three 4's and so on, and then one more roll to complete the experiment. In particular, the experiment always ends in a finite number of rolls. Observe that the experiment ends when you roll a $1$. If you have a one-sided die the experiment always ends after the first roll and so you end on $1$ with probability 1. If you have a two sided die (i.e. a coin) then the probability of rolling a $1$ on the first roll is $1/2$; the probability of rolling a 2 first and a 1 second is $1/4$ and so the probability of ending the experiment on a $1$ is $3/4$. Let $P_N$ be the probability that you end the experiment on a $1$. What is $\lim_{N\to\infty}P_N$? $P_N$ is decreasing and of course $0\leq P_N$ so the limit exists. I tried taking the limit along ``easy'' sequences like $2^N$ hoping the the extra structure would lend itself to easier analysis, but I couldn't. I imagine I am not the first to ask this question, but I couldn't find it on MSE any other place. Any references to similar questions are also appreciated.",,"['probability', 'combinatorics']"
77,Picking points on a sphere at random,Picking points on a sphere at random,,"Suppose we pick up $N$ points uniformly at random on a sphere. The probability that these points lie within a 'fixed' hemisphere is easily calculated to be $1/2^N$.  But what is the probability that all the points lie within any hemisphere on the sphere?  I am actually interested in this question for $d$-dimensional hypersphere as well, so method of computation that extends to higher dimensions will be much appreciated.","Suppose we pick up $N$ points uniformly at random on a sphere. The probability that these points lie within a 'fixed' hemisphere is easily calculated to be $1/2^N$.  But what is the probability that all the points lie within any hemisphere on the sphere?  I am actually interested in this question for $d$-dimensional hypersphere as well, so method of computation that extends to higher dimensions will be much appreciated.",,"['probability', 'uniform-distribution', 'spheres']"
78,Salvaging a damaged cable,Salvaging a damaged cable,,"Let's say we have a cable of unit length, which is damaged at one unknown point, the location of which is uniformly distributed. You are allowed to cut the cable at any point, and after a cut, you'd know which piece is damaged and which is not. You can do this as many times as you want, and you want to maximize the expected length of the biggest undamaged piece after all the cutting. What is the best you can do? The strategy need not be deterministic. I currently have a lower bound of $\frac12$ and upper bound of $\frac34$. The lower bound comes from just cutting the cable in half once. For the upper bound, notice that if the fault is at $\frac12 \pm x$, then you cannot do better than $\frac12 +x$. So taking the expected value, $$ \int_0^{\frac12} \left(\frac12+x\right)2 dx = \frac34$$ I initially thought that an optimal strategy would have to be applied recursively to the damaged piece, but now I'm no longer convinced of this. If you've already obtained an undamaged piece of length $l$, then there is no point in cutting a damaged piece into two pieces of length $\leq l$. Any reference to an existing treatment is also welcome.","Let's say we have a cable of unit length, which is damaged at one unknown point, the location of which is uniformly distributed. You are allowed to cut the cable at any point, and after a cut, you'd know which piece is damaged and which is not. You can do this as many times as you want, and you want to maximize the expected length of the biggest undamaged piece after all the cutting. What is the best you can do? The strategy need not be deterministic. I currently have a lower bound of $\frac12$ and upper bound of $\frac34$. The lower bound comes from just cutting the cable in half once. For the upper bound, notice that if the fault is at $\frac12 \pm x$, then you cannot do better than $\frac12 +x$. So taking the expected value, $$ \int_0^{\frac12} \left(\frac12+x\right)2 dx = \frac34$$ I initially thought that an optimal strategy would have to be applied recursively to the damaged piece, but now I'm no longer convinced of this. If you've already obtained an undamaged piece of length $l$, then there is no point in cutting a damaged piece into two pieces of length $\leq l$. Any reference to an existing treatment is also welcome.",,"['probability', 'game-theory']"
79,Expected size of subset forming convex polygon.,Expected size of subset forming convex polygon.,,"If there are $4$ random points in the plane whose horizontal coordinate and vertical coordinate are uniformly distributed on the interval $\left(0,1\right)$, what is the expected largest size (or cardinality) of a subset in which the points form the vertices of a convex polygon? Thanks.","If there are $4$ random points in the plane whose horizontal coordinate and vertical coordinate are uniformly distributed on the interval $\left(0,1\right)$, what is the expected largest size (or cardinality) of a subset in which the points form the vertices of a convex polygon? Thanks.",,"['probability', 'combinatorics', 'geometry', 'convex-analysis', 'geometric-probability']"
80,Probability that at least one of four hands missing at least one suit,Probability that at least one of four hands missing at least one suit,,"Deal each of four players a 13-card hand at random.  What is the probability that at least one of the four hands is missing at least one suit? Let $A_i$ mean that player $i$ is missing at least one suit. I can compute the probability that player 1 is missing at least one suit using the inclusion-exclusion principle: $P(A_1) = \dfrac{4 {39 \choose 13} - 6 {26 \choose 13} + 4{13 \choose 13}}{52\choose 13}$ The four players are identical so that $P(A_1)=P(A_2)=P(A_3)=P(A_4)$. Again using the inclusion-exclusion principle, the probability that at least one of the four players is missing at least one suit is $P(\cup_{i=1}^4A_i)=4*P(A_1)-{4 \choose 2}P(A_1\cap A_2) + {4\choose 3} P(A_1\cap A_2 \cap A_3) - P(A_1\cap A_2 \cap A_3 \cap A_4)$ Now we know that $P(A_1 \cap A_2)= P(A_2)P(A_1|A_2)$.  Here is where I am stuck.  So far as I can tell, $A_1$ and $A_2$ are not independent, and I can't figure out how to calculate the conditional probability $P(A_1|A_2)$.  Anyone know how to do it?","Deal each of four players a 13-card hand at random.  What is the probability that at least one of the four hands is missing at least one suit? Let $A_i$ mean that player $i$ is missing at least one suit. I can compute the probability that player 1 is missing at least one suit using the inclusion-exclusion principle: $P(A_1) = \dfrac{4 {39 \choose 13} - 6 {26 \choose 13} + 4{13 \choose 13}}{52\choose 13}$ The four players are identical so that $P(A_1)=P(A_2)=P(A_3)=P(A_4)$. Again using the inclusion-exclusion principle, the probability that at least one of the four players is missing at least one suit is $P(\cup_{i=1}^4A_i)=4*P(A_1)-{4 \choose 2}P(A_1\cap A_2) + {4\choose 3} P(A_1\cap A_2 \cap A_3) - P(A_1\cap A_2 \cap A_3 \cap A_4)$ Now we know that $P(A_1 \cap A_2)= P(A_2)P(A_1|A_2)$.  Here is where I am stuck.  So far as I can tell, $A_1$ and $A_2$ are not independent, and I can't figure out how to calculate the conditional probability $P(A_1|A_2)$.  Anyone know how to do it?",,"['probability', 'combinatorics', 'card-games']"
81,Azuma's inequality to McDiarmid's inequality?,Azuma's inequality to McDiarmid's inequality?,,"I was going through some notes on concentration inequalities when I noticed that there are two commonly-cited forms of McDiarmid's inequality. Long story short: I know how to prove the weaker one from Azuma's inequality. I also know how to prove the stronger one not directly from Azuma. But is there a way to prove the strong one from Azuma's inequality? In what follows I will assume for simplicity that all differences are bounded by 1. Azuma's inequality: Let $S_n = \sum_{i=1}^n X_i$ and $S_0 = 0$. Let the filtration $\{\mathcal{F}_n\}$ be the usual one defined by $\mathcal{F}_n = \sigma(X_1, \ldots, X_n)$. If $\{S_n\}_{n \geq 0}$ is a martingale and $|X_n| \leq 1$ for all $n$, then for $\lambda>0$, $$P(S_n \geq \lambda) \leq \exp \left(-\frac{\lambda^2}{2n} \right)$$ Now here is the ""weak"" version of McDiarmid's which is an obvious application of Azuma's inequality: McDiarmid's inequality: Suppose $\xi_1, \ldots, \xi_n$ are independent. Let $Z = f(\xi_1, \ldots, \xi_n)$. Also, assume that: $$ \Big|\; f(\xi_1, \ldots, \xi_k, \ldots, \xi_n) - f(\xi_1, \ldots, \xi_k', \ldots, \xi_n) \;\Big| \leq 1$$ for two realizations of the same random variable $\xi_k$ and $\xi_k'$. Then for $\lambda>0$, $$ P(Z-EZ \geq \lambda) \leq \exp \left(-\frac{\lambda^2}{2n} \right) $$ Now the strong version of McDiarmid's inequality has the same setup except that the ""2"" in the denominator is moved up to the numerator, so the bound is: $$P(Z-EZ \geq \lambda) \leq \exp \left(-\frac{2\lambda^2}{n} \right)$$ Clearly this bound is sharper than the one in the version presented above. I know a proof for this bound but it does not explicitly use Azuma's inequality above. The question: Is it possible to adapt Azuma's inequality to prove this second bound. More specifically, is there a more general form of Azuma's inequality that can be applied to the case of McDiarmid's inequality to yield the tighter bound? Edit: After pondering it over, I now think that it is not possible. Just intuitively, the bounded martingale difference condition in Azuma's inequality seems somehow ""weaker"" than the condition in McDiarmid's inequality, which is a Lipschitz-like condition on the function $f$. So one would expect that using Azuma's inequality would not give the sharpest bound. Edit 2: To shed some more light on this, the proof of the ""weak"" McDiarmid's using Azuma's inequality goes like this. Define $S_n = E(Z \;|\; \xi_1, \ldots, \xi_m) - EZ$. Then $\{S_m\}_{m \geq 1}$ is a martingale. Also, for $m=n$, $S_m = S_n = Z - EZ$. To prove that the martingale differences are bounded, let $\xi_1', \ldots, \xi_n'$ be independent copies of the $\xi_1, \ldots, \xi_n$. Then we have: $$ E\big[f(\xi_1, \ldots, \xi_m, \ldots, \xi_n) \;\big|\; \xi_1, \ldots, \xi_{m-1}\big] = E\big[f(\xi_1, \ldots, \xi_m', \ldots, \xi_n) \;\big|\; \xi_1, \ldots, \xi_m\big] $$ Thus we have: $$\big|S_m - S_{m-1}\big| \leq E\big[|\, f(\xi_1, \ldots, \xi_m, \ldots, \xi_n) - f(\xi_1, \ldots, \xi_m', \ldots, \xi_n)\,| \;\big|\; \xi_1, \ldots, \xi_m\big]$$ So to satisfy the bounded martingale difference in Azuma's inequality, we only need the expectation of the difference of $f(\cdot) - f(\cdot)$ (conditional on $\xi_1, \ldots, \xi_m$) to be bounded, whereas the assumption in McDiarmid's is slightly stronger. However, the bounded martingale difference must also hold for all $m$, and in particular for the case of conditioning on $\xi_1, \ldots, \xi_n$. In that case it seems to reduce to assumption. So... it does seem like Azuma's inequality (in this form) is not strong enough. Thoughts? Here is a resource presenting the ""standard"" proof of the strong version of McDiarmid's inequality: http://empslocal.ex.ac.uk/people/staff/yy267/McDiarmid.pdf","I was going through some notes on concentration inequalities when I noticed that there are two commonly-cited forms of McDiarmid's inequality. Long story short: I know how to prove the weaker one from Azuma's inequality. I also know how to prove the stronger one not directly from Azuma. But is there a way to prove the strong one from Azuma's inequality? In what follows I will assume for simplicity that all differences are bounded by 1. Azuma's inequality: Let $S_n = \sum_{i=1}^n X_i$ and $S_0 = 0$. Let the filtration $\{\mathcal{F}_n\}$ be the usual one defined by $\mathcal{F}_n = \sigma(X_1, \ldots, X_n)$. If $\{S_n\}_{n \geq 0}$ is a martingale and $|X_n| \leq 1$ for all $n$, then for $\lambda>0$, $$P(S_n \geq \lambda) \leq \exp \left(-\frac{\lambda^2}{2n} \right)$$ Now here is the ""weak"" version of McDiarmid's which is an obvious application of Azuma's inequality: McDiarmid's inequality: Suppose $\xi_1, \ldots, \xi_n$ are independent. Let $Z = f(\xi_1, \ldots, \xi_n)$. Also, assume that: $$ \Big|\; f(\xi_1, \ldots, \xi_k, \ldots, \xi_n) - f(\xi_1, \ldots, \xi_k', \ldots, \xi_n) \;\Big| \leq 1$$ for two realizations of the same random variable $\xi_k$ and $\xi_k'$. Then for $\lambda>0$, $$ P(Z-EZ \geq \lambda) \leq \exp \left(-\frac{\lambda^2}{2n} \right) $$ Now the strong version of McDiarmid's inequality has the same setup except that the ""2"" in the denominator is moved up to the numerator, so the bound is: $$P(Z-EZ \geq \lambda) \leq \exp \left(-\frac{2\lambda^2}{n} \right)$$ Clearly this bound is sharper than the one in the version presented above. I know a proof for this bound but it does not explicitly use Azuma's inequality above. The question: Is it possible to adapt Azuma's inequality to prove this second bound. More specifically, is there a more general form of Azuma's inequality that can be applied to the case of McDiarmid's inequality to yield the tighter bound? Edit: After pondering it over, I now think that it is not possible. Just intuitively, the bounded martingale difference condition in Azuma's inequality seems somehow ""weaker"" than the condition in McDiarmid's inequality, which is a Lipschitz-like condition on the function $f$. So one would expect that using Azuma's inequality would not give the sharpest bound. Edit 2: To shed some more light on this, the proof of the ""weak"" McDiarmid's using Azuma's inequality goes like this. Define $S_n = E(Z \;|\; \xi_1, \ldots, \xi_m) - EZ$. Then $\{S_m\}_{m \geq 1}$ is a martingale. Also, for $m=n$, $S_m = S_n = Z - EZ$. To prove that the martingale differences are bounded, let $\xi_1', \ldots, \xi_n'$ be independent copies of the $\xi_1, \ldots, \xi_n$. Then we have: $$ E\big[f(\xi_1, \ldots, \xi_m, \ldots, \xi_n) \;\big|\; \xi_1, \ldots, \xi_{m-1}\big] = E\big[f(\xi_1, \ldots, \xi_m', \ldots, \xi_n) \;\big|\; \xi_1, \ldots, \xi_m\big] $$ Thus we have: $$\big|S_m - S_{m-1}\big| \leq E\big[|\, f(\xi_1, \ldots, \xi_m, \ldots, \xi_n) - f(\xi_1, \ldots, \xi_m', \ldots, \xi_n)\,| \;\big|\; \xi_1, \ldots, \xi_m\big]$$ So to satisfy the bounded martingale difference in Azuma's inequality, we only need the expectation of the difference of $f(\cdot) - f(\cdot)$ (conditional on $\xi_1, \ldots, \xi_m$) to be bounded, whereas the assumption in McDiarmid's is slightly stronger. However, the bounded martingale difference must also hold for all $m$, and in particular for the case of conditioning on $\xi_1, \ldots, \xi_n$. In that case it seems to reduce to assumption. So... it does seem like Azuma's inequality (in this form) is not strong enough. Thoughts? Here is a resource presenting the ""standard"" proof of the strong version of McDiarmid's inequality: http://empslocal.ex.ac.uk/people/staff/yy267/McDiarmid.pdf",,"['probability', 'measure-theory', 'probability-theory', 'inequality', 'martingales']"
82,Multiplicative version of Mcdiarmid's inequality?,Multiplicative version of Mcdiarmid's inequality?,,"Suppose you have $n$ i.i.d. random variables taking values in $\{0,1\}$, and $X$ represents their sum. Then you can use a Chernoff bound to control the deviation of $X$ from its expectation. The Chernoff bound has two useful forms: the typical bound which controls the additive deviation, in terms of the number of random variables $n$, and the multiplicative bound , which controls the relative deviation from the expectation, with a bound that is independent of the number of random variables $n$. When the quantity that one is interested in is not the sum of $n$ i.i.d. random variables, but instead some other $1$-Lipschitz function of the random variables, then Mcdiarmid's inequality gives essentially the same bound as the additive version of the Chernoff bound. My question: Is there a multiplicative version of Mcdiarmid's inequality that bounds the relative deviation of an arbitrary $1$-Lipschitz function of $n$ i.i.d. random variables in a way that is independent of $n$, akin to the multiplicative version of the Chernoff bound?","Suppose you have $n$ i.i.d. random variables taking values in $\{0,1\}$, and $X$ represents their sum. Then you can use a Chernoff bound to control the deviation of $X$ from its expectation. The Chernoff bound has two useful forms: the typical bound which controls the additive deviation, in terms of the number of random variables $n$, and the multiplicative bound , which controls the relative deviation from the expectation, with a bound that is independent of the number of random variables $n$. When the quantity that one is interested in is not the sum of $n$ i.i.d. random variables, but instead some other $1$-Lipschitz function of the random variables, then Mcdiarmid's inequality gives essentially the same bound as the additive version of the Chernoff bound. My question: Is there a multiplicative version of Mcdiarmid's inequality that bounds the relative deviation of an arbitrary $1$-Lipschitz function of $n$ i.i.d. random variables in a way that is independent of $n$, akin to the multiplicative version of the Chernoff bound?",,"['probability', 'statistics', 'probability-theory']"
83,At what rate does the entropy of shuffled cards converge?,At what rate does the entropy of shuffled cards converge?,,"Consider a somewhat primitive method of shuffling a stack of $n$ cards: In every step, take the top card and insert it at a uniformly randomly selected one of the $n$ possible positions above, between or below the remaining $n-1$ cards. Start with a well-defined configuration, and then track the entropy of the distribution over the possible permutations of the stack as these shuffling steps are applied. It starts off at $0$. Initially most moves will lead to unique permutations, so we should have roughly $n^k$ equiprobable states after $k$ steps, so the entropy should initially increase as $k\log n$. For $k\to\infty$ it should converge to the entropy corresponding to perfect shuffling, $\log n!\approx n(\log n-1)$. What I'd like to know is how this convergence takes place. I have no idea how to approximate the distribution as it approaches perfect shuffling. I computed the entropy for $n=8$ for $k$ up to $50$; here's a plot of the natural logarithm of the deviation from the perfect shuffling entropy $\log n!$: The red crosses show the computed entropy; the green line is a linear fit to the last $30$ crosses, with slope about $-0.57$. So the entropy converges to its maximal value roughly as $\exp (-0.57k)$. For $n=7$, the slope is about $-0.67$, and for $n=9$ it's about $-0.50$. How can we derive this behaviour?","Consider a somewhat primitive method of shuffling a stack of $n$ cards: In every step, take the top card and insert it at a uniformly randomly selected one of the $n$ possible positions above, between or below the remaining $n-1$ cards. Start with a well-defined configuration, and then track the entropy of the distribution over the possible permutations of the stack as these shuffling steps are applied. It starts off at $0$. Initially most moves will lead to unique permutations, so we should have roughly $n^k$ equiprobable states after $k$ steps, so the entropy should initially increase as $k\log n$. For $k\to\infty$ it should converge to the entropy corresponding to perfect shuffling, $\log n!\approx n(\log n-1)$. What I'd like to know is how this convergence takes place. I have no idea how to approximate the distribution as it approaches perfect shuffling. I computed the entropy for $n=8$ for $k$ up to $50$; here's a plot of the natural logarithm of the deviation from the perfect shuffling entropy $\log n!$: The red crosses show the computed entropy; the green line is a linear fit to the last $30$ crosses, with slope about $-0.57$. So the entropy converges to its maximal value roughly as $\exp (-0.57k)$. For $n=7$, the slope is about $-0.67$, and for $n=9$ it's about $-0.50$. How can we derive this behaviour?",,"['probability', 'permutations', 'entropy', 'card-games']"
84,Poisson distribution with an integer $\lambda$ value,Poisson distribution with an integer  value,\lambda,"I have noticed that when a Poisson distribution has an integer value of $\lambda$ , the following holds: $$ \mathbb{P}[X = \lambda] = \mathbb{P}[X = \lambda - 1] $$ I have been able to prove this rather simply using an algebraic method. However, my question is, is there an intuitive reason for why this is the case ? For example, if an average of 10 phone calls are received an hour, why is it that 10 phone calls are equally likely as 9 phone calls?","I have noticed that when a Poisson distribution has an integer value of , the following holds: I have been able to prove this rather simply using an algebraic method. However, my question is, is there an intuitive reason for why this is the case ? For example, if an average of 10 phone calls are received an hour, why is it that 10 phone calls are equally likely as 9 phone calls?","\lambda 
\mathbb{P}[X = \lambda] = \mathbb{P}[X = \lambda - 1]
","['probability', 'probability-distributions', 'intuition', 'poisson-distribution']"
85,Does this random variable have a density?,Does this random variable have a density?,,"I have a persistent problem, which I'm almost certain can be answered using elementary probabilistic arguments, but for some reason I've been stuck for some time. Here is the problem. Let $(B_s, s \in [0,1])$ be a fractional Brownian motion (here is the Wikipedia link for this process: http://en.wikipedia.org/wiki/Fractional_Brownian_motion ). Consider the random variable: $$Z = \int_0^1 B_s^4 \, ds.$$ Does $Z$ have a density? In other words, is the measure induced on $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ by $Z$ absolutley continuous? Many thanks in advance for some thoughts or advice! :) John","I have a persistent problem, which I'm almost certain can be answered using elementary probabilistic arguments, but for some reason I've been stuck for some time. Here is the problem. Let $(B_s, s \in [0,1])$ be a fractional Brownian motion (here is the Wikipedia link for this process: http://en.wikipedia.org/wiki/Fractional_Brownian_motion ). Consider the random variable: $$Z = \int_0^1 B_s^4 \, ds.$$ Does $Z$ have a density? In other words, is the measure induced on $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$ by $Z$ absolutley continuous? Many thanks in advance for some thoughts or advice! :) John",,"['probability', 'measure-theory', 'random-variables', 'brownian-motion']"
86,Number of couples sitting at same table,Number of couples sitting at same table,,"The Problem $ab$ couples are sitting at $a$ tables with $2b$ seats each. Call a couple a ""good"" couple if they are seated at the same table. (1) What is the probability that, in total, there are exactly $k$ ""good"" couples? My Approach so Far Recurrence Relations One possible approach is to set up a recurrence relation, with $p_{a,b,n}$ denoting the probability of having exactly $k$ ""good"" couples. However, the issue with this is to recurrence equation between $p_{a+1,b,k}$ and $p_{a,b,k}$ will not be simple as one will have to consider the different combinations of people on the additional table. Principle of Inclusion and Exclusion Another possible approach is to use PIE. We denote $P_S$ as the probability that only the couples in $S$ are good. While $P_S$ for $|S|=1$ is easy ($P={b-1}/{ab}$), I'm not sure how to proceed.","The Problem $ab$ couples are sitting at $a$ tables with $2b$ seats each. Call a couple a ""good"" couple if they are seated at the same table. (1) What is the probability that, in total, there are exactly $k$ ""good"" couples? My Approach so Far Recurrence Relations One possible approach is to set up a recurrence relation, with $p_{a,b,n}$ denoting the probability of having exactly $k$ ""good"" couples. However, the issue with this is to recurrence equation between $p_{a+1,b,k}$ and $p_{a,b,k}$ will not be simple as one will have to consider the different combinations of people on the additional table. Principle of Inclusion and Exclusion Another possible approach is to use PIE. We denote $P_S$ as the probability that only the couples in $S$ are good. While $P_S$ for $|S|=1$ is easy ($P={b-1}/{ab}$), I'm not sure how to proceed.",,['probability']
87,Probability of a group being finite,Probability of a group being finite,,"Suppose $F_m := F[x_1, … , x_m]$ is a free group on $m$ generators $x_1, … , x_m$ and lets define Cayley ball $B_m^n := \{e, x_1, x_1^{-1}, … , x_m, x_m^{-1}\}^n$ as the set of all elements with Cayley length $n$ or less. Suppose $R_1, … , R_l$ are $l$ random elements chosen uniformly from $B_m^n$ . Then we can define a random group as $G(m, l, n) := \frac{F_m}{\langle \langle \{R_1, … , R_l\} \rangle \rangle}$ . Now will suppose that $m$ is fixed and $l = l(n)$ depends on $n$ . We say that the random group $G(m, l, n)$ belongs to a class of groups $\mathfrak{U}$ almost surely iff $\lim_{n \to \infty} P(G(m, l, n) \in \mathfrak{U}) = 1$ . A following theorem was proved by Ollivier: If $\lim_{n \to \infty} \frac{\ln(l(n))}{n(\ln(2m - 1))} > \frac{1}{2}$ then $G(m, l, n)$ is almost surely finite. If $\lim_{n \to \infty} \frac{\ln(l(n))}{n(\ln(2m - 1))} < \frac{1}{2}$ then $G(m, l, n)$ is almost surely infinite My question is: Is there some sort of exact expression for limit probability $\lim_{n \to \infty} P(G(m, l(n), n) \text{ is finite})$ for arbitrary  non-decreasing $l: \mathbb{N} \to \mathbb{N}$ ? I, personally think, that it is very likely to be of the form $$\lim_{n \to \infty} P(G(m, l(n), n) \text{ is finite}) = \lim_{n \to \infty} a^{-b^{\ln(2m - 1)n - 2\ln(l(n))}}$$ for some positive real numbers $a(m)$ and $b(m)$ . However, I do not know that for sure. That is just intuition mostly based on analogies with a somewhat similar ""phase transition theorem"" from a completely different field, that states: Suppose $G(n, p(n))$ is an Erdos-Renyi random graph with $n$ vertices and edge probability $p(n)$ . Then $\lim_{n \to \infty} P(G(n, p(n)) \text{ is connected}) = \lim_{n \to \infty} e^{-e^{\ln(n) - np(n)}}$","Suppose is a free group on generators and lets define Cayley ball as the set of all elements with Cayley length or less. Suppose are random elements chosen uniformly from . Then we can define a random group as . Now will suppose that is fixed and depends on . We say that the random group belongs to a class of groups almost surely iff . A following theorem was proved by Ollivier: If then is almost surely finite. If then is almost surely infinite My question is: Is there some sort of exact expression for limit probability for arbitrary  non-decreasing ? I, personally think, that it is very likely to be of the form for some positive real numbers and . However, I do not know that for sure. That is just intuition mostly based on analogies with a somewhat similar ""phase transition theorem"" from a completely different field, that states: Suppose is an Erdos-Renyi random graph with vertices and edge probability . Then","F_m := F[x_1, … , x_m] m x_1, … , x_m B_m^n := \{e, x_1, x_1^{-1}, … , x_m, x_m^{-1}\}^n n R_1, … , R_l l B_m^n G(m, l, n) := \frac{F_m}{\langle \langle \{R_1, … , R_l\} \rangle \rangle} m l = l(n) n G(m, l, n) \mathfrak{U} \lim_{n \to \infty} P(G(m, l, n) \in \mathfrak{U}) = 1 \lim_{n \to \infty} \frac{\ln(l(n))}{n(\ln(2m - 1))} > \frac{1}{2} G(m, l, n) \lim_{n \to \infty} \frac{\ln(l(n))}{n(\ln(2m - 1))} < \frac{1}{2} G(m, l, n) \lim_{n \to \infty} P(G(m, l(n), n) \text{ is finite}) l: \mathbb{N} \to \mathbb{N} \lim_{n \to \infty} P(G(m, l(n), n) \text{ is finite}) = \lim_{n \to \infty} a^{-b^{\ln(2m - 1)n - 2\ln(l(n))}} a(m) b(m) G(n, p(n)) n p(n) \lim_{n \to \infty} P(G(n, p(n)) \text{ is connected}) = \lim_{n \to \infty} e^{-e^{\ln(n) - np(n)}}","['probability', 'group-theory', 'finite-groups', 'infinite-groups', 'combinatorial-group-theory']"
88,Random sum in coupon collection,Random sum in coupon collection,,"I have a problem which involves the standard coupon collector's problem to find a probability density from the generating convolution. I start by defining the problem and a few basic statistics. Let the number of unique coupons be $N$, numbered from $1$ to $N$. Our goal is to collect each unique coupon at least once . I want to find the probability distribution of $T=\sum\limits_{i=1}^R X_i$ which is a random sum. Define $R$ to be the number of draws until we collect at least 1 of each unique coupon. This is itself a sum of N independent Geometric random variables $Z_i$, with $R=\sum\limits_{i=1}^N Z_i$. By inclusion-exclusion principles and a little algebra, it is trivial to show $R$ has a probability distribution: $$\mathbb P(R=r)= \frac{N!}{N^r} \times {r-1 \brace N-1}. \quad R\ge N$$ Since $R$ is a sum of independent geometric random variables, it can be shown the probability generating function $g_R(t)$ is $$\mathbb E(t^R) = \prod_{i=1}^N \frac{N - i + 1}{N - (i - 1)t}. \quad |t| \lt \frac{N}{N - 1}$$ Define $X_i$ to be the value of the drawn coupon on each of the independent draws. They are i.i.d. with probability distribution $\mathbb P(X_i=x)= \dfrac 1N$, i.e. $X_i$ has a discrete uniform distribution with $ 1\le X_i \le N$. Therefore the probability generating function $\space g_{X_{i}}(t)$ is $$\mathbb E(t^{X_i}) = \frac {t \left({1 - t^N}\right)} {N \left({1 - t}\right)}. \quad |t| \lt 1$$ Therefore the random sum $T=\sum\limits_{i=1}^R X_i$ should have a convoluted probability generating function $$g_R(g_{X_{i}}(t))= \prod_{i=1}^N \frac{N - i + 1}{N - (i - 1) \times \dfrac {t \left({1 - t^N}\right)} {N \left({1 - t}\right)}}, \quad |t| \lt 1$$ which simplifies to $$\prod_{i=1}^N \frac{N(1-t)(N - i + 1)}{N^2(1-t) - (i - 1) {t \left({1 - t^N}\right)}}.$$ I am as new as you can get to this site so sorry if I buggered something up! Never worked with latex so feel free to change any errors I made. Hopefully this is a fulfilling and interesting question and someone can find a naughty method. Given what I am doing is right (oops if I made a silly error and the answer is cat), if anyone can help with this fun looking convolution (I have chucked a few things at it and resulted in poop) it would be awesome! I have also tried it from first principles through computing $\mathbb P(T=t)$ using combinatorics and compositions but it seems I would need to read up a bit about A-restricted compositions, mostly of which I am having trouble getting my head around. Then again, I am stuck here too. Please help. Much appreciated. :) Links below are just formality for those unfamiliar with the base problem. The standard coupon collector's problem as can be found here . The term in the braces for the distribution of $R$ is the Stirling number of the second kind . Edit 1 Having thought about it for a few days, it seems this problem MAY be able to be done by the law of total probability. However I am still restricted by conditions on the collection, i.e. the number of each coupon collected should be at least $1$ to successfully complete the total. Let me explain: $$\mathbb P(T=t)= \sum_i \mathbb P(T=t \mid R=i) \mathbb P(R=i),$$ where $$i \in \left[ \bigg \lceil {\frac {T- \frac {N(N+1)}2}N} \bigg \rceil +N,N+ T-\frac {N(N+1)}2 \right]$$ So all we need is away to get $\mathbb P(T=t \mid R=i)$ for all $i$. And I know this can be achieved by finding: (1) How many ways in exactly $i-1$ steps we can get a total of $T-j$ for each for each $j \in [1,N]$, and divide it by: (2) the number of ways to finish in $i$ such that each number is rolled at least once not before collection step $i$. Lets think about the case $N=6$ (a fir 6-sided dice) and $T=22$ It is clear our limits for $i$ are from $[\max(6,1)+1,6+1]=[7,7]$, which this implies the only way to achieve total of $22$ where we roll every number from $1 \to 6$ at least once is in exactly $7$ rolls. Hopefully we can see that is the case intuitively. So (1) is calculated by all the permutations of $22-j$ without $j$ for each $j  \in [1,6]$ and (2) is calculated by all the permutations of finishing in $R=i$ goes, independent of finishing on a total of $22$. My issue is then calculating (1) and (to some extent without high knowledge of A-restricted compositions) (2)! Edit 2 I found a closed form for the simplest case N=2. Which is just a coin. With one side labeled a $1$. The other having a $2$. $X_i$ is discrete uniform with $P(X_i=1)=1-P(X_i=2)=\frac 12$. I want to get $P(T=t)$ for $T \ge3$. Let $T=3$. By counting, we can roll a total of 3 by: $$(1,2) \ \ OR \ \ (2,1)$$ Either event has probability $\left( \frac 12 \right)^2$. So we have $P(T=3)=2\left( \frac 12 \right)^2=\left( \frac 12 \right)$ Let $T=4$. By counting, we can roll a total of 4 by: $$(1,1,2)$$ This event has probability $\left( \frac 12 \right)^3$. So we have $P(T=4)=\left( \frac 18 \right)$ Here we do not count the event $(2,1,1)$ as a total of $4$ since by the second roll we have successfully achieved $D$. hence the actual total would be $3$ and we ignore the final $1$. Now, let $T=5$. By counting, we can roll a total of 5 by: $$(1,1,1,2) \ \ OR \ \ (2,2,1)$$ The first event has probability $\left( \frac 12 \right)^4$. The second event has probability $\left( \frac 12 \right)^3$ So we have $P(T=5)=\left( \frac 12 \right)^4+ \left( \frac 12 \right)^3$ If we continue in this fashion, we will always have exactly 2 ways of rolling a total of $T=t$. One with probability to the power of $T-\sum_{i=1}^2i=T-3$ and the other with probability to the power of $\frac {T-3}2$ when T is odd and $0$ if even. We can hence write down the closed form for the simplest case where $N=2$ as: $$P(T=t|N=2)=\frac 14 \left(\left(\frac 12 \right)^{t-3}+\Bbb I_{t \ is \ odd} \left(\frac 12 \right)^{\frac{t-3}2} \right)$$ But of course this still leaves me with not knowing $N=3,4,5,...$ Edit 3 As well noted in the comments, the basic statistics for this problem follow from the definitions of $R$ and $X_i$. Firstly: $$\Bbb E(T)=\Bbb E(\sum\limits_{i=1}^R X_i)$$. It is known that:  $$\Bbb E(R)=N\ \sum\limits_{i=1}^N E(Z_i)=NH_N$$ for $H_n=\sum\limits_{i=1}^N \frac 1i$ the harmonic number. Since $X_i$ is uniform: $$\Bbb E(X_i)=\frac {N+1}2 \ \ \forall i$$ Putting it all together using Wald's identity we get: $$\Bbb E(T)=\Bbb E(R)\Bbb E(X_i)=N\sum\limits_{i=1}^N \frac 1i \frac {N+1}2$$ $$=\frac 12 N(N+1) \sum\limits_{i=1}^N \frac 1i$$ Next lets consider the variance: $$\Bbb V(T)=\Bbb V(\sum\limits_{i=1}^R X_i)$$ It is also known that (from properties of i.i.d. geometric random variables): $$\Bbb V(R)=N\sum\limits_{i=1}^N \frac {i-1}{(N-i+1)^2}$$ Since $X_i$ is uniform: $$\Bbb V(X_i)=\frac {N^2-1}{12} \ \ \forall i$$ Now using the identity for the variance of a random sum via law of iterated variance: $$\Bbb V(T)=\Bbb E(R) \Bbb V(X_i) + [\Bbb E(X_i)]^2 \Bbb V(R)$$ $$=N \sum\limits_{i=1}^N \frac 1i \frac {N^2-1}{12}+\frac {(N+1)^2}4 \sum\limits_{i=1}^N \frac {N(i-1)}{(N-i+1)^2}$$ $$=\frac {N(N+1)(N-1)}{12} \sum\limits_{i=1}^N \frac 1i+\frac {N(N+1)(N+1)}4 \sum\limits_{i=1}^N \frac {i-1}{(N-i+1)^2}$$ $$=\frac {N(N+1)}{12} \sum\limits_{i=1}^N \left[ \frac {N-1}i + \frac {3(N+1)(i-1)}{(N-i+1)^2} \right]$$ So for example when $N=6$, i.e. a die: $$\Bbb E(T)=\frac 12 6(6+1) \sum\limits_{i=1}^6 \frac 1i=51.45$$ $$\Bbb V(T)=\frac {6(7)}{12} \sum\limits_{i=1}^6 \left[ \frac {5}i + \frac {3(7)(i-1)}{(6-i+1)^2} \right]=\frac {42}{12} 148.715= 520.5025$$ This makes sense. On average we roll $14.7$ times and get $3.5$ on each roll. $14.7 \cdot 3.5=51.45$. In fact, a simulation of $10$ million collections shows that these are the correct values: > mean(Test$Roll_Total) [1] 51.45751 > var(Test$Roll_Total) [1] 520.5317 And the following diagram shows the distribution for the total $T$: Aside : I have been trying to read up on generating functions for compositions and I cannot quite find what I am looking for in terms of restrictions. If someone finds one please let me know! Help / hints appreciated :)","I have a problem which involves the standard coupon collector's problem to find a probability density from the generating convolution. I start by defining the problem and a few basic statistics. Let the number of unique coupons be $N$, numbered from $1$ to $N$. Our goal is to collect each unique coupon at least once . I want to find the probability distribution of $T=\sum\limits_{i=1}^R X_i$ which is a random sum. Define $R$ to be the number of draws until we collect at least 1 of each unique coupon. This is itself a sum of N independent Geometric random variables $Z_i$, with $R=\sum\limits_{i=1}^N Z_i$. By inclusion-exclusion principles and a little algebra, it is trivial to show $R$ has a probability distribution: $$\mathbb P(R=r)= \frac{N!}{N^r} \times {r-1 \brace N-1}. \quad R\ge N$$ Since $R$ is a sum of independent geometric random variables, it can be shown the probability generating function $g_R(t)$ is $$\mathbb E(t^R) = \prod_{i=1}^N \frac{N - i + 1}{N - (i - 1)t}. \quad |t| \lt \frac{N}{N - 1}$$ Define $X_i$ to be the value of the drawn coupon on each of the independent draws. They are i.i.d. with probability distribution $\mathbb P(X_i=x)= \dfrac 1N$, i.e. $X_i$ has a discrete uniform distribution with $ 1\le X_i \le N$. Therefore the probability generating function $\space g_{X_{i}}(t)$ is $$\mathbb E(t^{X_i}) = \frac {t \left({1 - t^N}\right)} {N \left({1 - t}\right)}. \quad |t| \lt 1$$ Therefore the random sum $T=\sum\limits_{i=1}^R X_i$ should have a convoluted probability generating function $$g_R(g_{X_{i}}(t))= \prod_{i=1}^N \frac{N - i + 1}{N - (i - 1) \times \dfrac {t \left({1 - t^N}\right)} {N \left({1 - t}\right)}}, \quad |t| \lt 1$$ which simplifies to $$\prod_{i=1}^N \frac{N(1-t)(N - i + 1)}{N^2(1-t) - (i - 1) {t \left({1 - t^N}\right)}}.$$ I am as new as you can get to this site so sorry if I buggered something up! Never worked with latex so feel free to change any errors I made. Hopefully this is a fulfilling and interesting question and someone can find a naughty method. Given what I am doing is right (oops if I made a silly error and the answer is cat), if anyone can help with this fun looking convolution (I have chucked a few things at it and resulted in poop) it would be awesome! I have also tried it from first principles through computing $\mathbb P(T=t)$ using combinatorics and compositions but it seems I would need to read up a bit about A-restricted compositions, mostly of which I am having trouble getting my head around. Then again, I am stuck here too. Please help. Much appreciated. :) Links below are just formality for those unfamiliar with the base problem. The standard coupon collector's problem as can be found here . The term in the braces for the distribution of $R$ is the Stirling number of the second kind . Edit 1 Having thought about it for a few days, it seems this problem MAY be able to be done by the law of total probability. However I am still restricted by conditions on the collection, i.e. the number of each coupon collected should be at least $1$ to successfully complete the total. Let me explain: $$\mathbb P(T=t)= \sum_i \mathbb P(T=t \mid R=i) \mathbb P(R=i),$$ where $$i \in \left[ \bigg \lceil {\frac {T- \frac {N(N+1)}2}N} \bigg \rceil +N,N+ T-\frac {N(N+1)}2 \right]$$ So all we need is away to get $\mathbb P(T=t \mid R=i)$ for all $i$. And I know this can be achieved by finding: (1) How many ways in exactly $i-1$ steps we can get a total of $T-j$ for each for each $j \in [1,N]$, and divide it by: (2) the number of ways to finish in $i$ such that each number is rolled at least once not before collection step $i$. Lets think about the case $N=6$ (a fir 6-sided dice) and $T=22$ It is clear our limits for $i$ are from $[\max(6,1)+1,6+1]=[7,7]$, which this implies the only way to achieve total of $22$ where we roll every number from $1 \to 6$ at least once is in exactly $7$ rolls. Hopefully we can see that is the case intuitively. So (1) is calculated by all the permutations of $22-j$ without $j$ for each $j  \in [1,6]$ and (2) is calculated by all the permutations of finishing in $R=i$ goes, independent of finishing on a total of $22$. My issue is then calculating (1) and (to some extent without high knowledge of A-restricted compositions) (2)! Edit 2 I found a closed form for the simplest case N=2. Which is just a coin. With one side labeled a $1$. The other having a $2$. $X_i$ is discrete uniform with $P(X_i=1)=1-P(X_i=2)=\frac 12$. I want to get $P(T=t)$ for $T \ge3$. Let $T=3$. By counting, we can roll a total of 3 by: $$(1,2) \ \ OR \ \ (2,1)$$ Either event has probability $\left( \frac 12 \right)^2$. So we have $P(T=3)=2\left( \frac 12 \right)^2=\left( \frac 12 \right)$ Let $T=4$. By counting, we can roll a total of 4 by: $$(1,1,2)$$ This event has probability $\left( \frac 12 \right)^3$. So we have $P(T=4)=\left( \frac 18 \right)$ Here we do not count the event $(2,1,1)$ as a total of $4$ since by the second roll we have successfully achieved $D$. hence the actual total would be $3$ and we ignore the final $1$. Now, let $T=5$. By counting, we can roll a total of 5 by: $$(1,1,1,2) \ \ OR \ \ (2,2,1)$$ The first event has probability $\left( \frac 12 \right)^4$. The second event has probability $\left( \frac 12 \right)^3$ So we have $P(T=5)=\left( \frac 12 \right)^4+ \left( \frac 12 \right)^3$ If we continue in this fashion, we will always have exactly 2 ways of rolling a total of $T=t$. One with probability to the power of $T-\sum_{i=1}^2i=T-3$ and the other with probability to the power of $\frac {T-3}2$ when T is odd and $0$ if even. We can hence write down the closed form for the simplest case where $N=2$ as: $$P(T=t|N=2)=\frac 14 \left(\left(\frac 12 \right)^{t-3}+\Bbb I_{t \ is \ odd} \left(\frac 12 \right)^{\frac{t-3}2} \right)$$ But of course this still leaves me with not knowing $N=3,4,5,...$ Edit 3 As well noted in the comments, the basic statistics for this problem follow from the definitions of $R$ and $X_i$. Firstly: $$\Bbb E(T)=\Bbb E(\sum\limits_{i=1}^R X_i)$$. It is known that:  $$\Bbb E(R)=N\ \sum\limits_{i=1}^N E(Z_i)=NH_N$$ for $H_n=\sum\limits_{i=1}^N \frac 1i$ the harmonic number. Since $X_i$ is uniform: $$\Bbb E(X_i)=\frac {N+1}2 \ \ \forall i$$ Putting it all together using Wald's identity we get: $$\Bbb E(T)=\Bbb E(R)\Bbb E(X_i)=N\sum\limits_{i=1}^N \frac 1i \frac {N+1}2$$ $$=\frac 12 N(N+1) \sum\limits_{i=1}^N \frac 1i$$ Next lets consider the variance: $$\Bbb V(T)=\Bbb V(\sum\limits_{i=1}^R X_i)$$ It is also known that (from properties of i.i.d. geometric random variables): $$\Bbb V(R)=N\sum\limits_{i=1}^N \frac {i-1}{(N-i+1)^2}$$ Since $X_i$ is uniform: $$\Bbb V(X_i)=\frac {N^2-1}{12} \ \ \forall i$$ Now using the identity for the variance of a random sum via law of iterated variance: $$\Bbb V(T)=\Bbb E(R) \Bbb V(X_i) + [\Bbb E(X_i)]^2 \Bbb V(R)$$ $$=N \sum\limits_{i=1}^N \frac 1i \frac {N^2-1}{12}+\frac {(N+1)^2}4 \sum\limits_{i=1}^N \frac {N(i-1)}{(N-i+1)^2}$$ $$=\frac {N(N+1)(N-1)}{12} \sum\limits_{i=1}^N \frac 1i+\frac {N(N+1)(N+1)}4 \sum\limits_{i=1}^N \frac {i-1}{(N-i+1)^2}$$ $$=\frac {N(N+1)}{12} \sum\limits_{i=1}^N \left[ \frac {N-1}i + \frac {3(N+1)(i-1)}{(N-i+1)^2} \right]$$ So for example when $N=6$, i.e. a die: $$\Bbb E(T)=\frac 12 6(6+1) \sum\limits_{i=1}^6 \frac 1i=51.45$$ $$\Bbb V(T)=\frac {6(7)}{12} \sum\limits_{i=1}^6 \left[ \frac {5}i + \frac {3(7)(i-1)}{(6-i+1)^2} \right]=\frac {42}{12} 148.715= 520.5025$$ This makes sense. On average we roll $14.7$ times and get $3.5$ on each roll. $14.7 \cdot 3.5=51.45$. In fact, a simulation of $10$ million collections shows that these are the correct values: > mean(Test$Roll_Total) [1] 51.45751 > var(Test$Roll_Total) [1] 520.5317 And the following diagram shows the distribution for the total $T$: Aside : I have been trying to read up on generating functions for compositions and I cannot quite find what I am looking for in terms of restrictions. If someone finds one please let me know! Help / hints appreciated :)",,"['probability', 'combinatorics', 'probability-theory', 'generating-functions', 'coupon-collector']"
89,Progressive Dice Game,Progressive Dice Game,,"$(2019.)$ Edit: Rewriting the question to make it clear. The progressive dice game At the start, you have a fair, regular six sided dice $D=(1,2,3,4,5,6)$ . The game is played for $n$ turns. Each turn you make a roll, which will be $r\in D$ . Then to complete the turn, you make one of the following choices: Bank the rolled number: You gain $r$ points (score). Invest in (upgrade) the dice ""evenly"" : If $r\lt 6$ , choose $r$ sides and increase them by $1$ each. If $r\ge 6$ , that is, $r=6k+k_0,k_0\lt 6$ , then increase each of the six sides by $k$ , and then choose $k_0$ sides and increase them by $1$ each. Reroll the dice, effectively restarting this turn. But before rerolling, you must apply the penalty to the dice: ""Evenly"" downgrade the dice: If $S_0$ is the number of sides $\gt 0$ on the dice, then: If $r\lt S_0$ , choose $r$ sides and decrease them by $1$ each. If $r\ge S_0$ , that is, $r=S_0k+k_0,k_0\lt S_0$ , then decrease each of the $S_0$ sides by $k$ , and then choose $k_0$ sides and decrease them by $1$ each. What is the optimal way to play to maximize your expected score at the end of the game? If the dice was allowed to be upgraded/downgraded arbitrarily (not ""evenly""), then one could downgrade the first five sides until they reach $0$ . These sides now act as free rerolls. Then, keep investing the remaining points into the sixth side, which is now guaranteed to be rolled on each turn, after some amount of rerolls of that turn. Finally, bank that sixth rolled side in the last couple turns to maximize the expected value of the score. But since we must upgrade/downgrade evenly, I'm not sure what is the optimal strategy. If we ignore the ""reroll"" move: If you upgrade the first $t$ turns, then bank the rest of the turns, you will expect the following amount of points on average: $$ f(t) = 3.5\times\left(\frac{7}{6}\right)^{t}\times(n-t)$$ Which boils down to, that if you want to maximize your expected score, you should upgrade until the last $6$ (or $7$ ) turns and then bank those turns. But this approach completely ignores the third action; the rerolls. Can we do better than this strategy, if we use the rerolls somehow? Rerolls? I haven't worked out the strategy if the rerolls are considered. A reroll will on average decrease the average value of the dice, and allow you to either improve or worsen your current turn, with equal probability on average? But there seem to be exceptions? For example, rerolling a $1$ seems useful if used early (as later, if we had upgraded a lot, all sides will be much greater than $1$ ). Simply downgrade the rolled $1$ side when downgrading (rerolling). If you roll that side again, it will be $0$ , and this allows you to again reroll the dice for free (downgrading $0$ points is a free reroll). Which means, choosing to downgrade when you roll a $1$ , can only increase your expected score in that turn. But there is still a (small?) drawback: Lets say some other side is a number $\ge 6$ . Then when upgrading later, you will have to put back at least one of those upgrade points into that downgraded $0$ side. Seems to me that rerolls will decrease the expected score on average   (as they decrease the average value of the dice), so it is always   better not to use them (except in that early scenario of the game, if $n$ is small)? Is this true? For example, for small $n$ , rerolls can be useful to force larger values. For $n=1$ specifically, it seems we can always force the first turn (the only turn) to end up banking a $6$ , the maximal possible score for $n=1$ , by rerolling and downgrading strategically the rest of the sides if $6$ was not rolled. But for large $n$ , the rerolls seem to lower the average expected score at the end, if used anytime in previous turns, as larger upgrades will need to replenish those downgraded points inevetably at some point, as they are carried out ""evenly"".","Edit: Rewriting the question to make it clear. The progressive dice game At the start, you have a fair, regular six sided dice . The game is played for turns. Each turn you make a roll, which will be . Then to complete the turn, you make one of the following choices: Bank the rolled number: You gain points (score). Invest in (upgrade) the dice ""evenly"" : If , choose sides and increase them by each. If , that is, , then increase each of the six sides by , and then choose sides and increase them by each. Reroll the dice, effectively restarting this turn. But before rerolling, you must apply the penalty to the dice: ""Evenly"" downgrade the dice: If is the number of sides on the dice, then: If , choose sides and decrease them by each. If , that is, , then decrease each of the sides by , and then choose sides and decrease them by each. What is the optimal way to play to maximize your expected score at the end of the game? If the dice was allowed to be upgraded/downgraded arbitrarily (not ""evenly""), then one could downgrade the first five sides until they reach . These sides now act as free rerolls. Then, keep investing the remaining points into the sixth side, which is now guaranteed to be rolled on each turn, after some amount of rerolls of that turn. Finally, bank that sixth rolled side in the last couple turns to maximize the expected value of the score. But since we must upgrade/downgrade evenly, I'm not sure what is the optimal strategy. If we ignore the ""reroll"" move: If you upgrade the first turns, then bank the rest of the turns, you will expect the following amount of points on average: Which boils down to, that if you want to maximize your expected score, you should upgrade until the last (or ) turns and then bank those turns. But this approach completely ignores the third action; the rerolls. Can we do better than this strategy, if we use the rerolls somehow? Rerolls? I haven't worked out the strategy if the rerolls are considered. A reroll will on average decrease the average value of the dice, and allow you to either improve or worsen your current turn, with equal probability on average? But there seem to be exceptions? For example, rerolling a seems useful if used early (as later, if we had upgraded a lot, all sides will be much greater than ). Simply downgrade the rolled side when downgrading (rerolling). If you roll that side again, it will be , and this allows you to again reroll the dice for free (downgrading points is a free reroll). Which means, choosing to downgrade when you roll a , can only increase your expected score in that turn. But there is still a (small?) drawback: Lets say some other side is a number . Then when upgrading later, you will have to put back at least one of those upgrade points into that downgraded side. Seems to me that rerolls will decrease the expected score on average   (as they decrease the average value of the dice), so it is always   better not to use them (except in that early scenario of the game, if is small)? Is this true? For example, for small , rerolls can be useful to force larger values. For specifically, it seems we can always force the first turn (the only turn) to end up banking a , the maximal possible score for , by rerolling and downgrading strategically the rest of the sides if was not rolled. But for large , the rerolls seem to lower the average expected score at the end, if used anytime in previous turns, as larger upgrades will need to replenish those downgraded points inevetably at some point, as they are carried out ""evenly"".","(2019.) D=(1,2,3,4,5,6) n r\in D r r\lt 6 r 1 r\ge 6 r=6k+k_0,k_0\lt 6 k k_0 1 S_0 \gt 0 r\lt S_0 r 1 r\ge S_0 r=S_0k+k_0,k_0\lt S_0 S_0 k k_0 1 0 t  f(t) = 3.5\times\left(\frac{7}{6}\right)^{t}\times(n-t) 6 7 1 1 1 0 0 1 \ge 6 0 n n n=1 6 n=1 6 n","['probability', 'recreational-mathematics', 'game-theory', 'dice']"
90,Probability that the sum of 6 dice rolls is even,Probability that the sum of 6 dice rolls is even,,"Question: 6 unbiased dice are tossed together. What is the probability that the sum of all the dice is an even number? I think the answer would be 50%, purely by intuition. However, not sure if this is correct. How should I go about solving such a problem?","Question: 6 unbiased dice are tossed together. What is the probability that the sum of all the dice is an even number? I think the answer would be 50%, purely by intuition. However, not sure if this is correct. How should I go about solving such a problem?",,"['probability', 'dice']"
91,Rolling $2$ dice: NOT using $36$ as the base?,Rolling  dice: NOT using  as the base?,2 36,"I apologize for such a simple question. It has been a while since I took math classes. When you roll $2$ dice, there are $36$ possibilities. However, there are only $21$ combinations, if order does not matter. Rolling a $(4,2)$ = rolling a $(2,4)$. Let's say in a game, rolling a $(1,1)$ makes you lose. The odds of rolling this is a $1/36$. But why can't you say the probability is a $1/21$, assuming you roll both dice at the same time? There's only one combination that makes you lose, so why can't you use $21$ as the denominator? I have tried searching on this topic, but have not found a good answer. (Most likely because my thinking is fallacious.)","I apologize for such a simple question. It has been a while since I took math classes. When you roll $2$ dice, there are $36$ possibilities. However, there are only $21$ combinations, if order does not matter. Rolling a $(4,2)$ = rolling a $(2,4)$. Let's say in a game, rolling a $(1,1)$ makes you lose. The odds of rolling this is a $1/36$. But why can't you say the probability is a $1/21$, assuming you roll both dice at the same time? There's only one combination that makes you lose, so why can't you use $21$ as the denominator? I have tried searching on this topic, but have not found a good answer. (Most likely because my thinking is fallacious.)",,"['probability', 'combinatorics', 'permutations', 'dice']"
92,Four coins with reflip problem?,Four coins with reflip problem?,,"I came across the following problem today. Flip four coins. For every head, you get $\$1$ . You may reflip one coin after the four flips. Calculate the expected returns. I know that the expected value without the extra flip is $\$2$ . However, I am unsure of how to condition on the extra flips. I am tempted to claim that having the reflip simply adds $\$\frac{1}{2}$ to each case with tails since the only thing which affects the reflip is whether there are tails or not, but my gut tells me this is wrong. I am also told the correct returns is $\$\frac{79}{32}$ and I have no idea where this comes from.","I came across the following problem today. Flip four coins. For every head, you get . You may reflip one coin after the four flips. Calculate the expected returns. I know that the expected value without the extra flip is . However, I am unsure of how to condition on the extra flips. I am tempted to claim that having the reflip simply adds to each case with tails since the only thing which affects the reflip is whether there are tails or not, but my gut tells me this is wrong. I am also told the correct returns is and I have no idea where this comes from.",\1 \2 \\frac{1}{2} \\frac{79}{32},"['probability', 'conditional-expectation', 'conditional-probability', 'expected-value']"
93,"Six throws, only two distinct numbers: coincidence?","Six throws, only two distinct numbers: coincidence?",,"My daughter threw a die (D6) six times and got: 6,2,2,6,2,6. This got us wondering whether having only two distinct numbers come up in six throws was very unlikely or would happen fairly often. How would we go about working out the answer to that question? (short of doing it lots of times and counting!)","My daughter threw a die (D6) six times and got: 6,2,2,6,2,6. This got us wondering whether having only two distinct numbers come up in six throws was very unlikely or would happen fairly often. How would we go about working out the answer to that question? (short of doing it lots of times and counting!)",,['probability']
94,Probability of picking a random natural number,Probability of picking a random natural number,,"I randomly pick a natural number n . Assuming that I would have picked each number with the same probability, what was the probability for me to pick n before I did it?","I randomly pick a natural number n . Assuming that I would have picked each number with the same probability, what was the probability for me to pick n before I did it?",,[]
95,Find the probability density function of $Y=X^2$,Find the probability density function of,Y=X^2,"Consider the random variable X with probability density function $$f(x) = \begin{cases}   3x^2; & \text{ if, } 0 < x < 1 \\  0; & \text{ otherwise } \end{cases}$$ Find the probability density function of $Y=X^2$. This is the first question of this type I have encountered, I have started by noting that since $0<x<1$, we have that $0< x^2<1$. So $X^2$ is distributed over $(0,1)$. I'm not really sure how to progress or what method to take to actually find the pdf.","Consider the random variable X with probability density function $$f(x) = \begin{cases}   3x^2; & \text{ if, } 0 < x < 1 \\  0; & \text{ otherwise } \end{cases}$$ Find the probability density function of $Y=X^2$. This is the first question of this type I have encountered, I have started by noting that since $0<x<1$, we have that $0< x^2<1$. So $X^2$ is distributed over $(0,1)$. I'm not really sure how to progress or what method to take to actually find the pdf.",,"['probability', 'probability-theory', 'functions', 'probability-distributions']"
96,Expected number of unique items when drawing with replacement [duplicate],Expected number of unique items when drawing with replacement [duplicate],,"This question already has answers here : How many bins do random numbers fill? (2 answers) Closed last year . Having a set of size M, I'm drawing M items with replacement. What is expected number of unique items that got picked? Thanks, Jarek","This question already has answers here : How many bins do random numbers fill? (2 answers) Closed last year . Having a set of size M, I'm drawing M items with replacement. What is expected number of unique items that got picked? Thanks, Jarek",,['probability']
97,What is the probability of a biased coin coming up heads given that a liar is claiming that the coin came up heads?,What is the probability of a biased coin coming up heads given that a liar is claiming that the coin came up heads?,,"A biased coin is tossed. Probability of Head - $\frac{1}{8}$ Probability of Tail - $\frac{7}{8}$ A liar watches the coin toss. Probability of his lying is $\frac{3}{4}$ and telling the truth is $\frac{1}{4}$ . He says that that the outcome is Head. What is the probability that the coin has truly turned Head? My Attempt : I used the formula: $$P(A \mid B) = \frac{P(A\cap B)}{P(B)}$$ $\ \ \ \ \ \ $ P(it is head GIVEN liar said it's head) = P(it's head AND liar said it's head) / P(liar said it's head) or, P(it is head GIVEN liar said it's head) = $\frac{ \frac{1}{8} \frac{1}{4} }{ \frac{7}{8}\frac{3}{4} + \frac{1}{8}\frac{1}{4} }$ [using a probability tree will be helpful here] or, P(it is head GIVEN liar said it's head) = $\frac{1}{22}$ The Question: Is the method I used wrong in any way? Some others I have talked to are saying the answer will be $\frac{1}{4}$ . Their reasoning is this: since the liar lies 3 times out of 4 and he said it is head, then the probability of it being head is 1/4. So who is right? What will be the answer?","A biased coin is tossed. Probability of Head - Probability of Tail - A liar watches the coin toss. Probability of his lying is and telling the truth is . He says that that the outcome is Head. What is the probability that the coin has truly turned Head? My Attempt : I used the formula: P(it is head GIVEN liar said it's head) = P(it's head AND liar said it's head) / P(liar said it's head) or, P(it is head GIVEN liar said it's head) = [using a probability tree will be helpful here] or, P(it is head GIVEN liar said it's head) = The Question: Is the method I used wrong in any way? Some others I have talked to are saying the answer will be . Their reasoning is this: since the liar lies 3 times out of 4 and he said it is head, then the probability of it being head is 1/4. So who is right? What will be the answer?",\frac{1}{8} \frac{7}{8} \frac{3}{4} \frac{1}{4} P(A \mid B) = \frac{P(A\cap B)}{P(B)} \ \ \ \ \ \  \frac{ \frac{1}{8} \frac{1}{4} }{ \frac{7}{8}\frac{3}{4} + \frac{1}{8}\frac{1}{4} } \frac{1}{22} \frac{1}{4},"['probability', 'conditional-probability']"
98,Probability of getting a full house,Probability of getting a full house,,"If five cards are selected at random from a standard 52 card deck, what is the probability of getting a full house. This is what I am thinking. $(52*\binom{4}{3}*\binom{4}{2})/_{52}C_5$ Is that right?","If five cards are selected at random from a standard 52 card deck, what is the probability of getting a full house. This is what I am thinking. $(52*\binom{4}{3}*\binom{4}{2})/_{52}C_5$ Is that right?",,['probability']
99,Why is $0.63212$ the probability of a $\frac1n$-probability event happening in $n$ trials?,Why is  the probability of a -probability event happening in  trials?,0.63212 \frac1n n,"I've always assumed on faulty intuition that if you have an event which occurs 1 in n chances, it will be super likely to happen at some point of that event occuring n times.  However, given some analysis, it doesn't actually seem to be all that super likely, and seems to converge at a particular value as the value of n rises.  That value is about 0.63212. Is this correct?  If so, is there a name for this value and is it considered significant within the field of probability? Below is the Python code that I used to arrive at this value. >>> def p(x, r): ...   return x + r * (1.0 - x)  >>> def p_of_1(r): ...   x = r ...   while True: ...     yield x ...     x = p(x, r)  >>> def p_of_n(n): ...   g = p_of_1(1.0 / n) ...   return [next(g) for x in range(n)] ...  >>> p_of_n(1) [1.0] >>> p_of_n(2) [0.5, 0.75] >>> p_of_n(3) [0.3333333333333333, 0.5555555555555556, 0.7037037037037037] >>> p_of_n(4) [0.25, 0.4375, 0.578125, 0.68359375] >>> p_of_n(5) [0.2, 0.36000000000000004, 0.488, 0.5904, 0.67232]  >>> p_of_n(6)[-1] 0.6651020233196159 >>> p_of_n(10)[-1] 0.6513215599000001 >>> p_of_n(100)[-1] 0.6339676587267709 >>> p_of_n(10000)[-1] 0.6321389535670703 >>> p_of_n(10000000)[-1] 0.6321205772225762","I've always assumed on faulty intuition that if you have an event which occurs 1 in n chances, it will be super likely to happen at some point of that event occuring n times.  However, given some analysis, it doesn't actually seem to be all that super likely, and seems to converge at a particular value as the value of n rises.  That value is about 0.63212. Is this correct?  If so, is there a name for this value and is it considered significant within the field of probability? Below is the Python code that I used to arrive at this value. >>> def p(x, r): ...   return x + r * (1.0 - x)  >>> def p_of_1(r): ...   x = r ...   while True: ...     yield x ...     x = p(x, r)  >>> def p_of_n(n): ...   g = p_of_1(1.0 / n) ...   return [next(g) for x in range(n)] ...  >>> p_of_n(1) [1.0] >>> p_of_n(2) [0.5, 0.75] >>> p_of_n(3) [0.3333333333333333, 0.5555555555555556, 0.7037037037037037] >>> p_of_n(4) [0.25, 0.4375, 0.578125, 0.68359375] >>> p_of_n(5) [0.2, 0.36000000000000004, 0.488, 0.5904, 0.67232]  >>> p_of_n(6)[-1] 0.6651020233196159 >>> p_of_n(10)[-1] 0.6513215599000001 >>> p_of_n(100)[-1] 0.6339676587267709 >>> p_of_n(10000)[-1] 0.6321389535670703 >>> p_of_n(10000000)[-1] 0.6321205772225762",,['probability']
