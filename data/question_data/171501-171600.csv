,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,the maximum likelihood estimator of $p?$ [closed],the maximum likelihood estimator of  [closed],p?,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question $X$ is a single observation from Binomial $(1, p)$ population, where $p \in [1/5, 4/5]$ is unknown. If the observed value of $X$ is zero, then the maximum likelihood estimator of $p?$ I am stuck with this problem, please help.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question $X$ is a single observation from Binomial $(1, p)$ population, where $p \in [1/5, 4/5]$ is unknown. If the observed value of $X$ is zero, then the maximum likelihood estimator of $p?$ I am stuck with this problem, please help.",,['probability']
1,Question on the properties of of the Statistical Variance,Question on the properties of of the Statistical Variance,,"So, I have a question on which I am not entirely sure on the answers and I would like to discuss it here. Given two random variables $X$ and $Y$, and two real numbers $a$ and $b$, then which of the following hold true? 1) Variance of $X$ is always non-negative 2) The Standard Deviation of $X$ is always non-negative 3) If $V(X) = V(Y)$, then $V(X+a)=V(Y+b)$ 4) If $V(aX) = V(bX)$ for $a \neq 0$ and $b \neq 0$, then $a = b$ 5) If $E[X] = E[Y]$ and $V(X) = V(Y)$, then $X = Y$ 6) If $E[X] = E[Y]$ and $V(X) = V(Y)$, then $E[X^2] = E[Y^2]$ I know that 1) and 2) must be True for all X, because the formula of both Standard Deviation and Variance (also, in a logical sense: you cant measure the distance of a data point from the mean in negative values). 3) is also correct given that a translation of a Random Variable does not affect how far apart each data point lie from the mean. Number 4) is where I'm a little bit less sure: Given that $$ V(zX) = z^2V(X) $$ Then... $$ V(aX) = V(bX) \\ a^2V(X) = b^2V(X) \\ a^2 = b^2 \\ \pm \sqrt{a^2} =\pm \sqrt{b^2} $$ And this is where I'm a bit lost given the possible cases that can come up. Number 5) seems logically enough for me to think it's true and number 6) unfortunately I am not sure. Can anybody help?","So, I have a question on which I am not entirely sure on the answers and I would like to discuss it here. Given two random variables $X$ and $Y$, and two real numbers $a$ and $b$, then which of the following hold true? 1) Variance of $X$ is always non-negative 2) The Standard Deviation of $X$ is always non-negative 3) If $V(X) = V(Y)$, then $V(X+a)=V(Y+b)$ 4) If $V(aX) = V(bX)$ for $a \neq 0$ and $b \neq 0$, then $a = b$ 5) If $E[X] = E[Y]$ and $V(X) = V(Y)$, then $X = Y$ 6) If $E[X] = E[Y]$ and $V(X) = V(Y)$, then $E[X^2] = E[Y^2]$ I know that 1) and 2) must be True for all X, because the formula of both Standard Deviation and Variance (also, in a logical sense: you cant measure the distance of a data point from the mean in negative values). 3) is also correct given that a translation of a Random Variable does not affect how far apart each data point lie from the mean. Number 4) is where I'm a little bit less sure: Given that $$ V(zX) = z^2V(X) $$ Then... $$ V(aX) = V(bX) \\ a^2V(X) = b^2V(X) \\ a^2 = b^2 \\ \pm \sqrt{a^2} =\pm \sqrt{b^2} $$ And this is where I'm a bit lost given the possible cases that can come up. Number 5) seems logically enough for me to think it's true and number 6) unfortunately I am not sure. Can anybody help?",,"['statistics', 'variance']"
2,Inequality involving independent random variables [closed],Inequality involving independent random variables [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question We have independent random variables $X$ and $Y$. Why does the following equality hold? $$P(X>Y)=\int P(X>Y\mid Y=z)f_Y(z) \, dz,$$ where $f_Y$ is the density of $Y$. Any ideas?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question We have independent random variables $X$ and $Y$. Why does the following equality hold? $$P(X>Y)=\int P(X>Y\mid Y=z)f_Y(z) \, dz,$$ where $f_Y$ is the density of $Y$. Any ideas?",,"['probability-theory', 'statistics']"
3,Finding the marginal density when the conditional density is given to us.,Finding the marginal density when the conditional density is given to us.,,"Let the conditional probability density of $X$ given $Y=y$ is as follows: $f(x|y)= {e^{y-x}, x>y}$ where $y>0$. and let the density of $Y$ has been provided as exponential distribution with mean $\frac{1}{\lambda}$. then what is the marginal density of the $X$. I have obtained the joint density of the $X$ and $Y$ by multiplying the given densities and obtained: $f(x,y)=\lambda e^{-x} e^{-\lambda y+y}$ where $y<x$. To obtain the density of $X$, i calculated the following integral: $\int_{0}^{x} \lambda e^{-x} e^{-\lambda y+y} dy$ which after a little simplification turned out to be: $f(x)=\frac{\lambda}{1-\lambda} [e^{-\lambda x}+e^{-x}]$ I am not sure whether my density of $X$ is correct or not. My textbook is showing some different answers. Also, is there any quick method to the given problem because the definite integral took some time to solve. Thanks in advance.","Let the conditional probability density of $X$ given $Y=y$ is as follows: $f(x|y)= {e^{y-x}, x>y}$ where $y>0$. and let the density of $Y$ has been provided as exponential distribution with mean $\frac{1}{\lambda}$. then what is the marginal density of the $X$. I have obtained the joint density of the $X$ and $Y$ by multiplying the given densities and obtained: $f(x,y)=\lambda e^{-x} e^{-\lambda y+y}$ where $y<x$. To obtain the density of $X$, i calculated the following integral: $\int_{0}^{x} \lambda e^{-x} e^{-\lambda y+y} dy$ which after a little simplification turned out to be: $f(x)=\frac{\lambda}{1-\lambda} [e^{-\lambda x}+e^{-x}]$ I am not sure whether my density of $X$ is correct or not. My textbook is showing some different answers. Also, is there any quick method to the given problem because the definite integral took some time to solve. Thanks in advance.",,['statistics']
4,What is the meaning of the word parameter in the context of statistics?,What is the meaning of the word parameter in the context of statistics?,,"Question:  The per capita consumption of bottled water in the United States amounted to 27.6 gallons in 2009. Bottled water is drinking water (carbonated or still) sold in plastic or glass water bottles. Per capita consumption of bottled water in the United States has continued to steadily increase. In 2012, it amounted to 30.8 gallons. In 2015, the per capita consumption was 36.5 gallons.† The per capita consumption of bottled water in the United States is which of the following? (a).biased statistic (b). categorical variable (c). numerical variable (d). parameter The answer is (d).  Please can someone explain why the answer is parameter? I don't feel like I truly understand the meaning of parameter in context of statistics. I just think of a parameter like a variable or a placeholder for something else. But this seems to be different in statistics.","Question:  The per capita consumption of bottled water in the United States amounted to 27.6 gallons in 2009. Bottled water is drinking water (carbonated or still) sold in plastic or glass water bottles. Per capita consumption of bottled water in the United States has continued to steadily increase. In 2012, it amounted to 30.8 gallons. In 2015, the per capita consumption was 36.5 gallons.† The per capita consumption of bottled water in the United States is which of the following? (a).biased statistic (b). categorical variable (c). numerical variable (d). parameter The answer is (d).  Please can someone explain why the answer is parameter? I don't feel like I truly understand the meaning of parameter in context of statistics. I just think of a parameter like a variable or a placeholder for something else. But this seems to be different in statistics.",,['statistics']
5,Variance Derivation of Chi-Squared Distribution,Variance Derivation of Chi-Squared Distribution,,"If we find the MGF of $$Z^2$$ where $$Z \sim N(0,1)$$ we find that $$M_{Z^2}(t) = (1-2t)^{-.5}$$ for $t < .5.$ Consider that a chi squared distributed variable $X$ with $r$ degrees of freedom is the sum of $r$ iid standard normal variables squared. ie:  $$X \sim \chi^2(r) = \sum_{j=0}^r Z_j^2$$ where $$Z_j \sim N(0,1)$$ are independent therefore the mgf of chi squared is $$M_X(t) = (1-2t)^{-r/2}$$ Then $$M'_X(t) = -r/2\cdot-2r(1-2t)^{-r/2-1} = r(1-2t)^{-r/2-1}$$ so  $$E(X) = r(1) =r$$ And then $$M''_X(t) = r\cdot-r/2\cdot-2r(1-2t)^{-r/2-2} = r^2 (1-2t)^{-r/2-2}$$ so $$E(X^2) = r^2$$ But this implies that  $$Var(X) = E(X^2) - (E(X))^2 = r^2 - r^2 = 0$$ Which is obviously false as the variance of chi squared depends on $r.$ Where is the mistake in my derivation?","If we find the MGF of $$Z^2$$ where $$Z \sim N(0,1)$$ we find that $$M_{Z^2}(t) = (1-2t)^{-.5}$$ for $t < .5.$ Consider that a chi squared distributed variable $X$ with $r$ degrees of freedom is the sum of $r$ iid standard normal variables squared. ie:  $$X \sim \chi^2(r) = \sum_{j=0}^r Z_j^2$$ where $$Z_j \sim N(0,1)$$ are independent therefore the mgf of chi squared is $$M_X(t) = (1-2t)^{-r/2}$$ Then $$M'_X(t) = -r/2\cdot-2r(1-2t)^{-r/2-1} = r(1-2t)^{-r/2-1}$$ so  $$E(X) = r(1) =r$$ And then $$M''_X(t) = r\cdot-r/2\cdot-2r(1-2t)^{-r/2-2} = r^2 (1-2t)^{-r/2-2}$$ so $$E(X^2) = r^2$$ But this implies that  $$Var(X) = E(X^2) - (E(X))^2 = r^2 - r^2 = 0$$ Which is obviously false as the variance of chi squared depends on $r.$ Where is the mistake in my derivation?",,"['statistics', 'proof-verification', 'variance', 'moment-generating-functions']"
6,Derive the posterior density of $\Theta$.,Derive the posterior density of .,\Theta,"Suppose that $X\sim \operatorname{Unif}(0,\theta)$ and assume a priori that $\Theta\sim Ga(2,1)$, that is $f_\Theta(\theta)\propto\theta e^{-\theta}\mathbb{1}_{[0,\infty)}(\theta)$. Exercise: Derive the posterior density of $\Theta$. What I've tried: I know that $$f_{\Theta\mid X}(\theta\mid x) = \dfrac{f_{X\mid\Theta}(x\mid\theta)\,f_\Theta(\theta)}{\displaystyle\int f_{X\mid\Theta}(x\mid\theta)\,f_\Theta(\theta)d\theta}\propto f_{X\mid\Theta}(x\mid\theta)\,f_\Theta(\theta)$$ What I'm unsure about is how to write $f_{\Theta\mid X}(\theta\mid x)\propto f_{X\mid\Theta}(x\mid\theta)\,f_\Theta(\theta)$, because this product of functions has two indicator functions in it, both with a different argument. We have (sort of?) $f_{\Theta\mid X}(\theta, x) \propto \dfrac{1}{\theta}\mathbb{1}_{(0,\theta)}(x)\,\theta e^{-\theta}\mathbb{1}_{[0,\infty)}(\theta)$ which makes me very uncomfortable. Furthermore when asked to give the posterior distribution, I'm not if I have to supply the entire fraction with the constant, or just the part to which it is proportional. Question: How do I solve this exercise? Thanks!","Suppose that $X\sim \operatorname{Unif}(0,\theta)$ and assume a priori that $\Theta\sim Ga(2,1)$, that is $f_\Theta(\theta)\propto\theta e^{-\theta}\mathbb{1}_{[0,\infty)}(\theta)$. Exercise: Derive the posterior density of $\Theta$. What I've tried: I know that $$f_{\Theta\mid X}(\theta\mid x) = \dfrac{f_{X\mid\Theta}(x\mid\theta)\,f_\Theta(\theta)}{\displaystyle\int f_{X\mid\Theta}(x\mid\theta)\,f_\Theta(\theta)d\theta}\propto f_{X\mid\Theta}(x\mid\theta)\,f_\Theta(\theta)$$ What I'm unsure about is how to write $f_{\Theta\mid X}(\theta\mid x)\propto f_{X\mid\Theta}(x\mid\theta)\,f_\Theta(\theta)$, because this product of functions has two indicator functions in it, both with a different argument. We have (sort of?) $f_{\Theta\mid X}(\theta, x) \propto \dfrac{1}{\theta}\mathbb{1}_{(0,\theta)}(x)\,\theta e^{-\theta}\mathbb{1}_{[0,\infty)}(\theta)$ which makes me very uncomfortable. Furthermore when asked to give the posterior distribution, I'm not if I have to supply the entire fraction with the constant, or just the part to which it is proportional. Question: How do I solve this exercise? Thanks!",,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'statistical-inference']"
7,Show that the posterior probability of $H_0$ equals $\Phi\left(\sqrt{n}\frac{\theta_o -\bar{X}_n}{\sigma}\right)$,Show that the posterior probability of  equals,H_0 \Phi\left(\sqrt{n}\frac{\theta_o -\bar{X}_n}{\sigma}\right),"Exercise: Assume a Bayesian setup in which $X_1,\ldots,X_n\mid\Theta\stackrel{iid}{\sim}N(\theta,\sigma^2)$ and $\Theta$ gets assigned a prior distribution. Take a flat prior on $\Theta: f_\Theta(\theta)\propto 1$. We consider testing $H_0:\theta\leq \theta_0$ versus $H_1:\theta > \theta_0$. Show that the posterior probability of $H_0$ equals $$\Phi\bigg(\sqrt{n}\dfrac{\theta_o -\bar{X}_n}{\sigma}\bigg)$$ My approach: I need to show that $\mathbb{P}(\theta\leq \theta_0\mid X) = \Phi\bigg(\sqrt{n}\dfrac{\theta_o -\bar{X}_n}{\sigma}\bigg)$, and I know that $f_{\Theta\mid X}(\theta\mid x)\propto f_\Theta(\theta)\,f_{X\mid\Theta}(x\mid\theta) \propto\prod\limits_{i = 1}^n\exp\bigg(\dfrac{(x_i - \theta)^2}{\sigma^2}\bigg) = \exp\bigg(-\dfrac{\sum_{i = 1}^nx_i^2}{n\sigma^2} + \dfrac{2\theta\frac{1}{n}\sum_{i = 1}^n x_i}{2\sigma^2} - \dfrac{\theta^2}{\sigma^2}\bigg)$. If I'm not mistaken, I need to find $a$ and $b$ in $\Theta|X\sim N(a,b^2)$ so that I can normalise $\Theta$. Unfortunately I can't find a way to write $\exp\bigg(-\dfrac{\sum_{i = 1}^nx_i^2}{n\sigma^2} + \dfrac{2\theta\frac{1}{n}\sum_{i = 1}^n x_i}{2\sigma^2} - \dfrac{\theta^2}{\sigma^2}\bigg)$ as $\exp\bigg(-\dfrac{(\theta - a)^2}{b^2}\bigg)$. Question: How do I solve this exercise/what am I missing? Thanks in advance!","Exercise: Assume a Bayesian setup in which $X_1,\ldots,X_n\mid\Theta\stackrel{iid}{\sim}N(\theta,\sigma^2)$ and $\Theta$ gets assigned a prior distribution. Take a flat prior on $\Theta: f_\Theta(\theta)\propto 1$. We consider testing $H_0:\theta\leq \theta_0$ versus $H_1:\theta > \theta_0$. Show that the posterior probability of $H_0$ equals $$\Phi\bigg(\sqrt{n}\dfrac{\theta_o -\bar{X}_n}{\sigma}\bigg)$$ My approach: I need to show that $\mathbb{P}(\theta\leq \theta_0\mid X) = \Phi\bigg(\sqrt{n}\dfrac{\theta_o -\bar{X}_n}{\sigma}\bigg)$, and I know that $f_{\Theta\mid X}(\theta\mid x)\propto f_\Theta(\theta)\,f_{X\mid\Theta}(x\mid\theta) \propto\prod\limits_{i = 1}^n\exp\bigg(\dfrac{(x_i - \theta)^2}{\sigma^2}\bigg) = \exp\bigg(-\dfrac{\sum_{i = 1}^nx_i^2}{n\sigma^2} + \dfrac{2\theta\frac{1}{n}\sum_{i = 1}^n x_i}{2\sigma^2} - \dfrac{\theta^2}{\sigma^2}\bigg)$. If I'm not mistaken, I need to find $a$ and $b$ in $\Theta|X\sim N(a,b^2)$ so that I can normalise $\Theta$. Unfortunately I can't find a way to write $\exp\bigg(-\dfrac{\sum_{i = 1}^nx_i^2}{n\sigma^2} + \dfrac{2\theta\frac{1}{n}\sum_{i = 1}^n x_i}{2\sigma^2} - \dfrac{\theta^2}{\sigma^2}\bigg)$ as $\exp\bigg(-\dfrac{(\theta - a)^2}{b^2}\bigg)$. Question: How do I solve this exercise/what am I missing? Thanks in advance!",,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'statistical-inference']"
8,How many independent measurement of CPU-time are required such that the difference $|\bar{X} - \mu|<0.1$ with probability $0.9$ at least?,How many independent measurement of CPU-time are required such that the difference  with probability  at least?,|\bar{X} - \mu|<0.1 0.9,"The actual required CPU-time of a workstation session is assumed (due to a long-term study) as a   random variable with unknown expected value $\mu$ and known variance   $\sigma^2=6.25[s^2]$. How many independent measurement of CPU-time   are needed such that with probability of at least $0.9$, you have that   the difference $|\bar{X}-\mu|$ is less than $0.1$? This is task from old exam with different teacher. I ask my teacher and he say he don't show this example in class but give me two method for solve it: Central limit theorem and Chebyshev's inequality . This already help me much and I try solve like this: I use central limit theorem: We have that $$\sqrt{n} (\bar{X}-\mu) \text{ for } n \rightarrow \infty \text { is approximately standard normally distributed}$$ Now assume we have very big $n$ such that approximation mistake is very small so we don't need to keep it in mind. Then we can do $$P(|\bar{X}-\mu|) < \varepsilon) = P(\sqrt{n}|\bar{X}-\mu|<\sqrt{n} \varepsilon)=P(-\sqrt{n}\varepsilon< \sqrt{n}(\bar{X}-\mu)< \sqrt{n} \varepsilon) \\ \approx \Phi(\sqrt{n} \varepsilon)- \Phi(-\sqrt{n}\varepsilon) = 2\Phi(\sqrt{n}\varepsilon)-1$$ Now insert $\varepsilon= 0.1$ in inequality $P(|\bar{X}-\mu|<\varepsilon)\geq 0.9$ then we have $$2\Phi(0.1 \cdot \sqrt{n})-1 \geq 0.9 \Leftrightarrow \Phi(0.1 \cdot \sqrt{n}) \geq 0.95$$ And from this step I don't know how finish it :/ Can you tell me if this is correct till here and how to finish it? I really think I almost got it but something is missing.. But actually I'm more interested to know how you would do this with Chebyshev? I tried it already but also not sure if correct (see my comment of karakfa 's answer).","The actual required CPU-time of a workstation session is assumed (due to a long-term study) as a   random variable with unknown expected value $\mu$ and known variance   $\sigma^2=6.25[s^2]$. How many independent measurement of CPU-time   are needed such that with probability of at least $0.9$, you have that   the difference $|\bar{X}-\mu|$ is less than $0.1$? This is task from old exam with different teacher. I ask my teacher and he say he don't show this example in class but give me two method for solve it: Central limit theorem and Chebyshev's inequality . This already help me much and I try solve like this: I use central limit theorem: We have that $$\sqrt{n} (\bar{X}-\mu) \text{ for } n \rightarrow \infty \text { is approximately standard normally distributed}$$ Now assume we have very big $n$ such that approximation mistake is very small so we don't need to keep it in mind. Then we can do $$P(|\bar{X}-\mu|) < \varepsilon) = P(\sqrt{n}|\bar{X}-\mu|<\sqrt{n} \varepsilon)=P(-\sqrt{n}\varepsilon< \sqrt{n}(\bar{X}-\mu)< \sqrt{n} \varepsilon) \\ \approx \Phi(\sqrt{n} \varepsilon)- \Phi(-\sqrt{n}\varepsilon) = 2\Phi(\sqrt{n}\varepsilon)-1$$ Now insert $\varepsilon= 0.1$ in inequality $P(|\bar{X}-\mu|<\varepsilon)\geq 0.9$ then we have $$2\Phi(0.1 \cdot \sqrt{n})-1 \geq 0.9 \Leftrightarrow \Phi(0.1 \cdot \sqrt{n}) \geq 0.95$$ And from this step I don't know how finish it :/ Can you tell me if this is correct till here and how to finish it? I really think I almost got it but something is missing.. But actually I'm more interested to know how you would do this with Chebyshev? I tried it already but also not sure if correct (see my comment of karakfa 's answer).",,"['probability', 'probability-theory', 'statistics', 'discrete-mathematics', 'probability-distributions']"
9,Finding statistical data for repeated surveys in a population,Finding statistical data for repeated surveys in a population,,"I came across this statistical problem: in a population of 223 people, repeated surveys are carried out by different groups. The first group will randomly choose 40 people to survey, and the second group will randomly choose 40 people to survey, and so on. Each group will choose independently of each other. There are 16 total groups, with 14 of them choosing 40 people, 1 of them choosing 50 people, and 1 of them choosing 60 people. Questions: Can this situation be related to an existing and well-studied type of problem? What is the average amount of surveys each individual will get? What is the standard deviation? What is the expected (average) amount of people that receives 0, 1, 2, 3...16 surveys? If we suspect some groups did not carry out the amount of surveys they are supposed to (e.g. all groups only did a-half of the surveys they claimed to) and so we collected a sample in the population, what should we find in order to conclude that some groups did not survey the amount they claimed. I found some of these questions quite simple, while some are quite complicated. The mean is easily solvable: $\frac{40*14+50+60}{223}$ When it comes to the standard deviation, the first thing I thought of is to calculate each possible scenario. Using a simple example: 3 groups chose 3, 4, and 7 people from a population of 8. The pictures showed calculations by hand. It became quite apparent that the number of cases grow at a fast rate (perhaps an exponential growth), so I wrote a program that did the calculations. Unfortunately, though I tried to perform multiple optimizations, including ignoring cases that has a low probability of occurring and tracking only people that received 0 and 1 surveys, the calculation still took half an hour. The result is: Expected values: People with 0 surveys: 7.94284 People with 1 survey: 29.52534 People with 2 surveys and above: 185.53182 When I try to increase the amount of surveys counted, it seems to take forever when calculating group 8 or so. The brute-force method of finding every case (or, with optimizations, probable cases), therefore, failed to get an answer due to the amount of calculations needed. But, I found out that the expected values displayed a pattern. Though I have no ironclad proof, for smaller testing samples, the pattern matches the brute-force method perfectly. Here is an example. Selecting from a population of 8. The expected (average) amount of people getting n surveys after selecting m people = (amount of people getting n surveys before this selection) * [(n-m) / n)] + (amount of people getting n - 1 surveys before this selection) * (m / n). In other words, expected survey count = amount of people remaining in this count due to not getting selected + amount of people promoted from (count - 1) due to getting selected. The computation is still quite tedious, so I wrote a program and an Excel spreadsheet that calculates it. The formula is shown on the top of the picture. The program is more flexible and have more options in accuracy, so here is the rounded result of the program. Mean: 3.0044843049 Standard Deviation: 2.4423302226 Expected surveys received: 0 surveys: 7.9428 people 1 survey: 29.525 people 2 surveys: 51.350 people 3 surveys: 55.471 people 4 surveys: 41.663 5 surveys: 23.072 6 surveys: 9.7455 7 surveys: 3.2032 8 surveys: 0.82802 9 surveys: 0.16891 10 surveys: 0.027101 11 surveys: 0.0033846 12 surveys: 0.00032254 13 surveys: 0.000022674 14 surveys: 0.0000011090 15 surveys: 3.3720E-8 16 surveys: 4.8016E-10 Now answering the fifth question (suspecting groups making less surveys than claimed), according to the Central Limit Theorem, the mean of the sample distribution is equal to the mean of the population, and the standard deviation is $\sigma_\bar{x} = \frac{\sigma}{\sqrt{n}}$. So after the sample is taken (not violating the 10% rule), we can plug the value of n in an see if the sample mean is 2$\sigma$ away from the expected mean. If it is more than 2$\sigma$ away, we have sufficient reason to doubt the integrity of the sampling groups. We can probably also look at whether the sample survey counts match the population expected survey counts, but I don't know how this comparison can lead to any conclusion. So, my final questions now became: Can this situation be related to any existing problems that are well-studied? Are all my calculations and methodologies correct? Especially, is the formula for making inferences about expected count correct? If so, what is the proof? Are there any formula that can calculate the expected survey counts faster? Can I infer anything from the comparison between expected survey counts and sample survey counts? I apologize for the long description, but that's what I've got so far and I am quite curious about this problem.","I came across this statistical problem: in a population of 223 people, repeated surveys are carried out by different groups. The first group will randomly choose 40 people to survey, and the second group will randomly choose 40 people to survey, and so on. Each group will choose independently of each other. There are 16 total groups, with 14 of them choosing 40 people, 1 of them choosing 50 people, and 1 of them choosing 60 people. Questions: Can this situation be related to an existing and well-studied type of problem? What is the average amount of surveys each individual will get? What is the standard deviation? What is the expected (average) amount of people that receives 0, 1, 2, 3...16 surveys? If we suspect some groups did not carry out the amount of surveys they are supposed to (e.g. all groups only did a-half of the surveys they claimed to) and so we collected a sample in the population, what should we find in order to conclude that some groups did not survey the amount they claimed. I found some of these questions quite simple, while some are quite complicated. The mean is easily solvable: $\frac{40*14+50+60}{223}$ When it comes to the standard deviation, the first thing I thought of is to calculate each possible scenario. Using a simple example: 3 groups chose 3, 4, and 7 people from a population of 8. The pictures showed calculations by hand. It became quite apparent that the number of cases grow at a fast rate (perhaps an exponential growth), so I wrote a program that did the calculations. Unfortunately, though I tried to perform multiple optimizations, including ignoring cases that has a low probability of occurring and tracking only people that received 0 and 1 surveys, the calculation still took half an hour. The result is: Expected values: People with 0 surveys: 7.94284 People with 1 survey: 29.52534 People with 2 surveys and above: 185.53182 When I try to increase the amount of surveys counted, it seems to take forever when calculating group 8 or so. The brute-force method of finding every case (or, with optimizations, probable cases), therefore, failed to get an answer due to the amount of calculations needed. But, I found out that the expected values displayed a pattern. Though I have no ironclad proof, for smaller testing samples, the pattern matches the brute-force method perfectly. Here is an example. Selecting from a population of 8. The expected (average) amount of people getting n surveys after selecting m people = (amount of people getting n surveys before this selection) * [(n-m) / n)] + (amount of people getting n - 1 surveys before this selection) * (m / n). In other words, expected survey count = amount of people remaining in this count due to not getting selected + amount of people promoted from (count - 1) due to getting selected. The computation is still quite tedious, so I wrote a program and an Excel spreadsheet that calculates it. The formula is shown on the top of the picture. The program is more flexible and have more options in accuracy, so here is the rounded result of the program. Mean: 3.0044843049 Standard Deviation: 2.4423302226 Expected surveys received: 0 surveys: 7.9428 people 1 survey: 29.525 people 2 surveys: 51.350 people 3 surveys: 55.471 people 4 surveys: 41.663 5 surveys: 23.072 6 surveys: 9.7455 7 surveys: 3.2032 8 surveys: 0.82802 9 surveys: 0.16891 10 surveys: 0.027101 11 surveys: 0.0033846 12 surveys: 0.00032254 13 surveys: 0.000022674 14 surveys: 0.0000011090 15 surveys: 3.3720E-8 16 surveys: 4.8016E-10 Now answering the fifth question (suspecting groups making less surveys than claimed), according to the Central Limit Theorem, the mean of the sample distribution is equal to the mean of the population, and the standard deviation is $\sigma_\bar{x} = \frac{\sigma}{\sqrt{n}}$. So after the sample is taken (not violating the 10% rule), we can plug the value of n in an see if the sample mean is 2$\sigma$ away from the expected mean. If it is more than 2$\sigma$ away, we have sufficient reason to doubt the integrity of the sampling groups. We can probably also look at whether the sample survey counts match the population expected survey counts, but I don't know how this comparison can lead to any conclusion. So, my final questions now became: Can this situation be related to any existing problems that are well-studied? Are all my calculations and methodologies correct? Especially, is the formula for making inferences about expected count correct? If so, what is the proof? Are there any formula that can calculate the expected survey counts faster? Can I infer anything from the comparison between expected survey counts and sample survey counts? I apologize for the long description, but that's what I've got so far and I am quite curious about this problem.",,"['probability', 'combinatorics', 'statistics', 'probability-distributions', 'expectation']"
10,Maximum likelihood estimate and Wald interval for binomial success probability $p$,Maximum likelihood estimate and Wald interval for binomial success probability,p,"In an interview $63\%$ of $100$ randomly chosen people gave an positive answer. $p$ is this amount from all people. What is the maximum likelihood estimation of $p$? Calculate the wald interval of $p$! I understand it so, that $p = 0.63 $.  I also want to give the steps of the deviation of the formula of the likelihood. So I tried to start with this formula for the likelihood: $L(p)=\prod \limits_{i=1}^{n}p(x_i, p) = \prod \limits_{i=1}^{n}P(X_i=x_i) = \prod \limits_{i=1}^{100}P(X_i =0.63)$ $\hat{p} = \frac{1}{n} * \sum\limits_{i=1}^{n} x_i = \frac{1}{100} * 63 = 0.63$ And for the wald interval: $\hat{p} \pm Z_{1-\frac{\alpha}{2}} * \sqrt{\frac{\hat{p} (1-\hat{p} )}{n}}$ When I use $0.63$ for $\hat{p}$ I get the interval $[0.54; 0.72]$. So I don't really understand how to get from the formula of $L(p)$ to the value of $\hat{p}$. I'm also not sure if this is already my final result for the likelihood. I got this with the help of a book, and there seem to be some steps missing. I'm also not sure if this is in general the right way of solving it and if I used the right formula and values for the Wald interval.","In an interview $63\%$ of $100$ randomly chosen people gave an positive answer. $p$ is this amount from all people. What is the maximum likelihood estimation of $p$? Calculate the wald interval of $p$! I understand it so, that $p = 0.63 $.  I also want to give the steps of the deviation of the formula of the likelihood. So I tried to start with this formula for the likelihood: $L(p)=\prod \limits_{i=1}^{n}p(x_i, p) = \prod \limits_{i=1}^{n}P(X_i=x_i) = \prod \limits_{i=1}^{100}P(X_i =0.63)$ $\hat{p} = \frac{1}{n} * \sum\limits_{i=1}^{n} x_i = \frac{1}{100} * 63 = 0.63$ And for the wald interval: $\hat{p} \pm Z_{1-\frac{\alpha}{2}} * \sqrt{\frac{\hat{p} (1-\hat{p} )}{n}}$ When I use $0.63$ for $\hat{p}$ I get the interval $[0.54; 0.72]$. So I don't really understand how to get from the formula of $L(p)$ to the value of $\hat{p}$. I'm also not sure if this is already my final result for the likelihood. I got this with the help of a book, and there seem to be some steps missing. I'm also not sure if this is in general the right way of solving it and if I used the right formula and values for the Wald interval.",,"['probability', 'statistics', 'maximum-likelihood', 'confidence-interval']"
11,Asymptotic equivalence of Akaike Information Criterion and cross-validation?,Asymptotic equivalence of Akaike Information Criterion and cross-validation?,,"I've been studying information criteria for a while now from the book of Konishi et al. and I came across a chapter where the authors refer to publication made by Stone in 1977 , in which he proves the claim that Akaike Information Criteria (AIC) and cross-validation are asymptotically equivalent . In my reference book this proof is also demonstrated in a more general information criterion case. This claim, as I've understood, should be true both in linear and nonlinear regression, but the form of the information criterion is not the same in all cases. I was shown an example where the claim made by Stone seems not to hold and I wish to better understand what's going on under the hood. Here is the problem: Take the following classifier model: $$f(x)=\text{sign}(\sin(tx)),\;\;t>0.$$ Our task is to select such a frequency parameter $t$ such that a given data set $(x_1, y_1), ...(x_n, y_n)$, where $x_i\in\mathbb{R}$ and $y\in\{-1, 1\}\;\forall\,i$ is classified as well as possible. The values of the $y_i$s are labels of the data points and are selected randomly. It is known that no matter what data set we have, we can always select such a value of $t$ so that we get a perfect classification. In below is an example illustration of the function $f(x)$ which correctly classifies all data points: The argument of this example is that because such a $t$ always exists that produces a perfect classification, so the squared error term in $AIC$ is zero and we left with only the bias term, which in this case would be $2*1=2$ ($t$ only parameter), so $AIC=2$. In case of a leave-one-out cross-validation (LOOCV), we would get asymptotically a classification error where approximately $50$% of the data points were classified wrongly, since the classifier can not guess the labels of the test points due the random phenomena. So AIC-value would be $2$ and LOOCV would have a value of $CV=\sum_{i=1}^n (y_i-f(x_i))^2 = $ $4n/2=2n\;$ ($50$% of data points misclassified) no matter how many data points we have. My question: Does this prove that Stone's claim is wrong? Or is there a fundamental misunderstanding on how AIC should be applied here? P.S. please ask me if you need more information.","I've been studying information criteria for a while now from the book of Konishi et al. and I came across a chapter where the authors refer to publication made by Stone in 1977 , in which he proves the claim that Akaike Information Criteria (AIC) and cross-validation are asymptotically equivalent . In my reference book this proof is also demonstrated in a more general information criterion case. This claim, as I've understood, should be true both in linear and nonlinear regression, but the form of the information criterion is not the same in all cases. I was shown an example where the claim made by Stone seems not to hold and I wish to better understand what's going on under the hood. Here is the problem: Take the following classifier model: $$f(x)=\text{sign}(\sin(tx)),\;\;t>0.$$ Our task is to select such a frequency parameter $t$ such that a given data set $(x_1, y_1), ...(x_n, y_n)$, where $x_i\in\mathbb{R}$ and $y\in\{-1, 1\}\;\forall\,i$ is classified as well as possible. The values of the $y_i$s are labels of the data points and are selected randomly. It is known that no matter what data set we have, we can always select such a value of $t$ so that we get a perfect classification. In below is an example illustration of the function $f(x)$ which correctly classifies all data points: The argument of this example is that because such a $t$ always exists that produces a perfect classification, so the squared error term in $AIC$ is zero and we left with only the bias term, which in this case would be $2*1=2$ ($t$ only parameter), so $AIC=2$. In case of a leave-one-out cross-validation (LOOCV), we would get asymptotically a classification error where approximately $50$% of the data points were classified wrongly, since the classifier can not guess the labels of the test points due the random phenomena. So AIC-value would be $2$ and LOOCV would have a value of $CV=\sum_{i=1}^n (y_i-f(x_i))^2 = $ $4n/2=2n\;$ ($50$% of data points misclassified) no matter how many data points we have. My question: Does this prove that Stone's claim is wrong? Or is there a fundamental misunderstanding on how AIC should be applied here? P.S. please ask me if you need more information.",,"['probability', 'statistics', 'mathematical-modeling', 'information-theory']"
12,Calculate probability using the central limit theorem,Calculate probability using the central limit theorem,,"A multiple choice test consists of 25 questions with 3 answers for every question. Only one of the three answers is correct for every question. With which probability can someone, that is only guessing the test, get a positive grade, when more than half of the questions must be answered correctly to pass the test? We have to use the central limit theorem. As the questions are independant from each other, I think it should be possible to approximate it by: $$ P(a \le S_n \le b) \sim \phi\left( \frac{b+\frac{1}{2}-np}{\sqrt{np(1-p)}}  \right) - \phi\left( \frac{a-\frac{1}{2}-np}{\sqrt{np(1-p)}}  \right).$$ We've $25$ questions, and every answer can be correct with a probability of $ \frac{1}{3}$ as there are $3$ answers given for every question. So I got the values: $n=25$, $p = \frac{1}{3}$, $a=13$, and $b=25$. When I calculate it with these values, I get $\phi(7.28)-\phi(1.77)$ which results in $3.84\%$ and doesn't seem to be correct. So how can I do it the right way?","A multiple choice test consists of 25 questions with 3 answers for every question. Only one of the three answers is correct for every question. With which probability can someone, that is only guessing the test, get a positive grade, when more than half of the questions must be answered correctly to pass the test? We have to use the central limit theorem. As the questions are independant from each other, I think it should be possible to approximate it by: $$ P(a \le S_n \le b) \sim \phi\left( \frac{b+\frac{1}{2}-np}{\sqrt{np(1-p)}}  \right) - \phi\left( \frac{a-\frac{1}{2}-np}{\sqrt{np(1-p)}}  \right).$$ We've $25$ questions, and every answer can be correct with a probability of $ \frac{1}{3}$ as there are $3$ answers given for every question. So I got the values: $n=25$, $p = \frac{1}{3}$, $a=13$, and $b=25$. When I calculate it with these values, I get $\phi(7.28)-\phi(1.77)$ which results in $3.84\%$ and doesn't seem to be correct. So how can I do it the right way?",,"['probability', 'statistics', 'normal-distribution', 'independence', 'central-limit-theorem']"
13,Proof: Why Poisson Distribution expresses the probability of a given number of events occurring in a fixed interval of time,Proof: Why Poisson Distribution expresses the probability of a given number of events occurring in a fixed interval of time,,"Since i did not find a good proof of this anywhere on the internet, I want somebody to check my proof: An experiment runs over a specific time span $[0,t]$.  The expected number of arrivals in this time interval is $\lambda$, and the time intervals in between 2 arrivals has exponential distribution (it does not matter when the last arrival took place, the probability distribution until the next one is always the same). E.g.: number of radioactive decays of a sample in a given time interval, number of calls arriving, ... Let $X$ be the number of arrivals in this time interval $[0,t]$. Then $X$ has the following probability distribution: $$ P_{[0,t]}(X= k) = \frac{\lambda^k}{k!} e^{-\lambda}. $$ Proof: If we slice the interval in $n\gg0$ equal parts: $[0,t] = [0,t/n)\cup [t/n, 2\cdot t/n) \cup  \dots \cup  [(n-1)\cdot t/n, t]$ Let $Y_1, Y_2, \dots, Y_n$ be the random variables describing the number of arrivals in the time intervals $[0,t/n), [t/n, 2t/n), \dots, [(n-1)t/n, t]$. Since the time from a specific point until the first arrival has exponential distribution, $P(Y_1 = 1) = P(Y_2 = 1) = \dots = P(Y_n = 1)$.  Also, the expected number of arrivals in a subinterval is proportional to the length of the interval, therefore:  $P(Y_1 = 1)= \dots =P(Y_n = 1) = \frac \lambda n$. Because there can only be one arrival at the same time, $n$ can be chosen so big, that there will always be only zero or one arrivals in every subinterval. Now one can see, that the probability of $k$ events in the interval $[0,t]$ can be written as a binomial distribution: \begin{align} P_{[0,t]}(X = k)  &= \binom{n}{k} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n} \right)^{n-k} = \\ &= \frac{n(n-1)\cdots (n-k+1)}{k!} \frac{\lambda^k}{n^k} \left(1-\frac{\lambda}{n}\right)^n\left(1-\frac{\lambda}{n}\right)^{-k}, \end{align} since, $\lim_{n\rightarrow \infty} \frac{n(n-1)\cdots(n-k+1)}{n^k} = 1$, $\lim_{n\rightarrow \infty} \left( 1-\frac{\lambda}{n}\right)^n = e^{-\lambda}$ and $\lim_{n \rightarrow \infty} \left(1-\frac{\lambda}{n}\right)^{-k} = 1$: \begin{align} P_{[0,t]}(X=k) = \frac{\lambda^k}{k!} e^{-\lambda}. \end{align} (I think it should be mostly correct, put please can anyone check this)","Since i did not find a good proof of this anywhere on the internet, I want somebody to check my proof: An experiment runs over a specific time span $[0,t]$.  The expected number of arrivals in this time interval is $\lambda$, and the time intervals in between 2 arrivals has exponential distribution (it does not matter when the last arrival took place, the probability distribution until the next one is always the same). E.g.: number of radioactive decays of a sample in a given time interval, number of calls arriving, ... Let $X$ be the number of arrivals in this time interval $[0,t]$. Then $X$ has the following probability distribution: $$ P_{[0,t]}(X= k) = \frac{\lambda^k}{k!} e^{-\lambda}. $$ Proof: If we slice the interval in $n\gg0$ equal parts: $[0,t] = [0,t/n)\cup [t/n, 2\cdot t/n) \cup  \dots \cup  [(n-1)\cdot t/n, t]$ Let $Y_1, Y_2, \dots, Y_n$ be the random variables describing the number of arrivals in the time intervals $[0,t/n), [t/n, 2t/n), \dots, [(n-1)t/n, t]$. Since the time from a specific point until the first arrival has exponential distribution, $P(Y_1 = 1) = P(Y_2 = 1) = \dots = P(Y_n = 1)$.  Also, the expected number of arrivals in a subinterval is proportional to the length of the interval, therefore:  $P(Y_1 = 1)= \dots =P(Y_n = 1) = \frac \lambda n$. Because there can only be one arrival at the same time, $n$ can be chosen so big, that there will always be only zero or one arrivals in every subinterval. Now one can see, that the probability of $k$ events in the interval $[0,t]$ can be written as a binomial distribution: \begin{align} P_{[0,t]}(X = k)  &= \binom{n}{k} \left(\frac{\lambda}{n}\right)^k \left(1-\frac{\lambda}{n} \right)^{n-k} = \\ &= \frac{n(n-1)\cdots (n-k+1)}{k!} \frac{\lambda^k}{n^k} \left(1-\frac{\lambda}{n}\right)^n\left(1-\frac{\lambda}{n}\right)^{-k}, \end{align} since, $\lim_{n\rightarrow \infty} \frac{n(n-1)\cdots(n-k+1)}{n^k} = 1$, $\lim_{n\rightarrow \infty} \left( 1-\frac{\lambda}{n}\right)^n = e^{-\lambda}$ and $\lim_{n \rightarrow \infty} \left(1-\frac{\lambda}{n}\right)^{-k} = 1$: \begin{align} P_{[0,t]}(X=k) = \frac{\lambda^k}{k!} e^{-\lambda}. \end{align} (I think it should be mostly correct, put please can anyone check this)",,"['probability-theory', 'statistics', 'probability-distributions', 'poisson-distribution', 'poisson-process']"
14,Binomial computation: Probability of winning at least 175 games out of 900 trials,Binomial computation: Probability of winning at least 175 games out of 900 trials,,"We roll a die, if it stops on 1 , we win, if not we lose. So we have $\frac{1}{6}$ chance of winning. What is the probability of winnign at least 175 times out of 900 rolls ? We can see this as a repetition of independent games so we can use Binomial distribution. I want to find $$P(\text{Win} \geq 175)$$ but the binomial formula will only give me $P(\text{Win} = 175)$ so I will need to do that for $176,..900$. Or I can also compute $1-P(\text{Win} < 175)$ but I still need to do 175 calculations.. How can I do it ?","We roll a die, if it stops on 1 , we win, if not we lose. So we have $\frac{1}{6}$ chance of winning. What is the probability of winnign at least 175 times out of 900 rolls ? We can see this as a repetition of independent games so we can use Binomial distribution. I want to find $$P(\text{Win} \geq 175)$$ but the binomial formula will only give me $P(\text{Win} = 175)$ so I will need to do that for $176,..900$. Or I can also compute $1-P(\text{Win} < 175)$ but I still need to do 175 calculations.. How can I do it ?",,"['probability', 'statistics', 'dice']"
15,Likelihood ratio with unknown parameters,Likelihood ratio with unknown parameters,,"Suppose we have an observation vector $x$, where $f_X(x,\theta)$ is its probability distribution function which depends on the parameter $\theta$. The parameter $\theta$ is also a random variable. Under $H_0$ it is distributed as $p_{\theta_0}(\theta)$, and under $H_1$ it is distributed as $p_{\theta_1}(\theta)$. Now I want to construct a likelihood ratio test to decide between $H_0$ and $H_1$.  Can I simply take expectations over $\theta_1$ and $\theta_0$ to construct my test? i.e. is the following test correct? $$\frac{E_{\theta_1}[f_X(x,\theta)]}{E_{\theta_0}[f_X(x,\theta)]}\begin{array}{c}     H_1 \\ > \\ < \\ H_0   \end{array}   \lambda.$$","Suppose we have an observation vector $x$, where $f_X(x,\theta)$ is its probability distribution function which depends on the parameter $\theta$. The parameter $\theta$ is also a random variable. Under $H_0$ it is distributed as $p_{\theta_0}(\theta)$, and under $H_1$ it is distributed as $p_{\theta_1}(\theta)$. Now I want to construct a likelihood ratio test to decide between $H_0$ and $H_1$.  Can I simply take expectations over $\theta_1$ and $\theta_0$ to construct my test? i.e. is the following test correct? $$\frac{E_{\theta_1}[f_X(x,\theta)]}{E_{\theta_0}[f_X(x,\theta)]}\begin{array}{c}     H_1 \\ > \\ < \\ H_0   \end{array}   \lambda.$$",,"['statistics', 'statistical-inference', 'estimation', 'hypothesis-testing']"
16,Finding stationary distribution of the following stochastic process?,Finding stationary distribution of the following stochastic process?,,"Take the stochastic process coming from $$\ddot X + \frac{\eta}{m} \dot X + \frac{k}{m}X = \frac{1}{m} W(t)\tag{1}$$ (where $W$ is white noise) or equivalently the Itô differential equation $$ d \begin{pmatrix} X\\V\\\end{pmatrix} = \begin{pmatrix} V\\ -\dfrac{\eta}{m} V - \dfrac{k}{m}X\\\end{pmatrix}dt + \begin{pmatrix} 0&0\\0&\frac1m\end{pmatrix}\begin{pmatrix} d\beta_1 \\d\beta_2\end{pmatrix}\tag{2}  $$ $$ \equiv d \mathbf{X} = f(\mathbf{X})dt + \mathbf{L}\, d\boldsymbol{\beta} \tag{3}.$$ This is just the damped harmonic oscillator driven by white noise. In particular, $\beta_1,\beta_2$ are Brownian motion. I know from the literature that the stationary distribution is of the form $$p(x,v) = \exp( - Ax^2 - Bv^2 )$$ (see edit). Attempt: I believe I need to use the Fokker-Planck equation: $$\frac{\partial p(\mathbf{X},t)}{\partial t} = 0= - \sum_{i}\frac{\partial}{\partial X_i}[\mathbf{f}_i(\mathbf{X})p(\mathbf{X},t)]+ \sum_{i,j} \frac{\partial^2}{\partial X_i X_j}\left[(\mathbf{L}^T\mathbf{L})_{ij} \,p(\mathbf{X},t)\right]\tag{4}$$   where the $0$ is because we consider the stationary distribution. This, however, gives me (writing $p(\mathbf{X},t) = p(x,v)$) $$0=-\left[ \frac{\partial}{\partial x}(vp(x,v)) + \frac{\partial}{\partial v}\left(\left( -\frac{\eta}{m}v - \frac{k}{m}x\right) p(x,v)\right) \right]+ \frac12 \frac{\partial^2}{\partial v^2} \frac{p(x,v)}{m^2}\tag{5}$$ which is certainly not solved by a Gaussian $p(x,v)$. Edit: An error stopped me from solving (5) with a Gaussian ansatz and plugging and chugging. Thank you stochastic for clearing this up.","Take the stochastic process coming from $$\ddot X + \frac{\eta}{m} \dot X + \frac{k}{m}X = \frac{1}{m} W(t)\tag{1}$$ (where $W$ is white noise) or equivalently the Itô differential equation $$ d \begin{pmatrix} X\\V\\\end{pmatrix} = \begin{pmatrix} V\\ -\dfrac{\eta}{m} V - \dfrac{k}{m}X\\\end{pmatrix}dt + \begin{pmatrix} 0&0\\0&\frac1m\end{pmatrix}\begin{pmatrix} d\beta_1 \\d\beta_2\end{pmatrix}\tag{2}  $$ $$ \equiv d \mathbf{X} = f(\mathbf{X})dt + \mathbf{L}\, d\boldsymbol{\beta} \tag{3}.$$ This is just the damped harmonic oscillator driven by white noise. In particular, $\beta_1,\beta_2$ are Brownian motion. I know from the literature that the stationary distribution is of the form $$p(x,v) = \exp( - Ax^2 - Bv^2 )$$ (see edit). Attempt: I believe I need to use the Fokker-Planck equation: $$\frac{\partial p(\mathbf{X},t)}{\partial t} = 0= - \sum_{i}\frac{\partial}{\partial X_i}[\mathbf{f}_i(\mathbf{X})p(\mathbf{X},t)]+ \sum_{i,j} \frac{\partial^2}{\partial X_i X_j}\left[(\mathbf{L}^T\mathbf{L})_{ij} \,p(\mathbf{X},t)\right]\tag{4}$$   where the $0$ is because we consider the stationary distribution. This, however, gives me (writing $p(\mathbf{X},t) = p(x,v)$) $$0=-\left[ \frac{\partial}{\partial x}(vp(x,v)) + \frac{\partial}{\partial v}\left(\left( -\frac{\eta}{m}v - \frac{k}{m}x\right) p(x,v)\right) \right]+ \frac12 \frac{\partial^2}{\partial v^2} \frac{p(x,v)}{m^2}\tag{5}$$ which is certainly not solved by a Gaussian $p(x,v)$. Edit: An error stopped me from solving (5) with a Gaussian ansatz and plugging and chugging. Thank you stochastic for clearing this up.",,"['probability', 'statistics', 'stochastic-processes', 'stochastic-calculus', 'stochastic-analysis']"
17,Multi-Variate Statistics verification,Multi-Variate Statistics verification,,"Let $X_i$ for $i=1,2,3$ be independent identically distributed random variables with probability density function $f(x)=e^{-x}$ for $x\in(0,\infty)$ (and $0$ otherwise). Find $$P(X_1<X_2<X_3|X_3<1).$$ By the definition of conditional probability I figured  \begin{align} P(X_1<X_2<X_3|X_3<1)&=\frac{P(\left[X_1<X_2<X_3\right]\cap [X_3<1])}{P(X_3<1)}\\ &=\frac{P(X_1<X_2<X_3<1)}{P(X_3<1)} \end{align} I had to figure out a triple integral to represent the numerator and I believe it comes out to  $$P(X_1<X_2<X_3<1)=\int_{0}^{1}\int_{0}^{x_3}\int_{0}^{x_3-x_2}e^{-(x_1+x_2+x_3)}\mathrm{d}x_1\mathrm{d}x_2\mathrm{d}x_3$$ and $P(X_3<1)=\int_{0}^{1}e^{-x_3}\mathrm{d}x_3$, is this correct? I am unsure about the triple integral bounds and if they satisfy the inequality given.","Let $X_i$ for $i=1,2,3$ be independent identically distributed random variables with probability density function $f(x)=e^{-x}$ for $x\in(0,\infty)$ (and $0$ otherwise). Find $$P(X_1<X_2<X_3|X_3<1).$$ By the definition of conditional probability I figured  \begin{align} P(X_1<X_2<X_3|X_3<1)&=\frac{P(\left[X_1<X_2<X_3\right]\cap [X_3<1])}{P(X_3<1)}\\ &=\frac{P(X_1<X_2<X_3<1)}{P(X_3<1)} \end{align} I had to figure out a triple integral to represent the numerator and I believe it comes out to  $$P(X_1<X_2<X_3<1)=\int_{0}^{1}\int_{0}^{x_3}\int_{0}^{x_3-x_2}e^{-(x_1+x_2+x_3)}\mathrm{d}x_1\mathrm{d}x_2\mathrm{d}x_3$$ and $P(X_3<1)=\int_{0}^{1}e^{-x_3}\mathrm{d}x_3$, is this correct? I am unsure about the triple integral bounds and if they satisfy the inequality given.",,"['probability', 'statistics']"
18,Combination of probabilities for probability densities,Combination of probabilities for probability densities,,"If I have an experiment with discrete probabilities like drawing black and white balls, the probability of drawing both black and white is just a multiplication of probabilities of drawing black and white. Similarly, if I want to work with ""OR"" type of situations, I add the probabilities. But how does this work with continuous random variables? Say, I have the following experiment: I have a large bucket of some material and I am trying to determine the melt temperature. So I take small samples and put them on a burner and note the temperature when they melt. Let's assume that after many of such measurements, I get a gaussian with some mean value and variance. If I then would like to say something about another bucket of the same material, I might ask, what is the probability of a sample melting at temperature between $(T,T+{\rm d}T)$. Then the probability should be $\Pr(\text{melt at }T)\approx f(T)\,{\rm d} T$ or more exactly $\int_T^{T+{\rm d}T}f(x)\,{\rm d} x$ where $f(T)$ is the gaussian. But what if I want to ask about two samples from taken from the bucket both melting at $\{T,T+{\rm d}T\}$ or one of the samples from the bucket melting between  $(T_1,T_1+{\rm d}T)$ and the other from the bucket melting  between $(T_2,T_2+{\rm d}T)$? Is it just $f^2(T)\,{\rm d}x^2$ and $f(T_1)f(T_2)\,{\rm d}x^2$ respectively? Or more exactly $$\int_T^{T+{\rm d}T}f(x)\,{\rm d} x\int_T^{T+{\rm d}T}f(x)\,{\rm d} x$$ or $$ \int_{T_1}^{T_1+{\rm d}T} f(x){\rm d} x \int_{T_2}^{T_2+{\rm d}T}f(x)\,{\rm d} x $$ But this leads to having new probability distribution functions $f(x)f(y)$ which from what I have read are not necessarily distribution functions. And if I want to ask about the probability of the melt temperature being between $(T_1, T_1+{\rm d}T)$ or between $(T_2,T_2+{\rm d}T)$, would it be $f(T_1)\,{\rm d}T + f(T_2)\,{\rm d}T$ or more precisely $$\int_{T_1}^{T_1+{\rm d}T} f(x)\,{\rm d} x + \int_{T_2}^{T_2+{\rm d}T} f(x)\,{\rm d} x\text{?}$$","If I have an experiment with discrete probabilities like drawing black and white balls, the probability of drawing both black and white is just a multiplication of probabilities of drawing black and white. Similarly, if I want to work with ""OR"" type of situations, I add the probabilities. But how does this work with continuous random variables? Say, I have the following experiment: I have a large bucket of some material and I am trying to determine the melt temperature. So I take small samples and put them on a burner and note the temperature when they melt. Let's assume that after many of such measurements, I get a gaussian with some mean value and variance. If I then would like to say something about another bucket of the same material, I might ask, what is the probability of a sample melting at temperature between $(T,T+{\rm d}T)$. Then the probability should be $\Pr(\text{melt at }T)\approx f(T)\,{\rm d} T$ or more exactly $\int_T^{T+{\rm d}T}f(x)\,{\rm d} x$ where $f(T)$ is the gaussian. But what if I want to ask about two samples from taken from the bucket both melting at $\{T,T+{\rm d}T\}$ or one of the samples from the bucket melting between  $(T_1,T_1+{\rm d}T)$ and the other from the bucket melting  between $(T_2,T_2+{\rm d}T)$? Is it just $f^2(T)\,{\rm d}x^2$ and $f(T_1)f(T_2)\,{\rm d}x^2$ respectively? Or more exactly $$\int_T^{T+{\rm d}T}f(x)\,{\rm d} x\int_T^{T+{\rm d}T}f(x)\,{\rm d} x$$ or $$ \int_{T_1}^{T_1+{\rm d}T} f(x){\rm d} x \int_{T_2}^{T_2+{\rm d}T}f(x)\,{\rm d} x $$ But this leads to having new probability distribution functions $f(x)f(y)$ which from what I have read are not necessarily distribution functions. And if I want to ask about the probability of the melt temperature being between $(T_1, T_1+{\rm d}T)$ or between $(T_2,T_2+{\rm d}T)$, would it be $f(T_1)\,{\rm d}T + f(T_2)\,{\rm d}T$ or more precisely $$\int_{T_1}^{T_1+{\rm d}T} f(x)\,{\rm d} x + \int_{T_2}^{T_2+{\rm d}T} f(x)\,{\rm d} x\text{?}$$",,"['probability', 'statistics', 'probability-distributions']"
19,How to show an estimator is consistent and solve the asymptotic distribution?,How to show an estimator is consistent and solve the asymptotic distribution?,,"Question: Let $X_1,……,X_n$ be an i.i.d random sample from the distribution with PDF $f(x;\theta)=\theta(1+\theta)x^{\theta-1}(1-x),0<x<1,\theta>0$ a)Find the method of moments estimator for $\theta$ based on the first moment of $X_i$ b)Show the estimator obtained in part(a) is consistent.Derive its asymptotic distribution."" Confusion: It's easy to calculate that the answer for part should be $\hat{\theta}=\frac{2\overline{X_n}}{1-\overline{X_n}}$,the question is part b. To prove consistent, we must prove$\frac{2\overline{X_n}}{1-\overline{X_n}}\xrightarrow[]{p}\theta$,since only ""$L_P$-Convergence"" and ""Almost Sure convergence"" can led to  ""Convergence in Probability"", but I've tried these two method, nothing. What's the correct method to solve this problem?","Question: Let $X_1,……,X_n$ be an i.i.d random sample from the distribution with PDF $f(x;\theta)=\theta(1+\theta)x^{\theta-1}(1-x),0<x<1,\theta>0$ a)Find the method of moments estimator for $\theta$ based on the first moment of $X_i$ b)Show the estimator obtained in part(a) is consistent.Derive its asymptotic distribution."" Confusion: It's easy to calculate that the answer for part should be $\hat{\theta}=\frac{2\overline{X_n}}{1-\overline{X_n}}$,the question is part b. To prove consistent, we must prove$\frac{2\overline{X_n}}{1-\overline{X_n}}\xrightarrow[]{p}\theta$,since only ""$L_P$-Convergence"" and ""Almost Sure convergence"" can led to  ""Convergence in Probability"", but I've tried these two method, nothing. What's the correct method to solve this problem?",,"['statistics', 'statistical-inference']"
20,"MLE for gaussian, finding $\mu$ and $\sigma^2$","MLE for gaussian, finding  and",\mu \sigma^2,"""Assume that a dataset $x_1,\ldots, x_N$ consisting of $N$ points was sampled from a Gaussian distribution, i.e., $X_i \sim N(\mu; \sigma^2)$ for some unknown $- \infty < \mu < \infty$ and unknown $0 < \sigma^2 < \infty$. Also, assume that the $X_i$ are independent and identically distributed (iid). Find the maximum likelihood estimate of the Gaussian mean $\mu$ and variance $\sigma^2$ (and show that the critical point obtained is, at least, a local maximum)"" -exercise $2.8$, A first course in machine learning, second edition. I'm currently trying to solve the exercise above, however it's proving hard for me, nad i would love some help / a reference solution to the exercise. So first i'll define the log-likelihood as: $$\log L = -\frac{N}{2}\log2\pi-N \log \sigma - \frac {1}{2 \sigma^2}\sum_{n=1}^N(t_n - w^Tx_n$$ I then find the derivative and set it equal to $0$ so: $$\frac{\log L} w = \frac{1}{\sigma^2}\sum_{n=1}^N x_nt_n - x_n x_n^T w=0$$ which can then be rewritten as: $$\frac{\log L} w = \frac 1 {\sigma^2}(X^T t-X^t Xw)=0,$$ and i can then solve for $w$ and get: $$w = (X^TX)^{-1} X^T t$$ After this point i get stuck, and unsure of how to find MLE for $\mu$ and $\sigma^2$, aswell as how to show that the critical point is at least a local maximum.","""Assume that a dataset $x_1,\ldots, x_N$ consisting of $N$ points was sampled from a Gaussian distribution, i.e., $X_i \sim N(\mu; \sigma^2)$ for some unknown $- \infty < \mu < \infty$ and unknown $0 < \sigma^2 < \infty$. Also, assume that the $X_i$ are independent and identically distributed (iid). Find the maximum likelihood estimate of the Gaussian mean $\mu$ and variance $\sigma^2$ (and show that the critical point obtained is, at least, a local maximum)"" -exercise $2.8$, A first course in machine learning, second edition. I'm currently trying to solve the exercise above, however it's proving hard for me, nad i would love some help / a reference solution to the exercise. So first i'll define the log-likelihood as: $$\log L = -\frac{N}{2}\log2\pi-N \log \sigma - \frac {1}{2 \sigma^2}\sum_{n=1}^N(t_n - w^Tx_n$$ I then find the derivative and set it equal to $0$ so: $$\frac{\log L} w = \frac{1}{\sigma^2}\sum_{n=1}^N x_nt_n - x_n x_n^T w=0$$ which can then be rewritten as: $$\frac{\log L} w = \frac 1 {\sigma^2}(X^T t-X^t Xw)=0,$$ and i can then solve for $w$ and get: $$w = (X^TX)^{-1} X^T t$$ After this point i get stuck, and unsure of how to find MLE for $\mu$ and $\sigma^2$, aswell as how to show that the critical point is at least a local maximum.",,"['statistics', 'maximum-likelihood', 'log-likelihood']"
21,double integral over unbounded region?,double integral over unbounded region?,,"I've looked through a few calculus textbooks and I'm not finding much about how to reduce double integrals over unbounded regions to iterated integrals. Usually double integrals over bounded regions are discussed and categorized as either ""type 1"" or ""type 2"", and from there we have some version of Fubini's Theorem which lets us do iterated integration. Here is an example appearing in a book on statistics: $f_{X,Y}(x,y) = \begin{cases} 2e^{-x-y} & 0<x<y\\ 0 & \text{otherwise}  \end{cases}$ I have to find $P(Y<3X)$. I believe this is just the double integral over the region between the lines $y=x$ and $y=3x$ in the first quadrant. Is there a definition or theorem that lets me make the reduction to iterated integration?","I've looked through a few calculus textbooks and I'm not finding much about how to reduce double integrals over unbounded regions to iterated integrals. Usually double integrals over bounded regions are discussed and categorized as either ""type 1"" or ""type 2"", and from there we have some version of Fubini's Theorem which lets us do iterated integration. Here is an example appearing in a book on statistics: $f_{X,Y}(x,y) = \begin{cases} 2e^{-x-y} & 0<x<y\\ 0 & \text{otherwise}  \end{cases}$ I have to find $P(Y<3X)$. I believe this is just the double integral over the region between the lines $y=x$ and $y=3x$ in the first quadrant. Is there a definition or theorem that lets me make the reduction to iterated integration?",,"['probability', 'statistics', 'multivariable-calculus']"
22,Relation between probability distribution for area and diameter of circle,Relation between probability distribution for area and diameter of circle,,"If the area of a circle is normally distributed with mean $\mu$ and standard deviation $\sigma$, what distribution does the diameter follow? Edit: I should clarify my question a bit. I found a reference suggesting the cross sectional  area (of a reinforcement bar) follows a normal distribution with CoV=0.02. But the model I'm working with takes the bar diameter as input. Thus I want to find what distribution to use for input, to have similar uncertainty. That is, when I run a large number of simulations of  $\phi$, the resulting diameter  $\pi\phi^2/4$ should be normally distributed with CoV 0.02. I have found that a CoV of 0.01 gives the intended result through trial and error, but would like to have a derivation. Best regards, Mattias","If the area of a circle is normally distributed with mean $\mu$ and standard deviation $\sigma$, what distribution does the diameter follow? Edit: I should clarify my question a bit. I found a reference suggesting the cross sectional  area (of a reinforcement bar) follows a normal distribution with CoV=0.02. But the model I'm working with takes the bar diameter as input. Thus I want to find what distribution to use for input, to have similar uncertainty. That is, when I run a large number of simulations of  $\phi$, the resulting diameter  $\pi\phi^2/4$ should be normally distributed with CoV 0.02. I have found that a CoV of 0.01 gives the intended result through trial and error, but would like to have a derivation. Best regards, Mattias",,"['statistics', 'probability-distributions']"
23,Lower bound for binomial tail probability conditional on composite parameter space,Lower bound for binomial tail probability conditional on composite parameter space,,"Suppose that $X\sim \text{Bin}(n,\theta)$ is a binomial random variable and we are interested in the quantity $$ P(X>c\mid\theta\leq\theta_0) $$ where $\theta_0\in(0,1)$ is a fixed, known quantity. Is it possible to find a lower bound for this probability? So far, I can express the following: \begin{eqnarray*} P(X>c\mid\theta\leq\theta_0)&=&\frac{P(X>c,\theta\leq\theta_0)}{P(\theta\leq\theta_0)}\\ &=&\frac{1}{\Theta(\theta_0)}\int_0^{\theta_0}P(X>c\mid t)\, d\Theta(t) \end{eqnarray*} where $\Theta(t)=P(\theta\leq t)$ is some unspecified weight function (distribution) on $\theta$. From this post I can bound the integrand further from below, assuming that $c/n>t$: $$ P(X>c\mid t)\geq \frac{1}{\sqrt{2n}} \exp\left(-c\log\frac{c}{nt}\right) $$ This is where I get stuck. I can't seem to bound this further, preferably with something that depends on $\theta_0$. Are there any references to bound this type of quantity? EDIT One possible idea is to note that $\theta_0$ is the supremum of $\theta$. So, for some $d_n\downarrow 0$, we can consider the set $\mathcal{B}=\{\theta\in(0,1):\theta>\theta_0-d_n\}$. Then \begin{eqnarray*} P(X>c\mid\theta\leq\theta_0)&=&\frac{1}{\Theta(\theta_0)}\int_0^{\theta_0}P(X>c\mid t)\, d\Theta(t)\\ &\geq&\frac{1}{\Theta(\theta_0)}\int_{t\in(0,\theta_0)\cap\mathcal{B}}P(X>c\mid t)\, d\Theta(t)\\ &>&\frac{\Theta(\{\theta\in (0,\theta_0)\cap\mathcal{B} \})}{\Theta(\theta_0)}P(X>c\mid \theta_0-d_n)\\ &\geq& \frac{1}{\sqrt{2n}} \exp\left(-c\log\frac{c}{n(\theta_0-d_n)}\right)\frac{\Theta(\{\theta\in (0,\theta_0)\cap\mathcal{B} \})}{\Theta(\theta_0)} \end{eqnarray*} where the second inequality follows from the fact that $P(X>c\mid \theta)$ increases with $\theta$, so that $P(X>c\mid \theta)>P(X>c\mid\theta_0-d_n)$ on $\mathcal{B}$. Since $\Theta(\theta_0)\leq 1$, I can also remove the quantity from the denominator above and get a smaller bound.","Suppose that $X\sim \text{Bin}(n,\theta)$ is a binomial random variable and we are interested in the quantity $$ P(X>c\mid\theta\leq\theta_0) $$ where $\theta_0\in(0,1)$ is a fixed, known quantity. Is it possible to find a lower bound for this probability? So far, I can express the following: \begin{eqnarray*} P(X>c\mid\theta\leq\theta_0)&=&\frac{P(X>c,\theta\leq\theta_0)}{P(\theta\leq\theta_0)}\\ &=&\frac{1}{\Theta(\theta_0)}\int_0^{\theta_0}P(X>c\mid t)\, d\Theta(t) \end{eqnarray*} where $\Theta(t)=P(\theta\leq t)$ is some unspecified weight function (distribution) on $\theta$. From this post I can bound the integrand further from below, assuming that $c/n>t$: $$ P(X>c\mid t)\geq \frac{1}{\sqrt{2n}} \exp\left(-c\log\frac{c}{nt}\right) $$ This is where I get stuck. I can't seem to bound this further, preferably with something that depends on $\theta_0$. Are there any references to bound this type of quantity? EDIT One possible idea is to note that $\theta_0$ is the supremum of $\theta$. So, for some $d_n\downarrow 0$, we can consider the set $\mathcal{B}=\{\theta\in(0,1):\theta>\theta_0-d_n\}$. Then \begin{eqnarray*} P(X>c\mid\theta\leq\theta_0)&=&\frac{1}{\Theta(\theta_0)}\int_0^{\theta_0}P(X>c\mid t)\, d\Theta(t)\\ &\geq&\frac{1}{\Theta(\theta_0)}\int_{t\in(0,\theta_0)\cap\mathcal{B}}P(X>c\mid t)\, d\Theta(t)\\ &>&\frac{\Theta(\{\theta\in (0,\theta_0)\cap\mathcal{B} \})}{\Theta(\theta_0)}P(X>c\mid \theta_0-d_n)\\ &\geq& \frac{1}{\sqrt{2n}} \exp\left(-c\log\frac{c}{n(\theta_0-d_n)}\right)\frac{\Theta(\{\theta\in (0,\theta_0)\cap\mathcal{B} \})}{\Theta(\theta_0)} \end{eqnarray*} where the second inequality follows from the fact that $P(X>c\mid \theta)$ increases with $\theta$, so that $P(X>c\mid \theta)>P(X>c\mid\theta_0-d_n)$ on $\mathcal{B}$. Since $\Theta(\theta_0)\leq 1$, I can also remove the quantity from the denominator above and get a smaller bound.",,"['probability', 'statistics', 'binomial-distribution']"
24,Acceptance Sampling: Probability that the owner will return a shipment of fruits,Acceptance Sampling: Probability that the owner will return a shipment of fruits,,"A grocery shop receives a monthly shipment of $1000$ fruits. The owner knows that usually $1 \%$ of the fruits are damaged when they arrive. To estimate the number of damaged ones, he takes a sample of $50$ fruits. If $2$ or more fruits in the sample are damaged then he returns the package. Approximate the probability that the owner will return a shipment. The way I've tried solving is: $1 - \binom{50}{0}(0.99)^{50}(0.01)^{0} - \binom{50}{1}(0.99)^{49}(0.01)^{1} = 0.089$ Is this correct? They ask for an approximation so that's why I'm confused.","A grocery shop receives a monthly shipment of fruits. The owner knows that usually of the fruits are damaged when they arrive. To estimate the number of damaged ones, he takes a sample of fruits. If or more fruits in the sample are damaged then he returns the package. Approximate the probability that the owner will return a shipment. The way I've tried solving is: Is this correct? They ask for an approximation so that's why I'm confused.",1000 1 \% 50 2 1 - \binom{50}{0}(0.99)^{50}(0.01)^{0} - \binom{50}{1}(0.99)^{49}(0.01)^{1} = 0.089,"['probability', 'statistics']"
25,Determine number of trials in Monte Carlo simulation,Determine number of trials in Monte Carlo simulation,,"Assume we estimate $P(C) = P(A+B)$, where $P(B|\overline{A})$ is given, using Monte Carlo simulation in two different ways: $P(C)$ is equals to number of event $C$ occurences in $n$ independent experiments At first we estimate frequency $\frac{m}{n}$ of event $A$ occurence in $n$ independent experiments and then we compute $P(C)$ as $$P(C) \approx P_n(C)=\frac{m}{n} + (1-\frac{m}{n})P(B|\overline{A})$$ If $P(B|\overline{A}) = 0.3$ and $P(A) = 0.4$, how to determine (for both ways) the minimal number of trials, that is sufficient to get absolute error of $P(C)$ estimation less than $0.01$ with probability $\geq 0.95$? Thank you for any help!","Assume we estimate $P(C) = P(A+B)$, where $P(B|\overline{A})$ is given, using Monte Carlo simulation in two different ways: $P(C)$ is equals to number of event $C$ occurences in $n$ independent experiments At first we estimate frequency $\frac{m}{n}$ of event $A$ occurence in $n$ independent experiments and then we compute $P(C)$ as $$P(C) \approx P_n(C)=\frac{m}{n} + (1-\frac{m}{n})P(B|\overline{A})$$ If $P(B|\overline{A}) = 0.3$ and $P(A) = 0.4$, how to determine (for both ways) the minimal number of trials, that is sufficient to get absolute error of $P(C)$ estimation less than $0.01$ with probability $\geq 0.95$? Thank you for any help!",,"['probability', 'probability-theory', 'statistics', 'probability-limit-theorems', 'monte-carlo']"
26,Proving MLE is asymptotically normal.,Proving MLE is asymptotically normal.,,"I'm proving that mle is asymptitocally normal and I roughly follow the steps in this question . My problem now would be to proof that $$Z_n' = \frac 1 n \frac{d^2}{d\theta^2} \log \ell(\theta^*\mid x) \text{ converges to } I(\theta_0)$$ Here $\theta^*$ is the point obtained between the real value of the parameter and the solutions of the likelihood equation $\hat \theta = \hat \theta(X_1,\ldots,X_n)$. $\ell$ is the likelihood function. I clearly have that $\theta^* \to \theta_0$ almost surely. And as most texts cite Slutsky theorem I would like to apply what my notes state as Slutsky-Fréchet theorem, that is: $X_n \to X$ in probability and $g$ continuous then $g(X_n) \to g(X)$   in probability. So I could take $\frac{d^2}{d\theta^2} \log(\theta\mid x)$ as $g$, in fact, to have a unique solution of the likelihood equation, I impose that it is continuous uniformly on $\theta$. The problem is that, in this way $g$ depends on $n$ and therefore I cannot obtain the wanted result $I(\theta_0)$. How do I solve this? My thoughts Apparently, this is further explained in Wilk's Mathematical Statistics 4.3.8. Someone dares to give a comprehensive approach to my situation? There are some things that surprise me even in this proof. What is $g_l,g_u$?  If $g$ is not continuous does it need to have a least upper bound and a greatest lowest bound? Also, how is that a stochastic process can have several variables (I read in Wikipedia that they need to be defined over the same probability space)?","I'm proving that mle is asymptitocally normal and I roughly follow the steps in this question . My problem now would be to proof that $$Z_n' = \frac 1 n \frac{d^2}{d\theta^2} \log \ell(\theta^*\mid x) \text{ converges to } I(\theta_0)$$ Here $\theta^*$ is the point obtained between the real value of the parameter and the solutions of the likelihood equation $\hat \theta = \hat \theta(X_1,\ldots,X_n)$. $\ell$ is the likelihood function. I clearly have that $\theta^* \to \theta_0$ almost surely. And as most texts cite Slutsky theorem I would like to apply what my notes state as Slutsky-Fréchet theorem, that is: $X_n \to X$ in probability and $g$ continuous then $g(X_n) \to g(X)$   in probability. So I could take $\frac{d^2}{d\theta^2} \log(\theta\mid x)$ as $g$, in fact, to have a unique solution of the likelihood equation, I impose that it is continuous uniformly on $\theta$. The problem is that, in this way $g$ depends on $n$ and therefore I cannot obtain the wanted result $I(\theta_0)$. How do I solve this? My thoughts Apparently, this is further explained in Wilk's Mathematical Statistics 4.3.8. Someone dares to give a comprehensive approach to my situation? There are some things that surprise me even in this proof. What is $g_l,g_u$?  If $g$ is not continuous does it need to have a least upper bound and a greatest lowest bound? Also, how is that a stochastic process can have several variables (I read in Wikipedia that they need to be defined over the same probability space)?",,"['probability-theory', 'statistics', 'statistical-inference']"
27,Calculating Probability of Die Rolls with a single reroll,Calculating Probability of Die Rolls with a single reroll,,"I am trying to figure out the odds of success for this problem, but keep running into issues around the ability to reroll one die. Scenario:  I am making two rolls of special dice.  I am allowed to reroll one die in the first set, and in total I need 3 ""successes"" Set 1, where I am allowed to reroll one die, has the following dice: A Die with success on 1 of 6 faces A Die with success on 2 of 6 faces A Die with success on 3 of 6 faces Set 2, where no reroll is allowed, has the following dice: A Die with sucess on 1 of 6 faces Two Dice with successes on 2 of 6 faces I need a total of 3 successes among all of the dice rolled (with the reroll replacing the result of the rolled die). Calculating the odds of each group succeeding is easy (disregarding reroll 6/216 or 2.8% and 4/216 or 1.85% respectively).  I am at a total loss for how to figure in that reroll for the larger problem. EDIT FOR CLARITY:  Three success must happen among all six dice, the sets are just defining where a reroll can happen.  You can choose which die in the first set to reroll (but obviously if it rolled a success and you reroll, the success is ignored and the new result is used).","I am trying to figure out the odds of success for this problem, but keep running into issues around the ability to reroll one die. Scenario:  I am making two rolls of special dice.  I am allowed to reroll one die in the first set, and in total I need 3 ""successes"" Set 1, where I am allowed to reroll one die, has the following dice: A Die with success on 1 of 6 faces A Die with success on 2 of 6 faces A Die with success on 3 of 6 faces Set 2, where no reroll is allowed, has the following dice: A Die with sucess on 1 of 6 faces Two Dice with successes on 2 of 6 faces I need a total of 3 successes among all of the dice rolled (with the reroll replacing the result of the rolled die). Calculating the odds of each group succeeding is easy (disregarding reroll 6/216 or 2.8% and 4/216 or 1.85% respectively).  I am at a total loss for how to figure in that reroll for the larger problem. EDIT FOR CLARITY:  Three success must happen among all six dice, the sets are just defining where a reroll can happen.  You can choose which die in the first set to reroll (but obviously if it rolled a success and you reroll, the success is ignored and the new result is used).",,"['statistics', 'dice']"
28,Maximum likelihood estimator of $\operatorname{Poisson}(\lambda)$ with restricted $\lambda$,Maximum likelihood estimator of  with restricted,\operatorname{Poisson}(\lambda) \lambda,"Consider $X_1, X_2, \ldots,X_n$ iid $\operatorname{Poisson}(\lambda)$ random variables, where $\lambda \in [a,b]$, $0<a<b$. How do you find the maximum likelihood estimator of the restricted $\lambda$? I know that the maximum likelihood estimator of the unrestricted $\lambda$, $(\lambda \in [0, \infty])$, is $$\widehat{\lambda}_\text{MLE}=\bar{X}_n = \dfrac{X_1+X_2+\cdots+X_n}{n}.$$ I was thinking of finding the behavior as the maximum likelihood estimator at as it moves between $0$ and $\infty$ and substituting $a$ and $b$ respectively, but I am unsure if that is correct. Thank you in advanced.","Consider $X_1, X_2, \ldots,X_n$ iid $\operatorname{Poisson}(\lambda)$ random variables, where $\lambda \in [a,b]$, $0<a<b$. How do you find the maximum likelihood estimator of the restricted $\lambda$? I know that the maximum likelihood estimator of the unrestricted $\lambda$, $(\lambda \in [0, \infty])$, is $$\widehat{\lambda}_\text{MLE}=\bar{X}_n = \dfrac{X_1+X_2+\cdots+X_n}{n}.$$ I was thinking of finding the behavior as the maximum likelihood estimator at as it moves between $0$ and $\infty$ and substituting $a$ and $b$ respectively, but I am unsure if that is correct. Thank you in advanced.",,"['statistics', 'poisson-distribution', 'estimation', 'maximum-likelihood']"
29,Motivation for using a prior distribution with the same functional form as the likelihood,Motivation for using a prior distribution with the same functional form as the likelihood,,When finding the functional form of the posterior distribution my textbook has suggested that when deciding on a prior distribution it should have the same functional form as the likelihood.  Wondering why exactly this is the case ? Is it just for ease of analysis and interpretation or are there any other reasons ?,When finding the functional form of the posterior distribution my textbook has suggested that when deciding on a prior distribution it should have the same functional form as the likelihood.  Wondering why exactly this is the case ? Is it just for ease of analysis and interpretation or are there any other reasons ?,,"['statistics', 'bayesian']"
30,More information gives better estimation error,More information gives better estimation error,,"I saw this inequality stated as a fact in our textbook: $$E[(X - E[X \mid Y, Z])^2] \le E[(X - E[X \mid Y])^2]$$ Intuitively, I can understand what it is saying. But how would we prove such a relationship without knowing anything about $X$, $Y$, and $Z$?","I saw this inequality stated as a fact in our textbook: $$E[(X - E[X \mid Y, Z])^2] \le E[(X - E[X \mid Y])^2]$$ Intuitively, I can understand what it is saying. But how would we prove such a relationship without knowing anything about $X$, $Y$, and $Z$?",,"['probability', 'statistics']"
31,Finding the probability mass function of a uniform distribution.,Finding the probability mass function of a uniform distribution.,,"The number of letters, $X$, delivered to our home each day is uniformly distributed between $3$ and $10$. Find the probability mass function. A little unsure about this question. But would the pmf be $\frac{1}{8}$ (with a domain between $3$ and $10$)?","The number of letters, $X$, delivered to our home each day is uniformly distributed between $3$ and $10$. Find the probability mass function. A little unsure about this question. But would the pmf be $\frac{1}{8}$ (with a domain between $3$ and $10$)?",,"['probability', 'statistics']"
32,"If number of customers are known, find probability wait time exceeds certain number","If number of customers are known, find probability wait time exceeds certain number",,"The question is: There is one checkout line and the average service time is 4 minutes per customer. There are 3 people in the queue ahead of you. What is the probability that your wait time will exceed 6 minutes? I thought that the distribution was gamma with n = 3 and $\lambda$ = 1/4 but apparently I'm not correct. That is, I thought it was $$\int^{\infty}_{6} {\frac{(1/4) e^{-x/4}(x/4)^{3-1}}{(3-1)!} dx} \approx 0.808847.$$ I'm thinking that there is a simpler way of computing this without (at least directly) using calculus because it is supposed to be an algebra-based statistics course. EDIT. The reason why I think I am wrong is because the answer was marked incorrect for this online homework that I'm trying to help out a friend with. I wonder if Central Limit Theorem needs to be used here.","The question is: There is one checkout line and the average service time is 4 minutes per customer. There are 3 people in the queue ahead of you. What is the probability that your wait time will exceed 6 minutes? I thought that the distribution was gamma with n = 3 and $\lambda$ = 1/4 but apparently I'm not correct. That is, I thought it was $$\int^{\infty}_{6} {\frac{(1/4) e^{-x/4}(x/4)^{3-1}}{(3-1)!} dx} \approx 0.808847.$$ I'm thinking that there is a simpler way of computing this without (at least directly) using calculus because it is supposed to be an algebra-based statistics course. EDIT. The reason why I think I am wrong is because the answer was marked incorrect for this online homework that I'm trying to help out a friend with. I wonder if Central Limit Theorem needs to be used here.",,"['probability', 'statistics']"
33,P-Value of a Z-Score by Hand,P-Value of a Z-Score by Hand,,"I am running into an issue with a question that I am working on.  I want to find the $p$-value of a $z$-score by hand.  Here is the exact question and the work that I have done so far on it.: A controversy has arisen in the mathematics department at a large university over the proportion of freshman who had AP statistics in high school.  The department chair insists that exactly $70\%$ of freshman had AP statistics in HS, but the other department member suspect that the proportion may be different.  To resolve this issue, the department surveys $55$ freshman finding that $32$ had AP statistics in high school.  Using level $0.05$, test for evidence that the ""other department members"" are right.  Give the p-value. The work that I have done so far is as follows: $H_0$: $\pi=0.7$ vs HA: $\pi \ne 0.7$. This is a two sided test.  $\hat\pi=32/55=.5818$ about.  $\alpha=0.05$ Working the formulas I obtain $z=-1.91$.  The rejection region is $|z|>1.96$.  We conclude that we fail to reject $H_0$ as $1.91 \ngtr 1.96$. My issue now is figuring out how to find the $p$-value without using a calculator.  Any advise would be helpful.","I am running into an issue with a question that I am working on.  I want to find the $p$-value of a $z$-score by hand.  Here is the exact question and the work that I have done so far on it.: A controversy has arisen in the mathematics department at a large university over the proportion of freshman who had AP statistics in high school.  The department chair insists that exactly $70\%$ of freshman had AP statistics in HS, but the other department member suspect that the proportion may be different.  To resolve this issue, the department surveys $55$ freshman finding that $32$ had AP statistics in high school.  Using level $0.05$, test for evidence that the ""other department members"" are right.  Give the p-value. The work that I have done so far is as follows: $H_0$: $\pi=0.7$ vs HA: $\pi \ne 0.7$. This is a two sided test.  $\hat\pi=32/55=.5818$ about.  $\alpha=0.05$ Working the formulas I obtain $z=-1.91$.  The rejection region is $|z|>1.96$.  We conclude that we fail to reject $H_0$ as $1.91 \ngtr 1.96$. My issue now is figuring out how to find the $p$-value without using a calculator.  Any advise would be helpful.",,"['probability', 'statistics', 'hypothesis-testing']"
34,Probability of events A and B occurring in order AABB,Probability of events A and B occurring in order AABB,,In a given problem there are two possibilities: The probability of A is 20% The probability of B is 80% How would you calculate the probability of the events occurring in order AABB ? (they are independent) $P(BB|AA) = \frac{P(AA \cap BB)}{P(AA)}$ I think: $P(AA) = (20)(20) $ $P(AA \cap BB) = (20)(20)(80)(80)$ Using the equation I get 64% which seems too high? What am I doing wrong?,In a given problem there are two possibilities: The probability of A is 20% The probability of B is 80% How would you calculate the probability of the events occurring in order AABB ? (they are independent) $P(BB|AA) = \frac{P(AA \cap BB)}{P(AA)}$ I think: $P(AA) = (20)(20) $ $P(AA \cap BB) = (20)(20)(80)(80)$ Using the equation I get 64% which seems too high? What am I doing wrong?,,"['probability', 'statistics']"
35,White Noise Sequence,White Noise Sequence,,"Would this process be a white noise sequence? Consider the process $\{tY_t\}_{t = 1, . . . , 100}$, where $Y_t$ are independently, normally distributed with mean 0 and variance 1. The process holds for the two first conditions which are: $$ E(Y_t) = 0 $$ $$ Var (Y_t) = 1 $$ I am unsure about the third condition which states that: $$ E(Y_t,Y_s) = 0  $$ My intuitive guess would be that this condition will still hold as the sequence is independent.","Would this process be a white noise sequence? Consider the process $\{tY_t\}_{t = 1, . . . , 100}$, where $Y_t$ are independently, normally distributed with mean 0 and variance 1. The process holds for the two first conditions which are: $$ E(Y_t) = 0 $$ $$ Var (Y_t) = 1 $$ I am unsure about the third condition which states that: $$ E(Y_t,Y_s) = 0  $$ My intuitive guess would be that this condition will still hold as the sequence is independent.",,"['sequences-and-series', 'statistics', 'noise']"
36,"If parametric quantile esimation estimates $p$ by computing the MLE, then how to get non-parametric $p$? [closed]","If parametric quantile esimation estimates  by computing the MLE, then how to get non-parametric ? [closed]",p p,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question For non-parametric or parametric quantile estimation. If parametric quantile esimation estimates $p$ by computing the MLE, then how to get non-parametric $p$? Related: https://mathoverflow.net/questions/48223/parametric-vs-non-parametric-estimation-of-quantiles But I don't understand how to do non-parametric quantile estimation, nor how is $p$ estimated in that case. Does one still have to use the inverse CDF?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question For non-parametric or parametric quantile estimation. If parametric quantile esimation estimates $p$ by computing the MLE, then how to get non-parametric $p$? Related: https://mathoverflow.net/questions/48223/parametric-vs-non-parametric-estimation-of-quantiles But I don't understand how to do non-parametric quantile estimation, nor how is $p$ estimated in that case. Does one still have to use the inverse CDF?",,"['statistics', 'quantile']"
37,Mode of sum of two random variables (RVs) v.s. Mode of each RV,Mode of sum of two random variables (RVs) v.s. Mode of each RV,,"I wonder is there any literature or answer of the following relationship. What I want to know is whether the maximum peak of $\mathbf{X}+\mathbf{Y}$ is reasonably close to the maximum peak of $\mathbf{X}$. Suppose the following things. $\mathbf{X}$ and $\mathbf{Y}$ are two random variables on the same probability space $\mathbf{X}$ should be any arbitrary distribution, while $\mathbf{Y}$ is unimodal (or uniform distribution within some range). $\mathbf{X}$ can have multiple modes, but there is only a single mode that has  a maximum probability. Doesn't matter whether discrete or continuous case for simplicity, $\mathbf{Y}$ has no shifted bias, i.e. zero-mean Can I quantify or bound the position of the mode of $\mathbf{X}+\mathbf{Y}$ by the positions of the maximum mode of $\mathbf{X}$ and $\mathbf{Y}$?  I don't want to get some simulation examples, which has been already checked by myself. What I'm interested in is an explicit inequality by each of mode. If any generic relationship doesn't exist, what will be the condition for that? I appreciate in advance, thanks!","I wonder is there any literature or answer of the following relationship. What I want to know is whether the maximum peak of $\mathbf{X}+\mathbf{Y}$ is reasonably close to the maximum peak of $\mathbf{X}$. Suppose the following things. $\mathbf{X}$ and $\mathbf{Y}$ are two random variables on the same probability space $\mathbf{X}$ should be any arbitrary distribution, while $\mathbf{Y}$ is unimodal (or uniform distribution within some range). $\mathbf{X}$ can have multiple modes, but there is only a single mode that has  a maximum probability. Doesn't matter whether discrete or continuous case for simplicity, $\mathbf{Y}$ has no shifted bias, i.e. zero-mean Can I quantify or bound the position of the mode of $\mathbf{X}+\mathbf{Y}$ by the positions of the maximum mode of $\mathbf{X}$ and $\mathbf{Y}$?  I don't want to get some simulation examples, which has been already checked by myself. What I'm interested in is an explicit inequality by each of mode. If any generic relationship doesn't exist, what will be the condition for that? I appreciate in advance, thanks!",,"['probability', 'statistics', 'probability-distributions', 'random-variables', 'convolution']"
38,Combinatorics in ML: Counting Points with co-ordinates from among a set.,Combinatorics in ML: Counting Points with co-ordinates from among a set.,,"I'm trying to re-prove a theorem in the book Understanding Machine Learning: From Theory to Algorithms by Shalev-Schwartz et. al to aid my understanding of the material. The proof in the book derives a crude bound, and I'd like to derive a tighter one by counting the relevant quantities. General Version of Problem: Given a finite domain $X$ of size $M$, I'd like to consider points in the $n$-fold product of X; these points have n-coordinates, each an element of X. There are a total of $M^{n}$ such points. Now, I'd like to partition these points into $n$ sets. The first set, $S_{1}$, will contain all points that contain exactly 1 unique element of $X$ among its co-ordinates. The second set, $S_{2}$, will contain all points that contain exactly two unique elements, and so on. I would like to determine $|S_{i}|$ for $1\leq i \leq n$. $|S_{1}| = M$, since, there are exactly $M$ points with one unique member of $X$ among their co-ordinates. Similarly, $|S_{n}| = \frac{M!}{(M-n)!}$. Using the inclusion-exclusion formula, I've been able to derive a long and messy formula for $|S_{i}|$. I'm wondering if anyone knows a simple way to do this, or a standard reference where this problem is solved. Here's an example: Let $M = 6$, and the members of $X$ are just labelled with integers. Also, suppose $n=3$. The point (1,1,1)) would belong to $S_{1}$. The point (6,2,2) would belong to $S_{2}$. The point (1,5,3) would belong to $S_{3}$. This case can be solved explicitly, since $|S_{1}|$ = 6, $|S_{3}|$ = 120, and  $|S_{1}|+|S_{2}|+|S_{3}|$ = 216 I'm not very good at counting, and hope that there is a simple way to do this. Thank you!","I'm trying to re-prove a theorem in the book Understanding Machine Learning: From Theory to Algorithms by Shalev-Schwartz et. al to aid my understanding of the material. The proof in the book derives a crude bound, and I'd like to derive a tighter one by counting the relevant quantities. General Version of Problem: Given a finite domain $X$ of size $M$, I'd like to consider points in the $n$-fold product of X; these points have n-coordinates, each an element of X. There are a total of $M^{n}$ such points. Now, I'd like to partition these points into $n$ sets. The first set, $S_{1}$, will contain all points that contain exactly 1 unique element of $X$ among its co-ordinates. The second set, $S_{2}$, will contain all points that contain exactly two unique elements, and so on. I would like to determine $|S_{i}|$ for $1\leq i \leq n$. $|S_{1}| = M$, since, there are exactly $M$ points with one unique member of $X$ among their co-ordinates. Similarly, $|S_{n}| = \frac{M!}{(M-n)!}$. Using the inclusion-exclusion formula, I've been able to derive a long and messy formula for $|S_{i}|$. I'm wondering if anyone knows a simple way to do this, or a standard reference where this problem is solved. Here's an example: Let $M = 6$, and the members of $X$ are just labelled with integers. Also, suppose $n=3$. The point (1,1,1)) would belong to $S_{1}$. The point (6,2,2) would belong to $S_{2}$. The point (1,5,3) would belong to $S_{3}$. This case can be solved explicitly, since $|S_{1}|$ = 6, $|S_{3}|$ = 120, and  $|S_{1}|+|S_{2}|+|S_{3}|$ = 216 I'm not very good at counting, and hope that there is a simple way to do this. Thank you!",,"['combinatorics', 'statistics']"
39,Probability - An assortment of 20 parts,Probability - An assortment of 20 parts,,"An  assortment of 20 parts is considered to be good if it has not more than 2 defective parts, it is considered bad if it contains at least 4 defective parts. Buyer and seller of the assortment agree to test 4 randomly picked out parts. Only when all 4 are good, the purchase will take place. In this procedure the seller bears the risk of not selling a good assortment, the buyer to buy a bad assortment. Who carries the greater risk? So I have two problems here: 1) If at least 1 part is defective, the purchase won't take place (The Seller has the risk of not selling a good assortment) 2) If all 4 are good, the purchase will take place (But the buyer has the risk of buying a bad assortment) My Idea for 1)  (at least 1 part is defective) $$P(X\ge 1)=1-P(X=0)=1-\begin{pmatrix}         1  \\         0            \end{pmatrix}* \begin{pmatrix}         19  \\         4            \end{pmatrix}/ \begin{pmatrix}         20  \\         4            \end{pmatrix}=1-4/5=0,2$$ My idea for 2) (All 4 parts are good) $$        P(B)= \begin{pmatrix}         4  \\         0            \end{pmatrix}* \begin{pmatrix}         16  \\         4            \end{pmatrix}/ \begin{pmatrix}         20  \\         4            \end{pmatrix} =364/969=0,3756 $$ So the Buyer has a higher risk than the seller. However I think I made a mistake somewhere. Thanks in advance!","An  assortment of 20 parts is considered to be good if it has not more than 2 defective parts, it is considered bad if it contains at least 4 defective parts. Buyer and seller of the assortment agree to test 4 randomly picked out parts. Only when all 4 are good, the purchase will take place. In this procedure the seller bears the risk of not selling a good assortment, the buyer to buy a bad assortment. Who carries the greater risk? So I have two problems here: 1) If at least 1 part is defective, the purchase won't take place (The Seller has the risk of not selling a good assortment) 2) If all 4 are good, the purchase will take place (But the buyer has the risk of buying a bad assortment) My Idea for 1)  (at least 1 part is defective) $$P(X\ge 1)=1-P(X=0)=1-\begin{pmatrix}         1  \\         0            \end{pmatrix}* \begin{pmatrix}         19  \\         4            \end{pmatrix}/ \begin{pmatrix}         20  \\         4            \end{pmatrix}=1-4/5=0,2$$ My idea for 2) (All 4 parts are good) $$        P(B)= \begin{pmatrix}         4  \\         0            \end{pmatrix}* \begin{pmatrix}         16  \\         4            \end{pmatrix}/ \begin{pmatrix}         20  \\         4            \end{pmatrix} =364/969=0,3756 $$ So the Buyer has a higher risk than the seller. However I think I made a mistake somewhere. Thanks in advance!",,"['probability', 'probability-theory', 'statistics', 'stochastic-processes']"
40,What if the relative error is undefined?,What if the relative error is undefined?,,The relative error is defined by the simple formula: $$\text{Rel. Error} = \frac{|v_\text{approx}-v_\text{analytical}|}{v_\text{analytical}}$$ but what if the theoretical value $v_\text{analytical}$ should be $0$? then our relative error is undefined.... this is also quite a common occurs. If our analytical function is $x^2$ then at its $x=0$ we have a problem. I'm trying to program this on a computer. How do I make sure that I don't have any problems with this formula?,The relative error is defined by the simple formula: $$\text{Rel. Error} = \frac{|v_\text{approx}-v_\text{analytical}|}{v_\text{analytical}}$$ but what if the theoretical value $v_\text{analytical}$ should be $0$? then our relative error is undefined.... this is also quite a common occurs. If our analytical function is $x^2$ then at its $x=0$ we have a problem. I'm trying to program this on a computer. How do I make sure that I don't have any problems with this formula?,,['statistics']
41,Sums of Chi-Square Random Variables,Sums of Chi-Square Random Variables,,"Let $X_1\dots X_n$ be independent random variables with moment generating functions (mgf) $M_i(t) (i = 1 \dots n)$. The chi-squared random variable with ν degrees of freedom has mgf $M(t) = (1 − 2t)^{ −ν/2}$. When $ν$ is a positive integer, the random variable is the sum of $ν$ independent squared standard normal random variables, i.e.$\sum_{i=1}^{v} Z_i^2$. (i) Let the $X_i$ be chi-squared random variables with $ν_i$ degrees of freedom respectively. Using the result ""$Y = \sum_{i=1}^{n} a_iX_i$ has mgf $M_Y (t) = \prod_{i=1}^nM_i(a_it)$"", show that $Y =\sum_{i=1}^n X_i$ is chi-squared with $\sum_{i=1}^n ν_i$ degrees of freedom. Assuming the $ν_i$ are positive integers, give intuition for this result by describing a scenario by which $Y$ might be generated. HI, would someone please solve for me? It is not my homework, just one of the problems from the past exam. I've tried substituting $M_Y (t) = \prod_{i=1}^n (1 − 2t)^{−ν/2}=(1 − 2t)^{−nν/2}$ and what now?","Let $X_1\dots X_n$ be independent random variables with moment generating functions (mgf) $M_i(t) (i = 1 \dots n)$. The chi-squared random variable with ν degrees of freedom has mgf $M(t) = (1 − 2t)^{ −ν/2}$. When $ν$ is a positive integer, the random variable is the sum of $ν$ independent squared standard normal random variables, i.e.$\sum_{i=1}^{v} Z_i^2$. (i) Let the $X_i$ be chi-squared random variables with $ν_i$ degrees of freedom respectively. Using the result ""$Y = \sum_{i=1}^{n} a_iX_i$ has mgf $M_Y (t) = \prod_{i=1}^nM_i(a_it)$"", show that $Y =\sum_{i=1}^n X_i$ is chi-squared with $\sum_{i=1}^n ν_i$ degrees of freedom. Assuming the $ν_i$ are positive integers, give intuition for this result by describing a scenario by which $Y$ might be generated. HI, would someone please solve for me? It is not my homework, just one of the problems from the past exam. I've tried substituting $M_Y (t) = \prod_{i=1}^n (1 − 2t)^{−ν/2}=(1 − 2t)^{−nν/2}$ and what now?",,"['probability', 'statistics', 'random-variables', 'independence', 'chi-squared']"
42,Differences in abstract Poisson population samplings,Differences in abstract Poisson population samplings,,"Given some abstract population, we take samples of sizes $n=15$, $n=25$, and $n=50$, and then do 10000 trials with each sample with Poisson distribution. As a result, we obtain the following plots: I'm trying to understand the following: Why does increasing the sample size also increases the range of the $y$-axis? Why are there fewer (thinner) columns in each histogram when samples increase? A sample of 10000 will plot a rectangle (just one wide column). What does this imply? Would appreciate some clarification.","Given some abstract population, we take samples of sizes $n=15$, $n=25$, and $n=50$, and then do 10000 trials with each sample with Poisson distribution. As a result, we obtain the following plots: I'm trying to understand the following: Why does increasing the sample size also increases the range of the $y$-axis? Why are there fewer (thinner) columns in each histogram when samples increase? A sample of 10000 will plot a rectangle (just one wide column). What does this imply? Would appreciate some clarification.",,"['statistics', 'poisson-distribution', 'means']"
43,Finding mean value of a distribution so that the probabilty of an interval equals 0.5,Finding mean value of a distribution so that the probabilty of an interval equals 0.5,,"So, I have an exercise I can't solve that goes like this: ""Professor Y always adjusts its students' grades by adding a fixed value c to each grade so that 50% of the students get a grade between 70 and 80. If the grades follow a normal distribution with an expected value of 65 and a variance  of 38, what value of c should be added? There are two possible values, choose the one which benefits the students the most."" This is what I've managed to do so far: Adding a value c to all grades corresponds to shifting the mean value of the distribution to the right. Let X be the variable which represents the students' grades, modeled by a normal distribution N(65,38). We want to know the value of c such that: P(a < X < a + 10) = 0.5 <=> P(X < a + 10) - P(X < a) = 0.5 c = 70 - a a (and by consequence c) can take two values because we can easily see graphically that there are two posssible intervals, symmetric to each other about the mean which are a solution to the problem. The preferred value for a is the smaller one, so that c can be larger, which causes a greater change on the grades. I stopped here because I couldn't find a way to solve the two equations and get the values of c and a. Any help is highly appreciated.","So, I have an exercise I can't solve that goes like this: ""Professor Y always adjusts its students' grades by adding a fixed value c to each grade so that 50% of the students get a grade between 70 and 80. If the grades follow a normal distribution with an expected value of 65 and a variance  of 38, what value of c should be added? There are two possible values, choose the one which benefits the students the most."" This is what I've managed to do so far: Adding a value c to all grades corresponds to shifting the mean value of the distribution to the right. Let X be the variable which represents the students' grades, modeled by a normal distribution N(65,38). We want to know the value of c such that: P(a < X < a + 10) = 0.5 <=> P(X < a + 10) - P(X < a) = 0.5 c = 70 - a a (and by consequence c) can take two values because we can easily see graphically that there are two posssible intervals, symmetric to each other about the mean which are a solution to the problem. The preferred value for a is the smaller one, so that c can be larger, which causes a greater change on the grades. I stopped here because I couldn't find a way to solve the two equations and get the values of c and a. Any help is highly appreciated.",,"['probability', 'statistics', 'random-variables', 'normal-distribution']"
44,One thousand raffle tickets are sold,One thousand raffle tickets are sold,,"The scenario is: One thousand raffle tickets are sold. There is a grand prize of \$300, 3 second prizes of \$100, and 6 third prizes of \$50.  A person purchased one raffle ticket. Find the probability that the person wins at least \$100. I am thinking that let X denote the amount of money the person wins from the raffle. I am interested in finding $P(X \geq 100)$ (if I am correct). Since the person only buys one raffle, then this turns out to be the probability the person wins either the grand prize or the second prize category, not the third prize because even if the person won that prize, he or she could only win at most 50$. Therefore, the probability I am looking at is (1/1000) + (2/1000); this is incorrect. I am not sure why. Thank you!","The scenario is: One thousand raffle tickets are sold. There is a grand prize of \$300, 3 second prizes of \$100, and 6 third prizes of \$50.  A person purchased one raffle ticket. Find the probability that the person wins at least \$100. I am thinking that let X denote the amount of money the person wins from the raffle. I am interested in finding $P(X \geq 100)$ (if I am correct). Since the person only buys one raffle, then this turns out to be the probability the person wins either the grand prize or the second prize category, not the third prize because even if the person won that prize, he or she could only win at most 50$. Therefore, the probability I am looking at is (1/1000) + (2/1000); this is incorrect. I am not sure why. Thank you!",,"['probability', 'statistics', 'central-limit-theorem']"
45,"Using the Normal Approximation to the Poisson Distribution, where appropiate, If X ~ Po(30) find P(X=<31)","Using the Normal Approximation to the Poisson Distribution, where appropiate, If X ~ Po(30) find P(X=<31)",,P(X =< 31) Z = X - μ/σ = 31-30/30^1/2 = 0.183 -> Φ(0.183) = 0.5726 The Answer is 0.608,P(X =< 31) Z = X - μ/σ = 31-30/30^1/2 = 0.183 -> Φ(0.183) = 0.5726 The Answer is 0.608,,"['statistics', 'normal-distribution', 'poisson-distribution']"
46,Need help on the Proof of Lemma 7.3.11 in Statistical Inference Casella&Berger (v2),Need help on the Proof of Lemma 7.3.11 in Statistical Inference Casella&Berger (v2),,"The Lemma states that if $f(x|\theta)$ satisfies $\frac{d}{d\theta}\mathbb{E}_\theta\left(\frac{\partial}{\partial\theta} \log(X|\theta)\right) = \int \frac{\partial}{\partial\theta} \left[\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right) f(x|\theta)\right] dx$ then $\mathbb{E}_\theta \left( \left(\frac{\partial}{\partial\theta} \log f(X|\theta)\right)^2\right)  = -\mathbb{E}_\theta \left( \frac{\partial^2}{\partial \theta^2}\log f(X|\theta)\right). $ The proof of the Lemma is left as an Exercise (7.39). what I get is $\mathbb{E}_\theta \left( \frac{\partial^2}{\partial \theta^2}\log f(X|\theta)\right) = \int \left( \frac{\partial^2}{\partial \theta^2}\log f(X|\theta)\right) \log(x|\theta) dx $ $=\int \frac{\partial}{\partial\theta} \left[\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right) f(x|\theta)\right] dx - \int\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right)\frac{\partial}{\partial\theta} f(x|\theta) dx   $ Note that $\mathbb{E}_\theta \left( \left(\frac{\partial}{\partial\theta} \log f(X|\theta)\right)^2\right) =\int\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right)\frac{\partial}{\partial\theta} f(x|\theta) dx,$ So basically I need that $\int \frac{\partial}{\partial\theta} \left[\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right) f(x|\theta)\right] dx=0$, for which I am unable to derive from the assumption of the Lemma. Am I missing anything? Thanks.","The Lemma states that if $f(x|\theta)$ satisfies $\frac{d}{d\theta}\mathbb{E}_\theta\left(\frac{\partial}{\partial\theta} \log(X|\theta)\right) = \int \frac{\partial}{\partial\theta} \left[\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right) f(x|\theta)\right] dx$ then $\mathbb{E}_\theta \left( \left(\frac{\partial}{\partial\theta} \log f(X|\theta)\right)^2\right)  = -\mathbb{E}_\theta \left( \frac{\partial^2}{\partial \theta^2}\log f(X|\theta)\right). $ The proof of the Lemma is left as an Exercise (7.39). what I get is $\mathbb{E}_\theta \left( \frac{\partial^2}{\partial \theta^2}\log f(X|\theta)\right) = \int \left( \frac{\partial^2}{\partial \theta^2}\log f(X|\theta)\right) \log(x|\theta) dx $ $=\int \frac{\partial}{\partial\theta} \left[\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right) f(x|\theta)\right] dx - \int\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right)\frac{\partial}{\partial\theta} f(x|\theta) dx   $ Note that $\mathbb{E}_\theta \left( \left(\frac{\partial}{\partial\theta} \log f(X|\theta)\right)^2\right) =\int\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right)\frac{\partial}{\partial\theta} f(x|\theta) dx,$ So basically I need that $\int \frac{\partial}{\partial\theta} \left[\left(\frac{\partial}{\partial\theta}\log f(x|\theta)\right) f(x|\theta)\right] dx=0$, for which I am unable to derive from the assumption of the Lemma. Am I missing anything? Thanks.",,"['probability', 'statistics', 'statistical-inference']"
47,Minimize the sum of Type I and Type II errors,Minimize the sum of Type I and Type II errors,,"Given $X_1,\dots,X_n$ a simple random sample with normal variables ($\mu, \sigma^2$). We assume $\mu$ is unknown but $\sigma$ is known. Now consider the hypothesis $  	\begin{cases} 	H_0: & \mu=\mu_0 \\ 	H_1: & \mu=\mu_1 > \mu_0 	\end{cases} 	$ Determine the critical region $R$ in order to minimize the risk $P_{H_0}(R)+P_{H_1}(R^c)$. I'm not sure how to start this problem, in particular due to the fact that I'm dealing with $n$ samples here. I believe the test statistic I have to apply here is $z=\displaystyle\frac{\bar{X}-\mu}{(\sigma/\sqrt{n})}$, but I'm not sure how the application of it follows. EDIT Alright, let's consider the following: using the error function above I have that the error function with mean 0 and variance $\sigma $ is $\frac{1}{2\pi}\int_0^{\alpha/(\sigma\sqrt{2})} e^{-t^2}dt$. This error gives the probability of falling in $(-\alpha,\alpha)$ but I am interested in the rejection region, this is $(-\infty, \alpha)\cup(\alpha, +\infty)$. Therefore, I think I should consider the complementary error function $$ \operatorname{erfc}(\alpha) = 1-\frac{1}{2\pi}\int_0^{\alpha/(\sigma\sqrt{2})} e^{-t^2} \, dt = \frac 1 {2\pi}\int_{\alpha/(\sigma\sqrt{2})}^\infty e^{-t^2}\,dt $$ Now I could derive and get that $\frac{d}{dt}\operatorname{erfc}(\sigma) = - \frac{1}{2\pi}e^{-\alpha^2/(2\sigma^2)}$. I should set it to $0$ and find $\alpha$, to ""solve"" the problem. There are three issues here: (1) $e^{-\alpha^2/(2\sigma^2)}$ will never be zero for any $\alpha$. (2) I didn't get involved the hypothesis testing. (3) It is not clear what the $\sigma$ in the error function is. The wikipedia entry linked above says that error generally have mean zero, but it is possible for the error to have a variance. Is the $\sigma$ in the normal distribution the very same $\sigma$ in the error function?","Given $X_1,\dots,X_n$ a simple random sample with normal variables ($\mu, \sigma^2$). We assume $\mu$ is unknown but $\sigma$ is known. Now consider the hypothesis $  	\begin{cases} 	H_0: & \mu=\mu_0 \\ 	H_1: & \mu=\mu_1 > \mu_0 	\end{cases} 	$ Determine the critical region $R$ in order to minimize the risk $P_{H_0}(R)+P_{H_1}(R^c)$. I'm not sure how to start this problem, in particular due to the fact that I'm dealing with $n$ samples here. I believe the test statistic I have to apply here is $z=\displaystyle\frac{\bar{X}-\mu}{(\sigma/\sqrt{n})}$, but I'm not sure how the application of it follows. EDIT Alright, let's consider the following: using the error function above I have that the error function with mean 0 and variance $\sigma $ is $\frac{1}{2\pi}\int_0^{\alpha/(\sigma\sqrt{2})} e^{-t^2}dt$. This error gives the probability of falling in $(-\alpha,\alpha)$ but I am interested in the rejection region, this is $(-\infty, \alpha)\cup(\alpha, +\infty)$. Therefore, I think I should consider the complementary error function $$ \operatorname{erfc}(\alpha) = 1-\frac{1}{2\pi}\int_0^{\alpha/(\sigma\sqrt{2})} e^{-t^2} \, dt = \frac 1 {2\pi}\int_{\alpha/(\sigma\sqrt{2})}^\infty e^{-t^2}\,dt $$ Now I could derive and get that $\frac{d}{dt}\operatorname{erfc}(\sigma) = - \frac{1}{2\pi}e^{-\alpha^2/(2\sigma^2)}$. I should set it to $0$ and find $\alpha$, to ""solve"" the problem. There are three issues here: (1) $e^{-\alpha^2/(2\sigma^2)}$ will never be zero for any $\alpha$. (2) I didn't get involved the hypothesis testing. (3) It is not clear what the $\sigma$ in the error function is. The wikipedia entry linked above says that error generally have mean zero, but it is possible for the error to have a variance. Is the $\sigma$ in the normal distribution the very same $\sigma$ in the error function?",,"['statistics', 'statistical-inference', 'hypothesis-testing']"
48,Reverse Z-Value for normal distrubtion,Reverse Z-Value for normal distrubtion,,"Wondering if I'm on the right path on this question. Let $X$ be a Normal distributed stochastic value with $\mu=4$ and $\sigma = 7$ Find a value $C$ so that $P(X>C)=0.78$ The way I've solved this question was to first change the equation like so $$1-P(X<C)=0.78$$ $$P(X<C)=0.22$$ Then find the $Z$ value that equals $0.22$ and that would be $Z(-0.77)$ That makes my new equation equal to. $$P(X<C)=Z(-0.77)$$ I then use the formula for the normal distrubtion and solve for a C that would make the equation equal to $-0.77$ $$\frac{C-4}{7}=-0.77$$ And then I get the answer $$C=-1.39$$ I would believe my execution is right but it differs from the solution my teacher has given. Granted his solution set has a couple of miscalculations because it has not been verified I have yet to find anyone complain about his answer on this one which leads me to believe that I have made an error. His answer was, by the way, $$C=9.39$$","Wondering if I'm on the right path on this question. Let $X$ be a Normal distributed stochastic value with $\mu=4$ and $\sigma = 7$ Find a value $C$ so that $P(X>C)=0.78$ The way I've solved this question was to first change the equation like so $$1-P(X<C)=0.78$$ $$P(X<C)=0.22$$ Then find the $Z$ value that equals $0.22$ and that would be $Z(-0.77)$ That makes my new equation equal to. $$P(X<C)=Z(-0.77)$$ I then use the formula for the normal distrubtion and solve for a C that would make the equation equal to $-0.77$ $$\frac{C-4}{7}=-0.77$$ And then I get the answer $$C=-1.39$$ I would believe my execution is right but it differs from the solution my teacher has given. Granted his solution set has a couple of miscalculations because it has not been verified I have yet to find anyone complain about his answer on this one which leads me to believe that I have made an error. His answer was, by the way, $$C=9.39$$",,"['statistics', 'stochastic-processes', 'normal-distribution', 'standard-deviation']"
49,What is the expected value of the mean of a random subset?,What is the expected value of the mean of a random subset?,,Lets say you have a set $A$ made up of $n$ integers. We then randomly choose $m$ distinct elements from $A$ and put them in a set $B$. How would you prove that the expected value of the mean of $B$ is equal to the mean of $A$? Namely $E\left[\dfrac{1}{m}\sum_ja_j\right] = \dfrac{1}{n}\sum_ia_i$ where $j$ represents each of the random integers in $B$ and $i$ represents the items in $A$.,Lets say you have a set $A$ made up of $n$ integers. We then randomly choose $m$ distinct elements from $A$ and put them in a set $B$. How would you prove that the expected value of the mean of $B$ is equal to the mean of $A$? Namely $E\left[\dfrac{1}{m}\sum_ja_j\right] = \dfrac{1}{n}\sum_ia_i$ where $j$ represents each of the random integers in $B$ and $i$ represents the items in $A$.,,"['probability', 'statistics']"
50,Probability of guessing incorrect infinite number of times,Probability of guessing incorrect infinite number of times,,"Suppose I have an event with probability p , what is the probability of this event never occurring infinite number of times. For example; what is the probability of someone rolling a dice and guessing the number wrong infinite number of times.","Suppose I have an event with probability p , what is the probability of this event never occurring infinite number of times. For example; what is the probability of someone rolling a dice and guessing the number wrong infinite number of times.",,"['probability', 'probability-theory', 'statistics', 'law-of-large-numbers']"
51,Definition of Method of Moments,Definition of Method of Moments,,"In the mathematical literature, I have found two definitions for the Method of Moments so far: The first definition concerns a method for estimating the parameters of a population. This method is described, for instance, in Wikipedia: https://en.wikipedia.org/wiki/Method_of_moments_(statistics) In probability theory, the Method of Moment concerns a result which allows to prove the convergence in distribution of a sequence of random variables. There is another Wikipedia entry for this method: https://en.wikipedia.org/wiki/Method_of_moments_(probability_theory) My question is whether these two meanings are somehow related, or whether ""Method of Moment"" is indeed used to describe two unrelated methods?","In the mathematical literature, I have found two definitions for the Method of Moments so far: The first definition concerns a method for estimating the parameters of a population. This method is described, for instance, in Wikipedia: https://en.wikipedia.org/wiki/Method_of_moments_(statistics) In probability theory, the Method of Moment concerns a result which allows to prove the convergence in distribution of a sequence of random variables. There is another Wikipedia entry for this method: https://en.wikipedia.org/wiki/Method_of_moments_(probability_theory) My question is whether these two meanings are somehow related, or whether ""Method of Moment"" is indeed used to describe two unrelated methods?",,"['probability-theory', 'statistics']"
52,mgf of an infinite sum of independent random variables,mgf of an infinite sum of independent random variables,,"It is known that if $S_n = \sum_{i=1}^{n} X_i$, where the $X_i$ are independent random variables, then  the moment-generating function for $S_n$ is given by $M_{S_n}(t)=\prod_{i=1}^{n}M_{X_i}(t)$. Now suppose that we have infinitely many random variables $X_i,i\in\mathbb{N}$, and suppose that the moment-generating function exists for each random variable $X_i,i\in\mathbb{N}$. Denote $S = \sum_{i=1}^{\infty} X_i$. Then do we have that (maybe under some additional conditions) $ M_{S}(t)=\prod_{i=1}^{\infty}M_{X_i}(t)$? If so then how can we prove it? I really tried hard to find out such a formula for the mgf of an infinite sum of independent random variables but all the lecture notes and books that I dipped into only present the formula for finite case.","It is known that if $S_n = \sum_{i=1}^{n} X_i$, where the $X_i$ are independent random variables, then  the moment-generating function for $S_n$ is given by $M_{S_n}(t)=\prod_{i=1}^{n}M_{X_i}(t)$. Now suppose that we have infinitely many random variables $X_i,i\in\mathbb{N}$, and suppose that the moment-generating function exists for each random variable $X_i,i\in\mathbb{N}$. Denote $S = \sum_{i=1}^{\infty} X_i$. Then do we have that (maybe under some additional conditions) $ M_{S}(t)=\prod_{i=1}^{\infty}M_{X_i}(t)$? If so then how can we prove it? I really tried hard to find out such a formula for the mgf of an infinite sum of independent random variables but all the lecture notes and books that I dipped into only present the formula for finite case.",,"['probability', 'statistics', 'probability-distributions']"
53,How to find the MLE for $P(X>a)$ for $n$ iid normal random variables,How to find the MLE for  for  iid normal random variables,P(X>a) n,"I am given that $X_i \stackrel {iid}\sim N(\theta,\sigma^2)$ for $i=1,\cdots,n$, with known $\sigma$ and given $a$. Where $p=\mathbb P(X_1>a)$, I am asked to find the MLE of $p$. So far, I have tried to put the joint likelihood of the $X_i$ in terms containing $p$. I have not succeeded in doing this. I know that  $$L(\mathbf{\vec{X}})=(2\pi\sigma^2)^{-n/2}\exp\left\{-\frac1{2\sigma^2} \sum_{i=1}^n (X_i-\theta)^2\right\}$$ and that $p=1-\Phi(\frac{a-\theta}\sigma)$, with $\Phi$ the cdf of $N(0,1)$. But I can't find a way to put $p$ into the expression for $L(\mathbf{\vec{X}})$. Edit: after reading this question on Cross Validated, I have a possible answer, which I will put below. Comments would be appreciated.","I am given that $X_i \stackrel {iid}\sim N(\theta,\sigma^2)$ for $i=1,\cdots,n$, with known $\sigma$ and given $a$. Where $p=\mathbb P(X_1>a)$, I am asked to find the MLE of $p$. So far, I have tried to put the joint likelihood of the $X_i$ in terms containing $p$. I have not succeeded in doing this. I know that  $$L(\mathbf{\vec{X}})=(2\pi\sigma^2)^{-n/2}\exp\left\{-\frac1{2\sigma^2} \sum_{i=1}^n (X_i-\theta)^2\right\}$$ and that $p=1-\Phi(\frac{a-\theta}\sigma)$, with $\Phi$ the cdf of $N(0,1)$. But I can't find a way to put $p$ into the expression for $L(\mathbf{\vec{X}})$. Edit: after reading this question on Cross Validated, I have a possible answer, which I will put below. Comments would be appreciated.",,"['probability', 'statistics', 'statistical-inference', 'maximum-likelihood']"
54,Determine the relationship between number of sales vs. percentage of the time that the phone is answered (instead of going to voicemail),Determine the relationship between number of sales vs. percentage of the time that the phone is answered (instead of going to voicemail),,"Problem Determine the relationship between the percentage of the time that the phone gets answered before going to voicemail and the number of sales that are made. So example output might be: f(43%) = 4 f(80%) = 10 f(95%) = 12 Note: I'm not a math professional so I apologize that I am unable to express this problem in the correct and formal way. Background I own a mobile auto detailing company. I wrote a computer program that routes all of our calls in and out of the company. It also has a scheduler where we put in all of our appointments (a new appointment is how I am defining a ""sale"" here.) So I have a huge list of phone calls about 13,000 in the past year - and I can go back at least 5 years if need be. I also have a huge list of all of the appointments that we've scheduled, including the times that the appointments were created. What I don't understand is how to process this data so that I can get an approximate relationship between the percentage of the time that we are answering the phone at any given time and how many appointments we are scheduling. This is especially difficult since we almost always return calls that are missed, and sometimes we do schedule appointments that way, so its hard to see the affect on answering the phone when they first call vs. calling them back. For all I know, the relationship could be inverted and we make more sales when we don't answer the phone as much (although this is highly unlikely) I am a computer programmer, so I can write up some code to process this data, but I don't know the correct statistical methods to process it properly. My end goal is to be able to understand things like ""Since we answered the phone 75% of the time today, and got 43 total   calls, we probably would have scheduled 2 more jobs if we had answered   the phone 20% more."" The only way I can think of to do this is do break all of the data into days, then plot it in a spreadsheet with one axis being percent of the time the phone was answered that day and the other axis being the ratio between appointments scheduled and total calls for that day - then draw a trend line - but this seems a little crude since the data is being broken up into days. For anyone who's interested, here's a screenshot of some of the information tallied by day: Edit I think what I had in mind when writing this original question was probably overkill for the problem. Essentially we are dealing with a few signals: Calls: _____1____1____0_1____1____1_____0___________0______         0 = Missed, 1 = Answered  Sales: ______1_________1_________1____________1___________1        1 = a sale was made There is probably some mathematical way to find the relationship between the two signals. Like looking at the froward time deltas between phone calls and sales being made that will expose the relationship between periods of time with greater and lesser answer rates vs. sales being made. The complexity here is that I was looking for a mathematical process that doesn't require the data to be pre-clustered into days (or some other time period). ...But enough of that! There is an easier and slightly less precise way to do this with ""common sense"" math if I just take the precision hit and pre-cluster into days. Frankly the results are more than good enough for the purposes here: For us to understand the approximate financial cost of missing calls (and the financial gain of higher answer rates). Thus I can balance this priority against other priorities. Now I can answer questions like Should I pay X dollars to hire another person to help answer the phone? Is it ok to miss a call during a team meeting? Do we have enough volume to hire another technician if we answer the phone more? Approximate Solution (Good-enough solution) I exported a year of data into Google Sheets, specifically I looked at:    - Percent of phone calls answered     - Total appointments scheduled / Total calls for the day. (a higher percentage here means that we converted more of our inbound leads into sales) Each dot represents the ""Percent of Inbound Calls Answered"" for that day vs ""Number of Appointments Scheduled Divided by Total Inbound Calls"". As you can see, higher answer rates are correlated with a larger percentage of inbound leads being converted into sales (Note, all missed calls are always returned even if they don't leave a message): Then I added a trend line. If I understand what I did correctly, the trend line is basically saying that for each call we answer, there is about an 18% chance we will make an additional sale that day. Another way of looking at it is that for every 5.5 calls that we miss, we are losing  1 sale.","Problem Determine the relationship between the percentage of the time that the phone gets answered before going to voicemail and the number of sales that are made. So example output might be: f(43%) = 4 f(80%) = 10 f(95%) = 12 Note: I'm not a math professional so I apologize that I am unable to express this problem in the correct and formal way. Background I own a mobile auto detailing company. I wrote a computer program that routes all of our calls in and out of the company. It also has a scheduler where we put in all of our appointments (a new appointment is how I am defining a ""sale"" here.) So I have a huge list of phone calls about 13,000 in the past year - and I can go back at least 5 years if need be. I also have a huge list of all of the appointments that we've scheduled, including the times that the appointments were created. What I don't understand is how to process this data so that I can get an approximate relationship between the percentage of the time that we are answering the phone at any given time and how many appointments we are scheduling. This is especially difficult since we almost always return calls that are missed, and sometimes we do schedule appointments that way, so its hard to see the affect on answering the phone when they first call vs. calling them back. For all I know, the relationship could be inverted and we make more sales when we don't answer the phone as much (although this is highly unlikely) I am a computer programmer, so I can write up some code to process this data, but I don't know the correct statistical methods to process it properly. My end goal is to be able to understand things like ""Since we answered the phone 75% of the time today, and got 43 total   calls, we probably would have scheduled 2 more jobs if we had answered   the phone 20% more."" The only way I can think of to do this is do break all of the data into days, then plot it in a spreadsheet with one axis being percent of the time the phone was answered that day and the other axis being the ratio between appointments scheduled and total calls for that day - then draw a trend line - but this seems a little crude since the data is being broken up into days. For anyone who's interested, here's a screenshot of some of the information tallied by day: Edit I think what I had in mind when writing this original question was probably overkill for the problem. Essentially we are dealing with a few signals: Calls: _____1____1____0_1____1____1_____0___________0______         0 = Missed, 1 = Answered  Sales: ______1_________1_________1____________1___________1        1 = a sale was made There is probably some mathematical way to find the relationship between the two signals. Like looking at the froward time deltas between phone calls and sales being made that will expose the relationship between periods of time with greater and lesser answer rates vs. sales being made. The complexity here is that I was looking for a mathematical process that doesn't require the data to be pre-clustered into days (or some other time period). ...But enough of that! There is an easier and slightly less precise way to do this with ""common sense"" math if I just take the precision hit and pre-cluster into days. Frankly the results are more than good enough for the purposes here: For us to understand the approximate financial cost of missing calls (and the financial gain of higher answer rates). Thus I can balance this priority against other priorities. Now I can answer questions like Should I pay X dollars to hire another person to help answer the phone? Is it ok to miss a call during a team meeting? Do we have enough volume to hire another technician if we answer the phone more? Approximate Solution (Good-enough solution) I exported a year of data into Google Sheets, specifically I looked at:    - Percent of phone calls answered     - Total appointments scheduled / Total calls for the day. (a higher percentage here means that we converted more of our inbound leads into sales) Each dot represents the ""Percent of Inbound Calls Answered"" for that day vs ""Number of Appointments Scheduled Divided by Total Inbound Calls"". As you can see, higher answer rates are correlated with a larger percentage of inbound leads being converted into sales (Note, all missed calls are always returned even if they don't leave a message): Then I added a trend line. If I understand what I did correctly, the trend line is basically saying that for each call we answer, there is about an 18% chance we will make an additional sale that day. Another way of looking at it is that for every 5.5 calls that we miss, we are losing  1 sale.",,"['statistics', 'computational-mathematics']"
55,"If there are $5,000,000$ couples in a city, and the probability that a couple matches a specific description is $1\over12,000,000$...?","If there are  couples in a city, and the probability that a couple matches a specific description is ...?","5,000,000 1\over12,000,000","If there are $5,000,000$ couples in a city, and the probability that a couple matches a specific description is $1\over 12,000,000$, what are the chances that there are two couples that match the specific description given that there is at least one couple that matches the description? I guess I'm supposed to use conditional probability, but I'm not sure how.","If there are $5,000,000$ couples in a city, and the probability that a couple matches a specific description is $1\over 12,000,000$, what are the chances that there are two couples that match the specific description given that there is at least one couple that matches the description? I guess I'm supposed to use conditional probability, but I'm not sure how.",,"['probability', 'statistics']"
56,"Show that $\operatorname{cov}(x,a + by) = b \operatorname{cov}(x,y)$",Show that,"\operatorname{cov}(x,a + by) = b \operatorname{cov}(x,y)","Let $x$ and $y$ be jointly distributed numeric variables and let $z=a+by$ , where $a$ and $b$ are constants. Show that $\operatorname{cov}(x,z)=b\, \operatorname{cov}(x,y)$. Here's what I have so far, but then I got stuck. Finished.","Let $x$ and $y$ be jointly distributed numeric variables and let $z=a+by$ , where $a$ and $b$ are constants. Show that $\operatorname{cov}(x,z)=b\, \operatorname{cov}(x,y)$. Here's what I have so far, but then I got stuck. Finished.",,"['statistics', 'proof-writing', 'covariance']"
57,Is This Bayes' Theorem Solution Correct?,Is This Bayes' Theorem Solution Correct?,,"Q: Considering 2 slot machines. One machine has a 10% chance of paying out, the other has a 20% chance. One machine is red, the other green. You don't know which pays more. Initially, you're 50% sure that the red machine pays more. You try it once, and it doesn't pay out. After this first attempt, how should you update the estimate that the red machine has a higher chance of paying out? So, I did this, but I'm not sure if it's right. Any clarification appreciated! $P(Red\ Pays\ More|No\ Pay\ Out) = P(No\ Pay\ Out|Red\ Pays\ More)P(Red\ Pays\ More)/P(No\ Pay\ Out)$ I assumed the $P(No\ Pay\ Out|Red\ Pays\ More) = 0.8$ (because there is a 0.8 chance of not being paid if the red machine is the one that pays more). $P(Red\ Pays\ More) = 0.5$ $P(No\ Pay\ Out) = 0.85$","Q: Considering 2 slot machines. One machine has a 10% chance of paying out, the other has a 20% chance. One machine is red, the other green. You don't know which pays more. Initially, you're 50% sure that the red machine pays more. You try it once, and it doesn't pay out. After this first attempt, how should you update the estimate that the red machine has a higher chance of paying out? So, I did this, but I'm not sure if it's right. Any clarification appreciated! $P(Red\ Pays\ More|No\ Pay\ Out) = P(No\ Pay\ Out|Red\ Pays\ More)P(Red\ Pays\ More)/P(No\ Pay\ Out)$ I assumed the $P(No\ Pay\ Out|Red\ Pays\ More) = 0.8$ (because there is a 0.8 chance of not being paid if the red machine is the one that pays more). $P(Red\ Pays\ More) = 0.5$ $P(No\ Pay\ Out) = 0.85$",,['probability']
58,"Variance of a random sum, with a random variable as upper limit","Variance of a random sum, with a random variable as upper limit",,"How did they get this result starting in ($\star$)? Define: $X_0 := 1, X_{n+1} = \sum_{i=1}^{X_n} Y_i$ with $Y_i$ iid for all $i = 1,2,\ldots$, and $\mathbb{E}(Y_i) = \mu, \operatorname{Var}(Y_i) = \sigma^2$. We found that $\mathbb{E}(X_n) = \mu^{n}$. We want to find the variance of $X_{n+1}$. $$\operatorname{Var}(X_{n+1})= \mathbb{E}(\operatorname{Var}(X_n \mid X_{n+1}) + \operatorname{Var}(\mathbb{E}(X_{n}\mid X_{n+1}) \\ = \sigma^2 \mu^{n-1} + \mu^2 \operatorname{Var}(X_{n-1})$$ Since $\operatorname{Var}(X_0) = 0$ and $\operatorname{Var}(X_1) = \sigma^2$, we obtain: $$\operatorname{Var}(X_n) = \sigma^2 (\mu^{n-1} + \mu^n + \cdots +\mu^{2n-2}) \qquad  (\star)$$","How did they get this result starting in ($\star$)? Define: $X_0 := 1, X_{n+1} = \sum_{i=1}^{X_n} Y_i$ with $Y_i$ iid for all $i = 1,2,\ldots$, and $\mathbb{E}(Y_i) = \mu, \operatorname{Var}(Y_i) = \sigma^2$. We found that $\mathbb{E}(X_n) = \mu^{n}$. We want to find the variance of $X_{n+1}$. $$\operatorname{Var}(X_{n+1})= \mathbb{E}(\operatorname{Var}(X_n \mid X_{n+1}) + \operatorname{Var}(\mathbb{E}(X_{n}\mid X_{n+1}) \\ = \sigma^2 \mu^{n-1} + \mu^2 \operatorname{Var}(X_{n-1})$$ Since $\operatorname{Var}(X_0) = 0$ and $\operatorname{Var}(X_1) = \sigma^2$, we obtain: $$\operatorname{Var}(X_n) = \sigma^2 (\mu^{n-1} + \mu^n + \cdots +\mu^{2n-2}) \qquad  (\star)$$",,"['probability-theory', 'statistics', 'variance']"
59,Numerics for Tracy-Widom distribution,Numerics for Tracy-Widom distribution,,"I have data for a random variable and I wish to test whether it conforms to the Tracy-Widom distribution. However, the T-W distribution is hard to compute. Is there a readly available table of its values I can just download?","I have data for a random variable and I wish to test whether it conforms to the Tracy-Widom distribution. However, the T-W distribution is hard to compute. Is there a readly available table of its values I can just download?",,['statistics']
60,Example of $\arg\min\limits_{T: E(T(X))=\theta}\mathbb{E}|T(X) - \theta| \neq \arg\min\limits_{E(T(X))=\theta}\mathbb{E}(T(X) - \theta)^2$,Example of,\arg\min\limits_{T: E(T(X))=\theta}\mathbb{E}|T(X) - \theta| \neq \arg\min\limits_{E(T(X))=\theta}\mathbb{E}(T(X) - \theta)^2,"Suppose that $X_1, X_2, \dots, X_n$ is an i.i.d. sample distributed according to $F(x, \theta)$ distribution function, and we want to estimate $\theta$. Among all unbiased estimators, the best one is considered to be the one which has the minimum variance. But what if we want to minimize not variance, but absolute deviation, e.g. find such statistics $T(X)$ which has minimum $\mathbb{E}|T(X_1, X_2, \dots, X_n) - \theta|$, not $\mathbb{E}(T(X_1, X_2, \dots, X_n) - \theta)^2$? Can you provide examples of a distribution $F(x, \theta)$ and two unbiased estimators one of which has the least variance and another one – the least expected absolute deviation? I tried to consider normal distribution. It is known that both the sample mean and the sample median are unbiased estimators for the mean. But I'm not sure that the median has the least expected absolute deviation here. Any help, comments, hints and, especially, complete answers are very welcome and would be greatly appreciated!","Suppose that $X_1, X_2, \dots, X_n$ is an i.i.d. sample distributed according to $F(x, \theta)$ distribution function, and we want to estimate $\theta$. Among all unbiased estimators, the best one is considered to be the one which has the minimum variance. But what if we want to minimize not variance, but absolute deviation, e.g. find such statistics $T(X)$ which has minimum $\mathbb{E}|T(X_1, X_2, \dots, X_n) - \theta|$, not $\mathbb{E}(T(X_1, X_2, \dots, X_n) - \theta)^2$? Can you provide examples of a distribution $F(x, \theta)$ and two unbiased estimators one of which has the least variance and another one – the least expected absolute deviation? I tried to consider normal distribution. It is known that both the sample mean and the sample median are unbiased estimators for the mean. But I'm not sure that the median has the least expected absolute deviation here. Any help, comments, hints and, especially, complete answers are very welcome and would be greatly appreciated!",,"['probability-theory', 'statistics', 'optimization', 'parameter-estimation']"
61,Covariance and Variance,Covariance and Variance,,"Given two random variables $X$ and $Y$ , I wish to find $Cov(X + Y, X − Y )$ assuming that $(a)$ $X$ and $Y$ are independent and $(b)$ $X$ and $Y$ are dependent & $Var(X) = Var(Y )$ I started with $$Cov(X + Y, X − Y) = Cov(X, X-Y) + Cov(Y, X-Y) = Var(X)- Cov(X,Y) + Cov(Y,X)- Var(Y)$$  such that for $a)$ we have $Var(x) - Var (Y)$ and for $b)$ we have $0$. Just checking if my method is correct thanks!","Given two random variables $X$ and $Y$ , I wish to find $Cov(X + Y, X − Y )$ assuming that $(a)$ $X$ and $Y$ are independent and $(b)$ $X$ and $Y$ are dependent & $Var(X) = Var(Y )$ I started with $$Cov(X + Y, X − Y) = Cov(X, X-Y) + Cov(Y, X-Y) = Var(X)- Cov(X,Y) + Cov(Y,X)- Var(Y)$$  such that for $a)$ we have $Var(x) - Var (Y)$ and for $b)$ we have $0$. Just checking if my method is correct thanks!",,"['probability', 'statistics', 'covariance', 'variance']"
62,How to make conditional probability of continuous variable match intuition? [closed],How to make conditional probability of continuous variable match intuition? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I'm stuck with the following ""physical problem"": I have a set $E=\{1, \ldots, n\}$, a function $f : E \to \mathbb{R}$ and a secret value $x_0\in E$. My goal is to find $x_0$. Furthermore, I know that for $x\neq x_0$ (resp. $x= x_0$), $f(x)$ is supposed to be drawn from a fixed continuous distribution $D$ (resp. $D'$). Hence my first thought was to sort all $x$ according to: $$\Pr(x=x_0\mid\forall x'\in E, f(x'))$$ At this point I have already a problem, because I don't know how to formalize the intuitive meaning of $\Pr(\cdot\mid\forall x\in E,f(x))$ (I can't find any way to write the RHS as an event). And then applying a kind of Bayes formula for continuous variables: $$\Pr(x=x_0\mid\forall x'\in E, f(x'))=\frac{\text{Pr}(\forall x'\in E,f(x')\mid x=x_0) \Pr(x=x_0)}{\sum_{x''}\Pr(\forall x'\in E, f(x')\mid x''=x_0) \Pr(x''=x_0)}$$ Thus, as I think my model implies to choose $x_0$ uniformly at random in $E$, only $\Pr(\forall x'\in E,f(x')\mid x=x_0)$ depends on $x$. And my intuition tells me that if my model was correctly formalized, it could be expressed with the CDF $F_D$ and $F_D'$. How can I do this? I'm not familiar with statistics, so I'm expecting an explanation from probability theory.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I'm stuck with the following ""physical problem"": I have a set $E=\{1, \ldots, n\}$, a function $f : E \to \mathbb{R}$ and a secret value $x_0\in E$. My goal is to find $x_0$. Furthermore, I know that for $x\neq x_0$ (resp. $x= x_0$), $f(x)$ is supposed to be drawn from a fixed continuous distribution $D$ (resp. $D'$). Hence my first thought was to sort all $x$ according to: $$\Pr(x=x_0\mid\forall x'\in E, f(x'))$$ At this point I have already a problem, because I don't know how to formalize the intuitive meaning of $\Pr(\cdot\mid\forall x\in E,f(x))$ (I can't find any way to write the RHS as an event). And then applying a kind of Bayes formula for continuous variables: $$\Pr(x=x_0\mid\forall x'\in E, f(x'))=\frac{\text{Pr}(\forall x'\in E,f(x')\mid x=x_0) \Pr(x=x_0)}{\sum_{x''}\Pr(\forall x'\in E, f(x')\mid x''=x_0) \Pr(x''=x_0)}$$ Thus, as I think my model implies to choose $x_0$ uniformly at random in $E$, only $\Pr(\forall x'\in E,f(x')\mid x=x_0)$ depends on $x$. And my intuition tells me that if my model was correctly formalized, it could be expressed with the CDF $F_D$ and $F_D'$. How can I do this? I'm not familiar with statistics, so I'm expecting an explanation from probability theory.",,"['probability', 'statistics', 'bayes-theorem']"
63,"On SVD, PCA and optimization","On SVD, PCA and optimization",,"Let's say we got a data matrix $X_{n,p}$ wich represent $n$ person with $p$ feature. We can represent each person in an $R^n$ space, then we get a data cloud. One goal of PCA is to find the ""best approximation"" of the data cloud in a $k$ dimensional subspace of $R^n$ . This best approximation is introduced in various geometric way: We look for a projection $P_{E_k}$ such that the sum of the  distance between the  ""projected person"" would be maximum. Similar to ""least square""method we look for an ""orthogonal projection"" which would minimize the sum of distance between the points and their projected. We look for the maximum ""inertie"" or Variance of the projected cloud which geometrically give the total distance between the projected cloud and his bartcenter. Finally a non geometric approach lead us to look for the ""best"" low rank (rank $k $ ) approximation of $X $ (cf. Eckart-Young theorem. My questions are the following (please don't miss the drawing at the end) A) Could you prove the equivalence between all theses statement? B) In 1)  we consider all the projection whereas in 2) we focused on orthogonal projection. How is that possible ? How do we finally get that the ""best"" projection is an orthogonal one? PS: All my question raised from a really interesting presentation wich suffer to prove nothing: http://bertrand.michel.perso.math.cnrs.fr/Enseignements/5MS04/ACP-AFC-ACM.pdf Could you prove the equivalence of the 4 point of view ? Thanks","Let's say we got a data matrix wich represent person with feature. We can represent each person in an space, then we get a data cloud. One goal of PCA is to find the ""best approximation"" of the data cloud in a dimensional subspace of . This best approximation is introduced in various geometric way: We look for a projection such that the sum of the  distance between the  ""projected person"" would be maximum. Similar to ""least square""method we look for an ""orthogonal projection"" which would minimize the sum of distance between the points and their projected. We look for the maximum ""inertie"" or Variance of the projected cloud which geometrically give the total distance between the projected cloud and his bartcenter. Finally a non geometric approach lead us to look for the ""best"" low rank (rank ) approximation of (cf. Eckart-Young theorem. My questions are the following (please don't miss the drawing at the end) A) Could you prove the equivalence between all theses statement? B) In 1)  we consider all the projection whereas in 2) we focused on orthogonal projection. How is that possible ? How do we finally get that the ""best"" projection is an orthogonal one? PS: All my question raised from a really interesting presentation wich suffer to prove nothing: http://bertrand.michel.perso.math.cnrs.fr/Enseignements/5MS04/ACP-AFC-ACM.pdf Could you prove the equivalence of the 4 point of view ? Thanks","X_{n,p} n p R^n k R^n P_{E_k} k  X ","['statistics', 'optimization', 'svd', 'principal-component-analysis']"
64,why is R-square NOT well-defined for a regression without a constant term,why is R-square NOT well-defined for a regression without a constant term,,"We often have a constant term in a linear regression such as, $y=\beta_1 x+\beta_0$. The $R^2$ or the coefficient of determination, is defined as $R^2=1-\frac{SS_{res}}{SS_{tot}}$, where $SS_{res}$ and $SS_{tot}$ are residual sum of squares and total sum of squares. Let's say now we drop the constant term $\beta_0$, the above formula for calculating $R^2$ still works, or is it? If we try this in Matlab, we receive a Warning that says, R-square and the F statistic are not well-defined unless X has a column of ones. What does ""not well-defined"" mean here? It seems okay.","We often have a constant term in a linear regression such as, $y=\beta_1 x+\beta_0$. The $R^2$ or the coefficient of determination, is defined as $R^2=1-\frac{SS_{res}}{SS_{tot}}$, where $SS_{res}$ and $SS_{tot}$ are residual sum of squares and total sum of squares. Let's say now we drop the constant term $\beta_0$, the above formula for calculating $R^2$ still works, or is it? If we try this in Matlab, we receive a Warning that says, R-square and the F statistic are not well-defined unless X has a column of ones. What does ""not well-defined"" mean here? It seems okay.",,"['statistics', 'matlab', 'regression', 'linear-regression']"
65,Estimator of $\mu - \mu^2$ when sampling without replacement,Estimator of  when sampling without replacement,\mu - \mu^2,"Question Consider a population of known size $N$, from which we sample $n$ individuals without replacement and measure their trait value $X_i$. All traits values are bounded between $[0,1]$. Let $\mu = \frac{\sum_i^N x_i}{N}$ be the average trait value in the population. If it makes things easier, I am happy to consider that $X$ is boolean ($0$ or $1$). What is the unbiased estimator for $\mu - \mu^2$? Attempt $$ \begin{align} \mu - \mu^2 &= \operatorname{E}[\bar X] - \operatorname{E}[\bar X]^2\\ &= \operatorname{E}[\bar X] - \operatorname{E}[\bar X]^2 - \operatorname{var}[\bar X] + \operatorname{var}[\bar X] \\ &= \operatorname{E}[\bar X] - \operatorname{E}[\bar X]^2 - \operatorname{var}[\bar X] + \frac{1}{n} \sigma^2 \\ &= \operatorname{E}[\bar X] - \operatorname{E}[\bar X^2] + \frac{1}{n} \operatorname{E}[\hat \sigma^2], \end{align}$$ where $\hat \sigma^2$ is the estimator for the variance. Looking at this post , $$\hat\sigma^2 = \frac{N-1}{N(n-1)} \sum_{i=1}^n (X_i-\bar X)^2$$ Hence, $$\mu - \mu^2 = \operatorname{E}\left[ \bar X - \bar X^2 + \frac{1}{n} \frac{N-1}{N(n-1)} \sum_{i=1}^n (X_i-\bar X)^2\right] $$ Test Looked good to me so I tried it out (in R ) nbtrials = 5000      # number of independent samples N = 20               # Number of individuals in the population pop = rep(0:1, N/2)  # Create a boolean population with $\mu = 0.5$ n = 17               # Sample size  out = numeric(nbtrials)  # out will collect the estimates of $\mu - \mu^2$ for (trial in 1:nbtrials) {     s = sample(pop,size=n, replace=FALSE)   # Take a sample without replacement     xbar = sum(s) / n                       # Compute the average frequency in the sample     out[trial] = xbar - xbar^2 + 1/n * (N - 1) / (N*(n-1)) * sum((s - mean(s))^2)   # Compute the estimator }  # Now compare the population with the average of estimations taken from the samples trueMean=sum(pop) / length(pop) print(paste(""True value  = "",trueMean *(1-trueMean))) print(paste(""Average estimated value = "",mean(out))) which outputs something like ""True value  =  0.25"" ""Average estimated value =  0.262343771626298"" showing a clear systematic overestimation. Where did I go wrong? Where does the mistake lie? From @EinarRødland's comment, it seems likely that my mistake is in the equation $var[\bar X] = \frac{\sigma^2}{n}$, which is wrong due to the fact that sampling occurs without replacement from a finite population.","Question Consider a population of known size $N$, from which we sample $n$ individuals without replacement and measure their trait value $X_i$. All traits values are bounded between $[0,1]$. Let $\mu = \frac{\sum_i^N x_i}{N}$ be the average trait value in the population. If it makes things easier, I am happy to consider that $X$ is boolean ($0$ or $1$). What is the unbiased estimator for $\mu - \mu^2$? Attempt $$ \begin{align} \mu - \mu^2 &= \operatorname{E}[\bar X] - \operatorname{E}[\bar X]^2\\ &= \operatorname{E}[\bar X] - \operatorname{E}[\bar X]^2 - \operatorname{var}[\bar X] + \operatorname{var}[\bar X] \\ &= \operatorname{E}[\bar X] - \operatorname{E}[\bar X]^2 - \operatorname{var}[\bar X] + \frac{1}{n} \sigma^2 \\ &= \operatorname{E}[\bar X] - \operatorname{E}[\bar X^2] + \frac{1}{n} \operatorname{E}[\hat \sigma^2], \end{align}$$ where $\hat \sigma^2$ is the estimator for the variance. Looking at this post , $$\hat\sigma^2 = \frac{N-1}{N(n-1)} \sum_{i=1}^n (X_i-\bar X)^2$$ Hence, $$\mu - \mu^2 = \operatorname{E}\left[ \bar X - \bar X^2 + \frac{1}{n} \frac{N-1}{N(n-1)} \sum_{i=1}^n (X_i-\bar X)^2\right] $$ Test Looked good to me so I tried it out (in R ) nbtrials = 5000      # number of independent samples N = 20               # Number of individuals in the population pop = rep(0:1, N/2)  # Create a boolean population with $\mu = 0.5$ n = 17               # Sample size  out = numeric(nbtrials)  # out will collect the estimates of $\mu - \mu^2$ for (trial in 1:nbtrials) {     s = sample(pop,size=n, replace=FALSE)   # Take a sample without replacement     xbar = sum(s) / n                       # Compute the average frequency in the sample     out[trial] = xbar - xbar^2 + 1/n * (N - 1) / (N*(n-1)) * sum((s - mean(s))^2)   # Compute the estimator }  # Now compare the population with the average of estimations taken from the samples trueMean=sum(pop) / length(pop) print(paste(""True value  = "",trueMean *(1-trueMean))) print(paste(""Average estimated value = "",mean(out))) which outputs something like ""True value  =  0.25"" ""Average estimated value =  0.262343771626298"" showing a clear systematic overestimation. Where did I go wrong? Where does the mistake lie? From @EinarRødland's comment, it seems likely that my mistake is in the equation $var[\bar X] = \frac{\sigma^2}{n}$, which is wrong due to the fact that sampling occurs without replacement from a finite population.",,"['probability', 'statistics', 'estimation', 'sampling', 'variance']"
66,Find an unbiased estimate of $\hat{\theta}$ which is a function of $T$.,Find an unbiased estimate of  which is a function of .,\hat{\theta} T,"$(X,Y)$ is uniform over the triangular region with vertices at $(0,0)$,$(\theta, 0)$, and $(0,\theta)$, $\theta$ is unknown. Let $(X_i,Y_i)$ be iid as $(X,Y)$. Find a one dimensional sufficient statistic $T$ for $\theta$, and prove it's sufficient. Find an unbiased estimate of $\hat{\theta}$ which is a function of $T$. Attempt $f_{X,Y}(x,y) = \frac{2}{\theta^2}$ $L(\theta| \mathbf{X},\mathbf{Y}) = (\frac{\theta^2}{2})^{-n} \prod I_{x_i+y_i < \theta}$ Sufficient statistic: $T = max_i (X_i+Y_i)$ $\hat{\theta} = ?$","$(X,Y)$ is uniform over the triangular region with vertices at $(0,0)$,$(\theta, 0)$, and $(0,\theta)$, $\theta$ is unknown. Let $(X_i,Y_i)$ be iid as $(X,Y)$. Find a one dimensional sufficient statistic $T$ for $\theta$, and prove it's sufficient. Find an unbiased estimate of $\hat{\theta}$ which is a function of $T$. Attempt $f_{X,Y}(x,y) = \frac{2}{\theta^2}$ $L(\theta| \mathbf{X},\mathbf{Y}) = (\frac{\theta^2}{2})^{-n} \prod I_{x_i+y_i < \theta}$ Sufficient statistic: $T = max_i (X_i+Y_i)$ $\hat{\theta} = ?$",,"['statistics', 'random-variables', 'uniform-distribution']"
67,Expectation of CDF of standard normal distribution,Expectation of CDF of standard normal distribution,,"How to calculate $E[\{\Phi(\alpha X)\}^{K}]$ for K being positive integer, $\Phi()$ is the CDF of standard normal distribution and $X\sim N(0,1)$. I tried using integration by part stuck.","How to calculate $E[\{\Phi(\alpha X)\}^{K}]$ for K being positive integer, $\Phi()$ is the CDF of standard normal distribution and $X\sim N(0,1)$. I tried using integration by part stuck.",,['statistics']
68,Moments about the mean of a uniform distribution,Moments about the mean of a uniform distribution,,"I really don't know what needs to be completed here, because I don't understand the parameters of alpha and beta: Show that if a random variable has a uniform density with the parameters alpha and beta, the $r$th moment about the mean is $\frac{1}{r+1}\left(\frac{\beta-\alpha}{2}\right)^r$ and zero otherwise.","I really don't know what needs to be completed here, because I don't understand the parameters of alpha and beta: Show that if a random variable has a uniform density with the parameters alpha and beta, the $r$th moment about the mean is $\frac{1}{r+1}\left(\frac{\beta-\alpha}{2}\right)^r$ and zero otherwise.",,"['probability', 'statistics', 'probability-distributions', 'expectation', 'uniform-distribution']"
69,Does bounded expectation imply almost sure boundedness for the sample mean?,Does bounded expectation imply almost sure boundedness for the sample mean?,,"Let $X_1,X_2,X_3,\dots, X_n$ be i.i.d random variables from a probability distribution. Further there is a positive constant M such that $|E[X]|<M.$ My question is does the strong law imply that the sample mean $\bar{X_n}$ is almost surely bounded (i.e $P(|\bar{X_n}|>C)=0$,$\forall n\geq n_0$ and some constant $C>0.$) for very large n?","Let $X_1,X_2,X_3,\dots, X_n$ be i.i.d random variables from a probability distribution. Further there is a positive constant M such that $|E[X]|<M.$ My question is does the strong law imply that the sample mean $\bar{X_n}$ is almost surely bounded (i.e $P(|\bar{X_n}|>C)=0$,$\forall n\geq n_0$ and some constant $C>0.$) for very large n?",,"['probability-theory', 'statistics', 'measure-theory']"
70,Best way to model reliability,Best way to model reliability,,"I have 10 databases of facts from 10 different sources, I now know if the facts were true or false. What is the best way to form an equation to determine the reliability of each of the source? I don't want a source who got 4/4 True to have a higher reliability rating than someone who got 395/400 correct. I want a formula that takes into account the total number of facts in the database ? Thanks for any help.","I have 10 databases of facts from 10 different sources, I now know if the facts were true or false. What is the best way to form an equation to determine the reliability of each of the source? I don't want a source who got 4/4 True to have a higher reliability rating than someone who got 395/400 correct. I want a formula that takes into account the total number of facts in the database ? Thanks for any help.",,['statistics']
71,Generative / Discriminative model for linear regression,Generative / Discriminative model for linear regression,,"In Murphy's book , page 242-243, it is asked to describe the advantages and disadvantages of the generative model for linear regression, compared with the standard discriminative approach. I'm looking for a complete answer to this, since it is not clear what to say. What I got so far: Disvantages: It is an indirect method, since we have to estimate the joint distribution $Y,\mathbf{X}$ before finding the optimal predictor; There are too many parameters to estimate, namely $\frac{(p+1)(p+2)}{2}$ in the covariance matrix $\Sigma$ of the joint distribution, plus the $p+1$ parameters for the mean of $\textbf{X}$ and $Y$ . Advantages: Better accuracy for small training sets; One can use the joint distribution to generate new data similar to the existing data. There is also one disadvantage that I don't understand so well: it is said that the number of needed parameters is $p+1$ . I think that this refers to $\textbf{w}$ and $w_0$ , but I'm not sure. Thanks in advance.","In Murphy's book , page 242-243, it is asked to describe the advantages and disadvantages of the generative model for linear regression, compared with the standard discriminative approach. I'm looking for a complete answer to this, since it is not clear what to say. What I got so far: Disvantages: It is an indirect method, since we have to estimate the joint distribution before finding the optimal predictor; There are too many parameters to estimate, namely in the covariance matrix of the joint distribution, plus the parameters for the mean of and . Advantages: Better accuracy for small training sets; One can use the joint distribution to generate new data similar to the existing data. There is also one disadvantage that I don't understand so well: it is said that the number of needed parameters is . I think that this refers to and , but I'm not sure. Thanks in advance.","Y,\mathbf{X} \frac{(p+1)(p+2)}{2} \Sigma p+1 \textbf{X} Y p+1 \textbf{w} w_0","['statistics', 'regression', 'machine-learning', 'linear-regression']"
72,How to prove that $E[U_1U_2 \mid |U_1-U_2|<a]$ is the sum of two double integrals?,How to prove that  is the sum of two double integrals?,E[U_1U_2 \mid |U_1-U_2|<a],"Suppose that $U_1, U_2 \sim Unif(0,1)$ are iid random variables. I am trying to find: $$ E[U_1U_2 \mid |U_1-U_2|<a] $$ for $a<\frac{1}{2}$. It appears that the answer is: $$ \int_{u_1 = 0}^1 \int_{u_2 = u_1}^{u_1 + a} u_1 u_2  \text{d} u_2 \text{d} u_1 +     \int_{u_2 = 0}^1 \int_{u_1 = u_2}^{u_2 + a} u_1 u_2  \text{d} u_1 \text{d} u_2 $$ However, I have no idea how the conditional expectation was turned into two integrals with the bounds. Can anyone walk me through how exactly this result formally came about? Thanks.","Suppose that $U_1, U_2 \sim Unif(0,1)$ are iid random variables. I am trying to find: $$ E[U_1U_2 \mid |U_1-U_2|<a] $$ for $a<\frac{1}{2}$. It appears that the answer is: $$ \int_{u_1 = 0}^1 \int_{u_2 = u_1}^{u_1 + a} u_1 u_2  \text{d} u_2 \text{d} u_1 +     \int_{u_2 = 0}^1 \int_{u_1 = u_2}^{u_2 + a} u_1 u_2  \text{d} u_1 \text{d} u_2 $$ However, I have no idea how the conditional expectation was turned into two integrals with the bounds. Can anyone walk me through how exactly this result formally came about? Thanks.",,"['probability', 'probability-theory', 'statistics']"
73,Is it possible to not know if a random variable is continuous or not?,Is it possible to not know if a random variable is continuous or not?,,"Suppose I have a sample of a random variable, $X$ but I do not know if the distribution is continuous or discrete. First of all is this possible? Second if it is possible how could I determine if $X$ is continuous from a set of iid random variables $X_1, ... X_n$?","Suppose I have a sample of a random variable, $X$ but I do not know if the distribution is continuous or discrete. First of all is this possible? Second if it is possible how could I determine if $X$ is continuous from a set of iid random variables $X_1, ... X_n$?",,"['statistics', 'random-variables']"
74,Finding conditional covariance and expectation for Poisson process,Finding conditional covariance and expectation for Poisson process,,"Let $\{N_t:t \ge 0 \}$ be a Poisson process with rate $\lambda$. Find the followings: (a) $\mathrm{Cov}(N_{3t}, N_{5t}|N_t)$ (b) $\mathbb E[\mathrm{Cov}(N_t, N_{3t}|N_{5t})]$ To find (a), using that $N_{3t} $ and $N_{5t}-N_{3t}$ are independent when given $N_t$, $\mathrm{Cov}(N_{3t}, N_{5t}|N_t)=\mathrm{Cov}(N_{3t}, N_{5t}-N_{3t}+N_{3t}|N_t)=\mathrm{Cov}(N_{3t}, N_{5t}-N_{3t}|N_t)+\mathrm{Cov}(N_{3t}, N_{3t}|N_t)=\mathrm{Var}(N_{3t}|N_t)=\mathrm{Var}(N_{3t}-N_t+N_t|N_t)=\mathrm{Var}(N_{3t}-N_t|N_t)+\mathrm{Var}(N_{t}|N_t)$ Where the last equality is from the fact that $N_{3t}-N_t$ and $N_t$ are independent. Also, Since $N_t$ is already given, $\mathrm{Var}(N_{t}|N_t)=0$, and $\mathrm{Var}(N_{3t}-N_t|N_t)=\mathrm{Var}(N_{3t}-N_t)=2\lambda t$. Am I right? For (b), since $N_{5t}$ is given, we cannot argue that $N_t$ and $N_{3t}-N_t$ are independent because they cannot exceed $N_{5t}$. What should I do for (b)?","Let $\{N_t:t \ge 0 \}$ be a Poisson process with rate $\lambda$. Find the followings: (a) $\mathrm{Cov}(N_{3t}, N_{5t}|N_t)$ (b) $\mathbb E[\mathrm{Cov}(N_t, N_{3t}|N_{5t})]$ To find (a), using that $N_{3t} $ and $N_{5t}-N_{3t}$ are independent when given $N_t$, $\mathrm{Cov}(N_{3t}, N_{5t}|N_t)=\mathrm{Cov}(N_{3t}, N_{5t}-N_{3t}+N_{3t}|N_t)=\mathrm{Cov}(N_{3t}, N_{5t}-N_{3t}|N_t)+\mathrm{Cov}(N_{3t}, N_{3t}|N_t)=\mathrm{Var}(N_{3t}|N_t)=\mathrm{Var}(N_{3t}-N_t+N_t|N_t)=\mathrm{Var}(N_{3t}-N_t|N_t)+\mathrm{Var}(N_{t}|N_t)$ Where the last equality is from the fact that $N_{3t}-N_t$ and $N_t$ are independent. Also, Since $N_t$ is already given, $\mathrm{Var}(N_{t}|N_t)=0$, and $\mathrm{Var}(N_{3t}-N_t|N_t)=\mathrm{Var}(N_{3t}-N_t)=2\lambda t$. Am I right? For (b), since $N_{5t}$ is given, we cannot argue that $N_t$ and $N_{3t}-N_t$ are independent because they cannot exceed $N_{5t}$. What should I do for (b)?",,"['probability', 'statistics', 'stochastic-processes', 'poisson-process']"
75,Finding Variance from a joint moment generating function,Finding Variance from a joint moment generating function,,"The random vars X and Y have, for all real values of $T_1, T_2$, the joint mgf $M(T_1 , T_2) = \frac{1}{2} e^{T_1 +T_2} + \frac{1}{4} e^{2T_1 +T2} + \frac{1}{12}e^{T_2} + \frac{1}{6} e^{4T_1 +3T_2}$ I'm looking for V[X], but I believe that I am overlooking a way to simplify this problem. I know that variance is the second moment or the second derivative of the mgf,but I am not sure how to generate these derivatives and what to do after, given that it is a bivariate equation. Any pointers would be appreciated.","The random vars X and Y have, for all real values of $T_1, T_2$, the joint mgf $M(T_1 , T_2) = \frac{1}{2} e^{T_1 +T_2} + \frac{1}{4} e^{2T_1 +T2} + \frac{1}{12}e^{T_2} + \frac{1}{6} e^{4T_1 +3T_2}$ I'm looking for V[X], but I believe that I am overlooking a way to simplify this problem. I know that variance is the second moment or the second derivative of the mgf,but I am not sure how to generate these derivatives and what to do after, given that it is a bivariate equation. Any pointers would be appreciated.",,"['statistics', 'variance', 'moment-generating-functions', 'bivariate-distributions']"
76,Which subject are these students best? (basic high school statistical question),Which subject are these students best? (basic high school statistical question),,"It's a very basic high school statistical question, but I'm struggling to solve it. Suppose I have a school with $287$ students and each one made a test with $50$ questions (multiple choice questions with $5$ items each, they have to choose one item in each question). These questions are divided into the following subjects: Subject A - $8$ questions Subject B - $6$ questions Subject C - $10$ questions Subject D - $6$ questions Subject E - $6$ questions Subject F - $14$ questions We say a student fail the test when he doesn't solve any question. Then we have the following result: Subject A - $3$ students failed Subject B - $16$ students failed Subject C - $1$ students failed Subject D - $1$ students failed Subject E - $8$ students failed Subject F - $0$ students failed So how can I compare the performance of the students? In another words, which subject were they best and which one were they worse? Remark: Each student has only two options: successful or failure, so in this case the overall score in each subject is not important.","It's a very basic high school statistical question, but I'm struggling to solve it. Suppose I have a school with students and each one made a test with questions (multiple choice questions with items each, they have to choose one item in each question). These questions are divided into the following subjects: Subject A - questions Subject B - questions Subject C - questions Subject D - questions Subject E - questions Subject F - questions We say a student fail the test when he doesn't solve any question. Then we have the following result: Subject A - students failed Subject B - students failed Subject C - students failed Subject D - students failed Subject E - students failed Subject F - students failed So how can I compare the performance of the students? In another words, which subject were they best and which one were they worse? Remark: Each student has only two options: successful or failure, so in this case the overall score in each subject is not important.",287 50 5 8 6 10 6 6 14 3 16 1 1 8 0,['statistics']
77,A-Posteriori Probability,A-Posteriori Probability,,"I have a question to the following: Let $\lambda$ ~ $Exp(1)$ and for a given $\lambda$ the $X_1, \ldots, X_n$  are i.i.d. with $X_i \mid \lambda$ ~ $Exp(\lambda)$. What is the a-posteriori distribution of $\lambda$ and what is the a-posteriori probability for $\lambda \geq 2$ if $n = 5$ and the mean value of the $X_i$ is given by $1.2$? Ma idea was the following: The likelihood is given by: $$ l(\lambda \mid \underline{x}) = \prod_{i=1}^n \lambda \exp(-\lambda x_i) = \lambda^n\exp(-\lambda \sum_{i=1}^n x_i)$$ The a-priori is given by $\pi(\lambda)=\exp(-\lambda)$. Therefore the a-posteriori is given by: $$ \pi(\lambda \mid \underline{x}) \propto l(\lambda \mid \underline{x})\pi(\lambda) = \lambda^n \exp(-\lambda(\sum_{i=1}^n x_i+1))$$ Therefore $\pi(\lambda \mid \underline{x})$ ~ $Ga(n+1, 1+n\overline{x})$ where $\overline{x} = \frac{1}{n} \sum_{i=1}^n x_i$. Now for the probabilty my idea was to calculate $$ P(\lambda \geq 2 \mid \underline{x}) = 1-P(\lambda \leq 1 \mid \underline{x}) = 1-\int_0^1 \frac{(1+5*1,2)^6}{\Gamma(6)}\lambda^5\exp(-\lambda(1+5*1,2)) d\lambda $$ but is this approach the correct one?","I have a question to the following: Let $\lambda$ ~ $Exp(1)$ and for a given $\lambda$ the $X_1, \ldots, X_n$  are i.i.d. with $X_i \mid \lambda$ ~ $Exp(\lambda)$. What is the a-posteriori distribution of $\lambda$ and what is the a-posteriori probability for $\lambda \geq 2$ if $n = 5$ and the mean value of the $X_i$ is given by $1.2$? Ma idea was the following: The likelihood is given by: $$ l(\lambda \mid \underline{x}) = \prod_{i=1}^n \lambda \exp(-\lambda x_i) = \lambda^n\exp(-\lambda \sum_{i=1}^n x_i)$$ The a-priori is given by $\pi(\lambda)=\exp(-\lambda)$. Therefore the a-posteriori is given by: $$ \pi(\lambda \mid \underline{x}) \propto l(\lambda \mid \underline{x})\pi(\lambda) = \lambda^n \exp(-\lambda(\sum_{i=1}^n x_i+1))$$ Therefore $\pi(\lambda \mid \underline{x})$ ~ $Ga(n+1, 1+n\overline{x})$ where $\overline{x} = \frac{1}{n} \sum_{i=1}^n x_i$. Now for the probabilty my idea was to calculate $$ P(\lambda \geq 2 \mid \underline{x}) = 1-P(\lambda \leq 1 \mid \underline{x}) = 1-\int_0^1 \frac{(1+5*1,2)^6}{\Gamma(6)}\lambda^5\exp(-\lambda(1+5*1,2)) d\lambda $$ but is this approach the correct one?",,"['probability', 'probability-theory', 'statistics', 'bayes-theorem', 'exponential-distribution']"
78,What metric is used to measure consistency in scores?,What metric is used to measure consistency in scores?,,"So suppose you are trying to compare 2 people's consistency in Bowling where the max score is 300. Standard deviation seems like it would not be reliable to measure consistency in performance because large variations are seen without context. If player A gets 104, 115, and 180 while player B gets 120, 123, and 127, player B is seen as the more consistently better one if you plainly use standard deviation. If you use the mean of both players' data, player A's average will be affected by the outlier. So I'm wondering which formula can be reliably used to determine who is more consistent as well as better performing overall.","So suppose you are trying to compare 2 people's consistency in Bowling where the max score is 300. Standard deviation seems like it would not be reliable to measure consistency in performance because large variations are seen without context. If player A gets 104, 115, and 180 while player B gets 120, 123, and 127, player B is seen as the more consistently better one if you plainly use standard deviation. If you use the mean of both players' data, player A's average will be affected by the outlier. So I'm wondering which formula can be reliably used to determine who is more consistent as well as better performing overall.",,"['statistics', 'data-analysis']"
79,How to use cross-validation to select probability threshold for logistic regression,How to use cross-validation to select probability threshold for logistic regression,,"I have a question about how to use cross-validation to select probability threshold for logistic regression. Suppose I want to minimize the misclassification rate. Say, I use 5-fold CV, and is this procedure correct: 1.fit 5 logistic regression models using each 4-folds of the data. 2.for each probability threshold(e.g. from 0.01 to 0.99), apply the 5 models on the left 1-fold of data, get misclassification rate. Then average these 5 error rates. 3.the optimal probability threshold is the one with smallest misclassification rate. And suppose I fit a ridge logistic regression model, to select the tuning parameter $\lambda$, is it okay to first use CV to select an optimal $\lambda$(e.g. use cv.glmnet function in R package glmnet), then apply this parameter to the procedure above to find probability threshold?","I have a question about how to use cross-validation to select probability threshold for logistic regression. Suppose I want to minimize the misclassification rate. Say, I use 5-fold CV, and is this procedure correct: 1.fit 5 logistic regression models using each 4-folds of the data. 2.for each probability threshold(e.g. from 0.01 to 0.99), apply the 5 models on the left 1-fold of data, get misclassification rate. Then average these 5 error rates. 3.the optimal probability threshold is the one with smallest misclassification rate. And suppose I fit a ridge logistic regression model, to select the tuning parameter $\lambda$, is it okay to first use CV to select an optimal $\lambda$(e.g. use cv.glmnet function in R package glmnet), then apply this parameter to the procedure above to find probability threshold?",,"['statistics', 'regression', 'machine-learning', 'data-analysis']"
80,"Sample mean, without replacement","Sample mean, without replacement",,"I'm going through a statistics course and I'm having some difficulties with the point estimation. It makes sense to me in basic examples, but as soon as the ""without replacement"" examples got introduced, I got stuck. Here's an example: A box has $4$ numbered balls, $1$ , $2$ , $3$ and $4$ . A sample of $2$ is drawn without replacement. What is the expected sample mean? For $1$ ball it's $\frac{1}{4} \sum X_i$ , which is $2.5$ . Simple so far. Once one ball is extracted, the probabilities change for the others, but since I don't know which ball number was removed, I can't use the same formula. What shall I do? I would really appreciate some advice and pointers. Thanks in advance.","I'm going through a statistics course and I'm having some difficulties with the point estimation. It makes sense to me in basic examples, but as soon as the ""without replacement"" examples got introduced, I got stuck. Here's an example: A box has numbered balls, , , and . A sample of is drawn without replacement. What is the expected sample mean? For ball it's , which is . Simple so far. Once one ball is extracted, the probabilities change for the others, but since I don't know which ball number was removed, I can't use the same formula. What shall I do? I would really appreciate some advice and pointers. Thanks in advance.",4 1 2 3 4 2 1 \frac{1}{4} \sum X_i 2.5,"['probability', 'statistics']"
81,Finding the PDF of a Second Order Statistic,Finding the PDF of a Second Order Statistic,,"Suppose that $Y_1,Y_2 ~ i.i.d$ Expo(b) Find the pdf of the second order statistic, $U_2 =max(Y_1,Y_2)$ $F_{U_2}(u)= P(U_2<u) = P\{Max(Y_1,Y_2)<u\}= P(Y_1<u,Y_2<u)=P(Y_1<u)P(Y_2<u)= P(Y_1<u)^2 =(1-e^{-u/b})^2$ Then you do some differentiation and get the answer. The problem is that I am confused about how we go from $P\{Max(Y_1,Y_2)<u\}$ to $P(Y_1<u,Y_2<u)$ and from $P(Y_1<u)P(Y_2<u)$ to $P(Y_1<u)^2$  could someone please explain?","Suppose that $Y_1,Y_2 ~ i.i.d$ Expo(b) Find the pdf of the second order statistic, $U_2 =max(Y_1,Y_2)$ $F_{U_2}(u)= P(U_2<u) = P\{Max(Y_1,Y_2)<u\}= P(Y_1<u,Y_2<u)=P(Y_1<u)P(Y_2<u)= P(Y_1<u)^2 =(1-e^{-u/b})^2$ Then you do some differentiation and get the answer. The problem is that I am confused about how we go from $P\{Max(Y_1,Y_2)<u\}$ to $P(Y_1<u,Y_2<u)$ and from $P(Y_1<u)P(Y_2<u)$ to $P(Y_1<u)^2$  could someone please explain?",,"['probability', 'probability-theory', 'statistics', 'probability-distributions', 'order-statistics']"
82,Definitions of E(X^2) - expected value of r.v. X squared,Definitions of E(X^2) - expected value of r.v. X squared,,"My book has two examples of computing $E(X^2)$ Let X be the score on a fair die $E(X^2) = \frac{1}{6}(1^2 + 2^2+3^2+4^2+5^2+6^2)$ Let X be the number of fixed points in a permutation $E(X^2)=\sum_i^nE(X_i)^2 + \sum_{i\neq j}E(X_iX_j)$ I understand that the second one comes from the fact that $X = X_1+X_2+...X_n$ so $X^2 = (X = X_1+X_2+...X_n)(X = X_1+X_2+...X_n)$ which is where the two summations come from. The part I don't understand is how the two methods relate. Can we express the score on a fair die in the form of the second definition, or is the second definition reserved only for indicator r.v.'s ?","My book has two examples of computing $E(X^2)$ Let X be the score on a fair die $E(X^2) = \frac{1}{6}(1^2 + 2^2+3^2+4^2+5^2+6^2)$ Let X be the number of fixed points in a permutation $E(X^2)=\sum_i^nE(X_i)^2 + \sum_{i\neq j}E(X_iX_j)$ I understand that the second one comes from the fact that $X = X_1+X_2+...X_n$ so $X^2 = (X = X_1+X_2+...X_n)(X = X_1+X_2+...X_n)$ which is where the two summations come from. The part I don't understand is how the two methods relate. Can we express the score on a fair die in the form of the second definition, or is the second definition reserved only for indicator r.v.'s ?",,"['probability-theory', 'statistics', 'expectation']"
83,Determining the mode or median in a statistical survey of a continuous variable,Determining the mode or median in a statistical survey of a continuous variable,,"we learned in school that the rule to determine a mode in a statistical distribution of a continuous variable is Mo=Lower boundary of modal classe+(fmo-fb)/(fmo-f before+fmo-f greater) ×class width. Actually, I wasn't  convinced because there is no logical reason for the answer that we get to be the mode. The mode doesn't  necessarily belong to the modal class; it may be any number between the least and greatest variable although it is nearly impossible to have two exactly equal variables of same frequency. So the great question is: is the previous rule really correct and makes sense? Why are we interested in determining the exact mode? Isn't what really matters the modal class? Similarly for the median.","we learned in school that the rule to determine a mode in a statistical distribution of a continuous variable is Mo=Lower boundary of modal classe+(fmo-fb)/(fmo-f before+fmo-f greater) ×class width. Actually, I wasn't  convinced because there is no logical reason for the answer that we get to be the mode. The mode doesn't  necessarily belong to the modal class; it may be any number between the least and greatest variable although it is nearly impossible to have two exactly equal variables of same frequency. So the great question is: is the previous rule really correct and makes sense? Why are we interested in determining the exact mode? Isn't what really matters the modal class? Similarly for the median.",,['statistics']
84,Trivial AP Statistics Problem 2012: Confidence Intervals of a survey,Trivial AP Statistics Problem 2012: Confidence Intervals of a survey,,"I assume that this problem is trivial but I am not sure what to do: In a survey of 900 people in the US a journalist says that 60% of people support a new law. If the margin of error is 2.7% for the percentage, what is the level of confidence?","I assume that this problem is trivial but I am not sure what to do: In a survey of 900 people in the US a journalist says that 60% of people support a new law. If the margin of error is 2.7% for the percentage, what is the level of confidence?",,"['statistics', 'confidence-interval']"
85,Show that $\sum_{j=M}^{\infty}\left(\frac{M}{j}\right)^{a+n} \to 1$ as $n\to \infty$,Show that  as,\sum_{j=M}^{\infty}\left(\frac{M}{j}\right)^{a+n} \to 1 n\to \infty,"Assume this is to be solved under timed conditions. Show that   $\sum_{j=M}^{\infty}\left(\frac{M}{j}\right)^{a+n}  \to 1$ as $n \to \infty$, where $M\geq 1$ is an integer and   $a > 1$ is fixed (not necessarily an integer). I do have a solution available to me, but I'm not a fan of it - essentially, it breaks apart the summation into $1 + \sum_{j=M+1}^{\infty}(M/j)^{a+n}$ and then does some fancy inequality work to show that the resulting summation starting at $j = M + 1$ is less than or equal to some constant not dependent on $n$ times $\left(\dfrac{M}{M+1}\right)^n \to 0$ as $n \to \infty$, hence we get $1^{-1} = 1$ as $n \to \infty$. Long story short, I wouldn't have thought about doing this (particularly the breaking of the summation into two parts). Is there a better, more brute-force method of approaching this that wouldn't involve messing around with inequalities? Note that this was an intermediate step for a question from a grad-level statistics qualifying exam, covering material at the level of Casella and Berger's text.","Assume this is to be solved under timed conditions. Show that   $\sum_{j=M}^{\infty}\left(\frac{M}{j}\right)^{a+n}  \to 1$ as $n \to \infty$, where $M\geq 1$ is an integer and   $a > 1$ is fixed (not necessarily an integer). I do have a solution available to me, but I'm not a fan of it - essentially, it breaks apart the summation into $1 + \sum_{j=M+1}^{\infty}(M/j)^{a+n}$ and then does some fancy inequality work to show that the resulting summation starting at $j = M + 1$ is less than or equal to some constant not dependent on $n$ times $\left(\dfrac{M}{M+1}\right)^n \to 0$ as $n \to \infty$, hence we get $1^{-1} = 1$ as $n \to \infty$. Long story short, I wouldn't have thought about doing this (particularly the breaking of the summation into two parts). Is there a better, more brute-force method of approaching this that wouldn't involve messing around with inequalities? Note that this was an intermediate step for a question from a grad-level statistics qualifying exam, covering material at the level of Casella and Berger's text.",,"['probability', 'sequences-and-series', 'statistics', 'summation']"
86,What is the present value of an annuity consisting of monthly payments of an amount C.,What is the present value of an annuity consisting of monthly payments of an amount C.,,What is the present value of an annuity consisting of monthly payments of an amount C continuing for n years? Express the answer in terms of the effective rate re. I know that the effective rate $re = (1 + \frac {r}{m}) ^ m $. Where m is the amount of payments per year. But apart from that I don't understand how to solve this question.,What is the present value of an annuity consisting of monthly payments of an amount C continuing for n years? Express the answer in terms of the effective rate re. I know that the effective rate $re = (1 + \frac {r}{m}) ^ m $. Where m is the amount of payments per year. But apart from that I don't understand how to solve this question.,,"['statistics', 'finance']"
87,One die is rolled three times,One die is rolled three times,,"One die is rolled three times. What is the probability that you get a strictly increasing sequence of rolls (meaning roll 1 < roll 2 < roll 3)? The total number of possible outcomes is 216. I was shown the answer to this question, but not the steps taken to get the answer. I would like to know how visually, if that makes sense. If it says increasing , it means I can't have, for example: (1 < 4 < 6)? Or does it have to be in order, like: (1 < 2 < 3), (2 < 3 < 4), (4 < 5 < 6)?","One die is rolled three times. What is the probability that you get a strictly increasing sequence of rolls (meaning roll 1 < roll 2 < roll 3)? The total number of possible outcomes is 216. I was shown the answer to this question, but not the steps taken to get the answer. I would like to know how visually, if that makes sense. If it says increasing , it means I can't have, for example: (1 < 4 < 6)? Or does it have to be in order, like: (1 < 2 < 3), (2 < 3 < 4), (4 < 5 < 6)?",,"['probability', 'statistics']"
88,Chi-Squared Hypothesis Testing of Letter Frequency,Chi-Squared Hypothesis Testing of Letter Frequency,,"The hypothesized letter-frequency values below are taken from Pavel Micka's website, which cites Robert Lewand's Cryptological Mathematics. The Actual Appearances were manually obtained upon reading ""A Study in Scarlet"" by Arthur Conan Doyle. Use the Chi-squared statistic to test whether the hypothesized frequencies are correct. This will be a one-tailed test by design. Use a $5\%$ chance of a Type I error. Hypothesized    Actual Letter  Frequency       Appearances  a   0.08167            19890 b   0.01492            1701 c   0.02782            5556 d   0.04253            10578 e   0.12703            29479 f   0.02228            4252 g   0.02015            5601 h   0.06094            8663 i   0.06966            9267 j   0.00153            276 k   0.00772            2244 l   0.04025            9458 m   0.02406            7184 n   0.06749            13765 o   0.07507            16986 p   0.01929            5887 q   0.00095            153 r   0.05987            7984 s   0.06327            11181 t   0.09056            27087 u   0.02758            5277 v   0.00978            3031 w   0.02360            7670 x   0.00150            200 y   0.01974            3396 z   0.00074            159 Attempted Solution: I added each of the actual appearances to get $216{,}925$. Then I multiplied all the hypothesized frequencies by that number. I then used the formula Chi-squared Statistic $= \sum$$(O-E)^2\over{E}$ to get  $14598.17$. The critical value I found from the table was $37.652$, thus rejecting the null hypothesis. I was wondering if I did this correctly. I suspect I did not because of how much larger my Chi-square statistic was than my critical value. Any help would be much appreciated. EDIT: I think I need to square root my chi-square statistic to get $120.8$. That is still a lot bigger than $37.652$, my critical value.","The hypothesized letter-frequency values below are taken from Pavel Micka's website, which cites Robert Lewand's Cryptological Mathematics. The Actual Appearances were manually obtained upon reading ""A Study in Scarlet"" by Arthur Conan Doyle. Use the Chi-squared statistic to test whether the hypothesized frequencies are correct. This will be a one-tailed test by design. Use a $5\%$ chance of a Type I error. Hypothesized    Actual Letter  Frequency       Appearances  a   0.08167            19890 b   0.01492            1701 c   0.02782            5556 d   0.04253            10578 e   0.12703            29479 f   0.02228            4252 g   0.02015            5601 h   0.06094            8663 i   0.06966            9267 j   0.00153            276 k   0.00772            2244 l   0.04025            9458 m   0.02406            7184 n   0.06749            13765 o   0.07507            16986 p   0.01929            5887 q   0.00095            153 r   0.05987            7984 s   0.06327            11181 t   0.09056            27087 u   0.02758            5277 v   0.00978            3031 w   0.02360            7670 x   0.00150            200 y   0.01974            3396 z   0.00074            159 Attempted Solution: I added each of the actual appearances to get $216{,}925$. Then I multiplied all the hypothesized frequencies by that number. I then used the formula Chi-squared Statistic $= \sum$$(O-E)^2\over{E}$ to get  $14598.17$. The critical value I found from the table was $37.652$, thus rejecting the null hypothesis. I was wondering if I did this correctly. I suspect I did not because of how much larger my Chi-square statistic was than my critical value. Any help would be much appreciated. EDIT: I think I need to square root my chi-square statistic to get $120.8$. That is still a lot bigger than $37.652$, my critical value.",,"['statistics', 'hypothesis-testing', 'chi-squared']"
89,P-value of a One-sided One-sample t Test,P-value of a One-sided One-sample t Test,,"John claims that the typical lifetime of a car in his shop with 10 years warranty, is significantly more than 10 years. To test the claim, 9 cars are randomly selected, with lifetimes recorded. Sample mean lifetime is 13.5 years, and sample standard deviation is 3.2 years. Assuming the lifetime has a normal distribution, what conclusion can be drawn at 1% significant level? So I have several tables and formulas here, first I am looking to see if it's a one sample or two sample problem, it's one sample. Then I am looking to see of the sample is large or small, it's small, only 9. Then I am looking to see if the population variance or standard deviation is known, or unknown, and it's unknown. And lastly I am looking for normality, and it's normally distributed. So with this information, I'd assume we're using the T test looking for the mue (population mean) parameter. Which then follows: $H_0: \mu = 10$ $H_a: \mu > 10$ $T = (\bar X - \mu)/(S/\sqrt{n})$ Plugging our values in, I get 3.281 as a T-score. The rejection region is then defined by $T > T_\alpha(\nu)$ where $\nu = n - 1.$ So on the T-table, with degrees 8, and an alpha of .01, this would be the same as the $T > -T_1-\alpha$ so alpha would be now .99, and we can find the T-score of .99 from the table ensuring to make it negative as -2.896. Our P-value would also be $P(T > 3.281).$ Now since our test statistic which is 3.281, is greater than -2.896, it's in the rejection region and we can reject the null hypothesis. Which in turn then, we can also support John's claim. So if I did all this correct, great, but the options I am given for this problem are the following: a. Sufficient evidence at 1% to support the claim, and the p-value is equal to P(T > 3.355). b. Sufficient evidence at 1% to reject the claim, and the p-value is equal to P(T < -3.281). c. Insufficient evidence at 1% to support the claim, and the p-value is equal to P(Z > 2.896). d. Insufficient evidence at 1% to support the claim, and the p-value is equal to P(Z > 2.896). e. None of these answers Is the answer here really e? Did I do everything correct? Already seems kind of a funky question as one answer is repeated and we're not even using Z. And the answer could be a. but that t-score is if the alpha level was 0.005, and we have an alpha of 0.01, and it's not a two tail test, it's a one tail test. And then b. is wrong because it's not negative nor <.","John claims that the typical lifetime of a car in his shop with 10 years warranty, is significantly more than 10 years. To test the claim, 9 cars are randomly selected, with lifetimes recorded. Sample mean lifetime is 13.5 years, and sample standard deviation is 3.2 years. Assuming the lifetime has a normal distribution, what conclusion can be drawn at 1% significant level? So I have several tables and formulas here, first I am looking to see if it's a one sample or two sample problem, it's one sample. Then I am looking to see of the sample is large or small, it's small, only 9. Then I am looking to see if the population variance or standard deviation is known, or unknown, and it's unknown. And lastly I am looking for normality, and it's normally distributed. So with this information, I'd assume we're using the T test looking for the mue (population mean) parameter. Which then follows: $H_0: \mu = 10$ $H_a: \mu > 10$ $T = (\bar X - \mu)/(S/\sqrt{n})$ Plugging our values in, I get 3.281 as a T-score. The rejection region is then defined by $T > T_\alpha(\nu)$ where $\nu = n - 1.$ So on the T-table, with degrees 8, and an alpha of .01, this would be the same as the $T > -T_1-\alpha$ so alpha would be now .99, and we can find the T-score of .99 from the table ensuring to make it negative as -2.896. Our P-value would also be $P(T > 3.281).$ Now since our test statistic which is 3.281, is greater than -2.896, it's in the rejection region and we can reject the null hypothesis. Which in turn then, we can also support John's claim. So if I did all this correct, great, but the options I am given for this problem are the following: a. Sufficient evidence at 1% to support the claim, and the p-value is equal to P(T > 3.355). b. Sufficient evidence at 1% to reject the claim, and the p-value is equal to P(T < -3.281). c. Insufficient evidence at 1% to support the claim, and the p-value is equal to P(Z > 2.896). d. Insufficient evidence at 1% to support the claim, and the p-value is equal to P(Z > 2.896). e. None of these answers Is the answer here really e? Did I do everything correct? Already seems kind of a funky question as one answer is repeated and we're not even using Z. And the answer could be a. but that t-score is if the alpha level was 0.005, and we have an alpha of 0.01, and it's not a two tail test, it's a one tail test. And then b. is wrong because it's not negative nor <.",,"['statistics', 'statistical-inference', 'hypothesis-testing']"
90,Expected Mean Squares for Two Factor Experiments,Expected Mean Squares for Two Factor Experiments,,"I am looking at two-factor experiments with fixed factors. I've seen that for MSE, the expected value is $\sigma^2$. For E(MSA), E(MSB), and E(MSAB) I think these will be linear combinations of $\sigma^2$ such as $\sigma^2$+ something. How can I go about finding these? Research: I found for one-way ANOVA that E(MSE) can be obtained by dividing SSE by its' degrees of freedom and denoting it as a chi-square random variable. Can this be done in two-way ANOVA and if so, would it work for the factors MSA, MSB, and MSE?","I am looking at two-factor experiments with fixed factors. I've seen that for MSE, the expected value is $\sigma^2$. For E(MSA), E(MSB), and E(MSAB) I think these will be linear combinations of $\sigma^2$ such as $\sigma^2$+ something. How can I go about finding these? Research: I found for one-way ANOVA that E(MSE) can be obtained by dividing SSE by its' degrees of freedom and denoting it as a chi-square random variable. Can this be done in two-way ANOVA and if so, would it work for the factors MSA, MSB, and MSE?",,['statistics']
91,For what value of $w$ is $(1-w)\bar X_1 + w\bar X_2$ the minimum variance unbiased estimator of $\mu$,For what value of  is  the minimum variance unbiased estimator of,w (1-w)\bar X_1 + w\bar X_2 \mu,"Let $\bar X_1$ and $\bar X_2$ be the means of two independent samples of sizes $n$ and $2n$ from an infinite population that has mean $\mu$ and variance $\sigma^2 \gt 0$. For what value of $w$ is $(1-w)\bar X_1 + w\bar X_2$ the minimum variance unbiased estimator of $\mu$ ? I first wrote that I need to show $$E[(1-w)\bar X_1 + w\bar X_2] = \mu \qquad (1)$$ and that $$Var[(1-w)\bar X_1 + w\bar X_2] = \frac{1}{E\left[\left(\frac{d\ell(\theta)}{d\theta}\right)^2\right]} \qquad (2) $$ And then I will have shown that my parameter is a minimum variance unbiased estimator. First problem I see is that I don't know the probability distribution of this sample, so does that mean I can't find the log-likelihood function and by extension, can't find the R.H.S of (2)? Also, the question states that the population size is inifite. Does this mean that $E[X_i] = \mu$ ? Where $X_i$ is the sample mean from any population. Even if this is true, does it help me? I tried expanding (1) with the premise that $E[X_i] = \mu$ but i only got this: $$ E[(1-w)\bar X_1 + w\bar X_2] = \mu $$ $$ (1-w)E[\bar X_1] + wE[\bar X_2] = \mu $$ $$ (1-w)\mu + w\mu = \mu $$ $$ 1-w+w = 1 $$ $$ \text{trivial...}$$ Is my thought process wrong here? Is there another way to determine whether something is a minimum variance unbiased estimator?","Let $\bar X_1$ and $\bar X_2$ be the means of two independent samples of sizes $n$ and $2n$ from an infinite population that has mean $\mu$ and variance $\sigma^2 \gt 0$. For what value of $w$ is $(1-w)\bar X_1 + w\bar X_2$ the minimum variance unbiased estimator of $\mu$ ? I first wrote that I need to show $$E[(1-w)\bar X_1 + w\bar X_2] = \mu \qquad (1)$$ and that $$Var[(1-w)\bar X_1 + w\bar X_2] = \frac{1}{E\left[\left(\frac{d\ell(\theta)}{d\theta}\right)^2\right]} \qquad (2) $$ And then I will have shown that my parameter is a minimum variance unbiased estimator. First problem I see is that I don't know the probability distribution of this sample, so does that mean I can't find the log-likelihood function and by extension, can't find the R.H.S of (2)? Also, the question states that the population size is inifite. Does this mean that $E[X_i] = \mu$ ? Where $X_i$ is the sample mean from any population. Even if this is true, does it help me? I tried expanding (1) with the premise that $E[X_i] = \mu$ but i only got this: $$ E[(1-w)\bar X_1 + w\bar X_2] = \mu $$ $$ (1-w)E[\bar X_1] + wE[\bar X_2] = \mu $$ $$ (1-w)\mu + w\mu = \mu $$ $$ 1-w+w = 1 $$ $$ \text{trivial...}$$ Is my thought process wrong here? Is there another way to determine whether something is a minimum variance unbiased estimator?",,"['statistics', 'statistical-inference']"
92,Determining a value $k$ that gives a size = 0.05 test.,Determining a value  that gives a size = 0.05 test.,k,"A single observation $X$ from a normal distribution with mean $\mu$ and $\sigma^2$ =1 is used to test $$H_0 : \mu = 1 \ \ \ \text{vs} \ \ \ H_1 : \mu \lt 1 $$ using the critical region $C = {{x : x \lt k}}$ Determine the value of k that gives a size 0.05 test. My attempt: The size of the test = significance level = $\alpha$ = 0.05 From my notes, I am told $\alpha = \pi(H_0)$ , where $\pi$ signifies the power function. The only thing I could think of that might link these together is the z-score formula. $$ Z_{0.05} = 1.65 $$ $$ 1.65 = \frac{\bar x - 1}{1} $$ However this doesn't make sense to me, as when I solve for $\bar x$ I get 2.65, which is greater than $\mu$ , and this region should be less than $\mu$ Am I supposed to derive the power function for $\mu$ myself?","A single observation from a normal distribution with mean and =1 is used to test using the critical region Determine the value of k that gives a size 0.05 test. My attempt: The size of the test = significance level = = 0.05 From my notes, I am told , where signifies the power function. The only thing I could think of that might link these together is the z-score formula. However this doesn't make sense to me, as when I solve for I get 2.65, which is greater than , and this region should be less than Am I supposed to derive the power function for myself?",X \mu \sigma^2 H_0 : \mu = 1 \ \ \ \text{vs} \ \ \ H_1 : \mu \lt 1  C = {{x : x \lt k}} \alpha \alpha = \pi(H_0) \pi  Z_{0.05} = 1.65   1.65 = \frac{\bar x - 1}{1}  \bar x \mu \mu \mu,['statistics']
93,Sum of $X\sim\chi^2_ \nu$ and $Y\sim\chi^2_ k$ and gamma function,Sum of  and  and gamma function,X\sim\chi^2_ \nu Y\sim\chi^2_ k,"Suppose $X\sim\chi^2_ \nu$ and $Y\sim\chi^2_ k$ are independent. (a) Show that $X+Y\sim\chi^2_{\nu+k}.$ (b) Additionally, find the value of $$\int_0^1u^{\frac{\nu}{2}-1}(1-u)^{\frac{k}{2}-1}du$$ as a ratio of Gamma functions. This formula was discovered by Euler. I was able to solve part (a) and this is my result. Proof: If $X$ is $\chi^2_\nu$ distributed then we can express $X$ as $X=A_1^2+\cdots+A_\nu^2$ where $A_1,\ldots,A_\nu$ are $N(0,1)$. Similarly, if $Y$ is $\chi^2_k$ distributed then we can express $Y$ as $Y=B_1^2+\cdots+B_k^2$ where $B_1,\ldots,B_k$ are $N(0,1)$. These two statements can be made due to the definition of $\chi_\nu^2$ with $\nu$ degrees of freedom. Now, we know that the sum of two independent random variables preserves independence, therefore, adding $X+Y$ we obtain  $$X+Y=A_1^2+B_1^2+\cdots+A^2_\nu+B_k^2$$ We can conclude that $$X+Y \sim \chi^2_{\nu+k}$$ However, I am uncertain as to how to compute (b). I have seen and computed Gamma integrals but they have been in the conventional form with an exponential term and $1$ variable. This integrals contains $2$ variables and so I am uncertain how to go about it.","Suppose $X\sim\chi^2_ \nu$ and $Y\sim\chi^2_ k$ are independent. (a) Show that $X+Y\sim\chi^2_{\nu+k}.$ (b) Additionally, find the value of $$\int_0^1u^{\frac{\nu}{2}-1}(1-u)^{\frac{k}{2}-1}du$$ as a ratio of Gamma functions. This formula was discovered by Euler. I was able to solve part (a) and this is my result. Proof: If $X$ is $\chi^2_\nu$ distributed then we can express $X$ as $X=A_1^2+\cdots+A_\nu^2$ where $A_1,\ldots,A_\nu$ are $N(0,1)$. Similarly, if $Y$ is $\chi^2_k$ distributed then we can express $Y$ as $Y=B_1^2+\cdots+B_k^2$ where $B_1,\ldots,B_k$ are $N(0,1)$. These two statements can be made due to the definition of $\chi_\nu^2$ with $\nu$ degrees of freedom. Now, we know that the sum of two independent random variables preserves independence, therefore, adding $X+Y$ we obtain  $$X+Y=A_1^2+B_1^2+\cdots+A^2_\nu+B_k^2$$ We can conclude that $$X+Y \sim \chi^2_{\nu+k}$$ However, I am uncertain as to how to compute (b). I have seen and computed Gamma integrals but they have been in the conventional form with an exponential term and $1$ variable. This integrals contains $2$ variables and so I am uncertain how to go about it.",,"['probability', 'statistics']"
94,Number of observations needed to distinguish two known distributions with p-confidence,Number of observations needed to distinguish two known distributions with p-confidence,,"I have a 1-length cube.   $N$ spots are located in the cube according to the one of known distributions: $f(x,y,z) = 1$ $g(r) = k\ exp(-2\ r^2)$ (where $k$ is a normalization constant and $r= \sqrt{x^2 +y^2+z^2 }$) Problem: How many points, $N$, do I need to distinguish these distributions with $p = 90\%$ confidence? Is it enough to consider not the whole cube, but just a quarter of sphere inside it? (Because it's difficult to transform $f$ to sphere coordinates in cube, but easy in sphere) What exactly is the probability here? Do I have to use statistical tests?","I have a 1-length cube.   $N$ spots are located in the cube according to the one of known distributions: $f(x,y,z) = 1$ $g(r) = k\ exp(-2\ r^2)$ (where $k$ is a normalization constant and $r= \sqrt{x^2 +y^2+z^2 }$) Problem: How many points, $N$, do I need to distinguish these distributions with $p = 90\%$ confidence? Is it enough to consider not the whole cube, but just a quarter of sphere inside it? (Because it's difficult to transform $f$ to sphere coordinates in cube, but easy in sphere) What exactly is the probability here? Do I have to use statistical tests?",,"['statistics', 'probability-distributions']"
95,How to derive the cdf of given function,How to derive the cdf of given function,,Let $$Y = \frac{X_1+X_2+\cdots+X_{100}}{100}$$ I understand that the Central Limit Theorem says you can approximate Y. But by what random variable? And how can I write the cumulative distribution function of this random variable? I am confused on how to derive the CDF. Do I need to find the PDF first?,Let $$Y = \frac{X_1+X_2+\cdots+X_{100}}{100}$$ I understand that the Central Limit Theorem says you can approximate Y. But by what random variable? And how can I write the cumulative distribution function of this random variable? I am confused on how to derive the CDF. Do I need to find the PDF first?,,"['statistics', 'central-limit-theorem']"
96,Probability of Dice,Probability of Dice,,"Q) If 20 fair dice are rolled, then the probability that the sum obtained is between 30 and 40 is 0.325. True or False? A) So far I have that $ \mu = \frac{7}{2}$ and $ \sigma^2 = \frac{35}{12} $. So for 20 rolls $ \mu = 20 \times \frac{7}{2} $ and $\sigma^2 = 20 \times \frac{35}{12}$. So using the continuity correction we have $ \frac{29.5-\mu}{\sigma}\leq z \leq \frac{40.5-\mu}{\sigma}$. However, this gives the probability equal to $0.0001$ using the normal distribution tables. I don't know if what I have done is right and the statement is false or if I have made a mistake somewhere. Thanks for the help!","Q) If 20 fair dice are rolled, then the probability that the sum obtained is between 30 and 40 is 0.325. True or False? A) So far I have that $ \mu = \frac{7}{2}$ and $ \sigma^2 = \frac{35}{12} $. So for 20 rolls $ \mu = 20 \times \frac{7}{2} $ and $\sigma^2 = 20 \times \frac{35}{12}$. So using the continuity correction we have $ \frac{29.5-\mu}{\sigma}\leq z \leq \frac{40.5-\mu}{\sigma}$. However, this gives the probability equal to $0.0001$ using the normal distribution tables. I don't know if what I have done is right and the statement is false or if I have made a mistake somewhere. Thanks for the help!",,"['probability', 'statistics', 'summation', 'dice']"
97,How to apply the Empirical Rule to find the percentage?,How to apply the Empirical Rule to find the percentage?,,"So I am working on this question but I don't know how to apply the Empirical Rule. Question: A Cornell University researcher measured the mouth volumes of a large number of men and women and reported that the distribution of the mouth volumes for men is approximately bell-shaped with a mean of 66 cc and a standard deviation of 17 cc. Moreover, the distribution of the mouth volumes for women is also approximately bell-shaped with a mean of 54 cc and a standard deviation of 14.5 cc. a) Applying the Empirical Rule, what percentage of man has mouth volume over 100 cc or less than 49 cc? Now this is what I did. 100-66=34 which is 2(17). Thus, 100 is 2 standard deviation to the right of the mean. 66-49=17 which is 1(17). Thus, 17 is 1 standard deviation below the mean From here, I don't know which formula to apply to get the percentage that I did for this question. So can someone help me solve this. Thank you.","So I am working on this question but I don't know how to apply the Empirical Rule. Question: A Cornell University researcher measured the mouth volumes of a large number of men and women and reported that the distribution of the mouth volumes for men is approximately bell-shaped with a mean of 66 cc and a standard deviation of 17 cc. Moreover, the distribution of the mouth volumes for women is also approximately bell-shaped with a mean of 54 cc and a standard deviation of 14.5 cc. a) Applying the Empirical Rule, what percentage of man has mouth volume over 100 cc or less than 49 cc? Now this is what I did. 100-66=34 which is 2(17). Thus, 100 is 2 standard deviation to the right of the mean. 66-49=17 which is 1(17). Thus, 17 is 1 standard deviation below the mean From here, I don't know which formula to apply to get the percentage that I did for this question. So can someone help me solve this. Thank you.",,"['statistics', 'standard-deviation', 'means', 'confidence-interval']"
98,Gamma distribution and probability less then expected value?,Gamma distribution and probability less then expected value?,,"Let $X\sim \operatorname{Gamma}(\alpha = 7, \beta)$, then $P(X > E(X))$ is: A) 0.35 B) 0.45 C) 0.55 D) 0.65 The answer is 0.45. This is what I have so far: $E(X)=\alpha\beta$ so I want $P(X > \alpha \beta)$, $\alpha=7$ so I can use the table for this if I divide by beta, but I don't have beta's original value. From the table I'm deducting that $X=7$.. My main question is, when I divide by $\beta$, am I also dividing the mean and variance by Beta? if that's the actual case I'm guessing $$P(X > E(X))= P(X > 7)$$ which then would make sense since $\alpha$ and $x$ are both 7. So is this the general rule when dividing by beta to make it equal to 1 to use the tables? Thank you!!! sorry for the rather lengthy question","Let $X\sim \operatorname{Gamma}(\alpha = 7, \beta)$, then $P(X > E(X))$ is: A) 0.35 B) 0.45 C) 0.55 D) 0.65 The answer is 0.45. This is what I have so far: $E(X)=\alpha\beta$ so I want $P(X > \alpha \beta)$, $\alpha=7$ so I can use the table for this if I divide by beta, but I don't have beta's original value. From the table I'm deducting that $X=7$.. My main question is, when I divide by $\beta$, am I also dividing the mean and variance by Beta? if that's the actual case I'm guessing $$P(X > E(X))= P(X > 7)$$ which then would make sense since $\alpha$ and $x$ are both 7. So is this the general rule when dividing by beta to make it equal to 1 to use the tables? Thank you!!! sorry for the rather lengthy question",,"['probability', 'statistics', 'means', 'gamma-distribution']"
99,Conditional Expectation Problem?,Conditional Expectation Problem?,,"An insurance company supposes that the number of accidents that each of its customers will have this year is Poisson distributed, with a mean depending on the customer: the Poisson mean $\Lambda$ of a randomly chosen person has a Gamma distribution with the $\Gamma(2, 1)$-density function $f_\Lambda(\lambda) = \lambda e^{−\lambda}$, $(\lambda > 0)$. Find the expected value of $\Lambda$ for a policyholder having $x$ accidents this year $(x = 0, 1, 2 \ldots)$? Not quite sure how to start this, I was thinking it's $\mathbb E[\Lambda|X=x]$, but I can't find any documentation on how conditional expectation is solved when the distributions aren't both discrete or both continuous.","An insurance company supposes that the number of accidents that each of its customers will have this year is Poisson distributed, with a mean depending on the customer: the Poisson mean $\Lambda$ of a randomly chosen person has a Gamma distribution with the $\Gamma(2, 1)$-density function $f_\Lambda(\lambda) = \lambda e^{−\lambda}$, $(\lambda > 0)$. Find the expected value of $\Lambda$ for a policyholder having $x$ accidents this year $(x = 0, 1, 2 \ldots)$? Not quite sure how to start this, I was thinking it's $\mathbb E[\Lambda|X=x]$, but I can't find any documentation on how conditional expectation is solved when the distributions aren't both discrete or both continuous.",,"['probability', 'statistics']"
