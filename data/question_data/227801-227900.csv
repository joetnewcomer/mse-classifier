,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Unique line in $\mathbb{P}^3$ through a point $p$ and intersecting two disjoint lines,Unique line in  through a point  and intersecting two disjoint lines,\mathbb{P}^3 p,"I'm a bit stuck with this exercise from a script I'm reading, and I'm not very familiar with projective $n$-space yet. The problem: Let $L_1$ and $L_2$ be two disjoint lines in $\mathbb{P}^3$, and let $p\in\mathbb{P}^3\smallsetminus(L_1\cup L_2)$. Show that there is a unique line $L\subseteq\mathbb{P}^3$ meeting $L_1$, $L_2$, and $p$ (i.e. such that $p\in L$ and $L\cap L_i\neq\varnothing$ for $i=1,2$). To be honest, I already have a problem with the term 'line'. As I take it, a line in $\mathbb{P}^3$ should be something cut out by two degree-1 polynomials (homogeneous, since it wouldn't be well defined otherwise, right?). But what are disjoint lines in projective space? As far as I understood it, two distinct lines should always intersect in exactly one point there, so how can they be disjoint? Can it be that these two statements mean a different kind of 'line'? Any explanation of this, hints, or even a solution would be very appreciated. Thanks in advance!","I'm a bit stuck with this exercise from a script I'm reading, and I'm not very familiar with projective $n$-space yet. The problem: Let $L_1$ and $L_2$ be two disjoint lines in $\mathbb{P}^3$, and let $p\in\mathbb{P}^3\smallsetminus(L_1\cup L_2)$. Show that there is a unique line $L\subseteq\mathbb{P}^3$ meeting $L_1$, $L_2$, and $p$ (i.e. such that $p\in L$ and $L\cap L_i\neq\varnothing$ for $i=1,2$). To be honest, I already have a problem with the term 'line'. As I take it, a line in $\mathbb{P}^3$ should be something cut out by two degree-1 polynomials (homogeneous, since it wouldn't be well defined otherwise, right?). But what are disjoint lines in projective space? As far as I understood it, two distinct lines should always intersect in exactly one point there, so how can they be disjoint? Can it be that these two statements mean a different kind of 'line'? Any explanation of this, hints, or even a solution would be very appreciated. Thanks in advance!",,"['algebraic-geometry', 'projective-space']"
1,Is it faster to count to the infinite going one by one or two by two? [closed],Is it faster to count to the infinite going one by one or two by two? [closed],,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 10 years ago . Improve this question A child asked me this question yesterday: Would it be faster to count to the infinite going one by one or two by two ? And I was split with two answers: In both case it will take an infinite time. Skipping half of the number should be really faster. Which brings me this question: Could an infinite be greater than another one?,Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 10 years ago . Improve this question A child asked me this question yesterday: Would it be faster to count to the infinite going one by one or two by two ? And I was split with two answers: In both case it will take an infinite time. Skipping half of the number should be really faster. Which brings me this question: Could an infinite be greater than another one?,,['elementary-set-theory']
2,What Does it Really Mean to Have Different Kinds of Infinities?,What Does it Really Mean to Have Different Kinds of Infinities?,,"Can someone explain to me how there can be different kinds of infinities? I was reading "" The man who loved only numbers "" by Paul Hoffman and came across the concept of countable and uncountable infinities, but they're only words to me. Any help would be appreciated.","Can someone explain to me how there can be different kinds of infinities? I was reading "" The man who loved only numbers "" by Paul Hoffman and came across the concept of countable and uncountable infinities, but they're only words to me. Any help would be appreciated.",,"['elementary-set-theory', 'intuition', 'infinity', 'faq']"
3,Are there real-life relations which are symmetric and reflexive but not transitive?,Are there real-life relations which are symmetric and reflexive but not transitive?,,"Inspired by Halmos ( Naive Set Theory ) . . . For each of these three possible properties [reflexivity, symmetry, and transitivity], find a relation that does not have that property but does have the other two. One can construct each of these relations and, in particular, a relation that is symmetric and reflexive but not transitive: $$R=\{(a,a),(a,b),(b,a),(b,b),(c,c),(b,c),(c,b)\}.$$ It is clearly not transitive since $(a,b)\in R$ and $(b,c)\in R$ whilst $(a,c)\notin R$ . On the other hand, it is reflexive since $(x,x)\in R$ for all cases of $x$ : $x=a$ , $x=b$ , and $x=c$ . Likewise, it is symmetric since $(a,b)\in R$ and $(b,a)\in R$ and $(b,c)\in R$ and $(c,b)\in R$ . However, this doesn't satisfy me. Are there real-life examples of $R$ ? In this question, I am asking if there are tangible and not directly mathematical examples of $R$ : a relation that is reflexive and symmetric, but not transitive. For example, when dealing with relations which are symmetric, we could say that $R$ is equivalent to being married. Another common example is ancestry. If $xRy$ means $x$ is an ancestor of $y$ , $R$ is transitive but neither symmetric nor reflexive. I would like to see an example along these lines within the answer. Thank you.","Inspired by Halmos ( Naive Set Theory ) . . . For each of these three possible properties [reflexivity, symmetry, and transitivity], find a relation that does not have that property but does have the other two. One can construct each of these relations and, in particular, a relation that is symmetric and reflexive but not transitive: It is clearly not transitive since and whilst . On the other hand, it is reflexive since for all cases of : , , and . Likewise, it is symmetric since and and and . However, this doesn't satisfy me. Are there real-life examples of ? In this question, I am asking if there are tangible and not directly mathematical examples of : a relation that is reflexive and symmetric, but not transitive. For example, when dealing with relations which are symmetric, we could say that is equivalent to being married. Another common example is ancestry. If means is an ancestor of , is transitive but neither symmetric nor reflexive. I would like to see an example along these lines within the answer. Thank you.","R=\{(a,a),(a,b),(b,a),(b,b),(c,c),(b,c),(c,b)\}. (a,b)\in R (b,c)\in R (a,c)\notin R (x,x)\in R x x=a x=b x=c (a,b)\in R (b,a)\in R (b,c)\in R (c,b)\in R R R R xRy x y R","['elementary-set-theory', 'relations']"
4,lim sup and lim inf of sequence of sets.,lim sup and lim inf of sequence of sets.,,I was wondering if someone would be so kind to provide a very simple explanation of $\limsup$ and $\liminf$ of a sequence of sets. For a sequence of subsets $A_n$ of a set $X$ we have $$\limsup A_n= \bigcap_{N=1}^\infty \left( \bigcup_{n\ge N} A_n \right)$$ and $$\liminf A_n = \bigcup_{N=1}^\infty \left(\bigcap_{n \ge N} A_n\right).$$ But I am having a hard time imagining what that really means unions of intersections and intersections of unions I think maybe causing the trouble. I read the version on Wikipedia but that didn't resolve this either. Any help would be much appreciated.,I was wondering if someone would be so kind to provide a very simple explanation of and of a sequence of sets. For a sequence of subsets of a set we have and But I am having a hard time imagining what that really means unions of intersections and intersections of unions I think maybe causing the trouble. I read the version on Wikipedia but that didn't resolve this either. Any help would be much appreciated.,\limsup \liminf A_n X \limsup A_n= \bigcap_{N=1}^\infty \left( \bigcup_{n\ge N} A_n \right) \liminf A_n = \bigcup_{N=1}^\infty \left(\bigcap_{n \ge N} A_n\right).,"['elementary-set-theory', 'limsup-and-liminf']"
5,Produce an explicit bijection between rationals and naturals,Produce an explicit bijection between rationals and naturals,,"I remember my professor in college challenging me with this question, which I failed to answer satisfactorily: I know there exists a bijection between the rational numbers and the natural numbers, but can anyone produce an explicit formula for such a bijection?","I remember my professor in college challenging me with this question, which I failed to answer satisfactorily: I know there exists a bijection between the rational numbers and the natural numbers, but can anyone produce an explicit formula for such a bijection?",,"['elementary-set-theory', 'rational-numbers', 'natural-numbers']"
6,"What are the differences between class, set, family, and collection?","What are the differences between class, set, family, and collection?",,"In school, I have always seen sets. I was watching a video the other day about functors, and they started talking about a set being a collection, but not vice-versa. I also heard people talking about classes. What is their relation? Some background would be nice. It has to do with something called Russell's paradox, but I don't know what that is. I think that the difference between a family and a set is that the former is a function and the latter is a set. Is this right?","In school, I have always seen sets. I was watching a video the other day about functors, and they started talking about a set being a collection, but not vice-versa. I also heard people talking about classes. What is their relation? Some background would be nice. It has to do with something called Russell's paradox, but I don't know what that is. I think that the difference between a family and a set is that the former is a function and the latter is a set. Is this right?",,"['elementary-set-theory', 'terminology', 'definition', 'paradoxes']"
7,Show that the set of all finite subsets of $\mathbb{N}$ is countable.,Show that the set of all finite subsets of  is countable.,\mathbb{N},"Show that the set of all finite subsets of $\mathbb{N}$ is countable. I'm not sure how to do this problem. I keep trying to think of an explicit formula for 1-1 correspondence like adding all the elements in each subset and sending that sum to itself in the natural numbers, but that wouldn't be 1-1 because, for example, the set {1,2,3} would send to 6 and so would the set {2,4}.  Multiplying all the elements in each subset and sending that product to itself in the natural numbers wouldn't work either since, for example, {2,3} would send to 5 and so would the set {1,5}. Any ideas?","Show that the set of all finite subsets of $\mathbb{N}$ is countable. I'm not sure how to do this problem. I keep trying to think of an explicit formula for 1-1 correspondence like adding all the elements in each subset and sending that sum to itself in the natural numbers, but that wouldn't be 1-1 because, for example, the set {1,2,3} would send to 6 and so would the set {2,4}.  Multiplying all the elements in each subset and sending that product to itself in the natural numbers wouldn't work either since, for example, {2,3} would send to 5 and so would the set {1,5}. Any ideas?",,['elementary-set-theory']
8,Does mathematics become circular at the bottom? What is at the bottom of mathematics? [duplicate],Does mathematics become circular at the bottom? What is at the bottom of mathematics? [duplicate],,"This question already has answers here : When does the set enter set theory? (7 answers) Closed 8 years ago . I am trying to understand what mathematics is really built up of. I thought mathematical logic was the foundation of everything. But from reading a book in mathematical logic, they use ""=""(equals-sign), functions and relations. Now is the ""="" taken as undefined? I have seen it been defined in terms of the identity relation. But in order to talk about functions and relations you need set theory.  However, set theory seems to be a part of mathematical logic. Does this mean that (naive) set theory comes before sentential and predicate logic? Is (naive)set-theory at the absolute bottom, where we can define relations and functions and the eqality relation. And then comes sentential logic, and then predicate logic? I am a little confused because when I took an introductory course, we had a little logic before set-theory. But now I see in another book on introduction to proofs that set-theory is in a chapter before logic. So what is at the bottom/start of mathematics, logic or set theory?, or is it circular at the bottom? Can this be how it is at the bottom? naive set-theory $\rightarrow$ sentential logic $\rightarrow $ predicate logic $\rightarrow$ axiomatic set-theory(ZFC) $\rightarrow$ mathematics (But the problem with this explanation is that it seems that some naive-set theory proofs use logic...) (The arrows are of course not ""logical"" arrows.) simple explanation of the problem: a book on logic uses at the start : functions, relations, sets, ordered pairs, ""="" a book on set theory uses at the start: logical deductions like this: ""$B \subseteq A$"", means every element in B is in A, so if $C \subseteq B, B \subseteq A$, a proof can be ""since every element in C is in B, and every element in B is in A, every element of C is in A: $C \subseteq A$"". But this is first order logic? ($(c \rightarrow b \wedge b \rightarrow a)\rightarrow (c\rightarrow a)$). Hence, both started from each other?","This question already has answers here : When does the set enter set theory? (7 answers) Closed 8 years ago . I am trying to understand what mathematics is really built up of. I thought mathematical logic was the foundation of everything. But from reading a book in mathematical logic, they use ""=""(equals-sign), functions and relations. Now is the ""="" taken as undefined? I have seen it been defined in terms of the identity relation. But in order to talk about functions and relations you need set theory.  However, set theory seems to be a part of mathematical logic. Does this mean that (naive) set theory comes before sentential and predicate logic? Is (naive)set-theory at the absolute bottom, where we can define relations and functions and the eqality relation. And then comes sentential logic, and then predicate logic? I am a little confused because when I took an introductory course, we had a little logic before set-theory. But now I see in another book on introduction to proofs that set-theory is in a chapter before logic. So what is at the bottom/start of mathematics, logic or set theory?, or is it circular at the bottom? Can this be how it is at the bottom? naive set-theory $\rightarrow$ sentential logic $\rightarrow $ predicate logic $\rightarrow$ axiomatic set-theory(ZFC) $\rightarrow$ mathematics (But the problem with this explanation is that it seems that some naive-set theory proofs use logic...) (The arrows are of course not ""logical"" arrows.) simple explanation of the problem: a book on logic uses at the start : functions, relations, sets, ordered pairs, ""="" a book on set theory uses at the start: logical deductions like this: ""$B \subseteq A$"", means every element in B is in A, so if $C \subseteq B, B \subseteq A$, a proof can be ""since every element in C is in B, and every element in B is in A, every element of C is in A: $C \subseteq A$"". But this is first order logic? ($(c \rightarrow b \wedge b \rightarrow a)\rightarrow (c\rightarrow a)$). Hence, both started from each other?",,"['elementary-set-theory', 'logic', 'foundations']"
9,Where are the axioms?,Where are the axioms?,,"It is said that our current basis for mathematics are the ZFC-axioms. Question: Where are these axioms in our mathematics? When do we use them? I have now studied math for a year, and have yet to run into a single one of these ZFC axioms. How can this be if they are supposed to be the basis for everything I have done so far?","It is said that our current basis for mathematics are the ZFC-axioms. Question: Where are these axioms in our mathematics? When do we use them? I have now studied math for a year, and have yet to run into a single one of these ZFC axioms. How can this be if they are supposed to be the basis for everything I have done so far?",,"['elementary-set-theory', 'logic', 'definition', 'axioms', 'foundations']"
10,Why isn't reflexivity redundant in the definition of equivalence relation?,Why isn't reflexivity redundant in the definition of equivalence relation?,,"An equivalence relation is defined by three properties: reflexivity, symmetry and transitivity. Doesn't symmetry and transitivity implies reflexivity? Consider the following argument. For any $a$ and $b$, $a R b$ implies $b R a$ by symmetry. Using transitivity, we have $a R a$. Source: Exercise 8.46, P195 of Mathematical Proofs , 2nd (not 3rd) ed. by Chartrand et al","An equivalence relation is defined by three properties: reflexivity, symmetry and transitivity. Doesn't symmetry and transitivity implies reflexivity? Consider the following argument. For any $a$ and $b$, $a R b$ implies $b R a$ by symmetry. Using transitivity, we have $a R a$. Source: Exercise 8.46, P195 of Mathematical Proofs , 2nd (not 3rd) ed. by Chartrand et al",,"['elementary-set-theory', 'relations', 'equivalence-relations']"
11,How do we know that Cantor's diagonalization isn't creating a different decimal of the same number?,How do we know that Cantor's diagonalization isn't creating a different decimal of the same number?,,"Edit: As the comments mention, I misunderstood how to use the diagonalization method. However, the issue I'm trying to understand is a potential problem with diagonalization and it is addressed in the answers so I will not delete the question. Cantor's diagonalization is a way of creating a unique number given a countable list of all reals. I can see how Cantor's method creates a unique decimal string but I'm unsure if this decimal string corresponds to a unique number. Essentially this is because $1 = 0.\overline{999}$. Consider the list which contains all real numbers between $0$ and $1$: $0.5000 \mathord\ldots \\ 0.4586 \mathord\ldots \\ 0.3912 \mathord\ldots \\ 0.3195 \mathord\ldots \\ 0.7719 \mathord\ldots\\ \vdots$ The start of this list produces a new number which to four decimal places is: $0.4999 \mathord\ldots$ But $0.5$ was the first number and $0.4\overline{999} = 0.5$ so this hasn't produced a unique number. Of course my list is very contrived, I admit that it's hard to imagine a list of the reals where numbers would align nicely to give a problem like this (since some numbers have no nines). However, I can't see a good reason why such an enumeration of numbers would be impossible.","Edit: As the comments mention, I misunderstood how to use the diagonalization method. However, the issue I'm trying to understand is a potential problem with diagonalization and it is addressed in the answers so I will not delete the question. Cantor's diagonalization is a way of creating a unique number given a countable list of all reals. I can see how Cantor's method creates a unique decimal string but I'm unsure if this decimal string corresponds to a unique number. Essentially this is because $1 = 0.\overline{999}$. Consider the list which contains all real numbers between $0$ and $1$: $0.5000 \mathord\ldots \\ 0.4586 \mathord\ldots \\ 0.3912 \mathord\ldots \\ 0.3195 \mathord\ldots \\ 0.7719 \mathord\ldots\\ \vdots$ The start of this list produces a new number which to four decimal places is: $0.4999 \mathord\ldots$ But $0.5$ was the first number and $0.4\overline{999} = 0.5$ so this hasn't produced a unique number. Of course my list is very contrived, I admit that it's hard to imagine a list of the reals where numbers would align nicely to give a problem like this (since some numbers have no nines). However, I can't see a good reason why such an enumeration of numbers would be impossible.",,"['elementary-set-theory', 'decimal-expansion']"
12,How does Cantor's diagonal argument work?,How does Cantor's diagonal argument work?,,"I'm having trouble understanding Cantor's diagonal argument.  Specifically, I do not understand how it proves that something is ""uncountable"".  My understanding of the argument is that it takes the following form (modified slightly from the wikipedia article, assuming base 2, where the numbers must be from the set $ \lbrace 0,1 \rbrace $ ): \begin{align} s_1 &= (\mathbf{0},1,0,\dots)\\ s_2 &= (1,\mathbf{1},0,\dots)\\ s_3 &= (0,0,\mathbf{1},\dots)\\ \vdots &= (s_n \text{ continues}) \end{align} In this case, the diagonal number is the bold diagonal numbers $(0, 1, 1)$ , which when ""flipped"" is $(1,0,0)$ , neither of which is $s_1$ , $s_2$ , or $s_3$ . My question, or misunderstanding, is: When there exists the possibility that more $s_n$ exist, as is the case in the example above, how does this ""prove"" anything?  For example: \begin{align} s_0 &= (1,0,0,\mathbf{0},\dots)\ \ \textrm{ (...the wikipedia flipped diagonal)}\\ s_1 &= (\mathbf{0},1,0,\dots)\\ s_2 &= (1,\mathbf{1},0,\dots)\\ s_3 &= (0,0,\mathbf{1},\dots)\\ s_4 &= (0,1,1,\mathbf{1},\dots)\\ s_4 &= (1,0,0,\mathbf{1},\dots)\ \ \textrm{ (...alternate, flipped } s_4\textrm{)}\\ s_5 &= (1,0,0,0,\dots)\\ s_6 &= (1,0,0,1,\dots)\\ \vdots &= (s_n \text{ continues}) \end{align} In other words, as long as there is a $\dots \text{ continues}$ at the end, the very next number could be the ""impossible diagonal number"", with the caveat that it's not strictly identical to the ""impossible diagonal number"" as the wikipedia article defines it: For each $m$ and $n$ let $s_{n,m}$ be the $m^{th}$ element of the $n^{th}$ sequence on the list; so for each $n$ , $$s_n = (s_{n,1}, s_{n,2}, s_{n,3}, s_{n,4}, \dots).$$ ...snip... Otherwise, it would be possible by the above process to construct a sequence $s_0$ which would both be in $T$ (because it is a sequence of 0s and 1s which is by the definition of $T$ in $T$ ) and at the same time not in $T$ (because we can deliberately construct it not to be in the list). $T$ , containing all such sequences, must contain $s_0$ , which is just such a sequence. But since $s_0$ does not appear anywhere on the list, $T$ cannot contain $s_0$ . Therefore $T$ cannot be placed in one-to-one correspondence with the natural numbers. In other words, it is uncountable. I'm not sure this definition is correct, because if we assume that $m = (1, \dots)$ , then this definition says that "" $s_n$ is equal to itself""&mdadshthere is no ""diagonalization"" in this particular description of the argument, nor does it incorporate the ""flipping"" part of the argument, never mind the fact that we have very clearly constructed just such an impossible $T$ list above.  An attempt to correct the ""diagonalization"" and ""flipping"" problem: $$s_n = (\lnot s_{m,m}, \lnot s_{m,m}, \dots) \quad \text{where $m$ is the element index and} \quad\begin{equation}\lnot s_{m,m} = \begin{cases}0 & \mathrm{if\ } s_{m,m} = 1\\1 & \mathrm{if\ } s_{m,m} = 0\end{cases}\end{equation}$$ This definition doesn't quite work either, as we immediately run in to problems with just $s_1 = (0),$ which is impossible because by definition $s_1$ must be $ = (1)$ if $s_1 = (0)$ , which would also be impossible because... it's turtles all the way down!? Or more generally, with the revised definition there is a contradiction whenever $n = m$ , which would seem to invalidate the revised formulation of the argument / proof. Nothing about this argument / proof makes any sense to me, nor why it only applies to real numbers and makes them ""uncountable"". As near as I can tell it would seem to apply equal well to natural numbers, which are ""countable"". What am I missing?","I'm having trouble understanding Cantor's diagonal argument.  Specifically, I do not understand how it proves that something is ""uncountable"".  My understanding of the argument is that it takes the following form (modified slightly from the wikipedia article, assuming base 2, where the numbers must be from the set ): In this case, the diagonal number is the bold diagonal numbers , which when ""flipped"" is , neither of which is , , or . My question, or misunderstanding, is: When there exists the possibility that more exist, as is the case in the example above, how does this ""prove"" anything?  For example: In other words, as long as there is a at the end, the very next number could be the ""impossible diagonal number"", with the caveat that it's not strictly identical to the ""impossible diagonal number"" as the wikipedia article defines it: For each and let be the element of the sequence on the list; so for each , ...snip... Otherwise, it would be possible by the above process to construct a sequence which would both be in (because it is a sequence of 0s and 1s which is by the definition of in ) and at the same time not in (because we can deliberately construct it not to be in the list). , containing all such sequences, must contain , which is just such a sequence. But since does not appear anywhere on the list, cannot contain . Therefore cannot be placed in one-to-one correspondence with the natural numbers. In other words, it is uncountable. I'm not sure this definition is correct, because if we assume that , then this definition says that "" is equal to itself""&mdadshthere is no ""diagonalization"" in this particular description of the argument, nor does it incorporate the ""flipping"" part of the argument, never mind the fact that we have very clearly constructed just such an impossible list above.  An attempt to correct the ""diagonalization"" and ""flipping"" problem: This definition doesn't quite work either, as we immediately run in to problems with just which is impossible because by definition must be if , which would also be impossible because... it's turtles all the way down!? Or more generally, with the revised definition there is a contradiction whenever , which would seem to invalidate the revised formulation of the argument / proof. Nothing about this argument / proof makes any sense to me, nor why it only applies to real numbers and makes them ""uncountable"". As near as I can tell it would seem to apply equal well to natural numbers, which are ""countable"". What am I missing?"," \lbrace 0,1 \rbrace  \begin{align}
s_1 &= (\mathbf{0},1,0,\dots)\\
s_2 &= (1,\mathbf{1},0,\dots)\\
s_3 &= (0,0,\mathbf{1},\dots)\\
\vdots &= (s_n \text{ continues})
\end{align} (0, 1, 1) (1,0,0) s_1 s_2 s_3 s_n \begin{align}
s_0 &= (1,0,0,\mathbf{0},\dots)\ \ \textrm{ (...the wikipedia flipped diagonal)}\\
s_1 &= (\mathbf{0},1,0,\dots)\\
s_2 &= (1,\mathbf{1},0,\dots)\\
s_3 &= (0,0,\mathbf{1},\dots)\\
s_4 &= (0,1,1,\mathbf{1},\dots)\\
s_4 &= (1,0,0,\mathbf{1},\dots)\ \ \textrm{ (...alternate, flipped } s_4\textrm{)}\\
s_5 &= (1,0,0,0,\dots)\\
s_6 &= (1,0,0,1,\dots)\\
\vdots &= (s_n \text{ continues})
\end{align} \dots \text{ continues} m n s_{n,m} m^{th} n^{th} n s_n = (s_{n,1}, s_{n,2}, s_{n,3}, s_{n,4}, \dots). s_0 T T T T T s_0 s_0 T s_0 T m = (1, \dots) s_n T s_n = (\lnot s_{m,m}, \lnot s_{m,m}, \dots) \quad \text{where m is the element index and} \quad\begin{equation}\lnot s_{m,m} = \begin{cases}0 & \mathrm{if\ } s_{m,m} = 1\\1 & \mathrm{if\ } s_{m,m} = 0\end{cases}\end{equation} s_1 = (0), s_1  = (1) s_1 = (0) n = m",['elementary-set-theory']
13,Prove that the union of countably many countable sets is countable.,Prove that the union of countably many countable sets is countable.,,I am doing some homework exercises and stumbled upon this question. I don't know where to start. Prove that the union of countably many countable sets is countable. Just reading it confuses me. Any hints or help is greatly appreciated! Cheers!,I am doing some homework exercises and stumbled upon this question. I don't know where to start. Prove that the union of countably many countable sets is countable. Just reading it confuses me. Any hints or help is greatly appreciated! Cheers!,,"['elementary-set-theory', 'logic']"
14,Infinite sets don't exist!?,Infinite sets don't exist!?,,"Has anyone read this article ? This accomplished mathematician gives his opinion on why he doesn't think infinite sets exist, and claims that axioms are nonsense. I don't disagree with his arguments, but with my limited knowledge of axiomatic set theory and logic, I am unable to take sides. Would someone be so kind as to enlighten me on why his arguments are/aren't correct? Thanks","Has anyone read this article ? This accomplished mathematician gives his opinion on why he doesn't think infinite sets exist, and claims that axioms are nonsense. I don't disagree with his arguments, but with my limited knowledge of axiomatic set theory and logic, I am unable to take sides. Would someone be so kind as to enlighten me on why his arguments are/aren't correct? Thanks",,"['elementary-set-theory', 'logic', 'philosophy', 'foundations']"
15,"Is ""The empty set is a subset of any set"" a convention?","Is ""The empty set is a subset of any set"" a convention?",,"Recently I learned that for any set A, we have $\varnothing\subset A$. I found some explanation of why it holds. $\varnothing\subset A$ means ""for every object $x$, if $x$ belongs to the empty set, then $x$ also belongs to the set A"". This is a vacuous truth, because the antecedent ($x$ belongs to the empty set) could never be true, so the conclusion always holds ($x$ also belongs to the set A). So $\varnothing\subset A$ holds. What confused me was that, the following expression was also a vacuous truth. For every object  $x$, if $x$ belongs to the empty set, then $x$ doesn't belong to the set A. According to the definition of the vacuous truth, the conclusion ($x$ doesn't belong to the set A) holds, so $\varnothing\not\subset A$ would be true, too. Which one is correct? Or is it just a convention to let $\varnothing\subset A$?","Recently I learned that for any set A, we have $\varnothing\subset A$. I found some explanation of why it holds. $\varnothing\subset A$ means ""for every object $x$, if $x$ belongs to the empty set, then $x$ also belongs to the set A"". This is a vacuous truth, because the antecedent ($x$ belongs to the empty set) could never be true, so the conclusion always holds ($x$ also belongs to the set A). So $\varnothing\subset A$ holds. What confused me was that, the following expression was also a vacuous truth. For every object  $x$, if $x$ belongs to the empty set, then $x$ doesn't belong to the set A. According to the definition of the vacuous truth, the conclusion ($x$ doesn't belong to the set A) holds, so $\varnothing\not\subset A$ would be true, too. Which one is correct? Or is it just a convention to let $\varnothing\subset A$?",,"['elementary-set-theory', 'logic']"
16,Overview of basic results on cardinal arithmetic,Overview of basic results on cardinal arithmetic,,"Are there some good overviews of basic formulas about addition, multiplication and exponentiation of cardinals (preferably available online)?","Are there some good overviews of basic formulas about addition, multiplication and exponentiation of cardinals (preferably available online)?",,"['reference-request', 'elementary-set-theory', 'cardinals', 'online-resources']"
17,Why can't you pick socks using coin flips?,Why can't you pick socks using coin flips?,,"I'm teaching myself axiomatic set theory and I'm having some trouble getting my head around the axiom of choice . I (think I) understand what the axiom says, but I don't get why it is so 'contentious', which probably means I haven't yet digested it properly. As far as I can make out, one phrasing of the axiom is: for any family of non-empty, pairwise disjoint sets, there exists a set containing exactly one element from each set in the family. If that's all the axiom states, why is there so much debate around it? If it were stated as there exists a procedure for constructing such a set , that might help me understand (though is that an incorrect statement of the axiom?), but then again: To use Russell's classic shoes-and-socks example, why won't a coin flip for each pair of socks suffice? I'm sure this must be a stupid question, but please help me understand why.","I'm teaching myself axiomatic set theory and I'm having some trouble getting my head around the axiom of choice . I (think I) understand what the axiom says, but I don't get why it is so 'contentious', which probably means I haven't yet digested it properly. As far as I can make out, one phrasing of the axiom is: for any family of non-empty, pairwise disjoint sets, there exists a set containing exactly one element from each set in the family. If that's all the axiom states, why is there so much debate around it? If it were stated as there exists a procedure for constructing such a set , that might help me understand (though is that an incorrect statement of the axiom?), but then again: To use Russell's classic shoes-and-socks example, why won't a coin flip for each pair of socks suffice? I'm sure this must be a stupid question, but please help me understand why.",,"['elementary-set-theory', 'self-learning', 'axiom-of-choice']"
18,Proof that the irrational numbers are uncountable,Proof that the irrational numbers are uncountable,,"Can someone point me to a proof that the set of irrational numbers is uncountable? I know how to show that the set $\mathbb{Q}$ of rational numbers is countable, but how would you show that the irrationals are uncountable?","Can someone point me to a proof that the set of irrational numbers is uncountable? I know how to show that the set $\mathbb{Q}$ of rational numbers is countable, but how would you show that the irrationals are uncountable?",,"['elementary-set-theory', 'irrational-numbers']"
19,How can a set contain itself?,How can a set contain itself?,,"In Russell's famous paradox (""Does the set of all sets which do not contain themselves contain itself?"") he obviously makes the assumption that a set can contain itself. I do not understand how this should be possible and therefore my answer to Russell's question would simply be ""No, because a set cannot contain itself in the first place."" How can a set be exactly the same set as the one that contains it? To me it seems unavoidable that the containing set will always have one more additional level of depth compared to all the sets which it contains, just like those russian matryoshka-dolls where every doll contains at least one more doll than all the dolls inside it. Of course one can define something like ""the set of all sets with at least one element"" which of course would include a lot of sets and therefore by definition should also include itself, but does it necessarily need to include itself just because its definition demands so? To me this only seems to prove that it's possible to define something that cannot exist beyond its pure definition.","In Russell's famous paradox (""Does the set of all sets which do not contain themselves contain itself?"") he obviously makes the assumption that a set can contain itself. I do not understand how this should be possible and therefore my answer to Russell's question would simply be ""No, because a set cannot contain itself in the first place."" How can a set be exactly the same set as the one that contains it? To me it seems unavoidable that the containing set will always have one more additional level of depth compared to all the sets which it contains, just like those russian matryoshka-dolls where every doll contains at least one more doll than all the dolls inside it. Of course one can define something like ""the set of all sets with at least one element"" which of course would include a lot of sets and therefore by definition should also include itself, but does it necessarily need to include itself just because its definition demands so? To me this only seems to prove that it's possible to define something that cannot exist beyond its pure definition.",,"['elementary-set-theory', 'paradoxes']"
20,Example of Partial Order that's not a Total Order and why?,Example of Partial Order that's not a Total Order and why?,,I'm looking for a simple example of a partial order which is not a total order so that I can grasp the concept and the difference between the two. An explanation of why the example is a partial order but not a total order would also be greatly appreciated.,I'm looking for a simple example of a partial order which is not a total order so that I can grasp the concept and the difference between the two. An explanation of why the example is a partial order but not a total order would also be greatly appreciated.,,"['elementary-set-theory', 'examples-counterexamples', 'order-theory']"
21,Refuting the Anti-Cantor Cranks,Refuting the Anti-Cantor Cranks,,"I occasionally have the opportunity to argue with anti-Cantor cranks, people who for some reason or the other attack the validity of Cantor's diagonalization proof of the uncountability of the real numbers, arguably one of the most beautiful ideas in mathematics. They usually make the same sorts of arguments, so years ago I wrote up this FAQ to deal with them. Unfortunately, it's still hard to get anywhere with these people; the discussion frequently turns into something of this form: ME: Suppose there is an ordered list containing all the real numbers. Then we can read off the diagonal entries and construct a real number that differs in the Nth decimal place from the Nth real number on the list. This real number obviously cannot be in the list. So the list doesn't contain all the real numbers. THEM: Of course your proposed number is not on the list; it's not a well-defined real number. ME: What do you mean? I gave you the exact procedure for constructing it. You take the Nth real number on the list, and you make it differ from that number in the Nth decimal place. THEM: But if we really have a list of all the real numbers, then your proposed number has to be somewhere in the list, right? ME: Yes, of course, so let's say it's in the 57th place. Then it would have to differ from itself in the 57th place, which is impossible! THEM: Exactly, it's impossible! Your definition requires that it differs in some place from itself, which is impossible, so your definition is bad. ME: But you're only saying that it's impossible on the basis of the assumption that there's a complete list of real numbers, and the whole point is to disprove that assumption. THEM: But we're doing this proof under that assumption, so how can we make a definition that runs contrary to that assumption? ME: But that definition is a good one regardless of whether there are countably or uncountably many reals. It is a complete, algorithmic, unambiguous specification of the real number. What else could you want? THEM: I want the definition to be both unambiguous and non-contradictory, and your definition is contradictory! ME: Forget about the purported complete lists of real numbers for a moment. Don't you agree that for any list of real numbers, complete or incomplete, it's possible to construct a real number that differs in the Nth place from the Nth number on the list? THEM: No, it's only possible to construct such a real number if that real number isn't on the list, otherwise it's a contradictory definition. ME: Don't you see that the contradiction is not the fault of my perfectly good definition, but rather the fault of your assumption that there are countably many real numbers? THEM: No, I don't. ME: But what if we took our putative complete list of real numbers, and fed it in line by line into a computer with an algorithm that spits out, digit by digit, a real number that differs in the Nth digit from the Nth number on the list? Would such a computer program work? THEM: No it wouldn't, the computer program would hit the place on the list where the number being constructed would reside, and then it would get crash, because it can't choose a digit for the number that differs in the nth place from itself. ME: Argh! So how do I stop going in circles and convince them that they're wrong? Any help would be greatly appreciated. Thank You in Advance.","I occasionally have the opportunity to argue with anti-Cantor cranks, people who for some reason or the other attack the validity of Cantor's diagonalization proof of the uncountability of the real numbers, arguably one of the most beautiful ideas in mathematics. They usually make the same sorts of arguments, so years ago I wrote up this FAQ to deal with them. Unfortunately, it's still hard to get anywhere with these people; the discussion frequently turns into something of this form: ME: Suppose there is an ordered list containing all the real numbers. Then we can read off the diagonal entries and construct a real number that differs in the Nth decimal place from the Nth real number on the list. This real number obviously cannot be in the list. So the list doesn't contain all the real numbers. THEM: Of course your proposed number is not on the list; it's not a well-defined real number. ME: What do you mean? I gave you the exact procedure for constructing it. You take the Nth real number on the list, and you make it differ from that number in the Nth decimal place. THEM: But if we really have a list of all the real numbers, then your proposed number has to be somewhere in the list, right? ME: Yes, of course, so let's say it's in the 57th place. Then it would have to differ from itself in the 57th place, which is impossible! THEM: Exactly, it's impossible! Your definition requires that it differs in some place from itself, which is impossible, so your definition is bad. ME: But you're only saying that it's impossible on the basis of the assumption that there's a complete list of real numbers, and the whole point is to disprove that assumption. THEM: But we're doing this proof under that assumption, so how can we make a definition that runs contrary to that assumption? ME: But that definition is a good one regardless of whether there are countably or uncountably many reals. It is a complete, algorithmic, unambiguous specification of the real number. What else could you want? THEM: I want the definition to be both unambiguous and non-contradictory, and your definition is contradictory! ME: Forget about the purported complete lists of real numbers for a moment. Don't you agree that for any list of real numbers, complete or incomplete, it's possible to construct a real number that differs in the Nth place from the Nth number on the list? THEM: No, it's only possible to construct such a real number if that real number isn't on the list, otherwise it's a contradictory definition. ME: Don't you see that the contradiction is not the fault of my perfectly good definition, but rather the fault of your assumption that there are countably many real numbers? THEM: No, I don't. ME: But what if we took our putative complete list of real numbers, and fed it in line by line into a computer with an algorithm that spits out, digit by digit, a real number that differs in the Nth digit from the Nth number on the list? Would such a computer program work? THEM: No it wouldn't, the computer program would hit the place on the list where the number being constructed would reside, and then it would get crash, because it can't choose a digit for the number that differs in the nth place from itself. ME: Argh! So how do I stop going in circles and convince them that they're wrong? Any help would be greatly appreciated. Thank You in Advance.",,"['elementary-set-theory', 'soft-question', 'cardinals', 'education', 'infinity']"
22,Is the power set of the natural numbers countable?,Is the power set of the natural numbers countable?,,"Some explanations: A set S is countable if there exists an injective function $f$ from $S$ to the natural numbers ($f:S \rightarrow \mathbb{N}$). $\{1,2,3,4\}, \mathbb{N},\mathbb{Z}, \mathbb{Q}$ are all countable. $\mathbb{R}$ is not countable. The power set $\mathcal P(A) $ is defined as a set of all possible subsets of A, including the empty set and the whole set. $\mathcal P (\{\})=\{\{\}\}, \mathcal P (\mathcal P(\{\}))=\{\{\}, \{\{\}\}\} $ $\mathcal P(\{1,2\})=\{\{\}, \{1\},\{2\},\{1,2\}\}$ My question is: Is $\mathcal P(\mathbb{N})$ countable? How would an injective function $f:S \rightarrow \mathbb{N}$ look like?","Some explanations: A set S is countable if there exists an injective function $f$ from $S$ to the natural numbers ($f:S \rightarrow \mathbb{N}$). $\{1,2,3,4\}, \mathbb{N},\mathbb{Z}, \mathbb{Q}$ are all countable. $\mathbb{R}$ is not countable. The power set $\mathcal P(A) $ is defined as a set of all possible subsets of A, including the empty set and the whole set. $\mathcal P (\{\})=\{\{\}\}, \mathcal P (\mathcal P(\{\}))=\{\{\}, \{\{\}\}\} $ $\mathcal P(\{1,2\})=\{\{\}, \{1\},\{2\},\{1,2\}\}$ My question is: Is $\mathcal P(\mathbb{N})$ countable? How would an injective function $f:S \rightarrow \mathbb{N}$ look like?",,['elementary-set-theory']
23,What does it take to divide by $2$?,What does it take to divide by ?,2,"Theorem 1 [ZFC, classical logic]: If $A,B$ are sets such that $\textbf{2}\times A\cong \textbf{2}\times B$, then $A\cong B$. That's because the axiom of choice allows for the definition of cardinality $|A|$ of any set $A$, and for $|A|\geq\aleph_0$ we have $|\textbf{2}\times A|=|A|$. Theorem 2 : Theorem 1 still holds in ZF with classical logic. This is less trivial and explained in Section 5 of Division by Three - however, though the construction does not involve any choices, it does involve the law of excluded middle. Question: Are there intuitionistic set theories in which one can prove $$\textbf{2}\times A\cong \textbf{2}\times B\quad\Rightarrow\quad A\cong B\quad\text{?}$$ For example, is this statement true in elementary topoi or can it be proved in some intuitionistic type theory? In his comment below Kyle indicated that the statement is unprovable in some type theory - does somebody know the argument or a reference for that? Edit See also the related question Does $A\times A\cong B\times B$ imply $A\cong B$? about 'square roots'","Theorem 1 [ZFC, classical logic]: If $A,B$ are sets such that $\textbf{2}\times A\cong \textbf{2}\times B$, then $A\cong B$. That's because the axiom of choice allows for the definition of cardinality $|A|$ of any set $A$, and for $|A|\geq\aleph_0$ we have $|\textbf{2}\times A|=|A|$. Theorem 2 : Theorem 1 still holds in ZF with classical logic. This is less trivial and explained in Section 5 of Division by Three - however, though the construction does not involve any choices, it does involve the law of excluded middle. Question: Are there intuitionistic set theories in which one can prove $$\textbf{2}\times A\cong \textbf{2}\times B\quad\Rightarrow\quad A\cong B\quad\text{?}$$ For example, is this statement true in elementary topoi or can it be proved in some intuitionistic type theory? In his comment below Kyle indicated that the statement is unprovable in some type theory - does somebody know the argument or a reference for that? Edit See also the related question Does $A\times A\cong B\times B$ imply $A\cong B$? about 'square roots'",,"['elementary-set-theory', 'logic', 'topos-theory', 'constructive-mathematics']"
24,What are good books/other readings for elementary set theory?,What are good books/other readings for elementary set theory?,,"I am looking to expand my knowledge on set theory (which is pretty poor right now -- basic understanding of sets, power sets, and different (infinite) cardinalities). Are there any books that come to your mind that would be useful for an undergrad math student who hasn't taken a set theory course yet? Thanks a lot for your suggestions!","I am looking to expand my knowledge on set theory (which is pretty poor right now -- basic understanding of sets, power sets, and different (infinite) cardinalities). Are there any books that come to your mind that would be useful for an undergrad math student who hasn't taken a set theory course yet? Thanks a lot for your suggestions!",,"['elementary-set-theory', 'reference-request', 'book-recommendation']"
25,Is the axiom of choice really all that important?,Is the axiom of choice really all that important?,,"According to this book : The Axiom of Choice is the most controversial axiom in the entire history of mathematics. Yet it remains a crucial assumption not only in set theory but equally in modern algebra, analysis, mathematical logic, and topology (often under the name Zorn's Lemma). I am not a set theorist, and I don't pretend to be, but I have heard of some weird things that can happen with choice, such as the Banachâ€“Tarski paradox --paradoxes like these are presumably why the Axiom of Choice was so controversial at first, but I am interested in what would happen without choice. Question: What notable consequences would occur without the Axiom of Choice? I found one very interesting example here on an MO thread (reproduced here for ease): The universe can be very a strange place without choice. One consequence of the Axiom of Choice is that when you partition a set into disjoint nonempty parts, then the number of parts does not exceed the number of elements of the set being partitioned. This can fail without the Axiom of Choice. In fact, if all sets of reals are Lebesgue measurable, then it is possible to partition $2^{\omega}$ into more than $2^{\omega}$ many pairwise disjoint nonempty sets! What other weird things would result without this axiom? Would it really be a devastating blow to mathematics or is it really not that big of a deal? I'm hoping for examples/answers geared toward the undergrad level--suitable for someone with very little set theory background.","According to this book : The Axiom of Choice is the most controversial axiom in the entire history of mathematics. Yet it remains a crucial assumption not only in set theory but equally in modern algebra, analysis, mathematical logic, and topology (often under the name Zorn's Lemma). I am not a set theorist, and I don't pretend to be, but I have heard of some weird things that can happen with choice, such as the Banachâ€“Tarski paradox --paradoxes like these are presumably why the Axiom of Choice was so controversial at first, but I am interested in what would happen without choice. Question: What notable consequences would occur without the Axiom of Choice? I found one very interesting example here on an MO thread (reproduced here for ease): The universe can be very a strange place without choice. One consequence of the Axiom of Choice is that when you partition a set into disjoint nonempty parts, then the number of parts does not exceed the number of elements of the set being partitioned. This can fail without the Axiom of Choice. In fact, if all sets of reals are Lebesgue measurable, then it is possible to partition $2^{\omega}$ into more than $2^{\omega}$ many pairwise disjoint nonempty sets! What other weird things would result without this axiom? Would it really be a devastating blow to mathematics or is it really not that big of a deal? I'm hoping for examples/answers geared toward the undergrad level--suitable for someone with very little set theory background.",,"['elementary-set-theory', 'examples-counterexamples', 'axiom-of-choice']"
26,difference between maximal element and greatest element,difference between maximal element and greatest element,,"I know that it's very elementary question but I still don't fully understand difference between maximal element and greatest element. If it's possible, please explain to me this difference with some examples etc. I tried to explain this difference to myself using only definition, but maximal element and greatest element still seems almost the same for me. Thank you.","I know that it's very elementary question but I still don't fully understand difference between maximal element and greatest element. If it's possible, please explain to me this difference with some examples etc. I tried to explain this difference to myself using only definition, but maximal element and greatest element still seems almost the same for me. Thank you.",,"['elementary-set-theory', 'order-theory']"
27,Why can't a set have two elements of the same value?,Why can't a set have two elements of the same value?,,"Suppose I have two sets, $A$ and $B$: $$A = \{1, 2, 3, 4, 5\} \\ B = \{1, 1, 2, 3, 4\}$$ Set $A$ is valid, but set $B$ isn't because not all of its elements are unique. My question is, why can't sets contain duplicate elements?","Suppose I have two sets, $A$ and $B$: $$A = \{1, 2, 3, 4, 5\} \\ B = \{1, 1, 2, 3, 4\}$$ Set $A$ is valid, but set $B$ isn't because not all of its elements are unique. My question is, why can't sets contain duplicate elements?",,['elementary-set-theory']
28,"In set theory, how are real numbers represented as sets?","In set theory, how are real numbers represented as sets?",,"In set theory, if natural numbers are represented by nested sets that include the empty set, how are the rest of the real numbers represented as sets? Thanks for the answers. Several answers basically said for irrational numbers that  A Dedekind cut is a pair of sets of rational numbers $\{L, R\}$. The set of real numbers is defined to be the set of all Dedekind cuts, where a Dedekind cut is a pair of sets of rational numbers $\{L, R\}$ which have no elements in common, and where all the elements of $L$ are less than any element of $R$.  Each Dedekind cut is a real number. This is where I have a problem - surely that canâ€™t be correct. The set $L$ is a set of all rationals, and there must be a rational in the set $L$ that is greater than all other rationals in that set, even if we have no method of determining it. And similarly, there must be a rational in the set $R$ that is less than all other rationals in that set, even if we have no method of determining it. If every irrational number has a corresponding set $L$, then each irrational number has some such corresponding largest element of that set $L$, and then each irrational number has some corresponding rational number. And that would mean that the irrational numbers are countable. So, with Dedekind cuts,  the only conclusion is that there must be irrational numbers $x$ which are either greater or lesser than some irrational cut $y$ of the rationals, and between $x$ and $y$ there is no rational number.  But that is impossible, so that the Dedekind cuts cannot be the correct representation of the real numbers. Surely the problem with Dedekind cuts is in using sets of rationals that include all rationals up to a certain rational. But there is an alternative method of representing irrationals can be defined in terms of infinite sets of rational numbers. For example, in binary notation, the non-integer part of $\pi$ is $.00100100\ 00111111\ 01101010\ 10001$. You define a set by: if the nth digit is a $1$, then  the natural number $n$ is in the set. And then we have that, for the real numbers between $0$ and $1$, that the set of real numbers is simply the set of all subsets of natural numbers. Each subset corresponds to some real number between $0$ and $1$. And in this way, all real numbers can be considered to be some set based only on nested sets of the empty set. But I still havenâ€™t got a satisfactory answer for how negative numbers can be represented in terms only of sets containing the empty set. Any ideas?","In set theory, if natural numbers are represented by nested sets that include the empty set, how are the rest of the real numbers represented as sets? Thanks for the answers. Several answers basically said for irrational numbers that  A Dedekind cut is a pair of sets of rational numbers $\{L, R\}$. The set of real numbers is defined to be the set of all Dedekind cuts, where a Dedekind cut is a pair of sets of rational numbers $\{L, R\}$ which have no elements in common, and where all the elements of $L$ are less than any element of $R$.  Each Dedekind cut is a real number. This is where I have a problem - surely that canâ€™t be correct. The set $L$ is a set of all rationals, and there must be a rational in the set $L$ that is greater than all other rationals in that set, even if we have no method of determining it. And similarly, there must be a rational in the set $R$ that is less than all other rationals in that set, even if we have no method of determining it. If every irrational number has a corresponding set $L$, then each irrational number has some such corresponding largest element of that set $L$, and then each irrational number has some corresponding rational number. And that would mean that the irrational numbers are countable. So, with Dedekind cuts,  the only conclusion is that there must be irrational numbers $x$ which are either greater or lesser than some irrational cut $y$ of the rationals, and between $x$ and $y$ there is no rational number.  But that is impossible, so that the Dedekind cuts cannot be the correct representation of the real numbers. Surely the problem with Dedekind cuts is in using sets of rationals that include all rationals up to a certain rational. But there is an alternative method of representing irrationals can be defined in terms of infinite sets of rational numbers. For example, in binary notation, the non-integer part of $\pi$ is $.00100100\ 00111111\ 01101010\ 10001$. You define a set by: if the nth digit is a $1$, then  the natural number $n$ is in the set. And then we have that, for the real numbers between $0$ and $1$, that the set of real numbers is simply the set of all subsets of natural numbers. Each subset corresponds to some real number between $0$ and $1$. And in this way, all real numbers can be considered to be some set based only on nested sets of the empty set. But I still havenâ€™t got a satisfactory answer for how negative numbers can be represented in terms only of sets containing the empty set. Any ideas?",,['elementary-set-theory']
29,Cardinality of the set of all real functions of real variable,Cardinality of the set of all real functions of real variable,,How does one compute the cardinality of the set of functions $f:\mathbb{R} \to \mathbb{R}$ (not necessarily continuous)?,How does one compute the cardinality of the set of functions $f:\mathbb{R} \to \mathbb{R}$ (not necessarily continuous)?,,"['elementary-set-theory', 'cardinals']"
30,Empty intersection and empty union,Empty intersection and empty union,,"If $A_\alpha$ are subsets of a set $S$ then $\bigcup_{\alpha \in I}A_\alpha$ = ""all $x \in S$ so that $x$ is in at least one $A_\alpha$"" $\bigcap_{\alpha \in I} A_\alpha$ = ""all $x \in S$ so that $x$ is in all $A_\alpha$"" It is the convention that $\bigcup_{\alpha \in \emptyset}A_\alpha = \emptyset$ and $\bigcap_{\alpha \in \emptyset} A_\alpha = S$. But if $x$ is in $\bigcap_{\alpha \in \emptyset} A_\alpha = S$ then $x$ is in all $A_\alpha$ with $\alpha \in \emptyset$ and therefore $x$ is certainly in at least one $A_\alpha$ with $\alpha  \in \emptyset$. But then $x \in \bigcup_{\alpha \in I}A_\alpha$. Can someone help me and tell me what is wrong with this? Thank you.","If $A_\alpha$ are subsets of a set $S$ then $\bigcup_{\alpha \in I}A_\alpha$ = ""all $x \in S$ so that $x$ is in at least one $A_\alpha$"" $\bigcap_{\alpha \in I} A_\alpha$ = ""all $x \in S$ so that $x$ is in all $A_\alpha$"" It is the convention that $\bigcup_{\alpha \in \emptyset}A_\alpha = \emptyset$ and $\bigcap_{\alpha \in \emptyset} A_\alpha = S$. But if $x$ is in $\bigcap_{\alpha \in \emptyset} A_\alpha = S$ then $x$ is in all $A_\alpha$ with $\alpha \in \emptyset$ and therefore $x$ is certainly in at least one $A_\alpha$ with $\alpha  \in \emptyset$. But then $x \in \bigcup_{\alpha \in I}A_\alpha$. Can someone help me and tell me what is wrong with this? Thank you.",,['elementary-set-theory']
31,How can an ordered pair be expressed as a set?,How can an ordered pair be expressed as a set?,,"My book says  \begin{equation} (a,b)=\{\{a\},\{a,b\}\} \end{equation} I have been staring at this for a bit and it doesn't make sense to me. I have read several others posts on this, but none made any sense to me. For example, Definition of an Ordered Pair Based on how my ignorant brain is viewing this, I don't see why the definition could not be. \begin{equation} (a,b)=\{\{a\},\{b\},\{a,b\}\} \end{equation} aka the power set. What is the significance of the {a} in that definition? Please keep things simple if possible. Normally definitions have a valid and clear reason for being defined that way. Clarification First, I understand what an ordered pair is. I just don't see how the set notation says that. Second,  \begin{equation} (a,b) = \{\{a\},\{a,b\}\}=\{\{a,b\},\{a\}\} \end{equation} Sets don't preserve order, but ordered pairs do. How does the third part of the equality apply to the definition? Third, another issue with the notation that I have starts with the Product Property of Sets \begin{equation} \text{Let $X$ and $Y$ be sets} :\ X=\{a,b,c\}\text{ and }Y=\{a,d,e\}. \end{equation} \begin{equation} \text{Then }X \times Y = \{(a,a),(a,d),(a,e),(b,a),(b,d),(b,e),\dots,(c,e)\} \end{equation} If we look at the first ordered pair and our given definition we have \begin{equation} (a,a)=\{\{a\},\{a,a\}\} \end{equation} How can this be so, you can't have duplicates in sets? I guess what I am looking for in an answer, is not a proof or a definition of ordered pairs, but rather something like, ""This notation says what it says because..."". Except for the second to last point I get the terminology, I just don't get the connection between the two different uses of notation.","My book says  \begin{equation} (a,b)=\{\{a\},\{a,b\}\} \end{equation} I have been staring at this for a bit and it doesn't make sense to me. I have read several others posts on this, but none made any sense to me. For example, Definition of an Ordered Pair Based on how my ignorant brain is viewing this, I don't see why the definition could not be. \begin{equation} (a,b)=\{\{a\},\{b\},\{a,b\}\} \end{equation} aka the power set. What is the significance of the {a} in that definition? Please keep things simple if possible. Normally definitions have a valid and clear reason for being defined that way. Clarification First, I understand what an ordered pair is. I just don't see how the set notation says that. Second,  \begin{equation} (a,b) = \{\{a\},\{a,b\}\}=\{\{a,b\},\{a\}\} \end{equation} Sets don't preserve order, but ordered pairs do. How does the third part of the equality apply to the definition? Third, another issue with the notation that I have starts with the Product Property of Sets \begin{equation} \text{Let $X$ and $Y$ be sets} :\ X=\{a,b,c\}\text{ and }Y=\{a,d,e\}. \end{equation} \begin{equation} \text{Then }X \times Y = \{(a,a),(a,d),(a,e),(b,a),(b,d),(b,e),\dots,(c,e)\} \end{equation} If we look at the first ordered pair and our given definition we have \begin{equation} (a,a)=\{\{a\},\{a,a\}\} \end{equation} How can this be so, you can't have duplicates in sets? I guess what I am looking for in an answer, is not a proof or a definition of ordered pairs, but rather something like, ""This notation says what it says because..."". Except for the second to last point I get the terminology, I just don't get the connection between the two different uses of notation.",,"['elementary-set-theory', 'definition']"
32,The cardinality of the set of all finite subsets of an infinite set,The cardinality of the set of all finite subsets of an infinite set,,"Let $X$ be an infinite set of cardinality $|X|$ , and let $S$ be the set of all finite subsets of $X$ . How can we show that Card( $S$ ) $=|X|$ ? Can anyone help, please?","Let be an infinite set of cardinality , and let be the set of all finite subsets of . How can we show that Card( ) ? Can anyone help, please?",X |X| S X S =|X|,['elementary-set-theory']
33,Why are integers subset of reals?,Why are integers subset of reals?,,"In most programming languages, integer and real (or float, rational, whatever) types are usually disjoint; 2 is not the same as 2.0 (although most languages do an automatic conversion when necessary). In addition to technical reasons, this separation makes sense -- you use them for quite different purposes. Why did they choose to say $\mathbb{Z} \subset \mathbb{R}$ in math? In other words, why are 2 and 2.0 considered the same? When you are working in $\mathbb{R}$, does it make any difference whether some elements, eg. 2.0, also belong to $\mathbb{Z}$ or not?","In most programming languages, integer and real (or float, rational, whatever) types are usually disjoint; 2 is not the same as 2.0 (although most languages do an automatic conversion when necessary). In addition to technical reasons, this separation makes sense -- you use them for quite different purposes. Why did they choose to say $\mathbb{Z} \subset \mathbb{R}$ in math? In other words, why are 2 and 2.0 considered the same? When you are working in $\mathbb{R}$, does it make any difference whether some elements, eg. 2.0, also belong to $\mathbb{Z}$ or not?",,"['elementary-set-theory', 'math-history', 'real-numbers', 'integers']"
34,De Morgan's law on infinite unions and intersections,De Morgan's law on infinite unions and intersections,,"While going through Probability: Theory and Examples by Rick Durrett (4th edition, p.9), I came across the familiar definition of $\sigma$-algebras where, if $A_i \in \mathcal{F}$ is a countable sequence of sets for some $\sigma$-algebra $\mathcal{F}$ and $\cup_i A_i \in \mathcal{F}$ by definition, then it follows that $\cap_i A_i^C \in \mathcal{F}$ by de Morgan's law. That's when it occurred to me that I had never seen a proof that de Morgan's law holds over a countably infinite number of sets. I don't have my measure theory/probably theory books with me right now, but I'm quite sure that I've never seen any of them prove this before extending $\sigma$-algebras to countable union or intersection, depending on which definition it started with. On the one hand, it seems obvious that it would hold. On the other hand, seeming obvious is not a proof, especially when it comes to something involving infinity. I can imagine an inductive proof where I assume de Morgan's law holds for an index set of size $n$ Then prove that it holds for an index set of size $n+1$ and wrap it up by $n \rightarrow \infty$ but I'm not convinced that's right. For example, an argument like that doesn't work for countable intersection being closed on a collection of open sets. So what's a good proof that can extend de Morgan's law to an infinite collection of sets.","While going through Probability: Theory and Examples by Rick Durrett (4th edition, p.9), I came across the familiar definition of $\sigma$-algebras where, if $A_i \in \mathcal{F}$ is a countable sequence of sets for some $\sigma$-algebra $\mathcal{F}$ and $\cup_i A_i \in \mathcal{F}$ by definition, then it follows that $\cap_i A_i^C \in \mathcal{F}$ by de Morgan's law. That's when it occurred to me that I had never seen a proof that de Morgan's law holds over a countably infinite number of sets. I don't have my measure theory/probably theory books with me right now, but I'm quite sure that I've never seen any of them prove this before extending $\sigma$-algebras to countable union or intersection, depending on which definition it started with. On the one hand, it seems obvious that it would hold. On the other hand, seeming obvious is not a proof, especially when it comes to something involving infinity. I can imagine an inductive proof where I assume de Morgan's law holds for an index set of size $n$ Then prove that it holds for an index set of size $n+1$ and wrap it up by $n \rightarrow \infty$ but I'm not convinced that's right. For example, an argument like that doesn't work for countable intersection being closed on a collection of open sets. So what's a good proof that can extend de Morgan's law to an infinite collection of sets.",,['elementary-set-theory']
35,"What is the difference between ""family"" and ""set""?","What is the difference between ""family"" and ""set""?",,"What is the difference between ""family"" and ""set"" ? The definition of ""family"" on mathworld ( http://mathworld.wolfram.com/Family.html ) is a collection of objects of the form $\{a_i\}_{i \in I}$, where $I$ is an index set. But, I think a set can also be represented in this form. So, what is the difference between the concept family and the concept set? Is there any example of a collection of objects that is a family, but not a set, or reversely? Many thanks!","What is the difference between ""family"" and ""set"" ? The definition of ""family"" on mathworld ( http://mathworld.wolfram.com/Family.html ) is a collection of objects of the form $\{a_i\}_{i \in I}$, where $I$ is an index set. But, I think a set can also be represented in this form. So, what is the difference between the concept family and the concept set? Is there any example of a collection of objects that is a family, but not a set, or reversely? Many thanks!",,"['elementary-set-theory', 'terminology']"
36,Every partial order can be extended to a linear ordering,Every partial order can be extended to a linear ordering,,"How do I show that every partial order can be extended to a linear ordering? I think that I manage to prove that claim for finite set, how can I prove it for infinite set? Thank you.","How do I show that every partial order can be extended to a linear ordering? I think that I manage to prove that claim for finite set, how can I prove it for infinite set? Thank you.",,"['reference-request', 'elementary-set-theory', 'order-theory']"
37,Can you have negative sets?,Can you have negative sets?,,"I figure that since you can, of course, have members in a set, have only a single member in a set, and then have no members in a set, it seems not then a big step forward (or backwards depending how you think of it) to think of a set with negative members. I shall elucidate. Since set theory deals with membership, and it deals not with the quantity, but the quality of those members, perhaps it be possible to have a set with negative members which subtract members from another set whose positive counterparts is contained therein. For example, the union of the sets $A$ and $B$, where set $A = \{1,2,3\}$ and set $B =\{-3\}$ would result in the set $A âˆª B = {1,2}$. Two notes: First, you can arbitrarily construct any set one desires, but when applied to the real world, perhaps this may be of use?; Second, the empty set seems frivolous but turned out to be quite useful, maybe the same may be said for negative sets? As someone pointed out, and they are of course correct, the set would actually be $\{1,2,3,-3\}$. However, in sticking with the principle, is what am describing denotable?","I figure that since you can, of course, have members in a set, have only a single member in a set, and then have no members in a set, it seems not then a big step forward (or backwards depending how you think of it) to think of a set with negative members. I shall elucidate. Since set theory deals with membership, and it deals not with the quantity, but the quality of those members, perhaps it be possible to have a set with negative members which subtract members from another set whose positive counterparts is contained therein. For example, the union of the sets $A$ and $B$, where set $A = \{1,2,3\}$ and set $B =\{-3\}$ would result in the set $A âˆª B = {1,2}$. Two notes: First, you can arbitrarily construct any set one desires, but when applied to the real world, perhaps this may be of use?; Second, the empty set seems frivolous but turned out to be quite useful, maybe the same may be said for negative sets? As someone pointed out, and they are of course correct, the set would actually be $\{1,2,3,-3\}$. However, in sticking with the principle, is what am describing denotable?",,['elementary-set-theory']
38,Set theory: difference between belong/contained and includes/subset?,Set theory: difference between belong/contained and includes/subset?,,"This is a total noob question. I am reading Naive Set Theory by Paul R. Halmos , and I'm having difficulty to understand something which seems to be trivial. In the first chapter he writes: If $x$ belongs to $A$ ($x$ is an element of $A$, $x$ is contained in $A$), we shall write $x\in A$ I understand this. Then, he write: If $A$ and $B$ are sets and if every element of $A$ is an element of $B$, we say that $A$ is a subset of $B$, or $B$ includes $A$, and we write: $A \subset B$ I understand this too. Then he says: The working of the definition implies that each set must be considered to be included in itself ($A \subset A$); this fact is described by saying that set inclusion is reflexive . I understand this too. But then: Observe that belonging ($\in$) and inclusion ($\subset$) are conceptually very different things indeed. One important difference has already manifested itself above: inclusion is always reflexive, whereas it is not at all clear that belonging is ever reflexive. That is: $A \subset A$ is always true;  is $A\in A$ ever true? It is certainly not true of any reasonable set that anyone has ever seen. And this is where I don't think I understand anything. There is not more elaboration on this point in the text. I tried to skip this but it seems it is quite fundamental for understanding what follows in the book. Could someone explain what is meant here?","This is a total noob question. I am reading Naive Set Theory by Paul R. Halmos , and I'm having difficulty to understand something which seems to be trivial. In the first chapter he writes: If $x$ belongs to $A$ ($x$ is an element of $A$, $x$ is contained in $A$), we shall write $x\in A$ I understand this. Then, he write: If $A$ and $B$ are sets and if every element of $A$ is an element of $B$, we say that $A$ is a subset of $B$, or $B$ includes $A$, and we write: $A \subset B$ I understand this too. Then he says: The working of the definition implies that each set must be considered to be included in itself ($A \subset A$); this fact is described by saying that set inclusion is reflexive . I understand this too. But then: Observe that belonging ($\in$) and inclusion ($\subset$) are conceptually very different things indeed. One important difference has already manifested itself above: inclusion is always reflexive, whereas it is not at all clear that belonging is ever reflexive. That is: $A \subset A$ is always true;  is $A\in A$ ever true? It is certainly not true of any reasonable set that anyone has ever seen. And this is where I don't think I understand anything. There is not more elaboration on this point in the text. I tried to skip this but it seems it is quite fundamental for understanding what follows in the book. Could someone explain what is meant here?",,['elementary-set-theory']
39,"Correct set notation for ""all integers which are not multiples of 7""?","Correct set notation for ""all integers which are not multiples of 7""?",,"What is correct set notation for ""all integers which are not multiples of $7$""? My best guess is: $$ \{ x : (\forall k \in \mathbb{Z})(\neg(7k = x)) \}$$ Or $$ \{ x : \neg(\exists k \in \mathbb{Z})(7k = x) \}$$ However this seems unlike other examples I have seen. Is there are proper way to denote this set in set notation?","What is correct set notation for ""all integers which are not multiples of $7$""? My best guess is: $$ \{ x : (\forall k \in \mathbb{Z})(\neg(7k = x)) \}$$ Or $$ \{ x : \neg(\exists k \in \mathbb{Z})(7k = x) \}$$ However this seems unlike other examples I have seen. Is there are proper way to denote this set in set notation?",,"['elementary-set-theory', 'notation']"
40,Why don't Venn diagrams count as formal proofs?,Why don't Venn diagrams count as formal proofs?,,"Just curious. If the purpose of a proof is to inform and persuade, why don't Venn diagrams count? Is it just convention or is there a more, umm, formal reason haha. Thanks!","Just curious. If the purpose of a proof is to inform and persuade, why don't Venn diagrams count? Is it just convention or is there a more, umm, formal reason haha. Thanks!",,"['elementary-set-theory', 'proof-writing']"
41,Example of set which contains itself,Example of set which contains itself,,I am trying to understand Russells's paradox How can a set contain itself? Can you show example of set which is not a set of all sets and it contains itself.,I am trying to understand Russells's paradox How can a set contain itself? Can you show example of set which is not a set of all sets and it contains itself.,,"['elementary-set-theory', 'logic']"
42,Bijection between $\mathbb{R}$ and $\mathbb{R}/\mathbb{Q}$,Bijection between  and,\mathbb{R} \mathbb{R}/\mathbb{Q},"I was wondering if it is possible to produce an explicit bijection $h\colon \mathbb{R} \rightarrow \mathbb{R}/\mathbb{Q}$. If we can produce an explicit injection $i\colon \mathbb{R} \rightarrow \mathbb{R}/\mathbb{Q}$, can the Cantor-Bernstein-Schroeder Theorem be used constructively? It is clear that the two sets have the same cardinality, so the existence of such a bijection is trivial. What I am really looking for is a nice-looking bijection, or a proof that no such nice-looking bijection exists, for a definition of ""nice-looking"" which I cannot quite figure out. One problem which I think makes finding such a bijection difficult is that any natural injection of $\mathbb{R}/\mathbb{Q}$ (ie, those injections in which one representative is chosen from each coset) produces a non-measurable set, specifically a Vitali set . I hate to ask such a vague question, but I'm really not sure about whether the correct answer is constructive, or whether it is a proof that any such bijection is in some sense ""very complicated."" As a final note, the motivation for this question came from this discussion , in which I was somewhat astonished to see such a clear, constructive bijection given between $\mathbb{R}$ and $\mathbb{R} \setminus S$, where $S$ is countable.","I was wondering if it is possible to produce an explicit bijection $h\colon \mathbb{R} \rightarrow \mathbb{R}/\mathbb{Q}$. If we can produce an explicit injection $i\colon \mathbb{R} \rightarrow \mathbb{R}/\mathbb{Q}$, can the Cantor-Bernstein-Schroeder Theorem be used constructively? It is clear that the two sets have the same cardinality, so the existence of such a bijection is trivial. What I am really looking for is a nice-looking bijection, or a proof that no such nice-looking bijection exists, for a definition of ""nice-looking"" which I cannot quite figure out. One problem which I think makes finding such a bijection difficult is that any natural injection of $\mathbb{R}/\mathbb{Q}$ (ie, those injections in which one representative is chosen from each coset) produces a non-measurable set, specifically a Vitali set . I hate to ask such a vague question, but I'm really not sure about whether the correct answer is constructive, or whether it is a proof that any such bijection is in some sense ""very complicated."" As a final note, the motivation for this question came from this discussion , in which I was somewhat astonished to see such a clear, constructive bijection given between $\mathbb{R}$ and $\mathbb{R} \setminus S$, where $S$ is countable.",,['elementary-set-theory']
43,"Why do we say â€˜pairwise disjointâ€™, rather than â€˜disjointâ€™?","Why do we say â€˜pairwise disjointâ€™, rather than â€˜disjointâ€™?",,"I donâ€™t see the ambiguity that â€˜pairwiseâ€™ resolves. Surely if $A$ , $B$ and $C$ are disjoint sets then they are pairwise disjoint and vice versa ? Or am I being dim?","I donâ€™t see the ambiguity that â€˜pairwiseâ€™ resolves. Surely if , and are disjoint sets then they are pairwise disjoint and vice versa ? Or am I being dim?",A B C,"['elementary-set-theory', 'terminology', 'definition']"
44,Is the empty set a subset of itself?,Is the empty set a subset of itself?,,"Sorry, but I don't think I can know, since it's a definition. Please tell me. I don't think that $0=\emptyset\,$ , since I distinguish between empty set and the value $0$ . Do all sets, even the empty set, have infinite emptiness e.g. do all sets, including the empty set, contain infinitely many empty sets?","Sorry, but I don't think I can know, since it's a definition. Please tell me. I don't think that , since I distinguish between empty set and the value . Do all sets, even the empty set, have infinite emptiness e.g. do all sets, including the empty set, contain infinitely many empty sets?","0=\emptyset\, 0","['elementary-set-theory', 'logic', 'definition']"
45,Why is the Cartesian product of a set $A$ and empty set an empty set? [duplicate],Why is the Cartesian product of a set  and empty set an empty set? [duplicate],A,"This question already has answers here : Is the product of two sets well-defined if one is empty [duplicate] (3 answers) Closed 11 years ago . Let $A \times \emptyset = \{(x,y)| x\in A, y \in \emptyset \}$. We know there is no element in $\emptyset$. But how does it follow that $A \times \emptyset = \emptyset $?","This question already has answers here : Is the product of two sets well-defined if one is empty [duplicate] (3 answers) Closed 11 years ago . Let $A \times \emptyset = \{(x,y)| x\in A, y \in \emptyset \}$. We know there is no element in $\emptyset$. But how does it follow that $A \times \emptyset = \emptyset $?",,['elementary-set-theory']
46,Is it possible to define countability without referring the natural numbers?,Is it possible to define countability without referring the natural numbers?,,Cantor defined countable sets as A set is countable if there exists an injective function from the set to the set of natural numbers. Still today countability is almost always defined in Cantor's words. Are the natural numbers really necessary to define countability. Most mathematicians admit that set theory is still a rich subject to study without getting into the conception of numbers. And I believe that the notion of countability is more fundamental than the set of natural numbers itself. Hence I wonder is it possible to define countability without referring the natural numbers? Let $A$ be a set and let $S:A\rightarrow A$ be a successor function which is characterised by the following properties. Two different elements in $A$ can not have same successor. The successor of an element should not be its ancestor. Shall I define countable sets as below? A set is countable if there exists a successor function as characterised above.,Cantor defined countable sets as A set is countable if there exists an injective function from the set to the set of natural numbers. Still today countability is almost always defined in Cantor's words. Are the natural numbers really necessary to define countability. Most mathematicians admit that set theory is still a rich subject to study without getting into the conception of numbers. And I believe that the notion of countability is more fundamental than the set of natural numbers itself. Hence I wonder is it possible to define countability without referring the natural numbers? Let $A$ be a set and let $S:A\rightarrow A$ be a successor function which is characterised by the following properties. Two different elements in $A$ can not have same successor. The successor of an element should not be its ancestor. Shall I define countable sets as below? A set is countable if there exists a successor function as characterised above.,,"['elementary-set-theory', 'logic']"
47,Prove that the power set of an $n$-element set contains $2^n$ elements,Prove that the power set of an -element set contains  elements,n 2^n,"Theorem. Let $X$ denote an arbitrary set such that $|X|=n$ . Then $|\mathcal P(X)|=2^n$ . Proof. The proof is by induction on the numbers of elements of $X$ . For the base case, suppose $|X|=0$ . Clearly, $X=\emptyset$ . But the empty set is the only subset of itself, so $|\mathcal P(X)|=1=2^0$ . Now, the induction step. Suppose $|X|=n$ ; by the induction hypothesis, we know that $|\mathcal P(X)|=2^n$ . Let $Y$ be a set with $n+1$ elements, namely $Y=X\cup\{a\}$ . There are two kinds of subsets of $Y$ : those that include $a$ and those that don't. The first are exactly the subsets of $X$ , and there are $2^n$ of them. The latter are sets of the form $Z\cup\{a\}$ , where $Z\in\mathcal P(X)$ ; since there are $2^n$ possible choices for $Z$ , there must be exactly $2^n$ subsets of $Y$ of which $a$ is an element. Therefore $|\mathcal P(Y)|=2^n+2^n=2^{n+1}$ . $\square$ Image that replaced text. From the above explanation, I don't understand why the set that contains $\{a\}$ will contain $2^{|n|}$ elements when it should clearly be $2^{|1|}$ . The construction of a new set $S$ is the union of the old set with cardinality $n$ and a new element $\{a\}$ , therefore the set that does not contain $\{a\}$ still has cardinality $n$ and the set that contains $\{a\}$ is just $\{a\}$ , one element. Can someone please elucidate?","Theorem. Let denote an arbitrary set such that . Then . Proof. The proof is by induction on the numbers of elements of . For the base case, suppose . Clearly, . But the empty set is the only subset of itself, so . Now, the induction step. Suppose ; by the induction hypothesis, we know that . Let be a set with elements, namely . There are two kinds of subsets of : those that include and those that don't. The first are exactly the subsets of , and there are of them. The latter are sets of the form , where ; since there are possible choices for , there must be exactly subsets of of which is an element. Therefore . Image that replaced text. From the above explanation, I don't understand why the set that contains will contain elements when it should clearly be . The construction of a new set is the union of the old set with cardinality and a new element , therefore the set that does not contain still has cardinality and the set that contains is just , one element. Can someone please elucidate?",X |X|=n |\mathcal P(X)|=2^n X |X|=0 X=\emptyset |\mathcal P(X)|=1=2^0 |X|=n |\mathcal P(X)|=2^n Y n+1 Y=X\cup\{a\} Y a X 2^n Z\cup\{a\} Z\in\mathcal P(X) 2^n Z 2^n Y a |\mathcal P(Y)|=2^n+2^n=2^{n+1} \square \{a\} 2^{|n|} 2^{|1|} S n \{a\} \{a\} n \{a\} \{a\},"['elementary-set-theory', 'induction']"
48,Does $k+\aleph_0=\mathfrak{c}$ imply $k=\mathfrak{c}$ without the Axiom of Choice?,Does  imply  without the Axiom of Choice?,k+\aleph_0=\mathfrak{c} k=\mathfrak{c},"I'm currently reading a little deeper into the Axiom of Choice, and I'm pleasantly surprised to find it makes the arithmetic of infinite cardinals seem easy. With AC follows the Absorption Law of Cardinal Arithmetic, which states that for $\kappa$ and $\lambda$ cardinal numbers, the larger infinite and the smaller nonzero, then $\kappa+\lambda=\kappa\cdot\lambda=\max(\kappa,\lambda)$. I was playing around with the equation $k+\aleph_0=\mathfrak{c}$ for some cardinal $k$. From the above, it follows that $\mathfrak{c}=k+\aleph_0=\max(k,\aleph_0)$, which implies $k=\mathfrak{c}$. I'm curious, can we still show $k=\mathfrak{c}$ without the Axiom of Choice? Is it maybe possible to bound $\mathfrak{c}-\aleph_0$ above and below by $\mathfrak{c}$? But then I'm not quite sure such algebraic manipulations even mean anything, or work like that here. Certainly normal arithmetic does not! Thanks.","I'm currently reading a little deeper into the Axiom of Choice, and I'm pleasantly surprised to find it makes the arithmetic of infinite cardinals seem easy. With AC follows the Absorption Law of Cardinal Arithmetic, which states that for $\kappa$ and $\lambda$ cardinal numbers, the larger infinite and the smaller nonzero, then $\kappa+\lambda=\kappa\cdot\lambda=\max(\kappa,\lambda)$. I was playing around with the equation $k+\aleph_0=\mathfrak{c}$ for some cardinal $k$. From the above, it follows that $\mathfrak{c}=k+\aleph_0=\max(k,\aleph_0)$, which implies $k=\mathfrak{c}$. I'm curious, can we still show $k=\mathfrak{c}$ without the Axiom of Choice? Is it maybe possible to bound $\mathfrak{c}-\aleph_0$ above and below by $\mathfrak{c}$? But then I'm not quite sure such algebraic manipulations even mean anything, or work like that here. Certainly normal arithmetic does not! Thanks.",,"['elementary-set-theory', 'cardinals', 'axiom-of-choice']"
49,Is First Order Logic (FOL) the only fundamental logic?,Is First Order Logic (FOL) the only fundamental logic?,,"I'm far from being an expert in the field of mathematical logic, but I've been reading about the academic work invested in the foundations of mathematics, both in a historical and objective sense; and I learned that it all seems to reduce to a proper -axiomatic- formulation of set theory. It also seems that all set theories (even if those come in ontologically different flavours, such as the ones which pursue the "" iterative approach "" like ZFC, versus the "" stratified approach "" -inspired by Russell's and Whitehead's type theory first formulated in their Principia - such as Quine's NFU or Mendelson's ST) are built as collections of axioms expressed in a common language , which invariably involves an underlying first order predicate logic augmented with the set-membership binary relation symbol. From this follows that FOL makes up the ( necessary ) ""formal template"" in mathematics, at least from a foundational perspective. The justification of this very fact, is the reason behind this question. All the stuff I've read about the metalogical virtues of FOL and the properties of its ""extensions"" could be summarized as the statements below: FOL is complete ( GÃ¶del, 1929 ), compact and sound, and all its particular formalizations as deductive systems are equivalent ( LindstrÃ¶m, 1969 ). That means that, given a (consistent) collection of axioms on top of a FOL deductive system, the set of all theorems which are syntactically provable, are semantically satisfied by a model of the axioms. The specification of the axioms absolutely entails all its consequences; and the fact that every first order deductive system is equivalent, suggests that FOL is a context-independent (i.e. objective), formal structure. On the other hand, the LÃ¶wenheimâ€“Skolem theorem implies that FOL cannot categorically characterize infinite structures, and so every first order theory satisfied by a model of a particular infinite cardinality, is also satisfied by multiple additional models of every other infinite cardinality. This non-categoricity feature is explained to be caused by the lack of expressive power of FOL. The categoricity results that FOL-based theories cannot achieve, can be obtained in a Second Order Logic (SOL) framework. Examples abound in ordinary mathematics, such as the Least Upper Bound axiom, which allows the definition of the real number system up to isomorphism. Nevertheless, SOL fails to verify an analog to the completeness results of FOL, and so there is no general match between syntactic provability and semantic satisfiability (in other words, it doesn't admit a complete proof calculus). That means that, even if a chosen collection of axioms is able to categorically characterize an infinite mathematical structure, there is an infinite set of wff's satisfied by the unique model of the axioms which cannot be derived through deduction. The syntactic-semantic schism in SOL also implies that there is no such a thing as an equivalent formulation of potential deductive systems, as is the case in FOL and stated by LindstrÃ¶m's theorem. One of the results of this fact is that the domain over which second order variables range must be specified, otherwise being ill-defined. If the domain is allowed to be the full set of subsets of the domain of first order variables, the corresponding standard semantics involve the formal properties stated above (enough expressive power to establish categoricity results, and incompleteness of potential, non-equivalent deductive systems). On the other hand, through an appropriate definition of second order domains for second order variables to range over, the resultant logic exhibits nonstandard semantics (or Henkin semantics ) which can be shown to be equivalent to many-sorted FOL; and as single-sorted FOL, it verifies the same metalogical properties stated at the beginning (and of course, its lack of expressive power). The quantification extension over variables of successive superior orders can be formalized, or even eliminate the distinction between individual (first order) variables and predicates; in each case, is obtained -for every N- an Nth Order Logic (NOL), and Higher Order Logic (HOL), respectively. Nevertheless, it can be shown ( Hintikka, 1955 ) that any sentence in any logic over FOL with standard semantics to be equivalent (in an effective manner) to a sentence in full SOL, using many-sorting. All of this points to the fact that the fundamental distinction, in logical terms, lies between FOL (be it single-sorted or many-sorted) and SOL (with standard semantics ). Or what seems to be the case, the logical foundations of every mathematical theory must be either non-categorical or lack a complete proof calculus, with nothing in between that trade-off. Why, so, is FOL invariably chosen as the underlying logic on top of which the set theoretical axioms are established, in any potentially foundational formalization of mathematics? As I've said, I'm not an expert in this topic, and I just happen to be interested in these themes. What I wrote here is a summary of what I assume I understood of what I read (even though I'm personally inclined against the people who speaks about what they don't fully understand). In this light, I'd be very pleased if any answer to this question involves a rectification of any assertion which happened to be wrong. P.S. : this is an exact repost of the question I originally asked at Philosophy .SE , because I assumed this to be an overly philosophical matter, and so it wouldn't be well received by the mathematics community. The lack of response there (be it because I wrong, and this actually makes up a question which can only be answered with a technical background on the subject, or because it's of little philosophical interest) is the reason why I decided to ask it here. Feel free to point out if my original criteria was actually correct, and of course, I'll take no offense if any moderator takes actions because of the probable unsuitability of the question in this site.","I'm far from being an expert in the field of mathematical logic, but I've been reading about the academic work invested in the foundations of mathematics, both in a historical and objective sense; and I learned that it all seems to reduce to a proper -axiomatic- formulation of set theory. It also seems that all set theories (even if those come in ontologically different flavours, such as the ones which pursue the "" iterative approach "" like ZFC, versus the "" stratified approach "" -inspired by Russell's and Whitehead's type theory first formulated in their Principia - such as Quine's NFU or Mendelson's ST) are built as collections of axioms expressed in a common language , which invariably involves an underlying first order predicate logic augmented with the set-membership binary relation symbol. From this follows that FOL makes up the ( necessary ) ""formal template"" in mathematics, at least from a foundational perspective. The justification of this very fact, is the reason behind this question. All the stuff I've read about the metalogical virtues of FOL and the properties of its ""extensions"" could be summarized as the statements below: FOL is complete ( GÃ¶del, 1929 ), compact and sound, and all its particular formalizations as deductive systems are equivalent ( LindstrÃ¶m, 1969 ). That means that, given a (consistent) collection of axioms on top of a FOL deductive system, the set of all theorems which are syntactically provable, are semantically satisfied by a model of the axioms. The specification of the axioms absolutely entails all its consequences; and the fact that every first order deductive system is equivalent, suggests that FOL is a context-independent (i.e. objective), formal structure. On the other hand, the LÃ¶wenheimâ€“Skolem theorem implies that FOL cannot categorically characterize infinite structures, and so every first order theory satisfied by a model of a particular infinite cardinality, is also satisfied by multiple additional models of every other infinite cardinality. This non-categoricity feature is explained to be caused by the lack of expressive power of FOL. The categoricity results that FOL-based theories cannot achieve, can be obtained in a Second Order Logic (SOL) framework. Examples abound in ordinary mathematics, such as the Least Upper Bound axiom, which allows the definition of the real number system up to isomorphism. Nevertheless, SOL fails to verify an analog to the completeness results of FOL, and so there is no general match between syntactic provability and semantic satisfiability (in other words, it doesn't admit a complete proof calculus). That means that, even if a chosen collection of axioms is able to categorically characterize an infinite mathematical structure, there is an infinite set of wff's satisfied by the unique model of the axioms which cannot be derived through deduction. The syntactic-semantic schism in SOL also implies that there is no such a thing as an equivalent formulation of potential deductive systems, as is the case in FOL and stated by LindstrÃ¶m's theorem. One of the results of this fact is that the domain over which second order variables range must be specified, otherwise being ill-defined. If the domain is allowed to be the full set of subsets of the domain of first order variables, the corresponding standard semantics involve the formal properties stated above (enough expressive power to establish categoricity results, and incompleteness of potential, non-equivalent deductive systems). On the other hand, through an appropriate definition of second order domains for second order variables to range over, the resultant logic exhibits nonstandard semantics (or Henkin semantics ) which can be shown to be equivalent to many-sorted FOL; and as single-sorted FOL, it verifies the same metalogical properties stated at the beginning (and of course, its lack of expressive power). The quantification extension over variables of successive superior orders can be formalized, or even eliminate the distinction between individual (first order) variables and predicates; in each case, is obtained -for every N- an Nth Order Logic (NOL), and Higher Order Logic (HOL), respectively. Nevertheless, it can be shown ( Hintikka, 1955 ) that any sentence in any logic over FOL with standard semantics to be equivalent (in an effective manner) to a sentence in full SOL, using many-sorting. All of this points to the fact that the fundamental distinction, in logical terms, lies between FOL (be it single-sorted or many-sorted) and SOL (with standard semantics ). Or what seems to be the case, the logical foundations of every mathematical theory must be either non-categorical or lack a complete proof calculus, with nothing in between that trade-off. Why, so, is FOL invariably chosen as the underlying logic on top of which the set theoretical axioms are established, in any potentially foundational formalization of mathematics? As I've said, I'm not an expert in this topic, and I just happen to be interested in these themes. What I wrote here is a summary of what I assume I understood of what I read (even though I'm personally inclined against the people who speaks about what they don't fully understand). In this light, I'd be very pleased if any answer to this question involves a rectification of any assertion which happened to be wrong. P.S. : this is an exact repost of the question I originally asked at Philosophy .SE , because I assumed this to be an overly philosophical matter, and so it wouldn't be well received by the mathematics community. The lack of response there (be it because I wrong, and this actually makes up a question which can only be answered with a technical background on the subject, or because it's of little philosophical interest) is the reason why I decided to ask it here. Feel free to point out if my original criteria was actually correct, and of course, I'll take no offense if any moderator takes actions because of the probable unsuitability of the question in this site.",,"['logic', 'elementary-set-theory', 'philosophy', 'higher-order-logic']"
50,Defeating Russell's paradox,Defeating Russell's paradox,,"I am not very big in mathematics yet(will be hopefully), naive set theory has a problem with Russell's paradox , how do they defeat this sort of problem in mathematics? Is there a greater form of set theory than naive set theory that beats this problem? (Maybe something like superposition if is both or neither)?","I am not very big in mathematics yet(will be hopefully), naive set theory has a problem with Russell's paradox , how do they defeat this sort of problem in mathematics? Is there a greater form of set theory than naive set theory that beats this problem? (Maybe something like superposition if is both or neither)?",,['elementary-set-theory']
51,Is this a valid proof that there are infinitely many natural numbers?,Is this a valid proof that there are infinitely many natural numbers?,,"I remember reading a simple proof that natural numbers are infinite which goes like the following: Let $â„•$ be the set of natural numbers. Assume that $â„•$ is finite. Now consider an arbitrary number $K$, where $K$ is the largest number in $â„•$. $K+1$ is also a natural number such that $K+1 > K$. Therefore, $â„•$ cannot be finite. Is this a valid proof? And if so, how can the 3rd step be valid when we assumed in the 2nd step that $K$ is the largest number in $â„•$? I understand this is a proof by contradiction (wrong?), but if we initially assume $K$ to be the largest number, then we cannot simply assume that there is such a number as $K+1$ later!","I remember reading a simple proof that natural numbers are infinite which goes like the following: Let $â„•$ be the set of natural numbers. Assume that $â„•$ is finite. Now consider an arbitrary number $K$, where $K$ is the largest number in $â„•$. $K+1$ is also a natural number such that $K+1 > K$. Therefore, $â„•$ cannot be finite. Is this a valid proof? And if so, how can the 3rd step be valid when we assumed in the 2nd step that $K$ is the largest number in $â„•$? I understand this is a proof by contradiction (wrong?), but if we initially assume $K$ to be the largest number, then we cannot simply assume that there is such a number as $K+1$ later!",,"['elementary-set-theory', 'proof-explanation']"
52,Is cardinality a well defined function?,Is cardinality a well defined function?,,"I was wondering if the cardinality of a set is a well defined function, more specifically, does it have a well defined domain and range? One would say you could assign a number to every finite set, and a cardinality for an infinite set. So the range would be clear, the set of cardinal numbers. But what about the domain, here we get a few problems. This should be the set of all sets, yet this concept isn't allowed in mathematics as it leads to paradoxes like Russell's paradox. So how do we formalize the notion of 'cardinality'? It seems to behave like a function that maps sets into cardinal numbers, but you can't define it this way as that definition would be based on a paradoxical notion. Even if we only restrict ourselves to finite sets the problem pops up, as we could define the set {A} for every set, thereby showing a one-to-one correspondence between 'the set of all sets' (that doesn't exist) and the 'set of all sets with one element'. So how should one look at the concept of cardinality? You can't reasonably call it a function. Formalizing this concept without getting into paradoxes seems very hard indeed.","I was wondering if the cardinality of a set is a well defined function, more specifically, does it have a well defined domain and range? One would say you could assign a number to every finite set, and a cardinality for an infinite set. So the range would be clear, the set of cardinal numbers. But what about the domain, here we get a few problems. This should be the set of all sets, yet this concept isn't allowed in mathematics as it leads to paradoxes like Russell's paradox. So how do we formalize the notion of 'cardinality'? It seems to behave like a function that maps sets into cardinal numbers, but you can't define it this way as that definition would be based on a paradoxical notion. Even if we only restrict ourselves to finite sets the problem pops up, as we could define the set {A} for every set, thereby showing a one-to-one correspondence between 'the set of all sets' (that doesn't exist) and the 'set of all sets with one element'. So how should one look at the concept of cardinality? You can't reasonably call it a function. Formalizing this concept without getting into paradoxes seems very hard indeed.",,"['elementary-set-theory', 'cardinals']"
53,"Intuitive explanation for how could there be ""more"" irrational numbers than rational? [duplicate]","Intuitive explanation for how could there be ""more"" irrational numbers than rational? [duplicate]",,"This question already has answers here : Why Are the Reals Uncountable? (9 answers) Closed 6 years ago . I've been told that the rational numbers from zero to one form a countable infinity, while the irrational ones form an uncountable infinity, which is in some sense ""larger"". But how could that be? There is always a rational between two irrationals, and always an irrational between two rationals, so it seems like it should be split pretty evenly.","This question already has answers here : Why Are the Reals Uncountable? (9 answers) Closed 6 years ago . I've been told that the rational numbers from zero to one form a countable infinity, while the irrational ones form an uncountable infinity, which is in some sense ""larger"". But how could that be? There is always a rational between two irrationals, and always an irrational between two rationals, so it seems like it should be split pretty evenly.",,"['elementary-set-theory', 'cardinals']"
54,Lamport claims there is an error in Kelley's proof of the Schroeder-Bernstein theorem. What is it?,Lamport claims there is an error in Kelley's proof of the Schroeder-Bernstein theorem. What is it?,,"In section 4.1 of his note How to write a proof , Leslie Lamport mentions an error in Kelley's exposition of the Schroeder-Bernstein theorem: Some twenty years ago, I decided to write a proof of the Schroeder-Bernstein theorem for an introductory mathematics class. The simplest proof I could find was in Kelleyâ€™s classic general topology text [4, page 28]. Since Kelley was writing for a more sophisticated audience, I had to add a great deal of explanation to his half-page proof. I had written five pages when I realized that Kelleyâ€™s proof was wrong. Recently, I wanted to illustrate a lecture on my proof style with a convincing incorrect proof, so I turned to Kelley. I could find nothing wrong with his proof; it seemed obviously correct! Read- ing and rereading the proof convinced me that either my memory had failed, or else I was very stupid twenty years ago. Still, Kelleyâ€™s proof was short and would serve as a nice example, so I started rewriting it as a structured proof. Within minutes, I rediscovered the error. However, Lamport doesn't explain what this error is.  I looked at Kelley's proof and stared at it for a long time, but I was unable to spot the mistake.  Could somebody please explain to me what this alleged mistake might be? Here's Kelley's proof (which he attributes to Birkhoff and Mac Lane) in its entirety (Kelley, General Topology, page 28): Theorem If there is a one-to-one function on a set $A$ to a subset of a set $B$ and there is also a one-to-one function on $B$ to a subset of $A$, then $A$ and $B$ are equipollent. Proof Suppose that $f$ is a one-to-one map of $A$ into $B$ and $g$ is one to one on $B$ to $A$.  It may be supposed that $A$ and $B$ are disjoint.  The proof of the theorem is accomplished by decomposing $A$ and $B$ into classes which are most easily described in terms of parthenogenesis.  A point $x$ (of either $A$ or $B$) is an ancestor of a point $y$ iff $y$ can be obtained from $x$ by successive application of $f$ and $g$ (or $g$ and $f$). Now decompose $A$ into three sets: let $A_E$ consist of all points of $A$ which have an even number of ancestors, let $A_O$ consist of points which have an odd number of ancestors, and let $A_I$ consist of points with infinitely many ancestors.  Decompose $B$ similarly and observe: $f$ maps $A_E$ onto $B_O$ and $A_I$ onto $B_I$, and $g^{-1}$ maps $A_O$ onto $B_E$. Hence the function which agrees with $f$ on $A_{E} \cup A_{I}$ and agrees with $g^{-1}$ on $A_{O}$ is a one-to-one map of $A$ onto $B$. I suspected that the error might lie with the edge-cases (the points in $A_E$ and $B_{E}$ with no ancestor), but there the argument seems to work. Thanks in advance.","In section 4.1 of his note How to write a proof , Leslie Lamport mentions an error in Kelley's exposition of the Schroeder-Bernstein theorem: Some twenty years ago, I decided to write a proof of the Schroeder-Bernstein theorem for an introductory mathematics class. The simplest proof I could find was in Kelleyâ€™s classic general topology text [4, page 28]. Since Kelley was writing for a more sophisticated audience, I had to add a great deal of explanation to his half-page proof. I had written five pages when I realized that Kelleyâ€™s proof was wrong. Recently, I wanted to illustrate a lecture on my proof style with a convincing incorrect proof, so I turned to Kelley. I could find nothing wrong with his proof; it seemed obviously correct! Read- ing and rereading the proof convinced me that either my memory had failed, or else I was very stupid twenty years ago. Still, Kelleyâ€™s proof was short and would serve as a nice example, so I started rewriting it as a structured proof. Within minutes, I rediscovered the error. However, Lamport doesn't explain what this error is.  I looked at Kelley's proof and stared at it for a long time, but I was unable to spot the mistake.  Could somebody please explain to me what this alleged mistake might be? Here's Kelley's proof (which he attributes to Birkhoff and Mac Lane) in its entirety (Kelley, General Topology, page 28): Theorem If there is a one-to-one function on a set $A$ to a subset of a set $B$ and there is also a one-to-one function on $B$ to a subset of $A$, then $A$ and $B$ are equipollent. Proof Suppose that $f$ is a one-to-one map of $A$ into $B$ and $g$ is one to one on $B$ to $A$.  It may be supposed that $A$ and $B$ are disjoint.  The proof of the theorem is accomplished by decomposing $A$ and $B$ into classes which are most easily described in terms of parthenogenesis.  A point $x$ (of either $A$ or $B$) is an ancestor of a point $y$ iff $y$ can be obtained from $x$ by successive application of $f$ and $g$ (or $g$ and $f$). Now decompose $A$ into three sets: let $A_E$ consist of all points of $A$ which have an even number of ancestors, let $A_O$ consist of points which have an odd number of ancestors, and let $A_I$ consist of points with infinitely many ancestors.  Decompose $B$ similarly and observe: $f$ maps $A_E$ onto $B_O$ and $A_I$ onto $B_I$, and $g^{-1}$ maps $A_O$ onto $B_E$. Hence the function which agrees with $f$ on $A_{E} \cup A_{I}$ and agrees with $g^{-1}$ on $A_{O}$ is a one-to-one map of $A$ onto $B$. I suspected that the error might lie with the edge-cases (the points in $A_E$ and $B_{E}$ with no ancestor), but there the argument seems to work. Thanks in advance.",,"['elementary-set-theory', 'proof-verification', 'fake-proofs']"
55,How is the set of all programs countable?,How is the set of all programs countable?,,"I'm having a hard time seeing how the number of programs is not uncountable, since for every real number, you can create a program that's prints out that number.  Doesn't that immediately establish uncountably many programs?","I'm having a hard time seeing how the number of programs is not uncountable, since for every real number, you can create a program that's prints out that number.  Doesn't that immediately establish uncountably many programs?",,"['elementary-set-theory', 'computer-science']"
56,Partitioning an infinite set,Partitioning an infinite set,,"Can you partition an infinite set, into an infinite number of infinite sets?","Can you partition an infinite set, into an infinite number of infinite sets?",,"['elementary-set-theory', 'infinity', 'set-partition']"
57,What is the difference between disjoint union and union?,What is the difference between disjoint union and union?,,"If $S = A \cup B$, then $S$ is the collection of all points in $A$ and $B$ What about $S = A \sqcup B$?, I think disjoint union is the same as union, only $A, B$ are disjoint. So the notation is a bit misleading. Because it is not a new operation, but operation where the pair $A,B$ satisfies $A \cap B = \varnothing$. So given $A \cap B = \varnothing$, $S = A \sqcup B = A \cup B$. Is my interpretation correct?","If $S = A \cup B$, then $S$ is the collection of all points in $A$ and $B$ What about $S = A \sqcup B$?, I think disjoint union is the same as union, only $A, B$ are disjoint. So the notation is a bit misleading. Because it is not a new operation, but operation where the pair $A,B$ satisfies $A \cap B = \varnothing$. So given $A \cap B = \varnothing$, $S = A \sqcup B = A \cup B$. Is my interpretation correct?",,"['elementary-set-theory', 'notation', 'terminology']"
58,Mathematical notation for the maximum of a set of function values,Mathematical notation for the maximum of a set of function values,,"I have a question about the proper notation of the following (simplified) example: I want to express that I have a value alpha, which is the maximum of a set of n values. Each value in the set is the result of a function $f(x)$, and the range of $x$ is between $1$ and $n$. So something like $$\alpha = \max(\{f(x) : x = 1,\ldots,n\}).$$ Is this a proper notation? If not, how would I properly express this? It's too long ago for me studying this sort of thing to convince myself I'm writing it down right.","I have a question about the proper notation of the following (simplified) example: I want to express that I have a value alpha, which is the maximum of a set of n values. Each value in the set is the result of a function $f(x)$, and the range of $x$ is between $1$ and $n$. So something like $$\alpha = \max(\{f(x) : x = 1,\ldots,n\}).$$ Is this a proper notation? If not, how would I properly express this? It's too long ago for me studying this sort of thing to convince myself I'm writing it down right.",,"['elementary-set-theory', 'notation']"
59,Why does Cantor's diagonal argument not work for rational numbers?,Why does Cantor's diagonal argument not work for rational numbers?,,"If we map every integer to a string that represents a rational number, and produce a number different from all the ones listed, we are essentially following Cantor's algorithm. But why does it not apply? Is it because we can't be certain that the number produced is a rational number?","If we map every integer to a string that represents a rational number, and produce a number different from all the ones listed, we are essentially following Cantor's algorithm. But why does it not apply? Is it because we can't be certain that the number produced is a rational number?",,"['elementary-set-theory', 'infinity']"
60,Zorn's Lemma And Axiom of Choice,Zorn's Lemma And Axiom of Choice,,How can I prove Zorn's lemma is equivalent to Axiom of choice?,How can I prove Zorn's lemma is equivalent to Axiom of choice?,,"['elementary-set-theory', 'axiom-of-choice']"
61,What is the largest set for which its set of self bijections is countable?,What is the largest set for which its set of self bijections is countable?,,"I recently came across a problem which required some knowledge about the self bijections of $\mathbb{N}$, and after looking up how to construct some different bijections I came across the result that the set of self bijections of $\mathbb{N}$ is uncountable. And this got me wondering, what is the largest set for which its set of self bijections is countable? This obviously holds true for any finite set, but what is the last example of a set whose set of self bijections is countable?","I recently came across a problem which required some knowledge about the self bijections of $\mathbb{N}$, and after looking up how to construct some different bijections I came across the result that the set of self bijections of $\mathbb{N}$ is uncountable. And this got me wondering, what is the largest set for which its set of self bijections is countable? This obviously holds true for any finite set, but what is the last example of a set whose set of self bijections is countable?",,"['elementary-set-theory', 'examples-counterexamples', 'cardinals', 'infinity']"
62,"What is wrong with my ""disproof"" of Cantor's Theorem?","What is wrong with my ""disproof"" of Cantor's Theorem?",,"I cannot figure out what is wrong: We will attempt to show that $\mathcal{P} (\mathbb{N})$ is countable. We use the following corollary from Rudin's Principles of Mathematical Analysis , p. 29: Suppose $A$ is at most countable, and, for every $\alpha\in A$ , $B_{\alpha}$ is at most countable. Put $$T=\bigcup_{\alpha \in A}B_{\alpha}$$ Then $T$ is at most countable. ""Proof"" 1: Let $A = \mathbb{N}$ and for every $\alpha \in A$ let $B_{\alpha}=\{S \in \mathcal{P} (\mathbb{N})| \text{the sum of the elements of } S \text{ is } \alpha \}$ . $A$ is countable and for every $\alpha \in A$ , $B_{\alpha}$ is finite. Therefore $$\bigcup_{\alpha \in A}B_{\alpha}$$ is countable. But $\displaystyle \bigcup_{\alpha \in A}B_{\alpha}=\mathcal{P} (\mathbb{N})$ , so $\mathcal{P} (\mathbb{N})$ is countable. ""Proof"" 2: Let $A= \mathbb{N}$ and for every $\alpha \in A$ let $B_{\alpha}=\{ S \in \mathcal{P} (\mathbb{N}): |S| = \alpha \}$ . I think that I can show by induction (if requested) that for each $\alpha \in A$ , $B_{\alpha}$ is countable. Thus $$\bigcup_{\alpha \in A}B_{\alpha}$$ is countable. But again, $\bigcup_{\alpha \in A}B_{\alpha} = \mathcal{P} (\mathbb{N})$","I cannot figure out what is wrong: We will attempt to show that is countable. We use the following corollary from Rudin's Principles of Mathematical Analysis , p. 29: Suppose is at most countable, and, for every , is at most countable. Put Then is at most countable. ""Proof"" 1: Let and for every let . is countable and for every , is finite. Therefore is countable. But , so is countable. ""Proof"" 2: Let and for every let . I think that I can show by induction (if requested) that for each , is countable. Thus is countable. But again,",\mathcal{P} (\mathbb{N}) A \alpha\in A B_{\alpha} T=\bigcup_{\alpha \in A}B_{\alpha} T A = \mathbb{N} \alpha \in A B_{\alpha}=\{S \in \mathcal{P} (\mathbb{N})| \text{the sum of the elements of } S \text{ is } \alpha \} A \alpha \in A B_{\alpha} \bigcup_{\alpha \in A}B_{\alpha} \displaystyle \bigcup_{\alpha \in A}B_{\alpha}=\mathcal{P} (\mathbb{N}) \mathcal{P} (\mathbb{N}) A= \mathbb{N} \alpha \in A B_{\alpha}=\{ S \in \mathcal{P} (\mathbb{N}): |S| = \alpha \} \alpha \in A B_{\alpha} \bigcup_{\alpha \in A}B_{\alpha} \bigcup_{\alpha \in A}B_{\alpha} = \mathcal{P} (\mathbb{N}),"['elementary-set-theory', 'proof-verification', 'fake-proofs']"
63,Why is Axiom of Choice required for the proof of countable union of countable sets is countable?,Why is Axiom of Choice required for the proof of countable union of countable sets is countable?,,"I know that this question has been asked a lot here, some of them are duplicate of each other. Iâ€™ve read every single of them, but my problem has not been resolved. I can just memorize that Axiom of Choice (AC) is needed, but I want to be clear of this, logically. Note : â€œCountableâ€ here means infinitely countable. Recall the proof, it goes like this: First, I have countably many of countable sets. Let me enumerate them to $\langle A_i\rangle_{i\in\mathbb{N}}$. For each $i$, $A_i$ is countable. Since $A_i$ is countable for each $i$, there exists a bijection $h_i:\mathbb{N}\rightarrow A_i$ for each $i$. Then this is where Axiom of Choice (AC) comes into play. There are countably many $A_i$, so I have to choose â€˜countably manyâ€™ times. Then Iâ€™ve got $h_i:\mathbb{N}\rightarrow A_i$ for each $i$ I want. But why is AC needed? What I understand about AC is, if I have a collection of non-empty sets, and I want to construct a new set by picking an element from each set in the collection, then AC allows me to pick them to â€˜constructâ€™ my new set. This is explicitly stated in its logical formula. For example, if I have a collection $\mathcal{A}=\lbrace A_i\rbrace_{i\in\mathbb{N}}$ where $A_i$ is non-empty for each $i$ and I want to construct a new set $\lbrace a_i\rbrace_{i\in\mathbb{N}}$ such that $a_i\in A_i$ for each $i$, then I need AC to guarantee that such set can be made. However, if my collection $\mathcal{A}=\lbrace A_i\rbrace_{i=0}^n$ is finite, then I can construct the new set without AC, i.e., it can be proved that such $\lbrace a_i\rbrace$ can be constructed without the need of AC. But what I donâ€™t understand is, why am I not even permitted to just pick an element and manipulate them? Return to the same example, if I have a collection $\mathcal{A}=\lbrace A_i\rbrace_{i\in\mathbb{N}}$ where $A_i$ is non-empty for each $i$, then I know that there exists $a_i\in A_i$ for each $i$. Am I permitted to manipulate $a_i$ for each $i$?, like constructing $\lbrace a_i\rbrace$ by the Axiom of Pair? Can I construct a set $A_iâ€™:=A_i-\lbrace a_i\rbrace$ for each $i$? Each $a_i$ exists logically, and I want to put bracket around them like this $\lbrace a_i\rbrace$. This is allowed by the Axiom of Pair. Of course, I cannot make $\lbrace a_i\rbrace_{i\in\mathbb{N}}$ since this is not implied by any axiom (even by the Axiom of Union or Axiom of Infinity) except AC. Most answer I found here is, I cannot even 'pick' an element from each set infinitely many times without AC (not to mention constructing a new set from them). Some people even said that each $A_i$ in the proof being countable does not mean that its enumeration is given. Well, in that case, can't I just say that since it does not have enumeration, then it's not countable and hence a contradiction to the assumption? An enumeration must exists. Some might say that it exists but is not given. Then what does 'given' mean in logic? Even in the proof that utilizes AC, we claim that a choice function exists, but not clearly stated 'which' choice function. We only know that it exists and use it to finish the proof. Why is this situation is different from knowing that each bijection $h_i$ exists for each $i$. Why are we permitted to manipulate existing choice function, but not allowed to manipulate existing bijection? Is this related to the fact that it is formulated in First-order logic? Thank you!","I know that this question has been asked a lot here, some of them are duplicate of each other. Iâ€™ve read every single of them, but my problem has not been resolved. I can just memorize that Axiom of Choice (AC) is needed, but I want to be clear of this, logically. Note : â€œCountableâ€ here means infinitely countable. Recall the proof, it goes like this: First, I have countably many of countable sets. Let me enumerate them to $\langle A_i\rangle_{i\in\mathbb{N}}$. For each $i$, $A_i$ is countable. Since $A_i$ is countable for each $i$, there exists a bijection $h_i:\mathbb{N}\rightarrow A_i$ for each $i$. Then this is where Axiom of Choice (AC) comes into play. There are countably many $A_i$, so I have to choose â€˜countably manyâ€™ times. Then Iâ€™ve got $h_i:\mathbb{N}\rightarrow A_i$ for each $i$ I want. But why is AC needed? What I understand about AC is, if I have a collection of non-empty sets, and I want to construct a new set by picking an element from each set in the collection, then AC allows me to pick them to â€˜constructâ€™ my new set. This is explicitly stated in its logical formula. For example, if I have a collection $\mathcal{A}=\lbrace A_i\rbrace_{i\in\mathbb{N}}$ where $A_i$ is non-empty for each $i$ and I want to construct a new set $\lbrace a_i\rbrace_{i\in\mathbb{N}}$ such that $a_i\in A_i$ for each $i$, then I need AC to guarantee that such set can be made. However, if my collection $\mathcal{A}=\lbrace A_i\rbrace_{i=0}^n$ is finite, then I can construct the new set without AC, i.e., it can be proved that such $\lbrace a_i\rbrace$ can be constructed without the need of AC. But what I donâ€™t understand is, why am I not even permitted to just pick an element and manipulate them? Return to the same example, if I have a collection $\mathcal{A}=\lbrace A_i\rbrace_{i\in\mathbb{N}}$ where $A_i$ is non-empty for each $i$, then I know that there exists $a_i\in A_i$ for each $i$. Am I permitted to manipulate $a_i$ for each $i$?, like constructing $\lbrace a_i\rbrace$ by the Axiom of Pair? Can I construct a set $A_iâ€™:=A_i-\lbrace a_i\rbrace$ for each $i$? Each $a_i$ exists logically, and I want to put bracket around them like this $\lbrace a_i\rbrace$. This is allowed by the Axiom of Pair. Of course, I cannot make $\lbrace a_i\rbrace_{i\in\mathbb{N}}$ since this is not implied by any axiom (even by the Axiom of Union or Axiom of Infinity) except AC. Most answer I found here is, I cannot even 'pick' an element from each set infinitely many times without AC (not to mention constructing a new set from them). Some people even said that each $A_i$ in the proof being countable does not mean that its enumeration is given. Well, in that case, can't I just say that since it does not have enumeration, then it's not countable and hence a contradiction to the assumption? An enumeration must exists. Some might say that it exists but is not given. Then what does 'given' mean in logic? Even in the proof that utilizes AC, we claim that a choice function exists, but not clearly stated 'which' choice function. We only know that it exists and use it to finish the proof. Why is this situation is different from knowing that each bijection $h_i$ exists for each $i$. Why are we permitted to manipulate existing choice function, but not allowed to manipulate existing bijection? Is this related to the fact that it is formulated in First-order logic? Thank you!",,"['elementary-set-theory', 'axiom-of-choice']"
64,What in Mathematics cannot be described within set theory? [duplicate],What in Mathematics cannot be described within set theory? [duplicate],,"This question already has an answer here : Are there areas of mathematics (current or future) that cannot be formalized in set theory? (1 answer) Closed 9 years ago . I have begun reading Patrick Suppes' book Axiomatic Set Theory . The first sentence in chapter 1 reads: ""Among the many branches of modern mathematics set theory occupies a unique place: with a few rare exceptions the entities which are studied and analyzed in mathematics may be regarded as certain particular sets or classes of objects."" What are these rare exceptions? What in mathematics cannot be described within set theory?","This question already has an answer here : Are there areas of mathematics (current or future) that cannot be formalized in set theory? (1 answer) Closed 9 years ago . I have begun reading Patrick Suppes' book Axiomatic Set Theory . The first sentence in chapter 1 reads: ""Among the many branches of modern mathematics set theory occupies a unique place: with a few rare exceptions the entities which are studied and analyzed in mathematics may be regarded as certain particular sets or classes of objects."" What are these rare exceptions? What in mathematics cannot be described within set theory?",,"['elementary-set-theory', 'soft-question', 'foundations']"
65,The cartesian product $\mathbb{N} \times \mathbb{N}$ is countable,The cartesian product  is countable,\mathbb{N} \times \mathbb{N},"I'm examining a proof I have read that claims to show that the Cartesian product $\mathbb{N} \times \mathbb{N}$ is countable, and as part of this proof, I am looking to show that the given map is surjective (indeed bijective), but I'm afraid that I can't see why this is the case. I wonder whether you might be able to point me in the right direction? Indeed, the proof begins like this: ""For each $n \in \mathbb{N}$, let $k_n, l_n$ be such that $n = 2^{k_n - 1} \left(2l_n - 1 \right)$; that is, $k_n - 1$ is the power of $2$ in the prime factorisation of $n$, and $2 l_n - 1$ is the (necessarily odd) number $\frac{n}{2^{k_n - 1}}$."" It then states that $n \mapsto \left(k_n , l_n \right)$ is a surjection from $\mathbb{N}$ to $\mathbb{N} \times \mathbb{N}$, and so ends the proof. I can intuitively see why this should be a bijection, I think, but I'm not sure how to make these feelings rigorous? I suppose I'd say that the map is surjective since given any $\left(k_n , l_n \right) \in \mathbb{N} \times \mathbb{N}$ we can simply take $n$ indeed to be equal to $2^{k_n - 1} \left(2l_n - 1 \right)$ and note that $k_n - 1 \geq 0$ and thus $2^{k_n - 1}$  is both greater or equal to one so is a natural number (making the obvious inductive argument, noting that multiplication on $\mathbb{N}$ is closed), and similarly that $2 l_n - 1 \geq 2\cdot 1 - 1 = 1$ and is also a natural number, and thus the product of these two, $n$ must also be a natural number. Is it just as simple as this? I suppose my gut feeling in the proving that the map is injective would be to assume that $2^{k_n - 1} \left(2 l_n - 1 \right) = 2^{k_m - 1} \left(2 l_m - 1 \right)$ and then use the Fundamental Theorem of Arithmetic to conclude that $n = m$. Is this going along the right lines? The 'implicit' definition of the mapping has me a little confused about the approach. On a related, but separate note, I am indeed aware that if $K$ and $L$ are any countable sets, then so is $K \times L$, so trivially, taking the identity mapping we see trivially that this map is bijective and therefore that $\mathbb{N}$ is certainly countable (!), and thus so is $\mathbb{N} \times \mathbb{N}$. Hence, it's not really the statement that I'm interested in, but rather the exciting excursion into number theory that the above alternative proof provides.","I'm examining a proof I have read that claims to show that the Cartesian product $\mathbb{N} \times \mathbb{N}$ is countable, and as part of this proof, I am looking to show that the given map is surjective (indeed bijective), but I'm afraid that I can't see why this is the case. I wonder whether you might be able to point me in the right direction? Indeed, the proof begins like this: ""For each $n \in \mathbb{N}$, let $k_n, l_n$ be such that $n = 2^{k_n - 1} \left(2l_n - 1 \right)$; that is, $k_n - 1$ is the power of $2$ in the prime factorisation of $n$, and $2 l_n - 1$ is the (necessarily odd) number $\frac{n}{2^{k_n - 1}}$."" It then states that $n \mapsto \left(k_n , l_n \right)$ is a surjection from $\mathbb{N}$ to $\mathbb{N} \times \mathbb{N}$, and so ends the proof. I can intuitively see why this should be a bijection, I think, but I'm not sure how to make these feelings rigorous? I suppose I'd say that the map is surjective since given any $\left(k_n , l_n \right) \in \mathbb{N} \times \mathbb{N}$ we can simply take $n$ indeed to be equal to $2^{k_n - 1} \left(2l_n - 1 \right)$ and note that $k_n - 1 \geq 0$ and thus $2^{k_n - 1}$  is both greater or equal to one so is a natural number (making the obvious inductive argument, noting that multiplication on $\mathbb{N}$ is closed), and similarly that $2 l_n - 1 \geq 2\cdot 1 - 1 = 1$ and is also a natural number, and thus the product of these two, $n$ must also be a natural number. Is it just as simple as this? I suppose my gut feeling in the proving that the map is injective would be to assume that $2^{k_n - 1} \left(2 l_n - 1 \right) = 2^{k_m - 1} \left(2 l_m - 1 \right)$ and then use the Fundamental Theorem of Arithmetic to conclude that $n = m$. Is this going along the right lines? The 'implicit' definition of the mapping has me a little confused about the approach. On a related, but separate note, I am indeed aware that if $K$ and $L$ are any countable sets, then so is $K \times L$, so trivially, taking the identity mapping we see trivially that this map is bijective and therefore that $\mathbb{N}$ is certainly countable (!), and thus so is $\mathbb{N} \times \mathbb{N}$. Hence, it's not really the statement that I'm interested in, but rather the exciting excursion into number theory that the above alternative proof provides.",,"['elementary-set-theory', 'cardinals']"
66,What is wrong with ZFC?,What is wrong with ZFC?,,"Why are there seemingly so many who want to use ETCS, or HoTT, or similar as a foundation of mathematics? I'm aware that HoTT has a good few good aspects, but that doesn't entirely explain the strong desire to find something other than ZFC to use, so I ask: What is actually wrong with ZFC that drives this desire? I've heard a few arguments already, though they were a bit vague - I'll list them below. As all the objects of ZFC are sets, in ZFC questions such as ""is $\pi \in 3$"" may be asked, and for some reason just the fact that that may be asked is a problem...but I can't really see the issue. You never need to ask those questions so where would they cause a problem? Another argument is that ZFC has too much ""baggage"" caused by the cumulative hierarchy - we don't want to have to worry about the set theoretical aspects of the elements of the real numbers, for example. This, again, is lost on me - can anyone give an example of where we ever actually feel the need to say anything at all about such aspects? Surely once you've got your definitions and you have a few properties that you want you can proceed to deduce using only those properties and may safely ignore those you don't want to think about? You'll never get a false theorem from ignoring an axiom - when one proves something about groups in general it does not matter what extraneous properties individual groups have, they follow the group axioms so the conclusion is valid. Similarly we know what properties we want the real numbers to have, so surely we can deduce from those without any real issue once we have an object with those (though possibly other) properties? The last apparent issue I'll mention is categories. Apparently ZFC (let's assume with Universes) is a headache for category theorists. Something about ZFC makes category theory harder than it would be in, say, homotopy type theoretic foundations. So far all I've seen is hand waving - can anyone give an example of where ZFC(+U) truly makes life so much more difficult for category theorists? What is the problem? I know that this is a negative post, asking what is wrong with ZFC rather than what is right about HoTT, ETCS, etc, it's just that I've seen many vague references from those disgruntled with the set theory, but not yet any concrete grievances. As with many of my unusual questions, the tags are guesswork.","Why are there seemingly so many who want to use ETCS, or HoTT, or similar as a foundation of mathematics? I'm aware that HoTT has a good few good aspects, but that doesn't entirely explain the strong desire to find something other than ZFC to use, so I ask: What is actually wrong with ZFC that drives this desire? I've heard a few arguments already, though they were a bit vague - I'll list them below. As all the objects of ZFC are sets, in ZFC questions such as ""is $\pi \in 3$"" may be asked, and for some reason just the fact that that may be asked is a problem...but I can't really see the issue. You never need to ask those questions so where would they cause a problem? Another argument is that ZFC has too much ""baggage"" caused by the cumulative hierarchy - we don't want to have to worry about the set theoretical aspects of the elements of the real numbers, for example. This, again, is lost on me - can anyone give an example of where we ever actually feel the need to say anything at all about such aspects? Surely once you've got your definitions and you have a few properties that you want you can proceed to deduce using only those properties and may safely ignore those you don't want to think about? You'll never get a false theorem from ignoring an axiom - when one proves something about groups in general it does not matter what extraneous properties individual groups have, they follow the group axioms so the conclusion is valid. Similarly we know what properties we want the real numbers to have, so surely we can deduce from those without any real issue once we have an object with those (though possibly other) properties? The last apparent issue I'll mention is categories. Apparently ZFC (let's assume with Universes) is a headache for category theorists. Something about ZFC makes category theory harder than it would be in, say, homotopy type theoretic foundations. So far all I've seen is hand waving - can anyone give an example of where ZFC(+U) truly makes life so much more difficult for category theorists? What is the problem? I know that this is a negative post, asking what is wrong with ZFC rather than what is right about HoTT, ETCS, etc, it's just that I've seen many vague references from those disgruntled with the set theory, but not yet any concrete grievances. As with many of my unusual questions, the tags are guesswork.",,"['elementary-set-theory', 'foundations', 'homotopy-type-theory', 'univalent-foundations']"
67,Why do people accept the axiom of choice given the well ordering principle?,Why do people accept the axiom of choice given the well ordering principle?,,"We know without any doubt that the axiom of choice implies (in fact is equivalent to) the well ordering principle. The well ordering principle can't be true! If we take the open interval $(0,1)$ for example, there can't be a least (or most) element. If you give me any element of this set, I could always find one that is greater than or smaller than the one you give me. Isn't this enough to conclude that the axiom of choice - though intuitive - should be viewed as untrue? Thanks.","We know without any doubt that the axiom of choice implies (in fact is equivalent to) the well ordering principle. The well ordering principle can't be true! If we take the open interval $(0,1)$ for example, there can't be a least (or most) element. If you give me any element of this set, I could always find one that is greater than or smaller than the one you give me. Isn't this enough to conclude that the axiom of choice - though intuitive - should be viewed as untrue? Thanks.",,"['elementary-set-theory', 'order-theory', 'axiom-of-choice']"
68,"What does ""closed under ..."" mean?","What does ""closed under ..."" mean?",,"What exactly is meant by ""closed under fill in the blank ""? Thanks.","What exactly is meant by ""closed under fill in the blank ""? Thanks.",,['elementary-set-theory']
69,What does it mean for a set to exist?,What does it mean for a set to exist?,,"Is there a precise meaning of the word 'exist', what does it mean for a set to exist? And what does it mean for a set to 'not exist' ? And what is a set, what is the precise definition of a set?","Is there a precise meaning of the word 'exist', what does it mean for a set to exist? And what does it mean for a set to 'not exist' ? And what is a set, what is the precise definition of a set?",,"['elementary-set-theory', 'soft-question', 'philosophy']"
70,Associativity of Cartesian Product,Associativity of Cartesian Product,,"I have a basic doubt about the associativity of the cartesian product. Well, first wikipedia says that the cartesian product isn't associative, and there's a good argument for it: if $x\in E$, $y\in F$ and $z \in G$ the identity $((x,y), z)=(x,(y,z))$ would imply that $(x,y) =x$ and $(y,z) = z$ so that $((x,y),z)=(x,y,z)$ would mean nothing. That's fine, I like this argument. However, in his book Calculus on Manifolds, Spivak says that the cartesian product is associative. He says: if $A \subset \mathbb{R}^m$, $B\subset \mathbb{R}^n$ and $C \subset \mathbb{R}^p$ then $(A\times B)\times C = A \times (B \times C)$, and both of these are denoted simply by $A \times B \times C$. Well, this confuses me because Spivak is always very rigorous, so that he wouldn't state something that's not true in such way. Is Spivak or Wikipedia right ? Or Spivak's statement only works for subsets of euclidean spaces ? Thanks in advance and sorry if this question is too basic.","I have a basic doubt about the associativity of the cartesian product. Well, first wikipedia says that the cartesian product isn't associative, and there's a good argument for it: if $x\in E$, $y\in F$ and $z \in G$ the identity $((x,y), z)=(x,(y,z))$ would imply that $(x,y) =x$ and $(y,z) = z$ so that $((x,y),z)=(x,y,z)$ would mean nothing. That's fine, I like this argument. However, in his book Calculus on Manifolds, Spivak says that the cartesian product is associative. He says: if $A \subset \mathbb{R}^m$, $B\subset \mathbb{R}^n$ and $C \subset \mathbb{R}^p$ then $(A\times B)\times C = A \times (B \times C)$, and both of these are denoted simply by $A \times B \times C$. Well, this confuses me because Spivak is always very rigorous, so that he wouldn't state something that's not true in such way. Is Spivak or Wikipedia right ? Or Spivak's statement only works for subsets of euclidean spaces ? Thanks in advance and sorry if this question is too basic.",,['elementary-set-theory']
71,Why does one have to check if axioms are true?,Why does one have to check if axioms are true?,,"In Tao's book Analysis 1 , he writes: Thus, from the point of view of logic, we can define equality on a [remark by myself: I think he forgot the word ""type of object"" here] however we please, so long as it obeys the reflexive, symmetry, and transitive axioms, and it is consistent with all other operations on the class of objects under discussion in the sense that the substitution axiom was true for all of those operations. Does he mean that, if one wants to define define equality on a specific type of object (like functions, ordered pairs, for example), one has to check that these axioms of equality (he refers to these four axioms of equality as ""symmetry"", ""reflexivity"", ""transitivity"", and ""substitution"") hold in the sense that one has to prove them? It seems so, because of these two passages: [In section 3.3 Functions] We observe that functions obey the axiom of substitution: if $x=x'$, then $f(x) = f(x')$ (why?). (My answer would be ""because that's an axiom"", but Tao apparently wouldn't accept that.) And after defining equality of sets ($A=B:\iff \forall x(x\in A\iff x\in B)$), Tao writes (on page 39): One can easily verify that this notion of equality is reflexive, symmetric, and transitive (Exercise 3.1.1). Observe that if $x\in A$ and $A = B$, then $x\in B$, by Definition 3.1.4. Thus the ""is an element of"" relation $\in $ obeys the axiom of substitution So he gives the exercise to prove the axioms of equality for sets. Why does one has to prove axioms? Or, put differently: if one can prove these things, why does he state them as axioms?","In Tao's book Analysis 1 , he writes: Thus, from the point of view of logic, we can define equality on a [remark by myself: I think he forgot the word ""type of object"" here] however we please, so long as it obeys the reflexive, symmetry, and transitive axioms, and it is consistent with all other operations on the class of objects under discussion in the sense that the substitution axiom was true for all of those operations. Does he mean that, if one wants to define define equality on a specific type of object (like functions, ordered pairs, for example), one has to check that these axioms of equality (he refers to these four axioms of equality as ""symmetry"", ""reflexivity"", ""transitivity"", and ""substitution"") hold in the sense that one has to prove them? It seems so, because of these two passages: [In section 3.3 Functions] We observe that functions obey the axiom of substitution: if $x=x'$, then $f(x) = f(x')$ (why?). (My answer would be ""because that's an axiom"", but Tao apparently wouldn't accept that.) And after defining equality of sets ($A=B:\iff \forall x(x\in A\iff x\in B)$), Tao writes (on page 39): One can easily verify that this notion of equality is reflexive, symmetric, and transitive (Exercise 3.1.1). Observe that if $x\in A$ and $A = B$, then $x\in B$, by Definition 3.1.4. Thus the ""is an element of"" relation $\in $ obeys the axiom of substitution So he gives the exercise to prove the axioms of equality for sets. Why does one has to prove axioms? Or, put differently: if one can prove these things, why does he state them as axioms?",,"['elementary-set-theory', 'logic']"
72,Are there fewer positive integers than all integers? [duplicate],Are there fewer positive integers than all integers? [duplicate],,"This question already has answers here : How to show the integers have same cardinality as the natural numbers? (4 answers) Closed 8 years ago . In our 6th grade math class we got introduced to the concept of integers. With all the talk about positive and negative, it got me wondering. Is the amount of elements in $\mathbb{Z^+}$ less than the amount of elements in $\mathbb{Z}$? Here is how I thought of it. If we have $\mathbb{Z^+}$ and add one element to the ""back"" of it ($\mathbb{Z}^{\geq-1}$) there are certainly more elements in that new set, so there must be more elements in $\mathbb{Z}$ than in $\mathbb{Z}^+$ but on the other side if we try to express the amount of elements in them ""numerically"" (In a loose sense of the word) they both have $\infty$ elements. So what is the right answer? Is there even one? (Please note I am a bit of a layman when it comes to mathematics) Edit: About the possible duplicate, I am not looking for a bijection between the two sets, I am looking for if they even have the same number of elements and why a bijection shows that they do/don't","This question already has answers here : How to show the integers have same cardinality as the natural numbers? (4 answers) Closed 8 years ago . In our 6th grade math class we got introduced to the concept of integers. With all the talk about positive and negative, it got me wondering. Is the amount of elements in $\mathbb{Z^+}$ less than the amount of elements in $\mathbb{Z}$? Here is how I thought of it. If we have $\mathbb{Z^+}$ and add one element to the ""back"" of it ($\mathbb{Z}^{\geq-1}$) there are certainly more elements in that new set, so there must be more elements in $\mathbb{Z}$ than in $\mathbb{Z}^+$ but on the other side if we try to express the amount of elements in them ""numerically"" (In a loose sense of the word) they both have $\infty$ elements. So what is the right answer? Is there even one? (Please note I am a bit of a layman when it comes to mathematics) Edit: About the possible duplicate, I am not looking for a bijection between the two sets, I am looking for if they even have the same number of elements and why a bijection shows that they do/don't",,[]
73,Examples of transfinite induction,Examples of transfinite induction,,"I know what transfinite induction is, but not sure how it is used to prove something. Can anyone show how transfinite induction is used to prove something? A simple case is OK.","I know what transfinite induction is, but not sure how it is used to prove something. Can anyone show how transfinite induction is used to prove something? A simple case is OK.",,"['elementary-set-theory', 'induction', 'ordinals', 'transfinite-induction']"
74,"What is the order-type of the set of natural numbers, when written in alphabetical order?","What is the order-type of the set of natural numbers, when written in alphabetical order?",,"We are all familiar with the standard nomenclature for the smallish natural numbers, such as one, two, three, ..., one hundred, one hundred one, ..., fifteen    thousand two hundred forty-nine. I have in mind the simple American number naming conventions , together with the names for large numbers . ( Update Names of large numbers seems to be more thorough. Note to Wikipedians: should probably merge those two pages somehow.) Preliminary question. Is there a sensible naming system that provides a canonical name for every natural number? That is, I want a naming system that extends the current naming system sensibly in such a way that every number gets a unique name. Please provide a system and explain why it is sensible. For example, if there were some natural way to extend the Latin naming convention indefinitely, that would be great. Let me assume that some of you will be able to provide such a naming system. Main Question. What is the order-type of the set of natural numbers, when written in alphabetical order? For example, the order will not be the same as the order $\omega$ of the natural number themselves, since presumably there will be infinitely many numbers starting with ""o"", as in one hundred, one million, one thousand, and so on, and these will all be alphabetically preceding two hundred, two million, two thousand and so on. So the order type will probably be related naturally $L\times 26$ for some order $L$ , or actually, less than $26$ , since probably not every letter will be a legitimate first letter of a number name. It is conceivable that the order type will depend on syntactic features of the naming convention. Here is a part of the order, for numbers up to 100: (from hervÃ© graumann 1988 ) 1) eight  2) eighteen  3) eighty  4) eighty-eight  5) eighty-five  6) eighty-four  7) eighty-nine  8) eighty-one  9) eighty-seven  10) eighty-six  11) eighty-three  12) eighty-two  13) eleven  14) fifteen  15) fifty  16) fifty-eight  17) fifty-five  18) fifty-four  19) fifty-nine  20) fifty-one  21) fifty-seven  22) fifty-six  23) fifty-three  24) fifty-two  25) five  26) forty  27) forty-eight  28) forty-five  29) forty-four  30) forty-nine  31) forty-one  32) forty-seven  33) forty-six  34) forty-three  35) forty-two  36) four  37) fourteen  38) hundred  39) nine  40) nineteen  41) ninety  42) ninety-eight  43) ninety-five  44) ninety-four  45) ninety-nine  46) ninety-one  47) ninety-seven  48) ninety-six  49) ninety-three  50) ninety-two  51) one  52) seven  53) seventeen  54) seventy  55) seventy-eight  56) seventy-five  57) seventy-four  58) seventy-nine  59) seventy-one  60) seventy-seven  61) seventy-six  62) seventy-three  63) seventy-two  64) six  65) sixteen  66) sixty  67) sixty-eight  68) sixty-five  69) sixty-four  70) sixty-nine  71) sixty-one  72) sixty-seven  73) sixty-six  74) sixty-three  75) sixty-two  76) ten  77) thirteen  78) thirty  79) thirty-eight  80) thirty-five  81) thirty-four  82) thirty-nine  83) thirty-one  84) thirty-seven  85) thirty-six  86) thirty-three  87) thirty-two  88) three  89) twelve  90) twenty  91) twenty-eight  92) twenty-five  93) twenty-four  94) twenty-nine  95) twenty-one  96) twenty-seven  97) twenty-six  98) twenty-three  99) twenty-two  100) two  101) zero Let me add that I don't necessarily expect that the order is a well-order. For example, if we have a naming convention whereby $10^k$ is represented for large $k$ simply by repeating ""penpenpenpen $\cdots$ pen"", then we could make a descending sequence via penpenpenpen $\cdots$ pen twelve, which would descend as the number of pen's increased, since we would be replacing t with p.","We are all familiar with the standard nomenclature for the smallish natural numbers, such as one, two, three, ..., one hundred, one hundred one, ..., fifteen    thousand two hundred forty-nine. I have in mind the simple American number naming conventions , together with the names for large numbers . ( Update Names of large numbers seems to be more thorough. Note to Wikipedians: should probably merge those two pages somehow.) Preliminary question. Is there a sensible naming system that provides a canonical name for every natural number? That is, I want a naming system that extends the current naming system sensibly in such a way that every number gets a unique name. Please provide a system and explain why it is sensible. For example, if there were some natural way to extend the Latin naming convention indefinitely, that would be great. Let me assume that some of you will be able to provide such a naming system. Main Question. What is the order-type of the set of natural numbers, when written in alphabetical order? For example, the order will not be the same as the order of the natural number themselves, since presumably there will be infinitely many numbers starting with ""o"", as in one hundred, one million, one thousand, and so on, and these will all be alphabetically preceding two hundred, two million, two thousand and so on. So the order type will probably be related naturally for some order , or actually, less than , since probably not every letter will be a legitimate first letter of a number name. It is conceivable that the order type will depend on syntactic features of the naming convention. Here is a part of the order, for numbers up to 100: (from hervÃ© graumann 1988 ) 1) eight  2) eighteen  3) eighty  4) eighty-eight  5) eighty-five  6) eighty-four  7) eighty-nine  8) eighty-one  9) eighty-seven  10) eighty-six  11) eighty-three  12) eighty-two  13) eleven  14) fifteen  15) fifty  16) fifty-eight  17) fifty-five  18) fifty-four  19) fifty-nine  20) fifty-one  21) fifty-seven  22) fifty-six  23) fifty-three  24) fifty-two  25) five  26) forty  27) forty-eight  28) forty-five  29) forty-four  30) forty-nine  31) forty-one  32) forty-seven  33) forty-six  34) forty-three  35) forty-two  36) four  37) fourteen  38) hundred  39) nine  40) nineteen  41) ninety  42) ninety-eight  43) ninety-five  44) ninety-four  45) ninety-nine  46) ninety-one  47) ninety-seven  48) ninety-six  49) ninety-three  50) ninety-two  51) one  52) seven  53) seventeen  54) seventy  55) seventy-eight  56) seventy-five  57) seventy-four  58) seventy-nine  59) seventy-one  60) seventy-seven  61) seventy-six  62) seventy-three  63) seventy-two  64) six  65) sixteen  66) sixty  67) sixty-eight  68) sixty-five  69) sixty-four  70) sixty-nine  71) sixty-one  72) sixty-seven  73) sixty-six  74) sixty-three  75) sixty-two  76) ten  77) thirteen  78) thirty  79) thirty-eight  80) thirty-five  81) thirty-four  82) thirty-nine  83) thirty-one  84) thirty-seven  85) thirty-six  86) thirty-three  87) thirty-two  88) three  89) twelve  90) twenty  91) twenty-eight  92) twenty-five  93) twenty-four  94) twenty-nine  95) twenty-one  96) twenty-seven  97) twenty-six  98) twenty-three  99) twenty-two  100) two  101) zero Let me add that I don't necessarily expect that the order is a well-order. For example, if we have a naming convention whereby is represented for large simply by repeating ""penpenpenpen pen"", then we could make a descending sequence via penpenpenpen pen twelve, which would descend as the number of pen's increased, since we would be replacing t with p.",\omega L\times 26 L 26 10^k k \cdots \cdots,"['elementary-number-theory', 'elementary-set-theory', 'logic', 'order-theory', 'puzzle']"
75,Is $\{\emptyset\}$ a subset of $\{\{\emptyset\}\}$?,Is  a subset of ?,\{\emptyset\} \{\{\emptyset\}\},"$\{\emptyset\}$ is a set containing the empty set. Is $\{\emptyset\}$ a subset of $\{\{\emptyset\}\}$? My hypothesis is yes by looking at the form of ""the superset $\{\{\emptyset\}\}$"" which contains ""the subset $\{\emptyset\}$"".","$\{\emptyset\}$ is a set containing the empty set. Is $\{\emptyset\}$ a subset of $\{\{\emptyset\}\}$? My hypothesis is yes by looking at the form of ""the superset $\{\{\emptyset\}\}$"" which contains ""the subset $\{\emptyset\}$"".",,['elementary-set-theory']
76,How do you prove Well-Ordering without Mathematical Induction? (and vice-versa),How do you prove Well-Ordering without Mathematical Induction? (and vice-versa),,"Here is my attempt to prove the Well-Ordering Principle, i.e. that any non-empty subset of $\Bbb N$ , the set of natural numbers, has a minimum element. Proof . Suppose there exists a non-empty subset $S$ of $\Bbb N$ such that $S$ has NO minimum element. Define $A = \left\{n\in \Bbb N : (\forall s\in S)(n \leq s)\right\}$ . It is obvious that $1\in A$ . Suppose $n\in A$ , then for each $s \in S$ , there exists $q \in N$ such that $n + q = s$ . Since $q \ge 1$ , $n+1 \leq s$ , for all $s\in S$ . By Principle of mathematical induction, $A = \Bbb N$ . Take any $s_0 âˆˆ S$ , then $(\forall s\in S)(s_0 \leq s)$ . (This contradicts that $S$ has no minimum element). How do I prove the statement without invoking Mathematical Induction? Also, I read that the proof of Principle of Mathematical Induction makes use of Well-Ordering. Can it be proven independently of Well-Ordering too?","Here is my attempt to prove the Well-Ordering Principle, i.e. that any non-empty subset of , the set of natural numbers, has a minimum element. Proof . Suppose there exists a non-empty subset of such that has NO minimum element. Define . It is obvious that . Suppose , then for each , there exists such that . Since , , for all . By Principle of mathematical induction, . Take any , then . (This contradicts that has no minimum element). How do I prove the statement without invoking Mathematical Induction? Also, I read that the proof of Principle of Mathematical Induction makes use of Well-Ordering. Can it be proven independently of Well-Ordering too?",\Bbb N S \Bbb N S A = \left\{n\in \Bbb N : (\forall s\in S)(n \leq s)\right\} 1\in A n\in A s \in S q \in N n + q = s q \ge 1 n+1 \leq s s\in S A = \Bbb N s_0 âˆˆ S (\forall s\in S)(s_0 \leq s) S,"['elementary-set-theory', 'induction']"
77,Prove/Disprove that if two sets have the same power set then they are the same set,Prove/Disprove that if two sets have the same power set then they are the same set,,"I am really sure that if two sets have the same power set, then they are the same set. I just am wondering how does one exactly go about proving/showing this? I'm usually wrong, so if anyone can show me an example where this fails, I'd like that too. The homework just asks for true/false, but I'm wanting to show it if possible. My thoughts are that since the power set is by definition the set of all subsets of a set, if each of the two power sets are identical, we have an identity map between each set, thus it's indistinguishable which power set is a given set's power set. I hope that wasn't verbose. Since a set has only one power set, we can conclude they are in fact the same set.","I am really sure that if two sets have the same power set, then they are the same set. I just am wondering how does one exactly go about proving/showing this? I'm usually wrong, so if anyone can show me an example where this fails, I'd like that too. The homework just asks for true/false, but I'm wanting to show it if possible. My thoughts are that since the power set is by definition the set of all subsets of a set, if each of the two power sets are identical, we have an identity map between each set, thus it's indistinguishable which power set is a given set's power set. I hope that wasn't verbose. Since a set has only one power set, we can conclude they are in fact the same set.",,['elementary-set-theory']
78,What's the meaning of a set to the power of another set?,What's the meaning of a set to the power of another set?,,"${ \mathbb{N} }^{ \left\{ 0,1 \right\}  }$ and ${ \left\{ 0,1 \right\}  }^{ \mathbb{N} }$ to be more specific, and is there a countable subset in each one of them? How do I find them?","${ \mathbb{N} }^{ \left\{ 0,1 \right\}  }$ and ${ \left\{ 0,1 \right\}  }^{ \mathbb{N} }$ to be more specific, and is there a countable subset in each one of them? How do I find them?",,['elementary-set-theory']
79,"If the infinite cardinals aleph-null, aleph-two, etc. continue indefinitely, is there any meaning in the idea of aleph-aleph-null?","If the infinite cardinals aleph-null, aleph-two, etc. continue indefinitely, is there any meaning in the idea of aleph-aleph-null?",,"If the infinite cardinals aleph-null, aleph-two, etc. continue indefinitely, is there any meaning in the idea of aleph-aleph-null? Apologies if this isn't a sensible question, I really don't know too much about these infinite cardinals aside from the basics. I did, however, think that the idea of the ""aleph-null""th aleph number was interesting enough to base my username on and my own attempts did not prove fruitful, so I was wondering if anyone here could shed some light. Thanks! For clarity: I'm asking about $\aleph_{\aleph_0}$ . Thanks! P.S. I was somewhat unsure about the tags for this, sorry if I accidentally placed it in the wrong category.","If the infinite cardinals aleph-null, aleph-two, etc. continue indefinitely, is there any meaning in the idea of aleph-aleph-null? Apologies if this isn't a sensible question, I really don't know too much about these infinite cardinals aside from the basics. I did, however, think that the idea of the ""aleph-null""th aleph number was interesting enough to base my username on and my own attempts did not prove fruitful, so I was wondering if anyone here could shed some light. Thanks! For clarity: I'm asking about $\aleph_{\aleph_0}$ . Thanks! P.S. I was somewhat unsure about the tags for this, sorry if I accidentally placed it in the wrong category.",,"['elementary-set-theory', 'cardinals']"
80,what is total order - explanation please,what is total order - explanation please,,"sorry for the dumbest question ever, but i want to understand total order in an intuitive way,  this is the defition of total order: i) If $a â‰¤ b$ and $b â‰¤ a$ then $a = b$ (antisymmetry); ii) If $a â‰¤ b$ and $b â‰¤ c$ then $a â‰¤ c$ (transitivity); iii) $a â‰¤ b$ or $b â‰¤ a$ (totality). totality means that any pair of the total ordered pair is mutually comparable. i dont understand what they mean under comparable , what is the defition of comparability? i can also compare the elements of partial order, where is problem? why is partial order not not mutually comparable? can someone explain me please in simple words :(","sorry for the dumbest question ever, but i want to understand total order in an intuitive way,  this is the defition of total order: i) If $a â‰¤ b$ and $b â‰¤ a$ then $a = b$ (antisymmetry); ii) If $a â‰¤ b$ and $b â‰¤ c$ then $a â‰¤ c$ (transitivity); iii) $a â‰¤ b$ or $b â‰¤ a$ (totality). totality means that any pair of the total ordered pair is mutually comparable. i dont understand what they mean under comparable , what is the defition of comparability? i can also compare the elements of partial order, where is problem? why is partial order not not mutually comparable? can someone explain me please in simple words :(",,"['elementary-set-theory', 'definition', 'order-theory']"
81,Are there more rational numbers than integers?,Are there more rational numbers than integers?,,"I've been told that there are precisely the same number of rationals as there are of integers. The set of rationals is countably infinite, therefore every rational can be associated with a positive integer, therefore there are the same number of rationals as integers. I've ignored sign-related issues, but these are easily handled. To count the rationals, consider sets of rationals where the denominator and numerator are positive and sum to some constant. If the constant is 2 there's 1/1. If the constant is 3, there's 1/2 and 2/1. If the constant is 4 there's 1/3, 2/2 and 3/1. So far we have counted out 6 rationals, and if we continue long enough, we will eventually count to any specific rational you care to mention. The trouble is, I find this very hard to accept. I have two reasons. First, this logic seems to assume that infinity is a finite number. You can count to and number any rational, but you cannot number all rationals. You can't even count all positive integers. Infinity is code for ""no matter how far you count, you have never counted enough"". If it were possible to count to infinity, it would be possible to count one step less and stop at count infinity-1 which must be different to infinity. The second reason is that it's very easy to construct alternative mappings. Between zero and one there are infinitely many rational numbers, between one and two there are infinitely many rational numbers, and so on. To me, this seems a much more reasonable approach, implying that there are infinite rational numbers for every integer. But even then, this is just one of many alternative ways to map between ranges of rationals and ranges of integers. Since you can count the rationals, you can equally count stepping by any amount for each rational. You can use 1..10 for the first rational and 11..20 for the second etc. Or 1..100 and 101..200 etc, or 1..1000 and 1001..2000 etc. You can map finite range of integers of any size to each rational this way and, since there is no finite upper bound to the stepping amount, you could argue there are potentially infinite integers for every single rational. So... can anyone convince me that there is a single unambiguous correct answer to this question? Are there more rational numbers than integers, or not? EDIT Although I've already accepted an answer, I'll just add some extra context. My reason for questioning this relates to the Hilbert space-filling curve. I find this interesting because of applications to multi-dimensional indexing data structures in software. However, I found Hilberts claim that the Hilbert curve literally filled a multi-dimensional space hard to accept. As mentioned in a comment below, a one meter line segment and a two meter line segment can both be seen as sets of points and, but (by the logic in answers below), those two sets are both the same size (cardinality). Yet we would not claim the two line segments are both the same size. The lengths are finite and different. Going beyond this, we most certainly wouldn't claim that the size of any finite straight line segment is equal to the size of a one-meter-by-one-meter square. The Hilbert curve reasoning makes sense now - the set of points in the curve is equal to the set of points in the space it fills. Previously, I was thinking too much about basic geometry, and couldn't accept the size of a curve as being equal to the size of a space. However, this isn't based on a fallacious counting-to-infinity argument - it's a necessary consequence of an alternative line of reasoning. The two constructs are equal because they both represent the same set of points. The area/volume/etc of the curve follows from that.","I've been told that there are precisely the same number of rationals as there are of integers. The set of rationals is countably infinite, therefore every rational can be associated with a positive integer, therefore there are the same number of rationals as integers. I've ignored sign-related issues, but these are easily handled. To count the rationals, consider sets of rationals where the denominator and numerator are positive and sum to some constant. If the constant is 2 there's 1/1. If the constant is 3, there's 1/2 and 2/1. If the constant is 4 there's 1/3, 2/2 and 3/1. So far we have counted out 6 rationals, and if we continue long enough, we will eventually count to any specific rational you care to mention. The trouble is, I find this very hard to accept. I have two reasons. First, this logic seems to assume that infinity is a finite number. You can count to and number any rational, but you cannot number all rationals. You can't even count all positive integers. Infinity is code for ""no matter how far you count, you have never counted enough"". If it were possible to count to infinity, it would be possible to count one step less and stop at count infinity-1 which must be different to infinity. The second reason is that it's very easy to construct alternative mappings. Between zero and one there are infinitely many rational numbers, between one and two there are infinitely many rational numbers, and so on. To me, this seems a much more reasonable approach, implying that there are infinite rational numbers for every integer. But even then, this is just one of many alternative ways to map between ranges of rationals and ranges of integers. Since you can count the rationals, you can equally count stepping by any amount for each rational. You can use 1..10 for the first rational and 11..20 for the second etc. Or 1..100 and 101..200 etc, or 1..1000 and 1001..2000 etc. You can map finite range of integers of any size to each rational this way and, since there is no finite upper bound to the stepping amount, you could argue there are potentially infinite integers for every single rational. So... can anyone convince me that there is a single unambiguous correct answer to this question? Are there more rational numbers than integers, or not? EDIT Although I've already accepted an answer, I'll just add some extra context. My reason for questioning this relates to the Hilbert space-filling curve. I find this interesting because of applications to multi-dimensional indexing data structures in software. However, I found Hilberts claim that the Hilbert curve literally filled a multi-dimensional space hard to accept. As mentioned in a comment below, a one meter line segment and a two meter line segment can both be seen as sets of points and, but (by the logic in answers below), those two sets are both the same size (cardinality). Yet we would not claim the two line segments are both the same size. The lengths are finite and different. Going beyond this, we most certainly wouldn't claim that the size of any finite straight line segment is equal to the size of a one-meter-by-one-meter square. The Hilbert curve reasoning makes sense now - the set of points in the curve is equal to the set of points in the space it fills. Previously, I was thinking too much about basic geometry, and couldn't accept the size of a curve as being equal to the size of a space. However, this isn't based on a fallacious counting-to-infinity argument - it's a necessary consequence of an alternative line of reasoning. The two constructs are equal because they both represent the same set of points. The area/volume/etc of the curve follows from that.",,['elementary-set-theory']
82,Why is the empty set considered a set?,Why is the empty set considered a set?,,"I have recently been thinking about the following question: Why is $\emptyset$ considered as a set? The definition of a set is: a well-defined collection of ""elements"". So my question arose, that $\emptyset$ is well defined but does not contain any elements which should be there according to the set's definition.","I have recently been thinking about the following question: Why is considered as a set? The definition of a set is: a well-defined collection of ""elements"". So my question arose, that is well defined but does not contain any elements which should be there according to the set's definition.",\emptyset \emptyset,"['elementary-set-theory', 'terminology', 'definition']"
83,What are the ways of proving that the Cantor set is uncountable apart from Cantor diagonalization?,What are the ways of proving that the Cantor set is uncountable apart from Cantor diagonalization?,,What are the ways of proving that the Cantor set is uncountable apart from Cantor diagonalization? Are there any based on dynamical systems?,What are the ways of proving that the Cantor set is uncountable apart from Cantor diagonalization? Are there any based on dynamical systems?,,['elementary-set-theory']
84,A simple example of an uncountable set that is not $\mathbb{R}$,A simple example of an uncountable set that is not,\mathbb{R},"Let's suppose that I have only defined $\mathbb{N}$ and then I define the terms finite and infinite set, and also countable and uncountable set. I can think of some examples of finite, infinite and countable sets, but what about uncountable sets? I think the simplest example is $\mathbb{R}$. But as I don't have it defined yet then I cannot use it. What may be a good and simple example in this case?. By simple I mean easy to verify without knowing anything about ordinals, cardinals or $\mathbb{R}$.","Let's suppose that I have only defined $\mathbb{N}$ and then I define the terms finite and infinite set, and also countable and uncountable set. I can think of some examples of finite, infinite and countable sets, but what about uncountable sets? I think the simplest example is $\mathbb{R}$. But as I don't have it defined yet then I cannot use it. What may be a good and simple example in this case?. By simple I mean easy to verify without knowing anything about ordinals, cardinals or $\mathbb{R}$.",,['elementary-set-theory']
85,Can a countable set contain uncountably many infinite subsets such that the intersection of any two such distinct subsets is finite?,Can a countable set contain uncountably many infinite subsets such that the intersection of any two such distinct subsets is finite?,,Can a countable set contain uncountably many infinite subsets such that the intersection of any two such distinct subsets is finite?,Can a countable set contain uncountably many infinite subsets such that the intersection of any two such distinct subsets is finite?,,['elementary-set-theory']
86,Proof that the empty set is a relation,Proof that the empty set is a relation,,"In the book Naive Set Theory , Halmos mentions that the ""The least exciting relation is the empty one."" and proves that the empty set is a set of ordered pairs because there is no element of the empty set that is not an ordered pair. Since the empty set is a set of ordered pairs, it follows that it is a relation. I understand this line of reasoning but couldn't I use that same line of reasoning to prove that the empty set is a set of singletons? And since the empty set is a set of singletons (because it contains no elements which are not singletons) it is not a relation (because a relation is a set of ordered pairs, not singletons). Why is this reasoning invalid?","In the book Naive Set Theory , Halmos mentions that the ""The least exciting relation is the empty one."" and proves that the empty set is a set of ordered pairs because there is no element of the empty set that is not an ordered pair. Since the empty set is a set of ordered pairs, it follows that it is a relation. I understand this line of reasoning but couldn't I use that same line of reasoning to prove that the empty set is a set of singletons? And since the empty set is a set of singletons (because it contains no elements which are not singletons) it is not a relation (because a relation is a set of ordered pairs, not singletons). Why is this reasoning invalid?",,"['elementary-set-theory', 'definition', 'relations']"
87,Non-existence of a Surjective Function from a Set to Its Subsets (Cantor's theorem),Non-existence of a Surjective Function from a Set to Its Subsets (Cantor's theorem),,"Show that: Let A be a set and let $P(A)$ be the set of all subsets of $A$. Then there is no surjection $f: Aâ†’P(A)$. Here is what I thought: if $A=\{a,b\}$ then it has only two elements where $P(A)=\{âˆ…,\{a\},\{b\},\{a,b\}\}$ has 4 elements. Therefore $f:Aâ†’P(A)$ cannot be surjective. But I have some problems: 1) How is it possible that any $f$ function to take $\{a\}$ from set $A$ to $\{a,b\}$? Maybe because I am thinking mainly about functions with real values like $f(x)=2x$, I find it a little bit strange that a function to take an element of a set to another set which has more elements. Is it possible? edit: Now I thought that if $f(x)$ is $\sqrt{x}$, then $f(4)=Â±2$ which means it took an element from a set to a set which has 2 elements. But still I find it kind of strange to denote $f(\{a\})=\{a,b,c,...\}$ 2) How can I construct a explicit proof for this question? Regards","Show that: Let A be a set and let $P(A)$ be the set of all subsets of $A$. Then there is no surjection $f: Aâ†’P(A)$. Here is what I thought: if $A=\{a,b\}$ then it has only two elements where $P(A)=\{âˆ…,\{a\},\{b\},\{a,b\}\}$ has 4 elements. Therefore $f:Aâ†’P(A)$ cannot be surjective. But I have some problems: 1) How is it possible that any $f$ function to take $\{a\}$ from set $A$ to $\{a,b\}$? Maybe because I am thinking mainly about functions with real values like $f(x)=2x$, I find it a little bit strange that a function to take an element of a set to another set which has more elements. Is it possible? edit: Now I thought that if $f(x)$ is $\sqrt{x}$, then $f(4)=Â±2$ which means it took an element from a set to a set which has 2 elements. But still I find it kind of strange to denote $f(\{a\})=\{a,b,c,...\}$ 2) How can I construct a explicit proof for this question? Regards",,['elementary-set-theory']
88,Why cannot a set be its own element?,Why cannot a set be its own element?,,"When I study Topology, I met with a problem. On my book, it says 'we cannot admit that there exists a set whose members are all the topological spaces. That will lead to a logical contradiction, that there will be a set who is a member of itself.' But why we cannot have a set who is a member of itself?","When I study Topology, I met with a problem. On my book, it says 'we cannot admit that there exists a set whose members are all the topological spaces. That will lead to a logical contradiction, that there will be a set who is a member of itself.' But why we cannot have a set who is a member of itself?",,"['elementary-set-theory', 'paradoxes']"
89,Simplest Example of a Poset that is not a Lattice,Simplest Example of a Poset that is not a Lattice,,"A partially ordered set $(X, \leq)$ is called a lattice if for every pair of elements $x,y \in X$ both the infimum and suprememum of the set $\{x,y\}$ exists. I'm trying to get an intuition for how a partially ordered set can fail to be a lattice. In $\mathbb{R}$, for example, once two elements are selected the completeness of the real numbers guarantees the existence of both the infimum and supremum. Now, if we restrict our attention to a nondegenerate interval $(a,b)$ it is clear that no two points in $(a,b)$ have either a suprememum or infimum in $(a,b)$. Is this the right way to think of a poset that is not a lattice? Is there perhaps a more fundamental example that would yield further clarity?","A partially ordered set $(X, \leq)$ is called a lattice if for every pair of elements $x,y \in X$ both the infimum and suprememum of the set $\{x,y\}$ exists. I'm trying to get an intuition for how a partially ordered set can fail to be a lattice. In $\mathbb{R}$, for example, once two elements are selected the completeness of the real numbers guarantees the existence of both the infimum and supremum. Now, if we restrict our attention to a nondegenerate interval $(a,b)$ it is clear that no two points in $(a,b)$ have either a suprememum or infimum in $(a,b)$. Is this the right way to think of a poset that is not a lattice? Is there perhaps a more fundamental example that would yield further clarity?",,"['elementary-set-theory', 'examples-counterexamples', 'order-theory', 'lattice-orders']"
90,Are there more transcendental numbers or irrational numbers that are not transcendental?,Are there more transcendental numbers or irrational numbers that are not transcendental?,,"This is not a question of counting (obviously), but more of a question of bigger vs. smaller infinities. I really don't know where to even start with this one whatsoever. Any help? Or is it unsolvable?","This is not a question of counting (obviously), but more of a question of bigger vs. smaller infinities. I really don't know where to even start with this one whatsoever. Any help? Or is it unsolvable?",,"['elementary-set-theory', 'infinity']"
91,"Why KÃ¶nig's lemma isn't ""obvious""?","Why KÃ¶nig's lemma isn't ""obvious""?",,"I keep facing KÃ¶nig's lemma ""Every finitely branching infinite tree over $\mathbb{N}$ has infinite branch"". Why it is not taken ""obvious"" but needs a careful proof? It seems somewhat obvious, but I guess I overlook something.","I keep facing KÃ¶nig's lemma ""Every finitely branching infinite tree over has infinite branch"". Why it is not taken ""obvious"" but needs a careful proof? It seems somewhat obvious, but I guess I overlook something.",\mathbb{N},"['elementary-set-theory', 'logic']"
92,How does the axiom of regularity forbid self containing sets?,How does the axiom of regularity forbid self containing sets?,,"The axiom of regularity basically says that a set must be disjoint from at least one element. I have heard this disproves self containing sets. I see how it could prevent $A=\{A\}$, but it would seem to do nothing about $B=\{B,\emptyset\}$. It is disjoint from $\emptyset$. What is a disproof of the existence of $B$, and how is it related to the axiom of regularity?","The axiom of regularity basically says that a set must be disjoint from at least one element. I have heard this disproves self containing sets. I see how it could prevent $A=\{A\}$, but it would seem to do nothing about $B=\{B,\emptyset\}$. It is disjoint from $\emptyset$. What is a disproof of the existence of $B$, and how is it related to the axiom of regularity?",,"['elementary-set-theory', 'axioms']"
93,Is there a set whose power set is countably infinite? [duplicate],Is there a set whose power set is countably infinite? [duplicate],,"This question already has answers here : Existence in ZF of a set with countable power set (2 answers) Closed 6 years ago . Does there exist a set whose power set is countably infinite? I know for sure that if a set has a finite number of elements, then its power set must have a finite number of elements, and if a set has an infinite number of elements, then its power set must have an infinite number of elements (possibly uncountably many elements). Then, there must not exist something like that (which I stated at first). Am I right? Please someone clarify it.","This question already has answers here : Existence in ZF of a set with countable power set (2 answers) Closed 6 years ago . Does there exist a set whose power set is countably infinite? I know for sure that if a set has a finite number of elements, then its power set must have a finite number of elements, and if a set has an infinite number of elements, then its power set must have an infinite number of elements (possibly uncountably many elements). Then, there must not exist something like that (which I stated at first). Am I right? Please someone clarify it.",,"['elementary-set-theory', 'cardinals']"
94,Set Addition vs. Set Union,Set Addition vs. Set Union,,"Given two sets $A$ and $B$, what is the difference between $A + B$ and $A \cup B$? For example, if $A = \left\{ a, b, c \right\}$ and $B = \left\{ d, e, f \right\}$, what are $A + B$ and $A \cup B$, respectively?","Given two sets $A$ and $B$, what is the difference between $A + B$ and $A \cup B$? For example, if $A = \left\{ a, b, c \right\}$ and $B = \left\{ d, e, f \right\}$, what are $A + B$ and $A \cup B$, respectively?",,"['elementary-set-theory', 'arithmetic']"
95,Definition of the Infinite Cartesian Product,Definition of the Infinite Cartesian Product,,"(1) If $X$ and $Y$ are two sets, we define the Cartesian product $X \times Y$ as the set of ordered pairs $(x,y)$, such that $x \in X$ and $y \in Y$. (2) On the other hand [Folland, Real Analysis, page 4], if $\{X_\alpha\}_{\alpha \in A}$ is infinite indexed family of sets, their Cartesian product $$ \prod_{\alpha \in A}X_\alpha $$ is defined as the set of maps $f: A \to \bigcup\limits_{\alpha \in A} X_\alpha$ such that $f(\alpha) \in X_\alpha$ for every $\alpha \in A$. After saying this, Folland remarks: it should be noted, and promptly forgotten, that when $A = \{1,2\}$, the previous definition  of $X_1 \times X_2$ [that's (1) above] is set-theoretically different from the present definition of $\prod_1^2 X_j$ [that's (2) above]. Indeed, the latter concept depends on the mappings, which are defined in terms of the former one. I am not grasping this remark. Specifically, here are my questions. Question 1 : How is (2) set-theoretically different from (1)? A simple illustrative example? Question 2 : If (1) is extended to infinite families, which definition would be stronger? A simple illustrative example? Question 3 : Why should this be ""promptly forgotten""? I'll probably have more questions depending on the type of answers I'll get to these. Thanks!","(1) If $X$ and $Y$ are two sets, we define the Cartesian product $X \times Y$ as the set of ordered pairs $(x,y)$, such that $x \in X$ and $y \in Y$. (2) On the other hand [Folland, Real Analysis, page 4], if $\{X_\alpha\}_{\alpha \in A}$ is infinite indexed family of sets, their Cartesian product $$ \prod_{\alpha \in A}X_\alpha $$ is defined as the set of maps $f: A \to \bigcup\limits_{\alpha \in A} X_\alpha$ such that $f(\alpha) \in X_\alpha$ for every $\alpha \in A$. After saying this, Folland remarks: it should be noted, and promptly forgotten, that when $A = \{1,2\}$, the previous definition  of $X_1 \times X_2$ [that's (1) above] is set-theoretically different from the present definition of $\prod_1^2 X_j$ [that's (2) above]. Indeed, the latter concept depends on the mappings, which are defined in terms of the former one. I am not grasping this remark. Specifically, here are my questions. Question 1 : How is (2) set-theoretically different from (1)? A simple illustrative example? Question 2 : If (1) is extended to infinite families, which definition would be stronger? A simple illustrative example? Question 3 : Why should this be ""promptly forgotten""? I'll probably have more questions depending on the type of answers I'll get to these. Thanks!",,"['elementary-set-theory', 'products']"
96,Subset of a finite set is finite,Subset of a finite set is finite,,"We define $A$ to be a finite set if there is a bijection between $A$ and a set of the form $\{0,\ldots,n-1\}$ for some $n\in\mathbb N$. How can we prove that a subset of a finite set is finite? It is of course sufficient to show that for a subset of $\{0,\ldots,n-1\}$. But how do I do that?","We define $A$ to be a finite set if there is a bijection between $A$ and a set of the form $\{0,\ldots,n-1\}$ for some $n\in\mathbb N$. How can we prove that a subset of a finite set is finite? It is of course sufficient to show that for a subset of $\{0,\ldots,n-1\}$. But how do I do that?",,['elementary-set-theory']
97,Is there a shorthand notation for adding an element to a set?,Is there a shorthand notation for adding an element to a set?,,"I know that if you want to refer to the set $ A $ with the element $ x $ added, you can write $ A \cup \{x\} $. But is there a common shorthand for this?","I know that if you want to refer to the set $ A $ with the element $ x $ added, you can write $ A \cup \{x\} $. But is there a common shorthand for this?",,"['elementary-set-theory', 'notation']"
98,"Why is the empty set described as ""unique"" when it is a subset of every set?","Why is the empty set described as ""unique"" when it is a subset of every set?",,"I am completely new to set theory, so please bear with me. I have watched a youtube video that is an introduction to set theory and have read enough basic websites to have learned that the empty set is a subset of every set, and that it is unique. I understand the first proposition, but not the second. How can it be unique if there's one in every set? Unless the word ""unique"" means something different in set theory to everyday usage. Does it just mean its properties are unique?","I am completely new to set theory, so please bear with me. I have watched a youtube video that is an introduction to set theory and have read enough basic websites to have learned that the empty set is a subset of every set, and that it is unique. I understand the first proposition, but not the second. How can it be unique if there's one in every set? Unless the word ""unique"" means something different in set theory to everyday usage. Does it just mean its properties are unique?",,['elementary-set-theory']
99,Covering the Euclidean plane with constructible lines and circles,Covering the Euclidean plane with constructible lines and circles,,"It is a well-known fact that the set of points which are finitely constructible with straightedge and compass (starting with two points $0$ and $1$) doesn't cover the Euclidean plane $\mathbb{R}\times \mathbb{R}$ because only $\mathbb{Q}^{\sqrt{}}\times \mathbb{Q}^{\sqrt{}}$ is finitely constructible (which is a countable set). [Side question 1: What is the official name (and symbol) for the set which I call $\mathbb{Q}^{\sqrt{}}$, i.e. the set of those numbers that can be defined by addition, substraction, multiplication, division and taking the square root alone (starting from $0$ and $1$). Note that the set of algebraic numbers $\mathbb{Q}^\text{alg}$ allows for taking arbitrary roots.] But in the process of constructing points with straightedge and compass a lot of other points are ""created"", just by drawing the allowed lines and circles that are needed to take intersections (allowed = defined by previously constructed points). Only those points count as constructed that are intersections of such constructed lines and circles with other constructed lines and circles. But the other ones at least have been drawn . My question is: Does it make sense to ask â€“ and how can it be proved or disproved â€“ whether   $\mathbb{R}^2$ might be ""finitely coverable"" in the sense that for any   given point $p \in \mathbb{R}^2$ there is a line or circle   constructible in finitely many steps (starting from points $[0,0]$ and $[1,0]$) which $p$ lies on? The question and answer is not trivial at first glance (at least not for me), because the number of constructed points grows so incredibly fast, and the number of constructed lines and circles grows even faster (roughly quadratically, because each pair of new points gives â€“ roughly â€“ one new line and two new circles). [Side question 2: Can a rough estimate of the growth rate of the numbers of points, lines and circles be given, when starting with $n$ points in general or regular position?] To give a little visual sugar to my question: These are the constructible points, lines and circles after only three steps (starting with two points $0$ (red) and $1$ (orange)). (Each intersection of a line or circle with a line or circle is a constructed point â€“ and there are myriads of them, after only three steps!) This is after two steps: This it how it looks like after only two steps when starting with five points $0, 1, -1, i, -i$. [Side question 3: What might the little (and internally structured) white cross in the middle (around $(0,0)$ (red)) ""mean""?] This is after one step: For the sake of completeness: This is where the two points $0$, $1$ started off: And this is where the five points $0$, $1$, $i$, $-1$, $-i$ started off:","It is a well-known fact that the set of points which are finitely constructible with straightedge and compass (starting with two points $0$ and $1$) doesn't cover the Euclidean plane $\mathbb{R}\times \mathbb{R}$ because only $\mathbb{Q}^{\sqrt{}}\times \mathbb{Q}^{\sqrt{}}$ is finitely constructible (which is a countable set). [Side question 1: What is the official name (and symbol) for the set which I call $\mathbb{Q}^{\sqrt{}}$, i.e. the set of those numbers that can be defined by addition, substraction, multiplication, division and taking the square root alone (starting from $0$ and $1$). Note that the set of algebraic numbers $\mathbb{Q}^\text{alg}$ allows for taking arbitrary roots.] But in the process of constructing points with straightedge and compass a lot of other points are ""created"", just by drawing the allowed lines and circles that are needed to take intersections (allowed = defined by previously constructed points). Only those points count as constructed that are intersections of such constructed lines and circles with other constructed lines and circles. But the other ones at least have been drawn . My question is: Does it make sense to ask â€“ and how can it be proved or disproved â€“ whether   $\mathbb{R}^2$ might be ""finitely coverable"" in the sense that for any   given point $p \in \mathbb{R}^2$ there is a line or circle   constructible in finitely many steps (starting from points $[0,0]$ and $[1,0]$) which $p$ lies on? The question and answer is not trivial at first glance (at least not for me), because the number of constructed points grows so incredibly fast, and the number of constructed lines and circles grows even faster (roughly quadratically, because each pair of new points gives â€“ roughly â€“ one new line and two new circles). [Side question 2: Can a rough estimate of the growth rate of the numbers of points, lines and circles be given, when starting with $n$ points in general or regular position?] To give a little visual sugar to my question: These are the constructible points, lines and circles after only three steps (starting with two points $0$ (red) and $1$ (orange)). (Each intersection of a line or circle with a line or circle is a constructed point â€“ and there are myriads of them, after only three steps!) This is after two steps: This it how it looks like after only two steps when starting with five points $0, 1, -1, i, -i$. [Side question 3: What might the little (and internally structured) white cross in the middle (around $(0,0)$ (red)) ""mean""?] This is after one step: For the sake of completeness: This is where the two points $0$, $1$ started off: And this is where the five points $0$, $1$, $i$, $-1$, $-i$ started off:",,"['elementary-set-theory', 'euclidean-geometry']"
