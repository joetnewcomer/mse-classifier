,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Atiyah Macdonald Exercise 5.12,Atiyah Macdonald Exercise 5.12,,"I am stuck on one part of Exercise 5.12 in Atiyah Macdonald. The entire exercise is quoted below: Let $G$ be a finite group of automorphisms of a ring $A$ , and let $A^G$ denote the subring of $G$ -invariants, that is of all $x \in A$ such that $\sigma(x) = x$ for all $\sigma \in G$ . Prove that $A$ is integral over $A^G$ . [If $x \in A$ , observe that $x$ is a root of the polynomial $\prod_{\sigma \in G} (t - \sigma(x))$ .] Let $S$ be a multiplicatively closed subset of $A$ such that $\sigma(S) \subset S$ for all $\sigma \in G$ , and let $S^G = S \cap A^G$ . Show that the action of $G$ on $A$ extends to an action on $S^{-1} A$ , and that $(S^G)^{-1} A^G \cong (S^{-1} A)^G$ . The piece that I am stuck on is proving that $(S^G)^{-1} A^G \cong (S^{-1} A)^G$ . I have tried two approaches: Using the universal property of localizations, and defining the ""obvious"" map $\phi : (S^G)^{-1} A^G \to (S^{-1} A)^G$ via $\frac{a}{s} \mapsto \frac{a}{s}$ . In both cases, the issue I run into is that I need to show that any $\frac{a}{s} \in (S^{-1} A)^G$ , is equal to $\frac{a'}{s'}$ , where $a' \in A^G$ and $s' \in S^G$ . My best attempt so far is to start with $\frac{a}{s} \in (S^{-1} A)^G$ , and note that $$\frac{a}{s} = \frac{\prod_{\sigma \in G, \sigma \neq 1} \sigma(s) a}{\prod_{\sigma \in G} \sigma(s)}.$$ Clearly the denominator is in $S^G$ . For the numerator, if $A$ is an integral domain , then since $\frac{a}{s} \in (S^{-1} A)^G$ , we have that $\sigma(a)s - \sigma(s)a = 0$ . I can use this to show that the numerator is in $A^G$ by applying $\sigma$ to the numerator, and noting that if $\sigma \neq 1$ , then we get $s \sigma(a) \prod_{\tau \in G, \tau \neq \sigma,1} \tau(s) = a\prod_{\tau \in G, \tau \neq 1} \tau(s)$ , so the numerator is in $A^G$ . If $A$ is not an integral domain, then we get only that there exists $s_\sigma \in S$ such that $(\sigma(a) s - \sigma(s) a)s_\sigma = 0$ , and we have that $(\prod_{\sigma \in G} s_\sigma)(\prod_{\sigma \in G, \sigma \neq 1} \sigma(s))a \in A^G$ , but then we need to show that $(\prod_{\sigma \in G} s_\sigma) \in S^G$ . Is there a way to do this, or am I missing a simpler approach?","I am stuck on one part of Exercise 5.12 in Atiyah Macdonald. The entire exercise is quoted below: Let be a finite group of automorphisms of a ring , and let denote the subring of -invariants, that is of all such that for all . Prove that is integral over . [If , observe that is a root of the polynomial .] Let be a multiplicatively closed subset of such that for all , and let . Show that the action of on extends to an action on , and that . The piece that I am stuck on is proving that . I have tried two approaches: Using the universal property of localizations, and defining the ""obvious"" map via . In both cases, the issue I run into is that I need to show that any , is equal to , where and . My best attempt so far is to start with , and note that Clearly the denominator is in . For the numerator, if is an integral domain , then since , we have that . I can use this to show that the numerator is in by applying to the numerator, and noting that if , then we get , so the numerator is in . If is not an integral domain, then we get only that there exists such that , and we have that , but then we need to show that . Is there a way to do this, or am I missing a simpler approach?","G A A^G G x \in A \sigma(x) = x \sigma \in G A A^G x \in A x \prod_{\sigma \in G} (t - \sigma(x)) S A \sigma(S) \subset S \sigma \in G S^G = S \cap A^G G A S^{-1} A (S^G)^{-1} A^G \cong (S^{-1} A)^G (S^G)^{-1} A^G \cong (S^{-1} A)^G \phi : (S^G)^{-1} A^G \to (S^{-1} A)^G \frac{a}{s} \mapsto \frac{a}{s} \frac{a}{s} \in (S^{-1} A)^G \frac{a'}{s'} a' \in A^G s' \in S^G \frac{a}{s} \in (S^{-1} A)^G \frac{a}{s} = \frac{\prod_{\sigma \in G, \sigma \neq 1} \sigma(s) a}{\prod_{\sigma \in G} \sigma(s)}. S^G A \frac{a}{s} \in (S^{-1} A)^G \sigma(a)s - \sigma(s)a = 0 A^G \sigma \sigma \neq 1 s \sigma(a) \prod_{\tau \in G, \tau \neq \sigma,1} \tau(s) = a\prod_{\tau \in G, \tau \neq 1} \tau(s) A^G A s_\sigma \in S (\sigma(a) s - \sigma(s) a)s_\sigma = 0 (\prod_{\sigma \in G} s_\sigma)(\prod_{\sigma \in G, \sigma \neq 1} \sigma(s))a \in A^G (\prod_{\sigma \in G} s_\sigma) \in S^G","['abstract-algebra', 'commutative-algebra', 'group-actions']"
1,How to compute the ring of all $f\in K[X]$ with $f(\mathcal{O}_K)\subseteq \mathcal{O}_K$?,How to compute the ring of all  with ?,f\in K[X] f(\mathcal{O}_K)\subseteq \mathcal{O}_K,"Let $K$ be a number field, $\mathcal{O}_K$ the ring of integers of $K$ , and $A\subseteq K[X]$ the ring of all polynomials $f\in K[X]$ with $f(\mathcal{O}_K)\subseteq\mathcal{O}_K$ . It is obvious that $\mathcal{O}_K[X]\subseteq A\subseteq K[X]$ , but we can find better bounds. Define a sequence of polynomials $\{f_n\}_{n\ge 0}$ in $\mathbb{Z}[X]$ by $f_0=1$ and $f_{n+1}=(X-n-1)f_n$ . For each prime $\mathfrak{p}\mid (p)$ of $\mathcal{O}_K$ , define an ideal $I_n:=\langle f_n(\mathcal{O}_K)\rangle$ For all $n$ , let $\lambda_n\in\mathcal{O}_K$ with $I_n\subseteq (\lambda_n)$ , then if I'm not mistaken $$ \bigoplus_{n\ge 0}\frac{f_n}{\lambda_n}\cdot \mathcal{O}_K\subseteq A\subseteq \bigoplus_{n\ge 0}\frac{f_n}{n!}\cdot \mathcal{O}_K. $$ Moreover, define $$ m(\mathfrak{p},n):=\min_{\alpha\in\mathcal{O}_K}\operatorname{ord}_\mathfrak{p}(f_n(\alpha)). $$ It is easy see that $I_n=\prod_{\mathfrak{p}}\mathfrak{p}^{m(\mathfrak{p},n)}$ . let $f(\mathfrak{p})$ be the residue class degree and $e(\mathfrak{p})$ be the ramification index, then I believe that $$ m(\mathfrak{p},n) = \begin{cases} \operatorname{ord}_p(n!)\quad&\text{if $f(\mathfrak{p})=e(\mathfrak{p})=1$}\\ \left\lfloor\frac np\right\rfloor&\text{if $f(\mathfrak{p})=1$ and $e(\mathfrak{p})>1$}\\ 0&\text{otherwise.} \end{cases} $$ Which makes the lower bound fairly concrete. The lower and upper bounds are equal only when $K=\mathbb{Q}$ . In this case, we find that $A = \bigoplus_{n\ge 0}{X\choose n}\cdot \mathbb{Z}$ Questions: Can you compute $A$ for a few number fields other than $\mathbb{Q}$ ? Is there an algorithm to do it in general? Is $A$ free as a $\mathcal{O}_K$ -module? Can you compute a minimal generating set (so a basis if the answer to the previous question is affirmative) for $A$ for a few number fields other than $\mathbb{Q}$ ? Is there an algorithm to do it in general? Proof of the upper bound Define $\Delta:A\to A$ by $\Delta f:=f(X+1)-f(X)$ . Note that all constant polynomials in $A$ lie in $\mathcal{O}_K$ . Let $f\in A$ have degree $d$ and leading coefficient $a_d\in K$ , then $\Delta^{(d)}f=d!a_d\in\mathcal{O}_K$ , and $f-d!a_d\cdot \frac{f_d}{d!}=f-d!a_d{X\choose d}$ has degree strictly less than $f$ . Induction on the $\deg(f)$ finishes the job.","Let be a number field, the ring of integers of , and the ring of all polynomials with . It is obvious that , but we can find better bounds. Define a sequence of polynomials in by and . For each prime of , define an ideal For all , let with , then if I'm not mistaken Moreover, define It is easy see that . let be the residue class degree and be the ramification index, then I believe that Which makes the lower bound fairly concrete. The lower and upper bounds are equal only when . In this case, we find that Questions: Can you compute for a few number fields other than ? Is there an algorithm to do it in general? Is free as a -module? Can you compute a minimal generating set (so a basis if the answer to the previous question is affirmative) for for a few number fields other than ? Is there an algorithm to do it in general? Proof of the upper bound Define by . Note that all constant polynomials in lie in . Let have degree and leading coefficient , then , and has degree strictly less than . Induction on the finishes the job.","K \mathcal{O}_K K A\subseteq K[X] f\in K[X] f(\mathcal{O}_K)\subseteq\mathcal{O}_K \mathcal{O}_K[X]\subseteq A\subseteq K[X] \{f_n\}_{n\ge 0} \mathbb{Z}[X] f_0=1 f_{n+1}=(X-n-1)f_n \mathfrak{p}\mid (p) \mathcal{O}_K I_n:=\langle f_n(\mathcal{O}_K)\rangle n \lambda_n\in\mathcal{O}_K I_n\subseteq (\lambda_n) 
\bigoplus_{n\ge 0}\frac{f_n}{\lambda_n}\cdot \mathcal{O}_K\subseteq A\subseteq \bigoplus_{n\ge 0}\frac{f_n}{n!}\cdot \mathcal{O}_K.
 
m(\mathfrak{p},n):=\min_{\alpha\in\mathcal{O}_K}\operatorname{ord}_\mathfrak{p}(f_n(\alpha)).
 I_n=\prod_{\mathfrak{p}}\mathfrak{p}^{m(\mathfrak{p},n)} f(\mathfrak{p}) e(\mathfrak{p}) 
m(\mathfrak{p},n) = \begin{cases}
\operatorname{ord}_p(n!)\quad&\text{if f(\mathfrak{p})=e(\mathfrak{p})=1}\\
\left\lfloor\frac np\right\rfloor&\text{if f(\mathfrak{p})=1 and e(\mathfrak{p})>1}\\
0&\text{otherwise.}
\end{cases}
 K=\mathbb{Q} A = \bigoplus_{n\ge 0}{X\choose n}\cdot \mathbb{Z} A \mathbb{Q} A \mathcal{O}_K A \mathbb{Q} \Delta:A\to A \Delta f:=f(X+1)-f(X) A \mathcal{O}_K f\in A d a_d\in K \Delta^{(d)}f=d!a_d\in\mathcal{O}_K f-d!a_d\cdot \frac{f_d}{d!}=f-d!a_d{X\choose d} f \deg(f)","['abstract-algebra', 'number-theory', 'polynomials', 'algebraic-number-theory']"
2,Choosing elements from an abelian group $\mathbb{Z}_n$ that make the enumeration of partitions incomplete.,Choosing elements from an abelian group  that make the enumeration of partitions incomplete.,\mathbb{Z}_n,"Take an abelian group $(\mathbb{Z}_n,+)$ and enumerate all partitions of two elements (i.e. $x=x_1+x_2$ ) of each element $\{0,1,...,n-1\}=\mathbb{Z}_n$ . Take, for example, abelian groups $\mathbb{Z}_9$ and $\mathbb{Z}_{10}$ . Now, the enumerations of the partitions of these groups would be the following (note that $x=x_1+x_2$ where $x_1=x_2$ is not allowed, i.e. $x_1$ and $x_2$ may not be equal!): $\mathbb{Z}_9:$ $0=8+1,7+2,6+3,5+4$ $1=8+2,7+3,6+4,0+1$ $2=8+3,7+4,6+5,0+2$ $3=8+4,7+5,0+3,1+2$ $4=8+5,7+6,0+4,1+3$ $5=8+6,0+5,1+4,2+3$ $6=8+7,0+6,1+5,2+4$ $7=0+7,1+6,2+5,3+4$ $8=0+8,1+7,2+6,3+5$ $\mathbb{Z}_{10}:$ $0=9+1,8+2,7+3,6+4$ $1=9+2,8+3,7+4,6+5,0+1$ $2=9+3,8+4,7+5,0+2$ $3=9+4,8+5,7+6,0+3,1+2$ $4=9+5,8+6,0+4,1+3$ $5=9+6,8+7,0+5,1+4,2+3$ $6=9+7,0+6,1+5,2+4$ $7=9+8,0+7,1+6,2+5,3+4$ $8=0+8,1+7,2+6,3+5$ $9=0+9,1+8,2+7,3+6,4+5$ Now, my question is the following: how many ways can we choose the total of $\lfloor \frac{n-1}{2}\rfloor$ distinct elements from $\mathbb{Z}_n$ such that when these elements are deleted, there exists at least one remaining element in $\mathbb{Z}_n$ that may not be expressed as a partition $x=x_1+x_2$ anymore. For instance, if we look at $\mathbb{Z}_9$ then $\lfloor \frac{9-1}{2} \rfloor=4$ and if we delete $\{8,2,3,5\}$ from $\mathbb{Z}_9$ then we cannot express $0$ as a partition $0=x_1+x_2$ where $x_1,x_2\in \mathbb{Z}_9 \setminus \{8,2,3,5\}$ . I noticed that no $\lfloor \frac{n-1}{2} \rfloor$ consecutive elements may be deleted from $\mathbb{Z}_n$ so there must be at least $n$ different ways to do this. However, there have to be more than $n$ due to, for instance, my previous example of $\mathbb{Z}_9\setminus \{8,2,3,5\}$ .","Take an abelian group and enumerate all partitions of two elements (i.e. ) of each element . Take, for example, abelian groups and . Now, the enumerations of the partitions of these groups would be the following (note that where is not allowed, i.e. and may not be equal!): Now, my question is the following: how many ways can we choose the total of distinct elements from such that when these elements are deleted, there exists at least one remaining element in that may not be expressed as a partition anymore. For instance, if we look at then and if we delete from then we cannot express as a partition where . I noticed that no consecutive elements may be deleted from so there must be at least different ways to do this. However, there have to be more than due to, for instance, my previous example of .","(\mathbb{Z}_n,+) x=x_1+x_2 \{0,1,...,n-1\}=\mathbb{Z}_n \mathbb{Z}_9 \mathbb{Z}_{10} x=x_1+x_2 x_1=x_2 x_1 x_2 \mathbb{Z}_9: 0=8+1,7+2,6+3,5+4 1=8+2,7+3,6+4,0+1 2=8+3,7+4,6+5,0+2 3=8+4,7+5,0+3,1+2 4=8+5,7+6,0+4,1+3 5=8+6,0+5,1+4,2+3 6=8+7,0+6,1+5,2+4 7=0+7,1+6,2+5,3+4 8=0+8,1+7,2+6,3+5 \mathbb{Z}_{10}: 0=9+1,8+2,7+3,6+4 1=9+2,8+3,7+4,6+5,0+1 2=9+3,8+4,7+5,0+2 3=9+4,8+5,7+6,0+3,1+2 4=9+5,8+6,0+4,1+3 5=9+6,8+7,0+5,1+4,2+3 6=9+7,0+6,1+5,2+4 7=9+8,0+7,1+6,2+5,3+4 8=0+8,1+7,2+6,3+5 9=0+9,1+8,2+7,3+6,4+5 \lfloor \frac{n-1}{2}\rfloor \mathbb{Z}_n \mathbb{Z}_n x=x_1+x_2 \mathbb{Z}_9 \lfloor \frac{9-1}{2} \rfloor=4 \{8,2,3,5\} \mathbb{Z}_9 0 0=x_1+x_2 x_1,x_2\in \mathbb{Z}_9 \setminus \{8,2,3,5\} \lfloor \frac{n-1}{2} \rfloor \mathbb{Z}_n n n \mathbb{Z}_9\setminus \{8,2,3,5\}","['abstract-algebra', 'combinatorics']"
3,"Counterexample to ""kernel determines image""","Counterexample to ""kernel determines image""",,"Working over a base field, there is a typical homomorphism theorem for affine algebraic groups ensuring that any two homomporphisms $G \to H_1$ , $G \to H_2$ with the same kernel in $G$ have isomorphic images. Proving this makes heavily use of the nontrivial fact that injective homomorphisms between Hopf algebras over fields are faithfully flat. Working over general base rings (which are not fields), it is easy to find non-faithfully flat injective Hopf algebra homomorphisms: For example over the base ring of integers, $\mathbb{Z}[X] \to \mathbb{Z}[X]$ sending $X$ to $nX$ for any $n \not\in \{0,1,-1\}$ is not faithfully flat. (It corresponds to the multiplication-by- $n$ -homomorphism $\mathbb{G}_a \to \mathbb{G}_a$ .) I suspect the above statement fails in this general setting, but I cound not find any counterexample so far. Question 1: Are there homomorphisms $f_1 \colon G \to H_1$ , $f_2 \colon G \to H_2$ of affine algebraic groups with the same kernel such that $\mathrm{Im}(f_1)$ is not isomorphic to $\mathrm{Im}(f_2)$ ? More specifically: Question 2: Is there an injective homomorphism $f \colon G \to H$ of affine algebraic groups such that $\mathrm{Im}(f)$ is not isomorphic to $G$ ? Edit 1 Here is an attempt to find a counterexample to question 2. My idea is to adapt known homomorphisms of algebraic groups which can be defined over general base rings but show different behavior after base extensions to fields of different characteristics. For any base ring $R$ there is the circle group $C$ defined for any $R$ -algebra $A$ by $$ C(A) = \{ (x,y) \in A^2 : x^2+y^2 = 1 \}. $$ The identity element is $(1,0)$ , and the group operations are given by $$ (x_1,y_1) \cdot (x_2,y_2) = (x_1x_2 - y_1y_2, x_1y_2+ x_2y_1), \text{ and } (x,y)^{-1} = (x,-y). $$ If $R$ has an element $i \in R$ with $i^2 = -1$ , there is a homomorphism $$ \varphi \colon C \to \mathbb{G}_m, \quad (x,y) \mapsto x+iy.$$ This morphism is quite exiting: If $2$ is invertible in $R$ then $\varphi$ is already an isomorphism. If $2$ not not invertible however, then $\varphi$ is not injective, and we can extend $R$ to a field of characteristics 2, where $\varphi$ is neither injective nor surjective (it maps onto $\mu_2$ then). This example can be found in [Waterhouse, Introduction to affine group schemes, chapter 1, exercise 11]. Since $\varphi$ has nontrivial kernel, it cannot be a counterexample to (2). So let's add an additional equation: Let $C'$ be the subgroup of the circle group given by $$ C'(A) = \{ (x,y) \in A^2 : x^2+y^2=1, 3y=0 \}. $$ Now the restriction of $\varphi$ to $C'$ has trivial kernel, but it is not surjective anymore - we have to add at least one additional equation $3t^2=3$ to $\mathbb{G}_m$ . That is, $\varphi$ induces a homomorphism of algebraic subgroups $$ \{ (x,y) : x^2+y^2=1, 3y = 0 \} \to \{ t : t \text{ invertible}, 3t^2=3 \}. $$ I think this might be a counterexample to (2) since it becomes an isomorphism after extending the base ring to any field, but I cannot see how it should be an isomorphism over (say) the Gaussian integers $R = \mathbb{Z}[i]$ . However, I also cannot see at the moment why it should be (scheme-theoretically) surjective. To restate the question in terms of Hopf algebras: There is a homomorphism $$ (\mathbb{Z}[i])[T,T^{-1}]/(3(T^2-1)) \to (\mathbb{Z}[i])[X,Y]/(X^2+Y^2-1, 3Y), \quad T \mapsto X+iY. $$ Is this morphism injective but not surjective? (Of course (2) asks for a little bit more: Is the left hand side not ismomorphic to the right hand side?) Edit 2 Unfortunately, this specific morphism is already an isomorphism which can be easily seen by condiering the localizations of $\mathbb{Z}[i]$ at all primes $\mathfrak{p}$ . For all primes with $3 \notin \mathfrak{p}$ it is quite obvious that the morphism is basically the same as the identity map $\mu_2 \to \mu_2$ , since $3$ is invertible in $\mathbb{Z}[i]_\mathfrak{p}$ . On the other hand, if $3 \in \mathfrak{p}$ then $2$ is invertible in $\mathbb{Z}[i]_\mathfrak{p}$ . In this case, $\varphi \colon C \to \mathbb{G}_m$ is an isomorphism, and it can be easily checked that its inverse maps $\{ t : t \text{ invertible }, 3t^2=3 \}$ to $C'$ . In order to get a counterexample in the way sketched above, we have to choose some other equation (instead of $3y=0$ ) which nontrivially affects the groups over the base ring $\mathbb{Z}[i]_\mathfrak{p}$ for $\mathfrak{p} = (1+i)$ .","Working over a base field, there is a typical homomorphism theorem for affine algebraic groups ensuring that any two homomporphisms , with the same kernel in have isomorphic images. Proving this makes heavily use of the nontrivial fact that injective homomorphisms between Hopf algebras over fields are faithfully flat. Working over general base rings (which are not fields), it is easy to find non-faithfully flat injective Hopf algebra homomorphisms: For example over the base ring of integers, sending to for any is not faithfully flat. (It corresponds to the multiplication-by- -homomorphism .) I suspect the above statement fails in this general setting, but I cound not find any counterexample so far. Question 1: Are there homomorphisms , of affine algebraic groups with the same kernel such that is not isomorphic to ? More specifically: Question 2: Is there an injective homomorphism of affine algebraic groups such that is not isomorphic to ? Edit 1 Here is an attempt to find a counterexample to question 2. My idea is to adapt known homomorphisms of algebraic groups which can be defined over general base rings but show different behavior after base extensions to fields of different characteristics. For any base ring there is the circle group defined for any -algebra by The identity element is , and the group operations are given by If has an element with , there is a homomorphism This morphism is quite exiting: If is invertible in then is already an isomorphism. If not not invertible however, then is not injective, and we can extend to a field of characteristics 2, where is neither injective nor surjective (it maps onto then). This example can be found in [Waterhouse, Introduction to affine group schemes, chapter 1, exercise 11]. Since has nontrivial kernel, it cannot be a counterexample to (2). So let's add an additional equation: Let be the subgroup of the circle group given by Now the restriction of to has trivial kernel, but it is not surjective anymore - we have to add at least one additional equation to . That is, induces a homomorphism of algebraic subgroups I think this might be a counterexample to (2) since it becomes an isomorphism after extending the base ring to any field, but I cannot see how it should be an isomorphism over (say) the Gaussian integers . However, I also cannot see at the moment why it should be (scheme-theoretically) surjective. To restate the question in terms of Hopf algebras: There is a homomorphism Is this morphism injective but not surjective? (Of course (2) asks for a little bit more: Is the left hand side not ismomorphic to the right hand side?) Edit 2 Unfortunately, this specific morphism is already an isomorphism which can be easily seen by condiering the localizations of at all primes . For all primes with it is quite obvious that the morphism is basically the same as the identity map , since is invertible in . On the other hand, if then is invertible in . In this case, is an isomorphism, and it can be easily checked that its inverse maps to . In order to get a counterexample in the way sketched above, we have to choose some other equation (instead of ) which nontrivially affects the groups over the base ring for .","G \to H_1 G \to H_2 G \mathbb{Z}[X] \to \mathbb{Z}[X] X nX n \not\in \{0,1,-1\} n \mathbb{G}_a \to \mathbb{G}_a f_1 \colon G \to H_1 f_2 \colon G \to H_2 \mathrm{Im}(f_1) \mathrm{Im}(f_2) f \colon G \to H \mathrm{Im}(f) G R C R A  C(A) = \{ (x,y) \in A^2 : x^2+y^2 = 1 \}.  (1,0)  (x_1,y_1) \cdot (x_2,y_2) = (x_1x_2 - y_1y_2, x_1y_2+ x_2y_1), \text{ and } (x,y)^{-1} = (x,-y).  R i \in R i^2 = -1  \varphi \colon C \to \mathbb{G}_m, \quad (x,y) \mapsto x+iy. 2 R \varphi 2 \varphi R \varphi \mu_2 \varphi C'  C'(A) = \{ (x,y) \in A^2 : x^2+y^2=1, 3y=0 \}.  \varphi C' 3t^2=3 \mathbb{G}_m \varphi  \{ (x,y) : x^2+y^2=1, 3y = 0 \} \to \{ t : t \text{ invertible}, 3t^2=3 \}.  R = \mathbb{Z}[i]  (\mathbb{Z}[i])[T,T^{-1}]/(3(T^2-1)) \to (\mathbb{Z}[i])[X,Y]/(X^2+Y^2-1, 3Y), \quad T \mapsto X+iY.  \mathbb{Z}[i] \mathfrak{p} 3 \notin \mathfrak{p} \mu_2 \to \mu_2 3 \mathbb{Z}[i]_\mathfrak{p} 3 \in \mathfrak{p} 2 \mathbb{Z}[i]_\mathfrak{p} \varphi \colon C \to \mathbb{G}_m \{ t : t \text{ invertible }, 3t^2=3 \} C' 3y=0 \mathbb{Z}[i]_\mathfrak{p} \mathfrak{p} = (1+i)","['abstract-algebra', 'algebraic-groups', 'hopf-algebras']"
4,Proving a group homomorphism is surjective,Proving a group homomorphism is surjective,,"Define the homomorphism $\phi:SL(2,\mathbb{Z})\rightarrow SL(2,\mathbb{Z_2})$ by sending $\begin{pmatrix} a & b\\ c & d \end{pmatrix} \in SL(2,\mathbb{Z})$ to $\begin{pmatrix} [a] & [b]\\ [c] & [d] \end{pmatrix} \in SL(2,\mathbb{Z_2})$ , where $[x]$ represents the congruence class of $x$ modulo $2$ . The goal is to prove that this mapping is surjective. My thought was to define a matrix in $SL(2,\mathbb{Z_2})$ and define the counterpart in $SL(2,\mathbb{Z})$ with entries without $[]$ . But I felt there something is missing. Can anyone please help me out? Thank you!","Define the homomorphism by sending to , where represents the congruence class of modulo . The goal is to prove that this mapping is surjective. My thought was to define a matrix in and define the counterpart in with entries without . But I felt there something is missing. Can anyone please help me out? Thank you!","\phi:SL(2,\mathbb{Z})\rightarrow SL(2,\mathbb{Z_2}) \begin{pmatrix}
a & b\\
c & d
\end{pmatrix} \in SL(2,\mathbb{Z}) \begin{pmatrix}
[a] & [b]\\
[c] & [d]
\end{pmatrix} \in SL(2,\mathbb{Z_2}) [x] x 2 SL(2,\mathbb{Z_2}) SL(2,\mathbb{Z}) []","['abstract-algebra', 'group-theory', 'number-theory', 'modular-arithmetic']"
5,"To check $N\preccurlyeq^+ M$, does it suffice to consider single-variable formulas?","To check , does it suffice to consider single-variable formulas?",N\preccurlyeq^+ M,"Let $R$ any unital ring, and let $\mathcal{L}_R=\{+,-,0,r\}_{r\in R}$ be the language of left $R$ -modules, where each $r$ is a unary function symbol. Recall that a positive primitive (pp) $\mathcal{L}_R$ -formula is one of the form $\exists\overline{w}\bigwedge_{i=1}^k\overline{r_i}\bullet\overline{v}=\overline{s_i}\bullet\overline{w}$ , where each $\overline{r_i}$ and $\overline{s_i}$ is a tuple of elements of $R$ , and $\bullet$ denotes the ""dot product"". (So, eg, $\overline{r_i}\bullet\overline{v}=\sum_{j=1}^mr_{ij}\cdot v_j$ .) It is well-known that, modulo the complete theory of any $R$ -module, every $\mathcal{L}_R$ -formula is equivalent to a boolean combination of pp-formulas. Given a pair of modules $N\leqslant M$ , we say that $N$ is a pure submodule of $M$ , denoted $N\preccurlyeq^+M$ , if $$N\models\psi(\overline{a})\iff M\models\psi(\overline{a})$$ for any pp-formula $\psi$ and any tuple $\overline{a}\in N$ . (Note that the forward implication always holds, so the content of purity is the backwards implication.) Question: When checking that $N$ is a pure submodule of $M$ , does it suffice to consider pp-formulas in a single variable? $\square$ This seems like a very natural and straightforward question, but the answer is unclear to me. Certainly if $\psi$ is of the form $\exists\overline{w}(\overline{r}\bullet\overline{v}=\overline{s}\bullet\overline{w})$ then the desired implications hold. Indeed, then the sentence $\psi(\overline{a})$ for a tuple $\overline{a}\in N$ is equivalent to the sentence $\psi'(a^1)$ , where $a^1=\overline{r}\bullet\overline{a}\in N$ and $\psi'$ is the single-variable formula $\exists \overline{w}(v=\overline{s}\bullet\overline{w})$ . However, things seem less straightforward if $\psi$ has multiple conjuncts. By a similar argument as above (considering each $\overline{r_i}\bullet\overline{a}$ as a single element of $N$ ), it suffices to consider formulas of the form $\exists\overline{w}\bigwedge_{i=1}^kv_i=\overline{s_i}\bullet\overline{w}$ . Then saying that $N$ is pure in $M$ with respect to formulas in one variable amounts to saying that each equation $a_i=\overline{s_i}\bullet\overline{w}$ has a solution in $N$ if and only if it has a solution in $M$ , for every $a_i\in N$ . But I don't immediately see how we can ""stitch"" these solutions together in the way that we want, and I'm not even sure if we can in general. Does anyone have any thoughts? A counterexample, or a proof for a particularly nice class of ring (PIDs perhaps?), would also be much appreciated. For instance, I believe the result holds if $R$ is a local PID. Sketch: suppose $R$ has maximal ideal $(\pi)$ . Then every element of $R$ is associate with a power of $\pi$ , so we may assume that the length of the tuple $\overline{w}$ in the formula above is $1$ , and that each $s_i$ is of the form $\pi^{n_i}$ for some $n_i$ . Then, assuming wlog that $n_1$ is minimal among the $n_i$ , we have $N\models\exists w\bigwedge_{i=1}^ka_i=\pi^{n_i}w$ if and only if $$\text{(i) }a_1\text{ is divisible by }\pi^{n_1}\text{ in }N\ \ \ \ \ \ \ \text{  and }\ \ \ \ \ \ \ \text{(ii) }a_i=\pi^{n_i-n_1}a_1\text{ for each }i.$$ Clearly (ii) holds in $N$ if and only if it holds in $M$ , and (i) is covered by the pp-criterion for single variable formulas, and so we are done.","Let any unital ring, and let be the language of left -modules, where each is a unary function symbol. Recall that a positive primitive (pp) -formula is one of the form , where each and is a tuple of elements of , and denotes the ""dot product"". (So, eg, .) It is well-known that, modulo the complete theory of any -module, every -formula is equivalent to a boolean combination of pp-formulas. Given a pair of modules , we say that is a pure submodule of , denoted , if for any pp-formula and any tuple . (Note that the forward implication always holds, so the content of purity is the backwards implication.) Question: When checking that is a pure submodule of , does it suffice to consider pp-formulas in a single variable? This seems like a very natural and straightforward question, but the answer is unclear to me. Certainly if is of the form then the desired implications hold. Indeed, then the sentence for a tuple is equivalent to the sentence , where and is the single-variable formula . However, things seem less straightforward if has multiple conjuncts. By a similar argument as above (considering each as a single element of ), it suffices to consider formulas of the form . Then saying that is pure in with respect to formulas in one variable amounts to saying that each equation has a solution in if and only if it has a solution in , for every . But I don't immediately see how we can ""stitch"" these solutions together in the way that we want, and I'm not even sure if we can in general. Does anyone have any thoughts? A counterexample, or a proof for a particularly nice class of ring (PIDs perhaps?), would also be much appreciated. For instance, I believe the result holds if is a local PID. Sketch: suppose has maximal ideal . Then every element of is associate with a power of , so we may assume that the length of the tuple in the formula above is , and that each is of the form for some . Then, assuming wlog that is minimal among the , we have if and only if Clearly (ii) holds in if and only if it holds in , and (i) is covered by the pp-criterion for single variable formulas, and so we are done.","R \mathcal{L}_R=\{+,-,0,r\}_{r\in R} R r \mathcal{L}_R \exists\overline{w}\bigwedge_{i=1}^k\overline{r_i}\bullet\overline{v}=\overline{s_i}\bullet\overline{w} \overline{r_i} \overline{s_i} R \bullet \overline{r_i}\bullet\overline{v}=\sum_{j=1}^mr_{ij}\cdot v_j R \mathcal{L}_R N\leqslant M N M N\preccurlyeq^+M N\models\psi(\overline{a})\iff M\models\psi(\overline{a}) \psi \overline{a}\in N N M \square \psi \exists\overline{w}(\overline{r}\bullet\overline{v}=\overline{s}\bullet\overline{w}) \psi(\overline{a}) \overline{a}\in N \psi'(a^1) a^1=\overline{r}\bullet\overline{a}\in N \psi' \exists \overline{w}(v=\overline{s}\bullet\overline{w}) \psi \overline{r_i}\bullet\overline{a} N \exists\overline{w}\bigwedge_{i=1}^kv_i=\overline{s_i}\bullet\overline{w} N M a_i=\overline{s_i}\bullet\overline{w} N M a_i\in N R R (\pi) R \pi \overline{w} 1 s_i \pi^{n_i} n_i n_1 n_i N\models\exists w\bigwedge_{i=1}^ka_i=\pi^{n_i}w \text{(i) }a_1\text{ is divisible by }\pi^{n_1}\text{ in }N\ \ \ \ \ \ \ \text{  and }\ \ \ \ \ \ \ \text{(ii) }a_i=\pi^{n_i-n_1}a_1\text{ for each }i. N M","['abstract-algebra', 'logic', 'ring-theory', 'modules', 'model-theory']"
6,Finding a tricky quotient set,Finding a tricky quotient set,,"We will denote by $\mathbb{K}$ one of the fields $\mathbb{Q}, \mathbb{R}$ or $\mathbb{C}$ . On $\mathbb{K}\times \mathbb{K}$ we define the following equivalence relation: $$(a,b)\equiv (a', b') \iff \exists (q,\alpha)\in \mathbb{K}^{*}\times \mathbb{K} \text{ such that } \begin{cases} a=q^2a'+\alpha^2-b\alpha \\ b=qb'+2\alpha \end{cases}.$$ We wish to determine the quotient set $\mathbb{K} \times \mathbb{K}/\equiv$ $\space$ for all $\mathbb{K}$ s. This problem was an extra problem in my abstract algebra class (don't worry, this isn't an attempt to cheat, I am posting this a week after the solution was due to be sent) and I kind of got stuck when it comes to $\mathbb{K}=\mathbb{Q}$ . For $\mathbb{K}=\mathbb{C}$ , the things were nice and easy, because the original question asked me to prove that $\mathbb{C}\times \mathbb{C}/\equiv$ is equal to $\{\hat{(0,0)}, \hat{(0,1)}\}$ and this can be checked through (tedious) direct computations. For $\mathbb{K}=\mathbb{R}$ , a friend came up with the idea of expressing $\alpha$ from the second equation and then substituing it in the first one. This gives us the following equivalent characterisation of the equivalence relation: $$(a,b)\equiv (a', b') \iff \exists q\in \mathbb{K}^{*} \text{ such that } 4a+b^2=q^2(4a'+b'^2) \space (*).$$ (notice that this works for all $\mathbb{K}$ s, the case $\mathbb{K}=\mathbb{C}$ can be solved much easier by using this, but I didn't really need to think that much for that one since direct computations worked in my context) For real numbers, this rewrites as $(a,b)\equiv (a', b') \iff \operatorname{sgn}(4a+b^2)=\operatorname{sgn}(4a'+b'^2)$ . As a result, there will be three equivalence classes: the parabola $4x+y^2=0$ , its interior and its exterior. A representative for each of these are, respectively, $(0,0), (-1,0)$ and $(0,1)$ , so $\mathbb{R}\times \mathbb{R}/\equiv \space = \{\hat{(0,0)}, \hat{(-1,0)}, \hat{(0,1)}\}$ . For $\mathbb{K}=\mathbb{Q}$ , the things get pretty nasty by this approach. In this case, $(*)$ rewrites as $(a,b)\equiv (a',b') \iff \sqrt{\frac{4a+b^2}{4a'+b'^2}}\in \mathbb{Q}$ and I haven't been able to make any further progress.","We will denote by one of the fields or . On we define the following equivalence relation: We wish to determine the quotient set for all s. This problem was an extra problem in my abstract algebra class (don't worry, this isn't an attempt to cheat, I am posting this a week after the solution was due to be sent) and I kind of got stuck when it comes to . For , the things were nice and easy, because the original question asked me to prove that is equal to and this can be checked through (tedious) direct computations. For , a friend came up with the idea of expressing from the second equation and then substituing it in the first one. This gives us the following equivalent characterisation of the equivalence relation: (notice that this works for all s, the case can be solved much easier by using this, but I didn't really need to think that much for that one since direct computations worked in my context) For real numbers, this rewrites as . As a result, there will be three equivalence classes: the parabola , its interior and its exterior. A representative for each of these are, respectively, and , so . For , the things get pretty nasty by this approach. In this case, rewrites as and I haven't been able to make any further progress.","\mathbb{K} \mathbb{Q}, \mathbb{R} \mathbb{C} \mathbb{K}\times \mathbb{K} (a,b)\equiv (a', b') \iff \exists (q,\alpha)\in \mathbb{K}^{*}\times \mathbb{K} \text{ such that } \begin{cases} a=q^2a'+\alpha^2-b\alpha \\ b=qb'+2\alpha \end{cases}. \mathbb{K} \times \mathbb{K}/\equiv \space \mathbb{K} \mathbb{K}=\mathbb{Q} \mathbb{K}=\mathbb{C} \mathbb{C}\times \mathbb{C}/\equiv \{\hat{(0,0)}, \hat{(0,1)}\} \mathbb{K}=\mathbb{R} \alpha (a,b)\equiv (a', b') \iff \exists q\in \mathbb{K}^{*} \text{ such that } 4a+b^2=q^2(4a'+b'^2) \space (*). \mathbb{K} \mathbb{K}=\mathbb{C} (a,b)\equiv (a', b') \iff \operatorname{sgn}(4a+b^2)=\operatorname{sgn}(4a'+b'^2) 4x+y^2=0 (0,0), (-1,0) (0,1) \mathbb{R}\times \mathbb{R}/\equiv \space = \{\hat{(0,0)}, \hat{(-1,0)}, \hat{(0,1)}\} \mathbb{K}=\mathbb{Q} (*) (a,b)\equiv (a',b') \iff \sqrt{\frac{4a+b^2}{4a'+b'^2}}\in \mathbb{Q}","['abstract-algebra', 'equivalence-relations']"
7,"Find all finite groups $G$ s.t for any $a,b\in G$ either $a$ is a power of $b$ or $b$ is a power of $a$",Find all finite groups  s.t for any  either  is a power of  or  is a power of,"G a,b\in G a b b a","Find all finite groups $G$ s.t for any $a,b\in G$ either $a$ is a power of $b$ or $b$ is a power of $a$ I think i showed that all such groups are $Z_{p^n}$ for $p$ prime, is this correct? I first showed that the group must be cyclic by considering the element of the largest order $\langle a\rangle$ and achiveing contradiction if $\langle a\rangle\not= G$ ., and then that if $Z_n$ with $n$ composite then it does not have this property. as there are two disjoint cyclic subgroups of coprime orders. Is this correct? Are all groups such groups $Z_{p^n}$ ?","Find all finite groups s.t for any either is a power of or is a power of I think i showed that all such groups are for prime, is this correct? I first showed that the group must be cyclic by considering the element of the largest order and achiveing contradiction if ., and then that if with composite then it does not have this property. as there are two disjoint cyclic subgroups of coprime orders. Is this correct? Are all groups such groups ?","G a,b\in G a b b a Z_{p^n} p \langle a\rangle \langle a\rangle\not= G Z_n n Z_{p^n}",['abstract-algebra']
8,Determine the number of homomorphisms from $S_{3} \rightarrow \Bbb Z_{2} \times \Bbb Z_{4}$.,Determine the number of homomorphisms from .,S_{3} \rightarrow \Bbb Z_{2} \times \Bbb Z_{4},"Determine the number of homomorphism from $S_{3}  \rightarrow \Bbb Z_{2} \times \Bbb Z_{4}$ . My attempt: A homomorphism from $S_{3}  \rightarrow \Bbb Z_{2} \times \Bbb Z_{4}$ is a homomorphism into an abelian group. Therefore, ${\rm hom}(S_{3},\Bbb Z_{2} \times \Bbb Z_{4})= {\rm hom}\left(\frac{S_{3}}{[S_{3},S_{3}]},\Bbb Z_{2} \times \Bbb Z_{4}\right)$ , where $[S_{3},S_{3}]$ is the normal subgroup of $S_{3}$ generated by the elements of the form $aba^{-1}b^{-1}$ and $[S_{3},S_{3}]=A_{3}$ . ${\rm hom}(S_{3},\Bbb Z_{2} \times \Bbb Z_{4})= {\rm hom}(\Bbb Z_{2},\Bbb Z_{2} \times \Bbb Z_{4})$ . Next my idea is to calculate the number of elements in $\Bbb Z_{2} \times \Bbb Z_{4}$ whose order is divisible by 2. I get 4 elements of order 4, 3 elements of order 2, and one element of order 1. Anyone can please suggest to me, is this direction correct to think this question?","Determine the number of homomorphism from . My attempt: A homomorphism from is a homomorphism into an abelian group. Therefore, , where is the normal subgroup of generated by the elements of the form and . . Next my idea is to calculate the number of elements in whose order is divisible by 2. I get 4 elements of order 4, 3 elements of order 2, and one element of order 1. Anyone can please suggest to me, is this direction correct to think this question?","S_{3}  \rightarrow \Bbb Z_{2} \times \Bbb Z_{4} S_{3}  \rightarrow \Bbb Z_{2} \times \Bbb Z_{4} {\rm hom}(S_{3},\Bbb Z_{2} \times \Bbb Z_{4})= {\rm hom}\left(\frac{S_{3}}{[S_{3},S_{3}]},\Bbb Z_{2} \times \Bbb Z_{4}\right) [S_{3},S_{3}] S_{3} aba^{-1}b^{-1} [S_{3},S_{3}]=A_{3} {\rm hom}(S_{3},\Bbb Z_{2} \times \Bbb Z_{4})= {\rm hom}(\Bbb Z_{2},\Bbb Z_{2} \times \Bbb Z_{4}) \Bbb Z_{2} \times \Bbb Z_{4}","['abstract-algebra', 'group-theory', 'group-homomorphism']"
9,Properties of injective modules,Properties of injective modules,,"I am reading A course in Homological Algebra by Hilton and Stammbach. In the first chapter they showed that a $\Lambda$ -module is projective iff it is a direct summand of a free module. They then defined the categorical dual of projective modules, which are injective modules as follows: A $\Lambda$ -module is injective if for every homomorphism $\alpha:A\to I$ and every monomorphism $\mu:A \to B$ there exists a homomorphism $\beta: B \to I$ such that $\beta \mu = \alpha$ . Then proceed to show the following characterization for when $\Lambda$ is a PID: Let $\Lambda$ be a PID. A $\Lambda$ -module is injective iff it is divisible. Now this seems quite concerning to me because the characterization doesn't seem very ""dual-like"" to projective modules. Two questions natually arise: Does being a divisible module have any categorical relations to being free or being a direct summand? The characterization for injective modules is proved only for PIDs whereas the characterization for projective modules is true for all rings. Is there a generalization to all rings for the injective case, or is there a big-picture reason to why this fails? Because of my interest in K-theory, I have also two more questions: A special case of projective module is stably free module. Is there a categorical dual to stably-freeness and if so what's its relation to injectivity? Projective modules are used in the construction of the $K_0$ group for rings, I'd like to know if injective modules have any significance in the K-theories of rings? Update: Apparently I was too hasty in asking this question, as the next section of the book provides a better characterization, and that is A $\Lambda$ -module $I$ is injective iff it is a direct factor (coincides with direct summand in this case) of a cofree module. This is the kind of result that I was looking for, but the definition of cofree seems even more enigmatic, it is defined to be direct products of $\Lambda^* = \text{Hom}_\mathbb Z(\Lambda, \mathbb Q / \mathbb Z)$ , where $\Lambda ^*$ has the left module structure induced by the right module structure of $\Lambda$ . I am very puzzled by this $\mathbb Q / \mathbb Z$ . I found a thread on MO about cofree modules. Todd explains that free modules does not have a formal dual notion. The definition of cofree with $\mathbb Q/ \mathbb Z$ involved is somewhat ad hoc and imprecise. Considering Captain Lama's comment, I will accept that duality in modules aren't perfect.","I am reading A course in Homological Algebra by Hilton and Stammbach. In the first chapter they showed that a -module is projective iff it is a direct summand of a free module. They then defined the categorical dual of projective modules, which are injective modules as follows: A -module is injective if for every homomorphism and every monomorphism there exists a homomorphism such that . Then proceed to show the following characterization for when is a PID: Let be a PID. A -module is injective iff it is divisible. Now this seems quite concerning to me because the characterization doesn't seem very ""dual-like"" to projective modules. Two questions natually arise: Does being a divisible module have any categorical relations to being free or being a direct summand? The characterization for injective modules is proved only for PIDs whereas the characterization for projective modules is true for all rings. Is there a generalization to all rings for the injective case, or is there a big-picture reason to why this fails? Because of my interest in K-theory, I have also two more questions: A special case of projective module is stably free module. Is there a categorical dual to stably-freeness and if so what's its relation to injectivity? Projective modules are used in the construction of the group for rings, I'd like to know if injective modules have any significance in the K-theories of rings? Update: Apparently I was too hasty in asking this question, as the next section of the book provides a better characterization, and that is A -module is injective iff it is a direct factor (coincides with direct summand in this case) of a cofree module. This is the kind of result that I was looking for, but the definition of cofree seems even more enigmatic, it is defined to be direct products of , where has the left module structure induced by the right module structure of . I am very puzzled by this . I found a thread on MO about cofree modules. Todd explains that free modules does not have a formal dual notion. The definition of cofree with involved is somewhat ad hoc and imprecise. Considering Captain Lama's comment, I will accept that duality in modules aren't perfect.","\Lambda \Lambda \alpha:A\to I \mu:A \to B \beta: B \to I \beta \mu = \alpha \Lambda \Lambda \Lambda K_0 \Lambda I \Lambda^* = \text{Hom}_\mathbb Z(\Lambda, \mathbb Q / \mathbb Z) \Lambda ^* \Lambda \mathbb Q / \mathbb Z \mathbb Q/ \mathbb Z","['abstract-algebra', 'category-theory', 'homological-algebra', 'injective-module', 'algebraic-k-theory']"
10,Alternative proof of the generalized associative law for groups,Alternative proof of the generalized associative law for groups,,"The generalized associative law for groups claims that the value of $a_1\star a_2\star ... \star a_n$ is independent of how it is bracketed, where the symbols denote the usual notations of group theory. While attempting a proof on my own, I discovered a method that seems right to me but does not appear anywhere as a standard proof. Please comment on the validity of this proof, since it is likely I messed up somewhere. Throughout the proof we consider elements belonging to a group $G$ . We attempt a proof by induction on the number of elements in the expression. The base cases of 1,2,3 are seen to be true trivially or by the associative property. Now assume that the value of any n-element expression is independent of how the expression is bracketed. (Induction Hypothesis) Now consider any $(n+1)$ -element expression given by $a_1\star a_2\star ... \star a_n\star a_{n+1}$ . All bracketings of this expression may be divided into $n$ types as follows (these types are not necessarily disjoint ): bracketings containing $(a_1\star a_2)$ bracketings containing $(a_2\star a_3)$ . . . n. bracketings containing $(a_n\star a_{n+1})$ Let $(a_i\star a_{i+1})$ = $a_{(i,i+1)}$ , which is also an element of $G$ (where $i$ ranges from $1$ to $n$ ). Now for any type $i$ considered above, the corresponding $(n+1)$ - element expression can be reduced to an $n$ - element expression by substituting $a_{(i,i+1)}$ instead of $(a_i\star a_{i+1})$ . Then by IH, all bracketings of this type evaluate to a bracketing- independent value which we shall call $A_i$ . It remains to show that $A_1 = A_2 = A_3 = .... = A_n$ . But note that for any $i$ , $A_i$ = $(..((a_1\star a_2)\star a_3)..\star a_{i-1}) \star ((a_{i}\star a_{i+1})\star a_{i+2})\star(..((a_{i+3}\star a_{i+4})\star a_{i+5})..\star a_{n+1})$ = $(..((a_1\star a_2)\star a_3)..\star a_{i-1}) \star (a_{i}\star( a_{i+1}\star a_{i+2}))\star(..((a_{i+3}\star a_{i+4})\star a_{i+5})..\star a_{n+1})$ = $A_{i+1}$ . So for all $i$ from $1$ to $n$ , $A_i$ = $A_{i+1}$ . This implies $A_1 = A_2 = A_3 = .... = A_n$ , as required. This proves the result for the case of $n+1$ . The result is then true by induction for all natural $n$ .","The generalized associative law for groups claims that the value of is independent of how it is bracketed, where the symbols denote the usual notations of group theory. While attempting a proof on my own, I discovered a method that seems right to me but does not appear anywhere as a standard proof. Please comment on the validity of this proof, since it is likely I messed up somewhere. Throughout the proof we consider elements belonging to a group . We attempt a proof by induction on the number of elements in the expression. The base cases of 1,2,3 are seen to be true trivially or by the associative property. Now assume that the value of any n-element expression is independent of how the expression is bracketed. (Induction Hypothesis) Now consider any -element expression given by . All bracketings of this expression may be divided into types as follows (these types are not necessarily disjoint ): bracketings containing bracketings containing . . . n. bracketings containing Let = , which is also an element of (where ranges from to ). Now for any type considered above, the corresponding - element expression can be reduced to an - element expression by substituting instead of . Then by IH, all bracketings of this type evaluate to a bracketing- independent value which we shall call . It remains to show that . But note that for any , = = = . So for all from to , = . This implies , as required. This proves the result for the case of . The result is then true by induction for all natural .","a_1\star a_2\star ... \star a_n G (n+1) a_1\star a_2\star ... \star a_n\star a_{n+1} n (a_1\star a_2) (a_2\star a_3) (a_n\star a_{n+1}) (a_i\star a_{i+1}) a_{(i,i+1)} G i 1 n i (n+1) n a_{(i,i+1)} (a_i\star a_{i+1}) A_i A_1 = A_2 = A_3 = .... = A_n i A_i (..((a_1\star a_2)\star a_3)..\star a_{i-1}) \star ((a_{i}\star a_{i+1})\star a_{i+2})\star(..((a_{i+3}\star a_{i+4})\star a_{i+5})..\star a_{n+1}) (..((a_1\star a_2)\star a_3)..\star a_{i-1}) \star (a_{i}\star( a_{i+1}\star a_{i+2}))\star(..((a_{i+3}\star a_{i+4})\star a_{i+5})..\star a_{n+1}) A_{i+1} i 1 n A_i A_{i+1} A_1 = A_2 = A_3 = .... = A_n n+1 n","['abstract-algebra', 'group-theory', 'induction', 'alternative-proof']"
11,Show that $G = M \circledast N$ has a diagonal subgroup iff $M$ is isomorphic to $N$.,Show that  has a diagonal subgroup iff  is isomorphic to .,G = M \circledast N M N,"A subgroup $D$ of $G = M \circledast N$ is a diagonal subgroup provided: $$D \cap M = 1 = D \cap N$$ $$DM = G = DN$$ (Where $\circledast$ is denoting the internal direct product of $M$ and $N$ .) $$$$ GOAL: Show that $G$ has a diagonal subgroup iff $M \cong N$ . First assume G has a diagonal subgroup as described. Since $G = M \circledast N$ is the internal direct product of $M$ and $N$ we know $M$ and $N$ are normal in $G$ , $G=MN$ and $M \cap N = 1$ . We must show that $M \cong N$ . $$$$ (Here are a few results that may or may not be helpful for getting to a solution. If $G = M \circledast N$ then $G \cong M \times N$ . If $G = M \circledast N = M \circledast L$ then $N \cong L$ .) I need help with the other direction as well. You have my appreciation in advance.","A subgroup of is a diagonal subgroup provided: (Where is denoting the internal direct product of and .) GOAL: Show that has a diagonal subgroup iff . First assume G has a diagonal subgroup as described. Since is the internal direct product of and we know and are normal in , and . We must show that . (Here are a few results that may or may not be helpful for getting to a solution. If then . If then .) I need help with the other direction as well. You have my appreciation in advance.",D G = M \circledast N D \cap M = 1 = D \cap N DM = G = DN \circledast M N  G M \cong N G = M \circledast N M N M N G G=MN M \cap N = 1 M \cong N  G = M \circledast N G \cong M \times N G = M \circledast N = M \circledast L N \cong L,"['abstract-algebra', 'group-theory', 'normal-subgroups', 'group-isomorphism']"
12,If $G$ is finite and every subgroup is characteristic then $G$ is abelian and cyclic,If  is finite and every subgroup is characteristic then  is abelian and cyclic,G G,"I've been trying to prove that if $G$ is finite and every subgroup is characteristic then $G$ is cyclic. If I suppose that $G$ is abelian I've been able to prove it this way The statement is true if $|G|=1$ , so lets supose by induction that it is true for every group of order less than $n$ . Then if $|G|=n=p_1^{\alpha_1} \cdots p_m^{\alpha_m}$ with $p_i$ primes, as $G$ is abelian, we know that is direct product of its uniques Sylow subgroups $$G=P_1P_2 \cdots P_m$$ Let $K$ be a subgroup of $P_i$ and $f \in Aut(P_i)$ , then we can define $h:G \longrightarrow G$ such that given $a \in G$ and $a=a_1 \cdots a_m$ its unique expresion as a product where $a_j \in P_j$ , $$h(a)=h(a_1\cdots a_m)=a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m$$ The function $h$ is a homomorphism because given $a, b \in G$ , if we express $a=a_1 \cdots a_m$ , $b=b_1 \cdots b_m$ in the unique way as specified before, we have that $$ab=(a_1\cdots a_m)(b_1\cdots b_m)=(a_1b_1) \cdots (a_mb_m)$$ and again, because $a_jb_j \in P_j$ , by uniqueness of the expresion we have $$h(ab)=(a_1b_1) \cdots (a_{i-1}b_{i-1}) f(a_ib_i) (a_{i+1}b_{i+1}) \cdots (a_mb_m)=\\=(a_1b_1) \cdots (a_{i-1}b_{i-1}) f(a_i)f(b_i) (a_{i+1}b_{i+1}) \cdots (a_mb_m)=\\=(a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m)(b_1 \cdots b_{i-1} f(b_i) b_{i+1} \cdots b_m)=\\=h(a)h(b)$$ Furthermore, $h$ is inyective because if $h(a)=h(b)$ then $$a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m=b_1 \cdots b_{i-1} f(b_i) b_{i+1} \cdots b_m$$ and again by uniqueness of the expression of an element of $G$ as a product of elements of $P_j$ we have that $a_j=b_j$ if $j=1, \cdots, i-1,i+1, \cdots m$ and $f(a_i)=f(b_i)$ , and as $f$ is injective, $a_j=b_j$ and $a=b$ . We stated that $G$ is finite so $h$ is onto and we conclude that $h \in Aut(G)$ . Now, we observe that as $K \subset P_i$ and it is a characteristic group of $G$ , $f(K)=h(K)=K$ so $K$ is a characteristic group of $P_i$ . So, we have proven that every subgroup of $P_i$ is characteristic in $P_i$ so by induction hypothesis, every $P_i$ is cyclic and there exists elements $a_1, \cdots, a_m$ in $G$ such that $o(a_i)=p_i^{\alpha_i}$ . Lastly, we observe that as the $\gcd(p_1^{\alpha_1}, \cdots, p_m^{\alpha_m})=1$ and $G$ is abelian, we conclude that $$o(a_1\cdots a_m)=p_1^{\alpha_1} \cdots p_m^{\alpha_m}=|G|$$ and then $G$ is cyclic. My doubts now are if this prove is correct and, in case it is correct, is there a way to prove in an easy way that if $G$ is finite and every subgroup is characteristic then $G$ is abelian? Thank you very much for the comments.","I've been trying to prove that if is finite and every subgroup is characteristic then is cyclic. If I suppose that is abelian I've been able to prove it this way The statement is true if , so lets supose by induction that it is true for every group of order less than . Then if with primes, as is abelian, we know that is direct product of its uniques Sylow subgroups Let be a subgroup of and , then we can define such that given and its unique expresion as a product where , The function is a homomorphism because given , if we express , in the unique way as specified before, we have that and again, because , by uniqueness of the expresion we have Furthermore, is inyective because if then and again by uniqueness of the expression of an element of as a product of elements of we have that if and , and as is injective, and . We stated that is finite so is onto and we conclude that . Now, we observe that as and it is a characteristic group of , so is a characteristic group of . So, we have proven that every subgroup of is characteristic in so by induction hypothesis, every is cyclic and there exists elements in such that . Lastly, we observe that as the and is abelian, we conclude that and then is cyclic. My doubts now are if this prove is correct and, in case it is correct, is there a way to prove in an easy way that if is finite and every subgroup is characteristic then is abelian? Thank you very much for the comments.","G G G |G|=1 n |G|=n=p_1^{\alpha_1} \cdots p_m^{\alpha_m} p_i G G=P_1P_2 \cdots P_m K P_i f \in Aut(P_i) h:G \longrightarrow G a \in G a=a_1 \cdots a_m a_j \in P_j h(a)=h(a_1\cdots a_m)=a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m h a, b \in G a=a_1 \cdots a_m b=b_1 \cdots b_m ab=(a_1\cdots a_m)(b_1\cdots b_m)=(a_1b_1) \cdots (a_mb_m) a_jb_j \in P_j h(ab)=(a_1b_1) \cdots (a_{i-1}b_{i-1}) f(a_ib_i) (a_{i+1}b_{i+1}) \cdots (a_mb_m)=\\=(a_1b_1) \cdots (a_{i-1}b_{i-1}) f(a_i)f(b_i) (a_{i+1}b_{i+1}) \cdots (a_mb_m)=\\=(a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m)(b_1 \cdots b_{i-1} f(b_i) b_{i+1} \cdots b_m)=\\=h(a)h(b) h h(a)=h(b) a_1 \cdots a_{i-1} f(a_i) a_{i+1} \cdots a_m=b_1 \cdots b_{i-1} f(b_i) b_{i+1} \cdots b_m G P_j a_j=b_j j=1, \cdots, i-1,i+1, \cdots m f(a_i)=f(b_i) f a_j=b_j a=b G h h \in Aut(G) K \subset P_i G f(K)=h(K)=K K P_i P_i P_i P_i a_1, \cdots, a_m G o(a_i)=p_i^{\alpha_i} \gcd(p_1^{\alpha_1}, \cdots, p_m^{\alpha_m})=1 G o(a_1\cdots a_m)=p_1^{\alpha_1} \cdots p_m^{\alpha_m}=|G| G G G","['abstract-algebra', 'group-theory', 'finite-groups']"
13,Why is $\mathscr C\to \mathbf{Mon}$ an equivalence?,Why is  an equivalence?,\mathscr C\to \mathbf{Mon},"In Example 1.3.21 Leinster says that the functor $F: \mathscr C\to \mathbf{Mon}$ sending a one-object category to the monoid of arrows from the unique object to itself is full, faithful, and essentially surjective on objects. He says that fullness and faithfullness follows from Example 1.2.7 which says that a functor between categories corresponding to monoids is the same as a homomorphism of monoids. How does this imply that $F$ is full and faithful? I also don't understand why $F$ is essentially surjective on objects. This would mean that every monoid is a set of arrows from some object to itself under composition. Why does this hold?","In Example 1.3.21 Leinster says that the functor sending a one-object category to the monoid of arrows from the unique object to itself is full, faithful, and essentially surjective on objects. He says that fullness and faithfullness follows from Example 1.2.7 which says that a functor between categories corresponding to monoids is the same as a homomorphism of monoids. How does this imply that is full and faithful? I also don't understand why is essentially surjective on objects. This would mean that every monoid is a set of arrows from some object to itself under composition. Why does this hold?",F: \mathscr C\to \mathbf{Mon} F F,"['abstract-algebra', 'category-theory']"
14,"Non-unique factorization of ideals in $\mathbb{Z}[t,t^{-1}]$",Non-unique factorization of ideals in,"\mathbb{Z}[t,t^{-1}]","Edited version: In a Dedekind domain $R$ , every nonzero proper ideal factors uniquely as a product of prime ideals. If $R$ is a Noetherian domain, then by this post any ideal $I$ which does factor into a product of primes, does so uniquely. The ideal class monoid of $R$ is the quotient of the monoid of nonzero ideals of $R$ under multiplication by the equivalence relation $I\sim J$ if there exist $x,y$ so that $(x)I=(y)J$ . If $R$ is also a UFD, irreducible elements are prime, so all nonzero proper principal ideals factor into a product of primes. Therefore, if $I$ factors as a product of primes, it can be factored as a principal ideal times some unique nonprincipal prime ideals $p_1,\dots,p_n$ , and since $(x)I$ also has a unique prime factorization for all nonzero $x\in R$ its ideal class will consist of $\{(x)p_1\cdots p_n:x\in R\}$ . I am wondering if this ever doesn't happen, ie. if there can be an ideal class which is not of the form $\{(x)I\}$ for some ideal $I$ . By the above discussion a necessary requirement is that $I$ does not factor as a product of prime ideals. The ring I'm interested in is $\mathbb{Z}[t,t^{-1}]$ , which has trivial Picard group, so the only invertible ideals are already principal. Another way to think about this question is the following: consider a graph $\Gamma$ with vertices the nonzero ideals of $R$ and a directed edge $I\rightarrow J$ whenever there is some nonzero $x\in R$ so that $J=(x)I$ . The connected components of this graph are the ideal classes of $R$ . Maximal ideals are ""roots"", so is any product of nonprincipal prime ideals, and by the above they are the only roots of their connected components. I would like an example of an ideal class which has more than one root. Otherwise, every ideal class has a unique root $I$ , and the only ideals $J\sim I$ are of the form $J=(x)I$ , which is not very interesting. A case of two roots in the same component will yield an equation $(x)I=(y)J$ , where $I$ and $J$ are not both principal ideal multiples of a third ideal $K$ , so this is a particular way an ideal can have distinct factorizations, hence the original question. Thanks for any comments or questions! [Original post: I know that unique factorization of nonzero proper ideals in an integral domain $R$ is equivalent to being a Dedekind domain, and that my ring of interest, $\mathbb{Z}[t,t^{-1}]$ , is not Dedekind, because it has dimension 2 and Dedekind domains have dimension 1. So $R=\mathbb{Z}[t,t^{-1}]$ must have a nonzero proper ideal which factors non-uniquely. What is an example? I would think that such an ideal would not factor as a product of prime ideals, e.g. $(4, t+1)$ appears to be unfactorable, yet is not prime. My strategy so far has been to find unfactorable ideals $I$ , $J$ so that $(f)I=(g)J$ for some nonzero $f,g\in R$ . Really what I am interested in is an example of an ideal class in the ideal class monoid of $R$ which is not of the form $\{(f(t))I:f(t)\in R\}$ for some ideal $I$ , but my hope is that an ideal which factors non-uniquely will supply such an example.]","Edited version: In a Dedekind domain , every nonzero proper ideal factors uniquely as a product of prime ideals. If is a Noetherian domain, then by this post any ideal which does factor into a product of primes, does so uniquely. The ideal class monoid of is the quotient of the monoid of nonzero ideals of under multiplication by the equivalence relation if there exist so that . If is also a UFD, irreducible elements are prime, so all nonzero proper principal ideals factor into a product of primes. Therefore, if factors as a product of primes, it can be factored as a principal ideal times some unique nonprincipal prime ideals , and since also has a unique prime factorization for all nonzero its ideal class will consist of . I am wondering if this ever doesn't happen, ie. if there can be an ideal class which is not of the form for some ideal . By the above discussion a necessary requirement is that does not factor as a product of prime ideals. The ring I'm interested in is , which has trivial Picard group, so the only invertible ideals are already principal. Another way to think about this question is the following: consider a graph with vertices the nonzero ideals of and a directed edge whenever there is some nonzero so that . The connected components of this graph are the ideal classes of . Maximal ideals are ""roots"", so is any product of nonprincipal prime ideals, and by the above they are the only roots of their connected components. I would like an example of an ideal class which has more than one root. Otherwise, every ideal class has a unique root , and the only ideals are of the form , which is not very interesting. A case of two roots in the same component will yield an equation , where and are not both principal ideal multiples of a third ideal , so this is a particular way an ideal can have distinct factorizations, hence the original question. Thanks for any comments or questions! [Original post: I know that unique factorization of nonzero proper ideals in an integral domain is equivalent to being a Dedekind domain, and that my ring of interest, , is not Dedekind, because it has dimension 2 and Dedekind domains have dimension 1. So must have a nonzero proper ideal which factors non-uniquely. What is an example? I would think that such an ideal would not factor as a product of prime ideals, e.g. appears to be unfactorable, yet is not prime. My strategy so far has been to find unfactorable ideals , so that for some nonzero . Really what I am interested in is an example of an ideal class in the ideal class monoid of which is not of the form for some ideal , but my hope is that an ideal which factors non-uniquely will supply such an example.]","R R I R R I\sim J x,y (x)I=(y)J R I p_1,\dots,p_n (x)I x\in R \{(x)p_1\cdots p_n:x\in R\} \{(x)I\} I I \mathbb{Z}[t,t^{-1}] \Gamma R I\rightarrow J x\in R J=(x)I R I J\sim I J=(x)I (x)I=(y)J I J K R \mathbb{Z}[t,t^{-1}] R=\mathbb{Z}[t,t^{-1}] (4, t+1) I J (f)I=(g)J f,g\in R R \{(f(t))I:f(t)\in R\} I","['abstract-algebra', 'number-theory', 'commutative-algebra', 'factoring', 'ideal-class-group']"
15,Total order relations on $\mathbb{Z}_{2^n}$,Total order relations on,\mathbb{Z}_{2^n},"I'm a programmer and not a professional mathematician so I need some abstract-algebra help regarding the following question: Introduction: When performing integer comparison x86 CPU s have some instructions that compares only signed 2's complement integers. So in order to perform unsigned comparison we usually use the following proposition: $a \leq_{signed} b \iff a + 2^{n-1} \leq_{unsigned} b + 2^{n-1}$ for $n$ -bit integers (i.e xor 0x800...000 ). This is not really obvious for me so I'm looking for a formal proof of that ""ought to be obvious"" fact. My thoughts: Consider $\mathbb{Z}_{2^n}$ group with + operation and for any $m \in \mathbb{Z}_{2^n}$ define the following relations $\forall a \neq m:  a \leq_m a + 1$ . So the signed and unsigned comparison can be defined as $\leq_{2^{n-1} -1}$ and $\leq_{2^n-1}$ . The first thing I'm considering to prove is that for each $m\in\mathbb{Z}_{2^n}$ there is only one total order relation $\leq_m$ . This can be easily proven by assuming two different total order relations with $\forall a \neq m:  a \leq_m a + 1$ which are equal then. Now I'm considering to prove that for any $m, k \in\mathbb{Z}_{2^n}$ we have $a \leq_m b \iff a + (m - k)\leq_k b + (m - k)$ . The question is if the latter statement is even true? If so, can you give a hint how to prove this.","I'm a programmer and not a professional mathematician so I need some abstract-algebra help regarding the following question: Introduction: When performing integer comparison x86 CPU s have some instructions that compares only signed 2's complement integers. So in order to perform unsigned comparison we usually use the following proposition: for -bit integers (i.e xor 0x800...000 ). This is not really obvious for me so I'm looking for a formal proof of that ""ought to be obvious"" fact. My thoughts: Consider group with + operation and for any define the following relations . So the signed and unsigned comparison can be defined as and . The first thing I'm considering to prove is that for each there is only one total order relation . This can be easily proven by assuming two different total order relations with which are equal then. Now I'm considering to prove that for any we have . The question is if the latter statement is even true? If so, can you give a hint how to prove this.","a \leq_{signed} b \iff a + 2^{n-1} \leq_{unsigned} b + 2^{n-1} n \mathbb{Z}_{2^n} m \in \mathbb{Z}_{2^n} \forall a \neq m:  a \leq_m a + 1 \leq_{2^{n-1} -1} \leq_{2^n-1} m\in\mathbb{Z}_{2^n} \leq_m \forall a \neq m:  a \leq_m a + 1 m, k \in\mathbb{Z}_{2^n} a \leq_m b \iff a + (m - k)\leq_k b + (m - k)","['abstract-algebra', 'group-theory', 'finite-groups', 'intuition']"
16,Center of wreath product $\mathbb{Z_n} \wr \mathbb{Z_m}$ and $\mathbb{S_m} \wr \mathbb{Z_n}$,Center of wreath product  and,\mathbb{Z_n} \wr \mathbb{Z_m} \mathbb{S_m} \wr \mathbb{Z_n},"I have a problem with calculate center of wreath products $\mathbb{Z_n} \wr \mathbb{Z_m}$ and $\mathbb{S_m} \wr \mathbb{Z_n}$ . I was trying to write definitions and try do calculate something, but I don't have any idea how to do it. Could someone help me with some ideas?","I have a problem with calculate center of wreath products and . I was trying to write definitions and try do calculate something, but I don't have any idea how to do it. Could someone help me with some ideas?",\mathbb{Z_n} \wr \mathbb{Z_m} \mathbb{S_m} \wr \mathbb{Z_n},"['abstract-algebra', 'group-theory']"
17,"A question on ""generating graphs""","A question on ""generating graphs""",,"Suppose $H$ is a group. $X \subset H$ , $|X| < \infty$ . Lets define $GG(H, X)$ (generating graph of $H$ ) as a finite undirected simple graph $\Gamma(V, E)$ , such that $V = X$ , $E = \{(x, y) \in X \times X| x \neq y, \langle x, y \rangle = H\}$ . $GG(H, X)$ has following properties (which are relatively obvious): If $K < H$ , then $GG(K, K \cap X)$ is a subgraph of the complementary graph of $GG(H, X)$ If $\phi: H \to K$ is a surjective group homomorphism, such that $\phi|_X$ is injective. then $GG(K, \phi(X))$ contains $GG(H, \phi(X))$ as a subgraph. $Stab(X, Aut(H)) \leq Aut(GG(H, X))$ , where $Stab(X, Aut(H)) = \{\phi \in Aut(H)| \phi(X) = X\}$ My question however is: Does for any finite simple undirected graph $\Gamma$ , there exist such a group $H$ and its finite subset $X$ , that $\Gamma \cong GG(H, X)$ ? I failed to construct such $H$ and $X$ for arbitrary $\Gamma$ , however a counterexample does not come to my mind either.","Suppose is a group. , . Lets define (generating graph of ) as a finite undirected simple graph , such that , . has following properties (which are relatively obvious): If , then is a subgraph of the complementary graph of If is a surjective group homomorphism, such that is injective. then contains as a subgraph. , where My question however is: Does for any finite simple undirected graph , there exist such a group and its finite subset , that ? I failed to construct such and for arbitrary , however a counterexample does not come to my mind either.","H X \subset H |X| < \infty GG(H, X) H \Gamma(V, E) V = X E = \{(x, y) \in X \times X| x \neq y, \langle x, y \rangle = H\} GG(H, X) K < H GG(K, K \cap X) GG(H, X) \phi: H \to K \phi|_X GG(K, \phi(X)) GG(H, \phi(X)) Stab(X, Aut(H)) \leq Aut(GG(H, X)) Stab(X, Aut(H)) = \{\phi \in Aut(H)| \phi(X) = X\} \Gamma H X \Gamma \cong GG(H, X) H X \Gamma","['abstract-algebra', 'combinatorics', 'group-theory', 'graph-theory', 'finitely-generated']"
18,Local properties of rings,Local properties of rings,,"Let $R$ be a ring or more genrally a $R$ -module $M$ . My question is what is the intuition behind or more precisely when following argumentation is applicable: Let $\mathcal{P}$ be a ring theoretical property then $R$ has $\mathcal{P}$ if and only if ALL localisations $R_m$ with respect to the maximal ideals $m$ of $R$ have property $\mathcal{P}$ What is the deeper nature of the properties $\mathcal{P}$ which are compatible with the argumentation technique described above? Taking into account the theory of schemes one can simply say that this concerns ""local"" properties. Is there any intuition to recognize when such property has local nature?","Let be a ring or more genrally a -module . My question is what is the intuition behind or more precisely when following argumentation is applicable: Let be a ring theoretical property then has if and only if ALL localisations with respect to the maximal ideals of have property What is the deeper nature of the properties which are compatible with the argumentation technique described above? Taking into account the theory of schemes one can simply say that this concerns ""local"" properties. Is there any intuition to recognize when such property has local nature?",R R M \mathcal{P} R \mathcal{P} R_m m R \mathcal{P} \mathcal{P},['abstract-algebra']
19,"Large counterexamples to ""Non-isomorphic finite groups have verbal subgroups of different order""","Large counterexamples to ""Non-isomorphic finite groups have verbal subgroups of different order""",,"In this question , it was conjectured that for every pair of non-isomorphic finite groups $G$ and $H$ , there exists some word $\omega$ such that $|V_{\omega}(G)|\ne|V_{\omega}(H)|$ , i.e. their corresponding verbal subgroups have unequal order. The answer is no: the groups $D_4$ and $Q_8$ yield a counterexample, as explained in the link. However, these are relatively small groups with relatively few subgroups. It seems reasonable that this conjecture fails for small groups as they don't have quite enough structure for verbal subgroups to tell them apart. Is this conjecture true for sufficiently large groups? That is, does there exist some $n\in\mathbb{N}$ such that any counterexample pair $(G,H)$ must have order $|G|,|H|\le n$ ?","In this question , it was conjectured that for every pair of non-isomorphic finite groups and , there exists some word such that , i.e. their corresponding verbal subgroups have unequal order. The answer is no: the groups and yield a counterexample, as explained in the link. However, these are relatively small groups with relatively few subgroups. It seems reasonable that this conjecture fails for small groups as they don't have quite enough structure for verbal subgroups to tell them apart. Is this conjecture true for sufficiently large groups? That is, does there exist some such that any counterexample pair must have order ?","G H \omega |V_{\omega}(G)|\ne|V_{\omega}(H)| D_4 Q_8 n\in\mathbb{N} (G,H) |G|,|H|\le n","['abstract-algebra', 'group-theory', 'finite-groups', 'verbal-subgroups']"
20,Different ways we can paint the faces of a tetrahedron using $4$ colors,Different ways we can paint the faces of a tetrahedron using  colors,4,"Suppose we want to paint the faces of a tetrahedron using $4$ different colors, assuming that we allow different faces to be painted with the same color. By not taking the symmetries of tetrahedron into account, there are $|X|=4^4=256$ ways. Now, when its symmetries are introduced, from Burnside's orbit-counting theorem : $$ r=\frac{1}{|G|}\sum_{g \in G}|X_g| $$ where $G$ is the symmetry group of the tetrahedron (considering only orientation preserving symmetries), $X_g$ are the elements fixed by $g$ and $r$ is the number of orbits of $X$ under $G$ 's action. Therefore, we need to keep track of how many elements are fixed by every $g \in G$ . $\bullet \space $ The identity element keeps everything unchanged, so $X_e=256$ $\bullet \space $ Let $\rho^j_i$ denote the rotations about the vertex $i$ by $j$ degrees. For the element to stay fixed, the adjacent faces to this vertex must be of the same color. So $$|X_{\rho^{120}_1}|=|X_{\rho_1^{240}}|=\dots=|X_{\rho^{240}_4}|=4 \cdot4=16$$ $\bullet \space $ There are $3$ more symmetries left to examine, which are the $180^o$ rotations, $m_1,m_2, m_3$ . Elements stay fixed only if they have two pairs of similarly colored adjacent faces. Thus $$ |X_{m_1}|=|X_{m_2}|=|X_{m_3}|=4 \cdot 4=16 $$ Taking all this into account, we yield: $$ r=\frac{1}{12}(256+8 \cdot 16 + 3 \cdot 16)=\frac{432}{12}=36 $$ Therefore, there are $36$ different ways to color the faces of a tetrahedron using $4$ colors.","Suppose we want to paint the faces of a tetrahedron using different colors, assuming that we allow different faces to be painted with the same color. By not taking the symmetries of tetrahedron into account, there are ways. Now, when its symmetries are introduced, from Burnside's orbit-counting theorem : where is the symmetry group of the tetrahedron (considering only orientation preserving symmetries), are the elements fixed by and is the number of orbits of under 's action. Therefore, we need to keep track of how many elements are fixed by every . The identity element keeps everything unchanged, so Let denote the rotations about the vertex by degrees. For the element to stay fixed, the adjacent faces to this vertex must be of the same color. So There are more symmetries left to examine, which are the rotations, . Elements stay fixed only if they have two pairs of similarly colored adjacent faces. Thus Taking all this into account, we yield: Therefore, there are different ways to color the faces of a tetrahedron using colors.","4 |X|=4^4=256 
r=\frac{1}{|G|}\sum_{g \in G}|X_g|
 G X_g g r X G g \in G \bullet \space  X_e=256 \bullet \space  \rho^j_i i j |X_{\rho^{120}_1}|=|X_{\rho_1^{240}}|=\dots=|X_{\rho^{240}_4}|=4 \cdot4=16 \bullet \space  3 180^o m_1,m_2, m_3 
|X_{m_1}|=|X_{m_2}|=|X_{m_3}|=4 \cdot 4=16
 
r=\frac{1}{12}(256+8 \cdot 16 + 3 \cdot 16)=\frac{432}{12}=36
 36 4","['abstract-algebra', 'combinatorics', 'group-theory', 'proof-verification', 'group-actions']"
21,Question about Isomorphism of Aut(G),Question about Isomorphism of Aut(G),,"In material supplied by my instructor there is a question which asks to pick the incorrect statement among the following: If $\text{Aut}(G_1)\cong \text{Aut}(G_2)$ and $G_1$ is infinite group then $G_2$ is also infinite If $\text{Aut}(G_1) \cong \text{Aut}(G_2)$ and $G_1$ is finite group then $G_2$ is also finite If $G_1$ not isomorphic to $G_2$ then Aut( $G_1$ ) not isomorphic to Aut( $G_2$ ). $G_1$ and $G_2$ are two groups, Aut(G) is group of their automorphisms and "" $\cong$ "" means isomorphism. I know all three above are incorrect as Aut( $\Bbb Z_3$ )= $U_3$ (that is, $\Bbb Z_2$ ) and I also found this statement on groupprops : ""Of the three endomorphisms, two are automorphisms: the identity map and the square map. These form a cyclic group of order two: the square map, applied twice, gives the identity map"" and Aut( $\Bbb Z$ ) is isomorphic to $\Bbb Z_2$ so $G_1=\Bbb Z$ and $G_2=\Bbb Z_3$ $G_2=\Bbb Z$ and $G_1=\Bbb Z_3$ We can easily see $\Bbb Z$ and $\Bbb Z_3$ are not isomorphic but Aut( $\Bbb Z$ ) and Aut( $\Bbb Z_3$ ) are. But the given answer is that (1.) is only incorrect statement. Is there any problem in my reasoning?","In material supplied by my instructor there is a question which asks to pick the incorrect statement among the following: If and is infinite group then is also infinite If and is finite group then is also finite If not isomorphic to then Aut( ) not isomorphic to Aut( ). and are two groups, Aut(G) is group of their automorphisms and "" "" means isomorphism. I know all three above are incorrect as Aut( )= (that is, ) and I also found this statement on groupprops : ""Of the three endomorphisms, two are automorphisms: the identity map and the square map. These form a cyclic group of order two: the square map, applied twice, gives the identity map"" and Aut( ) is isomorphic to so and and We can easily see and are not isomorphic but Aut( ) and Aut( ) are. But the given answer is that (1.) is only incorrect statement. Is there any problem in my reasoning?",\text{Aut}(G_1)\cong \text{Aut}(G_2) G_1 G_2 \text{Aut}(G_1) \cong \text{Aut}(G_2) G_1 G_2 G_1 G_2 G_1 G_2 G_1 G_2 \cong \Bbb Z_3 U_3 \Bbb Z_2 \Bbb Z \Bbb Z_2 G_1=\Bbb Z G_2=\Bbb Z_3 G_2=\Bbb Z G_1=\Bbb Z_3 \Bbb Z \Bbb Z_3 \Bbb Z \Bbb Z_3,"['abstract-algebra', 'group-theory', 'automorphism-group']"
22,Prove order of a group is even,Prove order of a group is even,,"I am trying to solve this question and wanted to know whether my proof was correct. Suppose that $n \geq 3$ , $n$ is odd, $G$ is a non-trivial group and $\varphi : D_{2n} \rightarrow G$ is a surjective homomorphism. (a) Prove that $|G|$ is even. (b) Prove that every proper normal subgroup of $G$ has odd order. My attempt for a : Since $G$ is not trivial and is equal to $\varphi(D_{2n})$ , then either $\varphi(s) \not = 1$ or $\varphi(r) \not = 1$ . If $\varphi(s) \not = 1$ , then we have $\varphi(s)^2 = 1$ and we have found an element of order 2 in $G$ so it must be even. If $\varphi(r) \not = 1, \varphi(s) = 1$ , then we have that $\varphi(sr) = \varphi(r^{-1}s) \Rightarrow \varphi(s)\varphi(r) = \varphi(r)^{-1}\varphi(s) \Rightarrow \varphi(r) = \varphi(r)^{-1} \Rightarrow \varphi(r)^2 = 1$ and since $\varphi(r) \not = 1$ , we have again found an element of order 2 in $G$ . My attempt for b : I'm not sure about this one, but I first note that by the first isomorphism theorem, $G \cong D_{2n}/\ker(\varphi)$ . Any proper normal subgroup of $G$ now has to be isomorphic to one of $D_{2n}/\ker(\varphi)$ . Then, by the fourth isomorphism theorem, it has to be isomorphic to a normal subgroup of $D_{2n}$ . Now I don't know how to proceed.","I am trying to solve this question and wanted to know whether my proof was correct. Suppose that , is odd, is a non-trivial group and is a surjective homomorphism. (a) Prove that is even. (b) Prove that every proper normal subgroup of has odd order. My attempt for a : Since is not trivial and is equal to , then either or . If , then we have and we have found an element of order 2 in so it must be even. If , then we have that and since , we have again found an element of order 2 in . My attempt for b : I'm not sure about this one, but I first note that by the first isomorphism theorem, . Any proper normal subgroup of now has to be isomorphic to one of . Then, by the fourth isomorphism theorem, it has to be isomorphic to a normal subgroup of . Now I don't know how to proceed.","n \geq 3 n G \varphi : D_{2n} \rightarrow G |G| G G \varphi(D_{2n}) \varphi(s) \not = 1 \varphi(r) \not = 1 \varphi(s) \not = 1 \varphi(s)^2 = 1 G \varphi(r) \not = 1, \varphi(s) = 1 \varphi(sr) = \varphi(r^{-1}s) \Rightarrow \varphi(s)\varphi(r) = \varphi(r)^{-1}\varphi(s) \Rightarrow \varphi(r) = \varphi(r)^{-1} \Rightarrow \varphi(r)^2 = 1 \varphi(r) \not = 1 G G \cong D_{2n}/\ker(\varphi) G D_{2n}/\ker(\varphi) D_{2n}","['abstract-algebra', 'group-theory', 'finite-groups', 'dihedral-groups']"
23,Finding the minimum degree of a representation of an algebra,Finding the minimum degree of a representation of an algebra,,"I'm reading this paper, and in it the authors make the following claim (Eq. 27 in the paper): They first show that a certain subspace of $\mathbb{C}^N$ is invariant under a set of unitary operators $\{Z_i, Y_i\}$, $i=1,...,\alpha$, satisfying $[Z_i,Z_j]=0$ $[Y_i,Y_j]=0$ $[Y_i,Z_j]=0\quad$ provided $i\neq j$ $Y_iZ_i=e^{2\pi i p/q}Z_iY_i\qquad$  ($p/q$ is a fraction in lowest form) They go on to say the algebra generated by the $\{Z_i,Y_i\}$ can be represented in this subspace; in other words, by restricting the $Z_i,Y_i$ to act only on this subspace, we can get a lower-dimensional representation of the algebra. That makes sense. They then say that this representation must have degree at least $q^{\alpha}$, where $q$ is the denominator in the fourth bullet point. I don't understand how they reach this conclusion. How can we conclude from the relations between the generators that we cannot have a smaller complex representation than degree $q^\alpha$? Is there a method in general to find the minimal degree of a representation from some presentation of an algebra?","I'm reading this paper, and in it the authors make the following claim (Eq. 27 in the paper): They first show that a certain subspace of $\mathbb{C}^N$ is invariant under a set of unitary operators $\{Z_i, Y_i\}$, $i=1,...,\alpha$, satisfying $[Z_i,Z_j]=0$ $[Y_i,Y_j]=0$ $[Y_i,Z_j]=0\quad$ provided $i\neq j$ $Y_iZ_i=e^{2\pi i p/q}Z_iY_i\qquad$  ($p/q$ is a fraction in lowest form) They go on to say the algebra generated by the $\{Z_i,Y_i\}$ can be represented in this subspace; in other words, by restricting the $Z_i,Y_i$ to act only on this subspace, we can get a lower-dimensional representation of the algebra. That makes sense. They then say that this representation must have degree at least $q^{\alpha}$, where $q$ is the denominator in the fourth bullet point. I don't understand how they reach this conclusion. How can we conclude from the relations between the generators that we cannot have a smaller complex representation than degree $q^\alpha$? Is there a method in general to find the minimal degree of a representation from some presentation of an algebra?",,"['abstract-algebra', 'group-theory', 'representation-theory']"
24,On epimorphisms of groups.,On epimorphisms of groups.,,"I want to prove by absurdity that every epimorphism of groups is a surjective morphism. So let $f\colon A\to B$ be an epimorphism of groups. Let by absurd assume that $f$ is non surjective, so that the image $f(A)$ of $f$ is properly contained in $B$ and let us also assume that $f(A)$ is not a normal subgroup of $B$, because in that case we can form the quotient group of classes of elements of $B$ modulo $f(A)$ and use the same argument that is used for abelian groups. So, the index of $f(A)$ in $B$ must be at least $3$, otherwise $f(A)$ would be normal in $B$. Let $f(A)$, $f(A)u$ and $f(A)v$ be three distinct cosets of $f(A)$ in $B$. Then, we consider the permutation $\sigma$ on $B$, defined by: $\sigma(xu)=xv$ for all $x\in f(A)$; $\sigma(xv)=xu$ for all $x\in f(A)$ and $\sigma(b)=b$ on the remaining part of $B$. Then, for all $x,b\in B$, let us define $\psi_b(x)=bx$ and $\overline{\psi}_b=\sigma^{-1}\circ\psi_b\circ\sigma$. Let us finally define $\psi,\overline{\psi}\colon B\to\operatorname{Sym}_B$ by $\psi(b)=\psi_b$ and $\overline{\psi}(b)=\overline{\psi}_b$. Since $\psi\circ f=\overline{\psi}\circ f$, then $\psi=\overline{\psi}$, because $f$ is assumed to be an epimorphism. So I need to prove that $\psi\neq\overline{\psi}$ to get a contradiction, but I can't. Can you please help me to show that actually $\psi\neq\overline{\psi}$.","I want to prove by absurdity that every epimorphism of groups is a surjective morphism. So let $f\colon A\to B$ be an epimorphism of groups. Let by absurd assume that $f$ is non surjective, so that the image $f(A)$ of $f$ is properly contained in $B$ and let us also assume that $f(A)$ is not a normal subgroup of $B$, because in that case we can form the quotient group of classes of elements of $B$ modulo $f(A)$ and use the same argument that is used for abelian groups. So, the index of $f(A)$ in $B$ must be at least $3$, otherwise $f(A)$ would be normal in $B$. Let $f(A)$, $f(A)u$ and $f(A)v$ be three distinct cosets of $f(A)$ in $B$. Then, we consider the permutation $\sigma$ on $B$, defined by: $\sigma(xu)=xv$ for all $x\in f(A)$; $\sigma(xv)=xu$ for all $x\in f(A)$ and $\sigma(b)=b$ on the remaining part of $B$. Then, for all $x,b\in B$, let us define $\psi_b(x)=bx$ and $\overline{\psi}_b=\sigma^{-1}\circ\psi_b\circ\sigma$. Let us finally define $\psi,\overline{\psi}\colon B\to\operatorname{Sym}_B$ by $\psi(b)=\psi_b$ and $\overline{\psi}(b)=\overline{\psi}_b$. Since $\psi\circ f=\overline{\psi}\circ f$, then $\psi=\overline{\psi}$, because $f$ is assumed to be an epimorphism. So I need to prove that $\psi\neq\overline{\psi}$ to get a contradiction, but I can't. Can you please help me to show that actually $\psi\neq\overline{\psi}$.",,"['abstract-algebra', 'group-theory', 'category-theory']"
25,"Lemma: Let $b,c \in \mathbb{Q}-\{0\}$. Then $\mathbb{Q}(\sqrt2,\sqrt3) =\mathbb{Q}(b\sqrt2+c\sqrt3+\sqrt6)$.",Lemma: Let . Then .,"b,c \in \mathbb{Q}-\{0\} \mathbb{Q}(\sqrt2,\sqrt3) =\mathbb{Q}(b\sqrt2+c\sqrt3+\sqrt6)","I am attempting to prove that $\mathbb{Q}(\sqrt2,\sqrt3)=\mathbb{Q}()$ iff $=a+b\sqrt2+c\sqrt3+d\sqrt6$ where $a,b,c,d\in \mathbb{Q}$ and two or more of $b,c,d$ are nonzero. The forward direction is easy, but I am having some trouble with the backward direction. Let $=a+b\sqrt2+c\sqrt3+d\sqrt6$, where $a,b,c,d\in \mathbb{Q}$ and at least two of $b,c,d$ are nonzero. I see that, without loss of generality, we can assume $a=0$. Now, the problem splits in two cases. Either exactly two of $b,c,d$ are nonzero OR all three of $b,c,d$ are nonzero. I think I can tackle the former case on my own, but I could use some help on the latter. Assume $b,c,d$ are all nonzero. WLOG, we can take $d=1$ so $=b\sqrt2+c\sqrt3+\sqrt6$. I see that $\mathbb{Q}(\sqrt2,\sqrt3) \supseteq \mathbb{Q}()$, but I need some help proving $\subseteq$. An elementary, straightforward, complete proof without gaps is what I'm looking for. I desire to prove the following Lemma: Let $b,c \in \mathbb{Q}-\{0\}$. Then $\mathbb{Q}(\sqrt2,\sqrt3)=\mathbb{Q}(b\sqrt2+c\sqrt3+\sqrt6)$.","I am attempting to prove that $\mathbb{Q}(\sqrt2,\sqrt3)=\mathbb{Q}()$ iff $=a+b\sqrt2+c\sqrt3+d\sqrt6$ where $a,b,c,d\in \mathbb{Q}$ and two or more of $b,c,d$ are nonzero. The forward direction is easy, but I am having some trouble with the backward direction. Let $=a+b\sqrt2+c\sqrt3+d\sqrt6$, where $a,b,c,d\in \mathbb{Q}$ and at least two of $b,c,d$ are nonzero. I see that, without loss of generality, we can assume $a=0$. Now, the problem splits in two cases. Either exactly two of $b,c,d$ are nonzero OR all three of $b,c,d$ are nonzero. I think I can tackle the former case on my own, but I could use some help on the latter. Assume $b,c,d$ are all nonzero. WLOG, we can take $d=1$ so $=b\sqrt2+c\sqrt3+\sqrt6$. I see that $\mathbb{Q}(\sqrt2,\sqrt3) \supseteq \mathbb{Q}()$, but I need some help proving $\subseteq$. An elementary, straightforward, complete proof without gaps is what I'm looking for. I desire to prove the following Lemma: Let $b,c \in \mathbb{Q}-\{0\}$. Then $\mathbb{Q}(\sqrt2,\sqrt3)=\mathbb{Q}(b\sqrt2+c\sqrt3+\sqrt6)$.",,"['abstract-algebra', 'field-theory']"
26,computer program-software for galois,computer program-software for galois,,"I need a reference for a good algebra program-software, especially for Galois theory. What I have found so far is PARI which calculates the galois group over $\mathbb Q$ of a polynomial up to degree 8, but what I am missing which I need, is to be able to calculate, say for $a=\sqrt{2}+\sqrt{3}+\sqrt{5}$, the irreducible polynomial $irr_{\mathbb{Q}, a}$(x), or even maybe over different fields. Maybe Pari can calculate that as well but personally I couldn't find how and the manual was not very illuminating. Other programs I have heard of for algebra are CoCoa and Macaulay but it 's really time consuming searching what are the capabilities of each one of them, so I decided to post this as a question, in case anyone could suggest such a program which he found most convenient. So overall 2 questions: 1)In general, which program do you find most convenient for abstract algebra? 2)Specifically for Galois? (need not be different from the above)","I need a reference for a good algebra program-software, especially for Galois theory. What I have found so far is PARI which calculates the galois group over $\mathbb Q$ of a polynomial up to degree 8, but what I am missing which I need, is to be able to calculate, say for $a=\sqrt{2}+\sqrt{3}+\sqrt{5}$, the irreducible polynomial $irr_{\mathbb{Q}, a}$(x), or even maybe over different fields. Maybe Pari can calculate that as well but personally I couldn't find how and the manual was not very illuminating. Other programs I have heard of for algebra are CoCoa and Macaulay but it 's really time consuming searching what are the capabilities of each one of them, so I decided to post this as a question, in case anyone could suggest such a program which he found most convenient. So overall 2 questions: 1)In general, which program do you find most convenient for abstract algebra? 2)Specifically for Galois? (need not be different from the above)",,"['abstract-algebra', 'galois-theory', 'math-software', 'computational-algebra']"
27,Showing $\mathbb{Z}[i]/(1+2i) \oplus\mathbb{Z}[i]/(6-i)\cong\mathbb{Z}[i]/(8+11i)$,Showing,\mathbb{Z}[i]/(1+2i) \oplus\mathbb{Z}[i]/(6-i)\cong\mathbb{Z}[i]/(8+11i),"I am attempting to solve Ch 14 Problem 7.7 from Artin's algebra book. Let $R=\mathbb{Z}[i]$ and let $V$ be the R-module generated by elements $v_1$ and $v_2$ with relations $(1+i)v_1+(2-i)v_2=0$ and $3v_1+5iv_2=0$. Write this module as a direct sum of cyclic modules. Attempt I have obtained $V\cong R^2/ \begin{bmatrix} 1+i & 3 \\ 2-i & 5i \end{bmatrix} R^2 \cong R/[8+11i]R=\mathbb{Z}[i]/(8+11i)$. Now, I see that $(1+2i)(6-i)=8+11i.$ Now, I would like to show that $\mathbb{Z}[i]/(1+2i) \oplus\mathbb{Z}[i]/(6-i)\cong\mathbb{Z}[i]/(8+11i)$, so I can have $V$ as a direct sum of cyclic modules as needed, but how can I show this? I have already shown that $(1+2i,6-i)=(1)=\mathbb{Z}[i]$ and thus $(1+2i)+(6-i)=\mathbb{Z}[i]$. Intuition would suggest that $(1+2i)\oplus(6-i)=\mathbb{Z}[i]$, although I think this is false since $(i-6)(1+2i)+(1+2i)(6-i)=0$. I must confess that I am very new to module theory so please be patient with me. I don't even how it would be possible to have $\mathbb{Z}[i]/(1+2i) \oplus\mathbb{Z}[i]/(6-i)\cong\mathbb{Z}[i]/(8+11i)$ since $\mathbb{Z}[i]/(1+2i)$and $\mathbb{Z}[i]/(6-i)$ aren't even submodules of the same set.","I am attempting to solve Ch 14 Problem 7.7 from Artin's algebra book. Let $R=\mathbb{Z}[i]$ and let $V$ be the R-module generated by elements $v_1$ and $v_2$ with relations $(1+i)v_1+(2-i)v_2=0$ and $3v_1+5iv_2=0$. Write this module as a direct sum of cyclic modules. Attempt I have obtained $V\cong R^2/ \begin{bmatrix} 1+i & 3 \\ 2-i & 5i \end{bmatrix} R^2 \cong R/[8+11i]R=\mathbb{Z}[i]/(8+11i)$. Now, I see that $(1+2i)(6-i)=8+11i.$ Now, I would like to show that $\mathbb{Z}[i]/(1+2i) \oplus\mathbb{Z}[i]/(6-i)\cong\mathbb{Z}[i]/(8+11i)$, so I can have $V$ as a direct sum of cyclic modules as needed, but how can I show this? I have already shown that $(1+2i,6-i)=(1)=\mathbb{Z}[i]$ and thus $(1+2i)+(6-i)=\mathbb{Z}[i]$. Intuition would suggest that $(1+2i)\oplus(6-i)=\mathbb{Z}[i]$, although I think this is false since $(i-6)(1+2i)+(1+2i)(6-i)=0$. I must confess that I am very new to module theory so please be patient with me. I don't even how it would be possible to have $\mathbb{Z}[i]/(1+2i) \oplus\mathbb{Z}[i]/(6-i)\cong\mathbb{Z}[i]/(8+11i)$ since $\mathbb{Z}[i]/(1+2i)$and $\mathbb{Z}[i]/(6-i)$ aren't even submodules of the same set.",,"['abstract-algebra', 'ring-theory', 'complex-numbers', 'modules', 'ideals']"
28,For what irreducible $f\in\mathbb{Q}[X]$ is this sequence periodic modulo $f$?,For what irreducible  is this sequence periodic modulo ?,f\in\mathbb{Q}[X] f,"This is just an interesting problem I found in an old notebook of mine: Given an irreducible $f\in\mathbb{Q}[X]$, is there a way to determine whether   the sequence $(p_n)_{n=0}^{\infty}\subset \mathbb{Q}[X]$ given by:   $$p_0=X$$ $$p_{n+1}=p_n^2-2$$ is periodic modulo $f$, without first having to determine the roots of $f$? I've only found a way which involves finding the exact roots and that's nearly impossible for $\deg f\ge 5$. The direct formula for $p_n$ might be useful: $$p_n=\left(\frac X2+\frac12\sqrt{X^2-4}\right)^{2^n}+\left(\frac{X}{2}-\frac12\sqrt{X^2-4}\right)^{2^n}$$ My method using the roots For anyone interested, here's my method, which relies on finding the exact roots of $f$. Given an irreducible polynomial $f\in\mathbb{Q}[X]$ with $f\neq X$ such that $(p_n)_{n=1}^{\infty}$ is periodic with period $d$, let $\alpha$ be a root of $f$ and define $(a_{n})_{n=1}^{\infty}$ by: $$a_n=p_n(\alpha)$$ We can also define $(a_{n})_{n=1}^{\infty}$ by: $$a_0=\alpha$$ $$a_{n+1}=a_n^2-2$$ and if we take $\beta$ with $\alpha=\beta+\beta^{-1}$, then it can easily be shown via induction that  $$a_n=\beta^{2^n}+\beta^{-2^n}$$ Suppose $|\beta|\neq 1$. If $|\beta|<1$, exchange $\beta$ and $\beta^{-1}$, so we can be sure that $|\beta|>1$ and $|\beta^{-1}|<1$. It follows that: $$|\alpha|=\lim_{k\to\infty} |a_{kd}|=\lim_{k\to\infty}|\beta^{2^{kd}}+\beta^{-2^{kd}}|=\infty$$ Which is a contradiction. Therefore, $\beta=e^{i\gamma}$ for some $\gamma\in\mathbb{R}$ and: $$a_n=e^{i\gamma n}+e^{-i\gamma n}=2\cos(\gamma n)$$ Which is only periodic if $\gamma$ is a rational multiple of $2\pi$. The only $f$ we have't checked is $f=X$, but it is easily seen that $p_n\equiv 2\pmod X$ for all $n$. So $(p_n)_{n=1}^{\infty}$ can only be periodic modulo $f$ when all the roots of $f$ are of the form: $$2\cos\left(\frac{2\pi p}{q}\right)$$ for some $p/q\in\mathbb{Q}$. On the other hand, if for some $p/q\in\mathbb{Q}$ we take $$\alpha:=2\cos\left(\frac{2\pi p}{q}\right)$$ Then we can define $(a_n)_{n=1}^{\infty}$ as before and show it's periodic, say with period $d$. For all $k,m$, we now have: $$p_k(\alpha)=p_{k+md}(\alpha)\implies (p_{k+md}-p_k)(\alpha)=0$$ and since for $m\neq 0$, we have $\deg p_k\neq \deg p_{k+md}$, it follows that $f^{\alpha}_{\mathbb{Q}}\mid p_{k+md}-p_k$. This implies that all such $\alpha$ are algebrac over $\mathbb{Q}$ and if a monic irreducible $f\in\mathbb{Q}[X]$ has just one root of the form $$2\cos\left(\frac{2\pi p}{q}\right)$$ then all of its roots are of this form (because it's a unity times $f^{\alpha}_{\mathbb{Q}}$, the sequence is periodic modulo $f^\alpha_{\mathbb{Q}}$ and can only be periodic if all roots are of this form.","This is just an interesting problem I found in an old notebook of mine: Given an irreducible $f\in\mathbb{Q}[X]$, is there a way to determine whether   the sequence $(p_n)_{n=0}^{\infty}\subset \mathbb{Q}[X]$ given by:   $$p_0=X$$ $$p_{n+1}=p_n^2-2$$ is periodic modulo $f$, without first having to determine the roots of $f$? I've only found a way which involves finding the exact roots and that's nearly impossible for $\deg f\ge 5$. The direct formula for $p_n$ might be useful: $$p_n=\left(\frac X2+\frac12\sqrt{X^2-4}\right)^{2^n}+\left(\frac{X}{2}-\frac12\sqrt{X^2-4}\right)^{2^n}$$ My method using the roots For anyone interested, here's my method, which relies on finding the exact roots of $f$. Given an irreducible polynomial $f\in\mathbb{Q}[X]$ with $f\neq X$ such that $(p_n)_{n=1}^{\infty}$ is periodic with period $d$, let $\alpha$ be a root of $f$ and define $(a_{n})_{n=1}^{\infty}$ by: $$a_n=p_n(\alpha)$$ We can also define $(a_{n})_{n=1}^{\infty}$ by: $$a_0=\alpha$$ $$a_{n+1}=a_n^2-2$$ and if we take $\beta$ with $\alpha=\beta+\beta^{-1}$, then it can easily be shown via induction that  $$a_n=\beta^{2^n}+\beta^{-2^n}$$ Suppose $|\beta|\neq 1$. If $|\beta|<1$, exchange $\beta$ and $\beta^{-1}$, so we can be sure that $|\beta|>1$ and $|\beta^{-1}|<1$. It follows that: $$|\alpha|=\lim_{k\to\infty} |a_{kd}|=\lim_{k\to\infty}|\beta^{2^{kd}}+\beta^{-2^{kd}}|=\infty$$ Which is a contradiction. Therefore, $\beta=e^{i\gamma}$ for some $\gamma\in\mathbb{R}$ and: $$a_n=e^{i\gamma n}+e^{-i\gamma n}=2\cos(\gamma n)$$ Which is only periodic if $\gamma$ is a rational multiple of $2\pi$. The only $f$ we have't checked is $f=X$, but it is easily seen that $p_n\equiv 2\pmod X$ for all $n$. So $(p_n)_{n=1}^{\infty}$ can only be periodic modulo $f$ when all the roots of $f$ are of the form: $$2\cos\left(\frac{2\pi p}{q}\right)$$ for some $p/q\in\mathbb{Q}$. On the other hand, if for some $p/q\in\mathbb{Q}$ we take $$\alpha:=2\cos\left(\frac{2\pi p}{q}\right)$$ Then we can define $(a_n)_{n=1}^{\infty}$ as before and show it's periodic, say with period $d$. For all $k,m$, we now have: $$p_k(\alpha)=p_{k+md}(\alpha)\implies (p_{k+md}-p_k)(\alpha)=0$$ and since for $m\neq 0$, we have $\deg p_k\neq \deg p_{k+md}$, it follows that $f^{\alpha}_{\mathbb{Q}}\mid p_{k+md}-p_k$. This implies that all such $\alpha$ are algebrac over $\mathbb{Q}$ and if a monic irreducible $f\in\mathbb{Q}[X]$ has just one root of the form $$2\cos\left(\frac{2\pi p}{q}\right)$$ then all of its roots are of this form (because it's a unity times $f^{\alpha}_{\mathbb{Q}}$, the sequence is periodic modulo $f^\alpha_{\mathbb{Q}}$ and can only be periodic if all roots are of this form.",,"['abstract-algebra', 'sequences-and-series', 'recurrence-relations', 'irreducible-polynomials']"
29,"$R/(a) \oplus R/(b) \cong R/\gcd(a,b) \oplus R/\operatorname{lcm}(a,b) $ [duplicate]",[duplicate],"R/(a) \oplus R/(b) \cong R/\gcd(a,b) \oplus R/\operatorname{lcm}(a,b) ","This question already has answers here : Proving that $\mathbb{Z}_m\oplus \mathbb{Z}_n \cong \mathbb{Z}_d\oplus \mathbb{Z}_l $ as groups, where $l=\mathrm{lcm}(m,n)$ and $d=\gcd(m,n)$ (2 answers) Closed 3 years ago . Let $R$ be a PID. How can one show that for all non zero $a,b \in R$ we have $R/(a) \oplus R/(b) \cong R/\gcd(a,b) \oplus R/\operatorname{lcm}(a,b) $ . I have no idea how to define such an isomorphism. What I tried is to define $f([x],[y])=([\gcd(x,y)], [\operatorname{lcm}(x,y)])$ . I didn't get anywhere with that my map is probably not even well defined I got lost in the calculations. So does anyone know how to find the desired isomorphism. Thanks in advance","This question already has answers here : Proving that $\mathbb{Z}_m\oplus \mathbb{Z}_n \cong \mathbb{Z}_d\oplus \mathbb{Z}_l $ as groups, where $l=\mathrm{lcm}(m,n)$ and $d=\gcd(m,n)$ (2 answers) Closed 3 years ago . Let be a PID. How can one show that for all non zero we have . I have no idea how to define such an isomorphism. What I tried is to define . I didn't get anywhere with that my map is probably not even well defined I got lost in the calculations. So does anyone know how to find the desired isomorphism. Thanks in advance","R a,b \in R R/(a) \oplus R/(b) \cong R/\gcd(a,b) \oplus R/\operatorname{lcm}(a,b)  f([x],[y])=([\gcd(x,y)], [\operatorname{lcm}(x,y)])","['abstract-algebra', 'principal-ideal-domains']"
30,Prove that a group $G$ of order 280 is not simple and has a subgroup of order 35,Prove that a group  of order 280 is not simple and has a subgroup of order 35,G,"Prove that a group $G$ of order $280=2^3 \cdot 5 \cdot 7$ is not simple and has a subgroup of order 35 Using Sylow's theorem's it was easy to prove that $G$ is not simple. I had a proof for the second statement, but I was unsure. The question "" Proving if $|G|=280$, then $G$ is not simple "" inspired me for a a different proof. Are both proofs correct? Proof 1 ""I'm pretty sure the following is correct"" Note $|\mathrm{Syl}_7(G)| \in \{1,8\}, |\mathrm{Syl}_5(G)| \in \{1,56\}$ and $|\mathrm{Syl}_2(G)| \in \{1,5,7,35\}$ If $|\mathrm{Syl}_7(G)| =1$ then the statement is easily proven. Choose a $P\in \mathrm{Syl}_7(G)$ which is also a normal subgroup and a $Q\in \mathrm{Syl}_5(G)$, then since $P\cap Q = 1$ the group $PQ\leq G$ and $|PQ|=|P|\cdot |Q| = 35$. If $|\mathrm{Syl}_7(G)| =8$ then there are $8$ Sylow 7-subgroups of $G$. Now consider the action of $G$ on $\mathrm{Syl}_7(G)$ by conjugation. Choose a $P\in \mathrm{Syl}_7(G)$ and consider the orbit-stabilizer formula $$ |G| = |G_P|\cdot |P^G| \Rightarrow 280 = |G_P| \cdot 8 \Rightarrow |G_P| = 35 $$ Now since $G_P = \{g\in G: P^g= P\} = N_G(P) \leq G$ the group $N_G(P)$ is a subgroup  of $G$ with the desired order. Proof 2 "" Less sure about this proof ... "" First notice that if $|\mathrm{Syl}_7(G)|=1$ or $|\mathrm{Syl}_5(G)| =1$ then choosing a $P$ in one and a $Q$ in the other Sylow $p$-subgroups once again creates a $PQ\leq G$ with order $35$. Let nog $|\mathrm{Syl}_7(G)| \not =1, |\mathrm{Syl}_5(G)| \not = 1$, then because the group $G$ is not simple $|\mathrm{Syl}_2(G)|=1$. Let $P\in \mathrm{Syl}_2(G)$ then $P\trianglelefteq G$ with order 8. Now consider the quotient group $G/P$ which has order 35. This group has through Sylow's theorems exactly one Sylow 5-subgroup, $A$ and one Sylow 7-subgroup $B$. Notice how $A\trianglelefteq G/P$ and $|A|=5$ implies that $A$ is a cylic group with a generator $\langle Pa\rangle$ for a certain $a \in G$. Then $o(Pa) = 5$ which implies $a^5 \in P$. Because it is possible to choose 8 different $\tilde a\in G$ such that $Pa = P\tilde a$, choose now the $\tilde a$ such that $\tilde a^5=1$. Repeat for $B= \langle P\tilde b\rangle$ such that $\tilde b^7 = 1$. ($\color{red}{\text{? unsure if this is right}}$) Now since $\langle \tilde a \rangle \times \langle \tilde b\rangle \cong \langle \tilde a\rangle \cdot \langle \tilde b\rangle$ it follows that $\langle \tilde a \rangle \cdot \langle \tilde b\rangle$ is a subgroup of $G$ with order 35. Third proof (?) Writing the last proof out, made me think of one shorter version of the last statement. Since $5\mid |G|$ and $7\mid |G|$ then by Cauchy's theorem there is a $a, b\in G$ such that $o(a)=5, o(b)=7$. Now consider $\langle a\rangle \cdot \langle b\rangle$ which has trivial intersection and is a subgroup of $G$. (through isomorphism with a direct product)","Prove that a group $G$ of order $280=2^3 \cdot 5 \cdot 7$ is not simple and has a subgroup of order 35 Using Sylow's theorem's it was easy to prove that $G$ is not simple. I had a proof for the second statement, but I was unsure. The question "" Proving if $|G|=280$, then $G$ is not simple "" inspired me for a a different proof. Are both proofs correct? Proof 1 ""I'm pretty sure the following is correct"" Note $|\mathrm{Syl}_7(G)| \in \{1,8\}, |\mathrm{Syl}_5(G)| \in \{1,56\}$ and $|\mathrm{Syl}_2(G)| \in \{1,5,7,35\}$ If $|\mathrm{Syl}_7(G)| =1$ then the statement is easily proven. Choose a $P\in \mathrm{Syl}_7(G)$ which is also a normal subgroup and a $Q\in \mathrm{Syl}_5(G)$, then since $P\cap Q = 1$ the group $PQ\leq G$ and $|PQ|=|P|\cdot |Q| = 35$. If $|\mathrm{Syl}_7(G)| =8$ then there are $8$ Sylow 7-subgroups of $G$. Now consider the action of $G$ on $\mathrm{Syl}_7(G)$ by conjugation. Choose a $P\in \mathrm{Syl}_7(G)$ and consider the orbit-stabilizer formula $$ |G| = |G_P|\cdot |P^G| \Rightarrow 280 = |G_P| \cdot 8 \Rightarrow |G_P| = 35 $$ Now since $G_P = \{g\in G: P^g= P\} = N_G(P) \leq G$ the group $N_G(P)$ is a subgroup  of $G$ with the desired order. Proof 2 "" Less sure about this proof ... "" First notice that if $|\mathrm{Syl}_7(G)|=1$ or $|\mathrm{Syl}_5(G)| =1$ then choosing a $P$ in one and a $Q$ in the other Sylow $p$-subgroups once again creates a $PQ\leq G$ with order $35$. Let nog $|\mathrm{Syl}_7(G)| \not =1, |\mathrm{Syl}_5(G)| \not = 1$, then because the group $G$ is not simple $|\mathrm{Syl}_2(G)|=1$. Let $P\in \mathrm{Syl}_2(G)$ then $P\trianglelefteq G$ with order 8. Now consider the quotient group $G/P$ which has order 35. This group has through Sylow's theorems exactly one Sylow 5-subgroup, $A$ and one Sylow 7-subgroup $B$. Notice how $A\trianglelefteq G/P$ and $|A|=5$ implies that $A$ is a cylic group with a generator $\langle Pa\rangle$ for a certain $a \in G$. Then $o(Pa) = 5$ which implies $a^5 \in P$. Because it is possible to choose 8 different $\tilde a\in G$ such that $Pa = P\tilde a$, choose now the $\tilde a$ such that $\tilde a^5=1$. Repeat for $B= \langle P\tilde b\rangle$ such that $\tilde b^7 = 1$. ($\color{red}{\text{? unsure if this is right}}$) Now since $\langle \tilde a \rangle \times \langle \tilde b\rangle \cong \langle \tilde a\rangle \cdot \langle \tilde b\rangle$ it follows that $\langle \tilde a \rangle \cdot \langle \tilde b\rangle$ is a subgroup of $G$ with order 35. Third proof (?) Writing the last proof out, made me think of one shorter version of the last statement. Since $5\mid |G|$ and $7\mid |G|$ then by Cauchy's theorem there is a $a, b\in G$ such that $o(a)=5, o(b)=7$. Now consider $\langle a\rangle \cdot \langle b\rangle$ which has trivial intersection and is a subgroup of $G$. (through isomorphism with a direct product)",,"['abstract-algebra', 'proof-verification', 'sylow-theory']"
31,Kronecker quiver and tensor product,Kronecker quiver and tensor product,,"Good day, based on representation theory of Assem, and the definition of tensor product I need to find $\varphi^1_{21}$ and its domain in the kronecker quiver. I did the next: but Im confused to find $F_0$ and therefore $F/F_0$ to deduce the domain $\varepsilon _2KQ\varepsilon _1\otimes  \varepsilon _1KQ\varepsilon _1$. Depends it of the field $K$ and of the external operation $ka$, $k\in K, a\in \varepsilon _2KQ\varepsilon _1$?","Good day, based on representation theory of Assem, and the definition of tensor product I need to find $\varphi^1_{21}$ and its domain in the kronecker quiver. I did the next: but Im confused to find $F_0$ and therefore $F/F_0$ to deduce the domain $\varepsilon _2KQ\varepsilon _1\otimes  \varepsilon _1KQ\varepsilon _1$. Depends it of the field $K$ and of the external operation $ka$, $k\in K, a\in \varepsilon _2KQ\varepsilon _1$?",,"['abstract-algebra', 'representation-theory', 'tensor-products', 'tensors', 'quiver']"
32,When an ideal is generated by idempotents,When an ideal is generated by idempotents,,"Let $f:R\rightarrow S$ be a ring homomorphism of commutative rings with identities such that $f(1_R)=1_S$. And let $J$ be an ideal of $S$ such that for every prime ideal $P$ of $R$ and every $n\in \mathbb{N}$, $J\subseteq {\langle f(P)+J \rangle}^{n}$, where $\langle f(P)+J \rangle$ is the ideal generated by $f(P)+J$ in the ring $f(R)+J$, as a subring of $S$. How can we show that $J$ is generated by idempotents, as an ideal of $f (R)+J $ or $ S $?","Let $f:R\rightarrow S$ be a ring homomorphism of commutative rings with identities such that $f(1_R)=1_S$. And let $J$ be an ideal of $S$ such that for every prime ideal $P$ of $R$ and every $n\in \mathbb{N}$, $J\subseteq {\langle f(P)+J \rangle}^{n}$, where $\langle f(P)+J \rangle$ is the ideal generated by $f(P)+J$ in the ring $f(R)+J$, as a subring of $S$. How can we show that $J$ is generated by idempotents, as an ideal of $f (R)+J $ or $ S $?",,"['abstract-algebra', 'ideals', 'idempotents']"
33,The canonical map from the group algebra to the set of endomorphism of a vector space is surjective,The canonical map from the group algebra to the set of endomorphism of a vector space is surjective,,"Let $G$ be a finite group. Suppose $\pi:G \rightarrow GL(V)$ be an irreducible representation of $G$. This representation gives a canonical map $$\tilde{\pi}: \mathbb{C}[G] \rightarrow End(V)$$ where End(V) denotes the set of linear maps on $V$. Prove that $\tilde{\pi}$ is surjective. I have no clue about the solution. There is a hint given that if we consider on the contrary that $\tilde{\pi}$ is not surjective we will get a linear functional on $End(V)$ which is zero on the image of $\tilde{\pi}$, which will contradict some kind of orthogonality relation. I have no idea where this hint leads to. I also don't have any other idea to solve. A little help will be appreciated. Thanks in advance!!!!","Let $G$ be a finite group. Suppose $\pi:G \rightarrow GL(V)$ be an irreducible representation of $G$. This representation gives a canonical map $$\tilde{\pi}: \mathbb{C}[G] \rightarrow End(V)$$ where End(V) denotes the set of linear maps on $V$. Prove that $\tilde{\pi}$ is surjective. I have no clue about the solution. There is a hint given that if we consider on the contrary that $\tilde{\pi}$ is not surjective we will get a linear functional on $End(V)$ which is zero on the image of $\tilde{\pi}$, which will contradict some kind of orthogonality relation. I have no idea where this hint leads to. I also don't have any other idea to solve. A little help will be appreciated. Thanks in advance!!!!",,"['abstract-algebra', 'finite-groups', 'representation-theory']"
34,$x^{p-1}+x^{p-2}+\cdots+x+1$ is irreducible over $\mathbb{F}_2$ if and only if $2$ generates $\mathbb{F}_p^{*}$,is irreducible over  if and only if  generates,x^{p-1}+x^{p-2}+\cdots+x+1 \mathbb{F}_2 2 \mathbb{F}_p^{*},"I need to show the equivalence: $x^{p-1}+x^{p-2}+\cdots+x+1$ is irreducible over $\mathbb{F}_2$ if and only if $2$ generates $\mathbb{F}_p^{*}$. Maybe I should clarify the meaning of ""generates"": $\mathbb{F}_p^{*}$ is a cyclic group (as the mulplicitive group of a finite field) composed of the elements $1, 2, ...., p-1$, and $2$ generates $\mathbb{F}_p^{*}$ means that all elements are its powers. I tried what seems to be, intuitively the easy direction. Here's my attempt: Suppose $1+x+...+x^{p-1}$ is irreducible. Let $\alpha\in \overline{\mathbb{F}}_2$ be a root of the polynomial. Then $[\mathbb{F}_2[\alpha]: \mathbb{F}_2]=p-1$ thus $\mathbb{F}_2[\alpha]\cong \mathbb{F}_{2^{p-1}}$. Now I'm stuck. I think it might have something to do with the multiplcitive group of this field, since it's order is $2^{p-1}-1$ who's divisable be $p$, but maybe I'm wrong. Any ideas?","I need to show the equivalence: $x^{p-1}+x^{p-2}+\cdots+x+1$ is irreducible over $\mathbb{F}_2$ if and only if $2$ generates $\mathbb{F}_p^{*}$. Maybe I should clarify the meaning of ""generates"": $\mathbb{F}_p^{*}$ is a cyclic group (as the mulplicitive group of a finite field) composed of the elements $1, 2, ...., p-1$, and $2$ generates $\mathbb{F}_p^{*}$ means that all elements are its powers. I tried what seems to be, intuitively the easy direction. Here's my attempt: Suppose $1+x+...+x^{p-1}$ is irreducible. Let $\alpha\in \overline{\mathbb{F}}_2$ be a root of the polynomial. Then $[\mathbb{F}_2[\alpha]: \mathbb{F}_2]=p-1$ thus $\mathbb{F}_2[\alpha]\cong \mathbb{F}_{2^{p-1}}$. Now I'm stuck. I think it might have something to do with the multiplcitive group of this field, since it's order is $2^{p-1}-1$ who's divisable be $p$, but maybe I'm wrong. Any ideas?",,"['abstract-algebra', 'finite-fields', 'irreducible-polynomials']"
35,Ring homomorphism: Prove the image is a subring,Ring homomorphism: Prove the image is a subring,,"I was given the following question (in my undergraduate Abstract Algebra module): Let $f:R\to S$ be a ring homomorphism. Prove that: the image of $f$ is a subring of $S$ if $R$ is a ring with unity and $f$ is surjective. The following is my attempt: The image of $f=\{s\in S\mid s=f(r)$  for some $r\in R\}$. Let $x,y\in R$ and  $f(x), f(y)\in f(R)$ $$f(x)-f(y)=f(x-y)$$  $x-y\in R$ (since $R$ is a group). Thus the image of $f$ is closed under subtraction. $$f(x)*f(y)=f(xy)        $$ $xy\in R$ (since $R$ is a group). Thus the image of $f$ is closed under multiplication. Therefore the image of $f$ is a subring of $S$. Is this even correct? I never used the fact that $R$ is a ring with unity and that $f$ is surjective so it is confusing me? Thank you.","I was given the following question (in my undergraduate Abstract Algebra module): Let $f:R\to S$ be a ring homomorphism. Prove that: the image of $f$ is a subring of $S$ if $R$ is a ring with unity and $f$ is surjective. The following is my attempt: The image of $f=\{s\in S\mid s=f(r)$  for some $r\in R\}$. Let $x,y\in R$ and  $f(x), f(y)\in f(R)$ $$f(x)-f(y)=f(x-y)$$  $x-y\in R$ (since $R$ is a group). Thus the image of $f$ is closed under subtraction. $$f(x)*f(y)=f(xy)        $$ $xy\in R$ (since $R$ is a group). Thus the image of $f$ is closed under multiplication. Therefore the image of $f$ is a subring of $S$. Is this even correct? I never used the fact that $R$ is a ring with unity and that $f$ is surjective so it is confusing me? Thank you.",,"['abstract-algebra', 'ring-theory']"
36,Quotient of solvable groups is solvable - what's wrong with this proof?,Quotient of solvable groups is solvable - what's wrong with this proof?,,"Prove: $G$ is a solvable group and $H\trianglelefteq G$. Then $G/H$ is solvable. Definition: A group $G$ is said to be solvable if there is a normal series of $G$ such that the factors are abelian, i.e. $G=G_0\trianglerighteq G_1\trianglerighteq \ldots \trianglerighteq G_n=\{1\},$ where $G_{i}/G_{i+1}$ are abelians. What's wrong with the following proof? I searched on MSE and it seems that in order to quotient out $H$ many (such as here ) consider the tower $G_iH$, but why can't we just take the image of canonical map as below? Let $\phi: G \rightarrow G/H$ be the canonical map, then $\phi(G_i)$ forms a normal tower: $\phi(G_i)$ are groups as they are images of homomorphic maps, and given $\phi(a) \in \phi(G_i)$,  $$ \phi(a)\phi(G_{i+1})\phi(a)^{-1} = \phi(aG_{i+1}a^{-1}) \subseteq \phi(G_{i+1}).$$ using normality of $G_{i+1}$ in $G_i$. $\phi(G_i)/ \phi(G_{i+1})$ is abelian: We have $$ \phi(a)\phi(G_{i+1}) \phi(b) \phi(G_{i+1}) = \phi(ab) \phi(G_{i+1})$$ since $G_i/G_{i+1}$ is abelian, $abG_{i+1} = baG_{i+1}$ so, $ab= ba g'$, for some $g' \in G_{i+1}$. Hence,  $$ \phi(ab) G_{i+1} = \phi(ba)\phi(g')\phi(G_{i+1})= \phi(ba) \phi(G_{i+1}). $$ so the group is abelian. Thus, $G/H= \phi(G) \trianglerighteq \ldots \trianglerighteq \phi(1) = H$ is an abelian tower.","Prove: $G$ is a solvable group and $H\trianglelefteq G$. Then $G/H$ is solvable. Definition: A group $G$ is said to be solvable if there is a normal series of $G$ such that the factors are abelian, i.e. $G=G_0\trianglerighteq G_1\trianglerighteq \ldots \trianglerighteq G_n=\{1\},$ where $G_{i}/G_{i+1}$ are abelians. What's wrong with the following proof? I searched on MSE and it seems that in order to quotient out $H$ many (such as here ) consider the tower $G_iH$, but why can't we just take the image of canonical map as below? Let $\phi: G \rightarrow G/H$ be the canonical map, then $\phi(G_i)$ forms a normal tower: $\phi(G_i)$ are groups as they are images of homomorphic maps, and given $\phi(a) \in \phi(G_i)$,  $$ \phi(a)\phi(G_{i+1})\phi(a)^{-1} = \phi(aG_{i+1}a^{-1}) \subseteq \phi(G_{i+1}).$$ using normality of $G_{i+1}$ in $G_i$. $\phi(G_i)/ \phi(G_{i+1})$ is abelian: We have $$ \phi(a)\phi(G_{i+1}) \phi(b) \phi(G_{i+1}) = \phi(ab) \phi(G_{i+1})$$ since $G_i/G_{i+1}$ is abelian, $abG_{i+1} = baG_{i+1}$ so, $ab= ba g'$, for some $g' \in G_{i+1}$. Hence,  $$ \phi(ab) G_{i+1} = \phi(ba)\phi(g')\phi(G_{i+1})= \phi(ba) \phi(G_{i+1}). $$ so the group is abelian. Thus, $G/H= \phi(G) \trianglerighteq \ldots \trianglerighteq \phi(1) = H$ is an abelian tower.",,"['abstract-algebra', 'group-theory', 'proof-verification', 'normal-subgroups', 'solvable-groups']"
37,Simple way to prove that $\mathbb{Z}[\sqrt[3]{2}]=\mathcal{O}_{\mathbb{Q}(\sqrt[3]{2})}$ [duplicate],Simple way to prove that  [duplicate],\mathbb{Z}[\sqrt[3]{2}]=\mathcal{O}_{\mathbb{Q}(\sqrt[3]{2})},"This question already has answers here : Easy way to show that $\mathbb{Z}[\sqrt[3]{2}]$ is the ring of integers of $\mathbb{Q}[\sqrt[3]{2}]$ (8 answers) Closed 7 years ago . Leting $\delta:=\sqrt[3]{2}$, prove that $\mathbb{Z}[\delta]$ is the ring of integers of $\mathbb{Q}(\delta)$. Here's what I've done: let $K:=\mathbb{Q}(\delta)$. Since $[K:\mathbb{Q}]=3$, then $1, \delta, \delta^2$ are $\mathbb{Q}$-linearly independent (in particular, they are $\mathbb{Z}$-independent). Since $1, \delta, \delta^2$ are integers of $K$, we have that $\mathbb{Z}[\delta]=<1, \delta, \delta^2>_{\mathbb{Z}}\subset\mathcal{O}_{K}$. To prove $\supset$, I did the following: if $z=a+b\delta+c\delta^2$ is an integer of $K$, its minimal polynomial $p(x)=x^3+c_2x^2+c_1x+c_0$ lies in $\mathbb{Z}[x]$ and has roots $\sigma_1(z),\sigma_2(z)$ and $\sigma_3(z)$, where \begin{align*}  \sigma_1 &:\delta\mapsto\delta\\ \sigma_2 &:\delta\mapsto\omega\delta\\ \sigma_3 &:\delta\mapsto\omega^2\delta \end{align*} are the embeddings fixing $\mathbb{Q}$ and $\omega^3=1$. Using Vite's relations we get: \begin{align*}   c_2&=-\sum_{i}\sigma_i(z)= -3a\\          c_1&= \sum_{i<j}\sigma_i(z)\sigma_j(z)=3a^2-6bc\\  c_0&= -\prod_{i}\sigma_i(z)=-(a^3+2b^3+4c^3-6abc) \end{align*} which gives us restrictions for $a, b, c$, since $c_0, c_1, c_2\in\mathbb{Z}$. Since $\delta z$ and $\delta^2 z$ are also integers of $K$, we calculate its respective minimal polynomials and find new restrictions for $a, b, c$. After a very tiresome case analysis, I could prove that $a, b, c\in\mathbb{Z}$, concluding the proof. This solution was given as a hint by the professor, and seems to me not very natural and, above all, way too long. My question is: is there a more natural and/or shorter solution for this? Thanks!","This question already has answers here : Easy way to show that $\mathbb{Z}[\sqrt[3]{2}]$ is the ring of integers of $\mathbb{Q}[\sqrt[3]{2}]$ (8 answers) Closed 7 years ago . Leting $\delta:=\sqrt[3]{2}$, prove that $\mathbb{Z}[\delta]$ is the ring of integers of $\mathbb{Q}(\delta)$. Here's what I've done: let $K:=\mathbb{Q}(\delta)$. Since $[K:\mathbb{Q}]=3$, then $1, \delta, \delta^2$ are $\mathbb{Q}$-linearly independent (in particular, they are $\mathbb{Z}$-independent). Since $1, \delta, \delta^2$ are integers of $K$, we have that $\mathbb{Z}[\delta]=<1, \delta, \delta^2>_{\mathbb{Z}}\subset\mathcal{O}_{K}$. To prove $\supset$, I did the following: if $z=a+b\delta+c\delta^2$ is an integer of $K$, its minimal polynomial $p(x)=x^3+c_2x^2+c_1x+c_0$ lies in $\mathbb{Z}[x]$ and has roots $\sigma_1(z),\sigma_2(z)$ and $\sigma_3(z)$, where \begin{align*}  \sigma_1 &:\delta\mapsto\delta\\ \sigma_2 &:\delta\mapsto\omega\delta\\ \sigma_3 &:\delta\mapsto\omega^2\delta \end{align*} are the embeddings fixing $\mathbb{Q}$ and $\omega^3=1$. Using Vite's relations we get: \begin{align*}   c_2&=-\sum_{i}\sigma_i(z)= -3a\\          c_1&= \sum_{i<j}\sigma_i(z)\sigma_j(z)=3a^2-6bc\\  c_0&= -\prod_{i}\sigma_i(z)=-(a^3+2b^3+4c^3-6abc) \end{align*} which gives us restrictions for $a, b, c$, since $c_0, c_1, c_2\in\mathbb{Z}$. Since $\delta z$ and $\delta^2 z$ are also integers of $K$, we calculate its respective minimal polynomials and find new restrictions for $a, b, c$. After a very tiresome case analysis, I could prove that $a, b, c\in\mathbb{Z}$, concluding the proof. This solution was given as a hint by the professor, and seems to me not very natural and, above all, way too long. My question is: is there a more natural and/or shorter solution for this? Thanks!",,"['abstract-algebra', 'number-theory', 'field-theory', 'algebraic-number-theory']"
38,Algebra problem - traces and norms,Algebra problem - traces and norms,,"This question: Assume $F$ has $p$ distinct $p$th roots of $1$, $p$ a prime, and $E|F$ is cyclic of dimension $p^f$. Let $z$ be a primitie $p$th root of $1$. Show that if $E|F$ can be imbedded in a cyclic field $K|F$ of dimension $p^{f+1}$, then $z = N_{E|F}(u)$ for some u $\in E$. is in the book Basic Algebra, Jacobson. $N_{E|F}(u)$ is the norm of u (If $E|F$ is Galois then the norm of $u$ is $\prod_{\phi \in Gal(E|F)} \phi_i (u) $). Can anyone give a hint on how to solve it? For example, what would be a good way to show that an element of $E$ is norm of some other element?","This question: Assume $F$ has $p$ distinct $p$th roots of $1$, $p$ a prime, and $E|F$ is cyclic of dimension $p^f$. Let $z$ be a primitie $p$th root of $1$. Show that if $E|F$ can be imbedded in a cyclic field $K|F$ of dimension $p^{f+1}$, then $z = N_{E|F}(u)$ for some u $\in E$. is in the book Basic Algebra, Jacobson. $N_{E|F}(u)$ is the norm of u (If $E|F$ is Galois then the norm of $u$ is $\prod_{\phi \in Gal(E|F)} \phi_i (u) $). Can anyone give a hint on how to solve it? For example, what would be a good way to show that an element of $E$ is norm of some other element?",,"['abstract-algebra', 'field-theory', 'galois-theory']"
39,How is a ring a $\mathbb{Z}$-algebra?,How is a ring a -algebra?,\mathbb{Z},"If all of the below is true, does it follow directly from the definitions and the canonical way every abelian group can be considered a $\mathbb{Z}$ -module? EDIT: In the ""definitions"" below, it is necessary to include left and right distributivity; the two distributive axioms do not follow from the other structures. (For commutative rings technically one of the two will always follow from the other so it is only necessary to assume one -- for non-commutative rings one needs to assume both.) Question: If we define: ring : abelian group under $+$ , semigroup under $\times$ , ring with identity : abelian group under $+$ , monoid under $\times$ , commutative ring : abelian group under $+$ , commutative semigroup under $\times$ , commutative ring with identity : abelian group under $+$ , commutative monoid under $\times$ , then are the following equivalences true? (Yes/no will suffice for an answer.) $R$ ring $\iff$ $R$ associative $\mathbb{Z}$ -algebra $R$ ring with identity $\iff$ $R$ unital, associative $\mathbb{Z}$ -algebra $R$ commutative ring $\iff$ $R$ commutative, associative $\mathbb{Z}$ -algebra $R$ commutative ring with identity $\iff$ $R$ unital, commutative, associative $\mathbb{Z}$ -algebra In particular, no ring is a non-associative $\mathbb{Z}$ -algebra?","If all of the below is true, does it follow directly from the definitions and the canonical way every abelian group can be considered a -module? EDIT: In the ""definitions"" below, it is necessary to include left and right distributivity; the two distributive axioms do not follow from the other structures. (For commutative rings technically one of the two will always follow from the other so it is only necessary to assume one -- for non-commutative rings one needs to assume both.) Question: If we define: ring : abelian group under , semigroup under , ring with identity : abelian group under , monoid under , commutative ring : abelian group under , commutative semigroup under , commutative ring with identity : abelian group under , commutative monoid under , then are the following equivalences true? (Yes/no will suffice for an answer.) ring associative -algebra ring with identity unital, associative -algebra commutative ring commutative, associative -algebra commutative ring with identity unital, commutative, associative -algebra In particular, no ring is a non-associative -algebra?",\mathbb{Z} + \times + \times + \times + \times R \iff R \mathbb{Z} R \iff R \mathbb{Z} R \iff R \mathbb{Z} R \iff R \mathbb{Z} \mathbb{Z},"['abstract-algebra', 'terminology', 'definition']"
40,Question about embeddings in algebraically closed fields,Question about embeddings in algebraically closed fields,,"I was looking at the two following well known propositions: $1$) Let $E|F$ be a finite separable extension of degree n, and let $\sigma$ be an embedding of $F$ in $C$, where $C$ is an algebraic closure of $E$. Then $\sigma$ extends to exactly $n$ embeddings of $E$ in $C$; $2$) The extension $E|F$ is normal if and only if every $F$-monomorphism of $E$ into an algebraic closure $C$ is actually an $F$-automorphism of $E$. Observing the proofs, it seems to me that actually instead of $C$ we can pick any algebraically closed field $L$ containing $F$ (we don't need to assume that it contains also $E$ in these propositions, right?)  $\textbf{in both propositions}$. Is it correct? (I'm not so sure for prop 2)). What I'm thinking of, is the typical situation in number theory where you have $\mathbb C$ instead of $C$. In general $\mathbb C$ is not the algebraic closure of $E$, but just an algebraically closed field. So why in many texts the authors put algebraic closure instead of simply algebraically closed field?","I was looking at the two following well known propositions: $1$) Let $E|F$ be a finite separable extension of degree n, and let $\sigma$ be an embedding of $F$ in $C$, where $C$ is an algebraic closure of $E$. Then $\sigma$ extends to exactly $n$ embeddings of $E$ in $C$; $2$) The extension $E|F$ is normal if and only if every $F$-monomorphism of $E$ into an algebraic closure $C$ is actually an $F$-automorphism of $E$. Observing the proofs, it seems to me that actually instead of $C$ we can pick any algebraically closed field $L$ containing $F$ (we don't need to assume that it contains also $E$ in these propositions, right?)  $\textbf{in both propositions}$. Is it correct? (I'm not so sure for prop 2)). What I'm thinking of, is the typical situation in number theory where you have $\mathbb C$ instead of $C$. In general $\mathbb C$ is not the algebraic closure of $E$, but just an algebraically closed field. So why in many texts the authors put algebraic closure instead of simply algebraically closed field?",,"['abstract-algebra', 'number-theory', 'field-theory', 'algebraic-number-theory', 'extension-field']"
41,Define $A^{-1}$ (in some cases) even if $A$ is not an invertible matrix,Define  (in some cases) even if  is not an invertible matrix,A^{-1} A,"$\def\r{\Bbb R}$  $\def\q{\Bbb Q}$ As the title suggest, I am trying to do something that I know cannot be done, so my question is confused, and I am trying to make sense of it. Generally: (1) How does one make sense of what I describe below, and (2) are there known results and known terminology applicable, related to my comments? (I am tempted to think of some generalizations of rings, monoids, but I can't make sense of it without using a unit.) So, I was reading about irreducible matrices (and relations to strongly connected graphs, online), after starting with the book Dynamical Systems and Ergodic Theory by Pollicott and Yuri. As an example of an irreducible matrix they give  $A=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}$. Since the first two rows coincide, clearly $\det(A)=0$ and $A$ is not invertible. Nevertheless one may look at powers $A^n$ of $A$, as well as at $A^n-A^{n-1}$.  Certainly this is possible for $n\ge2$, and my computer (using computer algebra Reduce) happily evaluates the case $n=1$ too, as $A^1-A^{1-1}=\begin{pmatrix} -1 & 1 & 1 \\ 0 & 0 & 1 \\ 1 & 0 & -1 \end{pmatrix}$ (obviously using $A^{1-1}=I=\begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$), but the case $n=0$,  that is $A^0-A^{-1}$ generates an error message ``Singular matrix'' (of course, as $A^{-1}$ does not exist). But, it turns out $A^{n+1}-A^n= A^{n-1}$ for $n\ge2$. For example, $n=2$, then $A^3=\begin{pmatrix} 1 & 2 & 2 \\ 1 & 2 & 2 \\ 1 & 1 & 1 \end{pmatrix}$, and $A^3-A^2=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}= A^1$. $n=3$, then $A^4=\begin{pmatrix} 2 & 3 & 3 \\ 2 & 3 & 3 \\ 1 & 2 & 2 \end{pmatrix}$, and $A^4-A^3=\begin{pmatrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 0 & 1 & 1 \end{pmatrix}= A^2$. $n=4$, then $A^5=\begin{pmatrix} 3 & 5 & 5 \\ 3 & 5 & 5 \\ 2 & 3 & 3 \end{pmatrix}$, and $A^5-A^4=\begin{pmatrix} 1 & 2 & 2 \\ 1 & 2 & 2 \\ 1 & 1 & 1 \end{pmatrix}= A^3$. $n=5$, then $A^6=\begin{pmatrix} 5 & 8 & 8 \\ 5 & 8 & 8 \\ 3 & 5 & 5 \end{pmatrix}$, and $A^6-A^5=\begin{pmatrix} 2 & 3 & 3 \\ 2 & 3 & 3 \\ 1 & 2 & 2 \end{pmatrix}= A^4$. (As seen the Fibonacci numbers are involved too.) From the above, one if tempted to (recursively) define $A^{n-1}=A^{n+1}-A^n$ for all $n\le1$. For example, $A^0=A^2-A^1 = \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix} \not= I$. Even though $A^0$, defined this way, is different from $I$, it acts like $I$ when multiplied to $A^n$, $n\ge1$. For example, $A^0\cdot A=A\cdot A^0=A$, $A^0\cdot A^7=A^7\cdot A^0=A^7$, etc. Also, $(A^0)^2=A^0$, and $(A^0)^n=A^0$ for $n\ge1$. Similarly, one may define $A^{-1}=A^1-A^0 = \begin{pmatrix} -1 & 1 & 1 \\ -1 & 1 & 1 \\ 2 & -1 & -1 \end{pmatrix}$. (And, one may define $A^{-n}$ for all $n\ge1$.) Even though $A$ is not invertible, the $A^{-1}$ as defined above behaves like an inverse of $A$, namely $A^{-1}\cdot A=A\cdot A^{-1}=A^0 =  \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$. So, my (confused) question (in addition to (1) and (2) at the beginning) is:  (3) What am I observing (assuming it has already observed and is well-known)? Edit. I think I understand better what I was asking (or what had confused me) and will post my comments here. This is essentially an answer, but I will leave the option open for someone else to post their answer, as they find appropriate, as the question was a bit open ended, and may get different types of answers.  (Also, after typing this edit, I feel there are more details to be verified.) QiaochuYuan left a comment which I initially did not understand, but now I think he meant something along what is illustrated by the following example. Let $F=\{\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}: x\in\r\}$. Then $F$ is a field isomorphic to $\r$, with additive identity $O=\begin{pmatrix} 0 & 0  \\ 0 & 0 \end{pmatrix}$ and multiplicative identity $U=\begin{pmatrix} 1 & 0  \\ 0 & 0 \end{pmatrix}$, and if $X=\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}\not=O$ then $X^{-1}=\begin{pmatrix} x^{-1} & 0  \\ 0 & 0 \end{pmatrix}$. The latter does not contradict the fact that $\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}$, as a matrix, is not invertible. If $Id=\begin{pmatrix} 1 & 0  \\ 0 & 1 \end{pmatrix}$ is the identity matrix, this looks like a contradiction, having two different multiplicative identities, namely $U$ and $Id$, but there is no contradiction as simply $Id$ does not belong to $F$. It didn't seem that QiaochuYuan addressed the identity $A^{n+1}-A^n= A^{n-1}$ for $n\ge2$ (and the latter seemed special to me). Let $E= \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$ (which I had denoted by $A^0$ above, but I prefer $E$ now). $E$ is the multiplicative identity of the structure described in my question, and I was puzzled as it looked like there were two different multiplicative identities, namely $E$, and $I= \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$. It seemed to me that if we use the usual matrix multiplication, then there was only one choice for the multiplicative identity, namely $I$. The matrix $E$ isn't even a diagonal matrix, and it looked strange it would be a multiplicative identity  (and I must have forgotten that matrices have normal forms). Well, I verified the details later, and $E$ is indeed the multiplicative identity, while $I$ simply does not belong to this structure. Call the structure hinted at in my question $K$. So $K$ contains  $A=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}$ as well as  all $A^n$, $n\ge1$ (usual matrix multiplication). We have that $A^{n-1}=A^{n+1}-A^n$ for all $n\ge2$, and this suggest that $E=A^2-A= \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$ would play the role of the multiplicative identity. Once this is done, we could define the inverse of $A$, as $A-E$ (where $E$ plays the role of $A^0$). I had used the notation $A^{-1}$ in my question, but I confuse myself with that as I think in this context it should be reserved for matrix inverse (which for $A$ does not exist). So, if $n\ge1$, I will denote the multiplicative inverse of $A^n$ (in $K$) by $A^{[-n]}$. In particular, $A^{[-1]}=A-E=\begin{pmatrix} -1 & 1 & 1 \\ -1 & 1 & 1 \\ 2 & -1 & -1 \end{pmatrix}$, then $A^{[-2]}=E-A^{[-1]}=\begin{pmatrix} 2 & -1 & -1 \\ 2 & -1 & -1 \\ -3 & 2 & 2 \end{pmatrix}$, next $A^{[-3]}=A^{[-1]}-A^{[-2]}$, etc. (using the identity $A^{n-1}=A^{n+1}-A^n$ as a model). Let $S=\{A^{[-n]}:n\ge1\}\cup\{E\}\cup\{A^n:n\ge1\}$. Then $S$ is a commutative ring under usual matrix multiplication, with identity element $E$. Since of course we could add and subtract the elements of $S$ (as matrices), I was confused that $S$ is a field, and I knew that couldn't be, as the multiplicative group should contain a copy of the rationals $\q$, whereas $S$ seems isomorphic as a group to $(\Bbb Z,+)$. (But it was getting late.) I had simply forgotten that $S$ is not closed under addition (and subtraction).  So $S$ is not a field, but it generates a field. Let $K$ be the field that is generated by $S$. I will present a couple of more specific descriptions of $K$ below. First, every element of $S$ is of the form $\begin{pmatrix} q & r & r \\ q & r & r \\ p & q & q \end{pmatrix}$, with $p+q=r$ (so obviously such an element is completely determined by $p$ and $q$). Every element of $K$ is of this form too, where $p,q,r\in\q$ and $p+q=r$. The operations are usual matrix addition and multiplication, with the usual zero matrix, but with $E$ for the multiplicative identity. Suppose that there is a field isomorphism $h:K\to L \subset \r$. (There is one, indeed, described below.) Let $a=h(A)$, then $1+a=a^2$ since $E+A=A^2$. The solutions for $a$ are the golden section $\varphi=\frac{1+\sqrt{5}}2\approx1.618$ and $\psi=\frac{1-\sqrt{5}}2\approx-0.618$. Thus, $K$ is isomorphic to the field extension $\q(\sqrt{5})$ (hmm, I didn't verify if matrix multiplication goes into usual multiplication in $\r$, so I may be wrong, but will keep writing). Let $(p,q)$ abbreviate the matrix $\begin{pmatrix} q & r & r \\ q & r & r \\ p & q & q \end{pmatrix}$, where $p+q=r$. Then $h(E)=h(-1,1)=1$, $h(A)=h(1,0)=a$, and  $h(A^2)=h(0,1)=a^2$. Thus $h(p,q)=pa+qa^2$. Note also that $\pm\sqrt{5}=3a-a^2$. There are two possibilities for $h$. Either (1), $a=\varphi$ and then $h(p,q)=\frac{p+3q}2+\frac{p+q}2\sqrt{5}$, or (2), $a=\psi$ and then $h(p,q)=\frac{p+3q}2-\frac{p+q}2\sqrt{5}$. I feel I didn't verify all details, but it is getting late again. If what I wrote in this edit is incorrect, then the question remains as to explain what the above example is or does.","$\def\r{\Bbb R}$  $\def\q{\Bbb Q}$ As the title suggest, I am trying to do something that I know cannot be done, so my question is confused, and I am trying to make sense of it. Generally: (1) How does one make sense of what I describe below, and (2) are there known results and known terminology applicable, related to my comments? (I am tempted to think of some generalizations of rings, monoids, but I can't make sense of it without using a unit.) So, I was reading about irreducible matrices (and relations to strongly connected graphs, online), after starting with the book Dynamical Systems and Ergodic Theory by Pollicott and Yuri. As an example of an irreducible matrix they give  $A=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}$. Since the first two rows coincide, clearly $\det(A)=0$ and $A$ is not invertible. Nevertheless one may look at powers $A^n$ of $A$, as well as at $A^n-A^{n-1}$.  Certainly this is possible for $n\ge2$, and my computer (using computer algebra Reduce) happily evaluates the case $n=1$ too, as $A^1-A^{1-1}=\begin{pmatrix} -1 & 1 & 1 \\ 0 & 0 & 1 \\ 1 & 0 & -1 \end{pmatrix}$ (obviously using $A^{1-1}=I=\begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$), but the case $n=0$,  that is $A^0-A^{-1}$ generates an error message ``Singular matrix'' (of course, as $A^{-1}$ does not exist). But, it turns out $A^{n+1}-A^n= A^{n-1}$ for $n\ge2$. For example, $n=2$, then $A^3=\begin{pmatrix} 1 & 2 & 2 \\ 1 & 2 & 2 \\ 1 & 1 & 1 \end{pmatrix}$, and $A^3-A^2=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}= A^1$. $n=3$, then $A^4=\begin{pmatrix} 2 & 3 & 3 \\ 2 & 3 & 3 \\ 1 & 2 & 2 \end{pmatrix}$, and $A^4-A^3=\begin{pmatrix} 1 & 1 & 1 \\ 1 & 1 & 1 \\ 0 & 1 & 1 \end{pmatrix}= A^2$. $n=4$, then $A^5=\begin{pmatrix} 3 & 5 & 5 \\ 3 & 5 & 5 \\ 2 & 3 & 3 \end{pmatrix}$, and $A^5-A^4=\begin{pmatrix} 1 & 2 & 2 \\ 1 & 2 & 2 \\ 1 & 1 & 1 \end{pmatrix}= A^3$. $n=5$, then $A^6=\begin{pmatrix} 5 & 8 & 8 \\ 5 & 8 & 8 \\ 3 & 5 & 5 \end{pmatrix}$, and $A^6-A^5=\begin{pmatrix} 2 & 3 & 3 \\ 2 & 3 & 3 \\ 1 & 2 & 2 \end{pmatrix}= A^4$. (As seen the Fibonacci numbers are involved too.) From the above, one if tempted to (recursively) define $A^{n-1}=A^{n+1}-A^n$ for all $n\le1$. For example, $A^0=A^2-A^1 = \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix} \not= I$. Even though $A^0$, defined this way, is different from $I$, it acts like $I$ when multiplied to $A^n$, $n\ge1$. For example, $A^0\cdot A=A\cdot A^0=A$, $A^0\cdot A^7=A^7\cdot A^0=A^7$, etc. Also, $(A^0)^2=A^0$, and $(A^0)^n=A^0$ for $n\ge1$. Similarly, one may define $A^{-1}=A^1-A^0 = \begin{pmatrix} -1 & 1 & 1 \\ -1 & 1 & 1 \\ 2 & -1 & -1 \end{pmatrix}$. (And, one may define $A^{-n}$ for all $n\ge1$.) Even though $A$ is not invertible, the $A^{-1}$ as defined above behaves like an inverse of $A$, namely $A^{-1}\cdot A=A\cdot A^{-1}=A^0 =  \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$. So, my (confused) question (in addition to (1) and (2) at the beginning) is:  (3) What am I observing (assuming it has already observed and is well-known)? Edit. I think I understand better what I was asking (or what had confused me) and will post my comments here. This is essentially an answer, but I will leave the option open for someone else to post their answer, as they find appropriate, as the question was a bit open ended, and may get different types of answers.  (Also, after typing this edit, I feel there are more details to be verified.) QiaochuYuan left a comment which I initially did not understand, but now I think he meant something along what is illustrated by the following example. Let $F=\{\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}: x\in\r\}$. Then $F$ is a field isomorphic to $\r$, with additive identity $O=\begin{pmatrix} 0 & 0  \\ 0 & 0 \end{pmatrix}$ and multiplicative identity $U=\begin{pmatrix} 1 & 0  \\ 0 & 0 \end{pmatrix}$, and if $X=\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}\not=O$ then $X^{-1}=\begin{pmatrix} x^{-1} & 0  \\ 0 & 0 \end{pmatrix}$. The latter does not contradict the fact that $\begin{pmatrix} x & 0  \\ 0 & 0 \end{pmatrix}$, as a matrix, is not invertible. If $Id=\begin{pmatrix} 1 & 0  \\ 0 & 1 \end{pmatrix}$ is the identity matrix, this looks like a contradiction, having two different multiplicative identities, namely $U$ and $Id$, but there is no contradiction as simply $Id$ does not belong to $F$. It didn't seem that QiaochuYuan addressed the identity $A^{n+1}-A^n= A^{n-1}$ for $n\ge2$ (and the latter seemed special to me). Let $E= \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$ (which I had denoted by $A^0$ above, but I prefer $E$ now). $E$ is the multiplicative identity of the structure described in my question, and I was puzzled as it looked like there were two different multiplicative identities, namely $E$, and $I= \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{pmatrix}$. It seemed to me that if we use the usual matrix multiplication, then there was only one choice for the multiplicative identity, namely $I$. The matrix $E$ isn't even a diagonal matrix, and it looked strange it would be a multiplicative identity  (and I must have forgotten that matrices have normal forms). Well, I verified the details later, and $E$ is indeed the multiplicative identity, while $I$ simply does not belong to this structure. Call the structure hinted at in my question $K$. So $K$ contains  $A=\begin{pmatrix} 0 & 1 & 1 \\ 0 & 1 & 1 \\ 1 & 0 & 0 \end{pmatrix}$ as well as  all $A^n$, $n\ge1$ (usual matrix multiplication). We have that $A^{n-1}=A^{n+1}-A^n$ for all $n\ge2$, and this suggest that $E=A^2-A= \begin{pmatrix} 1 & 0 & 0 \\ 1 & 0 & 0 \\ -1 & 1 & 1 \end{pmatrix}$ would play the role of the multiplicative identity. Once this is done, we could define the inverse of $A$, as $A-E$ (where $E$ plays the role of $A^0$). I had used the notation $A^{-1}$ in my question, but I confuse myself with that as I think in this context it should be reserved for matrix inverse (which for $A$ does not exist). So, if $n\ge1$, I will denote the multiplicative inverse of $A^n$ (in $K$) by $A^{[-n]}$. In particular, $A^{[-1]}=A-E=\begin{pmatrix} -1 & 1 & 1 \\ -1 & 1 & 1 \\ 2 & -1 & -1 \end{pmatrix}$, then $A^{[-2]}=E-A^{[-1]}=\begin{pmatrix} 2 & -1 & -1 \\ 2 & -1 & -1 \\ -3 & 2 & 2 \end{pmatrix}$, next $A^{[-3]}=A^{[-1]}-A^{[-2]}$, etc. (using the identity $A^{n-1}=A^{n+1}-A^n$ as a model). Let $S=\{A^{[-n]}:n\ge1\}\cup\{E\}\cup\{A^n:n\ge1\}$. Then $S$ is a commutative ring under usual matrix multiplication, with identity element $E$. Since of course we could add and subtract the elements of $S$ (as matrices), I was confused that $S$ is a field, and I knew that couldn't be, as the multiplicative group should contain a copy of the rationals $\q$, whereas $S$ seems isomorphic as a group to $(\Bbb Z,+)$. (But it was getting late.) I had simply forgotten that $S$ is not closed under addition (and subtraction).  So $S$ is not a field, but it generates a field. Let $K$ be the field that is generated by $S$. I will present a couple of more specific descriptions of $K$ below. First, every element of $S$ is of the form $\begin{pmatrix} q & r & r \\ q & r & r \\ p & q & q \end{pmatrix}$, with $p+q=r$ (so obviously such an element is completely determined by $p$ and $q$). Every element of $K$ is of this form too, where $p,q,r\in\q$ and $p+q=r$. The operations are usual matrix addition and multiplication, with the usual zero matrix, but with $E$ for the multiplicative identity. Suppose that there is a field isomorphism $h:K\to L \subset \r$. (There is one, indeed, described below.) Let $a=h(A)$, then $1+a=a^2$ since $E+A=A^2$. The solutions for $a$ are the golden section $\varphi=\frac{1+\sqrt{5}}2\approx1.618$ and $\psi=\frac{1-\sqrt{5}}2\approx-0.618$. Thus, $K$ is isomorphic to the field extension $\q(\sqrt{5})$ (hmm, I didn't verify if matrix multiplication goes into usual multiplication in $\r$, so I may be wrong, but will keep writing). Let $(p,q)$ abbreviate the matrix $\begin{pmatrix} q & r & r \\ q & r & r \\ p & q & q \end{pmatrix}$, where $p+q=r$. Then $h(E)=h(-1,1)=1$, $h(A)=h(1,0)=a$, and  $h(A^2)=h(0,1)=a^2$. Thus $h(p,q)=pa+qa^2$. Note also that $\pm\sqrt{5}=3a-a^2$. There are two possibilities for $h$. Either (1), $a=\varphi$ and then $h(p,q)=\frac{p+3q}2+\frac{p+q}2\sqrt{5}$, or (2), $a=\psi$ and then $h(p,q)=\frac{p+3q}2-\frac{p+q}2\sqrt{5}$. I feel I didn't verify all details, but it is getting late again. If what I wrote in this edit is incorrect, then the question remains as to explain what the above example is or does.",,"['abstract-algebra', 'matrices', 'recurrence-relations', 'dynamical-systems', 'algebraic-graph-theory']"
42,Is there a (not so) generalized version of Hilbert's Theorem 90?,Is there a (not so) generalized version of Hilbert's Theorem 90?,,"I'm sorry if my following question doesn't make any sense. We know that if $L/k$ is a finite Galois extension then $H^{1}(\mathrm{Gal}(L/k),L^{*})=0$ (Hilbert's theorem 90). However I would like to know if there is some generalized version involving some field extension $M/L$ such that $H^{1}(\mathrm{Gal}(L/k),M^{*})=0$? Here note that $L$ and $M$ are not the same as in the usual version $H^{1}(\mathrm{Gal}(L/k),L^{*})$=0. Also I'm assuming that $M$ is already a $\mathrm{Gal}(L/k)$-module. (Edit: If $M/k$ is a Galois extension and $\sigma\in{\mathrm{Gal}(L/k)}$, then choose an automorphism $\tilde{\sigma}:M\rightarrow{M}$ extending $\sigma$ and define $\sigma\cdot{m}:=\tilde{\sigma}(m)$ for all $m\in{M}$. This could give $M$ a structure of $\mathrm{Gal}(L/k)$-module but I'm not sure!) The motivation of this question is a proof regarding divisors on a smooth curve that I'm trying to understand. In that proof the author says that he will use a generalized version of Hilbert's theorem 90 but he doesn't say what version is. The context is a smooth curve $C/k$ with a generic point $\xi$, a finite Galois extension $L/k$ and a 1-cocycle $f:\mathrm{Gal}(L/k)\rightarrow{L(\xi)^{*}}$ and then the author says ""by a generalization of Hilbert's theorem 90 this 1-cocycle is a 1-coboundary"", so I'm assuming that the version is something like $H^{1}(\mathrm{Gal}(L/k),L(\xi)^{*})=0$ (whereas the usual version only implies $H^{1}(\mathrm{Gal}(L/k),L^{*})=0$). Could anyone tell me what this generalization could be? I know that there is a generalization involving tale cohomology but I don't think it should be that complicated. Any help is appreciated.","I'm sorry if my following question doesn't make any sense. We know that if $L/k$ is a finite Galois extension then $H^{1}(\mathrm{Gal}(L/k),L^{*})=0$ (Hilbert's theorem 90). However I would like to know if there is some generalized version involving some field extension $M/L$ such that $H^{1}(\mathrm{Gal}(L/k),M^{*})=0$? Here note that $L$ and $M$ are not the same as in the usual version $H^{1}(\mathrm{Gal}(L/k),L^{*})$=0. Also I'm assuming that $M$ is already a $\mathrm{Gal}(L/k)$-module. (Edit: If $M/k$ is a Galois extension and $\sigma\in{\mathrm{Gal}(L/k)}$, then choose an automorphism $\tilde{\sigma}:M\rightarrow{M}$ extending $\sigma$ and define $\sigma\cdot{m}:=\tilde{\sigma}(m)$ for all $m\in{M}$. This could give $M$ a structure of $\mathrm{Gal}(L/k)$-module but I'm not sure!) The motivation of this question is a proof regarding divisors on a smooth curve that I'm trying to understand. In that proof the author says that he will use a generalized version of Hilbert's theorem 90 but he doesn't say what version is. The context is a smooth curve $C/k$ with a generic point $\xi$, a finite Galois extension $L/k$ and a 1-cocycle $f:\mathrm{Gal}(L/k)\rightarrow{L(\xi)^{*}}$ and then the author says ""by a generalization of Hilbert's theorem 90 this 1-cocycle is a 1-coboundary"", so I'm assuming that the version is something like $H^{1}(\mathrm{Gal}(L/k),L(\xi)^{*})=0$ (whereas the usual version only implies $H^{1}(\mathrm{Gal}(L/k),L^{*})=0$). Could anyone tell me what this generalization could be? I know that there is a generalization involving tale cohomology but I don't think it should be that complicated. Any help is appreciated.",,"['abstract-algebra', 'number-theory', 'algebraic-geometry', 'field-theory', 'galois-cohomology']"
43,On normal $p$-complements,On normal -complements,p,"This is question 5E.3. of Isaacs's Finite Group Theory: Suppose every two generator subgroup of a finite group has a normal $p$-complement. Show that $G$ has a normal $p$-complement. Of course there's a hint there: consider the subgroup generated by $x$ and $y$, where $x$ is in some $p$-group $P$ and $y \in {N_G(P)}$ has order not divisible by $p$. Any hints on how to use the hint would be immensely appreciated!","This is question 5E.3. of Isaacs's Finite Group Theory: Suppose every two generator subgroup of a finite group has a normal $p$-complement. Show that $G$ has a normal $p$-complement. Of course there's a hint there: consider the subgroup generated by $x$ and $y$, where $x$ is in some $p$-group $P$ and $y \in {N_G(P)}$ has order not divisible by $p$. Any hints on how to use the hint would be immensely appreciated!",,"['abstract-algebra', 'group-theory', 'finite-groups']"
44,"Norm on ""tower"" of fields (the question comes from algebraic number theory)","Norm on ""tower"" of fields (the question comes from algebraic number theory)",,"Consider the field extensions $L\supset K'\supset K$ , where both $L|K$ and $K'|K$ are finite and Galois. I want to prove that $$N_{L|K}(L^\ast)\subseteq N_{L|K'}(L^{\ast})$$ Maybe it is very easy, but I wasn't able to find a solution after much time spent on it. Clearly $N_{L|K}(L^\ast)\subseteq K^\ast$ and $N_{L|K'}(L^{\ast})\subseteq K'^\ast$ , also from transitivity of norm we have $N_{L/K}(L^\ast) \subseteq N_{K'/K}(K'^\ast)$ , but they obviously doesn't imply anything. Edit: For completeness I explain from where my question comes from. I'm reading chapter $IV$ of Neukirch's Algebraic number theory book (the chapter is about abstract class field theory) and I saw the following commutative diagram at page $297$ : I can't completely understand the vertical arrow on the right. The author says that it is induced by the inclusion $A_K\subset A_{K'}$ (here unfortunately you have to be familiar with Neukirch notation to understand what is $A_K$ ). So, such a vertical arrow is well defined if I can solve the problem of my question. I've decided to write my question in the category of fields extensions in order to be as clear as possible. In this way also I avoided a cumbersome introduction about notations.","Consider the field extensions , where both and are finite and Galois. I want to prove that Maybe it is very easy, but I wasn't able to find a solution after much time spent on it. Clearly and , also from transitivity of norm we have , but they obviously doesn't imply anything. Edit: For completeness I explain from where my question comes from. I'm reading chapter of Neukirch's Algebraic number theory book (the chapter is about abstract class field theory) and I saw the following commutative diagram at page : I can't completely understand the vertical arrow on the right. The author says that it is induced by the inclusion (here unfortunately you have to be familiar with Neukirch notation to understand what is ). So, such a vertical arrow is well defined if I can solve the problem of my question. I've decided to write my question in the category of fields extensions in order to be as clear as possible. In this way also I avoided a cumbersome introduction about notations.",L\supset K'\supset K L|K K'|K N_{L|K}(L^\ast)\subseteq N_{L|K'}(L^{\ast}) N_{L|K}(L^\ast)\subseteq K^\ast N_{L|K'}(L^{\ast})\subseteq K'^\ast N_{L/K}(L^\ast) \subseteq N_{K'/K}(K'^\ast) IV 297 A_K\subset A_{K'} A_K,"['abstract-algebra', 'field-theory', 'algebraic-number-theory', 'galois-theory']"
45,Prove that $u$ is a trivial unit,Prove that  is a trivial unit,u,"Let $G$ be a finite group. I want to prove that if $u\in \mathbb{Z}G$ be a torsion  unit (i.e. for some $n$, $u^n=1$) of integral group ring $\mathbb{Z}G$ such that $u$ normalizes $G$,  then $u$ is a trivial unit i.e. $u=\pm g$ for some $g\in G$. In simple language , I need to prove that for a finite group $G$, all torsion units in $N_U(G)$ are trivial (i.e. of form $\pm g$) where $U$ is unit group of $\mathbb{Z}G$ It looked easy, but after several attempts and using known results on units in Integral group rings I was getting nowhere. Any help is appreciated! Thanks","Let $G$ be a finite group. I want to prove that if $u\in \mathbb{Z}G$ be a torsion  unit (i.e. for some $n$, $u^n=1$) of integral group ring $\mathbb{Z}G$ such that $u$ normalizes $G$,  then $u$ is a trivial unit i.e. $u=\pm g$ for some $g\in G$. In simple language , I need to prove that for a finite group $G$, all torsion units in $N_U(G)$ are trivial (i.e. of form $\pm g$) where $U$ is unit group of $\mathbb{Z}G$ It looked easy, but after several attempts and using known results on units in Integral group rings I was getting nowhere. Any help is appreciated! Thanks",,"['abstract-algebra', 'ring-theory', 'group-rings']"
46,Denominator in rational gcd of integer polynomials,Denominator in rational gcd of integer polynomials,,"A recent question tells us that even if two polynomials $f,g\in \mathbb Z[X]$ have no common factor as polynomials, their values at integer points may have common factors. That question gives this example: $$ f=x^3-x^2+3x-1, \qquad g=x^3+2, \qquad \gcd(f(27),g(27))=31 $$ The explanation I've given for this example is that even though $\gcd(f,g)=1$ in $\mathbb{Z}[x]$, we cannot always write $1=uf+vg$ with $u,v \in \mathbb{Z}[x]$ (because $\mathbb{Z}[x]$ is not a PID). But we can write $1=uf+vg$, if we allow $u,v \in \mathbb{Q}[x]$. In the example above, we get $$ 1 = \dfrac1{31} (-6 x^2-7 x-3)f(x)+\dfrac1{31}(6 x^2+x+14)g(x) $$ Now, clearing denominators, we get $d = uf+vg$ with $u,v \in \mathbb{Z}[x]$ and $d \in \mathbb{Z}$. Is there a name for $d$ in terms of $f$ and $g$? Can we compute $d$ without performing the entire  extended Euclidean algorithm in $\mathbb{Q}[x]$? When $d>1$, is it always true that some values of $f$ and $g$ (at the same point) are not coprime? It seemed that $d$ is the resultant of $f$ and $g$, but perhaps not .","A recent question tells us that even if two polynomials $f,g\in \mathbb Z[X]$ have no common factor as polynomials, their values at integer points may have common factors. That question gives this example: $$ f=x^3-x^2+3x-1, \qquad g=x^3+2, \qquad \gcd(f(27),g(27))=31 $$ The explanation I've given for this example is that even though $\gcd(f,g)=1$ in $\mathbb{Z}[x]$, we cannot always write $1=uf+vg$ with $u,v \in \mathbb{Z}[x]$ (because $\mathbb{Z}[x]$ is not a PID). But we can write $1=uf+vg$, if we allow $u,v \in \mathbb{Q}[x]$. In the example above, we get $$ 1 = \dfrac1{31} (-6 x^2-7 x-3)f(x)+\dfrac1{31}(6 x^2+x+14)g(x) $$ Now, clearing denominators, we get $d = uf+vg$ with $u,v \in \mathbb{Z}[x]$ and $d \in \mathbb{Z}$. Is there a name for $d$ in terms of $f$ and $g$? Can we compute $d$ without performing the entire  extended Euclidean algorithm in $\mathbb{Q}[x]$? When $d>1$, is it always true that some values of $f$ and $g$ (at the same point) are not coprime? It seemed that $d$ is the resultant of $f$ and $g$, but perhaps not .",,"['abstract-algebra', 'elementary-number-theory', 'polynomials', 'gcd-and-lcm']"
47,Is the sheaf of differentials on an elliptic curve over $R$ with a Weierstrass equation free?,Is the sheaf of differentials on an elliptic curve over  with a Weierstrass equation free?,R,"Let $R$ be an integral domain and $E\stackrel{f}{\rightarrow}\text{Spec }R$ be an elliptic curve given by $$E := \text{Proj }R[x,y,z]/(y^2z + a_1xyz + a_3yz^2 = x^3 + a_2x^2z + a_4xz^2 + a_6z^3)$$ where $a_i\in R$. Is there a nowhere vanishing differential on $E/R$? Ie., is $f_*\Omega_{E/R}$ free? (isomorphic to $\tilde{R}$?) If $R$ is a field, then the language of Silverman seems pretty straightforward and allows one to calculate that $\omega := \frac{dx}{2y+a_1x + a_3}$ is holomorphic and nonvanishing, hence a basis for $f_*\Omega_{E/R}$ in this case. However, I don't feel like I have the right language for discussing differentials when $R$ is not a field.","Let $R$ be an integral domain and $E\stackrel{f}{\rightarrow}\text{Spec }R$ be an elliptic curve given by $$E := \text{Proj }R[x,y,z]/(y^2z + a_1xyz + a_3yz^2 = x^3 + a_2x^2z + a_4xz^2 + a_6z^3)$$ where $a_i\in R$. Is there a nowhere vanishing differential on $E/R$? Ie., is $f_*\Omega_{E/R}$ free? (isomorphic to $\tilde{R}$?) If $R$ is a field, then the language of Silverman seems pretty straightforward and allows one to calculate that $\omega := \frac{dx}{2y+a_1x + a_3}$ is holomorphic and nonvanishing, hence a basis for $f_*\Omega_{E/R}$ in this case. However, I don't feel like I have the right language for discussing differentials when $R$ is not a field.",,"['abstract-algebra', 'number-theory', 'algebraic-geometry', 'elliptic-curves']"
48,What is the discriminant of a degree $n$ polynomial?,What is the discriminant of a degree  polynomial?,n,In my high school algebra class the teacher (who is me) says that the discriminant of a quadratic polynomial $ax^2 + bx + c$ is $b^2 - 4ac$. I have read in the Wikipedia article that the discriminant of a polynomial is the product of the squares of the differences of its roots.  This does not seem to be consistent with the above.  If I subtract the roots of a quadratic and then square the result I get $\frac{(b^2 - 4ac)}{a^2}$.,In my high school algebra class the teacher (who is me) says that the discriminant of a quadratic polynomial $ax^2 + bx + c$ is $b^2 - 4ac$. I have read in the Wikipedia article that the discriminant of a polynomial is the product of the squares of the differences of its roots.  This does not seem to be consistent with the above.  If I subtract the roots of a quadratic and then square the result I get $\frac{(b^2 - 4ac)}{a^2}$.,,"['abstract-algebra', 'algebra-precalculus']"
49,Tensor product of modules: $\Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z \cong (\Bbb Z/p\Bbb Z)[x]/\langle f(x) \rangle$,Tensor product of modules:,\Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z \cong (\Bbb Z/p\Bbb Z)[x]/\langle f(x) \rangle,"This is a question about tensor product of modules. How to show that   $$\Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z \cong (\Bbb Z/p\Bbb Z)[x]/\langle f(x) \rangle$$   for any prime $p$ and irreducible polynomial $f(x)\in\Bbb Z[x]$? Attempt: I start with the map $$\phi:\Bbb Z/p\Bbb Z[x] \to \Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z$$ defined by $$\phi(a_0+a_1x+\cdots+a_nx^n)=1\otimes a_0+x\otimes a_1+\cdots+x^n\otimes a_n.$$ It is easy to show that $\phi$ is a well-defined surjective module homomorphism, so it suffices to show that $$\ker\phi=\langle f(x) \rangle \subset\Bbb{Z}/p\Bbb{Z}[x].$$ But this is where I am stuck. Suppose $$\phi(a_0+\cdots+a_nx^n)=1\otimes a_0+\cdots+x^n\otimes a_n=(a_0+\cdots+a_nx^n)\otimes 1=0.$$ I am tempted to say that this implies that $a_0+\cdots+a_nx^n=0\in\Bbb{Z}[x]/\langle f(x)\rangle$, but I am not sure how to justify this.","This is a question about tensor product of modules. How to show that   $$\Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z \cong (\Bbb Z/p\Bbb Z)[x]/\langle f(x) \rangle$$   for any prime $p$ and irreducible polynomial $f(x)\in\Bbb Z[x]$? Attempt: I start with the map $$\phi:\Bbb Z/p\Bbb Z[x] \to \Bbb Z[x]/\langle f(x) \rangle \otimes_{\Bbb Z} \Bbb Z/p\Bbb Z$$ defined by $$\phi(a_0+a_1x+\cdots+a_nx^n)=1\otimes a_0+x\otimes a_1+\cdots+x^n\otimes a_n.$$ It is easy to show that $\phi$ is a well-defined surjective module homomorphism, so it suffices to show that $$\ker\phi=\langle f(x) \rangle \subset\Bbb{Z}/p\Bbb{Z}[x].$$ But this is where I am stuck. Suppose $$\phi(a_0+\cdots+a_nx^n)=1\otimes a_0+\cdots+x^n\otimes a_n=(a_0+\cdots+a_nx^n)\otimes 1=0.$$ I am tempted to say that this implies that $a_0+\cdots+a_nx^n=0\in\Bbb{Z}[x]/\langle f(x)\rangle$, but I am not sure how to justify this.",,"['abstract-algebra', 'modules', 'tensor-products']"
50,Tensor products and morphisms,Tensor products and morphisms,,"Let $C$ be  semisimple category with simple objects $X_1, \dots, X_r$. Suppose we have a fusion relation $X_i\otimes X_j =\bigoplus_{l=1}^r N_{ij}^l X_l$. Let $m\in \mathbb{N}$ and let $g:mX_j \to mX_j$ be a morphism given by $m$ by $m$ matrix over a field $k$. Using the relation above, the algebra $\mathrm{End}((X_i\otimes mX_j)\otimes X_l)=\mathrm{End}(X_i \otimes (mX_j \otimes X_l))$ is equal to $$\otimes_{s=1}^r \mathrm{Mat}_{mn_{s}}(k),$$ where $$n_s=\sum_{p=1}^rN_{ij}^p N_{pl}^s=\sum_{q=1}^r N_{iq}^s N_{jl}^q.$$ I want to show that in this algebra, we have $$(\mathrm{id}_{X_i} \otimes g ) \otimes \mathrm{id}_{X_l}=\bigoplus_{p=1}^r \mathrm{id}_{N_{ij}^p} \otimes g \otimes \mathrm{id}_{N_{pl}^s}.$$ [That formula needs to be fixed; for example, $s$ is undefined.] I don't understand how morphisms are changed by the fusion relation. EDIT It is really hard to see but actually $s$ is defined. The subscript in $\otimes_{s=1}^r \mathrm{Mat}_{mn_{s}}(k)$ is $mn_{s}$.","Let $C$ be  semisimple category with simple objects $X_1, \dots, X_r$. Suppose we have a fusion relation $X_i\otimes X_j =\bigoplus_{l=1}^r N_{ij}^l X_l$. Let $m\in \mathbb{N}$ and let $g:mX_j \to mX_j$ be a morphism given by $m$ by $m$ matrix over a field $k$. Using the relation above, the algebra $\mathrm{End}((X_i\otimes mX_j)\otimes X_l)=\mathrm{End}(X_i \otimes (mX_j \otimes X_l))$ is equal to $$\otimes_{s=1}^r \mathrm{Mat}_{mn_{s}}(k),$$ where $$n_s=\sum_{p=1}^rN_{ij}^p N_{pl}^s=\sum_{q=1}^r N_{iq}^s N_{jl}^q.$$ I want to show that in this algebra, we have $$(\mathrm{id}_{X_i} \otimes g ) \otimes \mathrm{id}_{X_l}=\bigoplus_{p=1}^r \mathrm{id}_{N_{ij}^p} \otimes g \otimes \mathrm{id}_{N_{pl}^s}.$$ [That formula needs to be fixed; for example, $s$ is undefined.] I don't understand how morphisms are changed by the fusion relation. EDIT It is really hard to see but actually $s$ is defined. The subscript in $\otimes_{s=1}^r \mathrm{Mat}_{mn_{s}}(k)$ is $mn_{s}$.",,"['abstract-algebra', 'category-theory']"
51,Integer parts isomorphic?,Integer parts isomorphic?,,"Let $F$ be a real closed field. It is known$^{[1]}$ that $F$ has an integer part, that is, a subring $A$ such that $\forall x \in F, \exists ! a \in A,  a \leq x < a+1$. Are all integer parts over $F$ isomorphic as ordered rings? $[1]$: M. H. Mourgues and J. P. Ressayre The Journal of Symbolic Logic Vol. 58, No. 2 (Jun., 1993), pp. 641-647 Real closed fields are fields in which $X^2 + 1$ is irreductible and $F[X] / (X^2 + 1)$ is algebraically closed. They are ordered by setting $x \geq 0$ iff $x$ is a square. A few ideas: -Every order preserving isomorphism between two integer parts in $F$ extends in a unique way as an automorphism of $F$. -Integer parts of real closed fields are exactly models of open induction (PA with induction scheme restricted to quantifier-free formulas). -If $G$ is a subgroup of $(F,+)$ such that $\forall x \in F, \exists ! g \in G, g \leq x < g+1$ then the group $(F,+) / G$ is isomorphic to the ""torus"" $([0;1[_F,\underline{+})$ where $x\underline{+}y = x+y \ \mod 1$. This torus need not be isomorphic to ${{\mathbb{S}}^1}_F = \{(x,y) \in F^2 \ | \ x^2 + y^2 = 1\}$ with $(x,y)\underline{.}(z,t) = (x.z-y.t,x.t+y.z)$. -No integer part over $F$ is definable in $(F,+,.,0,1)$.","Let $F$ be a real closed field. It is known$^{[1]}$ that $F$ has an integer part, that is, a subring $A$ such that $\forall x \in F, \exists ! a \in A,  a \leq x < a+1$. Are all integer parts over $F$ isomorphic as ordered rings? $[1]$: M. H. Mourgues and J. P. Ressayre The Journal of Symbolic Logic Vol. 58, No. 2 (Jun., 1993), pp. 641-647 Real closed fields are fields in which $X^2 + 1$ is irreductible and $F[X] / (X^2 + 1)$ is algebraically closed. They are ordered by setting $x \geq 0$ iff $x$ is a square. A few ideas: -Every order preserving isomorphism between two integer parts in $F$ extends in a unique way as an automorphism of $F$. -Integer parts of real closed fields are exactly models of open induction (PA with induction scheme restricted to quantifier-free formulas). -If $G$ is a subgroup of $(F,+)$ such that $\forall x \in F, \exists ! g \in G, g \leq x < g+1$ then the group $(F,+) / G$ is isomorphic to the ""torus"" $([0;1[_F,\underline{+})$ where $x\underline{+}y = x+y \ \mod 1$. This torus need not be isomorphic to ${{\mathbb{S}}^1}_F = \{(x,y) \in F^2 \ | \ x^2 + y^2 = 1\}$ with $(x,y)\underline{.}(z,t) = (x.z-y.t,x.t+y.z)$. -No integer part over $F$ is definable in $(F,+,.,0,1)$.",,"['abstract-algebra', 'model-theory', 'ordered-fields']"
52,The exceptional Klein four group,The exceptional Klein four group,,"There are at least four major cases I know where $V\cong C_2\times C_2$ is an exceptional group: The commuting probability of a nonabelian group $G$ (the probability two elements drawn uniformly at random from $G$ commute) is maximized precisely when $G/Z(G)\cong V$. A group $G$ cannot be the union of two proper subgroups , however Scorza's theorem implies that $G=H_1\cup H_2\cup H_3\iff G/(H_1\cap H_2\cap H_3)\cong V$ for proper $H\subset G$. The only vector space canonically isomorphic to its dual is $V$. See Martin's answer here , the idea traces back to ACL's comment which gives earlier attribution. Given $\{0,a,b,c\}$ is a copy of $V$, one can define e.g. the dual vector $a^*$ to be the characteristic function of $\{b,c\}$. Say $G$ is a functor from the category ${\sf B}_n$ of sets of cardinality $n$ with bijections into $\sf Grp$, equipped with a natural transformation $G\to{\rm Perm}$ consisting of injective group homomorphisms. One calls $GX$ a natural permutation group on $X$. The only natural permutation groups are trivial, alternating, symmetric, and $V$ on four element sets. The last is of my own making and follows from $V\triangleleft S_4$ being the only exceptional normal subgroup of symmetric groups (arguably I should have just stated that as my bullet point). It is the unique subgroup of ${\rm Perm}(\{a,b,c,d\})$ which fixes every partition of the form $\{\{\alpha,\beta\},\{\gamma,\delta\}\}$, and thus can be specified canonically without making any arbitrary choices. I also have a vague sense that $V$s automorphisms ${\rm Aut}(V)\cong S_3$ act exceptionally transitively, but that's likely just a special case of the same phenomenon for all elementary abelian groups. Questions: Are the above examples related to each other, or is there a unifying explanation for why we should expect $V$ to manifest as an edge case in so many different guises? Does anybody have more examples of $V$ being an exceptional group to add to the list?","There are at least four major cases I know where $V\cong C_2\times C_2$ is an exceptional group: The commuting probability of a nonabelian group $G$ (the probability two elements drawn uniformly at random from $G$ commute) is maximized precisely when $G/Z(G)\cong V$. A group $G$ cannot be the union of two proper subgroups , however Scorza's theorem implies that $G=H_1\cup H_2\cup H_3\iff G/(H_1\cap H_2\cap H_3)\cong V$ for proper $H\subset G$. The only vector space canonically isomorphic to its dual is $V$. See Martin's answer here , the idea traces back to ACL's comment which gives earlier attribution. Given $\{0,a,b,c\}$ is a copy of $V$, one can define e.g. the dual vector $a^*$ to be the characteristic function of $\{b,c\}$. Say $G$ is a functor from the category ${\sf B}_n$ of sets of cardinality $n$ with bijections into $\sf Grp$, equipped with a natural transformation $G\to{\rm Perm}$ consisting of injective group homomorphisms. One calls $GX$ a natural permutation group on $X$. The only natural permutation groups are trivial, alternating, symmetric, and $V$ on four element sets. The last is of my own making and follows from $V\triangleleft S_4$ being the only exceptional normal subgroup of symmetric groups (arguably I should have just stated that as my bullet point). It is the unique subgroup of ${\rm Perm}(\{a,b,c,d\})$ which fixes every partition of the form $\{\{\alpha,\beta\},\{\gamma,\delta\}\}$, and thus can be specified canonically without making any arbitrary choices. I also have a vague sense that $V$s automorphisms ${\rm Aut}(V)\cong S_3$ act exceptionally transitively, but that's likely just a special case of the same phenomenon for all elementary abelian groups. Questions: Are the above examples related to each other, or is there a unifying explanation for why we should expect $V$ to manifest as an edge case in so many different guises? Does anybody have more examples of $V$ being an exceptional group to add to the list?",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups', 'big-list']"
53,What shall I learn in order to understand Auslander-Reiten theory and tilting theory?,What shall I learn in order to understand Auslander-Reiten theory and tilting theory?,,"I work on cluster algebras and quivers and hence I need to understand Auslander-Reiten theory and tilting theory as soon as possible. I have read some noncommutative algebra and homological algebra but still have trouble pondering on Auslander-Reiten-Smalo's book, Representation Theory of Artin Algebras. Without Auslander-Reiten theory I can not understand tilting theory, either. May I ask what shall I learn in order to understand both of them? Thank you very much!","I work on cluster algebras and quivers and hence I need to understand Auslander-Reiten theory and tilting theory as soon as possible. I have read some noncommutative algebra and homological algebra but still have trouble pondering on Auslander-Reiten-Smalo's book, Representation Theory of Artin Algebras. Without Auslander-Reiten theory I can not understand tilting theory, either. May I ask what shall I learn in order to understand both of them? Thank you very much!",,"['abstract-algebra', 'soft-question', 'representation-theory', 'noncommutative-algebra']"
54,A question on coalgebras(2),A question on coalgebras(2),,"Assume that $C$ is  a  coalgebra with comultiplication $\Delta:C \to C\otimes C$. The higher order comultiplication can be defined inductively as follows(with some abuse of notations we denote them by $\Delta$,  again): $$\Delta:C\to C\otimes C \otimes C\\ \text{with}\\ \Delta:=(\Delta \otimes id) \circ \Delta$$....etc. Consider the polynomial coalgebra $C=\mathbb{C}[x]$  with divided power structure Then every power of the differentiation operator satisfies $$(\overbrace{T\otimes T \ldots\otimes T}^{n-times} )\circ \Delta=\Delta \circ T^{n}\\  \forall  n\in \mathbb{N}$$. See this post Is there another example of an operator on polynomial coalgebra which satisfies the above equation for all natural number $n$? Is there an example of  an operator on polynomial coalgebra which satisfies the above equation for some $n>2$ but does not satisfy for $n=2$?","Assume that $C$ is  a  coalgebra with comultiplication $\Delta:C \to C\otimes C$. The higher order comultiplication can be defined inductively as follows(with some abuse of notations we denote them by $\Delta$,  again): $$\Delta:C\to C\otimes C \otimes C\\ \text{with}\\ \Delta:=(\Delta \otimes id) \circ \Delta$$....etc. Consider the polynomial coalgebra $C=\mathbb{C}[x]$  with divided power structure Then every power of the differentiation operator satisfies $$(\overbrace{T\otimes T \ldots\otimes T}^{n-times} )\circ \Delta=\Delta \circ T^{n}\\  \forall  n\in \mathbb{N}$$. See this post Is there another example of an operator on polynomial coalgebra which satisfies the above equation for all natural number $n$? Is there an example of  an operator on polynomial coalgebra which satisfies the above equation for some $n>2$ but does not satisfy for $n=2$?",,"['abstract-algebra', 'quantum-groups', 'coalgebras']"
55,Algebraic proof that a set generated by irrational rotations is dense in $S^1$.,Algebraic proof that a set generated by irrational rotations is dense in .,S^1,"This is exercise 1.9 in Lie Groups, Lie Algebras and Representations - Hall. Suppose $a$ is an irrational real number.  Show that the set $E_a$ of the numbers of the form $e^{2\pi i n a}$, $n \in \mathbb{Z}$, is dense in the unit circle $S_1$.  Hint: Show that if we divided $S^1$ into $N$ equally sized ""bins"" of length $2\pi/N$, there is at least one bin that contains infinitely many elements of $E_a$.  Then use the fact that $E_a$ is a subgroup of $S^1$. My proof of this proposition is as follows.  Since $a$ is irrational, you can determine that the set of rotations $E_a$ is infinite.  Since $S^1$ is compact we can find two $r_1, r_2$ that are within $\epsilon$ of each other.  Then $r_1^{-1}r_2$ is a small rotation of size $\epsilon$.  Now, $r_1^{-1}r_2$ generates rotations that are within $\epsilon$ distance of any point of $S^1$. That said, I don't believe that the hint suggested in the problem uses that technique.  My knowledge of algebra is not all that strong so I was hoping someone could shed some light on what is being suggested there.","This is exercise 1.9 in Lie Groups, Lie Algebras and Representations - Hall. Suppose $a$ is an irrational real number.  Show that the set $E_a$ of the numbers of the form $e^{2\pi i n a}$, $n \in \mathbb{Z}$, is dense in the unit circle $S_1$.  Hint: Show that if we divided $S^1$ into $N$ equally sized ""bins"" of length $2\pi/N$, there is at least one bin that contains infinitely many elements of $E_a$.  Then use the fact that $E_a$ is a subgroup of $S^1$. My proof of this proposition is as follows.  Since $a$ is irrational, you can determine that the set of rotations $E_a$ is infinite.  Since $S^1$ is compact we can find two $r_1, r_2$ that are within $\epsilon$ of each other.  Then $r_1^{-1}r_2$ is a small rotation of size $\epsilon$.  Now, $r_1^{-1}r_2$ generates rotations that are within $\epsilon$ distance of any point of $S^1$. That said, I don't believe that the hint suggested in the problem uses that technique.  My knowledge of algebra is not all that strong so I was hoping someone could shed some light on what is being suggested there.",,"['abstract-algebra', 'group-theory']"
56,Adjoint representation is Lie algebra homomorphism,Adjoint representation is Lie algebra homomorphism,,"Let $T_g:=L_g R_{g^{-1}}: G \rightarrow G$ be the standard automorphism of a Lie algebra, then $Ad_g:=DT_g(e): \mathfrak{g} \rightarrow \mathfrak{g} $is called the adjoint representation. Now, I want to show that $[Ad_g \xi, Ad_g  \eta] = Ad_g [\xi,\eta].$ Here, $\xi,\eta \in \mathfrak{g}.$ So the goal is to see that $Ad$ respects also the Lie-Bracket. Unfortunately, I don't see how this can be shown.  (and I cannot use more properties here, as I only have this basic definitions available).","Let $T_g:=L_g R_{g^{-1}}: G \rightarrow G$ be the standard automorphism of a Lie algebra, then $Ad_g:=DT_g(e): \mathfrak{g} \rightarrow \mathfrak{g} $is called the adjoint representation. Now, I want to show that $[Ad_g \xi, Ad_g  \eta] = Ad_g [\xi,\eta].$ Here, $\xi,\eta \in \mathfrak{g}.$ So the goal is to see that $Ad$ respects also the Lie-Bracket. Unfortunately, I don't see how this can be shown.  (and I cannot use more properties here, as I only have this basic definitions available).",,"['abstract-algebra', 'differential-geometry', 'differential-topology', 'lie-groups', 'lie-algebras']"
57,Challenging problems in algebra (book recommendation) [closed],Challenging problems in algebra (book recommendation) [closed],,"Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 9 years ago . Improve this question Could you suggest me a book/web page where I can find challenging/hard problems in algebra (possibly with solutions) for an undergraduate student (groups, rings, fields, Galois theory)? Thanks in advance. I already know Hernstein and Dummit books.","Closed . This question needs to be more focused . It is not currently accepting answers. Want to improve this question? Update the question so it focuses on one problem only by editing this post . Closed 9 years ago . Improve this question Could you suggest me a book/web page where I can find challenging/hard problems in algebra (possibly with solutions) for an undergraduate student (groups, rings, fields, Galois theory)? Thanks in advance. I already know Hernstein and Dummit books.",,"['abstract-algebra', 'reference-request', 'big-list', 'book-recommendation']"
58,Why restriction to $B(\alpha)$ is a homomorphism from $Gal(E/B)$ to a group with kernel $Gal(E/B(\alpha))$?,Why restriction to  is a homomorphism from  to a group with kernel ?,B(\alpha) Gal(E/B) Gal(E/B(\alpha)),"I'm reading Galois Theory for Beginners by John Stillwell. It's a good introduction, giving the essence of the idea with minimum algebra complexity. However, I'm a bit lost at his Theorem 2 (the details are at the end). The proof intend to find a homomorphism of $\texttt{Gal}(E/B)$, with kernel $\texttt{Gal}(E/B(\alpha))$, into an abelian group. John says: The obvious map with kernel $\texttt{Gal}(E/B(\alpha))$ is restriction   to $B(\alpha)$, $\lvert_{B(\alpha)}$, since by definition $$\sigma \in \texttt{Gal}(E/B(\alpha)) \Leftrightarrow \sigma \lvert_{B(\alpha)} \texttt{ is the  identity map}.$$ Why restriction to $B(\alpha)$ is a homomorphism from $\texttt{Gal}(E/B)$ to a group with kernel $\texttt{Gal}(E/B(\alpha))$? What does this ""restriction"" mean? Trying to understand it, I'm taking $B = \mathbb Q$, $\alpha = \zeta$, $B(\alpha) =\mathbb Q(\zeta)$, $E = \mathbb Q (\zeta, \sqrt{2})$,  where $\zeta^5 = 1$. So $$\texttt{Gal}(E/B(\alpha)) =  \texttt{Gal}(\mathbb Q(\zeta, \sqrt{2})/\mathbb Q(\zeta)), $$  in this example  it is $\begin{array}{c|cc}  \mathbb Q(\zeta, \sqrt{2})  & \sigma_1 & \sigma_2  \\  \hline \sqrt{2}  & \sqrt{2}  & -\sqrt{2}   \\  -\sqrt{2} & -\sqrt{2} & \sqrt{2}  \\  \zeta     & \zeta     & \zeta   \\  \zeta^2   & \zeta^2   & \zeta^2  \\ \zeta^3   & \zeta^3   & \zeta^3  \\ \zeta^4   & \zeta^4   & \zeta^4,   \end{array}$ so it's isomorphism to  $$S_2 = \{(1), (1,2)\}.$$ Then  $$\texttt{Gal}(E/B) = \texttt{Gal} (\mathbb Q(\zeta, \sqrt{2})/\mathbb Q),$$ in this example it is $\begin{array}{c|cccccccc}  \mathbb Q(\zeta, \sqrt{2})  & \sigma_1 & \sigma_2 & \sigma_3 & \sigma_4 & \sigma_5 & \sigma_6 & \sigma_7 & \sigma_8 \\  \hline \sqrt{2}  & \sqrt{2}  & \sqrt{2}  & \sqrt{2}  & \sqrt{2}  & -\sqrt{2} & -\sqrt{2}  & -\sqrt{2} & -\sqrt{2}\\  -\sqrt{2} & -\sqrt{2} & -\sqrt{2} & -\sqrt{2} & -\sqrt{2} & \sqrt{2} & \sqrt{2} & \sqrt{2} & \sqrt{2}\\  \zeta     & \zeta   & \zeta^2 & \zeta^3 & \zeta^4 & \zeta   & \zeta^2 & \zeta^3  & \zeta^4 \\  \zeta^2   & \zeta^2 & \zeta^4 & \zeta   & \zeta^3 & \zeta^2 & \zeta^4 & \zeta & \zeta^3 \\ \zeta^3   & \zeta^3 & \zeta   & \zeta^4 & \zeta^2 & \zeta^3 & \zeta   & \zeta^4 & \zeta^2 \\ \zeta^4   & \zeta^4 & \zeta^3 & \zeta^2 & \zeta   & \zeta^4 & \zeta^3 & \zeta^2 & \zeta, \end{array}$ so it's isomorphism to $$\{(1), (3,4,5,6), (3,5,6,4), (3,6)(4,5), (1,2), (1,2)(3,4,5,6), (1,2)(3,5,6,4), (1,2)(3,6)(4,5) \}.$$ My guess is, so that the ""restriction to $B(\alpha)$"" actually means a subset of $\texttt{Gal} (E/B)$ that only change elements in $B(\alpha)$, so itcan be defined as $$\Sigma := \{ \tau \in \texttt{Gal}(E/B) \lvert \tau(\beta) = \beta, \forall \beta \in E \setminus B(\alpha) \},$$ in this example $\begin{array}{c|c}  \mathbb Q(\zeta, \sqrt{2}) & A = f(\texttt{Gal}(\mathbb Q(\zeta, \sqrt{2})/\mathbb Q)) \\  \hline (1)              & (1) \\  (1,2)            & (1) \\  (3,4,6,5)        & (3,4,6,5) \\  (1,2)(3,4,6,5)   & (3,4,6,5) \\  (3,5,6,4)        & (3,5,6,4)   \\  (1,2)(3,5,6,4)   & (3,5,6,4) \\  (3,6)(4,5)       & (3,6)(4,5) \\  (1,2)(3,6)(4,5)  & (3,6)(4,5) \end{array}$ Is my understanding correct? -- Theorem 2 details -- Any radical extension $F(\alpha_1, \dots, \alpha_k)$ is the union of an ascending tower of fields $F=F_0 \subseteq F_1 \subseteq \cdots \subseteq F_k = F(\alpha_1, \dots, \alpha_k)$ where each $F_i = F_{i-1}(\alpha_i)$, $\alpha_i$ is the $p_i$-th rot of an element in $F_i{i-1}$, $p_i$ is prime, and $F_i$ contains no $p_i$-th roots of unity not in $F_i{i-1}$ unless $\alpha_i$ is itself a $p_i$-th root of unity. Theorem 2. If $E\supseteq B(\alpha) \supseteq B$ are fields with $\alpha^p \in B$ for some prime $p$, and if $B(\alpha)$ contains no $p$th roots of unity not in $B$ unless a itself is a $p$th root of unity, then $\texttt{Gal}(E/B(\alpha))$ is a normal subgroup of $\texttt{Gal}(E/B)$ and $\texttt{Gal}(E/B)/\texttt{Gal}(E/B(\alpha))$ is abelian. Proof: By the homomorphism theorem for groups, it suffices to find a homomorphism of $\texttt{Gal}(E/B)$, with kernel $\texttt{Gal}(E/B(\alpha))$, into an abelian group (i.e., onto a subgroup of an abelian group, which of course is also abelian). The obvious map with kernel $\texttt{Gal}(E/B(\alpha))$ is restriction to $B(\alpha)$, $\lvert_{B(\alpha)}$, since by definition $$\sigma \in \texttt{Gal}(E/B(\alpha)) \Leftrightarrow \sigma \lvert_{B(\alpha)} \texttt{ is the identity map}.$$ The homomorphism property, $$\sigma' \sigma \lvert_{B(\alpha)}=\sigma'\lvert_{B(\alpha)} \sigma\lvert_{B(\alpha)}, \forall \sigma', \sigma \in \texttt{Gal}(E/B),$$ is automatic provided $\sigma \lvert_{B(\alpha)}(b) \in B(\alpha)$ for each $b \in B(\alpha)$, i.e. provided $B(\alpha)$ is closed under each $\sigma \in \texttt{Gal}(E/B)$. Since $\sigma$ fixes $B$, $\sigma \lvert_{B(\alpha)}$ is completely determined by the value $\sigma(\alpha)$. If $\alpha$ is a $p$th root of unity then $$(\sigma(\alpha))^p = \sigma(\alpha^p) = \sigma(\zeta^p) = \sigma(1) = 1,$$ hence $\sigma(\alpha) = \zeta^i= \alpha^i \in  B(\alpha)$, since each $p$th root of unity is some $\zeta^i$. If $\alpha$ is not a root of unity then $$ (\sigma(\alpha))^p = \sigma(\alpha^p) = \alpha^p \texttt{ since } \alpha^p \in B,$$ hence $\sigma(\alpha) = \zeta^ia$ for some $p$th root of unity $\zeta$; and $\zeta \in B$ by hypothesis, so a\texttt{Gal}in $\sigma(\alpha) \in B(\alpha)$. Thus $B(\alpha)$ is closed as required. This also implies that $I_{B(\alpha)}$ maps $\texttt{Gal}(E/B)$ into $\texttt{Gal}(B(\alpha)/B)$, so it now remains to check that $\texttt{Gal}(B(\alpha)/B)$ is abelian. If $\alpha$ is a root of unity then, as we have just seen, each $\sigma \lvert_{B(\alpha)} \in \texttt{Gal}(B(\alpha)/B)$ is of the form $\sigma_i$, where $\sigma_i(\alpha) = \alpha^i$, hence $$\sigma_i\sigma_j(\alpha) = \sigma_i(\alpha^j) = \alpha^{ij} = \sigma_j\sigma_i(\alpha).$$ Likewise, if $\alpha$ is not a root of unity then each $\sigma \lvert_{B(\alpha)} \in \texttt{Gal}(B(\alpha)/B)$ is of the form $\sigma_i$ where $\sigma_i(\alpha) = \zeta^i\alpha$, hence $$\sigma_i\sigma_j(\alpha) = \sigma_i(\zeta^j\alpha) = \zeta^{i+j}\alpha = \sigma_j\sigma_i(\alpha)$$ since $\zeta \in B$ and therefore $\zeta$ is fixed. Hence in either case $\texttt{Gal}(B(\alpha)/B)$ is abelian.","I'm reading Galois Theory for Beginners by John Stillwell. It's a good introduction, giving the essence of the idea with minimum algebra complexity. However, I'm a bit lost at his Theorem 2 (the details are at the end). The proof intend to find a homomorphism of $\texttt{Gal}(E/B)$, with kernel $\texttt{Gal}(E/B(\alpha))$, into an abelian group. John says: The obvious map with kernel $\texttt{Gal}(E/B(\alpha))$ is restriction   to $B(\alpha)$, $\lvert_{B(\alpha)}$, since by definition $$\sigma \in \texttt{Gal}(E/B(\alpha)) \Leftrightarrow \sigma \lvert_{B(\alpha)} \texttt{ is the  identity map}.$$ Why restriction to $B(\alpha)$ is a homomorphism from $\texttt{Gal}(E/B)$ to a group with kernel $\texttt{Gal}(E/B(\alpha))$? What does this ""restriction"" mean? Trying to understand it, I'm taking $B = \mathbb Q$, $\alpha = \zeta$, $B(\alpha) =\mathbb Q(\zeta)$, $E = \mathbb Q (\zeta, \sqrt{2})$,  where $\zeta^5 = 1$. So $$\texttt{Gal}(E/B(\alpha)) =  \texttt{Gal}(\mathbb Q(\zeta, \sqrt{2})/\mathbb Q(\zeta)), $$  in this example  it is $\begin{array}{c|cc}  \mathbb Q(\zeta, \sqrt{2})  & \sigma_1 & \sigma_2  \\  \hline \sqrt{2}  & \sqrt{2}  & -\sqrt{2}   \\  -\sqrt{2} & -\sqrt{2} & \sqrt{2}  \\  \zeta     & \zeta     & \zeta   \\  \zeta^2   & \zeta^2   & \zeta^2  \\ \zeta^3   & \zeta^3   & \zeta^3  \\ \zeta^4   & \zeta^4   & \zeta^4,   \end{array}$ so it's isomorphism to  $$S_2 = \{(1), (1,2)\}.$$ Then  $$\texttt{Gal}(E/B) = \texttt{Gal} (\mathbb Q(\zeta, \sqrt{2})/\mathbb Q),$$ in this example it is $\begin{array}{c|cccccccc}  \mathbb Q(\zeta, \sqrt{2})  & \sigma_1 & \sigma_2 & \sigma_3 & \sigma_4 & \sigma_5 & \sigma_6 & \sigma_7 & \sigma_8 \\  \hline \sqrt{2}  & \sqrt{2}  & \sqrt{2}  & \sqrt{2}  & \sqrt{2}  & -\sqrt{2} & -\sqrt{2}  & -\sqrt{2} & -\sqrt{2}\\  -\sqrt{2} & -\sqrt{2} & -\sqrt{2} & -\sqrt{2} & -\sqrt{2} & \sqrt{2} & \sqrt{2} & \sqrt{2} & \sqrt{2}\\  \zeta     & \zeta   & \zeta^2 & \zeta^3 & \zeta^4 & \zeta   & \zeta^2 & \zeta^3  & \zeta^4 \\  \zeta^2   & \zeta^2 & \zeta^4 & \zeta   & \zeta^3 & \zeta^2 & \zeta^4 & \zeta & \zeta^3 \\ \zeta^3   & \zeta^3 & \zeta   & \zeta^4 & \zeta^2 & \zeta^3 & \zeta   & \zeta^4 & \zeta^2 \\ \zeta^4   & \zeta^4 & \zeta^3 & \zeta^2 & \zeta   & \zeta^4 & \zeta^3 & \zeta^2 & \zeta, \end{array}$ so it's isomorphism to $$\{(1), (3,4,5,6), (3,5,6,4), (3,6)(4,5), (1,2), (1,2)(3,4,5,6), (1,2)(3,5,6,4), (1,2)(3,6)(4,5) \}.$$ My guess is, so that the ""restriction to $B(\alpha)$"" actually means a subset of $\texttt{Gal} (E/B)$ that only change elements in $B(\alpha)$, so itcan be defined as $$\Sigma := \{ \tau \in \texttt{Gal}(E/B) \lvert \tau(\beta) = \beta, \forall \beta \in E \setminus B(\alpha) \},$$ in this example $\begin{array}{c|c}  \mathbb Q(\zeta, \sqrt{2}) & A = f(\texttt{Gal}(\mathbb Q(\zeta, \sqrt{2})/\mathbb Q)) \\  \hline (1)              & (1) \\  (1,2)            & (1) \\  (3,4,6,5)        & (3,4,6,5) \\  (1,2)(3,4,6,5)   & (3,4,6,5) \\  (3,5,6,4)        & (3,5,6,4)   \\  (1,2)(3,5,6,4)   & (3,5,6,4) \\  (3,6)(4,5)       & (3,6)(4,5) \\  (1,2)(3,6)(4,5)  & (3,6)(4,5) \end{array}$ Is my understanding correct? -- Theorem 2 details -- Any radical extension $F(\alpha_1, \dots, \alpha_k)$ is the union of an ascending tower of fields $F=F_0 \subseteq F_1 \subseteq \cdots \subseteq F_k = F(\alpha_1, \dots, \alpha_k)$ where each $F_i = F_{i-1}(\alpha_i)$, $\alpha_i$ is the $p_i$-th rot of an element in $F_i{i-1}$, $p_i$ is prime, and $F_i$ contains no $p_i$-th roots of unity not in $F_i{i-1}$ unless $\alpha_i$ is itself a $p_i$-th root of unity. Theorem 2. If $E\supseteq B(\alpha) \supseteq B$ are fields with $\alpha^p \in B$ for some prime $p$, and if $B(\alpha)$ contains no $p$th roots of unity not in $B$ unless a itself is a $p$th root of unity, then $\texttt{Gal}(E/B(\alpha))$ is a normal subgroup of $\texttt{Gal}(E/B)$ and $\texttt{Gal}(E/B)/\texttt{Gal}(E/B(\alpha))$ is abelian. Proof: By the homomorphism theorem for groups, it suffices to find a homomorphism of $\texttt{Gal}(E/B)$, with kernel $\texttt{Gal}(E/B(\alpha))$, into an abelian group (i.e., onto a subgroup of an abelian group, which of course is also abelian). The obvious map with kernel $\texttt{Gal}(E/B(\alpha))$ is restriction to $B(\alpha)$, $\lvert_{B(\alpha)}$, since by definition $$\sigma \in \texttt{Gal}(E/B(\alpha)) \Leftrightarrow \sigma \lvert_{B(\alpha)} \texttt{ is the identity map}.$$ The homomorphism property, $$\sigma' \sigma \lvert_{B(\alpha)}=\sigma'\lvert_{B(\alpha)} \sigma\lvert_{B(\alpha)}, \forall \sigma', \sigma \in \texttt{Gal}(E/B),$$ is automatic provided $\sigma \lvert_{B(\alpha)}(b) \in B(\alpha)$ for each $b \in B(\alpha)$, i.e. provided $B(\alpha)$ is closed under each $\sigma \in \texttt{Gal}(E/B)$. Since $\sigma$ fixes $B$, $\sigma \lvert_{B(\alpha)}$ is completely determined by the value $\sigma(\alpha)$. If $\alpha$ is a $p$th root of unity then $$(\sigma(\alpha))^p = \sigma(\alpha^p) = \sigma(\zeta^p) = \sigma(1) = 1,$$ hence $\sigma(\alpha) = \zeta^i= \alpha^i \in  B(\alpha)$, since each $p$th root of unity is some $\zeta^i$. If $\alpha$ is not a root of unity then $$ (\sigma(\alpha))^p = \sigma(\alpha^p) = \alpha^p \texttt{ since } \alpha^p \in B,$$ hence $\sigma(\alpha) = \zeta^ia$ for some $p$th root of unity $\zeta$; and $\zeta \in B$ by hypothesis, so a\texttt{Gal}in $\sigma(\alpha) \in B(\alpha)$. Thus $B(\alpha)$ is closed as required. This also implies that $I_{B(\alpha)}$ maps $\texttt{Gal}(E/B)$ into $\texttt{Gal}(B(\alpha)/B)$, so it now remains to check that $\texttt{Gal}(B(\alpha)/B)$ is abelian. If $\alpha$ is a root of unity then, as we have just seen, each $\sigma \lvert_{B(\alpha)} \in \texttt{Gal}(B(\alpha)/B)$ is of the form $\sigma_i$, where $\sigma_i(\alpha) = \alpha^i$, hence $$\sigma_i\sigma_j(\alpha) = \sigma_i(\alpha^j) = \alpha^{ij} = \sigma_j\sigma_i(\alpha).$$ Likewise, if $\alpha$ is not a root of unity then each $\sigma \lvert_{B(\alpha)} \in \texttt{Gal}(B(\alpha)/B)$ is of the form $\sigma_i$ where $\sigma_i(\alpha) = \zeta^i\alpha$, hence $$\sigma_i\sigma_j(\alpha) = \sigma_i(\zeta^j\alpha) = \zeta^{i+j}\alpha = \sigma_j\sigma_i(\alpha)$$ since $\zeta \in B$ and therefore $\zeta$ is fixed. Hence in either case $\texttt{Gal}(B(\alpha)/B)$ is abelian.",,"['abstract-algebra', 'galois-theory', 'group-homomorphism']"
59,"In a group of order $pq^2$, if p divides $|Z(G)|$, then G is abelian","In a group of order , if p divides , then G is abelian",pq^2 |Z(G)|,"I want to prove that in a group of order $pq^2$, if $p$ divides $|Z(G)|$, then $G$ is abelian. I know that in this case, the order of $G/Z(G)$ must be $q^2$. If $G/Z(G)\simeq \mathbb{Z}/{q^2}\mathbb{Z}$, then we are done, because $\mathbb{Z}/{q^2}\mathbb{Z}$ is cyclic. But what happens if $G/Z(G)\simeq \mathbb{Z}/{q}\mathbb{Z}\times \mathbb{Z}/{q}\mathbb{Z}$? I think I'm missing something trivial..","I want to prove that in a group of order $pq^2$, if $p$ divides $|Z(G)|$, then $G$ is abelian. I know that in this case, the order of $G/Z(G)$ must be $q^2$. If $G/Z(G)\simeq \mathbb{Z}/{q^2}\mathbb{Z}$, then we are done, because $\mathbb{Z}/{q^2}\mathbb{Z}$ is cyclic. But what happens if $G/Z(G)\simeq \mathbb{Z}/{q}\mathbb{Z}\times \mathbb{Z}/{q}\mathbb{Z}$? I think I'm missing something trivial..",,"['abstract-algebra', 'group-theory', 'cyclic-groups']"
60,Question about right and left cosets.,Question about right and left cosets.,,"I want to do a question about how my algebraic structures professor defined left and right cosets. I'll write here his way to present them. We first talked about quotient group. Let $G$ be a group, $H\leq G$, and we want to build $G\ /\ H$. We look the particular case of $\mathbb{Z}\ /\ n\mathbb{Z}$ to make the generalization. After a little explanation of the last group, he defined two relations: $\sim$ and $\approx$: Let $G$ be a group. Let $H\leq G$. Let $g_1$ and $g_2$ $\in G$. We say that  \begin{equation} g_1\sim g_2\ \ \text{ if }\ \  g_1\ g_2^{-1}\in H, \end{equation} and \begin{equation} g_1\approx g_2\ \ \text{ if }\ \   g_2^{-1}g_1\ \in H. \end{equation} After that, we proved that they are equivalence relations, and then he defined the quotient groups on whom we were interested: \begin{equation} G\ / \sim\  =  G\ /\ H,\\ G\ / \approx\  = H\ \backslash\ G. \end{equation} We say that $G\ /\ H$ is the set of the right equivalence classes (I think that in english it's called right coset), and then $H\ \backslash\ G$ is the left coset. Now it comes the part that I don't understand: Let $g \in G\ /\ H$. The equivalence class of g is: \begin{equation} [g]=\{ g'\in\  G \mid  g' \sim g \}= \{ g' \in\ G \mid (g')^{-1} \in\ H\}=\{ g' \in\ G \mid g\in Hg \}= Hg \end{equation} The equivalence classes of the elements of $H\ \backslash\ G$ are similar. My question is: how he can say that \begin{equation} \{ g'\in\  G \mid  g' \sim g \}= \{ g' \in\ G \mid (g')^{-1} \in\ H\}? \end{equation} As far as I'm concerned, $\ g'\sim g \implies g'g^{-1} \in\ H$. He can say from this that $(g')^{-1}\! \in H$? Sorry about this long explanation, but I wanted you to know how my professor deduced these quotient groups, because I haven't seen it in any group theory book. I hope you understood it clearly, despite my english. Thank you!","I want to do a question about how my algebraic structures professor defined left and right cosets. I'll write here his way to present them. We first talked about quotient group. Let $G$ be a group, $H\leq G$, and we want to build $G\ /\ H$. We look the particular case of $\mathbb{Z}\ /\ n\mathbb{Z}$ to make the generalization. After a little explanation of the last group, he defined two relations: $\sim$ and $\approx$: Let $G$ be a group. Let $H\leq G$. Let $g_1$ and $g_2$ $\in G$. We say that  \begin{equation} g_1\sim g_2\ \ \text{ if }\ \  g_1\ g_2^{-1}\in H, \end{equation} and \begin{equation} g_1\approx g_2\ \ \text{ if }\ \   g_2^{-1}g_1\ \in H. \end{equation} After that, we proved that they are equivalence relations, and then he defined the quotient groups on whom we were interested: \begin{equation} G\ / \sim\  =  G\ /\ H,\\ G\ / \approx\  = H\ \backslash\ G. \end{equation} We say that $G\ /\ H$ is the set of the right equivalence classes (I think that in english it's called right coset), and then $H\ \backslash\ G$ is the left coset. Now it comes the part that I don't understand: Let $g \in G\ /\ H$. The equivalence class of g is: \begin{equation} [g]=\{ g'\in\  G \mid  g' \sim g \}= \{ g' \in\ G \mid (g')^{-1} \in\ H\}=\{ g' \in\ G \mid g\in Hg \}= Hg \end{equation} The equivalence classes of the elements of $H\ \backslash\ G$ are similar. My question is: how he can say that \begin{equation} \{ g'\in\  G \mid  g' \sim g \}= \{ g' \in\ G \mid (g')^{-1} \in\ H\}? \end{equation} As far as I'm concerned, $\ g'\sim g \implies g'g^{-1} \in\ H$. He can say from this that $(g')^{-1}\! \in H$? Sorry about this long explanation, but I wanted you to know how my professor deduced these quotient groups, because I haven't seen it in any group theory book. I hope you understood it clearly, despite my english. Thank you!",,"['abstract-algebra', 'group-theory', 'equivalence-relations']"
61,Gallian: is it true that the well-ordering principle can't be proven from properties of arithmetic?,Gallian: is it true that the well-ordering principle can't be proven from properties of arithmetic?,,"I just started reading Gallian's Abstract algebra and on page 3 it says ""An important property of the integers...is the so-called Well Ordering Principle. Since this property cannot be proved from the usual properties of arithmetic , we will take it as an axiom"". [my emphasis] My question is, how can one (in this case the author) be so sure that the Well Ordering Principle cannot be proved from the properties of arithmetic. Is it possible to prove statements like this (i.e. the one in italics above). If so, what would a proof look like?","I just started reading Gallian's Abstract algebra and on page 3 it says ""An important property of the integers...is the so-called Well Ordering Principle. Since this property cannot be proved from the usual properties of arithmetic , we will take it as an axiom"". [my emphasis] My question is, how can one (in this case the author) be so sure that the Well Ordering Principle cannot be proved from the properties of arithmetic. Is it possible to prove statements like this (i.e. the one in italics above). If so, what would a proof look like?",,"['abstract-algebra', 'reference-request', 'order-theory', 'natural-numbers']"
62,Determine whether an ideal is principal or not,Determine whether an ideal is principal or not,,"Let $I=\{a+b\sqrt{-3}: a+b \text{ even}\}$ be an ideal in $R=\mathbb{Z}[\sqrt{-3}]$. I want to determine whether $I$ is a principal ideal or not. I've been trying to work with the ideal $(2)$. I know that $(2)\subset I$, but $I$ is not in $(2)$ since $(2)$ does not contain elements of the form $(2a+1)+(2b+1)\sqrt{-3}$ even though $(2a+1)+(2b+1)=2a+2b+2$, which is even  and hence in $I$.  Any help on this would be appreciated.","Let $I=\{a+b\sqrt{-3}: a+b \text{ even}\}$ be an ideal in $R=\mathbb{Z}[\sqrt{-3}]$. I want to determine whether $I$ is a principal ideal or not. I've been trying to work with the ideal $(2)$. I know that $(2)\subset I$, but $I$ is not in $(2)$ since $(2)$ does not contain elements of the form $(2a+1)+(2b+1)\sqrt{-3}$ even though $(2a+1)+(2b+1)=2a+2b+2$, which is even  and hence in $I$.  Any help on this would be appreciated.",,"['abstract-algebra', 'ideals']"
63,"Let $a$ be an element of order $n$ in a group $G$. If $a^m$ has order $n$, then $m$ and $n$ are relatively prime.","Let  be an element of order  in a group . If  has order , then  and  are relatively prime.",a n G a^m n m n,"Let $a$ be an element of order $n$ in a group $G$ . If $a^m$ has order $n$ , then $m$ and $n$ are relatively prime. Assume $a^m$ has order $n$ and, $m$ and $n$ are not relatively prime.  Then $m$ and $n$ have a common factor, say $q$ . So, $m=m'q$ and $n=n'q$ . So, $$(a^m)^{n'}=(a^m)^\frac nq= (a^{mn})^\frac 1q= e^\frac 1q=e$$ So, $(a^m)^\frac nq=(a^m)^n=e$ . Since $a^m$ has order $n$ : $e \neq (a^m)^\frac nq = (a^m)^n$ . Contradiction.","Let be an element of order in a group . If has order , then and are relatively prime. Assume has order and, and are not relatively prime.  Then and have a common factor, say . So, and . So, So, . Since has order : . Contradiction.",a n G a^m n m n a^m n m n m n q m=m'q n=n'q (a^m)^{n'}=(a^m)^\frac nq= (a^{mn})^\frac 1q= e^\frac 1q=e (a^m)^\frac nq=(a^m)^n=e a^m n e \neq (a^m)^\frac nq = (a^m)^n,"['abstract-algebra', 'group-theory', 'finite-groups', 'proof-verification']"
64,"How do I show $[\mathbb{Q}(\sqrt{2},\sqrt{3}):\mathbb{Q}]\geq[\mathbb{Q}(\sqrt2):\mathbb{Q}][\mathbb{Q}(\sqrt3):\mathbb{Q}]$?",How do I show ?,"[\mathbb{Q}(\sqrt{2},\sqrt{3}):\mathbb{Q}]\geq[\mathbb{Q}(\sqrt2):\mathbb{Q}][\mathbb{Q}(\sqrt3):\mathbb{Q}]","I know how to show $[\mathbb{Q}(\sqrt{2},\sqrt{3}):\mathbb{Q}]\leq[\mathbb{Q}(\sqrt2):\mathbb{Q}][\mathbb{Q}(\sqrt3):\mathbb{Q}]$, but don't know how to show the converse inequality. $[\mathbb{Q}(\sqrt2):\mathbb{Q}]$ and $[\mathbb{Q}(\sqrt3):\mathbb{Q}] $ both divides $[\mathbb{Q}(\sqrt{2},\sqrt{3}):\mathbb{Q}]$, but they are not relatively prime, so I guess I can't the converse inequality this way. I'm considering using the fact that the intersection of $\mathbb{Q}(\sqrt2)$ and $\mathbb{Q}(\sqrt 3)$ is $\mathbb{Q}$, but I don't know how to proceed...","I know how to show $[\mathbb{Q}(\sqrt{2},\sqrt{3}):\mathbb{Q}]\leq[\mathbb{Q}(\sqrt2):\mathbb{Q}][\mathbb{Q}(\sqrt3):\mathbb{Q}]$, but don't know how to show the converse inequality. $[\mathbb{Q}(\sqrt2):\mathbb{Q}]$ and $[\mathbb{Q}(\sqrt3):\mathbb{Q}] $ both divides $[\mathbb{Q}(\sqrt{2},\sqrt{3}):\mathbb{Q}]$, but they are not relatively prime, so I guess I can't the converse inequality this way. I'm considering using the fact that the intersection of $\mathbb{Q}(\sqrt2)$ and $\mathbb{Q}(\sqrt 3)$ is $\mathbb{Q}$, but I don't know how to proceed...",,['abstract-algebra']
65,factoring $x^n+x+1$,factoring,x^n+x+1,Is there a way of factoring a polynomial of the general form $$x^n+x+1$$ in the ring $\mathbb C[x]$ or $\mathbb R[x]$ or $\mathbb Z [x]$ for any $n \in \mathbb N$? (Or perhaps with certain conditions on $n$?),Is there a way of factoring a polynomial of the general form $$x^n+x+1$$ in the ring $\mathbb C[x]$ or $\mathbb R[x]$ or $\mathbb Z [x]$ for any $n \in \mathbb N$? (Or perhaps with certain conditions on $n$?),,"['abstract-algebra', 'factoring', 'prime-factorization']"
66,What is the correct statement of the infinitary associativity law?,What is the correct statement of the infinitary associativity law?,,"Let $X$ denote a non-empty set. Write $\mathcal{L}$ for the class of all ordered pairs $(L,f)$ where: $L$ is a linear poset (possibly empty), and $f$ is an arbitrary function $L \rightarrow X.$ Then $\mathcal{L}$ forms a ""complete monoid."" What I mean by this is that firstly, we can take products of infinitely many elements. In particular, for any linear poset $I$ and any family $\lambda:I \rightarrow\mathcal{L}$, write $\prod_{i \in I} \lambda_i$ for the concatenation of all the $\lambda_i$'s in the order determined by $\lambda$ and $I$. Secondly, (possibly) infinite products clearly satisfy some kind of infinitary associativity law. It should be of the form: $$\prod_{i \in I}\prod_{j \in J(i)}(\lambda_i)_j = \prod_{\mathrm{something}}\mathrm{something}$$ Where: $I$ is an arbitrary linear poset $J(i)$ is a linear poset dependent on $i \in I$ $(\lambda_i)_j$ is an element of $\cal L$ dependent on $i \in I$ and $j \in J(i)$. Anyway, I'm having trouble writing down this law correctly. Question. What is the correct statement of the infinitary associativity law?","Let $X$ denote a non-empty set. Write $\mathcal{L}$ for the class of all ordered pairs $(L,f)$ where: $L$ is a linear poset (possibly empty), and $f$ is an arbitrary function $L \rightarrow X.$ Then $\mathcal{L}$ forms a ""complete monoid."" What I mean by this is that firstly, we can take products of infinitely many elements. In particular, for any linear poset $I$ and any family $\lambda:I \rightarrow\mathcal{L}$, write $\prod_{i \in I} \lambda_i$ for the concatenation of all the $\lambda_i$'s in the order determined by $\lambda$ and $I$. Secondly, (possibly) infinite products clearly satisfy some kind of infinitary associativity law. It should be of the form: $$\prod_{i \in I}\prod_{j \in J(i)}(\lambda_i)_j = \prod_{\mathrm{something}}\mathrm{something}$$ Where: $I$ is an arbitrary linear poset $J(i)$ is a linear poset dependent on $i \in I$ $(\lambda_i)_j$ is an element of $\cal L$ dependent on $i \in I$ and $j \in J(i)$. Anyway, I'm having trouble writing down this law correctly. Question. What is the correct statement of the infinitary associativity law?",,"['abstract-algebra', 'definition']"
67,Subgroups of Symmetric Group $S_4$ and Isomorphism,Subgroups of Symmetric Group  and Isomorphism,S_4,"During my Algebra class we were given this exercise to solve at home, but I couldn't find any solution and I also did not really get the one our teacher gave us. So, the text was: Given G = S 4 = Sym({1, 2, 3, 4}). Then: Is there a subgroup of G of order 5? Motivate your answer. Give and example of two subgroups H 1 and H 2 so that |H 1 | = |H 2 | and H 1 $\ncong$ H 2 (H 1 not isomorphic to H 2 ) Part 1 of the question is fairly simple in fact thanks to Lagrange Theorem on subgroups, but the problems arise with Part 2. The given solution is: Let's consider as an example: H 1 = { id, (1,2), (3,4), (1,2)(3,4) } H 2 = { id, (1,2)(3,4), (1,3)(2,4), (1,4)(2,3) } In fact, H 1 elements are all of order 2 (apart from id = identity ) while (1,2,3,4) $\in$ H 2 has order 4. Thus H 1 $\ncong$ H 2 ( H 1 not isomorphic with H 2 ) I've tried my best, but given the fact that our teacher sometimes is very messy I still can not figure out why this is a valid proof, nor the steps needed to find it. This is my first time posting, so sorry in advance for any mistake. Thank you for your time!","During my Algebra class we were given this exercise to solve at home, but I couldn't find any solution and I also did not really get the one our teacher gave us. So, the text was: Given G = S 4 = Sym({1, 2, 3, 4}). Then: Is there a subgroup of G of order 5? Motivate your answer. Give and example of two subgroups H 1 and H 2 so that |H 1 | = |H 2 | and H 1 $\ncong$ H 2 (H 1 not isomorphic to H 2 ) Part 1 of the question is fairly simple in fact thanks to Lagrange Theorem on subgroups, but the problems arise with Part 2. The given solution is: Let's consider as an example: H 1 = { id, (1,2), (3,4), (1,2)(3,4) } H 2 = { id, (1,2)(3,4), (1,3)(2,4), (1,4)(2,3) } In fact, H 1 elements are all of order 2 (apart from id = identity ) while (1,2,3,4) $\in$ H 2 has order 4. Thus H 1 $\ncong$ H 2 ( H 1 not isomorphic with H 2 ) I've tried my best, but given the fact that our teacher sometimes is very messy I still can not figure out why this is a valid proof, nor the steps needed to find it. This is my first time posting, so sorry in advance for any mistake. Thank you for your time!",,"['abstract-algebra', 'group-theory', 'symmetric-groups']"
68,Literature to the ring $\mathbb{Z}[\phi]$ where $\phi=\frac{1+\sqrt{5}}{2}$ is the golden ratio,Literature to the ring  where  is the golden ratio,\mathbb{Z}[\phi] \phi=\frac{1+\sqrt{5}}{2},"I know few about algebraic number theory but recently I stumbled upon the ring $\mathbb{Z}[\phi]$ where $\phi = \frac{1+\sqrt{5}}{2}$ is the golden ratio. It seems to be a very interesting object to study, so now I'm curious what is known about this ring. Is there some literature about it?","I know few about algebraic number theory but recently I stumbled upon the ring $\mathbb{Z}[\phi]$ where $\phi = \frac{1+\sqrt{5}}{2}$ is the golden ratio. It seems to be a very interesting object to study, so now I'm curious what is known about this ring. Is there some literature about it?",,"['abstract-algebra', 'reference-request', 'ring-theory', 'algebraic-number-theory', 'online-resources']"
69,Equations of the image of a curve with elimination theory,Equations of the image of a curve with elimination theory,,"I've been trying to solve the next problem but I can't complete the last step. The problem is: Considering the image of the circle $$V=\{  (x_1,x_2): x_1^2+x_2^2=1  \}$$ given by the map $$\rho: V \rightarrow \mathbb{A}^2(\mathbb{R})$$ $$(x_1,x_2) \longmapsto (\frac{x_1}{1+x_2^2}, \frac{x_1x_2}{1+x_2^2})$$ Compute the equations of the image. My attemp: The map $\rho$ is well defined over the open set $$U=\{(x_1,x_2)\in V: g=(1+x_2^2)(1+x_2^2) \neq 0\}=V$$ so we can take the affine variety $ Y:=\mathbb{A}^2(\mathbb{R})_g \subset  \mathbb{A}^3(\mathbb{R})$ given by $$Y:=\{(x_1,x_2,z):zg(x_1,x_2)-1=0\}=\{(x_1,x_2,z):z(1+x_2^2)^2-1=0\}$$ and a morphism $\phi: Y \rightarrow W $ such that $\phi(Y)= \rho(V)$. $$ $$ Calling $ \Gamma_\phi$ to the graph of $\phi$ in $ \mathbb{A}^3(\mathbb{R}) \times  \mathbb{A}^2(\mathbb{R})$, we have that: $$I(\Gamma_\phi)=\langle  z(1+x_2^2)^2-1, y_1-x_1 (1+x_2^2), y_2-x_1x_2(1+x_2^2)  \rangle$$ Now we have to compute a Grbner basis of that ideal and, after that, use elimination theory to quit all the expresions in that basis that depend on $x_1,x_2,z$. The remaining equations will be those asked in our problem. I've tried this last part many times but I always get all the equations depending on $x_1,x_2,z$. I'd really appreciate if someone could help me in this last part.  Thanks in advance.","I've been trying to solve the next problem but I can't complete the last step. The problem is: Considering the image of the circle $$V=\{  (x_1,x_2): x_1^2+x_2^2=1  \}$$ given by the map $$\rho: V \rightarrow \mathbb{A}^2(\mathbb{R})$$ $$(x_1,x_2) \longmapsto (\frac{x_1}{1+x_2^2}, \frac{x_1x_2}{1+x_2^2})$$ Compute the equations of the image. My attemp: The map $\rho$ is well defined over the open set $$U=\{(x_1,x_2)\in V: g=(1+x_2^2)(1+x_2^2) \neq 0\}=V$$ so we can take the affine variety $ Y:=\mathbb{A}^2(\mathbb{R})_g \subset  \mathbb{A}^3(\mathbb{R})$ given by $$Y:=\{(x_1,x_2,z):zg(x_1,x_2)-1=0\}=\{(x_1,x_2,z):z(1+x_2^2)^2-1=0\}$$ and a morphism $\phi: Y \rightarrow W $ such that $\phi(Y)= \rho(V)$. $$ $$ Calling $ \Gamma_\phi$ to the graph of $\phi$ in $ \mathbb{A}^3(\mathbb{R}) \times  \mathbb{A}^2(\mathbb{R})$, we have that: $$I(\Gamma_\phi)=\langle  z(1+x_2^2)^2-1, y_1-x_1 (1+x_2^2), y_2-x_1x_2(1+x_2^2)  \rangle$$ Now we have to compute a Grbner basis of that ideal and, after that, use elimination theory to quit all the expresions in that basis that depend on $x_1,x_2,z$. The remaining equations will be those asked in our problem. I've tried this last part many times but I always get all the equations depending on $x_1,x_2,z$. I'd really appreciate if someone could help me in this last part.  Thanks in advance.",,"['abstract-algebra', 'algebraic-geometry', 'commutative-algebra', 'proof-verification']"
70,"$S^{-1}(\mathbb{Z}[i])$, where $S=\{x\in \mathbb{Z}|5\nmid x\}$.",", where .",S^{-1}(\mathbb{Z}[i]) S=\{x\in \mathbb{Z}|5\nmid x\},"Let $S=\{x\in \mathbb{Z}|5\nmid x\}$. I would like to know all the prime ideals of $S^{-1}(\mathbb{Z}[i])$. My attempt: Since $S\subset \mathbb{Z}$, the given question can be rewritten as $(\mathbb{Z}[x]/(x^2+1))_{(5)}=\mathbb{Z}_{(5)}[x]/(x^2+1)=\mathbb{Z}_{(5)}[i]$. How do we determine how many prime ideals are there, and what they are?","Let $S=\{x\in \mathbb{Z}|5\nmid x\}$. I would like to know all the prime ideals of $S^{-1}(\mathbb{Z}[i])$. My attempt: Since $S\subset \mathbb{Z}$, the given question can be rewritten as $(\mathbb{Z}[x]/(x^2+1))_{(5)}=\mathbb{Z}_{(5)}[x]/(x^2+1)=\mathbb{Z}_{(5)}[i]$. How do we determine how many prime ideals are there, and what they are?",,['abstract-algebra']
71,Why is the polynomial $S(\vec{x})$ with coefficients obeying a constraint homogeneous?,Why is the polynomial  with coefficients obeying a constraint homogeneous?,S(\vec{x}),"I have recently been working on a problem to prove that a particular polynomial is in fact homogeneous. Although I have found out that this is true, I am curious to see whether there might be a deeper meaning to this, perhaps in algebra theory. Therefore, I will pose the problem here: Let $\{x_1,x_2,\cdots,x_N\}$ be a set of complex variables. We can write for a polynomial $S$ the following expansion $$ S(\vec{x})=\sum_{\vec{m}_\in D^N}d_{m_1,m_2,\cdots,m_N}(\vec{p})\prod_{j=1}^Nx_j^{m_j}, $$ where $\vec{p}=(p_1,p_2,\cdots,p_N)^T$ is complex and the hypercube $D^N$ is defined as $$ D^N=\{0,1,\cdots,N-1\}^N. $$ The allowed powers of each variable are thus $0,1,\cdots,N-1$. Now we impose the condition that $(x_i \partial_i -x_j \partial_j +i/2\kappa(p_i-p_j))S(\vec{x})$ should be divisible by $(x_i-x_j)$ for every $i,j$ satisfying $i\neq j$. By trying to divide out this term we get the following condition on the coefficients: for each $\beta,\rho\in \{1,2,\cdots,N\}$ where $\beta \neq \rho$,  $$ \sum_{l\in \mathbb{Z}}^*d_{m_1,\cdots,m_{\beta+l},\cdots,m_{\rho-l},\cdots,m_N}(\vec{p})\left(m_\beta-m_\rho +\frac{i}{2\kappa}(p_\beta-p_\rho) \right)=0, $$ where the star $*$ in the summation indicates that the summation runs over all $l\in \mathbb{Z}$ such that $0\leq m_\beta+l \leq N-1$ and $0\leq m_\rho-l \leq N-1$. Using this relation, prove that the polynomial $S$ is homogeneous of degree $\frac{N(N-1)}{2}$. This is equivalent to proving that if $\sum_{i=1}^Nm_i\neq \frac{N(N-1)}{2}$, then $d_{m_1,m_2,\cdots,m_N}(\vec{p})=0$. My own approach consisted in formulating an algorithm which rewrites the coefficient under consideration as a linear combination of coefficients which we are $0$. Consequently, I only showed that this algorithm terminated in a finite number of steps. However, for me this algorithm has no deep interpretation, while it would be very nice to understand the reason for this homogeneity. I would therefore very much like to know other approaches.","I have recently been working on a problem to prove that a particular polynomial is in fact homogeneous. Although I have found out that this is true, I am curious to see whether there might be a deeper meaning to this, perhaps in algebra theory. Therefore, I will pose the problem here: Let $\{x_1,x_2,\cdots,x_N\}$ be a set of complex variables. We can write for a polynomial $S$ the following expansion $$ S(\vec{x})=\sum_{\vec{m}_\in D^N}d_{m_1,m_2,\cdots,m_N}(\vec{p})\prod_{j=1}^Nx_j^{m_j}, $$ where $\vec{p}=(p_1,p_2,\cdots,p_N)^T$ is complex and the hypercube $D^N$ is defined as $$ D^N=\{0,1,\cdots,N-1\}^N. $$ The allowed powers of each variable are thus $0,1,\cdots,N-1$. Now we impose the condition that $(x_i \partial_i -x_j \partial_j +i/2\kappa(p_i-p_j))S(\vec{x})$ should be divisible by $(x_i-x_j)$ for every $i,j$ satisfying $i\neq j$. By trying to divide out this term we get the following condition on the coefficients: for each $\beta,\rho\in \{1,2,\cdots,N\}$ where $\beta \neq \rho$,  $$ \sum_{l\in \mathbb{Z}}^*d_{m_1,\cdots,m_{\beta+l},\cdots,m_{\rho-l},\cdots,m_N}(\vec{p})\left(m_\beta-m_\rho +\frac{i}{2\kappa}(p_\beta-p_\rho) \right)=0, $$ where the star $*$ in the summation indicates that the summation runs over all $l\in \mathbb{Z}$ such that $0\leq m_\beta+l \leq N-1$ and $0\leq m_\rho-l \leq N-1$. Using this relation, prove that the polynomial $S$ is homogeneous of degree $\frac{N(N-1)}{2}$. This is equivalent to proving that if $\sum_{i=1}^Nm_i\neq \frac{N(N-1)}{2}$, then $d_{m_1,m_2,\cdots,m_N}(\vec{p})=0$. My own approach consisted in formulating an algorithm which rewrites the coefficient under consideration as a linear combination of coefficients which we are $0$. Consequently, I only showed that this algorithm terminated in a finite number of steps. However, for me this algorithm has no deep interpretation, while it would be very nice to understand the reason for this homogeneity. I would therefore very much like to know other approaches.",,"['abstract-algebra', 'complex-analysis', 'polynomials']"
72,Finite abelian p-group and an element of maximal order,Finite abelian p-group and an element of maximal order,,"I'm studying for an exam and I'm having trouble understanding the proof given for the following statement: Suppose $G$ is a finite abelian $p$-group and $a \in G$ has maximum order, then there exists a subgroup $K \subseteq G$ such that: $<a>\ast$  $K$ $= G$ $<a> \cap$  $K$ $= \{e\}$ What I have written down seems disjoint, so I probably missed a few details from lecture.  Could anyone give me the proof, or a reference to one?  For reference, this particular proof started with choosing $b \in G/<a>$ of minimal order and showing that $<a> \cap <b> = \{e\}$ and $|b|=p$, but it already has lost me by that point. This was given near the beginning of the course: at that time, we only knew the Chinese Remainder theorem and that, given a finite abelian $G$ such that $\forall x \in G$, $x^{nm} = e$ with $\operatorname{gcd}(m,n) = 1$, if we define $G_n = \{x \in G : x^n = e\}$ and $G_m = \{x \in G : x^m = e\}$, we have that $G \cong G_n \times G_m$","I'm studying for an exam and I'm having trouble understanding the proof given for the following statement: Suppose $G$ is a finite abelian $p$-group and $a \in G$ has maximum order, then there exists a subgroup $K \subseteq G$ such that: $<a>\ast$  $K$ $= G$ $<a> \cap$  $K$ $= \{e\}$ What I have written down seems disjoint, so I probably missed a few details from lecture.  Could anyone give me the proof, or a reference to one?  For reference, this particular proof started with choosing $b \in G/<a>$ of minimal order and showing that $<a> \cap <b> = \{e\}$ and $|b|=p$, but it already has lost me by that point. This was given near the beginning of the course: at that time, we only knew the Chinese Remainder theorem and that, given a finite abelian $G$ such that $\forall x \in G$, $x^{nm} = e$ with $\operatorname{gcd}(m,n) = 1$, if we define $G_n = \{x \in G : x^n = e\}$ and $G_m = \{x \in G : x^m = e\}$, we have that $G \cong G_n \times G_m$",,"['abstract-algebra', 'group-theory', 'finite-groups', 'abelian-groups']"
73,Abstract Algebra Proof Help,Abstract Algebra Proof Help,,"Let $G$ be a group. Prove that each element of $G$ appears exactly once in each column and exactly once in each row of the multiplication table for $G$. Proof: Suppose some $a \in G$ appears twice in some column of the multiplication table. Then for some $b \in G$, the equation $xb = a$ has at least two solutions, say $c$ and $d$. So $cb = a = db$. Since there is some $f \in G$ such that $bf = e$, then $c = ce = cbf = dbf = de = d$. Thus this is a contradiction. Suppose some $a \in G$ appears twice in some row of the multiplication table. Then some $b \in G$ where $bx = a$ has at least two solutions, $c$ and $d$. So $bc = a = bd$. Then there is an $f \in G$ such that $fb = e$, so $c = ec = fbc = fbd = ed = d$. Thus this is a contradiction.","Let $G$ be a group. Prove that each element of $G$ appears exactly once in each column and exactly once in each row of the multiplication table for $G$. Proof: Suppose some $a \in G$ appears twice in some column of the multiplication table. Then for some $b \in G$, the equation $xb = a$ has at least two solutions, say $c$ and $d$. So $cb = a = db$. Since there is some $f \in G$ such that $bf = e$, then $c = ce = cbf = dbf = de = d$. Thus this is a contradiction. Suppose some $a \in G$ appears twice in some row of the multiplication table. Then some $b \in G$ where $bx = a$ has at least two solutions, $c$ and $d$. So $bc = a = bd$. Then there is an $f \in G$ such that $fb = e$, so $c = ec = fbc = fbd = ed = d$. Thus this is a contradiction.",,"['abstract-algebra', 'group-theory', 'proof-verification']"
74,Homogenous polynomial and partial derivatives,Homogenous polynomial and partial derivatives,,"I'm struggling to understand this part in a book I'm reading: Let $F$ be a projective curve of degree $d$ with $P\in F$. Wlog,   suppose $P=(a:b:1)$. Let's look the affine chart $(a,b)\mapsto  (a,b,1)$. Let $f$ be the deshomogenization of $F$, we can write $f$ in this way: (WHY?) $$f=F(x,y,1)=f_1(x-a,y-b)+\ldots +f_d(x-a,y-b)$$ Where $f_l$ is a homogeneous polynomial of degree $l$ and we have (WHY?) $$f_l=\sum_{i+j=l}\frac{1}{i!j!}\frac{\partial^lf}{\partial^ix\partial^jy}x^iy^j$$ I know this should be a silly question, but I'm a beginner in this subject and I really need help, if anyone could help me I would be grateful. Thanks EDIT I'm thinking about Taylor's formula, but The formula of the post doesn't match with the Taylor's  one of several variables, see for example this link , maybe there is some mistake in the formula of my post?","I'm struggling to understand this part in a book I'm reading: Let $F$ be a projective curve of degree $d$ with $P\in F$. Wlog,   suppose $P=(a:b:1)$. Let's look the affine chart $(a,b)\mapsto  (a,b,1)$. Let $f$ be the deshomogenization of $F$, we can write $f$ in this way: (WHY?) $$f=F(x,y,1)=f_1(x-a,y-b)+\ldots +f_d(x-a,y-b)$$ Where $f_l$ is a homogeneous polynomial of degree $l$ and we have (WHY?) $$f_l=\sum_{i+j=l}\frac{1}{i!j!}\frac{\partial^lf}{\partial^ix\partial^jy}x^iy^j$$ I know this should be a silly question, but I'm a beginner in this subject and I really need help, if anyone could help me I would be grateful. Thanks EDIT I'm thinking about Taylor's formula, but The formula of the post doesn't match with the Taylor's  one of several variables, see for example this link , maybe there is some mistake in the formula of my post?",,"['abstract-algebra', 'algebraic-geometry', 'algebraic-curves']"
75,Geometric Proof that $\mathbb{Z}[\sqrt{-3}]$ is non-Euclidean,Geometric Proof that  is non-Euclidean,\mathbb{Z}[\sqrt{-3}],"Is there a geometric proof showing that $\mathbb{Z}[\sqrt{-3}]$ is non-Euclidean? I think this is a sketch of how to proceed. Consider the elliptical region $x^2+3y^2<1$. We can then partition the plane into unit squares -- four of which contain parts of our region. Now, can we translate these pieces on top of a single unit square and examine what points are not covered by some new translated part of the ellipse? Using this, can we find elements of $\mathbb{Z}[\sqrt{-3}]$ such that the division algorithm is invalid? I'm not really sure how to approach this; any help is greatly appreciated.","Is there a geometric proof showing that $\mathbb{Z}[\sqrt{-3}]$ is non-Euclidean? I think this is a sketch of how to proceed. Consider the elliptical region $x^2+3y^2<1$. We can then partition the plane into unit squares -- four of which contain parts of our region. Now, can we translate these pieces on top of a single unit square and examine what points are not covered by some new translated part of the ellipse? Using this, can we find elements of $\mathbb{Z}[\sqrt{-3}]$ such that the division algorithm is invalid? I'm not really sure how to approach this; any help is greatly appreciated.",,"['abstract-algebra', 'number-theory']"
76,An equivalent definition of GROUPS,An equivalent definition of GROUPS,,"Let $G$ be a nonempty set together a binary operation $\cdot$. I wonder why the following two statements are equivalent: a. $(G,\cdot)$ is a group. b. There is a function $T : G \longrightarrow G$ such that for any $a,b,c,d,f \in G$ if $(a\cdot b)\cdot c = (a\cdot d)\cdot f$ then $b = d\cdot(f\cdot T(c))$. It is clear that we have a. $\Longrightarrow$ b. Just take $T(c) = c^{-1}$. But how about the converse?","Let $G$ be a nonempty set together a binary operation $\cdot$. I wonder why the following two statements are equivalent: a. $(G,\cdot)$ is a group. b. There is a function $T : G \longrightarrow G$ such that for any $a,b,c,d,f \in G$ if $(a\cdot b)\cdot c = (a\cdot d)\cdot f$ then $b = d\cdot(f\cdot T(c))$. It is clear that we have a. $\Longrightarrow$ b. Just take $T(c) = c^{-1}$. But how about the converse?",,"['abstract-algebra', 'group-theory']"
77,"Let G be a group of order $n$, where $n$ is a positive integer relatively prime to $\varphi(n)$. Show that G is cyclic.","Let G be a group of order , where  is a positive integer relatively prime to . Show that G is cyclic.",n n \varphi(n),"Let G be a group of order $n$, where $n$ is a positive integer relatively prime to $\varphi(n)$. Show that G is cyclic. You may only assume the Feit-Thompson theorem here and prove in the following way: (1) $n$ is a product of odd prime numbers and squarefree. (2) Then $G$ is solvable. Show that it has a cyclic quotient of prime order, that is there is a an epimorphism $G\to H$with $H$ cyclic of prime order. Let $N$ be the kernel. (Hint: using composition series) (3)Show that $G\cong N \times H$ and then prove $G$ is abelian. (4)Show that $G$ is cyclic. I have proved (1) but get stuck at step 2. Is there any help? Thanks.","Let G be a group of order $n$, where $n$ is a positive integer relatively prime to $\varphi(n)$. Show that G is cyclic. You may only assume the Feit-Thompson theorem here and prove in the following way: (1) $n$ is a product of odd prime numbers and squarefree. (2) Then $G$ is solvable. Show that it has a cyclic quotient of prime order, that is there is a an epimorphism $G\to H$with $H$ cyclic of prime order. Let $N$ be the kernel. (Hint: using composition series) (3)Show that $G\cong N \times H$ and then prove $G$ is abelian. (4)Show that $G$ is cyclic. I have proved (1) but get stuck at step 2. Is there any help? Thanks.",,"['abstract-algebra', 'group-theory', 'abelian-groups', 'cyclic-groups']"
78,Hamilton's three dimensional algebra,Hamilton's three dimensional algebra,,"The popular story of the discovery of the quaternions goes very roughly as follows. William Rowan Hamilton has interested in the construction of an algebra of triplets that would in some ways be analogous to the complex numbers. He eventually realized this can not be done, but that one can construct such an algebra for $4$-tuples thereby creating the quaternions. My questions are: What are the properties that Hamilton desired this algebra of triplets would have? Why was or would it be desirable to have such an algebra? Why can't it be done? I'd appreciate any sources or answers to these questions.","The popular story of the discovery of the quaternions goes very roughly as follows. William Rowan Hamilton has interested in the construction of an algebra of triplets that would in some ways be analogous to the complex numbers. He eventually realized this can not be done, but that one can construct such an algebra for $4$-tuples thereby creating the quaternions. My questions are: What are the properties that Hamilton desired this algebra of triplets would have? Why was or would it be desirable to have such an algebra? Why can't it be done? I'd appreciate any sources or answers to these questions.",,"['abstract-algebra', 'reference-request', 'math-history']"
79,A (probably) wrong exercise from Morandi's Field and Galois theory,A (probably) wrong exercise from Morandi's Field and Galois theory,,"After some efforts I realize that the following exercise is wrong: (rings are unitary throughout the book) Morandi's Field and Galois Theory, Appendix A, exercise 18 (b) Let $A\subseteq B$ be commutative rings, suppose that there's a subset $S$ of $A$ that is closed under multiplication, every element of $S$ is a unit in $B$, and $B=\{a/s\colon a\in A,s\in S\}$. If $a\in A-S$, show that $aB\cap A=aA$. We write $B=A_S$ when $B$ is of this form. The next exercise is: (c) Let $A\subseteq B$, and suppose that there's a set $S$ as in Problem 18b with $B=A_S$. If $P$ is a prime ideal of $A$ with $P\cap S=\emptyset$, show that $PB$ is a prime ideal of $B$ and that $PB\cap A=P$. Exercise 18b is wrong. Let $A=\mathbb Z$, and $S=\{2^n\colon n\in\mathbb Z_{\ge0}\}$, then $B=\{m/2^n\colon m\in\mathbb Z,n\in\mathbb Z_{\ge0}\}$. Set $a=6$, then $aB\cap A=3\mathbb Z$, not $6A$. The preceding paragraph says that some of these parts are standard facts of localization . I believe that there's some typo in 18b, and 18c should be right. I have no idea on the topic of localization, so I don't know how to modify it to a true statement. Any idea? Thanks!","After some efforts I realize that the following exercise is wrong: (rings are unitary throughout the book) Morandi's Field and Galois Theory, Appendix A, exercise 18 (b) Let $A\subseteq B$ be commutative rings, suppose that there's a subset $S$ of $A$ that is closed under multiplication, every element of $S$ is a unit in $B$, and $B=\{a/s\colon a\in A,s\in S\}$. If $a\in A-S$, show that $aB\cap A=aA$. We write $B=A_S$ when $B$ is of this form. The next exercise is: (c) Let $A\subseteq B$, and suppose that there's a set $S$ as in Problem 18b with $B=A_S$. If $P$ is a prime ideal of $A$ with $P\cap S=\emptyset$, show that $PB$ is a prime ideal of $B$ and that $PB\cap A=P$. Exercise 18b is wrong. Let $A=\mathbb Z$, and $S=\{2^n\colon n\in\mathbb Z_{\ge0}\}$, then $B=\{m/2^n\colon m\in\mathbb Z,n\in\mathbb Z_{\ge0}\}$. Set $a=6$, then $aB\cap A=3\mathbb Z$, not $6A$. The preceding paragraph says that some of these parts are standard facts of localization . I believe that there's some typo in 18b, and 18c should be right. I have no idea on the topic of localization, so I don't know how to modify it to a true statement. Any idea? Thanks!",,"['abstract-algebra', 'commutative-algebra', 'ring-theory', 'ideals']"
80,Classification of isometries of a regular polygon,Classification of isometries of a regular polygon,,"A dihedral group is the group of symmetries of a regular polygon, including both rotations and reflections. Here comes my question : How can I show that rotations and reflections are the only symmetries of a regular polygon? I have found no proof for such a statement when the dihedral groups are introduced in lots of textbooks. It might be a starting point to show first that an isometry (symmetry) on a regular polygon maps the vertices to vertices and then the center must be a fixed point of the isometry. But I get stuck with showing that reflections are the only possible isometries besides the rotations.","A dihedral group is the group of symmetries of a regular polygon, including both rotations and reflections. Here comes my question : How can I show that rotations and reflections are the only symmetries of a regular polygon? I have found no proof for such a statement when the dihedral groups are introduced in lots of textbooks. It might be a starting point to show first that an isometry (symmetry) on a regular polygon maps the vertices to vertices and then the center must be a fixed point of the isometry. But I get stuck with showing that reflections are the only possible isometries besides the rotations.",,['abstract-algebra']
81,Order of elements in cyclic groups...,Order of elements in cyclic groups...,,"Let $G$ be a cyclic group of order $n$. Suppose $x$, $y$ are two elements of order $d$, where $d$ divides $n$. Show that $y = x^m$, where $m$ is an integer coprime to $n$. I know $y=x^m$ since the subgroups generated by $x$ and $y$ must be identical. I do not know how to show the coprimeness, however.","Let $G$ be a cyclic group of order $n$. Suppose $x$, $y$ are two elements of order $d$, where $d$ divides $n$. Show that $y = x^m$, where $m$ is an integer coprime to $n$. I know $y=x^m$ since the subgroups generated by $x$ and $y$ must be identical. I do not know how to show the coprimeness, however.",,['abstract-algebra']
82,Let $f(x)=x^8-16$. Determine the Galois group of the splitting field of $f(x)$ over the fields $\Bbb{Q}$ and $\Bbb{Z}_{17}$.,Let . Determine the Galois group of the splitting field of  over the fields  and .,f(x)=x^8-16 f(x) \Bbb{Q} \Bbb{Z}_{17},"Let $f(x)=x^8-16$ . Determine the Galois group of the splitting field of $f(x)$ over the field $K$ in each case. a) $K=\Bbb{Q}$ b) $K=\Bbb{F}_{17}$ . a) The roots of $f(x)$ are $\alpha$ , $\alpha\omega$ , $\alpha\omega^2$ , ... , $\alpha\omega^7$ where $\alpha=16^{1/8} = (2^4)^{1/8} = 2^{1/2}$ and $\omega$ is the $8$ th primitive root of unity. First we need to find the degree of the extension since it is equal to the order of the Galois group. We have $$[\Bbb{Q}(\alpha,\omega):\Bbb{Q}]=[\Bbb{Q}(\alpha,\omega):\Bbb{Q}(\omega)][\Bbb{Q}(\omega):\Bbb{Q}],$$ where $[\Bbb{Q}(\omega):\Bbb{Q}]=\Psi_8(x)$ , where $\Psi_k(x)$ is the $k$ th cyclotomic polynomial. We know that $$x^8-1 = \Psi_1(x)\Psi_2(x)\Psi_4(x)\Psi_8(x)$$ $$\implies x^8-1 = (x-1)(x+1)(x^2+1)\Psi_8(x)$$ $$\implies \Psi_8(x)=x^4+1$$ Since cyclotomic polynomials are irreducible over $\Bbb{Q}$ , we know that $[\Bbb{Q}(\omega):\Bbb{Q}]=4$ . Now we need to find $[\Bbb{Q}(\omega,\alpha):\Bbb{Q}(\omega)]$ . Since $\alpha$ is a root of $x^8-16$ , the minimal polynomial must be a divisor of it. We have $x^8-16 = (x^2-2)(x^2+2)(x^4+4)$ . Here, we can see that $\alpha$ is a root of $x^2-2$ , so we just need to check if $x^2-2$ is reducible. But $x^2-2=(x-\sqrt{2})(x+\sqrt{2})$ , and we know that $\sqrt{2} \not\in \Bbb{Q}(\omega)$ since it is irrational. So $[\Bbb{Q}(\omega,\alpha):\Bbb{Q}(\omega)]=2 \implies [K:\Bbb{Q}]=8$ There are five groups of order 8 up to isomorphism: $\bullet \Bbb{Z}_8$ $\bullet \Bbb{Z}_4 \times \Bbb{Z}_2$ $\bullet \Bbb{Z}_2 \times \Bbb{Z}_2 \times \Bbb{Z}_2$ $\bullet D_8$ $\bullet Q_8$ Since $x^8-16 = (x^2-2)(x^2+2)(x^4+4)$ , the automorphisms are $$\sigma_1: \alpha \rightarrow -\alpha$$ $$\sigma_2: \alpha\omega^2 \rightarrow \alpha\omega^6$$ $$\sigma_3: \alpha\omega \rightarrow \alpha\omega^3$$ $$\sigma_4: \alpha\omega \rightarrow \alpha\omega^5$$ $$\sigma_5: \alpha\omega \rightarrow \alpha\omega^7$$ $$\sigma_6: \alpha\omega^3 \rightarrow \alpha\omega^5$$ $$\sigma_7: \alpha\omega^3 \rightarrow \alpha\omega^7$$ $$\sigma_8: \alpha\omega^5 \rightarrow \alpha\omega^7$$ I guess I can tell which group of order 8 this is isomrophic to by direct computation, but I was kind of confused...for example, let's say I want to check if $\sigma_3\sigma_2(\sigma\omega) = \sigma_2\sigma_3(\alpha\omega)$ . But $\sigma_2$ takes $\sigma\omega^2$ to $\alpha\omega^6$ . But we don't have $\alpha\omega^2$ , we have $\alpha\omega$ . If we just raise it to the 3rd power, then what's the difference between $\sigma_2$ and $\sigma_3$ ? So that doesn't really make sense to me... Also is there an easier way find out which group it's isomorphic to without actually having to directly go through all the elements and subgroups of the Galois group? b) As in part a) we hav $$[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}]=[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}(\omega)][\Bbb{F}_{17}(\omega):\Bbb{F}_{17}].$$ So, again, we need to check if $\Psi_8(x) = x^4+1$ is irreducible in $\Bbb{F}_{17}$ . In other words, since $x^4+1=0 \implies x^4=-1 \implies x^8=1$ , we need to check if there are elements of order 8 in $\Bbb{F}_{17}$ . We know that the multiplicative group of $\Bbb{F}_{17}$ is cyclic of order $16$ . So we have a cyclic subgroup of order 8 $\implies$ the minimal polynomial of $\omega$ over $\Bbb{F}_{17}$ is of degree 1 $\implies$ $[\Bbb{F}_{17}(\omega):\Bbb{F}_{17}]=1$ . For $[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}(\omega)]$ , we get the same polynomial as we did for part a), which is not reducible since $x^2-2=(x-\sqrt{2})(x+\sqrt{2})$ and $\sqrt{2} \notin\Bbb{F}_{17}$ . So $[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}]=2$ , implying that the Galois group is isomorphic to a cyclic group of order 2. Is my answer for part b), correct? Thanks in advance","Let . Determine the Galois group of the splitting field of over the field in each case. a) b) . a) The roots of are , , , ... , where and is the th primitive root of unity. First we need to find the degree of the extension since it is equal to the order of the Galois group. We have where , where is the th cyclotomic polynomial. We know that Since cyclotomic polynomials are irreducible over , we know that . Now we need to find . Since is a root of , the minimal polynomial must be a divisor of it. We have . Here, we can see that is a root of , so we just need to check if is reducible. But , and we know that since it is irrational. So There are five groups of order 8 up to isomorphism: Since , the automorphisms are I guess I can tell which group of order 8 this is isomrophic to by direct computation, but I was kind of confused...for example, let's say I want to check if . But takes to . But we don't have , we have . If we just raise it to the 3rd power, then what's the difference between and ? So that doesn't really make sense to me... Also is there an easier way find out which group it's isomorphic to without actually having to directly go through all the elements and subgroups of the Galois group? b) As in part a) we hav So, again, we need to check if is irreducible in . In other words, since , we need to check if there are elements of order 8 in . We know that the multiplicative group of is cyclic of order . So we have a cyclic subgroup of order 8 the minimal polynomial of over is of degree 1 . For , we get the same polynomial as we did for part a), which is not reducible since and . So , implying that the Galois group is isomorphic to a cyclic group of order 2. Is my answer for part b), correct? Thanks in advance","f(x)=x^8-16 f(x) K K=\Bbb{Q} K=\Bbb{F}_{17} f(x) \alpha \alpha\omega \alpha\omega^2 \alpha\omega^7 \alpha=16^{1/8} = (2^4)^{1/8} = 2^{1/2} \omega 8 [\Bbb{Q}(\alpha,\omega):\Bbb{Q}]=[\Bbb{Q}(\alpha,\omega):\Bbb{Q}(\omega)][\Bbb{Q}(\omega):\Bbb{Q}], [\Bbb{Q}(\omega):\Bbb{Q}]=\Psi_8(x) \Psi_k(x) k x^8-1 = \Psi_1(x)\Psi_2(x)\Psi_4(x)\Psi_8(x) \implies x^8-1 = (x-1)(x+1)(x^2+1)\Psi_8(x) \implies \Psi_8(x)=x^4+1 \Bbb{Q} [\Bbb{Q}(\omega):\Bbb{Q}]=4 [\Bbb{Q}(\omega,\alpha):\Bbb{Q}(\omega)] \alpha x^8-16 x^8-16 = (x^2-2)(x^2+2)(x^4+4) \alpha x^2-2 x^2-2 x^2-2=(x-\sqrt{2})(x+\sqrt{2}) \sqrt{2} \not\in \Bbb{Q}(\omega) [\Bbb{Q}(\omega,\alpha):\Bbb{Q}(\omega)]=2 \implies [K:\Bbb{Q}]=8 \bullet \Bbb{Z}_8 \bullet \Bbb{Z}_4 \times \Bbb{Z}_2 \bullet \Bbb{Z}_2 \times \Bbb{Z}_2 \times \Bbb{Z}_2 \bullet D_8 \bullet Q_8 x^8-16 = (x^2-2)(x^2+2)(x^4+4) \sigma_1: \alpha \rightarrow -\alpha \sigma_2: \alpha\omega^2 \rightarrow \alpha\omega^6 \sigma_3: \alpha\omega \rightarrow \alpha\omega^3 \sigma_4: \alpha\omega \rightarrow \alpha\omega^5 \sigma_5: \alpha\omega \rightarrow \alpha\omega^7 \sigma_6: \alpha\omega^3 \rightarrow \alpha\omega^5 \sigma_7: \alpha\omega^3 \rightarrow \alpha\omega^7 \sigma_8: \alpha\omega^5 \rightarrow \alpha\omega^7 \sigma_3\sigma_2(\sigma\omega) = \sigma_2\sigma_3(\alpha\omega) \sigma_2 \sigma\omega^2 \alpha\omega^6 \alpha\omega^2 \alpha\omega \sigma_2 \sigma_3 [\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}]=[\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}(\omega)][\Bbb{F}_{17}(\omega):\Bbb{F}_{17}]. \Psi_8(x) = x^4+1 \Bbb{F}_{17} x^4+1=0 \implies x^4=-1 \implies x^8=1 \Bbb{F}_{17} \Bbb{F}_{17} 16 \implies \omega \Bbb{F}_{17} \implies [\Bbb{F}_{17}(\omega):\Bbb{F}_{17}]=1 [\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}(\omega)] x^2-2=(x-\sqrt{2})(x+\sqrt{2}) \sqrt{2} \notin\Bbb{F}_{17} [\Bbb{F}_{17}(\alpha,\omega):\Bbb{F}_{17}]=2","['abstract-algebra', 'number-theory']"
83,On composition of polynomials,On composition of polynomials,,"Given two irreducible polynomials $f_{u}(x),f_{r}(x) \in \Bbb Q[x]$, can one find two polynomials or rational functions $h_{u}(x),h_{r}(x) \in \Bbb Q[x]$ or $\Bbb Q(x)$ respectively such that:$$f_{u}(h_{u}(x)) = f_{r}(h_{r}(x))?$$","Given two irreducible polynomials $f_{u}(x),f_{r}(x) \in \Bbb Q[x]$, can one find two polynomials or rational functions $h_{u}(x),h_{r}(x) \in \Bbb Q[x]$ or $\Bbb Q(x)$ respectively such that:$$f_{u}(h_{u}(x)) = f_{r}(h_{r}(x))?$$",,"['abstract-algebra', 'polynomials', 'irreducible-polynomials']"
84,"Compute $\operatorname{Tor}_n^R(I,R/I)$",Compute,"\operatorname{Tor}_n^R(I,R/I)","The problem is as follows: Let $I=\langle x^2,y\rangle\subset R=\mathbb{Q}[x,y]$. Compute $\operatorname{Tor}_n^R(I,R/I)$ for all $n\geq 0$. Thoughts: Usually when I see these types of problems, I consider a SES of the form(s): $0\rightarrow I\rightarrow R\rightarrow R/I\rightarrow 0$ or $0\rightarrow R\rightarrow R\rightarrow R/I\rightarrow 0$ where the first map in the last SES would be multiplication by an appropriate factor. The first SES does not seem promising in our case, since it boils down to computing $\operatorname{Tor}_n^R(I,I)$, which I don't see any immediate ways of doing. To use the second SES I was thinking of letting $f:R\rightarrow R$ be such that $x\rightarrow x^2$ and $y\rightarrow y$. I'm not sure if this would work?","The problem is as follows: Let $I=\langle x^2,y\rangle\subset R=\mathbb{Q}[x,y]$. Compute $\operatorname{Tor}_n^R(I,R/I)$ for all $n\geq 0$. Thoughts: Usually when I see these types of problems, I consider a SES of the form(s): $0\rightarrow I\rightarrow R\rightarrow R/I\rightarrow 0$ or $0\rightarrow R\rightarrow R\rightarrow R/I\rightarrow 0$ where the first map in the last SES would be multiplication by an appropriate factor. The first SES does not seem promising in our case, since it boils down to computing $\operatorname{Tor}_n^R(I,I)$, which I don't see any immediate ways of doing. To use the second SES I was thinking of letting $f:R\rightarrow R$ be such that $x\rightarrow x^2$ and $y\rightarrow y$. I'm not sure if this would work?",,"['abstract-algebra', 'homological-algebra']"
85,Galois group of $x^6-5$ over $\Bbb{Q}$.,Galois group of  over .,x^6-5 \Bbb{Q},"Let $K$ be the splitting field of $x^6-5$ over $\Bbb{Q}$ , (a) Let $\omega_6$ be a primitive sixth root of unity over $\Bbb{Q}$ . Compute the  Galois group of $K$ over $\Bbb{Q}(\omega_6)$ . (b) Compute the Galois group of $K$ over $\Bbb{Q}$ . (a) Let $\alpha = 5^{1/6}$ . We know that the roots of $x^6-5$ are $\alpha$ , $\alpha\omega_6$ , $\alpha\omega_6^2$ , $\alpha\omega_6^3$ , $\alpha\omega_6^4$ , and $\alpha\omega_6^5$ . Since $x^6-5$ is irreducible over $\Bbb{Q}$ by Eisenstein's criteria, $[\Bbb{Q}(\alpha, \omega_6):\Bbb{Q}] \leq 6$ . We also know that $$[\Bbb{Q}(\alpha, \omega_6):\Bbb{Q}]=[\Bbb{Q}(\alpha,\omega_6):\Bbb{Q}(\omega_6)][\Bbb{Q}(\omega_6):\Bbb{Q})].$$ Since $[\Bbb{Q}(\omega_6):\Bbb{Q}]=\phi(6)=(3-1)(2-1)=2$ , $[\Bbb{Q}(\alpha,\omega_6):\Bbb{Q}(\omega_6)]=1$ or $3$ . But since $\alpha \not\in \Bbb{Q}(\omega_6)$ , it must be of degree 3. So $[\Bbb{Q}(\alpha,\omega_6):\Bbb{Q}(\omega_6)] = |Gal(\Bbb{Q}(\alpha,\omega_6)/\Bbb{Q}(\omega_6))|=3$ . Since there is only one group of order 3 up to isomorphism, $Gal(\Bbb{Q}(\alpha,\omega_6)/\Bbb{Q}(\omega_6)) \cong \Bbb{Z}_3$ . (b) We know that $|Gal(K/\Bbb{Q})|=6$ , and there are only two groups of order 6 up to isomorphism, $\Bbb{Z}_6$ and $S_3$ . We know that there is an automorphism $\sigma: \alpha \rightarrow \alpha\omega_6$ , which is cyclic of order 6, so $Gal(K/\Bbb{Q}) \cong \Bbb{Z}_6$ .","Let be the splitting field of over , (a) Let be a primitive sixth root of unity over . Compute the  Galois group of over . (b) Compute the Galois group of over . (a) Let . We know that the roots of are , , , , , and . Since is irreducible over by Eisenstein's criteria, . We also know that Since , or . But since , it must be of degree 3. So . Since there is only one group of order 3 up to isomorphism, . (b) We know that , and there are only two groups of order 6 up to isomorphism, and . We know that there is an automorphism , which is cyclic of order 6, so .","K x^6-5 \Bbb{Q} \omega_6 \Bbb{Q} K \Bbb{Q}(\omega_6) K \Bbb{Q} \alpha = 5^{1/6} x^6-5 \alpha \alpha\omega_6 \alpha\omega_6^2 \alpha\omega_6^3 \alpha\omega_6^4 \alpha\omega_6^5 x^6-5 \Bbb{Q} [\Bbb{Q}(\alpha, \omega_6):\Bbb{Q}] \leq 6 [\Bbb{Q}(\alpha, \omega_6):\Bbb{Q}]=[\Bbb{Q}(\alpha,\omega_6):\Bbb{Q}(\omega_6)][\Bbb{Q}(\omega_6):\Bbb{Q})]. [\Bbb{Q}(\omega_6):\Bbb{Q}]=\phi(6)=(3-1)(2-1)=2 [\Bbb{Q}(\alpha,\omega_6):\Bbb{Q}(\omega_6)]=1 3 \alpha \not\in \Bbb{Q}(\omega_6) [\Bbb{Q}(\alpha,\omega_6):\Bbb{Q}(\omega_6)] = |Gal(\Bbb{Q}(\alpha,\omega_6)/\Bbb{Q}(\omega_6))|=3 Gal(\Bbb{Q}(\alpha,\omega_6)/\Bbb{Q}(\omega_6)) \cong \Bbb{Z}_3 |Gal(K/\Bbb{Q})|=6 \Bbb{Z}_6 S_3 \sigma: \alpha \rightarrow \alpha\omega_6 Gal(K/\Bbb{Q}) \cong \Bbb{Z}_6",['abstract-algebra']
86,Let G be a group of order 24 that is not isomorphic to S4. Then one of its Sylow subgroups is normal.,Let G be a group of order 24 that is not isomorphic to S4. Then one of its Sylow subgroups is normal.,,"Let G be a group of order 24 that is not isomorphic to S4. Then   one of its Sylow subgroups is normal. This is the proof from my textbook . Proof Suppose that the 3-Sylow subgroups are not normal. The number of 3-Sylow subgroups is 1 mod 3 and divides 8. Thus, if there is more than one 3-Sylow subgroup, there must be four of them. Let X be the set of 3-Sylow subgroups of G. Then G acts on X by conjugation, so we get a homomorphism $f : G  S(X) \cong S_4$. As weve seen in the discussion on G-sets, the kernel of f is the intersection of the isotropy subgroups of the elements of X. Moreover, since the action is that given by conjugation, the isotropy subgroup of H  X is $N_G(H)$ (the normalizer of H in G). Thus, $$ker f = \cap_{H \in X} N_G(H).$$ For H  X, the index of $N_G(H)$ is 4, the number of conjugates of H. Thus, the order of $N_G(H)$ is 6. Suppose that K is a different element of X. We claim that the order of $N_G(H) \cap N_G(K)$ divides 2. To see this, note that the order of $N_G(H) \cap N_G(K)$ cannot be divisible by 3. This is because any p-group contained in the normalizer of a p-Sylow subgroup must be contained in the p-Sylow subgroup itself (Corollary 5.3.5). Since the 3-Sylow subgroups have prime order here, they cannot intersect unless they are equal. But if the order of $N_G(H) \cap N_G(K)$ divides 6 and is not divisible by 3, it must divide 2. In consequence, we see that the order of the kernel of f divides 2. If the kernel has order 1, then f is an isomorphism, since G and $S_4$ have the same number of elements. Thus, we shall assume that ker f has order 2. In this case, the image of f has order 12. But by Problem 2 of Exercises 4.2.18, $A_4$ is the only subgroup of $S_4$ of order 12, so we must have im f = $A_4$. By Problem 1 of Exercises 4.2.18, the 2-Sylow subgroup, $P_2$, of $A_4$ is normal. But since ker f has order 2, $f^{1}P_2$ has order 8, and must be a 2-Sylow subgroup of G. As the pre-image of a normal subgroup, it must be normal, and were done. My Question I'm just confused about the last part. I kind of got lost when it was explaining how/why $f^{-1}P_2$ has order 8. I'm not really sure how that's related to the kernel of f. Thank you in advance","Let G be a group of order 24 that is not isomorphic to S4. Then   one of its Sylow subgroups is normal. This is the proof from my textbook . Proof Suppose that the 3-Sylow subgroups are not normal. The number of 3-Sylow subgroups is 1 mod 3 and divides 8. Thus, if there is more than one 3-Sylow subgroup, there must be four of them. Let X be the set of 3-Sylow subgroups of G. Then G acts on X by conjugation, so we get a homomorphism $f : G  S(X) \cong S_4$. As weve seen in the discussion on G-sets, the kernel of f is the intersection of the isotropy subgroups of the elements of X. Moreover, since the action is that given by conjugation, the isotropy subgroup of H  X is $N_G(H)$ (the normalizer of H in G). Thus, $$ker f = \cap_{H \in X} N_G(H).$$ For H  X, the index of $N_G(H)$ is 4, the number of conjugates of H. Thus, the order of $N_G(H)$ is 6. Suppose that K is a different element of X. We claim that the order of $N_G(H) \cap N_G(K)$ divides 2. To see this, note that the order of $N_G(H) \cap N_G(K)$ cannot be divisible by 3. This is because any p-group contained in the normalizer of a p-Sylow subgroup must be contained in the p-Sylow subgroup itself (Corollary 5.3.5). Since the 3-Sylow subgroups have prime order here, they cannot intersect unless they are equal. But if the order of $N_G(H) \cap N_G(K)$ divides 6 and is not divisible by 3, it must divide 2. In consequence, we see that the order of the kernel of f divides 2. If the kernel has order 1, then f is an isomorphism, since G and $S_4$ have the same number of elements. Thus, we shall assume that ker f has order 2. In this case, the image of f has order 12. But by Problem 2 of Exercises 4.2.18, $A_4$ is the only subgroup of $S_4$ of order 12, so we must have im f = $A_4$. By Problem 1 of Exercises 4.2.18, the 2-Sylow subgroup, $P_2$, of $A_4$ is normal. But since ker f has order 2, $f^{1}P_2$ has order 8, and must be a 2-Sylow subgroup of G. As the pre-image of a normal subgroup, it must be normal, and were done. My Question I'm just confused about the last part. I kind of got lost when it was explaining how/why $f^{-1}P_2$ has order 8. I'm not really sure how that's related to the kernel of f. Thank you in advance",,['abstract-algebra']
87,Decompose $P$ into the direct sum of irreducible representations.,Decompose  into the direct sum of irreducible representations.,P,"Note: I need help with part (c). Consider the representation $P: S_3 \rightarrow GL_3$ where $P_{\sigma}$ is the permutation matrix associated to $\sigma$. a) Determine the character $\chi_P : S_3 \rightarrow \mathbb{C}$ b) Find all the irreducible representations of $S_3$. c) Decompose $P$ into the direct sum of irreducible representations.  That is, find a single matrix $Q$ so that $Q^{-1}P_{\sigma}Q$ is block diagonal where the blocks along the diagonal are either $T_{\sigma}$, $\Sigma_{\sigma}$ or $A_{\sigma}$ My Attempt Here is my overall progress for the problem: I let $e$ to be the identity permutation, $x = (1 \ 2 \ 3)$ and $y = (1 \ 2)$ Then, I let $P_x = \begin{bmatrix} 0 & 0 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \end{bmatrix}$, $P_y = \begin{bmatrix} 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ and $P_e = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$. The conjugacy classes are as followed: $\{e\}$ $\{y, xy, yx\}$ $\{x, x^2\}$ The character table shows that: $$\chi (\{e\}) = 3$$ $$\chi (\{x, x^2\}) = 0$$ $$\chi (\{y, xy, yx\}) = 1$$ By the theorem I have applied, I have found three representations, which is congruent to the number of conjugacy classes.  They are: trivial representation $T$ sign representation $\Sigma$ two-dimensional representation $A$, presented as the symmetries of equilateral triangle The sum of their dimensions corresponds to the theorem I applied: $$d_1^2 + d_2^2 + d_3^2 = |S_3| = 6$$ The only possibility for equality to hold is $d_1 = d_2 = 1$ and $d_3 = 2$. Another character table shows that: $\chi_T (\{e\}) = 1$ $\chi_T (\{x, x^2\}) = 1$ $\chi_T (\{y, yx, xy\}) = 1$ $\chi_A (\{e\}) = 2$ $\chi_A (\{x, x^2\}) = -1$ $\chi_A (\{y, xy, yx\}) = 0$ $\chi_{\Sigma} (\{e\}) = 1$ $\chi_{\Sigma} (\{x, x^2\}) = 1$ $\chi_{\Sigma} (\{y, yx, xy\}) = -1$ Now, I am stuck in determining what is the matrix $Q$ for $Q^{-1}P_{\sigma}Q$. I know that I need to do ""change of basis"" and work out the vectors and stuff like this, but I can't seem to find the thorough approach. EDIT : Here is what I currently have: For the trivial representation, I have the vector $(1 , 1 , 1)$ spanning the invariant subspace. For the two-dimensional representation, I need to find two vectors $v$ and $w$ such that: $P_x v = -v/2 + \sqrt{3}w/2$ $P_x w = -v/2 - \sqrt{3}w/2$ $P_y v = v$ $P_y w = -w$ I found the $Q$ matrix, which is: $$\begin{bmatrix} 1 & 1 & -\frac{(1 + \sqrt{3})}{2} \\ 1 & 1 & \frac{(1 + \sqrt{3})}{2} \\ 1 & -2 & 0 \end{bmatrix}$$ But it is wrong. Any advices or comments you have?","Note: I need help with part (c). Consider the representation $P: S_3 \rightarrow GL_3$ where $P_{\sigma}$ is the permutation matrix associated to $\sigma$. a) Determine the character $\chi_P : S_3 \rightarrow \mathbb{C}$ b) Find all the irreducible representations of $S_3$. c) Decompose $P$ into the direct sum of irreducible representations.  That is, find a single matrix $Q$ so that $Q^{-1}P_{\sigma}Q$ is block diagonal where the blocks along the diagonal are either $T_{\sigma}$, $\Sigma_{\sigma}$ or $A_{\sigma}$ My Attempt Here is my overall progress for the problem: I let $e$ to be the identity permutation, $x = (1 \ 2 \ 3)$ and $y = (1 \ 2)$ Then, I let $P_x = \begin{bmatrix} 0 & 0 & 1 \\ 1 & 0 & 0 \\ 0 & 1 & 0 \end{bmatrix}$, $P_y = \begin{bmatrix} 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ and $P_e = \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$. The conjugacy classes are as followed: $\{e\}$ $\{y, xy, yx\}$ $\{x, x^2\}$ The character table shows that: $$\chi (\{e\}) = 3$$ $$\chi (\{x, x^2\}) = 0$$ $$\chi (\{y, xy, yx\}) = 1$$ By the theorem I have applied, I have found three representations, which is congruent to the number of conjugacy classes.  They are: trivial representation $T$ sign representation $\Sigma$ two-dimensional representation $A$, presented as the symmetries of equilateral triangle The sum of their dimensions corresponds to the theorem I applied: $$d_1^2 + d_2^2 + d_3^2 = |S_3| = 6$$ The only possibility for equality to hold is $d_1 = d_2 = 1$ and $d_3 = 2$. Another character table shows that: $\chi_T (\{e\}) = 1$ $\chi_T (\{x, x^2\}) = 1$ $\chi_T (\{y, yx, xy\}) = 1$ $\chi_A (\{e\}) = 2$ $\chi_A (\{x, x^2\}) = -1$ $\chi_A (\{y, xy, yx\}) = 0$ $\chi_{\Sigma} (\{e\}) = 1$ $\chi_{\Sigma} (\{x, x^2\}) = 1$ $\chi_{\Sigma} (\{y, yx, xy\}) = -1$ Now, I am stuck in determining what is the matrix $Q$ for $Q^{-1}P_{\sigma}Q$. I know that I need to do ""change of basis"" and work out the vectors and stuff like this, but I can't seem to find the thorough approach. EDIT : Here is what I currently have: For the trivial representation, I have the vector $(1 , 1 , 1)$ spanning the invariant subspace. For the two-dimensional representation, I need to find two vectors $v$ and $w$ such that: $P_x v = -v/2 + \sqrt{3}w/2$ $P_x w = -v/2 - \sqrt{3}w/2$ $P_y v = v$ $P_y w = -w$ I found the $Q$ matrix, which is: $$\begin{bmatrix} 1 & 1 & -\frac{(1 + \sqrt{3})}{2} \\ 1 & 1 & \frac{(1 + \sqrt{3})}{2} \\ 1 & -2 & 0 \end{bmatrix}$$ But it is wrong. Any advices or comments you have?",,"['abstract-algebra', 'representation-theory']"
88,Some Results in $\mathbb{Z} [\sqrt{10}]$,Some Results in,\mathbb{Z} [\sqrt{10}],"This is a question from an old Oxford undergrad paper on calculations in $\mathbb{Z} [\sqrt{10}]$. We equip this ring with the Eucliden function $d(a+b\sqrt{10})=|a^2-10b^2|$. I want to prove the following results: If $d(x)=1$, then $\frac{1}{x} \in \mathbb{Z} [\sqrt{10}]$ Any non-zero element of $\mathbb{Z} [\sqrt{10}]$ which is not a unit can be expressed as a product of finitely many irreducibles in $\mathbb{Z} [\sqrt{10}]$ The ideal generated by $2$ and $\sqrt{10}$ is not principal in $\mathbb{Z} [\sqrt{10}]$ Thought so far Suppose $x=a+b\sqrt{10}$. Clearly if $x$ is a unit then $d(x)=1$, though I'm not sure if this helps. Are we OK simply to note that $\frac{1}{x}=\frac{a-b\sqrt{10}}{a^2-10b^2}$ and since $d(x)=1$ then the deonminator is either $1$ or $-1$. I know this is true in general in a principal ideal domain and every Euclidean ring is a principal ideal domain, but this proof is lengthy. Is there any calculation one can perform in $\mathbb{Z} [\sqrt{10}]$ to demonstrate this property more quickly. Any help would be appreciated; I'm not actually too sure what this ideal looks set. Could someone put it in a set notation for me? Many thanks.","This is a question from an old Oxford undergrad paper on calculations in $\mathbb{Z} [\sqrt{10}]$. We equip this ring with the Eucliden function $d(a+b\sqrt{10})=|a^2-10b^2|$. I want to prove the following results: If $d(x)=1$, then $\frac{1}{x} \in \mathbb{Z} [\sqrt{10}]$ Any non-zero element of $\mathbb{Z} [\sqrt{10}]$ which is not a unit can be expressed as a product of finitely many irreducibles in $\mathbb{Z} [\sqrt{10}]$ The ideal generated by $2$ and $\sqrt{10}$ is not principal in $\mathbb{Z} [\sqrt{10}]$ Thought so far Suppose $x=a+b\sqrt{10}$. Clearly if $x$ is a unit then $d(x)=1$, though I'm not sure if this helps. Are we OK simply to note that $\frac{1}{x}=\frac{a-b\sqrt{10}}{a^2-10b^2}$ and since $d(x)=1$ then the deonminator is either $1$ or $-1$. I know this is true in general in a principal ideal domain and every Euclidean ring is a principal ideal domain, but this proof is lengthy. Is there any calculation one can perform in $\mathbb{Z} [\sqrt{10}]$ to demonstrate this property more quickly. Any help would be appreciated; I'm not actually too sure what this ideal looks set. Could someone put it in a set notation for me? Many thanks.",,['abstract-algebra']
89,A question on an answer on Math Overflow about Artin approximation,A question on an answer on Math Overflow about Artin approximation,,"I have a question on an answer of this Math Overflow question . Let $(A,I)$ be a commutative excellent normal local domain. The completion $$ \hat A=\underset{\longleftarrow}{\operatorname{lim}} A/(I^nA) $$ has $A$ as a subring by the canonical map. An answer to the referred question on MO states that the henselization $A^h$ of $A$ can be defined as the separable closure $S$ of $A$ in $\hat A$. More precisely, an element $a\in \hat A$ is in $A^h$ iff there if a separable polynomial $f\in A[X]$ with $f(a)=0$ (is this interpretation correct?). According to the answers, this should follow from Artin approximation. How does this description of $A^h$ follows from Artin approximation? Where do I need the properties ''excellent'' and ''normal''? Where ''separability''? At least for the (probably easy?) direction $S\subseteq A^h$ there should be an other argument. To cite a lecture of Popescu, a Noetherian local ring $(A,I)$ has the property of approximation if   every finite system of polynomial equations $f$ over $A$ in   $X_1,\ldots,X_n$ has its solutions in $A$ dense with respect to the   $I$-adic topology in the set of its solutions in the completion $\hat A$   of $A$; that is, for every solution $\hat x$ of $f$ in $\hat A$ and   every positive integer $c$ there exists a solution $x$ of $f$ in $A$   such that $$x\equiv \hat x\mod I^c\hat A.$$ The Artin approximation theorem is the statement that some rings have this property of approximation. This should be relevant for the question with a single polynomial equation instead of a system. I think one needs ''normality'' and ''excellence'' for the Artin approximation theorem to hold but I can't find it in the literature formulated with these properties. Moreover, I am curious where the separability comes into the game.","I have a question on an answer of this Math Overflow question . Let $(A,I)$ be a commutative excellent normal local domain. The completion $$ \hat A=\underset{\longleftarrow}{\operatorname{lim}} A/(I^nA) $$ has $A$ as a subring by the canonical map. An answer to the referred question on MO states that the henselization $A^h$ of $A$ can be defined as the separable closure $S$ of $A$ in $\hat A$. More precisely, an element $a\in \hat A$ is in $A^h$ iff there if a separable polynomial $f\in A[X]$ with $f(a)=0$ (is this interpretation correct?). According to the answers, this should follow from Artin approximation. How does this description of $A^h$ follows from Artin approximation? Where do I need the properties ''excellent'' and ''normal''? Where ''separability''? At least for the (probably easy?) direction $S\subseteq A^h$ there should be an other argument. To cite a lecture of Popescu, a Noetherian local ring $(A,I)$ has the property of approximation if   every finite system of polynomial equations $f$ over $A$ in   $X_1,\ldots,X_n$ has its solutions in $A$ dense with respect to the   $I$-adic topology in the set of its solutions in the completion $\hat A$   of $A$; that is, for every solution $\hat x$ of $f$ in $\hat A$ and   every positive integer $c$ there exists a solution $x$ of $f$ in $A$   such that $$x\equiv \hat x\mod I^c\hat A.$$ The Artin approximation theorem is the statement that some rings have this property of approximation. This should be relevant for the question with a single polynomial equation instead of a system. I think one needs ''normality'' and ''excellence'' for the Artin approximation theorem to hold but I can't find it in the literature formulated with these properties. Moreover, I am curious where the separability comes into the game.",,"['abstract-algebra', 'commutative-algebra', 'ring-theory']"
90,Generalization of Cauchy's functional equation,Generalization of Cauchy's functional equation,,"We know that if $f(x+y)=f(x)+f(y)$ and $f$ meets some ""reasonable"" conditions, then $f$ is linear. I've been considering the following extension: consider the reals under some unknown group operation $\oplus$ which is isomorphic to the reals under standard addition, i.e. $f(x\oplus y)=f(x)+f(y)$. Under what conditions must we conclude that $f(x)=cx$ where $f$ is the isomorphism? I think over the rationals we could use the same argument as for Cauchy, but I'm not sure about over the reals. Update : In another question Joy gives an example where $f:(\mathbb{R},\oplus)\to (\mathbb{R},+)$ with $f$ continuous yet $f(x)\not=cx$. So the answer to this generalization is not the same as the answer to the normal Cauchy.","We know that if $f(x+y)=f(x)+f(y)$ and $f$ meets some ""reasonable"" conditions, then $f$ is linear. I've been considering the following extension: consider the reals under some unknown group operation $\oplus$ which is isomorphic to the reals under standard addition, i.e. $f(x\oplus y)=f(x)+f(y)$. Under what conditions must we conclude that $f(x)=cx$ where $f$ is the isomorphism? I think over the rationals we could use the same argument as for Cauchy, but I'm not sure about over the reals. Update : In another question Joy gives an example where $f:(\mathbb{R},\oplus)\to (\mathbb{R},+)$ with $f$ continuous yet $f(x)\not=cx$. So the answer to this generalization is not the same as the answer to the normal Cauchy.",,"['abstract-algebra', 'group-theory', 'functional-equations']"
91,Natural way to define a free action of a finite abelian group,Natural way to define a free action of a finite abelian group,,"Let $G$ be a finite abelian group. Then $G \simeq \mathbb{Z}_{u_1} \oplus \cdots \oplus \mathbb{Z}_{u_m}$, where $u_{i}$ is a power of some prime number. Without loss of generality I will consider $G = \mathbb{Z}_{u_1} \oplus \cdots \oplus \mathbb{Z}_{u_m}$. Let $Y$ be an infinite set. I introduce a set $$   \mathcal{Y} = Y^{u_1 \times\cdots \times u_m} \setminus \mathcal{Y}_0, $$ where $\mathcal{Y}_0$ is the diagonal of $Y^{u_1 \times \ldots \times u_m}$: $$ \mathcal{Y}_0 = \left\{ \left\{ y_{i_1,\ldots,i_m} \right\} \in Y^{u_1 \times \cdots \times u_m} \mid y_{k_1,\ldots,k_m}=y_{j_1,\ldots,j_m} \, \forall k_1,\ldots,k_m, j_1,\ldots,j_m   \right\}. $$ I define an action of $G$ on $\mathcal{Y}$ by the rule $$    (l_1,\ldots,l_m) \cdot \left\{ y_{i_1,\ldots,i_m} \right\} = \left\{y_{i_1 + l_1\pmod{u_1}, \ldots, i_m + l_m\pmod{u_m}} \right\}. $$ It is just a circular shift of multidimensional matrix $\left\{ y_{i_1,\ldots,i_m} \right\}$ in each dimension by appropriate number of positions. If $m=1$ then this action is free if and only if $u_1$ is prime. For $m>1$ this action is never free. For example for $G = \mathbb{Z}_2 \oplus \mathbb{Z}_2$ we have $$     (1,0) \cdot \begin{bmatrix} 1  & 2 \\ 1 & 2   \end{bmatrix} = \begin{bmatrix} 1  & 2 \\ 1 & 2   \end{bmatrix}. $$ My question is if there is a natural way to generalize the above construction $\mathcal{Y}$ so that an analogous (in some sense) action of $G$ will be free for a more general class of finite groups? For example for $\mathbb{Z}_{p^k}$ or $\mathbb{Z}_{p} \oplus \mathbb{Z}_{q}$?","Let $G$ be a finite abelian group. Then $G \simeq \mathbb{Z}_{u_1} \oplus \cdots \oplus \mathbb{Z}_{u_m}$, where $u_{i}$ is a power of some prime number. Without loss of generality I will consider $G = \mathbb{Z}_{u_1} \oplus \cdots \oplus \mathbb{Z}_{u_m}$. Let $Y$ be an infinite set. I introduce a set $$   \mathcal{Y} = Y^{u_1 \times\cdots \times u_m} \setminus \mathcal{Y}_0, $$ where $\mathcal{Y}_0$ is the diagonal of $Y^{u_1 \times \ldots \times u_m}$: $$ \mathcal{Y}_0 = \left\{ \left\{ y_{i_1,\ldots,i_m} \right\} \in Y^{u_1 \times \cdots \times u_m} \mid y_{k_1,\ldots,k_m}=y_{j_1,\ldots,j_m} \, \forall k_1,\ldots,k_m, j_1,\ldots,j_m   \right\}. $$ I define an action of $G$ on $\mathcal{Y}$ by the rule $$    (l_1,\ldots,l_m) \cdot \left\{ y_{i_1,\ldots,i_m} \right\} = \left\{y_{i_1 + l_1\pmod{u_1}, \ldots, i_m + l_m\pmod{u_m}} \right\}. $$ It is just a circular shift of multidimensional matrix $\left\{ y_{i_1,\ldots,i_m} \right\}$ in each dimension by appropriate number of positions. If $m=1$ then this action is free if and only if $u_1$ is prime. For $m>1$ this action is never free. For example for $G = \mathbb{Z}_2 \oplus \mathbb{Z}_2$ we have $$     (1,0) \cdot \begin{bmatrix} 1  & 2 \\ 1 & 2   \end{bmatrix} = \begin{bmatrix} 1  & 2 \\ 1 & 2   \end{bmatrix}. $$ My question is if there is a natural way to generalize the above construction $\mathcal{Y}$ so that an analogous (in some sense) action of $G$ will be free for a more general class of finite groups? For example for $\mathbb{Z}_{p^k}$ or $\mathbb{Z}_{p} \oplus \mathbb{Z}_{q}$?",,"['abstract-algebra', 'finite-groups', 'group-actions']"
92,A question about the quotient of a $K$-algebra by its radical.,A question about the quotient of a -algebra by its radical.,K,"Let $A$ be a $K$-algebra and $B=A/\operatorname{rad} A$, where $\operatorname{rad}A$ is the radical of $A$ (intersection of all maximal right ideals of $A$).  Let $e$ be an idempotent of  $A$ and $\bar{e}=e+\operatorname{rad} A$. How to show that $eA/\operatorname{rad} eA$ is isomorphic to $\bar{e}B$? We have $\bar{e}B=(e+\operatorname{rad} A)(A/\operatorname{rad} A)$. The elements in $\bar{e}B$ is of the form $ea+\operatorname{rad} A$, where $a \in A$. But the elements of $eA/\operatorname{rad} eA$ is of the form $ea+\operatorname{rad} eA$, where $a \in A$. This question comes from the reading of the book (page 21, line 1 of the proof of Proposition 4.5 of the book Elements of the Representation Theory of Associative Algebras: Volume 1 ). Another question is how to show that $\operatorname{rad} eA = eA \operatorname{rad} A = e \operatorname{rad} A$? Thank you very much.","Let $A$ be a $K$-algebra and $B=A/\operatorname{rad} A$, where $\operatorname{rad}A$ is the radical of $A$ (intersection of all maximal right ideals of $A$).  Let $e$ be an idempotent of  $A$ and $\bar{e}=e+\operatorname{rad} A$. How to show that $eA/\operatorname{rad} eA$ is isomorphic to $\bar{e}B$? We have $\bar{e}B=(e+\operatorname{rad} A)(A/\operatorname{rad} A)$. The elements in $\bar{e}B$ is of the form $ea+\operatorname{rad} A$, where $a \in A$. But the elements of $eA/\operatorname{rad} eA$ is of the form $ea+\operatorname{rad} eA$, where $a \in A$. This question comes from the reading of the book (page 21, line 1 of the proof of Proposition 4.5 of the book Elements of the Representation Theory of Associative Algebras: Volume 1 ). Another question is how to show that $\operatorname{rad} eA = eA \operatorname{rad} A = e \operatorname{rad} A$? Thank you very much.",,"['abstract-algebra', 'representation-theory', 'modules']"
93,"If $V$ is a vector space over $k$, is every $k[x]$-module structure on $V$ induced by some linear transformation?","If  is a vector space over , is every -module structure on  induced by some linear transformation?",V k k[x] V,"Suppose $V$ is a vector space over a field $k$. Fixing a linear transformation $T$, it is common to make $V$ a $k[x]$-module by defining $f(x)\cdot v=f(T)(v)$. Is every possible $k[x]$-module structure over $V$ necessarily induced by some $T\in L(V)$? If $V$ is some $k[x]$-module, we can define a map $T$ on $V$ by $T(v)=x\cdot v$. Then $T$ is additive. But for scalars,  $$T(cv)=x\cdot(cv)=(xc)\cdot v=(cx)\cdot v=c\cdot(x\cdot v)=c\cdot T(v)$$ but I don't think we can assume that multiplication by scalars in $k$ over $V$ as a $k$-vector space needs to be the same as multiplication by scalars in $k$ when viewing $V$ as a $k[x]$-module.","Suppose $V$ is a vector space over a field $k$. Fixing a linear transformation $T$, it is common to make $V$ a $k[x]$-module by defining $f(x)\cdot v=f(T)(v)$. Is every possible $k[x]$-module structure over $V$ necessarily induced by some $T\in L(V)$? If $V$ is some $k[x]$-module, we can define a map $T$ on $V$ by $T(v)=x\cdot v$. Then $T$ is additive. But for scalars,  $$T(cv)=x\cdot(cv)=(xc)\cdot v=(cx)\cdot v=c\cdot(x\cdot v)=c\cdot T(v)$$ but I don't think we can assume that multiplication by scalars in $k$ over $V$ as a $k$-vector space needs to be the same as multiplication by scalars in $k$ when viewing $V$ as a $k[x]$-module.",,"['abstract-algebra', 'modules']"
94,Splitting field of $ x^2 + 1$ over $\mathbb{Z_3}$,Splitting field of  over, x^2 + 1 \mathbb{Z_3},"I have the following exercise: Find splitting field for the polynomial $x^2 + 1$ over $\mathbb{Z_3}$. My solution: At first, we should try to solve the equation $x^2 + 1 = 0$, thus $x^2 = 2$ and we need $\sqrt2$.  Add this root to our new field and we have  $\{0, 1, 2, \sqrt2, 2\sqrt2, 1+\sqrt2, 2 + \sqrt2, 1+2\sqrt2, 2 + 2\sqrt2 \}$  and that's our splitting field where roots of $x^2 + 1 = 0$ are $\sqrt2$ and $2\sqrt2$. Is it correct or not? And I think there is no exact algorithm how to build a splitting field. How to do it properly?","I have the following exercise: Find splitting field for the polynomial $x^2 + 1$ over $\mathbb{Z_3}$. My solution: At first, we should try to solve the equation $x^2 + 1 = 0$, thus $x^2 = 2$ and we need $\sqrt2$.  Add this root to our new field and we have  $\{0, 1, 2, \sqrt2, 2\sqrt2, 1+\sqrt2, 2 + \sqrt2, 1+2\sqrt2, 2 + 2\sqrt2 \}$  and that's our splitting field where roots of $x^2 + 1 = 0$ are $\sqrt2$ and $2\sqrt2$. Is it correct or not? And I think there is no exact algorithm how to build a splitting field. How to do it properly?",,"['abstract-algebra', 'galois-theory', 'finite-fields']"
95,Tensor product and exterior algebra,Tensor product and exterior algebra,,"I want to show that there is a unique $R$-module isomorphism $M\otimes_{R}N\cong N\otimes_{R}M$, which sends $m\otimes n $ to $n\otimes m$. My idea is to show the map is onto and injective, then how to show its uniqueness? The second question is that $R$ is an integral domain and $F$ its fraction field, consider $F$ as $R$-module. Show that $\bigwedge^{2}F=0$. Also, I am confused about the universal properties when I learn the tensor product and exterior algebra, can anyone give me an example of how to calculate the exterior algebra? Here is another question, the countable direct product of Z is not free. Can anyone give me some hint about how to prove this?","I want to show that there is a unique $R$-module isomorphism $M\otimes_{R}N\cong N\otimes_{R}M$, which sends $m\otimes n $ to $n\otimes m$. My idea is to show the map is onto and injective, then how to show its uniqueness? The second question is that $R$ is an integral domain and $F$ its fraction field, consider $F$ as $R$-module. Show that $\bigwedge^{2}F=0$. Also, I am confused about the universal properties when I learn the tensor product and exterior algebra, can anyone give me an example of how to calculate the exterior algebra? Here is another question, the countable direct product of Z is not free. Can anyone give me some hint about how to prove this?",,['abstract-algebra']
96,Splitting fields and Galois extensions,Splitting fields and Galois extensions,,"Let $L/K$ be a field extension such that $L$ is a splitting field of $f\in K[X]$, i.e. $f=\prod_{i=1}^{k} (X-u_i)^{n_i}$ for some $u_i\in L$. If we denote the coefficients of $g:=\prod_{i=1}^{k} (X-u_i)$ with $v_0,\ldots,v_k$ is then 1) $L/K(v_0,\ldots,v_k)$ a Galois extension ? 2) Does $\text{Gal}(L/K(v_0,\ldots,v_k))=\text{Gal}(L/K) $ hold ? I also have to show that $L$ is a splitting field of $g$, but this seems trivial, since $L$ contains the $u_i$'s, so if $f$ split, also $g$ has to split - or am I missing something here ?","Let $L/K$ be a field extension such that $L$ is a splitting field of $f\in K[X]$, i.e. $f=\prod_{i=1}^{k} (X-u_i)^{n_i}$ for some $u_i\in L$. If we denote the coefficients of $g:=\prod_{i=1}^{k} (X-u_i)$ with $v_0,\ldots,v_k$ is then 1) $L/K(v_0,\ldots,v_k)$ a Galois extension ? 2) Does $\text{Gal}(L/K(v_0,\ldots,v_k))=\text{Gal}(L/K) $ hold ? I also have to show that $L$ is a splitting field of $g$, but this seems trivial, since $L$ contains the $u_i$'s, so if $f$ split, also $g$ has to split - or am I missing something here ?",,"['abstract-algebra', 'field-theory']"
97,Image of conjugacy class under surjective homomorphism,Image of conjugacy class under surjective homomorphism,,"There is a surjective homomorphism from $G$ to $G'$. Let $C$ denote the conjugacy class of element $x$ in $G$, $C'$ the conjugacy class of the image of $x$ in $G'$. Prove the order of $C'$ divides the order of $C$. So far, using the class equation I can observe that $|C|$ divides $|G|$ and $|C'|$ divides $|G'|$, and it's also obvious that the homomorphism maps $C$ surjectively to $C'$. But I can't quite piece it all together. Any help appreciated.","There is a surjective homomorphism from $G$ to $G'$. Let $C$ denote the conjugacy class of element $x$ in $G$, $C'$ the conjugacy class of the image of $x$ in $G'$. Prove the order of $C'$ divides the order of $C$. So far, using the class equation I can observe that $|C|$ divides $|G|$ and $|C'|$ divides $|G'|$, and it's also obvious that the homomorphism maps $C$ surjectively to $C'$. But I can't quite piece it all together. Any help appreciated.",,"['abstract-algebra', 'group-theory', 'finite-groups']"
98,Irreducible polynomial over an algebraically closed field of characteristic distinct from 2,Irreducible polynomial over an algebraically closed field of characteristic distinct from 2,,"Let $k$ be an algebraically closed field such that $\textrm{char(k)} \neq 2$ and let $n$ be a fixed positive integer greater than $3$ Suppose that $m$ is a positive integer such that $3 \leq m \leq n$. Is it always true that $f(x_{1},x_{2},\ldots,x_{m})=x_{1}^{2}+x_{2}^{2}+\cdots+x_{m}^{2}$ is irreducible over $k[x_{1},x_{2},\ldots,x_{n}]$? I think yes. For $m=3$ we need to check that $f(x,y,z)=x^{2}+y^{2}+z^{2}$ is irreducible, yes? can't we use Eisenstein as follows? Note $y+iz$ divides $y^{2}+z^{2}$ and $y+iz$ is irreducible over $k[y,z]$ and $(y+iz)^{2}$ does not divide $y^{2}+z^{2}$. Therefore $f(x,y,z)=x^{2}+y^{2}+z^{2}$ is irreducible. Now we induct on $m$. Suppose the result holds for $m$ and let us show it holds for $m+1$. So we must look at the polynomial $x_{1}^{2}+\cdots+x_{m}^{2}+x_{m+1}^{2}$. Consider the ring $k[x_{m+1}][x_{1},..,x_{m}]$,  we have a monic polynomial and by hypothesis $x_{1}^{2}+\cdots+x_{m}^{2}$ is irreducible over $k[x_{1},\ldots,x_{m}]$ and $(x_{1}^{2}+\cdots+x_{m}^{2} )^{2}$ does not divides $x_{1}^{2}+\cdots+x_{m}^{2}$ so Eisenstein applies again and we are done. Question(s): Is this OK? In case not, can you please provide a proof?","Let $k$ be an algebraically closed field such that $\textrm{char(k)} \neq 2$ and let $n$ be a fixed positive integer greater than $3$ Suppose that $m$ is a positive integer such that $3 \leq m \leq n$. Is it always true that $f(x_{1},x_{2},\ldots,x_{m})=x_{1}^{2}+x_{2}^{2}+\cdots+x_{m}^{2}$ is irreducible over $k[x_{1},x_{2},\ldots,x_{n}]$? I think yes. For $m=3$ we need to check that $f(x,y,z)=x^{2}+y^{2}+z^{2}$ is irreducible, yes? can't we use Eisenstein as follows? Note $y+iz$ divides $y^{2}+z^{2}$ and $y+iz$ is irreducible over $k[y,z]$ and $(y+iz)^{2}$ does not divide $y^{2}+z^{2}$. Therefore $f(x,y,z)=x^{2}+y^{2}+z^{2}$ is irreducible. Now we induct on $m$. Suppose the result holds for $m$ and let us show it holds for $m+1$. So we must look at the polynomial $x_{1}^{2}+\cdots+x_{m}^{2}+x_{m+1}^{2}$. Consider the ring $k[x_{m+1}][x_{1},..,x_{m}]$,  we have a monic polynomial and by hypothesis $x_{1}^{2}+\cdots+x_{m}^{2}$ is irreducible over $k[x_{1},\ldots,x_{m}]$ and $(x_{1}^{2}+\cdots+x_{m}^{2} )^{2}$ does not divides $x_{1}^{2}+\cdots+x_{m}^{2}$ so Eisenstein applies again and we are done. Question(s): Is this OK? In case not, can you please provide a proof?",,"['abstract-algebra', 'polynomials']"
99,On Constructions by Marked Straightedge and Compass,On Constructions by Marked Straightedge and Compass,,"Pierpont proved that a regular $n$-gon is constructible by (singly) marked straightedge and compass if and only if $n = k \, p_1 \cdots p_{s}$, where $k = 2^{a_1} 3^{a_2}$ for $a_i \geq 0$ and $p_i = 2^{b_1} 3^{b_2} + 1 > 3$ is prime with $b_i \geq 0$. It has been known since the time of Archimedes that a marked straightedge allows for angle trisection . Let a $q$-sector be an object which allows for angle $q$-section. Does this result generalize to the following? Let $q$ be a prime. A regular $n$-gon is constructible by $q$-sector, straightedge and compass if and only if $n = k \, p_1 \cdots p_{s}$, where $k = 2^{a_1} 3^{a_2} \cdots q^{a_m}$ for $a_i \geq 0$ and $p_i = 2^{b_1} 3^{b_2} \cdots q^{b_m} + 1 > q$ is prime with $b_i \geq 0$. Update : Gleason 's paper provides the complete answer for constructible $n$-gons. Here, it is shown that a regular $n$-gon is constructible by straightedge, compass and $p$-sector for each prime $p$ dividing $\varphi(n)$, the Euler totient of $n$. Thus, I must modify my conjecture to the following: Let $q$ be a prime. A regular $n$-gon is constructible by $\{ 3, 5, \dots, q \}$-sectors, straightedge and compass if and only if $n = k \, p_1 \cdots p_{s}$, where $k = 2^{a_1} 3^{a_2} \cdots q^{a_m}$ for $a_i \geq 0$ and $p_i = 2^{b_1} 3^{b_2} \cdots q^{b_m} + 1 > q$ is prime with $b_i \geq 0$. One direction is certainly true by using the multiplicativity of the Euler totient function. The question is now whether the other direction also holds.","Pierpont proved that a regular $n$-gon is constructible by (singly) marked straightedge and compass if and only if $n = k \, p_1 \cdots p_{s}$, where $k = 2^{a_1} 3^{a_2}$ for $a_i \geq 0$ and $p_i = 2^{b_1} 3^{b_2} + 1 > 3$ is prime with $b_i \geq 0$. It has been known since the time of Archimedes that a marked straightedge allows for angle trisection . Let a $q$-sector be an object which allows for angle $q$-section. Does this result generalize to the following? Let $q$ be a prime. A regular $n$-gon is constructible by $q$-sector, straightedge and compass if and only if $n = k \, p_1 \cdots p_{s}$, where $k = 2^{a_1} 3^{a_2} \cdots q^{a_m}$ for $a_i \geq 0$ and $p_i = 2^{b_1} 3^{b_2} \cdots q^{b_m} + 1 > q$ is prime with $b_i \geq 0$. Update : Gleason 's paper provides the complete answer for constructible $n$-gons. Here, it is shown that a regular $n$-gon is constructible by straightedge, compass and $p$-sector for each prime $p$ dividing $\varphi(n)$, the Euler totient of $n$. Thus, I must modify my conjecture to the following: Let $q$ be a prime. A regular $n$-gon is constructible by $\{ 3, 5, \dots, q \}$-sectors, straightedge and compass if and only if $n = k \, p_1 \cdots p_{s}$, where $k = 2^{a_1} 3^{a_2} \cdots q^{a_m}$ for $a_i \geq 0$ and $p_i = 2^{b_1} 3^{b_2} \cdots q^{b_m} + 1 > q$ is prime with $b_i \geq 0$. One direction is certainly true by using the multiplicativity of the Euler totient function. The question is now whether the other direction also holds.",,"['abstract-algebra', 'geometry', 'geometric-construction']"
