,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Prove that Helly Theorem is not true in $L^{\infty}[0,1]$",Prove that Helly Theorem is not true in,"L^{\infty}[0,1]","Prove that Helly Theorem is not true in $X=L^{\infty}[0,1]$ Helly's Theorem: Let $X$ be a separable normed linear space and $\{T_n \}$ a sequence in its dual space $X^*$ that is bounded, that is, there is an $M > 0$ for which $|T_n(f)|\leq M \cdot ||f||$ for all $f$ in $X$ and all $n$ . Then there is a subsequence $\{T_{n_k}\}$ of $\{T_n\}$ and $T$ in $X^*$ for which $\lim\limits_{k \to \infty} T_{n_k} =T(f)$ for all $f$ in $X$ My thoughts: Since one of the condition of the theorem is $X$ is separable normed linear space, I thought that will be enough to prove that $L^{\infty} [0,1]$ is not separable (and we can do this by contradiction) but I think it is not enough and maybe a counterexample (that I can't see) will solve this problem easily, any clues or solutions? Thanks","Prove that Helly Theorem is not true in Helly's Theorem: Let be a separable normed linear space and a sequence in its dual space that is bounded, that is, there is an for which for all in and all . Then there is a subsequence of and in for which for all in My thoughts: Since one of the condition of the theorem is is separable normed linear space, I thought that will be enough to prove that is not separable (and we can do this by contradiction) but I think it is not enough and maybe a counterexample (that I can't see) will solve this problem easily, any clues or solutions? Thanks","X=L^{\infty}[0,1] X \{T_n \} X^* M > 0 |T_n(f)|\leq M \cdot ||f|| f X n \{T_{n_k}\} \{T_n\} T X^* \lim\limits_{k \to \infty} T_{n_k} =T(f) f X X L^{\infty} [0,1]","['real-analysis', 'functional-analysis']"
1,Is there a function on a compact interval that is differentiable but not Lipschitz continuous?,Is there a function on a compact interval that is differentiable but not Lipschitz continuous?,,"Consider a function $f:[a,b]\rightarrow \mathbb{R}$, does there exist a differentiable function that is not Lipschitz continuous? After discussing this with friends we have come to the conclusion that none exist. However there is every chance we are wrong. If it is true that none exist how could we go about proving that? It is true that if $f$ is continuously differentiable then $f$ is Lipschitz , but what if we don't assume the derivative is continuous?","Consider a function $f:[a,b]\rightarrow \mathbb{R}$, does there exist a differentiable function that is not Lipschitz continuous? After discussing this with friends we have come to the conclusion that none exist. However there is every chance we are wrong. If it is true that none exist how could we go about proving that? It is true that if $f$ is continuously differentiable then $f$ is Lipschitz , but what if we don't assume the derivative is continuous?",,"['real-analysis', 'derivatives', 'lipschitz-functions']"
2,Find the sum of the series $1+\frac{1}{3}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4^2}+\frac{1}{7}\cdot\frac{1}{4^3}+\cdots$ [duplicate],Find the sum of the series  [duplicate],1+\frac{1}{3}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4^2}+\frac{1}{7}\cdot\frac{1}{4^3}+\cdots,This question already has an answer here : Evaluate $ 1 + \frac{1}{3}\frac{1}{4}+\frac{1}{5}\frac{1}{4^2}+\frac{1}{7}\frac{1}{4^3}+\dots$ (1 answer) Closed 3 years ago . Find the sum of the series : $$1+\frac{1}{3}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4^2}+\frac{1}{7}\cdot\frac{1}{4^3}+\cdots$$,This question already has an answer here : Evaluate $ 1 + \frac{1}{3}\frac{1}{4}+\frac{1}{5}\frac{1}{4^2}+\frac{1}{7}\frac{1}{4^3}+\dots$ (1 answer) Closed 3 years ago . Find the sum of the series : $$1+\frac{1}{3}\cdot\frac{1}{4}+\frac{1}{5}\cdot\frac{1}{4^2}+\frac{1}{7}\cdot\frac{1}{4^3}+\cdots$$,,['real-analysis']
3,Proof that pointwise equicontinuity on a compact subset of $\mathbb{R}$ implies uniform equicontinuity.,Proof that pointwise equicontinuity on a compact subset of  implies uniform equicontinuity.,\mathbb{R},"I have an idea of the proof of the above statement, but I'm not entirely sure if it's right. Any comments would be appreciated. This question was supposedly answered here but the answer doesn't address the question at all. Work so far: Suppose not, i.e. that there exists some $\epsilon > 0$ such that for all $\delta > 0$ and $x,t \in [a,b]$, $|x-t| < \delta$ but $|f_k(x) - f_k(t)| \geq \epsilon$ for some $k \in \mathbb{N}$. Fix this $\epsilon$. We are given a family of functions $f_n:\mathbb{R} \to \mathbb{R}$ defined on a compact interval $[a,b]$, and that this family is pointwise equicontinuous. Pointwise equicontinuity of {$f_n$} implies that each $f_n$ is continuous, and since the domain is compact, we have that each $f_n$ is uniformly continuous. In particular $f_k$ is uniformly continuous, but this contradicts the hypothesis above.","I have an idea of the proof of the above statement, but I'm not entirely sure if it's right. Any comments would be appreciated. This question was supposedly answered here but the answer doesn't address the question at all. Work so far: Suppose not, i.e. that there exists some $\epsilon > 0$ such that for all $\delta > 0$ and $x,t \in [a,b]$, $|x-t| < \delta$ but $|f_k(x) - f_k(t)| \geq \epsilon$ for some $k \in \mathbb{N}$. Fix this $\epsilon$. We are given a family of functions $f_n:\mathbb{R} \to \mathbb{R}$ defined on a compact interval $[a,b]$, and that this family is pointwise equicontinuous. Pointwise equicontinuity of {$f_n$} implies that each $f_n$ is continuous, and since the domain is compact, we have that each $f_n$ is uniformly continuous. In particular $f_k$ is uniformly continuous, but this contradicts the hypothesis above.",,"['real-analysis', 'equicontinuity']"
4,"Procedure for ""rounding the corner"" of a piecewise smooth function","Procedure for ""rounding the corner"" of a piecewise smooth function",,"Let $f : \mathbb{R} \to \mathbb{C}$ be a piecewise smooth function which is continuous everywhere and smooth at all but one point $a \in \mathbb{R}$. I would like to know if there is a procedure for taking $f$ and modifying it slightly to get $F \in C^\infty(\mathbb{R})$ such that $F = f$ everywhere except for a small interval around $a$. Intuitively, I think the idea is to replace $f$ on some small interval $(a + \epsilon, a - \epsilon)$ by a smooth function, and then connect that function up to $f$ on either end (in a smooth way). But I'm not exactly sure if or how this can done (for instance, can we only get $F \in C^N(\mathbb{R})$?). I imagine that a convolution may need to be used. Is there a standard analysis book that gives a proof of this procedure, if in fact it can be done? Solutions or reference suggestions are greatly appreciated.","Let $f : \mathbb{R} \to \mathbb{C}$ be a piecewise smooth function which is continuous everywhere and smooth at all but one point $a \in \mathbb{R}$. I would like to know if there is a procedure for taking $f$ and modifying it slightly to get $F \in C^\infty(\mathbb{R})$ such that $F = f$ everywhere except for a small interval around $a$. Intuitively, I think the idea is to replace $f$ on some small interval $(a + \epsilon, a - \epsilon)$ by a smooth function, and then connect that function up to $f$ on either end (in a smooth way). But I'm not exactly sure if or how this can done (for instance, can we only get $F \in C^N(\mathbb{R})$?). I imagine that a convolution may need to be used. Is there a standard analysis book that gives a proof of this procedure, if in fact it can be done? Solutions or reference suggestions are greatly appreciated.",,"['real-analysis', 'reference-request']"
5,How can I prove that $\lim_{n \rightarrow \infty} \sqrt[n]x=1$ [duplicate],How can I prove that  [duplicate],\lim_{n \rightarrow \infty} \sqrt[n]x=1,"This question already has answers here : Prove $\forall K > 0: \lim_{n\rightarrow\infty} \sqrt[n]{K} = 1$ [duplicate] (3 answers) Show that $\lim_{n \rightarrow \infty} \sqrt[n]{a} =1$ (3 answers) Closed 4 years ago . How can I prove that $$\lim_{n \rightarrow \infty} \sqrt[n]x=1$$ for all $x>0$ I know I've got to use the monotone convergence theorem somehow. It's easy to show that $\sqrt[n]x$ is bounded, but having trouble showing that it is strictly increasing for $0<a<1$ and strictly decreasing for $a>1$. Also how can prove the infimum and supremum is 1 for the two cases?","This question already has answers here : Prove $\forall K > 0: \lim_{n\rightarrow\infty} \sqrt[n]{K} = 1$ [duplicate] (3 answers) Show that $\lim_{n \rightarrow \infty} \sqrt[n]{a} =1$ (3 answers) Closed 4 years ago . How can I prove that $$\lim_{n \rightarrow \infty} \sqrt[n]x=1$$ for all $x>0$ I know I've got to use the monotone convergence theorem somehow. It's easy to show that $\sqrt[n]x$ is bounded, but having trouble showing that it is strictly increasing for $0<a<1$ and strictly decreasing for $a>1$. Also how can prove the infimum and supremum is 1 for the two cases?",,"['real-analysis', 'sequences-and-series', 'limits', 'radicals']"
6,Is a continuous open surjection $f:\mathbb R \to \mathbb R$ a homeomorphism?,Is a continuous open surjection  a homeomorphism?,f:\mathbb R \to \mathbb R,"I have this problem: If $f: \mathbb{R} \rightarrow \mathbb{R}$ is a continuous, open surjection, must it be a homeomorphism? What about if $f$ was defined from $S \rightarrow S$ instead, where S is the unit circle? Now, I know that if $f$ is a continuous, open bijection, then $f$ is a homeomorphism, so my plan is to show that $f$ is injective. Would I use the property of continuity that convergent sequences are mapped to convergent sequences? How would I handle the second part of the question?","I have this problem: If $f: \mathbb{R} \rightarrow \mathbb{R}$ is a continuous, open surjection, must it be a homeomorphism? What about if $f$ was defined from $S \rightarrow S$ instead, where S is the unit circle? Now, I know that if $f$ is a continuous, open bijection, then $f$ is a homeomorphism, so my plan is to show that $f$ is injective. Would I use the property of continuity that convergent sequences are mapped to convergent sequences? How would I handle the second part of the question?",,"['real-analysis', 'continuity']"
7,"How to show that ""most"" functions $f : [0,1] \to \Bbb R$ are discontinuous everywhere?","How to show that ""most"" functions  are discontinuous everywhere?","f : [0,1] \to \Bbb R","Consider the family of functions $\mathcal F$ consisting of all functions $f : [0,1] \to \Bbb R$. I think that most of these functions will be discontinuous everywhere, that is, if you were to pick a random function $f \in \mathcal F$ it will be everywhere discontinuous with probability $1$. How can one prove this statement? My first thought was to somehow prove that the set of $f$ that are continuous at any point $x \in [0,1]$ is countable, but that isn't true (e.g. the family of constant functions in $[0,1]$ is uncountable). Perhaps show that this set is $\aleph_1$ and the original set is $\aleph_2$? (I don't know if $|\mathcal F| = \aleph_2$ is true, it's just a thought).","Consider the family of functions $\mathcal F$ consisting of all functions $f : [0,1] \to \Bbb R$. I think that most of these functions will be discontinuous everywhere, that is, if you were to pick a random function $f \in \mathcal F$ it will be everywhere discontinuous with probability $1$. How can one prove this statement? My first thought was to somehow prove that the set of $f$ that are continuous at any point $x \in [0,1]$ is countable, but that isn't true (e.g. the family of constant functions in $[0,1]$ is uncountable). Perhaps show that this set is $\aleph_1$ and the original set is $\aleph_2$? (I don't know if $|\mathcal F| = \aleph_2$ is true, it's just a thought).",,"['real-analysis', 'probability', 'functions']"
8,"If $\int_0^{x/3} f(t)dt =\int_0^xf(t)dt$, prove $f$ is identically $0$","If , prove  is identically",\int_0^{x/3} f(t)dt =\int_0^xf(t)dt f 0,"$f:[0,1] \to \mathbf R$ is continuous. If $$\int_0^{x/3} f(t)dt =\int_0^xf(t)dt$$ for all $x$ in $[0,1]$, prove that $f$ is identically $0$. My thought is to prove that the maximum and minimum of $f$ are equal then $f$ is constant and this constant can only be zero. But I can't think of a way to do that. Can somebody help and give me some hints. Thanks.","$f:[0,1] \to \mathbf R$ is continuous. If $$\int_0^{x/3} f(t)dt =\int_0^xf(t)dt$$ for all $x$ in $[0,1]$, prove that $f$ is identically $0$. My thought is to prove that the maximum and minimum of $f$ are equal then $f$ is constant and this constant can only be zero. But I can't think of a way to do that. Can somebody help and give me some hints. Thanks.",,['real-analysis']
9,"$f$ is positive continuous function on $[0,1]$.",is positive continuous function on .,"f [0,1]","$f$ is positive continuous function on $[0,1]$. Define  $$\int_{0}^{a_n} f(x) dx =  \frac{1}{n} \int_{0}^1 f(x) dx$$ where $a_n>0$. Find $ \lim_{n\to \infty} n a_n$. It is clear that $lim_{n\to \infty} a_n =0$ because $f(x)$ is positive.I tried to use Weierstrass approximation of continuous function by polynomials but could no quite get the right way.I do not see a  way to bring down this equation $\int_{0}^{a_n} f(x) dx =  \frac{1}{n} \int_{0}^1 f(x) dx$ to $n a_n$. This is a qualifying problem of real analysis. Small hint works for me. Thanks.","$f$ is positive continuous function on $[0,1]$. Define  $$\int_{0}^{a_n} f(x) dx =  \frac{1}{n} \int_{0}^1 f(x) dx$$ where $a_n>0$. Find $ \lim_{n\to \infty} n a_n$. It is clear that $lim_{n\to \infty} a_n =0$ because $f(x)$ is positive.I tried to use Weierstrass approximation of continuous function by polynomials but could no quite get the right way.I do not see a  way to bring down this equation $\int_{0}^{a_n} f(x) dx =  \frac{1}{n} \int_{0}^1 f(x) dx$ to $n a_n$. This is a qualifying problem of real analysis. Small hint works for me. Thanks.",,['real-analysis']
10,To show that ${x_n}$ is convergent where $|x_{n+1} - x_n|< \frac{1}{n^2}$,To show that  is convergent where,{x_n} |x_{n+1} - x_n|< \frac{1}{n^2},"Let ${x_n}$ be a sequence in $R$ such that $|x_{n+1} - x_n|< \frac{1}{n^2}$ for all $n \in N$. Show that the sequence is convergent. If it were $|x_{n+1} - x_n|= \frac{1}{n^2}$, could take help of the fact $\sum \frac{1}{n^2}$ is convergent and of triangular inequality. But what to do here? Please help. Thanks in advance.","Let ${x_n}$ be a sequence in $R$ such that $|x_{n+1} - x_n|< \frac{1}{n^2}$ for all $n \in N$. Show that the sequence is convergent. If it were $|x_{n+1} - x_n|= \frac{1}{n^2}$, could take help of the fact $\sum \frac{1}{n^2}$ is convergent and of triangular inequality. But what to do here? Please help. Thanks in advance.",,"['real-analysis', 'sequences-and-series']"
11,Why this polynomial represents this figure?,Why this polynomial represents this figure?,,"I'm trying to understand why this figure is represented by this polynomial expression: My goal is to prove directly why cartesian product of natural numbers is equinumerous to the natural numbers. I've already checked to the first elements of $(m,n)$ and indeed this polynomial seems to represent this figure. I'm having problems to see why this figure is represented by this polynomial expression. Thanks","I'm trying to understand why this figure is represented by this polynomial expression: My goal is to prove directly why cartesian product of natural numbers is equinumerous to the natural numbers. I've already checked to the first elements of $(m,n)$ and indeed this polynomial seems to represent this figure. I'm having problems to see why this figure is represented by this polynomial expression. Thanks",,"['real-analysis', 'analytic-geometry']"
12,"how that if $P(\lim \sup A_n) = 1$ then, $P(\bigcup_{n=1}^\infty A_n)=1$","how that if  then,",P(\lim \sup A_n) = 1 P(\bigcup_{n=1}^\infty A_n)=1,"Question: Let $\{A_n\}$ be a sequence of independent events in a probability space $(\Omega, F, P)$ show that if $P(\lim \sup A_n) = 1$ then, $P(\bigcup_{n=1}^\infty A_n)=1$ I tried solving this question, i think that i need to use the following inequalities; $$P( \lim\sup A_n) = P(\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k) \le P(\bigcup_{k=n}^\infty A_k) \le \sum_{k=n}^\infty P(A_k)$$ my thought may be false or not.I'm not sure. please help me solving this question. thank you.","Question: Let $\{A_n\}$ be a sequence of independent events in a probability space $(\Omega, F, P)$ show that if $P(\lim \sup A_n) = 1$ then, $P(\bigcup_{n=1}^\infty A_n)=1$ I tried solving this question, i think that i need to use the following inequalities; $$P( \lim\sup A_n) = P(\bigcap_{n=1}^\infty \bigcup_{k=n}^\infty A_k) \le P(\bigcup_{k=n}^\infty A_k) \le \sum_{k=n}^\infty P(A_k)$$ my thought may be false or not.I'm not sure. please help me solving this question. thank you.",,"['real-analysis', 'probability', 'measure-theory', 'probability-theory', 'limsup-and-liminf']"
13,Bernstein's Theorem of Analytic Function Proof,Bernstein's Theorem of Analytic Function Proof,,"I'm studying from a textbook and came across an exercise to prove the following, which it calls the Bernstein's Theorem: If $f$ is infinitely differentiable on an interval $I$, and $f^n(x)\ge0$ for all $n\in\mathbb N$ and $x\in I$, then $f$ is analytic on $I$. I'm trying to find more information and/or a proof of it, though most of my search comes up with the Cantor-Bernstein or Schröder-Bernstein theorems, which don't seem to be the same as this. Is anyone more knowledgable of this proof?","I'm studying from a textbook and came across an exercise to prove the following, which it calls the Bernstein's Theorem: If $f$ is infinitely differentiable on an interval $I$, and $f^n(x)\ge0$ for all $n\in\mathbb N$ and $x\in I$, then $f$ is analytic on $I$. I'm trying to find more information and/or a proof of it, though most of my search comes up with the Cantor-Bernstein or Schröder-Bernstein theorems, which don't seem to be the same as this. Is anyone more knowledgable of this proof?",,"['real-analysis', 'differential']"
14,Measure of non-measurable set is zero,Measure of non-measurable set is zero,,"I am working on a problem from Richard Bass' analysis, which to a slowpoke is just a jumbling of unrelated terms: Suppose that set $N$ is non-measurable as defined in Section 4.4. Show that $m(A) = 0$ if $A \subset N$, where $A$ is Lebesgue measurable. (Section 4.4 has this theorem: Let $m^*$ be defined by the usual outer measure definition, where $\mathcal C$ is the collection of intervals that are open on the left and closed on the right and $\mathscr l ((a, b]) = b - a$. Then $m^*$ is not a measure on the collection of all subsets of $\mathbb R$. ) Here are what I managed to salvage from the mess before my mind goes on strike: (1) Since $N$ is non-measurable per Section 4.4, which says that all subsets of $\mathbb R$ is non-measurable, then $N \subset \mathbb R.$ (2) Since $A \subset N$, isn't it $A \subset \mathbb R$ as well? (3) Since $A$ is Lebesgue measurable, then $$\forall B \subseteq \mathbb R, \ m(B) = m(B \cap A) + m(B \cap A^c).$$ Please let me know how and where I should go from here. Thank you for your time and effort.","I am working on a problem from Richard Bass' analysis, which to a slowpoke is just a jumbling of unrelated terms: Suppose that set $N$ is non-measurable as defined in Section 4.4. Show that $m(A) = 0$ if $A \subset N$, where $A$ is Lebesgue measurable. (Section 4.4 has this theorem: Let $m^*$ be defined by the usual outer measure definition, where $\mathcal C$ is the collection of intervals that are open on the left and closed on the right and $\mathscr l ((a, b]) = b - a$. Then $m^*$ is not a measure on the collection of all subsets of $\mathbb R$. ) Here are what I managed to salvage from the mess before my mind goes on strike: (1) Since $N$ is non-measurable per Section 4.4, which says that all subsets of $\mathbb R$ is non-measurable, then $N \subset \mathbb R.$ (2) Since $A \subset N$, isn't it $A \subset \mathbb R$ as well? (3) Since $A$ is Lebesgue measurable, then $$\forall B \subseteq \mathbb R, \ m(B) = m(B \cap A) + m(B \cap A^c).$$ Please let me know how and where I should go from here. Thank you for your time and effort.",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
15,Proof attempt to the ratio test for sequences,Proof attempt to the ratio test for sequences,,"I'm trying to prove the ratio test for sequences. Here's what I got: If $ \lim \limits_{n \to \infty} \frac{a_{n+1}}{a_n} = L < 1 $ and $ a_n>0 \;\ \forall n $ then $ a_n $ is bounded below by $0$. Also there's $N$ so that forall $n>N$,  $a_{n+1}<a_n $. Therefore, the sequence is decreasing and bounded below so it must converge. Now, according to the test, $ \lim \limits_{n \to \infty} a_n = 0 $. Why is that?","I'm trying to prove the ratio test for sequences. Here's what I got: If $ \lim \limits_{n \to \infty} \frac{a_{n+1}}{a_n} = L < 1 $ and $ a_n>0 \;\ \forall n $ then $ a_n $ is bounded below by $0$. Also there's $N$ so that forall $n>N$,  $a_{n+1}<a_n $. Therefore, the sequence is decreasing and bounded below so it must converge. Now, according to the test, $ \lim \limits_{n \to \infty} a_n = 0 $. Why is that?",,"['real-analysis', 'sequences-and-series', 'limits', 'convergence-divergence']"
16,"Borel measurable functions $f:[0,1]\to[0,\infty)$ which cannot be expressed as pointwise limit of nondecreasing sequence of step functions",Borel measurable functions  which cannot be expressed as pointwise limit of nondecreasing sequence of step functions,"f:[0,1]\to[0,\infty)","An interval in this problem may be open, closed or half open. We regard a singleton $\{a\}$ as being an interval also. A step function is a real valued function on $\mathbb{R}$ which is a linear combination of characteristic functions of intervals. How do I go about showing there are Borel measurable functions $f: [0,1] \to [0, \infty)$ which cannot be expressed as the pointwise limit of a nondecreasing sequence of step functions? As with progressm I know I want to show there are Borel measurable functions $f: [0,1] \to [0, \infty)$ such that there does not exist a sequence of step functions $\{s_n\}$ with $s_n(x) \le s_{n+1}(x)$ for each $x$ and $\lim_{n \to\infty} s_n(x) = f(x)$. Any help would be appreciated.","An interval in this problem may be open, closed or half open. We regard a singleton $\{a\}$ as being an interval also. A step function is a real valued function on $\mathbb{R}$ which is a linear combination of characteristic functions of intervals. How do I go about showing there are Borel measurable functions $f: [0,1] \to [0, \infty)$ which cannot be expressed as the pointwise limit of a nondecreasing sequence of step functions? As with progressm I know I want to show there are Borel measurable functions $f: [0,1] \to [0, \infty)$ such that there does not exist a sequence of step functions $\{s_n\}$ with $s_n(x) \le s_{n+1}(x)$ for each $x$ and $\lim_{n \to\infty} s_n(x) = f(x)$. Any help would be appreciated.",,['real-analysis']
17,Product of a Convergent Series and Bounded Sequence,Product of a Convergent Series and Bounded Sequence,,Let $a_n$ be a bounded sequence and $\sum_{n=1}^\infty b_n$ be a convergent series. Then $\sum_{n=1}^\infty b_na_n$ is convergent. I have found a counterexample to prove it false; If we let $a_n$=$(-1)^n$ and $b_n$ = $(-1)^{n+1}$$1\over{n}$ Then $\sum_{n=1}^\infty b_na_n$ diverges But if $b_n$$>0$ the series converges How can I prove this in general?,Let $a_n$ be a bounded sequence and $\sum_{n=1}^\infty b_n$ be a convergent series. Then $\sum_{n=1}^\infty b_na_n$ is convergent. I have found a counterexample to prove it false; If we let $a_n$=$(-1)^n$ and $b_n$ = $(-1)^{n+1}$$1\over{n}$ Then $\sum_{n=1}^\infty b_na_n$ diverges But if $b_n$$>0$ the series converges How can I prove this in general?,,"['real-analysis', 'sequences-and-series', 'convergence-divergence']"
18,How does $\int_0^\infty e^{-t^4}dt = \Gamma (\frac{5}{4}) ?$,How does,\int_0^\infty e^{-t^4}dt = \Gamma (\frac{5}{4}) ?,"My text book claims that $$\int_0^\infty e^{-t^4}dt = \Gamma \left(\frac{5}{4}\right).$$ I fail to see this. By the definition of the gamma function we have $$\Gamma (z) = \int_0^\infty t^{z-1}e^{-t}dt.$$ Thus, plugging in $\frac{5}{4}$ for $z$ should give us $$\begin{array}{ccc} \Gamma\left(\frac{5}{4}\right) & = & \int_0^\infty t^{\frac{5}{4}-1}e^{-t}dt \\ & = & \int_0^\infty t^{1/4}e^{-t}dt. \\ \end{array}$$ This algebraically implies that $$t^{1/4}e^{-t} = e^{-t^4} \Leftrightarrow t^{1/4} = e^{-t^3}.$$ And from here I just get into a messy algebra scenario using logarithms that just really doesn't get me anywhere (as far as solving for $t$ goes). So what am I missing here?","My text book claims that $$\int_0^\infty e^{-t^4}dt = \Gamma \left(\frac{5}{4}\right).$$ I fail to see this. By the definition of the gamma function we have $$\Gamma (z) = \int_0^\infty t^{z-1}e^{-t}dt.$$ Thus, plugging in $\frac{5}{4}$ for $z$ should give us $$\begin{array}{ccc} \Gamma\left(\frac{5}{4}\right) & = & \int_0^\infty t^{\frac{5}{4}-1}e^{-t}dt \\ & = & \int_0^\infty t^{1/4}e^{-t}dt. \\ \end{array}$$ This algebraically implies that $$t^{1/4}e^{-t} = e^{-t^4} \Leftrightarrow t^{1/4} = e^{-t^3}.$$ And from here I just get into a messy algebra scenario using logarithms that just really doesn't get me anywhere (as far as solving for $t$ goes). So what am I missing here?",,"['calculus', 'real-analysis', 'integration', 'exponential-function', 'gamma-function']"
19,How is Fubini's theorem used in the following proof?,How is Fubini's theorem used in the following proof?,,"I'm having trouble to understand exactly how we are using Fubini's theorem in the following proof involving the distribution function, since it newer explicitly involves an integral with product measure. The proof is given to show that we can calculate an integral over some measure space $X $ as an integral over $[0, \infty ]$ $$\int _X (\phi \circ f ) d \mu= \int _0 ^{\infty } \mu \{f > t \} \phi '(t) dt$$ Where $(X, \mu ) $ is a $\sigma $-finite measure space, and $\phi :[0, \infty ] \mapsto [0, \infty ]$ is monotonic and absolutely continuous on $[0, T ]$ The proof consits of constructing a set $E $ consisting of all points $(x,t) $ where $f> t $. It is easily shown that this set is measurable with respect to the product measure on $X \times [0, \infty ] $. Further the t-section $E^t $ is measurable with respect ot $\mu $. The distribution function of $f $ is $\mu(E^t )= \int _X \chi _E (x,t) d \mu (x) $ And the right side of the top equality is equal to $\int _0 ^{\infty } \mu (E^t) \phi '(t) dt= \int _X d \mu \int \chi _E (x,t) \phi '(t) d t  $ By Fubini's theorem? Exactly how are we using Fubini's theorem as there is no explicit use of an  integral with respect to the product measure. I can see that a part of the conclusion in Fubini's theorem is used to conclude that $\mu (E^t) $ is measurable with respect to the measure on $[0, \infty ]$. Is that all? Thanks in advance!","I'm having trouble to understand exactly how we are using Fubini's theorem in the following proof involving the distribution function, since it newer explicitly involves an integral with product measure. The proof is given to show that we can calculate an integral over some measure space $X $ as an integral over $[0, \infty ]$ $$\int _X (\phi \circ f ) d \mu= \int _0 ^{\infty } \mu \{f > t \} \phi '(t) dt$$ Where $(X, \mu ) $ is a $\sigma $-finite measure space, and $\phi :[0, \infty ] \mapsto [0, \infty ]$ is monotonic and absolutely continuous on $[0, T ]$ The proof consits of constructing a set $E $ consisting of all points $(x,t) $ where $f> t $. It is easily shown that this set is measurable with respect to the product measure on $X \times [0, \infty ] $. Further the t-section $E^t $ is measurable with respect ot $\mu $. The distribution function of $f $ is $\mu(E^t )= \int _X \chi _E (x,t) d \mu (x) $ And the right side of the top equality is equal to $\int _0 ^{\infty } \mu (E^t) \phi '(t) dt= \int _X d \mu \int \chi _E (x,t) \phi '(t) d t  $ By Fubini's theorem? Exactly how are we using Fubini's theorem as there is no explicit use of an  integral with respect to the product measure. I can see that a part of the conclusion in Fubini's theorem is used to conclude that $\mu (E^t) $ is measurable with respect to the measure on $[0, \infty ]$. Is that all? Thanks in advance!",,"['real-analysis', 'measure-theory', 'fubini-tonelli-theorems']"
20,Does $\frac{1}{n}\sum_{i=1}^n|x_i|\to L<\infty$ imply $\frac{1}{n}\max_{1\leq i\leq n}|x_i|=0$?,Does  imply ?,\frac{1}{n}\sum_{i=1}^n|x_i|\to L<\infty \frac{1}{n}\max_{1\leq i\leq n}|x_i|=0,"To simplify notation, let us assume that $\{x_n\}_{n\geq 1}$ is a sequence of nonnegative real numbers. Does $$ \frac{1}{n}\sum_{i=1}^nx_i\to L $$ for some finite $L$ imply $$ \frac{1}{n}\max_{1\leq i\leq n}x_i\to 0? $$ I have been thinking about this question for the past few hours because of here but I can't come up with anything. If you can help me, please feel free to head there to resolve that post as well.","To simplify notation, let us assume that $\{x_n\}_{n\geq 1}$ is a sequence of nonnegative real numbers. Does $$ \frac{1}{n}\sum_{i=1}^nx_i\to L $$ for some finite $L$ imply $$ \frac{1}{n}\max_{1\leq i\leq n}x_i\to 0? $$ I have been thinking about this question for the past few hours because of here but I can't come up with anything. If you can help me, please feel free to head there to resolve that post as well.",,"['real-analysis', 'sequences-and-series', 'limits']"
21,To control first derivative with the function itself: $f'(x)^2\leq Cf(x)$ near where $f(x_0)=f'(x_0)=f''(x_0)=0$.,To control first derivative with the function itself:  near where .,f'(x)^2\leq Cf(x) f(x_0)=f'(x_0)=f''(x_0)=0,"Let $f$ be a compactly supported nonnegative $C^2$ function. I want to show that there exists $C$, such that for all $x\in \mathbb R$, we have $f'(x)^2\leq  C f(x) $ by showing that for every point $x\in \mathbb R$, we can find a neighborhood $U$, that on $U$ we can find such a $C$. However I have a trouble to find such a $U$ and $C$ when $f, f', f''$ all vanish at x. Any advice would be appreciated, thanks.","Let $f$ be a compactly supported nonnegative $C^2$ function. I want to show that there exists $C$, such that for all $x\in \mathbb R$, we have $f'(x)^2\leq  C f(x) $ by showing that for every point $x\in \mathbb R$, we can find a neighborhood $U$, that on $U$ we can find such a $C$. However I have a trouble to find such a $U$ and $C$ when $f, f', f''$ all vanish at x. Any advice would be appreciated, thanks.",,"['real-analysis', 'analysis', 'inequality']"
22,How to finish this proof about compact implies bounded by the open cover definition,How to finish this proof about compact implies bounded by the open cover definition,,"If $K$ is compact then it is bounded. (that it is closed was very easy to prove) Definitions .A set is called compact if every sequence has a convergent subsequence. Attempt Let $K$ be compact and assume that it is  not bounded. Let $x \in K$ be any point. Then for every $n \in \mathbb N$ let $x_n$ be such that $d(x,x_n) > n$ . Now I want to show that $x_n$ does not have a convergent subsequence. I tried by contradiction: assume $x_{n_k}$ was a convergent subsequence and $x_{n_k}\to y$ for some $y \in K$ . How to proceed?",If is compact then it is bounded. (that it is closed was very easy to prove) Definitions .A set is called compact if every sequence has a convergent subsequence. Attempt Let be compact and assume that it is  not bounded. Let be any point. Then for every let be such that . Now I want to show that does not have a convergent subsequence. I tried by contradiction: assume was a convergent subsequence and for some . How to proceed?,"K K x \in K n \in \mathbb N x_n d(x,x_n) > n x_n x_{n_k} x_{n_k}\to y y \in K","['real-analysis', 'metric-spaces']"
23,Is the Hardy Littlewood maximal function non- integrable ？,Is the Hardy Littlewood maximal function non- integrable ？,,"Some books said that the Hardy Littlewood maximal function of f, denoted by $$Hf(x)=sup_{r>0} \frac{1}{m(B(x,r))}\int_{B(x,r)} |f(y)| dy $$ is bounded by a function $C|x|^{-n}$when the norm of $x$ is very large, namely $\exists$ constants $C$ and $R$, st$Hf\geq C|x|^{-n}, \forall |x|\geq R$. How to prove this inequality? I have no idea.  Then from this inequality, can we say that $Hf$ is non-integrable?","Some books said that the Hardy Littlewood maximal function of f, denoted by $$Hf(x)=sup_{r>0} \frac{1}{m(B(x,r))}\int_{B(x,r)} |f(y)| dy $$ is bounded by a function $C|x|^{-n}$when the norm of $x$ is very large, namely $\exists$ constants $C$ and $R$, st$Hf\geq C|x|^{-n}, \forall |x|\geq R$. How to prove this inequality? I have no idea.  Then from this inequality, can we say that $Hf$ is non-integrable?",,"['real-analysis', 'integration']"
24,What problems arise when using infinitesimals in calculus?,What problems arise when using infinitesimals in calculus?,,"In contemporary real analysis we use a limit definition in terms of deltas and epsilons. Before that, people used infinitesimals to calculate limits. Is there a specific non-philosophical reason why we didn't keep on using infinitesimals? I.e. are there concrete examples in which the use of infinitesimals lead to serious problems?","In contemporary real analysis we use a limit definition in terms of deltas and epsilons. Before that, people used infinitesimals to calculate limits. Is there a specific non-philosophical reason why we didn't keep on using infinitesimals? I.e. are there concrete examples in which the use of infinitesimals lead to serious problems?",,"['calculus', 'real-analysis', 'infinitesimals']"
25,Why there are no constant functions on $\mathbb{R}$ with compact support?,Why there are no constant functions on  with compact support?,\mathbb{R},"For some the question might seem trivial but the concept is new to me and  I have been wondering  why there are no constant functions on $\mathbb{R}$ with compact support? Following wiki: Def.1) Functions with compact support on a topological space $X$ are those whose support is a compact subset of $X$ . Def.2) $\operatorname{supp}f=:\overline{\{x\in X\;,f(x)\neq 0\}}$ What if we take such function $f:\mathbb{R}\to\mathbb{R}$ defined as $f(x)=0\;,\forall x\in\mathbb{R}$ then $\operatorname{supp}f=\overline{\{x\in\mathbb{R}\;,f(x)\neq 0\}}=\overline{\emptyset}=\emptyset$ but $\emptyset$ is a compact subset of $\mathbb{R}$ I think.... Could someone enlighten me? Thank you.",For some the question might seem trivial but the concept is new to me and  I have been wondering  why there are no constant functions on with compact support? Following wiki: Def.1) Functions with compact support on a topological space are those whose support is a compact subset of . Def.2) What if we take such function defined as then but is a compact subset of I think.... Could someone enlighten me? Thank you.,"\mathbb{R} X X \operatorname{supp}f=:\overline{\{x\in X\;,f(x)\neq 0\}} f:\mathbb{R}\to\mathbb{R} f(x)=0\;,\forall x\in\mathbb{R} \operatorname{supp}f=\overline{\{x\in\mathbb{R}\;,f(x)\neq 0\}}=\overline{\emptyset}=\emptyset \emptyset \mathbb{R}","['calculus', 'real-analysis']"
26,Prove or disprove inequality $\frac{a^2}{b+c}+\frac{b^2}{a+c}+\frac{c^2}{a+b}\le\frac{a^4+b^4+c^4}{2abc}$.,Prove or disprove inequality .,\frac{a^2}{b+c}+\frac{b^2}{a+c}+\frac{c^2}{a+b}\le\frac{a^4+b^4+c^4}{2abc},"Let $a$, $b$ and $c$ be real numbers greater than $0$. Prove inequality $$\displaystyle{\frac{a^2}{b+c}+\frac{b^2}{a+c}+\frac{c^2}{a+b}\le\frac{a^4+b^4+c^4}{2abc}}.$$","Let $a$, $b$ and $c$ be real numbers greater than $0$. Prove inequality $$\displaystyle{\frac{a^2}{b+c}+\frac{b^2}{a+c}+\frac{c^2}{a+b}\le\frac{a^4+b^4+c^4}{2abc}}.$$",,"['real-analysis', 'algebra-precalculus', 'inequality', 'a.m.-g.m.-inequality', 'cauchy-schwarz-inequality']"
27,Pointwise Convergence in $L^1$ norm,Pointwise Convergence in  norm,L^1,"Suppose we have a sequence of functions $\left\{f_n\right\}_{n=1}^\infty\subseteq C^1([0,1])$ and $f_n\to f\in C([0,1])$ in the $L^1$ norm and $f_n'\to g\in C([0,1])$ in $L^1$. Does it follow that $f_n(x)\to f(x)$ for all $x\in[0,1]$? I'm hoping that it is true, and my thoughts have been directed toward trying to use a proof by contradiction. The slightly shady part here might be some counterexample like $f(x)=x^{1/3}$ which is continuous but has an unbounded derivative. Counterexamples abound for sequences of functions not satisfying the second condition, but I've neither been able to prove nor find a counterexample for this question. In addition, if it turns out this is true, then I will also have proven $f\in C^1([0,1])$ and $f'=g$. As a side note, the question originally began as homework, at which point I e-mailed the professor... It turns out I misread the question, so this question is just seeing through to the end my original thought.","Suppose we have a sequence of functions $\left\{f_n\right\}_{n=1}^\infty\subseteq C^1([0,1])$ and $f_n\to f\in C([0,1])$ in the $L^1$ norm and $f_n'\to g\in C([0,1])$ in $L^1$. Does it follow that $f_n(x)\to f(x)$ for all $x\in[0,1]$? I'm hoping that it is true, and my thoughts have been directed toward trying to use a proof by contradiction. The slightly shady part here might be some counterexample like $f(x)=x^{1/3}$ which is continuous but has an unbounded derivative. Counterexamples abound for sequences of functions not satisfying the second condition, but I've neither been able to prove nor find a counterexample for this question. In addition, if it turns out this is true, then I will also have proven $f\in C^1([0,1])$ and $f'=g$. As a side note, the question originally began as homework, at which point I e-mailed the professor... It turns out I misread the question, so this question is just seeing through to the end my original thought.",,"['real-analysis', 'sequences-and-series', 'functional-analysis', 'convergence-divergence']"
28,Is the n-dim lebesgue measure the product of the lebesgue measure?,Is the n-dim lebesgue measure the product of the lebesgue measure?,,"Let $\mathfrak{M}$ be the sigma-algebra of the n-dimensional Lebesgue measurable sets (Completion of translation invariant measure having 1 for $[0,1]^n$) Let $\Sigma$ be the sigma-algebra of the Lebesgue-measurable sets in $\mathbb{R}$. Is $\mathfrak{M}$ the sigma-algebra generated by $\{\prod_{i=1}^n p(i) : p\in \Sigma^n\}$?","Let $\mathfrak{M}$ be the sigma-algebra of the n-dimensional Lebesgue measurable sets (Completion of translation invariant measure having 1 for $[0,1]^n$) Let $\Sigma$ be the sigma-algebra of the Lebesgue-measurable sets in $\mathbb{R}$. Is $\mathfrak{M}$ the sigma-algebra generated by $\{\prod_{i=1}^n p(i) : p\in \Sigma^n\}$?",,"['real-analysis', 'measure-theory']"
29,"$\int_{0}^{\infty} f(x) \,dx$ exists. Then $\lim_{x\rightarrow \infty} f(x) $ must exist and is $0$. A rigorous proof?",exists. Then  must exist and is . A rigorous proof?,"\int_{0}^{\infty} f(x) \,dx \lim_{x\rightarrow \infty} f(x)  0","Let $f: \mathbb R \rightarrow \mathbb R $ be a continuous function such that $\int_{0}^{\infty} \,f(x) dx$ exists. Then Prove that incase (i) $f$ is a non negative function, then $\lim_{x\rightarrow \infty} f(x) $ must exist and is $0$. (ii) $f$ is a positive differentiable function , $\lim_{x\rightarrow \infty} f'(x) $ must exist and is $0$ $Attempt$: For the first part, i don't have a rigorous proof except for the fact that the given condition can be visualised geometrically. Since, the definite integral is actually calculating the area beneath the non negative function, the only way the given limit can exist when limit of f(x) itself tends to 0 at infinity. Please give me a direction so that i can make this proof rigorous enough. For the second part, i took an example. We know that ( leaving out the finite integration parts from $0$ to $1$ ..) $\int_{1}^{\infty} e^{-x^2} dx \leq \int_{1}^{\infty} e^{-x} dx$ and the latter converges.  But the derivative of $e^{-x^2} = (-2x)e^{-x^2}$ whose integration does not exist when x $\in~[1,\infty)$ as it's a monotonic function after a finite $x$. Any help in providing rigor to the above proof will be very helpful Thanks","Let $f: \mathbb R \rightarrow \mathbb R $ be a continuous function such that $\int_{0}^{\infty} \,f(x) dx$ exists. Then Prove that incase (i) $f$ is a non negative function, then $\lim_{x\rightarrow \infty} f(x) $ must exist and is $0$. (ii) $f$ is a positive differentiable function , $\lim_{x\rightarrow \infty} f'(x) $ must exist and is $0$ $Attempt$: For the first part, i don't have a rigorous proof except for the fact that the given condition can be visualised geometrically. Since, the definite integral is actually calculating the area beneath the non negative function, the only way the given limit can exist when limit of f(x) itself tends to 0 at infinity. Please give me a direction so that i can make this proof rigorous enough. For the second part, i took an example. We know that ( leaving out the finite integration parts from $0$ to $1$ ..) $\int_{1}^{\infty} e^{-x^2} dx \leq \int_{1}^{\infty} e^{-x} dx$ and the latter converges.  But the derivative of $e^{-x^2} = (-2x)e^{-x^2}$ whose integration does not exist when x $\in~[1,\infty)$ as it's a monotonic function after a finite $x$. Any help in providing rigor to the above proof will be very helpful Thanks",,"['calculus', 'real-analysis', 'integration', 'definite-integrals', 'improper-integrals']"
30,Showing a sequence convergence,Showing a sequence convergence,,"Let $a_1,a_2>0$ and $a_{n+1}=\cfrac{2}{a_{n-1}+a_{n}}(n\ge2)$, How to prove $a_n$ is convergent?","Let $a_1,a_2>0$ and $a_{n+1}=\cfrac{2}{a_{n-1}+a_{n}}(n\ge2)$, How to prove $a_n$ is convergent?",,"['calculus', 'real-analysis', 'limits']"
31,Every divergence-free vector field generated from skew-symmetric matrix,Every divergence-free vector field generated from skew-symmetric matrix,,"Let $[a_{i,j}(x_1,\ldots,x_n)]$ be a skew-symmetric $n\times n$ matrix of functions $a_{i,j}\in C^\infty(\mathbb{R}^n)$ . The vector field $$v=\sum\left(\dfrac{\partial}{\partial x_i}a_{i,j}\right)\dfrac{\partial}{\partial x_j}$$ is divergence-free . Prove by induction that for every $n\geq 2$ , every $C^\infty$ divergence-free vector field on $\mathbb{R}^n$ is of this form. Consider $n=2$ . Suppose the vector field is $f_1(x_1,x_2)\dfrac{\partial}{\partial x_1}+f_2(x_1,x_2)\dfrac{\partial}{\partial x_2}$ . Since the vector field is divergence-free, we have that $\dfrac{\partial}{\partial x_1}f_1(x_1,x_2)+\dfrac{\partial}{\partial x_2}f_2(x_1,x_2)=0$ . By this result , there exists a function $g(x_1,x_2)$ whose $x_1$ -derivative equals $f_2$ and whose $x_2$ -derivative equals $-f_1$ . The result follows. But how about for $n>2$ ? To use induction, I have to relate a divergence-free vector field of $\mathbb{R}^n$ to a divergence-free vector field of $\mathbb{R}^{n-1}$ . It is possible that the following result will help: Let $v$ be a vector field on $\mathbb{R}^n$ . Show that $v$ can be written as a sum $v=f_1\dfrac{\partial}{\partial x_1}+w$ where $w$ is a divergence-free vector field.","Let be a skew-symmetric matrix of functions . The vector field is divergence-free . Prove by induction that for every , every divergence-free vector field on is of this form. Consider . Suppose the vector field is . Since the vector field is divergence-free, we have that . By this result , there exists a function whose -derivative equals and whose -derivative equals . The result follows. But how about for ? To use induction, I have to relate a divergence-free vector field of to a divergence-free vector field of . It is possible that the following result will help: Let be a vector field on . Show that can be written as a sum where is a divergence-free vector field.","[a_{i,j}(x_1,\ldots,x_n)] n\times n a_{i,j}\in C^\infty(\mathbb{R}^n) v=\sum\left(\dfrac{\partial}{\partial x_i}a_{i,j}\right)\dfrac{\partial}{\partial x_j} n\geq 2 C^\infty \mathbb{R}^n n=2 f_1(x_1,x_2)\dfrac{\partial}{\partial x_1}+f_2(x_1,x_2)\dfrac{\partial}{\partial x_2} \dfrac{\partial}{\partial x_1}f_1(x_1,x_2)+\dfrac{\partial}{\partial x_2}f_2(x_1,x_2)=0 g(x_1,x_2) x_1 f_2 x_2 -f_1 n>2 \mathbb{R}^n \mathbb{R}^{n-1} v \mathbb{R}^n v v=f_1\dfrac{\partial}{\partial x_1}+w w","['real-analysis', 'vector-fields']"
32,Let $f:\mathbb{R}^2\to\mathbb{R}$ be a $C^1$ function. Prove that the restriction is not injective.,Let  be a  function. Prove that the restriction is not injective.,f:\mathbb{R}^2\to\mathbb{R} C^1,Let $f:\mathbb{R}^2\to\mathbb{R}$ be a $C^1$ function. And let $D$ an open subset of $\mathbb{R}^2$. Prove that the restriction of $f$ to $D$ is not injective. Im trying to solve this but i dont know how... The problem have a hint: Use the inverse theorem applied to an appropiate transformation in $\mathbb{R}^2$.,Let $f:\mathbb{R}^2\to\mathbb{R}$ be a $C^1$ function. And let $D$ an open subset of $\mathbb{R}^2$. Prove that the restriction of $f$ to $D$ is not injective. Im trying to solve this but i dont know how... The problem have a hint: Use the inverse theorem applied to an appropiate transformation in $\mathbb{R}^2$.,,"['calculus', 'real-analysis']"
33,Show that $\sqrt{6}$ is irrational. [duplicate],Show that  is irrational. [duplicate],\sqrt{6},"This question already has answers here : Prove $\sqrt6$ is irrational (5 answers) Closed 8 years ago . Suppose $x\in \mathbb{Q}$ such that $x^{2}=6$. Since  $x\in \mathbb{Q}$, there exists $m,n \in \mathbb{Z} $ where either $m$ or $n$ is odd such that $x=\frac{m}{n}$. $\implies$ $x^2=(\frac{m}{n})^2=\frac{m^2}{n^2}=6$ $\implies$ $m^2=6n^2$, so $m^2$ is even. Hence, $m$ is even. Since $m$ is even, $m=2k, k\in \mathbb{Z}$. Then, $m^2=(2k)^2=4k^2=6n^2$ $\implies$ $n^2$ is even, so $n$ is even. But one of $m$ or $n$ must be odd, so $x\notin \mathbb{Q}$. Therefore, $\sqrt{6}$ is irrational. Does everything look alright here?","This question already has answers here : Prove $\sqrt6$ is irrational (5 answers) Closed 8 years ago . Suppose $x\in \mathbb{Q}$ such that $x^{2}=6$. Since  $x\in \mathbb{Q}$, there exists $m,n \in \mathbb{Z} $ where either $m$ or $n$ is odd such that $x=\frac{m}{n}$. $\implies$ $x^2=(\frac{m}{n})^2=\frac{m^2}{n^2}=6$ $\implies$ $m^2=6n^2$, so $m^2$ is even. Hence, $m$ is even. Since $m$ is even, $m=2k, k\in \mathbb{Z}$. Then, $m^2=(2k)^2=4k^2=6n^2$ $\implies$ $n^2$ is even, so $n$ is even. But one of $m$ or $n$ must be odd, so $x\notin \mathbb{Q}$. Therefore, $\sqrt{6}$ is irrational. Does everything look alright here?",,"['real-analysis', 'radicals', 'rationality-testing']"
34,Zeros of $C^\infty$ functions,Zeros of  functions,C^\infty,"If $f(x)  \in C^\infty(\Bbb{R})$,and $f(a)=0$, do we have $$f(x)=(x-a)g(x)$$? where $g(x) \in C^\infty(\Bbb{R})$ and $g(a)=f'(a)$","If $f(x)  \in C^\infty(\Bbb{R})$,and $f(a)=0$, do we have $$f(x)=(x-a)g(x)$$? where $g(x) \in C^\infty(\Bbb{R})$ and $g(a)=f'(a)$",,"['real-analysis', 'analysis']"
35,"If $f$ is continuous almost everywhere, must there exist a function $g$ such that $g=f$ almost everywhere and $g$ is continuous?","If  is continuous almost everywhere, must there exist a function  such that  almost everywhere and  is continuous?",f g g=f g,"If $f$ is continuous almost everywhere, must there exist a function $g$ such that $g=f$ almost everywhere and $g$ is continuous? I have one example that shows it could happen. Let $f$ be defined as $1$ on irrationals and $0$ the rationals. Then the constant function $g$ defined as $1$ everywhere is such that: $g=f$ a.e. and $g$ is continuous. Thus, the statement may be true, but I am not able to show why. Thanks for any tips!","If is continuous almost everywhere, must there exist a function such that almost everywhere and is continuous? I have one example that shows it could happen. Let be defined as on irrationals and the rationals. Then the constant function defined as everywhere is such that: a.e. and is continuous. Thus, the statement may be true, but I am not able to show why. Thanks for any tips!",f g g=f g f 1 0 g 1 g=f g,"['real-analysis', 'measure-theory']"
36,"If $f$ is a $C^2$ diffeomorphism $\Longrightarrow$ $f(B[a,r])$ is convex",If  is a  diffeomorphism   is convex,"f C^2 \Longrightarrow f(B[a,r])","Let $f:U\longrightarrow V$ be a $C^2$ diffeomorphism where $U,V\subset\mathbb{R}^n$ are open sets. How can we prove that $$\forall a\in U,\exists \epsilon>0:r\le \epsilon \Longrightarrow f(B[a,r])\text{ is convex }$$ Any hints would be appreciated.","Let $f:U\longrightarrow V$ be a $C^2$ diffeomorphism where $U,V\subset\mathbb{R}^n$ are open sets. How can we prove that $$\forall a\in U,\exists \epsilon>0:r\le \epsilon \Longrightarrow f(B[a,r])\text{ is convex }$$ Any hints would be appreciated.",,['real-analysis']
37,Does the set of computable numbers get bigger if we strengthen our language?,Does the set of computable numbers get bigger if we strengthen our language?,,"This might be a silly question, but can one given an example for a number, which is not computable? I want to get a mental picture of what these real numbers are, which you can't write down. At the end of this Wikipedia article en.wikipedia.org/wiki/Computable_number it says To actually develop analysis over computable numbers, some care must be taken. For example, if one uses the classical definition of a sequence, the set of computable numbers is not closed under the basic operation of taking the supremum of a bounded sequence (for example, consider a Specker sequence). This difficulty is addressed by considering only sequences which have a computable modulus of convergence. The resulting mathematical theory is called computable analysis. So does this say that one has identified something uncomputable here? But if this is so, doesn't a description of such a thing give us a way of compute it or the object it represents? If we step by step forever strengthen our language, do we somehow obtain more numbers out of the set or $\mathbb R\setminus\mathrm{computable numbers}$? Or is it that we can say ""once we've got a process of this and that computing power, we can compute certain numbers and never more.""?","This might be a silly question, but can one given an example for a number, which is not computable? I want to get a mental picture of what these real numbers are, which you can't write down. At the end of this Wikipedia article en.wikipedia.org/wiki/Computable_number it says To actually develop analysis over computable numbers, some care must be taken. For example, if one uses the classical definition of a sequence, the set of computable numbers is not closed under the basic operation of taking the supremum of a bounded sequence (for example, consider a Specker sequence). This difficulty is addressed by considering only sequences which have a computable modulus of convergence. The resulting mathematical theory is called computable analysis. So does this say that one has identified something uncomputable here? But if this is so, doesn't a description of such a thing give us a way of compute it or the object it represents? If we step by step forever strengthen our language, do we somehow obtain more numbers out of the set or $\mathbb R\setminus\mathrm{computable numbers}$? Or is it that we can say ""once we've got a process of this and that computing power, we can compute certain numbers and never more.""?",,"['real-analysis', 'computer-science']"
38,If a sequence converges pointwise and a subsequence converges uniformly does the sequence converge uniformly?,If a sequence converges pointwise and a subsequence converges uniformly does the sequence converge uniformly?,,Let $f_{n}: X \rightarrow Y$ be a sequence of continuous functions from  one metric space to another. Suppose the sequence converges pointwise.  However a subsequence $\{ f_{n_k} \} $ converges uniformly.  Can one conclude that that the sequence converges uniformly?,Let $f_{n}: X \rightarrow Y$ be a sequence of continuous functions from  one metric space to another. Suppose the sequence converges pointwise.  However a subsequence $\{ f_{n_k} \} $ converges uniformly.  Can one conclude that that the sequence converges uniformly?,,"['real-analysis', 'convergence-divergence', 'uniform-convergence']"
39,What is the global maximum of $x^{1/x}$,What is the global maximum of,x^{1/x},"Let the following function be defined as such: $$F_x: \Bbb R \to \Bbb C, x \mapsto x^{1/x}, \forall x \ne 0$$ What I want to know is  $$\max_{x<0}\Re\left(F_x\right)=\,?$$ and $$\max_{x<0}\Im\left(F_x\right)=\,?$$ Additional Questions Why does $F$ act weird when approaching $0$ form the left? For example $$\lim_{x\to0^-}F_x=\infty \text{ and }\lim_{x\to0^+}F_x=0$$ What is with the oscillation when approaching? How are $\Re(F_x)$ and $\Im(F_x)$ related during the left approach? Are there any other functions with similar behaviors?","Let the following function be defined as such: $$F_x: \Bbb R \to \Bbb C, x \mapsto x^{1/x}, \forall x \ne 0$$ What I want to know is  $$\max_{x<0}\Re\left(F_x\right)=\,?$$ and $$\max_{x<0}\Im\left(F_x\right)=\,?$$ Additional Questions Why does $F$ act weird when approaching $0$ form the left? For example $$\lim_{x\to0^-}F_x=\infty \text{ and }\lim_{x\to0^+}F_x=0$$ What is with the oscillation when approaching? How are $\Re(F_x)$ and $\Im(F_x)$ related during the left approach? Are there any other functions with similar behaviors?",,"['calculus', 'real-analysis', 'complex-analysis', 'optimization']"
40,"If A and B are disjoint open sets, prove that they are separated","If A and B are disjoint open sets, prove that they are separated",,I just proved this statement like the below. Is this valid or solid proof? Thank you!,I just proved this statement like the below. Is this valid or solid proof? Thank you!,,['real-analysis']
41,Show that $\int_{0}^\infty \frac{1-\cos x}{x^2}dx=\pi/2$.,Show that .,\int_{0}^\infty \frac{1-\cos x}{x^2}dx=\pi/2,"I am trying to show that $$\int_{0}^\infty \frac{1-\cos x}{x^2}dx=\pi/2.$$The hint is ""try simple substitution"", and not incidentally, the previous problem has shown that $\int_0^\infty \frac{\sin^2(xu)}{u^2}du=\frac{\pi}{2}|x|$. This looks an awful lot like we'd like to reduce it to the earlier case, for $x=1$. What shall we try to substitute for? I think we'd have some problems subbing for cosine, since it does not approach a limit at infinity (correct me if there is a way to make this substitution). Subbing for $x^2$ hasn't gotten me anywhere. We might want to try to split it up, and see if anything better comes out of trying to integrate $\int_0^\infty \frac{\cos x}{x^2}dx$. No luck there so far. Any ideas?","I am trying to show that $$\int_{0}^\infty \frac{1-\cos x}{x^2}dx=\pi/2.$$The hint is ""try simple substitution"", and not incidentally, the previous problem has shown that $\int_0^\infty \frac{\sin^2(xu)}{u^2}du=\frac{\pi}{2}|x|$. This looks an awful lot like we'd like to reduce it to the earlier case, for $x=1$. What shall we try to substitute for? I think we'd have some problems subbing for cosine, since it does not approach a limit at infinity (correct me if there is a way to make this substitution). Subbing for $x^2$ hasn't gotten me anywhere. We might want to try to split it up, and see if anything better comes out of trying to integrate $\int_0^\infty \frac{\cos x}{x^2}dx$. No luck there so far. Any ideas?",,"['calculus', 'real-analysis', 'integration']"
42,Archimedean Proof?,Archimedean Proof?,,"I've been struggling with a concept concerning the Archimedean property proof.  That is showing my contradiction that For all $x$ in the reals, there exists $n$ in the naturals such that $n>x$. Okay so we assume that the naturals is bounded above and show a contradiction. If the naturals is bounded above, then it has a least upper bound (supremum) say $u$ Now consider $u-1$.  Since $u=\sup(\mathbb N)$ , $u-1$ is an element of $\mathbb N$.  (here is my first hiccup, not entirely sure why we can say $u-1$ is in $\mathbb N$) This implies (again not confident with this implication) that there exists a $m$ in $\mathbb N$ such that $m>u-1$.  A little bit of algebra leads to $m+1>u$. $m+1$ is in $\mathbb N$ and $m+1>u=\sup(\mathbb N)$ thus we have a contradiction. Can anyone help clear up these implications that I'm not really comfortable with?  Thanks!","I've been struggling with a concept concerning the Archimedean property proof.  That is showing my contradiction that For all $x$ in the reals, there exists $n$ in the naturals such that $n>x$. Okay so we assume that the naturals is bounded above and show a contradiction. If the naturals is bounded above, then it has a least upper bound (supremum) say $u$ Now consider $u-1$.  Since $u=\sup(\mathbb N)$ , $u-1$ is an element of $\mathbb N$.  (here is my first hiccup, not entirely sure why we can say $u-1$ is in $\mathbb N$) This implies (again not confident with this implication) that there exists a $m$ in $\mathbb N$ such that $m>u-1$.  A little bit of algebra leads to $m+1>u$. $m+1$ is in $\mathbb N$ and $m+1>u=\sup(\mathbb N)$ thus we have a contradiction. Can anyone help clear up these implications that I'm not really comfortable with?  Thanks!",,['real-analysis']
43,Open Cover / Real Analysis [duplicate],Open Cover / Real Analysis [duplicate],,"This question already has answers here : Proving that $S=\{\frac{1}{n}:n\in\mathbb{Z}\}\cup\{0\}$ is compact using the open cover definition (2 answers) Closed 11 years ago . I have the next question: Let $K \subset $ $R^1$ consist of $0$ and the numbers 1/$n$, for $n=1,2,3,\ldots$ Prove that $K$ is compact directly from the definition (without using Heine-Borel). I'm trying to understand compact sets so I would be grateful if someone could give me some examples of open covers and subcovers. Thank you!","This question already has answers here : Proving that $S=\{\frac{1}{n}:n\in\mathbb{Z}\}\cup\{0\}$ is compact using the open cover definition (2 answers) Closed 11 years ago . I have the next question: Let $K \subset $ $R^1$ consist of $0$ and the numbers 1/$n$, for $n=1,2,3,\ldots$ Prove that $K$ is compact directly from the definition (without using Heine-Borel). I'm trying to understand compact sets so I would be grateful if someone could give me some examples of open covers and subcovers. Thank you!",,['real-analysis']
44,Can one define the derivative of a function using tangent cones? Does such a notion already exist?,Can one define the derivative of a function using tangent cones? Does such a notion already exist?,,"I'm interested in finding an analogue of a derivative that applies to functions which are defined more general subsets of $\mathbb{R}^n$ than open subsets. In particularly, I'm looking at functions defined on the non-negative orthant of $\mathbb{R}^n$. I've been thinking that one could use tangent cones to such an end. The question is organised as follows, first are the standard definitions of a tangent cone and a differentiable function, then comes my candidate extension of differentiability and finally are the questions. Thank you very much in advanced (even if for just having a read!). EDIT: Does anyone think that this would be an appropriate (or not) question for MathOverflow? Tangent Cones: Let $X\subseteq\mathbb{R}^n$ and $x\in X$. Then the tangent cone to $X$ at $x$ , $T_X(x)$ is defined as the closure of the cone formed by all half-lines emanating from $x$ and intersecting $X$ in at least one point $y\in X$ distinct from $x$. Formally $$T_X(x)=\{0\}\cup\left\{y:y\neq0,\exists (x_k)_{k\in\mathbb{N}}\subseteq X,\quad x_k\neq x\quad \forall k,\quad \frac{x_k-x}{||x_k-x||}\rightarrow\frac{y}{||y||}\right\}.$$ Differentiable function: Suppose $E$ is an open set in $\mathbb{R}^n$, $f$ is a function that maps $E$ into $\mathbb{R}^m$, and $x\in E$. If there exists a linear transformation $A$ from $\mathbb{R}^n$ to $\mathbb{R}^m$ such that $$\lim_{h\rightarrow 0}\frac{|f(x+h)-f(x)-A(h)|}{|h|}=0,$$ where $|\cdot|$ denotes any p-norm, then we say that $f$ is differentiable at $x$, and we write $$f'(x)=A.$$ Tentative extension of ""differentiability"": Suppose $X\subseteq\mathbb{R}^n$, $x\in X$ and $f:X\rightarrow\mathbb{R}^m$. We say that $f$ is differentiable at $x$ if there exists a ""pseudo-linear"" transformation $\tilde{A}$ from $T_X(x)$ to $\mathbb{R}^m$ such that for any sequence $$(h_k)_{k\in\mathbb{N}}\subset T_X(x)$$ that satisfies $h_k\rightarrow 0$ as $k\rightarrow\infty$ $$\frac{|f(x+h)-f(x)-\tilde{A}(h)|}{|h|}=0,$$ then we say that $f$ is differentiable at $x$, and we write $$f'(x)=\tilde{A}.$$ By $\tilde{A}$ being pseudo-linear I mean that for any $a,b\in\mathbb{R}$ and $x,y\in X$ such that $ax+by\in X$ $$\tilde{A}(ax+by)=a\tilde{A}(x)+b\tilde{A}(y).$$ Note that, because $x\in int(X)$ implies that $T_X(x)=\mathbb{R}^n$, the above definition coincides with the usual one if $X$ is open. My questions then are: Does the above notion of a differentiable function and its derivative already exist? If so what is it called? Or is there a more general notion for which the above is a special case? If 1., does there exist an analogue of the chain rule that applies to it? Similarly, if $\tilde{A}$ is a continuous, is there an easy way to compute the $\tilde{A}$ in the standard basis of $\mathbb{R}^n$ (much in the same way we use the partial derivatives to compute the derivative of a continuously differentiable functions)? Similarly, can one extend a differentiable (in the sense above) function on $X$ to a differentiable (in the usual sense) function on $\mathbb{R}^n$? Is there any reason why any or all the above could not be answered affirmatively (for example, something that does not make sense in the derivative)? Any answers or references that might contain them would be greatly appreciated. If it helps, please add any extra conditions on $X$ that are satisfied by the orthant (closed, convex, closure of an open set, ...etc).","I'm interested in finding an analogue of a derivative that applies to functions which are defined more general subsets of $\mathbb{R}^n$ than open subsets. In particularly, I'm looking at functions defined on the non-negative orthant of $\mathbb{R}^n$. I've been thinking that one could use tangent cones to such an end. The question is organised as follows, first are the standard definitions of a tangent cone and a differentiable function, then comes my candidate extension of differentiability and finally are the questions. Thank you very much in advanced (even if for just having a read!). EDIT: Does anyone think that this would be an appropriate (or not) question for MathOverflow? Tangent Cones: Let $X\subseteq\mathbb{R}^n$ and $x\in X$. Then the tangent cone to $X$ at $x$ , $T_X(x)$ is defined as the closure of the cone formed by all half-lines emanating from $x$ and intersecting $X$ in at least one point $y\in X$ distinct from $x$. Formally $$T_X(x)=\{0\}\cup\left\{y:y\neq0,\exists (x_k)_{k\in\mathbb{N}}\subseteq X,\quad x_k\neq x\quad \forall k,\quad \frac{x_k-x}{||x_k-x||}\rightarrow\frac{y}{||y||}\right\}.$$ Differentiable function: Suppose $E$ is an open set in $\mathbb{R}^n$, $f$ is a function that maps $E$ into $\mathbb{R}^m$, and $x\in E$. If there exists a linear transformation $A$ from $\mathbb{R}^n$ to $\mathbb{R}^m$ such that $$\lim_{h\rightarrow 0}\frac{|f(x+h)-f(x)-A(h)|}{|h|}=0,$$ where $|\cdot|$ denotes any p-norm, then we say that $f$ is differentiable at $x$, and we write $$f'(x)=A.$$ Tentative extension of ""differentiability"": Suppose $X\subseteq\mathbb{R}^n$, $x\in X$ and $f:X\rightarrow\mathbb{R}^m$. We say that $f$ is differentiable at $x$ if there exists a ""pseudo-linear"" transformation $\tilde{A}$ from $T_X(x)$ to $\mathbb{R}^m$ such that for any sequence $$(h_k)_{k\in\mathbb{N}}\subset T_X(x)$$ that satisfies $h_k\rightarrow 0$ as $k\rightarrow\infty$ $$\frac{|f(x+h)-f(x)-\tilde{A}(h)|}{|h|}=0,$$ then we say that $f$ is differentiable at $x$, and we write $$f'(x)=\tilde{A}.$$ By $\tilde{A}$ being pseudo-linear I mean that for any $a,b\in\mathbb{R}$ and $x,y\in X$ such that $ax+by\in X$ $$\tilde{A}(ax+by)=a\tilde{A}(x)+b\tilde{A}(y).$$ Note that, because $x\in int(X)$ implies that $T_X(x)=\mathbb{R}^n$, the above definition coincides with the usual one if $X$ is open. My questions then are: Does the above notion of a differentiable function and its derivative already exist? If so what is it called? Or is there a more general notion for which the above is a special case? If 1., does there exist an analogue of the chain rule that applies to it? Similarly, if $\tilde{A}$ is a continuous, is there an easy way to compute the $\tilde{A}$ in the standard basis of $\mathbb{R}^n$ (much in the same way we use the partial derivatives to compute the derivative of a continuously differentiable functions)? Similarly, can one extend a differentiable (in the sense above) function on $X$ to a differentiable (in the usual sense) function on $\mathbb{R}^n$? Is there any reason why any or all the above could not be answered affirmatively (for example, something that does not make sense in the derivative)? Any answers or references that might contain them would be greatly appreciated. If it helps, please add any extra conditions on $X$ that are satisfied by the orthant (closed, convex, closure of an open set, ...etc).",,"['calculus', 'real-analysis', 'analysis', 'multivariable-calculus', 'convex-analysis']"
45,limit with $\arctan$,limit with,\arctan,I have to find the limit  and want ask about a hint: $$\lim_{n \to \infty} n^{\frac{3}{2}}[\arctan((n+1)^{\frac{1}{2}})- \arctan(n^{\frac{1}{2}})]$$ I dont have idea what to do. Derivatives and L'Hôpital's rule are so hard,I have to find the limit  and want ask about a hint: $$\lim_{n \to \infty} n^{\frac{3}{2}}[\arctan((n+1)^{\frac{1}{2}})- \arctan(n^{\frac{1}{2}})]$$ I dont have idea what to do. Derivatives and L'Hôpital's rule are so hard,,['real-analysis']
46,Suppose that $f$ is a real valued function such that its second derivative is discontinuous.Can you give some example?,Suppose that  is a real valued function such that its second derivative is discontinuous.Can you give some example?,f,In an interview somebody asked me the following question but I failed to give the answer. Suppose that $f$ is a real valued function such that its second derivative is discontinuous. Can you give some example?,In an interview somebody asked me the following question but I failed to give the answer. Suppose that $f$ is a real valued function such that its second derivative is discontinuous. Can you give some example?,,"['calculus', 'real-analysis', 'derivatives']"
47,"Prove for every function that from sphere to real number has points $x$, $-x$ such that f$(x)=f(-x)$","Prove for every function that from sphere to real number has points ,  such that f",x -x (x)=f(-x),"I have not taken topology course yet. This is just the question that my undergrad research professor left us to think about. She hinted that I could use a theorem from Calculus. So I reviewed all theorems in Calculus, and I found Intermediate Value Theorem might be helpful(?)... since it has some generalizations on topology.  But I still don't know how to get started. If you could give me some hints or similar examples, that would be really helpful. Thanks!","I have not taken topology course yet. This is just the question that my undergrad research professor left us to think about. She hinted that I could use a theorem from Calculus. So I reviewed all theorems in Calculus, and I found Intermediate Value Theorem might be helpful(?)... since it has some generalizations on topology.  But I still don't know how to get started. If you could give me some hints or similar examples, that would be really helpful. Thanks!",,"['calculus', 'real-analysis']"
48,Map that satisfies $f(\lambda x) = \lambda f(x)$ but not $f(x+y) = f(x)+f(y)$,Map that satisfies  but not,f(\lambda x) = \lambda f(x) f(x+y) = f(x)+f(y),"Could you give me example of maps $f:\mathbb R \to \mathbb R$ that satisfy $$ f(\lambda x) = \lambda f(x) \quad \forall x,\lambda \in \mathbb R $$ but not $ f(x+y) = f(x)+f(y) $? Thanks in advance.","Could you give me example of maps $f:\mathbb R \to \mathbb R$ that satisfy $$ f(\lambda x) = \lambda f(x) \quad \forall x,\lambda \in \mathbb R $$ but not $ f(x+y) = f(x)+f(y) $? Thanks in advance.",,"['real-analysis', 'functional-equations']"
49,"Let $\displaystyle f$ be differentiable, $\displaystyle f(x)=0$ for $|x| \geq 10 $ and $g(x)=\sum_{k \in \mathbb Z}f(x+k).$","Let  be differentiable,  for  and",\displaystyle f \displaystyle f(x)=0 |x| \geq 10  g(x)=\sum_{k \in \mathbb Z}f(x+k).,I came across the following problem that says: Let $\displaystyle f \colon \mathbb R \rightarrow \mathbb R$ be differentiable function and $\displaystyle f(x)=0$ for $|x| \geq 10.$ Let  $g(x)=\sum_{k \in \mathbb Z}f(x+k).$ Then   which of the following is true? $1.g$ is differentiable and $g'$ has infinitely many zeros $2.g$ is continuous and $g'$ has no zeros $3.g$ is differentiable and $g'$ has no zeros $4.g$ is differentiable and $g'$ has only finitely many zeros. I am not sure about how to progress with it.Can someone point me in the right direction? Thanks in advance for your time.,I came across the following problem that says: Let $\displaystyle f \colon \mathbb R \rightarrow \mathbb R$ be differentiable function and $\displaystyle f(x)=0$ for $|x| \geq 10.$ Let  $g(x)=\sum_{k \in \mathbb Z}f(x+k).$ Then   which of the following is true? $1.g$ is differentiable and $g'$ has infinitely many zeros $2.g$ is continuous and $g'$ has no zeros $3.g$ is differentiable and $g'$ has no zeros $4.g$ is differentiable and $g'$ has only finitely many zeros. I am not sure about how to progress with it.Can someone point me in the right direction? Thanks in advance for your time.,,[]
50,Supremum/Infimum proof: $\sup \{1/x; x\in A\} = 1/\inf(A)$,Supremum/Infimum proof:,\sup \{1/x; x\in A\} = 1/\inf(A),"Assume that $\inf(A)>0$ and let $A'=\left\{\frac{1}{x} : x\in A\right\}$. I need to show that $\sup(A') = \dfrac{1}{\inf(A)}$. I think this is quite simple, $\sup(A')$ must be $\dfrac{1}{\inf(A)}$ since $\inf(A)$ is the smallest number to divide by, that is $x > \inf(A)$ for all $x\in A$. Maybe I made a mistake, but if not is this sufficient? Or, how could I make this more formal? EDIT I could probably make this formal by proving this by contradiction...","Assume that $\inf(A)>0$ and let $A'=\left\{\frac{1}{x} : x\in A\right\}$. I need to show that $\sup(A') = \dfrac{1}{\inf(A)}$. I think this is quite simple, $\sup(A')$ must be $\dfrac{1}{\inf(A)}$ since $\inf(A)$ is the smallest number to divide by, that is $x > \inf(A)$ for all $x\in A$. Maybe I made a mistake, but if not is this sufficient? Or, how could I make this more formal? EDIT I could probably make this formal by proving this by contradiction...",,"['real-analysis', 'supremum-and-infimum']"
51,An elementary way to show any bounded subset of $\Bbb{R}^k$ is totally bounded,An elementary way to show any bounded subset of  is totally bounded,\Bbb{R}^k,"I'm trying to show that any subset bounded of $\Bbb{R}^k$ is totally bounded. Here is what I did: (1)A subset of a totally bounded Set is bounded: Proof: Let $X$ be a totally bounded subset and $Y\subset X$ then there exists an $\epsilon /2$-net $\{x_1,x_2,..,x_n\}$ and $X\subset \displaystyle\bigcup_{i=1}^n B(x_i,\epsilon/2)$ . Let $\{x_1,x_2,..,x_m\}$ be the points whose balls contain $Y$ $(m\le n)$. Now $\forall i \in \{1,..,m\} \exists q_i \in A \cap B(x_i,\epsilon/2) $ and $B(x_i,\epsilon/2)\subset B(q_i,\epsilon)$. We have for every $x\in B(x_i,\epsilon/2)$ $$ d(x,q_i)\le d(x,x_i)+d(x_i,q_i) < \frac \epsilon 2 + \frac \epsilon 2 =\epsilon$$ Hence $Y \subset \displaystyle\bigcup_{i=1}^m B(x_i,\epsilon/2) \subset \bigcup_{i=1}^m B(q_i,\epsilon)$ and $q_i \in Y$ for all $i$ hence $Y$ is totally bounded Back to the problem: Let $A \subset \Bbb{R}^k$ be a bounded set  then $A \subset B(0,R)$ for some $R$ then $A \subset [-R,R] \times [-R,R] \times ...\times [-R,R] $ then $A$ is a subset of a compact set by the Heine-Borel Theorem which is also a totally bounded set, hence by (1) $A$ is totally bounded. I'm trying to do this problem by only using (1) without invoking the Heine-Borel theorem, can anyone tell me how that can be done? (Is the proof of (1) right for that matter?)","I'm trying to show that any subset bounded of $\Bbb{R}^k$ is totally bounded. Here is what I did: (1)A subset of a totally bounded Set is bounded: Proof: Let $X$ be a totally bounded subset and $Y\subset X$ then there exists an $\epsilon /2$-net $\{x_1,x_2,..,x_n\}$ and $X\subset \displaystyle\bigcup_{i=1}^n B(x_i,\epsilon/2)$ . Let $\{x_1,x_2,..,x_m\}$ be the points whose balls contain $Y$ $(m\le n)$. Now $\forall i \in \{1,..,m\} \exists q_i \in A \cap B(x_i,\epsilon/2) $ and $B(x_i,\epsilon/2)\subset B(q_i,\epsilon)$. We have for every $x\in B(x_i,\epsilon/2)$ $$ d(x,q_i)\le d(x,x_i)+d(x_i,q_i) < \frac \epsilon 2 + \frac \epsilon 2 =\epsilon$$ Hence $Y \subset \displaystyle\bigcup_{i=1}^m B(x_i,\epsilon/2) \subset \bigcup_{i=1}^m B(q_i,\epsilon)$ and $q_i \in Y$ for all $i$ hence $Y$ is totally bounded Back to the problem: Let $A \subset \Bbb{R}^k$ be a bounded set  then $A \subset B(0,R)$ for some $R$ then $A \subset [-R,R] \times [-R,R] \times ...\times [-R,R] $ then $A$ is a subset of a compact set by the Heine-Borel Theorem which is also a totally bounded set, hence by (1) $A$ is totally bounded. I'm trying to do this problem by only using (1) without invoking the Heine-Borel theorem, can anyone tell me how that can be done? (Is the proof of (1) right for that matter?)",,"['real-analysis', 'general-topology']"
52,"Prove that $\int_{0}^{1} \ln\left(\frac{1-a x}{1-a}\right) \frac{1}{\ln x} \mathrm{dx} = -\sum_{k=1}^{\infty} a^{k} \frac{\ln(1+k)}{k}, \space a<1$",Prove that,"\int_{0}^{1} \ln\left(\frac{1-a x}{1-a}\right) \frac{1}{\ln x} \mathrm{dx} = -\sum_{k=1}^{\infty} a^{k} \frac{\ln(1+k)}{k}, \space a<1","Prove that $$\int_{0}^{1} \ln\left(\frac{1-a x}{1-a}\right) \frac{1}{\ln x} \mathrm{dx} =   -\sum_{k=1}^{\infty} a^{k} \frac{\ln(1+k)}{k}, \space a<1$$ I find this question rather troublesome since the both sides seem hard  to compute. I appreciate any hint/suggestion. Thanks!","Prove that $$\int_{0}^{1} \ln\left(\frac{1-a x}{1-a}\right) \frac{1}{\ln x} \mathrm{dx} =   -\sum_{k=1}^{\infty} a^{k} \frac{\ln(1+k)}{k}, \space a<1$$ I find this question rather troublesome since the both sides seem hard  to compute. I appreciate any hint/suggestion. Thanks!",,"['calculus', 'real-analysis', 'sequences-and-series', 'integration', 'definite-integrals']"
53,"""Commutativity"" of integrals","""Commutativity"" of integrals",,"Let $\mu$ and $\nu$ be two measures on a space $X$. Suppose $$ \int_X fd\mu \int_X gd\nu = \int_X fd\nu \int_X gd\mu$$ for any integrable functions $f,g$. I would like to show that this implies that $\mu = \lambda\nu$ for some $\lambda > 0$, but I don't know how. Any help would be appreciated! Thanks!","Let $\mu$ and $\nu$ be two measures on a space $X$. Suppose $$ \int_X fd\mu \int_X gd\nu = \int_X fd\nu \int_X gd\mu$$ for any integrable functions $f,g$. I would like to show that this implies that $\mu = \lambda\nu$ for some $\lambda > 0$, but I don't know how. Any help would be appreciated! Thanks!",,"['real-analysis', 'measure-theory']"
54,Questions about convergence in Lp,Questions about convergence in Lp,,"If $X_n$ converges to $X$ in $L^p$, do we have $X_n^p$ converges to $X^p$ in $L^1$? We can prove that it is true when p=1,2 easily. I am curious whether this is true for all $p>0$.","If $X_n$ converges to $X$ in $L^p$, do we have $X_n^p$ converges to $X^p$ in $L^1$? We can prove that it is true when p=1,2 easily. I am curious whether this is true for all $p>0$.",,"['real-analysis', 'analysis']"
55,Continuous functions between metric spaces are equal if they are equal on a dense subset,Continuous functions between metric spaces are equal if they are equal on a dense subset,,"If two functions defined on metric spaces $X$ and $Y$ are equal on a dense subset of $X$  and are continuous also, then are they equal on all of the metric space $X$?","If two functions defined on metric spaces $X$ and $Y$ are equal on a dense subset of $X$  and are continuous also, then are they equal on all of the metric space $X$?",,"['real-analysis', 'metric-spaces']"
56,Is this actually true?,Is this actually true?,,"This exercise appeared in my real analysis test last year, and is still puzzling me since then. Ironically, even the professor doubts if the b part is actually truth (still...) Let $A \subset \mathbb{R}$ a) If $\displaystyle0<m^*(A)<\infty$, then for every $\alpha\in (0,1)$, exists an open interval $I$ such that $\displaystyle \alpha m^*(I) \leq m^*(A \cap I) $ b) If $ \displaystyle m^*(A \cap I) \leq  \frac{m^*(I)}{2}$ for every open interval, then $m^*(A) = 0$","This exercise appeared in my real analysis test last year, and is still puzzling me since then. Ironically, even the professor doubts if the b part is actually truth (still...) Let $A \subset \mathbb{R}$ a) If $\displaystyle0<m^*(A)<\infty$, then for every $\alpha\in (0,1)$, exists an open interval $I$ such that $\displaystyle \alpha m^*(I) \leq m^*(A \cap I) $ b) If $ \displaystyle m^*(A \cap I) \leq  \frac{m^*(I)}{2}$ for every open interval, then $m^*(A) = 0$",,"['real-analysis', 'measure-theory']"
57,$L^p$-norm of a non-negative measurable function,-norm of a non-negative measurable function,L^p,"Can I ask a homework question here? Let $f$ be measurable and non-negative in $\mathbb R^d.$  Using Fubini's theorem, show that for $1 \leq p \lt \infty,$ $$\lVert f\rVert^p_p = \int^{\infty}_{0}pt^{p-1}\lambda(\{x:f(x)\gt t\}) \ dt.$$","Can I ask a homework question here? Let $f$ be measurable and non-negative in $\mathbb R^d.$  Using Fubini's theorem, show that for $1 \leq p \lt \infty,$ $$\lVert f\rVert^p_p = \int^{\infty}_{0}pt^{p-1}\lambda(\{x:f(x)\gt t\}) \ dt.$$",,"['real-analysis', 'lebesgue-integral']"
58,Compactness of $\mathcal K$ in the Hausdorff distance [duplicate],Compactness of  in the Hausdorff distance [duplicate],\mathcal K,"This question already has answers here : Closed 11 years ago . Possible Duplicate: The Class of Non-empty Compact Subsets of a Compact Metric Space is Compact Let $(M,d)$ be a metric space and let $\mathcal K(M)$ denote the set of all non-empty compact subsets of $M$. This collection is a metric space when equipped with the Hausdorff distance $h$. I want to prove$$(M,d)\mbox{ is compact}\implies(\mathcal K,h)\mbox{ is compact}.$$ The statement is true according to the book [V. I. Istratescu, Fixed Point Theory: An Introduction ], but the proof is omitted. I have already shown that $M$ is complete implies that $\mathcal K$ is complete.","This question already has answers here : Closed 11 years ago . Possible Duplicate: The Class of Non-empty Compact Subsets of a Compact Metric Space is Compact Let $(M,d)$ be a metric space and let $\mathcal K(M)$ denote the set of all non-empty compact subsets of $M$. This collection is a metric space when equipped with the Hausdorff distance $h$. I want to prove$$(M,d)\mbox{ is compact}\implies(\mathcal K,h)\mbox{ is compact}.$$ The statement is true according to the book [V. I. Istratescu, Fixed Point Theory: An Introduction ], but the proof is omitted. I have already shown that $M$ is complete implies that $\mathcal K$ is complete.",,"['real-analysis', 'functional-analysis', 'metric-spaces', 'compactness']"
59,Implicit Function Theorem example in Baby Rudin,Implicit Function Theorem example in Baby Rudin,,"I am looking at example 2.29 of Baby Rudin (page 227) of my edition to illustrate the implicit function theorem. This is what the example is: Take $n= 2$ and $m=3$ and consider $\mathbf{f} = (f_1,f_2)$ of $\Bbb{R}^5$ to $\Bbb{R}^2$ given by      $$\begin{eqnarray*} f_1(x_1,x_2,y_1,y_2,y_3) &=& 2e^{x_1} + x_2y_1 -4y_2 + 3 \\ f_2(x_1,x_2,y_1,y_2,y_3) &=& x_2\cos x_1 - 6x_1 + 2y_1 - y_3 \end{eqnarray*}.$$     If $\mathbf{a} = (0,1)$ and $\mathbf{b} = (3,2,7)$, then $\mathbf{f(a,b)} = 0$. With respect to the standard bases, the derivative of $f$ at the point $(0,1,3,2,7) $ is the matrix      $$[A] = \left[\begin{array}{ccccc} 2 & 3 & 1 & -4 & 0 \\ -6 & 1 & 2 & 0 & -1 \end{array}\right].$$     Hence if we observe the $2 \times 2$ block     $$\left[\begin{array}{cc} 2 & 3 \\ -6 & 1 \end{array}\right]$$     it is invertible, and so by the implicit function theorem there exists a $C^1$ mapping $\mathbf{g}$ defined on a neighbourhood of $(3,2,7)$ such that $\mathbf{g}(3,2,7 ) = (0,1)$ and $\mathbf{f}(\mathbf{g}(\mathbf{y}),\mathbf{y}) = 0$. Now what I don't understand is from such a $\mathbf{g}$, how does this mean that I can solve the variables $x_1$ and $x_2$ for $y_1,y_2,y_3$ locally about $(3,2,7)$? Also if I wanted to carry out this computation explicitly, how can I do it? We do not have a nice and shiny linear system to solve unlike problem 19 of the same chapter. Thanks.","I am looking at example 2.29 of Baby Rudin (page 227) of my edition to illustrate the implicit function theorem. This is what the example is: Take $n= 2$ and $m=3$ and consider $\mathbf{f} = (f_1,f_2)$ of $\Bbb{R}^5$ to $\Bbb{R}^2$ given by      $$\begin{eqnarray*} f_1(x_1,x_2,y_1,y_2,y_3) &=& 2e^{x_1} + x_2y_1 -4y_2 + 3 \\ f_2(x_1,x_2,y_1,y_2,y_3) &=& x_2\cos x_1 - 6x_1 + 2y_1 - y_3 \end{eqnarray*}.$$     If $\mathbf{a} = (0,1)$ and $\mathbf{b} = (3,2,7)$, then $\mathbf{f(a,b)} = 0$. With respect to the standard bases, the derivative of $f$ at the point $(0,1,3,2,7) $ is the matrix      $$[A] = \left[\begin{array}{ccccc} 2 & 3 & 1 & -4 & 0 \\ -6 & 1 & 2 & 0 & -1 \end{array}\right].$$     Hence if we observe the $2 \times 2$ block     $$\left[\begin{array}{cc} 2 & 3 \\ -6 & 1 \end{array}\right]$$     it is invertible, and so by the implicit function theorem there exists a $C^1$ mapping $\mathbf{g}$ defined on a neighbourhood of $(3,2,7)$ such that $\mathbf{g}(3,2,7 ) = (0,1)$ and $\mathbf{f}(\mathbf{g}(\mathbf{y}),\mathbf{y}) = 0$. Now what I don't understand is from such a $\mathbf{g}$, how does this mean that I can solve the variables $x_1$ and $x_2$ for $y_1,y_2,y_3$ locally about $(3,2,7)$? Also if I wanted to carry out this computation explicitly, how can I do it? We do not have a nice and shiny linear system to solve unlike problem 19 of the same chapter. Thanks.",,['real-analysis']
60,Continuity in two dimensions,Continuity in two dimensions,,"How would you prove or disprove that the function given by $$f(x,y) = \begin{cases} \frac{x^3y^2}{x^4 + y^4} & (x,y) \neq (0,0) \\ 0 & (x,y) = (0,0) \end{cases}$$ is continuous at $(0,0$). I tried to think of a function where the limit approached zero over which tended to an answer apart from zero, but they all went to zero! So this makes me think that the function is continuous at $(0,0)$. But how can I prove this? Thanks!","How would you prove or disprove that the function given by $$f(x,y) = \begin{cases} \frac{x^3y^2}{x^4 + y^4} & (x,y) \neq (0,0) \\ 0 & (x,y) = (0,0) \end{cases}$$ is continuous at $(0,0$). I tried to think of a function where the limit approached zero over which tended to an answer apart from zero, but they all went to zero! So this makes me think that the function is continuous at $(0,0)$. But how can I prove this? Thanks!",,[]
61,"""Unsolvable"" Equations","""Unsolvable"" Equations",,"I was just playing around with some equations the other day and losing interest I started writing down what were mostly ""random"" equations at first. But, I realized that there's something special about them, they don't have solutions! At least, as far as I could tell. On the surface it seems there should be solutions to them, seeing they look simple; at any rate, couldn't we just ""define"" objects which would satisfy these equations? Similar to what was done when complex numbers were introduced? I can't say; anywho, here is a sample of what I have: $$ \tag{1} \sqrt{ix} = -1, \sqrt{ix} = -i, \sqrt{x} = -1 - i, \\ \sqrt{ix} = -1 - i, \sqrt{-ix} = -1 - i, \sqrt{-ix} = i - 1, \\ \sqrt{-ix} = -i $$ What do you think? Can we get any solutions? Can we define solutions? Thanks in advance. EDIT: I have to mention that I'm looking for solutions that would ""force"" the LHS of the equations to equal the RHS. I'm not an expert so I'm not sure if this is the right question to ask, but that's why I have it here :)","I was just playing around with some equations the other day and losing interest I started writing down what were mostly ""random"" equations at first. But, I realized that there's something special about them, they don't have solutions! At least, as far as I could tell. On the surface it seems there should be solutions to them, seeing they look simple; at any rate, couldn't we just ""define"" objects which would satisfy these equations? Similar to what was done when complex numbers were introduced? I can't say; anywho, here is a sample of what I have: $$ \tag{1} \sqrt{ix} = -1, \sqrt{ix} = -i, \sqrt{x} = -1 - i, \\ \sqrt{ix} = -1 - i, \sqrt{-ix} = -1 - i, \sqrt{-ix} = i - 1, \\ \sqrt{-ix} = -i $$ What do you think? Can we get any solutions? Can we define solutions? Thanks in advance. EDIT: I have to mention that I'm looking for solutions that would ""force"" the LHS of the equations to equal the RHS. I'm not an expert so I'm not sure if this is the right question to ask, but that's why I have it here :)",,"['real-analysis', 'complex-analysis']"
62,Convergence in $L^{\infty}$ norm implies convergence in $L^1$ norm,Convergence in  norm implies convergence in  norm,L^{\infty} L^1,"Let $\{f_n\}_{n\in \mathbb{N}}$ be a sequence of measurable functions on a measure space and $f$ measurable. Assume the measure space $X$ has finite measure. If $f_n$ converges to $f$ in $L^{\infty}$-norm , then $f_n$ converges to $f$ in $L^{1}$-norm. This is my approach: We know $||f_n-f||_{\infty} \to 0 $ and by definition $||f_n-f||_{\infty} =\inf\{M\geq 0: |f_n-f|\leq M \}.$ Then \begin{align} ||f_n-f||_1\ &=\int |f_n-f| dm\ &\leq \int|f_n|dm+\int|f|dm\ \end{align} I don't know how to proceed after that, any help would be appreciated.","Let $\{f_n\}_{n\in \mathbb{N}}$ be a sequence of measurable functions on a measure space and $f$ measurable. Assume the measure space $X$ has finite measure. If $f_n$ converges to $f$ in $L^{\infty}$-norm , then $f_n$ converges to $f$ in $L^{1}$-norm. This is my approach: We know $||f_n-f||_{\infty} \to 0 $ and by definition $||f_n-f||_{\infty} =\inf\{M\geq 0: |f_n-f|\leq M \}.$ Then \begin{align} ||f_n-f||_1\ &=\int |f_n-f| dm\ &\leq \int|f_n|dm+\int|f|dm\ \end{align} I don't know how to proceed after that, any help would be appreciated.",,"['real-analysis', 'measure-theory', 'convergence-divergence', 'lp-spaces']"
63,"$\int_0^1|f(x)-g(x)|dx=1$ for distinct $f,g\in S$",for distinct,"\int_0^1|f(x)-g(x)|dx=1 f,g\in S","Does there exists an infinite subset $S$ of $C([0,1],\mathbb{R})$ such   that $$\int_0^1|f(x)-g(x)|dx=1$$ for any distinct $f,g\in S$? I was guessing the the answer is yes. I can construct such a set with 3 functions, but can't really be generalized.","Does there exists an infinite subset $S$ of $C([0,1],\mathbb{R})$ such   that $$\int_0^1|f(x)-g(x)|dx=1$$ for any distinct $f,g\in S$? I was guessing the the answer is yes. I can construct such a set with 3 functions, but can't really be generalized.",,['real-analysis']
64,A sequence of singular measures converging weakly* to a continuous measure,A sequence of singular measures converging weakly* to a continuous measure,,"Can anyone provide a sequence of singular (w.r.t. Lebesgue measure) measures $\in\mathcal{M}([0,1])=C[0,1]^*$ converging $weakly^*$ to an absolutely continuous (w.r.t. Lebesgue measure) measure?","Can anyone provide a sequence of singular (w.r.t. Lebesgue measure) measures $\in\mathcal{M}([0,1])=C[0,1]^*$ converging $weakly^*$ to an absolutely continuous (w.r.t. Lebesgue measure) measure?",,"['real-analysis', 'functional-analysis', 'measure-theory', 'singular-measures']"
65,Proving formulas for $\cos(nx)$ and $\sin(nx)$,Proving formulas for  and,\cos(nx) \sin(nx),"How do I prove the following formulas? Let $n \in \mathbb{N}, x \in \mathbb{R}$ . Prove that: $$\cos(nx)=\sum_{j=0}^{[n/2]} (-1)^j {n \choose 2j} (\cos x)^{n-2j} (\sin x)^{2j}$$ $$\sin(nx)=\sum_{j=0}^{[(n-1)/2]} (-1)^j {n \choose 2j+1} (\cos x)^{n-2j-1} (\sin x)^{2j+1}$$",How do I prove the following formulas? Let . Prove that:,"n \in \mathbb{N}, x \in \mathbb{R} \cos(nx)=\sum_{j=0}^{[n/2]} (-1)^j {n \choose 2j} (\cos x)^{n-2j} (\sin x)^{2j} \sin(nx)=\sum_{j=0}^{[(n-1)/2]} (-1)^j {n \choose 2j+1} (\cos x)^{n-2j-1} (\sin x)^{2j+1}","['real-analysis', 'trigonometry']"
66,Contraction mapping does not hold in metric space,Contraction mapping does not hold in metric space,,"Let $X=\mathbb{Q}\cap [1,2]$, i.e $X$ is the set of rational number between 1 and 2 inclusive. We can consider $X$ to be a metric space by endowing it with the usual distance function, i.e for $x,y \in X$ we put $d(x,y)=|x-y|$. Now we define $f:X\rightarrow X$ by $f(x)=x-\dfrac{x^2-2}{2x}$. Ones should check that if$x\in X$ , then $f(x)\in X$ as well. This means checking that if $x$ is rational and in $[1,2]$ then $f(x)$ is also rational and in $[1,2]$. Prove that $f$ is a contraction mapping but $f$ does not has a fixed point.  This is my homework exercise, but I am not good at mathematics, so please feel freely helping me. Thank you very much !","Let $X=\mathbb{Q}\cap [1,2]$, i.e $X$ is the set of rational number between 1 and 2 inclusive. We can consider $X$ to be a metric space by endowing it with the usual distance function, i.e for $x,y \in X$ we put $d(x,y)=|x-y|$. Now we define $f:X\rightarrow X$ by $f(x)=x-\dfrac{x^2-2}{2x}$. Ones should check that if$x\in X$ , then $f(x)\in X$ as well. This means checking that if $x$ is rational and in $[1,2]$ then $f(x)$ is also rational and in $[1,2]$. Prove that $f$ is a contraction mapping but $f$ does not has a fixed point.  This is my homework exercise, but I am not good at mathematics, so please feel freely helping me. Thank you very much !",,"['real-analysis', 'metric-spaces', 'examples-counterexamples', 'fixed-point-theorems']"
67,How to approach number guessing game(with a twist) algorithm?,How to approach number guessing game(with a twist) algorithm?,,"I posted this on stackoverflow, but was advised to also post here. It's kind of a math/algo question so I think it's kind of stuck between both worlds of math and computer science.  I believe this to be ontopic but if not, please let me know and I'll delete it. Here's the link to the stackoverflow post. I am learning programming (python and algo’s) and was trying to work on a project that I find interesting.   I have created a few basic python scripts but I’m not sure how to approach a solution to a game I am trying to build. Here’s how the game will work: Users will be given items with a value. For example Apple = 1 Pears = 2 Oranges  = 3 They will then get a chance to choose any combo of them they like (e.g. 100 apples, 20 pears, and 1 orange).  The only input the computer gets is the total value (in this example, it's currently $143).  The computer will try to guess what they have. Which obviously it won’t be able to get correctly the first turn. Value  quantity(day1)  value(day1) Apple    1      100             100 Pears    2      20              40 Orange   3      1               3 Total           121             143 The next turn the user can modify their numbers but no more than 5% of the total quantity (or some other percent we may chose. I’ll use 5% for example.).  Using the above example, on day 2 of the game, the user returns a value of \$152 and \$164 on day 3. Here's an example. quantity(day2)  %change(day2)   value(day2) quantity(day3)  %change(day3)   value(day3) 104                             104         106                             106 21                              42          23                              46 2                               6           4                               12 127             4.96%           152         133             4.72%           164 (I hope the tables show up right, I had to manually space them so hopefully it's not just doing it on my screen; if it doesn't work let me know and I'll try to upload a screenshot). I am trying to see if I can figure out what the quantities are over time (assuming the user will have the patience to keep entering numbers). I know right now my only restriction is that the total value cannot be more than 5%, so I cannot be within 5% accuracy right now, so the user will be entering it forever. What I have done so far Here’s my solution so far (not much).  Basically I take all the values and figure out all the possible combos of them (I am done this part).  Then I take all the possible combos and put them in a database as a dictionary (so for example for \$143, there could be a dictionary entry {apple:143, Pears:0, Oranges :0}… all the way to {apple:0, Pears:1, Oranges :47}.  I do this each time I get a new number so I have a list of all possibilities. Here’s where I’m stuck.  Using the rules above, how can I figure out the best possible solution? I think I’ll need a fitness function that automatically compares the two days' data and removes any possibilities that have more than 5% variance of the previous days data. Questions: So my question with user changing the total and me having a list of all the probabilities, how should I approach this? What do I need to learn? Is there any algorithms out there  or theories that I can use that are applicable? Or, to help me understand my mistake, can you suggest what rules I can add to make this goal feasible (if it's not in its current state. I was thinking adding more fruits and saying they must pick at least 3, etc.)?  Also, I only have a vague understanding of genetic algorithms but I thought I could use them here; is there something I can use? I'm very very eager to learn so any advice or tips would be greatly appreciated (just please don't tell me this game is impossible). Thanks in advance. UPDATE: Getting feedback that this is hard to solve. So I thought I'd add another condition to the game that won't interfere with what the player is doing(game stays the same for them) but everyday the value of the fruits change price(randomly). Would that make it easier to solve? Because within a 5% movement and certain fruit value changes, only a few combo's are probable over time. Day 1, anything is possible and getting a close enough range is almost impossible, but as the prices of fruits change and the user can only choose a 5% change, then shouldn't(over time) the range be narrow and narrow. In the above example, if prices are volatile enough I think I could brute force a solution that gave me a range to guess in, but I'm trying to figure out if there's a more elegant solution or other solutions to keep narrowing this range over time.","I posted this on stackoverflow, but was advised to also post here. It's kind of a math/algo question so I think it's kind of stuck between both worlds of math and computer science.  I believe this to be ontopic but if not, please let me know and I'll delete it. Here's the link to the stackoverflow post. I am learning programming (python and algo’s) and was trying to work on a project that I find interesting.   I have created a few basic python scripts but I’m not sure how to approach a solution to a game I am trying to build. Here’s how the game will work: Users will be given items with a value. For example Apple = 1 Pears = 2 Oranges  = 3 They will then get a chance to choose any combo of them they like (e.g. 100 apples, 20 pears, and 1 orange).  The only input the computer gets is the total value (in this example, it's currently $143).  The computer will try to guess what they have. Which obviously it won’t be able to get correctly the first turn. Value  quantity(day1)  value(day1) Apple    1      100             100 Pears    2      20              40 Orange   3      1               3 Total           121             143 The next turn the user can modify their numbers but no more than 5% of the total quantity (or some other percent we may chose. I’ll use 5% for example.).  Using the above example, on day 2 of the game, the user returns a value of \$152 and \$164 on day 3. Here's an example. quantity(day2)  %change(day2)   value(day2) quantity(day3)  %change(day3)   value(day3) 104                             104         106                             106 21                              42          23                              46 2                               6           4                               12 127             4.96%           152         133             4.72%           164 (I hope the tables show up right, I had to manually space them so hopefully it's not just doing it on my screen; if it doesn't work let me know and I'll try to upload a screenshot). I am trying to see if I can figure out what the quantities are over time (assuming the user will have the patience to keep entering numbers). I know right now my only restriction is that the total value cannot be more than 5%, so I cannot be within 5% accuracy right now, so the user will be entering it forever. What I have done so far Here’s my solution so far (not much).  Basically I take all the values and figure out all the possible combos of them (I am done this part).  Then I take all the possible combos and put them in a database as a dictionary (so for example for \$143, there could be a dictionary entry {apple:143, Pears:0, Oranges :0}… all the way to {apple:0, Pears:1, Oranges :47}.  I do this each time I get a new number so I have a list of all possibilities. Here’s where I’m stuck.  Using the rules above, how can I figure out the best possible solution? I think I’ll need a fitness function that automatically compares the two days' data and removes any possibilities that have more than 5% variance of the previous days data. Questions: So my question with user changing the total and me having a list of all the probabilities, how should I approach this? What do I need to learn? Is there any algorithms out there  or theories that I can use that are applicable? Or, to help me understand my mistake, can you suggest what rules I can add to make this goal feasible (if it's not in its current state. I was thinking adding more fruits and saying they must pick at least 3, etc.)?  Also, I only have a vague understanding of genetic algorithms but I thought I could use them here; is there something I can use? I'm very very eager to learn so any advice or tips would be greatly appreciated (just please don't tell me this game is impossible). Thanks in advance. UPDATE: Getting feedback that this is hard to solve. So I thought I'd add another condition to the game that won't interfere with what the player is doing(game stays the same for them) but everyday the value of the fruits change price(randomly). Would that make it easier to solve? Because within a 5% movement and certain fruit value changes, only a few combo's are probable over time. Day 1, anything is possible and getting a close enough range is almost impossible, but as the prices of fruits change and the user can only choose a 5% change, then shouldn't(over time) the range be narrow and narrow. In the above example, if prices are volatile enough I think I could brute force a solution that gave me a range to guess in, but I'm trying to figure out if there's a more elegant solution or other solutions to keep narrowing this range over time.",,"['probability', 'real-analysis', 'number-theory', 'logic', 'algorithms']"
68,Open $\sigma$-compact sets with finite measure,Open -compact sets with finite measure,\sigma,"Let $X$ be locally compact Hausdorff space and let $\mu$ be positive Borel measure, finite on compacts, outer regular with respect to open subsets, for each Borel set, and inner regular with respect to compact subsets, for each open set and for each Borel with finite measure. Is it true that for every compact $F$ there exists an open $\sigma$-compact $G$ such $F\subset G$ and $G$ has finite measure. Thanks.","Let $X$ be locally compact Hausdorff space and let $\mu$ be positive Borel measure, finite on compacts, outer regular with respect to open subsets, for each Borel set, and inner regular with respect to compact subsets, for each open set and for each Borel with finite measure. Is it true that for every compact $F$ there exists an open $\sigma$-compact $G$ such $F\subset G$ and $G$ has finite measure. Thanks.",,['real-analysis']
69,The norm of Borel measures,The norm of Borel measures,,"I was looking on at the Convolution page on wikipedia and saw that it stated that we can define the convolution of two Borel measures of bounded variation on $\mathbb{R}^d$, $\mu$ and $\nu$, to be $$\int_{\mathbb{R}^d} f(x) d(\mu\ast \nu)(x) = \int_{\mathbb{R}^d} \int_{\mathbb{R}^d} f(x+y) d\mu(x) d\nu(y),$$ and that we have the result $$||\mu \ast \nu || \leq ||\mu|| ||\nu||.$$ I'm not sure what the second statement means though. Is there a natural norm for the space of Borel measures with bounded variation?","I was looking on at the Convolution page on wikipedia and saw that it stated that we can define the convolution of two Borel measures of bounded variation on $\mathbb{R}^d$, $\mu$ and $\nu$, to be $$\int_{\mathbb{R}^d} f(x) d(\mu\ast \nu)(x) = \int_{\mathbb{R}^d} \int_{\mathbb{R}^d} f(x+y) d\mu(x) d\nu(y),$$ and that we have the result $$||\mu \ast \nu || \leq ||\mu|| ||\nu||.$$ I'm not sure what the second statement means though. Is there a natural norm for the space of Borel measures with bounded variation?",,"['real-analysis', 'measure-theory']"
70,How to show that a limit vanishes,How to show that a limit vanishes,,"Let $1<p<\infty$, $f \in L^p([0,\infty))$. Why is it then true that $$\lim_{x\to\infty} \frac{1}{x^{1-\frac{1}{p}}} \left( \int_0^x f(t)dt\right) =0?$$ I know that from Hölder's inequality, we can get that $||f||_{L^1([0,\infty))} \leq ||f||_{L^p([0,\infty))} x^{1-\frac{1}{p}}, \; \forall x >0$, and I also think that this inequality must be strict, since equality would imply that $f$ is constant, which would contradict the fact that $f \in L^p$ on a domain with infinite measure. That's only a necessary condition though, and I'm not really sure how to proceed any further.","Let $1<p<\infty$, $f \in L^p([0,\infty))$. Why is it then true that $$\lim_{x\to\infty} \frac{1}{x^{1-\frac{1}{p}}} \left( \int_0^x f(t)dt\right) =0?$$ I know that from Hölder's inequality, we can get that $||f||_{L^1([0,\infty))} \leq ||f||_{L^p([0,\infty))} x^{1-\frac{1}{p}}, \; \forall x >0$, and I also think that this inequality must be strict, since equality would imply that $f$ is constant, which would contradict the fact that $f \in L^p$ on a domain with infinite measure. That's only a necessary condition though, and I'm not really sure how to proceed any further.",,['real-analysis']
71,Proving an integral identity: $\int\nolimits_{-\infty}^\infty x f(x)f(t-x) dx =\frac{t}{2} \int_{-\infty}^\infty f(x)f(t-x) dx $,Proving an integral identity:,\int\nolimits_{-\infty}^\infty x f(x)f(t-x) dx =\frac{t}{2} \int_{-\infty}^\infty f(x)f(t-x) dx ,"Let $f$ be a nonnegative (probably not needed) function on $\mathbb{R}$ such that for all $t$, $xf(x)f(t-x)$ and $f(x)f(t-x)$ are both integrable in $x$. Is it true that $$ \int\nolimits_{-\infty}^\infty x f(x)f(t-x) dx =\frac{t}{2} \int_{-\infty}^\infty f(x)f(t-x) dx $$ for all $t$? I found that this is true if $f(x)=e^{-|x|} $ or $\frac{1}{1+x^2}$.","Let $f$ be a nonnegative (probably not needed) function on $\mathbb{R}$ such that for all $t$, $xf(x)f(t-x)$ and $f(x)f(t-x)$ are both integrable in $x$. Is it true that $$ \int\nolimits_{-\infty}^\infty x f(x)f(t-x) dx =\frac{t}{2} \int_{-\infty}^\infty f(x)f(t-x) dx $$ for all $t$? I found that this is true if $f(x)=e^{-|x|} $ or $\frac{1}{1+x^2}$.",,"['real-analysis', 'integration', 'convolution']"
72,Does the fact that every interval in $\mathbb{R}$ is connected implies that $\mathbb{R}$ is order-complete?,Does the fact that every interval in  is connected implies that  is order-complete?,\mathbb{R} \mathbb{R},"Suppose that every open interval in $\mathbb{R}$ is a connected set. Does this implies the least upper bound axiom? (i.e every non-empty subset of $\mathbb{R}$ which is bounded above has a least upper bound) Is this true? in such case, how would you prove this?","Suppose that every open interval in $\mathbb{R}$ is a connected set. Does this implies the least upper bound axiom? (i.e every non-empty subset of $\mathbb{R}$ which is bounded above has a least upper bound) Is this true? in such case, how would you prove this?",,"['real-analysis', 'general-topology']"
73,How to perform this sum,How to perform this sum,,"I encountered this sum $$S(N,j)= \frac{2 \sqrt{2}h(-1)^j}{N+1}\cdot\sum _{n=1}^{\frac{N}{2}} \frac{\sin ^2\left(\frac{\pi  j n}{N+1}\right)}{\sqrt{2 h^2+\cos \left(\frac{2 \pi  n}{N+1}\right)+1}},$$ where $h\in \mathbb{R}^+, \{n,j\}\in \mathbb{Z}^+$ and $N\to \infty.$ It has the curious property that for a fixed $h$ (say $5/4$ ) as $N$ increases, the value of the sum seems to be the same for all values of $j$ other than the first few ( $j=1,2,3,\ldots$ ) and the last few $j=N,N-1,N-2,\ldots$ , otherwise there is a single value $a$ , which alternates in sign i.e. $$S(N,j)=(\ldots, a,-a,a,-a,\ldots).$$ Is it possible to obtain an expression for $S(N,j)$ by summing over $n$ , either for finite $N$ or if that's not possible is it possible to obtain $$\lim_{N\to \infty} S(N,j)$$ or at least the value of $|a|$ ?","I encountered this sum where and It has the curious property that for a fixed (say ) as increases, the value of the sum seems to be the same for all values of other than the first few ( ) and the last few , otherwise there is a single value , which alternates in sign i.e. Is it possible to obtain an expression for by summing over , either for finite or if that's not possible is it possible to obtain or at least the value of ?","S(N,j)= \frac{2 \sqrt{2}h(-1)^j}{N+1}\cdot\sum _{n=1}^{\frac{N}{2}}
\frac{\sin ^2\left(\frac{\pi  j n}{N+1}\right)}{\sqrt{2 h^2+\cos \left(\frac{2 \pi  n}{N+1}\right)+1}}, h\in \mathbb{R}^+, \{n,j\}\in \mathbb{Z}^+ N\to \infty. h 5/4 N j j=1,2,3,\ldots j=N,N-1,N-2,\ldots a S(N,j)=(\ldots, a,-a,a,-a,\ldots). S(N,j) n N \lim_{N\to \infty} S(N,j) |a|","['real-analysis', 'summation', 'riemann-sum']"
74,"Prove that $\log\left(1+\frac{1}{x^2}\right)$ is $L^1$ on $(0,\infty)$.",Prove that  is  on .,"\log\left(1+\frac{1}{x^2}\right) L^1 (0,\infty)","Let $f(x) = \log(1+\frac{1}{x^2})$ . I am trying to show $f \in L^1(\mathbb{R}^+)$ where $\mathbb{R}^+ = (0,\infty)$ . What I have done so far Since $f$ is strictly positive, I just have to show that $\int_{\mathbb{R}^+}f < \infty$ . I already proved that this is true on $(\varepsilon,\infty)$ for any $\varepsilon>0$ : since $\log(1+1/x^2) \leq 1/x^2$ for all $x > 0$ , we have $$ \int_{(\varepsilon,\infty)}\log\left(1+\frac{1}{x^2}\right)dx \leq \int_{(\varepsilon,\infty)}\frac{1}{x^2}dx = \frac{1}{\varepsilon}, $$ so $\int_{(\varepsilon,\infty)}f < \infty$ , where I used the Riemann integrability of $1/x^2$ . But here I run into trouble where I can't figure out how to bring the lower bound to zero, as $1/\varepsilon$ blows up as $\varepsilon \to 0$ . I attempted to use the fact that for any $\alpha >0$ , $$ \lim_{x \to \infty}\frac{\log(1+x)}{x^{\alpha}} = 0, $$ i.e. there must exist an $M_{\alpha}>0$ such that $x>M_{\alpha}$ implies that $\log(1+x)\leq x^{\alpha}$ . Letting $z = 1/x^2$ , we see that for $x<1/\sqrt{M_{\alpha}}$ we have $$ \log\left(1+\frac{1}{x^2}\right)\leq \frac{1}{x^{2\alpha}}. $$ Then we set $\alpha = 1/3$ or something like that, so for $x < 1/\sqrt{M_{1/3}} = \varepsilon$ we have $f(x)\leq 1/x^{2/3}$ . I'm thinking then to use some sort of Monotone Convergence Theorem argument, i.e. let $f_n(x) = f(x)\chi_{[1/n,\varepsilon]}$ , making sure to start at large enough $n$ such that $1/n < \varepsilon$ , then $$ \int_{(0,\varepsilon)}f_n(x)dx = \int_{(0,\varepsilon)}\log\left(1 + \frac{1}{x^2}\right)\chi_{[1/n,\varepsilon]}dx \leq \int_{1/n}^{\varepsilon}\frac{1}{x^{2/3}}dx = 3\left(\sqrt[3]{\varepsilon} - \frac{1}{\sqrt[3]{n}}\right), $$ where I again used Riemann integrability, which implies Lebesgue integrability. Sending $n \to \infty$ and using monotone convergence theorem we have that $\int_{(0,\varepsilon)}f(x)dx \leq 3 \sqrt[3]{\varepsilon}< \infty$ . My main question I have shown then that $f$ is Lebesgue integrable on $(0,\varepsilon)$ for sufficiently small $\varepsilon$ , and also that it is Lebesgue integrable on $(\varepsilon,\infty)$ for any $\varepsilon>0$ . Is it possible to ""glue"" these results together to get that $f\in L^1(\mathbb{R}^+)$ ? This solution seems kind of sloppy and disconnected to me, but it's the closest I could come to a solution and I'd really appreciate any help someone could provide. Please let me know if something is unclear, thank you!","Let . I am trying to show where . What I have done so far Since is strictly positive, I just have to show that . I already proved that this is true on for any : since for all , we have so , where I used the Riemann integrability of . But here I run into trouble where I can't figure out how to bring the lower bound to zero, as blows up as . I attempted to use the fact that for any , i.e. there must exist an such that implies that . Letting , we see that for we have Then we set or something like that, so for we have . I'm thinking then to use some sort of Monotone Convergence Theorem argument, i.e. let , making sure to start at large enough such that , then where I again used Riemann integrability, which implies Lebesgue integrability. Sending and using monotone convergence theorem we have that . My main question I have shown then that is Lebesgue integrable on for sufficiently small , and also that it is Lebesgue integrable on for any . Is it possible to ""glue"" these results together to get that ? This solution seems kind of sloppy and disconnected to me, but it's the closest I could come to a solution and I'd really appreciate any help someone could provide. Please let me know if something is unclear, thank you!","f(x) = \log(1+\frac{1}{x^2}) f \in L^1(\mathbb{R}^+) \mathbb{R}^+ = (0,\infty) f \int_{\mathbb{R}^+}f < \infty (\varepsilon,\infty) \varepsilon>0 \log(1+1/x^2) \leq 1/x^2 x > 0 
\int_{(\varepsilon,\infty)}\log\left(1+\frac{1}{x^2}\right)dx \leq \int_{(\varepsilon,\infty)}\frac{1}{x^2}dx = \frac{1}{\varepsilon},
 \int_{(\varepsilon,\infty)}f < \infty 1/x^2 1/\varepsilon \varepsilon \to 0 \alpha >0 
\lim_{x \to \infty}\frac{\log(1+x)}{x^{\alpha}} = 0,
 M_{\alpha}>0 x>M_{\alpha} \log(1+x)\leq x^{\alpha} z = 1/x^2 x<1/\sqrt{M_{\alpha}} 
\log\left(1+\frac{1}{x^2}\right)\leq \frac{1}{x^{2\alpha}}.
 \alpha = 1/3 x < 1/\sqrt{M_{1/3}} = \varepsilon f(x)\leq 1/x^{2/3} f_n(x) = f(x)\chi_{[1/n,\varepsilon]} n 1/n < \varepsilon 
\int_{(0,\varepsilon)}f_n(x)dx = \int_{(0,\varepsilon)}\log\left(1 + \frac{1}{x^2}\right)\chi_{[1/n,\varepsilon]}dx \leq \int_{1/n}^{\varepsilon}\frac{1}{x^{2/3}}dx = 3\left(\sqrt[3]{\varepsilon} - \frac{1}{\sqrt[3]{n}}\right),
 n \to \infty \int_{(0,\varepsilon)}f(x)dx \leq 3 \sqrt[3]{\varepsilon}< \infty f (0,\varepsilon) \varepsilon (\varepsilon,\infty) \varepsilon>0 f\in L^1(\mathbb{R}^+)","['real-analysis', 'lebesgue-integral']"
75,What algebraic manipulations are needed for real analysis?,What algebraic manipulations are needed for real analysis?,,"What level of algebraic manipulations are needed for real analysis and higher math, and how should one attain it? I'm able to solve most proofs in typical Real Analysis textbooks or university exams.  Yet, despite that, when presented with a challenging, but elementary, algebraic manipulation (i.e. the kind seen on olympiads), I sometimes struggle. Take, for example, some of the problems on this AoPS Intermediate Algebra Test , such as: Find all solutions (real and complex) to $\sqrt{x − 5} + \sqrt{x + 15} = 10$ and to $\sqrt[3]{x^2 - 1} + \frac {20}{\sqrt[3]{x^2 - 1}} = 12$ Simplify $\sqrt[4]{161 − 72\sqrt 5}$ or this one from Gelfand's Algebra: How to factor $a^{3} + b^{3} + c^{3} - 3abc$ into a product of polynomials I find these and similar problems quite challenging. Should I go back and build up these elementary algebraic manipulation skills before proceeding further with higher math?  If so, how?  When and how did you built these skills? In the spirit of math.SE, I'll share my ""work"" on this question so far: It would seem yes, go back and build these foundations before proceeding , because you need the foundations before building. But: The fact that you're able to succeed at math well beyond that raises doubts if these really are foundations, or more contest style challenges. These algebraic manipulations, beyond the very basics, don't seem to be covered in any standard text, at any level, except for contest math .  High school algebra and precalculus texts do not teach the advanced manipulations needed to solve problems like the above.  And university level analysis, linear algebra, abstract algebra start after them. All of which suggests that this level of manipulation is primarily part of contest math , but not generally a foundation or component of ""standard"" math.  It's well established the difference: contest math revolves around ""tricks,"" usually to remove deliberate obfuscation; standard math revolves around underlying concepts and techniques which expose a unity and clarity Support for the above: When looking for resources on problems like the above, the results are almost entirely contest math sites (even the names, like ""Simon's Favorite Factoring Trick,"" are from contest math). Still: Eventually, students of ""standard"" math need to be able to use the techniques, eventually.  There have been problems, such as What is the locus of points in the plane $\{v : v \cdot (v-a) = 0\}$ for fixed $a$? or simplfying $xy−bx−ay−ab=0$ ,  where I get stuck on the manipulations.  Do they just pick them up somehow? Do they become obvious once you've learn enough e.g. analysis and algebra? Update: Another example of where this came up in analysis is How to solve a particular system of non-linear multivariate equations? To fill this gap, I invested some effort in going through books and resources on algebraic manipulations for contest math, and while I found it helpful, it certainly doesn't provide the satisfaction or insight as e.g. proving problems in analysis.  So I'm confused whether I should return to analysis or continue working these manipulations, and, if I do, when and how can I pick these manipulations up?  When and how have others done so?","What level of algebraic manipulations are needed for real analysis and higher math, and how should one attain it? I'm able to solve most proofs in typical Real Analysis textbooks or university exams.  Yet, despite that, when presented with a challenging, but elementary, algebraic manipulation (i.e. the kind seen on olympiads), I sometimes struggle. Take, for example, some of the problems on this AoPS Intermediate Algebra Test , such as: Find all solutions (real and complex) to and to Simplify or this one from Gelfand's Algebra: How to factor $a^{3} + b^{3} + c^{3} - 3abc$ into a product of polynomials I find these and similar problems quite challenging. Should I go back and build up these elementary algebraic manipulation skills before proceeding further with higher math?  If so, how?  When and how did you built these skills? In the spirit of math.SE, I'll share my ""work"" on this question so far: It would seem yes, go back and build these foundations before proceeding , because you need the foundations before building. But: The fact that you're able to succeed at math well beyond that raises doubts if these really are foundations, or more contest style challenges. These algebraic manipulations, beyond the very basics, don't seem to be covered in any standard text, at any level, except for contest math .  High school algebra and precalculus texts do not teach the advanced manipulations needed to solve problems like the above.  And university level analysis, linear algebra, abstract algebra start after them. All of which suggests that this level of manipulation is primarily part of contest math , but not generally a foundation or component of ""standard"" math.  It's well established the difference: contest math revolves around ""tricks,"" usually to remove deliberate obfuscation; standard math revolves around underlying concepts and techniques which expose a unity and clarity Support for the above: When looking for resources on problems like the above, the results are almost entirely contest math sites (even the names, like ""Simon's Favorite Factoring Trick,"" are from contest math). Still: Eventually, students of ""standard"" math need to be able to use the techniques, eventually.  There have been problems, such as What is the locus of points in the plane $\{v : v \cdot (v-a) = 0\}$ for fixed $a$? or simplfying ,  where I get stuck on the manipulations.  Do they just pick them up somehow? Do they become obvious once you've learn enough e.g. analysis and algebra? Update: Another example of where this came up in analysis is How to solve a particular system of non-linear multivariate equations? To fill this gap, I invested some effort in going through books and resources on algebraic manipulations for contest math, and while I found it helpful, it certainly doesn't provide the satisfaction or insight as e.g. proving problems in analysis.  So I'm confused whether I should return to analysis or continue working these manipulations, and, if I do, when and how can I pick these manipulations up?  When and how have others done so?",\sqrt{x − 5} + \sqrt{x + 15} = 10 \sqrt[3]{x^2 - 1} + \frac {20}{\sqrt[3]{x^2 - 1}} = 12 \sqrt[4]{161 − 72\sqrt 5} xy−bx−ay−ab=0,"['real-analysis', 'algebra-precalculus', 'soft-question', 'contest-math', 'self-learning']"
76,$\int_0^\infty\frac{u}{2\nu^2}\left(u+\left(u^2+\nu^2\right)^\frac{1}{2}\right)\left(e^{-u}-e^{-\left(u^2+\nu^2\right)^\frac{1}{2}}\right)\sin(ut)du$,,\int_0^\infty\frac{u}{2\nu^2}\left(u+\left(u^2+\nu^2\right)^\frac{1}{2}\right)\left(e^{-u}-e^{-\left(u^2+\nu^2\right)^\frac{1}{2}}\right)\sin(ut)du,"Evaluating $$ F_\nu(t) := \int_0^\infty \frac{u}{2\nu^2} \left( u+ \left( u^2+\nu^2 \right)^\frac{1}{2}  \right)  \left(  e^{-u} - e^{-\left(u^2+\nu^2\right)^\frac{1}{2}} \right) \sin \left( ut \right) \, \mathrm{d} u \, ,  $$ where $\nu\ge 0$ is a parameter. Considering the simplistic limit when $\nu \to 0$ , it can readily be shown that $$ \lim_{\nu\to 0} F_\nu (t) = \frac{1}{2} \int_0^\infty u\, e^{-u} \sin \left(ut\right) \, \mathrm{d} u = \frac{t}{\left( 1+t^2 \right)^2} \, . $$ This integral arises from solving a fluid mechanical problem involving dual integral equations. The full problem has previously been asked in a separate question . What I tried is to express the sine and exponential functions in terms of series expansions. This yield double sums involving hypergeometric functions. However, an analytical evaluation of the resulting sums does not seen to be within reach. Assuming that $\alpha \ll 1$ and performing Taylor expansion of $F_\nu(t)$ around $\alpha=0$ leads to a series of terms whose integrals diverge (except the terms $\propto \alpha^2$ ), making a Taylor-expansion-based approach obsolete. I am wondering whether there is a clever way to handle this improper integral. Any help is highly appreciated.","Evaluating where is a parameter. Considering the simplistic limit when , it can readily be shown that This integral arises from solving a fluid mechanical problem involving dual integral equations. The full problem has previously been asked in a separate question . What I tried is to express the sine and exponential functions in terms of series expansions. This yield double sums involving hypergeometric functions. However, an analytical evaluation of the resulting sums does not seen to be within reach. Assuming that and performing Taylor expansion of around leads to a series of terms whose integrals diverge (except the terms ), making a Taylor-expansion-based approach obsolete. I am wondering whether there is a clever way to handle this improper integral. Any help is highly appreciated.","
F_\nu(t) :=
\int_0^\infty \frac{u}{2\nu^2} \left( u+ \left( u^2+\nu^2 \right)^\frac{1}{2}  \right) 
\left( 
e^{-u} - e^{-\left(u^2+\nu^2\right)^\frac{1}{2}}
\right) \sin \left( ut \right) \, \mathrm{d} u \, , 
 \nu\ge 0 \nu \to 0 
\lim_{\nu\to 0}
F_\nu (t) = \frac{1}{2} \int_0^\infty u\, e^{-u} \sin \left(ut\right) \, \mathrm{d} u
= \frac{t}{\left( 1+t^2 \right)^2} \, .
 \alpha \ll 1 F_\nu(t) \alpha=0 \propto \alpha^2","['real-analysis', 'calculus', 'integration', 'complex-analysis', 'improper-integrals']"
77,(Grafakos 2.2.12) Prove that all Schwartz functions $f$ on $\Bbb R^n$ satisfy this inequality,(Grafakos 2.2.12) Prove that all Schwartz functions  on  satisfy this inequality,f \Bbb R^n,"Let $1 \leq p \leq \infty $ and let $p'$ thus $\frac{1}{p} + \frac{1}{p'}=1$ . $\mathcal{S}(\mathbb R^n)$ is the Schwartz space defined as the class of all $C^\infty$ functions $\varphi:\Bbb R^n\rightarrow \mathbb C$ such that $$\sup_{x\in\mathbb R^n}|x^\beta \partial^\alpha \varphi(x)|<\infty,$$ for all multi-indices $\alpha, \beta\in\mathbb N^n$ Prove that all Schwartz functions $f$ on $R^n$ satisfy this inequality $$\|f\|_{\infty}^2 \leq \sum_{|\alpha + \beta|=n} \|\partial^\alpha f\|_p\|\partial^\beta f\|_{p^{'}}$$ where the sum is taken over all pairs of multi-indices $\alpha$ and $\beta$ whose sum has size $n$ . My try: I have already proved that $\|f\|_{\infty}^2 \leq 2\|f\|_p \|f\|_{p^{'}}$ but I don't know how to continue. Could someone help me? I am allowed to use only the theorems a definitions of that chapter of the book.",Let and let thus . is the Schwartz space defined as the class of all functions such that for all multi-indices Prove that all Schwartz functions on satisfy this inequality where the sum is taken over all pairs of multi-indices and whose sum has size . My try: I have already proved that but I don't know how to continue. Could someone help me? I am allowed to use only the theorems a definitions of that chapter of the book.,"1 \leq p \leq \infty  p' \frac{1}{p} + \frac{1}{p'}=1 \mathcal{S}(\mathbb R^n) C^\infty \varphi:\Bbb R^n\rightarrow \mathbb C \sup_{x\in\mathbb R^n}|x^\beta \partial^\alpha \varphi(x)|<\infty, \alpha, \beta\in\mathbb N^n f R^n \|f\|_{\infty}^2 \leq \sum_{|\alpha + \beta|=n} \|\partial^\alpha f\|_p\|\partial^\beta f\|_{p^{'}} \alpha \beta n \|f\|_{\infty}^2 \leq 2\|f\|_p \|f\|_{p^{'}}","['real-analysis', 'analysis', 'fourier-analysis', 'harmonic-analysis']"
78,Prove that $\nu$ is absolutely continuous w.r.t. $\mu$ iff $\sum \alpha_j^2<\infty$,Prove that  is absolutely continuous w.r.t.  iff,\nu \mu \sum \alpha_j^2<\infty,"This is question 3 in Chapter 4.12 from Barry Simon - Real analysis I tried to define $ f_j : \{0,1\} \to \mathbb{R} $ where $n$ means that it is a function from $j$ th $\{0,1\}$ in the product to $\mathbb{R}$ . It is given by $$ f_j(0)=2p_j \ \ \ f_j(1)=2(1-p_j)$$ Finally, let $f=\otimes f_j$ which gives me, by Kolmogorov Consistency Theorem, $d\nu=fd\mu$ (???). But, I believe this is wrong or I am missing something because I didn't even use the assumption. Idea behind defining $f_j$ in this way was, consider $\{0,1\}^N$ then for example for the point $(1,1,...1)$ the integral gives ( $f^N=\otimes_{j=1}^N f_j$ ) $$ \int_{\{(1,1,...,1)\}}f^N(x)d\mu(x)=\prod_{j=1}^N \frac{1}{2}2(1-p_j)=\int_{\{(1,1,...,1)\}}d\nu(x) $$ Then I tried to find counter example but I couldn't even find a counter example for the case $\alpha_j=1/4$ for all $j$ . Maybe we can use the fact $X=\{0,1\}^\infty$ is Cantor set in product topology? $d\nu_p$ should be $d\mu_p$ obviously. Any hint and solution is appreciated.","This is question 3 in Chapter 4.12 from Barry Simon - Real analysis I tried to define where means that it is a function from th in the product to . It is given by Finally, let which gives me, by Kolmogorov Consistency Theorem, (???). But, I believe this is wrong or I am missing something because I didn't even use the assumption. Idea behind defining in this way was, consider then for example for the point the integral gives ( ) Then I tried to find counter example but I couldn't even find a counter example for the case for all . Maybe we can use the fact is Cantor set in product topology? should be obviously. Any hint and solution is appreciated."," f_j : \{0,1\} \to \mathbb{R}  n j \{0,1\} \mathbb{R}  f_j(0)=2p_j \ \ \ f_j(1)=2(1-p_j) f=\otimes f_j d\nu=fd\mu f_j \{0,1\}^N (1,1,...1) f^N=\otimes_{j=1}^N f_j  \int_{\{(1,1,...,1)\}}f^N(x)d\mu(x)=\prod_{j=1}^N \frac{1}{2}2(1-p_j)=\int_{\{(1,1,...,1)\}}d\nu(x)  \alpha_j=1/4 j X=\{0,1\}^\infty d\nu_p d\mu_p","['real-analysis', 'measure-theory', 'probability-distributions']"
79,Can A function grow quicker than another but never catch up to it,Can A function grow quicker than another but never catch up to it,,"I know this is a bit of a strange question, but it is one that has been on my mind for a little bit now. If we have two real valued functions f(x) and g(x) and they are both everywhere continuous and differentiable, could we choose f(x) and g(x) such that three conditions are satisfied f(x) > g(x) for all x in R g'(x) > f'(x) for all x in R f(x) and g(x) both diverge as x tends to infinity Essentially, I'm asking if g(x) can grow infinitely but never catch up to f(x)? I know this problem would be simple if f(x) and g(x) converged, but I am curious about if these criterion could be met while maintaining divergence. My initial thought is that no such functions exist, but I am not sure how I could prove that.  If such functions did exist, I suspect g(x) would need to be ln(x) or something of the like, but I am not convinced it is possible for these criterion to all be met. If anyone has insight either way, that would be extremely helpful.","I know this is a bit of a strange question, but it is one that has been on my mind for a little bit now. If we have two real valued functions f(x) and g(x) and they are both everywhere continuous and differentiable, could we choose f(x) and g(x) such that three conditions are satisfied f(x) > g(x) for all x in R g'(x) > f'(x) for all x in R f(x) and g(x) both diverge as x tends to infinity Essentially, I'm asking if g(x) can grow infinitely but never catch up to f(x)? I know this problem would be simple if f(x) and g(x) converged, but I am curious about if these criterion could be met while maintaining divergence. My initial thought is that no such functions exist, but I am not sure how I could prove that.  If such functions did exist, I suspect g(x) would need to be ln(x) or something of the like, but I am not convinced it is possible for these criterion to all be met. If anyone has insight either way, that would be extremely helpful.",,"['real-analysis', 'calculus']"
80,Compute the Fourier transform of $(x_{1}+ix_{2})^{-1}$ in $S'(\mathbb{R}^{2})$ (as a tempered distribution).,Compute the Fourier transform of  in  (as a tempered distribution).,(x_{1}+ix_{2})^{-1} S'(\mathbb{R}^{2}),"I am trying to compute the Fourier transform of $(x_{1}+ix_{2})^{-1}$ in $S'(\mathbb{R}^{2})$ . i.e. as a tempered distribution. It might be useful to note that for $\mu \in S'(\mathbb{R}^{2})$ and $\psi \in S(\mathbb{R}^{2})$ we define $\langle\hat{\mu},\psi\rangle=\langle\mu,\hat{\psi}\rangle$ . In my attempt, I noted that the definition of the Fourier transform in $S(\mathbb{R}^{2})$ : $$ \hat{f}(\lambda)=\int_{\mathbb{R}^{2}}f(x)e^{-i \lambda \cdot x} dx, $$ gave us that $\widehat{(-i \partial_{1}+\partial_{2}) \delta}=x_{1}+ix_{2}$ . I'm not sure how to use this fact to help me complete the problem. Any help would be greatly appreciated.","I am trying to compute the Fourier transform of in . i.e. as a tempered distribution. It might be useful to note that for and we define . In my attempt, I noted that the definition of the Fourier transform in : gave us that . I'm not sure how to use this fact to help me complete the problem. Any help would be greatly appreciated.","(x_{1}+ix_{2})^{-1} S'(\mathbb{R}^{2}) \mu \in S'(\mathbb{R}^{2}) \psi \in S(\mathbb{R}^{2}) \langle\hat{\mu},\psi\rangle=\langle\mu,\hat{\psi}\rangle S(\mathbb{R}^{2}) 
\hat{f}(\lambda)=\int_{\mathbb{R}^{2}}f(x)e^{-i \lambda \cdot x} dx,
 \widehat{(-i \partial_{1}+\partial_{2}) \delta}=x_{1}+ix_{2}","['real-analysis', 'functional-analysis', 'fourier-analysis', 'fourier-transform', 'distribution-theory']"
81,High dimensional generalizations of $\int_{\sqrt{2} }^{\sqrt{3} } \frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } dy =\frac{5\pi^2}{96}$,High dimensional generalizations of,\int_{\sqrt{2} }^{\sqrt{3} } \frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } dy =\frac{5\pi^2}{96},"Let $Q=n_1+n_2+n_3+1$ , $\mathbf{s}=(n_1,n_2,n_3)$ . Define $$ A(\mathbf{s}) =\int_{D}\prod_{n=1}^{Q-1}\frac{1}{1+x_n^2}\int_{1}^{\infty}\left(Q+\sum_{n=1}^{Q-1}x_n^2 +y^2\right)^{-1}\mathrm{d}y \text{d}x_i. $$ Where $D=[0,\infty]^{n_1}\times[0,1]^{n_2} \times[1,\infty]^{n_3}\subset\mathbb{R}^{Q-1}$ , $\mathrm{d}x_i =\prod_{n=1}^{Q-1} \text{d}x_n$ . Special case. For $\mathbf{s}=(0,0,n_3)$ , we have $$ A(\mathbf{s}) =\frac{1}{Q}\left ( \frac{\pi}{4}  \right )^Q. $$ Question 1 Prove $$ \pi^{-Q}A(\mathbf{s})\in\mathbb{Q}. $$ My ultimate goal is to evaluate $A(\mathbf{s})$ . Numerical calculations suggest that $$A(1,0,0)=\frac{\pi^2}{12} \quad A(0,1,0)=\frac{5\pi^2}{96}\quad A(0,0,1)=\frac{\pi^2}{32}$$ $$A(2,0,0)=\frac{\pi^3}{32} \quad A(1,1,0)=\frac{\pi^3}{80}$$ $$A(0,3,0)=\frac{93\pi^4}{35840} \qquad A(0,4,0)=\frac{193\pi^5}{322560}$$ Actually, if we explicit calculate the multiple integrals, it yields $$ \begin{aligned} &\int_{\sqrt{2} }^{\sqrt{3} }  \frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } \text{d}y =\frac{5\pi^2}{96},\\ &\frac{\pi}{6} \int_{\sqrt{3} }^{\sqrt{5} }  \frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } \text{d}y -\int_{2}^{\sqrt{5} }  \frac{\displaystyle{\arctan (y)\arctan \sqrt{\frac{y^2-4}{y^2-2} } } }{(y^2-1)\sqrt{y^2-2} } \text{d}y=\frac{11\pi^3}{5760},\\ &\frac{\pi}{6} \int_{\sqrt{3} }^{\sqrt{5} }  \frac{\arctan\left(y\sqrt{2+y^2} \right)}{(y^2-1)\sqrt{y^2-2} } \text{d}y -\int_{2}^{\sqrt{5} }  \frac{\displaystyle{\arctan\left(y\sqrt{2+y^2}\right)\arctan \sqrt{\frac{y^2-4}{y^2-2} } } }{(y^2-1)\sqrt{y^2-2} } \text{d}y=\frac{\pi^3}{420}. \end{aligned} $$ Are there any other simple results? For $Q=4$ , we may meet some 'troubles', such as this one: $$ \int_{0}^{1} \int_{1}^{\sqrt{2} }  \frac{u\left(\pi-2\arctan\sqrt{u^4-1}-2\arctan \sqrt{\frac{u^2-1}{u^2+1} } \right) \arctan \sqrt{4+u^2+v^2}  } {(1+v^2)\sqrt{1+u^2}(2+u^2) \sqrt{4+u^2+v^2}  } \text{d}u\text{d}v. $$ I can hardly convert into a 'simple' form. Question 2. Can we evaluate a more general family of this kind of integrals? $$A(\alpha,\mathbf{s}) =\int_{D}\prod_{n=1}^{Q-1}\frac{1}{\alpha^2+x_n^2}\int_{1}^{\infty}\left(\alpha^2 Q+\sum_{n=1}^{Q-1}x_n^2 +y^2\right)^{-1}\mathrm{d}y \text{d}x_i.$$","Let , . Define Where , . Special case. For , we have Question 1 Prove My ultimate goal is to evaluate . Numerical calculations suggest that Actually, if we explicit calculate the multiple integrals, it yields Are there any other simple results? For , we may meet some 'troubles', such as this one: I can hardly convert into a 'simple' form. Question 2. Can we evaluate a more general family of this kind of integrals?","Q=n_1+n_2+n_3+1 \mathbf{s}=(n_1,n_2,n_3) 
A(\mathbf{s})
=\int_{D}\prod_{n=1}^{Q-1}\frac{1}{1+x_n^2}\int_{1}^{\infty}\left(Q+\sum_{n=1}^{Q-1}x_n^2 +y^2\right)^{-1}\mathrm{d}y
\text{d}x_i.
 D=[0,\infty]^{n_1}\times[0,1]^{n_2}
\times[1,\infty]^{n_3}\subset\mathbb{R}^{Q-1} \mathrm{d}x_i
=\prod_{n=1}^{Q-1} \text{d}x_n \mathbf{s}=(0,0,n_3) 
A(\mathbf{s})
=\frac{1}{Q}\left ( \frac{\pi}{4}  \right )^Q.
 
\pi^{-Q}A(\mathbf{s})\in\mathbb{Q}.
 A(\mathbf{s}) A(1,0,0)=\frac{\pi^2}{12} \quad A(0,1,0)=\frac{5\pi^2}{96}\quad A(0,0,1)=\frac{\pi^2}{32} A(2,0,0)=\frac{\pi^3}{32} \quad A(1,1,0)=\frac{\pi^3}{80} A(0,3,0)=\frac{93\pi^4}{35840} \qquad A(0,4,0)=\frac{193\pi^5}{322560} 
\begin{aligned}
&\int_{\sqrt{2} }^{\sqrt{3} } 
\frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } \text{d}y
=\frac{5\pi^2}{96},\\
&\frac{\pi}{6} \int_{\sqrt{3} }^{\sqrt{5} } 
\frac{\arctan(y)}{(y^2-1)\sqrt{y^2-2} } \text{d}y
-\int_{2}^{\sqrt{5} } 
\frac{\displaystyle{\arctan (y)\arctan \sqrt{\frac{y^2-4}{y^2-2} } } }{(y^2-1)\sqrt{y^2-2} }
\text{d}y=\frac{11\pi^3}{5760},\\
&\frac{\pi}{6} \int_{\sqrt{3} }^{\sqrt{5} } 
\frac{\arctan\left(y\sqrt{2+y^2} \right)}{(y^2-1)\sqrt{y^2-2} } \text{d}y
-\int_{2}^{\sqrt{5} } 
\frac{\displaystyle{\arctan\left(y\sqrt{2+y^2}\right)\arctan \sqrt{\frac{y^2-4}{y^2-2} } } }{(y^2-1)\sqrt{y^2-2} }
\text{d}y=\frac{\pi^3}{420}.
\end{aligned}
 Q=4 
\int_{0}^{1} \int_{1}^{\sqrt{2} } 
\frac{u\left(\pi-2\arctan\sqrt{u^4-1}-2\arctan \sqrt{\frac{u^2-1}{u^2+1} }
\right) \arctan \sqrt{4+u^2+v^2}  }
{(1+v^2)\sqrt{1+u^2}(2+u^2) \sqrt{4+u^2+v^2}  } \text{d}u\text{d}v.
 A(\alpha,\mathbf{s})
=\int_{D}\prod_{n=1}^{Q-1}\frac{1}{\alpha^2+x_n^2}\int_{1}^{\infty}\left(\alpha^2 Q+\sum_{n=1}^{Q-1}x_n^2 +y^2\right)^{-1}\mathrm{d}y
\text{d}x_i.","['real-analysis', 'integration', 'definite-integrals', 'improper-integrals', 'multiple-integral']"
82,Prove $\lim_{x\to \infty}\frac{\sin x}{x^2} = 0$.,Prove .,\lim_{x\to \infty}\frac{\sin x}{x^2} = 0,Prove using definition of a limit that $\lim_{x\to \infty}\frac{\sin x}{x^2} = 0$ . Proof: Let $\epsilon > 0$ . Note that $\left|\frac{\sin x}{x^2}\right| \leq \frac 1 {x^2}$ for $x\ne 0$ . Then choose $M= \frac 1{\sqrt{\epsilon}}$ . Then if $x> M$ implies that $\left|\frac{\sin x}{x^2}\right| \leq \frac 1 {x^2} < \epsilon$ . Am I allowed to give an $M$ the way I did?,Prove using definition of a limit that . Proof: Let . Note that for . Then choose . Then if implies that . Am I allowed to give an the way I did?,\lim_{x\to \infty}\frac{\sin x}{x^2} = 0 \epsilon > 0 \left|\frac{\sin x}{x^2}\right| \leq \frac 1 {x^2} x\ne 0 M= \frac 1{\sqrt{\epsilon}} x> M \left|\frac{\sin x}{x^2}\right| \leq \frac 1 {x^2} < \epsilon M,"['real-analysis', 'solution-verification', 'epsilon-delta']"
83,A conjectural infinite series for $\frac{\pi}{2}$,A conjectural infinite series for,\frac{\pi}{2},"Can you provide a proof for the claim given below? In this Wikipedia article the constant $\pi$ is represented by the following infinite series: $$\pi=\displaystyle\sum_{n=1}^{\infty}\frac{(-1)^{\epsilon(n)}}{n}$$ where $\epsilon(n)$ is the number of prime factors of the form $p \equiv 1 \pmod{4}$ of $n$ . (Euler, 1748) Similarly, we can formulate the following claim: $$\frac{\pi}{2}=\displaystyle\sum_{n=1}^{\infty}\frac{(-1)^{\kappa(n)}}{n}$$ where $\kappa(n)$ is the number of prime factors of the form $p \equiv 3 \pmod{4}$ of $n$ . The SageMath cell that demonstrates this claim can be found here . Now, I don't know how to start the proof. Any hints or references are welcomed.","Can you provide a proof for the claim given below? In this Wikipedia article the constant is represented by the following infinite series: where is the number of prime factors of the form of . (Euler, 1748) Similarly, we can formulate the following claim: where is the number of prime factors of the form of . The SageMath cell that demonstrates this claim can be found here . Now, I don't know how to start the proof. Any hints or references are welcomed.",\pi \pi=\displaystyle\sum_{n=1}^{\infty}\frac{(-1)^{\epsilon(n)}}{n} \epsilon(n) p \equiv 1 \pmod{4} n \frac{\pi}{2}=\displaystyle\sum_{n=1}^{\infty}\frac{(-1)^{\kappa(n)}}{n} \kappa(n) p \equiv 3 \pmod{4} n,"['real-analysis', 'sequences-and-series', 'elementary-number-theory', 'prime-numbers', 'pi']"
84,Why doesn't MVT prove all derivatives are continuous?,Why doesn't MVT prove all derivatives are continuous?,,"Obviously something is wrong with the following argument, but I'm not entirely what is. Let $f$ be differentiable in $(-1,1)$ and fix $0<x<1$ . Then, by MVT, there exists $0<y<x$ such that $$\frac{f(x)-f(0)}{x} = f'(y)$$ Taking the limit as $x \rightarrow 0$ on both sides gives $f'(0)$ on the LHS by definition, so we get $f'(0) = \lim_{x \rightarrow 0} f'(y)$ , which seems to prove $f'$ is continuous at zero since $y \rightarrow 0$ as $x \rightarrow 0$ . Again, I know this is wrong and can produce a counter-example (for instance, $f(x) = x^2\sin(1/x)$ , so $f'(0) = 1$ but $f'(x) < 0$ in neighborhoods of $0$ ). Can someone tell me exactly which step is invalid? Based on the conditions of L'Hopital's rule, the flaw seems to be that I'm assuming $\lim_{x \rightarrow 0} f'(y)$ exists, but I'm not sure if this is it since we just proved that it exists and equals $f'(x)$ .","Obviously something is wrong with the following argument, but I'm not entirely what is. Let be differentiable in and fix . Then, by MVT, there exists such that Taking the limit as on both sides gives on the LHS by definition, so we get , which seems to prove is continuous at zero since as . Again, I know this is wrong and can produce a counter-example (for instance, , so but in neighborhoods of ). Can someone tell me exactly which step is invalid? Based on the conditions of L'Hopital's rule, the flaw seems to be that I'm assuming exists, but I'm not sure if this is it since we just proved that it exists and equals .","f (-1,1) 0<x<1 0<y<x \frac{f(x)-f(0)}{x} = f'(y) x \rightarrow 0 f'(0) f'(0) = \lim_{x \rightarrow 0} f'(y) f' y \rightarrow 0 x \rightarrow 0 f(x) = x^2\sin(1/x) f'(0) = 1 f'(x) < 0 0 \lim_{x \rightarrow 0} f'(y) f'(x)",['real-analysis']
85,Reference request: Pedagogical/tutorial articles on the historical development of modern real analysis.,Reference request: Pedagogical/tutorial articles on the historical development of modern real analysis.,,"Are there any pedagogical/tutorial articles presenting the historical development of modern real analysis? Context and some information on my background. I am currently self-studying Understanding Analysis by Stephen Abbott (2015), with a view to moving to Principles of Mathematical Analysis by Walter Rudin (1976) at some point. This is my first exposure to a more rigorous, abstract, and at times beautiful, style of mathematics; most of my previous exposure to mathematics has been skewed towards applied/computational areas. Hence  the type of article I am looking for is at the 1st year undergraduate level. Article style. Primarily, I am soliciting recommendation on tutorial articles which contextualise mathematical developments of standard topics in analysis within a historical perspective, as a supplement to some of the epilogues in Abbott. I have previously read articles aimed at mathematically literate, but not necessarily deeply technically proficient audiences whereby the author introduces the topic in layman's terms, then some mathematical formalism, then summarises some crowning achievements of the field. All of this is interwoven with a historical narrative of how these tools developed through attempts to resolve seminal problems/paradoxes, together with broader debates in mathematics at the time. As an example, in probability and statistics, I really enjoyed Part II: A tutorial on probability, measure and the laws of large numbers (page 56 onwards) of the following article by Richard Mauldin in a special edition of Los Alamos Science dedicated to the mathematician Stanislaw Ulam: Mauldin, R. D. (1987). Probability and nonlinear systems. Los Alamos Science 15, Special Issue 1987 15. 52-90. Rationale. I've had experience with both formal education and self-study in economics, machine learning and statistics. Generally I've found that in the case of formal education, time constraints generally mean that the courses are taught with a view to getting students up to speed quickly on a battery of techniques/proofs/computational skills. In the case of mathematical monographs, I've often found that historical developments are often treated as ""literature reviews"" at the end of a chapter. This is not a deficiency as the constraint of fluent mathematical flow often does not allow for interwoven comments on historical developments. What can be lost however, is valuable historical context. As a final example, when I studied time-series techniques as part of formal economics training using Time-Series Analysis by Hamilton, and during self-study using Introductory Time Series Analysis by Brockwell and Davis, ergodicity and ensembles of time series are presented without much discussion. It was only when I skimmed some of the communications engineering roots of time series e.g. the work of Norbert Wiener, did it become apparent that modern persentations have decontextualised these methods from their original statistical mechanics overtones (it seems that Norbert Wiener discussed time series in relation to Birkhoff's ergodic theorem). Any suggestions from the community here would be greatly appreciated.","Are there any pedagogical/tutorial articles presenting the historical development of modern real analysis? Context and some information on my background. I am currently self-studying Understanding Analysis by Stephen Abbott (2015), with a view to moving to Principles of Mathematical Analysis by Walter Rudin (1976) at some point. This is my first exposure to a more rigorous, abstract, and at times beautiful, style of mathematics; most of my previous exposure to mathematics has been skewed towards applied/computational areas. Hence  the type of article I am looking for is at the 1st year undergraduate level. Article style. Primarily, I am soliciting recommendation on tutorial articles which contextualise mathematical developments of standard topics in analysis within a historical perspective, as a supplement to some of the epilogues in Abbott. I have previously read articles aimed at mathematically literate, but not necessarily deeply technically proficient audiences whereby the author introduces the topic in layman's terms, then some mathematical formalism, then summarises some crowning achievements of the field. All of this is interwoven with a historical narrative of how these tools developed through attempts to resolve seminal problems/paradoxes, together with broader debates in mathematics at the time. As an example, in probability and statistics, I really enjoyed Part II: A tutorial on probability, measure and the laws of large numbers (page 56 onwards) of the following article by Richard Mauldin in a special edition of Los Alamos Science dedicated to the mathematician Stanislaw Ulam: Mauldin, R. D. (1987). Probability and nonlinear systems. Los Alamos Science 15, Special Issue 1987 15. 52-90. Rationale. I've had experience with both formal education and self-study in economics, machine learning and statistics. Generally I've found that in the case of formal education, time constraints generally mean that the courses are taught with a view to getting students up to speed quickly on a battery of techniques/proofs/computational skills. In the case of mathematical monographs, I've often found that historical developments are often treated as ""literature reviews"" at the end of a chapter. This is not a deficiency as the constraint of fluent mathematical flow often does not allow for interwoven comments on historical developments. What can be lost however, is valuable historical context. As a final example, when I studied time-series techniques as part of formal economics training using Time-Series Analysis by Hamilton, and during self-study using Introductory Time Series Analysis by Brockwell and Davis, ergodicity and ensembles of time series are presented without much discussion. It was only when I skimmed some of the communications engineering roots of time series e.g. the work of Norbert Wiener, did it become apparent that modern persentations have decontextualised these methods from their original statistical mechanics overtones (it seems that Norbert Wiener discussed time series in relation to Birkhoff's ergodic theorem). Any suggestions from the community here would be greatly appreciated.",,"['real-analysis', 'reference-request']"
86,The $L^p$ limit of characteristic functions is a characteristic function.,The  limit of characteristic functions is a characteristic function.,L^p,"Let $(X,\mathcal{A},\mu)$ a measurable space where $X$ is a set, $\mathcal{A}$ is a $\sigma$ -álgebra and $\mu:\mathcal{A}\rightarrow[0,\infty]$ is a measure. Let $(\chi_{E_{n}})$ be a sequence of characteristic functions; this is $$\chi_{E_{n}}(x)=\begin{cases} 0,&x\notin E_n,\\ 1, &x\in E_n.  \end{cases}$$ where $E_n\in \mathcal{A}$ . Suppose that the sequence $(\chi_{E_{n}})$ is a Cauchy sequence in $L^p(X,\mathcal{A},\mu)$ ; that is given $\epsilon>0$ exists $n_0\in \mathbb{N}$ such that $$\|\chi_{E_n}-\chi_{E_{n}} \|_p=\left(\int|\chi_{E_{n}}-\chi_{E_{m}}|^pd\mu\right)^{1/p}<\epsilon,\,\forall n\geq n_0.$$ I would like to probe that exists a function $f\in L^p$ such that $f=\chi_{E}$ where $E\in \mathcal{A}$ such that the sequence $(\chi_{E_{n}})$ converges to $f$ in $L_p$ ; that is, given $\varepsilon>0$ exists $n_1>0$ such that $$\|\chi_{E_{n}}-f\|_p<\varepsilon,\,\forall n\geq n_1.$$ My attempt: I think the function is $f=\chi_{E}$ where $$E=\bigcup_{m=1}^{\infty}\left(\bigcap_{k=m}^{\infty}E_k\right).$$ The reason I believe it is that the identity $$|\chi_{E_{n}}-\chi_{E_{m}}|=\chi_{E_{n}\triangle E_{m}}$$ where $E_{n}\triangle E_{m}=E_n\backslash E_m\cup E_m\backslash E_n$ together with the Cauchy property implies that $$\mu(E_{n}\triangle E_{m})<\epsilon$$ So my reasoning tells me that the ""substance"" of the functions is in their intersection.","Let a measurable space where is a set, is a -álgebra and is a measure. Let be a sequence of characteristic functions; this is where . Suppose that the sequence is a Cauchy sequence in ; that is given exists such that I would like to probe that exists a function such that where such that the sequence converges to in ; that is, given exists such that My attempt: I think the function is where The reason I believe it is that the identity where together with the Cauchy property implies that So my reasoning tells me that the ""substance"" of the functions is in their intersection.","(X,\mathcal{A},\mu) X \mathcal{A} \sigma \mu:\mathcal{A}\rightarrow[0,\infty] (\chi_{E_{n}}) \chi_{E_{n}}(x)=\begin{cases}
0,&x\notin E_n,\\
1, &x\in E_n. 
\end{cases} E_n\in \mathcal{A} (\chi_{E_{n}}) L^p(X,\mathcal{A},\mu) \epsilon>0 n_0\in \mathbb{N} \|\chi_{E_n}-\chi_{E_{n}} \|_p=\left(\int|\chi_{E_{n}}-\chi_{E_{m}}|^pd\mu\right)^{1/p}<\epsilon,\,\forall n\geq n_0. f\in L^p f=\chi_{E} E\in \mathcal{A} (\chi_{E_{n}}) f L_p \varepsilon>0 n_1>0 \|\chi_{E_{n}}-f\|_p<\varepsilon,\,\forall n\geq n_1. f=\chi_{E} E=\bigcup_{m=1}^{\infty}\left(\bigcap_{k=m}^{\infty}E_k\right). |\chi_{E_{n}}-\chi_{E_{m}}|=\chi_{E_{n}\triangle E_{m}} E_{n}\triangle E_{m}=E_n\backslash E_m\cup E_m\backslash E_n \mu(E_{n}\triangle E_{m})<\epsilon","['real-analysis', 'integration', 'measure-theory', 'characteristic-functions']"
87,Proving that $f$ verifies $f(1-x)=-f(x)$,Proving that  verifies,f f(1-x)=-f(x),"I'm trying to show an identity verified by a function. I have this function which is defined for all real numbers as $ f(x) = \sum_{k=0}^{p-1} \frac{(x+k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!}$ I would like to show that $f(1-x) = -f(x)$ . First thing that tried: $ \begin{align*}  f(1-x) &= \sum_{k=0}^{p-1} \frac{(1-x+k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!} \\ &= \sum_{k=0}^{p-1} \frac{(-1)^{2m-1}(x-1-k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!}  \quad \text{factoring the numerator by }(-1)^{2m-1}\\ &= -\sum_{k=0}^{p-1} \frac{(x-1-k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!} \quad \text{reducing }(-1)^{2m-1}=-1\\ &= -\sum_{i=-p}^{-1} \frac{(x+i)^{2m-1}}{(-1)^{p-i-1} (p+i)!(p-i-1)!} \quad \text{doing a change of variable } i = -k-1 \\ \end{align*} $ I'm kind of stuck at this point and I don't see how to move forward with it. I think I'm not going to the optimal direction to prove that relation. Second thing that I am investigating: Since $f(x)$ is a polynomial of degree $2m-1$ , I could write it as a finite power series centered at $0$ . So with Taylor's theorem I would have $f(x) = \sum_{i=0}^{2m-1}  \frac{f^{(i)}(0) }{i!} x^{i}$ . and $ \begin{align*}  f(1-x)  &= \sum_{i=0}^{2m-1}  \frac{ f^{(i)}(0) }{i!} (1-x)^{i} \\ &= \sum_{i=0}^{2m-1}  \frac{ f^{(i)}(0) }{i!} \Bigg( \sum_{j=0}^{i} \binom{i}{j} (-x)^{j} \Bigg) \quad \text{binomial expansion applied to } (1-x)^{i} \\ &= \sum_{j=0}^{2m-1}  \Bigg((-1)^{j}\sum_{i=j}^{2m-1} \binom{i}{j} \frac{ f^{(i)}(0) }{i!} \Bigg) x^{j} \quad \text{changing the summation order} \sum_{i=0}^{2m-1}\sum_{j=0}^{i} \text{ to }   \sum_{j=0}^{2m-1}\sum_{i=j}^{2m-1}  \\ \end{align*} $ So showing that $f(1-x) = -f(x)$ is equivalent to showing that $(-1)^{j}\sum_{i=j}^{2m-1} \binom{i}{j} \frac{ f^{(i)}(0) }{i!} = - \frac{f^{(j)}(0) }{j!} $ . I think this is the more elegant way to go but I don't know if it is going to make things worse. Any feedback ? EDIT : clarification of the parameters m and p : I forgot to mention hypothesis on the parameters $m$ and $p$ . So we consider that $ 1 \leq m < p$","I'm trying to show an identity verified by a function. I have this function which is defined for all real numbers as I would like to show that . First thing that tried: I'm kind of stuck at this point and I don't see how to move forward with it. I think I'm not going to the optimal direction to prove that relation. Second thing that I am investigating: Since is a polynomial of degree , I could write it as a finite power series centered at . So with Taylor's theorem I would have . and So showing that is equivalent to showing that . I think this is the more elegant way to go but I don't know if it is going to make things worse. Any feedback ? EDIT : clarification of the parameters m and p : I forgot to mention hypothesis on the parameters and . So we consider that"," f(x) = \sum_{k=0}^{p-1} \frac{(x+k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!} f(1-x) = -f(x) 
\begin{align*} 
f(1-x)
&= \sum_{k=0}^{p-1} \frac{(1-x+k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!} \\
&= \sum_{k=0}^{p-1} \frac{(-1)^{2m-1}(x-1-k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!} 
\quad \text{factoring the numerator by }(-1)^{2m-1}\\
&= -\sum_{k=0}^{p-1} \frac{(x-1-k)^{2m-1}}{(-1)^{p+k} (p-1-k)!(p+k)!}
\quad \text{reducing }(-1)^{2m-1}=-1\\
&= -\sum_{i=-p}^{-1} \frac{(x+i)^{2m-1}}{(-1)^{p-i-1} (p+i)!(p-i-1)!}
\quad \text{doing a change of variable } i = -k-1 \\
\end{align*}
 f(x) 2m-1 0 f(x) = \sum_{i=0}^{2m-1}  \frac{f^{(i)}(0) }{i!} x^{i} 
\begin{align*} 
f(1-x) 
&= \sum_{i=0}^{2m-1}  \frac{ f^{(i)}(0) }{i!} (1-x)^{i} \\
&= \sum_{i=0}^{2m-1}  \frac{ f^{(i)}(0) }{i!} \Bigg( \sum_{j=0}^{i} \binom{i}{j} (-x)^{j} \Bigg)
\quad \text{binomial expansion applied to } (1-x)^{i} \\
&= \sum_{j=0}^{2m-1}  \Bigg((-1)^{j}\sum_{i=j}^{2m-1} \binom{i}{j} \frac{ f^{(i)}(0) }{i!} \Bigg) x^{j}
\quad \text{changing the summation order} \sum_{i=0}^{2m-1}\sum_{j=0}^{i} \text{ to }   \sum_{j=0}^{2m-1}\sum_{i=j}^{2m-1}  \\
\end{align*}
 f(1-x) = -f(x) (-1)^{j}\sum_{i=j}^{2m-1} \binom{i}{j} \frac{ f^{(i)}(0) }{i!} = - \frac{f^{(j)}(0) }{j!}  m p  1 \leq m < p","['real-analysis', 'calculus', 'functions']"
88,Derivative and inverse,Derivative and inverse,,"Is there a function whos derivative of its inverse equals the inverse of its derivative? This may also hold on a specific interval only. $$\frac{d}{dx}f^{\langle-1\rangle}(x)=\left(\frac{d}{dx}f(x)\right)^{\langle-1\rangle}$$ Considering that $f(x)=x$ is its own inverse and $e^x$ is its own derivative, neither of them satisfies the equation, but both are the only functions with the respective properties (over the reels). Is this already a proof that there is no solution to the above equation? Also, I dont know much about complex analysis but if a complex-valued function meets the criteria I'd be happy to know too :)","Is there a function whos derivative of its inverse equals the inverse of its derivative? This may also hold on a specific interval only. Considering that is its own inverse and is its own derivative, neither of them satisfies the equation, but both are the only functions with the respective properties (over the reels). Is this already a proof that there is no solution to the above equation? Also, I dont know much about complex analysis but if a complex-valued function meets the criteria I'd be happy to know too :)",\frac{d}{dx}f^{\langle-1\rangle}(x)=\left(\frac{d}{dx}f(x)\right)^{\langle-1\rangle} f(x)=x e^x,"['real-analysis', 'complex-analysis', 'derivatives', 'inverse-function']"
89,how many base $10$ decimal expansions can a real number have?,how many base  decimal expansions can a real number have?,10,"A somewhat unintuitive result of real analysis is that decimal expansions are not unique. For example, $$0.99999...=1.$$ So it can be gathered that every real number has at least one base- $10$ decimal expansion, sometimes even two. But is two the maximum ? Are there any real numbers with three different base- $10$ decimal expansions? Intuitively, I would think not, but I have close to no idea how to prove it other than knowing that the easiest method would be a proof by contraction. It may help to restrict the problem by considering the expansions of numbers only in $[0,1]$ . That is because if $a\in[0,1]$ has more than two base- $10$ decimal expansions, then so does $a+x$ for all $x\in\Bbb R$ . And likewise, if $x\in\Bbb R\setminus [0,1]$ has more than two base- $10$ expansions, it can be written as $x=\mathrm{sgn}(x)(\lfloor x\rfloor+a)$ , where $a\in[0,1)$ , and by necessity $a$ has more than two base- $10$ expansions. To be clear, I should define what I mean by base- $10$ expansion. Let $N\in[0,1]$ . Then a decimal expansion of $N$ is a sequence $\delta=(\delta_0,\delta_1,\delta_2,...)$ of integers $0\le \delta_i\le 9$ such that $$\sigma(\delta):=\sum_{i\ge0}\frac{\delta_i}{10^i}=N.$$ Furthermore, let $\mathcal U=\{(a_0,a_1,a_2,...):0\le a_i\le 9,\, a_i\in\Bbb Z\}$ and let $$D_N=\{\delta\in\mathcal U :\sigma(\delta)=N\}.$$ Lastly, let $$\mathcal C_k=\{N\in[0,1]:\#(D_N)\ge k\},\qquad k\in\Bbb N$$ where $\#(S)$ is the number of elements in the set $S$ . So, is $\mathcal C_k$ empty for $k>2$ ?","A somewhat unintuitive result of real analysis is that decimal expansions are not unique. For example, So it can be gathered that every real number has at least one base- decimal expansion, sometimes even two. But is two the maximum ? Are there any real numbers with three different base- decimal expansions? Intuitively, I would think not, but I have close to no idea how to prove it other than knowing that the easiest method would be a proof by contraction. It may help to restrict the problem by considering the expansions of numbers only in . That is because if has more than two base- decimal expansions, then so does for all . And likewise, if has more than two base- expansions, it can be written as , where , and by necessity has more than two base- expansions. To be clear, I should define what I mean by base- expansion. Let . Then a decimal expansion of is a sequence of integers such that Furthermore, let and let Lastly, let where is the number of elements in the set . So, is empty for ?","0.99999...=1. 10 10 [0,1] a\in[0,1] 10 a+x x\in\Bbb R x\in\Bbb R\setminus [0,1] 10 x=\mathrm{sgn}(x)(\lfloor x\rfloor+a) a\in[0,1) a 10 10 N\in[0,1] N \delta=(\delta_0,\delta_1,\delta_2,...) 0\le \delta_i\le 9 \sigma(\delta):=\sum_{i\ge0}\frac{\delta_i}{10^i}=N. \mathcal U=\{(a_0,a_1,a_2,...):0\le a_i\le 9,\, a_i\in\Bbb Z\} D_N=\{\delta\in\mathcal U :\sigma(\delta)=N\}. \mathcal C_k=\{N\in[0,1]:\#(D_N)\ge k\},\qquad k\in\Bbb N \#(S) S \mathcal C_k k>2","['real-analysis', 'sequences-and-series', 'real-numbers', 'decimal-expansion']"
90,"If $\sum\limits_{n=0}^{\infty} a_n\ $ is a conditionally convergent series, then is $\sum\limits_{n=0}^{\infty} |a_n+a_{n+1}|\ $ convergent?","If  is a conditionally convergent series, then is  convergent?",\sum\limits_{n=0}^{\infty} a_n\  \sum\limits_{n=0}^{\infty} |a_n+a_{n+1}|\ ,"If $\sum\limits_{n=0}^{\infty} a_n\ $ is a conditionally convergent series, then is the sum of the average of consecutive terms necessarily convergent? In other words, is $\sum\limits_{n=0}^{\infty} |a_n+a_{n+1}|\ $ convergent? For the most standard example, the alternating harmonic series $\sum\limits_{n=0}^\infty {(-1)^n\over n+1},$ we get that $\sum\limits_{n=0}^{\infty} |a_n+a_{n+1}|\ $ is half the sum of the reciprocal triangular numbers, which does converge. But does every conditionally convergent (but not necessarily alternating sign) series have this property, or is there one that diverges? I feel like I'm missing some obvious triangle inequality trick, but I just don't see it.","If is a conditionally convergent series, then is the sum of the average of consecutive terms necessarily convergent? In other words, is convergent? For the most standard example, the alternating harmonic series we get that is half the sum of the reciprocal triangular numbers, which does converge. But does every conditionally convergent (but not necessarily alternating sign) series have this property, or is there one that diverges? I feel like I'm missing some obvious triangle inequality trick, but I just don't see it.","\sum\limits_{n=0}^{\infty} a_n\  \sum\limits_{n=0}^{\infty} |a_n+a_{n+1}|\  \sum\limits_{n=0}^\infty {(-1)^n\over n+1}, \sum\limits_{n=0}^{\infty} |a_n+a_{n+1}|\ ","['real-analysis', 'sequences-and-series']"
91,What change of variables is this?,What change of variables is this?,,"I have come across this integral: $$\int \frac{f(x+tv)-f(x)}{t}g(x)dx = \int -\frac{g(x)-g(x-tv)}{t}f(x)dx$$ which the author claims is justified by a change of variables, but I cannot see what they did. Would anyone be able to elaborate?","I have come across this integral: which the author claims is justified by a change of variables, but I cannot see what they did. Would anyone be able to elaborate?",\int \frac{f(x+tv)-f(x)}{t}g(x)dx = \int -\frac{g(x)-g(x-tv)}{t}f(x)dx,"['real-analysis', 'integration']"
92,Manifolds are Borel sets,Manifolds are Borel sets,,"Consider $M\subseteq \mathbb{R}^n$ , an (embedded) $C^{k\geq 1}$ manifold. Is $M$ Borel? I think yes but I got stuck at proving this. For some context, I was checking that integrals over manifolds with respect to Hausdorff measures make sense. My try: Graphs of continuous functions are Borel: let $U$ be open and $f:U \rightarrow \mathbb{R}^q$ be continuous. Let $\phi(x)=(x,f(x))$ , a continuous function. We can write $U=\bigcup_n K_n$ for some compact sets $K_n \subseteq U$ and therefore $\text{graf}f=\phi(U)=\bigcup_n\phi(K_n)$ , so that the graph of $f$ is the countable union of compact (hence Borel) sets. A manifold is ""countably locally"" the graph of a $C^k$ function: by this I mean that $M$ is the countable union of the graphs of some $C^k$ functions. Here I am stuck. I know that $M$ is locally a graph, but I cannot get the countability property. I was thinking of using the density of rationals in the real numbers but I'm not sure if this is the way to go, also beacause I'm not sure that second countability of $M$ is guaranteed with my definition of manifold (see below). Do you have any hint on how to get through point 2, provided my claim is correct? $M\subseteq \mathbb{R}^n$ is an embedded $C^{k\geq 1}$ $m-$ manifold if for every $p$ in $M$ there exists $U\subseteq \mathbb{R}^m$ open and $\phi:U\rightarrow M$ of class $C^{k}$ such that: $\phi(U)$ is a neighbourhood of $p$ , open in $M$ $\phi$ is a homeomorphism onto its image $d\phi$ is everywhere injective","Consider , an (embedded) manifold. Is Borel? I think yes but I got stuck at proving this. For some context, I was checking that integrals over manifolds with respect to Hausdorff measures make sense. My try: Graphs of continuous functions are Borel: let be open and be continuous. Let , a continuous function. We can write for some compact sets and therefore , so that the graph of is the countable union of compact (hence Borel) sets. A manifold is ""countably locally"" the graph of a function: by this I mean that is the countable union of the graphs of some functions. Here I am stuck. I know that is locally a graph, but I cannot get the countability property. I was thinking of using the density of rationals in the real numbers but I'm not sure if this is the way to go, also beacause I'm not sure that second countability of is guaranteed with my definition of manifold (see below). Do you have any hint on how to get through point 2, provided my claim is correct? is an embedded manifold if for every in there exists open and of class such that: is a neighbourhood of , open in is a homeomorphism onto its image is everywhere injective","M\subseteq \mathbb{R}^n C^{k\geq 1} M U f:U \rightarrow \mathbb{R}^q \phi(x)=(x,f(x)) U=\bigcup_n K_n K_n \subseteq U \text{graf}f=\phi(U)=\bigcup_n\phi(K_n) f C^k M C^k M M M\subseteq \mathbb{R}^n C^{k\geq 1} m- p M U\subseteq \mathbb{R}^m \phi:U\rightarrow M C^{k} \phi(U) p M \phi d\phi","['real-analysis', 'measure-theory', 'differential-geometry']"
93,Does the Chain Rule Hold for General Derivatives?,Does the Chain Rule Hold for General Derivatives?,,"For vector space $\mathbb{R}^n$ we have partial derivatives, which obey the chain rule, e.g: let $F:\mathbb{R}^n \to \mathbb{R}^m$ , $f:\mathbb{R}^m\to \mathbb{R}$ , assume standard basis for $\mathbb{R}^n$ is $x^i$ and standard basis for $\mathbb{R}^m$ is $y^j$ .So for composition we have: $$\left.\frac{\partial}{\partial x^{i}}\right|_{p}(f \circ F)=\frac{\partial f}{\partial y^{j}}(F(p)) \frac{\partial F^{j}}{\partial x^{i}}(p)$$ which is the standard chain rule. Now consider the general case derivative as linear map between algebra $v:A\to B$ with $v(fg) = fv(g)+gv(f)$ . In this case does chain rule for composition $v(f\circ g)$ still hold? It seems not? (we know for differential $dF_p:T_pM\to T_p N$ chain rule still holds)","For vector space we have partial derivatives, which obey the chain rule, e.g: let , , assume standard basis for is and standard basis for is .So for composition we have: which is the standard chain rule. Now consider the general case derivative as linear map between algebra with . In this case does chain rule for composition still hold? It seems not? (we know for differential chain rule still holds)",\mathbb{R}^n F:\mathbb{R}^n \to \mathbb{R}^m f:\mathbb{R}^m\to \mathbb{R} \mathbb{R}^n x^i \mathbb{R}^m y^j \left.\frac{\partial}{\partial x^{i}}\right|_{p}(f \circ F)=\frac{\partial f}{\partial y^{j}}(F(p)) \frac{\partial F^{j}}{\partial x^{i}}(p) v:A\to B v(fg) = fv(g)+gv(f) v(f\circ g) dF_p:T_pM\to T_p N,"['real-analysis', 'differential-geometry', 'manifolds', 'smooth-manifolds']"
94,Basic questions about the sobolev space $H^\infty(\mathbb{R})$,Basic questions about the sobolev space,H^\infty(\mathbb{R}),"Let's consider $H^\infty(\mathbb{R})$ to be the intersection of all Sobolev spaces $H^s$ for $s\geq0$ , that is, $$ H^\infty(\mathbb{R}):=\bigcap_{s\geq 0}H^s(\mathbb{R}). $$ I am wondering some trivial questions about this space, like for example, is this space different from the space of Schwartz functions $\mathcal{S}$ ? Or maybe do we have an inclusion like $$ H^\infty\subset\mathcal{S} \quad \hbox{or} \quad \mathcal{S}\subset H^\infty? $$ If not, I was wondering if even possible to prove that any function $f\in H^\infty$ belongs to $f\in L^1$ . This last question arises to me because I know that by Sobolev's embedding we have that $f$ belongs to any $L^p$ space for $p\geq 2$ , but what about $p<2$ ? Since we have a ""super"" regularity, I guess this doesn't sound crazy right? Finally, does $f\in H^\infty$ implies (for example) exponential decay?","Let's consider to be the intersection of all Sobolev spaces for , that is, I am wondering some trivial questions about this space, like for example, is this space different from the space of Schwartz functions ? Or maybe do we have an inclusion like If not, I was wondering if even possible to prove that any function belongs to . This last question arises to me because I know that by Sobolev's embedding we have that belongs to any space for , but what about ? Since we have a ""super"" regularity, I guess this doesn't sound crazy right? Finally, does implies (for example) exponential decay?","H^\infty(\mathbb{R}) H^s s\geq0 
H^\infty(\mathbb{R}):=\bigcap_{s\geq 0}H^s(\mathbb{R}).
 \mathcal{S} 
H^\infty\subset\mathcal{S} \quad \hbox{or} \quad \mathcal{S}\subset H^\infty?
 f\in H^\infty f\in L^1 f L^p p\geq 2 p<2 f\in H^\infty","['real-analysis', 'examples-counterexamples', 'lp-spaces', 'sobolev-spaces', 'weak-derivatives']"
95,"Show that the inequality $\left|\int_{0}^{1} f(x)\,dx\right| \leq \frac{1}{12}$ holds for certain initial conditions",Show that the inequality  holds for certain initial conditions,"\left|\int_{0}^{1} f(x)\,dx\right| \leq \frac{1}{12}","Given that a function $f$ has a continuous second derivative on the interval $[0,1]$ , $f(0)=f(1)=0$ , and $|f''(x)|\leq 1$ , show that $$\left|\int_{0}^{1}f(x)\,dx\right|\leq \frac{1}{12}\,.$$ My attempt: This looks to be a maximization/minimization problem. Since the largest value $f''(x)$ can take on is $1$ , then the first case will be to assume $f''(x)=1$ . This is because it is the maximum concavity and covers the most amount of area from $[0,1]$ while still maintaining the given conditions. Edit: Because of the MVT and Rolle's Theorem, there exists extrema on the interval $[0,1]$ satisfying $f'(c)=0$ for some $c\in[0,1]$ . These extrema could occur at endpoints. Then $f'(x)=x+b$ and $f(x)=\frac{x^2}{2}+bx+c$ . Since $f(0)=0$ , then $c=0$ and $f(1)=0$ , then $b=-\frac{1}{2}$ . Remark: Any function with a continuous, constant second derivative will be of the form $ax^2+bx+c$ and in this case, $a=-b$ and $c=0$ . Now, $$\begin{align*}\int_{0}^{1}f(x)\,dx&=\frac{1}{2}\int_{0}^{1}(x^2-x)\,dx\\&=\frac{1}{2}\bigg[\frac{x^3}{3}-\frac{x^2}{2}\bigg]_{x=0}^{x=1}\\&=-\frac{1}{12}\end{align*}$$ Next, we assume that $f''(x)=-1$ and repeating the process yields $$ \begin{align*}\int_{0}^{1}f(x)\,dx&=\frac{1}{2}\int_{0}^{1}(-x^2+x)\,dx\\&=\frac{1}{2}\bigg[\frac{-x^3}{3}+\frac{x^2}{2}\bigg]_{x=0}^{x=1}\\&=\frac{1}{12}\end{align*}$$ Thus we have shown that at the upper and lower bounds for $f''(x)$ that $\frac{-1}{12}\leq\int_{0}^{1}f(x)\,dx\leq \frac{1}{12}   \Longleftrightarrow \left|\int_{0}^{1}f(x)\,dx\right|\leq\frac{1}{12}$ because $f''(x)$ is continuous on $[0,1]$ . I was wondering if this was 'rigorous' enough to be considered a full proof and solution to the problem.","Given that a function has a continuous second derivative on the interval , , and , show that My attempt: This looks to be a maximization/minimization problem. Since the largest value can take on is , then the first case will be to assume . This is because it is the maximum concavity and covers the most amount of area from while still maintaining the given conditions. Edit: Because of the MVT and Rolle's Theorem, there exists extrema on the interval satisfying for some . These extrema could occur at endpoints. Then and . Since , then and , then . Remark: Any function with a continuous, constant second derivative will be of the form and in this case, and . Now, Next, we assume that and repeating the process yields Thus we have shown that at the upper and lower bounds for that because is continuous on . I was wondering if this was 'rigorous' enough to be considered a full proof and solution to the problem.","f [0,1] f(0)=f(1)=0 |f''(x)|\leq 1 \left|\int_{0}^{1}f(x)\,dx\right|\leq \frac{1}{12}\,. f''(x) 1 f''(x)=1 [0,1] [0,1] f'(c)=0 c\in[0,1] f'(x)=x+b f(x)=\frac{x^2}{2}+bx+c f(0)=0 c=0 f(1)=0 b=-\frac{1}{2} ax^2+bx+c a=-b c=0 \begin{align*}\int_{0}^{1}f(x)\,dx&=\frac{1}{2}\int_{0}^{1}(x^2-x)\,dx\\&=\frac{1}{2}\bigg[\frac{x^3}{3}-\frac{x^2}{2}\bigg]_{x=0}^{x=1}\\&=-\frac{1}{12}\end{align*} f''(x)=-1  \begin{align*}\int_{0}^{1}f(x)\,dx&=\frac{1}{2}\int_{0}^{1}(-x^2+x)\,dx\\&=\frac{1}{2}\bigg[\frac{-x^3}{3}+\frac{x^2}{2}\bigg]_{x=0}^{x=1}\\&=\frac{1}{12}\end{align*} f''(x) \frac{-1}{12}\leq\int_{0}^{1}f(x)\,dx\leq \frac{1}{12} 
 \Longleftrightarrow \left|\int_{0}^{1}f(x)\,dx\right|\leq\frac{1}{12} f''(x) [0,1]","['real-analysis', 'definite-integrals', 'proof-writing', 'solution-verification', 'integral-inequality']"
96,Showing that there is a point belonging to $2000$ sets.,Showing that there is a point belonging to  sets.,2000,"Question: Let $E_j\subset[0,1]$ be a sequence of measurable sets satisfying $$m(E_i\cap E_j)\geq\frac{1}{i^2+j^2}$$ for all $i,j\geq1$ .  Prove that there is an $x\in[0,1]$ belonging to at least $2000$ sets $E_j$ .  Does there exist an $x\in[0,1]$ belonging to infinitely many $E_j$ 's? My thoughts: If we consider the function $f=\sum_j \chi_{E_j}$ , then $f$ is a measurable function from $[0,1]$ to $[0,\infty]$ .  So, $f^{-1}([2000,\infty])$ is measurable, and $f^{-1}([2000,\infty])$ is the set of points $x\in[0,1]$ that belong in at least $2000$ of the $E_j$ 's. I'm not sure if what I have above is totally accurate, and for the second question, I am not sure if that would just, then, be obvious (well, I suppose, evidently not) or if there is a bit more to consider.  Moreover, I suppose I never really used the "" $m(E_i\cap E_j)\geq\frac{1}{i^2+j^2}$ for all $i,j\geq1$ "" part, so I feel like I have something incorrect here.... Any thoughts, suggestions, etc. are appreciated!  Thank you!","Question: Let be a sequence of measurable sets satisfying for all .  Prove that there is an belonging to at least sets .  Does there exist an belonging to infinitely many 's? My thoughts: If we consider the function , then is a measurable function from to .  So, is measurable, and is the set of points that belong in at least of the 's. I'm not sure if what I have above is totally accurate, and for the second question, I am not sure if that would just, then, be obvious (well, I suppose, evidently not) or if there is a bit more to consider.  Moreover, I suppose I never really used the "" for all "" part, so I feel like I have something incorrect here.... Any thoughts, suggestions, etc. are appreciated!  Thank you!","E_j\subset[0,1] m(E_i\cap E_j)\geq\frac{1}{i^2+j^2} i,j\geq1 x\in[0,1] 2000 E_j x\in[0,1] E_j f=\sum_j \chi_{E_j} f [0,1] [0,\infty] f^{-1}([2000,\infty]) f^{-1}([2000,\infty]) x\in[0,1] 2000 E_j m(E_i\cap E_j)\geq\frac{1}{i^2+j^2} i,j\geq1","['real-analysis', 'measure-theory', 'lebesgue-measure']"
97,"Let $b \in [0,1)$. Prove that $\frac{b}{1-b} \in [0,\infty)$",Let . Prove that,"b \in [0,1) \frac{b}{1-b} \in [0,\infty)","Can someone check my solution for this problem? It seems to me that it’s incomplete, and I’m not sure. Problem: Let $b \in [0,1)$ . Prove that $\frac{b}{1-b} \in [0,\infty)$ . Solution: We know that $b \in [0,1)$ , so $0 \leq b < 1$ . From here we can also deduce that $ 0 < 1-b \leq 1$ . So $\frac{1}{1-b} \geq 1$ . Multiplying by $b$ we obtain that $\frac{b}{1-b} \geq b$ . Since $b \geq 0$ we conclude that $\frac{b}{1-b} \geq 0$ . Therefore $\frac{b}{b-1} \in [0,\infty)$ .","Can someone check my solution for this problem? It seems to me that it’s incomplete, and I’m not sure. Problem: Let . Prove that . Solution: We know that , so . From here we can also deduce that . So . Multiplying by we obtain that . Since we conclude that . Therefore .","b \in [0,1) \frac{b}{1-b} \in [0,\infty) b \in [0,1) 0 \leq b < 1  0 < 1-b \leq 1 \frac{1}{1-b} \geq 1 b \frac{b}{1-b} \geq b b \geq 0 \frac{b}{1-b} \geq 0 \frac{b}{b-1} \in [0,\infty)","['real-analysis', 'algebra-precalculus', 'inequality', 'solution-verification']"
98,Bijective map from a set to a subset of reals?,Bijective map from a set to a subset of reals?,,"There is a concept that I have been thinking about quite a lot lately as I am currently self-studying point-set topology: Say we have a bijective map from one interval, $[a,b]$ , to another interval, $[c,d]$ , both of which are in $\mathbb{R}$ . Also set $c$ and $d$ so that $[c,d] \subseteq [a,b]$ . How can it be that function maps to a subset which is a proper subset of the map's preimage bijectively? I.e. How can the map be both one-to-one and onto when the image should contain ""less"" elements than the domain? One example would be $f(x) := \frac{x}{1+x}: [0,10] \to [0, \frac{10}{11}]$ I'm hoping someone can show me why this isn't such a strange concept? Is there a theorem or result that explains this or provides some intuition?","There is a concept that I have been thinking about quite a lot lately as I am currently self-studying point-set topology: Say we have a bijective map from one interval, , to another interval, , both of which are in . Also set and so that . How can it be that function maps to a subset which is a proper subset of the map's preimage bijectively? I.e. How can the map be both one-to-one and onto when the image should contain ""less"" elements than the domain? One example would be I'm hoping someone can show me why this isn't such a strange concept? Is there a theorem or result that explains this or provides some intuition?","[a,b] [c,d] \mathbb{R} c d [c,d] \subseteq [a,b] f(x) := \frac{x}{1+x}: [0,10] \to [0, \frac{10}{11}]","['real-analysis', 'general-topology', 'elementary-set-theory']"
99,Showing $\lim_{n\to\infty}\int_{\mathbb{R}} f(x)f(x+n) dx=0$,Showing,\lim_{n\to\infty}\int_{\mathbb{R}} f(x)f(x+n) dx=0,"Problem Let $f(x)\in L^2(-\infty,\infty)$ . Prove that $$ \lim_{n\to\infty}\int_{-\infty}^\infty f(x)f(x+n) dx=0. $$ My attempt Let $N\in\mathbb{N}$ and $f_N(x):=f(x)\chi_{[-N,N]}(x)$ . For any $n\in\mathbb{N}$ , consider $$ \begin{split} \int_{-\infty}^\infty f(x)f_N(x+n)dx&=\int_{-\infty}^\infty f(x)f(x+n)\chi_{[-N,N]}(x+n)dx\\ &=\int_{-\infty}^\infty f(x)f(x+n)\chi_{[-N-n,N-n]}(x)dx\\ &=\int_{-N-n}^{N-n}f(x)f(x+n)dx \end{split} $$ This is where I get stuck. We know for a.e. $x\in\mathbb{R}$ that $\lim_{n\to\infty} f(x+n)=0$ . Thus, if I were allowed to interchange limit and integral, I would get the desired conclusion. I tried Dominated Convergence Theorem, but could not find a way to dominate the integrand by an integrable function not depending on $n$ . Maybe there is a different approach. Any hints? I'd like to be able to say the absolute value of the above integral is less than any $\varepsilon>0$ for $n$ large enough, and then since $N$ is arbitrary, the conclusion follows.","Problem Let . Prove that My attempt Let and . For any , consider This is where I get stuck. We know for a.e. that . Thus, if I were allowed to interchange limit and integral, I would get the desired conclusion. I tried Dominated Convergence Theorem, but could not find a way to dominate the integrand by an integrable function not depending on . Maybe there is a different approach. Any hints? I'd like to be able to say the absolute value of the above integral is less than any for large enough, and then since is arbitrary, the conclusion follows.","f(x)\in L^2(-\infty,\infty) 
\lim_{n\to\infty}\int_{-\infty}^\infty f(x)f(x+n) dx=0.
 N\in\mathbb{N} f_N(x):=f(x)\chi_{[-N,N]}(x) n\in\mathbb{N} 
\begin{split}
\int_{-\infty}^\infty f(x)f_N(x+n)dx&=\int_{-\infty}^\infty f(x)f(x+n)\chi_{[-N,N]}(x+n)dx\\
&=\int_{-\infty}^\infty f(x)f(x+n)\chi_{[-N-n,N-n]}(x)dx\\
&=\int_{-N-n}^{N-n}f(x)f(x+n)dx
\end{split}
 x\in\mathbb{R} \lim_{n\to\infty} f(x+n)=0 n \varepsilon>0 n N","['real-analysis', 'lebesgue-integral']"
