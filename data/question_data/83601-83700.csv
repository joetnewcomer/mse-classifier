,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Question about boundedness of a sequence in $ W^{3,q} $ for any $ 1\leq q < \frac{N}{N-1} $",Question about boundedness of a sequence in  for any," W^{3,q}   1\leq q < \frac{N}{N-1} ","I have asked this question several months ago, I have understood every thing and there are good comments and they have helped me , but only I have a question about tomas comment, how can Calderón-Zygmund estimate prove that $\{u_n \}$ is bounded in $ W^{3,q} $ . And I have another new question, can some one says that why $v$ , $u$ are a positive solutions and why we can consider $u_n >0$ and $u_n \in L^{\infty}$ . I have not changed the question, and it was : Can someone see the 10th line of page 9 in this article and give a hint that why $$ \nabla v_n \to \nabla v \   \ (a.e.)$$ and $$ v_n \to v $$ and how with theorem 2.1 we could conclude there exists $ u \in W^{2,q}(\Omega) $ such that $ v=-\Delta u $ Thanks","I have asked this question several months ago, I have understood every thing and there are good comments and they have helped me , but only I have a question about tomas comment, how can Calderón-Zygmund estimate prove that is bounded in . And I have another new question, can some one says that why , are a positive solutions and why we can consider and . I have not changed the question, and it was : Can someone see the 10th line of page 9 in this article and give a hint that why and and how with theorem 2.1 we could conclude there exists such that Thanks","\{u_n \}  W^{3,q}  v u u_n >0 u_n \in L^{\infty}  \nabla v_n \to \nabla v \   \ (a.e.)  v_n \to v   u \in W^{2,q}(\Omega)   v=-\Delta u ","['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
1,Dual of $\ell^p$ Direct sum,Dual of  Direct sum,\ell^p,"I am asked to show that the $\ell^p$-direct sum of a sequence of Banach Spaces $X_n$ is isometrically isomorphic to the $\ell^q$ direct sum of $X_n^*$ where $X_n^*$ is the dual of $X_n$ for each $n$ respectively. (Here $p$, $q$ are conjugate indices with $1\leq p<\infty$). So far I have tried the case $p>1$, and I am trying to adapt the proof of $(\ell^p)^*$ being isometrically isomorphic to $\ell^q$ but this isn't getting anywhere. Could someone please give any hints? EDITED by idonknow: Fix $1\leq p<\infty.$ The $\ell^p$-direct sum of a sequence of Banach spaces $X_n,$  denoted as $\left( \bigoplus_{n=1}^\infty X_n\right)_{\ell^p},$ means that for every $x=(x_n)_{n=1}^\infty\in \left( \bigoplus_{n=1}^\infty X_n\right)_{\ell^p},$ we have  $$\|x\| = \left(\sum_{n=1}^\infty\|x_n\|^p \right)^{\frac{1}{p}}.$$","I am asked to show that the $\ell^p$-direct sum of a sequence of Banach Spaces $X_n$ is isometrically isomorphic to the $\ell^q$ direct sum of $X_n^*$ where $X_n^*$ is the dual of $X_n$ for each $n$ respectively. (Here $p$, $q$ are conjugate indices with $1\leq p<\infty$). So far I have tried the case $p>1$, and I am trying to adapt the proof of $(\ell^p)^*$ being isometrically isomorphic to $\ell^q$ but this isn't getting anywhere. Could someone please give any hints? EDITED by idonknow: Fix $1\leq p<\infty.$ The $\ell^p$-direct sum of a sequence of Banach spaces $X_n,$  denoted as $\left( \bigoplus_{n=1}^\infty X_n\right)_{\ell^p},$ means that for every $x=(x_n)_{n=1}^\infty\in \left( \bigoplus_{n=1}^\infty X_n\right)_{\ell^p},$ we have  $$\|x\| = \left(\sum_{n=1}^\infty\|x_n\|^p \right)^{\frac{1}{p}}.$$",,"['functional-analysis', 'lp-spaces', 'direct-sum', 'dual-spaces']"
2,Eigenprojection as Contour Integral over Resolvent,Eigenprojection as Contour Integral over Resolvent,,"Let $H$ be a Hilbert space and let $A \in L(H)$ be a bounded linear operator. Assume that $\lambda$ is an eigenvalue of $A$ and assume further that $C_\lambda$ is a simple closed curve in the complex plane that separates $\lambda$ from the rest of the spectrum of $A$. Then $$ - \frac{1}{2 \pi i} \int_{C_\lambda}{(A-zI)^{-1}dz} $$ is the projection of $H$ onto the eigenspace of $\lambda$. Where can I find a proof of this theorem? I am looking for an introductory text that maybe also sheds some light on the theory around this claim, i.e. the definition of the contour integral and the relation of this integral to the measurable functional calculus and the spectral measure of $A$. EDIT: Assume that $A$ is normal or self-adjoint.","Let $H$ be a Hilbert space and let $A \in L(H)$ be a bounded linear operator. Assume that $\lambda$ is an eigenvalue of $A$ and assume further that $C_\lambda$ is a simple closed curve in the complex plane that separates $\lambda$ from the rest of the spectrum of $A$. Then $$ - \frac{1}{2 \pi i} \int_{C_\lambda}{(A-zI)^{-1}dz} $$ is the projection of $H$ onto the eigenspace of $\lambda$. Where can I find a proof of this theorem? I am looking for an introductory text that maybe also sheds some light on the theory around this claim, i.e. the definition of the contour integral and the relation of this integral to the measurable functional calculus and the spectral measure of $A$. EDIT: Assume that $A$ is normal or self-adjoint.",,"['reference-request', 'functional-analysis', 'operator-theory', 'spectral-theory']"
3,Is there any motivation for Zorn's Lemma?,Is there any motivation for Zorn's Lemma?,,"I have been reading Kreyszig's book on functional analysis, where it uses Zorn's lemma to prove the Hahn Banach theorem. However I don't quite get what Zorn's lemma is saying. I understand that it is an axiom and it is equivalent to the axiom of choice, but axiom of choice seems much more intuitive to me. So is there any way to understand the Zorn's lemma in a more intuitive way?","I have been reading Kreyszig's book on functional analysis, where it uses Zorn's lemma to prove the Hahn Banach theorem. However I don't quite get what Zorn's lemma is saying. I understand that it is an axiom and it is equivalent to the axiom of choice, but axiom of choice seems much more intuitive to me. So is there any way to understand the Zorn's lemma in a more intuitive way?",,"['functional-analysis', 'set-theory', 'intuition', 'axiom-of-choice']"
4,Inclusion of Schwartz space on $L^p$,Inclusion of Schwartz space on,L^p,"I'm looking for a proof of $\mathcal{S}(\mathbb{R}) \subset L^p(\mathbb{R})$ for $1 \leq p \leq \infty$. My informal probe follow like this: For any function $f \in L^p(\mathbb{R})$ exists a piecewise function $h_n$ such that $||h_n(x) - f(x)||_{L^p} \rightarrow 0 \ \text{with} \ n\rightarrow \infty \ (\forall x)$, and any $h_n$ could be approximated by compactly supported smooth functions ($C_{c}^{\infty}(\mathbb{R})$). And Since $C_{c}^{\infty}(\mathbb{R})$ is dense in $\mathcal{S}(\mathbb{R})$, then can be concluded that $\mathcal{S}(\mathbb{R}) \subset L^p(\mathbb{R})$. Any help to formalize that, or any different proof will be helpful.","I'm looking for a proof of $\mathcal{S}(\mathbb{R}) \subset L^p(\mathbb{R})$ for $1 \leq p \leq \infty$. My informal probe follow like this: For any function $f \in L^p(\mathbb{R})$ exists a piecewise function $h_n$ such that $||h_n(x) - f(x)||_{L^p} \rightarrow 0 \ \text{with} \ n\rightarrow \infty \ (\forall x)$, and any $h_n$ could be approximated by compactly supported smooth functions ($C_{c}^{\infty}(\mathbb{R})$). And Since $C_{c}^{\infty}(\mathbb{R})$ is dense in $\mathcal{S}(\mathbb{R})$, then can be concluded that $\mathcal{S}(\mathbb{R}) \subset L^p(\mathbb{R})$. Any help to formalize that, or any different proof will be helpful.",,"['functional-analysis', 'lp-spaces', 'schwartz-space']"
5,"Double dual of the space $C[0,1]$",Double dual of the space,"C[0,1]","The second dual or double dual of the space of all continuous functions on $[0,1]$, $C[0,1]$ is von Neumann algebra. Can anyone help me identifying this space?","The second dual or double dual of the space of all continuous functions on $[0,1]$, $C[0,1]$ is von Neumann algebra. Can anyone help me identifying this space?",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
6,Closure of the span in a Banach space,Closure of the span in a Banach space,,"Let $X$ be a Banach space, and $S$ a subset.  Is it true that $\overline {\operatorname{span}(S)}$ is equal to the set of the elements of $X$ that are obtained as norm convergent infinite sums of the scalar multiples of the elements of $S$?  I can see that the infinite sums are in the closure of the span, and also that it would suffice to see that the collection of infinite sums of elements of $S$ forms a norm-closed set.  I just can't show that.","Let $X$ be a Banach space, and $S$ a subset.  Is it true that $\overline {\operatorname{span}(S)}$ is equal to the set of the elements of $X$ that are obtained as norm convergent infinite sums of the scalar multiples of the elements of $S$?  I can see that the infinite sums are in the closure of the span, and also that it would suffice to see that the collection of infinite sums of elements of $S$ forms a norm-closed set.  I just can't show that.",,"['analysis', 'functional-analysis', 'banach-spaces']"
7,"If $V \times W$ with the product norm is complete, must $V$ and $W$ be complete?","If  with the product norm is complete, must  and  be complete?",V \times W V W,"Let $V,W$ be two normed vector spaces (over a field $K$). Then their product $V \times W$ with the norm $\|(x,y)\| = \|x\|_V + \|y\|_W$ is a normed space. Using this norm it's easy to show that if $V,W$ are complete then so is $V \times W$. To see this, let the limit of the sequence $(x_n , y_n)$ be $(x,y) = (\lim x_n, \lim y_n)$.  Then for $n$ large enough, both $\|x - x_n\|_V$ and $\|y - y_n\|_W$ are less than $\varepsilon / 2$ and hence $\|(x,y) - (x_n, y_n)\|< \varepsilon$. The other direction does (probably) not hold. Can someone show me an example of a space $V \times W$ that is complete but either $V$ or $W$ (or both) are not?","Let $V,W$ be two normed vector spaces (over a field $K$). Then their product $V \times W$ with the norm $\|(x,y)\| = \|x\|_V + \|y\|_W$ is a normed space. Using this norm it's easy to show that if $V,W$ are complete then so is $V \times W$. To see this, let the limit of the sequence $(x_n , y_n)$ be $(x,y) = (\lim x_n, \lim y_n)$.  Then for $n$ large enough, both $\|x - x_n\|_V$ and $\|y - y_n\|_W$ are less than $\varepsilon / 2$ and hence $\|(x,y) - (x_n, y_n)\|< \varepsilon$. The other direction does (probably) not hold. Can someone show me an example of a space $V \times W$ that is complete but either $V$ or $W$ (or both) are not?",,"['functional-analysis', 'vector-spaces', 'banach-spaces', 'examples-counterexamples', 'normed-spaces']"
8,What should a PDE/analysis enthusiast know?,What should a PDE/analysis enthusiast know?,,"What are the cool things someone who likes PDE and functional analysis should know and learn about? What do you think are the fundamentals and the next steps? I was thinking it would be good to know how to show existence or even to know where to start to show existence of any non-linear PDE I come across. For example, I only recently found about about how people can use the inverse theorem to prove existence of a non-linear PDE. This involved Frechet derivatives which I have never seen before. And I don't fully appreciate the link between normal derivative, Gateaux derivative and Frechet derivative. So I thought how many other things I have no idea about in PDEs. And PDEs on surface are interesting (but I'm just learning differential geometry so a long wait till I look at that in detail) but it seems studied to death. So anyway what do you think is interesting in this field? I am less interested in constructing solutions to PDEs and more into existence. PS: you can assume the basic knowledge (Lax-Milgram, linear elliptic and parabolic existence and uniqueness, etc..)","What are the cool things someone who likes PDE and functional analysis should know and learn about? What do you think are the fundamentals and the next steps? I was thinking it would be good to know how to show existence or even to know where to start to show existence of any non-linear PDE I come across. For example, I only recently found about about how people can use the inverse theorem to prove existence of a non-linear PDE. This involved Frechet derivatives which I have never seen before. And I don't fully appreciate the link between normal derivative, Gateaux derivative and Frechet derivative. So I thought how many other things I have no idea about in PDEs. And PDEs on surface are interesting (but I'm just learning differential geometry so a long wait till I look at that in detail) but it seems studied to death. So anyway what do you think is interesting in this field? I am less interested in constructing solutions to PDEs and more into existence. PS: you can assume the basic knowledge (Lax-Milgram, linear elliptic and parabolic existence and uniqueness, etc..)",,"['functional-analysis', 'soft-question', 'partial-differential-equations']"
9,Spectra of restrictions of bounded operators,Spectra of restrictions of bounded operators,,"Suppose $T$ is a bounded operator on a Banach Space $X$ and $Y$ is a non-trivial closed  invariant subspace for $T$. It is fairly easy to show that for the point spectrum one has $\sigma_p(T_{|Y})\subseteq\sigma_p(T)$ and this is also true for the approximate point spectrum , i.e. $\sigma_a(T_{|Y})\subseteq\sigma_a(T)$. However I think it is not true in general that $\sigma(T_{|Y})\subseteq\sigma(T)$. We also have $$ \partial(\sigma(T_{|Y}))\subseteq\sigma_a(T_{|Y})\subseteq\sigma_a(T) $$ Hence $\sigma(T_{|Y})\cap\sigma(T)\ne\emptyset$. Moreover, if $\sigma(T)$ is discrete then $\partial(\sigma(T_{|Y}))$ is also discrete, which implies that $\partial(\sigma(T_{|Y}))=\sigma(T_{|Y})$, so at least in this case the inclusion  $\sigma(T_{|Y})\subseteq\sigma(T)$ holds true. So for example holds true for compact, strictly singular and quasinilpotent operators. Question 1 : Is it true, as I suspect, that $\sigma(T_{|Y})\subseteq\sigma(T)$  doesn't hold in general? A counterexample will be appreciated. On $l_2$ will do, as I think that on some Banach spaces this holds for any operators. For example, if $X$ is hereditary indecomposable (HI), the spectrum of any operator is discrete. Question 2 (imprecise): If the answer to Q1 is 'yes', is there some known result regarding how large the spectrum of the restriction can become? Thank you.","Suppose $T$ is a bounded operator on a Banach Space $X$ and $Y$ is a non-trivial closed  invariant subspace for $T$. It is fairly easy to show that for the point spectrum one has $\sigma_p(T_{|Y})\subseteq\sigma_p(T)$ and this is also true for the approximate point spectrum , i.e. $\sigma_a(T_{|Y})\subseteq\sigma_a(T)$. However I think it is not true in general that $\sigma(T_{|Y})\subseteq\sigma(T)$. We also have $$ \partial(\sigma(T_{|Y}))\subseteq\sigma_a(T_{|Y})\subseteq\sigma_a(T) $$ Hence $\sigma(T_{|Y})\cap\sigma(T)\ne\emptyset$. Moreover, if $\sigma(T)$ is discrete then $\partial(\sigma(T_{|Y}))$ is also discrete, which implies that $\partial(\sigma(T_{|Y}))=\sigma(T_{|Y})$, so at least in this case the inclusion  $\sigma(T_{|Y})\subseteq\sigma(T)$ holds true. So for example holds true for compact, strictly singular and quasinilpotent operators. Question 1 : Is it true, as I suspect, that $\sigma(T_{|Y})\subseteq\sigma(T)$  doesn't hold in general? A counterexample will be appreciated. On $l_2$ will do, as I think that on some Banach spaces this holds for any operators. For example, if $X$ is hereditary indecomposable (HI), the spectrum of any operator is discrete. Question 2 (imprecise): If the answer to Q1 is 'yes', is there some known result regarding how large the spectrum of the restriction can become? Thank you.",,"['reference-request', 'functional-analysis', 'banach-spaces', 'operator-theory']"
10,A Riesz-type norm-preserving and bijective mapping between a Banach space and its dual,A Riesz-type norm-preserving and bijective mapping between a Banach space and its dual,,"Let $\Omega$ be a measure space and let $1<p<\infty$ and $p'=p/(p-1)$. Also let us agree to write simply $L^p$ instead of $L^p(\Omega)$. If we identify the dual space $\left(L^p\right)^\star$ with $L^{p'}$ via the isomorphism $$\left[ v \in L^{p'}\right] \leftrightarrow \left[ L_v\in \left(L^p\right)^\star\ \text{defined to be}\ \langle L_v, u\rangle=\int_{\Omega}vu\, d\mu\right],$$ we can define an interesting map $\mathcal{D}\colon L^p\to \left(L^p\right)^\star$ as follows: $$\mathcal{D}u=\frac{\lvert u \rvert^{p-1}\text{signum}(u)}{\left(\int_{\Omega}\lvert u \rvert^p\, d\mu\right)^{\frac{p-2}{p}}},$$ (with the convention that $\mathcal{D}0=0$). This map $\mathcal{D}$ is non-linear, except for $p=2$ in which case it becomes the Riesz isomorphism of the Hilbert space $L^2$ with its dual. Also, $\mathcal{D}$ is norm-preserving and is characterized by the following property: $\mathcal{D}u$ is the unique element of $\left(L^p\right)^\star$ such that    $$\tag{1} \lVert \mathcal{D}u\rVert_\star=\lVert u \rVert_p\quad \text{and}\quad \langle \mathcal{D}u,u\rangle=\lVert  \mathcal{D}u\rVert_{\star}\lVert u\rVert_p.$$ Moreover, $\mathcal{D}$ is invertible: indeed, as it is readily seen, $$\mathcal{D}^{-1}v=\frac{\lvert v \rvert^{p'-1}\text{signum}(v)}{\left(\int_{\Omega}\lvert v \rvert^{p'}\, d\mu\right)^{\frac{p'-2}{p'}}}.$$ We can also characterize $\mathcal{D}^{-1}$ in complete analogy with what we have already done: $\mathcal{D}^{-1}v$ is the unique element of $L^p$ such that   $$\tag{2}\lVert \mathcal{D}^{-1}v\rVert_p=\lVert v\rVert_{\star}\quad \text{and}\quad \langle v, \mathcal{D}^{-1}v\rangle=\lVert v\rVert_\star\lVert\mathcal{D}^{-1}v\rVert_p.$$ The question follows. Question Suppose that $X$ is an abstract Banach space. Which properties must $X$ have so that a mapping $\mathcal{D}\colon X \to X^\star$ is uniquely defined by property (1)? When is $\mathcal{D}$ bijective? As already mentioned in this question ,  the existence and bijectivity of $\mathcal{D}$ in $L^p$ space seem to have something to do with the uniform convexity of $L^p$ and $(L^p)^\star$. I guess there is something more general beneath the surface here. Thank you for reading.","Let $\Omega$ be a measure space and let $1<p<\infty$ and $p'=p/(p-1)$. Also let us agree to write simply $L^p$ instead of $L^p(\Omega)$. If we identify the dual space $\left(L^p\right)^\star$ with $L^{p'}$ via the isomorphism $$\left[ v \in L^{p'}\right] \leftrightarrow \left[ L_v\in \left(L^p\right)^\star\ \text{defined to be}\ \langle L_v, u\rangle=\int_{\Omega}vu\, d\mu\right],$$ we can define an interesting map $\mathcal{D}\colon L^p\to \left(L^p\right)^\star$ as follows: $$\mathcal{D}u=\frac{\lvert u \rvert^{p-1}\text{signum}(u)}{\left(\int_{\Omega}\lvert u \rvert^p\, d\mu\right)^{\frac{p-2}{p}}},$$ (with the convention that $\mathcal{D}0=0$). This map $\mathcal{D}$ is non-linear, except for $p=2$ in which case it becomes the Riesz isomorphism of the Hilbert space $L^2$ with its dual. Also, $\mathcal{D}$ is norm-preserving and is characterized by the following property: $\mathcal{D}u$ is the unique element of $\left(L^p\right)^\star$ such that    $$\tag{1} \lVert \mathcal{D}u\rVert_\star=\lVert u \rVert_p\quad \text{and}\quad \langle \mathcal{D}u,u\rangle=\lVert  \mathcal{D}u\rVert_{\star}\lVert u\rVert_p.$$ Moreover, $\mathcal{D}$ is invertible: indeed, as it is readily seen, $$\mathcal{D}^{-1}v=\frac{\lvert v \rvert^{p'-1}\text{signum}(v)}{\left(\int_{\Omega}\lvert v \rvert^{p'}\, d\mu\right)^{\frac{p'-2}{p'}}}.$$ We can also characterize $\mathcal{D}^{-1}$ in complete analogy with what we have already done: $\mathcal{D}^{-1}v$ is the unique element of $L^p$ such that   $$\tag{2}\lVert \mathcal{D}^{-1}v\rVert_p=\lVert v\rVert_{\star}\quad \text{and}\quad \langle v, \mathcal{D}^{-1}v\rangle=\lVert v\rVert_\star\lVert\mathcal{D}^{-1}v\rVert_p.$$ The question follows. Question Suppose that $X$ is an abstract Banach space. Which properties must $X$ have so that a mapping $\mathcal{D}\colon X \to X^\star$ is uniquely defined by property (1)? When is $\mathcal{D}$ bijective? As already mentioned in this question ,  the existence and bijectivity of $\mathcal{D}$ in $L^p$ space seem to have something to do with the uniform convexity of $L^p$ and $(L^p)^\star$. I guess there is something more general beneath the surface here. Thank you for reading.",,"['functional-analysis', 'banach-spaces']"
11,Quantum Mechanics state space,Quantum Mechanics state space,,"In Quantum Mechanics one often deals with wavefunctions of particles. In that case, it is natural to consider as the space of states the space $L^2(\mathbb{R}^3)$. On the other hand, on the book I'm reading, there's a construction which it's quite elegant and general, however it is not rigorous. For those interested in seeing the book, it's ""Quantum Mechanics"" by Cohen-Tannoudji. The book proceeds as follows: the first postulate of Quantum Mechanics states that for every quantum system there is one Hilbert space $\mathcal{H}$ whose elements describe the possible states of the system. The idea then is that $\mathcal{H}$ doesn't necessarily is a space of functions. Indeed, Cohen defines (or doesn't define) $\mathcal{H}$ as the space of kets $|\psi\rangle\in \mathcal{H}$, being the kets just vectors encoding the states of the system. The second postulate states that for each physically observable quantity there is associated one hermitian operator $A$ such that the only possible values to be measured are the eigenvalues of $A$ and such that If $A$ has discrete spectrum $\{|\psi_n\rangle : n \in \mathbb{N}\}$ then the probability of measuring the eigenvalue $a_n$ on the state $|\psi\rangle$ is $\langle \psi_n | \psi\rangle$ considering that $|\psi\rangle$ is normalized. If $A$ has continuous spectrum $\{|\psi_{\lambda}\rangle : \lambda \in \Lambda\}$ then the probability density on state $|\psi\rangle$ for the possible eigenvalues is $\lambda \mapsto \langle \psi_\lambda | \psi\rangle$ If, for example, the position operator $X$ for particle in one-dimension, exists, and if its eigenvectors are $|x\rangle$ with eigenvalues $x$, for each $x\in \mathbb{R}$, the probability density of position is $\langle x |\psi\rangle$ which is a function $\mathbb{R}\to \mathbb{C}$ and we recover the wavefunction. This formulation, though, seems to be more general. In that case, wavefunction is just the information about one possible kind of measurement which we can obtain from the postulates. There is nothing special with it. Now, although quite elegant and simple, this is not even a little rigorous. For example: the position operator hasn't been defined! It is just ""the operator associated to position with continuous spectrum"", but this doesn't define the operator. On the book, it is defined on the basis $\{|x\rangle\}$, but this set is defined in terms of it, so we get circular. Another problem is that usually we are dealing with unbounded operators which are not defined on the whole of $\mathcal{H}$. And an even greater problem is that $\mathcal{H}$ was never defined! I've been looking forward to find out how to make this rigorous, but couldn't find anything useful. Many people simply say that the right way is to consider always $L^2(\mathbb{R}^3)$, so that all of this talk is nonsense. But I disagree, I find it quite natural to consider this generalized version. The only thing I've found was the idea of rigged Hilbert spaces, known also as Gel'fand triple. I've found not much material about it, but anyway, I didn't understand how it can be used to make this rigorous. In that case, how does one make this idea of space of states, or space of kets, fully rigorous, overcoming the problems I found out, and possibly any others that may exist? Is it through the Gel'fand triple? If so, how is it done?","In Quantum Mechanics one often deals with wavefunctions of particles. In that case, it is natural to consider as the space of states the space $L^2(\mathbb{R}^3)$. On the other hand, on the book I'm reading, there's a construction which it's quite elegant and general, however it is not rigorous. For those interested in seeing the book, it's ""Quantum Mechanics"" by Cohen-Tannoudji. The book proceeds as follows: the first postulate of Quantum Mechanics states that for every quantum system there is one Hilbert space $\mathcal{H}$ whose elements describe the possible states of the system. The idea then is that $\mathcal{H}$ doesn't necessarily is a space of functions. Indeed, Cohen defines (or doesn't define) $\mathcal{H}$ as the space of kets $|\psi\rangle\in \mathcal{H}$, being the kets just vectors encoding the states of the system. The second postulate states that for each physically observable quantity there is associated one hermitian operator $A$ such that the only possible values to be measured are the eigenvalues of $A$ and such that If $A$ has discrete spectrum $\{|\psi_n\rangle : n \in \mathbb{N}\}$ then the probability of measuring the eigenvalue $a_n$ on the state $|\psi\rangle$ is $\langle \psi_n | \psi\rangle$ considering that $|\psi\rangle$ is normalized. If $A$ has continuous spectrum $\{|\psi_{\lambda}\rangle : \lambda \in \Lambda\}$ then the probability density on state $|\psi\rangle$ for the possible eigenvalues is $\lambda \mapsto \langle \psi_\lambda | \psi\rangle$ If, for example, the position operator $X$ for particle in one-dimension, exists, and if its eigenvectors are $|x\rangle$ with eigenvalues $x$, for each $x\in \mathbb{R}$, the probability density of position is $\langle x |\psi\rangle$ which is a function $\mathbb{R}\to \mathbb{C}$ and we recover the wavefunction. This formulation, though, seems to be more general. In that case, wavefunction is just the information about one possible kind of measurement which we can obtain from the postulates. There is nothing special with it. Now, although quite elegant and simple, this is not even a little rigorous. For example: the position operator hasn't been defined! It is just ""the operator associated to position with continuous spectrum"", but this doesn't define the operator. On the book, it is defined on the basis $\{|x\rangle\}$, but this set is defined in terms of it, so we get circular. Another problem is that usually we are dealing with unbounded operators which are not defined on the whole of $\mathcal{H}$. And an even greater problem is that $\mathcal{H}$ was never defined! I've been looking forward to find out how to make this rigorous, but couldn't find anything useful. Many people simply say that the right way is to consider always $L^2(\mathbb{R}^3)$, so that all of this talk is nonsense. But I disagree, I find it quite natural to consider this generalized version. The only thing I've found was the idea of rigged Hilbert spaces, known also as Gel'fand triple. I've found not much material about it, but anyway, I didn't understand how it can be used to make this rigorous. In that case, how does one make this idea of space of states, or space of kets, fully rigorous, overcoming the problems I found out, and possibly any others that may exist? Is it through the Gel'fand triple? If so, how is it done?",,"['functional-analysis', 'hilbert-spaces', 'mathematical-physics', 'spectral-theory', 'quantum-mechanics']"
12,Does existence of a non-continuous linear functional depend on Axiom of Choice?,Does existence of a non-continuous linear functional depend on Axiom of Choice?,,"Well, it is easy to construct a non-continuous linear functional on an arbitrary infinite-dimensional vector space (assuming Choice, and taking a basis etc.). I think it is intuitive to say that: Every non-finite-dimensional space has a non-continuous linear functional. depends on the axiom of choice. But what if I am not so demanding, and just want an example of a vector space where there exists a non-continuous linear functional. Do I need choice for that? (OBS: I'm restricting myself to normed spaces)","Well, it is easy to construct a non-continuous linear functional on an arbitrary infinite-dimensional vector space (assuming Choice, and taking a basis etc.). I think it is intuitive to say that: Every non-finite-dimensional space has a non-continuous linear functional. depends on the axiom of choice. But what if I am not so demanding, and just want an example of a vector space where there exists a non-continuous linear functional. Do I need choice for that? (OBS: I'm restricting myself to normed spaces)",,"['functional-analysis', 'vector-spaces', 'banach-spaces', 'axiom-of-choice']"
13,$l^\infty(I)$ and $l^\infty(J)$ isometrically isomorphic with $|I| \not= |J|.$,and  isometrically isomorphic with,l^\infty(I) l^\infty(J) |I| \not= |J|.,"Is it possible for $l^\infty (I)$ and $l^{\infty} (J)$ to be isometrically isomorphic with the cardinality of $I$ not equal to the cardinality of $J$? I'm able to show that if $1\le p < \infty,$ then $l^{p} (I)$ and $l^p (J)$ are isometrically isomorphic iff $|I| = |J|,$ but this relies on constructing a dense subset of $l^p (I)$ with cardinality equal to that of $I.$ Obviously this fails in $l^{\infty}$ since $l^\infty$ isn't separable, but I'm having trouble coming up with an example. Edit: This is an exercise in Conway's ""A Course in Functional Analysis,"" Chapter III, Section 1, just after the introduction to Banach spaces, so it seems that it can be done from first principles.","Is it possible for $l^\infty (I)$ and $l^{\infty} (J)$ to be isometrically isomorphic with the cardinality of $I$ not equal to the cardinality of $J$? I'm able to show that if $1\le p < \infty,$ then $l^{p} (I)$ and $l^p (J)$ are isometrically isomorphic iff $|I| = |J|,$ but this relies on constructing a dense subset of $l^p (I)$ with cardinality equal to that of $I.$ Obviously this fails in $l^{\infty}$ since $l^\infty$ isn't separable, but I'm having trouble coming up with an example. Edit: This is an exercise in Conway's ""A Course in Functional Analysis,"" Chapter III, Section 1, just after the introduction to Banach spaces, so it seems that it can be done from first principles.",,"['functional-analysis', 'lp-spaces']"
14,"Cauchy Sequence in $X$ on $[0,1]$ with norm $\int_{0}^{1} |x(t)|dt$",Cauchy Sequence in  on  with norm,"X [0,1] \int_{0}^{1} |x(t)|dt","In Luenberger's Optimization book pg. 34 an example says ""Let $X$ be the space of continuous functions on $[0,1]$ with norm defined as $\|x\| = \int_{0}^{1} |x(t)|dt$"". In order to prove $X$ is incomplete, he defines a sequence of elements in $X$ by $$ x_n(t) = \left\{ \begin{array}{ll} 0 &  0 \le t \le \frac{1}{2} - \frac{1}{n} \\ \\ nt-\frac{n}{2} + 1 &  \frac{1}{2} - \frac{1}{n} \le t \le \frac{1}{2} \\ \\ 1 & t \ge \frac{1}{2} \end{array} \right.  $$ Each member of the sequence is a continuous function and thus member of space $X$. Then he says: the sequence is Cauchy since, as it is easily verified, $\|x_n - x_m\| = \frac{1}{2}\left|\dfrac1n - \dfrac1m\right| \to 0$. as $n,m \to \infty$. I tried to verify the norm $\|x_n - x_m\|$ by computing the integral for the norm. The piecewise function is not dependent on $n,m$ on the last piece (for $t \ge 1/2$), so norm $\|x_n - x_m\|$ is 0. For the middle piece I calculated the integral, it comes up zero. That leaves the first piece, and I did not receive the result Luenberger has. Is there something wrong in my approach?","In Luenberger's Optimization book pg. 34 an example says ""Let $X$ be the space of continuous functions on $[0,1]$ with norm defined as $\|x\| = \int_{0}^{1} |x(t)|dt$"". In order to prove $X$ is incomplete, he defines a sequence of elements in $X$ by $$ x_n(t) = \left\{ \begin{array}{ll} 0 &  0 \le t \le \frac{1}{2} - \frac{1}{n} \\ \\ nt-\frac{n}{2} + 1 &  \frac{1}{2} - \frac{1}{n} \le t \le \frac{1}{2} \\ \\ 1 & t \ge \frac{1}{2} \end{array} \right.  $$ Each member of the sequence is a continuous function and thus member of space $X$. Then he says: the sequence is Cauchy since, as it is easily verified, $\|x_n - x_m\| = \frac{1}{2}\left|\dfrac1n - \dfrac1m\right| \to 0$. as $n,m \to \infty$. I tried to verify the norm $\|x_n - x_m\|$ by computing the integral for the norm. The piecewise function is not dependent on $n,m$ on the last piece (for $t \ge 1/2$), so norm $\|x_n - x_m\|$ is 0. For the middle piece I calculated the integral, it comes up zero. That leaves the first piece, and I did not receive the result Luenberger has. Is there something wrong in my approach?",,"['analysis', 'functional-analysis', 'cauchy-sequences']"
15,"For which $s\in\mathbb R$, is $H^s(\mathbb T)$ a Banach algebra?","For which , is  a Banach algebra?",s\in\mathbb R H^s(\mathbb T),"According to Theorem 4.39 in Adams & Fournier Sobolev Spaces : If $mp>n$ , $m\in\mathbb N$ , then $W^{m,p}(\Omega)$ is a Banach algebra $($ i.e., if $u,v\in W^{m,p}(\Omega)$ , then $uv\in W^{m,p}(\Omega)$ as well $)$ , provided that $\Omega\subset\mathbb R^n$ satisfies the cone condition. Clearly, $(0,2\pi)$ does satisfy the cone condition. However, does the above Theorem 4.39 apply for $m$ real? In particular, is it true that $H^s(\mathbb T)$ is a Banach algebra, for $s>1/2$ and there is a $c>0$ , such that $$ \|uv\|_{H^s} \le c\,\|u\|_{H^s}\|v\|_{H^s}, $$ for all $u,v \in H^s(\mathbb T)$ ?","According to Theorem 4.39 in Adams & Fournier Sobolev Spaces : If , , then is a Banach algebra i.e., if , then as well , provided that satisfies the cone condition. Clearly, does satisfy the cone condition. However, does the above Theorem 4.39 apply for real? In particular, is it true that is a Banach algebra, for and there is a , such that for all ?","mp>n m\in\mathbb N W^{m,p}(\Omega) ( u,v\in W^{m,p}(\Omega) uv\in W^{m,p}(\Omega) ) \Omega\subset\mathbb R^n (0,2\pi) m H^s(\mathbb T) s>1/2 c>0 
\|uv\|_{H^s} \le c\,\|u\|_{H^s}\|v\|_{H^s},
 u,v \in H^s(\mathbb T)","['analysis', 'functional-analysis', 'fourier-analysis', 'sobolev-spaces', 'banach-algebras']"
16,Soft Question Hilbert Space Geometry,Soft Question Hilbert Space Geometry,,"Just a quick question about the geometry of Hilbert spaces from an intuitive standpoint.  Maybe just assuming we're working with $L^2$ would simplify the situation. Basically, in something like $\mathbb{R}^2$ we have the situation that $\cos(\theta)=\frac{\langle a,b\rangle}{\vert a\vert\cdot\vert b\vert}$, and the idea of an angle between vectors is very meaningful, geometrically.  We can easily extend this idea to $\mathbb{R}^n$ because when we talk about the angle between two vectors, we mean we are choosing the plane that both of them lie in, and picking the vector in there.  But what does this really mean in a Hilbert space like $L^2$? I have a good intuition about functions, and about geometry (topology) separately, but not really the ""geometry of functions"". Now, there may be no visualization of this in $L^2$, and I'm not asking for one, but is there any sense to doing geometry (i.e. actual polygons, things like that) in a space like $L^2$?  Also, what sort of applications do ideas like this have in functional analysis?  Are we ever interested in ideas like ""planes"" of functions, polygons, surfaces, solids, etc.? What do we really mean by angles, projections, normal vectors?  And do these sorts of things ever have any sort of interesting relationships? I'm primarily asking for an intuitive idea here.  It's easy to just do the math, prove theorems about inner products, norms, etc. Maybe geometry gives some clues or intuitive ideas when doing functional analysis?","Just a quick question about the geometry of Hilbert spaces from an intuitive standpoint.  Maybe just assuming we're working with $L^2$ would simplify the situation. Basically, in something like $\mathbb{R}^2$ we have the situation that $\cos(\theta)=\frac{\langle a,b\rangle}{\vert a\vert\cdot\vert b\vert}$, and the idea of an angle between vectors is very meaningful, geometrically.  We can easily extend this idea to $\mathbb{R}^n$ because when we talk about the angle between two vectors, we mean we are choosing the plane that both of them lie in, and picking the vector in there.  But what does this really mean in a Hilbert space like $L^2$? I have a good intuition about functions, and about geometry (topology) separately, but not really the ""geometry of functions"". Now, there may be no visualization of this in $L^2$, and I'm not asking for one, but is there any sense to doing geometry (i.e. actual polygons, things like that) in a space like $L^2$?  Also, what sort of applications do ideas like this have in functional analysis?  Are we ever interested in ideas like ""planes"" of functions, polygons, surfaces, solids, etc.? What do we really mean by angles, projections, normal vectors?  And do these sorts of things ever have any sort of interesting relationships? I'm primarily asking for an intuitive idea here.  It's easy to just do the math, prove theorems about inner products, norms, etc. Maybe geometry gives some clues or intuitive ideas when doing functional analysis?",,"['soft-question', 'functional-analysis', 'hilbert-spaces']"
17,Show that $F+G$ is closed when $G$ a closed subspace of normed space $E$ and $F$ a finite dimensional subspace of $E$.,Show that  is closed when  a closed subspace of normed space  and  a finite dimensional subspace of .,F+G G E F E,"Question: Let $E$ be a normed space. Let $G$ be a closed subspace of $E$ and let $F$ be a finite dimensional subspace of $E$. Show that $F+G$ is a subspace of $E$ and is closed. I'm having trouble in showing $F+G$ to be closed. I know that $F$ is itself closed and complete, as it is a finite dimensional subspace of a normed space, and that if $F$ were compact that $G+F$ would be closed. I also know that the closed unit ball of any finite dimensional normed space is compact. I tried two methods. One was to take a convergent sequence $(x_n)_{n \in \mathbb N}$ in $G+F$. Then we can write $x_n = f_n + g_n$ where $f_n$ and $g_n$ are sequences in $F$ and $G$ respectively, and I attempted to find a way to force the individual components $f_n$ and $g_n$ inside the unit ball which would enable me to say that they had convergent subsequences. I couldn't see how to do this, however. The other thought was to try and show that $F$ is compact, but I don't see a way to do this as I can't imagine it to be simply true without some other conditions on $F$. Are one of these methods the right way to go? Or should I go another direction? I would appreciate any help I can get, although I would prefer not to be presented with a full proof so that I can do some work for myself. Thanks!","Question: Let $E$ be a normed space. Let $G$ be a closed subspace of $E$ and let $F$ be a finite dimensional subspace of $E$. Show that $F+G$ is a subspace of $E$ and is closed. I'm having trouble in showing $F+G$ to be closed. I know that $F$ is itself closed and complete, as it is a finite dimensional subspace of a normed space, and that if $F$ were compact that $G+F$ would be closed. I also know that the closed unit ball of any finite dimensional normed space is compact. I tried two methods. One was to take a convergent sequence $(x_n)_{n \in \mathbb N}$ in $G+F$. Then we can write $x_n = f_n + g_n$ where $f_n$ and $g_n$ are sequences in $F$ and $G$ respectively, and I attempted to find a way to force the individual components $f_n$ and $g_n$ inside the unit ball which would enable me to say that they had convergent subsequences. I couldn't see how to do this, however. The other thought was to try and show that $F$ is compact, but I don't see a way to do this as I can't imagine it to be simply true without some other conditions on $F$. Are one of these methods the right way to go? Or should I go another direction? I would appreciate any help I can get, although I would prefer not to be presented with a full proof so that I can do some work for myself. Thanks!",,"['functional-analysis', 'vector-spaces', 'normed-spaces']"
18,Isometry between $L_\infty$ and $\ell_\infty$,Isometry between  and,L_\infty \ell_\infty,"It is known that there exist some isomorphism between $L_\infty$ and $\ell_\infty$, which is not explicit at all. Could someone tell me whether there exist an isometric isomorphism between $L_\infty$ and $\ell_\infty$?","It is known that there exist some isomorphism between $L_\infty$ and $\ell_\infty$, which is not explicit at all. Could someone tell me whether there exist an isometric isomorphism between $L_\infty$ and $\ell_\infty$?",,"['functional-analysis', 'banach-spaces', 'lp-spaces']"
19,Isomorphisms of Fréchet Spaces,Isomorphisms of Fréchet Spaces,,"What is the proper notion of an isomorphism between Fréchet spaces?  Obviously it should be a linear map.  I'm just worried about the analytic structure.  Should one be able to order the seminorms on each space so that the isomorphism preserves each seminorm (i.e., $q_n(\phi (v))=p_n(v)$)?  Should it preserve the translation invariant metric?  Or should it just be a homeomorphism? I'm leaning towards the last one, as the other two notions seem too strong, especially the first, but I figured I'd ask here to double check before I go ahead with what I'm doing. Thanks much!","What is the proper notion of an isomorphism between Fréchet spaces?  Obviously it should be a linear map.  I'm just worried about the analytic structure.  Should one be able to order the seminorms on each space so that the isomorphism preserves each seminorm (i.e., $q_n(\phi (v))=p_n(v)$)?  Should it preserve the translation invariant metric?  Or should it just be a homeomorphism? I'm leaning towards the last one, as the other two notions seem too strong, especially the first, but I figured I'd ask here to double check before I go ahead with what I'm doing. Thanks much!",,"['functional-analysis', 'topological-vector-spaces']"
20,"Prove that $(l^\infty,\|.\|_\infty)$ is a Banach space.",Prove that  is a Banach space.,"(l^\infty,\|.\|_\infty)","$(l^\infty,\|.\|_\infty)$ is a Banach space. In the proof, $\mathbb{F}$ is either the field of complex numbers or the field of real numbers. Proof: Let $(x^n)_{n\in\mathbb{N}}$ be a Cauchy sequence in $l^\infty$ , where $x^n=(x_k^n)_{k\in\mathbb{N}}$ . Consider the sequence $(x^0_k,x^1_k,\cdots,x^n_k,\cdots)$ of $k$ th coordinates of the sequence $(x^n)_{n\in\mathbb{N}}$ . Let $\epsilon>0$ . Since $(x^n)_{n\in\mathbb{N}}$ is Cauchy, there exists $n_0\in\mathbb{N}$ such that $$\forall m,n>n_0,\|x^m-x^n\|_\infty<\epsilon.$$ Therefore for each $m,n>n_0$ we have $$|x^m_k-x^n_k|<\epsilon.$$ So the sequence $(x^0_k,x^1_k,\cdots,x^n_k,\cdots)$ is Cauchy. Therefore it converges to some $y_k\in\mathbb{F}\ $ ( $\mathbb{F}$ is complete). Let $y=(y_k)_{k\in\mathbb{N}}$ . Since $(x^0_k,x^1_k,\cdots,x^n_k,\cdots)$ is Cauchy it is bounded. Choose $M>0$ such that for each $n\in\mathbb{N}$ , $|x^n_k|<M$ . But since $$y_k=\lim_{n\to\infty}x_k^n,$$ we have $|y_k|\leq M$ for each $k$ . Therefore, $y\in l^\infty$ . Fix $m>n_0$ . Then we have $\|x^m-x^n\|_\infty<\epsilon.$ Therefore $\|x^m-y\|_\infty<\epsilon$ as $n\to\infty$ . Therefore for each $m>n_0,\ \|x^m-y\|_\infty<\epsilon$ . Hence $(x^n)_{n\in\mathbb{N}}$ converges in $l^\infty$ and the proof is complete. Could someone please tell me if the above proof is alright? Thanks.","is a Banach space. In the proof, is either the field of complex numbers or the field of real numbers. Proof: Let be a Cauchy sequence in , where . Consider the sequence of th coordinates of the sequence . Let . Since is Cauchy, there exists such that Therefore for each we have So the sequence is Cauchy. Therefore it converges to some ( is complete). Let . Since is Cauchy it is bounded. Choose such that for each , . But since we have for each . Therefore, . Fix . Then we have Therefore as . Therefore for each . Hence converges in and the proof is complete. Could someone please tell me if the above proof is alright? Thanks.","(l^\infty,\|.\|_\infty) \mathbb{F} (x^n)_{n\in\mathbb{N}} l^\infty x^n=(x_k^n)_{k\in\mathbb{N}} (x^0_k,x^1_k,\cdots,x^n_k,\cdots) k (x^n)_{n\in\mathbb{N}} \epsilon>0 (x^n)_{n\in\mathbb{N}} n_0\in\mathbb{N} \forall m,n>n_0,\|x^m-x^n\|_\infty<\epsilon. m,n>n_0 |x^m_k-x^n_k|<\epsilon. (x^0_k,x^1_k,\cdots,x^n_k,\cdots) y_k\in\mathbb{F}\  \mathbb{F} y=(y_k)_{k\in\mathbb{N}} (x^0_k,x^1_k,\cdots,x^n_k,\cdots) M>0 n\in\mathbb{N} |x^n_k|<M y_k=\lim_{n\to\infty}x_k^n, |y_k|\leq M k y\in l^\infty m>n_0 \|x^m-x^n\|_\infty<\epsilon. \|x^m-y\|_\infty<\epsilon n\to\infty m>n_0,\ \|x^m-y\|_\infty<\epsilon (x^n)_{n\in\mathbb{N}} l^\infty","['functional-analysis', 'banach-spaces', 'solution-verification']"
21,Show that $c_0$ is a Banach space with the norm $\rVert \cdot \lVert_\infty$,Show that  is a Banach space with the norm,c_0 \rVert \cdot \lVert_\infty,"Let $ c_0 = \{ x = (x_n)_{n \in \mathbb N} \in l^\infty : \lim_{n \to \infty} x_n = 0\}$ . Show that $c_0$ is a Banach space with the norm $\rVert \cdot \lVert_\infty$ I am capable of showing the space where the limit of $x_n$ exists is normed linear space but am having trouble with showing that the limit of Cauchy sequences must converge to 0. Let $(x^{(n)})_{n \in \mathbb N}$ be a Cauchy sequence in $c_0$ such that $x^{n} = (x^n_1, x^n_2,...)$ . Fix $k \in \mathbb N$ consider the sequence $(x^n_k)_{n \in \mathbb N}$ in $\mathbb F$ . For any $n,m \in \mathbb N$ $\lvert x^n_k - x^m_k \rvert \le \sup_{k \in \mathbb N} \lvert x^n_k - x^m_k \rvert = \lVert x^n - x^m \rVert_\infty \lt \epsilon $ (1) Thus $x^n_k$ is Cauchy in $\mathbb F$ and so has limit $y_k$ such that $y = (y_1,y_2,...)$ and y is the limit of $x^n$ To show that such a y exists we look at the value of $\lvert y_n - y_m \rvert \le \lvert y_n - x^N_n \rvert + \lvert x^N_n - x^N_m \rvert + \lvert x^N_m - y_m \rvert \lt \epsilon$ for all $n,m \ge N$ (2) The middle expression on RHS of (2)  is $\lt \epsilon/3$ by (1) The other two are also $\lt \epsilon/3$ follow from $x^N_k$ being Cauchy and converging to $y_k$ This shows that $\lim_{n \to \infty} y_n$ exists but we still have not shown that $y \in c_0$ . I know that to show y tends to 0 i should show that $\lvert y_k \rvert \lt \epsilon$ for $k \ge N$ This is where I am stuck. Perhaps $\lvert y_k \rvert = \lvert \lim_{n \to \infty} x^n_k \rvert$ and then we can take the limit function outside the absolute value sign by continuity? Then we might say due to it being a Cauchy sequence $x^n_k \lt \epsilon$ . I know this last bit isn't at all convincing so I could do with some help.",Let . Show that is a Banach space with the norm I am capable of showing the space where the limit of exists is normed linear space but am having trouble with showing that the limit of Cauchy sequences must converge to 0. Let be a Cauchy sequence in such that . Fix consider the sequence in . For any (1) Thus is Cauchy in and so has limit such that and y is the limit of To show that such a y exists we look at the value of for all (2) The middle expression on RHS of (2)  is by (1) The other two are also follow from being Cauchy and converging to This shows that exists but we still have not shown that . I know that to show y tends to 0 i should show that for This is where I am stuck. Perhaps and then we can take the limit function outside the absolute value sign by continuity? Then we might say due to it being a Cauchy sequence . I know this last bit isn't at all convincing so I could do with some help.," c_0 = \{ x = (x_n)_{n \in \mathbb N} \in l^\infty : \lim_{n \to \infty} x_n = 0\} c_0 \rVert \cdot \lVert_\infty x_n (x^{(n)})_{n \in \mathbb N} c_0 x^{n} = (x^n_1, x^n_2,...) k \in \mathbb N (x^n_k)_{n \in \mathbb N} \mathbb F n,m \in \mathbb N \lvert x^n_k - x^m_k \rvert \le \sup_{k \in \mathbb N} \lvert x^n_k - x^m_k \rvert = \lVert x^n - x^m \rVert_\infty \lt \epsilon  x^n_k \mathbb F y_k y = (y_1,y_2,...) x^n \lvert y_n - y_m \rvert \le \lvert y_n - x^N_n \rvert + \lvert x^N_n - x^N_m \rvert + \lvert x^N_m - y_m \rvert \lt \epsilon n,m \ge N \lt \epsilon/3 \lt \epsilon/3 x^N_k y_k \lim_{n \to \infty} y_n y \in c_0 \lvert y_k \rvert \lt \epsilon k \ge N \lvert y_k \rvert = \lvert \lim_{n \to \infty} x^n_k \rvert x^n_k \lt \epsilon","['functional-analysis', 'banach-spaces', 'cauchy-sequences']"
22,Proof of uniqueness of the bounded linear transformation extended in the Bounded Linear Transformation theorem,Proof of uniqueness of the bounded linear transformation extended in the Bounded Linear Transformation theorem,,"B.L.T Theorem (from Reed/Simon): Suppose $T$ is a bounded linear transformation from a normed linear space $\langle V_1, \|\cdot\|\rangle$ to a complete normed linear space $\langle V_2, \|\cdot\|\rangle$.  Then $T$ can be uniquely extended to a bounded linear transformation (with the same bound), $\widetilde{T}$, from the completion of $V_1$ to $\langle V_2, \|\cdot\|\rangle$. The proof for $\widetilde{T}$ being bounded was given and very straightforward, and proving that it was linear was pretty simple as well.  I have been having issues with proving that $\widetilde{T}$ is unique, however, despite it probably being easy.  I tried supposing towards a contradiction and using that $V_1$ is dense in its completion, $\tilde{V_1}$, the extending transformations must agree on $V_1$, the extending transformations must both have the same bound as $T$, and since this implies that the extending transformations must have different bounds to be different themselves, this proves that $\widetilde{T}$ is unique. I don't think that this reasoning is right since I think that a transformation can act differently on some subset of $\tilde{V_1}\setminus{V_1}$ without changing the bound, and my only other idea was to use that both of these spaces are $T_1$, so if a sequence converges, it must converge to a unique point, and since $T$ is bounded and therefore continuous, and any extensions must be bounded and therefore continuous, we'll have sequences being mapped to their limits, and since these limits are unique, we will only yield one extension $\widetilde{T}$ that works for all of $\tilde{V_1}$.  Again, I think that this reasoning is missing something. Any insights, whether it be a nudge in the right direction or full proofs, are very welcome!  Thanks in advance.","B.L.T Theorem (from Reed/Simon): Suppose $T$ is a bounded linear transformation from a normed linear space $\langle V_1, \|\cdot\|\rangle$ to a complete normed linear space $\langle V_2, \|\cdot\|\rangle$.  Then $T$ can be uniquely extended to a bounded linear transformation (with the same bound), $\widetilde{T}$, from the completion of $V_1$ to $\langle V_2, \|\cdot\|\rangle$. The proof for $\widetilde{T}$ being bounded was given and very straightforward, and proving that it was linear was pretty simple as well.  I have been having issues with proving that $\widetilde{T}$ is unique, however, despite it probably being easy.  I tried supposing towards a contradiction and using that $V_1$ is dense in its completion, $\tilde{V_1}$, the extending transformations must agree on $V_1$, the extending transformations must both have the same bound as $T$, and since this implies that the extending transformations must have different bounds to be different themselves, this proves that $\widetilde{T}$ is unique. I don't think that this reasoning is right since I think that a transformation can act differently on some subset of $\tilde{V_1}\setminus{V_1}$ without changing the bound, and my only other idea was to use that both of these spaces are $T_1$, so if a sequence converges, it must converge to a unique point, and since $T$ is bounded and therefore continuous, and any extensions must be bounded and therefore continuous, we'll have sequences being mapped to their limits, and since these limits are unique, we will only yield one extension $\widetilde{T}$ that works for all of $\tilde{V_1}$.  Again, I think that this reasoning is missing something. Any insights, whether it be a nudge in the right direction or full proofs, are very welcome!  Thanks in advance.",,"['functional-analysis', 'normed-spaces']"
23,Distance between point and linear Space,Distance between point and linear Space,,"Suppose $E$ is a normed vector space. Let $f$ be a continuous linear functional on $E$ and denote by $M$ the Kernel of $f$. Let $x\in E$. How to show that $$\operatorname{dist}(x,M)=\displaystyle\inf_{y\in M}\|y-x\|=\frac{|f(x)|}{\|f\|}\, ? $$","Suppose $E$ is a normed vector space. Let $f$ be a continuous linear functional on $E$ and denote by $M$ the Kernel of $f$. Let $x\in E$. How to show that $$\operatorname{dist}(x,M)=\displaystyle\inf_{y\in M}\|y-x\|=\frac{|f(x)|}{\|f\|}\, ? $$",,"['functional-analysis', 'normed-spaces']"
24,Sum of Closed Operators Closable?,Sum of Closed Operators Closable?,,"Let $A$ and $B$ be closed operators on a (separable complex) Hilbert space with dense domains $D(A)$ and $D(B)$ respecitvely.  Then, we may define the operator $A+B$ on $D(A)\cap D(B)$.  In general, we have no reason to believe that this operator will be closed, which begs the question, is it closable? I hope I'm not being an idiot again. . .  Any ideas?","Let $A$ and $B$ be closed operators on a (separable complex) Hilbert space with dense domains $D(A)$ and $D(B)$ respecitvely.  Then, we may define the operator $A+B$ on $D(A)\cap D(B)$.  In general, we have no reason to believe that this operator will be closed, which begs the question, is it closable? I hope I'm not being an idiot again. . .  Any ideas?",,"['functional-analysis', 'hilbert-spaces', 'operator-theory']"
25,Why are inner products in RKHS linear evaluation functionals?,Why are inner products in RKHS linear evaluation functionals?,,"I'd like to know why inner products in Reproducing kernel Hilbert spaces are (linear) evaluation functionals. I understand that inner products are linear functionals, and I know what an evaluation functional is, I just can't explain why an inner product (in a RKHS) is evaluation functional, and vise-versa.","I'd like to know why inner products in Reproducing kernel Hilbert spaces are (linear) evaluation functionals. I understand that inner products are linear functionals, and I know what an evaluation functional is, I just can't explain why an inner product (in a RKHS) is evaluation functional, and vise-versa.",,['functional-analysis']
26,How can I get eigenvalues of infinite dimensional linear operator?,How can I get eigenvalues of infinite dimensional linear operator?,,"What I want to prove is that for infinite dimensional vector space, $0$ is the only eigenvalue doesn't imply $T$ is nilpotent. But I am not sure how to find eigenvalues of infinite dimensional linear operator $T$. Since we normally find eigenvalues by find zeros of characteristic polynomials, we even cannot find the characteristic polynomial for this situation. I am specifically interested in the differential operator on the vector space of all formal power series.","What I want to prove is that for infinite dimensional vector space, $0$ is the only eigenvalue doesn't imply $T$ is nilpotent. But I am not sure how to find eigenvalues of infinite dimensional linear operator $T$. Since we normally find eigenvalues by find zeros of characteristic polynomials, we even cannot find the characteristic polynomial for this situation. I am specifically interested in the differential operator on the vector space of all formal power series.",,"['functional-analysis', 'operator-theory', 'linear-transformations', 'infinite-matrices']"
27,Why $C_0^\infty$ is dense in $L^p$?,Why  is dense in ?,C_0^\infty L^p,Why $C_0^\infty$ is dense in $L^p$? Would you give me a simple proof or the outline of the proof?,Why $C_0^\infty$ is dense in $L^p$? Would you give me a simple proof or the outline of the proof?,,"['functional-analysis', 'measure-theory']"
28,Why doesn't $c_0$ admit a complement in $l^\infty$?,Why doesn't  admit a complement in ?,c_0 l^\infty,"The projection theorem shows that every closed linear subspace $ M $ of hilbert space $H$ has  at least one complementry closed linear subspace namely $M^\perp$. But in some Banach spaces a closed subspace may fail to have complementry closed linear subspace; for instance, the closed subspace $c_0$ of banach space $l^\infty$ is not complemented in $l^\infty$. I wonder why $c_0$ have not a complemented linear subspace  in $l^\infty$.","The projection theorem shows that every closed linear subspace $ M $ of hilbert space $H$ has  at least one complementry closed linear subspace namely $M^\perp$. But in some Banach spaces a closed subspace may fail to have complementry closed linear subspace; for instance, the closed subspace $c_0$ of banach space $l^\infty$ is not complemented in $l^\infty$. I wonder why $c_0$ have not a complemented linear subspace  in $l^\infty$.",,"['functional-analysis', 'banach-spaces']"
29,projection theorem for Banach spaces,projection theorem for Banach spaces,,"In a remark to the projection theorem for Hilbert spaces I read this conjecture of a more general projection theorem: Let $X$ be a reflexive Banach space and $K\subset X$ nonempty, closed and convex. Then for every $x\in X$ there exists $y\in K$ such that $$\| x-y\|=d(x,K)=\inf_{z\in K} \|x-z\|$$ Now I tried showing this similarly to the projection theorem for Hilbert spaces, but this didn't get me far as the proof I used makes use of the parallelogram equation heavily, which does not hold in Banach spaces. So how can I show this?","In a remark to the projection theorem for Hilbert spaces I read this conjecture of a more general projection theorem: Let be a reflexive Banach space and nonempty, closed and convex. Then for every there exists such that Now I tried showing this similarly to the projection theorem for Hilbert spaces, but this didn't get me far as the proof I used makes use of the parallelogram equation heavily, which does not hold in Banach spaces. So how can I show this?","X K\subset X x\in X y\in K \| x-y\|=d(x,K)=\inf_{z\in K} \|x-z\|",['functional-analysis']
30,Topology of test functions $\mathcal{D}(\mathbb R)$,Topology of test functions,\mathcal{D}(\mathbb R),"(My motivation for the following question is to understand the distribution theory) The space of test functions : $\mathcal{D}(\mathbb R)= \{\phi:\mathbb R \to \mathbb R : \phi \in C^{\infty}(\mathbb R), \ \text{and support of }\  \phi \ \text{is compact} \}.$ Let us introduce the norms, $$\|\phi\|_{N}=\text{max} \{|D^{\alpha}\phi(x)|: x\in \mathbb R, |\alpha| \leq N \}$$ for $\phi \in \mathcal{D}(\mathbb R)$ and $N=0,1,2,...$. My Question : (1) How to use these norms to define locally convex metrizable topology on $\mathcal{D}(\mathbb R)$ ? (2) This topology is not complete; but I don't understand the reason; Pick $\phi \in \mathcal{D}(\mathbb R)$ with support in $[0,1], \phi>0$ in $(0,1),$ and    define,    $$\psi_{m}(x)=\phi(x-1)+\frac{1}{2}\phi(x-2) +...+\frac{1}{m}\phi(x-m);$$   so, my sub-question is:   (a) How to verify $\{\psi_{m}\}$ is a Cauchy sequence in $\mathcal{D}(\mathbb R)$ ? (b) How to verify $\lim \psi_{m}$ does not have a compact support ? I want to add one more question to it i.e. If $\Omega\subset_{open} \mathbb R^n$ and the norms are defined by $$\|\phi\|_{N}=\text{max} \{|D^{\alpha}\phi(x)|: x\in \mathbb \Omega, |\alpha| \leq N \}$$ for $\phi\in\text D(\Omega) \ \text{instead of}\ \text D(\mathbb R)$ then how to show that the metrizable topology on $\text D(\Omega)$ is not complete. Thanks.","(My motivation for the following question is to understand the distribution theory) The space of test functions : $\mathcal{D}(\mathbb R)= \{\phi:\mathbb R \to \mathbb R : \phi \in C^{\infty}(\mathbb R), \ \text{and support of }\  \phi \ \text{is compact} \}.$ Let us introduce the norms, $$\|\phi\|_{N}=\text{max} \{|D^{\alpha}\phi(x)|: x\in \mathbb R, |\alpha| \leq N \}$$ for $\phi \in \mathcal{D}(\mathbb R)$ and $N=0,1,2,...$. My Question : (1) How to use these norms to define locally convex metrizable topology on $\mathcal{D}(\mathbb R)$ ? (2) This topology is not complete; but I don't understand the reason; Pick $\phi \in \mathcal{D}(\mathbb R)$ with support in $[0,1], \phi>0$ in $(0,1),$ and    define,    $$\psi_{m}(x)=\phi(x-1)+\frac{1}{2}\phi(x-2) +...+\frac{1}{m}\phi(x-m);$$   so, my sub-question is:   (a) How to verify $\{\psi_{m}\}$ is a Cauchy sequence in $\mathcal{D}(\mathbb R)$ ? (b) How to verify $\lim \psi_{m}$ does not have a compact support ? I want to add one more question to it i.e. If $\Omega\subset_{open} \mathbb R^n$ and the norms are defined by $$\|\phi\|_{N}=\text{max} \{|D^{\alpha}\phi(x)|: x\in \mathbb \Omega, |\alpha| \leq N \}$$ for $\phi\in\text D(\Omega) \ \text{instead of}\ \text D(\mathbb R)$ then how to show that the metrizable topology on $\text D(\Omega)$ is not complete. Thanks.",,"['analysis', 'functional-analysis', 'proof-verification', 'distribution-theory']"
31,$a: E\times F\to G$ bilinear separately continuous implies continuous?,bilinear separately continuous implies continuous?,a: E\times F\to G,"Let $E$, $F$ and $G$ be Banach spaces and let $a$: $E \times F \to G$ be a bilinear map which is separately continuous, that is $$\forall x \in E \textrm{ the map } y \mapsto a(x,y) \textrm{ is continuous}$$ and $$\forall y \in F \textrm{ the map } x \mapsto a(x,y) \textrm{ is continuous}$$ Show that $a$ is bounded, i.e., there exists a constant $M\geq 0$ such that $$\|a(x,y)\|_G \leq M \|x\|_E \|y\|_F,\quad\forall(x,y)\in E \times F.$$","Let $E$, $F$ and $G$ be Banach spaces and let $a$: $E \times F \to G$ be a bilinear map which is separately continuous, that is $$\forall x \in E \textrm{ the map } y \mapsto a(x,y) \textrm{ is continuous}$$ and $$\forall y \in F \textrm{ the map } x \mapsto a(x,y) \textrm{ is continuous}$$ Show that $a$ is bounded, i.e., there exists a constant $M\geq 0$ such that $$\|a(x,y)\|_G \leq M \|x\|_E \|y\|_F,\quad\forall(x,y)\in E \times F.$$",,['functional-analysis']
32,"Let $X$ and $Y$ be Banach spaces, show that if they are isomorphic, then $X$ is reflexive iff $Y$ is reflexive.","Let  and  be Banach spaces, show that if they are isomorphic, then  is reflexive iff  is reflexive.",X Y X Y,"I want to show that if $X$ and $Y$ are two Banach spaces, and $T : X \to Y$ is an isomorphism, then $$   X \textrm{ reflexive} \iff Y \textrm{ reflexive}. $$ I saw several proofs, but I cannot comprehend them, some are working with the dual of $T$, but I am not sure what the dual of $T$ should be?","I want to show that if $X$ and $Y$ are two Banach spaces, and $T : X \to Y$ is an isomorphism, then $$   X \textrm{ reflexive} \iff Y \textrm{ reflexive}. $$ I saw several proofs, but I cannot comprehend them, some are working with the dual of $T$, but I am not sure what the dual of $T$ should be?",,"['analysis', 'functional-analysis', 'banach-spaces']"
33,Some examples in C* algebras and Banach * algebras,Some examples in C* algebras and Banach * algebras,,"I would like an example of the following things. A Banach * algebra that is not a C* algebra for which there exists a positive linear functional (it takes $x^*x$ to numbers $ \geq 0$) that is not norm continuous. (Apparently if a Banach * algebra so much as even has a bounded approximate identity, then all positive linear functionals are continuous.  Does anybody have a proof of this?) An example of a Banach algebra with an unbounded approximate identity A couple of examples of some C* algebras and nonC* algebra Banach * algebras that admit nice representations into $B(H)$ other than those given by the GNS construction. An example of a Hilbert space $H$ and a C* subalgebra $A$ of operators on $H$ for which there exists a vector $v \in H$ such that $\overline{Av}$ does not contain $v$.  See here where I proved that if $v$ belongs to the usual family from Zorn's Lemma that decomposes $H$ into cyclic pieces, then $v$ cannot be an example for 4.  But maybe other $v$s can serve as an example? Decomposition of representations Partial answers are also much appreciated, and I caution that I am not asserting that examples to all 4 of these things exist.  If not, I'd like to see a proof why not.  But most of them should probably exist because I got the impression that they do from for example a textbook making a point of saying ""bounded approximate identity"" vs. ""approximate identity.""","I would like an example of the following things. A Banach * algebra that is not a C* algebra for which there exists a positive linear functional (it takes $x^*x$ to numbers $ \geq 0$) that is not norm continuous. (Apparently if a Banach * algebra so much as even has a bounded approximate identity, then all positive linear functionals are continuous.  Does anybody have a proof of this?) An example of a Banach algebra with an unbounded approximate identity A couple of examples of some C* algebras and nonC* algebra Banach * algebras that admit nice representations into $B(H)$ other than those given by the GNS construction. An example of a Hilbert space $H$ and a C* subalgebra $A$ of operators on $H$ for which there exists a vector $v \in H$ such that $\overline{Av}$ does not contain $v$.  See here where I proved that if $v$ belongs to the usual family from Zorn's Lemma that decomposes $H$ into cyclic pieces, then $v$ cannot be an example for 4.  But maybe other $v$s can serve as an example? Decomposition of representations Partial answers are also much appreciated, and I caution that I am not asserting that examples to all 4 of these things exist.  If not, I'd like to see a proof why not.  But most of them should probably exist because I got the impression that they do from for example a textbook making a point of saying ""bounded approximate identity"" vs. ""approximate identity.""",,"['functional-analysis', 'examples-counterexamples', 'operator-algebras', 'banach-algebras', 'von-neumann-algebras']"
34,Linear isometry and operator norm $=1$,Linear isometry and operator norm,=1,"For some reason I used to think that if $T$ is a linear operator on normed spaces $V \to W$ then saying $T$ is an isometry is the same as saying $\|T\|_{op} = 1$. Well, I got stuck on a proof and subsequently looked up the definition and realised that the definition of isometry is that a linear operator $T$ is an isometry if $\|Tx\| = \|x\|$. Now I've been wondering whether we have that $\|T\|_{op} = 1$ implies $T$ is an isometry? The other direction holds: if $\|Tx\| = \|x\|$ for all $x$ then $\frac{\|Tx\|}{\|x\|} = 1$ for all $x \neq 0$ and hence $\sup_{\|x\|=1}\|Tx\| = \sup_{\|x\|=1} \frac{\|Tx\|}{\|x\|} = \|T\| = 1$. Thanks for your help.","For some reason I used to think that if $T$ is a linear operator on normed spaces $V \to W$ then saying $T$ is an isometry is the same as saying $\|T\|_{op} = 1$. Well, I got stuck on a proof and subsequently looked up the definition and realised that the definition of isometry is that a linear operator $T$ is an isometry if $\|Tx\| = \|x\|$. Now I've been wondering whether we have that $\|T\|_{op} = 1$ implies $T$ is an isometry? The other direction holds: if $\|Tx\| = \|x\|$ for all $x$ then $\frac{\|Tx\|}{\|x\|} = 1$ for all $x \neq 0$ and hence $\sup_{\|x\|=1}\|Tx\| = \sup_{\|x\|=1} \frac{\|Tx\|}{\|x\|} = \|T\| = 1$. Thanks for your help.",,"['functional-analysis', 'normed-spaces']"
35,"What does the term ""geometry"" means in a Banach space？","What does the term ""geometry"" means in a Banach space？",,"I heard someone saying that it's popular to study geometry on Banach space in the past several years. He showed me some important results. However, I am still not clear about what it means by geometry in functional analysis. Is convexity a geometrical property?  In what occasion can I say that a theorem is about a geometric property?","I heard someone saying that it's popular to study geometry on Banach space in the past several years. He showed me some important results. However, I am still not clear about what it means by geometry in functional analysis. Is convexity a geometrical property?  In what occasion can I say that a theorem is about a geometric property?",,"['geometry', 'functional-analysis', 'banach-spaces']"
36,Does there exist a Banach space with no complemented closed subspaces?,Does there exist a Banach space with no complemented closed subspaces?,,"I know that every Hilbert space can be decomposed as the direct sum of two non-trivial closed subspaces, eg. taking the kernel and range of any non-trivial bounded projection. But I don't know what happens in Banach spaces. Does there exist a Banach space $B$ with no complemented closed subspaces? In other words, such that there do not exist closed subspaces $U,V\subset B$ with $B=U\oplus V$?","I know that every Hilbert space can be decomposed as the direct sum of two non-trivial closed subspaces, eg. taking the kernel and range of any non-trivial bounded projection. But I don't know what happens in Banach spaces. Does there exist a Banach space $B$ with no complemented closed subspaces? In other words, such that there do not exist closed subspaces $U,V\subset B$ with $B=U\oplus V$?",,"['functional-analysis', 'banach-spaces']"
37,"General ""Hodge theorem""","General ""Hodge theorem""",,"I know basically zero Hodge theory, so this question might be weird. Let $$A \stackrel{S}{\longrightarrow} B \stackrel{T}{\longrightarrow} C$$ be a sequence of closed, densely defined maps of Hilbert spaces, with $T \circ S = 0$.  Note that the conditions imply that the adjoints of both maps are also densely defined. Let $\Delta = SS^*+T^*T$ be the ""Laplacian"" of this complex. Call an element $b$ of $B$ ""harmonic"" if $\Delta b = 0$. Question 1 Is it true that every cohomology class $[b] = \{ b+ Sa : a \in \textrm{Dom}(S)\}$ has a harmonic representative? I suspect the answer is ""no"", since otherwise proofs of the Hodge theorem would be presented in this generality. Question 2 Can someone give me a natural example of where this fails? Question 3 At this level of generality, are there any additional hypotheses which would yield a Hodge theorem? Some motivation : I frequently use the lemma that, in this situation, all closed forms are exact precisely when $\langle \Delta b,b \rangle \geq C\lVert b \rVert ^2$ for some constant $C$. The proof of this is a slightly tricky application of Hahn-Banach. If the ""Hodge theorem"" was true, the lemma would be a corollary of it, since the inequality implies 0 is the only harmonic form, and thus that the cohomology must be trivial.","I know basically zero Hodge theory, so this question might be weird. Let $$A \stackrel{S}{\longrightarrow} B \stackrel{T}{\longrightarrow} C$$ be a sequence of closed, densely defined maps of Hilbert spaces, with $T \circ S = 0$.  Note that the conditions imply that the adjoints of both maps are also densely defined. Let $\Delta = SS^*+T^*T$ be the ""Laplacian"" of this complex. Call an element $b$ of $B$ ""harmonic"" if $\Delta b = 0$. Question 1 Is it true that every cohomology class $[b] = \{ b+ Sa : a \in \textrm{Dom}(S)\}$ has a harmonic representative? I suspect the answer is ""no"", since otherwise proofs of the Hodge theorem would be presented in this generality. Question 2 Can someone give me a natural example of where this fails? Question 3 At this level of generality, are there any additional hypotheses which would yield a Hodge theorem? Some motivation : I frequently use the lemma that, in this situation, all closed forms are exact precisely when $\langle \Delta b,b \rangle \geq C\lVert b \rVert ^2$ for some constant $C$. The proof of this is a slightly tricky application of Hahn-Banach. If the ""Hodge theorem"" was true, the lemma would be a corollary of it, since the inequality implies 0 is the only harmonic form, and thus that the cohomology must be trivial.",,"['functional-analysis', 'hodge-theory']"
38,Is $L^2(\Omega)$ dense in $H^{-1}(\Omega)$?,Is  dense in ?,L^2(\Omega) H^{-1}(\Omega),"Is it true that $L^2(\Omega)$, identified with its own dual, is dense in $H^{-1}(\Omega)$? $H^{-1}(\Omega)$ is the dual of $H^1_0(\Omega)$ and $H^1_0(\Omega)$ is the $H^1$-closure of smooth functions with compact support contained in $\Omega$. The $H^1$ inner product of a couple of functions is the sum of their $L^2$ inner product and the $L^2$ inner product of their derivatives of first order. Ps 1: I am reading Richard Falk's 1974 paper ( http://www.ams.org/journals/mcom/1974-28-128/S0025-5718-1974-0391502-8/S0025-5718-1974-0391502-8.pdf ) and there, in section 3, by using his Theorem 1, he seems to use the ""fact"" that $L^2(\Omega)$ is dense in $H^{-1}(\Omega)$. I am having trouble verifying that. Can I get some help, please? Thanks,","Is it true that $L^2(\Omega)$, identified with its own dual, is dense in $H^{-1}(\Omega)$? $H^{-1}(\Omega)$ is the dual of $H^1_0(\Omega)$ and $H^1_0(\Omega)$ is the $H^1$-closure of smooth functions with compact support contained in $\Omega$. The $H^1$ inner product of a couple of functions is the sum of their $L^2$ inner product and the $L^2$ inner product of their derivatives of first order. Ps 1: I am reading Richard Falk's 1974 paper ( http://www.ams.org/journals/mcom/1974-28-128/S0025-5718-1974-0391502-8/S0025-5718-1974-0391502-8.pdf ) and there, in section 3, by using his Theorem 1, he seems to use the ""fact"" that $L^2(\Omega)$ is dense in $H^{-1}(\Omega)$. I am having trouble verifying that. Can I get some help, please? Thanks,",,"['functional-analysis', 'hilbert-spaces', 'sobolev-spaces']"
39,Trace of non-negative self-adjoint integral operator,Trace of non-negative self-adjoint integral operator,,"Suppose that $K:L^2([0,1],\mathbb C)\to L^2([0,1],\mathbb C)$ is a bounded linear integral operator given by   $$ Kf(x)=\int_0^1k(x,y)f(y)dy $$   for each $f\in L^2([0,1],\mathbb C)$ and $x\in[0,1]$. Let us further assume that $K$ is non-negative self-adjoint and trace class. Can we conclude that $\operatorname{Tr}K=\int_0^1k(x,x)dx$? The trace of a non-negative self-adjoint operator is given by (see here ) $$ \operatorname{Tr} K=\sum_i\langle Ke_i,e_i\rangle, $$ where $\{e_i\}$ is an orthonormal base of $L^2([0,1],\mathbb C)$. Hence, we have that $$ \operatorname{Tr} K=\sum_i\int_0^1\biggl[\int_0^1 k(x,y)e_i(y)dy\biggr]\overline{e_i(x)}dx=\sum_i\int_0^1\int_0^1 k(x,y)e_i(y)\overline{e_i(x)}dydx. $$ However, I am not sure if it is possible to proceed without further assumptions on the kernel $k$. If we assume that $k(x,y)=\varphi(x)\overline\varphi(y)$ for each $x,y\in[0,1]$, then we have that $$ \operatorname{Tr} K=\sum_i|\langle\varphi,e_i\rangle|^2=\|\varphi\|^2=\int_0^1|\varphi(x)|^2dx=\int_0^1k(x,x)dx. $$ Is there an example of a non-negative self-adjoint trace class operator such that $\operatorname{Tr}K\ne\int_0^1k(x,x)dx$ or is it possible to prove that the trace is always equal to the integral of the kernel over the diagonal? Any help is much appreciated!","Suppose that $K:L^2([0,1],\mathbb C)\to L^2([0,1],\mathbb C)$ is a bounded linear integral operator given by   $$ Kf(x)=\int_0^1k(x,y)f(y)dy $$   for each $f\in L^2([0,1],\mathbb C)$ and $x\in[0,1]$. Let us further assume that $K$ is non-negative self-adjoint and trace class. Can we conclude that $\operatorname{Tr}K=\int_0^1k(x,x)dx$? The trace of a non-negative self-adjoint operator is given by (see here ) $$ \operatorname{Tr} K=\sum_i\langle Ke_i,e_i\rangle, $$ where $\{e_i\}$ is an orthonormal base of $L^2([0,1],\mathbb C)$. Hence, we have that $$ \operatorname{Tr} K=\sum_i\int_0^1\biggl[\int_0^1 k(x,y)e_i(y)dy\biggr]\overline{e_i(x)}dx=\sum_i\int_0^1\int_0^1 k(x,y)e_i(y)\overline{e_i(x)}dydx. $$ However, I am not sure if it is possible to proceed without further assumptions on the kernel $k$. If we assume that $k(x,y)=\varphi(x)\overline\varphi(y)$ for each $x,y\in[0,1]$, then we have that $$ \operatorname{Tr} K=\sum_i|\langle\varphi,e_i\rangle|^2=\|\varphi\|^2=\int_0^1|\varphi(x)|^2dx=\int_0^1k(x,x)dx. $$ Is there an example of a non-negative self-adjoint trace class operator such that $\operatorname{Tr}K\ne\int_0^1k(x,x)dx$ or is it possible to prove that the trace is always equal to the integral of the kernel over the diagonal? Any help is much appreciated!",,"['functional-analysis', 'operator-theory', 'hilbert-spaces', 'trace']"
40,Prove that $T(x^* + W^{\perp}) = y^*$ is an isometric isomorphism from $V^*/W^\perp$ to $W^*$,Prove that  is an isometric isomorphism from  to,T(x^* + W^{\perp}) = y^* V^*/W^\perp W^*,"Let $(V, \| \cdot \|)$ be a normed vector space and $W$ be a linear subspace. Prove that $T: V^*/W^{\perp} \to W^*, \ T(x^* + W^{\perp}) = y^*$ where $y^*(x) = x^*(x)$ for all $x \in W$, is an isometric isomorphism. $\perp$ denotes the annihilator, and $*$ the dual. There was a hint included that said ""First show that $W^{\perp}$ is a closed linear subspace of $V^*$. Prove that $T$ is a well-defined linear operator. To show that $T$ is an isometric isomorphism apply the Hahn-Banach theorem."" I'm stuck at the last part. Let $y^* \in W^*$ then from Hahn-Banach we have that $\exists \ x^* \in V^*$ s.t $x^* = y^*$ on $W$, and $\|x^*\|_{V^*} = \|y^* \|_{W^*}$. But how can I arrive at $\|T(x^* + W^{\perp})\|_{W^*} = \|x^*+ W^{\perp}\|_{V^*/W^{\perp}}$?","Let $(V, \| \cdot \|)$ be a normed vector space and $W$ be a linear subspace. Prove that $T: V^*/W^{\perp} \to W^*, \ T(x^* + W^{\perp}) = y^*$ where $y^*(x) = x^*(x)$ for all $x \in W$, is an isometric isomorphism. $\perp$ denotes the annihilator, and $*$ the dual. There was a hint included that said ""First show that $W^{\perp}$ is a closed linear subspace of $V^*$. Prove that $T$ is a well-defined linear operator. To show that $T$ is an isometric isomorphism apply the Hahn-Banach theorem."" I'm stuck at the last part. Let $y^* \in W^*$ then from Hahn-Banach we have that $\exists \ x^* \in V^*$ s.t $x^* = y^*$ on $W$, and $\|x^*\|_{V^*} = \|y^* \|_{W^*}$. But how can I arrive at $\|T(x^* + W^{\perp})\|_{W^*} = \|x^*+ W^{\perp}\|_{V^*/W^{\perp}}$?",,"['functional-analysis', 'banach-spaces']"
41,Does Closed Graph Theorem imply Uniform Boundedness Principle for functionals?,Does Closed Graph Theorem imply Uniform Boundedness Principle for functionals?,,"For Functionals, Uniform Boundedness Principle can be rephrased as the following : Let ${X}$ be a Banach Space, $K$ be the field($\mathbb{R}$ or $\mathbb{C}$). Let $\mathcal{F}$ be the subset of $BL(X,K)$ such that for each $x \in X$, the set $\{F(x): F \in \mathcal{F}\}$ is bounded in $K$. Then $\{||F||:F \in \mathcal{F}\}$ is bounded i.e uniformly bounded on the unitball of $X$. The closed graph theorem states that: Let $X$ and $Y$ be Banach Spaces. Let $F: X \to Y$ be a closed Linear map. Then $F$ is continuous. Does Closed Graph Theorem imply Uniform Boundedness Principle? I don't know if it is possible or not. But to make it possible, all I need to do is find a map from $X$ to $K$ which is linear and closed. The first thing that comes to my mind is : $\sup\{F(x)|F \in \mathcal{F}\}$. But this is not a linear map. So it doesn't work. I can take a slightly detour from here and use Zabreiko's Theorem to prove (since $\sup\{F(x)|F \in \mathcal{F}\}$ is a seminorm, which is countably subadditive). But that deviates from what I want to prove here.","For Functionals, Uniform Boundedness Principle can be rephrased as the following : Let ${X}$ be a Banach Space, $K$ be the field($\mathbb{R}$ or $\mathbb{C}$). Let $\mathcal{F}$ be the subset of $BL(X,K)$ such that for each $x \in X$, the set $\{F(x): F \in \mathcal{F}\}$ is bounded in $K$. Then $\{||F||:F \in \mathcal{F}\}$ is bounded i.e uniformly bounded on the unitball of $X$. The closed graph theorem states that: Let $X$ and $Y$ be Banach Spaces. Let $F: X \to Y$ be a closed Linear map. Then $F$ is continuous. Does Closed Graph Theorem imply Uniform Boundedness Principle? I don't know if it is possible or not. But to make it possible, all I need to do is find a map from $X$ to $K$ which is linear and closed. The first thing that comes to my mind is : $\sup\{F(x)|F \in \mathcal{F}\}$. But this is not a linear map. So it doesn't work. I can take a slightly detour from here and use Zabreiko's Theorem to prove (since $\sup\{F(x)|F \in \mathcal{F}\}$ is a seminorm, which is countably subadditive). But that deviates from what I want to prove here.",,"['functional-analysis', 'closed-graph']"
42,A Banach space is reflexive if a closed subspace and its quotient space are both reflexive,A Banach space is reflexive if a closed subspace and its quotient space are both reflexive,,"Let $X$ be a Banach space. Let $Y$ be a closed subspace. Suppose that the normed spaces (in fact Banach spaces) $Y$ and $X/Y$ are both reflexive. I need to show that $X$ is reflexive. I cannot show this but I feel that I could use the fact that a Banach space is reflexive if and only if its closed unit ball is weakly compact. So in this case we know $B_Y$ and $B_{X/Y}$ are weakly compact. Let $\mathcal{U}$ be a weakly open cover for $B_X$. I feel that a finite subcover can be obtained by considering the sets of the form $a+Y\cap B_X\subset X$, which are certainly compact, as $a+Y\cap B_X\subset a+nB_Y\cap B_X$, which is w-closed in the weakly compact set $a+nB_Y$ for some sufficiently large $n$, and the corresponding $a+Y\in X/Y$. Could anybody suggest anything? Thanks.","Let $X$ be a Banach space. Let $Y$ be a closed subspace. Suppose that the normed spaces (in fact Banach spaces) $Y$ and $X/Y$ are both reflexive. I need to show that $X$ is reflexive. I cannot show this but I feel that I could use the fact that a Banach space is reflexive if and only if its closed unit ball is weakly compact. So in this case we know $B_Y$ and $B_{X/Y}$ are weakly compact. Let $\mathcal{U}$ be a weakly open cover for $B_X$. I feel that a finite subcover can be obtained by considering the sets of the form $a+Y\cap B_X\subset X$, which are certainly compact, as $a+Y\cap B_X\subset a+nB_Y\cap B_X$, which is w-closed in the weakly compact set $a+nB_Y$ for some sufficiently large $n$, and the corresponding $a+Y\in X/Y$. Could anybody suggest anything? Thanks.",,"['functional-analysis', 'banach-spaces']"
43,Counterexamples of Arzèla Ascoli theorem for non-obeyed criteria,Counterexamples of Arzèla Ascoli theorem for non-obeyed criteria,,"I had an exam on functional analysis some time ago, and one of the questions I couldn't make any sense out was the following: Let $\Omega\subset \mathbb{R}$ and $\{f_n\}$ a sequence of continuous functions from $\Omega$ to $\mathbb{R}$. If the following criteria are obeyed: $\exists M>0$ such that $||f_n||_{\infty}< M$ $\forall n\in\mathbb{N}$, $\Omega$ is compact, The sequence $\{f_n\}$ is uniform equicontinuous. then the theorem of Arzèla Ascoli states that the sequence $\{f_n\}$ has a subsequence which converges in the $||.||_{\infty}$norm to a continuous function. Show that the theorem is not true by stating counter examples in the cases: (1) and (2) are obeyed, but not (3), (1) and (3) are obeyed, but not (2), (2) and (3) are obeyed, but not (1). I spend a lot of time thinking about this, but I couldn't think of any counter examples. For a non-compact subset of $\mathbb{R}$ I tried $(0,1)$ (as it is not closed) and for a bounded sequence I was thinking of $f_n = x^n$ but these didn't work. Can anyone help me with some counter examples and maybe a good way of thinking of them?","I had an exam on functional analysis some time ago, and one of the questions I couldn't make any sense out was the following: Let $\Omega\subset \mathbb{R}$ and $\{f_n\}$ a sequence of continuous functions from $\Omega$ to $\mathbb{R}$. If the following criteria are obeyed: $\exists M>0$ such that $||f_n||_{\infty}< M$ $\forall n\in\mathbb{N}$, $\Omega$ is compact, The sequence $\{f_n\}$ is uniform equicontinuous. then the theorem of Arzèla Ascoli states that the sequence $\{f_n\}$ has a subsequence which converges in the $||.||_{\infty}$norm to a continuous function. Show that the theorem is not true by stating counter examples in the cases: (1) and (2) are obeyed, but not (3), (1) and (3) are obeyed, but not (2), (2) and (3) are obeyed, but not (1). I spend a lot of time thinking about this, but I couldn't think of any counter examples. For a non-compact subset of $\mathbb{R}$ I tried $(0,1)$ (as it is not closed) and for a bounded sequence I was thinking of $f_n = x^n$ but these didn't work. Can anyone help me with some counter examples and maybe a good way of thinking of them?",,"['functional-analysis', 'normed-spaces']"
44,Can we define a norm on $\Bbb{R^\omega}$ in a basis free way?,Can we define a norm on  in a basis free way?,\Bbb{R^\omega},"Let $\Bbb{R^\omega}=\{(x_n)_{n\in \mathbb{N}}: x_n \in \Bbb{R}\}$ . Then, $(\Bbb{R^\omega}, +, \cdot) $ is a linear space. I know , if $(x_n) $ are $p$ - summable, then we can define norm , $\ell_p$ -norm ( $1\le p<\infty $ ) on $\Bbb{R^\omega}$ . And if $(x_n) 's$ are bounded we can define supremum norm, $\ell_{\infty}$ on $\Bbb{R^\omega}$ . The best thing I can do for general $\Bbb{R^\omega}$ (no special assumption on sequences) is to define a metric on $\Bbb{R^\omega}$ by $$d(x, y) =\sum_{j\in\mathbb{N}}{(a_j)} \frac{|x_j -y_j|}{1+|x_j -y_j|}$$ where $(a_j) _{j\in\mathbb{N}}$ is any convergent series of positive reals. I can show that the metric isn't induced by a norm on $\Bbb{R^\omega}$ . But by checking a particular metric on $\Bbb{R^\omega}$ , doesn't gives us an opportunity to make sure that the linear space $\Bbb{R^\omega}$ is not a normed space. I also know that the existence of Hamel basis of a linear space implies the linear space is a normed space. Again to prove existence of Hamel basis we need Zorn's lemma, an equivalent version of AC. Question: Can we define a norm in a basis-free way on $\Bbb{R^\omega}$ to make it a normed space?","Let . Then, is a linear space. I know , if are - summable, then we can define norm , -norm ( ) on . And if are bounded we can define supremum norm, on . The best thing I can do for general (no special assumption on sequences) is to define a metric on by where is any convergent series of positive reals. I can show that the metric isn't induced by a norm on . But by checking a particular metric on , doesn't gives us an opportunity to make sure that the linear space is not a normed space. I also know that the existence of Hamel basis of a linear space implies the linear space is a normed space. Again to prove existence of Hamel basis we need Zorn's lemma, an equivalent version of AC. Question: Can we define a norm in a basis-free way on to make it a normed space?","\Bbb{R^\omega}=\{(x_n)_{n\in \mathbb{N}}: x_n \in \Bbb{R}\} (\Bbb{R^\omega}, +, \cdot)  (x_n)  p \ell_p 1\le p<\infty  \Bbb{R^\omega} (x_n) 's \ell_{\infty} \Bbb{R^\omega} \Bbb{R^\omega} \Bbb{R^\omega} d(x, y) =\sum_{j\in\mathbb{N}}{(a_j)} \frac{|x_j -y_j|}{1+|x_j -y_j|} (a_j) _{j\in\mathbb{N}} \Bbb{R^\omega} \Bbb{R^\omega} \Bbb{R^\omega} \Bbb{R^\omega}","['functional-analysis', 'metric-spaces', 'set-theory', 'normed-spaces', 'axiom-of-choice']"
45,"An inner product on $\mathcal{C}[a,b]$",An inner product on,"\mathcal{C}[a,b]","I've to prove that the functional $$\langle f,g\rangle = \int_{a}^{b} \int_{a}^{b} \frac{\sin(\pi(t-s))}{\pi (t-s)} f(s) \overline{g(t)}dsdt$$ is an inner product on $\mathcal{C}[a,b]$ (complex continuous functions). I've already made a similar exercise where I shown that $$\int_{a}^{b} f(t) \overline{g(t)} dt$$ is an inner product. And most of the properties follow the same reason. But I can't see how $$\langle f,f\rangle = \int_{a}^{b} \int_{a}^{b} \frac{\sin(\pi(t-s))}{\pi (t-s)} f(s) \overline{f(t)}dsdt = 0 \iff f \equiv 0.$$ The implication $f=0 \Longrightarrow \langle f,f\rangle=0$ is clear from of the definition of the functional, but since $\frac{\sin(\pi(t-s))}{\pi (t-s)} = 0$ for $\pi(t-s) = n\pi$ I can't get the other implication. Same with $\langle f,f\rangle \geq 0.$","I've to prove that the functional is an inner product on (complex continuous functions). I've already made a similar exercise where I shown that is an inner product. And most of the properties follow the same reason. But I can't see how The implication is clear from of the definition of the functional, but since for I can't get the other implication. Same with","\langle f,g\rangle = \int_{a}^{b} \int_{a}^{b} \frac{\sin(\pi(t-s))}{\pi (t-s)} f(s) \overline{g(t)}dsdt \mathcal{C}[a,b] \int_{a}^{b} f(t) \overline{g(t)} dt \langle f,f\rangle = \int_{a}^{b} \int_{a}^{b} \frac{\sin(\pi(t-s))}{\pi (t-s)} f(s) \overline{f(t)}dsdt = 0 \iff f \equiv 0. f=0 \Longrightarrow \langle f,f\rangle=0 \frac{\sin(\pi(t-s))}{\pi (t-s)} = 0 \pi(t-s) = n\pi \langle f,f\rangle \geq 0.","['functional-analysis', 'inner-products']"
46,Banach space with respect to two norms must be Banach wrt the sum of the norms?,Banach space with respect to two norms must be Banach wrt the sum of the norms?,,"Let $X $ be an infinite dimensional $R$-vector space, suppose that $||\cdot||_1$ and $||\cdot||_2$ are two norms that makes $X$ into a Banach space. Let $||\cdot||_3 = ||\cdot||_1  + ||\cdot||_2 $ ,this is another norm on $X$. Is $X$ complete wrt $||\cdot||_3 $? It is obvious that if $\{x_n\}_{n\in \mathbb{N}} \subset X$ is $||\cdot||_3 $-Cauchy sequence then it is also $||\cdot||_1 $-Cauchy and $||\cdot||_2 $-Cauchy. Therefore there exist $x_1^*, x_2^*\in X$ such that $x_n \overset{||\cdot||_1}{\to} x_1^*$ and $x_n \overset{||\cdot||_2}{\to} x_2^*$ but a priori $x_1^*$ can be different from $x_2^*$. Can we prove that $x_1^* = x_2^*$ in general? Otherwise can we find a counterexample? I only managed to show this  if $||\cdot||_1  < C ||\cdot||_2$, thanks to the fact that $X$ is T2 (or in another manner this condition implies that the two Banach norms are equivalent). Infact if $x_1^*\neq x_2^*$ then  for $n$ big enough,  $x_n $ must belong to a neighbourhood $U(x_1^*)$ of $x_1^*$ (neighbourhood in both the topologies) disjoint from another neighbourhood (in both topologies) of $x_2^*$.  Unfortunately I cannot generalize this proof since in the general case the two topologies are not comparable.","Let $X $ be an infinite dimensional $R$-vector space, suppose that $||\cdot||_1$ and $||\cdot||_2$ are two norms that makes $X$ into a Banach space. Let $||\cdot||_3 = ||\cdot||_1  + ||\cdot||_2 $ ,this is another norm on $X$. Is $X$ complete wrt $||\cdot||_3 $? It is obvious that if $\{x_n\}_{n\in \mathbb{N}} \subset X$ is $||\cdot||_3 $-Cauchy sequence then it is also $||\cdot||_1 $-Cauchy and $||\cdot||_2 $-Cauchy. Therefore there exist $x_1^*, x_2^*\in X$ such that $x_n \overset{||\cdot||_1}{\to} x_1^*$ and $x_n \overset{||\cdot||_2}{\to} x_2^*$ but a priori $x_1^*$ can be different from $x_2^*$. Can we prove that $x_1^* = x_2^*$ in general? Otherwise can we find a counterexample? I only managed to show this  if $||\cdot||_1  < C ||\cdot||_2$, thanks to the fact that $X$ is T2 (or in another manner this condition implies that the two Banach norms are equivalent). Infact if $x_1^*\neq x_2^*$ then  for $n$ big enough,  $x_n $ must belong to a neighbourhood $U(x_1^*)$ of $x_1^*$ (neighbourhood in both the topologies) disjoint from another neighbourhood (in both topologies) of $x_2^*$.  Unfortunately I cannot generalize this proof since in the general case the two topologies are not comparable.",,"['functional-analysis', 'banach-spaces', 'normed-spaces', 'cauchy-sequences']"
47,Surjective bounded operator in Banach spaces without bounded right-inverse,Surjective bounded operator in Banach spaces without bounded right-inverse,,Could someone give a simple example of surjective (not bijective) bounded operator in Banach spaces without bounded right-inverse?,Could someone give a simple example of surjective (not bijective) bounded operator in Banach spaces without bounded right-inverse?,,"['functional-analysis', 'banach-spaces', 'unbounded-operators']"
48,A technical relation,A technical relation,,"I have encountered the following interesting technical relation. $$ \pi^2 = \inf_{x \in \mathcal{D}(0,1) \setminus\{0\}} \frac{\int_0^1 |x'(s)|^2 \, \text{d}s}{\int_0^1 |x(s)|^2 \, \text{d}s}$$ where $\mathcal{D}(0,1)$ is the set of all smooth functions in $(0,1)$ with a compact support. Amazing. Can anyone please give a hint why this is true? Thank you.","I have encountered the following interesting technical relation. $$ \pi^2 = \inf_{x \in \mathcal{D}(0,1) \setminus\{0\}} \frac{\int_0^1 |x'(s)|^2 \, \text{d}s}{\int_0^1 |x(s)|^2 \, \text{d}s}$$ where $\mathcal{D}(0,1)$ is the set of all smooth functions in $(0,1)$ with a compact support. Amazing. Can anyone please give a hint why this is true? Thank you.",,"['functional-analysis', 'partial-differential-equations']"
49,"Every metric space can be isometrically embedded in a Banach space, so that it's a linearly independent set","Every metric space can be isometrically embedded in a Banach space, so that it's a linearly independent set",,"I'm trying to prove the following:  Every metric space can be isometrically embedded in a Banach space, so that it's a linearly independent set. I came up with the following idea: Let $ (X,d) $ be a metric space. We can take the vector space of all functions from $ X $ to $ \mathbb{R} $. Now we can send an element $ x \in X $ to the function which takes the value $ 1 $ on $ x $ and $ 0 $ everywhere else. This would embed $ X $ in $ \mathbb{R}^X $, so that it would be a linearly independent set and actually a basis. The problem seems to be finding a suitable norm, to make the embedding also an isometry. With that, we could just use the fact that every normed space can be isometrically embedded in a Banach space to get the desired result. Any hints on constructing the metric? Or have I chosen a bad space?","I'm trying to prove the following:  Every metric space can be isometrically embedded in a Banach space, so that it's a linearly independent set. I came up with the following idea: Let $ (X,d) $ be a metric space. We can take the vector space of all functions from $ X $ to $ \mathbb{R} $. Now we can send an element $ x \in X $ to the function which takes the value $ 1 $ on $ x $ and $ 0 $ everywhere else. This would embed $ X $ in $ \mathbb{R}^X $, so that it would be a linearly independent set and actually a basis. The problem seems to be finding a suitable norm, to make the embedding also an isometry. With that, we could just use the fact that every normed space can be isometrically embedded in a Banach space to get the desired result. Any hints on constructing the metric? Or have I chosen a bad space?",,"['functional-analysis', 'metric-spaces', 'banach-spaces']"
50,Geometric series of an operator,Geometric series of an operator,,"In solving a first order linear differential equation $(1-D)y=x^2$ where $D\equiv \frac{d}{dx}$ the way I learnt was that we proceed as $y=\frac{1}{1-D}x^2=(1-D)^{-1}x^2=(1+D+D^2+D^3+\cdots)x^2=x^2+2x+2+0+0+\cdots=x^2+2x+2.$ Now the question that comes to mind is that what justifies our saying that $$(1-D)^{-1}=1+D+D^2+D^3+\cdots$$ When I asked my teacher about this he said that it is not the case that the inverse operator of $1-D$ is $1+D+D^2+D^3+\cdots$ (whose meaning is unclear anyway). What is true instead is that $$(1-D)(1+D+D^2+\cdots+D^m)x^m=x^m$$ and that we are actually using this fact. Although I understand this, but I am not entirely satisfied for two reasons. Firstly the resemblance with the expression for the geometric series must be there for a reason which I want to know. Secondly can an appropriate norm be given to an appropriate function space in which we can actually prove this geometric series to be true? (The answer to the second question also covers the first). Thanks","In solving a first order linear differential equation $(1-D)y=x^2$ where $D\equiv \frac{d}{dx}$ the way I learnt was that we proceed as $y=\frac{1}{1-D}x^2=(1-D)^{-1}x^2=(1+D+D^2+D^3+\cdots)x^2=x^2+2x+2+0+0+\cdots=x^2+2x+2.$ Now the question that comes to mind is that what justifies our saying that $$(1-D)^{-1}=1+D+D^2+D^3+\cdots$$ When I asked my teacher about this he said that it is not the case that the inverse operator of $1-D$ is $1+D+D^2+D^3+\cdots$ (whose meaning is unclear anyway). What is true instead is that $$(1-D)(1+D+D^2+\cdots+D^m)x^m=x^m$$ and that we are actually using this fact. Although I understand this, but I am not entirely satisfied for two reasons. Firstly the resemblance with the expression for the geometric series must be there for a reason which I want to know. Secondly can an appropriate norm be given to an appropriate function space in which we can actually prove this geometric series to be true? (The answer to the second question also covers the first). Thanks",,['analysis']
51,"If $f \in L^{\infty}$ and $\exists r < \infty$ so that $\|f\|_r < \infty$, show $\lim_{p \rightarrow \infty} \|f\|_p = \|f\|_{\infty}$ [duplicate]","If  and  so that , show  [duplicate]",f \in L^{\infty} \exists r < \infty \|f\|_r < \infty \lim_{p \rightarrow \infty} \|f\|_p = \|f\|_{\infty},"This question already has answers here : Limit of $L^p$ norm (4 answers) Closed 10 years ago . Question: This is the last part of a 5 part question I am working on. Let $(X,\mu)$ be a possibly infinite measure space. Assume $\exists r < \infty$ with $\|f\|_r < \infty$ and that $\|f \|_{\infty} < \infty$. Show that $\lim_{p \rightarrow \infty} \|f_p\| = \|f\|_{\infty}$. This is from Real and Complex by Rudin, chapter 3 exercise 14. Progress: I have shown that $\|f\|_{\infty} \le \lim_{p \rightarrow \infty} \|f\|_p$ as follows, Fix $\epsilon > 0$. Let $E = \{x : |f(x)| > \|f\|_{\infty} - \epsilon \}$. Then observe $$ \|f\|_p \ge \left( \int_{E} |f|^p d\mu \right)^{1/p} > \left( \int_{E}(\| f \|_{\infty} - \epsilon)^{p} d\mu \right)^{1/p} = \left( \|f\|_{\infty} - \epsilon \right) \mu(E)^{1/p}, $$ thus, $\lim_{p \rightarrow \infty} \|f\|_p \ge \|f\|_{\infty} - \epsilon$ since $\mu(E) < \infty$. I attempted something similar for the other direction, but could not say the measure of a set was finite like (I think) I need for this argument to work. Here is what I tried: Since $\|f\|_r < \infty, \exists R$ so that $|x| > R \implies f(x) < \frac{1}{2}$. Let $A = \{ x : |x| \le R \}$ and $B = \{x : |x| > R \}$. Then, $$\|f\|_{p} \le \left( \int_{A} |f|^p d \mu + \int_{B} \frac{1}{2^p} d\mu\right)^{1/p} = \left( \int_{A} |f|^p d\mu + \frac{1}{2^p} \mu( B ) \right)^{1/p}.$$ If $\mu(B) < \infty$ this can easily show the desired result. Moreover, if I could show that there is a family of sets $\{B_p\}$ that act similarly so that $\mu(B_p)$ grows slower than $e^p$, then I can also complete the proof. Thoughts?","This question already has answers here : Limit of $L^p$ norm (4 answers) Closed 10 years ago . Question: This is the last part of a 5 part question I am working on. Let $(X,\mu)$ be a possibly infinite measure space. Assume $\exists r < \infty$ with $\|f\|_r < \infty$ and that $\|f \|_{\infty} < \infty$. Show that $\lim_{p \rightarrow \infty} \|f_p\| = \|f\|_{\infty}$. This is from Real and Complex by Rudin, chapter 3 exercise 14. Progress: I have shown that $\|f\|_{\infty} \le \lim_{p \rightarrow \infty} \|f\|_p$ as follows, Fix $\epsilon > 0$. Let $E = \{x : |f(x)| > \|f\|_{\infty} - \epsilon \}$. Then observe $$ \|f\|_p \ge \left( \int_{E} |f|^p d\mu \right)^{1/p} > \left( \int_{E}(\| f \|_{\infty} - \epsilon)^{p} d\mu \right)^{1/p} = \left( \|f\|_{\infty} - \epsilon \right) \mu(E)^{1/p}, $$ thus, $\lim_{p \rightarrow \infty} \|f\|_p \ge \|f\|_{\infty} - \epsilon$ since $\mu(E) < \infty$. I attempted something similar for the other direction, but could not say the measure of a set was finite like (I think) I need for this argument to work. Here is what I tried: Since $\|f\|_r < \infty, \exists R$ so that $|x| > R \implies f(x) < \frac{1}{2}$. Let $A = \{ x : |x| \le R \}$ and $B = \{x : |x| > R \}$. Then, $$\|f\|_{p} \le \left( \int_{A} |f|^p d \mu + \int_{B} \frac{1}{2^p} d\mu\right)^{1/p} = \left( \int_{A} |f|^p d\mu + \frac{1}{2^p} \mu( B ) \right)^{1/p}.$$ If $\mu(B) < \infty$ this can easily show the desired result. Moreover, if I could show that there is a family of sets $\{B_p\}$ that act similarly so that $\mu(B_p)$ grows slower than $e^p$, then I can also complete the proof. Thoughts?",,"['functional-analysis', 'measure-theory', 'lp-spaces']"
52,References on the Nash-Moser implicit function theorem,References on the Nash-Moser implicit function theorem,,"To learn, the Nash-Moser implicit function theorem, I tried the document Hamilton (1982) The Inverse Function Theorem of Nash and Moser , but the article is very encyclopedic. I have a background in functional analysis, but not in differential geometry so I often lost the main idea of the text. I will try with the original article of Nash and Moser . Are there any other treatments of the theorem? The theorem has been around for a long time, so maybe they are some lecture notes or book which expose it with less sophistication than Hamilton.","To learn, the Nash-Moser implicit function theorem, I tried the document Hamilton (1982) The Inverse Function Theorem of Nash and Moser , but the article is very encyclopedic. I have a background in functional analysis, but not in differential geometry so I often lost the main idea of the text. I will try with the original article of Nash and Moser . Are there any other treatments of the theorem? The theorem has been around for a long time, so maybe they are some lecture notes or book which expose it with less sophistication than Hamilton.",,"['analysis', 'functional-analysis']"
53,A commutator identity for bounded linear maps and the identity operator of a non-zero normed space is never a commutator,A commutator identity for bounded linear maps and the identity operator of a non-zero normed space is never a commutator,,"Let $ \mathcal{X} $ be a normed linear space and $ S,T: \mathcal{X} \to \mathcal{X} $ be linear operators such that $ S \circ T- T \circ S=1 $. Show that $ S \circ T^{n+1}- T^{n+1} \circ S=(n+1)T^n $ for $ n=0,1,2,... $ Deduce that if $ S$ is bounded then $ T$ is unbounded. For the first part I thought of applying the principle of mathematical induction.Is it alright to get the result like that or is there any other method to get that result?And for the second part, Since $ S \circ T- T \circ S=1 $ is the commutator operator,the result is obvious,but how can I give a proof of this?Please help!! Thanks!!","Let $ \mathcal{X} $ be a normed linear space and $ S,T: \mathcal{X} \to \mathcal{X} $ be linear operators such that $ S \circ T- T \circ S=1 $. Show that $ S \circ T^{n+1}- T^{n+1} \circ S=(n+1)T^n $ for $ n=0,1,2,... $ Deduce that if $ S$ is bounded then $ T$ is unbounded. For the first part I thought of applying the principle of mathematical induction.Is it alright to get the result like that or is there any other method to get that result?And for the second part, Since $ S \circ T- T \circ S=1 $ is the commutator operator,the result is obvious,but how can I give a proof of this?Please help!! Thanks!!",,"['functional-analysis', 'normed-spaces']"
54,"Functions of bounded variation as the dual of $C([a,b])$",Functions of bounded variation as the dual of,"C([a,b])","I am trying to understand this proposition about the dual of $C([a,b])$. I would like some help with the following: (1) What does the integral with respect to a function of bounded variation mean? (2) According to Riesz Representation Theorem, the dual of $C([a,b])$ is the space of regular Borel measures (Radon measures) on $[a,b]$. So what is the relation between these measures and the bounded variation functions? It would be nice to get some explanation in terms of distributions.","I am trying to understand this proposition about the dual of $C([a,b])$. I would like some help with the following: (1) What does the integral with respect to a function of bounded variation mean? (2) According to Riesz Representation Theorem, the dual of $C([a,b])$ is the space of regular Borel measures (Radon measures) on $[a,b]$. So what is the relation between these measures and the bounded variation functions? It would be nice to get some explanation in terms of distributions.",,"['functional-analysis', 'bounded-variation']"
55,"$C_c(X)$ is complete, then $X$ is compact","is complete, then  is compact",C_c(X) X,"Let $X$ be a locally compact Hausdorff space such that $C_c(X),$ the space of all continuous functions with compact support is complete. Show that $X$ is compact. My attempt: I have shown that $C_c(X)$ is dense in $C_0(X),$ the space of all continuous functions vanishing at infinity. Since $C_c(X)$ is complete, therefore $$C_c(X)=C_0(X).$$ Now to conclude that $X$ is compact, it suffices to find a function in $C_0(X)$ which vanishes nowhere on $X.$ Is this always possible?","Let $X$ be a locally compact Hausdorff space such that $C_c(X),$ the space of all continuous functions with compact support is complete. Show that $X$ is compact. My attempt: I have shown that $C_c(X)$ is dense in $C_0(X),$ the space of all continuous functions vanishing at infinity. Since $C_c(X)$ is complete, therefore $$C_c(X)=C_0(X).$$ Now to conclude that $X$ is compact, it suffices to find a function in $C_0(X)$ which vanishes nowhere on $X.$ Is this always possible?",,"['functional-analysis', 'banach-algebras']"
56,Norm of the Resolvent,Norm of the Resolvent,,"Let $\mathbb{H}$ be a Hilbert space, $A$ a self-adjoint operator with domain $D_{A}$ , $R_{A}$ the resolvent of $A$ , and $z$ a point in the resolvent set $\rho(A)$ . How could you prove the inequality \begin{equation} ||R_{A}(z)|| \leq 1/ d(z,\sigma(A)), \end{equation} where $\sigma(A)$ is the spectrum of $A$ , and $d(z,\sigma(A))$ the distance of $z$ from $\sigma(A)$ ? I found this inequality in Hislop & Sigal, Introduction to Spectral Theory , Sect 5.2, where they reference Reed and Simon, Methods of Modern Mathematical Physics, vol. I, but I could not find a proof in that book. Thank you very much in advance. PS I just note here that since for any closed operator \begin{equation} ||R_{A}(z)|| \geq 1/ d(z,\sigma(A)), \end{equation} (just note that all the point $w$ such that $|z-w| < ||R_{A}(z)||$ belong to $\rho(A)$ ), the above inequality must actually hold with equality.","Let be a Hilbert space, a self-adjoint operator with domain , the resolvent of , and a point in the resolvent set . How could you prove the inequality where is the spectrum of , and the distance of from ? I found this inequality in Hislop & Sigal, Introduction to Spectral Theory , Sect 5.2, where they reference Reed and Simon, Methods of Modern Mathematical Physics, vol. I, but I could not find a proof in that book. Thank you very much in advance. PS I just note here that since for any closed operator (just note that all the point such that belong to ), the above inequality must actually hold with equality.","\mathbb{H} A D_{A} R_{A} A z \rho(A) \begin{equation}
||R_{A}(z)|| \leq 1/ d(z,\sigma(A)),
\end{equation} \sigma(A) A d(z,\sigma(A)) z \sigma(A) \begin{equation}
||R_{A}(z)|| \geq 1/ d(z,\sigma(A)),
\end{equation} w |z-w| < ||R_{A}(z)|| \rho(A)","['functional-analysis', 'operator-theory']"
57,Weak and weak star topologies are locally convex,Weak and weak star topologies are locally convex,,Why weak and weak star topologies are locally convex?  I searched for a basis that the open sets at the origin consisting of convex set but I did'nt reach any result!,Why weak and weak star topologies are locally convex?  I searched for a basis that the open sets at the origin consisting of convex set but I did'nt reach any result!,,"['functional-analysis', 'topological-vector-spaces']"
58,"Given a ""composite"" norm, what polygon describes its unit ball?","Given a ""composite"" norm, what polygon describes its unit ball?",,"When answering this question about finding the open unit ball $\mathscr{B} := \{ x \in \mathbb{R}^2: \| x \| < 1\}$ of the ""composite"" norm $$ \| \cdot \|: \mathbb{R}^2 \to \mathbb{R}, \ (x,y) \mapsto a \| (x,y) \|_1 + \frac{b}{2} \| (x,y) \|_{\infty}. $$ I thought of the following question. In the above question one has $\Omega := \mathbb{R}^2$ , $a := \frac{1}{3}$ and $b := \frac{4}{3}$ but those aren't important for my question. All that matters is $a,b > 0$ , as verified in this question . It turns out that $\mathscr{B}$ is a octagon (as intersection of two rotated squares, as they are the geometric interpretations of $\| \cdot \|_1$ and $\| \cdot \|_{\infty}$ (is that really true?), which can be seen in the diagram appended to my answer to the first mentioned question). My question is if (and how) one can find out which shape (polygon?) $\mathscr{B}$ corresponds for a composite norm of the form $$ \| \cdot \| := \sum_{k = 1}^{\infty} \alpha_k \| \cdot \|_{x_k}, \qquad \text{where } \alpha_k \ge 0, x_k \in [1, \infty]. $$ As @CalvinKohr points out in the comments, we can normalize this representation: $\sum_{k} \alpha_k = 1$ such that the sum is well defined i.e. converges. This question seems to be related but I don't know how the Minkowski functional would relate to this problem even though it was briefly covered in my Functional Analysis course. It remarks that a polygon with a odd number of vertices can not occur because of the symmetry of the norm. As you can see in the last example below, other shapes than octagons are possible. Can $\mathscr{B}$ be another polygon with an even number of vertices? Maybe this is related to the concept of polyhedral norms ? One special case Cosider the norm $\mathfrak{p}_n(x,y) := \sum_{k = 1}^{n} \| (x,y) \|_{k}$ . If we graph it and intersect it with a plane $z = \ell$ for $\ell > 0$ we obtain the the shape of $\mathscr{B}$ . I graphed $\mathfrak{p}_n$ for $n \in \{1, \ldots, 5\}$ and one observes that shapes of $\mathscr{B}$ are 4-gons that ""get more convex"" and converge to some circle. This suggests it might by only interesting to at norms whose $\mathscr{B}$ is a polygon i.e. $\mathscr{B}$ s with straight lines. Are those just produced by $\| \cdot \|_1$ and $\| \cdot \|_{\infty}$ ?.","When answering this question about finding the open unit ball of the ""composite"" norm I thought of the following question. In the above question one has , and but those aren't important for my question. All that matters is , as verified in this question . It turns out that is a octagon (as intersection of two rotated squares, as they are the geometric interpretations of and (is that really true?), which can be seen in the diagram appended to my answer to the first mentioned question). My question is if (and how) one can find out which shape (polygon?) corresponds for a composite norm of the form As @CalvinKohr points out in the comments, we can normalize this representation: such that the sum is well defined i.e. converges. This question seems to be related but I don't know how the Minkowski functional would relate to this problem even though it was briefly covered in my Functional Analysis course. It remarks that a polygon with a odd number of vertices can not occur because of the symmetry of the norm. As you can see in the last example below, other shapes than octagons are possible. Can be another polygon with an even number of vertices? Maybe this is related to the concept of polyhedral norms ? One special case Cosider the norm . If we graph it and intersect it with a plane for we obtain the the shape of . I graphed for and one observes that shapes of are 4-gons that ""get more convex"" and converge to some circle. This suggests it might by only interesting to at norms whose is a polygon i.e. s with straight lines. Are those just produced by and ?.","\mathscr{B} := \{ x \in \mathbb{R}^2: \| x \| < 1\} 
\| \cdot \|:
\mathbb{R}^2 \to \mathbb{R}, \
(x,y) \mapsto a \| (x,y) \|_1 + \frac{b}{2} \| (x,y) \|_{\infty}.
 \Omega := \mathbb{R}^2 a := \frac{1}{3} b := \frac{4}{3} a,b > 0 \mathscr{B} \| \cdot \|_1 \| \cdot \|_{\infty} \mathscr{B} 
\| \cdot \|
:= \sum_{k = 1}^{\infty} \alpha_k \| \cdot \|_{x_k}, \qquad \text{where }
\alpha_k \ge 0, x_k \in [1, \infty].
 \sum_{k} \alpha_k = 1 \mathscr{B} \mathfrak{p}_n(x,y) := \sum_{k = 1}^{n} \| (x,y) \|_{k} z = \ell \ell > 0 \mathscr{B} \mathfrak{p}_n n \in \{1, \ldots, 5\} \mathscr{B} \mathscr{B} \mathscr{B} \| \cdot \|_1 \| \cdot \|_{\infty}","['functional-analysis', 'geometry', 'normed-spaces', 'polygons', 'geometric-functional-analysis']"
59,"If $f$ is proper, lsc, and $\frac{f(x) + f(y)}{2} = f^{**}\left(\frac{x + y}{2}\right) \implies x = y$, is $f$ necessarily convex?","If  is proper, lsc, and , is  necessarily convex?",f \frac{f(x) + f(y)}{2} = f^{**}\left(\frac{x + y}{2}\right) \implies x = y f,"Suppose $X$ is a real Hilbert Space and $f : X \to (-\infty, \infty]$ is a lower semicontinuous, proper function. Further, suppose $f$ satisfies the following, for all $x, y \in \operatorname{dom} f$:   $$\frac{f(x) + f(y)}{2} = f^{**}\left(\frac{x + y}{2}\right) \implies x = y.$$   Is $f$ necessarily a convex function? Here $^*$ refers to the Fenchel conjugate, and $\operatorname{dom} f$ is the set of points $x \in X$ such that $f(x) \neq \infty$. I know that: $f^{**}(x) \le f(x)$ for all $x$ and $f^{**}(x) = f(x)$ for all $x$ if and only if $f$ is convex (and lsc). In fact, $f^{**}$ is the greatest lsc convex minorant of $f$. This means that $$\frac{f(x) + f(y)}{2} \ge \frac{f^{**}(x) + f^{**}(y)}{2} \ge  f^{**}\left(\frac{x + y}{2}\right)$$ for all $x, y \in \operatorname{dom} f$. Therefore, $$\frac{f(x) + f(y)}{2} = f^{**}\left(\frac{x + y}{2}\right)$$ implies that $f(x) = f^{**}(x)$ and $f(y) = f^{**}(y)$. Another consequence is that $f^{**}(\lambda x + (1 - \lambda y)) = \lambda f^{**}(x) + (1 - \lambda)f^{**}(y)$ for all $\lambda \in [0, 1]$. My thoughts: Really, I just need to establish that $f^{**}(x) = f(x)$ for all $x$. Despite biduals showing up both in the premises and the above desired conclusion, there doesn't seem to be a direct path to manipulate one to the other, especially since not every point in $\overline{\operatorname{conv}} \operatorname{dom} f$ can be expressed as $\frac{x+y}{2}$ where $x, y \in \operatorname{dom} f$. The function $g(x, y) = \frac{f(x)+f(y)}{2} - f^{**}\left(\frac{x + y}{2}\right)$ is not a metric in general, even if $g(x, y) = 0 \implies x = y$. I get a feeling that Stegall's variational principle might help, for a variety of reasons, but one handy reason is that we may add any linear functional to $f$, without changing $g$. Any thoughts are welcome!","Suppose $X$ is a real Hilbert Space and $f : X \to (-\infty, \infty]$ is a lower semicontinuous, proper function. Further, suppose $f$ satisfies the following, for all $x, y \in \operatorname{dom} f$:   $$\frac{f(x) + f(y)}{2} = f^{**}\left(\frac{x + y}{2}\right) \implies x = y.$$   Is $f$ necessarily a convex function? Here $^*$ refers to the Fenchel conjugate, and $\operatorname{dom} f$ is the set of points $x \in X$ such that $f(x) \neq \infty$. I know that: $f^{**}(x) \le f(x)$ for all $x$ and $f^{**}(x) = f(x)$ for all $x$ if and only if $f$ is convex (and lsc). In fact, $f^{**}$ is the greatest lsc convex minorant of $f$. This means that $$\frac{f(x) + f(y)}{2} \ge \frac{f^{**}(x) + f^{**}(y)}{2} \ge  f^{**}\left(\frac{x + y}{2}\right)$$ for all $x, y \in \operatorname{dom} f$. Therefore, $$\frac{f(x) + f(y)}{2} = f^{**}\left(\frac{x + y}{2}\right)$$ implies that $f(x) = f^{**}(x)$ and $f(y) = f^{**}(y)$. Another consequence is that $f^{**}(\lambda x + (1 - \lambda y)) = \lambda f^{**}(x) + (1 - \lambda)f^{**}(y)$ for all $\lambda \in [0, 1]$. My thoughts: Really, I just need to establish that $f^{**}(x) = f(x)$ for all $x$. Despite biduals showing up both in the premises and the above desired conclusion, there doesn't seem to be a direct path to manipulate one to the other, especially since not every point in $\overline{\operatorname{conv}} \operatorname{dom} f$ can be expressed as $\frac{x+y}{2}$ where $x, y \in \operatorname{dom} f$. The function $g(x, y) = \frac{f(x)+f(y)}{2} - f^{**}\left(\frac{x + y}{2}\right)$ is not a metric in general, even if $g(x, y) = 0 \implies x = y$. I get a feeling that Stegall's variational principle might help, for a variety of reasons, but one handy reason is that we may add any linear functional to $f$, without changing $g$. Any thoughts are welcome!",,"['functional-analysis', 'convex-analysis', 'variational-analysis']"
60,About bounded below operators,About bounded below operators,,"In Murphy's book, ''bounded below'' is defined on a linear map $u\colon X\to Y$ between Banach spaces, not on a bounded linear operator.But continuity of $u$ is used when proving closedness of $u(X)$. Do I misunderstand the definition of ''bounded below''? Or does continuity of $u$ follow from ''bounded below''?","In Murphy's book, ''bounded below'' is defined on a linear map $u\colon X\to Y$ between Banach spaces, not on a bounded linear operator.But continuity of $u$ is used when proving closedness of $u(X)$. Do I misunderstand the definition of ''bounded below''? Or does continuity of $u$ follow from ''bounded below''?",,"['functional-analysis', 'operator-theory']"
61,Are sequences with Cesaro mean a closed subset of $\ell_\infty$?,Are sequences with Cesaro mean a closed subset of ?,\ell_\infty,"How can we show that the bounded sequences which are Cesaro summable , i.e., the sequences such that the limit $$\lim\limits_{n\to\infty} \frac{x_1+\dots+x_n}n$$ exists, form a closed subset of $\ell_\infty$? As usually, $\ell_\infty$ denotes the space of all bounded sequences with the sup-norm $\|x\|=\sup\limits_{n\in\mathbb N} |x_n|$. Closedness of this set was brought up in comments to an answer discussing a proof of existence of Banach limit based on Hahn–Banach theorem . I can think of this quick argument (I hope I did not miss something there): It's relatively easy to show that the function  \begin{align*} T &\colon \ell_\infty \to \ell_\infty\\ T &\colon (x_n) \mapsto \left(\frac{x_1+\dots+x_n}n\right) \end{align*} is continuous simply by noticing that $\|Tx\|\le\|x\|$. And since the set $c$ of all convergent sequences is closed in $\ell_\infty$, so is $T^{-1}(c)$; which is exactly the set of all sequences that have Cesaro mean. Are there some other proofs how to show the closedness of this set?","How can we show that the bounded sequences which are Cesaro summable , i.e., the sequences such that the limit $$\lim\limits_{n\to\infty} \frac{x_1+\dots+x_n}n$$ exists, form a closed subset of $\ell_\infty$? As usually, $\ell_\infty$ denotes the space of all bounded sequences with the sup-norm $\|x\|=\sup\limits_{n\in\mathbb N} |x_n|$. Closedness of this set was brought up in comments to an answer discussing a proof of existence of Banach limit based on Hahn–Banach theorem . I can think of this quick argument (I hope I did not miss something there): It's relatively easy to show that the function  \begin{align*} T &\colon \ell_\infty \to \ell_\infty\\ T &\colon (x_n) \mapsto \left(\frac{x_1+\dots+x_n}n\right) \end{align*} is continuous simply by noticing that $\|Tx\|\le\|x\|$. And since the set $c$ of all convergent sequences is closed in $\ell_\infty$, so is $T^{-1}(c)$; which is exactly the set of all sequences that have Cesaro mean. Are there some other proofs how to show the closedness of this set?",,"['functional-analysis', 'lp-spaces', 'cesaro-summable']"
62,Extension and trace operators for Sobolev spaces,Extension and trace operators for Sobolev spaces,,"Given that $\Omega \subset \mathbb{R}^{n}$ is an open, convex, Lipschitz bounded set. Let $O \subset \Omega$ be open bounded set then consider. $$u_{m} \rightharpoonup^{*} u \text{ in } W^{1,\infty}_{o}(O)$$ Assume that we can find $v_{m}$ such that $$v_{m} \rightharpoonup^{*} u \text{ in } W^{1,\infty}(O)$$$$ v_{m} = u \text{ on } \partial O$$ Assume that we apply the linear continuous operator $$P: W^{1,\infty}(O) \rightarrow W^{1,\infty}(\Omega)$$ We then extend $u$ from $O$ to $\Omega$ in such a way that the extension $\bar{u} \in W^{1,\infty}(\Omega)$ and similarly since $v_{m} = u$ on $\partial O$ we define ${\bar{v}}_{m} = v_{m}$ in $O$ and ${\bar{v}}_{m} = \bar{u}$ in $\Omega - O$. We then have $${\bar{v}}_{m} \rightharpoonup^{*} \bar{u} \text{ in } W^{1,\infty}_{o}(\Omega)$$ In Lawrence's book ""Partial Differential Equations"" the trace operator isn't defined for $p = \infty$. If the trace operator isn't defined how would you describe how '$v_{m} = u$ on $\partial O$' is defined? Can we immediately state that $v_{m} \in W^{1,\infty}_{o}(O)$ since $v_{m} = u$ on $\partial O$ and $u \in W^{1,\infty}_{o}(O)$? Do we get ${\bar{v}}_{m} \rightharpoonup^{*} \bar{u}$ in $W^{1,\infty}_{o}(\Omega)$ since we have that from the extension operator it follows that $P_{2}: W^{1,\infty}_{o}(O) \rightarrow W^{1,\infty}_{o}(\Omega)$ is also a continuous linear extension operator? If this is true, how would you go about showing this? Thanks for any assistance","Given that $\Omega \subset \mathbb{R}^{n}$ is an open, convex, Lipschitz bounded set. Let $O \subset \Omega$ be open bounded set then consider. $$u_{m} \rightharpoonup^{*} u \text{ in } W^{1,\infty}_{o}(O)$$ Assume that we can find $v_{m}$ such that $$v_{m} \rightharpoonup^{*} u \text{ in } W^{1,\infty}(O)$$$$ v_{m} = u \text{ on } \partial O$$ Assume that we apply the linear continuous operator $$P: W^{1,\infty}(O) \rightarrow W^{1,\infty}(\Omega)$$ We then extend $u$ from $O$ to $\Omega$ in such a way that the extension $\bar{u} \in W^{1,\infty}(\Omega)$ and similarly since $v_{m} = u$ on $\partial O$ we define ${\bar{v}}_{m} = v_{m}$ in $O$ and ${\bar{v}}_{m} = \bar{u}$ in $\Omega - O$. We then have $${\bar{v}}_{m} \rightharpoonup^{*} \bar{u} \text{ in } W^{1,\infty}_{o}(\Omega)$$ In Lawrence's book ""Partial Differential Equations"" the trace operator isn't defined for $p = \infty$. If the trace operator isn't defined how would you describe how '$v_{m} = u$ on $\partial O$' is defined? Can we immediately state that $v_{m} \in W^{1,\infty}_{o}(O)$ since $v_{m} = u$ on $\partial O$ and $u \in W^{1,\infty}_{o}(O)$? Do we get ${\bar{v}}_{m} \rightharpoonup^{*} \bar{u}$ in $W^{1,\infty}_{o}(\Omega)$ since we have that from the extension operator it follows that $P_{2}: W^{1,\infty}_{o}(O) \rightarrow W^{1,\infty}_{o}(\Omega)$ is also a continuous linear extension operator? If this is true, how would you go about showing this? Thanks for any assistance",,"['functional-analysis', 'operator-theory', 'sobolev-spaces', 'trace']"
63,On Pitt's theorem,On Pitt's theorem,,"The famous Pitt's theorem asserts that if $p>q$ then each bounded operator $T\colon \ell^p\to\ell^q$ is compact. Since $\ell^p$ and $\ell^q$ are incomparable ($p\neq q$, $p,q\geq 1$), each operator $T\colon \ell^p\to\ell^q$ is strictly singular anyway. Now I want to ask about $L^p(\mu)$ (put any assumptions on $\mu$ as you wish). Under what conditions on $p$ and $q$ each weakly compact operator $T\colon L^p(\mu)\to L^q(\mu)$ is compact?","The famous Pitt's theorem asserts that if $p>q$ then each bounded operator $T\colon \ell^p\to\ell^q$ is compact. Since $\ell^p$ and $\ell^q$ are incomparable ($p\neq q$, $p,q\geq 1$), each operator $T\colon \ell^p\to\ell^q$ is strictly singular anyway. Now I want to ask about $L^p(\mu)$ (put any assumptions on $\mu$ as you wish). Under what conditions on $p$ and $q$ each weakly compact operator $T\colon L^p(\mu)\to L^q(\mu)$ is compact?",,"['functional-analysis', 'banach-spaces', 'operator-theory']"
64,An eely function $\mu (n):\;\;\prod\limits_{k = 0}^{n - 1} {\left( {\mu (n) - \mu (k)} \right)} = 1$,An eely function,\mu (n):\;\;\prod\limits_{k = 0}^{n - 1} {\left( {\mu (n) - \mu (k)} \right)} = 1,"Time ago, dealing with a generalization of the Stirling numbers, I stumbled on the following implicit recurrence $$ \mu (n):\;\;\prod\limits_{k = 0}^{n - 1} {\left( {\mu (n) - \mu (k)} \right)}  = 1\quad \left| \matrix{   \,0 \le n \in Z \hfill \cr    \,0 \le \mu (n) \in R \hfill \cr    \,\mu (0) = 0 \hfill \cr}  \right. $$ Using a good CAS it is not difficult to compute the first few values and plot them Clearly, the sequence is monotonically increasing, and its finite difference is monotonically decreasing (1) . Such a regular behaviour leads me to expect that it might be extended over the reals and that $\mu (x)$ might be expressible through a combination of conventional functions. From time to time I am returning to this challenge with some inspiration for a new approach, but the combination difference & product has frustrated all my attempts. I couldn't even succeed to establish its asymptotic behaviour (now, thanks to @AMarino answer I know it's logarithmic) . So I am asking for hints, suggestions. -- addendum  -- Putting $\rho _{\,n,\,m}  = \mu _{\,n + 1}  - \mu _{\,m} $ , an alternative way to express the problem is $$ \left\{ \matrix{   \prod\limits_{0\,\, \le \,k\, \le \,n} {\rho _{\,n,\,k} }  = 1 \hfill \cr    \rho _{\,n,\,k}  - \rho _{\,n - 1,\,k}  = \mu _{\,n + 1}  - \mu _{\,n}  \hfill \cr}  \right. $$ which means to find a family of functions whose product wrt $k$ is $1$ and whose difference wrt $n$ is constant, as shown My last tentative has been to take two discrete pmf's on the support $[0,n]$ and put $$ \rho \left( {n,m} \right) = e^{\,h(n)\left( {p(m\,|n) - q(m\,|n)} \right)}  $$ which by definition gives the unitary product, but cannot go  yet through keeping the difference constant. -- note 1 -- That the difference is monotonically decreasing comes from being $$ \eqalign{   & \prod\limits_{k = 0}^{n - 1} {\left( {\mu (n) - \mu (k)} \right)}   = \prod\limits_{k = 0}^{n - 1} {\left( {\mu (n) - \mu (n - 1) + \mu (n - 1) - \mu (k)} \right)}  =   \cr    &  = \prod\limits_{k = 0}^{n - 1} {\left( {x + \left( {\mu (n - 1) - \mu (k)} \right)} \right)}   = p_n (x)\quad  \Rightarrow   \cr    &  \Rightarrow \quad \left\{ \matrix{   p_n (0) = 0 \hfill \cr    p_n (x) < p_{n + 1} (x)\quad \left| {\,0 < x} \right. \hfill \cr    1 = p_n (\mu (n) - \mu (n - 1)) < p_{n + 1} (\mu (n + 1) - \mu (n)) \hfill \cr}  \right.\quad  \Rightarrow   \cr    &  \Rightarrow \quad \mu (n + 1) - \mu (n) < \mu (n) - \mu (n - 1) \cr}  $$ which tells the interesting fact that $\Delta \mu (n-1)$ comes as the root of $p_n(x)=1$ , which in turn is added to its zeros, shifting them to the left as to start from $0$ and making them the zeros of $p_{n+1}(x)$ .","Time ago, dealing with a generalization of the Stirling numbers, I stumbled on the following implicit recurrence Using a good CAS it is not difficult to compute the first few values and plot them Clearly, the sequence is monotonically increasing, and its finite difference is monotonically decreasing (1) . Such a regular behaviour leads me to expect that it might be extended over the reals and that might be expressible through a combination of conventional functions. From time to time I am returning to this challenge with some inspiration for a new approach, but the combination difference & product has frustrated all my attempts. I couldn't even succeed to establish its asymptotic behaviour (now, thanks to @AMarino answer I know it's logarithmic) . So I am asking for hints, suggestions. -- addendum  -- Putting , an alternative way to express the problem is which means to find a family of functions whose product wrt is and whose difference wrt is constant, as shown My last tentative has been to take two discrete pmf's on the support and put which by definition gives the unitary product, but cannot go  yet through keeping the difference constant. -- note 1 -- That the difference is monotonically decreasing comes from being which tells the interesting fact that comes as the root of , which in turn is added to its zeros, shifting them to the left as to start from and making them the zeros of .","
\mu (n):\;\;\prod\limits_{k = 0}^{n - 1} {\left( {\mu (n) - \mu (k)} \right)}  = 1\quad \left| \matrix{
  \,0 \le n \in Z \hfill \cr 
  \,0 \le \mu (n) \in R \hfill \cr 
  \,\mu (0) = 0 \hfill \cr}  \right.
 \mu (x) \rho _{\,n,\,m}  = \mu _{\,n + 1}  - \mu _{\,m}  
\left\{ \matrix{
  \prod\limits_{0\,\, \le \,k\, \le \,n} {\rho _{\,n,\,k} }  = 1 \hfill \cr 
  \rho _{\,n,\,k}  - \rho _{\,n - 1,\,k}  = \mu _{\,n + 1}  - \mu _{\,n}  \hfill \cr}  \right.
 k 1 n [0,n] 
\rho \left( {n,m} \right) = e^{\,h(n)\left( {p(m\,|n) - q(m\,|n)} \right)} 
 
\eqalign{
  & \prod\limits_{k = 0}^{n - 1} {\left( {\mu (n) - \mu (k)} \right)}
  = \prod\limits_{k = 0}^{n - 1} {\left( {\mu (n) - \mu (n - 1) + \mu (n - 1) - \mu (k)} \right)}  =   \cr 
  &  = \prod\limits_{k = 0}^{n - 1} {\left( {x + \left( {\mu (n - 1) - \mu (k)} \right)} \right)}
  = p_n (x)\quad  \Rightarrow   \cr 
  &  \Rightarrow \quad \left\{ \matrix{
  p_n (0) = 0 \hfill \cr 
  p_n (x) < p_{n + 1} (x)\quad \left| {\,0 < x} \right. \hfill \cr 
  1 = p_n (\mu (n) - \mu (n - 1)) < p_{n + 1} (\mu (n + 1) - \mu (n)) \hfill \cr}  \right.\quad  \Rightarrow   \cr 
  &  \Rightarrow \quad \mu (n + 1) - \mu (n) < \mu (n) - \mu (n - 1) \cr} 
 \Delta \mu (n-1) p_n(x)=1 0 p_{n+1}(x)","['functional-analysis', 'functional-equations', 'recursion']"
65,Short and elegant introduction to Sobolev spaces,Short and elegant introduction to Sobolev spaces,,"I am preparing a course on Nonlinear Analysis, and I need to teach the most important facts about Sobolev spaces to my students. I know most books on this subject, from Brezis' to Adams', from Mazya's to Leoni's. But I wonder if there you know a very short introduction, a chapter or a little book that you would define delightful for a beginner. Of course I do not need advanced topics: just the basics, the embeddings and the most important inequalities.","I am preparing a course on Nonlinear Analysis, and I need to teach the most important facts about Sobolev spaces to my students. I know most books on this subject, from Brezis' to Adams', from Mazya's to Leoni's. But I wonder if there you know a very short introduction, a chapter or a little book that you would define delightful for a beginner. Of course I do not need advanced topics: just the basics, the embeddings and the most important inequalities.",,"['functional-analysis', 'reference-request', 'sobolev-spaces']"
66,Stone-Weierstrass implies Fourier expansion,Stone-Weierstrass implies Fourier expansion,,"To prove the existence of Fourier expansion, I have to solve the following exercise, which supposedly follows from the Stone-Weierstrass theorem: Let $G$ be a compact abelian topological group with Haar measure $m$. Let $\hat G$ be the dual. The members of $\hat G$ form an orthonormal basis for $L^2(m)$. Here I do not know about existence of Haar measure and I took it for granted. I was able to show that the members of $\hat G$ are orthonormal. How to show that these form a basis? Stone-Weierstrass(whose proof too I don't know), reads as: Let $X$ be a compact Hausdorff space and let $A$ be a closed subalgebra of the space of complex continuous functions $\mathcal C(X,\mathbb C)$ which separates points, contains a nonzero constant function and contains the conjugate of each of its functions. Then $A$ equals $\mathcal C(X,\mathbb C)$. Here it is easy to show everything except the fact that the subspace of $L^2(m)$ generated by the characters separate points. How to do this?","To prove the existence of Fourier expansion, I have to solve the following exercise, which supposedly follows from the Stone-Weierstrass theorem: Let $G$ be a compact abelian topological group with Haar measure $m$. Let $\hat G$ be the dual. The members of $\hat G$ form an orthonormal basis for $L^2(m)$. Here I do not know about existence of Haar measure and I took it for granted. I was able to show that the members of $\hat G$ are orthonormal. How to show that these form a basis? Stone-Weierstrass(whose proof too I don't know), reads as: Let $X$ be a compact Hausdorff space and let $A$ be a closed subalgebra of the space of complex continuous functions $\mathcal C(X,\mathbb C)$ which separates points, contains a nonzero constant function and contains the conjugate of each of its functions. Then $A$ equals $\mathcal C(X,\mathbb C)$. Here it is easy to show everything except the fact that the subspace of $L^2(m)$ generated by the characters separate points. How to do this?",,"['functional-analysis', 'harmonic-analysis', 'locally-compact-groups']"
67,"Quadratic P.S.D. differential operator that is invariant under $\textrm{SL}(2, \mathbb{R})$",Quadratic P.S.D. differential operator that is invariant under,"\textrm{SL}(2, \mathbb{R})","Given some function $f \in L^2(\mathbb{R}^2)$ , I'm interested in finding a positive semi-definite differential operator $\mathcal P: L^2(\mathbb{R}^2) \rightarrow L^2(\mathbb{R}^2)$ that is quadratic in $f$ and invariant under the the action of $\textrm{SL}{(2, \mathbb{R})},$ such that $\forall A \in \textrm{SL}(2, \mathbb{R})$ and $\forall {\bf x} \in \mathbb{R}^2,$ $$ {\mathcal P} f(A {\bf x}) = [{\mathcal P} f] (A {\bf x} ).$$ After thinking for some time, I've come up with two operators that are invariant and P.S.D, but not quadratic. For example, suppose we consider the operator $${\mathcal P} = \left( \frac{\partial^2}{\partial x^2} \frac{\partial^2}{\partial y^2} - \left[\frac{\partial^2}{\partial x y}\right] \right)^2,$$ which is the squared determinant of the Hessian. It's clear that it is P.S.D. and invariant under transformations in $\textrm{SL}(2, \mathbb{R})$ , though it is quartic in $f$ . Furthermore, letting $H$ denote the Hessian and $J \in \textrm{SO}(2)$ be a rotation by $90^\circ$ , the operator $$ {\mathcal P} = \left(\nabla^T  J^T H  \ J \ \nabla\right)^2,$$ is also invariant and P.S.D., but is not quadratic. I'm asking this question in the hope that someone might know of such a quadratic P.S.D. differential operator that is invariant under $\textrm{SL}(2, \mathbb{R})$ (if it even exists) or be able to point me toward a with a few other ideas I could try. Some possibly related question(s): Projective invariant differential operator Classification of diffeomorphisms by association of differentials with Lie groups Proof that $a\nabla u = b u$ is the only homogenous second order 2D PDE unchanged/invariant by rotation","Given some function , I'm interested in finding a positive semi-definite differential operator that is quadratic in and invariant under the the action of such that and After thinking for some time, I've come up with two operators that are invariant and P.S.D, but not quadratic. For example, suppose we consider the operator which is the squared determinant of the Hessian. It's clear that it is P.S.D. and invariant under transformations in , though it is quartic in . Furthermore, letting denote the Hessian and be a rotation by , the operator is also invariant and P.S.D., but is not quadratic. I'm asking this question in the hope that someone might know of such a quadratic P.S.D. differential operator that is invariant under (if it even exists) or be able to point me toward a with a few other ideas I could try. Some possibly related question(s): Projective invariant differential operator Classification of diffeomorphisms by association of differentials with Lie groups Proof that is the only homogenous second order 2D PDE unchanged/invariant by rotation","f \in L^2(\mathbb{R}^2) \mathcal P: L^2(\mathbb{R}^2) \rightarrow L^2(\mathbb{R}^2) f \textrm{SL}{(2, \mathbb{R})}, \forall A \in \textrm{SL}(2, \mathbb{R}) \forall {\bf x} \in \mathbb{R}^2,  {\mathcal P} f(A {\bf x}) = [{\mathcal P} f] (A {\bf x} ). {\mathcal P} = \left( \frac{\partial^2}{\partial x^2} \frac{\partial^2}{\partial y^2} - \left[\frac{\partial^2}{\partial x y}\right] \right)^2, \textrm{SL}(2, \mathbb{R}) f H J \in \textrm{SO}(2) 90^\circ  {\mathcal P} = \left(\nabla^T  J^T H  \ J \ \nabla\right)^2, \textrm{SL}(2, \mathbb{R}) a\nabla u = b u","['functional-analysis', 'differential-geometry', 'lie-groups', 'differential-operators', 'invariance']"
68,"""bounding"" an unbounded operator","""bounding"" an unbounded operator",,"I was wondering if, given a certain unbounded operator on a Hilbert space, it can (naively speaking) be ""cutted"" (or ""bounded"") by certain projections. So, thinking about this in a more sensible way, I have the following question: Let $T$ be a unbounded (densely defined) self-adjoint (positive) operator on $\mathcal{H}$ , and let $\{P_\lambda\}_{\lambda > 0}$ the spectral family of $T$ . Then we can look at the following: $\mathcal{H}_\lambda:= P_{(\lambda^{-1},\lambda)}\mathcal{H}$ , where $P_{(\lambda^{-1},\lambda)}$ correspond to the Borel functional calculus on $T$ of the characteristic function on the interval $(\lambda^{-1},\lambda)$ . Is it true that, on $\mathcal{H}_\lambda$ , $||Tx||\leq \lambda||x||$ ?","I was wondering if, given a certain unbounded operator on a Hilbert space, it can (naively speaking) be ""cutted"" (or ""bounded"") by certain projections. So, thinking about this in a more sensible way, I have the following question: Let be a unbounded (densely defined) self-adjoint (positive) operator on , and let the spectral family of . Then we can look at the following: , where correspond to the Borel functional calculus on of the characteristic function on the interval . Is it true that, on , ?","T \mathcal{H} \{P_\lambda\}_{\lambda > 0} T \mathcal{H}_\lambda:= P_{(\lambda^{-1},\lambda)}\mathcal{H} P_{(\lambda^{-1},\lambda)} T (\lambda^{-1},\lambda) \mathcal{H}_\lambda ||Tx||\leq \lambda||x||","['functional-analysis', 'operator-theory', 'spectral-theory', 'unbounded-operators']"
69,Proof Nehari manifold of semilineal subcritical $-\Delta u = f(u)$ in $\Omega$ is not empty.,Proof Nehari manifold of semilineal subcritical  in  is not empty.,-\Delta u = f(u) \Omega,"Given the problem $$ \left\{  \begin{array}{rll} -\Delta u& = f(u) & \text{in }\Omega \\  u & = 0 & \text{in } \partial\Omega \end{array} \right. $$ In a bounded domain $\Omega\subset \mathbb{R}^N, N\geq 3$ with $f$ satisfying: $f\in C^1(\mathbb{R}), f(0)=0$ and  $f'(0)<\lambda_1$, $\lambda_1$ the first eigenvalue of $-\Delta$ in $H_0^1(\Omega)$ There exists $c>0$ and $\sigma \in (1,2^{*}-1)$ such that $$|f'(s)|\leq c(|s|^{\sigma-1}+1) \quad \forall s\in \mathbb{R}$$ There is some $\alpha\in(0,1)$ such that $$f(s)s-2F(s)\geq \alpha f(s)s \quad \forall s$$ for $F(s)=\int_0^s f$. For all $s$ $$f'(s)>\frac{f(s)}{s} \quad \text{and} \quad \lim_{|s|\rightarrow \infty}\frac{f(s)}{s}=\infty$$ I am to show that the Nehari manifold associated with the functional $$J(u)=\frac{1}{2}\| u\|^2-\int_{\Omega} F(u)$$ is not empty. I already proved $u\in H_0^1$ is a solution to the PDE if and only if it is a critical point of $J$. I know from a previous exercise that $J$ is $C^2$ and $$J'(u)v=\langle u,v \rangle -\int f(u)v$$ and $$J''(u)(v,w)=\langle v,w\rangle-\int f'(u)vw$$ It is hinted that I must show that given $u\not\equiv 0$, the real valued function $J_u(t):(0,\infty)\mapsto \mathbb{R}, \, J_u(t)$$ =J(tu)$ satisfies $J^\prime_u (t)=0$ for exactly one $t$ and that this is a maximum. I used the Chain rule for generalized (Frechet) derivatives to obtain $$\frac{d J_u}{d t}(t)=\frac{d }{d t} J\circ h \,(t)=J'(h(t))\circ h'(t)=J'(tu)u.$$ Where I defined $h(t)=tu$. I must therefore prove $$t^2\|u\|^2-\int f(tu)tu=0$$ has precisely one solution for $t$. I know that the above equation is continuous in $t$ so I thought I'd show the above goes to $0^{+}$ as $t\rightarrow 0^{+}$, and to $-\infty$ as $t\rightarrow \infty$, but I can't quite work it out. Am I missing something? or am I just getting tunnel vision? Thank you in advance.","Given the problem $$ \left\{  \begin{array}{rll} -\Delta u& = f(u) & \text{in }\Omega \\  u & = 0 & \text{in } \partial\Omega \end{array} \right. $$ In a bounded domain $\Omega\subset \mathbb{R}^N, N\geq 3$ with $f$ satisfying: $f\in C^1(\mathbb{R}), f(0)=0$ and  $f'(0)<\lambda_1$, $\lambda_1$ the first eigenvalue of $-\Delta$ in $H_0^1(\Omega)$ There exists $c>0$ and $\sigma \in (1,2^{*}-1)$ such that $$|f'(s)|\leq c(|s|^{\sigma-1}+1) \quad \forall s\in \mathbb{R}$$ There is some $\alpha\in(0,1)$ such that $$f(s)s-2F(s)\geq \alpha f(s)s \quad \forall s$$ for $F(s)=\int_0^s f$. For all $s$ $$f'(s)>\frac{f(s)}{s} \quad \text{and} \quad \lim_{|s|\rightarrow \infty}\frac{f(s)}{s}=\infty$$ I am to show that the Nehari manifold associated with the functional $$J(u)=\frac{1}{2}\| u\|^2-\int_{\Omega} F(u)$$ is not empty. I already proved $u\in H_0^1$ is a solution to the PDE if and only if it is a critical point of $J$. I know from a previous exercise that $J$ is $C^2$ and $$J'(u)v=\langle u,v \rangle -\int f(u)v$$ and $$J''(u)(v,w)=\langle v,w\rangle-\int f'(u)vw$$ It is hinted that I must show that given $u\not\equiv 0$, the real valued function $J_u(t):(0,\infty)\mapsto \mathbb{R}, \, J_u(t)$$ =J(tu)$ satisfies $J^\prime_u (t)=0$ for exactly one $t$ and that this is a maximum. I used the Chain rule for generalized (Frechet) derivatives to obtain $$\frac{d J_u}{d t}(t)=\frac{d }{d t} J\circ h \,(t)=J'(h(t))\circ h'(t)=J'(tu)u.$$ Where I defined $h(t)=tu$. I must therefore prove $$t^2\|u\|^2-\int f(tu)tu=0$$ has precisely one solution for $t$. I know that the above equation is continuous in $t$ so I thought I'd show the above goes to $0^{+}$ as $t\rightarrow 0^{+}$, and to $-\infty$ as $t\rightarrow \infty$, but I can't quite work it out. Am I missing something? or am I just getting tunnel vision? Thank you in advance.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'calculus-of-variations']"
70,The constant in the Sobolev trace theorem inequality,The constant in the Sobolev trace theorem inequality,,"The trace theorem for nice enough domains states that there is a operator $T:H^1(\Omega) \to L^2(\partial \Omega)$ such that $$|Tu|_{L^2(\partial \Omega)} \leq C|u|_{H^1}.$$ My question, is there an expression for the constant $C$? I want to see exactly how it depends on the domain $\Omega.$ This is because I want to see how the constant varies (eg. continuously) if I vary the domain.","The trace theorem for nice enough domains states that there is a operator $T:H^1(\Omega) \to L^2(\partial \Omega)$ such that $$|Tu|_{L^2(\partial \Omega)} \leq C|u|_{H^1}.$$ My question, is there an expression for the constant $C$? I want to see exactly how it depends on the domain $\Omega.$ This is because I want to see how the constant varies (eg. continuously) if I vary the domain.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'trace']"
71,"Spectral Theorem for bounded compact, self-adjoint operators as corollary of Hilbert-Schmidt theorem","Spectral Theorem for bounded compact, self-adjoint operators as corollary of Hilbert-Schmidt theorem",,"I'm following Debnath and Mikusinksi's ""Introduction to Hilbert Spaces with Applications"" and am trying to understand how the spectral theorem for compact self-adjoint operators is a corollary of the Hilbert-Schmidt theorem. Here is the Hilbert-Schmidt theorem: Theorem (Hilbert-Schmidt) Let $T:H\to H$ be a bounded, compact, self-adjoint linear operator on a complex Hilbert space $H$. Then there exists an orthonormal set of eigenvectors $\left(w_{n}\right)$ corresponding to non-zero eigenvalues $\left(\lambda_{n}\right)$ s.t. for each $x\in H$ we can write unique  $$ x=\sum_{n=1}^{\infty}a_{n}w_{n}+v $$  for some $a_{n}\in\mathbb{C}$ and $v\in\mathscr{N}\left(T\right)$. ...and here is the spectral theorem that I wish to prove: Spectral Theorem Let $T$ be a bounded, compact, self-adjoint linear operator on a complex Hilbert space $H$. Then $H$ has an orthonormal basis $\left\{ v_{n}\right\} _{n\in\mathbb{N}}$ consisting of eigenvectors of $T$. Furthermore,  $$ Tx=\sum_{k=1}^{\infty}\lambda_{k}\left\langle x,v_{k}\right\rangle v_{k} $$  where $\lambda_{k}$ is the eigenvalue associated with eigenvector $v_{k}$. Could anyone help me to understand how this comes about from the Hilbert-Schmidt theorem? The explanation in the textbook is not helpful to me. The explanation is as follows: ""Debnath & Mikusinski's proof of the spectral theorem goes as follows: ""To obtain a complete orthonormal system $\left\{v_1 , v_2 , \ldots \right\}$, we need to complement the system $\left\{u_1, u_2, \ldots \right\}$, defined in the proof of the Hilbert-Schmidt theorem, with an arbitrary orthonormal basis of $\mathscr N (T)$. The eigenvalues corresponding to the vectors that form $\mathscr N (T)$ are all equal zero. The desired equality follows from the continuity of $A$."" I can post up the proof of the Hilbert-Schmidt theorem if it is helpful?","I'm following Debnath and Mikusinksi's ""Introduction to Hilbert Spaces with Applications"" and am trying to understand how the spectral theorem for compact self-adjoint operators is a corollary of the Hilbert-Schmidt theorem. Here is the Hilbert-Schmidt theorem: Theorem (Hilbert-Schmidt) Let $T:H\to H$ be a bounded, compact, self-adjoint linear operator on a complex Hilbert space $H$. Then there exists an orthonormal set of eigenvectors $\left(w_{n}\right)$ corresponding to non-zero eigenvalues $\left(\lambda_{n}\right)$ s.t. for each $x\in H$ we can write unique  $$ x=\sum_{n=1}^{\infty}a_{n}w_{n}+v $$  for some $a_{n}\in\mathbb{C}$ and $v\in\mathscr{N}\left(T\right)$. ...and here is the spectral theorem that I wish to prove: Spectral Theorem Let $T$ be a bounded, compact, self-adjoint linear operator on a complex Hilbert space $H$. Then $H$ has an orthonormal basis $\left\{ v_{n}\right\} _{n\in\mathbb{N}}$ consisting of eigenvectors of $T$. Furthermore,  $$ Tx=\sum_{k=1}^{\infty}\lambda_{k}\left\langle x,v_{k}\right\rangle v_{k} $$  where $\lambda_{k}$ is the eigenvalue associated with eigenvector $v_{k}$. Could anyone help me to understand how this comes about from the Hilbert-Schmidt theorem? The explanation in the textbook is not helpful to me. The explanation is as follows: ""Debnath & Mikusinski's proof of the spectral theorem goes as follows: ""To obtain a complete orthonormal system $\left\{v_1 , v_2 , \ldots \right\}$, we need to complement the system $\left\{u_1, u_2, \ldots \right\}$, defined in the proof of the Hilbert-Schmidt theorem, with an arbitrary orthonormal basis of $\mathscr N (T)$. The eigenvalues corresponding to the vectors that form $\mathscr N (T)$ are all equal zero. The desired equality follows from the continuity of $A$."" I can post up the proof of the Hilbert-Schmidt theorem if it is helpful?",,"['functional-analysis', 'hilbert-spaces', 'spectral-theory']"
72,Weak generator of Feller semigroup,Weak generator of Feller semigroup,,"Let $(T_t)_{t \geq 0}$ a Feller semigroup and define a linear operator $(A,\mathcal{D}(A))$ by $$\mathcal{D}(A) := \left\{u \in C_{\infty}(\mathbb{R}^d); \exists f \in C_{\infty} \forall x \in \mathbb{R}^d: f(x) = \lim_{t \to 0} \frac{T_t u(x)-u(x)}{t} \right\} \\ Au(x) := \lim_{t \to 0} \frac{T_t u(x)-u(x)}{t} \qquad (u \in \mathcal{D}(A))$$ ($A$ is called weak generator of the semigroup). Now I want to show that this generator is the generator in the sense of the weak topology on $C_{\infty}(\mathbb{R}^d)$, i.e. that the convergence is bounded pointwise convergence. Let $u \in \mathcal{D}(A)$. Since (by definition) the sequence is pointwise convergent, the only remaining thing is to show the boundedness, i.e. $$\sup_{t>0} \left\| \frac{T_t u-u}{t} \right\|_{\infty} < \infty$$ Well, since the sequence is pointwise convergent we have $$\sup_{t > 0} \left|\frac{T_t u(x)-u(x)}{t} \right| < \infty$$ for fixed $x \in \mathbb{R}^d$. A hint says that one should apply the Banach-Steinhaus theorem, but I don't see how to apply this theorem here, because there are not even linear operators (note that $u$ is fixed). Some hint...? Remark A Feller semigroup is a positivity preserving, conservative, strongly continuous semigroup satisfying the sub-markov property.","Let $(T_t)_{t \geq 0}$ a Feller semigroup and define a linear operator $(A,\mathcal{D}(A))$ by $$\mathcal{D}(A) := \left\{u \in C_{\infty}(\mathbb{R}^d); \exists f \in C_{\infty} \forall x \in \mathbb{R}^d: f(x) = \lim_{t \to 0} \frac{T_t u(x)-u(x)}{t} \right\} \\ Au(x) := \lim_{t \to 0} \frac{T_t u(x)-u(x)}{t} \qquad (u \in \mathcal{D}(A))$$ ($A$ is called weak generator of the semigroup). Now I want to show that this generator is the generator in the sense of the weak topology on $C_{\infty}(\mathbb{R}^d)$, i.e. that the convergence is bounded pointwise convergence. Let $u \in \mathcal{D}(A)$. Since (by definition) the sequence is pointwise convergent, the only remaining thing is to show the boundedness, i.e. $$\sup_{t>0} \left\| \frac{T_t u-u}{t} \right\|_{\infty} < \infty$$ Well, since the sequence is pointwise convergent we have $$\sup_{t > 0} \left|\frac{T_t u(x)-u(x)}{t} \right| < \infty$$ for fixed $x \in \mathbb{R}^d$. A hint says that one should apply the Banach-Steinhaus theorem, but I don't see how to apply this theorem here, because there are not even linear operators (note that $u$ is fixed). Some hint...? Remark A Feller semigroup is a positivity preserving, conservative, strongly continuous semigroup satisfying the sub-markov property.",,"['functional-analysis', 'semigroup-of-operators']"
73,"Sex, Crime and Functional Analysis?","Sex, Crime and Functional Analysis?",,"Ever since a friend told me about this book titled Sex, Crime and Functional Analysis: Part I. Functional Analysis , I have been looking for a copy of this book, but in vain. SO does this book actually exist or is it just a joke? If it does exist I am pretty sure someone on Math.SE has read it. GEdgar said the book might exist on the shelf of UCLA library but as pointed out by Nate, the library catalog does not contain such an entry. Anybody from UCLA here?","Ever since a friend told me about this book titled Sex, Crime and Functional Analysis: Part I. Functional Analysis , I have been looking for a copy of this book, but in vain. SO does this book actually exist or is it just a joke? If it does exist I am pretty sure someone on Math.SE has read it. GEdgar said the book might exist on the shelf of UCLA library but as pointed out by Nate, the library catalog does not contain such an entry. Anybody from UCLA here?",,"['functional-analysis', 'reference-request', 'soft-question']"
74,Can a norm on polynomials be supermultiplicative?,Can a norm on polynomials be supermultiplicative?,,"A norm on a real algebra is supermultiplicative when $\lVert f\cdot g\rVert\geq\lVert f\rVert\cdot\lVert g\rVert$ for all $f$ and $g$ in the algebra. Is there a supermultiplicative norm on $\mathbb R[x]$ ? This is a one-sided form of my previous question . An answer to either question could provide an answer to the other. I suspect that the norm given by $\Big\lVert\sum_ka_kx^k\Big\rVert=\max_k(k!|a_k|)$ , or equivalently by $\Big\lVert\sum_ka_kx^k/k!\Big\rVert=\max_k|a_k|$ , is a multiple of a supermultiplicative norm (so $\lVert f\cdot g\rVert\geq C\lVert f\rVert\lVert g\rVert$ for some constant $C>0$ ). Is this true?","A norm on a real algebra is supermultiplicative when for all and in the algebra. Is there a supermultiplicative norm on ? This is a one-sided form of my previous question . An answer to either question could provide an answer to the other. I suspect that the norm given by , or equivalently by , is a multiple of a supermultiplicative norm (so for some constant ). Is this true?",\lVert f\cdot g\rVert\geq\lVert f\rVert\cdot\lVert g\rVert f g \mathbb R[x] \Big\lVert\sum_ka_kx^k\Big\rVert=\max_k(k!|a_k|) \Big\lVert\sum_ka_kx^k/k!\Big\rVert=\max_k|a_k| \lVert f\cdot g\rVert\geq C\lVert f\rVert\lVert g\rVert C>0,"['functional-analysis', 'polynomials', 'normed-spaces', 'upper-lower-bounds']"
75,Infinite convolution of a smooth compactly supported function converges uniformly,Infinite convolution of a smooth compactly supported function converges uniformly,,"$\newcommand{\R}{\mathbb{R}}$$\newcommand{\diff}{\mathrm{d}}$ Let $\rho\in C^\infty_c(\mathbb R^d;\mathbb R)$ be an even function, i.e. $\rho(-x)=\rho(x)$ for all $x\in\mathbb R^d$ that furthermore satisfies $\operatorname{supp}\rho\subset B(0,1)$ and $$\int_{\mathbb R^d}\rho(x)\,\mathrm{d} x=1.$$ The function is not necessarily non-negative (which then implies $\int |\rho(x)|\, \diff x\geq 1$ ). We define $$\rho^{(n)}(x)=2^{2d}\rho(2^nx).$$ Basically $\rho^{(n)}$ is somehow an approximation to the identity. We also define $$\eta^{(n)}=\rho^{(0)}*\rho^{(1)}*\rho^{(2)}*\cdots * \rho^{(n)},$$ where $*$ is the convolution operator. Problem. Show that $\eta^{(n)}$ converges in $C(\mathbb R^d)$ uniformly. Attempt. The book (see Motivation section below) gives the hint to prove the limit exists in Fourier space. I imagine that they mean that I have to prove $\mathcal F\eta^{(n)}\to \hat\eta$ in the Schwartz space $\mathscr S(\mathbb R^d)$ and use continuity of the Fourier transform (-/inversion) from $\mathscr S(\mathbb R^d)$ to $\mathscr S(\mathbb R^d)$ .  So I did that and in particular I wanted to show that $\eta^{(n)}$ is Cauchy. So let $m\geq n$ and look at $$(\mathcal F(\eta^{(m)}-\eta^{(n)}))(\xi)=\prod_{i=0}^m (\mathcal F\rho^{(i)})(\xi)-\prod_{i=0}^n (\mathcal F\rho^{(i)})(\xi)=\prod_{i=0}^n (\mathcal F\rho^{(i)})(\xi)\left(\left[\prod_{i=n+1}^m (\mathcal F\rho^{(i)})(\xi)\right]-1 \right).$$ It is not difficult to see that $$(\mathcal F\rho^{(i)})(\xi)=(\mathcal F\rho)(2^{-i}\xi).$$ So in particular as $i\to\infty$ we easily see that $$\mathcal F\rho^{(i)}\to \mathcal F\rho(0)=\int\rho(x)\,dx= 1$$ in $\mathcal S'(\mathbb R^d)$ , i.e. convergence as in tempered distribution. After this I was wishing the product written above also would converge to $1$ , so I wrote $$(\mathcal F(\eta^{(m)}-\eta^{(n)}))(\xi)=\prod_{i=0}^n(\mathcal F\rho)(2^{-i}\xi)\left( \left[\prod_{i=n+1}^m(\mathcal F\rho)(2^{-i}\xi)\right]-1\right).$$ I felt that this is just as stiff, because I do not know the rate for which the convergence happens. I was guessing through Taylor approximation $$(\mathcal F\rho^{(i)})(\xi)-1=(\mathcal F\rho)(2^{-i}\xi)-1\approx \xi 2^{-i},$$ but then $\xi$ is a polynomial so it does not belong in $\mathscr S(\mathbb R^d)$ . After this I tried showing it directly, something like $$|\eta^{(n)}(x)-\eta^{(n+1)}(x)|\leq C 2^{-n}$$ uniformly, so that it is Cauchy in $C(\mathbb R^d)$ . One thing one easily sees is that $\rho^{(n)}$ has support inside $B(0,2^{-n})$ and therefore $\eta^{(n)}$ has support inside $$B(0,1)+B(0,2^{-1})+B(0,2^{-2})+\cdots + B(0,2^{-n})\subset B(0,3) $$ for all $n\in\mathbb N$ (by the support property of the convolution). In this case it is actually enough to show uniform convergence in say $C(\overline{B(0,3};\mathbb R)$ . I could not show that either. I appreciate any hint, or any methods to attack this problem. Motivation. I am reading the book ""A course on Rough Paths"" by Friz and Hairer and I am struggeling in proving the previous result (Exercise 13.7, second edition) which is needed for the proof of the so-called reconstruction theorem (Theorem 13.26). This question is somehow independent of the context, because it serves as a useful tool from basic analysis. Edit (Added attempt). Let us use the notation $$\rho^{(n,m)}=\rho^{(n)}*\rho^{(n+1)}*\cdots *\rho^{(m)}.$$ Basically $\eta^{(n)}=\rho^{(0,n)}$ . This notation is somehow easier for the things we will do soon. We want to show that $(\eta^{(n)})_{n\in\mathbb N}$ is Cauchy in $C_b(\R^d)$ . To that end we want to control $$\eta^{(n+1)}-\eta^{(n)}=\rho^{(0,n+1)}-\rho^{(0,n)}=\rho^{(0,n)}*(\rho^{(n+1)}-\delta_0)=\rho^{(1,n)}*(\rho^{(n+1)}-\delta_0)*\rho.$$ Let us focus on the term coming after $\rho^{(1,n)}$ , we have $$((\rho^{(n+1)}-\delta_0)*\rho)(x)=\int \rho^{(n+1)}(y)(\rho(x-y)-\rho(x))\,\diff y.$$ We have by the Mean value theorem $$|\rho(x-y)-\rho(x)|\leq \sup_{z\in \mathbb R^d} |D\rho(z)||y|$$ so that uniformly over $y\in\R^d$ $$|\rho(x-y)-\rho(x)|\leq C|y|.$$ Hence $$|((\rho^{(n+1)}-\delta_0)*\rho)(x)|\leq C\int_{\R^d} |\rho^{(n+1)}(y)||y|\,\diff y=C2^{-n-1}\int_{\R^d} 2^{(n+1)d}|\rho(2^{(n+1)}y)||2^{(n+1)}y|\,\diff y. $$ We change variables to get $$|((\rho^{(n+1)}-\delta)*\rho)(x)|\leq C2^{-n-1}\int_{\R^d} |\rho(y)||y|\,\diff y \leq \tilde C 2^{-n}.$$ Let us back to what we had $$(\eta^{(n+1)}-\eta^{(n)})(z)=\int_{\R^d}\rho^{(1,n)}(z-x) \int_{\R^d} \rho^{(n+1)}(y)(\rho(x-y)-\rho(x))\,\diff y\,\diff x.$$ Bounding all this $$|(\eta^{(n+1)}-\eta^{(n)})(z)|\leq \tilde C2^{-n} \int_{\R^d}|\rho^{(1,n)}(x)|\,\diff x.$$ Life would be much easier if we could bound the integral on the RHS. It is not difficult to see (through induction) that $$\int_{\R^d}|\rho^{(1,n)}(x)|\,\diff x=\int_{\R^d}|\rho^{(0,n-1)}(x)|\,\diff x=\int_{\R^d}|\eta^{(n)}(x)|\,\diff x.$$ So it is enough to show that $\eta^{(n)}$ is bounded in $L^1(\R^d)$ . I could not show that... According to the exercise it actually says that the integral is actually bounded. It is also enough to show that the Fourier transform $\mathcal F\eta^{(n)}$ is bounded in $L^1(\R^d)$ . So here is where I am stuck now. Note. that $\rho$ is not necessarily non-negative, otherwise it was easy. Edit 2. Since every little piece helps, let me add this. Define $$A_n:=\int_{\R^d}|\rho^{(0,n)}(x)|\,\diff x=\int_{\R^d}|\eta^{(n)}(x)|\,\diff x.$$ Recall we ended the previous edit with the observation that it is enough to show $\sup_n A_n<\infty$ . It is not difficult to find a recurrence relation for $A_n$ , namely $$A_{n+1}\leq \int_{\R^d}|\eta^{(n+1)}(x)-\eta^{(n)}(x)|\,\diff x+\int_{\R^d}|\eta^{(n)}(x)|\,\diff x\leq  C' 2^{-n} A_{n-1}+A_n,  $$ where $C'$ is some constant depending on $\tilde C$ above and the volume of $B(0,3)$ . This recurrence is promising except that it doesn't lead to anywhere if we bound $A_n\leq A_0A_{n-1}$ through Young's inequality because $A_0=\int |\rho(x)|\,\diff x\geq 1$ . Remark. On the other hand if $\rho(x)\geq 0$ then necessarily $A_0=1$ and the above argument works. This is why the case $\rho(x)\geq 0$ is easy.","Let be an even function, i.e. for all that furthermore satisfies and The function is not necessarily non-negative (which then implies ). We define Basically is somehow an approximation to the identity. We also define where is the convolution operator. Problem. Show that converges in uniformly. Attempt. The book (see Motivation section below) gives the hint to prove the limit exists in Fourier space. I imagine that they mean that I have to prove in the Schwartz space and use continuity of the Fourier transform (-/inversion) from to .  So I did that and in particular I wanted to show that is Cauchy. So let and look at It is not difficult to see that So in particular as we easily see that in , i.e. convergence as in tempered distribution. After this I was wishing the product written above also would converge to , so I wrote I felt that this is just as stiff, because I do not know the rate for which the convergence happens. I was guessing through Taylor approximation but then is a polynomial so it does not belong in . After this I tried showing it directly, something like uniformly, so that it is Cauchy in . One thing one easily sees is that has support inside and therefore has support inside for all (by the support property of the convolution). In this case it is actually enough to show uniform convergence in say . I could not show that either. I appreciate any hint, or any methods to attack this problem. Motivation. I am reading the book ""A course on Rough Paths"" by Friz and Hairer and I am struggeling in proving the previous result (Exercise 13.7, second edition) which is needed for the proof of the so-called reconstruction theorem (Theorem 13.26). This question is somehow independent of the context, because it serves as a useful tool from basic analysis. Edit (Added attempt). Let us use the notation Basically . This notation is somehow easier for the things we will do soon. We want to show that is Cauchy in . To that end we want to control Let us focus on the term coming after , we have We have by the Mean value theorem so that uniformly over Hence We change variables to get Let us back to what we had Bounding all this Life would be much easier if we could bound the integral on the RHS. It is not difficult to see (through induction) that So it is enough to show that is bounded in . I could not show that... According to the exercise it actually says that the integral is actually bounded. It is also enough to show that the Fourier transform is bounded in . So here is where I am stuck now. Note. that is not necessarily non-negative, otherwise it was easy. Edit 2. Since every little piece helps, let me add this. Define Recall we ended the previous edit with the observation that it is enough to show . It is not difficult to find a recurrence relation for , namely where is some constant depending on above and the volume of . This recurrence is promising except that it doesn't lead to anywhere if we bound through Young's inequality because . Remark. On the other hand if then necessarily and the above argument works. This is why the case is easy.","\newcommand{\R}{\mathbb{R}}\newcommand{\diff}{\mathrm{d}} \rho\in C^\infty_c(\mathbb R^d;\mathbb R) \rho(-x)=\rho(x) x\in\mathbb R^d \operatorname{supp}\rho\subset B(0,1) \int_{\mathbb R^d}\rho(x)\,\mathrm{d} x=1. \int |\rho(x)|\, \diff x\geq 1 \rho^{(n)}(x)=2^{2d}\rho(2^nx). \rho^{(n)} \eta^{(n)}=\rho^{(0)}*\rho^{(1)}*\rho^{(2)}*\cdots * \rho^{(n)}, * \eta^{(n)} C(\mathbb R^d) \mathcal F\eta^{(n)}\to \hat\eta \mathscr S(\mathbb R^d) \mathscr S(\mathbb R^d) \mathscr S(\mathbb R^d) \eta^{(n)} m\geq n (\mathcal F(\eta^{(m)}-\eta^{(n)}))(\xi)=\prod_{i=0}^m (\mathcal F\rho^{(i)})(\xi)-\prod_{i=0}^n (\mathcal F\rho^{(i)})(\xi)=\prod_{i=0}^n (\mathcal F\rho^{(i)})(\xi)\left(\left[\prod_{i=n+1}^m (\mathcal F\rho^{(i)})(\xi)\right]-1 \right). (\mathcal F\rho^{(i)})(\xi)=(\mathcal F\rho)(2^{-i}\xi). i\to\infty \mathcal F\rho^{(i)}\to \mathcal F\rho(0)=\int\rho(x)\,dx= 1 \mathcal S'(\mathbb R^d) 1 (\mathcal F(\eta^{(m)}-\eta^{(n)}))(\xi)=\prod_{i=0}^n(\mathcal F\rho)(2^{-i}\xi)\left( \left[\prod_{i=n+1}^m(\mathcal F\rho)(2^{-i}\xi)\right]-1\right). (\mathcal F\rho^{(i)})(\xi)-1=(\mathcal F\rho)(2^{-i}\xi)-1\approx \xi 2^{-i}, \xi \mathscr S(\mathbb R^d) |\eta^{(n)}(x)-\eta^{(n+1)}(x)|\leq C 2^{-n} C(\mathbb R^d) \rho^{(n)} B(0,2^{-n}) \eta^{(n)} B(0,1)+B(0,2^{-1})+B(0,2^{-2})+\cdots + B(0,2^{-n})\subset B(0,3)  n\in\mathbb N C(\overline{B(0,3};\mathbb R) \rho^{(n,m)}=\rho^{(n)}*\rho^{(n+1)}*\cdots *\rho^{(m)}. \eta^{(n)}=\rho^{(0,n)} (\eta^{(n)})_{n\in\mathbb N} C_b(\R^d) \eta^{(n+1)}-\eta^{(n)}=\rho^{(0,n+1)}-\rho^{(0,n)}=\rho^{(0,n)}*(\rho^{(n+1)}-\delta_0)=\rho^{(1,n)}*(\rho^{(n+1)}-\delta_0)*\rho. \rho^{(1,n)} ((\rho^{(n+1)}-\delta_0)*\rho)(x)=\int \rho^{(n+1)}(y)(\rho(x-y)-\rho(x))\,\diff y. |\rho(x-y)-\rho(x)|\leq \sup_{z\in \mathbb R^d} |D\rho(z)||y| y\in\R^d |\rho(x-y)-\rho(x)|\leq C|y|. |((\rho^{(n+1)}-\delta_0)*\rho)(x)|\leq C\int_{\R^d} |\rho^{(n+1)}(y)||y|\,\diff y=C2^{-n-1}\int_{\R^d} 2^{(n+1)d}|\rho(2^{(n+1)}y)||2^{(n+1)}y|\,\diff y.  |((\rho^{(n+1)}-\delta)*\rho)(x)|\leq C2^{-n-1}\int_{\R^d} |\rho(y)||y|\,\diff y \leq \tilde C 2^{-n}. (\eta^{(n+1)}-\eta^{(n)})(z)=\int_{\R^d}\rho^{(1,n)}(z-x) \int_{\R^d} \rho^{(n+1)}(y)(\rho(x-y)-\rho(x))\,\diff y\,\diff x. |(\eta^{(n+1)}-\eta^{(n)})(z)|\leq \tilde C2^{-n} \int_{\R^d}|\rho^{(1,n)}(x)|\,\diff x. \int_{\R^d}|\rho^{(1,n)}(x)|\,\diff x=\int_{\R^d}|\rho^{(0,n-1)}(x)|\,\diff x=\int_{\R^d}|\eta^{(n)}(x)|\,\diff x. \eta^{(n)} L^1(\R^d) \mathcal F\eta^{(n)} L^1(\R^d) \rho A_n:=\int_{\R^d}|\rho^{(0,n)}(x)|\,\diff x=\int_{\R^d}|\eta^{(n)}(x)|\,\diff x. \sup_n A_n<\infty A_n A_{n+1}\leq \int_{\R^d}|\eta^{(n+1)}(x)-\eta^{(n)}(x)|\,\diff x+\int_{\R^d}|\eta^{(n)}(x)|\,\diff x\leq  C' 2^{-n} A_{n-1}+A_n,   C' \tilde C B(0,3) A_n\leq A_0A_{n-1} A_0=\int |\rho(x)|\,\diff x\geq 1 \rho(x)\geq 0 A_0=1 \rho(x)\geq 0","['functional-analysis', 'partial-differential-equations', 'fourier-analysis', 'approximation-theory', 'stochastic-pde']"
76,"Can $\nabla$ be called a ""vector"" in any meaningful way?","Can  be called a ""vector"" in any meaningful way?",\nabla,"I used to think that $\nabla$ (or $\vec \nabla$) was just some fancy notation to represent some differential operators ($\nabla f \equiv \text{grad} \ f$, $\nabla \cdot \vec v \equiv \text{div} \ \vec v$, $\nabla \times \vec v \equiv \text{curl} \ \vec v$), which is particularly convenient because it happens to behave like a vector in algebraic manipulations. However, I've read in some posts on this site (like this answer or this answer ) that seem to suggest that there could in fact be a way to consider $\nabla$ as a vector in a formally meaningful way. For example, quoting from this answer : There are at least two layers of ideas here. First, as you say, the ""dual space"" $V^*$ to a real vector space is (by definition) the   collection of linear maps/functionals $V\rightarrow \mathbb R$, with   or without picking a basis. Nowadays, $V^*$ would more often be called   simply the ""dual space"", rather than ""covectors"". Next, the notion of ""tangent space"" to a smooth manifold, such as   $\mathbb R^n$ itself, at a point, is (intuitively) the vector space of   directional derivative operators (of smooth functions) at that point.   So, on $\mathbb R^n$, at $0$ (or at any point, actually),   $\{\partial/\partial x_1, \ldots, \partial/\partial x_n\}$ forms a   basis for that vector space of directional-derivative operators. It thus seems to me that there could be a meaningful, rigorous way to interpret $\nabla$ as an element of some vector space, maybe the dual space of an appropriate vector space of functions. Is this line of reasoning correct? PS I am a physicist, not a mathematician, and I only have a very basic background on functional analysis and differential geometry.","I used to think that $\nabla$ (or $\vec \nabla$) was just some fancy notation to represent some differential operators ($\nabla f \equiv \text{grad} \ f$, $\nabla \cdot \vec v \equiv \text{div} \ \vec v$, $\nabla \times \vec v \equiv \text{curl} \ \vec v$), which is particularly convenient because it happens to behave like a vector in algebraic manipulations. However, I've read in some posts on this site (like this answer or this answer ) that seem to suggest that there could in fact be a way to consider $\nabla$ as a vector in a formally meaningful way. For example, quoting from this answer : There are at least two layers of ideas here. First, as you say, the ""dual space"" $V^*$ to a real vector space is (by definition) the   collection of linear maps/functionals $V\rightarrow \mathbb R$, with   or without picking a basis. Nowadays, $V^*$ would more often be called   simply the ""dual space"", rather than ""covectors"". Next, the notion of ""tangent space"" to a smooth manifold, such as   $\mathbb R^n$ itself, at a point, is (intuitively) the vector space of   directional derivative operators (of smooth functions) at that point.   So, on $\mathbb R^n$, at $0$ (or at any point, actually),   $\{\partial/\partial x_1, \ldots, \partial/\partial x_n\}$ forms a   basis for that vector space of directional-derivative operators. It thus seems to me that there could be a meaningful, rigorous way to interpret $\nabla$ as an element of some vector space, maybe the dual space of an appropriate vector space of functions. Is this line of reasoning correct? PS I am a physicist, not a mathematician, and I only have a very basic background on functional analysis and differential geometry.",,"['functional-analysis', 'differential-geometry', 'vector-spaces']"
77,How can I show that given a norm one linear functional on $c_0$ that there is a unique extension to a norm one functional on $\ell_\infty$?,How can I show that given a norm one linear functional on  that there is a unique extension to a norm one functional on ?,c_0 \ell_\infty,"We are given that our Banach space is $c_0 \subset \ell_\infty(\mathbb{N})$ and there is a functional $y^* \in c_0^*$ such that $||y^*|| = 1$. We are guaranteed that this extends, via Hahn-Banach to a functional $x^* \in \ell_\infty^*$. How can I prove this extension is always unique in this case?","We are given that our Banach space is $c_0 \subset \ell_\infty(\mathbb{N})$ and there is a functional $y^* \in c_0^*$ such that $||y^*|| = 1$. We are guaranteed that this extends, via Hahn-Banach to a functional $x^* \in \ell_\infty^*$. How can I prove this extension is always unique in this case?",,"['functional-analysis', 'operator-theory', 'operator-algebras']"
78,Perturbation property of Orthonormal basis for Hilbert space,Perturbation property of Orthonormal basis for Hilbert space,,"Suppose $\{e_i\}_{i\in I}$ is an orthonormal basis for some Hilbert space. $\{f_i\}_{i\in I}$ is an orthonormal family with the property $\sum^\infty_{i\in I} \|e_i-f_i\|^2<\infty$, show that $\{f_i\}_{i\in I}$ is also orthonormal basis. I can think of for a $x$ with $(x,f_i)=0$ for all $i$, prove $x=0$. However, I don't know how to continue to the next step.","Suppose $\{e_i\}_{i\in I}$ is an orthonormal basis for some Hilbert space. $\{f_i\}_{i\in I}$ is an orthonormal family with the property $\sum^\infty_{i\in I} \|e_i-f_i\|^2<\infty$, show that $\{f_i\}_{i\in I}$ is also orthonormal basis. I can think of for a $x$ with $(x,f_i)=0$ for all $i$, prove $x=0$. However, I don't know how to continue to the next step.",,"['functional-analysis', 'hilbert-spaces']"
79,Extending the domains of densely defined bounded integral transforms on $L^2(\Bbb R)$,Extending the domains of densely defined bounded integral transforms on,L^2(\Bbb R),"This is a question I've contemplated for quite some time since it's pretty closely related to Fourier theory (particularly choosing the ""right"" space to define the Fourier transform on). However I've never been able to come up with anything resembling an answer for this. Nor have I seen it be addressed anywhere. Let $X$ be dense in $L^2(\Bbb R)$ and $T:X\subseteq L^2(\Bbb R)\to L^2(\Bbb R)$ be the integral operator given by $$ Tf(x) = \int_{-\infty}^{\infty} k(y,x) f(x)\,dx$$ where the integral is the Lebesgue integral. Assume that $T$ is bounded. If $g\in L^2(\Bbb R)\setminus X$ but we have that $$ \int_{-\infty}^{\infty} |k(y,x)| |g(x)|\,dx < \infty$$ for each $y$ (i.e. $Tg$ is well-posed). Is it necessarily the case that $Tg$ is in $L^2(\Bbb R)$? Note here that $T$ is meant as an integral transform, not the extension of $T$ (since that would be true trivially). My first approach was to consider some limit of elements in $X$ which approach $g$ in $L^2$, but I couldn't really piece any more of an argument together since it wasn't obvious to me how to proceed. A partial attempt: Since $X$ is dense in $L^2(\Bbb R)$, there is a a sequence $(f_m)\subseteq X$ such that $f_m\to g$ in $L^2(\Bbb R)$. Since $L^p$ convergence implies pointwise almost everywhere convergence of a subsequence $(f_{m_k})$ to $g$. Moreover, $f_{m_k}\to g$ in $L^2(\Bbb R)$. Since $f_{m_k}(x) \to g(x)$ for almost every $x$, we have that $k(y,x) f_{m_k}(x) \to k(y,x)g(x)$ almost everywhere. Assuming that it can be shown that $$\int_{-\infty}^{\infty} k(y,x) f_{m_k}(x)\,dx\to \int_{-\infty}^{\infty} k(y,x)g(x)\,dx,\tag{1}$$ then since $(f_{m_k})$ is Cauchy and $T$ is bounded, $(Tf_{m_k})$ is Cauchy and thus converges to an element of $L^2(\Bbb R)$. This then says that $$\int_{-\infty}^{\infty} k(y,x) g(x)\,dx = \lim_k \int_{-\infty}^{\infty} k(y,x) f_{m_k}(x)\,dx = \lim_k Tf_{m_k}(y).$$ Since $\lim_k Tf_{m_k}\in L^2(\Bbb R)$, we'd have that $Tg\in L^2(\Bbb R)$ since they agree almost everywhere. This is predicated on $(1)$ being true. $(1)$ can be shown if dominated convergence can be applied, though it isn't clear that the $k(y,\cdot)f_{m_k}$ can be bounded uniformly by an integrable function for a fixed but arbitrary $y$. If $g$ could be approximated within by elements in $X$, then this would work, but that is a very strong condition and will not be the case in general.","This is a question I've contemplated for quite some time since it's pretty closely related to Fourier theory (particularly choosing the ""right"" space to define the Fourier transform on). However I've never been able to come up with anything resembling an answer for this. Nor have I seen it be addressed anywhere. Let $X$ be dense in $L^2(\Bbb R)$ and $T:X\subseteq L^2(\Bbb R)\to L^2(\Bbb R)$ be the integral operator given by $$ Tf(x) = \int_{-\infty}^{\infty} k(y,x) f(x)\,dx$$ where the integral is the Lebesgue integral. Assume that $T$ is bounded. If $g\in L^2(\Bbb R)\setminus X$ but we have that $$ \int_{-\infty}^{\infty} |k(y,x)| |g(x)|\,dx < \infty$$ for each $y$ (i.e. $Tg$ is well-posed). Is it necessarily the case that $Tg$ is in $L^2(\Bbb R)$? Note here that $T$ is meant as an integral transform, not the extension of $T$ (since that would be true trivially). My first approach was to consider some limit of elements in $X$ which approach $g$ in $L^2$, but I couldn't really piece any more of an argument together since it wasn't obvious to me how to proceed. A partial attempt: Since $X$ is dense in $L^2(\Bbb R)$, there is a a sequence $(f_m)\subseteq X$ such that $f_m\to g$ in $L^2(\Bbb R)$. Since $L^p$ convergence implies pointwise almost everywhere convergence of a subsequence $(f_{m_k})$ to $g$. Moreover, $f_{m_k}\to g$ in $L^2(\Bbb R)$. Since $f_{m_k}(x) \to g(x)$ for almost every $x$, we have that $k(y,x) f_{m_k}(x) \to k(y,x)g(x)$ almost everywhere. Assuming that it can be shown that $$\int_{-\infty}^{\infty} k(y,x) f_{m_k}(x)\,dx\to \int_{-\infty}^{\infty} k(y,x)g(x)\,dx,\tag{1}$$ then since $(f_{m_k})$ is Cauchy and $T$ is bounded, $(Tf_{m_k})$ is Cauchy and thus converges to an element of $L^2(\Bbb R)$. This then says that $$\int_{-\infty}^{\infty} k(y,x) g(x)\,dx = \lim_k \int_{-\infty}^{\infty} k(y,x) f_{m_k}(x)\,dx = \lim_k Tf_{m_k}(y).$$ Since $\lim_k Tf_{m_k}\in L^2(\Bbb R)$, we'd have that $Tg\in L^2(\Bbb R)$ since they agree almost everywhere. This is predicated on $(1)$ being true. $(1)$ can be shown if dominated convergence can be applied, though it isn't clear that the $k(y,\cdot)f_{m_k}$ can be bounded uniformly by an integrable function for a fixed but arbitrary $y$. If $g$ could be approximated within by elements in $X$, then this would work, but that is a very strong condition and will not be the case in general.",,"['functional-analysis', 'integral-transforms']"
80,Hille Yosida theorem application,Hille Yosida theorem application,,"Disclaimer: pretty long and specific (contraction semi groups involved). I have fourth order parabolic equation $$ u_t + \Delta^2 u = 0 $$ on $U_T = U \times [0,T]$. $U \subset \mathbb{R}^m$ is a bounded open set with smooth boundary. Boundary conditions are: $$ u(x,0) = g \in L^2(U) $$ and $$ u=\frac{\partial U}{\partial n}=0 \quad \text{on } \partial U \times [0,T]  $$ I would like to prove the existence of a weak solution. From Hille Yosida theorem i deduce that weak solution exists if the operator $-\Delta^2$ generates a contraction semigroup (is this ok?): To prove this i define (is this ok?) $$ D(-\Delta^2) = H^4(U) \cap H_0^2 (U) $$ Density: $C_0^{\infty}(U) \subset H^4(U) \cap H_0^2 (U)$. $C_0^{\infty}(U)$  is dense in $L^2(U)$ and thus $D(-\Delta^2) $ is dense in $L^2(U)$ (is this ok?) Closedness: $\{u_k\}_k^{\infty} \subset D(-\Delta^2)$ with \begin{align*} u_k & \to u \\ -\Delta^2 u_k & \to f \end{align*} in $L^2(U)$ when $k \to \infty$. I have $$ ||u_k - u_l||_{H^2(U)} \leq C(||-\Delta^2 u_k + \Delta^2 u_l||_{L^2(U)} + ||u_k - u_l||_{L^2(U)}) $$ and then $u \in D(-\Delta^2)$ and $-\Delta^2 u =f$ $\lambda \in \mathbb{R}$ belongs to resolvent set $\rho (-\Delta^2)$ if operator $\lambda I + \Delta^2: D(-\Delta^2) \to L^2(U)$ is one-to-one and onto. For $\lambda \in \rho (-\Delta^2)$, the resolvent operator $R_{\lambda}: L^2(U) \to L^2(U)$ is defined by $R_{\lambda}u =  (\lambda I + \Delta^2)^{-1} u $. I have to prove also $(0,\infty) \subset \rho (-\Delta^2)$: I show that equation $\lambda u + \Delta^2 u = f$ has unique weak solution for $\lambda > 0$ and assume that is also regular (can i do this?) Now $\lambda I + \Delta^2$ is one-to-one and onto for $\lambda > 0$ and thus $(0,\infty) \subset \rho (-\Delta^2)$. Last thing to prove $||R_{\lambda}||_{L^2(U)} \leq \frac1{\lambda}$: Weak solution satisfies $$ \lambda \int_U uv dx + \int_U \Delta v \Delta u dx = \int_U fv dx $$ for all $v \in H_0^2(U)$. I set $u=v$ to get $$ \lambda \int_U u^2 dx + \int_U (\Delta u)^2 dx = \int_U fu dx $$ From here  $$ \lambda \int_U u^2 dx  = \lambda ||u||_{L^2(U)}^2 \leq \int_U fu dx \leq ||f||_{L^2(U)} ||u||_{L^2(U)}  $$ and $$ ||u||_{L^2(U)} \leq \frac{1}{\lambda} ||f||_{L^2(U)} $$ Acknowledging $$R_{\lambda}f = u$$ we get $$ ||R_{\lambda}|| \leq \frac{1}{\lambda} $$ as desired. Is this close to ok? Help warmly accepted.","Disclaimer: pretty long and specific (contraction semi groups involved). I have fourth order parabolic equation $$ u_t + \Delta^2 u = 0 $$ on $U_T = U \times [0,T]$. $U \subset \mathbb{R}^m$ is a bounded open set with smooth boundary. Boundary conditions are: $$ u(x,0) = g \in L^2(U) $$ and $$ u=\frac{\partial U}{\partial n}=0 \quad \text{on } \partial U \times [0,T]  $$ I would like to prove the existence of a weak solution. From Hille Yosida theorem i deduce that weak solution exists if the operator $-\Delta^2$ generates a contraction semigroup (is this ok?): To prove this i define (is this ok?) $$ D(-\Delta^2) = H^4(U) \cap H_0^2 (U) $$ Density: $C_0^{\infty}(U) \subset H^4(U) \cap H_0^2 (U)$. $C_0^{\infty}(U)$  is dense in $L^2(U)$ and thus $D(-\Delta^2) $ is dense in $L^2(U)$ (is this ok?) Closedness: $\{u_k\}_k^{\infty} \subset D(-\Delta^2)$ with \begin{align*} u_k & \to u \\ -\Delta^2 u_k & \to f \end{align*} in $L^2(U)$ when $k \to \infty$. I have $$ ||u_k - u_l||_{H^2(U)} \leq C(||-\Delta^2 u_k + \Delta^2 u_l||_{L^2(U)} + ||u_k - u_l||_{L^2(U)}) $$ and then $u \in D(-\Delta^2)$ and $-\Delta^2 u =f$ $\lambda \in \mathbb{R}$ belongs to resolvent set $\rho (-\Delta^2)$ if operator $\lambda I + \Delta^2: D(-\Delta^2) \to L^2(U)$ is one-to-one and onto. For $\lambda \in \rho (-\Delta^2)$, the resolvent operator $R_{\lambda}: L^2(U) \to L^2(U)$ is defined by $R_{\lambda}u =  (\lambda I + \Delta^2)^{-1} u $. I have to prove also $(0,\infty) \subset \rho (-\Delta^2)$: I show that equation $\lambda u + \Delta^2 u = f$ has unique weak solution for $\lambda > 0$ and assume that is also regular (can i do this?) Now $\lambda I + \Delta^2$ is one-to-one and onto for $\lambda > 0$ and thus $(0,\infty) \subset \rho (-\Delta^2)$. Last thing to prove $||R_{\lambda}||_{L^2(U)} \leq \frac1{\lambda}$: Weak solution satisfies $$ \lambda \int_U uv dx + \int_U \Delta v \Delta u dx = \int_U fv dx $$ for all $v \in H_0^2(U)$. I set $u=v$ to get $$ \lambda \int_U u^2 dx + \int_U (\Delta u)^2 dx = \int_U fu dx $$ From here  $$ \lambda \int_U u^2 dx  = \lambda ||u||_{L^2(U)}^2 \leq \int_U fu dx \leq ||f||_{L^2(U)} ||u||_{L^2(U)}  $$ and $$ ||u||_{L^2(U)} \leq \frac{1}{\lambda} ||f||_{L^2(U)} $$ Acknowledging $$R_{\lambda}f = u$$ we get $$ ||R_{\lambda}|| \leq \frac{1}{\lambda} $$ as desired. Is this close to ok? Help warmly accepted.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
81,What is the interpretation/intuition of $e^{itA}$ for a self-adjoint unbounded operator?,What is the interpretation/intuition of  for a self-adjoint unbounded operator?,e^{itA},"Let $A : i \frac{d}{dt} : D(A) \to H^1([0,1])$ with domain $D(A)=H^1_*([0,1])=\{u \in H^1([0,1]): u(0)=u(1)\} \subseteq H^1([0,1])$ . Then I know that $A$ is self-adjoint. Using the spectral theorem, we find that for any $u \in L^2([0,1])$ , an explicit formula for $(e^{itA}u)(x,t)$ is given by $\tilde{u}(x,t)= u(x-t)$ . This makes sense to me, because $\tilde{u}$ satisfies the PDE $\ \partial_t \tilde{u} = -\partial_x \tilde{u}$ with initial condition $u$ , which is what one finds when formally taking the following derivative : $$ \partial_t (e^{itA}u) = iA (e^{itA}u) = -\partial_x (e^{itA}u).$$ Now, I have trouble understanding the following. If we take $A_{\alpha}: i \frac{d}{dt} : D(A_\alpha) \to H^1$ this time with domain $D(A_\alpha) = \{u \in H^1([0,1]) : u(0)=e^{i\alpha}u(1)\}$ , then $A_\alpha$ is also self-adjoint. With the spectral theorem, we find $(e^{itA_\alpha}u)(x,t)= u(x-t)e^{-i \alpha t},$ which this time satisfies the PDE $\partial_t \tilde{u} + \partial_x \tilde{u} = -i\alpha \tilde{u}.$ But in my opinion, this contradicts the intuition provided by the formal derivative (which hasn't changed) : $$ \partial_t (e^{itA}u) = iA (e^{itA}u) = -\partial_x (e^{itA}u). $$ So we see that even though we have taken the ""same"" operator $A \sim A_{\alpha}$ , the PDE solved by applying $e^{itA}$ has changed, just by changing the domain of definition of the operator and the formal derivation doesn't work (at least the same way) anymore. I thought the point of $e^{itA}$ was just to solve the 'heat equation' $\partial_t \tilde{u} = iA \tilde{u}$ ? What is an interpretation of this phenomenon ? Is there a way to know what domain we should work on if we are given a specific PDE to 'solve' ?","Let with domain . Then I know that is self-adjoint. Using the spectral theorem, we find that for any , an explicit formula for is given by . This makes sense to me, because satisfies the PDE with initial condition , which is what one finds when formally taking the following derivative : Now, I have trouble understanding the following. If we take this time with domain , then is also self-adjoint. With the spectral theorem, we find which this time satisfies the PDE But in my opinion, this contradicts the intuition provided by the formal derivative (which hasn't changed) : So we see that even though we have taken the ""same"" operator , the PDE solved by applying has changed, just by changing the domain of definition of the operator and the formal derivation doesn't work (at least the same way) anymore. I thought the point of was just to solve the 'heat equation' ? What is an interpretation of this phenomenon ? Is there a way to know what domain we should work on if we are given a specific PDE to 'solve' ?","A : i \frac{d}{dt} : D(A) \to H^1([0,1]) D(A)=H^1_*([0,1])=\{u \in H^1([0,1]): u(0)=u(1)\} \subseteq H^1([0,1]) A u \in L^2([0,1]) (e^{itA}u)(x,t) \tilde{u}(x,t)= u(x-t) \tilde{u} \ \partial_t \tilde{u} = -\partial_x \tilde{u} u  \partial_t (e^{itA}u) = iA (e^{itA}u) = -\partial_x (e^{itA}u). A_{\alpha}: i \frac{d}{dt} : D(A_\alpha) \to H^1 D(A_\alpha) = \{u \in H^1([0,1]) : u(0)=e^{i\alpha}u(1)\} A_\alpha (e^{itA_\alpha}u)(x,t)= u(x-t)e^{-i \alpha t}, \partial_t \tilde{u} + \partial_x \tilde{u} = -i\alpha \tilde{u}.  \partial_t (e^{itA}u) = iA (e^{itA}u) = -\partial_x (e^{itA}u).  A \sim A_{\alpha} e^{itA} e^{itA} \partial_t \tilde{u} = iA \tilde{u}","['functional-analysis', 'partial-differential-equations', 'operator-theory']"
82,A projection operator is linear iff $X$ is a Hilbert space,A projection operator is linear iff  is a Hilbert space,X,"This question comes from Linear and Nonlinear Functional Analysis with Applications (Philippe G. Ciarlet), Chapter 4, Problem 4.3-4. 4.3-4 Let $\mathcal{P}_n[0,1]=\left\{\left.p\right|_{[0,1]} ; p \in \mathcal{P}_n\right\}$ , where $\mathcal{P}_n$ denotes the space of all polynomials $p: \mathbb{R} \rightarrow \mathbb{R}$ of degree $\leq n$ , and let a number $q>1$ be given. (1) Show that, given any function $f \in \mathcal{C}[0,1]$ , there exists a unique polynomial $P f \in \mathcal{P}_n[0,1]$ such that $$ \|f-P f\|_{L^q(0,1)}=\inf _{p \in \mathcal{P}_n(0,1]}\|f-p\|_{L^q(0,1)} . $$ (2) Show that the mapping $P: \mathcal{C}[0,1] \rightarrow \mathcal{P}_n[0,1]$ defined in this fashion is linear if and only if $q=2$ (the proof of the ""if"" part is similar to that of Theorem 4.3-1(e)). I have proved (1), my question is about how to prove (2) $""\Rightarrow""$ (only if) part. Any help is appreciated!","This question comes from Linear and Nonlinear Functional Analysis with Applications (Philippe G. Ciarlet), Chapter 4, Problem 4.3-4. 4.3-4 Let , where denotes the space of all polynomials of degree , and let a number be given. (1) Show that, given any function , there exists a unique polynomial such that (2) Show that the mapping defined in this fashion is linear if and only if (the proof of the ""if"" part is similar to that of Theorem 4.3-1(e)). I have proved (1), my question is about how to prove (2) (only if) part. Any help is appreciated!","\mathcal{P}_n[0,1]=\left\{\left.p\right|_{[0,1]} ; p \in \mathcal{P}_n\right\} \mathcal{P}_n p: \mathbb{R} \rightarrow \mathbb{R} \leq n q>1 f \in \mathcal{C}[0,1] P f \in \mathcal{P}_n[0,1] 
\|f-P f\|_{L^q(0,1)}=\inf _{p \in \mathcal{P}_n(0,1]}\|f-p\|_{L^q(0,1)} .
 P: \mathcal{C}[0,1] \rightarrow \mathcal{P}_n[0,1] q=2 ""\Rightarrow""","['functional-analysis', 'hilbert-spaces', 'projection']"
83,Fourier transform of $L^1$ function is continuous function,Fourier transform of  function is continuous function,L^1,"I would like to know if my proof is correct. Define Fourier transform of $f\in L^1(\mathbb{R}^n)$ as $$\widehat{f}(x)=\int_{\mathbb{R}^n}e^{-ix\cdot y}f(y)\text{d}y.$$  I want to show that $\widehat{f}$ is continuous. So pick any sequence $x_n\rightarrow x$. Now $g_n(y)=e^{-ix_n\cdot y}f(y)$ is measurable for all $n\in\mathbb{N}$, $g_n(y)\rightarrow e^{-ix\cdot y}f(y)=g(y)$ for all $y$ and $|e^{-ix_n\cdot y}f(y)|=|f(y)|$ where $|f(y)|$ is integrable. So by dominated convergence theorem we have $$\lim_{n\rightarrow \infty}\widehat{f}(x_n)=\lim_{n\rightarrow \infty}\int_{\mathbb{R}^n}e^{-ix_n\cdot y}f(y)\text{d}y=\lim_{n\rightarrow\infty}\int_{\mathbb{R}^n}g_n(y)\text{d}y=\int_{\mathbb{R}^n}g(y)\text{d}y=\int_{\mathbb{R}^n}e^{-ix\cdot y}f(y)\text{d}y=\widehat{f}(x).$$ Therefore $\hat{f}$ is continuous. Am I correct?","I would like to know if my proof is correct. Define Fourier transform of $f\in L^1(\mathbb{R}^n)$ as $$\widehat{f}(x)=\int_{\mathbb{R}^n}e^{-ix\cdot y}f(y)\text{d}y.$$  I want to show that $\widehat{f}$ is continuous. So pick any sequence $x_n\rightarrow x$. Now $g_n(y)=e^{-ix_n\cdot y}f(y)$ is measurable for all $n\in\mathbb{N}$, $g_n(y)\rightarrow e^{-ix\cdot y}f(y)=g(y)$ for all $y$ and $|e^{-ix_n\cdot y}f(y)|=|f(y)|$ where $|f(y)|$ is integrable. So by dominated convergence theorem we have $$\lim_{n\rightarrow \infty}\widehat{f}(x_n)=\lim_{n\rightarrow \infty}\int_{\mathbb{R}^n}e^{-ix_n\cdot y}f(y)\text{d}y=\lim_{n\rightarrow\infty}\int_{\mathbb{R}^n}g_n(y)\text{d}y=\int_{\mathbb{R}^n}g(y)\text{d}y=\int_{\mathbb{R}^n}e^{-ix\cdot y}f(y)\text{d}y=\widehat{f}(x).$$ Therefore $\hat{f}$ is continuous. Am I correct?",,"['functional-analysis', 'measure-theory', 'fourier-analysis', 'fourier-transform']"
84,"A characterization of the ""Direct Integral"" construction in terms of the properties it satisfies?","A characterization of the ""Direct Integral"" construction in terms of the properties it satisfies?",,"Fortunately there's a wonderful thing called the ""direct integral"" which enables one to make sense of direct sums of uncountably infinite families of Hilbert spaces. Unfortunately I've tried to read about the constructions several times and while every time I walked away with a bit more confidence i'm still not sure how to spell out precisely what properties it satisfies - which is in practice much more important then the construction itself. Hence the question: Is there a ""unique"" characterization of the ""direct integral"" construction for hilbert spaces in terms of the list of the properties it satisfies? By ""unique"" I don't mean anything precise, I'm only looking for the most exhaustive list of properties of the construction such that it is more or less clear that the direct integral is not some aribtrary construction. I'm not asking for a precise categorical definition or anything like that (although if there is one i'd be happy to hear it). I'm just trying to understand the construction enough to be able to use confidently in places where it appears. In particular such a description should be easily adjusted to describe direct integrals of representations of groups/algebras etc...","Fortunately there's a wonderful thing called the ""direct integral"" which enables one to make sense of direct sums of uncountably infinite families of Hilbert spaces. Unfortunately I've tried to read about the constructions several times and while every time I walked away with a bit more confidence i'm still not sure how to spell out precisely what properties it satisfies - which is in practice much more important then the construction itself. Hence the question: Is there a ""unique"" characterization of the ""direct integral"" construction for hilbert spaces in terms of the list of the properties it satisfies? By ""unique"" I don't mean anything precise, I'm only looking for the most exhaustive list of properties of the construction such that it is more or less clear that the direct integral is not some aribtrary construction. I'm not asking for a precise categorical definition or anything like that (although if there is one i'd be happy to hear it). I'm just trying to understand the construction enough to be able to use confidently in places where it appears. In particular such a description should be easily adjusted to describe direct integrals of representations of groups/algebras etc...",,"['functional-analysis', 'measure-theory', 'representation-theory', 'hilbert-spaces', 'spectral-theory']"
85,"Are uncountable ""Schauder-like"" bases studied/used?","Are uncountable ""Schauder-like"" bases studied/used?",,"We could define the following notion of basis in a way analogous to unconditional Schauder basis : If $X$ is a topological vector space over $\mathbb R$ and $B=\{b_i; i\in I\}$ be a subset of $X$. We say that $B$ is a basis if, for every $x\in X$ there exists a unique ""coefficient function"" $c\colon I\to\mathbb R$ such that   $$\sum_{i\in I} c(i) b_i =x.$$ Probably more natural notation -- resembling the usual notation for linear combinations -- would be $\sum\limits_{i\in I} c_i b_i =x$. The sum $\sum\limits_{i\in I} v_i$ of elements of a topological vector space is defined as a limit of the net $$x_F=\sum_{i\in F} x_i$$ on the directed set consisting of all finite subsets of $I$ (ordered by inclusion). This seems to be the usual approach for defining sums over an index set which is not necessarily countable. It is defined in this way, for example, in this answer . Does this type of basis have a name? Are such basis studied? Are they useful in some areas of mathematics? For example, orthonormal basis (maximal orthonormal set) in a Hilbert space is such basis. Motivation for this questions is that it seems to be a very natural next step after defining Hamel basis and Schauder basis. In a typical curriculum, most people usually encounter the word basis for the first time in connection with vector space. If we only have structure of a vector space, we only can do finite sums and finite linear combinations. So trying to define basis using something like $\sum\limits_{i=1}^\infty c_i b_i$ is not possible. But later we learn about normed spaces and topological vector space, where we have the notion of convergence and thus the expression $\sum\limits_{i=1}^\infty c_i b_i$ makes sense. So we now can define the Schauder basis and the definition seems very similar to the definition of Hamel basis - we just replaced finite sum by an infinite series. Now we could try to define the analogous notion for arbitrary index set, not just $\mathbb N$. One possible way to do this would be to use the notion of sum over arbitrary index set which I described above. (On $\mathbb N$ we have a natural ordering, while on arbitrary set $I$ we do not have an order which we could call ""natural"". Therefore this notion is closer to unconditional Schauder basis than to Schauder basis.) When trying to find some references for this type of basis I found the following remark in Heil's Basis Theory Primer ( doi:10.1007/978-0-8176-4687-5 ; some version of the manuscript seems to be available on the author's website : Remark 4.4: (d) The definition of basis requires that $\{x_n\}$ be a countable sequence. Sometimes, as in Exercises 3.6 and 3.7, it is possible to deal with uncountable systems that have basis-like properties, but to avoid confusion we will not call such systems bases. The above remark suggest that the type of basis I described above is probably not very useful. (By the way the Exercise 3.6 and 3.7 mentioned in this remark contain, among other things, the fact that orthonormal basis of a Hilbert space has such properties.) On the other hand, special case of such basis is an orthonormal basis in a Hilbert space. I'd say that the fact that an inner-product space has an orthonormal basis gives some useful information about this space. But I guess that it might be difficult to use similar basis in a sensible way in a Banach space, which is not a Hilbert space. Despite this skepticism, I posted the question here. It is still possible that I will learn from answers about some unexpected applications. EDIT: Almost immediately after posting this question I have noticed this older question: What do we call a Schauder-like basis that is uncountable? I would argue that the questions are a bit different. The other posts only asks about the name for such basis, not for applications. And the OP does not describe how exactly they want to go from the countable case to the arbitrary case. (Although to me the above seems the most natural way, the phrasing of the other question leaves also other possibilities open. (And in fact, a comment posted there describes some kind of basis which seems different from my definition above.) I will leave it to other users to judge whether the two questions are different enough to remain open, or whether one of them should be closed as a duplicate. EDIT 2: After a bit of searching I found a post on MO which asks (if I understand it correctly) whether the cardinality of this type of basis (assuming it exists) is determined uniquely by the space $X$: Uniqueness of dimension in Banach spaces","We could define the following notion of basis in a way analogous to unconditional Schauder basis : If $X$ is a topological vector space over $\mathbb R$ and $B=\{b_i; i\in I\}$ be a subset of $X$. We say that $B$ is a basis if, for every $x\in X$ there exists a unique ""coefficient function"" $c\colon I\to\mathbb R$ such that   $$\sum_{i\in I} c(i) b_i =x.$$ Probably more natural notation -- resembling the usual notation for linear combinations -- would be $\sum\limits_{i\in I} c_i b_i =x$. The sum $\sum\limits_{i\in I} v_i$ of elements of a topological vector space is defined as a limit of the net $$x_F=\sum_{i\in F} x_i$$ on the directed set consisting of all finite subsets of $I$ (ordered by inclusion). This seems to be the usual approach for defining sums over an index set which is not necessarily countable. It is defined in this way, for example, in this answer . Does this type of basis have a name? Are such basis studied? Are they useful in some areas of mathematics? For example, orthonormal basis (maximal orthonormal set) in a Hilbert space is such basis. Motivation for this questions is that it seems to be a very natural next step after defining Hamel basis and Schauder basis. In a typical curriculum, most people usually encounter the word basis for the first time in connection with vector space. If we only have structure of a vector space, we only can do finite sums and finite linear combinations. So trying to define basis using something like $\sum\limits_{i=1}^\infty c_i b_i$ is not possible. But later we learn about normed spaces and topological vector space, where we have the notion of convergence and thus the expression $\sum\limits_{i=1}^\infty c_i b_i$ makes sense. So we now can define the Schauder basis and the definition seems very similar to the definition of Hamel basis - we just replaced finite sum by an infinite series. Now we could try to define the analogous notion for arbitrary index set, not just $\mathbb N$. One possible way to do this would be to use the notion of sum over arbitrary index set which I described above. (On $\mathbb N$ we have a natural ordering, while on arbitrary set $I$ we do not have an order which we could call ""natural"". Therefore this notion is closer to unconditional Schauder basis than to Schauder basis.) When trying to find some references for this type of basis I found the following remark in Heil's Basis Theory Primer ( doi:10.1007/978-0-8176-4687-5 ; some version of the manuscript seems to be available on the author's website : Remark 4.4: (d) The definition of basis requires that $\{x_n\}$ be a countable sequence. Sometimes, as in Exercises 3.6 and 3.7, it is possible to deal with uncountable systems that have basis-like properties, but to avoid confusion we will not call such systems bases. The above remark suggest that the type of basis I described above is probably not very useful. (By the way the Exercise 3.6 and 3.7 mentioned in this remark contain, among other things, the fact that orthonormal basis of a Hilbert space has such properties.) On the other hand, special case of such basis is an orthonormal basis in a Hilbert space. I'd say that the fact that an inner-product space has an orthonormal basis gives some useful information about this space. But I guess that it might be difficult to use similar basis in a sensible way in a Banach space, which is not a Hilbert space. Despite this skepticism, I posted the question here. It is still possible that I will learn from answers about some unexpected applications. EDIT: Almost immediately after posting this question I have noticed this older question: What do we call a Schauder-like basis that is uncountable? I would argue that the questions are a bit different. The other posts only asks about the name for such basis, not for applications. And the OP does not describe how exactly they want to go from the countable case to the arbitrary case. (Although to me the above seems the most natural way, the phrasing of the other question leaves also other possibilities open. (And in fact, a comment posted there describes some kind of basis which seems different from my definition above.) I will leave it to other users to judge whether the two questions are different enough to remain open, or whether one of them should be closed as a duplicate. EDIT 2: After a bit of searching I found a post on MO which asks (if I understand it correctly) whether the cardinality of this type of basis (assuming it exists) is determined uniquely by the space $X$: Uniqueness of dimension in Banach spaces",,"['functional-analysis', 'normed-spaces', 'topological-vector-spaces', 'schauder-basis']"
86,Energy inequalities with negative sobolev number.,Energy inequalities with negative sobolev number.,,"Let $\phi\in H^{s}$ such that the following energy inequality is true: $$\|\phi(t,\cdot)\|_s \le\int^t_0 C \| P\phi(t,\cdot)\|_s \, dt  $$ where $P$ is a strictly hyperbolic  linear operator. For concreteness, let $P$ be the wave operator $\square_{g}$. Now is the energy inequality true for $-s$? I have attempted the following: Let $\phi\in H^{-s}$. Then we can define $\psi=(1-\Delta)^{-s} \phi\in H^s$ So we have $$\|\phi\|_{-s}=\| \psi\|_s \le C \int \| P\psi\|_s $$ Now if we estimate $\| P\psi\|_s $ in terms of $\|\phi\|_{-s}$ and $\| P\phi\|_{-s}$ The proof will be over. Notice that $$P\phi=P(1-\Delta)^s \psi=(1-\Delta)^s P \psi+ [P,(1-\Delta)^s]\psi $$ Hence, $$\| P \psi\|_s \le  \Arrowvert P\phi\Arrowvert_{-s} +\|[P,(1-\Delta)^s]\psi\|_{-s} $$ Can someone point me out if there are some estimates for the  commutator? In the book ""The Cauchy problem in General Relativity "" by Ringstrom it is stated that the following proposition: Let $m$ and $l$ be non-negative integers, $\alpha\le l+m$, $u\in S$ and $f\in C^{\infty}$. Then $$||f\partial^{\alpha}u||_{-m}\le C ||u||_{l}$$ gives the following bound for the commutator \begin{equation}   C(||\psi||_{s}+||\psi_{t}||_{s-1}) \end{equation} Although I am not clear how he gets it. Also he expresses the problem as a first order PDE. Is this necessary? I also think that the result can be shown using the theory of pseudo-differential operators. The idea will be two show that $$[P,(1-\Delta)^s]$$ is a bounded linear operator from $H^{s}$ to $H^{-s}$. We know that  $(1-\Delta)^s\in OPS^{2s}$ and that $P\in OPS^{2}$. Is there any theorem that might show the desire result?","Let $\phi\in H^{s}$ such that the following energy inequality is true: $$\|\phi(t,\cdot)\|_s \le\int^t_0 C \| P\phi(t,\cdot)\|_s \, dt  $$ where $P$ is a strictly hyperbolic  linear operator. For concreteness, let $P$ be the wave operator $\square_{g}$. Now is the energy inequality true for $-s$? I have attempted the following: Let $\phi\in H^{-s}$. Then we can define $\psi=(1-\Delta)^{-s} \phi\in H^s$ So we have $$\|\phi\|_{-s}=\| \psi\|_s \le C \int \| P\psi\|_s $$ Now if we estimate $\| P\psi\|_s $ in terms of $\|\phi\|_{-s}$ and $\| P\phi\|_{-s}$ The proof will be over. Notice that $$P\phi=P(1-\Delta)^s \psi=(1-\Delta)^s P \psi+ [P,(1-\Delta)^s]\psi $$ Hence, $$\| P \psi\|_s \le  \Arrowvert P\phi\Arrowvert_{-s} +\|[P,(1-\Delta)^s]\psi\|_{-s} $$ Can someone point me out if there are some estimates for the  commutator? In the book ""The Cauchy problem in General Relativity "" by Ringstrom it is stated that the following proposition: Let $m$ and $l$ be non-negative integers, $\alpha\le l+m$, $u\in S$ and $f\in C^{\infty}$. Then $$||f\partial^{\alpha}u||_{-m}\le C ||u||_{l}$$ gives the following bound for the commutator \begin{equation}   C(||\psi||_{s}+||\psi_{t}||_{s-1}) \end{equation} Although I am not clear how he gets it. Also he expresses the problem as a first order PDE. Is this necessary? I also think that the result can be shown using the theory of pseudo-differential operators. The idea will be two show that $$[P,(1-\Delta)^s]$$ is a bounded linear operator from $H^{s}$ to $H^{-s}$. We know that  $(1-\Delta)^s\in OPS^{2s}$ and that $P\in OPS^{2}$. Is there any theorem that might show the desire result?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
87,Donsker's Theorem for triangular arrays,Donsker's Theorem for triangular arrays,,"Assume we have a sequence of smooth i.i.d. random variables $(X_i)_{i=1}^{\infty}$. Given $\alpha>0$, does some sort of Donsker's Theorem hold for $\left(\frac{X_i}{n^{\alpha}}\right)_{i=1}^n$? More precisely, does $$n^{2\alpha}\left(\frac{\sum_{i=1}^n \mathbf 1_{\{X_i\leq t n^{-\alpha}\}}}{n} - F_X(tn^{-\alpha})\right)\stackrel{\mathrm d}{\rightarrow} B(t),$$ where $B(\cdot)$ is a Brownian motion and $F_X$ is the distribution function of $X_1$, hold? I should mention that the $n^{2\alpha}$ is only an (informed) guess.  In the usual Donsker's Theorem the limiting process is $B_0(F(t))$, where $B_0$ is a Brownian Bridge, but in this case the limiting process would need to be pinned down to zero 'at infinity', and thus my guess that it's actually a Brownian Motion. Is this common knowledge? I have been digging through the literature and it does not seem to be proved anywhere.","Assume we have a sequence of smooth i.i.d. random variables $(X_i)_{i=1}^{\infty}$. Given $\alpha>0$, does some sort of Donsker's Theorem hold for $\left(\frac{X_i}{n^{\alpha}}\right)_{i=1}^n$? More precisely, does $$n^{2\alpha}\left(\frac{\sum_{i=1}^n \mathbf 1_{\{X_i\leq t n^{-\alpha}\}}}{n} - F_X(tn^{-\alpha})\right)\stackrel{\mathrm d}{\rightarrow} B(t),$$ where $B(\cdot)$ is a Brownian motion and $F_X$ is the distribution function of $X_1$, hold? I should mention that the $n^{2\alpha}$ is only an (informed) guess.  In the usual Donsker's Theorem the limiting process is $B_0(F(t))$, where $B_0$ is a Brownian Bridge, but in this case the limiting process would need to be pinned down to zero 'at infinity', and thus my guess that it's actually a Brownian Motion. Is this common knowledge? I have been digging through the literature and it does not seem to be proved anywhere.",,"['functional-analysis', 'statistics', 'probability-theory', 'stochastic-processes', 'stochastic-analysis']"
88,Sampling theorem.,Sampling theorem.,,"Let us consider \begin{equation} \hat{f}(x)=\sum_{n\in \mathbb Z}\left\langle\hat{f},e^{i n x}\right\rangle_{L^2[-\pi,\pi]} e^{i n x} \ \ \ \ \ \ \ \ (1) \end{equation} where $\langle g, h\rangle_{L^2[-\pi,\pi]}=\int_{-\pi}^\pi g(x) \overline{h(x)} dx$. Taking the inverse Fourier transform in (1), we obtain the Whittaker-Kotelnikov-Shannon (WKS) sampling theorem, \begin{equation} f(x)=\sum_{n\in \mathbb Z}f(n) \operatorname{sinc}(x-n), \ \ \ x\in \mathbb R \end{equation} where $f$ is the inverse Fourier transform of the function $\hat{f}$. I would like to know if there is a version of this theorem for $x\in \mathbb C$.  Are there any good online resources for it? Thanks!","Let us consider \begin{equation} \hat{f}(x)=\sum_{n\in \mathbb Z}\left\langle\hat{f},e^{i n x}\right\rangle_{L^2[-\pi,\pi]} e^{i n x} \ \ \ \ \ \ \ \ (1) \end{equation} where $\langle g, h\rangle_{L^2[-\pi,\pi]}=\int_{-\pi}^\pi g(x) \overline{h(x)} dx$. Taking the inverse Fourier transform in (1), we obtain the Whittaker-Kotelnikov-Shannon (WKS) sampling theorem, \begin{equation} f(x)=\sum_{n\in \mathbb Z}f(n) \operatorname{sinc}(x-n), \ \ \ x\in \mathbb R \end{equation} where $f$ is the inverse Fourier transform of the function $\hat{f}$. I would like to know if there is a version of this theorem for $x\in \mathbb C$.  Are there any good online resources for it? Thanks!",,"['functional-analysis', 'reference-request', 'fourier-analysis', 'signal-processing']"
89,Hilbert transform and Hilbert matrix,Hilbert transform and Hilbert matrix,,"The Hilbert matrix is \begin{bmatrix}  1 & \frac{1}{2} & \frac{1}{3} & \frac{1}{4} & \dots \\[4pt] \frac{1}{2} & \frac{1}{3} & \frac{1}{4} & & \ddots \\[4pt] \frac{1}{3} & \frac{1}{4} & & \ddots & \\[4pt] \frac{1}{4} & & \ddots & & \\[4pt] \vdots & \ddots & & & \end{bmatrix} I believe the Hilbert transform of a function $u$ on the circle $\mathbb T$ is, when it exists, the radial limit of the harmonic conjugate of u defined in the open disk $\mathbb D$. This conjugate limit exists in $L^p$ (it also exists pointwise a.e. for Lebesgue measure on $\mathbb T$ then) for all $u\in L^p, p>1$. Here we only need $L^2$. The Hilbert matrix is a bounded Hankel operator on $\ell^2$, whose entries are therefore the positive Fourier coefficients of some $L^\infty(\mathbb T)$ function. The function $\sum_{n\ge 0}\frac{z^n}{n+1}$ has those Fourier coefficients but is not bounded on the circle, we can add negative Fourier coefficients to obtain $ie^{-it}(\pi-t)$ which is bounded -i.e. in $L^\infty(\mathbb T)$. From this last function we get an $L^\infty$ symbol for the Hilbert matrix as a multiplication operator from Hardy space to negative Hardy space. The Hilbert transform is a multiplication operator (in $\hat{\ell^2}$, ""Fourier"" space) but from Hardy space ($H^2(\mathbb T)$) to itself because we just multiply the $n$th Fourier coefficients by $(-1)^{n-1}i$ -if I made no mistake. Hilbert arrived at both at different times in his career: In 1894 for the matrix, investigating a question of approximation by orthogonal polynomials, and 1905 for the transform, investigating the Riemann-Hilbert problem. However I wonder if they may be related, because they connect to many related concepts. I may expand later, but if anyone has guesses or knows anything, I'd be glad to hear them.","The Hilbert matrix is \begin{bmatrix}  1 & \frac{1}{2} & \frac{1}{3} & \frac{1}{4} & \dots \\[4pt] \frac{1}{2} & \frac{1}{3} & \frac{1}{4} & & \ddots \\[4pt] \frac{1}{3} & \frac{1}{4} & & \ddots & \\[4pt] \frac{1}{4} & & \ddots & & \\[4pt] \vdots & \ddots & & & \end{bmatrix} I believe the Hilbert transform of a function $u$ on the circle $\mathbb T$ is, when it exists, the radial limit of the harmonic conjugate of u defined in the open disk $\mathbb D$. This conjugate limit exists in $L^p$ (it also exists pointwise a.e. for Lebesgue measure on $\mathbb T$ then) for all $u\in L^p, p>1$. Here we only need $L^2$. The Hilbert matrix is a bounded Hankel operator on $\ell^2$, whose entries are therefore the positive Fourier coefficients of some $L^\infty(\mathbb T)$ function. The function $\sum_{n\ge 0}\frac{z^n}{n+1}$ has those Fourier coefficients but is not bounded on the circle, we can add negative Fourier coefficients to obtain $ie^{-it}(\pi-t)$ which is bounded -i.e. in $L^\infty(\mathbb T)$. From this last function we get an $L^\infty$ symbol for the Hilbert matrix as a multiplication operator from Hardy space to negative Hardy space. The Hilbert transform is a multiplication operator (in $\hat{\ell^2}$, ""Fourier"" space) but from Hardy space ($H^2(\mathbb T)$) to itself because we just multiply the $n$th Fourier coefficients by $(-1)^{n-1}i$ -if I made no mistake. Hilbert arrived at both at different times in his career: In 1894 for the matrix, investigating a question of approximation by orthogonal polynomials, and 1905 for the transform, investigating the Riemann-Hilbert problem. However I wonder if they may be related, because they connect to many related concepts. I may expand later, but if anyone has guesses or knows anything, I'd be glad to hear them.",,"['complex-analysis', 'functional-analysis', 'operator-theory']"
90,Gradient operator the adjoint of (minus) divergence operator?,Gradient operator the adjoint of (minus) divergence operator?,,"Recently I found this statement -- the gradient operator is the adjoint of the minus divergence operator -- in one of my lecture notes. Knowing only a little about functional analysis, I'm looking for an intuitive interpretation. I already found this topic which has a few good answers, but I'd like to view it from a somewhat different angle. So say there are two vector spaces $X$ and $Y$, and that $L$ is a linear operator that maps elements from $X$ to $Y$, i.e. $L:X\to Y$. Furthermore, the set of all bounded/continuous linear functionals on $X$ (i.e. $f\;| f:X\to\mathbb{R}$) is called the dual (space) of $X$, marked $X'$. Mutatis mutandis for $Y'$. Then, apparently if we take a look at our $L$, there is an operator (called the adjoint operator) $L'$ that maps elements from $Y'$ to $X'$, right? So $L':Y'\to X'$. To make this a little less abstract, let's take the gradient operator $\nabla$. Now, I don't know how to write down appropriate spaces $X$ and $Y$ such that $\nabla:X\to Y$. I thought about $C^1[a,b]$, the space of continuous differentiable functions on the interval $[a,b]$, which is then mapped to $C^0[a,b]$. But these are only functions of a single variable, right? How to denote the space of functions that depend on two or three variables, say $(x,y)$ resp. $(x,y,z)$? If I know the above mentioned spaces, then it should be possible to think of some operators in their duals, $X'$ and $Y'$. If I understand it correctly, the divergence operator should then be the operator to map operators from $Y'$ to $X'$. So my actual question: how to denote the mentioned spaces, come up with a few operators in their duals $X'$ and $Y'$ (so some examples), and then show that the divergence indeed maps the operators from $Y'$ to $X'$?","Recently I found this statement -- the gradient operator is the adjoint of the minus divergence operator -- in one of my lecture notes. Knowing only a little about functional analysis, I'm looking for an intuitive interpretation. I already found this topic which has a few good answers, but I'd like to view it from a somewhat different angle. So say there are two vector spaces $X$ and $Y$, and that $L$ is a linear operator that maps elements from $X$ to $Y$, i.e. $L:X\to Y$. Furthermore, the set of all bounded/continuous linear functionals on $X$ (i.e. $f\;| f:X\to\mathbb{R}$) is called the dual (space) of $X$, marked $X'$. Mutatis mutandis for $Y'$. Then, apparently if we take a look at our $L$, there is an operator (called the adjoint operator) $L'$ that maps elements from $Y'$ to $X'$, right? So $L':Y'\to X'$. To make this a little less abstract, let's take the gradient operator $\nabla$. Now, I don't know how to write down appropriate spaces $X$ and $Y$ such that $\nabla:X\to Y$. I thought about $C^1[a,b]$, the space of continuous differentiable functions on the interval $[a,b]$, which is then mapped to $C^0[a,b]$. But these are only functions of a single variable, right? How to denote the space of functions that depend on two or three variables, say $(x,y)$ resp. $(x,y,z)$? If I know the above mentioned spaces, then it should be possible to think of some operators in their duals, $X'$ and $Y'$. If I understand it correctly, the divergence operator should then be the operator to map operators from $Y'$ to $X'$. So my actual question: how to denote the mentioned spaces, come up with a few operators in their duals $X'$ and $Y'$ (so some examples), and then show that the divergence indeed maps the operators from $Y'$ to $X'$?",,"['functional-analysis', 'adjoint-operators']"
91,Fixed point: linear operators,Fixed point: linear operators,,"I ask my question in two parts: though the topic is similar, I would like to distinguish linear and general cases since methods may be too different while my questions are broad. Consider a space $X$ which we assume to be Banach. We define a linear operator $A:X\to X$ which is bounded: $$ \|\mathcal A\| := \sup\limits_{x\in X}\frac{\|\mathcal Ax\|}{\|x\|}<\infty. $$ I would like to discuss an existence of solution for a fixpoint equation  $$\mathcal Ax = x.\quad (1)$$ What do I know: this is an eigenvalue problem for $\lambda = 1$ or it is a problem of finding the kernel for $(\mathcal A-\mathcal I)$, $\mathcal I$ is an identity operator. Also, if $\dim X<\infty$ then $\mathcal  A$ has a correspondent finite-dimensional matrix $A$ and all properties of $(1)$ can be studied through the rang of $A$. E.g. there exists a solution of $(1)$ iff $\det (A-I)=0$ for $I$ is an identity matrix of the same size as $A$. For the general state-space my first question is: 1.If there is a method similar to calculating $\det (A-I)$ to verify the existence of solution for $(1)$? If the dimension of $X$ is not necessary finite, one of the main methods is to use Banach theorem based on the contraction principle - so it is only valid if $|\lambda^*(\mathcal A)<1|$ for the maximum eigenvalue in the absolute sense. 2.What can we do if the spectrum is not bounded by $1$ but just does not contain it? There are also procedures (usually in the discrete-time setting, e.g. $X = L^2$ and $\mathcal A$ is an integral operator) connected with the iterations of operator $\mathcal A$. There are examples (if one wants, I can put it here) when for some $x\neq 0$ the limit $$x' = \lim\limits_{n\to\infty}\mathcal A^nx\quad (2)$$ exists while $\mathcal A$ is not contractive. 3.Under which conditions $\mathcal Ax' = x'$? Finally, there are some methods in the continuous time setting (e.g. $X = L^2$ again and we are talking about differential operators). If one would like to solve an equation $\mathcal Bx = 0$ then it's helpful to consider a function $f(t)$ such that $f(0) = x_0$ and  $$ \frac{df}{dt}(t) = \mathcal B f(t).\quad (3) $$ Suppose, $\lim\limits_{t\to\infty}f(t) = x'\in X$. 4.Under which conditions $\mathcal Bx' = 0$? Finally, we can put $\mathcal A = \mathcal B+\mathcal I$. Then if the conditions of 4. are satisfied, $\mathcal Ax' = x'$. 5. Why for the integral equations (""discrete-time"") people commonly use $(2)$ while for, say PDEs they use $(3)$ rather then $(2)$? So there are 5 questions, and I would appreciate if you can help me with answering at least one of them or referring me to a literature which covers these questions. I guess that 5. is can be an unclear question - so if it is, just tell, I will try to make it clear.","I ask my question in two parts: though the topic is similar, I would like to distinguish linear and general cases since methods may be too different while my questions are broad. Consider a space $X$ which we assume to be Banach. We define a linear operator $A:X\to X$ which is bounded: $$ \|\mathcal A\| := \sup\limits_{x\in X}\frac{\|\mathcal Ax\|}{\|x\|}<\infty. $$ I would like to discuss an existence of solution for a fixpoint equation  $$\mathcal Ax = x.\quad (1)$$ What do I know: this is an eigenvalue problem for $\lambda = 1$ or it is a problem of finding the kernel for $(\mathcal A-\mathcal I)$, $\mathcal I$ is an identity operator. Also, if $\dim X<\infty$ then $\mathcal  A$ has a correspondent finite-dimensional matrix $A$ and all properties of $(1)$ can be studied through the rang of $A$. E.g. there exists a solution of $(1)$ iff $\det (A-I)=0$ for $I$ is an identity matrix of the same size as $A$. For the general state-space my first question is: 1.If there is a method similar to calculating $\det (A-I)$ to verify the existence of solution for $(1)$? If the dimension of $X$ is not necessary finite, one of the main methods is to use Banach theorem based on the contraction principle - so it is only valid if $|\lambda^*(\mathcal A)<1|$ for the maximum eigenvalue in the absolute sense. 2.What can we do if the spectrum is not bounded by $1$ but just does not contain it? There are also procedures (usually in the discrete-time setting, e.g. $X = L^2$ and $\mathcal A$ is an integral operator) connected with the iterations of operator $\mathcal A$. There are examples (if one wants, I can put it here) when for some $x\neq 0$ the limit $$x' = \lim\limits_{n\to\infty}\mathcal A^nx\quad (2)$$ exists while $\mathcal A$ is not contractive. 3.Under which conditions $\mathcal Ax' = x'$? Finally, there are some methods in the continuous time setting (e.g. $X = L^2$ again and we are talking about differential operators). If one would like to solve an equation $\mathcal Bx = 0$ then it's helpful to consider a function $f(t)$ such that $f(0) = x_0$ and  $$ \frac{df}{dt}(t) = \mathcal B f(t).\quad (3) $$ Suppose, $\lim\limits_{t\to\infty}f(t) = x'\in X$. 4.Under which conditions $\mathcal Bx' = 0$? Finally, we can put $\mathcal A = \mathcal B+\mathcal I$. Then if the conditions of 4. are satisfied, $\mathcal Ax' = x'$. 5. Why for the integral equations (""discrete-time"") people commonly use $(2)$ while for, say PDEs they use $(3)$ rather then $(2)$? So there are 5 questions, and I would appreciate if you can help me with answering at least one of them or referring me to a literature which covers these questions. I guess that 5. is can be an unclear question - so if it is, just tell, I will try to make it clear.",,"['functional-analysis', 'operator-theory', 'fixed-point-theorems']"
92,Reference for the range of possible values in Hahn-Banach Theorem,Reference for the range of possible values in Hahn-Banach Theorem,,"This is the usual formulation of Hahn-Banach theorem (some books use sublinear function instead, but it probably does not make much difference): Let $X$ be a vector space and let $p:X\to{\mathbb R}$ be any convex function. Let $M$ be a vector subspace of $X$ and let $f:M\to{\mathbb R}$ be a linear functional dominated by $p$ on $M$. Then there is a linear extension $\hat{f}$ of $f$ to $X$ that is dominated by $p$ on $X$. However if you look into the proof, you find out that it shows that for a given $v\in X$, there exists an extension with the value $\hat{f}(v)=c$ for any choice of $c$ anywhere between $$\sup_{x\in M,\lambda>0} \frac1\lambda [f(x)-p(x-\lambda{v})] \le c \le \inf_{y\in M,\mu>0} \frac1\mu [p(y+\mu{v})-f(y)].$$ If $p$ is positive homogeneous, i.e., $p(\lambda x)=\lambda p(x)$ for $\lambda>0$, than the expression for the range is simpler: $$\sup_{x\in M} [f(x)-p(x-{v})] \le c \le \inf_{y\in M} [p(y+{v})-f(y)].$$ In case the $p$ and $f$ have the additional property that $$(\forall x\in X)(\forall y\in M) p(x+y)=p(x)+f(y)$$ then the above interval can be simplified to $$-p(-v)\le c \le p(v).$$ (This situation happens quite often, take for example $f(x)=\lim x$ on the space $c$ of all convergent sequences and the function $p(x)=\limsup x$ on the space $\ell_\infty$ of all bounded sequences.) On several occasions I found the above observations useful. (Since sometimes the function $p(x)$ can be chosen in a such way that the set of linear functionals which we want to study is precisely the set of all extensions of some given functional fulfilling $\hat{f}(x)\le p(x)$. Hence this might give some additional information about an interesting set of functionals.) So I wonder why I have not find a book where Hahn-Banach theorem was not formulated with the inclusion of the information about the possible range of those extensions. Question 1 Do you know about a reference giving a formulation of Hahn-Banach theorem which includes the information about possible values of extensions? Question 2 Were the extreme points of the set of Hahn-Banach extensions studied? (By the set of Hahn-Banach extensions I mean the set of all linear functionals $\hat{f}:X\to{\mathbb R}$ fulfilling $(\forall x\in X)\hat{f}(x)\le p(x)$ and $(\forall x\in M)\hat{f}(x)=f(x)$ for a given linear functional $f:M\to{\mathbb R}$ and a convex function $p:X\to{\mathbb R}$.) EDIT: Perhaps I should mention that the formulation and the proof of Hahn-Banach theorem I followed is from Aliprantis, Border: Infinite-Dimensional Analysis . As far as I remember, all proofs of HBT I've seen have pretty much the same idea. Thus my guess is that the answer to the following question would be probably negative, but I'll ask it anyway. Question 3 Have you seen a formulation (or a proof) of Hahn-Banach theorem that would yield substantially different expression for the bounds I've given above. (I believe its more-or-less obvious from the proof that these bounds are best possible in the sense that extension of $f$ dominated by $p$ cannot have value in the point $v$ outside the given intervals. So only change that could happen would be some different expression of the same value. Alternatively, some books might contain proof of HBT which does not obtain the optimal bounds, but again, I do not see any way how this would simplify the proof, so there's probably no reason to give such a proof.)","This is the usual formulation of Hahn-Banach theorem (some books use sublinear function instead, but it probably does not make much difference): Let $X$ be a vector space and let $p:X\to{\mathbb R}$ be any convex function. Let $M$ be a vector subspace of $X$ and let $f:M\to{\mathbb R}$ be a linear functional dominated by $p$ on $M$. Then there is a linear extension $\hat{f}$ of $f$ to $X$ that is dominated by $p$ on $X$. However if you look into the proof, you find out that it shows that for a given $v\in X$, there exists an extension with the value $\hat{f}(v)=c$ for any choice of $c$ anywhere between $$\sup_{x\in M,\lambda>0} \frac1\lambda [f(x)-p(x-\lambda{v})] \le c \le \inf_{y\in M,\mu>0} \frac1\mu [p(y+\mu{v})-f(y)].$$ If $p$ is positive homogeneous, i.e., $p(\lambda x)=\lambda p(x)$ for $\lambda>0$, than the expression for the range is simpler: $$\sup_{x\in M} [f(x)-p(x-{v})] \le c \le \inf_{y\in M} [p(y+{v})-f(y)].$$ In case the $p$ and $f$ have the additional property that $$(\forall x\in X)(\forall y\in M) p(x+y)=p(x)+f(y)$$ then the above interval can be simplified to $$-p(-v)\le c \le p(v).$$ (This situation happens quite often, take for example $f(x)=\lim x$ on the space $c$ of all convergent sequences and the function $p(x)=\limsup x$ on the space $\ell_\infty$ of all bounded sequences.) On several occasions I found the above observations useful. (Since sometimes the function $p(x)$ can be chosen in a such way that the set of linear functionals which we want to study is precisely the set of all extensions of some given functional fulfilling $\hat{f}(x)\le p(x)$. Hence this might give some additional information about an interesting set of functionals.) So I wonder why I have not find a book where Hahn-Banach theorem was not formulated with the inclusion of the information about the possible range of those extensions. Question 1 Do you know about a reference giving a formulation of Hahn-Banach theorem which includes the information about possible values of extensions? Question 2 Were the extreme points of the set of Hahn-Banach extensions studied? (By the set of Hahn-Banach extensions I mean the set of all linear functionals $\hat{f}:X\to{\mathbb R}$ fulfilling $(\forall x\in X)\hat{f}(x)\le p(x)$ and $(\forall x\in M)\hat{f}(x)=f(x)$ for a given linear functional $f:M\to{\mathbb R}$ and a convex function $p:X\to{\mathbb R}$.) EDIT: Perhaps I should mention that the formulation and the proof of Hahn-Banach theorem I followed is from Aliprantis, Border: Infinite-Dimensional Analysis . As far as I remember, all proofs of HBT I've seen have pretty much the same idea. Thus my guess is that the answer to the following question would be probably negative, but I'll ask it anyway. Question 3 Have you seen a formulation (or a proof) of Hahn-Banach theorem that would yield substantially different expression for the bounds I've given above. (I believe its more-or-less obvious from the proof that these bounds are best possible in the sense that extension of $f$ dominated by $p$ cannot have value in the point $v$ outside the given intervals. So only change that could happen would be some different expression of the same value. Alternatively, some books might contain proof of HBT which does not obtain the optimal bounds, but again, I do not see any way how this would simplify the proof, so there's probably no reason to give such a proof.)",,"['functional-analysis', 'reference-request', 'hahn-banach-theorem']"
93,"Show that $SL(n, \mathbb{R})$ is a $(n^2 -1)$ smooth submanifold of $M(n,\mathbb{R})$",Show that  is a  smooth submanifold of,"SL(n, \mathbb{R}) (n^2 -1) M(n,\mathbb{R})","I need to show for $n=3$ that $SL(n,\mathbb{R})=\{A \in M(n, \mathbb{R}) : detA=1 \}$ is a $(n^2 -1)$ dimensional smooth submanifold of the vector space $M(n,\mathbb{R})$ of all real $n \times n$ matrices. I would assume that I need to use the regular value theorem and use the determinant map to get the result, but I'm a bit unsure on how to set this up correctly. Any help would be appreciated.","I need to show for $n=3$ that $SL(n,\mathbb{R})=\{A \in M(n, \mathbb{R}) : detA=1 \}$ is a $(n^2 -1)$ dimensional smooth submanifold of the vector space $M(n,\mathbb{R})$ of all real $n \times n$ matrices. I would assume that I need to use the regular value theorem and use the determinant map to get the result, but I'm a bit unsure on how to set this up correctly. Any help would be appreciated.",,"['functional-analysis', 'differential-geometry', 'manifolds', 'smooth-manifolds']"
94,Does every bounded operator on a complex Hilbert space have an eigenvalue?,Does every bounded operator on a complex Hilbert space have an eigenvalue?,,"Is the following statment true? Let $\mathscr{H}$ be a complex Hilbert space and let $\varphi: \mathscr{H} \to \mathscr{H}$ be a bounded operator. Does $\varphi$ have an eigenvalue in general? If yes, how to prove this? If not, what is a counterexample and what property does one need in order to ensure the existence of an eigenvalue. In particular, I am interested in the case where $\mathscr{H}$ has a unitary representation $\pi: G \to U(\mathscr{H})$ such that $\varphi \circ \pi(g) = \pi(g) \circ \varphi$ for all $g \in G$.","Is the following statment true? Let $\mathscr{H}$ be a complex Hilbert space and let $\varphi: \mathscr{H} \to \mathscr{H}$ be a bounded operator. Does $\varphi$ have an eigenvalue in general? If yes, how to prove this? If not, what is a counterexample and what property does one need in order to ensure the existence of an eigenvalue. In particular, I am interested in the case where $\mathscr{H}$ has a unitary representation $\pi: G \to U(\mathscr{H})$ such that $\varphi \circ \pi(g) = \pi(g) \circ \varphi$ for all $g \in G$.",,"['functional-analysis', 'eigenvalues-eigenvectors']"
95,Integrable function whose Fourier transform is not integrable,Integrable function whose Fourier transform is not integrable,,I am looking for an example of a function $f: \mathbb R \rightarrow \mathbb R$ such that $f \in L^1$ in the sense that $\int_{\mathbb R} |f| < \infty$ but its Fourier transform $\hat f$ is not in $L^1$. Does anyone have one? Thanks.,I am looking for an example of a function $f: \mathbb R \rightarrow \mathbb R$ such that $f \in L^1$ in the sense that $\int_{\mathbb R} |f| < \infty$ but its Fourier transform $\hat f$ is not in $L^1$. Does anyone have one? Thanks.,,"['measure-theory', 'functional-analysis', 'fourier-analysis']"
96,Convergence in weak topology implies convergence in norm topology,Convergence in weak topology implies convergence in norm topology,,"In Hilbert space why does convergence in weak topology $x_n$ to $x$ imply that $x_n$ converges to $x$ in norm? Thank you very much for your answers. What if I put a condition on weak convergence i.e., suppose it also holds $\lim_{n\to \infty } \lVert x_n\rVert \to \lVert x\rVert$ then can I say that $x_n$ converges in norm? I doubt if it always holds! I think to understand this I need bit more explanation because I am struggling with the understanding of weak topologies.  Thank you","In Hilbert space why does convergence in weak topology $x_n$ to $x$ imply that $x_n$ converges to $x$ in norm? Thank you very much for your answers. What if I put a condition on weak convergence i.e., suppose it also holds $\lim_{n\to \infty } \lVert x_n\rVert \to \lVert x\rVert$ then can I say that $x_n$ converges in norm? I doubt if it always holds! I think to understand this I need bit more explanation because I am struggling with the understanding of weak topologies.  Thank you",,"['functional-analysis', 'hilbert-spaces', 'weak-convergence']"
97,"$\langle Tu\;|\;u\rangle=0,\;\forall u\in E \Longrightarrow T=0$?",?,"\langle Tu\;|\;u\rangle=0,\;\forall u\in E \Longrightarrow T=0","Let $E$ be  a complex Hilbert space. Let $T\in \mathcal{L}(E)$. I have two questions: Why it is not true that for an arbitrary operator $T\in \mathcal{L}(E)$, we have $\langle Tu\;|\;u\rangle=0,\;\forall u\in E \Longrightarrow T=0$? And is  this property true for normal operators? I think it is true for self adjoint operators because the norm of a self adjoint operators is given by $$\left\|T\right\|= \sup\big\{\;\left|\langle Tu\;|\;u\rangle \right|,\;\;u \in E\;, \left\| u \right\| = 1\;\big\}$$ Thank you.","Let $E$ be  a complex Hilbert space. Let $T\in \mathcal{L}(E)$. I have two questions: Why it is not true that for an arbitrary operator $T\in \mathcal{L}(E)$, we have $\langle Tu\;|\;u\rangle=0,\;\forall u\in E \Longrightarrow T=0$? And is  this property true for normal operators? I think it is true for self adjoint operators because the norm of a self adjoint operators is given by $$\left\|T\right\|= \sup\big\{\;\left|\langle Tu\;|\;u\rangle \right|,\;\;u \in E\;, \left\| u \right\| = 1\;\big\}$$ Thank you.",,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
98,What is the $L^2$ gradient flow?,What is the  gradient flow?,L^2,"What does $L^2$ gradient flow mean? Here is the Ginzburg–Landau free energy: $$\mathcal{E}(\phi):=\int_{\Omega}(F(\phi)+\frac{\epsilon^2}{2}|\nabla\phi|^2)\text{d}\mathbf{x}$$ Some references say the Allen-Cahn equation  $$\frac{\partial \phi(\mathbf{x},t)}{\partial t} = {\epsilon^2}\Delta\phi(\mathbf{x},t)-F'(\phi(\mathbf{x},t))$$ $$\frac{\partial \phi(\mathbf{x},t)}{\partial \mathbf{n}}=0, \ \text{on} \ \partial \Omega \times [0,T]$$ is the $L^2$-gradient flow of the total free energy $\mathcal{E}(\phi)$. How to derive this?","What does $L^2$ gradient flow mean? Here is the Ginzburg–Landau free energy: $$\mathcal{E}(\phi):=\int_{\Omega}(F(\phi)+\frac{\epsilon^2}{2}|\nabla\phi|^2)\text{d}\mathbf{x}$$ Some references say the Allen-Cahn equation  $$\frac{\partial \phi(\mathbf{x},t)}{\partial t} = {\epsilon^2}\Delta\phi(\mathbf{x},t)-F'(\phi(\mathbf{x},t))$$ $$\frac{\partial \phi(\mathbf{x},t)}{\partial \mathbf{n}}=0, \ \text{on} \ \partial \Omega \times [0,T]$$ is the $L^2$-gradient flow of the total free energy $\mathcal{E}(\phi)$. How to derive this?",,"['functional-analysis', 'ordinary-differential-equations', 'partial-differential-equations']"
99,Weak convergence in reflexive Banach space,Weak convergence in reflexive Banach space,,"Let $X$ be a reflexive Banach space. Let $T: X \to Y$ a linear operator. I want to show that: $$T \in \mathcal{L}(X, Y) \iff ((x_n \stackrel{w}{\rightharpoonup} x) \implies (T(x_n) \stackrel{w}{\rightharpoonup} T(x))) $$ Any help, thoughts, hints, solutions will be greatly appreciated. I am lots of trouble regarding weak convergence.","Let $X$ be a reflexive Banach space. Let $T: X \to Y$ a linear operator. I want to show that: $$T \in \mathcal{L}(X, Y) \iff ((x_n \stackrel{w}{\rightharpoonup} x) \implies (T(x_n) \stackrel{w}{\rightharpoonup} T(x))) $$ Any help, thoughts, hints, solutions will be greatly appreciated. I am lots of trouble regarding weak convergence.",,"['analysis', 'functional-analysis']"
