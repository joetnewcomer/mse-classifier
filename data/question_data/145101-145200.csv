,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,$\lim_{n\to \infty} (1+n+\cos n) ^\frac{1}{2n+n \sin n}$,,\lim_{n\to \infty} (1+n+\cos n) ^\frac{1}{2n+n \sin n},"While in class, we were proving a limit problem using the Squeeze Theorem, but when I was reviewing my notes, I came up with a problem,, The first question was to prove that  $$\lim_{n\to \infty}(1+n)^\frac{1}{n}=1$$ Okay, this was easy. The next question was to use the limit proven above to evaluate the following limit: $$\lim_{n\to \infty}(1+n+n\cos n)^\frac{1}{2n+n\sin n}$$ In my notes, this was written; $$1\leq(1+n+n\cos n)^\frac{1}{2n+n\sin n} \leq (1+2n+n\sin n)^\frac{1}{2n+n\sin n}$$ And since $$\lim_{n\to \infty}(1+2n+n\sin n)^\frac{1}{2n+n\sin n}=1$$ Therefore by Squeeze Theorem,  $$\lim_{n\to \infty}(1+n+n\cos n)^\frac{1}{2n+n\sin n}=1$$ My question is that the inequality doesn't seem to make sense. Is the inequality correct? Does it only hold for very large $n$ or something? Then how would I evaluate this limit by using the first limit equation?","While in class, we were proving a limit problem using the Squeeze Theorem, but when I was reviewing my notes, I came up with a problem,, The first question was to prove that  $$\lim_{n\to \infty}(1+n)^\frac{1}{n}=1$$ Okay, this was easy. The next question was to use the limit proven above to evaluate the following limit: $$\lim_{n\to \infty}(1+n+n\cos n)^\frac{1}{2n+n\sin n}$$ In my notes, this was written; $$1\leq(1+n+n\cos n)^\frac{1}{2n+n\sin n} \leq (1+2n+n\sin n)^\frac{1}{2n+n\sin n}$$ And since $$\lim_{n\to \infty}(1+2n+n\sin n)^\frac{1}{2n+n\sin n}=1$$ Therefore by Squeeze Theorem,  $$\lim_{n\to \infty}(1+n+n\cos n)^\frac{1}{2n+n\sin n}=1$$ My question is that the inequality doesn't seem to make sense. Is the inequality correct? Does it only hold for very large $n$ or something? Then how would I evaluate this limit by using the first limit equation?",,"['real-analysis', 'limits', 'trigonometry', 'exponential-function']"
1,How to figure $\displaystyle\sum_{n=1}^{\infty}\sin\frac{1}{n^2}$?,How to figure ?,\displaystyle\sum_{n=1}^{\infty}\sin\frac{1}{n^2},$\displaystyle\sum_{n=1}^{\infty}\sin\frac{1}{n^2}=?$ Does it have a precise expression?,$\displaystyle\sum_{n=1}^{\infty}\sin\frac{1}{n^2}=?$ Does it have a precise expression?,,"['sequences-and-series', 'limits']"
2,"Shouldn't l'Hopital's rule work for every limit, not just indeterminate forms?","Shouldn't l'Hopital's rule work for every limit, not just indeterminate forms?",,"Why does taking the ratio of $f'(x)$ to $g'(x)$ as $x \to a$ give you the correct limit when $f(a)$ and $g(a)$ $= 0, \infty, -\infty$  , but not for other values of $a$? If the rationale for using LHR is that the tangent is the linear approximation of the curve at a point, shouldn't the rule work for all values of $a$?","Why does taking the ratio of $f'(x)$ to $g'(x)$ as $x \to a$ give you the correct limit when $f(a)$ and $g(a)$ $= 0, \infty, -\infty$  , but not for other values of $a$? If the rationale for using LHR is that the tangent is the linear approximation of the curve at a point, shouldn't the rule work for all values of $a$?",,"['calculus', 'limits', 'derivatives']"
3,"If $f(x)=\lim_{n\to\infty}[2x+4x^3+\cdots+2nx^{2n-1}]$, $0<x<1$, then find $\int f(x)\mathrm{d}x$","If , , then find",f(x)=\lim_{n\to\infty}[2x+4x^3+\cdots+2nx^{2n-1}] 0<x<1 \int f(x)\mathrm{d}x,"If $f(x)=\lim_{n\to\infty}[2x+4x^3+\cdots+2nx^{2n-1}]$, $0<x<1$, then find $\int f(x)\mathrm{d}x$ $$f(x)=\lim_{n\to\infty}2x[1+2x^2+\cdots+nx^{2n}]$$ $$S=\frac{f(x)}{2x}=1+2x^2+\cdots+nx^{2n}$$ $S$ is an AGP. I used the general method for finding $S$. $$x^2S=x^2+2x^4+\cdots+nx^{2n+2}$$ $$(1-x^2)S=1+(x^2+x^4+\cdots+x^{2n})+nx^{2n+2}$$ $$(1-x^2)S=\frac{1-x^{2n+1}}{1-x^2}+nx^{2n+2}$$ $$S=\frac{1-x^{2n+1}}{(1-x^2)^2}+\frac{nx^{2n+2}}{1-x^2}$$ $$f(x)=\lim_{n\to\infty}\left(2x\frac{1-x^{2n+1}}{(1-x^2)^2}+2x\frac{nx^{2n+2}}{1-x^2}\right)$$ I got stuck here.","If $f(x)=\lim_{n\to\infty}[2x+4x^3+\cdots+2nx^{2n-1}]$, $0<x<1$, then find $\int f(x)\mathrm{d}x$ $$f(x)=\lim_{n\to\infty}2x[1+2x^2+\cdots+nx^{2n}]$$ $$S=\frac{f(x)}{2x}=1+2x^2+\cdots+nx^{2n}$$ $S$ is an AGP. I used the general method for finding $S$. $$x^2S=x^2+2x^4+\cdots+nx^{2n+2}$$ $$(1-x^2)S=1+(x^2+x^4+\cdots+x^{2n})+nx^{2n+2}$$ $$(1-x^2)S=\frac{1-x^{2n+1}}{1-x^2}+nx^{2n+2}$$ $$S=\frac{1-x^{2n+1}}{(1-x^2)^2}+\frac{nx^{2n+2}}{1-x^2}$$ $$f(x)=\lim_{n\to\infty}\left(2x\frac{1-x^{2n+1}}{(1-x^2)^2}+2x\frac{nx^{2n+2}}{1-x^2}\right)$$ I got stuck here.",,"['calculus', 'integration', 'sequences-and-series', 'limits']"
4,$\lim_{x \to 2} \frac{x^{2n}-4^n}{x^2-3x+2}$,,\lim_{x \to 2} \frac{x^{2n}-4^n}{x^2-3x+2},Calculate the limit $$\lim_{x \to 2} \frac{x^{2n}-4^n}{x^2-3x+2}$$ I tried to use  $$\lim_{x \to 2} \frac{(x^2)^n-4^n}{x^2-3x+2}$$ but i can't find anything special,Calculate the limit $$\lim_{x \to 2} \frac{x^{2n}-4^n}{x^2-3x+2}$$ I tried to use  $$\lim_{x \to 2} \frac{(x^2)^n-4^n}{x^2-3x+2}$$ but i can't find anything special,,['limits']
5,Prove that $f$ has a minimum,Prove that  has a minimum,f,"Let $f$ be a positive and continuous function in $[0,\infty)$ , such that $\lim\limits_{x\to \infty} f(x)=2$ . Prove that if $f(0)<2$ , $f$ has  a minimum in $[0,\infty)$ . I am stuck in the final step, in my opinion. From the limit's definition, there is $M \in \Bbb R$ such that for every $x>M$ , $|f(x)-2| < \varepsilon$ In the closed interval, $[0,M]$ , the function has a minimum, according to Weierstrass theorem. I have to prove that it is the global minimum. It won't be a global minimum if there is some $x_0>M$ which is a minimum. I think that's where I have to reach a contradiction which I can't formalize. Thanks for you help.","Let be a positive and continuous function in , such that . Prove that if , has  a minimum in . I am stuck in the final step, in my opinion. From the limit's definition, there is such that for every , In the closed interval, , the function has a minimum, according to Weierstrass theorem. I have to prove that it is the global minimum. It won't be a global minimum if there is some which is a minimum. I think that's where I have to reach a contradiction which I can't formalize. Thanks for you help.","f [0,\infty) \lim\limits_{x\to \infty} f(x)=2 f(0)<2 f [0,\infty) M \in \Bbb R x>M |f(x)-2| < \varepsilon [0,M] x_0>M","['calculus', 'real-analysis', 'limits', 'continuity']"
6,Evaluating the following limit: $\lim _{x\to \frac{\pi }{4}}\left(\tan\left(2x\right)\tan\left(\frac{\pi }{4}-x\right)\right)$,Evaluating the following limit:,\lim _{x\to \frac{\pi }{4}}\left(\tan\left(2x\right)\tan\left(\frac{\pi }{4}-x\right)\right),I don't find the right identities for this $$\lim _{x\to \frac{\pi }{4}}\left(\tan\left(2x\right)\tan\left(\frac{\pi }{4}-x\right)\right)$$ Someone can help me ? Thanks.,I don't find the right identities for this $$\lim _{x\to \frac{\pi }{4}}\left(\tan\left(2x\right)\tan\left(\frac{\pi }{4}-x\right)\right)$$ Someone can help me ? Thanks.,,"['limits', 'trigonometry']"
7,"I need to find $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}$",I need to find,"\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}","I need to find $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}$. My attempt: $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}=\lim_{h \to 0, h\ne 0}\exp(\frac{\log(\frac{2^h+3^h}{2})}{h})=\exp(\lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})}{h})$ $\lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})}{h}= \lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})-\log(\frac{2^0+3^0}{2})}{h-0}=(\log(\frac{2^h+3^h}{2}))'(0)=\frac{1}{2^0+3^0}0(2^{(0-1)}+3^{(0-1)})=0$ So $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}=\exp(0)=1$ Was my solution correct? I am asking because I tried to check numerically with Matlab and have not noticed the convergence to $1$.","I need to find $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}$. My attempt: $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}=\lim_{h \to 0, h\ne 0}\exp(\frac{\log(\frac{2^h+3^h}{2})}{h})=\exp(\lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})}{h})$ $\lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})}{h}= \lim_{h \to 0, h\ne 0}\frac{\log(\frac{2^h+3^h}{2})-\log(\frac{2^0+3^0}{2})}{h-0}=(\log(\frac{2^h+3^h}{2}))'(0)=\frac{1}{2^0+3^0}0(2^{(0-1)}+3^{(0-1)})=0$ So $\lim_{h \to 0, h\ne 0} \sqrt[h]{\frac{3^h+2^h}{2}}=\exp(0)=1$ Was my solution correct? I am asking because I tried to check numerically with Matlab and have not noticed the convergence to $1$.",,['limits']
8,Does $f$ have a limit if $\lim_{x\to\infty}f'(x)=0$?,Does  have a limit if ?,f \lim_{x\to\infty}f'(x)=0,"Let $f:\mathbb{R}\to\mathbb{R}$ be a bounded function such that $\lim_{x\to\infty}f'(x)=0$. Is it true that $\lim_{x\to\infty}f(x)$ exists? I think it's true since I fail to see a counter example, but I don't see how to use the boundedness in order to exclude functions like the logarithm. How to tackle it?","Let $f:\mathbb{R}\to\mathbb{R}$ be a bounded function such that $\lim_{x\to\infty}f'(x)=0$. Is it true that $\lim_{x\to\infty}f(x)$ exists? I think it's true since I fail to see a counter example, but I don't see how to use the boundedness in order to exclude functions like the logarithm. How to tackle it?",,"['calculus', 'real-analysis', 'limits']"
9,Why is $\lim_{x \to \infty}\left( \frac{x-1}{e^{1/x}} - x \right) = -2$?,Why is ?,\lim_{x \to \infty}\left( \frac{x-1}{e^{1/x}} - x \right) = -2,"Please, I need the method of doing the following limit: $$  \lim_{x \to \infty}\left( \frac{x-1}{e^{1/x}} - x \right) = -2. $$","Please, I need the method of doing the following limit: $$  \lim_{x \to \infty}\left( \frac{x-1}{e^{1/x}} - x \right) = -2. $$",,"['calculus', 'limits']"
10,How to compute $\lim\limits_{x \to +\infty} \left(\frac{\left((x-1)^2-x\ln(x)\right)(x)!}{(x+2)!+7^x}\right)$? [closed],How to compute ? [closed],\lim\limits_{x \to +\infty} \left(\frac{\left((x-1)^2-x\ln(x)\right)(x)!}{(x+2)!+7^x}\right),"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I have a problem with this limit, I don't know what method to use. I have no idea how to compute it. Can you explain the method and the steps used? $$\lim\limits_{x \to +\infty} \left(\frac{\left((x-1)^2-x\ln(x)\right)(x)!}{(x+2)!+7^x}\right)$$","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 5 years ago . Improve this question I have a problem with this limit, I don't know what method to use. I have no idea how to compute it. Can you explain the method and the steps used? $$\lim\limits_{x \to +\infty} \left(\frac{\left((x-1)^2-x\ln(x)\right)(x)!}{(x+2)!+7^x}\right)$$",,"['limits', 'factorial']"
11,Evaluating $\lim_{x\rightarrow 0}\frac{1-\cos (\sin ^5(x))}{(e^{x^4}-1)(\sin(x^2)-x^2)}$,Evaluating,\lim_{x\rightarrow 0}\frac{1-\cos (\sin ^5(x))}{(e^{x^4}-1)(\sin(x^2)-x^2)},"How do I evaluate the limit $\lim_{x\rightarrow 0}\frac{1-\cos (\sin ^5(x))}{(e^{x^4}-1)(\sin(x^2)-x^2)}$? The only method I know to deal with these kinds of limits is L'hopital, but it doesn't seem to help here at all..","How do I evaluate the limit $\lim_{x\rightarrow 0}\frac{1-\cos (\sin ^5(x))}{(e^{x^4}-1)(\sin(x^2)-x^2)}$? The only method I know to deal with these kinds of limits is L'hopital, but it doesn't seem to help here at all..",,"['calculus', 'limits', 'limits-without-lhopital']"
12,Justifying the result of $\lim_{x\to\infty} \tfrac{3^x}{4^x}$,Justifying the result of,\lim_{x\to\infty} \tfrac{3^x}{4^x},"I am working with the next limit: $$\lim_{x\to\infty} \frac{3^x}{4^x}$$ I intuitively know that since $$3^x< 4^x$$ when $x$ tends to infinite, the result of the limit is: $$\lim_{x\to\infty} \frac{3^x}{4^x}=0$$ However, I need a some more mathematical justification rather than the intuitive justification, I would appreciate any help or hint to justify this result, the l'Hospital's rule doesn't work for this limit, since if I apply the rule, the limit remains similar.","I am working with the next limit: $$\lim_{x\to\infty} \frac{3^x}{4^x}$$ I intuitively know that since $$3^x< 4^x$$ when $x$ tends to infinite, the result of the limit is: $$\lim_{x\to\infty} \frac{3^x}{4^x}=0$$ However, I need a some more mathematical justification rather than the intuitive justification, I would appreciate any help or hint to justify this result, the l'Hospital's rule doesn't work for this limit, since if I apply the rule, the limit remains similar.",,['limits']
13,Evaluate the limit $\mathop {\lim }\limits_{n \to \infty } \frac{{(n + 1){{\log }^2}(n + 1) - n{{\log }^2}n}}{{{{\log }^2}n}}$,Evaluate the limit,\mathop {\lim }\limits_{n \to \infty } \frac{{(n + 1){{\log }^2}(n + 1) - n{{\log }^2}n}}{{{{\log }^2}n}},"Evaluate: $$\mathop {\lim }\limits_{n \to \infty } \frac{{(n + 1){{\log }^2}(n + 1) - n{{\log }^2}n}}{{{{\log }^2}n}}$$ Intuitively, I feel that for large $n$, ${\log}(n+1) \approx \ {\log}(n)  $. So, the above limit should reduce to: $$=\mathop {\lim }\limits_{n \to \infty } \frac{{\{ (n + 1) - n\} {{\log }^2}n}}{{{{\log }^2}n}} \ = 1$$ However, can someone please suggest how can one mathematically show this. Thanks!","Evaluate: $$\mathop {\lim }\limits_{n \to \infty } \frac{{(n + 1){{\log }^2}(n + 1) - n{{\log }^2}n}}{{{{\log }^2}n}}$$ Intuitively, I feel that for large $n$, ${\log}(n+1) \approx \ {\log}(n)  $. So, the above limit should reduce to: $$=\mathop {\lim }\limits_{n \to \infty } \frac{{\{ (n + 1) - n\} {{\log }^2}n}}{{{{\log }^2}n}} \ = 1$$ However, can someone please suggest how can one mathematically show this. Thanks!",,['limits']
14,Prove that: $\lim\limits_{n \to \infty} b_n = \lim\limits_{n \to \infty} a_n$.,Prove that: .,\lim\limits_{n \to \infty} b_n = \lim\limits_{n \to \infty} a_n,"It's given that $a_n$ and $b_n$ two convergent sequences. prove that if for each $even$ $n$: $a_n \le b_n$ and for each $odd$ $n:$ $b_n  \le a_n$ then $\lim\limits_{n \to \infty} b_n = \lim\limits_{n \to \infty} a_n$. SOLUTION: I tried to use the definition of limit. that for each $\epsilon>0$ there is such $N_1$ s.t. for each $n>N_1$: $L-\epsilon \lt a_n < L+\epsilon$ and  for each $\epsilon>0$ there is such $N_2$ s.t. for each $n>N_2$: $K-\epsilon \lt b_n < K+\epsilon$ and I thought about the idea that Odd and Even numbers together cover all the numbers. and I treid to prove by contradiction, that $L \neq K$ and try to reach a place where K must be euqal to L. but didn't quite know how to do it. any kind of help would be appreciated.","It's given that $a_n$ and $b_n$ two convergent sequences. prove that if for each $even$ $n$: $a_n \le b_n$ and for each $odd$ $n:$ $b_n  \le a_n$ then $\lim\limits_{n \to \infty} b_n = \lim\limits_{n \to \infty} a_n$. SOLUTION: I tried to use the definition of limit. that for each $\epsilon>0$ there is such $N_1$ s.t. for each $n>N_1$: $L-\epsilon \lt a_n < L+\epsilon$ and  for each $\epsilon>0$ there is such $N_2$ s.t. for each $n>N_2$: $K-\epsilon \lt b_n < K+\epsilon$ and I thought about the idea that Odd and Even numbers together cover all the numbers. and I treid to prove by contradiction, that $L \neq K$ and try to reach a place where K must be euqal to L. but didn't quite know how to do it. any kind of help would be appreciated.",,"['calculus', 'sequences-and-series', 'limits']"
15,Faults in epsilon-delta proof?,Faults in epsilon-delta proof?,,"Above is the textbook proof that $\lim\limits_{x\to 3}\frac 1x=\frac 13$. I'm not sure if this is completely correct or not since I noticed that some of the implied inequalities doesn't hold $\forall~\epsilon\gt 0$. Take, for example, the inequality in the 4th line of the image : $$\frac 3{1+3\epsilon}\lt x\lt \frac 3{1-3\epsilon}$$ that is implied by the 3rd line. That inequality doesn't hold, for say $\epsilon=2\gt 0$, i.e., there is no real $x$ for when $\epsilon=2$ that satisfies that inequality. Also, I wonder why they took the $\min$ of $\delta_1$ and $\delta_2$ to be the $\delta$ since I think we should take the $\max$. This is because $-a\lt x\lt b\implies |x|\lt \max(a,b)~\forall~a,b\in\Bbb R$. I'm pretty much a beginner at rigorous stuff like this, so I might be completely wrong in my thinking. I look forward to helpful responses from the community. Thanks.","Above is the textbook proof that $\lim\limits_{x\to 3}\frac 1x=\frac 13$. I'm not sure if this is completely correct or not since I noticed that some of the implied inequalities doesn't hold $\forall~\epsilon\gt 0$. Take, for example, the inequality in the 4th line of the image : $$\frac 3{1+3\epsilon}\lt x\lt \frac 3{1-3\epsilon}$$ that is implied by the 3rd line. That inequality doesn't hold, for say $\epsilon=2\gt 0$, i.e., there is no real $x$ for when $\epsilon=2$ that satisfies that inequality. Also, I wonder why they took the $\min$ of $\delta_1$ and $\delta_2$ to be the $\delta$ since I think we should take the $\max$. This is because $-a\lt x\lt b\implies |x|\lt \max(a,b)~\forall~a,b\in\Bbb R$. I'm pretty much a beginner at rigorous stuff like this, so I might be completely wrong in my thinking. I look forward to helpful responses from the community. Thanks.",,"['real-analysis', 'limits', 'epsilon-delta']"
16,Integral of a function with different value for different intervals,Integral of a function with different value for different intervals,,"I have a function $$ f(x) = \begin{cases} x & \text{if } 0 \leq x \leq \pi \\ 0 & \text{if } \pi < x \leq 2\pi \end{cases} $$ I have to solve $$ \int_0^\pi f(x) \sin(nx) \, \mathrm{d}x $$ How do I do that? Since $f(x) = x$ for $0 \leq x \leq \pi$ and my integral limits are $a=0$ and $b=\pi$, can I just substitute $f(x) = x$ into the integral or do I have to look at the integral for both intervals? Does it makes sense to look at the limits from $a=0$ to $b=\pi$ if the function, for instance, is only defined outside these limits?","I have a function $$ f(x) = \begin{cases} x & \text{if } 0 \leq x \leq \pi \\ 0 & \text{if } \pi < x \leq 2\pi \end{cases} $$ I have to solve $$ \int_0^\pi f(x) \sin(nx) \, \mathrm{d}x $$ How do I do that? Since $f(x) = x$ for $0 \leq x \leq \pi$ and my integral limits are $a=0$ and $b=\pi$, can I just substitute $f(x) = x$ into the integral or do I have to look at the integral for both intervals? Does it makes sense to look at the limits from $a=0$ to $b=\pi$ if the function, for instance, is only defined outside these limits?",,"['integration', 'limits', 'definite-integrals']"
17,How to evaluate the definite integral by the limit definition $\int_{-1}^1 x^3 dx$?,How to evaluate the definite integral by the limit definition ?,\int_{-1}^1 x^3 dx,"Solve the definite integral by the limit definition: $$\int_{-1}^1 x^3 dx$$ The formula: $$\int_a^bf(x)dx= \lim_{n\rightarrow \infty} \sum_{i=1}^n f(c_i)\Delta x_i$$ Get the variables: $$\Delta x_i : \frac{b-a}{n} = \frac{1-(-1)}{n} = \frac{2}{n}$$ $$f(c_i) : a + i(\Delta x_i) = \left(-1+\frac{2i}{n}\right)$$ Now plug them into the formula I get: $$\lim_{n\rightarrow \infty} \sum_{i=1}^n \left(-1+\frac{2i}{n}\right)^3\left(\frac{2}{n}\right)$$ Take out the delta and distribute the cube: $$\lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \sum_{i=1}^n \left(-1+\frac{2i}{n}\right)^3 = \lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \sum_{i=1}^n \left(-1+\frac{8i^3}{n^3}\right) $$ Expand the summation and take out constants, and properties of Simga: $$\lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \left[- \sum_{i=1}^n 1+ \frac{8}{n^3} \sum_{i=1}^n i^3\right] = \lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \left[-n + \frac{8}{n^3}\left( \frac{n^2(n+1)^2}{4}\right)\right]$$ Distribute the $\frac{2}{n}$ and simplify: $$\lim_{n\rightarrow \infty}\left[-2 + \frac{16}{n^4}\left( \frac{n^2(n+1)^2}{4}\right)\right] = \lim_{n\rightarrow \infty}\left[-2 + \frac{4}{n^2}\left( \frac{n^2+2n+1}{1}\right)\right]$$ Distribute and simplify/cancel: $$\lim_{n\rightarrow \infty}\left[-2 + \frac{4n^2}{n^2} + \frac{8n}{n^2} + \frac{4}{n^4}\right] = \lim_{n\rightarrow \infty}\left[-2 + 4 + \frac{8}{n} + \frac{4}{n^4}\right] $$ I keep getting the limit is -2 (-2+4), but the book says it's 0. Where did I go wrong?","Solve the definite integral by the limit definition: $$\int_{-1}^1 x^3 dx$$ The formula: $$\int_a^bf(x)dx= \lim_{n\rightarrow \infty} \sum_{i=1}^n f(c_i)\Delta x_i$$ Get the variables: $$\Delta x_i : \frac{b-a}{n} = \frac{1-(-1)}{n} = \frac{2}{n}$$ $$f(c_i) : a + i(\Delta x_i) = \left(-1+\frac{2i}{n}\right)$$ Now plug them into the formula I get: $$\lim_{n\rightarrow \infty} \sum_{i=1}^n \left(-1+\frac{2i}{n}\right)^3\left(\frac{2}{n}\right)$$ Take out the delta and distribute the cube: $$\lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \sum_{i=1}^n \left(-1+\frac{2i}{n}\right)^3 = \lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \sum_{i=1}^n \left(-1+\frac{8i^3}{n^3}\right) $$ Expand the summation and take out constants, and properties of Simga: $$\lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \left[- \sum_{i=1}^n 1+ \frac{8}{n^3} \sum_{i=1}^n i^3\right] = \lim_{n\rightarrow \infty} \left(\frac{2}{n}\right) \left[-n + \frac{8}{n^3}\left( \frac{n^2(n+1)^2}{4}\right)\right]$$ Distribute the $\frac{2}{n}$ and simplify: $$\lim_{n\rightarrow \infty}\left[-2 + \frac{16}{n^4}\left( \frac{n^2(n+1)^2}{4}\right)\right] = \lim_{n\rightarrow \infty}\left[-2 + \frac{4}{n^2}\left( \frac{n^2+2n+1}{1}\right)\right]$$ Distribute and simplify/cancel: $$\lim_{n\rightarrow \infty}\left[-2 + \frac{4n^2}{n^2} + \frac{8n}{n^2} + \frac{4}{n^4}\right] = \lim_{n\rightarrow \infty}\left[-2 + 4 + \frac{8}{n} + \frac{4}{n^4}\right] $$ I keep getting the limit is -2 (-2+4), but the book says it's 0. Where did I go wrong?",,"['calculus', 'integration', 'limits', 'definite-integrals']"
18,"If $\lim_{x\rightarrow\infty}f(f(x))=\infty$, $f:(-\infty,\infty)\rightarrow\mathbb{R}$ is continuous, prove $\lim_{x\rightarrow\infty}|f(x)|=\infty$","If ,  is continuous, prove","\lim_{x\rightarrow\infty}f(f(x))=\infty f:(-\infty,\infty)\rightarrow\mathbb{R} \lim_{x\rightarrow\infty}|f(x)|=\infty","I'm working on another homework problem that I could use some help with. The question is posed in the title, and given here (exactly): Problem: Let $f:(-\infty,+\infty)\rightarrow\mathbb{R}$ be continuous and the $\!\!\lim\limits_{x\rightarrow+\infty}\!\!f(f(x))=+\infty$. Prove that $\!\!\lim\limits_{x\rightarrow+\infty}\!\!|f(x)|=+\infty$. It is a former, prelim problem from earlier in the year, and that was why I was requesting help - please note, I'm finishing up an honors, undergraduate degree in Mathematics, so this is a regular homework problem. As we speak, I'm trying to prove this by contradiction. If I'm correct, we have $\exists\varepsilon>0:\forall M\in\mathbb{N},\exists x\in(-\infty,+\infty):x>M~\text{and}~|f(x)|>\varepsilon$ negating the sufficient part, or we can suppose that $\lim\limits_{x\rightarrow\infty}|f(x)|\neq +\infty$ so that $\lim\limits_{x\rightarrow\infty}|f(x)|=L$. I've been working with both, going back and forth, using the precise definitions overall in order to get a contradiction against one of the two given assumptions using the other.  I'm not sure if this is the way to go, and any help is GREATLY appreciated!","I'm working on another homework problem that I could use some help with. The question is posed in the title, and given here (exactly): Problem: Let $f:(-\infty,+\infty)\rightarrow\mathbb{R}$ be continuous and the $\!\!\lim\limits_{x\rightarrow+\infty}\!\!f(f(x))=+\infty$. Prove that $\!\!\lim\limits_{x\rightarrow+\infty}\!\!|f(x)|=+\infty$. It is a former, prelim problem from earlier in the year, and that was why I was requesting help - please note, I'm finishing up an honors, undergraduate degree in Mathematics, so this is a regular homework problem. As we speak, I'm trying to prove this by contradiction. If I'm correct, we have $\exists\varepsilon>0:\forall M\in\mathbb{N},\exists x\in(-\infty,+\infty):x>M~\text{and}~|f(x)|>\varepsilon$ negating the sufficient part, or we can suppose that $\lim\limits_{x\rightarrow\infty}|f(x)|\neq +\infty$ so that $\lim\limits_{x\rightarrow\infty}|f(x)|=L$. I've been working with both, going back and forth, using the precise definitions overall in order to get a contradiction against one of the two given assumptions using the other.  I'm not sure if this is the way to go, and any help is GREATLY appreciated!",,"['real-analysis', 'limits', 'metric-spaces', 'continuity', 'epsilon-delta']"
19,How Does the ($\sqrt{x^2+x}+x)$ Equal $(\sqrt{x^2}+x)$ When Calculating The Limit of Infinity?,How Does the ( Equal  When Calculating The Limit of Infinity?,\sqrt{x^2+x}+x) (\sqrt{x^2}+x),"I am asking this because of the following question: What is the Limit of positive infinity for the equation $\frac{1}{\sqrt{x^2+x}+x}$? The following steps are done to get the answer, which is 2. I am not sure how the 3rd step went from having a numerator of $\sqrt{x^2+x}+x$ to having a numerator of $\sqrt{x^2}+x$. It's as if the $\sqrt{x}$ just disappeared. Can anyone explain why this happens? All help is appreciated.","I am asking this because of the following question: What is the Limit of positive infinity for the equation $\frac{1}{\sqrt{x^2+x}+x}$? The following steps are done to get the answer, which is 2. I am not sure how the 3rd step went from having a numerator of $\sqrt{x^2+x}+x$ to having a numerator of $\sqrt{x^2}+x$. It's as if the $\sqrt{x}$ just disappeared. Can anyone explain why this happens? All help is appreciated.",,"['calculus', 'limits', 'infinity']"
20,Impossibility of bisecting a line.,Impossibility of bisecting a line.,,"There is a line of $10$ units length.I am marking a point on the line What is the probability that the point is exactly on the middle of the line ? Can we apply classical probability here : $P(A)=\frac{n(A)}{n(S)}$ where $A$ is the event and $S$ is the sample space .Then it will give the answer $\frac{1}{\infty}$. Instead of this approach I use another method.On the line I marked $10$ points including middle point.Selecting middle point from these $10$ points will be $0.1$. If we increase the points to $100$ the probability reduces to $0.01$. As the number of points increases probability tends to zero. Now can we say that probability is zero ? If so, using language of probability bisecting line becomes an impossible event. Does the problem lies in classical approach ?","There is a line of $10$ units length.I am marking a point on the line What is the probability that the point is exactly on the middle of the line ? Can we apply classical probability here : $P(A)=\frac{n(A)}{n(S)}$ where $A$ is the event and $S$ is the sample space .Then it will give the answer $\frac{1}{\infty}$. Instead of this approach I use another method.On the line I marked $10$ points including middle point.Selecting middle point from these $10$ points will be $0.1$. If we increase the points to $100$ the probability reduces to $0.01$. As the number of points increases probability tends to zero. Now can we say that probability is zero ? If so, using language of probability bisecting line becomes an impossible event. Does the problem lies in classical approach ?",,"['probability', 'limits']"
21,How to evaluate the limit of $\frac {2\cos({x-1})-2}{({x²}-2\sqrt{x}+1 )}$ when $x\to1$ without using L'Hospital's rule?,How to evaluate the limit of  when  without using L'Hospital's rule?,\frac {2\cos({x-1})-2}{({x²}-2\sqrt{x}+1 )} x\to1,How do I evaluate this without using L'Hospital's rule:$$\lim_{x \to 1}\frac {2\cos({x-1})-2}{({x²}-2\sqrt{x}+1 )}\ ?$$ Note : I used L'Hospital's Rule I find $\frac{-4}{3}$ but in wolfram alpha is $0$,How do I evaluate this without using L'Hospital's rule:$$\lim_{x \to 1}\frac {2\cos({x-1})-2}{({x²}-2\sqrt{x}+1 )}\ ?$$ Note : I used L'Hospital's Rule I find $\frac{-4}{3}$ but in wolfram alpha is $0$,,"['real-analysis', 'limits', 'functions', 'limits-without-lhopital']"
22,Estimating numerically $\lim \limits _{x \to 0} \frac {\sin 4x} x$,Estimating numerically,\lim \limits _{x \to 0} \frac {\sin 4x} x,"As the title says, I am looking for ways to estimate numerically $\lim \limits _{x \to 0} \frac {\sin 4x} x$. So far, I've tried filling in numbers on either end of zero to make an estimate, and keep getting answers around $.0697$ or $.0698$, but the homework website I am on is marking me wrong. Am I solving this the wrong way? Does anyone know how else I should go about this? Please let me know.","As the title says, I am looking for ways to estimate numerically $\lim \limits _{x \to 0} \frac {\sin 4x} x$. So far, I've tried filling in numbers on either end of zero to make an estimate, and keep getting answers around $.0697$ or $.0698$, but the homework website I am on is marking me wrong. Am I solving this the wrong way? Does anyone know how else I should go about this? Please let me know.",,"['calculus', 'limits', 'approximation']"
23,Limit of a trigonometric rational expression,Limit of a trigonometric rational expression,,"How to evaluate the limit of this expression? $$\lim_{x\to\infty} \frac{\sin^2\left( \sqrt{x+1}-\sqrt{x}\right)}{1-\cos^2\frac{1}{x}}$$ I managed to simplify the denominator into a sinus form by the Pythagorean formula, and also modified the argument of the sinus in the numerator by dividing with a conjugate which I think is necessary, into this final form: $$\lim_{x\to\infty} \frac{\sin^2\left(\frac{1}{\sqrt{x+1}+\sqrt{x}}\right)}{\sin^2\frac{1}{x}}$$ And that's where I got stuck. So far I've tried to come up with some solution to eliminate the sinus from the denominator, without success. I'm sure the solution is pretty obvious but I don't quite know how to modify the trigonometric functions in this fashion, so any help would be most appreciated.","How to evaluate the limit of this expression? $$\lim_{x\to\infty} \frac{\sin^2\left( \sqrt{x+1}-\sqrt{x}\right)}{1-\cos^2\frac{1}{x}}$$ I managed to simplify the denominator into a sinus form by the Pythagorean formula, and also modified the argument of the sinus in the numerator by dividing with a conjugate which I think is necessary, into this final form: $$\lim_{x\to\infty} \frac{\sin^2\left(\frac{1}{\sqrt{x+1}+\sqrt{x}}\right)}{\sin^2\frac{1}{x}}$$ And that's where I got stuck. So far I've tried to come up with some solution to eliminate the sinus from the denominator, without success. I'm sure the solution is pretty obvious but I don't quite know how to modify the trigonometric functions in this fashion, so any help would be most appreciated.",,"['limits', 'trigonometry', 'infinity']"
24,prove if f(x) has an infinite limit then limit of 1/f(x) is = 0,prove if f(x) has an infinite limit then limit of 1/f(x) is = 0,,"I wanted to ask if someone can do me the favor pointing out the mistakes I might of made in proving the theorem below. Also is there a way to prove the theorem without using the definition of limits? Theorem: If $\lim_{x\to c}$f(x) =$\infty$ then $\lim_{x\to c} \frac{1}{f(x)}$ = $0$ Proof: Rewriting the above statement using the definition of limits and definition of infinite limits: ($ 0<|x-c|<\delta \Rightarrow f(x)>M)$ $\Longrightarrow (0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $) where $\epsilon$ and $M$ are both greater than zero and M denotes any real number. Taking the second conditional statement:      ($0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $) we can see that (i) $$-\epsilon <\frac{1}{f(x)} <\epsilon$$ Taking the first conditional statement:  $ 0<|x-c|<\delta \Rightarrow f(x)>M$, we can conclude using the reciprocal of inequalities that $f(x)>M>0$ is equivalent to (ii)$$0<\frac{1}{f(x)}<\frac{1}{M}$$ From (i) and (ii) we get$$0<\frac{1}{f(x)}<\frac{1}{M}<\epsilon.$$ Meaning for any chosen value of $\epsilon>0$ and $M>0$ we can rewrite the theorem as  ($ 0<|x-c|<\delta \Rightarrow \frac{1}{f(x)}<\frac{1}{M}<\epsilon )$ $\Longrightarrow (0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $) which shows that for any $\epsilon$ there exists a$\frac{1}{f(x)}$  that is always lower than $\frac{1}{M}$.","I wanted to ask if someone can do me the favor pointing out the mistakes I might of made in proving the theorem below. Also is there a way to prove the theorem without using the definition of limits? Theorem: If $\lim_{x\to c}$f(x) =$\infty$ then $\lim_{x\to c} \frac{1}{f(x)}$ = $0$ Proof: Rewriting the above statement using the definition of limits and definition of infinite limits: ($ 0<|x-c|<\delta \Rightarrow f(x)>M)$ $\Longrightarrow (0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $) where $\epsilon$ and $M$ are both greater than zero and M denotes any real number. Taking the second conditional statement:      ($0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $) we can see that (i) $$-\epsilon <\frac{1}{f(x)} <\epsilon$$ Taking the first conditional statement:  $ 0<|x-c|<\delta \Rightarrow f(x)>M$, we can conclude using the reciprocal of inequalities that $f(x)>M>0$ is equivalent to (ii)$$0<\frac{1}{f(x)}<\frac{1}{M}$$ From (i) and (ii) we get$$0<\frac{1}{f(x)}<\frac{1}{M}<\epsilon.$$ Meaning for any chosen value of $\epsilon>0$ and $M>0$ we can rewrite the theorem as  ($ 0<|x-c|<\delta \Rightarrow \frac{1}{f(x)}<\frac{1}{M}<\epsilon )$ $\Longrightarrow (0<|x-c|<\delta \Rightarrow |\frac{1}{f(x)} -0|< \epsilon $) which shows that for any $\epsilon$ there exists a$\frac{1}{f(x)}$  that is always lower than $\frac{1}{M}$.",,"['calculus', 'limits', 'proof-verification', 'proof-writing', 'alternative-proof']"
25,Find this Limit (Fourier series),Find this Limit (Fourier series),,"Find the following limit: $$\large\lim_{n\to\infty} \int_{-\pi}^\pi \biggl(x + \frac{\pi}{2}\biggr)^2 \frac{\sin\bigl(\bigl(n+\frac{1}{2}\bigr)x\bigr) + x \cos nx}{\sin \frac{x}{2}}\,dx.$$ We tried to use what we know about the Dirichlet kernel and the real version of the Riemann-Lebesgue lemma but we're stuck. Thanks","Find the following limit: $$\large\lim_{n\to\infty} \int_{-\pi}^\pi \biggl(x + \frac{\pi}{2}\biggr)^2 \frac{\sin\bigl(\bigl(n+\frac{1}{2}\bigr)x\bigr) + x \cos nx}{\sin \frac{x}{2}}\,dx.$$ We tried to use what we know about the Dirichlet kernel and the real version of the Riemann-Lebesgue lemma but we're stuck. Thanks",,"['calculus', 'integration', 'limits', 'fourier-series']"
26,How to prove the limit exists for function of two variables?,How to prove the limit exists for function of two variables?,,"Problem: Evaluate the indicated limit or explain why it does not exist: \begin{align*} \lim_{(x,y) \to (0,0)} \frac{x^2 y^2}{x^2 + y^4} \end{align*} The definition of limit my calculus textbook gives is: We say that $\lim_{(x,y) \to (a,b)} f(x,y) = L$, provided that: 1) Every neighbourhood of $(a,b)$ contains points of the domain of $f$   different from $(a,b)$, and 2) For every positive number $\epsilon$ there exists a positive number   $\delta = \delta (\epsilon)$ such that $|f(x,y) - L| < \epsilon$ holds   whenever $(x,y)$ is in the domain of $f$ and satisfies $0 < \sqrt{(x-a)^2 + (y-b)^2} < \delta$. So in this specific problem I first checked the limiting behaviour when $(x,y)$ approaches $(0,0)$ from different directions: When $y =0$ or $x = 0$ then $\lim_{(x,y) \to (0,0)} f(x,y) = 0$. When $y = x^2$, we also have that $\lim_{(x,y) \to (0,0)} f(x,x^2) = 0$. So I believe the limit exists and is zero, and I want to prove it now by using the definition. So let $\epsilon > 0$. Then we need to find a $\delta > 0$ such that if $0 < \sqrt{x^2 + y^2} < \delta$, then $| \frac{x^2 y^2}{x^2 + y^4} - 0 | < \epsilon$. Now, since $x^2 \leq x^2 + y^4$, it follows that $\frac{x^2}{x^2 + y^4} \leq 1$. Let $\delta = \sqrt{\epsilon}$. If $0 \leq \sqrt{x^2 + y^2} < \delta$, then it follows that $x^2 + y^2 < \epsilon$. Thus we also have that $y^2 < \epsilon$. Since we already had that $\frac{x^2}{x^2 + y^4} \leq 1$ we can multiply this with $y^2$ and get $\frac{x^2 y^2}{x^2 + y^4} \leq y^2$, from which it follows that $\frac{x^2 y^2}{x^2 + y^4} < \epsilon$. Can someone tell me if my reasoning is correct? Also, is this the right method to proof the existence of limits of functions of two variables? I mean, if you suspect that the limit exists, you have to use the delta-epsilon notation to prove it? Also, I found an alternative solution: Since $0 \leq \frac{x^2 y^2}{x^2 + y^4} \leq \frac{x^2 y^2}{x^2}$, and since $\lim_{(x,y) \to (0,0)} \frac{x^2 y^2}{x^2} = 0$, we have also $\lim_{(x,y) \to (0,0)} \frac{x^2 y^2}{x^2 + y^4} = 0$ by the Squeeze Theorem.","Problem: Evaluate the indicated limit or explain why it does not exist: \begin{align*} \lim_{(x,y) \to (0,0)} \frac{x^2 y^2}{x^2 + y^4} \end{align*} The definition of limit my calculus textbook gives is: We say that $\lim_{(x,y) \to (a,b)} f(x,y) = L$, provided that: 1) Every neighbourhood of $(a,b)$ contains points of the domain of $f$   different from $(a,b)$, and 2) For every positive number $\epsilon$ there exists a positive number   $\delta = \delta (\epsilon)$ such that $|f(x,y) - L| < \epsilon$ holds   whenever $(x,y)$ is in the domain of $f$ and satisfies $0 < \sqrt{(x-a)^2 + (y-b)^2} < \delta$. So in this specific problem I first checked the limiting behaviour when $(x,y)$ approaches $(0,0)$ from different directions: When $y =0$ or $x = 0$ then $\lim_{(x,y) \to (0,0)} f(x,y) = 0$. When $y = x^2$, we also have that $\lim_{(x,y) \to (0,0)} f(x,x^2) = 0$. So I believe the limit exists and is zero, and I want to prove it now by using the definition. So let $\epsilon > 0$. Then we need to find a $\delta > 0$ such that if $0 < \sqrt{x^2 + y^2} < \delta$, then $| \frac{x^2 y^2}{x^2 + y^4} - 0 | < \epsilon$. Now, since $x^2 \leq x^2 + y^4$, it follows that $\frac{x^2}{x^2 + y^4} \leq 1$. Let $\delta = \sqrt{\epsilon}$. If $0 \leq \sqrt{x^2 + y^2} < \delta$, then it follows that $x^2 + y^2 < \epsilon$. Thus we also have that $y^2 < \epsilon$. Since we already had that $\frac{x^2}{x^2 + y^4} \leq 1$ we can multiply this with $y^2$ and get $\frac{x^2 y^2}{x^2 + y^4} \leq y^2$, from which it follows that $\frac{x^2 y^2}{x^2 + y^4} < \epsilon$. Can someone tell me if my reasoning is correct? Also, is this the right method to proof the existence of limits of functions of two variables? I mean, if you suspect that the limit exists, you have to use the delta-epsilon notation to prove it? Also, I found an alternative solution: Since $0 \leq \frac{x^2 y^2}{x^2 + y^4} \leq \frac{x^2 y^2}{x^2}$, and since $\lim_{(x,y) \to (0,0)} \frac{x^2 y^2}{x^2} = 0$, we have also $\lim_{(x,y) \to (0,0)} \frac{x^2 y^2}{x^2 + y^4} = 0$ by the Squeeze Theorem.",,"['calculus', 'real-analysis', 'limits', 'multivariable-calculus']"
27,Limit as $\lim\limits_{x\to 0+} x^2\cot( x )$,Limit as,\lim\limits_{x\to 0+} x^2\cot( x ),Why does  $x^2\cot(x)$ become $0$ as $x$ tends to $0+$? I tried using L'Hôpital's rule but I'm not getting it! Please help!!  I'm getting the value as infinity...I think I went wrong somewhere...please help me sort it out.,Why does  $x^2\cot(x)$ become $0$ as $x$ tends to $0+$? I tried using L'Hôpital's rule but I'm not getting it! Please help!!  I'm getting the value as infinity...I think I went wrong somewhere...please help me sort it out.,,[]
28,Frazzle game question,Frazzle game question,,"In $7^{th}$ grade, in order to learn divisibility, memory, and focus, my math teacher had my pre-algebra class play a game called Frazzle. To play the game Frazzle, each person went around the room and said the next number (someone would say 1, then 2, etc), but if the number had a 7 in it (such as 721) or was divisible by 7 (such as 21), you yelled frazzle. Admittedly the game was a blast, but I've always had this question in my mind. In the game, I found that as we continued into 2 or 3 digit numbers, the word frazzle came up much more. For example in 1-->10, 1 number frazzle. 1-->20, 3 numbers would frazzle. I conjecture that: $$\lim_{n\to \infty}f/n=1$$ In other words that 100% of the numbers would frazzle, with n standing for the number that you are on and f being the number of frazzled numbers. But that creates a conundrum 1 is not divisible by 7. or 2. -Please either provide a proof or disproof of what I am saying or disprove it. I find myself extremely confused at this odd paradox. Thanks loads.","In $7^{th}$ grade, in order to learn divisibility, memory, and focus, my math teacher had my pre-algebra class play a game called Frazzle. To play the game Frazzle, each person went around the room and said the next number (someone would say 1, then 2, etc), but if the number had a 7 in it (such as 721) or was divisible by 7 (such as 21), you yelled frazzle. Admittedly the game was a blast, but I've always had this question in my mind. In the game, I found that as we continued into 2 or 3 digit numbers, the word frazzle came up much more. For example in 1-->10, 1 number frazzle. 1-->20, 3 numbers would frazzle. I conjecture that: $$\lim_{n\to \infty}f/n=1$$ In other words that 100% of the numbers would frazzle, with n standing for the number that you are on and f being the number of frazzled numbers. But that creates a conundrum 1 is not divisible by 7. or 2. -Please either provide a proof or disproof of what I am saying or disprove it. I find myself extremely confused at this odd paradox. Thanks loads.",,"['elementary-number-theory', 'limits']"
29,"How do I prove that $\lim_{(x,y)→(0,0)}\frac{1-\cos(x^2+y^2)}{\sqrt{x^2+y^2}} = 0$",How do I prove that,"\lim_{(x,y)→(0,0)}\frac{1-\cos(x^2+y^2)}{\sqrt{x^2+y^2}} = 0","$$\lim_{(x,y)→(0,0)}\frac{1-\cos(x^2+y^2)}{\sqrt{x^2+y^2}} = 0$$ I believe this is correct since I couldn't find a directional limit that won't validate this. From what I know, I have to prove that $$\forall\epsilon\gt 0, \exists\delta\gt 0$$ $$ \mbox{such that}$$ $$0 \lt \|(x,y)\| \lt \delta\Rightarrow \frac{1-\cos(x^2+y^2)}{\sqrt{x^2+y^2}} \lt \epsilon$$ I know that $$\sqrt{x^2+y^2} = \|(x,y)\|$$ So I take $$\frac{1-\cos(x^2+y^2)}{\sqrt{x^2+y^2}} \le \frac{2}{\|v\|}$$ and I kind of get stuck there. I greatly appreciate some help.","$$\lim_{(x,y)→(0,0)}\frac{1-\cos(x^2+y^2)}{\sqrt{x^2+y^2}} = 0$$ I believe this is correct since I couldn't find a directional limit that won't validate this. From what I know, I have to prove that $$\forall\epsilon\gt 0, \exists\delta\gt 0$$ $$ \mbox{such that}$$ $$0 \lt \|(x,y)\| \lt \delta\Rightarrow \frac{1-\cos(x^2+y^2)}{\sqrt{x^2+y^2}} \lt \epsilon$$ I know that $$\sqrt{x^2+y^2} = \|(x,y)\|$$ So I take $$\frac{1-\cos(x^2+y^2)}{\sqrt{x^2+y^2}} \le \frac{2}{\|v\|}$$ and I kind of get stuck there. I greatly appreciate some help.",,"['limits', 'multivariable-calculus']"
30,How to find this limit and prove it rigorously: $\sqrt{2 + \sqrt{2+\sqrt{2+\sqrt2...)}}}$? [duplicate],How to find this limit and prove it rigorously: ? [duplicate],\sqrt{2 + \sqrt{2+\sqrt{2+\sqrt2...)}}},"This question already has answers here : Limit of the nested radical $x_{n+1} = \sqrt{c+x_n}$ (5 answers) Closed 9 years ago . $\sqrt{2 + \sqrt{2+\sqrt{2+\sqrt2...)}}}$. Pretty classic question, I think - and the limit is equal to 2. But how do I prove this rigorously?  An epsilon-delta proof wouldn't work, since I wouldn't know the limit is equal to 2 - the question asks, if the limit exists, compute it.  This was for an old analysis exam, not a calculus class, so I feel that I can't just set the above = some number L, and then make algebraic manipulations on both sides of the equation, until I get what I want.  We can't assume the limit exists, I think. Thanks,","This question already has answers here : Limit of the nested radical $x_{n+1} = \sqrt{c+x_n}$ (5 answers) Closed 9 years ago . $\sqrt{2 + \sqrt{2+\sqrt{2+\sqrt2...)}}}$. Pretty classic question, I think - and the limit is equal to 2. But how do I prove this rigorously?  An epsilon-delta proof wouldn't work, since I wouldn't know the limit is equal to 2 - the question asks, if the limit exists, compute it.  This was for an old analysis exam, not a calculus class, so I feel that I can't just set the above = some number L, and then make algebraic manipulations on both sides of the equation, until I get what I want.  We can't assume the limit exists, I think. Thanks,",,"['calculus', 'real-analysis', 'limits', 'nested-radicals']"
31,Prove $\lim_{x\to3}\frac{x^2 - 9}{x - 3} = 6$ using $\delta-\epsilon$ definition of limit,Prove  using  definition of limit,\lim_{x\to3}\frac{x^2 - 9}{x - 3} = 6 \delta-\epsilon,"I need to prove that the $$\lim_{x\to3}\frac{x^2 - 9}{x - 3} = 6$$ using $\delta-\epsilon$ definition of limit. Now, I have started with a discussion, saying that what we want is that if $\left| x - 3\right| < \delta$, then we have $\left|\frac{x^2 - 9}{x - 3} - 6\right| < \epsilon$, then if we simplify it, we arrive at $\left| x - 3\right| < \epsilon$, so it seems that if we have $\left| x - 3\right| < \delta$, then we also have $\left| x - 3\right| < \epsilon$, so I could make $\delta = \epsilon$, given any $\epsilon$, but this seems to be just a stupid thing to do, I think I am not understanding what's going on. Am I right? If not, where am I wrong and how can I finish this proof?","I need to prove that the $$\lim_{x\to3}\frac{x^2 - 9}{x - 3} = 6$$ using $\delta-\epsilon$ definition of limit. Now, I have started with a discussion, saying that what we want is that if $\left| x - 3\right| < \delta$, then we have $\left|\frac{x^2 - 9}{x - 3} - 6\right| < \epsilon$, then if we simplify it, we arrive at $\left| x - 3\right| < \epsilon$, so it seems that if we have $\left| x - 3\right| < \delta$, then we also have $\left| x - 3\right| < \epsilon$, so I could make $\delta = \epsilon$, given any $\epsilon$, but this seems to be just a stupid thing to do, I think I am not understanding what's going on. Am I right? If not, where am I wrong and how can I finish this proof?",,"['limits', 'proof-verification']"
32,"Prove $ \lim\limits_{x\to\infty}y_{n}=\sqrt{x}$ if $y_{n}=\frac{1}{2}\left(y_{n-1}+\frac{x}{y_{n-1}}\right),n\in \mathbb{N},x>0,y_{0}>0$",Prove  if," \lim\limits_{x\to\infty}y_{n}=\sqrt{x} y_{n}=\frac{1}{2}\left(y_{n-1}+\frac{x}{y_{n-1}}\right),n\in \mathbb{N},x>0,y_{0}>0","Can someone say how to solve this problem? In solution, it says that it stars with $$\frac{y_{n}-\sqrt{x}}{y_{n}+\sqrt{x}}=\left(\frac{y_{n-1}-\sqrt{x}}{y_{n-1}+\sqrt{x}}\right)^2,n\ge 1$$ How to get to this formula?","Can someone say how to solve this problem? In solution, it says that it stars with $$\frac{y_{n}-\sqrt{x}}{y_{n}+\sqrt{x}}=\left(\frac{y_{n-1}-\sqrt{x}}{y_{n-1}+\sqrt{x}}\right)^2,n\ge 1$$ How to get to this formula?",,"['calculus', 'limits', 'recurrence-relations']"
33,Calculate $\lim_{n \to \infty} \ln \frac{n!^{\frac{1}{n}}}{n}$ [duplicate],Calculate  [duplicate],\lim_{n \to \infty} \ln \frac{n!^{\frac{1}{n}}}{n},"This question already has answers here : Finding the limit of $\frac {n}{\sqrt[n]{n!}}$ (11 answers) Closed 4 years ago . How can I calculate the following limit? I was thinking of applying Cesaro's theorem, but I'm getting nowhere. What should I do? $$\lim_{n \to \infty} \ln \frac{n!^{\frac{1}{n}}}{n}$$","This question already has answers here : Finding the limit of $\frac {n}{\sqrt[n]{n!}}$ (11 answers) Closed 4 years ago . How can I calculate the following limit? I was thinking of applying Cesaro's theorem, but I'm getting nowhere. What should I do? $$\lim_{n \to \infty} \ln \frac{n!^{\frac{1}{n}}}{n}$$",,"['calculus', 'real-analysis', 'sequences-and-series', 'limits']"
34,How to find the limit of this seq.?,How to find the limit of this seq.?,,Please help me to solve this limit: $$ \lim _{n\to \infty }\left(\frac{1}{n^2}\sqrt[n^2]{e}+\frac{2}{n^2}\sqrt[n^2]{e^4}+\frac{3}{n^2}\sqrt[n^2]{e^9}+...+\frac{n}{n^2}\sqrt[n^2]{e^{n^2}}\right) $$ Thank you,Please help me to solve this limit: $$ \lim _{n\to \infty }\left(\frac{1}{n^2}\sqrt[n^2]{e}+\frac{2}{n^2}\sqrt[n^2]{e^4}+\frac{3}{n^2}\sqrt[n^2]{e^9}+...+\frac{n}{n^2}\sqrt[n^2]{e^{n^2}}\right) $$ Thank you,,['limits']
35,How to compute this multivariable limit?,How to compute this multivariable limit?,,"How do I evaluate $$\lim_{x \to 0 ,\, y \to 0} \frac{x^3y-xy^3}{(x^2+y^2)^{3/2}}$$  I tried using squeeze theorem and writing it in polar coordinates, but I got stuck. Can anyone give me a hint?","How do I evaluate $$\lim_{x \to 0 ,\, y \to 0} \frac{x^3y-xy^3}{(x^2+y^2)^{3/2}}$$  I tried using squeeze theorem and writing it in polar coordinates, but I got stuck. Can anyone give me a hint?",,"['real-analysis', 'limits']"
36,"Are there general guidelines to make ""assumptions"" when proving limits?","Are there general guidelines to make ""assumptions"" when proving limits?",,"I am studying the definition of the limit using Paul's Online Notes When proving the following limit (Example 3) $\lim\limits_{x \to 2} x^2+x-11 = 9$ At one point he assumes: $|x+5| < K$ He also asumes: $|x-4| < 1$ Because one is a nice number to work with. I have read multiple explanations and every author seems to make their own ""assumptions"" when dealing with limit proofs. So my question is: Why the assumptions they make are right? Lets say I have to prove the following: $\lim\limits_{x \to 4} x = 2$ While the above is impossible, what stops me from making my own ""assumptions"" like 2=4 to prove the limit? Thanks in advance.","I am studying the definition of the limit using Paul's Online Notes When proving the following limit (Example 3) $\lim\limits_{x \to 2} x^2+x-11 = 9$ At one point he assumes: $|x+5| < K$ He also asumes: $|x-4| < 1$ Because one is a nice number to work with. I have read multiple explanations and every author seems to make their own ""assumptions"" when dealing with limit proofs. So my question is: Why the assumptions they make are right? Lets say I have to prove the following: $\lim\limits_{x \to 4} x = 2$ While the above is impossible, what stops me from making my own ""assumptions"" like 2=4 to prove the limit? Thanks in advance.",,"['limits', 'proof-verification']"
37,Prove that $\limsup_{n \to \infty} (a_n+b_n)= a + \limsup_{n \to \infty} b_n$,Prove that,\limsup_{n \to \infty} (a_n+b_n)= a + \limsup_{n \to \infty} b_n,"I have to prove the following: Given that lim $a_n$ exists and that lim $a_n$ = $a\in \mathbb{R}$  prove that: $$\limsup_{n \to \infty} (a_n+b_n)= a + \limsup_{n \to \infty} b_n$$ I proved one side of the inequality that is, I showed that $$\limsup_{n \to \infty} (a_n+b_n) \le a + \limsup_{n \to \infty} b_n$$ by using supremums of $(a_n)$, $(b_n)$ and $(c_n)$ where $(c_n)$={$c_k$|$k$$\ge$$n$} and $c_k=a_k+b_k$. But I can't figure out how to prove the converse. Can anyone explain how to do that without using $\epsilon$ or subsequences ? Any help would be appreciated thanks.","I have to prove the following: Given that lim $a_n$ exists and that lim $a_n$ = $a\in \mathbb{R}$  prove that: $$\limsup_{n \to \infty} (a_n+b_n)= a + \limsup_{n \to \infty} b_n$$ I proved one side of the inequality that is, I showed that $$\limsup_{n \to \infty} (a_n+b_n) \le a + \limsup_{n \to \infty} b_n$$ by using supremums of $(a_n)$, $(b_n)$ and $(c_n)$ where $(c_n)$={$c_k$|$k$$\ge$$n$} and $c_k=a_k+b_k$. But I can't figure out how to prove the converse. Can anyone explain how to do that without using $\epsilon$ or subsequences ? Any help would be appreciated thanks.",,"['real-analysis', 'analysis', 'limits', 'limsup-and-liminf']"
38,Prove that the limit doesn't exist,Prove that the limit doesn't exist,,"I have to prove that $$\lim_{(x,y)->(0,0)} \frac{xy}{2x-y}$$ doesn't exist. I have tried to use these restrictions: $x=0;  y=0; y=x;  y=mx; y=mx+q; y=ax^2;y=ax^2+bx+c; y=1/x, y=1/x^2,..$ and for each of them, I have done the related limit. But I have always obtained 0.  I know that I if want to prove that the limit doesn't exist, I have to find two restrictions that have different values for their limits. Any suggestions? Many thanks","I have to prove that $$\lim_{(x,y)->(0,0)} \frac{xy}{2x-y}$$ doesn't exist. I have tried to use these restrictions: $x=0;  y=0; y=x;  y=mx; y=mx+q; y=ax^2;y=ax^2+bx+c; y=1/x, y=1/x^2,..$ and for each of them, I have done the related limit. But I have always obtained 0.  I know that I if want to prove that the limit doesn't exist, I have to find two restrictions that have different values for their limits. Any suggestions? Many thanks",,"['limits', 'multivariable-calculus']"
39,Why does this converge to $\|x\|$,Why does this converge to,\|x\|,"Take $h_n(x) = x^{1+ \frac{1}{2n-1}}$ on the set $[-1,1]$ Then if we take $\lim_{n \to \infty} h_n(x)$ shouldn't this converge to $x$ seeing as $$\lim_{n \to \infty} h_n(x) = x \lim_{n \to \infty} x^{\frac{1}{2n-1}} = x?$$","Take $h_n(x) = x^{1+ \frac{1}{2n-1}}$ on the set $[-1,1]$ Then if we take $\lim_{n \to \infty} h_n(x)$ shouldn't this converge to $x$ seeing as $$\lim_{n \to \infty} h_n(x) = x \lim_{n \to \infty} x^{\frac{1}{2n-1}} = x?$$",,['limits']
40,Evaluating $\lim\limits_{x \to 0}\frac{\sin x}{\ln\left(\frac1{1+x}\right)}$,Evaluating,\lim\limits_{x \to 0}\frac{\sin x}{\ln\left(\frac1{1+x}\right)},Can you please give me some hints to evaluate $$\lim_{x \to 0}\frac{\sin x}{\ln\left(\frac1{1+x}\right)}\ ?$$ I'm stuck.,Can you please give me some hints to evaluate $$\lim_{x \to 0}\frac{\sin x}{\ln\left(\frac1{1+x}\right)}\ ?$$ I'm stuck.,,"['calculus', 'limits', 'trigonometry']"
41,Limits from the left and right: Does this limit exist?,Limits from the left and right: Does this limit exist?,,"For the problem below, I came to the conclusion that the $\lim_{x\to 2}$ does not exist, as $$\lim_{x\to 2^-}\neq \lim_{x\to 2^+}$$ Is my conclusion correct, and have I solved these problems correctly?","For the problem below, I came to the conclusion that the $\lim_{x\to 2}$ does not exist, as $$\lim_{x\to 2^-}\neq \lim_{x\to 2^+}$$ Is my conclusion correct, and have I solved these problems correctly?",,"['calculus', 'limits', 'solution-verification']"
42,How to evaluate the limit $\lim_\limits{x\to 0+ } \frac{1}{\sqrt{x}}\left ( \frac{1}{\sin x} - \frac{1}{x}\right )$?,How to evaluate the limit ?,\lim_\limits{x\to 0+ } \frac{1}{\sqrt{x}}\left ( \frac{1}{\sin x} - \frac{1}{x}\right ),"$$\lim_{x\to 0^+ } \frac{1}{\sqrt{x}}\left ( \frac{1}{\sin x} - \frac{1}{x}\right ) =\ ?$$ I rearranged it as $$\lim_{x\to 0^+ } \frac{x-\sin x}{x\sqrt{x}\sin x} = \lim_{x\to0^+ } \frac{x-\sin x}{x^{\frac{3}{2}}\sin x}$$ Which gives an indetermination of the form $0/0$. Then, I tried L'Hospital: $$\lim_{x\to 0^+ } \frac{x-\sin x}{x^{\frac{3}{2}}\sin x} = \lim_{x\to 0^+ } \frac{1-\cos x}{\frac{3}{2}x^{\frac{1}{2}}\sin x + x^{\frac{3}{2}} \cos x}$$ Should I continue to apply L'Hospital or is there a simpler way to solve it?","$$\lim_{x\to 0^+ } \frac{1}{\sqrt{x}}\left ( \frac{1}{\sin x} - \frac{1}{x}\right ) =\ ?$$ I rearranged it as $$\lim_{x\to 0^+ } \frac{x-\sin x}{x\sqrt{x}\sin x} = \lim_{x\to0^+ } \frac{x-\sin x}{x^{\frac{3}{2}}\sin x}$$ Which gives an indetermination of the form $0/0$. Then, I tried L'Hospital: $$\lim_{x\to 0^+ } \frac{x-\sin x}{x^{\frac{3}{2}}\sin x} = \lim_{x\to 0^+ } \frac{1-\cos x}{\frac{3}{2}x^{\frac{1}{2}}\sin x + x^{\frac{3}{2}} \cos x}$$ Should I continue to apply L'Hospital or is there a simpler way to solve it?",,"['calculus', 'limits', 'indeterminate-forms']"
43,Limit evaluation with integral,Limit evaluation with integral,,"Evaluate the limit $$\lim_{n\to\infty} \int_0^1 n^2x(1-x^2)^n dx$$ My Proof: We may look at $n$ as a constant and evaluate the integral $\int_0^1 x(1-x^2)^ndx$ (I already moved out the $n^2$). From here we integrate by parts; $$\int_0^1 x(1-x^2)^ndx = x \frac{(1-x^2)^{n+1}}{n+1}|_0^1 - \int_0^1 \frac{(1-x^2)^{n+1}}{n+1} dx = 0 - \frac{1}{n+1} \int_0^1 (1-x^2)^{n+1}dx = -\frac{1}{n+1} - ...$$ If I continue, something not very pretty happens. Is that even the preferable way of evaluating the limit?","Evaluate the limit $$\lim_{n\to\infty} \int_0^1 n^2x(1-x^2)^n dx$$ My Proof: We may look at $n$ as a constant and evaluate the integral $\int_0^1 x(1-x^2)^ndx$ (I already moved out the $n^2$). From here we integrate by parts; $$\int_0^1 x(1-x^2)^ndx = x \frac{(1-x^2)^{n+1}}{n+1}|_0^1 - \int_0^1 \frac{(1-x^2)^{n+1}}{n+1} dx = 0 - \frac{1}{n+1} \int_0^1 (1-x^2)^{n+1}dx = -\frac{1}{n+1} - ...$$ If I continue, something not very pretty happens. Is that even the preferable way of evaluating the limit?",,"['real-analysis', 'integration', 'limits']"
44,Solve this limit $\lim_{n\to \infty} \int_{0}^1 nxe^{-nx}dx$,Solve this limit,\lim_{n\to \infty} \int_{0}^1 nxe^{-nx}dx,"I would like to solve that limit: $$ \lim_{n \to\infty}  \int_{0}^1  nxe^{-nx} dx$$ I would like to take the limit inside the integral but for doing this, I have to use Beppo Levi's theorem or Dominated convergence Theorem.  But the sequence of function is not increasing so I cannot use Beppo Levi's theorem, am I correct?","I would like to solve that limit: I would like to take the limit inside the integral but for doing this, I have to use Beppo Levi's theorem or Dominated convergence Theorem.  But the sequence of function is not increasing so I cannot use Beppo Levi's theorem, am I correct?", \lim_{n \to\infty}  \int_{0}^1  nxe^{-nx} dx,"['integration', 'limits', 'convergence-divergence']"
45,Prove that $\lim_{x \to 0 } \frac{\ln(x+1)}{x} = 1$,Prove that,\lim_{x \to 0 } \frac{\ln(x+1)}{x} = 1,I've looked around to see a proof for this limit and encountered this: $$ \lim_{x \to 0 } \frac{\ln(x+1)}{x}  $$ $$ \lim_{x \to 0 } \frac{1}{x} \ln(x+1) $$ $$ \lim_{x \to 0 } \ln(x+1)^\frac{1}{x} $$ $ t = \frac{1}{x}$ Then: $$ \lim_{t \to +- \infty } ln(\frac{1}{t}+1)^t $$ $$ \lim_{t \to +- \infty } ln(e) = 1 $$ What I didn't understand is how did he transfer $\frac{1}{x} \ln(x+1)$ to this: $ \ln(x+1)^\frac{1}{x} $ and how did he transfer this: $\ln(\frac{1}{t}+1)^t$ to this: $ \ln(e) = 1 $ Is this the right approach to prove this limit? can someone explain me the steps with I didn't understand? Thanks :),I've looked around to see a proof for this limit and encountered this: $$ \lim_{x \to 0 } \frac{\ln(x+1)}{x}  $$ $$ \lim_{x \to 0 } \frac{1}{x} \ln(x+1) $$ $$ \lim_{x \to 0 } \ln(x+1)^\frac{1}{x} $$ $ t = \frac{1}{x}$ Then: $$ \lim_{t \to +- \infty } ln(\frac{1}{t}+1)^t $$ $$ \lim_{t \to +- \infty } ln(e) = 1 $$ What I didn't understand is how did he transfer $\frac{1}{x} \ln(x+1)$ to this: $ \ln(x+1)^\frac{1}{x} $ and how did he transfer this: $\ln(\frac{1}{t}+1)^t$ to this: $ \ln(e) = 1 $ Is this the right approach to prove this limit? can someone explain me the steps with I didn't understand? Thanks :),,"['calculus', 'limits']"
46,Limit of a sequence containing root of n!-th degree - how to deal with that?,Limit of a sequence containing root of n!-th degree - how to deal with that?,,"Here is a sequence the limit of which I'm trying to find as $n$ goes to infinity: $$a_n=\sqrt[n!]{\frac{1}{2^{n!}}-\frac{1}{3^{n!}}}$$ Here is what I've done: $a_n=\sqrt[n!]{\frac{1}{2^{n!}}(1-\frac{2^{n!}}{3^{n!}})}=\frac{1}{2}\sqrt[n!]{1-(\frac{2}{3})^{n!}}$ Intuitevely this should converge to $\frac{1}{2}$ because as $n$ becomes large $(\frac{2}{3})^{n!}$ becomes closer and closer to $0$ so this expression under the root basically becomes $\sqrt[n!]{1}$ which is equal to $1$. I don't think I'm allowed to finish solving the problem now (as I am aware such operations can be quite risky, for example limit of $(1+\frac{1}{n})^n$ evaluates to $e$ even though $\frac{1}{n}$ becomes closer and closer to $0$ as $n$ becomes large). So how to prove it formally?","Here is a sequence the limit of which I'm trying to find as $n$ goes to infinity: $$a_n=\sqrt[n!]{\frac{1}{2^{n!}}-\frac{1}{3^{n!}}}$$ Here is what I've done: $a_n=\sqrt[n!]{\frac{1}{2^{n!}}(1-\frac{2^{n!}}{3^{n!}})}=\frac{1}{2}\sqrt[n!]{1-(\frac{2}{3})^{n!}}$ Intuitevely this should converge to $\frac{1}{2}$ because as $n$ becomes large $(\frac{2}{3})^{n!}$ becomes closer and closer to $0$ so this expression under the root basically becomes $\sqrt[n!]{1}$ which is equal to $1$. I don't think I'm allowed to finish solving the problem now (as I am aware such operations can be quite risky, for example limit of $(1+\frac{1}{n})^n$ evaluates to $e$ even though $\frac{1}{n}$ becomes closer and closer to $0$ as $n$ becomes large). So how to prove it formally?",,"['sequences-and-series', 'limits']"
47,"Calculate if $ \lim_{(x,y) \to (0,0)} \frac{|x^2y^2|}{|x^3|+|y^3|}$ exists [closed]",Calculate if  exists [closed]," \lim_{(x,y) \to (0,0)} \frac{|x^2y^2|}{|x^3|+|y^3|}","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I have to calculate if this limit exist: $$ \lim_{(x,y) \to (0,0)} \frac{\vert x^2y^2\vert}{\vert x^3\vert +\vert y^3\vert}$$ Could anyone give me a hand?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I have to calculate if this limit exist: $$ \lim_{(x,y) \to (0,0)} \frac{\vert x^2y^2\vert}{\vert x^3\vert +\vert y^3\vert}$$ Could anyone give me a hand?",,"['limits', 'multivariable-calculus']"
48,Finding the limit without L'Hopital's rule,Finding the limit without L'Hopital's rule,,"$$\lim_{h\to 0}\frac{\cos(x_0+h)-\cos(x_0)}h \quad\text{as } x_0\in(0,\pi)$$ I did actually do it without L'Hopital rule as I just multiplied the top and bottom of the conjugate of the top of the fraction and just went from there, using the addition formula for the cosine. But this was extremely tedious. I was wondering if there is an easier way. The answer to this gives $-\sin(x_0)$.","$$\lim_{h\to 0}\frac{\cos(x_0+h)-\cos(x_0)}h \quad\text{as } x_0\in(0,\pi)$$ I did actually do it without L'Hopital rule as I just multiplied the top and bottom of the conjugate of the top of the fraction and just went from there, using the addition formula for the cosine. But this was extremely tedious. I was wondering if there is an easier way. The answer to this gives $-\sin(x_0)$.",,['limits']
49,Why those division by zero are formalized?,Why those division by zero are formalized?,,"Easy example first: $f(x) = nx$ $f'(x) = (f(x+0)-f(x))/0 = (nx+0n-nx)/0 = (0n)/0 = n$ Hard one: $f(x) = a^x$ $f'(x) = (f(x+0)-f(x))/0 = (a^{x+0}-a^x)/0 = (a^x(a^0-1))/0 = (a^x(e^{\ln(a^0)}-1))/0 = (a^x(e^{0\ln(a)}-1))/0$ Place $e^x = 1 + x + x^2/2 + ... + x^k/!k$ in $f'(x)$. $f'(x) = (a^x(1 + 0\ln(a) + ... - 1))/0 = (a^x(0\ln(a) + ...))/0 = a^x(\ln(a) + (...)/0)$ Discard values that are $0$ that we can't rescue them with that $/0$. $f'(x) = a^x(\ln(a)) = a^x\ln(a) $ Why is this working? Is there a name for this type of equations? (Or type of a way of solving equations) This way of solving involves expanding $x$ of $x/0$ until some $*0$ to elimnate the outside $/0$. But as you see this is not exactly limit, but I tagged it because it's similar.","Easy example first: $f(x) = nx$ $f'(x) = (f(x+0)-f(x))/0 = (nx+0n-nx)/0 = (0n)/0 = n$ Hard one: $f(x) = a^x$ $f'(x) = (f(x+0)-f(x))/0 = (a^{x+0}-a^x)/0 = (a^x(a^0-1))/0 = (a^x(e^{\ln(a^0)}-1))/0 = (a^x(e^{0\ln(a)}-1))/0$ Place $e^x = 1 + x + x^2/2 + ... + x^k/!k$ in $f'(x)$. $f'(x) = (a^x(1 + 0\ln(a) + ... - 1))/0 = (a^x(0\ln(a) + ...))/0 = a^x(\ln(a) + (...)/0)$ Discard values that are $0$ that we can't rescue them with that $/0$. $f'(x) = a^x(\ln(a)) = a^x\ln(a) $ Why is this working? Is there a name for this type of equations? (Or type of a way of solving equations) This way of solving involves expanding $x$ of $x/0$ until some $*0$ to elimnate the outside $/0$. But as you see this is not exactly limit, but I tagged it because it's similar.",,"['limits', 'nonstandard-analysis', 'infinitesimals']"
50,How find this limits with hardly form?,How find this limits with hardly form?,,"show that: $$\lim_{n\to\infty}n\left[\left(\dfrac{1}{\pi}\left(\sin{\left(\dfrac{\pi}{\sqrt{n^2+1}}\right)}+ \sin{\left(\dfrac{\pi}{\sqrt{n^2+2}}\right)}+\cdots+\sin{\left(\dfrac{\pi}{\sqrt{n^2+n}}\right)} \right)\right)^n-\dfrac{1}{\sqrt[4]{e}}\right]=-\dfrac{1}{\sqrt[4]{e}}\left(\dfrac{31}{96}+\dfrac{\pi^2}{6}\right)$$ I only solve this :$$\lim_{n\to\infty}\left(\dfrac{1}{\pi}\sum_{i=1}^{n}\sin{\left(\dfrac{\pi}{\sqrt{n^2+i}}\right)}\right)^n=\dfrac{1}{\sqrt[4]{e}}\tag{1}$$ use $$\sin{x}\approx x,\Longrightarrow \dfrac{1}{\pi}\sin{(\dfrac{\pi}{\sqrt{n^2+i}})}=\dfrac{1}{\sqrt{n^2+i}}+o(\dfrac{1}{\sqrt{n^2+i}})\to \dfrac{1}{n}\left(1+\dfrac{i}{n^2}\right)^{-\frac{1}{2}},n\to\infty$$ and note $$(1+x)^{-1/2}=1-\dfrac{1}{2}x+o(x)$$ so $$\lim_{n\to\infty}\left(\dfrac{1}{\pi}\sum_{i=1}^{n}\sin{\left(\dfrac{\pi}{\sqrt{n^2+i}}\right)}\right)^n=\lim_{n\to\infty}\left(\dfrac{1}{n}\sum_{i=1}^{n}\left(1-\dfrac{i}{2n^2}+o(i/n^2)\right)\right)^n=e^{-\frac{1}{4}}$$ But I can't solve my problem,Thank you","show that: $$\lim_{n\to\infty}n\left[\left(\dfrac{1}{\pi}\left(\sin{\left(\dfrac{\pi}{\sqrt{n^2+1}}\right)}+ \sin{\left(\dfrac{\pi}{\sqrt{n^2+2}}\right)}+\cdots+\sin{\left(\dfrac{\pi}{\sqrt{n^2+n}}\right)} \right)\right)^n-\dfrac{1}{\sqrt[4]{e}}\right]=-\dfrac{1}{\sqrt[4]{e}}\left(\dfrac{31}{96}+\dfrac{\pi^2}{6}\right)$$ I only solve this :$$\lim_{n\to\infty}\left(\dfrac{1}{\pi}\sum_{i=1}^{n}\sin{\left(\dfrac{\pi}{\sqrt{n^2+i}}\right)}\right)^n=\dfrac{1}{\sqrt[4]{e}}\tag{1}$$ use $$\sin{x}\approx x,\Longrightarrow \dfrac{1}{\pi}\sin{(\dfrac{\pi}{\sqrt{n^2+i}})}=\dfrac{1}{\sqrt{n^2+i}}+o(\dfrac{1}{\sqrt{n^2+i}})\to \dfrac{1}{n}\left(1+\dfrac{i}{n^2}\right)^{-\frac{1}{2}},n\to\infty$$ and note $$(1+x)^{-1/2}=1-\dfrac{1}{2}x+o(x)$$ so $$\lim_{n\to\infty}\left(\dfrac{1}{\pi}\sum_{i=1}^{n}\sin{\left(\dfrac{\pi}{\sqrt{n^2+i}}\right)}\right)^n=\lim_{n\to\infty}\left(\dfrac{1}{n}\sum_{i=1}^{n}\left(1-\dfrac{i}{2n^2}+o(i/n^2)\right)\right)^n=e^{-\frac{1}{4}}$$ But I can't solve my problem,Thank you",,['limits']
51,Limit of a finite sum,Limit of a finite sum,,"Let $\{a_n\}_{n=1}^{\infty}$ be a sequence defined by $$a_n = \frac{n+1}{2^{n+1}}\left(\sum_{k=1}^n \frac{2^k}{k}\right)$$ Show that the sequence converges and find its limit. Update : After some computation I see that its limit is 1. Maybe we can use the ""squeeze"" theorem? I proved that $a_n > 1, \forall n \geq 2$ but I can't find the upper bound. I appreciate all help. Thank you","Let $\{a_n\}_{n=1}^{\infty}$ be a sequence defined by $$a_n = \frac{n+1}{2^{n+1}}\left(\sum_{k=1}^n \frac{2^k}{k}\right)$$ Show that the sequence converges and find its limit. Update : After some computation I see that its limit is 1. Maybe we can use the ""squeeze"" theorem? I proved that $a_n > 1, \forall n \geq 2$ but I can't find the upper bound. I appreciate all help. Thank you",,"['sequences-and-series', 'limits', 'convergence-divergence', 'summation']"
52,Evaluating $\lim_{n\to \infty} \bigg(\frac{(2n!)}{n!^2}\bigg)^{\frac{1}{4n}}$ [duplicate],Evaluating  [duplicate],\lim_{n\to \infty} \bigg(\frac{(2n!)}{n!^2}\bigg)^{\frac{1}{4n}},"This question already has answers here : Evaluating $\lim_{n\to \infty}\frac1{2n}\log\left({2n \choose n}\right)$ [duplicate] (3 answers) Closed 9 years ago . I am trying to evaluate $$\lim_{n\to \infty} \bigg(\frac{(2n!)}{n!^2}\bigg)^{\frac{1}{4n}},$$ which came from trying to find the radius of convergence of the complex power series $$\sum_{n\ge0} z^{2n}\frac{\sqrt{(2n)!}}{n!}$$ In the limit I we have some cancellation: $$\frac{(2n!)}{n!^2}=\frac{1\cdots n\cdot (n+1)\cdots(2n)}{1\cdots n\cdot 1\cdots n}=\frac{(n+1)\cdot(2n)}{1\cdots n},\,\,\,(*)$$ and the right hand side is less than $2^n$, so an upper bound on the limit is $$(2^n)^{\frac{1}{4n}}=2^{1/4}$$ The right hand side of $(*)$ is at least $1$, so I have the bounds $1,2^{1/4}$, but I don't know how to get a better estimate. How can I compute this limit?","This question already has answers here : Evaluating $\lim_{n\to \infty}\frac1{2n}\log\left({2n \choose n}\right)$ [duplicate] (3 answers) Closed 9 years ago . I am trying to evaluate $$\lim_{n\to \infty} \bigg(\frac{(2n!)}{n!^2}\bigg)^{\frac{1}{4n}},$$ which came from trying to find the radius of convergence of the complex power series $$\sum_{n\ge0} z^{2n}\frac{\sqrt{(2n)!}}{n!}$$ In the limit I we have some cancellation: $$\frac{(2n!)}{n!^2}=\frac{1\cdots n\cdot (n+1)\cdots(2n)}{1\cdots n\cdot 1\cdots n}=\frac{(n+1)\cdot(2n)}{1\cdots n},\,\,\,(*)$$ and the right hand side is less than $2^n$, so an upper bound on the limit is $$(2^n)^{\frac{1}{4n}}=2^{1/4}$$ The right hand side of $(*)$ is at least $1$, so I have the bounds $1,2^{1/4}$, but I don't know how to get a better estimate. How can I compute this limit?",,['limits']
53,Finding functions for the squeeze theorem for $\lim_{x \to 0}{\frac {x}{\sin x}}$,Finding functions for the squeeze theorem for,\lim_{x \to 0}{\frac {x}{\sin x}},"I was solving a problem today and at one point I had to evaluate the $\lim_{x \to 0}{\frac {x}{\sin x}}$. I know I could easily do this with L'hôspital's but I haven't learned that yet. So what I did was try to use the squeeze theorem with the two bounding functions of $ f (x)=x^2 + 1 $ and $ h (x)=-x^2 +1 $, and it worked (I think?) giving me the answer of 1. However, I was only able to choose those two functions after googling the graph of $\lim_{x \to 0}{\frac {x}{\sin x}}$, so that kind of ruins the purpose. Is there a way I could have visualized this or chosen other, more fitting functions? Or maybe there is another way to solve this limit?","I was solving a problem today and at one point I had to evaluate the $\lim_{x \to 0}{\frac {x}{\sin x}}$. I know I could easily do this with L'hôspital's but I haven't learned that yet. So what I did was try to use the squeeze theorem with the two bounding functions of $ f (x)=x^2 + 1 $ and $ h (x)=-x^2 +1 $, and it worked (I think?) giving me the answer of 1. However, I was only able to choose those two functions after googling the graph of $\lim_{x \to 0}{\frac {x}{\sin x}}$, so that kind of ruins the purpose. Is there a way I could have visualized this or chosen other, more fitting functions? Or maybe there is another way to solve this limit?",,"['calculus', 'limits', 'limits-without-lhopital']"
54,Limit of implicit function,Limit of implicit function,,"For $v>0$, let $f(v)$ be the smallest positive solution $x$ of $$\sqrt{\left(\frac{v}{x}\right)^2-1}=\tan x.$$ It can be confirmed graphically that $f(v)$ exists for all $v>0$. How can I show that $$ \lim_{v \to \infty} f(v) = \frac{\pi}{2}?$$","For $v>0$, let $f(v)$ be the smallest positive solution $x$ of $$\sqrt{\left(\frac{v}{x}\right)^2-1}=\tan x.$$ It can be confirmed graphically that $f(v)$ exists for all $v>0$. How can I show that $$ \lim_{v \to \infty} f(v) = \frac{\pi}{2}?$$",,"['real-analysis', 'limits', 'roots']"
55,Limit $\lim_{x \to 1} \ (1-x^2)\tan(\frac{\pi x}{2})$?,Limit ?,\lim_{x \to 1} \ (1-x^2)\tan(\frac{\pi x}{2}),"Somebody, help me please with this limit $$\lim_{x \to 1} \ (1-x^2)\tan\left(\frac{\pi x}{2}\right)$$ I've tried to dissasemble this equation into $$\lim_{x \to 1} \ (1-x^2)\frac{\sin\frac{\pi x}{2}}{\cos\frac{\pi x}{2}}$$ Sinus will be equal to 1, so: $$\lim_{x \to 1} \ \frac{(1-x^2)}{\cos\frac{\pi x}{2}}$$ And then I don't know what should i do next. I feel very sorry that i didn't mention it before, but i need to solve it without l'hospital rule.","Somebody, help me please with this limit $$\lim_{x \to 1} \ (1-x^2)\tan\left(\frac{\pi x}{2}\right)$$ I've tried to dissasemble this equation into $$\lim_{x \to 1} \ (1-x^2)\frac{\sin\frac{\pi x}{2}}{\cos\frac{\pi x}{2}}$$ Sinus will be equal to 1, so: $$\lim_{x \to 1} \ \frac{(1-x^2)}{\cos\frac{\pi x}{2}}$$ And then I don't know what should i do next. I feel very sorry that i didn't mention it before, but i need to solve it without l'hospital rule.",,"['limits', 'limits-without-lhopital']"
56,"Has anyone defined a limit of a sequence of fields? In particular, what is the limit of finite fields?","Has anyone defined a limit of a sequence of fields? In particular, what is the limit of finite fields?",,"I'm curious about  $$ \lim_{n \rightarrow \infty} \mathbb{F}_n $$ Is it $\mathbb{Z}$? That seems reasonable if you consider it as a set but of course $\mathbb{Z}$ is not a field so that is confusing. I think the problem is probably how you define the limit in this case. Has anyone ever done so? Edit: Another question. What is the smallest field that contains all finite fields? We think the answer to this is $\mathbb{Q}$, but again we don't have a formal definition of ""containment"", so this is a problem too. Maybe using subfields. Have either of my questions ever been studied?","I'm curious about  $$ \lim_{n \rightarrow \infty} \mathbb{F}_n $$ Is it $\mathbb{Z}$? That seems reasonable if you consider it as a set but of course $\mathbb{Z}$ is not a field so that is confusing. I think the problem is probably how you define the limit in this case. Has anyone ever done so? Edit: Another question. What is the smallest field that contains all finite fields? We think the answer to this is $\mathbb{Q}$, but again we don't have a formal definition of ""containment"", so this is a problem too. Maybe using subfields. Have either of my questions ever been studied?",,"['limits', 'field-theory', 'finite-fields']"
57,"For any integer $n\geq 1$, define $\sin_n=\sin\circ ... \circ \sin$ ($n$ times). Prove that $\lim_{x\to 0}\frac{\sin_nx}{x}=1$ for all $n\geq 1$","For any integer , define  ( times). Prove that  for all",n\geq 1 \sin_n=\sin\circ ... \circ \sin n \lim_{x\to 0}\frac{\sin_nx}{x}=1 n\geq 1,"I got this problem: For any integer $n\geq 1$, define $\sin_n=\sin\circ ... \circ \sin$ ($n$ times). Prove that $\lim_{x\to 0}\frac{\sin_nx}{x}=1$ for all $n\geq 1$. Some hints will be appreciated.","I got this problem: For any integer $n\geq 1$, define $\sin_n=\sin\circ ... \circ \sin$ ($n$ times). Prove that $\lim_{x\to 0}\frac{\sin_nx}{x}=1$ for all $n\geq 1$. Some hints will be appreciated.",,"['calculus', 'real-analysis', 'limits']"
58,"Limits to infinity, even and odd functions","Limits to infinity, even and odd functions",,"I have a couple of questions regarding a practice test I just made, so the subject might vary a little bit but most of it has to do with limits. $$ \lim_{x \to \infty} \dfrac{7x+3x^2}{1-x^3} $$ Apparently this is $-3$, but I've read in my book that if a rational function has a higher order polynomial in the denominator, that the limit always becomes $0$. If this is false, how are you supposed to evaluate this limit? $$ \lim_{x \to 1+} \dfrac{7x+3x^2}{1-x^3} $$ I just have no idea how to do this, right and left limits are very difficult to me unless I have the graph. $g(x) = f(x) - f(-x)$ and $h(x) = f(x) + f(-x)$. What is the parity of $g$ and $h$. $f$ is a function with domain $\mathbb{R}$. How are you supposed to do this without knowing the parity of $f$? $$ \lim_{x \to \infty} \dfrac{1}{x-\sqrt{x^2+ax+b}} $$ $a,b \in \mathbb{R}$ with $a\neq 0$. I haven't worked with 2 variables yet, so I would appreciate a good tactic here.","I have a couple of questions regarding a practice test I just made, so the subject might vary a little bit but most of it has to do with limits. $$ \lim_{x \to \infty} \dfrac{7x+3x^2}{1-x^3} $$ Apparently this is $-3$, but I've read in my book that if a rational function has a higher order polynomial in the denominator, that the limit always becomes $0$. If this is false, how are you supposed to evaluate this limit? $$ \lim_{x \to 1+} \dfrac{7x+3x^2}{1-x^3} $$ I just have no idea how to do this, right and left limits are very difficult to me unless I have the graph. $g(x) = f(x) - f(-x)$ and $h(x) = f(x) + f(-x)$. What is the parity of $g$ and $h$. $f$ is a function with domain $\mathbb{R}$. How are you supposed to do this without knowing the parity of $f$? $$ \lim_{x \to \infty} \dfrac{1}{x-\sqrt{x^2+ax+b}} $$ $a,b \in \mathbb{R}$ with $a\neq 0$. I haven't worked with 2 variables yet, so I would appreciate a good tactic here.",,"['calculus', 'limits', 'functions']"
59,Limits without L'Hopitals Rule,Limits without L'Hopitals Rule,,Evaluate the limit without using L'hopital's rule a)$$\lim_{x \to 0} \frac {(1+2x)^{1/3}-1}{x} $$ I got the answer as $l=\frac 23$... but I used L'hopitals rule for that... How can I do it another way? b)$$\lim_{x \to 5^-} \frac {e^x}{(x-5)^3}$$ $l=-\infty$ c)$$\lim_{x \to \frac {\pi} 2} \frac{\sin x}{\cos^2x} - \tan^2 x$$ I don't know how to work with this at all So basically I was able to find most of the limits through L'Hopitals Rule... BUT how do I find the limits without using his rule?,Evaluate the limit without using L'hopital's rule a)$$\lim_{x \to 0} \frac {(1+2x)^{1/3}-1}{x} $$ I got the answer as $l=\frac 23$... but I used L'hopitals rule for that... How can I do it another way? b)$$\lim_{x \to 5^-} \frac {e^x}{(x-5)^3}$$ $l=-\infty$ c)$$\lim_{x \to \frac {\pi} 2} \frac{\sin x}{\cos^2x} - \tan^2 x$$ I don't know how to work with this at all So basically I was able to find most of the limits through L'Hopitals Rule... BUT how do I find the limits without using his rule?,,"['calculus', 'limits', 'trigonometry', 'limits-without-lhopital']"
60,Other ways to evaluate $\lim_{x \to 0} \frac 1x \left [ \sqrt[3]{\frac{1 - \sqrt{1 - x}}{\sqrt{1 + x} - 1}} - 1\right ]$?,Other ways to evaluate ?,\lim_{x \to 0} \frac 1x \left [ \sqrt[3]{\frac{1 - \sqrt{1 - x}}{\sqrt{1 + x} - 1}} - 1\right ],"Using the facts that: $$\begin{align} \sqrt{1 + x} &= 1 + x/2 - x^2/8 + \mathcal{o}(x^2)\\ \sqrt{1 - x} &= 1 - x/2 - x^2/8 + \mathcal{o}(x^2)\\ \sqrt[3]{1 + x} &= 1 + x/3 + \mathcal{o}(x) \end{align}$$ I was able to evaluate the limit as follows: $$\begin{align} \lim_{x \to 0} \frac 1x \left [ \sqrt[3]{\frac{1 - \sqrt{1 - x}}{\sqrt{1 + x} - 1}} - 1\right ] &\sim \lim_{x \to 0} \frac 1x \left [ \sqrt[3]{\frac{\dfrac x2 + \dfrac{x^2} 8}{\dfrac x2 + \dfrac{x^2} 8}} - 1\right ] =\\ &= \lim_{x \to 0} \frac 1x \left [ \sqrt[3]{1 + \frac{2x^2}{4x - x^2}} - 1\right ] \sim\\ &\sim \lim_{x \to 0} \frac{2x^2}{12x^2 - 3x^3} = \frac 16 \end{align}$$ What are other ways to evaluate it? Maybe pure algebraically? I tried to rationalize the denominator, but got stuck at some point...","Using the facts that: $$\begin{align} \sqrt{1 + x} &= 1 + x/2 - x^2/8 + \mathcal{o}(x^2)\\ \sqrt{1 - x} &= 1 - x/2 - x^2/8 + \mathcal{o}(x^2)\\ \sqrt[3]{1 + x} &= 1 + x/3 + \mathcal{o}(x) \end{align}$$ I was able to evaluate the limit as follows: $$\begin{align} \lim_{x \to 0} \frac 1x \left [ \sqrt[3]{\frac{1 - \sqrt{1 - x}}{\sqrt{1 + x} - 1}} - 1\right ] &\sim \lim_{x \to 0} \frac 1x \left [ \sqrt[3]{\frac{\dfrac x2 + \dfrac{x^2} 8}{\dfrac x2 + \dfrac{x^2} 8}} - 1\right ] =\\ &= \lim_{x \to 0} \frac 1x \left [ \sqrt[3]{1 + \frac{2x^2}{4x - x^2}} - 1\right ] \sim\\ &\sim \lim_{x \to 0} \frac{2x^2}{12x^2 - 3x^3} = \frac 16 \end{align}$$ What are other ways to evaluate it? Maybe pure algebraically? I tried to rationalize the denominator, but got stuck at some point...",,"['limits', 'taylor-expansion']"
61,How to show $f(x)$ is bounded?,How to show  is bounded?,f(x),Consider: $$2x\sin(1/x) - \cos(1/x)$$. How to show $f(x)$ is bounded? Thanks!,Consider: $$2x\sin(1/x) - \cos(1/x)$$. How to show $f(x)$ is bounded? Thanks!,,"['calculus', 'real-analysis', 'limits']"
62,How prove this limit $\left(\frac{1}{2}+\sum_{k=1}^{n-1}(-1)^{\lfloor\frac{mk}{n}\rfloor}\{\frac{mk}{n}\} \right)^n=\frac{1}{\sqrt{e}}$,How prove this limit,\left(\frac{1}{2}+\sum_{k=1}^{n-1}(-1)^{\lfloor\frac{mk}{n}\rfloor}\{\frac{mk}{n}\} \right)^n=\frac{1}{\sqrt{e}},"let $m$ is even number,and $n$ is  odd number,and such $(m,n)=1$, show this limit: $$\lim_{n\to\infty}\left(\dfrac{1}{2}+\sum_{k=1}^{n-1}(-1)^{\left\lfloor\dfrac{mk}{n}\right\rfloor}\left\{\dfrac{mk}{n}\right\} \right)^n=\dfrac{1}{\sqrt{e}}$$ where $\{x\}=x-\lfloor x\rfloor$ I think we can find this sum $$\sum_{k=1}^{n-1}(-1)^{\left\lfloor\dfrac{mk}{n}\right\rfloor}\left\{\dfrac{mk}{n}\right\}$$ But I can't","let $m$ is even number,and $n$ is  odd number,and such $(m,n)=1$, show this limit: $$\lim_{n\to\infty}\left(\dfrac{1}{2}+\sum_{k=1}^{n-1}(-1)^{\left\lfloor\dfrac{mk}{n}\right\rfloor}\left\{\dfrac{mk}{n}\right\} \right)^n=\dfrac{1}{\sqrt{e}}$$ where $\{x\}=x-\lfloor x\rfloor$ I think we can find this sum $$\sum_{k=1}^{n-1}(-1)^{\left\lfloor\dfrac{mk}{n}\right\rfloor}\left\{\dfrac{mk}{n}\right\}$$ But I can't",,"['calculus', 'limits']"
63,Why are all convergent sequences necessarily Cauchy?,Why are all convergent sequences necessarily Cauchy?,,"I can understand the proof, which I could do myself: $|s_n - s_m| = |s_n - s + s - s_m|$ $\Rightarrow |s_n - s_m|  \leq |s_n - s| + |s_m - s|  $ For some $\epsilon > 0, \exists\ \ N(\epsilon) \in \mathbb{N} s.t.$ $ |s_n - s_m|  \leq \epsilon + \epsilon \ \  \forall \ \  m,n > N(\epsilon)$ $\therefore |s_n - s_m| \leq 2\epsilon$ where $2\epsilon \in \mathbb{R}$ The fact that the Cauchy sequence gradually closes up, i.e. the elements get closer together in obvious from the last point. $N(\epsilon)$ necessarily is a non-increasing  function of $\epsilon$. But I can't see this physically. I can think of instances in which the sequence may close up, then diverge, then close up again at infinity. What stops the sequence from coming as close as $\epsilon_1$ to the limit, then diverging, then coming back after some elements. Of course, the Cauchy sequence does not allow this, but I don't see how this instance violates the basic definition of an existence of a limit. The basic definition simply requires that $\forall \epsilon >0\exists N \in \mathbb{N}\  s.t. |s_n -s| < \epsilon$. There is no rule on the $\epsilon$ increasing with $N$.","I can understand the proof, which I could do myself: $|s_n - s_m| = |s_n - s + s - s_m|$ $\Rightarrow |s_n - s_m|  \leq |s_n - s| + |s_m - s|  $ For some $\epsilon > 0, \exists\ \ N(\epsilon) \in \mathbb{N} s.t.$ $ |s_n - s_m|  \leq \epsilon + \epsilon \ \  \forall \ \  m,n > N(\epsilon)$ $\therefore |s_n - s_m| \leq 2\epsilon$ where $2\epsilon \in \mathbb{R}$ The fact that the Cauchy sequence gradually closes up, i.e. the elements get closer together in obvious from the last point. $N(\epsilon)$ necessarily is a non-increasing  function of $\epsilon$. But I can't see this physically. I can think of instances in which the sequence may close up, then diverge, then close up again at infinity. What stops the sequence from coming as close as $\epsilon_1$ to the limit, then diverging, then coming back after some elements. Of course, the Cauchy sequence does not allow this, but I don't see how this instance violates the basic definition of an existence of a limit. The basic definition simply requires that $\forall \epsilon >0\exists N \in \mathbb{N}\  s.t. |s_n -s| < \epsilon$. There is no rule on the $\epsilon$ increasing with $N$.",,"['limits', 'cauchy-sequences']"
64,How to solve this: $\lim_{n \rightarrow \infty} \frac{3}{n} \sum_{k=1}^n \left(\frac{2n+3k}{n} \right)^2$,How to solve this:,\lim_{n \rightarrow \infty} \frac{3}{n} \sum_{k=1}^n \left(\frac{2n+3k}{n} \right)^2,How to solve this: $$\lim_{n \rightarrow \infty} \frac{3}{n} \sum_{k=1}^n \left(\frac{2n+3k}{n} \right)^2$$ The answer is supposed to be 39. My attempt: $$\frac{3}{n}\sum\left(4+\frac{12}{n}k+\frac{9}{n^{2}}k^{2}\right)=\frac{3}{n}\left(4+\frac{12}{n}\sum k+\frac{9}{n^{2}}\sum k^{2}\right)=\frac{3}{n}\left(4+\frac{12}{n}\frac{n}{2}\left(n+1\right)+\frac{9}{n^{2}}\frac{n}{6}\left(n+1\right)\left(2n+1\right)\right)=3\left(6+3\right)=27\neq39$$,How to solve this: $$\lim_{n \rightarrow \infty} \frac{3}{n} \sum_{k=1}^n \left(\frac{2n+3k}{n} \right)^2$$ The answer is supposed to be 39. My attempt: $$\frac{3}{n}\sum\left(4+\frac{12}{n}k+\frac{9}{n^{2}}k^{2}\right)=\frac{3}{n}\left(4+\frac{12}{n}\sum k+\frac{9}{n^{2}}\sum k^{2}\right)=\frac{3}{n}\left(4+\frac{12}{n}\frac{n}{2}\left(n+1\right)+\frac{9}{n^{2}}\frac{n}{6}\left(n+1\right)\left(2n+1\right)\right)=3\left(6+3\right)=27\neq39$$,,"['calculus', 'sequences-and-series', 'limits']"
65,Does the limit of a sequence with floor function exist?,Does the limit of a sequence with floor function exist?,,"Question : Let $a_n=n\alpha-\lfloor n\alpha\rfloor\ (n=1,2,\cdots)$ where $\alpha$ is an irrational number. Then, does the limit $n\to\infty$ of $(a_n)^n$ exist? I know that $\lim_{n\to\infty}(a_n)^n=0$ for a rational number $\alpha$. However, I don't have any good idea to solve the question. Can anyone help? $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $","Question : Let $a_n=n\alpha-\lfloor n\alpha\rfloor\ (n=1,2,\cdots)$ where $\alpha$ is an irrational number. Then, does the limit $n\to\infty$ of $(a_n)^n$ exist? I know that $\lim_{n\to\infty}(a_n)^n=0$ for a rational number $\alpha$. However, I don't have any good idea to solve the question. Can anyone help? $\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ $",,"['number-theory', 'limits', 'irrational-numbers']"
66,I need help solving these limits [closed],I need help solving these limits [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I've been struggling to solve the following limits for about an hour. I've tried using conjugates as well as common factors, but it gets me nowhere. Wolfram Alpha does not provide steps for these limits. I could really use some help. (x greater than 1) ( SOLVED ) ( SOLVED ) Thanks for taking your time!","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 9 years ago . Improve this question I've been struggling to solve the following limits for about an hour. I've tried using conjugates as well as common factors, but it gets me nowhere. Wolfram Alpha does not provide steps for these limits. I could really use some help. (x greater than 1) ( SOLVED ) ( SOLVED ) Thanks for taking your time!",,['limits']
67,Limit of an unusual function?,Limit of an unusual function?,,"First, I define the function, $f(k)=1$ if the sum of the factors of $k$ (excluding $k$) is greater than $k$, $f(k)=-1$ if the sum of the factors of $k$ (excluding $k$) is less than $k$, and $f(k)=0$ if $k$ is a perfect number for $k\in\mathbb{N}$. Is it possible to know the value of the limit $$\lim_{n\rightarrow\infty}\frac{\sum_{k=1}^nf(k)}{n}?$$If so, what is it and how does one calculate it?","First, I define the function, $f(k)=1$ if the sum of the factors of $k$ (excluding $k$) is greater than $k$, $f(k)=-1$ if the sum of the factors of $k$ (excluding $k$) is less than $k$, and $f(k)=0$ if $k$ is a perfect number for $k\in\mathbb{N}$. Is it possible to know the value of the limit $$\lim_{n\rightarrow\infty}\frac{\sum_{k=1}^nf(k)}{n}?$$If so, what is it and how does one calculate it?",,"['elementary-number-theory', 'limits', 'summation']"
68,If $\lim_{x\to \infty} f(x) + f'(x) = L$... [duplicate],If ... [duplicate],\lim_{x\to \infty} f(x) + f'(x) = L,"This question already has answers here : If $\lim_{x\to\infty}(f(x)+f'(x))=L$ show that $\lim_{x\to\infty} f(x) = L$ and $\lim_{x\to\infty} f'(x) = 0$ [duplicate] (2 answers) Closed 10 years ago . How can I prove $\lim_{x\to \infty} f(x) = L$ ? I tried to prove by L'Hospital's Rule, but I only proved when the limit exists... How can I prove when I am not provided that the limit exists?","This question already has answers here : If $\lim_{x\to\infty}(f(x)+f'(x))=L$ show that $\lim_{x\to\infty} f(x) = L$ and $\lim_{x\to\infty} f'(x) = 0$ [duplicate] (2 answers) Closed 10 years ago . How can I prove $\lim_{x\to \infty} f(x) = L$ ? I tried to prove by L'Hospital's Rule, but I only proved when the limit exists... How can I prove when I am not provided that the limit exists?",,"['real-analysis', 'limits']"
69,How to show a sequence converges given that $\lim_{n \to \infty} u_n + \frac{u_{2n}}{2} = 1$,How to show a sequence converges given that,\lim_{n \to \infty} u_n + \frac{u_{2n}}{2} = 1,Let $u_n$ be a bounded sequence of real numbers. Suppose that $$\lim_{n \to \infty} u_n + \frac{u_{2n}}{2} = 1$$ Show that $u_n$ converges. Can someone provide some hints or insight to this problem or similar? I don't really know where to start.,Let $u_n$ be a bounded sequence of real numbers. Suppose that $$\lim_{n \to \infty} u_n + \frac{u_{2n}}{2} = 1$$ Show that $u_n$ converges. Can someone provide some hints or insight to this problem or similar? I don't really know where to start.,,"['calculus', 'real-analysis', 'sequences-and-series', 'limits']"
70,Limit of $f(x)=\frac{x}{1+\sin^2x}$ as $x\to0$ and proof,Limit of  as  and proof,f(x)=\frac{x}{1+\sin^2x} x\to0,"I computed the limit using the limit theorems and the answer is obviously $0$. So now I am attempting to prove it using the $\epsilon,\delta$  definition. $f(x)=\frac{x}{1+\sin^2x}$ $|\frac{x}{1+\sin^2x}|<\epsilon$ if $|x|<\delta$ $|x|<\epsilon|1+\sin^2x|$ $|\sin x|<1$ $\implies$ $|\sin^2x|<1$ $\implies$ $1+|\sin^2x|<2$ $\implies$ $|1+\sin^2x|<1+|\sin^2x|<2$ $\implies$  $|1+\sin^2x|<2$ $\implies$ $\epsilon|1+\sin^2x|<2\epsilon$ Finally, $|x|<\epsilon|1+\sin^2x|<2\epsilon$ $\implies$ $|x|<2\epsilon=\delta$ But when I plug $\epsilon=0.2$ then the $\delta=0.4$. If I put my $x=0.3<0.4$ then the answer is $0.3>0.2=\epsilon$. What am I doing wrong here ? Also sometimes Spivak assumes (for example in $|x^2-a^2|<\epsilon$ if $|x-a|<\delta$) that $|x-a|<1$ and chooses $\min(1,\frac{\epsilon}{2|a|+1})$ I cant understand how is it possible to make the assumption that $|x-a|<1=\delta$ if our objective IS to find $\delta$ to prove that this $\delta$ exists for every $\epsilon$. Isnt this circular reasoning ? Otherwise we can just choose that $\delta=\frac{\epsilon}{10000000}$ (10000000 is an arbitrary number that makes delta very small). Also in the example $|x^2-a^2|<\epsilon$ if $|x-a|<\delta$ assuming by some magical means that $|x-a|<1$ then $|x|-|a|<|x-a|<1$ $\implies$ $|x|<1 + |a|$ $\implies$ $|x+a|<|x|+|a|<2|a|+1$ $\implies$ $\frac{1}{|x+a|}>\frac{1}{2|a|+1}$ $\implies$ $\frac{\epsilon}{|x+a|}>\frac{\epsilon}{2|a|+1}$. And since $|x-a|<\frac{\epsilon}{|x+a|} >\frac{\epsilon}{2|a|+1}$ isn't it WRONG to write $|x-a|< \frac{\epsilon}{2|a|+1}$ since we DONT know if  $|x-a|< \frac{\epsilon}{2|a|+1}$ is true or not ? Apologies for the long question but limits have been utterly confusing me for a long while now.","I computed the limit using the limit theorems and the answer is obviously $0$. So now I am attempting to prove it using the $\epsilon,\delta$  definition. $f(x)=\frac{x}{1+\sin^2x}$ $|\frac{x}{1+\sin^2x}|<\epsilon$ if $|x|<\delta$ $|x|<\epsilon|1+\sin^2x|$ $|\sin x|<1$ $\implies$ $|\sin^2x|<1$ $\implies$ $1+|\sin^2x|<2$ $\implies$ $|1+\sin^2x|<1+|\sin^2x|<2$ $\implies$  $|1+\sin^2x|<2$ $\implies$ $\epsilon|1+\sin^2x|<2\epsilon$ Finally, $|x|<\epsilon|1+\sin^2x|<2\epsilon$ $\implies$ $|x|<2\epsilon=\delta$ But when I plug $\epsilon=0.2$ then the $\delta=0.4$. If I put my $x=0.3<0.4$ then the answer is $0.3>0.2=\epsilon$. What am I doing wrong here ? Also sometimes Spivak assumes (for example in $|x^2-a^2|<\epsilon$ if $|x-a|<\delta$) that $|x-a|<1$ and chooses $\min(1,\frac{\epsilon}{2|a|+1})$ I cant understand how is it possible to make the assumption that $|x-a|<1=\delta$ if our objective IS to find $\delta$ to prove that this $\delta$ exists for every $\epsilon$. Isnt this circular reasoning ? Otherwise we can just choose that $\delta=\frac{\epsilon}{10000000}$ (10000000 is an arbitrary number that makes delta very small). Also in the example $|x^2-a^2|<\epsilon$ if $|x-a|<\delta$ assuming by some magical means that $|x-a|<1$ then $|x|-|a|<|x-a|<1$ $\implies$ $|x|<1 + |a|$ $\implies$ $|x+a|<|x|+|a|<2|a|+1$ $\implies$ $\frac{1}{|x+a|}>\frac{1}{2|a|+1}$ $\implies$ $\frac{\epsilon}{|x+a|}>\frac{\epsilon}{2|a|+1}$. And since $|x-a|<\frac{\epsilon}{|x+a|} >\frac{\epsilon}{2|a|+1}$ isn't it WRONG to write $|x-a|< \frac{\epsilon}{2|a|+1}$ since we DONT know if  $|x-a|< \frac{\epsilon}{2|a|+1}$ is true or not ? Apologies for the long question but limits have been utterly confusing me for a long while now.",,"['calculus', 'real-analysis', 'limits', 'proof-verification', 'epsilon-delta']"
71,How to find $\lim_{x\to\ln 2} \frac{2e^{3x}-16}{3e^{2x}-12}$?,How to find ?,\lim_{x\to\ln 2} \frac{2e^{3x}-16}{3e^{2x}-12},"Need to find without using L'Hopital's rule or derivatives. I know the answer is 2, but how can I find this analytically, without using limit tables? Thanks!","Need to find without using L'Hopital's rule or derivatives. I know the answer is 2, but how can I find this analytically, without using limit tables? Thanks!",,"['calculus', 'limits']"
72,How to prove series convergence: $\sum \limits_{n=1}^\infty \left(\frac1n+\sqrt{1+n^2}-\sqrt{2+n^2}\right)^2$,How to prove series convergence:,\sum \limits_{n=1}^\infty \left(\frac1n+\sqrt{1+n^2}-\sqrt{2+n^2}\right)^2,I have this series: $$\sum \limits_{n=1}^\infty \left(\frac1n+\sqrt{1+n^2}-\sqrt{2+n^2}\right)^2$$ I know that it's convergent (from WolframAlpha) but I need to prove it is convergent. How can I do it?,I have this series: $$\sum \limits_{n=1}^\infty \left(\frac1n+\sqrt{1+n^2}-\sqrt{2+n^2}\right)^2$$ I know that it's convergent (from WolframAlpha) but I need to prove it is convergent. How can I do it?,,"['sequences-and-series', 'limits']"
73,Limit and supremum conceptual question,Limit and supremum conceptual question,,"Is it true that for a monotone increasing sequence, the limit of the sequence must be its supremum, but the supremum of the sequence might not be its limit? Else what is the relationship between supremum and limit. Are they the same? How to prove the relationship?","Is it true that for a monotone increasing sequence, the limit of the sequence must be its supremum, but the supremum of the sequence might not be its limit? Else what is the relationship between supremum and limit. Are they the same? How to prove the relationship?",,"['real-analysis', 'sequences-and-series', 'limits']"
74,Using epsilon -delta definition to show that $\lim_{x \rightarrow 2} (x^3 + \sqrt[3]{x}) = 8+ \sqrt[3]{2} $,Using epsilon -delta definition to show that,\lim_{x \rightarrow 2} (x^3 + \sqrt[3]{x}) = 8+ \sqrt[3]{2} ,"I'm trying to use the  $\varepsilon$-$\delta$ definition to show that $\lim\limits_{x \rightarrow 2} (x^3 + \sqrt[3]{x}) = 8+ \sqrt[3]{2} $. I already know how to prove continuity for cubic root using $\epsilon$-$\delta$, but now that it's mixed up with cubed $x$, I'm confused. What I've done so far is this: I need to show that $\forall\varepsilon>0, \exists \delta >0$ s.t. if $0<|x-2|<\delta$ then $|x^3+\sqrt[3]{x}-8-\sqrt[3]{2}|<\varepsilon$. I've organized the $|x^3 +\sqrt[3]{x}-8-\sqrt[3]{2} |$ to $|x-2|\left|\frac{(x^2+2x+4)( x^{2/3}+(2x)^{1/3}+2^{2/3})+1 }{x^{2/3}+(2x)^{1/3}+2^{2/3}}\right|$. Now I think I need to make sure that $x^{2/3}+(2x)^{1/3}+2^{2/3}$ doesn't get too small, but I have no idea how. How should I set $\delta$?","I'm trying to use the  $\varepsilon$-$\delta$ definition to show that $\lim\limits_{x \rightarrow 2} (x^3 + \sqrt[3]{x}) = 8+ \sqrt[3]{2} $. I already know how to prove continuity for cubic root using $\epsilon$-$\delta$, but now that it's mixed up with cubed $x$, I'm confused. What I've done so far is this: I need to show that $\forall\varepsilon>0, \exists \delta >0$ s.t. if $0<|x-2|<\delta$ then $|x^3+\sqrt[3]{x}-8-\sqrt[3]{2}|<\varepsilon$. I've organized the $|x^3 +\sqrt[3]{x}-8-\sqrt[3]{2} |$ to $|x-2|\left|\frac{(x^2+2x+4)( x^{2/3}+(2x)^{1/3}+2^{2/3})+1 }{x^{2/3}+(2x)^{1/3}+2^{2/3}}\right|$. Now I think I need to make sure that $x^{2/3}+(2x)^{1/3}+2^{2/3}$ doesn't get too small, but I have no idea how. How should I set $\delta$?",,"['calculus', 'real-analysis', 'limits', 'proof-verification']"
75,How to answer the question from Calculus by Michael Spivak Chapter 5 Problem 14,How to answer the question from Calculus by Michael Spivak Chapter 5 Problem 14,,"Prove that if $\lim\limits_{x\rightarrow0}{\frac{f(x)}x}=l$ and $b\neq 0$, then $\lim\limits_{x\rightarrow0}{\frac{f(bx)}x}=bl$. Hint: Write $\frac{f(bx)}x=b\frac{f(bx)}{bx}$ What happens if $b=0$? Part 1 enables us to find $\lim\limits_{x\rightarrow0}{\frac{\sin{2x}}{x}}$ in terms of $\lim\limits_{x\to0}\frac{\sin x}x$. Find this limit in another way. This is a question from Calculus by Michael Spivak Chapter 5 Problem 14.","Prove that if $\lim\limits_{x\rightarrow0}{\frac{f(x)}x}=l$ and $b\neq 0$, then $\lim\limits_{x\rightarrow0}{\frac{f(bx)}x}=bl$. Hint: Write $\frac{f(bx)}x=b\frac{f(bx)}{bx}$ What happens if $b=0$? Part 1 enables us to find $\lim\limits_{x\rightarrow0}{\frac{\sin{2x}}{x}}$ in terms of $\lim\limits_{x\to0}\frac{\sin x}x$. Find this limit in another way. This is a question from Calculus by Michael Spivak Chapter 5 Problem 14.",,"['calculus', 'limits']"
76,"If $\lim f(x)$ and $\lim g(x)$ do not exist, can the $\lim [f(x)+g(x)]$ exist?","If  and  do not exist, can the  exist?",\lim f(x) \lim g(x) \lim [f(x)+g(x)],"This is a question from Calculus by Michael Spivak, how do start answering this question?","This is a question from Calculus by Michael Spivak, how do start answering this question?",,"['calculus', 'limits']"
77,Limit in which terms involve n,Limit in which terms involve n,,Limit n goes to infinity $\frac{1}{n}+\frac{1}{n+1}+......+\frac{1}{n+2n}$. Well the answer came out log[3].. but i dont know how.? I am trying for MCA. please don't tell complete answer just a hint would be useful,Limit n goes to infinity $\frac{1}{n}+\frac{1}{n+1}+......+\frac{1}{n+2n}$. Well the answer came out log[3].. but i dont know how.? I am trying for MCA. please don't tell complete answer just a hint would be useful,,['limits']
78,Proof of something that doesn't exist,Proof of something that doesn't exist,,"Let $\lfloor x \rfloor$ be the greatest integer function.  Show that the $\lim_{x\to 2} \frac{1}{\lfloor x \rfloor}$ does not exist. So far I have: Assume the limit exists.  Choose $\epsilon =1>0$.  Then for this $\epsilon$, there exists a $\delta>0$ such that if $x_1$ and $x_2$ satisfy $0<|x-0|<\delta$, then by the 2 Point Lemma the absolute value of $f(x_1)-f(x_2)<\epsilon=1$.  Since $\delta>0$, but the Archimedian property, there exists some $n \in \mathbb{N}$ such that $-\delta<-1/n<0<1/n<\delta$.  Choose $x_1=1/n$ and $x_2=-1/n$.  Thus $|\lfloor n\rfloor-(-\lfloor n \rfloor)|=|2\lfloor n \rfloor|\ge 2$.  This produces the contradiction that $2<1$, thus the limit does not exist. Is this right, wrong, anybody indifferent?","Let $\lfloor x \rfloor$ be the greatest integer function.  Show that the $\lim_{x\to 2} \frac{1}{\lfloor x \rfloor}$ does not exist. So far I have: Assume the limit exists.  Choose $\epsilon =1>0$.  Then for this $\epsilon$, there exists a $\delta>0$ such that if $x_1$ and $x_2$ satisfy $0<|x-0|<\delta$, then by the 2 Point Lemma the absolute value of $f(x_1)-f(x_2)<\epsilon=1$.  Since $\delta>0$, but the Archimedian property, there exists some $n \in \mathbb{N}$ such that $-\delta<-1/n<0<1/n<\delta$.  Choose $x_1=1/n$ and $x_2=-1/n$.  Thus $|\lfloor n\rfloor-(-\lfloor n \rfloor)|=|2\lfloor n \rfloor|\ge 2$.  This produces the contradiction that $2<1$, thus the limit does not exist. Is this right, wrong, anybody indifferent?",,"['limits', 'proof-writing', 'proof-verification']"
79,Showing that $\lim\limits_{n \to\infty} z_n = A$ implies $\lim\limits_{n \to\infty} \frac{1}{n} (z_1 + z_2 + \ldots + z_n) = A$ [duplicate],Showing that  implies  [duplicate],\lim\limits_{n \to\infty} z_n = A \lim\limits_{n \to\infty} \frac{1}{n} (z_1 + z_2 + \ldots + z_n) = A,"This question already has answers here : On Cesàro convergence: If $x_n \to x$ then $z_n = \frac{x_1 + \dots +x_n}{n} \to x$ (3 answers) Prove convergence of the sequence $(z_1+z_2+\cdots + z_n)/n$ of Cesaro means [duplicate] (3 answers) Closed 4 years ago . In what follows let all values be in $\mathbb{C}$.  I'm trying to show that if $$\lim z_n = A,$$ that then $$ \lim_{n \to \infty} \frac{1}{n} (z_1 + z_2 + \ldots + z_n) = A. $$ For ease of notation, let $s_n = \frac{1}{n} (z_1 + z_2 + \ldots + z_n)$. Attempt: Let $n \in \mathbb{N}$ be arbitrary and consider that $$ \left| A - s_n \right| = \left|A - \frac{1}{n} (z_1 + \ldots + z_n) \right| = \left|A - \frac{z_1}{n} - \ldots - \frac{z_n}{n} \right|  $$ so that through repeated applications of the triangle inequality we have that $$ \left| A - s_n \right| \le \left| A - \frac{z_n}{n} \right| + \left| - \frac{z_{n-1}}{n} - \ldots - \frac{z_{1}}{n} \right| \le \left| A - \frac{z_n}{n} \right| + \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right| $$ Now as $n \rightarrow \infty$, we have that the numerator of the term  $\left| -\frac{z_{n-1}}{n} \right|$ approaches $-A$ while the denominators of all of the terms in the sum $\left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right|$ approach infinity.  \uline{[Gap]}. Then as $n \rightarrow  \infty$, we have that $\left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right|$ approaches $0$. On the other hand, we have also that $z_n \rightarrow A$ (by hypothesis) so that the term $\left| A - \frac{z_n}{n} \right|$ can get as close to $\left| A - \frac{A}{n} \right|$ as we'd like.  Yet since $\frac{A}{n} \rightarrow 0$, we have that $\left| A - \frac{z_n}{n} \right| \rightarrow \left| A - 0 \right| = \left| A \right|$. Then since $$ \left( \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right| \right) \rightarrow 0 $$ and $$ \left| A - \frac{z_n}{n} \right| \rightarrow \left| A \right| $$ we have that $$ |A - s_n| \le \left| A - \frac{z_n}{n} \right| + \left( \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right| \right) \rightarrow |A| + 0 = |A|. $$ Question: My argument doesn't quite work since I have shown only that $|A - s_n| \rightarrow |A|$ and yet we want $|A - s_n| \rightarrow |0|$.  Is there a way to keep most of my argument in place and yet actually to prove the desired statement?","This question already has answers here : On Cesàro convergence: If $x_n \to x$ then $z_n = \frac{x_1 + \dots +x_n}{n} \to x$ (3 answers) Prove convergence of the sequence $(z_1+z_2+\cdots + z_n)/n$ of Cesaro means [duplicate] (3 answers) Closed 4 years ago . In what follows let all values be in $\mathbb{C}$.  I'm trying to show that if $$\lim z_n = A,$$ that then $$ \lim_{n \to \infty} \frac{1}{n} (z_1 + z_2 + \ldots + z_n) = A. $$ For ease of notation, let $s_n = \frac{1}{n} (z_1 + z_2 + \ldots + z_n)$. Attempt: Let $n \in \mathbb{N}$ be arbitrary and consider that $$ \left| A - s_n \right| = \left|A - \frac{1}{n} (z_1 + \ldots + z_n) \right| = \left|A - \frac{z_1}{n} - \ldots - \frac{z_n}{n} \right|  $$ so that through repeated applications of the triangle inequality we have that $$ \left| A - s_n \right| \le \left| A - \frac{z_n}{n} \right| + \left| - \frac{z_{n-1}}{n} - \ldots - \frac{z_{1}}{n} \right| \le \left| A - \frac{z_n}{n} \right| + \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right| $$ Now as $n \rightarrow \infty$, we have that the numerator of the term  $\left| -\frac{z_{n-1}}{n} \right|$ approaches $-A$ while the denominators of all of the terms in the sum $\left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right|$ approach infinity.  \uline{[Gap]}. Then as $n \rightarrow  \infty$, we have that $\left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right|$ approaches $0$. On the other hand, we have also that $z_n \rightarrow A$ (by hypothesis) so that the term $\left| A - \frac{z_n}{n} \right|$ can get as close to $\left| A - \frac{A}{n} \right|$ as we'd like.  Yet since $\frac{A}{n} \rightarrow 0$, we have that $\left| A - \frac{z_n}{n} \right| \rightarrow \left| A - 0 \right| = \left| A \right|$. Then since $$ \left( \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right| \right) \rightarrow 0 $$ and $$ \left| A - \frac{z_n}{n} \right| \rightarrow \left| A \right| $$ we have that $$ |A - s_n| \le \left| A - \frac{z_n}{n} \right| + \left( \left| -\frac{z_{n-1}}{n} \right| + \ldots + \left|- \frac{z_{1}}{n} \right| \right) \rightarrow |A| + 0 = |A|. $$ Question: My argument doesn't quite work since I have shown only that $|A - s_n| \rightarrow |A|$ and yet we want $|A - s_n| \rightarrow |0|$.  Is there a way to keep most of my argument in place and yet actually to prove the desired statement?",,"['sequences-and-series', 'limits', 'analysis']"
80,Explanation for an equality (series),Explanation for an equality (series),,$$\mathop {\lim }\limits_{x \to 0} \left( {\frac{1}{2} + \frac{x}{{3!}} + \frac{{{x^2}}}{{4!}} + \frac{{{x^3}}}{{5!}} + ...} \right) = \frac{1}{2}$$ Why can one claim this equality? Thanks.,$$\mathop {\lim }\limits_{x \to 0} \left( {\frac{1}{2} + \frac{x}{{3!}} + \frac{{{x^2}}}{{4!}} + \frac{{{x^3}}}{{5!}} + ...} \right) = \frac{1}{2}$$ Why can one claim this equality? Thanks.,,"['sequences-and-series', 'limits']"
81,What is $\lim_{n \to \infty} \space n^2\int_{0}^{1/n} x^{x+1} dx$?,What is ?,\lim_{n \to \infty} \space n^2\int_{0}^{1/n} x^{x+1} dx,"How do we evaluate $$\lim_{n \to \infty} \space n^2\int_{0}^{1/n} x^{x+1} dx\quad ?$$ I know that $$\lim_{z \to 0+} \space \dfrac{\int_{0}^z x^{x+1} dx}{z^2}=\dfrac12,$$ and I think the asked limit should also be $1/2$ but I can not prove it. Please help.","How do we evaluate $$\lim_{n \to \infty} \space n^2\int_{0}^{1/n} x^{x+1} dx\quad ?$$ I know that $$\lim_{z \to 0+} \space \dfrac{\int_{0}^z x^{x+1} dx}{z^2}=\dfrac12,$$ and I think the asked limit should also be $1/2$ but I can not prove it. Please help.",,['sequences-and-series']
82,Evaluating a limit involves parameters,Evaluating a limit involves parameters,,"Let $a,b>0$: $$\mathop {\lim }\limits_{n \to \infty } {({a^n} + {b^n})^{\frac{1}{n}}}$$ At first look, it seemed simple, yet I couldn't evaluate it. Maybe Squeeze Thm?","Let $a,b>0$: $$\mathop {\lim }\limits_{n \to \infty } {({a^n} + {b^n})^{\frac{1}{n}}}$$ At first look, it seemed simple, yet I couldn't evaluate it. Maybe Squeeze Thm?",,"['calculus', 'limits']"
83,Proving the Limit of a Sequence of without the Dominated Convergence Theorem,Proving the Limit of a Sequence of without the Dominated Convergence Theorem,,Show: $$ \lim_{n\to \infty} \int_{0}^{\frac{\pi }{2}} \sin^n(x) = 0. $$ I showed this using the dominated convergence theorem . I want other methods to prove it. Thank you.,Show: $$ \lim_{n\to \infty} \int_{0}^{\frac{\pi }{2}} \sin^n(x) = 0. $$ I showed this using the dominated convergence theorem . I want other methods to prove it. Thank you.,,"['real-analysis', 'limits']"
84,Strategy for tackling the $\lim_{n\to+\infty}\frac{(-1)^nn}{(1+n)^n}$,Strategy for tackling the,\lim_{n\to+\infty}\frac{(-1)^nn}{(1+n)^n},What strategy should I use to calculate this limit? Can I avoid using Hopital? $$\lim_{n\to+\infty}\frac{(-1)^nn}{(1+n)^n}$$ Thank you in advance.,What strategy should I use to calculate this limit? Can I avoid using Hopital? $$\lim_{n\to+\infty}\frac{(-1)^nn}{(1+n)^n}$$ Thank you in advance.,,['limits']
85,Limit of function with three variables,Limit of function with three variables,,"given is $f(x,y,z) = \frac{xy + yz}{x^2+y^2+z^2}$. I want the limit for this function for $(x,y,z)\to(0,0,0)$. Since I haven't done this ($=$calculating a limit for a function with more than $1$ variable), I'm not sure what to do. But having taken a look at some specific examples I found on the internet, I tried doing this: $f(x,y,0) = \frac{0}{x^2} \to 0$. Same for $f(x,0,z)$ and $f(0,y,z)$. $f(x,x,0) = \frac{1}{2}$. So since the limits are not the same, the whole function is not convergent. I'm grateful for any kind of help!","given is $f(x,y,z) = \frac{xy + yz}{x^2+y^2+z^2}$. I want the limit for this function for $(x,y,z)\to(0,0,0)$. Since I haven't done this ($=$calculating a limit for a function with more than $1$ variable), I'm not sure what to do. But having taken a look at some specific examples I found on the internet, I tried doing this: $f(x,y,0) = \frac{0}{x^2} \to 0$. Same for $f(x,0,z)$ and $f(0,y,z)$. $f(x,x,0) = \frac{1}{2}$. So since the limits are not the same, the whole function is not convergent. I'm grateful for any kind of help!",,"['analysis', 'limits', 'convergence-divergence']"
86,calculus limit question: another difficult limit problem,calculus limit question: another difficult limit problem,,"I have posted previously on a problem in a similar vein here: Limit evaluation: very tough question, cannot use L'hopitals rule I believe this problem is very similar, but it has stumped me. $$\lim_{x \to 0}\frac{1-\frac12 x^2 - \cos\left(\frac{x}{1-x^2}\right)}{x^4}$$ Really appreciate it if someone has some insight on this.This comes out to be indeterminate if one plugs in zero. Following the idea from the link above, I tried to recognize this as derivative evaluated at zero of a function, BUT I could not find the function, because I tried to make this all over x, so that means the function I would create would generate a rational type with x^3 on the bottom. I guess I should also try to look at some trig limit identities as well. Hope someone out there can see how to navigate this problem. P","I have posted previously on a problem in a similar vein here: Limit evaluation: very tough question, cannot use L'hopitals rule I believe this problem is very similar, but it has stumped me. $$\lim_{x \to 0}\frac{1-\frac12 x^2 - \cos\left(\frac{x}{1-x^2}\right)}{x^4}$$ Really appreciate it if someone has some insight on this.This comes out to be indeterminate if one plugs in zero. Following the idea from the link above, I tried to recognize this as derivative evaluated at zero of a function, BUT I could not find the function, because I tried to make this all over x, so that means the function I would create would generate a rational type with x^3 on the bottom. I guess I should also try to look at some trig limit identities as well. Hope someone out there can see how to navigate this problem. P",,"['calculus', 'limits']"
87,Show that $p$ is prime if the following limit property holds,Show that  is prime if the following limit property holds,p,Let $n$ be a positive integer. Show that $n$ is prime if and only if $$\lim_{r\to \infty}\lim_{s\to\infty} \lim_{t\to\infty} \sum_{k=0}^s\left(1-\left(\cos\left(\frac{(k!)^r\pi}{n}\right)\right)^2t\right)=n$$,Let $n$ be a positive integer. Show that $n$ is prime if and only if $$\lim_{r\to \infty}\lim_{s\to\infty} \lim_{t\to\infty} \sum_{k=0}^s\left(1-\left(\cos\left(\frac{(k!)^r\pi}{n}\right)\right)^2t\right)=n$$,,"['elementary-number-theory', 'limits']"
88,Help clarify the limit of $e$ when there is an exponent,Help clarify the limit of  when there is an exponent,e,"I want to compute: $$\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right)^n$$ I know that: $$e = \lim_{x\to \infty}\left(1+\frac{1}{x}\right)^x$$ So, I let $x=-\frac{n}{\lambda}$ and get: $$\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right) = \lim_{n\to \infty} \left(1+\frac{1}{x}\right)^{x(-\lambda)} = e^{-\lambda}$$ My question is how do I justify going from $\lim_{n\to \infty} \left(1+\frac{1}{x}\right)^{x(-\lambda)}$ to $e^{-\lambda}$? I thought of the following: $$\lim_{n\to \infty} \left(1+\frac{1}{x}\right)^{x(-\lambda)}=\left[\lim_{n\to \infty} \left(1+\frac{1}{x}\right)^x\right]^{-\lambda} = \left[ e \right]^{-\lambda} = e^{-\lambda}$$ I don't think that is right since $-\lambda$ is part of the expression that I want to find the limit for and I don't recall ever learning that we can factor out an exponent from a limit expression. Please help.","I want to compute: $$\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right)^n$$ I know that: $$e = \lim_{x\to \infty}\left(1+\frac{1}{x}\right)^x$$ So, I let $x=-\frac{n}{\lambda}$ and get: $$\lim_{n\to \infty} \left(1-\frac{\lambda}{n}\right) = \lim_{n\to \infty} \left(1+\frac{1}{x}\right)^{x(-\lambda)} = e^{-\lambda}$$ My question is how do I justify going from $\lim_{n\to \infty} \left(1+\frac{1}{x}\right)^{x(-\lambda)}$ to $e^{-\lambda}$? I thought of the following: $$\lim_{n\to \infty} \left(1+\frac{1}{x}\right)^{x(-\lambda)}=\left[\lim_{n\to \infty} \left(1+\frac{1}{x}\right)^x\right]^{-\lambda} = \left[ e \right]^{-\lambda} = e^{-\lambda}$$ I don't think that is right since $-\lambda$ is part of the expression that I want to find the limit for and I don't recall ever learning that we can factor out an exponent from a limit expression. Please help.",,"['calculus', 'limits']"
89,Is it valid to write $\displaystyle \lim_{x \to 0} \frac{1}{x^2} = \infty$?,Is it valid to write ?,\displaystyle \lim_{x \to 0} \frac{1}{x^2} = \infty,"AFAIK the limit of a term does not exist if that term does not converge, but I haven't found a suiting question here yet.  This probably is a double of a similar question.","AFAIK the limit of a term does not exist if that term does not converge, but I haven't found a suiting question here yet.  This probably is a double of a similar question.",,"['calculus', 'limits', 'infinity']"
90,Prove: $\sum {{a_{{n_k}}}} < \infty \Rightarrow \sum {|{a_n}| < \infty } $,Prove:,\sum {{a_{{n_k}}}} < \infty \Rightarrow \sum {|{a_n}| < \infty } ,"Prove:  $$\sum {{a_{{n_k}}}}  < \infty  \Rightarrow \sum {|{a_n}| < \infty } $$ In words, if every sub-series of $\sum a_n$ converges then $\sum a_n$ converges absolutely. I know that: $$\liminf\sum {{a_n}}  \le \sum {{a_{{n_{}}}}}  \le \limsup \sum {{a_n}} $$ therefore, $\sum a_n$ is bounded, which implies $\sum a_n$ converges, but it doesn't tell me if the series converges absolutely. Other direction crossed my mind is splitting the series into two sub-series; odd-indices-series and even-indices-series, but I can't see how it can be helpful in this case.","Prove:  $$\sum {{a_{{n_k}}}}  < \infty  \Rightarrow \sum {|{a_n}| < \infty } $$ In words, if every sub-series of $\sum a_n$ converges then $\sum a_n$ converges absolutely. I know that: $$\liminf\sum {{a_n}}  \le \sum {{a_{{n_{}}}}}  \le \limsup \sum {{a_n}} $$ therefore, $\sum a_n$ is bounded, which implies $\sum a_n$ converges, but it doesn't tell me if the series converges absolutely. Other direction crossed my mind is splitting the series into two sub-series; odd-indices-series and even-indices-series, but I can't see how it can be helpful in this case.",,"['calculus', 'sequences-and-series', 'limits']"
91,Can this limit be solved algebraically?,Can this limit be solved algebraically?,,"I know it's pretty straight forward with L'Hopital's rule, but I was trying to solve algebraically to no avail. $$ \lim_{x\to 2} \frac{x^2+2x - 8}{\sqrt{x^2 + 5} - (x+1)}$$ The limit is $-18$, as discerned using L'Hopital's... Can we solve algebraically?","I know it's pretty straight forward with L'Hopital's rule, but I was trying to solve algebraically to no avail. $$ \lim_{x\to 2} \frac{x^2+2x - 8}{\sqrt{x^2 + 5} - (x+1)}$$ The limit is $-18$, as discerned using L'Hopital's... Can we solve algebraically?",,"['calculus', 'limits']"
92,Limit of a fraction of double factorials,Limit of a fraction of double factorials,,"How can we show that $\begin{align*} \lim_{n\rightarrow\infty} U_n = 0 \end{align*}$ where $\begin{align*} U_n = \frac{(n-1)!!}{n!!}=\frac{n-1}{n}\frac{n-3}{n-2}\frac{n-5}{n-4}\cdots \end{align*}$ terminates at $\displaystyle\frac{2}{3}$ (odd) or $\displaystyle\frac{1}{2}$ (even). At first glance I thought it was 1 because each individual multiplied fraction goes to 1 as $n\rightarrow\infty$. Mahthematica says this is not case, however. Does it help if I write it in recurrence relation? $\begin{align*} U_{n+2} = \frac{n+1}{n+2}U_n\\ U_{n+1} = \frac{1}{n+1}\frac{1}{U_n} \end{align*}$","How can we show that $\begin{align*} \lim_{n\rightarrow\infty} U_n = 0 \end{align*}$ where $\begin{align*} U_n = \frac{(n-1)!!}{n!!}=\frac{n-1}{n}\frac{n-3}{n-2}\frac{n-5}{n-4}\cdots \end{align*}$ terminates at $\displaystyle\frac{2}{3}$ (odd) or $\displaystyle\frac{1}{2}$ (even). At first glance I thought it was 1 because each individual multiplied fraction goes to 1 as $n\rightarrow\infty$. Mahthematica says this is not case, however. Does it help if I write it in recurrence relation? $\begin{align*} U_{n+2} = \frac{n+1}{n+2}U_n\\ U_{n+1} = \frac{1}{n+1}\frac{1}{U_n} \end{align*}$",,"['sequences-and-series', 'limits', 'recurrence-relations', 'factorial']"
93,How find this limit $\lim_{x\to 0^{+}}x^{x^{x^{\cdots}}}$,How find this limit,\lim_{x\to 0^{+}}x^{x^{x^{\cdots}}},"let $$f_{1}(x)=x,f_{2}(x)=x^x,f_{3}(x)=x^{x^x},f_{4}(x)=x^{x^{x^x}},\cdots,f_{n}(x)=x^{f_{n-1}(x)}$$ Find this follow two  limit (1):let $n<+\infty$ is give a postive integer number,and is  $$\lim_{x\to 0^{+}}f_{n}(x)=1?$$ (2) if  $n=+\infty$,then $$\lim_{x\to 0^{+}}f_{n}(x)=1?$$ My try: it is well know this  $$\lim_{x\to 0^{+}}x^x=e^{\lim_{x\to 0^{+}}x\ln{x}}=1$$ and $$\lim_{x\to 0^{+}}x^{x^x}=e^{\lim_{x\to 0^{+}}x^x\ln{x}}=1$$ and How can for any $n<+\infty$? Thank you","let $$f_{1}(x)=x,f_{2}(x)=x^x,f_{3}(x)=x^{x^x},f_{4}(x)=x^{x^{x^x}},\cdots,f_{n}(x)=x^{f_{n-1}(x)}$$ Find this follow two  limit (1):let $n<+\infty$ is give a postive integer number,and is  $$\lim_{x\to 0^{+}}f_{n}(x)=1?$$ (2) if  $n=+\infty$,then $$\lim_{x\to 0^{+}}f_{n}(x)=1?$$ My try: it is well know this  $$\lim_{x\to 0^{+}}x^x=e^{\lim_{x\to 0^{+}}x\ln{x}}=1$$ and $$\lim_{x\to 0^{+}}x^{x^x}=e^{\lim_{x\to 0^{+}}x^x\ln{x}}=1$$ and How can for any $n<+\infty$? Thank you",,['limits']
94,Why is acceleration $\frac{1}{2}at^2$ halved when finding final height (distance)?,Why is acceleration  halved when finding final height (distance)?,\frac{1}{2}at^2,"The final distance of an object dropped from a certain height is: $$S_f=S_0-\frac{1}{2}at^2,$$ $S_f=$ Final distance $S_0=$ Initial height from which the object was dropped $a=$ acceleration due to gravity (gravitational acceleration) $t=$ the time traveled by object. Why is $a$ halved? It goes from $9.8$ to $4.9$. Why is the time $t$ squared? These are basic equations, however, I couldn't find explanations as to the whys , only methodology telling me to ""plug in"". Thank you.","The final distance of an object dropped from a certain height is: $$S_f=S_0-\frac{1}{2}at^2,$$ $S_f=$ Final distance $S_0=$ Initial height from which the object was dropped $a=$ acceleration due to gravity (gravitational acceleration) $t=$ the time traveled by object. Why is $a$ halved? It goes from $9.8$ to $4.9$. Why is the time $t$ squared? These are basic equations, however, I couldn't find explanations as to the whys , only methodology telling me to ""plug in"". Thank you.",,"['calculus', 'limits', 'physics', 'mathematical-physics']"
95,Clarification on $\frac{0^n}{0}$ when $n>0$,Clarification on  when,\frac{0^n}{0} n>0,"If this is a duplicate, I will gladly delete this if there is a duplicate but I've had difficulty finding one.  I had, until recently, believed that we don't define $\frac 0 0$ as the limits coming from different directions vary widely and so no value works for all cases. I thought that $0^0$ wasn't defined as $0^1*0^{-1}=0^0=\frac 0 0$.  I have been corrected on this but am now confused about such numbers as $\frac {0^2} 0$. I had believed that as $\frac{0^2}{0} = 0^2*0^{-1} = 0^1 = 0$.  Is $\frac {0^n} 0$ for $n>1$ equal to zero as I had previously believed?  To be clear, I am mostly curious if I can state that $y=\frac{x^2}{x}$ is zero when $x=0$ or whether I have to specify that the limit as $x \rightarrow 0$ is $0$.","If this is a duplicate, I will gladly delete this if there is a duplicate but I've had difficulty finding one.  I had, until recently, believed that we don't define $\frac 0 0$ as the limits coming from different directions vary widely and so no value works for all cases. I thought that $0^0$ wasn't defined as $0^1*0^{-1}=0^0=\frac 0 0$.  I have been corrected on this but am now confused about such numbers as $\frac {0^2} 0$. I had believed that as $\frac{0^2}{0} = 0^2*0^{-1} = 0^1 = 0$.  Is $\frac {0^n} 0$ for $n>1$ equal to zero as I had previously believed?  To be clear, I am mostly curious if I can state that $y=\frac{x^2}{x}$ is zero when $x=0$ or whether I have to specify that the limit as $x \rightarrow 0$ is $0$.",,['limits']
96,How find this $\lim_{n\to\infty}\sum_{i=1}^{n}\left(\frac{i}{n}\right)^n$ [duplicate],How find this  [duplicate],\lim_{n\to\infty}\sum_{i=1}^{n}\left(\frac{i}{n}\right)^n,"This question already has answers here : What is $\lim_{n\to \infty}\sum_{k=1}^n \left(\frac{k}{n}\right)^n$? [duplicate] (4 answers) Closed 4 years ago . How find this $$\lim_{n\to\infty}\sum_{i=1}^{n}\left(\dfrac{i}{n}\right)^n$$ I think this answer is $\dfrac{e}{e-1}$ and I think this problem have more nice methods,Thank you","This question already has answers here : What is $\lim_{n\to \infty}\sum_{k=1}^n \left(\frac{k}{n}\right)^n$? [duplicate] (4 answers) Closed 4 years ago . How find this $$\lim_{n\to\infty}\sum_{i=1}^{n}\left(\dfrac{i}{n}\right)^n$$ I think this answer is $\dfrac{e}{e-1}$ and I think this problem have more nice methods,Thank you",,['limits']
97,Limit at Infinity $\lim\limits_{m\to\infty}\frac{\sum\limits_{k=1}^m\cot^{2n+1}\left(\frac{k\pi}{2m+1}\right)}{m^{2n+1}}$,Limit at Infinity,\lim\limits_{m\to\infty}\frac{\sum\limits_{k=1}^m\cot^{2n+1}\left(\frac{k\pi}{2m+1}\right)}{m^{2n+1}},How can I prove the following equality? $$\lim_{m\to{\infty}}\frac{\displaystyle\sum_{k=1}^m\cot^{2n+1}\left(\frac{k\pi}{2m+1}\right)}{m^{2n+1}}=\frac{2^{2n+1}\zeta(2n+1)}{\pi^{2n+1}}$$,How can I prove the following equality? $$\lim_{m\to{\infty}}\frac{\displaystyle\sum_{k=1}^m\cot^{2n+1}\left(\frac{k\pi}{2m+1}\right)}{m^{2n+1}}=\frac{2^{2n+1}\zeta(2n+1)}{\pi^{2n+1}}$$,,"['calculus', 'real-analysis', 'limits', 'closed-form', 'riemann-zeta']"
98,Is my answer correct? (And what's the name of the rule?)$\lim_{n \to \infty} \frac{\left(n+3\right)!-n!}{n\left(n+2\right)!}$,Is my answer correct? (And what's the name of the rule?),\lim_{n \to \infty} \frac{\left(n+3\right)!-n!}{n\left(n+2\right)!},"Want to know if I solved this problem correctly: $$\lim_{n \to \infty} \frac{\left(n+3\right)!-n!}{n\left(n+2\right)!} =\lim_{n \to \infty} \frac{1 \cdot 2 \ldots(n-1)n(n+1)(n+2)(n+3) - 1 \cdot 2 \ldots(n-1)n}{(1 \cdot 2 \ldots(n-1)n(n+1)(n+2))\cdot n}=\lim_{n \to \infty}\frac{(1 \cdot 2 \ldots(n-1) n)\cdot((n+1)(n+2)(n+3)-1)}{(1 \cdot 2 \ldots(n-1)n(n+1)(n+2))\cdot n} =\lim_{n \to \infty} \frac{(n+1)(n+2)(n+3)-1}{(n+1)(n+2)\cdot n} = \frac{1}{1}=1$$  The answer is 1 because we've got $n^3$ in numerator and $n^3 $ in denominator, and the constants are both equals 1 so the limit can be calculated as $\frac{1}{1}$. (Sorry I don't remember that rule. Could you remain me please?)","Want to know if I solved this problem correctly: $$\lim_{n \to \infty} \frac{\left(n+3\right)!-n!}{n\left(n+2\right)!} =\lim_{n \to \infty} \frac{1 \cdot 2 \ldots(n-1)n(n+1)(n+2)(n+3) - 1 \cdot 2 \ldots(n-1)n}{(1 \cdot 2 \ldots(n-1)n(n+1)(n+2))\cdot n}=\lim_{n \to \infty}\frac{(1 \cdot 2 \ldots(n-1) n)\cdot((n+1)(n+2)(n+3)-1)}{(1 \cdot 2 \ldots(n-1)n(n+1)(n+2))\cdot n} =\lim_{n \to \infty} \frac{(n+1)(n+2)(n+3)-1}{(n+1)(n+2)\cdot n} = \frac{1}{1}=1$$  The answer is 1 because we've got $n^3$ in numerator and $n^3 $ in denominator, and the constants are both equals 1 so the limit can be calculated as $\frac{1}{1}$. (Sorry I don't remember that rule. Could you remain me please?)",,"['real-analysis', 'limits']"
99,"Delta-Epsilon, find delta?","Delta-Epsilon, find delta?",,"I have to find a number $\delta$ such that if $|x-2|<\delta$ then $|4x-8|<\epsilon$ where $\epsilon=0.1$ Are the steps mentioned below correct? Step 1: Simplified the expression, $ 4|x-2|<\epsilon ==> |x-2|<\epsilon/4===> \epsilon=\delta/4 ==> \delta=0.1/4=0.025$ Is this the correct method to approach this problem?","I have to find a number $\delta$ such that if $|x-2|<\delta$ then $|4x-8|<\epsilon$ where $\epsilon=0.1$ Are the steps mentioned below correct? Step 1: Simplified the expression, $ 4|x-2|<\epsilon ==> |x-2|<\epsilon/4===> \epsilon=\delta/4 ==> \delta=0.1/4=0.025$ Is this the correct method to approach this problem?",,"['calculus', 'limits']"
