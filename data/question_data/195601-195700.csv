,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,differentability from a functional inequality,differentability from a functional inequality,,"Let $f$ be a non-negative continuous function on $[0,\infty)$ vanishing at $0$. If $f\left(\frac{x}{n}\right)$ does not exceed $\frac{f(x)}{n}$ for any $n,x$ show that $f$ has a finite right-hand derivative at $0$.","Let $f$ be a non-negative continuous function on $[0,\infty)$ vanishing at $0$. If $f\left(\frac{x}{n}\right)$ does not exceed $\frac{f(x)}{n}$ for any $n,x$ show that $f$ has a finite right-hand derivative at $0$.",,"['derivatives', 'continuity']"
1,Second derivative of the nuclear norm,Second derivative of the nuclear norm,,"The nuclear norm is defined in the following way $$\| X \|_* := \mbox{tr} \left( \sqrt{X^T X} \right)$$ and, from Derivative of the nuclear norm with respect to its argument , $$\frac{d}{dX} \| X \|_*  = U\Sigma^{-1}\mid\Sigma \mid V^T$$ What is the second derivative of the nuclear norm? $$\frac{d^2}{dX^2} \| X \|_* = ?$$ I need it to compute Newton's method for my algorithm and I haven't had much success. Any help would greatly be appreciated. Thanks in advance!","The nuclear norm is defined in the following way $$\| X \|_* := \mbox{tr} \left( \sqrt{X^T X} \right)$$ and, from Derivative of the nuclear norm with respect to its argument , $$\frac{d}{dX} \| X \|_*  = U\Sigma^{-1}\mid\Sigma \mid V^T$$ What is the second derivative of the nuclear norm? $$\frac{d^2}{dX^2} \| X \|_* = ?$$ I need it to compute Newton's method for my algorithm and I haven't had much success. Any help would greatly be appreciated. Thanks in advance!",,"['linear-algebra', 'derivatives', 'optimization', 'matrix-calculus', 'nuclear-norm']"
2,Rolle's Theorem: $f(x)=3-\left\lvert x-3 \right\rvert$,Rolle's Theorem:,f(x)=3-\left\lvert x-3 \right\rvert,"Determine whether Rolle's Theorem can be applied to the function on the closed interval of $[a,b]$ .  If Rolle's Theorem can be applied, find all values of c in the open interval $(a,b)$ such that $f'(c)=0$ . If Rolle's Theorem can not be applied explain why. $f(x)=3-\left\lvert x-3 \right\rvert$ in the interval of $[0,6]$ I began the problem by finding the derivative, and looking for the critical numbers and got that the critical number was at $x=3$ .  I also saw that the function was not differentiable in the interval of $[0,6]$ How would I word my answer, would I state that the function is not differentiable in the open interval of $(0,6)$ leading to Rolle's Theorem not be applicable in this certain scenario?","Determine whether Rolle's Theorem can be applied to the function on the closed interval of .  If Rolle's Theorem can be applied, find all values of c in the open interval such that . If Rolle's Theorem can not be applied explain why. in the interval of I began the problem by finding the derivative, and looking for the critical numbers and got that the critical number was at .  I also saw that the function was not differentiable in the interval of How would I word my answer, would I state that the function is not differentiable in the open interval of leading to Rolle's Theorem not be applicable in this certain scenario?","[a,b] (a,b) f'(c)=0 f(x)=3-\left\lvert x-3 \right\rvert [0,6] x=3 [0,6] (0,6)","['calculus', 'derivatives']"
3,Chain Rule $f(x) = (ax + b)^n$,Chain Rule,f(x) = (ax + b)^n,"So I'm fairly new to this and I just wanted to check my understanding of the chain rule . Suppose $f(x) = (ax + b)^n$ and we want to find $f'(x)$. We first work out the derivative of the first function, then multiply it to the derivative of the second function giving: $$n(ax +b)^{n-1}\cdot(ax+b)'$$ To calculate the derivative of the second function, we use the sum rule , but this is where I get a little stuck. I know I have to find both $ax'$ and $b'$, so here's how I think I should do it...please tell me if I'm crazy and wrong: As $b$ is a constant it follows that $b' = 0$. My textbook hasn't gone into this yet, so it isn't clear why. Anyway, moving on. This leaves us with: $$ax' = a$$ What I REALLY don't understand is why we don't use the product rule for $ax$. Any clues?","So I'm fairly new to this and I just wanted to check my understanding of the chain rule . Suppose $f(x) = (ax + b)^n$ and we want to find $f'(x)$. We first work out the derivative of the first function, then multiply it to the derivative of the second function giving: $$n(ax +b)^{n-1}\cdot(ax+b)'$$ To calculate the derivative of the second function, we use the sum rule , but this is where I get a little stuck. I know I have to find both $ax'$ and $b'$, so here's how I think I should do it...please tell me if I'm crazy and wrong: As $b$ is a constant it follows that $b' = 0$. My textbook hasn't gone into this yet, so it isn't clear why. Anyway, moving on. This leaves us with: $$ax' = a$$ What I REALLY don't understand is why we don't use the product rule for $ax$. Any clues?",,"['calculus', 'derivatives', 'chain-rule']"
4,"Let $U$,$V$ and $W$ be finite dimensional normed vector spaces and let $B:U\times V\rightarrow W$ be a bilinear map. Prove it is differentiable.","Let , and  be finite dimensional normed vector spaces and let  be a bilinear map. Prove it is differentiable.",U V W B:U\times V\rightarrow W,"The derivative at any point $(u,v)\in V\times W$   is the linear map defined by $(x,y)\longmapsto B(u,y)+B(x,v)$  . I am trying to prove this using the limit definition. My limit ended up looking like ${{\displaystyle {\lim_{(h_{1},h_{2})\to0}}}}\frac{|B(h_{1},h_{2})|}{|(h_{1},h_{2})|}$   and I am trying to prove that it is $0$  , but I don't now how.","The derivative at any point $(u,v)\in V\times W$   is the linear map defined by $(x,y)\longmapsto B(u,y)+B(x,v)$  . I am trying to prove this using the limit definition. My limit ended up looking like ${{\displaystyle {\lim_{(h_{1},h_{2})\to0}}}}\frac{|B(h_{1},h_{2})|}{|(h_{1},h_{2})|}$   and I am trying to prove that it is $0$  , but I don't now how.",,"['functional-analysis', 'derivatives']"
5,Uniform continuity of difference function,Uniform continuity of difference function,,"Assume that both $f$ and $f'$ are uniformly continuous real functions. Let $F:\mathbb R^2\to\mathbb R$ be defined by $$F(x_1,x_2)=\begin{cases}        \frac{f(x_2)-f(x_1)}{x_2-x_1} & \text{if }x_1\neq x_2 \\       f'(x_1) & \text{if }x_1=x_2. \end{cases}$$ Is there a simple proof (i.e. one that proceeds directly from the definitions of uniform continuity and limits) that $F$ is also uniformly continuous? Update: This has been proved by user251257 below, but I am still very interested in a simper proof that does not use the mean value theorem, if that is possible.","Assume that both $f$ and $f'$ are uniformly continuous real functions. Let $F:\mathbb R^2\to\mathbb R$ be defined by $$F(x_1,x_2)=\begin{cases}        \frac{f(x_2)-f(x_1)}{x_2-x_1} & \text{if }x_1\neq x_2 \\       f'(x_1) & \text{if }x_1=x_2. \end{cases}$$ Is there a simple proof (i.e. one that proceeds directly from the definitions of uniform continuity and limits) that $F$ is also uniformly continuous? Update: This has been proved by user251257 below, but I am still very interested in a simper proof that does not use the mean value theorem, if that is possible.",,"['real-analysis', 'derivatives', 'uniform-continuity']"
6,Finding stationary points numerically,Finding stationary points numerically,,"I'm writing a program which needs to be able to find the stationary points of a function within a given interval, and evaluate whether these points are maxima, minima or points of inflection. Using numerical differentiation I can find the derivative at a given point, but I'd prefer not to have to check every point on the function for a zero derivate, but I can't think of / find a better method. Once I have a stationary point, I should be able to use numerical differentiation techniques to find the second derivative (and thus whether it is a maxima, minima etc.) How can I estimate the stationary points without checking every point on a line?","I'm writing a program which needs to be able to find the stationary points of a function within a given interval, and evaluate whether these points are maxima, minima or points of inflection. Using numerical differentiation I can find the derivative at a given point, but I'd prefer not to have to check every point on the function for a zero derivate, but I can't think of / find a better method. Once I have a stationary point, I should be able to use numerical differentiation techniques to find the second derivative (and thus whether it is a maxima, minima etc.) How can I estimate the stationary points without checking every point on a line?",,"['calculus', 'derivatives', 'numerical-methods']"
7,Computations of derivatives on traces and determinants,Computations of derivatives on traces and determinants,,"$\newcommand{\tr}{\operatorname{tr}}$I am looking for some indications on how to approach the following derivatives: $$\frac{\partial}{\partial \bf{W}} (\tr(\bf{Y}^T(\bf{WW^T}+\sigma^2 I)^{-1}\bf{Y}))$$ and $$\frac{\partial}{\partial \bf{W}} \log(|\bf{WW^T} + \sigma^2I|)$$ I have been using matrix cookbook For the first one, using eq.59 from the above document i believe that i have the following \begin{align} & \frac{\partial}{\partial \bf{W}} (\tr(\bf{Y}^T(\bf{WW^T}+\sigma^2 I)^{-1}\bf{Y})) \\[10pt] = {} & \bf{Y^T}(\bf{WW^T}+\sigma^2 I)^{-1}\frac{\partial (\bf{WW^T}+\sigma^2 I)}{\partial \bf{W}} (\bf{WW^T}+\sigma^2 I)^{-1} \bf{Y}  \end{align} Set $\Sigma = \bf{WW^T}+\sigma^2 I$ And obtain $2\bf{Y^T\Sigma^{-1}W\Sigma^{-1}Y}$, implying that $\bf{W}$ is symmetric thus $\frac{\partial \Sigma}{\partial W}=2\bf{W}$ For the second one, using eq.46, I obtain $$\frac{1}{|\Sigma|}|\Sigma|\tr\left(\Sigma^{-1}\frac{\partial \Sigma}{\partial \bf{W}}\right) = \tr(\Sigma^{-1}\bf{W})$$ Are these computations correct?","$\newcommand{\tr}{\operatorname{tr}}$I am looking for some indications on how to approach the following derivatives: $$\frac{\partial}{\partial \bf{W}} (\tr(\bf{Y}^T(\bf{WW^T}+\sigma^2 I)^{-1}\bf{Y}))$$ and $$\frac{\partial}{\partial \bf{W}} \log(|\bf{WW^T} + \sigma^2I|)$$ I have been using matrix cookbook For the first one, using eq.59 from the above document i believe that i have the following \begin{align} & \frac{\partial}{\partial \bf{W}} (\tr(\bf{Y}^T(\bf{WW^T}+\sigma^2 I)^{-1}\bf{Y})) \\[10pt] = {} & \bf{Y^T}(\bf{WW^T}+\sigma^2 I)^{-1}\frac{\partial (\bf{WW^T}+\sigma^2 I)}{\partial \bf{W}} (\bf{WW^T}+\sigma^2 I)^{-1} \bf{Y}  \end{align} Set $\Sigma = \bf{WW^T}+\sigma^2 I$ And obtain $2\bf{Y^T\Sigma^{-1}W\Sigma^{-1}Y}$, implying that $\bf{W}$ is symmetric thus $\frac{\partial \Sigma}{\partial W}=2\bf{W}$ For the second one, using eq.46, I obtain $$\frac{1}{|\Sigma|}|\Sigma|\tr\left(\Sigma^{-1}\frac{\partial \Sigma}{\partial \bf{W}}\right) = \tr(\Sigma^{-1}\bf{W})$$ Are these computations correct?",,"['matrices', 'derivatives', 'determinant', 'matrix-calculus', 'trace']"
8,Minimal perimeter,Minimal perimeter,,"The problem is: Find the angle to OX axis, at which a line should be drawn through the point A (a,b) (a>0, b>0), so, that triangle, formed by this line and positive coordinate semi-axes had the minimal perimeter. I.e. the triangle vertices are (0,0), and two intersection points of line passing through A with OX and OY axes: (x,0), x>0 and (0,y),y>0. I found the function appearance: the function to minimize is  $$ f(\varphi)=\left({a\over\cos \varphi}+{b\over\sin \varphi}\right)(1+\cos \varphi+\sin \varphi) $$ and found its derivative,but I failed to solve equation derivative=0: there is 4th degree equation with respect to $\sin\varphi$, $\cos\varphi$ which I failed to solve. The answer is known, it was in the same book, but I can't come to that answer. Could somebody, please, help me?","The problem is: Find the angle to OX axis, at which a line should be drawn through the point A (a,b) (a>0, b>0), so, that triangle, formed by this line and positive coordinate semi-axes had the minimal perimeter. I.e. the triangle vertices are (0,0), and two intersection points of line passing through A with OX and OY axes: (x,0), x>0 and (0,y),y>0. I found the function appearance: the function to minimize is  $$ f(\varphi)=\left({a\over\cos \varphi}+{b\over\sin \varphi}\right)(1+\cos \varphi+\sin \varphi) $$ and found its derivative,but I failed to solve equation derivative=0: there is 4th degree equation with respect to $\sin\varphi$, $\cos\varphi$ which I failed to solve. The answer is known, it was in the same book, but I can't come to that answer. Could somebody, please, help me?",,"['calculus', 'trigonometry', 'derivatives']"
9,Related Rates: Tip of a Shadow,Related Rates: Tip of a Shadow,,"A man 6 feet tall walks at a rate of 5 feet per second away from a light that is 15 feet above the ground.  When he is 10 feet from the base of the light, (a) at what rate is the tip of his shadow moving? (b) at what rate is the length of his shadow changing? My Attempt Given: $a=6\ \mathbb{ft}$ ; $b'=5\ \frac{\mathbb{ft}}{\mathbb{s}}$ ; $h=15\ \mathbb{ft}$ ; $d=10\ \mathbb{ft}$ I used the triangle proportionality theorem and got my $b=4\ \mathbb{ft}$ , and then by Pythagoras Theorem I got my $c=\sqrt{52}$ .  I do not know how to show you the triangle I drew, but I drew a triangle with in a larger triangle.  I am sort of confused on what to do in the problem, and how solve both parts.   I assumed that I would have to use Pythagoras Theorem: $$a^2+b^2=c^2$$ Then take the derivative of that $$a(a')+b(b')=c(c')$$","A man 6 feet tall walks at a rate of 5 feet per second away from a light that is 15 feet above the ground.  When he is 10 feet from the base of the light, (a) at what rate is the tip of his shadow moving? (b) at what rate is the length of his shadow changing? My Attempt Given: ; ; ; I used the triangle proportionality theorem and got my , and then by Pythagoras Theorem I got my .  I do not know how to show you the triangle I drew, but I drew a triangle with in a larger triangle.  I am sort of confused on what to do in the problem, and how solve both parts.   I assumed that I would have to use Pythagoras Theorem: Then take the derivative of that",a=6\ \mathbb{ft} b'=5\ \frac{\mathbb{ft}}{\mathbb{s}} h=15\ \mathbb{ft} d=10\ \mathbb{ft} b=4\ \mathbb{ft} c=\sqrt{52} a^2+b^2=c^2 a(a')+b(b')=c(c'),"['calculus', 'derivatives']"
10,Differential of a function definition,Differential of a function definition,,"Consider $f: U \rightarrow \mathbb R$, $U \subset \mathbb R^n $ is an open set. a. Show that if $f$ is differenciable on $a \in U$ then there is a unique vector $w$ such that $\lim\limits_{h\mapsto 0}\dfrac{f(a + hv) - f(a)}{h} = \langle w,v \rangle$. b. Is the reciprocal statement true ? c. Find the parcials derivatives of $f$ on $a$ with respect to $w$. I think part $a$ comes from the definition of a differentiable function, $w$ is unique because of the uniqueness of the limit. However, I'm not so sure about  $b$ and $c$. Any help will be appreciated !","Consider $f: U \rightarrow \mathbb R$, $U \subset \mathbb R^n $ is an open set. a. Show that if $f$ is differenciable on $a \in U$ then there is a unique vector $w$ such that $\lim\limits_{h\mapsto 0}\dfrac{f(a + hv) - f(a)}{h} = \langle w,v \rangle$. b. Is the reciprocal statement true ? c. Find the parcials derivatives of $f$ on $a$ with respect to $w$. I think part $a$ comes from the definition of a differentiable function, $w$ is unique because of the uniqueness of the limit. However, I'm not so sure about  $b$ and $c$. Any help will be appreciated !",,"['real-analysis', 'derivatives', 'definition']"
11,Find the points on the curve $x^2+xy+y^2=7$ where tangent is parallel to (a) X axis (b) parallel to Y axis.,Find the points on the curve  where tangent is parallel to (a) X axis (b) parallel to Y axis.,x^2+xy+y^2=7,"Find the points on the curve $x^2+xy+y^2=7$ where tangent is parallel   to (a) X axis (b) parallel to Y axis. For part (a) if we differentiate w.r.t $x$ we get $y'=\large-\frac{2x+y}{x+2y}$, this when equated to zero (parallel to X axis means slope is zero) gives $x=-y/2$, this when substituted in the equation of the curve gives $\left(\sqrt{\frac{7}{3}},-2\sqrt{\frac{7}{3}}\right),\left(-\sqrt{\frac{7}{3}},2\sqrt{\frac{7}{3}}\right)$ For part (b) we find $dx/dy$, equate it to zero and find that the points are $\left(-2\sqrt{\frac{7}{3}},\sqrt{\frac{7}{3}}\right),\left(2\sqrt{\frac{7}{3}},-\sqrt{\frac{7}{3}}\right)$ $\underline{\text{My question}}$ is if we consider two points on the curve $(x_1, y_1),(x_2, y_2)$ such that $x_1 = x_2$, because for the line parallel to Y axis coordinates of x remain the same.  Substituting these two points in the equation of the curve we get $$x_1^2+x_1y_1+y_1^2=7$$ $$x_1^2+x_1y_2+y_2^2=7$$ solving them simultaneously we get $x_1=-(y_1+y_2)=x_2$, but this does not agree with the points that we calculated $\left(-2\sqrt{\frac{7}{3}},\sqrt{\frac{7}{3}}\right),\left(2\sqrt{\frac{7}{3}},-\sqrt{\frac{7}{3}}\right)$ in part (b).  $y_1+y_2=0\neq x_1 \hspace{10pt}\text{OR} \hspace{10pt} \neq x_2$","Find the points on the curve $x^2+xy+y^2=7$ where tangent is parallel   to (a) X axis (b) parallel to Y axis. For part (a) if we differentiate w.r.t $x$ we get $y'=\large-\frac{2x+y}{x+2y}$, this when equated to zero (parallel to X axis means slope is zero) gives $x=-y/2$, this when substituted in the equation of the curve gives $\left(\sqrt{\frac{7}{3}},-2\sqrt{\frac{7}{3}}\right),\left(-\sqrt{\frac{7}{3}},2\sqrt{\frac{7}{3}}\right)$ For part (b) we find $dx/dy$, equate it to zero and find that the points are $\left(-2\sqrt{\frac{7}{3}},\sqrt{\frac{7}{3}}\right),\left(2\sqrt{\frac{7}{3}},-\sqrt{\frac{7}{3}}\right)$ $\underline{\text{My question}}$ is if we consider two points on the curve $(x_1, y_1),(x_2, y_2)$ such that $x_1 = x_2$, because for the line parallel to Y axis coordinates of x remain the same.  Substituting these two points in the equation of the curve we get $$x_1^2+x_1y_1+y_1^2=7$$ $$x_1^2+x_1y_2+y_2^2=7$$ solving them simultaneously we get $x_1=-(y_1+y_2)=x_2$, but this does not agree with the points that we calculated $\left(-2\sqrt{\frac{7}{3}},\sqrt{\frac{7}{3}}\right),\left(2\sqrt{\frac{7}{3}},-\sqrt{\frac{7}{3}}\right)$ in part (b).  $y_1+y_2=0\neq x_1 \hspace{10pt}\text{OR} \hspace{10pt} \neq x_2$",,"['calculus', 'derivatives']"
12,What rule is used in this example (derivative of a complex function)?,What rule is used in this example (derivative of a complex function)?,,"I apologize for the second question on the same day, but I really do need to understand it. We've got a consumption function (it's from economics but the question is still mathematical) looking like: $$C=C(Y-T(Y))$$ where $C$ is the consumption, $Y$ is the income and $T(Y)$ is the tax as the function of income $Y$ (as in real world the taxes we pay are some proportion of the money we've earned); What we need here is to differentiate this function in respect to Y (e.g. find $\frac {dC}{dY}$); When browsing through internet, I've actually found a solution for this but I want to figure out how it's actually done (as it's a number of problems utilizing the same logic, so if I understand this one, it should be easy to do the rest). In that solution it's done the following way $$\frac{dC}{dY} = \frac{dC}{d(Y-T(Y))} * \frac{d(Y-T(Y))}{dY} + \frac{dC}{d(Y-T(Y))} * \frac{d(Y-T(Y))}{dT} * \frac{dT}{dY} $$ (and then it goes along so that the result looks more elegant) I wonder which rule is used to do this. It somehow resembles the multivariable version of the chain rule, but the function we've got here is quite different from classical examples (like $x=y^2z^3$ while $y$ and $z$ are both some functions). Is it really the chain rule? Or something else?","I apologize for the second question on the same day, but I really do need to understand it. We've got a consumption function (it's from economics but the question is still mathematical) looking like: $$C=C(Y-T(Y))$$ where $C$ is the consumption, $Y$ is the income and $T(Y)$ is the tax as the function of income $Y$ (as in real world the taxes we pay are some proportion of the money we've earned); What we need here is to differentiate this function in respect to Y (e.g. find $\frac {dC}{dY}$); When browsing through internet, I've actually found a solution for this but I want to figure out how it's actually done (as it's a number of problems utilizing the same logic, so if I understand this one, it should be easy to do the rest). In that solution it's done the following way $$\frac{dC}{dY} = \frac{dC}{d(Y-T(Y))} * \frac{d(Y-T(Y))}{dY} + \frac{dC}{d(Y-T(Y))} * \frac{d(Y-T(Y))}{dT} * \frac{dT}{dY} $$ (and then it goes along so that the result looks more elegant) I wonder which rule is used to do this. It somehow resembles the multivariable version of the chain rule, but the function we've got here is quite different from classical examples (like $x=y^2z^3$ while $y$ and $z$ are both some functions). Is it really the chain rule? Or something else?",,"['derivatives', 'economics']"
13,Constructing a potential energy function from a conservative force field,Constructing a potential energy function from a conservative force field,,"Given: $F(x,y,z)=(x-y,-x-y+z,y+z)$ Find a potential energy that corresponds to this force field. Check your answer by taking its gradient. I've already shown that this force field is conservative by $$\nabla \times  F =0$$ Now, I used $\nabla U=-F$ to find the potential function. I did so by $$U=-\int F \cdot \vec{dr}$$ $$=-\left [\int (x-y)dx + \int(-x-y+z)dy + \int (y+z)dz \right ]$$ $$=\frac{1}{2}(-x^2+y^2-z^2)+2xy-2yz$$ Now I need to check it by taking its gradient, but its not resulting in the original force field. $$\nabla U=-F$$ $$F=-\nabla U$$ $$=- \left [\frac{\partial U}{\partial x}+\frac{\partial U}{\partial x}+\frac{\partial U}{\partial x} \right ]$$ $$=- \left [ (-x+2y)+(y+2x-2z)+(-z-2y)\right ]$$ $$=(x-2y)+(-2x-y+2z)+(2y+z)$$ What did I miss?","Given: $F(x,y,z)=(x-y,-x-y+z,y+z)$ Find a potential energy that corresponds to this force field. Check your answer by taking its gradient. I've already shown that this force field is conservative by $$\nabla \times  F =0$$ Now, I used $\nabla U=-F$ to find the potential function. I did so by $$U=-\int F \cdot \vec{dr}$$ $$=-\left [\int (x-y)dx + \int(-x-y+z)dy + \int (y+z)dz \right ]$$ $$=\frac{1}{2}(-x^2+y^2-z^2)+2xy-2yz$$ Now I need to check it by taking its gradient, but its not resulting in the original force field. $$\nabla U=-F$$ $$F=-\nabla U$$ $$=- \left [\frac{\partial U}{\partial x}+\frac{\partial U}{\partial x}+\frac{\partial U}{\partial x} \right ]$$ $$=- \left [ (-x+2y)+(y+2x-2z)+(-z-2y)\right ]$$ $$=(x-2y)+(-2x-y+2z)+(2y+z)$$ What did I miss?",,"['calculus', 'derivatives', 'vector-analysis', 'vector-fields']"
14,Second derivative definition and osculating circle,Second derivative definition and osculating circle,,"The definition of first derivative is $$f'(x) = \lim_{y \to x} \frac{f(y) - f(x)}{y-x}.$$ Iterating, we have for the second derivative $$f''(x) = \lim_{y \to x} \frac{f'(y) - f'(x)}{y-x}.$$ Combining the two, we have $$f''(x) = \lim_{y \to x} \frac{1}{y-x} \left[\lim_{z \to y} \frac{f(z)-f(y)}{z-y} - \lim_{w \to x} \frac{f(w)-f(x)}{w-x}\right].$$ This would imply that we need to fix four points, $x,y,z$ and $w$ and then take the above limits where all of them tend to the point $x$. However, from the geometric interpretation, we know that the second derivative describes the curvature (of the osculating circle) at a point $x$. But, to specify a circle, we need only three , and not four point. Therefore, there should be a way of writing the expression for the second derivative which has only three, and not four values of the independent variable. How to get this expression?","The definition of first derivative is $$f'(x) = \lim_{y \to x} \frac{f(y) - f(x)}{y-x}.$$ Iterating, we have for the second derivative $$f''(x) = \lim_{y \to x} \frac{f'(y) - f'(x)}{y-x}.$$ Combining the two, we have $$f''(x) = \lim_{y \to x} \frac{1}{y-x} \left[\lim_{z \to y} \frac{f(z)-f(y)}{z-y} - \lim_{w \to x} \frac{f(w)-f(x)}{w-x}\right].$$ This would imply that we need to fix four points, $x,y,z$ and $w$ and then take the above limits where all of them tend to the point $x$. However, from the geometric interpretation, we know that the second derivative describes the curvature (of the osculating circle) at a point $x$. But, to specify a circle, we need only three , and not four point. Therefore, there should be a way of writing the expression for the second derivative which has only three, and not four values of the independent variable. How to get this expression?",,['derivatives']
15,"If $F(x,y)=0$, prove $\frac{d^2y}{dx^2}=-\frac{F_{xx}F_y^2-2F_{xy}F_xF_y+F_{yy}F^2_x}{F_y^3}$","If , prove","F(x,y)=0 \frac{d^2y}{dx^2}=-\frac{F_{xx}F_y^2-2F_{xy}F_xF_y+F_{yy}F^2_x}{F_y^3}","If $$F(x,y)=0$$ prove $$\frac{d^2y}{dx^2}=-\frac{F_{xx}F_y^2-2F_{xy}F_xF_y+F_{yy}F^2_x}{F_y^3}$$ I tried  $$\frac{dy}{dx}=-\frac{F_x}{F_y}$$ Then  $$\frac{d^2y}{dx^2}=-\frac{F_{xx}F_y-F_xF_{xy}}{F_y^2}$$ I do not know where I got wrong... any help? Thanks~","If $$F(x,y)=0$$ prove $$\frac{d^2y}{dx^2}=-\frac{F_{xx}F_y^2-2F_{xy}F_xF_y+F_{yy}F^2_x}{F_y^3}$$ I tried  $$\frac{dy}{dx}=-\frac{F_x}{F_y}$$ Then  $$\frac{d^2y}{dx^2}=-\frac{F_{xx}F_y-F_xF_{xy}}{F_y^2}$$ I do not know where I got wrong... any help? Thanks~",,"['derivatives', 'partial-derivative']"
16,"Related rates, using the Pythagorean theorem or otherwise","Related rates, using the Pythagorean theorem or otherwise",,"I'm having a hard time understanding this question: A spotlight is placed on the ground, and shines on a wall 12 meters away. Frank is a 75 cm tall dog who walks at a speed of 1.6 m/s. Frank walks from the spotlight directly towards the wall, projecting a shadow onto the wall. When Frank is 9 meters from the wall (a) how high is his shadow on the wall? (b) how fast is the length of his shadow decreasing? Specifically, do I relate the Pythagorean Theorem to the total distance from the spotlight to the wall, or the distance from Frank to the wall, or the distance from the spotlight to Frank? And if the latter two, how would I include the total distance into finding part (a)? How would I set up the Pythagorean Theorem to accommodate this scenario in order to find dy/dt? Thank you!","I'm having a hard time understanding this question: A spotlight is placed on the ground, and shines on a wall 12 meters away. Frank is a 75 cm tall dog who walks at a speed of 1.6 m/s. Frank walks from the spotlight directly towards the wall, projecting a shadow onto the wall. When Frank is 9 meters from the wall (a) how high is his shadow on the wall? (b) how fast is the length of his shadow decreasing? Specifically, do I relate the Pythagorean Theorem to the total distance from the spotlight to the wall, or the distance from Frank to the wall, or the distance from the spotlight to Frank? And if the latter two, how would I include the total distance into finding part (a)? How would I set up the Pythagorean Theorem to accommodate this scenario in order to find dy/dt? Thank you!",,"['calculus', 'derivatives']"
17,Does the derivative exist?,Does the derivative exist?,,"So I have this question here: $f(x)=\frac{1}{1+|x|}+\frac{1}{1+|x-a|},a>0$ I am asked to find the derivative and I correctly found it as: $f'(x)=-\frac{x-a}{|x-a|(|x-a|+1)^2}-\frac{x}{|x|(|x|+1)^2},a>0$ I am then asked to determine if $f'(0)$ and $f'(a)$ exist. My understanding is that they don't exist because the derivative of $|x|$and$|x-a|$ don't exist at 0 and a by the definition of the derivative (There is a corner at those particular points.) Is that correct? Or am I making a mistake?","So I have this question here: $f(x)=\frac{1}{1+|x|}+\frac{1}{1+|x-a|},a>0$ I am asked to find the derivative and I correctly found it as: $f'(x)=-\frac{x-a}{|x-a|(|x-a|+1)^2}-\frac{x}{|x|(|x|+1)^2},a>0$ I am then asked to determine if $f'(0)$ and $f'(a)$ exist. My understanding is that they don't exist because the derivative of $|x|$and$|x-a|$ don't exist at 0 and a by the definition of the derivative (There is a corner at those particular points.) Is that correct? Or am I making a mistake?",,['derivatives']
18,Derivative of Mittag-Leffler type function,Derivative of Mittag-Leffler type function,,"I am working on the following function for a fixed $0<\nu<1$. $$ f(t) = E_\nu (-t^\nu) = \sum \limits_{n=0}^\infty (-1)^n\frac{t^{n \nu}}{\Gamma(n\nu +1)} $$ where $E_\nu(\cdot)$ is a Mittag-Leffler function. I want to show that $f(t) = E_\nu (-t^\nu)$ is decreasing for $t>0$. I have tried the usual idea: Showing the derivative is negative. However the derivative function which is $$ f'(t) = \frac{d}{dt}E_\nu (-t^\nu) = \sum \limits_{n=1}^\infty (-1)^n\frac{t^{n \nu-1}}{\Gamma(n\nu)} $$ also hard to deal with. I have tried separating the cases $0<t<1$ and $t >1$. I believe for large $t$ the derivative function should be ""much more negative"". I couldn't prove that either. Any help will be appreciated.","I am working on the following function for a fixed $0<\nu<1$. $$ f(t) = E_\nu (-t^\nu) = \sum \limits_{n=0}^\infty (-1)^n\frac{t^{n \nu}}{\Gamma(n\nu +1)} $$ where $E_\nu(\cdot)$ is a Mittag-Leffler function. I want to show that $f(t) = E_\nu (-t^\nu)$ is decreasing for $t>0$. I have tried the usual idea: Showing the derivative is negative. However the derivative function which is $$ f'(t) = \frac{d}{dt}E_\nu (-t^\nu) = \sum \limits_{n=1}^\infty (-1)^n\frac{t^{n \nu-1}}{\Gamma(n\nu)} $$ also hard to deal with. I have tried separating the cases $0<t<1$ and $t >1$. I believe for large $t$ the derivative function should be ""much more negative"". I couldn't prove that either. Any help will be appreciated.",,"['calculus', 'real-analysis', 'derivatives', 'special-functions', 'monotone-functions']"
19,What is the geometric meaning of $f(x)=f(c)+f'(c)(x-c)+r(x)(x-c)$?,What is the geometric meaning of ?,f(x)=f(c)+f'(c)(x-c)+r(x)(x-c),"I see a few, but not many, books give a characteristic theorem about derivatives of real-valued real functions. That is the following: If $f$ is differentiable at $c$, then there is a function $r$   continuous at $c$ such that $f$ can be written as   $f(x)=f(c)+f'(c)(x-c)+r(x)(x-c)$ in an appropriate neighborhood of $c$, where $r(x)=\begin{cases}\frac{f(x)-f(c)-f'(c)(x-c)}{x-c},\qquad x\neq c \\0,\qquad x=c\end{cases}$ However, I can't find any explanation that says what is the geometric meaning of $f$ being written in this way and how did we come up with this somewhat technical function $r$. And what can we do with this function $r$? Does it have any theoretical benefit?","I see a few, but not many, books give a characteristic theorem about derivatives of real-valued real functions. That is the following: If $f$ is differentiable at $c$, then there is a function $r$   continuous at $c$ such that $f$ can be written as   $f(x)=f(c)+f'(c)(x-c)+r(x)(x-c)$ in an appropriate neighborhood of $c$, where $r(x)=\begin{cases}\frac{f(x)-f(c)-f'(c)(x-c)}{x-c},\qquad x\neq c \\0,\qquad x=c\end{cases}$ However, I can't find any explanation that says what is the geometric meaning of $f$ being written in this way and how did we come up with this somewhat technical function $r$. And what can we do with this function $r$? Does it have any theoretical benefit?",,"['real-analysis', 'derivatives']"
20,Awkward behavior of $x^2 \sin\frac{1}{x}$ at $x=0$?,Awkward behavior of  at ?,x^2 \sin\frac{1}{x} x=0,"According to p. 107 of the book Advanced Calculus by Fitzpatrick, Assuming that the periodicity and differentiability properties of the sine function are familiar, the following is an example of a differentiable function having a positive derivative at $x = 0$ but such that there is no neighborhood of $0$ on which it is monotonically increasing:   $$f(x) = \begin{cases}x^2\sin 1/x & \text{if}\ x\neq 0 \\ 0 & \text{if}\ x = 0\end{cases}$$   The source of this counterintuitive behavior is that the derivative $f'$ is not continuous at $x = 0$. There are two confusing things about it: a. By the definition of derivative (at $x=0$), $$\lim_{x\to 0} \dfrac{f(x)-f(0)}{x-0} = \lim_{x\to 0} \dfrac{x^2 \sin \bigl(\frac{1}{x}\bigr)}{x} = 0,$$ since $\bigl\lvert\sin\bigl(\frac{1}{x}\bigr)\bigr\rvert \le 1$. b. By use of rules for the derivative of products and quotients, $$f'(0) = \biggl[ 2x \sin \biggl(\frac{1}{x}\biggr) + x^2 \biggl(-\frac{1}{x^2} \cos \biggl(\frac{1}{x}\biggr)\biggr) \biggr]_{x=0} $$ which is not defined since $\cos\bigl(\frac{1}{0}\bigr)$ is not defined. So why the text says that its derivative exists and its value is $>0$? The function $f(x)$ is monotonically increasing because it is an odd function so for any neighborhood abound $x=0$, $f(x_1>0)>f(x_2<0)$. So why the text says otherwise?","According to p. 107 of the book Advanced Calculus by Fitzpatrick, Assuming that the periodicity and differentiability properties of the sine function are familiar, the following is an example of a differentiable function having a positive derivative at $x = 0$ but such that there is no neighborhood of $0$ on which it is monotonically increasing:   $$f(x) = \begin{cases}x^2\sin 1/x & \text{if}\ x\neq 0 \\ 0 & \text{if}\ x = 0\end{cases}$$   The source of this counterintuitive behavior is that the derivative $f'$ is not continuous at $x = 0$. There are two confusing things about it: a. By the definition of derivative (at $x=0$), $$\lim_{x\to 0} \dfrac{f(x)-f(0)}{x-0} = \lim_{x\to 0} \dfrac{x^2 \sin \bigl(\frac{1}{x}\bigr)}{x} = 0,$$ since $\bigl\lvert\sin\bigl(\frac{1}{x}\bigr)\bigr\rvert \le 1$. b. By use of rules for the derivative of products and quotients, $$f'(0) = \biggl[ 2x \sin \biggl(\frac{1}{x}\biggr) + x^2 \biggl(-\frac{1}{x^2} \cos \biggl(\frac{1}{x}\biggr)\biggr) \biggr]_{x=0} $$ which is not defined since $\cos\bigl(\frac{1}{0}\bigr)$ is not defined. So why the text says that its derivative exists and its value is $>0$? The function $f(x)$ is monotonically increasing because it is an odd function so for any neighborhood abound $x=0$, $f(x_1>0)>f(x_2<0)$. So why the text says otherwise?",,['real-analysis']
21,When we can equate two probability functions $p(r)dr=p(\gamma)d\gamma$?,When we can equate two probability functions ?,p(r)dr=p(\gamma)d\gamma,"I am doing wireless communication the signal envelope is assumed to have rayleigh fading given by $$p(r_i)= \frac{r_i}{\sigma^2} \exp\left(-\frac{r_i^2}{2\sigma^2}\right)$$ and we need to find distribution of SNR given by$$p(\gamma)|d(\gamma_i)|=p(r_i)|d(r_i)|   ~~~\text{and}~~~~ \gamma_i=\frac{r_i^2}{2N}\tag{1}$$ I want to know how equation one comes, I mean to say I have seen in coordinate geometry $\text{slope} = \frac{|\text{length of } y|}{|\text{length of }x|} $, but what specifically leads to (1).","I am doing wireless communication the signal envelope is assumed to have rayleigh fading given by $$p(r_i)= \frac{r_i}{\sigma^2} \exp\left(-\frac{r_i^2}{2\sigma^2}\right)$$ and we need to find distribution of SNR given by$$p(\gamma)|d(\gamma_i)|=p(r_i)|d(r_i)|   ~~~\text{and}~~~~ \gamma_i=\frac{r_i^2}{2N}\tag{1}$$ I want to know how equation one comes, I mean to say I have seen in coordinate geometry $\text{slope} = \frac{|\text{length of } y|}{|\text{length of }x|} $, but what specifically leads to (1).",,"['calculus', 'derivatives']"
22,"Value of $a,b $ given two conditions",Value of  given two conditions,"a,b ","If the function $f (x)=a\log|x|+bx^2+x $ has extreme points at $x=-1,2$ then the value of $a,b $ is? Now at extreme points $1^{st}$ derivative is $0$ so I differentiated it by making cases : i.e.  $x <0,x>0$(which is probably wrong) so we get two equations as $0.5a-4b=-1,2a-4b=-2$:but they yield a wrong answer. Wheres the fault?Thanks","If the function $f (x)=a\log|x|+bx^2+x $ has extreme points at $x=-1,2$ then the value of $a,b $ is? Now at extreme points $1^{st}$ derivative is $0$ so I differentiated it by making cases : i.e.  $x <0,x>0$(which is probably wrong) so we get two equations as $0.5a-4b=-1,2a-4b=-2$:but they yield a wrong answer. Wheres the fault?Thanks",,"['calculus', 'derivatives']"
23,How to find tangents to curves at points with undefined derivatives,How to find tangents to curves at points with undefined derivatives,,"I will explain my question with the help of an example. We need to find the tangent at origin to the curve $$x^3 + y^3 =3axy$$ The derivative at origin is $0/0$ or indeterminate, found after implicit differentiation. But the tangents exist (via Wolfram Alpha) and they are $x=y=0$. If the derivative at the origin does not exist, how are we getting the tangents? At least $y=0$ has a determinate slope (0). Also how should I find tangents to more general curves at points where the derivative doesn't exist? Is there a general method using differentiation? My professor told me that as $x,y\to0$, $x^3 + y^3\ll3axy$ and hence the zeroes of the function will be approximately where the zeroes of $3axy$ are. Now I couldn't understand the next line that he said: Near the origin the curve will look like the solutions to $3axy$. What does he mean by this? Of course the solutions to $3axy=0$ are $x=0$ and $y=0$, which are the tangents, but the curve isn't like that. Can anyone please explain me this? And is there a general method to find tangents at points where the derivative doesn't exist?","I will explain my question with the help of an example. We need to find the tangent at origin to the curve $$x^3 + y^3 =3axy$$ The derivative at origin is $0/0$ or indeterminate, found after implicit differentiation. But the tangents exist (via Wolfram Alpha) and they are $x=y=0$. If the derivative at the origin does not exist, how are we getting the tangents? At least $y=0$ has a determinate slope (0). Also how should I find tangents to more general curves at points where the derivative doesn't exist? Is there a general method using differentiation? My professor told me that as $x,y\to0$, $x^3 + y^3\ll3axy$ and hence the zeroes of the function will be approximately where the zeroes of $3axy$ are. Now I couldn't understand the next line that he said: Near the origin the curve will look like the solutions to $3axy$. What does he mean by this? Of course the solutions to $3axy=0$ are $x=0$ and $y=0$, which are the tangents, but the curve isn't like that. Can anyone please explain me this? And is there a general method to find tangents at points where the derivative doesn't exist?",,"['derivatives', 'tangent-line', 'slope']"
24,"Piece-wise Function Differentable, and Continuous","Piece-wise Function Differentable, and Continuous",,"I have this piece-wise function: $$f(x)=\begin{cases} 2x+3 & \text{x$\le4$} \\ x^2-5 &\text{x$\gt 4$}\end{cases}$$ I know the function is continuous at $x=4$ except how would I go finding out if it were differentable at that point? I tried by taking the derivative of the top portion and the bottom portion and got $$2$$   $$2x$$ Then I plugged in $4$ for both and got $2$, and $8$.  Since $2 \ne 8$ I deduced that at $x=4$ the function is not differentable.  Is my ideology correct of am I wrong?","I have this piece-wise function: $$f(x)=\begin{cases} 2x+3 & \text{x$\le4$} \\ x^2-5 &\text{x$\gt 4$}\end{cases}$$ I know the function is continuous at $x=4$ except how would I go finding out if it were differentable at that point? I tried by taking the derivative of the top portion and the bottom portion and got $$2$$   $$2x$$ Then I plugged in $4$ for both and got $2$, and $8$.  Since $2 \ne 8$ I deduced that at $x=4$ the function is not differentable.  Is my ideology correct of am I wrong?",,"['calculus', 'limits', 'derivatives', 'piecewise-continuity']"
25,Summation calculus differentiation problem,Summation calculus differentiation problem,,I am new in calculus. So it will be helpful if anyone solve it and give some hint how it works. $$E = \frac{1}{3} \sum_{i=1}^3 (mx_i+c-y_i)^2$$ Then what will be $\frac{dE}{dm}$ and $\frac{dE}{dc}$? Thanks.,I am new in calculus. So it will be helpful if anyone solve it and give some hint how it works. $$E = \frac{1}{3} \sum_{i=1}^3 (mx_i+c-y_i)^2$$ Then what will be $\frac{dE}{dm}$ and $\frac{dE}{dc}$? Thanks.,,"['calculus', 'derivatives', 'summation']"
26,"What's the proof of the following formula: If f(x/y)= Constt., then dy/dx= y/x?","What's the proof of the following formula: If f(x/y)= Constt., then dy/dx= y/x?",,"This formula (trick) is directly given in my study material. I have tried to prove it but its getting too long.Please help by giving proof of this condition, ie,formula.Thanks in advance.","This formula (trick) is directly given in my study material. I have tried to prove it but its getting too long.Please help by giving proof of this condition, ie,formula.Thanks in advance.",,['derivatives']
27,How to formally use Taylor expansions for $n$th derivatives and generating functions?,How to formally use Taylor expansions for th derivatives and generating functions?,n,"When deriving Catalan numbers , the generating function takes on this form: $$C(x) = \frac{1}{2} (1 - \sqrt{1-4x}) = \frac{1}{2} (1 - f(x))$$ where $f(x) = \sqrt{1-4x}$ How does one formally show what it evaluates to? I can do it somewhat ""informally"" like so: $$f(x) = \sqrt{1-4x} = \sum_{n=0}^{\infty} \frac{f^{(n)}(0)}{n!} x^n$$ $$f(x) = \frac{f^{(0)}(0)}{0!} x^0 + \frac{f^{(1)}(0)}{1!} x^1 + \frac{f^{(2)}(0)}{2!} x^2 + \frac{f^{(3)}(0)}{3!} x^3 + \frac{f^{(4)}(0)}{4!} x^4 + ...$$ Now at this point I can literally start computing the successive derivatives of $f(x)$ and then plug in $0$ for each $x$ and look for patterns and ""eyeball"" a closed-form for it. But is there a way at this point to formally show what the $n$th derivative is? Or is this more of an art than a science that changes depending on the function? I could eyeball the $n$th derivative formula as well: $f^{0}(x) = (1 - 4x)^{\frac{1}{2}}$ $f^{1}(x) = (\frac{1}{2})(-4)(1 - 4x)^{-\frac{1}{2}}$ $f^{2}(x) = (-\frac{1}{2})(\frac{1}{2})(-4)(-4)(1 - 4x)^{-\frac{3}{2}}$ $f^{3}(x) = (-\frac{3}{2})(-\frac{1}{2})(\frac{1}{2})(-4)(-4)(-4)(1 - 4x)^{-\frac{5}{2}}$ $f^{4}(x) = (-\frac{5}{2})(-\frac{3}{2})(-\frac{1}{2})(\frac{1}{2})(-4)(-4)(-4)(-4)(1 - 4x)^{-\frac{7}{2}}$ At this point I can eyeball the pattern and solve it manually. But again, what if I couldn't do that? Is there a more direct and methodical way to this?","When deriving Catalan numbers , the generating function takes on this form: $$C(x) = \frac{1}{2} (1 - \sqrt{1-4x}) = \frac{1}{2} (1 - f(x))$$ where $f(x) = \sqrt{1-4x}$ How does one formally show what it evaluates to? I can do it somewhat ""informally"" like so: $$f(x) = \sqrt{1-4x} = \sum_{n=0}^{\infty} \frac{f^{(n)}(0)}{n!} x^n$$ $$f(x) = \frac{f^{(0)}(0)}{0!} x^0 + \frac{f^{(1)}(0)}{1!} x^1 + \frac{f^{(2)}(0)}{2!} x^2 + \frac{f^{(3)}(0)}{3!} x^3 + \frac{f^{(4)}(0)}{4!} x^4 + ...$$ Now at this point I can literally start computing the successive derivatives of $f(x)$ and then plug in $0$ for each $x$ and look for patterns and ""eyeball"" a closed-form for it. But is there a way at this point to formally show what the $n$th derivative is? Or is this more of an art than a science that changes depending on the function? I could eyeball the $n$th derivative formula as well: $f^{0}(x) = (1 - 4x)^{\frac{1}{2}}$ $f^{1}(x) = (\frac{1}{2})(-4)(1 - 4x)^{-\frac{1}{2}}$ $f^{2}(x) = (-\frac{1}{2})(\frac{1}{2})(-4)(-4)(1 - 4x)^{-\frac{3}{2}}$ $f^{3}(x) = (-\frac{3}{2})(-\frac{1}{2})(\frac{1}{2})(-4)(-4)(-4)(1 - 4x)^{-\frac{5}{2}}$ $f^{4}(x) = (-\frac{5}{2})(-\frac{3}{2})(-\frac{1}{2})(\frac{1}{2})(-4)(-4)(-4)(-4)(1 - 4x)^{-\frac{7}{2}}$ At this point I can eyeball the pattern and solve it manually. But again, what if I couldn't do that? Is there a more direct and methodical way to this?",,"['number-theory', 'derivatives', 'power-series', 'generating-functions', 'catalan-numbers']"
28,Values which makes my function continuous,Values which makes my function continuous,,"I have: $$f(x)= \begin{cases} \dfrac{\ln(x+1)-e^x+1}{x}, & x>0 \\ ax, & x \le 0 \end{cases} $$ I need the values who makes the function continuous. I calculated the limit about 0 of the first part, and the result is 0, so i suppose the limit abous 0 of the second part should be 0 too. But in this case i'll get a point and i suppose a point is not derivable. So how can i calculate the values?","I have: $$f(x)= \begin{cases} \dfrac{\ln(x+1)-e^x+1}{x}, & x>0 \\ ax, & x \le 0 \end{cases} $$ I need the values who makes the function continuous. I calculated the limit about 0 of the first part, and the result is 0, so i suppose the limit abous 0 of the second part should be 0 too. But in this case i'll get a point and i suppose a point is not derivable. So how can i calculate the values?",,"['calculus', 'limits', 'derivatives']"
29,local minimum is isolated,local minimum is isolated,,"Let $f:\mathbb{R}^2\to \mathbb{R}$, $f(x,y)=(y-x^2)(y-2x^2)$. Claim: For all $(a,b)\in\mathbb{R}^2\setminus\{(0,0)\}$ the function $\varphi(t)=f(at,bt)=b^2t^2-3a^2bt^3+2a^4t^4$ has an isolated local minimum at $t=0$. I proved that $\varphi$ has an local minimum at $t=0$ (because $\varphi'(0)=0$ and $\varphi''(0)>0$) but I don't know why this is an isolated minimum. Isolated means that there is a $\epsilon >0$ such that for all $t\neq 0$ with  $|t|<\epsilon$ $\Rightarrow$ $\varphi(0)<\varphi(t)$. But how to define $\epsilon$? Can you help me? Edit: If for example $b=0$ (see the hint below), then $\varphi(t)=2a^4t^4$ has a local minimum in $t=0$ too. But what does that have to do with ""isolated""?","Let $f:\mathbb{R}^2\to \mathbb{R}$, $f(x,y)=(y-x^2)(y-2x^2)$. Claim: For all $(a,b)\in\mathbb{R}^2\setminus\{(0,0)\}$ the function $\varphi(t)=f(at,bt)=b^2t^2-3a^2bt^3+2a^4t^4$ has an isolated local minimum at $t=0$. I proved that $\varphi$ has an local minimum at $t=0$ (because $\varphi'(0)=0$ and $\varphi''(0)>0$) but I don't know why this is an isolated minimum. Isolated means that there is a $\epsilon >0$ such that for all $t\neq 0$ with  $|t|<\epsilon$ $\Rightarrow$ $\varphi(0)<\varphi(t)$. But how to define $\epsilon$? Can you help me? Edit: If for example $b=0$ (see the hint below), then $\varphi(t)=2a^4t^4$ has a local minimum in $t=0$ too. But what does that have to do with ""isolated""?",,"['calculus', 'real-analysis', 'derivatives']"
30,Using the chain rule for cos and sin functions,Using the chain rule for cos and sin functions,,"I am having issues with derivatives containing chain rules. I know there is multiple threads already but after reading a few, I still find myself confused. I also checked the actual answer following a step by step website without success. Derivate: $$h(x)=\sin ( x^6 - cos^3 x^2)$$ Now I have $sin = f(x)$ and $( x^6 - cos^3 x^2) = g(x)$ so i have a $f(g(x))$ form The general formula says $f(g(x))$  = $f'(g(x))*g'(x)$ First, let's derivate the first part using --> $sin f(x) = cos f(x) * f'(x)$ $$cos (x^6-cos^3x^2)*(6x^5 - ??)$$ I know that $cos^3 x$ is $(cos x)^3$ so that means $((cos x^2)^3)'= 3(cos x^2)^2*-sinx^2*2x$ So we have $$cos (x^6-cos^3x^2)*(6x^5-(6x(cos x^2)^2*-sinx^2)))$$ Simplified $$cos (x^6-cos^3x^2)(6x^5-6xcos^2 x^2*sinx^2)$$ Where i'm confused : The rule says that we need to do f'(g(x))*g'(x), this would mean that I would need to do: $$(sin(x^6-cos^3x^2))'*(x^6-cos^3x^2)'$$ Which would make an even bigger answer $$cos (x^6-cos^3x^2)*(6x^5-6xcos^2 x^2*sinx^2) * (6x^5-6xcos^2 x^2*sinx^2)$$ And then I don't understand. Also, it seems that i have done a mistake because the actual answer is the following (I have a $-$ where it's suppose to be a $+$) Real answer : $$[cos (x^6-cos^3x^2)](6x^5+6xcos^2 x^2sinx^2)$$ My answer : $$cos (x^6-cos^3x^2)(6x^5-6xcos^2 x^2*sinx^2)$$","I am having issues with derivatives containing chain rules. I know there is multiple threads already but after reading a few, I still find myself confused. I also checked the actual answer following a step by step website without success. Derivate: $$h(x)=\sin ( x^6 - cos^3 x^2)$$ Now I have $sin = f(x)$ and $( x^6 - cos^3 x^2) = g(x)$ so i have a $f(g(x))$ form The general formula says $f(g(x))$  = $f'(g(x))*g'(x)$ First, let's derivate the first part using --> $sin f(x) = cos f(x) * f'(x)$ $$cos (x^6-cos^3x^2)*(6x^5 - ??)$$ I know that $cos^3 x$ is $(cos x)^3$ so that means $((cos x^2)^3)'= 3(cos x^2)^2*-sinx^2*2x$ So we have $$cos (x^6-cos^3x^2)*(6x^5-(6x(cos x^2)^2*-sinx^2)))$$ Simplified $$cos (x^6-cos^3x^2)(6x^5-6xcos^2 x^2*sinx^2)$$ Where i'm confused : The rule says that we need to do f'(g(x))*g'(x), this would mean that I would need to do: $$(sin(x^6-cos^3x^2))'*(x^6-cos^3x^2)'$$ Which would make an even bigger answer $$cos (x^6-cos^3x^2)*(6x^5-6xcos^2 x^2*sinx^2) * (6x^5-6xcos^2 x^2*sinx^2)$$ And then I don't understand. Also, it seems that i have done a mistake because the actual answer is the following (I have a $-$ where it's suppose to be a $+$) Real answer : $$[cos (x^6-cos^3x^2)](6x^5+6xcos^2 x^2sinx^2)$$ My answer : $$cos (x^6-cos^3x^2)(6x^5-6xcos^2 x^2*sinx^2)$$",,"['derivatives', 'chain-rule']"
31,What is the difference between derevative w.r.t a vector and directional derivative?,What is the difference between derevative w.r.t a vector and directional derivative?,,"Say we have a scalar-valued function $f: \mathbb R^3 \rightarrow \mathbb R$, such that:  $$f(\mathbf x) = \mathbf x^T\mathbf a$$ $\mathbf x$ and $\mathbf a$ are two vectors. The derivative of $f$ with respect to $\mathbf x$ is $\nabla f$, but the directional derivative of $f$ in $\mathbf x$ direction is $\nabla f\cdot \mathbf x$ (the dot denotes the dot product). EDIT 1: By definition: $\dfrac{\mathrm d f}{\mathrm d \mathbf x} = \nabla f$ Based on this definition, we have: $$\dfrac{\partial f}{\partial \mathbf x} = \mathbf a$$ My question is: why there is a difference between the two ($\dfrac{\mathrm d f}{\mathrm d \mathbf x} = \nabla f$ and the directional derivative in $\mathbf x$ direction)? Thank you","Say we have a scalar-valued function $f: \mathbb R^3 \rightarrow \mathbb R$, such that:  $$f(\mathbf x) = \mathbf x^T\mathbf a$$ $\mathbf x$ and $\mathbf a$ are two vectors. The derivative of $f$ with respect to $\mathbf x$ is $\nabla f$, but the directional derivative of $f$ in $\mathbf x$ direction is $\nabla f\cdot \mathbf x$ (the dot denotes the dot product). EDIT 1: By definition: $\dfrac{\mathrm d f}{\mathrm d \mathbf x} = \nabla f$ Based on this definition, we have: $$\dfrac{\partial f}{\partial \mathbf x} = \mathbf a$$ My question is: why there is a difference between the two ($\dfrac{\mathrm d f}{\mathrm d \mathbf x} = \nabla f$ and the directional derivative in $\mathbf x$ direction)? Thank you",,['derivatives']
32,Prove that $\frac{dy}{dx} = -\frac1{(1+x)^2}$ for given that $x\sqrt{1+y} + y\sqrt{1+x} = 0$,Prove that  for given that,\frac{dy}{dx} = -\frac1{(1+x)^2} x\sqrt{1+y} + y\sqrt{1+x} = 0,$$x\sqrt{1+y} + y\sqrt{1+x} = 0$$ Please tell me where I went wrong. Why I am not getting correct answer ?,$$x\sqrt{1+y} + y\sqrt{1+x} = 0$$ Please tell me where I went wrong. Why I am not getting correct answer ?,,['derivatives']
33,Finding the second derivative of $x^x$,Finding the second derivative of,x^x,"Find the second derivative $d^2y/dx^2$ when $y=x^x\:(x>0)$ . $$y=x^x,\:\:(x\gt0)$$ \begin{align} \log y&=x\log x \\ \rm{Differentiating}&\:{\rm{with\:respect\:to\:}}x \end{align} \begin{align} \frac{1}{y}\frac{dy}{dx}&=1\cdot(\log x+1)+x\cdot\frac{1}{x} \\[0.8ex] \frac{dy}{dx}&=x^x(\log x+1) \end{align} I found the first derivative, and now I want to know how to find the second derivative of this function.","Find the second derivative when . I found the first derivative, and now I want to know how to find the second derivative of this function.","d^2y/dx^2 y=x^x\:(x>0) y=x^x,\:\:(x\gt0) \begin{align}
\log y&=x\log x \\
\rm{Differentiating}&\:{\rm{with\:respect\:to\:}}x
\end{align} \begin{align}
\frac{1}{y}\frac{dy}{dx}&=1\cdot(\log x+1)+x\cdot\frac{1}{x} \\[0.8ex]
\frac{dy}{dx}&=x^x(\log x+1)
\end{align}",['derivatives']
34,Derivative that includes several functions of time,Derivative that includes several functions of time,,"I'd like to compute the following derivative (i.e., solve for $v$): \begin{align} \frac{dv}{dt} = \frac{-v(t) + I_{rec}(t) + I_{ext}(t)}{\tau_m}. \end{align} I know that if I had $\frac{dv}{dt}=\frac{-v(t)}{\tau_m}$, I'd have $v(t) = e^{-t/\tau_m}$.  But it's not clear to me what to do here. Any help would be much appreciated.","I'd like to compute the following derivative (i.e., solve for $v$): \begin{align} \frac{dv}{dt} = \frac{-v(t) + I_{rec}(t) + I_{ext}(t)}{\tau_m}. \end{align} I know that if I had $\frac{dv}{dt}=\frac{-v(t)}{\tau_m}$, I'd have $v(t) = e^{-t/\tau_m}$.  But it's not clear to me what to do here. Any help would be much appreciated.",,"['calculus', 'ordinary-differential-equations', 'derivatives', 'exponential-function']"
35,Partial Derivative of $xy^2+yz^2+xyz+x^2y^2z^2=5$,Partial Derivative of,xy^2+yz^2+xyz+x^2y^2z^2=5,"Someone can tell me what the Partial Derivative of $\frac{d^2z}{dy^2}$ of function $z(x,y)$ if it`s look like this: $$xy^2+yz^2+xyz+x^2y^2z^2=5$$ I try to solve the first derivative: $$\frac{dz}{dy}=(2yx+z^2z+xzz+2x^2yz^2z)$$ but I am not sure if its okay, Thank you!","Someone can tell me what the Partial Derivative of $\frac{d^2z}{dy^2}$ of function $z(x,y)$ if it`s look like this: $$xy^2+yz^2+xyz+x^2y^2z^2=5$$ I try to solve the first derivative: $$\frac{dz}{dy}=(2yx+z^2z+xzz+2x^2yz^2z)$$ but I am not sure if its okay, Thank you!",,['derivatives']
36,Application of calculus in real life,Application of calculus in real life,,"I'm no mathematician, so bear with simplicity of what I'm asking. My calculus course(post-Soviet country, a while ago) was utter trash. I've recently decided to approach the topic for self eduction. I'd like to know how all of it is being applied IRL.  The textbook examples on differentiation and integration use convenient incomes to be typical and easy to solve. But how would I start with computing intergal of a real-life function, with 'non-textbook' equivalents? How do I compute derivative from speed change graph of real-life wehicle which stops, speeds up in 'undeterministic' manner?","I'm no mathematician, so bear with simplicity of what I'm asking. My calculus course(post-Soviet country, a while ago) was utter trash. I've recently decided to approach the topic for self eduction. I'd like to know how all of it is being applied IRL.  The textbook examples on differentiation and integration use convenient incomes to be typical and easy to solve. But how would I start with computing intergal of a real-life function, with 'non-textbook' equivalents? How do I compute derivative from speed change graph of real-life wehicle which stops, speeds up in 'undeterministic' manner?",,"['calculus', 'derivatives', 'soft-question']"
37,Sequence of funtions $f_n = n(f(x+ \frac{1}{n})-f(x))$ for the continous differentiable function $f$ on $\mathbb R$,Sequence of funtions  for the continous differentiable function  on,f_n = n(f(x+ \frac{1}{n})-f(x)) f \mathbb R,"Let  $f$ be a continous differentiable function on $\mathbb R$. Let $f_n$ be a sequence of functions $f_n = n(f(x+ \frac{1}{n})-f(x))$. Then (a) $f_n$ converges uniformly on $\mathbb R$ (b) $f_n$ converges on $\mathbb R$, but not necessarily uniformly. (c) $f_n$ converges to the derivative of $f$ uniformly on$[0,1]$ (d) there is no guarantee that $f_n$ converges on any open interval. We know that $f'(x) =\lim_{h \to 0} \frac{f(x+h) - f(x)}{h} = \lim_{n \to\infty} \frac{f(x+\frac{1}{n}) - f(x)}{\frac{1}{n}}=\lim_{n \to \infty} f_n(x)$. Thus $f_n$ converges pointwise to $f'$ Please tell me how to check the uniform convergence. Any help would be appreciated. Thank you.","Let  $f$ be a continous differentiable function on $\mathbb R$. Let $f_n$ be a sequence of functions $f_n = n(f(x+ \frac{1}{n})-f(x))$. Then (a) $f_n$ converges uniformly on $\mathbb R$ (b) $f_n$ converges on $\mathbb R$, but not necessarily uniformly. (c) $f_n$ converges to the derivative of $f$ uniformly on$[0,1]$ (d) there is no guarantee that $f_n$ converges on any open interval. We know that $f'(x) =\lim_{h \to 0} \frac{f(x+h) - f(x)}{h} = \lim_{n \to\infty} \frac{f(x+\frac{1}{n}) - f(x)}{\frac{1}{n}}=\lim_{n \to \infty} f_n(x)$. Thus $f_n$ converges pointwise to $f'$ Please tell me how to check the uniform convergence. Any help would be appreciated. Thank you.",,"['real-analysis', 'sequences-and-series', 'derivatives', 'uniform-convergence']"
38,Help Me Understand How this was Derived,Help Me Understand How this was Derived,,"Here is the question: ""Newtons Law of Cooling. Newton's Law of Cooling states that the rate of change of the temperature of an object is proportional to the difference between its own temperature and the temperature of its surroundings. The temperature of a warm object can be found by $T = A + (T_0  A)e^{kt}\;$, where $A\;$ is the temperature of the surroundings, $T_0\;$ is the initial temperature of the object, $t\;$ is the time in minutes since the initial temperature was measured, and $k\;$ is a characteristic of the object. At what rate is a cup of tea cooling 3 minutes after its initial temperature was taken, if it had an initial temperature of 92C, is placed in a room at a temperature of 21C, and has a $k\;$ value of 0.054?"" During the explanation of the answer to this question they show this deriving: From the four lines of math seen above, how did ""they"" get from the third line to the fourth line (last line)? I believe the chain rule is being applied here, please explain the process of this math. Thanks!","Here is the question: ""Newtons Law of Cooling. Newton's Law of Cooling states that the rate of change of the temperature of an object is proportional to the difference between its own temperature and the temperature of its surroundings. The temperature of a warm object can be found by $T = A + (T_0  A)e^{kt}\;$, where $A\;$ is the temperature of the surroundings, $T_0\;$ is the initial temperature of the object, $t\;$ is the time in minutes since the initial temperature was measured, and $k\;$ is a characteristic of the object. At what rate is a cup of tea cooling 3 minutes after its initial temperature was taken, if it had an initial temperature of 92C, is placed in a room at a temperature of 21C, and has a $k\;$ value of 0.054?"" During the explanation of the answer to this question they show this deriving: From the four lines of math seen above, how did ""they"" get from the third line to the fourth line (last line)? I believe the chain rule is being applied here, please explain the process of this math. Thanks!",,"['calculus', 'derivatives', 'chain-rule']"
39,Finding a general form of $ \frac{d^{2n}}{dk^{2n}}\frac{1}{k} \sin(k)$,Finding a general form of, \frac{d^{2n}}{dk^{2n}}\frac{1}{k} \sin(k),I'm trying to solve the general form of  $$ \frac{d^{2n}}{dk^{2n}}\frac{1}{k} \sin(k)$$ using the general Leibniz rule but im getting confused while calculating it. Hope someone can help me. Thanks in advance,I'm trying to solve the general form of  $$ \frac{d^{2n}}{dk^{2n}}\frac{1}{k} \sin(k)$$ using the general Leibniz rule but im getting confused while calculating it. Hope someone can help me. Thanks in advance,,"['calculus', 'derivatives']"
40,Find the derivative of each of the the following functions,Find the derivative of each of the the following functions,,Find the derivative of each of the the following functions. $f(x)=\sqrt{7+\sqrt{x^3}}$ $\frac{d}{du}\left(\sqrt{u}\right)\frac{d}{dx}\left(7+\sqrt{x^3}\right)$ A: $3x^2/4\sqrt{x^3}\sqrt{\sqrt{x^3}+7}$ $7x/\sqrt{5-2x}$ $7\frac{\frac{d}{dx}\left(x\right)\sqrt{5-2x}-\frac{d}{dx}\left(\sqrt{5-2x}\right)x}{\left(\sqrt{5-2x}\right)^2}$ A: $7(-x+5)/(-2x+5)$ Are my solutions correct?,Find the derivative of each of the the following functions. $f(x)=\sqrt{7+\sqrt{x^3}}$ $\frac{d}{du}\left(\sqrt{u}\right)\frac{d}{dx}\left(7+\sqrt{x^3}\right)$ A: $3x^2/4\sqrt{x^3}\sqrt{\sqrt{x^3}+7}$ $7x/\sqrt{5-2x}$ $7\frac{\frac{d}{dx}\left(x\right)\sqrt{5-2x}-\frac{d}{dx}\left(\sqrt{5-2x}\right)x}{\left(\sqrt{5-2x}\right)^2}$ A: $7(-x+5)/(-2x+5)$ Are my solutions correct?,,"['calculus', 'derivatives']"
41,"Study the absolute minima and maxima of $f(x,y)=(x^2-y^2)(x-2)$",Study the absolute minima and maxima of,"f(x,y)=(x^2-y^2)(x-2)","Study the absolute minima and maxima of $$f(x,y)=(x^2-y^2)(x-2)$$ in the triangle $A$ of this vertices: $$O=(0,0) \qquad P=(2,2) \qquad Q=(2,-2)$$ I consider the set: $$A=\{ (x,y) \in \mathbb{R}^2 : 0 \le x \le 2 \ , \ -x \le y \le x \}$$ I have tried to find minima and maxima in $int(A)$ Partial derivatives: $$f_x(x,y)=3x^2-y^2-4x \\ f_y(x,y)=-2xy+4y \\ f_{xx}(x,y)=6x-4 \\ f_{yy}(x,y)=-2x+4 \\ f_{xy}(x,y)=f_{yx}(x,y)=-2y$$ Hessian matrix: $$H(x,y)=\begin{bmatrix}6x-4 & -2y  \\ -2y & -2x+4 \end{bmatrix}$$ Stationary points: \begin{cases} 3x^2-y^2-4x=0 \\ -2xy+4y=0 \\ \end{cases} $S_1=(0,0) \qquad S_2=(2,2) \qquad S_3=(2,-2)$ So $$S_1=O \qquad S_2=P \qquad S_3=Q $$ $$\det H(O)=\det H(P)=\det H(Q)=-16<0$$ $O,P,Q$ are saddle points I try to search maxima and minima on the sides of triangle $$y=x \qquad 0\le x\le 2 \\ F(x,x)=0 \qquad \forall x \in \mathbb{R}$$ $$y=-x \qquad 0\le x\le 2 \\ F(x,-x)=0 \qquad \forall x \in \mathbb{R}$$ $$x=2 \qquad -2\le y\le 2 \\ F(2,y)=0 \qquad \forall y \in \mathbb{R}$$ Is there any mistake? Thanks!","Study the absolute minima and maxima of $$f(x,y)=(x^2-y^2)(x-2)$$ in the triangle $A$ of this vertices: $$O=(0,0) \qquad P=(2,2) \qquad Q=(2,-2)$$ I consider the set: $$A=\{ (x,y) \in \mathbb{R}^2 : 0 \le x \le 2 \ , \ -x \le y \le x \}$$ I have tried to find minima and maxima in $int(A)$ Partial derivatives: $$f_x(x,y)=3x^2-y^2-4x \\ f_y(x,y)=-2xy+4y \\ f_{xx}(x,y)=6x-4 \\ f_{yy}(x,y)=-2x+4 \\ f_{xy}(x,y)=f_{yx}(x,y)=-2y$$ Hessian matrix: $$H(x,y)=\begin{bmatrix}6x-4 & -2y  \\ -2y & -2x+4 \end{bmatrix}$$ Stationary points: \begin{cases} 3x^2-y^2-4x=0 \\ -2xy+4y=0 \\ \end{cases} $S_1=(0,0) \qquad S_2=(2,2) \qquad S_3=(2,-2)$ So $$S_1=O \qquad S_2=P \qquad S_3=Q $$ $$\det H(O)=\det H(P)=\det H(Q)=-16<0$$ $O,P,Q$ are saddle points I try to search maxima and minima on the sides of triangle $$y=x \qquad 0\le x\le 2 \\ F(x,x)=0 \qquad \forall x \in \mathbb{R}$$ $$y=-x \qquad 0\le x\le 2 \\ F(x,-x)=0 \qquad \forall x \in \mathbb{R}$$ $$x=2 \qquad -2\le y\le 2 \\ F(2,y)=0 \qquad \forall y \in \mathbb{R}$$ Is there any mistake? Thanks!",,"['derivatives', 'partial-derivative', 'hessian-matrix']"
42,"Suppose $f$ is a mapping between a normed space and a Hilbert space with ONB $(e_n)_n$, what's the second derivative of $\langle f,e_n\rangle$?","Suppose  is a mapping between a normed space and a Hilbert space with ONB , what's the second derivative of ?","f (e_n)_n \langle f,e_n\rangle","Let $E$ be a normed space $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a Hilbert space $f:E\to H$ be Frchet differentiable $(e_n)_{n\in\mathbb N}$ be an orthonormal basis of $H$ and $$f_n:=\langle f,e_n\rangle\;\;\;\text{for }n\in\mathbb N$$ How can we compute the second Frchet derivative ${\rm D^2}f_n:E\to\mathfrak L(E,\mathfrak L(E,H))$ of $f_n$?$^1$ Let $$L_n:=\langle\;\cdot\;,e_n\rangle\;\;\;\text{for }n\in\mathbb N\;.$$ Then, since each $L_n$ is an element of $\mathfrak L(H,\mathbb R)$$^1$, $${\rm D}L_n(u)=L_n\;\;\;\text{for all }u\in H\text{ and }n\in\mathbb N$$ and hence $${\rm D}f_n(x)={\rm D}(L_n\circ f)(x)={\rm D}L_n(f(x))\circ{\rm D}f(x)=L_n\circ{\rm D}f(x)=\langle{\rm D}f(x),e_n\rangle$$ by the chain rule, for all $x\in E$ and $n\in\mathbb N$. So, I guess that $${\rm D^2}f_n(x)={\rm D}({\rm D}f_n)(x)={\rm D}(L_n\circ{\rm D}f)(x)={\rm D}L_n({\rm D}f(x))\circ {\rm D^2}f(x)=L_n\circ{\rm D^2}f(x)=\langle{\rm D^2}f(x),e_n\rangle\;,$$ again by the chain rule, for all $x\in E$ and $n\in\mathbb N$. But I'm unsure whether I made a mistake or not. $^1$ Let $\mathfrak L(A,B)$ be the space of bounded, linear operators from $A$ to $B$.","Let $E$ be a normed space $(H,\langle\;\cdot\;,\;\cdot\;\rangle)$ be a Hilbert space $f:E\to H$ be Frchet differentiable $(e_n)_{n\in\mathbb N}$ be an orthonormal basis of $H$ and $$f_n:=\langle f,e_n\rangle\;\;\;\text{for }n\in\mathbb N$$ How can we compute the second Frchet derivative ${\rm D^2}f_n:E\to\mathfrak L(E,\mathfrak L(E,H))$ of $f_n$?$^1$ Let $$L_n:=\langle\;\cdot\;,e_n\rangle\;\;\;\text{for }n\in\mathbb N\;.$$ Then, since each $L_n$ is an element of $\mathfrak L(H,\mathbb R)$$^1$, $${\rm D}L_n(u)=L_n\;\;\;\text{for all }u\in H\text{ and }n\in\mathbb N$$ and hence $${\rm D}f_n(x)={\rm D}(L_n\circ f)(x)={\rm D}L_n(f(x))\circ{\rm D}f(x)=L_n\circ{\rm D}f(x)=\langle{\rm D}f(x),e_n\rangle$$ by the chain rule, for all $x\in E$ and $n\in\mathbb N$. So, I guess that $${\rm D^2}f_n(x)={\rm D}({\rm D}f_n)(x)={\rm D}(L_n\circ{\rm D}f)(x)={\rm D}L_n({\rm D}f(x))\circ {\rm D^2}f(x)=L_n\circ{\rm D^2}f(x)=\langle{\rm D^2}f(x),e_n\rangle\;,$$ again by the chain rule, for all $x\in E$ and $n\in\mathbb N$. But I'm unsure whether I made a mistake or not. $^1$ Let $\mathfrak L(A,B)$ be the space of bounded, linear operators from $A$ to $B$.",,"['functional-analysis', 'derivatives', 'operator-theory', 'hilbert-spaces']"
43,Having trouble deriving the symbols used in a quadratric approximation problem.,Having trouble deriving the symbols used in a quadratric approximation problem.,,"I'm refreshing my calculus by studying MIT OCW's Single Variable Calculus course online. The problem is 2A-11, part of Unit 2 ""Applications of Derivatives"". It's a problem dealing with quadratic approximation. I'm understanding the concepts again fairly well and enjoying it, but sometimes things are glossed over in the solutions manual. The problem is stated thus: 2A-11 For an ideal gas at constant temperature, the variables $p$ (pressure) and $v$ (volume) are related by the equation ${pv}^k = C$, where $k$ and $C$ are constants. If the volume is changed slightly from $\,v{}_0$ to  $\,v{}_0+\overrightarrow{D\,}v$, what quadratic approximation expressing p in terms of $\,\overrightarrow{D\,}v\,$ would you use? $\big(\text{Find the approximation valid for }\,\overrightarrow{D\,}v \approx0.\big)$ I started on it, but hit a wall, so I caved in and peeked at the answer... $${pv}^{\hspace{0.1ex}k} = c \quad\implies\quad p = {cv}^{-k} \\ \begin{aligned} p &= {cv}^{-k} %\\ & = \big(v{}_0+\Delta v\big)^{-k} & \leftarrow &~~ \text{got this far} \\ &= {cv}{}_0^{-k}\left(1+\dfrac{\Delta v}{v{}_0}\right)^{-k} & \leftarrow &~~ \text{I assume this is their definition of function $f$,} \\ &&&~~\text{although I'm not clear  $f(?)$ of what argument.} \\&\approx \dfrac{c}{v{}_0^{\hspace{0.1ex}k}} \left(1 - k\hspace{0.1ex}\dfrac{\Delta v}{v{}_0} + \dfrac{k\left(k+1\right)}{2}\,\left(\frac{\Delta v}{v{}_0}\right)^{\!\!2}\right) \end{aligned}$$ My question is : How does the $\dfrac{\Delta v}{v{}_0}$ make its way into that approximation as the ""$?$"" in ""$f(?)$""? In other words, when they state things like ""when $x \approx 0$"" , they are relating that to ""$f(x)$"". But somehow here, we have a $v{}_0$ in the denominator, and $\dfrac{\Delta v}{v{}_0}$ as a whole is taking the place of ""$x$"". For reminder, the quadratic approximation is thus: $$f(x) \approx f\left(x{}_0\right) + f'\left(x{}_0\right)\hspace{0.125ex}\left(x-x{}_0\right) + \dfrac{f''\left(x{}_0\right)}{2}\,{\left(x-x{}_0\right)}^2$$ So at $\,x_0 \approx 0$, it's: $$f\left(x\right) \approx f\left(0\right) + f'\left(0\right)\,x + \dfrac{f''\left(0\right)}{2}\,x^2$$ Anyway, I see where it originated in the previous step in the answer by a refactoring of $v{}_0$, but I am hitting a wall trying to connect the two parts, and wasn't able to reach the answer myself. Any light you can shed would be wonderful.","I'm refreshing my calculus by studying MIT OCW's Single Variable Calculus course online. The problem is 2A-11, part of Unit 2 ""Applications of Derivatives"". It's a problem dealing with quadratic approximation. I'm understanding the concepts again fairly well and enjoying it, but sometimes things are glossed over in the solutions manual. The problem is stated thus: 2A-11 For an ideal gas at constant temperature, the variables $p$ (pressure) and $v$ (volume) are related by the equation ${pv}^k = C$, where $k$ and $C$ are constants. If the volume is changed slightly from $\,v{}_0$ to  $\,v{}_0+\overrightarrow{D\,}v$, what quadratic approximation expressing p in terms of $\,\overrightarrow{D\,}v\,$ would you use? $\big(\text{Find the approximation valid for }\,\overrightarrow{D\,}v \approx0.\big)$ I started on it, but hit a wall, so I caved in and peeked at the answer... $${pv}^{\hspace{0.1ex}k} = c \quad\implies\quad p = {cv}^{-k} \\ \begin{aligned} p &= {cv}^{-k} %\\ & = \big(v{}_0+\Delta v\big)^{-k} & \leftarrow &~~ \text{got this far} \\ &= {cv}{}_0^{-k}\left(1+\dfrac{\Delta v}{v{}_0}\right)^{-k} & \leftarrow &~~ \text{I assume this is their definition of function $f$,} \\ &&&~~\text{although I'm not clear  $f(?)$ of what argument.} \\&\approx \dfrac{c}{v{}_0^{\hspace{0.1ex}k}} \left(1 - k\hspace{0.1ex}\dfrac{\Delta v}{v{}_0} + \dfrac{k\left(k+1\right)}{2}\,\left(\frac{\Delta v}{v{}_0}\right)^{\!\!2}\right) \end{aligned}$$ My question is : How does the $\dfrac{\Delta v}{v{}_0}$ make its way into that approximation as the ""$?$"" in ""$f(?)$""? In other words, when they state things like ""when $x \approx 0$"" , they are relating that to ""$f(x)$"". But somehow here, we have a $v{}_0$ in the denominator, and $\dfrac{\Delta v}{v{}_0}$ as a whole is taking the place of ""$x$"". For reminder, the quadratic approximation is thus: $$f(x) \approx f\left(x{}_0\right) + f'\left(x{}_0\right)\hspace{0.125ex}\left(x-x{}_0\right) + \dfrac{f''\left(x{}_0\right)}{2}\,{\left(x-x{}_0\right)}^2$$ So at $\,x_0 \approx 0$, it's: $$f\left(x\right) \approx f\left(0\right) + f'\left(0\right)\,x + \dfrac{f''\left(0\right)}{2}\,x^2$$ Anyway, I see where it originated in the previous step in the answer by a refactoring of $v{}_0$, but I am hitting a wall trying to connect the two parts, and wasn't able to reach the answer myself. Any light you can shed would be wonderful.",,"['calculus', 'derivatives']"
44,Inconsistency in partial derivatives in polar and Cartesian coordinates,Inconsistency in partial derivatives in polar and Cartesian coordinates,,"We know that for polar $(r,\theta)$ and Cartesian $(x,y)$ coordinates: $r=\sqrt{x^2+y^2}$ (1) $x=r\cos\theta$ (2) I am trying to find $\dfrac{\partial r}{\partial x}$. I have tried two methods, which do not give the same answer, and I want to know where I've gone wrong. Method 1 : Use equation (1) to get $$\frac{\partial r}{\partial x}=\frac{x}{\sqrt{x^2+y^2}}=\frac{r\cos\theta}{r}=\cos\theta$$ Method 2 : Use equation (2) to write $$r=\frac{x}{\cos\theta}$$ so $$\frac{\partial r}{\partial x}=\frac{1}{\cos\theta}$$ I think that it's Method 1 that's correct, but I can't see what the mistake is that I've made in Method 2. I'm sure it's blindingly obvious, but any advice would be highly appreciated.","We know that for polar $(r,\theta)$ and Cartesian $(x,y)$ coordinates: $r=\sqrt{x^2+y^2}$ (1) $x=r\cos\theta$ (2) I am trying to find $\dfrac{\partial r}{\partial x}$. I have tried two methods, which do not give the same answer, and I want to know where I've gone wrong. Method 1 : Use equation (1) to get $$\frac{\partial r}{\partial x}=\frac{x}{\sqrt{x^2+y^2}}=\frac{r\cos\theta}{r}=\cos\theta$$ Method 2 : Use equation (2) to write $$r=\frac{x}{\cos\theta}$$ so $$\frac{\partial r}{\partial x}=\frac{1}{\cos\theta}$$ I think that it's Method 1 that's correct, but I can't see what the mistake is that I've made in Method 2. I'm sure it's blindingly obvious, but any advice would be highly appreciated.",,"['derivatives', 'partial-derivative']"
45,Inconsistencies with multiple differentiation methods,Inconsistencies with multiple differentiation methods,,"$$w=\sin x$$ $$\frac{dw}{dx} = \cos x$$ $$\therefore\frac{dx}{dw} = \frac{1}{\cos x}$$ Rearranging the initial relationship; $$x = \arcsin(w)$$ $$\therefore\frac{dx}{dw} = \frac{1}{(1-w^2)^{0.5}}$$ But, $$\frac{1}{\cos x} \neq \frac{1}{(1-w^2)^{0.5}}$$ What's wrong with one of the methods?","$$w=\sin x$$ $$\frac{dw}{dx} = \cos x$$ $$\therefore\frac{dx}{dw} = \frac{1}{\cos x}$$ Rearranging the initial relationship; $$x = \arcsin(w)$$ $$\therefore\frac{dx}{dw} = \frac{1}{(1-w^2)^{0.5}}$$ But, $$\frac{1}{\cos x} \neq \frac{1}{(1-w^2)^{0.5}}$$ What's wrong with one of the methods?",,['derivatives']
46,"What is meant by the ""contour of a function?""","What is meant by the ""contour of a function?""",,"Suppose that we have $f(x,y)=(x+y)^2.$ What is meant by the ""contour of a function,"" and what is an analytic expression for it? All software, such as Matlab, Mathematica,.. gives just a function like ContourPlot[] without details of the analytic expression. Further, I read in a book that the direction of the gradient gives the normal to the contour.  Thanks for suggesting any details.","Suppose that we have $f(x,y)=(x+y)^2.$ What is meant by the ""contour of a function,"" and what is an analytic expression for it? All software, such as Matlab, Mathematica,.. gives just a function like ContourPlot[] without details of the analytic expression. Further, I read in a book that the direction of the gradient gives the normal to the contour.  Thanks for suggesting any details.",,"['discrete-mathematics', 'derivatives', 'graphing-functions', 'contour-integration']"
47,Checking units following differentiation,Checking units following differentiation,,"I'm trying to construct a simple mathematical model for a physical system, but my calculus is rusty and I'm tying myself in knots, especially with regard to the dimensions of the quantities I'm using. The system obeys the equations $$y = \frac{x - a}{\tau} \qquad for \qquad x > a$$ $$y = 0 \qquad for \qquad x \leq a$$ $x$ and $a$ have units of length, $\tau$ has units of time and $y$ has units of $L/T$. $a$ and $\tau$ are constants. The discontinuity at $x = a$ causes me some problems later in my analysis, so I've been approximating it as $$y = \frac{x -a}{\tau} g(x)$$ where $$g(x) = \frac{1}{1 + e^{(a - x)}}$$ The function $g(x)$ switches fairly quickly from $\approx 0$ to $\approx 1$ at $x = a$, which gives a continuous representation of the discontinuity that is sufficiently abrupt for my purposes. In principle, $g(x)$ is just a dimensionless multiplier, but in reality both $a$ and $x$ have units and I'm a bit nervous about having these quantities inside my exponential . In the next step, I need to differentiate $$y = \frac{x - a}{\tau(1 + e^{(a - x)})}$$ with respect to $x$. This took me a depressingly long time by hand, but my answer (which agrees with Wolfram Alpha) is $$\frac{dy}{dx} = \frac{(x - a)e^{(a - x)}}{\tau(e^{(a - x)} + 1)^2} + \frac{1}{\tau(e^{(a - x)} + 1)}$$ When I link all this together with the other ODEs in my system, everything works fine and the results look plausible, which is great. However, because of the way I constructed $g(x)$, the units/dimensions in the above equation no longer make sense, which makes me think I might be getting a sensible answer, but for the wrong reasons . Is my general approach here valid, or is there a better/more rigorous way of thinking about this that would keep the units consistent? Thanks very much!","I'm trying to construct a simple mathematical model for a physical system, but my calculus is rusty and I'm tying myself in knots, especially with regard to the dimensions of the quantities I'm using. The system obeys the equations $$y = \frac{x - a}{\tau} \qquad for \qquad x > a$$ $$y = 0 \qquad for \qquad x \leq a$$ $x$ and $a$ have units of length, $\tau$ has units of time and $y$ has units of $L/T$. $a$ and $\tau$ are constants. The discontinuity at $x = a$ causes me some problems later in my analysis, so I've been approximating it as $$y = \frac{x -a}{\tau} g(x)$$ where $$g(x) = \frac{1}{1 + e^{(a - x)}}$$ The function $g(x)$ switches fairly quickly from $\approx 0$ to $\approx 1$ at $x = a$, which gives a continuous representation of the discontinuity that is sufficiently abrupt for my purposes. In principle, $g(x)$ is just a dimensionless multiplier, but in reality both $a$ and $x$ have units and I'm a bit nervous about having these quantities inside my exponential . In the next step, I need to differentiate $$y = \frac{x - a}{\tau(1 + e^{(a - x)})}$$ with respect to $x$. This took me a depressingly long time by hand, but my answer (which agrees with Wolfram Alpha) is $$\frac{dy}{dx} = \frac{(x - a)e^{(a - x)}}{\tau(e^{(a - x)} + 1)^2} + \frac{1}{\tau(e^{(a - x)} + 1)}$$ When I link all this together with the other ODEs in my system, everything works fine and the results look plausible, which is great. However, because of the way I constructed $g(x)$, the units/dimensions in the above equation no longer make sense, which makes me think I might be getting a sensible answer, but for the wrong reasons . Is my general approach here valid, or is there a better/more rigorous way of thinking about this that would keep the units consistent? Thanks very much!",,"['derivatives', 'dimensional-analysis']"
48,If $x = a( \theta +\sin \theta)$ and $y = a(1-\cos \theta)$ then find $\frac{dy}{dx}$,If  and  then find,x = a( \theta +\sin \theta) y = a(1-\cos \theta) \frac{dy}{dx},If $x = a( \theta +\sin \theta)$ and $y = a(1-\cos \theta)$ then $\frac{dy}{dx}$ will be equal to : $a) \sin \frac{\theta}{2}$ $b) \cos \frac{\theta}{2}$ $c) \tan \frac{\theta}{2}$ $d) \cot \frac{\theta}{2}$ I have solved till : $\frac{dy}{dx} = \frac{\sin \theta}{1 + \cos \theta}$ using $\frac{dy}{dx} = \frac{dy}{d \theta} . \frac{d \theta}{dx}$. How do I reduce to the option's forms?,If $x = a( \theta +\sin \theta)$ and $y = a(1-\cos \theta)$ then $\frac{dy}{dx}$ will be equal to : $a) \sin \frac{\theta}{2}$ $b) \cos \frac{\theta}{2}$ $c) \tan \frac{\theta}{2}$ $d) \cot \frac{\theta}{2}$ I have solved till : $\frac{dy}{dx} = \frac{\sin \theta}{1 + \cos \theta}$ using $\frac{dy}{dx} = \frac{dy}{d \theta} . \frac{d \theta}{dx}$. How do I reduce to the option's forms?,,"['calculus', 'derivatives']"
49,How are these two methods for numerical differentiation connected?,How are these two methods for numerical differentiation connected?,,"I've read a book about Numerical Differentiation, and I found this formula: coefficient derivative I think this might be connected to the derivative of Lagrange Interpolating Polynomial, if I'm not mistaken they are equal. I just don't know how to prove it.","I've read a book about Numerical Differentiation, and I found this formula: coefficient derivative I think this might be connected to the derivative of Lagrange Interpolating Polynomial, if I'm not mistaken they are equal. I just don't know how to prove it.",,"['derivatives', 'numerical-methods', 'lagrange-interpolation']"
50,How to calculate this integral without any integration techniques?,How to calculate this integral without any integration techniques?,,"Differentiate  $f(x) = (5x+2)\ln(2x+1)$ with respect to $x$. Hence, find $\int \ln(2x+1)^3dx$. Because of the word ""Hence"" I'm assuming that the question doesn't allow integration techniques such as integration by parts or substitution. The first part is trivial. The derivative is $5\ln(2x+1) + \dfrac{2(5x+2)}{2x+1}$. Now my line of thought so far has been to somehow get this derivative to the desired result: $\ln(2x+1)^3$ and then use $f(x)$ to get the integral. However I don't see any straight way to do this. So I decided to experiment a little. Firstly I differentiated $(3x+2)\ln(2x+1)$ and got $$3\ln(2x+1) + \dfrac{2(3x+2)}{2x+1}$$ Now at least I have the $\ln(2x+1)^3$ term but I have another complication: $\dfrac{2(3x+2)}{2x+1}$. I decided to take a look at the answer: $3x\ln(2x+1) + \dfrac{3}{2}\ln(2x+1) - 3x + C$. I thought that if I differentiated this, I would have some idea of where I should go, and how to proceed. So that's what I did, and I got: $$3\ln(2x+1) + \dfrac{2(3x)}{2x+1} + \dfrac{3}{2x+1} - 3$$ This is perfect because $\dfrac{2(3x)}{2x+1} + \dfrac{3}{2x+1} - 3$ cancels out perfectly. But I have no idea how to get here, starting from $f'(x)$. But I'd say that my first experiment was pretty close. Any help would be highly appreciated.","Differentiate  $f(x) = (5x+2)\ln(2x+1)$ with respect to $x$. Hence, find $\int \ln(2x+1)^3dx$. Because of the word ""Hence"" I'm assuming that the question doesn't allow integration techniques such as integration by parts or substitution. The first part is trivial. The derivative is $5\ln(2x+1) + \dfrac{2(5x+2)}{2x+1}$. Now my line of thought so far has been to somehow get this derivative to the desired result: $\ln(2x+1)^3$ and then use $f(x)$ to get the integral. However I don't see any straight way to do this. So I decided to experiment a little. Firstly I differentiated $(3x+2)\ln(2x+1)$ and got $$3\ln(2x+1) + \dfrac{2(3x+2)}{2x+1}$$ Now at least I have the $\ln(2x+1)^3$ term but I have another complication: $\dfrac{2(3x+2)}{2x+1}$. I decided to take a look at the answer: $3x\ln(2x+1) + \dfrac{3}{2}\ln(2x+1) - 3x + C$. I thought that if I differentiated this, I would have some idea of where I should go, and how to proceed. So that's what I did, and I got: $$3\ln(2x+1) + \dfrac{2(3x)}{2x+1} + \dfrac{3}{2x+1} - 3$$ This is perfect because $\dfrac{2(3x)}{2x+1} + \dfrac{3}{2x+1} - 3$ cancels out perfectly. But I have no idea how to get here, starting from $f'(x)$. But I'd say that my first experiment was pretty close. Any help would be highly appreciated.",,"['calculus', 'integration', 'derivatives']"
51,Quick clarification on the definition of vector field,Quick clarification on the definition of vector field,,"I am having a class on differential geometry and another on ODEs In the ODE class, if we were given something of the type $$\dot x = x^2$$ The professor refers to $x^2$ as the vector field. In the differential geometry class, we refer to $$X = x^2 \frac{\partial}{\partial x}$$ as the vector field Can someone clarify the relationship between the two equations above?","I am having a class on differential geometry and another on ODEs In the ODE class, if we were given something of the type $$\dot x = x^2$$ The professor refers to $x^2$ as the vector field. In the differential geometry class, we refer to $$X = x^2 \frac{\partial}{\partial x}$$ as the vector field Can someone clarify the relationship between the two equations above?",,"['ordinary-differential-equations', 'differential-geometry', 'derivatives', 'definition', 'vector-fields']"
52,Problem on Rolle's Theorem,Problem on Rolle's Theorem,,"I need to get hint/solution for the following problem: Let $f(x)$ defined in $[0,1]$ be twice differentiable such that $$|f''(x)| \leq 1$$ for all $x$ belonging to $[0,1]$. If $$f(0) = f(1)$$ show that $$|f(x)| < 1$$ for all $x$ belonging to $[0,1]$. I tried like this: Integrating  $|f''(x)| \leq 1$ we get $$|f'(x)| \leq x$$ and since $x \leqslant 1$ $$|f'(x)| \leq 1$$ Integrating again, $$|f(x)| \leq x$$ and since $x \leqslant 1$ $$|f(x)| \leq 1$$ Is there any better approach? Am I doing anything wrong?","I need to get hint/solution for the following problem: Let $f(x)$ defined in $[0,1]$ be twice differentiable such that $$|f''(x)| \leq 1$$ for all $x$ belonging to $[0,1]$. If $$f(0) = f(1)$$ show that $$|f(x)| < 1$$ for all $x$ belonging to $[0,1]$. I tried like this: Integrating  $|f''(x)| \leq 1$ we get $$|f'(x)| \leq x$$ and since $x \leqslant 1$ $$|f'(x)| \leq 1$$ Integrating again, $$|f(x)| \leq x$$ and since $x \leqslant 1$ $$|f(x)| \leq 1$$ Is there any better approach? Am I doing anything wrong?",,"['real-analysis', 'analysis', 'derivatives']"
53,Complex continuity and differentiability of a piecewise function,Complex continuity and differentiability of a piecewise function,,"Let $g(z):\mathbb{C}\rightarrow\mathbb{C}$ with  $$g(z)=g(x+iy) =        \begin{cases}         \dfrac{x^2y+ixy^2}{x^2+y^2} & : (x,y)\neq (0,0), \\         0 & : (x,y)=(0,0).      \end{cases} $$ 1 How do I show that $g$ is continuous at $z=0$? 2 How do I show that $g$ is not complex differentiable at $z=0$? What I know: 1 I know that the composition of continuous functions is continuous, but I don't know how to show that the 'subfunctions' of $g$ are continuous. How would I do this with the $\varepsilon$-$\delta$-definition of continuity? 2 I know that $g$ satisfies the Cauchy-Riemann equations at $z=0$, but this is not enough right? My textbook says that $g$ must be also totally differentiable at $z=0$ in the sense of real analysis ($\mathbb{C}=\mathbb{R}^2$). How would I show this? Edit: $g$ is NOT differentiable at $z=0$.","Let $g(z):\mathbb{C}\rightarrow\mathbb{C}$ with  $$g(z)=g(x+iy) =        \begin{cases}         \dfrac{x^2y+ixy^2}{x^2+y^2} & : (x,y)\neq (0,0), \\         0 & : (x,y)=(0,0).      \end{cases} $$ 1 How do I show that $g$ is continuous at $z=0$? 2 How do I show that $g$ is not complex differentiable at $z=0$? What I know: 1 I know that the composition of continuous functions is continuous, but I don't know how to show that the 'subfunctions' of $g$ are continuous. How would I do this with the $\varepsilon$-$\delta$-definition of continuity? 2 I know that $g$ satisfies the Cauchy-Riemann equations at $z=0$, but this is not enough right? My textbook says that $g$ must be also totally differentiable at $z=0$ in the sense of real analysis ($\mathbb{C}=\mathbb{R}^2$). How would I show this? Edit: $g$ is NOT differentiable at $z=0$.",,"['real-analysis', 'complex-analysis', 'derivatives', 'continuity']"
54,Differentiability of $\int_0^tx^2f(x)dt$,Differentiability of,\int_0^tx^2f(x)dt,"If $f(x)$ is continuous, how can I prove that $\int_0^tx^2f(x)dt$ is differentiable? This is what I thought of: Since $\int_0^tx^2f(x)dt=F(t)-F(0)$ for some function $F$ which is the antiderivative of $x^2f(x)$ so $F$ is differentiable. Thus $\int_0^tx^2f(x)dt$ is differentiable. Am I right?","If $f(x)$ is continuous, how can I prove that $\int_0^tx^2f(x)dt$ is differentiable? This is what I thought of: Since $\int_0^tx^2f(x)dt=F(t)-F(0)$ for some function $F$ which is the antiderivative of $x^2f(x)$ so $F$ is differentiable. Thus $\int_0^tx^2f(x)dt$ is differentiable. Am I right?",,"['calculus', 'derivatives']"
55,Does the first derivative test always work for finding minima and maxima?,Does the first derivative test always work for finding minima and maxima?,,"Suppose you want to find the max of the function $\ f(x)=\sqrt{x} - x$. Using the first derivative test you get, $f'(x)= \frac{1}{2\sqrt{x}} - 1$ . If we equate this to $0$ we get $x =\frac{1}{4}$. Taking as $x$ as $0.20$ and $0.30$, we get that the first derivative doesn't change signs (remains positive). However, if x is taken as $x > 1$, then the first derivative becomes negative. Graphing the function reveals that $x =\frac{1}{4}$ is indeed the maximum point. Taking the second derivative $\ f\prime\prime(x)= \frac{-1}{4x^\frac{3}{2}}$ and using the second derivative test at the point $x =\frac{1}{4}$ shows the second derivative is negative, indicating a maximum. My question therefore is does the first derivative test necessarily always show the maximum? Both the graphs and second derivatives indicate a maximum; however if the first derivative is taken with $x < 1$ then the first derivative test fails. Can someone explain how this could happen?","Suppose you want to find the max of the function $\ f(x)=\sqrt{x} - x$. Using the first derivative test you get, $f'(x)= \frac{1}{2\sqrt{x}} - 1$ . If we equate this to $0$ we get $x =\frac{1}{4}$. Taking as $x$ as $0.20$ and $0.30$, we get that the first derivative doesn't change signs (remains positive). However, if x is taken as $x > 1$, then the first derivative becomes negative. Graphing the function reveals that $x =\frac{1}{4}$ is indeed the maximum point. Taking the second derivative $\ f\prime\prime(x)= \frac{-1}{4x^\frac{3}{2}}$ and using the second derivative test at the point $x =\frac{1}{4}$ shows the second derivative is negative, indicating a maximum. My question therefore is does the first derivative test necessarily always show the maximum? Both the graphs and second derivatives indicate a maximum; however if the first derivative is taken with $x < 1$ then the first derivative test fails. Can someone explain how this could happen?",,"['calculus', 'derivatives']"
56,Finite derivative of the harmonic series,Finite derivative of the harmonic series,,"In Knuth's Concrete Mathematics he represents the famous quicksort algorithm in computer science as a infinite sum then shows that sum can be simplified to being essentially harmonic. I want to explore this sum more by taking a finite derivative of the function but I have not taken any discrete math courses and am struggling with notation. My question: Suppose, $$f(n)=\sum_{n=0}^\infty \frac{1}{n+1}$$ Now suppose we take the generalized finite difference of that function,  $$\Delta _h^\mu [f](x)=\sum_{x=0}^\infty \mu_k f(x+kh)$$ Have I set this up properly? I want to explore the finite difference of this series. If I have not set this up correctly, might you point me in the right direction of what I might read to learn how to do this myself. Thank you.","In Knuth's Concrete Mathematics he represents the famous quicksort algorithm in computer science as a infinite sum then shows that sum can be simplified to being essentially harmonic. I want to explore this sum more by taking a finite derivative of the function but I have not taken any discrete math courses and am struggling with notation. My question: Suppose, $$f(n)=\sum_{n=0}^\infty \frac{1}{n+1}$$ Now suppose we take the generalized finite difference of that function,  $$\Delta _h^\mu [f](x)=\sum_{x=0}^\infty \mu_k f(x+kh)$$ Have I set this up properly? I want to explore the finite difference of this series. If I have not set this up correctly, might you point me in the right direction of what I might read to learn how to do this myself. Thank you.",,"['sequences-and-series', 'discrete-mathematics', 'derivatives', 'summation']"
57,Uniform convergence towards continuous derivative?,Uniform convergence towards continuous derivative?,,"Hi I was having trouble with the following question: A user called Fischer has said that ""The convergence is uniform on every compact subset of $\mathbb{R}$, however"", without providing a proof. ( Uniform convergence to the derivative ) Help will be appreciated?","Hi I was having trouble with the following question: A user called Fischer has said that ""The convergence is uniform on every compact subset of $\mathbb{R}$, however"", without providing a proof. ( Uniform convergence to the derivative ) Help will be appreciated?",,"['derivatives', 'uniform-convergence']"
58,Frechet Derivative of a direct product of functions,Frechet Derivative of a direct product of functions,,"Given two functions $f: U \to \mathbb{Y}$ and $g: U \to \mathbb{Y}$ (where $U\subset \mathbb{X}$ is open) that are Frechet differentiable at $x$. Also, $||(x,y)||_{\mathbb{X} \times \mathbb{X}}=||x||_{\mathbb{X}} + ||y||_{\mathbb{X}}$.  What is the Frechet derivate of $f \times g: U \times U \to \mathbb{Y} \times \mathbb{Y}$ at $x$, where $(f \times g)(u,v)=(f(u),g(v))$ I have proven that $f \times g$ is Frechet differentiable at $x$, but I cannot find an appropriate derivative for it.","Given two functions $f: U \to \mathbb{Y}$ and $g: U \to \mathbb{Y}$ (where $U\subset \mathbb{X}$ is open) that are Frechet differentiable at $x$. Also, $||(x,y)||_{\mathbb{X} \times \mathbb{X}}=||x||_{\mathbb{X}} + ||y||_{\mathbb{X}}$.  What is the Frechet derivate of $f \times g: U \times U \to \mathbb{Y} \times \mathbb{Y}$ at $x$, where $(f \times g)(u,v)=(f(u),g(v))$ I have proven that $f \times g$ is Frechet differentiable at $x$, but I cannot find an appropriate derivative for it.",,"['derivatives', 'frechet-derivative']"
59,Derivative of Nested Matrix Quadratic Form,Derivative of Nested Matrix Quadratic Form,,"I have two real matrices: $\mathbf{A} \in \mathbb{R}^{k \times d}$, $\mathbf{B} \in \mathbb{R}^{d \times d}$, where $k \leq d$. Further $\mathbf{B}$ is symmetric. I also have two vectors $\mathbf{c},\mathbf{d} \in \mathbb{R}^d$. My question is, what is gradient of the following expression with respect to $\mathbf{A}$: $$ (\mathbf{A} \mathbf{c})^\top (\mathbf{A} \mathbf{B} \mathbf{A}^\top)^{-1} (\mathbf{A} \mathbf{d}) $$ An observation: I know from the Matrix Cookbook that, if I replace the matrix $(\mathbf{A}^\top \mathbf{B} \mathbf{A})^{-1}$ with a matrix $\mathbf{E} \in \mathbb{R}^{d \times d}$ (that does not depend on $\mathbf{A}$) we have that: $$ \nabla_\mathbf{A} (\mathbf{A} \mathbf{c})^\top \mathbf{E} (\mathbf{A} \mathbf{d}) = \mathbf{E}^\top \mathbf{A} \mathbf{c} \mathbf{d}^\top + \mathbf{E} \mathbf{A} \mathbf{d} \mathbf{c}^\top $$ where $\nabla_\mathbf{A}$ signifies the gradient with respect to $\mathbf{A}$. So it seems I'm just missing a chain-rule step. Thank you very much for any insights about this.","I have two real matrices: $\mathbf{A} \in \mathbb{R}^{k \times d}$, $\mathbf{B} \in \mathbb{R}^{d \times d}$, where $k \leq d$. Further $\mathbf{B}$ is symmetric. I also have two vectors $\mathbf{c},\mathbf{d} \in \mathbb{R}^d$. My question is, what is gradient of the following expression with respect to $\mathbf{A}$: $$ (\mathbf{A} \mathbf{c})^\top (\mathbf{A} \mathbf{B} \mathbf{A}^\top)^{-1} (\mathbf{A} \mathbf{d}) $$ An observation: I know from the Matrix Cookbook that, if I replace the matrix $(\mathbf{A}^\top \mathbf{B} \mathbf{A})^{-1}$ with a matrix $\mathbf{E} \in \mathbb{R}^{d \times d}$ (that does not depend on $\mathbf{A}$) we have that: $$ \nabla_\mathbf{A} (\mathbf{A} \mathbf{c})^\top \mathbf{E} (\mathbf{A} \mathbf{d}) = \mathbf{E}^\top \mathbf{A} \mathbf{c} \mathbf{d}^\top + \mathbf{E} \mathbf{A} \mathbf{d} \mathbf{c}^\top $$ where $\nabla_\mathbf{A}$ signifies the gradient with respect to $\mathbf{A}$. So it seems I'm just missing a chain-rule step. Thank you very much for any insights about this.",,"['linear-algebra', 'matrices', 'derivatives', 'inverse']"
60,"Compute $\frac{d}{dt}\int_0^t e^{x(s)}ds$, where $x$ is a standard Brownian motion.","Compute , where  is a standard Brownian motion.",\frac{d}{dt}\int_0^t e^{x(s)}ds x,"How to compute the following differentiation? Is there a general rule that can be applied? $$\frac{d}{dt}\int_0^t e^{x(s)}ds$$ in the case of $x=W$ where $W$ is a standard brownian motion, is there some particular facts to take into account? if one applies the fundamental theorem of calculus : $$\frac{d}{dx}\left( \int_{a(x)}^{b(x)}f(x,t)dt \right)=f(x,b(x))b'(x)-f(x,a(x))a'(x)+\int_{a(x)}^{b(x)}\frac{d}{dx}f(x,t)dt$$ letting in our case $x=t$, $b(x)=t$, $a(x)=0$ and $f(W,t)=e^{W_t}$ we have : $$\frac{d}{dt}\left( \int_{0}^{t}e^{W_s}ds \right)=e^{W_t}+\int_{0}^{t}\frac{d}{ds}e^{W_s}ds$$ the problem is that $\frac{d}{ds}e^{W_s}$ cannot be computed as a borwian motion is not derivable. any help?","How to compute the following differentiation? Is there a general rule that can be applied? $$\frac{d}{dt}\int_0^t e^{x(s)}ds$$ in the case of $x=W$ where $W$ is a standard brownian motion, is there some particular facts to take into account? if one applies the fundamental theorem of calculus : $$\frac{d}{dx}\left( \int_{a(x)}^{b(x)}f(x,t)dt \right)=f(x,b(x))b'(x)-f(x,a(x))a'(x)+\int_{a(x)}^{b(x)}\frac{d}{dx}f(x,t)dt$$ letting in our case $x=t$, $b(x)=t$, $a(x)=0$ and $f(W,t)=e^{W_t}$ we have : $$\frac{d}{dt}\left( \int_{0}^{t}e^{W_s}ds \right)=e^{W_t}+\int_{0}^{t}\frac{d}{ds}e^{W_s}ds$$ the problem is that $\frac{d}{ds}e^{W_s}$ cannot be computed as a borwian motion is not derivable. any help?",,"['probability', 'integration', 'derivatives', 'stochastic-processes', 'stochastic-calculus']"
61,General question of derivatives and their inversions,General question of derivatives and their inversions,,"If $\frac{df(x,y)}{dx} = a$, does $\frac{1}{a} = \frac{dx}{df(x,y)}$? Consider $f(x,y) = x^2y \Rightarrow \frac{df(x,y)}{dx} = 2xy \equiv a$, than $\frac{1}{a} = \frac{1}{2xy}$. Now calculate $\frac{dx}{df(x,y)} = \frac{dx}{d(x^2y)}$ via substitution $x^2y = u \Rightarrow x = \pm \sqrt{\frac{u}{y}} \Rightarrow \frac{dx}{d(x^2y)} = \frac{\sqrt{\frac{u}{y}}}{du} = \frac{1}{2} (\frac{u}{y})^{-\frac{1}{2}} \frac{1}{y} = \frac{1}{2} \frac{1}{\sqrt{x^2}y} = \frac{1}{2xy}$ So it seems my claim is true, but it still feels strange to me. Could I be just lucky with my example? Some info about my background. I'm a physics major and started pondering about thermodynamics, where the definition of absolute temperature is given as $\frac{1}{T} = \frac{dS(E,\lambda)}{dE}$, with temperature $T$, entropy $S$, energy $E$ and some other (fixed) system variable $\lambda$. Reason for my confusion is that I can't make much (physical) sense out of $\frac{dE}{dS(E,\lambda)}$, which with my claim would equal to $T$.","If $\frac{df(x,y)}{dx} = a$, does $\frac{1}{a} = \frac{dx}{df(x,y)}$? Consider $f(x,y) = x^2y \Rightarrow \frac{df(x,y)}{dx} = 2xy \equiv a$, than $\frac{1}{a} = \frac{1}{2xy}$. Now calculate $\frac{dx}{df(x,y)} = \frac{dx}{d(x^2y)}$ via substitution $x^2y = u \Rightarrow x = \pm \sqrt{\frac{u}{y}} \Rightarrow \frac{dx}{d(x^2y)} = \frac{\sqrt{\frac{u}{y}}}{du} = \frac{1}{2} (\frac{u}{y})^{-\frac{1}{2}} \frac{1}{y} = \frac{1}{2} \frac{1}{\sqrt{x^2}y} = \frac{1}{2xy}$ So it seems my claim is true, but it still feels strange to me. Could I be just lucky with my example? Some info about my background. I'm a physics major and started pondering about thermodynamics, where the definition of absolute temperature is given as $\frac{1}{T} = \frac{dS(E,\lambda)}{dE}$, with temperature $T$, entropy $S$, energy $E$ and some other (fixed) system variable $\lambda$. Reason for my confusion is that I can't make much (physical) sense out of $\frac{dE}{dS(E,\lambda)}$, which with my claim would equal to $T$.",,['derivatives']
62,"What is the range of the derivative of $g(x) = f(x)/(x+1)$, where $f(x)$ is differentiable on $x\in[0,5]$?","What is the range of the derivative of , where  is differentiable on ?","g(x) = f(x)/(x+1) f(x) x\in[0,5]","Let $g(x) = f(x)/(x+1)$, where $f(x)$ is differentiable on $x\in[0,5]$, such that $f(0)=4$ and $f(5)=-1$. What is the range of values $g'(c)$ for a $c$ belonging to $[0,5]$? Considering values of $f(x_i)$, $f(x)$ must decrease at least once from $0$ to $5$. But that is all the information I can use here. Is there anything I am missing?","Let $g(x) = f(x)/(x+1)$, where $f(x)$ is differentiable on $x\in[0,5]$, such that $f(0)=4$ and $f(5)=-1$. What is the range of values $g'(c)$ for a $c$ belonging to $[0,5]$? Considering values of $f(x_i)$, $f(x)$ must decrease at least once from $0$ to $5$. But that is all the information I can use here. Is there anything I am missing?",,"['calculus', 'derivatives']"
63,Clarke's generalized gradient formula computed on functions defined on open sets,Clarke's generalized gradient formula computed on functions defined on open sets,,"In the book [1], Clarke et al. define the generalized gradient for a Lipschitz function $f:\mathbb{R}^n\to\mathbb{R}$ as follows. 8.1. Theorem (Generalized Gradient Formula). Let $x\in\mathbb{R}^n$, and let $f:\mathbb{R}^n\to\mathbb{R}$ be Lipschitz near $x$. Let $\Omega$ be any subset of zero measure in $\mathbb{R}^n$, and let $\Omega_f$ be the set of points in $\mathbb{R}^n$ at which $f$ fails to be differentiable. Then,   \begin{equation*}  \partial f(x):=co\{\lim\nabla f(x_i):x_i\to x, x_i\notin\Omega,x_i\notin\Omega_f\} \end{equation*} In other words, the generalized gradient of $f$ at $x$ is the convex hull whose elements are the limiting points of the gradient of $f$ computed at the elements of sequences converging to $x$. Moreover, these elements of sequences do not belong to any set of measure zero nor to the set of points where $f$ fails to be differentiable. Here follows my question. If $f$ is defined on any open subset $S$ of $\mathbb{R}^n$, i.e., $f:S\to\mathbb{R}$, does the above formula hold as below Let $x\in S$, and $\Omega(S)$ be any subset of $S$ with measure zero with respect to $\mathbb{R}^n$, and let $\Omega_f(S)$ be the set of points in $S$ at which $f$ fails to be differentiable. Then, \begin{equation*}  \partial f(x):=co\{\lim\nabla f(x_i):x_i\to x, x_i\notin\Omega(S),x_i\notin\Omega_f(S)\} ? \end{equation*} My answer is no, because $S$ is open. Consequently, $S$ does not contains the limit $\lim\nabla f(x_i)$. Thus, $\partial f(x)$ may not be defined in $S$. Is this reasoning correct? References [1] Clarke et al, ""Nonsmooth Analysis and Control Theory"", Springer 1998","In the book [1], Clarke et al. define the generalized gradient for a Lipschitz function $f:\mathbb{R}^n\to\mathbb{R}$ as follows. 8.1. Theorem (Generalized Gradient Formula). Let $x\in\mathbb{R}^n$, and let $f:\mathbb{R}^n\to\mathbb{R}$ be Lipschitz near $x$. Let $\Omega$ be any subset of zero measure in $\mathbb{R}^n$, and let $\Omega_f$ be the set of points in $\mathbb{R}^n$ at which $f$ fails to be differentiable. Then,   \begin{equation*}  \partial f(x):=co\{\lim\nabla f(x_i):x_i\to x, x_i\notin\Omega,x_i\notin\Omega_f\} \end{equation*} In other words, the generalized gradient of $f$ at $x$ is the convex hull whose elements are the limiting points of the gradient of $f$ computed at the elements of sequences converging to $x$. Moreover, these elements of sequences do not belong to any set of measure zero nor to the set of points where $f$ fails to be differentiable. Here follows my question. If $f$ is defined on any open subset $S$ of $\mathbb{R}^n$, i.e., $f:S\to\mathbb{R}$, does the above formula hold as below Let $x\in S$, and $\Omega(S)$ be any subset of $S$ with measure zero with respect to $\mathbb{R}^n$, and let $\Omega_f(S)$ be the set of points in $S$ at which $f$ fails to be differentiable. Then, \begin{equation*}  \partial f(x):=co\{\lim\nabla f(x_i):x_i\to x, x_i\notin\Omega(S),x_i\notin\Omega_f(S)\} ? \end{equation*} My answer is no, because $S$ is open. Consequently, $S$ does not contains the limit $\lim\nabla f(x_i)$. Thus, $\partial f(x)$ may not be defined in $S$. Is this reasoning correct? References [1] Clarke et al, ""Nonsmooth Analysis and Control Theory"", Springer 1998",,"['real-analysis', 'functional-analysis', 'derivatives', 'control-theory', 'non-smooth-analysis']"
64,Find the $\Delta y$ of $f(x)={1 \over x^2}$; $x=2; \Delta x = 0.01$,Find the  of ;,\Delta y f(x)={1 \over x^2} x=2; \Delta x = 0.01,Find the $\Delta y$ of $f(x)={1 \over x^2}$; $x=2; \Delta x = 0.01$ when $\Delta y = f(x+ \Delta x) - f(x)$ So here's what I did: $$\Delta y = f(x+ \Delta x) - f(x) \\ \Delta y = {1 \over (x+ \Delta x)^2} - {1 \over x^2}\\ = {1 \over x^2+2x\Delta x +\Delta x^2} - {1 \over x^2}\\ ={1 \over 2x\Delta x + \Delta x^2}$$ Now substituting x=2 and $\Delta x$=0.01 $${1\over 2(2)(0.01) + (0.01)^2}\\ ={1\over 0.04+0.0001}\\ ={1 \over 0.0401}\\ $$ I'm pretty sure there is something wrong I did. It says that the answer is supposed to be $$-0.00248$$,Find the $\Delta y$ of $f(x)={1 \over x^2}$; $x=2; \Delta x = 0.01$ when $\Delta y = f(x+ \Delta x) - f(x)$ So here's what I did: $$\Delta y = f(x+ \Delta x) - f(x) \\ \Delta y = {1 \over (x+ \Delta x)^2} - {1 \over x^2}\\ = {1 \over x^2+2x\Delta x +\Delta x^2} - {1 \over x^2}\\ ={1 \over 2x\Delta x + \Delta x^2}$$ Now substituting x=2 and $\Delta x$=0.01 $${1\over 2(2)(0.01) + (0.01)^2}\\ ={1\over 0.04+0.0001}\\ ={1 \over 0.0401}\\ $$ I'm pretty sure there is something wrong I did. It says that the answer is supposed to be $$-0.00248$$,,"['calculus', 'ordinary-differential-equations', 'derivatives', 'proof-verification', 'differential']"
65,General clarification for derivative notation,General clarification for derivative notation,,"I am a bit confused on the different notations of derivatives, could you help me clear it up? The following can be interpreted as: the total derivative of f wrt x, or equivalently, the derivative of f(x) wrt x the partial derivative of f wrt x, or equivalently, the derivative of f(x,y,z) wrt x $\dfrac{df}{dx}=\dfrac{d(f(x))}{dx},\, f=f(x)$ $\dfrac{\partial f}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x},\, f=f(x,y,z)$ now the above is different from the below, which is: the total derivative of f wrt x, evaluated at the point a the partial derivative of f wrt x, evaluated at the point a, b, c $\dfrac{df}{dx}(a)=\dfrac{d(f(x))}{dx}(a),\, f=f(x)$ $\dfrac{\partial f}{\partial x}(a,b,c)=\dfrac{\partial(f(x,y,z))}{\partial x}(a,b,c),\, f=f(x,y,z)$ however if we do a super contrived example and set a = x and a, b, c=x, y, z then the following equality holds (except super contrived, yes?) $\dfrac{df}{dx}=\dfrac{d(f(x))}{dx}=\dfrac{d(f(x))}{dx}(x),\, f=f(x)$ $\dfrac{\partial f}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x}(x,y,z),\, f=f(x,y,z)$ no, this is not how I normally write derivatives, and I am only bending the rules so far as to test the boundaries/semantics Is the preceding interpretation correct?","I am a bit confused on the different notations of derivatives, could you help me clear it up? The following can be interpreted as: the total derivative of f wrt x, or equivalently, the derivative of f(x) wrt x the partial derivative of f wrt x, or equivalently, the derivative of f(x,y,z) wrt x $\dfrac{df}{dx}=\dfrac{d(f(x))}{dx},\, f=f(x)$ $\dfrac{\partial f}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x},\, f=f(x,y,z)$ now the above is different from the below, which is: the total derivative of f wrt x, evaluated at the point a the partial derivative of f wrt x, evaluated at the point a, b, c $\dfrac{df}{dx}(a)=\dfrac{d(f(x))}{dx}(a),\, f=f(x)$ $\dfrac{\partial f}{\partial x}(a,b,c)=\dfrac{\partial(f(x,y,z))}{\partial x}(a,b,c),\, f=f(x,y,z)$ however if we do a super contrived example and set a = x and a, b, c=x, y, z then the following equality holds (except super contrived, yes?) $\dfrac{df}{dx}=\dfrac{d(f(x))}{dx}=\dfrac{d(f(x))}{dx}(x),\, f=f(x)$ $\dfrac{\partial f}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x}=\dfrac{\partial(f(x,y,z))}{\partial x}(x,y,z),\, f=f(x,y,z)$ no, this is not how I normally write derivatives, and I am only bending the rules so far as to test the boundaries/semantics Is the preceding interpretation correct?",,"['derivatives', 'notation']"
66,Textual explanation of a derivative,Textual explanation of a derivative,,"In the book Structure and Interpretation of Computer Programs , there is an interesting example on how one might explore symbolic data in programming. They used the differentiation algorithm. That is, there is an algebraic expression (E.G. x+3) and find the derivative of this expression with respect to x. Now I've read and understood the program they created, but unfortunately have no idea what I'm actually doing. So, I began exploring derivatives because I thought I might learn something amazing. Unfortunately, all the explanations I found were in terms of slopes, y-intercept, x-intercept and all that. My eyes are destroyed, so I can't imagine those slope things and graphing function stuff, and no one explained to me what those things are in a clear way before. Is there an explanation of derivatives and how you might solve for one without using visual slopes?","In the book Structure and Interpretation of Computer Programs , there is an interesting example on how one might explore symbolic data in programming. They used the differentiation algorithm. That is, there is an algebraic expression (E.G. x+3) and find the derivative of this expression with respect to x. Now I've read and understood the program they created, but unfortunately have no idea what I'm actually doing. So, I began exploring derivatives because I thought I might learn something amazing. Unfortunately, all the explanations I found were in terms of slopes, y-intercept, x-intercept and all that. My eyes are destroyed, so I can't imagine those slope things and graphing function stuff, and no one explained to me what those things are in a clear way before. Is there an explanation of derivatives and how you might solve for one without using visual slopes?",,['derivatives']
67,Absolute continuity and Radon-Nikodym derivative,Absolute continuity and Radon-Nikodym derivative,,"Let $\nu$ be a measure and $\mu$ a finite measure on $(X,\Sigma)$ with $\nu \ll \mu$. (All $\mu$-null sets are $\nu$-null.) Theorem:   There exists a measurable $f:X \to [0,\infty]$ such that $\forall S \in \Sigma$,   $$ \nu(S) = \int_S f\,d\mu $$ How to prove this theorem? If $\nu$ is $\sigma$-finite, the result follows from Radon- Nikodym theorem. The question hints that there exists a $\nu\,\sigma$-finite $U$ such that $\mu(U) \geq \mu(T)$ for all $\nu\,\sigma$-finite $T$. I tried to make $U$ the union of all $\sigma$-finite sets, but I cannot show that it is $\sigma$-finite.","Let $\nu$ be a measure and $\mu$ a finite measure on $(X,\Sigma)$ with $\nu \ll \mu$. (All $\mu$-null sets are $\nu$-null.) Theorem:   There exists a measurable $f:X \to [0,\infty]$ such that $\forall S \in \Sigma$,   $$ \nu(S) = \int_S f\,d\mu $$ How to prove this theorem? If $\nu$ is $\sigma$-finite, the result follows from Radon- Nikodym theorem. The question hints that there exists a $\nu\,\sigma$-finite $U$ such that $\mu(U) \geq \mu(T)$ for all $\nu\,\sigma$-finite $T$. I tried to make $U$ the union of all $\sigma$-finite sets, but I cannot show that it is $\sigma$-finite.",,"['real-analysis', 'integration', 'measure-theory', 'derivatives']"
68,Finding the Fourth Derivative,Finding the Fourth Derivative,,"Let $f(x)$ be a four-times differential function such that $f(2x^2-1)=2xf(x)$ What is the value of $f''''(0)$? A brute force approach is differentiating the given condition 4 times and finding values of $f(x)$ and its derivatives at required numbers or at a value of $x$ where the function can be simplified. Considering the LHS has a composite function and the RHS has the product of 2 functions, differentiating both sides leads to a lot of terms. I tried shifting values of $x$ but  did not find a convenient substitution to simplify the problem. How should I proceed?","Let $f(x)$ be a four-times differential function such that $f(2x^2-1)=2xf(x)$ What is the value of $f''''(0)$? A brute force approach is differentiating the given condition 4 times and finding values of $f(x)$ and its derivatives at required numbers or at a value of $x$ where the function can be simplified. Considering the LHS has a composite function and the RHS has the product of 2 functions, differentiating both sides leads to a lot of terms. I tried shifting values of $x$ but  did not find a convenient substitution to simplify the problem. How should I proceed?",,"['calculus', 'derivatives']"
69,Banach fixed point theorem - Find $x$ such that $f(x) = 0$.,Banach fixed point theorem - Find  such that .,x f(x) = 0,"Let $f: \mathbb R \to \mathbb R$ be a continuous function with a continuous derivative. In short $f \in C^1$. We know that $0<c\leq f'(x) \leq d < \infty$.  We want to prove that $\exists! x_0 \in \mathbb R: f(x_0)=0$. Disclaimer: I am fully aware that there is a simple proof involving Rolle's theorem. This is not the proof I am after. I am trying to somehow invoke Banach Fixed Point Theorem in order to show that this function has a single root. Something I tried, to give you a general idea of what I'm looking for: Define $g(x) = \frac{1}{d}(f(x)-cx)$. We have that $0 \leq g'(x) \leq 1-\frac{c}{d}<1$ Now, since $f$ is $C^1$, we also have that $g$ is $C^1$. And more specifically, $g$ is continuous and with continuous derivative on all $[x_1,x_2]$ segments of the real line. So Lagrange mean value theorem applies. $\forall x_1,x_2 \in \mathbb R \exists c \in \mathbb R: g(x_1)-g(x_2)=g'(x)(x_1-x_2)$ If we add modules we get $|g(x_1)-g(x_2)| = |g'(c)||x_1-x_2| \leq |1-\frac{c}{d}||x_1-x_2|$ And so we have for all $x_1,x_2:$ $|g(x_1)-g(x_2)| \leq |1-\frac{c}{d}||x_1-x_2|$, which means $g$ is a contraction. So from Banach Fixed Point Theorem, $g$ admits a unique fixed point $g(x_0)=x_0$. The problem is: $g(x_0)=x_0$ does not imply that $f(x_0)=0$. Sure, it admits a fixed point but that does not help us prove that $f$ has a unique zero. if $g(x) = f(x)+x$ then that would have solved our problem, but no such luck. How can I use Banach fixed point theorem in a similar way to prove $f$ has a unique zero?","Let $f: \mathbb R \to \mathbb R$ be a continuous function with a continuous derivative. In short $f \in C^1$. We know that $0<c\leq f'(x) \leq d < \infty$.  We want to prove that $\exists! x_0 \in \mathbb R: f(x_0)=0$. Disclaimer: I am fully aware that there is a simple proof involving Rolle's theorem. This is not the proof I am after. I am trying to somehow invoke Banach Fixed Point Theorem in order to show that this function has a single root. Something I tried, to give you a general idea of what I'm looking for: Define $g(x) = \frac{1}{d}(f(x)-cx)$. We have that $0 \leq g'(x) \leq 1-\frac{c}{d}<1$ Now, since $f$ is $C^1$, we also have that $g$ is $C^1$. And more specifically, $g$ is continuous and with continuous derivative on all $[x_1,x_2]$ segments of the real line. So Lagrange mean value theorem applies. $\forall x_1,x_2 \in \mathbb R \exists c \in \mathbb R: g(x_1)-g(x_2)=g'(x)(x_1-x_2)$ If we add modules we get $|g(x_1)-g(x_2)| = |g'(c)||x_1-x_2| \leq |1-\frac{c}{d}||x_1-x_2|$ And so we have for all $x_1,x_2:$ $|g(x_1)-g(x_2)| \leq |1-\frac{c}{d}||x_1-x_2|$, which means $g$ is a contraction. So from Banach Fixed Point Theorem, $g$ admits a unique fixed point $g(x_0)=x_0$. The problem is: $g(x_0)=x_0$ does not imply that $f(x_0)=0$. Sure, it admits a fixed point but that does not help us prove that $f$ has a unique zero. if $g(x) = f(x)+x$ then that would have solved our problem, but no such luck. How can I use Banach fixed point theorem in a similar way to prove $f$ has a unique zero?",,"['calculus', 'derivatives', 'fixed-point-theorems']"
70,Define the function $H:\mathbb{R}\rightarrow\mathbb{R}$ by $H(x)=\int_{-x}^{x}[f(t)+f(-t)]dt\forall x$ Find $H''(x)$.,Define the function  by  Find .,H:\mathbb{R}\rightarrow\mathbb{R} H(x)=\int_{-x}^{x}[f(t)+f(-t)]dt\forall x H''(x),"Suppose that the function $f:\mathbb{R}\rightarrow\mathbb{R}$ is differentiable. Define the function $H:\mathbb{R}\rightarrow\mathbb{R}$ by $$H(x)=\int_{-x}^{x}[f(t)+f(-t)]dt\qquad\forall x$$ Find $H''(x)$. Proof: $\begin{align*} H(x)&=\int_{-x}^{x}[f(t)+f(-t)]dt=\int_{0}^{x}[f(t)+f(-t)]dt+\int_{-x}^{0}[f(t)+f(-t)]dt\\ H'(x)&=(f(x)+f(-x))+(f(-x)+f(x))=2f(x)+2f(-x) \end{align*}$ We have: $H''(x)=2f'(x)-2f'(-x)$ Can someone check the solution? I am not sure I apply the second fundamental theorem of calculus correctly or not. From the theorem, $$\frac{d}{dx}\left(\int_{a}^{x}f\right)=f(x)$$ So if $F(x)=\int_{0}^{x}f(-t)dt$, then $F'(x)=f(-x)$.","Suppose that the function $f:\mathbb{R}\rightarrow\mathbb{R}$ is differentiable. Define the function $H:\mathbb{R}\rightarrow\mathbb{R}$ by $$H(x)=\int_{-x}^{x}[f(t)+f(-t)]dt\qquad\forall x$$ Find $H''(x)$. Proof: $\begin{align*} H(x)&=\int_{-x}^{x}[f(t)+f(-t)]dt=\int_{0}^{x}[f(t)+f(-t)]dt+\int_{-x}^{0}[f(t)+f(-t)]dt\\ H'(x)&=(f(x)+f(-x))+(f(-x)+f(x))=2f(x)+2f(-x) \end{align*}$ We have: $H''(x)=2f'(x)-2f'(-x)$ Can someone check the solution? I am not sure I apply the second fundamental theorem of calculus correctly or not. From the theorem, $$\frac{d}{dx}\left(\int_{a}^{x}f\right)=f(x)$$ So if $F(x)=\int_{0}^{x}f(-t)dt$, then $F'(x)=f(-x)$.",,"['real-analysis', 'integration', 'derivatives']"
71,Differentiability for function $f(x) =$ greatest lower bound of $|x-\frac 1n|$ at $x=0$.,Differentiability for function  greatest lower bound of  at .,f(x) = |x-\frac 1n| x=0,"Let $$f(x)=\inf\,\bigl\{|x-\frac1n|: n\in\mathbb Z^+\bigr\}\,.$$ Is $f$ differentiable at $x=0$?","Let $$f(x)=\inf\,\bigl\{|x-\frac1n|: n\in\mathbb Z^+\bigr\}\,.$$ Is $f$ differentiable at $x=0$?",,"['real-analysis', 'derivatives']"
72,A function and its derivative chasing tails,A function and its derivative chasing tails,,"For which $t\ge0$ does there exist a differentiable function $f$ with $f(0)=0$, $f'(x)>f(x)$ for all $x>0$ and with $f'(0)=t$? This question was inspired by (and is a variation of) the following question and its answer . Let $f:\mathbb R \to \mathbb R$ be a differentiable function such that $f(0)=0$ and $f'(x)>f(x)$ for all $x>0$. It could be shown then, as in the answer referred to above,  that $f(x)>0$ for all $x>0$. The solution goes as follows (with some details added). Let $g(x)=e^{-x} f(x)$. Because $g'(x)=e^{-x}\Bigl(f'(x)-f(x\Bigr)>0$ we have that $g(x)$ is strictly increasing on the interval $(0,\infty)$. Since $g(0)=0$ we have $g(x)>0$ for all $x\in(0,\infty)$, hence $f(x)=e^x g(x)>0$ whenever $x\in(0,\infty)$. On close inspection this argument works even if we add to the assumptions the requirement that $f'(0)<0$. This seems contradictory, since then on one hand $f(x)>0$ for all $x>0$, but on the other hand $f(x)<0$ for all $x\in(0,\varepsilon)$, for some small enough $\varepsilon>0$. This contradiction only shows that no such $f$ exist that satisfy all these conditions (including  $f'(0)<0$).  Thus the following: Question .  For which $t\ge0$ does there exist an $f$ with $f'(0)=t$,  and with $f(0)=0$, $f'(x)>f(x)$ for all $x>0$? Easily $t1$ works, e.g. $f(x)=e^{tx}1$. I wonder if any $t<1$ might also work, in particular if $t=0$ works. I feel the solution may have something to do with the notion of blow up as understood in this answer , but I don't seem to be able to figure the details. Tried to get a modification of $e^{-\frac1{x^2}}$ but it only works on a bounded interval of positive reals, not on all of $(0,\infty)$. Thank you for your help. (I included tag integration only because I thought the answer may have also something to do with the average value of $f$ on any interval $[a,b]$, defined as $\frac1{b-a}\int_a^b f(x) dx$. In particular the average value of $f'(x)$ on $[0,b]$ is $\frac1b\int_0^b f'(x) dx=f(b)$.)","For which $t\ge0$ does there exist a differentiable function $f$ with $f(0)=0$, $f'(x)>f(x)$ for all $x>0$ and with $f'(0)=t$? This question was inspired by (and is a variation of) the following question and its answer . Let $f:\mathbb R \to \mathbb R$ be a differentiable function such that $f(0)=0$ and $f'(x)>f(x)$ for all $x>0$. It could be shown then, as in the answer referred to above,  that $f(x)>0$ for all $x>0$. The solution goes as follows (with some details added). Let $g(x)=e^{-x} f(x)$. Because $g'(x)=e^{-x}\Bigl(f'(x)-f(x\Bigr)>0$ we have that $g(x)$ is strictly increasing on the interval $(0,\infty)$. Since $g(0)=0$ we have $g(x)>0$ for all $x\in(0,\infty)$, hence $f(x)=e^x g(x)>0$ whenever $x\in(0,\infty)$. On close inspection this argument works even if we add to the assumptions the requirement that $f'(0)<0$. This seems contradictory, since then on one hand $f(x)>0$ for all $x>0$, but on the other hand $f(x)<0$ for all $x\in(0,\varepsilon)$, for some small enough $\varepsilon>0$. This contradiction only shows that no such $f$ exist that satisfy all these conditions (including  $f'(0)<0$).  Thus the following: Question .  For which $t\ge0$ does there exist an $f$ with $f'(0)=t$,  and with $f(0)=0$, $f'(x)>f(x)$ for all $x>0$? Easily $t1$ works, e.g. $f(x)=e^{tx}1$. I wonder if any $t<1$ might also work, in particular if $t=0$ works. I feel the solution may have something to do with the notion of blow up as understood in this answer , but I don't seem to be able to figure the details. Tried to get a modification of $e^{-\frac1{x^2}}$ but it only works on a bounded interval of positive reals, not on all of $(0,\infty)$. Thank you for your help. (I included tag integration only because I thought the answer may have also something to do with the average value of $f$ on any interval $[a,b]$, defined as $\frac1{b-a}\int_a^b f(x) dx$. In particular the average value of $f'(x)$ on $[0,b]$ is $\frac1b\int_0^b f'(x) dx=f(b)$.)",,"['real-analysis', 'integration', 'ordinary-differential-equations', 'derivatives', 'exponential-function']"
73,Does $\frac{f'(x+h)- \frac{f(x+h)-f(x)}{h}}{h}$ converge uniformly to the second derivative?,Does  converge uniformly to the second derivative?,\frac{f'(x+h)- \frac{f(x+h)-f(x)}{h}}{h},"I have arrived at an expression $$\frac{f'(x+h)- \frac{f(x+h)-f(x)}{h}}{h}$$ for a compactly supported function $f \in C_C^{\infty}(\mathbb{R}).$ Now I was asking myself, whether we have uniform convergence to the second derivative of $f$ at point $x.$ Intuitively it is clear that there could be a second derivative involved, as the right summand in the nominator goes to $f'(x)$ and thus we have a difference quotient $$\frac{f'(x+h)-f'(x)}{h}$$ which goes uniformly to zero, as $|f''|$ is bounded. Unfortunately, in this argument I am taking the limits separately which is not allowed I guess, so is there any way to make this argument rigorous?","I have arrived at an expression $$\frac{f'(x+h)- \frac{f(x+h)-f(x)}{h}}{h}$$ for a compactly supported function $f \in C_C^{\infty}(\mathbb{R}).$ Now I was asking myself, whether we have uniform convergence to the second derivative of $f$ at point $x.$ Intuitively it is clear that there could be a second derivative involved, as the right summand in the nominator goes to $f'(x)$ and thus we have a difference quotient $$\frac{f'(x+h)-f'(x)}{h}$$ which goes uniformly to zero, as $|f''|$ is bounded. Unfortunately, in this argument I am taking the limits separately which is not allowed I guess, so is there any way to make this argument rigorous?",,"['calculus', 'real-analysis']"
74,Explaining a proof of Euler's theorem,Explaining a proof of Euler's theorem,,Can someone please explain the question marked extrapolation in the following image?,Can someone please explain the question marked extrapolation in the following image?,,"['symmetry', 'derivatives']"
75,"Minimising Function, derivative with exponentials","Minimising Function, derivative with exponentials",,"First of all, I apologise for not giving a more descriptive title. I really do not know how to word it. I'll go straight into the meat of the question. If a function $$h(x)=\frac{e^x-1}{x^5}$$ is to be minimised, then you go about finding the first derivative and solving that for zero to find the critical points. I've done that and get the following $$h'(x)=\frac{xe^x-5e^x+5}{x^6}$$ and to find the critical points we then get $xe^x-5e^x+5=0$. I am either being extremely stupid or there is no way which you can use to isolate $x$ and so can't solve via a ""straightforward"" method. It should follow into a transcendental equation in the form $x=g(x)$. My research suggests there is a solution in terms of Lambert W functions, however this has not yet be taught in my university course, and checking with the lecturer we do not need them, i.e. ""straightforward"" method... What exactly am I missing here? Thanks in advance.","First of all, I apologise for not giving a more descriptive title. I really do not know how to word it. I'll go straight into the meat of the question. If a function $$h(x)=\frac{e^x-1}{x^5}$$ is to be minimised, then you go about finding the first derivative and solving that for zero to find the critical points. I've done that and get the following $$h'(x)=\frac{xe^x-5e^x+5}{x^6}$$ and to find the critical points we then get $xe^x-5e^x+5=0$. I am either being extremely stupid or there is no way which you can use to isolate $x$ and so can't solve via a ""straightforward"" method. It should follow into a transcendental equation in the form $x=g(x)$. My research suggests there is a solution in terms of Lambert W functions, however this has not yet be taught in my university course, and checking with the lecturer we do not need them, i.e. ""straightforward"" method... What exactly am I missing here? Thanks in advance.",,"['derivatives', 'optimization', 'exponential-function']"
76,Derivatives question on partial derivatives,Derivatives question on partial derivatives,,"If $z=f(x,y)$ and $x=e^u \cos v$, $y=e^u \sin v$ then show that  $y \frac{dz}{du} + x \frac{dz}{dv} = e^{2u} \frac{dz}{dy}$","If $z=f(x,y)$ and $x=e^u \cos v$, $y=e^u \sin v$ then show that  $y \frac{dz}{du} + x \frac{dz}{dv} = e^{2u} \frac{dz}{dy}$",,"['trigonometry', 'derivatives', 'exponential-function', 'partial-derivative']"
77,"Is the (anti)derivative of an even complex valued function odd, and vice versa?","Is the (anti)derivative of an even complex valued function odd, and vice versa?",,"I'm not sure how much content I can put for a relatively straightforward question, haha. But, I'm attempting to prove something about even and odd functions and integrals in Complex Analysis, and I was curious as to if it is true that the (anti)derivative of an even complex valued function is odd, and vice versa, as it is for reals (to my knowledge).","I'm not sure how much content I can put for a relatively straightforward question, haha. But, I'm attempting to prove something about even and odd functions and integrals in Complex Analysis, and I was curious as to if it is true that the (anti)derivative of an even complex valued function is odd, and vice versa, as it is for reals (to my knowledge).",,"['integration', 'complex-analysis', 'derivatives']"
78,derivative on both sides,derivative on both sides,,I am reading about feedback topologies and having some problems about math. I am not a math student so I need your help. Could you explain if the operation of taking derivative of both sides correct rigorously.  I read that we can't treat dA as a number (standard analysis) and there is something about differential form that could make it correct. Am I understanding it correctly?,I am reading about feedback topologies and having some problems about math. I am not a math student so I need your help. Could you explain if the operation of taking derivative of both sides correct rigorously.  I read that we can't treat dA as a number (standard analysis) and there is something about differential form that could make it correct. Am I understanding it correctly?,,"['calculus', 'derivatives']"
79,Differentiable limit theorem of a Continuous nowhere differentiable function,Differentiable limit theorem of a Continuous nowhere differentiable function,,"I am looking at Abbott's second edition of Understanding Analysis , and I am unsure if my answer is accurate. Exercise: The function $g(x) =\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}$ has been used as an example of a continuous nowhere differentiable function. What happens if we try to use the Differentiable Limit Theorem to explore whether g is differentiable? My solution: $g(x) =\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}$ $g'(x) =\frac{d}{dx}\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}=\sum_{n=0}^{\infty}\frac{d}{dx} \frac{\cos (2^{n}x)}{2^{n}}$ Consider the nth term $y =\frac{\cos (2^{n}x)}{2^{n}}$ Let $\Delta x$ be a small increment given to $x$, and $\Delta y$ the corresponding increment in $ y.$ $\Delta y=\frac{\cos (2^{n}(x+\Delta x))}{2^{n}}-\frac{\cos (2^{n}x)}{2^{n}}$ $=\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x) \sin 2^{n-1}\Delta x)$ Divide by $\Delta x$ $\frac{\Delta y}{\Delta x}=\frac{1}{\Delta x}\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x) \sin 2^{n-1}\Delta x)$ As $\Delta x$ tends to $0$, $\frac{\sin \Delta x}{\Delta x}$ tends to $1$ $=\frac{\Delta y}{\Delta x}=\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x))2^{n-1}$ $= (-2 \sin 2^{n-1}(2x))$ Thus it gives some answer for derivative of nth term","I am looking at Abbott's second edition of Understanding Analysis , and I am unsure if my answer is accurate. Exercise: The function $g(x) =\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}$ has been used as an example of a continuous nowhere differentiable function. What happens if we try to use the Differentiable Limit Theorem to explore whether g is differentiable? My solution: $g(x) =\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}$ $g'(x) =\frac{d}{dx}\sum_{n=0}^{\infty} \frac{\cos (2^{n}x)}{2^{n}}=\sum_{n=0}^{\infty}\frac{d}{dx} \frac{\cos (2^{n}x)}{2^{n}}$ Consider the nth term $y =\frac{\cos (2^{n}x)}{2^{n}}$ Let $\Delta x$ be a small increment given to $x$, and $\Delta y$ the corresponding increment in $ y.$ $\Delta y=\frac{\cos (2^{n}(x+\Delta x))}{2^{n}}-\frac{\cos (2^{n}x)}{2^{n}}$ $=\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x) \sin 2^{n-1}\Delta x)$ Divide by $\Delta x$ $\frac{\Delta y}{\Delta x}=\frac{1}{\Delta x}\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x) \sin 2^{n-1}\Delta x)$ As $\Delta x$ tends to $0$, $\frac{\sin \Delta x}{\Delta x}$ tends to $1$ $=\frac{\Delta y}{\Delta x}=\frac{1}{2^n}(-2 \sin 2^{n-1}(2x+\Delta x))2^{n-1}$ $= (-2 \sin 2^{n-1}(2x))$ Thus it gives some answer for derivative of nth term",,"['real-analysis', 'derivatives']"
80,Related rates: Two planes converging towards a point,Related rates: Two planes converging towards a point,,"An air traffic controller spots two planes at the same altitude converging on a point as they fly at right angles to each other. One plane is 225 miles from the point and is moving at 450 miles per hour. The other plane is 300 miles from the point and has a speed of 600 miles per hour."" ""a. At what rate is the distance between the planes decreasing? b. If the controller does not intervene, how close will the planes come to each other?"" I understand that we can use implicit differentiation to solve part a, which shows that the difference is decreasing at 750 mph. However, I wonder why in part b, the answer is 30 minutes. In other words, the difference between the two planes (the hypotenuse of their right angle) is decreasing at a constant rate. Why is that so?","An air traffic controller spots two planes at the same altitude converging on a point as they fly at right angles to each other. One plane is 225 miles from the point and is moving at 450 miles per hour. The other plane is 300 miles from the point and has a speed of 600 miles per hour."" ""a. At what rate is the distance between the planes decreasing? b. If the controller does not intervene, how close will the planes come to each other?"" I understand that we can use implicit differentiation to solve part a, which shows that the difference is decreasing at 750 mph. However, I wonder why in part b, the answer is 30 minutes. In other words, the difference between the two planes (the hypotenuse of their right angle) is decreasing at a constant rate. Why is that so?",,['derivatives']
81,Find $\nabla \|x^HAx - b\|_2^2$,Find,\nabla \|x^HAx - b\|_2^2,"I have to find- $$\nabla\|x^HAx - b\|_2^2,$$ where $x$ is a vector and $A$ is a $4\times 4$ hermitian matrix. I am trying to solve it by using identities given in https://en.wikipedia.org/wiki/Matrix_calculus but I am not able to figure out which identity suits my problem. I would appreciate if anyone tells me how to tackle this problem.","I have to find- $$\nabla\|x^HAx - b\|_2^2,$$ where $x$ is a vector and $A$ is a $4\times 4$ hermitian matrix. I am trying to solve it by using identities given in https://en.wikipedia.org/wiki/Matrix_calculus but I am not able to figure out which identity suits my problem. I would appreciate if anyone tells me how to tackle this problem.",,"['matrices', 'derivatives', 'matrix-calculus']"
82,Calculate derivative: $\frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x)$,Calculate derivative:,\frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x),"Is it possible to ""calculate"" / simplify this expression? If it is, how can it be done? $$ \frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x) $$ for $ \alpha,\beta\in\mathbb{R}_{\ge0} $ I think it is equal to $\left(\frac{\pi}{2}\right)^\beta \sin\left(x+\frac{\pi}{2}\left(\alpha+\beta\right)\right)$, but i am absolutely not sure if this is true. Thank you, Best regards Kevin -edit- Here is the desription how i got my result (which maybe helps to verify it): https://en.wikipedia.org/wiki/Differintegral#A_selection_of_basic_formul.C3.A6 $$\Rightarrow \frac{d^\alpha}{dx^\alpha}\sin(x)=\sin(x+\alpha\frac{\pi}{2})$$ Because $\frac{d^n}{dx^n}f(ax)=a^nf^{\left(n\right)}(ax), n\in \mathbb{N}$ i think $\frac{d^\alpha}{dx^\alpha}f(ax)=a^\alpha f^{\left(\alpha\right)}(ax), \alpha\in\mathbb{R}_{\ge 0}$ is also true. Unfortunately i'm not sure if this is true. Because $\frac{d^n}{dx^n}f(x+a)=f^{\left(n\right)}(x+a), n\in\mathbb{N}$ is true, i also hope that $\frac{d^\alpha}{dx^\alpha}f(x+a)=f^{\left(\alpha\right)}(x+a), \alpha\in\mathbb{R}_{\ge 0}$ is true. With these new rules the expression can be calculated: $$ \frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x) $$ $$ =\frac{d^\beta}{d\alpha^\beta}\sin(x+\alpha\frac{\pi}{2}) $$ $$ =\frac{d^\beta}{d\alpha^\beta}\sin(\frac{\pi}{2}\left(\alpha+\frac{2}{\pi}x\right)) $$ This is just a shifted $\sin(\frac{\pi}{2}\gamma)$. $$ \gamma=\alpha+\frac{2}{\pi}x $$ $$ \Rightarrow\frac{d^\beta}{d\alpha^\beta}\sin(\frac{\pi}{2}\gamma) $$ $$ =\left(\frac{\pi}{2}\right)^{\beta}\sin^{\left(\beta\right)}(\frac{\pi}{2}\gamma) $$ $$ =\left(\frac{\pi}{2}\right)^{\beta}\sin(\frac{\pi}{2}\gamma+\frac{\pi}{2}\beta) $$ $$ =\left(\frac{\pi}{2}\right)^{\beta}\sin(\frac{\pi}{2}\left(\alpha+\frac{2}{\pi}x\right)+\frac{\pi}{2}\beta) $$ $$ =\left(\frac{\pi}{2}\right)^\beta \sin\left(x+\frac{\pi}{2}\left(\alpha+\beta\right)\right) $$","Is it possible to ""calculate"" / simplify this expression? If it is, how can it be done? $$ \frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x) $$ for $ \alpha,\beta\in\mathbb{R}_{\ge0} $ I think it is equal to $\left(\frac{\pi}{2}\right)^\beta \sin\left(x+\frac{\pi}{2}\left(\alpha+\beta\right)\right)$, but i am absolutely not sure if this is true. Thank you, Best regards Kevin -edit- Here is the desription how i got my result (which maybe helps to verify it): https://en.wikipedia.org/wiki/Differintegral#A_selection_of_basic_formul.C3.A6 $$\Rightarrow \frac{d^\alpha}{dx^\alpha}\sin(x)=\sin(x+\alpha\frac{\pi}{2})$$ Because $\frac{d^n}{dx^n}f(ax)=a^nf^{\left(n\right)}(ax), n\in \mathbb{N}$ i think $\frac{d^\alpha}{dx^\alpha}f(ax)=a^\alpha f^{\left(\alpha\right)}(ax), \alpha\in\mathbb{R}_{\ge 0}$ is also true. Unfortunately i'm not sure if this is true. Because $\frac{d^n}{dx^n}f(x+a)=f^{\left(n\right)}(x+a), n\in\mathbb{N}$ is true, i also hope that $\frac{d^\alpha}{dx^\alpha}f(x+a)=f^{\left(\alpha\right)}(x+a), \alpha\in\mathbb{R}_{\ge 0}$ is true. With these new rules the expression can be calculated: $$ \frac{d^\beta}{d\alpha^\beta}\frac{d^\alpha}{dx^\alpha}\sin(x) $$ $$ =\frac{d^\beta}{d\alpha^\beta}\sin(x+\alpha\frac{\pi}{2}) $$ $$ =\frac{d^\beta}{d\alpha^\beta}\sin(\frac{\pi}{2}\left(\alpha+\frac{2}{\pi}x\right)) $$ This is just a shifted $\sin(\frac{\pi}{2}\gamma)$. $$ \gamma=\alpha+\frac{2}{\pi}x $$ $$ \Rightarrow\frac{d^\beta}{d\alpha^\beta}\sin(\frac{\pi}{2}\gamma) $$ $$ =\left(\frac{\pi}{2}\right)^{\beta}\sin^{\left(\beta\right)}(\frac{\pi}{2}\gamma) $$ $$ =\left(\frac{\pi}{2}\right)^{\beta}\sin(\frac{\pi}{2}\gamma+\frac{\pi}{2}\beta) $$ $$ =\left(\frac{\pi}{2}\right)^{\beta}\sin(\frac{\pi}{2}\left(\alpha+\frac{2}{\pi}x\right)+\frac{\pi}{2}\beta) $$ $$ =\left(\frac{\pi}{2}\right)^\beta \sin\left(x+\frac{\pi}{2}\left(\alpha+\beta\right)\right) $$",,"['derivatives', 'fractional-calculus', 'trigonometry']"
83,Confusion about Differentiability with partial derivatives,Confusion about Differentiability with partial derivatives,,"Theorem: Let $A  R^n$ be open and $f: A  R^n  R^m$.  Suppose $f = (f_1,...,f_m)$.  If each of the partials  $\frac{f_j}{x_i}$ exists and is continuous on $A$, then $f$ is differentiable on A. Use the Theorem to show that $f(x,y)$ defined by $f(x,y) = \frac{xy}{\sqrt{x^2+y^2}}$, $(x,y)(0,0)$ and $f(x,y)=0, (x,y)=(0,0)$ is differentiable at $(0,0)$ So I first found $\frac{f}{x}$ = $\frac{xy(2x^2+2y^2-x^2y)}{(x^2+y^2)\sqrt{x^2+y^2}}$ but that is not continuous at $(0,0)$.  So I'm not sure how I can prove $f$ is differentiable with this theorem.","Theorem: Let $A  R^n$ be open and $f: A  R^n  R^m$.  Suppose $f = (f_1,...,f_m)$.  If each of the partials  $\frac{f_j}{x_i}$ exists and is continuous on $A$, then $f$ is differentiable on A. Use the Theorem to show that $f(x,y)$ defined by $f(x,y) = \frac{xy}{\sqrt{x^2+y^2}}$, $(x,y)(0,0)$ and $f(x,y)=0, (x,y)=(0,0)$ is differentiable at $(0,0)$ So I first found $\frac{f}{x}$ = $\frac{xy(2x^2+2y^2-x^2y)}{(x^2+y^2)\sqrt{x^2+y^2}}$ but that is not continuous at $(0,0)$.  So I'm not sure how I can prove $f$ is differentiable with this theorem.",,"['analysis', 'derivatives', 'continuity', 'partial-derivative']"
84,Regression maximum likelihood,Regression maximum likelihood,,"Given this regression model: $y_{i}=\beta_{0}+\beta_{1}x_{i}+E_{i}$. All the assumptions are valid except that now: $E_{i}\sim N(0,x_{i}\sigma^{2})$ Find Maximum likelihood parameters for $\beta_0$,$\beta_1$","Given this regression model: $y_{i}=\beta_{0}+\beta_{1}x_{i}+E_{i}$. All the assumptions are valid except that now: $E_{i}\sim N(0,x_{i}\sigma^{2})$ Find Maximum likelihood parameters for $\beta_0$,$\beta_1$",,"['calculus', 'derivatives', 'optimization', 'convex-optimization', 'regression']"
85,Find all values of $\theta$ such that the tangent line to $f(\theta) = \theta \sin(\theta)$ is given by $y = \theta$,Find all values of  such that the tangent line to  is given by,\theta f(\theta) = \theta \sin(\theta) y = \theta,$$f(\theta) = \theta \sin(\theta)$$ Derived to: $$f'(\theta) = \sin(\theta) + \theta \cos(\theta)$$ How do I solve it from here?,$$f(\theta) = \theta \sin(\theta)$$ Derived to: $$f'(\theta) = \sin(\theta) + \theta \cos(\theta)$$ How do I solve it from here?,,['derivatives']
86,Taylor Series and Differentiation with Sigma notation $f(x) = \frac{x}{(2-3x)^2}$,Taylor Series and Differentiation with Sigma notation,f(x) = \frac{x}{(2-3x)^2},Use Term By Term Differentiation to Find the Taylor Series about $x$=3 for  Give The Open Interval of Convergence and express as sigma notation   $\sum A_n(x-3)^n$ $f(x) = \frac{x}{(2-3x)^2}$ So I have Found the Taylor Series for 1/(2-3x) to be $\sum{(-3)^{n}\cdot(x-3)^{n} }\cdot{(-7)^ {n+1}}$ How Do you find the original function taylor series and its interval of convergence and then express in sigma notation of the form  $\sum A_n(x-3)^n$,Use Term By Term Differentiation to Find the Taylor Series about $x$=3 for  Give The Open Interval of Convergence and express as sigma notation   $\sum A_n(x-3)^n$ $f(x) = \frac{x}{(2-3x)^2}$ So I have Found the Taylor Series for 1/(2-3x) to be $\sum{(-3)^{n}\cdot(x-3)^{n} }\cdot{(-7)^ {n+1}}$ How Do you find the original function taylor series and its interval of convergence and then express in sigma notation of the form  $\sum A_n(x-3)^n$,,"['sequences-and-series', 'derivatives', 'summation', 'taylor-expansion']"
87,prove $f(x)=\sum_{k=1}^{+\infty}\frac{1}{n}\cos^{n}x\sin(nx)$ is $\mathcal{C}^{1}(\mathbb{R}-\pi\mathbb{Z})$,prove  is,f(x)=\sum_{k=1}^{+\infty}\frac{1}{n}\cos^{n}x\sin(nx) \mathcal{C}^{1}(\mathbb{R}-\pi\mathbb{Z}),"let $f$ be a real valued function of a real variable defined by: $$f(x)=\sum_{k=1}^{+\infty}\frac{1}{n}\cos^{n}x\sin(nx)$$ Prove that $f(x)$ is $\displaystyle \mathcal{C}^{1}(\mathbb{R}-\pi\mathbb{Z})$ and calculate $\dfrac{df}{dx}$ My thoughts: at points of $\pi\mathbb{Z}$ we have $ \sin(nx)=0$ so there is no problem to set the  infinite series. On an interval $[a,b]$ included in $\mathbb{R}\setminus\pi\mathbb{Z}$ we can show that $|\cos x|\leq k$ for some constant $k<1$ which proves the existence of the sum and must be sufficient to apply the term by term derivation theorem series The union of all these intervals is $\mathbb{R}\setminus\pi\mathbb{Z}$","let $f$ be a real valued function of a real variable defined by: $$f(x)=\sum_{k=1}^{+\infty}\frac{1}{n}\cos^{n}x\sin(nx)$$ Prove that $f(x)$ is $\displaystyle \mathcal{C}^{1}(\mathbb{R}-\pi\mathbb{Z})$ and calculate $\dfrac{df}{dx}$ My thoughts: at points of $\pi\mathbb{Z}$ we have $ \sin(nx)=0$ so there is no problem to set the  infinite series. On an interval $[a,b]$ included in $\mathbb{R}\setminus\pi\mathbb{Z}$ we can show that $|\cos x|\leq k$ for some constant $k<1$ which proves the existence of the sum and must be sufficient to apply the term by term derivation theorem series The union of all these intervals is $\mathbb{R}\setminus\pi\mathbb{Z}$",,"['calculus', 'real-analysis', 'sequences-and-series', 'derivatives']"
88,Find the maximum and minimum values absolute value,Find the maximum and minimum values absolute value,,"So I am asked to find the maximum and minimum  of the function: $$f(x)=(2+|x|)\sqrt{2+(2-x)^2}$$ on the interval $[-1,2]$ So I took the derivative and got: $$\frac{ 2((x-2)|x|+x(x^2-3x+3)) }{|x|\sqrt{(2+(2-x)^2}}$$ which is in fact correct. So I set it equal to zero and try to find the critical points. The problem is though, how do I solve for $2((x-2)|x|+x(x^2-3x+3))=0$??? I certainly can't see a way...","So I am asked to find the maximum and minimum  of the function: $$f(x)=(2+|x|)\sqrt{2+(2-x)^2}$$ on the interval $[-1,2]$ So I took the derivative and got: $$\frac{ 2((x-2)|x|+x(x^2-3x+3)) }{|x|\sqrt{(2+(2-x)^2}}$$ which is in fact correct. So I set it equal to zero and try to find the critical points. The problem is though, how do I solve for $2((x-2)|x|+x(x^2-3x+3))=0$??? I certainly can't see a way...",,"['calculus', 'derivatives']"
89,Find $dy/dx$ if $xe^{9y}+y^4\sin(4x)=e^{8x}$,Find  if,dy/dx xe^{9y}+y^4\sin(4x)=e^{8x},"If $xe^{9y}+y^4\sin(4x)=e^{8x}$ implicitly defines $y$ as a function of $x$ then what is $\displaystyle \frac{dy}{dx}$? So far, I have made the following steps: 1) Get all parts of the equation onto one side 2) Find the derivative of the whole equation 3) This equals $9e^{9y}+y^4(4cos(4x))+4y^3(sin(4x))-8e^{8x}$ 4) Now, I think I am to get 'y' by itself. However, I am not sure how to do this, since there are $y$ variables as exponents, as well as non-exponent $y$ variables. Does anyone know how I may find the derivative of this function? All help is appreciated.","If $xe^{9y}+y^4\sin(4x)=e^{8x}$ implicitly defines $y$ as a function of $x$ then what is $\displaystyle \frac{dy}{dx}$? So far, I have made the following steps: 1) Get all parts of the equation onto one side 2) Find the derivative of the whole equation 3) This equals $9e^{9y}+y^4(4cos(4x))+4y^3(sin(4x))-8e^{8x}$ 4) Now, I think I am to get 'y' by itself. However, I am not sure how to do this, since there are $y$ variables as exponents, as well as non-exponent $y$ variables. Does anyone know how I may find the derivative of this function? All help is appreciated.",,"['calculus', 'trigonometry', 'derivatives']"
90,how to find the derivate of a function g(x),how to find the derivate of a function g(x),,It's $g(x)={{x^{2}-1}\over{x^{2}+2}}$ and i have to calculate $g^{13}(0)$. I can't calculate all the derivates so i think to use power series. $g(x)={{x^2\over{x^{2}+2}}-{1\over{x^2+2}}}$ Can i use the geometric series?,It's $g(x)={{x^{2}-1}\over{x^{2}+2}}$ and i have to calculate $g^{13}(0)$. I can't calculate all the derivates so i think to use power series. $g(x)={{x^2\over{x^{2}+2}}-{1\over{x^2+2}}}$ Can i use the geometric series?,,"['calculus', 'real-analysis', 'derivatives', 'power-series']"
91,Definition of Concavity for Twice Differentiable Functions,Definition of Concavity for Twice Differentiable Functions,,"Let $f(x)$ be a twice-differentiable function. The definitions for concave upward and concave downward I found in my textbooks are all somewhat wordy, something along the lines of: Definition 1: $f(x)$ is concave upward at $c$ if $f(x) > [f(c)+f(c)(xc)]$ for all $x$ in some open interval containing $c$. (See here for example.) Why don't we simply use the following definition: Proposed Definition 2: $f(x)$ is concave upward at $c$ if $f''(c) > 0 $ Are there cases where $f''(c) > 0$, but Definition 1 is not satisfied? Aren't Definitions 1 and 2 equivalent?","Let $f(x)$ be a twice-differentiable function. The definitions for concave upward and concave downward I found in my textbooks are all somewhat wordy, something along the lines of: Definition 1: $f(x)$ is concave upward at $c$ if $f(x) > [f(c)+f(c)(xc)]$ for all $x$ in some open interval containing $c$. (See here for example.) Why don't we simply use the following definition: Proposed Definition 2: $f(x)$ is concave upward at $c$ if $f''(c) > 0 $ Are there cases where $f''(c) > 0$, but Definition 1 is not satisfied? Aren't Definitions 1 and 2 equivalent?",,"['calculus', 'real-analysis', 'derivatives']"
92,"Related Rates Question with Resistor, Finding rate of change of $R$ (Physics)?","Related Rates Question with Resistor, Finding rate of change of  (Physics)?",R,"Let $R_1$,$R_2$,$R_3$ be connected in parallel! See circuit bellow: If $R_1$ increasing at $4\:\frac{\Omega }{s}$, If $R_2$ increasing at $2\:\frac{\Omega }{s}$, If $R_3$ decreases at $16\:\frac{\Omega }{s}$, how fast does is R changing? I don't know what to do, I feel like my teacher didn't give enough information. Normally we would take the derivative to find the rate of change with respect to time and then substitute values we know. But I don't even have any relationship between $R_1$,$R_2$,$R_3$.","Let $R_1$,$R_2$,$R_3$ be connected in parallel! See circuit bellow: If $R_1$ increasing at $4\:\frac{\Omega }{s}$, If $R_2$ increasing at $2\:\frac{\Omega }{s}$, If $R_3$ decreases at $16\:\frac{\Omega }{s}$, how fast does is R changing? I don't know what to do, I feel like my teacher didn't give enough information. Normally we would take the derivative to find the rate of change with respect to time and then substitute values we know. But I don't even have any relationship between $R_1$,$R_2$,$R_3$.",,"['calculus', 'derivatives', 'physics', 'implicit-differentiation']"
93,Differentiation and second derivative,Differentiation and second derivative,,"Let $f$ be a function continuous on $[0, 1]$ and twice differentiable on $(0,1)$. Suppose that: $f(0) = f(1) = 0$ and $f(c) >0$ for some $c \in (0,1)$. Prove that there exists $x_{0}\in(0,1)$ such that $f''(x_{0}) < 0$. I'm not sure how to approach this question. Do I have to use the mean value theorem or is there actually another way to approach this question?","Let $f$ be a function continuous on $[0, 1]$ and twice differentiable on $(0,1)$. Suppose that: $f(0) = f(1) = 0$ and $f(c) >0$ for some $c \in (0,1)$. Prove that there exists $x_{0}\in(0,1)$ such that $f''(x_{0}) < 0$. I'm not sure how to approach this question. Do I have to use the mean value theorem or is there actually another way to approach this question?",,['derivatives']
94,What is wrong with this derivative?,What is wrong with this derivative?,,I have the simple function: $$ f=\ln(ka^k) $$ Here are two methods of taking the derivative with respect to $k$: Method 1: $$ \frac{\partial f}{\partial k}=\frac{\partial}{\partial k}(\ln(ka^k))=\frac{1}{ka^k}(a^k+k^2a^{k-1})=\frac 1k+\frac ka $$ Method 2: $$ \frac{\partial f}{\partial k}=\frac{\partial}{\partial k}(\ln(ka^k))=\frac{\partial}{\partial k}(\ln(k)+k\ln a)=\frac 1k+\ln a $$ How come the result is not the same? Thanks a lot for explaining!,I have the simple function: $$ f=\ln(ka^k) $$ Here are two methods of taking the derivative with respect to $k$: Method 1: $$ \frac{\partial f}{\partial k}=\frac{\partial}{\partial k}(\ln(ka^k))=\frac{1}{ka^k}(a^k+k^2a^{k-1})=\frac 1k+\frac ka $$ Method 2: $$ \frac{\partial f}{\partial k}=\frac{\partial}{\partial k}(\ln(ka^k))=\frac{\partial}{\partial k}(\ln(k)+k\ln a)=\frac 1k+\ln a $$ How come the result is not the same? Thanks a lot for explaining!,,"['calculus', 'derivatives', 'partial-derivative']"
95,Numerical derivative of compoiste function,Numerical derivative of compoiste function,,sorry for the very basic question. I am writing a Fortran program in which I have a quite complicated function in a non-linear system of equations and I need to differentiate it numerically in order to get a member of the Jacobian for solving the system with the Newton-Raphson method. The question is... being a composite function like $$g(f(x))$$ is the numerical derivative (central difference formula) simply: $$ \dfrac{\partial g(f(x))}{\partial x} = \dfrac{g(f(x+h)) - g(f(x-h))}{2h}$$ ? Do I need to change this formula according to the chain rule? Regards.,sorry for the very basic question. I am writing a Fortran program in which I have a quite complicated function in a non-linear system of equations and I need to differentiate it numerically in order to get a member of the Jacobian for solving the system with the Newton-Raphson method. The question is... being a composite function like $$g(f(x))$$ is the numerical derivative (central difference formula) simply: $$ \dfrac{\partial g(f(x))}{\partial x} = \dfrac{g(f(x+h)) - g(f(x-h))}{2h}$$ ? Do I need to change this formula according to the chain rule? Regards.,,"['derivatives', 'numerical-methods', 'function-and-relation-composition', 'finite-differences']"
96,Definition of limit with$ f(x)=|x^3|$,Definition of limit with, f(x)=|x^3|,"Using the definition of the limit I tried to find the derivative of $f(x)=|x^3|$. I came up with: $$f'(x)=\frac{3x^5}{|x^3|}$$ Question: Why is the derivative (according to this answer) not defined for $x=0$ (division by zero) while $f'(0)$ actually exists, since: $$f'(0)=\lim_{x\to 0}\frac{|x^3|-|0^3|}{x-0}=0$$ Elaboration using the definition of the limit: $$f'(x)=\lim_{h\to 0}\frac{|(x+h)^3|-|x^3|}{h}$$ $$=\lim_{h\to 0}\frac{\sqrt{(x+h)^6}-\sqrt{x^6}}{h}$$ $$=\lim_{h\to 0}\frac{(x+h)^6-x^6}{h(\sqrt{(x+h)^6}+\sqrt{x^6})}$$ $$=\lim_{h\to 0}\frac{h^5 + 6 h^4 x + 15 h^3 x^2 + 20 h^2 x^3 + 15 h x^4 + 6 x^5}{(\sqrt{(x+h)^6}+\sqrt{x^6})}$$ $$=\frac{6x^5}{2\sqrt{x^6}}=\frac{3x^5}{|x^3|}$$ Which is not defined for $x=0$.","Using the definition of the limit I tried to find the derivative of $f(x)=|x^3|$. I came up with: $$f'(x)=\frac{3x^5}{|x^3|}$$ Question: Why is the derivative (according to this answer) not defined for $x=0$ (division by zero) while $f'(0)$ actually exists, since: $$f'(0)=\lim_{x\to 0}\frac{|x^3|-|0^3|}{x-0}=0$$ Elaboration using the definition of the limit: $$f'(x)=\lim_{h\to 0}\frac{|(x+h)^3|-|x^3|}{h}$$ $$=\lim_{h\to 0}\frac{\sqrt{(x+h)^6}-\sqrt{x^6}}{h}$$ $$=\lim_{h\to 0}\frac{(x+h)^6-x^6}{h(\sqrt{(x+h)^6}+\sqrt{x^6})}$$ $$=\lim_{h\to 0}\frac{h^5 + 6 h^4 x + 15 h^3 x^2 + 20 h^2 x^3 + 15 h x^4 + 6 x^5}{(\sqrt{(x+h)^6}+\sqrt{x^6})}$$ $$=\frac{6x^5}{2\sqrt{x^6}}=\frac{3x^5}{|x^3|}$$ Which is not defined for $x=0$.",,"['limits', 'derivatives', 'absolute-value']"
97,Lyapunov invariant set for affine systems,Lyapunov invariant set for affine systems,,"Given a linear system $\dot{x}=Ax$ such that the real part of every eigenvalue of $A$ is less than $0$, Lyapunov's equation $A^T P + P A = -Q$ with $Q$ being any suitably sized positive definite matrix gives us an invariant ellipsoid $x^T P x \leq 1$, i.e. for any initial state $x_0$ such that $x_0^T P x_0 \leq 1$ we know that the states $x$ or rather $x(t)$ (making dependency to $t$ explicit) reachable from $x_0$ remain inside the invariant ellipsoid, i.e. $x(t)^T P x(t) \leq 1 ~\forall t \geq t_0$. How can this be generalized to affine systems $\dot{x}=Ax + b$ where the real part of every eigenvalue of $A$ is less than $0$? Clearly, transforming the affine system into a linear system by extending state vector by $b$ with $\dot{b}=0$ does not help since we will have eigenvalue(s) $0$ which violates our assumption.","Given a linear system $\dot{x}=Ax$ such that the real part of every eigenvalue of $A$ is less than $0$, Lyapunov's equation $A^T P + P A = -Q$ with $Q$ being any suitably sized positive definite matrix gives us an invariant ellipsoid $x^T P x \leq 1$, i.e. for any initial state $x_0$ such that $x_0^T P x_0 \leq 1$ we know that the states $x$ or rather $x(t)$ (making dependency to $t$ explicit) reachable from $x_0$ remain inside the invariant ellipsoid, i.e. $x(t)^T P x(t) \leq 1 ~\forall t \geq t_0$. How can this be generalized to affine systems $\dot{x}=Ax + b$ where the real part of every eigenvalue of $A$ is less than $0$? Clearly, transforming the affine system into a linear system by extending state vector by $b$ with $\dot{b}=0$ does not help since we will have eigenvalue(s) $0$ which violates our assumption.",,"['ordinary-differential-equations', 'derivatives', 'control-theory', 'invariant-theory', 'invariance']"
98,Proof: Need help with Rodrigues's formula for finding coefficent of $x^n$,Proof: Need help with Rodrigues's formula for finding coefficent of,x^n,Im having problems with proving Rodriguess formula. Im stuck on expanding $$u=D^n((x^2-1)^n)$$ (where D is the differential operator) to show that the coefficient of x^n in u is $$(2n)!/(n!)$$. Ive used Leibnizs formula to differentiate it n times via difference of squares and got to this:$$\sum_{k=0}^n ((x+1)^{n-k}(x-1)^k\frac{(n!)^3}{(k!)^2((n-k)!)^2})$$but Im still no closer to proving it. Can someone please give me a hint with this.,Im having problems with proving Rodriguess formula. Im stuck on expanding $$u=D^n((x^2-1)^n)$$ (where D is the differential operator) to show that the coefficient of x^n in u is $$(2n)!/(n!)$$. Ive used Leibnizs formula to differentiate it n times via difference of squares and got to this:$$\sum_{k=0}^n ((x+1)^{n-k}(x-1)^k\frac{(n!)^3}{(k!)^2((n-k)!)^2})$$but Im still no closer to proving it. Can someone please give me a hint with this.,,"['ordinary-differential-equations', 'derivatives']"
99,Related Rates - Particle Moving along a parabola,Related Rates - Particle Moving along a parabola,,"A bug is moving along the right side of the parabola y=x^2 at a rate such that its distance from the origin is increasing 3 cm/min. At what rate are the x- and y-coordinates of the bug increasing when the bug is at the point (1,1)? D^2 = y + y^2 2 dD/dt = dy/dt + 2y dy/dt","A bug is moving along the right side of the parabola y=x^2 at a rate such that its distance from the origin is increasing 3 cm/min. At what rate are the x- and y-coordinates of the bug increasing when the bug is at the point (1,1)? D^2 = y + y^2 2 dD/dt = dy/dt + 2y dy/dt",,"['calculus', 'derivatives']"
