,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,What is second Bartlett identity?,What is second Bartlett identity?,,I came across the term second Bartlett identity in the wikipedia link: https://en.wikipedia.org/wiki/Variance_function However could not find detail about it. Can anyone help me to understand what this identity is about. More importantly I want to know under what assumption this identity is true.,I came across the term second Bartlett identity in the wikipedia link: https://en.wikipedia.org/wiki/Variance_function However could not find detail about it. Can anyone help me to understand what this identity is about. More importantly I want to know under what assumption this identity is true.,,"['probability', 'statistics', 'statistical-inference', 'fisher-information']"
1,Can one infer independence by simple reasoning/intuition?,Can one infer independence by simple reasoning/intuition?,,"From my recent experience in probability, it feels as though independence is something we ""discover"" from the system via the equation: $$P(A)*P(B)=P(A\cap B)$$ Could one ever conclude independence from the ""system"" by intuition? Is it wise to conclude independence for events that are ""seemingly"" independent? What would be some interesting examples where this would fail.","From my recent experience in probability, it feels as though independence is something we ""discover"" from the system via the equation: $$P(A)*P(B)=P(A\cap B)$$ Could one ever conclude independence from the ""system"" by intuition? Is it wise to conclude independence for events that are ""seemingly"" independent? What would be some interesting examples where this would fail.",,"['probability', 'probability-theory', 'independence']"
2,Average number of guesses to guess number between 1 and 1000?,Average number of guesses to guess number between 1 and 1000?,,"There is a game where you get to pick a number between 1 and 1000 and then the system will tell if you guessed to high or too low. Using a binary search you can find the answer in a maximum of ten guesses (2^10 = 1024) , but how would I go about calculating the average number of guesses required to guess the given method, assuming the user uses this binary chop method?","There is a game where you get to pick a number between 1 and 1000 and then the system will tell if you guessed to high or too low. Using a binary search you can find the answer in a maximum of ten guesses (2^10 = 1024) , but how would I go about calculating the average number of guesses required to guess the given method, assuming the user uses this binary chop method?",,"['probability', 'statistics']"
3,Birthday Paradox: why permutations and not combinations?,Birthday Paradox: why permutations and not combinations?,,"The Birthday Problem: given $n$ people (typically $n<365$), what is the probability that some pair of them share a birthday (omitting Feb 29th, for simplicity)? The solution: First, find the probability that all $n$ people have different birthdays. Here is where I am confused. The solutions I have seen all say this probability is: $$ \frac{_{365}P_n}{365^n} $$ Why isn't this $_{365}C_n$,instead?","The Birthday Problem: given $n$ people (typically $n<365$), what is the probability that some pair of them share a birthday (omitting Feb 29th, for simplicity)? The solution: First, find the probability that all $n$ people have different birthdays. Here is where I am confused. The solutions I have seen all say this probability is: $$ \frac{_{365}P_n}{365^n} $$ Why isn't this $_{365}C_n$,instead?",,"['probability', 'combinatorics', 'birthday']"
4,Probability brainteaser: expected value of these two games,Probability brainteaser: expected value of these two games,,"I found this brainteaser on the internet and do not know how to solve it. For the second question, My first thought is to deduct from the situation when there is only 2 slots, then 3, 4, .., n,.. slots. But I find it not that easy. Can someone give me a hint on this? You can toss a coin 100 times or stop earlier, you are   paid the percentage of heads of your tosses, estimate the upper bound of the value of the game. There is a gambling machine with n-slots. You put balls one-by-one into the machine, each ball has equal probability to get inside each slot. You can stop the game anytime. In the end you will be rewarded like this: for each 1-ball slot, you are rewarded \$1; for each k-ball slot (k>=2), you are penalized \$k; for each 0-ball slot you are rewarded nothing. What is your strategy? What is the expected value of the game?","I found this brainteaser on the internet and do not know how to solve it. For the second question, My first thought is to deduct from the situation when there is only 2 slots, then 3, 4, .., n,.. slots. But I find it not that easy. Can someone give me a hint on this? You can toss a coin 100 times or stop earlier, you are   paid the percentage of heads of your tosses, estimate the upper bound of the value of the game. There is a gambling machine with n-slots. You put balls one-by-one into the machine, each ball has equal probability to get inside each slot. You can stop the game anytime. In the end you will be rewarded like this: for each 1-ball slot, you are rewarded \$1; for each k-ball slot (k>=2), you are penalized \$k; for each 0-ball slot you are rewarded nothing. What is your strategy? What is the expected value of the game?",,['probability']
5,100 sequential parking spaces,100 sequential parking spaces,,"In my high school's math club today, we explored but did not solve this interesting problem: 100 autonomous robotic vehicles enter a warehouse in arbitrary order to park. Inside the  warehouse, there are 100 sequential parking spaces enumerated from 1 to 100. Each vehicle has an assigned number where it will attempt to park. However, there is an error in the programming such that if a vehicle finds its path to the assigned parking spot blocked by an already-parked robot, the robot will immediately park in the spot before it. For example, if vehicle 50 parks in spot 50 but vehicle 75 is immediately behind it, vehicle 75 will park in spot 49. Also, if vehicle 1 parks in spot 1, every robot behind it will be blocked from entering the warehouse at all. The vehicles do not have the ability to maneuver around already-parked vehicles. What is the most likely number of robots that will be parked in the warehouse at the end of the routine? So far the group came up with just some underlying intuition that the most likely number should be fewer than 50, as it is likely that some robot will park in position $\leq 50$ early on and leave many spaces unable to be occupied. I tried manually exploring small cases with 2, 3, 4, and 5 parking spaces, but this did not produce much help.","In my high school's math club today, we explored but did not solve this interesting problem: 100 autonomous robotic vehicles enter a warehouse in arbitrary order to park. Inside the  warehouse, there are 100 sequential parking spaces enumerated from 1 to 100. Each vehicle has an assigned number where it will attempt to park. However, there is an error in the programming such that if a vehicle finds its path to the assigned parking spot blocked by an already-parked robot, the robot will immediately park in the spot before it. For example, if vehicle 50 parks in spot 50 but vehicle 75 is immediately behind it, vehicle 75 will park in spot 49. Also, if vehicle 1 parks in spot 1, every robot behind it will be blocked from entering the warehouse at all. The vehicles do not have the ability to maneuver around already-parked vehicles. What is the most likely number of robots that will be parked in the warehouse at the end of the routine? So far the group came up with just some underlying intuition that the most likely number should be fewer than 50, as it is likely that some robot will park in position $\leq 50$ early on and leave many spaces unable to be occupied. I tried manually exploring small cases with 2, 3, 4, and 5 parking spaces, but this did not produce much help.",,"['probability', 'problem-solving']"
6,Books that use probabilistic/combinatorial/graph theoretical/physical/geometrical methods to solve problems from other branches of mathematics,Books that use probabilistic/combinatorial/graph theoretical/physical/geometrical methods to solve problems from other branches of mathematics,,"I am searching for some books that describe useful, interesting, not-so-common, (possibly) intuitive and non-standard methods (see note *) for approaching problems and interpreting theorems and results in number theory, analysis, algebra, linear algebra, and other branches of mathematics. (*) Such methods can be (but not limited to) from the areas of probability; combinatorics; graph theory; physics; geometry. Examples of such books can be Uspenskii's Some Applications of Mechanics to Mathematics or Apostol's and Mnatsakanian's New Horizons in geometry .","I am searching for some books that describe useful, interesting, not-so-common, (possibly) intuitive and non-standard methods (see note *) for approaching problems and interpreting theorems and results in number theory, analysis, algebra, linear algebra, and other branches of mathematics. (*) Such methods can be (but not limited to) from the areas of probability; combinatorics; graph theory; physics; geometry. Examples of such books can be Uspenskii's Some Applications of Mechanics to Mathematics or Apostol's and Mnatsakanian's New Horizons in geometry .",,"['probability', 'reference-request', 'soft-question', 'big-list', 'book-recommendation']"
7,Is there a simple way to illustrate that Fermat's Last Theorem is plausible?,Is there a simple way to illustrate that Fermat's Last Theorem is plausible?,,"A first step in proving a theorem is true could be to show that it is plausible, so at least you then would have a general idea that it could be true and have something to start with in proving it. Simply put: if you get the picture, you can do the math. This brings me to my question: Is there a simple way to demonstrate that Fermat's Last Theorem is (at least) plausible? And if so, is it thought that Fermat had found it himself? Or has trying to proof FLT always been 'a shot in the dark' for everyone anyway?","A first step in proving a theorem is true could be to show that it is plausible, so at least you then would have a general idea that it could be true and have something to start with in proving it. Simply put: if you get the picture, you can do the math. This brings me to my question: Is there a simple way to demonstrate that Fermat's Last Theorem is (at least) plausible? And if so, is it thought that Fermat had found it himself? Or has trying to proof FLT always been 'a shot in the dark' for everyone anyway?",,['probability']
8,Conditional distribution of binomial random variables is hypergeometric,Conditional distribution of binomial random variables is hypergeometric,,Let's say $X$ and $Y$ are binomial random variables with parameters $n$ and $p$ and $X+Y=m$. I want to show that the conditional distribution of $X$ if $X+Y=m$ is a hypergeometric distribution. I'm thinking about putting these in terms of coin flips with the $m^\text{th}$ head occurring after $2n$ tosses. $X$ and $Y$ have $n$ tosses with probability of heads $p$. I'm not sure how to relate this to the hypergeometric distribution however.,Let's say $X$ and $Y$ are binomial random variables with parameters $n$ and $p$ and $X+Y=m$. I want to show that the conditional distribution of $X$ if $X+Y=m$ is a hypergeometric distribution. I'm thinking about putting these in terms of coin flips with the $m^\text{th}$ head occurring after $2n$ tosses. $X$ and $Y$ have $n$ tosses with probability of heads $p$. I'm not sure how to relate this to the hypergeometric distribution however.,,['probability']
9,The difference between unbiased/biased estimator variance.,The difference between unbiased/biased estimator variance.,,The biased MLE of Normal distribution is: $\hat{\sigma }_{MLE} = \frac{1}{N}\sum_{N}^{i=1}\left({x}_{i} - \hat{\mu }\right)^{2}$ And unbiased is: $\hat{\sigma }_{unbiased} = \frac{1}{N-1}\sum_{N}^{i=1}\left({x}_{i} - \hat{\mu }\right)^{2}$ So Why the former is N and later is N-1?,The biased MLE of Normal distribution is: $\hat{\sigma }_{MLE} = \frac{1}{N}\sum_{N}^{i=1}\left({x}_{i} - \hat{\mu }\right)^{2}$ And unbiased is: $\hat{\sigma }_{unbiased} = \frac{1}{N-1}\sum_{N}^{i=1}\left({x}_{i} - \hat{\mu }\right)^{2}$ So Why the former is N and later is N-1?,,"['probability', 'normal-distribution']"
10,How to prove uniform distribution of $m\oplus k$ if $k$ is uniformly distributed?,How to prove uniform distribution of  if  is uniformly distributed?,m\oplus k k,"All values $m, k, c$ are $n$-bit strings. $\oplus$ stands for the bitwise modulo-2 addition. How to prove uniform distribution of $c=m\oplus k$ if $k$ is uniformly distributed? $m$ may be of any distribution and statistically independant of $k$. For example you have a $m$-bit string that is with probability p=1 always '1111...111'. Adding it bitwise to a random $k$-bit string which is uniformly distributed makes the result also uniformly distributed. Why?","All values $m, k, c$ are $n$-bit strings. $\oplus$ stands for the bitwise modulo-2 addition. How to prove uniform distribution of $c=m\oplus k$ if $k$ is uniformly distributed? $m$ may be of any distribution and statistically independant of $k$. For example you have a $m$-bit string that is with probability p=1 always '1111...111'. Adding it bitwise to a random $k$-bit string which is uniformly distributed makes the result also uniformly distributed. Why?",,"['probability', 'probability-distributions']"
11,"Why is that the events (Sum of dice roll=6, first die=4) are dependent, but the events (Sum of dice roll=7, first die =4) are independent?","Why is that the events (Sum of dice roll=6, first die=4) are dependent, but the events (Sum of dice roll=7, first die =4) are independent?",,"Roll $2$ dice. Let $E$ be the event that the sum of the dice is $6$ Let $F$ be the event that the sum of the dice is $7$ Let $G$ be the event that the first die rolled is a $4$ $E$ and $G$ are dependent (since $P(E\cap G) \neq P(E)P(G)$ ) $F$ and $G$ are independent (since $P(F\cap G) = P(F)P(G)$ ) Intuitively, why is this true?","Roll $2$ dice. Let $E$ be the event that the sum of the dice is $6$ Let $F$ be the event that the sum of the dice is $7$ Let $G$ be the event that the first die rolled is a $4$ $E$ and $G$ are dependent (since $P(E\cap G) \neq P(E)P(G)$ ) $F$ and $G$ are independent (since $P(F\cap G) = P(F)P(G)$ ) Intuitively, why is this true?",,['probability']
12,Find the unfair coin,Find the unfair coin,,"I've had some fun thinking about these (and related) problems, but things get very complicated very quickly, and I constantly doubt my own work! I would like to see what others do with them. Thanks! You have two identical-looking coins, but one is fair, and the other is unfair, coming up Heads 2/3 of the time. You flipped coin A once, and it came up Heads. You flipped coin B three times, and got two Heads and a Tail. a) What's the probability that coin A is the unfair one? b) Suppose you were allowed to perform one more flip, then declare which coin you believed to be unfair. Which coin should you flip? After performing this flip, which coin will you say is the unfair one (based on the result of that flip), and how likely are you to be correct?","I've had some fun thinking about these (and related) problems, but things get very complicated very quickly, and I constantly doubt my own work! I would like to see what others do with them. Thanks! You have two identical-looking coins, but one is fair, and the other is unfair, coming up Heads 2/3 of the time. You flipped coin A once, and it came up Heads. You flipped coin B three times, and got two Heads and a Tail. a) What's the probability that coin A is the unfair one? b) Suppose you were allowed to perform one more flip, then declare which coin you believed to be unfair. Which coin should you flip? After performing this flip, which coin will you say is the unfair one (based on the result of that flip), and how likely are you to be correct?",,['probability']
13,PDF for sum of dependent random variables,PDF for sum of dependent random variables,,"When the variables $X, Y$ are independent, then the PDF of $Z = X + Y$ can be computed using convolutions: $$ f_Z(z) = \int_{-\infty}^{\infty} f_X(x)f_Y(z - x) dx $$ When the variables are dependent, apparently you can use $$ f_Z(z) = \int_{-\infty}^{\infty} f_{XY}(x, z - x) dx $$ I am wondering where the expression came from for the dependent case? It looks very similar to the independent case except you can't separate the joint distribution into marginals.","When the variables are independent, then the PDF of can be computed using convolutions: When the variables are dependent, apparently you can use I am wondering where the expression came from for the dependent case? It looks very similar to the independent case except you can't separate the joint distribution into marginals.","X, Y Z = X + Y 
f_Z(z) = \int_{-\infty}^{\infty} f_X(x)f_Y(z - x) dx
 
f_Z(z) = \int_{-\infty}^{\infty} f_{XY}(x, z - x) dx
","['probability', 'convolution']"
14,"If you picked a number between $1$ to $10^n$ with no zero digits,find the probability that the digits' product is less than the number's square root?","If you picked a number between  to  with no zero digits,find the probability that the digits' product is less than the number's square root?",1 10^n,"What is the probability if you picked a number with no zero digits between $1$ to $10^n$ that the digits' product is less than the number's square root? You can't pick a number like $371790$ because it has a zero. An example for it being bigger than the square root is $\;2\times2\times2\times2\times9\times9>\sqrt{222299}.$ An example for it being smaller than the square root is ; $2\times2\times2\times2\times9\times2<\sqrt{222292}.$ If there is a limit of the probability as n goes to infinity, what is it?","What is the probability if you picked a number with no zero digits between to that the digits' product is less than the number's square root? You can't pick a number like because it has a zero. An example for it being bigger than the square root is An example for it being smaller than the square root is ; If there is a limit of the probability as n goes to infinity, what is it?",1 10^n 371790 \;2\times2\times2\times2\times9\times9>\sqrt{222299}. 2\times2\times2\times2\times9\times2<\sqrt{222292}.,"['probability', 'limits']"
15,Does finiteness of expectation of $X$ imply $X$ is finite almost surely?,Does finiteness of expectation of  imply  is finite almost surely?,X X,"Formally, let $\left(\Omega, \mathscr{F}, \mathbb{P}\right)$ be a probability triple. Let $X$ be a nonnegative random variable such that $\mathbb{E} \left(X\right) < \infty$ , then is it true that $\mathbb{P} \left(X < \infty \right) = 1$ ? Is this something trivial? I just do not know how to begin the proof","Formally, let be a probability triple. Let be a nonnegative random variable such that , then is it true that ? Is this something trivial? I just do not know how to begin the proof","\left(\Omega, \mathscr{F}, \mathbb{P}\right) X \mathbb{E} \left(X\right) < \infty \mathbb{P} \left(X < \infty \right) = 1","['probability', 'measure-theory']"
16,You meet two arbitrary children of a married couple the odds are $50\%$ that they both have blue eyes. How many children does the family have?,You meet two arbitrary children of a married couple the odds are  that they both have blue eyes. How many children does the family have?,50\%,I'm stuck on the following riddle: you meet two arbitrary children of a married couple the odds are $50\%$ that they both have blue eyes. How many children does the family (the married couple) have? The possible answers are: A: $3$ B: $4$ C: $5$,I'm stuck on the following riddle: you meet two arbitrary children of a married couple the odds are $50\%$ that they both have blue eyes. How many children does the family (the married couple) have? The possible answers are: A: $3$ B: $4$ C: $5$,,"['probability', 'recreational-mathematics', 'puzzle']"
17,Expected number of draws to find a match,Expected number of draws to find a match,,"Suppose I have $n$ pairs of socks in a drawer, well mixed, with each pair distinct, so each sock has one unique match. I begin drawing socks one-at-a-time, at random, without replacement. Let $X_n$ be a random variable representing the number of draws necessary to find one matching pair. Is there a nice way to describe the distribution function of $X_n$ ? What is its expected value? Does $\lim_{n\to\infty}\frac{E(X_n)}{n}$ exist, and if so, what is it? It is clear that the support of the distribution is the set of integers $\{2,\ldots,n+1\}$ . I have calculated the distribution and expectation for the first few values of $n$ ; I believe the following is without error: $n=1$ : $\begin{matrix}x & P(X_1=x)\\ 2 & 1\end{matrix}$ $E(X_1)=2$ $n=2$ : $\begin{matrix}x & P(X_2=x)\\ 2 & \frac13\\ 3 & \frac23 \end{matrix}$ $E(X_2)=\frac83$ $n=3$ : $\begin{matrix}x & P(X_3=x)\\ 2 & \frac15\\ 3 & \frac25\\ 4 & \frac25 \end{matrix}$ $E(X_3)=\frac{16}5$ $n=4$ : $\begin{matrix}x & P(X_4=x)\\ 2 & \frac17\\ 3 & \frac27\\ 4 & \frac{12}{35}\\ 5 & \frac{8}{35} \end{matrix}$ $E(X_4)=\frac{128}{35}$ $n=5$ : $\begin{matrix}x & P(X_5=x)\\ 2 & \frac19\\ 3 & \frac29\\ 4 & \frac27\\ 5 & \frac{16}{63}\\ 6 & \frac{8}{63} \end{matrix}$ $E(X_5)=\frac{256}{63}$ From this work so far, I find it striking that the numerators are all powers of $2$ . The first two probabilities in each table ( $n>1$ ) are $\frac{1}{2n-1}$ and $\frac{2}{2n-1}$ , and this is easy to show. After that.... the patterns seem a little more elusive. I conjecture that the limit of $\frac{E(X_n)}{n}$ exists and is greater than $0$ , but I don't know what it is. Its first few values, rounded, are $2, 1.333, 1.067, 0.914, 0.813$ Any ideas, insights, or references are very much appreciated. This is not a problem from a class or anything; it just comes from my own curiosity.","Suppose I have pairs of socks in a drawer, well mixed, with each pair distinct, so each sock has one unique match. I begin drawing socks one-at-a-time, at random, without replacement. Let be a random variable representing the number of draws necessary to find one matching pair. Is there a nice way to describe the distribution function of ? What is its expected value? Does exist, and if so, what is it? It is clear that the support of the distribution is the set of integers . I have calculated the distribution and expectation for the first few values of ; I believe the following is without error: : : : : : From this work so far, I find it striking that the numerators are all powers of . The first two probabilities in each table ( ) are and , and this is easy to show. After that.... the patterns seem a little more elusive. I conjecture that the limit of exists and is greater than , but I don't know what it is. Its first few values, rounded, are Any ideas, insights, or references are very much appreciated. This is not a problem from a class or anything; it just comes from my own curiosity.","n X_n X_n \lim_{n\to\infty}\frac{E(X_n)}{n} \{2,\ldots,n+1\} n n=1 \begin{matrix}x & P(X_1=x)\\ 2 & 1\end{matrix} E(X_1)=2 n=2 \begin{matrix}x & P(X_2=x)\\ 2 & \frac13\\ 3 & \frac23 \end{matrix} E(X_2)=\frac83 n=3 \begin{matrix}x & P(X_3=x)\\ 2 & \frac15\\ 3 & \frac25\\ 4 & \frac25 \end{matrix} E(X_3)=\frac{16}5 n=4 \begin{matrix}x & P(X_4=x)\\ 2 & \frac17\\ 3 & \frac27\\ 4 & \frac{12}{35}\\ 5 & \frac{8}{35} \end{matrix} E(X_4)=\frac{128}{35} n=5 \begin{matrix}x & P(X_5=x)\\ 2 & \frac19\\ 3 & \frac29\\ 4 & \frac27\\ 5 & \frac{16}{63}\\ 6 & \frac{8}{63} \end{matrix} E(X_5)=\frac{256}{63} 2 n>1 \frac{1}{2n-1} \frac{2}{2n-1} \frac{E(X_n)}{n} 0 2, 1.333, 1.067, 0.914, 0.813","['probability', 'expectation']"
18,Proof of Probability of Set Difference,Proof of Probability of Set Difference,,I've been trying to figure out a rigorous proof for the following identity but I'm getting nowhere: $P[A\setminus B]=P[A]-P[A \cap B]$ It seems obvious with Venn diagrams but I'm interested in a formal proof for this. Any help and/or hints appreciated!,I've been trying to figure out a rigorous proof for the following identity but I'm getting nowhere: $P[A\setminus B]=P[A]-P[A \cap B]$ It seems obvious with Venn diagrams but I'm interested in a formal proof for this. Any help and/or hints appreciated!,,"['probability', 'probability-theory', 'elementary-set-theory']"
19,What is this binomial sum?,What is this binomial sum?,,"I'm trying to figure out what this sum is equal to: $$\sum^n_{k=0}k \binom{m-k}{m-n}$$ I thought there are n turns and on each turn you pick 1 object from k objects ($\binom{k}{1}=k$) and also pick $m-n$ objects from $m-k$ objects. So I thought we pick a total of $m-n+1$ objects from $m-k+k=m$ objects, giving  $$\sum^n_{k=0}k \binom{m-k}{m-n}=\binom{m}{m-n+1}$$ But I plugged in some test numbers and this didn't seem to work. What am I thinking wrong?","I'm trying to figure out what this sum is equal to: $$\sum^n_{k=0}k \binom{m-k}{m-n}$$ I thought there are n turns and on each turn you pick 1 object from k objects ($\binom{k}{1}=k$) and also pick $m-n$ objects from $m-k$ objects. So I thought we pick a total of $m-n+1$ objects from $m-k+k=m$ objects, giving  $$\sum^n_{k=0}k \binom{m-k}{m-n}=\binom{m}{m-n+1}$$ But I plugged in some test numbers and this didn't seem to work. What am I thinking wrong?",,"['probability', 'combinatorics', 'summation', 'binomial-coefficients', 'combinations']"
20,Why does $e^{-(x^2/2)} \approx \cos[\frac{x}{\sqrt{n}}]^n$ hold for large $n$?,Why does  hold for large ?,e^{-(x^2/2)} \approx \cos[\frac{x}{\sqrt{n}}]^n n,Why does this hold: $$ e^{-x^2/2} = \lim_{n \to \infty} \cos^n \left( \frac{x}{\sqrt{n}} \right) $$ I am not sure how to solve this using the limit theorem.,Why does this hold: $$ e^{-x^2/2} = \lim_{n \to \infty} \cos^n \left( \frac{x}{\sqrt{n}} \right) $$ I am not sure how to solve this using the limit theorem.,,"['probability', 'limits', 'exponential-function', 'central-limit-theorem']"
21,Radon-Nikodym derivative of Measures,Radon-Nikodym derivative of Measures,,"Im having some trouble reconciling what I thought I learned about RN Derivatives as they relate to probability measures wikipedia , lecture notes with this blog post by John Baez mentioning it as it relates to KL divergences. Specifically, when John says: And by the way, in case you're wondering, the $d$ here doesn't   actually mean much: we're just so brainwashed into wanting a $dx$ in   our integrals that people often use $d$ for a measure even though the   simpler notation $\mu$ might be more logical. So, the function: $\frac{d\mu}{d\nu}$ is really just a ratio of probability measures, but people call it a   Radon-Nikodym derivative, because it looks like a derivative (and in   some important examples it actually is). It seems to me that there is some deep intuition Im missing here. Could anyone please elaborate on this perspective? Specifically: I'm asking: To what degree is an RN derivative really just a ratio of probability measures? If isn't technically a ratio of two measures, is it helpful to think of it sometimes as being that ratio? In what instances? Thanks!","Im having some trouble reconciling what I thought I learned about RN Derivatives as they relate to probability measures wikipedia , lecture notes with this blog post by John Baez mentioning it as it relates to KL divergences. Specifically, when John says: And by the way, in case you're wondering, the $d$ here doesn't   actually mean much: we're just so brainwashed into wanting a $dx$ in   our integrals that people often use $d$ for a measure even though the   simpler notation $\mu$ might be more logical. So, the function: $\frac{d\mu}{d\nu}$ is really just a ratio of probability measures, but people call it a   Radon-Nikodym derivative, because it looks like a derivative (and in   some important examples it actually is). It seems to me that there is some deep intuition Im missing here. Could anyone please elaborate on this perspective? Specifically: I'm asking: To what degree is an RN derivative really just a ratio of probability measures? If isn't technically a ratio of two measures, is it helpful to think of it sometimes as being that ratio? In what instances? Thanks!",,"['probability', 'measure-theory']"
22,Best book for self-study on the foundations of probability,Best book for self-study on the foundations of probability,,"After some selection, I have three ""candidates"" books to purchase in order to study by myself the foundations of the theory of probability, at a level that I can define as ""high undergraduate""/""low graduate"". These are my candidates: 1) Probability. A.N.Shiryaev. GTM Springer-Verlag. 2) Probability and Stochastics. Erhan Çinlar. GTM Springer-Verlag. 3) Probability Theory. A. Borovkov. UT Springer-Verlag. I have very good references from all of them. Which one do you recommend me ? Thank you for your answers.","After some selection, I have three ""candidates"" books to purchase in order to study by myself the foundations of the theory of probability, at a level that I can define as ""high undergraduate""/""low graduate"". These are my candidates: 1) Probability. A.N.Shiryaev. GTM Springer-Verlag. 2) Probability and Stochastics. Erhan Çinlar. GTM Springer-Verlag. 3) Probability Theory. A. Borovkov. UT Springer-Verlag. I have very good references from all of them. Which one do you recommend me ? Thank you for your answers.",,"['probability', 'book-recommendation']"
23,Fair coin tosses: Probability of $\geq 4$ consecutive heads,Fair coin tosses: Probability of  consecutive heads,\geq 4,"I know that there are some related questions, but they seem to be overkill for this small exercise. I have 10 (fair) coin tosses and am interested in the probability that I have at least 4 consecutive heads. So I had a lot of different ideas, but I think many of them do not work too well. 1) Markov chain: But then, somehow, we need to keep track of the number of coins we have already tossed, so one ""loses"" the Markov property. 2) count all possibilities: we have $2^{10}$ possibilities in total and can subtract the ones that have at most 3 consecutive heads. But seems to be nasty. 3) recursive equation? Let $p_{i,j}$ for $i \leq j$ be the probability that we have at least $j$ consecutive heads. But also this seems to be not that easy.. So this question is asked in a book in the first chapter, so it shouldn't be too hard?","I know that there are some related questions, but they seem to be overkill for this small exercise. I have 10 (fair) coin tosses and am interested in the probability that I have at least 4 consecutive heads. So I had a lot of different ideas, but I think many of them do not work too well. 1) Markov chain: But then, somehow, we need to keep track of the number of coins we have already tossed, so one ""loses"" the Markov property. 2) count all possibilities: we have $2^{10}$ possibilities in total and can subtract the ones that have at most 3 consecutive heads. But seems to be nasty. 3) recursive equation? Let $p_{i,j}$ for $i \leq j$ be the probability that we have at least $j$ consecutive heads. But also this seems to be not that easy.. So this question is asked in a book in the first chapter, so it shouldn't be too hard?",,"['probability', 'probability-theory']"
24,(Ito lemma proof): convergence of $\sum_{i=0}^{n-1}f(W(t_{i}))(W(t_{i+1})-W(t_{i}))^{2}.$,(Ito lemma proof): convergence of,\sum_{i=0}^{n-1}f(W(t_{i}))(W(t_{i+1})-W(t_{i}))^{2}.,"The purpose of this question is to complete my personal exposition on the rigorous proof of Ito's lemma.  I have consulted more than half a dozen mathematical finance texts and not a single one, for all its importance, rigorously proves this.  The closest I've seen is Shreve's treatment in Stochastic Calculus for Finance Vol II Let $\{W(t)\}_{t\geq0}$ be a standard Brownian motion.  Let $f$ be a smooth function, $T>0$, and $\Pi=\{t_{0}=0,t_{1},\ldots,t_{n}=T\}$ be a partition of $[0,T]$. Consider the random variable $$X(\omega)=\lim_{||\Pi||\to0}\;\sum_{i=0}^{n-1}f(W(t_{i}))(W(t_{i+1})-W(t_{i}))^{2}.$$ If $f\equiv1$, then almost surely $X\equiv T$.  This is the standard result that Brownian motion accumulates quadratic variation at a unit rate. If we make the substitution $(W(t_{i+1})-W(t_{i}))^{2}\approx(t_{i+1}-t_{i})$, then after $||\Pi||\to0$ and summing, the errors committed with this approximation go to $0$ and we recover almost surely $$X\equiv \int_{0}^{T}f(W(s))\;ds.$$ Is there a way to make this more precise?  I would like to adapt the usual proof that $$\lim_{||\Pi||\to0}\;\sum_{i=0}^{n-1}(W(t_{i+1})-W(t_{i}))^{2}=T,$$ which proceeds by showing that the expectation of the sampled quadratic variation (i.e. the sum on any partition) is $T$ and that the variance tends to $0$ as the partition becomes finer.  Indeed, $$\mathbb{E}[(W(t_{i+1})-W(t_{i}))^{2}]=\text{Var}[W(t_{i+1})-W(t_{i})]=t_{i+1}-t_{i}$$ and $$\text{Var}[(W(t_{i+1})-W(t_{i}))^{2}]=2(t_{i+1}-t_{i})^{2}$$ and the claim follows after summing, taking limits, and performing a simple estimate on the variance.  Based on my efforts, it does not seem like such simple formulas hold for the expectation and variance when the quantity is multiplied by $f(W(t_{i})).$ A heuristic for the approximation above can be obtained by noting that (if $\Pi$ is a uniformly spaced partition) $$(W(t_{i+1})-W(t_{i}))^{2}=\frac{T}{n}\left(\frac{W(t_{i+1})-W(t_{i})}{\sqrt{t_{i+1}-t_{i}}}\right)^{2}.$$ Thus if $$Y_{i}:=\left(\frac{W(t_{i+1})-W(t_{i})}{\sqrt{t_{i+1}-t_{i}}}\right)^{2},$$ then (being a collection of squared normal iid random variables with mean $1$) the law of large numbers implies $$\sum_{i=0}^{n-1}(W(t_{i+1})-W(t_{i}))^{2}=T\sum_{i=0}^{n-1}\frac{Y_{i+1}}{n}\to T\;\text{as}\;n\to\infty.$$ Thus, while $(W(t_{i+1})-W(t_{i}))^{2}\neq t_{i+1}-t_{i}$, the law of large numbers says that the error committed with this approximation cancels out in the limit.  In other words, we may write $$(W(t_{i+1})-W(t_{i}))^{2}=(t_{i+1}-t_{i})+\phi(t_{i})$$ where $\sum_{i=0}^{n-1}\phi(t_{i}))\to0\;\text{as}\;n\to\infty.$  What I'm trying to rigorously establish is that the above equations/limits all remain valid if we multiply them by $f(W(t_{i}))$. In other words, is it correct to write $$f(W(t_{i}))(W(t_{i+1})-W(t_{i}))^{2}=f(W(t_{i}))(t_{i+1}-t_{i})+\phi(t_{i}))$$ where $\sum_{i=0}^{n}f(W(t_{i}))\phi(t_{i})\to0\;\text{as}\;n\to\infty?$ The obvious problem with the above heuristic is that the random variables $$Y_{i}':=f(W(t_{i}))Y_{i}:=f(W(t_{i}))\left(\frac{W(t_{i+1})-W(t_{i})}{\sqrt{t_{i+1}-t_{i}}}\right)^{2}$$ are no longer independent, so the law of large numbers cannot be used in the manner above.","The purpose of this question is to complete my personal exposition on the rigorous proof of Ito's lemma.  I have consulted more than half a dozen mathematical finance texts and not a single one, for all its importance, rigorously proves this.  The closest I've seen is Shreve's treatment in Stochastic Calculus for Finance Vol II Let $\{W(t)\}_{t\geq0}$ be a standard Brownian motion.  Let $f$ be a smooth function, $T>0$, and $\Pi=\{t_{0}=0,t_{1},\ldots,t_{n}=T\}$ be a partition of $[0,T]$. Consider the random variable $$X(\omega)=\lim_{||\Pi||\to0}\;\sum_{i=0}^{n-1}f(W(t_{i}))(W(t_{i+1})-W(t_{i}))^{2}.$$ If $f\equiv1$, then almost surely $X\equiv T$.  This is the standard result that Brownian motion accumulates quadratic variation at a unit rate. If we make the substitution $(W(t_{i+1})-W(t_{i}))^{2}\approx(t_{i+1}-t_{i})$, then after $||\Pi||\to0$ and summing, the errors committed with this approximation go to $0$ and we recover almost surely $$X\equiv \int_{0}^{T}f(W(s))\;ds.$$ Is there a way to make this more precise?  I would like to adapt the usual proof that $$\lim_{||\Pi||\to0}\;\sum_{i=0}^{n-1}(W(t_{i+1})-W(t_{i}))^{2}=T,$$ which proceeds by showing that the expectation of the sampled quadratic variation (i.e. the sum on any partition) is $T$ and that the variance tends to $0$ as the partition becomes finer.  Indeed, $$\mathbb{E}[(W(t_{i+1})-W(t_{i}))^{2}]=\text{Var}[W(t_{i+1})-W(t_{i})]=t_{i+1}-t_{i}$$ and $$\text{Var}[(W(t_{i+1})-W(t_{i}))^{2}]=2(t_{i+1}-t_{i})^{2}$$ and the claim follows after summing, taking limits, and performing a simple estimate on the variance.  Based on my efforts, it does not seem like such simple formulas hold for the expectation and variance when the quantity is multiplied by $f(W(t_{i})).$ A heuristic for the approximation above can be obtained by noting that (if $\Pi$ is a uniformly spaced partition) $$(W(t_{i+1})-W(t_{i}))^{2}=\frac{T}{n}\left(\frac{W(t_{i+1})-W(t_{i})}{\sqrt{t_{i+1}-t_{i}}}\right)^{2}.$$ Thus if $$Y_{i}:=\left(\frac{W(t_{i+1})-W(t_{i})}{\sqrt{t_{i+1}-t_{i}}}\right)^{2},$$ then (being a collection of squared normal iid random variables with mean $1$) the law of large numbers implies $$\sum_{i=0}^{n-1}(W(t_{i+1})-W(t_{i}))^{2}=T\sum_{i=0}^{n-1}\frac{Y_{i+1}}{n}\to T\;\text{as}\;n\to\infty.$$ Thus, while $(W(t_{i+1})-W(t_{i}))^{2}\neq t_{i+1}-t_{i}$, the law of large numbers says that the error committed with this approximation cancels out in the limit.  In other words, we may write $$(W(t_{i+1})-W(t_{i}))^{2}=(t_{i+1}-t_{i})+\phi(t_{i})$$ where $\sum_{i=0}^{n-1}\phi(t_{i}))\to0\;\text{as}\;n\to\infty.$  What I'm trying to rigorously establish is that the above equations/limits all remain valid if we multiply them by $f(W(t_{i}))$. In other words, is it correct to write $$f(W(t_{i}))(W(t_{i+1})-W(t_{i}))^{2}=f(W(t_{i}))(t_{i+1}-t_{i})+\phi(t_{i}))$$ where $\sum_{i=0}^{n}f(W(t_{i}))\phi(t_{i})\to0\;\text{as}\;n\to\infty?$ The obvious problem with the above heuristic is that the random variables $$Y_{i}':=f(W(t_{i}))Y_{i}:=f(W(t_{i}))\left(\frac{W(t_{i+1})-W(t_{i})}{\sqrt{t_{i+1}-t_{i}}}\right)^{2}$$ are no longer independent, so the law of large numbers cannot be used in the manner above.",,"['probability', 'probability-theory', 'stochastic-calculus', 'brownian-motion']"
25,How can expected value be infinite?,How can expected value be infinite?,,"My book as well as Wikipedia gives this definition of expected value: $\mathbb E(X)=\sum _x xf(x).$ But, $\mathbb E(X)$ is said to exist if and only if that equation is absolute convergent. But, I see that many places do not follw this def., e.g. here $${\mathbb E} X = \sum_{n=1}^\infty 2^{-n} \cdot 2^n = \sum_{n=1}^\infty 1 = \infty,$$ though we can see that absolute convergence test is failed. So, can expected value be infinity or negative infinity?","My book as well as Wikipedia gives this definition of expected value: $\mathbb E(X)=\sum _x xf(x).$ But, $\mathbb E(X)$ is said to exist if and only if that equation is absolute convergent. But, I see that many places do not follw this def., e.g. here $${\mathbb E} X = \sum_{n=1}^\infty 2^{-n} \cdot 2^n = \sum_{n=1}^\infty 1 = \infty,$$ though we can see that absolute convergence test is failed. So, can expected value be infinity or negative infinity?",,"['probability', 'random-variables']"
26,Is probability and the Law of Large Numbers a huge circular argument?,Is probability and the Law of Large Numbers a huge circular argument?,,"I've always been confused on this part of probability. My (naïve?) definition of probability seems to be $Pr(X=x)=p$ meaning on average, $X$ would equal $x$ in a proportion $p$ of the time, as the number of trials goes to infinity. However, this seems to be what the Law of Large Numbers says, and that Law is a theorem, not an axiom or definition of probability. What actually is probability, if not a restatement of the Law of Large Numbers? This always bothers me - probability seems to be one huge circular argument. Where am I wrong?","I've always been confused on this part of probability. My (naïve?) definition of probability seems to be $Pr(X=x)=p$ meaning on average, $X$ would equal $x$ in a proportion $p$ of the time, as the number of trials goes to infinity. However, this seems to be what the Law of Large Numbers says, and that Law is a theorem, not an axiom or definition of probability. What actually is probability, if not a restatement of the Law of Large Numbers? This always bothers me - probability seems to be one huge circular argument. Where am I wrong?",,"['probability', 'statistics']"
27,Round table seating logic question.,Round table seating logic question.,,"what is the probability of 5 people with different ages sitting in ascending or descending order at a round table. So, let me know if there's a better way to go about this problem. Let's have the people be named 1,2,3,4,5 They could sit: 12345 23451 34512 45123 51234 or the reverse since order matters (12345 is different from 54321) There are 5! or 120 different ways the people can sit So 10/120 or 1/12 is the chance that they sit in ascending or descending order.  Is there a more formal way to do this? Also, how many ways can 5 people sit at a round table? (combination problem, order doesn't matter)","what is the probability of 5 people with different ages sitting in ascending or descending order at a round table. So, let me know if there's a better way to go about this problem. Let's have the people be named 1,2,3,4,5 They could sit: 12345 23451 34512 45123 51234 or the reverse since order matters (12345 is different from 54321) There are 5! or 120 different ways the people can sit So 10/120 or 1/12 is the chance that they sit in ascending or descending order.  Is there a more formal way to do this? Also, how many ways can 5 people sit at a round table? (combination problem, order doesn't matter)",,['probability']
28,Relation between Memorylessness and Independence,Relation between Memorylessness and Independence,,"I was reading about Memorylessness and Independence and was wondering whether there is any relationship between the two. I realize that memorylessness is a property of a random variable of a particular distribution (such as X is a RV following exponential distribution ) and independence has more to do with 2 or more random variables rather than their distribution. But, is there any fact that links the two?","I was reading about Memorylessness and Independence and was wondering whether there is any relationship between the two. I realize that memorylessness is a property of a random variable of a particular distribution (such as X is a RV following exponential distribution ) and independence has more to do with 2 or more random variables rather than their distribution. But, is there any fact that links the two?",,['probability']
29,How to put eggs in baskets,How to put eggs in baskets,,"A farmer has c chickens who have each laid e eggs, which she will put into b baskets.  Each basket has a probability p(d) of being dropped, which breaks all the eggs in the basket.  How should the farmer distribute the eggs into the baskets in such a way that she minimizes the number of chickens whose eggs all get broken?","A farmer has c chickens who have each laid e eggs, which she will put into b baskets.  Each basket has a probability p(d) of being dropped, which breaks all the eggs in the basket.  How should the farmer distribute the eggs into the baskets in such a way that she minimizes the number of chickens whose eggs all get broken?",,"['probability', 'tiling']"
30,Nice riddle - is there an elegant solution [duplicate],Nice riddle - is there an elegant solution [duplicate],,"This question already has answers here : Closed 12 years ago . Possible Duplicate: Taking Seats on a Plane There are 100 seats on a plane and 100 passengers, each with his ticket. However, the first person to enter the plane discovers he has lost his ticket, so he picks a seat at random. Afterwards, every new passenger sits in his place if it is free, and otherwise picks a vacant seat at random. You are the last to enter the plane. What is the probability you'll sit in your seat? I managed to solve this using induction (i.e. marking by $A(n)$ the probability where $n$ is the number of passengers and then finding a recursive formula for $A(n)$ which is quite simple). However, I want to know if there are more ""instantly obvious"" or one-liner solutions.","This question already has answers here : Closed 12 years ago . Possible Duplicate: Taking Seats on a Plane There are 100 seats on a plane and 100 passengers, each with his ticket. However, the first person to enter the plane discovers he has lost his ticket, so he picks a seat at random. Afterwards, every new passenger sits in his place if it is free, and otherwise picks a vacant seat at random. You are the last to enter the plane. What is the probability you'll sit in your seat? I managed to solve this using induction (i.e. marking by $A(n)$ the probability where $n$ is the number of passengers and then finding a recursive formula for $A(n)$ which is quite simple). However, I want to know if there are more ""instantly obvious"" or one-liner solutions.",,"['probability', 'puzzle']"
31,Variance of product of Brownian motions,Variance of product of Brownian motions,,Let $\{B_{t}\}_{t\geq0}$ be Brownian motion. What is the variance of $B_{t}B_{s}$?,Let $\{B_{t}\}_{t\geq0}$ be Brownian motion. What is the variance of $B_{t}B_{s}$?,,"['probability', 'brownian-motion']"
32,The limit of binomial distributed random variable,The limit of binomial distributed random variable,,"Edit (As Robert pointed out, what I was trying to prove is incorrect.  So now I ask the right question here, to avoid duplicate question) For infinite independent Bernoulli trials with probability $p$ to success, define a random variable N which equals to the number of successful trial.  Intuitively, we know if $p > 0$,  $\Pr \{N < \infty \} = 0$, in other word $N \rightarrow \infty$.  But I got stuck when I try to prove it mathematically. \begin{aligned} \Pr \{ N < \infty \}  & = \Pr \{ \cup_{n=1}^{\infty} [N \le n] \} \\ & = \lim_{n \rightarrow \infty} \Pr \{ N \le n \} \\ & = \lim_{n \rightarrow \infty}\sum_{i=1}^{n} b(i; \infty, p) \\ & = \sum_{i=1}^{\infty} b(i; \infty, p) \\ \end{aligned} I've totally no idea how to calculate the last expression. (Original Question) For infinite independent Bernoulli trials with probability $p$ to success, define a random variable N which equals to the number of successful trial.  Can we prove that $\Pr \{N < \infty \} = 1$  by: \begin{aligned} \Pr \{ N < \infty \}  & = \Pr \{ \cup_{n=1}^{\infty} [N \le n] \} \\ & = \lim_{n \rightarrow \infty} \Pr \{ N \le n \} \\ & = \lim_{n \rightarrow \infty}\sum_{i=1}^{n} b(i; \infty, p) \\ & = \sum_{i=1}^{\infty} b(i; \infty, p) \\ & = \lim_{m \rightarrow \infty}\sum_{i=1}^{m} b(i; m, p) \\ & = \lim_{m \rightarrow \infty}[p + (1 - p)]^m \\ & = \lim_{m \rightarrow \infty} 1^m \\ & = 1 \end{aligned} I know there must be some mistake in the process because if $p = 1$, N must infinite. So the  equation only holds when $ p < 1 $.  Which step is wrong?","Edit (As Robert pointed out, what I was trying to prove is incorrect.  So now I ask the right question here, to avoid duplicate question) For infinite independent Bernoulli trials with probability $p$ to success, define a random variable N which equals to the number of successful trial.  Intuitively, we know if $p > 0$,  $\Pr \{N < \infty \} = 0$, in other word $N \rightarrow \infty$.  But I got stuck when I try to prove it mathematically. \begin{aligned} \Pr \{ N < \infty \}  & = \Pr \{ \cup_{n=1}^{\infty} [N \le n] \} \\ & = \lim_{n \rightarrow \infty} \Pr \{ N \le n \} \\ & = \lim_{n \rightarrow \infty}\sum_{i=1}^{n} b(i; \infty, p) \\ & = \sum_{i=1}^{\infty} b(i; \infty, p) \\ \end{aligned} I've totally no idea how to calculate the last expression. (Original Question) For infinite independent Bernoulli trials with probability $p$ to success, define a random variable N which equals to the number of successful trial.  Can we prove that $\Pr \{N < \infty \} = 1$  by: \begin{aligned} \Pr \{ N < \infty \}  & = \Pr \{ \cup_{n=1}^{\infty} [N \le n] \} \\ & = \lim_{n \rightarrow \infty} \Pr \{ N \le n \} \\ & = \lim_{n \rightarrow \infty}\sum_{i=1}^{n} b(i; \infty, p) \\ & = \sum_{i=1}^{\infty} b(i; \infty, p) \\ & = \lim_{m \rightarrow \infty}\sum_{i=1}^{m} b(i; m, p) \\ & = \lim_{m \rightarrow \infty}[p + (1 - p)]^m \\ & = \lim_{m \rightarrow \infty} 1^m \\ & = 1 \end{aligned} I know there must be some mistake in the process because if $p = 1$, N must infinite. So the  equation only holds when $ p < 1 $.  Which step is wrong?",,"['probability', 'infinity']"
33,The sum of two i.i.d. random variables cannot be uniformly distributed,The sum of two i.i.d. random variables cannot be uniformly distributed,,"Given $X$ and $Y$ iid (independent and identically distributed), show that $Z=X+Y$ cannot be uniformly distributed. The uniform distribution might be on any set, not necessarily an interval. Notice that the density might not exist, so convolution might not work. For the trivial cases of where the pdf (probability density function) exists, we just use the continuity of convolution and it's done. This also shows that in this case any uniform distribution cannot work, whether it's an interval or not. So, I'm guessing for the more general case. The original question is like this. *I'm not asking about this, but (1) might help as a hint, and the original condition might tell you whether my abstraction is correct. $X,Y$ are iid on $[0,\frac12]$ , cdf (cumulative distribution function) is $F(x)$ , $Z=X+Y$ , (1) Show that $\forall \epsilon\in(0,\frac14)$ , $$P(Z\leq\epsilon)\leq F(\epsilon)^2$$ $$P(\frac12-\epsilon\leq Z\leq \frac12+\epsilon)\geq2F(\epsilon)(1-F(\frac12-\epsilon))$$ (2) Prove that $Z$ is not uniformly distributed.","Given and iid (independent and identically distributed), show that cannot be uniformly distributed. The uniform distribution might be on any set, not necessarily an interval. Notice that the density might not exist, so convolution might not work. For the trivial cases of where the pdf (probability density function) exists, we just use the continuity of convolution and it's done. This also shows that in this case any uniform distribution cannot work, whether it's an interval or not. So, I'm guessing for the more general case. The original question is like this. *I'm not asking about this, but (1) might help as a hint, and the original condition might tell you whether my abstraction is correct. are iid on , cdf (cumulative distribution function) is , , (1) Show that , (2) Prove that is not uniformly distributed.","X Y Z=X+Y X,Y [0,\frac12] F(x) Z=X+Y \forall \epsilon\in(0,\frac14) P(Z\leq\epsilon)\leq F(\epsilon)^2 P(\frac12-\epsilon\leq Z\leq \frac12+\epsilon)\geq2F(\epsilon)(1-F(\frac12-\epsilon)) Z","['probability', 'probability-theory', 'statistics', 'probability-distributions']"
34,What's the point of a Story Proof?,What's the point of a Story Proof?,,"I've been working through the Stat 110 Lecture Series and have come across the idea of Story Proofs. I've read the following from the author's book on the subject: A story proof is a proof by interpretation. For counting problems, this often means counting the same thing in two different ways, rather than doing tedious algebra. A story proof often avoids messy calculations and goes further than an algebraic proof toward explaining why the result is true. The word “story” has several meanings, some more mathematical than others, but a story proof (in the sense in which we’re using the term) is a fully valid mathematical proof. - Introduction To Probability, page 20. But what does the proof consist of? It appears a story proof creates two real-world scenarios that supposedly count the same thing, defines both counting situations in mathematics, and equates them. Fine, but without checking the mathematics, how can you be certain you are counting the same thing? Surely you end up checking the numerical proof in any case? Doesn't that make the story proof redundant?","I've been working through the Stat 110 Lecture Series and have come across the idea of Story Proofs. I've read the following from the author's book on the subject: A story proof is a proof by interpretation. For counting problems, this often means counting the same thing in two different ways, rather than doing tedious algebra. A story proof often avoids messy calculations and goes further than an algebraic proof toward explaining why the result is true. The word “story” has several meanings, some more mathematical than others, but a story proof (in the sense in which we’re using the term) is a fully valid mathematical proof. - Introduction To Probability, page 20. But what does the proof consist of? It appears a story proof creates two real-world scenarios that supposedly count the same thing, defines both counting situations in mathematics, and equates them. Fine, but without checking the mathematics, how can you be certain you are counting the same thing? Surely you end up checking the numerical proof in any case? Doesn't that make the story proof redundant?",,"['probability', 'proof-writing', 'proof-explanation']"
35,"Probability that of $5$ cards drawn from a shuffled deck the 1st, 3rd and 5th will be the same suit.","Probability that of  cards drawn from a shuffled deck the 1st, 3rd and 5th will be the same suit.",5,"Given a well shuffled deck, what is the probability that the first, third and fifth card will be of the same suit. Initially I was inclined to quickly say $\frac{4 \times {13 \choose 3} \times 49 \times 48}{{52 \choose 5}}$ ( $4$ ways to choose $3$ of the same suit and the rest can be whatever) but clearly the order matters here. So it seems that the simple, brute force way to do it would be a lot of conditioning: i.e, the first card can be whatever. Now condition on whether or not the second card is of the same suit or not. And then each of these above splits into two more conditionals - whether the fourth card is the same suit or not. So you'll have a sum of $4$ probabilities: $\frac{52 \times 39 \times 12 \times 38 \times 11}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 12 \times 11 \times 39 \times 10}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 39 \times 12 \times 11 \times 10}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 12 \times 11 \times 10 \times 9}{52 \times 51 \times 50 \times 49 \times 48}$ This looks about right to me, but I'm guessing there is a sleeker, more compact way to express this? $\frac{4 \times {13 \choose 5}}{{52 \choose 5}} + \frac{4 \times {13 \choose 4} \times {39 \choose 1}}{{52 \choose 5}} \times 2 + \frac{4 \times {13 \choose 3}\times {39 \choose 2}}{{52 \choose 5}}$ This is clearly the same thing as the above, but I guess it makes me uncomfortable - the question very clearly enforces a kind of order, which isn't really being paid attention to in the combinations solution. Perhaps I'm overthinking it. Why can we ignore considerations of order in the expression above, or is it just the wrong solution entirely?","Given a well shuffled deck, what is the probability that the first, third and fifth card will be of the same suit. Initially I was inclined to quickly say ( ways to choose of the same suit and the rest can be whatever) but clearly the order matters here. So it seems that the simple, brute force way to do it would be a lot of conditioning: i.e, the first card can be whatever. Now condition on whether or not the second card is of the same suit or not. And then each of these above splits into two more conditionals - whether the fourth card is the same suit or not. So you'll have a sum of probabilities: This looks about right to me, but I'm guessing there is a sleeker, more compact way to express this? This is clearly the same thing as the above, but I guess it makes me uncomfortable - the question very clearly enforces a kind of order, which isn't really being paid attention to in the combinations solution. Perhaps I'm overthinking it. Why can we ignore considerations of order in the expression above, or is it just the wrong solution entirely?",\frac{4 \times {13 \choose 3} \times 49 \times 48}{{52 \choose 5}} 4 3 4 \frac{52 \times 39 \times 12 \times 38 \times 11}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 12 \times 11 \times 39 \times 10}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 39 \times 12 \times 11 \times 10}{52 \times 51 \times 50 \times 49 \times 48} + \frac{52 \times 12 \times 11 \times 10 \times 9}{52 \times 51 \times 50 \times 49 \times 48} \frac{4 \times {13 \choose 5}}{{52 \choose 5}} + \frac{4 \times {13 \choose 4} \times {39 \choose 1}}{{52 \choose 5}} \times 2 + \frac{4 \times {13 \choose 3}\times {39 \choose 2}}{{52 \choose 5}},"['probability', 'combinatorics', 'probability-theory', 'permutations', 'conditional-probability']"
36,Symmetric random walk on a regular hexagon,Symmetric random walk on a regular hexagon,,"I wonder if there is any trick in this problem. The following graph is a regular hexagon with its center $C$ and one of the vertices $A$ . There are $6$ vertices and a center on the graph, and now assume we perform the symmetric random walk on it. Suppose the random walk starts from $A$ . Given now the process is at one of the vertices, then it has probability $\frac{1}{3}$ for entering into $C$ for the next step, and $\frac{1}{3}$ probability for moving to its two neighbors respectively as well. We want to compute the probability of this random process started from $A$ and finally return to $A$ , and it must not go through $C$ before its first arrival back to $A$ . Therefore, basically $A$ and $C$ are two absorbing states. Denote this discrete random walk as $\left\{ X_{t} \right\}_{t\geq 0}$ , and I want to compute: $$ P(X_{t} = A, ~ X_{s} \notin \left\{A, C \right\} \mbox{ for } \forall ~ 0 < s < t ~ | ~ X_{0} = A) $$ The following are my thoughts: The first intuition came to me was DTMC by regarding $A$ and $C$ as two absorbing states and the process absorbed by $A$ eventually. This requires me to write down a probability transition matrix and then solve linear equations. However, it is actually an interviewing question, so I suppose there is a much easier way to do this. Also, by intuition I think by constructing a stopping time might help, but my thought just stuck at here.","I wonder if there is any trick in this problem. The following graph is a regular hexagon with its center and one of the vertices . There are vertices and a center on the graph, and now assume we perform the symmetric random walk on it. Suppose the random walk starts from . Given now the process is at one of the vertices, then it has probability for entering into for the next step, and probability for moving to its two neighbors respectively as well. We want to compute the probability of this random process started from and finally return to , and it must not go through before its first arrival back to . Therefore, basically and are two absorbing states. Denote this discrete random walk as , and I want to compute: The following are my thoughts: The first intuition came to me was DTMC by regarding and as two absorbing states and the process absorbed by eventually. This requires me to write down a probability transition matrix and then solve linear equations. However, it is actually an interviewing question, so I suppose there is a much easier way to do this. Also, by intuition I think by constructing a stopping time might help, but my thought just stuck at here.","C A 6 A \frac{1}{3} C \frac{1}{3} A A C A A C \left\{ X_{t} \right\}_{t\geq 0} 
P(X_{t} = A, ~ X_{s} \notin \left\{A, C \right\} \mbox{ for } \forall ~ 0 < s < t ~ | ~ X_{0} = A)
 A C A",['probability']
37,Probability of a number to appear once after every number appear once in rolling die,Probability of a number to appear once after every number appear once in rolling die,,"A die is rolled until every number appears at least once. What is the probability that the number 1 only appears once? I think the problem is related to the Coupon collector's problem, but I cannot think of a good way to solve this problem. Edit: I have used simulation to find that the probability is around 0.4081. I have tried methods such as dividing the case with 1 appears in the last roll, and the case 1 appears not in the last roll, but the computation is too complicated.","A die is rolled until every number appears at least once. What is the probability that the number 1 only appears once? I think the problem is related to the Coupon collector's problem, but I cannot think of a good way to solve this problem. Edit: I have used simulation to find that the probability is around 0.4081. I have tried methods such as dividing the case with 1 appears in the last roll, and the case 1 appears not in the last roll, but the computation is too complicated.",,"['probability', 'dice', 'coupon-collector']"
38,Seemingly tricky dice question-probability that one event occurs before another event?,Seemingly tricky dice question-probability that one event occurs before another event?,,"The question is as follows: You roll two fair dice over and over.  Let $A$ be the event you see two even sums.  Let $B$ be the event you see a sum of $7$ four times.  What is the probability that event $A$ occurs before event $B$ ? I know that for mutually exclusive events with independent trials, the probability that event $E$ occurs before event $F$ is $$\frac{\mathbb{P}(E)}{\mathbb{P}(E) + \mathbb{P}(F)}.$$ I tried using this formula, but I ran into a problem.  I calculated $$\mathbb{P}(A)=\frac{1}{2}\cdot \frac{1}{2}=\frac{1}{4} \ \ \ \  \text{and} \ \ \ \  \mathbb{P}(B)=\left ( \frac{1}{6} \right )^4=\frac{1}{1296}.$$ However, I then realized that these probabilites are the events that two even sums occur $\textit{in a row},$ and similarly for my $\mathbb{P}(B).$ Does anyone have any suggestions on how to figure this out, or even if this formula is the one I should be using? Thanks in advance! Edit: I know there is a geometric distribution involved.","The question is as follows: You roll two fair dice over and over.  Let be the event you see two even sums.  Let be the event you see a sum of four times.  What is the probability that event occurs before event ? I know that for mutually exclusive events with independent trials, the probability that event occurs before event is I tried using this formula, but I ran into a problem.  I calculated However, I then realized that these probabilites are the events that two even sums occur and similarly for my Does anyone have any suggestions on how to figure this out, or even if this formula is the one I should be using? Thanks in advance! Edit: I know there is a geometric distribution involved.","A B 7 A B E F \frac{\mathbb{P}(E)}{\mathbb{P}(E) + \mathbb{P}(F)}. \mathbb{P}(A)=\frac{1}{2}\cdot \frac{1}{2}=\frac{1}{4} \ \ \ \  \text{and} \ \ \ \  \mathbb{P}(B)=\left ( \frac{1}{6} \right )^4=\frac{1}{1296}. \textit{in a row}, \mathbb{P}(B).",['probability']
39,Monty Hall problem generalized to $n$ doors,Monty Hall problem generalized to  doors,n,"Generalize the Monty Hall problem where there are $n \geq 3$ doors, of which Monty opens $m$ goat doors, with $1 \leq m \leq n$. Original Monty Hall Problem: There are $3$ doors, behind one of which there is a car (which you want), and behind the other two of which there are goats (which you don’t want). Initially, all possibilities are equally likely for where the car is. You choose a door, which for concreteness we assume is Door $1$. Monty Hall then opens a door to reveal a goat, and offers you the option of switching. Assume that Monty Hall knows which door has the car, will always open a goat door and offer the option of switching, and as above assume that if Monty Hall has a choice between opening Door $2$and Door $3$, he chooses Door $2$ and Door $3$ with equal probability . Find the probability that the strategy of always switching succeeds, given that Monty opens Door $2$. My approach: Let $C_i$ be the event that car is behind the door $i$, $O_i$ be the event that Monty opened door $i$ and $X_i$ be the event that intially I chose door $i$. Here $i=1,2,3,...,n$. Let's start with case where I chose $X_1$. Then: $P(O_{j_1, j_2, ..., j_m}|C_1, X_1) = {{n-1}\choose{m}}(\frac{1}{n-1})^m$, here $j \in$ {$m$ doors out of $n-1$, i.e., exclude Door$1$ } $P(O_{k_1, k_2, ..., k_m}|C_t, X_1) = {{n-2}\choose{m}}(\frac{1}{n-2})^m$,   here $k \in$ {$m$ doors out of $n-2$, i.e., exclude Door$1$ & Door$t$}, $t \in$ {$2,3, ..., n$} Also, $P(C_r|X_s) = \frac{1}{n}$, here $r,s \in$ {$1,2,...,n$} Probability of winning by switching is, $$P(C_3 | O_{k_1, k_2, ..., k_m}, X_1) = \frac{P(O_{k_1, k_2, ..., k_m}|C_3, X_1).P(C_3|X_1)}{P(O_{m-doors}|X_1)}$$ $$= \frac{P(O_{k_1, k_2, ..., k_m}|C_3, X_1).P(C_3|X_1)}{P(O_{j_1, j_2, ..., j_m}|C_1, X_1).P(C_1|X_1) + \sum_{t=2}^n(P(O_{k_1, k_2, ..., k_m}|C_t, X_1).P(C_t|X_1))}$$ $$ = \frac{{{n-2}\choose{m}}(\frac{1}{n-2})^m.\frac{1}{n}}{(\frac{1}{n}).({{n-1}\choose{m}}(\frac{1}{n-1})^m + {{n-2}\choose{m}}(\frac{1}{n-2})^m.(n-1))}$$ $$= \frac{(n-m-1)(n-1)^{m-1}}{(n-2)^m + (n-m-1)(n-1)^m}$$ However, the correct answer is $\frac{(n-1)}{(n-m-1).n}$. Any insights to what I have done wrong.","Generalize the Monty Hall problem where there are $n \geq 3$ doors, of which Monty opens $m$ goat doors, with $1 \leq m \leq n$. Original Monty Hall Problem: There are $3$ doors, behind one of which there is a car (which you want), and behind the other two of which there are goats (which you don’t want). Initially, all possibilities are equally likely for where the car is. You choose a door, which for concreteness we assume is Door $1$. Monty Hall then opens a door to reveal a goat, and offers you the option of switching. Assume that Monty Hall knows which door has the car, will always open a goat door and offer the option of switching, and as above assume that if Monty Hall has a choice between opening Door $2$and Door $3$, he chooses Door $2$ and Door $3$ with equal probability . Find the probability that the strategy of always switching succeeds, given that Monty opens Door $2$. My approach: Let $C_i$ be the event that car is behind the door $i$, $O_i$ be the event that Monty opened door $i$ and $X_i$ be the event that intially I chose door $i$. Here $i=1,2,3,...,n$. Let's start with case where I chose $X_1$. Then: $P(O_{j_1, j_2, ..., j_m}|C_1, X_1) = {{n-1}\choose{m}}(\frac{1}{n-1})^m$, here $j \in$ {$m$ doors out of $n-1$, i.e., exclude Door$1$ } $P(O_{k_1, k_2, ..., k_m}|C_t, X_1) = {{n-2}\choose{m}}(\frac{1}{n-2})^m$,   here $k \in$ {$m$ doors out of $n-2$, i.e., exclude Door$1$ & Door$t$}, $t \in$ {$2,3, ..., n$} Also, $P(C_r|X_s) = \frac{1}{n}$, here $r,s \in$ {$1,2,...,n$} Probability of winning by switching is, $$P(C_3 | O_{k_1, k_2, ..., k_m}, X_1) = \frac{P(O_{k_1, k_2, ..., k_m}|C_3, X_1).P(C_3|X_1)}{P(O_{m-doors}|X_1)}$$ $$= \frac{P(O_{k_1, k_2, ..., k_m}|C_3, X_1).P(C_3|X_1)}{P(O_{j_1, j_2, ..., j_m}|C_1, X_1).P(C_1|X_1) + \sum_{t=2}^n(P(O_{k_1, k_2, ..., k_m}|C_t, X_1).P(C_t|X_1))}$$ $$ = \frac{{{n-2}\choose{m}}(\frac{1}{n-2})^m.\frac{1}{n}}{(\frac{1}{n}).({{n-1}\choose{m}}(\frac{1}{n-1})^m + {{n-2}\choose{m}}(\frac{1}{n-2})^m.(n-1))}$$ $$= \frac{(n-m-1)(n-1)^{m-1}}{(n-2)^m + (n-m-1)(n-1)^m}$$ However, the correct answer is $\frac{(n-1)}{(n-m-1).n}$. Any insights to what I have done wrong.",,"['probability', 'monty-hall']"
40,"What is the possibility that at least one digit will not show up in a 20-digit ""code""?","What is the possibility that at least one digit will not show up in a 20-digit ""code""?",,"A ""code"" is composed of 20 digits (numbers from 0 to 9), and we want to choose a number randomly. What is the possibility that at least one digit will not show up in the code? What I did: We have $10^{20}$ possibilities.  Now, I want to choose 9 numbers out of the ten, and choose them randomly, so the possibility is: $\frac{10\cdot9^{20}}{10^{20}} = \frac{9^{20}}{10^{19}}$ But when I put this in the calculator, I get $1.25\dots$ I thought maybe I need a more precise calculator, but even calculators I found in google returns the same answer. The possibility isn't supposed to be above 1. What is the problem here?","A ""code"" is composed of 20 digits (numbers from 0 to 9), and we want to choose a number randomly. What is the possibility that at least one digit will not show up in the code? What I did: We have $10^{20}$ possibilities.  Now, I want to choose 9 numbers out of the ten, and choose them randomly, so the possibility is: $\frac{10\cdot9^{20}}{10^{20}} = \frac{9^{20}}{10^{19}}$ But when I put this in the calculator, I get $1.25\dots$ I thought maybe I need a more precise calculator, but even calculators I found in google returns the same answer. The possibility isn't supposed to be above 1. What is the problem here?",,"['probability', 'combinatorics', 'inclusion-exclusion']"
41,"Let $U=\operatorname{min}\{X,Y\}$ and $V=\operatorname{max}\{X,Y\}$. Show that $V-U$ is independent of $U$.",Let  and . Show that  is independent of .,"U=\operatorname{min}\{X,Y\} V=\operatorname{max}\{X,Y\} V-U U","Let $X$ and $Y$ be exponentially distributed random variables with   parameter $1$ and let $U=\operatorname{min}\{X,Y\}$ and   $V=\operatorname{max}\{X,Y\}$. Show that $V-U$ is independent of $U$. We have shown that $U$ is distributed exponentially with parameter $2$. I am surprised to find that I don't actually know how to do this. I know of no other way than to show that $\mathbb{P}(U<x,V-U<y)=\mathbb{P}(U<x)\space\mathbb{P}(V-U<y)$ and I don't think I know how to compute the left hand side. Can we do $$\int^{\infty}_0f_V(v)\mathbb{P}(x>U>v-y)\operatorname{dv}=\int^{\infty}_0\left(\left(\int F_X(t)F_Y(t)\operatorname{dt}\right)\left(\int^x_{v-y}2e^{-2u}\operatorname{du}\right)\right)\operatorname{dv}?$$ As $F_V(v)=F_X(v)F_Y(v)$ where $F_X$ and $F_Y$ are the distribution functions of $X$ and $Y$ respectively and $\int^x_{v-y}2e^{-2u}\operatorname{du}=\mathbb{P}(v-y<U<x)$. I think I've seen this before but I really don't think this is what I'm meant to do, is this correct in general and is there a better way in this specific case? Any guidance would help me out a lot, thanks!","Let $X$ and $Y$ be exponentially distributed random variables with   parameter $1$ and let $U=\operatorname{min}\{X,Y\}$ and   $V=\operatorname{max}\{X,Y\}$. Show that $V-U$ is independent of $U$. We have shown that $U$ is distributed exponentially with parameter $2$. I am surprised to find that I don't actually know how to do this. I know of no other way than to show that $\mathbb{P}(U<x,V-U<y)=\mathbb{P}(U<x)\space\mathbb{P}(V-U<y)$ and I don't think I know how to compute the left hand side. Can we do $$\int^{\infty}_0f_V(v)\mathbb{P}(x>U>v-y)\operatorname{dv}=\int^{\infty}_0\left(\left(\int F_X(t)F_Y(t)\operatorname{dt}\right)\left(\int^x_{v-y}2e^{-2u}\operatorname{du}\right)\right)\operatorname{dv}?$$ As $F_V(v)=F_X(v)F_Y(v)$ where $F_X$ and $F_Y$ are the distribution functions of $X$ and $Y$ respectively and $\int^x_{v-y}2e^{-2u}\operatorname{du}=\mathbb{P}(v-y<U<x)$. I think I've seen this before but I really don't think this is what I'm meant to do, is this correct in general and is there a better way in this specific case? Any guidance would help me out a lot, thanks!",,"['probability', 'independence', 'poisson-process', 'exponential-distribution']"
42,Combinatorics logic,Combinatorics logic,,"Say you have a bag with one black, two white and three red balls. How   many different ways can you pick the the balls? Now i've tried to visualise the problem in my head, and written it down on my paper but i still can't grapple with the logic when it comes to combinatorics. Yes i understand that we have a total of 6 balls. Which means that for the first ball we choose we have 6 positions, now here is where my logic gets skewed. Since the second ball we pick could be white, and there are two white balls. Then the we dont have 5 places to put the second one. This is because one black, followed by two whites, and three reds is the same combination if you get what i mean. There is where my intuition gets lost. Any help would be greatly appreciated.","Say you have a bag with one black, two white and three red balls. How   many different ways can you pick the the balls? Now i've tried to visualise the problem in my head, and written it down on my paper but i still can't grapple with the logic when it comes to combinatorics. Yes i understand that we have a total of 6 balls. Which means that for the first ball we choose we have 6 positions, now here is where my logic gets skewed. Since the second ball we pick could be white, and there are two white balls. Then the we dont have 5 places to put the second one. This is because one black, followed by two whites, and three reds is the same combination if you get what i mean. There is where my intuition gets lost. Any help would be greatly appreciated.",,"['probability', 'combinatorics', 'permutations']"
43,"How do you prove Cov $\left( \bar{X} , X_i - \bar{X} \right) = 0$?",How do you prove Cov ?,"\left( \bar{X} , X_i - \bar{X} \right) = 0","How do you prove Cov $\left( \bar{X} , X_i - \bar{X} \right) = 0$ given $ X_1 ,..., X_i$ are i.i.d. each with variance $\sigma^2$ and $\bar{X}$ is the sample mean?? In other words, how do you show that the sample mean and the differences of the observations from that mean are not linearly correlated??? Am I on the write track?  I've written $Var \left( \bar{X} + \left( X_i - \bar{X} \right) \right) = Var  X_i =  Var \bar{X} + Var \left( X_i - \bar{X} \right) + Cov \left( \bar{X} , X_i - \bar{X} \right)$ . I know  $Var  X_i = \sigma^2 , Var \bar{X}= \frac{\sigma^2}{n}$, so all I need left to find the covariance is $Var \left( X_i - \bar{X} \right)$. I don't know if this is right, but I wrote $Var \left( X_i - \bar{X} \right) = E\left( \left( \left( X_i - \bar{X} \right) - \mu_{ X_i - \bar{X}} \right)^2 \right)=E \left( \left( X_i - \bar{X} \right)^2 \right)=s^2$, but I don't know if that's right or helpful at all. Am I on the right track??","How do you prove Cov $\left( \bar{X} , X_i - \bar{X} \right) = 0$ given $ X_1 ,..., X_i$ are i.i.d. each with variance $\sigma^2$ and $\bar{X}$ is the sample mean?? In other words, how do you show that the sample mean and the differences of the observations from that mean are not linearly correlated??? Am I on the write track?  I've written $Var \left( \bar{X} + \left( X_i - \bar{X} \right) \right) = Var  X_i =  Var \bar{X} + Var \left( X_i - \bar{X} \right) + Cov \left( \bar{X} , X_i - \bar{X} \right)$ . I know  $Var  X_i = \sigma^2 , Var \bar{X}= \frac{\sigma^2}{n}$, so all I need left to find the covariance is $Var \left( X_i - \bar{X} \right)$. I don't know if this is right, but I wrote $Var \left( X_i - \bar{X} \right) = E\left( \left( \left( X_i - \bar{X} \right) - \mu_{ X_i - \bar{X}} \right)^2 \right)=E \left( \left( X_i - \bar{X} \right)^2 \right)=s^2$, but I don't know if that's right or helpful at all. Am I on the right track??",,"['probability', 'statistics']"
44,probability of sorted array with duplicate numbers,probability of sorted array with duplicate numbers,,"Suppose I have a sequence of n numbers {a 1 ,a 2 ,a 3 ,...a n } where some of the numbers are repeated . What is the probability that the sequence is sorted ?","Suppose I have a sequence of n numbers {a 1 ,a 2 ,a 3 ,...a n } where some of the numbers are repeated . What is the probability that the sequence is sorted ?",,"['probability', 'discrete-mathematics']"
45,"Find the probability that a word with 15 letters (selected from P,T,I,N) does not contain TINT","Find the probability that a word with 15 letters (selected from P,T,I,N) does not contain TINT",,"If a word with 15 letters is formed at random using the letters P, T, I, N, find the probability that it does not contain the sequence TINT. (I just made up this problem.)","If a word with 15 letters is formed at random using the letters P, T, I, N, find the probability that it does not contain the sequence TINT. (I just made up this problem.)",,"['probability', 'combinatorics', 'discrete-mathematics', 'inclusion-exclusion']"
46,Probabilities playing bridge,Probabilities playing bridge,,"Being very bad with probabilities, I would greatly appreciate help for the following problem. The first bid of my partner indicates that, among his $13$ cards, he handles $6$ hearts and a maximum of $3$ spades. In my hand, I handle $0$ hearts and $6$ spades. So, my question is : what are the probabilities corresponding to $0$, $1$, $2$ or $3$ spades in my partner's hand ? Should I need to precise that this is not homework ? Thnaks for your help.","Being very bad with probabilities, I would greatly appreciate help for the following problem. The first bid of my partner indicates that, among his $13$ cards, he handles $6$ hearts and a maximum of $3$ spades. In my hand, I handle $0$ hearts and $6$ spades. So, my question is : what are the probabilities corresponding to $0$, $1$, $2$ or $3$ spades in my partner's hand ? Should I need to precise that this is not homework ? Thnaks for your help.",,"['probability', 'card-games']"
47,Is there any interesting interpretation of Taylor coefficients of $e^{-\log(1-x)}$?,Is there any interesting interpretation of Taylor coefficients of ?,e^{-\log(1-x)},"Consider the series expansion of $e^{-\log(1-x)} = \frac{1}{1-x}$. Using the Taylor series of $\exp(x)$ and $-\log(1-x)$, we find that $$ 1 + \sum_{n=1}^{\infty} \Bigg( \sum_{k=1}^{\infty} \sum_{\substack{ \alpha \in \Bbb{N}_1^k \\ |\alpha| = n}} \frac{1}{k!} \frac{1}{\alpha_1 \cdots \alpha_k} \Bigg)x^n = 1 + x + x^2 + \cdots, $$ where $\alpha = (\alpha_1, \cdots, \alpha_k) \in \Bbb{N}_1^k$ is a multi-index and $|\alpha| = \alpha_1 + \cdots + \alpha_k$. Comparing both sides, we find that for any $n \geq 1$, $$ \sum_{k=1}^{\infty} \sum_{\substack{ \alpha \in \Bbb{N}_1^k \\ |\alpha| = n}} \frac{1}{k!} \frac{1}{\alpha_1 \cdots \alpha_k} = 1. $$ Is there any known combinatorial or probabilistic interpretation on it? We may think of this as a discrete distribution which assigns the probability $p(\alpha) = \frac{1}{k!}\frac{1}{\alpha_1 \cdots \alpha_k}$ to each $\alpha \in \Bbb{N}_1^k$ with $|\alpha| = n$, but I see no clear interpretation of this probability (if we have any).","Consider the series expansion of $e^{-\log(1-x)} = \frac{1}{1-x}$. Using the Taylor series of $\exp(x)$ and $-\log(1-x)$, we find that $$ 1 + \sum_{n=1}^{\infty} \Bigg( \sum_{k=1}^{\infty} \sum_{\substack{ \alpha \in \Bbb{N}_1^k \\ |\alpha| = n}} \frac{1}{k!} \frac{1}{\alpha_1 \cdots \alpha_k} \Bigg)x^n = 1 + x + x^2 + \cdots, $$ where $\alpha = (\alpha_1, \cdots, \alpha_k) \in \Bbb{N}_1^k$ is a multi-index and $|\alpha| = \alpha_1 + \cdots + \alpha_k$. Comparing both sides, we find that for any $n \geq 1$, $$ \sum_{k=1}^{\infty} \sum_{\substack{ \alpha \in \Bbb{N}_1^k \\ |\alpha| = n}} \frac{1}{k!} \frac{1}{\alpha_1 \cdots \alpha_k} = 1. $$ Is there any known combinatorial or probabilistic interpretation on it? We may think of this as a discrete distribution which assigns the probability $p(\alpha) = \frac{1}{k!}\frac{1}{\alpha_1 \cdots \alpha_k}$ to each $\alpha \in \Bbb{N}_1^k$ with $|\alpha| = n$, but I see no clear interpretation of this probability (if we have any).",,"['probability', 'combinatorics']"
48,How is the mode of an exponential distribution zero?,How is the mode of an exponential distribution zero?,,"The exponential distribution has a mode of $0$, which, according to Wikipedia , means that $0$ ""is the value that is most likely to be sampled"". This is not what I would expect, given that the exponential distribution ""describes the time between events in a Poisson process"". So, say me getting phone calls is a Poisson process and I get a call every hour on average. How is it that $0$ is the most likely sample? My intuition tells me that $0$ is one of the most unlikely samples, or at least much less likely than some number around $1$ hour.","The exponential distribution has a mode of $0$, which, according to Wikipedia , means that $0$ ""is the value that is most likely to be sampled"". This is not what I would expect, given that the exponential distribution ""describes the time between events in a Poisson process"". So, say me getting phone calls is a Poisson process and I get a call every hour on average. How is it that $0$ is the most likely sample? My intuition tells me that $0$ is one of the most unlikely samples, or at least much less likely than some number around $1$ hour.",,"['probability', 'probability-distributions', 'exponential-distribution']"
49,"Tightness, relative compactness and convergence of stochastic processes","Tightness, relative compactness and convergence of stochastic processes",,"For proving the convergence of a certain sequence of stochastic processes (which take values on a compact set), I am taking the following approach (as taken in previous papers I am looking at): 1) First proving the sequence of stochastic processes is tight. 2) Having proven tightness, I try to identify a possible limit of the sequence of stochastic processes (e.g. using tools like Donsker's invariance principle). I want to understand why, with the relevant additional conditions, these two steps are sufficient for proving that the sequence of stochastic processes does indeed converge to the possible limit (which is also a stochastic process) I find in step 2 above. My understanding so far: By Prohorov's theorem on a family $\mathcal{M}$ of probability measures on a complete, separable metric space (S,d), tightness is equivalent to relative compactness. Here relative compactness is equivalent to saying every sequence in $\mathcal{M}$  has a subsequence which converges in $\mathcal{M}_1(S)$ (the complete space of probability measures in $(S,\mathcal{B}(S)))$. So taking the family of probability measures to be the laws of the stochastic processes in the sequence gives: if the sequence of stochastic processes is tight, then there is a subsequence which has a weak convergence limit. However, at this point I am lost- how can I now show that the entire sequence (rather than one of its subsequences) has a weak convergence limit? Do we need some form of Cauchy criterion now to be satisfied by the sequence, so that the subsequence limit turns out to indeed be the sequence limit under completeness? Thanks.","For proving the convergence of a certain sequence of stochastic processes (which take values on a compact set), I am taking the following approach (as taken in previous papers I am looking at): 1) First proving the sequence of stochastic processes is tight. 2) Having proven tightness, I try to identify a possible limit of the sequence of stochastic processes (e.g. using tools like Donsker's invariance principle). I want to understand why, with the relevant additional conditions, these two steps are sufficient for proving that the sequence of stochastic processes does indeed converge to the possible limit (which is also a stochastic process) I find in step 2 above. My understanding so far: By Prohorov's theorem on a family $\mathcal{M}$ of probability measures on a complete, separable metric space (S,d), tightness is equivalent to relative compactness. Here relative compactness is equivalent to saying every sequence in $\mathcal{M}$  has a subsequence which converges in $\mathcal{M}_1(S)$ (the complete space of probability measures in $(S,\mathcal{B}(S)))$. So taking the family of probability measures to be the laws of the stochastic processes in the sequence gives: if the sequence of stochastic processes is tight, then there is a subsequence which has a weak convergence limit. However, at this point I am lost- how can I now show that the entire sequence (rather than one of its subsequences) has a weak convergence limit? Do we need some form of Cauchy criterion now to be satisfied by the sequence, so that the subsequence limit turns out to indeed be the sequence limit under completeness? Thanks.",,"['probability', 'probability-theory', 'stochastic-processes', 'weak-convergence']"
50,Submartingale convergence (Durrett 5.3.1),Submartingale convergence (Durrett 5.3.1),,"Exercise 5.3.1 in Durrett's ""Probability Theory and Examples"" states Let $X_n$, $n\ge 0$, be a submartingale with $\sup X_n < \infty$. Let $\xi_n=X_n-X_{n-1}$, and suppose $E(\sup \xi_n^+)<\infty$. Show that $X_n$ converges almost surely. Here are my thoughts: It looks like we need to use theorem 5.2.8 (Martingale convergence theorem), which states that $X_n$ converges almost surely if $\sup EX_n^+<\infty$. I am trying to understand why we can just do the following (or at least I'm guessing we can't): Suppose $X_n > 0$ (edit: on some set with positive measure), then $0< \sup X_n < \infty$, and therefore $EX_n^+ \le \sup X_n < \infty$. So we're done. Otherwise, if $X_n \le 0$ a.e., then $\sup X_n^+ = 0$ a.e. Once again, we're done. Am I missing something? Since I didn't use all the information, I probably am. Thanks for the help.","Exercise 5.3.1 in Durrett's ""Probability Theory and Examples"" states Let $X_n$, $n\ge 0$, be a submartingale with $\sup X_n < \infty$. Let $\xi_n=X_n-X_{n-1}$, and suppose $E(\sup \xi_n^+)<\infty$. Show that $X_n$ converges almost surely. Here are my thoughts: It looks like we need to use theorem 5.2.8 (Martingale convergence theorem), which states that $X_n$ converges almost surely if $\sup EX_n^+<\infty$. I am trying to understand why we can just do the following (or at least I'm guessing we can't): Suppose $X_n > 0$ (edit: on some set with positive measure), then $0< \sup X_n < \infty$, and therefore $EX_n^+ \le \sup X_n < \infty$. So we're done. Otherwise, if $X_n \le 0$ a.e., then $\sup X_n^+ = 0$ a.e. Once again, we're done. Am I missing something? Since I didn't use all the information, I probably am. Thanks for the help.",,"['probability', 'probability-theory', 'martingales']"
51,Is rolling a dice a Gauss distribution?,Is rolling a dice a Gauss distribution?,,"I'm in an argument with a friend over rolling a dice several times, for example rolling 5 times. His argument is, that is far more difficult to roll out 1-1-1-1-1 than any other combination (for example 1-5-2-4-3) as the results of the rolls distribute in a Gauss manner so the edges are somehow less probable. His arguments have to do with Bayes theory. My intuition tells just the opposite since the dices have no memmory and one roll isn't conditioned by the latter, so any combination is equally probable. I know that dices are a very recurrent topic here but I haven't found an straight answer to my question... In the final terms it seems is a discussion of the Bayessian against frequentist approaches to probabilistics. We're not going to solve it today... I abandon you since we have a duel at twelve o'clock in the church yard. EDIT As I'm seeing many comments and answers here I would like to point out that the discussion is about combinations WITHOUT PERMUTATIONS, that is 12345 is different of 54321. Furthermore, I said 5 rolls to put a concrete example, but what we were discussing was for a large number of rolls (take large as the number you want...)","I'm in an argument with a friend over rolling a dice several times, for example rolling 5 times. His argument is, that is far more difficult to roll out 1-1-1-1-1 than any other combination (for example 1-5-2-4-3) as the results of the rolls distribute in a Gauss manner so the edges are somehow less probable. His arguments have to do with Bayes theory. My intuition tells just the opposite since the dices have no memmory and one roll isn't conditioned by the latter, so any combination is equally probable. I know that dices are a very recurrent topic here but I haven't found an straight answer to my question... In the final terms it seems is a discussion of the Bayessian against frequentist approaches to probabilistics. We're not going to solve it today... I abandon you since we have a duel at twelve o'clock in the church yard. EDIT As I'm seeing many comments and answers here I would like to point out that the discussion is about combinations WITHOUT PERMUTATIONS, that is 12345 is different of 54321. Furthermore, I said 5 rolls to put a concrete example, but what we were discussing was for a large number of rolls (take large as the number you want...)",,"['probability', 'probability-theory', 'probability-distributions', 'dice']"
52,A coin is tossed $m+n$ times $(m>n)$.Show that the probability of atleast $m$ consecutive heads is $\frac{n+2}{2^{m+1}}$,A coin is tossed  times .Show that the probability of atleast  consecutive heads is,m+n (m>n) m \frac{n+2}{2^{m+1}},"A coin is tossed $m+n$ times $(m>n)$.Show that the probability of atleast $m$ consecutive heads is $\frac{n+2}{2^{m+1}}$. I could not attempt this question,except few initial steps.Let $H$ and $T$ denote turning up of the head and tail.$\therefore P(H)=P(T)=\frac{1}{2}$ Please help me.","A coin is tossed $m+n$ times $(m>n)$.Show that the probability of atleast $m$ consecutive heads is $\frac{n+2}{2^{m+1}}$. I could not attempt this question,except few initial steps.Let $H$ and $T$ denote turning up of the head and tail.$\therefore P(H)=P(T)=\frac{1}{2}$ Please help me.",,"['probability', 'combinatorics']"
53,E[XY] from table,E[XY] from table,,"This is an example from a book that I dn't really understand. X=1 | X=2 Y=3 | 0.3 | 0.1 Y=6 | 0.1 | 0.5 $$E(XY)=\sum_{all\;y}\sum_{all\;x}xyp_{x,y}(x,y)=8.1$$ I can't grasp how this dubble sum works. I thought it was something lke this: First I take the sum off all y $3*(0.3+0.1)+6*(0.1+0.5)=4.8$ and then I take the sum of all x $1*(0.3+0.1)+2*(0.1+0.5)=1.6$ then i take $x*y = 7.68$. Clearly I was wrong. And honestly I don't even know what $p_{x,y}(x,y)$ means.","This is an example from a book that I dn't really understand. X=1 | X=2 Y=3 | 0.3 | 0.1 Y=6 | 0.1 | 0.5 $$E(XY)=\sum_{all\;y}\sum_{all\;x}xyp_{x,y}(x,y)=8.1$$ I can't grasp how this dubble sum works. I thought it was something lke this: First I take the sum off all y $3*(0.3+0.1)+6*(0.1+0.5)=4.8$ and then I take the sum of all x $1*(0.3+0.1)+2*(0.1+0.5)=1.6$ then i take $x*y = 7.68$. Clearly I was wrong. And honestly I don't even know what $p_{x,y}(x,y)$ means.",,['probability']
54,Probability of balls in boxes,Probability of balls in boxes,,"If $12$ balls are thrown at random into $20$ boxes, what is the probability that no box will receive more than $1$ ball? So my book says the answer is: $\displaystyle \frac{20!}{8!20^{12}}$ However I am having some trouble understanding this result and was hoping for some clarification. There's a formula in my book: $\displaystyle p=\frac{n!}{(n-k)!n^k}$ so it's apparent that $n=20$ and $k=12$, but I don't understand the reasoning behind it.","If $12$ balls are thrown at random into $20$ boxes, what is the probability that no box will receive more than $1$ ball? So my book says the answer is: $\displaystyle \frac{20!}{8!20^{12}}$ However I am having some trouble understanding this result and was hoping for some clarification. There's a formula in my book: $\displaystyle p=\frac{n!}{(n-k)!n^k}$ so it's apparent that $n=20$ and $k=12$, but I don't understand the reasoning behind it.",,['probability']
55,Probability that two random permutations of an $n$-set commute?,Probability that two random permutations of an -set commute?,n,"From this MathOverflow question : It is well known that two randomly chosen permutations of $n$ symbols commute with probability $p_n/n!$ where $p_n$ is the number of partitions of $n$. -- Benjamin Steinberg Unfortunately, it's not well known to me.  Can I get a reference or link to this result?  Or a proof, if it's simple enough. (Google doesn't work where I am; I tried Binging two random permutations commute but it only gives the MathOverflow link.) I need this result for a secret sharing scheme I'm currently analyzing.","From this MathOverflow question : It is well known that two randomly chosen permutations of $n$ symbols commute with probability $p_n/n!$ where $p_n$ is the number of partitions of $n$. -- Benjamin Steinberg Unfortunately, it's not well known to me.  Can I get a reference or link to this result?  Or a proof, if it's simple enough. (Google doesn't work where I am; I tried Binging two random permutations commute but it only gives the MathOverflow link.) I need this result for a secret sharing scheme I'm currently analyzing.",,"['probability', 'group-theory', 'reference-request', 'permutations']"
56,Flip a coin 6 times. What is probability of at least 4 heads?,Flip a coin 6 times. What is probability of at least 4 heads?,,"I can figure out the much simpler case of the probability of getting at least 2 heads in 3 coin flips: There are 8 (2^3) ways to flip a coin 3 times: HHH, HHT, TTT, TTH, HTH, HTT, THT, THH. 4 of these contain 2 or more heads. Therefor the probability of at least 2 heads in 3 coin flips is 4/8. How could I have done this without writing out all the possibilities and counting the ones with 2 or 3 H's? Today the Indiana Pacers won the first game in the 4 out of 7 series with the Miami Heat. Assuming that either team has a 50% chance of winning each of the remaining games, what is the probability of the Heat winning 4 of the remaining games?","I can figure out the much simpler case of the probability of getting at least 2 heads in 3 coin flips: There are 8 (2^3) ways to flip a coin 3 times: HHH, HHT, TTT, TTH, HTH, HTT, THT, THH. 4 of these contain 2 or more heads. Therefor the probability of at least 2 heads in 3 coin flips is 4/8. How could I have done this without writing out all the possibilities and counting the ones with 2 or 3 H's? Today the Indiana Pacers won the first game in the 4 out of 7 series with the Miami Heat. Assuming that either team has a 50% chance of winning each of the remaining games, what is the probability of the Heat winning 4 of the remaining games?",,['probability']
57,Constructing a probability function from its moments.,Constructing a probability function from its moments.,,"My intuition tells me that if we have a random variable that follows a Probability Mass Function (PMF) and that can take $n$ different values, then if we have the $n^{th}$ first moments we can reconstruct the original PMF. Is it true? How can we perform such thing? For example, what is the PMF which can take only 5 different values and which $5^{th}$ first moments are [1, 0.5, 0.4, 0.3, 0.2]? Similarly could we define the infinite set of Probability Density Functions (PDF) which correspond to a list of $n$ first moments? How can we do such thing? For example what is the infinite set of PDF which $5^{th}$ first moments are [1, 0.5, 0.4, 0.3, 0.2]?","My intuition tells me that if we have a random variable that follows a Probability Mass Function (PMF) and that can take $n$ different values, then if we have the $n^{th}$ first moments we can reconstruct the original PMF. Is it true? How can we perform such thing? For example, what is the PMF which can take only 5 different values and which $5^{th}$ first moments are [1, 0.5, 0.4, 0.3, 0.2]? Similarly could we define the infinite set of Probability Density Functions (PDF) which correspond to a list of $n$ first moments? How can we do such thing? For example what is the infinite set of PDF which $5^{th}$ first moments are [1, 0.5, 0.4, 0.3, 0.2]?",,"['probability', 'probability-theory', 'probability-distributions']"
58,Probability that $ax^2+bx+c$ has no real roots after rolling 3 dice.,Probability that  has no real roots after rolling 3 dice.,ax^2+bx+c,"Suppose that I roll $3$ dice and write down the outcome as the coefficients $a,b,c$ in the polynomial $ax^2+bx+c$ respectively. What is the probability that this polynomial has no real roots? So, I have to count the number of triples $(a,b,c)$ such that $b^2 < 4ac$, where $a,b,c \in \{1,2,3,4,5,6\}$. I'm not sure how I can do that. Please give me a hint first. This problem is from a high school probability course, so I think it must have a very basic solution.","Suppose that I roll $3$ dice and write down the outcome as the coefficients $a,b,c$ in the polynomial $ax^2+bx+c$ respectively. What is the probability that this polynomial has no real roots? So, I have to count the number of triples $(a,b,c)$ such that $b^2 < 4ac$, where $a,b,c \in \{1,2,3,4,5,6\}$. I'm not sure how I can do that. Please give me a hint first. This problem is from a high school probability course, so I think it must have a very basic solution.",,"['probability', 'quadratics', 'dice']"
59,Normal distribution with absolute value,Normal distribution with absolute value,,"I am new to the normal distribution topic. While I have understood and solved various different kind of questions, the normal distribution questions with absolute value, are the ones I have no idea on. So could someone plz help me in these type of questions? Here are the ones I am stuck at. (Thanks a LOT in advance for your help) If $Z$ is the coefficient of normally distributed random variable, find ‘$a$’ such that: $\mathbb P(|Z| < a) = 0.383$ $X$ is a normally distributed random variable with mean($\mu$) $84$ and variance($\sigma^2$) $12$, calculate: $\mathbb P(|X-84| > 2.9)$ If $X$ is normally distributed with mean($\mu$) $400$ and standard deviation($\sigma$) $8$, find the value of $k$ such that: $\mathbb P(|X-400| < k) = 0.975$ $X$ is normally distributed random variable with mean $m$ and standard deviation $s$ . Find the value of $m$ and the value of $s$ if: $\mathbb P (X<35) = 0.02$ & $\mathbb P(35 < X < 45) = 0.65$. (for this, I just need help in the second part with the two values case. The first part Ive done already)","I am new to the normal distribution topic. While I have understood and solved various different kind of questions, the normal distribution questions with absolute value, are the ones I have no idea on. So could someone plz help me in these type of questions? Here are the ones I am stuck at. (Thanks a LOT in advance for your help) If $Z$ is the coefficient of normally distributed random variable, find ‘$a$’ such that: $\mathbb P(|Z| < a) = 0.383$ $X$ is a normally distributed random variable with mean($\mu$) $84$ and variance($\sigma^2$) $12$, calculate: $\mathbb P(|X-84| > 2.9)$ If $X$ is normally distributed with mean($\mu$) $400$ and standard deviation($\sigma$) $8$, find the value of $k$ such that: $\mathbb P(|X-400| < k) = 0.975$ $X$ is normally distributed random variable with mean $m$ and standard deviation $s$ . Find the value of $m$ and the value of $s$ if: $\mathbb P (X<35) = 0.02$ & $\mathbb P(35 < X < 45) = 0.65$. (for this, I just need help in the second part with the two values case. The first part Ive done already)",,"['probability', 'normal-distribution', 'absolute-value']"
60,"30-sided die, 2-player game","30-sided die, 2-player game",,"Two players play a game. Player 1 goes first, and chooses a number between 1 and 30 (inclusive). Player 2 chooses second; he can't choose Player 1's number. A fair 30-sided die is rolled. The player that chose the number closest to the value of the roll takes that value (say, in dollars) from the other player. Would you rather be Player 1 (choose first) or Player 2 (choose second)? Also, what integer should that player choose? After doing some trial-and-error calculation, I now know the correct player and the integer he should choose, but what is a faster way to determine which player to be, and which number he should choose?","Two players play a game. Player 1 goes first, and chooses a number between 1 and 30 (inclusive). Player 2 chooses second; he can't choose Player 1's number. A fair 30-sided die is rolled. The player that chose the number closest to the value of the roll takes that value (say, in dollars) from the other player. Would you rather be Player 1 (choose first) or Player 2 (choose second)? Also, what integer should that player choose? After doing some trial-and-error calculation, I now know the correct player and the integer he should choose, but what is a faster way to determine which player to be, and which number he should choose?",,"['probability', 'dice']"
61,"""Pairwise independent"" is weaker that ""independent""","""Pairwise independent"" is weaker that ""independent""",,"Can someone please give me a reference  to an (simple, realworld, i.e. not constructed) example of a discrete probability space such that there are three events in it that are pairwise independent but all three together are not independent (although I wouldn't mind, if someone would give me the example as an answer).","Can someone please give me a reference  to an (simple, realworld, i.e. not constructed) example of a discrete probability space such that there are three events in it that are pairwise independent but all three together are not independent (although I wouldn't mind, if someone would give me the example as an answer).",,['probability']
62,What is the best way to compare probabilities?,What is the best way to compare probabilities?,,"If you have two different events with different (known) probabilities, what is the best way to compare the probabilities? For example, the relationship between $0.5$ and $0.7$ is not the same as the relationship between $0.79$ and $0.99$. In both cases, the second number is $0.2$ more than the first; however, raising the probability of something from $0.5$ to $0.7$ will not have nearly as much of an effect as raising it from $0.79$ to $0.99$. To me, it seems like there should be some sort of precise way to compare probabilities, but I have not been able to find one. I want to be able to quantify the comparison in a way that makes sense. Given two numbers, there are countless ways to compare them (subtraction, division, logarithms, etc), but I want to know which comparisons make the most sense in the context of probability. My current idea is converting the probabilities to z-scores, so $(0.5, 0.7)$ becomes $(0,0.52)$, which is a gain of $0.52$. Also, $(0.79,0.99)$ becomes $(0.81,2.31)$, which is a gain of $1.5$.","If you have two different events with different (known) probabilities, what is the best way to compare the probabilities? For example, the relationship between $0.5$ and $0.7$ is not the same as the relationship between $0.79$ and $0.99$. In both cases, the second number is $0.2$ more than the first; however, raising the probability of something from $0.5$ to $0.7$ will not have nearly as much of an effect as raising it from $0.79$ to $0.99$. To me, it seems like there should be some sort of precise way to compare probabilities, but I have not been able to find one. I want to be able to quantify the comparison in a way that makes sense. Given two numbers, there are countless ways to compare them (subtraction, division, logarithms, etc), but I want to know which comparisons make the most sense in the context of probability. My current idea is converting the probabilities to z-scores, so $(0.5, 0.7)$ becomes $(0,0.52)$, which is a gain of $0.52$. Also, $(0.79,0.99)$ becomes $(0.81,2.31)$, which is a gain of $1.5$.",,"['probability', 'soft-question']"
63,Defective items probability question.,Defective items probability question.,,"Hi I'm working with probability as part of an engineering course, and I'm struggling with the following tutorial question:  Components of a certain type are shipped to a supplier in batches of ten. Suppose that 50% of all such batches contain no defective components, 35% contain one defective component while 15% contain two defective components. If two components are randomly selected from the batch. What are the probabilities associated with 0, 1 and 2 defective components being in the batch under each of the following conditions? a) Neither selected component is defective. b) One of the two components is defective. c) Both components are defective. I've considered using hypergeometric probability distribution for events P(35%) and P(15%) while comparing to P(50%) but this yields no result.","Hi I'm working with probability as part of an engineering course, and I'm struggling with the following tutorial question:  Components of a certain type are shipped to a supplier in batches of ten. Suppose that 50% of all such batches contain no defective components, 35% contain one defective component while 15% contain two defective components. If two components are randomly selected from the batch. What are the probabilities associated with 0, 1 and 2 defective components being in the batch under each of the following conditions? a) Neither selected component is defective. b) One of the two components is defective. c) Both components are defective. I've considered using hypergeometric probability distribution for events P(35%) and P(15%) while comparing to P(50%) but this yields no result.",,"['probability', 'statistics']"
64,'Quantum' approach to classical probability,'Quantum' approach to classical probability,,"Quantum mechanics defines a state of a system as a superposition of 'classical' states with complex coefficients, thus reducing many problems to linear algebra. Can classical statistics be approached to that way? Is this approach useful?","Quantum mechanics defines a state of a system as a superposition of 'classical' states with complex coefficients, thus reducing many problems to linear algebra. Can classical statistics be approached to that way? Is this approach useful?",,"['probability', 'quantum-mechanics']"
65,Probability of throwing the same multiset twice in a row with six dice,Probability of throwing the same multiset twice in a row with six dice,,"Six dice are thrown. The six dice are thrown a second time. What is the probability of getting the same numbers as in the first throw? If the order of the six numbers matters, the problem is easy, but if the order does not matter, I find myself in troubles, because I should consider too many cases depending on the number of repeated numbers and don't know how to proceed.","Six dice are thrown. The six dice are thrown a second time. What is the probability of getting the same numbers as in the first throw? If the order of the six numbers matters, the problem is easy, but if the order does not matter, I find myself in troubles, because I should consider too many cases depending on the number of repeated numbers and don't know how to proceed.",,"['probability', 'combinatorics', 'dice', 'multisets']"
66,Weaker condition for law of large numbers,Weaker condition for law of large numbers,,"$X_k$'s are i.i.d. Suppose $X_k$ is symmetric and $E[|X_k|^{3/4}]<\infty$. Do we have $S_n/n \rightarrow 0$ either in probability or almost surely, where $S_n$ is the partial sum.","$X_k$'s are i.i.d. Suppose $X_k$ is symmetric and $E[|X_k|^{3/4}]<\infty$. Do we have $S_n/n \rightarrow 0$ either in probability or almost surely, where $S_n$ is the partial sum.",,['probability']
67,Produce output with certain probability using fair coin flips,Produce output with certain probability using fair coin flips,,"""Introduction to Algorithm"" C.2-6 Describe a procedure that takes as input two integers a and b such that $0 < a < b$   and, using fair coin flips, produces as output heads with probability $a / b$ and tails   with probability $(b - a) /b$. Give a bound on the expected number of coin flips,   which should be O(1) (Hint: Represent a/b in binary.) My guess is that we can use head to represent bit 0 and tail for bit 1. Then by flipping $m = \lceil \log_2 b \rceil$ times, we obtain a $m$ bit binary based number $x$.  If $ x \ge b $, then we just drop x and do the experiment again, until we can an $ x < b$.  This x has probility $P\{ x < a\} = \frac a b$ and $P\{ a \le x < a\} = \frac {b - a} b$ But I'm not quite sure if my solution is what the question asks. Am I right? Edit, I think Michael and TonyK gave the correct algorithm, but Michael explained the reason behind the algorithm. The 3 questions he asked: show that this process requires c coin flips, in expectation, for some constant c; The expectation of c, the number of flips, as TonyK pointed out, is 2. show that you yell ""NO!"" with probability 2/3; P(yell ""NO!"") = P(""the coin comes up tails on an odd toss"") = $ \sum_{k=1}^\infty (\frac 1 2)^ k = \frac 2 3$ explain how you'd generalize to other rational numbers, with the same constant c It's the algorithm given by TonyK. We can restate it like this Represent a/b in binary. Define $f(Head) = 0$, and $f(Tail) = 1$.  If f(nth flip's result) = ""nth bit of a/b"" then terminate.  If the last flip is Head, we yell ""Yes"", otherwise ""No"". We have $ P \{Yes\} = \sum_{i\in I}(1/2)^i = \frac a b $ where I represent the set of index where the binary expression of a/b is 1.","""Introduction to Algorithm"" C.2-6 Describe a procedure that takes as input two integers a and b such that $0 < a < b$   and, using fair coin flips, produces as output heads with probability $a / b$ and tails   with probability $(b - a) /b$. Give a bound on the expected number of coin flips,   which should be O(1) (Hint: Represent a/b in binary.) My guess is that we can use head to represent bit 0 and tail for bit 1. Then by flipping $m = \lceil \log_2 b \rceil$ times, we obtain a $m$ bit binary based number $x$.  If $ x \ge b $, then we just drop x and do the experiment again, until we can an $ x < b$.  This x has probility $P\{ x < a\} = \frac a b$ and $P\{ a \le x < a\} = \frac {b - a} b$ But I'm not quite sure if my solution is what the question asks. Am I right? Edit, I think Michael and TonyK gave the correct algorithm, but Michael explained the reason behind the algorithm. The 3 questions he asked: show that this process requires c coin flips, in expectation, for some constant c; The expectation of c, the number of flips, as TonyK pointed out, is 2. show that you yell ""NO!"" with probability 2/3; P(yell ""NO!"") = P(""the coin comes up tails on an odd toss"") = $ \sum_{k=1}^\infty (\frac 1 2)^ k = \frac 2 3$ explain how you'd generalize to other rational numbers, with the same constant c It's the algorithm given by TonyK. We can restate it like this Represent a/b in binary. Define $f(Head) = 0$, and $f(Tail) = 1$.  If f(nth flip's result) = ""nth bit of a/b"" then terminate.  If the last flip is Head, we yell ""Yes"", otherwise ""No"". We have $ P \{Yes\} = \sum_{i\in I}(1/2)^i = \frac a b $ where I represent the set of index where the binary expression of a/b is 1.",,['probability']
68,Failing to guess each card in a deck,Failing to guess each card in a deck,,"Consider the situation from this video . Cards from a normal playing deck are dealt out one at a time while the player guesses what the number of the card is not (suit is ignored). To be clear, the player wants to go through the entire deck, never having their guess match the card. What are the odds that the player will achieve this, assuming they possess a perfect memory and use a perfect strategy? There is some discussion on the show's forums .","Consider the situation from this video . Cards from a normal playing deck are dealt out one at a time while the player guesses what the number of the card is not (suit is ignored). To be clear, the player wants to go through the entire deck, never having their guess match the card. What are the odds that the player will achieve this, assuming they possess a perfect memory and use a perfect strategy? There is some discussion on the show's forums .",,"['probability', 'card-games']"
69,Can the Binomial Theorem be proved probabilistically?,Can the Binomial Theorem be proved probabilistically?,,"I believe that the answer is affirmative, as there is a reputable-appearing subscription-hidden link on the web claiming such, and because, although I have not seen that proof, I have (I believe) a proof of my own (which I’m pretty sure is similar to the hidden one). Here is the link to the subscription-hidden article. And here’s my take on the question that I have posed: Using elementary Probability Theory, and an appeal to symmetry and continuity, it is easy to prove the Binomial Theorem. First, we note that it is easy to establish that $\binom{n}{k}$ = C(n,k), by first (easily) establishing the formula for P(n,k), and then (easily) modifying it to give C(n,k). We can easily show that the binomial coefficients must be C(n,k) for the expansion of ${(x + y)}^n$, for positive integers x and y, by noting the following situation: If an urn contains x white balls and y black balls, then, given that (exactly) $n$ balls are selected, with replacement, the events: 0. picking n white balls 1. picking n – 1 white balls and 1 black ball 2. picking n – 2 white balls and 2 black balls … n – 1. picking 1 white ball and n – 1 black balls n. picking n black balls are mutually-exclusive and exhaustive events, and so the sum of their probabilities is unity. However, it is obvious that the number of ways in which event k can occur is C(n,k). Since all the terms have a denominator of ${(x + y)}^n$, we can multiply both sides of the equation by ${(x + y)}^n$ to get the Binomial Theorem. The case for arbitrary integers x and y follows by symmetry, and the case for arbitrary real numbers x and y follows by continuity. Done. Notation: $\binom{n}{k}$ is $\frac{n!}{(k!)(n – k)!}$, C(n,k) is the number of combinations of n things taken k at a time, and P(n,k) is the number of permutations of n things taken k at a time.","I believe that the answer is affirmative, as there is a reputable-appearing subscription-hidden link on the web claiming such, and because, although I have not seen that proof, I have (I believe) a proof of my own (which I’m pretty sure is similar to the hidden one). Here is the link to the subscription-hidden article. And here’s my take on the question that I have posed: Using elementary Probability Theory, and an appeal to symmetry and continuity, it is easy to prove the Binomial Theorem. First, we note that it is easy to establish that $\binom{n}{k}$ = C(n,k), by first (easily) establishing the formula for P(n,k), and then (easily) modifying it to give C(n,k). We can easily show that the binomial coefficients must be C(n,k) for the expansion of ${(x + y)}^n$, for positive integers x and y, by noting the following situation: If an urn contains x white balls and y black balls, then, given that (exactly) $n$ balls are selected, with replacement, the events: 0. picking n white balls 1. picking n – 1 white balls and 1 black ball 2. picking n – 2 white balls and 2 black balls … n – 1. picking 1 white ball and n – 1 black balls n. picking n black balls are mutually-exclusive and exhaustive events, and so the sum of their probabilities is unity. However, it is obvious that the number of ways in which event k can occur is C(n,k). Since all the terms have a denominator of ${(x + y)}^n$, we can multiply both sides of the equation by ${(x + y)}^n$ to get the Binomial Theorem. The case for arbitrary integers x and y follows by symmetry, and the case for arbitrary real numbers x and y follows by continuity. Done. Notation: $\binom{n}{k}$ is $\frac{n!}{(k!)(n – k)!}$, C(n,k) is the number of combinations of n things taken k at a time, and P(n,k) is the number of permutations of n things taken k at a time.",,"['probability', 'combinatorics']"
70,Refining the central limit theorem on discrete random vars,Refining the central limit theorem on discrete random vars,,"Let $x_i$ be iid nonnegative discrete random variables $E[x_i]=N/M$ for some integers $N, M$, variance $\sigma^2$ and higher moments known (finite). Then, the sum $\displaystyle S = \sum_{i=1}^M x_i$ will have $E[S]=N$. I'm interested in the probability that  $S$ takes that precise value: $A=P\left(S=E[S]\right)$. Applying the central limit theorem, I can write $\displaystyle A \approx \frac{1}{\sqrt{ 2 \pi M \sigma^2}}$ My question is: can this approximation be refined? ADDED: To add some example-context-motivation: Lets consider $X$ as a sum of $N$ Bernoullis (0/1) with prob=$p$, such that $E(X)=E(N p)$ is an integer. We can compute exactly the probability that $X$ attains its expected value, it's a Binomial: $\displaystyle P = P(X= N p) = {N \choose N p} p^{N p} q^{N q} \hspace{2cm}$  [1a] We might also get an approximate value of that probability using the CTL (Central Limit Theorem) $\displaystyle P \approx \frac{1}{\sqrt{2 \pi N p q}} \hspace{2cm} $  [2a] If we take [1a] and use the Stirling approximation, with $K \approx (K/e)^K \sqrt{2 \pi K}$, we get the same value. Fine. Now, we may try to refine the approximation, both from [1a] and [2a]. Plugging the next orden Stirling approximation in [1a], we get (I am not mistaken) $\displaystyle P \approx \frac{1}{\sqrt{2 \pi N p q}} \left(1 - \frac{1- p q}{12 N p q} \right) \hspace{2cm} $  [1b] To refine the CTL, one can think of use some ""continuity correction"" to evaluate more precisely the (hipothetical) gaussian integral add some terms from the Edgeworth expansions do nothing of the above - because the CLT does not justify those procedures in this scenario (just one value of a discrete variable) I'm not sure which is the correct way. But let's try the first one:  the next order approximation of the integral gives me (again, if I'm not mistaken) $\displaystyle P \approx \frac{1}{\sqrt{2 \pi N p q}} \left(1 - \frac{1}{24 N p q} \right) \hspace{2cm} $  [2b] This is not the same as [1b], but it's close. Is this just casual? Was it a reasonable thing to do? Should I look (also/instead) after the Edgeworth expansions?","Let $x_i$ be iid nonnegative discrete random variables $E[x_i]=N/M$ for some integers $N, M$, variance $\sigma^2$ and higher moments known (finite). Then, the sum $\displaystyle S = \sum_{i=1}^M x_i$ will have $E[S]=N$. I'm interested in the probability that  $S$ takes that precise value: $A=P\left(S=E[S]\right)$. Applying the central limit theorem, I can write $\displaystyle A \approx \frac{1}{\sqrt{ 2 \pi M \sigma^2}}$ My question is: can this approximation be refined? ADDED: To add some example-context-motivation: Lets consider $X$ as a sum of $N$ Bernoullis (0/1) with prob=$p$, such that $E(X)=E(N p)$ is an integer. We can compute exactly the probability that $X$ attains its expected value, it's a Binomial: $\displaystyle P = P(X= N p) = {N \choose N p} p^{N p} q^{N q} \hspace{2cm}$  [1a] We might also get an approximate value of that probability using the CTL (Central Limit Theorem) $\displaystyle P \approx \frac{1}{\sqrt{2 \pi N p q}} \hspace{2cm} $  [2a] If we take [1a] and use the Stirling approximation, with $K \approx (K/e)^K \sqrt{2 \pi K}$, we get the same value. Fine. Now, we may try to refine the approximation, both from [1a] and [2a]. Plugging the next orden Stirling approximation in [1a], we get (I am not mistaken) $\displaystyle P \approx \frac{1}{\sqrt{2 \pi N p q}} \left(1 - \frac{1- p q}{12 N p q} \right) \hspace{2cm} $  [1b] To refine the CTL, one can think of use some ""continuity correction"" to evaluate more precisely the (hipothetical) gaussian integral add some terms from the Edgeworth expansions do nothing of the above - because the CLT does not justify those procedures in this scenario (just one value of a discrete variable) I'm not sure which is the correct way. But let's try the first one:  the next order approximation of the integral gives me (again, if I'm not mistaken) $\displaystyle P \approx \frac{1}{\sqrt{2 \pi N p q}} \left(1 - \frac{1}{24 N p q} \right) \hspace{2cm} $  [2b] This is not the same as [1b], but it's close. Is this just casual? Was it a reasonable thing to do? Should I look (also/instead) after the Edgeworth expansions?",,['probability']
71,"flip a fair coin until $n$ consecutive results, whats the probability of the first and last toss matching?","flip a fair coin until  consecutive results, whats the probability of the first and last toss matching?",n,"lets say i flip a coin until i get $n$ consecutive heads or tails. whats the probability of the first ever coin i flipped to match the last coin i flipped? the question also asks, is it exactly $0.5$ ? more or less? i figured if the total flips i make is $n$ then $p(e)=1$ . for $n+1$ total flips i get $p(e)=0$ . at the end i got something like $(0.5)^n$ but this just doesnt feel right. thanks for the help.","lets say i flip a coin until i get consecutive heads or tails. whats the probability of the first ever coin i flipped to match the last coin i flipped? the question also asks, is it exactly ? more or less? i figured if the total flips i make is then . for total flips i get . at the end i got something like but this just doesnt feel right. thanks for the help.",n 0.5 n p(e)=1 n+1 p(e)=0 (0.5)^n,"['probability', 'probability-distributions']"
72,Binomial theorem from first principles?,Binomial theorem from first principles?,,"I suppose I'll give a little context to this... I was at first really excited by the prospect that both Bernoulli and Taylor's versions of $e^x$ actually ammount to the same thing (where, when you expand Bernoulli's definition $\lim_{n\to\infty}(1+\frac{x}{n})^n$ it simplifies to the Taylor series $\sum_{n=0}^{\infty}\frac{x^n}{n!}$ - unlike, say, trigonometric functions like $\sin(x)$ which look a bit more unsatisfying). However, upon further reflection, to say that one identity 'simplifies' to the other seems almost circular given it presupposes binomial theorem. So, I decided to do a little scouting online, and found that binomial theorem could be proven using proof by induction. But once again, I felt unsatisfied as it feels as though you've just divined up some formula which works. How did you come up with it in the first place? Well, that's when I thought of probability theory. We use a binomial expression $^nC_{r}$ when we are looking for the number of combinations we have for arranging things. We can very intuitively derive this formula, however, as I don't want this question to be unecessarily large, I'm not going to go into detail about this here. What counts, is that we can figure out this formula from first principles - we're not getting it from nowhere. As I'm sure you already know, $^nC_{r}$ is key to figuring out binomial distributions. Once again I'm not going to explaim this, but an example probability calculation becomes $^{10}C_{4}(\frac{1}{6})^4(\frac{1}{6})^{10-4}$ for rolling 4 sixes in 10 total rolls. According to (Kolmogorov's) axioms of probability, the probability of all total outcomes $P(\Omega)$ is 1. Let's consider the context of total binomial outcomes of 3 trials (I pick this number for simple and illustrative purposes), where we designate the probablity of success, $\frac{1}{5}$ , and that of failure, $\frac{4}{5}$ , (where the sum of all different outcomes, here success and failure = 1). Well, we know that becuase we have 3 trials, logically, we'll have 4 possibilities: 0 successes, 1 success, 2 successess, or 3 success; we can write out our probability as: $^{3}C_{0}(\frac{1}{5})^3(\frac{4}{5})^0$ + $^{3}C_{1}(\frac{1}{5})^2(\frac{4}{5})^1$ + $^{3}C_{2}(\frac{1}{5})^1(\frac{4}{5})^2$ + $^{3}C_{3}(\frac{1}{5})^0(\frac{4}{5})^3$ = $(\frac{1}{5})^3$ + $3(\frac{1}{5})^2(\frac{4}{5})$ + $3(\frac{1}{5})(\frac{4}{5})^2$ + $(\frac{4}{5})^3$ $= 1$ . This can of course be generalised to $\sum_{k=0}^{n}$$^{n}C_{k}{p}^k{q}^{n-k}$ where $n$ is the total number of trials $k$ the number of successes, $p$ the probability of success, $q$ that of failure. Now let's consider the binomial expansion of $(a + b)^3$ . Well, supposing we know nothing about binomial theory and do it by hand, our algebra nonetheless simplifies to $a^3 + 3a^2b + 3b^2a + b^3$ . Hmmm... this looks suspicously like our total probability forumla expanded above. It almost looks as though $a$ could be representing our successes, and $b$ our failures. So my reasoning is such: it just so happens that in the context of probability, the total probability of your outcomes add up to 1. If $\Omega = \left\{ a, b \right\}$ , then, by Kolmogorov's axioms, $a + b = 1$ . What we're effectively saying is that for any binomial expansion, we can treat them as 'probability outcomes' where $a + b \ne 1$ . Is this a reasonable proof?","I suppose I'll give a little context to this... I was at first really excited by the prospect that both Bernoulli and Taylor's versions of actually ammount to the same thing (where, when you expand Bernoulli's definition it simplifies to the Taylor series - unlike, say, trigonometric functions like which look a bit more unsatisfying). However, upon further reflection, to say that one identity 'simplifies' to the other seems almost circular given it presupposes binomial theorem. So, I decided to do a little scouting online, and found that binomial theorem could be proven using proof by induction. But once again, I felt unsatisfied as it feels as though you've just divined up some formula which works. How did you come up with it in the first place? Well, that's when I thought of probability theory. We use a binomial expression when we are looking for the number of combinations we have for arranging things. We can very intuitively derive this formula, however, as I don't want this question to be unecessarily large, I'm not going to go into detail about this here. What counts, is that we can figure out this formula from first principles - we're not getting it from nowhere. As I'm sure you already know, is key to figuring out binomial distributions. Once again I'm not going to explaim this, but an example probability calculation becomes for rolling 4 sixes in 10 total rolls. According to (Kolmogorov's) axioms of probability, the probability of all total outcomes is 1. Let's consider the context of total binomial outcomes of 3 trials (I pick this number for simple and illustrative purposes), where we designate the probablity of success, , and that of failure, , (where the sum of all different outcomes, here success and failure = 1). Well, we know that becuase we have 3 trials, logically, we'll have 4 possibilities: 0 successes, 1 success, 2 successess, or 3 success; we can write out our probability as: + + + = + + + . This can of course be generalised to where is the total number of trials the number of successes, the probability of success, that of failure. Now let's consider the binomial expansion of . Well, supposing we know nothing about binomial theory and do it by hand, our algebra nonetheless simplifies to . Hmmm... this looks suspicously like our total probability forumla expanded above. It almost looks as though could be representing our successes, and our failures. So my reasoning is such: it just so happens that in the context of probability, the total probability of your outcomes add up to 1. If , then, by Kolmogorov's axioms, . What we're effectively saying is that for any binomial expansion, we can treat them as 'probability outcomes' where . Is this a reasonable proof?","e^x \lim_{n\to\infty}(1+\frac{x}{n})^n \sum_{n=0}^{\infty}\frac{x^n}{n!} \sin(x) ^nC_{r} ^nC_{r} ^{10}C_{4}(\frac{1}{6})^4(\frac{1}{6})^{10-4} P(\Omega) \frac{1}{5} \frac{4}{5} ^{3}C_{0}(\frac{1}{5})^3(\frac{4}{5})^0 ^{3}C_{1}(\frac{1}{5})^2(\frac{4}{5})^1 ^{3}C_{2}(\frac{1}{5})^1(\frac{4}{5})^2 ^{3}C_{3}(\frac{1}{5})^0(\frac{4}{5})^3 (\frac{1}{5})^3 3(\frac{1}{5})^2(\frac{4}{5}) 3(\frac{1}{5})(\frac{4}{5})^2 (\frac{4}{5})^3 = 1 \sum_{k=0}^{n}^{n}C_{k}{p}^k{q}^{n-k} n k p q (a + b)^3 a^3 + 3a^2b + 3b^2a + b^3 a b \Omega = \left\{ a, b \right\} a + b = 1 a + b \ne 1","['probability', 'probability-theory', 'alternative-proof', 'binomial-theorem', 'binomial-distribution']"
73,A square appears randomly within a square of ten time its area. What is probability that the smaller square contains the larger square's center?,A square appears randomly within a square of ten time its area. What is probability that the smaller square contains the larger square's center?,,"The alignment relative to the larger square can be anywhere between 0° to 90° (0° or 90° being identical orientation to the larger square, 45° being all the way skewed), and the probability distribution of the alignment is based on percentage of total possibility given the constraint guaranteeing that it will fit within the larger square. The largest discrete probability, for an alignment of 0°=90°, should be simple enough to figure-out‡. The smallest discrete probability, for alignment of 45°, is a bit trickier but straightforward enough. Edit :The off-kilter version would be more likely to contain the center, since it has less possible places to exist and a larger proportion of them are the center. Intuitively this should correspond directly (though not necessarily uniformly) to what I am totally clueless about, which is: how to determine the probability  distribution for between 0° to 45°, ‡ 2. how this continuum corresponds to the probability of the original problem (e.g. {1/17?} for 0° up to {2/9?} for 45° back down to {1/17?} for 90°, along finite part of some sort of curve function presumably), and 3. how then to apply these equations formulated into the original problem to find the final probability that a square true-randomly generated wholly within a larger square with sides √(10)-times longer would surround (or contain exactly on an edge or corner) the center of the larger square. ‡ I haven't calculated the maximum or minimum ‘discrete’ probabilities (let alone any inbetween) yet. Those guesstimate values are placeholders. I am especially interested in the processes required to solve this, and appreciate any insight or clues.","The alignment relative to the larger square can be anywhere between 0° to 90° (0° or 90° being identical orientation to the larger square, 45° being all the way skewed), and the probability distribution of the alignment is based on percentage of total possibility given the constraint guaranteeing that it will fit within the larger square. The largest discrete probability, for an alignment of 0°=90°, should be simple enough to figure-out‡. The smallest discrete probability, for alignment of 45°, is a bit trickier but straightforward enough. Edit :The off-kilter version would be more likely to contain the center, since it has less possible places to exist and a larger proportion of them are the center. Intuitively this should correspond directly (though not necessarily uniformly) to what I am totally clueless about, which is: how to determine the probability  distribution for between 0° to 45°, ‡ 2. how this continuum corresponds to the probability of the original problem (e.g. {1/17?} for 0° up to {2/9?} for 45° back down to {1/17?} for 90°, along finite part of some sort of curve function presumably), and 3. how then to apply these equations formulated into the original problem to find the final probability that a square true-randomly generated wholly within a larger square with sides √(10)-times longer would surround (or contain exactly on an edge or corner) the center of the larger square. ‡ I haven't calculated the maximum or minimum ‘discrete’ probabilities (let alone any inbetween) yet. Those guesstimate values are placeholders. I am especially interested in the processes required to solve this, and appreciate any insight or clues.",,"['probability', 'geometry']"
74,Opposite of Coupon Collector / Birthday Problems?,Opposite of Coupon Collector / Birthday Problems?,,"There are $n$ combinatorial lists of a certain form.  I don't know what $n$ is. I can randomly generate lists of that form.  Let's say that after a million such trials I've gotten 960000 distinct lists. Let's also assume my random method has an equal likelihood of picking any of the $n$ items from the complete list. Based on that, is there a good guess for $n$ ? The coupon collector problem , birthday problem and german tank problem are related. Is there a name for the problem? Here's another version:  I randomly sample 1000 integers from 1 to $n$ and get 800 distinct values. What is a good guess for $n$ ?","There are combinatorial lists of a certain form.  I don't know what is. I can randomly generate lists of that form.  Let's say that after a million such trials I've gotten 960000 distinct lists. Let's also assume my random method has an equal likelihood of picking any of the items from the complete list. Based on that, is there a good guess for ? The coupon collector problem , birthday problem and german tank problem are related. Is there a name for the problem? Here's another version:  I randomly sample 1000 integers from 1 to and get 800 distinct values. What is a good guess for ?",n n n n n n,"['probability', 'combinatorics', 'statistics']"
75,Probability of getting 6 heads in a row from 200 flips and intuition about this high value,Probability of getting 6 heads in a row from 200 flips and intuition about this high value,,"A few days ago I had an argument with a friend about this question : What is the probability of getting 6 heads in a row from 200 flips ? I argued it is high probability (significantly bigger than a half) while he argued it is low probability. When I tried to give exact formula I failed, so we checked the web were the answer was about 84%, yet he is still not convinced so from this I have two questions: What is the exact formula for $k$ Heads in a row (consecutive) out of $n$ coin flips? (Not a mathematical) How to convince my friend that 6 in a row have high probability? Meaning what is the intuition behind the question ?","A few days ago I had an argument with a friend about this question : What is the probability of getting 6 heads in a row from 200 flips ? I argued it is high probability (significantly bigger than a half) while he argued it is low probability. When I tried to give exact formula I failed, so we checked the web were the answer was about 84%, yet he is still not convinced so from this I have two questions: What is the exact formula for Heads in a row (consecutive) out of coin flips? (Not a mathematical) How to convince my friend that 6 in a row have high probability? Meaning what is the intuition behind the question ?",k n,"['probability', 'intuition']"
76,Sum of 3 uniform random variables is a constant,Sum of 3 uniform random variables is a constant,,"Give a construction of three random variables $X,Y,Z$ that are each   uniform on $(0,1)$ but $X+Y+Z$ is a constant. Is the following argument correct? We first consider every number in $(0,1)$ in ternary and for the $n$-th digit, randomly assign $0,1,2$ to $X, Y, Z$, such that all $n$-th digits are different.  This means each random variable is uniformly distributed since each of it's digits has a 1/3 chance for each $ \{0,1,2 \}$ To rigorize, you can show that $P(X\leq a) = a$ where $a = k/3^n$ and $n,k$ are positive integers. So this extends to $P(X\leq r) = r, r\in \mathbb{Q}\cap (0,1)$ because we can find a decreasing sequence $a_j = \frac{k_j}{3^{n_j}}$ s.t $a_j\downarrow r$.  Do I need to justify this step more?  And then from here we extend it to reals in the same way.  We use decreasing sequences because the CDF is right continuous.  This shows that $X$ is uniform and similarly $Y$ and $Z$ are uniform on $(0,1)$ They add up to a constant since the digit-wise sum is just $0+1+2$ for each place.","Give a construction of three random variables $X,Y,Z$ that are each   uniform on $(0,1)$ but $X+Y+Z$ is a constant. Is the following argument correct? We first consider every number in $(0,1)$ in ternary and for the $n$-th digit, randomly assign $0,1,2$ to $X, Y, Z$, such that all $n$-th digits are different.  This means each random variable is uniformly distributed since each of it's digits has a 1/3 chance for each $ \{0,1,2 \}$ To rigorize, you can show that $P(X\leq a) = a$ where $a = k/3^n$ and $n,k$ are positive integers. So this extends to $P(X\leq r) = r, r\in \mathbb{Q}\cap (0,1)$ because we can find a decreasing sequence $a_j = \frac{k_j}{3^{n_j}}$ s.t $a_j\downarrow r$.  Do I need to justify this step more?  And then from here we extend it to reals in the same way.  We use decreasing sequences because the CDF is right continuous.  This shows that $X$ is uniform and similarly $Y$ and $Z$ are uniform on $(0,1)$ They add up to a constant since the digit-wise sum is just $0+1+2$ for each place.",,"['probability', 'probability-theory', 'probability-distributions', 'uniform-distribution']"
77,The hot hand and coin flips after a sequence of heads,The hot hand and coin flips after a sequence of heads,,"ESPN recently posted a story demonstrating that the ""hot hand"" concept is, in fact, real. Part of the justification is this example based on coin flips from a paper by Adam Sanjurjo and Joshua B. Miller : And now [Joshua] Miller brings it back to coin flips and the subtle selection bias of hit streaks. The broken-clock example, Miller says, is an extreme illustration of what's happening in a long line of coin flips. Let's say that in analyzing the results of 100 coin flips you see a string of three heads (HHH_) and ""_"" is, say, Flip 42 in the sequence -- which was selected because it was preceded by HHH. What is the _ in the sequence? Of course, you don't know which kind of sequence you are in. it could be HHHT or it could be HHHH. You think it's a 50-50 chance that Flip 42 is H (or T). But here's where it changes, and it is sneaky. In sequence HHHH, you could have selected Flip 43 because it continues a run of three heads, and you haven't excluded Flip 44 or 45, like you would have in sequence HHHT (it ends the run of heads). The excluded flips in the HHHT world mean it is more likely that Flip 42 will turn up T rather than H, given the condition that the flip was selected because it was preceded by three heads in a row. The choice has been restricted. To tie it back to the big ol' mansion, the broken clock excludes more times that are different from the one you are seeing, and the kind of sequence with HHHT excludes more flips that are different from the one you selected. I am struggling to follow this explanation and the significant of the restricted choice. What does excluding flips 44 or 45 mean? Why is flip 42 more likely to be T rather than H?","ESPN recently posted a story demonstrating that the ""hot hand"" concept is, in fact, real. Part of the justification is this example based on coin flips from a paper by Adam Sanjurjo and Joshua B. Miller : And now [Joshua] Miller brings it back to coin flips and the subtle selection bias of hit streaks. The broken-clock example, Miller says, is an extreme illustration of what's happening in a long line of coin flips. Let's say that in analyzing the results of 100 coin flips you see a string of three heads (HHH_) and ""_"" is, say, Flip 42 in the sequence -- which was selected because it was preceded by HHH. What is the _ in the sequence? Of course, you don't know which kind of sequence you are in. it could be HHHT or it could be HHHH. You think it's a 50-50 chance that Flip 42 is H (or T). But here's where it changes, and it is sneaky. In sequence HHHH, you could have selected Flip 43 because it continues a run of three heads, and you haven't excluded Flip 44 or 45, like you would have in sequence HHHT (it ends the run of heads). The excluded flips in the HHHT world mean it is more likely that Flip 42 will turn up T rather than H, given the condition that the flip was selected because it was preceded by three heads in a row. The choice has been restricted. To tie it back to the big ol' mansion, the broken clock excludes more times that are different from the one you are seeing, and the kind of sequence with HHHT excludes more flips that are different from the one you selected. I am struggling to follow this explanation and the significant of the restricted choice. What does excluding flips 44 or 45 mean? Why is flip 42 more likely to be T rather than H?",,['probability']
78,Extending a distribution over samples to a distribution over functions,Extending a distribution over samples to a distribution over functions,,"A gaussian process is a distribution over a function space, which can be parametrized as \begin{align} 		x(\cdot) &\sim \mathrm{GP}(m(\cdot), K(\cdot,\cdot))\,. 	\end{align} For simplicity, let's choose $x\colon \mathbb{R}\to\mathbb{R}$. We can write the probability density of a finite set of samples of $x$ as \begin{align} 		p(\{x(l) : l \in L\}; m, K) 			&\propto \exp{\left[ 				-\frac{1}{2} 				\sum_{i\in L} 				\sum_{j\in L} 					\left(x(i) - m(i)\right) 					{K(i,j)}^{-1} 					\left(x(j) - m(j)\right) 			\right]}\,. 	\end{align} (Apologies for any notational misuse here). Can this be extended to the probability density for the infinite set $x(\cdot)$? Is it valid to write \begin{align} 		p(x(\cdot); m, K) 			&\propto \exp{\left[ 				-\frac{1}{2} 				\sum_{i\in \mathbb{R}} 				\sum_{j\in \mathbb{R}} 					\left(x(i) - m(i)\right) 					{K(i,j)}^{-1} 					\left(x(j) - m(j)\right) 			\right]}\,. 	\end{align} It feels incorrect to me to sum over the reals rather than integrate, but I have little intuition in this area.","A gaussian process is a distribution over a function space, which can be parametrized as \begin{align} 		x(\cdot) &\sim \mathrm{GP}(m(\cdot), K(\cdot,\cdot))\,. 	\end{align} For simplicity, let's choose $x\colon \mathbb{R}\to\mathbb{R}$. We can write the probability density of a finite set of samples of $x$ as \begin{align} 		p(\{x(l) : l \in L\}; m, K) 			&\propto \exp{\left[ 				-\frac{1}{2} 				\sum_{i\in L} 				\sum_{j\in L} 					\left(x(i) - m(i)\right) 					{K(i,j)}^{-1} 					\left(x(j) - m(j)\right) 			\right]}\,. 	\end{align} (Apologies for any notational misuse here). Can this be extended to the probability density for the infinite set $x(\cdot)$? Is it valid to write \begin{align} 		p(x(\cdot); m, K) 			&\propto \exp{\left[ 				-\frac{1}{2} 				\sum_{i\in \mathbb{R}} 				\sum_{j\in \mathbb{R}} 					\left(x(i) - m(i)\right) 					{K(i,j)}^{-1} 					\left(x(j) - m(j)\right) 			\right]}\,. 	\end{align} It feels incorrect to me to sum over the reals rather than integrate, but I have little intuition in this area.",,"['probability', 'functional-analysis', 'notation']"
79,conditional expected value of a brownian motion,conditional expected value of a brownian motion,,"Professor gave us this homework: given $B_t$ a standard brownian motion and $0<s<t$ compute $\mathbb{E}[B_t|B_s]$ $\mathbb{E}[B_s|B_t]$ $\mathbb{E}[B_{(t+s)/2}|B_s,B_t]$ The first one is easy: $\mathbb{E}[B_t|B_s]=\mathbb{E}[B_t-B_s+B_s|B_s]=B_s$ because of independent increments. The second one was a little more difficult: I define ${W_t=tB_{1/t}}$ so that $0<\frac 1 t<\frac 1 s$ and then $$\mathbb{E}[B_s|B_t]=s\mathbb{E}[W_{\frac 1 s}|tW_{\frac 1 t}]=s\mathbb{E}[W_{\frac 1 s}|W_{\frac 1 t}]$$ Then using the previous exercise $$s\mathbb{E}[W_{\frac 1 s}|W_{\frac 1 t}]=s\mathbb{E}[W_{\frac 1 s}-W_{\frac 1 t}+W_{\frac 1 t}|W_{\frac 1 t}]=sW_{\frac 1 t}=\frac s t B_t$$ I don't know if I'm right on this one. For the last one I don't know where to start: have you any suggestions?","Professor gave us this homework: given $B_t$ a standard brownian motion and $0<s<t$ compute $\mathbb{E}[B_t|B_s]$ $\mathbb{E}[B_s|B_t]$ $\mathbb{E}[B_{(t+s)/2}|B_s,B_t]$ The first one is easy: $\mathbb{E}[B_t|B_s]=\mathbb{E}[B_t-B_s+B_s|B_s]=B_s$ because of independent increments. The second one was a little more difficult: I define ${W_t=tB_{1/t}}$ so that $0<\frac 1 t<\frac 1 s$ and then $$\mathbb{E}[B_s|B_t]=s\mathbb{E}[W_{\frac 1 s}|tW_{\frac 1 t}]=s\mathbb{E}[W_{\frac 1 s}|W_{\frac 1 t}]$$ Then using the previous exercise $$s\mathbb{E}[W_{\frac 1 s}|W_{\frac 1 t}]=s\mathbb{E}[W_{\frac 1 s}-W_{\frac 1 t}+W_{\frac 1 t}|W_{\frac 1 t}]=sW_{\frac 1 t}=\frac s t B_t$$ I don't know if I'm right on this one. For the last one I don't know where to start: have you any suggestions?",,"['probability', 'stochastic-processes', 'brownian-motion']"
80,"What does it mean for a probability model to be ""well-specified"" or ""misspecified""?","What does it mean for a probability model to be ""well-specified"" or ""misspecified""?",,"I read in several articles that a model $\{p_\theta , \theta \in \Theta\}$ is well-specified if there exists a $\theta^* \in \Theta$ such that $p_{\theta^*} = p^*$. Similarly, a model $\{p_\theta , \theta \in \Theta\}$ is misspecified if there does not exists a $\theta^* \in \Theta$ such that $p_{\theta^*} = p^*$. Here, the definition of $p^*$ is that it is the true ""data-generating distribution"". I can understand the terminology but what is the underlying logic here? I feel that I am missing the deeper story here. What is an example of a misspecified model? thanks!","I read in several articles that a model $\{p_\theta , \theta \in \Theta\}$ is well-specified if there exists a $\theta^* \in \Theta$ such that $p_{\theta^*} = p^*$. Similarly, a model $\{p_\theta , \theta \in \Theta\}$ is misspecified if there does not exists a $\theta^* \in \Theta$ such that $p_{\theta^*} = p^*$. Here, the definition of $p^*$ is that it is the true ""data-generating distribution"". I can understand the terminology but what is the underlying logic here? I feel that I am missing the deeper story here. What is an example of a misspecified model? thanks!",,"['probability', 'probability-theory']"
81,How many ways can 8 teachers be distributed among $4 $ schools?,How many ways can 8 teachers be distributed among  schools?,4 ,"There are several ways that the teachers can be divided amongst $4$ schools, namely here are the possible choices I came up with: $1) 1 1 1 5$ $2) 1 1 2 4$ $3) 1 1 3 3$ $4) 1 2 2 3$ $5) 2 2 2 2$ now given the fact that say $2213$ is the same as $1 2 2 3$ it was omitted. With out repeats I believe these 5 are the only possibilities. 1) ${8 \choose 5} \times {3 \choose 1} \times {2 \choose 1} \times {1 \choose 1}$: $\frac{8!}{5!3!} \times \frac{3!}{1!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $56 \times 3 \times 2 \times 1 = 336$ 2) ${8 \choose 4} \times {4 \choose 2} \times {2 \choose 1} \times {1 \choose 1}$: $\frac{8!}{4!4!} \times \frac{4!}{2!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $70 \times 6 \times 2 \times 1= 840$ 3) ${8 \choose 3} \times {5 \choose 3} \times {2 \choose 1} \times {1 \choose 1}$ $\frac{8!}{3!5!} \times \frac{5!}{3!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $56 \times 10 \times \times 2 = 1,120$ 4) ${8 \choose 3} \times {5 \choose 2} \times {3 \choose 2} \times {1 \choose 1}$ $\frac{8!}{3!5!} \times \frac{5!}{2!3!} \times \frac{3!}{2!1!} \times \frac{1!}{1!0!}$ Which comes out to: If 8 new teachers are to be divided amongst 4 new schools how many divisions are possible? $56 \times 10 \times 3 \times 1= 1,680$ 5) ${8 \choose 2} \times {6 \choose 2} \times {4 \choose 2} \times {2 \choose 2}$ $\frac{8!}{2!6!} \times \frac{6!}{2!4!} \times \frac{4!}{2!2!} \times \frac{2!}{2!0!}$ Which comes out to: $28 \times 15 \times 6 \times 1 = 2,520$ What am I missing?","There are several ways that the teachers can be divided amongst $4$ schools, namely here are the possible choices I came up with: $1) 1 1 1 5$ $2) 1 1 2 4$ $3) 1 1 3 3$ $4) 1 2 2 3$ $5) 2 2 2 2$ now given the fact that say $2213$ is the same as $1 2 2 3$ it was omitted. With out repeats I believe these 5 are the only possibilities. 1) ${8 \choose 5} \times {3 \choose 1} \times {2 \choose 1} \times {1 \choose 1}$: $\frac{8!}{5!3!} \times \frac{3!}{1!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $56 \times 3 \times 2 \times 1 = 336$ 2) ${8 \choose 4} \times {4 \choose 2} \times {2 \choose 1} \times {1 \choose 1}$: $\frac{8!}{4!4!} \times \frac{4!}{2!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $70 \times 6 \times 2 \times 1= 840$ 3) ${8 \choose 3} \times {5 \choose 3} \times {2 \choose 1} \times {1 \choose 1}$ $\frac{8!}{3!5!} \times \frac{5!}{3!2!} \times \frac{2!}{1!1!} \times 1$ Which comes out to $56 \times 10 \times \times 2 = 1,120$ 4) ${8 \choose 3} \times {5 \choose 2} \times {3 \choose 2} \times {1 \choose 1}$ $\frac{8!}{3!5!} \times \frac{5!}{2!3!} \times \frac{3!}{2!1!} \times \frac{1!}{1!0!}$ Which comes out to: If 8 new teachers are to be divided amongst 4 new schools how many divisions are possible? $56 \times 10 \times 3 \times 1= 1,680$ 5) ${8 \choose 2} \times {6 \choose 2} \times {4 \choose 2} \times {2 \choose 2}$ $\frac{8!}{2!6!} \times \frac{6!}{2!4!} \times \frac{4!}{2!2!} \times \frac{2!}{2!0!}$ Which comes out to: $28 \times 15 \times 6 \times 1 = 2,520$ What am I missing?",,"['probability', 'combinatorics']"
82,Expectation and Variance of Gaussian going through Rectified Linear or Sigmoid function,Expectation and Variance of Gaussian going through Rectified Linear or Sigmoid function,,"When you apply a Gaussian probability densityfunction to Rectified Linear/Sigmoid function,  you will get a rectified(*)/distorted Gaussian function. (*)rectified Gaussian function is a mixture of delta and truncated gaussian as shown belown https://en.wikipedia.org/wiki/Rectified_Gaussian_distribution I am wondering, what is the Expectation and Variance of this rectified/distorted Gaussian? The Expectation of distorted Gaussian from Sigmoid is shown below. Expected value of applying the sigmoid function to a normal distribution How about Variance? or Expectation and Variance of rectified Gaussian from Rectified Linear? Thank you.","When you apply a Gaussian probability densityfunction to Rectified Linear/Sigmoid function,  you will get a rectified(*)/distorted Gaussian function. (*)rectified Gaussian function is a mixture of delta and truncated gaussian as shown belown https://en.wikipedia.org/wiki/Rectified_Gaussian_distribution I am wondering, what is the Expectation and Variance of this rectified/distorted Gaussian? The Expectation of distorted Gaussian from Sigmoid is shown below. Expected value of applying the sigmoid function to a normal distribution How about Variance? or Expectation and Variance of rectified Gaussian from Rectified Linear? Thank you.",,"['probability', 'integration']"
83,Approximating the variance of the integral of a white noise Gaussian process,Approximating the variance of the integral of a white noise Gaussian process,,"Let $X(t)$ be a stationary Gaussian process with mean $\mu$, variance $\sigma^2$ and stationary correlation function $\rho(t_1-t_2)$. If $X(t)$ is a white noise process the correlation function is given by the Dirac delta function $\rho(t_1-t_2) = \delta(t_1-t_2)$. The integral of this process is given by: $$I = \int_0^L X(t) \, dt$$ According to this CrossValidated post the variance of $I$ is given by: $$\text{Var}[I] = L\sigma^2$$ However this does not agree with the results I obtained through simulation. The approach is to discretise the white noise Gaussian process into $N$ independent normal variables. The integral can then be approximated through: $$ I = \int_0^L X(t) \approx \frac{L}{N}\sum_{i=1}^NX_i$$ Where $X_i$ are indepedent random variables $X_i \sim \mathcal{N}(\mu,\sigma^2)$. In simulation I find that as $N$ grows large then $\text{Var}[I] \rightarrow 0$. Why does it not approach $L\sigma^2$? What is the problem with my approximation?","Let $X(t)$ be a stationary Gaussian process with mean $\mu$, variance $\sigma^2$ and stationary correlation function $\rho(t_1-t_2)$. If $X(t)$ is a white noise process the correlation function is given by the Dirac delta function $\rho(t_1-t_2) = \delta(t_1-t_2)$. The integral of this process is given by: $$I = \int_0^L X(t) \, dt$$ According to this CrossValidated post the variance of $I$ is given by: $$\text{Var}[I] = L\sigma^2$$ However this does not agree with the results I obtained through simulation. The approach is to discretise the white noise Gaussian process into $N$ independent normal variables. The integral can then be approximated through: $$ I = \int_0^L X(t) \approx \frac{L}{N}\sum_{i=1}^NX_i$$ Where $X_i$ are indepedent random variables $X_i \sim \mathcal{N}(\mu,\sigma^2)$. In simulation I find that as $N$ grows large then $\text{Var}[I] \rightarrow 0$. Why does it not approach $L\sigma^2$? What is the problem with my approximation?",,"['probability', 'integration', 'stochastic-processes', 'random-variables']"
84,Is there an alternative intuition for solving the probability of having one ace card in every bridge player's hand?,Is there an alternative intuition for solving the probability of having one ace card in every bridge player's hand?,,"I am trying to get to know probability a little better since it's a weak point for me and I was wondering what other ways there were to intuitively think about the problem of finding the probability that 4 bridge players each have exactly one ace after being dealt a deck of 52 cards. My solution started with that there are $4!$ ways of distributing the aces initially, and then subsequently there are $48 \choose 12$ ways of distributing the rest of the first hand, $36 \choose 12$ ways of distributing the rest of the second hand, and $24 \choose 12$ ways of distributing the third hand, and one way to distribute the last hand. Thus there are $4! *$ $48 \choose 12$ $*$ $36 \choose 12$ $*$ $24 \choose 12$ ways of the players having exactly one ace. The total sample space, however, is counted for by first giving the first player his hand ($52 \choose 13$), the second player has hand from the remaining deck, ($39 \choose 13$), etc.; so the sample space is $ 52\choose 13$ $*$ $39 \choose 13$ $*$ $26 \choose 13$. The final answer after simplifying is that the probability that each player receives exactly one ace is $\frac{4!48!13^{3}}{52!}$ I think this is correct (correct me if my solution is wrong), but what are the other ways of thinking of this problem?","I am trying to get to know probability a little better since it's a weak point for me and I was wondering what other ways there were to intuitively think about the problem of finding the probability that 4 bridge players each have exactly one ace after being dealt a deck of 52 cards. My solution started with that there are $4!$ ways of distributing the aces initially, and then subsequently there are $48 \choose 12$ ways of distributing the rest of the first hand, $36 \choose 12$ ways of distributing the rest of the second hand, and $24 \choose 12$ ways of distributing the third hand, and one way to distribute the last hand. Thus there are $4! *$ $48 \choose 12$ $*$ $36 \choose 12$ $*$ $24 \choose 12$ ways of the players having exactly one ace. The total sample space, however, is counted for by first giving the first player his hand ($52 \choose 13$), the second player has hand from the remaining deck, ($39 \choose 13$), etc.; so the sample space is $ 52\choose 13$ $*$ $39 \choose 13$ $*$ $26 \choose 13$. The final answer after simplifying is that the probability that each player receives exactly one ace is $\frac{4!48!13^{3}}{52!}$ I think this is correct (correct me if my solution is wrong), but what are the other ways of thinking of this problem?",,['probability']
85,How to understand the definition of weak convergence of stochastic processes,How to understand the definition of weak convergence of stochastic processes,,"I have some problems with the definition of $\textit{weak convergence of stochastic processes}$. To ask my question, we start with two well-known definitions corresponding to measures and random variables. $\textbf{Definition 1 (weak convergence of measures).}$ Suppose $\left(\mu_n\right)_{n =1}^{\infty}$ is a sequence of probability measures. Then we say that $\mu_n$ converges weakly (or in distribution) to a probability measure $\mu$ and write $\mu_n \xrightarrow{\mathcal{D}} \mu$, if   $$  \forall \, \varphi \in \mathcal{C}_b(\mathbb{R}) \colon \int_{\Omega} \varphi \, \text{d} \mu_n \xrightarrow{n \to \infty} \int_{\Omega}\varphi \, \text{d} \mu, $$   where $\mathcal{C}_b(\mathbb{R})$ denotes the set of continuous and bounded functions. $\textbf{Definition 2 (weak convergence of random variables).}$ Suppose $\left( \Omega, \mathcal{F}, \mathbb{P}\right)$ is a probability space and $\left(f_n\right)_{n =1}^{\infty}$ is a sequence of random variables. Then we say that $f_n$ converges weakly (or in distribution) to a random variable $f$ and write $f_n \xrightarrow{\mathcal{D}} f$, if   $$  \forall \, \varphi \in \mathcal{C}_b(\mathbb{R}) \colon \ \mathbb{E} \varphi(f_n)\xrightarrow{n \to \infty} \mathbb{E} \varphi(f) \Longleftrightarrow \int_{\Omega} \varphi(f_n(\omega)) \, \text{d} \mathbb{P}(\omega) \xrightarrow{n \to \infty} \int_{\Omega} \varphi(f(\omega)) \, \text{d} \mathbb{P}(\omega) \\ \Longleftrightarrow \int_{\Omega} \varphi \, \text{d} \mathbb{P}_{f_n} \xrightarrow{n \to \infty} \int_{\Omega}\varphi \, \text{d} \mathbb{P}_f.$$ These two definitions were clear to me. The following definition is the one I am asking about. $\textbf{Definition 3 (weak convergence of stochastic processes).}$ Suppose $f$ and $\left(f_n\right)_{n \in \mathbb{N}}$ are random variables with values in $\mathcal{C}([0,\infty))$. Then we say that the stochastic processes $\left(f_n\right)_{n \in \mathbb{N}}$ converge to the stochastic process $f$, if the corresponding laws converge weakly in the topological space $\mathbb{S}$ consiting of $\mathcal{C}([0,\infty))$ equipped with the topology of uniform convergence on comapct subsets of $\mathcal{C}([0,\infty))$. That is, if $\varphi(f_n) \xrightarrow{\mathcal{D}} \varphi(f)$ whenever $\varphi \colon \mathcal{C}([0,\infty)) \rightarrow \mathbb{R}$ Borel measurable. Now my question is, how can I understand Definition $3$ in the sense of Definition $2$? Can I just replace $\varphi \in \mathcal{C}_b(\mathbb{R})$ by $\varphi \in \mathcal{C}([0,\infty))$? What is meant with ""equipped with the topology of uniform convergence on comapct subsets of $\mathcal{C}([0,\infty))$""?","I have some problems with the definition of $\textit{weak convergence of stochastic processes}$. To ask my question, we start with two well-known definitions corresponding to measures and random variables. $\textbf{Definition 1 (weak convergence of measures).}$ Suppose $\left(\mu_n\right)_{n =1}^{\infty}$ is a sequence of probability measures. Then we say that $\mu_n$ converges weakly (or in distribution) to a probability measure $\mu$ and write $\mu_n \xrightarrow{\mathcal{D}} \mu$, if   $$  \forall \, \varphi \in \mathcal{C}_b(\mathbb{R}) \colon \int_{\Omega} \varphi \, \text{d} \mu_n \xrightarrow{n \to \infty} \int_{\Omega}\varphi \, \text{d} \mu, $$   where $\mathcal{C}_b(\mathbb{R})$ denotes the set of continuous and bounded functions. $\textbf{Definition 2 (weak convergence of random variables).}$ Suppose $\left( \Omega, \mathcal{F}, \mathbb{P}\right)$ is a probability space and $\left(f_n\right)_{n =1}^{\infty}$ is a sequence of random variables. Then we say that $f_n$ converges weakly (or in distribution) to a random variable $f$ and write $f_n \xrightarrow{\mathcal{D}} f$, if   $$  \forall \, \varphi \in \mathcal{C}_b(\mathbb{R}) \colon \ \mathbb{E} \varphi(f_n)\xrightarrow{n \to \infty} \mathbb{E} \varphi(f) \Longleftrightarrow \int_{\Omega} \varphi(f_n(\omega)) \, \text{d} \mathbb{P}(\omega) \xrightarrow{n \to \infty} \int_{\Omega} \varphi(f(\omega)) \, \text{d} \mathbb{P}(\omega) \\ \Longleftrightarrow \int_{\Omega} \varphi \, \text{d} \mathbb{P}_{f_n} \xrightarrow{n \to \infty} \int_{\Omega}\varphi \, \text{d} \mathbb{P}_f.$$ These two definitions were clear to me. The following definition is the one I am asking about. $\textbf{Definition 3 (weak convergence of stochastic processes).}$ Suppose $f$ and $\left(f_n\right)_{n \in \mathbb{N}}$ are random variables with values in $\mathcal{C}([0,\infty))$. Then we say that the stochastic processes $\left(f_n\right)_{n \in \mathbb{N}}$ converge to the stochastic process $f$, if the corresponding laws converge weakly in the topological space $\mathbb{S}$ consiting of $\mathcal{C}([0,\infty))$ equipped with the topology of uniform convergence on comapct subsets of $\mathcal{C}([0,\infty))$. That is, if $\varphi(f_n) \xrightarrow{\mathcal{D}} \varphi(f)$ whenever $\varphi \colon \mathcal{C}([0,\infty)) \rightarrow \mathbb{R}$ Borel measurable. Now my question is, how can I understand Definition $3$ in the sense of Definition $2$? Can I just replace $\varphi \in \mathcal{C}_b(\mathbb{R})$ by $\varphi \in \mathcal{C}([0,\infty))$? What is meant with ""equipped with the topology of uniform convergence on comapct subsets of $\mathcal{C}([0,\infty))$""?",,"['probability', 'stochastic-processes', 'stochastic-calculus', 'weak-convergence', 'stochastic-analysis']"
86,measure-theoretic definition of expectation,measure-theoretic definition of expectation,,"Consider a random variable $X \colon\Omega \rightarrow \mathbb{R}$ for a probability space $(\Omega, \mathcal{F}, P)$. We had the following definition for the expectation: $$\mathbb{E}[X]= \int_{\Omega} X(\omega) d P(\omega). \quad (1)$$ For the discrete case we would probably write $$\mathbb{E}[X]= \sum_{ \omega \in \Omega} X(\omega) P(\omega). \quad (2)$$ Now as non-mathematician (i.e. not having much knowledge about integrals and measure theory), I am  wondering why converting the sum in (2) to an integral does not result in $$\mathbb{E}[X]=\int_{\Omega} X(\omega) P(\omega) d \omega\quad (3)$$ instead of (1). (3) is what I would expect, because instead of the sum we just integrate, hence informally ""replace sum in (2) by integral sign and add a $d \omega$ at the end"". What is the difference between (1) and (3)? Is it valid to write (3)? Is it just ""notation"" for measures $P$ or is there a reason for this? Thank you very much and please have patient with a non-mathematician that never had a lecture in mass theory or integrals.","Consider a random variable $X \colon\Omega \rightarrow \mathbb{R}$ for a probability space $(\Omega, \mathcal{F}, P)$. We had the following definition for the expectation: $$\mathbb{E}[X]= \int_{\Omega} X(\omega) d P(\omega). \quad (1)$$ For the discrete case we would probably write $$\mathbb{E}[X]= \sum_{ \omega \in \Omega} X(\omega) P(\omega). \quad (2)$$ Now as non-mathematician (i.e. not having much knowledge about integrals and measure theory), I am  wondering why converting the sum in (2) to an integral does not result in $$\mathbb{E}[X]=\int_{\Omega} X(\omega) P(\omega) d \omega\quad (3)$$ instead of (1). (3) is what I would expect, because instead of the sum we just integrate, hence informally ""replace sum in (2) by integral sign and add a $d \omega$ at the end"". What is the difference between (1) and (3)? Is it valid to write (3)? Is it just ""notation"" for measures $P$ or is there a reason for this? Thank you very much and please have patient with a non-mathematician that never had a lecture in mass theory or integrals.",,"['probability', 'integration', 'measure-theory', 'probability-theory', 'expectation']"
87,Blackjack Probability,Blackjack Probability,,"Suppose that you are playing blackjack against the dealer. In a freshly shuffled deck (standard $52$ cards), what is the probability that neither of you are dealt a blackjack. Blackjack being $2$ cards adding to $21$ i.e. $Ace + 10,J,Q,or K$ (or vice versa as order does not matter). The farthest I've really come is that the odds of the first player getting dealt a blackjack is $128\over 2652$. First case: Odds of getting an Ace are $4\over52$, odds of the next being 10,J,Q,or K are $16\over51$. Other case: Odds of getting 10,J,Q,or K are $16\over52$ and Ace $4\over 51$ so ${((4*16)*2)\over (52*51)} == {128\over 2652}$ Not sure where to go from here...","Suppose that you are playing blackjack against the dealer. In a freshly shuffled deck (standard $52$ cards), what is the probability that neither of you are dealt a blackjack. Blackjack being $2$ cards adding to $21$ i.e. $Ace + 10,J,Q,or K$ (or vice versa as order does not matter). The farthest I've really come is that the odds of the first player getting dealt a blackjack is $128\over 2652$. First case: Odds of getting an Ace are $4\over52$, odds of the next being 10,J,Q,or K are $16\over51$. Other case: Odds of getting 10,J,Q,or K are $16\over52$ and Ace $4\over 51$ so ${((4*16)*2)\over (52*51)} == {128\over 2652}$ Not sure where to go from here...",,"['probability', 'statistics']"
88,Why would a uniform prior distribution give a different result than a purely frequentist approach?,Why would a uniform prior distribution give a different result than a purely frequentist approach?,,"I would expect a uniform prior to be a good example of an uninformed prior and get the same result as the frequentist approach. However, this is not the case. As an example, let's look the classical Bernoulli problem - you flip coins and $s$ are heads, $f$ are tails. You want to predict $p$, the probability of heads on any given coin flip. Frequentist Approach The frequentist approach is to say that $p$ is simply $s/(s + f)$. In this approach, we assume nothing about the distribution of $p$ and we're simply finding the maximium likelihood estimate. This makes sense to me. Bayesian approach Now, let's say you do the Bayesian approach and you say: $$ P(p|data) = \dfrac{P(data | p) \cdot P(p)} {P(data)} $$ According to wikipedia , if you make your prior the beta distribution, you get: $$ P(p|data) = \dfrac{p^{s+\alpha-1}(1-p)^{f+\beta-1}}{B(s+\alpha, f+\beta)} $$ Now let's say we want to find the expected value of p: $$ E[p|data] = \int_{0}^{1} P(p|data) \cdot p \cdot dp $$ $$ E[p|data] = \int_{0}^{1} \dfrac{p^{s+\alpha-1}(1-p)^{f+\beta-1}}{B(s+\alpha, f+\beta)} \cdot p \cdot dp $$ $$ E[p|data] = \int_{0}^{1} \dfrac{p^{s+\alpha}(1-p)^{f+\beta-1}}{B(s+\alpha, f+\beta)} \cdot dp $$ $$ E[p|data] = \dfrac{B(s+\alpha + 1, f+\beta)}{B(s+\alpha, f+\beta)} $$ Great! We can continuing simplifying this since we know a property of the beta function: $$ B(s + 1, f) = B(s, f) \cdot \dfrac{s} {s + f} $$ Which implies: $$ E[p|data] = \dfrac{B(s+\alpha, f+\beta)}{B(s+\alpha, f+\beta)} \cdot \dfrac{s+\alpha}{f+\beta} $$ $$ E[p|data] = \dfrac{s+\alpha}{s+\alpha + f+\beta} $$ Makes sense so far! Now, let's say we want to choose a really ""objective"" prior to emulate the frequentist approach, like a uniform distribution. This is equivalent to Beta(1,1). In this case, we would get: $$ E[p|data;\alpha=1,\beta=1] = \dfrac{s+1}{s + f + 2} $$ This hurts my brain. Even though we're being as objective as we can (""p is equally likely to be anything""), we're getting a different result than the frequentist approach. On the flip side, if we do the improper prior Beta(0,0), we get the same result as the frequentist approach: $$ E[p|data;\alpha=0,\beta=0] = \dfrac{s}{s + f} $$ What makes Beta(0,0) more similar to the frequentist approach than Beta(1,1)? What assumption are we making in Beta(1,1)? How is Beta(0,0) ""less informed""?","I would expect a uniform prior to be a good example of an uninformed prior and get the same result as the frequentist approach. However, this is not the case. As an example, let's look the classical Bernoulli problem - you flip coins and $s$ are heads, $f$ are tails. You want to predict $p$, the probability of heads on any given coin flip. Frequentist Approach The frequentist approach is to say that $p$ is simply $s/(s + f)$. In this approach, we assume nothing about the distribution of $p$ and we're simply finding the maximium likelihood estimate. This makes sense to me. Bayesian approach Now, let's say you do the Bayesian approach and you say: $$ P(p|data) = \dfrac{P(data | p) \cdot P(p)} {P(data)} $$ According to wikipedia , if you make your prior the beta distribution, you get: $$ P(p|data) = \dfrac{p^{s+\alpha-1}(1-p)^{f+\beta-1}}{B(s+\alpha, f+\beta)} $$ Now let's say we want to find the expected value of p: $$ E[p|data] = \int_{0}^{1} P(p|data) \cdot p \cdot dp $$ $$ E[p|data] = \int_{0}^{1} \dfrac{p^{s+\alpha-1}(1-p)^{f+\beta-1}}{B(s+\alpha, f+\beta)} \cdot p \cdot dp $$ $$ E[p|data] = \int_{0}^{1} \dfrac{p^{s+\alpha}(1-p)^{f+\beta-1}}{B(s+\alpha, f+\beta)} \cdot dp $$ $$ E[p|data] = \dfrac{B(s+\alpha + 1, f+\beta)}{B(s+\alpha, f+\beta)} $$ Great! We can continuing simplifying this since we know a property of the beta function: $$ B(s + 1, f) = B(s, f) \cdot \dfrac{s} {s + f} $$ Which implies: $$ E[p|data] = \dfrac{B(s+\alpha, f+\beta)}{B(s+\alpha, f+\beta)} \cdot \dfrac{s+\alpha}{f+\beta} $$ $$ E[p|data] = \dfrac{s+\alpha}{s+\alpha + f+\beta} $$ Makes sense so far! Now, let's say we want to choose a really ""objective"" prior to emulate the frequentist approach, like a uniform distribution. This is equivalent to Beta(1,1). In this case, we would get: $$ E[p|data;\alpha=1,\beta=1] = \dfrac{s+1}{s + f + 2} $$ This hurts my brain. Even though we're being as objective as we can (""p is equally likely to be anything""), we're getting a different result than the frequentist approach. On the flip side, if we do the improper prior Beta(0,0), we get the same result as the frequentist approach: $$ E[p|data;\alpha=0,\beta=0] = \dfrac{s}{s + f} $$ What makes Beta(0,0) more similar to the frequentist approach than Beta(1,1)? What assumption are we making in Beta(1,1)? How is Beta(0,0) ""less informed""?",,"['probability', 'probability-distributions', 'bayesian']"
89,Find the probability of winning at this lottery.,Find the probability of winning at this lottery.,,"So, the problem I found goes like this: You have $n$ different numbers, numbered from $ 1 $ to $n$. You can   randomly choose $m$ (different) of them. The computer also randomly   selects $m$ (different) of them. If you and the computer have exactly   $k$ common numbers, then you win a certain amount of money. The problem asks us to find the probability of winning. I have solved some easier problems involving probabilities. But here, the only thing I could think of was that the probability for a certain sequence of $m$ numbers to emerge is: $$ \frac{1}{\dbinom{n}{m}} $$ How do you solve it? I'm on my way of getting used to this type of problems and I could really use some help.","So, the problem I found goes like this: You have $n$ different numbers, numbered from $ 1 $ to $n$. You can   randomly choose $m$ (different) of them. The computer also randomly   selects $m$ (different) of them. If you and the computer have exactly   $k$ common numbers, then you win a certain amount of money. The problem asks us to find the probability of winning. I have solved some easier problems involving probabilities. But here, the only thing I could think of was that the probability for a certain sequence of $m$ numbers to emerge is: $$ \frac{1}{\dbinom{n}{m}} $$ How do you solve it? I'm on my way of getting used to this type of problems and I could really use some help.",,"['probability', 'problem-solving']"
90,What is the correct way to think about this yet another balls/boxes problem?,What is the correct way to think about this yet another balls/boxes problem?,,"How would you do the following problem: Suppose that $n$ balls are placed at random into $n$ boxes. Find the probability that there is exactly one empty box. I mentally pictured $n$ boxes being in front of me and $n$ balls which I'm throwing (hence randomness) in the boxes, each ball has an equal chance of landing in any of the boxes. That led me to this: $$\frac{n(n-1)\frac{n!}{2}}{n^n}\tag{1}$$ Which is a good answer yet to a different problem, and the answer to the above problem turned out to be $$\frac{n(n-1)}{\binom{2n-1}{n}}\tag{2}$$ I can reverse engineer the correct answer $(2)$ and think about it in terms of stars and bars but it's unclear what mental picture do I need to have in mind after reading the word problem? And as a side question: do you think the phrasing of the cited problem is unambiguous? How would you state the problem which has $(1)$ as its solution?","How would you do the following problem: Suppose that $n$ balls are placed at random into $n$ boxes. Find the probability that there is exactly one empty box. I mentally pictured $n$ boxes being in front of me and $n$ balls which I'm throwing (hence randomness) in the boxes, each ball has an equal chance of landing in any of the boxes. That led me to this: $$\frac{n(n-1)\frac{n!}{2}}{n^n}\tag{1}$$ Which is a good answer yet to a different problem, and the answer to the above problem turned out to be $$\frac{n(n-1)}{\binom{2n-1}{n}}\tag{2}$$ I can reverse engineer the correct answer $(2)$ and think about it in terms of stars and bars but it's unclear what mental picture do I need to have in mind after reading the word problem? And as a side question: do you think the phrasing of the cited problem is unambiguous? How would you state the problem which has $(1)$ as its solution?",,"['probability', 'combinatorics']"
91,Probability of getting split pill from bottle?,Probability of getting split pill from bottle?,,"I have a bottle of 100 pills.  The daily dose is 1/2 pill, so if the first pill I extract is a whole pill, I split it and put 1/2 back. Just out of my own general curiosity, I'd like to model the probability of extracting a whole pill vs. a half pill over time, but I'm not sure how to start.","I have a bottle of 100 pills.  The daily dose is 1/2 pill, so if the first pill I extract is a whole pill, I split it and put 1/2 back. Just out of my own general curiosity, I'd like to model the probability of extracting a whole pill vs. a half pill over time, but I'm not sure how to start.",,['probability']
92,Three points on a circle,Three points on a circle,,"If three points are randomly chosen on the boundary of a circle, what is the probability that there exists a diameter of the circle such that all three points lie on the same side of it? I have a solution, but I'm very curious to see how others do it (and whether we get the same answer)! Thanks.","If three points are randomly chosen on the boundary of a circle, what is the probability that there exists a diameter of the circle such that all three points lie on the same side of it? I have a solution, but I'm very curious to see how others do it (and whether we get the same answer)! Thanks.",,['probability']
93,Generating random numbers with the distribution of the primes,Generating random numbers with the distribution of the primes,,"I would like to generate random numbers whose distribution mimics that of the primes. So the number of generated random numbers less than $n$ should grow like $n / \log n$, most intervals $[n,n+n^\epsilon]$ should contain approximately $n^\epsilon / \log n$ generated numbers (Selberg's short intervals), etc.  Does anyone know of a computationally feasible method for generating such ""look-a-like primes""? Addendum . I implemented Henry and Xoff's suggestions. Here are several instances of the first ten ""pseudoprimes"": $$ 4, 5, 9, 10, 17, 23, 27, 28, 31, 44 $$ $$ 7, 8, 9, 10, 12, 15, 18, 19, 27, 34 $$ $$ 6, 11, 15, 16, 23, 26, 27, 29, 45, 49 $$ And here is the cumulative distribution pseudoprimes up to $10^6$ (red), together with  a plot of $n / \log n$ (purple), for one random run:","I would like to generate random numbers whose distribution mimics that of the primes. So the number of generated random numbers less than $n$ should grow like $n / \log n$, most intervals $[n,n+n^\epsilon]$ should contain approximately $n^\epsilon / \log n$ generated numbers (Selberg's short intervals), etc.  Does anyone know of a computationally feasible method for generating such ""look-a-like primes""? Addendum . I implemented Henry and Xoff's suggestions. Here are several instances of the first ten ""pseudoprimes"": $$ 4, 5, 9, 10, 17, 23, 27, 28, 31, 44 $$ $$ 7, 8, 9, 10, 12, 15, 18, 19, 27, 34 $$ $$ 6, 11, 15, 16, 23, 26, 27, 29, 45, 49 $$ And here is the cumulative distribution pseudoprimes up to $10^6$ (red), together with  a plot of $n / \log n$ (purple), for one random run:",,"['probability', 'number-theory', 'prime-numbers']"
94,Continuity of the Characteristic Function of a RV,Continuity of the Characteristic Function of a RV,,"Defining the Characteristic Function $ \quad  \phi(t) := \mathbb{E} \left[ e^{itx} \right] $ for a random variable with distribution function $F(x)$ in order to show it is  uniformly continuous I say $$ |\phi(t+u) - \phi(t)| = \left |\int e^{itx}(e^{iux} - 1) dF(x) \right| \le \\ \int 1 \cdot|e^{iux} -1|dF(x) \to 0 \quad as  \quad u\to0 $$ Now my question is, does the convergence I state in the last line follow directly, or do I need to be a little carful before I conclude it is true ? (i.e. can I directly use that $|e^{itu} -1| \to 0 ? )$","Defining the Characteristic Function $ \quad  \phi(t) := \mathbb{E} \left[ e^{itx} \right] $ for a random variable with distribution function $F(x)$ in order to show it is  uniformly continuous I say $$ |\phi(t+u) - \phi(t)| = \left |\int e^{itx}(e^{iux} - 1) dF(x) \right| \le \\ \int 1 \cdot|e^{iux} -1|dF(x) \to 0 \quad as  \quad u\to0 $$ Now my question is, does the convergence I state in the last line follow directly, or do I need to be a little carful before I conclude it is true ? (i.e. can I directly use that $|e^{itu} -1| \to 0 ? )$",,"['probability', 'analysis', 'probability-theory', 'fourier-analysis', 'convergence-divergence']"
95,Boggle letter probability,Boggle letter probability,,"How to distribute English alphabet letters among Boggle game dice? How to make rolling for example letter ""A"" more often than others? How to choose how many copies of each letter to make, and how many copies of them to put on one dice? Can you please answer to these questions?","How to distribute English alphabet letters among Boggle game dice? How to make rolling for example letter ""A"" more often than others? How to choose how many copies of each letter to make, and how many copies of them to put on one dice? Can you please answer to these questions?",,['probability']
96,Probability of picking a specific value from a countably infinite set,Probability of picking a specific value from a countably infinite set,,"I have just learned in probability that picking a specific value from an uncountably infinite set (continuous) has a probability of zero, and that we thus estimate such things over an interval using integrals. This clearly does not apply to finite sets (discrete), where you can easily calculate the probability. But does it not apply to a countably infinite set (natural numbers for example), as it is discrete? On one hand, if we calculate limit of picking a certain element as one over x where x goes to infinity, it seems to be zero, but then again, it's discrete variable and I am not sure if it works the same way as continuous...","I have just learned in probability that picking a specific value from an uncountably infinite set (continuous) has a probability of zero, and that we thus estimate such things over an interval using integrals. This clearly does not apply to finite sets (discrete), where you can easily calculate the probability. But does it not apply to a countably infinite set (natural numbers for example), as it is discrete? On one hand, if we calculate limit of picking a certain element as one over x where x goes to infinity, it seems to be zero, but then again, it's discrete variable and I am not sure if it works the same way as continuous...",,[]
97,What's the name of this stochastic process?,What's the name of this stochastic process?,,"I heard about it sometime somewhere and want to read about it now, but I can't recall what the name is: Start with $a_1 = \ldots =a_n=1$. Choose a number between 1 and $n$ with probability $a_i/(a_1+ \ldots + a_n)$ to choose $i$. If $i_0$ is the number chosen, increase $a_i$ by 1 and now choose another number and so on indefinitely.","I heard about it sometime somewhere and want to read about it now, but I can't recall what the name is: Start with $a_1 = \ldots =a_n=1$. Choose a number between 1 and $n$ with probability $a_i/(a_1+ \ldots + a_n)$ to choose $i$. If $i_0$ is the number chosen, increase $a_i$ by 1 and now choose another number and so on indefinitely.",,['probability']
98,Expectation of a monotone function of CDF: $\mathbb E \left [g(F(X)) \right ]$,Expectation of a monotone function of CDF:,\mathbb E \left [g(F(X)) \right ],"If $X$ is a random variable with distribution function $F,$ then $\mathbb{E}[(F[X])^{-1/2}]$ can be computed by integration by parts, if $X$ has a continuous density $f$ . What happens in the general case? Can we always compute it (or bound it)?","If is a random variable with distribution function then can be computed by integration by parts, if has a continuous density . What happens in the general case? Can we always compute it (or bound it)?","X F, \mathbb{E}[(F[X])^{-1/2}] X f","['probability', 'statistics', 'expected-value', 'cumulative-distribution-functions']"
99,Probability of two intersecting straight paths,Probability of two intersecting straight paths,,"Two people, A and B, starts from two different points and move in a perfectly straight line in an infinite plane. When they move they leave a visible trace after them. Question: What is the probability that their path (of traces) will intersect at some point regardless of where they start? What I've tried so far is to draw two circles and split it in quadrants. That helped a little bit but didn't really solve the problem, just got an overview. Here's some examples of interesecting paths (first row) and non intersecting paths (second row) which gives you an idea of the criterias for when they intersect and don't intersect: How would you approach and solve this problem?","Two people, A and B, starts from two different points and move in a perfectly straight line in an infinite plane. When they move they leave a visible trace after them. Question: What is the probability that their path (of traces) will intersect at some point regardless of where they start? What I've tried so far is to draw two circles and split it in quadrants. That helped a little bit but didn't really solve the problem, just got an overview. Here's some examples of interesecting paths (first row) and non intersecting paths (second row) which gives you an idea of the criterias for when they intersect and don't intersect: How would you approach and solve this problem?",,['probability']
