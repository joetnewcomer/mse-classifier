,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Difference between ""scalar line integral"" and ""line integral""","Difference between ""scalar line integral"" and ""line integral""",,"What is the difference between the phrases ""scalar line integral"" and ""line integral""? If the phrases are equivalent, what purpose does the adjective ""scalar"" serve in the phrase; why is it there?","What is the difference between the phrases ""scalar line integral"" and ""line integral""? If the phrases are equivalent, what purpose does the adjective ""scalar"" serve in the phrase; why is it there?",,"['integration', 'multivariable-calculus', 'curves']"
1,"Computing $\int_D x^3-3xy^2\,{\rm d}x\,{\rm d}y$ using the mean value property.",Computing  using the mean value property.,"\int_D x^3-3xy^2\,{\rm d}x\,{\rm d}y","I am asked to compute $$\int_D x^3-3xy^2\,{\rm d}x\,{\rm d}y,$$where $D = \{ (x,y) \mid (x+1)^2+y^2 \leq 9, \text{and }(x-1)^2+y^2 \geq 1 \}$. Granted, $u(x,y) = x^3-3xy^2$ is harmonic (it is the real part of $z^3$, which is holomorphic, say), so we have the mean value property here. Let $D_1$ be the bigger disk and $D_2$ the smaller one. Then $$\int_D x^3-3xy^2\,{\rm d}x\,{\rm d}y = \int_{D_1} x^3-3xy^2\,{\rm d}x\,{\rm d}y -\int_{D_2} x^3-3xy^2\,{\rm d}x\,{\rm d}y .$$We should have have that: $$u(-1,0) = \frac{1}{9\pi}\int_{D_1}x^3-3xy^2\,{\rm d}x\,{\rm d}y \implies \int_{D_1} x^3-3xy^2\,{\rm d}x\,{\rm d}y = -9\pi.$$But wolfram alpha gives the other sign . I don't know how to set up the double integral there, so I passed it to (shifted) polar coordinates and threw it there - I don't think I made mistakes in this part. I got so paranoid that I actually did it again by hand and got $9 \pi$ too. For the second one, we'd get: $$u(1,0) = \frac{1}{\pi}\int_{D_2}x^3-3xy^2\,{\rm d}x\,{\rm d}y \implies \int_{D_2}x^3-3xy^2\,{\rm d}x\,{\rm d}y = \pi.$$ Wolfram doesn't seems to understand this second integral, so I couldn't double-check - anyway, I'm not trusting anything here. My computation would give that the initial integral is equal to $-10 \pi$. Can someone please find out what I'm missing here, explain what is going on here and find out what the integral evaluates to?","I am asked to compute $$\int_D x^3-3xy^2\,{\rm d}x\,{\rm d}y,$$where $D = \{ (x,y) \mid (x+1)^2+y^2 \leq 9, \text{and }(x-1)^2+y^2 \geq 1 \}$. Granted, $u(x,y) = x^3-3xy^2$ is harmonic (it is the real part of $z^3$, which is holomorphic, say), so we have the mean value property here. Let $D_1$ be the bigger disk and $D_2$ the smaller one. Then $$\int_D x^3-3xy^2\,{\rm d}x\,{\rm d}y = \int_{D_1} x^3-3xy^2\,{\rm d}x\,{\rm d}y -\int_{D_2} x^3-3xy^2\,{\rm d}x\,{\rm d}y .$$We should have have that: $$u(-1,0) = \frac{1}{9\pi}\int_{D_1}x^3-3xy^2\,{\rm d}x\,{\rm d}y \implies \int_{D_1} x^3-3xy^2\,{\rm d}x\,{\rm d}y = -9\pi.$$But wolfram alpha gives the other sign . I don't know how to set up the double integral there, so I passed it to (shifted) polar coordinates and threw it there - I don't think I made mistakes in this part. I got so paranoid that I actually did it again by hand and got $9 \pi$ too. For the second one, we'd get: $$u(1,0) = \frac{1}{\pi}\int_{D_2}x^3-3xy^2\,{\rm d}x\,{\rm d}y \implies \int_{D_2}x^3-3xy^2\,{\rm d}x\,{\rm d}y = \pi.$$ Wolfram doesn't seems to understand this second integral, so I couldn't double-check - anyway, I'm not trusting anything here. My computation would give that the initial integral is equal to $-10 \pi$. Can someone please find out what I'm missing here, explain what is going on here and find out what the integral evaluates to?",,"['integration', 'multivariable-calculus', 'partial-differential-equations', 'proof-verification', 'harmonic-functions']"
2,"Why is the direction of propagation of $y = \sin(kx - \omega t) \quad \omega , k \gt 0$ toward $+X$ axis?",Why is the direction of propagation of  toward  axis?,"y = \sin(kx - \omega t) \quad \omega , k \gt 0 +X","I'm not sure if this question should be in Physics or here in Mathematics. Forgive me if it doesn't belong here. My book says that the wave $y = \sin(kx -\omega t)$ travels in $+X$ direction. I tried deriving the speed of propagation, and I am getting the direction to be towards $-X$ We have, $$\frac{\partial y}{\partial t} = -\omega \cos(kx - \omega t)$$ Also, $$\frac{\partial y}{\partial x} = k \cos(kx - \omega t)$$ Dividing, $$\frac{\partial x}{\partial t} = - \frac \omega k $$ This is speed of propagation of wave. Now I'm not sure if partial derivative of $x$ with $t$ gives speed of wave or not, but since the magnitude of speed is coming out to be $\frac \omega k$ which is the actual speed of a wave, I must be close. The Problem From my derivation, I get the speed of wave $= - \frac \omega k $, which means wave is travelling in $-X$ direction. My book says that the wave $y = \sin(kx - \omega t)$ travels in $+X$ direction with a speed of $\frac \omega k$. The wave $y = \sin(kx + \omega t)$ travels in $-X$ direction, which according to my calculation should go in $+X$ Why do I get the direction to be opposite? The magnitude of speed from my calculation is correct, but direction is coming out to be opposite.","I'm not sure if this question should be in Physics or here in Mathematics. Forgive me if it doesn't belong here. My book says that the wave $y = \sin(kx -\omega t)$ travels in $+X$ direction. I tried deriving the speed of propagation, and I am getting the direction to be towards $-X$ We have, $$\frac{\partial y}{\partial t} = -\omega \cos(kx - \omega t)$$ Also, $$\frac{\partial y}{\partial x} = k \cos(kx - \omega t)$$ Dividing, $$\frac{\partial x}{\partial t} = - \frac \omega k $$ This is speed of propagation of wave. Now I'm not sure if partial derivative of $x$ with $t$ gives speed of wave or not, but since the magnitude of speed is coming out to be $\frac \omega k$ which is the actual speed of a wave, I must be close. The Problem From my derivation, I get the speed of wave $= - \frac \omega k $, which means wave is travelling in $-X$ direction. My book says that the wave $y = \sin(kx - \omega t)$ travels in $+X$ direction with a speed of $\frac \omega k$. The wave $y = \sin(kx + \omega t)$ travels in $-X$ direction, which according to my calculation should go in $+X$ Why do I get the direction to be opposite? The magnitude of speed from my calculation is correct, but direction is coming out to be opposite.",,"['multivariable-calculus', 'derivatives', 'wave-equation']"
3,Derivative is an alternating 1-tensor?,Derivative is an alternating 1-tensor?,,"I am reading through spivak, and he states, if $f: \mathbb{R^n} \to \mathbb{R}$ is differentiable, then $Df(p): \mathbb{R^n} \to \mathbb{R}$, and since this is linear, we have that $Df(p) \in \Lambda^1(\mathbb{R^n})$. I don't follow this exactly, I know that since it is linear, $Df(p) \in \mathcal{J}^1(\mathbb{R^n})$, but I don't see how it is alternating.","I am reading through spivak, and he states, if $f: \mathbb{R^n} \to \mathbb{R}$ is differentiable, then $Df(p): \mathbb{R^n} \to \mathbb{R}$, and since this is linear, we have that $Df(p) \in \Lambda^1(\mathbb{R^n})$. I don't follow this exactly, I know that since it is linear, $Df(p) \in \mathcal{J}^1(\mathbb{R^n})$, but I don't see how it is alternating.",,"['calculus', 'real-analysis', 'multivariable-calculus', 'exterior-algebra']"
4,"Diffeomorphism group $\text{Diff}_\omega(D^2, \partial D^2)$, exact differential form.","Diffeomorphism group , exact differential form.","\text{Diff}_\omega(D^2, \partial D^2)","Let $D^2$ denote the closed unit disk in $\mathbb{R}^2$. Let $\omega = dx \wedge dy$ denote the standard area form on $\mathbb{R}^2$ (and on $D^2$ by restriction). Let $\phi$ be a diffeomorphism of $D^2$ which is equal to the identity in a neighborhood of $\partial D^2$, and which preserves area; i.e. $\phi^*\omega = \omega$. We denote the group of such diffeomorphisms by $\text{Diff}_\omega(D^2, \partial D^2)$. I know from here that there is a $1$-form $\alpha$ with $d\alpha = \omega$. I have two questions. Is $\phi^* \alpha - \alpha$ exact? Is $\phi^*\alpha - \alpha$ equal to $df$ for some smooth function $f$?","Let $D^2$ denote the closed unit disk in $\mathbb{R}^2$. Let $\omega = dx \wedge dy$ denote the standard area form on $\mathbb{R}^2$ (and on $D^2$ by restriction). Let $\phi$ be a diffeomorphism of $D^2$ which is equal to the identity in a neighborhood of $\partial D^2$, and which preserves area; i.e. $\phi^*\omega = \omega$. We denote the group of such diffeomorphisms by $\text{Diff}_\omega(D^2, \partial D^2)$. I know from here that there is a $1$-form $\alpha$ with $d\alpha = \omega$. I have two questions. Is $\phi^* \alpha - \alpha$ exact? Is $\phi^*\alpha - \alpha$ equal to $df$ for some smooth function $f$?",,['multivariable-calculus']
5,"Prove $\lim_{(x,y)\rightarrow(0,0)} \sqrt{(x − y)} \ln |x + y| = 0$ [closed]",Prove  [closed],"\lim_{(x,y)\rightarrow(0,0)} \sqrt{(x − y)} \ln |x + y| = 0","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I am asked to prove that the limit of this multivariable function is equal to zero. I used the squeeze theorem to say that the limit is greater than 0 and less than x+y, by taking the limit of those we get that it is between zero and zero thus making it = to 0.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question I am asked to prove that the limit of this multivariable function is equal to zero. I used the squeeze theorem to say that the limit is greater than 0 and less than x+y, by taking the limit of those we get that it is between zero and zero thus making it = to 0.",,['multivariable-calculus']
6,Area of the region inside $r=\cos{\theta}$ but outside of $r=4\cos{3\theta}$.,Area of the region inside  but outside of .,r=\cos{\theta} r=4\cos{3\theta},I have been crazy finding the area of the region inside $r=\cos{\theta}$ but outside of $r=4\cos{3\theta}$. I can't decide the integral bounds,I have been crazy finding the area of the region inside $r=\cos{\theta}$ but outside of $r=4\cos{3\theta}$. I can't decide the integral bounds,,"['integration', 'multivariable-calculus', 'polar-coordinates', 'area']"
7,Multi-variable Limit,Multi-variable Limit,,"Question : Does the following limit exist, if so what does it equal?  $$\lim_{(x, y) \to (0,0)} \frac{x^2 y^5}{2x^4 +3y^{10}}$$ - Solution 1 : The limit DOES NOT exist. Let $ x=y^{5/2}$ $$\lim_{y \to 0} \frac{(y^{5/2})^2 y^5}{2(y^{5/2})^4 +3y^{10}} = \lim_{y \to 0} \frac{y^{10}}{2y^{10} +3y^{10}} = \lim_{y \to 0} \frac{1}{2 +3} = \frac{1}{5} $$ Let $ x=0$ $$\lim_{y \to 0} \frac{(0)^2 y^5}{2(0)^4 +3y^{10}} = \lim_{y \to 0} \frac{0}{0 +3y^{10}} = \lim_{y \to 0} 0 = 0 $$ Thus the limit does not exist Solution 2 : The limit DOES exist. Change to polar coordinates and find limit as $r \to 0$ $$\lim_{r \to 0} \frac{(r^2cos^2{\theta}) (r^5sin^5\theta)}{2(r^4cos^4{\theta}) +3(r^{10}cos^{10}{\theta})} =\lim_{r \to 0}\frac{r^4}{r^4} \times\frac{r^3cos^2{\theta} sin^5\theta}{2cos^4{\theta} +3r^{6}cos^{10}{\theta}} =\frac{0}{2cos^4{\theta} +0}= 0  $$ Thus the limit does exist and is $0$ - Problem Can someone please tell me which solution is correct (if any) and why the other is wrong?","Question : Does the following limit exist, if so what does it equal?  $$\lim_{(x, y) \to (0,0)} \frac{x^2 y^5}{2x^4 +3y^{10}}$$ - Solution 1 : The limit DOES NOT exist. Let $ x=y^{5/2}$ $$\lim_{y \to 0} \frac{(y^{5/2})^2 y^5}{2(y^{5/2})^4 +3y^{10}} = \lim_{y \to 0} \frac{y^{10}}{2y^{10} +3y^{10}} = \lim_{y \to 0} \frac{1}{2 +3} = \frac{1}{5} $$ Let $ x=0$ $$\lim_{y \to 0} \frac{(0)^2 y^5}{2(0)^4 +3y^{10}} = \lim_{y \to 0} \frac{0}{0 +3y^{10}} = \lim_{y \to 0} 0 = 0 $$ Thus the limit does not exist Solution 2 : The limit DOES exist. Change to polar coordinates and find limit as $r \to 0$ $$\lim_{r \to 0} \frac{(r^2cos^2{\theta}) (r^5sin^5\theta)}{2(r^4cos^4{\theta}) +3(r^{10}cos^{10}{\theta})} =\lim_{r \to 0}\frac{r^4}{r^4} \times\frac{r^3cos^2{\theta} sin^5\theta}{2cos^4{\theta} +3r^{6}cos^{10}{\theta}} =\frac{0}{2cos^4{\theta} +0}= 0  $$ Thus the limit does exist and is $0$ - Problem Can someone please tell me which solution is correct (if any) and why the other is wrong?",,['multivariable-calculus']
8,Existence of second partial derivative,Existence of second partial derivative,,"let $f: \mathbf{R}^2 \to \mathbf{R}$ be a continuous function. Then can the derivative $\dfrac{\partial^2f}{\partial x \, \partial y}$ can exist without $\dfrac{\partial f}{\partial x}$ existing? I have no idea how to look for this?","let $f: \mathbf{R}^2 \to \mathbf{R}$ be a continuous function. Then can the derivative $\dfrac{\partial^2f}{\partial x \, \partial y}$ can exist without $\dfrac{\partial f}{\partial x}$ existing? I have no idea how to look for this?",,"['real-analysis', 'multivariable-calculus', 'partial-derivative']"
9,Prove that $\frac{d}{dt} (\vec{r} \cdot (\vec{r}' \times \vec{r}'') = \vec{r} \cdot (\vec{r}' \times \vec{r}''')$,Prove that,\frac{d}{dt} (\vec{r} \cdot (\vec{r}' \times \vec{r}'') = \vec{r} \cdot (\vec{r}' \times \vec{r}'''),"I have $\frac{d}{dt} (\vec{r} \cdot (\vec{r}' \times \vec{r}'') \\ = \vec{r}' \cdot (\vec{r}' \times \vec{r}'') + \vec{r} \cdot (\vec{r}' \times \vec{r}'')'\\ =\vec{r}' \cdot (\vec{r}' \times \vec{r}'')+ \vec{r} \cdot (\vec{r}' \times \vec{r}''')$ Now I don't know what to do because i think when a vector is in form $a \cdot (b \times c)$, then I need to use triple determinant. But I can't because I don't have components.","I have $\frac{d}{dt} (\vec{r} \cdot (\vec{r}' \times \vec{r}'') \\ = \vec{r}' \cdot (\vec{r}' \times \vec{r}'') + \vec{r} \cdot (\vec{r}' \times \vec{r}'')'\\ =\vec{r}' \cdot (\vec{r}' \times \vec{r}'')+ \vec{r} \cdot (\vec{r}' \times \vec{r}''')$ Now I don't know what to do because i think when a vector is in form $a \cdot (b \times c)$, then I need to use triple determinant. But I can't because I don't have components.",,[]
10,Equal integrals using Fubini,Equal integrals using Fubini,,"I tried to prove that $$\iint_{\Bbb{R^2}} f\left(x^3+x,{\frac{y}{3x^2+1}}\right) \, d(x,y) = \iint_{\Bbb{R^2}} f(x,y) \, d(x,y)$$ for $f$ Lipschitz/integrable function. I know it can be proven with Fubini's theorem and  $$\int_{\Bbb{R}} \int_{\Bbb{R}} f\left(x^3+x,{\frac{y}{3x^2+1}}\right) \, dx\,dy, \qquad \left[t=x^3+x, dt= 3x^2+1 \vphantom{\frac 1 1} \right]_\text{change-of-variables} $$ but don't sure how to continue from here. Thanks ahead.","I tried to prove that $$\iint_{\Bbb{R^2}} f\left(x^3+x,{\frac{y}{3x^2+1}}\right) \, d(x,y) = \iint_{\Bbb{R^2}} f(x,y) \, d(x,y)$$ for $f$ Lipschitz/integrable function. I know it can be proven with Fubini's theorem and  $$\int_{\Bbb{R}} \int_{\Bbb{R}} f\left(x^3+x,{\frac{y}{3x^2+1}}\right) \, dx\,dy, \qquad \left[t=x^3+x, dt= 3x^2+1 \vphantom{\frac 1 1} \right]_\text{change-of-variables} $$ but don't sure how to continue from here. Thanks ahead.",,"['calculus', 'integration', 'multivariable-calculus']"
11,Swapping partial derivative and curl operator,Swapping partial derivative and curl operator,,The third Maxwell equation states that $$\nabla \times \mathbf E = -\frac{\partial\mathbf B}{\partial t}.$$ Then I have in my notes: $$\nabla \times (\nabla \times \mathbf E) = -\nabla \times \frac{\partial\mathbf B}{\partial t} \color{red}{=} -\frac{\partial}{\partial t}\nabla \times \mathbf B.$$ I don't understand why it's possible to swap the two operators. What are the conditions that have to be satisfied in order to do so?,The third Maxwell equation states that $$\nabla \times \mathbf E = -\frac{\partial\mathbf B}{\partial t}.$$ Then I have in my notes: $$\nabla \times (\nabla \times \mathbf E) = -\nabla \times \frac{\partial\mathbf B}{\partial t} \color{red}{=} -\frac{\partial}{\partial t}\nabla \times \mathbf B.$$ I don't understand why it's possible to swap the two operators. What are the conditions that have to be satisfied in order to do so?,,"['multivariable-calculus', 'vector-analysis']"
12,Projective Plane Embedding Ambiguity,Projective Plane Embedding Ambiguity,,"I'm working in a problem in do Carmo: let $F: \mathbb{R}^3 \to \mathbb{R}^4$ be given by $$ F(x,y,z) \;\; =\;\; (x^2 - y^2, xy, xz, yz). $$ Let $\varphi: \mathbb{S}^2 \to \mathbb{R}^3$ be the restriction $\varphi = F|_{\mathbb{S}^2}$.  Observing that $\varphi(p) = \varphi(-p)$ for all $p \in \mathbb{S}^2$ we can unambiguously define the mapping $\tilde{\varphi}: \mathbb{RP}^2 \to \mathbb{R}^4$ given by $\tilde{\varphi}[p] = \varphi(p)$.  Ultimately we want to show that $\tilde{\varphi}$ is an immersion, and subsequently an embedding of the projective plane into $\mathbb{R}^4$. My Problem: It's not hard to see, considering $\mathbb{RP}^2 \approx \mathbb{S}^2/\mathbb{Z}_2$, that the map $\tilde{\varphi}$ is well-defined, but when I try to take the differential, wouldn't we expect $d\tilde\varphi_p$ to be well-defined as well?  This is to say, shouldn't we expect $d\tilde{\varphi}_p = d\tilde{\varphi}_{-p}$, or at least the columns of each Jacobian to span the same 2-dimensional affine subspace of $\mathbb{R}^4$? Example 1 : First consider the case that we restrict $F$ to the upper and lower open hemispheres.  We can rewrite these restrictions as \begin{eqnarray*} F^{z+}(x,y) & = & \left (x^2 - y^2, xy, x\sqrt{1-x^2-y^2}, y\sqrt{1-x^2-y^2} \right ) \\ F^{z-}(x,y) & = & \left ( x^2 - y^2, xy, -x\sqrt{1-x^2-y^2}, -y\sqrt{1-x^2-y^2} \right ) \end{eqnarray*} where we can see that $F^{z+}(x,y) = F^{z-}(-x,-y)$.  This yields two Jacobians which are incompatible at antipodal points: \begin{eqnarray*} dF^{z+}_{(x,y)} & =& \left [ \begin{array}{cc} 2x & -2y \\ y & x \\ \frac{1- 2x^2 - y^2}{\sqrt{1-x^2-y^2}} & -\frac{xy}{\sqrt{1-x^2-y^2}} \\ -\frac{xy}{\sqrt{1-x^2-y^2}} & \frac{1-x^2-2y^2}{\sqrt{1-x^2-y^2}} \end{array} \right ] \\ dF^{z-}_{(x,y)} & = & \left [ \begin{array}{cc} 2x & -2y \\ y & x \\ -\frac{(1-2x^2-y^2)}{\sqrt{1-x^2-y^2}} & \frac{xy}{\sqrt{1-x^2-y^2}} \\ \frac{xy}{\sqrt{1-x^2-y^2}} & -\frac{(1-x^2-2y^2)}{\sqrt{1-x^2-y^2}} \\ \end{array} \right ]. \end{eqnarray*} Wouldn't we expect that if $F(p) = F(-p)$ for all $p \in \mathbb{R}^3$ that at least $dF^{z+}_{(x,y)} = dF^{z-}_{(-x,-y)}$, or at least have their columns span the same affine subspace? Example 2: Another approach I've considered for this problem is using the stereographic projection $\pi^{-1}:\mathbb{R}^2 \to \mathbb{S}^2/\{N\}$ given by $$ \pi^{-1}(u,v) \;\; =\;\; \left ( \frac{2u}{u^2+v^2+1}, \frac{2v}{u^2+v^2+1}, \frac{u^2+v^2-1}{u^2+v^2+1} \right ) $$ and writing $\varphi|_{\mathbb{S}^2/\{N\}} = F \circ \pi^{-1}$. The problem that I see with this latter approach is that antipodal coordinates in the plane don't map to antipodal coordinates in $\mathbb{S}^2/\{N\}$. Overall my main question is how we appropriately compute the Jacobian $d\tilde{\varphi}_p$, and how are we guaranteed that the Jacobian is well-defined on antipodal points of $\mathbb{S}^2$?  I assume that this condition is necessary in order to show that $\tilde{\varphi}$ is an immersion.  Am I mistaken?","I'm working in a problem in do Carmo: let $F: \mathbb{R}^3 \to \mathbb{R}^4$ be given by $$ F(x,y,z) \;\; =\;\; (x^2 - y^2, xy, xz, yz). $$ Let $\varphi: \mathbb{S}^2 \to \mathbb{R}^3$ be the restriction $\varphi = F|_{\mathbb{S}^2}$.  Observing that $\varphi(p) = \varphi(-p)$ for all $p \in \mathbb{S}^2$ we can unambiguously define the mapping $\tilde{\varphi}: \mathbb{RP}^2 \to \mathbb{R}^4$ given by $\tilde{\varphi}[p] = \varphi(p)$.  Ultimately we want to show that $\tilde{\varphi}$ is an immersion, and subsequently an embedding of the projective plane into $\mathbb{R}^4$. My Problem: It's not hard to see, considering $\mathbb{RP}^2 \approx \mathbb{S}^2/\mathbb{Z}_2$, that the map $\tilde{\varphi}$ is well-defined, but when I try to take the differential, wouldn't we expect $d\tilde\varphi_p$ to be well-defined as well?  This is to say, shouldn't we expect $d\tilde{\varphi}_p = d\tilde{\varphi}_{-p}$, or at least the columns of each Jacobian to span the same 2-dimensional affine subspace of $\mathbb{R}^4$? Example 1 : First consider the case that we restrict $F$ to the upper and lower open hemispheres.  We can rewrite these restrictions as \begin{eqnarray*} F^{z+}(x,y) & = & \left (x^2 - y^2, xy, x\sqrt{1-x^2-y^2}, y\sqrt{1-x^2-y^2} \right ) \\ F^{z-}(x,y) & = & \left ( x^2 - y^2, xy, -x\sqrt{1-x^2-y^2}, -y\sqrt{1-x^2-y^2} \right ) \end{eqnarray*} where we can see that $F^{z+}(x,y) = F^{z-}(-x,-y)$.  This yields two Jacobians which are incompatible at antipodal points: \begin{eqnarray*} dF^{z+}_{(x,y)} & =& \left [ \begin{array}{cc} 2x & -2y \\ y & x \\ \frac{1- 2x^2 - y^2}{\sqrt{1-x^2-y^2}} & -\frac{xy}{\sqrt{1-x^2-y^2}} \\ -\frac{xy}{\sqrt{1-x^2-y^2}} & \frac{1-x^2-2y^2}{\sqrt{1-x^2-y^2}} \end{array} \right ] \\ dF^{z-}_{(x,y)} & = & \left [ \begin{array}{cc} 2x & -2y \\ y & x \\ -\frac{(1-2x^2-y^2)}{\sqrt{1-x^2-y^2}} & \frac{xy}{\sqrt{1-x^2-y^2}} \\ \frac{xy}{\sqrt{1-x^2-y^2}} & -\frac{(1-x^2-2y^2)}{\sqrt{1-x^2-y^2}} \\ \end{array} \right ]. \end{eqnarray*} Wouldn't we expect that if $F(p) = F(-p)$ for all $p \in \mathbb{R}^3$ that at least $dF^{z+}_{(x,y)} = dF^{z-}_{(-x,-y)}$, or at least have their columns span the same affine subspace? Example 2: Another approach I've considered for this problem is using the stereographic projection $\pi^{-1}:\mathbb{R}^2 \to \mathbb{S}^2/\{N\}$ given by $$ \pi^{-1}(u,v) \;\; =\;\; \left ( \frac{2u}{u^2+v^2+1}, \frac{2v}{u^2+v^2+1}, \frac{u^2+v^2-1}{u^2+v^2+1} \right ) $$ and writing $\varphi|_{\mathbb{S}^2/\{N\}} = F \circ \pi^{-1}$. The problem that I see with this latter approach is that antipodal coordinates in the plane don't map to antipodal coordinates in $\mathbb{S}^2/\{N\}$. Overall my main question is how we appropriately compute the Jacobian $d\tilde{\varphi}_p$, and how are we guaranteed that the Jacobian is well-defined on antipodal points of $\mathbb{S}^2$?  I assume that this condition is necessary in order to show that $\tilde{\varphi}$ is an immersion.  Am I mistaken?",,"['multivariable-calculus', 'differential-geometry', 'manifolds']"
13,"Injection and Bijection of the function $f(x,y)=(\frac{x}{1+x+y},\frac{y}{1+x+y}).$",Injection and Bijection of the function,"f(x,y)=(\frac{x}{1+x+y},\frac{y}{1+x+y}).","Let $A=\{(x,y)\in\mathbb{R}^{2}:x+y\neq-1 \}$ Define $$f:A\rightarrow\mathbb{R}^{2}$$ by $$f(x,y)=(\frac{x}{1+x+y},\frac{y}{1+x+y}).$$ I have to prove that the the function $f$ is one one but not onto. It is clear that $f$ is continuously differentiable but Inverse map theorem gives locally injectiveness of $f.$ How to show that $f$ is one one but not onto? For onto i think $(u,v)$ such that $u+v-1=0$ does not have pre image. Please help me. Thanks in advance.","Let $A=\{(x,y)\in\mathbb{R}^{2}:x+y\neq-1 \}$ Define $$f:A\rightarrow\mathbb{R}^{2}$$ by $$f(x,y)=(\frac{x}{1+x+y},\frac{y}{1+x+y}).$$ I have to prove that the the function $f$ is one one but not onto. It is clear that $f$ is continuously differentiable but Inverse map theorem gives locally injectiveness of $f.$ How to show that $f$ is one one but not onto? For onto i think $(u,v)$ such that $u+v-1=0$ does not have pre image. Please help me. Thanks in advance.",,"['calculus', 'real-analysis', 'multivariable-calculus']"
14,What's the most fundamental derivative of multivariable functions?,What's the most fundamental derivative of multivariable functions?,,"There are several derivatives of multivariable functions.  For instance, given a function $F: \Bbb R^n \to \Bbb R^m$ there's the divergence $\nabla \cdot F$ the curl $\nabla \times F$ (if $n=m=3$) the Jacobian $J_F(p)$ the directional derivative $dF(p,v) = \lim\limits_{h\to 0}\frac{F(p+hv)-F(p)}{h}$ I'm wondering which of these is really the derivative of $F$.  I don't think it could be the divergence or curl because $(1)$ the curl isn't even defined except on $\Bbb R^3$ and $(2)$ when they're defined $(\nabla \cdot F)(p) = \operatorname{trace}(J_F(p))$ and $[(\nabla \times F)(p)]_k = \left[\frac12\big([J_F(p)]^T-J_F(p)\big)\right]_{ij}\varepsilon_{ijk}$.  So it seems that $J_F(p)$ is more fundamental. But what about the directional derivative?  I don't even see have this relates to the Jacobian.  So which one (perhaps including some type of derivative I've never heard of) is more ""fundamental""?  What is the derivative of a multivariable function?","There are several derivatives of multivariable functions.  For instance, given a function $F: \Bbb R^n \to \Bbb R^m$ there's the divergence $\nabla \cdot F$ the curl $\nabla \times F$ (if $n=m=3$) the Jacobian $J_F(p)$ the directional derivative $dF(p,v) = \lim\limits_{h\to 0}\frac{F(p+hv)-F(p)}{h}$ I'm wondering which of these is really the derivative of $F$.  I don't think it could be the divergence or curl because $(1)$ the curl isn't even defined except on $\Bbb R^3$ and $(2)$ when they're defined $(\nabla \cdot F)(p) = \operatorname{trace}(J_F(p))$ and $[(\nabla \times F)(p)]_k = \left[\frac12\big([J_F(p)]^T-J_F(p)\big)\right]_{ij}\varepsilon_{ijk}$.  So it seems that $J_F(p)$ is more fundamental. But what about the directional derivative?  I don't even see have this relates to the Jacobian.  So which one (perhaps including some type of derivative I've never heard of) is more ""fundamental""?  What is the derivative of a multivariable function?",,"['multivariable-calculus', 'derivatives']"
15,substituting spherical coordinates to evaluate an integral.,substituting spherical coordinates to evaluate an integral.,,"I have to evaluate $$\int^1_{-1} \int^{ \sqrt {1-x^2}}_{-\sqrt {1-x^2}} \int^1_{-\sqrt{x^2+y^2}} \, dz \, dy \, dx$$ using spherical coordinates. This is what I have come up with \begin{align} & \int^1_0 \int^{2\pi}_0 \int^{3\pi/4}_0 r^2\sin\theta \, d\theta \, d\phi \, dr \\[10pt] = {} & \int^1_0 r^2 \, dr \int^{2\pi}_0 d \phi \int^{3\pi/4}_0 r^2\sin\theta \, d\theta \\[10pt] = {} & \frac 1 3 \times 2\pi \times \left[-\cos\theta\vphantom{\frac 1 1}\right]^{3\pi/4}_0 \end{align} by a combination of sketching and substituting spherical coordinates. After evaluating I obtain this integral to equal 3.57. where as the first one evaluates to 5.236. EDIT: A bit of thought shows me that the above integral gives a spherical volume. We need to restrict $r$ As $x^2 + y^2 = 1 \implies \rho = \csc \theta$ $$\int^{3\pi/4}_{\pi/4} \int^{2\pi}_0 \int^{\csc \theta}_1 r^2\sin\theta \, dr d\phi \, d\theta $$ However This, yet again, does not give me what I want.","I have to evaluate $$\int^1_{-1} \int^{ \sqrt {1-x^2}}_{-\sqrt {1-x^2}} \int^1_{-\sqrt{x^2+y^2}} \, dz \, dy \, dx$$ using spherical coordinates. This is what I have come up with \begin{align} & \int^1_0 \int^{2\pi}_0 \int^{3\pi/4}_0 r^2\sin\theta \, d\theta \, d\phi \, dr \\[10pt] = {} & \int^1_0 r^2 \, dr \int^{2\pi}_0 d \phi \int^{3\pi/4}_0 r^2\sin\theta \, d\theta \\[10pt] = {} & \frac 1 3 \times 2\pi \times \left[-\cos\theta\vphantom{\frac 1 1}\right]^{3\pi/4}_0 \end{align} by a combination of sketching and substituting spherical coordinates. After evaluating I obtain this integral to equal 3.57. where as the first one evaluates to 5.236. EDIT: A bit of thought shows me that the above integral gives a spherical volume. We need to restrict $r$ As $x^2 + y^2 = 1 \implies \rho = \csc \theta$ $$\int^{3\pi/4}_{\pi/4} \int^{2\pi}_0 \int^{\csc \theta}_1 r^2\sin\theta \, dr d\phi \, d\theta $$ However This, yet again, does not give me what I want.",,['multivariable-calculus']
16,Show that $\iint_F f(ax+by+cz)dS = 2 \pi \int_{-1}^1 f(u \sqrt{a^2+b^2+c^2})du$,Show that,\iint_F f(ax+by+cz)dS = 2 \pi \int_{-1}^1 f(u \sqrt{a^2+b^2+c^2})du,Show that $$\iint_F f(ax+by+cz)dS = 2 \pi \int_{-1}^1 f(u \sqrt{a^2+b^2+c^2})du$$ where $F$ is the sphere $x^2 + y^2 +z^2 = 1$ Please provide me hints on how to proceed with this proof.,Show that where is the sphere Please provide me hints on how to proceed with this proof.,\iint_F f(ax+by+cz)dS = 2 \pi \int_{-1}^1 f(u \sqrt{a^2+b^2+c^2})du F x^2 + y^2 +z^2 = 1,['multivariable-calculus']
17,Existence of some differentiable function,Existence of some differentiable function,,"Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ be a differentiable function such that $x f_x=f_y$. How can I prove that there is a differentiable function $g:\mathbb{R} \rightarrow \mathbb{R}$ such that $f(x,y)=g(xe^y)$? It's clear for me that the gradient of this function is orthogonal to the vector $(x,-1)$. Can I somehow deduce from this that $f$ is constant on $xe^y$?","Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}$ be a differentiable function such that $x f_x=f_y$. How can I prove that there is a differentiable function $g:\mathbb{R} \rightarrow \mathbb{R}$ such that $f(x,y)=g(xe^y)$? It's clear for me that the gradient of this function is orthogonal to the vector $(x,-1)$. Can I somehow deduce from this that $f$ is constant on $xe^y$?",,"['real-analysis', 'multivariable-calculus']"
18,derivative of kronecker product,derivative of kronecker product,,"Given $x \in \mathbb{R}^N$ and a function $$H = \sum_{i,j,k=1}^n\ J_{i,j,k}\ x_i x_j x_k$$ for a fixed $J \in \mathbb{R}^{n \times n \times n}$, I am trying to calculate the derivative $\frac{d H}{d x}$ and a little lost in the expressions. Is there is a clean formula to do so? In the quadratic case, if $J$ is symmetric, the derivative is simply $J x$, is the expression simpler if $J_{i,j,k}$ is made symmetric, e.g., by adding all the 6 permutations together? In general, if we have $$ H = \sum_{i_1,i_2 \ldots i_p=1}^n\ J_{i_1,i_2 \ldots i_p}\ x_{i_1} \ldots x_{i_p} $$ can we find a formula for the derivative?","Given $x \in \mathbb{R}^N$ and a function $$H = \sum_{i,j,k=1}^n\ J_{i,j,k}\ x_i x_j x_k$$ for a fixed $J \in \mathbb{R}^{n \times n \times n}$, I am trying to calculate the derivative $\frac{d H}{d x}$ and a little lost in the expressions. Is there is a clean formula to do so? In the quadratic case, if $J$ is symmetric, the derivative is simply $J x$, is the expression simpler if $J_{i,j,k}$ is made symmetric, e.g., by adding all the 6 permutations together? In general, if we have $$ H = \sum_{i_1,i_2 \ldots i_p=1}^n\ J_{i_1,i_2 \ldots i_p}\ x_{i_1} \ldots x_{i_p} $$ can we find a formula for the derivative?",,"['linear-algebra', 'multivariable-calculus', 'multilinear-algebra', 'kronecker-product']"
19,"Evaluate the inward flux of the vector field $F=<y,-x,z>$ over the surface $S$ of the solid bounded by $z=\sqrt{x^2+y^2}$ and $z=3$.",Evaluate the inward flux of the vector field  over the surface  of the solid bounded by  and .,"F=<y,-x,z> S z=\sqrt{x^2+y^2} z=3","Evaluate the inward flux of the vector field $F=<y,-x,z>$ over the surface $S$ of the solid bounded by $z=\sqrt{x^2+y^2}$ and $z=3$. this is basically an inverted cone (right?) So by changing to polar coordinates: $0\leq r\leq3$ and $0\leq \theta \leq 2\pi$ $$-\int_0^{2\pi} \int_0^3-y\frac{x}{\sqrt{x^2+y^2}} + x\frac{y}{\sqrt{x^2+y^2}}+\sqrt{x^2+y^2}\space \space \times rdrd\theta$$ Simplified to $$-\int_0^{2\pi} \int_0^3r^2drd\theta $$ Did i make any mistakes here? because i solved this to be $-18\pi$ but the answer given is $-9\pi$ I'm thinking maybe the range for $\theta$ is wrong but then it can't be because the conditions require full circles.","Evaluate the inward flux of the vector field $F=<y,-x,z>$ over the surface $S$ of the solid bounded by $z=\sqrt{x^2+y^2}$ and $z=3$. this is basically an inverted cone (right?) So by changing to polar coordinates: $0\leq r\leq3$ and $0\leq \theta \leq 2\pi$ $$-\int_0^{2\pi} \int_0^3-y\frac{x}{\sqrt{x^2+y^2}} + x\frac{y}{\sqrt{x^2+y^2}}+\sqrt{x^2+y^2}\space \space \times rdrd\theta$$ Simplified to $$-\int_0^{2\pi} \int_0^3r^2drd\theta $$ Did i make any mistakes here? because i solved this to be $-18\pi$ but the answer given is $-9\pi$ I'm thinking maybe the range for $\theta$ is wrong but then it can't be because the conditions require full circles.",,"['integration', 'multivariable-calculus']"
20,Is the partial derivative continuous w.r.t. other variables that locally Lipschitz continuous to the function?,Is the partial derivative continuous w.r.t. other variables that locally Lipschitz continuous to the function?,,"Consider a function $F(x,y)$, where $x \in {\mathbb R}^n$, $y \in {\mathbb R}^m$, and $F(x,y) \in {\mathbb R}^n$. Additionally, $F(x,y)$ is continuously differentiable w.r.t. $x$ but locally Lipschitz continuous w.r.t. $y$ (not necessarily differentiable). The question is: is the partially derivative $\frac {\partial F(x, y)}{\partial x}$ continuous w.r.t. $y$? (Without  locally Lipschitz condition, $y\sin(x/y)$ is a counterexample.)","Consider a function $F(x,y)$, where $x \in {\mathbb R}^n$, $y \in {\mathbb R}^m$, and $F(x,y) \in {\mathbb R}^n$. Additionally, $F(x,y)$ is continuously differentiable w.r.t. $x$ but locally Lipschitz continuous w.r.t. $y$ (not necessarily differentiable). The question is: is the partially derivative $\frac {\partial F(x, y)}{\partial x}$ continuous w.r.t. $y$? (Without  locally Lipschitz condition, $y\sin(x/y)$ is a counterexample.)",,"['real-analysis', 'multivariable-calculus', 'partial-derivative', 'lipschitz-functions']"
21,Relating the total derivative and the Jacobian matrix,Relating the total derivative and the Jacobian matrix,,"Take for example $f(x,y) = x^y$. I defined the total derivative to be the best linear approximation of $f$. Without working out the Jacobian I found that $$Df(x,y)(h_1,h_2) = h_1yx^{y-1} + h_2x^y\log(x)$$ However the Jacobian gives me a $1 \times 2$ matris: $$\begin{bmatrix} yx^{y-1} &   x^y \log (x) \end{bmatrix} $$ I don't really understand how computing the total derivative explicitly gives me a real number, and computing the Jacobian gives me a matrix, how are they related because I do know they somehow are.","Take for example $f(x,y) = x^y$. I defined the total derivative to be the best linear approximation of $f$. Without working out the Jacobian I found that $$Df(x,y)(h_1,h_2) = h_1yx^{y-1} + h_2x^y\log(x)$$ However the Jacobian gives me a $1 \times 2$ matris: $$\begin{bmatrix} yx^{y-1} &   x^y \log (x) \end{bmatrix} $$ I don't really understand how computing the total derivative explicitly gives me a real number, and computing the Jacobian gives me a matrix, how are they related because I do know they somehow are.",,['multivariable-calculus']
22,Interpreting the results of a Lagrange multiplier problem,Interpreting the results of a Lagrange multiplier problem,,"I was looking for example problems online and came across this problem: a) Use Lagrange multipliers to find the absolute min and absolute max   values of $f(x,y)=x^2+4y^2$ subject to the constraint $y=x^2-2$, if   they exist b) Sketch the level set diagram of $f(x,y)=x^2+4y^2$ and the constant   curve $y=x^2-2$. Where are the candidate points that the Lagrange   multipliers finds? Solution: For a) I get the points $\displaystyle{P=\left(\pm\sqrt{\frac{15}{8}},\frac{-1}{8}\right)}$. I can't real say if they are max or min points the function gives the same value at both points. I know the graph is a paraboloid and was trying to think of the constant curve projected onto the graph. I also tried plugging the constraint into the function and running optimization in one variable. The result is all critical values are complex. How can we confirm if they are max, min or neither? Part b) is easy enough to plot and think about level curves being tangent to the constraint curve. Here is a contour plot","I was looking for example problems online and came across this problem: a) Use Lagrange multipliers to find the absolute min and absolute max   values of $f(x,y)=x^2+4y^2$ subject to the constraint $y=x^2-2$, if   they exist b) Sketch the level set diagram of $f(x,y)=x^2+4y^2$ and the constant   curve $y=x^2-2$. Where are the candidate points that the Lagrange   multipliers finds? Solution: For a) I get the points $\displaystyle{P=\left(\pm\sqrt{\frac{15}{8}},\frac{-1}{8}\right)}$. I can't real say if they are max or min points the function gives the same value at both points. I know the graph is a paraboloid and was trying to think of the constant curve projected onto the graph. I also tried plugging the constraint into the function and running optimization in one variable. The result is all critical values are complex. How can we confirm if they are max, min or neither? Part b) is easy enough to plot and think about level curves being tangent to the constraint curve. Here is a contour plot",,"['calculus', 'multivariable-calculus', 'lagrange-multiplier']"
23,"What is the rate of change of the diagonal, volume, and surface of a box with dimensions a, b, and c?","What is the rate of change of the diagonal, volume, and surface of a box with dimensions a, b, and c?",,"I am working through some problems in my calculus workbook, and this one has me a bit stuck. If someone wouldnt mind lending a hand, I would much appreciate it. This is the problem: A rectangular box has dimensions a, b, and c which are changing with time. At $t = t_0$: $a = 1 m$, $b = 2 m$, and $c = 3 m$ (m is meters). $da/dt = db/dt = 1 m/sec$ and $dc/dt = -3 m/sec$   What is the rate of change of the volume, surface area, and the diagonals of the box at $t = t_0$. If someone wouldnt mind lending me a hand as to the way you would solve this, I would greatly appreciate it. Thanks Corey","I am working through some problems in my calculus workbook, and this one has me a bit stuck. If someone wouldnt mind lending a hand, I would much appreciate it. This is the problem: A rectangular box has dimensions a, b, and c which are changing with time. At $t = t_0$: $a = 1 m$, $b = 2 m$, and $c = 3 m$ (m is meters). $da/dt = db/dt = 1 m/sec$ and $dc/dt = -3 m/sec$   What is the rate of change of the volume, surface area, and the diagonals of the box at $t = t_0$. If someone wouldnt mind lending me a hand as to the way you would solve this, I would greatly appreciate it. Thanks Corey",,"['calculus', 'multivariable-calculus']"
24,"Evaluate $\iint_{0<x<y<1}xy\,dxdy$",Evaluate,"\iint_{0<x<y<1}xy\,dxdy","Let $$f(x,y)=\begin{cases}xy &\text{ if } 0<x<y<1, \\ 0 &\text { otherwise. }\end{cases}$$  Evaluate the  integral $\displaystyle \iint f(x,y)\,dx\,dy$. I'm having trouble with the limits on integration.","Let $$f(x,y)=\begin{cases}xy &\text{ if } 0<x<y<1, \\ 0 &\text { otherwise. }\end{cases}$$  Evaluate the  integral $\displaystyle \iint f(x,y)\,dx\,dy$. I'm having trouble with the limits on integration.",,"['multivariable-calculus', 'definite-integrals']"
25,Finding the distance from the origin to the surface $xy^2 z^4 = 32$ using the method of Lagrange Multipliers,Finding the distance from the origin to the surface  using the method of Lagrange Multipliers,xy^2 z^4 = 32,"Problem: Find the distance from the origin to the surface $xy^2z^4 = 32$. Attempt: The Lagrange equation for this problem is $L(x,y,z, \lambda) = x^2 + y^2 + z^2 + \lambda (xy^2 z^4 - 32)$. Setting the first partials to zero we have \begin{align*} \frac{\partial L}{\partial x} &= 2x + \lambda y^2 z^4 = 0 \qquad (1)  \\ \frac{\partial L}{\partial y} &= 2y + 2 \lambda x y z^4 = 0 \qquad (2) \\ \frac{\partial L}{\partial z} &= 2z + 4 \lambda x y^2 z^3 = 0 \qquad (3) \\ \frac{\partial L}{\partial \lambda} &= xy^2 z^4 - 32 = 0 \qquad (4) \end{align*} Now I'm having a hard time solving this system for $x,y$ and $z$. Here is what I did so far. From $(1)$ and $(2)$ we get \begin{align*} \frac{2x}{y^2 z^4} = - \lambda \qquad \text{and} \qquad \frac{1}{xz^4} = - \lambda \end{align*} Thus $\frac{2x}{y^2 z^4}  = \frac{1}{xz^4} $ or $y^2 = 2x^2$ after simplification. Also, from $(2)$ and $(3)$ we can deduce that \begin{align*} \frac{1}{xz^4} = - \lambda = \frac{2z}{4xy^2 z^3} \end{align*} so that $2y^2 = z^2$ after simplification. Now I used all this and substituted it into $(4)$. This gave me \begin{align*} x(2x^2) (4y^4) - 32 = 0 \end{align*} or (since $y^4 = 4x^4)$ \begin{align*} 8x^3 (4x^4) - 32 = 0 \end{align*}  This means that $32x^7 - 32 = 0$, so that $x = 1$. Then $y^2 = 2$, so that $y = \pm \sqrt{2}$. Then $z^2 = 4$, so that $z = \pm 2$. So I found the points $(x,y,z) = (1, \sqrt{2}, 2)$ and $(1, - \sqrt{2}, -2)$. They both give me the distance $\sqrt{x^2 + y^2 + z^2} = \sqrt{7}$, so I'm guessing they are equal? Is my reasoning correct?","Problem: Find the distance from the origin to the surface $xy^2z^4 = 32$. Attempt: The Lagrange equation for this problem is $L(x,y,z, \lambda) = x^2 + y^2 + z^2 + \lambda (xy^2 z^4 - 32)$. Setting the first partials to zero we have \begin{align*} \frac{\partial L}{\partial x} &= 2x + \lambda y^2 z^4 = 0 \qquad (1)  \\ \frac{\partial L}{\partial y} &= 2y + 2 \lambda x y z^4 = 0 \qquad (2) \\ \frac{\partial L}{\partial z} &= 2z + 4 \lambda x y^2 z^3 = 0 \qquad (3) \\ \frac{\partial L}{\partial \lambda} &= xy^2 z^4 - 32 = 0 \qquad (4) \end{align*} Now I'm having a hard time solving this system for $x,y$ and $z$. Here is what I did so far. From $(1)$ and $(2)$ we get \begin{align*} \frac{2x}{y^2 z^4} = - \lambda \qquad \text{and} \qquad \frac{1}{xz^4} = - \lambda \end{align*} Thus $\frac{2x}{y^2 z^4}  = \frac{1}{xz^4} $ or $y^2 = 2x^2$ after simplification. Also, from $(2)$ and $(3)$ we can deduce that \begin{align*} \frac{1}{xz^4} = - \lambda = \frac{2z}{4xy^2 z^3} \end{align*} so that $2y^2 = z^2$ after simplification. Now I used all this and substituted it into $(4)$. This gave me \begin{align*} x(2x^2) (4y^4) - 32 = 0 \end{align*} or (since $y^4 = 4x^4)$ \begin{align*} 8x^3 (4x^4) - 32 = 0 \end{align*}  This means that $32x^7 - 32 = 0$, so that $x = 1$. Then $y^2 = 2$, so that $y = \pm \sqrt{2}$. Then $z^2 = 4$, so that $z = \pm 2$. So I found the points $(x,y,z) = (1, \sqrt{2}, 2)$ and $(1, - \sqrt{2}, -2)$. They both give me the distance $\sqrt{x^2 + y^2 + z^2} = \sqrt{7}$, so I'm guessing they are equal? Is my reasoning correct?",,"['calculus', 'multivariable-calculus', 'optimization', 'lagrange-multiplier']"
26,The explicit expression for integral of forms,The explicit expression for integral of forms,,"Could anyone please help me with the following three questions? They are simple questions, but I am confused. With a $2$-form $F=\frac{1}{2}F_{\mu\nu}dx^{\mu}\wedge dx^{\nu}$ in 4 dimension, what is the explicit expression of $\int F\wedge F$ in coordinates?  I got something like $$ \int F\wedge F= \frac{1}{4}\int F_{\mu\nu}F_{\rho\sigma}\epsilon^{\mu\nu\rho\sigma}d^4x.$$ My question is: How is that $\epsilon$ defined? I found several definitions and they differ from each other by a factor of $\sqrt{|g|}$ infront. If I am going to do it in 4-D spherical coordinate, how does $\epsilon$ look like ? What is the explicit expression of this one in a 3-D coordinate?  $$\int_{R^3} d(\phi df\wedge dg)$$  $\phi$, $f$ and $g$ are $0$-form functions. What if I use the Stoke's theorem, $$\int_{\partial R^3} \phi df\wedge dg$$  how does it look like explicitly in some coordinate?","Could anyone please help me with the following three questions? They are simple questions, but I am confused. With a $2$-form $F=\frac{1}{2}F_{\mu\nu}dx^{\mu}\wedge dx^{\nu}$ in 4 dimension, what is the explicit expression of $\int F\wedge F$ in coordinates?  I got something like $$ \int F\wedge F= \frac{1}{4}\int F_{\mu\nu}F_{\rho\sigma}\epsilon^{\mu\nu\rho\sigma}d^4x.$$ My question is: How is that $\epsilon$ defined? I found several definitions and they differ from each other by a factor of $\sqrt{|g|}$ infront. If I am going to do it in 4-D spherical coordinate, how does $\epsilon$ look like ? What is the explicit expression of this one in a 3-D coordinate?  $$\int_{R^3} d(\phi df\wedge dg)$$  $\phi$, $f$ and $g$ are $0$-form functions. What if I use the Stoke's theorem, $$\int_{\partial R^3} \phi df\wedge dg$$  how does it look like explicitly in some coordinate?",,"['calculus', 'multivariable-calculus', 'differential-geometry', 'differential-forms']"
27,Vector Field Conceptual Question,Vector Field Conceptual Question,,"Given that: $$F = \langle yz-2xy^2, axz-2x^2y+z, xy+y \rangle$$ in which $a$ is some constant. Now, for what $a$ would make the vector field of $F$ conservative? Why is there only one, or are there many? How can we find an $f$ with $\nabla f=F$? Also for what $a$ would $F$ be the curl of another vector field? For to find for which $a$ the vector field is conservative, do we have to go through the process of finding partial derivative, or is there a much shorter approach. I don't know how to approach my other questions either.","Given that: $$F = \langle yz-2xy^2, axz-2x^2y+z, xy+y \rangle$$ in which $a$ is some constant. Now, for what $a$ would make the vector field of $F$ conservative? Why is there only one, or are there many? How can we find an $f$ with $\nabla f=F$? Also for what $a$ would $F$ be the curl of another vector field? For to find for which $a$ the vector field is conservative, do we have to go through the process of finding partial derivative, or is there a much shorter approach. I don't know how to approach my other questions either.",,['multivariable-calculus']
28,For which values does this series converge? [duplicate],For which values does this series converge? [duplicate],,"This question already has answers here : Convergence of double sum $\sum_{m, n}\frac{1}{m^p + n^k}$ (4 answers) Closed 8 months ago . p and k are real numbers.  For which values of p and k does the following double series converge $$\sum_{n,m=1}^\infty \frac{1}{n^p + m^k}$$ I am trying to find a better (and quicker) way to solve this problem. I'm trying to use RRL's hints (see below) to prove boundedness of the partial sums. Edit:  I was able to figure out the solution with the integral test method and think that I will move on to new problems now.  But if anyone would like to post a solution that doesn't use the integral test and p-tests, that would be interesting to see - thanks in advance :-) Thanks,","This question already has answers here : Convergence of double sum $\sum_{m, n}\frac{1}{m^p + n^k}$ (4 answers) Closed 8 months ago . p and k are real numbers.  For which values of p and k does the following double series converge $$\sum_{n,m=1}^\infty \frac{1}{n^p + m^k}$$ I am trying to find a better (and quicker) way to solve this problem. I'm trying to use RRL's hints (see below) to prove boundedness of the partial sums. Edit:  I was able to figure out the solution with the integral test method and think that I will move on to new problems now.  But if anyone would like to post a solution that doesn't use the integral test and p-tests, that would be interesting to see - thanks in advance :-) Thanks,",,"['calculus', 'real-analysis', 'sequences-and-series', 'multivariable-calculus', 'convergence-divergence']"
29,Does the formula for arc length hold for other coordinate systems?,Does the formula for arc length hold for other coordinate systems?,,"Does the formula for arc length, integration of $\sqrt{(x'(t))^2 + (y'(t))^2 + (z'(t))^2}$, hold for other coordinate systems, such as cylindrical coordinates, meaning can I compute the integral of  $\sqrt{(r'(t))^2 + (\theta'(t))^2 + (z'(t))^2}$ to get the arc length of a curve in 3-D that is parametrized in cylindrical coordinates?  Or, do I have to first convert r(t), $\theta(t)$ and z(t) to x(t), y(t), z(t) coordinates, before applying the formula? Edit: Converting to x,y,z worked for me in an arc length problem.  However, keeping the cylindrical coordinates and going for the integration of $\sqrt{(r'(t))^2 + (\theta'(t))^2 + (z'(t))^2}$ doesn't seem to work. Is it just simply because the arc length formula is derived by the Pythagoras theorem and so must require rectangular coordinates to make sense?","Does the formula for arc length, integration of $\sqrt{(x'(t))^2 + (y'(t))^2 + (z'(t))^2}$, hold for other coordinate systems, such as cylindrical coordinates, meaning can I compute the integral of  $\sqrt{(r'(t))^2 + (\theta'(t))^2 + (z'(t))^2}$ to get the arc length of a curve in 3-D that is parametrized in cylindrical coordinates?  Or, do I have to first convert r(t), $\theta(t)$ and z(t) to x(t), y(t), z(t) coordinates, before applying the formula? Edit: Converting to x,y,z worked for me in an arc length problem.  However, keeping the cylindrical coordinates and going for the integration of $\sqrt{(r'(t))^2 + (\theta'(t))^2 + (z'(t))^2}$ doesn't seem to work. Is it just simply because the arc length formula is derived by the Pythagoras theorem and so must require rectangular coordinates to make sense?",,"['calculus', 'real-analysis', 'integration', 'multivariable-calculus']"
30,"show that the equation $r_1+r_2= \text{constant}$ implies the relation $\mathbf{T}\cdot \nabla(r_1+r_2)=0,$",show that the equation  implies the relation,"r_1+r_2= \text{constant} \mathbf{T}\cdot \nabla(r_1+r_2)=0,","This is a problem from Apostol's Calculus, which I have difficulty solving. If $r_1$ and $r_2$ denote the distances from a point $(x,y)$ on an ellipse to its foci, show that the equation $r_1+r_2= \text{constant}$ (satisfied by these distances) implies the relation $$\mathbf{T}\cdot \nabla(r_1+r_2)=0,$$ where $\mathbf{T}$ is the unit tangent to the curve. Interpret this result geometrically, thereby showing that the tangent makes equal angles with the lines joining $(x,y)$ to the foci. I would greatly appreciate any solutions or suggestions.","This is a problem from Apostol's Calculus, which I have difficulty solving. If $r_1$ and $r_2$ denote the distances from a point $(x,y)$ on an ellipse to its foci, show that the equation $r_1+r_2= \text{constant}$ (satisfied by these distances) implies the relation $$\mathbf{T}\cdot \nabla(r_1+r_2)=0,$$ where $\mathbf{T}$ is the unit tangent to the curve. Interpret this result geometrically, thereby showing that the tangent makes equal angles with the lines joining $(x,y)$ to the foci. I would greatly appreciate any solutions or suggestions.",,"['multivariable-calculus', 'vector-analysis']"
31,Proving $f$ is continuous using the $\epsilon-\delta$ definition,Proving  is continuous using the  definition,f \epsilon-\delta,"Prove that $f(x,y) = x^2 + xy$ is continuous using the $\epsilon-\delta$ definition, at $(1,-1).$ I encountered this question in a test and I fumbled through it quite shamelessly. Here is my latest attempt. We want to find a $\epsilon > 0$ such that when $ \rho ((x,y),(1,-1)) < \delta$ and $N \in \mathbb{N}$, we have $$|f(x,y) - f(1,-1)|< \epsilon$$ $\forall n \le N$. $$\sqrt{(x-1)^2 + (y+1)^2} < \delta$$ $$|x-1|^2 + |y+1|^2 < \delta^2$$ So, $$|x-1| < \delta$$ and  $$|y+1| < \delta$$ Here is where I get reach-y. \begin{align} |f(x,y)-f(1,-1)| &\le& |x-1|^2 + 2 |x-1||y+1|\\ &<& \delta^2 + 2 \delta^2\\ \end{align} In the end I take $\epsilon$ as $3\delta^2$ which seems strange to me. Is this as wrong as I think it is? I've never been able to follow this specific method in class.","Prove that $f(x,y) = x^2 + xy$ is continuous using the $\epsilon-\delta$ definition, at $(1,-1).$ I encountered this question in a test and I fumbled through it quite shamelessly. Here is my latest attempt. We want to find a $\epsilon > 0$ such that when $ \rho ((x,y),(1,-1)) < \delta$ and $N \in \mathbb{N}$, we have $$|f(x,y) - f(1,-1)|< \epsilon$$ $\forall n \le N$. $$\sqrt{(x-1)^2 + (y+1)^2} < \delta$$ $$|x-1|^2 + |y+1|^2 < \delta^2$$ So, $$|x-1| < \delta$$ and  $$|y+1| < \delta$$ Here is where I get reach-y. \begin{align} |f(x,y)-f(1,-1)| &\le& |x-1|^2 + 2 |x-1||y+1|\\ &<& \delta^2 + 2 \delta^2\\ \end{align} In the end I take $\epsilon$ as $3\delta^2$ which seems strange to me. Is this as wrong as I think it is? I've never been able to follow this specific method in class.",,"['calculus', 'real-analysis', 'multivariable-calculus']"
32,Finding $\nabla r^n$,Finding,\nabla r^n,"Find $\nabla r^n$ where $r= \sqrt{x^2+y^2+z^2}$. So $r^n = (x^2+y^2+z^2)^{n/2}$. Then $$\frac{\partial r^n}{\partial x} = 2x\cdot\frac{n}{2}\cdot(x^2+y^2+z^2)^{n/2 - 1} = nx(x^2+y^2+z^2)^{(n-2)/2} = nxr^{n-2},$$ similarly $$\frac{\partial r^n}{\partial y} = nyr^{n-2}, \quad \frac{\partial r^n}{\partial z} = nzr^{n-2}.$$ Thus $$\nabla r^n = nr^{n-2} (x\mathbf{i} + y\mathbf{j} + z\mathbf{k}) = nr^{n-2}\mathbf{r}.$$ However the correct answer is $$\nabla r^n=nr^{n-1} \hat{\mathbf{r}}.$$ I don't really understand where I have gone wrong.","Find $\nabla r^n$ where $r= \sqrt{x^2+y^2+z^2}$. So $r^n = (x^2+y^2+z^2)^{n/2}$. Then $$\frac{\partial r^n}{\partial x} = 2x\cdot\frac{n}{2}\cdot(x^2+y^2+z^2)^{n/2 - 1} = nx(x^2+y^2+z^2)^{(n-2)/2} = nxr^{n-2},$$ similarly $$\frac{\partial r^n}{\partial y} = nyr^{n-2}, \quad \frac{\partial r^n}{\partial z} = nzr^{n-2}.$$ Thus $$\nabla r^n = nr^{n-2} (x\mathbf{i} + y\mathbf{j} + z\mathbf{k}) = nr^{n-2}\mathbf{r}.$$ However the correct answer is $$\nabla r^n=nr^{n-1} \hat{\mathbf{r}}.$$ I don't really understand where I have gone wrong.",,['multivariable-calculus']
33,When is shear useful?,When is shear useful?,,"I'd never heard of the shear of a vector field until reading this article . Shear is the symmetric, tracefree part of the gradient of a vector field. If you were to decompose the gradient of a vector field into antisymmetric ($\propto$ curl), symmetric tracefree (shear), and tracefull(?) ($\propto$ divergence) parts you'd get that it has components: $$\frac {\partial A_i}{\partial x^j} = \sigma(A)_{ij} - \frac 12 \epsilon_{ijk}(\nabla \times A)_k + \frac 13 \delta_{ij} (\nabla \cdot A)$$ where $\sigma(A)$ is the shear and is defined as $$\sigma(A)_{ij} = \frac 12 \left(\dfrac {\partial A_i}{\partial x^j} + \frac {\partial A_j}{\partial x^i}\right) - \frac 13 \delta_{ij} (\nabla \cdot A)$$ Is the shear of a vector field only useful in fluid mechanics?  Does it have any use in pure mathematics -- perhaps analysis or differential geometry?  If so, does anyone have a reference?","I'd never heard of the shear of a vector field until reading this article . Shear is the symmetric, tracefree part of the gradient of a vector field. If you were to decompose the gradient of a vector field into antisymmetric ($\propto$ curl), symmetric tracefree (shear), and tracefull(?) ($\propto$ divergence) parts you'd get that it has components: $$\frac {\partial A_i}{\partial x^j} = \sigma(A)_{ij} - \frac 12 \epsilon_{ijk}(\nabla \times A)_k + \frac 13 \delta_{ij} (\nabla \cdot A)$$ where $\sigma(A)$ is the shear and is defined as $$\sigma(A)_{ij} = \frac 12 \left(\dfrac {\partial A_i}{\partial x^j} + \frac {\partial A_j}{\partial x^i}\right) - \frac 13 \delta_{ij} (\nabla \cdot A)$$ Is the shear of a vector field only useful in fluid mechanics?  Does it have any use in pure mathematics -- perhaps analysis or differential geometry?  If so, does anyone have a reference?",,"['multivariable-calculus', 'reference-request', 'tensors', 'fluid-dynamics']"
34,Power function of fixed numbers.,Power function of fixed numbers.,,"Prove that $3^x-4^x+2x4^{x-1}\le0$, where $x\in[-0.5,0]$.Here is it's plot . I tried to do it by first and second derivative test but it involves $log$  which make the expression more complicated.","Prove that $3^x-4^x+2x4^{x-1}\le0$, where $x\in[-0.5,0]$.Here is it's plot . I tried to do it by first and second derivative test but it involves $log$  which make the expression more complicated.",,"['calculus', 'multivariable-calculus', 'inequality']"
35,Spherical coordinates for sphere with centre $\neq 0$,Spherical coordinates for sphere with centre,\neq 0,"For something like $(x-1)^2+y^2+z^2=1$, we would let $x-1=\rho \sin (\phi)\cos (\theta)$ $y=\rho \sin (\phi)\sin (\theta)$ $z=\rho \cos (\phi)$ But we know $\rho =1$ right? So it becomes $x-1= \sin (\phi)\cos (\theta)$ $y= \sin (\phi)\sin (\theta)$ $z= \cos (\phi)$ If the sphere was centred on the origin, then the limits would be $\phi \in [0, \pi]$ and $\theta \in [0, 2\pi]$ but since its not, I am guessing it isn't this. I need to know how to find the limits when it is not in the centre. I know that the $\phi$ is the angle from the positive $z$ axis downwards but it is strange because if the sphere is in the origin, and if the limit is from $0$ to $\pi$, it doesn't cover all of it, it covers half. Is it always meant to cover half? Also with $\theta$, is it the angle on the $xy$ plane with respect to the origin or on the $xy$ plane with respect to the centre of the sphere?","For something like $(x-1)^2+y^2+z^2=1$, we would let $x-1=\rho \sin (\phi)\cos (\theta)$ $y=\rho \sin (\phi)\sin (\theta)$ $z=\rho \cos (\phi)$ But we know $\rho =1$ right? So it becomes $x-1= \sin (\phi)\cos (\theta)$ $y= \sin (\phi)\sin (\theta)$ $z= \cos (\phi)$ If the sphere was centred on the origin, then the limits would be $\phi \in [0, \pi]$ and $\theta \in [0, 2\pi]$ but since its not, I am guessing it isn't this. I need to know how to find the limits when it is not in the centre. I know that the $\phi$ is the angle from the positive $z$ axis downwards but it is strange because if the sphere is in the origin, and if the limit is from $0$ to $\pi$, it doesn't cover all of it, it covers half. Is it always meant to cover half? Also with $\theta$, is it the angle on the $xy$ plane with respect to the origin or on the $xy$ plane with respect to the centre of the sphere?",,['multivariable-calculus']
36,"Method of Characteristics, Quasilinear pde","Method of Characteristics, Quasilinear pde",,"I am attempting to solve the quasilinear pde: $u_t+uu_x=-u$;  $x\in \mathbb{R}$, $t>0$ $u(x,0)=-x/2$ ; $x\in \mathbb{R}$ I understand everything except from the last step. If I make $\xi$ the subject of (s2) I get: $\xi=\frac{2x}{1+e^{-t}}$, then subbing into (s1) $u(\frac{2x}{1+e^{-t}},t)=-\frac{xe^{-t}}{1+e^{-t}}$ How do I get to what is written in the green box?","I am attempting to solve the quasilinear pde: $u_t+uu_x=-u$;  $x\in \mathbb{R}$, $t>0$ $u(x,0)=-x/2$ ; $x\in \mathbb{R}$ I understand everything except from the last step. If I make $\xi$ the subject of (s2) I get: $\xi=\frac{2x}{1+e^{-t}}$, then subbing into (s1) $u(\frac{2x}{1+e^{-t}},t)=-\frac{xe^{-t}}{1+e^{-t}}$ How do I get to what is written in the green box?",,"['multivariable-calculus', 'partial-differential-equations']"
37,On the definition of critical point,On the definition of critical point,,"Let $f:\mathbb{R}^n\to \mathbb{R}^m$ be a smooth function (or in general between two smooth manifolds). Then $p\in \mathbb{R}^n$ is a critical point if $df_p$ is not surjective. I feel confused about this definition. If $n<m$, then $df_p$ can never be surjective, so that every point in $\mathbb{R}^n$ is critical in this case?! For instance, let $\alpha:\mathbb{R}\to\mathbb{R}^2$ be the curve $\alpha(t)=(\sin t,\cos t)$. Is every $t$ critical?","Let $f:\mathbb{R}^n\to \mathbb{R}^m$ be a smooth function (or in general between two smooth manifolds). Then $p\in \mathbb{R}^n$ is a critical point if $df_p$ is not surjective. I feel confused about this definition. If $n<m$, then $df_p$ can never be surjective, so that every point in $\mathbb{R}^n$ is critical in this case?! For instance, let $\alpha:\mathbb{R}\to\mathbb{R}^2$ be the curve $\alpha(t)=(\sin t,\cos t)$. Is every $t$ critical?",,"['multivariable-calculus', 'differential-geometry', 'manifolds']"
38,Gradient and Hessian of a function with Matrix Variables,Gradient and Hessian of a function with Matrix Variables,,"What is the Gradient and Hessian of this function? $$ f(X)=\langle X,D\rangle-c \cdot \sqrt{\langle X,E\rangle}$$ where $X,D,E$ are all semi-definite matrices. Where Gradient becomes zero?","What is the Gradient and Hessian of this function? $$ f(X)=\langle X,D\rangle-c \cdot \sqrt{\langle X,E\rangle}$$ where $X,D,E$ are all semi-definite matrices. Where Gradient becomes zero?",,"['multivariable-calculus', 'convex-analysis']"
39,Can someone clarify the definition of flux?,Can someone clarify the definition of flux?,,"I am confused by the concept of flux as used in vector calculus. Suppose I have a sphere. On the inside of this sphere is a spherically symmetric electric charge distribution. Now I want to find the flux through the surface of the sphere. Obviously, the electric field of that charge distribution is a vector field. So presumably I can apply a surface integral here to find the total flux through the surface. But this is what I am having trouble understanding.  What am I adding up with a surface integral in computing the flux through a surface? In other words, I have heard flux described as ""Field lines per unit area"" of the surface. How can we quantify the density of a vector field? I thought in a vector space like $\Bbb{R}^3$ there would be an infinite number of possible lines going through a patch of a surface. In that sense, then this definition  of flux as ""Field lines per unit area"" makes no sense. My Question: Can someone clarify the definition of flux in a rigorous enough way that some of the mathematical contradictions (ie infinite number of lines through surface) I named are clarified? EDIT: Tom Apostol mentions the term ""flux density vector field"" that essentially assigns a flux density vector to each point in space. Perhaps answerers could clarify what this is as I think it's likely related to my question.","I am confused by the concept of flux as used in vector calculus. Suppose I have a sphere. On the inside of this sphere is a spherically symmetric electric charge distribution. Now I want to find the flux through the surface of the sphere. Obviously, the electric field of that charge distribution is a vector field. So presumably I can apply a surface integral here to find the total flux through the surface. But this is what I am having trouble understanding.  What am I adding up with a surface integral in computing the flux through a surface? In other words, I have heard flux described as ""Field lines per unit area"" of the surface. How can we quantify the density of a vector field? I thought in a vector space like $\Bbb{R}^3$ there would be an infinite number of possible lines going through a patch of a surface. In that sense, then this definition  of flux as ""Field lines per unit area"" makes no sense. My Question: Can someone clarify the definition of flux in a rigorous enough way that some of the mathematical contradictions (ie infinite number of lines through surface) I named are clarified? EDIT: Tom Apostol mentions the term ""flux density vector field"" that essentially assigns a flux density vector to each point in space. Perhaps answerers could clarify what this is as I think it's likely related to my question.",,"['multivariable-calculus', 'physics', 'surfaces', 'vector-fields', 'surface-integrals']"
40,Integral $\int_{\mathbb{R}^{n-1}} \frac{1}{(y_1^2 + y_2^2 +...y_{n-1}^2 + C^2)^\frac{n}{2}} dy = \frac{n\alpha(n)}{2C}$,Integral,\int_{\mathbb{R}^{n-1}} \frac{1}{(y_1^2 + y_2^2 +...y_{n-1}^2 + C^2)^\frac{n}{2}} dy = \frac{n\alpha(n)}{2C},"$$\int_{\mathbb{R}^{n-1}} \frac{1}{(y_1^2 + y_2^2 +...y_{n-1}^2 + C^2)^\frac{n}{2}} dy = \frac{n\alpha(n)}{2C}$$ where $\alpha(n)$ is the volume of the unit ball in $\mathbb{R}^n$. Could anyone help me with this integral? The proof about Green's function that I am reading says this is a direct calculation, but I couldn't see it. The original equation is  $$\frac{2x_n}{n\alpha(n)} \int_{\partial \mathbb{R}_+^n} \frac{1}{|x-y|^n} dS(y) = 1 \text{ for each } x\in \mathbb{R}^n.$$  First I would like to show this for $x = (0,0,..., C)$, and intuitively I know the first $n-1$ component of $x$ will not effect the calculation because $y = (y_1, ...y_{n-1}, 0)$ will range over the entire ${\partial \mathbb{R}_+^n}$. Thank you very much.","$$\int_{\mathbb{R}^{n-1}} \frac{1}{(y_1^2 + y_2^2 +...y_{n-1}^2 + C^2)^\frac{n}{2}} dy = \frac{n\alpha(n)}{2C}$$ where $\alpha(n)$ is the volume of the unit ball in $\mathbb{R}^n$. Could anyone help me with this integral? The proof about Green's function that I am reading says this is a direct calculation, but I couldn't see it. The original equation is  $$\frac{2x_n}{n\alpha(n)} \int_{\partial \mathbb{R}_+^n} \frac{1}{|x-y|^n} dS(y) = 1 \text{ for each } x\in \mathbb{R}^n.$$  First I would like to show this for $x = (0,0,..., C)$, and intuitively I know the first $n-1$ component of $x$ will not effect the calculation because $y = (y_1, ...y_{n-1}, 0)$ will range over the entire ${\partial \mathbb{R}_+^n}$. Thank you very much.",,"['real-analysis', 'integration', 'multivariable-calculus', 'partial-differential-equations', 'polar-coordinates']"
41,Loss functions for regression,Loss functions for regression,,"[From PRML Bishop, p:46] The average or expected loss function is given by $$E[L] = \int\int (y(x)-t)^2 p(x,t)\ \ dx\ \ dt$$, where, the loss function  $L = (y(x)-t)^2$, given x and the corresponding output t . To obtain the $y(x)$ which minimizes the expected loss,  $\frac {\partial E[L]}  {\partial  y(x)}$ is calculated and set to $0$. Which is the following: $$\frac {\partial E[L]}  {\partial  y(x)}=2\int\{y(x)-t\}p(x,t)dt$$ I am facing difficulty in doing this differentiation myself. Could anyone help? Very Thanks","[From PRML Bishop, p:46] The average or expected loss function is given by $$E[L] = \int\int (y(x)-t)^2 p(x,t)\ \ dx\ \ dt$$, where, the loss function  $L = (y(x)-t)^2$, given x and the corresponding output t . To obtain the $y(x)$ which minimizes the expected loss,  $\frac {\partial E[L]}  {\partial  y(x)}$ is calculated and set to $0$. Which is the following: $$\frac {\partial E[L]}  {\partial  y(x)}=2\int\{y(x)-t\}p(x,t)dt$$ I am facing difficulty in doing this differentiation myself. Could anyone help? Very Thanks",,"['calculus', 'multivariable-calculus', 'partial-derivative', 'machine-learning', 'bayesian']"
42,Integration over the intersection of the $n$-ball and a hyperplane,Integration over the intersection of the -ball and a hyperplane,n,"Let the $n$-ball of radius $r$, centred at $\mathbf{x}_0$, which will be denoted as the region  $$ U = \{\mathbf{x}\in\Bbb{R}^n\colon\|\mathbf{x}-\mathbf{x}_0\|^2\leq r^2\}, $$ and is shown in the figure below. Also let a function $f\colon\Bbb{R}^n\to\Bbb{R}$ defined as $$ f(\mathbf{x}) = \left\{ 	\begin{array}{ll} 		c  & \mbox{if } \mathbf{x}\in U \\ 		0  & \mbox{if } \mathbf{x}\notin U. 	\end{array} \right. $$ We would like to evaluate the following integral $$ I= \int_{\Omega}\! \Big[\mathbf{a}\cdot\mathbf{x}+b\Big]f(\mathbf{x}) \,\mathrm{d}\mathbf{x}, $$ where the region $\Omega$ is defined as the halfspace  $$ \Omega = \{\mathbf{x}\in\Bbb{R}^n\colon\mathbf{a}\cdot\mathbf{x}+b\geq0\}. $$ Apparently, this is equal (does this really hold?) to the following: $$ I= \int_{\Omega\cap U}\! c\Big[\mathbf{a}\cdot\mathbf{x}+b\Big] \,\mathrm{d}\mathbf{x}. $$ Any ideas on how to evaluate this integral in terms of $\mathbf{a}$, $b$, and $c$? Thank you in advance.","Let the $n$-ball of radius $r$, centred at $\mathbf{x}_0$, which will be denoted as the region  $$ U = \{\mathbf{x}\in\Bbb{R}^n\colon\|\mathbf{x}-\mathbf{x}_0\|^2\leq r^2\}, $$ and is shown in the figure below. Also let a function $f\colon\Bbb{R}^n\to\Bbb{R}$ defined as $$ f(\mathbf{x}) = \left\{ 	\begin{array}{ll} 		c  & \mbox{if } \mathbf{x}\in U \\ 		0  & \mbox{if } \mathbf{x}\notin U. 	\end{array} \right. $$ We would like to evaluate the following integral $$ I= \int_{\Omega}\! \Big[\mathbf{a}\cdot\mathbf{x}+b\Big]f(\mathbf{x}) \,\mathrm{d}\mathbf{x}, $$ where the region $\Omega$ is defined as the halfspace  $$ \Omega = \{\mathbf{x}\in\Bbb{R}^n\colon\mathbf{a}\cdot\mathbf{x}+b\geq0\}. $$ Apparently, this is equal (does this really hold?) to the following: $$ I= \int_{\Omega\cap U}\! c\Big[\mathbf{a}\cdot\mathbf{x}+b\Big] \,\mathrm{d}\mathbf{x}. $$ Any ideas on how to evaluate this integral in terms of $\mathbf{a}$, $b$, and $c$? Thank you in advance.",,"['real-analysis', 'integration', 'multivariable-calculus']"
43,Parametric representation of a line segment with boundaries,Parametric representation of a line segment with boundaries,,"Let $S$ be a subset of $\mathbb{R}^n$. $S$ is called convex if for all pairs of $(a, b)$, line segment from $b$ to $a$ is element of $S$. It is also given that $at + (1 - t)b$ is line segment between two vectors, for $0 < t < 1$. I can't see how $at+(1-t)b$ is found, and why boundary for $t$ is important.","Let $S$ be a subset of $\mathbb{R}^n$. $S$ is called convex if for all pairs of $(a, b)$, line segment from $b$ to $a$ is element of $S$. It is also given that $at + (1 - t)b$ is line segment between two vectors, for $0 < t < 1$. I can't see how $at+(1-t)b$ is found, and why boundary for $t$ is important.",,"['linear-algebra', 'multivariable-calculus', 'elementary-set-theory']"
44,$f:\mathbb{R}^n \to \mathbb{R}$ has expansion $\sum_i g_i(x)x^i$,has expansion,f:\mathbb{R}^n \to \mathbb{R} \sum_i g_i(x)x^i,"Problem 2-35 on page 34 of Spivak's Calculus on Manifolds states If $f: \mathbb{R}^n: \to \mathbb{R}$ is differentiable and $f(0) =0$,   prove that there exist $g_i: \mathbb{R}^n \to \mathbb{R}$ such that   $f(x) = \sum_{i=1}^n x^ig_i(x)$. Hint: if $h_x(t) = f(tx)$, then $f(x)  = \int_0^1 h_x'(t)$. I understand the answer he wants, but hasn't he left out a hypothesis that would ensure $h_x'(t)$ is integrable? (For instance the continuity of $df$.) Secondly, I'm wondering if this theorem is used anywhere. Perhaps in differential geometry it might be useful to write locally $f \in C^\infty (M)$ as $\sum_i g_i(x) x_i$ for some coordinates $x_i$.","Problem 2-35 on page 34 of Spivak's Calculus on Manifolds states If $f: \mathbb{R}^n: \to \mathbb{R}$ is differentiable and $f(0) =0$,   prove that there exist $g_i: \mathbb{R}^n \to \mathbb{R}$ such that   $f(x) = \sum_{i=1}^n x^ig_i(x)$. Hint: if $h_x(t) = f(tx)$, then $f(x)  = \int_0^1 h_x'(t)$. I understand the answer he wants, but hasn't he left out a hypothesis that would ensure $h_x'(t)$ is integrable? (For instance the continuity of $df$.) Secondly, I'm wondering if this theorem is used anywhere. Perhaps in differential geometry it might be useful to write locally $f \in C^\infty (M)$ as $\sum_i g_i(x) x_i$ for some coordinates $x_i$.",,"['multivariable-calculus', 'differential-geometry']"
45,Find the area of a subset of $\mathbb{R}^3$ given by an implicit relation.,Find the area of a subset of  given by an implicit relation.,\mathbb{R}^3,"Let x, y, z be real numbers and let  $A =  \begin{bmatrix} 1&x&x^{2} \\ 1&y&y^{2} \\ 1&z&z^{2} \end{bmatrix}  $ Let S be the subset of $\mathbf{R}^{3}$ given by $S = \{ (x,y,x) \in \mathbf{R}^{3} \: |\: x^{2}+y^{2}+z^{2} \leq 1 $, and det A=0$ \}$. Find the area of S. I'm assuming I need to use the surface area formula $A(S) = \iint_D \sqrt{1+ (\frac{\partial z}{\partial x})^{2} + (\frac{\partial z}{\partial x})^{2}}\,dx \,dy$. Expanding out the determinant directly becomes messy, so I think that I may be missing something.  Does the guaranteed linear dependence of the vectors help me somehow?  Also I know I do not have to solve for z explicitly to find the partial derivatives ($\frac{\partial z}{\partial x} $ and $ \frac{\partial z}{\partial y}$) but solving for the partial derivatives with implicit differentiation yields a solution in terms of z (as well as x and y). Finally, I am at a loss in determining the domain that I integrate over. Also this is my first time posting to stackexchange and first time using latex, so I apologize for any formatting issues.","Let x, y, z be real numbers and let  $A =  \begin{bmatrix} 1&x&x^{2} \\ 1&y&y^{2} \\ 1&z&z^{2} \end{bmatrix}  $ Let S be the subset of $\mathbf{R}^{3}$ given by $S = \{ (x,y,x) \in \mathbf{R}^{3} \: |\: x^{2}+y^{2}+z^{2} \leq 1 $, and det A=0$ \}$. Find the area of S. I'm assuming I need to use the surface area formula $A(S) = \iint_D \sqrt{1+ (\frac{\partial z}{\partial x})^{2} + (\frac{\partial z}{\partial x})^{2}}\,dx \,dy$. Expanding out the determinant directly becomes messy, so I think that I may be missing something.  Does the guaranteed linear dependence of the vectors help me somehow?  Also I know I do not have to solve for z explicitly to find the partial derivatives ($\frac{\partial z}{\partial x} $ and $ \frac{\partial z}{\partial y}$) but solving for the partial derivatives with implicit differentiation yields a solution in terms of z (as well as x and y). Finally, I am at a loss in determining the domain that I integrate over. Also this is my first time posting to stackexchange and first time using latex, so I apologize for any formatting issues.",,"['linear-algebra', 'multivariable-calculus', 'area']"
46,Calculate surface integral,Calculate surface integral,,"I need some help with the following: Given $$f(x,y,z)=\left( \frac{-x}{(x^2+y^2+z^2)^{\frac{3}{2}}}, \frac{-y}{(x^2+y^2+z^2)^{\frac32}}, \frac{-z}{(x^2+y^2+z^2)^{\frac32}} \right),$$ calculate the flow rate of fuid out of the total surface $S$, where $$S=\{(x,y,z)\; | \; x^2+y^2+z^2=1 \}.$$ I got $\displaystyle \frac{4\pi}{3}$ but I think I messed up with the normal vector. Any help would be really appreciated. Thank you!","I need some help with the following: Given $$f(x,y,z)=\left( \frac{-x}{(x^2+y^2+z^2)^{\frac{3}{2}}}, \frac{-y}{(x^2+y^2+z^2)^{\frac32}}, \frac{-z}{(x^2+y^2+z^2)^{\frac32}} \right),$$ calculate the flow rate of fuid out of the total surface $S$, where $$S=\{(x,y,z)\; | \; x^2+y^2+z^2=1 \}.$$ I got $\displaystyle \frac{4\pi}{3}$ but I think I messed up with the normal vector. Any help would be really appreciated. Thank you!",,"['integration', 'multivariable-calculus', 'surface-integrals']"
47,Set up integral in spherical coordinates outside cylinder but inside sphere,Set up integral in spherical coordinates outside cylinder but inside sphere,,"I have the equation of a cylinder and the equation of a sphere given: Cylinder: $x^2+y^2=4$ Sphere: $x^2+y^2+z^2=25$ I'm asked to set this up in cylindrical and spherical coordinates. Cylindrical was easy enough, but I'm having some trouble figuring out the limits for spherical. My first thought: $\int\limits_0^{2\pi}\int\limits_0^\pi\int\limits_2^5\rho^2\sin\phi\ d\rho\ d\phi\ d\theta$ I thought that in spherical $\rho$ is basically the radius so setting it from 2 to 5 would exclude the area of the cylinder but apparently it is not that simple.  Below is the answer my teacher gave and I'm not exactly sure what she did. Correct integral in spherical: $2\int\limits_0^{2\pi}\int\limits_{cos^{-1}(\frac{\sqrt{21}}{5})}^{\pi/2}\int\limits_{2\csc(\phi)}^5\rho^2\sin\phi\ d\rho\ d\phi\ d\theta$ The picture when graphed is just a sphere with radius 5 and a cylinder that cuts through the middle.  I'm not sure how my teacher got limits like $cos^{-1}(\frac{\sqrt{21}}{5})$ or $2\csc(\phi)$","I have the equation of a cylinder and the equation of a sphere given: Cylinder: $x^2+y^2=4$ Sphere: $x^2+y^2+z^2=25$ I'm asked to set this up in cylindrical and spherical coordinates. Cylindrical was easy enough, but I'm having some trouble figuring out the limits for spherical. My first thought: $\int\limits_0^{2\pi}\int\limits_0^\pi\int\limits_2^5\rho^2\sin\phi\ d\rho\ d\phi\ d\theta$ I thought that in spherical $\rho$ is basically the radius so setting it from 2 to 5 would exclude the area of the cylinder but apparently it is not that simple.  Below is the answer my teacher gave and I'm not exactly sure what she did. Correct integral in spherical: $2\int\limits_0^{2\pi}\int\limits_{cos^{-1}(\frac{\sqrt{21}}{5})}^{\pi/2}\int\limits_{2\csc(\phi)}^5\rho^2\sin\phi\ d\rho\ d\phi\ d\theta$ The picture when graphed is just a sphere with radius 5 and a cylinder that cuts through the middle.  I'm not sure how my teacher got limits like $cos^{-1}(\frac{\sqrt{21}}{5})$ or $2\csc(\phi)$",,"['integration', 'multivariable-calculus', 'spherical-coordinates']"
48,Surface area of this helicoid?,Surface area of this helicoid?,,"What is the surface area of the paramatized helicoid  $$X(r,s)=(r\cos(s), r\sin(s), s)$$  with $0\leq r \leq 1$ and $0\leq s \leq 2n\pi$, where $n$ is a positive integer? I attempted to take the standard normal vector with the two tangent vectors  $$T_r=(\cos(s),\sin(s),0) \text{ and } Ts=(-r\sin(s),r\cos(s), 1).$$ and I got the cross product of these two as $\sin(s)i+\cos(s)j+ rk$. Then when I took the length of this I got $\sqrt{r^2+1}$. I don't know how to integrate this function and I also wanted to be sure that I did the rest of the set up correctly.","What is the surface area of the paramatized helicoid  $$X(r,s)=(r\cos(s), r\sin(s), s)$$  with $0\leq r \leq 1$ and $0\leq s \leq 2n\pi$, where $n$ is a positive integer? I attempted to take the standard normal vector with the two tangent vectors  $$T_r=(\cos(s),\sin(s),0) \text{ and } Ts=(-r\sin(s),r\cos(s), 1).$$ and I got the cross product of these two as $\sin(s)i+\cos(s)j+ rk$. Then when I took the length of this I got $\sqrt{r^2+1}$. I don't know how to integrate this function and I also wanted to be sure that I did the rest of the set up correctly.",,"['calculus', 'multivariable-calculus']"
49,How to Evaluate this Multiple integral,How to Evaluate this Multiple integral,,"$$\int\!\!\!\int\!\!\!\int_{V}\frac{(b-x)\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z}{\left(\sqrt{(b-x)^2+y^2+z^2}\right)^3},(b>a>0)$$ $$V:x^2+y^2+z^2\leq a^2$$ Let $x=r\sin\varphi\cos\theta,y=r\sin\varphi\sin\theta,z=r\cos\varphi,J=r^2\sin\varphi.$but i still can't solve the problem.it's too complex to calculate.does anyone have a better way? what i think: $$\int\!\!\!\int\!\!\!\int_{V}\frac{(b-x)\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z}{\left(\sqrt{(b-x)^2+y^2+z^2}\right)^3}=\oint_{x^2+y^2+z^2= a^2} \frac{\:\mathrm{d}y\:\mathrm{d}z}{\sqrt{(b-x)^2+y^2+z^2}}$$ but it's still not easy to calculate","$$\int\!\!\!\int\!\!\!\int_{V}\frac{(b-x)\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z}{\left(\sqrt{(b-x)^2+y^2+z^2}\right)^3},(b>a>0)$$ $$V:x^2+y^2+z^2\leq a^2$$ Let $x=r\sin\varphi\cos\theta,y=r\sin\varphi\sin\theta,z=r\cos\varphi,J=r^2\sin\varphi.$but i still can't solve the problem.it's too complex to calculate.does anyone have a better way? what i think: $$\int\!\!\!\int\!\!\!\int_{V}\frac{(b-x)\:\mathrm{d}x\:\mathrm{d}y\:\mathrm{d}z}{\left(\sqrt{(b-x)^2+y^2+z^2}\right)^3}=\oint_{x^2+y^2+z^2= a^2} \frac{\:\mathrm{d}y\:\mathrm{d}z}{\sqrt{(b-x)^2+y^2+z^2}}$$ but it's still not easy to calculate",,"['multivariable-calculus', 'definite-integrals', 'volume']"
50,How to prove the existence of a vector potential for a solenoidal vector field?,How to prove the existence of a vector potential for a solenoidal vector field?,,"If $\textbf{F}$ is a vector field and $\bf{divF}=0$, how would you show that this implies the existence of a vector field $\bf{A}$ such that $\bf{F}=curl A $?","If $\textbf{F}$ is a vector field and $\bf{divF}=0$, how would you show that this implies the existence of a vector field $\bf{A}$ such that $\bf{F}=curl A $?",,"['calculus', 'multivariable-calculus']"
51,"$f: \mathbb{R}^2\to \mathbb{R}^2$ is differentiable, and satisfies an inequality that involves its partials - show that f is a bijection.","is differentiable, and satisfies an inequality that involves its partials - show that f is a bijection.",f: \mathbb{R}^2\to \mathbb{R}^2,"Suppose that $f: \mathbb{R}^2\to \mathbb{R}^2$ is differentiable, and the partial derivatives of the components $f_1$, $f_2$ satisfy $$max(|\frac{\ df_1}{dx} -1|, |\frac{df_1}{d_y}|, |\frac{df_2}{d_x}|, |\frac{df_2}{d_y}-1|) <10^{-10}.$$ Prove that f is a bijection.  Note: f is not assumed to be continuously differentiable. Any ideas on how to tackle this problem? We don't have an explicit function given for f, unfortunately.  And I can't assume that f $\in$ $C^1$, let alone assume that f is as smooth as we want it to be, so that rules out the usage of the Inverse and Implicit Function Theorems. Thanks in advance, edit:  I can view the objects that we are taking the maximum of...as a row vector.  Then express this row vector as a 2x2 matrix of the form: $$         \begin{bmatrix}         \frac{\ df_1}{dx} -1 & \frac{df_1}{d_y} \\          \frac{df_2}{d_x}& \frac{df_2}{d_y}-1 \\                \end{bmatrix} $$ I observe that this is just the total derivative matrix of the function f, minus the identity matrix, i.e. we have g:= Df - I. Using the inequality that we are given, we have that the sup norm of the matrix < $10^{-10}$. Where can I go from here?","Suppose that $f: \mathbb{R}^2\to \mathbb{R}^2$ is differentiable, and the partial derivatives of the components $f_1$, $f_2$ satisfy $$max(|\frac{\ df_1}{dx} -1|, |\frac{df_1}{d_y}|, |\frac{df_2}{d_x}|, |\frac{df_2}{d_y}-1|) <10^{-10}.$$ Prove that f is a bijection.  Note: f is not assumed to be continuously differentiable. Any ideas on how to tackle this problem? We don't have an explicit function given for f, unfortunately.  And I can't assume that f $\in$ $C^1$, let alone assume that f is as smooth as we want it to be, so that rules out the usage of the Inverse and Implicit Function Theorems. Thanks in advance, edit:  I can view the objects that we are taking the maximum of...as a row vector.  Then express this row vector as a 2x2 matrix of the form: $$         \begin{bmatrix}         \frac{\ df_1}{dx} -1 & \frac{df_1}{d_y} \\          \frac{df_2}{d_x}& \frac{df_2}{d_y}-1 \\                \end{bmatrix} $$ I observe that this is just the total derivative matrix of the function f, minus the identity matrix, i.e. we have g:= Df - I. Using the inequality that we are given, we have that the sup norm of the matrix < $10^{-10}$. Where can I go from here?",,"['real-analysis', 'multivariable-calculus', 'derivatives', 'vector-analysis', 'partial-derivative']"
52,Finding Triangle with constant perimeter and largest area (Lagrange Multiplier),Finding Triangle with constant perimeter and largest area (Lagrange Multiplier),,"Question is to find Finding Triangle with constant perimeter and largest area by method of lagrange multiplier . What i have done is that i have firstly taken $x+y+z=2k$ , where x,y,z are sides of triangle..k is any constant Then  i use Heron's formula as $\sqrt{s(s-x)(s-y)(s-z)}$ ,  where $s = (x +y+z)/2$ .... Since Area  = $\sqrt{s(s-x)(s-y)(s-z)}$ So substituting values of $s$  and replacing $z$ by $2k-x-y$ (to make it to two variable problem ) i finally get $f(x,y) = k(k-x)(k-y)(x+y-k)$   ...($A$ is squared so as to be easy easy derivatives) And my constraint equation is $g=x+y+z-2k=0 $  .....But problem here is that constraint consists z also . So i feel stuck to use LAGRANGE MULTIPLIER Method.....Can any1 help me furthure what to do from here .THANKS","Question is to find Finding Triangle with constant perimeter and largest area by method of lagrange multiplier . What i have done is that i have firstly taken $x+y+z=2k$ , where x,y,z are sides of triangle..k is any constant Then  i use Heron's formula as $\sqrt{s(s-x)(s-y)(s-z)}$ ,  where $s = (x +y+z)/2$ .... Since Area  = $\sqrt{s(s-x)(s-y)(s-z)}$ So substituting values of $s$  and replacing $z$ by $2k-x-y$ (to make it to two variable problem ) i finally get $f(x,y) = k(k-x)(k-y)(x+y-k)$   ...($A$ is squared so as to be easy easy derivatives) And my constraint equation is $g=x+y+z-2k=0 $  .....But problem here is that constraint consists z also . So i feel stuck to use LAGRANGE MULTIPLIER Method.....Can any1 help me furthure what to do from here .THANKS",,"['multivariable-calculus', 'lagrange-multiplier']"
53,Distance between plane and elliptic paraboloid,Distance between plane and elliptic paraboloid,,Find a point on the plane $z = x + y - 2$ and a point on the surface $z = x^2 + y^2$ such that the distance between them is minimized. I know what is happening. But I just don't know where to start. I am self-teaching vector calculus. Any help would be appreciated! Thanks in advance.,Find a point on the plane $z = x + y - 2$ and a point on the surface $z = x^2 + y^2$ such that the distance between them is minimized. I know what is happening. But I just don't know where to start. I am self-teaching vector calculus. Any help would be appreciated! Thanks in advance.,,"['multivariable-calculus', 'optimization', 'vector-analysis']"
54,epsilon-delta limit with multiple variables,epsilon-delta limit with multiple variables,,"I am getting confused with this epsilon delta proof of the limit for this particular case. Prove that $\lim_{(x,y)\to(0,0)} (2x^2+3y^2)=0.$ if the limit is equal to zero, then for any given positive epsilon there exists some positive delta, such that $0$ so in this case i have $|2x^2+3y^2|$ I cannot seem to find the way to express delta in epsilon terms  I feel like i need to find the relationship between the given function and the $\sqrt{x^2+y^2}$","I am getting confused with this epsilon delta proof of the limit for this particular case. Prove that $\lim_{(x,y)\to(0,0)} (2x^2+3y^2)=0.$ if the limit is equal to zero, then for any given positive epsilon there exists some positive delta, such that $0$ so in this case i have $|2x^2+3y^2|$ I cannot seem to find the way to express delta in epsilon terms  I feel like i need to find the relationship between the given function and the $\sqrt{x^2+y^2}$",,"['real-analysis', 'multivariable-calculus', 'epsilon-delta']"
55,Doubt on a paragraph regarding Lagrange's multiplier.,Doubt on a paragraph regarding Lagrange's multiplier.,,"I've a topic in my notes "" The method of Lagrange's multipliers "" which is described as follows: Let $U$ be an open set in $\mathbb R^n$.Let $f\in C^1(U,\mathbb R)$ and let   $$g_i(x)=0,~~~~~~~~i=1,\ldots,m$$ be a collection of equality constraints with $m\lt n$.Now consider the system of non-linear equations$$f(x)=a$$ $$g_i(x)=0,~~~~i=1,\ldots,m$$ $x_0\in U$ is a local maximum if $f(x_0\geq f(x)$ for all $x\in U$ near $x_0$ which also satisfies the above constrints.A local minimum is defined similarly. Let $F:U\times \mathbb R\to \mathbb R^{m+1}$ be defined by $$F(x,a)=\left[ \begin{array}{ccc} f(x)-a  \\  g_1(x)\\ \vdots \\ g_m(x)\end{array} \right] $$ Now consider the $m+1\times n$ Jacobian matrix ,the matrix of linear transformation , $F'(x,a)$ w.rt. usual basis for $\mathbb R^n$ and $\mathbb R^{m+1}$ at $x_0$ : $$\left[ \begin{array}{ccc} \partial_1 f(x_0) \ldots \partial_n f(x_0) \\  \partial_1g_1(x_0)\ldots \partial_n g_1(x_0)\\ \vdots ~~~~~~~~~~~~\vdots\\\partial_1 g_m(x_0) \ldots\partial_n g_1(x_0)\end{array} \right] $$ If this matrix has rank $m+1$ then some $m+1\times m+1$ sub matrix has non-zero determinant.It follows from the implicit function theorem that there exist $m+1$ variables $x_{i_1},\ldots,x_{i_{m+1}}$ such that the system $$F(x,a)=0$$ specifies these $m+1$ variables as a function of remaining $n-(m+1)$ variables and $a$ in an open set of $\mathbb R^{n-m}$ . Thus ,there is a solution $(x,a)$ to equation $F(x,a)=0$ for some $x$ close $x_0$ whenever $a$ is in some open interval . Therefore , $x_0$ cannot be local maximum or minimum.  If $x_0$ is either a local maximum or minimum ,then the above matrix must have rank less than $m+1$ which reqiures the rows to be linearly dependent. Thus   ,$\exists m$ scalars $\lambda_1,\ldots,\lambda_m$ and a scalar $\mu$ not all zero s.t.: >$\mu\left[ \begin{array}{ccc} \partial_1f(x_0)\\  \vdots \\ \partial_nf(x_0)\end{array} \right] $ = $\lambda_1\left[ \begin{array}{ccc} \partial_1g_1(x_0)\\  \vdots \\ \partial_ng_1(x_0)\end{array} \right] $+$\ldots$ +$\lambda_m\left[ \begin{array}{ccc} \partial_1g_m(x_0)\\  \vdots \\ \partial_ng_m(x_0)\end{array} \right] $ I have the following doubts from the above extract: $1.)$ for what purpose did we define  : $$F(x,a)=\left[ \begin{array}{ccc} f(x)-a  \\  g_1(x)\\ \vdots \\ g_m(x)\end{array} \right] $$ $2.)$ I can't understand how is it concluded that : "" Therefore ,$x_0$ cannot be local maximum or minimum."" Please if anyone can help me with these doubts...","I've a topic in my notes "" The method of Lagrange's multipliers "" which is described as follows: Let $U$ be an open set in $\mathbb R^n$.Let $f\in C^1(U,\mathbb R)$ and let   $$g_i(x)=0,~~~~~~~~i=1,\ldots,m$$ be a collection of equality constraints with $m\lt n$.Now consider the system of non-linear equations$$f(x)=a$$ $$g_i(x)=0,~~~~i=1,\ldots,m$$ $x_0\in U$ is a local maximum if $f(x_0\geq f(x)$ for all $x\in U$ near $x_0$ which also satisfies the above constrints.A local minimum is defined similarly. Let $F:U\times \mathbb R\to \mathbb R^{m+1}$ be defined by $$F(x,a)=\left[ \begin{array}{ccc} f(x)-a  \\  g_1(x)\\ \vdots \\ g_m(x)\end{array} \right] $$ Now consider the $m+1\times n$ Jacobian matrix ,the matrix of linear transformation , $F'(x,a)$ w.rt. usual basis for $\mathbb R^n$ and $\mathbb R^{m+1}$ at $x_0$ : $$\left[ \begin{array}{ccc} \partial_1 f(x_0) \ldots \partial_n f(x_0) \\  \partial_1g_1(x_0)\ldots \partial_n g_1(x_0)\\ \vdots ~~~~~~~~~~~~\vdots\\\partial_1 g_m(x_0) \ldots\partial_n g_1(x_0)\end{array} \right] $$ If this matrix has rank $m+1$ then some $m+1\times m+1$ sub matrix has non-zero determinant.It follows from the implicit function theorem that there exist $m+1$ variables $x_{i_1},\ldots,x_{i_{m+1}}$ such that the system $$F(x,a)=0$$ specifies these $m+1$ variables as a function of remaining $n-(m+1)$ variables and $a$ in an open set of $\mathbb R^{n-m}$ . Thus ,there is a solution $(x,a)$ to equation $F(x,a)=0$ for some $x$ close $x_0$ whenever $a$ is in some open interval . Therefore , $x_0$ cannot be local maximum or minimum.  If $x_0$ is either a local maximum or minimum ,then the above matrix must have rank less than $m+1$ which reqiures the rows to be linearly dependent. Thus   ,$\exists m$ scalars $\lambda_1,\ldots,\lambda_m$ and a scalar $\mu$ not all zero s.t.: >$\mu\left[ \begin{array}{ccc} \partial_1f(x_0)\\  \vdots \\ \partial_nf(x_0)\end{array} \right] $ = $\lambda_1\left[ \begin{array}{ccc} \partial_1g_1(x_0)\\  \vdots \\ \partial_ng_1(x_0)\end{array} \right] $+$\ldots$ +$\lambda_m\left[ \begin{array}{ccc} \partial_1g_m(x_0)\\  \vdots \\ \partial_ng_m(x_0)\end{array} \right] $ I have the following doubts from the above extract: $1.)$ for what purpose did we define  : $$F(x,a)=\left[ \begin{array}{ccc} f(x)-a  \\  g_1(x)\\ \vdots \\ g_m(x)\end{array} \right] $$ $2.)$ I can't understand how is it concluded that : "" Therefore ,$x_0$ cannot be local maximum or minimum."" Please if anyone can help me with these doubts...",,"['multivariable-calculus', 'lagrange-multiplier', 'proof-explanation']"
56,necessity of continuous partial derivatives?,necessity of continuous partial derivatives?,,"In my old book in calculus, it says that a sufficient condition for the function $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ to be differentiable at an internal point z, is that the partial derivatives exist at z and are continuous there. Is this also a necessairy condition? Or is there a function defined in a domain areound z, where the function is differentiable at z, but there is no domain around z where the partial derivatives are continuous?","In my old book in calculus, it says that a sufficient condition for the function $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ to be differentiable at an internal point z, is that the partial derivatives exist at z and are continuous there. Is this also a necessairy condition? Or is there a function defined in a domain areound z, where the function is differentiable at z, but there is no domain around z where the partial derivatives are continuous?",,"['calculus', 'real-analysis', 'multivariable-calculus', 'continuity', 'partial-derivative']"
57,"Is $(0,0)$ a local minima,local maxima or the saddle point?","Is  a local minima,local maxima or the saddle point?","(0,0)","$f(x,y)=5x^2+xy^3-3x^2y$ Is $(0,0)$ a local minima,local maxima or the saddle point? My attempt:I calculated $$f_{xx}(0,0)=10, \hspace{0.3cm}f_{xy}(0,0)=0, \hspace{0.3cm}f_{yy}(0,0)=0$$ So $$f_{xx}(0,0)f_{yy}(0,0)-(f_{xy}(0,0))^2=0$$ I concluded nothing from this test.I do not know other method to solve this problem.Please help me. Thanks.","$f(x,y)=5x^2+xy^3-3x^2y$ Is $(0,0)$ a local minima,local maxima or the saddle point? My attempt:I calculated $$f_{xx}(0,0)=10, \hspace{0.3cm}f_{xy}(0,0)=0, \hspace{0.3cm}f_{yy}(0,0)=0$$ So $$f_{xx}(0,0)f_{yy}(0,0)-(f_{xy}(0,0))^2=0$$ I concluded nothing from this test.I do not know other method to solve this problem.Please help me. Thanks.",,"['calculus', 'algebra-precalculus', 'multivariable-calculus']"
58,"Can the partial derivative of f(x,y) at (a,b) exist if f(x,y) is not continuous at (a,b)?","Can the partial derivative of f(x,y) at (a,b) exist if f(x,y) is not continuous at (a,b)?",,"Suppose f(x,y) is continuous for all $(x,y) \neq (a,b)$, (not continuous at (a,b)), can the partial derivative with respect to x (or y) at (a,b) still exist?","Suppose f(x,y) is continuous for all $(x,y) \neq (a,b)$, (not continuous at (a,b)), can the partial derivative with respect to x (or y) at (a,b) still exist?",,['multivariable-calculus']
59,"Evaluate the integral $\iiint\limits_E x^2 \,\, \mathrm{d}V$",Evaluate the integral,"\iiint\limits_E x^2 \,\, \mathrm{d}V","Where E is the region bounded by the xz-plane and the hemispheres $y=\sqrt{9-x^2-z^2}$ and $y=\sqrt{16-x^2-z^2}$. This is an exercise from my professor guide. What I tried so far: These exercise is obviously easier using spherical coordinates, with that in mind I've come up with the following limits: $ 3 \le \rho \le 4 \\ 0 \le \phi \le \pi \\ 0 \le \theta\ \le \pi $ That is, the sphere cap formed by the 2 semi-spheres, more or less the volume described between the 2 surfaces in the image: With the limits already established, I constructed the following integral: $\int_0^\pi \int_0^\pi \int_3^4 \, \cos^2{(\theta)} \sin^3{(\phi)} \, \rho^4 \,\, \mathrm{d}\rho \, \mathrm{d}\phi \, \mathrm{d}\theta$ $= \frac{1562}{15}\pi$ However, the solution tha appears in the guide says that the result is: $\frac{3124}{15}\pi$ Is there anything I'm doing wrong? I checked the exercise twice and I get the correct result IF I set the limits of $\theta$ from $0$ to $2\pi$, but that is the whole spherical surface not just the half described by the exercise. Best regards, Daniel Rivas.","Where E is the region bounded by the xz-plane and the hemispheres $y=\sqrt{9-x^2-z^2}$ and $y=\sqrt{16-x^2-z^2}$. This is an exercise from my professor guide. What I tried so far: These exercise is obviously easier using spherical coordinates, with that in mind I've come up with the following limits: $ 3 \le \rho \le 4 \\ 0 \le \phi \le \pi \\ 0 \le \theta\ \le \pi $ That is, the sphere cap formed by the 2 semi-spheres, more or less the volume described between the 2 surfaces in the image: With the limits already established, I constructed the following integral: $\int_0^\pi \int_0^\pi \int_3^4 \, \cos^2{(\theta)} \sin^3{(\phi)} \, \rho^4 \,\, \mathrm{d}\rho \, \mathrm{d}\phi \, \mathrm{d}\theta$ $= \frac{1562}{15}\pi$ However, the solution tha appears in the guide says that the result is: $\frac{3124}{15}\pi$ Is there anything I'm doing wrong? I checked the exercise twice and I get the correct result IF I set the limits of $\theta$ from $0$ to $2\pi$, but that is the whole spherical surface not just the half described by the exercise. Best regards, Daniel Rivas.",,"['integration', 'multivariable-calculus', 'definite-integrals', 'volume', 'spherical-coordinates']"
60,"Example of a function $F(x,y)$",Example of a function,"F(x,y)","I'm trying to find a non trivial function $F(x,y)$ such that $div F(x,y)=0$ everywhere and $F(x,y)=0$ on the unit square. I know that there are some books that provide such example but I didn't find anything. Thanks for your help","I'm trying to find a non trivial function $F(x,y)$ such that $div F(x,y)=0$ everywhere and $F(x,y)=0$ on the unit square. I know that there are some books that provide such example but I didn't find anything. Thanks for your help",,"['multivariable-calculus', 'functions', 'examples-counterexamples']"
61,"Derivative: $f_x, f_y, f_{xy}$ of function - $f(x,y)$",Derivative:  of function -,"f_x, f_y, f_{xy} f(x,y)","Let's say $f(x,y) = x^2 + 2xy +y^2$ $f'_x = 2x + 2y$ $f'_y = 2y + 2x$ $f'_{xy} = 2x + 2y$ ? Am I right about the third?","Let's say $f(x,y) = x^2 + 2xy +y^2$ $f'_x = 2x + 2y$ $f'_y = 2y + 2x$ $f'_{xy} = 2x + 2y$ ? Am I right about the third?",,"['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative']"
62,Third Order PDE written as a System of (Linear) First Order PDEs,Third Order PDE written as a System of (Linear) First Order PDEs,,"I need to rewrite the PDE $$f_{y}+ff_{x}+f_{xxx}=0,$$ where $f=f(x,y)$ as a system of first order quasi-linear PDEs. I have no idea how to tackle this problem. Any form of help will be appreciated. Are there any methodologies for such questions? Thanks, Jay.","I need to rewrite the PDE $$f_{y}+ff_{x}+f_{xxx}=0,$$ where $f=f(x,y)$ as a system of first order quasi-linear PDEs. I have no idea how to tackle this problem. Any form of help will be appreciated. Are there any methodologies for such questions? Thanks, Jay.",,"['multivariable-calculus', 'reference-request', 'partial-differential-equations']"
63,Find maximum of $P$,Find maximum of,P,"Let $$P = \frac{{{x^2}}}{{{x^2} + yz + x + 1}} + \frac{{y + z}}{{x + y + z + 1}} - \frac{{1 + yz}}{9}.$$  Find maximum of $P$  where $x, y,z$ are nonnegative real numbers such that ${x^2} + {y^2} + {z^2} = 2$. I guess $\max P=\dfrac{5}{9}$ when $x=y=1, z=0$. But I can not prove.","Let $$P = \frac{{{x^2}}}{{{x^2} + yz + x + 1}} + \frac{{y + z}}{{x + y + z + 1}} - \frac{{1 + yz}}{9}.$$  Find maximum of $P$  where $x, y,z$ are nonnegative real numbers such that ${x^2} + {y^2} + {z^2} = 2$. I guess $\max P=\dfrac{5}{9}$ when $x=y=1, z=0$. But I can not prove.",,"['multivariable-calculus', 'inequality', 'optimization']"
64,Cauchy inequality proof,Cauchy inequality proof,,"I am studying cauchy inequality proof from notes I have from my class$$(\forall\vec{x},\vec{y}\in\mathbb{R}^n):|\sum_{i=1}^{n}x_iy_i|\le||\vec{x}||\cdot||\vec{y}||$$ We choose  $\vec{x},\vec{y}$. And also this notation is used $<\vec{a},\vec{b}>=\sum_{i=1}^{n}a_ib_i$. For any $r\in\mathbb{R}$ we have: $$0\le <\vec{x}+r\vec{y},\vec{x}+r\vec{y}>=...=<\vec{y},\vec{y}>r^2+2<\vec{x},\vec{y}>r+<\vec{x},\vec{x}>$$ Now we set the discriminant $D\le0$ $$4<\vec{x},\vec{y}>-4<\vec{y},\vec{y}><\vec{x},\vec{x}>\le0$$ Here is one thing I don't undestand, since $D=b^2-4ac$ and $b=2<\vec{x},\vec{y}>$ why it's not $$4<\vec{x},\vec{y}>^2-4<\vec{y},\vec{y}><\vec{x},\vec{x}>\le0$$ It might be trivial but I don't see it(or I might have copied my notes wrong). The rest of the proof follows as this: $$<\vec{x},\vec{y}>\le<\vec{y},\vec{y}><\vec{x},\vec{x}>$$ $$\sum_{i=1}^{n}x_iy_i\le\sum_{i=1}^{n}x_i^2\sum_{i=1}^{n}y_i^2$$ $$\sum_{i=1}^{n}x_iy_i\le||\vec{x}||\cdot||\vec{y}||$$","I am studying cauchy inequality proof from notes I have from my class$$(\forall\vec{x},\vec{y}\in\mathbb{R}^n):|\sum_{i=1}^{n}x_iy_i|\le||\vec{x}||\cdot||\vec{y}||$$ We choose  $\vec{x},\vec{y}$. And also this notation is used $<\vec{a},\vec{b}>=\sum_{i=1}^{n}a_ib_i$. For any $r\in\mathbb{R}$ we have: $$0\le <\vec{x}+r\vec{y},\vec{x}+r\vec{y}>=...=<\vec{y},\vec{y}>r^2+2<\vec{x},\vec{y}>r+<\vec{x},\vec{x}>$$ Now we set the discriminant $D\le0$ $$4<\vec{x},\vec{y}>-4<\vec{y},\vec{y}><\vec{x},\vec{x}>\le0$$ Here is one thing I don't undestand, since $D=b^2-4ac$ and $b=2<\vec{x},\vec{y}>$ why it's not $$4<\vec{x},\vec{y}>^2-4<\vec{y},\vec{y}><\vec{x},\vec{x}>\le0$$ It might be trivial but I don't see it(or I might have copied my notes wrong). The rest of the proof follows as this: $$<\vec{x},\vec{y}>\le<\vec{y},\vec{y}><\vec{x},\vec{x}>$$ $$\sum_{i=1}^{n}x_iy_i\le\sum_{i=1}^{n}x_i^2\sum_{i=1}^{n}y_i^2$$ $$\sum_{i=1}^{n}x_iy_i\le||\vec{x}||\cdot||\vec{y}||$$",,"['multivariable-calculus', 'metric-spaces', 'proof-verification']"
65,Unique solution for parametric system of two equations,Unique solution for parametric system of two equations,,"The system is: $$x - 2y + z = 2\alpha \\ 3(xy + xz + yz) = 3\alpha - 4$$ I have to find for which values of $\alpha$, the system has an unique solution. I've tried to simplify both expressions, set $x,y,z$ to some special values, and even apply some well-known inequalities to check for validity. Any hint will be greatly appreciated!","The system is: $$x - 2y + z = 2\alpha \\ 3(xy + xz + yz) = 3\alpha - 4$$ I have to find for which values of $\alpha$, the system has an unique solution. I've tried to simplify both expressions, set $x,y,z$ to some special values, and even apply some well-known inequalities to check for validity. Any hint will be greatly appreciated!",,['multivariable-calculus']
66,Double integral involving zeta function: $\int_0^\infty \frac{1-12y^2}{(1+4y^2)^3}\int_{1/2}^{\infty}\log|\zeta(x+iy)|~dx ~dy.$,Double integral involving zeta function:,\int_0^\infty \frac{1-12y^2}{(1+4y^2)^3}\int_{1/2}^{\infty}\log|\zeta(x+iy)|~dx ~dy.,I'm having trouble evaluating the following double integral: $$\int_0^\infty \frac{1-12y^2}{(1+4y^2)^3}\int_{1/2}^{\infty}\log|\zeta(x+iy)|~dx ~dy.$$ Do please remark that $\zeta$ is the zeta function. I don't even really know where to start. Please offer any hints.,I'm having trouble evaluating the following double integral: $$\int_0^\infty \frac{1-12y^2}{(1+4y^2)^3}\int_{1/2}^{\infty}\log|\zeta(x+iy)|~dx ~dy.$$ Do please remark that $\zeta$ is the zeta function. I don't even really know where to start. Please offer any hints.,,"['integration', 'multivariable-calculus', 'improper-integrals']"
67,The meaning of Differentials in Integration,The meaning of Differentials in Integration,,"This is further to the questions discussed in a previous post Here is an example of what I mean: Suppose that $C$ is a closed path in the plane and consider the line integral of $xy\,dx+x^2\,dy$ over $C$. Note that this can be written as $$\oint_C x\,d(xy)$$ Question: If we let $A$ denote the starting and ending point of the path, is it valid to use ""Integration by Parts"" to write $$\oint_C x\,d(xy)=x\cdot xy\bigg|_A^A -\oint_C xy\cdot dx=-\oint_C xy\cdot dx$$ Note that the claim is valid , as the sum of the two integrands is $2xy\,dx+x^2\,dy$ which is conservative, being the gradient of $f(x,y)=x^2y$. Therefore the sum of the two integrals in the last equation is zero, hence they are negatives of each other. (And obviously, the second integral will usually be more desirable to compute than the first.) But what does this mean, and why is it true? More generally, I think it would insightful to have a discussion about differentials in the context of integration and how/why the Leibniz notation can or cannot be used to intuitively understand calculations such as the above. And how can we interpret differentials of general quantities which may involve several variables, as opposed to just single ones? Does the expression $d(xy)$ only make sense in the context of a path $C$, where we can view it as the change in $g(x,y)=xy$ over small segments of that curve, or does it admit a broader interpretation?","This is further to the questions discussed in a previous post Here is an example of what I mean: Suppose that $C$ is a closed path in the plane and consider the line integral of $xy\,dx+x^2\,dy$ over $C$. Note that this can be written as $$\oint_C x\,d(xy)$$ Question: If we let $A$ denote the starting and ending point of the path, is it valid to use ""Integration by Parts"" to write $$\oint_C x\,d(xy)=x\cdot xy\bigg|_A^A -\oint_C xy\cdot dx=-\oint_C xy\cdot dx$$ Note that the claim is valid , as the sum of the two integrands is $2xy\,dx+x^2\,dy$ which is conservative, being the gradient of $f(x,y)=x^2y$. Therefore the sum of the two integrals in the last equation is zero, hence they are negatives of each other. (And obviously, the second integral will usually be more desirable to compute than the first.) But what does this mean, and why is it true? More generally, I think it would insightful to have a discussion about differentials in the context of integration and how/why the Leibniz notation can or cannot be used to intuitively understand calculations such as the above. And how can we interpret differentials of general quantities which may involve several variables, as opposed to just single ones? Does the expression $d(xy)$ only make sense in the context of a path $C$, where we can view it as the change in $g(x,y)=xy$ over small segments of that curve, or does it admit a broader interpretation?",,['multivariable-calculus']
68,Total derivative,Total derivative,,What is the significance and meaning of the total derivative? Why is it introduced in the definition of differentiability of scalar and vector fields?,What is the significance and meaning of the total derivative? Why is it introduced in the definition of differentiability of scalar and vector fields?,,"['multivariable-calculus', 'derivatives', 'partial-derivative']"
69,please help me to do Triple integral,please help me to do Triple integral,,Integrate over the region in the first octant above the parabolic cylinder and below the paraboloid I could not get the limits right even that I tried many one but I still could not get it,Integrate over the region in the first octant above the parabolic cylinder and below the paraboloid I could not get the limits right even that I tried many one but I still could not get it,,"['integration', 'multivariable-calculus']"
70,"How to plot a surface in maple where the range is given by an expression, not constants?","How to plot a surface in maple where the range is given by an expression, not constants?",,"Im trying to plot the surface $z=(1+x^2)/(1+y^2)$ , but specifically the part of the surface that is above $|x|+|y|\leq1$. Cant seem to find any information on how to produce a plot in maple, where your range is given by an expression, and not specific constants.","Im trying to plot the surface $z=(1+x^2)/(1+y^2)$ , but specifically the part of the surface that is above $|x|+|y|\leq1$. Cant seem to find any information on how to produce a plot in maple, where your range is given by an expression, and not specific constants.",,"['multivariable-calculus', 'surfaces', 'maple']"
71,Prove $\nabla f$ is orthogonal to the surface $f$,Prove  is orthogonal to the surface,\nabla f f,"I'm trying to prove that $\nabla f$ is orthogonal to the surface $f$. I think I have a valid proof but I'm not sure that it is rigorous. To prove $\nabla f$ is normal  I am proving that $\nabla f\cdot u=0$ for any vector $u$ tangent to the surface $f$. Say $z=f(x,y)$ then $\nabla f$ $= \left(\begin{array}{c} \delta_x\\ \delta_y\end{array}\right)$ and choosing any vector $v=(v_1,v_2)$ we need to construct the tangent vector to the surface. The tangent vector is $(v_1,v_2,f'_u$( x )). We achieve $f'_u$( x ) from $\nabla f\cdot u$ which gives us $f'_u$( x )$= v_1\delta_x + v_2\delta_y$. Therefore the tangent vector is $u=(v_1,v_2,v_1\delta_x+v_2\delta_y)$. Now we can dot $\nabla f$ with $u$. However now I came across the problem that we had one vector with 3 rows and one with 2 rows. Therefore I redefined $\nabla f$ and called a new fucntion $g(x,y,z)=f(x,y)-z$ at the level set $g(x,y,z)=0$. Now $\nabla g$ has three components and $$\nabla g=(\delta_x,\delta_y,-1)$$ I then took the dot product of $\nabla g$ and $u$ and this gave $$v_1\delta_x+v_2\delta_y-(v_1\delta_x+v_2\delta_y)=0$$ Therefore $\nabla g$ is orthogonal to the level set $g(x,y,z)=0$ and by equivalence $\nabla f$ is orthogonal to the surface $f(x,y)$. Now that is I'm guessing that's a long way round but would you class it as rigorous? Any suggestions to improve it? Is there any way to not have to use $g(x,y,z)$? Thanks","I'm trying to prove that $\nabla f$ is orthogonal to the surface $f$. I think I have a valid proof but I'm not sure that it is rigorous. To prove $\nabla f$ is normal  I am proving that $\nabla f\cdot u=0$ for any vector $u$ tangent to the surface $f$. Say $z=f(x,y)$ then $\nabla f$ $= \left(\begin{array}{c} \delta_x\\ \delta_y\end{array}\right)$ and choosing any vector $v=(v_1,v_2)$ we need to construct the tangent vector to the surface. The tangent vector is $(v_1,v_2,f'_u$( x )). We achieve $f'_u$( x ) from $\nabla f\cdot u$ which gives us $f'_u$( x )$= v_1\delta_x + v_2\delta_y$. Therefore the tangent vector is $u=(v_1,v_2,v_1\delta_x+v_2\delta_y)$. Now we can dot $\nabla f$ with $u$. However now I came across the problem that we had one vector with 3 rows and one with 2 rows. Therefore I redefined $\nabla f$ and called a new fucntion $g(x,y,z)=f(x,y)-z$ at the level set $g(x,y,z)=0$. Now $\nabla g$ has three components and $$\nabla g=(\delta_x,\delta_y,-1)$$ I then took the dot product of $\nabla g$ and $u$ and this gave $$v_1\delta_x+v_2\delta_y-(v_1\delta_x+v_2\delta_y)=0$$ Therefore $\nabla g$ is orthogonal to the level set $g(x,y,z)=0$ and by equivalence $\nabla f$ is orthogonal to the surface $f(x,y)$. Now that is I'm guessing that's a long way round but would you class it as rigorous? Any suggestions to improve it? Is there any way to not have to use $g(x,y,z)$? Thanks",,"['multivariable-calculus', 'proof-verification']"
72,How to find the equation of a plane containing a given point and perpendicular to a given line?,How to find the equation of a plane containing a given point and perpendicular to a given line?,,"I am asked to find the plane that contains the point $(-4, 7, -3)$ and is perpendicular to the line defined by the parametric equations $x = -4 + t$, $y = 7 + 3t$ and $z = -2t$. Now, I know that if $n = (a, b, c)$ is a normal vector to a plane $P$ and if $r_{0} = (x_{0}, y_{0}, z_{0})$ is a point in the plane, then $$P = \{ r: n \cdot (r - r_{0}) = 0 \} = \{ (x, y, z): a (x - x_{0}) + b (y - y_{0}) + c (z - z_{0}) = 0 \},$$ so I thought I just had to take a particular point in the line and call it $n$, then call $r_{0} = (-4, 7, -3)$ and apply the aforementioned equation, but I think there is something wrong with this approach since the four possible answers to the exercise are: \begin{equation} x - 3y - 2z = 21 \end{equation} \begin{equation} 3x +y - 2z = 23 \end{equation} \begin{equation} x + 3y - 2z = 23 \end{equation} \begin{equation} x + 3y +z = 21, \end{equation} leaving the possible choices of $n$ to $(1, -3, -2)$, $(3, 1, -2)$, $(1, 3, -2)$ or $(1, 3, 2)$. The problem is that none of those points are in the given line. I would like to know what is wrong with my strategy to find the equation of the plane.","I am asked to find the plane that contains the point $(-4, 7, -3)$ and is perpendicular to the line defined by the parametric equations $x = -4 + t$, $y = 7 + 3t$ and $z = -2t$. Now, I know that if $n = (a, b, c)$ is a normal vector to a plane $P$ and if $r_{0} = (x_{0}, y_{0}, z_{0})$ is a point in the plane, then $$P = \{ r: n \cdot (r - r_{0}) = 0 \} = \{ (x, y, z): a (x - x_{0}) + b (y - y_{0}) + c (z - z_{0}) = 0 \},$$ so I thought I just had to take a particular point in the line and call it $n$, then call $r_{0} = (-4, 7, -3)$ and apply the aforementioned equation, but I think there is something wrong with this approach since the four possible answers to the exercise are: \begin{equation} x - 3y - 2z = 21 \end{equation} \begin{equation} 3x +y - 2z = 23 \end{equation} \begin{equation} x + 3y - 2z = 23 \end{equation} \begin{equation} x + 3y +z = 21, \end{equation} leaving the possible choices of $n$ to $(1, -3, -2)$, $(3, 1, -2)$, $(1, 3, -2)$ or $(1, 3, 2)$. The problem is that none of those points are in the given line. I would like to know what is wrong with my strategy to find the equation of the plane.",,['multivariable-calculus']
73,Multidimensional Fourier transform of the laplacian,Multidimensional Fourier transform of the laplacian,,"In my course on electromagnetic field theory we use the Fourier transform to simplify Maxwell's equations, for example: $$\frac{\partial ^2\vec E(\vec r,t)}{\partial t^2} \rightleftharpoons -\omega^2\mathcal{F}_t\vec E(\vec r,\omega)$$ I haven't officially studied multidimensional fourier transforms but I've been exposed to them through MIT's set of courses ""The fourier transform and its applications"" (Brad Osgood). I tried transforming things like the Laplacian of a function and this is what I got: Start by considering the $\mathbb{R}^3$ FT of the second x-derivative of some nice function f and manupulate the integral to be in terms of the one dimensional FT with respect to x: $$\mathcal{F}_{xyz}\{\frac{\partial ^2f(\vec r)}{\partial x^2}\}=\int\limits_{\mathbb{R}^3}e^{j\vec\xi\cdot\vec r}\frac{\partial ^2f(\vec r)}{\partial x^2}dxdydz=\int\limits_{\mathbb{R}^2}e^{j(\xi_2y+\xi_3z)}\mathcal{F}_x\{\frac{\partial ^2f(\vec r)}{\partial x^2}\}dydz$$ and so, using a well known identity for the FT of a derrivative: $$ \mathcal{F}_{xyz}\{\frac{\partial ^2f(\vec r)}{\partial x^2}\}= \int\limits_{\mathbb{R}^2}e^{j(\xi_2y+\xi_3z)}(j\xi_1)^2\mathcal{F}_x\{f\}dydz=-\xi_1^2\mathcal{F}_{xyz}\{f\}$$ and since that is the case we can conclude that: $$\mathcal{F}_{xyz}\{\Delta f\}= -(\xi_1^2+\xi_2^2+\xi_3^2)\mathcal{F}_{xyz}f= -\|\vec\xi \|^2\mathcal{F}_{xyz} f $$ The reason I have for doubting this is that if I use this to transform the homogeneous wave equation for the electric field:  $$ \Delta \vec E-\mu\epsilon\frac{\partial ^2\vec E}{\partial t^2}=0$$ I get: $$-( \|\vec\xi \|^2-\omega^2\mu\epsilon)\mathcal{F}\vec E=0 \Rightarrow \mathcal{F}\vec E=0$$ This seems to say that $\vec E$ is equal to zero for all points in space and time (which is definitely false). So either I've got my multidimensional FT wrong (maybe a $\mathcal{F}f=0$ does not imply $f=0$ like in the one dimensional case?) or I've got my electromagnetics wrong in which case this isn't the right forum. Anyway, I'm interested to hear anything you have to say on the subject, I've had a hard time finding anything relating the Fourier transform and vector calculus so any pointers on where to look is appreciated as well.","In my course on electromagnetic field theory we use the Fourier transform to simplify Maxwell's equations, for example: $$\frac{\partial ^2\vec E(\vec r,t)}{\partial t^2} \rightleftharpoons -\omega^2\mathcal{F}_t\vec E(\vec r,\omega)$$ I haven't officially studied multidimensional fourier transforms but I've been exposed to them through MIT's set of courses ""The fourier transform and its applications"" (Brad Osgood). I tried transforming things like the Laplacian of a function and this is what I got: Start by considering the $\mathbb{R}^3$ FT of the second x-derivative of some nice function f and manupulate the integral to be in terms of the one dimensional FT with respect to x: $$\mathcal{F}_{xyz}\{\frac{\partial ^2f(\vec r)}{\partial x^2}\}=\int\limits_{\mathbb{R}^3}e^{j\vec\xi\cdot\vec r}\frac{\partial ^2f(\vec r)}{\partial x^2}dxdydz=\int\limits_{\mathbb{R}^2}e^{j(\xi_2y+\xi_3z)}\mathcal{F}_x\{\frac{\partial ^2f(\vec r)}{\partial x^2}\}dydz$$ and so, using a well known identity for the FT of a derrivative: $$ \mathcal{F}_{xyz}\{\frac{\partial ^2f(\vec r)}{\partial x^2}\}= \int\limits_{\mathbb{R}^2}e^{j(\xi_2y+\xi_3z)}(j\xi_1)^2\mathcal{F}_x\{f\}dydz=-\xi_1^2\mathcal{F}_{xyz}\{f\}$$ and since that is the case we can conclude that: $$\mathcal{F}_{xyz}\{\Delta f\}= -(\xi_1^2+\xi_2^2+\xi_3^2)\mathcal{F}_{xyz}f= -\|\vec\xi \|^2\mathcal{F}_{xyz} f $$ The reason I have for doubting this is that if I use this to transform the homogeneous wave equation for the electric field:  $$ \Delta \vec E-\mu\epsilon\frac{\partial ^2\vec E}{\partial t^2}=0$$ I get: $$-( \|\vec\xi \|^2-\omega^2\mu\epsilon)\mathcal{F}\vec E=0 \Rightarrow \mathcal{F}\vec E=0$$ This seems to say that $\vec E$ is equal to zero for all points in space and time (which is definitely false). So either I've got my multidimensional FT wrong (maybe a $\mathcal{F}f=0$ does not imply $f=0$ like in the one dimensional case?) or I've got my electromagnetics wrong in which case this isn't the right forum. Anyway, I'm interested to hear anything you have to say on the subject, I've had a hard time finding anything relating the Fourier transform and vector calculus so any pointers on where to look is appreciated as well.",,"['multivariable-calculus', 'fourier-analysis', 'vector-analysis']"
74,Double integral -- tricky?,Double integral -- tricky?,,"If $f(x,y) = x^2+y^2$ and $D=\{(x,y)\in\mathbb{R}^2:x^2+y^2\geq1, x^2+y^2-2x\leq0 \text{ and } y\geq0\}$, find $\displaystyle\int\displaystyle\int_D f$. $D$ looks like the intersection between two circumferences, as I draw below: Polar coordinates seems a obvious choice, but using them I'd have unwanted bits, this is, if I split the region in two sections (by $x=\frac{1}{2}$) after computing the red and blue region I would have twice $R1$ and $R2$, a problem that could be solved computing each one of them and then substract them of the final answer -this is, after adding the integral of the red and blue sections-. I believe the answer would be given by $$\displaystyle\int \displaystyle\int_D f = \displaystyle\int\displaystyle\int _{\text{RED}} f + \displaystyle\int\displaystyle\int _{\text{BLUE}} f - \displaystyle\int\displaystyle\int _{\text{R1}} f - \displaystyle\int\displaystyle\int _{\text{R2}} f$$ $R1$ and $R2$ could be described as follows: $$R1 = \{(x,y):0\leq y\leq \sqrt{3}x,\;0\leq x\leq 1/2\}$$ $$R2 = \{(x,y):0\leq y\leq \sqrt{3}-\sqrt{3}x,\;1/2 \leq x\leq 1\}$$ Which gives $$\displaystyle\int\displaystyle\int _{\text{R1}} f =\displaystyle\int_0^{1/2}\displaystyle\int_0^{\sqrt{3}x} (x^2+y^2)\; dy dx = 2\sqrt{3}\displaystyle\int_0^{1/2}x^3 = \displaystyle\frac{1}{52\sqrt{3}}.$$ $$\displaystyle\int\displaystyle\int_{R2} f = \displaystyle\int_{1/2}^1\displaystyle\int_0^{\sqrt{3}-\sqrt{3}x}(x^2+y^2)\; dydx \\ = \displaystyle\int_{1/2}^1(x^2(\sqrt{3}-\sqrt{3}x)dx + \frac{1}{3}\int_{\frac{1}{2}}^1 (\sqrt{3}-\sqrt{3}x)^3 dx \\ = \left[\sqrt{3}\displaystyle\int_{1/2}^1 x^2 -\sqrt{3}\displaystyle\int_{1/2}^1 x^3\right]  + \frac{1}{3}\int_{\frac{1}{2}}^1 (\sqrt{3}-\sqrt{3}x)^3 dx \\ = \sqrt{3}\left[\left(\displaystyle\frac{1}{3}-\displaystyle\frac{1}{24}\right)+\left(\displaystyle\frac{1}{4}-\displaystyle\frac{1}{64}\right) \right] + \displaystyle\frac{1}{3}\left(\displaystyle\frac{1}{2}\right) \\= \frac{\sqrt{3}}{16}+\frac{1}{6} = \frac{1}{48}(3\sqrt{3}+8).$$ Now changing to polar coordinates $x=r\cos \theta$, $y= r\sin \theta$ to compute the red and blue: $$\displaystyle\int\displaystyle\int _{\text{RED}} f = \displaystyle\int_0^{\pi/3}\displaystyle\int_0^1 r^3\;drd\theta = \frac{1}{4}\displaystyle\int_0^{\pi/3}d\theta = \frac{1}{12}\pi$$ Setting auxiliary axis $u = x-1, v = y$ I have $\displaystyle\frac{\partial (x,y)}{\partial (u,v)}=1$ and after with $u=r\cos \theta$, $v=r\sin \theta$ $$\displaystyle\int\displaystyle\int _{\text{BLUE}} f = \displaystyle\int_{2\pi/3}^{\pi}\displaystyle\int_0^1 r^3\;drd\theta = \frac{1}{12}\pi.$$ Finally  $$\displaystyle\int \displaystyle\int_D f = \frac{1}{6}\pi -\displaystyle\frac{1}{52\sqrt{3}} -\frac{1}{48}(3\sqrt{3}+8) .$$ Now I'd like to know if the solution is right, but fundamentally, can this integral be computed without splitting the $D$? P.S: Legitimate question, but couldn't resist the pun.","If $f(x,y) = x^2+y^2$ and $D=\{(x,y)\in\mathbb{R}^2:x^2+y^2\geq1, x^2+y^2-2x\leq0 \text{ and } y\geq0\}$, find $\displaystyle\int\displaystyle\int_D f$. $D$ looks like the intersection between two circumferences, as I draw below: Polar coordinates seems a obvious choice, but using them I'd have unwanted bits, this is, if I split the region in two sections (by $x=\frac{1}{2}$) after computing the red and blue region I would have twice $R1$ and $R2$, a problem that could be solved computing each one of them and then substract them of the final answer -this is, after adding the integral of the red and blue sections-. I believe the answer would be given by $$\displaystyle\int \displaystyle\int_D f = \displaystyle\int\displaystyle\int _{\text{RED}} f + \displaystyle\int\displaystyle\int _{\text{BLUE}} f - \displaystyle\int\displaystyle\int _{\text{R1}} f - \displaystyle\int\displaystyle\int _{\text{R2}} f$$ $R1$ and $R2$ could be described as follows: $$R1 = \{(x,y):0\leq y\leq \sqrt{3}x,\;0\leq x\leq 1/2\}$$ $$R2 = \{(x,y):0\leq y\leq \sqrt{3}-\sqrt{3}x,\;1/2 \leq x\leq 1\}$$ Which gives $$\displaystyle\int\displaystyle\int _{\text{R1}} f =\displaystyle\int_0^{1/2}\displaystyle\int_0^{\sqrt{3}x} (x^2+y^2)\; dy dx = 2\sqrt{3}\displaystyle\int_0^{1/2}x^3 = \displaystyle\frac{1}{52\sqrt{3}}.$$ $$\displaystyle\int\displaystyle\int_{R2} f = \displaystyle\int_{1/2}^1\displaystyle\int_0^{\sqrt{3}-\sqrt{3}x}(x^2+y^2)\; dydx \\ = \displaystyle\int_{1/2}^1(x^2(\sqrt{3}-\sqrt{3}x)dx + \frac{1}{3}\int_{\frac{1}{2}}^1 (\sqrt{3}-\sqrt{3}x)^3 dx \\ = \left[\sqrt{3}\displaystyle\int_{1/2}^1 x^2 -\sqrt{3}\displaystyle\int_{1/2}^1 x^3\right]  + \frac{1}{3}\int_{\frac{1}{2}}^1 (\sqrt{3}-\sqrt{3}x)^3 dx \\ = \sqrt{3}\left[\left(\displaystyle\frac{1}{3}-\displaystyle\frac{1}{24}\right)+\left(\displaystyle\frac{1}{4}-\displaystyle\frac{1}{64}\right) \right] + \displaystyle\frac{1}{3}\left(\displaystyle\frac{1}{2}\right) \\= \frac{\sqrt{3}}{16}+\frac{1}{6} = \frac{1}{48}(3\sqrt{3}+8).$$ Now changing to polar coordinates $x=r\cos \theta$, $y= r\sin \theta$ to compute the red and blue: $$\displaystyle\int\displaystyle\int _{\text{RED}} f = \displaystyle\int_0^{\pi/3}\displaystyle\int_0^1 r^3\;drd\theta = \frac{1}{4}\displaystyle\int_0^{\pi/3}d\theta = \frac{1}{12}\pi$$ Setting auxiliary axis $u = x-1, v = y$ I have $\displaystyle\frac{\partial (x,y)}{\partial (u,v)}=1$ and after with $u=r\cos \theta$, $v=r\sin \theta$ $$\displaystyle\int\displaystyle\int _{\text{BLUE}} f = \displaystyle\int_{2\pi/3}^{\pi}\displaystyle\int_0^1 r^3\;drd\theta = \frac{1}{12}\pi.$$ Finally  $$\displaystyle\int \displaystyle\int_D f = \frac{1}{6}\pi -\displaystyle\frac{1}{52\sqrt{3}} -\frac{1}{48}(3\sqrt{3}+8) .$$ Now I'd like to know if the solution is right, but fundamentally, can this integral be computed without splitting the $D$? P.S: Legitimate question, but couldn't resist the pun.",,"['integration', 'multivariable-calculus', 'definite-integrals']"
75,Proving a map between the triangle and the square is bijective,Proving a map between the triangle and the square is bijective,,"Prove that $$(u,v) \mapsto \left(\frac{\sin u}{\cos v}, \frac{\sin v}{\cos u}\right)=\left(x, y\right)$$ is a bijection between the interior of the triangle $T:= \{0\le u,v; u+v \le \frac {\pi}2\}$ and the square $S:=\{0\le u,v \le 1\}$. I managed to partly show injectivity in the following way: assume $$\begin{aligned} \frac {\sin u}{\cos v} &= \frac {\sin u'}{\cos v'} \\  \frac {\sin v}{\cos u} &= \frac {\sin v'}{\cos u'} \end{aligned}$$ then it follows that $$\begin{aligned} \sin u\cos v' - \sin v'\cos u &= \sin u' \cos v - \sin v \cos u' \\ \sin(u-v')&=\sin(u'-v)\\ \Rightarrow u+v &=u'+v'\end{aligned}$$ Hence two points in the triangle are mapped to the same point in the square only if they lie on a straight line parallel to the hypotenuse. I also computed the jacobian of this map and I know it is equal to $1-x^2y^2$, so that the map is smooth in the interior of the triangle. I'm sure I can use this at some point in the proof but I don't know where.","Prove that $$(u,v) \mapsto \left(\frac{\sin u}{\cos v}, \frac{\sin v}{\cos u}\right)=\left(x, y\right)$$ is a bijection between the interior of the triangle $T:= \{0\le u,v; u+v \le \frac {\pi}2\}$ and the square $S:=\{0\le u,v \le 1\}$. I managed to partly show injectivity in the following way: assume $$\begin{aligned} \frac {\sin u}{\cos v} &= \frac {\sin u'}{\cos v'} \\  \frac {\sin v}{\cos u} &= \frac {\sin v'}{\cos u'} \end{aligned}$$ then it follows that $$\begin{aligned} \sin u\cos v' - \sin v'\cos u &= \sin u' \cos v - \sin v \cos u' \\ \sin(u-v')&=\sin(u'-v)\\ \Rightarrow u+v &=u'+v'\end{aligned}$$ Hence two points in the triangle are mapped to the same point in the square only if they lie on a straight line parallel to the hypotenuse. I also computed the jacobian of this map and I know it is equal to $1-x^2y^2$, so that the map is smooth in the interior of the triangle. I'm sure I can use this at some point in the proof but I don't know where.",,"['multivariable-calculus', 'differential-geometry']"
76,"What information can one get from $f(x,y)\geq -3x+4y$ provided that $f$ is continuously differentiable near $(0,0)$?",What information can one get from  provided that  is continuously differentiable near ?,"f(x,y)\geq -3x+4y f (0,0)","Let $V$ be a neighborhood of the origin in ${\Bbb R}^2$ and $f:V\to{\Bbb R}$ be continuously differentiable. Assume that $f(0,0)=0$ and $f(x,y)\geq -3x+4y$ for $(x,y)\in V$. Prove that there is a neighborhood $U$ of the origin in ${\Bbb R}^2$ and a positive number $\epsilon$ such that, if $(x_1,y_1),(x_2,y_2)\in U$ and $f(x_1,y_1)=f(x_2,y_2)=0$, then   $$ |y_1-y_2|\geq\epsilon|x_1-x_2|. $$ Using the assumption, we have $$ f(x)=f'(0)x+o(\|x\|) $$ which gives the local behavior of $f$ near the origin. But how the inequality $f(x,y)\geq -3x+4y$ would be used here?","Let $V$ be a neighborhood of the origin in ${\Bbb R}^2$ and $f:V\to{\Bbb R}$ be continuously differentiable. Assume that $f(0,0)=0$ and $f(x,y)\geq -3x+4y$ for $(x,y)\in V$. Prove that there is a neighborhood $U$ of the origin in ${\Bbb R}^2$ and a positive number $\epsilon$ such that, if $(x_1,y_1),(x_2,y_2)\in U$ and $f(x_1,y_1)=f(x_2,y_2)=0$, then   $$ |y_1-y_2|\geq\epsilon|x_1-x_2|. $$ Using the assumption, we have $$ f(x)=f'(0)x+o(\|x\|) $$ which gives the local behavior of $f$ near the origin. But how the inequality $f(x,y)\geq -3x+4y$ would be used here?",,[]
77,Expansion of $ \frac{1}{|\vec r -\vec r'|} $,Expansion of, \frac{1}{|\vec r -\vec r'|} ,"I would like to show that: $$ \frac{1}{|\vec r -\vec r'|} =\frac{1}{r} + \frac{\vec r'\cdot r'}{r^3}+\frac{3 ((\vec r \cdot \vec r)^2 -\vec r^2 \vec r'^2 )}{2r^5} +\dots$$ What I derived so far is: $$\frac{1}{|\vec r -\vec r'|}= \sum_{n=0}^{\infty} \frac{1}{n!} (-\vec r' \cdot \nabla_r )^n \frac{1}{r} $$ The last part is however unclear to me, since I don't know how to rewrite, e.g. $(-\vec r' \cdot \nabla_r )$","I would like to show that: $$ \frac{1}{|\vec r -\vec r'|} =\frac{1}{r} + \frac{\vec r'\cdot r'}{r^3}+\frac{3 ((\vec r \cdot \vec r)^2 -\vec r^2 \vec r'^2 )}{2r^5} +\dots$$ What I derived so far is: $$\frac{1}{|\vec r -\vec r'|}= \sum_{n=0}^{\infty} \frac{1}{n!} (-\vec r' \cdot \nabla_r )^n \frac{1}{r} $$ The last part is however unclear to me, since I don't know how to rewrite, e.g. $(-\vec r' \cdot \nabla_r )$",,"['calculus', 'multivariable-calculus']"
78,At what time is the speed minimum?,At what time is the speed minimum?,,"The position function of a particle is given by $r(t) = \langle-5t^2, -1t, t^2 + 1t\rangle$. At what time is the speed minimum?","The position function of a particle is given by $r(t) = \langle-5t^2, -1t, t^2 + 1t\rangle$. At what time is the speed minimum?",,['multivariable-calculus']
79,Partial derivatives of a function which is constant on the diagonal,Partial derivatives of a function which is constant on the diagonal,,"Suppose that $f:\mathbb{R}^n\times \mathbb{R}^n\to \mathbb{R}_+$ is a non negative smooth function such that it vanishes only on the diagonal, i.e., $f(x,y)=0$ iff $x=y$. Is it true then that $$\left[\frac{\partial}{\partial x_i}\frac{\partial}{\partial x_j}f(x,y)\right]_{x=y}=\left[\frac{\partial}{\partial y_i}\frac{\partial}{\partial y_j}f(x,y)\right]_{y=x}?$$","Suppose that $f:\mathbb{R}^n\times \mathbb{R}^n\to \mathbb{R}_+$ is a non negative smooth function such that it vanishes only on the diagonal, i.e., $f(x,y)=0$ iff $x=y$. Is it true then that $$\left[\frac{\partial}{\partial x_i}\frac{\partial}{\partial x_j}f(x,y)\right]_{x=y}=\left[\frac{\partial}{\partial y_i}\frac{\partial}{\partial y_j}f(x,y)\right]_{y=x}?$$",,"['real-analysis', 'multivariable-calculus']"
80,Partial derivatives of second order,Partial derivatives of second order,,"Find all functions $f:\mathbb{R}^2\rightarrow \mathbb{R}$ of class ${\cal C}^2$, such that: $\frac{\partial^2f}{\partial x\partial y} = 0$ $\frac{\partial^2f}{\partial x^2} = \frac{\partial^2f}{\partial y^2}$ (Separate questions) For the first one I prove that $f(x,y) = h(x)+g(y)$ for some $h,g\in{\cal C}^2$, but I can't determine a condition for $f$ in the second part.","Find all functions $f:\mathbb{R}^2\rightarrow \mathbb{R}$ of class ${\cal C}^2$, such that: $\frac{\partial^2f}{\partial x\partial y} = 0$ $\frac{\partial^2f}{\partial x^2} = \frac{\partial^2f}{\partial y^2}$ (Separate questions) For the first one I prove that $f(x,y) = h(x)+g(y)$ for some $h,g\in{\cal C}^2$, but I can't determine a condition for $f$ in the second part.",,['multivariable-calculus']
81,"Prove function (0, ∞) to (0, ∞) can't exist if $(f(x))^2>(f(x+y))((f(x)+y))$","Prove function (0, ∞) to (0, ∞) can't exist if",(f(x))^2>(f(x+y))((f(x)+y)),"So we're trying to prove that no function exists $f: (0,\infty) \rightarrow(0,\infty)$ such that $f(x)^2\ge f(x+y) (f(x)+y)\quad x,y\gt0$ I've tried to break it up into 3 cases to show if $x\gt y$ and  $x\lt y$ and $x= y$ to show that $f(x+y)\gt f(x)$, but doesn't that depend on the initial function? i.e $\frac{1}{x}\gt\frac{1}{x+y}$ not $\lt$ like I wanted to show. I'm just stumped at how to prove this for any function. We've tried to set it all up on one side and do the quadratic equation to try and chase down a numerical value to prove that $f(x+y)\gt f(x)$ so we could then say that $f(x+y)f(x)\gt f(x)f(x)$ which would imply that $f(x+y)f(x)\gt f(x)^2$ so our original function of $f(x)^2\ge((f(x+y))((f(x)+y))$ could be rewritten as $f(x)^2\ge((f(x))^2+f(x+y)y)$ which we know $f(x)^2 \lt f(x)^2 + y$ so we'd have a contradiction. But I can never seem to figure out how to write a formal proof of the ideas I have. If my idea was even a valid idea. Thanks ahead of time! Just had an idea to find some value such that it is always contradictory like choosing $y=x^2-x$, but then $y$ could have a negative value so I'm going to have to find a new y=, but that's the path I'm going now!","So we're trying to prove that no function exists $f: (0,\infty) \rightarrow(0,\infty)$ such that $f(x)^2\ge f(x+y) (f(x)+y)\quad x,y\gt0$ I've tried to break it up into 3 cases to show if $x\gt y$ and  $x\lt y$ and $x= y$ to show that $f(x+y)\gt f(x)$, but doesn't that depend on the initial function? i.e $\frac{1}{x}\gt\frac{1}{x+y}$ not $\lt$ like I wanted to show. I'm just stumped at how to prove this for any function. We've tried to set it all up on one side and do the quadratic equation to try and chase down a numerical value to prove that $f(x+y)\gt f(x)$ so we could then say that $f(x+y)f(x)\gt f(x)f(x)$ which would imply that $f(x+y)f(x)\gt f(x)^2$ so our original function of $f(x)^2\ge((f(x+y))((f(x)+y))$ could be rewritten as $f(x)^2\ge((f(x))^2+f(x+y)y)$ which we know $f(x)^2 \lt f(x)^2 + y$ so we'd have a contradiction. But I can never seem to figure out how to write a formal proof of the ideas I have. If my idea was even a valid idea. Thanks ahead of time! Just had an idea to find some value such that it is always contradictory like choosing $y=x^2-x$, but then $y$ could have a negative value so I'm going to have to find a new y=, but that's the path I'm going now!",,"['calculus', 'multivariable-calculus', 'functions']"
82,"C.H. Edwards ""Advanced Calculus of Several Variables"", Problem 3.5 of page 194","C.H. Edwards ""Advanced Calculus of Several Variables"", Problem 3.5 of page 194",,"In C.H. Edward's Advanced Calculus of Several Variables in the Chapter III in Section 3 on Inverse and Implicit Mapping Theorems question #5 is given as follows: 3.5 Show that the equations   $$ \sin(x+z)+\log yz^2 = 0, \qquad e^{x+z}+yz=0 $$   implicitly define $z$ near $-1$ as a function of $(x,y)$ near $(1,1)$. My trouble here is in understanding what is meant by the statement. If I am to consider the collection of points in $\mathbb{R}^3$ for which both $G_1(x,y,z)= \sin(x+z)+\log yz^2 = 0$  and $G_2(x,y,z)=e^{x+z}+yz=0$ then, if the Jacobian is rank two near $(1,1,-1)$ then we have two (independent) equations and three unknowns hence the implicit solution would have just one free parameter. That is, the implicit solution would seem to be a curve not a surface. Very well, for completeness, let us calculate the Jacobian: $$ G'(x,y,z) = [\partial_xG|\partial_yG|\partial_zG] =  \left[ \begin{array}{ccc} \cos(x+z) & 1/y & \cos(x+z)+2/z \\ e^{x+z} & z & e^{x+z}+y \end{array}\right] $$ and evaluate at $(1,1,-1)$ for which clearly $G(1,1,-1)=(0,0)$ $$ G'(1,1,-1) =   \left[ \begin{array}{ccc} 1 & 1 & -1 \\ 1 & -1 & 2 \end{array}\right] $$ It is clear to me that the matrix above has rank two. Moreover, we can apply the implicit mapping theorem to solve for $x,z$ as a functions of $y$, that is we could find $h_1,h_2$ functions for which $G(h_1(y),y,h_2(y))=(0,0)$ for $y$ near $1$. Or, we could solve for $x,y$ are functions of $z$, that is we could find $h_3,h_4$ such that $G(h_3(z),h_4(z),z)=(0,0)$ for $z$ near $-1$. Finally (thanks to Ted Shifrin's correction) we can also find solution exists for $z,y$ in terms of $x$ exists near $(1,1,-1)$. In short, if I consider both equations at once, I don't see a surface parametrized by $x,y$ near $(1,1,-1)$. Question: does Edwards intend us to consider the equations $G_1=0$ and $G_2=0$ separately? In that case, I can solve for two (distinct) surfaces implicitly given by $G_1(x,y,z)=0$ and $G_2(x,y,z)=0$ respective. The intersection of those surfaces would correspond to the curve which the implicit mapping theorem applied to $G = (G_1,G_2)$ revealed. Am I missing something here?","In C.H. Edward's Advanced Calculus of Several Variables in the Chapter III in Section 3 on Inverse and Implicit Mapping Theorems question #5 is given as follows: 3.5 Show that the equations   $$ \sin(x+z)+\log yz^2 = 0, \qquad e^{x+z}+yz=0 $$   implicitly define $z$ near $-1$ as a function of $(x,y)$ near $(1,1)$. My trouble here is in understanding what is meant by the statement. If I am to consider the collection of points in $\mathbb{R}^3$ for which both $G_1(x,y,z)= \sin(x+z)+\log yz^2 = 0$  and $G_2(x,y,z)=e^{x+z}+yz=0$ then, if the Jacobian is rank two near $(1,1,-1)$ then we have two (independent) equations and three unknowns hence the implicit solution would have just one free parameter. That is, the implicit solution would seem to be a curve not a surface. Very well, for completeness, let us calculate the Jacobian: $$ G'(x,y,z) = [\partial_xG|\partial_yG|\partial_zG] =  \left[ \begin{array}{ccc} \cos(x+z) & 1/y & \cos(x+z)+2/z \\ e^{x+z} & z & e^{x+z}+y \end{array}\right] $$ and evaluate at $(1,1,-1)$ for which clearly $G(1,1,-1)=(0,0)$ $$ G'(1,1,-1) =   \left[ \begin{array}{ccc} 1 & 1 & -1 \\ 1 & -1 & 2 \end{array}\right] $$ It is clear to me that the matrix above has rank two. Moreover, we can apply the implicit mapping theorem to solve for $x,z$ as a functions of $y$, that is we could find $h_1,h_2$ functions for which $G(h_1(y),y,h_2(y))=(0,0)$ for $y$ near $1$. Or, we could solve for $x,y$ are functions of $z$, that is we could find $h_3,h_4$ such that $G(h_3(z),h_4(z),z)=(0,0)$ for $z$ near $-1$. Finally (thanks to Ted Shifrin's correction) we can also find solution exists for $z,y$ in terms of $x$ exists near $(1,1,-1)$. In short, if I consider both equations at once, I don't see a surface parametrized by $x,y$ near $(1,1,-1)$. Question: does Edwards intend us to consider the equations $G_1=0$ and $G_2=0$ separately? In that case, I can solve for two (distinct) surfaces implicitly given by $G_1(x,y,z)=0$ and $G_2(x,y,z)=0$ respective. The intersection of those surfaces would correspond to the curve which the implicit mapping theorem applied to $G = (G_1,G_2)$ revealed. Am I missing something here?",,"['multivariable-calculus', 'solution-verification', 'implicit-function-theorem']"
83,what path reduces magnetic field strength,what path reduces magnetic field strength,,"I'm having trouble solving this particular problem in Colley's Vector Calculus.  I believe my trouble lies in not being able to set up a differential equation.  Here is the problem; Igor, the inchworm, is crawling along graph paper in a magnetic field.  The intensitiy of the field at the point $(x,y)$ is given by $M(x,y)=3x^2+y^2+5000$.  If Igor is at the point $(8,6)$, describe the curve along which he should travel if he wishes to reduce the field as rapidly as possible. So, the section this is in is Directional Derivatives and the Gradient, and so this is a gradient problem.  Since we are minimizing magnetic field strength, we are looking for $-\nabla{M(x,y)}$ and we can easily find this at any point.  In this case, $(8,6)$.  But how do we go about doing this starting at a point and following the path for the entire magnetic field? EDIT:  If it isn't necessary, please don't give me the answer.  Guidance would be much more appreciated, since I want to understand what is happening here.","I'm having trouble solving this particular problem in Colley's Vector Calculus.  I believe my trouble lies in not being able to set up a differential equation.  Here is the problem; Igor, the inchworm, is crawling along graph paper in a magnetic field.  The intensitiy of the field at the point $(x,y)$ is given by $M(x,y)=3x^2+y^2+5000$.  If Igor is at the point $(8,6)$, describe the curve along which he should travel if he wishes to reduce the field as rapidly as possible. So, the section this is in is Directional Derivatives and the Gradient, and so this is a gradient problem.  Since we are minimizing magnetic field strength, we are looking for $-\nabla{M(x,y)}$ and we can easily find this at any point.  In this case, $(8,6)$.  But how do we go about doing this starting at a point and following the path for the entire magnetic field? EDIT:  If it isn't necessary, please don't give me the answer.  Guidance would be much more appreciated, since I want to understand what is happening here.",,"['multivariable-calculus', 'partial-derivative']"
84,"Find the volume of $K=\{(x,y,z):|x-z^2|+|y-z^2|+z^2\le1\}$",Find the volume of,"K=\{(x,y,z):|x-z^2|+|y-z^2|+z^2\le1\}","How can I find the volume of $K=\{(x,y,z):|x-z^2|+|y-z^2|+z^2\le1\}$? First, $z^2\le1$ since $|x-z^2|+|y-z^2|\ge0$ This would give me $$\int \limits_{-1}^1 \left(\iint\limits_K \,dx\,dy\right)\,dz$$ where $K=\{(x,y):|x-z^2|+|y-z^2|\le1-z^2\}$ Now I don't recognize this form of $K$, though $i$ does look look like a square if you let the absolute values represent intervals with respect to the $x$- and $y$ axis. How can I calculate the double integral? Thanks! Alexander","How can I find the volume of $K=\{(x,y,z):|x-z^2|+|y-z^2|+z^2\le1\}$? First, $z^2\le1$ since $|x-z^2|+|y-z^2|\ge0$ This would give me $$\int \limits_{-1}^1 \left(\iint\limits_K \,dx\,dy\right)\,dz$$ where $K=\{(x,y):|x-z^2|+|y-z^2|\le1-z^2\}$ Now I don't recognize this form of $K$, though $i$ does look look like a square if you let the absolute values represent intervals with respect to the $x$- and $y$ axis. How can I calculate the double integral? Thanks! Alexander",,"['multivariable-calculus', 'integration', 'volume']"
85,Integral on surface,Integral on surface,,"Please help me calculate integral on surface. $$\iint\!(2-y)\,dS $$ $$ 0\leq z\leq 1;\,  y =1 $$ I can't understand what should I do with '$z$' coordinate. I assume I should do something with it, not to leave blank. Maybe like this? $$= \iint\!dy dz  = 1?$$","Please help me calculate integral on surface. $$\iint\!(2-y)\,dS $$ $$ 0\leq z\leq 1;\,  y =1 $$ I can't understand what should I do with '$z$' coordinate. I assume I should do something with it, not to leave blank. Maybe like this? $$= \iint\!dy dz  = 1?$$",,"['integration', 'multivariable-calculus']"
86,Find the image of the set,Find the image of the set,,"Given set $$D=\{(x,y): x\geq -1, y-x\geq1, y+x\leq1\}$$ and the regular transformation $$\phi:\begin{cases}u=x^2+y^2\\v=x+y\end{cases}$$ How to find out the image of $D$, i.e. $\phi (D)$?","Given set $$D=\{(x,y): x\geq -1, y-x\geq1, y+x\leq1\}$$ and the regular transformation $$\phi:\begin{cases}u=x^2+y^2\\v=x+y\end{cases}$$ How to find out the image of $D$, i.e. $\phi (D)$?",,"['calculus', 'multivariable-calculus']"
87,Surface integral over graph of a function,Surface integral over graph of a function,,"Q: Evaluate the surface integral $\iint_S \mathbf{F}\cdot d\mathbf{S}$ , where $\mathbf{F}(x,y,z)= 3x^2\mathbf{i}-2xy\mathbf{j}+8\mathbf{k}$ , and $S$ is the graph of the function $z=f(x,y)=2x-y$ for $0\leq x\leq2$ and $0\leq y \leq2$ . Attempt: This question is from a previous years Vector Calculus exam. When attempting to solve, I had thought to parameterize the surface, and then use $\int_a^b \mathbf{F}(\mathbf{c}(t))\cdot \mathbf{c}'(t)\,dt$ , $a \leq t \leq b$ . In the solutions, they have $$\iint_S \mathbf{F}\cdot d\mathbf{S} = \int_0^2\int_0^2  (-6x^2-2xy+8)\,dxdy= -8$$ I'm mostly looking for an explanation as to how they arrived at the expression inside the integral ( $-6x^2-2xy+8$ ), any help would be greatly appreciated. Thanks.","Q: Evaluate the surface integral , where , and is the graph of the function for and . Attempt: This question is from a previous years Vector Calculus exam. When attempting to solve, I had thought to parameterize the surface, and then use , . In the solutions, they have I'm mostly looking for an explanation as to how they arrived at the expression inside the integral ( ), any help would be greatly appreciated. Thanks.","\iint_S \mathbf{F}\cdot d\mathbf{S} \mathbf{F}(x,y,z)= 3x^2\mathbf{i}-2xy\mathbf{j}+8\mathbf{k} S z=f(x,y)=2x-y 0\leq x\leq2 0\leq y \leq2 \int_a^b \mathbf{F}(\mathbf{c}(t))\cdot \mathbf{c}'(t)\,dt a \leq t \leq b \iint_S \mathbf{F}\cdot d\mathbf{S} = \int_0^2\int_0^2  (-6x^2-2xy+8)\,dxdy= -8 -6x^2-2xy+8","['calculus', 'multivariable-calculus']"
88,Differentiation of $\operatorname{tr}(A^TB)$ if $A$ is symmetric,Differentiation of  if  is symmetric,\operatorname{tr}(A^TB) A,"May be an easy question but I am quite confused. Differentiation of $\operatorname{tr}(A^TB)$ with respect to $A$ is $B$ and $\operatorname{tr}(AB)$ is $B^T$. What if $A^T = A$, that is $A$ symmetric, is the differentiation $B$ or $B^T$?","May be an easy question but I am quite confused. Differentiation of $\operatorname{tr}(A^TB)$ with respect to $A$ is $B$ and $\operatorname{tr}(AB)$ is $B^T$. What if $A^T = A$, that is $A$ symmetric, is the differentiation $B$ or $B^T$?",,['multivariable-calculus']
89,Integral inequality (Divergence theorem),Integral inequality (Divergence theorem),,"I'm trying to prove the following inequality: $$2 \int_U |\nabla \phi|^2 dx \leq \int_U \phi^2 dx + \int_U |\Delta \phi|^2 dx$$ where $U \subset \mathbb{R}^n$ is bounded and open and $\phi \in C^\infty_c(U)$. I actually think I have managed to prove this just using one of Green's identities $$\int_UD \phi \cdot D \phi dx = -\int_U \phi \Delta \phi dx + \int_{\partial U}\frac{\partial \phi}{\partial \nu} \phi dx$$ (which comes from the divergence theorem), and then using the fact that $\phi = 0$ on $\partial U$. This then gives: $$\int_U |\nabla \phi|^2 dx = -\int_U \phi \Delta \phi dx \leq \int_U |\phi| |\Delta \phi| dx \leq \int_U \frac{\phi^2}{2}+\frac{|\Delta \phi|^2}{2}$$ where the last inequality comes from Cauchy's inequality $ab \leq a^2/2 + b^2/2$. Does this seem correct? The problem is that I have been given a hint which says to use the fact that $\nabla \cdot(\phi \nabla \phi) = |\nabla \phi|^2 + \phi \Delta \phi$ and I'm not sure how to use this hint. Would this just lead to an alternative proof of the inequality?","I'm trying to prove the following inequality: $$2 \int_U |\nabla \phi|^2 dx \leq \int_U \phi^2 dx + \int_U |\Delta \phi|^2 dx$$ where $U \subset \mathbb{R}^n$ is bounded and open and $\phi \in C^\infty_c(U)$. I actually think I have managed to prove this just using one of Green's identities $$\int_UD \phi \cdot D \phi dx = -\int_U \phi \Delta \phi dx + \int_{\partial U}\frac{\partial \phi}{\partial \nu} \phi dx$$ (which comes from the divergence theorem), and then using the fact that $\phi = 0$ on $\partial U$. This then gives: $$\int_U |\nabla \phi|^2 dx = -\int_U \phi \Delta \phi dx \leq \int_U |\phi| |\Delta \phi| dx \leq \int_U \frac{\phi^2}{2}+\frac{|\Delta \phi|^2}{2}$$ where the last inequality comes from Cauchy's inequality $ab \leq a^2/2 + b^2/2$. Does this seem correct? The problem is that I have been given a hint which says to use the fact that $\nabla \cdot(\phi \nabla \phi) = |\nabla \phi|^2 + \phi \Delta \phi$ and I'm not sure how to use this hint. Would this just lead to an alternative proof of the inequality?",,['multivariable-calculus']
90,Vector calculus for ellipse in polar coordinates,Vector calculus for ellipse in polar coordinates,,"I'm having trouble with this question, can somebody please help me with it! I'll thanks/like your comment if help me =) I know that for a ellipse the parametric is $x=a\sin t$ , $b= b \cos t$, $t\in (0, 2\pi)$ (?) For part a) I drew up the graph but not sure if it's right. The circle has radius 1 and for the ellipse I'm able to find $x= 2 $. $$ (x-1)^2 =9  \\ \sqrt{(x-1)^2}=\sqrt 9\\ x-1=3\\ x=4$$ For $y=2\sqrt 2$ $$ y^2=8\\ \sqrt y=\sqrt 8\\ y=\sqrt 4 \sqrt 2\\ y= 2\sqrt 2 \text{ or } 2.8 $$ So the region should be the circle? since the ellipse covers the whole circle? Thank you very much for helping!  Cheers.","I'm having trouble with this question, can somebody please help me with it! I'll thanks/like your comment if help me =) I know that for a ellipse the parametric is $x=a\sin t$ , $b= b \cos t$, $t\in (0, 2\pi)$ (?) For part a) I drew up the graph but not sure if it's right. The circle has radius 1 and for the ellipse I'm able to find $x= 2 $. $$ (x-1)^2 =9  \\ \sqrt{(x-1)^2}=\sqrt 9\\ x-1=3\\ x=4$$ For $y=2\sqrt 2$ $$ y^2=8\\ \sqrt y=\sqrt 8\\ y=\sqrt 4 \sqrt 2\\ y= 2\sqrt 2 \text{ or } 2.8 $$ So the region should be the circle? since the ellipse covers the whole circle? Thank you very much for helping!  Cheers.",,"['multivariable-calculus', 'integration']"
91,How to find the discontinuity set?,How to find the discontinuity set?,,"What is the discontinuity set of the function $f:\mathbb{R}^2 \rightarrow \mathbb{R}$,   $ f(x,y) := \sup \{ \sin (tx) + \sin (ty) : t \in \mathbb{R} \} ?$","What is the discontinuity set of the function $f:\mathbb{R}^2 \rightarrow \mathbb{R}$,   $ f(x,y) := \sup \{ \sin (tx) + \sin (ty) : t \in \mathbb{R} \} ?$",,['multivariable-calculus']
92,Showing $\nabla^2 \phi = \rho$ with $r \phi$ bounded has at most one solution,Showing  with  bounded has at most one solution,\nabla^2 \phi = \rho r \phi,"Given a continuous function $\rho (x,y,z)$, which is zero for $x^2+y^2+z^2 > a^2 > 0$ find $\phi$ such that: $\nabla^2 \phi = \rho$ with $r \phi$ bounded and $r \displaystyle\frac{\partial \phi}{\partial r} \rightarrow 0$ as $r \rightarrow \infty$ I literally have no idea where to even begin with this question any help would be greatly appreciated. Thanks.","Given a continuous function $\rho (x,y,z)$, which is zero for $x^2+y^2+z^2 > a^2 > 0$ find $\phi$ such that: $\nabla^2 \phi = \rho$ with $r \phi$ bounded and $r \displaystyle\frac{\partial \phi}{\partial r} \rightarrow 0$ as $r \rightarrow \infty$ I literally have no idea where to even begin with this question any help would be greatly appreciated. Thanks.",,['multivariable-calculus']
93,"Find area of a simple, smooth, closed curve lying in a plane","Find area of a simple, smooth, closed curve lying in a plane",,"I was given this question in class and I assume it is a spin off of Green's theorem for finding the area of a closed curve $\lambda$ in 2D but expanded to 3D I believe. Anyways I am pretty confused about it so if anyone could help I would appreciate it,. Question: Let $\lambda$ be a simple closed smooth space curve that lies in a plane with unit normal vector n = (a, b, c) and has positive orientation with re- spect to the normal vector n of the plane. Show that the plane area enclosed by $\lambda$ is $$\frac12 \int_{\lambda} (bz-cy)dx + (cx-az)dy + (ay-bx)dz$$","I was given this question in class and I assume it is a spin off of Green's theorem for finding the area of a closed curve $\lambda$ in 2D but expanded to 3D I believe. Anyways I am pretty confused about it so if anyone could help I would appreciate it,. Question: Let $\lambda$ be a simple closed smooth space curve that lies in a plane with unit normal vector n = (a, b, c) and has positive orientation with re- spect to the normal vector n of the plane. Show that the plane area enclosed by $\lambda$ is $$\frac12 \int_{\lambda} (bz-cy)dx + (cx-az)dy + (ay-bx)dz$$",,"['multivariable-calculus', 'integration', 'plane-curves', 'surfaces']"
94,Inequalities related to infimum and supremum,Inequalities related to infimum and supremum,,"Let $f,g: A \rightarrow \mathbb{R}$ be integrable functions on a closed rectangle $A \subset \mathbb{R}^n$. Let $P$ be a partition of $A$ and $S \in P$ a sub-rectangle. Show that: $m_S(f+g) \geq m_S(f)+m_S(g)$ and $M_S(f+g) \leq M_S(f)+ M_S(g)$","Let $f,g: A \rightarrow \mathbb{R}$ be integrable functions on a closed rectangle $A \subset \mathbb{R}^n$. Let $P$ be a partition of $A$ and $S \in P$ a sub-rectangle. Show that: $m_S(f+g) \geq m_S(f)+m_S(g)$ and $M_S(f+g) \leq M_S(f)+ M_S(g)$",,"['multivariable-calculus', 'inequality', 'supremum-and-infimum']"
95,Integration with Spherical Coordinates,Integration with Spherical Coordinates,,Use spherical coordinates to find the volume of the solid inside both $x^2+y^2+z^2=16$ and $z=(x^2+y^2)^{1/2}$.,Use spherical coordinates to find the volume of the solid inside both $x^2+y^2+z^2=16$ and $z=(x^2+y^2)^{1/2}$.,,"['multivariable-calculus', 'integration', 'spherical-coordinates']"
96,Use chain rule to express $f_x$ and $f_y$ in terms of $f_\xi$ and $f_\eta$?,Use chain rule to express  and  in terms of  and ?,f_x f_y f_\xi f_\eta,"Consider partial differential equation: $f_x + 2 f_y = 1$ Trick is to introduce new variables $\xi = x$ and $\eta = 2x - y$ Using chain rule to express $f_x$ and $f_y$ in terms of $f_\xi$ and $f_\eta$ and rewrite equation 1 in terms of new variable. You should find that you can then antidifferentiate, after which you can return to the original variables. Your answer should contain an arbitrary function, and you should easily be able to check it satisfies equation 1.","Consider partial differential equation: $f_x + 2 f_y = 1$ Trick is to introduce new variables $\xi = x$ and $\eta = 2x - y$ Using chain rule to express $f_x$ and $f_y$ in terms of $f_\xi$ and $f_\eta$ and rewrite equation 1 in terms of new variable. You should find that you can then antidifferentiate, after which you can return to the original variables. Your answer should contain an arbitrary function, and you should easily be able to check it satisfies equation 1.",,"['multivariable-calculus', 'partial-differential-equations']"
97,"$\int_C ( 2 xz \, \vec {\mathbf i} + x^2z \, \vec {\mathbf j}+ x^2y \, \vec {\mathbf k}) \mathrm d \, \vec {\mathbf r}$ : Line Integral",: Line Integral,"\int_C ( 2 xz \, \vec {\mathbf i} + x^2z \, \vec {\mathbf j}+ x^2y \, \vec {\mathbf k}) \mathrm d \, \vec {\mathbf r}","Evaluate $\int_C \vec {\mathbf F} \mathrm d \, \vec {\mathbf r}$ , where $\vec {\mathbf F} (x,y,z) = 2 xz \, \vec {\mathbf i} + x^2z \, \vec {\mathbf j}+ x^2y \, \vec {\mathbf k}$ , and C is the path from (0 , 1 , 2) to (1 , 2, 3) that consists of three line segments parallel to the x    -axis, y-axis, and z-axis, in this order. Ill try it in a few moments","Evaluate $\int_C \vec {\mathbf F} \mathrm d \, \vec {\mathbf r}$ , where $\vec {\mathbf F} (x,y,z) = 2 xz \, \vec {\mathbf i} + x^2z \, \vec {\mathbf j}+ x^2y \, \vec {\mathbf k}$ , and C is the path from (0 , 1 , 2) to (1 , 2, 3) that consists of three line segments parallel to the x    -axis, y-axis, and z-axis, in this order. Ill try it in a few moments",,['multivariable-calculus']
98,Exact expansion of functions,Exact expansion of functions,,"Prove that for any twice differentiable function $f: {R}^n \to R$, $f(y) = f(x) + \nabla f(x)^T (y-x)+ \frac{1}{2} (y-x)^T \nabla^2f(z)(y-x) $, for some $z$ on the line segment $[x, y]$. Note that it is not approximation, it is exact equality.","Prove that for any twice differentiable function $f: {R}^n \to R$, $f(y) = f(x) + \nabla f(x)^T (y-x)+ \frac{1}{2} (y-x)^T \nabla^2f(z)(y-x) $, for some $z$ on the line segment $[x, y]$. Note that it is not approximation, it is exact equality.",,"['calculus', 'multivariable-calculus', 'taylor-expansion']"
99,smoothness of multivariable functions,smoothness of multivariable functions,,"What does it mean for a function $\mathbb{R}^n \to \mathbb{R}^m$ to be smooth? I see this in books, but typically we only talk about smoothness when the target set is $\mathbb{R}$.","What does it mean for a function $\mathbb{R}^n \to \mathbb{R}^m$ to be smooth? I see this in books, but typically we only talk about smoothness when the target set is $\mathbb{R}$.",,"['calculus', 'multivariable-calculus', 'terminology']"
