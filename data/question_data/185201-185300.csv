,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,"Injective, Surjective Question on functions","Injective, Surjective Question on functions",,"Consider two functions $ùëì:ùëÜ‚Üíùëá$ and $ùëî:ùëá‚Üíùëà$ Decide whether each of the following statements is true or false, and prove each claim. a) If $ùëî‚àòùëì$ is injective, then $ùëì$ is injective. b) If $ùëî‚àòùëì$ is surjective, then $ùëì$ is surjective. c) If $ùëî‚àòùëì$ is surjective and $ùëî$ is injective, then ùëì is surjective. For part a, injective means: $f(x)=f(y)‚Üíx=y$ and therefore is true. I am unsure about part b and c. How do I prove and solve the 3 parts?","Consider two functions and Decide whether each of the following statements is true or false, and prove each claim. a) If is injective, then is injective. b) If is surjective, then is surjective. c) If is surjective and is injective, then ùëì is surjective. For part a, injective means: and therefore is true. I am unsure about part b and c. How do I prove and solve the 3 parts?",ùëì:ùëÜ‚Üíùëá ùëî:ùëá‚Üíùëà ùëî‚àòùëì ùëì ùëî‚àòùëì ùëì ùëî‚àòùëì ùëî f(x)=f(y)‚Üíx=y,['functions']
1,Finding the number of solutions to an equation given the derivative,Finding the number of solutions to an equation given the derivative,,"Today my teacher gave us this question in class to think about at home. I've been through my textbook trying to find a way to answer this but I have no idea how to find the number of solutions to $g(x)=0$ given that I only have the graph of its derivative, $g'$ .","Today my teacher gave us this question in class to think about at home. I've been through my textbook trying to find a way to answer this but I have no idea how to find the number of solutions to given that I only have the graph of its derivative, .",g(x)=0 g',"['calculus', 'functions', 'derivatives']"
2,if $f(g(x))=x^3$ and $g(f(x))=x^4$ find $f(x)$ and $g(x)$ [duplicate],if  and  find  and  [duplicate],f(g(x))=x^3 g(f(x))=x^4 f(x) g(x),"This question already has answers here : How to prove that there exist no functions $f,g:\Bbb{R}\to\Bbb{R}$ such that $f(g(x))=x^{2018}$ and $g(f(x))=x^{2019}$? (2 answers) Closed 4 years ago . I am taking algebra two and questions like this popped into my head so I would like to learn how to solve them, I am currently working on composing functions.","This question already has answers here : How to prove that there exist no functions $f,g:\Bbb{R}\to\Bbb{R}$ such that $f(g(x))=x^{2018}$ and $g(f(x))=x^{2019}$? (2 answers) Closed 4 years ago . I am taking algebra two and questions like this popped into my head so I would like to learn how to solve them, I am currently working on composing functions.",,['functions']
3,Figuring out the underlying construction of a finite set,Figuring out the underlying construction of a finite set,,"Say you have a set A = { 1, 5, 10 } which when put through a function, produces the set: B = { 1, 5, 10, 6, 11, 15, 16 } That is, f(A) = B . I‚Äôm not sure the proper way to write the math for this, but the gist is that the output is made from all combinations of the input set, without duplicates. So, for example, here's how the elements are computed in the given example: B = { 1, 5, 10, 5+1, 10+1, 10+5, 10+5+1 } Each individual item in A is combined with the others so that the output is a list of unique values. That is, since 1+5 is the same as 5+1 , we only use that value once. A more concise way to describe the function is that it is the set of unique values from all nonempty combinations. The second (and most important) part to this is to go the other direction: given B , how do you figure out A ? Since I‚Äôm so new to this whole field, my question can be broken down into a few parts: What is the proper way to write the mathematics described above? What branch of mathematics would generally cover this problem? What would a solution to this specific problem look like? I'm generally coming from more of a self-taught programming background, so I'm sure there are plenty of gaps in my knowledge. Sorry for my ignorance, and thanks in advance! I've explored a bit of of matrix algebra for this, and I've had some success with combining A and its transpose, taking the lower triangular matrix from the result, and combining this with the original values of A. I was hoping there would be a straight-forward way to reverse this process? (Possibly wishful thinking?) I think there may also be some way to puzzle through this by looking at which combinations of values in B produce the others, but I imagine there's a much more elegant way to go about it. I've asked a corresponding question regarding the CS aspects of this problem here: https://stackoverflow.com/questions/56825784/is-there-a-standard-approach-to-solving-non-injective-functions","Say you have a set A = { 1, 5, 10 } which when put through a function, produces the set: B = { 1, 5, 10, 6, 11, 15, 16 } That is, f(A) = B . I‚Äôm not sure the proper way to write the math for this, but the gist is that the output is made from all combinations of the input set, without duplicates. So, for example, here's how the elements are computed in the given example: B = { 1, 5, 10, 5+1, 10+1, 10+5, 10+5+1 } Each individual item in A is combined with the others so that the output is a list of unique values. That is, since 1+5 is the same as 5+1 , we only use that value once. A more concise way to describe the function is that it is the set of unique values from all nonempty combinations. The second (and most important) part to this is to go the other direction: given B , how do you figure out A ? Since I‚Äôm so new to this whole field, my question can be broken down into a few parts: What is the proper way to write the mathematics described above? What branch of mathematics would generally cover this problem? What would a solution to this specific problem look like? I'm generally coming from more of a self-taught programming background, so I'm sure there are plenty of gaps in my knowledge. Sorry for my ignorance, and thanks in advance! I've explored a bit of of matrix algebra for this, and I've had some success with combining A and its transpose, taking the lower triangular matrix from the result, and combining this with the original values of A. I was hoping there would be a straight-forward way to reverse this process? (Possibly wishful thinking?) I think there may also be some way to puzzle through this by looking at which combinations of values in B produce the others, but I imagine there's a much more elegant way to go about it. I've asked a corresponding question regarding the CS aspects of this problem here: https://stackoverflow.com/questions/56825784/is-there-a-standard-approach-to-solving-non-injective-functions",,"['functions', 'elementary-set-theory', 'notation']"
4,Does anyone recognize the function from this picture?,Does anyone recognize the function from this picture?,,"I was playing with the exterior algebra, and stumbled on this interesting function from $\Bbb N^2 \to \Bbb N$ , which I'll call $f(x,y)$ . This is plotted from $1 \leq x,y \leq 100$ : In this picture, yellow values are higher, blue values are lower. So you can see the function is at its lowest when $x:y$ is closest to a simple ratio. For all $x$ , we have $f(x,x) = 2$ . However, for sufficiently large $x$ , we also have $f(x,x+1) = 3$ , $f(x,x+2)=4$ , etc, so this function is also in some sense measuring the distance to the nearest low-slope line. In comparison, here's the gcd(x,y) function: So you can see that while both functions feature prominent rational slopes, that the first one seems to be ""smoothed"" relative to the GCD, and also reaches minima at rational slopes rather than maxima . Is there some simple function that this resembles? Here is a CSV, if anyone wants to play with it, but due to the way I calculated this function, there may be some sporadic errors (though should be good for $x,y < 50$ or so: https://pastebin.com/raw/vEWAdBVM Just to say how I got this function: So for each $x,y$ pair, I generated the vector $(x,y,1)$ . Then, I wanted to find the ""shortest"" integer bivector that is the wedge product of $(x,y,1) \wedge v$ for some $v$ with integer coordinates. This is a plot of the norm of the resulting shortest bivector for each $(x,y)$ . I was using the $\ell_1$ norm to measure shortest for the thing I'm doing, but you get the same basic plot with the $\ell_2$ norm, as well as any $\ell_p$ norm. For each $(x,y)$ pair above, I ran a Monte Carlo search testing 10000 randomly generated bivectors and took the best one; after a few tries everything converged to the plot above. If you start with $(x,y,0)$ instead, you seem to get the basic GCD function instead, but $(x,y,1)$ gives the ""smooth nega-GCD"" pattern above. I was surprised to find something so simple and beautiful from such a strange starting point!","I was playing with the exterior algebra, and stumbled on this interesting function from , which I'll call . This is plotted from : In this picture, yellow values are higher, blue values are lower. So you can see the function is at its lowest when is closest to a simple ratio. For all , we have . However, for sufficiently large , we also have , , etc, so this function is also in some sense measuring the distance to the nearest low-slope line. In comparison, here's the gcd(x,y) function: So you can see that while both functions feature prominent rational slopes, that the first one seems to be ""smoothed"" relative to the GCD, and also reaches minima at rational slopes rather than maxima . Is there some simple function that this resembles? Here is a CSV, if anyone wants to play with it, but due to the way I calculated this function, there may be some sporadic errors (though should be good for or so: https://pastebin.com/raw/vEWAdBVM Just to say how I got this function: So for each pair, I generated the vector . Then, I wanted to find the ""shortest"" integer bivector that is the wedge product of for some with integer coordinates. This is a plot of the norm of the resulting shortest bivector for each . I was using the norm to measure shortest for the thing I'm doing, but you get the same basic plot with the norm, as well as any norm. For each pair above, I ran a Monte Carlo search testing 10000 randomly generated bivectors and took the best one; after a few tries everything converged to the plot above. If you start with instead, you seem to get the basic GCD function instead, but gives the ""smooth nega-GCD"" pattern above. I was surprised to find something so simple and beautiful from such a strange starting point!","\Bbb N^2 \to \Bbb N f(x,y) 1 \leq x,y \leq 100 x:y x f(x,x) = 2 x f(x,x+1) = 3 f(x,x+2)=4 x,y < 50 x,y (x,y,1) (x,y,1) \wedge v v (x,y) \ell_1 \ell_2 \ell_p (x,y) (x,y,0) (x,y,1)","['elementary-number-theory', 'functions', 'graphing-functions', 'special-functions']"
5,Functions that have the same derivative,Functions that have the same derivative,,"Let‚Äôs say I have two continuous functions $f(x)$ and $g(x)$ , and both have the same derivative $h(x)$ . How could I formally show that $f(x)=g(x)+c$ where $c$ is a constant. I know I have to show that $f(x)-g(x)$ is a constant function but not sure how?  Thanks","Let‚Äôs say I have two continuous functions and , and both have the same derivative . How could I formally show that where is a constant. I know I have to show that is a constant function but not sure how?  Thanks",f(x) g(x) h(x) f(x)=g(x)+c c f(x)-g(x),"['integration', 'functions', 'derivatives']"
6,How does one prove such an equation?,How does one prove such an equation?,,The problem occurred to me while I was trying to solve a problem in planimetry using analytic geometry. for $b$ between $-\frac{1}2$ and $1$ : $\sqrt{2+\sqrt{3-3b^2}+b} = \sqrt{2-2b}+ \sqrt{2-\sqrt{3-3b^2}+b}$,The problem occurred to me while I was trying to solve a problem in planimetry using analytic geometry. for between and :,b -\frac{1}2 1 \sqrt{2+\sqrt{3-3b^2}+b} = \sqrt{2-2b}+ \sqrt{2-\sqrt{3-3b^2}+b},['functions']
7,Inverse of $\frac{\sin(x)}{x}$,Inverse of,\frac{\sin(x)}{x},"How would one find the inverse of the function $y=\frac{\sin(x)}{x}$ ? Here are my steps: $y=\frac{\sin(x)}{x}$ , $x=\frac{\sin(y)}{y}$ , $xy=\sin(y)$ , $\arcsin(xy)=y$ , After that step, I can‚Äôt find a way to isolate $y$ .","How would one find the inverse of the function ? Here are my steps: , , , , After that step, I can‚Äôt find a way to isolate .",y=\frac{\sin(x)}{x} y=\frac{\sin(x)}{x} x=\frac{\sin(y)}{y} xy=\sin(y) \arcsin(xy)=y y,"['functions', 'trigonometry', 'inverse-function']"
8,Positive and increasing function?,Positive and increasing function?,,"Let $f:\mathbb{R}_+\to\mathbb{R}_+$ with $f(0)=0$ and $f\geq 0$ .  There exists a constant $\varepsilon \in (0,1)$ such that $f(y)\geq \varepsilon \left( \frac{y}{x}\right) f(x)$ for every $y\geq x\geq 0$ .  Is it possible to conclude that $f$ is increasing?",Let with and .  There exists a constant such that for every .  Is it possible to conclude that is increasing?,"f:\mathbb{R}_+\to\mathbb{R}_+ f(0)=0 f\geq 0 \varepsilon \in (0,1) f(y)\geq \varepsilon \left( \frac{y}{x}\right) f(x) y\geq x\geq 0 f","['real-analysis', 'functions']"
9,atomic formula and $\Pi_1^0$ is still $\Pi_1^0?$,atomic formula and  is still,\Pi_1^0 \Pi_1^0?,"Currently I am reading Simpson's Subsystem of Second Order Arithmetic , Chapter II.3, Primitive Recursion. Notations: $(i,j) = (i+j)^2+i$ Theorem II. $3.2$ The following is provable in RCA $_0.$ If $f:X\to Y$ and $g:Y\to Z$ then there exists $h=gf:X\to Z$ defined by $h(i) = g(f(i)).$ In the proof, the author introduced the following formula $$\exists j((i,j)\in f \wedge (j,k)\in g)\leftrightarrow (i\in X\wedge \forall j((i,j)\in f\rightarrow (j,k)\in g)).$$ Then he quoted by $\Delta_1^0$ comprehension that $h$ exists such that $$(i,k)\in h \leftrightarrow \exists j((i,j)\in f \wedge (j,k)\in g).$$ I fail to understand why is the formula $\Delta_1^0.$ I have a vague feeling that left hand side is $\Sigma_1^0$ while the other side is $\Pi_1^0$ . However, on the right side, the quantifier is inside the formula, not at outside.  Would this affect the formula?","Currently I am reading Simpson's Subsystem of Second Order Arithmetic , Chapter II.3, Primitive Recursion. Notations: Theorem II. The following is provable in RCA If and then there exists defined by In the proof, the author introduced the following formula Then he quoted by comprehension that exists such that I fail to understand why is the formula I have a vague feeling that left hand side is while the other side is . However, on the right side, the quantifier is inside the formula, not at outside.  Would this affect the formula?","(i,j) = (i+j)^2+i 3.2 _0. f:X\to Y g:Y\to Z h=gf:X\to Z h(i) = g(f(i)). \exists j((i,j)\in f \wedge (j,k)\in g)\leftrightarrow (i\in X\wedge \forall j((i,j)\in f\rightarrow (j,k)\in g)). \Delta_1^0 h (i,k)\in h \leftrightarrow \exists j((i,j)\in f \wedge (j,k)\in g). \Delta_1^0. \Sigma_1^0 \Pi_1^0","['functions', 'logic', 'reverse-math']"
10,"Find number of sequences $ \langle A_1,...,A_k \rangle $",Find number of sequences," \langle A_1,...,A_k \rangle ","Find number of sequences $$ \langle A_1,...,A_k \rangle \text{ such that } A_i \subset \left\{1,...,n \right\} \text{ and } \left| A_1 \cap A_2 \cap ... \cap A_k \right| = r $$ My solution $$ \binom{n}{r} \cdot(2^{n-r} - (n-r) )^k   $$ 1. $\binom{n}{r}$ we choose $r$ elements from $\left\{1,...,n \right\}$ which will be in every $A_i$ 2. For each from $k$ sets we choose additional elements. It can be represented via functions: $$ f: \left\{ A_1,...,A_k \right\} \rightarrow  \left\{1,...,n \right\} \setminus \text{ (choosen elements in step 1) } $$ It can be done in $2^{n-r}$ ways. We also should remove $n-r$ const functions: for example $$f(A_i) = p \in  \left\{1,...,n \right\} \setminus \text{ (choosen elements in step 1) }$$ because then our $$ \left| A_1 \cap A_2 \cap ... \cap A_k \right| \neq r $$ But answer is supposedly $$ \binom{n}{r} \cdot(2^{k} - 1 )^{n-r} $$ (I am not sure if it is correct answer because I found it on faculty website.",Find number of sequences My solution 1. we choose elements from which will be in every 2. For each from sets we choose additional elements. It can be represented via functions: It can be done in ways. We also should remove const functions: for example because then our But answer is supposedly (I am not sure if it is correct answer because I found it on faculty website.," \langle A_1,...,A_k \rangle \text{ such that } A_i \subset \left\{1,...,n \right\} \text{ and } \left| A_1 \cap A_2 \cap ... \cap A_k \right| = r   \binom{n}{r} \cdot(2^{n-r} - (n-r) )^k    \binom{n}{r} r \left\{1,...,n \right\} A_i k  f: \left\{ A_1,...,A_k \right\} \rightarrow  \left\{1,...,n \right\} \setminus \text{ (choosen elements in step 1) }  2^{n-r} n-r f(A_i) = p \in  \left\{1,...,n \right\} \setminus \text{ (choosen elements in step 1) }  \left| A_1 \cap A_2 \cap ... \cap A_k \right| \neq r   \binom{n}{r} \cdot(2^{k} - 1 )^{n-r} ","['sequences-and-series', 'combinatorics']"
11,Does this recursive function have a function in terms of n?,Does this recursive function have a function in terms of n?,,"I am trying to convert the following recursive function to a non-recursive equation: $$f(2) = 2$$ For $n>2$ : $$f(n)=nf(n-1)+n$$ I have calculated the results for n=2 through to n=9: $$\begin{align} f(2)&=2\\ f(3)&=9\\ f(4)&=40\\ f(5)&=205\\ f(6)&=1236\\ f(7)&=8659\\ f(8)&=69280\\ f(9)&=623529 \end{align}$$ I've tried graphing the function, but have got nowhere Any help is appreciated!","I am trying to convert the following recursive function to a non-recursive equation: For : I have calculated the results for n=2 through to n=9: I've tried graphing the function, but have got nowhere Any help is appreciated!","f(2) = 2 n>2 f(n)=nf(n-1)+n \begin{align}
f(2)&=2\\
f(3)&=9\\
f(4)&=40\\
f(5)&=205\\
f(6)&=1236\\
f(7)&=8659\\
f(8)&=69280\\
f(9)&=623529
\end{align}","['functions', 'recurrence-relations', 'recursive-algorithms']"
12,"If $f$ and $g$ are one-to-one, then $gf$ is one-to-one.","If  and  are one-to-one, then  is one-to-one.",f g gf,"I'm aware that there is a thread about this proof. However, I have a slightly different approach which I can not verify myself - hence, this thread. Proof . If $\,g(f(a_j))=g(f(a_k))$ and $g$ is injective, then $f(a_j)=f(a_k)$ . If $\,f(a_j)=f(a_k)$ and $f$ is injective, then $a_j=a_k$ . Therefore, if $\,g(f(a_j))=g(f(a_k))$ and $g$ and $f$ are injective, then $a_j=a_k$ and thus $g(f(a))$ is an injective function if $g$ and $f$ are injective. Is it correct? In a logical context, I have some troubles getting this proof intuitively. All I can see is usage of implications and thus I don't fully understand the full picture...","I'm aware that there is a thread about this proof. However, I have a slightly different approach which I can not verify myself - hence, this thread. Proof . If and is injective, then . If and is injective, then . Therefore, if and and are injective, then and thus is an injective function if and are injective. Is it correct? In a logical context, I have some troubles getting this proof intuitively. All I can see is usage of implications and thus I don't fully understand the full picture...","\,g(f(a_j))=g(f(a_k)) g f(a_j)=f(a_k) \,f(a_j)=f(a_k) f a_j=a_k \,g(f(a_j))=g(f(a_k)) g f a_j=a_k g(f(a)) g f","['calculus', 'functions']"
13,What functions satisfy $f(x)+f(y-x) = g(y)$?,What functions satisfy ?,f(x)+f(y-x) = g(y),"What functions $f$ have the property that, for all $x$ and $y$ : $$ f(x) + f(y-x) = g(y) $$ i.e., the sum does not depend on $x$ ? Linear functions obviously this property: if $f(x) = ax+b$ , then: $$ f(x) + f(y-x) = ay+2b = g(y). $$ On the other hand, if we look only at differentiable functions, then only linear functions have this property. By taking the derivative of the first equation as a function of $x$ : $$ f'(x) - f'(y-x) = 0 \iff f'(x)=f'(y-x) $$ Since this is true for every $y$ , $f'(\cdot)$ must be a constant function, so $f$ must be linear. Are there non-differentiable functions with this property?","What functions have the property that, for all and : i.e., the sum does not depend on ? Linear functions obviously this property: if , then: On the other hand, if we look only at differentiable functions, then only linear functions have this property. By taking the derivative of the first equation as a function of : Since this is true for every , must be a constant function, so must be linear. Are there non-differentiable functions with this property?","f x y 
f(x) + f(y-x) = g(y)
 x f(x) = ax+b 
f(x) + f(y-x) = ay+2b = g(y).
 x 
f'(x) - f'(y-x) = 0 \iff f'(x)=f'(y-x)
 y f'(\cdot) f",['functions']
14,Defining a tricky function: $(A \rightarrow \mathcal{P}(B)) \rightarrow\mathcal{P}(A \rightarrow B)$,Defining a tricky function:,(A \rightarrow \mathcal{P}(B)) \rightarrow\mathcal{P}(A \rightarrow B),"How would I define a function of the form: \begin{align*} \phi: (A \rightarrow \mathcal{P}(B)) \rightarrow\mathcal{P}(A \rightarrow B) \end{align*} I know what behaviour I want, I'm just struggling to define it. For example, consider a function \begin{align*} &f: {0, 1} \rightarrow \mathcal{P}(\{0, 1, 2, 3\}) \\ &f(0) = \{0, 1\} \\ &f(1) = \{2, 3\} \\ \end{align*} I want $\phi(f)$ to be: \begin{align*} &\phi(f) = \{g_1, g_2, g_3, g_4 \} \\ &g_1(0) = 0 \qquad g_1(1) = 2 \\ &g_2(0) = 0 \qquad g_2(1) = 3 \\ &g_3(0) = 1 \qquad g_3(1) = 2 \\ &g_4(0) = 1 \qquad g_4(2) = 3 \\ \end{align*} That is, I want all possible combinations of $\{0, 1\} \times \{2, 3\}$ as functions .","How would I define a function of the form: I know what behaviour I want, I'm just struggling to define it. For example, consider a function I want to be: That is, I want all possible combinations of as functions .","\begin{align*}
\phi: (A \rightarrow \mathcal{P}(B)) \rightarrow\mathcal{P}(A \rightarrow B)
\end{align*} \begin{align*}
&f: {0, 1} \rightarrow \mathcal{P}(\{0, 1, 2, 3\}) \\
&f(0) = \{0, 1\} \\
&f(1) = \{2, 3\} \\
\end{align*} \phi(f) \begin{align*}
&\phi(f) = \{g_1, g_2, g_3, g_4 \} \\
&g_1(0) = 0 \qquad g_1(1) = 2 \\
&g_2(0) = 0 \qquad g_2(1) = 3 \\
&g_3(0) = 1 \qquad g_3(1) = 2 \\
&g_4(0) = 1 \qquad g_4(2) = 3 \\
\end{align*} \{0, 1\} \times \{2, 3\}","['functions', 'elementary-set-theory']"
15,An exercise on the calculation of a function of operator,An exercise on the calculation of a function of operator,,The operator is given by $$A=\begin{pmatrix} 1 & 0 & 0\\ 1 & 1 & 0\\ 0 & 0 & 4 \end{pmatrix}$$ I have to write down the operator $$B=\tan(\frac{\pi} {4}A)$$ I calculate $$\mathcal{R} (z) =\frac{1}{z\mathbb{1}-A}=\begin{pmatrix}  \frac{1}{z-1} & 0 & 0\\ \frac{1}{(z-1)^2} & \frac{1}{z-1} & 0\\ 0 & 0 & \frac{1}{z-4}\end{pmatrix} $$ Now the B operator is given by: $$B=\begin{pmatrix} Res_{z=1}\frac{\tan(\frac{\pi}{4}z)}{z-1} & 0 & 0\\ Res_{z=1}\frac{\tan(\frac{\pi}{4}z)}{(z-1)^2} & Res_{z=1}\frac{\tan(\frac{\pi}{4}z)}{z-1} & 0\\ 0 & 0 & Res_{z=4}\frac{\tan(\frac{\pi}{4}z)}{z-4} \end{pmatrix} $$ For me the result should be $$ B=\begin{pmatrix} 1 & 0 & 0\\ \frac{\pi}{2} & 1 & 0\\ 0 & 0 & 0\end{pmatrix}$$ But the exercise gives as  solution: $$ B=\begin{pmatrix} 1 & 0 & 0\\ \frac{\pi}{4} & 1 & 0\\ 0 & 0 & 1\end{pmatrix}$$ Where is the error? Thank you and sorry for bad English,The operator is given by I have to write down the operator I calculate Now the B operator is given by: For me the result should be But the exercise gives as  solution: Where is the error? Thank you and sorry for bad English,"A=\begin{pmatrix}
1 & 0 & 0\\
1 & 1 & 0\\
0 & 0 & 4
\end{pmatrix} B=\tan(\frac{\pi} {4}A) \mathcal{R} (z) =\frac{1}{z\mathbb{1}-A}=\begin{pmatrix} 
\frac{1}{z-1} & 0 & 0\\
\frac{1}{(z-1)^2} & \frac{1}{z-1} & 0\\
0 & 0 & \frac{1}{z-4}\end{pmatrix}  B=\begin{pmatrix}
Res_{z=1}\frac{\tan(\frac{\pi}{4}z)}{z-1} & 0 & 0\\
Res_{z=1}\frac{\tan(\frac{\pi}{4}z)}{(z-1)^2} & Res_{z=1}\frac{\tan(\frac{\pi}{4}z)}{z-1} & 0\\
0 & 0 & Res_{z=4}\frac{\tan(\frac{\pi}{4}z)}{z-4}
\end{pmatrix}   B=\begin{pmatrix}
1 & 0 & 0\\
\frac{\pi}{2} & 1 & 0\\
0 & 0 & 0\end{pmatrix}  B=\begin{pmatrix}
1 & 0 & 0\\
\frac{\pi}{4} & 1 & 0\\
0 & 0 & 1\end{pmatrix}","['linear-algebra', 'functions', 'operator-theory', 'matrix-calculus']"
16,a Function to Push Numbers Away From a Central Number,a Function to Push Numbers Away From a Central Number,,"I'm looking for a function that takes an array of values between a..b (like 0..1) and a central point a < c < b (like 0.5) and a factor (like 2, 3, 4, etc) and pushes all the array's values away from the central point. For example if we have [0.0, 0.25, 0.48, 0.56, 0.87, 0.98] as input to the function, I'm expecting to get something like [0.0, 0.23, 0.41, 0.65, 0.895, 0.9848]. The factor number should be able to control how much the numbers are stretched away from the central point. There are some implementation details like how much should the factor affect the stretching that I leave up to you. I just want a pushing function to do something as mentioned above. If there is a name for these kinds of functions, I'd be glad if you could point me towards that direction. Thanks...","I'm looking for a function that takes an array of values between a..b (like 0..1) and a central point a < c < b (like 0.5) and a factor (like 2, 3, 4, etc) and pushes all the array's values away from the central point. For example if we have [0.0, 0.25, 0.48, 0.56, 0.87, 0.98] as input to the function, I'm expecting to get something like [0.0, 0.23, 0.41, 0.65, 0.895, 0.9848]. The factor number should be able to control how much the numbers are stretched away from the central point. There are some implementation details like how much should the factor affect the stretching that I leave up to you. I just want a pushing function to do something as mentioned above. If there is a name for these kinds of functions, I'd be glad if you could point me towards that direction. Thanks...",,"['functions', 'percentages']"
17,Tetration of non-integers: is there something wrong with this approach?,Tetration of non-integers: is there something wrong with this approach?,,"I'm trying to figure out a formula for tetration that will work for non-integer heights. I know the usual recurrence relation for tetration ( $x \in \mathbb{R}, \text{ }n \in \mathbb{N})$ : $${^{n}x} = \begin{cases} 1 &\text{if }n=0 \\ \\ x^{\left(^{(n-1)}x\right)} &\text{if }n>0 \end{cases}$$ I also know that $x^y=e^{y \ln x}$ for positive $x$ . I combined these two and formed this recurrence: $$ {^y}x =  f(x,y) =  \begin{cases} e^{y \ln x}                & \text{if }0 \lt y \le 1 \\ \\ e^{f(x,\text{ }y-1) \ln x} & \text{if }1 \lt y  \end{cases} $$ Playing around with this in Maxima, I got correct answers for integer $y$ , and reasonable-looking answers for non-integers.  Yet I have read numerous sources stating that a general formula for tetration is very difficult. So, my question: have I a correct solution for a limited domain, or am I off in the weeds and it just happens to work for integers? Thank you.","I'm trying to figure out a formula for tetration that will work for non-integer heights. I know the usual recurrence relation for tetration ( : I also know that for positive . I combined these two and formed this recurrence: Playing around with this in Maxima, I got correct answers for integer , and reasonable-looking answers for non-integers.  Yet I have read numerous sources stating that a general formula for tetration is very difficult. So, my question: have I a correct solution for a limited domain, or am I off in the weeds and it just happens to work for integers? Thank you.","x \in \mathbb{R}, \text{ }n \in \mathbb{N}) {^{n}x} = \begin{cases} 1 &\text{if }n=0 \\ \\ x^{\left(^{(n-1)}x\right)} &\text{if }n>0 \end{cases} x^y=e^{y \ln x} x 
{^y}x = 
f(x,y) = 
\begin{cases}
e^{y \ln x}                & \text{if }0 \lt y \le 1 \\
\\
e^{f(x,\text{ }y-1) \ln x} & \text{if }1 \lt y 
\end{cases}
 y","['functions', 'exponentiation', 'tetration']"
18,Is mathematical relation between functions the same as relation between their Fourier series?,Is mathematical relation between functions the same as relation between their Fourier series?,,"For example I have three functions $a(x)$,$b(x)$ and $c(x)$ which are defined on $(-\pi,\pi)$  They have a relation that $a(x)=2b(x)+c(x)$. Assume their Fourier series are $A(x)$ $B(x)$ and $C(x)$.  Is the relation among their Fourier series same as functions relations? In other words, is $A(x)=2B(x)+C(x)$ on interval $(-\pi,\pi)$? If yes, how to prove this is true?","For example I have three functions $a(x)$,$b(x)$ and $c(x)$ which are defined on $(-\pi,\pi)$  They have a relation that $a(x)=2b(x)+c(x)$. Assume their Fourier series are $A(x)$ $B(x)$ and $C(x)$.  Is the relation among their Fourier series same as functions relations? In other words, is $A(x)=2B(x)+C(x)$ on interval $(-\pi,\pi)$? If yes, how to prove this is true?",,"['functions', 'fourier-series', 'relations']"
19,Finding derivative given $f(x)$ and limit,Finding derivative given  and limit,f(x),"this is my very first post here. I'm a longtime lurker, I have learned a lot from this site and I hope I can, even though I'm still a student, be of any help to others.  I have been working on the following exercise. Given: $ f(4) = a, f'(4) = b $ and  $$ \lim_{x\to 2} = {f(3x-2)-5 \over (x^2-4)} = 9$$ Find a and b. I already found the value of $a$ following this reasoning: $f(4)$ must be such a value that, when replaced in the given limit, yields zero; otherwise, the limit won't be $9$ but infinity. Under the assumption that I can factor the denominator easily -and simplify $(x-2)$ from $f(x)$ I found $a=f(4)=5$ and it coincides with the answer. I have, however, no reasonable clue of how to approach the $f'(4)=b$ part. All the information I seem to have is that the derivative is continuous, and that $(x-2)$ must be a factor of $f(x)$ .If it's derivative is continuous over Reals, then I infer that it is not a rational function. But I still cant see the right path towards the solution. I'd be extremely grateful if someone could give me a hint, so I can work it out by myself Thanks in advance!","this is my very first post here. I'm a longtime lurker, I have learned a lot from this site and I hope I can, even though I'm still a student, be of any help to others.  I have been working on the following exercise. Given: $ f(4) = a, f'(4) = b $ and  $$ \lim_{x\to 2} = {f(3x-2)-5 \over (x^2-4)} = 9$$ Find a and b. I already found the value of $a$ following this reasoning: $f(4)$ must be such a value that, when replaced in the given limit, yields zero; otherwise, the limit won't be $9$ but infinity. Under the assumption that I can factor the denominator easily -and simplify $(x-2)$ from $f(x)$ I found $a=f(4)=5$ and it coincides with the answer. I have, however, no reasonable clue of how to approach the $f'(4)=b$ part. All the information I seem to have is that the derivative is continuous, and that $(x-2)$ must be a factor of $f(x)$ .If it's derivative is continuous over Reals, then I infer that it is not a rational function. But I still cant see the right path towards the solution. I'd be extremely grateful if someone could give me a hint, so I can work it out by myself Thanks in advance!",,"['functions', 'derivatives']"
20,Limit superior of a sequence of oscillating functions related to Chebyshev polynomials,Limit superior of a sequence of oscillating functions related to Chebyshev polynomials,,"Let $n \in \mathbb N$ and consider the polynomial function $f_n \colon \mathbb R \to \mathbb R$ defined by $$f_n(x) = \sum_{k=0}^n (-1)^k \binom {2n+1} {2k+1} (1 - x^2)^{n-k} x^{2k}$$ for any $x \in \mathbb R$. ( These functions are related to Chebyshev polynomials, see the update below. ) By plotting the graphs of the functions as $n$ increases, one sees that they exhibit an oscillating behavior in $[-1, 1]$. For example, here are the graphs of  $f_3, f_5, f_7$: As $n \to \infty$, it looks as though the crests of the wave describe the graph of another function. For example, here is the graph of $f_{50}$: Let $f \colon D \to \mathbb R$ be defined by $$f(x) = \limsup_{n \to \infty} f_n(x)$$ whenever the limit superior exists and is finite. I would like to find as much information as possible about this function. So far, I have only been able to show the following ( see the update below ): $f$ is an even function, since all of the $f_n$'s are even. $0 \notin D$. Indeed, $f_n(0) = 2n + 1 \to \infty$ as $n \to \infty$. $f(\pm 1) = 1$, because $f_n(\pm 1) = (-1)^n$ for any $n \in \mathbb N$. $f \left (\pm \frac {\sqrt 2} 2 \right ) = 1$. This is because: $$f_n \left ( \pm \frac {\sqrt 2} 2 \right ) = \sum_{k=0}^n (-1)^k \binom {2n+1} {2k+1} \left ( \frac 1 2 \right )^n = (-1)^{\left \lfloor \frac n 2 \right \rfloor} 2^n \left ( \frac 1 2 \right )^n = (-1)^{\left \lfloor \frac n 2 \right \rfloor} \le 1$$ In particular, $f_{4m} \left (\pm \frac {\sqrt 2} 2 \right ) = 1$ for any $m \in \mathbb N$, so $\limsup_{n \to \infty} f_n \left ( \pm \frac {\sqrt 2} 2 \right ) = 1$. By looking at the definition of $f_n(x)$, it seems as though one should use the binomial theorem to find a better expression to work with, but I'm not sure how. What else can we say about $f$? Is it possible to find a ""simple"" expression? Thank you in advance for any reply. Update : By looking up the coefficients of the first few polynomials, I found out that they are closely related to the Chebyshev polynomials of the second kind. In fact, it appears that $$f_n(\sin \alpha) = \frac {\sin ((2n+1) \alpha)}{\sin \alpha}$$ for any $\alpha \in \mathbb R \smallsetminus \pi \mathbb Z$, which immediately provides us with many other values of $f$. For instance, $$f_n \left (\sin \frac \pi 6 \right ) = \frac{\sin \left ( (2n+1) \frac \pi 6 \right )}{\sin \frac \pi 6} \le \frac 1 {\frac 1 2} = 2$$ In particular, $$f_{6m+1} \left (\sin \frac \pi 6 \right ) = \frac{\sin \left ( (12 m + 3) \frac \pi 6 \right )}{\sin \frac \pi 6} = \frac{\sin \left ( 2 m \pi + \frac \pi 2 \right )}{\sin \frac \pi 6} = \frac 1 {\frac 1 2} = 2$$ for any $m \in \mathbb N$, and thus $f \left (\pm \frac 1 2 \right ) = 2$. How can we get a simple expression for $f$ using this information?","Let $n \in \mathbb N$ and consider the polynomial function $f_n \colon \mathbb R \to \mathbb R$ defined by $$f_n(x) = \sum_{k=0}^n (-1)^k \binom {2n+1} {2k+1} (1 - x^2)^{n-k} x^{2k}$$ for any $x \in \mathbb R$. ( These functions are related to Chebyshev polynomials, see the update below. ) By plotting the graphs of the functions as $n$ increases, one sees that they exhibit an oscillating behavior in $[-1, 1]$. For example, here are the graphs of  $f_3, f_5, f_7$: As $n \to \infty$, it looks as though the crests of the wave describe the graph of another function. For example, here is the graph of $f_{50}$: Let $f \colon D \to \mathbb R$ be defined by $$f(x) = \limsup_{n \to \infty} f_n(x)$$ whenever the limit superior exists and is finite. I would like to find as much information as possible about this function. So far, I have only been able to show the following ( see the update below ): $f$ is an even function, since all of the $f_n$'s are even. $0 \notin D$. Indeed, $f_n(0) = 2n + 1 \to \infty$ as $n \to \infty$. $f(\pm 1) = 1$, because $f_n(\pm 1) = (-1)^n$ for any $n \in \mathbb N$. $f \left (\pm \frac {\sqrt 2} 2 \right ) = 1$. This is because: $$f_n \left ( \pm \frac {\sqrt 2} 2 \right ) = \sum_{k=0}^n (-1)^k \binom {2n+1} {2k+1} \left ( \frac 1 2 \right )^n = (-1)^{\left \lfloor \frac n 2 \right \rfloor} 2^n \left ( \frac 1 2 \right )^n = (-1)^{\left \lfloor \frac n 2 \right \rfloor} \le 1$$ In particular, $f_{4m} \left (\pm \frac {\sqrt 2} 2 \right ) = 1$ for any $m \in \mathbb N$, so $\limsup_{n \to \infty} f_n \left ( \pm \frac {\sqrt 2} 2 \right ) = 1$. By looking at the definition of $f_n(x)$, it seems as though one should use the binomial theorem to find a better expression to work with, but I'm not sure how. What else can we say about $f$? Is it possible to find a ""simple"" expression? Thank you in advance for any reply. Update : By looking up the coefficients of the first few polynomials, I found out that they are closely related to the Chebyshev polynomials of the second kind. In fact, it appears that $$f_n(\sin \alpha) = \frac {\sin ((2n+1) \alpha)}{\sin \alpha}$$ for any $\alpha \in \mathbb R \smallsetminus \pi \mathbb Z$, which immediately provides us with many other values of $f$. For instance, $$f_n \left (\sin \frac \pi 6 \right ) = \frac{\sin \left ( (2n+1) \frac \pi 6 \right )}{\sin \frac \pi 6} \le \frac 1 {\frac 1 2} = 2$$ In particular, $$f_{6m+1} \left (\sin \frac \pi 6 \right ) = \frac{\sin \left ( (12 m + 3) \frac \pi 6 \right )}{\sin \frac \pi 6} = \frac{\sin \left ( 2 m \pi + \frac \pi 2 \right )}{\sin \frac \pi 6} = \frac 1 {\frac 1 2} = 2$$ for any $m \in \mathbb N$, and thus $f \left (\pm \frac 1 2 \right ) = 2$. How can we get a simple expression for $f$ using this information?",,"['sequences-and-series', 'functions', 'polynomials', 'limsup-and-liminf', 'chebyshev-polynomials']"
21,Which Sign do I choose using the Half Angle Formula for sin for this?,Which Sign do I choose using the Half Angle Formula for sin for this?,,"I'm evaluating $\sin\left(\frac{1}{2}\sin^{-1}\left(-\frac{7}{25}\right)\right).$ The first thing I did was rewrite it as $\sin\left(\frac{\beta }{2}\right)$ Then I said that  $\sin\left(\beta \right)=-\frac{7}{25}$ Using the Pythagorean Identity I found $cos\left(\beta \right)$ $\cos\left(\beta \right)=\pm\sqrt{1-\left(-\frac{7}{25}\right)^2}$ So $\cos\left(\beta \right)=\pm\frac{24}{25}$ Then to choose the sign of $\cos\left(\beta \right)$, I did this: 1) $\sin^{-1}\left(...\right)$: QI or QIV 2) $\sin\left(\beta \right)>0$   QI or QII 3) $\rightarrow \cos\left(\beta \right)$ is in QI $\cos\left(\beta \right)=+\frac{24}{25}$ Then I applied this to the Half Angle Formula for Sine: $\pm\sqrt{\frac{1}{25}\left(\frac{1}{2}\right)}$ $=\pm\frac{1}{5}\left(\frac{\sqrt{2}}{2}\right)$ $=\pm\frac{\sqrt{2}}{10}$ But which sign do I choose?","I'm evaluating $\sin\left(\frac{1}{2}\sin^{-1}\left(-\frac{7}{25}\right)\right).$ The first thing I did was rewrite it as $\sin\left(\frac{\beta }{2}\right)$ Then I said that  $\sin\left(\beta \right)=-\frac{7}{25}$ Using the Pythagorean Identity I found $cos\left(\beta \right)$ $\cos\left(\beta \right)=\pm\sqrt{1-\left(-\frac{7}{25}\right)^2}$ So $\cos\left(\beta \right)=\pm\frac{24}{25}$ Then to choose the sign of $\cos\left(\beta \right)$, I did this: 1) $\sin^{-1}\left(...\right)$: QI or QIV 2) $\sin\left(\beta \right)>0$   QI or QII 3) $\rightarrow \cos\left(\beta \right)$ is in QI $\cos\left(\beta \right)=+\frac{24}{25}$ Then I applied this to the Half Angle Formula for Sine: $\pm\sqrt{\frac{1}{25}\left(\frac{1}{2}\right)}$ $=\pm\frac{1}{5}\left(\frac{\sqrt{2}}{2}\right)$ $=\pm\frac{\sqrt{2}}{10}$ But which sign do I choose?",,"['functions', 'trigonometry', 'analytic-geometry', 'inverse-function', 'angle']"
22,Expected number of cycles in random function,Expected number of cycles in random function,,"Let f be a left-total function with a discrete domain and codomain both in the range of 0..N . The image of f is chosen randomly (with replacement). Given N, how many cycles is the function expected to contain? Edit: Here's the code from random import randint   def test(N):     """"""Returns all cycles for a function over 0..N-1""""""     edges = [randint(0,N-1) for n in range(N)]      cycles = []      def cycle(start):         """"""Find a cycle from a given start point""""""         current = start         lst = []         while True:             if current in lst:                 lst = lst[lst.index(current):]                 break             lst.append(current)             current = edges[current]         return lst      # For every edge from domain to codomain:     # append the cycle to the list if it isn't contained already     for e in edges:         c = cycle(e)         #if c is not None:         srt = sorted(c)         if not srt in cycles:             cycles.append(srt)      #Print function     #for i,e in enumerate(edges):     #    print(f""{i} -> {e}"")      # Print N and the number of cycles in this function     #print(N, cycles)      return len(cycles)  # Get the average number of cycles for N=1..200 for n in range(1,200):     avg = []     # 1000 random functions of size N     for i in range(1000):         avg.append(test(n))     #print(avg)     print(""%i\t%f"" % (n, sum(avg)/len(avg))) With values: 1   1.000000 10  1.966000 20  2.191000 30  2.356000 40  2.573000 50  2.635000 60  2.742000 70  2.762000 80  2.932000 90  2.851000 100 3.002000","Let f be a left-total function with a discrete domain and codomain both in the range of 0..N . The image of f is chosen randomly (with replacement). Given N, how many cycles is the function expected to contain? Edit: Here's the code from random import randint   def test(N):     """"""Returns all cycles for a function over 0..N-1""""""     edges = [randint(0,N-1) for n in range(N)]      cycles = []      def cycle(start):         """"""Find a cycle from a given start point""""""         current = start         lst = []         while True:             if current in lst:                 lst = lst[lst.index(current):]                 break             lst.append(current)             current = edges[current]         return lst      # For every edge from domain to codomain:     # append the cycle to the list if it isn't contained already     for e in edges:         c = cycle(e)         #if c is not None:         srt = sorted(c)         if not srt in cycles:             cycles.append(srt)      #Print function     #for i,e in enumerate(edges):     #    print(f""{i} -> {e}"")      # Print N and the number of cycles in this function     #print(N, cycles)      return len(cycles)  # Get the average number of cycles for N=1..200 for n in range(1,200):     avg = []     # 1000 random functions of size N     for i in range(1000):         avg.append(test(n))     #print(avg)     print(""%i\t%f"" % (n, sum(avg)/len(avg))) With values: 1   1.000000 10  1.966000 20  2.191000 30  2.356000 40  2.573000 50  2.635000 60  2.742000 70  2.762000 80  2.932000 90  2.851000 100 3.002000",,"['probability', 'combinatorics', 'functions', 'discrete-mathematics', 'fixed-points']"
23,Show $A(x) = \int_{0}^{x}f(t)dt$ is convex if $f(x)$ is increasing.,Show  is convex if  is increasing.,A(x) = \int_{0}^{x}f(t)dt f(x),"Not using $f'(x) = A''(x)$, and that $A''(x) >0$ means convex, Show $A(x) = \int_{0}^{x}f(t)dt$ is convex if $f(x)$ is increasing. This is from Apostol Calculus Vol. 1, Theorem 2.9 Pg. 122 . My try is given For a function to be convex in $[a,b]$ we need $\forall \alpha \in (0,1)$ $$f(\alpha b + (1-\alpha) a) < (\alpha) f(b) + (1-\alpha) f(a)$$ Using this, we need to show $A(\alpha x) < \alpha A(x)$ Now $A(\alpha x) = \int_0^{\alpha x} f(t) dt = \alpha \int _{0}^{x} f(\alpha t) dt < \alpha \int_{0}^{x} f(t) dt = \alpha A(x)$ because $t > \alpha t \implies f(t) > f(\alpha t)$. Is this proof alright, and how can I write it more properly. I am self learning calculus and will then proceed to real analysis.","Not using $f'(x) = A''(x)$, and that $A''(x) >0$ means convex, Show $A(x) = \int_{0}^{x}f(t)dt$ is convex if $f(x)$ is increasing. This is from Apostol Calculus Vol. 1, Theorem 2.9 Pg. 122 . My try is given For a function to be convex in $[a,b]$ we need $\forall \alpha \in (0,1)$ $$f(\alpha b + (1-\alpha) a) < (\alpha) f(b) + (1-\alpha) f(a)$$ Using this, we need to show $A(\alpha x) < \alpha A(x)$ Now $A(\alpha x) = \int_0^{\alpha x} f(t) dt = \alpha \int _{0}^{x} f(\alpha t) dt < \alpha \int_{0}^{x} f(t) dt = \alpha A(x)$ because $t > \alpha t \implies f(t) > f(\alpha t)$. Is this proof alright, and how can I write it more properly. I am self learning calculus and will then proceed to real analysis.",,"['calculus', 'functions']"
24,Finding period of rational function of trigonometric functions,Finding period of rational function of trigonometric functions,,I want to find the period of the function  $$f(x)=\frac{2\cos (3x)\cdot |\sin(5x)|\cdot 3|\tan (8x)|\cos^4(x)}{7\tan\left( \frac{x}{9}\right)\cdot \sec^3\left(\frac{2x}{3}\right)}$$ which is a rational function of trig functions. So far I have found that: the period of $\displaystyle \cos(3x)$ is $\frac{2\pi}{3};$ the period of $\displaystyle |\sin (5x)|$ is $\frac{\pi}{5};$ the period of $\displaystyle \cos^4(x)$ is $\pi$; the period of $\displaystyle \tan(x/9)$ is $9\pi$; and the period of $\displaystyle \sec^3(2x/3)$ is $3\pi$. How do I find the total period?,I want to find the period of the function  $$f(x)=\frac{2\cos (3x)\cdot |\sin(5x)|\cdot 3|\tan (8x)|\cos^4(x)}{7\tan\left( \frac{x}{9}\right)\cdot \sec^3\left(\frac{2x}{3}\right)}$$ which is a rational function of trig functions. So far I have found that: the period of $\displaystyle \cos(3x)$ is $\frac{2\pi}{3};$ the period of $\displaystyle |\sin (5x)|$ is $\frac{\pi}{5};$ the period of $\displaystyle \cos^4(x)$ is $\pi$; the period of $\displaystyle \tan(x/9)$ is $9\pi$; and the period of $\displaystyle \sec^3(2x/3)$ is $3\pi$. How do I find the total period?,,"['functions', 'periodic-functions']"
25,Find a left-inverse for the function $f:\Bbb Z \to \Bbb Z$ given by $f(n)=2n+1$.,Find a left-inverse for the function  given by .,f:\Bbb Z \to \Bbb Z f(n)=2n+1,"Find a left-inverse for the function $f:\Bbb Z \to \Bbb Z$ given by $f(n)=2n+1$. Verify that your answer is correct. Does f have a right-inverse? Explain. Hi all, I need to asses whether this function is left and/or right invertible, and then prove it using proper proof language. I'm trying to follow the way my professor taught me, but I'm not really sure I understand what I'm doing. This is what I have: Theorem. $f$ is left-invertible. Proof. $f$ is left-invertible if there is some function $g:\Bbb Z \to \Bbb Z$ such that $g \circ f = id_{\Bbb Z}$. Consider $g(n)=\frac{n-1}{2}$. Then, $g \circ f(n) =\frac{2n+1-1}{2}=n=id_{\Bbb Z}$. Therefore, $f$ is left-invertible. Does that make any sense so far? Honestly, it doesn't  make any sense to me. The other problem is that using a similar strategy, I find that $f$ is also right-invertible. However, I know that not to be true, because $f(1)=3$ and $f(2)=5$, and thus there is no $n\in\Bbb Z$ such that $f(n)=4$ (aka, the function only spits out odd numbers if we restrict the domain to integer inputs). Therefore, it is not survective. If anyone can help me understand, perhaps from the beginning, how to properly do this problem and write it out, that would be amazing. Cheers","Find a left-inverse for the function $f:\Bbb Z \to \Bbb Z$ given by $f(n)=2n+1$. Verify that your answer is correct. Does f have a right-inverse? Explain. Hi all, I need to asses whether this function is left and/or right invertible, and then prove it using proper proof language. I'm trying to follow the way my professor taught me, but I'm not really sure I understand what I'm doing. This is what I have: Theorem. $f$ is left-invertible. Proof. $f$ is left-invertible if there is some function $g:\Bbb Z \to \Bbb Z$ such that $g \circ f = id_{\Bbb Z}$. Consider $g(n)=\frac{n-1}{2}$. Then, $g \circ f(n) =\frac{2n+1-1}{2}=n=id_{\Bbb Z}$. Therefore, $f$ is left-invertible. Does that make any sense so far? Honestly, it doesn't  make any sense to me. The other problem is that using a similar strategy, I find that $f$ is also right-invertible. However, I know that not to be true, because $f(1)=3$ and $f(2)=5$, and thus there is no $n\in\Bbb Z$ such that $f(n)=4$ (aka, the function only spits out odd numbers if we restrict the domain to integer inputs). Therefore, it is not survective. If anyone can help me understand, perhaps from the beginning, how to properly do this problem and write it out, that would be amazing. Cheers",,"['functions', 'proof-verification', 'inverse-function']"
26,Is $f(x)=x^2-4x$ injective and surjective? [closed],Is  injective and surjective? [closed],f(x)=x^2-4x,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $f: A\to \mathbb{R}$ be such that $f(x) = x^2 - 4x$, where $A = \{x ‚àà \mathbb{R}: x \ge 2\}$. How do I determine if the following function is injective or surjective and has an inverse? Here's my attempt: domain: $\mathrm{dom} (f) = [2,\infty)$, co-domain: $(-\infty,\infty) = \mathbb R$. Let $a, b \in  A$. Then \begin{align} f (a) = f(b) &\Rightarrow a^2 - 4a = b^2  - 4b \\ &\Rightarrow a^2 - b^2 - 4a + 4b = 0 \\ &\Rightarrow(a + b)(a - b) - 4(a - b) = 0 \\ &\Rightarrow(a - b)(b - 4) = 0 \\ &\Rightarrow a - b = 0 \text{ or }a + b -4 = 0 \\ &\Rightarrow a = b \text{ or }a + b = 4. \end{align} Therefore, f is injective. Then I become stuck.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question If $f: A\to \mathbb{R}$ be such that $f(x) = x^2 - 4x$, where $A = \{x ‚àà \mathbb{R}: x \ge 2\}$. How do I determine if the following function is injective or surjective and has an inverse? Here's my attempt: domain: $\mathrm{dom} (f) = [2,\infty)$, co-domain: $(-\infty,\infty) = \mathbb R$. Let $a, b \in  A$. Then \begin{align} f (a) = f(b) &\Rightarrow a^2 - 4a = b^2  - 4b \\ &\Rightarrow a^2 - b^2 - 4a + 4b = 0 \\ &\Rightarrow(a + b)(a - b) - 4(a - b) = 0 \\ &\Rightarrow(a - b)(b - 4) = 0 \\ &\Rightarrow a - b = 0 \text{ or }a + b -4 = 0 \\ &\Rightarrow a = b \text{ or }a + b = 4. \end{align} Therefore, f is injective. Then I become stuck.",,"['functions', 'elementary-set-theory']"
27,Proof of $f(x)=e^x+x$ injective,Proof of  injective,f(x)=e^x+x,"I am asked: Let $f:\mathbb{R} \to \mathbb{R}$ be given by $f(x)=e^x+x$. Prove that $f$ is injective. Here's my attempt: Proof: (Contrapositive) Assume $x_1,x_2\in \mathbb{R}, x_1\neq x_2$. So if $x_1\neq x_2$, then either $x_1<x_2$ or $x_2<x_1$. If $x_1<x_2$, then $x_2=x_1+a$ for some $a\in \mathbb{R}^+$. Thus, $e^{x_1}+x_1<e^{x_1+a}+(x_1+a)\implies e^{x_1}+x_1<e^{x_1}*e^a+x_1+a\implies \frac{e^{x_1}}{e^{x_1}}<\frac{e^{x_1}*e^a}{e^{x_1}}+\frac{x_1}{e^{x_1}}\implies 1<e^a+\frac{x_1}{e^{x_1}}\implies 0<e^a+\frac{x_1}{e^{x_1}}-1$. Since $a\in \mathbb{R}^+$, $e^a\in \mathbb{R}^+,e^a>1$. Thus, this inequality must be true, so when $x_1<x_2$, $e^{x_1}+x_1<e^{x_2}+x_2\implies f(x_1)\neq f(x_2)$. Alternatively, if $x_2<x_1$, then $x_1=x_2+b$ for some $b\in \mathbb{R}^+$ Thus, $e^{x_2}+x<e^{x_2+b}+(x_2+b)\implies e^{x_2}+x_2<e^{x_2}*e^b+x_2+b\implies 1<e^b+\frac{x_2}{e^{x_1}}\implies 0<e^b+\frac{x_2}{e^{x_2}}-1$. Since $b\in \mathbb{R}^+$, $e^b\in \mathbb{R}^+,e^b>1$. Thus, this inequality must be true, so when $x_2<x_1$, $e^{x_2}+x_2<e^{x_1}+x_1\implies f(x_1)\neq f(x_2)$. In either case, $x_1\neq x_2\implies f(x_1)\neq f(x_2)$, which is the contrapositive of the definition of injectivity. Therefore, the function $f$ is injective. $\blacksquare$ Did I miss anything? Thanks!","I am asked: Let $f:\mathbb{R} \to \mathbb{R}$ be given by $f(x)=e^x+x$. Prove that $f$ is injective. Here's my attempt: Proof: (Contrapositive) Assume $x_1,x_2\in \mathbb{R}, x_1\neq x_2$. So if $x_1\neq x_2$, then either $x_1<x_2$ or $x_2<x_1$. If $x_1<x_2$, then $x_2=x_1+a$ for some $a\in \mathbb{R}^+$. Thus, $e^{x_1}+x_1<e^{x_1+a}+(x_1+a)\implies e^{x_1}+x_1<e^{x_1}*e^a+x_1+a\implies \frac{e^{x_1}}{e^{x_1}}<\frac{e^{x_1}*e^a}{e^{x_1}}+\frac{x_1}{e^{x_1}}\implies 1<e^a+\frac{x_1}{e^{x_1}}\implies 0<e^a+\frac{x_1}{e^{x_1}}-1$. Since $a\in \mathbb{R}^+$, $e^a\in \mathbb{R}^+,e^a>1$. Thus, this inequality must be true, so when $x_1<x_2$, $e^{x_1}+x_1<e^{x_2}+x_2\implies f(x_1)\neq f(x_2)$. Alternatively, if $x_2<x_1$, then $x_1=x_2+b$ for some $b\in \mathbb{R}^+$ Thus, $e^{x_2}+x<e^{x_2+b}+(x_2+b)\implies e^{x_2}+x_2<e^{x_2}*e^b+x_2+b\implies 1<e^b+\frac{x_2}{e^{x_1}}\implies 0<e^b+\frac{x_2}{e^{x_2}}-1$. Since $b\in \mathbb{R}^+$, $e^b\in \mathbb{R}^+,e^b>1$. Thus, this inequality must be true, so when $x_2<x_1$, $e^{x_2}+x_2<e^{x_1}+x_1\implies f(x_1)\neq f(x_2)$. In either case, $x_1\neq x_2\implies f(x_1)\neq f(x_2)$, which is the contrapositive of the definition of injectivity. Therefore, the function $f$ is injective. $\blacksquare$ Did I miss anything? Thanks!",,"['functions', 'proof-verification']"
28,Let $f(x)=\big(|x+a|-|x+2|+b|x+5| \big)$ be an odd function then find $a+b$,Let  be an odd function then find,f(x)=\big(|x+a|-|x+2|+b|x+5| \big) a+b,Let $f(x)=\big(|x+a|-|x+2|+b|x+5| \big)$ be an odd function then find $a+b$. My try : $$\begin{align}f(-x)&=|-x+a|-|-x+2|+b|-x+5| \\ &=-f(x) \\&= -\big(|x+a|-|x+2|+b|x+5| \big)  \end{align}$$ $$|-x+a|-|-x+2|+b|-x+5|+ \big(|x+a|-|x+2|+b|x+5|) =0$$ Now what do I do?,Let $f(x)=\big(|x+a|-|x+2|+b|x+5| \big)$ be an odd function then find $a+b$. My try : $$\begin{align}f(-x)&=|-x+a|-|-x+2|+b|-x+5| \\ &=-f(x) \\&= -\big(|x+a|-|x+2|+b|x+5| \big)  \end{align}$$ $$|-x+a|-|-x+2|+b|-x+5|+ \big(|x+a|-|x+2|+b|x+5|) =0$$ Now what do I do?,,"['calculus', 'functions', 'absolute-value']"
29,"Is there a name for this operation? $f(a, b) = a + (1 - a)b$",Is there a name for this operation?,"f(a, b) = a + (1 - a)b","Is there a name for this simple operation/function? $$(a, b) \mapsto a + (1 - a)b$$ The operator takes two real numbers that are between $0$ and $1$, and returns a real number per the formula. Intuitively, it moves the $a$ value towards $1$ by using $b$ as the fraction of the remaining distance to travel. Note that the order of the operands doesn't matter, since $a + (1 - a)b$ rearranges to $b + (1 - b)a$. Another perspective is that it's the sum, minus the product: $$(a, b) \mapsto a + b - ab$$ So, for example: $(0.5, 0.5) \mapsto 0.75$ $(0.3, 1) \mapsto 1$ $(0.47, 0.61) \mapsto 0.7933$ Thanks!","Is there a name for this simple operation/function? $$(a, b) \mapsto a + (1 - a)b$$ The operator takes two real numbers that are between $0$ and $1$, and returns a real number per the formula. Intuitively, it moves the $a$ value towards $1$ by using $b$ as the fraction of the remaining distance to travel. Note that the order of the operands doesn't matter, since $a + (1 - a)b$ rearranges to $b + (1 - b)a$. Another perspective is that it's the sum, minus the product: $$(a, b) \mapsto a + b - ab$$ So, for example: $(0.5, 0.5) \mapsto 0.75$ $(0.3, 1) \mapsto 1$ $(0.47, 0.61) \mapsto 0.7933$ Thanks!",,['functions']
30,Finding period of $f$ using the functional equation $f(x) + f(x+a+b) = f(x+a) + f(x+b)$,Finding period of  using the functional equation,f f(x) + f(x+a+b) = f(x+a) + f(x+b),"Assume that $f:\mathbb R\to\mathbb R$ , and $f(x) + f(x+a+b) = f(x+a) + f(x+b)$ where $|f(x)|\le 1 \ \forall x \in \mathbb R$ ( $a > b$ ). Find the period of the function $f(x)$ . My approach: $$f(x+a+b) - f(x+a) = f(x+b) - f(x)$$ After this, I tried replacing $x $ with $x+a $ and several other substitutions but couldn't reach a conclusive result. Also, I'm not sure how to use $ |f(x)|\le 1 $ to get the function's period. Of course, the aim is to establish a result of the form $f(x+T) = f(x)$ . It'd be great if someone could give a detailed solution. Thanks a lot! $f(x)$ is not a constant function. If it is, prove it to be so. Edit: The problem is a modified IMO 1996 shortlisted problem. In that problem, $a$ and $b$ had specific values ( $\frac16$ and $\frac17$ ), but I wish to generalize the problem for any two constants $a$ and $b$ .","Assume that , and where ( ). Find the period of the function . My approach: After this, I tried replacing with and several other substitutions but couldn't reach a conclusive result. Also, I'm not sure how to use to get the function's period. Of course, the aim is to establish a result of the form . It'd be great if someone could give a detailed solution. Thanks a lot! is not a constant function. If it is, prove it to be so. Edit: The problem is a modified IMO 1996 shortlisted problem. In that problem, and had specific values ( and ), but I wish to generalize the problem for any two constants and .",f:\mathbb R\to\mathbb R f(x) + f(x+a+b) = f(x+a) + f(x+b) |f(x)|\le 1 \ \forall x \in \mathbb R a > b f(x) f(x+a+b) - f(x+a) = f(x+b) - f(x) x  x+a   |f(x)|\le 1  f(x+T) = f(x) f(x) a b \frac16 \frac17 a b,"['functions', 'functional-equations', 'periodic-functions']"
31,Multiple soft step function,Multiple soft step function,,I want to create a function that have multiple (infinite) steps like this one: $x+\sin x$ But i want to have control of two things: how quickly it increases and when the (soft) steps occur. For example: for the function $\frac{1}{(1+e^{-x})}$ which has the following graph: We can make the step rise faster by multiplying x by a big number. One possible way to write such a function is writing it as a sum of previous function: $\sum_{i=0}^4 \frac{1}{1+e^{-(x-i)*5}}$ Unfortunately I can't use this kind of series to solve my problem. How can I obtain such function?,I want to create a function that have multiple (infinite) steps like this one: $x+\sin x$ But i want to have control of two things: how quickly it increases and when the (soft) steps occur. For example: for the function $\frac{1}{(1+e^{-x})}$ which has the following graph: We can make the step rise faster by multiplying x by a big number. One possible way to write such a function is writing it as a sum of previous function: $\sum_{i=0}^4 \frac{1}{1+e^{-(x-i)*5}}$ Unfortunately I can't use this kind of series to solve my problem. How can I obtain such function?,,['functions']
32,Derivative of bounded function when $x \to \infty$ [duplicate],Derivative of bounded function when  [duplicate],x \to \infty,"This question already has answers here : If a function has a finite limit at infinity, does that imply its derivative goes to zero? (6 answers) Closed 6 years ago . Can it be said for a differentiable bounded function $f(x)$ that if $\lim_{x \to \infty} f(x)$ exists then $\lim_{x \to \infty} f'(x)=0$ ? This holds for functions like $\arctan(x)$ and arccot$(x)$ but will it always be true and can it be proved?","This question already has answers here : If a function has a finite limit at infinity, does that imply its derivative goes to zero? (6 answers) Closed 6 years ago . Can it be said for a differentiable bounded function $f(x)$ that if $\lim_{x \to \infty} f(x)$ exists then $\lim_{x \to \infty} f'(x)=0$ ? This holds for functions like $\arctan(x)$ and arccot$(x)$ but will it always be true and can it be proved?",,"['calculus', 'functions']"
33,What Motivated the Definition of the Orthogonality of Functions?,What Motivated the Definition of the Orthogonality of Functions?,,"I am curious to know why the orthogonality of two (real) functions $f(x)$, $g(x)$ is given by: $$\int_{-L}^{L} f(x) \,g(x) \; \text{d}x = 0$$ I see a kind of similarity between this definition and the orthogonality of vectors $\vec{v}$, $\vec{w}$ $\in$ $\mathbb{R}^n$, $\,$ viz. $\vec{v} \cdot \vec{w} = v_i \, w_i = 0$. It even makes sense to me that the domain of integration should play an important role in this result. However, I'm at a loss to imagine a) the context that would've prompted such an extension; b) the meaning of orthogonality (i.e. is there any way of thinking of this that is as intuitive as the geometric orthogonality of the vector version, where we can intuitively understand the meaning of orthogonality for vectors in $\mathbb{R}^2$ and $\mathbb{R}^3$ and extend the concept to higher dimensions?). Perhaps the most concise way of asking my question would be is there an alternative way of viewing the definition of orthogonality of functions that is analogous to the geometric definition of the vector dot product (i.e. $\vec{v} \cdot \vec{w} = |\vec{v}|\, |\vec{w}| \cos\theta$)? I looked at this question , but it doesn't really get at what I'm after.","I am curious to know why the orthogonality of two (real) functions $f(x)$, $g(x)$ is given by: $$\int_{-L}^{L} f(x) \,g(x) \; \text{d}x = 0$$ I see a kind of similarity between this definition and the orthogonality of vectors $\vec{v}$, $\vec{w}$ $\in$ $\mathbb{R}^n$, $\,$ viz. $\vec{v} \cdot \vec{w} = v_i \, w_i = 0$. It even makes sense to me that the domain of integration should play an important role in this result. However, I'm at a loss to imagine a) the context that would've prompted such an extension; b) the meaning of orthogonality (i.e. is there any way of thinking of this that is as intuitive as the geometric orthogonality of the vector version, where we can intuitively understand the meaning of orthogonality for vectors in $\mathbb{R}^2$ and $\mathbb{R}^3$ and extend the concept to higher dimensions?). Perhaps the most concise way of asking my question would be is there an alternative way of viewing the definition of orthogonality of functions that is analogous to the geometric definition of the vector dot product (i.e. $\vec{v} \cdot \vec{w} = |\vec{v}|\, |\vec{w}| \cos\theta$)? I looked at this question , but it doesn't really get at what I'm after.",,"['functions', 'inner-products', 'orthogonality']"
34,Difference between $y = x^{1/2}$ & $y = x^{2/4}$,Difference between  &,y = x^{1/2} y = x^{2/4},The other day something occurred to me when graphing $y = x^{1/2}$. I understand that this is equivalent to $y = \sqrt{x}$ & this can't have negative values for $x$. But is it not also equivalent to $y = x^{2/4}$ which in turn is $y = \sqrt[4]{x^2}$ which would allow negative values for $x$? I know the easy answer here is to say you should simplify $\frac24$ first but is there a deeper mathematical explanation for what looks to me to be a bit of a paradox?,The other day something occurred to me when graphing $y = x^{1/2}$. I understand that this is equivalent to $y = \sqrt{x}$ & this can't have negative values for $x$. But is it not also equivalent to $y = x^{2/4}$ which in turn is $y = \sqrt[4]{x^2}$ which would allow negative values for $x$? I know the easy answer here is to say you should simplify $\frac24$ first but is there a deeper mathematical explanation for what looks to me to be a bit of a paradox?,,"['functions', 'graphing-functions']"
35,Doubt about substitution in$\int_{-1}^{1}\sqrt{1+x^2}dx$,Doubt about substitution in,\int_{-1}^{1}\sqrt{1+x^2}dx,"I've tried this substitution in this integral $$\int_{-1}^{1}\sqrt{1+x^2}dx$$ Let $x^2=t$, so $x=\sqrt{t}$ and $dx=\frac{1}{2\sqrt{t}}dt$. So we have $$\frac{1}{2}\int_{1}^{1}\sqrt{\frac{1+t}{t}}dt=0$$ Which is obviously wrong. I know that this integral can be done with integration by parts or hyperbolic substitution, I want to know why this happens. My idea is that $x^2$ isn't always invertible, it is only on $[0, +\infty)$, and that causes this problem with the interval of integration. Am I right? Thanks for your time.","I've tried this substitution in this integral $$\int_{-1}^{1}\sqrt{1+x^2}dx$$ Let $x^2=t$, so $x=\sqrt{t}$ and $dx=\frac{1}{2\sqrt{t}}dt$. So we have $$\frac{1}{2}\int_{1}^{1}\sqrt{\frac{1+t}{t}}dt=0$$ Which is obviously wrong. I know that this integral can be done with integration by parts or hyperbolic substitution, I want to know why this happens. My idea is that $x^2$ isn't always invertible, it is only on $[0, +\infty)$, and that causes this problem with the interval of integration. Am I right? Thanks for your time.",,"['integration', 'functions', 'inverse-function']"
36,Distinct roots for a continuous function with $\int^{1}_{0}{f(x)}\text{d}x=\int^{1}_{0}{xf(x)}\text{d}x=0.$,Distinct roots for a continuous function with,\int^{1}_{0}{f(x)}\text{d}x=\int^{1}_{0}{xf(x)}\text{d}x=0.,"Let $f:\left[0,1\right] \to \mathbb{R}$ be a continuous function and $$\int^{1}_{0}{f(x)}\text{d}x=\int^{1}_{0}{xf(x)}\text{d}x=0.$$ Prove that $f$ has at least two distinct roots. What can I say it is that if $f$ is continuous and $\displaystyle \int^{1}_{0}{f(x)}\text{d}x=0$ will result that $f$ has a root which belongs to $\left(0,1\right)$. From this point my idea is going down.","Let $f:\left[0,1\right] \to \mathbb{R}$ be a continuous function and $$\int^{1}_{0}{f(x)}\text{d}x=\int^{1}_{0}{xf(x)}\text{d}x=0.$$ Prove that $f$ has at least two distinct roots. What can I say it is that if $f$ is continuous and $\displaystyle \int^{1}_{0}{f(x)}\text{d}x=0$ will result that $f$ has a root which belongs to $\left(0,1\right)$. From this point my idea is going down.",,"['integration', 'functions', 'definite-integrals', 'continuity']"
37,Inequality: $\ln(\frac{a+y}{y})-\frac{a}{a+y}> 0$,Inequality:,\ln(\frac{a+y}{y})-\frac{a}{a+y}> 0,"I want to show that the function $g(y)=y\ln(1+\frac{a}{y})$ is increasing for $y>0, a>0$. I've found the derivative and set up the inequality that I need to show: $\ln(\frac{a+y}{y})-\frac{a}{a+y}> 0$ I'm not sure about how to show it. Would appreciate a suggestion or hint.","I want to show that the function $g(y)=y\ln(1+\frac{a}{y})$ is increasing for $y>0, a>0$. I've found the derivative and set up the inequality that I need to show: $\ln(\frac{a+y}{y})-\frac{a}{a+y}> 0$ I'm not sure about how to show it. Would appreciate a suggestion or hint.",,"['functions', 'inequality']"
38,"Possible variation of the $""3n+1""$ problem as $""3n+K""$",Possible variation of the  problem as,"""3n+1"" ""3n+K""","Variations of the Collatz problem Let $$ f(n) = \begin{cases} 3n+K          & \text {$n$ odd} \\ \frac{n}{2}   & \text {$n$ even}  \end{cases} $$ with $$K\in\mathbb Z^*$$ I am looking for $K\neq1$ such that $(\forall n\in\mathbb{N})\,\,\, f^k(n)=1$ for large enough $k$.","Variations of the Collatz problem Let $$ f(n) = \begin{cases} 3n+K          & \text {$n$ odd} \\ \frac{n}{2}   & \text {$n$ even}  \end{cases} $$ with $$K\in\mathbb Z^*$$ I am looking for $K\neq1$ such that $(\forall n\in\mathbb{N})\,\,\, f^k(n)=1$ for large enough $k$.",,"['number-theory', 'functions', 'examples-counterexamples', 'collatz-conjecture']"
39,Is a unary function a binary relation,Is a unary function a binary relation,,"$f: X \rightarrow Y$ is a unary function, however writing it in relation notation, we would write it $xRy$, which would be binary relation. Is my assumption that a $n$-ary function, corresponds to a $(n+1)$-ary relation correct?","$f: X \rightarrow Y$ is a unary function, however writing it in relation notation, we would write it $xRy$, which would be binary relation. Is my assumption that a $n$-ary function, corresponds to a $(n+1)$-ary relation correct?",,"['functions', 'relations']"
40,How to guess the function by its values on the mesh?,How to guess the function by its values on the mesh?,,"How to guess the function by its values on the mesh? More precisely, I have the value of a function on some uniform mesh. If you plot the graph of this function by points, you get the following picture. The picture quality is poor, but I have values at 11325 points on a uniform mesh. What are the ways to guess the analytical representation of this function? My main idea is to find with some accuracy the first few coefficients of the Taylor series, to restore the exact values ‚Äã‚Äãof the coefficients and sum the series. Attempt number 1. Approximate the function by the Lagrange interpolation polynomial on a uniform mesh. This attempt failed, because on a uniform mesh the Lagrange polynomial even for small degrees (about 10) became very different from the function and had huge coefficients. Attempt number 2. The method of coordinate-wise descent for the coefficients of the interpolation polynomial. Failed, because the coefficients instantly slid into some local extremum. Attempt number 3. Approximate the function by the Lagrange interpolation polynomial on the Chebyshev mesh. I managed to approximate my function with a polynomial of degree 30 with an error of about 0.01 in the C-norm, but the coefficients again turned out to be quite large and completely different from the Taylor coefficients. I will be happy with any help or ideas! Here is the values of the function .","How to guess the function by its values on the mesh? More precisely, I have the value of a function on some uniform mesh. If you plot the graph of this function by points, you get the following picture. The picture quality is poor, but I have values at 11325 points on a uniform mesh. What are the ways to guess the analytical representation of this function? My main idea is to find with some accuracy the first few coefficients of the Taylor series, to restore the exact values ‚Äã‚Äãof the coefficients and sum the series. Attempt number 1. Approximate the function by the Lagrange interpolation polynomial on a uniform mesh. This attempt failed, because on a uniform mesh the Lagrange polynomial even for small degrees (about 10) became very different from the function and had huge coefficients. Attempt number 2. The method of coordinate-wise descent for the coefficients of the interpolation polynomial. Failed, because the coefficients instantly slid into some local extremum. Attempt number 3. Approximate the function by the Lagrange interpolation polynomial on the Chebyshev mesh. I managed to approximate my function with a polynomial of degree 30 with an error of about 0.01 in the C-norm, but the coefficients again turned out to be quite large and completely different from the Taylor coefficients. I will be happy with any help or ideas! Here is the values of the function .",,"['real-analysis', 'functions', 'numerical-methods']"
41,"Hoffman and Kunze , linear algebra Sec 3.2 exercise 9","Hoffman and Kunze , linear algebra Sec 3.2 exercise 9",,"Let $T$ be a linear operator on the finite-dimensional space $V.$ Suppose there is a linear operator $U$ on $V$ such that $TU=I.$ Prove that $T$ is invertible and $U=T^{-1}.$ Attempt: Let $\dim V=n$ and $\{\alpha_i\}_{i=1}^n$ a basis for $V$. We claim that $\{U(\alpha_i)_{i=1}^n\}$ is a basis for $V.$ If not then there exists scalars $c_i$'s $\in F$ not all zero such that $\sum c_iU(\alpha_i)=0.$ Applying $T$ on both sides we get $\sum c_iTU(\alpha_i)=\sum c_i\alpha_i=0,$ a contradiction. Thus $\{U(\alpha_i)_{i=1}^n\}$ is a basis for $V.$ Now we observe that $T[U(\alpha_i)]=\alpha_i$ since $TU=I.$ We infer that $T$ and $U$ are invertible since they map basis vectors to basis vectors. It remains to show that $U=T^{-1}.$ Can I say that $U=T^{-1}$ using $TU=I$? I am not sure if I can use this since I don't know if inverses are unique.","Let $T$ be a linear operator on the finite-dimensional space $V.$ Suppose there is a linear operator $U$ on $V$ such that $TU=I.$ Prove that $T$ is invertible and $U=T^{-1}.$ Attempt: Let $\dim V=n$ and $\{\alpha_i\}_{i=1}^n$ a basis for $V$. We claim that $\{U(\alpha_i)_{i=1}^n\}$ is a basis for $V.$ If not then there exists scalars $c_i$'s $\in F$ not all zero such that $\sum c_iU(\alpha_i)=0.$ Applying $T$ on both sides we get $\sum c_iTU(\alpha_i)=\sum c_i\alpha_i=0,$ a contradiction. Thus $\{U(\alpha_i)_{i=1}^n\}$ is a basis for $V.$ Now we observe that $T[U(\alpha_i)]=\alpha_i$ since $TU=I.$ We infer that $T$ and $U$ are invertible since they map basis vectors to basis vectors. It remains to show that $U=T^{-1}.$ Can I say that $U=T^{-1}$ using $TU=I$? I am not sure if I can use this since I don't know if inverses are unique.",,"['linear-algebra', 'functions', 'linear-transformations']"
42,Weird functional equation $(e^x-1)f(2x)=\left(e^{2x}-1\right)f(x)$,Weird functional equation,(e^x-1)f(2x)=\left(e^{2x}-1\right)f(x),"I had a rehearsal test today and got this question in the test that completely stumped me. Let $f: \mathbb{R} \to \mathbb{R}$ be a non constant continuous function such that $$(e^x-1)f(2x)=\left(e^{2x}-1\right)f(x)$$ If $f'(0)=1$ , then what are $f(x)$ and $f(2x)$ ? My try: I just differentiated both sides with respect to $x$ and made use of $f'(0)=1$ , but that got me nowhere. Please help me someone. Thanks in advance.","I had a rehearsal test today and got this question in the test that completely stumped me. Let be a non constant continuous function such that If , then what are and ? My try: I just differentiated both sides with respect to and made use of , but that got me nowhere. Please help me someone. Thanks in advance.",f: \mathbb{R} \to \mathbb{R} (e^x-1)f(2x)=\left(e^{2x}-1\right)f(x) f'(0)=1 f(x) f(2x) x f'(0)=1,"['functions', 'exponential-function', 'functional-equations']"
43,Finding the value of $f(1)$ from a given functional equation,Finding the value of  from a given functional equation,f(1),"A function $f: \mathbb{Q}^+ \cup \{0\} \to \mathbb{Q}^+ \cup \{0\}$ is defined such that $$ f(x) + f(y) + 2xyf(xy) = \frac{f(xy)}{f(x+y)}$$   Then what is the value of $\left[f(1)\right]$ (where $[.]$ denotes the greatest integer function)? I proceeded this way: Putting $x=y=0$ I got $f(0) = \frac{1}{2}$ (assuming $f(0) \neq 0$) Again putting $y=0$ I got $f(x) + f(0) = \frac{f(0}{f(x)}$ which gave 2 values of $f(x)$ as $-1$ and $\frac{1}{2}$. As $f(0)$ was equal to $\frac{1}{2}$ so I assumed $f(x)$ as a constant function having value $\frac{1}{2}$ for all $x$. When $f(0) = 0$ then I got $f(x) = 0$ for all $x$. But the answer was given to be equal to $1$ which means $f(1) \in [1,2)$. Where am I wrong?","A function $f: \mathbb{Q}^+ \cup \{0\} \to \mathbb{Q}^+ \cup \{0\}$ is defined such that $$ f(x) + f(y) + 2xyf(xy) = \frac{f(xy)}{f(x+y)}$$   Then what is the value of $\left[f(1)\right]$ (where $[.]$ denotes the greatest integer function)? I proceeded this way: Putting $x=y=0$ I got $f(0) = \frac{1}{2}$ (assuming $f(0) \neq 0$) Again putting $y=0$ I got $f(x) + f(0) = \frac{f(0}{f(x)}$ which gave 2 values of $f(x)$ as $-1$ and $\frac{1}{2}$. As $f(0)$ was equal to $\frac{1}{2}$ so I assumed $f(x)$ as a constant function having value $\frac{1}{2}$ for all $x$. When $f(0) = 0$ then I got $f(x) = 0$ for all $x$. But the answer was given to be equal to $1$ which means $f(1) \in [1,2)$. Where am I wrong?",,['functions']
44,Pointwise convergence of $f_n(x) = (x+1)\arctan(x^n)$,Pointwise convergence of,f_n(x) = (x+1)\arctan(x^n),"I want to study the pointwise convergence of $f_n(x) = (x+1)\arctan(x^n)$ on $R$ but I have trouble establishing pointwise convergence on the interval $I = [-\infty, -1)$. My reasoning is the following: When $x\in I$, $x^n$ diverges, hence, $\arctan(x^n)$ is also divergent. Since $\arctan(x^n)$ diverges as $n \to \infty$, $f_n(x)$ is also divergent. Is my reasoning correct or does this count as a rigorous proof at all? Thanks.","I want to study the pointwise convergence of $f_n(x) = (x+1)\arctan(x^n)$ on $R$ but I have trouble establishing pointwise convergence on the interval $I = [-\infty, -1)$. My reasoning is the following: When $x\in I$, $x^n$ diverges, hence, $\arctan(x^n)$ is also divergent. Since $\arctan(x^n)$ diverges as $n \to \infty$, $f_n(x)$ is also divergent. Is my reasoning correct or does this count as a rigorous proof at all? Thanks.",,"['real-analysis', 'functions', 'pointwise-convergence']"
45,"Uniform continuity of $f(x) = \frac{x+1}{x+2}$ on $(-2,\infty)$",Uniform continuity of  on,"f(x) = \frac{x+1}{x+2} (-2,\infty)","Is the function $f(x) = \frac{x+1}{x+2}$ uniformly continuous on $(-2,\infty)$?   I know how to prove this for the case when the domain is closed or is, say,  $[-1, \infty)$,  but I am not sure how to estimate the fraction from above when working with this domain.","Is the function $f(x) = \frac{x+1}{x+2}$ uniformly continuous on $(-2,\infty)$?   I know how to prove this for the case when the domain is closed or is, say,  $[-1, \infty)$,  but I am not sure how to estimate the fraction from above when working with this domain.",,"['functions', 'uniform-continuity']"
46,Standard notation for expressing a certain binary operation between functions,Standard notation for expressing a certain binary operation between functions,,"Given two functions whose outputs coincide at all values in the intersection of their domains, is there some commonly used notation to express the function whose graph is formed by the union of both those function's graphs? Symbolically given any two functions $f:A\to X$ and $g:B\to Y$ with $f(r)=g(r)$ for all $r\in A\cap B$ I'm looking for some standard notation to write the function $h:A\cup B\to X\cup Y$ defined by: $$h(r)=\begin{cases} f(r)& \text{if } r\in A\\ g(r)& \text{if } r\in B\end{cases}$$ So far I've just been writing $h=f\cup g$, as this notation seems pretty natural and also satisfies a lot of nice properties involving the standard usage of the union operator between sets. For example: $$f\cup g=g\cup f$$  $$(f\cup g)\cup h=f\cup (g\cup h)$$  $$\text{dom}(f\cup g)=\text{dom}(f)\cup \text{dom}(g)$$  $$\text{range}(f\cup g)=\text{range}(f)\cup \text{range}(g)$$  $$(f\cup g)[U]=f[U\cap A]\cup g[U\cap B] \text{ for any subset } U\subseteq A\cup B$$  $$\text{ If } f \text{ and } g \text{ are bijective then so is } f\cup g \text{ further we have } (f\cup g)^{-1}=f^{-1}\cup g^{-1}$$ In particular a recent example of where this notation would have been useful, was when I was dealing with three functions $f:A\to X$ and $g:B\to Y$ and $h:C\to Z$ as well as two binary operations $*$ on $A\times B$ to $C$ and $\cdot$ on $X\times Y$ to $Z$ which satisfied: $$h(a*b)=f(a)\cdot g(b)$$ Now using the previous notation this is equivalent to the identity: $$(f\cup g\cup h)(a*b)=(f\cup g\cup h)(a)\cdot (f\cup g\cup h)(b)$$ Thus instead of writing all the aforementioned relations I could have just more concisely wrote that $f\cup g\cup h$ is a homomorphism from $(*,A\times B)$ to $(\cdot,X\times Y)$. However for the sake of communicability I'm hesitant to define the ""union"" of functions in the way that I did and so I'm curious if there is some standard notation for expressing this binary operation between arbitrary functions.","Given two functions whose outputs coincide at all values in the intersection of their domains, is there some commonly used notation to express the function whose graph is formed by the union of both those function's graphs? Symbolically given any two functions $f:A\to X$ and $g:B\to Y$ with $f(r)=g(r)$ for all $r\in A\cap B$ I'm looking for some standard notation to write the function $h:A\cup B\to X\cup Y$ defined by: $$h(r)=\begin{cases} f(r)& \text{if } r\in A\\ g(r)& \text{if } r\in B\end{cases}$$ So far I've just been writing $h=f\cup g$, as this notation seems pretty natural and also satisfies a lot of nice properties involving the standard usage of the union operator between sets. For example: $$f\cup g=g\cup f$$  $$(f\cup g)\cup h=f\cup (g\cup h)$$  $$\text{dom}(f\cup g)=\text{dom}(f)\cup \text{dom}(g)$$  $$\text{range}(f\cup g)=\text{range}(f)\cup \text{range}(g)$$  $$(f\cup g)[U]=f[U\cap A]\cup g[U\cap B] \text{ for any subset } U\subseteq A\cup B$$  $$\text{ If } f \text{ and } g \text{ are bijective then so is } f\cup g \text{ further we have } (f\cup g)^{-1}=f^{-1}\cup g^{-1}$$ In particular a recent example of where this notation would have been useful, was when I was dealing with three functions $f:A\to X$ and $g:B\to Y$ and $h:C\to Z$ as well as two binary operations $*$ on $A\times B$ to $C$ and $\cdot$ on $X\times Y$ to $Z$ which satisfied: $$h(a*b)=f(a)\cdot g(b)$$ Now using the previous notation this is equivalent to the identity: $$(f\cup g\cup h)(a*b)=(f\cup g\cup h)(a)\cdot (f\cup g\cup h)(b)$$ Thus instead of writing all the aforementioned relations I could have just more concisely wrote that $f\cup g\cup h$ is a homomorphism from $(*,A\times B)$ to $(\cdot,X\times Y)$. However for the sake of communicability I'm hesitant to define the ""union"" of functions in the way that I did and so I'm curious if there is some standard notation for expressing this binary operation between arbitrary functions.",,"['abstract-algebra', 'functions', 'elementary-set-theory', 'graphing-functions', 'binary-operations']"
47,Determining the image of a map,Determining the image of a map,,"Let $\mathbb{P}^1(\mathbb{C})\times \mathbb{P}^1(\mathbb{C})\rightarrow \mathbb{P}^3(\mathbb{C})$, $[a:b],[c:d]\mapsto[ac:ad:bc:bd]=[z_0:z_1:z_2:z_3]$. How to show that $Z_0=Z(z_0z_3-z_1z_2)$ is a subset of the image of this map? I take a point $[z_0:z_1:z_2:z_3]\in Z_0$ and I need to find its preimage. I tried to consider two cases: $z_0=0$ and $z_0\ne 0$. The former yields $5$ subcases: $(z_1,z_2,z_3)=(0,\ne 0, 0)$ $(z_1,z_2,z_3)=(0, \ne 0, \ne 0)$ $(z_1,z_2,z_3)=(\ne 0, 0, 0)$ $(z_1,z_2,z_3)=(\ne 0, 0, \ne 0)$ $(z_1,z_2,z_3)=(0,0,\ne 0)$ And the latter yields $4$ subcases: $(z_1,z_2,z_3)=(0,\ne 0, 0)$ $(z_1,z_2,z_3)=(\ne 0, 0,0$ $(z_1,z_2,z_3)=(0,0,0)$ $(z_1,z_2,z_3)=(\ne 0, \ne 0, \ne 0)$ I concentrate on the first $5$ subcases. I managed to find preimages for cases $1$ and $3$ (they are respectively $[z_0:z_2],[1:0]$ and $[1:0],[z_0:z_1]$), but I don't know how to proceed because for example in case $2$ I need to find a preimage of $[z_0:0:z_2:z_3]$ with $z_i\ne 0$, but I think this is impossible.","Let $\mathbb{P}^1(\mathbb{C})\times \mathbb{P}^1(\mathbb{C})\rightarrow \mathbb{P}^3(\mathbb{C})$, $[a:b],[c:d]\mapsto[ac:ad:bc:bd]=[z_0:z_1:z_2:z_3]$. How to show that $Z_0=Z(z_0z_3-z_1z_2)$ is a subset of the image of this map? I take a point $[z_0:z_1:z_2:z_3]\in Z_0$ and I need to find its preimage. I tried to consider two cases: $z_0=0$ and $z_0\ne 0$. The former yields $5$ subcases: $(z_1,z_2,z_3)=(0,\ne 0, 0)$ $(z_1,z_2,z_3)=(0, \ne 0, \ne 0)$ $(z_1,z_2,z_3)=(\ne 0, 0, 0)$ $(z_1,z_2,z_3)=(\ne 0, 0, \ne 0)$ $(z_1,z_2,z_3)=(0,0,\ne 0)$ And the latter yields $4$ subcases: $(z_1,z_2,z_3)=(0,\ne 0, 0)$ $(z_1,z_2,z_3)=(\ne 0, 0,0$ $(z_1,z_2,z_3)=(0,0,0)$ $(z_1,z_2,z_3)=(\ne 0, \ne 0, \ne 0)$ I concentrate on the first $5$ subcases. I managed to find preimages for cases $1$ and $3$ (they are respectively $[z_0:z_2],[1:0]$ and $[1:0],[z_0:z_1]$), but I don't know how to proceed because for example in case $2$ I need to find a preimage of $[z_0:0:z_2:z_3]$ with $z_i\ne 0$, but I think this is impossible.",,"['functions', 'algebraic-geometry', 'projective-geometry', 'projective-space']"
48,Gardener and mole one-to-one correspondence question,Gardener and mole one-to-one correspondence question,,"In a flat plane, I have an infinite number of holes in a straight line. A mole lies in one of the holes and will travel $d$ number of holes every morning, and he will move that number of holes in the same direction. We do not know which hole the mole is in. A gardener wants to catch this mole because it is destroying his crops. A gardener will only check once every night at a particular hole. If the mole is there, it is caught. If it is not there, the gardener goes back home. What should the gardener do so that he will catch the mole eventually? (Assuming there exist an infinite number of days) What I have tried: I label the holes $...,-n, -n+1, -n+2,..., -2, -1, 0, 1, 2, 3, ..., n-2, n-1, n...$. I assume that if the mole starts in hole $0$ and travels $2$ steps back, then he is in hole $-2$. If the mole starts in hole $0$ and travels $2$ steps forward, then he is in hole $2$. Suppose both the mole and the gardener starts on the same hole, and for simplicity, both the mole and gardener starts on hole $0$. What the farmer can do: Check hole $1$ on the first day, check hole $-2$ on the second day, $6$ on the third day, $-8$ on the fourth day, $15$ on the fifth day, $-18$ on the sixth day.. In general, he should check: Hole # = $n.\frac {-n}{2}$ if $n$ is even, and Hole # = $n.\lfloor \frac {n+1}{2} \rfloor$ if $n$ is odd, where $n$ is the $n^{th}$ day. In my earlier statement, I have proved that I can form a one-to-one correspondence. For example, $f(1)=1, f(2)=-1, f(3)=2, f(4)=-2,...$. Hence, the gardener is able to find a way to hunt down the moles. Hence, even though he does not know how many steps does the mole move a day or in which direction, the gardener am still able to track it down. Now here's the real problem. The gardener does not know which hole the mole is in, nor how many steps or in which direction the mole is heading. What can the gardener do to catch the mole eventually? Any answers are appreciated but I hope that you can explain why the answer works that way too! Thank you! It would be good to show me how a one-to-one correspondence works for this question too!","In a flat plane, I have an infinite number of holes in a straight line. A mole lies in one of the holes and will travel $d$ number of holes every morning, and he will move that number of holes in the same direction. We do not know which hole the mole is in. A gardener wants to catch this mole because it is destroying his crops. A gardener will only check once every night at a particular hole. If the mole is there, it is caught. If it is not there, the gardener goes back home. What should the gardener do so that he will catch the mole eventually? (Assuming there exist an infinite number of days) What I have tried: I label the holes $...,-n, -n+1, -n+2,..., -2, -1, 0, 1, 2, 3, ..., n-2, n-1, n...$. I assume that if the mole starts in hole $0$ and travels $2$ steps back, then he is in hole $-2$. If the mole starts in hole $0$ and travels $2$ steps forward, then he is in hole $2$. Suppose both the mole and the gardener starts on the same hole, and for simplicity, both the mole and gardener starts on hole $0$. What the farmer can do: Check hole $1$ on the first day, check hole $-2$ on the second day, $6$ on the third day, $-8$ on the fourth day, $15$ on the fifth day, $-18$ on the sixth day.. In general, he should check: Hole # = $n.\frac {-n}{2}$ if $n$ is even, and Hole # = $n.\lfloor \frac {n+1}{2} \rfloor$ if $n$ is odd, where $n$ is the $n^{th}$ day. In my earlier statement, I have proved that I can form a one-to-one correspondence. For example, $f(1)=1, f(2)=-1, f(3)=2, f(4)=-2,...$. Hence, the gardener is able to find a way to hunt down the moles. Hence, even though he does not know how many steps does the mole move a day or in which direction, the gardener am still able to track it down. Now here's the real problem. The gardener does not know which hole the mole is in, nor how many steps or in which direction the mole is heading. What can the gardener do to catch the mole eventually? Any answers are appreciated but I hope that you can explain why the answer works that way too! Thank you! It would be good to show me how a one-to-one correspondence works for this question too!",,"['functions', 'discrete-mathematics', 'proof-verification', 'problem-solving', 'infinity']"
49,Cardinality of set of functions with given domain and co-domain,Cardinality of set of functions with given domain and co-domain,,"I am reading a book (Klein, Philip. Coding the Matrix: Linear Algebra through Computer Science Applications)and came across the following statement: I'm having trouble understanding what this means, I realize it's talking about the cardinalities, but I don't understand the ""pun"" and can't come up with a concrete example to illustrate this ""fact"".","I am reading a book (Klein, Philip. Coding the Matrix: Linear Algebra through Computer Science Applications)and came across the following statement: I'm having trouble understanding what this means, I realize it's talking about the cardinalities, but I don't understand the ""pun"" and can't come up with a concrete example to illustrate this ""fact"".",,"['linear-algebra', 'functions']"
50,What's the symbol for diffeomorphism? [duplicate],What's the symbol for diffeomorphism? [duplicate],,"This question already has answers here : Notations involving squiggly lines over horizontal lines (3 answers) Closed 7 years ago . I know that isomorphism has a well known symbol, but what about diffeomorphism?","This question already has answers here : Notations involving squiggly lines over horizontal lines (3 answers) Closed 7 years ago . I know that isomorphism has a well known symbol, but what about diffeomorphism?",,"['functions', 'notation', 'smooth-manifolds']"
51,Does there exist continous function $f(x)$ defined on $(-\infty ; +\infty)$?,Does there exist continous function  defined on ?,f(x) (-\infty ; +\infty),"Does there  exist continous function $f(x)$ such that  $$f(x)=\begin{cases} \frac{m}{n} & \text{if } x \text{ is irrational,} \\ \text{irrational} & \text{if } x \text{ is rational} \end{cases}$$ I think it's impossible, as definition of that function is similar to Dirichlet Function or Thomae's function. And these functions are always discontinous somewhere. Please help, I don't know what to start with. I'm first year undergraduate","Does there  exist continous function $f(x)$ such that  $$f(x)=\begin{cases} \frac{m}{n} & \text{if } x \text{ is irrational,} \\ \text{irrational} & \text{if } x \text{ is rational} \end{cases}$$ I think it's impossible, as definition of that function is similar to Dirichlet Function or Thomae's function. And these functions are always discontinous somewhere. Please help, I don't know what to start with. I'm first year undergraduate",,"['calculus', 'functions', 'continuity']"
52,Term-by-term differentiation of a sequence of functions without uniform convergence of derivatives,Term-by-term differentiation of a sequence of functions without uniform convergence of derivatives,,"Consider a sequence of functions $f_n(x)$, which converges to $f(x)$ pointwise on the interval $(0,1)$. The functions $f_n(x)$ and the limit function $f(x)$ are differentiable, with derivatives $f'_n(x)$ and $f'(x)$ respectively. Assume that the sequence $f'_n(x)$ converges to a function pointwise. Because convergence of the derivatives is not necessarily uniform, the usual theorem for term-by-term differentiability cannot be applied to give $\lim_{n \rightarrow \infty} f'_n(x) = f'(x)$. However, If it is known that both $f_n(x)$ and $x f'_n(x)$ converge uniformly on $[0,1]$, does that imply that $\lim_{n \rightarrow \infty} f'_n(x) = f'(x)$ on $(0,1)$? I think the answer is yes. But it strikes me a bit that I get the desired result side-stepping the need for uniform convergence of $f'_n(x)$. So I'll post my proof and please let me know if there's any mistake in it. Or if the result is well-known, can you point me to a relevant theorem?","Consider a sequence of functions $f_n(x)$, which converges to $f(x)$ pointwise on the interval $(0,1)$. The functions $f_n(x)$ and the limit function $f(x)$ are differentiable, with derivatives $f'_n(x)$ and $f'(x)$ respectively. Assume that the sequence $f'_n(x)$ converges to a function pointwise. Because convergence of the derivatives is not necessarily uniform, the usual theorem for term-by-term differentiability cannot be applied to give $\lim_{n \rightarrow \infty} f'_n(x) = f'(x)$. However, If it is known that both $f_n(x)$ and $x f'_n(x)$ converge uniformly on $[0,1]$, does that imply that $\lim_{n \rightarrow \infty} f'_n(x) = f'(x)$ on $(0,1)$? I think the answer is yes. But it strikes me a bit that I get the desired result side-stepping the need for uniform convergence of $f'_n(x)$. So I'll post my proof and please let me know if there's any mistake in it. Or if the result is well-known, can you point me to a relevant theorem?",,"['calculus', 'sequences-and-series', 'functions', 'convergence-divergence', 'uniform-convergence']"
53,Proving a function is unique because it is composed of unique functions?,Proving a function is unique because it is composed of unique functions?,,"$$x(t) = E(t) + O(t),$$ where $E(t)$ is an even function and $O(t)$ is an odd function. Prove that $$E(t) = (x(t) + x(-t))/2$$ is unique. Can I just say that $x(t)$ is unique and $x(-t)$ is unique because both each represent only one particular function, so $E(t)$ must be unique?","$$x(t) = E(t) + O(t),$$ where $E(t)$ is an even function and $O(t)$ is an odd function. Prove that $$E(t) = (x(t) + x(-t))/2$$ is unique. Can I just say that $x(t)$ is unique and $x(-t)$ is unique because both each represent only one particular function, so $E(t)$ must be unique?",,"['functions', 'proof-verification']"
54,When a union of a family $\{f_i \}_{i \in I}$ of functions $f_i: X_i \to Y_i$ is itself a function $\bigcup_{i \in I} X_i \to \bigcup_{i \in I} Y_i$?,When a union of a family  of functions  is itself a function ?,\{f_i \}_{i \in I} f_i: X_i \to Y_i \bigcup_{i \in I} X_i \to \bigcup_{i \in I} Y_i,"I wish to know when a union of a family $\{f_i \}_{i \in I}$ of functions $f_i: X_i \to Y_i$ is itself a function $\bigcup_{i \in I} X_i \to \bigcup_{i \in I} Y_i$. I take the definition of a function $X \to Y$ as of a relation $f \subseteq X \times Y$ so that $\mathrm{dom \ f} = \{ x \in X \ | \ \exists y \in Y: \ (x,y) \in f \} = X$ and $(x,y_1), \ (x,y_2) \in f \Rightarrow y_1 = y_2$. Now, let $\{ f_i \}_{i \in I}$ be a family of functions, $f_i \in {Y_i}^{X_i}$. I know that $\bigcup_{i \in I} f_i \subseteq \bigcup_{i \in I} X_i \times Y_i \subseteq \bigcup_{i \in I} X_i \times \bigcup_{i \in I} Y_i$. What is more, $x \in \bigcup_{i \in I} X_i \Leftrightarrow \exists i \in I: \ x \in X_i \Rightarrow \exists y \in Y_i: \ (x,y) \in f_i \Rightarrow \exists y \in \bigcup_{i \in I} Y_i: (x,y) \in \bigcup_{i \in I} f_i \Leftrightarrow x \in \mathrm{dom \ \bigcup_{i \in I} f_i}$. What is left to check is when $(x,y_1), (x,y_2) \in \bigcup_{i \in I} f_i \Rightarrow y_1 = y_2$. But $(x,y_1), (x,y_2) \in \bigcup_{i \in I} f_i$ means that there exists $i, j \in I$ so that $f_i(x) = y_1$ and $f_j(x) = y_2$. Is it right?","I wish to know when a union of a family $\{f_i \}_{i \in I}$ of functions $f_i: X_i \to Y_i$ is itself a function $\bigcup_{i \in I} X_i \to \bigcup_{i \in I} Y_i$. I take the definition of a function $X \to Y$ as of a relation $f \subseteq X \times Y$ so that $\mathrm{dom \ f} = \{ x \in X \ | \ \exists y \in Y: \ (x,y) \in f \} = X$ and $(x,y_1), \ (x,y_2) \in f \Rightarrow y_1 = y_2$. Now, let $\{ f_i \}_{i \in I}$ be a family of functions, $f_i \in {Y_i}^{X_i}$. I know that $\bigcup_{i \in I} f_i \subseteq \bigcup_{i \in I} X_i \times Y_i \subseteq \bigcup_{i \in I} X_i \times \bigcup_{i \in I} Y_i$. What is more, $x \in \bigcup_{i \in I} X_i \Leftrightarrow \exists i \in I: \ x \in X_i \Rightarrow \exists y \in Y_i: \ (x,y) \in f_i \Rightarrow \exists y \in \bigcup_{i \in I} Y_i: (x,y) \in \bigcup_{i \in I} f_i \Leftrightarrow x \in \mathrm{dom \ \bigcup_{i \in I} f_i}$. What is left to check is when $(x,y_1), (x,y_2) \in \bigcup_{i \in I} f_i \Rightarrow y_1 = y_2$. But $(x,y_1), (x,y_2) \in \bigcup_{i \in I} f_i$ means that there exists $i, j \in I$ so that $f_i(x) = y_1$ and $f_j(x) = y_2$. Is it right?",,"['functions', 'elementary-set-theory', 'relations']"
55,Graphical understanding of why the function $g(x)=x^3+x^2$ is not scale invariant unlike $f(x)=x^2$,Graphical understanding of why the function  is not scale invariant unlike,g(x)=x^3+x^2 f(x)=x^2,The function $f(x)=x^2$ is scale-invariant because $f(\lambda x)=\lambda^2f(x)$ but $g(x)=x^3+x^2$ is not because $g(\lambda x)\neq\lambda^{\Delta}g(x)$. How can we understand this feature by comparing the graphical plots of $f(x)$ and $g(x)$?,The function $f(x)=x^2$ is scale-invariant because $f(\lambda x)=\lambda^2f(x)$ but $g(x)=x^3+x^2$ is not because $g(\lambda x)\neq\lambda^{\Delta}g(x)$. How can we understand this feature by comparing the graphical plots of $f(x)$ and $g(x)$?,,"['functions', 'polynomials', 'graphing-functions']"
56,Show that $f(\sup(A))= \sup(f(A))$.,Show that .,f(\sup(A))= \sup(f(A)),"Let $f : \small \mathbb{R} ‚Üí  \mathbb{R}$ be a continuous nondecreasing function. Let $A$ be a nonempty, bounded set. (a)  Show that $f(\sup A) = \sup(f(A)).$ (b) If we drop the assumption that $f$ is continuous, what can you say? Attempt: $x\le \sup(A)\ \  \forall x \in A$ $\Rightarrow f(x)\le f(\sup(A))\ \  \forall x \in A$ $\Rightarrow \sup(f(A))\le f(\sup(A))\ \  $ also, $f(x)\le \sup(f(A))\ \  \forall x \in A$ $\Rightarrow x\le f^{-1}(\sup(f(A)))\ \  \forall x \in A$ $\Rightarrow \sup(A)\le f^{-1}(\sup(f(A)))\ \ $ $\Rightarrow f(\sup(A))\le \sup(f(A))\ \ $ Thus $f(\sup(A))= \sup(f(A))$ But in the Highlighted line I have used that $f$ is injective, but $f$ may not be injective as $f$ is given to be non decreasing. So how to correct that part.","Let be a continuous nondecreasing function. Let be a nonempty, bounded set. (a)  Show that (b) If we drop the assumption that is continuous, what can you say? Attempt: also, Thus But in the Highlighted line I have used that is injective, but may not be injective as is given to be non decreasing. So how to correct that part.",f : \small \mathbb{R} ‚Üí  \mathbb{R} A f(\sup A) = \sup(f(A)). f x\le \sup(A)\ \  \forall x \in A \Rightarrow f(x)\le f(\sup(A))\ \  \forall x \in A \Rightarrow \sup(f(A))\le f(\sup(A))\ \   f(x)\le \sup(f(A))\ \  \forall x \in A \Rightarrow x\le f^{-1}(\sup(f(A)))\ \  \forall x \in A \Rightarrow \sup(A)\le f^{-1}(\sup(f(A)))\ \  \Rightarrow f(\sup(A))\le \sup(f(A))\ \  f(\sup(A))= \sup(f(A)) f f f,"['real-analysis', 'functions', 'continuity', 'supremum-and-infimum']"
57,Does every power series have an inverse?,Does every power series have an inverse?,,"I'm not even sure if every polynomial has an inverse, and what restrictions are required on them to have inverses. For example, the people in this question seem to suggest that the polynomial needs to be increasing to have an inverse. My main question is, does every power series have an inverse?","I'm not even sure if every polynomial has an inverse, and what restrictions are required on them to have inverses. For example, the people in this question seem to suggest that the polynomial needs to be increasing to have an inverse. My main question is, does every power series have an inverse?",,"['functions', 'polynomials', 'power-series', 'inverse']"
58,Absolute convergence of series $f_n(x)+g_n(x)$ implies convergence of series $f_n(x)$ and $g_n(x)$?,Absolute convergence of series  implies convergence of series  and ?,f_n(x)+g_n(x) f_n(x) g_n(x),"Consider two function series $\sum_{n\geq 0} f_n(x)$ and $\sum_{n\geq 0} g_n(x)$. The following implication holds: $$\sum_{n\geq 0} f_n(x) \text{ converges absolutely and } \sum_{n\geq 0} g_n(x) \text{ converges absolutely} \\ \implies \sum_{n\geq 0} (f_n(x)+g_n(x)) \text{ converges absolutely}$$ But also the following proposition is true in general for another  function series $\sum_{n\geq 0} h_n(x)$ If $\sum_{n\geq 0} h_n(x)$ converges absolutely, then also every   subseries converges. So in particular if $h_n(x)=f_n(x)+g_n(x)$, can I say the following? $$\sum_{n\geq 0} (f_n(x)+g_n(x)) \text{ converges absolutely} \\ \implies\sum_{n\geq 0} f_n(x) \text{ converges and } \sum_{n\geq 0} g_n(x) \text{ converges}  $$ If this is true, then is the convergence of $\sum_{n\geq 0} f_n(x)$ and $\sum_{n\geq 0} g_n(x)$ conditional, in general or is it absolute?","Consider two function series $\sum_{n\geq 0} f_n(x)$ and $\sum_{n\geq 0} g_n(x)$. The following implication holds: $$\sum_{n\geq 0} f_n(x) \text{ converges absolutely and } \sum_{n\geq 0} g_n(x) \text{ converges absolutely} \\ \implies \sum_{n\geq 0} (f_n(x)+g_n(x)) \text{ converges absolutely}$$ But also the following proposition is true in general for another  function series $\sum_{n\geq 0} h_n(x)$ If $\sum_{n\geq 0} h_n(x)$ converges absolutely, then also every   subseries converges. So in particular if $h_n(x)=f_n(x)+g_n(x)$, can I say the following? $$\sum_{n\geq 0} (f_n(x)+g_n(x)) \text{ converges absolutely} \\ \implies\sum_{n\geq 0} f_n(x) \text{ converges and } \sum_{n\geq 0} g_n(x) \text{ converges}  $$ If this is true, then is the convergence of $\sum_{n\geq 0} f_n(x)$ and $\sum_{n\geq 0} g_n(x)$ conditional, in general or is it absolute?",,"['real-analysis', 'sequences-and-series', 'functions', 'power-series']"
59,Calculate $\int ^{\pi}_0\ln(1+\alpha \cos x) dx$,Calculate,\int ^{\pi}_0\ln(1+\alpha \cos x) dx,Calculate $$\int ^{\pi}_0\ln(1+\alpha \cos x) dx$$ for $|\alpha|<1$. I tried Let  $$f(\alpha)=\int ^{\pi}_0\ln(1+\alpha \cos x) dx$$  then $$\frac{df}{d\alpha}=\int^{\pi}_0\frac{\cos x}{1+\alpha \cos x}dx$$ But it seems need some other tricks... Then I tried  $$ \begin{align} \int^{\pi}_0\ln(1+\alpha\cos x) dx &=\int^{\pi}_0[\ln(1+\alpha\cos x)-\ln1]dx\\ &=\int^{\pi}_0[\ln(1+y\cos x)]^{y=\alpha}_{y=0}dx\\ & =\int^{\pi}_0[\int^{\alpha}_0\frac{\cos x}{1+y\cos x}dy]dx \end{align} $$ Any help? Thanks~,Calculate $$\int ^{\pi}_0\ln(1+\alpha \cos x) dx$$ for $|\alpha|<1$. I tried Let  $$f(\alpha)=\int ^{\pi}_0\ln(1+\alpha \cos x) dx$$  then $$\frac{df}{d\alpha}=\int^{\pi}_0\frac{\cos x}{1+\alpha \cos x}dx$$ But it seems need some other tricks... Then I tried  $$ \begin{align} \int^{\pi}_0\ln(1+\alpha\cos x) dx &=\int^{\pi}_0[\ln(1+\alpha\cos x)-\ln1]dx\\ &=\int^{\pi}_0[\ln(1+y\cos x)]^{y=\alpha}_{y=0}dx\\ & =\int^{\pi}_0[\int^{\alpha}_0\frac{\cos x}{1+y\cos x}dy]dx \end{align} $$ Any help? Thanks~,,"['calculus', 'functions']"
60,"Show $f\colon\{\,x+iy \mid x,y\in\mathbb{Q}\,\}\rightarrow\mathbb{Q}\times\mathbb{Q}$, $f(x+iy)=(x,y)$ is well defined","Show ,  is well defined","f\colon\{\,x+iy \mid x,y\in\mathbb{Q}\,\}\rightarrow\mathbb{Q}\times\mathbb{Q} f(x+iy)=(x,y)","My original assignment was to prove that the set $\{\,x+iy \mid x,y\in\mathbb{Q}\,\}$ is countable. Since I now that $\mathbb{Q}\times\mathbb{Q}$ is countable, I immediately thought of the injection $f\colon \{\,x+iy \mid x,y\in\mathbb{Q}\,\}\rightarrow\mathbb{Q}\times\mathbb{Q}$ with $f(x+iy)=(x,y)$. My teacher then asked me, whether or not this function is well defined. I'd say it's pretty obvious that $f$ is well defined, since unique $x+iy$, gives unique pairs of $x$ and $y$, but I'm not quiet sure on how I can show it more strictly?","My original assignment was to prove that the set $\{\,x+iy \mid x,y\in\mathbb{Q}\,\}$ is countable. Since I now that $\mathbb{Q}\times\mathbb{Q}$ is countable, I immediately thought of the injection $f\colon \{\,x+iy \mid x,y\in\mathbb{Q}\,\}\rightarrow\mathbb{Q}\times\mathbb{Q}$ with $f(x+iy)=(x,y)$. My teacher then asked me, whether or not this function is well defined. I'd say it's pretty obvious that $f$ is well defined, since unique $x+iy$, gives unique pairs of $x$ and $y$, but I'm not quiet sure on how I can show it more strictly?",,['functions']
61,Am I allowed to make these kinds of substitutions?,Am I allowed to make these kinds of substitutions?,,"I am trying to solve this: Let $$\dfrac{u(x+1)+u(x-1)}{2} = f(x) \tag 1$$ and $$\dfrac{u(x+4)+u(x-4)}{2} = g(x) \tag 2$$ Express $u$ in terms of $f$ and $g$ . My question is if the following steps are justified (I think they're not): Make the substitutions $x\to x+4$ and $x \to x+1$ in $(1)$ and $(2)$ respectively Let $$\dfrac{u(x+5)+u(x+3)}{2} = f(x+4) \tag 3$$ $$\dfrac{u(x+5)+u(x-3)}{2} = g(x+1) \tag 4$$ Subtract $(4)$ from $(3)$ : $$\dfrac{u(x+3)-u(x-3)}{2} = f(x+4)-g(x+1) \tag 5$$ I continue and get the solution doing a few more of these substitutions, but I am just not quite sure if the substitutions are valid. I don't think that I can just combine $3$ and $4$ , this is just abuse of notation, right? Because actually I am setting $x=a+4$ and $x=b+1$ , so I can't pretend like $a$ and $b$ are independent.","I am trying to solve this: Let and Express in terms of and . My question is if the following steps are justified (I think they're not): Make the substitutions and in and respectively Let Subtract from : I continue and get the solution doing a few more of these substitutions, but I am just not quite sure if the substitutions are valid. I don't think that I can just combine and , this is just abuse of notation, right? Because actually I am setting and , so I can't pretend like and are independent.",\dfrac{u(x+1)+u(x-1)}{2} = f(x) \tag 1 \dfrac{u(x+4)+u(x-4)}{2} = g(x) \tag 2 u f g x\to x+4 x \to x+1 (1) (2) \dfrac{u(x+5)+u(x+3)}{2} = f(x+4) \tag 3 \dfrac{u(x+5)+u(x-3)}{2} = g(x+1) \tag 4 (4) (3) \dfrac{u(x+3)-u(x-3)}{2} = f(x+4)-g(x+1) \tag 5 3 4 x=a+4 x=b+1 a b,"['functions', 'functional-equations']"
62,Tangents and roots to simultaneous equations.,Tangents and roots to simultaneous equations.,,"Straight line tangents I've been solving questions about linear tangents to curves and I noticed that when you create a simultaneous equation with a linear tangent you get a repeated root if it is tangent to a quadratic (and this is the only solution) and a repeated root (and one other root) when it is tangent to a cubic. { EDIT 1: Thinking about this a little more, I've realised that you can also have triple repeated roots where the line crosses the curve but has the same gradient as the curve where it crosses.} I was wondering if the number of repeated roots for a straight-line tangent to a curve is always two, and I thought about quartic curves and I think the roots you can get are: -2 equal roots that are real (tangent) and two complex roots -4 real roots: 2 are equal (tangent) and 2 different real rots (where the line crosses the curve) -2 pairs of equal roots (when the line is tangent to the curve at two points) Please correct me if I am wrong, but I think that with a straight-line tangent it always just has a double root at the point where it is tangent, and it may or may not have other roots... But I have also only thought about this using sketches of cubic and quartic curves. I was wondering if there was another way to see why this would be the case? Also, what would happen if you get a triple root? What does this mean? EDIT 2: Please scrap all of what I said above! I'm leaving it in just to show my thought process and general question, but after some more investigation with curves, my question has changed a bit... See below! So I now see that whenever there is a repeated root to an even power, the line is tangent to the curve. When there is a repeated root with an odd power, the line and curve meet and have the same gradient at this point, but they cross. So my questions now are: What is the significance of having a double root, as opposed to a quadruple root, when the line meets the curve (e.g. a curve defined by a quartic polynomial)? Does it have something to do with the second and third order derivatives too? What is the significance of complex roots to these equations? Specifically, what would be the difference between a tangent to a quartic where there is a single, real, repeated root to the power of four in the simultaneous equation as opposed to a single real root to the power of two, and a set of complex conjugate roots? My current idea of this is that with a single real root to the power of four, as you diverge away from the tangent point, the distance between the line and the curve keeps on growing, but each single complex conjugate root pair adds another dip of the curve towards line. If that is the case, then what is the significance of the real and imaginary components of the complex pair? I think the real component is the actual x value at which there is the closest PERPENDICULAR distance (I think! Please correct me on this one) between the line and the curve (i.e. the shortest distance following a normal to the tangent, as this is the actual closest distance) as opposed to the shortest vertical distance...) But then I am not sure what the significance of the imaginary part is. What difference does it make if, for instance, the conjugate pair is $-1/+-/2i$ as opposed to $-1/+-/7i$?? Tangents which are curves This I am not sure about at all. Does it follow the same principles that: Even power repeated root means tangent Odd power repeated root meant same gradient but crossing Extra real roots mean intersection Extra complex conjugate roots means shortening of distance between the two curves? Thinking about it now, when you solve the simultaneous equations and you set the two functions (i.e. y values) equal to each other, you literally create a distance function and you are trying to find where the distance is zero. Other than the fact that this means solutions to the equation show where the functions meet, whether tangent or intersection, i'm not sure what the significance of this is in my consideration. And it makes me a little more confused as to whether the shortest distance represented by a complex conjugate root pair is the vertical distance or the perpendicular distance. On the one hand, if it were the perpendicular distance, I am essentially imagining tilting the coordinate system so that the line (or lower power curve) is forming the x axis. The problem with it being the perpendicular distance though, is that this shortest distance follows a line which cuts the two curves (or line and curve) at different values of x. Which, then, is the solution that we find when solving the simultaneous equation? The vertical distance would solve this issue of the discrepancy of the x coordinate, and I suppose in that case the 'shortest actual distance' function would be more complicated... Unless, the 'base' line-i.e. x axis-- was formed by whichever function you subtract . E.g. if you have the curve f(x) and line g(x) and you form the distance function f(x)-g(x)=0, then maybe the distance line must be perpendicuular to the subtracted function, g(x), and not the first function, f(x), and the distance line must only be perpendicular to g(x) and the solution is the x value on f(x) that gives the shortest distance to any point on the line g(x)... I apologise for the length of this post and hope I have made myself sufficiently clear! Thank you in advance for any help.","Straight line tangents I've been solving questions about linear tangents to curves and I noticed that when you create a simultaneous equation with a linear tangent you get a repeated root if it is tangent to a quadratic (and this is the only solution) and a repeated root (and one other root) when it is tangent to a cubic. { EDIT 1: Thinking about this a little more, I've realised that you can also have triple repeated roots where the line crosses the curve but has the same gradient as the curve where it crosses.} I was wondering if the number of repeated roots for a straight-line tangent to a curve is always two, and I thought about quartic curves and I think the roots you can get are: -2 equal roots that are real (tangent) and two complex roots -4 real roots: 2 are equal (tangent) and 2 different real rots (where the line crosses the curve) -2 pairs of equal roots (when the line is tangent to the curve at two points) Please correct me if I am wrong, but I think that with a straight-line tangent it always just has a double root at the point where it is tangent, and it may or may not have other roots... But I have also only thought about this using sketches of cubic and quartic curves. I was wondering if there was another way to see why this would be the case? Also, what would happen if you get a triple root? What does this mean? EDIT 2: Please scrap all of what I said above! I'm leaving it in just to show my thought process and general question, but after some more investigation with curves, my question has changed a bit... See below! So I now see that whenever there is a repeated root to an even power, the line is tangent to the curve. When there is a repeated root with an odd power, the line and curve meet and have the same gradient at this point, but they cross. So my questions now are: What is the significance of having a double root, as opposed to a quadruple root, when the line meets the curve (e.g. a curve defined by a quartic polynomial)? Does it have something to do with the second and third order derivatives too? What is the significance of complex roots to these equations? Specifically, what would be the difference between a tangent to a quartic where there is a single, real, repeated root to the power of four in the simultaneous equation as opposed to a single real root to the power of two, and a set of complex conjugate roots? My current idea of this is that with a single real root to the power of four, as you diverge away from the tangent point, the distance between the line and the curve keeps on growing, but each single complex conjugate root pair adds another dip of the curve towards line. If that is the case, then what is the significance of the real and imaginary components of the complex pair? I think the real component is the actual x value at which there is the closest PERPENDICULAR distance (I think! Please correct me on this one) between the line and the curve (i.e. the shortest distance following a normal to the tangent, as this is the actual closest distance) as opposed to the shortest vertical distance...) But then I am not sure what the significance of the imaginary part is. What difference does it make if, for instance, the conjugate pair is $-1/+-/2i$ as opposed to $-1/+-/7i$?? Tangents which are curves This I am not sure about at all. Does it follow the same principles that: Even power repeated root means tangent Odd power repeated root meant same gradient but crossing Extra real roots mean intersection Extra complex conjugate roots means shortening of distance between the two curves? Thinking about it now, when you solve the simultaneous equations and you set the two functions (i.e. y values) equal to each other, you literally create a distance function and you are trying to find where the distance is zero. Other than the fact that this means solutions to the equation show where the functions meet, whether tangent or intersection, i'm not sure what the significance of this is in my consideration. And it makes me a little more confused as to whether the shortest distance represented by a complex conjugate root pair is the vertical distance or the perpendicular distance. On the one hand, if it were the perpendicular distance, I am essentially imagining tilting the coordinate system so that the line (or lower power curve) is forming the x axis. The problem with it being the perpendicular distance though, is that this shortest distance follows a line which cuts the two curves (or line and curve) at different values of x. Which, then, is the solution that we find when solving the simultaneous equation? The vertical distance would solve this issue of the discrepancy of the x coordinate, and I suppose in that case the 'shortest actual distance' function would be more complicated... Unless, the 'base' line-i.e. x axis-- was formed by whichever function you subtract . E.g. if you have the curve f(x) and line g(x) and you form the distance function f(x)-g(x)=0, then maybe the distance line must be perpendicuular to the subtracted function, g(x), and not the first function, f(x), and the distance line must only be perpendicular to g(x) and the solution is the x value on f(x) that gives the shortest distance to any point on the line g(x)... I apologise for the length of this post and hope I have made myself sufficiently clear! Thank you in advance for any help.",,"['functions', 'systems-of-equations', 'roots']"
63,Proving that a set is countable,Proving that a set is countable,,"My attempt is as follows: We will start by considering each ‚Äòwalk‚Äô as some set of steps.  So a walk of length $m$ can be represented by the set $S_m =$ {$x_1, x_2, x_3, ‚Ä¶ , x_m$}.  To each of these steps we assign at random a value of $0$ or $1$. The number of possible walks of a certain length, say $n$, is the same as the number of functions from $S_n$ to {$0, 1$}, which is $2^n$.  Now, the question tells us that the number of steps in a certain walk can get ‚Äòvery large‚Äô so, assuming we begin the walk at the entrance to the pub, it would be silly to have walks consisting only of a ‚Äòvery large‚Äô number of backward steps. It may, therefore, be better to write the number of possible walks of length $n$ as being $\leqslant 2^n$ The set of all possible random walks is then the disjoint union  $S = \bigcup_{r = 1}^{L} S_r$, where $L$ is possibly a very large number, the cardinality of which is $\leqslant 2^1 + 2^2 + 2^3 + ... +2^L$ So the cardinality is bounded above by a finite quantity, so there is a bijection $f : \mathbb{N}_{i} \mapsto S$ for some $1 \leqslant i \leqslant 2^1 + 2^2 + 2^3 + ... +2^L$ hence the set is countable. The context is a little peculiar, so I'm not entirely convinced that my interpretation of the question is correct, so if anyone could give me some feedback on this that'd be great.","My attempt is as follows: We will start by considering each ‚Äòwalk‚Äô as some set of steps.  So a walk of length $m$ can be represented by the set $S_m =$ {$x_1, x_2, x_3, ‚Ä¶ , x_m$}.  To each of these steps we assign at random a value of $0$ or $1$. The number of possible walks of a certain length, say $n$, is the same as the number of functions from $S_n$ to {$0, 1$}, which is $2^n$.  Now, the question tells us that the number of steps in a certain walk can get ‚Äòvery large‚Äô so, assuming we begin the walk at the entrance to the pub, it would be silly to have walks consisting only of a ‚Äòvery large‚Äô number of backward steps. It may, therefore, be better to write the number of possible walks of length $n$ as being $\leqslant 2^n$ The set of all possible random walks is then the disjoint union  $S = \bigcup_{r = 1}^{L} S_r$, where $L$ is possibly a very large number, the cardinality of which is $\leqslant 2^1 + 2^2 + 2^3 + ... +2^L$ So the cardinality is bounded above by a finite quantity, so there is a bijection $f : \mathbb{N}_{i} \mapsto S$ for some $1 \leqslant i \leqslant 2^1 + 2^2 + 2^3 + ... +2^L$ hence the set is countable. The context is a little peculiar, so I'm not entirely convinced that my interpretation of the question is correct, so if anyone could give me some feedback on this that'd be great.",,"['functions', 'proof-verification']"
64,What is $\csc^{-1}(\csc 0)$?,What is ?,\csc^{-1}(\csc 0),"We have been taught that $\csc^{-1}(\csc 0)$ is undefined, as $\csc 0$ is not defined. But when I graphed it on desmos, $\csc^{-1}(\csc x)$ was defined on $x = 0$ and was equal to $0$. Same is the case for $\sec^{-1}(\sec x)$ at $x = \frac{\pi}{2}$. Can someone explain this discrepancy? Thank you.","We have been taught that $\csc^{-1}(\csc 0)$ is undefined, as $\csc 0$ is not defined. But when I graphed it on desmos, $\csc^{-1}(\csc x)$ was defined on $x = 0$ and was equal to $0$. Same is the case for $\sec^{-1}(\sec x)$ at $x = \frac{\pi}{2}$. Can someone explain this discrepancy? Thank you.",,"['functions', 'trigonometry', 'inverse-function']"
65,Finding the function of a sine graph that has both translation and transformation,Finding the function of a sine graph that has both translation and transformation,,"I can't quite find a problem similar enough to this yet, and I need some serious help. Here is a photo of the graph of the function I am trying to find out: Sorry, but I don't have enough reputation to post a physical copy of the photo yet. I've figured out most of the problem. The basic formula for a sine graph is $\sin(2\pi/P(x‚àíb))$. So far from the picture, I've figured out that the amplitude is $4$ and the frequency (is that right?) is $2\pi/5$ and that $x$ will most definitely be negative. My problem is in finding b, which for the life of me I can't figure out. So far I've hit $4\sin(2\pi/5(-x-1.5))$, but that doesn't seem to be correct. Can you guys explain what I'm doing wrong, so that I can learn how to do this correctly? Thank You","I can't quite find a problem similar enough to this yet, and I need some serious help. Here is a photo of the graph of the function I am trying to find out: Sorry, but I don't have enough reputation to post a physical copy of the photo yet. I've figured out most of the problem. The basic formula for a sine graph is $\sin(2\pi/P(x‚àíb))$. So far from the picture, I've figured out that the amplitude is $4$ and the frequency (is that right?) is $2\pi/5$ and that $x$ will most definitely be negative. My problem is in finding b, which for the life of me I can't figure out. So far I've hit $4\sin(2\pi/5(-x-1.5))$, but that doesn't seem to be correct. Can you guys explain what I'm doing wrong, so that I can learn how to do this correctly? Thank You",,"['functions', 'trigonometry', 'transformation']"
66,How do I find the domain/range of functions algebraically?,How do I find the domain/range of functions algebraically?,,"I've been having trouble when trying to find the domain/range of functions algebraically. Here is an example: $P(x)=\frac{1}{3+\sqrt{x+1}}$ Finding the domain: $x+1\ge0$ $x\ge-1$ Therefore, $x \in [-1,+\infty)$ Finding the range: Let $y=P(x)=\frac{1}{3+\sqrt{x+1}}$ From isolating x we find: $x=(\frac{1}{y} -3)^2-1$ Therefore: $(\frac{1}{y} -3)^2-1\ge-1$ $(\frac{1}{y} -3)^2\ge0$ $\frac{1}{y} -3\ge0$ or $\frac{1}{y} -3\le0$ $y\le \frac{1}{3}$ or $y\ge \frac{1}{3}$ This doesn't make any sense! Intuitively I can see that when $x=-1$ then $f(x)=\frac{1}{3}$ and as x approaches $+\infty$ then $f(x)$ approaches zero (without ever reaching it). How do I find this solution algebraically? What are the ""rules"" for working with inequalities w/ exponents and radicals (both positive and negative)? How do I find the range for other functions such as $g(x)=3+\sqrt{16-(x-3)^2}$ and $h(x)=\frac{12x-9}{6-9x}$ algebraically? A thorough explanation would be appreciated (also, feel free to point out errors in my work- there are obviously many).","I've been having trouble when trying to find the domain/range of functions algebraically. Here is an example: $P(x)=\frac{1}{3+\sqrt{x+1}}$ Finding the domain: $x+1\ge0$ $x\ge-1$ Therefore, $x \in [-1,+\infty)$ Finding the range: Let $y=P(x)=\frac{1}{3+\sqrt{x+1}}$ From isolating x we find: $x=(\frac{1}{y} -3)^2-1$ Therefore: $(\frac{1}{y} -3)^2-1\ge-1$ $(\frac{1}{y} -3)^2\ge0$ $\frac{1}{y} -3\ge0$ or $\frac{1}{y} -3\le0$ $y\le \frac{1}{3}$ or $y\ge \frac{1}{3}$ This doesn't make any sense! Intuitively I can see that when $x=-1$ then $f(x)=\frac{1}{3}$ and as x approaches $+\infty$ then $f(x)$ approaches zero (without ever reaching it). How do I find this solution algebraically? What are the ""rules"" for working with inequalities w/ exponents and radicals (both positive and negative)? How do I find the range for other functions such as $g(x)=3+\sqrt{16-(x-3)^2}$ and $h(x)=\frac{12x-9}{6-9x}$ algebraically? A thorough explanation would be appreciated (also, feel free to point out errors in my work- there are obviously many).",,"['functions', 'inequality']"
67,removable discontinuity,removable discontinuity,,"I am having some confusions about the removable discontinuities. most of the functions with removable discontinuity I have faced are piece wise functions.example: $f(x)=\begin{cases}x+2,x\neq 1 \\4,x=1\end{cases}$ my first question:how can the discontinuity of a piecewise function be removed?? 2nd question:functions with removable discontinuities usually violate the 3rd condition of continuity,which is understandable for piecewise functions.but the function $f(x)=\frac{(x-1)(x-2)}{(x-1)}$  also has a removable  discontinuity at $x=1$.but this function violates the very first condition of continuity ($f(a)$ is not defined).should it still be called a removable discontinuity??","I am having some confusions about the removable discontinuities. most of the functions with removable discontinuity I have faced are piece wise functions.example: $f(x)=\begin{cases}x+2,x\neq 1 \\4,x=1\end{cases}$ my first question:how can the discontinuity of a piecewise function be removed?? 2nd question:functions with removable discontinuities usually violate the 3rd condition of continuity,which is understandable for piecewise functions.but the function $f(x)=\frac{(x-1)(x-2)}{(x-1)}$  also has a removable  discontinuity at $x=1$.but this function violates the very first condition of continuity ($f(a)$ is not defined).should it still be called a removable discontinuity??",,"['functions', 'continuity']"
68,Why is that any function from $X$ to the trivial topological space is continuous?,Why is that any function from  to the trivial topological space is continuous?,X,"I think this is a super silly question, but I just can't figure out why is that given any function $f: X \to Y$, where $(X, \mathcal{T})$ is an arbitrary topological space, and $(Y, \mathcal{T}_{trivial})$ where $ \mathcal{T}_{trivial} = \{\varnothing, Y\}$ Okay, so $f^{-1}(\varnothing) = \varnothing \in \mathcal{T}$, but how do we know that $f^{-1}(Y) \in \mathcal{T}?$ Since the preimage of the codomain is not necessarily the domain When is the preimage of codomain not equal to domain? Why couldn't there be a case where $f^{-1}(Y) = U \subset X$, but $U \notin \mathcal{T}?$ Edit: So is it always the case that $f^{-1}(Y) = X$, given $f: X \to Y$?","I think this is a super silly question, but I just can't figure out why is that given any function $f: X \to Y$, where $(X, \mathcal{T})$ is an arbitrary topological space, and $(Y, \mathcal{T}_{trivial})$ where $ \mathcal{T}_{trivial} = \{\varnothing, Y\}$ Okay, so $f^{-1}(\varnothing) = \varnothing \in \mathcal{T}$, but how do we know that $f^{-1}(Y) \in \mathcal{T}?$ Since the preimage of the codomain is not necessarily the domain When is the preimage of codomain not equal to domain? Why couldn't there be a case where $f^{-1}(Y) = U \subset X$, but $U \notin \mathcal{T}?$ Edit: So is it always the case that $f^{-1}(Y) = X$, given $f: X \to Y$?",,"['general-topology', 'functions']"
69,"Given bijection between $\mathbb{N}$ and $A$ and $B$, find bijection from $\mathbb{N}$ to $A \cup B$","Given bijection between  and  and , find bijection from  to",\mathbb{N} A B \mathbb{N} A \cup B,"Let $A$ and $B$ be two countable sets and consider that $f$ is a bijection from $\mathbb{N}$ to $A$ and $g$ is a bijection from $\mathbb{N}$ to $B$. I have to find a bijection from $\mathbb{N}$ to $A \cup B$ involving both $f$ and $g$. I thought of split  $\mathbb{N}$ in even and odd numbers using $f(\frac{n}{2})$ if $n$ is even and $g(\frac{n-1}{2})$ if $n$ is odd, but it doesn't work because I can just prove the onto property, I can't guarantee it will be one-to-one because $A \cap B$ may be non empty (for instance, it might happen that $f(2)$ would be equal $g(5)$...) In general, all the strategies I've tried to construct such bijection have failed because $A \cap B$ may be non empty. How can I work around this?","Let $A$ and $B$ be two countable sets and consider that $f$ is a bijection from $\mathbb{N}$ to $A$ and $g$ is a bijection from $\mathbb{N}$ to $B$. I have to find a bijection from $\mathbb{N}$ to $A \cup B$ involving both $f$ and $g$. I thought of split  $\mathbb{N}$ in even and odd numbers using $f(\frac{n}{2})$ if $n$ is even and $g(\frac{n-1}{2})$ if $n$ is odd, but it doesn't work because I can just prove the onto property, I can't guarantee it will be one-to-one because $A \cap B$ may be non empty (for instance, it might happen that $f(2)$ would be equal $g(5)$...) In general, all the strategies I've tried to construct such bijection have failed because $A \cap B$ may be non empty. How can I work around this?",,"['functions', 'elementary-set-theory']"
70,"If $x \geq C$, where $C > 0$ is a constant, then what is the least upper bound for $\dfrac{2x}{x + 1}$?","If , where  is a constant, then what is the least upper bound for ?",x \geq C C > 0 \dfrac{2x}{x + 1},"The title says it all. Since $$f(x) = \dfrac{2x}{x + 1} = 2\left(1 - \dfrac{1}{x + 1}\right),$$ then because $x \geq C$ where $C > 0$, an upper bound is given by $$\dfrac{2x}{x + 1} < 2.$$ Note that the lower bound is equivalent to $$x \geq C \iff x + 1 \geq C + 1 \iff \dfrac{1}{x + 1} \leq \dfrac{1}{C + 1}$$ $$\iff 2\left(1 - \dfrac{1}{x + 1}\right) \geq 2\left(1 - \dfrac{1}{C + 1}\right),$$ so that if $2 - \varepsilon$ is an upper bound for $f(x)$ ($\varepsilon > 0$), then $\varepsilon$ satisfies the inequality $$2 - \varepsilon \geq f(x) \geq 2\left(1 - \dfrac{1}{C + 1}\right) \implies 0 < \varepsilon < \dfrac{2}{C + 1}.$$ My question is essentially whether we can do better than this.","The title says it all. Since $$f(x) = \dfrac{2x}{x + 1} = 2\left(1 - \dfrac{1}{x + 1}\right),$$ then because $x \geq C$ where $C > 0$, an upper bound is given by $$\dfrac{2x}{x + 1} < 2.$$ Note that the lower bound is equivalent to $$x \geq C \iff x + 1 \geq C + 1 \iff \dfrac{1}{x + 1} \leq \dfrac{1}{C + 1}$$ $$\iff 2\left(1 - \dfrac{1}{x + 1}\right) \geq 2\left(1 - \dfrac{1}{C + 1}\right),$$ so that if $2 - \varepsilon$ is an upper bound for $f(x)$ ($\varepsilon > 0$), then $\varepsilon$ satisfies the inequality $$2 - \varepsilon \geq f(x) \geq 2\left(1 - \dfrac{1}{C + 1}\right) \implies 0 < \varepsilon < \dfrac{2}{C + 1}.$$ My question is essentially whether we can do better than this.",,"['functions', 'inequality']"
71,Combination of even and odd functions,Combination of even and odd functions,,"Can someone help me how to show that any function $f(x)$ defined on a symmetrically placed interval can be written as a sum of an even and a odd function? What is the special role played by ""symmetrically placed interval"" here?","Can someone help me how to show that any function $f(x)$ defined on a symmetrically placed interval can be written as a sum of an even and a odd function? What is the special role played by ""symmetrically placed interval"" here?",,"['functions', 'fourier-series', 'symmetry']"
72,"Let $f(x)=x^5$. For $x_1>0$, let $p_1=(x_1,f(x_1))$.Draw a tangent at the point $p_1$","Let . For , let .Draw a tangent at the point","f(x)=x^5 x_1>0 p_1=(x_1,f(x_1)) p_1","Let $f(x)=x^5$. For $x_1>0$, let $p_1=(x_1,f(x_1))$. Draw a tangent at the point $p_1$ and let it meet the graph again at point $p_2$. Then draw a tangent at $p_2$ and so on . Show that , the ratio  $\frac{A(\bigtriangleup p_np_{n+1}p_{n+2})}{A( \bigtriangleup p_{n+1}p_{n+2}p_{n+3} )}$ is constant. I don't think just taking the ratio of two triangles will help, something more need to be used.","Let $f(x)=x^5$. For $x_1>0$, let $p_1=(x_1,f(x_1))$. Draw a tangent at the point $p_1$ and let it meet the graph again at point $p_2$. Then draw a tangent at $p_2$ and so on . Show that , the ratio  $\frac{A(\bigtriangleup p_np_{n+1}p_{n+2})}{A( \bigtriangleup p_{n+1}p_{n+2}p_{n+3} )}$ is constant. I don't think just taking the ratio of two triangles will help, something more need to be used.",,['functions']
73,Showing convergence with complex numbers,Showing convergence with complex numbers,,"I would like to show that if $|a-b|<\delta$ then $|e^{a}-e^b|<\epsilon$. Where $a$ is complex and $b$ is real. In essence if the difference between a and b is small then the difference between e^a and e^b is small I was hoping to use The Mean value theorem and say the following: Take $f(y)=e^y$ then $|f(a)-f(b)|=|a-b||f'(u)|$ and so as $|a-b|<\delta$ then $|f(a)-f(b)|<\epsilon$ unfortunately the mean value theorem follows a different structur when dealing with complex values (according to https://en.wikipedia.org/wiki/Mean_value_theorem ) I have a feeling that my statement is not necessarily true because if i write the $|e^a-e^b|$ as a sum I get $$ \left|\sum_{n=0}^{\infty} \frac{(a^n-b^n)}{n!}\right| \leq \sum_{n=0}^{\infty} \frac{(|a^n-b^n|)}{n!} $$ and just because $|a-b|<\epsilon$ we don't necessarily  have $|a^n-b^n|<\epsilon$ as $n$ goes to $\infty$ Any help would be much appreciated edit: in original i wrote ""I would like to show that if $|a-b|<\epsilon$ then $|e^{a}-e^b|<\epsilon$. Where $a$ is complex and $b$ is real.""","I would like to show that if $|a-b|<\delta$ then $|e^{a}-e^b|<\epsilon$. Where $a$ is complex and $b$ is real. In essence if the difference between a and b is small then the difference between e^a and e^b is small I was hoping to use The Mean value theorem and say the following: Take $f(y)=e^y$ then $|f(a)-f(b)|=|a-b||f'(u)|$ and so as $|a-b|<\delta$ then $|f(a)-f(b)|<\epsilon$ unfortunately the mean value theorem follows a different structur when dealing with complex values (according to https://en.wikipedia.org/wiki/Mean_value_theorem ) I have a feeling that my statement is not necessarily true because if i write the $|e^a-e^b|$ as a sum I get $$ \left|\sum_{n=0}^{\infty} \frac{(a^n-b^n)}{n!}\right| \leq \sum_{n=0}^{\infty} \frac{(|a^n-b^n|)}{n!} $$ and just because $|a-b|<\epsilon$ we don't necessarily  have $|a^n-b^n|<\epsilon$ as $n$ goes to $\infty$ Any help would be much appreciated edit: in original i wrote ""I would like to show that if $|a-b|<\epsilon$ then $|e^{a}-e^b|<\epsilon$. Where $a$ is complex and $b$ is real.""",,"['functions', 'convergence-divergence', 'complex-numbers']"
74,"If $f$ is a polynomial and $g(n+1)-g(n)=f(n)$, then $g$ is a polynomial. [closed]","If  is a polynomial and , then  is a polynomial. [closed]",f g(n+1)-g(n)=f(n) g,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Assume that $f$ is a polynomial of degree $s$ which is not constant, and that for sufficiently large positive integers $n$, $g(n+1)-g(n)=f(n)$. Here $g$ is defined on the positive integers.  Must $g$ be a polynomial of degree $s+1$? This is an ambiguous statement in Atiyah and MacDonald, page 119.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 8 years ago . Improve this question Assume that $f$ is a polynomial of degree $s$ which is not constant, and that for sufficiently large positive integers $n$, $g(n+1)-g(n)=f(n)$. Here $g$ is defined on the positive integers.  Must $g$ be a polynomial of degree $s+1$? This is an ambiguous statement in Atiyah and MacDonald, page 119.",,"['functions', 'polynomials', 'commutative-algebra']"
75,What is the mathematical term for an operation that is self reversing? [duplicate],What is the mathematical term for an operation that is self reversing? [duplicate],,This question already has answers here : What's the name for the property of a function $f$ that means $f(f(x))=x$? (2 answers) Closed 8 years ago . What is the mathematical term for an operation that is self reversing? For example: Multiplying by -1 1/x In general: f(f(x)) = x,This question already has answers here : What's the name for the property of a function $f$ that means $f(f(x))=x$? (2 answers) Closed 8 years ago . What is the mathematical term for an operation that is self reversing? For example: Multiplying by -1 1/x In general: f(f(x)) = x,,"['functions', 'terminology', 'inverse']"
76,If $B\subset A$ and $f:A\to B$ is injective prove it's a bijection between $A$ and $B$,If  and  is injective prove it's a bijection between  and,B\subset A f:A\to B A B,"I want to show that if $B\subset A$ and $f:A\to B$ is an injective function then there's a bijection between $A$ and $B$. I believe my ""proof"" is wrong, I probably use too much ""intuition"" when I try to solve it. But hopefully I will get a better feeling if someone tells me where/what I do wrong and help me. :) That said, a friend to me ""solved"" another problem ""if $f:A\to C$ is an injective function, and $g:C\to A$ is an injective function, then there is a bijection between $A$ and $C$"". She argued like this "" for all $a$ in $A$ we can find an element $f(a)$ in $C$ and for all $c$ in $C$ we have an element $g(c)$ in $A$. If f(a)=c then we must have g(c)=a. This holds for all $a$ and $c$. So each $a$ maps to exactly one $c$ and each $c$ maps to exactly one $a$"". That is the Schr√∂der‚ÄìBernstein theorem though, I have seen the proof, so I could directly tell that it's a wrong proof. I would probably not argue in the exactly same way but probably in a similar fashion. On the other hand I cannot really tell why this doesn't prove the fact either. Oh well, here comes my proof, it's a similar argument so I guess I'm wrong :) Proof: Since I already know it's injective, I just have to show it's surjective. We have that $B\subset A$, that is, every element of $B$ is in $A$. Because of this we can for every element $b\in B$ find an element $a\in A$ such that $b=f(a)$. That is, $\forall b\in B\exists a\in A:\textbf{ }b=f(a)$. But that is the definition of surjection. Hence, there exists a bijection between $A$ and $B$ since f is injective. I bet I've forgot to mention something now, which I found important to mention, but unfortunately I have forgotten it. Hopefully I will remind myself. Thanks for your help :)","I want to show that if $B\subset A$ and $f:A\to B$ is an injective function then there's a bijection between $A$ and $B$. I believe my ""proof"" is wrong, I probably use too much ""intuition"" when I try to solve it. But hopefully I will get a better feeling if someone tells me where/what I do wrong and help me. :) That said, a friend to me ""solved"" another problem ""if $f:A\to C$ is an injective function, and $g:C\to A$ is an injective function, then there is a bijection between $A$ and $C$"". She argued like this "" for all $a$ in $A$ we can find an element $f(a)$ in $C$ and for all $c$ in $C$ we have an element $g(c)$ in $A$. If f(a)=c then we must have g(c)=a. This holds for all $a$ and $c$. So each $a$ maps to exactly one $c$ and each $c$ maps to exactly one $a$"". That is the Schr√∂der‚ÄìBernstein theorem though, I have seen the proof, so I could directly tell that it's a wrong proof. I would probably not argue in the exactly same way but probably in a similar fashion. On the other hand I cannot really tell why this doesn't prove the fact either. Oh well, here comes my proof, it's a similar argument so I guess I'm wrong :) Proof: Since I already know it's injective, I just have to show it's surjective. We have that $B\subset A$, that is, every element of $B$ is in $A$. Because of this we can for every element $b\in B$ find an element $a\in A$ such that $b=f(a)$. That is, $\forall b\in B\exists a\in A:\textbf{ }b=f(a)$. But that is the definition of surjection. Hence, there exists a bijection between $A$ and $B$ since f is injective. I bet I've forgot to mention something now, which I found important to mention, but unfortunately I have forgotten it. Hopefully I will remind myself. Thanks for your help :)",,['real-analysis']
77,Taylor expansion of $\cos{x}$,Taylor expansion of,\cos{x},I found a pdf file on the internet which gives you  known expansions of Taylor's. There is something I cant understand : Why is the remainder of $\cos x$ is written like this? $$\frac{\cos ^{(2n+2)}(c)x^{2n+2}}{(2n+2)!}$$ And not like this: $$\frac{\cos^{(2n+1)} (c)x^{2n+1}}{(2n+1)!}$$ when the last element was : $$\frac{(-1)^nx^{2n}} {(2n)!} $$,I found a pdf file on the internet which gives you  known expansions of Taylor's. There is something I cant understand : Why is the remainder of $\cos x$ is written like this? $$\frac{\cos ^{(2n+2)}(c)x^{2n+2}}{(2n+2)!}$$ And not like this: $$\frac{\cos^{(2n+1)} (c)x^{2n+1}}{(2n+1)!}$$ when the last element was : $$\frac{(-1)^nx^{2n}} {(2n)!} $$,,['functions']
78,Set of Discontinuities for a function $f$,Set of Discontinuities for a function,f,"Take $f$ to be a function over the reals. I want to show that a set of discontinuities of the first kind for $f$ are countable. This is the discontinuity type at point $P \in \mathbb{R}$ where $lim_{x \rightarrow P^{-}} f(x)$ and $\lim_{x \rightarrow P^{+}} f(x)$ both exist but either do not equal each other or do not equal $f(P).$ The suggestion given to me is that if there is a discontinuity but the right and left limits exist, I can slip a rational number between them. Hence, I am considering showing this countability by developing a bijection between the set of discontinuities and the rationals, although I am having difficulty formalizing this in the language of functions. Any assistance will be appreciated.","Take $f$ to be a function over the reals. I want to show that a set of discontinuities of the first kind for $f$ are countable. This is the discontinuity type at point $P \in \mathbb{R}$ where $lim_{x \rightarrow P^{-}} f(x)$ and $\lim_{x \rightarrow P^{+}} f(x)$ both exist but either do not equal each other or do not equal $f(P).$ The suggestion given to me is that if there is a discontinuity but the right and left limits exist, I can slip a rational number between them. Hence, I am considering showing this countability by developing a bijection between the set of discontinuities and the rationals, although I am having difficulty formalizing this in the language of functions. Any assistance will be appreciated.",,['functions']
79,What does this mean? (parabola),What does this mean? (parabola),,"The question is: If ($x,y$) represents a point on the graph of $y = 2x + 1$, which of the following could be a portion of the graph of the set of points ($x,y^2$)? The graphs are hard to put on and it is the general shape, not the specific graph that I am confused about. To me I thought the question meant substituting ($x,y^2$) into $y = 2x + 1$. So in the end this gives you a root function. But the answer said that the set of points ($x,y^2$) makes the equation $y = (2x+1)^2$. Could someone tell me where I went wrong or is this just ambiguous? Thanks!","The question is: If ($x,y$) represents a point on the graph of $y = 2x + 1$, which of the following could be a portion of the graph of the set of points ($x,y^2$)? The graphs are hard to put on and it is the general shape, not the specific graph that I am confused about. To me I thought the question meant substituting ($x,y^2$) into $y = 2x + 1$. So in the end this gives you a root function. But the answer said that the set of points ($x,y^2$) makes the equation $y = (2x+1)^2$. Could someone tell me where I went wrong or is this just ambiguous? Thanks!",,"['calculus', 'functions', 'graphing-functions']"
80,Is an injective map of $B$-modules also injective as an $A$-linear map if $B$ is an $A$-algebra?,Is an injective map of -modules also injective as an -linear map if  is an -algebra?,B A B A,"I've been going through my submitted exercises again of my Commutative Algebra -class and I have the following question: Let $A$ be a commutative ring with unity. Given any injective homomorphism of $B$-modules $M \rightarrow M'$, where $B$ is any $A$-algebra, is it necessarily true that $M \rightarrow M'$ is injective when considered as an $A$-linear map? In the solution I handed in, I used the rather weak argument that ""injectivity is a set-theoretic property, so stays preserved"" - which wasn't marked false by the assistant. However, the reasoning doesn't quite convince me. Is it true that injectivity stays preserved? If not, is there any counterexample? Thanks a lot!","I've been going through my submitted exercises again of my Commutative Algebra -class and I have the following question: Let $A$ be a commutative ring with unity. Given any injective homomorphism of $B$-modules $M \rightarrow M'$, where $B$ is any $A$-algebra, is it necessarily true that $M \rightarrow M'$ is injective when considered as an $A$-linear map? In the solution I handed in, I used the rather weak argument that ""injectivity is a set-theoretic property, so stays preserved"" - which wasn't marked false by the assistant. However, the reasoning doesn't quite convince me. Is it true that injectivity stays preserved? If not, is there any counterexample? Thanks a lot!",,"['abstract-algebra', 'functions', 'ring-theory', 'modules']"
81,Domain of convergence of $f_n(x)= { {nx^{n-1}} \over {1+x^{2n}} }$,Domain of convergence of,f_n(x)= { {nx^{n-1}} \over {1+x^{2n}} },"What is the domain of convergence of the real functions sequence: $$f_n(x)=  { {nx^{n-1}} \over {1+x^{2n}} }$$ I thought about looking at the numerator and denominator and take the intersection of their convergence domain, so I got $\{x<-1 \ or \ -1<x<1 \ or \ x>1\}$. But how do I justify such thing? Or prove it in better way?","What is the domain of convergence of the real functions sequence: $$f_n(x)=  { {nx^{n-1}} \over {1+x^{2n}} }$$ I thought about looking at the numerator and denominator and take the intersection of their convergence domain, so I got $\{x<-1 \ or \ -1<x<1 \ or \ x>1\}$. But how do I justify such thing? Or prove it in better way?",,"['sequences-and-series', 'functions', 'convergence-divergence']"
82,"Prove that if a function is surjective and strictly increasing, then it is continuous","Prove that if a function is surjective and strictly increasing, then it is continuous",,"Let $f: [a,b]\rightarrow [c,d]$ be a surjective and strictly increasing function. Show that $f$ is continuous. I have already proved that any function $f$ in $\mathbb{R}$ is continuous if and only if the preimage of a closed set is again a closed set. Thus it is enough to prove that if $x\le d$ then $f^{-1}([c,y])$ is closed or that $f^{-1}([c,y])=[a,f^{-1}(\{y\})]$ (using the fact that $f$ is surjective and strictly increasing - thus injective so that $f^{-1}(\{y\})$ is exactly one element from $[a,b]$). Choose $y\in (c,d]$. Assume that there is $p \in [a,f^{-1}(\{y\})]$ and $f(p)>y$. Since $f$ is strictly increasing we have $p>f^{-1}(\{y\})$. Contradiction. Could someone ""verify"" this proof? I don't think this is correct. Thanks.","Let $f: [a,b]\rightarrow [c,d]$ be a surjective and strictly increasing function. Show that $f$ is continuous. I have already proved that any function $f$ in $\mathbb{R}$ is continuous if and only if the preimage of a closed set is again a closed set. Thus it is enough to prove that if $x\le d$ then $f^{-1}([c,y])$ is closed or that $f^{-1}([c,y])=[a,f^{-1}(\{y\})]$ (using the fact that $f$ is surjective and strictly increasing - thus injective so that $f^{-1}(\{y\})$ is exactly one element from $[a,b]$). Choose $y\in (c,d]$. Assume that there is $p \in [a,f^{-1}(\{y\})]$ and $f(p)>y$. Since $f$ is strictly increasing we have $p>f^{-1}(\{y\})$. Contradiction. Could someone ""verify"" this proof? I don't think this is correct. Thanks.",,"['real-analysis', 'functions', 'proof-verification', 'continuity']"
83,Differentiating the inverse of a function with respect to a parameter,Differentiating the inverse of a function with respect to a parameter,,"The derivative of a function's inverse is well understood, and it is explained in full detail here . Say I have a function $\varphi_\varepsilon:\mathbb{R}\to\mathbb{R}$, where $\varepsilon$ is a parameter.  I also know that the function is smooth, invertible, and has smooth inverse.  This leads us to the question: do we have a representation for $\frac{\partial}{\partial\varepsilon}\varphi_\varepsilon^{-1}$ that is similar to the single variable case? Here is a post that already addresses this question, but it is quite old and doesn't have any significant responses.  I'm also more interested in the theoretical case than a concrete example.","The derivative of a function's inverse is well understood, and it is explained in full detail here . Say I have a function $\varphi_\varepsilon:\mathbb{R}\to\mathbb{R}$, where $\varepsilon$ is a parameter.  I also know that the function is smooth, invertible, and has smooth inverse.  This leads us to the question: do we have a representation for $\frac{\partial}{\partial\varepsilon}\varphi_\varepsilon^{-1}$ that is similar to the single variable case? Here is a post that already addresses this question, but it is quite old and doesn't have any significant responses.  I'm also more interested in the theoretical case than a concrete example.",,"['calculus', 'functions']"
84,Cauchy's functional equation for involutions: $ f ( x + y ) = f ( x ) + f ( y ) $ and $ f \big( f ( x ) \big) = x $,Cauchy's functional equation for involutions:  and, f ( x + y ) = f ( x ) + f ( y )   f \big( f ( x ) \big) = x ,"It is well known that Cauchy's functional equation for $ f : \mathbb R \to \mathbb R $ , $$ f ( x + y ) = f ( x ) + f ( y ) \quad \forall x , y \in \mathbb R \text , $$ admits highly pathological solutions if no further conditions are given. Is the condition $$ f \big( f ( x ) \big) = x \quad \forall x \in \mathbb R \text , $$ i.e. $ f $ being an involution, enough to ensure that no ""ugly"" function is a solution?","It is well known that Cauchy's functional equation for , admits highly pathological solutions if no further conditions are given. Is the condition i.e. being an involution, enough to ensure that no ""ugly"" function is a solution?"," f : \mathbb R \to \mathbb R  
f ( x + y ) = f ( x ) + f ( y ) \quad \forall x , y \in \mathbb R \text ,
 
f \big( f ( x ) \big) = x \quad \forall x \in \mathbb R \text ,
  f ","['functions', 'functional-equations']"
85,Prove $f^{-1}(U_1 \times \cdots \times U_n) = \bigcap_{i \in I} (f_i)^{-1}(U_i)$,Prove,f^{-1}(U_1 \times \cdots \times U_n) = \bigcap_{i \in I} (f_i)^{-1}(U_i),"I was looking through some problems in one of my books which does not have solutions in the back, and I found a problem stating to construct a proof for the following problem. If someone would not mind verifying whether or not the argument is valid, I would appreciate it. Problem Let the set $I = \{1, \dotsc, n\}$ for some $n \in \mathbb{N}$, let $B$ be a set, let $A_1, \dotsc, A_n$ be sets, let $U_i \subseteq A_i$ be a subset for all $i \in I$, and let $f: B \rightarrow A_1 \times \cdots \times A_n$ be a function. Prove that $$f^{-1}(U_1 \times \cdots \times U_n) = \bigcap_{i \in I} (f_i)^{-1}(U_i)$$ where the $f_i$ are the coordinate functions of $f$ (Recall that the coordinate function $f_i : B \rightarrow A_i$ is defined by $f_i = \pi_i \circ f$ for each $i = \{1, \dotsc, n\}$, and the function $\pi_i: A_1 \times \cdots \times A_n \rightarrow A_i$ is a projection mapping). Proof First, let $b \in B$. If $b \in f^{-1}(U_1 \times \cdots \times U_n)$, then there exists an image $f(b) \in U_1 \times \cdots \times U_n$, so that $f(b) = (u_1, \dotsc, u_n)$ for some $u_i \in U_i$, where $i \in I$. Mapping $f(b)$ to an element in $U_i$ by $\pi_i$, we obtain the image $\pi_i(f(b)) = f_i(b) \in U_i$. Consequenlty, $b \in (f_i)^{-1}(U_i)$ for each $i \in I$, so we can write $$b \in \bigcap_{i\in I} (f_i)^{-1}(U_i)$$ from which we conclude that $$f^{-1}(U_1 \times \cdots \times U_n) \subseteq \, \bigcap_{i \in I} (f_i)^{-1}(U_i)$$ Now suppose that $b\in B$. Assuming $m \in \bigcap_{i \in I} (f_i)^{-1}(U_i)$, we deduce that, for every $i \in I$, $b\in (f_i)^{-1}(U_i)$. Hence, there exists $f_i(b) \in U_i)$ such that $f_i(b) = \pi_i(f(b))$. Define the preimage $(\pi_i \circ f)^{-1} = \{u \in U_1 \times \dotsc \times U_n \, : \, (\pi_i \circ f)(u) \in U_i\}$. Clearly, $\pi_i(f(b)) \in (\pi_i \circ f)^{-1}$, so $f(b) \in U_1 \times \cdots \times U_n$. Consequently, $b \in f^{-1}(U_1 \times \cdots \times U_n)$. Therefore, $$\bigcap_{i \in I} (f_i)^{-1}(U_i) \subseteq f^{-1}(U_1 \times \cdots \times U_n)$$ We conclude that $$f^{-1}(U_1 \times \cdots \times U_n) = \bigcap_{i \in I} (f_i)^{-1}(U_i)$$ $\blacksquare$","I was looking through some problems in one of my books which does not have solutions in the back, and I found a problem stating to construct a proof for the following problem. If someone would not mind verifying whether or not the argument is valid, I would appreciate it. Problem Let the set $I = \{1, \dotsc, n\}$ for some $n \in \mathbb{N}$, let $B$ be a set, let $A_1, \dotsc, A_n$ be sets, let $U_i \subseteq A_i$ be a subset for all $i \in I$, and let $f: B \rightarrow A_1 \times \cdots \times A_n$ be a function. Prove that $$f^{-1}(U_1 \times \cdots \times U_n) = \bigcap_{i \in I} (f_i)^{-1}(U_i)$$ where the $f_i$ are the coordinate functions of $f$ (Recall that the coordinate function $f_i : B \rightarrow A_i$ is defined by $f_i = \pi_i \circ f$ for each $i = \{1, \dotsc, n\}$, and the function $\pi_i: A_1 \times \cdots \times A_n \rightarrow A_i$ is a projection mapping). Proof First, let $b \in B$. If $b \in f^{-1}(U_1 \times \cdots \times U_n)$, then there exists an image $f(b) \in U_1 \times \cdots \times U_n$, so that $f(b) = (u_1, \dotsc, u_n)$ for some $u_i \in U_i$, where $i \in I$. Mapping $f(b)$ to an element in $U_i$ by $\pi_i$, we obtain the image $\pi_i(f(b)) = f_i(b) \in U_i$. Consequenlty, $b \in (f_i)^{-1}(U_i)$ for each $i \in I$, so we can write $$b \in \bigcap_{i\in I} (f_i)^{-1}(U_i)$$ from which we conclude that $$f^{-1}(U_1 \times \cdots \times U_n) \subseteq \, \bigcap_{i \in I} (f_i)^{-1}(U_i)$$ Now suppose that $b\in B$. Assuming $m \in \bigcap_{i \in I} (f_i)^{-1}(U_i)$, we deduce that, for every $i \in I$, $b\in (f_i)^{-1}(U_i)$. Hence, there exists $f_i(b) \in U_i)$ such that $f_i(b) = \pi_i(f(b))$. Define the preimage $(\pi_i \circ f)^{-1} = \{u \in U_1 \times \dotsc \times U_n \, : \, (\pi_i \circ f)(u) \in U_i\}$. Clearly, $\pi_i(f(b)) \in (\pi_i \circ f)^{-1}$, so $f(b) \in U_1 \times \cdots \times U_n$. Consequently, $b \in f^{-1}(U_1 \times \cdots \times U_n)$. Therefore, $$\bigcap_{i \in I} (f_i)^{-1}(U_i) \subseteq f^{-1}(U_1 \times \cdots \times U_n)$$ We conclude that $$f^{-1}(U_1 \times \cdots \times U_n) = \bigcap_{i \in I} (f_i)^{-1}(U_i)$$ $\blacksquare$",,"['functions', 'elementary-set-theory', 'proof-verification', 'relations']"
86,Prove a function in 2 variables is onto,Prove a function in 2 variables is onto,,"Consider the function $h: N \times N \rightarrow N$ so that $h(a,b) = (2a +1)2^b - 1$, where $N=\{0,1,2,3,\dots\}$ is the set of natural numbers. Prove that it is onto . Tried taking various examples and value putting technique to see that most of values in the range are covered, which supports my intuition that the function is onto. \begin{array}{cc|c} a & b & h(a,b) \\\hline 0 & 0 & 0 \\ 0 & 1 & 1 \\ 1 & 0 & 2 \\ 0 & 2 & 3 \\ 2 & 0 & 4 \\ 1 & 1 & 5 \\ \vdots&\vdots & \vdots \end{array}","Consider the function $h: N \times N \rightarrow N$ so that $h(a,b) = (2a +1)2^b - 1$, where $N=\{0,1,2,3,\dots\}$ is the set of natural numbers. Prove that it is onto . Tried taking various examples and value putting technique to see that most of values in the range are covered, which supports my intuition that the function is onto. \begin{array}{cc|c} a & b & h(a,b) \\\hline 0 & 0 & 0 \\ 0 & 1 & 1 \\ 1 & 0 & 2 \\ 0 & 2 & 3 \\ 2 & 0 & 4 \\ 1 & 1 & 5 \\ \vdots&\vdots & \vdots \end{array}",,['functions']
87,Help me in showing that there is only 2 solutions for $f(x)=(x-1)e^{2x}+x^2-x-1=0$?,Help me in showing that there is only 2 solutions for ?,f(x)=(x-1)e^{2x}+x^2-x-1=0,"I have a problem with part (b) in the following question Question a) Function: $f(x)=(x-1)e^{2x}+x^2-x-1$, show that $f(x)$ has a zero between ‚àí1 and 1/2 and between 1/2 and 2. b) Show that there are only exactly two solutions (two 0's). My Approach a) Pretty easy: $$f(x)=(x-1)e^{2x}+x^2-x-1=0$$ $f(-1)>0,f(1/2)<0$ Intermediate Theorem tells that there is a solution. $f(1/2)<0,f(2)>0$ Intermediate Theorem tells that there is a solution in between. b) This is where I have the problem with, how do I show exactly that there is only 2 solutions. The most obvious thing that came to my mind is that the highest power is 2 . But then I thought it can't be that easy, there is something I am missing.","I have a problem with part (b) in the following question Question a) Function: $f(x)=(x-1)e^{2x}+x^2-x-1$, show that $f(x)$ has a zero between ‚àí1 and 1/2 and between 1/2 and 2. b) Show that there are only exactly two solutions (two 0's). My Approach a) Pretty easy: $$f(x)=(x-1)e^{2x}+x^2-x-1=0$$ $f(-1)>0,f(1/2)<0$ Intermediate Theorem tells that there is a solution. $f(1/2)<0,f(2)>0$ Intermediate Theorem tells that there is a solution in between. b) This is where I have the problem with, how do I show exactly that there is only 2 solutions. The most obvious thing that came to my mind is that the highest power is 2 . But then I thought it can't be that easy, there is something I am missing.",,"['calculus', 'functions']"
88,Cartesian product of bijective functions is bijective,Cartesian product of bijective functions is bijective,,"If $A, B, C, D$ are sets such that $A \sim B$ and $C \sim D$, $\exists$ bijections $f: A \to B$ and $g: C \to D$. Let $h: A \times C \to B \times D$ be $h(a,c) = (f(a), g(c))$. Show that $h$ is a bijection (and thus $A\times C \sim B \times D$). How can I solve this?","If $A, B, C, D$ are sets such that $A \sim B$ and $C \sim D$, $\exists$ bijections $f: A \to B$ and $g: C \to D$. Let $h: A \times C \to B \times D$ be $h(a,c) = (f(a), g(c))$. Show that $h$ is a bijection (and thus $A\times C \sim B \times D$). How can I solve this?",,"['functions', 'elementary-set-theory']"
89,"Is $f(x,y)=ax^2+by^2, \ a,b \in \mathbb R $ a bijection between $\mathbb R^2 \to \mathbb R$? Bijections of topologies",Is  a bijection between ? Bijections of topologies,"f(x,y)=ax^2+by^2, \ a,b \in \mathbb R  \mathbb R^2 \to \mathbb R","Is $f(x,y)=ax^2+by^2$ a bijection between $\mathbb R^2 \to \mathbb R$ ? How about $f(x,y,z)=\frac{x^2}{a^2} + \frac{y^2}{b^2}+ \frac{z^2}{c^2}? ( \mathbb R^3 \to \mathbb R )$ What confuses me now is this: My professor defined the function   $f(x,y)=x^2+y^2$ then stating : $f^{-1}((1,2))=\{(x,y)\in \mathbb R^2:  1 < f(x,y)<2\}$ Then, what I can assume the logic: since $(1,2)$ is    open in $\mathbb R $ then $f^{-1}((1,2)) $ is open in $\mathbb R^2.$   What are your thoughts on this? And also, if a have a bijective between two topologies, are the following statements correct: 1.)If a subset in one topology is open/closed its map is  open/closed as well in the respected topology. 2.)If a subset is nor open nor closed in one topology its map is nor open nor closed in the respected topology. 3.) If a subset is open and closed in one topology then it's map is open and closed in the respected other topology.","Is $f(x,y)=ax^2+by^2$ a bijection between $\mathbb R^2 \to \mathbb R$ ? How about $f(x,y,z)=\frac{x^2}{a^2} + \frac{y^2}{b^2}+ \frac{z^2}{c^2}? ( \mathbb R^3 \to \mathbb R )$ What confuses me now is this: My professor defined the function   $f(x,y)=x^2+y^2$ then stating : $f^{-1}((1,2))=\{(x,y)\in \mathbb R^2:  1 < f(x,y)<2\}$ Then, what I can assume the logic: since $(1,2)$ is    open in $\mathbb R $ then $f^{-1}((1,2)) $ is open in $\mathbb R^2.$   What are your thoughts on this? And also, if a have a bijective between two topologies, are the following statements correct: 1.)If a subset in one topology is open/closed its map is  open/closed as well in the respected topology. 2.)If a subset is nor open nor closed in one topology its map is nor open nor closed in the respected topology. 3.) If a subset is open and closed in one topology then it's map is open and closed in the respected other topology.",,['calculus']
90,Range of an inverse trigonometric function,Range of an inverse trigonometric function,,"Find the range of $f(x)=\arccos\sqrt {x^2+3x+1}+\arccos\sqrt {x^2+3x}$ My attempt is:I first found domain, $x^2+3x\geq0$ $x\leq-3$ or $x\geq0$...........(1) $x^2+3x+1\geq0$ $x\leq\frac{-3-\sqrt5}{2}$ or $x\geq \frac{-3+\sqrt5}{2}$...........(2) From (1) and (2), domain is $x\leq-3$ or $x\geq0$ but could not solve further..Any help will be greatly appreciated.","Find the range of $f(x)=\arccos\sqrt {x^2+3x+1}+\arccos\sqrt {x^2+3x}$ My attempt is:I first found domain, $x^2+3x\geq0$ $x\leq-3$ or $x\geq0$...........(1) $x^2+3x+1\geq0$ $x\leq\frac{-3-\sqrt5}{2}$ or $x\geq \frac{-3+\sqrt5}{2}$...........(2) From (1) and (2), domain is $x\leq-3$ or $x\geq0$ but could not solve further..Any help will be greatly appreciated.",,"['functions', 'trigonometry']"
91,Finding periodic (trigonometric?) function given points,Finding periodic (trigonometric?) function given points,,"It's been a while since I've taken a math class. I need a couple functions for a program I'm working on. I can tell they involve trigonometry, but I can't figure out how to derive the function given some points I know lie on the curve. Here are the points: degrees     x-axis force multiplier     ----  | ----       0   |  .5       45  |   0       90  |  -.5      135  |  -1      180  |  -.5      225  |   0      270  |  .5      315  |   1      360  |  .5 And another, similar function I would like to know how to figure out (in case you're feeling ambitious) degrees     y-axis force multiplier     ----  | ----       0   |  .5       45  |   1       90  |  .5      135  |   0      180  |  -.5      225  |  -1      270  |  -.5       315  |   0      360  |  .5 Thanks! EDIT I want to clarify what I am actually attempting to do here in hopes that it will help me receive the best suggestions. The points I posted above are x vector and y vector ratios of a force, given that force's change in rotation from an arbitrary starting orientation. Let me put it another way: I have an arrow that can rotate.  I also have a force that I need to apply in the direction the arrow points.  So I need values for the x and y component of the force vector given the arrow's rotation. ^ is 0x, 1y    (because it's vertical and up) < is -1x, 0y   (because it's horizontal and left) > is 1x, 0y    (because its horizontal and right) etc. So would a sawtooth function model it appropriately (as suggested below)?  I think linear will work but I want to be sure.  Thank you! EDIT 2 Though the suggestion to use a Fourier series was very interesting and seemed to work well, it was merely imitating a 'sawtooth' plot: So the piecewise function (linear) seems the best way to model the data.  Thanks for all the help! EDIT 3 For anyone who stumbles across this page in the future, I want to be clear that the way I'm modeling 2 dimensional force vectors in my program is not real-world accurate.  The ""sawtooth"" function works for me and my game, but is does not reflect actual physics.","It's been a while since I've taken a math class. I need a couple functions for a program I'm working on. I can tell they involve trigonometry, but I can't figure out how to derive the function given some points I know lie on the curve. Here are the points: degrees     x-axis force multiplier     ----  | ----       0   |  .5       45  |   0       90  |  -.5      135  |  -1      180  |  -.5      225  |   0      270  |  .5      315  |   1      360  |  .5 And another, similar function I would like to know how to figure out (in case you're feeling ambitious) degrees     y-axis force multiplier     ----  | ----       0   |  .5       45  |   1       90  |  .5      135  |   0      180  |  -.5      225  |  -1      270  |  -.5       315  |   0      360  |  .5 Thanks! EDIT I want to clarify what I am actually attempting to do here in hopes that it will help me receive the best suggestions. The points I posted above are x vector and y vector ratios of a force, given that force's change in rotation from an arbitrary starting orientation. Let me put it another way: I have an arrow that can rotate.  I also have a force that I need to apply in the direction the arrow points.  So I need values for the x and y component of the force vector given the arrow's rotation. ^ is 0x, 1y    (because it's vertical and up) < is -1x, 0y   (because it's horizontal and left) > is 1x, 0y    (because its horizontal and right) etc. So would a sawtooth function model it appropriately (as suggested below)?  I think linear will work but I want to be sure.  Thank you! EDIT 2 Though the suggestion to use a Fourier series was very interesting and seemed to work well, it was merely imitating a 'sawtooth' plot: So the piecewise function (linear) seems the best way to model the data.  Thanks for all the help! EDIT 3 For anyone who stumbles across this page in the future, I want to be clear that the way I'm modeling 2 dimensional force vectors in my program is not real-world accurate.  The ""sawtooth"" function works for me and my game, but is does not reflect actual physics.",,"['functions', 'trigonometry']"
92,Is there a theory of transcendental functions?,Is there a theory of transcendental functions?,,"Lately I've been interested in transcendental functions but as I tried to search for books or articles on the theory of transcendental functions, I only obtained irrelevant results (like calculus books or special functions). On the other hand, there's many books and articles on algebraic functions like: Algebraic Function Fields and Codes Topics in the Theory of Algebraic Function Fields Introduction to Algebraic and Abelian Functions Are there any references for the theory of transcendental functions? Did anyone studied rigorously such functions or is this field of mathematics outside the reach of contemporary mathematics?","Lately I've been interested in transcendental functions but as I tried to search for books or articles on the theory of transcendental functions, I only obtained irrelevant results (like calculus books or special functions). On the other hand, there's many books and articles on algebraic functions like: Algebraic Function Fields and Codes Topics in the Theory of Algebraic Function Fields Introduction to Algebraic and Abelian Functions Are there any references for the theory of transcendental functions? Did anyone studied rigorously such functions or is this field of mathematics outside the reach of contemporary mathematics?",,"['real-analysis', 'functions', 'reference-request']"
93,Show $\phi(x) = (x - x_1)(x - x_2) \cdots (x - x_m)$ is odd for $m$ odd.,Show  is odd for  odd.,\phi(x) = (x - x_1)(x - x_2) \cdots (x - x_m) m,"Given the function $$    \phi(x) = (x - x_1) (x - x_2) \cdots (x - x_m) $$ where $m$ is odd, and the points $x_1, x_2, \cdots, x_m$ are symmetric wrt the midpoint of its domain, show that the function is odd wrt the midpoint of its domain. We define $$ a \le x_1 < x_2 < \cdots < x_m \le b $$ so that the midpoint of its domain $[a, b]$ is $\frac{a+b}{2}$. What we can do is define a transform $$ \tau = x - \frac{a + b}{2}$$ that recentres the domain onto $$ \left[\frac{a - b}{2}, \frac{b - a}{2}\right] $$ which has midpoint the origin. It remains to show that $$ \phi(-\tau) = -\phi(\tau). $$ I understand the function should be odd, but I can't show this algebraically. I've tried using induction on $m$, but if $m=1$ then $$ -\phi(\tau) = -(\tau - x_1),$$ $$ \phi(-\tau) = (-\tau - x_1),$$ and I can't even prove the base case. I've also tried just substituting in $\tau$ and $-\tau$ for arbitrary odd $m$ and doing some algebra but I only get $$ -\phi(\tau) = - (\tau - x_1) (\tau - x_2) \cdots (\tau - x_m),$$ $$ \phi(-\tau) = - (\tau + x_1) (\tau + x_2) \cdots (\tau + x_m).$$","Given the function $$    \phi(x) = (x - x_1) (x - x_2) \cdots (x - x_m) $$ where $m$ is odd, and the points $x_1, x_2, \cdots, x_m$ are symmetric wrt the midpoint of its domain, show that the function is odd wrt the midpoint of its domain. We define $$ a \le x_1 < x_2 < \cdots < x_m \le b $$ so that the midpoint of its domain $[a, b]$ is $\frac{a+b}{2}$. What we can do is define a transform $$ \tau = x - \frac{a + b}{2}$$ that recentres the domain onto $$ \left[\frac{a - b}{2}, \frac{b - a}{2}\right] $$ which has midpoint the origin. It remains to show that $$ \phi(-\tau) = -\phi(\tau). $$ I understand the function should be odd, but I can't show this algebraically. I've tried using induction on $m$, but if $m=1$ then $$ -\phi(\tau) = -(\tau - x_1),$$ $$ \phi(-\tau) = (-\tau - x_1),$$ and I can't even prove the base case. I've also tried just substituting in $\tau$ and $-\tau$ for arbitrary odd $m$ and doing some algebra but I only get $$ -\phi(\tau) = - (\tau - x_1) (\tau - x_2) \cdots (\tau - x_m),$$ $$ \phi(-\tau) = - (\tau + x_1) (\tau + x_2) \cdots (\tau + x_m).$$",,['functions']
94,"For any strictly increasing convergent sequence $x_n$, the sequence $f(x_n)$ is convergent","For any strictly increasing convergent sequence , the sequence  is convergent",x_n f(x_n),"Let $f(x)$ be defined on R and be strictly increasing. Claim: for any strictly increasing convergent sequence $x_n$, the   sequence $f(x_n)$ is convergent. I believe it's false. Think about any strictly increasing right-continuous function with a jump discontinuity. Clearly, as $x_n$ goes to the point of discontinuity, $f(x_n)$ fails to converge because at that point the left-sided limit isn't equal to the value of the function. The problem is that the suggested answer is that the claim is true. Am I right or no?","Let $f(x)$ be defined on R and be strictly increasing. Claim: for any strictly increasing convergent sequence $x_n$, the   sequence $f(x_n)$ is convergent. I believe it's false. Think about any strictly increasing right-continuous function with a jump discontinuity. Clearly, as $x_n$ goes to the point of discontinuity, $f(x_n)$ fails to converge because at that point the left-sided limit isn't equal to the value of the function. The problem is that the suggested answer is that the claim is true. Am I right or no?",,"['real-analysis', 'sequences-and-series', 'functions']"
95,When does a function have an inverse?,When does a function have an inverse?,,"I have been told that a function has an inverse if it is one-to-one or injective, but how can we rigorously prove this?  I have been struggling to find a proof for days.","I have been told that a function has an inverse if it is one-to-one or injective, but how can we rigorously prove this?  I have been struggling to find a proof for days.",,"['functions', 'inverse']"
96,Is there a non-decreasing function that is discontinuous at every rational point? [duplicate],Is there a non-decreasing function that is discontinuous at every rational point? [duplicate],,"This question already has an answer here : Construct a monotone function which has countably many discontinuities (1 answer) Closed 9 years ago . A well-known theorem is that if $f:[a,b]\to\mathbb{R}$ is non-decreasing, then $f$ as at most countably many discontinuities. This led me think of the following question. Question: Is there a non-decreasing function $f:[0,1]\to\mathbb{R}$ such that $f$ is discontinuous at every rational point? Such a function would definitively be geometrically counter-intuitive. Intuitively, I would think that if it is discontinues at every rational point, then it will be discontinues everywhere, and hence would not exist by the aforementioned theorem. But I cannot think of any proof or disproof of these claims.","This question already has an answer here : Construct a monotone function which has countably many discontinuities (1 answer) Closed 9 years ago . A well-known theorem is that if $f:[a,b]\to\mathbb{R}$ is non-decreasing, then $f$ as at most countably many discontinuities. This led me think of the following question. Question: Is there a non-decreasing function $f:[0,1]\to\mathbb{R}$ such that $f$ is discontinuous at every rational point? Such a function would definitively be geometrically counter-intuitive. Intuitively, I would think that if it is discontinues at every rational point, then it will be discontinues everywhere, and hence would not exist by the aforementioned theorem. But I cannot think of any proof or disproof of these claims.",,"['real-analysis', 'functions', 'continuity']"
97,Sum of resulting values of dice,Sum of resulting values of dice,,"We have thrown with $n$ dice. The sum of resulting values is $k$. We are looking for a function $f$ which gives the number of throws, with we can construct $k$ with $n$ dice. Some example for $f(n,k)$: $f(3,3)=1$ because only the $1+1+1$ produces $3$. $f(3,4)=3$ because $1+1+2$, $1+2+1$, $2+1+1$ are the only sums, which give $4$. Can anyone give me an explicit formula for $f$?","We have thrown with $n$ dice. The sum of resulting values is $k$. We are looking for a function $f$ which gives the number of throws, with we can construct $k$ with $n$ dice. Some example for $f(n,k)$: $f(3,3)=1$ because only the $1+1+1$ produces $3$. $f(3,4)=3$ because $1+1+2$, $1+2+1$, $2+1+1$ are the only sums, which give $4$. Can anyone give me an explicit formula for $f$?",,"['probability', 'functions', 'dice']"
98,Finding range of $f(x) = \sin^4 x\tan x + \cos^4 x\cot x$,Finding range of,f(x) = \sin^4 x\tan x + \cos^4 x\cot x,"I got to a certain step and couldn't continue. I can't fully understand the provided solution... $$ f(x) = {\sin^6x+\cos^6x \over \sin x \cos x} = {2-1.5\sin^2 2x \over \sin 2x}$$ Let$$ t=\sin2x, t \neq 0$$ $$ f(x) = g(t) = {2 \over t} - {3t \over 2}$$ I don't get the next part. Since $$\frac2t\ \text{and}\ -\frac{3t}2$$ are both decreasing on $$[-1,0)\cup(0,1]$$ The range of $g(t)$ is $$(-\infty , -0.5]\cup[0.5,+\infty)$$ which is the range of $f(x)$. Any explanation would be greatly appreciated.","I got to a certain step and couldn't continue. I can't fully understand the provided solution... $$ f(x) = {\sin^6x+\cos^6x \over \sin x \cos x} = {2-1.5\sin^2 2x \over \sin 2x}$$ Let$$ t=\sin2x, t \neq 0$$ $$ f(x) = g(t) = {2 \over t} - {3t \over 2}$$ I don't get the next part. Since $$\frac2t\ \text{and}\ -\frac{3t}2$$ are both decreasing on $$[-1,0)\cup(0,1]$$ The range of $g(t)$ is $$(-\infty , -0.5]\cup[0.5,+\infty)$$ which is the range of $f(x)$. Any explanation would be greatly appreciated.",,"['functions', 'trigonometry']"
99,Show that $S$ and $2^{S}$ are not equinumerous. (Not bijective?),Show that  and  are not equinumerous. (Not bijective?),S 2^{S},"I have tried to look for a problem the same as mine, but I have not been too lucky, or if I did I had trouble applying that solution to my problem. Any help would be appreciated. I know how to solve this problem, but I'm afraid it would someone ""cheap"" because it is just a fact I found. Let $S$ be any set.  Let $2^{S} =\{f\mid f\colon S\to\{0,1\}\}$. Then $S$ and $2^{S}$ are not equinumerous. Now, I believe the ""cheap"" way I found out how to do this is to use the fact that the there is a bijection between $2^{S}$ and $\mathcal{P}(S)$, but there is no bijection between a set and it's power set. I was given a hint to assume there is a bijection $f\colon S\to2^{S}$, and to copy the method used in Cantor's Theorem. I went through this theorem a few weeks ago. Also, I just looked at in my text and on Proofwiki, but I am still having trouble. Edit: I forgot to mention I am just taking an introductory logic class. The only thing we have done with Cantor's Theorem is prove that the powerset of integers is non enumerable.","I have tried to look for a problem the same as mine, but I have not been too lucky, or if I did I had trouble applying that solution to my problem. Any help would be appreciated. I know how to solve this problem, but I'm afraid it would someone ""cheap"" because it is just a fact I found. Let $S$ be any set.  Let $2^{S} =\{f\mid f\colon S\to\{0,1\}\}$. Then $S$ and $2^{S}$ are not equinumerous. Now, I believe the ""cheap"" way I found out how to do this is to use the fact that the there is a bijection between $2^{S}$ and $\mathcal{P}(S)$, but there is no bijection between a set and it's power set. I was given a hint to assume there is a bijection $f\colon S\to2^{S}$, and to copy the method used in Cantor's Theorem. I went through this theorem a few weeks ago. Also, I just looked at in my text and on Proofwiki, but I am still having trouble. Edit: I forgot to mention I am just taking an introductory logic class. The only thing we have done with Cantor's Theorem is prove that the powerset of integers is non enumerable.",,"['functions', 'elementary-set-theory']"
