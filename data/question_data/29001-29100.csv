,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,I roll 6-sided dice until the sum exceeds 50. What is the expected value of the final roll?,I roll 6-sided dice until the sum exceeds 50. What is the expected value of the final roll?,,"I roll 6-sided dice until the sum exceeds 50. What is the expected value of the final roll? I am not sure how to set this one up. This one is not homework, by the way, but a question I am making up that is inspired by one. I'm hoping this will help me understand what's going on better.","I roll 6-sided dice until the sum exceeds 50. What is the expected value of the final roll? I am not sure how to set this one up. This one is not homework, by the way, but a question I am making up that is inspired by one. I'm hoping this will help me understand what's going on better.",,"['probability', 'statistics']"
1,Expected number of runs in a sequence of coin flips,Expected number of runs in a sequence of coin flips,,"A coin with heads probability $p$ is flipped $n$ times. A ""run"" is a maximal sequence of consecutive flips that are all the same. For example, the sequence HTHHHTTH with $n=8$ has five runs, namely H, T, HHH, TT,H. Show that the expected number of runs is  $$1+2(n-1)p(1-p).$$ I have tried to use some generating function on this but calculus got pretty messy and didn't work.","A coin with heads probability $p$ is flipped $n$ times. A ""run"" is a maximal sequence of consecutive flips that are all the same. For example, the sequence HTHHHTTH with $n=8$ has five runs, namely H, T, HHH, TT,H. Show that the expected number of runs is  $$1+2(n-1)p(1-p).$$ I have tried to use some generating function on this but calculus got pretty messy and didn't work.",,"['probability', 'discrete-mathematics']"
2,Curious about a made-up paradox,Curious about a made-up paradox,,"I have thought up a paradox, that may already exist, but I do not know what it's called. It's bothering me though, so any help regarding solving it or proving it impossible would be appreciated. In this paradox, you have a gambler. The gambler is \$200 in debt, but the gambler has a wealthy friend who lets the gambler bet using money he does not have to play a game. In this game, the gambler bets \$1, and a random number generator generates a number from 1 to 100. If the number roll over, or exactly 55, the gambler wins \$2. If the number rolls under 55 the gambler loses that \$1 he bet. From my understanding of statistics, over a certain expected period of time, the gambler should hit the unlikely scenario to get out of debt using this method. However using my computer simulations, it seems to take more time than I can allow my simulations to run. Is it possible to guess an expected number of times the gambler would have to play the game in order to get out of debt using some mathematical model? I am also concerned that the nature of random-number generators may make it impossible for the gambler to get out of debt, as random number generators could be heavily biased to avoid situations such as randomized decks to be fully sorted, or getting out of debt with negative debt and unlikely odds. What I want to get out of this question is, how to explain why it's possible, how to calculate expected number of times the game has to be played to reach the goal, or why it's impossible, or some existing question I can try to study to better understand the problem.","I have thought up a paradox, that may already exist, but I do not know what it's called. It's bothering me though, so any help regarding solving it or proving it impossible would be appreciated. In this paradox, you have a gambler. The gambler is \$200 in debt, but the gambler has a wealthy friend who lets the gambler bet using money he does not have to play a game. In this game, the gambler bets \$1, and a random number generator generates a number from 1 to 100. If the number roll over, or exactly 55, the gambler wins \$2. If the number rolls under 55 the gambler loses that \$1 he bet. From my understanding of statistics, over a certain expected period of time, the gambler should hit the unlikely scenario to get out of debt using this method. However using my computer simulations, it seems to take more time than I can allow my simulations to run. Is it possible to guess an expected number of times the gambler would have to play the game in order to get out of debt using some mathematical model? I am also concerned that the nature of random-number generators may make it impossible for the gambler to get out of debt, as random number generators could be heavily biased to avoid situations such as randomized decks to be fully sorted, or getting out of debt with negative debt and unlikely odds. What I want to get out of this question is, how to explain why it's possible, how to calculate expected number of times the game has to be played to reach the goal, or why it's impossible, or some existing question I can try to study to better understand the problem.",,['probability']
3,What is the probability that I roll a 2 before I roll two odd numbers?,What is the probability that I roll a 2 before I roll two odd numbers?,,"Assuming that I use a standard die, what is the probability that I roll a 2 before I roll  two odd numbers? The odd numbers do not have to be distinct. For example, 1,6,4,2 wins and 3,3 loses.","Assuming that I use a standard die, what is the probability that I roll a 2 before I roll  two odd numbers? The odd numbers do not have to be distinct. For example, 1,6,4,2 wins and 3,3 loses.",,['probability']
4,"Is there a closed form expression for $\int_{- \infty}^\infty \int_{-\infty}^y \frac{1}{2 \pi} e^{-(1/2) ( x^2+y^2 )} \mathrm{d}x\,\mathrm{d}y$?",Is there a closed form expression for ?,"\int_{- \infty}^\infty \int_{-\infty}^y \frac{1}{2 \pi} e^{-(1/2) ( x^2+y^2 )} \mathrm{d}x\,\mathrm{d}y","I have been trying to evaluate the integral: $$\int_{- \infty}^\infty \int_{-\infty}^y \frac{1}{2 \pi} e^{-(1/2) ( x^2+y^2 )}\mathrm {d}x\,\mathrm{d}y$$ I know of course that the integral equals $1$ over $[-\infty,\infty] \times [-\infty,\infty]$ but I do not quite know how to handle the present case. Are there any tricks here? Thank you.","I have been trying to evaluate the integral: $$\int_{- \infty}^\infty \int_{-\infty}^y \frac{1}{2 \pi} e^{-(1/2) ( x^2+y^2 )}\mathrm {d}x\,\mathrm{d}y$$ I know of course that the integral equals $1$ over $[-\infty,\infty] \times [-\infty,\infty]$ but I do not quite know how to handle the present case. Are there any tricks here? Thank you.",,"['probability', 'statistics', 'definite-integrals', 'self-learning']"
5,Probability of streaks,Probability of streaks,,"I thought of this question lately, but I'm not satisfied with the answer I got: If I flip a coin 100 times, what is the probability that I will get a streak of at least ten of the same side? The way I thought of solving it was just: $\left(90 \times 0.5 ^ 9\right) = 0.0879$, but this has to be wrong because, for the probability of getting a streak of at least 4 in the same scenario, it yields: $\left(96 \times 0.5 ^ 3\right) = 12$, which obviously doesn't make sense.","I thought of this question lately, but I'm not satisfied with the answer I got: If I flip a coin 100 times, what is the probability that I will get a streak of at least ten of the same side? The way I thought of solving it was just: $\left(90 \times 0.5 ^ 9\right) = 0.0879$, but this has to be wrong because, for the probability of getting a streak of at least 4 in the same scenario, it yields: $\left(96 \times 0.5 ^ 3\right) = 12$, which obviously doesn't make sense.",,['probability']
6,Calculating the probability of a coin falling on its side,Calculating the probability of a coin falling on its side,,"A classical example that's given for probability exercises is coin flipping. Generally it is accepted that there are two possible outcomes which are heads or tails. However, it is possible in the real world for a coin to also fall on its side which makes a third event ( $P(\text{side}) = 1 - P(\text{heads}) - P(\text{tails})$ ?). How would a mathematician go about calculating the probability of that? Could it be done by simply using respective surface areas or would a proper model be more complex?","A classical example that's given for probability exercises is coin flipping. Generally it is accepted that there are two possible outcomes which are heads or tails. However, it is possible in the real world for a coin to also fall on its side which makes a third event ( $P(\text{side}) = 1 - P(\text{heads}) - P(\text{tails})$ ?). How would a mathematician go about calculating the probability of that? Could it be done by simply using respective surface areas or would a proper model be more complex?",,"['probability', 'physics', 'polyhedra']"
7,Expectation of maximum of n i.i.d random variables,Expectation of maximum of n i.i.d random variables,,"I have $n$ i.i.d. random variables, $X_1,..., X_n$ which follow some arbitrary distribution. Based on experiments in Python with various distributions, it seems that $\mathbb{E}(\max(X_1,...,X_n))$ is a linear (or seemingly close to linear) function of $\mathbb{E}(X_i)$ . It is indeed linear for some examples where it is possible to get a closed form solution for $\mathbb{E}(\max(X_1,...,X_n))$ or a good approximation. Expected value of $\max\{X_1,\ldots,X_n\}$ where $X_i$ are iid uniform. Expectation of the maximum of i.i.d. geometric random variables I wonder if this is the case more generally? Is there some way to prove it?","I have i.i.d. random variables, which follow some arbitrary distribution. Based on experiments in Python with various distributions, it seems that is a linear (or seemingly close to linear) function of . It is indeed linear for some examples where it is possible to get a closed form solution for or a good approximation. Expected value of $\max\{X_1,\ldots,X_n\}$ where $X_i$ are iid uniform. Expectation of the maximum of i.i.d. geometric random variables I wonder if this is the case more generally? Is there some way to prove it?","n X_1,..., X_n \mathbb{E}(\max(X_1,...,X_n)) \mathbb{E}(X_i) \mathbb{E}(\max(X_1,...,X_n))","['probability', 'probability-distributions', 'expected-value', 'order-statistics']"
8,Flip a fair coin until three consecutive heads or tails appear,Flip a fair coin until three consecutive heads or tails appear,,What is the expected number of flips until three consecutive heads or tails appear?,What is the expected number of flips until three consecutive heads or tails appear?,,['probability']
9,Betting on the appearance of HHT or HTH in a series of coin flips,Betting on the appearance of HHT or HTH in a series of coin flips,,"Suppose that we bet on the outcomes of coin flips in the following way. Each of us chooses a different series of three flips, and we flip a coin until three consecutive flips, in order, match your choice or mine. For example, you might pick HHT while I pick HTH, and we flip until either HHT or HTH. Is one of us more likely to win? My friend Shimon argues as follows. If you pick HHT and I pick HTH, a long stream of flips will sooner or later include HH, the first two flips in your choice; and at that moment you have won, because there's no way that later flips can produce my HTH streak before it produces your HHT streak. But no corresponding situation exists for the other side; should HT, the first two flips in my choice, arise, it's still possible for you to win, because the next flips could be THHT, so that the six flips HTTHHT would be another win for you. I consider this total nonsense. It's obvious that the next three flips are as likely to be HHT, or HTT, or any of the six other possible sets of three flips. His approach of asking whether wins are possible given certain strings of past flips is mind-boggling, working without any clear sample-space and defying mathematics. I suggested a simulation. The simulation I produced is an Excel spreadsheet that flips sets of 65 flips. In each set, it finds the first flip that begins your choice or mine, and assigns a winner. The following screen shot shows that simulation. Blue is associated with HHT, and pink is associated with HTH. In the first set, HHT began in flips 2, 10, 16, 20, 29, 36 and 50. HTH began in flips 3, 5, 11, 13, 21 and 51. Because HHT arose first, there's a 1 in the blue vertical bar beside the first set. As you may be able to see, HHT won 8 sets of the pictured 10 sets. In my little experiment, HHT won far more often, and often by dramatic margins. I've looked around this stack exchange, and found a few questions almost exactly like mine – like this one and this one -- and several questions at least very similar to mine -- like this one and this one . They all seem to believe that Shimon is right, and some sequences are more likely than others. But despite that seeming (if not very clearly stated) unanimity, and despite my own simulation, I just cannot believe it. Obviously every possible set of three flips is equally likely. So I guess that my question is, can someone explain this at a more intuitive level, reaching the mistake that's misleading me or (I still think) Shimon?","Suppose that we bet on the outcomes of coin flips in the following way. Each of us chooses a different series of three flips, and we flip a coin until three consecutive flips, in order, match your choice or mine. For example, you might pick HHT while I pick HTH, and we flip until either HHT or HTH. Is one of us more likely to win? My friend Shimon argues as follows. If you pick HHT and I pick HTH, a long stream of flips will sooner or later include HH, the first two flips in your choice; and at that moment you have won, because there's no way that later flips can produce my HTH streak before it produces your HHT streak. But no corresponding situation exists for the other side; should HT, the first two flips in my choice, arise, it's still possible for you to win, because the next flips could be THHT, so that the six flips HTTHHT would be another win for you. I consider this total nonsense. It's obvious that the next three flips are as likely to be HHT, or HTT, or any of the six other possible sets of three flips. His approach of asking whether wins are possible given certain strings of past flips is mind-boggling, working without any clear sample-space and defying mathematics. I suggested a simulation. The simulation I produced is an Excel spreadsheet that flips sets of 65 flips. In each set, it finds the first flip that begins your choice or mine, and assigns a winner. The following screen shot shows that simulation. Blue is associated with HHT, and pink is associated with HTH. In the first set, HHT began in flips 2, 10, 16, 20, 29, 36 and 50. HTH began in flips 3, 5, 11, 13, 21 and 51. Because HHT arose first, there's a 1 in the blue vertical bar beside the first set. As you may be able to see, HHT won 8 sets of the pictured 10 sets. In my little experiment, HHT won far more often, and often by dramatic margins. I've looked around this stack exchange, and found a few questions almost exactly like mine – like this one and this one -- and several questions at least very similar to mine -- like this one and this one . They all seem to believe that Shimon is right, and some sequences are more likely than others. But despite that seeming (if not very clearly stated) unanimity, and despite my own simulation, I just cannot believe it. Obviously every possible set of three flips is equally likely. So I guess that my question is, can someone explain this at a more intuitive level, reaching the mistake that's misleading me or (I still think) Shimon?",,"['probability', 'intuition']"
10,Distribution of a binomial variable squared,Distribution of a binomial variable squared,,"If I know $X$ is a binomial random variable, how can I find the distribution of $X$ squared (I know that $P(Y=y=x^2) = p(X=x)$ but does this distribution have a standard name)? In particular, how can I find its expected value? Thanks! EDIT: Thank you all! (-:","If I know $X$ is a binomial random variable, how can I find the distribution of $X$ squared (I know that $P(Y=y=x^2) = p(X=x)$ but does this distribution have a standard name)? In particular, how can I find its expected value? Thanks! EDIT: Thank you all! (-:",,"['probability', 'probability-distributions', 'binomial-coefficients']"
11,Time until a consecutive sequence of ones in a random bit sequence,Time until a consecutive sequence of ones in a random bit sequence,,"This a reformulation of a practical problem I encountered. Say we have an infinite sequence of random, i.i.d bits. For each bit $X_i$, $P(X_i=1)=p$. What is the expected time until we get a sequence of $n$ 1 bits? Thanks!","This a reformulation of a practical problem I encountered. Say we have an infinite sequence of random, i.i.d bits. For each bit $X_i$, $P(X_i=1)=p$. What is the expected time until we get a sequence of $n$ 1 bits? Thanks!",,"['stochastic-processes', 'probability']"
12,"Darth Vader Rule: what is the reason for its name, and a formal proof?","Darth Vader Rule: what is the reason for its name, and a formal proof?",,"I often hear the term "" Darth Vader Rule "" when calculating the expected value using the survival function and taking the integral where it is defined. I am not quite sure why it is called that (is it customary?) and I would also like to know a formal proof of it.  I tried to look around, but I have a feeling that the name of this rule is not official and I cannot seem to find it right away.","I often hear the term "" Darth Vader Rule "" when calculating the expected value using the survival function and taking the integral where it is defined. I am not quite sure why it is called that (is it customary?) and I would also like to know a formal proof of it.  I tried to look around, but I have a feeling that the name of this rule is not official and I cannot seem to find it right away.",,"['probability', 'actuarial-science']"
13,$CLT$ and $LLN$ give different results,and  give different results,CLT LLN,"I tried to solve a problem two different ways and I got different results. Let $( X_i )_{i \in \mathbb{N}}$ be a series of independent, identically distributed random variables, with $\mathbb{E}[X_i] = 1$ and $\mathbb{V}[X_i] = 1$ Determine $$ \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \leq \sqrt{n}\right) $$ Here are the two approaches that I tried. Central limit theorem \begin{align*} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \leq \sqrt{n}\right) \\ = {} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n (X_i - 1) \leq \sqrt{n} - \frac{n}{\sqrt{n}}\right) \\ = {} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n (X_i - 1) \leq 0\right) \\ = {} & \Phi_{0,1}(0) = \frac{1}{2} \end{align*} Law of large numbers \begin{align*} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \leq \sqrt{n}\right) \\ = {} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{n} \sum_{i=1}^n X_i \leq 1 \right) \\ \geq {} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{n} \sum_{i=1}^n X_i = 1\right) \\ = {} & 1 \end{align*} according to the strong law of large numbers. This then means that $$ \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \leq \sqrt{n}\right) = 1 $$ What am I doing wrong here? My understanding is that the CLT solution is correct, but I don't see what I did wrong with applying the law of large numbers either.","I tried to solve a problem two different ways and I got different results. Let $( X_i )_{i \in \mathbb{N}}$ be a series of independent, identically distributed random variables, with $\mathbb{E}[X_i] = 1$ and $\mathbb{V}[X_i] = 1$ Determine $$ \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \leq \sqrt{n}\right) $$ Here are the two approaches that I tried. Central limit theorem \begin{align*} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \leq \sqrt{n}\right) \\ = {} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n (X_i - 1) \leq \sqrt{n} - \frac{n}{\sqrt{n}}\right) \\ = {} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n (X_i - 1) \leq 0\right) \\ = {} & \Phi_{0,1}(0) = \frac{1}{2} \end{align*} Law of large numbers \begin{align*} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \leq \sqrt{n}\right) \\ = {} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{n} \sum_{i=1}^n X_i \leq 1 \right) \\ \geq {} & \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{n} \sum_{i=1}^n X_i = 1\right) \\ = {} & 1 \end{align*} according to the strong law of large numbers. This then means that $$ \lim_{n \to \infty} \mathbb{P}\left(\frac{1}{\sqrt{n}} \sum_{i=1}^n X_i \leq \sqrt{n}\right) = 1 $$ What am I doing wrong here? My understanding is that the CLT solution is correct, but I don't see what I did wrong with applying the law of large numbers either.",,"['probability', 'proof-verification', 'probability-limit-theorems']"
14,Expectation of quotient of random variables,Expectation of quotient of random variables,,"Let $X_1,...X_n$ be independent, identically distributed and nonnegative random variables, and let $k\le n$. Compute: $$E\left[{\sum_{i=1}^k X_i\over \sum_{i=1}^n X_i}\right].$$ This question has already been asked: Expectation of random variables ratio . The thing is that my teacher told me that the solution in the link wasn't really a ""solution"" the correct thing to do is to compute the conditional expectation of $${\sum_{i=1}^k X_i\over \sum_{i=1}^n X_i}$$ given that $\sum_{i=1}^n X_i=m$ where $m$ is a positive integer, but I have no idea how to do this, I would really appreciate if you can help me with this problem.","Let $X_1,...X_n$ be independent, identically distributed and nonnegative random variables, and let $k\le n$. Compute: $$E\left[{\sum_{i=1}^k X_i\over \sum_{i=1}^n X_i}\right].$$ This question has already been asked: Expectation of random variables ratio . The thing is that my teacher told me that the solution in the link wasn't really a ""solution"" the correct thing to do is to compute the conditional expectation of $${\sum_{i=1}^k X_i\over \sum_{i=1}^n X_i}$$ given that $\sum_{i=1}^n X_i=m$ where $m$ is a positive integer, but I have no idea how to do this, I would really appreciate if you can help me with this problem.",,"['probability', 'random-variables', 'expectation', 'conditional-expectation']"
15,"Distribution of sine of uniform random variable on $[0, 2\pi]$",Distribution of sine of uniform random variable on,"[0, 2\pi]","Let $X$ be a continuous random variable having uniform distribution on $[0, 2\pi]$. What distribution has the random variable $Y=\sin X$ ? I think, it is also uniform. Am I right?","Let $X$ be a continuous random variable having uniform distribution on $[0, 2\pi]$. What distribution has the random variable $Y=\sin X$ ? I think, it is also uniform. Am I right?",,"['probability', 'probability-distributions', 'random-variables', 'uniform-distribution']"
16,Probability that an integer number having Poisson distribution is even,Probability that an integer number having Poisson distribution is even,,"The probability $P(X=n)$ that an event X takes place $n$ times in a fixed period of time follows the Poisson distribution with parameter $\lambda$ i.e. $$ P(X = n) = e^{-\lambda} \frac{\lambda ^ n}{n!}$$ I have to evaluate the probability that the event $X$ takes place an even number of times. I know that: $$ P(X \text{ is even} ) = e^{-\lambda} \cdot \sum_{k=0}^{+\infty} \frac{\lambda^{2k}}{(2k)!}$$ but I can't solve the series. I guess that I have to use the fact that $e^\lambda = \sum_{n = 0}^{+\infty} \lambda^n/n!$, but I got stuck. How can I evaluate $P(X \text{ is even})$ (alternative solutions appreciated).","The probability $P(X=n)$ that an event X takes place $n$ times in a fixed period of time follows the Poisson distribution with parameter $\lambda$ i.e. $$ P(X = n) = e^{-\lambda} \frac{\lambda ^ n}{n!}$$ I have to evaluate the probability that the event $X$ takes place an even number of times. I know that: $$ P(X \text{ is even} ) = e^{-\lambda} \cdot \sum_{k=0}^{+\infty} \frac{\lambda^{2k}}{(2k)!}$$ but I can't solve the series. I guess that I have to use the fact that $e^\lambda = \sum_{n = 0}^{+\infty} \lambda^n/n!$, but I got stuck. How can I evaluate $P(X \text{ is even})$ (alternative solutions appreciated).",,"['probability', 'sequences-and-series']"
17,Expected value of average of Brownian motion,Expected value of average of Brownian motion,,"For a standard one-dimensional Brownian motion $W(t)$, calculate: $$E\bigg[\Big(\frac{1}{T}\int\limits_0^TW_t\, dt\Big)^2\bigg]$$ Note: I am not able to figure out how to approach this problem. All i can think of is that the term $\frac{1}{T}\int\limits_0^TW_t\,dt$ is like 'average'. But not sure how to proceed ahead. I'm relatively new to Brownian motion. I tried searching the forum for some hints..but could not find one. I will really appreciate if you could please guide me in the right direction. Thanks!","For a standard one-dimensional Brownian motion $W(t)$, calculate: $$E\bigg[\Big(\frac{1}{T}\int\limits_0^TW_t\, dt\Big)^2\bigg]$$ Note: I am not able to figure out how to approach this problem. All i can think of is that the term $\frac{1}{T}\int\limits_0^TW_t\,dt$ is like 'average'. But not sure how to proceed ahead. I'm relatively new to Brownian motion. I tried searching the forum for some hints..but could not find one. I will really appreciate if you could please guide me in the right direction. Thanks!",,"['probability', 'brownian-motion', 'stochastic-calculus']"
18,fair value of a hat-drawing game,fair value of a hat-drawing game,,"I've been going through a problem solving book, and I'm a little stumped on the following question: At each round, draw a number 1-100 out of a hat (and replace the number after you draw). You can play as many rounds as you want, and the last number you draw is the number of dollars you win, but each round costs an extra $1. What is a fair value to charge for entering this game? One thought I had was to suppose I only have N rounds, instead of an unlimited number. (I'd then let N approach infinity.) Then my expected payoff at the Nth round is (Expected number I draw - N) = 50.5 - N. So if I draw a number d at the (N-1)th round, my current payoff would be d - (N-1), so I should redraw if d - (N-1) < 50.5 - N, i.e., if d < 49.5. So my expected payoff at the (N-1)th round is 49(50.5-N) + 1/100*[(50 - (N-1)) + (51 - (N-1)) + ... + (100 - (N-1))] = 62.995 - N (if I did my calculations correctly), and so on. The problem is that this gets messy, so I think I'm doing something wrong. Any hints/suggestions to the right approach?","I've been going through a problem solving book, and I'm a little stumped on the following question: At each round, draw a number 1-100 out of a hat (and replace the number after you draw). You can play as many rounds as you want, and the last number you draw is the number of dollars you win, but each round costs an extra $1. What is a fair value to charge for entering this game? One thought I had was to suppose I only have N rounds, instead of an unlimited number. (I'd then let N approach infinity.) Then my expected payoff at the Nth round is (Expected number I draw - N) = 50.5 - N. So if I draw a number d at the (N-1)th round, my current payoff would be d - (N-1), so I should redraw if d - (N-1) < 50.5 - N, i.e., if d < 49.5. So my expected payoff at the (N-1)th round is 49(50.5-N) + 1/100*[(50 - (N-1)) + (51 - (N-1)) + ... + (100 - (N-1))] = 62.995 - N (if I did my calculations correctly), and so on. The problem is that this gets messy, so I think I'm doing something wrong. Any hints/suggestions to the right approach?",,[]
19,Independent events or conditional probability?,Independent events or conditional probability?,,"In my daily morning walk there is a 20% chance I drop my pouch. Every day I follow the exact same straight path, to the district square and then back. Assuming that my walk is on a straight segment from A to B and then back from B to A, what is the probability I dropped it from A to B? I know this seems to be a very easy problem, but I am a little confused: Initially, there is equal probability for me to drop my pouch in any of the two directions. So for AB, this probability is 50% of 20%? But for the second part of my walk back home, the probability is conditional. If I have already dropped it in AB, the probability is zero. If I haven’t, the probability is 100% of the total 20%, that is, 20%. Any clue? Edit : There are two answer which have been updated, but they sort of conflict each other. Any help clearing it out would be greatly appreciated.","In my daily morning walk there is a 20% chance I drop my pouch. Every day I follow the exact same straight path, to the district square and then back. Assuming that my walk is on a straight segment from A to B and then back from B to A, what is the probability I dropped it from A to B? I know this seems to be a very easy problem, but I am a little confused: Initially, there is equal probability for me to drop my pouch in any of the two directions. So for AB, this probability is 50% of 20%? But for the second part of my walk back home, the probability is conditional. If I have already dropped it in AB, the probability is zero. If I haven’t, the probability is 100% of the total 20%, that is, 20%. Any clue? Edit : There are two answer which have been updated, but they sort of conflict each other. Any help clearing it out would be greatly appreciated.",,['probability']
20,$\frac{1}{2^n}\binom{n}{n}+\frac{1}{2^{n+1}}\binom{n+1}{n}+...+\frac{1}{2^{2n}}\binom{2n}{n}=1$: short proof?,: short proof?,\frac{1}{2^n}\binom{n}{n}+\frac{1}{2^{n+1}}\binom{n+1}{n}+...+\frac{1}{2^{2n}}\binom{2n}{n}=1,"The identity $\frac{1}{2^n}\binom{n}{n}+\frac{1}{2^{n+1}}\binom{n+1}{n}+...+\frac{1}{2^{2n}}\binom{2n}{n}=1$ arises from a question on probability in my textbook. A proof by induction on $n$, which exploits the fact that $\binom{a}{b}+\binom{a}{b+1}=\binom{a+1}{b+1}$, is straightforward but not enlightening. Is it possible to find any very clever approaches? Via a combinatorial or probabilistic interpretation, for instance?","The identity $\frac{1}{2^n}\binom{n}{n}+\frac{1}{2^{n+1}}\binom{n+1}{n}+...+\frac{1}{2^{2n}}\binom{2n}{n}=1$ arises from a question on probability in my textbook. A proof by induction on $n$, which exploits the fact that $\binom{a}{b}+\binom{a}{b+1}=\binom{a+1}{b+1}$, is straightforward but not enlightening. Is it possible to find any very clever approaches? Via a combinatorial or probabilistic interpretation, for instance?",,"['probability', 'combinatorics', 'summation', 'combinations']"
21,Calculating probability of winning best-of-7-games tournament. Why is my method wrong?,Calculating probability of winning best-of-7-games tournament. Why is my method wrong?,,"The question is as follows: A and B participate in a tournament of ""best of 7 games"". It is equally likely that either A wins the game or B wins the game, or the game ends in a draw. What is the probability that A wins the tournament? So I tried an approach like this. I made a table like: $$ \begin{array}{c|c} \text{Ways of Winning} & \text{Probability} \\ \hline \text{W W W W _ _ _} & (1/3)^4 \\ \color{red}{\text{W W W L }} \text{W _ _} & (1/3)^5\times 4 \\ \color{red}{\text{W W W L L }} \text{W _} & (1/3)^6\times \dfrac{5!}{3!\,2!} \\ \color{red}{\text{W W W L L L }} \text{W} & (1/3)^7\times \dfrac{6!}{3!\,3!} \\ \color{red}{\text{W W W D }} \text{W _ _} & (1/3)^5\times 4 \\ \color{red}{\text{W W W D L }} \text{W _} & (1/3)^6\times \dfrac{5!}{3!} \\ \color{red}{\text{W W W D L L }} \text{W} & (1/3)^7\times \dfrac{6!}{3!\,2!} \\ \vdots & \vdots \\ \color{red}{\text{W D D D D L }} \text{W} & (1/3)^7\times \dfrac{6!}{4!} \\ \color{red}{\text{W D D D D D }} \text{W} & (1/3)^7\times 6 \\ \color{red}{\text{W D D D D D D}} & (1/3)^7\times 7 \\ \end{array} $$ Here the W represents a win for A , L represents a loss while D represents a draw. If a character is in red, it means that it can be exchanged (rearranged) with the other characters in red. If in black, it's position is fixed. Underscores represent any value can be taken at that point. The procedure I followed is that, for zero draws, I kept adding an extra red L before the last W and still letting A win the tournament. Then I added a red D, then kept adding a red L, again letting A win the tournament. I wrote all such arrangements in this fashion and wrote the corresponding probabilities and added them together. There were 16 such rows for me. The answer i got was $651/3^7$ or $217/729$, but the answer given is $299/729$. They calculated it by subtracting the probability of a draw from one and then dividing it by two. I understand why they did it, what I don't understand is why our answers don't match! So, what is wrong with my approach? Am i missing some cases? Or is totally scrap?","The question is as follows: A and B participate in a tournament of ""best of 7 games"". It is equally likely that either A wins the game or B wins the game, or the game ends in a draw. What is the probability that A wins the tournament? So I tried an approach like this. I made a table like: $$ \begin{array}{c|c} \text{Ways of Winning} & \text{Probability} \\ \hline \text{W W W W _ _ _} & (1/3)^4 \\ \color{red}{\text{W W W L }} \text{W _ _} & (1/3)^5\times 4 \\ \color{red}{\text{W W W L L }} \text{W _} & (1/3)^6\times \dfrac{5!}{3!\,2!} \\ \color{red}{\text{W W W L L L }} \text{W} & (1/3)^7\times \dfrac{6!}{3!\,3!} \\ \color{red}{\text{W W W D }} \text{W _ _} & (1/3)^5\times 4 \\ \color{red}{\text{W W W D L }} \text{W _} & (1/3)^6\times \dfrac{5!}{3!} \\ \color{red}{\text{W W W D L L }} \text{W} & (1/3)^7\times \dfrac{6!}{3!\,2!} \\ \vdots & \vdots \\ \color{red}{\text{W D D D D L }} \text{W} & (1/3)^7\times \dfrac{6!}{4!} \\ \color{red}{\text{W D D D D D }} \text{W} & (1/3)^7\times 6 \\ \color{red}{\text{W D D D D D D}} & (1/3)^7\times 7 \\ \end{array} $$ Here the W represents a win for A , L represents a loss while D represents a draw. If a character is in red, it means that it can be exchanged (rearranged) with the other characters in red. If in black, it's position is fixed. Underscores represent any value can be taken at that point. The procedure I followed is that, for zero draws, I kept adding an extra red L before the last W and still letting A win the tournament. Then I added a red D, then kept adding a red L, again letting A win the tournament. I wrote all such arrangements in this fashion and wrote the corresponding probabilities and added them together. There were 16 such rows for me. The answer i got was $651/3^7$ or $217/729$, but the answer given is $299/729$. They calculated it by subtracting the probability of a draw from one and then dividing it by two. I understand why they did it, what I don't understand is why our answers don't match! So, what is wrong with my approach? Am i missing some cases? Or is totally scrap?",,['probability']
22,Why is it that $E(xy) = E(x)E(y)$ if $x$ and $y$ are uncorrelated random variables?,Why is it that  if  and  are uncorrelated random variables?,E(xy) = E(x)E(y) x y,"Also, why does $E(xy) = E(x)E(y)$ not hold if $x$ and $y$ are correlated? Perhaps at a more basic, intuitive level, what's the difference between $E(xy)$ and $E(x)E(y)$?","Also, why does $E(xy) = E(x)E(y)$ not hold if $x$ and $y$ are correlated? Perhaps at a more basic, intuitive level, what's the difference between $E(xy)$ and $E(x)E(y)$?",,['probability']
23,Name Drawing Puzzle,Name Drawing Puzzle,,"There is a party with 20 people, and everyone writes their name down   on a piece of paper and puts it into a bag. The bag is mixed up, and   each person draws one piece of paper. If you draw the name of someone   else, you are considered to be in his ""group"". What is the expected   number of groups after everyone draws? So basically if we have a loop where each person draws someone else's name, and the last person draws the first person in that list's name, we have a group. Not quite sure how to approach this problem. Thanks for any help.","There is a party with 20 people, and everyone writes their name down   on a piece of paper and puts it into a bag. The bag is mixed up, and   each person draws one piece of paper. If you draw the name of someone   else, you are considered to be in his ""group"". What is the expected   number of groups after everyone draws? So basically if we have a loop where each person draws someone else's name, and the last person draws the first person in that list's name, we have a group. Not quite sure how to approach this problem. Thanks for any help.",,"['probability', 'puzzle', 'harmonic-numbers']"
24,Is the probability $\frac12$?,Is the probability ?,\frac12,"I have $n$ players in total. Note that $n$ is even. We want to pick $\frac n2$ players uniformly at random. We have access to only one unbiased coin. We want to make this bisection in minimum expected number of coin tosses. What should I do? My approach: I will keep tossing-if it is H I will add the player to team A else to team B. If there are already $\frac n2$ players in any team, I stop tossing and put the rest in other team. Leaving aside the problem of proving why this will give minimum number of tosses, I am not sure why the players have equal probability of getting to team A or B. It is clear for the first $\frac n2$ players but after that it gets a little messy. Please don't say that it is symmetric so probability is half trivially.","I have $n$ players in total. Note that $n$ is even. We want to pick $\frac n2$ players uniformly at random. We have access to only one unbiased coin. We want to make this bisection in minimum expected number of coin tosses. What should I do? My approach: I will keep tossing-if it is H I will add the player to team A else to team B. If there are already $\frac n2$ players in any team, I stop tossing and put the rest in other team. Leaving aside the problem of proving why this will give minimum number of tosses, I am not sure why the players have equal probability of getting to team A or B. It is clear for the first $\frac n2$ players but after that it gets a little messy. Please don't say that it is symmetric so probability is half trivially.",,['probability']
25,Roll a dice infinite times BUT pay $1 to play - strategy?,Roll a dice infinite times BUT pay $1 to play - strategy?,,"I am stuck with a question related to the optimal strategy of rolling a dice. Its an extension of the problem ""Roll a dice and take either the amount on the dice or re-roll (a maximum of twice)"". Heres the link to the basic version and solution: The expected payoff of a dice game So the idea is you roll a 6 sided dice, and you can EITHER take the money shown on the dice, OR pay \$$1$ and play again . You can now re-roll as many times as you like. What is the optimal strategy and whats the fair value of the game? I tried to use the same approach by working backwards as the basic case above, but after a few iterations, it seems to be never ending. This doesn't make sense intuitively, because after 6 rolls, you have spent \$$6$ to play and can only win a maximum of \$$6$ on your next roll, so it would never be optimal to roll more than 6 times!","I am stuck with a question related to the optimal strategy of rolling a dice. Its an extension of the problem ""Roll a dice and take either the amount on the dice or re-roll (a maximum of twice)"". Heres the link to the basic version and solution: The expected payoff of a dice game So the idea is you roll a 6 sided dice, and you can EITHER take the money shown on the dice, OR pay \$$1$ and play again . You can now re-roll as many times as you like. What is the optimal strategy and whats the fair value of the game? I tried to use the same approach by working backwards as the basic case above, but after a few iterations, it seems to be never ending. This doesn't make sense intuitively, because after 6 rolls, you have spent \$$6$ to play and can only win a maximum of \$$6$ on your next roll, so it would never be optimal to roll more than 6 times!",,['probability']
26,Expected Value Proof - Law of Total Expectation.,Expected Value Proof - Law of Total Expectation.,,"Given that X and Y are random variables show that: $$E[E[X \mid Y]] = E[X]$$ I was thinking that I could use the definition of expected value (the summation one) to solve this, but when I tried I hit a wall. Thanks.","Given that X and Y are random variables show that: $$E[E[X \mid Y]] = E[X]$$ I was thinking that I could use the definition of expected value (the summation one) to solve this, but when I tried I hit a wall. Thanks.",,"['probability', 'statistics', 'conditional-expectation']"
27,What does $E[XY]$ mean?,What does  mean?,E[XY],"Let's say I have two random variables, $X$ and $Y$. $X$ is the value of a fair die, $Y$ is the result of a coin flip, with heads being 1 and tails being 0. $E[X] = \sum_{k=1}^{6}{\frac{k}{6}} = \frac{7}{2}$, and $E[Y] = \frac{1}{2}$. Thus $E[X]E[Y] = \frac{7}{4}$. I'm aware that the expectation of $XY$ is not multiplicative, i.e.: $E[X]E[Y]$ is not necessarily equal to $E[XY]$. But I'm confused about what $E[XY]$ means in the first place. That is, is $E[XY]$ each possible value of the two events combined, multiplied by the probability that the two events occur? That is, is $E[XY] = \frac{1}{2}(1)\sum_{k=1}^{6}{\frac{k}{6}} + \frac{1}{2}(0)\sum_{k=1}^{6}{\frac{k}{6}} = \frac{7}{4}$? If not, what is it? Edit 1: Typo Due to a typo the last equation $E[XY] = \frac{1}{2}(1)\sum_{k=1}^{6}{\frac{k}{6}} + \frac{1}{2}(0)\sum_{k=1}^{6}{\frac{k}{6}}$ was evaluated as $\frac{7}{2}$, when I believe it should be $\frac{7}{4}$. I'd appreciate it if responders told me whether this is a correct value for $E[XY]$. Edit 2: Clarification I'm not that concerned with how to calculate $E[XY]$ in the quickest way possible, but how to interpret what $E[XY]$ means. $E[X]E[Y] = E[XY]$ for independent events doesn't concern me as much as why that is the case, and how to manually evaluate $E[XY]$ in order to prove that indeed $E[XY] = E[X]E[Y]$.","Let's say I have two random variables, $X$ and $Y$. $X$ is the value of a fair die, $Y$ is the result of a coin flip, with heads being 1 and tails being 0. $E[X] = \sum_{k=1}^{6}{\frac{k}{6}} = \frac{7}{2}$, and $E[Y] = \frac{1}{2}$. Thus $E[X]E[Y] = \frac{7}{4}$. I'm aware that the expectation of $XY$ is not multiplicative, i.e.: $E[X]E[Y]$ is not necessarily equal to $E[XY]$. But I'm confused about what $E[XY]$ means in the first place. That is, is $E[XY]$ each possible value of the two events combined, multiplied by the probability that the two events occur? That is, is $E[XY] = \frac{1}{2}(1)\sum_{k=1}^{6}{\frac{k}{6}} + \frac{1}{2}(0)\sum_{k=1}^{6}{\frac{k}{6}} = \frac{7}{4}$? If not, what is it? Edit 1: Typo Due to a typo the last equation $E[XY] = \frac{1}{2}(1)\sum_{k=1}^{6}{\frac{k}{6}} + \frac{1}{2}(0)\sum_{k=1}^{6}{\frac{k}{6}}$ was evaluated as $\frac{7}{2}$, when I believe it should be $\frac{7}{4}$. I'd appreciate it if responders told me whether this is a correct value for $E[XY]$. Edit 2: Clarification I'm not that concerned with how to calculate $E[XY]$ in the quickest way possible, but how to interpret what $E[XY]$ means. $E[X]E[Y] = E[XY]$ for independent events doesn't concern me as much as why that is the case, and how to manually evaluate $E[XY]$ in order to prove that indeed $E[XY] = E[X]E[Y]$.",,"['probability', 'combinatorics', 'statistics', 'probability-theory']"
28,Jensen's Inequality (with probability one),Jensen's Inequality (with probability one),,"In the following theorem, I have a problem about the second part. That is showing if $f$ is strictly convex then $X=EX$ with probability $1$. While I can see this must be true, I don't know how to show it holds with probability $1$. I am specially interested in the case where $X$ is s continuous random variable in reals. Thanks a lot in advance for explaining.","In the following theorem, I have a problem about the second part. That is showing if $f$ is strictly convex then $X=EX$ with probability $1$. While I can see this must be true, I don't know how to show it holds with probability $1$. I am specially interested in the case where $X$ is s continuous random variable in reals. Thanks a lot in advance for explaining.",,"['probability', 'analysis', 'probability-theory', 'random-variables']"
29,Self-study on probability.,Self-study on probability.,,"What book do you recommend for self-study of probability theory? I have a rather significant gap in that area (in lame terms sometimes I feel I don't get it) and need to try (strugle more likely) to rectify this. What would you recommend for someone like me, who has problem/gap in this area, would be a self-study and would not be a ""heavy/scary"" book or tutorial? I assume there are such books available?","What book do you recommend for self-study of probability theory? I have a rather significant gap in that area (in lame terms sometimes I feel I don't get it) and need to try (strugle more likely) to rectify this. What would you recommend for someone like me, who has problem/gap in this area, would be a self-study and would not be a ""heavy/scary"" book or tutorial? I assume there are such books available?",,"['probability', 'probability-theory', 'self-learning']"
30,Expected difference between largest and second largest of i.i.d. random variables,Expected difference between largest and second largest of i.i.d. random variables,,"Let $(X_i)_{i\geq 0}$ be i.i.d. nonnegative random variables with continuous density function $f$ . Let \begin{align} \mu_n = \mathbb{E}[X_{(n)}-X_{(n-1)}] \end{align} be the expected difference between the largest and second largest of the first $n$ random variables. Question : Can we show that $\mu_n$ is decreasing in $n$ ? We can assume the density $f$ to be decreasing for $x>0$ and the mean of the order statistics to be well-defined; in particular, assume $\mathbb{E}[X_i]<\infty$ . Edit: My intuition tells me that $\mu_n$ is generally decreasing in $n$ , but I have been unable to prove it. I am more interested in simple conditions under which the result is true, rather than a specific counterexample where it is not.","Let be i.i.d. nonnegative random variables with continuous density function . Let be the expected difference between the largest and second largest of the first random variables. Question : Can we show that is decreasing in ? We can assume the density to be decreasing for and the mean of the order statistics to be well-defined; in particular, assume . Edit: My intuition tells me that is generally decreasing in , but I have been unable to prove it. I am more interested in simple conditions under which the result is true, rather than a specific counterexample where it is not.","(X_i)_{i\geq 0} f \begin{align}
\mu_n = \mathbb{E}[X_{(n)}-X_{(n-1)}]
\end{align} n \mu_n n f x>0 \mathbb{E}[X_i]<\infty \mu_n n","['probability', 'probability-theory', 'stochastic-processes', 'order-statistics']"
31,Probability Q on rolling two 8-sided dice,Probability Q on rolling two 8-sided dice,,"Let's say I roll two 8-sided dice. I win if the sums '7' and '11' show up before we see the sum '9' TWICE. What is my probability of winning? So this is my answer and please correct me if I am wrong: Prob of getting either 7 or 9 —> 6/64 + 6/64 = 12/64 —> 18.75% Prob of getting 9 twice —> 8/64 x 8/64 = 1/64 —> 1.6% But now to find the probability of winning, would it be 18.75 - 1.6 = 17.15% ? Am I right or wrong? Thanks! EDIT From the answers provided below, we have three different results: 84% 49% 60% Which one would be the correct answer?","Let's say I roll two 8-sided dice. I win if the sums '7' and '11' show up before we see the sum '9' TWICE. What is my probability of winning? So this is my answer and please correct me if I am wrong: Prob of getting either 7 or 9 —> 6/64 + 6/64 = 12/64 —> 18.75% Prob of getting 9 twice —> 8/64 x 8/64 = 1/64 —> 1.6% But now to find the probability of winning, would it be 18.75 - 1.6 = 17.15% ? Am I right or wrong? Thanks! EDIT From the answers provided below, we have three different results: 84% 49% 60% Which one would be the correct answer?",,"['probability', 'dice']"
32,Cube and unit cubes,Cube and unit cubes,,"Consider a $3\times 3\times 3$ cube consisting of smaller $1\times 1\times 1$ unit cubes. The big cube is painted black on the outside. Suppose we disassemble the cube and pick a random unit cube, look at only one face and see it is black, without looking at the other faces. What is the probability the unit cube we picked is one of the 8 corner cubes? This one seems simple to me but I am not sure I am right: The big cube consists of 27 unit cubes of which one only, the middle one, does not have any painted face. All the others (26) have at least one face painted and 8 have 3 faces painted. Thus the requested probability is $\frac{8}{26}$ —is this so?","Consider a cube consisting of smaller unit cubes. The big cube is painted black on the outside. Suppose we disassemble the cube and pick a random unit cube, look at only one face and see it is black, without looking at the other faces. What is the probability the unit cube we picked is one of the 8 corner cubes? This one seems simple to me but I am not sure I am right: The big cube consists of 27 unit cubes of which one only, the middle one, does not have any painted face. All the others (26) have at least one face painted and 8 have 3 faces painted. Thus the requested probability is —is this so?",3\times 3\times 3 1\times 1\times 1 \frac{8}{26},['probability']
33,"(Combinatorial?) Proof of the identity $\sum_{k=1}^n \frac {(-1)^k}{k\,(k+1)}\binom nk = \frac 12 + \frac 13 + \dots + \frac 1{n+1}$?",(Combinatorial?) Proof of the identity ?,"\sum_{k=1}^n \frac {(-1)^k}{k\,(k+1)}\binom nk = \frac 12 + \frac 13 + \dots + \frac 1{n+1}","Recently I've come across an interesting identity: $$ \frac 1{1\cdot 2}\binom n1 - \frac 1{2\cdot 3}\binom n2 + \frac 1{3\cdot 4}\binom n3 - \dots + \frac {(-1)^n}{n\cdot (n+1)}\binom nn = \frac 12 + \frac 13 + \dots + \frac 1{n+1}. $$ Does anyone have an idea how to prove this? PS. It'd be of special interest if someone could provide a combinatorial approach to this problem, although I'm not sure if that'd make sense since this is an identity for non-integer. Edit: Perhaps my question was worded in a way that seems trivial since there's a vote to close this question. I should have mentioned that I can prove it by expanding $\frac 1{k(k-1)}$ and do some further calculation. What I want is a clever way to interpret it, e.g. using combinatorics or some kind of generating function or integration.","Recently I've come across an interesting identity: Does anyone have an idea how to prove this? PS. It'd be of special interest if someone could provide a combinatorial approach to this problem, although I'm not sure if that'd make sense since this is an identity for non-integer. Edit: Perhaps my question was worded in a way that seems trivial since there's a vote to close this question. I should have mentioned that I can prove it by expanding and do some further calculation. What I want is a clever way to interpret it, e.g. using combinatorics or some kind of generating function or integration.","
\frac 1{1\cdot 2}\binom n1 - \frac 1{2\cdot 3}\binom n2 + \frac 1{3\cdot 4}\binom n3 - \dots + \frac {(-1)^n}{n\cdot (n+1)}\binom nn =
\frac 12 + \frac 13 + \dots + \frac 1{n+1}.
 \frac 1{k(k-1)}","['probability', 'combinatorics', 'number-theory', 'summation', 'harmonic-numbers']"
34,One sided Chebyshev's inequality,One sided Chebyshev's inequality,,"How to prove the one-sided Chebyshev's inequality which states that if $X$ has mean $0$ and variance $\sigma^2$ , then for any $a > 0$ $$P(X \geq a) \leq \frac{\sigma^2}{\sigma^2+a^2} \quad?$$ Attempted solution: I know the Chebyshev's inequality which States that $$P(|X-\mu| \geq a) \leq \frac{\mathrm{Var}(X)}{a^2}~.$$ If I first argue that for any $b > 0$ $$P(X \geq a) \leq P{[(X+b)^2 \geq (a+b)^2]} \\ \begin{align} \implies &P(X\geq a) \leq \frac{E(X+b)^2}{(a+b)^2} \\ &P(X \geq a) \leq \frac{E(X^2)+2E(X)b+b^2}{(a+b)^2} \\ &P(X \geq a) \leq \frac{\sigma^2+ b^2}{(a+b)^2} \end{align}$$ I got the correct answer.","How to prove the one-sided Chebyshev's inequality which states that if has mean and variance , then for any Attempted solution: I know the Chebyshev's inequality which States that If I first argue that for any I got the correct answer.","X 0 \sigma^2 a > 0 P(X \geq a) \leq \frac{\sigma^2}{\sigma^2+a^2} \quad? P(|X-\mu| \geq a) \leq \frac{\mathrm{Var}(X)}{a^2}~. b > 0 P(X \geq a) \leq P{[(X+b)^2 \geq (a+b)^2]} \\
\begin{align}
\implies &P(X\geq a) \leq \frac{E(X+b)^2}{(a+b)^2} \\
&P(X \geq a) \leq \frac{E(X^2)+2E(X)b+b^2}{(a+b)^2} \\
&P(X \geq a) \leq \frac{\sigma^2+ b^2}{(a+b)^2}
\end{align}","['probability', 'inequality']"
35,Joint PDF of two random variables in a triangle,Joint PDF of two random variables in a triangle,,"Let the random variables $X$ and $Y$ have a joint PDF which is uniform   over the triangle with vertices at $(0, 0), (0, 1 )$ and $(1, 0)$. Find the joint PDF of $X$ and $Y$. So apparently the answer is $2$. And it's related with the area of this triangle that easily we can see is $1/2$. How do we get that answer? I guess I don't understand the meaning of joint PDF. Could someone explain that to me too?","Let the random variables $X$ and $Y$ have a joint PDF which is uniform   over the triangle with vertices at $(0, 0), (0, 1 )$ and $(1, 0)$. Find the joint PDF of $X$ and $Y$. So apparently the answer is $2$. And it's related with the area of this triangle that easily we can see is $1/2$. How do we get that answer? I guess I don't understand the meaning of joint PDF. Could someone explain that to me too?",,"['probability', 'random-variables', 'triangles']"
36,CDF of absolute value of difference in random variables,CDF of absolute value of difference in random variables,,"Let $X$ and $Y$ be independent random variables, uniformly distributed in the interval $[0,1]$. Find the CDF and the PDF of $|X - Y|$? Attempt Let $Z = |X - Y|$, so for $z \geq 0$, the CDF $F_{Z}(z) = \mathbf{P}(Z \leq z) = \mathbf{P}(|X - Y| \leq z) = \mathbf{P}(-z \leq X - Y \leq z)$, which is where the algebra becomes confusing. Since they are independent, the joint pdf of $X$ & $Y$ is simply 1, as long as $(X,Y)$ belong to the unit square. The solution suggests a plot the event of interest as a subset of the unit square and find its area. Any hints?","Let $X$ and $Y$ be independent random variables, uniformly distributed in the interval $[0,1]$. Find the CDF and the PDF of $|X - Y|$? Attempt Let $Z = |X - Y|$, so for $z \geq 0$, the CDF $F_{Z}(z) = \mathbf{P}(Z \leq z) = \mathbf{P}(|X - Y| \leq z) = \mathbf{P}(-z \leq X - Y \leq z)$, which is where the algebra becomes confusing. Since they are independent, the joint pdf of $X$ & $Y$ is simply 1, as long as $(X,Y)$ belong to the unit square. The solution suggests a plot the event of interest as a subset of the unit square and find its area. Any hints?",,['probability']
37,Intuitive/heuristic explanation of Polya's urn,Intuitive/heuristic explanation of Polya's urn,,"Suppose we have an urn with one red ball and one blue ball. At each step, we take out a single ball from the urn and note its color; we then put that ball back into the urn, along with an additional ball of the same color. This is Polya's urn, and one of the basic facts about it is the following: the number of red balls after $n$ draws is uniform over $\{1, \ldots, n+1\}$. This is very surprising to me. While its not hard to show this by direct calculation, I wonder if anyone can give an intuitive/heuristic explanation why this distribution should be uniform. There are quite a few questions on Polya's urn on math.stackexchange, but none of them seem to be asking exactly this. The closest is this question , where there are some nice explanations for why, assuming as above that we start with one red and one blue ball, the probability of drawing a red ball at the $k$'th step is $1/2$ for every $k$ (it follows by symmetry).","Suppose we have an urn with one red ball and one blue ball. At each step, we take out a single ball from the urn and note its color; we then put that ball back into the urn, along with an additional ball of the same color. This is Polya's urn, and one of the basic facts about it is the following: the number of red balls after $n$ draws is uniform over $\{1, \ldots, n+1\}$. This is very surprising to me. While its not hard to show this by direct calculation, I wonder if anyone can give an intuitive/heuristic explanation why this distribution should be uniform. There are quite a few questions on Polya's urn on math.stackexchange, but none of them seem to be asking exactly this. The closest is this question , where there are some nice explanations for why, assuming as above that we start with one red and one blue ball, the probability of drawing a red ball at the $k$'th step is $1/2$ for every $k$ (it follows by symmetry).",,"['probability', 'recreational-mathematics', 'polya-urn-model']"
38,"At time n, randomly choose a natural number ≤n. How long is it until a single number is chosen three times?","At time n, randomly choose a natural number ≤n. How long is it until a single number is chosen three times?",,"To clarify, the number ≤n is chosen uniformly at random at each step, and n chooses from the natural numbers beginning with 1. I wish to determine the expected value of $n$ at which a natural number is chosen three times (for the first time). (I would also ideally like to know how to calculate E(a number being chosen $y$ times)) I calculated $\Pr(\text{hitting a number thrice at } n=x)$ for some low values, but it rapidly becomes a lot to do by hand. \begin{align*} \Pr(n=1) &= \Pr(n=2) = 0 \\ \Pr(n=3) &= 1/6 \\ \Pr(n=4) &= 1/6 \\ \Pr(n=5) &= 19/120 \end{align*} The inspiration for this question refers to the card game Hearthstone and a particular card interaction. See http://hearthstone.gamepedia.com/Grim_Patron http://hearthstone.gamepedia.com/Bouncing_Blade The title of this question and the phrasing used throughout is not how I conceived the question, but a reformulation that mjqxxxx posted.","To clarify, the number ≤n is chosen uniformly at random at each step, and n chooses from the natural numbers beginning with 1. I wish to determine the expected value of $n$ at which a natural number is chosen three times (for the first time). (I would also ideally like to know how to calculate E(a number being chosen $y$ times)) I calculated $\Pr(\text{hitting a number thrice at } n=x)$ for some low values, but it rapidly becomes a lot to do by hand. \begin{align*} \Pr(n=1) &= \Pr(n=2) = 0 \\ \Pr(n=3) &= 1/6 \\ \Pr(n=4) &= 1/6 \\ \Pr(n=5) &= 19/120 \end{align*} The inspiration for this question refers to the card game Hearthstone and a particular card interaction. See http://hearthstone.gamepedia.com/Grim_Patron http://hearthstone.gamepedia.com/Bouncing_Blade The title of this question and the phrasing used throughout is not how I conceived the question, but a reformulation that mjqxxxx posted.",,"['probability', 'probability-theory', 'card-games']"
39,10 little dwarves,10 little dwarves,,"A dwarf-killing giant lines up 10 dwarfs from shortest to tallest. Each dwarf can see all the shortest dwarfs in front of him, but cannot see the dwarfs behind himself. The giant randomly puts a white or black hat on each dwarf. No dwarf can see their own hat. The giant tells all the dwarfs that he will ask each dwarf, starting with the tallest, for the color of his hat. If the dwarf answers incorrectly, the giant will kill the dwarf. Each dwarf can hear the previous answers, but cannot hear when a dwarf is killed. The dwarves are given an opportunity to collude before the hats are distributed. What strategy should be used to kill the fewest dwarfs, and what is the minimum number of dwarfs that can be saved with this strategy? My approach:  1st guy counts which color is max, says it, all others copy his ans. This way, we save at least 5, but I think we can optimize this, just can't figure out how....","A dwarf-killing giant lines up 10 dwarfs from shortest to tallest. Each dwarf can see all the shortest dwarfs in front of him, but cannot see the dwarfs behind himself. The giant randomly puts a white or black hat on each dwarf. No dwarf can see their own hat. The giant tells all the dwarfs that he will ask each dwarf, starting with the tallest, for the color of his hat. If the dwarf answers incorrectly, the giant will kill the dwarf. Each dwarf can hear the previous answers, but cannot hear when a dwarf is killed. The dwarves are given an opportunity to collude before the hats are distributed. What strategy should be used to kill the fewest dwarfs, and what is the minimum number of dwarfs that can be saved with this strategy? My approach:  1st guy counts which color is max, says it, all others copy his ans. This way, we save at least 5, but I think we can optimize this, just can't figure out how....",,"['probability', 'puzzle']"
40,Prove the Probability of Two Events,Prove the Probability of Two Events,,"I'm taking my first course in Probability and one of my homework problems is to prove that for any two sets:  $$P(A \cup B) = P(A) + P(B) - P(A \cap B) $$ Note that the function $P$ is the probability of an event happening.  From the third axiom, we are given that for any two disjoint sets, that is $ A \cap B = \emptyset$: $$P(A \cup B) = P(A) + P(B)$$ My thought process follows from this third axiom, but I run into a problem near the end: Since $A$ and $B$ are disjoint sets, $P(A)=P(A-B)$ and $P(B)=P(B-A)$, so $$P(A \cup B) = P(A) + P(B)=P(A-B)+P(B-A)$$ From this, it appears that we are essentially taking the symmetric difference of A and B.  This, to me, seems to be equivalent to: $$P(A-B)+P(B-A)=P(A)+P(B)-P(A \cap B)$$ Hence, by my logic: $$P(A \cup B) = P(A)+P(B)-P(A \cap B)$$ Which, in essence, doesn't care whether two sets are disjoint or not as we are subtracting the intersection of them.  If the sets are disjoint, then the intersection is merely null.  If they intersect, then we are removing the ""extra pieces"". I feel like this is inadequate proof despite my ability to convince myself that it is true..  Where, if anywhere, did I go wrong? Thanks!","I'm taking my first course in Probability and one of my homework problems is to prove that for any two sets:  $$P(A \cup B) = P(A) + P(B) - P(A \cap B) $$ Note that the function $P$ is the probability of an event happening.  From the third axiom, we are given that for any two disjoint sets, that is $ A \cap B = \emptyset$: $$P(A \cup B) = P(A) + P(B)$$ My thought process follows from this third axiom, but I run into a problem near the end: Since $A$ and $B$ are disjoint sets, $P(A)=P(A-B)$ and $P(B)=P(B-A)$, so $$P(A \cup B) = P(A) + P(B)=P(A-B)+P(B-A)$$ From this, it appears that we are essentially taking the symmetric difference of A and B.  This, to me, seems to be equivalent to: $$P(A-B)+P(B-A)=P(A)+P(B)-P(A \cap B)$$ Hence, by my logic: $$P(A \cup B) = P(A)+P(B)-P(A \cap B)$$ Which, in essence, doesn't care whether two sets are disjoint or not as we are subtracting the intersection of them.  If the sets are disjoint, then the intersection is merely null.  If they intersect, then we are removing the ""extra pieces"". I feel like this is inadequate proof despite my ability to convince myself that it is true..  Where, if anywhere, did I go wrong? Thanks!",,"['probability', 'statistics', 'probability-theory']"
41,Can someone explain what plim is?,Can someone explain what plim is?,,"In my Introductory Econometrics class we discussed a concept of ""plim"" or ""probability limit. I'm not sure what this means though and my professor doesn't explain it well at all. Can someone tell me what this is if you have heard of it? It seems to be used in the same way we would use a regular limit but I just don't understand it. Thanks!!","In my Introductory Econometrics class we discussed a concept of ""plim"" or ""probability limit. I'm not sure what this means though and my professor doesn't explain it well at all. Can someone tell me what this is if you have heard of it? It seems to be used in the same way we would use a regular limit but I just don't understand it. Thanks!!",,"['probability', 'probability-theory', 'regression', 'economics']"
42,Probability distribution and their related distributions,Probability distribution and their related distributions,,"I am taking a probability course right now and have encountered a lot of interesting distributions and their related distributions. For example, if we have two independent Poisson distribution random variables $X_1,X_2$ with parameters $\lambda_1,\lambda_2$ respectively, and $Y = X_1+X_2$, then $X_1\mid Y= y $ is a binomial distribution random variable with parameter $\left(y,\dfrac{\lambda_1}{\lambda_1+\lambda_2} \right)$. I am wondering if there is a nice summary or something like that about all the distributions and their related distributions.","I am taking a probability course right now and have encountered a lot of interesting distributions and their related distributions. For example, if we have two independent Poisson distribution random variables $X_1,X_2$ with parameters $\lambda_1,\lambda_2$ respectively, and $Y = X_1+X_2$, then $X_1\mid Y= y $ is a binomial distribution random variable with parameter $\left(y,\dfrac{\lambda_1}{\lambda_1+\lambda_2} \right)$. I am wondering if there is a nice summary or something like that about all the distributions and their related distributions.",,"['probability', 'probability-distributions']"
43,Why does this expected value simplify as shown?,Why does this expected value simplify as shown?,,"I was reading about the german tank problem and they say that in a sample of size $k$, from a population of integers from $1,\ldots,N$ the probability that the sample maximum equals $m$ is: $$\frac{\binom{m-1}{k-1}}{\binom{N}{k}}$$ This make sense. But then they take expected value of the sample maximum and claim: $$\mu = \sum_{m=k}^N m \frac{\binom{m-1}{k-1}}{\binom{N}{k}} = \frac{k(N+1)}{k+1}$$ And I don't quite see how to simplify that summation. I can pull out the denominator and a $(k-1)!$ term out and get: $$\mu = \frac{(k-1)!}{\binom{N}{k}} \sum_{m=k}^N m(m-1) \ldots (m-k+1)$$ But I get stuck there...","I was reading about the german tank problem and they say that in a sample of size $k$, from a population of integers from $1,\ldots,N$ the probability that the sample maximum equals $m$ is: $$\frac{\binom{m-1}{k-1}}{\binom{N}{k}}$$ This make sense. But then they take expected value of the sample maximum and claim: $$\mu = \sum_{m=k}^N m \frac{\binom{m-1}{k-1}}{\binom{N}{k}} = \frac{k(N+1)}{k+1}$$ And I don't quite see how to simplify that summation. I can pull out the denominator and a $(k-1)!$ term out and get: $$\mu = \frac{(k-1)!}{\binom{N}{k}} \sum_{m=k}^N m(m-1) \ldots (m-k+1)$$ But I get stuck there...",,"['combinatorics', 'sequences-and-series', 'binomial-coefficients', 'probability']"
44,What is the probability somebody's birthday is the day before mine?,What is the probability somebody's birthday is the day before mine?,,"What is the probability that someone's birthday is the day before my birthday? For example, my birthday is Feb 28, what is the probability that my mom's birthday is Feb 27? Is it just $\frac1{365}$ ? That seems too simple to me but maybe I'm just complicating things unnecessarily.","What is the probability that someone's birthday is the day before my birthday? For example, my birthday is Feb 28, what is the probability that my mom's birthday is Feb 27? Is it just ? That seems too simple to me but maybe I'm just complicating things unnecessarily.",\frac1{365},"['probability', 'statistics']"
45,Underdog leading at least once in an infinite series of games,Underdog leading at least once in an infinite series of games,,"We are observing a tournament where 2 players play a series of games. Exactly one player wins each game. So we can keep count and 5:3 might be the standing after 8 games. The first player is the favorite and will win a game with probability $p > 1 - p$. What is the probability that the underdog will lead the standing at least once at some point in an infinite series of games? Or maybe more important than the specific value: Is it $1$ or not? Somehow I think that it should be $1$, independent of $p$, but I am not sure how much my intuition is worth here. Maybe I can take it to the infinite case with a hint about finite series of $k$ games.","We are observing a tournament where 2 players play a series of games. Exactly one player wins each game. So we can keep count and 5:3 might be the standing after 8 games. The first player is the favorite and will win a game with probability $p > 1 - p$. What is the probability that the underdog will lead the standing at least once at some point in an infinite series of games? Or maybe more important than the specific value: Is it $1$ or not? Somehow I think that it should be $1$, independent of $p$, but I am not sure how much my intuition is worth here. Maybe I can take it to the infinite case with a hint about finite series of $k$ games.",,"['probability', 'sequences-and-series', 'binomial-distribution']"
46,How do you estimate the mean of a Poisson distribution from data?,How do you estimate the mean of a Poisson distribution from data?,,"I have thought of three different approaches for estimating the mean for a Poisson, but I am not sure which one is the correct method to estimate it (the third one is documented separately at the end of the question). For the sake of a concrete example, say that we want to find the Poisson distribution for the number of cars passing by in an hour (in front of our house or whatever). Say that we want to estimate this by standing outside of hours house for $t$ hours and counting the number $n$ of cars we saw. Then we could approximate the mean $\lambda$ as: $$\lambda \approx \frac{n}{t}$$ where $\lambda$ is the mean number of cars that we see per hour. That is first approach (which is the one I believe is the correct one). (note: that I know the first one is easier to do in real life for the specific example, but I am not concerned with that, I am concerned with the mathematical correctness) The second approach is the following approach. Instead imagine that for some reason we are only allowed to record how long it takes us to see 1 single specific car. We record how long it took to see car i as $\tau_i$ (hours). Now we could estimate how many cars we see expect to see in 1 hour by doing: $$ \lambda_i \approx \frac{1}{\tau_i}$$ [note that if $\tau_i < 1$, then we can have an mean value of seeing a car for an hour to be > 1] So now, say that instead we choose to do this on independent days and we took k of these time periods $\tau_i$ and instead we estimated the ""global"" mean by doing a average of the means: $$\lambda = \frac{1}{k}\sum^{k}_{i=1} \lambda_i = \frac{1}{k}\sum^{k}_{i=1} \frac{1}{\tau_i}$$ The second method might seem a little strange, but I was wondering if the two method where actually equivalent somehow, or if the second one was completely wrong and I why. The first one seems to be the correct one but I can't seem to ""prove"" to myself why my intuition says that. [notice that the second method has an interesting property where we can instead of weighting all of them equally, we can do a weighted average to maybe insert the intuitive concept of which $\tau_i$ we trust more for our certain application. A little tangential to my original question, but an interesting thought...] Bounty Section I forgot to add this the first time I asked the question and thought it was important to add it now (since this was the reason my question came up in the first place!). I have a different method for estimating the mean and was wondering if it was correct. Instead of waiting outside for t minutes, what if you did the following. You waited outside and recored how much time it took to see 1 car. Let $\tau_i$ be amount of time you waited to see the ith car. However, notice that after you see a car, you stop your stop-watch and later (maybe on another day), you restart your watch waiting to see the next occurrence of a single car (otherwise, if you you just stop your stop-watch and re-start it immediately, its just the same as the original MLE estimator I was asking about), and you obviously repeat this a but of times. In fact, assume you do this $n$ times (i.e. you see n cars and record how long it took to see each one). Then instead of doing my previous method of $\frac{1}{\tau_i}$, you instead try to do something similar to the first maximum likelihood method by doing the following: $$\lambda \approx \frac{n}{t} = \frac{n}{\sum^{n}_{i=1} \tau_i}$$ where t is the total time it took you to see n cars. But this time these cars were seen by n independent ""samples"". It feels that this method might not be correct but I was not sure. Is there something about necessarily having the total time interval t happen in one consecutive time interval?","I have thought of three different approaches for estimating the mean for a Poisson, but I am not sure which one is the correct method to estimate it (the third one is documented separately at the end of the question). For the sake of a concrete example, say that we want to find the Poisson distribution for the number of cars passing by in an hour (in front of our house or whatever). Say that we want to estimate this by standing outside of hours house for $t$ hours and counting the number $n$ of cars we saw. Then we could approximate the mean $\lambda$ as: $$\lambda \approx \frac{n}{t}$$ where $\lambda$ is the mean number of cars that we see per hour. That is first approach (which is the one I believe is the correct one). (note: that I know the first one is easier to do in real life for the specific example, but I am not concerned with that, I am concerned with the mathematical correctness) The second approach is the following approach. Instead imagine that for some reason we are only allowed to record how long it takes us to see 1 single specific car. We record how long it took to see car i as $\tau_i$ (hours). Now we could estimate how many cars we see expect to see in 1 hour by doing: $$ \lambda_i \approx \frac{1}{\tau_i}$$ [note that if $\tau_i < 1$, then we can have an mean value of seeing a car for an hour to be > 1] So now, say that instead we choose to do this on independent days and we took k of these time periods $\tau_i$ and instead we estimated the ""global"" mean by doing a average of the means: $$\lambda = \frac{1}{k}\sum^{k}_{i=1} \lambda_i = \frac{1}{k}\sum^{k}_{i=1} \frac{1}{\tau_i}$$ The second method might seem a little strange, but I was wondering if the two method where actually equivalent somehow, or if the second one was completely wrong and I why. The first one seems to be the correct one but I can't seem to ""prove"" to myself why my intuition says that. [notice that the second method has an interesting property where we can instead of weighting all of them equally, we can do a weighted average to maybe insert the intuitive concept of which $\tau_i$ we trust more for our certain application. A little tangential to my original question, but an interesting thought...] Bounty Section I forgot to add this the first time I asked the question and thought it was important to add it now (since this was the reason my question came up in the first place!). I have a different method for estimating the mean and was wondering if it was correct. Instead of waiting outside for t minutes, what if you did the following. You waited outside and recored how much time it took to see 1 car. Let $\tau_i$ be amount of time you waited to see the ith car. However, notice that after you see a car, you stop your stop-watch and later (maybe on another day), you restart your watch waiting to see the next occurrence of a single car (otherwise, if you you just stop your stop-watch and re-start it immediately, its just the same as the original MLE estimator I was asking about), and you obviously repeat this a but of times. In fact, assume you do this $n$ times (i.e. you see n cars and record how long it took to see each one). Then instead of doing my previous method of $\frac{1}{\tau_i}$, you instead try to do something similar to the first maximum likelihood method by doing the following: $$\lambda \approx \frac{n}{t} = \frac{n}{\sum^{n}_{i=1} \tau_i}$$ where t is the total time it took you to see n cars. But this time these cars were seen by n independent ""samples"". It feels that this method might not be correct but I was not sure. Is there something about necessarily having the total time interval t happen in one consecutive time interval?",,"['probability', 'statistics', 'probability-distributions']"
47,Concentration inequality for the median,Concentration inequality for the median,,Most concentration inequalities talk about deviation of the sample mean from the population mean. Is there a result bounding the probability of deviation of the sample median from the median of the density function?,Most concentration inequalities talk about deviation of the sample mean from the population mean. Is there a result bounding the probability of deviation of the sample median from the median of the density function?,,"['probability', 'inequality']"
48,Covariance of a Normal with its Square,Covariance of a Normal with its Square,,"Assume there is a random variable distributed normal $X\sim N(\mu,\sigma^2)$. Is there an analytic expression for the covariance of $X$ with its square $X^2$? $$\operatorname{Cov}(X,X^2)$$ I have done a extensive search but I haven't found any result on this. I conjecture that when $\mu=0$, the covariance is zero, but I don't know how to generalize it.","Assume there is a random variable distributed normal $X\sim N(\mu,\sigma^2)$. Is there an analytic expression for the covariance of $X$ with its square $X^2$? $$\operatorname{Cov}(X,X^2)$$ I have done a extensive search but I haven't found any result on this. I conjecture that when $\mu=0$, the covariance is zero, but I don't know how to generalize it.",,"['probability', 'normal-distribution']"
49,Sum of n i.i.d Beta-distributed variables,Sum of n i.i.d Beta-distributed variables,,"Assume that I have $n$ variables that are each $X_i \sim \text{Beta}(\alpha, 1)$ distributed (with the same $\alpha$, i.i.d.). Is there anything known about the distribution of the sum $Y=\sum_i X_i$? I've tried to understand the works of Pham-Gia, but couldn't entirely grasp them. He seems to use some modified generalized Beta $B^*$. An approximation is also fine with me, as long as I can compute some quantiles. I'm mostly interested in quantiles.","Assume that I have $n$ variables that are each $X_i \sim \text{Beta}(\alpha, 1)$ distributed (with the same $\alpha$, i.i.d.). Is there anything known about the distribution of the sum $Y=\sum_i X_i$? I've tried to understand the works of Pham-Gia, but couldn't entirely grasp them. He seems to use some modified generalized Beta $B^*$. An approximation is also fine with me, as long as I can compute some quantiles. I'm mostly interested in quantiles.",,"['probability', 'probability-distributions']"
50,Intuitive idea of Expectation of random variable?,Intuitive idea of Expectation of random variable?,,"I'm studying probability for preparing myself for machine learning. I came across this notion of Expectation of (random variable) or (function of random variable) like $E[X]$ or $E[g(X)]$. Can anybody explain me the intuitive idea of the above notion (taking into consideration it's implications in machine learning, may be)","I'm studying probability for preparing myself for machine learning. I came across this notion of Expectation of (random variable) or (function of random variable) like $E[X]$ or $E[g(X)]$. Can anybody explain me the intuitive idea of the above notion (taking into consideration it's implications in machine learning, may be)",,['probability']
51,"Choosing a number between $1$ and $100$, and randomly guessing it. What is the expected value of the number of guesses?","Choosing a number between  and , and randomly guessing it. What is the expected value of the number of guesses?",1 100,"I was watching Steve Balmer’s interview and he was talking about questions they’d ask from candidates. This is a question he gave, he says- I choose a number between $1$ to $100$ , the other person has to guess the number. If he gets it right the first time he gets $5$ bucks, if he misses the first time steve tells you whether the number is higher or lower( he does this every time you miss), if he gets it right the second time he gets $4$ bucks, third time $3$ , fourth $2$ and so on and if he gets it right in the seventh guess the person has to give a buck to Steve and so on, the value goes decreasing. I am trying to calculate the expected value of this game, how can I solve this, I can’t seem to come up with a way. P.S. I have edited the question with a slight variation, in the previous version steve doesn’t tell you anything after you have guessed the wrong number.","I was watching Steve Balmer’s interview and he was talking about questions they’d ask from candidates. This is a question he gave, he says- I choose a number between to , the other person has to guess the number. If he gets it right the first time he gets bucks, if he misses the first time steve tells you whether the number is higher or lower( he does this every time you miss), if he gets it right the second time he gets bucks, third time , fourth and so on and if he gets it right in the seventh guess the person has to give a buck to Steve and so on, the value goes decreasing. I am trying to calculate the expected value of this game, how can I solve this, I can’t seem to come up with a way. P.S. I have edited the question with a slight variation, in the previous version steve doesn’t tell you anything after you have guessed the wrong number.",1 100 5 4 3 2,"['probability', 'probability-distributions', 'random-variables']"
52,Maximum mean absolute difference of two iid random variables,Maximum mean absolute difference of two iid random variables,,"Suppose $X$ is any random variable taking values in $[0,1]$, and let $Y$ be an iid copy of $X$. What is the maximum possible value of $\mathbb{E}|X-Y|$, over all possible $X$'s? I suspect that $\mathbb{E}|X-Y| \leq 1/2$ for any $X$, but I don't see an easy proof of this. The value $1/2$ is attained if $X$ has distribution Bernoulli(1/2), i.e. $\mathbb{P}(X = 0) = \mathbb{P}(X = 1) = 1/2$. I can prove that $E|X-Y|^2 \leq 1/2$ for any iid variables $X$ and $Y$, as follows: just write $\mathbb{E}|X-Y|^2 = EX^2 + EY^2 - 2E(XY) = 2(EX^2 - (EX)^2) \leq 2(EX - (EX)^2) \leq 1/2$, since the quadratic $s(1-s)$ has maximum value $1/2$. (Here I used the fact that $X$ takes values in $[0,1]$ to bound $EX^2 \leq EX$.) The bound on $\mathbb{E}|X-Y|^2$ is tight, again with $X$ having the Bernoulli(1/2) distribution. (Edit 1) There is an easy way to get a bound of $\frac{1}{\sqrt{2}}$, using Jensen: $\mathbb{E}|X-Y| \leq \sqrt{\mathbb{E}|X-Y|^2} \leq \frac{1}{\sqrt{2}}$, since we showed above that $\mathbb{E}|X-Y|^2 \leq \frac{1}{2}$ always. Edit: Thanks to @Sergei Golovan for a nice solution. I am now wondering if this can be generalized to other moments. Is it true that $\mathbb{E}|X-Y|^\alpha \leq 1/2$ for all $\alpha > 0$? As before, since a Bernoulli variable is 0-1 valued, it achieves the value 1/2. I don't think the given solution for $\alpha = 1$ will generalize. I wonder if there is a way to think about this using characteristic functions / moment generating functions of $|X-Y|$.","Suppose $X$ is any random variable taking values in $[0,1]$, and let $Y$ be an iid copy of $X$. What is the maximum possible value of $\mathbb{E}|X-Y|$, over all possible $X$'s? I suspect that $\mathbb{E}|X-Y| \leq 1/2$ for any $X$, but I don't see an easy proof of this. The value $1/2$ is attained if $X$ has distribution Bernoulli(1/2), i.e. $\mathbb{P}(X = 0) = \mathbb{P}(X = 1) = 1/2$. I can prove that $E|X-Y|^2 \leq 1/2$ for any iid variables $X$ and $Y$, as follows: just write $\mathbb{E}|X-Y|^2 = EX^2 + EY^2 - 2E(XY) = 2(EX^2 - (EX)^2) \leq 2(EX - (EX)^2) \leq 1/2$, since the quadratic $s(1-s)$ has maximum value $1/2$. (Here I used the fact that $X$ takes values in $[0,1]$ to bound $EX^2 \leq EX$.) The bound on $\mathbb{E}|X-Y|^2$ is tight, again with $X$ having the Bernoulli(1/2) distribution. (Edit 1) There is an easy way to get a bound of $\frac{1}{\sqrt{2}}$, using Jensen: $\mathbb{E}|X-Y| \leq \sqrt{\mathbb{E}|X-Y|^2} \leq \frac{1}{\sqrt{2}}$, since we showed above that $\mathbb{E}|X-Y|^2 \leq \frac{1}{2}$ always. Edit: Thanks to @Sergei Golovan for a nice solution. I am now wondering if this can be generalized to other moments. Is it true that $\mathbb{E}|X-Y|^\alpha \leq 1/2$ for all $\alpha > 0$? As before, since a Bernoulli variable is 0-1 valued, it achieves the value 1/2. I don't think the given solution for $\alpha = 1$ will generalize. I wonder if there is a way to think about this using characteristic functions / moment generating functions of $|X-Y|$.",,"['probability', 'measure-theory', 'statistics']"
53,How can I write an SDE in Matlab?,How can I write an SDE in Matlab?,,"My professor would like me to solve a system similar to the following:  $$ dx_i=[f_i(x_1,x_2,...x_n)]dt + g_ix_idW_i$$ Where $g_i$ are positive constants that measure the amplitude of the random perturbations, and $W_i$ are random variables normally distributed. Im not sure how I can implement this in Matlab for ode45 to solve.  What is throwing me off is the $dt$ tacked on to $f_i(x_1,...)$ and $dW_i$. Is it as simple as coding function dxdt=money(t,x,a,b,c)  x1=x(1); x2=x(2); x3=x(3);  dx1=x1.*(x2-a)+x3 + 10*rand(); dx2=1-b*x2-x1.^2 + 10*rand; dx3=-x1-c*x3 +10*rand();  dxdt=[dx1;dx2;dx3];  end","My professor would like me to solve a system similar to the following:  $$ dx_i=[f_i(x_1,x_2,...x_n)]dt + g_ix_idW_i$$ Where $g_i$ are positive constants that measure the amplitude of the random perturbations, and $W_i$ are random variables normally distributed. Im not sure how I can implement this in Matlab for ode45 to solve.  What is throwing me off is the $dt$ tacked on to $f_i(x_1,...)$ and $dW_i$. Is it as simple as coding function dxdt=money(t,x,a,b,c)  x1=x(1); x2=x(2); x3=x(3);  dx1=x1.*(x2-a)+x3 + 10*rand(); dx2=1-b*x2-x1.^2 + 10*rand; dx3=-x1-c*x3 +10*rand();  dxdt=[dx1;dx2;dx3];  end",,"['probability', 'ordinary-differential-equations', 'stochastic-calculus', 'matlab', 'stochastic-differential-equations']"
54,Upper/lower bound on covariance two dependent random random variables.,Upper/lower bound on covariance two dependent random random variables.,,"X and Y are two dependent random variables. Marginal pmfs f(X) and f(Y) is given, but joint pmf f(X,Y) is not known. Is it possible to find upper/lower bound on covariance cov(X,Y)?","X and Y are two dependent random variables. Marginal pmfs f(X) and f(Y) is given, but joint pmf f(X,Y) is not known. Is it possible to find upper/lower bound on covariance cov(X,Y)?",,"['probability', 'probability-distributions']"
55,Guessing the probability by results of just 1 experiment,Guessing the probability by results of just 1 experiment,,"I have a probability question that seems easy, but I somehow can't wrap my head around it. Suppose we have a coin. Probability that coin toss will come out heads is some unknown value X. First toss came out as heads. What would you be your best guess about the value X (so, if you guess is y, your task is to minimize $ |X - y| $)? For me it seems like given the result of the first experiment, coin is just a little bit more likely to be loaded in a way that heads come out more often, so optimal guess about the likelihood of heads is 1. But I can't formulate it in a proper way or prove it mathematically. Besides, there is an opinion in other (non-math) online community that probability 0.5 would be more likely. I think there is a flow somewhere in my logic. Can you help me to understand this concept? Thanks. Update: for anyone interested, the question originally emerged during the discussion of Hindsight bias phenomenon . More precisely, the result of Fischhoff and Beyth experiment seems to be logically correct since differences in the results of predictions were caused by the differences in the information given to the groups. Even if the students were explicitly asked not to consider the result of conflicts as the probability factor, the only thing that experiment states is that we can't throw things out from our subconscious perception of the world at will (and that is obvious from the definition of the subconsciousness itself). So the phenomenon of hindsight bias can not be tested through such experiment or any one alike. The experiment should show difference between mathematical probability and empirical probability given the same initial data.","I have a probability question that seems easy, but I somehow can't wrap my head around it. Suppose we have a coin. Probability that coin toss will come out heads is some unknown value X. First toss came out as heads. What would you be your best guess about the value X (so, if you guess is y, your task is to minimize $ |X - y| $)? For me it seems like given the result of the first experiment, coin is just a little bit more likely to be loaded in a way that heads come out more often, so optimal guess about the likelihood of heads is 1. But I can't formulate it in a proper way or prove it mathematically. Besides, there is an opinion in other (non-math) online community that probability 0.5 would be more likely. I think there is a flow somewhere in my logic. Can you help me to understand this concept? Thanks. Update: for anyone interested, the question originally emerged during the discussion of Hindsight bias phenomenon . More precisely, the result of Fischhoff and Beyth experiment seems to be logically correct since differences in the results of predictions were caused by the differences in the information given to the groups. Even if the students were explicitly asked not to consider the result of conflicts as the probability factor, the only thing that experiment states is that we can't throw things out from our subconscious perception of the world at will (and that is obvious from the definition of the subconsciousness itself). So the phenomenon of hindsight bias can not be tested through such experiment or any one alike. The experiment should show difference between mathematical probability and empirical probability given the same initial data.",,['probability']
56,Maximum of the Variance Function for Given Set of Bounded Numbers,Maximum of the Variance Function for Given Set of Bounded Numbers,,"Let $ \boldsymbol{x} $ be a vector of $n$ numbers in the range $ \left[0, c \right] $ , where $ c $ is a positive real number. What's is the maximum of the variance function of this $ n $ numbers? Maximum in the meaning what spread of the number will maximize the variance? What would be a tighter bound for other assumptions on the spread of the numbers. The variance of the vector $ \boldsymbol{x} $ is given by: $$ \operatorname{var} (\boldsymbol{x}) = \frac{1}{n} \sum_{i = 1}^{n} {\left( {x}_{i} - \overline{\mathbf{x}} \right )}^2 $$ Where the mean $\overline{\boldsymbol{x}}$ is given by: $$ \overline{\boldsymbol{x}} = \frac{1}{n} \sum_{i = 1}^{n} {x}_{i} $$","Let be a vector of numbers in the range , where is a positive real number. What's is the maximum of the variance function of this numbers? Maximum in the meaning what spread of the number will maximize the variance? What would be a tighter bound for other assumptions on the spread of the numbers. The variance of the vector is given by: Where the mean is given by:"," \boldsymbol{x}  n  \left[0, c \right]   c   n   \boldsymbol{x}   \operatorname{var} (\boldsymbol{x}) = \frac{1}{n} \sum_{i = 1}^{n} {\left( {x}_{i} - \overline{\mathbf{x}} \right )}^2  \overline{\boldsymbol{x}}  \overline{\boldsymbol{x}} = \frac{1}{n} \sum_{i = 1}^{n} {x}_{i} ","['probability', 'analysis', 'statistics', 'functions', 'variance']"
57,"With $n$ balls and $n$ bins, what is the probability that exactly $k$ bins have exactly $1$ ball?","With  balls and  bins, what is the probability that exactly  bins have exactly  ball?",n n k 1,"I've got a balls and bins problem.  Suppose I throw $n$ balls uniformly at random into $n$ bins.  What is the probability that exactly $k$ bins end up with exactly $1$ ball? I know this seems a classical problem and may look ""simple"" or ""naive,"" but I've worked days on it and still can't get the answer. However, I think I do have a good approximation for it. Namely, let $X$ denote the number of such bins.  Then $$ Pr(X=k) \approx \binom{n}{k}\left(\frac{1}{e}\right)^{k}\left(1-\frac{1}{e}\right)^{n-k} $$ where $1/e$ is an approximation for $(1-1/n)^{n-1}$. This approximation works great when $n$ is big and poorly when $n$ is small (like $n<5$). Anyway, I'm looking for an exact expression.  Anyone have an idea? PS: I've written a simple simulation in C++; you can check your answer with it first: Simulation Code Here .","I've got a balls and bins problem.  Suppose I throw $n$ balls uniformly at random into $n$ bins.  What is the probability that exactly $k$ bins end up with exactly $1$ ball? I know this seems a classical problem and may look ""simple"" or ""naive,"" but I've worked days on it and still can't get the answer. However, I think I do have a good approximation for it. Namely, let $X$ denote the number of such bins.  Then $$ Pr(X=k) \approx \binom{n}{k}\left(\frac{1}{e}\right)^{k}\left(1-\frac{1}{e}\right)^{n-k} $$ where $1/e$ is an approximation for $(1-1/n)^{n-1}$. This approximation works great when $n$ is big and poorly when $n$ is small (like $n<5$). Anyway, I'm looking for an exact expression.  Anyone have an idea? PS: I've written a simple simulation in C++; you can check your answer with it first: Simulation Code Here .",,"['probability', 'statistics']"
58,Probability that the triangle is acute,Probability that the triangle is acute,,A triangle is formed by randomly choosing three distinct points on the circumference of a circle and joining them. What is the probability that the formed triangle is an acute triangle?,A triangle is formed by randomly choosing three distinct points on the circumference of a circle and joining them. What is the probability that the formed triangle is an acute triangle?,,"['probability', 'geometry', 'geometric-probability']"
59,Variance formula in terms of the CDF for a continuous nonnegative random variable.,Variance formula in terms of the CDF for a continuous nonnegative random variable.,,"Is there a formula for the variance of a (continuous, non-negative) random variable in terms of its CDF? The only place I saw such formula was is Wikipedia's page for the Variance ( https://en.wikipedia.org/wiki/Variance ). Unfortunately, I was not able to prove the expression there.  Please, can anyone help?","Is there a formula for the variance of a (continuous, non-negative) random variable in terms of its CDF? The only place I saw such formula was is Wikipedia's page for the Variance ( https://en.wikipedia.org/wiki/Variance ). Unfortunately, I was not able to prove the expression there.  Please, can anyone help?",,['probability']
60,Derivation of the moment generating function of the geometric distribution - why is this wrong?,Derivation of the moment generating function of the geometric distribution - why is this wrong?,,"Let $P(k,X)=p(1-p)^{k-1}$. When deriving the moment generating function I start off as follows: $E[e^{kt}X]=\sum\limits_{k=1}^{\infty}e^{kt}p(1-p)^{k-1}$. How I end up rearranging this is as follows: $\frac{p}{1-p}\sum\limits_{k=1}^{\infty}e^{kt}(1-p)^k=\frac{p}{1-p}\sum\limits_{k=1}^{\infty}(e^{t}(1-p))^k=\frac{p}{1-p}\frac{1}{1-e^t(1-p)}$ I'm obviously not arriving at the correct answer, but I want to know why this derivation is wrong.","Let $P(k,X)=p(1-p)^{k-1}$. When deriving the moment generating function I start off as follows: $E[e^{kt}X]=\sum\limits_{k=1}^{\infty}e^{kt}p(1-p)^{k-1}$. How I end up rearranging this is as follows: $\frac{p}{1-p}\sum\limits_{k=1}^{\infty}e^{kt}(1-p)^k=\frac{p}{1-p}\sum\limits_{k=1}^{\infty}(e^{t}(1-p))^k=\frac{p}{1-p}\frac{1}{1-e^t(1-p)}$ I'm obviously not arriving at the correct answer, but I want to know why this derivation is wrong.",,"['probability', 'statistics']"
61,Probability of rolling the first 6 on an even throw?,Probability of rolling the first 6 on an even throw?,,"I came across this question and I wasn't sure how to approach it. The question says basically roll a die, what's the probability you get the first 6 on an even throw? I.e., the 2nd, 4th, 6, 8th, etc. die throw. Part of my issue is that obviously you never know when it may come. Here's my guess: The probability of you getting a 6 on your $n$th  throw is: $$\left(\frac{5}{6}\right)^{n-1}\cdot\frac{1}{6}$$ Now we want to solve when $n=2k$ where $k$ is a natural number which gives us: $$\left(\frac{5}{6}\right)^{2k-1}\cdot\frac{1}{6}=\left(\frac{5}{6}\right)^{2k}\cdot\left(\frac{5}{6}\right)^{-1}\cdot\frac{1}{6}$$ The obvious guess is $\frac12$, since it seems it would be equally likely to fall on an even vs. odd, though odd should have an edge since the number of odd rolls are always greater than or equal to the even throws, but unsure. $$=\left(\frac{5}{6}\right)^{2k}\cdot\frac{1}{5}=\left(\frac{25}{36}\right)^{k}\cdot\frac{1}{5}$$ This point I have no idea how to proceed, have I been doing this right so far? What's the next step?","I came across this question and I wasn't sure how to approach it. The question says basically roll a die, what's the probability you get the first 6 on an even throw? I.e., the 2nd, 4th, 6, 8th, etc. die throw. Part of my issue is that obviously you never know when it may come. Here's my guess: The probability of you getting a 6 on your $n$th  throw is: $$\left(\frac{5}{6}\right)^{n-1}\cdot\frac{1}{6}$$ Now we want to solve when $n=2k$ where $k$ is a natural number which gives us: $$\left(\frac{5}{6}\right)^{2k-1}\cdot\frac{1}{6}=\left(\frac{5}{6}\right)^{2k}\cdot\left(\frac{5}{6}\right)^{-1}\cdot\frac{1}{6}$$ The obvious guess is $\frac12$, since it seems it would be equally likely to fall on an even vs. odd, though odd should have an edge since the number of odd rolls are always greater than or equal to the even throws, but unsure. $$=\left(\frac{5}{6}\right)^{2k}\cdot\frac{1}{5}=\left(\frac{25}{36}\right)^{k}\cdot\frac{1}{5}$$ This point I have no idea how to proceed, have I been doing this right so far? What's the next step?",,"['probability', 'probability-theory']"
62,Deal 4 cards from a deck. What is the probability that we get one card from each suit?,Deal 4 cards from a deck. What is the probability that we get one card from each suit?,,"My simple easy homework question. Just needed some double check :D Deal 4 cards from a deck of 52 cards. What is the probability that we get one card from each suit? My answer First Draw: We can get any card, and the card's suit will be done. $Chance:1$ Second Draw: Now we need to get 1 of the 3 remaining suits. There are 51 cards left. $Chance:\frac{13+13+13}{51}$ Third Draw: Now we need to get 1 of the 2 remaining suits. There are 50 cards left. $Chance:\frac{13+13}{50}$ Fourth Draw: Now we need to get the last remaining suit. There are 49 cards left. $Chance:\frac{13}{49}$ $P($One card from each suit$)=1*\frac{13+13+13}{51}*\frac{13+13}{50}*\frac{13}{49}=0.1055$ My tutor is known for giving not-so straightforward questions, so I'm wondering if I need to consider another way, or I could be wrong. Any alternatives welcome too!","My simple easy homework question. Just needed some double check :D Deal 4 cards from a deck of 52 cards. What is the probability that we get one card from each suit? My answer First Draw: We can get any card, and the card's suit will be done. $Chance:1$ Second Draw: Now we need to get 1 of the 3 remaining suits. There are 51 cards left. $Chance:\frac{13+13+13}{51}$ Third Draw: Now we need to get 1 of the 2 remaining suits. There are 50 cards left. $Chance:\frac{13+13}{50}$ Fourth Draw: Now we need to get the last remaining suit. There are 49 cards left. $Chance:\frac{13}{49}$ $P($One card from each suit$)=1*\frac{13+13+13}{51}*\frac{13+13}{50}*\frac{13}{49}=0.1055$ My tutor is known for giving not-so straightforward questions, so I'm wondering if I need to consider another way, or I could be wrong. Any alternatives welcome too!",,['probability']
63,Expected number of distinct objects in sampling with replacement,Expected number of distinct objects in sampling with replacement,,"Given the set of numbers from 1 to n: { 1, 2, 3 .. n } We draw n numbers randomly (with uniform distribution) from this set (with replacement). What is the expected number of distinct values that we would draw? My Approach : Let $X(k)$ denote the expected number of distinct values in a sample of size $k$ . Then, $X(k) =  \frac{n - X(k-1)}{n}*(1 + X(k-1)) + \frac{X(k-1)}{n}*X(k-1)$ $X(k) =  1 + \frac{n-1}{n}*X(k-1)$ Since $X(1) = 1$ , solving the recursive relation, we get $X(k) =  1 + (\frac{n-1}{n}) + (\frac{n-1}{n})^2 + (\frac{n-1}{n})^3 + ... + (\frac{n-1}{n})^{k-1}$ $X(k) = \frac{1-(\frac{n-1}{n})^k}{\frac{1}{n}} = n*(1-(1-\frac{1}{n})^k)$ Hence, $X(n) = n*(1-(1-\frac{1}{n})^n)$ The answer is correct, but I doubt if my approach is correct or not. The idea behind the first equation is: after $k-1$ th sample, the probability of getting a new value in $k$ th sample is $ \frac{n - X(k-1)}{n} $ . Since $X(k-1)$ is not necessarily an integer, I doubt if the probability is correct or not. So my question is: is my approach correct or not? please provide some convincing explanation as to why or why not is it correct.","Given the set of numbers from 1 to n: { 1, 2, 3 .. n } We draw n numbers randomly (with uniform distribution) from this set (with replacement). What is the expected number of distinct values that we would draw? My Approach : Let denote the expected number of distinct values in a sample of size . Then, Since , solving the recursive relation, we get Hence, The answer is correct, but I doubt if my approach is correct or not. The idea behind the first equation is: after th sample, the probability of getting a new value in th sample is . Since is not necessarily an integer, I doubt if the probability is correct or not. So my question is: is my approach correct or not? please provide some convincing explanation as to why or why not is it correct.",X(k) k X(k) =  \frac{n - X(k-1)}{n}*(1 + X(k-1)) + \frac{X(k-1)}{n}*X(k-1) X(k) =  1 + \frac{n-1}{n}*X(k-1) X(1) = 1 X(k) =  1 + (\frac{n-1}{n}) + (\frac{n-1}{n})^2 + (\frac{n-1}{n})^3 + ... + (\frac{n-1}{n})^{k-1} X(k) = \frac{1-(\frac{n-1}{n})^k}{\frac{1}{n}} = n*(1-(1-\frac{1}{n})^k) X(n) = n*(1-(1-\frac{1}{n})^n) k-1 k  \frac{n - X(k-1)}{n}  X(k-1),"['probability', 'expected-value']"
64,"Probability that there exists a person who will ""only flip heads"" or ""only flip tails"" in their lifetime?","Probability that there exists a person who will ""only flip heads"" or ""only flip tails"" in their lifetime?",,"My question has two parts: Am I approaching the problem correctly, resulting in a reasonable formula? How do I do the final calculation for numbers as large and as small as these. I put my formula into google and it just gives an answer of ""1"", which surely isn't the right answer. My approach: Lets start with an assumption, that the average person experiences 225 coin flips in a lifetime (3/year for 75 years) The odds of an individual having the extraordinary results of ""only heads"" or ""only tails"" for all 225 of their flips would be 0.5^224 (the first flip can be either so we only say 224). Then we can say that the odds that someone goes through life without these extraordinary results would be 1-(0.5^224). The odds then of nobody experiencing these extraordinary results will be to take the previous calculation multiplied by itself for each member of the human population, so we raise it all to the power of 7.8 billion. The final formula for this calculation is then (1-(0.5^224))^7800000000. Edit: Given the insight from Stacker's answer its clear that I missed a step, I only ""calculated the probability that everyone will not have such an extraordinary event in their lifetime. To find the probability that at least one person will, subtract that number from 1 (the complement rule)."" The final formula for this calculation is actually 1-((1-(0.5^224))^7800000000) P.S. If your interested in some context, I'm trying to do this calculation to explore the idea of perspective. To better understand how likely it is that there are people that will experience the world in a way that is entirely different from reality.","My question has two parts: Am I approaching the problem correctly, resulting in a reasonable formula? How do I do the final calculation for numbers as large and as small as these. I put my formula into google and it just gives an answer of ""1"", which surely isn't the right answer. My approach: Lets start with an assumption, that the average person experiences 225 coin flips in a lifetime (3/year for 75 years) The odds of an individual having the extraordinary results of ""only heads"" or ""only tails"" for all 225 of their flips would be 0.5^224 (the first flip can be either so we only say 224). Then we can say that the odds that someone goes through life without these extraordinary results would be 1-(0.5^224). The odds then of nobody experiencing these extraordinary results will be to take the previous calculation multiplied by itself for each member of the human population, so we raise it all to the power of 7.8 billion. The final formula for this calculation is then (1-(0.5^224))^7800000000. Edit: Given the insight from Stacker's answer its clear that I missed a step, I only ""calculated the probability that everyone will not have such an extraordinary event in their lifetime. To find the probability that at least one person will, subtract that number from 1 (the complement rule)."" The final formula for this calculation is actually 1-((1-(0.5^224))^7800000000) P.S. If your interested in some context, I'm trying to do this calculation to explore the idea of perspective. To better understand how likely it is that there are people that will experience the world in a way that is entirely different from reality.",,['probability']
65,Two players pick cards from standard 52 card deck without replacement...,Two players pick cards from standard 52 card deck without replacement...,,"I am struggling with this interview prep question... SOS Two players pick cards from standard 52 card deck without replacement: 1st player picks a card, then 2nd, then again 1st, then 2nd etc. They stop once somebody picks a king (of any suit), the player who picks the king wins. What is the probability that the first player wins? the second player? Which player has more chances of winning: the first or the second? It is sufficient to set up the correct formula for the probabilities, no need to evaluate it numerically. The last question can be answered without numerical evaluation, by analysis of the formulas What is the probability that the first player wins? the second player? couldn't be far of from 50% for both... right? Which player has more chances of winning: the first or the second? Intuition tells me the first person but I'm not sure if that follows or how to setup a formula -- EDIT: for this I'm thinking certainly the first player because they have one more opportunity to win by choosing a king first","I am struggling with this interview prep question... SOS Two players pick cards from standard 52 card deck without replacement: 1st player picks a card, then 2nd, then again 1st, then 2nd etc. They stop once somebody picks a king (of any suit), the player who picks the king wins. What is the probability that the first player wins? the second player? Which player has more chances of winning: the first or the second? It is sufficient to set up the correct formula for the probabilities, no need to evaluate it numerically. The last question can be answered without numerical evaluation, by analysis of the formulas What is the probability that the first player wins? the second player? couldn't be far of from 50% for both... right? Which player has more chances of winning: the first or the second? Intuition tells me the first person but I'm not sure if that follows or how to setup a formula -- EDIT: for this I'm thinking certainly the first player because they have one more opportunity to win by choosing a king first",,['probability']
66,Splitting Poisson process formal proof,Splitting Poisson process formal proof,,"Let $\{X_t\}_{t\ge 0}$ be a Poisson Process with parameter $\lambda$. Suppose that each event is type 1 with probability $\alpha$ and type 2 with probability $1-\alpha$. Let $\{X^{(1)}_t\}_{t\ge 0}$ the number of type 1 events up until time $t$ and $\{X^{(2)}_t\}_{t\ge 0}$ the number of type 2 events up until time $t$ Prove that $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are Poisson Processes with parameter $\lambda \alpha$ and $\lambda(1-\alpha)$ respectively Furrthermore prove that for each $t\ge 0$ the random variables $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are independent My attempt: In order to prove that they are poisson process I will use the next definition: An stochastic process $\{Y_t\}_{t\ge 0}$ is a poisson process iff: a) $Y_0=0$ b) It has independent increments c) $Y_{t+s}-Y_{s}$~$Poisson(\lambda t)$ for any values $s\ge 0$ and $t>0$ a) For any $t\ge 0$ we have: $X_t=X^{(1)}_t+X^{(2)}_t$; we know that $\{X_t\}_{t\ge 0}$ is a poisson process hence $X_0=0$ $\Rightarrow X^{(1)}_0+X^{(2)}_0=0 \Rightarrow X^{(1)}_0=0$ and $X^{(2)}_0=0$ b)Let $n\in \mathbb N$ In this part I need to prove that for any $n$ arbitrary times $0<t_1\le t_2\le...\le t_n$ and states $x_1,...,x_n$  $$P[X^{(1)}_{t_1}=x_1,X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2,...,X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]=P[X^{(1)}_{t_1}=x_1]P[X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2]...P[X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]$$ I don´t know how to Formally prove this part, and I don´t think this is trivial. Any help would be highly appreciated c) $$P[X^{(1)}_t=k]=\sum_{i=k}^\infty P[X^{(1)}_t=k|X_t=i]P[X_t=i]=\sum_{i=k}^\infty \binom{i}{k}\alpha^i(1-\alpha)^{i-k}{e^{-\lambda t}(\lambda t)^i \over i!}={e^{-\lambda \alpha t}(\lambda \alpha t)^k\over k!}$$ Know I need to compute $P[X^{(1)}_{t+s}-X^{(1)}_t=n]=\sum_{j=0}^\infty P[X^{(1)}_{t+s}-X^{(1)}_t=n|X^{(1)}_s=j]P[X^{(1)}_s=j]$ This part is also giving me trouble because I dont´know what to do from here I would really apreciate if you can help me with this problem. Also I hope that this won´t be marked as a duplicate because I haven´t seen a formal proof about the splitting poisson process.","Let $\{X_t\}_{t\ge 0}$ be a Poisson Process with parameter $\lambda$. Suppose that each event is type 1 with probability $\alpha$ and type 2 with probability $1-\alpha$. Let $\{X^{(1)}_t\}_{t\ge 0}$ the number of type 1 events up until time $t$ and $\{X^{(2)}_t\}_{t\ge 0}$ the number of type 2 events up until time $t$ Prove that $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are Poisson Processes with parameter $\lambda \alpha$ and $\lambda(1-\alpha)$ respectively Furrthermore prove that for each $t\ge 0$ the random variables $\{X^{(1)}_t\}_{t\ge 0}$ and $\{X^{(2)}_t\}_{t\ge 0}$ are independent My attempt: In order to prove that they are poisson process I will use the next definition: An stochastic process $\{Y_t\}_{t\ge 0}$ is a poisson process iff: a) $Y_0=0$ b) It has independent increments c) $Y_{t+s}-Y_{s}$~$Poisson(\lambda t)$ for any values $s\ge 0$ and $t>0$ a) For any $t\ge 0$ we have: $X_t=X^{(1)}_t+X^{(2)}_t$; we know that $\{X_t\}_{t\ge 0}$ is a poisson process hence $X_0=0$ $\Rightarrow X^{(1)}_0+X^{(2)}_0=0 \Rightarrow X^{(1)}_0=0$ and $X^{(2)}_0=0$ b)Let $n\in \mathbb N$ In this part I need to prove that for any $n$ arbitrary times $0<t_1\le t_2\le...\le t_n$ and states $x_1,...,x_n$  $$P[X^{(1)}_{t_1}=x_1,X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2,...,X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]=P[X^{(1)}_{t_1}=x_1]P[X^{(1)}_{t_2}-X^{(1)}_{t_1}=x_2]...P[X^{(1)}_{t_n}-X^{(1)}_{t_{n-1}}=x_n]$$ I don´t know how to Formally prove this part, and I don´t think this is trivial. Any help would be highly appreciated c) $$P[X^{(1)}_t=k]=\sum_{i=k}^\infty P[X^{(1)}_t=k|X_t=i]P[X_t=i]=\sum_{i=k}^\infty \binom{i}{k}\alpha^i(1-\alpha)^{i-k}{e^{-\lambda t}(\lambda t)^i \over i!}={e^{-\lambda \alpha t}(\lambda \alpha t)^k\over k!}$$ Know I need to compute $P[X^{(1)}_{t+s}-X^{(1)}_t=n]=\sum_{j=0}^\infty P[X^{(1)}_{t+s}-X^{(1)}_t=n|X^{(1)}_s=j]P[X^{(1)}_s=j]$ This part is also giving me trouble because I dont´know what to do from here I would really apreciate if you can help me with this problem. Also I hope that this won´t be marked as a duplicate because I haven´t seen a formal proof about the splitting poisson process.",,"['probability', 'probability-distributions', 'stochastic-processes', 'poisson-distribution', 'poisson-process']"
67,Boy and girl paradox is driving me crazy,Boy and girl paradox is driving me crazy,,"I know this question is asked over and over, but I still can't understand anything. Say I'm introduced to a random father of two and I want to know what's the probability that both his children are boys. Currently: BB BG GB GG ⇢ 1/4 Where the first letter represents the younger sibling and the second letter represents the older sibling. So far so good. (1) Now the father tells me that his youngest child is boy: BB BG GB GG ⇢ 1/2 (2) If, instead, he told me that at least one of his children is a boy: BB BG GB GG ⇢ 1/3 Makes sense, kind of. (3) But if the father brought one of his children with him without telling whether he's the younger child or the older child and that child happened to be a boy, I think I could have still honestly arrived to the 50/50 probability: BB BG GB GG ⇢ 1/2 Where the first letter represents the boy I've just seen and the second letter represents his sibling. Now, say, the father first told me that he has at least 1 boy. That's the case (2). Then the father called (one of) the boy(s) here, and somehow the situation turned into the case (3)! What exactly has changed? What kind of new information did I just get? OK, I've seen (one of) the boy(s), but the only thing it tells me is that one of the children is a boy, which I already knew from the father's own words. It seems to me that anything he could bring that has some kind of relationship to (one of) the boy(s) so as to allow me to uniquely identify him would work: a photo, a footprint on a beach, etc. Even if he simply told me that he has just thought about one of his children who is a boy, I think I could still have done this: BB BG GB GG ⇢ 1/2 Where the first letter represents the boy the father has thought about at XX/XX/XXXX XX:XX:XX UTC, and the second letter represents his other child. Is this magic? Or am I just stupid? Can't I simply construct such a way of identification myself? For example, let the first letter represent the youngest boy (the only boy if there's just one), and let the other letter represent the other child. Since the father is not an abstract entity, this would uniquely identify some child. I don't see how changing the representation changes things. Say I saw one of the father's on a photo behind a thick blurry glass that doesn't let me see whether it's a girl or a boy. Therefore: BB BG GB GG ⇢ 1/4 Where the first letter represents the child on the photo and the second letter represents the other child. Now the glass is removed and I can see the photo clearly and it's indeed a boy: BB BG GB GG ⇢ 1/2","I know this question is asked over and over, but I still can't understand anything. Say I'm introduced to a random father of two and I want to know what's the probability that both his children are boys. Currently: BB BG GB GG ⇢ 1/4 Where the first letter represents the younger sibling and the second letter represents the older sibling. So far so good. (1) Now the father tells me that his youngest child is boy: BB BG GB GG ⇢ 1/2 (2) If, instead, he told me that at least one of his children is a boy: BB BG GB GG ⇢ 1/3 Makes sense, kind of. (3) But if the father brought one of his children with him without telling whether he's the younger child or the older child and that child happened to be a boy, I think I could have still honestly arrived to the 50/50 probability: BB BG GB GG ⇢ 1/2 Where the first letter represents the boy I've just seen and the second letter represents his sibling. Now, say, the father first told me that he has at least 1 boy. That's the case (2). Then the father called (one of) the boy(s) here, and somehow the situation turned into the case (3)! What exactly has changed? What kind of new information did I just get? OK, I've seen (one of) the boy(s), but the only thing it tells me is that one of the children is a boy, which I already knew from the father's own words. It seems to me that anything he could bring that has some kind of relationship to (one of) the boy(s) so as to allow me to uniquely identify him would work: a photo, a footprint on a beach, etc. Even if he simply told me that he has just thought about one of his children who is a boy, I think I could still have done this: BB BG GB GG ⇢ 1/2 Where the first letter represents the boy the father has thought about at XX/XX/XXXX XX:XX:XX UTC, and the second letter represents his other child. Is this magic? Or am I just stupid? Can't I simply construct such a way of identification myself? For example, let the first letter represent the youngest boy (the only boy if there's just one), and let the other letter represent the other child. Since the father is not an abstract entity, this would uniquely identify some child. I don't see how changing the representation changes things. Say I saw one of the father's on a photo behind a thick blurry glass that doesn't let me see whether it's a girl or a boy. Therefore: BB BG GB GG ⇢ 1/4 Where the first letter represents the child on the photo and the second letter represents the other child. Now the glass is removed and I can see the photo clearly and it's indeed a boy: BB BG GB GG ⇢ 1/2",,"['probability', 'paradoxes']"
68,Does variance do any good to gambling game makers?,Does variance do any good to gambling game makers?,,"People always like to evaluate the variance, but is there any way for variance to be interesting to the gambling game makers? In another word, what is a pratical gambling game that involving some distributions that is relating to variance other than the normal distribution?","People always like to evaluate the variance, but is there any way for variance to be interesting to the gambling game makers? In another word, what is a pratical gambling game that involving some distributions that is relating to variance other than the normal distribution?",,"['probability', 'statistics', 'probability-distributions', 'applications', 'gambling']"
69,Expected value of normal distribution given that distribution is positive,Expected value of normal distribution given that distribution is positive,,"Given $X \sim N(0, \sigma^2)$ (that is, $X:\mathbb{R} \to \mathbb{R}$ is a normal random variable with mean $0$ and variance $\sigma^2$), I'm trying to calculate the expected value of $X$ given that $X>0$. I thought that integrating $$ \int_{0}^{\infty} x\cdot \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{x^2}{2\sigma^2}}dx $$ would do it, but the value, $\frac{\sigma}{\sqrt{2\pi}}$, seems to be off by a factor of 2 based on some other information I have; I think the answer should be $\sqrt{\frac{2}{\pi}}\sigma$. Question: How should the expected value of $X$, given that $X>0$, be computed?","Given $X \sim N(0, \sigma^2)$ (that is, $X:\mathbb{R} \to \mathbb{R}$ is a normal random variable with mean $0$ and variance $\sigma^2$), I'm trying to calculate the expected value of $X$ given that $X>0$. I thought that integrating $$ \int_{0}^{\infty} x\cdot \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{x^2}{2\sigma^2}}dx $$ would do it, but the value, $\frac{\sigma}{\sqrt{2\pi}}$, seems to be off by a factor of 2 based on some other information I have; I think the answer should be $\sqrt{\frac{2}{\pi}}\sigma$. Question: How should the expected value of $X$, given that $X>0$, be computed?",,"['probability', 'probability-distributions', 'normal-distribution']"
70,Confusion over probability problems,Confusion over probability problems,,"I am stuck with these probability problems, A pair of unbiased dice is rolled together till a sum of either $5$ or $7$ is obtained. Find the probability that $5$ comes before $7$? A letter is taken at random from the letters of the word ‘STATISTICS’ and another letter is taken random from the letters of   the word ‘ASSISTANT ’. Find the probability that they are the same   letter. A bag contains $6$ red and $4$ green balls. A fair dice is rolled and a number of balls equal to that appearing on the dice is chosen from   the urn at random.What is the probability that all the balls selected   are red? A letter is known  to have come from either TATANAGAR  or CALCUTTA. On the envelope, just two consecutive letters, TA, are   visible. Find the probability that the letter has come from CALCUTTA. Could anybody help me to understand how to approach them?","I am stuck with these probability problems, A pair of unbiased dice is rolled together till a sum of either $5$ or $7$ is obtained. Find the probability that $5$ comes before $7$? A letter is taken at random from the letters of the word ‘STATISTICS’ and another letter is taken random from the letters of   the word ‘ASSISTANT ’. Find the probability that they are the same   letter. A bag contains $6$ red and $4$ green balls. A fair dice is rolled and a number of balls equal to that appearing on the dice is chosen from   the urn at random.What is the probability that all the balls selected   are red? A letter is known  to have come from either TATANAGAR  or CALCUTTA. On the envelope, just two consecutive letters, TA, are   visible. Find the probability that the letter has come from CALCUTTA. Could anybody help me to understand how to approach them?",,"['probability', 'combinatorics', 'dice']"
71,Non-probabilistic proofs of a binomial coefficient identity from a probability question,Non-probabilistic proofs of a binomial coefficient identity from a probability question,,"Combining the answers given by me and Ralth to the probability question at Probability of getting three zeros when sampling a set , we get the following identity: $$ \sum\limits_{k = m}^n {{n \choose k}p^k (1 - p)^{n - k} {k \choose m} p_j^m (1 - p_j )^{k - m} } = {n \choose m} (p p_j)^m (1 - p p_j)^{n-m}, $$ where $m \geq 0$ and $n \geq m$ are arbitrary integers, and $p$ and $p_j$ are arbitrary probabilities (in Ralth's notation $m$ is $k$, $p$ is $p_s$, and $p_j$ is $p_h$). Can you prove this identity directly (i.e., in a non-probabilistic setting)? Whether you'll find this identity interesting or not, at least Ralth's answer may now gain its due recognition.","Combining the answers given by me and Ralth to the probability question at Probability of getting three zeros when sampling a set , we get the following identity: $$ \sum\limits_{k = m}^n {{n \choose k}p^k (1 - p)^{n - k} {k \choose m} p_j^m (1 - p_j )^{k - m} } = {n \choose m} (p p_j)^m (1 - p p_j)^{n-m}, $$ where $m \geq 0$ and $n \geq m$ are arbitrary integers, and $p$ and $p_j$ are arbitrary probabilities (in Ralth's notation $m$ is $k$, $p$ is $p_s$, and $p_j$ is $p_h$). Can you prove this identity directly (i.e., in a non-probabilistic setting)? Whether you'll find this identity interesting or not, at least Ralth's answer may now gain its due recognition.",,"['probability', 'combinatorics', 'algebra-precalculus', 'binomial-coefficients']"
72,How to apply Ito's Formula to show that this is a martingale?,How to apply Ito's Formula to show that this is a martingale?,,"In the book Brownian Motion, Martingales and Stochastic Calculus by J.F. Le Gall, in order to give an alternatice derivation of the distribution of $L_{U_{a}}^{0}(B)$ where $L^{0}_{t}(B)$ is the Local-Time at $0$ of a Standard Brownian Motion and $U_{a}=\inf\{t:|B_{t}|\geq a\}$ , he states as a remark that ""use Itô’s formula to verify that, for every $\lambda>0$ , $$(1+\lambda |B_{t}|)e^{-\lambda L_{0}^{t}(B)}$$ is a continuous Martingale (local)"". My question: What is the function that we are supposed to apply Ito's Formula to? I can write $L_{0}^{t}(B)=|B_{t}|-\int_{0}^{t}\text{sgn}(B_{s})\,dB_s$ by using Tanaka's Formula. In that case, I will get $$(1+\lambda|B_{t}|)\exp\bigg(-\lambda |B_{t}|+\lambda\int_{0}^{t}\text{sgn}(B_{s})\,dB_{s}\bigg)$$ But the problem is I cannot express it in the form of $f(X_{t})$ where $f$ is some function and $dX_{t}=\mu_{t}\,dt+\sigma_{t}\,dB_{t}$ inorder to apply Ito's Formula. Can someone help me out with this?","In the book Brownian Motion, Martingales and Stochastic Calculus by J.F. Le Gall, in order to give an alternatice derivation of the distribution of where is the Local-Time at of a Standard Brownian Motion and , he states as a remark that ""use Itô’s formula to verify that, for every , is a continuous Martingale (local)"". My question: What is the function that we are supposed to apply Ito's Formula to? I can write by using Tanaka's Formula. In that case, I will get But the problem is I cannot express it in the form of where is some function and inorder to apply Ito's Formula. Can someone help me out with this?","L_{U_{a}}^{0}(B) L^{0}_{t}(B) 0 U_{a}=\inf\{t:|B_{t}|\geq a\} \lambda>0 (1+\lambda |B_{t}|)e^{-\lambda L_{0}^{t}(B)} L_{0}^{t}(B)=|B_{t}|-\int_{0}^{t}\text{sgn}(B_{s})\,dB_s (1+\lambda|B_{t}|)\exp\bigg(-\lambda |B_{t}|+\lambda\int_{0}^{t}\text{sgn}(B_{s})\,dB_{s}\bigg) f(X_{t}) f dX_{t}=\mu_{t}\,dt+\sigma_{t}\,dB_{t}","['probability', 'stochastic-calculus', 'brownian-motion', 'martingales', 'local-time']"
73,When does the game end?,When does the game end?,,"A recent question has inspired the following one. $M$ people ( $M\ge2$ ) play the following game. Each round every person admitted to the round rolls a $K$ -sided dice ( $K\ge2$ ), the sides being marked with numbers from $1$ to $K$ . If only a single person has the highest score, the game ends. Otherwise the people with the highest score are admitted to the next round and the game continues. What is the probability that the game ends exactly in $n$ rounds?","A recent question has inspired the following one. people ( ) play the following game. Each round every person admitted to the round rolls a -sided dice ( ), the sides being marked with numbers from to . If only a single person has the highest score, the game ends. Otherwise the people with the highest score are admitted to the next round and the game continues. What is the probability that the game ends exactly in rounds?",M M\ge2 K K\ge2 1 K n,"['probability', 'combinatorics', 'stochastic-processes', 'dice']"
74,How many times would you have to roll a single die on average to reach a sum of at least 30?,How many times would you have to roll a single die on average to reach a sum of at least 30?,,"I am primarily asking for what this kind of problem would be called. Say I have one six-sided die. How many times on average would I have to roll it in order to have a sum of at least 30? Doing some googling, the closest I have found was a geometric distribution. But I am unsure if that is strictly for pass/fail scenarios (such as flipping a coin or drawing a name out of a hat). The closest I can get is that it will take no more than 30 tries (at a $1/6^30$ chance) and no less than 5 tries (at a $1/6^5$ chance). My problem arises when I think about the number of possible ways to get 6 tries. It would be easy if each die had 2 outcomes, but each one has 6, and many combinations can accomplish this. I don't even know where to begin figuring out how many combinations exist outside of counting (which would take hours). EDIT: So I found this Help with the Probabilty of Rolling Two Ten-Sided Dice Multiple Times Until 100 is Reached This is very much what this problem is, but it doesn't mention what the process is called. Which in the end is what my main question is.","I am primarily asking for what this kind of problem would be called. Say I have one six-sided die. How many times on average would I have to roll it in order to have a sum of at least 30? Doing some googling, the closest I have found was a geometric distribution. But I am unsure if that is strictly for pass/fail scenarios (such as flipping a coin or drawing a name out of a hat). The closest I can get is that it will take no more than 30 tries (at a chance) and no less than 5 tries (at a chance). My problem arises when I think about the number of possible ways to get 6 tries. It would be easy if each die had 2 outcomes, but each one has 6, and many combinations can accomplish this. I don't even know where to begin figuring out how many combinations exist outside of counting (which would take hours). EDIT: So I found this Help with the Probabilty of Rolling Two Ten-Sided Dice Multiple Times Until 100 is Reached This is very much what this problem is, but it doesn't mention what the process is called. Which in the end is what my main question is.",1/6^30 1/6^5,"['probability', 'dice']"
75,Probability it rains,Probability it rains,,"The probability it rains on Wednesday this week is 40%, while the probability it rains on Thursday this week is 30%. However, it is twice more likely to also rain on Thursday, if it has already rained on Wednesday. What is the probability it rains at least one of the two days? Although I am not familiar with probabilities (I just did a bit of reading), I will try to start: The probability it rains at least one of the two days is 1- the probability it will not rain on any of the two days. This is 1-(1-40%)(1-30%)=58% But this is only when the two events are independent. The probability it rains on Thursday is not independent. How do I take into account this? Thanks for your help.","The probability it rains on Wednesday this week is 40%, while the probability it rains on Thursday this week is 30%. However, it is twice more likely to also rain on Thursday, if it has already rained on Wednesday. What is the probability it rains at least one of the two days? Although I am not familiar with probabilities (I just did a bit of reading), I will try to start: The probability it rains at least one of the two days is 1- the probability it will not rain on any of the two days. This is 1-(1-40%)(1-30%)=58% But this is only when the two events are independent. The probability it rains on Thursday is not independent. How do I take into account this? Thanks for your help.",,['probability']
76,How to prove Poisson Distribution is the approximation of Binomial Distribution?,How to prove Poisson Distribution is the approximation of Binomial Distribution?,,"I was reading Introduction to Probability Models 11th Edition and saw this proof of why Poisson Distribution is the approximation of Binomial Distribution when n is large and p is small: An important property of the Poisson random variable is that it may be used to approximate a binomial random variable when the binomial parameter $n$ is large and $p$ is small. To see this, suppose that $X$ is a binomial random variable with parameters $(n, p),$ and let $\lambda=n p .$ Then $$ \begin{aligned} P\{X=i\} &=\frac{n !}{(n-i) ! i !} p^{i}(1-p)^{n-i} \\ &=\frac{n !}{(n-i) ! i !}\left(\frac{\lambda}{n}\right)^{i}\left(1-\frac{\lambda}{n}\right)^{n-i} \\ &=\frac{n(n-1) \cdots(n-i+1)}{n^{i}} \frac{\lambda^{i}}{i !} \frac{(1-\lambda / n)^{n}}{(1-\lambda / n)^{i}} \end{aligned} $$ Now, for $n$ large and $p$ small $$ \left(1-\frac{\lambda}{n}\right)^{n} \approx e^{-\lambda}, \quad \frac{n(n-1) \cdots(n-i+1)}{n^{i}} \approx 1, \quad\left(1-\frac{\lambda}{n}\right)^{i} \approx 1 $$ Hence, for $n$ large and $p$ small, $$ P\{X=i\} \approx e^{-\lambda} \frac{\lambda^{i}}{i !} $$ I can understand most part of the proof except for this equation: $\left(1-\frac{\lambda}{n}\right)^{n} \approx e^{-\lambda}$ I really don't remember where it comes from, could anybody explain this to me? Thanks!.","I was reading Introduction to Probability Models 11th Edition and saw this proof of why Poisson Distribution is the approximation of Binomial Distribution when n is large and p is small: An important property of the Poisson random variable is that it may be used to approximate a binomial random variable when the binomial parameter is large and is small. To see this, suppose that is a binomial random variable with parameters and let Then Now, for large and small Hence, for large and small, I can understand most part of the proof except for this equation: I really don't remember where it comes from, could anybody explain this to me? Thanks!.","n p X (n, p), \lambda=n p . 
\begin{aligned}
P\{X=i\} &=\frac{n !}{(n-i) ! i !} p^{i}(1-p)^{n-i} \\
&=\frac{n !}{(n-i) ! i !}\left(\frac{\lambda}{n}\right)^{i}\left(1-\frac{\lambda}{n}\right)^{n-i} \\
&=\frac{n(n-1) \cdots(n-i+1)}{n^{i}} \frac{\lambda^{i}}{i !} \frac{(1-\lambda / n)^{n}}{(1-\lambda / n)^{i}}
\end{aligned}
 n p 
\left(1-\frac{\lambda}{n}\right)^{n} \approx e^{-\lambda}, \quad \frac{n(n-1) \cdots(n-i+1)}{n^{i}} \approx 1, \quad\left(1-\frac{\lambda}{n}\right)^{i} \approx 1
 n p 
P\{X=i\} \approx e^{-\lambda} \frac{\lambda^{i}}{i !}
 \left(1-\frac{\lambda}{n}\right)^{n} \approx e^{-\lambda}","['probability', 'poisson-distribution', 'binomial-distribution']"
77,Difference between two independent binomial random variables with equal success probability,Difference between two independent binomial random variables with equal success probability,,"Let $X$ ~ $Bin(n,p)$ and $Y$ ~ $Bin(m,p)$ be two independent random variables. Find the distribution of $Z=X-Y$. see also Difference of two binomial random variables I figured this out: $$ P(Z=z)=\cases{\sum_{i=o}^{min(m,n)} Bin(k+i,n,p)*Bin(i,m,p), &if $z\ge0$;\cr \sum_{i=0}^{min(m,n)} Bin(i,n,p) * Bin(i-z, m, p),&otherwise. \cr}$$ I also validated it by Monte Carlo simulation. For $n=30$, $m=20$ and $p=0.5$, I get the following distribution, where the circles are the analytical probabilities and the line connects the MC estimates. Because that looked to me pretty much like a binomial distribution, I gave it a try and figured out that its actually a binomial, just shifted by m to the left. This can be simply written as $P(Y=y) = Bin(y+m, m+n, p)$. Hence, given equal success probabilities, the sum of two independent binomially distributed random variables is binomial, but also their difference, just shifted to the left. This question here difference between independent binomial variables is actually the same as mine, but received no answer and only the comment that there would be no simple formula. But the above formula looks pretty simple to me. Is it correct that for the case of equal success probabilities, the above equations actually describes the distribution of $Z=X-Y$? I read in a book that $Z$ could not be binomial distributed because it had negative support. Is it right to call it a shifted binomial?","Let $X$ ~ $Bin(n,p)$ and $Y$ ~ $Bin(m,p)$ be two independent random variables. Find the distribution of $Z=X-Y$. see also Difference of two binomial random variables I figured this out: $$ P(Z=z)=\cases{\sum_{i=o}^{min(m,n)} Bin(k+i,n,p)*Bin(i,m,p), &if $z\ge0$;\cr \sum_{i=0}^{min(m,n)} Bin(i,n,p) * Bin(i-z, m, p),&otherwise. \cr}$$ I also validated it by Monte Carlo simulation. For $n=30$, $m=20$ and $p=0.5$, I get the following distribution, where the circles are the analytical probabilities and the line connects the MC estimates. Because that looked to me pretty much like a binomial distribution, I gave it a try and figured out that its actually a binomial, just shifted by m to the left. This can be simply written as $P(Y=y) = Bin(y+m, m+n, p)$. Hence, given equal success probabilities, the sum of two independent binomially distributed random variables is binomial, but also their difference, just shifted to the left. This question here difference between independent binomial variables is actually the same as mine, but received no answer and only the comment that there would be no simple formula. But the above formula looks pretty simple to me. Is it correct that for the case of equal success probabilities, the above equations actually describes the distribution of $Z=X-Y$? I read in a book that $Z$ could not be binomial distributed because it had negative support. Is it right to call it a shifted binomial?",,"['probability', 'statistics', 'random-variables']"
78,Distribution of the maximum of $n$ uniform random variables,Distribution of the maximum of  uniform random variables,n,"If $U_1,\dots, U_n$ are independent uniform random variables with range $\{1,\dots,N\}$, what can be said about the distribution of $Z=\max U_i$?  I am interested in the case where $n$ is large and $N\geq n$. In particular, I am interested in tail bounds for $Z$.  That is how tightly concentrated it is around its mean $\mathbb{E}(Z)$.","If $U_1,\dots, U_n$ are independent uniform random variables with range $\{1,\dots,N\}$, what can be said about the distribution of $Z=\max U_i$?  I am interested in the case where $n$ is large and $N\geq n$. In particular, I am interested in tail bounds for $Z$.  That is how tightly concentrated it is around its mean $\mathbb{E}(Z)$.",,[]
79,Prove $E[XY]=E[YE[X|Y]]$,Prove,E[XY]=E[YE[X|Y]],"Prove $E[XY]=E[YE[X|Y]]$. I tried proving it using the definition of covariance, but I ended up going in a circle. Any hints on how to go about the proof?","Prove $E[XY]=E[YE[X|Y]]$. I tried proving it using the definition of covariance, but I ended up going in a circle. Any hints on how to go about the proof?",,['probability']
80,Two random variables and their sum,Two random variables and their sum,,"$X$ and $Y$ are random variables uniformly distributed on $[a,b]$. Could the random variable $Z=X+Y$ be uniformly distributed if $X$ and $Y$ are dependent and correlation between them doesn't equal $1$ or $-1$?","$X$ and $Y$ are random variables uniformly distributed on $[a,b]$. Could the random variable $Z=X+Y$ be uniformly distributed if $X$ and $Y$ are dependent and correlation between them doesn't equal $1$ or $-1$?",,['probability']
81,"Probability in single-lane traffic flow: What are the odds of ""choke points"" being encountered?","Probability in single-lane traffic flow: What are the odds of ""choke points"" being encountered?",,"Let's say you have a single-lane road (single in this case meaning single lane in each direction, or what you could also call two-lane). Let's say you have a random number of vehicles on a given 10-mile stretch of road. The speed limit is 45 mph, but some people go faster and some go slower. Is there any math that describes the likelihood that faster vehicles will overtake slower vehicles at ""choke points"" (points where oncoming traffic makes passing impossible)? (Assume a straight, flat road where safe passing is always allowed.) EDIT: Choke points are points where oncoming cars make it impossible to pass without the overtaking vehicle having to slow down and wait for the oncoming car (or cars) to pass. Obviously, the answer has to be some kind of curve, because if there is only one vehicle on the road the probability is 0 that a choke point will be encountered, and if the road is completely filled with vehicles in both directions (or even one) the probability is 1 that a choke point will be encountered at any given time. Sorry if this is a stupid question. But it seems like there should be a way to express this mathematically. EDIT 2: Limiting the scope of the problem Thanks to Mike Spivey, and I hope this helps narrow the problem so that may be in some way answerable. If not, I'll just declare defeat and retire from the field. Let's say that we have two cars going in one direction: a slow vehicle (Vehicle A) traveling at 30mph and a faster vehicle (Vehicle B) traveling at 60mph. At the start of the problem the A is somewhere between mile 2 and mile 4 on the 10-mile road, and B is at mile 0. Additionally, there will be four oncoming vehicles randomly distributed, and these vehicles are randomly traveling at 30 or 60mph. The overtaking vehicle requires .5 miles of ""clear"" space to pass safely if the oncoming vehicle is traveling at 60mph, and .25 if it is traveling at 30mph. Assume further that the car lengths do not matter, but that a ""choke point"" (or bottleneck, if you prefer) is not reached until B gets within .05 miles of the rear bumper of A, at which point B has to pass A or decelerate. We will call the latter condition a ""deceleration event,"" (DE) and I would like to be able to calculate the probability that at least one DE will occur for Vehicle A along the 10-mile route. Perhaps this clarification is still insufficient to render the problem solvable, but I appreciate anyone taking the time to consider it.","Let's say you have a single-lane road (single in this case meaning single lane in each direction, or what you could also call two-lane). Let's say you have a random number of vehicles on a given 10-mile stretch of road. The speed limit is 45 mph, but some people go faster and some go slower. Is there any math that describes the likelihood that faster vehicles will overtake slower vehicles at ""choke points"" (points where oncoming traffic makes passing impossible)? (Assume a straight, flat road where safe passing is always allowed.) EDIT: Choke points are points where oncoming cars make it impossible to pass without the overtaking vehicle having to slow down and wait for the oncoming car (or cars) to pass. Obviously, the answer has to be some kind of curve, because if there is only one vehicle on the road the probability is 0 that a choke point will be encountered, and if the road is completely filled with vehicles in both directions (or even one) the probability is 1 that a choke point will be encountered at any given time. Sorry if this is a stupid question. But it seems like there should be a way to express this mathematically. EDIT 2: Limiting the scope of the problem Thanks to Mike Spivey, and I hope this helps narrow the problem so that may be in some way answerable. If not, I'll just declare defeat and retire from the field. Let's say that we have two cars going in one direction: a slow vehicle (Vehicle A) traveling at 30mph and a faster vehicle (Vehicle B) traveling at 60mph. At the start of the problem the A is somewhere between mile 2 and mile 4 on the 10-mile road, and B is at mile 0. Additionally, there will be four oncoming vehicles randomly distributed, and these vehicles are randomly traveling at 30 or 60mph. The overtaking vehicle requires .5 miles of ""clear"" space to pass safely if the oncoming vehicle is traveling at 60mph, and .25 if it is traveling at 30mph. Assume further that the car lengths do not matter, but that a ""choke point"" (or bottleneck, if you prefer) is not reached until B gets within .05 miles of the rear bumper of A, at which point B has to pass A or decelerate. We will call the latter condition a ""deceleration event,"" (DE) and I would like to be able to calculate the probability that at least one DE will occur for Vehicle A along the 10-mile route. Perhaps this clarification is still insufficient to render the problem solvable, but I appreciate anyone taking the time to consider it.",,"['probability', 'mathematical-modeling']"
82,What are the chances of finding all the balls?,What are the chances of finding all the balls?,,"Given $x$ distinguishable balls (say they have different colors), sample with replacement repeatedly until all the balls that have been sampled have been sampled at least twice.  I am interested in $$P(\text{number of distinct balls sampled} = x).$$ That is, the probability that you would have seen all the balls when you stop. You can of course stop before then, if for example you sample the same ball the first two times and $x > 1$ . @leonbloy gives the different values of $x$ from $2$ to $20$ : 2   0.5 3   0.4444444 4   0.4479167 5   0.4689333 6   0.4958611 7   0.5240295 8   0.5512568 9   0.5765074 10  0.5993544 11  0.6197125 12  0.6376863 13  0.6534778 14  0.6673292 15  0.6794889 16  0.6901919 17  0.6996503 18  0.7080495 19  0.7155483 20  0.7222809 Calculating by hand, the correct probability for $x = 3$ is in fact $4/9$ . Bounty Is it possible to compute what the probabilities are in general, either exactly or at least what they are asymptotic to, and do they tend to $1$ as $x$ tends to infinity?","Given distinguishable balls (say they have different colors), sample with replacement repeatedly until all the balls that have been sampled have been sampled at least twice.  I am interested in That is, the probability that you would have seen all the balls when you stop. You can of course stop before then, if for example you sample the same ball the first two times and . @leonbloy gives the different values of from to : 2   0.5 3   0.4444444 4   0.4479167 5   0.4689333 6   0.4958611 7   0.5240295 8   0.5512568 9   0.5765074 10  0.5993544 11  0.6197125 12  0.6376863 13  0.6534778 14  0.6673292 15  0.6794889 16  0.6901919 17  0.6996503 18  0.7080495 19  0.7155483 20  0.7222809 Calculating by hand, the correct probability for is in fact . Bounty Is it possible to compute what the probabilities are in general, either exactly or at least what they are asymptotic to, and do they tend to as tends to infinity?",x P(\text{number of distinct balls sampled} = x). x > 1 x 2 20 x = 3 4/9 1 x,['probability']
83,Probability distribution vs. probability mass function (PMF): what is the difference between the terms? [duplicate],Probability distribution vs. probability mass function (PMF): what is the difference between the terms? [duplicate],,"This question already has answers here : Concept of Probability distribution (3 answers) Closed 2 years ago . Consider a discrete case. PMF is the probability each value of random variable gets. So, for example, X ~ Poisson(2). I plot these probabilities (below), so I can say that I show the PMF of X. But on the other hand I show the distribution of X. For example, I can say whether the distribution I have is symmetrical or not. So, what is the difference between probability distribution and PMF terms (in discrete case)? Below I also bring the definitions from Wikipedia, but it is not helpful either. Many thanks! A probability mass function (pmf) is a function that gives the probability that a discrete random variable is exactly equal to some value. A probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment.","This question already has answers here : Concept of Probability distribution (3 answers) Closed 2 years ago . Consider a discrete case. PMF is the probability each value of random variable gets. So, for example, X ~ Poisson(2). I plot these probabilities (below), so I can say that I show the PMF of X. But on the other hand I show the distribution of X. For example, I can say whether the distribution I have is symmetrical or not. So, what is the difference between probability distribution and PMF terms (in discrete case)? Below I also bring the definitions from Wikipedia, but it is not helpful either. Many thanks! A probability mass function (pmf) is a function that gives the probability that a discrete random variable is exactly equal to some value. A probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment.",,"['probability', 'probability-distributions', 'terminology']"
84,Machine Learning: Good book for learning Probability and statistics? [duplicate],Machine Learning: Good book for learning Probability and statistics? [duplicate],,"This question already has answers here : What is the best book to learn probability? (13 answers) Closed 8 months ago . I am trying to learn machine learning and looking for a good book to understand probability and statistics from machine learning point of view and for the sake of understanding probability. Though I have studied probability in the past, I am still having a hard time to solve homework questions from Stats 110 course by Blitzstein. I think I am missing many concepts in probability theory as I didn't pay attention in my Probability classes. So what I need is a good book which can kind of introduce me and at the same time refresh some concept left in my brain and provides good intuitive explanation of questions and their answers and provide very good but few important exercises to understand all the concepts. I checked many questions like this and I am still in a dilemma which book to consider: 1 - An Introduction to Probability Theory and Its Applications - William Feller 2 - A First Course in Probability - Sheldon Ross Which one would you recommend? Or if you have other good book in mind please do let me know.","This question already has answers here : What is the best book to learn probability? (13 answers) Closed 8 months ago . I am trying to learn machine learning and looking for a good book to understand probability and statistics from machine learning point of view and for the sake of understanding probability. Though I have studied probability in the past, I am still having a hard time to solve homework questions from Stats 110 course by Blitzstein. I think I am missing many concepts in probability theory as I didn't pay attention in my Probability classes. So what I need is a good book which can kind of introduce me and at the same time refresh some concept left in my brain and provides good intuitive explanation of questions and their answers and provide very good but few important exercises to understand all the concepts. I checked many questions like this and I am still in a dilemma which book to consider: 1 - An Introduction to Probability Theory and Its Applications - William Feller 2 - A First Course in Probability - Sheldon Ross Which one would you recommend? Or if you have other good book in mind please do let me know.",,"['probability', 'probability-theory', 'statistics', 'machine-learning']"
85,Why are random variables measurable?,Why are random variables measurable?,,Why do we require random variables to be measurable? The only reason I can think of is being able to identify which event happened knowing that the value of random variable (and therefore we can also calculate the probability of random variable assuming that particular value)? This is what the definition of random variable basically says where it requires the random variable function to be measurable. Do the reasons I gave above make sense?,Why do we require random variables to be measurable? The only reason I can think of is being able to identify which event happened knowing that the value of random variable (and therefore we can also calculate the probability of random variable assuming that particular value)? This is what the definition of random variable basically says where it requires the random variable function to be measurable. Do the reasons I gave above make sense?,,"['probability', 'measure-theory', 'random-variables']"
86,Using two coins to select a person fairly.,Using two coins to select a person fairly.,,"Good evening, I would like to know if the solution to this problem, I know it can be solved because it is from  a Hungarian Olympiad. The problem is as follows: You need to fairly select a person between $n$ persons using two unfair coins for which you get to decide the odds. This is simple if you label the people $1$ through $n$ in binary and then flip $\lceil \log_2 n \rceil$  coins to get a number in binary. If the number corresponds to a person that person gets selected, otherwise repeat the process again. The problem here is that we need to give a bound for the number of flips before hand. I don't really know how to solve the problem now. Thank you very much in advance. Regards.","Good evening, I would like to know if the solution to this problem, I know it can be solved because it is from  a Hungarian Olympiad. The problem is as follows: You need to fairly select a person between $n$ persons using two unfair coins for which you get to decide the odds. This is simple if you label the people $1$ through $n$ in binary and then flip $\lceil \log_2 n \rceil$  coins to get a number in binary. If the number corresponds to a person that person gets selected, otherwise repeat the process again. The problem here is that we need to give a bound for the number of flips before hand. I don't really know how to solve the problem now. Thank you very much in advance. Regards.",,"['probability', 'combinatorics', 'contest-math']"
87,Strong Markov property of Brownian motion,Strong Markov property of Brownian motion,,"I was able to understand Brownian Motion $\{B(t):t\geq0\}$ has Strong Markov Property i.e. For any stopping time $\tau$, $P(B(t+\tau)\leq y | \mathcal{F}_{\tau})=P(B(t+\tau)\leq y|B(\tau))$ a.s. , $y \in \mathbb{R}$. I want to prove the following assertions $\cdot$ $\hat{B}(t):=B(\tau+t)-B(\tau)$, $t\geq0$ is independent of $\mathcal{F}_{\tau}$ $\cdot$ $0\leq \forall s < \forall t$,  $\hat{B}(t)-\hat{B}(s)$ has the normal distribution of $N(0, t-s)$. $\cdot$ $0\leq \forall s < \forall t$,  $\hat{B}(t)-\hat{B}(s)$ is independent of $\hat{B}(u),\,u\in[0,s]$ How do I use Strong Markov property? Please teach me. My Brownian motion definition is as follows: $\cdot$ $\forall \omega \in \Omega$, $t \mapsto B(t,\omega)$ is continuous. $\cdot$ $0\leq \forall s < \forall t$,  $B(t)-B(s)$ has the normal distribution of $N(0, t-s)$. $\cdot$ $0\leq \forall s < \forall t$,  $B(t)-B(s)$ is independ of $B(u),\,u\in[0,s]$.","I was able to understand Brownian Motion $\{B(t):t\geq0\}$ has Strong Markov Property i.e. For any stopping time $\tau$, $P(B(t+\tau)\leq y | \mathcal{F}_{\tau})=P(B(t+\tau)\leq y|B(\tau))$ a.s. , $y \in \mathbb{R}$. I want to prove the following assertions $\cdot$ $\hat{B}(t):=B(\tau+t)-B(\tau)$, $t\geq0$ is independent of $\mathcal{F}_{\tau}$ $\cdot$ $0\leq \forall s < \forall t$,  $\hat{B}(t)-\hat{B}(s)$ has the normal distribution of $N(0, t-s)$. $\cdot$ $0\leq \forall s < \forall t$,  $\hat{B}(t)-\hat{B}(s)$ is independent of $\hat{B}(u),\,u\in[0,s]$ How do I use Strong Markov property? Please teach me. My Brownian motion definition is as follows: $\cdot$ $\forall \omega \in \Omega$, $t \mapsto B(t,\omega)$ is continuous. $\cdot$ $0\leq \forall s < \forall t$,  $B(t)-B(s)$ has the normal distribution of $N(0, t-s)$. $\cdot$ $0\leq \forall s < \forall t$,  $B(t)-B(s)$ is independ of $B(u),\,u\in[0,s]$.",,"['probability', 'stochastic-processes', 'brownian-motion', 'markov-process']"
88,Reciprocal of a Binomial,Reciprocal of a Binomial,,"I'm wondering if there is any formula to do this. Suppose $B$~$B(N,p)$, and hence we have $E[B]=Np,D[B]=Np(1-p)$. I'm just wondering how to do $E[\frac{1}{c+B}]$,for some $c>0$? Thanks.","I'm wondering if there is any formula to do this. Suppose $B$~$B(N,p)$, and hence we have $E[B]=Np,D[B]=Np(1-p)$. I'm just wondering how to do $E[\frac{1}{c+B}]$,for some $c>0$? Thanks.",,"['probability', 'random-variables']"
89,Generalization of the Sultan's dowry problem,Generalization of the Sultan's dowry problem,,"We know the solution of the Sultan's dowry problem : To reject the first $n/e$ candidates and then to select the first who exceeds the best of the sample. How to find the best strategy if we want select the 2, or 3, or $k$ best instead of only one?","We know the solution of the Sultan's dowry problem : To reject the first $n/e$ candidates and then to select the first who exceeds the best of the sample. How to find the best strategy if we want select the 2, or 3, or $k$ best instead of only one?",,"['probability', 'optimization']"
90,Estimating $\bigg|\mathbb{P}\bigg(\sum\limits_{j=1}^n\theta_jX_j\leq x\bigg)-\mathbb{P}\bigg(\sum\limits_{j=1}^{n-1}\theta_jX_j\leq x\bigg)\bigg|$,Estimating,\bigg|\mathbb{P}\bigg(\sum\limits_{j=1}^n\theta_jX_j\leq x\bigg)-\mathbb{P}\bigg(\sum\limits_{j=1}^{n-1}\theta_jX_j\leq x\bigg)\bigg|,"Suppose that $X_1, ... , X_n$ are independent, identically-distributed random variables and $\theta_1,...,\theta_n$ are some real coefficients. Then, for given $x\in\mathbb{R}$ , how can we estimate the difference $$\bigg|\mathbb{P}\bigg(\sum\limits_{j=1}^n\theta_jX_j\leq x\bigg)-\mathbb{P}\bigg(\sum\limits_{j=1}^{n-1}\theta_jX_j\leq x\bigg)\bigg|$$ (note that the second sum has $n-1$ terms). I think that if we take the last coefficient $\theta_n$ to be small, then the above difference should also be small. I, however, do not know how to estimate that difference in terms of $\theta_n$ . $\textbf{Update}:$ Although there are already 2 answers given below, I am wondering whether it is possible to derive a formula that explicitly estimates the above difference in terms of $\theta_n$ so that by taking $\theta_n$ to be small it can be clearly seen that the difference above is also small. If needed, additional conditions on random variables $X_i$ may be imposed (e.g., bounded moments of given order).","Suppose that are independent, identically-distributed random variables and are some real coefficients. Then, for given , how can we estimate the difference (note that the second sum has terms). I think that if we take the last coefficient to be small, then the above difference should also be small. I, however, do not know how to estimate that difference in terms of . Although there are already 2 answers given below, I am wondering whether it is possible to derive a formula that explicitly estimates the above difference in terms of so that by taking to be small it can be clearly seen that the difference above is also small. If needed, additional conditions on random variables may be imposed (e.g., bounded moments of given order).","X_1, ... , X_n \theta_1,...,\theta_n x\in\mathbb{R} \bigg|\mathbb{P}\bigg(\sum\limits_{j=1}^n\theta_jX_j\leq x\bigg)-\mathbb{P}\bigg(\sum\limits_{j=1}^{n-1}\theta_jX_j\leq x\bigg)\bigg| n-1 \theta_n \theta_n \textbf{Update}: \theta_n \theta_n X_i","['probability', 'probability-theory', 'inequality']"
91,A wavy histogram from a maximum likelihood algorithm,A wavy histogram from a maximum likelihood algorithm,,"This question is based on a Puzzling Stack question I answered. Suppose you have a loaded $10$ -sided die that gives one value with probability $\frac7{25}$ and the rest with probability $\frac2{25}$ each, but you do not know the favoured value. A maximum likelihood method to determine this favoured value is as follows: Set probabilities $p_1=\dots=p_{10}=\frac1{10}$ , where $p_i$ is the likelihood of $i$ being the favoured value. Roll the die repeatedly; for each value $c$ that comes up multiply $p_c$ by $3.5$ , the ratio of probabilities of a favoured face to an unfavoured face. Normalise after each update and stop when one $p_i$ becomes dominant enough. This strategy is quite efficient, for simulating it $4121000$ times gave a mean of about $35.47$ rolls until one $p_i$ exceeded $0.99$ and a median of $32$ rolls. The histogram of rolls needed, however, looks very odd with its wavy top: Is there any logical explanation for the histogram's peculiar shape? The number of simulations I made certainly seems high enough to rule out sample size as an explanation. Here is the histogram corresponding to a d3 with one value twice as likely ( $1/2$ ) to come up as the other two ( $1/4$ ): Clearly there is a dependence on the number of possibilities, but what kind?","This question is based on a Puzzling Stack question I answered. Suppose you have a loaded -sided die that gives one value with probability and the rest with probability each, but you do not know the favoured value. A maximum likelihood method to determine this favoured value is as follows: Set probabilities , where is the likelihood of being the favoured value. Roll the die repeatedly; for each value that comes up multiply by , the ratio of probabilities of a favoured face to an unfavoured face. Normalise after each update and stop when one becomes dominant enough. This strategy is quite efficient, for simulating it times gave a mean of about rolls until one exceeded and a median of rolls. The histogram of rolls needed, however, looks very odd with its wavy top: Is there any logical explanation for the histogram's peculiar shape? The number of simulations I made certainly seems high enough to rule out sample size as an explanation. Here is the histogram corresponding to a d3 with one value twice as likely ( ) to come up as the other two ( ): Clearly there is a dependence on the number of possibilities, but what kind?",10 \frac7{25} \frac2{25} p_1=\dots=p_{10}=\frac1{10} p_i i c p_c 3.5 p_i 4121000 35.47 p_i 0.99 32 1/2 1/4,"['probability', 'probability-distributions', 'dice', 'maximum-likelihood']"
92,Why does the sum of $N$ Bernoulli random variables have a Poisson distribution if $N$ is Poisson distributed?,Why does the sum of  Bernoulli random variables have a Poisson distribution if  is Poisson distributed?,N N,"Assume those $N$ Bernoulli random variables are i.i.d. with probability $p$, where $N \sim \operatorname{Poisson}(\lambda)$. The finite sum of them is Poisson distributed with $p\lambda$. I read a book claims that but without proof.","Assume those $N$ Bernoulli random variables are i.i.d. with probability $p$, where $N \sim \operatorname{Poisson}(\lambda)$. The finite sum of them is Poisson distributed with $p\lambda$. I read a book claims that but without proof.",,"['probability', 'probability-theory', 'statistics', 'measure-theory', 'random-variables']"
93,Calculating the Second Moment of a Binomial Random Variable,Calculating the Second Moment of a Binomial Random Variable,,"The first step in calculating the variance of a Binomial Random Variable is calculating the second moment. I have no idea as to how the last two steps have happened. Why is a n(n-1)p^2 outside the first summation and a similar expression outside the second? Also, how did the expression turn out to be the last equation?","The first step in calculating the variance of a Binomial Random Variable is calculating the second moment. I have no idea as to how the last two steps have happened. Why is a n(n-1)p^2 outside the first summation and a similar expression outside the second? Also, how did the expression turn out to be the last equation?",,"['probability', 'binomial-distribution']"
94,Average minimum distance between $n$ points generate i.i.d. uniformly in the ball,Average minimum distance between  points generate i.i.d. uniformly in the ball,n,"Let $U \in \mathbb{R}^3$ be distributed uniformly in the Ball in $\mathbb{R}^3$ centered at zero.   That is $U \sim  f_U(u)= \frac{1}{ \frac{4}{3} \pi R^3}$  for all $\|u\|\le R$  where $R$ is the radius of the ball. Now suppose we generate $n$ points i.i.d. according distribution of   $U$. My questions is: Can we compute the expected minimum distance between the generated points, that is \begin{align} E\left[ \min_{i,j\in \{1,2,,,n\}} \| U_i-U_j\| \right], \end{align}  where  $\| U_i-U_j\|$ is Euclidean distance. This question is related to a number of other questions.  For example, Average distance between two random points in a square Average minimum distance between $n$ points generate i.i.d. with uniform dist. I feel that this question should have been addressed before but not sure where to look. There is a conjecture that the minimum distance behaves as $\frac{1}{n^{\frac{2}{3}}}$ but I am not sure how to show this? Update See a recently add proof of this statement for the case when 'border' effects are negligible. That is the answer is asymptotic.  The question know is how to take into account the border effects? Thank you very much.","Let $U \in \mathbb{R}^3$ be distributed uniformly in the Ball in $\mathbb{R}^3$ centered at zero.   That is $U \sim  f_U(u)= \frac{1}{ \frac{4}{3} \pi R^3}$  for all $\|u\|\le R$  where $R$ is the radius of the ball. Now suppose we generate $n$ points i.i.d. according distribution of   $U$. My questions is: Can we compute the expected minimum distance between the generated points, that is \begin{align} E\left[ \min_{i,j\in \{1,2,,,n\}} \| U_i-U_j\| \right], \end{align}  where  $\| U_i-U_j\|$ is Euclidean distance. This question is related to a number of other questions.  For example, Average distance between two random points in a square Average minimum distance between $n$ points generate i.i.d. with uniform dist. I feel that this question should have been addressed before but not sure where to look. There is a conjecture that the minimum distance behaves as $\frac{1}{n^{\frac{2}{3}}}$ but I am not sure how to show this? Update See a recently add proof of this statement for the case when 'border' effects are negligible. That is the answer is asymptotic.  The question know is how to take into account the border effects? Thank you very much.",,"['probability', 'geometry', 'probability-theory', 'expectation']"
95,Can you create non transitive dice for any finite graph?,Can you create non transitive dice for any finite graph?,,"Let's say you have a finite directed graph, with no two nodes that point at each other. Can we assign each node a dice, so that each node beats the node it is pointing at. This is easy for acyclic graphs, but it is possible for some non-acyclic graphs: see Nontransitive dice . By dice, I mean any probability distribution the natural numbers (including those of infinite support). A dice beats another if the probability of it being higher than the other is more than a half. Can we assign nontransitive dice to an arbitrary graph? Also: Can this still work with certain infinite graphs?","Let's say you have a finite directed graph, with no two nodes that point at each other. Can we assign each node a dice, so that each node beats the node it is pointing at. This is easy for acyclic graphs, but it is possible for some non-acyclic graphs: see Nontransitive dice . By dice, I mean any probability distribution the natural numbers (including those of infinite support). A dice beats another if the probability of it being higher than the other is more than a half. Can we assign nontransitive dice to an arbitrary graph? Also: Can this still work with certain infinite graphs?",,"['probability', 'probability-theory', 'graph-theory', 'probability-distributions', 'dice']"
96,Sharper Lower Bounds for Binomial/Chernoff Tails,Sharper Lower Bounds for Binomial/Chernoff Tails,,"The Wikipedia page for the Binomial Distribution states the following lower bound, which I suppose can also be generalized as a general Chernoff lower bound. $$\Pr(X \le k) \geq \frac{1}{(n+1)^2} \exp\left(-nD\left(\frac{k}{n}\left|\right|p\right)\right) \quad\quad\mbox{if }p<\frac{k}{n}<1$$ Clearly this is tight up to the $(n+1)^{-2}$ factor. However computationally it seems that $(n+1)^{-1}$ would be tight as well. Even (n+1)^{-.7} seems to be fine. It's not as easy to find lower bounds for tails as it is upper, but for the Normal Distribution there seems to be a standard bound : $$\int_x^\infty e^{-t^2/2}dt \ge (1/x-1/x^3)e^{-x^2/2}$$ My question is thus, is the $\frac{1}{(n+1)^2}$ factor the best known? Or can $\frac{1}{n+1}$ be shown to be sufficient? Update: Here is the region in which the conjecture holds numerically, by Mathematica:","The Wikipedia page for the Binomial Distribution states the following lower bound, which I suppose can also be generalized as a general Chernoff lower bound. $$\Pr(X \le k) \geq \frac{1}{(n+1)^2} \exp\left(-nD\left(\frac{k}{n}\left|\right|p\right)\right) \quad\quad\mbox{if }p<\frac{k}{n}<1$$ Clearly this is tight up to the $(n+1)^{-2}$ factor. However computationally it seems that $(n+1)^{-1}$ would be tight as well. Even (n+1)^{-.7} seems to be fine. It's not as easy to find lower bounds for tails as it is upper, but for the Normal Distribution there seems to be a standard bound : $$\int_x^\infty e^{-t^2/2}dt \ge (1/x-1/x^3)e^{-x^2/2}$$ My question is thus, is the $\frac{1}{(n+1)^2}$ factor the best known? Or can $\frac{1}{n+1}$ be shown to be sufficient? Update: Here is the region in which the conjecture holds numerically, by Mathematica:",,"['probability', 'inequality', 'binomial-distribution', 'distribution-tails', 'concentration-of-measure']"
97,$n$ balls are thrown randomly into $k$ bins - how many are empty?,balls are thrown randomly into  bins - how many are empty?,n k,"A large number of variants of this question were already asked here, including these - one , two , which are close, but none seem to answer my question. Assume that $n$ balls are thrown randomly and independently into $k$ bins. What is the probability of finding $x$ empty bins? What is the expectation of the number of empty bins?","A large number of variants of this question were already asked here, including these - one , two , which are close, but none seem to answer my question. Assume that balls are thrown randomly and independently into bins. What is the probability of finding empty bins? What is the expectation of the number of empty bins?",n k x,"['probability', 'combinatorics', 'probability-theory', 'expectation', 'balls-in-bins']"
98,"Are two random vectors independent, iff every pair of components from each vector are independent?","Are two random vectors independent, iff every pair of components from each vector are independent?",,"Let $X$ and $Y$ be two random vectors in $\mathbb R^n$. Are $X$ and $Y$  independent, iff any component $X_i$ of $X$ and any component $Y_j$ of $Y$ are independent? If not, is it true when $X$ and $Y$ are both normally distributed? If not, is it true when $X$ and $Y$ are jointly normal distributed? Thanks.","Let $X$ and $Y$ be two random vectors in $\mathbb R^n$. Are $X$ and $Y$  independent, iff any component $X_i$ of $X$ and any component $Y_j$ of $Y$ are independent? If not, is it true when $X$ and $Y$ are both normally distributed? If not, is it true when $X$ and $Y$ are jointly normal distributed? Thanks.",,"['probability', 'probability-theory']"
99,When to use Total Probability Rule and Bayes' Theorem.,When to use Total Probability Rule and Bayes' Theorem.,,"Consider the following information about travelers on vacation: $40$ % check work email, $30$ % use a cell phone, $25$ % bring a laptop with them, $23$ % both check work email and use a cell phone, and $51$ % neither check work email nor use a cell phone nor bring a laptop. In addition $88/100$ who bring a laptop also check work email, and $70/100$ who use a cell phone also bring a laptop. What is the probability that someone who brings a laptop on vacation also uses a cell phone? I let $A$ represent check work email, $B$ represent use cell phone, and $C$ represent brings laptop. I have the following probabilities: $$\begin{align}P(A)&=.4, \\P(B)&=.3, \\P(C)&=.25,\\ P(A\cap B)&=.23, \\P(A\cup B\cup C)&=.49,\\ P(A \mid C)&=.88, \\P(C \mid B)&=.7\end{align}$$ I found a solution online saying to use Bayes' Theorem to solve this part of the problem but I do not understand why to use Bayes' Theorem. Here is a picture to the solution I am referring to: Bayes' Theorem does not look like what the solution says to use. In my textbook, the theorem looks like this: Did the person that wrote the solution simplify something? It does not look like either of these two forms. Also, for problems like these, is there a general rule on when to use Bayes' Theorem and the rule for Total Probability? I cannot figure out when to use what.","Consider the following information about travelers on vacation: % check work email, % use a cell phone, % bring a laptop with them, % both check work email and use a cell phone, and % neither check work email nor use a cell phone nor bring a laptop. In addition who bring a laptop also check work email, and who use a cell phone also bring a laptop. What is the probability that someone who brings a laptop on vacation also uses a cell phone? I let represent check work email, represent use cell phone, and represent brings laptop. I have the following probabilities: I found a solution online saying to use Bayes' Theorem to solve this part of the problem but I do not understand why to use Bayes' Theorem. Here is a picture to the solution I am referring to: Bayes' Theorem does not look like what the solution says to use. In my textbook, the theorem looks like this: Did the person that wrote the solution simplify something? It does not look like either of these two forms. Also, for problems like these, is there a general rule on when to use Bayes' Theorem and the rule for Total Probability? I cannot figure out when to use what.","40 30 25 23 51 88/100 70/100 A B C \begin{align}P(A)&=.4, \\P(B)&=.3, \\P(C)&=.25,\\ P(A\cap B)&=.23, \\P(A\cup B\cup C)&=.49,\\ P(A \mid C)&=.88, \\P(C \mid B)&=.7\end{align}","['probability', 'bayes-theorem']"
