,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Convergence of the series $\sum\limits_{n=1}^{\infty}\frac{\cos(\alpha\sqrt{n})}{n^q}$,Convergence of the series,\sum\limits_{n=1}^{\infty}\frac{\cos(\alpha\sqrt{n})}{n^q},"Determine for which real values of $\alpha$ and $q$ the following series converges $\sum\limits_{n=1}^{\infty}\frac{\cos(\alpha\sqrt{n})}{n^q}$? So far I managed to prove that 1) for $q\leqslant0,\alpha\in\mathbb{R}$ the series diverges; 2) for $q>1,\alpha\in\mathbb{R}$ the series converges absolutely; 3) for $0<q\leqslant 1,\alpha=0$ the series diverges. How to approach the problem for the case $0<q\leqslant 1,\alpha\neq0$?","Determine for which real values of $\alpha$ and $q$ the following series converges $\sum\limits_{n=1}^{\infty}\frac{\cos(\alpha\sqrt{n})}{n^q}$? So far I managed to prove that 1) for $q\leqslant0,\alpha\in\mathbb{R}$ the series diverges; 2) for $q>1,\alpha\in\mathbb{R}$ the series converges absolutely; 3) for $0<q\leqslant 1,\alpha=0$ the series diverges. How to approach the problem for the case $0<q\leqslant 1,\alpha\neq0$?",,"['calculus', 'sequences-and-series']"
1,Shorter way to calculate this limit,Shorter way to calculate this limit,,I want to calculate this (without L'Hospital) : $$\lim_{x \to 0} \frac{\sqrt{1+ \tan x} - \sqrt{1+ \sin x}}{x^3}$$ I already solved it in a looooong way: \begin{align} \frac{\sqrt{1+ \tan x} - \sqrt{1+ \sin x}}{x^3} &= \frac{\tan x - \sin x}{x^3} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\frac{\sin x}{\cos x} - \sin x}{x^3} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x (1- \cos x )}{x^3 \cos x} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x}{x} \frac{1- \cos x }{x^2 \cos x} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x}{x} \frac{(1- \cos x)(1+\cos x) }{x^2 \cos x \ (1+\cos x)} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x}{x} \frac{1- \cos^2 x }{x^2} \frac{1}{\cos x \ (1 + \cos x)} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x}{x} \frac{\sin^2 x }{x^2} \frac{1}{\cos x \ (1 + \cos x)} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= 1 \cdot 1^2 \cdot \frac{1}{1 \cdot (1 +1)} \frac{1}{\sqrt{1+0}+\sqrt{1+0}} \tag{as $x \to 0$} \\ \\ &= \frac 1 4 \end{align} Is there a shorter way? EDIT: I am wondering whether there is a trick like $x= \arctan u^4$ etc.,I want to calculate this (without L'Hospital) : $$\lim_{x \to 0} \frac{\sqrt{1+ \tan x} - \sqrt{1+ \sin x}}{x^3}$$ I already solved it in a looooong way: \begin{align} \frac{\sqrt{1+ \tan x} - \sqrt{1+ \sin x}}{x^3} &= \frac{\tan x - \sin x}{x^3} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\frac{\sin x}{\cos x} - \sin x}{x^3} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x (1- \cos x )}{x^3 \cos x} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x}{x} \frac{1- \cos x }{x^2 \cos x} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x}{x} \frac{(1- \cos x)(1+\cos x) }{x^2 \cos x \ (1+\cos x)} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x}{x} \frac{1- \cos^2 x }{x^2} \frac{1}{\cos x \ (1 + \cos x)} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= \frac{\sin x}{x} \frac{\sin^2 x }{x^2} \frac{1}{\cos x \ (1 + \cos x)} \frac{1}{\sqrt{1+ \tan x} + \sqrt{1+ \sin x}}  \\ \\ &= 1 \cdot 1^2 \cdot \frac{1}{1 \cdot (1 +1)} \frac{1}{\sqrt{1+0}+\sqrt{1+0}} \tag{as $x \to 0$} \\ \\ &= \frac 1 4 \end{align} Is there a shorter way? EDIT: I am wondering whether there is a trick like $x= \arctan u^4$ etc.,,"['calculus', 'limits', 'limits-without-lhopital']"
2,How to solve this system of exponential equations?,How to solve this system of exponential equations?,,"Solve the following system of equations ($x,y \in \Bbb R$): $$\begin{cases}  3^{x+3y-2} + 6\cdot 3^{y^2+4x-2} &=5^{5y-3x} + 2\cdot 3^{y^2-2y+1}\\  1+2\sqrt{x+y-1} &=3\sqrt[3]{3y-2x}. \end{cases}$$ I think about it but I still have no solution... :( Since the second equation, I write $x+y \ge 1$ then $y \ge \dfrac{2}{3}x.$ So $y \ge \dfrac{2}{5}$. I rewrite the 1st equation: \begin{align*}  3^{x+3y-2} + 6\cdot 3^{y^2+4x-2} &=5^{5y-3x} + 2\cdot 3^{y^2-2y+1}\\ \iff 3^{x+3y-2} + 6\cdot 3^{y^2+4x-2}& \le 5^{5y-3x} -3^{5y-3x}+3^{5y-3x} + 2\cdot 3^{y^2+2y+1}\\ \iff (3^{x+3y-2}-3^{5y-3x})(1+2\cdot 3^{y^2+3x-3y+1})& \le 5^{5y-3x} -3^{5y-3x}\\ \iff (9^{2x-y-1}-1)\underset{>0}{\underbrace{(1+2\cdot 3^{y^2+3x-3y+1}})}&\le \left (\dfrac{5}{3}  \right )^{5y-3x}-1. \end{align*} Now, I have trouble.... Can anyone post the roots of this system of exponential equations. I really appreciate if some one can help me. Thanks!","Solve the following system of equations ($x,y \in \Bbb R$): $$\begin{cases}  3^{x+3y-2} + 6\cdot 3^{y^2+4x-2} &=5^{5y-3x} + 2\cdot 3^{y^2-2y+1}\\  1+2\sqrt{x+y-1} &=3\sqrt[3]{3y-2x}. \end{cases}$$ I think about it but I still have no solution... :( Since the second equation, I write $x+y \ge 1$ then $y \ge \dfrac{2}{3}x.$ So $y \ge \dfrac{2}{5}$. I rewrite the 1st equation: \begin{align*}  3^{x+3y-2} + 6\cdot 3^{y^2+4x-2} &=5^{5y-3x} + 2\cdot 3^{y^2-2y+1}\\ \iff 3^{x+3y-2} + 6\cdot 3^{y^2+4x-2}& \le 5^{5y-3x} -3^{5y-3x}+3^{5y-3x} + 2\cdot 3^{y^2+2y+1}\\ \iff (3^{x+3y-2}-3^{5y-3x})(1+2\cdot 3^{y^2+3x-3y+1})& \le 5^{5y-3x} -3^{5y-3x}\\ \iff (9^{2x-y-1}-1)\underset{>0}{\underbrace{(1+2\cdot 3^{y^2+3x-3y+1}})}&\le \left (\dfrac{5}{3}  \right )^{5y-3x}-1. \end{align*} Now, I have trouble.... Can anyone post the roots of this system of exponential equations. I really appreciate if some one can help me. Thanks!",,"['calculus', 'algebra-precalculus', 'systems-of-equations', 'problem-solving']"
3,Is there an English version of Johann Bernoulli's integral calculus lectures?,Is there an English version of Johann Bernoulli's integral calculus lectures?,,"The name of lectures of integral calculus written by Johann or Jeans Bernoulli (he is called by both names as far as I know) might be "" lecciones mathematicæ de calculo integral""; I must mention that, this is not the complete name of book, but a part of the name; as so many editions have come, it is difficult to say the name. I searched for one day for the english translation, I couldn't even find the english title of his book on integral calculus. I found his books called Opera Omnia, in latin and French , which contains these lectures, but onceagain, I couldn't even find a single english edition. I am really in need of his book, as he was the first to study lebnizian calculus; ofcourse Jackob Bernoulli also studied with Johann Bernoulli. I want to know nothing but the title of english edition of his calculus lectures and the name of the translator of it, if possible, even the downloadable version of it. I already have english editon of L'Hopital's book on differential calculus called "" Analyse des Infinements Petits "" (claimed to be the first textbook on differential calculus) which contains Johann Bernoulli's lectures on differential calculus titled ""Lectiones de Calculo Differentials"", but it doesn't contain lectures on integral calculus. If possible can anyone also point out some of the oldest books on ""integral calculus"". Edit (6/6/17): Google's ""Play Books"" app has translator, which translates books in most of the languages being offline. This is the optimal solution I have found till now.","The name of lectures of integral calculus written by Johann or Jeans Bernoulli (he is called by both names as far as I know) might be "" lecciones mathematicæ de calculo integral""; I must mention that, this is not the complete name of book, but a part of the name; as so many editions have come, it is difficult to say the name. I searched for one day for the english translation, I couldn't even find the english title of his book on integral calculus. I found his books called Opera Omnia, in latin and French , which contains these lectures, but onceagain, I couldn't even find a single english edition. I am really in need of his book, as he was the first to study lebnizian calculus; ofcourse Jackob Bernoulli also studied with Johann Bernoulli. I want to know nothing but the title of english edition of his calculus lectures and the name of the translator of it, if possible, even the downloadable version of it. I already have english editon of L'Hopital's book on differential calculus called "" Analyse des Infinements Petits "" (claimed to be the first textbook on differential calculus) which contains Johann Bernoulli's lectures on differential calculus titled ""Lectiones de Calculo Differentials"", but it doesn't contain lectures on integral calculus. If possible can anyone also point out some of the oldest books on ""integral calculus"". Edit (6/6/17): Google's ""Play Books"" app has translator, which translates books in most of the languages being offline. This is the optimal solution I have found till now.",,"['calculus', 'reference-request', 'soft-question', 'math-history']"
4,Substitution for limits [duplicate],Substitution for limits [duplicate],,"This question already has answers here : Change of Variables in Limits (Part 1) (3 answers) Closed 8 years ago . How does substitution for limits exactly work? I see often answers that use the substitution $t=\frac1x$, then changing $x\rightarrow\infty$ to  $t\rightarrow0^+$. I have seen this question , this appears to solve my question in the finite case. How does it work when going to infinty? Books I'm using don't cover substitutions, but they seem very useful.","This question already has answers here : Change of Variables in Limits (Part 1) (3 answers) Closed 8 years ago . How does substitution for limits exactly work? I see often answers that use the substitution $t=\frac1x$, then changing $x\rightarrow\infty$ to  $t\rightarrow0^+$. I have seen this question , this appears to solve my question in the finite case. How does it work when going to infinty? Books I'm using don't cover substitutions, but they seem very useful.",,"['calculus', 'limits', 'substitution']"
5,What's the relation between different antiderivatives?,What's the relation between different antiderivatives?,,"If a function $f(x)$ has different forms of antiderivatives: $\frac { d }{ dx } { F }_{ 1 }(x)=f(x)$ $\frac { d }{ dx } { F }_{ 2 }(x)=f(x)$ What's the relationship between $F_1$ and $F_2$, is that ${F}_{1}(x)-{F}_{2}(x)=constant$ correct? For example, question find $\int { \frac { dx }{ { x }^{ 4 }-1 } = } $ ? Method 1: $\int { \frac { dx }{ { x }^{ 4 }-1 } =\int { \frac { dx }{ \left( { x }^{ 2 }-1 \right) \left( { x }^{ 2 }+1 \right)  } =\frac { 1 }{ 2 } \int { \frac { dx }{ { x }^{ 2 }-1 } -\frac { 1 }{ 2 } \int { \frac { dx }{ { x }^{ 2 }+1 }  } =\frac { 1 }{ 4 } ln\left| \frac { x-1 }{ x+1 }  \right| -\frac { 1 }{ 2 } arctan(x) } +c }  } $ Method 2:$\int { \frac { dx }{ { x }^{ 4 }-1 } =\frac { 1 }{ 2 } \int { \frac { d{ x }^{ 2 } }{ { \left( { x }^{ 2 } \right)  }^{ 2 }-1 } =\frac { 1 }{ 2 } ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| +c }  } $ Ok, now the question is: what's the relation between $ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| $ and $\frac { 1 }{ 2 } ln\left| \frac { { x }-1 }{ { x }+1 }  \right| -arctan(x)$ ? Does the equation below is correct and how to prove it? $ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| =\frac { 1 }{ 2 } ln\left| \frac { { x }-1 }{ { x }+1 }  \right| -arctan(x) +constant$","If a function $f(x)$ has different forms of antiderivatives: $\frac { d }{ dx } { F }_{ 1 }(x)=f(x)$ $\frac { d }{ dx } { F }_{ 2 }(x)=f(x)$ What's the relationship between $F_1$ and $F_2$, is that ${F}_{1}(x)-{F}_{2}(x)=constant$ correct? For example, question find $\int { \frac { dx }{ { x }^{ 4 }-1 } = } $ ? Method 1: $\int { \frac { dx }{ { x }^{ 4 }-1 } =\int { \frac { dx }{ \left( { x }^{ 2 }-1 \right) \left( { x }^{ 2 }+1 \right)  } =\frac { 1 }{ 2 } \int { \frac { dx }{ { x }^{ 2 }-1 } -\frac { 1 }{ 2 } \int { \frac { dx }{ { x }^{ 2 }+1 }  } =\frac { 1 }{ 4 } ln\left| \frac { x-1 }{ x+1 }  \right| -\frac { 1 }{ 2 } arctan(x) } +c }  } $ Method 2:$\int { \frac { dx }{ { x }^{ 4 }-1 } =\frac { 1 }{ 2 } \int { \frac { d{ x }^{ 2 } }{ { \left( { x }^{ 2 } \right)  }^{ 2 }-1 } =\frac { 1 }{ 2 } ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| +c }  } $ Ok, now the question is: what's the relation between $ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| $ and $\frac { 1 }{ 2 } ln\left| \frac { { x }-1 }{ { x }+1 }  \right| -arctan(x)$ ? Does the equation below is correct and how to prove it? $ln\left| \frac { { x }^{ 2 }-1 }{ { x }^{ 2 }+1 }  \right| =\frac { 1 }{ 2 } ln\left| \frac { { x }-1 }{ { x }+1 }  \right| -arctan(x) +constant$",,['calculus']
6,How can I get unblocked on learning Calculus? [closed],How can I get unblocked on learning Calculus? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I love math and science. In fact paid for $1/2$ my college tuition by tutoring algebra and trigonometry. But when it came to calculus, I became blocked. I understand the concepts of speed and rate of change, but when I start seeing all the symbols like $f'(x)$ and $dx$, my mind goes all fuzzy. My learning style is that if I can picture something and comprehend it in real life, then I get it in symbols. Algebra, geometry, and trig are all easy enough to picture. But what does it look like in real life to 'take the derivative' or the integral of something? Does it look like a sphere becoming a circle? Does anyone else's brain work like this? How did you 'get' calculus?","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 9 years ago . Improve this question I love math and science. In fact paid for $1/2$ my college tuition by tutoring algebra and trigonometry. But when it came to calculus, I became blocked. I understand the concepts of speed and rate of change, but when I start seeing all the symbols like $f'(x)$ and $dx$, my mind goes all fuzzy. My learning style is that if I can picture something and comprehend it in real life, then I get it in symbols. Algebra, geometry, and trig are all easy enough to picture. But what does it look like in real life to 'take the derivative' or the integral of something? Does it look like a sphere becoming a circle? Does anyone else's brain work like this? How did you 'get' calculus?",,['calculus']
7,How do I compute this integral?,How do I compute this integral?,,"I'm wondering how to compute the integral $$ \int_2^3\int_0^\sqrt{3x-x^2}\frac{1}{(x^2+y^2)^{1/2}}\,\mathrm{d}y\mathrm{d}x. $$ Clearly it is too complicated to do it directly, so I'm guessing you have to do some change of variables. But what kind of change? This is not really a sphere, so I don't think that polar coordinates would be so good.","I'm wondering how to compute the integral $$ \int_2^3\int_0^\sqrt{3x-x^2}\frac{1}{(x^2+y^2)^{1/2}}\,\mathrm{d}y\mathrm{d}x. $$ Clearly it is too complicated to do it directly, so I'm guessing you have to do some change of variables. But what kind of change? This is not really a sphere, so I don't think that polar coordinates would be so good.",,"['calculus', 'integration', 'multivariable-calculus', 'definite-integrals']"
8,Proving $y=\lfloor x\rfloor$ doesn't have a primitive function,Proving  doesn't have a primitive function,y=\lfloor x\rfloor,"Prove that $y=\lfloor x\rfloor$ doesn't have a primitive function. I have the proof from a book here but I don't understand it: Suppose that there is $F(x)$ such that $F'(x)=\lfloor x\rfloor$. We   have that $y=\lfloor x\rfloor$ has a jump discontinuity (or type 1)   but $F'(x)$ has only an essential discontinuity (or type 2), a   contradiction. I don't understand, why does $F'(x)$ has an essential discontinuity?","Prove that $y=\lfloor x\rfloor$ doesn't have a primitive function. I have the proof from a book here but I don't understand it: Suppose that there is $F(x)$ such that $F'(x)=\lfloor x\rfloor$. We   have that $y=\lfloor x\rfloor$ has a jump discontinuity (or type 1)   but $F'(x)$ has only an essential discontinuity (or type 2), a   contradiction. I don't understand, why does $F'(x)$ has an essential discontinuity?",,"['calculus', 'integration']"
9,Good article or book to q-analogs?,Good article or book to q-analogs?,,"I want to learn more about the following Topics: $q$-analog calculus what can be done with the $q$-Pochhammer Symbol applications of $q$-analogs in combinatorics However, I have found very Little that answers These questions comprehensively. Are there some books or good articles where These Topics are explained? Every reply will be appreciated.","I want to learn more about the following Topics: $q$-analog calculus what can be done with the $q$-Pochhammer Symbol applications of $q$-analogs in combinatorics However, I have found very Little that answers These questions comprehensively. Are there some books or good articles where These Topics are explained? Every reply will be appreciated.",,"['calculus', 'combinatorics', 'reference-request', 'q-analogs']"
10,Calculus of Variations: Understanding functional derivative,Calculus of Variations: Understanding functional derivative,,"I am trying to understand the basics of the Calculus of Variations and the first thing to understand is the functional derivative. I failed to find a good introductory material, so I am trying to make sense out of various sources I found on the internet. Now, $F[y]$ is a functional, dependending on the function $y(x)$ on an interval $[a,b]$. The most explanatory resources I have came across builds the functional derivative from the definitions of multivariable calculus, so we divide the interval $[a,b]$ into $N$ subintervals and assume that $F$ depends on values of $y$ at such interval points. So we have a multivariable function: $F(y_0,y_1,y_2,\dots, y_N)$ where $y_i = y(a + i(\dfrac{b-a}{N}))$. Then we make a small displacement $\epsilon \vec{d} $ from the point $\{y_0,\dots,y_N\}$ and obtain: $$F(y_0 + \epsilon d_0 ,y_1 + \epsilon d_1,y_2+ \epsilon d_2,\dots, y_N+ \epsilon d_N) = F(y_0,y_1,y_2,\dots, y_N) + \epsilon\sum_{i=0}^N\frac{\partial F}{\partial y_i}d_i + O(\epsilon^2)$$ $O(\epsilon^2)$ shows that the residue is on the order of $\epsilon^2$. Now, how can I approach from here and obtain the formula for the functional derivative? What I have in mind is to refine the number of subintervals on $[a,b]$; make denser and denser meshes which results in taking the limit $N \to \infty$. But I don't know how to apply this idea in a correct way. The term $\epsilon\sum_{i=0}^N\frac{\partial F}{\partial y_i}d_i$ should turn into a definite integral if I take this limit, but $\frac{\partial F}{\partial y_i}d_i$ is not a proper continuous function to begin with. So I need help in understanding this derivation. Edit: The end result I am trying to reach is $ F [y (x) + \epsilon n (x)] = F [y (x)] + \epsilon \int \dfrac {\delta F}{\delta y (x)}n (x) dx +O (\epsilon^2) $","I am trying to understand the basics of the Calculus of Variations and the first thing to understand is the functional derivative. I failed to find a good introductory material, so I am trying to make sense out of various sources I found on the internet. Now, $F[y]$ is a functional, dependending on the function $y(x)$ on an interval $[a,b]$. The most explanatory resources I have came across builds the functional derivative from the definitions of multivariable calculus, so we divide the interval $[a,b]$ into $N$ subintervals and assume that $F$ depends on values of $y$ at such interval points. So we have a multivariable function: $F(y_0,y_1,y_2,\dots, y_N)$ where $y_i = y(a + i(\dfrac{b-a}{N}))$. Then we make a small displacement $\epsilon \vec{d} $ from the point $\{y_0,\dots,y_N\}$ and obtain: $$F(y_0 + \epsilon d_0 ,y_1 + \epsilon d_1,y_2+ \epsilon d_2,\dots, y_N+ \epsilon d_N) = F(y_0,y_1,y_2,\dots, y_N) + \epsilon\sum_{i=0}^N\frac{\partial F}{\partial y_i}d_i + O(\epsilon^2)$$ $O(\epsilon^2)$ shows that the residue is on the order of $\epsilon^2$. Now, how can I approach from here and obtain the formula for the functional derivative? What I have in mind is to refine the number of subintervals on $[a,b]$; make denser and denser meshes which results in taking the limit $N \to \infty$. But I don't know how to apply this idea in a correct way. The term $\epsilon\sum_{i=0}^N\frac{\partial F}{\partial y_i}d_i$ should turn into a definite integral if I take this limit, but $\frac{\partial F}{\partial y_i}d_i$ is not a proper continuous function to begin with. So I need help in understanding this derivation. Edit: The end result I am trying to reach is $ F [y (x) + \epsilon n (x)] = F [y (x)] + \epsilon \int \dfrac {\delta F}{\delta y (x)}n (x) dx +O (\epsilon^2) $",,"['calculus', 'multivariable-calculus', 'calculus-of-variations']"
11,How to find the inverse arc in the configuration space,How to find the inverse arc in the configuration space,,"The following Figure shows the function from configuration space (Torus) to operational space (Annulus). There is a naturally defined continuous function from configuration space $(\theta_A, \theta_B)$ to operational space $f(\theta_A, \theta_B)$. If any of $\theta_A$ and $\theta_B$ varies, chalk at the end of rod B draws an 'arc', Supposing we have an arc in operational space and we want to find its inverse arc in configuration space. Here are two simple examples: The problem is how can we find the arc of the configuration space (i.e. $\theta_A=f(\theta_B)$ for the following two operational space?: All I have approached is a little knowledge: $1-$ the coordinate $(x,y)$ of the end point can be determined through: $x={l_A}{\cos\theta_A}+{l_B}{\cos(\theta_A+\theta_B)}$ and $y={l_A}{\sin\theta_A}+{l_B}{\sin(\theta_A+\theta_B)}$. $2-$ The polar equation of the left picture is $r^2−2{l_B}r\cos(\theta)+{l_B}^2={l_A}^2$. But $\theta$ is in operational space, nothing to say about $(\theta_A,\theta_B)$ in configuration space (?) How it is possible to find the relation between $\theta_A$ and $\theta_B$ such that results in the mentioned arcs? I don't have any clue how to solve it. I would highly appreciate any helps. Thank you.","The following Figure shows the function from configuration space (Torus) to operational space (Annulus). There is a naturally defined continuous function from configuration space $(\theta_A, \theta_B)$ to operational space $f(\theta_A, \theta_B)$. If any of $\theta_A$ and $\theta_B$ varies, chalk at the end of rod B draws an 'arc', Supposing we have an arc in operational space and we want to find its inverse arc in configuration space. Here are two simple examples: The problem is how can we find the arc of the configuration space (i.e. $\theta_A=f(\theta_B)$ for the following two operational space?: All I have approached is a little knowledge: $1-$ the coordinate $(x,y)$ of the end point can be determined through: $x={l_A}{\cos\theta_A}+{l_B}{\cos(\theta_A+\theta_B)}$ and $y={l_A}{\sin\theta_A}+{l_B}{\sin(\theta_A+\theta_B)}$. $2-$ The polar equation of the left picture is $r^2−2{l_B}r\cos(\theta)+{l_B}^2={l_A}^2$. But $\theta$ is in operational space, nothing to say about $(\theta_A,\theta_B)$ in configuration space (?) How it is possible to find the relation between $\theta_A$ and $\theta_B$ such that results in the mentioned arcs? I don't have any clue how to solve it. I would highly appreciate any helps. Thank you.",,['calculus']
12,"Finding the derivative $f(x)=\sqrt{x^2 -9}$,","Finding the derivative ,",f(x)=\sqrt{x^2 -9},"I need to find the slope at a=5, using the definition for the function $f(x)=\sqrt{x^2 -9}$, $$f'(x) = \lim_{\Delta x \to 0} {f(x+\Delta x)\over \Delta x}$$ The answer book says the slope is ${1\over 4}$ Here's what I did, $$f'(x) = \lim_{\Delta x \to 0} {(\sqrt{(x+\Delta x)^2 -9} - \sqrt {x^2 -9} )(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)})\over\Delta x(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (1)\\=\lim_{\Delta x \to 0} {(x+\Delta x)^2 -9 -x^2 +9\over \Delta x(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (2)\\=\lim_{\Delta x \to 0}{x^2 +2x \Delta x+ \Delta x^2 -x^2\over\Delta x(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (3)\\=\lim_{\Delta x \to 0}{2x\Delta x +\Delta x^2\over\Delta x(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (4)\\=\lim_{\Delta x \to 0} {2x+\Delta x\over(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (5)\\={2x\over \sqrt{x^2-9+x^2-9}} (6)\\={2x\over2 \sqrt{x^2 -9}} (7)\\={x\over \sqrt {x^2 -9}} (8)$$ Now I substitute 5, and I don't get 1/4!! What have I done wrong?? Thanks","I need to find the slope at a=5, using the definition for the function $f(x)=\sqrt{x^2 -9}$, $$f'(x) = \lim_{\Delta x \to 0} {f(x+\Delta x)\over \Delta x}$$ The answer book says the slope is ${1\over 4}$ Here's what I did, $$f'(x) = \lim_{\Delta x \to 0} {(\sqrt{(x+\Delta x)^2 -9} - \sqrt {x^2 -9} )(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)})\over\Delta x(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (1)\\=\lim_{\Delta x \to 0} {(x+\Delta x)^2 -9 -x^2 +9\over \Delta x(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (2)\\=\lim_{\Delta x \to 0}{x^2 +2x \Delta x+ \Delta x^2 -x^2\over\Delta x(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (3)\\=\lim_{\Delta x \to 0}{2x\Delta x +\Delta x^2\over\Delta x(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (4)\\=\lim_{\Delta x \to 0} {2x+\Delta x\over(\sqrt{(x+\Delta x)^2 -9}+ \sqrt{x^2-9)}} (5)\\={2x\over \sqrt{x^2-9+x^2-9}} (6)\\={2x\over2 \sqrt{x^2 -9}} (7)\\={x\over \sqrt {x^2 -9}} (8)$$ Now I substitute 5, and I don't get 1/4!! What have I done wrong?? Thanks",,"['calculus', 'limits', 'derivatives', 'fractions']"
13,Proof that $\lim_{n\to\infty}{\sin{100n}}$ does not exist,Proof that  does not exist,\lim_{n\to\infty}{\sin{100n}},"How to prove that $$\lim_{n\to\infty}{\sin{100n}}$$ doesn't exist? Some possible approaches: It would be enough to find two subsequences $n_{k}$ that converge to two different numbers. But it's not clear how to find $n_k$ so that $\sin 100n_k$ converge. Show that $\sin (100(n+1))-\sin 100n$ does not approach $0$. This is not obvious, either.","How to prove that $$\lim_{n\to\infty}{\sin{100n}}$$ doesn't exist? Some possible approaches: It would be enough to find two subsequences $n_{k}$ that converge to two different numbers. But it's not clear how to find $n_k$ so that $\sin 100n_k$ converge. Show that $\sin (100(n+1))-\sin 100n$ does not approach $0$. This is not obvious, either.",,"['calculus', 'limits', 'trigonometry']"
14,"Integration $\frac{1}{2\pi}\int_{-\pi}^{\pi}(x-a)^ke^{-i\omega x}dx, \ \ \ \ a\in\mathbb R$.",Integration .,"\frac{1}{2\pi}\int_{-\pi}^{\pi}(x-a)^ke^{-i\omega x}dx, \ \ \ \ a\in\mathbb R","Give a compact form for the solution of integral: $$\frac{1}{2\pi}\int_{-\pi}^{\pi}(x-a)^ke^{-i\omega x}dx, \ \ \ \ a\in\mathbb R,k\in\mathbb N$$ any suggestions please?","Give a compact form for the solution of integral: $$\frac{1}{2\pi}\int_{-\pi}^{\pi}(x-a)^ke^{-i\omega x}dx, \ \ \ \ a\in\mathbb R,k\in\mathbb N$$ any suggestions please?",,"['calculus', 'integration', 'definite-integrals', 'closed-form']"
15,Geometric interpretation of analyticity?,Geometric interpretation of analyticity?,,"Suppose the real valued functions $u(x,y)$ and $v(x,y)$ are continuous and have continuous first order partial derivatives in a domain $D$. If $u$ and $v$ satisfy the Cauchy Riemann equations at all points of $D$, then the complex function $f(z)= u+iv$ is analytic in $D$. Could someone please give me a geometric interpretation of the theorem above? The Cauchy Riemann equations can be interpreted as saying the the gradient of $u$ and $v$ must be perpendicular for the function to be differentiable.","Suppose the real valued functions $u(x,y)$ and $v(x,y)$ are continuous and have continuous first order partial derivatives in a domain $D$. If $u$ and $v$ satisfy the Cauchy Riemann equations at all points of $D$, then the complex function $f(z)= u+iv$ is analytic in $D$. Could someone please give me a geometric interpretation of the theorem above? The Cauchy Riemann equations can be interpreted as saying the the gradient of $u$ and $v$ must be perpendicular for the function to be differentiable.",,"['calculus', 'complex-analysis', 'multivariable-calculus', 'intuition']"
16,"To prove $\lim_{x \rightarrow a} 3x^2 = 3a^2$, how do you deduce $\delta = \min \left\{ 1, \frac{\epsilon}{6|a| + h}\right\}$?","To prove , how do you deduce ?","\lim_{x \rightarrow a} 3x^2 = 3a^2 \delta = \min \left\{ 1, \frac{\epsilon}{6|a| + h}\right\}","I have a hard time understanding why we pick the $\delta$ 's that we do. Let's say we want to check if $\lim_{x \to a} 3x^2 = 3a^2.$ We would proceed as follows. Given that $h =  x -a$ , and so $x = h+ a$ , $|f(x) - 3a^2| = | 3(h+a)^2 - 3a^2| = |6a+3h||h|.$ I then don't understand how we can pick $\delta = \min\left\{ 1, \dfrac{\epsilon}{6|a| + h}\right\}.$","I have a hard time understanding why we pick the 's that we do. Let's say we want to check if We would proceed as follows. Given that , and so , I then don't understand how we can pick","\delta \lim_{x \to a} 3x^2 = 3a^2. h =  x -a x = h+ a |f(x) - 3a^2| = | 3(h+a)^2 - 3a^2| = |6a+3h||h|. \delta = \min\left\{ 1, \dfrac{\epsilon}{6|a| + h}\right\}.","['calculus', 'limits', 'epsilon-delta']"
17,Simple limit problem with squares,Simple limit problem with squares,,I'm doing a refreshment course in math but I'm stuck with some problem. Although this problem doesn't look hard I don't know what I'm doing wrong. $$\lim_{x \to 4} \frac{\sqrt{x-3}-1}{2\sqrt{2}-\sqrt{x^2-3x+4}}$$ I have tried to take the conjuct of both squares but I still got the indeterminate form of $\frac{0}{0}$. Thanks in advance...,I'm doing a refreshment course in math but I'm stuck with some problem. Although this problem doesn't look hard I don't know what I'm doing wrong. $$\lim_{x \to 4} \frac{\sqrt{x-3}-1}{2\sqrt{2}-\sqrt{x^2-3x+4}}$$ I have tried to take the conjuct of both squares but I still got the indeterminate form of $\frac{0}{0}$. Thanks in advance...,,"['calculus', 'algebra-precalculus', 'limits']"
18,Limit related to the recursion $a_{n+1}=(1-n^{-1/4}a_n)a_n$,Limit related to the recursion,a_{n+1}=(1-n^{-1/4}a_n)a_n,"Let $0<a_{1}<1$, with $$a_{n+1}=a_{n}(1-n^{-\frac{1}{4}}a_{n})$$ Does there a real numbers $A$  which make the limit $$ \lim_{n\to\infty}\sqrt[4]{n}\left(A-\frac{4}{3}\sqrt[4]{n^3}\left(1-\frac{4}{3}\sqrt[4]{n^3}a_{n}\right) \right)=B$$ exist? if possible find the value of $A$ and $B$. Here is my approach. First it is easy to find that $\{a_{n}\}$ is a strict decrease sequcence with $a_{n}\to 0 (n\to+\infty)$,and by O.Stolz Therom,we have: \begin{align*} \lim_{n\to\infty}\sqrt[4]{n^3}a_{n}&=\lim_{n\to\infty}\frac{n^{\frac{3}{4}}}{\frac{1}{a_{n}}}\\ &=\lim_{n\to\infty}\frac{(n+1)^{\frac{3}{4}}-n^{\frac{3}{4}}}{\frac{1}{a_{n+1}}-\frac{1}{a_{n}}}\\ &=\lim_{n\to\infty}\frac{n^{\frac{3}{4}}\left(\left(1+\frac{1}{n}\right)^{\frac{3}{4}}-1\right)}{\frac{1}{a_{n}(1-n^{-\frac{1}{4}}a_{n})}-\frac{1}{a_{n}}}\\ &=\lim_{n\to\infty}n\left(\left(1+\frac{1}{n}\right)^{\frac{3}{4}}-1\right)(1-n^{-\frac{1}{4}a_{n}})\\ &=\frac{3}{4} \end{align*} which implys that $$ a_{n}\sim \frac{3}{4}n^{-\frac{3}{4}} $$ Also we can rewrite the condition into $$ \frac{1}{a_{n+1}}=\frac{1}{a_{n}}+\frac{n^{-\frac{1}{4}}}{1-n^{-\frac{1}{4}}a_{n}}$$ and expand it $$\frac{1}{a_{n+1}}-\frac{1}{a_{n}}=n^{-\frac{1}{4}}\left(1+n^{-\frac{1}{4}}a_{n}+n^{-\frac{1}{2}}a_{n}^2+o\left(n^{-\frac{1}{2}}a_{n}^2\right)\right)$$ but  $$ a_{n}\sim \frac{3}{4}n^{-\frac{3}{4}}\Rightarrow \frac{1}{a_{n}}\sim\frac{4}{3}n^{\frac{3}{4}}$$ hence we use O.Stolz again to estimate $\frac{1}{a_{n}}$,it is \begin{align*} &\lim_{n\to\infty}\frac{\frac{1}{a_{n}}-\frac{4}{3}n^{\frac{3}{4}}}{n^{-\frac{1}{4}}}\\ &=\lim_{n\to\infty}\frac{\frac{1}{a_{n+1}}-\frac{1}{a_{n}}-\frac{4}{3}\left((n+1)^{\frac{3}{4}}-n^{\frac{3}{4}}\right)}{(n+1)^{-\frac{1}{4}}-n^{-\frac{1}{4}}}\\ &=\lim_{n\to\infty}\frac{n^{-\frac{1}{4}}+n^{-\frac{1}{2}}a_{n}+n^{-\frac{3}{4}}a_{n}^{2}+o(n^{-\frac{3}{4}}a_{n}^{2})-\frac{4}{3}n^{\frac{3}{4}}\left[\left(1+\frac{1}{n}\right)^{\frac{3}{4}}-1\right]}{n^{-\frac{1}{4}}\left[\left(1+\frac{1}{n} \right)^{-\frac{1}{4}}-1\right]}\\ &=\lim_{n\to\infty}\frac{n^{-\frac{1}{2}}a_{n}+\frac{1}{8}n^{-\frac{5}{4}}+n^{-\frac{3}{4}}a_{n}^{2}+o(n^{-\frac{5}{4}})}{-\frac{1}{4}n^{-\frac{5}{4}}}=-\frac{7}{2} \end{align*} Which leads  $$\frac{1}{a_{n}}=\frac{4}{3}n^{\frac{3}{4}}-\frac{7}{2}n^{-\frac{1}{4}}+o(n^{-\frac{1}{4}})$$ \begin{align*} &a_{n}=\frac{1}{\frac{4}{3}n^{\frac{3}{4}}-\frac{7}{2}n^{-\frac{1}{4}}+o(n^{-\frac{1}{4}})}\\ &=\frac{3}{4}n^{-\frac{3}{4}}\cdot \frac{1}{1-\frac{21}{8}\frac{1}{n}+o(\frac{1}{n})}\\ &=\frac{3}{4}n^{-\frac{3}{4}}\left(1+\frac{21}{8}\frac{1}{n}+o(\frac{1}{n})\right)\\ &=\frac{3}{4}n^{-\frac{3}{4}}+\frac{63}{32}n^{-\frac{7}{4}}+o(n^{-\frac{7}{4}}) \end{align*} After some simple compute,we find that $A=0$,and $B=\frac{7}{2}$, The man who propose this problem told me my solution was obviously wrong,but I didn't know where is wrong? Can someone help me to verify it? Or if you have better idea about such problem,I also do appreciate. Thank you very much!","Let $0<a_{1}<1$, with $$a_{n+1}=a_{n}(1-n^{-\frac{1}{4}}a_{n})$$ Does there a real numbers $A$  which make the limit $$ \lim_{n\to\infty}\sqrt[4]{n}\left(A-\frac{4}{3}\sqrt[4]{n^3}\left(1-\frac{4}{3}\sqrt[4]{n^3}a_{n}\right) \right)=B$$ exist? if possible find the value of $A$ and $B$. Here is my approach. First it is easy to find that $\{a_{n}\}$ is a strict decrease sequcence with $a_{n}\to 0 (n\to+\infty)$,and by O.Stolz Therom,we have: \begin{align*} \lim_{n\to\infty}\sqrt[4]{n^3}a_{n}&=\lim_{n\to\infty}\frac{n^{\frac{3}{4}}}{\frac{1}{a_{n}}}\\ &=\lim_{n\to\infty}\frac{(n+1)^{\frac{3}{4}}-n^{\frac{3}{4}}}{\frac{1}{a_{n+1}}-\frac{1}{a_{n}}}\\ &=\lim_{n\to\infty}\frac{n^{\frac{3}{4}}\left(\left(1+\frac{1}{n}\right)^{\frac{3}{4}}-1\right)}{\frac{1}{a_{n}(1-n^{-\frac{1}{4}}a_{n})}-\frac{1}{a_{n}}}\\ &=\lim_{n\to\infty}n\left(\left(1+\frac{1}{n}\right)^{\frac{3}{4}}-1\right)(1-n^{-\frac{1}{4}a_{n}})\\ &=\frac{3}{4} \end{align*} which implys that $$ a_{n}\sim \frac{3}{4}n^{-\frac{3}{4}} $$ Also we can rewrite the condition into $$ \frac{1}{a_{n+1}}=\frac{1}{a_{n}}+\frac{n^{-\frac{1}{4}}}{1-n^{-\frac{1}{4}}a_{n}}$$ and expand it $$\frac{1}{a_{n+1}}-\frac{1}{a_{n}}=n^{-\frac{1}{4}}\left(1+n^{-\frac{1}{4}}a_{n}+n^{-\frac{1}{2}}a_{n}^2+o\left(n^{-\frac{1}{2}}a_{n}^2\right)\right)$$ but  $$ a_{n}\sim \frac{3}{4}n^{-\frac{3}{4}}\Rightarrow \frac{1}{a_{n}}\sim\frac{4}{3}n^{\frac{3}{4}}$$ hence we use O.Stolz again to estimate $\frac{1}{a_{n}}$,it is \begin{align*} &\lim_{n\to\infty}\frac{\frac{1}{a_{n}}-\frac{4}{3}n^{\frac{3}{4}}}{n^{-\frac{1}{4}}}\\ &=\lim_{n\to\infty}\frac{\frac{1}{a_{n+1}}-\frac{1}{a_{n}}-\frac{4}{3}\left((n+1)^{\frac{3}{4}}-n^{\frac{3}{4}}\right)}{(n+1)^{-\frac{1}{4}}-n^{-\frac{1}{4}}}\\ &=\lim_{n\to\infty}\frac{n^{-\frac{1}{4}}+n^{-\frac{1}{2}}a_{n}+n^{-\frac{3}{4}}a_{n}^{2}+o(n^{-\frac{3}{4}}a_{n}^{2})-\frac{4}{3}n^{\frac{3}{4}}\left[\left(1+\frac{1}{n}\right)^{\frac{3}{4}}-1\right]}{n^{-\frac{1}{4}}\left[\left(1+\frac{1}{n} \right)^{-\frac{1}{4}}-1\right]}\\ &=\lim_{n\to\infty}\frac{n^{-\frac{1}{2}}a_{n}+\frac{1}{8}n^{-\frac{5}{4}}+n^{-\frac{3}{4}}a_{n}^{2}+o(n^{-\frac{5}{4}})}{-\frac{1}{4}n^{-\frac{5}{4}}}=-\frac{7}{2} \end{align*} Which leads  $$\frac{1}{a_{n}}=\frac{4}{3}n^{\frac{3}{4}}-\frac{7}{2}n^{-\frac{1}{4}}+o(n^{-\frac{1}{4}})$$ \begin{align*} &a_{n}=\frac{1}{\frac{4}{3}n^{\frac{3}{4}}-\frac{7}{2}n^{-\frac{1}{4}}+o(n^{-\frac{1}{4}})}\\ &=\frac{3}{4}n^{-\frac{3}{4}}\cdot \frac{1}{1-\frac{21}{8}\frac{1}{n}+o(\frac{1}{n})}\\ &=\frac{3}{4}n^{-\frac{3}{4}}\left(1+\frac{21}{8}\frac{1}{n}+o(\frac{1}{n})\right)\\ &=\frac{3}{4}n^{-\frac{3}{4}}+\frac{63}{32}n^{-\frac{7}{4}}+o(n^{-\frac{7}{4}}) \end{align*} After some simple compute,we find that $A=0$,and $B=\frac{7}{2}$, The man who propose this problem told me my solution was obviously wrong,but I didn't know where is wrong? Can someone help me to verify it? Or if you have better idea about such problem,I also do appreciate. Thank you very much!",,"['calculus', 'proof-verification', 'recurrence-relations']"
19,Integrate $I=\int_{-1}^3\frac{\sqrt{x+5}}{(1+\sqrt{2x+3})^2}dx$,Integrate,I=\int_{-1}^3\frac{\sqrt{x+5}}{(1+\sqrt{2x+3})^2}dx,"Compute $$ I=\int_{-1}^{3}\frac{\sqrt{\vphantom{\large A}\,x + 5\,}\,} {\left(1 + \sqrt{\vphantom{\large A}\,2x + 3\,}\,\right)^{2}}\,{\rm d}x $$ Here's what I have tried: Let $t = 1 + \sqrt{\vphantom{\large A}\,2x + 3\,}\,$ then we have ${\rm d}x=\left(t - 1\right)\,{\rm d}t$. So $$ I=\frac{1}{\sqrt{\vphantom{\large A}\,2\,}\,} \int_{2}^{4}\frac{\left(t - 1\right) \sqrt{\vphantom{\large A}\,\left(t - 1\right)^{2} + 7\,}}{t^{2}}\,{\rm d}t $$ Now, I have stuck.....can anyone help me????? Thanks.","Compute $$ I=\int_{-1}^{3}\frac{\sqrt{\vphantom{\large A}\,x + 5\,}\,} {\left(1 + \sqrt{\vphantom{\large A}\,2x + 3\,}\,\right)^{2}}\,{\rm d}x $$ Here's what I have tried: Let $t = 1 + \sqrt{\vphantom{\large A}\,2x + 3\,}\,$ then we have ${\rm d}x=\left(t - 1\right)\,{\rm d}t$. So $$ I=\frac{1}{\sqrt{\vphantom{\large A}\,2\,}\,} \int_{2}^{4}\frac{\left(t - 1\right) \sqrt{\vphantom{\large A}\,\left(t - 1\right)^{2} + 7\,}}{t^{2}}\,{\rm d}t $$ Now, I have stuck.....can anyone help me????? Thanks.",,"['calculus', 'integration', 'definite-integrals']"
20,Calculus Riemann Sums - why do the partitions have to be of the same size?,Calculus Riemann Sums - why do the partitions have to be of the same size?,,"To set up Riemann sums for integration, my calculus text will say that the intervals of partition are all of the same size.  Isn't it rather the case that they could be any size, as long as they are bounded by a largest partition which goes to zero as we take the limit?  Why bother being so explicit about the equalities of each delta x? Similarly, does it matter that the point within each partition be determined in the same manner each time?  As the limit goes to zero, as long as the x-value we choose is somewhere within that segment of the domain...","To set up Riemann sums for integration, my calculus text will say that the intervals of partition are all of the same size.  Isn't it rather the case that they could be any size, as long as they are bounded by a largest partition which goes to zero as we take the limit?  Why bother being so explicit about the equalities of each delta x? Similarly, does it matter that the point within each partition be determined in the same manner each time?  As the limit goes to zero, as long as the x-value we choose is somewhere within that segment of the domain...",,['calculus']
21,How to prove this to be an Irrational number?,How to prove this to be an Irrational number?,,"$$ \int^1_0 e^{-x^2} \, \mathrm{d} x $$ It seems that needs more than 30 word to make a discription of this problem,but actually that all included in the title. Thank you for your answer.","$$ \int^1_0 e^{-x^2} \, \mathrm{d} x $$ It seems that needs more than 30 word to make a discription of this problem,but actually that all included in the title. Thank you for your answer.",,['calculus']
22,Is the standard part function another devil's staircase?,Is the standard part function another devil's staircase?,,"The devil's staircase or Cantor function is an awesome function that increases value but has derivative zero everywhere (or ""almost"", whatever that means). I was incredibly amazed when I found out that the standard part function also seems to have derivative zero, no matter how you take it (I'll just show forwards): $$ \require{cancel} \frac{d(\text{st}\ x)}{dx}= \text{st}\frac{\text{st}(x+dx)-\text{st}(x)}{dx}= \text{st}\frac{\cancel{\text{st}(x)}+\text{st}(dx)\cancel{-\text{st}(x)}}{dx}= \text{st}\frac{0}{dx}=0 $$ Which is odd, since the standard part function looks exactly like the identity function, $y=x$, when plotted, well, with a normal real scale. When magnified with the infinitesimal microscope, one would see a straight horizontal line, as all nonstandard numbers would be ""rounded"" to the nearest real. This reminds me of the floor function, but somehow this one doesn't seem to have discontinuities (it really doesn't, for any infinitesimal $\Delta x$, there's always an infinitesimal $\Delta(\text{st}\ x)=0$). I'm confused, what's wrong here? Does the standard part function really have derivative zero everywhere?","The devil's staircase or Cantor function is an awesome function that increases value but has derivative zero everywhere (or ""almost"", whatever that means). I was incredibly amazed when I found out that the standard part function also seems to have derivative zero, no matter how you take it (I'll just show forwards): $$ \require{cancel} \frac{d(\text{st}\ x)}{dx}= \text{st}\frac{\text{st}(x+dx)-\text{st}(x)}{dx}= \text{st}\frac{\cancel{\text{st}(x)}+\text{st}(dx)\cancel{-\text{st}(x)}}{dx}= \text{st}\frac{0}{dx}=0 $$ Which is odd, since the standard part function looks exactly like the identity function, $y=x$, when plotted, well, with a normal real scale. When magnified with the infinitesimal microscope, one would see a straight horizontal line, as all nonstandard numbers would be ""rounded"" to the nearest real. This reminds me of the floor function, but somehow this one doesn't seem to have discontinuities (it really doesn't, for any infinitesimal $\Delta x$, there's always an infinitesimal $\Delta(\text{st}\ x)=0$). I'm confused, what's wrong here? Does the standard part function really have derivative zero everywhere?",,"['calculus', 'functions', 'derivatives', 'continuity', 'nonstandard-analysis']"
23,Find value range of $2^x+2^y$,Find value range of,2^x+2^y,"Assume $x,y \in \Bbb{R}$ satisfy $$4^x+4^y = 2^{x+1} + 2^{y+1}$$, Find the value range of $$2^x+2^y$$ I know $x=y=1$ is a solution of $4^x+4^y = 2^{x+1} + 2^{y+1}$ , but I can't go further more. I can only find one solution pair of $4^x+4^y = 2^{x+1} + 2^{y+1}$. It seems very far from solve this question...","Assume $x,y \in \Bbb{R}$ satisfy $$4^x+4^y = 2^{x+1} + 2^{y+1}$$, Find the value range of $$2^x+2^y$$ I know $x=y=1$ is a solution of $4^x+4^y = 2^{x+1} + 2^{y+1}$ , but I can't go further more. I can only find one solution pair of $4^x+4^y = 2^{x+1} + 2^{y+1}$. It seems very far from solve this question...",,"['calculus', 'algebra-precalculus', 'inequality']"
24,Volume vs. Surface Area Integrals,Volume vs. Surface Area Integrals,,"In order to find the volume of a sphere radiud $R$, one way is to slice it up into a stack of thin, concentric disks, perpendicular to the $z$-axis. a disk at any point $z$ will have radius $r=\sqrt{R^2-z^2}$ and infinitesimal thickness $dz$, so the volume integral is: $$ V = \int dV = \int_{-R}^{R} \pi r^2 dz = \int_{-R}^{R} \pi (R^2-z^2) \,dz $$ The above integral of course evaluates to $\frac{4}{3}\pi r^3$, the desired answer. Now, when I tried to do the same thing for the surface area, I treated it as a thin, hollow shell, sliced it up into a stack of concentric rings (or simply the outer surface area of the disks). The area integral in that case is: $$ A = \int dA = \int_{-R}^{R} 2\pi r \,dz = \int_{-R}^{R} 2\pi \sqrt{R^2-z^2} dz $$ Unfortunately, this integral does not evaluate to $4\pi r^2$. I discovered that instead of taking the thickness of the thin rings as $dz$, I have to take the infinitesimal arclength $dL$ at point $z$ on the cross-section $x = \sqrt{R^2-z^2}$ $$ dL = \sqrt{\left(\frac{z}{\sqrt{R^2-z^2}} \right)^2 +1} \,dz = \frac{R}{\sqrt{R^2-z^2}} dz $$ Putting that in place of $dz$, the integral evaluates perfectly. Conversely, if the thickness in the volume integral was $dL$, in won't work out. This baffles me. Why do the disks have to have different thickness when you're taking the volume, compared to when you're taking the surface area? Why does it matter? When you take the limit as the number of disk slices goes to infinity and the thickness goes to zero, the sum will approach the sphere, won't it? Is this a case where the sum of those volumes will approach the sphere, but the sum of their surface areas approaches some different shape, or doesn't approach anything if the thickness is $dz$ and reverse if the thickness is $dL$? If so, why? The same thing applies for any arbitrary surface/solid of evolution. The surface area integral always involves $dL$, but the volume only has $dx$","In order to find the volume of a sphere radiud $R$, one way is to slice it up into a stack of thin, concentric disks, perpendicular to the $z$-axis. a disk at any point $z$ will have radius $r=\sqrt{R^2-z^2}$ and infinitesimal thickness $dz$, so the volume integral is: $$ V = \int dV = \int_{-R}^{R} \pi r^2 dz = \int_{-R}^{R} \pi (R^2-z^2) \,dz $$ The above integral of course evaluates to $\frac{4}{3}\pi r^3$, the desired answer. Now, when I tried to do the same thing for the surface area, I treated it as a thin, hollow shell, sliced it up into a stack of concentric rings (or simply the outer surface area of the disks). The area integral in that case is: $$ A = \int dA = \int_{-R}^{R} 2\pi r \,dz = \int_{-R}^{R} 2\pi \sqrt{R^2-z^2} dz $$ Unfortunately, this integral does not evaluate to $4\pi r^2$. I discovered that instead of taking the thickness of the thin rings as $dz$, I have to take the infinitesimal arclength $dL$ at point $z$ on the cross-section $x = \sqrt{R^2-z^2}$ $$ dL = \sqrt{\left(\frac{z}{\sqrt{R^2-z^2}} \right)^2 +1} \,dz = \frac{R}{\sqrt{R^2-z^2}} dz $$ Putting that in place of $dz$, the integral evaluates perfectly. Conversely, if the thickness in the volume integral was $dL$, in won't work out. This baffles me. Why do the disks have to have different thickness when you're taking the volume, compared to when you're taking the surface area? Why does it matter? When you take the limit as the number of disk slices goes to infinity and the thickness goes to zero, the sum will approach the sphere, won't it? Is this a case where the sum of those volumes will approach the sphere, but the sum of their surface areas approaches some different shape, or doesn't approach anything if the thickness is $dz$ and reverse if the thickness is $dL$? If so, why? The same thing applies for any arbitrary surface/solid of evolution. The surface area integral always involves $dL$, but the volume only has $dx$",,"['calculus', 'integration', 'definite-integrals', 'applications']"
25,Hermite Differential Equation - Non-integer values of $\lambda$,Hermite Differential Equation - Non-integer values of,\lambda,"The Hermite differential equation, given by : $$ \frac{d^2y}{dx^2} - 2x \frac{dy}{dx} + \lambda y = 0 $$ has solutions of the  $$ y(x) = \mathcal{H_n(x)} $$ when $ \lambda \: \epsilon \:\mathcal{Z_+} $ Are there solutions to this equation for a more general case, where $ \lambda  $ is a real number ? More importantly are there convergent solutions for cases where  $ \lambda  $  is not integer.","The Hermite differential equation, given by : $$ \frac{d^2y}{dx^2} - 2x \frac{dy}{dx} + \lambda y = 0 $$ has solutions of the  $$ y(x) = \mathcal{H_n(x)} $$ when $ \lambda \: \epsilon \:\mathcal{Z_+} $ Are there solutions to this equation for a more general case, where $ \lambda  $ is a real number ? More importantly are there convergent solutions for cases where  $ \lambda  $  is not integer.",,"['calculus', 'ordinary-differential-equations', 'hermite-polynomials']"
26,Limits of $\sum_{m=1}^{+\infty} \sum_{n=1}^{+\infty}e^{-mn x}$ at $0$ and $\infty$,Limits of  at  and,\sum_{m=1}^{+\infty} \sum_{n=1}^{+\infty}e^{-mn x} 0 \infty,"Let $f(x) = \sum_{m=1}^{+\infty} \sum_{n=1}^{+\infty}e^{-mn x}$ for $x > 0$. Prove that $f(x) \sim e^{-x}$ as $x \to \infty$ and $\lim_{x\to 0} x\cdot (f(x) + \frac{1}{x}\log x)= \gamma$ where $\gamma$ is the Euler–Mascheroni constant. For the first point, I wanted to use the fact that $f(x) - e^{-x}$ involves only terms like $e^{-kx}$ with $k \geq 2$ but I don't know how to write it. I have no idea for the limit as $x$ tends towards $0$. Also, is it possible to generalize for $f_k(x) = \sum_{n_1=1}^{+\infty}\sum_{n_2=1}^{+\infty}\dots \sum_{n_k=1}^{+\infty}e^{-n_1n_2\dots n_k x}$?","Let $f(x) = \sum_{m=1}^{+\infty} \sum_{n=1}^{+\infty}e^{-mn x}$ for $x > 0$. Prove that $f(x) \sim e^{-x}$ as $x \to \infty$ and $\lim_{x\to 0} x\cdot (f(x) + \frac{1}{x}\log x)= \gamma$ where $\gamma$ is the Euler–Mascheroni constant. For the first point, I wanted to use the fact that $f(x) - e^{-x}$ involves only terms like $e^{-kx}$ with $k \geq 2$ but I don't know how to write it. I have no idea for the limit as $x$ tends towards $0$. Also, is it possible to generalize for $f_k(x) = \sum_{n_1=1}^{+\infty}\sum_{n_2=1}^{+\infty}\dots \sum_{n_k=1}^{+\infty}e^{-n_1n_2\dots n_k x}$?",,"['calculus', 'sequences-and-series', 'limits', 'asymptotics']"
27,Limit and ln switch,Limit and ln switch,,"Why is $$\lim_{x\to\infty}\ln\left(\frac{x+1}{\sqrt{x^2-x+1}}\right)=\ln\left(\lim_{x\to\infty}\frac{1+1/x}{\sqrt{1-1/x+1/x^2}}\right) ?$$  I've seen this way of rewriting, but I can't see why it's equal.","Why is $$\lim_{x\to\infty}\ln\left(\frac{x+1}{\sqrt{x^2-x+1}}\right)=\ln\left(\lim_{x\to\infty}\frac{1+1/x}{\sqrt{1-1/x+1/x^2}}\right) ?$$  I've seen this way of rewriting, but I can't see why it's equal.",,"['calculus', 'limits']"
28,Does $A_n= \sqrt{1^2+\sqrt{2^2+\sqrt{...+\sqrt{n^2}}}}$ converge?,Does  converge?,A_n= \sqrt{1^2+\sqrt{2^2+\sqrt{...+\sqrt{n^2}}}},"Can we find the value of $\lim\limits_{n\to \infty} A_n$, does it converge? $$A_n= \sqrt{1^2+\sqrt{2^2+\sqrt{3^2+\sqrt{4^2+\sqrt{...+\sqrt{n^2}}}}}} $$ I tried to calculate $A_1,A_2,\cdots A_{10}$, but my computer cannot do further terms.","Can we find the value of $\lim\limits_{n\to \infty} A_n$, does it converge? $$A_n= \sqrt{1^2+\sqrt{2^2+\sqrt{3^2+\sqrt{4^2+\sqrt{...+\sqrt{n^2}}}}}} $$ I tried to calculate $A_1,A_2,\cdots A_{10}$, but my computer cannot do further terms.",,"['calculus', 'nested-radicals']"
29,Differential — Mathematically conform?,Differential — Mathematically conform?,,"In calculus, I know that one defined the differential quotient $$\frac{dy}{dx} := \lim\limits_{h \rightarrow 0}{\frac{y(x+h)-y(x)}{h}}$$ I learned that it is not a quotient , but can be treated as one in many cases which you can prove like $$ \frac{dy}{dx} = {\frac{dx}{dy}}^{-1} \quad or \quad \frac{dy}{dx} \frac{dx}{dt} = \frac{dy}{dt} $$ For examples like that, it seems more intuitive and is easier to understand — but in a mathematically conform way . As far as this, no problem — until I reach some content in my book saying things just like $$ dU = d\vec{r} \cdot \operatorname{grad} U \quad \text{or even} \quad d\vec{r} \times \stackrel{\rightarrow}{A} = 0  $$ This confuses me in two ways: Math is the only science where it is essential to define everything which appears in an equation/expression etc. When I see the term $dy$, I ask myself “How is this defined?”. Each of the terms $\frac{dy}{dx}$, $∫fdx$ etc. have a concret definition, wheras $dy$ doesn't seem to have one — intuitively, one supposes to say $dx := \lim\limits_{h\rightarrow 0}{\left(x – (x+h)\right)}$, which would exactly be zero. According to what Wikipedia says, it is defined as $df(x,Δx):=f'(x)Δx$, which would not accord to the differential with one parameter as always used. Therefore, WP says $df(x):=f'(x)dx$ which is not appropriate because one cannot define a new operator under usage of this new operator itself. When some new content is introduced in a book with these expressions, even if I understand the intuitive sense or meaning of this equation, I feel like not to have understood a single word (or variable), because 90% of my thoughts ask how I should evaluate the equation/expression mathematically and that it is not legitimate to approve such knowledge based on wrong or unclear axioms, which results in a 2h-long bafflement. Could you please make this topic a little more clear for me?","In calculus, I know that one defined the differential quotient $$\frac{dy}{dx} := \lim\limits_{h \rightarrow 0}{\frac{y(x+h)-y(x)}{h}}$$ I learned that it is not a quotient , but can be treated as one in many cases which you can prove like $$ \frac{dy}{dx} = {\frac{dx}{dy}}^{-1} \quad or \quad \frac{dy}{dx} \frac{dx}{dt} = \frac{dy}{dt} $$ For examples like that, it seems more intuitive and is easier to understand — but in a mathematically conform way . As far as this, no problem — until I reach some content in my book saying things just like $$ dU = d\vec{r} \cdot \operatorname{grad} U \quad \text{or even} \quad d\vec{r} \times \stackrel{\rightarrow}{A} = 0  $$ This confuses me in two ways: Math is the only science where it is essential to define everything which appears in an equation/expression etc. When I see the term $dy$, I ask myself “How is this defined?”. Each of the terms $\frac{dy}{dx}$, $∫fdx$ etc. have a concret definition, wheras $dy$ doesn't seem to have one — intuitively, one supposes to say $dx := \lim\limits_{h\rightarrow 0}{\left(x – (x+h)\right)}$, which would exactly be zero. According to what Wikipedia says, it is defined as $df(x,Δx):=f'(x)Δx$, which would not accord to the differential with one parameter as always used. Therefore, WP says $df(x):=f'(x)dx$ which is not appropriate because one cannot define a new operator under usage of this new operator itself. When some new content is introduced in a book with these expressions, even if I understand the intuitive sense or meaning of this equation, I feel like not to have understood a single word (or variable), because 90% of my thoughts ask how I should evaluate the equation/expression mathematically and that it is not legitimate to approve such knowledge based on wrong or unclear axioms, which results in a 2h-long bafflement. Could you please make this topic a little more clear for me?",,"['calculus', 'definition', 'differential']"
30,Partial summation: integral version,Partial summation: integral version,,"In a book about analytic number theory, I found two lemmas about partial summation. The first one is the discrete version of partial summation (See http://en.wikipedia.org/wiki/Summation_by_parts ) which has a simple proof. However the book also mentioned an integral version of partial summation which states: Let $h(x)$ be a continuously differentiable function. Let $A(x)=\sum_{n\leq x} a_n$. Then $$\sum_{n\leq x} a_n h(n) = A(x)h(x)-\int_1^xA(u)h'(u)du.$$ The proof of this theorem is left as an exercise but I really have no clue how to start.","In a book about analytic number theory, I found two lemmas about partial summation. The first one is the discrete version of partial summation (See http://en.wikipedia.org/wiki/Summation_by_parts ) which has a simple proof. However the book also mentioned an integral version of partial summation which states: Let $h(x)$ be a continuously differentiable function. Let $A(x)=\sum_{n\leq x} a_n$. Then $$\sum_{n\leq x} a_n h(n) = A(x)h(x)-\int_1^xA(u)h'(u)du.$$ The proof of this theorem is left as an exercise but I really have no clue how to start.",,"['calculus', 'summation', 'analytic-number-theory']"
31,Convergence of $\sum_n^\infty (-1)^n\frac{\sin^2 n}n$,Convergence of,\sum_n^\infty (-1)^n\frac{\sin^2 n}n,"Could anyone give a hint how to prove the convergence of the following sum? $$\sum_n^\infty (-1)^n\frac{\sin^2 n}n$$ I tried writing it like this instead: $$\sum_n^\infty \frac1n (-1)^n \sin^2 n.$$ From here, it is easy to see that $\frac1n$ is a bounded and strictly decreasing sequence. It would be sufficient to prove that the sequence of partial sums of $(-1)^n\sin^2 n$ is bounded. From here, I get that $(-1)^n\sin^2 n = (-1)^n\frac{1 - \cos 2n}2 = \frac{(-1)^n}2 - \frac{(-1)^n \cos2n}2$, where the sequence of partial sums of $\frac{(-1)^n}2$ is bounded as well as the sequence of partial sums of $\frac{\cos 2n}2$. Unfortunately, I cannot tell anything about $\frac{(-1)^n\cos 2n}2$. Thank you.","Could anyone give a hint how to prove the convergence of the following sum? $$\sum_n^\infty (-1)^n\frac{\sin^2 n}n$$ I tried writing it like this instead: $$\sum_n^\infty \frac1n (-1)^n \sin^2 n.$$ From here, it is easy to see that $\frac1n$ is a bounded and strictly decreasing sequence. It would be sufficient to prove that the sequence of partial sums of $(-1)^n\sin^2 n$ is bounded. From here, I get that $(-1)^n\sin^2 n = (-1)^n\frac{1 - \cos 2n}2 = \frac{(-1)^n}2 - \frac{(-1)^n \cos2n}2$, where the sequence of partial sums of $\frac{(-1)^n}2$ is bounded as well as the sequence of partial sums of $\frac{\cos 2n}2$. Unfortunately, I cannot tell anything about $\frac{(-1)^n\cos 2n}2$. Thank you.",,"['calculus', 'sequences-and-series', 'trigonometry', 'convergence-divergence']"
32,Double integrals over general region -how to approach?,Double integrals over general region -how to approach?,,"I'm in doubt on how to approach a problem of double integrals over a specific region. I have to calculate $\int\int\limits_R e^x dA$, R being the region between $y=\frac{x}{2}$, $y=x$, $y=\frac{1}{x}$ and $y=\frac{2}{x}$. I am only interested in the first quadrant. That being said, the region is as follows: And the points: Where 1.414 is $\sqrt{2}$ and 0.707 is $\frac{\sqrt{2}}{2}$. My approach, which I'm in doubt if it's a valid one, was the following: Divide the region into 2 regions and consider each new region a ""case 2"" region and sum the integrals over each region to obtain the integral over the original region: The division is made in order to obtain well-defined functions in each region. Is that a valid approach? If not, how should I approach this problem?","I'm in doubt on how to approach a problem of double integrals over a specific region. I have to calculate $\int\int\limits_R e^x dA$, R being the region between $y=\frac{x}{2}$, $y=x$, $y=\frac{1}{x}$ and $y=\frac{2}{x}$. I am only interested in the first quadrant. That being said, the region is as follows: And the points: Where 1.414 is $\sqrt{2}$ and 0.707 is $\frac{\sqrt{2}}{2}$. My approach, which I'm in doubt if it's a valid one, was the following: Divide the region into 2 regions and consider each new region a ""case 2"" region and sum the integrals over each region to obtain the integral over the original region: The division is made in order to obtain well-defined functions in each region. Is that a valid approach? If not, how should I approach this problem?",,"['calculus', 'integration']"
33,Volume of a wine barrel,Volume of a wine barrel,,"This is a famous calculus problem and is stated like this Given a barrel with height $h$, and a small radius of $a$ and   large radius of $b$. Calculate the volume of the barrel    given that the sides are parabolic. Now I seem to have solved the problem incorrectly because here it seems 2 that the volume should be $ \displaystyle \hspace{1cm}    V(a,b,h) = \frac{h\pi}{3}\left(2b^2 + a^2\right)\,. $ Below is my attempt. As in the picture I view the barrel from the side, and try to find a formula for the parabola. So i solve $ \displaystyle \hspace{1cm}     f(x) := A x^2 + B x + C  $ given $f(0) = f(h) = a/2$ and $f(h/2) = b/2$. This yields $ \displaystyle \hspace{1cm} f(x) =  \frac{2(a-b)}{h^2} \cdot  x^2 -          \frac{2(a-b)}{h} \cdot x +         \frac{a}{2} $ Using the shell method integrating now gives the volume as $ \displaystyle \hspace{1cm}     V(a,b,h) := \pi \int_0^h \bigl[f(x)\bigr]^2\,\mathrm{d}x               = \frac{\pi}{60} \cdot h (a+2b)^2 + \frac{\pi}{30} \cdot h(a^2+b^2) $ Alas according to the formula above this seems incorrect! Where is my mistake?","This is a famous calculus problem and is stated like this Given a barrel with height $h$, and a small radius of $a$ and   large radius of $b$. Calculate the volume of the barrel    given that the sides are parabolic. Now I seem to have solved the problem incorrectly because here it seems 2 that the volume should be $ \displaystyle \hspace{1cm}    V(a,b,h) = \frac{h\pi}{3}\left(2b^2 + a^2\right)\,. $ Below is my attempt. As in the picture I view the barrel from the side, and try to find a formula for the parabola. So i solve $ \displaystyle \hspace{1cm}     f(x) := A x^2 + B x + C  $ given $f(0) = f(h) = a/2$ and $f(h/2) = b/2$. This yields $ \displaystyle \hspace{1cm} f(x) =  \frac{2(a-b)}{h^2} \cdot  x^2 -          \frac{2(a-b)}{h} \cdot x +         \frac{a}{2} $ Using the shell method integrating now gives the volume as $ \displaystyle \hspace{1cm}     V(a,b,h) := \pi \int_0^h \bigl[f(x)\bigr]^2\,\mathrm{d}x               = \frac{\pi}{60} \cdot h (a+2b)^2 + \frac{\pi}{30} \cdot h(a^2+b^2) $ Alas according to the formula above this seems incorrect! Where is my mistake?",,['calculus']
34,"integration by substitution, using $\;t = \tan \left(\frac 12 x\right)$","integration by substitution, using",\;t = \tan \left(\frac 12 x\right),"$\displaystyle\int_0^\frac{\pi}{2}\frac{1}{2-\cos x} \, dx$ using the substitution $t=\tan\frac{1}{2}x$ $x=2\tan^{-1}t$ $\dfrac{dx}{dt}=\dfrac{2}{1+t^2}$ $dx=\dfrac{2}{1+t^2}\,dt$ $\displaystyle\int_0^1 \left(\frac{1}{2-\cos x}\right)\left(\frac{2}{1+t^2}\right)\,dt$ Is this the right idea? If so what do I do next? $\displaystyle\int_0^1\left(\frac{1}{2-\frac{1-t^2}{1+t^2}}\right) \,\left(\frac{2}{1+t^2}\right)\, dt$ $\displaystyle\int_0^1\frac{2}{1+3t^2}\,dt$ $=2\left[\frac{\ln(1+3t^2)}{6t}\right]_0^1$","$\displaystyle\int_0^\frac{\pi}{2}\frac{1}{2-\cos x} \, dx$ using the substitution $t=\tan\frac{1}{2}x$ $x=2\tan^{-1}t$ $\dfrac{dx}{dt}=\dfrac{2}{1+t^2}$ $dx=\dfrac{2}{1+t^2}\,dt$ $\displaystyle\int_0^1 \left(\frac{1}{2-\cos x}\right)\left(\frac{2}{1+t^2}\right)\,dt$ Is this the right idea? If so what do I do next? $\displaystyle\int_0^1\left(\frac{1}{2-\frac{1-t^2}{1+t^2}}\right) \,\left(\frac{2}{1+t^2}\right)\, dt$ $\displaystyle\int_0^1\frac{2}{1+3t^2}\,dt$ $=2\left[\frac{\ln(1+3t^2)}{6t}\right]_0^1$",,"['calculus', 'integration', 'definite-integrals']"
35,$\sum_{k=1}^{n} \binom{n}{k}k^{r}$ [duplicate],[duplicate],\sum_{k=1}^{n} \binom{n}{k}k^{r},"This question already has answers here : Closed-form expression for $\sum_{k=0}^n\binom{n}kk^p$ for integers $n,\,p$ (7 answers) Closed 5 years ago . Find:$$\sum_{k=1}^{n} \binom{n}{k}k^{r}$$ For r=0 the sum is obviously $2^{n}$. For r=1 the sum is $n2^{n-1}$. For r=2 the sum is $n(n+1)2^{n-2}$. Here's what I've tried: $$\frac{d(1+x)^{n}}{dx}=n(1+x)^{n-1}=\binom{n}{1}+2\binom{n}{2}x+3\binom{n}{3}x^{2}+\cdots+n\binom{n}{n}x^{n-1}$$ $$\frac{d[x\cdot n(1+x)^{n-1}]}{dx}=\binom{n}{1}+2^{2}\binom{n}{2}x+3^{2}\binom{n}{3}x^{3}+\cdots+n^{2}\binom{n}{n}x^{n-1}$$ So if we continue like this and put x=1 we will get our result.However I cannot generalize this. I think the answer has something to do with the Stirling Numbers of the Second kind. Another way to present this question:     Find $A_{1},A_{2},\cdots ,A_{r}$ such that $$k^{r}=A_{1}k+A_{2}k(k-1)+A_{3}k(k-1)(k-2)+\cdots$$ If someone can answer the second question I can solve the first one.","This question already has answers here : Closed-form expression for $\sum_{k=0}^n\binom{n}kk^p$ for integers $n,\,p$ (7 answers) Closed 5 years ago . Find:$$\sum_{k=1}^{n} \binom{n}{k}k^{r}$$ For r=0 the sum is obviously $2^{n}$. For r=1 the sum is $n2^{n-1}$. For r=2 the sum is $n(n+1)2^{n-2}$. Here's what I've tried: $$\frac{d(1+x)^{n}}{dx}=n(1+x)^{n-1}=\binom{n}{1}+2\binom{n}{2}x+3\binom{n}{3}x^{2}+\cdots+n\binom{n}{n}x^{n-1}$$ $$\frac{d[x\cdot n(1+x)^{n-1}]}{dx}=\binom{n}{1}+2^{2}\binom{n}{2}x+3^{2}\binom{n}{3}x^{3}+\cdots+n^{2}\binom{n}{n}x^{n-1}$$ So if we continue like this and put x=1 we will get our result.However I cannot generalize this. I think the answer has something to do with the Stirling Numbers of the Second kind. Another way to present this question:     Find $A_{1},A_{2},\cdots ,A_{r}$ such that $$k^{r}=A_{1}k+A_{2}k(k-1)+A_{3}k(k-1)(k-2)+\cdots$$ If someone can answer the second question I can solve the first one.",,"['calculus', 'combinatorics']"
36,Exercise on convergent series,Exercise on convergent series,,"I am stumped by the following exercise (3.24 in Biler--Witkowski's book ""Problems in mathematical analysis""): Let $f$ be a continuous, increasing function from $[0,+\infty]$ to itself. Show that $$\sum \frac{1}{f(n)}$$ converges iff    $$\sum \frac{f^{-1}(n)}{n^2}$$ converges. Initially, I thought one could apply the integral test and do a change of variables in the integral (assuming $f$ to be $C^1$, say, which does not change anything) to move from one series to the other. This does not quite work - one of the issues being that $x \mapsto \frac{f^{-1}(x)}{x^2}$ does not need to be decreasing. I think I'm probably missing something obvious, as the exercise does not even deserve a hint in the book - would anyone have an idea? Note: this is not homework! I have not used series in a while and need to brush up on them for a class I'll be teaching over the summer, so I thought I'd spend the weekend doing exercises - so far, so good, except for this particular exercise. Thanks for your help!","I am stumped by the following exercise (3.24 in Biler--Witkowski's book ""Problems in mathematical analysis""): Let $f$ be a continuous, increasing function from $[0,+\infty]$ to itself. Show that $$\sum \frac{1}{f(n)}$$ converges iff    $$\sum \frac{f^{-1}(n)}{n^2}$$ converges. Initially, I thought one could apply the integral test and do a change of variables in the integral (assuming $f$ to be $C^1$, say, which does not change anything) to move from one series to the other. This does not quite work - one of the issues being that $x \mapsto \frac{f^{-1}(x)}{x^2}$ does not need to be decreasing. I think I'm probably missing something obvious, as the exercise does not even deserve a hint in the book - would anyone have an idea? Note: this is not homework! I have not used series in a while and need to brush up on them for a class I'll be teaching over the summer, so I thought I'd spend the weekend doing exercises - so far, so good, except for this particular exercise. Thanks for your help!",,"['calculus', 'sequences-and-series', 'analysis']"
37,I know this DE is solvable...,I know this DE is solvable...,,I need help with a seemingly simple looking diff equ $$ x\frac {d^{2}y} {dx^{2}}+2y=0 $$ $$ \rightarrow \frac {d^{2}y} {dx^{2}}+2\frac {y} {x}=0 $$ $v= (\frac {y} {x})$ substitution isn't working as it eventually shows: $$ xv''+v'+2v=0 $$ which isn't any easier.  That variable is making my blood pressure go up. I know I'm looking past something stupid.,I need help with a seemingly simple looking diff equ $$ x\frac {d^{2}y} {dx^{2}}+2y=0 $$ $$ \rightarrow \frac {d^{2}y} {dx^{2}}+2\frac {y} {x}=0 $$ $v= (\frac {y} {x})$ substitution isn't working as it eventually shows: $$ xv''+v'+2v=0 $$ which isn't any easier.  That variable is making my blood pressure go up. I know I'm looking past something stupid.,,"['calculus', 'ordinary-differential-equations']"
38,If $f\left(x\right)=\int\limits _{0}^{x}f\left(t\right)dt$ then $f \equiv 0$?,If  then ?,f\left(x\right)=\int\limits _{0}^{x}f\left(t\right)dt f \equiv 0,"$f:[0,\infty)\rightarrow\mathbb R$ is a function that for all $0\leq a<b\in \mathbb R$, $f_{|[a,b]}:[a,b]\rightarrow \mathbb R$ is integrable. assuming that for all $x\in[0,\infty)$ , $f\left(x\right)=\int\limits _{0}^{x}f\left(t\right)dt$ then $f\equiv0$ my attempt: First we know that $f\left(x\right)=\int\limits _{0}^{x}f\left(t\right)dt$ so $f(x)$ is an anti derivative of itself and continuous on $[0,\infty)$  $$ f\left(x\right)	=	\int\limits _{0}^{x}f\left(t\right)dt\Rightarrow f\left(x\right)-f\left(0\right)=f\left(x\right) 	\Rightarrow	f\left(0\right)=0 $$ Now according to Mean value theorem because $f$ is continuous and derivative on $[0,\infty)$ there exists $c\in[0,\infty)$ and $$ f(c)=\frac{f\left(x\right)-f\left(0\right)}{x}\Rightarrow f\left(c\right)=\frac{f\left(x\right)}{x} $$ It could be that this attempt will not lead me to a solution but this is all I got right now. if you have any ideas...","$f:[0,\infty)\rightarrow\mathbb R$ is a function that for all $0\leq a<b\in \mathbb R$, $f_{|[a,b]}:[a,b]\rightarrow \mathbb R$ is integrable. assuming that for all $x\in[0,\infty)$ , $f\left(x\right)=\int\limits _{0}^{x}f\left(t\right)dt$ then $f\equiv0$ my attempt: First we know that $f\left(x\right)=\int\limits _{0}^{x}f\left(t\right)dt$ so $f(x)$ is an anti derivative of itself and continuous on $[0,\infty)$  $$ f\left(x\right)	=	\int\limits _{0}^{x}f\left(t\right)dt\Rightarrow f\left(x\right)-f\left(0\right)=f\left(x\right) 	\Rightarrow	f\left(0\right)=0 $$ Now according to Mean value theorem because $f$ is continuous and derivative on $[0,\infty)$ there exists $c\in[0,\infty)$ and $$ f(c)=\frac{f\left(x\right)-f\left(0\right)}{x}\Rightarrow f\left(c\right)=\frac{f\left(x\right)}{x} $$ It could be that this attempt will not lead me to a solution but this is all I got right now. if you have any ideas...",,"['calculus', 'integration', 'definite-integrals']"
39,Help with Euler Substitution,Help with Euler Substitution,,"Let $a < 0$. Find the following indefinite integral by using the third Euler substitution. $$\int \frac{dx}{(x^2 + a^2) \sqrt{x^2 - a^2}}$$ Where the third Euler substitution is defined by: Given an integral of the form $\int R(x, \sqrt{ax^2 + bx + c})dx,$ $a \neq 0$. If the quadratic polynomial under the radical has 2 distinct real roots $\alpha_1$ and $\alpha_2$ i.e., $$ax^2 + bx + c = a(x-\alpha_1)(x - \alpha_2),$$ then set $$\sqrt{ax^2 + bx + c} = t(x - \alpha_{1 \text{ or } 2}).$$ Hint: $t^4 + 1 = (t^2 - \sqrt 2t + 1)(t^2 + \sqrt 2t + 1)$. I tried beginning by setting $$\sqrt{x^2 - a^2} = t(x-a)$$ and attempted to solve for $x$ in order to find some function to define $dx$ in terms of $dt$ but I'm having some trouble. I'm not quite sure how to apply the hint here. Thanks in advance.","Let $a < 0$. Find the following indefinite integral by using the third Euler substitution. $$\int \frac{dx}{(x^2 + a^2) \sqrt{x^2 - a^2}}$$ Where the third Euler substitution is defined by: Given an integral of the form $\int R(x, \sqrt{ax^2 + bx + c})dx,$ $a \neq 0$. If the quadratic polynomial under the radical has 2 distinct real roots $\alpha_1$ and $\alpha_2$ i.e., $$ax^2 + bx + c = a(x-\alpha_1)(x - \alpha_2),$$ then set $$\sqrt{ax^2 + bx + c} = t(x - \alpha_{1 \text{ or } 2}).$$ Hint: $t^4 + 1 = (t^2 - \sqrt 2t + 1)(t^2 + \sqrt 2t + 1)$. I tried beginning by setting $$\sqrt{x^2 - a^2} = t(x-a)$$ and attempted to solve for $x$ in order to find some function to define $dx$ in terms of $dt$ but I'm having some trouble. I'm not quite sure how to apply the hint here. Thanks in advance.",,"['calculus', 'integration']"
40,Find the maximum area of the regular pentagon,Find the maximum area of the regular pentagon,,Find the maximum area of the regular pentagon that inscribed a unit square.,Find the maximum area of the regular pentagon that inscribed a unit square.,,"['calculus', 'geometry', 'inequality', 'optimization']"
41,"If $f(x)+f'(x)-\frac{1}{x+1}\int_{0}^{x}f(t)dt=0$ and $f(0)=0$, then what is $f'(x)$?","If  and , then what is ?",f(x)+f'(x)-\frac{1}{x+1}\int_{0}^{x}f(t)dt=0 f(0)=0 f'(x),"$f\in C^{1}[0,\infty)$, $f(0)=0$ and  $$ f(x)+f'(x)-\frac{1}{x+1}\int_{0}^{x}f(t)dt=0 $$ then $f'(x)=$ ? I'v tried in the following ways. First, let $F(x)=\int_{0}^{x}f(t)dt$, then we are left to solve a second order ODE with initial condition $F(0)=0$, and $F'(0)=0$, but the problem is it seems to me that it's not that easy to solve it. I hope there are some other ways to handle it that a one year students can understand. (I have tried to write $g(x)=f(x)e^x$ to rewrite the equation, but it doesn't make it easier)","$f\in C^{1}[0,\infty)$, $f(0)=0$ and  $$ f(x)+f'(x)-\frac{1}{x+1}\int_{0}^{x}f(t)dt=0 $$ then $f'(x)=$ ? I'v tried in the following ways. First, let $F(x)=\int_{0}^{x}f(t)dt$, then we are left to solve a second order ODE with initial condition $F(0)=0$, and $F'(0)=0$, but the problem is it seems to me that it's not that easy to solve it. I hope there are some other ways to handle it that a one year students can understand. (I have tried to write $g(x)=f(x)e^x$ to rewrite the equation, but it doesn't make it easier)",,"['calculus', 'ordinary-differential-equations', 'integral-equations']"
42,"Showing that $f(x)$ is increasing on $(0,+\infty)$",Showing that  is increasing on,"f(x) (0,+\infty)","I am collecting some easy problems for my students and now I am facing to the following problem: Prove that the function $$f(x)=\left(1+\frac{1}{x}\right)^x$$ is increasing in   $(0,+\infty)$. Undoubtedly, they will solve it by using the logarithmic differentiation . I am wonder what can I do if someone wants me to verify it just by doing the definition of increasing function? I think , I am missing somethings here around. Light my way. Thanks!","I am collecting some easy problems for my students and now I am facing to the following problem: Prove that the function $$f(x)=\left(1+\frac{1}{x}\right)^x$$ is increasing in   $(0,+\infty)$. Undoubtedly, they will solve it by using the logarithmic differentiation . I am wonder what can I do if someone wants me to verify it just by doing the definition of increasing function? I think , I am missing somethings here around. Light my way. Thanks!",,['calculus']
43,Characterization of uniform continuity via sequence,Characterization of uniform continuity via sequence,,"For $f(x)$ , defined on the interval $X$ , $f(x)$ is uniformly continuous in X if and only if for every sequences $x_{n}$ , $y_{n}\in X$ , when we have $\lim_{n\rightarrow\infty}(x_{n}-y_{n})=0$ , then $\lim_{n\rightarrow\infty}[f(x_{n})-f(y_{n})]=0$ . For this characterization, I am confused with three point. It is shown on my textbook that, for $f(x)=x^2$ , defined in $[0,+\infty)$ , $x_{n}=\sqrt {n+1}$ , $y_{n}=\sqrt{n}$ were chosen. I wonder why not to choose some apparent sequence such as $x_{n}=1/n$ , $y_{n}=1/2n$ . In my opinion, I think that $1/n$ and $1/2n$ are not defined on zero point. For function $f(x)=1/x$ , defined in $(\xi,1)$ , $0\lt\xi\lt1$ ), I wonder why it's unwarranted to use $x_{n}=1/n$ , $y_{n}=1/2n$ . As far as I am concerned, we need to confirm $\lim_{n\rightarrow\infty}[f(x_{n})-f(y_{n})]$ and if $x_{n}$ is defined in $(\xi,1)$ then $n$ should be in $(1,1/\xi)$ . Finally, $n$ can't tend to $\infty$ . I noticed that this characterization mention that for all $x_{n}$ , $y_{n}$ . What if we want to prove uniform continuity for certain function? How can we choose all suited sequences? thanks.","For , defined on the interval , is uniformly continuous in X if and only if for every sequences , , when we have , then . For this characterization, I am confused with three point. It is shown on my textbook that, for , defined in , , were chosen. I wonder why not to choose some apparent sequence such as , . In my opinion, I think that and are not defined on zero point. For function , defined in , ), I wonder why it's unwarranted to use , . As far as I am concerned, we need to confirm and if is defined in then should be in . Finally, can't tend to . I noticed that this characterization mention that for all , . What if we want to prove uniform continuity for certain function? How can we choose all suited sequences? thanks.","f(x) X f(x) x_{n} y_{n}\in X \lim_{n\rightarrow\infty}(x_{n}-y_{n})=0 \lim_{n\rightarrow\infty}[f(x_{n})-f(y_{n})]=0 f(x)=x^2 [0,+\infty) x_{n}=\sqrt {n+1} y_{n}=\sqrt{n} x_{n}=1/n y_{n}=1/2n 1/n 1/2n f(x)=1/x (\xi,1) 0\lt\xi\lt1 x_{n}=1/n y_{n}=1/2n \lim_{n\rightarrow\infty}[f(x_{n})-f(y_{n})] x_{n} (\xi,1) n (1,1/\xi) n \infty x_{n} y_{n}",['calculus']
44,"Maximize the integral of $f$, knowing the integral of $\frac{1}{f}$, for a Lipschitz function $f$","Maximize the integral of , knowing the integral of , for a Lipschitz function",f \frac{1}{f} f,"This question is related to this recent other question , where two intervals $[a,b] $ and $[c,d]$ were considered. Here I ask about a simpler version with just one interval $[a,b]$. Consider the following optimization problem : $f$ is a positive continuous function $[a,b] \to ]0,+\infty[$, satisfying the Lipschitz condition $|f(x)-f(y)| \leq L|x-y|$ for any $x,y \in [a,b]$. Given the constraint $\int_{a}^{b}\frac{dt}{f(t)}=\alpha$ (where $\alpha$ is a positive constant), the problem is then to find the maximum (or supremum) value $M$ of $\int_{a}^{b}f(t)dt$ under this constraint, and find the functions for which this maximum is attained, if any. Although my evidence for this is still incomplete, I believe the maximum is attained when $f$ is a decreasing affine function with coefficient $-L$. In this case, $$ f(t)=L\bigg(b-t+\frac{b-a}{e^{L\alpha}-1}\bigg), \ \int_a^{b} f(t)dt= L(b-a)^2\bigg(\frac{1}{2}+\frac{1}{e^{L\alpha}-1}\bigg) $$ By the Stone-Weierstrass theorem, when looking for the maximum we may assume that $f$ is differentiable (we may even assume that $f$ is a polynomial). In this case, one may apply the methods explained in the abovementioned post : $|f'| \leq L$, so $|(f^2)'| =|2ff'| \leq 2L|f|$ and hence $f^2(x) \leq f^2(a)+2LF(x)$, where we put $F(x)=\int_a^x f(t)dt$. So $f(x)=\frac{f^2(x)}{f(x)} \leq \frac{ f^2(a)+2LF(x)}{f(x)}$. Putting $G(x)=f^2(a)+2LF(x)$, we deduce $\frac{G'(x)}{G(x)} \leq \frac{2L}{f(x)}$. integrating between $a$ and $b$, we obtain ${\sf ln}\big(\frac{G(b)}{G(a)}\big) \leq 2L\alpha$. Now $G(a)=f^2(a)$ and $G(b)=f^2(a)+2L\int_a^b f(t)dt$, so that one finally obtains $$ \int_a^b f(t)dt \leq \frac{e^{2L\alpha}-1}{2L}f^2(a) $$ Any feedback appreciated on the following questions : what is the maximum/supremum, which functions attain equality.","This question is related to this recent other question , where two intervals $[a,b] $ and $[c,d]$ were considered. Here I ask about a simpler version with just one interval $[a,b]$. Consider the following optimization problem : $f$ is a positive continuous function $[a,b] \to ]0,+\infty[$, satisfying the Lipschitz condition $|f(x)-f(y)| \leq L|x-y|$ for any $x,y \in [a,b]$. Given the constraint $\int_{a}^{b}\frac{dt}{f(t)}=\alpha$ (where $\alpha$ is a positive constant), the problem is then to find the maximum (or supremum) value $M$ of $\int_{a}^{b}f(t)dt$ under this constraint, and find the functions for which this maximum is attained, if any. Although my evidence for this is still incomplete, I believe the maximum is attained when $f$ is a decreasing affine function with coefficient $-L$. In this case, $$ f(t)=L\bigg(b-t+\frac{b-a}{e^{L\alpha}-1}\bigg), \ \int_a^{b} f(t)dt= L(b-a)^2\bigg(\frac{1}{2}+\frac{1}{e^{L\alpha}-1}\bigg) $$ By the Stone-Weierstrass theorem, when looking for the maximum we may assume that $f$ is differentiable (we may even assume that $f$ is a polynomial). In this case, one may apply the methods explained in the abovementioned post : $|f'| \leq L$, so $|(f^2)'| =|2ff'| \leq 2L|f|$ and hence $f^2(x) \leq f^2(a)+2LF(x)$, where we put $F(x)=\int_a^x f(t)dt$. So $f(x)=\frac{f^2(x)}{f(x)} \leq \frac{ f^2(a)+2LF(x)}{f(x)}$. Putting $G(x)=f^2(a)+2LF(x)$, we deduce $\frac{G'(x)}{G(x)} \leq \frac{2L}{f(x)}$. integrating between $a$ and $b$, we obtain ${\sf ln}\big(\frac{G(b)}{G(a)}\big) \leq 2L\alpha$. Now $G(a)=f^2(a)$ and $G(b)=f^2(a)+2L\int_a^b f(t)dt$, so that one finally obtains $$ \int_a^b f(t)dt \leq \frac{e^{2L\alpha}-1}{2L}f^2(a) $$ Any feedback appreciated on the following questions : what is the maximum/supremum, which functions attain equality.",,"['calculus', 'integration', 'functional-analysis', 'optimization', 'lipschitz-functions']"
45,Limit of sequence $x_n^n$,Limit of sequence,x_n^n,"Let $x_1=2$, $x_{n+1}=\sqrt{x_n+\frac{1}{n}}$ for all $n\geq 1$. Prove that $\lim\limits_{n\to\infty}x_n=1$ and evaluate $\lim\limits_{n\to\infty}x_n^n$.","Let $x_1=2$, $x_{n+1}=\sqrt{x_n+\frac{1}{n}}$ for all $n\geq 1$. Prove that $\lim\limits_{n\to\infty}x_n=1$ and evaluate $\lim\limits_{n\to\infty}x_n^n$.",,"['calculus', 'sequences-and-series', 'limits']"
46,Zeroes of a Particular Function,Zeroes of a Particular Function,,I'm looking for the zeroes of $f(k) = e^{\sqrt{k}}[\frac{s}{k} - \frac{d}{\sqrt{k}}] - 1$ on the set $k > 0$. Is there a nice way to describe the set of solutions for given $s$ and $d$? Thanks!,I'm looking for the zeroes of $f(k) = e^{\sqrt{k}}[\frac{s}{k} - \frac{d}{\sqrt{k}}] - 1$ on the set $k > 0$. Is there a nice way to describe the set of solutions for given $s$ and $d$? Thanks!,,"['calculus', 'roots']"
47,How does big-Oh notation work?,How does big-Oh notation work?,,"I am reading this document . In this article after defining strong derivative Knuth goes on to calculate derivative of $x^n$ . There he uses definition of strong derivative to expand $(x+\epsilon)^{n+1}$ as follows, $(x+\epsilon)^{n+1} = (x+\epsilon)[x^n + d_n(x)\epsilon + \mathcal{O}(\epsilon^2)]$ when I expand the right side  I get $x^{n+1} + (x d_n(x) +  \ x^n)\epsilon + \color{red}{x \ \mathcal{O}(\epsilon^2)  + \epsilon^2 \ d_n(x) + \epsilon \ \mathcal{O}(\epsilon^2)}$ But in Knuths calculations the red part is just $\mathcal{O}(\epsilon^2)$ . Question is how? I don't know how to work this out in detail.","I am reading this document . In this article after defining strong derivative Knuth goes on to calculate derivative of . There he uses definition of strong derivative to expand as follows, when I expand the right side  I get But in Knuths calculations the red part is just . Question is how? I don't know how to work this out in detail.",x^n (x+\epsilon)^{n+1} (x+\epsilon)^{n+1} = (x+\epsilon)[x^n + d_n(x)\epsilon + \mathcal{O}(\epsilon^2)] x^{n+1} + (x d_n(x) +  \ x^n)\epsilon + \color{red}{x \ \mathcal{O}(\epsilon^2)  + \epsilon^2 \ d_n(x) + \epsilon \ \mathcal{O}(\epsilon^2)} \mathcal{O}(\epsilon^2),"['calculus', 'asymptotics']"
48,how to calculate the limit of an integral?,how to calculate the limit of an integral?,,Could you please tell me how to calculate the limit:  $$\lim_{x\rightarrow+\infty}\left(\int_0^1\sup_{s>x}\frac{s}{e^{(s\log s)t}}dt\right)$$ Thank you so much!,Could you please tell me how to calculate the limit:  $$\lim_{x\rightarrow+\infty}\left(\int_0^1\sup_{s>x}\frac{s}{e^{(s\log s)t}}dt\right)$$ Thank you so much!,,['calculus']
49,When should the antiderivative of a rational function be defined as a piecewise function?,When should the antiderivative of a rational function be defined as a piecewise function?,,"I'm doing basic problems on antiderivatives and there seems to be an inconsistency in my book. The instructions for these problems are: Find the most general antiderivative of the function. Number 11 is: 11. $f(x) = \dfrac{10}{x^9}$ So, I naturally wrote down $F(x) = -\dfrac{5}{4x^8} + C$. The solution manual says this is wrong.  The function has domain $(-\infty, 0) \cup (0, \infty)$, so $F(x) = \begin{cases} -\dfrac{5}{4x^8}+C_1 & \text{if } x < 0 \\ -\dfrac{5}{4x^8}+C_2 & \text{if } x > 0 \end{cases}$ Okay, I thought.  That makes sense. I then come to number 13, which is: 13. $f(x) = \dfrac{u^4 + 3\sqrt{u}}{u^2}$. I figured the domain is $(-\infty, 0) \cup (0, \infty)$, so I wrote down $F(x) = \begin{cases} \frac{1}{3}u^3-6u^{-1/2}+C_1 & \text{if } u > 0 \\ \frac{1}{3}u^3-6u^{-1/2}+C_2 & \text{if } u < 0 \end{cases}$. Well, the solution book doesn't mention the domain and just says $F(x) = \frac{1}{3}u^3-6u^{-1/2}+C$. I later realized that the $\sqrt{u}$ in the numerator and the $u^2$ in the denominator must limit the domain to the positive numbers, so the antiderivative doesn't need to be defined for anything but positive numbers.  So, okay, I think I get it. Next number 19 is: 19. $f(x) = \dfrac{x^5-x^3+2x}{x^4} = x - \dfrac{1}{x} + \dfrac{2}{x^3}$ So, again, since the domain appears to be $(-\infty, 0) \cup (0, \infty)$, I wrote down $F(x) = \begin{cases} \frac{1}{2}x^2 - \ln|x| - \dfrac{1}{x^2} + C_1 & \text{if } x > 0 \\ \frac{1}{2}x^2 - \ln|x| - \dfrac{1}{x^2} + C_2 & \text{if } x < 0 \end{cases}$. But the book again doesn't mention the domain and just says that $F(x) = \frac{1}{2}x^2 - \ln|x| - \dfrac{1}{x^2} + C$. I am confused.  This doesn't seem consistent, especially between #11 and #19.  Why is my answer not right for #19?","I'm doing basic problems on antiderivatives and there seems to be an inconsistency in my book. The instructions for these problems are: Find the most general antiderivative of the function. Number 11 is: 11. $f(x) = \dfrac{10}{x^9}$ So, I naturally wrote down $F(x) = -\dfrac{5}{4x^8} + C$. The solution manual says this is wrong.  The function has domain $(-\infty, 0) \cup (0, \infty)$, so $F(x) = \begin{cases} -\dfrac{5}{4x^8}+C_1 & \text{if } x < 0 \\ -\dfrac{5}{4x^8}+C_2 & \text{if } x > 0 \end{cases}$ Okay, I thought.  That makes sense. I then come to number 13, which is: 13. $f(x) = \dfrac{u^4 + 3\sqrt{u}}{u^2}$. I figured the domain is $(-\infty, 0) \cup (0, \infty)$, so I wrote down $F(x) = \begin{cases} \frac{1}{3}u^3-6u^{-1/2}+C_1 & \text{if } u > 0 \\ \frac{1}{3}u^3-6u^{-1/2}+C_2 & \text{if } u < 0 \end{cases}$. Well, the solution book doesn't mention the domain and just says $F(x) = \frac{1}{3}u^3-6u^{-1/2}+C$. I later realized that the $\sqrt{u}$ in the numerator and the $u^2$ in the denominator must limit the domain to the positive numbers, so the antiderivative doesn't need to be defined for anything but positive numbers.  So, okay, I think I get it. Next number 19 is: 19. $f(x) = \dfrac{x^5-x^3+2x}{x^4} = x - \dfrac{1}{x} + \dfrac{2}{x^3}$ So, again, since the domain appears to be $(-\infty, 0) \cup (0, \infty)$, I wrote down $F(x) = \begin{cases} \frac{1}{2}x^2 - \ln|x| - \dfrac{1}{x^2} + C_1 & \text{if } x > 0 \\ \frac{1}{2}x^2 - \ln|x| - \dfrac{1}{x^2} + C_2 & \text{if } x < 0 \end{cases}$. But the book again doesn't mention the domain and just says that $F(x) = \frac{1}{2}x^2 - \ln|x| - \dfrac{1}{x^2} + C$. I am confused.  This doesn't seem consistent, especially between #11 and #19.  Why is my answer not right for #19?",,['calculus']
50,Exact Differential Equations,Exact Differential Equations,,"I was revising differential equations and came across the topic of exact differential equations. I have a doubt concerning it. Suppose the differential equation $M(x,y)dx + N(x,y)dy=0$ is exact. Then the solution is given by: $\int Mdx +\int (N-\frac{\partial}{\partial y}\int Mdx)dy = c$. I understand that the integrand in the second term is a function of y alone and also understand the derivation of this solution. What I don't understand is the following paragraph: My book then says ""Since all the terms of the solution that contain x must appear in $\int Mdx$, its derivative w.r.t. y must have all the terms of N that contain x. Hence the general rule to be followed is: Integrate $\int Mdx$ as if y were constant. Also integrate the terms of N that do not contain x w.r.t. y. Equate the sum of these integrals to a constant."" I don't understand the justification that is provided for the general rule. Can someone please explain this?","I was revising differential equations and came across the topic of exact differential equations. I have a doubt concerning it. Suppose the differential equation $M(x,y)dx + N(x,y)dy=0$ is exact. Then the solution is given by: $\int Mdx +\int (N-\frac{\partial}{\partial y}\int Mdx)dy = c$. I understand that the integrand in the second term is a function of y alone and also understand the derivation of this solution. What I don't understand is the following paragraph: My book then says ""Since all the terms of the solution that contain x must appear in $\int Mdx$, its derivative w.r.t. y must have all the terms of N that contain x. Hence the general rule to be followed is: Integrate $\int Mdx$ as if y were constant. Also integrate the terms of N that do not contain x w.r.t. y. Equate the sum of these integrals to a constant."" I don't understand the justification that is provided for the general rule. Can someone please explain this?",,['calculus']
51,A calculus question,A calculus question,,"On the interval $(0, \infty)$,the function $f \geq 0$,$f' \leq 0$, and $f'' \geq 0$.Prove that $\lim\limits_{x \to \infty} xf'(x) = 0$.","On the interval $(0, \infty)$,the function $f \geq 0$,$f' \leq 0$, and $f'' \geq 0$.Prove that $\lim\limits_{x \to \infty} xf'(x) = 0$.",,"['calculus', 'functions']"
52,Integrating over level sets of a function,Integrating over level sets of a function,,"I have a background in math, but I think the following construction appears often in physics. Is there a term for a functional which maps one smooth function $f: R^n \rightarrow R$ to another $L(f):R \rightarrow R$ which represents the integral along each level set?  That is,  $L(f)(a) = \int_{f^{-1}(a)} d\mu $  where the measure $d\mu$ might be the induced measure from the metric on $R^n$, or it might also depend on the original $f$ in some intelligent way. For instance, if the initial function is $f:R^2 \rightarrow R$ is defined $f(x)=x^2+y^2$ then $L(f)(a) = 2 \pi \sqrt{a}$. If the original function is $f:R \rightarrow R$ is defined $f(x)=x^2$, then we'd have $L(f)(a)=0$ for $a<0$, $1$ for $a=0$, and $2$ for $a>0$.  In both cases it might be more natural to integrate with a term derived from the value of $f'$ normal to the level set. I suppose one could generalize to any smooth map $f:M \rightarrow M'$ from a Riemannian manifold to a another smooth manifold and get a new function that represents a computed volume of the preimage for each point:  $L(f):M' \rightarrow R$. My question:  Is there a good way to compute $L(f)$ for some class of function $f$? Any thoughts would be appreciated.  It is reminiscent of (but I hope simpler than) stationary phase approximations and path integral calculations. http://en.wikipedia.org/wiki/Stationary_phase_approximation","I have a background in math, but I think the following construction appears often in physics. Is there a term for a functional which maps one smooth function $f: R^n \rightarrow R$ to another $L(f):R \rightarrow R$ which represents the integral along each level set?  That is,  $L(f)(a) = \int_{f^{-1}(a)} d\mu $  where the measure $d\mu$ might be the induced measure from the metric on $R^n$, or it might also depend on the original $f$ in some intelligent way. For instance, if the initial function is $f:R^2 \rightarrow R$ is defined $f(x)=x^2+y^2$ then $L(f)(a) = 2 \pi \sqrt{a}$. If the original function is $f:R \rightarrow R$ is defined $f(x)=x^2$, then we'd have $L(f)(a)=0$ for $a<0$, $1$ for $a=0$, and $2$ for $a>0$.  In both cases it might be more natural to integrate with a term derived from the value of $f'$ normal to the level set. I suppose one could generalize to any smooth map $f:M \rightarrow M'$ from a Riemannian manifold to a another smooth manifold and get a new function that represents a computed volume of the preimage for each point:  $L(f):M' \rightarrow R$. My question:  Is there a good way to compute $L(f)$ for some class of function $f$? Any thoughts would be appreciated.  It is reminiscent of (but I hope simpler than) stationary phase approximations and path integral calculations. http://en.wikipedia.org/wiki/Stationary_phase_approximation",,"['calculus', 'analysis']"
53,In what time $\tau$ will the particle reach the point $x=0$?,In what time  will the particle reach the point ?,\tau x=0,"A particle of mass $m$ capable of moving along the $x$ -axis, is acted upon by a force $F(x) = -\frac{k}{x^3}$ . At the initial time moment $t=0$ , the particle is at the point $x=x_0>0$ , and its velocity is $\dot{x}(0)=0$ . In what time $\tau$ will the particle reach the point $x=0$ ? My attempt: We basically have to solve this second order nonlinear ODE $$\frac{d^{2}x}{dt^{2}}=-\frac{k}{mx^{3}}.$$ Using substitution $v=\frac{dx}{dt}$ , we get $\frac{dv}{dt}=-\frac{k}{mx^3}$ , using chain rule to rewrite $\frac{dv}{dt}=v\frac{dv}{dx}$ , then separate ant integrate $$\frac{1}{2}v^2 = \frac{k}{2mx^2} + A \implies v = \sqrt{\frac{k}{mx^2} + A}.$$ The result I got is $v = \sqrt{\frac{k}{mx^2} + A}$ , where $A$ is a constant of integration. After plugging in the initial conditions we find the value of $A=-\frac{k}{2mx_0^2}$ . Next, applying the initial conditions and keeping in mind that velocity is negative due to given conditions, $$$$ \begin{aligned} &\int_0^\tau dt=-\int_{x_0}^0\frac{dx}{\sqrt{\frac k{mx^2}-\frac k{mx_0^2}}} \\ &\tau=-\int_{x_0}^0\frac{dx}{\sqrt{\frac k{mx^2}-\frac k{mx_0^2}}} \end{aligned} Are there any ways to simplify it further? I suppose we can make use of some integrals with similar form like $\int \frac{dx}{\sqrt{a^2-x^2}}=\arcsin(\frac{x}{a})$","A particle of mass capable of moving along the -axis, is acted upon by a force . At the initial time moment , the particle is at the point , and its velocity is . In what time will the particle reach the point ? My attempt: We basically have to solve this second order nonlinear ODE Using substitution , we get , using chain rule to rewrite , then separate ant integrate The result I got is , where is a constant of integration. After plugging in the initial conditions we find the value of . Next, applying the initial conditions and keeping in mind that velocity is negative due to given conditions, Are there any ways to simplify it further? I suppose we can make use of some integrals with similar form like","m x F(x) = -\frac{k}{x^3} t=0 x=x_0>0 \dot{x}(0)=0 \tau x=0 \frac{d^{2}x}{dt^{2}}=-\frac{k}{mx^{3}}. v=\frac{dx}{dt} \frac{dv}{dt}=-\frac{k}{mx^3} \frac{dv}{dt}=v\frac{dv}{dx} \frac{1}{2}v^2 = \frac{k}{2mx^2} + A \implies v = \sqrt{\frac{k}{mx^2} + A}. v = \sqrt{\frac{k}{mx^2} + A} A A=-\frac{k}{2mx_0^2}  \begin{aligned}
&\int_0^\tau dt=-\int_{x_0}^0\frac{dx}{\sqrt{\frac k{mx^2}-\frac k{mx_0^2}}} \\
&\tau=-\int_{x_0}^0\frac{dx}{\sqrt{\frac k{mx^2}-\frac k{mx_0^2}}}
\end{aligned} \int \frac{dx}{\sqrt{a^2-x^2}}=\arcsin(\frac{x}{a})","['calculus', 'integration', 'ordinary-differential-equations', 'solution-verification', 'physics']"
54,Evaluating $\int_1^{\sqrt2} \frac{\tanh^{-1}(\sqrt{2-x^2})}{1+x} dx$,Evaluating,\int_1^{\sqrt2} \frac{\tanh^{-1}(\sqrt{2-x^2})}{1+x} dx,"I was trying to compute the value of the integral $$\ I = \int_1^{\sqrt2} \frac{\operatorname{arctanh}(\sqrt{2-x^2})}{1+x}dx$$ I began by declaring the family of integrals: $$\ I(a) = \int_1^{\sqrt2} \frac{\operatorname{arctanh}(a\sqrt{2-x^2})}{1+x}dx$$ And then differentiating under the integral sign in accordance to the Leibnitz rule, keeping in mind that: $$\frac{d}{dx}\operatorname{arctanh}(x) = \frac{1}{1-x^2}$$ I obtained: $$\ I'(a) = \int_1^{\sqrt2} \frac{\sqrt{2-x^2}dx}{(1-a^2(2-x^2))\cdot (1+x)}$$ Now I substitute $\ x = \sqrt2 sin\theta$ . Changing the bounds, I received: $$\ I'(a) = \int_{\frac{\pi}{4}}^{\frac{\pi}{2}} \frac{2\cos^2\theta d\theta}{(1-2a^2\cos^2\theta)\cdot (1+\sqrt2 \sin\theta)}$$ The problem with this integral is that - When the cosine term in the denominator varies from $\frac{1}{\sqrt2}$ to $0$ , it will reach a point within the above range such that $$\ 1 = 2a^2cos^2\theta$$ For all non zero $a>1$ , it will have an asymptote. I do not understand how we will be able to then simplify the integral further. Maybe the radius of convergence of the integral necessitates that $\ a<1$ ? If we assume that the integral converges, I think we can evaluate $I'(a)$ by multiplying and dividing by $\frac{-1}{a^2}$ . I am getting a not-so-good expression for $I'(a)$ : $$\ I'(a) =  \frac{-1}{a^2}\cdot \big[ \frac{1}{2}\cdot \log(2) - \int_{\frac{\pi}{4}}^{\frac{\pi}{2}} \frac{d\theta}{(1-2a^2\cos^2\theta)(1+\sqrt2\sin\theta)}\big]$$ Note that for the special case $\ a = 1$ , it is probably the case that $$\ I(1) = \frac{\pi^2}{48}$$ This was deduced from WolframAlpha as a possible closed form for the integral. I have not confirmed whether this is the real answer or not, but it does seem to match. Any help is appreciated. I am also open to other techniques for evaluating the original integral. Thanks for reading!","I was trying to compute the value of the integral I began by declaring the family of integrals: And then differentiating under the integral sign in accordance to the Leibnitz rule, keeping in mind that: I obtained: Now I substitute . Changing the bounds, I received: The problem with this integral is that - When the cosine term in the denominator varies from to , it will reach a point within the above range such that For all non zero , it will have an asymptote. I do not understand how we will be able to then simplify the integral further. Maybe the radius of convergence of the integral necessitates that ? If we assume that the integral converges, I think we can evaluate by multiplying and dividing by . I am getting a not-so-good expression for : Note that for the special case , it is probably the case that This was deduced from WolframAlpha as a possible closed form for the integral. I have not confirmed whether this is the real answer or not, but it does seem to match. Any help is appreciated. I am also open to other techniques for evaluating the original integral. Thanks for reading!",\ I = \int_1^{\sqrt2} \frac{\operatorname{arctanh}(\sqrt{2-x^2})}{1+x}dx \ I(a) = \int_1^{\sqrt2} \frac{\operatorname{arctanh}(a\sqrt{2-x^2})}{1+x}dx \frac{d}{dx}\operatorname{arctanh}(x) = \frac{1}{1-x^2} \ I'(a) = \int_1^{\sqrt2} \frac{\sqrt{2-x^2}dx}{(1-a^2(2-x^2))\cdot (1+x)} \ x = \sqrt2 sin\theta \ I'(a) = \int_{\frac{\pi}{4}}^{\frac{\pi}{2}} \frac{2\cos^2\theta d\theta}{(1-2a^2\cos^2\theta)\cdot (1+\sqrt2 \sin\theta)} \frac{1}{\sqrt2} 0 \ 1 = 2a^2cos^2\theta a>1 \ a<1 I'(a) \frac{-1}{a^2} I'(a) \ I'(a) =  \frac{-1}{a^2}\cdot \big[ \frac{1}{2}\cdot \log(2) - \int_{\frac{\pi}{4}}^{\frac{\pi}{2}} \frac{d\theta}{(1-2a^2\cos^2\theta)(1+\sqrt2\sin\theta)}\big] \ a = 1 \ I(1) = \frac{\pi^2}{48},"['calculus', 'integration']"
55,Does $\int (x^{dx}-1)$ make sense?,Does  make sense?,\int (x^{dx}-1),"I came across the YouTube video ""I Computed An Integral That Breaks Math"" by BriTheMathGuy, where the problem is computing $$\label{eq_1}\tag{1}\int (x^{dx}-1)$$ And basically to solve this integral we use a little trick writing the argument of $\eqref{eq_1}$ like $$\label{eq_2}\tag{2}\color{red}{\frac{x^{dx}-1}{dx}}\cdot dx$$ The red part of $\eqref{eq_2}$ could be interpreted as $$\label{eq_3}\tag{3}\lim_{h\to 0} \frac{x^h-1}{h} = \log (x)$$ And then we can compute the integral of $$\eqref{eq_1} = \int \log(x)dx = x\log(x) - x + c$$ Is this possible, does $\eqref{eq_1}$ even makes sense to write an integral with $dx$ in that unusual position, or is a glamour social media trick? What disturbs me about $\eqref{eq_2}$ is that even tough we can think of $dx$ as an infinitesimal quantity, deeply it isn't, it is a differential. Has someone some thoughts on this or is just a waste of time? Thank you so much.","I came across the YouTube video ""I Computed An Integral That Breaks Math"" by BriTheMathGuy, where the problem is computing And basically to solve this integral we use a little trick writing the argument of like The red part of could be interpreted as And then we can compute the integral of Is this possible, does even makes sense to write an integral with in that unusual position, or is a glamour social media trick? What disturbs me about is that even tough we can think of as an infinitesimal quantity, deeply it isn't, it is a differential. Has someone some thoughts on this or is just a waste of time? Thank you so much.",\label{eq_1}\tag{1}\int (x^{dx}-1) \eqref{eq_1} \label{eq_2}\tag{2}\color{red}{\frac{x^{dx}-1}{dx}}\cdot dx \eqref{eq_2} \label{eq_3}\tag{3}\lim_{h\to 0} \frac{x^h-1}{h} = \log (x) \eqref{eq_1} = \int \log(x)dx = x\log(x) - x + c \eqref{eq_1} dx \eqref{eq_2} dx,"['calculus', 'integration', 'indefinite-integrals', 'recreational-mathematics']"
56,Is Fubini’s theorem behind this equality?,Is Fubini’s theorem behind this equality?,,"I consider $H$ and $h$ two non negative functions. I had hard time to understand this equality $$ \int_{0}^{t}h(t-s)\left(\int_{0}^{s}H(s-u)udu\right)ds = \int_{0}^{t}u\left(\int_{u}^{t}h(t-s)H(s-u)ds\right)du $$ I think it is just an application of Fubini theorem, however I don’t succeed to get the same expression. Indeed I get $$ \int_{0}^{t}h(t-s)\left(\int_{0}^{s}H(s-u)udu\right)ds = \int_{0}^{s}u\left(\int_{0}^{t}h(t-s)H(s-u)ds\right)du $$ I tried some change of variable ( introduce $v = s - u$ ), it was not successful. Am I missing something ? Thank you a lot Edit : use of the hint given by Bruno.B \begin{split}   = & \int_{0}^{t}h(t-s)\left(\int_{0}^{s}H(s-u)udu\right)ds \\ = & \int_{0}^{\infty}h(t-s)1_{u\leq s\leq t}\left(\int_{0}^{\infty}H(s-u)u1_{0\leq u \leq s\leq t}du\right)ds \\ = & \int_{0}^{\infty}u1_{0\leq u \leq t}\left(\int_{0}^{\infty}H(s-u)h(t-s)1_{u\leq s\leq t}ds\right)du \\ = & \int_{0}^{t}u\left(\int_{u}^{t}h(t-s)H(s-u)ds\right)du \end{split} Where the second equality follows because we have $0\leq u\leq s\leq t$ but since $s$ varies between $u$ and $t$ we must have that $u$ varies between $0$ and $t$ that is $1_{0\leq u\leq t}$ .","I consider and two non negative functions. I had hard time to understand this equality I think it is just an application of Fubini theorem, however I don’t succeed to get the same expression. Indeed I get I tried some change of variable ( introduce ), it was not successful. Am I missing something ? Thank you a lot Edit : use of the hint given by Bruno.B Where the second equality follows because we have but since varies between and we must have that varies between and that is .","H h 
\int_{0}^{t}h(t-s)\left(\int_{0}^{s}H(s-u)udu\right)ds = \int_{0}^{t}u\left(\int_{u}^{t}h(t-s)H(s-u)ds\right)du
 
\int_{0}^{t}h(t-s)\left(\int_{0}^{s}H(s-u)udu\right)ds = \int_{0}^{s}u\left(\int_{0}^{t}h(t-s)H(s-u)ds\right)du
 v = s - u \begin{split}  
= & \int_{0}^{t}h(t-s)\left(\int_{0}^{s}H(s-u)udu\right)ds \\
= & \int_{0}^{\infty}h(t-s)1_{u\leq s\leq t}\left(\int_{0}^{\infty}H(s-u)u1_{0\leq u \leq s\leq t}du\right)ds \\
= & \int_{0}^{\infty}u1_{0\leq u \leq t}\left(\int_{0}^{\infty}H(s-u)h(t-s)1_{u\leq s\leq t}ds\right)du \\
= & \int_{0}^{t}u\left(\int_{u}^{t}h(t-s)H(s-u)ds\right)du
\end{split} 0\leq u\leq s\leq t s u t u 0 t 1_{0\leq u\leq t}","['calculus', 'multiple-integral', 'change-of-variable', 'fubini-tonelli-theorems']"
57,Proving a Probability Limit is Non Zero,Proving a Probability Limit is Non Zero,,"I am reading these lecture notes : on page 1, it mentions (indirectly) that : Define the Score Function as the first derivative of the likelihood If the Expected Value of the Score Function is not equal to 0, then the resulting MLE estimator will not be Consistent . I am trying to understand why this is true. I understand that this is the definition of Consistency in Statistics: An estimator $\hat{\theta}$ is consistent if when the sample size $n$ grows to infinity, the empirical estimator $\hat{\theta}_n$ subtracted from the theoretical estimator $\theta$ has a 0 probability of being greater than some small number $\epsilon$ : $$\lim_{{n \to \infty}} P(|\hat{\theta}_n - \theta| > \epsilon) = 0$$ I also understand how to obtain the Score Function for a given Likelihood Function: A random variable $X$ . A probability density function (pdf) $f(x; \theta)$ . The likelihood of $f(x; \theta)$ given data $x_1, x_2, ..., x_n$ is $$L(\theta; x) = \prod_{i=1}^{n} f(x_i; \theta)$$ The log-likelihood is $$\log L(\theta; x) = \sum_{i=1}^{n} \log f(x_i; \theta)$$ The derivative of the log-likelihood is $$\frac{d}{d\theta} \log L(\theta; x) = \frac{d}{d\theta} \sum_{i=1}^{n} \log f(x_i; \theta)$$ The MLE estimator of $\theta$ is the only solution $\hat{\theta}$ of the equation $$\frac{d}{d\theta} \log L(\theta; x) = 0,$$ provided this equation has a unique solution. The expected value of the derivative of the log-likelihood is zero, i.e., $$E\left[\frac{d}{d\theta} \log L(\theta; x)\right] = 0$$ My Question: But mathematically, how can we show that if $E\left[\frac{d}{d\theta} \log L(\theta; x)\right] \neq 0$ , then $$\lim_{{n \to \infty}} P(|\hat{\theta}_n - \theta| > \epsilon) \neq 0$$ ??? Can someone please show me how this can be proven? Thanks!","I am reading these lecture notes : on page 1, it mentions (indirectly) that : Define the Score Function as the first derivative of the likelihood If the Expected Value of the Score Function is not equal to 0, then the resulting MLE estimator will not be Consistent . I am trying to understand why this is true. I understand that this is the definition of Consistency in Statistics: An estimator is consistent if when the sample size grows to infinity, the empirical estimator subtracted from the theoretical estimator has a 0 probability of being greater than some small number : I also understand how to obtain the Score Function for a given Likelihood Function: A random variable . A probability density function (pdf) . The likelihood of given data is The log-likelihood is The derivative of the log-likelihood is The MLE estimator of is the only solution of the equation provided this equation has a unique solution. The expected value of the derivative of the log-likelihood is zero, i.e., My Question: But mathematically, how can we show that if , then ??? Can someone please show me how this can be proven? Thanks!","\hat{\theta} n \hat{\theta}_n \theta \epsilon \lim_{{n \to \infty}} P(|\hat{\theta}_n - \theta| > \epsilon) = 0 X f(x; \theta) f(x; \theta) x_1, x_2, ..., x_n L(\theta; x) = \prod_{i=1}^{n} f(x_i; \theta) \log L(\theta; x) = \sum_{i=1}^{n} \log f(x_i; \theta) \frac{d}{d\theta} \log L(\theta; x) = \frac{d}{d\theta} \sum_{i=1}^{n} \log f(x_i; \theta) \theta \hat{\theta} \frac{d}{d\theta} \log L(\theta; x) = 0, E\left[\frac{d}{d\theta} \log L(\theta; x)\right] = 0 E\left[\frac{d}{d\theta} \log L(\theta; x)\right] \neq 0 \lim_{{n \to \infty}} P(|\hat{\theta}_n - \theta| > \epsilon) \neq 0","['calculus', 'probability', 'limits', 'statistics', 'proof-writing']"
58,Find maximum and minimum of $\frac{\sin(A) + \sin(B) + \sin(C)}{\cos(A) + \cos(B) + \cos(C)}$ in acute triangles,Find maximum and minimum of  in acute triangles,\frac{\sin(A) + \sin(B) + \sin(C)}{\cos(A) + \cos(B) + \cos(C)},"One day I had a question. In an acute angled triangle,what is maximum and minimum of $I$ ? $$ I=\frac{\sin(A) + \sin(B) + \sin(C)}{\cos(A) + \cos(B) + \cos(C)}$$ Attempt As law of cosines, $$\cos(A) + \cos(B) + \cos(C) = \frac{r}{R} + 1$$ $R$ is radius of the circumcircle $r$ is radius of the incircle so $ I=\frac{a+b+c}{2(r+R)}$ But I can't evaluate this, could not solve further. Would you mind solving my question?","One day I had a question. In an acute angled triangle,what is maximum and minimum of ? Attempt As law of cosines, is radius of the circumcircle is radius of the incircle so But I can't evaluate this, could not solve further. Would you mind solving my question?",I  I=\frac{\sin(A) + \sin(B) + \sin(C)}{\cos(A) + \cos(B) + \cos(C)} \cos(A) + \cos(B) + \cos(C) = \frac{r}{R} + 1 R r  I=\frac{a+b+c}{2(r+R)},"['calculus', 'inequality', 'trigonometry']"
59,Largest natural number $n$ such that $\int_1^\infty\frac{\log^nx}{e^x}\mathrm dx<1$,Largest natural number  such that,n \int_1^\infty\frac{\log^nx}{e^x}\mathrm dx<1,"Find the largest natural number $n$ such that $$\int_1^\infty\frac{\ln^nx}{e^x}\mathrm dx<1$$ Upon searching on site and google, I found a similar integral: $$\int_0^\infty\frac{\ln x}{e^x}\mathrm dx=-\gamma$$ But the techniques involving solving such integrals is beyond what I've learnt till now. The elementary method I know is to think of some adaptation of squeeze theorem like to search a $f$ such that: $$f>\frac{\ln^nx}{e^x}$$ and $$\int_1^\infty f\mathrm dx = 1$$ But I can't imagine any such $f$ upon hit and trial. (P.S.: This question came in my class test of applications of derivatives. According to answer key, $n=7$ )","Find the largest natural number such that Upon searching on site and google, I found a similar integral: But the techniques involving solving such integrals is beyond what I've learnt till now. The elementary method I know is to think of some adaptation of squeeze theorem like to search a such that: and But I can't imagine any such upon hit and trial. (P.S.: This question came in my class test of applications of derivatives. According to answer key, )",n \int_1^\infty\frac{\ln^nx}{e^x}\mathrm dx<1 \int_0^\infty\frac{\ln x}{e^x}\mathrm dx=-\gamma f f>\frac{\ln^nx}{e^x} \int_1^\infty f\mathrm dx = 1 f n=7,"['calculus', 'integration', 'derivatives', 'definite-integrals', 'improper-integrals']"
60,Obtain gravity direction by observing a pendulum's movement,Obtain gravity direction by observing a pendulum's movement,,"Lets say a damped pendulum takes 10 seconds to slow down and stop.  In that time it might swing past vertical perhaps 25 times or so. We have an accurate clock that measures absolute time reliably.  We are given very accurate  speed and direction data (+/- radians per second for instance) for the pendulum in real-time.  But we don't know what absolute angle the pendulum started at. Is it possible to accurately determine which direction is ""down"" (e.g. gravity's local direction) by observing the motion of a swinging damped pendulum before it has stopped swinging? Background: Please bear with me since I'm not well versed in mathematics, I realise that this question isn't rigorously defined.  This problem is based in a real situation I'm facing with some electromechanical apparatus.  A pendulum suffers from friction in its motion which generally prevents it from finding vertical once it finally comes to rest (usually it's a degree or two to the left or right, somewhat randomly).  If it is possible to find ""down"" mathematically from the dynamic properties of a pendulum before it stops, then this would be a tremendous help.","Lets say a damped pendulum takes 10 seconds to slow down and stop.  In that time it might swing past vertical perhaps 25 times or so. We have an accurate clock that measures absolute time reliably.  We are given very accurate  speed and direction data (+/- radians per second for instance) for the pendulum in real-time.  But we don't know what absolute angle the pendulum started at. Is it possible to accurately determine which direction is ""down"" (e.g. gravity's local direction) by observing the motion of a swinging damped pendulum before it has stopped swinging? Background: Please bear with me since I'm not well versed in mathematics, I realise that this question isn't rigorously defined.  This problem is based in a real situation I'm facing with some electromechanical apparatus.  A pendulum suffers from friction in its motion which generally prevents it from finding vertical once it finally comes to rest (usually it's a degree or two to the left or right, somewhat randomly).  If it is possible to find ""down"" mathematically from the dynamic properties of a pendulum before it stops, then this would be a tremendous help.",,"['calculus', 'physics', 'circular-motion']"
61,"find the largest number you can write with three 3's and three 8's, using only $+,-,/,\cdot$ and exponentiation","find the largest number you can write with three 3's and three 8's, using only  and exponentiation","+,-,/,\cdot","(HMMT 2000 Guts Round #38) Find the largest number you can write with three 3's and three 8's, using only $+,-,/,\cdot$ and exponentiation. Claim 1: if $x>y>e$ are real numbers, then $x^y < y^x$ . Assume that expressions without parentheses are evaluated using regular BEDMAS rules. I initially guessed that the answer is $3^{3^{3^{8^{8^8}}}},$ though I'm not sure how to prove this. From the problem conditions, there are 6 numbers and we can put 5 operations between them. The key to showing the desired result will be that adding in the other arithmetic operations doesn't result in a large enough number. This is fairly intuitive; if one had $a-b$ , where b is positive, one could replace that with $a+b$ to get a larger expression. To conclude, without parentheses, one clearly cannot use the subtraction operator. One also cannot use the division operator, since it can similarly be replaced by multiplication without decreasing the value of the expression. Finally, note that one can assume WLOG that addition is not used. Indeed, we've assumed that we can only have multiplication and division operations. since if a and b exceed 2 then $a+b < a\cdot b$ Finally, we may replace $a\cdot b$ with $a^b$ whenever a and b are integers exceeding 2 to get a larger expression. Hence we may indeed assume only the exponentiation operator is used. And the maximum value is the claimed value. Indeed, assume a $3$ , say b, follows an 8, say c, in the sequence of exponents. We may assume the 3 is preceded by an 8, since there must be an 8 followed by a 3 in the sequence of exponents between b and c. Then we claim that swapping the 3 and the 8 will result in a larger overall value for the expression. Indeed, by assumption, we have an expression of the form $8^{3^a}$ , where $a$ is a sequence of exponents containing $3$ . And the swap results in an expression of the form $3^{8^a}$ . Edit: It turns out that one can just use logarithms: $8^{3^a} < 3^{8^a}\Leftrightarrow \ln 8 \cdot 3^a < 8^a \cdot \ln 3.$ $\ln 8 / \ln 3 < (8/3)^a,$ which clearly holds for any positive integer $a$ .","(HMMT 2000 Guts Round #38) Find the largest number you can write with three 3's and three 8's, using only and exponentiation. Claim 1: if are real numbers, then . Assume that expressions without parentheses are evaluated using regular BEDMAS rules. I initially guessed that the answer is though I'm not sure how to prove this. From the problem conditions, there are 6 numbers and we can put 5 operations between them. The key to showing the desired result will be that adding in the other arithmetic operations doesn't result in a large enough number. This is fairly intuitive; if one had , where b is positive, one could replace that with to get a larger expression. To conclude, without parentheses, one clearly cannot use the subtraction operator. One also cannot use the division operator, since it can similarly be replaced by multiplication without decreasing the value of the expression. Finally, note that one can assume WLOG that addition is not used. Indeed, we've assumed that we can only have multiplication and division operations. since if a and b exceed 2 then Finally, we may replace with whenever a and b are integers exceeding 2 to get a larger expression. Hence we may indeed assume only the exponentiation operator is used. And the maximum value is the claimed value. Indeed, assume a , say b, follows an 8, say c, in the sequence of exponents. We may assume the 3 is preceded by an 8, since there must be an 8 followed by a 3 in the sequence of exponents between b and c. Then we claim that swapping the 3 and the 8 will result in a larger overall value for the expression. Indeed, by assumption, we have an expression of the form , where is a sequence of exponents containing . And the swap results in an expression of the form . Edit: It turns out that one can just use logarithms: which clearly holds for any positive integer .","+,-,/,\cdot x>y>e x^y < y^x 3^{3^{3^{8^{8^8}}}}, a-b a+b a+b < a\cdot b a\cdot b a^b 3 8^{3^a} a 3 3^{8^a} 8^{3^a} < 3^{8^a}\Leftrightarrow \ln 8 \cdot 3^a < 8^a \cdot \ln 3. \ln 8 / \ln 3 < (8/3)^a, a","['calculus', 'elementary-number-theory', 'inequality', 'contest-math', 'recreational-mathematics']"
62,Limit of Exponential and its Integral,Limit of Exponential and its Integral,,"Consider a function $h : \mathbb{R} \rightarrow \mathbb{R}$ without singularities such that $h(x) \nearrow \infty$ with $x \rightarrow \infty$ . Let $g(x)$ defined by $$ g(x) = \exp(-h(x)) \int_0^x \exp(h(s)) ds. $$ Playing around with Desmos, it seems that if $h(x)$ grows at approximately a linear rate, that is to say $\lim_{x \rightarrow \infty} \frac{h(x)}{x} = c \in \mathbb{R}$ , then $g(x)$ remains bounded away from both $0$ and $\infty$ . Meanwhile, if $h(x)$ grows faster than every line, then $g(x) \rightarrow 0$ , and if $h(x)$ grows slower than every line, $g(x) \rightarrow \infty$ . I believe I have a (partial) proof in the case that $h(x)$ is strictly increasing and differentiable, but I suspect this holds in a much more general setting. How can this be shown? Does there exists results that are related to functions of this form? Edit : This was my approach for the case $h(x)$ being differentiable and strictly increasing at some minimum rate $\alpha > 0$ . Write $h(x) = ax + k(x)$ , for $a > 0$ and for some $k(x)$ differentiable and $o(x)$ . Since $h(x)$ is non-singular, we have that $\sup_{x \in \mathbb{R}} k'(x) \leq m_1$ ( this seems questionable, actually ). Thus, we have that $$ \frac{d}{dx} e^{h(x)} \leq (a + m_1) e^{h(x)}. $$ Integrating this becomes $$ e^{h(x)} - e^{h(0)} \leq \int_0^x (a + m_1) e^{h(s)} ds \qquad \Rightarrow \qquad g(x) = e^{-h(x)} \int_0^x e^{h(s)} ds \geq \frac{1 - e^{h(0) - h(x)}}{a + m_1}. $$ Since $h(x)$ is everywhere increasing with a minimum rate $\alpha > 0$ , we have that $\inf_{x \in \mathbb{R}} k'(x) \geq m_2$ with $a > m_2$ . Performing the same as above and taking $x \rightarrow \infty$ , we finally obtain that $$ 0 < \frac{1}{a + m_1} \leq \lim_{x \rightarrow \infty} g(x) \leq \frac{1}{a + m_2} < \infty. $$ I have yet to show that this behaves as predicted if $h(x)$ grows at non-linear rates. Edit 2 : As EnEm pointed out in the comments, it is not difficult to find a function $h(x)$ that grows faster than any line but for which $g(x)$ does not go to $0$ . It still remains very likely that $h(x)$ with linear growth still forces $g(x)$ to avoid $0$ and $\infty$ under fairly weak conditions.","Consider a function without singularities such that with . Let defined by Playing around with Desmos, it seems that if grows at approximately a linear rate, that is to say , then remains bounded away from both and . Meanwhile, if grows faster than every line, then , and if grows slower than every line, . I believe I have a (partial) proof in the case that is strictly increasing and differentiable, but I suspect this holds in a much more general setting. How can this be shown? Does there exists results that are related to functions of this form? Edit : This was my approach for the case being differentiable and strictly increasing at some minimum rate . Write , for and for some differentiable and . Since is non-singular, we have that ( this seems questionable, actually ). Thus, we have that Integrating this becomes Since is everywhere increasing with a minimum rate , we have that with . Performing the same as above and taking , we finally obtain that I have yet to show that this behaves as predicted if grows at non-linear rates. Edit 2 : As EnEm pointed out in the comments, it is not difficult to find a function that grows faster than any line but for which does not go to . It still remains very likely that with linear growth still forces to avoid and under fairly weak conditions.","h : \mathbb{R} \rightarrow \mathbb{R} h(x) \nearrow \infty x \rightarrow \infty g(x) 
g(x) = \exp(-h(x)) \int_0^x \exp(h(s)) ds.
 h(x) \lim_{x \rightarrow \infty} \frac{h(x)}{x} = c \in \mathbb{R} g(x) 0 \infty h(x) g(x) \rightarrow 0 h(x) g(x) \rightarrow \infty h(x) h(x) \alpha > 0 h(x) = ax + k(x) a > 0 k(x) o(x) h(x) \sup_{x \in \mathbb{R}} k'(x) \leq m_1 
\frac{d}{dx} e^{h(x)} \leq (a + m_1) e^{h(x)}.
 
e^{h(x)} - e^{h(0)} \leq \int_0^x (a + m_1) e^{h(s)} ds \qquad \Rightarrow \qquad g(x) = e^{-h(x)} \int_0^x e^{h(s)} ds \geq \frac{1 - e^{h(0) - h(x)}}{a + m_1}.
 h(x) \alpha > 0 \inf_{x \in \mathbb{R}} k'(x) \geq m_2 a > m_2 x \rightarrow \infty 
0 < \frac{1}{a + m_1} \leq \lim_{x \rightarrow \infty} g(x) \leq \frac{1}{a + m_2} < \infty.
 h(x) h(x) g(x) 0 h(x) g(x) 0 \infty","['calculus', 'integration', 'limits', 'asymptotics']"
63,The correct understanding of limits,The correct understanding of limits,,"I want to be sure that I'm understanding the concept of limits correctly . When I faced the concept of limits for the first time I've been told that the definition of a limit is: $\lim _{x\to \:a}$ $f(x)$ $=$ $L$ Is that when the values of $x$ get closer to the value $a$ , the values of $f(x)$ get closer to the value $L$ ? But I see this definition is a vague and wrong one. Besides if we consider the constant function $f(x) = c$ the definition doesn't hold: ''if $x$ gets closer to $a$ the values of $f(x)$ stay the same and don't get closer to any value"". Then I read Tom Apostol's Calculus and the definition the book provides is the statement $\lim _{x\to \:a}$ $f(x)$ $=$ $L$ means that we can make the values of $f(x)$ as close as we please to the number ( $L$ ), provided that we make the values of $x$ sufficiently close to $a$ . This definition provides no ambiguities and makes perfect sense with every function. My question: Is the first definition I wrote really a wrong one because I see any one that introduces limits begin with definition and am I really understanding what Tom Apostol really wants to say? Note: What I wrote about the definition that Tom Apostol provides is how I understand it and I know that the the rigor definition is the $\epsilon -\delta$ but I see that the $\epsilon -\delta$ definition is just a rigor translation of what I've said about the definition that Tom Apostol provides. Correct me if I've written anything wrong.","I want to be sure that I'm understanding the concept of limits correctly . When I faced the concept of limits for the first time I've been told that the definition of a limit is: Is that when the values of get closer to the value , the values of get closer to the value ? But I see this definition is a vague and wrong one. Besides if we consider the constant function the definition doesn't hold: ''if gets closer to the values of stay the same and don't get closer to any value"". Then I read Tom Apostol's Calculus and the definition the book provides is the statement means that we can make the values of as close as we please to the number ( ), provided that we make the values of sufficiently close to . This definition provides no ambiguities and makes perfect sense with every function. My question: Is the first definition I wrote really a wrong one because I see any one that introduces limits begin with definition and am I really understanding what Tom Apostol really wants to say? Note: What I wrote about the definition that Tom Apostol provides is how I understand it and I know that the the rigor definition is the but I see that the definition is just a rigor translation of what I've said about the definition that Tom Apostol provides. Correct me if I've written anything wrong.",\lim _{x\to \:a} f(x) = L x a f(x) L f(x) = c x a f(x) \lim _{x\to \:a} f(x) = L f(x) L x a \epsilon -\delta \epsilon -\delta,['calculus']
64,Computing : $\displaystyle \int \frac {m + n\cos (x-x_0) }{ [a+b\cos (x-x_0)]^{3/2} } \mathrm{d}x $ with integration of $E$ and $F$,Computing :  with integration of  and,\displaystyle \int \frac {m + n\cos (x-x_0) }{ [a+b\cos (x-x_0)]^{3/2} } \mathrm{d}x  E F,"Yesterday I tried to find an expression to predict the behaviour of Magnetic Field due a circular loop at any point in the space, in cylindrical co-ordinates. At the end, I am stuck with some integrals. Diagram: Process: Initially I found out the position vector of a fixed point $\displaystyle P(\rho_0, \phi_0 , z_0)$ : $\displaystyle \vec{r_0} = \rho_0 \hat{\rho_0} + z_0 \hat{z}$ And a general point on loop $\displaystyle O(\rho, \phi , 0)$ : $\displaystyle \vec{r} = \rho \hat{\rho} \implies \displaystyle \vec{r^{'}} = \rho_0 \hat{\rho_0} + z_0 \hat{z} - \rho \hat{\rho} $ As the angle between $\displaystyle \hat{\rho} \ \text{and} \ \hat{\rho_0}  $ is $ (\phi - \phi_0) $ we can derive: $\displaystyle  \hat{\rho} = \cos (\phi - \phi_0 ) \hat{\rho_0} + \sin (\phi - \phi_0 ) \hat{\phi_0} $ . Now, the general line element in cylindrical co-ordinates is : $\displaystyle \vec{\mathrm{d}l} = \mathrm{d} \rho \ \hat{\rho} + \rho \mathrm{d}\phi \ \hat{\phi} +  \mathrm{d} z \ \hat{z} \ $ but here, $$ \displaystyle \ \text{line element:} \ \vec{\mathrm{d}l} = \rho \mathrm{d}\phi \ \hat{\phi} $$ Biot-Savart Law: $ \displaystyle \vec{B} = \frac{\mu_0}{4\pi} \int_{c} \frac{i \vec{\mathrm{d}l} \times \vec{r^{'}}}{||\vec{r^{'}}||^3}$ Hence, first we need to find the cross product $\displaystyle \vec{\mathrm{d}l} \times \vec{r^{'}} =   \rho \mathrm{d}\phi \ \hat{\phi}  \times \vec{r^{'}} $ $$\displaystyle  \hat{\phi} \times \vec{r^{'}} = z_0 \cos  (\phi - \phi_0) \hat{\rho_0} + z_0  \sin (\phi - \phi_0 ) \hat{\phi_0} - (\rho + \rho_0 \cos  (\phi - \phi_0)) \hat{z}$$ And $ \displaystyle ||\vec{r^{'}}|| = \left[ z^{2}_{0} + \rho_0^{2} + \rho^{2} - 2\rho_0 \rho  \cos  (\phi - \phi_0) \right]^{1/2} $ Thus our Integral becomes: $$ \displaystyle  \vec{B} = \frac{\mu_0 i \rho }{4\pi} \int_{0}^{2\pi} \frac{z_0 \cos  (\phi - \phi_0) \hat{\rho_0} + z_0  \sin (\phi - \phi_0 ) \hat{\phi_0} - (\rho + \rho_0 \cos  (\phi - \phi_0)) \hat{z}}{\left[ z^{2}_{0} + \rho_0^{2} + \rho^{2} - 2\rho_0 \rho  \cos  (\phi - \phi_0) \right]^{3/2} } \mathrm{d} \phi  $$ The coefficient of $\displaystyle  \hat{\phi_0} $ is integrable and the definite integral here, results to be zero. This have to be true according to laws of electromagnetism (i.e no magnetic field parallel to the current element). Hence our Magnetic field becomes: $$ \displaystyle  \vec{B} = \frac{\mu_0 i \rho z_0  }{4\pi} \int_{0}^{2\pi} \frac{\cos  (\phi - \phi_0)}{\left[ z^{2}_{0} + \rho_0^{2} + \rho^{2} - 2\rho_0 \rho  \cos  (\phi - \phi_0) \right]^{3/2} } \mathrm{d} \phi \ \hat{\rho_0}  \\ -  \frac{\mu_0 i \rho }{4\pi} \int_{0}^{2\pi} \frac{\rho + \rho_0 \cos  (\phi - \phi_0)}{\left[ z^{2}_{0} + \rho_0^{2} + \rho^{2} - 2\rho_0 \rho  \cos  (\phi - \phi_0) \right]^{3/2} } \mathrm{d} \phi \  \hat{z} $$ EDIT: I have used the Ellipltical integrals (as suggested by @Maxim ) to simplify the expression as: $$ \displaystyle \vec{B} = \frac{\mu_0 i \sqrt{a} }{2^{2.5} \pi \rho_0^{1.5} \sqrt{\rho} \sqrt{1-a}} (z_0-z) \left [ \frac{1}{1+a} \mathrm{E}\left(\pi, \frac{2a}{1-a} \right) -  \mathrm{F}\left( \pi,\frac{2a}{1-a} \right)\right ] \hat{\rho_0} -  \frac{\mu_0 i \sqrt{a}}{2^{2.5} \pi \rho_0^{1.5} \sqrt{\rho} \sqrt{1-a}} \left [ \left(\frac{\rho_0}{a+1} + \rho \right) \mathrm{E}\left(\pi, \frac{2a}{1-a} \right) -  \rho_0 \mathrm{F}\left( \pi,\frac{2a}{1-a} \right)\right ] \hat{z}\\ $$ Where $\displaystyle a = \frac{2\rho \rho_0}{(z_0-z)^2 + \rho^2 + \rho_0^2}$ and the position of the ring is $(\rho,\phi,z).$ $\mathrm{F}$ is elliptical integral of first kind and $\mathrm{E}$ is of second kind. Thus, my intial stage is well simplified. But the reason behind this complex calculation was that, I want to complute the Magnetic field due to a solenoid at any point in sapce. If we assume the number density of the coil to be $n$ and length $z_f - z_i,$ then in a small region of thickness $\mathrm{d}z$ , there will be $n\mathrm{d}z$ rings, each with nearly $\vec{B}$ as their magnetic field. Thus $$\displaystyle \vec{B}_{\text{solenoid}} = \int_{z_i}^{z_f} n\vec{B}\mathrm{d}z $$ Hence it is equivalent to compute : $$ \displaystyle  \vec{B}_{\text{solenoid}} =  \frac{\mu_0 n i }{2^{2.5} \pi \rho_0^{1.5} \sqrt{\rho}} \int_{z_i}^{z_f} \sqrt{\frac{a}{1-a}}  \left(  (z_0-z) \left [ \frac{1}{1+a} \mathrm{E}\left(\pi, \frac{2a}{1-a} \right) -  \mathrm{F}\left( \pi,\frac{2a}{1-a} \right)\right ] \hat{\rho_0} -   \left [ \left(\frac{\rho_0}{a+1} + \rho \right) \mathrm{E}\left(\pi, \frac{2a}{1-a} \right) -  \rho_0 \mathrm{F}\left( \pi,\frac{2a}{1-a} \right)\right ] \hat{z} \right) \mathrm{d}z $$ Thus I need help in solving, $\displaystyle \int_{z_i}^{z^f} \frac {(z_0-z) ( ( z-z_0)^2 +\rho^2 + \rho_0^2 ) }{\sqrt{( z-z_0)^2 + (\rho - \rho_0)^2} (( z-z_0)^2 + (\rho + \rho_0)^2)  } \mathrm{E} \left( \pi, \frac{4\rho \rho_0}{ (z-z_0)^2 + (\rho - \rho_0)^2 } \right) \mathrm{d}z $ $\displaystyle \int_{z_i}^{z^f} \frac {1 }{\sqrt{( z-z_0)^2 + (\rho - \rho_0)^2} } \mathrm{E} \left( \pi, \frac{4\rho \rho_0}{ (z-z_0)^2 + (\rho - \rho_0)^2 } \right) \mathrm{d}z $ $\displaystyle \int_{z_i}^{z^f} \frac {(z_0-z) }{\sqrt{( z-z_0)^2 + (\rho - \rho_0)^2} } \mathrm{F} \left( \pi, \frac{4\rho \rho_0}{ (z-z_0)^2 + (\rho - \rho_0)^2 } \right) \mathrm{d}z $ $\displaystyle \int_{z_i}^{z^f} \frac {1 }{\sqrt{( z-z_0)^2 + (\rho - \rho_0)^2} } \mathrm{F} \left( \pi, \frac{4\rho \rho_0}{ (z-z_0)^2 + (\rho - \rho_0)^2 } \right) \mathrm{d}z $ in order to solve for my expression Question: The above formula should give Magnetic field of solenoid at any point in space. Do we have any closed form for the above integral ? Or it's taylor series that could simplify the expression. Progress: Edit $(30/03/2022) :$ I have got a lead, we can break $\mathrm{E}(\pi,k)$ into complete elliptical integral as $$\displaystyle \mathrm{E}(\pi,k) = \mathrm{E}(k) + \mathrm{E}\left(\sqrt{\frac{k^2}{1-k^2}}\right)$$ and using the expansion we will get: $$\displaystyle \mathrm{E}(\pi,k) = \pi - \frac{\pi}{2} \sum_{n=0}^{\infty} \frac{1}{16^n (2n-1)} {\binom{2n}{n}}^2 \left( k^{2n} + {\left[\frac{k^2}{1-k^2} \right]}^n \right)$$ This does simplify our integrand, but it is still vey complicated to sort out.","Yesterday I tried to find an expression to predict the behaviour of Magnetic Field due a circular loop at any point in the space, in cylindrical co-ordinates. At the end, I am stuck with some integrals. Diagram: Process: Initially I found out the position vector of a fixed point : And a general point on loop : As the angle between is we can derive: . Now, the general line element in cylindrical co-ordinates is : but here, Biot-Savart Law: Hence, first we need to find the cross product And Thus our Integral becomes: The coefficient of is integrable and the definite integral here, results to be zero. This have to be true according to laws of electromagnetism (i.e no magnetic field parallel to the current element). Hence our Magnetic field becomes: EDIT: I have used the Ellipltical integrals (as suggested by @Maxim ) to simplify the expression as: Where and the position of the ring is is elliptical integral of first kind and is of second kind. Thus, my intial stage is well simplified. But the reason behind this complex calculation was that, I want to complute the Magnetic field due to a solenoid at any point in sapce. If we assume the number density of the coil to be and length then in a small region of thickness , there will be rings, each with nearly as their magnetic field. Thus Hence it is equivalent to compute : Thus I need help in solving, in order to solve for my expression Question: The above formula should give Magnetic field of solenoid at any point in space. Do we have any closed form for the above integral ? Or it's taylor series that could simplify the expression. Progress: Edit I have got a lead, we can break into complete elliptical integral as and using the expansion we will get: This does simplify our integrand, but it is still vey complicated to sort out.","\displaystyle P(\rho_0, \phi_0 , z_0) \displaystyle \vec{r_0} = \rho_0 \hat{\rho_0} + z_0 \hat{z} \displaystyle O(\rho, \phi , 0) \displaystyle \vec{r} = \rho \hat{\rho} \implies \displaystyle \vec{r^{'}} = \rho_0 \hat{\rho_0} + z_0 \hat{z} - \rho \hat{\rho}  \displaystyle \hat{\rho} \ \text{and} \ \hat{\rho_0}    (\phi - \phi_0)  \displaystyle  \hat{\rho} = \cos (\phi - \phi_0 ) \hat{\rho_0} + \sin (\phi - \phi_0 ) \hat{\phi_0}  \displaystyle \vec{\mathrm{d}l} = \mathrm{d} \rho \ \hat{\rho} + \rho \mathrm{d}\phi \ \hat{\phi} +  \mathrm{d} z \ \hat{z} \   \displaystyle \ \text{line element:} \ \vec{\mathrm{d}l} = \rho \mathrm{d}\phi \ \hat{\phi}   \displaystyle \vec{B} = \frac{\mu_0}{4\pi} \int_{c} \frac{i \vec{\mathrm{d}l} \times \vec{r^{'}}}{||\vec{r^{'}}||^3} \displaystyle \vec{\mathrm{d}l} \times \vec{r^{'}} =   \rho \mathrm{d}\phi \ \hat{\phi}  \times \vec{r^{'}}  \displaystyle  \hat{\phi} \times \vec{r^{'}} = z_0 \cos  (\phi - \phi_0) \hat{\rho_0} + z_0  \sin (\phi - \phi_0 ) \hat{\phi_0} - (\rho + \rho_0 \cos  (\phi - \phi_0)) \hat{z}  \displaystyle ||\vec{r^{'}}|| = \left[ z^{2}_{0} + \rho_0^{2} + \rho^{2} - 2\rho_0 \rho  \cos  (\phi - \phi_0) \right]^{1/2}   \displaystyle  \vec{B} = \frac{\mu_0 i \rho }{4\pi} \int_{0}^{2\pi} \frac{z_0 \cos  (\phi - \phi_0) \hat{\rho_0} + z_0  \sin (\phi - \phi_0 ) \hat{\phi_0} - (\rho + \rho_0 \cos  (\phi - \phi_0)) \hat{z}}{\left[ z^{2}_{0} + \rho_0^{2} + \rho^{2} - 2\rho_0 \rho  \cos  (\phi - \phi_0) \right]^{3/2} } \mathrm{d} \phi   \displaystyle  \hat{\phi_0}   \displaystyle  \vec{B} = \frac{\mu_0 i \rho z_0  }{4\pi} \int_{0}^{2\pi} \frac{\cos  (\phi - \phi_0)}{\left[ z^{2}_{0} + \rho_0^{2} + \rho^{2} - 2\rho_0 \rho  \cos  (\phi - \phi_0) \right]^{3/2} } \mathrm{d} \phi \ \hat{\rho_0}  \\
-  \frac{\mu_0 i \rho }{4\pi} \int_{0}^{2\pi} \frac{\rho + \rho_0 \cos  (\phi - \phi_0)}{\left[ z^{2}_{0} + \rho_0^{2} + \rho^{2} - 2\rho_0 \rho  \cos  (\phi - \phi_0) \right]^{3/2} } \mathrm{d} \phi \  \hat{z}  
\displaystyle
\vec{B} = \frac{\mu_0 i \sqrt{a} }{2^{2.5} \pi \rho_0^{1.5} \sqrt{\rho} \sqrt{1-a}} (z_0-z) \left [ \frac{1}{1+a} \mathrm{E}\left(\pi, \frac{2a}{1-a} \right) -  \mathrm{F}\left( \pi,\frac{2a}{1-a} \right)\right ] \hat{\rho_0} -  \frac{\mu_0 i \sqrt{a}}{2^{2.5} \pi \rho_0^{1.5} \sqrt{\rho} \sqrt{1-a}} \left [ \left(\frac{\rho_0}{a+1} + \rho \right) \mathrm{E}\left(\pi, \frac{2a}{1-a} \right) -  \rho_0 \mathrm{F}\left( \pi,\frac{2a}{1-a} \right)\right ] \hat{z}\\
 \displaystyle a = \frac{2\rho \rho_0}{(z_0-z)^2 + \rho^2 + \rho_0^2} (\rho,\phi,z). \mathrm{F} \mathrm{E} n z_f - z_i, \mathrm{d}z n\mathrm{d}z \vec{B} \displaystyle \vec{B}_{\text{solenoid}} = \int_{z_i}^{z_f} n\vec{B}\mathrm{d}z  
\displaystyle 
\vec{B}_{\text{solenoid}} =  \frac{\mu_0 n i }{2^{2.5} \pi \rho_0^{1.5} \sqrt{\rho}} \int_{z_i}^{z_f}
\sqrt{\frac{a}{1-a}} 
\left(
 (z_0-z) \left [ \frac{1}{1+a} \mathrm{E}\left(\pi, \frac{2a}{1-a} \right) -  \mathrm{F}\left( \pi,\frac{2a}{1-a} \right)\right ] \hat{\rho_0} -   \left [ \left(\frac{\rho_0}{a+1} + \rho \right) \mathrm{E}\left(\pi, \frac{2a}{1-a} \right) -  \rho_0 \mathrm{F}\left( \pi,\frac{2a}{1-a} \right)\right ] \hat{z}
\right) \mathrm{d}z
 \displaystyle \int_{z_i}^{z^f} \frac {(z_0-z) ( ( z-z_0)^2 +\rho^2 + \rho_0^2 ) }{\sqrt{( z-z_0)^2 + (\rho - \rho_0)^2} (( z-z_0)^2 + (\rho + \rho_0)^2)  } \mathrm{E} \left( \pi, \frac{4\rho \rho_0}{ (z-z_0)^2 + (\rho - \rho_0)^2 } \right) \mathrm{d}z  \displaystyle \int_{z_i}^{z^f} \frac {1 }{\sqrt{( z-z_0)^2 + (\rho - \rho_0)^2} } \mathrm{E} \left( \pi, \frac{4\rho \rho_0}{ (z-z_0)^2 + (\rho - \rho_0)^2 } \right) \mathrm{d}z  \displaystyle \int_{z_i}^{z^f} \frac {(z_0-z) }{\sqrt{( z-z_0)^2 + (\rho - \rho_0)^2} } \mathrm{F} \left( \pi, \frac{4\rho \rho_0}{ (z-z_0)^2 + (\rho - \rho_0)^2 } \right) \mathrm{d}z  \displaystyle \int_{z_i}^{z^f} \frac {1 }{\sqrt{( z-z_0)^2 + (\rho - \rho_0)^2} } \mathrm{F} \left( \pi, \frac{4\rho \rho_0}{ (z-z_0)^2 + (\rho - \rho_0)^2 } \right) \mathrm{d}z  (30/03/2022) : \mathrm{E}(\pi,k) \displaystyle \mathrm{E}(\pi,k) = \mathrm{E}(k) + \mathrm{E}\left(\sqrt{\frac{k^2}{1-k^2}}\right) \displaystyle \mathrm{E}(\pi,k) = \pi - \frac{\pi}{2} \sum_{n=0}^{\infty} \frac{1}{16^n (2n-1)} {\binom{2n}{n}}^2 \left( k^{2n} + {\left[\frac{k^2}{1-k^2} \right]}^n \right)","['calculus', 'integration', 'definite-integrals', 'elliptic-integrals', 'cylindrical-coordinates']"
65,"How to tackle the integral $\int_{0}^{\pi} \frac{3 \pi x^{2}-2 x^{3}}{(1+\sin x)^{n}}dx, \textrm{ where } n \in N $",How to tackle the integral,"\int_{0}^{\pi} \frac{3 \pi x^{2}-2 x^{3}}{(1+\sin x)^{n}}dx, \textrm{ where } n \in N ","Inspired by an integral in my post , I want to generalize the result by replacing the power 2 in the denominator by $n.$ Letting $x \mapsto\pi-x$ yields $$ I_n:=\int_{0}^{\pi} \frac{3 \pi x^{2}-2 x^{3}}{(1+\sin x)^{n}} d x=\int_{0}^{\pi} \frac{2 x^{3}-3 \pi x^{2}+\pi^{3}}{(1+\sin x)^{n}} d x=-I+\pi^{3} \int_{0}^{\pi} \frac{d x}{(1+\sin x)^{n}} $$ Rearranging gives $$ I_{n}=\frac{\pi^{3}}{2} \underbrace{\int_{0}^{\pi} \frac{d x}{(1+\sin x)^{n}}}_{K_n} $$ $$ \begin{aligned} K_{n} & \stackrel{2 y=\frac{\pi}{2}- x}{=} 2 \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{d y}{(1+\cos 2 y)^{n}} \\ &=2\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{d y}{\left(2 \cos ^{2} y\right)^{n}}\\&= \frac{1}{2^{n-2}} \underbrace{\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y}_{J_n}  \end{aligned} $$ Now we need a reduction formula for $J_n$ , for any natural number $n$ , $$ \begin{aligned} J_{n} &=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y\\ &=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n-2} y  d(\tan y) \\ &=\left[\sec ^{2 n-2} y \tan y\right]_{0}^{\frac{\pi}{4}}-(2 n-2) \int_{0}^{\frac{\pi}{4}} \tan ^{2} y \sec ^{2 n-3} y \sec y dy\\ &=2^{n-1}-(2 n-2) \int_{0}^{\frac{\pi}{4}}\left(\sec ^{2} y-1\right) \sec ^{2 n-2} y d y \\ &=2^{n-1}-(2 n-2) \int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y+(2 n-2) J_{n-1} \end{aligned} $$ Rearranging yields the reduction formula $$ J_{n}=\frac{1}{2 n-1}\left[2^{n-1}+(2 n-2) J_{n-1}\right] \tag*{(1)}  $$ Hence $$ I_{n}=\frac{\pi^{3}}{2} K_{n}=\frac{\pi^{3}}{2} \cdot \frac{1}{2^{n-2}} J_{n}=\frac{\pi^{3}}{2^{n-1}} J n\tag*{(2)} $$ Back to the reduction formula for our integral $I_n$ , combining (1) and (2) gives $$ \boxed{I_{n}=\frac{1}{2 n-1}\left[\pi^{3}+(n-1) I_{n-1}\right]} $$ For examples, $$ \displaystyle \begin{array}{l} I_{1}=\frac{1}{1}\left(\pi^{3}+0\cdot I_{0}\right)=\pi^{3} \\ I_{2}=\frac{1}{3}\left(\pi^{3}+1 \cdot I_{1}\right)=\frac{2 \pi^{3}}{3} \\ I_{3}=\frac{1}{5}\left(\pi^{3}+2 \cdot I_{2}\right)=\frac{7 \pi^{3}}{15} \\ I_{4}=\frac{1}{7}\left(\pi^{3}+3 \cdot I_{3}\right)=\frac{12 \pi^{3}}{35}\\ \qquad\qquad \vdots  \end{array} $$ My Question Although we can find our integral one by one by the reduction formula, it is tedious and unsatisfactory.  Is there any closed form for it? Latest Edit Helped by Mr Quanto, we got a closed form for the integral $$ \boxed{I_{n}=\frac{\pi^{3}}{2^{n-1}} \sum_{k=0}^{n-1}\left(\begin{array}{c} n-1 \\ k \end{array}\right) \frac{1}{2 k+1}} $$ which is obtained by letting $t=\tan y$ \begin{aligned} J_{n} &=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y \\ &=\int_{0}^{1}\left(1+t^{2}\right)^{n-1} d t \\ &=\sum_{k=0}^{n-1}\left(\begin{array}{c} n-1 \\ k \end{array}\right) \int_{0}^{1} t^{2 k} d t \\ &=\sum_{k=0}^{n-1}\left(\begin{array}{c} n-1 \\ k \end{array}\right) \frac{1}{2 k+1} \end{aligned} For example $$ \begin{aligned} I_{5} &=\frac{\pi^{3}}{2^{4}}\left[\left(\begin{array}{l} 4 \\ 0 \end{array}\right)+\left(\begin{array}{l} 4 \\ 1 \end{array}\right) \frac{1}{3}+\left(\begin{array}{l} 4 \\ 2 \end{array}\right) \frac{1}{5}+\left(\begin{array}{l} 4 \\ 3 \end{array}\right) \frac{1}{7}+\left(\begin{array}{l} 4 \\ 4 \end{array}\right) \frac{1}{9}\right] =\frac{83 \pi^{3}}{315}\approx{8.16991}, \end{aligned} $$ which is checked by Wolframalpha","Inspired by an integral in my post , I want to generalize the result by replacing the power 2 in the denominator by Letting yields Rearranging gives Now we need a reduction formula for , for any natural number , Rearranging yields the reduction formula Hence Back to the reduction formula for our integral , combining (1) and (2) gives For examples, My Question Although we can find our integral one by one by the reduction formula, it is tedious and unsatisfactory.  Is there any closed form for it? Latest Edit Helped by Mr Quanto, we got a closed form for the integral which is obtained by letting For example which is checked by Wolframalpha","n. x \mapsto\pi-x 
I_n:=\int_{0}^{\pi} \frac{3 \pi x^{2}-2 x^{3}}{(1+\sin x)^{n}} d x=\int_{0}^{\pi} \frac{2 x^{3}-3 \pi x^{2}+\pi^{3}}{(1+\sin x)^{n}} d x=-I+\pi^{3} \int_{0}^{\pi} \frac{d x}{(1+\sin x)^{n}}
 
I_{n}=\frac{\pi^{3}}{2} \underbrace{\int_{0}^{\pi} \frac{d x}{(1+\sin x)^{n}}}_{K_n}
 
\begin{aligned}
K_{n} & \stackrel{2 y=\frac{\pi}{2}- x}{=} 2 \int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{d y}{(1+\cos 2 y)^{n}} \\
&=2\int_{-\frac{\pi}{4}}^{\frac{\pi}{4}} \frac{d y}{\left(2 \cos ^{2} y\right)^{n}}\\&= \frac{1}{2^{n-2}} \underbrace{\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y}_{J_n} 
\end{aligned}
 J_n n 
\begin{aligned}
J_{n} &=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y\\
&=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n-2} y  d(\tan y) \\
&=\left[\sec ^{2 n-2} y \tan y\right]_{0}^{\frac{\pi}{4}}-(2 n-2) \int_{0}^{\frac{\pi}{4}} \tan ^{2} y \sec ^{2 n-3} y \sec y dy\\
&=2^{n-1}-(2 n-2) \int_{0}^{\frac{\pi}{4}}\left(\sec ^{2} y-1\right) \sec ^{2 n-2} y d y \\
&=2^{n-1}-(2 n-2) \int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y+(2 n-2) J_{n-1}
\end{aligned}
 
J_{n}=\frac{1}{2 n-1}\left[2^{n-1}+(2 n-2) J_{n-1}\right] \tag*{(1)} 
 
I_{n}=\frac{\pi^{3}}{2} K_{n}=\frac{\pi^{3}}{2} \cdot \frac{1}{2^{n-2}} J_{n}=\frac{\pi^{3}}{2^{n-1}} J n\tag*{(2)}
 I_n 
\boxed{I_{n}=\frac{1}{2 n-1}\left[\pi^{3}+(n-1) I_{n-1}\right]}
 
\displaystyle \begin{array}{l}
I_{1}=\frac{1}{1}\left(\pi^{3}+0\cdot I_{0}\right)=\pi^{3} \\
I_{2}=\frac{1}{3}\left(\pi^{3}+1 \cdot I_{1}\right)=\frac{2 \pi^{3}}{3} \\
I_{3}=\frac{1}{5}\left(\pi^{3}+2 \cdot I_{2}\right)=\frac{7 \pi^{3}}{15} \\
I_{4}=\frac{1}{7}\left(\pi^{3}+3 \cdot I_{3}\right)=\frac{12 \pi^{3}}{35}\\ \qquad\qquad \vdots 
\end{array}
 
\boxed{I_{n}=\frac{\pi^{3}}{2^{n-1}} \sum_{k=0}^{n-1}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right) \frac{1}{2 k+1}}
 t=\tan y \begin{aligned}
J_{n} &=\int_{0}^{\frac{\pi}{4}} \sec ^{2 n} y d y \\
&=\int_{0}^{1}\left(1+t^{2}\right)^{n-1} d t \\
&=\sum_{k=0}^{n-1}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right) \int_{0}^{1} t^{2 k} d t \\
&=\sum_{k=0}^{n-1}\left(\begin{array}{c}
n-1 \\
k
\end{array}\right) \frac{1}{2 k+1}
\end{aligned} 
\begin{aligned}
I_{5} &=\frac{\pi^{3}}{2^{4}}\left[\left(\begin{array}{l}
4 \\
0
\end{array}\right)+\left(\begin{array}{l}
4 \\
1
\end{array}\right) \frac{1}{3}+\left(\begin{array}{l}
4 \\
2
\end{array}\right) \frac{1}{5}+\left(\begin{array}{l}
4 \\
3
\end{array}\right) \frac{1}{7}+\left(\begin{array}{l}
4 \\
4
\end{array}\right) \frac{1}{9}\right] =\frac{83 \pi^{3}}{315}\approx{8.16991},
\end{aligned}
","['calculus', 'integration', 'trigonometry', 'definite-integrals', 'reduction-formula']"
66,Proof verification: $\lim_{x\to 2} \frac{\sqrt{x^2 + 5} - 3}{x - 2} = \frac23$,Proof verification:,\lim_{x\to 2} \frac{\sqrt{x^2 + 5} - 3}{x - 2} = \frac23,"The question is as follows: Prove that $\displaystyle\lim_{x\to 2} \dfrac{\sqrt{x^2 + 5} - 3}{x - 2} = \dfrac23$ . My proof is: Fix $\varepsilon > 0$ . Note that $$\begin{array}{rcl}\left|\dfrac{\sqrt{x^2 + 5} - 3}{x - 2} - \dfrac23\right| &=& \left|\dfrac{x + 2}{\sqrt{x^2 + 5} + 3} - \dfrac23\right|\\&=& \dfrac13\left|\dfrac{3x - 2\sqrt{x^2 + 5}}{3 + \sqrt{x^2 + 5}}\right|\\&=& \dfrac13 \left|\dfrac{5x^2 - 20}{\left(3 + \sqrt{x^2 + 5}\right)\left(3x + 2\sqrt{x^2 + 5}\right)}\right|\\&=& \dfrac{5|x - 2|\cdot|x + 2|}{3\left|3 + \sqrt{x^2 + 5}\right|\cdot \left|3x + 2\sqrt{x^2 + 5}\right|}\end{array}$$ Pick $\delta = \min\left\{1, \dfrac{21\varepsilon}5\right\}$ . Suppose that $0 < |x - 2| < \delta < 1$ . Then $1 < x < 3$ . Therefore, $|x + 2| < 5$ , $\left|3 + \sqrt{x^2 + 5}\right| > 3 + \sqrt 6 > 5$ , and $\left|3x + 2 \sqrt{x^2 + 5}\right| > 3 + 2\sqrt 6 > 7$ . Therefore, $$\left|\dfrac{\sqrt{x^2 + 5} - 3}{x - 2} - \dfrac23\right| < \dfrac{5 \cdot 5}{3 \cdot 5 \cdot 7} |x - 2| < \dfrac5{21} \delta < \varepsilon$$ Hence, $\displaystyle\lim_{x\to 2} \dfrac{\sqrt{x^2 + 5} - 3}{x - 2} =\dfrac23$ . Is my proof correct?","The question is as follows: Prove that . My proof is: Fix . Note that Pick . Suppose that . Then . Therefore, , , and . Therefore, Hence, . Is my proof correct?","\displaystyle\lim_{x\to 2} \dfrac{\sqrt{x^2 + 5} - 3}{x - 2} = \dfrac23 \varepsilon > 0 \begin{array}{rcl}\left|\dfrac{\sqrt{x^2 + 5} - 3}{x - 2} - \dfrac23\right| &=& \left|\dfrac{x + 2}{\sqrt{x^2 + 5} + 3} - \dfrac23\right|\\&=& \dfrac13\left|\dfrac{3x - 2\sqrt{x^2 + 5}}{3 + \sqrt{x^2 + 5}}\right|\\&=& \dfrac13 \left|\dfrac{5x^2 - 20}{\left(3 + \sqrt{x^2 + 5}\right)\left(3x + 2\sqrt{x^2 + 5}\right)}\right|\\&=& \dfrac{5|x - 2|\cdot|x + 2|}{3\left|3 + \sqrt{x^2 + 5}\right|\cdot \left|3x + 2\sqrt{x^2 + 5}\right|}\end{array} \delta = \min\left\{1, \dfrac{21\varepsilon}5\right\} 0 < |x - 2| < \delta < 1 1 < x < 3 |x + 2| < 5 \left|3 + \sqrt{x^2 + 5}\right| > 3 + \sqrt 6 > 5 \left|3x + 2 \sqrt{x^2 + 5}\right| > 3 + 2\sqrt 6 > 7 \left|\dfrac{\sqrt{x^2 + 5} - 3}{x - 2} - \dfrac23\right| < \dfrac{5 \cdot 5}{3 \cdot 5 \cdot 7} |x - 2| < \dfrac5{21} \delta < \varepsilon \displaystyle\lim_{x\to 2} \dfrac{\sqrt{x^2 + 5} - 3}{x - 2} =\dfrac23","['calculus', 'analysis', 'proof-writing', 'solution-verification']"
67,Evaluate the integral : $\int_0^\infty (-1)^{ \lfloor x \sin x \rfloor } dx$,Evaluate the integral :,\int_0^\infty (-1)^{ \lfloor x \sin x \rfloor } dx,"How to evaluate the following integral? $$ \int_0^\infty (-1)^{ \lfloor x \sin x  \rfloor } dx$$ I have no idea how to calculate this improper integral. Maybe I have to use some property of floor functions to reduce $ (-1)^{ \lfloor x \sin x  \rfloor } $ to something simpler I can work with, but I don't know what property. Thanks in advance for help! Edit: I reached the following, For every $ k \in \mathbb{Z_+} $ we have that $ \int_0^{\pi \cdot (k+1)} (-1)^{ \lfloor x \sin x  \rfloor } dx = \sum_{m=0}^k \int_{\pi \cdot m}^{ \pi \cdot (m+1)} (-1)^{ \lfloor x \sin x  \rfloor } =  \{ x = t + \pi \cdot m , dx = dt \} = \sum_{m=0}^k \int_{0}^{ \pi} (-1)^{ \lfloor ( t+\pi \cdot m)\cdot( \sin(t+\pi \cdot m) )  \rfloor } dt = \sum_{m=0}^k \int_{0}^{ \pi} (-1)^{ \lfloor ( t+\pi \cdot m)\cdot( \sin(\pi \cdot m )\cos(t) + \sin(t)\cos(\pi \cdot m)  )  \rfloor } dt = \sum_{m=0}^k \int_{0}^{ \pi} (-1)^{ \lfloor ( t+\pi \cdot m)\cdot  (-1)^m \cdot \sin(t)   \rfloor } dt $ . If I can get a formula for the last integral from $ 0 $ to $ \pi $ I'll have an answer whether the integral from $ 0 $ to $ \infty $ converges or not.","How to evaluate the following integral? I have no idea how to calculate this improper integral. Maybe I have to use some property of floor functions to reduce to something simpler I can work with, but I don't know what property. Thanks in advance for help! Edit: I reached the following, For every we have that . If I can get a formula for the last integral from to I'll have an answer whether the integral from to converges or not."," \int_0^\infty (-1)^{ \lfloor x \sin x  \rfloor } dx  (-1)^{ \lfloor x \sin x  \rfloor }   k \in \mathbb{Z_+}   \int_0^{\pi \cdot (k+1)} (-1)^{ \lfloor x \sin x  \rfloor } dx = \sum_{m=0}^k \int_{\pi \cdot m}^{ \pi \cdot (m+1)} (-1)^{ \lfloor x \sin x  \rfloor } =  \{ x = t + \pi \cdot m , dx = dt \} = \sum_{m=0}^k \int_{0}^{ \pi} (-1)^{ \lfloor ( t+\pi \cdot m)\cdot( \sin(t+\pi \cdot m) )  \rfloor } dt = \sum_{m=0}^k \int_{0}^{ \pi} (-1)^{ \lfloor ( t+\pi \cdot m)\cdot( \sin(\pi \cdot m )\cos(t) + \sin(t)\cos(\pi \cdot m)  )  \rfloor } dt = \sum_{m=0}^k \int_{0}^{ \pi} (-1)^{ \lfloor ( t+\pi \cdot m)\cdot  (-1)^m \cdot \sin(t)   \rfloor } dt   0   \pi   0   \infty ","['calculus', 'integration', 'ceiling-and-floor-functions']"
68,"Let $f : R → R$ be a continuous decreasing function. Prove that the system $x = f(y),$ $y = f(z),$ $z = f(x)$ has a unique solution.",Let  be a continuous decreasing function. Prove that the system    has a unique solution.,"f : R → R x = f(y), y = f(z), z = f(x)","Let $f : R → R$ be a continuous decreasing function. Prove that the system $$x = f(y),$$ $$y = f(z),$$ $$z = f(x)$$ has a unique solution. Here using the intermediate value theorem, it can clearly be seen that when $\displaystyle{\lim_{x \to -\infty}}f(x)-x$ = $\infty $ & $\displaystyle{\lim_{x \to \infty}}f(x)-x$ = - $\infty $ & we get some $x_0$ such that $f(x_0) = x_0$ But how or why does that imply that $x_0 = x = y = z$","Let be a continuous decreasing function. Prove that the system has a unique solution. Here using the intermediate value theorem, it can clearly be seen that when = & = - & we get some such that But how or why does that imply that","f : R → R x = f(y), y = f(z), z = f(x) \displaystyle{\lim_{x \to -\infty}}f(x)-x \infty  \displaystyle{\lim_{x \to \infty}}f(x)-x \infty  x_0 f(x_0) = x_0 x_0 = x = y = z","['calculus', 'limits']"
69,$\lim_{x\to 0} \left(\int_0^1 3y+2(1-y)^xdy\right)^{1/x}$,,\lim_{x\to 0} \left(\int_0^1 3y+2(1-y)^xdy\right)^{1/x},"$$\lim_{x\to 0} \left(\int_0^1 \left(3y+2(1-y)^x\right)  dy\right)^{1/x}$$ I was solving this problem, and when I solve I got the answer which the software says incorrect. My try: Firstly, the simplest approach I directly solved the integration to get $$\lim_{x\to 0} \left(\frac{3x+7}{2x+2}\right)^{\frac1x}=3.5^{\pm \infty}$$ not unique, so i thought it should be $\color{blue}{\text{Does not Exist}}$ Next approach was to use the shortcut formula of $1^\infty$ form involving exponent directly which gives me answer as $\frac1e$ which is also incorrect but later I feel it should be incorrect because when x tends to zero, the inner integral is not tends to 1. Furthermore, if put the limit at the very start, I wanna know out of those 7 indeterminate forms $\color{red}{\text{Which form is this limit ?}}$ Do you also think the question is wrong ?","I was solving this problem, and when I solve I got the answer which the software says incorrect. My try: Firstly, the simplest approach I directly solved the integration to get not unique, so i thought it should be Next approach was to use the shortcut formula of form involving exponent directly which gives me answer as which is also incorrect but later I feel it should be incorrect because when x tends to zero, the inner integral is not tends to 1. Furthermore, if put the limit at the very start, I wanna know out of those 7 indeterminate forms Do you also think the question is wrong ?",\lim_{x\to 0} \left(\int_0^1 \left(3y+2(1-y)^x\right)  dy\right)^{1/x} \lim_{x\to 0} \left(\frac{3x+7}{2x+2}\right)^{\frac1x}=3.5^{\pm \infty} \color{blue}{\text{Does not Exist}} 1^\infty \frac1e \color{red}{\text{Which form is this limit ?}},"['calculus', 'integration', 'limits', 'definite-integrals', 'limits-without-lhopital']"
70,Deriving the Integral for Alternating Harmonic Series Partial Sums,Deriving the Integral for Alternating Harmonic Series Partial Sums,,"The partial sums of the harmonic series (the Harmonic Number , $H_n$ ) are given by $$H_n=\sum_{k=1}^{n} \frac{1}{k}$$ and the well known integral representation is $$H_n=\int_0^1 \frac{1-x^n}{1-x}\,dx$$ This can be used to calculate $H_n$ using rational values of $n$ . The partial sums of the alternating harmonic series (the Alternating Harmonic Number , $\widetilde{H_n}$ ) are given by $$\widetilde{H_n}=\sum_{k=1}^{n} \frac{(-1)^{k-1}}{k}$$ Now I am happy with the equivalent integral representation for the alternating harmonic number at integer $n$ : $$\widetilde{H_n}=\int_0^1 \frac{1+(-1)^{n-1}x^n}{1+x}\,dx$$ but at rational values of $n$ this formula gives complex results which I don't believe are correct. The correct formula I think involves the real component of (-1)^z at non-integer values of z, i.e. $\text{Real}[(-1)^z]=\cos(\pi\,z)$ $$\widetilde{H_n}=\int_0^1 \frac{1+(-\cos(\pi\,n))x^n}{1+x}\,dx=\sum_{k=1}^{\infty}(-1)^{k-1} \left(\frac{1}{k}-\frac{\cos(\pi\,n)}{k+n}\right)\tag{1}$$ from which real solutions result for example $$\widetilde{H}_{1/2}=\log 2$$ However is this assertion of mine correct (concerning the integral at non-integer $n$ ) and if so, can it be easily proved (without resorting to complex analysis)? Development of the Argument Lets define the harmonic number in terms of partial zeta sums thus, $H_n=\zeta_n(1)$ and the alternating harmonic number in terms of partial sums of the Dirichlet eta function $\widetilde{H_n}=\eta_n(1)$ by analogy we can define the partial sums of the Dirichlet Lambda function thus, $\lambda_n(1)=\sum_{k=1}^{n} \frac{1}{2k-1}$ and of the Dirichlet Beta function thus, $\beta_n(1)=\sum_{k=1}^{n} \frac{(-1)^{k-1}}{2k-1}$ Now I have been able to find a simple relationship between $\zeta_n(1)$ (i.e. $H_n$ ) and $\lambda_n(1)$ , that is valid for rational $n$ . $$\lambda_n(1)=\zeta_{2n}(1) -\frac{1}{2}\zeta_{n}(1)=H_{2n}-\frac{1}{2}H_n$$ I was therefore wondering whether a similar simple relationship exits between $H_n$ and $\widetilde{H_n}$ for rational $n$ . Obviously that is not possible if $\widetilde{H_n}$ is typically a complex number. For example for integer $n$ we have two formulae for $\widetilde{H_n}$ or $\eta_n(1)$ : $$\eta_{2n-1}(1)=\widetilde{H}_{2n-1}=2\lambda_n(1)-\zeta_{2n-1}(1)$$ $$\eta_{2n}(1)=\widetilde{H}_{2n}=2\lambda_n(1)-\zeta_{2n}(1)$$ and I would like to get to one formula. Update 2: A result of playing with these ideas in Mathematica In Mathematica functions often get simplified in terms of the Generalized Harmonic Number function $H_n^{(s)}=\zeta_n(s)=\sum_{k=1}^n \frac{1}{k^s}$ So I've been trying to represent all the trigonometric functions in terms of the Generalized Harmonic Number function. It's easy for the functions involving $\csc x$ or $\sec x$ but much harder for the pure functions $\sin x$ and $\cos x$ . Anyway I at last managed to find a reasonably simple 4 term candidate for $\cos x$ , utilizing my definition for $\eta_n(1)$ above in (1). $$\cos(x)=1+\frac{x}{\pi}\left(\eta_{-x/\pi}(1)-\eta_{x/\pi}(1)\right)+\frac{x}{\pi}\left(\zeta_{-x/\pi}(1)-\zeta_{x/\pi}(1)\right)$$ But maybe the complex numbers cancel out using the alternative definition.","The partial sums of the harmonic series (the Harmonic Number , ) are given by and the well known integral representation is This can be used to calculate using rational values of . The partial sums of the alternating harmonic series (the Alternating Harmonic Number , ) are given by Now I am happy with the equivalent integral representation for the alternating harmonic number at integer : but at rational values of this formula gives complex results which I don't believe are correct. The correct formula I think involves the real component of (-1)^z at non-integer values of z, i.e. from which real solutions result for example However is this assertion of mine correct (concerning the integral at non-integer ) and if so, can it be easily proved (without resorting to complex analysis)? Development of the Argument Lets define the harmonic number in terms of partial zeta sums thus, and the alternating harmonic number in terms of partial sums of the Dirichlet eta function by analogy we can define the partial sums of the Dirichlet Lambda function thus, and of the Dirichlet Beta function thus, Now I have been able to find a simple relationship between (i.e. ) and , that is valid for rational . I was therefore wondering whether a similar simple relationship exits between and for rational . Obviously that is not possible if is typically a complex number. For example for integer we have two formulae for or : and I would like to get to one formula. Update 2: A result of playing with these ideas in Mathematica In Mathematica functions often get simplified in terms of the Generalized Harmonic Number function So I've been trying to represent all the trigonometric functions in terms of the Generalized Harmonic Number function. It's easy for the functions involving or but much harder for the pure functions and . Anyway I at last managed to find a reasonably simple 4 term candidate for , utilizing my definition for above in (1). But maybe the complex numbers cancel out using the alternative definition.","H_n H_n=\sum_{k=1}^{n} \frac{1}{k} H_n=\int_0^1 \frac{1-x^n}{1-x}\,dx H_n n \widetilde{H_n} \widetilde{H_n}=\sum_{k=1}^{n} \frac{(-1)^{k-1}}{k} n \widetilde{H_n}=\int_0^1 \frac{1+(-1)^{n-1}x^n}{1+x}\,dx n \text{Real}[(-1)^z]=\cos(\pi\,z) \widetilde{H_n}=\int_0^1 \frac{1+(-\cos(\pi\,n))x^n}{1+x}\,dx=\sum_{k=1}^{\infty}(-1)^{k-1} \left(\frac{1}{k}-\frac{\cos(\pi\,n)}{k+n}\right)\tag{1} \widetilde{H}_{1/2}=\log 2 n H_n=\zeta_n(1) \widetilde{H_n}=\eta_n(1) \lambda_n(1)=\sum_{k=1}^{n} \frac{1}{2k-1} \beta_n(1)=\sum_{k=1}^{n} \frac{(-1)^{k-1}}{2k-1} \zeta_n(1) H_n \lambda_n(1) n \lambda_n(1)=\zeta_{2n}(1) -\frac{1}{2}\zeta_{n}(1)=H_{2n}-\frac{1}{2}H_n H_n \widetilde{H_n} n \widetilde{H_n} n \widetilde{H_n} \eta_n(1) \eta_{2n-1}(1)=\widetilde{H}_{2n-1}=2\lambda_n(1)-\zeta_{2n-1}(1) \eta_{2n}(1)=\widetilde{H}_{2n}=2\lambda_n(1)-\zeta_{2n}(1) H_n^{(s)}=\zeta_n(s)=\sum_{k=1}^n \frac{1}{k^s} \csc x \sec x \sin x \cos x \cos x \eta_n(1) \cos(x)=1+\frac{x}{\pi}\left(\eta_{-x/\pi}(1)-\eta_{x/\pi}(1)\right)+\frac{x}{\pi}\left(\zeta_{-x/\pi}(1)-\zeta_{x/\pi}(1)\right)","['calculus', 'integration', 'sequences-and-series', 'definite-integrals', 'summation']"
71,Ways to prove a relation featuring $\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx$,Ways to prove a relation featuring,\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx,"From a previous post the following integral arised: $$\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx$$ And there user178256 linked us to this question where the user M.N.C.E. stated the following: $$\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx=\frac{1}{24}\int _0^{\infty }\frac{\ln ^4\left(1+x^2\right)}{x^2}\:dx+\frac{2}{3}\int _0^{\infty }\frac{\arctan ^4\left(x\right)}{x^2}\:dx$$ My question is, how can we prove this relation without evaluating each integral while also avoiding complex numbers? What I thought of doing is to use the following algebraic identity: $$a^2b^2=\frac{1}{12}\left(a+b\right)^4+\frac{1}{12}\left(a-b\right)^4-\frac{1}{6}a^4-\frac{1}{6}b^4$$ This means that if we set $a=\arctan\left(x\right)$ and $b=\ln\left(1+x^2\right)$ we have: $$\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx=\frac{1}{12}\int _0^{\infty }\frac{\left(\arctan \left(x\right)+\ln \left(1+x^2\right)\right)^4}{x^2}\:dx$$ $$+\frac{1}{12}\int _0^{\infty }\frac{\left(\arctan \left(x\right)-\ln \left(1+x^2\right)\right)^4}{x^2}\:dx-\frac{1}{6}\int _0^{\infty }\frac{\arctan ^4\left(x\right)}{x^2}\:dx-\frac{1}{6}\int _0^{\infty }\frac{\ln ^4\left(1+x^2\right)}{x^2}\:dx$$ Though I'm having a little bit of trouble getting somewhere with the first $2$ integrals, any help will be well received.","From a previous post the following integral arised: And there user178256 linked us to this question where the user M.N.C.E. stated the following: My question is, how can we prove this relation without evaluating each integral while also avoiding complex numbers? What I thought of doing is to use the following algebraic identity: This means that if we set and we have: Though I'm having a little bit of trouble getting somewhere with the first integrals, any help will be well received.",\int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx \int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx=\frac{1}{24}\int _0^{\infty }\frac{\ln ^4\left(1+x^2\right)}{x^2}\:dx+\frac{2}{3}\int _0^{\infty }\frac{\arctan ^4\left(x\right)}{x^2}\:dx a^2b^2=\frac{1}{12}\left(a+b\right)^4+\frac{1}{12}\left(a-b\right)^4-\frac{1}{6}a^4-\frac{1}{6}b^4 a=\arctan\left(x\right) b=\ln\left(1+x^2\right) \int _0^{\infty }\frac{\arctan ^2\left(x\right)\ln ^2\left(1+x^2\right)}{x^2}\:dx=\frac{1}{12}\int _0^{\infty }\frac{\left(\arctan \left(x\right)+\ln \left(1+x^2\right)\right)^4}{x^2}\:dx +\frac{1}{12}\int _0^{\infty }\frac{\left(\arctan \left(x\right)-\ln \left(1+x^2\right)\right)^4}{x^2}\:dx-\frac{1}{6}\int _0^{\infty }\frac{\arctan ^4\left(x\right)}{x^2}\:dx-\frac{1}{6}\int _0^{\infty }\frac{\ln ^4\left(1+x^2\right)}{x^2}\:dx 2,['calculus']
72,Help with arcsin integral,Help with arcsin integral,,"I have the following integral: $$ I =\int x^2\sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) dx$$ Where $a$ and $b$ are non-zero positive integers, and $x<a$ . I have started by integration by parts: $$ I = uv - \int vu'$$ $$u = \sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right )$$ $$u' =  \left [ \sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) \right ]'$$ We substitute the inside content of the arcsin by $z=\frac{\sqrt{a^2-x^2}}{b}$ : $$u' =  \left [ \sin^{-1}(z) \right ]' = \frac{1}{\sqrt{1-z^2}} \cdot  z'$$ $$z' = - \frac{x}{b} (a^2-x^2)^{- \frac{1}{2}}$$ Hence we obtain: $$u' =  -\frac{x}{\sqrt{(a^2-x^2)(b^2-a^2+x^2)}} $$ On the other hand of the integration by parts we have $v'$ : $$v' = x^2$$ $$v = \frac{1}{3}x^3$$ Hence we end up with: $$I = \frac{1}{3}x^3\sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) + \frac{1}{3}\int \frac{x^4}{\sqrt{(a^2-x^2)(b^2-a^2+x^2)}} $$ I cant really figure out how to solve this final integral . Any help would be appreciated","I have the following integral: Where and are non-zero positive integers, and . I have started by integration by parts: We substitute the inside content of the arcsin by : Hence we obtain: On the other hand of the integration by parts we have : Hence we end up with: I cant really figure out how to solve this final integral . Any help would be appreciated", I =\int x^2\sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) dx a b x<a  I = uv - \int vu' u = \sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) u' =  \left [ \sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) \right ]' z=\frac{\sqrt{a^2-x^2}}{b} u' =  \left [ \sin^{-1}(z) \right ]' = \frac{1}{\sqrt{1-z^2}} \cdot  z' z' = - \frac{x}{b} (a^2-x^2)^{- \frac{1}{2}} u' =  -\frac{x}{\sqrt{(a^2-x^2)(b^2-a^2+x^2)}}  v' v' = x^2 v = \frac{1}{3}x^3 I = \frac{1}{3}x^3\sin^{-1}\left ( \frac{\sqrt{a^2-x^2}}{b} \right ) + \frac{1}{3}\int \frac{x^4}{\sqrt{(a^2-x^2)(b^2-a^2+x^2)}} ,"['calculus', 'integration', 'indefinite-integrals']"
73,Double partial derivative proof,Double partial derivative proof,,"Let $z=f(x,y)$ where $x:=r \cos \theta$ and $y := r \sin \theta$ . I had to prove that $\frac {\partial ^{2}z}{\partial \ x^{2}} + \frac {\partial ^{2}z}{\partial \ x^{2}} = \frac {\partial ^{2}z}{\partial \ r^{2}} \ + \dots$ The whole equation was given. My doubt: I applied Jacobian and tried to solve this but I ended up in a loop where I was substituting the same things back and forth. The solution provided said this. $\frac {\partial ^{2}z}{\partial r^{2}} \ = \frac {\partial}{\partial r}(\frac {\partial z}{\partial r})  = \frac {\partial}{\partial r}(\cos \theta \frac {\partial z}{\partial x} + \sin \theta \frac {\partial z}{\partial y})$ $ = \cos \theta \ [ \cos \theta \frac {\partial}{\partial x} + \sin \theta \frac {\partial }{\partial y} ](\frac {\partial z}{\partial x}) \ + \sin \theta [ \cos \theta \frac {\partial }{\partial x} + \sin \theta \frac {\partial }{\partial y} ] (\frac {\partial z}{\partial y}).$ I do not understand the last step. What exactly is happening? Why do we use the partial derivative of $z$ with respect to $r$ (and skip the $z$ in the numerator) and multiply it with partial derivative of z with respect to $x$ and $y$ ? Since $x$ and $y$ are functions of $r$ and $\theta$ and since in $\frac {\partial z}{\partial x}$ we have kept $y$ constant are we accounting for that? I am really confused as this relevant theory wasn't taught in class and the professor hasn't been helpful to clear this part. Any insight is highly appreciated.",Let where and . I had to prove that The whole equation was given. My doubt: I applied Jacobian and tried to solve this but I ended up in a loop where I was substituting the same things back and forth. The solution provided said this. I do not understand the last step. What exactly is happening? Why do we use the partial derivative of with respect to (and skip the in the numerator) and multiply it with partial derivative of z with respect to and ? Since and are functions of and and since in we have kept constant are we accounting for that? I am really confused as this relevant theory wasn't taught in class and the professor hasn't been helpful to clear this part. Any insight is highly appreciated.,"z=f(x,y) x:=r \cos \theta y := r \sin \theta \frac {\partial ^{2}z}{\partial \ x^{2}} + \frac {\partial ^{2}z}{\partial \ x^{2}} = \frac {\partial ^{2}z}{\partial \ r^{2}} \ + \dots \frac {\partial ^{2}z}{\partial r^{2}} \ = \frac {\partial}{\partial r}(\frac {\partial z}{\partial r})  = \frac {\partial}{\partial r}(\cos \theta \frac {\partial z}{\partial x} + \sin \theta \frac {\partial z}{\partial y})  = \cos \theta \ [ \cos \theta \frac {\partial}{\partial x} + \sin \theta \frac {\partial }{\partial y} ](\frac {\partial z}{\partial x}) \ + \sin \theta [ \cos \theta \frac {\partial }{\partial x} + \sin \theta \frac {\partial }{\partial y} ] (\frac {\partial z}{\partial y}). z r z x y x y r \theta \frac {\partial z}{\partial x} y","['calculus', 'multivariable-calculus', 'derivatives', 'partial-derivative']"
74,Is it true that $ \sum_{n=1}^{\infty}\sqrt{a_{n}} $ converge $ \Rightarrow\sum_{n=1}^{\infty}a_{n} $ converge? [duplicate],Is it true that  converge  converge? [duplicate], \sum_{n=1}^{\infty}\sqrt{a_{n}}   \Rightarrow\sum_{n=1}^{\infty}a_{n} ,"This question already has answers here : $\sum_\limits{n=0}^{\infty} a_n$ converges $\implies \sum_\limits{n=0}^{\infty} a_n^2$ converges [duplicate] (7 answers) Closed 3 years ago . Let $ a_n $ be a non-negative sequence, such that $ \sum_{n=1}^{\infty}\sqrt{a_{n}} $ converge. Is it true that $ \sum_{n=1}^{\infty}a_{n} $ converge? I think that it is. But I want to make sure because it appeared in my final exam. Here is my reasoning: Since $ \sum_{n=1}^{\infty}\sqrt{a_{n}} $ converges, $ \sqrt{a_{n}}\underset{n\to\infty}{\to}0 $ and thus $ a_{n}\underset{n\to\infty}{\to}0 $ . So there exists some $ n_0 $ such that, for all $ n>n_0$ , it follows that $ 0\leq a_{n}<\frac{1}{2} $ . Thus, for each $ n>n_0 $ we have $$ a_{n}<\sqrt{a_{n}} .$$ So, from the comparison test, we get the convergence of $$ \sum_{n=1}^{\infty}a_{n}. $$ Do you agree?","This question already has answers here : $\sum_\limits{n=0}^{\infty} a_n$ converges $\implies \sum_\limits{n=0}^{\infty} a_n^2$ converges [duplicate] (7 answers) Closed 3 years ago . Let be a non-negative sequence, such that converge. Is it true that converge? I think that it is. But I want to make sure because it appeared in my final exam. Here is my reasoning: Since converges, and thus . So there exists some such that, for all , it follows that . Thus, for each we have So, from the comparison test, we get the convergence of Do you agree?", a_n   \sum_{n=1}^{\infty}\sqrt{a_{n}}   \sum_{n=1}^{\infty}a_{n}   \sum_{n=1}^{\infty}\sqrt{a_{n}}   \sqrt{a_{n}}\underset{n\to\infty}{\to}0   a_{n}\underset{n\to\infty}{\to}0   n_0   n>n_0  0\leq a_{n}<\frac{1}{2}   n>n_0   a_{n}<\sqrt{a_{n}} .  \sum_{n=1}^{\infty}a_{n}. ,"['calculus', 'sequences-and-series']"
75,Can $\int \frac{\sec x \ \mathrm{d}x}{\sqrt{\sin(x+2A)+\sin(A)}}$ be evaluated using elementary functions?,Can  be evaluated using elementary functions?,\int \frac{\sec x \ \mathrm{d}x}{\sqrt{\sin(x+2A)+\sin(A)}},"This question recently popped up on one of my tests and I still have no idea on how to even begin. I tried assuming $\sin(x+2A)+\sin(A)=t^2$ which did not help at all. Then I went on to multiply and divide by $\tan x$ to create a derivative on the numerator, still does not help. I even tried to expand $\sin(x+2A)$ which too does not seem to follow. I have also tried Approach $0$ and Wolfram Alpha  but they do not seem to help. and many more... Now I am stumped I have no idea as to how to even begin. I have tried everything that I could think of. Note that we are only familiar with basics of integration(no contour integrals ; no special functions etc..) $\bullet~\textbf{Question:}~$ ""Can the above integral be evaluated in elementary functions?"" If yes then how? If not , can we prove that it cannot be solved using elementary funcions?","This question recently popped up on one of my tests and I still have no idea on how to even begin. I tried assuming which did not help at all. Then I went on to multiply and divide by to create a derivative on the numerator, still does not help. I even tried to expand which too does not seem to follow. I have also tried Approach and Wolfram Alpha  but they do not seem to help. and many more... Now I am stumped I have no idea as to how to even begin. I have tried everything that I could think of. Note that we are only familiar with basics of integration(no contour integrals ; no special functions etc..) ""Can the above integral be evaluated in elementary functions?"" If yes then how? If not , can we prove that it cannot be solved using elementary funcions?",\sin(x+2A)+\sin(A)=t^2 \tan x \sin(x+2A) 0 \bullet~\textbf{Question:}~,"['calculus', 'integration', 'trigonometry', 'indefinite-integrals']"
76,Can any continuous function be re-parameterized into a differentiable function?,Can any continuous function be re-parameterized into a differentiable function?,,"$|x|$ is not differentiable at zero. However, if we compose it with another function that ""eases up"" very gently to zero, for example, $x=t^3$ , we can obtain a function $|t^3|$ which is differentiable everywhere. I imagine this as ""stretching out"" $|x|$ to make it smooth. It seems like any continuous function could be turned in to a differentiable function by composing it with another function, that momentarily comes down to a derivative of 0 everywhere the continuous function is not differentiable. As I have posed it, this question has a trivial solution: $f\circ 0$ is always differentiable (even if $f$ is not continuous!). So, an additional requirement should be imposed, to fit the intuition of ""stretching $f$ ."" The function being composed should be monotonically increasing and should cover the entire domain of $f$ . Given a continuous $f(x)$ , can such a $g(t)$ always be found so that $f(g(t))$ is differentiable everywhere?","is not differentiable at zero. However, if we compose it with another function that ""eases up"" very gently to zero, for example, , we can obtain a function which is differentiable everywhere. I imagine this as ""stretching out"" to make it smooth. It seems like any continuous function could be turned in to a differentiable function by composing it with another function, that momentarily comes down to a derivative of 0 everywhere the continuous function is not differentiable. As I have posed it, this question has a trivial solution: is always differentiable (even if is not continuous!). So, an additional requirement should be imposed, to fit the intuition of ""stretching ."" The function being composed should be monotonically increasing and should cover the entire domain of . Given a continuous , can such a always be found so that is differentiable everywhere?",|x| x=t^3 |t^3| |x| f\circ 0 f f f f(x) g(t) f(g(t)),"['calculus', 'continuity']"
77,Does the Fundamental Theorem of Calculus tell us that integration is the 'opposite' of differentiation?,Does the Fundamental Theorem of Calculus tell us that integration is the 'opposite' of differentiation?,,"I have often read that the Fundamental Theorem of Calculus (FTC) tells us that integration is the opposite of differentiation. I have always found this summary confusing, so I will lay out what I think people mean when they make such a statement. The First FTC implies the existence of antiderivatives for every function, $f$ , that is continuous on a particular interval, say $[a,b]$ . Generally, we denote this antiderivative as $F$ . Differentiating $F$ gets back to our original function, $f$ . So when people say that 'integration is the opposite of differentiation', what they mean is that an antiderivative of a function can be computed using a definite integral. The Second FTC is more powerful than the First FTC, as it tells us that definite integrals can be computed using the antiderivative of a function (which is generally more useful than knowing that one possible antiderivative of $f$ can be computed using a definite integral, $F$ ). For the Second FTC, I don't understand how this is related to 'integration being the opposite of differentiation' at all. The Second FTC shows us the link between antiderivatives (indefinite integrals) and definite integrals. It is extremely useful for trying to find the area under a curve, but I'm not sure how this relates to integration and differentiation being 'opposites'. Is there something about the First FTC or the Second FTC that has a bigger implication about integration being the opposite of differentiation, or is my understanding correct?","I have often read that the Fundamental Theorem of Calculus (FTC) tells us that integration is the opposite of differentiation. I have always found this summary confusing, so I will lay out what I think people mean when they make such a statement. The First FTC implies the existence of antiderivatives for every function, , that is continuous on a particular interval, say . Generally, we denote this antiderivative as . Differentiating gets back to our original function, . So when people say that 'integration is the opposite of differentiation', what they mean is that an antiderivative of a function can be computed using a definite integral. The Second FTC is more powerful than the First FTC, as it tells us that definite integrals can be computed using the antiderivative of a function (which is generally more useful than knowing that one possible antiderivative of can be computed using a definite integral, ). For the Second FTC, I don't understand how this is related to 'integration being the opposite of differentiation' at all. The Second FTC shows us the link between antiderivatives (indefinite integrals) and definite integrals. It is extremely useful for trying to find the area under a curve, but I'm not sure how this relates to integration and differentiation being 'opposites'. Is there something about the First FTC or the Second FTC that has a bigger implication about integration being the opposite of differentiation, or is my understanding correct?","f [a,b] F F f f F","['calculus', 'integration', 'derivatives', 'definite-integrals', 'indefinite-integrals']"
78,Prove that $\lim_{n \to \infty} a^{\frac{1}{n}} = 1$ when $a > 0$,Prove that  when,\lim_{n \to \infty} a^{\frac{1}{n}} = 1 a > 0,"The question is in the title. I will present the argument that I have for this. Proof Attempt: Let $a = 1$ . Then, $a^{\frac{1}{n}} = 1$ for all $n \in \mathbb{N}$ so the limit is clearly equal to 1. Let $a > 1$ . Define $x_n = a^{\frac{1}{n}} - 1$ . Then, we have: $$a = (1+x_n)^n$$ I claim that $x_n > 0$ for all $n \in \mathbb{N}$ . To show that this is true, suppose that $x_n \leq 0$ . Then, $a^{\frac{1}{n}} < 1$ and that implies that $a \leq 1$ . This is false under the given hypothesis that $a > 1$ . Now, we use Bernoulli's inequality and deduce that: $$a = (1+x_n)^n \geq 1+nx_n \geq 1$$ $$\frac{a-1}{n} \geq x_n \geq 0$$ By the Squeeze Theorem, it follows that $x_n \to 0$ as $n \to \infty$ . That is, $a^{\frac{1}{n}} \to 1$ as $n \to \infty$ . Suppose that $0 < a < 1$ . Then: $$b = \frac{1}{a} > 1$$ Clearly, the sequence defined by $x_n = b^{\frac{1}{n}}$ converges to 1. So: $$\lim_{n \to \infty} b^{\frac{1}{n}} = 1$$ $$\lim_{n \to \infty} \frac{1}{b^{\frac{1}{n}}} = \frac{1}{\lim_{n \to \infty} b^{\frac{1}{n}}} = \lim_{n \to \infty} a^{\frac{1}{n}} = 1$$ That proves the desired result. Is the proof above correct? If it isn't, why? How can I fix it? Edit: Since one individual has voted for this question to be closed, I want to explain why it's not a duplicate and the suggestion that it should be closed makes no sense. This question requires a solution to be verified. Namely, my solution to the given problem is what needs to be verified. It needs to be criticized and holes need to be pointed out so that I may fix the proof. That's actually explicitly what I've asked in the last line of the original question. Since I'm self-studying mathematics, it stands to reason that I may believe I have a proof but, in reality, do not have one. If someone can point out the mistake in my argument and if I can fix it without having to refer to another person's proof, then that would be more fruitful. Let $a > 1$ and $x > 0$. Prove that $a^x > 1$ Please refer to the above link for another question I asked, where I believed that I had a proof of the result and several individuals chipped in to help me fix it. The mistake with respect to my proof was explicitly pointed out to me and that ended up being very useful. The question that was linked, while containing useful and insightful information that I would be interested in AFTER I proved the result, does not answer the question as I had asked it.","The question is in the title. I will present the argument that I have for this. Proof Attempt: Let . Then, for all so the limit is clearly equal to 1. Let . Define . Then, we have: I claim that for all . To show that this is true, suppose that . Then, and that implies that . This is false under the given hypothesis that . Now, we use Bernoulli's inequality and deduce that: By the Squeeze Theorem, it follows that as . That is, as . Suppose that . Then: Clearly, the sequence defined by converges to 1. So: That proves the desired result. Is the proof above correct? If it isn't, why? How can I fix it? Edit: Since one individual has voted for this question to be closed, I want to explain why it's not a duplicate and the suggestion that it should be closed makes no sense. This question requires a solution to be verified. Namely, my solution to the given problem is what needs to be verified. It needs to be criticized and holes need to be pointed out so that I may fix the proof. That's actually explicitly what I've asked in the last line of the original question. Since I'm self-studying mathematics, it stands to reason that I may believe I have a proof but, in reality, do not have one. If someone can point out the mistake in my argument and if I can fix it without having to refer to another person's proof, then that would be more fruitful. Let $a > 1$ and $x > 0$. Prove that $a^x > 1$ Please refer to the above link for another question I asked, where I believed that I had a proof of the result and several individuals chipped in to help me fix it. The mistake with respect to my proof was explicitly pointed out to me and that ended up being very useful. The question that was linked, while containing useful and insightful information that I would be interested in AFTER I proved the result, does not answer the question as I had asked it.",a = 1 a^{\frac{1}{n}} = 1 n \in \mathbb{N} a > 1 x_n = a^{\frac{1}{n}} - 1 a = (1+x_n)^n x_n > 0 n \in \mathbb{N} x_n \leq 0 a^{\frac{1}{n}} < 1 a \leq 1 a > 1 a = (1+x_n)^n \geq 1+nx_n \geq 1 \frac{a-1}{n} \geq x_n \geq 0 x_n \to 0 n \to \infty a^{\frac{1}{n}} \to 1 n \to \infty 0 < a < 1 b = \frac{1}{a} > 1 x_n = b^{\frac{1}{n}} \lim_{n \to \infty} b^{\frac{1}{n}} = 1 \lim_{n \to \infty} \frac{1}{b^{\frac{1}{n}}} = \frac{1}{\lim_{n \to \infty} b^{\frac{1}{n}}} = \lim_{n \to \infty} a^{\frac{1}{n}} = 1,"['calculus', 'solution-verification']"
79,Cardioid in a coffee cup,Cardioid in a coffee cup,,"I was learning about cardioids and other figures recently and noticed that the a cardiod was formed in my coffee cup. Link to image: https://ibb.co/ngJD4jc So i decide to prove this mathematically. I took the equation of a circle centered at the origin with radius 1. I selected the point (-1,0) as the light source and found out that every reflected ray of light had the polar equation $$ r = \frac{\sin(\alpha/2)}{\sin(3\alpha/2 - \theta)} $$ where $$(1,\alpha)$$ is the point on the circle. From the equation of tangent how can i find the equation of the cardiod?","I was learning about cardioids and other figures recently and noticed that the a cardiod was formed in my coffee cup. Link to image: https://ibb.co/ngJD4jc So i decide to prove this mathematically. I took the equation of a circle centered at the origin with radius 1. I selected the point (-1,0) as the light source and found out that every reflected ray of light had the polar equation where is the point on the circle. From the equation of tangent how can i find the equation of the cardiod?"," r = \frac{\sin(\alpha/2)}{\sin(3\alpha/2 - \theta)}  (1,\alpha)","['calculus', 'geometry', 'polar-coordinates']"
80,Finding the value of k in the following limit,Finding the value of k in the following limit,,Let $f :\mathbb{R}\to \mathbb{R}$ be a continuous function with period $1$ and $$\lim_{n\to\infty}\int_0^1\sin^2(\pi x)f(nx)dx= \frac{1}{k}\int_0^1f(x)dx.$$ Find $k$ . My approach till now: Applying half angle formula $2\sin^2(x) = 1-\cos(2x)$ I got : $$\frac{1}{2}\int_0^1f(nx)dx- \frac{1}{2}\int_0^1\cos(2\pi x)f(nx)dx.$$ I can't think of a way forward from here without applying integration by parts but i don't know if its right to apply it as we don't know about the differentiability of the function $f$ . Please help me with this problem.,Let be a continuous function with period and Find . My approach till now: Applying half angle formula I got : I can't think of a way forward from here without applying integration by parts but i don't know if its right to apply it as we don't know about the differentiability of the function . Please help me with this problem.,"f :\mathbb{R}\to \mathbb{R} 1 \lim_{n\to\infty}\int_0^1\sin^2(\pi x)f(nx)dx= \frac{1}{k}\int_0^1f(x)dx. k 2\sin^2(x) = 1-\cos(2x) \frac{1}{2}\int_0^1f(nx)dx-
\frac{1}{2}\int_0^1\cos(2\pi x)f(nx)dx. f","['calculus', 'limits', 'functions', 'trigonometry', 'definite-integrals']"
81,How to calculate the spiral around a curve?,How to calculate the spiral around a curve?,,"I have a curve given by a set of points and want to build a spiral around it (like this). I tried it by STEP 1: calculated the vector of each step by $$v_n = \left<x_n,y_n,z_n\right> - \left<x_{n-1},y_{n-1},z_{n-1}\right>$$ STEP 2: I assumed a vector/plane of the rotating trajectory as $$ w_n = \left<\cos(i),1,\sin(i)\right>$$ where $i$ represents the intervals and increases by the point number. And calculated the perpendicular vector to find the spiral points by $$X = v_y \cdot w_z - v_z \cdot w_y $$ $$Y = v_z \cdot w_x - v_x \cdot w_z $$ $$Z = v_x \cdot w_y - v_y \cdot w_x $$ And, of course, I normalized the scale. The spiral is formed, but I have discontinuity or deformation at sharp angles (probably because the vector direction is changed). It is not a matter of smoothness, as the spiral changes its direction to rotate in the opposite direction. Where did I do wrong?","I have a curve given by a set of points and want to build a spiral around it (like this). I tried it by STEP 1: calculated the vector of each step by STEP 2: I assumed a vector/plane of the rotating trajectory as where represents the intervals and increases by the point number. And calculated the perpendicular vector to find the spiral points by And, of course, I normalized the scale. The spiral is formed, but I have discontinuity or deformation at sharp angles (probably because the vector direction is changed). It is not a matter of smoothness, as the spiral changes its direction to rotate in the opposite direction. Where did I do wrong?","v_n = \left<x_n,y_n,z_n\right> - \left<x_{n-1},y_{n-1},z_{n-1}\right>  w_n = \left<\cos(i),1,\sin(i)\right> i X = v_y \cdot w_z - v_z \cdot w_y  Y = v_z \cdot w_x - v_x \cdot w_z  Z = v_x \cdot w_y - v_y \cdot w_x ","['calculus', 'geometry', 'vector-spaces', 'vectors']"
82,Prove that $x + \frac{2x^3}{3} + \cdots + \frac{2\cdot 4 \cdot \cdots 2nx^{2n+1}}{3\cdot 5 \cdot (2n+1)}+\cdots = \frac{\arcsin(x)}{\sqrt{1-x^2}}$,Prove that,x + \frac{2x^3}{3} + \cdots + \frac{2\cdot 4 \cdot \cdots 2nx^{2n+1}}{3\cdot 5 \cdot (2n+1)}+\cdots = \frac{\arcsin(x)}{\sqrt{1-x^2}},"Prove that $x + \dfrac{2x^3}{3} + \cdots + \dfrac{2\cdot 4 \cdot \cdots 2nx^{2n+1}}{3\cdot 5 \cdot (2n+1)}+\cdots = \dfrac{\arcsin(x)}{\sqrt{1-x^2}}.$ Let $f(x) = x + \dfrac{2}3x^3 +\dfrac{8}{15}x^5 + \cdots + \dfrac{1}2n!\cdot\dfrac{n!}{(2n+1)!}(2x)^{2n+1}+\cdots.$ Then $xf(x) = x^2 + \dfrac{2}3 x^4 + \dfrac{8}{15}x^6 + \cdots + \dfrac{1}{4}n!\cdot \dfrac{n!}{(2n+1)!}(2x)^{2n+2}+\cdots.$ Also, $f'(x) = 1 + 2x^2 + \dfrac{8}3 x^4 + \cdots + n!\cdot \dfrac{n!}{(2n)!}(2x)^{2n}+\cdots$ and $(1-x^2)f'(x) =1+x^2 + \dfrac{2}3 x^4 + \cdots + [n!\cdot \dfrac{n!}{(2n)!}2^{2n}-(n-1)!\cdot \dfrac{(n-1)!}{(2n-2)!}2^{2n-2}]x^{2n}+\cdots\\ =1+x^2 + \dfrac{2}3 x^4 + \cdots + \dfrac{1}{4}\cdot(n-1)!\cdot \dfrac{(n-1)!}{(2n-1)!}\cdot(2x)^{2n}+ \cdots.$ Hence the derivative of $\sqrt{1-x^2}f(x)$ is $\sqrt{1-x^2}f'(x)-\dfrac{xf(x)}{\sqrt{1-x^2}} = \dfrac{1}{\sqrt{1-x^2}}((1-x^2)f'(x) - xf(x))=\dfrac{1}{\sqrt{1-x^2}}.$ Integrating, we see that $\sqrt{1-x^2}f(x) =\arcsin(x)+C.$ Plugging in the constant $C=0$ and dividing both sides by $\sqrt{1-x^2}$ gives the desired result. Are there other approaches to solving this problem?","Prove that Let Then Also, and Hence the derivative of is Integrating, we see that Plugging in the constant and dividing both sides by gives the desired result. Are there other approaches to solving this problem?","x + \dfrac{2x^3}{3} + \cdots + \dfrac{2\cdot 4 \cdot \cdots 2nx^{2n+1}}{3\cdot 5 \cdot (2n+1)}+\cdots = \dfrac{\arcsin(x)}{\sqrt{1-x^2}}. f(x) = x + \dfrac{2}3x^3 +\dfrac{8}{15}x^5 + \cdots + \dfrac{1}2n!\cdot\dfrac{n!}{(2n+1)!}(2x)^{2n+1}+\cdots. xf(x) = x^2 + \dfrac{2}3 x^4 + \dfrac{8}{15}x^6 + \cdots + \dfrac{1}{4}n!\cdot \dfrac{n!}{(2n+1)!}(2x)^{2n+2}+\cdots. f'(x) = 1 + 2x^2 + \dfrac{8}3 x^4 + \cdots + n!\cdot \dfrac{n!}{(2n)!}(2x)^{2n}+\cdots (1-x^2)f'(x) =1+x^2 + \dfrac{2}3 x^4 + \cdots + [n!\cdot \dfrac{n!}{(2n)!}2^{2n}-(n-1)!\cdot \dfrac{(n-1)!}{(2n-2)!}2^{2n-2}]x^{2n}+\cdots\\
=1+x^2 + \dfrac{2}3 x^4 + \cdots + \dfrac{1}{4}\cdot(n-1)!\cdot \dfrac{(n-1)!}{(2n-1)!}\cdot(2x)^{2n}+ \cdots. \sqrt{1-x^2}f(x) \sqrt{1-x^2}f'(x)-\dfrac{xf(x)}{\sqrt{1-x^2}} = \dfrac{1}{\sqrt{1-x^2}}((1-x^2)f'(x) - xf(x))=\dfrac{1}{\sqrt{1-x^2}}. \sqrt{1-x^2}f(x) =\arcsin(x)+C. C=0 \sqrt{1-x^2}","['calculus', 'integration', 'derivatives']"
83,Integrability of a polynomial under root,Integrability of a polynomial under root,,"Under what conditions can $$\int\sqrt[n]{a_0\cdot x^m+a_1 \cdot x^{m-1}+...+a_m}\ dx$$ be expressed in terms of elementary functions? $\sqrt{x^2+3x+5}$ can be expressed, while $\sqrt{x^3+3x+5}$ not.","Under what conditions can be expressed in terms of elementary functions? can be expressed, while not.",\int\sqrt[n]{a_0\cdot x^m+a_1 \cdot x^{m-1}+...+a_m}\ dx \sqrt{x^2+3x+5} \sqrt{x^3+3x+5},"['calculus', 'integration']"
84,Shortest path between two points around an obstacle?,Shortest path between two points around an obstacle?,,"I'm trying to figure out a problem that goes like this: A particle originally placed at the origin tries to reach the point $(12,16)$ whilst covering the shortest distance possible. But there is a circle of radius $3$ , centered at the point $(6,8)$ , and the point cannot go through the circle. (Click on image to view larger picture.) My original thought was to travel in a straight line until reaching the circle, and then travel along the circumference until we reach the point on the circumference that is the shortest distance to $(12,16)$ . However I feel like this path should be longer than a path along a curve that is tangent to the circle and passes through both the origin and the given point. Now I'm just stuck on how to find this specific curve. Since the curve must be tangent to the circle at some point I can equate the derivative at some point, but what point exactly?","I'm trying to figure out a problem that goes like this: A particle originally placed at the origin tries to reach the point whilst covering the shortest distance possible. But there is a circle of radius , centered at the point , and the point cannot go through the circle. (Click on image to view larger picture.) My original thought was to travel in a straight line until reaching the circle, and then travel along the circumference until we reach the point on the circumference that is the shortest distance to . However I feel like this path should be longer than a path along a curve that is tangent to the circle and passes through both the origin and the given point. Now I'm just stuck on how to find this specific curve. Since the curve must be tangent to the circle at some point I can equate the derivative at some point, but what point exactly?","(12,16) 3 (6,8) (12,16)","['calculus', 'differential-geometry', 'circles']"
85,error of Taylor series for $\ln x$,error of Taylor series for,\ln x,"Find the Taylor Polynomials for $f(x)=\ln x$ about $a=1$ and give error estimates. Below is what I've done. There may be some mistakes. Let $f(x) = \ln x$ . Then $f(1) = 0$ . $f'(x) = \dfrac{1}{x}$ so $f'(1) = 1$ . $f''(x) = -\dfrac{1}{x^2},$ so $f''(1) = -1$ . $f^{(3)}(x) = \dfrac{2}{x^3}$ so $f^{(3)}(1) = 2$ . From this, we see that $f^{(n)}(1)$ , where $n>0,$ has value $(-1)^{n-1}(n-1)!$ . Hence the Taylor polynomials $P_{n,1}(x)$ for $f(x)$ about $a=1$ are given by $\displaystyle\sum_{i=1}^n (-1)^{i-1}\dfrac{(x-1)^i}{i}$ . By Taylor's Theorem, we have that $f(x) - P_{n,1}(x)=\dfrac{f^{(n+1)}(x_0)}{(n+1)!}(x-1)^{n+1},$ where $1\leq x_0 \leq x$ . Hence since $|f^{(n+1)}(x_0)|=|(-1)^n\dfrac{n!}{(x_0)^{n+1}}|=\dfrac{n!}{(x_0)^{n+1}}, n\in\mathbb{N}$ is a decreasing function, for $x_0\geq1$ , it has a maximum of $n!$ at $x_0=1$ . Thus, the absolute value of the error is given by $\dfrac{n!}{(n+1)!}|(x-1)|^{n+1}=\dfrac{|(x-1)|^{n+1}}{n+1}.$ Edit: I guess this could also be shown using the fact that the error for an alternating series is smaller than the next term and has the same sign.","Find the Taylor Polynomials for about and give error estimates. Below is what I've done. There may be some mistakes. Let . Then . so . so . so . From this, we see that , where has value . Hence the Taylor polynomials for about are given by . By Taylor's Theorem, we have that where . Hence since is a decreasing function, for , it has a maximum of at . Thus, the absolute value of the error is given by Edit: I guess this could also be shown using the fact that the error for an alternating series is smaller than the next term and has the same sign.","f(x)=\ln x a=1 f(x) = \ln x f(1) = 0 f'(x) = \dfrac{1}{x} f'(1) = 1 f''(x) = -\dfrac{1}{x^2}, f''(1) = -1 f^{(3)}(x) = \dfrac{2}{x^3} f^{(3)}(1) = 2 f^{(n)}(1) n>0, (-1)^{n-1}(n-1)! P_{n,1}(x) f(x) a=1 \displaystyle\sum_{i=1}^n (-1)^{i-1}\dfrac{(x-1)^i}{i} f(x) - P_{n,1}(x)=\dfrac{f^{(n+1)}(x_0)}{(n+1)!}(x-1)^{n+1}, 1\leq x_0 \leq x |f^{(n+1)}(x_0)|=|(-1)^n\dfrac{n!}{(x_0)^{n+1}}|=\dfrac{n!}{(x_0)^{n+1}}, n\in\mathbb{N} x_0\geq1 n! x_0=1 \dfrac{n!}{(n+1)!}|(x-1)|^{n+1}=\dfrac{|(x-1)|^{n+1}}{n+1}.",['calculus']
86,"Calculus, Twice Differentiable Function","Calculus, Twice Differentiable Function",,"Question: Let $f(x)$ be a twice differentiable function on $\mathbb{R}$ . Show that for any $h>0$ and any $x\in\mathbb{R}$ there exists a $\zeta$ between $x-h$ and $x+h$ such that $$ \frac{f(x+h)-2f(x)+f(x-h)}{h^2}=f''(\zeta). $$ My Attempt: For $a \in (x-h,x) $ and $b \in (x,x+h)$ by Mean Value Theorem: $$ f'(a)=\frac{f(x)-f(x-h)}{h} $$ $$ f'(b)=\frac{f(x+h)-f(x)}{h} $$ Then, because $f$ is twice differentiable $\exists \zeta \in(a,b) \subset (x-h,x+h)$ s.t. $$ f''(\zeta)=\frac{f'(b)-f'(a)}{b-a} =\frac{\frac{f(x+h)-f(x)}{h}-\frac{f(x)-f(x-h)}{h}}{b-a}=\frac{f(x+h)-2f(x)+f(x-h)}{h(b-a)}$$ can we now, choose $a$ and $b$ to be $h$ apart? I don't think Mean Value Theorem allows us to choose it this way... If I use the derivative definition I'm not sure how to get rid of the limit. I also think the ""linearization"" formula may be useful something like $f(a)+f'(a)(x-a)+1/2 f''(\zeta)(x-a)^2$ ?","Question: Let be a twice differentiable function on . Show that for any and any there exists a between and such that My Attempt: For and by Mean Value Theorem: Then, because is twice differentiable s.t. can we now, choose and to be apart? I don't think Mean Value Theorem allows us to choose it this way... If I use the derivative definition I'm not sure how to get rid of the limit. I also think the ""linearization"" formula may be useful something like ?","f(x) \mathbb{R} h>0 x\in\mathbb{R} \zeta x-h x+h  \frac{f(x+h)-2f(x)+f(x-h)}{h^2}=f''(\zeta).  a \in (x-h,x)  b \in (x,x+h)  f'(a)=\frac{f(x)-f(x-h)}{h}   f'(b)=\frac{f(x+h)-f(x)}{h}  f \exists \zeta \in(a,b) \subset (x-h,x+h)  f''(\zeta)=\frac{f'(b)-f'(a)}{b-a} =\frac{\frac{f(x+h)-f(x)}{h}-\frac{f(x)-f(x-h)}{h}}{b-a}=\frac{f(x+h)-2f(x)+f(x-h)}{h(b-a)} a b h f(a)+f'(a)(x-a)+1/2 f''(\zeta)(x-a)^2","['calculus', 'derivatives']"
87,Derivative of transpose,Derivative of transpose,,"I am trying to find derivative of this : RQ(u) = u T X T Xu / u T u I need help finding derivative : 𝑑RQ/𝑑u Optimal sol should satisfy X T Xu = RQ(u)u I am very confused, any help would be great. If you could share some references that will be very helpful too.","I am trying to find derivative of this : RQ(u) = u T X T Xu / u T u I need help finding derivative : 𝑑RQ/𝑑u Optimal sol should satisfy X T Xu = RQ(u)u I am very confused, any help would be great. If you could share some references that will be very helpful too.",,"['calculus', 'linear-algebra', 'matrices', 'derivatives', 'transpose']"
88,Prove that $(x+1)^x-x^x(x-1)$ only has one (real) root,Prove that  only has one (real) root,(x+1)^x-x^x(x-1),"For $x>0$ , I want to prove that $(x+1)^x-x^x(x-1)$ only has one root","For , I want to prove that only has one root",x>0 (x+1)^x-x^x(x-1),"['calculus', 'analysis']"
89,Integrating rational function by multiplying with a high-power polynomial term,Integrating rational function by multiplying with a high-power polynomial term,,"When evaluating the integral $\int \frac{x^2 + 8}{x^3 + 9x} \textrm{d}x$ , WolframAlpha gave an interesting step-by-step suggestion. Here is the suggested method: $$\int \frac{x^2 + 8}{x^3 + 9x} \textrm{d}x = \int \frac{x^{17} + 8x^{15}}{x^{18} + 9x^{16}} \textrm{d}x=\frac{1}{18} \int \frac{18(x^{17} + 8x^{15})}{x^{18} + 9x^{16}} \textrm{d}x$$ Let $u = x^{18}+9x^{16} \implies \textrm{d}u=(18x^{17}+144x^{15}) \, \textrm{d}x = 18(x^{17} + 8x^{15}) \, \textrm{d}x $ $$\frac{1}{18} \int \frac{\textrm{d}u}{u} = \frac{1}{18} \log \vert u \vert + C $$ This indeed works, giving the correct answer (after substituting $x$ back and simplifying). But I've never seen this kind of an integration technique, and I'm wondering if there's a name for this method and perhaps a systematic way of determining which degree of polynomial to use? (The polynomial in this example happened to be $x^{15}$ , something that I would've never though of)","When evaluating the integral , WolframAlpha gave an interesting step-by-step suggestion. Here is the suggested method: Let This indeed works, giving the correct answer (after substituting back and simplifying). But I've never seen this kind of an integration technique, and I'm wondering if there's a name for this method and perhaps a systematic way of determining which degree of polynomial to use? (The polynomial in this example happened to be , something that I would've never though of)","\int \frac{x^2 + 8}{x^3 + 9x} \textrm{d}x \int \frac{x^2 + 8}{x^3 + 9x} \textrm{d}x = \int \frac{x^{17} + 8x^{15}}{x^{18} + 9x^{16}} \textrm{d}x=\frac{1}{18} \int \frac{18(x^{17} + 8x^{15})}{x^{18} + 9x^{16}} \textrm{d}x u = x^{18}+9x^{16} \implies \textrm{d}u=(18x^{17}+144x^{15}) \, \textrm{d}x = 18(x^{17} + 8x^{15}) \, \textrm{d}x  \frac{1}{18} \int \frac{\textrm{d}u}{u} = \frac{1}{18} \log \vert u \vert + C  x x^{15}","['calculus', 'integration', 'substitution']"
90,Finding range of function,Finding range of function,,"$$f(x) = \frac{1}{\sqrt{1+x}}+\frac{1}{\sqrt{1+a}}+\sqrt{\frac{ax}{ax+8}}$$ Prove that for all positive real number $a$ , $1<f(x)<2$ According  to me i think question is not correct. as at $a= 16$ , we have case when function reaches infinite value in left of $-1/2$ .","Prove that for all positive real number , According  to me i think question is not correct. as at , we have case when function reaches infinite value in left of .",f(x) = \frac{1}{\sqrt{1+x}}+\frac{1}{\sqrt{1+a}}+\sqrt{\frac{ax}{ax+8}} a 1<f(x)<2 a= 16 -1/2,"['calculus', 'proof-verification']"
91,"$u$-substitution failure in finding $f'(x)$ where $ f(x) = \int_x^0 \frac{\cos(xt)}{t}\, dt$",-substitution failure in finding  where,"u f'(x)  f(x) = \int_x^0 \frac{\cos(xt)}{t}\, dt","I'm practicing for the GRE exam, and came across the following question: If $$ f(x) = \int_x^0 \frac{\cos(xt)}{t}\, dt, $$ find $f'(x)$. The answer given is $\frac{1}{x}(1 - 2\cos(x^2))$, and I see how they get that answer. What I'm wondering is why the following $u$-substitution gives the wrong answer (or perhaps I'm making a mistake somewhere): If we set $u = xt$, then the integral transforms to  $$ f(x) = \int_{x^2}^0 \frac{\cos(u)}{u}\, du, $$ which means that $f'(x) = -(\cos(x^2)/x^2)(2x) = -\cos(x^2)/x$, which misses the $1/x$ term which the answer key says we should have. I cannot see where I am making a mistake in the $u$-sub; is it invalid in this case? Any help is much appreciated.","I'm practicing for the GRE exam, and came across the following question: If $$ f(x) = \int_x^0 \frac{\cos(xt)}{t}\, dt, $$ find $f'(x)$. The answer given is $\frac{1}{x}(1 - 2\cos(x^2))$, and I see how they get that answer. What I'm wondering is why the following $u$-substitution gives the wrong answer (or perhaps I'm making a mistake somewhere): If we set $u = xt$, then the integral transforms to  $$ f(x) = \int_{x^2}^0 \frac{\cos(u)}{u}\, du, $$ which means that $f'(x) = -(\cos(x^2)/x^2)(2x) = -\cos(x^2)/x$, which misses the $1/x$ term which the answer key says we should have. I cannot see where I am making a mistake in the $u$-sub; is it invalid in this case? Any help is much appreciated.",,"['calculus', 'integration', 'substitution']"
92,Is my solution for this integral problem correct?,Is my solution for this integral problem correct?,,"Can anyone tell me if I made any errors in my solution and whether or not my answer is correct? Is there a better/quicker method to solving this? If you can't see the writing very well (and therefore can't see my work and answer very well), then note the problem is read as ""the integral from 0 to infinity of $\cos(bx)(x-\log(e^x-1)~dx$ where $b>0$"" \begin{align} \require{cancel} \int_0^\infty e^{-ax}\cos(bx)~dx&=\sum_{n=0}^\infty\frac{(-1)^n}{(2n)!}\int_0^\infty\cos(bx)(bx)^{2n}~dx\\&=\sum_{n=0}^\infty\frac{(-b^2)^n}{(2n)!}\int_0^\infty e^{-ax}x^{2n}~dx \quad\boxed{u=ax,~du=a~dx,~x=\frac ua} \\ &= \frac1a\sum_{n=0}^\infty\frac{(-b^2)^n}{(2n)!(a^2)^n}\int_0^\infty u^{2n}e^{-u}~du\\&= \frac1a\sum_{n=0}^\infty\left(\frac{-b^2}{a^2}\right)^n\frac{\cancel{(2n)!}}{\cancel{(2n)!}}\\&= \frac1a\sum_{n=0}^\infty\left(\frac{-b^2}{a^2}\right)^n=\frac1a\left[\frac1{1+\frac{b^2}{a^2}}\right]=\frac a{a^2+b^2} \end{align} \begin{align} \require{cancel} \int_0^\infty e^{-ax}\cos(bx)~dx=\frac a{a^2+b^2}\implies \frac1{\cancel a}\left[\frac{\cancel a}{a^2+b^2}\right]&=\frac1a\int_0^\infty e^{-ax}\cos(bx)~dx\\&= \sum_{a=1}^\infty\frac1{a^2+b^2}=\sum_{a=1}^\infty\int_0^\infty\frac{e^{-ax}}a~dx \end{align} $$\implies \frac{\pi b\coth(\pi b)-1}{2b^2}=\int_0^\infty\cos(bx)\sum_{a=1}^\infty\frac{e^{-ax}}a~dx\implies \sum_{a=1}^\infty\frac{e^{-ax}}a=\frac{e^{-x}}{1-e^{-x}}=\frac1{e^x-1}$$ \begin{align} \implies-\sum_{a=1}^\infty\frac{e^{-ax}}a=\int\frac1{e^x-1}~dx&\implies\sum_{a=1}^\infty\frac{e^{-ax}}a=-(\ln(e^x-1)-x)=x-\ln(e^x-1)\end{align} $$\implies\small\sum_{a=1}^\infty\frac{e^{-ax}}a=\int_0^\infty\cos(bx)\sum_{a=1}^\infty\frac{e^{-ax}}a~dx=\int_0^\infty\cos(bx)(x-\ln(e^x-1))~dx=\frac{\pi b\coth(\pi b)-1}{2b^2}$$","Can anyone tell me if I made any errors in my solution and whether or not my answer is correct? Is there a better/quicker method to solving this? If you can't see the writing very well (and therefore can't see my work and answer very well), then note the problem is read as ""the integral from 0 to infinity of $\cos(bx)(x-\log(e^x-1)~dx$ where $b>0$"" \begin{align} \require{cancel} \int_0^\infty e^{-ax}\cos(bx)~dx&=\sum_{n=0}^\infty\frac{(-1)^n}{(2n)!}\int_0^\infty\cos(bx)(bx)^{2n}~dx\\&=\sum_{n=0}^\infty\frac{(-b^2)^n}{(2n)!}\int_0^\infty e^{-ax}x^{2n}~dx \quad\boxed{u=ax,~du=a~dx,~x=\frac ua} \\ &= \frac1a\sum_{n=0}^\infty\frac{(-b^2)^n}{(2n)!(a^2)^n}\int_0^\infty u^{2n}e^{-u}~du\\&= \frac1a\sum_{n=0}^\infty\left(\frac{-b^2}{a^2}\right)^n\frac{\cancel{(2n)!}}{\cancel{(2n)!}}\\&= \frac1a\sum_{n=0}^\infty\left(\frac{-b^2}{a^2}\right)^n=\frac1a\left[\frac1{1+\frac{b^2}{a^2}}\right]=\frac a{a^2+b^2} \end{align} \begin{align} \require{cancel} \int_0^\infty e^{-ax}\cos(bx)~dx=\frac a{a^2+b^2}\implies \frac1{\cancel a}\left[\frac{\cancel a}{a^2+b^2}\right]&=\frac1a\int_0^\infty e^{-ax}\cos(bx)~dx\\&= \sum_{a=1}^\infty\frac1{a^2+b^2}=\sum_{a=1}^\infty\int_0^\infty\frac{e^{-ax}}a~dx \end{align} $$\implies \frac{\pi b\coth(\pi b)-1}{2b^2}=\int_0^\infty\cos(bx)\sum_{a=1}^\infty\frac{e^{-ax}}a~dx\implies \sum_{a=1}^\infty\frac{e^{-ax}}a=\frac{e^{-x}}{1-e^{-x}}=\frac1{e^x-1}$$ \begin{align} \implies-\sum_{a=1}^\infty\frac{e^{-ax}}a=\int\frac1{e^x-1}~dx&\implies\sum_{a=1}^\infty\frac{e^{-ax}}a=-(\ln(e^x-1)-x)=x-\ln(e^x-1)\end{align} $$\implies\small\sum_{a=1}^\infty\frac{e^{-ax}}a=\int_0^\infty\cos(bx)\sum_{a=1}^\infty\frac{e^{-ax}}a~dx=\int_0^\infty\cos(bx)(x-\ln(e^x-1))~dx=\frac{\pi b\coth(\pi b)-1}{2b^2}$$",,"['calculus', 'sequences-and-series']"
93,"How to evaluate this integral $\int_0^1 \frac{x\log ^2(\sqrt{x^2+1}+1)}{\sqrt{1-x^2}} \, dx$",How to evaluate this integral,"\int_0^1 \frac{x\log ^2(\sqrt{x^2+1}+1)}{\sqrt{1-x^2}} \, dx","How to evaluate $$A=\int_0^1 \frac{x \log ^2\left(\sqrt{x^2+1}+1\right)}{\sqrt{1-x^2}} \, dx$$See the details here from a similar question: Evaluating $\int_0^1 \frac{z \log ^2\left(\sqrt{z^2+1}-1\right)}{\sqrt{1-z^2}} \, dz$ .  By applying the same process, I find:  $$A=\int_0^1\ln^2\left(\sqrt{2-y^2}+1\right)dy=\int_1^{\sqrt2}\frac {x\log^2 (x+1)}{\sqrt{2-x^2}}dx=\sqrt2 \int_{0}^{\pi/4}\cos\varphi\ln^2\left(\sqrt2 \cos\varphi+1\right)d\varphi.$$ $$A=\ln^22+32(1+\sqrt2)\int_{0}^{\sqrt2-1}\frac{t^2}{\left(1+t^2\right)^2(t+1+\sqrt2)(-t+1+\sqrt2)}\ln\left(\sqrt2\, \frac{1-t^2}{1+t^2}+1\right)dt.$$  Now,put $$A=\int_0^1 \frac{x \log ^2\left(\sqrt{x^2+1}+1\right)}{\sqrt{1-x^2}} \, dx,  B=\int_0^1 \frac{x \log ^2\left(\sqrt{x^2+1}-1\right)}{\sqrt{1-x^2}} \, dx.$$ We have: $$A-B=4\int_0^{1}\frac {x\log x\log(\sqrt{1+x^2}+1)}{\sqrt{1-x^2}}dx-4\int_0^{1}\frac {x\log^2 x}{\sqrt{1-x^2}}dx$$ $$A+B=-2\int_0^{1}\frac {x\log (\sqrt{1+x^2}-1)\log(\sqrt{1+x^2}+1)}{\sqrt{1-x^2}}dx+4\int_0^{1}\frac {x\log^2 x}{\sqrt{1-x^2}}dx$$  $$\int_0^{1}\frac {x\log^2 x}{\sqrt{1-x^2}}dx=\ln^22-\frac{\pi^2}{12}-2\ln2+2.$$ But how to deduce these integrals.(using Mathematica?)","How to evaluate $$A=\int_0^1 \frac{x \log ^2\left(\sqrt{x^2+1}+1\right)}{\sqrt{1-x^2}} \, dx$$See the details here from a similar question: Evaluating $\int_0^1 \frac{z \log ^2\left(\sqrt{z^2+1}-1\right)}{\sqrt{1-z^2}} \, dz$ .  By applying the same process, I find:  $$A=\int_0^1\ln^2\left(\sqrt{2-y^2}+1\right)dy=\int_1^{\sqrt2}\frac {x\log^2 (x+1)}{\sqrt{2-x^2}}dx=\sqrt2 \int_{0}^{\pi/4}\cos\varphi\ln^2\left(\sqrt2 \cos\varphi+1\right)d\varphi.$$ $$A=\ln^22+32(1+\sqrt2)\int_{0}^{\sqrt2-1}\frac{t^2}{\left(1+t^2\right)^2(t+1+\sqrt2)(-t+1+\sqrt2)}\ln\left(\sqrt2\, \frac{1-t^2}{1+t^2}+1\right)dt.$$  Now,put $$A=\int_0^1 \frac{x \log ^2\left(\sqrt{x^2+1}+1\right)}{\sqrt{1-x^2}} \, dx,  B=\int_0^1 \frac{x \log ^2\left(\sqrt{x^2+1}-1\right)}{\sqrt{1-x^2}} \, dx.$$ We have: $$A-B=4\int_0^{1}\frac {x\log x\log(\sqrt{1+x^2}+1)}{\sqrt{1-x^2}}dx-4\int_0^{1}\frac {x\log^2 x}{\sqrt{1-x^2}}dx$$ $$A+B=-2\int_0^{1}\frac {x\log (\sqrt{1+x^2}-1)\log(\sqrt{1+x^2}+1)}{\sqrt{1-x^2}}dx+4\int_0^{1}\frac {x\log^2 x}{\sqrt{1-x^2}}dx$$  $$\int_0^{1}\frac {x\log^2 x}{\sqrt{1-x^2}}dx=\ln^22-\frac{\pi^2}{12}-2\ln2+2.$$ But how to deduce these integrals.(using Mathematica?)",,"['calculus', 'integration', 'definite-integrals', 'special-functions']"
94,VERY difficult integral (Fourier transform),VERY difficult integral (Fourier transform),,"I'm working on a PDE semigroup problem and I'm calculating some things using Fourier transform, now I ended up having to find the inverse Fourier transform of $e^{-(1+\omega^2)^2 t}$. Watch this: $$ \mathcal{F}^{-1}\{e^{-(1+\omega^2)^2 t}\}(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} e^{i\omega x} d\omega $$ I tried messing about with the exponentials a bit, but nothing came from it. The problem is that we have this huge expression as an exponent, that has both real and imaginary part, so we can not easily (in my eyes) reduce it to for example a Gaussian integral via substitution. I however found the following: $$ \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} e^{i\omega x} d\omega = \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} \cos(\omega x) d\omega + i \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} \sin(\omega x ) d\omega$$ Now both integrals converge nicely, since the $e$-power kills everything off fast enough, and because $\sin(\omega x)$ is odd for all $x\in\mathbb{R}$, and $e^{-(1+\omega^2)^2 t}$ is even, we find: $$ i \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} \sin(\omega x ) d\omega = 0 $$ So that: $$\mathcal{F}^{-1}\{e^{-(1+\omega^2)^2 t}\}(x) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} \cos(\omega x) d\omega$$ But did we really make it easier on ourselves? I tried using partial integration on the above expression but got nowhere. I'm at a loss here. Can someone help me out?","I'm working on a PDE semigroup problem and I'm calculating some things using Fourier transform, now I ended up having to find the inverse Fourier transform of $e^{-(1+\omega^2)^2 t}$. Watch this: $$ \mathcal{F}^{-1}\{e^{-(1+\omega^2)^2 t}\}(x) = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} e^{i\omega x} d\omega $$ I tried messing about with the exponentials a bit, but nothing came from it. The problem is that we have this huge expression as an exponent, that has both real and imaginary part, so we can not easily (in my eyes) reduce it to for example a Gaussian integral via substitution. I however found the following: $$ \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} e^{i\omega x} d\omega = \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} \cos(\omega x) d\omega + i \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} \sin(\omega x ) d\omega$$ Now both integrals converge nicely, since the $e$-power kills everything off fast enough, and because $\sin(\omega x)$ is odd for all $x\in\mathbb{R}$, and $e^{-(1+\omega^2)^2 t}$ is even, we find: $$ i \int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} \sin(\omega x ) d\omega = 0 $$ So that: $$\mathcal{F}^{-1}\{e^{-(1+\omega^2)^2 t}\}(x) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^\infty e^{-(1+\omega^2)^2 t} \cos(\omega x) d\omega$$ But did we really make it easier on ourselves? I tried using partial integration on the above expression but got nowhere. I'm at a loss here. Can someone help me out?",,"['calculus', 'integration', 'fourier-analysis', 'fourier-transform']"
95,"$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^k}}}$",,"\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^k}}}","what is the minimum number of $k$ for which the following limit exist $$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^k}}}$$  I know that  $$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{n}$$ doesn't exist, and $$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^8}}} = 0.$$ But i don't know what is the minimum  number of $k$ for existing that limit. (note that here n's are positive integers not real numbers)","what is the minimum number of $k$ for which the following limit exist $$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^k}}}$$  I know that  $$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{n}$$ doesn't exist, and $$\mathop {\lim }\limits_{n \to \infty } \,\frac{{\tan (n)}}{{{n^8}}} = 0.$$ But i don't know what is the minimum  number of $k$ for existing that limit. (note that here n's are positive integers not real numbers)",,"['calculus', 'sequences-and-series']"
96,Mean value thorem - Showing $\sqrt{1+x} < 1+\frac{x}{2}$ for $x>0$,Mean value thorem - Showing  for,\sqrt{1+x} < 1+\frac{x}{2} x>0,"So as the title states I have to show $\sqrt{1+x} < 1+\frac{x}{2}$ for $x>0$. This is a example from the book which has to be explained for me, i'm having a hardtime understanding the proof. I do however understand the concept of MVT. So the rest of the solution looks like the following: If $x>0$, apply the Mean-Value Theorem to $f(x)= \sqrt{1+x}$ on the interval $[0,x]$. There exist $c\in [0,x]$ such that   $$\frac{\sqrt{1+x}-1}{x}=\frac{f(x)-f(0)}{x-0}=f'(c)=\frac{1}{2\sqrt{1+c}}<\frac{1}{2} $$   The last inequality hold because $c>0$. Mulitiplying by the positive number $x$ and transposing the $-1$ gives $\sqrt{1+x} <1+\frac{x}{2}$, So I am not sure why he(the author) choose $\frac{1}{2}$, it seems a little arbitrary to me. My guess is that you're allowed to pick a number for the derivative of $c$ which suits the cause/solution best, as long as it's $0<c<x$. I'm not sure though. All help would be greatly appriciated!","So as the title states I have to show $\sqrt{1+x} < 1+\frac{x}{2}$ for $x>0$. This is a example from the book which has to be explained for me, i'm having a hardtime understanding the proof. I do however understand the concept of MVT. So the rest of the solution looks like the following: If $x>0$, apply the Mean-Value Theorem to $f(x)= \sqrt{1+x}$ on the interval $[0,x]$. There exist $c\in [0,x]$ such that   $$\frac{\sqrt{1+x}-1}{x}=\frac{f(x)-f(0)}{x-0}=f'(c)=\frac{1}{2\sqrt{1+c}}<\frac{1}{2} $$   The last inequality hold because $c>0$. Mulitiplying by the positive number $x$ and transposing the $-1$ gives $\sqrt{1+x} <1+\frac{x}{2}$, So I am not sure why he(the author) choose $\frac{1}{2}$, it seems a little arbitrary to me. My guess is that you're allowed to pick a number for the derivative of $c$ which suits the cause/solution best, as long as it's $0<c<x$. I'm not sure though. All help would be greatly appriciated!",,"['calculus', 'inequality']"
97,Integral of Multivariable Gaussian across a Circular Domain.,Integral of Multivariable Gaussian across a Circular Domain.,,"Basically, trying to compute the probability, a.k.a volume under the bi-variate gaussian distribution: $$ f(x,y) = \frac{1}{2 \pi \sigma^2} \cdot \exp(\frac{-x^2 - y^2}{2 \sigma^2}) $$ over axis-aligned circles in the xy-plane. So, the circles all are of the form: $(x - c_x)^2 + y^2 = R^2$ So the centers always lie on the x-axis somewhere, and the gaussian always has mean $(x, y) = (0, 0)$ I've been using a numerical integration library which computes the following integral (setup in cartesian notation): $$ 2 \cdot \int_{x = c_x-R}^{c_x + R}\int_{y=0}^{\sqrt{R^2 - (x - c_x)^2}} f(x, y) \, dy\, dx $$ But I also know that computing this is very easy when the circle is centered at the origin (i.e. when $c_x = 0$). Since the integral can just be written in polar coordinates and turns into: $$ \frac{1}{2 \pi \sigma^2} \int_{\theta = 0}^{2\pi}\int_{r=0}^R re^{-r^2 / 2\sigma^2} \, dr\, d\theta = \frac{1 - e^{-R^2 / 2\sigma^2}}{2 \pi \sigma^2}$$ Buut, once I introduce the $c_x$ term and the circle is not centered at the origin, the polar integral gets a weird term added on, making things really scary lol. I don't know how I would go about finding a closed form, if one even exists? Here is what the polar integral becomes when $c_x \neq 0$: $$ \frac{1}{2 \pi \sigma^2} \int_{\theta = 0}^{2\pi}\int_{r=0}^R r e^{-r^2 / 2\sigma^2}e^{2r\cdot c_x \cdot\cos\theta / 2\sigma^2} \, dr\, d\theta$$ Anybody have a clue if/how I can find a closed form for the last integral? or perhaps that first integral, but I'd imagine it's harder from the cartesian perspective? Any help appreciated, Cheers :-)","Basically, trying to compute the probability, a.k.a volume under the bi-variate gaussian distribution: $$ f(x,y) = \frac{1}{2 \pi \sigma^2} \cdot \exp(\frac{-x^2 - y^2}{2 \sigma^2}) $$ over axis-aligned circles in the xy-plane. So, the circles all are of the form: $(x - c_x)^2 + y^2 = R^2$ So the centers always lie on the x-axis somewhere, and the gaussian always has mean $(x, y) = (0, 0)$ I've been using a numerical integration library which computes the following integral (setup in cartesian notation): $$ 2 \cdot \int_{x = c_x-R}^{c_x + R}\int_{y=0}^{\sqrt{R^2 - (x - c_x)^2}} f(x, y) \, dy\, dx $$ But I also know that computing this is very easy when the circle is centered at the origin (i.e. when $c_x = 0$). Since the integral can just be written in polar coordinates and turns into: $$ \frac{1}{2 \pi \sigma^2} \int_{\theta = 0}^{2\pi}\int_{r=0}^R re^{-r^2 / 2\sigma^2} \, dr\, d\theta = \frac{1 - e^{-R^2 / 2\sigma^2}}{2 \pi \sigma^2}$$ Buut, once I introduce the $c_x$ term and the circle is not centered at the origin, the polar integral gets a weird term added on, making things really scary lol. I don't know how I would go about finding a closed form, if one even exists? Here is what the polar integral becomes when $c_x \neq 0$: $$ \frac{1}{2 \pi \sigma^2} \int_{\theta = 0}^{2\pi}\int_{r=0}^R r e^{-r^2 / 2\sigma^2}e^{2r\cdot c_x \cdot\cos\theta / 2\sigma^2} \, dr\, d\theta$$ Anybody have a clue if/how I can find a closed form for the last integral? or perhaps that first integral, but I'd imagine it's harder from the cartesian perspective? Any help appreciated, Cheers :-)",,"['calculus', 'integration', 'multivariable-calculus', 'probability-distributions', 'gaussian-integral']"
98,Is there any way to Integrate this function?,Is there any way to Integrate this function?,,"After 2 change of variables, and a $x = \log(u)$ transformation, I have this integral... $$\int_0^{\infty } \frac{\alpha  e^x}{\lambda-e^x \lambda+e^{\alpha  x}} \, dx$$ What are some recommendations on how to integrate this? NOTE: The original integral looked like: $$\int_{1 }^{\infty } \frac{\alpha  \left(\frac{1 }{x}\right)^{\alpha }}{1-\lambda (x-1 ) \left(\frac{1 }{x}\right)^{\alpha }} \, dx$$ and for the integral to converge $\alpha > 1$. Finally, when $\alpha = 2$, I did get this expression... $$\frac{8 \tan ^{-1}\left(\frac{\sqrt{\lambda }}{\sqrt{4-\lambda }}\right)}{\sqrt{(4-\lambda ) \lambda }}$$ Thanks,","After 2 change of variables, and a $x = \log(u)$ transformation, I have this integral... $$\int_0^{\infty } \frac{\alpha  e^x}{\lambda-e^x \lambda+e^{\alpha  x}} \, dx$$ What are some recommendations on how to integrate this? NOTE: The original integral looked like: $$\int_{1 }^{\infty } \frac{\alpha  \left(\frac{1 }{x}\right)^{\alpha }}{1-\lambda (x-1 ) \left(\frac{1 }{x}\right)^{\alpha }} \, dx$$ and for the integral to converge $\alpha > 1$. Finally, when $\alpha = 2$, I did get this expression... $$\frac{8 \tan ^{-1}\left(\frac{\sqrt{\lambda }}{\sqrt{4-\lambda }}\right)}{\sqrt{(4-\lambda ) \lambda }}$$ Thanks,",,"['calculus', 'integration']"
99,Descartes rule of signs for Taylor Series.,Descartes rule of signs for Taylor Series.,,"Does descartes rule of signs for work with Taylor Series. For example, If we have $e^x-x$ then can we say because the Taylor series $1+\frac{x^2}{2}+\frac{x^3}{6}+\cdots$ does not have any sign changes then the equation has no positive roots?","Does descartes rule of signs for work with Taylor Series. For example, If we have $e^x-x$ then can we say because the Taylor series $1+\frac{x^2}{2}+\frac{x^3}{6}+\cdots$ does not have any sign changes then the equation has no positive roots?",,"['calculus', 'algebra-precalculus']"
