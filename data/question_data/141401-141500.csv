,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,How to prove that $\lim\limits_{x \to 0 }\;x^{-a}e^{\frac{-1}{x^{2}}} =0$ for all a?,How to prove that  for all a?,\lim\limits_{x \to 0 }\;x^{-a}e^{\frac{-1}{x^{2}}} =0,"I'd like your help with this: I tried using L'Hôpital's Rule and all kinds of arithmetic to prove that $$\lim_{x \to 0 }\left(x^{-a}e^{\left(\frac{-1}{x^{2}}\right)}\right) = 0$$ for every $a$, and it didn't work. ($a=0$ is trivial) Any hints? Thank you.","I'd like your help with this: I tried using L'Hôpital's Rule and all kinds of arithmetic to prove that $$\lim_{x \to 0 }\left(x^{-a}e^{\left(\frac{-1}{x^{2}}\right)}\right) = 0$$ for every $a$, and it didn't work. ($a=0$ is trivial) Any hints? Thank you.",,['calculus']
1,Evaluate $\lim\limits_{x\to\infty}x\!\left[2x\!-\!\left(x^3\!+\!x^2\!+\!x\right)^{\!\frac13}\!\!-\!\left(x^3\!-\!x^2\!+\!x\right)^{\!\frac13}\right]$ [closed],Evaluate  [closed],\lim\limits_{x\to\infty}x\!\left[2x\!-\!\left(x^3\!+\!x^2\!+\!x\right)^{\!\frac13}\!\!-\!\left(x^3\!-\!x^2\!+\!x\right)^{\!\frac13}\right],"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 25 days ago . The community reviewed whether to reopen this question 21 days ago and left it closed: Original close reason(s) were not resolved Improve this question Evaluate $\lim\limits_{x\to \infty}x\left[2x-\left(x^3+x^2+x\right)^{\frac{1}{3}}-\left(x^3-x^2+x\right)^{\frac{1}{3}}\right]$ My Approach: Formula I used $(1+x)^{n}=1+nx+\frac{n(n-1)}{2!}x^2+.....\infty$ where $x\in(-1,1)$ $\lim\limits_{x\to \infty}x\left[2x-x\left(1+\left(\frac{1}{x}+\frac{1}{x^2}\right)\right)^{\frac{1}{3}}-x\left(1+\left(\frac{-1}{x}+\frac{1}{x^2}\right)\right)^{\frac{1}{3}}\right]$ $\implies\lim\limits_{x\to \infty}x\left[2x-x\left(1+\left(\frac{1}{3x}+\frac{1}{3x^2}\right)\right)-x\left(1+\left(\frac{-1}{3x}+\frac{1}{3x^2}\right)\right)\right]$ $\implies\lim\limits_{x\to\infty}x\left(-\frac{2}{3x}\right)=-\frac{2}{3}$ But given answer is $\frac{2}{9}$ . I am attaching given solution below. Also I am attaching my two more solutions in Image formart.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 25 days ago . The community reviewed whether to reopen this question 21 days ago and left it closed: Original close reason(s) were not resolved Improve this question Evaluate My Approach: Formula I used where But given answer is . I am attaching given solution below. Also I am attaching my two more solutions in Image formart.","\lim\limits_{x\to \infty}x\left[2x-\left(x^3+x^2+x\right)^{\frac{1}{3}}-\left(x^3-x^2+x\right)^{\frac{1}{3}}\right] (1+x)^{n}=1+nx+\frac{n(n-1)}{2!}x^2+.....\infty x\in(-1,1) \lim\limits_{x\to \infty}x\left[2x-x\left(1+\left(\frac{1}{x}+\frac{1}{x^2}\right)\right)^{\frac{1}{3}}-x\left(1+\left(\frac{-1}{x}+\frac{1}{x^2}\right)\right)^{\frac{1}{3}}\right] \implies\lim\limits_{x\to \infty}x\left[2x-x\left(1+\left(\frac{1}{3x}+\frac{1}{3x^2}\right)\right)-x\left(1+\left(\frac{-1}{3x}+\frac{1}{3x^2}\right)\right)\right] \implies\lim\limits_{x\to\infty}x\left(-\frac{2}{3x}\right)=-\frac{2}{3} \frac{2}{9}","['calculus', 'limits', 'indeterminate-forms']"
2,Show that a continuous function zero for all rationals is zero everywhere. [duplicate],Show that a continuous function zero for all rationals is zero everywhere. [duplicate],,"This question already has answers here : Prove $f(x) = 0$ for all rational numbers implies $f(x)=0$ for all reals. (6 answers) Closed 1 year ago . Let $f: \mathbb{R} \to \mathbb{R}$ be continuous on $\mathbb{R}$ and that $f(r) = 0 \ \forall r \in \mathbb{Q}$ . Prove that $f(x) = 0 \ \forall x \in \mathbb{R}$ . I believe I have a proof of this, but I am hoping to confirm it because I found myself using the argument in other similar problems. I have: $\forall x \in \mathbb{R}, \forall \epsilon > 0, \exists \delta > 0$ s.t. whenever $y \in B_{\delta}(x), f(y) \in B_{\epsilon}(f(x))$ Since $\mathbb{Q}$ is dense in $\mathbb{R}$ , every ball around a rational contains irrationals. So, whenever $|r - y| < \delta, |f(r) - f(y)| = |f(y)| < \epsilon$ So, $f(y) = 0$ and $y$ is arbitrary. Take the union of all of the balls center at the rationals. This is open since the union of open balls is open. Since the rationals are dense, this union is equal to all of $\mathbb{R}$ . So, this holds $\forall y$ . Is this a possible argument? Thanks in advance!","This question already has answers here : Prove $f(x) = 0$ for all rational numbers implies $f(x)=0$ for all reals. (6 answers) Closed 1 year ago . Let be continuous on and that . Prove that . I believe I have a proof of this, but I am hoping to confirm it because I found myself using the argument in other similar problems. I have: s.t. whenever Since is dense in , every ball around a rational contains irrationals. So, whenever So, and is arbitrary. Take the union of all of the balls center at the rationals. This is open since the union of open balls is open. Since the rationals are dense, this union is equal to all of . So, this holds . Is this a possible argument? Thanks in advance!","f: \mathbb{R} \to \mathbb{R} \mathbb{R} f(r) = 0 \ \forall r \in \mathbb{Q} f(x) = 0 \ \forall x \in \mathbb{R} \forall x \in \mathbb{R}, \forall \epsilon > 0, \exists \delta > 0 y \in B_{\delta}(x), f(y) \in B_{\epsilon}(f(x)) \mathbb{Q} \mathbb{R} |r - y| < \delta, |f(r) - f(y)| = |f(y)| < \epsilon f(y) = 0 y \mathbb{R} \forall y","['real-analysis', 'limits', 'solution-verification', 'continuity']"
3,Limit Laws for Composite Functions,Limit Laws for Composite Functions,,"There are two rules I've seen for composite Limits. The first one is: If $f(x)$ is continuous at $x=b$ and $\newcommand{\limto}[2]{\lim\limits_{{#1}\to{#2}}}\limto xa g(x)=b$ then, $$\limto xa f(g(x))= f \left( \limto xa g(x)\right) = f(b).$$ The second one is: Assume that $g(x)$ and $f(x)$ are two functions. Assume that the domain of $g(x)$ contains an open interval containing $a$ , with exception of possibly $a$ , and that the domain of $f(x)$ contains an interval containing $b$ , with exception of possibly $b$ . Furthermore assume that for some number $L$ $$\limto xa g(x)=b \qquad\text{and}\qquad \limto yb f(y)=L.$$ Then $$\limto xa f\circ g(x) = \limto yb f(y) = L.$$ I was wondering if these are saying the same thing, with different variables, or if the 1st case is just a special case of the 2nd.  It seems to me like they have different conditions (continuity vs a limit existing). Is there a way to remember both of these in one rule?","There are two rules I've seen for composite Limits. The first one is: If is continuous at and then, The second one is: Assume that and are two functions. Assume that the domain of contains an open interval containing , with exception of possibly , and that the domain of contains an interval containing , with exception of possibly . Furthermore assume that for some number Then I was wondering if these are saying the same thing, with different variables, or if the 1st case is just a special case of the 2nd.  It seems to me like they have different conditions (continuity vs a limit existing). Is there a way to remember both of these in one rule?",f(x) x=b \newcommand{\limto}[2]{\lim\limits_{{#1}\to{#2}}}\limto xa g(x)=b \limto xa f(g(x))= f \left( \limto xa g(x)\right) = f(b). g(x) f(x) g(x) a a f(x) b b L \limto xa g(x)=b \qquad\text{and}\qquad \limto yb f(y)=L. \limto xa f\circ g(x) = \limto yb f(y) = L.,"['calculus', 'limits', 'functions', 'function-and-relation-composition']"
4,Difference between value of a function at a point and its limit at that point?,Difference between value of a function at a point and its limit at that point?,,"As a high school student,I understand the basic,theoretical difference between the two, as in, limit is what that function approaches as the input approaches something (but never equal to it) or how it behaves near that point etc etc. But sometimes it doesn't seem to make sense. Like Some textbooks, when evaluating certain simple limits like this: They just substitute the value 4 and evaluate it like this: But then how is it different than evaluating the function itself at that point? One can say that here the limit as well as the value at that point will be same, but I'm pointing out the method used here, SIMPLE SUBSTITUTION! Along with a better understanding of difference between the two, I would also like to understand what it means when both the value at that point and limit are defined but still they are different .Because I have been told that limits are used to evaluate undefined values/expressions like $\frac{0}{0}$ , $\infty / \infty$ , $0^{0}$ etc. For Ex- Both are well defined, still different.What does that difference mean in cases like these?","As a high school student,I understand the basic,theoretical difference between the two, as in, limit is what that function approaches as the input approaches something (but never equal to it) or how it behaves near that point etc etc. But sometimes it doesn't seem to make sense. Like Some textbooks, when evaluating certain simple limits like this: They just substitute the value 4 and evaluate it like this: But then how is it different than evaluating the function itself at that point? One can say that here the limit as well as the value at that point will be same, but I'm pointing out the method used here, SIMPLE SUBSTITUTION! Along with a better understanding of difference between the two, I would also like to understand what it means when both the value at that point and limit are defined but still they are different .Because I have been told that limits are used to evaluate undefined values/expressions like , , etc. For Ex- Both are well defined, still different.What does that difference mean in cases like these?",\frac{0}{0} \infty / \infty 0^{0},"['calculus', 'limits', 'continuity']"
5,"Calculus of $ \lim_{(x,y)\to (0,0)} \frac{8 x^2 y^3 }{x^9+y^3} $",Calculus of," \lim_{(x,y)\to (0,0)} \frac{8 x^2 y^3 }{x^9+y^3} ","By Wolfram Alpha I know that the limit $$    \lim_{(x,y)\to (0,0)} \dfrac{8 x^2 y^3 }{x^9+y^3}=0. $$ I have tried to prove that this limit is $0$ , by using polar coordinate, the AM–GM inequality and the change of variable $ x^9= r^2 \cos^2(t) $ and $y^3= r^2 \sin^2(t)$ , but these attempts were unsatisfactory. I also have reviewed the similar questions and their answers but there are difference between those functions and mine one, I think the principal difference is that the powers of the denominators are odd.","By Wolfram Alpha I know that the limit I have tried to prove that this limit is , by using polar coordinate, the AM–GM inequality and the change of variable and , but these attempts were unsatisfactory. I also have reviewed the similar questions and their answers but there are difference between those functions and mine one, I think the principal difference is that the powers of the denominators are odd.","
   \lim_{(x,y)\to (0,0)} \dfrac{8 x^2 y^3 }{x^9+y^3}=0.
 0  x^9= r^2 \cos^2(t)  y^3= r^2 \sin^2(t)","['real-analysis', 'limits', 'multivariable-calculus', 'rational-functions']"
6,Evaluating $\lim_{x \to \frac{\pi}{6}}{(1-2\sin(x))}^{\tan(\frac{\pi}{6}-x)}$,Evaluating,\lim_{x \to \frac{\pi}{6}}{(1-2\sin(x))}^{\tan(\frac{\pi}{6}-x)},"I'm in a little struggle with this limit, can anyone help me, please? $$\lim_{x \to \frac{\pi}{6}}{(1-2\sin(x))}^{\tan(\frac{\pi}{6}-x)}$$ I tried to use the logarithm to then use L'Hospital's rule but I got stuck here: $\ln(L)=\lim_{x \to \frac{\pi}{6}}{[\tan(\frac{\pi}{6}-x)\ln(1-2\sin(x))]}$ Thank you!","I'm in a little struggle with this limit, can anyone help me, please? I tried to use the logarithm to then use L'Hospital's rule but I got stuck here: Thank you!",\lim_{x \to \frac{\pi}{6}}{(1-2\sin(x))}^{\tan(\frac{\pi}{6}-x)} \ln(L)=\lim_{x \to \frac{\pi}{6}}{[\tan(\frac{\pi}{6}-x)\ln(1-2\sin(x))]},"['calculus', 'limits']"
7,About the limit $\mathop {\lim }\limits_{n \to \infty } \frac{1}{n \cdot \cos (n)} $,About the limit,\mathop {\lim }\limits_{n \to \infty } \frac{1}{n \cdot \cos (n)} ,"How do you prove that the limit $ \lim\limits_{n \to \infty } \frac{1}{n \cdot \cos (n)} $ does not exist? I tried using the fact that $ \{ \, \cos n \mid n \in \mathbb{N} \, \} $ is dense in $[0,1]$ , but all I get from this is that there is a subsequence $(y_n)$ of $(x_n)$ , $x_n=\frac{1}{n \cdot \cos (n)}$ such that $\lim\limits_{n \to \infty} y_n = 0$ . (Because we can choose $(y_n)$ such that $\lim\limits_{ n \to \infty} \cos (y_n) = 1 $ )","How do you prove that the limit does not exist? I tried using the fact that is dense in , but all I get from this is that there is a subsequence of , such that . (Because we can choose such that )"," \lim\limits_{n \to \infty } \frac{1}{n \cdot \cos (n)}   \{ \, \cos n \mid n \in \mathbb{N} \, \}  [0,1] (y_n) (x_n) x_n=\frac{1}{n \cdot \cos (n)} \lim\limits_{n \to \infty} y_n = 0 (y_n) \lim\limits_{ n \to \infty} \cos (y_n) = 1 ",['limits']
8,Understanding the definition of a limit point.,Understanding the definition of a limit point.,,"I am trying to understand the following definition of a limit point: A point $x$ is a limit point of a set $A$ if every $\epsilon$ -neighborhood $V_\epsilon(x)$ of $x$ intersects the set $A$ at some point other than $x$ . I am trying to understand what ""other than $x$ "" means. I know that a limit point $x$ need not be in $A$ . So, suppose we know somehow that $x \notin A$ . Then, would it be valid to modify the definition of a limit point as follows? A point $x$ is a limit point of a set $A$ if every $\epsilon$ -neighborhood $V_\epsilon(x)$ of $x$ intersects the set $A$ at some point in $A$ . EDIT : I found a different definition of a limit point: A point $x$ is a limit point of a set $A$ iff $x = \lim a_n$ for some $(a_n) \subseteq A$ satisfying $a_n \neq x$ $\forall n \in \mathbb{N}$ Does this definition fail when it comes to the sequence $(a, a, \dots)$ whose limit point clearly is $a$ ?","I am trying to understand the following definition of a limit point: A point is a limit point of a set if every -neighborhood of intersects the set at some point other than . I am trying to understand what ""other than "" means. I know that a limit point need not be in . So, suppose we know somehow that . Then, would it be valid to modify the definition of a limit point as follows? A point is a limit point of a set if every -neighborhood of intersects the set at some point in . EDIT : I found a different definition of a limit point: A point is a limit point of a set iff for some satisfying Does this definition fail when it comes to the sequence whose limit point clearly is ?","x A \epsilon V_\epsilon(x) x A x x x A x \notin A x A \epsilon V_\epsilon(x) x A A x A x = \lim a_n (a_n) \subseteq A a_n \neq x \forall n \in \mathbb{N} (a, a, \dots) a","['real-analysis', 'limits', 'definition']"
9,Compute $\lim \limits_{n\to \infty} \int_3^4 (-x^2+6x-8)^\frac{n}{2} dx$,Compute,\lim \limits_{n\to \infty} \int_3^4 (-x^2+6x-8)^\frac{n}{2} dx,"Compute $$\lim \limits_{n\to \infty} \int_3^4 (-x^2+6x-8)^\frac{n}{2}dx.$$ I am interested in a method to compute this as simply as possible. I know that by DCT this is $0$ , but I am not allowed to use it. With the substitution $t=x-3$ I got that this is $\int\limits_0^1 (1-t^2)^\frac{n}{2}dt$ and by using that $e^x\ge x+1, \forall x\in \mathbb{R}$ I could show that the limit is $0$ . This is anyway pretty complicated for the level of the exam where this was given, I would be interested in something even easier. Is it possible to write a recurrence relation for instance? EDIT: Based on Ian's answer I came up with the following solution and I would like to know whether it works: Let $\epsilon \in (0,1)$ and $I_n=\int_0^1 (1-t^2)^\frac{n}{2} dt$ . $$I_n=\int_0^{\epsilon}(1-t^2)^{\frac{n}{2}}dt+\int_{\epsilon}^{1}(1-t^2)^{\frac{n}{2}}dt\le \epsilon + (1-\epsilon^2)^\frac{n}{2}, \forall n\in \mathbb{N}$$ After we take the limit as $n\to \infty$ we get that $\lim\limits_{n\to\infty} I_n \le \epsilon, \forall \epsilon \in (0,1)$ and if we now let $\epsilon \searrow 0$ it follows that $\lim\limits_{n\to\infty} I_n \le0$ and since $I_n\ge 0$ we get that the limit is $0$ . I think this is basically what Ian did, but I would like to know whether it is correct to write it like this.","Compute I am interested in a method to compute this as simply as possible. I know that by DCT this is , but I am not allowed to use it. With the substitution I got that this is and by using that I could show that the limit is . This is anyway pretty complicated for the level of the exam where this was given, I would be interested in something even easier. Is it possible to write a recurrence relation for instance? EDIT: Based on Ian's answer I came up with the following solution and I would like to know whether it works: Let and . After we take the limit as we get that and if we now let it follows that and since we get that the limit is . I think this is basically what Ian did, but I would like to know whether it is correct to write it like this.","\lim \limits_{n\to \infty} \int_3^4 (-x^2+6x-8)^\frac{n}{2}dx. 0 t=x-3 \int\limits_0^1 (1-t^2)^\frac{n}{2}dt e^x\ge x+1, \forall x\in \mathbb{R} 0 \epsilon \in (0,1) I_n=\int_0^1 (1-t^2)^\frac{n}{2} dt I_n=\int_0^{\epsilon}(1-t^2)^{\frac{n}{2}}dt+\int_{\epsilon}^{1}(1-t^2)^{\frac{n}{2}}dt\le \epsilon + (1-\epsilon^2)^\frac{n}{2}, \forall n\in \mathbb{N} n\to \infty \lim\limits_{n\to\infty} I_n \le \epsilon, \forall \epsilon \in (0,1) \epsilon \searrow 0 \lim\limits_{n\to\infty} I_n \le0 I_n\ge 0 0","['real-analysis', 'calculus', 'limits', 'definite-integrals']"
10,Is 0 divided by a non-zero indeterminate equal to 0.,Is 0 divided by a non-zero indeterminate equal to 0.,,"Consider the following solution: $$ \lim\limits_{(x, y) \to (0, 0)} \dfrac{xy^4}{x^4+y^4}$$ Divide both numerator and denominator by $y^4$ $$ =  \lim\limits_{(x, y) \to (0, 0)} \dfrac{x}{\left(\dfrac{x}{y}\right)^4+1}$$ $$ =  \dfrac{ \lim\limits_{(x, y) \to (0, 0)}x}{ \lim\limits_{(x, y) \to (0, 0)}\left(\dfrac{x}{y}\right)^4+1}$$ The numerator is 0 and the denominator is non-zero, hence the limit is 0 ============================= Are you satisfied with this solution, if not, why? Edit: Thank You for the help guys. My mistake was looking at the final limit and not paying attention to how I got to that stage, ""by dividing both numerator and denominator by y^4"", that step itself is not allowed because y can be 0. The above solution will be complete if I include another case where $y=0$ , because when you divide by $y^4$ , you are implicitly stating that y is not 0.","Consider the following solution: Divide both numerator and denominator by The numerator is 0 and the denominator is non-zero, hence the limit is 0 ============================= Are you satisfied with this solution, if not, why? Edit: Thank You for the help guys. My mistake was looking at the final limit and not paying attention to how I got to that stage, ""by dividing both numerator and denominator by y^4"", that step itself is not allowed because y can be 0. The above solution will be complete if I include another case where , because when you divide by , you are implicitly stating that y is not 0."," \lim\limits_{(x, y) \to (0, 0)} \dfrac{xy^4}{x^4+y^4} y^4  =  \lim\limits_{(x, y) \to (0, 0)} \dfrac{x}{\left(\dfrac{x}{y}\right)^4+1}  =  \dfrac{ \lim\limits_{(x, y) \to (0, 0)}x}{ \lim\limits_{(x, y) \to (0, 0)}\left(\dfrac{x}{y}\right)^4+1} y=0 y^4","['limits', 'multivariable-calculus', 'proof-verification', 'limits-without-lhopital']"
11,Prove that $\limsup_{x\to\infty}\left(\cos x + \sin\left(\sqrt2 x\right)\right) = 2$,Prove that,\limsup_{x\to\infty}\left(\cos x + \sin\left(\sqrt2 x\right)\right) = 2,"Prove that $$ \limsup_{x\to\infty}\left(\cos x + \sin\left(\sqrt2 x\right)\right) = 2 $$ Pretty much always when I ask a question here I do provide some trials of mine to give some background. Unfortunately, this one is such a tough one for me that I don't even see a starting point. Here are some observations though. Let's denote the function under the limsup as $f(x)$ : $$ f(x) = \cos x + \sin\left(\sqrt2 x\right) $$ Since sin's argument contains an irrational multiplier the function itself is not periodic, perhaps this may be used somehow. I've tried assuming that there exists $x$ such that the equality holds, namely: $$ \cos x + \sin\left(\sqrt2 x\right) =2 $$ Unfortunately, I was not able to solve it for $x$ . I've then tried to use Mathematica for a numeric solution, but NSolve didn't output anything in Reals. The problem becomes even harder since there are some constraints on the tools to be used. It is given at the end of the chapter on ""Limit of a function"". Before the definition of derivatives, so the author assumes the statement might be proven using more or less elementary methods. Also, I was thinking that it could be possible to consider $f(n),\ n\in\Bbb N$ rather than $x\in\Bbb R$ and use the fact that $\sin(n)$ and $\cos(n)$ are dense in $[-1, 1]$ . But not sure how that may help. What would the argument be to prove the statement in the problem section?","Prove that Pretty much always when I ask a question here I do provide some trials of mine to give some background. Unfortunately, this one is such a tough one for me that I don't even see a starting point. Here are some observations though. Let's denote the function under the limsup as : Since sin's argument contains an irrational multiplier the function itself is not periodic, perhaps this may be used somehow. I've tried assuming that there exists such that the equality holds, namely: Unfortunately, I was not able to solve it for . I've then tried to use Mathematica for a numeric solution, but NSolve didn't output anything in Reals. The problem becomes even harder since there are some constraints on the tools to be used. It is given at the end of the chapter on ""Limit of a function"". Before the definition of derivatives, so the author assumes the statement might be proven using more or less elementary methods. Also, I was thinking that it could be possible to consider rather than and use the fact that and are dense in . But not sure how that may help. What would the argument be to prove the statement in the problem section?","
\limsup_{x\to\infty}\left(\cos x + \sin\left(\sqrt2 x\right)\right) = 2
 f(x) 
f(x) = \cos x + \sin\left(\sqrt2 x\right)
 x 
\cos x + \sin\left(\sqrt2 x\right) =2
 x f(n),\ n\in\Bbb N x\in\Bbb R \sin(n) \cos(n) [-1, 1]","['real-analysis', 'calculus', 'limits', 'trigonometry', 'limsup-and-liminf']"
12,"$\lim_{n\to\infty}\left(\sum_{k=0}^{n-1}(\zeta(2)-H_{k,2})-H_n\right)=1$",,"\lim_{n\to\infty}\left(\sum_{k=0}^{n-1}(\zeta(2)-H_{k,2})-H_n\right)=1","I found this limit in a book, without any explanation: $$\lim_{n\to\infty}\left(\sum_{k=0}^{n-1}(\zeta(2)-H_{k,2})-H_n\right)=1$$ where $H_{k,2}:=\sum_{j=1}^k\frac1{j^2}$ . However Im unable to find the value of this limit from myself. After some work I get the equivalent expression $$\lim_{n\to\infty}\sum_{k=0}^{n-1}\sum_{j=k}^\infty\frac1{(j+1)^2(j+2)}$$ but anyway Im stuck here. Can someone show me a way to compute this limit? Thank you. UPDATE: Wolfram Mathematica computed it value perfectly, so I guess there is some integral or algebraic identity from where to calculate it.","I found this limit in a book, without any explanation: where . However Im unable to find the value of this limit from myself. After some work I get the equivalent expression but anyway Im stuck here. Can someone show me a way to compute this limit? Thank you. UPDATE: Wolfram Mathematica computed it value perfectly, so I guess there is some integral or algebraic identity from where to calculate it.","\lim_{n\to\infty}\left(\sum_{k=0}^{n-1}(\zeta(2)-H_{k,2})-H_n\right)=1 H_{k,2}:=\sum_{j=1}^k\frac1{j^2} \lim_{n\to\infty}\sum_{k=0}^{n-1}\sum_{j=k}^\infty\frac1{(j+1)^2(j+2)}","['calculus', 'limits', 'special-functions']"
13,Finding value of $\lim\limits_{n\rightarrow \infty}\Big(\frac{(kn)!}{n^{kn}}\Big)^{\frac{1}{n}}$,Finding value of,\lim\limits_{n\rightarrow \infty}\Big(\frac{(kn)!}{n^{kn}}\Big)^{\frac{1}{n}},Finding value of $\displaystyle \lim_{n\rightarrow \infty}\bigg(\frac{(kn)!}{n^{kn}}\bigg)^{\frac{1}{n}}$ for all $k>1$ Try: I have solved it using stirling Approximation $\displaystyle n!\approx \bigg(\frac{n}{e}\bigg)^n\sqrt{2\pi n}$ for laege $n$ So we have $\displaystyle \lim_{n\rightarrow \infty}\bigg(\frac{kn}{e}\bigg)^{kn}\cdot \bigg(\sqrt{2\pi k n}\bigg)^{\frac{1}{n}}\cdot \frac{1}{n^k}=\bigg(\frac{k}{e}\bigg)^k$ Could some help me how to solve it without stirling Approximation Thanks.,Finding value of $\displaystyle \lim_{n\rightarrow \infty}\bigg(\frac{(kn)!}{n^{kn}}\bigg)^{\frac{1}{n}}$ for all $k>1$ Try: I have solved it using stirling Approximation $\displaystyle n!\approx \bigg(\frac{n}{e}\bigg)^n\sqrt{2\pi n}$ for laege $n$ So we have $\displaystyle \lim_{n\rightarrow \infty}\bigg(\frac{kn}{e}\bigg)^{kn}\cdot \bigg(\sqrt{2\pi k n}\bigg)^{\frac{1}{n}}\cdot \frac{1}{n^k}=\bigg(\frac{k}{e}\bigg)^k$ Could some help me how to solve it without stirling Approximation Thanks.,,"['calculus', 'limits', 'factorial', 'radical-equations']"
14,Limit of $n \left(\frac{1}{2}-e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right)$,Limit of,n \left(\frac{1}{2}-e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right),"It is known around here that $$\lim_{n\to\infty }e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)=\frac12$$ So what about the following limit: $$L=\lim_{n \to \infty}n \left(\frac{1}{2}-\frac{1}{e^n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right)$$ My thought was to apply Stolz-Cesaro theorem, after rewritting as $$L=\lim_{n \to \infty}\frac{ \left(\frac{1}{2}-\frac{1}{e^n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right)}{\frac1n}$$ would produce: $$L=\lim_{n \to \infty}\frac{e^{-(n+1)}\left(1+(n+1)+\frac{(n+1)^2}{2!}+...+\frac{(n+1)^{n+1}}{(n+1)!}\right)-e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)}{\frac1{n(n+1)}}$$ $$=\lim_{n \to \infty}\frac{e^{-n}\left(\frac{1-e}{e} +\frac1e\frac{(n+1)^{n+1}}{(n+1)!} +n\left(\frac{\left(1+\frac1n\right)}{e}-1\right) +\frac{n^2}{2!}\left(\frac{\left(1+\frac1n\right)^2}{e}-1\right)+\cdots +\frac{n^n}{n!}\left(\frac{\left(1+\frac1n\right)^n}{e}-1\right)\right)}{\frac1{n(n+1)}}$$ But I dont see how can I go further, can you help me evaluate it? Also, are limits of this form already known?","It is known around here that $$\lim_{n\to\infty }e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)=\frac12$$ So what about the following limit: $$L=\lim_{n \to \infty}n \left(\frac{1}{2}-\frac{1}{e^n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right)$$ My thought was to apply Stolz-Cesaro theorem, after rewritting as $$L=\lim_{n \to \infty}\frac{ \left(\frac{1}{2}-\frac{1}{e^n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)\right)}{\frac1n}$$ would produce: $$L=\lim_{n \to \infty}\frac{e^{-(n+1)}\left(1+(n+1)+\frac{(n+1)^2}{2!}+...+\frac{(n+1)^{n+1}}{(n+1)!}\right)-e^{-n}\left(1+n+\frac{n^2}{2!}+...+\frac{n^n}{n!}\right)}{\frac1{n(n+1)}}$$ $$=\lim_{n \to \infty}\frac{e^{-n}\left(\frac{1-e}{e} +\frac1e\frac{(n+1)^{n+1}}{(n+1)!} +n\left(\frac{\left(1+\frac1n\right)}{e}-1\right) +\frac{n^2}{2!}\left(\frac{\left(1+\frac1n\right)^2}{e}-1\right)+\cdots +\frac{n^n}{n!}\left(\frac{\left(1+\frac1n\right)^n}{e}-1\right)\right)}{\frac1{n(n+1)}}$$ But I dont see how can I go further, can you help me evaluate it? Also, are limits of this form already known?",,"['limits', 'exponential-function']"
15,Show that the $\lim \inf a_n = \lim \sup a_n$ if and only if $\lim a_n$ exists.,Show that the  if and only if  exists.,\lim \inf a_n = \lim \sup a_n \lim a_n,Show that the $\lim \inf a_n = \lim \sup a_n$ if and only if $\lim a_n$ exists. Attempt at proof. ($ \Rightarrow $) Assume $\lim \inf a_n = \lim \sup a_n= L$. Then we have $|\sup a_n -L| \lt \epsilon$ and $|\inf a_n - L| \lt \epsilon$ and thus $$L-\epsilon \lt \sup a_n \lt \epsilon +L $$ and $$L -\epsilon \lt \inf a_n \lt L + \epsilon$$ and since $\inf a_n \le a_n\le \sup a_n$ it follows that $L- \epsilon \lt a_n\lt L + \epsilon$  i.e. $\lim a_n =L$ ($\Leftarrow$) Let $\lim a_n = L$. Assume that $\lim \inf a_n \neq \lim \sup a_n$  Choose $N_0$ such that $n \ge N_0$ implies $|a_n- L| \lt \epsilon = \frac{\sup a_n- \inf a_n}{2}$ Then we see that $$|\sup a_n - a_n| \le |a_n- L| \lt  \frac{\sup a_n- \inf a_n}{2}$$ and  $$|\inf a_n - a_n| \le |a_n- L| \lt  \frac{\sup a_n- \inf a_n}{2}$$ By the Triangle Inequality we have $$|\sup a_n- \inf a_n| \lt |\sup a_n - a_n| + |a_n - \inf a_n| \lt 2\frac {\sup a_n- \inf a_n}{2}$$ which is a contradiction. Can you please provide the correct proof. I'm pretty sure the second direction is incorrect. I am having a hard time showing that $|\sup a_n - a_n| \le |a_n- L|$ and that $|\inf a_n - a_n| \le |a_n- L|$ could be true. Thanks in advance.,Show that the $\lim \inf a_n = \lim \sup a_n$ if and only if $\lim a_n$ exists. Attempt at proof. ($ \Rightarrow $) Assume $\lim \inf a_n = \lim \sup a_n= L$. Then we have $|\sup a_n -L| \lt \epsilon$ and $|\inf a_n - L| \lt \epsilon$ and thus $$L-\epsilon \lt \sup a_n \lt \epsilon +L $$ and $$L -\epsilon \lt \inf a_n \lt L + \epsilon$$ and since $\inf a_n \le a_n\le \sup a_n$ it follows that $L- \epsilon \lt a_n\lt L + \epsilon$  i.e. $\lim a_n =L$ ($\Leftarrow$) Let $\lim a_n = L$. Assume that $\lim \inf a_n \neq \lim \sup a_n$  Choose $N_0$ such that $n \ge N_0$ implies $|a_n- L| \lt \epsilon = \frac{\sup a_n- \inf a_n}{2}$ Then we see that $$|\sup a_n - a_n| \le |a_n- L| \lt  \frac{\sup a_n- \inf a_n}{2}$$ and  $$|\inf a_n - a_n| \le |a_n- L| \lt  \frac{\sup a_n- \inf a_n}{2}$$ By the Triangle Inequality we have $$|\sup a_n- \inf a_n| \lt |\sup a_n - a_n| + |a_n - \inf a_n| \lt 2\frac {\sup a_n- \inf a_n}{2}$$ which is a contradiction. Can you please provide the correct proof. I'm pretty sure the second direction is incorrect. I am having a hard time showing that $|\sup a_n - a_n| \le |a_n- L|$ and that $|\inf a_n - a_n| \le |a_n- L|$ could be true. Thanks in advance.,,"['real-analysis', 'limits', 'proof-verification', 'real-numbers', 'epsilon-delta']"
16,Is there another proof for Euler–Mascheroni Constant?,Is there another proof for Euler–Mascheroni Constant?,,"Problem Prove that the sequence $$x_n=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}-\ln n,~~~(n=1,2,\cdots)$$ is convergent. One Proof This proof is based on the following inequality $$\frac{1}{n+1}<\ln \left(1+\frac{1}{n}\right)<\frac{1}{n}$$ where $n=1,2,\cdots$ , which will be used repeatedly. On one hand, we obtain that $$\ln 2-\ln 1<1,~~\ln 3-\ln 2<\frac{1}{2},~~\ln 4-\ln 3<\frac{1}{3},~~\cdots,~~\ln (n+1)-\ln n<\frac{1}{n}.$$ Adding up all of these，we have that $\ln(n+1)<1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}.$ Hence, $$x_{n+1}=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}+\frac{1}{n+1}-\ln(n+1)>\frac{1}{n+1}>0.$$ This shows that $x_n$ is bounded below. On the other hand, $$x_n-x_{n+1}=-\frac{1}{n+1}+\ln(n+1)-\ln n=\ln \left(1+\frac{1}{n}\right)-\frac{1}{n+1}>0.$$ This shows that $x_n$ is decreasing. Combining the two aspects, according to Monotone Bounded Theorem, we can assert that $\lim\limits_{n \to \infty}x_n$ exists. Let $\gamma$ (so-called Euler–Mascheroni Constant ) denote the limit, i.e. $$\gamma=\lim_{n \to \infty}\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}-\ln n\right),$$ which equals $0.577216 \cdots$ . We may also express that as $$1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}=\gamma+\ln n+\varepsilon_n,$$ where $\varepsilon_n$ represents an infinitesimal related to $n$ under the process $n \to \infty$ .","Problem Prove that the sequence is convergent. One Proof This proof is based on the following inequality where , which will be used repeatedly. On one hand, we obtain that Adding up all of these，we have that Hence, This shows that is bounded below. On the other hand, This shows that is decreasing. Combining the two aspects, according to Monotone Bounded Theorem, we can assert that exists. Let (so-called Euler–Mascheroni Constant ) denote the limit, i.e. which equals . We may also express that as where represents an infinitesimal related to under the process .","x_n=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}-\ln n,~~~(n=1,2,\cdots) \frac{1}{n+1}<\ln \left(1+\frac{1}{n}\right)<\frac{1}{n} n=1,2,\cdots \ln 2-\ln 1<1,~~\ln 3-\ln 2<\frac{1}{2},~~\ln 4-\ln 3<\frac{1}{3},~~\cdots,~~\ln (n+1)-\ln n<\frac{1}{n}. \ln(n+1)<1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}. x_{n+1}=1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}+\frac{1}{n+1}-\ln(n+1)>\frac{1}{n+1}>0. x_n x_n-x_{n+1}=-\frac{1}{n+1}+\ln(n+1)-\ln n=\ln \left(1+\frac{1}{n}\right)-\frac{1}{n+1}>0. x_n \lim\limits_{n \to \infty}x_n \gamma \gamma=\lim_{n \to \infty}\left(1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}-\ln n\right), 0.577216 \cdots 1+\frac{1}{2}+\frac{1}{3}+\cdots+\frac{1}{n}=\gamma+\ln n+\varepsilon_n, \varepsilon_n n n \to \infty","['limits', 'euler-mascheroni-constant']"
17,Find the limit of some roots raised to n,Find the limit of some roots raised to n,,"let $x_1,x_2,x_3$ be the roots of $x^3-x^2-1=0$. If $x_1$ is a real root of the equation, compute: $\lim_{n\to\infty}(x_2^n+x_3^n).$ First I find these relations using viete: $x_1+x_2+x_3=1$ $x_1^2+x_2^2+x_3^2=1$ $x_1^3+x_2^3+x_3^3=4$ Now, we can find a recurrence of the other sum of roots using the inial equation and we get this sequence: $$a_n=a_{n-1}+a_{n-3}$$ where $$a_1=1, a_2=1, a_3=4$$ And I tried something like this to try and solve this problem but couldn't work it out until the end... I'm actually stuck here.","let $x_1,x_2,x_3$ be the roots of $x^3-x^2-1=0$. If $x_1$ is a real root of the equation, compute: $\lim_{n\to\infty}(x_2^n+x_3^n).$ First I find these relations using viete: $x_1+x_2+x_3=1$ $x_1^2+x_2^2+x_3^2=1$ $x_1^3+x_2^3+x_3^3=4$ Now, we can find a recurrence of the other sum of roots using the inial equation and we get this sequence: $$a_n=a_{n-1}+a_{n-3}$$ where $$a_1=1, a_2=1, a_3=4$$ And I tried something like this to try and solve this problem but couldn't work it out until the end... I'm actually stuck here.",,"['real-analysis', 'limits', 'polynomials']"
18,Improper integrals: is it possible to have a non bounded function such that its improper integral converges?,Improper integrals: is it possible to have a non bounded function such that its improper integral converges?,,"Find an example of a non-negative function $(f\geq 0)$ which is continuous and such that $\int_{0}^{\infty}f(x)dx$ is finite ($\int f < \infty$) but $\lim_{x\rightarrow\infty}f(x)$ does not exist. Also, is it possible that $\int_{0}^{\infty}f(x)\,dx$ exist but $f(x)$ is not bounded?","Find an example of a non-negative function $(f\geq 0)$ which is continuous and such that $\int_{0}^{\infty}f(x)dx$ is finite ($\int f < \infty$) but $\lim_{x\rightarrow\infty}f(x)$ does not exist. Also, is it possible that $\int_{0}^{\infty}f(x)\,dx$ exist but $f(x)$ is not bounded?",,"['limits', 'convergence-divergence', 'improper-integrals']"
19,"Does $\frac{(x^2 + y^2) y}{x}$ have a limit at $(0,0)$?",Does  have a limit at ?,"\frac{(x^2 + y^2) y}{x} (0,0)","Does $\frac{(x^2 + y^2) y}{x}$ have a limit at $(0,0)$? Recently, someone asked whether a function from $\mathbb{R}^2$ to $\mathbb{R}$ had a limit at $(0,0)$.  The question was easy and answered in the negative by showing that approaching $(0,0)$ on different lines led to different limits. This prompted a question: is there such a function which has a limit when restricted to any straight line through $(0,0)$ and the limit is the same in all cases yet the function does not have a limit at $(0,0)$? This led me to consider this function: $$   f(x, y) = \begin{cases} \frac{(x^2 + y^2) y}{x},  & \text{if $x \neq 0$} \\ 0, & \text{if $x = 0$} \end{cases} $$ This looks a bit nicer in polar coordinates with $x = r \sin \theta$ and $y = r \cos \theta$ $$   f(x, y) = \begin{cases} r^2 \tan \theta,  & \text{if $\theta \neq \pm \frac{\pi}{2} $} \\ 0, & \text{if $\theta = \pm \frac{\pi}{2} $} \end{cases} $$ So, if the function is restricted to a straight line through $(0,0)$ then the function clearly has the limit $0$ since $\tan \theta$ will be a constant. However, it is not continuous at $(0,0)$ as within any radius of $(0,0)$, it takes arbitrarily large values. So, here is my question: is the above right or have I made a mistake?  (I am rather rusty in this area.) Additional clarification I know that I don't need to restrict myself to straight lines when testing limits.  In fact, that was the point of the exercise: to show that straight lines may disprove a limit but testing only straight lines will not prove a limit.  I wanted an example that had a limit along all straight lines yet still failed to have a limit. Simpler examples that demonstrate this would be welcome.","Does $\frac{(x^2 + y^2) y}{x}$ have a limit at $(0,0)$? Recently, someone asked whether a function from $\mathbb{R}^2$ to $\mathbb{R}$ had a limit at $(0,0)$.  The question was easy and answered in the negative by showing that approaching $(0,0)$ on different lines led to different limits. This prompted a question: is there such a function which has a limit when restricted to any straight line through $(0,0)$ and the limit is the same in all cases yet the function does not have a limit at $(0,0)$? This led me to consider this function: $$   f(x, y) = \begin{cases} \frac{(x^2 + y^2) y}{x},  & \text{if $x \neq 0$} \\ 0, & \text{if $x = 0$} \end{cases} $$ This looks a bit nicer in polar coordinates with $x = r \sin \theta$ and $y = r \cos \theta$ $$   f(x, y) = \begin{cases} r^2 \tan \theta,  & \text{if $\theta \neq \pm \frac{\pi}{2} $} \\ 0, & \text{if $\theta = \pm \frac{\pi}{2} $} \end{cases} $$ So, if the function is restricted to a straight line through $(0,0)$ then the function clearly has the limit $0$ since $\tan \theta$ will be a constant. However, it is not continuous at $(0,0)$ as within any radius of $(0,0)$, it takes arbitrarily large values. So, here is my question: is the above right or have I made a mistake?  (I am rather rusty in this area.) Additional clarification I know that I don't need to restrict myself to straight lines when testing limits.  In fact, that was the point of the exercise: to show that straight lines may disprove a limit but testing only straight lines will not prove a limit.  I wanted an example that had a limit along all straight lines yet still failed to have a limit. Simpler examples that demonstrate this would be welcome.",,['limits']
20,Suppose $f$ is continuous on R such that $\lim_{h\to 0} \frac{f(x+h)-f(x-h)}{h} = 0$ for all $x\in\mathbb R$. Prove that $f$ is constant. [duplicate],Suppose  is continuous on R such that  for all . Prove that  is constant. [duplicate],f \lim_{h\to 0} \frac{f(x+h)-f(x-h)}{h} = 0 x\in\mathbb R f,"This question already has an answer here : Are constants the only continuous functions with ""symmetric derivative"" zero? (1 answer) Closed 6 years ago . I'm having a bit of trouble with the title problem out of Davidson and Donsig's Real Analysis. I'll state it again: Suppose $f$ is continuous on $\mathbb{R}$ such that $$\lim_{h\to 0} \frac{f(x+h)-f(x-h)}{h} = 0\  \forall x\in\mathbb{R}.$$ Prove that $f$ is constant. They provide the following hint which I have been trying to apply. HINT: Fix $\epsilon > 0$. For each $x$, find a $\delta > 0$ so that $|f(x+h)-f(x-h)| \leq \epsilon h$ for $0\leq h \leq \delta$. Let $\Delta$ be the supremum of all such $\delta$. Show that $\Delta = \infty$. Here's how I've started. Fix $\epsilon > 0,\ x\in\mathbb{R}$. By the definition of the limit,  $$(\forall x\in\mathbb{R})(\forall\epsilon>0)(\exists\delta>0)(0<|h|\leq\delta\implies\Bigg|\frac{f(x+h)-f(x-h)}{h}\Bigg|<\epsilon).$$ Therefore, we immediately get a $\delta>0$ for our $x,\epsilon$ such that $$|f(x+h)-f(x-h)|\leq\epsilon h,\ 0\leq h \leq\delta.$$ I don't know how to proceed from here. I'm not even sure conceptually how showing that $\Delta=\infty$ would give us that $f$ is constant. Any help would be appreciated!","This question already has an answer here : Are constants the only continuous functions with ""symmetric derivative"" zero? (1 answer) Closed 6 years ago . I'm having a bit of trouble with the title problem out of Davidson and Donsig's Real Analysis. I'll state it again: Suppose $f$ is continuous on $\mathbb{R}$ such that $$\lim_{h\to 0} \frac{f(x+h)-f(x-h)}{h} = 0\  \forall x\in\mathbb{R}.$$ Prove that $f$ is constant. They provide the following hint which I have been trying to apply. HINT: Fix $\epsilon > 0$. For each $x$, find a $\delta > 0$ so that $|f(x+h)-f(x-h)| \leq \epsilon h$ for $0\leq h \leq \delta$. Let $\Delta$ be the supremum of all such $\delta$. Show that $\Delta = \infty$. Here's how I've started. Fix $\epsilon > 0,\ x\in\mathbb{R}$. By the definition of the limit,  $$(\forall x\in\mathbb{R})(\forall\epsilon>0)(\exists\delta>0)(0<|h|\leq\delta\implies\Bigg|\frac{f(x+h)-f(x-h)}{h}\Bigg|<\epsilon).$$ Therefore, we immediately get a $\delta>0$ for our $x,\epsilon$ such that $$|f(x+h)-f(x-h)|\leq\epsilon h,\ 0\leq h \leq\delta.$$ I don't know how to proceed from here. I'm not even sure conceptually how showing that $\Delta=\infty$ would give us that $f$ is constant. Any help would be appreciated!",,"['real-analysis', 'limits', 'continuity']"
21,Finding the limit as $x$ approaches $0$,Finding the limit as  approaches,x 0,"I was shown the above problem in my calculus class today.  It seems that one can solve the limit in white by realizing that it mirrors the limit in yellow. However, I don't understand what the exact relationship between those two limits is. My TA went over it rather quickly. Can someone explain what point he was trying to make?","I was shown the above problem in my calculus class today.  It seems that one can solve the limit in white by realizing that it mirrors the limit in yellow. However, I don't understand what the exact relationship between those two limits is. My TA went over it rather quickly. Can someone explain what point he was trying to make?",,"['calculus', 'limits']"
22,How to calculate $\lim_{x\to\infty}\frac{7x^4+x^2 3^x+2}{x^3+x 4^x+1}$?,How to calculate ?,\lim_{x\to\infty}\frac{7x^4+x^2 3^x+2}{x^3+x 4^x+1},$$\lim_{x\to\infty}\frac{7x^4+x^2 3^x+2}{x^3+x 4^x+1}$$ I can't  seem to find away to get rid of the $3^x$ and $4^x$ and then resolve it.,$$\lim_{x\to\infty}\frac{7x^4+x^2 3^x+2}{x^3+x 4^x+1}$$ I can't  seem to find away to get rid of the $3^x$ and $4^x$ and then resolve it.,,"['calculus', 'limits']"
23,$\lim_{|x|\rightarrow\infty}(f\cdot g)(x)=0$,,\lim_{|x|\rightarrow\infty}(f\cdot g)(x)=0,"suppose $f,g\in L^1(\mathbb{R}^d)$ and $g$ bounded. then $\lim_\limits{{|x|\to\infty}}(f\cdot g)(x)=0$? since $|(f\cdot g)(x)|=|\int_{\mathbb{R}^d}f(x-y)\,g(y)\,dy|\leq ||g||_\infty\int_{\mathbb{R}^d}|f(x-y)|\,dy=||g||_\infty||f||_1<\infty$, at least the limit is bounded. I guess I need to know if $\int_{\mathbb{R}^d}|f(x-y)|\,dy$ goes to $0$ as $|x|\rightarrow \infty$, but I got nothing until now. if $x$ moves finite distance, then the integral won't change. would it be different near $\infty$?","suppose $f,g\in L^1(\mathbb{R}^d)$ and $g$ bounded. then $\lim_\limits{{|x|\to\infty}}(f\cdot g)(x)=0$? since $|(f\cdot g)(x)|=|\int_{\mathbb{R}^d}f(x-y)\,g(y)\,dy|\leq ||g||_\infty\int_{\mathbb{R}^d}|f(x-y)|\,dy=||g||_\infty||f||_1<\infty$, at least the limit is bounded. I guess I need to know if $\int_{\mathbb{R}^d}|f(x-y)|\,dy$ goes to $0$ as $|x|\rightarrow \infty$, but I got nothing until now. if $x$ moves finite distance, then the integral won't change. would it be different near $\infty$?",,"['calculus', 'real-analysis', 'limits', 'measure-theory', 'convolution']"
24,Show that $\lim_{x \rightarrow \infty} f(x)$ exists by the given condition.,Show that  exists by the given condition.,\lim_{x \rightarrow \infty} f(x),Suppose $f$ is a twice differentiable function such that $f''(x) \ge 0$ for all $x \in \mathbb R$. Let $0 \le f(x) \le 1$ for $x \ge 0$. Then show that $\lim_{x \rightarrow \infty} f(x)$ exists. I have tried it but I fail. Please give me some hint to proceed in the right way. Thank you in advance.,Suppose $f$ is a twice differentiable function such that $f''(x) \ge 0$ for all $x \in \mathbb R$. Let $0 \le f(x) \le 1$ for $x \ge 0$. Then show that $\lim_{x \rightarrow \infty} f(x)$ exists. I have tried it but I fail. Please give me some hint to proceed in the right way. Thank you in advance.,,"['real-analysis', 'limits', 'derivatives', 'proof-writing']"
25,Show that $\lim_{n\rightarrow\infty}\int_{0}^{\infty}\frac{x^{\frac{1}{n}}}{(1+\frac{x}{n})^{n}}dx=1.$,Show that,\lim_{n\rightarrow\infty}\int_{0}^{\infty}\frac{x^{\frac{1}{n}}}{(1+\frac{x}{n})^{n}}dx=1.,"Show that  $$\lim_{n\rightarrow\infty}\int_{0}^{\infty}\frac{x^{\frac{1}{n}}}{(1+\frac{x}{n})^{n}}dx=1.$$ Remark: I must accept that I have a conflict when I am faced with a situation where I must know the relationship between Integrals of Riemann and Integrals of Lebesgue, the conflict is stronger when integrals are improper. Most books address this relationship for integrals over intervals of the form $ [a, b] $, but very few address improper integrals. I would like to know the proof of the problem that I have proposed and that someone recommend me books where they propose exercises similar to the one I have proposed here.","Show that  $$\lim_{n\rightarrow\infty}\int_{0}^{\infty}\frac{x^{\frac{1}{n}}}{(1+\frac{x}{n})^{n}}dx=1.$$ Remark: I must accept that I have a conflict when I am faced with a situation where I must know the relationship between Integrals of Riemann and Integrals of Lebesgue, the conflict is stronger when integrals are improper. Most books address this relationship for integrals over intervals of the form $ [a, b] $, but very few address improper integrals. I would like to know the proof of the problem that I have proposed and that someone recommend me books where they propose exercises similar to the one I have proposed here.",,"['limits', 'measure-theory', 'improper-integrals', 'lebesgue-integral']"
26,Does $\lim f(x) = \frac{1}{\lim\frac{1}{f(x)}}$?,Does ?,\lim f(x) = \frac{1}{\lim\frac{1}{f(x)}},"I was trying to find $\lim_{z\rightarrow{0}} \frac{z^2}{\cos(z)-1}$ and the solution guide just told me to do $\lim_{z\rightarrow{0}} \frac{\cos(z)-1}{z^2} = -\frac{1}{2}$  and then take the reciprocal of this, which is $-2$ as my answer. Can we actually do that? Does this actually obey the limit laws?","I was trying to find $\lim_{z\rightarrow{0}} \frac{z^2}{\cos(z)-1}$ and the solution guide just told me to do $\lim_{z\rightarrow{0}} \frac{\cos(z)-1}{z^2} = -\frac{1}{2}$  and then take the reciprocal of this, which is $-2$ as my answer. Can we actually do that? Does this actually obey the limit laws?",,"['calculus', 'limits']"
27,Prove that $\lim_{x \to2 }x^{2}+4x=12$,Prove that,\lim_{x \to2 }x^{2}+4x=12,"Please check my prove we begin by $$x^{2}+4x-12<\epsilon $$ $$|x+6||x-2|<\epsilon $$ I will prove by use property  $\lim_{x->n}f(x)g(x)=\lim_{x->n}f(x)\lim_{x->n}g(x)$ then we divide into to case $|x+6|<\sqrt{\epsilon }$ and $ |x-2|<\sqrt{\epsilon }$ and let$\epsilon ,\delta _{1}\delta _{2}>0$ $$0<|x-2|<\delta _{1}\rightarrow |x+6|<\sqrt{\epsilon }$$ Choose $\delta _{1}=\sqrt{\epsilon }$ then $|x+6|<\sqrt{\epsilon }$ $$0<|x-2|<\delta _{2}\rightarrow |x-2|<\sqrt{\epsilon }$$ Choose $\delta _{1}=\sqrt{\epsilon }$ then $|x+6|<\sqrt{\epsilon }$ then use property $\lim_{x->n}f(x)g(x)=\lim_{x->n}f(x)\lim_{x->n}g(x)$ we get $$|x+6||x-2|<\sqrt{\epsilon }\sqrt{\epsilon }$$ then $\lim_{x->2}x^{2}+4x=12$","Please check my prove we begin by $$x^{2}+4x-12<\epsilon $$ $$|x+6||x-2|<\epsilon $$ I will prove by use property  $\lim_{x->n}f(x)g(x)=\lim_{x->n}f(x)\lim_{x->n}g(x)$ then we divide into to case $|x+6|<\sqrt{\epsilon }$ and $ |x-2|<\sqrt{\epsilon }$ and let$\epsilon ,\delta _{1}\delta _{2}>0$ $$0<|x-2|<\delta _{1}\rightarrow |x+6|<\sqrt{\epsilon }$$ Choose $\delta _{1}=\sqrt{\epsilon }$ then $|x+6|<\sqrt{\epsilon }$ $$0<|x-2|<\delta _{2}\rightarrow |x-2|<\sqrt{\epsilon }$$ Choose $\delta _{1}=\sqrt{\epsilon }$ then $|x+6|<\sqrt{\epsilon }$ then use property $\lim_{x->n}f(x)g(x)=\lim_{x->n}f(x)\lim_{x->n}g(x)$ we get $$|x+6||x-2|<\sqrt{\epsilon }\sqrt{\epsilon }$$ then $\lim_{x->2}x^{2}+4x=12$",,"['real-analysis', 'limits', 'proof-verification']"
28,Solving $\lim_{ x \to 0^+} \sqrt{\tan x}^{\sqrt{x}}$,Solving,\lim_{ x \to 0^+} \sqrt{\tan x}^{\sqrt{x}},"The limit to be calculated is: $$\lim_{x \to 0^+}\sqrt{\tan x}^{\sqrt{x}}$$ I tried: $$L =\lim_{x \to 0^+}\sqrt{\tan x}^{\sqrt{x}}$$ $$\log L = \lim _{x\to 0^+} \ \ \dfrac{1}{2}\cdot\dfrac{\sqrt{x}}{\frac{1}{\log(\tan x)}}$$ To apply the L'hospital theorem but failed, as it went more complex. How can we solve this, with or without L'Hospital?","The limit to be calculated is: $$\lim_{x \to 0^+}\sqrt{\tan x}^{\sqrt{x}}$$ I tried: $$L =\lim_{x \to 0^+}\sqrt{\tan x}^{\sqrt{x}}$$ $$\log L = \lim _{x\to 0^+} \ \ \dfrac{1}{2}\cdot\dfrac{\sqrt{x}}{\frac{1}{\log(\tan x)}}$$ To apply the L'hospital theorem but failed, as it went more complex. How can we solve this, with or without L'Hospital?",,"['calculus', 'limits', 'indeterminate-forms']"
29,Proof: $\lim\limits_{n\to\infty}\frac{\sqrt[n]{n!}}{n}=e^{-1}$,Proof:,\lim\limits_{n\to\infty}\frac{\sqrt[n]{n!}}{n}=e^{-1},Prove that $\displaystyle\lim_{n\to\infty}\frac{\sqrt[n]{n!}}{n}=e^{-1}$ . Here's my solution: Stirling's formula tells us $$\lim_{n\to\infty}\frac{n!}{n^ne^{-n}\sqrt{2\pi n}}=1$$ which implies $$\lim_{n\to\infty}\sqrt[n]{\frac{n!}{n^ne^{-n}\sqrt{2\pi n}}}=1$$ then simplifying the left side we have $$\lim_{n\to\infty}\sqrt[n]{\frac{n!}{n^n}}\lim_{n\to\infty}\sqrt[n]{e^{n}}\lim_{n\to\infty}\frac{1}{\sqrt[2n]{2\pi n}}=e\lim_{n\to\infty}\frac{\sqrt[n]{n!}}{n}=1$$ since $\lim_{n\to\infty}\sqrt[2n]{2\pi n}=1$ . Divide both sides by $e$ and we're done. Is this correct? This is a problem from Problems in Real Analysis by Radulescu and Andreescu. The book gives two other proofs. Thanks!,Prove that . Here's my solution: Stirling's formula tells us which implies then simplifying the left side we have since . Divide both sides by and we're done. Is this correct? This is a problem from Problems in Real Analysis by Radulescu and Andreescu. The book gives two other proofs. Thanks!,\displaystyle\lim_{n\to\infty}\frac{\sqrt[n]{n!}}{n}=e^{-1} \lim_{n\to\infty}\frac{n!}{n^ne^{-n}\sqrt{2\pi n}}=1 \lim_{n\to\infty}\sqrt[n]{\frac{n!}{n^ne^{-n}\sqrt{2\pi n}}}=1 \lim_{n\to\infty}\sqrt[n]{\frac{n!}{n^n}}\lim_{n\to\infty}\sqrt[n]{e^{n}}\lim_{n\to\infty}\frac{1}{\sqrt[2n]{2\pi n}}=e\lim_{n\to\infty}\frac{\sqrt[n]{n!}}{n}=1 \lim_{n\to\infty}\sqrt[2n]{2\pi n}=1 e,"['real-analysis', 'limits', 'solution-verification']"
30,How fast do iterated exponentiation converge?,How fast do iterated exponentiation converge?,,"Iterated exponentiation is defined by  $$x \mapsto x^{x^{x^{\cdot^{\cdot^{\cdot}}}}}$$ or more conveniently, we denote by $^rx$ the expression $\underbrace{x^{x^{\cdot^{\cdot^{\cdot^{x}}}}}}_{r \text{ times}}$. Let us define the function  $$\begin{array}{cccc} f_x:& \mathbb{N}& \to & \mathbb{R}\\ & r & \mapsto & ^rx. \end{array} $$ Euler proved that $\lim_{r \to \infty} f_x(r)$ exists for real numbers $x \in [e^{-e}, e^{1/e}]$ ([1]) (there is a convergence result in $\mathbb{C}$, but I am only interested in real numbers here). Now we consider the Lambert $W$ function , which is defined to be the function satisfying  $$W(z)e^{W(z)} = z.$$ Then we know from [1] that when $f_x$ converges, it converges to  $$\lim_{r \to \infty} f_x(r) = \frac{W(-\ln(x))}{-\ln(x)}.$$ My question is: Given $\epsilon > 0$, how can we determine $r_0 \in \mathbb{N}$ such that $\left|f_x(r_0) - \frac{W(-\ln(x))}{-\ln(x)} \right| < \epsilon$? Is it possible to solve this algebraically, or is it only possible to do it numerically?","Iterated exponentiation is defined by  $$x \mapsto x^{x^{x^{\cdot^{\cdot^{\cdot}}}}}$$ or more conveniently, we denote by $^rx$ the expression $\underbrace{x^{x^{\cdot^{\cdot^{\cdot^{x}}}}}}_{r \text{ times}}$. Let us define the function  $$\begin{array}{cccc} f_x:& \mathbb{N}& \to & \mathbb{R}\\ & r & \mapsto & ^rx. \end{array} $$ Euler proved that $\lim_{r \to \infty} f_x(r)$ exists for real numbers $x \in [e^{-e}, e^{1/e}]$ ([1]) (there is a convergence result in $\mathbb{C}$, but I am only interested in real numbers here). Now we consider the Lambert $W$ function , which is defined to be the function satisfying  $$W(z)e^{W(z)} = z.$$ Then we know from [1] that when $f_x$ converges, it converges to  $$\lim_{r \to \infty} f_x(r) = \frac{W(-\ln(x))}{-\ln(x)}.$$ My question is: Given $\epsilon > 0$, how can we determine $r_0 \in \mathbb{N}$ such that $\left|f_x(r_0) - \frac{W(-\ln(x))}{-\ln(x)} \right| < \epsilon$? Is it possible to solve this algebraically, or is it only possible to do it numerically?",,"['limits', 'convergence-divergence', 'tetration', 'power-towers', 'hyperoperation']"
31,Check that $\lim\limits_{n\to\infty}\sum\limits_{i=1}^{n}\left(\frac{i+x}{n}\right)^n=\frac{e^{x+1}}{e-1}$,Check that,\lim\limits_{n\to\infty}\sum\limits_{i=1}^{n}\left(\frac{i+x}{n}\right)^n=\frac{e^{x+1}}{e-1},"Show that   $$\lim_{n\to\infty}\sum_{i=1}^{n}\left(\frac{i+x}{n}\right)^n=\frac{e^{x+1}}{e-1}$$   Any hints how I can tackle this problem? Although I checked on a sum calculator that it converges very slowly, this result gives me a reason that the proposed closed form is incorrect. Can anyone verify it? I know that $$\lim_{n\to\infty}\left(\frac{n+x}{n}\right)^n=e^x$$ The limit to be computed is $$\lim_{n\to\infty}\left(\frac{1+x}{n}\right)^n+\left(\frac{2+x}{n}\right)^n+\left(\frac{3+x}{n}\right)^n+\cdots$$ It looks like the natural number series $$1^n+2^n+3^n+4^n+\cdots$$ But this is the farthest I can go.","Show that   $$\lim_{n\to\infty}\sum_{i=1}^{n}\left(\frac{i+x}{n}\right)^n=\frac{e^{x+1}}{e-1}$$   Any hints how I can tackle this problem? Although I checked on a sum calculator that it converges very slowly, this result gives me a reason that the proposed closed form is incorrect. Can anyone verify it? I know that $$\lim_{n\to\infty}\left(\frac{n+x}{n}\right)^n=e^x$$ The limit to be computed is $$\lim_{n\to\infty}\left(\frac{1+x}{n}\right)^n+\left(\frac{2+x}{n}\right)^n+\left(\frac{3+x}{n}\right)^n+\cdots$$ It looks like the natural number series $$1^n+2^n+3^n+4^n+\cdots$$ But this is the farthest I can go.",,['limits']
32,Equation with limit,Equation with limit,,"$\lim\limits_{n\to \infty}\sqrt{1+\sqrt{x+\sqrt{x^2+...+\sqrt{x^n}}}}=2$ I had never faced with problems like this. Give me, please, a little hint.","$\lim\limits_{n\to \infty}\sqrt{1+\sqrt{x+\sqrt{x^2+...+\sqrt{x^n}}}}=2$ I had never faced with problems like this. Give me, please, a little hint.",,"['real-analysis', 'limits']"
33,Show that $\lim_{n\to \infty}\prod_{i=n}^{Bn}\frac{\arctan(i\phi)}{\arccos\left(\frac{\phi}{i}\right)}=B^{\frac{2}{\pi}}$,Show that,\lim_{n\to \infty}\prod_{i=n}^{Bn}\frac{\arctan(i\phi)}{\arccos\left(\frac{\phi}{i}\right)}=B^{\frac{2}{\pi}},"Inspired from Gosper's formula $$\lim_{n\to \infty}\prod_{i=n}^{2n}\frac{\pi}{2\arctan(i)}=4^{\frac{1}{\pi}}$$ (See Pi Formulas on MathWorld ) Through mathematical experimental we found another formula similar to that of Gosper $\phi=\frac{1+\sqrt5}{2}$ B is an integer, $B\ge2$ $$\lim_{n\to \infty}\prod_{i=n}^{Bn}\frac{\arctan(i\phi)}{\arccos\left(\frac{\phi}{i}\right)}=B^{\frac{2}{\pi}}$$ We need help on proving it. Can anyone help us to prove it.","Inspired from Gosper's formula $$\lim_{n\to \infty}\prod_{i=n}^{2n}\frac{\pi}{2\arctan(i)}=4^{\frac{1}{\pi}}$$ (See Pi Formulas on MathWorld ) Through mathematical experimental we found another formula similar to that of Gosper $\phi=\frac{1+\sqrt5}{2}$ B is an integer, $B\ge2$ $$\lim_{n\to \infty}\prod_{i=n}^{Bn}\frac{\arctan(i\phi)}{\arccos\left(\frac{\phi}{i}\right)}=B^{\frac{2}{\pi}}$$ We need help on proving it. Can anyone help us to prove it.",,['limits']
34,"Dubious ""proof"" of $e^x$ derivative?","Dubious ""proof"" of  derivative?",e^x,"The proof to which I am referring is amply discussed here: Derivative of exponential function proof , but I remain unconvinced by the answers that pertain to the specific proof discovered by user1346994. It all boils down to showing that $\lim_{h\to 0}\left({\dfrac{e^{h}-1}{h}}\right) = 1$ I find it highly deceiving to replace $e$ with $(1+h)^{1/h}$ in the expression in the limit. https://math.stackexchange.com/a/671305/309566 is the answer in which I am most interested. But I'm still puzzled by the remark 'again by continuity' and the change of variables bit. I suppose if my wish were modest, it would be a proof that follows the one stated but with clear justifications. Thanks and sorry if I sound confused!","The proof to which I am referring is amply discussed here: Derivative of exponential function proof , but I remain unconvinced by the answers that pertain to the specific proof discovered by user1346994. It all boils down to showing that $\lim_{h\to 0}\left({\dfrac{e^{h}-1}{h}}\right) = 1$ I find it highly deceiving to replace $e$ with $(1+h)^{1/h}$ in the expression in the limit. https://math.stackexchange.com/a/671305/309566 is the answer in which I am most interested. But I'm still puzzled by the remark 'again by continuity' and the change of variables bit. I suppose if my wish were modest, it would be a proof that follows the one stated but with clear justifications. Thanks and sorry if I sound confused!",,"['limits', 'derivatives', 'exponential-function']"
35,"Finding limit of $ \lim \limits_{x,y \to 0,0}{(1 + x^2 y^2)}^{-\frac{1}{x^2 + y^2}}$",Finding limit of," \lim \limits_{x,y \to 0,0}{(1 + x^2 y^2)}^{-\frac{1}{x^2 + y^2}}","Here is my limit: $$ \lim \limits_{x,y \to 0,0}{(1 + x^2 y^2)}^{-\frac{1}{x^2 + y^2}}$$ I have learned two methods. One where we replace y with for example $y = kx $ (because $y = y_0 + k(x - x_0)$ and  $y_0 = 0, x_0 = 0$). Or with $x = r *cos(\phi)$ and $x = r *sin(\phi)$ where $r \to 0$. Neither seem to help me at the moment (or at least when I tried solving with both I didn't get a good answer. It kind of seems like I could use $ \lim \limits_{x \to \infty}{(1 + \frac{1}{x})}^{x} = e$, but I tried and also couldn't get a decent answer. Any ideas?","Here is my limit: $$ \lim \limits_{x,y \to 0,0}{(1 + x^2 y^2)}^{-\frac{1}{x^2 + y^2}}$$ I have learned two methods. One where we replace y with for example $y = kx $ (because $y = y_0 + k(x - x_0)$ and  $y_0 = 0, x_0 = 0$). Or with $x = r *cos(\phi)$ and $x = r *sin(\phi)$ where $r \to 0$. Neither seem to help me at the moment (or at least when I tried solving with both I didn't get a good answer. It kind of seems like I could use $ \lim \limits_{x \to \infty}{(1 + \frac{1}{x})}^{x} = e$, but I tried and also couldn't get a decent answer. Any ideas?",,"['limits', 'limits-without-lhopital']"
36,Limit problem $\ln(x)$ and $1^\infty$,Limit problem  and,\ln(x) 1^\infty,Can anyone help me with this limit problem without L'Hopital rule and Taylor series? $$\lim_{x\rightarrow\ 1}\left(\frac{2^x+2}{3^x+1}\right)^{1/\ln(x)}$$,Can anyone help me with this limit problem without L'Hopital rule and Taylor series? $$\lim_{x\rightarrow\ 1}\left(\frac{2^x+2}{3^x+1}\right)^{1/\ln(x)}$$,,"['calculus', 'limits', 'limits-without-lhopital']"
37,"Limit of $(1+x^2+y^2)^{\frac{1}{x^2+y^2+x y^2}}$, where do I get it wrong?","Limit of , where do I get it wrong?",(1+x^2+y^2)^{\frac{1}{x^2+y^2+x y^2}},"I am tasked with evaluating $$\lim_{(x, y) \to (0, 0)} (1+x^2+y^2)^{\frac{1}{x^2+y^2+x y^2}}.$$ We can rewrite the expression it as follows: $$ e^{\ln(1+x^2+y^2)\cdot\frac{1}{x^2+y^2+x y^2}} $$ Now, my first guess was that this tends to $1$.  But that is apparently incorrect, it tends towards $e$, which one can see just by graphing it. That is also what the book says. Now, we have the ""standard limit"": $$\lim_{x \to 0^+} \frac{\ln(1+x)}x = 1$$ So I can kinda see how we can get the power to tend toward $1$ so we get $e^1$, but the expression is not exactly the same, we have $xy^2$ tacked on to the end of the denominator of the fraction. Furthermore, $xy^2$ doesn't have to be positive. I tried using the substitution $x=\frac{1}{y^2}$, that gives us an expression that tends towards infinity both at $0$ and infinity and is never zero. Can anyone point out to me what I'm missing. It feels like it should be super-obvious.","I am tasked with evaluating $$\lim_{(x, y) \to (0, 0)} (1+x^2+y^2)^{\frac{1}{x^2+y^2+x y^2}}.$$ We can rewrite the expression it as follows: $$ e^{\ln(1+x^2+y^2)\cdot\frac{1}{x^2+y^2+x y^2}} $$ Now, my first guess was that this tends to $1$.  But that is apparently incorrect, it tends towards $e$, which one can see just by graphing it. That is also what the book says. Now, we have the ""standard limit"": $$\lim_{x \to 0^+} \frac{\ln(1+x)}x = 1$$ So I can kinda see how we can get the power to tend toward $1$ so we get $e^1$, but the expression is not exactly the same, we have $xy^2$ tacked on to the end of the denominator of the fraction. Furthermore, $xy^2$ doesn't have to be positive. I tried using the substitution $x=\frac{1}{y^2}$, that gives us an expression that tends towards infinity both at $0$ and infinity and is never zero. Can anyone point out to me what I'm missing. It feels like it should be super-obvious.",,"['limits', 'multivariable-calculus']"
38,Computing the $\lim_{n\to\infty} n^{\frac{1}{n!}}$?,Computing the ?,\lim_{n\to\infty} n^{\frac{1}{n!}},I want to find the following limit $$\lim\limits_{n\rightarrow \infty} n^{\frac{1}{n!}}$$ I tried solution as follows: Let $L=n^{\frac{1}{n!}}$ this implies $\log L=\frac{\log n}{n!}$ which is $\frac{\infty}{\infty}$ form as $n\rightarrow \infty.$ Don't know how to proceed. Help required,I want to find the following limit $$\lim\limits_{n\rightarrow \infty} n^{\frac{1}{n!}}$$ I tried solution as follows: Let $L=n^{\frac{1}{n!}}$ this implies $\log L=\frac{\log n}{n!}$ which is $\frac{\infty}{\infty}$ form as $n\rightarrow \infty.$ Don't know how to proceed. Help required,,"['real-analysis', 'limits', 'logarithms', 'factorial', 'radicals']"
39,How do i evaluate $\displaystyle \lim_{x \to -2}\frac {\sqrt{x+2}}{(\sqrt{x}+\sqrt{2} )}$?,How do i evaluate ?,\displaystyle \lim_{x \to -2}\frac {\sqrt{x+2}}{(\sqrt{x}+\sqrt{2} )},How do i evaluate $\displaystyle \lim_{x \to -2}\frac {\sqrt{x+2}}{(\sqrt{x}+\sqrt{2} )}$. I'm confused in wolfram alpha the result is $0$ however $\sqrt{x}$ at $x=-2$ is undefined in $\mathbb{R}$ then how it is $0$ ?,How do i evaluate $\displaystyle \lim_{x \to -2}\frac {\sqrt{x+2}}{(\sqrt{x}+\sqrt{2} )}$. I'm confused in wolfram alpha the result is $0$ however $\sqrt{x}$ at $x=-2$ is undefined in $\mathbb{R}$ then how it is $0$ ?,,"['calculus', 'real-analysis', 'limits', 'proof-verification']"
40,Taking the limit $\lim_{p\rightarrow \infty} \left( \frac{\|f\|_\infty}{\|f\|_p}\right)^p$,Taking the limit,\lim_{p\rightarrow \infty} \left( \frac{\|f\|_\infty}{\|f\|_p}\right)^p,"Taking the limit  $$\lim_{p\rightarrow \infty} \left( \frac{\|f\|_\infty}{\|f\|_p}\right)^p$$ First I think the expression after taking the limit will depend on the function $f$. In my attempt, because it is in the form $``1^\infty""$, I tried to use L'Hopital's rule. And we can calculate the limit (assuming the integrals are defined and finite, I just want to see what the limit might look like).  \begin{align*}  \lim_{p\rightarrow \infty} \left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)^{p} &=  \lim_{p\rightarrow \infty} \exp\left( p\log\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)\right)\\ &=\lim_{p\rightarrow \infty} \exp\left( \frac{\log\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)}{\frac{1}{p}}\right)\\ &=\lim_{p\rightarrow \infty} \exp\left( \frac{\frac{d}{dp} \left[-\log\left(\frac{\|\nabla u \|_p}{\|\nabla u\|_\infty}\right)\right]}{\frac{-1}{p^2}}\right)\\ &=\lim_{p\rightarrow \infty} \exp\left( \frac{\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)\frac{\frac{d}{dp}\left[\|\nabla u\|_p \right]}{\|\nabla u \|_\infty}\}}{\frac{1}{p^2}}\right)\\ \end{align*} where  \begin{align*} \frac{d}{dp}\left[\|\nabla u\|_p \right]  &= \frac{d}{dp}\left[\left(\int_{\mathbb R^N} |\nabla u |^p dx \right)^{1/p} \right] \\ &=\frac{d}{dp}\left[\exp\left(\frac{1}{p} \log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right)\right)\right] \\ &=\|\nabla u \|_p \left\{\frac{-1}{p^2}\log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right) + \frac{1}{p} \frac{1}{\int_{\mathbb R^N} |\nabla u |^p dx }\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx  \right\} \end{align*} Putting it back into the limit we get  $$\lim_{p\rightarrow \infty} \exp \left(-\log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right) + p \frac{1}{\int_{\mathbb R^N} |\nabla u |^p dx }\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx \right)$$ which simplifies to  $$\lim_{p\rightarrow \infty} \frac{\exp \left(p\frac{\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx}{\int_{\mathbb R^N} |\nabla u |^p dx } \right)}{\int_{\mathbb R^N} |\nabla u |^p dx }$$ And I am stuck. Is this a correct approach? Thank you very much!","Taking the limit  $$\lim_{p\rightarrow \infty} \left( \frac{\|f\|_\infty}{\|f\|_p}\right)^p$$ First I think the expression after taking the limit will depend on the function $f$. In my attempt, because it is in the form $``1^\infty""$, I tried to use L'Hopital's rule. And we can calculate the limit (assuming the integrals are defined and finite, I just want to see what the limit might look like).  \begin{align*}  \lim_{p\rightarrow \infty} \left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)^{p} &=  \lim_{p\rightarrow \infty} \exp\left( p\log\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)\right)\\ &=\lim_{p\rightarrow \infty} \exp\left( \frac{\log\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)}{\frac{1}{p}}\right)\\ &=\lim_{p\rightarrow \infty} \exp\left( \frac{\frac{d}{dp} \left[-\log\left(\frac{\|\nabla u \|_p}{\|\nabla u\|_\infty}\right)\right]}{\frac{-1}{p^2}}\right)\\ &=\lim_{p\rightarrow \infty} \exp\left( \frac{\left(\frac{\|\nabla u \|_\infty}{\|\nabla u\|_p}\right)\frac{\frac{d}{dp}\left[\|\nabla u\|_p \right]}{\|\nabla u \|_\infty}\}}{\frac{1}{p^2}}\right)\\ \end{align*} where  \begin{align*} \frac{d}{dp}\left[\|\nabla u\|_p \right]  &= \frac{d}{dp}\left[\left(\int_{\mathbb R^N} |\nabla u |^p dx \right)^{1/p} \right] \\ &=\frac{d}{dp}\left[\exp\left(\frac{1}{p} \log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right)\right)\right] \\ &=\|\nabla u \|_p \left\{\frac{-1}{p^2}\log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right) + \frac{1}{p} \frac{1}{\int_{\mathbb R^N} |\nabla u |^p dx }\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx  \right\} \end{align*} Putting it back into the limit we get  $$\lim_{p\rightarrow \infty} \exp \left(-\log\left(\int_{\mathbb R^N} |\nabla u |^p dx \right) + p \frac{1}{\int_{\mathbb R^N} |\nabla u |^p dx }\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx \right)$$ which simplifies to  $$\lim_{p\rightarrow \infty} \frac{\exp \left(p\frac{\int_{\mathbb R^N} |\nabla u|^p \log(|\nabla u |) dx}{\int_{\mathbb R^N} |\nabla u |^p dx } \right)}{\int_{\mathbb R^N} |\nabla u |^p dx }$$ And I am stuck. Is this a correct approach? Thank you very much!",,"['real-analysis', 'limits', 'normed-spaces', 'lp-spaces']"
41,Evaluating natural limit $\lim_{n \to \infty} \left( e^{2n} - 1\right) ^\frac{1}{n}$,Evaluating natural limit,\lim_{n \to \infty} \left( e^{2n} - 1\right) ^\frac{1}{n},Any idea evaluating this $$ \lim_{n \to \infty} \left( e^{2n} - 1\right) ^\frac{1}{n} $$ after I raise all to e like so $$ \exp\left( \frac{\ln\left(e^{2n}-1\right)}{n}\right) $$ and Hopital's it I get stuck. Thanks,Any idea evaluating this $$ \lim_{n \to \infty} \left( e^{2n} - 1\right) ^\frac{1}{n} $$ after I raise all to e like so $$ \exp\left( \frac{\ln\left(e^{2n}-1\right)}{n}\right) $$ and Hopital's it I get stuck. Thanks,,"['calculus', 'limits', 'exponential-function']"
42,"Find the value of $a$, $b$ and $c$ for the given limit.","Find the value of ,  and  for the given limit.",a b c,"Question - Find the values of $a$, $b$ and $c$ so that $$ \lim_{x\to 0} \cfrac{ae^x - b\cos x +c e^{-x} }{x\sin x} = 2 $$ This is what I've tried yet : For $ x\to 0 $ the numerator must also tend to zero as : $ e^x , \ \cos x, e^{-x} $ all $\to 1$   for $x \to 0$ . Therefore, we have:  $$  a - b + c = 0 \\ \color{blue}{\text{OR}} \\  b = a + c \\  $$ Now, plugging this in the original equation: $$\lim_{x\to 0} \cfrac{ae^x -(a+c)\cos x + ce^{-x} }{x^2 \times \frac{\sin x}{x} } = 2 $$ Which implies - $$\lim_{x\to 0} \cfrac{a(e^x - \cos x) + c(e^{-x} - \cos x) }{x^2} =2 $$ I do get a positive wave that there is some application of expansion series of $e^x \ \& \ \cos x $ . I tried that too but that just didn't work. May be I'm not doing right simplification. Any help will be greatly appreciated.","Question - Find the values of $a$, $b$ and $c$ so that $$ \lim_{x\to 0} \cfrac{ae^x - b\cos x +c e^{-x} }{x\sin x} = 2 $$ This is what I've tried yet : For $ x\to 0 $ the numerator must also tend to zero as : $ e^x , \ \cos x, e^{-x} $ all $\to 1$   for $x \to 0$ . Therefore, we have:  $$  a - b + c = 0 \\ \color{blue}{\text{OR}} \\  b = a + c \\  $$ Now, plugging this in the original equation: $$\lim_{x\to 0} \cfrac{ae^x -(a+c)\cos x + ce^{-x} }{x^2 \times \frac{\sin x}{x} } = 2 $$ Which implies - $$\lim_{x\to 0} \cfrac{a(e^x - \cos x) + c(e^{-x} - \cos x) }{x^2} =2 $$ I do get a positive wave that there is some application of expansion series of $e^x \ \& \ \cos x $ . I tried that too but that just didn't work. May be I'm not doing right simplification. Any help will be greatly appreciated.",,"['limits', 'taylor-expansion']"
43,Spivak's calculus: Chapter 7 problem 18 d),Spivak's calculus: Chapter 7 problem 18 d),,"In cases (a) and (c) [where it was proven that such a number exists for a continous $f$ on $\textbf{R}$], let $g(x)$ be the minimum distance from $(x,0)$ to a point on the graph $f$. Prove that $g(y)\leq g(x)+|x-y|$, and conclude that $g$ is continous. The answer from the answer book By definition, $g(x) = \sqrt{(f(z))^2+(z-x)^2}$ for some $z$ in $[a,b]$. Now $\sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2}+|z-y|$ for all $z$. So $g(y)$, the minimum of all $\sqrt{(f(z))^2+(z-y)^2}$, is less than or equal to $|z-y|+$ the minimum of all $\sqrt{(f(z))^2+(z-x)^2}$, which is $g(x)+|x-y|$. Since $|g(y)-g(x)|<|y-x|$ it follows that $g$ is continous (given $\varepsilon>0$, let $\delta = \varepsilon$). I understand why $\sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2}+|z-y|$ for all $z$ and I see how the continuity of $g$ would follow from the conclusion. But I don't get why the minimum of all $\sqrt{(f(z))^2+(z-y)^2}$, is less than or equal to $|z-y|+$ the minimum of all $\sqrt{(f(z))^2+(z-x)^2}$ and why this is supposed to be $g(x)+|x-y|$. Can someone help me here? Edit: I've now figured out the following things: if for some $z_0$ we have a minimum of $\sqrt{(f(z))^2+(z-y)^2}$, this means that  $$ g(y) \leq \sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2} +|y-z|  $$ for all $z$. So we can simply pick a $z=u$ such that $\sqrt{(f(u))^2+(u-x)^2} = g(x)$, so then we have $$ g(y) \leq g(x)+|u-y| $$ Does anyone now know how to turn that $|u-y|$ into $|x-y|$?","In cases (a) and (c) [where it was proven that such a number exists for a continous $f$ on $\textbf{R}$], let $g(x)$ be the minimum distance from $(x,0)$ to a point on the graph $f$. Prove that $g(y)\leq g(x)+|x-y|$, and conclude that $g$ is continous. The answer from the answer book By definition, $g(x) = \sqrt{(f(z))^2+(z-x)^2}$ for some $z$ in $[a,b]$. Now $\sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2}+|z-y|$ for all $z$. So $g(y)$, the minimum of all $\sqrt{(f(z))^2+(z-y)^2}$, is less than or equal to $|z-y|+$ the minimum of all $\sqrt{(f(z))^2+(z-x)^2}$, which is $g(x)+|x-y|$. Since $|g(y)-g(x)|<|y-x|$ it follows that $g$ is continous (given $\varepsilon>0$, let $\delta = \varepsilon$). I understand why $\sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2}+|z-y|$ for all $z$ and I see how the continuity of $g$ would follow from the conclusion. But I don't get why the minimum of all $\sqrt{(f(z))^2+(z-y)^2}$, is less than or equal to $|z-y|+$ the minimum of all $\sqrt{(f(z))^2+(z-x)^2}$ and why this is supposed to be $g(x)+|x-y|$. Can someone help me here? Edit: I've now figured out the following things: if for some $z_0$ we have a minimum of $\sqrt{(f(z))^2+(z-y)^2}$, this means that  $$ g(y) \leq \sqrt{(f(z))^2+(z-y)^2} \leq \sqrt{(f(z))^2+(z-x)^2} +|y-z|  $$ for all $z$. So we can simply pick a $z=u$ such that $\sqrt{(f(u))^2+(u-x)^2} = g(x)$, so then we have $$ g(y) \leq g(x)+|u-y| $$ Does anyone now know how to turn that $|u-y|$ into $|x-y|$?",,"['calculus', 'limits', 'continuity']"
44,Limit for sequence $a_{m+n}\leq a_m+a_n$,Limit for sequence,a_{m+n}\leq a_m+a_n,"Let $a_1,a_2,\ldots$ be a sequence of positive real numbers. Suppose that $a_{m+n}\leq a_m+a_n$ for all $n\geq 1$. Does $\lim_{n\rightarrow\infty}\dfrac{a_n}{n}$ always exist? From $a_{m+n}\leq a_m+a_n$ we know that $a_n\leq na_1$, so that $\dfrac{a_n}{n}\leq a_1$, which means the sequence $\dfrac{a_n}{n}$ is bounded both from above and below. But this is not enough to conclude that the limit exists.","Let $a_1,a_2,\ldots$ be a sequence of positive real numbers. Suppose that $a_{m+n}\leq a_m+a_n$ for all $n\geq 1$. Does $\lim_{n\rightarrow\infty}\dfrac{a_n}{n}$ always exist? From $a_{m+n}\leq a_m+a_n$ we know that $a_n\leq na_1$, so that $\dfrac{a_n}{n}\leq a_1$, which means the sequence $\dfrac{a_n}{n}$ is bounded both from above and below. But this is not enough to conclude that the limit exists.",,"['real-analysis', 'limits']"
45,Why upperbound $|x-a|$ by 1 in the proof of continuity?,Why upperbound  by 1 in the proof of continuity?,|x-a|,"In most (all?) proofs of continuity of polynomials ($x^2, x^3$, etc), for example in Max Rosenlicht's book ( http://www.math.pitt.edu/~frank/pittanal2121.pdf , page 97), the usual trick is to get to the expression  $$ |x-a||x+a| $$  and then bound $|x-a|$ by 1, which is then used to bound $|x+a|$ and then obtain $\delta = \min \{1, \frac{\epsilon}{2a +1} \}$. This baffles me even after numerous attempts. My questions are: 1) Why 1? What will change if I chose a different value? 2) Why do we need this other 'smaller' bound at all? I realize the question is not particularly challenging, but afte numerous attempts I still can't get my head around it.","In most (all?) proofs of continuity of polynomials ($x^2, x^3$, etc), for example in Max Rosenlicht's book ( http://www.math.pitt.edu/~frank/pittanal2121.pdf , page 97), the usual trick is to get to the expression  $$ |x-a||x+a| $$  and then bound $|x-a|$ by 1, which is then used to bound $|x+a|$ and then obtain $\delta = \min \{1, \frac{\epsilon}{2a +1} \}$. This baffles me even after numerous attempts. My questions are: 1) Why 1? What will change if I chose a different value? 2) Why do we need this other 'smaller' bound at all? I realize the question is not particularly challenging, but afte numerous attempts I still can't get my head around it.",,"['real-analysis', 'limits', 'continuity']"
46,Elementary way to show $\lim_{n \rightarrow \infty} \sqrt[n]{a_n} = \lim_{n \rightarrow \infty} \frac{a_{n+1}}{a_n}$?,Elementary way to show ?,\lim_{n \rightarrow \infty} \sqrt[n]{a_n} = \lim_{n \rightarrow \infty} \frac{a_{n+1}}{a_n},"Let $a_n \gt 0$ for $n \in \mathbb{N}$. The convergence radius of the series $\sum_{n=0}^\infty a_n z^n$ is $\frac{1}{q}$ with $q = \lim_{n \rightarrow \infty} \sqrt[n]{a_n}$ or $q = \lim_{n \rightarrow \infty} \frac{a_{n+1}}{a_n}$, if these limits exist. Therefore the $\lim$s must be identical. However I was wondering whether there exists a more elementary way to show this identity? (Or generally any other way?)","Let $a_n \gt 0$ for $n \in \mathbb{N}$. The convergence radius of the series $\sum_{n=0}^\infty a_n z^n$ is $\frac{1}{q}$ with $q = \lim_{n \rightarrow \infty} \sqrt[n]{a_n}$ or $q = \lim_{n \rightarrow \infty} \frac{a_{n+1}}{a_n}$, if these limits exist. Therefore the $\lim$s must be identical. However I was wondering whether there exists a more elementary way to show this identity? (Or generally any other way?)",,['limits']
47,Isosceles Triangle With Height Limiting To Zero,Isosceles Triangle With Height Limiting To Zero,,"The figure shows an isosceles triangle $ABC$ with $\angle B = \angle C$ . The bisector of angle $B$ intersects the side $AC$ at the point $P$. Suppose that the base $BC$ remains fixed but the altitude $|AM|$ of the triangle approaches $0$, so $A$ approaches the midpoint $M$ of $BC$. What happens to $P$ during this process? Does it have a limiting position? If so, find it. I have tried relating $P$ and $A$ in a few ways(the law of cosines being one them) but I fail at finding something that gives me an equation for the position of P. Can anybody give me a hint?","The figure shows an isosceles triangle $ABC$ with $\angle B = \angle C$ . The bisector of angle $B$ intersects the side $AC$ at the point $P$. Suppose that the base $BC$ remains fixed but the altitude $|AM|$ of the triangle approaches $0$, so $A$ approaches the midpoint $M$ of $BC$. What happens to $P$ during this process? Does it have a limiting position? If so, find it. I have tried relating $P$ and $A$ in a few ways(the law of cosines being one them) but I fail at finding something that gives me an equation for the position of P. Can anybody give me a hint?",,"['calculus', 'limits']"
48,Evaluate $\lim_{x \to 1} \frac{\sqrt[3]{x} -1}{\sqrt{x} -1}$ [duplicate],Evaluate  [duplicate],\lim_{x \to 1} \frac{\sqrt[3]{x} -1}{\sqrt{x} -1},This question already has answers here : Evaluating $\lim _{x\to 1}\left(\frac{\sqrt[3]{x}-1}{2\sqrt{x}-2}\right)$ [duplicate] (6 answers) Closed 8 years ago . Evaluate $\lim_{x \to 1} \frac{\sqrt[3]{x} -1}{\sqrt{x} -1}$ I want to solve this limit by employing the strategy of introducing a new variable $t$ in such a way as to make the problem simpler. I've tried using $t = \sqrt[3]{x} \Rightarrow \lim_{t \to 1} \frac{t -1}{\sqrt{t^3} -1}$ but I can't seem to manipulate the problem in to something simpler. Can anybody give a hint?,This question already has answers here : Evaluating $\lim _{x\to 1}\left(\frac{\sqrt[3]{x}-1}{2\sqrt{x}-2}\right)$ [duplicate] (6 answers) Closed 8 years ago . Evaluate $\lim_{x \to 1} \frac{\sqrt[3]{x} -1}{\sqrt{x} -1}$ I want to solve this limit by employing the strategy of introducing a new variable $t$ in such a way as to make the problem simpler. I've tried using $t = \sqrt[3]{x} \Rightarrow \lim_{t \to 1} \frac{t -1}{\sqrt{t^3} -1}$ but I can't seem to manipulate the problem in to something simpler. Can anybody give a hint?,,"['calculus', 'limits', 'radicals']"
49,Solving a trigonometric limit $\lim_{x\to\pi/6}\frac{1 - 2\sin{x}}{2\sqrt{3}\cos{x} - 3}$,Solving a trigonometric limit,\lim_{x\to\pi/6}\frac{1 - 2\sin{x}}{2\sqrt{3}\cos{x} - 3},"First off, please excuse my n00bishness I have only just begun learning about algebraic manipulation of limits so this is probably a really dumb or obvious question. I'm trying to solve the following limit: $$ \lim_{x\to\pi/6}\frac{1 - 2\sin{x}}{2\sqrt{3}\cos{x} - 3} $$ This limit is $0/0$ if evaluated directly, so I tried multiplying by the conjugate of the denominator: $$ \begin{align} & = \lim_{x\to\pi/6}\frac{(1 - 2\sin{x})(2\sqrt{3}\cos{x} + 3)}{(2\sqrt{3}\cos{x} - 3)(2\sqrt{3}\cos{x} + 3)}\\ & = \lim_{x\to\pi/6}\frac{(2\sin{x} - 1)(2\sqrt{3}\cos{x} - 3)}{(2\sqrt{3}\cos{x} - 3)(2\sqrt{3}\cos{3} + 3)} \\ & = \lim_{x\to\pi/6}\frac{2\sin{x} - 1}{2\sqrt{3}\cos{x} + 3}\\ & = \frac{2(1/2) - 1}{2\sqrt{3}\frac{\sqrt{3}}{2} + 3}\\ & = \frac{0}{6}\\ & = 0 \end{align} $$ But according to WolframAlpha this is incorrect, and the limit should be 1. What have I done wrong? Also, as I have only just begun I am unfamiliar with L'Hopital's rule.","First off, please excuse my n00bishness I have only just begun learning about algebraic manipulation of limits so this is probably a really dumb or obvious question. I'm trying to solve the following limit: $$ \lim_{x\to\pi/6}\frac{1 - 2\sin{x}}{2\sqrt{3}\cos{x} - 3} $$ This limit is $0/0$ if evaluated directly, so I tried multiplying by the conjugate of the denominator: $$ \begin{align} & = \lim_{x\to\pi/6}\frac{(1 - 2\sin{x})(2\sqrt{3}\cos{x} + 3)}{(2\sqrt{3}\cos{x} - 3)(2\sqrt{3}\cos{x} + 3)}\\ & = \lim_{x\to\pi/6}\frac{(2\sin{x} - 1)(2\sqrt{3}\cos{x} - 3)}{(2\sqrt{3}\cos{x} - 3)(2\sqrt{3}\cos{3} + 3)} \\ & = \lim_{x\to\pi/6}\frac{2\sin{x} - 1}{2\sqrt{3}\cos{x} + 3}\\ & = \frac{2(1/2) - 1}{2\sqrt{3}\frac{\sqrt{3}}{2} + 3}\\ & = \frac{0}{6}\\ & = 0 \end{align} $$ But according to WolframAlpha this is incorrect, and the limit should be 1. What have I done wrong? Also, as I have only just begun I am unfamiliar with L'Hopital's rule.",,"['limits', 'trigonometry']"
50,Squeeze Theorem with Factorial,Squeeze Theorem with Factorial,,"Is it correct to squeeze $\frac{3n}{(n+1)!}$ between $0$ and $\frac{1}{n!}$?  The proposed left side makes logical sense to me, however bounding the right hand side to prove the limit goes to $0$ is giving me a bit more trouble.","Is it correct to squeeze $\frac{3n}{(n+1)!}$ between $0$ and $\frac{1}{n!}$?  The proposed left side makes logical sense to me, however bounding the right hand side to prove the limit goes to $0$ is giving me a bit more trouble.",,"['calculus', 'limits']"
51,Limit points of $\cos n$.,Limit points of .,\cos n,Find the limit point of the sequence $\{s_n\}$ given by $s_n=\cos n $. I know by this post Limit of sequence $s_n = \cos(n)$ that the sequence does not converge. But I don't know how to search those points.,Find the limit point of the sequence $\{s_n\}$ given by $s_n=\cos n $. I know by this post Limit of sequence $s_n = \cos(n)$ that the sequence does not converge. But I don't know how to search those points.,,"['real-analysis', 'limits']"
52,Limit evaluation method inconsistency?,Limit evaluation method inconsistency?,,"I'm having trouble understanding what really happens when we evaluate the limit of a certain function f(x) as x approaches a certain value. For ex, if we have lim x-->2 $\frac{x^2 + x -6}{(x-2)}$ we can't just plug in 2 and evaluate that because f(x) is undefined when x=2. So we factor out the numerator and find that lim x-->2 $\frac{x^2 + x -6}{(x-2)} = \frac{(x+3)(x-2)}{(x-2)}$ Here is where there seems to be an inconsistency as far as I understand what's going on. We are ok with canceling out the (x+2) terms because we're not saying that x=2, we're saying x approaches 2, so (x-2) in the denominator =/= 0 and we can simplify. However, then it seems we just plug 2 into (x+3) and say that lim x-->2 $\frac{x^2 + x -6}{(x-2)} = 5$. That's very confusing to me because we go from not being ok with plugging in the value 2, instead imagining that we're getting closer and closer to it from both ends, to just plugging in 2 and saying (2+3) = 5. I understand that there's no more problem with using 2 once we got rid of (x-2) in the denominator, but what happened to just approaching x?","I'm having trouble understanding what really happens when we evaluate the limit of a certain function f(x) as x approaches a certain value. For ex, if we have lim x-->2 $\frac{x^2 + x -6}{(x-2)}$ we can't just plug in 2 and evaluate that because f(x) is undefined when x=2. So we factor out the numerator and find that lim x-->2 $\frac{x^2 + x -6}{(x-2)} = \frac{(x+3)(x-2)}{(x-2)}$ Here is where there seems to be an inconsistency as far as I understand what's going on. We are ok with canceling out the (x+2) terms because we're not saying that x=2, we're saying x approaches 2, so (x-2) in the denominator =/= 0 and we can simplify. However, then it seems we just plug 2 into (x+3) and say that lim x-->2 $\frac{x^2 + x -6}{(x-2)} = 5$. That's very confusing to me because we go from not being ok with plugging in the value 2, instead imagining that we're getting closer and closer to it from both ends, to just plugging in 2 and saying (2+3) = 5. I understand that there's no more problem with using 2 once we got rid of (x-2) in the denominator, but what happened to just approaching x?",,"['calculus', 'limits']"
53,Limits of the solutions to $x\sin x = 1$,Limits of the solutions to,x\sin x = 1,"Let $x_n$ be the sequence of increasing solutions to $x\sin{x} = 1$. Define $$a = \lim_{n \to \infty} n(x_{2n+1} - 2\pi n) $$ and $$b = \lim_{n \to \infty} n^3 \left( x_{2n+1} - 2\pi n - \frac{a}{n} \right) $$ These limits can be evaluated, but they appear to be the first limits in some sequence. How can we find a general formula for all the limits in this sequence? (For example,  $$c = \lim_{n \to \infty} n^5\left( x_{2n + 1} - 2\pi n - \frac{a}{n} - \frac{b}{n^3} \right) $$ might be the next in the sequence).","Let $x_n$ be the sequence of increasing solutions to $x\sin{x} = 1$. Define $$a = \lim_{n \to \infty} n(x_{2n+1} - 2\pi n) $$ and $$b = \lim_{n \to \infty} n^3 \left( x_{2n+1} - 2\pi n - \frac{a}{n} \right) $$ These limits can be evaluated, but they appear to be the first limits in some sequence. How can we find a general formula for all the limits in this sequence? (For example,  $$c = \lim_{n \to \infty} n^5\left( x_{2n + 1} - 2\pi n - \frac{a}{n} - \frac{b}{n^3} \right) $$ might be the next in the sequence).",,"['calculus', 'limits', 'contest-math', 'taylor-expansion', 'roots']"
54,Find the following limit: $L=\lim_{n\to \infty}\frac{\left(2\sqrt[n]{n}-1\right)^n}{n^2}$,Find the following limit:,L=\lim_{n\to \infty}\frac{\left(2\sqrt[n]{n}-1\right)^n}{n^2},"Find the following limit: $$L=\lim_{n\to \infty}\frac{\left(2\sqrt[n]{n}-1\right)^n}{n^2}$$ I think use Taylor's expansion give $\left(2\sqrt[n]{n}-1\right)^n$ or there is a workaround, but I do not know.","Find the following limit: $$L=\lim_{n\to \infty}\frac{\left(2\sqrt[n]{n}-1\right)^n}{n^2}$$ I think use Taylor's expansion give $\left(2\sqrt[n]{n}-1\right)^n$ or there is a workaround, but I do not know.",,['limits']
55,Evaluating $\lim_{x\to1}\frac{\sqrt{x^2+3}-2}{x^2-1}$?,Evaluating ?,\lim_{x\to1}\frac{\sqrt{x^2+3}-2}{x^2-1},"I tried to calculate, but couldn't get out of this: $$\lim_{x\to1}\frac{x^2+5}{x^2 (\sqrt{x^2 +3}+2)-\sqrt{x^2 +3}}$$ then multiply by the conjugate. $$\lim_{x\to1}\frac{\sqrt{x^2 +3}-2}{x^2 -1}$$ Thanks!","I tried to calculate, but couldn't get out of this: $$\lim_{x\to1}\frac{x^2+5}{x^2 (\sqrt{x^2 +3}+2)-\sqrt{x^2 +3}}$$ then multiply by the conjugate. $$\lim_{x\to1}\frac{\sqrt{x^2 +3}-2}{x^2 -1}$$ Thanks!",,"['calculus', 'limits']"
56,Limit involving a hypergeometric function,Limit involving a hypergeometric function,,"I am new to hypergeometric function and am interested in evaluating the following limit: $$L(m,n,r)=\lim_{x\rightarrow 0^+} x^m\times {}_2F_1\left(-m,-n,-(m+n);1-\frac{r}{x}\right)$$ where $n$ and $m$ are non-negative integers, and $r$ is a positive real constant. However, I don't know where to start.  I did have Wolfram Mathematica symbolically evaluate this limit for various values of $m$, and the patters seems to suggest the following expression for $L(m,n,r)$: $$L(m,n,r)=r^m\prod_{i=1}^m\frac{n-i+1}{n+i}$$ which one can re-write using the Pochhammer symbol notation as follows: $$L(m,n,r)=r^mn\frac{(n)_m}{n^{(m)}}$$ If the above is in fact correct, I am interested in learning how to derive it using ""first principles"" as opposed to the black box that is Wolfram Mathematica.  I am really confused by the definition of hypergeometric function ${}_2F_1(a,b,c;z)$, as the defition that uses the Pochhammer symbol in the wikipedia page excludes the case that I have where $c$ is a non-positive integer.  Any help would be appreciated.","I am new to hypergeometric function and am interested in evaluating the following limit: $$L(m,n,r)=\lim_{x\rightarrow 0^+} x^m\times {}_2F_1\left(-m,-n,-(m+n);1-\frac{r}{x}\right)$$ where $n$ and $m$ are non-negative integers, and $r$ is a positive real constant. However, I don't know where to start.  I did have Wolfram Mathematica symbolically evaluate this limit for various values of $m$, and the patters seems to suggest the following expression for $L(m,n,r)$: $$L(m,n,r)=r^m\prod_{i=1}^m\frac{n-i+1}{n+i}$$ which one can re-write using the Pochhammer symbol notation as follows: $$L(m,n,r)=r^mn\frac{(n)_m}{n^{(m)}}$$ If the above is in fact correct, I am interested in learning how to derive it using ""first principles"" as opposed to the black box that is Wolfram Mathematica.  I am really confused by the definition of hypergeometric function ${}_2F_1(a,b,c;z)$, as the defition that uses the Pochhammer symbol in the wikipedia page excludes the case that I have where $c$ is a non-positive integer.  Any help would be appreciated.",,"['limits', 'special-functions']"
57,Calculus Bonus Problem,Calculus Bonus Problem,,"solve algebraically $$\lim_{x\rightarrow 0}\frac{\sqrt[3]{1+x^2}-\sqrt[4]{1-2x}}{x+x^2}$$ without using L'hopital's rule This is a bonus question for my Math Intensive Major Cal 1 class, I would like to know how to solve it since it stumped me on the test, and after many hours of working at this problem it has stumped me again and again","solve algebraically $$\lim_{x\rightarrow 0}\frac{\sqrt[3]{1+x^2}-\sqrt[4]{1-2x}}{x+x^2}$$ without using L'hopital's rule This is a bonus question for my Math Intensive Major Cal 1 class, I would like to know how to solve it since it stumped me on the test, and after many hours of working at this problem it has stumped me again and again",,"['calculus', 'limits']"
58,"Finding $\lim\limits_{(x,y) \to (0,0)} \frac{|xy|}{\sqrt{x^2 + y^2}}$",Finding,"\lim\limits_{(x,y) \to (0,0)} \frac{|xy|}{\sqrt{x^2 + y^2}}","How does one find the limit of $$\lim\limits_{(x,y) \to (0,0)} \dfrac{|xy|}{\sqrt{x^2 + y^2}}$$? Can someone justify the steps they make? The answers in my book involves using some smart inequality that I've never seen before and could only say it resembles the AM-GM inequality","How does one find the limit of $$\lim\limits_{(x,y) \to (0,0)} \dfrac{|xy|}{\sqrt{x^2 + y^2}}$$? Can someone justify the steps they make? The answers in my book involves using some smart inequality that I've never seen before and could only say it resembles the AM-GM inequality",,"['limits', 'multivariable-calculus']"
59,Find the following limit $\lim_{x\to 0}\frac{\sqrt[3]{1+x}-1}{x}$ and $\lim_{x\to 0}\frac{\cos 3x-\cos x}{x^2}$,Find the following limit  and,\lim_{x\to 0}\frac{\sqrt[3]{1+x}-1}{x} \lim_{x\to 0}\frac{\cos 3x-\cos x}{x^2},"Find the following limits $$\lim_{x\to 0}\frac{\sqrt[3]{1+x}-1}{x}$$ Any hints/solutions how to approach this? I tried many ways, rationalization, taking out x, etc. But I still can't rid myself of the singularity. Thanks in advance. Also another question. Find the limit of $$\lim_{x\to 0}\frac{\cos 3x-\cos x}{x^2}$$ I worked up till here, after which I got stuck. I think I need to apply the squeeze theore, but I am not sure how to. $$\lim_{x\to 0}\frac{\cos 3x-\cos x}{x^2} = \lim_{x\to 0}\frac{-2\sin\frac{1}{2}(3x+x)\sin\frac{1}{2}(3x-x)}{x^2}=\lim_{x\to 0}\frac{-2\sin2x\sin x}{x^2}=\lim_{x\to 0}\frac{-2(2\sin x\cos x)\sin x}{x^2}=\lim_{x\to 0}\frac{-4\sin^2 x\cos x}{x^2}$$ Solutions or hints will be appreciated. Thanks in advance! L'hospital's rule not allowed.","Find the following limits Any hints/solutions how to approach this? I tried many ways, rationalization, taking out x, etc. But I still can't rid myself of the singularity. Thanks in advance. Also another question. Find the limit of I worked up till here, after which I got stuck. I think I need to apply the squeeze theore, but I am not sure how to. Solutions or hints will be appreciated. Thanks in advance! L'hospital's rule not allowed.",\lim_{x\to 0}\frac{\sqrt[3]{1+x}-1}{x} \lim_{x\to 0}\frac{\cos 3x-\cos x}{x^2} \lim_{x\to 0}\frac{\cos 3x-\cos x}{x^2} = \lim_{x\to 0}\frac{-2\sin\frac{1}{2}(3x+x)\sin\frac{1}{2}(3x-x)}{x^2}=\lim_{x\to 0}\frac{-2\sin2x\sin x}{x^2}=\lim_{x\to 0}\frac{-2(2\sin x\cos x)\sin x}{x^2}=\lim_{x\to 0}\frac{-4\sin^2 x\cos x}{x^2},"['calculus', 'limits', 'limits-without-lhopital']"
60,"Solving $\lim\limits_{(x,y)\to(0,0)}\;\frac{x^5 + \,y^5}{x^3+\,y^3}$",Solving,"\lim\limits_{(x,y)\to(0,0)}\;\frac{x^5 + \,y^5}{x^3+\,y^3}","How do I solve the limit $$\lim_{(x,y)\to(0,0)}\;\frac{x^5+y^5}{x^3+y^3}\quad ?$$ I have tried using polar coordinates, but I don't think an answer would be valid because theta is not fixed. What else can I do?","How do I solve the limit $$\lim_{(x,y)\to(0,0)}\;\frac{x^5+y^5}{x^3+y^3}\quad ?$$ I have tried using polar coordinates, but I don't think an answer would be valid because theta is not fixed. What else can I do?",,"['limits', 'multivariable-calculus']"
61,Limit involving floor function,Limit involving floor function,,"I've been asked (by a person not by a homework) about how to compute the following limit: $$ \lim_{x \to 10^-} \frac{[x^3] - x^3}{[x] - x}$$ where $[\cdot]$ is used to denote the floor function: $$ [x] := \begin{cases} x && x \in \mathbb{Z} \\      \text{biggest integer smaller than }x && \text{otherwise} \end{cases}$$ My first thought was to sandwich this but using $x^3 - 1 \leq [x^3] \leq x^3$ to get $-1 \leq [x^3] - x^3 \leq 0$ leaves me with $$ \lim_{x \to 10^-} \frac{1}{x - [x]} \leq \lim_{x \to 10^-} \frac{[x^3] - x^3}{[x] - x} \leq 0$$ Which doesn't seem to lead anywhere. What's the right way to compute this limit? Thanks for your help.","I've been asked (by a person not by a homework) about how to compute the following limit: $$ \lim_{x \to 10^-} \frac{[x^3] - x^3}{[x] - x}$$ where $[\cdot]$ is used to denote the floor function: $$ [x] := \begin{cases} x && x \in \mathbb{Z} \\      \text{biggest integer smaller than }x && \text{otherwise} \end{cases}$$ My first thought was to sandwich this but using $x^3 - 1 \leq [x^3] \leq x^3$ to get $-1 \leq [x^3] - x^3 \leq 0$ leaves me with $$ \lim_{x \to 10^-} \frac{1}{x - [x]} \leq \lim_{x \to 10^-} \frac{[x^3] - x^3}{[x] - x} \leq 0$$ Which doesn't seem to lead anywhere. What's the right way to compute this limit? Thanks for your help.",,"['real-analysis', 'limits']"
62,Interpretation of {Infinitely Often} = {Almost Always},Interpretation of {Infinitely Often} = {Almost Always},,"I am trying to better understand what it means for a sequence $A_n$ of subsets of a set $S$ to be such that $\bigcap^\infty_{n = 1} \bigcup^\infty_{m = n} A_n = \limsup A_n = \liminf A_n = \bigcup^\infty_{n = 1} \bigcap^\infty_{m = n} A_n$ I find the interpretation infinitely often and eventually always as in \begin{equation} \bigcap^\infty_{n = 1} \bigcup^\infty_{m = n} A_n = \limsup A_n = \{ w \,  \colon w \in A_n \quad \text{infinitely often} \} \end{equation} and \begin{equation} \bigcup^\infty_{n = 1} \bigcap^\infty_{m = n} A_n = \liminf A_n = \{ w \, \colon w \in A_n \quad\text{eventually always} \} \end{equation} very helpful and I am looking for an analogous interpretation what it means for the two to be equal.","I am trying to better understand what it means for a sequence $A_n$ of subsets of a set $S$ to be such that $\bigcap^\infty_{n = 1} \bigcup^\infty_{m = n} A_n = \limsup A_n = \liminf A_n = \bigcup^\infty_{n = 1} \bigcap^\infty_{m = n} A_n$ I find the interpretation infinitely often and eventually always as in \begin{equation} \bigcap^\infty_{n = 1} \bigcup^\infty_{m = n} A_n = \limsup A_n = \{ w \,  \colon w \in A_n \quad \text{infinitely often} \} \end{equation} and \begin{equation} \bigcup^\infty_{n = 1} \bigcap^\infty_{m = n} A_n = \liminf A_n = \{ w \, \colon w \in A_n \quad\text{eventually always} \} \end{equation} very helpful and I am looking for an analogous interpretation what it means for the two to be equal.",,"['elementary-set-theory', 'limits', 'limsup-and-liminf']"
63,$\lim_{x\to 10}(\sqrt{-(x-10)^2})=0$ or $\lim_{x\to 10}(\sqrt{-(x-10)^2})$ is undefined?,or  is undefined?,\lim_{x\to 10}(\sqrt{-(x-10)^2})=0 \lim_{x\to 10}(\sqrt{-(x-10)^2}),"I am reviewing calculus 1 and I saw this problem. The problem is $\lim_{x\to 10}(\sqrt{-(x-10)^2})$ . The answer guide says the answer is undefined, since the function is not defined on an open interval at x=10 and is only defined on a single point, $x=10$ , at which $\sqrt{-(x-10)^2}=0$ . Well I believe that $\lim_{x\to 10}(\sqrt{-(x-10)^2})$ does in fact $=0$ , contrary to the answer guide. This is because $\sqrt{-(x-10)^2}$ is actually defined for $x\ne10$ , just in the imaginary numbers instead of the real ones. And that the imaginary value of $\sqrt{-(x-10)^2}$ gets closer to zero as x approaches ten. I have shown this using a delta-epsilon proof. $$((\epsilon>0\;\land\;0<\delta\le\epsilon)\implies$$ $$(\lvert{x-10}\rvert<\delta\implies$$ $$\lvert{i(x-10)}\rvert<\delta\implies$$ $$\lvert{\sqrt{-(x-10)^2}}\rvert<\delta\implies$$ $$\lvert{\sqrt{-(x-10)^2}-0}\rvert<\delta\implies$$ $$\lvert{\sqrt{-(x-10)^2}-0}\rvert<\epsilon))\implies$$ $$(\forall\;\epsilon>0\;\exists\;\delta>0 \text{ s.t }\lvert{x-10}\rvert<\delta\implies\lvert{\sqrt{-(x-10)^2}-0}\rvert<\epsilon)\implies$$ $$\lim_{x\to10}(\sqrt{-(x-10)^2}=0$$ The crucial step of this proof is rewriting $\lvert{x-10}\rvert$ as $\lvert{i(x-10)}\rvert$ . As far as I'm aware, the two statements are equivalent because absolute value measures the distance of any complex number to the origin, so in general $\lvert{x}\rvert = \lvert{ix}\rvert$ just as $\lvert{x}\rvert = \lvert{-x}\rvert$ . Where is my mistake?","I am reviewing calculus 1 and I saw this problem. The problem is . The answer guide says the answer is undefined, since the function is not defined on an open interval at x=10 and is only defined on a single point, , at which . Well I believe that does in fact , contrary to the answer guide. This is because is actually defined for , just in the imaginary numbers instead of the real ones. And that the imaginary value of gets closer to zero as x approaches ten. I have shown this using a delta-epsilon proof. The crucial step of this proof is rewriting as . As far as I'm aware, the two statements are equivalent because absolute value measures the distance of any complex number to the origin, so in general just as . Where is my mistake?",\lim_{x\to 10}(\sqrt{-(x-10)^2}) x=10 \sqrt{-(x-10)^2}=0 \lim_{x\to 10}(\sqrt{-(x-10)^2}) =0 \sqrt{-(x-10)^2} x\ne10 \sqrt{-(x-10)^2} ((\epsilon>0\;\land\;0<\delta\le\epsilon)\implies (\lvert{x-10}\rvert<\delta\implies \lvert{i(x-10)}\rvert<\delta\implies \lvert{\sqrt{-(x-10)^2}}\rvert<\delta\implies \lvert{\sqrt{-(x-10)^2}-0}\rvert<\delta\implies \lvert{\sqrt{-(x-10)^2}-0}\rvert<\epsilon))\implies (\forall\;\epsilon>0\;\exists\;\delta>0 \text{ s.t }\lvert{x-10}\rvert<\delta\implies\lvert{\sqrt{-(x-10)^2}-0}\rvert<\epsilon)\implies \lim_{x\to10}(\sqrt{-(x-10)^2}=0 \lvert{x-10}\rvert \lvert{i(x-10)}\rvert \lvert{x}\rvert = \lvert{ix}\rvert \lvert{x}\rvert = \lvert{-x}\rvert,"['limits', 'complex-numbers']"
64,Does $\lim_{x \to 1}\left(\frac{x}{[x]}\right)$ exist?,Does  exist?,\lim_{x \to 1}\left(\frac{x}{[x]}\right),"Does the limit $\lim_{x \to 1}\left(\frac{x}{\lfloor x\rfloor}\right)$ exist? Where $\lfloor x\rfloor$ is the Greatest Integer Function or the Floor function. My teacher defined that a limit exists when the Left-hand Limit = Right-Hand Limit and If any one is undefined but the other is finite then also the limit exists. Like $\lim_{x \to 0}\sqrt{x}$ does exist although the LHL does not lie in the domain. In this question the domain of the function $\frac{x}{\lfloor x\rfloor}$ is $\mathbb R\setminus[0,1)$ where $\mathbb R$ represents Real Numbers. So, The Left-Hand Limit is not defined and Right Hand Limit is $1$ , which is finite so according to my teacher Limit does exist. But when I tried this question in WolframAlpha, it is saying that the LHL is $-\infty$ and RHL is $1$ , so limit does not exist. So, a more general question is: do we have to consider the domain of a function when we calculate a limit?","Does the limit exist? Where is the Greatest Integer Function or the Floor function. My teacher defined that a limit exists when the Left-hand Limit = Right-Hand Limit and If any one is undefined but the other is finite then also the limit exists. Like does exist although the LHL does not lie in the domain. In this question the domain of the function is where represents Real Numbers. So, The Left-Hand Limit is not defined and Right Hand Limit is , which is finite so according to my teacher Limit does exist. But when I tried this question in WolframAlpha, it is saying that the LHL is and RHL is , so limit does not exist. So, a more general question is: do we have to consider the domain of a function when we calculate a limit?","\lim_{x \to 1}\left(\frac{x}{\lfloor x\rfloor}\right) \lfloor x\rfloor \lim_{x \to 0}\sqrt{x} \frac{x}{\lfloor x\rfloor} \mathbb R\setminus[0,1) \mathbb R 1 -\infty 1","['calculus', 'limits', 'limits-without-lhopital']"
65,Finding the radius of convergence of this power series,Finding the radius of convergence of this power series,,"I need help finding the radius of convergence of the power series $$\sum_{n=1}^{\infty}\left(\sqrt{n+a}-\sqrt{n}\right) x^n,$$ for some $a > 0$ . I know the radius must be 1 but I can't formally show it by computing the limit of the quotients of the coefficients. Basically I want to show $$\lim\limits_{n\to \infty}\frac{\sqrt{n+a+1}-\sqrt{n+1}}{\sqrt{n+a}-\sqrt{n}} = 1.$$ I have tried expanding the quotient using the binomial formula, but I can't get it to work without using handwavy arguments. Thanks in advance!","I need help finding the radius of convergence of the power series for some . I know the radius must be 1 but I can't formally show it by computing the limit of the quotients of the coefficients. Basically I want to show I have tried expanding the quotient using the binomial formula, but I can't get it to work without using handwavy arguments. Thanks in advance!","\sum_{n=1}^{\infty}\left(\sqrt{n+a}-\sqrt{n}\right) x^n, a > 0 \lim\limits_{n\to \infty}\frac{\sqrt{n+a+1}-\sqrt{n+1}}{\sqrt{n+a}-\sqrt{n}} = 1.","['calculus', 'limits', 'convergence-divergence', 'power-series']"
66,Multiple answers for the same limit expression?,Multiple answers for the same limit expression?,,"So I was trying to find the limit of the following expression. $$\lim_{x\to 0} \frac{\tan x - \sin x}{\sin^3 x}$$ When using the L'Hospital's rule I got the answer $\frac {1}{2}$ . My steps: $$\lim_{x\to 0} \frac{\tan x - \sin x}{\sin^3 x} $$ $$=\lim_{x\to 0} \frac{\sec^2 x - \cos x}{3\sin^2 x \cos x}$$ $$=\lim_{x\to 0} \frac{2 \sec^2 x \tan x + \sin x}{6\sin x \cos^2 x}$$ $$=\lim_{x\to 0} \left(\frac{2 \sec^2 x \tan x}{6\sin x \cos^2 x}+\frac{\sin x}{6\sin x \cos^2 x}\right)$$ $$=\lim_{x\to 0} \left(\frac{1}{3\cos^5 x}+\frac{1}{6\cos^2 x}\right)$$ $$=\frac{1}{3}+\frac{1}{6}$$ $$=\frac{1}{2}$$ Edit: My steps are incorrect from the 3rd line onward as pointed out by @Fishbane in the comments Just to check my answer I substituted $x = 0.000000001$ and so on, on my calculator just to be sure, but I got the result to be $0$ . Believing it to be some kind of error I used WolframAlpha's calculator as well and got the same result, $0$ . What is the reason for this difference?","So I was trying to find the limit of the following expression. When using the L'Hospital's rule I got the answer . My steps: Edit: My steps are incorrect from the 3rd line onward as pointed out by @Fishbane in the comments Just to check my answer I substituted and so on, on my calculator just to be sure, but I got the result to be . Believing it to be some kind of error I used WolframAlpha's calculator as well and got the same result, . What is the reason for this difference?",\lim_{x\to 0} \frac{\tan x - \sin x}{\sin^3 x} \frac {1}{2} \lim_{x\to 0} \frac{\tan x - \sin x}{\sin^3 x}  =\lim_{x\to 0} \frac{\sec^2 x - \cos x}{3\sin^2 x \cos x} =\lim_{x\to 0} \frac{2 \sec^2 x \tan x + \sin x}{6\sin x \cos^2 x} =\lim_{x\to 0} \left(\frac{2 \sec^2 x \tan x}{6\sin x \cos^2 x}+\frac{\sin x}{6\sin x \cos^2 x}\right) =\lim_{x\to 0} \left(\frac{1}{3\cos^5 x}+\frac{1}{6\cos^2 x}\right) =\frac{1}{3}+\frac{1}{6} =\frac{1}{2} x = 0.000000001 0 0,"['calculus', 'limits']"
67,Evaluating the limit $\lim_{n \to \infty} \left[\log(n) + 2n \log(4n + 2) - \sum_{k = 1}^{2n} (-1)^k (2k+1)\log(2k+1)\right]$,Evaluating the limit,\lim_{n \to \infty} \left[\log(n) + 2n \log(4n + 2) - \sum_{k = 1}^{2n} (-1)^k (2k+1)\log(2k+1)\right],"I am trying to show that the limit $$\lim_{n \to \infty} \left[\log(n) + 2n \log(4n+2) - \sum_{k=1}^{2n} (-1)^k (2k+1) \log(2k + 1)\right] = \frac{2G}{\pi} - \log(4)$$ where $G$ is Catalan's constant. My attempt was to turn the partial sum into a product: \begin{align*} \sum_{k=1}^{2n} (-1)^n (2k+1) \log(2k + 1) &= \log\left(\prod_{k=1}^{2n}(2k+1)^{(-1)^k(2k+1)} \right). \end{align*} \begin{align*} a_n := \prod_{k=1}^{2n}(2k+1)^{(-1)^k(2k+1)} \end{align*} \begin{align*} a_n  &= \frac{\left(\prod_{k=1}^{n} (4k+1)^{(4k+1)}\right)^2}{\prod_{k=1}^{2n} (2k+1)^{(2k+1)}} \\ &=\frac{\left(\prod_{k=1}^{n} (4k+1)^{(4k+1)}\right)^2}{\prod_{k=1}^{2n} (2k+1)^{(2k+1)}} \cdot \frac{4^{n (2 n+1)} (H(2 n))^2}{\prod_{k = 1}^{2n} (2n)^{2n}} \quad \quad \Big[H(n) = \text{the hyperfactorial} \Big]\\ &= \frac{4^{n (2 n+1)} (H(2 n))^2}{H(4n+1)}\left(\prod_{k=1}^{n} (4k+1)^{(4k+1)}\right)^2. \end{align*} Another attempt, I considered using the following definition of the gamma function $$\Gamma(x + 1) = \lim_{n \to \infty} \frac{n^x}{\prod_{k = 1}^n \left(1 + \frac{x}{k} \right)},$$ but I was unable to fund any helpful algebraic moves. I also considered using Abel's summation formula to simplify the partial sum down to a closed form, but quickly realized it was not helpful. From here, I was unable to find a closed form. I also found this paper that I believe may be relevant to this problem. A note on products involving ζ(3) and Catalan’s constant . Are there any algebraic moves that can be done using the gamma function's infinite product representation to derive the result? Is it possible there is an asymptotic formula that can be substituted in to evaluate this limit? Is there a better way to evaluate this limit? If so, what can be done?","I am trying to show that the limit where is Catalan's constant. My attempt was to turn the partial sum into a product: Another attempt, I considered using the following definition of the gamma function but I was unable to fund any helpful algebraic moves. I also considered using Abel's summation formula to simplify the partial sum down to a closed form, but quickly realized it was not helpful. From here, I was unable to find a closed form. I also found this paper that I believe may be relevant to this problem. A note on products involving ζ(3) and Catalan’s constant . Are there any algebraic moves that can be done using the gamma function's infinite product representation to derive the result? Is it possible there is an asymptotic formula that can be substituted in to evaluate this limit? Is there a better way to evaluate this limit? If so, what can be done?","\lim_{n \to \infty} \left[\log(n) + 2n \log(4n+2) - \sum_{k=1}^{2n} (-1)^k (2k+1) \log(2k + 1)\right] = \frac{2G}{\pi} - \log(4) G \begin{align*}
\sum_{k=1}^{2n} (-1)^n (2k+1) \log(2k + 1)
&= \log\left(\prod_{k=1}^{2n}(2k+1)^{(-1)^k(2k+1)} \right).
\end{align*} \begin{align*}
a_n := \prod_{k=1}^{2n}(2k+1)^{(-1)^k(2k+1)}
\end{align*} \begin{align*}
a_n 
&= \frac{\left(\prod_{k=1}^{n} (4k+1)^{(4k+1)}\right)^2}{\prod_{k=1}^{2n} (2k+1)^{(2k+1)}} \\
&=\frac{\left(\prod_{k=1}^{n} (4k+1)^{(4k+1)}\right)^2}{\prod_{k=1}^{2n} (2k+1)^{(2k+1)}} \cdot \frac{4^{n (2 n+1)} (H(2 n))^2}{\prod_{k = 1}^{2n} (2n)^{2n}} \quad \quad \Big[H(n) = \text{the hyperfactorial} \Big]\\
&= \frac{4^{n (2 n+1)} (H(2 n))^2}{H(4n+1)}\left(\prod_{k=1}^{n} (4k+1)^{(4k+1)}\right)^2.
\end{align*} \Gamma(x + 1) = \lim_{n \to \infty} \frac{n^x}{\prod_{k = 1}^n \left(1 + \frac{x}{k} \right)},","['calculus', 'limits', 'summation', 'logarithms', 'infinite-product']"
68,"Original source of ""precise"" ε-δ (epsilon-delta) formal definition of a limit?","Original source of ""precise"" ε-δ (epsilon-delta) formal definition of a limit?",,"I frequently see Karl Weierstrass credited for formulating the precise definition of a limit. But what I'd like to know is the origin of the formal definition so common in textbooks, that given a continuous function $f : ℝ → ℝ$ , for all $x$ of its domain within the neighbourhood of a constant c (i.e., any point limit of $x$ ), \begin{align*} (\lim_{x→\textrm{c}} f(x) = \textrm{L})  &≜ ∀\, ε \in ℝ_{>0} : ∃\, δ \in ℝ_{>0} : ∀\, x ∈ \textrm{DOMAIN}\ f : \\ &\qquad 0 < \left|x - \textrm{c}\right| < δ ⇒ \left|f(x) - \textrm{L}\right| < ε \end{align*} The Stanford Encyclopedia of Philosophy's ""Continuity and Infinitesimals"" credits Weierstrass but cites Heine, and then only for the formal definition of a $\textit{continuous}$ function. Anyone know more history on this or Weierstrass's original publication? Did he use Gottlob Frege's notation or some other kind?","I frequently see Karl Weierstrass credited for formulating the precise definition of a limit. But what I'd like to know is the origin of the formal definition so common in textbooks, that given a continuous function , for all of its domain within the neighbourhood of a constant c (i.e., any point limit of ), The Stanford Encyclopedia of Philosophy's ""Continuity and Infinitesimals"" credits Weierstrass but cites Heine, and then only for the formal definition of a function. Anyone know more history on this or Weierstrass's original publication? Did he use Gottlob Frege's notation or some other kind?","f : ℝ → ℝ x x \begin{align*}
(\lim_{x→\textrm{c}} f(x) = \textrm{L})  &≜ ∀\, ε \in ℝ_{>0} : ∃\, δ \in ℝ_{>0} : ∀\, x ∈ \textrm{DOMAIN}\ f : \\
&\qquad 0 < \left|x - \textrm{c}\right| < δ ⇒ \left|f(x) - \textrm{L}\right| < ε
\end{align*} \textit{continuous}","['calculus', 'limits', 'epsilon-delta', 'math-history']"
69,Radical of Infinite Product of Primes,Radical of Infinite Product of Primes,,"I somehow stumbled across this thing. $$\lim_{n \to \infty}({p_1\times p_2\times p_3\times\cdots \times p_n})^{\frac{1}{p_n}}$$ Where $p_i$ is the $i$ -th prime. I wanted to know if this converges or not. So I wrote a python program, and computed it up to $n = 300000$ and got this: $2.7168952344276653$ , with $p_n = 4256249$ It seems to approach $e$ , but that doesn't make sense, $e$ doesn't have anything to do with prime numbers. It was converging extremely slowly, and the program was also very slow, so I wasn't able to compute it for higher values of $n$ . I want to know what this limit approach?","I somehow stumbled across this thing. Where is the -th prime. I wanted to know if this converges or not. So I wrote a python program, and computed it up to and got this: , with It seems to approach , but that doesn't make sense, doesn't have anything to do with prime numbers. It was converging extremely slowly, and the program was also very slow, so I wasn't able to compute it for higher values of . I want to know what this limit approach?",\lim_{n \to \infty}({p_1\times p_2\times p_3\times\cdots \times p_n})^{\frac{1}{p_n}} p_i i n = 300000 2.7168952344276653 p_n = 4256249 e e n,"['limits', 'prime-numbers', 'analytic-number-theory', 'radicals', 'infinite-product']"
70,Finding $n$ such that $\frac{n+1}{n}$ < $\frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}}$,Finding  such that  <,n \frac{n+1}{n} \frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}},"I have been thinking about this limit: $$\lim\limits_{n \rightarrow \infty}\frac{n}{\sqrt[n]{n!}} = e$$ Using a spreadsheet, I noticed that for $0 < n \le 150, \frac{n+1}{n} > \frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}}$ . The difference $\frac{n+1}{n} - \frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}}$ is strictly decreasing as $n$ increases. I wondered if there exists an integer $k$ such that if $n \ge k$ , then $\frac{n+1}{n} < \frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}}$ What would be a standard way to determine if $k$ exists?  And if $k$ exists, what would be a standard way to determine $k$ ? I suspect that there is a simple way to approach this question without using the gamma function . Am I right? Or does the determination of $k$ require using the gamma function?","I have been thinking about this limit: Using a spreadsheet, I noticed that for . The difference is strictly decreasing as increases. I wondered if there exists an integer such that if , then What would be a standard way to determine if exists?  And if exists, what would be a standard way to determine ? I suspect that there is a simple way to approach this question without using the gamma function . Am I right? Or does the determination of require using the gamma function?","\lim\limits_{n \rightarrow \infty}\frac{n}{\sqrt[n]{n!}} = e 0 < n \le 150, \frac{n+1}{n} > \frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}} \frac{n+1}{n} - \frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}} n k n \ge k \frac{n+1}{n} < \frac{\sqrt[n+1]{(n+1)!}}{\sqrt[n]{n!}} k k k k","['limits', 'inequality', 'radicals', 'factorial']"
71,Proving $\lim_{x \to \infty} \frac{\sum_{n=1}^{\infty}\frac{x^n}{n!}\sqrt{x}}{\sum_{n=1}^{\infty}\frac{x^n}{n!}\sqrt{n}} = 1$ [duplicate],Proving  [duplicate],\lim_{x \to \infty} \frac{\sum_{n=1}^{\infty}\frac{x^n}{n!}\sqrt{x}}{\sum_{n=1}^{\infty}\frac{x^n}{n!}\sqrt{n}} = 1,"This question already has answers here : How does this series scale ? (A fractional Touchard polynomial) (3 answers) Elementary asymptotics of $\sum_{k=0}^\infty \sqrt k \frac{x^k}{k!}$ as $x\to \infty$ (1 answer) Closed 2 years ago . As part of solving a problem, I am trying to prove the following identity: $$\lim_{x \to \infty }\dfrac{\sum_{n=1}^{\infty}\dfrac{x^n}{n!}\sqrt{x}}{\sum_{n=1}^{\infty}\dfrac{x^n}{n!}\sqrt{n}} = 1$$ Intuitively, I can understand why this is true. But I don't know how to make a rigorous argument to prove it. For small $n \ll x$ , $\frac{x^n}{n!}$ does not contribute to the sums as the terms with a higher power in $x$ dominate. As well, for $n \gg x$ , the denominator $n!$ dominates and the fractions become far too small. So the main contributors to the sum are the ones with $n$ at $n\approx \text{ceil}\left[x\right]$ or $n \approx \text{floor}\left[x\right]$ , at which $\dfrac{x^n}{n!}$ is maximized. Say the width of this region is $\Delta W$ . My guess at making this argument concrete, is that we have to prove that the contribution to the sum outside this interval $[x-\Delta W/2, x+\Delta W/2]$ is bounded above by an arbitrary $\epsilon/2$ , and inside the interval $\sqrt{x/n}$ differs from $1$ at most by $\epsilon/\Delta W$ .","This question already has answers here : How does this series scale ? (A fractional Touchard polynomial) (3 answers) Elementary asymptotics of $\sum_{k=0}^\infty \sqrt k \frac{x^k}{k!}$ as $x\to \infty$ (1 answer) Closed 2 years ago . As part of solving a problem, I am trying to prove the following identity: Intuitively, I can understand why this is true. But I don't know how to make a rigorous argument to prove it. For small , does not contribute to the sums as the terms with a higher power in dominate. As well, for , the denominator dominates and the fractions become far too small. So the main contributors to the sum are the ones with at or , at which is maximized. Say the width of this region is . My guess at making this argument concrete, is that we have to prove that the contribution to the sum outside this interval is bounded above by an arbitrary , and inside the interval differs from at most by .","\lim_{x \to \infty }\dfrac{\sum_{n=1}^{\infty}\dfrac{x^n}{n!}\sqrt{x}}{\sum_{n=1}^{\infty}\dfrac{x^n}{n!}\sqrt{n}} = 1 n \ll x \frac{x^n}{n!} x n \gg x n! n n\approx \text{ceil}\left[x\right] n \approx \text{floor}\left[x\right] \dfrac{x^n}{n!} \Delta W [x-\Delta W/2, x+\Delta W/2] \epsilon/2 \sqrt{x/n} 1 \epsilon/\Delta W","['real-analysis', 'limits', 'convergence-divergence']"
72,"$x_{n+1}=\log(1+x_n)$, then how can I solve $\lim{nx_n}$ within high-school level?",", then how can I solve  within high-school level?",x_{n+1}=\log(1+x_n) \lim{nx_n},"Given $x_{n+1}=\log(1+x_n)$ , I know $x_n\to0$ because if $\lim x_n=\alpha$ , then $\alpha=\log(1+\alpha)$ . And using Stolz-Cesaro Theorem, then $\lim nx_n=\lim\frac{x_nx_{n+1}}{x_n-x_{n+1}}$ , and it can be changed as $\lim_{t\to0}\frac{t\log(1+t)}{t-\log(1+t)}$ . It is not difficult to see that this value is 2.(Using L'Hopital, Talyor... etc.) But, how about high-school level? I don't know any other way not to use the Stolz-Cesaro theorem. Please help me if you know how to solve this in high school level.","Given , I know because if , then . And using Stolz-Cesaro Theorem, then , and it can be changed as . It is not difficult to see that this value is 2.(Using L'Hopital, Talyor... etc.) But, how about high-school level? I don't know any other way not to use the Stolz-Cesaro theorem. Please help me if you know how to solve this in high school level.",x_{n+1}=\log(1+x_n) x_n\to0 \lim x_n=\alpha \alpha=\log(1+\alpha) \lim nx_n=\lim\frac{x_nx_{n+1}}{x_n-x_{n+1}} \lim_{t\to0}\frac{t\log(1+t)}{t-\log(1+t)},"['calculus', 'limits', 'limits-without-lhopital']"
73,Euler constant as limit of zeta function,Euler constant as limit of zeta function,,"I want to prove that $ \lim \limits_{s \to 0} (\zeta(1+s)+\zeta(1-s))= 2\gamma$ , I divide it to two limits, $\lim \limits_{s \to 1^{+}} (\zeta(s)-\frac{1}{s-1}) = \gamma$ which I proved using the definition for $\gamma = H(\infty)-\ln (\infty)$ and $\zeta(s) = \sum \limits_{n=1}^{\infty} n^{-s} $ for $s>1$ but the definition of $\zeta(s)$ fails when evaluating $\lim \limits_{s\to 1^{-}} (\zeta(s)-\frac{1}{s-1})$ , so I want to use $\zeta(s) = \frac{1}{1-2^{-s}} \sum \limits_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^s}$ for $s>0$ , the problem for me now is that this new definition does not easily transform to the definition of $\gamma = \lim \limits_{n \to \infty } (H_n -\ln n)$ , I want to see a proof of the case when $s\to 1^{-}$ ? Thanks","I want to prove that , I divide it to two limits, which I proved using the definition for and for but the definition of fails when evaluating , so I want to use for , the problem for me now is that this new definition does not easily transform to the definition of , I want to see a proof of the case when ? Thanks", \lim \limits_{s \to 0} (\zeta(1+s)+\zeta(1-s))= 2\gamma \lim \limits_{s \to 1^{+}} (\zeta(s)-\frac{1}{s-1}) = \gamma \gamma = H(\infty)-\ln (\infty) \zeta(s) = \sum \limits_{n=1}^{\infty} n^{-s}  s>1 \zeta(s) \lim \limits_{s\to 1^{-}} (\zeta(s)-\frac{1}{s-1}) \zeta(s) = \frac{1}{1-2^{-s}} \sum \limits_{n=1}^{\infty} \frac{(-1)^{n+1}}{n^s} s>0 \gamma = \lim \limits_{n \to \infty } (H_n -\ln n) s\to 1^{-},"['limits', 'summation', 'riemann-zeta', 'euler-mascheroni-constant']"
74,Determine the limit using Taylor expansions:,Determine the limit using Taylor expansions:,,"I struggle with this one—maybe someone could point me in the right direction. $$\lim_{x\to 0} \frac{5^{(1+\tan^2x)} -5}{1-\cos^2x}$$ Getting the Taylor series expansion for $\tan^2x$ and $\sin^2x$ is no problem, but I struggle with getting further along at this step: $$\frac{5^1 \cdot 5^{x^2} \cdot 5^{(2/3)x^4} -5}{x^2 - \frac{x^4}3}$$ Any help would be greatly appreciated!","I struggle with this one—maybe someone could point me in the right direction. Getting the Taylor series expansion for and is no problem, but I struggle with getting further along at this step: Any help would be greatly appreciated!",\lim_{x\to 0} \frac{5^{(1+\tan^2x)} -5}{1-\cos^2x} \tan^2x \sin^2x \frac{5^1 \cdot 5^{x^2} \cdot 5^{(2/3)x^4} -5}{x^2 - \frac{x^4}3},"['limits', 'taylor-expansion']"
75,Is it true that $ \lim_{x\to0}\frac{f'\left(x\right)-\frac{f\left(x\right)-f\left(0\right)}{x}}{x}=\frac{f''\left(0\right)}{2} $ [duplicate],Is it true that  [duplicate], \lim_{x\to0}\frac{f'\left(x\right)-\frac{f\left(x\right)-f\left(0\right)}{x}}{x}=\frac{f''\left(0\right)}{2} ,"This question already has answers here : Let f be a function twice differentiable and with derivatives continuous on an interval $[a,b]$ containing $0$. Prove the following statement: (3 answers) Closed 3 years ago . Let $ f $ be a function such that $ f'' $ exists at $ x=0 $ . Is it true that : $$ \lim_{x\to0}\frac{f'\left(x\right)-\frac{f\left(x\right)-f\left(0\right)}{x}}{x}=\frac{f''\left(0\right)}{2} ~~?$$ Im pretty sure that in order for this to be true, $ f'' $ should be continuous, which is not given. But I'm struggling to find a counterexample. I need to find a function that is twice differentiable, but $ f'' $ is not continuous (assuming I understood the situation). I'd appreciate some help. Thanks in advance.","This question already has answers here : Let f be a function twice differentiable and with derivatives continuous on an interval $[a,b]$ containing $0$. Prove the following statement: (3 answers) Closed 3 years ago . Let be a function such that exists at . Is it true that : Im pretty sure that in order for this to be true, should be continuous, which is not given. But I'm struggling to find a counterexample. I need to find a function that is twice differentiable, but is not continuous (assuming I understood the situation). I'd appreciate some help. Thanks in advance.", f   f''   x=0   \lim_{x\to0}\frac{f'\left(x\right)-\frac{f\left(x\right)-f\left(0\right)}{x}}{x}=\frac{f''\left(0\right)}{2} ~~?  f''   f'' ,"['calculus', 'limits', 'derivatives']"
76,Characterization of Uniform Continuity,Characterization of Uniform Continuity,,"If $f:X \to Y$ is uniformly continuous, then there exists $\omega : (0, +\infty) \to (0, +\infty)$ with $\lim \limits_{t \to 0^+} \omega(t) = 0$ such that $d_Y(f(x), f(x')) < \omega(d_X(x, x'))$ . I am trying to come up with such an $\omega$ function. \begin{equation*}     \omega(t) =t +  \sup \limits_{x \in X, x' \in X} \{d_Y(f(x), f(x')) : d_X(x, x') < t \} \end{equation*} I don't know if it makes sense. There will probably be some issues with $\sup$ . Can anyone suggest improvements/corrections? Thanks.","If is uniformly continuous, then there exists with such that . I am trying to come up with such an function. I don't know if it makes sense. There will probably be some issues with . Can anyone suggest improvements/corrections? Thanks.","f:X \to Y \omega : (0, +\infty) \to (0, +\infty) \lim \limits_{t \to 0^+} \omega(t) = 0 d_Y(f(x), f(x')) < \omega(d_X(x, x')) \omega \begin{equation*}
    \omega(t) =t +  \sup \limits_{x \in X, x' \in X} \{d_Y(f(x), f(x')) : d_X(x, x') < t \}
\end{equation*} \sup","['real-analysis', 'limits', 'uniform-continuity']"
77,Proof using derivative information to find limit,Proof using derivative information to find limit,,"This is the last exercise of a quite challenging exercises paper a friend who is taking calculus has which I'm trying to help. I already helped her doing the other bunch. But this got me. I will appreciate anyone help to see my work and to tell me if is right or If I need to correct something. The exercise is: If $f'(a)=1$ for $a>0$ , find $\lim_{x \to a} \frac{f(x)-f(a)}{\sqrt{x}-\sqrt{a}}$ . What came to my mind was to rationalize the denominator. $$\lim_{x \to a} \frac{f(x)-f(a)}{\sqrt{x}-\sqrt{a}}$$ $$=\lim_{x \to a} \frac{f(x)-f(a)}{\sqrt{x}-\sqrt{a}}\cdot \frac{\sqrt{x}+\sqrt{a}}{\sqrt{x}+\sqrt{a}}$$ $$=\lim_{x \to a} \frac{(f(x)-f(a))(\sqrt{x}+\sqrt{a})}{x-a}$$ $$=\lim_{x \to a} \left(\frac{f(x)-f(a)}{x-a}\cdot (\sqrt{x}+\sqrt{a})\right)$$ $$=\lim_{x \to a} \frac{f(x)-f(a)}{x-a}\cdot \lim_{x \to a}(\sqrt{x}+\sqrt{a})$$ $$=f'(a)\cdot \lim_{x \to a}(\sqrt{x}+\sqrt{a})$$ $$=1\cdot \lim_{x \to a}(\sqrt{x}+\sqrt{a})$$ $$=\lim_{x \to a}(\sqrt{x}+\sqrt{a})$$ $$=\sqrt{a}+\sqrt{a}$$ $$=2\sqrt{a}$$","This is the last exercise of a quite challenging exercises paper a friend who is taking calculus has which I'm trying to help. I already helped her doing the other bunch. But this got me. I will appreciate anyone help to see my work and to tell me if is right or If I need to correct something. The exercise is: If for , find . What came to my mind was to rationalize the denominator.",f'(a)=1 a>0 \lim_{x \to a} \frac{f(x)-f(a)}{\sqrt{x}-\sqrt{a}} \lim_{x \to a} \frac{f(x)-f(a)}{\sqrt{x}-\sqrt{a}} =\lim_{x \to a} \frac{f(x)-f(a)}{\sqrt{x}-\sqrt{a}}\cdot \frac{\sqrt{x}+\sqrt{a}}{\sqrt{x}+\sqrt{a}} =\lim_{x \to a} \frac{(f(x)-f(a))(\sqrt{x}+\sqrt{a})}{x-a} =\lim_{x \to a} \left(\frac{f(x)-f(a)}{x-a}\cdot (\sqrt{x}+\sqrt{a})\right) =\lim_{x \to a} \frac{f(x)-f(a)}{x-a}\cdot \lim_{x \to a}(\sqrt{x}+\sqrt{a}) =f'(a)\cdot \lim_{x \to a}(\sqrt{x}+\sqrt{a}) =1\cdot \lim_{x \to a}(\sqrt{x}+\sqrt{a}) =\lim_{x \to a}(\sqrt{x}+\sqrt{a}) =\sqrt{a}+\sqrt{a} =2\sqrt{a},"['calculus', 'limits', 'derivatives']"
78,"Limit of $\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor$, as $x$ goes to zero","Limit of , as  goes to zero",\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor x,Find $\lim\limits_{x\to 0^+}\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor$ and $\lim\limits_{x\to 0^-}\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor$ ? See the plot of the function in GeoGebra. In the chart it seems that $\lim\limits_{x\to 0^+}\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor=0$ and $\lim\limits_{x\to 0^-}\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor=1$ but I don't know how to prove it.,Find and ? See the plot of the function in GeoGebra. In the chart it seems that and but I don't know how to prove it.,\lim\limits_{x\to 0^+}\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor \lim\limits_{x\to 0^-}\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor \lim\limits_{x\to 0^+}\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor=0 \lim\limits_{x\to 0^-}\left\lfloor x \left\lfloor \frac1x \right\rfloor \right\rfloor=1,"['limits', 'ceiling-and-floor-functions']"
79,Compute $\lim\limits_{x \to +\infty}\frac{\ln x}{ \int_0^x \frac{|\sin t|}{t}{\rm d}t}$,Compute,\lim\limits_{x \to +\infty}\frac{\ln x}{ \int_0^x \frac{|\sin t|}{t}{\rm d}t},"Problem Compute $$\lim\limits_{x \to +\infty}\dfrac{\ln x}{\displaystyle \int_0^x \dfrac{|\sin t|}{t}{\rm d}t}.$$ Comment Maybe, we can solve it by L'Hospital's rule , but there still exists a difficulty here. Though $x \to +\infty$ implies $\ln x \to +\infty$ ,  we do not know the limit of the denominator. How to solve it?","Problem Compute Comment Maybe, we can solve it by L'Hospital's rule , but there still exists a difficulty here. Though implies ,  we do not know the limit of the denominator. How to solve it?",\lim\limits_{x \to +\infty}\dfrac{\ln x}{\displaystyle \int_0^x \dfrac{|\sin t|}{t}{\rm d}t}. x \to +\infty \ln x \to +\infty,"['calculus', 'limits', 'trigonometry', 'definite-integrals']"
80,"About the limit $\lim_{n \to +\infty} \frac{1}{n^2} \sum_{1 \le a,b \le n} \frac{1}{ \mathrm{gcd} (a,b)} $",About the limit,"\lim_{n \to +\infty} \frac{1}{n^2} \sum_{1 \le a,b \le n} \frac{1}{ \mathrm{gcd} (a,b)} ","This is not homework. My question is: Prove or disprove: $$\lim_{n \to +\infty} \frac{1}{n^2} \sum_{a,b=1}^n \frac{1}{ \mathrm{gcd} (a,b)} = \frac{\zeta(3)}{\zeta(2)}$$ This would represent the probability as $n \to +\infty$ that, after having picked randomly $a,b,c \in \{ 1, \dots ,n \}$ , the line $$ax+by+c=0$$ has some integer coordinate point $(x,y \in \Bbb Z^2)$ . Indeed, fixed $a,b \in \{ 1, \dots ,n \}$ , then $c=-ax-by$ for some $x,y \in \Bbb Z$ is equivalent to $$c \mathrm{\  is  \ a\  multiple\  of\  gcd}(a,b)$$ because of Bezout identity; this event happens with probability $1/\gcd (a,b)$ . What I tried first: clearly $$0 \le \frac{1}{n^2} \sum_{a,b=1}^n \frac{1}{ \mathrm{gcd} (a,b)} \le \frac{1}{n^2} \sum_{a,b=1}^n 1 = 1$$ so, our limit belongs to $[0,1]$ (if it exists). Then I made some euristic argument: I know that the probability, as $n \to +\infty$ , that two random numbers $a,b\in \{ 1, \dots ,n \}$ are coprime is $$\zeta(2)^{-1} = \frac{6}{\pi^2},$$ thus the probability that $\gcd(a,b)=d$ is equal to $$\frac{\zeta(2)^{-1}}{d^2} = \frac{6}{d^2\pi^2}$$ Thus our probability is (and here is where I have doubts in my argument) $$\sum_{d=1}^n \ \frac{\zeta(2)^{-1}}{d^2} \to \frac{1}{\zeta(2)} \cdot \zeta(2) =1$$ EDIT: or maybe my last step should be $$\sum_{d=1}^n \ \frac{\zeta(2)^{-1}}{d^2} \frac{1}{d} \to \frac{\zeta(3)}{\zeta(2)}$$","This is not homework. My question is: Prove or disprove: This would represent the probability as that, after having picked randomly , the line has some integer coordinate point . Indeed, fixed , then for some is equivalent to because of Bezout identity; this event happens with probability . What I tried first: clearly so, our limit belongs to (if it exists). Then I made some euristic argument: I know that the probability, as , that two random numbers are coprime is thus the probability that is equal to Thus our probability is (and here is where I have doubts in my argument) EDIT: or maybe my last step should be","\lim_{n \to +\infty} \frac{1}{n^2} \sum_{a,b=1}^n \frac{1}{ \mathrm{gcd} (a,b)} = \frac{\zeta(3)}{\zeta(2)} n \to +\infty a,b,c \in \{ 1, \dots ,n \} ax+by+c=0 (x,y \in \Bbb Z^2) a,b \in \{ 1, \dots ,n \} c=-ax-by x,y \in \Bbb Z c \mathrm{\  is  \ a\  multiple\  of\  gcd}(a,b) 1/\gcd (a,b) 0 \le \frac{1}{n^2} \sum_{a,b=1}^n \frac{1}{ \mathrm{gcd} (a,b)} \le \frac{1}{n^2} \sum_{a,b=1}^n 1 = 1 [0,1] n \to +\infty a,b\in \{ 1, \dots ,n \} \zeta(2)^{-1} = \frac{6}{\pi^2}, \gcd(a,b)=d \frac{\zeta(2)^{-1}}{d^2} = \frac{6}{d^2\pi^2} \sum_{d=1}^n \ \frac{\zeta(2)^{-1}}{d^2} \to \frac{1}{\zeta(2)} \cdot \zeta(2) =1 \sum_{d=1}^n \ \frac{\zeta(2)^{-1}}{d^2} \frac{1}{d} \to \frac{\zeta(3)}{\zeta(2)}","['number-theory', 'limits', 'gcd-and-lcm', 'probability-limit-theorems']"
81,Prove $\frac{x+1}{x-1}\ln x \geq 2$,Prove,\frac{x+1}{x-1}\ln x \geq 2,"I'm trying to get back to maths after quite a pause, and I've solved a question in a way that does not satisfy me. I'm pretty sure there is a nicer way to go and I'd like your opinion. $\forall x \in \Bbb R_+\setminus \lbrace 0; 1\rbrace$ , $\quad $ $\frac{x+1}{x-1}\ln x \geq 2$ Let $f (x) = \frac{x+1}{x-1}\ln x$ defined on $\Bbb R_+\setminus \lbrace 0; 1\rbrace$ Then $$f'(x) = \frac{x^2-2x\ln x-1}{x(x-1)^2} = \frac{x-2\ln x-\frac 1x}{(x-1)^2}$$ which has the same sign as $$g(x) = x-2\ln x - \frac 1x$$ Since $$g'(x) = 1-\frac 2x + \frac{1}{x^2} = (1-\frac 1x)^2$$ $g$ is increasing over $\Bbb R_+$ , and since $g(1)= 0$ , $g(x)\leq 0$ for $0\leq x\leq 1$ and $g(x) \geq 0$ for $x\geq 1$ ; and so is $f'$ . Thus $f$ is decreasing on $]0; 1[$ and increasing on $]1; +\infty[$ . Now $$\lim_{x\to 1} \frac{\ln x}{x-1} =\lim_{x\to 1}\frac{\ln x -\ln 1}{x-1} = (\ln x)'(1)  = 1 $$ and thus $$\lim_{x\to 1} f(x) =  \lim_{x\to 1}(x+1)\frac{\ln x}{x-1}= 2$$ And thus $\forall x \in \Bbb R_+\setminus \lbrace 0; 1\rbrace$ , $f(x) \geq 2 \quad \blacksquare$","I'm trying to get back to maths after quite a pause, and I've solved a question in a way that does not satisfy me. I'm pretty sure there is a nicer way to go and I'd like your opinion. , Let defined on Then which has the same sign as Since is increasing over , and since , for and for ; and so is . Thus is decreasing on and increasing on . Now and thus And thus ,",\forall x \in \Bbb R_+\setminus \lbrace 0; 1\rbrace \quad  \frac{x+1}{x-1}\ln x \geq 2 f (x) = \frac{x+1}{x-1}\ln x \Bbb R_+\setminus \lbrace 0; 1\rbrace f'(x) = \frac{x^2-2x\ln x-1}{x(x-1)^2} = \frac{x-2\ln x-\frac 1x}{(x-1)^2} g(x) = x-2\ln x - \frac 1x g'(x) = 1-\frac 2x + \frac{1}{x^2} = (1-\frac 1x)^2 g \Bbb R_+ g(1)= 0 g(x)\leq 0 0\leq x\leq 1 g(x) \geq 0 x\geq 1 f' f ]0; 1[ ]1; +\infty[ \lim_{x\to 1} \frac{\ln x}{x-1} =\lim_{x\to 1}\frac{\ln x -\ln 1}{x-1} = (\ln x)'(1)  = 1  \lim_{x\to 1} f(x) =  \lim_{x\to 1}(x+1)\frac{\ln x}{x-1}= 2 \forall x \in \Bbb R_+\setminus \lbrace 0; 1\rbrace f(x) \geq 2 \quad \blacksquare,"['real-analysis', 'limits', 'derivatives', 'inequality']"
82,Evaluating the limit : $ \lim_{n \to \infty} \frac{ \sum_{k=1}^n n^k}{ \sum_{k=1}^n k^n}$,Evaluating the limit :, \lim_{n \to \infty} \frac{ \sum_{k=1}^n n^k}{ \sum_{k=1}^n k^n},Here I'm given this limit. $$\displaystyle \lim_{n \to \infty} \dfrac{\displaystyle \sum_{k=1}^n n^k}{\displaystyle \sum_{k=1}^n k^n}$$ $\displaystyle \sum_{k=1}^n n^k$ simplifies to $\dfrac{n(n^n-1)}{n-1}$ but I'm unable to tackle $\displaystyle \sum_{k=1}^n k^n$ . How do you evaluate this limit?,Here I'm given this limit. simplifies to but I'm unable to tackle . How do you evaluate this limit?,\displaystyle \lim_{n \to \infty} \dfrac{\displaystyle \sum_{k=1}^n n^k}{\displaystyle \sum_{k=1}^n k^n} \displaystyle \sum_{k=1}^n n^k \dfrac{n(n^n-1)}{n-1} \displaystyle \sum_{k=1}^n k^n,['limits']
83,"[Stuck]: Final step of solving limit, Calculus I","[Stuck]: Final step of solving limit, Calculus I",,"Calculate the value of $k$ such that the following limit has a finite solution, $L$ such that $L \ne 0$: $$\lim_{x\rightarrow0} \frac{(e^{x^2}-x^2-1)(\cos(x)-1)}{x^k}$$ I use the Taylor Series expansions of $e^x$ and $\cos(x)$ and simplify the above expression to the following: $$\lim_{x\rightarrow0} \frac{-\frac{1}{4}x^6+(\frac{1}{48}-\frac{1}{12})x^8+(\frac{1}{144})x^{10}}{x^k}$$ Now I have a mental roadblock. For $k<6$ the above limit goes to zero and for $k>6$ this expression should diverge but in my head it goes to zero again.... I am trying to think of a simple example to convince myself but can't. Can someone please help me understand this? Thanks.","Calculate the value of $k$ such that the following limit has a finite solution, $L$ such that $L \ne 0$: $$\lim_{x\rightarrow0} \frac{(e^{x^2}-x^2-1)(\cos(x)-1)}{x^k}$$ I use the Taylor Series expansions of $e^x$ and $\cos(x)$ and simplify the above expression to the following: $$\lim_{x\rightarrow0} \frac{-\frac{1}{4}x^6+(\frac{1}{48}-\frac{1}{12})x^8+(\frac{1}{144})x^{10}}{x^k}$$ Now I have a mental roadblock. For $k<6$ the above limit goes to zero and for $k>6$ this expression should diverge but in my head it goes to zero again.... I am trying to think of a simple example to convince myself but can't. Can someone please help me understand this? Thanks.",,"['calculus', 'limits', 'taylor-expansion']"
84,Find an asymptotic for $\sum_{j=1}^N \frac{1}{1 - \cos\frac{\pi j}{N}}$,Find an asymptotic for,\sum_{j=1}^N \frac{1}{1 - \cos\frac{\pi j}{N}},"I need to find the asymptotic behavior of $$\sum_{j=1}^N \frac{1}{1 - \cos\frac{\pi j}{N}}$$ as $N\to\infty$. I found (using a computer) that this asymptotically will be equivalent to $\frac{1}{3}N^2$, but don't know how to prove it mathematically.","I need to find the asymptotic behavior of $$\sum_{j=1}^N \frac{1}{1 - \cos\frac{\pi j}{N}}$$ as $N\to\infty$. I found (using a computer) that this asymptotically will be equivalent to $\frac{1}{3}N^2$, but don't know how to prove it mathematically.",,"['limits', 'summation', 'asymptotics']"
85,Proof of product rule for limits,Proof of product rule for limits,,"Let $$\lim_{x \to a} f(x) = L$$ $$\lim_{x \to a} g(x) = M$$ Where $L$ and $M$ are finite reals. Then I want to prove that $$\lim_{x \to a} f(x) g(x) = LM$$ Let $\epsilon > 0$. We need a $\delta > 0$ such that for all $x$ we have $0 < |x-a| < \delta$ implying $|f(x)g(x) - LM| < \epsilon$. Rearrange: $$\begin{align}|f(x)g(x)-LM|&=|f(x)g(x)-Lg(x)+Lg(x)-LM|\\ &=|g(x)(f(x)-L)+L(g(x)-M)|\\ &\le|g(x)||f(x)-L|+|L||g(x)-M| \\ &\lt|g(x)||f(x)-L|+(|L| + 1)|g(x)-M| < \epsilon\end{align}$$ Since the limits for $g(x)$ and $M$ approach the same value $M$, there exists a $\delta_1 > 0$ such that for all $x$, $0 < |x-a| < \delta_1$ implies $|g(x) - M| < \frac{\epsilon}{2(|L|+1)}$. Then: $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)||f(x)-L|+(|L|+1)|g(x)-M|\\ &<|g(x)||f(x)-L|+(|L|+1)\frac{\epsilon}{2(|L|+1)}   \\ &=|g(x)||f(x)-L|+\frac{\epsilon}{2}  = \epsilon \\ \end{align}$$ Since the limits for $f(x)$ and $L$ approach the same value $L$, there exists a $\delta_2 > 0$ such that for all $x$, $0 < |x-a| < \delta_2$ implies $|f(x) - L| < \frac{\epsilon}{2(|M|+1)}$. Then: $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)||f(x)-L|+\frac{\epsilon}{2} \\ &<|g(x)|\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} = \epsilon \\ \end{align}$$ Now we prove $|g(x)| \leq |M|+1$: $$|g(x)| = |g(x) - M + M| \leq |g(x) - M| + |M| \leq |M|+1$$ Subtracting $|M|$ from both sides, we see that: $$|g(x) - M|  \leq 1$$ Since the limits for $g(x)$ and $M$ approach the same value $M$, there exists a $\delta_3$ such that for all $x$, $0 < |x-a| < \delta_3$ implies $|g(x) - M| < 1$. $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)|\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} \\ &< (|M|+1)\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} \\ &= \frac{\epsilon}{2}+\frac{\epsilon}{2} = \epsilon \\ \end{align}$$ This is true granted that we set $\delta = \min(\delta_1, \delta_2, \delta_3)$. Is my proof correct and accurate? Have I actually proved the rule?","Let $$\lim_{x \to a} f(x) = L$$ $$\lim_{x \to a} g(x) = M$$ Where $L$ and $M$ are finite reals. Then I want to prove that $$\lim_{x \to a} f(x) g(x) = LM$$ Let $\epsilon > 0$. We need a $\delta > 0$ such that for all $x$ we have $0 < |x-a| < \delta$ implying $|f(x)g(x) - LM| < \epsilon$. Rearrange: $$\begin{align}|f(x)g(x)-LM|&=|f(x)g(x)-Lg(x)+Lg(x)-LM|\\ &=|g(x)(f(x)-L)+L(g(x)-M)|\\ &\le|g(x)||f(x)-L|+|L||g(x)-M| \\ &\lt|g(x)||f(x)-L|+(|L| + 1)|g(x)-M| < \epsilon\end{align}$$ Since the limits for $g(x)$ and $M$ approach the same value $M$, there exists a $\delta_1 > 0$ such that for all $x$, $0 < |x-a| < \delta_1$ implies $|g(x) - M| < \frac{\epsilon}{2(|L|+1)}$. Then: $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)||f(x)-L|+(|L|+1)|g(x)-M|\\ &<|g(x)||f(x)-L|+(|L|+1)\frac{\epsilon}{2(|L|+1)}   \\ &=|g(x)||f(x)-L|+\frac{\epsilon}{2}  = \epsilon \\ \end{align}$$ Since the limits for $f(x)$ and $L$ approach the same value $L$, there exists a $\delta_2 > 0$ such that for all $x$, $0 < |x-a| < \delta_2$ implies $|f(x) - L| < \frac{\epsilon}{2(|M|+1)}$. Then: $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)||f(x)-L|+\frac{\epsilon}{2} \\ &<|g(x)|\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} = \epsilon \\ \end{align}$$ Now we prove $|g(x)| \leq |M|+1$: $$|g(x)| = |g(x) - M + M| \leq |g(x) - M| + |M| \leq |M|+1$$ Subtracting $|M|$ from both sides, we see that: $$|g(x) - M|  \leq 1$$ Since the limits for $g(x)$ and $M$ approach the same value $M$, there exists a $\delta_3$ such that for all $x$, $0 < |x-a| < \delta_3$ implies $|g(x) - M| < 1$. $$\begin{align}|f(x)g(x)-LM| &\lt |g(x)|\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} \\ &< (|M|+1)\frac{\epsilon}{2(|M|+1)}+\frac{\epsilon}{2} \\ &= \frac{\epsilon}{2}+\frac{\epsilon}{2} = \epsilon \\ \end{align}$$ This is true granted that we set $\delta = \min(\delta_1, \delta_2, \delta_3)$. Is my proof correct and accurate? Have I actually proved the rule?",,"['calculus', 'limits', 'proof-verification', 'proof-writing', 'epsilon-delta']"
86,How do we derive the expression for $e^x$ from $e$?,How do we derive the expression for  from ?,e^x e,"Trying to go in historical order here and begin with Bernoulli's formulation for $e$: $$e = \lim_{n \to \infty} (1 + 1/n)^n$$ How do we then make the jump to $$e^x = \lim_{n \to \infty} (1 + x/n)^n$$ I had tried doing this: $$e^x = (\lim_{n \to \infty} (1 + 1/n)^n)^x$$ $$e^x = \lim_{n \to \infty} (1 + 1/n)^{nx}$$ Let $m = nx$ so $n = m/x$. As $n$ goes to infinity, $m$ also goes to infinity, so: $$e^x = \lim_{m \to \infty} (1 + x/m)^{m}$$ (although we could relabel with $n=m$ I just use $m$ to use a different one) But I was told that I'm skipping many unproven assumptions doing this. Is there an easy way to prove what I am missing or is there an easier way to arrive at the result?","Trying to go in historical order here and begin with Bernoulli's formulation for $e$: $$e = \lim_{n \to \infty} (1 + 1/n)^n$$ How do we then make the jump to $$e^x = \lim_{n \to \infty} (1 + x/n)^n$$ I had tried doing this: $$e^x = (\lim_{n \to \infty} (1 + 1/n)^n)^x$$ $$e^x = \lim_{n \to \infty} (1 + 1/n)^{nx}$$ Let $m = nx$ so $n = m/x$. As $n$ goes to infinity, $m$ also goes to infinity, so: $$e^x = \lim_{m \to \infty} (1 + x/m)^{m}$$ (although we could relabel with $n=m$ I just use $m$ to use a different one) But I was told that I'm skipping many unproven assumptions doing this. Is there an easy way to prove what I am missing or is there an easier way to arrive at the result?",,"['calculus', 'limits', 'exponential-function', 'proof-explanation']"
87,a limit about exponential function [duplicate],a limit about exponential function [duplicate],,"This question already has answers here : Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$ (9 answers) Closed 6 years ago . $\lim_{n\rightarrow\infty}\frac{1+\frac{n}{1!}+\cdot+\frac{n^n}{n!}}{e^n}=\frac12$ Taking the first $n$ terms of the Taylor series of $e^n$ as the numerator, the limit is true or false? How to prove?","This question already has answers here : Evaluating $\lim\limits_{n\to\infty} e^{-n} \sum\limits_{k=0}^{n} \frac{n^k}{k!}$ (9 answers) Closed 6 years ago . $\lim_{n\rightarrow\infty}\frac{1+\frac{n}{1!}+\cdot+\frac{n^n}{n!}}{e^n}=\frac12$ Taking the first $n$ terms of the Taylor series of $e^n$ as the numerator, the limit is true or false? How to prove?",,"['limits', 'estimation']"
88,Evaluation of limiting value of given series,Evaluation of limiting value of given series,,"For a given sequence,  $a_1=1$ and $a_n=n(1+a_{n-1})$ $\forall n\geq 2$, then value of given limit: $$\lim_{n\to \infty} \bigg(1+\frac{1}{a_1}\bigg)\bigg(1+\frac{1}{a_2}\bigg)\cdots\bigg(1+\frac{1}{a_n}\bigg)$$ Usually such type of questions are solved by squeeze theorem or by converting them into definite integral but don't see neither working here. Could someone give me little help to proceed","For a given sequence,  $a_1=1$ and $a_n=n(1+a_{n-1})$ $\forall n\geq 2$, then value of given limit: $$\lim_{n\to \infty} \bigg(1+\frac{1}{a_1}\bigg)\bigg(1+\frac{1}{a_2}\bigg)\cdots\bigg(1+\frac{1}{a_n}\bigg)$$ Usually such type of questions are solved by squeeze theorem or by converting them into definite integral but don't see neither working here. Could someone give me little help to proceed",,"['calculus', 'limits']"
89,Limit of average of decimal digits: $\lim\frac{1}{n} (x_1 + \dots +x_n) = constant$,Limit of average of decimal digits:,\lim\frac{1}{n} (x_1 + \dots +x_n) = constant,"I have a problem to solve in Ergodic Theory, but I am stuck and have no idea how to procedure. The problem is the following. Prove that there exists a constant α such that for Lebesgue a.e. x∈[0,1] $\lim_{n\to\infty} \frac{1}{n} (x_1 + \dots + x_n) = \alpha$ where $x_1 ,...,x_n$ are digits of the decimal expansion of x meaning $x_i \in $ {0,...,9}. I have, that if $x \in Q$,  $\alpha$ is obviously 0. So if $x \in $ R\Q we can bound the limit by above by 9 and below by 1 e.g.  $\lim_{n\to\infty} \frac{1}{n} (x_1 + \dots + x_n) \leq \lim_{n\to\infty} \frac{9n}{n} = 9$. Right? But now I still have to prove it exists, how can I do that? Thanks a lot already.","I have a problem to solve in Ergodic Theory, but I am stuck and have no idea how to procedure. The problem is the following. Prove that there exists a constant α such that for Lebesgue a.e. x∈[0,1] $\lim_{n\to\infty} \frac{1}{n} (x_1 + \dots + x_n) = \alpha$ where $x_1 ,...,x_n$ are digits of the decimal expansion of x meaning $x_i \in $ {0,...,9}. I have, that if $x \in Q$,  $\alpha$ is obviously 0. So if $x \in $ R\Q we can bound the limit by above by 9 and below by 1 e.g.  $\lim_{n\to\infty} \frac{1}{n} (x_1 + \dots + x_n) \leq \lim_{n\to\infty} \frac{9n}{n} = 9$. Right? But now I still have to prove it exists, how can I do that? Thanks a lot already.",,"['limits', 'lebesgue-measure', 'decimal-expansion', 'ergodic-theory']"
90,How can I calculate the limit $\lim\limits_{x \to 7} \frac{\sqrt{x+2} - \sqrt[3]{x+20}}{\sqrt[4]{x+9} - 2}$ without L'Hospital's rule?,How can I calculate the limit  without L'Hospital's rule?,\lim\limits_{x \to 7} \frac{\sqrt{x+2} - \sqrt[3]{x+20}}{\sqrt[4]{x+9} - 2},I have a problem with calculation of the limit: $$\lim\limits_{x \to 7} \frac{\sqrt{x+2} - \sqrt[3]{x+20}}{\sqrt[4]{x+9} - 2}$$ Is there a way to calculate it? How can I do it?,I have a problem with calculation of the limit: Is there a way to calculate it? How can I do it?,\lim\limits_{x \to 7} \frac{\sqrt{x+2} - \sqrt[3]{x+20}}{\sqrt[4]{x+9} - 2},"['real-analysis', 'limits', 'limits-without-lhopital']"
91,$\epsilon-\delta$ limit proof,limit proof,\epsilon-\delta,Using the epsilon delta definition of limits prove:   $$\lim\limits_{x \to -1} \frac{x^4+x+1}{x^3}=-1.$$ I have managed to get  $$\left|{\frac{x^4+x+1}{x^3}}+1\right| =  \frac{\vert x+1\vert^2\vert x^2-x+1 \vert}{|x|^3}$$  which is a step closer I think since I have  the factor $(x+1)$ which I can control. And I can also limit the other factor in the numerator. But the $x^3$ in the denominator is my problem because if I limit $(x+1)$ it seems to grow.  I not sure what to do with it.,Using the epsilon delta definition of limits prove:   $$\lim\limits_{x \to -1} \frac{x^4+x+1}{x^3}=-1.$$ I have managed to get  $$\left|{\frac{x^4+x+1}{x^3}}+1\right| =  \frac{\vert x+1\vert^2\vert x^2-x+1 \vert}{|x|^3}$$  which is a step closer I think since I have  the factor $(x+1)$ which I can control. And I can also limit the other factor in the numerator. But the $x^3$ in the denominator is my problem because if I limit $(x+1)$ it seems to grow.  I not sure what to do with it.,,"['real-analysis', 'calculus', 'limits']"
92,Limit at infinity.,Limit at infinity.,,$$\lim _{p\to \infty }\left(p\ln \left(e\left(1+\frac{1}{p}\right)^{1-p}\right)\right)?$$ I was getting $1$ as an answer but answer is $1.5$.  I solved it like this:- $$\lim_{p\to \infty} p\ln\left(e\left(\left(1+\frac{1}{p}\right)^{\left(1-p\right)\frac{p}{p}}\right)\right)$$ $$\lim_{p\to \infty} p\ln\left(e\cdot e^{\frac{1-p}{p}}\right)$$ $$\lim_{p\to \infty} p\ln\left(e^{\frac{1}{p}}\right)$$ $$\lim_{p\to \infty}p\frac{1}{p} = 1$$ What am I doing wrong?,$$\lim _{p\to \infty }\left(p\ln \left(e\left(1+\frac{1}{p}\right)^{1-p}\right)\right)?$$ I was getting $1$ as an answer but answer is $1.5$.  I solved it like this:- $$\lim_{p\to \infty} p\ln\left(e\left(\left(1+\frac{1}{p}\right)^{\left(1-p\right)\frac{p}{p}}\right)\right)$$ $$\lim_{p\to \infty} p\ln\left(e\cdot e^{\frac{1-p}{p}}\right)$$ $$\lim_{p\to \infty} p\ln\left(e^{\frac{1}{p}}\right)$$ $$\lim_{p\to \infty}p\frac{1}{p} = 1$$ What am I doing wrong?,,"['calculus', 'limits', 'limits-without-lhopital']"
93,Evaluating $\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2}x^r \sin x dx}{\int_0^{\pi/2}x^r \cos x dx}$,Evaluating,\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2}x^r \sin x dx}{\int_0^{\pi/2}x^r \cos x dx},"The question is basically to find out the following limit($c$ is any real number) $$\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2} x^r \sin x \, dx}{\int_0^{\pi/2}x^r \cos x \, dx}$$ I tried to use the property of definite integral and rewrote it as $$\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2}(\pi/2-x)^r \cos x dx}{\int_0^{\pi/2}x^r \cos x dx}$$ and then expanded the numerator using binomial theorem.But this didnot take me to the answer.I also tried using integration by parts in the numerator but that too didnot helped me.Any hint to go ahead will be highly appreciated.Thanks.","The question is basically to find out the following limit($c$ is any real number) $$\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2} x^r \sin x \, dx}{\int_0^{\pi/2}x^r \cos x \, dx}$$ I tried to use the property of definite integral and rewrote it as $$\lim_{r \to \infty} r^c \frac{\int_0^{\pi/2}(\pi/2-x)^r \cos x dx}{\int_0^{\pi/2}x^r \cos x dx}$$ and then expanded the numerator using binomial theorem.But this didnot take me to the answer.I also tried using integration by parts in the numerator but that too didnot helped me.Any hint to go ahead will be highly appreciated.Thanks.",,['limits']
94,Evaluate by a Riemann sum: $ \lim_{n \rightarrow \infty}\left(\frac {(n+1)^m+(n+2)^m+\cdots+(n+k)^m}{n^{m-1}}-kn\right)$,Evaluate by a Riemann sum:, \lim_{n \rightarrow \infty}\left(\frac {(n+1)^m+(n+2)^m+\cdots+(n+k)^m}{n^{m-1}}-kn\right),"Evaluate: $\displaystyle \lim_{n \rightarrow \infty}\left(\frac {(n+1)^m+(n+2)^m+\cdots+(n+k)^m}{n^{m-1}}-kn\right)$ ,where $m$ and $k$ are fixed positive integers MY ATTEMPT: $\displaystyle \lim_{n \rightarrow \infty}\left(\frac {(n+1)^m+(n+2)^m+\cdots+(n+k)^m}{n^{m-1}}-kn\right)$ $=\displaystyle \lim_{n \rightarrow \infty}\left(\frac {(1+\frac 1 n)^m+(1+\frac 2 n)^m+\cdots+(1+\frac k n)^m}{n^{-1}}-kn\right)$ $=\displaystyle \lim_{n \rightarrow \infty}\sum_{i=1}^k\left(\left(1+\frac i n\right)^m-k\right)\frac 1 n$ . Here i don't know how to apply reimann sum and what will be the limit of integration. Note:Answer of the problem is $\frac{k(k+1)}{2}m$","Evaluate: ,where and are fixed positive integers MY ATTEMPT: . Here i don't know how to apply reimann sum and what will be the limit of integration. Note:Answer of the problem is",\displaystyle \lim_{n \rightarrow \infty}\left(\frac {(n+1)^m+(n+2)^m+\cdots+(n+k)^m}{n^{m-1}}-kn\right) m k \displaystyle \lim_{n \rightarrow \infty}\left(\frac {(n+1)^m+(n+2)^m+\cdots+(n+k)^m}{n^{m-1}}-kn\right) =\displaystyle \lim_{n \rightarrow \infty}\left(\frac {(1+\frac 1 n)^m+(1+\frac 2 n)^m+\cdots+(1+\frac k n)^m}{n^{-1}}-kn\right) =\displaystyle \lim_{n \rightarrow \infty}\sum_{i=1}^k\left(\left(1+\frac i n\right)^m-k\right)\frac 1 n \frac{k(k+1)}{2}m,"['real-analysis', 'limits']"
95,"Find a limit, no Taylor formula","Find a limit, no Taylor formula",,"How to find this limit: $$ \lim_{x \to +\infty} \left[ (x+a)^{1+{1\over x}}-x^{1+{1\over x+a}}\right] $$ We know L'Hopital's rule, but don't know Taylor's formula.","How to find this limit: $$ \lim_{x \to +\infty} \left[ (x+a)^{1+{1\over x}}-x^{1+{1\over x+a}}\right] $$ We know L'Hopital's rule, but don't know Taylor's formula.",,['limits']
96,Evaluate limit.,Evaluate limit.,,Let $f : \mathbb R \to \mathbb R$ be differentiable at $x = a$. Evaluate: $$ \lim_{n\to \infty}\large[{f(a +\frac{1}{n^2})}+{f(a +\frac{2}{n^2})}+...+{f(a +\frac{n}{n^2})}-nf(a)] $$   Answer: $\   $ $\ \frac{1}{2}f'(a)$ My attempt : $$ \lim_{n\to \infty}\large[{f(a +\frac{1}{n^2})}-f(a)+{f(a +\frac{2}{n^2})}-f(a)+...+{f(a +\frac{n}{n^2})}- f(a)] $$ I don't know how to proceed from here? Please just give me hint. I want to solve this question by my self. Thank you.,Let $f : \mathbb R \to \mathbb R$ be differentiable at $x = a$. Evaluate: $$ \lim_{n\to \infty}\large[{f(a +\frac{1}{n^2})}+{f(a +\frac{2}{n^2})}+...+{f(a +\frac{n}{n^2})}-nf(a)] $$   Answer: $\   $ $\ \frac{1}{2}f'(a)$ My attempt : $$ \lim_{n\to \infty}\large[{f(a +\frac{1}{n^2})}-f(a)+{f(a +\frac{2}{n^2})}-f(a)+...+{f(a +\frac{n}{n^2})}- f(a)] $$ I don't know how to proceed from here? Please just give me hint. I want to solve this question by my self. Thank you.,,"['real-analysis', 'limits', 'derivatives', 'continuity']"
97,prove $\lim_{n\to\infty}{\frac{a^n}{n!}}=0$,prove,\lim_{n\to\infty}{\frac{a^n}{n!}}=0,"I have the proof but i don't understand one part. The proof (for $a>1$) goes as follows: there exists $k \in N$ such that$a<k, \frac{a}{k}<1$ and since $\frac{a}{k+i}<\frac{a}{k}, i \in N$ $$\frac{a^n}{n!}=\frac{a}{1} \cdot \frac{a}{2} \cdot...\cdot\frac{a}{k}\cdot\frac{a}{k+1}\cdot...\cdot\frac{a}{n}<\frac{a^k}{k!}(\frac{a}{k})^{n-k}=\frac{a^k}{k!}\cdot \frac{a^na^{-k}}{k^nk^{-k}}$$ $$0<\frac{a^n}{n!}<\frac{k^k}{k!}(\frac{a}{k})^n$$ then $$0 \leq \lim_{n\to\infty}{\frac{a^n}{n!}}\le\frac{k^k}{k!}\lim_{n\to\infty}{(\frac{a}{k})^n}$$ Now, the part I don't understand is in the expansion of $\frac{a^n}{n!}$. How does one come with $<\frac{a^k}{k!}(\frac{a}{k})^{n-k}$ part, to be more precise, how does one come up with $(\frac{a}{k})^{n-k}$ part of the inequality?","I have the proof but i don't understand one part. The proof (for $a>1$) goes as follows: there exists $k \in N$ such that$a<k, \frac{a}{k}<1$ and since $\frac{a}{k+i}<\frac{a}{k}, i \in N$ $$\frac{a^n}{n!}=\frac{a}{1} \cdot \frac{a}{2} \cdot...\cdot\frac{a}{k}\cdot\frac{a}{k+1}\cdot...\cdot\frac{a}{n}<\frac{a^k}{k!}(\frac{a}{k})^{n-k}=\frac{a^k}{k!}\cdot \frac{a^na^{-k}}{k^nk^{-k}}$$ $$0<\frac{a^n}{n!}<\frac{k^k}{k!}(\frac{a}{k})^n$$ then $$0 \leq \lim_{n\to\infty}{\frac{a^n}{n!}}\le\frac{k^k}{k!}\lim_{n\to\infty}{(\frac{a}{k})^n}$$ Now, the part I don't understand is in the expansion of $\frac{a^n}{n!}$. How does one come with $<\frac{a^k}{k!}(\frac{a}{k})^{n-k}$ part, to be more precise, how does one come up with $(\frac{a}{k})^{n-k}$ part of the inequality?",,"['limits', 'inequality']"
98,Find $\lim_{n\to\infty}1+\sqrt[2]{2+\sqrt[3]{3+\sqrt[4]{4+\ldots+\sqrt[n]{n}}}}$,Find,\lim_{n\to\infty}1+\sqrt[2]{2+\sqrt[3]{3+\sqrt[4]{4+\ldots+\sqrt[n]{n}}}},"$$\lim_{n\to\infty}1+\sqrt[2]{2+\sqrt[3]{3+\sqrt[4]{4+\ldots+\sqrt[n]{n}}}}$$ I have no idea about this. The equation can be written in its recursive form as: $$f(n) = g(1,n)$$ Where $$g(x,n) = [x\impliedby n]\cdot (x+ g(x+1,n))^{\frac 1x}+[x=n]\cdot (n)^{\frac 1n}$$ Of course, [] is the indicator function representing of piece wise notation.","I have no idea about this. The equation can be written in its recursive form as: Where Of course, [] is the indicator function representing of piece wise notation.","\lim_{n\to\infty}1+\sqrt[2]{2+\sqrt[3]{3+\sqrt[4]{4+\ldots+\sqrt[n]{n}}}} f(n) = g(1,n) g(x,n) = [x\impliedby n]\cdot (x+ g(x+1,n))^{\frac 1x}+[x=n]\cdot (n)^{\frac 1n}","['calculus', 'limits', 'nested-radicals']"
99,Evaluation of $ \lim\limits_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right]$,Evaluation of, \lim\limits_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right],"Evaluation of $\displaystyle \lim_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right]$ $\bf{My\; Try::}$ Let $\displaystyle l=\displaystyle \lim_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right]=\lim_{x\rightarrow \infty}x\left[1+(x-1)\ln\left(1+\frac{1}{x}\right)\right]$ So we get $$l=\lim_{x\rightarrow \infty}x\left[1+(1-x)\left(\frac{1}{x}-\frac{1}{2x^2}+\frac{1}{3x^3}-\frac{1}{4x^4}-.........\infty\right)\right]$$ So we get $$l=\lim_{x\rightarrow \infty}x\left[1-1+\frac{1}{2x}-\frac{1}{3x^2}+\frac{1}{4x^3}+\frac{1}{x}-\frac{1}{2x^2}+\frac{1}{3x^3}.....\right] = \frac{3}{2}$$ My Question is How can we solve it without using series expansion, If yes then plz explain here, Thanks","Evaluation of $\displaystyle \lim_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right]$ $\bf{My\; Try::}$ Let $\displaystyle l=\displaystyle \lim_{x\rightarrow \infty}x\left[\ln \left(e\left(1+\frac{1}{x}\right)^{1-x}\right)\right]=\lim_{x\rightarrow \infty}x\left[1+(x-1)\ln\left(1+\frac{1}{x}\right)\right]$ So we get $$l=\lim_{x\rightarrow \infty}x\left[1+(1-x)\left(\frac{1}{x}-\frac{1}{2x^2}+\frac{1}{3x^3}-\frac{1}{4x^4}-.........\infty\right)\right]$$ So we get $$l=\lim_{x\rightarrow \infty}x\left[1-1+\frac{1}{2x}-\frac{1}{3x^2}+\frac{1}{4x^3}+\frac{1}{x}-\frac{1}{2x^2}+\frac{1}{3x^3}.....\right] = \frac{3}{2}$$ My Question is How can we solve it without using series expansion, If yes then plz explain here, Thanks",,"['calculus', 'real-analysis', 'limits', 'taylor-expansion']"
