,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,A very curious rational fraction that converges. What is the value?,A very curious rational fraction that converges. What is the value?,,Is there any closed form for the following limit? Define the sequence   $$ \begin{cases}    a_{n+1} = b_n+2a_n + 14\\   b_{n+1} = 9b_n+ 2a_n+70 \end{cases}$$   with initial values $a_0 = b_0 = 1$. Then $\lim_{n\to\infty} \frac{a_n}{b_n} = ? $ The limit is approximately $0.1376$. My math teacher Carlos Ivorra says that this limit have a closed form involving the sine of an angle. What is the closed form for is limit? NOTE: I have found this (and another series of converging sequences) by the use of an ancient method for calculating sines recently rediscovered. I'll give the details soon as a more general question.,Is there any closed form for the following limit? Define the sequence   $$ \begin{cases}    a_{n+1} = b_n+2a_n + 14\\   b_{n+1} = 9b_n+ 2a_n+70 \end{cases}$$   with initial values $a_0 = b_0 = 1$. Then $\lim_{n\to\infty} \frac{a_n}{b_n} = ? $ The limit is approximately $0.1376$. My math teacher Carlos Ivorra says that this limit have a closed form involving the sine of an angle. What is the closed form for is limit? NOTE: I have found this (and another series of converging sequences) by the use of an ancient method for calculating sines recently rediscovered. I'll give the details soon as a more general question.,,"['real-analysis', 'sequences-and-series', 'analysis', 'limits', 'trigonometry']"
1,"$f : [0,\infty) → \mathbb{R}$ with $f(0) = f'(0) = 0$ and $f(x) < x^2$ and $f',f'',f''' > 0$?",with  and  and ?,"f : [0,\infty) → \mathbb{R} f(0) = f'(0) = 0 f(x) < x^2 f',f'',f''' > 0","I want to intuitively argue that there is no function with some properties, and find it tricky to explain it to someone who just understands that derivatives are representative of increase rates of a function. Here is the statement: There is no function $f(x)$ on $x \ge 0$ such that $f(0)=0$ , $f'(0)=0$ , $f(x)<x^2$ for $x>0$ and that the first, second and third derivative of $f(x)$ are strictly positive on $x>0$ . I appreciate any help!","I want to intuitively argue that there is no function with some properties, and find it tricky to explain it to someone who just understands that derivatives are representative of increase rates of a function. Here is the statement: There is no function on such that , , for and that the first, second and third derivative of are strictly positive on . I appreciate any help!",f(x) x \ge 0 f(0)=0 f'(0)=0 f(x)<x^2 x>0 f(x) x>0,"['real-analysis', 'functions', 'derivatives']"
2,Prove that $\int^{1}_{0} f^{-1} = 1 - \int^1_0 f$,Prove that,\int^{1}_{0} f^{-1} = 1 - \int^1_0 f,"One more from hard to believe facts, which I'm curious why are true. Let $f : [0,1] \rightarrow [0,1] $ is a continuous, monotonically increasing and surjective function Then $$\int^{1}_{0} f^{-1} = 1 - \int^1_0 f$$ Sorry if it was asked, but I can't find. I've tried to use the theorem about derivative of reverse function , but I wasn't able today to connect it with this task. Thanks in advance for help!","One more from hard to believe facts, which I'm curious why are true. Let $f : [0,1] \rightarrow [0,1] $ is a continuous, monotonically increasing and surjective function Then $$\int^{1}_{0} f^{-1} = 1 - \int^1_0 f$$ Sorry if it was asked, but I can't find. I've tried to use the theorem about derivative of reverse function , but I wasn't able today to connect it with this task. Thanks in advance for help!",,"['real-analysis', 'integration', 'derivatives']"
3,Examples illustrating the difference between closed and bounded sets.,Examples illustrating the difference between closed and bounded sets.,,"Intuitively for me, it seems as if closed sets are bounded, especially considering closed sets contain all limit points. But I know this isn't the case, because $ℝ$ is closed (and open) and is not bounded. Is this the only case of a closed set not being bounded? Can anyone provide an example that further illustrates the difference between closed and bounded?","Intuitively for me, it seems as if closed sets are bounded, especially considering closed sets contain all limit points. But I know this isn't the case, because is closed (and open) and is not bounded. Is this the only case of a closed set not being bounded? Can anyone provide an example that further illustrates the difference between closed and bounded?",ℝ,"['real-analysis', 'general-topology']"
4,Integral $\int_0^1 \log \frac{1+ax}{1-ax}\frac{dx}{x\sqrt{1-x^2}}=\pi\arcsin a$,Integral,\int_0^1 \log \frac{1+ax}{1-ax}\frac{dx}{x\sqrt{1-x^2}}=\pi\arcsin a,"Hi I am trying to solve this integral $$ I:=\int_0^1 \log\left(\frac{1+ax}{1-ax}\right)\,\frac{{\rm d}x}{x\sqrt{1-x^2}}=\pi\arcsin\left(a\right),\qquad \left\vert a\right\vert \leq 1. $$ It gives beautiful result for $a = 1$ $$ \int_0^1 \log\left(\frac{1+ x}{1-x}\right)\,\frac{{\rm d}x}{x\sqrt{1-x^2}} =\frac{\pi^2}{2}. $$ I tried to write $$ I=\int_0^1 \frac{\log(1+ax)}{x\sqrt{1-x^2}}dx-\int_0^1 \frac{\log(1-ax)}{x\sqrt{1-x^2}}dx $$ If we work with one of these integrals we can write $$ \sum_{n=1}^\infty \frac{(-1)^{n+1} a^n}{n}\int_0^1 \frac{x^{n-1}}{\sqrt{1-x^2}}dx-\sum_{n=1}^\infty \frac{a^n}{n}\int_0^1 \frac{x^{n-1}}{\sqrt{1-x^2}}dx, $$ simplifying this I get an infinite sum of Gamma functions. which i'm not sure how to relate to the $\arcsin$ Thanks.",Hi I am trying to solve this integral It gives beautiful result for I tried to write If we work with one of these integrals we can write simplifying this I get an infinite sum of Gamma functions. which i'm not sure how to relate to the Thanks.,"
I:=\int_0^1 \log\left(\frac{1+ax}{1-ax}\right)\,\frac{{\rm d}x}{x\sqrt{1-x^2}}=\pi\arcsin\left(a\right),\qquad
\left\vert a\right\vert \leq 1.
 a = 1 
\int_0^1 \log\left(\frac{1+ x}{1-x}\right)\,\frac{{\rm d}x}{x\sqrt{1-x^2}}
=\frac{\pi^2}{2}.
 
I=\int_0^1 \frac{\log(1+ax)}{x\sqrt{1-x^2}}dx-\int_0^1 \frac{\log(1-ax)}{x\sqrt{1-x^2}}dx
 
\sum_{n=1}^\infty \frac{(-1)^{n+1} a^n}{n}\int_0^1 \frac{x^{n-1}}{\sqrt{1-x^2}}dx-\sum_{n=1}^\infty \frac{a^n}{n}\int_0^1 \frac{x^{n-1}}{\sqrt{1-x^2}}dx,
 \arcsin","['calculus', 'real-analysis', 'integration', 'complex-analysis', 'definite-integrals']"
5,Convergence\Divergence of $\sum\limits_{n=1}^{\infty}\frac {1\cdot 3\cdots (2n-1)} {2\cdot 4\cdots (2n)}$,Convergence\Divergence of,\sum\limits_{n=1}^{\infty}\frac {1\cdot 3\cdots (2n-1)} {2\cdot 4\cdots (2n)},"Prove convergence\divergence of the series: $$\sum_{n=1}^{\infty}\dfrac {1\cdot 3\cdots (2n-1)} {2\cdot 4\cdots (2n)}$$ Here is what I have at the moment: Method I My first way uses a result that is related to Wallis product that we'll denote by $W_{n}$.  Also, we  may denote $\dfrac {1\cdot 3\cdots (2n-1)} {2\cdot 4\cdots (2n)}$ by $P_{n}$. Having noted these and taking a large value of $n$ we get: $$(P_{n})^2 =\frac{1}{W_{n} \cdot (2n+1)}\approx\frac{2}{\pi}\cdot \frac{1}{2n+1}$$ $$P_{n}\approx \sqrt {\frac{2}{\pi}} \cdot \frac{1}{\sqrt{2n+1}}$$ Further we have that: $$\lim_{n\to\infty}\sqrt {\frac{2}{\pi}} \cdot \frac{n}{\sqrt{2n+1}} \le \sum_{n=1}^{\infty} P_{n}$$  that obviously shows us that the series diverges. Method II The second way is to resort to the powerful Kummer's Test and firstly proceed with the ratio test: $$\lim_{n\to\infty} \frac{P_{n+1}}{P_{n}}=\frac{2n+1}{2n+2}=1$$ and according to the result, the ratio test is inconclusive. Now, we apply Kummer's test and get: $$\lim_{n\to\infty} \frac{P_{n}}{P_{n+1}}n-(n+1)=\lim_{n\to\infty} -\frac{n+1}{2n+1}=-\frac{1}{2} \le 0$$ Since  $$\sum_{n=1}^{\infty} \frac{1}{n} \longrightarrow \infty$$ our series diverges and we're done. On the site I've also found a related question with answers that can be applied for my question.  Since I've already have some answers for my question you may regard it as a recreational one and if you have a nice proof to share I'd be glad to receive it. I like this question very much and want to make up a collection with nice proofs for it. Thanks.","Prove convergence\divergence of the series: $$\sum_{n=1}^{\infty}\dfrac {1\cdot 3\cdots (2n-1)} {2\cdot 4\cdots (2n)}$$ Here is what I have at the moment: Method I My first way uses a result that is related to Wallis product that we'll denote by $W_{n}$.  Also, we  may denote $\dfrac {1\cdot 3\cdots (2n-1)} {2\cdot 4\cdots (2n)}$ by $P_{n}$. Having noted these and taking a large value of $n$ we get: $$(P_{n})^2 =\frac{1}{W_{n} \cdot (2n+1)}\approx\frac{2}{\pi}\cdot \frac{1}{2n+1}$$ $$P_{n}\approx \sqrt {\frac{2}{\pi}} \cdot \frac{1}{\sqrt{2n+1}}$$ Further we have that: $$\lim_{n\to\infty}\sqrt {\frac{2}{\pi}} \cdot \frac{n}{\sqrt{2n+1}} \le \sum_{n=1}^{\infty} P_{n}$$  that obviously shows us that the series diverges. Method II The second way is to resort to the powerful Kummer's Test and firstly proceed with the ratio test: $$\lim_{n\to\infty} \frac{P_{n+1}}{P_{n}}=\frac{2n+1}{2n+2}=1$$ and according to the result, the ratio test is inconclusive. Now, we apply Kummer's test and get: $$\lim_{n\to\infty} \frac{P_{n}}{P_{n+1}}n-(n+1)=\lim_{n\to\infty} -\frac{n+1}{2n+1}=-\frac{1}{2} \le 0$$ Since  $$\sum_{n=1}^{\infty} \frac{1}{n} \longrightarrow \infty$$ our series diverges and we're done. On the site I've also found a related question with answers that can be applied for my question.  Since I've already have some answers for my question you may regard it as a recreational one and if you have a nice proof to share I'd be glad to receive it. I like this question very much and want to make up a collection with nice proofs for it. Thanks.",,"['calculus', 'real-analysis', 'sequences-and-series', 'convergence-divergence', 'divergent-series']"
6,An absolutely convergent series of rational numbers which does not converge to a rational number [duplicate],An absolutely convergent series of rational numbers which does not converge to a rational number [duplicate],,"This question already has answers here : Absolute convergence to a rational number (6 answers) Closed 2 years ago . A standard theorem concerning series of real numbers states that every absolutely convergent series of real numbers converges. I would like to know a counterexample to this statement when we are dealing only with rational numbers. More precisely, I would like to know an example of a series $\sum_{n=0}^\infty q_n$ of rational numbers such that $\sum_{n=0}^\infty|q_n|$ converges to a rational number and that $\sum_{n=0}^\infty q_n$ converges to an irrational number. Furthermore, I want that the reason why the example works is understandable by someone who is only aware of basic statements concerning series. If it wasn't for the last requirement, I would know how to do it. One possibility would be to consider the power series $$\sum_{n=0}^\infty\binom{-1/2}nx^n,$$ which converges to $1/\sqrt{1+x}$ in $(-1,1)$ . In particular, $$\sum_{n=0}^\infty\binom{-1/2}n\left(\frac34\right)^n=\frac2{\sqrt7}\notin\Bbb Q.$$ But \begin{align}\sum_{n=0}^\infty\left|\binom{-1/2}n\left(\frac34\right)^n\right|&=\sum_{n=0}^\infty(-1)^n\binom{-1/2}n\left(\frac34\right)^n\\&=\sum_{n=0}^\infty\binom{-1/2}n\left(-\frac34\right)^n\\&=2\in\Bbb Q.\end{align} Another possibility consists in using a counting argument (although this only proves that a counter-example exists, rather than exhibiting one). The numbers of the form $$\sum_{n=0}^\infty\frac{\varepsilon_n}{3^n},$$ where $(\varepsilon_n)_{n\in\Bbb Z_+}$ is a sequence which takes only the values $1$ and $-1$ , form an uncountable set. So, for some sequences $(\varepsilon_n)_{n\in\Bbb Z_+}$ , the sum is irrational. But $$\sum_{n=0}^\infty\left|\frac{\varepsilon_n}{3^n}\right|=\frac32\in\Bbb Q.$$","This question already has answers here : Absolute convergence to a rational number (6 answers) Closed 2 years ago . A standard theorem concerning series of real numbers states that every absolutely convergent series of real numbers converges. I would like to know a counterexample to this statement when we are dealing only with rational numbers. More precisely, I would like to know an example of a series of rational numbers such that converges to a rational number and that converges to an irrational number. Furthermore, I want that the reason why the example works is understandable by someone who is only aware of basic statements concerning series. If it wasn't for the last requirement, I would know how to do it. One possibility would be to consider the power series which converges to in . In particular, But Another possibility consists in using a counting argument (although this only proves that a counter-example exists, rather than exhibiting one). The numbers of the form where is a sequence which takes only the values and , form an uncountable set. So, for some sequences , the sum is irrational. But","\sum_{n=0}^\infty q_n \sum_{n=0}^\infty|q_n| \sum_{n=0}^\infty q_n \sum_{n=0}^\infty\binom{-1/2}nx^n, 1/\sqrt{1+x} (-1,1) \sum_{n=0}^\infty\binom{-1/2}n\left(\frac34\right)^n=\frac2{\sqrt7}\notin\Bbb Q. \begin{align}\sum_{n=0}^\infty\left|\binom{-1/2}n\left(\frac34\right)^n\right|&=\sum_{n=0}^\infty(-1)^n\binom{-1/2}n\left(\frac34\right)^n\\&=\sum_{n=0}^\infty\binom{-1/2}n\left(-\frac34\right)^n\\&=2\in\Bbb Q.\end{align} \sum_{n=0}^\infty\frac{\varepsilon_n}{3^n}, (\varepsilon_n)_{n\in\Bbb Z_+} 1 -1 (\varepsilon_n)_{n\in\Bbb Z_+} \sum_{n=0}^\infty\left|\frac{\varepsilon_n}{3^n}\right|=\frac32\in\Bbb Q.","['real-analysis', 'examples-counterexamples', 'rational-numbers', 'absolute-convergence']"
7,How to construct a Bernstein set and what are their applications?,How to construct a Bernstein set and what are their applications?,,Bernstein Set: A subset of the real line that meets every uncountable closed subset of the real line but that contains none of them. It's from wiki. My question is this: How to construct a Bernstein set? And what's its application in mathematics? Thanks ahead for any help:),Bernstein Set: A subset of the real line that meets every uncountable closed subset of the real line but that contains none of them. It's from wiki. My question is this: How to construct a Bernstein set? And what's its application in mathematics? Thanks ahead for any help:),,"['real-analysis', 'general-topology', 'descriptive-set-theory']"
8,Importance of Axiom of Choice,Importance of Axiom of Choice,,"First a quick question regarding the definition of the axiom of choice. Do the sets have to be mutually disjoint nonempty sets or just non-empty? One source states: ""For any set X of nonempty sets, there exists a choice function f defined on X."" But another source states that the sets have to be mutually disjoint. Secondly, pardon me if I sound ignorant (I'm learning this as a hobby so I don't have much background or time for it) but isn't it a really obvious/self-evident concept? I mean essentially, it is saying that if you have a collection of non-empty sets, then you can pick an element out of each set. I realize that there are difficulties when we cannot make explicit choices because we cannot create an explicit algorithm for the choice function (for example the collection of all nonempty subsets of the real line), but does that really matter? I mean just like the number 5, the existence of the function 'f' is purely formal. Math isn't able to fully describe or prove everything but doesn't mean it doesn't exixt.","First a quick question regarding the definition of the axiom of choice. Do the sets have to be mutually disjoint nonempty sets or just non-empty? One source states: ""For any set X of nonempty sets, there exists a choice function f defined on X."" But another source states that the sets have to be mutually disjoint. Secondly, pardon me if I sound ignorant (I'm learning this as a hobby so I don't have much background or time for it) but isn't it a really obvious/self-evident concept? I mean essentially, it is saying that if you have a collection of non-empty sets, then you can pick an element out of each set. I realize that there are difficulties when we cannot make explicit choices because we cannot create an explicit algorithm for the choice function (for example the collection of all nonempty subsets of the real line), but does that really matter? I mean just like the number 5, the existence of the function 'f' is purely formal. Math isn't able to fully describe or prove everything but doesn't mean it doesn't exixt.",,"['real-analysis', 'elementary-set-theory', 'axiom-of-choice']"
9,Understanding the definition of a compact set,Understanding the definition of a compact set,,"I just need a bit of help clarifying the definition of a compact set. Let's start with the textbook definition: A set $S$ is called compact if, whenever it is covered by a collection of open sets $\{G\}$, $S$ is also covered by a finite sub-collection $\{H\}$ of $\{G\}$. Question: Does $\{H\}$ need to be a proper subset of $\{G\}$? If, for instance, $\{G\}$ is already a finite collection, does that mean $S$ is automatically covered by a finite sub-collection of $\{G\}$? Also, is there any need for the open sets in $\{H\}$ to be bounded sets?","I just need a bit of help clarifying the definition of a compact set. Let's start with the textbook definition: A set $S$ is called compact if, whenever it is covered by a collection of open sets $\{G\}$, $S$ is also covered by a finite sub-collection $\{H\}$ of $\{G\}$. Question: Does $\{H\}$ need to be a proper subset of $\{G\}$? If, for instance, $\{G\}$ is already a finite collection, does that mean $S$ is automatically covered by a finite sub-collection of $\{G\}$? Also, is there any need for the open sets in $\{H\}$ to be bounded sets?",,"['real-analysis', 'general-topology', 'compactness']"
10,Is an open $n$-ball homeomorphic to $\mathbb{R}^{n}$?,Is an open -ball homeomorphic to ?,n \mathbb{R}^{n},I read on Wikipedia the following claim: Any open topological $n$-ball is homeomorphic to the Cartesian space $\mathbb{R}^{n}$. No reason or proof was given. Can someone explain? I did try looking at other SE questions and didn't find anything I could understand. Thanks!,I read on Wikipedia the following claim: Any open topological $n$-ball is homeomorphic to the Cartesian space $\mathbb{R}^{n}$. No reason or proof was given. Can someone explain? I did try looking at other SE questions and didn't find anything I could understand. Thanks!,,"['real-analysis', 'general-topology']"
11,A example of closed and bounded does not imply compactnesss in metric Space,A example of closed and bounded does not imply compactnesss in metric Space,,"Let $X$ be the integers with metric $ρ(m,n)=1$, except that $ρ(n,n)=0$. Check that $ρ$ is a metric. Show that $X$ is closed and bounded, but not compact. This is a ""made-up"" example demonstrating closed and bounded doesn't imply compactess in more general metric space. I checked that $\rho$ is a metric already. Yet I have no idea how to approach ""showing $X$ is closed and bounded."" I visualized this metric to be a set of number with just $0$ and $1$ (or maybe this is not correct?). Also, I doubt that this metric is NOT compact. Anyway, I'd appreciate if you can help! Meanwhile, do we use a ball $B(0,1)$ in general to show that a metric is closed and bounded? If so, why?","Let $X$ be the integers with metric $ρ(m,n)=1$, except that $ρ(n,n)=0$. Check that $ρ$ is a metric. Show that $X$ is closed and bounded, but not compact. This is a ""made-up"" example demonstrating closed and bounded doesn't imply compactess in more general metric space. I checked that $\rho$ is a metric already. Yet I have no idea how to approach ""showing $X$ is closed and bounded."" I visualized this metric to be a set of number with just $0$ and $1$ (or maybe this is not correct?). Also, I doubt that this metric is NOT compact. Anyway, I'd appreciate if you can help! Meanwhile, do we use a ball $B(0,1)$ in general to show that a metric is closed and bounded? If so, why?",,['real-analysis']
12,"Is a differentiable function on $(-2, 4)$ always integrable on $[-2, 4]$?",Is a differentiable function on  always integrable on ?,"(-2, 4) [-2, 4]","So my question is, say I have a function that is differentiable on $(-2, 4)$. Is it always integrable on $[-2, 4]$? I know that if $f$ is diff on $(-2, 4)$, then it is continuous on $(-2, 4)$. And I also know that if $f$ is continuous on $[-2, 4]$ then it is integrable on $[-2, 4]$. However, I am wondering if there is such a function so that there would be a problem at the endpoints of the closed interval so that it is differentiable on the open interval, but not integrable on the closed interval.","So my question is, say I have a function that is differentiable on $(-2, 4)$. Is it always integrable on $[-2, 4]$? I know that if $f$ is diff on $(-2, 4)$, then it is continuous on $(-2, 4)$. And I also know that if $f$ is continuous on $[-2, 4]$ then it is integrable on $[-2, 4]$. However, I am wondering if there is such a function so that there would be a problem at the endpoints of the closed interval so that it is differentiable on the open interval, but not integrable on the closed interval.",,"['real-analysis', 'integration', 'derivatives', 'continuity', 'examples-counterexamples']"
13,Is there an everywhere discontinuous increasing function?,Is there an everywhere discontinuous increasing function?,,"Does there exist a function $f : \mathbb{R} \rightarrow \mathbb{R}$ that is strictly increasing and discontinuous everywhere? My line of thought (possibly incorrect): I know there are increasing functions such as $f(x) = x$, and there are everywhere-discontinuous functions such as the Dirichlet function. I also know that when there is a discontinuity at a point $c$, there is a finite gap $\epsilon$ such that there are points $d$ arbitrarily close to $c$ such that $|f(d) - f(c)| > \epsilon$. This is where my thinking gets unclear - does it make sense to have a ""gap"" at every real number?","Does there exist a function $f : \mathbb{R} \rightarrow \mathbb{R}$ that is strictly increasing and discontinuous everywhere? My line of thought (possibly incorrect): I know there are increasing functions such as $f(x) = x$, and there are everywhere-discontinuous functions such as the Dirichlet function. I also know that when there is a discontinuity at a point $c$, there is a finite gap $\epsilon$ such that there are points $d$ arbitrarily close to $c$ such that $|f(d) - f(c)| > \epsilon$. This is where my thinking gets unclear - does it make sense to have a ""gap"" at every real number?",,"['calculus', 'real-analysis']"
14,Real Analysis: Continuity of a Composition Function,Real Analysis: Continuity of a Composition Function,,"Suppose $f$ and $g$ are functions such that $g$ is continuous at $a$, and $f$ is continuous at $g(a)$. Show the composition $f(g(x))$ is continuous at $a$. My idea: Can I go straight from definition and take $\delta=\min\{\delta_1,\delta_2\}$, where $\delta_1$ is used for the continuity of $g$ at $a$ and $\delta_2$ is used for f being continuous at $g(a)$. In my proof I just treat $g(a)$ as a point when referring to the composition. So it goes like this: Proof: Given $\epsilon>0$, take $\delta=\min\{\delta_1,\delta_2\}$. Then $0<|x-g(a)|<\delta$ which implies $|f(g(x))-f(g(a))|<\epsilon$.","Suppose $f$ and $g$ are functions such that $g$ is continuous at $a$, and $f$ is continuous at $g(a)$. Show the composition $f(g(x))$ is continuous at $a$. My idea: Can I go straight from definition and take $\delta=\min\{\delta_1,\delta_2\}$, where $\delta_1$ is used for the continuity of $g$ at $a$ and $\delta_2$ is used for f being continuous at $g(a)$. In my proof I just treat $g(a)$ as a point when referring to the composition. So it goes like this: Proof: Given $\epsilon>0$, take $\delta=\min\{\delta_1,\delta_2\}$. Then $0<|x-g(a)|<\delta$ which implies $|f(g(x))-f(g(a))|<\epsilon$.",,"['real-analysis', 'continuity', 'function-and-relation-composition']"
15,Compute $\lim\limits_{n\to\infty} \int_{0}^{2\pi} \cos x \cos 2x\cdots \cos nx \space{dx}$,Compute,\lim\limits_{n\to\infty} \int_{0}^{2\pi} \cos x \cos 2x\cdots \cos nx \space{dx},"Compute the following limit:   $$\lim_{n \to \infty}\int_{0}^{2\pi}\cos\left(x\right)\cos\left(2x\right)\ldots \cos\left(nx\right)\,{\rm d}x$$ Today I was working on a W. L. Putnam competition's problem containing this  integral and wondered how I may compute its value when $n$ goes to $\infty$. So far I've found no answer. Could you give me some suggestions about the way I should go?","Compute the following limit:   $$\lim_{n \to \infty}\int_{0}^{2\pi}\cos\left(x\right)\cos\left(2x\right)\ldots \cos\left(nx\right)\,{\rm d}x$$ Today I was working on a W. L. Putnam competition's problem containing this  integral and wondered how I may compute its value when $n$ goes to $\infty$. So far I've found no answer. Could you give me some suggestions about the way I should go?",,"['calculus', 'real-analysis', 'integration', 'limits', 'definite-integrals']"
16,"An arctan integral $\int_0^{\infty } \frac{\arctan(x)}{x \left(x^2+1\right)^5} \, dx$",An arctan integral,"\int_0^{\infty } \frac{\arctan(x)}{x \left(x^2+1\right)^5} \, dx","According to Mathematica , we have that $$\int_0^{\infty } \frac{\arctan(x)}{x \left(x^2+1\right)^5} \, dx=\pi  \left(\frac{\log (2)}{2}-\frac{1321}{6144}\right)$$ that frankly speaking looks pretty nice. However Mathematica shows that $$\int \frac{\arctan(x)}{x \left(x^2+1\right)^5} \, dx$$ $$=-\frac{1}{2} i \text{Li}_2\left(e^{2 i \tan ^{-1}(x)}\right)-\frac{1}{2} i \tan ^{-1}(x)^2+\tan ^{-1}(x) \log \left(1-e^{2 i \tan ^{-1}(x)}\right)-\frac{65}{256} \sin \left(2 \tan ^{-1}(x)\right)-\frac{23 \sin \left(4 \tan ^{-1}(x)\right)}{1024}-\frac{5 \sin \left(6 \tan ^{-1}(x)\right)}{2304}-\frac{\sin \left(8 \tan ^{-1}(x)\right)}{8192}+\frac{65}{128} \tan ^{-1}(x) \cos \left(2 \tan ^{-1}(x)\right)+\frac{23}{256} \tan ^{-1}(x) \cos \left(4 \tan ^{-1}(x)\right)+\frac{5}{384} \tan ^{-1}(x) \cos \left(6 \tan ^{-1}(x)\right)+\frac{\tan ^{-1}(x) \cos \left(8 \tan ^{-1}(x)\right)}{1024}$$ and this form doesn't look that nice. Having given the nice form of the closed form I wonder if we can find a very nice and simple way of   getting the answer. What do you think? A supplementary question : $$\int_0^{\infty } \frac{\arctan^2(x)}{x \left(x^2+1\right)^5} \, dx=\frac{55}{108}-\frac{1321}{12288}\pi^2+\frac{\pi^2}{4} \log (2)-\frac{7 }{8}\zeta (3)$$","According to Mathematica , we have that $$\int_0^{\infty } \frac{\arctan(x)}{x \left(x^2+1\right)^5} \, dx=\pi  \left(\frac{\log (2)}{2}-\frac{1321}{6144}\right)$$ that frankly speaking looks pretty nice. However Mathematica shows that $$\int \frac{\arctan(x)}{x \left(x^2+1\right)^5} \, dx$$ $$=-\frac{1}{2} i \text{Li}_2\left(e^{2 i \tan ^{-1}(x)}\right)-\frac{1}{2} i \tan ^{-1}(x)^2+\tan ^{-1}(x) \log \left(1-e^{2 i \tan ^{-1}(x)}\right)-\frac{65}{256} \sin \left(2 \tan ^{-1}(x)\right)-\frac{23 \sin \left(4 \tan ^{-1}(x)\right)}{1024}-\frac{5 \sin \left(6 \tan ^{-1}(x)\right)}{2304}-\frac{\sin \left(8 \tan ^{-1}(x)\right)}{8192}+\frac{65}{128} \tan ^{-1}(x) \cos \left(2 \tan ^{-1}(x)\right)+\frac{23}{256} \tan ^{-1}(x) \cos \left(4 \tan ^{-1}(x)\right)+\frac{5}{384} \tan ^{-1}(x) \cos \left(6 \tan ^{-1}(x)\right)+\frac{\tan ^{-1}(x) \cos \left(8 \tan ^{-1}(x)\right)}{1024}$$ and this form doesn't look that nice. Having given the nice form of the closed form I wonder if we can find a very nice and simple way of   getting the answer. What do you think? A supplementary question : $$\int_0^{\infty } \frac{\arctan^2(x)}{x \left(x^2+1\right)^5} \, dx=\frac{55}{108}-\frac{1321}{12288}\pi^2+\frac{\pi^2}{4} \log (2)-\frac{7 }{8}\zeta (3)$$",,"['calculus', 'real-analysis', 'integration', 'definite-integrals']"
17,Is there any number that I can't find? [closed],Is there any number that I can't find? [closed],,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I have a question that I think is quite weird and I can't find an answer. Is there any real number that I can't find using only $+,-,\times,\div,$ limits and radicals? For example, using some series, I can find $\pi$ or $e$. But is there any number that I can't find using only those? Sorry if I made any mistakes, I don't know how to ask that question or which tags to put.","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I have a question that I think is quite weird and I can't find an answer. Is there any real number that I can't find using only $+,-,\times,\div,$ limits and radicals? For example, using some series, I can find $\pi$ or $e$. But is there any number that I can't find using only those? Sorry if I made any mistakes, I don't know how to ask that question or which tags to put.",,['real-analysis']
18,Which Analysis books did you learn from and how many years/textbooks did it take to become a master? [closed],Which Analysis books did you learn from and how many years/textbooks did it take to become a master? [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question It seems that nearly every graduate program in the U.S. requires an extensive education in Analysis clearly demonstrating its importance not only as a subfield itself, but as a foundation for other areas of abstract mathematics. I am interested in doing research in Analysis as a graduate student. I am curious how long it takes a student to get to the level of serious research in the subject. As subjective as this question is, I am curious to know from which texts some of you learned Analysis i.e. from Rudin (the family), Royden, Pugh, Bartle, Tao, Torchinsky, etc. How many classes did it take to be near or at the level of research in the area? Which texts helped you get there? Also, do you know of any summer programs in Analysis at your institution undergraduates can enroll in? Thanks in advance!","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 5 years ago . Improve this question It seems that nearly every graduate program in the U.S. requires an extensive education in Analysis clearly demonstrating its importance not only as a subfield itself, but as a foundation for other areas of abstract mathematics. I am interested in doing research in Analysis as a graduate student. I am curious how long it takes a student to get to the level of serious research in the subject. As subjective as this question is, I am curious to know from which texts some of you learned Analysis i.e. from Rudin (the family), Royden, Pugh, Bartle, Tao, Torchinsky, etc. How many classes did it take to be near or at the level of research in the area? Which texts helped you get there? Also, do you know of any summer programs in Analysis at your institution undergraduates can enroll in? Thanks in advance!",,"['real-analysis', 'reference-request', 'book-recommendation']"
19,Can a function with just one point in its domain be continuous?,Can a function with just one point in its domain be continuous?,,"For example if my function is $f:\{1\}\longrightarrow \mathbb{R}$ such that $f(1)=1$. I have the next context: 1) According to the definition given in Spivak's book and also in wikipedia, since $\lim_{x\to1}f$ doesn't exist because $1$ is not an accumulation point, then the function is not continuous at $1$ (Otherwise it should be $\lim_{x\to 1}f=f(1)$). 2) According to this answer , as far as I can understand a function is continuous at an isolated point. I don't understand. Edit: Spivak's definition of limit: The function $f$ approaches to $l$ near $a$ means $\forall \epsilon > 0 \; \exists \delta > 0 \; \forall x \; [0<|x-a|<\delta\implies |f(x)-l|<\epsilon]$ Spivak's definition of continuity: The function $f$ is continuous at $a$ if $\lim_{x\to a}f(x)=f(a)$","For example if my function is $f:\{1\}\longrightarrow \mathbb{R}$ such that $f(1)=1$. I have the next context: 1) According to the definition given in Spivak's book and also in wikipedia, since $\lim_{x\to1}f$ doesn't exist because $1$ is not an accumulation point, then the function is not continuous at $1$ (Otherwise it should be $\lim_{x\to 1}f=f(1)$). 2) According to this answer , as far as I can understand a function is continuous at an isolated point. I don't understand. Edit: Spivak's definition of limit: The function $f$ approaches to $l$ near $a$ means $\forall \epsilon > 0 \; \exists \delta > 0 \; \forall x \; [0<|x-a|<\delta\implies |f(x)-l|<\epsilon]$ Spivak's definition of continuity: The function $f$ is continuous at $a$ if $\lim_{x\to a}f(x)=f(a)$",,"['calculus', 'real-analysis', 'general-topology', 'self-learning']"
20,Countable closed sets,Countable closed sets,,There is a theorem that states that the finite union of closed sets is closed but I was wondering if we have a set that consists of countable many subsets that are all closed if that set is closed. I really want to believe that the set is closed but I've been wrong in past so if anyone can supply me with an answer I would be very grateful. Thank you.,There is a theorem that states that the finite union of closed sets is closed but I was wondering if we have a set that consists of countable many subsets that are all closed if that set is closed. I really want to believe that the set is closed but I've been wrong in past so if anyone can supply me with an answer I would be very grateful. Thank you.,,['real-analysis']
21,$\ell^p\subseteq\ell^q$ for $0<p<q<\infty$ and $\|\cdot\|_q<\|\cdot\|_p$ [duplicate],for  and  [duplicate],\ell^p\subseteq\ell^q 0<p<q<\infty \|\cdot\|_q<\|\cdot\|_p,"This question already has answers here : How do you show monotonicity of the $\ell^p$ norms? (6 answers) Closed 4 years ago . I'm trying to show the inclusion : $\ell^p\subseteq\ell^q$ for real-value sequences, and show that the norms satisfy: $\|\cdot\|_q<\|\cdot\|_p$. I think I can show the first part without much trouble: Take $a_n$ in $\ell^p$, then the partial sums are a Cauchy sequence, i.e., for any $\epsilon>0$ , there is a natural $N$ with $|S_{n,p}-S_{k,p}|<\epsilon$ for $n,k>N$, and $S_{n,p}$ the partial sums of $|a_n|^p$ and the individual terms go to $0$. So, we choose an index $J$ with $a_j<1$ for $j>J$. We then use that $f(x)=a^x$ decreases in $[0,1]$. This means that $|a_j|^p<|a_j|^q$. So the tail of $S_{n,q}$, the partial sums of $|a_n|^q$ decrease fast-enough to converge, by comparison with the tail of $S_{n,p}$. But I'm having trouble showing $\|\cdot\|_q<\|\cdot\|_p$ . Also, is there a specific canonical embedding between the two spaces?","This question already has answers here : How do you show monotonicity of the $\ell^p$ norms? (6 answers) Closed 4 years ago . I'm trying to show the inclusion : $\ell^p\subseteq\ell^q$ for real-value sequences, and show that the norms satisfy: $\|\cdot\|_q<\|\cdot\|_p$. I think I can show the first part without much trouble: Take $a_n$ in $\ell^p$, then the partial sums are a Cauchy sequence, i.e., for any $\epsilon>0$ , there is a natural $N$ with $|S_{n,p}-S_{k,p}|<\epsilon$ for $n,k>N$, and $S_{n,p}$ the partial sums of $|a_n|^p$ and the individual terms go to $0$. So, we choose an index $J$ with $a_j<1$ for $j>J$. We then use that $f(x)=a^x$ decreases in $[0,1]$. This means that $|a_j|^p<|a_j|^q$. So the tail of $S_{n,q}$, the partial sums of $|a_n|^q$ decrease fast-enough to converge, by comparison with the tail of $S_{n,p}$. But I'm having trouble showing $\|\cdot\|_q<\|\cdot\|_p$ . Also, is there a specific canonical embedding between the two spaces?",,"['real-analysis', 'functional-analysis']"
22,Evaluation of $\int_0^1 \frac{\log^2(1+x)}{x} \ dx$,Evaluation of,\int_0^1 \frac{\log^2(1+x)}{x} \ dx,"One of the ways to approach it lies in the area of the dilogarithm, but is it possible to evaluate it by other means of the real analysis (without using dilogarithm)? $$\int_0^1 \frac{\log^2(1+x)}{x} \ dx$$ EDIT : maybe you're aware of some easy way to do that. I'd appreciate it! Some words on the generalization case (by means of the real analysis again)? $$F(n)=\int_0^1 \frac{\log^n(1+x)}{x} \ dx, \space n\in \mathbb{N}$$","One of the ways to approach it lies in the area of the dilogarithm, but is it possible to evaluate it by other means of the real analysis (without using dilogarithm)? $$\int_0^1 \frac{\log^2(1+x)}{x} \ dx$$ EDIT : maybe you're aware of some easy way to do that. I'd appreciate it! Some words on the generalization case (by means of the real analysis again)? $$F(n)=\int_0^1 \frac{\log^n(1+x)}{x} \ dx, \space n\in \mathbb{N}$$",,"['real-analysis', 'calculus', 'integration', 'definite-integrals', 'harmonic-numbers']"
23,Why must harmonic functions on compact Riemannian manifolds be constant?,Why must harmonic functions on compact Riemannian manifolds be constant?,,"On a compact Riemannian manifold $(M,g)$ , a function $f$ is called harmonic if $\Delta_{g} f = 0$ , and it is known that the only harmonic function on a compact riemannian manifold is constant function. I wonder how one would prove this. So locally $\Delta_{g}$ is just a second order elliptic operator, thus has the weak maximum principle, which says that the max must appear on the boundary. However I do not think this is enough to prove that harmonic functions are constants. Instead, we need the strong maximum principle which I think holds when the operator is strongly elliptic. Is $\Delta_{g}$ strongly elliptic?","On a compact Riemannian manifold , a function is called harmonic if , and it is known that the only harmonic function on a compact riemannian manifold is constant function. I wonder how one would prove this. So locally is just a second order elliptic operator, thus has the weak maximum principle, which says that the max must appear on the boundary. However I do not think this is enough to prove that harmonic functions are constants. Instead, we need the strong maximum principle which I think holds when the operator is strongly elliptic. Is strongly elliptic?","(M,g) f \Delta_{g} f = 0 \Delta_{g} \Delta_{g}","['real-analysis', 'differential-geometry', 'partial-differential-equations', 'riemannian-geometry']"
24,Most functions are measurable,Most functions are measurable,,"My professor once said that if you did not use the axiom of choice to build a function $f : \mathbb{R}^n \to \mathbb{R}^m$, then it is Lebesgue measurable. To what extent this is true?","My professor once said that if you did not use the axiom of choice to build a function $f : \mathbb{R}^n \to \mathbb{R}^m$, then it is Lebesgue measurable. To what extent this is true?",,"['real-analysis', 'measure-theory', 'axiom-of-choice']"
25,Why not define infinite derivatives?,Why not define infinite derivatives?,,"Is there any particular reason ""infinite"" derivatives are not well-defined? For example, $x \mapsto x^{\frac 13}$ at $x=0$. More precisely, what is wrong with the following definition of differentiability? Let $f:I \to \mathbb{R}$ be a  real function and let $c$  be an interior point of $I$. If $f$ is continuous at $c$ and the limit   $$\lim_{h \to 0} \frac{f(c+h) - f(c)}{h}$$ exists and is equal to $L$, where $L \in \mathbb{R} \cup \{+\infty, -\infty\}$, $f$ is said to be differentiable at $c$. There doesn't seem to be anything obviously wrong with this. The most important theorem, the mean value theorem, still holds with this definition, according to Wikipedia. Furthermore, unless I'm mistaken, with this definition there is the nice property that if $f:(a,b) \to \mathbb{R}$ is injective and differentiable, $f^{-1}$ is as well. I am assuming, of course, that there are problems since we use the stricter definition: what are they?","Is there any particular reason ""infinite"" derivatives are not well-defined? For example, $x \mapsto x^{\frac 13}$ at $x=0$. More precisely, what is wrong with the following definition of differentiability? Let $f:I \to \mathbb{R}$ be a  real function and let $c$  be an interior point of $I$. If $f$ is continuous at $c$ and the limit   $$\lim_{h \to 0} \frac{f(c+h) - f(c)}{h}$$ exists and is equal to $L$, where $L \in \mathbb{R} \cup \{+\infty, -\infty\}$, $f$ is said to be differentiable at $c$. There doesn't seem to be anything obviously wrong with this. The most important theorem, the mean value theorem, still holds with this definition, according to Wikipedia. Furthermore, unless I'm mistaken, with this definition there is the nice property that if $f:(a,b) \to \mathbb{R}$ is injective and differentiable, $f^{-1}$ is as well. I am assuming, of course, that there are problems since we use the stricter definition: what are they?",,"['calculus', 'real-analysis', 'derivatives']"
26,Union of two $\sigma$-algebras is not $\sigma$-algebra,Union of two -algebras is not -algebra,\sigma \sigma,"Here is another very basic analysis problem but that puzzles me: Find an example of set $X$ and its two $\sigma$-algebras $\mathscr A_1$ and $\mathscr A_2$, such that $\mathscr A_1 \cup \mathscr A_2$ is not $\sigma$-algebra. To me at least, this question looks counter-intuitive since the union of two sets gives the resulting set larger number of elements, thus won't affect its $\sigma$-algebra status. Please help and thank you for your time and effort.","Here is another very basic analysis problem but that puzzles me: Find an example of set $X$ and its two $\sigma$-algebras $\mathscr A_1$ and $\mathscr A_2$, such that $\mathscr A_1 \cup \mathscr A_2$ is not $\sigma$-algebra. To me at least, this question looks counter-intuitive since the union of two sets gives the resulting set larger number of elements, thus won't affect its $\sigma$-algebra status. Please help and thank you for your time and effort.",,"['real-analysis', 'measure-theory']"
27,Proving the inverse of a continuous function is also continuous,Proving the inverse of a continuous function is also continuous,,"Let $E, E'$ be metric spaces, $f: E\to E'$ a continuous function. Prove that if $E$ is compact and $f$ is bijective then $f^{-1}:E' \to E$ is continuous. I know one way to prove it is by showing that if $S\subset E$ and $S$ is closed then $f(s)\subset E'$ is also closed where $s\in S$. Since $S$ is closed then $p_n \in S$ and $p_n \to p_0$ in $E$ then $p_o\in S$. Since $E$ is compact there is a convergent subsequence. How can I do this proof?","Let $E, E'$ be metric spaces, $f: E\to E'$ a continuous function. Prove that if $E$ is compact and $f$ is bijective then $f^{-1}:E' \to E$ is continuous. I know one way to prove it is by showing that if $S\subset E$ and $S$ is closed then $f(s)\subset E'$ is also closed where $s\in S$. Since $S$ is closed then $p_n \in S$ and $p_n \to p_0$ in $E$ then $p_o\in S$. Since $E$ is compact there is a convergent subsequence. How can I do this proof?",,"['real-analysis', 'metric-spaces', 'continuity', 'compactness', 'inverse']"
28,Proving $\prod_{n=1}^{\infty}\left(1+\frac{1}{n^{3}}\right)=\frac{1}{\pi}\cosh\frac{\pi\sqrt{3}}{2}$,Proving,\prod_{n=1}^{\infty}\left(1+\frac{1}{n^{3}}\right)=\frac{1}{\pi}\cosh\frac{\pi\sqrt{3}}{2},"First I rewrite $\prod_{n=1}^{\infty}\left(1+\frac{1}{n^{3}}\right)$ as $\prod_{n=1}^{\infty}\left(\frac{1+n^{3}}{n^{3}}\right)$ , then by factor out polynomial I get $\prod_{n=1}^{\infty}\left(\frac{(1+n)(n^{2}-n+1)}{n^{3}}\right)$ which is a problem because I can't factor any further which makes me stuck on this step I would hope for any help.","First I rewrite as , then by factor out polynomial I get which is a problem because I can't factor any further which makes me stuck on this step I would hope for any help.",\prod_{n=1}^{\infty}\left(1+\frac{1}{n^{3}}\right) \prod_{n=1}^{\infty}\left(\frac{1+n^{3}}{n^{3}}\right) \prod_{n=1}^{\infty}\left(\frac{(1+n)(n^{2}-n+1)}{n^{3}}\right),"['real-analysis', 'calculus', 'limits', 'infinite-product']"
29,"If $f$ is Lebesgue measurable on $[0,1]$ then there exists a Borel measurable function $g$ such that $f=g$ a.e.?",If  is Lebesgue measurable on  then there exists a Borel measurable function  such that  a.e.?,"f [0,1] g f=g","If $f:[0,1]\to\mathbb{R}$ is Lebesgue measurable then there exists a Borel measurable function $g:[0,1]\to\mathbb{R}$ such that $f=g$ a.e.?",If is Lebesgue measurable then there exists a Borel measurable function such that a.e.?,"f:[0,1]\to\mathbb{R} g:[0,1]\to\mathbb{R} f=g","['real-analysis', 'analysis', 'measure-theory', 'examples-counterexamples']"
30,Showing a compact metric space has a countable dense subset,Showing a compact metric space has a countable dense subset,,"I know that this is separable, but that has not been covered by the text at this point. I believe my proof (below) to be correct, but not very rigorous. Assuming that it actually is correct, could someone please help me make it more formal? (If it's not correct, please help with the proof). Thanks. Proof : Let $X$ be a compact metric space. Let $B_n = \{B(x,\frac1{n}) : x\in X\}$. be the collection of open balls centered at $x$. Let $\{x\}^{(n)}$ be the set of centers for some particular $n$. Then by compactness of $X$, there are also a finite number of centers for a particular $n$ (corresponding to each open ball). [This is where I have trouble properly saying what's on my mind:] Consider $B(x,r_0)$, where $r_0 = \frac{1}{n_0}$. When we decrease the magnitude of $r_0$ to $r_1$, we must still be able to cover $X$. Meaning some open ball(s) must be ""formed"" where $B(x,r_0)$ was once ""covering"". So by adding open balls, we also add to our collection of centers. This means at $B(x,r_0)$, there was originally a point $y \in B(x,r_0)$ s.t. $B(y,r') \subset B(x,r_0)$ for some $r'$. That is, $B(x,r_0)$ contained another point of $X$. Thus, by definition, $X$ contains a countable dense subset.","I know that this is separable, but that has not been covered by the text at this point. I believe my proof (below) to be correct, but not very rigorous. Assuming that it actually is correct, could someone please help me make it more formal? (If it's not correct, please help with the proof). Thanks. Proof : Let $X$ be a compact metric space. Let $B_n = \{B(x,\frac1{n}) : x\in X\}$. be the collection of open balls centered at $x$. Let $\{x\}^{(n)}$ be the set of centers for some particular $n$. Then by compactness of $X$, there are also a finite number of centers for a particular $n$ (corresponding to each open ball). [This is where I have trouble properly saying what's on my mind:] Consider $B(x,r_0)$, where $r_0 = \frac{1}{n_0}$. When we decrease the magnitude of $r_0$ to $r_1$, we must still be able to cover $X$. Meaning some open ball(s) must be ""formed"" where $B(x,r_0)$ was once ""covering"". So by adding open balls, we also add to our collection of centers. This means at $B(x,r_0)$, there was originally a point $y \in B(x,r_0)$ s.t. $B(y,r') \subset B(x,r_0)$ for some $r'$. That is, $B(x,r_0)$ contained another point of $X$. Thus, by definition, $X$ contains a countable dense subset.",,"['real-analysis', 'analysis', 'solution-verification']"
31,Every open cover of the real numbers has a countable subcover (Lindelöf's lemma),Every open cover of the real numbers has a countable subcover (Lindelöf's lemma),,"How to prove for every open cover of the real numbers $\mathbb{R}$ there is a countable subcover? Without using more sophisticated results from topology, assuming only a real analysis background. I've found a proof using second-countable space characterization, but since i never studied general topology before, it's hard to associate a countable base on the real line. My intuition says to transform the open cover into disjoint open subsets, but how to achieve that?","How to prove for every open cover of the real numbers $\mathbb{R}$ there is a countable subcover? Without using more sophisticated results from topology, assuming only a real analysis background. I've found a proof using second-countable space characterization, but since i never studied general topology before, it's hard to associate a countable base on the real line. My intuition says to transform the open cover into disjoint open subsets, but how to achieve that?",,"['real-analysis', 'general-topology']"
32,What is a Dynkin system? ($\lambda$-system),What is a Dynkin system? (-system),\lambda,"Until recently, all my knowledge of measure theory and Lebesgue integration are from Rudin's book, which focuses solely on the Lebesgue measure, its construction and nothing else. I have just put my hands on a nice book ""Measure and Integration Theory"" by Heinz Bauer and I'm currently enjoying it. I have encountered the definition of a Dynkin system $\mathcal D$ , which is a family of subsets of a set $\Omega$ satisfying 1.) $\Omega\in\mathcal D$ . 2.) If $A\in\mathcal D$ , then $A^c\in\mathcal D$ . 3.) For $n\in\Bbb N$ , if $A_n\in\mathcal D$ are pairwise disjoint then $\bigcup_{n=1}^{\infty}A_n\in\mathcal D$ . I have some idea about what a $\sigma$ -algebra is, but not about a Dynkin system. I would really appreciate if someone could give me an intuition about Dynkin systems or what they're supposed to represent. What is the characteristics of a Dynkin system that let you recognize it once you see it? I know the $\pi$ - $\lambda$ theorem and facts like a Dynkin system $\mathcal D$ is a $\sigma$ -algebra if it is closed under intersection, it would be also nice if anyone could explain to me why should we expect such a result. Thank you in advance.","Until recently, all my knowledge of measure theory and Lebesgue integration are from Rudin's book, which focuses solely on the Lebesgue measure, its construction and nothing else. I have just put my hands on a nice book ""Measure and Integration Theory"" by Heinz Bauer and I'm currently enjoying it. I have encountered the definition of a Dynkin system , which is a family of subsets of a set satisfying 1.) . 2.) If , then . 3.) For , if are pairwise disjoint then . I have some idea about what a -algebra is, but not about a Dynkin system. I would really appreciate if someone could give me an intuition about Dynkin systems or what they're supposed to represent. What is the characteristics of a Dynkin system that let you recognize it once you see it? I know the - theorem and facts like a Dynkin system is a -algebra if it is closed under intersection, it would be also nice if anyone could explain to me why should we expect such a result. Thank you in advance.",\mathcal D \Omega \Omega\in\mathcal D A\in\mathcal D A^c\in\mathcal D n\in\Bbb N A_n\in\mathcal D \bigcup_{n=1}^{\infty}A_n\in\mathcal D \sigma \pi \lambda \mathcal D \sigma,"['real-analysis', 'probability', 'measure-theory', 'descriptive-set-theory']"
33,How much proof knowledge is necessary to begin Spivak's Calculus? [duplicate],How much proof knowledge is necessary to begin Spivak's Calculus? [duplicate],,"This question already has answers here : What books are prerequisites for Spivak's Calculus? (5 answers) Closed 2 years ago . I bought Spivak's Calculus a month or so ago, and after doing a few problems from the first chapter, it's apparent that I need some type of foundational knowledge in formal maths and proofs. What did you study prior to Spivak? What books did you use? I've purchased Velleman's How To Prove It , but I'm not  sure if this book will help me tackle an introductory elementary analysis book.","This question already has answers here : What books are prerequisites for Spivak's Calculus? (5 answers) Closed 2 years ago . I bought Spivak's Calculus a month or so ago, and after doing a few problems from the first chapter, it's apparent that I need some type of foundational knowledge in formal maths and proofs. What did you study prior to Spivak? What books did you use? I've purchased Velleman's How To Prove It , but I'm not  sure if this book will help me tackle an introductory elementary analysis book.",,['calculus']
34,Differentiation wrt parameter $\int_0^\infty \sin^2(x)\cdot(x^2(x^2+1))^{-1}dx$,Differentiation wrt parameter,\int_0^\infty \sin^2(x)\cdot(x^2(x^2+1))^{-1}dx,"Use differentiation with respect to parameter obtaining a differential equation to solve $$ \int_0^\infty \frac{\sin^2(x)}{x^2(x^2+1)}dx $$ No complex variables, only this approach.  Interesting integral and it should have a nice ODE.  I have not found the right way yet.  we have singularities at $x=\pm i$.","Use differentiation with respect to parameter obtaining a differential equation to solve $$ \int_0^\infty \frac{\sin^2(x)}{x^2(x^2+1)}dx $$ No complex variables, only this approach.  Interesting integral and it should have a nice ODE.  I have not found the right way yet.  we have singularities at $x=\pm i$.",,"['real-analysis', 'integration', 'definite-integrals', 'contest-math', 'leibniz-integral-rule']"
35,An inflection point where the second derivative doesn't exist?,An inflection point where the second derivative doesn't exist?,,"A point $x=c$ is an inflection point if the function is continuous at that point and the concavity of the graph changes at that point.  And a list of possible inflection points will be those points where the second derivative is zero or doesn't exist. But if continuity is required in order for a point to be an inflection point, how can we consider points where the second derivative doesn't exist as inflection points? Also, an inflection point is like a critical point except it isn't an extremum, correct?  So why do we consider points where the second derivative doesn't exist as inflection points? thanks.","A point $x=c$ is an inflection point if the function is continuous at that point and the concavity of the graph changes at that point.  And a list of possible inflection points will be those points where the second derivative is zero or doesn't exist. But if continuity is required in order for a point to be an inflection point, how can we consider points where the second derivative doesn't exist as inflection points? Also, an inflection point is like a critical point except it isn't an extremum, correct?  So why do we consider points where the second derivative doesn't exist as inflection points? thanks.",,"['calculus', 'real-analysis', 'derivatives', 'continuity']"
36,"Why if $f'$ is unbounded, then $f$ isn't uniformly continuous?","Why if  is unbounded, then  isn't uniformly continuous?",f' f,"I've $I =  [0 ,+\infty)\,$ and $f: I \rightarrow \Bbb R.$ a. I've proved that if $f'$ is bounded on $I$ then $f$ is uniformly continuous on $I$. b. I've proved that if $\lim f' = \infty$ (with $x \rightarrow +\infty$) then $f$ isn't uniformly continuous on $I$. c. Now I should prove that if $f'$ is unbounded on $I,$ then isn't uniformly continuous on $I$. Using b I've proved that if c is wrong, there is a segement $T = [0, t]$ where $f'$ is unbounded. Added: the also known that $f'$ exists on every point on $I.$","I've $I =  [0 ,+\infty)\,$ and $f: I \rightarrow \Bbb R.$ a. I've proved that if $f'$ is bounded on $I$ then $f$ is uniformly continuous on $I$. b. I've proved that if $\lim f' = \infty$ (with $x \rightarrow +\infty$) then $f$ isn't uniformly continuous on $I$. c. Now I should prove that if $f'$ is unbounded on $I,$ then isn't uniformly continuous on $I$. Using b I've proved that if c is wrong, there is a segement $T = [0, t]$ where $f'$ is unbounded. Added: the also known that $f'$ exists on every point on $I.$",,"['real-analysis', 'analysis', 'uniform-continuity']"
37,Showing that $ |\cos x|+|\cos 2x|+\cdots+|\cos 2^nx|\geq \dfrac{n}{2\sqrt{2}}$,Showing that, |\cos x|+|\cos 2x|+\cdots+|\cos 2^nx|\geq \dfrac{n}{2\sqrt{2}},For every nonnegative integer $n$ and every real number $ x$ prove the inequality: $$\sum_{k=0}^n|\cos(2^kx)|= |\cos x|+|\cos 2x|+\cdots+|\cos 2^nx|\geq \dfrac{n}{2\sqrt{2}}$$,For every nonnegative integer $n$ and every real number $ x$ prove the inequality: $$\sum_{k=0}^n|\cos(2^kx)|= |\cos x|+|\cos 2x|+\cdots+|\cos 2^nx|\geq \dfrac{n}{2\sqrt{2}}$$,,"['real-analysis', 'analysis', 'trigonometry', 'inequality', 'contest-math']"
38,How can we calculate $(x^x)'$,How can we calculate,(x^x)',"We know that $(x^{n})' = nx^{n - 1}$ and $(n^{x})' = n^{x}\ln n$. My question is: how can calculate the formula of $x^x$? What about: $$\left(x^{x^{{ \begin{array}{ccc}  &\;&.\cdot^.\\ &n\; times & \\  .\cdot^. & & \; \end{array} }^x}}\right)' = ? $$ Is there any way to find a general formula? When $n$ is 2, we will have $x^x$. If n is 3, we will have $x^{x^x}$, and so on.","We know that $(x^{n})' = nx^{n - 1}$ and $(n^{x})' = n^{x}\ln n$. My question is: how can calculate the formula of $x^x$? What about: $$\left(x^{x^{{ \begin{array}{ccc}  &\;&.\cdot^.\\ &n\; times & \\  .\cdot^. & & \; \end{array} }^x}}\right)' = ? $$ Is there any way to find a general formula? When $n$ is 2, we will have $x^x$. If n is 3, we will have $x^{x^x}$, and so on.",,"['calculus', 'real-analysis']"
39,Compute $\lim_{n\to\infty} \left(\int_0^{\pi} \frac{\sin^2 n x}{\sin x} \ dx-\sum_{k=1}^n \frac{1}{k}\right)$,Compute,\lim_{n\to\infty} \left(\int_0^{\pi} \frac{\sin^2 n x}{\sin x} \ dx-\sum_{k=1}^n \frac{1}{k}\right),Compute the limit  $$\lim_{n\to\infty} \left(\int_0^{\pi} \frac{\sin^2 n x}{\sin x} \ dx-\sum_{k=1}^n \frac{1}{k}\right)$$,Compute the limit  $$\lim_{n\to\infty} \left(\int_0^{\pi} \frac{\sin^2 n x}{\sin x} \ dx-\sum_{k=1}^n \frac{1}{k}\right)$$,,"['calculus', 'real-analysis', 'sequences-and-series', 'limits', 'definite-integrals']"
40,Let $A\subset\mathbb{R}$ be an uncountable set of irrational numbers. Does there exist a finite $B\subset A$ such that $\sum_{x\in B} x\in\mathbb{Q}?$,Let  be an uncountable set of irrational numbers. Does there exist a finite  such that,A\subset\mathbb{R} B\subset A \sum_{x\in B} x\in\mathbb{Q}?,"Let $A\subset\mathbb{R}$ be an uncountable set of irrational numbers. Does there exist a nonempty finite subset $B\subset A$ such that $\displaystyle\sum_{x\in B}x \in \mathbb{Q}\ ?$ If we change ""uncountable"" to ""countable"" then the answer is trivially no, as $\ A=\{ q\pi: q\in\mathbb{Q}_{>0} \}\ $ is a counter-example. I believe there is no analogue to this counter-example to my question above. I am unsure how to answer the question, although I sense that maybe the Baire Category Theorem could be helpful, but I have poor familiarity with this theorem and it's applications.","Let be an uncountable set of irrational numbers. Does there exist a nonempty finite subset such that If we change ""uncountable"" to ""countable"" then the answer is trivially no, as is a counter-example. I believe there is no analogue to this counter-example to my question above. I am unsure how to answer the question, although I sense that maybe the Baire Category Theorem could be helpful, but I have poor familiarity with this theorem and it's applications.",A\subset\mathbb{R} B\subset A \displaystyle\sum_{x\in B}x \in \mathbb{Q}\ ? \ A=\{ q\pi: q\in\mathbb{Q}_{>0} \}\ ,"['real-analysis', 'general-topology', 'examples-counterexamples', 'irrational-numbers']"
41,What is the closed form of this sum?,What is the closed form of this sum?,,"What is the closed form of this sum? $$ S = \sum_{k\ge1, r>s\ge 1}\frac{1}{k^2(r^2 + s^2)^2} $$ Note : Though originally posted for Pythagorean triplets, their was an flaw in the question which changed the meaning of the question and was answered accordingly. I will post a separate question with the original question on Pythagorean triangles. Update : I have posted the related question of Pythagorean triangles in the link belwo What is the sum of the reciprocal of the square of hypotenuse of Pythagorean triangles?","What is the closed form of this sum? Note : Though originally posted for Pythagorean triplets, their was an flaw in the question which changed the meaning of the question and was answered accordingly. I will post a separate question with the original question on Pythagorean triangles. Update : I have posted the related question of Pythagorean triangles in the link belwo What is the sum of the reciprocal of the square of hypotenuse of Pythagorean triangles?","
S = \sum_{k\ge1, r>s\ge 1}\frac{1}{k^2(r^2 + s^2)^2}
","['real-analysis', 'sequences-and-series', 'geometry', 'number-theory', 'summation']"
42,"Must a continuous, non-constant, and periodic functions have a smallest period?","Must a continuous, non-constant, and periodic functions have a smallest period?",,"Let $D\subset\mathbb R$ and let $T\in(0,\infty)$ . A function $f\colon D\longrightarrow\mathbb R$ is called a periodic function with period $T$ if, for each $x\in D$ , $x+T\in D$ and $f(x+T)=f(x)$ . If $D\subset\mathbb R$ and if $f\colon D\longrightarrow\mathbb R$ is a continuous, not constant and periodic function, must there be, among all periods of $f$ , a minimal one? I posted a similar question a year ago. The difference is that now I am adding an extra hypothesis, namely that $f$ is not constant. All that I was able to prove was that the infimum of the set of periods has to be greater than $0$ .","Let and let . A function is called a periodic function with period if, for each , and . If and if is a continuous, not constant and periodic function, must there be, among all periods of , a minimal one? I posted a similar question a year ago. The difference is that now I am adding an extra hypothesis, namely that is not constant. All that I was able to prove was that the infimum of the set of periods has to be greater than .","D\subset\mathbb R T\in(0,\infty) f\colon D\longrightarrow\mathbb R T x\in D x+T\in D f(x+T)=f(x) D\subset\mathbb R f\colon D\longrightarrow\mathbb R f f 0","['real-analysis', 'continuity', 'periodic-functions']"
43,integral of $\int \limits_{0}^{\infty}\frac {\sin (x^n)} {x^n}dx$,integral of,\int \limits_{0}^{\infty}\frac {\sin (x^n)} {x^n}dx,"what is the answer of  $$\int \limits_{0}^{\infty}\frac {\sin (x^n)} {x^n}dx$$ From this A sine integral $\int_0^{\infty} \left(\frac{\sin x }{x }\right)^n\,\mathrm{d}x$ I saw the answer for $$\int \limits_{0}^{\infty}\left(\frac {\sin x} {x}\right)^ndx$$ but for my question i didn't see any answer is there any help thanks for all","what is the answer of  $$\int \limits_{0}^{\infty}\frac {\sin (x^n)} {x^n}dx$$ From this A sine integral $\int_0^{\infty} \left(\frac{\sin x }{x }\right)^n\,\mathrm{d}x$ I saw the answer for $$\int \limits_{0}^{\infty}\left(\frac {\sin x} {x}\right)^ndx$$ but for my question i didn't see any answer is there any help thanks for all",,"['calculus', 'real-analysis', 'integration', 'improper-integrals', 'closed-form']"
44,integral involving a periodic function,integral involving a periodic function,,"Let $f:[0,1] \longrightarrow \mathbb R$ be a continuous function, and let $g:\mathbb R \longrightarrow \mathbb R$ be a continuous and periodic function with period $1$. Prove that $\displaystyle\lim_{n\to \infty}\int_0^1f(x)g(nx)dx=\left(\int_0^1f(x)dx\right)\left(\int_0^1g(x)dx\right)$. any Ideas?","Let $f:[0,1] \longrightarrow \mathbb R$ be a continuous function, and let $g:\mathbb R \longrightarrow \mathbb R$ be a continuous and periodic function with period $1$. Prove that $\displaystyle\lim_{n\to \infty}\int_0^1f(x)g(nx)dx=\left(\int_0^1f(x)dx\right)\left(\int_0^1g(x)dx\right)$. any Ideas?",,"['real-analysis', 'limits']"
45,Continuous and bounded variation does not imply absolutely continuous,Continuous and bounded variation does not imply absolutely continuous,,I know that a continuous function which is a BV may not be absolutely continuous.  Is there an example of such a function?   I was looking for a BV whose derivative is not Lebesgue integrable but I couldn't find one.,I know that a continuous function which is a BV may not be absolutely continuous.  Is there an example of such a function?   I was looking for a BV whose derivative is not Lebesgue integrable but I couldn't find one.,,"['real-analysis', 'examples-counterexamples', 'bounded-variation', 'absolute-continuity']"
46,"Is the property ""being a derivative"" preserved under multiplication and composition?","Is the property ""being a derivative"" preserved under multiplication and composition?",,"Since differentiation is linear, we therefore have that if $f, g: I\to \mathbb{R}$ is a derivative (where $I\subset \mathbb{R}$ is an interval), then so does their linear combination. What if we consider their multiplication and composition? Due to the forms of the product rule of differentiation of product function and chain rule of differentiation of composition, I highly doubt their product or composition necessarily is still a derivative, but I cannot construct counterexamples.","Since differentiation is linear, we therefore have that if $f, g: I\to \mathbb{R}$ is a derivative (where $I\subset \mathbb{R}$ is an interval), then so does their linear combination. What if we consider their multiplication and composition? Due to the forms of the product rule of differentiation of product function and chain rule of differentiation of composition, I highly doubt their product or composition necessarily is still a derivative, but I cannot construct counterexamples.",,"['real-analysis', 'examples-counterexamples']"
47,Some integral representations of the Euler–Mascheroni constant,Some integral representations of the Euler–Mascheroni constant,,"What kind of substitution should I use to obtain the following integrals? $$\begin{align} \int_0^1 \ln \ln \left(\frac{1}{x}\right)\,dx &=\int_0^\infty e^{-x} \ln x\,dx\tag1\\ &=\int_0^\infty \left(\frac{1}{xe^x} - \frac{1}{e^x-1} \right)\,dx\tag2\\ &=-\int_0^1 \left(\frac{1}{1-x} + \frac{1}{\ln x} \right)\,dx\tag3\\ &=\int_0^\infty \left( e^{-x} - \frac{1}{1+x^k} \right)\,\frac{dx}{x},\qquad k>0\tag4\\ \end{align}$$ This is not homework problems and I know that the above integrals equal to $-\gamma$ (where $\gamma$ is the Euler-Mascheroni constant). I got these integrals while reading this Wikipedia page . According to Wikipedia, the Euler–Mascheroni constant is defined as the limiting difference between the harmonic series and the natural logarithm: $$\gamma=\lim_{N\to\infty} \left(\sum_{k=1}^N \frac{1}{k} - \ln N\right)$$ but I don't know why can this definition be associated to the above integrals? I can obtain the equation $(1)$ using substitution $t=\ln \left(\frac{1}{x}\right)\rightarrow x=e^{-t} \rightarrow dx=-e^{-t}\,dt$ and I know that $$\int_0^\infty e^{-x} \ln x\,dx=\Gamma'(1)=\Gamma(1)\psi(1)=-\gamma$$ but I can't obtain the rest. Any idea? Any help would be appreciated. Thanks in advance.","What kind of substitution should I use to obtain the following integrals? This is not homework problems and I know that the above integrals equal to (where is the Euler-Mascheroni constant). I got these integrals while reading this Wikipedia page . According to Wikipedia, the Euler–Mascheroni constant is defined as the limiting difference between the harmonic series and the natural logarithm: but I don't know why can this definition be associated to the above integrals? I can obtain the equation using substitution and I know that but I can't obtain the rest. Any idea? Any help would be appreciated. Thanks in advance.","\begin{align}
\int_0^1 \ln \ln \left(\frac{1}{x}\right)\,dx
&=\int_0^\infty e^{-x} \ln x\,dx\tag1\\
&=\int_0^\infty \left(\frac{1}{xe^x} - \frac{1}{e^x-1} \right)\,dx\tag2\\
&=-\int_0^1 \left(\frac{1}{1-x} + \frac{1}{\ln x} \right)\,dx\tag3\\
&=\int_0^\infty \left( e^{-x} - \frac{1}{1+x^k} \right)\,\frac{dx}{x},\qquad k>0\tag4\\
\end{align} -\gamma \gamma \gamma=\lim_{N\to\infty} \left(\sum_{k=1}^N \frac{1}{k} - \ln N\right) (1) t=\ln \left(\frac{1}{x}\right)\rightarrow x=e^{-t} \rightarrow dx=-e^{-t}\,dt \int_0^\infty e^{-x} \ln x\,dx=\Gamma'(1)=\Gamma(1)\psi(1)=-\gamma","['calculus', 'real-analysis', 'integration', 'sequences-and-series', 'improper-integrals']"
48,Do rational functions eventually have monotonic derivatives?,Do rational functions eventually have monotonic derivatives?,,"Given a rational function $R(x)=P(x)/Q(x)$ with real coefficients, is it true that there exists an $M>0$ such that, for every $k\geq 0$ , the restrictions $R^{(k)}|_{(-\infty,-M]}$ and $R^{(k)}|_{[M,\infty)}$ of the $k$ -th derivatives $R^{(k)}(x)$ are all monotonic? Or, in other words, is all the interesting stuff happening inside $[-M,M]$ to all orders? If we take the $k$ -th derivative of $P/Q$ , it can be proven by induction that it will be of the form $H/Q^{2^k}$ with $\deg H\leq p+(2^k-1)q-k$ where $p=\deg P$ and $q=\deg Q$ . Idk if this is of any help. (Edit: notice that we're asking if $\exists M\forall k \ldots$ and not just if $\forall k \exists M_k\ldots$ ; the latter is easy because a polynomial changes sign only finitely many times)","Given a rational function with real coefficients, is it true that there exists an such that, for every , the restrictions and of the -th derivatives are all monotonic? Or, in other words, is all the interesting stuff happening inside to all orders? If we take the -th derivative of , it can be proven by induction that it will be of the form with where and . Idk if this is of any help. (Edit: notice that we're asking if and not just if ; the latter is easy because a polynomial changes sign only finitely many times)","R(x)=P(x)/Q(x) M>0 k\geq 0 R^{(k)}|_{(-\infty,-M]} R^{(k)}|_{[M,\infty)} k R^{(k)}(x) [-M,M] k P/Q H/Q^{2^k} \deg H\leq p+(2^k-1)q-k p=\deg P q=\deg Q \exists M\forall k \ldots \forall k \exists M_k\ldots","['real-analysis', 'rational-functions']"
49,Proving Cauchy condensation test,Proving Cauchy condensation test,,"I have to prove the condensation test of Cauchy by tomorrow and I am really unconfident about what I did: $$\sum_{n=1}^\infty a_n\text{ converges } \iff \sum_{n=1}^\infty 2^n a_{2^n}\text{ converges}$$ I did the following: Let $(b_n)$ be a sequence as follow: $b_{2^k+m}:=a_{2^k}$ with $k\in\mathbb N_0$ and $0\leq m<2^k$. It's $a_{n+1}\leq a_n$ and so $0\leq a_{n+p}\leq a_n$ for all $n,p\in\mathbb N$. So $\sum\limits_{n=1}^\infty b_n$ converges by the majorizing series $\sum\limits_{n=1}^\infty a_n$. And it's $\sum\limits_{n=0}^\infty b_n=\sum\limits_{n=0}^\infty\sum\limits_{m=0}^{2^n-1}a_{2^{n+1}}=\sum\limits_{n=1}^\infty 2^{n-1}a_{2^n}$ so $\Rightarrow$ is done. For $\Leftarrow$ consider $c_{2^k+m}:=a_{2^k}$ with $k\in\mathbb N_0$ and $0\leq m<2^k$. It's $|a_n|\leq c_n$ and $\sum\limits_{n=0}^\infty c_n=\sum\limits_{n=0}^\infty\sum\limits_{m=0}^{2^n-1}a_{2^{n}}=\sum\limits_{n=1}^\infty 2^{n}a_{2^n}$ and so $\sum\limits_{n=1}^\infty a_n$ converges by the majorizing series $\sum\limits_{n=0}^\infty c_n$. Is this in form and content correct?","I have to prove the condensation test of Cauchy by tomorrow and I am really unconfident about what I did: $$\sum_{n=1}^\infty a_n\text{ converges } \iff \sum_{n=1}^\infty 2^n a_{2^n}\text{ converges}$$ I did the following: Let $(b_n)$ be a sequence as follow: $b_{2^k+m}:=a_{2^k}$ with $k\in\mathbb N_0$ and $0\leq m<2^k$. It's $a_{n+1}\leq a_n$ and so $0\leq a_{n+p}\leq a_n$ for all $n,p\in\mathbb N$. So $\sum\limits_{n=1}^\infty b_n$ converges by the majorizing series $\sum\limits_{n=1}^\infty a_n$. And it's $\sum\limits_{n=0}^\infty b_n=\sum\limits_{n=0}^\infty\sum\limits_{m=0}^{2^n-1}a_{2^{n+1}}=\sum\limits_{n=1}^\infty 2^{n-1}a_{2^n}$ so $\Rightarrow$ is done. For $\Leftarrow$ consider $c_{2^k+m}:=a_{2^k}$ with $k\in\mathbb N_0$ and $0\leq m<2^k$. It's $|a_n|\leq c_n$ and $\sum\limits_{n=0}^\infty c_n=\sum\limits_{n=0}^\infty\sum\limits_{m=0}^{2^n-1}a_{2^{n}}=\sum\limits_{n=1}^\infty 2^{n}a_{2^n}$ and so $\sum\limits_{n=1}^\infty a_n$ converges by the majorizing series $\sum\limits_{n=0}^\infty c_n$. Is this in form and content correct?",,['real-analysis']
50,Show that $f(x+y)=f(x)+f(y)$ implies $f$ continuous $\Leftrightarrow$ $f$ measurable [duplicate],Show that  implies  continuous   measurable [duplicate],f(x+y)=f(x)+f(y) f \Leftrightarrow f,"This question already has answers here : Additivity + Measurability $\implies$ Continuity (2 answers) Closed 2 years ago . Let $f:\mathbb R \rightarrow \mathbb R$, and for every $x,y\in \mathbb R$ we have $f(x+y)=f(x)+f(y)$. Show that $f$ measurable $\Leftrightarrow f$ continuous.","This question already has answers here : Additivity + Measurability $\implies$ Continuity (2 answers) Closed 2 years ago . Let $f:\mathbb R \rightarrow \mathbb R$, and for every $x,y\in \mathbb R$ we have $f(x+y)=f(x)+f(y)$. Show that $f$ measurable $\Leftrightarrow f$ continuous.",,"['real-analysis', 'functional-equations']"
51,"Calculating in closed form $\int_0^{\pi/2} \arctan\left(\sin ^3(x)\right) \, dx \ ?$",Calculating in closed form,"\int_0^{\pi/2} \arctan\left(\sin ^3(x)\right) \, dx \ ?","It's not hard to see that for powers like $1,2$, we have a nice closed form. What can be said about the cubic version, that is $$\int_0^{\pi/2} \arctan\left(\sin ^3(x)\right) \, dx \ ?$$ What are your ideas on it? Differentiation under the integral sign? Other ways? Mathematica 9 says that $$\int_0^{\pi/2} \arctan\left(\sin ^3(x)\right) \, dx=\frac{2}{3} \, _5F_4\left(\frac{1}{2},\frac{2}{3},1,1,\frac{4}{3};\frac{5}{6},\frac{7}{6},\frac{3}{2},\frac{3}{2};-1\right).$$","It's not hard to see that for powers like $1,2$, we have a nice closed form. What can be said about the cubic version, that is $$\int_0^{\pi/2} \arctan\left(\sin ^3(x)\right) \, dx \ ?$$ What are your ideas on it? Differentiation under the integral sign? Other ways? Mathematica 9 says that $$\int_0^{\pi/2} \arctan\left(\sin ^3(x)\right) \, dx=\frac{2}{3} \, _5F_4\left(\frac{1}{2},\frac{2}{3},1,1,\frac{4}{3};\frac{5}{6},\frac{7}{6},\frac{3}{2},\frac{3}{2};-1\right).$$",,"['calculus', 'real-analysis', 'integration', 'definite-integrals', 'polylogarithm']"
52,"A nicer closed form? $\int_0^1 \frac{\log (x) \log \left(x^2-x+1\right)}{x^2-x+2} \, dx$",A nicer closed form?,"\int_0^1 \frac{\log (x) \log \left(x^2-x+1\right)}{x^2-x+2} \, dx","Mathematica doesn't return a nice result for the integral below, maybe because such one doesn't exist, or it exists but it depends much on a certain way of tackling things. What do you think? $$\int_0^1 \frac{\log (x) \log \left(x^2-x+1\right)}{x^2-x+2} \, dx$$ $$=\frac{2 i \log ^3(2)}{3 \sqrt{7}}+\frac{i \log \left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}+\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}+\frac{i \log \left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log ^2(2)}{\sqrt{7}}+\frac{2 i \log \left(3-i \sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(i-\sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right) \log ^2(2)}{\sqrt{7}}-\frac{2 i \log \left(3+i \sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{\pi  \log ^2(2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log (4) \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{2 i \log (4) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{2 \pi  \log \left(i-\sqrt{7}\right) \log (2)}{3 \sqrt{7}}+\frac{2 i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(i-\sqrt{7}\right) \log \left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 \pi  \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{4 \pi  \log \left(7+i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{4 \pi  \log \left(7-i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{4 \pi  \log (7) \log (2)}{\sqrt{7}}-\frac{8 \pi  \log (8) \log (2)}{\sqrt{7}}-\frac{i \log (16) \log \left(i+\sqrt{3}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(i+\sqrt{3}\right) \log \left(-i+\sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(-i+\sqrt{3}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{\pi  \log (64) \log (2)}{3 \sqrt{7}}-\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{3 \sqrt{7}}-\frac{2 \pi  \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{3 \sqrt{7}}+\frac{503 \pi ^3}{648 \sqrt{7}}+\frac{i \log ^3\left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}+\frac{i \log (4) \log ^2\left(-i-\sqrt{3}\right)}{\sqrt{7}}+\frac{i \log (64) \log ^2\left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{\pi  \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{\pi  \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log (8) \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}+\frac{i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}+\frac{\pi  \log ^2\left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right)}{3 \sqrt{7}}+\frac{2 i \pi ^2 \log \left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{i \log (4) \log (64) \log \left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}+\frac{i \pi ^2 \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{2 \sqrt{7}}+\frac{5 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{13 i \pi ^2 \log \left(i-\sqrt{7}\right)}{18 \sqrt{7}}+\frac{2 \pi  \log (32) \log \left(i-\sqrt{7}\right)}{3 \sqrt{7}}+\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}+\frac{i \pi ^2 \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right)}{\sqrt{7}}+\frac{2 i \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}+\frac{2 \pi  \log (3) \log \left(7+i \sqrt{7}\right)}{\sqrt{7}}+\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(7+i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(i+\sqrt{3}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log (64) \log \left(i+\sqrt{3}\right) \log \left(3-i \sqrt{7}\right)}{3 \sqrt{7}}+\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(7-i \sqrt{7}\right)}{\sqrt{7}}+\frac{2 \pi  \log (3) \log \left(\frac{1}{448} \left(7-i \sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log (4) \log ^2\left(i-\sqrt{3}\right)}{\sqrt{7}}-\frac{i \log (4) \log ^2\left(i+\sqrt{3}\right)}{\sqrt{7}}-\frac{i \log \left(i-\sqrt{7}\right) \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{4 \pi  \log (7) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{8 \pi  \log (8) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(i+\sqrt{3}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log \left(-(-1)^{2/3} \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{2 i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(-i-\sqrt{3}\right) \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log ^2\left(-i+\sqrt{3}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^3\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}-\frac{i \log ^3\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}-\frac{i \pi ^2 \log \left(i+\sqrt{3}\right)}{3 \sqrt{7}}-\frac{5 \pi  \log \left(i-\sqrt{7}\right) \log \left(\left(-1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{i \pi ^2 \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{\pi  \log \left(i-\sqrt{7}\right) \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{5 \pi  \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{6 \sqrt{7}}-\frac{4 i \pi ^2 \log \left(\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)\right)}{9 \sqrt{7}}-\frac{i \pi ^2 \log (45671926166590716193865151022383844364247891968)}{36 \sqrt{7}} ...\text{and so on (that means many other terms)}$$","Mathematica doesn't return a nice result for the integral below, maybe because such one doesn't exist, or it exists but it depends much on a certain way of tackling things. What do you think? $$\int_0^1 \frac{\log (x) \log \left(x^2-x+1\right)}{x^2-x+2} \, dx$$ $$=\frac{2 i \log ^3(2)}{3 \sqrt{7}}+\frac{i \log \left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}+\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}+\frac{i \log \left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log ^2(2)}{\sqrt{7}}+\frac{2 i \log \left(3-i \sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(i-\sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{i \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right) \log ^2(2)}{\sqrt{7}}-\frac{2 i \log \left(3+i \sqrt{7}\right) \log ^2(2)}{\sqrt{7}}-\frac{\pi  \log ^2(2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{i \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log (4) \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{2 i \log (4) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}+\frac{2 \pi  \log \left(i-\sqrt{7}\right) \log (2)}{3 \sqrt{7}}+\frac{2 i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(i-\sqrt{7}\right) \log \left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 \pi  \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{4 \pi  \log \left(7+i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right) \log (2)}{\sqrt{7}}+\frac{4 \pi  \log \left(7-i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{4 \pi  \log (7) \log (2)}{\sqrt{7}}-\frac{8 \pi  \log (8) \log (2)}{\sqrt{7}}-\frac{i \log (16) \log \left(i+\sqrt{3}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(i+\sqrt{3}\right) \log \left(-i+\sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(-i+\sqrt{3}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{2 i \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right) \log (2)}{\sqrt{7}}-\frac{\pi  \log (64) \log (2)}{3 \sqrt{7}}-\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log (2)}{3 \sqrt{7}}-\frac{2 \pi  \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right) \log (2)}{3 \sqrt{7}}+\frac{503 \pi ^3}{648 \sqrt{7}}+\frac{i \log ^3\left(\frac{(-1)^{5/6}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log ^3\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}+\frac{i \log (4) \log ^2\left(-i-\sqrt{3}\right)}{\sqrt{7}}+\frac{i \log (64) \log ^2\left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{\pi  \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{\pi  \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log (8) \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}+\frac{i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}+\frac{\pi  \log ^2\left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right)}{3 \sqrt{7}}+\frac{2 i \pi ^2 \log \left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{i \log (4) \log (64) \log \left(-i+\sqrt{3}\right)}{3 \sqrt{7}}+\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}+\frac{i \pi ^2 \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{2 \sqrt{7}}+\frac{5 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}+\frac{13 i \pi ^2 \log \left(i-\sqrt{7}\right)}{18 \sqrt{7}}+\frac{2 \pi  \log (32) \log \left(i-\sqrt{7}\right)}{3 \sqrt{7}}+\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}+\frac{i \pi ^2 \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right)}{\sqrt{7}}+\frac{2 i \log \left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}+\frac{2 \pi  \log (3) \log \left(7+i \sqrt{7}\right)}{\sqrt{7}}+\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(7+i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(i+\sqrt{3}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}+\frac{i \log (64) \log \left(i+\sqrt{3}\right) \log \left(3-i \sqrt{7}\right)}{3 \sqrt{7}}+\frac{4 \pi  \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(7-i \sqrt{7}\right)}{\sqrt{7}}+\frac{2 \pi  \log (3) \log \left(\frac{1}{448} \left(7-i \sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log (4) \log ^2\left(i-\sqrt{3}\right)}{\sqrt{7}}-\frac{i \log (4) \log ^2\left(i+\sqrt{3}\right)}{\sqrt{7}}-\frac{i \log \left(i-\sqrt{7}\right) \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log ^2\left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{i-\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{4 \pi  \log (7) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{8 \pi  \log (8) \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right)}{\sqrt{7}}-\frac{i \log ^2\left(i+\sqrt{3}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(-i+\sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\sqrt[6]{-1} \left(1+i \sqrt{7}\right)\right) \log \left(-(-1)^{2/3} \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{2 i \log \left(-\frac{1}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(\left(-1+\sqrt[3]{-1}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{2 i \log (4) \log \left(-i-\sqrt{3}\right) \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{\sqrt{7}}-\frac{i \log ^2\left(-i+\sqrt{3}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^2\left(\frac{\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3+i \sqrt{7}\right)}{\sqrt{7}}-\frac{2 i \log \left(\frac{-i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right) \log \left(\frac{\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)}{\sqrt{3}-\sqrt{7}}\right) \log \left(3-i \sqrt{7}\right)}{\sqrt{7}}-\frac{i \log ^3\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}-\frac{i \log ^3\left(-\frac{i+\sqrt{3}}{\sqrt{3}-\sqrt{7}}\right)}{3 \sqrt{7}}-\frac{i \pi ^2 \log \left(i+\sqrt{3}\right)}{3 \sqrt{7}}-\frac{5 \pi  \log \left(i-\sqrt{7}\right) \log \left(\left(-1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{i \pi ^2 \log \left(\left(1-i \sqrt{3}\right) \left(-i+\sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{\pi  \log \left(i-\sqrt{7}\right) \log \left(\left(i+\sqrt{3}\right) \left(1+i \sqrt{7}\right)\right)}{3 \sqrt{7}}-\frac{5 \pi  \log ^2\left(-\frac{2}{\sqrt{3}-\sqrt{7}}\right)}{6 \sqrt{7}}-\frac{4 i \pi ^2 \log \left(\left(-i+\sqrt{3}\right) \left(1-i \sqrt{7}\right)\right)}{9 \sqrt{7}}-\frac{i \pi ^2 \log (45671926166590716193865151022383844364247891968)}{36 \sqrt{7}} ...\text{and so on (that means many other terms)}$$",,"['calculus', 'real-analysis', 'integration', 'definite-integrals']"
53,"Sequence in $C[0,1]$ with no convergent subsequence",Sequence in  with no convergent subsequence,"C[0,1]","I am trying to show that $C[0,1],$ the space of all real - valued continuous functions  with the sup metric is not sequentially compact with the sup metric by showing that the sequence $f_n = x^n$ has no convergent subsequence. The sup metric $\|\cdot\|$ is defined as $$\|f - g \| = \sup_{x \in [0,1]} |f(x) - g(x)|$$ where $|\cdot|$ is the ordinary Euclidean metric. Now I know that $f_n \rightarrow f$ pointwise, where $$f = \begin{cases} 0, & 0 \leq x < 1 \\ 1, & x = 1.\end{cases}$$ However $f \notin C[0,1]$ so this means by theorem 7.12 of Baby Rudin that $f_n$ cannot converge to $f$ uniformly. However how does this tell me that no subsequence of $f_n$ can converge to something in $C[0,1]$? Thanks.","I am trying to show that $C[0,1],$ the space of all real - valued continuous functions  with the sup metric is not sequentially compact with the sup metric by showing that the sequence $f_n = x^n$ has no convergent subsequence. The sup metric $\|\cdot\|$ is defined as $$\|f - g \| = \sup_{x \in [0,1]} |f(x) - g(x)|$$ where $|\cdot|$ is the ordinary Euclidean metric. Now I know that $f_n \rightarrow f$ pointwise, where $$f = \begin{cases} 0, & 0 \leq x < 1 \\ 1, & x = 1.\end{cases}$$ However $f \notin C[0,1]$ so this means by theorem 7.12 of Baby Rudin that $f_n$ cannot converge to $f$ uniformly. However how does this tell me that no subsequence of $f_n$ can converge to something in $C[0,1]$? Thanks.",,['real-analysis']
54,Are all measure zero sets measurable?,Are all measure zero sets measurable?,,"Definition of Lebesgue Outer Measure : Given a set $E$ of $\mathbb R$, we define the Lebesgue Outer Measure of $E$ by, $$m^*(E) = \inf \left\{\sum_{n=1}^{+\infty} \ell(I_n): E \subset \bigcup_{n=1}^{+\infty}I_n \right\}$$ where $\ell(I_n)$ denotes the length of interval (bounded and nonempty interval). Definition of measurable set : A set $E$ measurable if $$m^*(T) = m^*(T \cap E) + m^*(T \cap E^c)$$ for every subset of $T$ of $\mathbb R$. If $E \subset \mathbb R$ with $m^*(E) = 0$ and $\exists$ finite interval $I,$ such that $E \subset I, $, then is $E$ measurable? If $E \subset \mathbb R$ with $m^*(E) = 0$, then is $E$ measurable?","Definition of Lebesgue Outer Measure : Given a set $E$ of $\mathbb R$, we define the Lebesgue Outer Measure of $E$ by, $$m^*(E) = \inf \left\{\sum_{n=1}^{+\infty} \ell(I_n): E \subset \bigcup_{n=1}^{+\infty}I_n \right\}$$ where $\ell(I_n)$ denotes the length of interval (bounded and nonempty interval). Definition of measurable set : A set $E$ measurable if $$m^*(T) = m^*(T \cap E) + m^*(T \cap E^c)$$ for every subset of $T$ of $\mathbb R$. If $E \subset \mathbb R$ with $m^*(E) = 0$ and $\exists$ finite interval $I,$ such that $E \subset I, $, then is $E$ measurable? If $E \subset \mathbb R$ with $m^*(E) = 0$, then is $E$ measurable?",,"['real-analysis', 'measure-theory', 'lebesgue-measure']"
55,Integral $\int_0^{\pi/2} \theta^2 \log ^4(2\cos \theta) d\theta =\frac{33\pi^7}{4480}+\frac{3\pi}{2}\zeta^2(3)$,Integral,\int_0^{\pi/2} \theta^2 \log ^4(2\cos \theta) d\theta =\frac{33\pi^7}{4480}+\frac{3\pi}{2}\zeta^2(3),"$$ I=\int_0^{\pi/2}  \theta^2 \log ^4(2\cos \theta) d\theta =\frac{33\pi^7}{4480}+\frac{3\pi}{2}\zeta^2(3). $$ Note $\zeta(3)$ is given by $$ \zeta(3)=\sum_{n=1}^\infty \frac{1}{n^3}. $$ I have a previous post related to this except the logarithm power is squared and not to the 4th power.  If you are interested in seeing this result go here: Integral $\int_0^\pi \theta^2 \ln^2\big(2\cos\frac{\theta}{2}\big)d \theta$. .  However, I am wondering how to calculate the result shown above.  Thanks.","$$ I=\int_0^{\pi/2}  \theta^2 \log ^4(2\cos \theta) d\theta =\frac{33\pi^7}{4480}+\frac{3\pi}{2}\zeta^2(3). $$ Note $\zeta(3)$ is given by $$ \zeta(3)=\sum_{n=1}^\infty \frac{1}{n^3}. $$ I have a previous post related to this except the logarithm power is squared and not to the 4th power.  If you are interested in seeing this result go here: Integral $\int_0^\pi \theta^2 \ln^2\big(2\cos\frac{\theta}{2}\big)d \theta$. .  However, I am wondering how to calculate the result shown above.  Thanks.",,"['calculus', 'real-analysis', 'integration', 'definite-integrals', 'contour-integration']"
56,"If $f_n(x_n) \to f(x)$ whenever $x_n \to x$, show that $f$ is continuous","If  whenever , show that  is continuous",f_n(x_n) \to f(x) x_n \to x f,"From Pugh's analysis book, prelim problem 57 from Chapter 4: Let $f$ and $f_n$ be functions from $\Bbb R$ to $\Bbb R$. Assume that $f_n(x_n)\to f(x)$ as $n\to\infty$ whenever $x_n\to x$. Prove that $f$ is continuous. (Note: the functions $f_n$ are not assumed to be continuous.) here's my attempt: assume $x_n \to x$. we want to show that $f(x_n) \to f(x)$. so $|f(x_n) - f(x)| \leq |f(x_n)-f_n(x_n)| + |f_n(x_n)-f(x)|$. The second term can be made to be less than any $\varepsilon > 0$ for $n$ sufficiently large. i'm having trouble with the first term. can anyone help? thank you!","From Pugh's analysis book, prelim problem 57 from Chapter 4: Let $f$ and $f_n$ be functions from $\Bbb R$ to $\Bbb R$. Assume that $f_n(x_n)\to f(x)$ as $n\to\infty$ whenever $x_n\to x$. Prove that $f$ is continuous. (Note: the functions $f_n$ are not assumed to be continuous.) here's my attempt: assume $x_n \to x$. we want to show that $f(x_n) \to f(x)$. so $|f(x_n) - f(x)| \leq |f(x_n)-f_n(x_n)| + |f_n(x_n)-f(x)|$. The second term can be made to be less than any $\varepsilon > 0$ for $n$ sufficiently large. i'm having trouble with the first term. can anyone help? thank you!",,['real-analysis']
57,Let $(x_n)$ be a bounded but not convergent sequence. Prove that $(x_n)$ has two subsequences converging to different limits.,Let  be a bounded but not convergent sequence. Prove that  has two subsequences converging to different limits.,(x_n) (x_n),"Let $(x_n)$ be a bounded but not convergent sequence. Prove that $(x_n)$ has two subsequences converging to different limits. My attempt is:  Since the sequence is bounded , there exists $M>0$ such  that $x_n \in [-M,M]$ for all $n \in \mathbb{N}$. Since the sequence does not converge to $x$, there exists $\epsilon_0>0$ such that $ \forall N \in \mathbb{N}$, there exists $n \geq N$ such that $|x_n-x| \geq \epsilon_0$. Then we have $x_n \in [-M,x-\epsilon_0] \cup x_n \in [x+\epsilon_0,M]$. By Bolzano-weierstrass theorem, there exists a convergent subsequence in the two intervals. Is my proof valid? ${}{}$","Let $(x_n)$ be a bounded but not convergent sequence. Prove that $(x_n)$ has two subsequences converging to different limits. My attempt is:  Since the sequence is bounded , there exists $M>0$ such  that $x_n \in [-M,M]$ for all $n \in \mathbb{N}$. Since the sequence does not converge to $x$, there exists $\epsilon_0>0$ such that $ \forall N \in \mathbb{N}$, there exists $n \geq N$ such that $|x_n-x| \geq \epsilon_0$. Then we have $x_n \in [-M,x-\epsilon_0] \cup x_n \in [x+\epsilon_0,M]$. By Bolzano-weierstrass theorem, there exists a convergent subsequence in the two intervals. Is my proof valid? ${}{}$",,['real-analysis']
58,How do i prove that every open set in $\mathbb{R}^2$ is a union of at most countable open rectangles?,How do i prove that every open set in  is a union of at most countable open rectangles?,\mathbb{R}^2,"I know that every open set in $\mathbb{R}$ is a disjoint union of at most countable segments. But how do i prove that every open set in $\mathbb{R}^2$ is a union of at most countable open rectangles? Moreover, is it true for $\mathbb{R}^k$ if open rectangle is replaced to open $k$-dimensional open rectangle?","I know that every open set in $\mathbb{R}$ is a disjoint union of at most countable segments. But how do i prove that every open set in $\mathbb{R}^2$ is a union of at most countable open rectangles? Moreover, is it true for $\mathbb{R}^k$ if open rectangle is replaced to open $k$-dimensional open rectangle?",,"['real-analysis', 'general-topology']"
59,"Prove that $\sum\limits_{cyc}\frac{a}{a^{11}+1}\leq\frac{3}{2}$ for $a, b, c > 0$ with $abc = 1$",Prove that  for  with,"\sum\limits_{cyc}\frac{a}{a^{11}+1}\leq\frac{3}{2} a, b, c > 0 abc = 1","Let $a$ , $b$ and $c$ be positive numbers such  that $abc=1$ . Prove that: $$\frac{a}{a^{11}+1}+\frac{b}{b^{11}+1}+\frac{c}{c^{11}+1}\leq\frac{3}{2}.$$ I tried homogenization and the BW ( https://artofproblemsolving.com/community/c6h522084 ), but it does not work. Indeed, let $a=\frac{x}{y}$ , $b=\frac{y}{z}$ , where $x$ , $y$ and $z$ are positives. Hence, $c=\frac{z}{x}$ and we need to prove that $$\sum_{cyc}\frac{xy^{10}}{x^{11}+y^{11}}\leq\frac{3}{2},$$ which has a problem around $(x,y,z)=(7,5,6)$ . For these values $$\frac{3}{2}-\sum_{cyc}\frac{xy^{10}}{x^{11}+y^{11}}=0.0075...$$ I tried also TL, uvw, C-S, Lagrange multipliers and more, but without success. Also, Vasc's Theorems don't help. Also, the following method does not help here. Find the maximum of the expression Because the inequality $\frac{x}{x^{11}+1}\leq\frac{3(a^9+1)}{4(a^{18}+a^9+1)}$ is wrong.","Let , and be positive numbers such  that . Prove that: I tried homogenization and the BW ( https://artofproblemsolving.com/community/c6h522084 ), but it does not work. Indeed, let , , where , and are positives. Hence, and we need to prove that which has a problem around . For these values I tried also TL, uvw, C-S, Lagrange multipliers and more, but without success. Also, Vasc's Theorems don't help. Also, the following method does not help here. Find the maximum of the expression Because the inequality is wrong.","a b c abc=1 \frac{a}{a^{11}+1}+\frac{b}{b^{11}+1}+\frac{c}{c^{11}+1}\leq\frac{3}{2}. a=\frac{x}{y} b=\frac{y}{z} x y z c=\frac{z}{x} \sum_{cyc}\frac{xy^{10}}{x^{11}+y^{11}}\leq\frac{3}{2}, (x,y,z)=(7,5,6) \frac{3}{2}-\sum_{cyc}\frac{xy^{10}}{x^{11}+y^{11}}=0.0075... \frac{x}{x^{11}+1}\leq\frac{3(a^9+1)}{4(a^{18}+a^9+1)}","['real-analysis', 'multivariable-calculus', 'inequality', 'symmetric-polynomials']"
60,When does $(uv)'=u'v'?$ [duplicate],When does  [duplicate],(uv)'=u'v'?,"This question already has answers here : When does product of derivatives equals derivative of products? (2 answers) Closed 10 years ago . In any calculus course, one of the first thing we learn is that $(uv)'=u'v+v'u$ rather than the what I've written in the title. This got me wondering: when is this dream product rule true? There are of course trivial examples, and also many instances where the equality is true at a handful of points. Less obvious though, is the following: Are there non-constant $u,v$ such that there exists an interval $I$ where   $(uv)'=u'v'$ over $I?$ I have a feeling there should be, but I am having trouble constructing such a pair.","This question already has answers here : When does product of derivatives equals derivative of products? (2 answers) Closed 10 years ago . In any calculus course, one of the first thing we learn is that $(uv)'=u'v+v'u$ rather than the what I've written in the title. This got me wondering: when is this dream product rule true? There are of course trivial examples, and also many instances where the equality is true at a handful of points. Less obvious though, is the following: Are there non-constant $u,v$ such that there exists an interval $I$ where   $(uv)'=u'v'$ over $I?$ I have a feeling there should be, but I am having trouble constructing such a pair.",,"['calculus', 'real-analysis', 'analysis', 'ordinary-differential-equations', 'derivatives']"
61,Extremely hard and stimulating (undergraduate) real analysis $problems$,Extremely hard and stimulating (undergraduate) real analysis,problems,"To put it simply: I have seen many problem books in real analysis (also on this website), but the exercises they propose seem quite standardized. What are problem books that propose really challenging and stimulating problems (as opposed to standardized exercises)?","To put it simply: I have seen many problem books in real analysis (also on this website), but the exercises they propose seem quite standardized. What are problem books that propose really challenging and stimulating problems (as opposed to standardized exercises)?",,"['calculus', 'real-analysis', 'analysis', 'reference-request', 'soft-question']"
62,Every closed subset $E\subseteq \mathbb{R}^n$ is the zero point set of a smooth function,Every closed subset  is the zero point set of a smooth function,E\subseteq \mathbb{R}^n,"In Walter Rudin's Principles of mathematical analysis Exercise 5.21, it is proved that for any closed subset $E\subseteq \mathbb{R}$, there exists a smooth function $f$ on $\mathbb{R}$ such that $E=\{x\in \mathbb{R}\mid f(x)=0\}$. Since $E^c$ is open in $\mathbb{R}$, $E^c$ is a countable disjoint union of open intervals $(a_i,b_i)$. On an interval $(a,b)$, if we let $f(x)=\exp(\frac{1}{(x-a)(x-b)})$, $x\in(a,b)$; $f(x)=0$, $x\notin(a,b)$, ($f(x)=\exp(\frac{1}{(x-a)})$ or $f(x)=\exp(\frac{1}{(x-b)})$ on $(a,\infty)$ and $(-\infty,b)$ resp.), then $f$ is smooth. Hence we can get a smooth function on $\mathbb{R}$ such that $E$ is the zero point sets of $f$. (1). How about a closed subset $E$ of $\mathbb{R}^n$? is it true that for any closed subset $E\subseteq \mathbb{R}^n$, there exists a smooth function $f$ on $\mathbb{R}^n$ such that $E=\{x\in \mathbb{R}^n\mid f(x)=0\}$? An open set in $\mathbb{R}^n$ cannot be written as a disjoint union of countable open balls hence the proof above is not valid. The partition of unity only claims that for an  open set $U$, there exists open $V$ in $U$ such that $\bar V\subseteq U$ and a smooth function $f$ on $\mathbb{R}^n$ such that $supp f\subseteq U$, $f|_V=1$. (2). The taylor series of $f(x)=\exp(\frac{1}{(x-a)(x-b)})$ does not converge around points $a,b$ hence $f$ is not analytic at $a,b$. Is it true that for any closed subset $E\subseteq \mathbb{R}$, there exists an analytic function $f$ on $\mathbb{R}$ such that $E=\{x\in \mathbb{R}\mid f(x)=0\}$?","In Walter Rudin's Principles of mathematical analysis Exercise 5.21, it is proved that for any closed subset $E\subseteq \mathbb{R}$, there exists a smooth function $f$ on $\mathbb{R}$ such that $E=\{x\in \mathbb{R}\mid f(x)=0\}$. Since $E^c$ is open in $\mathbb{R}$, $E^c$ is a countable disjoint union of open intervals $(a_i,b_i)$. On an interval $(a,b)$, if we let $f(x)=\exp(\frac{1}{(x-a)(x-b)})$, $x\in(a,b)$; $f(x)=0$, $x\notin(a,b)$, ($f(x)=\exp(\frac{1}{(x-a)})$ or $f(x)=\exp(\frac{1}{(x-b)})$ on $(a,\infty)$ and $(-\infty,b)$ resp.), then $f$ is smooth. Hence we can get a smooth function on $\mathbb{R}$ such that $E$ is the zero point sets of $f$. (1). How about a closed subset $E$ of $\mathbb{R}^n$? is it true that for any closed subset $E\subseteq \mathbb{R}^n$, there exists a smooth function $f$ on $\mathbb{R}^n$ such that $E=\{x\in \mathbb{R}^n\mid f(x)=0\}$? An open set in $\mathbb{R}^n$ cannot be written as a disjoint union of countable open balls hence the proof above is not valid. The partition of unity only claims that for an  open set $U$, there exists open $V$ in $U$ such that $\bar V\subseteq U$ and a smooth function $f$ on $\mathbb{R}^n$ such that $supp f\subseteq U$, $f|_V=1$. (2). The taylor series of $f(x)=\exp(\frac{1}{(x-a)(x-b)})$ does not converge around points $a,b$ hence $f$ is not analytic at $a,b$. Is it true that for any closed subset $E\subseteq \mathbb{R}$, there exists an analytic function $f$ on $\mathbb{R}$ such that $E=\{x\in \mathbb{R}\mid f(x)=0\}$?",,"['real-analysis', 'general-topology', 'complex-analysis', 'derivatives']"
63,Convergence in measure and almost everywhere,Convergence in measure and almost everywhere,,"In a finite measure space, let $\{f_{n}\}$ be a sequence of measurable functions. Show that $f_{n}  \rightarrow f$ in measure if and only if every subsequence $\{f_{n_{k}}\}$ contains a subsequence $\{f_{n_{k_{j}}}\}$, that converges almost everywhere to f. I can prove from converge in measure to converge almost everywhere, but I don't know how to write it down for the other direction.","In a finite measure space, let $\{f_{n}\}$ be a sequence of measurable functions. Show that $f_{n}  \rightarrow f$ in measure if and only if every subsequence $\{f_{n_{k}}\}$ contains a subsequence $\{f_{n_{k_{j}}}\}$, that converges almost everywhere to f. I can prove from converge in measure to converge almost everywhere, but I don't know how to write it down for the other direction.",,"['real-analysis', 'measure-theory', 'convergence-divergence']"
64,What operations is a metric closed under?,What operations is a metric closed under?,,"Suppose $X$ is a set with a metric $d: X \times X \rightarrow \mathbb{R}$. What ""operations"" on $d$ will yield a metric in return? By this I mean a wide variety of things. For example, what functions $g: \mathbb{R} \rightarrow \mathbb{R}$ will make $g \circ d$ into a metric, for example $g \circ d = \sqrt{d}$. Or what functions of metrics will yield metrics in return, for example $d_1 + d_2$, where $d_1$ and $d_2$ are distinct metrics on $X$. I'm looking for a list of such operations, and counterexamples of ones which plausibly seem like they could define a metric but do not.","Suppose $X$ is a set with a metric $d: X \times X \rightarrow \mathbb{R}$. What ""operations"" on $d$ will yield a metric in return? By this I mean a wide variety of things. For example, what functions $g: \mathbb{R} \rightarrow \mathbb{R}$ will make $g \circ d$ into a metric, for example $g \circ d = \sqrt{d}$. Or what functions of metrics will yield metrics in return, for example $d_1 + d_2$, where $d_1$ and $d_2$ are distinct metrics on $X$. I'm looking for a list of such operations, and counterexamples of ones which plausibly seem like they could define a metric but do not.",,"['real-analysis', 'general-topology', 'metric-spaces']"
65,open conjectures in real analysis targeting real valued functions of a single real variable,open conjectures in real analysis targeting real valued functions of a single real variable,,I am hoping that this question (if in acceptable form) be community wiki. Are there any open conjectures in real analysis primarily targeting real valued functions of a single real variable ? (it may involve other concepts but primarily targeting these type of functions and no involvement of number theory). Its not that i am going to attack them right away ( not due to lack of interest but time) but am just curious to know them. Also how difficult it is get a new result in this area ?,I am hoping that this question (if in acceptable form) be community wiki. Are there any open conjectures in real analysis primarily targeting real valued functions of a single real variable ? (it may involve other concepts but primarily targeting these type of functions and no involvement of number theory). Its not that i am going to attack them right away ( not due to lack of interest but time) but am just curious to know them. Also how difficult it is get a new result in this area ?,,"['real-analysis', 'soft-question', 'big-list', 'conjectures']"
66,Proving the countability of algebraic numbers,Proving the countability of algebraic numbers,,"I am trying to prove that algebraic numbers are countably infinite, and I have a hint to use: after fixing the degree of the polynomial, consider summing the absolute values of its integer coefficients, and setting the sum less than or equal to $m$, for each $m \in \mathbb{N}$. I am also allowed to use the fact that every polynomial has a finite number of roots. I am not sure where to begin... Perhaps after fixing the degree of the polynomials, I could try enumerating them, and after proving countability of the set that contains the roots of all polynomials of a certain degree, I could state that the union of infinitely many ($\bigcup_{n=1}^{\infty}$, $n \in \mathbb{N}$) countably infinite sets is countable, and thus the algebraic numbers are countably infinite, too, but I am not sure if this is a good approach/how to enumerate the polynomials. Thanks!","I am trying to prove that algebraic numbers are countably infinite, and I have a hint to use: after fixing the degree of the polynomial, consider summing the absolute values of its integer coefficients, and setting the sum less than or equal to $m$, for each $m \in \mathbb{N}$. I am also allowed to use the fact that every polynomial has a finite number of roots. I am not sure where to begin... Perhaps after fixing the degree of the polynomials, I could try enumerating them, and after proving countability of the set that contains the roots of all polynomials of a certain degree, I could state that the union of infinitely many ($\bigcup_{n=1}^{\infty}$, $n \in \mathbb{N}$) countably infinite sets is countable, and thus the algebraic numbers are countably infinite, too, but I am not sure if this is a good approach/how to enumerate the polynomials. Thanks!",,"['real-analysis', 'elementary-set-theory']"
67,For what values does the geothmetic meandian converge?,For what values does the geothmetic meandian converge?,,"The geothmetic meandian, $G_{MDN}$ is defined in this XKCD as $$F(x_1, x_2, ..., x_n) = \left(\frac{x_1 +x_2+\cdots+x_n}{n}, \sqrt[n]{x_1 x_2 \cdots x_n}, x_{\frac{n+1}{2}} \right)$$ $$G_{MDN}(x_1, x_2, \ldots, x_n) = F(F(F(\ldots F(x_1, x_2, \ldots, x_n)\ldots)))$$ The comic also (correctly) claims that $G_{MDN}(1, 1, 2, 3, 5) \approx 2.089$ There are two convergence questions I'm interested in: For what values of $(x_1, x_2, \ldots, x_n)$ does $G_{MDN}$ converge to a single number? For what values of $(x_1, x_2, \ldots, x_n)$ does $G_{MDN}$ converge, but not to a single number? I've written up Python 3 code so that you can test out numbers yourself by changing the values at the bottom of the code. If the code never seems to stop running, then $G_{MDN}$ does not converge for your input. (In these situations, you can set verbose=True to see what's happening.) # assumes Python 3 because I assume that ""/"" always means float division from typing import Iterable, Tuple, Union from decimal import Decimal import math from functools import reduce  # Required in Python 3 import operator  # from https://stackoverflow.com/a/48648756 def prod(iterable):     return reduce(operator.mul, iterable, 1)  def geothmetic_meandian(nums: Iterable[float], verbose=False) -> Tuple[bool, Tuple[float, float, float]]:     def inner_geothmetic_meandian(nums: Iterable[float]) -> Tuple[float]:         arithmetic_mean = sum(nums)/len(nums)         geometric_mean = prod(nums)**(1 / len(nums))         sorted_nums = sorted(list(nums))         if len(nums) % 2 == 0:             # even number of numbers             higher_median_index = int(len(nums) / 2)             lower_median_index = higher_median_index - 1             median = (sorted_nums[higher_median_index] + sorted_nums[lower_median_index]) / 2         else:             # odd number of numbers             median = sorted_nums[int((len(nums) - 1) / 2)]          return (arithmetic_mean, geometric_mean, median)      last_ans = None     ans = inner_geothmetic_meandian(nums)     converged = True     while not (ans[0] == ans[1] == ans[2]):         if ans == last_ans:             converged = False             break         last_ans = ans         ans = inner_geothmetic_meandian(ans)          if verbose:             print(ans)      return converged, ans   if __name__ == ""__main__"":     verbose = False     values = (1, 1, 3, 2, 5)     converged, results = geothmetic_meandian(values, verbose=verbose)     if converged:         print(f""The geothmetic meandian of {values} converged to: {results[0]}"")     else:         print(f""The geothmetic meandian of {values} did not converge to a single value:\nArithmetic Mean: {results[0]}\nGeometric Mean:  {results[1]}\nMedian:          {results[2]}"") I've tested this code to verify that $G_{MDN}(1, 1, 2, 3, 5) \approx 2.089$ . I have also not found any inputs that cause the program to not converge at all. However, I have found that $G_{MDN}(1, 2, 3, 4, 5) = (2.8993696858822964, 2.899369685882296, 2.8993696858822964)$ which would mean that $(1, 2, 3, 4, 5)$ is in the second convergence class, where it converged, just not all to the same number. But I'm worried that this result is due to a rounding error in Python itself. (I quickly tried and failed to use the Decimal class due to the nth root operation.) Thus, my hunch is that all inputs converge to a single number , but I have not been able to prove this yet. It looks like an epsilon-delta proof.","The geothmetic meandian, is defined in this XKCD as The comic also (correctly) claims that There are two convergence questions I'm interested in: For what values of does converge to a single number? For what values of does converge, but not to a single number? I've written up Python 3 code so that you can test out numbers yourself by changing the values at the bottom of the code. If the code never seems to stop running, then does not converge for your input. (In these situations, you can set verbose=True to see what's happening.) # assumes Python 3 because I assume that ""/"" always means float division from typing import Iterable, Tuple, Union from decimal import Decimal import math from functools import reduce  # Required in Python 3 import operator  # from https://stackoverflow.com/a/48648756 def prod(iterable):     return reduce(operator.mul, iterable, 1)  def geothmetic_meandian(nums: Iterable[float], verbose=False) -> Tuple[bool, Tuple[float, float, float]]:     def inner_geothmetic_meandian(nums: Iterable[float]) -> Tuple[float]:         arithmetic_mean = sum(nums)/len(nums)         geometric_mean = prod(nums)**(1 / len(nums))         sorted_nums = sorted(list(nums))         if len(nums) % 2 == 0:             # even number of numbers             higher_median_index = int(len(nums) / 2)             lower_median_index = higher_median_index - 1             median = (sorted_nums[higher_median_index] + sorted_nums[lower_median_index]) / 2         else:             # odd number of numbers             median = sorted_nums[int((len(nums) - 1) / 2)]          return (arithmetic_mean, geometric_mean, median)      last_ans = None     ans = inner_geothmetic_meandian(nums)     converged = True     while not (ans[0] == ans[1] == ans[2]):         if ans == last_ans:             converged = False             break         last_ans = ans         ans = inner_geothmetic_meandian(ans)          if verbose:             print(ans)      return converged, ans   if __name__ == ""__main__"":     verbose = False     values = (1, 1, 3, 2, 5)     converged, results = geothmetic_meandian(values, verbose=verbose)     if converged:         print(f""The geothmetic meandian of {values} converged to: {results[0]}"")     else:         print(f""The geothmetic meandian of {values} did not converge to a single value:\nArithmetic Mean: {results[0]}\nGeometric Mean:  {results[1]}\nMedian:          {results[2]}"") I've tested this code to verify that . I have also not found any inputs that cause the program to not converge at all. However, I have found that which would mean that is in the second convergence class, where it converged, just not all to the same number. But I'm worried that this result is due to a rounding error in Python itself. (I quickly tried and failed to use the Decimal class due to the nth root operation.) Thus, my hunch is that all inputs converge to a single number , but I have not been able to prove this yet. It looks like an epsilon-delta proof.","G_{MDN} F(x_1, x_2, ..., x_n) = \left(\frac{x_1 +x_2+\cdots+x_n}{n}, \sqrt[n]{x_1 x_2 \cdots x_n}, x_{\frac{n+1}{2}} \right) G_{MDN}(x_1, x_2, \ldots, x_n) = F(F(F(\ldots F(x_1, x_2, \ldots, x_n)\ldots))) G_{MDN}(1, 1, 2, 3, 5) \approx 2.089 (x_1, x_2, \ldots, x_n) G_{MDN} (x_1, x_2, \ldots, x_n) G_{MDN} G_{MDN} G_{MDN}(1, 1, 2, 3, 5) \approx 2.089 G_{MDN}(1, 2, 3, 4, 5) = (2.8993696858822964, 2.899369685882296, 2.8993696858822964) (1, 2, 3, 4, 5)","['real-analysis', 'limits', 'convergence-divergence', 'means', 'median']"
68,"How to build a smooth ""transition function"" explicitly?","How to build a smooth ""transition function"" explicitly?",,It is easily shown that the function $$\begin{cases} \exp \left(\frac{1}{x^2-1} \right) & |x| < 1 \\ 0 & \text{otherwise} \\ \end{cases}$$ is smooth and has compact support in $\mathbb R$. I tried playing with it to find a function with the following properties: a. $f(x)=0$ for $x \le 0$ b. $f(x)=1$ for $x \ge 1$ c. $f$ is monotonically increasing. d. $f$ is smooth. Is it possible to find an explicit formula for such $f$?,It is easily shown that the function $$\begin{cases} \exp \left(\frac{1}{x^2-1} \right) & |x| < 1 \\ 0 & \text{otherwise} \\ \end{cases}$$ is smooth and has compact support in $\mathbb R$. I tried playing with it to find a function with the following properties: a. $f(x)=0$ for $x \le 0$ b. $f(x)=1$ for $x \ge 1$ c. $f$ is monotonically increasing. d. $f$ is smooth. Is it possible to find an explicit formula for such $f$?,,"['calculus', 'real-analysis']"
69,Prove continuity on a function at every irrational point and discontinuity at every rational point.,Prove continuity on a function at every irrational point and discontinuity at every rational point.,,"Consider the function: $f(x)= \begin{cases}  1/n \quad &\text{if $x= m/n$ in simplest form} \\ 0 \quad &\text{if $x \in \mathbb{R}\setminus\mathbb{Q}$}  \end{cases} $ Prove that the function is continuous at every irrational point and also that the function is not continuous at every rational point.  Also, we can say that the function is continuous at some point $k$ if $\displaystyle\lim_{x \to k} f(x)=f(k)$. I was thinking of doing an epsilon delta proof backwards using the fact that $\mathbb{Q}$ is dense in $\mathbb{R}$ for rational points and irrational points.  Any ways on how to expand on this are welcome.","Consider the function: $f(x)= \begin{cases}  1/n \quad &\text{if $x= m/n$ in simplest form} \\ 0 \quad &\text{if $x \in \mathbb{R}\setminus\mathbb{Q}$}  \end{cases} $ Prove that the function is continuous at every irrational point and also that the function is not continuous at every rational point.  Also, we can say that the function is continuous at some point $k$ if $\displaystyle\lim_{x \to k} f(x)=f(k)$. I was thinking of doing an epsilon delta proof backwards using the fact that $\mathbb{Q}$ is dense in $\mathbb{R}$ for rational points and irrational points.  Any ways on how to expand on this are welcome.",,['real-analysis']
70,"If $f,g$ are uniformly continuous prove $f+g$ is uniformly continuous but $fg$ and $\dfrac{f}{g}$ are not",If  are uniformly continuous prove  is uniformly continuous but  and  are not,"f,g f+g fg \dfrac{f}{g}","Suppose $f:\mathbb{R} \supset E \rightarrow \mathbb{R}$ and $g: \mathbb{R} \supset E \rightarrow \mathbb{R}$ are uniformly continuous. Show that $f+g$ is uniformly continuous. What about $fg$ and $\dfrac{f}{g}$ ? My Attempt Firstly let's state the definition; a function is uniformly continuous if $$\forall \varepsilon >0\ \ \exists \ \ \delta >0 \ \ \text{such that} \ \ |f(x)-f(y)|< \varepsilon \ \ \forall \ \ x,y \in \mathbb{R} \ \ \text{such  that} \ \ |x-y|<\delta$$ Sum $f+g$ Now to to prove $f+g$ is uniformly continuous; $\bullet$ Choose $\delta_1 >0$ such that $\forall$ $x,y \in \mathbb{R}$ $|x-y|<\delta_1$ $\implies$ $|f(x)-f(y)|< \dfrac{\epsilon}{2}$ $\bullet$ Choose $\delta_2 >0$ such that $\forall$ $x,y \in \mathbb{R}$ $|x-y|<\delta_2$ $\implies$ $|g(x)-g(y)|< \dfrac{\varepsilon}{2}$ $\bullet$ Now take $\delta := min\{ \delta_1, \delta_2\}$ Then we obtain for all $x,y \in \mathbb{R}$ $$ |x-y|<\delta \implies |f(x)+g(x)-f(y)+g(y)| < |f(x)-f(y)| + |g(x)-g(y)| < \dfrac{\varepsilon}{2}+\dfrac{\varepsilon}{2}= \varepsilon$$ Product $fg$ Now for $fg$ for this to hold both $f:E \rightarrow \mathbb{R}$ and $g:E \rightarrow \mathbb{R}$ must be bounded , if not it doesn't hold. $\bullet$ $\exists \ \ M>0 \ \  such \ that \ \ |f(x)|<M \ \ and \ \ |g(x)|<M \ \ \forall \ x \in E$ $\bullet$ Choose $\delta_1 >0$ such that $\forall$ $x,y \in \mathbb{R}$ $|x-y|<\delta_1$ $\implies$ $|f(x)-f(y)|< \dfrac{\epsilon}{2M}$ $\bullet$ Choose $\delta_2 >0$ such that $\forall$ $x,y \in \mathbb{R}$ $|x-y|<\delta_2$ $\implies$ $|g(x)-g(y)|< \dfrac{\epsilon}{2M}$ $\bullet$ Now take $\delta := min\{ \delta_1, \delta_2\}$ . Then, $|x-y|<\delta$ implies for all $x,y \in \mathbb{R}$ , that $$|f(x)g(x)-f(y)g(y)| \leq |g(x)||f(x)+f(y)|+|f(y)||g(x)+g(y)| \leq $$ $$ M|f(x)+f(y)| + M|g(x)+g(y)| < M \dfrac{\epsilon}{2M} + M \dfrac{\epsilon}{2M} = \epsilon$$ Are these proofs correct? I am not sure how to approach the $\dfrac{f}{g}$ case.","Suppose and are uniformly continuous. Show that is uniformly continuous. What about and ? My Attempt Firstly let's state the definition; a function is uniformly continuous if Sum Now to to prove is uniformly continuous; Choose such that Choose such that Now take Then we obtain for all Product Now for for this to hold both and must be bounded , if not it doesn't hold. Choose such that Choose such that Now take . Then, implies for all , that Are these proofs correct? I am not sure how to approach the case.","f:\mathbb{R} \supset E \rightarrow \mathbb{R} g: \mathbb{R} \supset E \rightarrow \mathbb{R} f+g fg \dfrac{f}{g} \forall \varepsilon >0\ \ \exists \ \ \delta >0 \ \ \text{such that} \ \ |f(x)-f(y)|< \varepsilon \ \ \forall \ \ x,y \in \mathbb{R} \ \ \text{such  that} \ \ |x-y|<\delta f+g f+g \bullet \delta_1 >0 \forall x,y \in \mathbb{R} |x-y|<\delta_1 \implies |f(x)-f(y)|< \dfrac{\epsilon}{2} \bullet \delta_2 >0 \forall x,y \in \mathbb{R} |x-y|<\delta_2 \implies |g(x)-g(y)|< \dfrac{\varepsilon}{2} \bullet \delta := min\{ \delta_1, \delta_2\} x,y \in \mathbb{R} 
|x-y|<\delta \implies
|f(x)+g(x)-f(y)+g(y)| <
|f(x)-f(y)| + |g(x)-g(y)| <
\dfrac{\varepsilon}{2}+\dfrac{\varepsilon}{2}=
\varepsilon fg fg f:E \rightarrow \mathbb{R} g:E \rightarrow \mathbb{R} \bullet \exists \ \ M>0 \ \  such \ that \ \ |f(x)|<M \ \ and \ \ |g(x)|<M \ \ \forall \ x \in E \bullet \delta_1 >0 \forall x,y \in \mathbb{R} |x-y|<\delta_1 \implies |f(x)-f(y)|< \dfrac{\epsilon}{2M} \bullet \delta_2 >0 \forall x,y \in \mathbb{R} |x-y|<\delta_2 \implies |g(x)-g(y)|< \dfrac{\epsilon}{2M} \bullet \delta := min\{ \delta_1, \delta_2\} |x-y|<\delta x,y \in \mathbb{R} |f(x)g(x)-f(y)g(y)| \leq
|g(x)||f(x)+f(y)|+|f(y)||g(x)+g(y)| \leq
 
M|f(x)+f(y)| + M|g(x)+g(y)| <
M \dfrac{\epsilon}{2M} + M \dfrac{\epsilon}{2M} =
\epsilon \dfrac{f}{g}","['real-analysis', 'proof-verification', 'continuity', 'epsilon-delta', 'uniform-continuity']"
71,Distance to a closed set,Distance to a closed set,,"The distance between a point $a \in \mathbb{R}$ and a set $X \subset \mathbb{R}$ is defined as $$d(a,X) := \inf\{|x-a|: x \in X\}.$$ How to prove if $X$ is closed, then there is a $b \in X$ such that $d(a,X) = |b-a|$ ? I've constructed a decreasing sequence converging to $d$ as follows: Given $r > d(a,X)$ , there is a $x \in X$ such that $|x-a| < r$ . Repeating the process with $r_{n+1} := \frac{d+r_n}{2}$ we get the inequality: $$d \le |x_n-a| < r_n$$ It's easy to prove that $r_n \to d$ , and therefore $|x_n-a| \to d$ . If i could show the set $A := \{|x-a|: x\in X\}$ is closed, the result would be immediate. This is somehow my second question, is true that for every closed set $X$ , the set $|X| := \{|x|: x\in X\}$ is closed? Be free to contribute alternative proofs, i would appreciate.","The distance between a point and a set is defined as How to prove if is closed, then there is a such that ? I've constructed a decreasing sequence converging to as follows: Given , there is a such that . Repeating the process with we get the inequality: It's easy to prove that , and therefore . If i could show the set is closed, the result would be immediate. This is somehow my second question, is true that for every closed set , the set is closed? Be free to contribute alternative proofs, i would appreciate.","a \in \mathbb{R} X \subset \mathbb{R} d(a,X) := \inf\{|x-a|: x \in X\}. X b \in X d(a,X) = |b-a| d r > d(a,X) x \in X |x-a| < r r_{n+1} := \frac{d+r_n}{2} d \le |x_n-a| < r_n r_n \to d |x_n-a| \to d A := \{|x-a|: x\in X\} X |X| := \{|x|: x\in X\}",['real-analysis']
72,Show that bounded continuous functions on $\Bbb R$ with $f(x)=\int_{x}^{x+1}f(t)\mathrm{d}t$ are constant,Show that bounded continuous functions on  with  are constant,\Bbb R f(x)=\int_{x}^{x+1}f(t)\mathrm{d}t,"I was doing my homework and one question occur to me: Let $f$ be a bounded continuous function on $\mathbb{R}$ that satisfies $f(x)=\int_{x}^{x+1}f(t)\mathrm{d}t$ for all $x\in\mathbb{R}$ . Show that $f$ is a constant, i.e. $f\equiv C$ for some $C\in\mathbb{R}$ . I didn't think too much of it, and I thought it was easy. This is my answer: By definition of $f$ it is trivial that $f\in C^\infty(\mathbb{R})$ . By taking the derivative on both side of the equation we obtain $$f^\prime(x)=f(x+1)-f(x),\forall x\in\mathbb{R}.$$ Since $f\in C^\infty(\mathbb{R})$ , it is valid to take the Taylor series of $f$ , i.e. $$f(x+1)-f(x)=\left(f(x)+\frac{f^\prime(x)}{1!}+\frac{f^{\prime\prime}(x)}{2!}+\cdots\right)-f(x)=f^\prime(x)+\frac{f^{\prime\prime}(x)}{2}+\cdots,$$ whence $f^{(k)}(x)=0$ for all $k=2,3,\cdots$ . This implies $f$ is linear. However, if $f(x)=kx+b$ with $k\ne 0$ , it will not satisfy the equation $f(x)=\int_{x}^{x+1}f(t)\mathrm{d}t$ , therefore $f$ is a constant. However, in the instructor's note the proof is very complicated. I wonder whether my proof is correct. Thanks in advance.","I was doing my homework and one question occur to me: Let be a bounded continuous function on that satisfies for all . Show that is a constant, i.e. for some . I didn't think too much of it, and I thought it was easy. This is my answer: By definition of it is trivial that . By taking the derivative on both side of the equation we obtain Since , it is valid to take the Taylor series of , i.e. whence for all . This implies is linear. However, if with , it will not satisfy the equation , therefore is a constant. However, in the instructor's note the proof is very complicated. I wonder whether my proof is correct. Thanks in advance.","f \mathbb{R} f(x)=\int_{x}^{x+1}f(t)\mathrm{d}t x\in\mathbb{R} f f\equiv C C\in\mathbb{R} f f\in C^\infty(\mathbb{R}) f^\prime(x)=f(x+1)-f(x),\forall x\in\mathbb{R}. f\in C^\infty(\mathbb{R}) f f(x+1)-f(x)=\left(f(x)+\frac{f^\prime(x)}{1!}+\frac{f^{\prime\prime}(x)}{2!}+\cdots\right)-f(x)=f^\prime(x)+\frac{f^{\prime\prime}(x)}{2}+\cdots, f^{(k)}(x)=0 k=2,3,\cdots f f(x)=kx+b k\ne 0 f(x)=\int_{x}^{x+1}f(t)\mathrm{d}t f","['real-analysis', 'calculus', 'integration']"
73,Functional inverse of $z=1+w+\cdots+w^{n-1}$,Functional inverse of,z=1+w+\cdots+w^{n-1},"Migrated to MO . I am interested in the functional inverse of $$ z=1+w+\cdots+w^{n-1},\quad w\geq0,\ n>1. $$ This function is strictly increasing on $w\geq0$ and thus admits an inverse. My attempt: By Lagrange's theorem we may write the inverse: $$ w(z)=a+\sum _{k=1}^\infty g_k\frac{(z-f(a))^k}{k!}, $$ with $f(w)=1+w+\cdots+w^{n-1}$ and $$ g_k=\lim_{w\to a}\partial_w^{k-1}\left({\frac {w-a}{f(w)-f(a)}}\right)^k. $$ Expanding $f(w)$ around $w=1$ gives $f(w)=nF(1,1-n;2;1-w)$ , which is a hypergeometric function. Choosing $a=1$ we write $$ \frac{f(w)-f(1)}{w-1}=-n\frac{F(1,1-n,2,1-w)-1}{1-w}=\frac{n(n-1)}{2}F(1,2-n;3;1-w). $$ It follows $$ w(z)=1+\sum _{k=1}^\infty a_k\frac{2^k}{n^k(n-1)^k}\frac{(z-n)^k}{k!}, $$ with $$ a_k=\lim_{w\to 1}\partial_w^{k-1}\left(F(1,2-n;3;1-w)\right)^{-k}. $$ Evaluating the limit for $a_k$ is certainly non-trivial. One thought was to use the Faà di Bruno formula but I am a little unclear on the details of this calculation and am curious if $a_k$ can be written in a ""nice"" form that does not involve Bell polynomials. Could someone please fill me in on the details of computing the $a_k$ 's? Also, for which values of $z$ does this series converge? I was able to write a quick one line code in Mathematica to compute the $a_k$ 's, which may lend itself to finding a pattern: a[k_] := Limit[D[Hypergeometric2F1[1, 2 - n, c, 1 - w]^-k, {w, k - 1}], w -> 1] /. c -> 3 $a_1$ , $a_2$ , and $a_3$ seem to factor nicely while $a_4$ does not. Edit: Using Faà di Bruno's formula I was able to write down an explicit form for the $a_k$ 's giving a final solution of $$ \bbox[5px,border:2px solid #C0A000]{% w(z)=1+\frac{2(z-n)}{n(n-1)}+\sum_{k=2}^\infty\sum_{\ell=1}^{k-1}(-k)^{(\ell)}B_{k-1,\ell}\left(\left\{(-1)^m\tfrac{m!(2-n)_m}{(3)_m}\right\}_{m=1}^{k-\ell}\right)\frac{\left(\frac{2(z-n)}{n(n-1)}\right)^k}{k!},% } $$ where $(s)^{(n)}=\Gamma(s+1)/\Gamma(s-n+1)$ is the falling factorial, $(s)_n=\Gamma(s+n)/\Gamma(s)$ is the Pochhammer symbol, and $B_{n,k}$ is the partial Bell polynomial. It is interesting to note that this result also works for the more general case $\{n\in\Bbb R:n>1\}$ . All that I am still curious about is the radius of convergence for this series which I believe is $|z-n|<n-1$ . Here is Mathematica code to compare the exact function $w(z)$ to approximation obtained by truncating its series expansion: a[k_, n_] :=   Sum[FactorialPower[-k, l] BellY[k - 1, l,      Table[(-1)^m (m! Pochhammer[2 - n, m])/Pochhammer[3, m], {m, 1,        k - l}]], {l, 1, k - 1}] g[z_, n_, K_] :=   1 + (2 (z - n))/(n (n - 1)) +    Sum[a[k, n] ((2 (z - n))/(n (n - 1)))^k/k!, {k, 2, K}] gAprx[z_, n_] :=   Quiet[N[Solve[(1 - w^n)/(1 - w) - z == 0, w, PositiveReals][[1, 1,       2]]]] P[n_] := Manipulate[   Plot[{gAprx[z, n], g[z, n, m]}, {z, 1, 2 n - 1}], {m, 2, 20, 1}] P[5]","Migrated to MO . I am interested in the functional inverse of This function is strictly increasing on and thus admits an inverse. My attempt: By Lagrange's theorem we may write the inverse: with and Expanding around gives , which is a hypergeometric function. Choosing we write It follows with Evaluating the limit for is certainly non-trivial. One thought was to use the Faà di Bruno formula but I am a little unclear on the details of this calculation and am curious if can be written in a ""nice"" form that does not involve Bell polynomials. Could someone please fill me in on the details of computing the 's? Also, for which values of does this series converge? I was able to write a quick one line code in Mathematica to compute the 's, which may lend itself to finding a pattern: a[k_] := Limit[D[Hypergeometric2F1[1, 2 - n, c, 1 - w]^-k, {w, k - 1}], w -> 1] /. c -> 3 , , and seem to factor nicely while does not. Edit: Using Faà di Bruno's formula I was able to write down an explicit form for the 's giving a final solution of where is the falling factorial, is the Pochhammer symbol, and is the partial Bell polynomial. It is interesting to note that this result also works for the more general case . All that I am still curious about is the radius of convergence for this series which I believe is . Here is Mathematica code to compare the exact function to approximation obtained by truncating its series expansion: a[k_, n_] :=   Sum[FactorialPower[-k, l] BellY[k - 1, l,      Table[(-1)^m (m! Pochhammer[2 - n, m])/Pochhammer[3, m], {m, 1,        k - l}]], {l, 1, k - 1}] g[z_, n_, K_] :=   1 + (2 (z - n))/(n (n - 1)) +    Sum[a[k, n] ((2 (z - n))/(n (n - 1)))^k/k!, {k, 2, K}] gAprx[z_, n_] :=   Quiet[N[Solve[(1 - w^n)/(1 - w) - z == 0, w, PositiveReals][[1, 1,       2]]]] P[n_] := Manipulate[   Plot[{gAprx[z, n], g[z, n, m]}, {z, 1, 2 n - 1}], {m, 2, 20, 1}] P[5]","
z=1+w+\cdots+w^{n-1},\quad w\geq0,\ n>1.
 w\geq0 
w(z)=a+\sum _{k=1}^\infty g_k\frac{(z-f(a))^k}{k!},
 f(w)=1+w+\cdots+w^{n-1} 
g_k=\lim_{w\to a}\partial_w^{k-1}\left({\frac {w-a}{f(w)-f(a)}}\right)^k.
 f(w) w=1 f(w)=nF(1,1-n;2;1-w) a=1 
\frac{f(w)-f(1)}{w-1}=-n\frac{F(1,1-n,2,1-w)-1}{1-w}=\frac{n(n-1)}{2}F(1,2-n;3;1-w).
 
w(z)=1+\sum _{k=1}^\infty a_k\frac{2^k}{n^k(n-1)^k}\frac{(z-n)^k}{k!},
 
a_k=\lim_{w\to 1}\partial_w^{k-1}\left(F(1,2-n;3;1-w)\right)^{-k}.
 a_k a_k a_k z a_k a_1 a_2 a_3 a_4 a_k 
\bbox[5px,border:2px solid #C0A000]{%
w(z)=1+\frac{2(z-n)}{n(n-1)}+\sum_{k=2}^\infty\sum_{\ell=1}^{k-1}(-k)^{(\ell)}B_{k-1,\ell}\left(\left\{(-1)^m\tfrac{m!(2-n)_m}{(3)_m}\right\}_{m=1}^{k-\ell}\right)\frac{\left(\frac{2(z-n)}{n(n-1)}\right)^k}{k!},%
}
 (s)^{(n)}=\Gamma(s+1)/\Gamma(s-n+1) (s)_n=\Gamma(s+n)/\Gamma(s) B_{n,k} \{n\in\Bbb R:n>1\} |z-n|<n-1 w(z)","['real-analysis', 'sequences-and-series', 'taylor-expansion', 'hypergeometric-function', 'lagrange-inversion']"
74,Showing that $\int_0^\infty x^{-x} \mathrm{d}x \leq 2$.,Showing that .,\int_0^\infty x^{-x} \mathrm{d}x \leq 2,"This integral is very closely related to the sophmores dream that states $$ \int_0^1 x^{-x}\mathrm{d}x = \sum_{n=1}^\infty n^{-n} = 1.27\ldots $$ For example here http://en.wikipedia.org/wiki/Sophomore%27s_dream Now I want to bound the integral, and showing that is less that 2.  For the interval $[0,1]$ a good bound is rewriting it to $\exp(x\log x)$ and using the expansion $$ 1 - x \log(x) + \frac12 (-x \log(x))^2$$ but how does one handle $[1,\infty)$ ? In this answer here How to evaluate $ \int_0^\infty {1 \over x^x}dx$ in terms of summation of series? gives bounds to the integral, but they are not tight enough.. So to taste my question again, how does one prove that $$ \int_0^\infty \frac{\mathrm{d}x}{x^x} \leq 2 $$","This integral is very closely related to the sophmores dream that states $$ \int_0^1 x^{-x}\mathrm{d}x = \sum_{n=1}^\infty n^{-n} = 1.27\ldots $$ For example here http://en.wikipedia.org/wiki/Sophomore%27s_dream Now I want to bound the integral, and showing that is less that 2.  For the interval $[0,1]$ a good bound is rewriting it to $\exp(x\log x)$ and using the expansion $$ 1 - x \log(x) + \frac12 (-x \log(x))^2$$ but how does one handle $[1,\infty)$ ? In this answer here How to evaluate $ \int_0^\infty {1 \over x^x}dx$ in terms of summation of series? gives bounds to the integral, but they are not tight enough.. So to taste my question again, how does one prove that $$ \int_0^\infty \frac{\mathrm{d}x}{x^x} \leq 2 $$",,"['real-analysis', 'approximation']"
75,When does l'Hospital's rule work for series?,When does l'Hospital's rule work for series?,,"This question stems from a response a colleague of mine received as a (flawed) solution to a problem on his calculus exam. The student was to determine convergence of a series of the form $\displaystyle\sum_{n=1}^\infty \frac{f(n)}{g(n)}$. The student instead considered the series  $\displaystyle\sum_{n=1}^\infty \frac{f'(n)}{g'(n)}$ and thought that this series and the original must behave the same way. This, of course, is false in general. What conditions on $f$ and $g$ are required so that the series  $\displaystyle\sum_{n=1}^\infty \frac{f(n)}{g(n)}$ converges iff  $\displaystyle\sum_{n=1}^\infty \frac{f'(n)}{g'(n)}$ converges?","This question stems from a response a colleague of mine received as a (flawed) solution to a problem on his calculus exam. The student was to determine convergence of a series of the form $\displaystyle\sum_{n=1}^\infty \frac{f(n)}{g(n)}$. The student instead considered the series  $\displaystyle\sum_{n=1}^\infty \frac{f'(n)}{g'(n)}$ and thought that this series and the original must behave the same way. This, of course, is false in general. What conditions on $f$ and $g$ are required so that the series  $\displaystyle\sum_{n=1}^\infty \frac{f(n)}{g(n)}$ converges iff  $\displaystyle\sum_{n=1}^\infty \frac{f'(n)}{g'(n)}$ converges?",,"['calculus', 'real-analysis', 'sequences-and-series', 'analysis']"
76,How is the fundamental theorem of calculus dependent on orientation?,How is the fundamental theorem of calculus dependent on orientation?,,"Using standard Lebesgue integration, we can write: \begin{equation} \int_{(a,b)}f'(x) d\lambda = f(b) - f(a) \end{equation} There's no orientation on the left hand side of the equation, yet on the right we take $f(b) - f(a)$ as opposed to $f(a) - f(b)$ . Due to what exactly is that the case? In what piece is the ""orientation"" $a \rightarrow b$ encoded? // My thoughts: I'd guess it's due to the fact that the derivative is in some sense defined in a slightly arbitrary way - both $\lim \frac{f(x+h)-f(x)}{h}$ and $\lim \frac{f(x)-f(x+h)}{h}$ make sense. But at the same time, it doesn't seem that arbitrary - it's natural to assume that numerator/enumerator order should be preserved, i.e. $\frac{f(x+h) - f(x)}{(x+h) - (x)}$ is the natural choice. So I think I might be missing something.","Using standard Lebesgue integration, we can write: There's no orientation on the left hand side of the equation, yet on the right we take as opposed to . Due to what exactly is that the case? In what piece is the ""orientation"" encoded? // My thoughts: I'd guess it's due to the fact that the derivative is in some sense defined in a slightly arbitrary way - both and make sense. But at the same time, it doesn't seem that arbitrary - it's natural to assume that numerator/enumerator order should be preserved, i.e. is the natural choice. So I think I might be missing something.","\begin{equation}
\int_{(a,b)}f'(x) d\lambda = f(b) - f(a)
\end{equation} f(b) - f(a) f(a) - f(b) a \rightarrow b \lim \frac{f(x+h)-f(x)}{h} \lim \frac{f(x)-f(x+h)}{h} \frac{f(x+h) - f(x)}{(x+h) - (x)}","['real-analysis', 'calculus', 'differential-forms']"
77,A continuous map that fixes the boundary of a domain pointwise is surjective,A continuous map that fixes the boundary of a domain pointwise is surjective,,"Let $\Omega$ be an open, bounded from $\mathbb{R}^n$ and $f: \overline{\Omega} \rightarrow \overline{\Omega}$ a contiuous function such that $f(x)=x, \forall x \in \partial \Omega$. Prove that $f(\overline{\Omega})=\overline{\Omega}$. how to solve it ? any idea please ?","Let $\Omega$ be an open, bounded from $\mathbb{R}^n$ and $f: \overline{\Omega} \rightarrow \overline{\Omega}$ a contiuous function such that $f(x)=x, \forall x \in \partial \Omega$. Prove that $f(\overline{\Omega})=\overline{\Omega}$. how to solve it ? any idea please ?",,"['real-analysis', 'general-topology']"
78,Why do people interchange between $\int$ and $\sum$ so easily?,Why do people interchange between  and  so easily?,\int \sum,"One of the things I found curious in many texts is how in certain cases interchange the $\sum$ operator with $\int$. What are the ""terms"" for such a swap? I understand that integration in the early days was seen as an approximation of the area under the curve by using the very definition of multiplication and area to lend a hand with very small increments where the number of samples goes to infinity. Beyond the original question, is this also the reason why we keep the right hand $dx$ (or any other infinitesimal variable), just to remind us of the origin because it ""multiplies against the function"", hence giving area. Or is there more to it? Hints, answers, references to books... I'd appreciate anything you can give me.","One of the things I found curious in many texts is how in certain cases interchange the $\sum$ operator with $\int$. What are the ""terms"" for such a swap? I understand that integration in the early days was seen as an approximation of the area under the curve by using the very definition of multiplication and area to lend a hand with very small increments where the number of samples goes to infinity. Beyond the original question, is this also the reason why we keep the right hand $dx$ (or any other infinitesimal variable), just to remind us of the origin because it ""multiplies against the function"", hence giving area. Or is there more to it? Hints, answers, references to books... I'd appreciate anything you can give me.",,"['real-analysis', 'reference-request', 'integration']"
79,Is the graph of the Conway base 13 function connected?,Is the graph of the Conway base 13 function connected?,,"IVT Property: If $a<b$ and $y$ is between $f(a)$ and $f(b)$, then there exists $c\in(a,b)$ such that $f(c)=y$. Theorem. Let $f:\mathbb R \to \mathbb R$ be a function with the IVT Property. If the set of discontinuities of $f$ is first category in $\mathbb R$, then the graph of $f$ is connected. This is an old Theorem. I assume there must be a counterexample if we leave out the first category assumption, though I don't know of any (help!). There are functions which are discontinuous everywhere and still have connected graphs. F.B. Jones showed that the graph of a function satisfying $f(x)+f(y)=f(x+y)$ for all $x$ and $y$ can be connected, even if the function is discontinuous everywhere. So now I come to Conway's example . It has the IVT property in a rather extreme way: it takes every value on every interval. It is discontinuous everywhere. Is the graph connected?","IVT Property: If $a<b$ and $y$ is between $f(a)$ and $f(b)$, then there exists $c\in(a,b)$ such that $f(c)=y$. Theorem. Let $f:\mathbb R \to \mathbb R$ be a function with the IVT Property. If the set of discontinuities of $f$ is first category in $\mathbb R$, then the graph of $f$ is connected. This is an old Theorem. I assume there must be a counterexample if we leave out the first category assumption, though I don't know of any (help!). There are functions which are discontinuous everywhere and still have connected graphs. F.B. Jones showed that the graph of a function satisfying $f(x)+f(y)=f(x+y)$ for all $x$ and $y$ can be connected, even if the function is discontinuous everywhere. So now I come to Conway's example . It has the IVT property in a rather extreme way: it takes every value on every interval. It is discontinuous everywhere. Is the graph connected?",,"['real-analysis', 'general-topology']"
80,Continuity of a function in two variables,Continuity of a function in two variables,,"Function $f(x,y)$ is continuous in each variable separately. Prove that there exists a point where it is continuous in two variables. I do not quite understand how to act here. I know the definition of continuity. But how to use them, I do not know. This is my homework on mathematical analysis.","Function $f(x,y)$ is continuous in each variable separately. Prove that there exists a point where it is continuous in two variables. I do not quite understand how to act here. I know the definition of continuity. But how to use them, I do not know. This is my homework on mathematical analysis.",,"['real-analysis', 'multivariable-calculus', 'continuity']"
81,Simple question: the double supremum,Simple question: the double supremum,,"Let $f:A\times B\to \mathbb R$. Is it always true that $$ f^* = \sup\limits_{a\in A,b\in B}f(a,b) = \sup\limits_{a\in A}\sup\limits_{b\in B}f(a,b). $$ I proved it by the $\varepsilon$-$\delta$ arguments, but I still do not sure if I've done it formal enough. Proof: Let $g(a) = \sup\limits_{b\in B}f(a,b)$ hence $g(a)\geq f(a,b)$ for all $b\in B$ and for any $\varepsilon>0$ exists $b'_{a,\varepsilon}\in B$ such that $f(a,b'_{a,\varepsilon})\geq g(a)-\varepsilon/2$. We put $g^* = \sup\limits_{a\in A}g(a)$, then $g^*\geq g(a)\geq f(a,b)$ for all $a\in A,b\in A$ and for any $\varepsilon>0$ there exists $a'_\varepsilon\in A$ such that $g(a'_\varepsilon)\geq g^*-\varepsilon/2$. Now, for an arbitrary $\varepsilon>0$ we can take $a'_\varepsilon\in A$ and $b'_{a',\varepsilon}\in B$ such that $f(a'_\varepsilon,b'_{a',\varepsilon})\geq g(a'_\varepsilon)-\varepsilon/2\geq g^*-\varepsilon$, so $g^* = f^*$. For the case $f^* = \infty$ I have almost the same proof (just inequalities are different). Should I also put it here?","Let $f:A\times B\to \mathbb R$. Is it always true that $$ f^* = \sup\limits_{a\in A,b\in B}f(a,b) = \sup\limits_{a\in A}\sup\limits_{b\in B}f(a,b). $$ I proved it by the $\varepsilon$-$\delta$ arguments, but I still do not sure if I've done it formal enough. Proof: Let $g(a) = \sup\limits_{b\in B}f(a,b)$ hence $g(a)\geq f(a,b)$ for all $b\in B$ and for any $\varepsilon>0$ exists $b'_{a,\varepsilon}\in B$ such that $f(a,b'_{a,\varepsilon})\geq g(a)-\varepsilon/2$. We put $g^* = \sup\limits_{a\in A}g(a)$, then $g^*\geq g(a)\geq f(a,b)$ for all $a\in A,b\in A$ and for any $\varepsilon>0$ there exists $a'_\varepsilon\in A$ such that $g(a'_\varepsilon)\geq g^*-\varepsilon/2$. Now, for an arbitrary $\varepsilon>0$ we can take $a'_\varepsilon\in A$ and $b'_{a',\varepsilon}\in B$ such that $f(a'_\varepsilon,b'_{a',\varepsilon})\geq g(a'_\varepsilon)-\varepsilon/2\geq g^*-\varepsilon$, so $g^* = f^*$. For the case $f^* = \infty$ I have almost the same proof (just inequalities are different). Should I also put it here?",,"['real-analysis', 'optimization']"
82,Finding $\int^{1}_{0}\frac{\ln^2(x)}{\sqrt{4-x^2}}dx$,Finding,\int^{1}_{0}\frac{\ln^2(x)}{\sqrt{4-x^2}}dx,"Finding $$\int^{1}_{0}\frac{\ln^2(x)}{\sqrt{4-x^2}}dx$$ Try: Let $$I=\frac{1}{2}\int^{1}_{0}\frac{\ln^2(x)}{\sqrt{1-\frac{x^2}{4}}}=\frac{1}{2}\int^{1}_{0}\sum^{\infty}_{n=0}\binom{-1/2}{n}\bigg(-\frac{1}{4}\bigg)^nx^{2n}\ln^2(x)dx$$ $$I=\frac{1}{2}\sum^{\infty}_{n=0}\binom{-1/2}{n}\bigg(-\frac{1}{4}\bigg)^n\int^{1}_{0}x^{2n}\ln^2(x)dx$$ Using By parts , We have $$I=\frac{1}{2}\sum^{\infty}_{n=0}\binom{-1/2}{n}\bigg(-\frac{1}{4}\bigg)^n\frac{2}{(2n+1)^3}$$ But answer given as $\displaystyle\frac{7\pi^3}{216}$ I am not understand How can i get it. could some help me , Thanks","Finding $$\int^{1}_{0}\frac{\ln^2(x)}{\sqrt{4-x^2}}dx$$ Try: Let $$I=\frac{1}{2}\int^{1}_{0}\frac{\ln^2(x)}{\sqrt{1-\frac{x^2}{4}}}=\frac{1}{2}\int^{1}_{0}\sum^{\infty}_{n=0}\binom{-1/2}{n}\bigg(-\frac{1}{4}\bigg)^nx^{2n}\ln^2(x)dx$$ $$I=\frac{1}{2}\sum^{\infty}_{n=0}\binom{-1/2}{n}\bigg(-\frac{1}{4}\bigg)^n\int^{1}_{0}x^{2n}\ln^2(x)dx$$ Using By parts , We have $$I=\frac{1}{2}\sum^{\infty}_{n=0}\binom{-1/2}{n}\bigg(-\frac{1}{4}\bigg)^n\frac{2}{(2n+1)^3}$$ But answer given as $\displaystyle\frac{7\pi^3}{216}$ I am not understand How can i get it. could some help me , Thanks",,"['real-analysis', 'integration', 'sequences-and-series', 'closed-form']"
83,Matrices equipped with the rank distance form a metric space,Matrices equipped with the rank distance form a metric space,,"Right now, I'm taking a basic introductory analysis course.   I came across this on wikipedia and I'm Really struggling to prove it is a metric space. (Need help with the 3rd axiom of metric space the most and making the 2nd one more rigorous/less handwaving) The set of all $m$ by $b$ matrices over some field is a metric space with respect to the rank distance $d(X,Y)=\operatorname{rank}(Y-X) $ Facts that I know: So I know that in order to prove something is a metric space $d(X,Y)=0$ iff $X=Y$   (have to prove both ways) $d(X,Y)=d(Y,X)$  (Symmetry) $d(X,Y)\leqslant d(X,Z) +d(Z,Y)$ (Triangle inequality). Also, it has been a long time since I have taken linear algebra"", but I now that to find the rank, you reduce a matrix to its row echelon form and the number of nonzero rows is the rank (or I think number of linearly independent rows, again it has been awhile). My attempt: If $Y=X$, We have $\operatorname{rank}(Y-X)=\operatorname{rank}(Y-Y)=\operatorname{rank}(O)$ (where $O$ is the null matrix) which is clearly equal to $0$.  Thus $d(X,Y)=0$.  Proving other direction if $d(X,Y)=0$, we have $\operatorname{rank}(Y-X)=0$.  In this case $Y$ must necessarily equal $X$.  If $Y$ does not equal $X$, rank must be at least $1$. Why must $d(X,Y)=d(Y,X)$?  The matrix $X-Y$ and $Y-X$ only differ by signs.  That doesn't change rank.  Hence $\operatorname{rank}(Y-X)=\operatorname{rank}(X-Y)$.  (feel like I hand waved this explanation a bit). Why must $d(X,Y)\leqslant d(X,Z)+ d(Z,Y)$? Need to show: $$\operatorname{rank}(Y-X)\leqslant\operatorname{rank}(Z-X)+ \operatorname{rank}(Y-Z)$$where $X,Y,Z$ are $m \times n$ matrices. This one I'm not sure at all how to approach this.  Why must $\operatorname{rank}(Y-X)\leqslant \operatorname{rank}(Z-X)+\operatorname{rank}(Y-Z)$?  I'm not sure why this must be the case and how to formally show this.","Right now, I'm taking a basic introductory analysis course.   I came across this on wikipedia and I'm Really struggling to prove it is a metric space. (Need help with the 3rd axiom of metric space the most and making the 2nd one more rigorous/less handwaving) The set of all $m$ by $b$ matrices over some field is a metric space with respect to the rank distance $d(X,Y)=\operatorname{rank}(Y-X) $ Facts that I know: So I know that in order to prove something is a metric space $d(X,Y)=0$ iff $X=Y$   (have to prove both ways) $d(X,Y)=d(Y,X)$  (Symmetry) $d(X,Y)\leqslant d(X,Z) +d(Z,Y)$ (Triangle inequality). Also, it has been a long time since I have taken linear algebra"", but I now that to find the rank, you reduce a matrix to its row echelon form and the number of nonzero rows is the rank (or I think number of linearly independent rows, again it has been awhile). My attempt: If $Y=X$, We have $\operatorname{rank}(Y-X)=\operatorname{rank}(Y-Y)=\operatorname{rank}(O)$ (where $O$ is the null matrix) which is clearly equal to $0$.  Thus $d(X,Y)=0$.  Proving other direction if $d(X,Y)=0$, we have $\operatorname{rank}(Y-X)=0$.  In this case $Y$ must necessarily equal $X$.  If $Y$ does not equal $X$, rank must be at least $1$. Why must $d(X,Y)=d(Y,X)$?  The matrix $X-Y$ and $Y-X$ only differ by signs.  That doesn't change rank.  Hence $\operatorname{rank}(Y-X)=\operatorname{rank}(X-Y)$.  (feel like I hand waved this explanation a bit). Why must $d(X,Y)\leqslant d(X,Z)+ d(Z,Y)$? Need to show: $$\operatorname{rank}(Y-X)\leqslant\operatorname{rank}(Z-X)+ \operatorname{rank}(Y-Z)$$where $X,Y,Z$ are $m \times n$ matrices. This one I'm not sure at all how to approach this.  Why must $\operatorname{rank}(Y-X)\leqslant \operatorname{rank}(Z-X)+\operatorname{rank}(Y-Z)$?  I'm not sure why this must be the case and how to formally show this.",,"['real-analysis', 'linear-algebra', 'general-topology', 'metric-spaces']"
84,Real Analysis question that affects how to think about the Dirac delta function.,Real Analysis question that affects how to think about the Dirac delta function.,,"Okay, here are the ingredients to this question. Me: 60 years old.  39 years ago I took two semesters of Real Analysis using the Royden textbook.  Rusty is an understatement.  But I am still quite anal and OCD.  I am also an electrical engineer, works in signal processing.  DSP and Linear System Theory are important to me.  I have also had two semesters (as a grad student) of Functional Analysis (using the Kreyszig text) and multiple courses in probability, random variables, and random processes (a.k.a. ""stochastic processes""). Electrical Engineers (and I suspect many physicists) essentially treat $\delta(x)$ as a ""function"".  But it isn't.  One thing I remember from R.A. is that if $$ f(x) = g(x) $$ almost everywhere in $E$, then $$ \int_E f(x) \, dx \ = \ \int_E g(x) \, dx $$ problem is, of course, that electrical engineers (and their professors) like to think of $$\begin{align} f(x) & = \delta(x) \\ g(x) & = 0 \end{align} $$ and that $$ \int\limits_{-1}^{+1} f(x) \, dx = 1 \quad \ne \quad \int\limits_{-1}^{+1} g(x) \, dx = 0 $$ yet $f(x) = g(x)$ everywhere except at one single value of $x$ . Now I have heard (or read) that the ""Dirac delta function is not really a function but is a ' distribution ' or a ' functional '.""  And I understand the meaning of the terms ""distribution"" in the context of random variables and ""functional"" in the context of metric spaces, normed spaces, etc.  Is that the given usage of these two terms regarding $\delta(x)$? Question 1:  Is the usage of the notation $$ \int\limits_{-\infty}^{+\infty} f(x) \, \delta(x) \, dx $$ a misnomer?  There is no integration going on.  It's just a linear functional that maps the function $f(x)$ to the number $f(0)$.  Now EEs and maybe physicists will comfortably look at that as an integral that is the same as $$ \int\limits_{-\infty}^{+\infty} f(0) \, \delta(x) \, dx = f(0)\int\limits_{-\infty}^{+\infty} \delta(x) \, dx = f(0) $$ But since $\delta(x)$ is not a function at all, what do mathematicians mean with that notation? Question 2:  How fatal is it for electrical engineers and physicists to consistently treat the Dirac delta function simply as a limit of ""nascent deltas"" such as $$ \delta(x) \ \triangleq \ \lim_{\sigma \to 0^+} \frac{1}{ \sigma} \operatorname{rect} \left( \frac{x}{\sigma} \right) $$ where $ \operatorname{rect}(x) \triangleq  \begin{cases}  1 \quad |x|<\frac{1}{2} \\ \frac{1}{2} \quad |x|=\frac{1}{2} \\ 0 \quad |x|>\frac{1}{2} \\ \end{cases} $ or $$ \delta(x) \ \triangleq \ \lim_{\sigma \to 0^+} \frac{1}{\sigma} \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x}{\sigma}\right)^2} $$ What is gonna kill us to simple-mindedly treat the Dirac delta as such a function ?  A function that is zero almost everywhere, yet it integrates to be equal to 1 (where the function that is zero everywhere integrates to be 0). If we do that, within our own disciplines, what mathematical problem might crop up that kills us? This is not exactly the same but smells a lot like this concern from Richard Hamming : “Does anyone believe that the difference between the Lebesgue and Riemann integrals can have physical significance, and that whether say, an airplane would or would not fly could depend on this difference? If such were claimed, I should not care to fly in that plane.” I might ask the same question regarding the mathematician's and the engineer's understanding of the Dirac delta function.  How might a mathematician answer that question?","Okay, here are the ingredients to this question. Me: 60 years old.  39 years ago I took two semesters of Real Analysis using the Royden textbook.  Rusty is an understatement.  But I am still quite anal and OCD.  I am also an electrical engineer, works in signal processing.  DSP and Linear System Theory are important to me.  I have also had two semesters (as a grad student) of Functional Analysis (using the Kreyszig text) and multiple courses in probability, random variables, and random processes (a.k.a. ""stochastic processes""). Electrical Engineers (and I suspect many physicists) essentially treat $\delta(x)$ as a ""function"".  But it isn't.  One thing I remember from R.A. is that if $$ f(x) = g(x) $$ almost everywhere in $E$, then $$ \int_E f(x) \, dx \ = \ \int_E g(x) \, dx $$ problem is, of course, that electrical engineers (and their professors) like to think of $$\begin{align} f(x) & = \delta(x) \\ g(x) & = 0 \end{align} $$ and that $$ \int\limits_{-1}^{+1} f(x) \, dx = 1 \quad \ne \quad \int\limits_{-1}^{+1} g(x) \, dx = 0 $$ yet $f(x) = g(x)$ everywhere except at one single value of $x$ . Now I have heard (or read) that the ""Dirac delta function is not really a function but is a ' distribution ' or a ' functional '.""  And I understand the meaning of the terms ""distribution"" in the context of random variables and ""functional"" in the context of metric spaces, normed spaces, etc.  Is that the given usage of these two terms regarding $\delta(x)$? Question 1:  Is the usage of the notation $$ \int\limits_{-\infty}^{+\infty} f(x) \, \delta(x) \, dx $$ a misnomer?  There is no integration going on.  It's just a linear functional that maps the function $f(x)$ to the number $f(0)$.  Now EEs and maybe physicists will comfortably look at that as an integral that is the same as $$ \int\limits_{-\infty}^{+\infty} f(0) \, \delta(x) \, dx = f(0)\int\limits_{-\infty}^{+\infty} \delta(x) \, dx = f(0) $$ But since $\delta(x)$ is not a function at all, what do mathematicians mean with that notation? Question 2:  How fatal is it for electrical engineers and physicists to consistently treat the Dirac delta function simply as a limit of ""nascent deltas"" such as $$ \delta(x) \ \triangleq \ \lim_{\sigma \to 0^+} \frac{1}{ \sigma} \operatorname{rect} \left( \frac{x}{\sigma} \right) $$ where $ \operatorname{rect}(x) \triangleq  \begin{cases}  1 \quad |x|<\frac{1}{2} \\ \frac{1}{2} \quad |x|=\frac{1}{2} \\ 0 \quad |x|>\frac{1}{2} \\ \end{cases} $ or $$ \delta(x) \ \triangleq \ \lim_{\sigma \to 0^+} \frac{1}{\sigma} \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x}{\sigma}\right)^2} $$ What is gonna kill us to simple-mindedly treat the Dirac delta as such a function ?  A function that is zero almost everywhere, yet it integrates to be equal to 1 (where the function that is zero everywhere integrates to be 0). If we do that, within our own disciplines, what mathematical problem might crop up that kills us? This is not exactly the same but smells a lot like this concern from Richard Hamming : “Does anyone believe that the difference between the Lebesgue and Riemann integrals can have physical significance, and that whether say, an airplane would or would not fly could depend on this difference? If such were claimed, I should not care to fly in that plane.” I might ask the same question regarding the mathematician's and the engineer's understanding of the Dirac delta function.  How might a mathematician answer that question?",,"['real-analysis', 'integration', 'dirac-delta']"
85,Is there a garden of derivatives?,Is there a garden of derivatives?,,"I've found a book called A Garden of Integrals , in which the author shows the evolution of the concept of Integral. I follow AnalysisFact on Twitter, some days ago, they posted the following: The got curious about the generalizations of the derivatives. I'm wondering if there's something analog to the book I mentioned: Some kind of garden of derivatives.","I've found a book called A Garden of Integrals , in which the author shows the evolution of the concept of Integral. I follow AnalysisFact on Twitter, some days ago, they posted the following: The got curious about the generalizations of the derivatives. I'm wondering if there's something analog to the book I mentioned: Some kind of garden of derivatives.",,"['real-analysis', 'reference-request']"
86,Differentiable functions satisfying $f'(f(x))=f(f'(x))$,Differentiable functions satisfying,f'(f(x))=f(f'(x)),"I am wondering whether or not there is a reasonable characterization of differentiable functions $f: \mathbb{R}\to \mathbb{R}$ such that $f'(f(x))=f(f'(x))$ for each $x\in\mathbb{R}$. (Or, if you like the composition sign, $f'\circ f=f\circ f'$). I could only come up with trivial examples of such functions: $f(x)=0$ and $f(x)=e^{x}$. This reminds me of a recent Putnam problem (2010), which asked whether or not there exists a strictly increasing function $f:\mathbb{R}\to\mathbb{R}$ satisfying $f'(x)=f(f(x))$. (The answer is: No). Note: I see that a question of similar type has been asked here .","I am wondering whether or not there is a reasonable characterization of differentiable functions $f: \mathbb{R}\to \mathbb{R}$ such that $f'(f(x))=f(f'(x))$ for each $x\in\mathbb{R}$. (Or, if you like the composition sign, $f'\circ f=f\circ f'$). I could only come up with trivial examples of such functions: $f(x)=0$ and $f(x)=e^{x}$. This reminds me of a recent Putnam problem (2010), which asked whether or not there exists a strictly increasing function $f:\mathbb{R}\to\mathbb{R}$ satisfying $f'(x)=f(f(x))$. (The answer is: No). Note: I see that a question of similar type has been asked here .",,"['real-analysis', 'functional-equations', 'problem-solving']"
87,Relation between uniform continuity and uniform convergence,Relation between uniform continuity and uniform convergence,,"Is there a relationship between uniform continuity and uniform convergence? For example, suppose $\{f_{n}\}$ is a sequence of functions each of which is uniformly continuous on $[a, b]$. Then does it follow that $f_{n}$ converges to $f$ uniformly on $[a, b]$? (Maybe with some additional conditions?)","Is there a relationship between uniform continuity and uniform convergence? For example, suppose $\{f_{n}\}$ is a sequence of functions each of which is uniformly continuous on $[a, b]$. Then does it follow that $f_{n}$ converges to $f$ uniformly on $[a, b]$? (Maybe with some additional conditions?)",,"['real-analysis', 'uniform-convergence', 'uniform-continuity']"
88,$\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}=\pi$ similar identities,similar identities,\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}=\pi,"I recently found that $$\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}=\pi$$ iff $$b^2-4ac=-4.$$ I found it by integrating $$I=\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}.$$ If the reciprocal of the function is to be integrated over the entire real line, then the function must not have any real zeros. This implies that $$b^2-4ac<0$$ With this in mind, we complete the square: $$I=\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{a(x+\frac{b}{2a})^2+c-\frac{b^2}{4a}}.$$ Then setting $g=c-\frac{b^2}{4a}$ , and $x+\frac{b}{2a}=\sqrt{\frac{g}{a}}\tan u$ , $$I=\sqrt{\frac{g}{a}}\int_{-\pi/2}^{\pi/2}\frac{\sec^2u\ \mathrm{d}u}{g\tan^2u+g}=\frac{\pi}{\sqrt{ag}}.$$ So our identity holds for $$ag=1.$$ And with a little algebra, $$b^2-4ac=-4.$$ So my question is, are there any other similar identities involving other famous constants? Cheers!","I recently found that iff I found it by integrating If the reciprocal of the function is to be integrated over the entire real line, then the function must not have any real zeros. This implies that With this in mind, we complete the square: Then setting , and , So our identity holds for And with a little algebra, So my question is, are there any other similar identities involving other famous constants? Cheers!",\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}=\pi b^2-4ac=-4. I=\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{ax^2+bx+c}. b^2-4ac<0 I=\int_{-\infty}^{\infty}\frac{\mathrm{d}x}{a(x+\frac{b}{2a})^2+c-\frac{b^2}{4a}}. g=c-\frac{b^2}{4a} x+\frac{b}{2a}=\sqrt{\frac{g}{a}}\tan u I=\sqrt{\frac{g}{a}}\int_{-\pi/2}^{\pi/2}\frac{\sec^2u\ \mathrm{d}u}{g\tan^2u+g}=\frac{\pi}{\sqrt{ag}}. ag=1. b^2-4ac=-4.,"['real-analysis', 'integration', 'improper-integrals', 'big-list']"
89,$C^\omega$ notation for real analytic functions,notation for real analytic functions,C^\omega,I've seen the notation $C^\omega$ used for the set of real analytic functions (e.g. on an interval). Where does it come from? What exactly does it mean? What is the reason behind it? Who first used it? Thanks!,I've seen the notation $C^\omega$ used for the set of real analytic functions (e.g. on an interval). Where does it come from? What exactly does it mean? What is the reason behind it? Who first used it? Thanks!,,"['real-analysis', 'notation']"
90,Homeomorphism between open unit ball and $\mathbb R^n$,Homeomorphism between open unit ball and,\mathbb R^n,"Let $B=\{x\in\mathbb R^n : ||x||<1\}$ the open unit ball with the subapce topology of $\mathbb R^n$. I want to show that $B^n\cong\mathbb R^n$ with the map $F(x)=\tan(\frac{\pi ||x||}{2})\frac{x}{||x||}$ for $x\not=0$ and $F(0)=0$ Well $\frac{x}{||x||}$ is more or less the direction of the vector $x$, the norm is a number out of $[0,1)$ and the scaled tangent is a Homeomorphism from $[0,1)$ to the positive real numbers. I want to show that $F(x)$ is contionous, bijective and there is an inverse map. Injectivity : Let $F(x)=F(y)\leftrightarrow ||F(x)||=||F(y)||\leftrightarrow \tan(\frac{\pi ||x||}{2})||\frac{x}{||x||}||=\tan(\frac{\pi ||y||}{2})||\frac{y}{||y||}||$ I know that the tangent is injective but I do not see how $x=y$ can be followed. Surjectivity : Let $y\in\mathbb R^n$, now I need to show $\exists x\in B^n: F(x)=y$, i.e $\tan(\frac{\pi ||x||}{2})\frac{x}{||x||}=y$ I do not see how surjectivity can be followed form this. Inverse map : I know that the tangent has an inverse map, namely the arctangent, but how can this be used here? Continuity : Well I know that the tangent is only contin. on $\mathbb R\setminus\{(n+\frac{1}{2})\pi: n\in \mathbb Z\}$","Let $B=\{x\in\mathbb R^n : ||x||<1\}$ the open unit ball with the subapce topology of $\mathbb R^n$. I want to show that $B^n\cong\mathbb R^n$ with the map $F(x)=\tan(\frac{\pi ||x||}{2})\frac{x}{||x||}$ for $x\not=0$ and $F(0)=0$ Well $\frac{x}{||x||}$ is more or less the direction of the vector $x$, the norm is a number out of $[0,1)$ and the scaled tangent is a Homeomorphism from $[0,1)$ to the positive real numbers. I want to show that $F(x)$ is contionous, bijective and there is an inverse map. Injectivity : Let $F(x)=F(y)\leftrightarrow ||F(x)||=||F(y)||\leftrightarrow \tan(\frac{\pi ||x||}{2})||\frac{x}{||x||}||=\tan(\frac{\pi ||y||}{2})||\frac{y}{||y||}||$ I know that the tangent is injective but I do not see how $x=y$ can be followed. Surjectivity : Let $y\in\mathbb R^n$, now I need to show $\exists x\in B^n: F(x)=y$, i.e $\tan(\frac{\pi ||x||}{2})\frac{x}{||x||}=y$ I do not see how surjectivity can be followed form this. Inverse map : I know that the tangent has an inverse map, namely the arctangent, but how can this be used here? Continuity : Well I know that the tangent is only contin. on $\mathbb R\setminus\{(n+\frac{1}{2})\pi: n\in \mathbb Z\}$",,"['real-analysis', 'general-topology', 'continuity']"
91,Choose signs such that $\pm\sqrt{1}\pm\sqrt{2}\pm\dots\pm\sqrt{2022}$ is as close as possible to $0$.,Choose signs such that  is as close as possible to .,\pm\sqrt{1}\pm\sqrt{2}\pm\dots\pm\sqrt{2022} 0,"Choose signs such that $\pm\sqrt{1}\pm\sqrt{2}\pm\dots\pm\sqrt{2022}$ is as close as possible to $0$ . I tried looking at examples for small $n$ (up to $8$ ) for inspiration: $$\begin{align} &1: -\sqrt{1} = -1 &(0, 0) \\ &2: +\sqrt{1}-\sqrt{2} = -0.414214 &(10, 2) \\ &3: +\sqrt{1}+\sqrt{2}-\sqrt{3} = 0.682163 &(110, 6) \\ &4: -\sqrt{1}+\sqrt{2}+\sqrt{3}-\sqrt{4} = 0.146264 &(0110, 6) \\ &5: +\sqrt{1}+\sqrt{2}+\sqrt{3}-\sqrt{4}-\sqrt{5} = -0.0898034 &(11100, 28) \\ &6: -\sqrt{1}+\sqrt{2}+\sqrt{3}-\sqrt{4}+\sqrt{5}-\sqrt{6} = -0.0671574 &(011010, 26) \\ &7: -\sqrt{1}-\sqrt{2}-\sqrt{3}+\sqrt{4}+\sqrt{5}+\sqrt{6}-\sqrt{7} = -0.106458 &(0001110, 14) \\ &8: -\sqrt{1}+\sqrt{2}-\sqrt{3}+\sqrt{4}+\sqrt{5}+\sqrt{6}-\sqrt{7}-\sqrt{8} = -0.106458 &(01011100, 92) \end{align}$$ The right side $(x, y)$ is interpreted as $$ \begin{align} x &= \text{binary for + and - where + is 1 and - is 0} \\ y &= x \text{ to base 10} \\ \end{align} $$ Doing this, I had hoped for a pattern that emerges from say powers of two but nothing seems useful here. By flipping each sign of a correct solution, we can trivially get another solution for each $n$ . If it was integers, we could use the parity argument but I don't see a way forward for square roots. This question was given in an interview for a trading firm. The interviewer wanted to hear how I would approach and analyze this problem under time-constrained circumstances. I asked this question in math.stackexchange because the structure of this question reminds me of typical Olympiad question where there's a ""trick"" to solving it.","Choose signs such that is as close as possible to . I tried looking at examples for small (up to ) for inspiration: The right side is interpreted as Doing this, I had hoped for a pattern that emerges from say powers of two but nothing seems useful here. By flipping each sign of a correct solution, we can trivially get another solution for each . If it was integers, we could use the parity argument but I don't see a way forward for square roots. This question was given in an interview for a trading firm. The interviewer wanted to hear how I would approach and analyze this problem under time-constrained circumstances. I asked this question in math.stackexchange because the structure of this question reminds me of typical Olympiad question where there's a ""trick"" to solving it.","\pm\sqrt{1}\pm\sqrt{2}\pm\dots\pm\sqrt{2022} 0 n 8 \begin{align}
&1: -\sqrt{1} = -1 &(0, 0) \\
&2: +\sqrt{1}-\sqrt{2} = -0.414214 &(10, 2) \\
&3: +\sqrt{1}+\sqrt{2}-\sqrt{3} = 0.682163 &(110, 6) \\
&4: -\sqrt{1}+\sqrt{2}+\sqrt{3}-\sqrt{4} = 0.146264 &(0110, 6) \\
&5: +\sqrt{1}+\sqrt{2}+\sqrt{3}-\sqrt{4}-\sqrt{5} = -0.0898034 &(11100, 28) \\
&6: -\sqrt{1}+\sqrt{2}+\sqrt{3}-\sqrt{4}+\sqrt{5}-\sqrt{6} = -0.0671574 &(011010, 26) \\
&7: -\sqrt{1}-\sqrt{2}-\sqrt{3}+\sqrt{4}+\sqrt{5}+\sqrt{6}-\sqrt{7} = -0.106458 &(0001110, 14) \\
&8: -\sqrt{1}+\sqrt{2}-\sqrt{3}+\sqrt{4}+\sqrt{5}+\sqrt{6}-\sqrt{7}-\sqrt{8} = -0.106458 &(01011100, 92)
\end{align} (x, y) 
\begin{align}
x &= \text{binary for + and - where + is 1 and - is 0} \\
y &= x \text{ to base 10} \\
\end{align}
 n","['real-analysis', 'combinatorics', 'numerical-methods', 'discrete-optimization']"
92,"Show that if the integral of function with compact support on straight line is zero, then $f$ is zero almost everywhere","Show that if the integral of function with compact support on straight line is zero, then  is zero almost everywhere",f,"I want to prove that that given $f:R^2 \rightarrow R$ which is continuous with compact support s.t the integral of $f$ for every straight line $l$ is zero ( $\int f(l(t))\mathrm{d}t=0$ ) then $f$ is almost everywhere $0.$ Well I know how to proof it in case that $l = 1_{B(x,r)}$ is measurable and bounded with compact support (from other thread) , but that's not the case here. Any idea? thanks!","I want to prove that that given which is continuous with compact support s.t the integral of for every straight line is zero ( ) then is almost everywhere Well I know how to proof it in case that is measurable and bounded with compact support (from other thread) , but that's not the case here. Any idea? thanks!","f:R^2 \rightarrow R f l \int f(l(t))\mathrm{d}t=0 f 0. l = 1_{B(x,r)}","['real-analysis', 'integration', 'lebesgue-integral', 'lebesgue-measure', 'lp-spaces']"
93,Minkowski inequality $-$ Why should it follow from Holder's?,Minkowski inequality  Why should it follow from Holder's?,-,"$$ ||f+g||_p \le ||f||_p + ||g||_p \quad\text{for $1\le p \le \infty$}$$ I have used Minkowski inequality for a long time without really knowing why it should be true. I kind of take it for grant every time I am dealing with $l^p$ or $L^p$ spaces. Years have passed by and now I am taking a better look at it again. It's not like I don't understand its proofs or anything, the standard proof goes like this: Consider the case $1<p<\infty$, it is not hard to see that    $$\left|\frac 12f+\frac 12 g\right|^p\le \left|\frac 12|f|+\frac 12|g|\right|^p$$   for any $f,g\in L^p$. Since $x \mapsto x^p$ is convex, we have   $$ \left(\frac 12|f|+\frac 12|g|\right)^p \le \frac 12|f|^p+\frac 12|g|^p. $$   Substituting $f,g$ in places of $\frac 12f,\frac12 g$ yields   $$ \left|f+g\right|^p \le 2^{p-1}\left(|f|^p+|g|^p \right) $$   so $f+g\in L^p$. Observe that for $q$ satisfying $\frac 1q + \frac 1p=1$,   $$\begin{align} |f+g|^p &\le |f+g|^{p-1}(|f|+|g|) \\  \int|f+g|^p  &\le \int|f||f+g|^{p-1} + \int|g||f+g|^{p-1} \\ &= ||f\cdot (f+g)^p ||_1 + ||g\cdot (f+g)^p ||_1 \\ ||f+g||^p_p&\le ||f||_p ||(f+g)^{p-1}||_q + ||g||_p ||(f+g)^{p-1}||_q \end{align}$$   by Holder inequality. Now, since $(p-1)q=p$ we have   $$\begin{align} ||(f+g)^{p-1}||_q &= \left(\int |f+g|^{(p-1)q}\right)^{\frac 1q} \\ & =\left(\int |f+g|^p\right)^{\frac 1q} \\ &= ||f+g||_p^{p/q}. \end{align}$$   By cancellation on both side of $$||f+g||^p_p\le ||f||_p ||(f+g)^{p-1}||_q + ||g||_p ||(f+g)^{p-1}||_q$$ and noting that $p-p/q=1$, we have   $$ ||f+g||_p \le ||f||_p + ||g||_p $$   as required. Yes, each step is clear and not hard to understand. However, it seems magical to me at several steps and I cannot intuitively follow the logical flow of the proof. The proof of Holder inequality via Jensen inequality seems quite natural to me, unlike this one. I'll try to be more specific: My questions Why should I expect that the splitting $|f+g|^p$ into $|f+g|^{p-1}(|f|+|g|)$ should be fruitful? We utilized the fact that $(p-1)q=p$ and $p-p/q=1$. While it is not hard to verify them algebraically, is there an intuitive reason to anticipate them beforehand? What is the intuitive/geometric relation between the conjugate pair $p,q$ beside from their algebraic relation $\frac 1q+\frac 1p =1$? I know that $(l^p)^*=l^q$ but I am not sure how it might help. In general, I just want a better grasp at Minkowski inequality. Any contribution would be really appreciated even if it does not address all of my question.","$$ ||f+g||_p \le ||f||_p + ||g||_p \quad\text{for $1\le p \le \infty$}$$ I have used Minkowski inequality for a long time without really knowing why it should be true. I kind of take it for grant every time I am dealing with $l^p$ or $L^p$ spaces. Years have passed by and now I am taking a better look at it again. It's not like I don't understand its proofs or anything, the standard proof goes like this: Consider the case $1<p<\infty$, it is not hard to see that    $$\left|\frac 12f+\frac 12 g\right|^p\le \left|\frac 12|f|+\frac 12|g|\right|^p$$   for any $f,g\in L^p$. Since $x \mapsto x^p$ is convex, we have   $$ \left(\frac 12|f|+\frac 12|g|\right)^p \le \frac 12|f|^p+\frac 12|g|^p. $$   Substituting $f,g$ in places of $\frac 12f,\frac12 g$ yields   $$ \left|f+g\right|^p \le 2^{p-1}\left(|f|^p+|g|^p \right) $$   so $f+g\in L^p$. Observe that for $q$ satisfying $\frac 1q + \frac 1p=1$,   $$\begin{align} |f+g|^p &\le |f+g|^{p-1}(|f|+|g|) \\  \int|f+g|^p  &\le \int|f||f+g|^{p-1} + \int|g||f+g|^{p-1} \\ &= ||f\cdot (f+g)^p ||_1 + ||g\cdot (f+g)^p ||_1 \\ ||f+g||^p_p&\le ||f||_p ||(f+g)^{p-1}||_q + ||g||_p ||(f+g)^{p-1}||_q \end{align}$$   by Holder inequality. Now, since $(p-1)q=p$ we have   $$\begin{align} ||(f+g)^{p-1}||_q &= \left(\int |f+g|^{(p-1)q}\right)^{\frac 1q} \\ & =\left(\int |f+g|^p\right)^{\frac 1q} \\ &= ||f+g||_p^{p/q}. \end{align}$$   By cancellation on both side of $$||f+g||^p_p\le ||f||_p ||(f+g)^{p-1}||_q + ||g||_p ||(f+g)^{p-1}||_q$$ and noting that $p-p/q=1$, we have   $$ ||f+g||_p \le ||f||_p + ||g||_p $$   as required. Yes, each step is clear and not hard to understand. However, it seems magical to me at several steps and I cannot intuitively follow the logical flow of the proof. The proof of Holder inequality via Jensen inequality seems quite natural to me, unlike this one. I'll try to be more specific: My questions Why should I expect that the splitting $|f+g|^p$ into $|f+g|^{p-1}(|f|+|g|)$ should be fruitful? We utilized the fact that $(p-1)q=p$ and $p-p/q=1$. While it is not hard to verify them algebraically, is there an intuitive reason to anticipate them beforehand? What is the intuitive/geometric relation between the conjugate pair $p,q$ beside from their algebraic relation $\frac 1q+\frac 1p =1$? I know that $(l^p)^*=l^q$ but I am not sure how it might help. In general, I just want a better grasp at Minkowski inequality. Any contribution would be really appreciated even if it does not address all of my question.",,"['real-analysis', 'functional-analysis', 'inequality', 'soft-question']"
94,Finding simply connected open sets between compact ones and general open ones in $\mathbb R^2$.,Finding simply connected open sets between compact ones and general open ones in .,\mathbb R^2,"In a paper  I am reading (not a published one), the following is considered obvious: Let $K$ be a compact and connected subset of $\,\mathbb R^2$, with $\mathbb R^2\smallsetminus K$ connected, and $U\subset \mathbb R^2$ open with $K\subset U$. Then there exists a simply connected and open  $V\subset \mathbb R^2$, with $K\subset V\subset U$. More generally, if $K$ is compact, $\mathbb R^2\smallsetminus K$ is connected and $U\subset \mathbb R^2$ open with $K\subset U$, then there exists an open  $V\subset \mathbb R^2$, with $K\subset V\subset U$, such that all the connected components of $V$ are simply connected. I have not managed to see why this is obvious. So far, I have shown this for simply connected compact sets $K$ with sufficiently smooth boundaries. Any ideas?","In a paper  I am reading (not a published one), the following is considered obvious: Let $K$ be a compact and connected subset of $\,\mathbb R^2$, with $\mathbb R^2\smallsetminus K$ connected, and $U\subset \mathbb R^2$ open with $K\subset U$. Then there exists a simply connected and open  $V\subset \mathbb R^2$, with $K\subset V\subset U$. More generally, if $K$ is compact, $\mathbb R^2\smallsetminus K$ is connected and $U\subset \mathbb R^2$ open with $K\subset U$, then there exists an open  $V\subset \mathbb R^2$, with $K\subset V\subset U$, such that all the connected components of $V$ are simply connected. I have not managed to see why this is obvious. So far, I have shown this for simply connected compact sets $K$ with sufficiently smooth boundaries. Any ideas?",,"['real-analysis', 'general-topology', 'algebraic-topology', 'connectedness']"
95,Discontinuous at rationals and differentiable at irrationals?,Discontinuous at rationals and differentiable at irrationals?,,We know that there exist real functions which are continuous at each irrational and dis- continuous at each rational number. But does there exist a function $f: \mathbb{R} \to \mathbb{R}$ that is differentiable at every irrational and discontinuous at every rational?,We know that there exist real functions which are continuous at each irrational and dis- continuous at each rational number. But does there exist a function $f: \mathbb{R} \to \mathbb{R}$ that is differentiable at every irrational and discontinuous at every rational?,,['real-analysis']
96,"On certain algebraic functions on the interval $[0, 1]$",On certain algebraic functions on the interval,"[0, 1]","Let $\mathcal{C}$ be the class of continuous and polynomially bounded functions that map the interval [0, 1] to [0, 1]. A function $f(x)$ is polynomially bounded if both $f$ and $1-f$ are bounded below by min( $x^n$ , $(1-x)^n$ ) for some integer $n$ (Keane and O'Brien 1994). This implies that $f$ admits no roots on (0, 1) and can't take on the value 0 or 1 except possibly at 0 and/or 1. A function $f(x)$ is algebraic over the rational numbers if— it can be a solution of a system of polynomial equations whose coefficients are rational numbers, or equivalently, there is a nonzero polynomial $P(x, y)$ in two variables and whose coefficients are rational numbers, such that $P(x, f(x)) = 0$ for every $x$ in the domain of $f$ . Then: Is a function in the class $\mathcal{C}$ algebraic over the rational numbers only if it's real analytic on the interval $(0, 1)$ ? Is a function in the class $\mathcal{C}$ algebraic over the rational numbers only if it's $\alpha$ -Hölder continuous for some $\alpha > 0$ ? (See note 2 below.) Are there functions in class $\mathcal{C}$ that— are algebraic over the rational numbers, but are not algebraic over the non-negative rational numbers? Motivation: According to Mossel and Peres (2005), a function in the class $\mathcal{C}$ can be simulated by a pushdown automaton only if the function is algebraic over the rational numbers, but the converse is not known to be true. Banderier and Drmota (2015) proved certain things involving algebraic functions over the non-negative real numbers, including their so-called ""critical exponents"" and the fact that these exponents impose a kind of lower bound on the complexity of any context-free grammar generating those functions. My question 3 may help answer whether those results apply more generally to algebraic functions over the rational numbers (not just over non-negative ones) in class $\mathcal{C}$ . Just like question 3, the other two questions may help answer whether certain things can be concluded about all algebraic functions in class $\mathcal{C}$ over rational numbers. Notes: A Google Scholar search didn't help me much in answering the first two questions. For example, Flajolet (1987) discussed how to determine if a power series is algebraic over rationals, but gave no example of a function that is algebraic over rationals but not analytic. Moreover, apparently not all algebraic functions over rationals might be expressible as power series, as Richman's results suggest. It is relatively easy to show that constants, the identity $x$ , and arbitrary additions and multiplications of these functions are Lipschitz continuous (1-Hölder continuous), and that those functions together with radicals are $\alpha$ -Hölder continuous.  However, it's not so easy to show whether those functions together with their reciprocals are $\alpha$ -Hölder continuous, or whether that remains true with arbitrary algebraic functions in the class $\mathcal{C}$ , including those that can't be expressed in terms of radicals.  Also, I believe that a function that maps (0, 1) to (0, 1) is algebraic over the rationals only if it's polynomially bounded. REFERENCES: Keane, M. S., and O'Brien, G. L., ""A Bernoulli factory"", ACM Transactions on Modeling and Computer Simulation 4(2), 1994. Mossel, Elchanan, and Yuval Peres. New coins from old: computing with unknown bias. Combinatorica, 25(6), pp.707-724. Banderier, C. And Drmota, M., 2015. Formulae and Asymptotics for Coefficients of Algebraic Functions. Comb. Probab. Comput., 24(1), pp.1-53. Richman, Fred. ""Algebraic functions, calculus style."" Communications in Algebra 40, no. 7 (2012): 2671-2683. Flajolet, P., 1987. Analytic models and ambiguity of context-free languages. Theoretical Computer Science, 49(2-3), pp.283-309.","Let be the class of continuous and polynomially bounded functions that map the interval [0, 1] to [0, 1]. A function is polynomially bounded if both and are bounded below by min( , ) for some integer (Keane and O'Brien 1994). This implies that admits no roots on (0, 1) and can't take on the value 0 or 1 except possibly at 0 and/or 1. A function is algebraic over the rational numbers if— it can be a solution of a system of polynomial equations whose coefficients are rational numbers, or equivalently, there is a nonzero polynomial in two variables and whose coefficients are rational numbers, such that for every in the domain of . Then: Is a function in the class algebraic over the rational numbers only if it's real analytic on the interval ? Is a function in the class algebraic over the rational numbers only if it's -Hölder continuous for some ? (See note 2 below.) Are there functions in class that— are algebraic over the rational numbers, but are not algebraic over the non-negative rational numbers? Motivation: According to Mossel and Peres (2005), a function in the class can be simulated by a pushdown automaton only if the function is algebraic over the rational numbers, but the converse is not known to be true. Banderier and Drmota (2015) proved certain things involving algebraic functions over the non-negative real numbers, including their so-called ""critical exponents"" and the fact that these exponents impose a kind of lower bound on the complexity of any context-free grammar generating those functions. My question 3 may help answer whether those results apply more generally to algebraic functions over the rational numbers (not just over non-negative ones) in class . Just like question 3, the other two questions may help answer whether certain things can be concluded about all algebraic functions in class over rational numbers. Notes: A Google Scholar search didn't help me much in answering the first two questions. For example, Flajolet (1987) discussed how to determine if a power series is algebraic over rationals, but gave no example of a function that is algebraic over rationals but not analytic. Moreover, apparently not all algebraic functions over rationals might be expressible as power series, as Richman's results suggest. It is relatively easy to show that constants, the identity , and arbitrary additions and multiplications of these functions are Lipschitz continuous (1-Hölder continuous), and that those functions together with radicals are -Hölder continuous.  However, it's not so easy to show whether those functions together with their reciprocals are -Hölder continuous, or whether that remains true with arbitrary algebraic functions in the class , including those that can't be expressed in terms of radicals.  Also, I believe that a function that maps (0, 1) to (0, 1) is algebraic over the rationals only if it's polynomially bounded. REFERENCES: Keane, M. S., and O'Brien, G. L., ""A Bernoulli factory"", ACM Transactions on Modeling and Computer Simulation 4(2), 1994. Mossel, Elchanan, and Yuval Peres. New coins from old: computing with unknown bias. Combinatorica, 25(6), pp.707-724. Banderier, C. And Drmota, M., 2015. Formulae and Asymptotics for Coefficients of Algebraic Functions. Comb. Probab. Comput., 24(1), pp.1-53. Richman, Fred. ""Algebraic functions, calculus style."" Communications in Algebra 40, no. 7 (2012): 2671-2683. Flajolet, P., 1987. Analytic models and ambiguity of context-free languages. Theoretical Computer Science, 49(2-3), pp.283-309.","\mathcal{C} f(x) f 1-f x^n (1-x)^n n f f(x) P(x, y) P(x, f(x)) = 0 x f \mathcal{C} (0, 1) \mathcal{C} \alpha \alpha > 0 \mathcal{C} \mathcal{C} \mathcal{C} \mathcal{C} x \alpha \alpha \mathcal{C}","['real-analysis', 'functions', 'algebraic-geometry', 'analytic-functions']"
97,Limit of uniformly converging volume-preserving homeomorphisms,Limit of uniformly converging volume-preserving homeomorphisms,,"Definition A continuous map $f\colon \mathbb{R}^d \to \mathbb{R}^d$ is volume-preserving if, for every Borel set $V\subset\mathbb{R}^d$ , $\mathcal{L}^d(V) = \mathcal{L}^d(f^{-1}(V))$ . I am wondering if the following holds: Suppose $f_n\colon \mathbb{R}^d \to \mathbb{R}^d$ is a volume-preserving homeomorphism for each $n\in\mathbb{N}$ . If $f_n$ converges uniformly to $f$ , then $f$ is a volume-preserving homeomorphism. So far, we know that $f$ is volume-preserving for the following reason. Let $\phi \in C_c^\infty$ . Because $f_n$ is volume-preserving, $\int \phi\circ f_n\,dx = \int \phi\,dx$ . As $f_n \to f$ uniformly, one can show that $\int \phi\circ f_n\,dx \to \int \phi \circ f\,dx$ . Now we know that $\int \phi \circ f\,dx = \int \phi\,dx$ , and so $f$ is volume-preserving.","Definition A continuous map is volume-preserving if, for every Borel set , . I am wondering if the following holds: Suppose is a volume-preserving homeomorphism for each . If converges uniformly to , then is a volume-preserving homeomorphism. So far, we know that is volume-preserving for the following reason. Let . Because is volume-preserving, . As uniformly, one can show that . Now we know that , and so is volume-preserving.","f\colon \mathbb{R}^d \to \mathbb{R}^d V\subset\mathbb{R}^d \mathcal{L}^d(V) = \mathcal{L}^d(f^{-1}(V)) f_n\colon \mathbb{R}^d \to \mathbb{R}^d n\in\mathbb{N} f_n f f f \phi \in C_c^\infty f_n \int \phi\circ f_n\,dx = \int \phi\,dx f_n \to f \int \phi\circ f_n\,dx \to \int \phi \circ f\,dx \int \phi \circ f\,dx = \int \phi\,dx f","['real-analysis', 'analysis', 'measure-theory', 'volume']"
98,Evaluating the integral $\int_1^{\infty} \int_1^{\infty} \frac{\Gamma(x+1)\Gamma(y+1)}{x y \Gamma(x+y+2)} \ dx \ dy$,Evaluating the integral,\int_1^{\infty} \int_1^{\infty} \frac{\Gamma(x+1)\Gamma(y+1)}{x y \Gamma(x+y+2)} \ dx \ dy,"During the study of some integrals I came across a very interesting integral, that is  $$\int_1^{\infty} \int_1^{\infty} \frac{\Gamma(x+1)\Gamma(y+1)}{x y \Gamma(x+y+2)} \ dx \ dy$$ that is obtained by manipulating  $$\int_0^1 \operatorname{li}(x) \operatorname{li}(1-x) \ dx$$  Apparently nothing seems to work, but I bet you can do much more than me. So, what tools would you recommend me to try?","During the study of some integrals I came across a very interesting integral, that is  $$\int_1^{\infty} \int_1^{\infty} \frac{\Gamma(x+1)\Gamma(y+1)}{x y \Gamma(x+y+2)} \ dx \ dy$$ that is obtained by manipulating  $$\int_0^1 \operatorname{li}(x) \operatorname{li}(1-x) \ dx$$  Apparently nothing seems to work, but I bet you can do much more than me. So, what tools would you recommend me to try?",,"['calculus', 'real-analysis', 'integration', 'definite-integrals']"
99,Does the series $\sum\frac{a_n}{a_{n+1}}\frac{1}{n}$ always diverge if $0<a_n<1$?,Does the series  always diverge if ?,\sum\frac{a_n}{a_{n+1}}\frac{1}{n} 0<a_n<1,"Does the series $$\sum_{n=1}^{\infty}\frac{a_n}{a_{n+1}}\frac{1}{n}$$ diverge for any $a_n$, satisfying $0<a_n<1$, $n=1, 2, 3\dots$ ?","Does the series $$\sum_{n=1}^{\infty}\frac{a_n}{a_{n+1}}\frac{1}{n}$$ diverge for any $a_n$, satisfying $0<a_n<1$, $n=1, 2, 3\dots$ ?",,"['calculus', 'real-analysis', 'sequences-and-series', 'convergence-divergence', 'divergent-series']"
