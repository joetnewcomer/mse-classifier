,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Can the formula for the exterior derivative be extended to vector valued differential forms?,Can the formula for the exterior derivative be extended to vector valued differential forms?,,"If $\omega$ is a real $k$-form then the exterior derivative $d\omega$ can be expressed as $ \begin{align*} d\omega(X_0,\dots,X_k)&=\sum_{i=0}^k (-1)^iX_i(\omega(X_0,\dots,\hat{X}_i,\dots,X_k)) \\ &\quad+\sum_{j=1}^k\sum_{i=0}^{j-1}(-1)^{i+j}\omega([X_i,X_j],X_0,\dots,\hat{X}_i,\dots,\hat{X}_j,\dots,X_k) \end{align*} $ where $X_0,\dots,X_k$ are vector fields and $\hat{X}_i$ indicates the omission of the argument $X_i$. Is there a way to extend this formula to the case when $\omega$ takes values in some finite dimensional real vector space $V$? The problem appears to be defining $X_i(\omega(X_0,\dots,\hat{X}_i,\dots,X_k))$ when $\omega$ is $V$-valued.","If $\omega$ is a real $k$-form then the exterior derivative $d\omega$ can be expressed as $ \begin{align*} d\omega(X_0,\dots,X_k)&=\sum_{i=0}^k (-1)^iX_i(\omega(X_0,\dots,\hat{X}_i,\dots,X_k)) \\ &\quad+\sum_{j=1}^k\sum_{i=0}^{j-1}(-1)^{i+j}\omega([X_i,X_j],X_0,\dots,\hat{X}_i,\dots,\hat{X}_j,\dots,X_k) \end{align*} $ where $X_0,\dots,X_k$ are vector fields and $\hat{X}_i$ indicates the omission of the argument $X_i$. Is there a way to extend this formula to the case when $\omega$ takes values in some finite dimensional real vector space $V$? The problem appears to be defining $X_i(\omega(X_0,\dots,\hat{X}_i,\dots,X_k))$ when $\omega$ is $V$-valued.",,"['differential-geometry', 'differential-forms']"
1,Holonomy of a curve in case of principal $U(1)$ bundle,Holonomy of a curve in case of principal  bundle,U(1),"Suppose $\pi : P\rightarrow M$ is principal $U(1)$ bundle. Let $\gamma$ be a loop in $M$ based at $x_0$ and write $iA$ as connection 1-form on $P$ where $A\in \Omega(P)$. Now define $hol_{\gamma}(A)\in U(1)$ as follows: let $\tilde{\gamma}$ be a horizontal lift of $\gamma$ with $\tilde{\gamma}(0)=p_0$ and $\pi(p_0)=x_0$. Then there is a unique element $hol_{\gamma}(A)$ in $U(1)$ such that $\tilde{\gamma}(1)=p_0\cdot hol_{\gamma}(A)$ because the action is free and transitive. I now want to calculate explicitly what is this number $hol_{\gamma}(A)$. I know already it has to be $hol_{\gamma}(A)=e^{i\int_{\gamma}A}$, but I have no idea how this is calculated as I am new to holonomy. Any hint is useful for me. Thanks","Suppose $\pi : P\rightarrow M$ is principal $U(1)$ bundle. Let $\gamma$ be a loop in $M$ based at $x_0$ and write $iA$ as connection 1-form on $P$ where $A\in \Omega(P)$. Now define $hol_{\gamma}(A)\in U(1)$ as follows: let $\tilde{\gamma}$ be a horizontal lift of $\gamma$ with $\tilde{\gamma}(0)=p_0$ and $\pi(p_0)=x_0$. Then there is a unique element $hol_{\gamma}(A)$ in $U(1)$ such that $\tilde{\gamma}(1)=p_0\cdot hol_{\gamma}(A)$ because the action is free and transitive. I now want to calculate explicitly what is this number $hol_{\gamma}(A)$. I know already it has to be $hol_{\gamma}(A)=e^{i\int_{\gamma}A}$, but I have no idea how this is calculated as I am new to holonomy. Any hint is useful for me. Thanks",,"['differential-geometry', 'principal-bundles']"
2,"What does it mean when a differential form ""stays the same""?","What does it mean when a differential form ""stays the same""?",,"For example, consider the differential one-form $$\frac{\mathrm dw}{1-w^2}$$ If we make the change of coordinates $w=1/z$ then we see that $$\frac{\mathrm dw}{1-w^2} \longrightarrow \frac{\mathrm dz}{1-z^2}$$ Is there any significance to the form ""being the same"" in both coordinate systems? Context: I'm looking at meromorphic differential forms on Riemann Surfaces.","For example, consider the differential one-form $$\frac{\mathrm dw}{1-w^2}$$ If we make the change of coordinates $w=1/z$ then we see that $$\frac{\mathrm dw}{1-w^2} \longrightarrow \frac{\mathrm dz}{1-z^2}$$ Is there any significance to the form ""being the same"" in both coordinate systems? Context: I'm looking at meromorphic differential forms on Riemann Surfaces.",,"['calculus', 'differential-geometry', 'riemann-surfaces']"
3,Existence of diffeomorphism so that $\int (\phi^* f) \omega = 0$,Existence of diffeomorphism so that,\int (\phi^* f) \omega = 0,"Can someone help me with this question?  Is a qual exam question and I have no idea how to tackle it. Prove or disprove: Let $f\in \mathcal{C}^\infty(S^n)$ be a smooth function and $x_1, x_2\in S^n$ be two points such that $f(x_1)<0<f(x_2)$. Let $\omega$ be a smooth nonvanishing $n$-form. Then there is a diffeomorphism $\phi\colon S^n \rightarrow S^n$ such that $\int_{S^n} (\phi^* f)\omega =0$.","Can someone help me with this question?  Is a qual exam question and I have no idea how to tackle it. Prove or disprove: Let $f\in \mathcal{C}^\infty(S^n)$ be a smooth function and $x_1, x_2\in S^n$ be two points such that $f(x_1)<0<f(x_2)$. Let $\omega$ be a smooth nonvanishing $n$-form. Then there is a diffeomorphism $\phi\colon S^n \rightarrow S^n$ such that $\int_{S^n} (\phi^* f)\omega =0$.",,['differential-geometry']
4,closed $1$-form that is exact,closed -form that is exact,1,Let $\alpha=\sum_{i=1}^n f_idx_i$ be a closed $1$-form defined on all of $\mathbb{R}^n$. Verify that the function $g(\textbf{x})=\sum_{i=1}^nx_i\int_0^1f_i(t\textbf{x})dt$ satisfies $dg=\alpha$. Proof. we must show that $\frac{\partial g}{\partial x_i}=f_i$. Then \begin{align} \frac{\partial g}{\partial x_j}(\textbf{x})&=\frac{\partial }{\partial x_j}\left(\sum_{i=1}^n x_i\int_0^1f_i(t\textbf{x})dt\right)\\ &=\sum_{i=1}^n \frac{\partial }{\partial x_j}\left( x_i\int_0^1f_i(t\textbf{x})dt\right)\\ &=\sum_{i=1}^n\left( \frac{\partial }{\partial x_j}x_i\int_0^1f_i(t\textbf{x})dt+x_i\frac{\partial }{\partial x_j}\int_0^1f_i(t\textbf{x})dt\right)\\ &=\sum_{i=1}^n\left(\frac{\partial }{\partial x_j}x_i\int_0^1f_i(t\textbf{x})dt\right)+\sum_{i=1}^nx_i\int_0^1\frac{\partial}{\partial x_j}f_i(t\textbf{x})dt\\ &=\int_0^1f_j(t\textbf{x})dt+\sum_{i=1}^nx_i\int_0^1\frac{\partial}{\partial x_j}f_i(t\textbf{x})dt \end{align} I don't know how to continue,Let $\alpha=\sum_{i=1}^n f_idx_i$ be a closed $1$-form defined on all of $\mathbb{R}^n$. Verify that the function $g(\textbf{x})=\sum_{i=1}^nx_i\int_0^1f_i(t\textbf{x})dt$ satisfies $dg=\alpha$. Proof. we must show that $\frac{\partial g}{\partial x_i}=f_i$. Then \begin{align} \frac{\partial g}{\partial x_j}(\textbf{x})&=\frac{\partial }{\partial x_j}\left(\sum_{i=1}^n x_i\int_0^1f_i(t\textbf{x})dt\right)\\ &=\sum_{i=1}^n \frac{\partial }{\partial x_j}\left( x_i\int_0^1f_i(t\textbf{x})dt\right)\\ &=\sum_{i=1}^n\left( \frac{\partial }{\partial x_j}x_i\int_0^1f_i(t\textbf{x})dt+x_i\frac{\partial }{\partial x_j}\int_0^1f_i(t\textbf{x})dt\right)\\ &=\sum_{i=1}^n\left(\frac{\partial }{\partial x_j}x_i\int_0^1f_i(t\textbf{x})dt\right)+\sum_{i=1}^nx_i\int_0^1\frac{\partial}{\partial x_j}f_i(t\textbf{x})dt\\ &=\int_0^1f_j(t\textbf{x})dt+\sum_{i=1}^nx_i\int_0^1\frac{\partial}{\partial x_j}f_i(t\textbf{x})dt \end{align} I don't know how to continue,,['differential-geometry']
5,Conditions on characteristic polynomial to define a matrix submanifold.,Conditions on characteristic polynomial to define a matrix submanifold.,,"I'm trying to find conditions on the characteristic polynomial, $p$, of a matrix such that the pre-image of matrices with characteristic polynomial $p$ form a manifold. More precisely, we can write down a map $\phi: \textrm{Mat}_n(\mathbb{R}) \to \mathbb{R}[x]$ given by $\phi(A) = \textrm{det}(xI-A)$ and so now the question reduces to finding $p \in \mathbb{R}[x]$ such that the derivative of $f$ evaluated at pre-images of $p$ is surjective. Using the ""Jacobi formula"" for the derivative of a determinant, namely $T_Af(X) = \mathrm{det}(A)Tr(A^{-1}X)$ where $f(A) = \mathrm{det}(A)$, I think we can deduce that the determinant of $\phi$ is given by: $$T_A(\phi)(X) = det(xI-A)tr((xI-A)^{-1}X)$$ This is where I first get in to trouble, how do we know in this case that $xI-A$ is even invertible? Surely this is only true in some finite interval (bounded by the norm of $A$)? Is this actually the correct formula for the derivative? It also seems impossible to determine if this map is surjective or not? How can we understand which polynomials are hit by this map? Edit: I've made some progress but am still struggling with this. Thanks to Qiaochu Yuan I'm now trying to show this when $p$ has distinct real roots. To find the derivative we can write $\phi(A+tH) = det(xI - (A+tH))$ and attempt to evaluate $\frac{\phi(A+tH) - \phi(A)}{t}$ as $t \to 0$. Now the numerator here gives: $$x^n + ... - tr(A+tH)x + det(A+tH) - det(xI-A)$$ Expanding out the determinants: $$x^n + ... - tr(A)x - t tr(H)x + det(A+tH) - x^n + ... + tr(A)x - det(A)$$ Now I'm left with the $x^n$ terms cancelling and the constant term will again just be the derivative of $det(A)$ which is $det(A)tr(A^{-1}H)$ and the $x$ term will be $-tr(H)$. The difficulty is, I have no idea what the $1<k<n-1$ terms should be, and these are the important ones because they describe the tangent space of the n monic polynomials!","I'm trying to find conditions on the characteristic polynomial, $p$, of a matrix such that the pre-image of matrices with characteristic polynomial $p$ form a manifold. More precisely, we can write down a map $\phi: \textrm{Mat}_n(\mathbb{R}) \to \mathbb{R}[x]$ given by $\phi(A) = \textrm{det}(xI-A)$ and so now the question reduces to finding $p \in \mathbb{R}[x]$ such that the derivative of $f$ evaluated at pre-images of $p$ is surjective. Using the ""Jacobi formula"" for the derivative of a determinant, namely $T_Af(X) = \mathrm{det}(A)Tr(A^{-1}X)$ where $f(A) = \mathrm{det}(A)$, I think we can deduce that the determinant of $\phi$ is given by: $$T_A(\phi)(X) = det(xI-A)tr((xI-A)^{-1}X)$$ This is where I first get in to trouble, how do we know in this case that $xI-A$ is even invertible? Surely this is only true in some finite interval (bounded by the norm of $A$)? Is this actually the correct formula for the derivative? It also seems impossible to determine if this map is surjective or not? How can we understand which polynomials are hit by this map? Edit: I've made some progress but am still struggling with this. Thanks to Qiaochu Yuan I'm now trying to show this when $p$ has distinct real roots. To find the derivative we can write $\phi(A+tH) = det(xI - (A+tH))$ and attempt to evaluate $\frac{\phi(A+tH) - \phi(A)}{t}$ as $t \to 0$. Now the numerator here gives: $$x^n + ... - tr(A+tH)x + det(A+tH) - det(xI-A)$$ Expanding out the determinants: $$x^n + ... - tr(A)x - t tr(H)x + det(A+tH) - x^n + ... + tr(A)x - det(A)$$ Now I'm left with the $x^n$ terms cancelling and the constant term will again just be the derivative of $det(A)$ which is $det(A)tr(A^{-1}H)$ and the $x$ term will be $-tr(H)$. The difficulty is, I have no idea what the $1<k<n-1$ terms should be, and these are the important ones because they describe the tangent space of the n monic polynomials!",,"['differential-geometry', 'manifolds', 'lie-groups', 'smooth-manifolds']"
6,Can you determine the length of a curve by the lengths of its projections onto planes?,Can you determine the length of a curve by the lengths of its projections onto planes?,,"If $\,\Gamma \subset \mathbb R^n$ is $1$–rectifiable, then its Hausdorff measure is equal to its integral geometric measure. That is,  $$\displaystyle\mathcal H^1\left(\Gamma\right) = \int_{G\left({1,\mathbb R}^n\right)} \int_K \operatorname{Card}\left(\left\lbrace {y \in \Pi_K}^{-1}\left(\left\lbrace x\right\rbrace \right)\right\rbrace \right)\, {d\hspace{0.125ex}\mathcal H}^1\left(x\right)\, d \hspace{0.125ex}\Theta_{{1,\mathbb R}^n}\left(K\right),$$ where $\operatorname{Card}(S)$ means the number of points in ${S,\Pi}_K$ denotes orthogonal projection onto ${K,\mathcal H}^1$ denotes the one–dimensional Hausdorff measure, $G\left({1,\mathbb R}^n\right)$ denotes the Grassmanian of unoriented lines through the origin in $\mathbb R^n$, and $\Theta_{{1,\mathbb R}^n}$ is the unique (up to suitable constant) finite Borel measure on $G\left({1,\mathbb R}^n\right)$ which is invariant under the action of the orthogonal group. I would like to know if the following is true: $$\displaystyle\mathcal H^1\left(\Gamma\right) = \int_{G\left({2,\mathbb R}^n\right)} \int_V \operatorname{Card}\left(\left\lbrace {y \in \Pi_V}^{-1}\left(\left\lbrace x\right\rbrace \right)\right\rbrace \right)\, {d\hspace{0.125ex}\mathcal H}^1\left(x\right)\, d \hspace{0.125ex}\Theta_{{2,\mathbb R}^n}\left(K\right),$$ The more general question where the numbers $1$ and $2$ are replaced by $j$ and $k$ with $j<k<n$ is also of interest.","If $\,\Gamma \subset \mathbb R^n$ is $1$–rectifiable, then its Hausdorff measure is equal to its integral geometric measure. That is,  $$\displaystyle\mathcal H^1\left(\Gamma\right) = \int_{G\left({1,\mathbb R}^n\right)} \int_K \operatorname{Card}\left(\left\lbrace {y \in \Pi_K}^{-1}\left(\left\lbrace x\right\rbrace \right)\right\rbrace \right)\, {d\hspace{0.125ex}\mathcal H}^1\left(x\right)\, d \hspace{0.125ex}\Theta_{{1,\mathbb R}^n}\left(K\right),$$ where $\operatorname{Card}(S)$ means the number of points in ${S,\Pi}_K$ denotes orthogonal projection onto ${K,\mathcal H}^1$ denotes the one–dimensional Hausdorff measure, $G\left({1,\mathbb R}^n\right)$ denotes the Grassmanian of unoriented lines through the origin in $\mathbb R^n$, and $\Theta_{{1,\mathbb R}^n}$ is the unique (up to suitable constant) finite Borel measure on $G\left({1,\mathbb R}^n\right)$ which is invariant under the action of the orthogonal group. I would like to know if the following is true: $$\displaystyle\mathcal H^1\left(\Gamma\right) = \int_{G\left({2,\mathbb R}^n\right)} \int_V \operatorname{Card}\left(\left\lbrace {y \in \Pi_V}^{-1}\left(\left\lbrace x\right\rbrace \right)\right\rbrace \right)\, {d\hspace{0.125ex}\mathcal H}^1\left(x\right)\, d \hspace{0.125ex}\Theta_{{2,\mathbb R}^n}\left(K\right),$$ The more general question where the numbers $1$ and $2$ are replaced by $j$ and $k$ with $j<k<n$ is also of interest.",,"['differential-geometry', 'geometric-measure-theory']"
7,Parallel transport along a closed geodesic,Parallel transport along a closed geodesic,,"It do Carmo, in exercise 9.4, it is claimed that parallel transport along a closed geodesic in an even-dimensional orientable manifold ""leaves a vector orthogonal to the geodesic invariant."" So, let $\gamma:[0,a]\to M$ be this geodesic, with $\gamma(0)=\gamma(a)=p$, and let $V\in T_pM$ be orthogonal to $\gamma'(0)$. Let $P_t$ be the parallel transport along the geodesic. From Picard-Lindelöf, it is clear that $P_a\gamma'(0)=\gamma'(a)$. Let $V(t):=P_t V$. I believe the claim is that $V=P_aV$. It is clear that $\langle V(a),\gamma'(0)\rangle=0$, so $V(a)$ lies in the same $\gamma'(0)$-orthogonal subspace ($T_pM^\bot$) as $V$. Let $E_1,\dotsc,E_{n-1}$ be an orthonormal basis of this subspace. Extend these via parallel transport along the geodesic. Then $E_1(a),\dotsc,E_{n-1}(a):=P_aE_1,\dotsc,P_aE_{n-1}$ is also an orthonormal frame of $T_pM^\bot$. Since $P_t$ preserves orientation (I have already proved this), there is an $O\in\mathrm{SO}(n-1)$ such that $E_i(a)=\sum_{j=1}^{n-1}O_i{}^jE_j$. At this point I get stuck. I see no reason for $O$ to be the identity or what $M$ being even-dimensional has to do with anything. How do I continue?","It do Carmo, in exercise 9.4, it is claimed that parallel transport along a closed geodesic in an even-dimensional orientable manifold ""leaves a vector orthogonal to the geodesic invariant."" So, let $\gamma:[0,a]\to M$ be this geodesic, with $\gamma(0)=\gamma(a)=p$, and let $V\in T_pM$ be orthogonal to $\gamma'(0)$. Let $P_t$ be the parallel transport along the geodesic. From Picard-Lindelöf, it is clear that $P_a\gamma'(0)=\gamma'(a)$. Let $V(t):=P_t V$. I believe the claim is that $V=P_aV$. It is clear that $\langle V(a),\gamma'(0)\rangle=0$, so $V(a)$ lies in the same $\gamma'(0)$-orthogonal subspace ($T_pM^\bot$) as $V$. Let $E_1,\dotsc,E_{n-1}$ be an orthonormal basis of this subspace. Extend these via parallel transport along the geodesic. Then $E_1(a),\dotsc,E_{n-1}(a):=P_aE_1,\dotsc,P_aE_{n-1}$ is also an orthonormal frame of $T_pM^\bot$. Since $P_t$ preserves orientation (I have already proved this), there is an $O\in\mathrm{SO}(n-1)$ such that $E_i(a)=\sum_{j=1}^{n-1}O_i{}^jE_j$. At this point I get stuck. I see no reason for $O$ to be the identity or what $M$ being even-dimensional has to do with anything. How do I continue?",,"['differential-geometry', 'riemannian-geometry']"
8,Arnold's proof of Liouville's Theorem on integrable systems,Arnold's proof of Liouville's Theorem on integrable systems,,"My question happens to be almost identical to the one left unanswered/closed here , which gives a bit of background information - it may not be necessary. I hope the reason it was closed on mathoverflow is not a reason for it to be closed here, please let me know if I should reformulate the question. To reiterate, I refer to page 278 of Arnold's book 'Mathematical Methods of classical mechanics', namely the part after Lemma 3 is proved but before section 50 on Action-angle variables. An online version can be referred to here . My confusion first occurs when $p$ is stated as being a chart for $\mathbb{T}^k\times\mathbb{R}^{n-k}$, since it is certainly not 1-1 (all $f_i$ are mapped to 0 under it). This leads on to confusion with problem 10 - I simply cannot see a way to prove $\tilde{A}$ is a diffeomorphism, given that neither $p$ nor $g$ are diffeomorphisms. This seems to be the only gap for me at the moment - at first glance I am not sure about Problem 11 either, but will post about that separately. Any help on this would be much appreciated.","My question happens to be almost identical to the one left unanswered/closed here , which gives a bit of background information - it may not be necessary. I hope the reason it was closed on mathoverflow is not a reason for it to be closed here, please let me know if I should reformulate the question. To reiterate, I refer to page 278 of Arnold's book 'Mathematical Methods of classical mechanics', namely the part after Lemma 3 is proved but before section 50 on Action-angle variables. An online version can be referred to here . My confusion first occurs when $p$ is stated as being a chart for $\mathbb{T}^k\times\mathbb{R}^{n-k}$, since it is certainly not 1-1 (all $f_i$ are mapped to 0 under it). This leads on to confusion with problem 10 - I simply cannot see a way to prove $\tilde{A}$ is a diffeomorphism, given that neither $p$ nor $g$ are diffeomorphisms. This seems to be the only gap for me at the moment - at first glance I am not sure about Problem 11 either, but will post about that separately. Any help on this would be much appreciated.",,"['differential-geometry', 'dynamical-systems', 'mathematical-physics', 'classical-mechanics', 'symplectic-geometry']"
9,Minimal-dimension example of (open) subset of $\mathbb{R}^n$ with trivial first cohomology but nontrivial fundamental group,Minimal-dimension example of (open) subset of  with trivial first cohomology but nontrivial fundamental group,\mathbb{R}^n,"As a follow-up to this question, I was wondering what dimension provides the minimal counterexample to the claims: If $U\subseteq\mathbb{R}^n$ is an open connected set with trivial $H^1(U)$, then $\pi_1(U)$ is trivial; Same as above, but with a more general $U$. Let $m$ be the minimal counterexample's ambient space's dimension. Qiaochu's answer to the above linked question shows $m\leq 4$, since for claim 2, we have $\mathbb{RP}^2$ smoothly imbedded into $\mathbb{R}^4$ providing the example directly, whereas for claim 1 we take a tubular neighborhood of the embedded image of $\mathbb{RP}^2$, which is then open and connected, and deformation retracts (I guess, correct me if I'm wrong) onto $\mathbb{RP}^2$, thus having the same fundamental group and cohomology. Qiaochu also stated in a comment that the fundamental group of an open subset of $\mathbb{R}^2$ is free, which I found proof-sketched here . He also stated that the Universal Coefficient Theorem (which I will sooner or later be studying for an exam) can be used to prove $H^1(U)=1\iff\mathrm{Hom}(\pi_1(U),\mathbb{R})=1$. These two facts put together imply $m_1\in\{1,3,4\}$, where $m_1$ is the $m$ for claim 1. In dimension 1, connected subsets are intervals, hence have trivial $\pi_1$. So $m_1\in\{2,3,4\}$ and $m_2\in\{3,4\}$. The 3-dimensional case seems to have claim 1 as an open problem , so I was wondering if I could get: An answer about 2 dimensions and claim 2; I'm guessing we can once more take a non open connected set in the plane and say a tubular neighborhoods of it would retract onto it, having the same fundamental group, thus concluding by Qiaochu's comment's ""nonobvious fact"" that we have no counterexamples in the plane because all fundamental groups are free; is that right? Something about the 3-dimensional case, if it is possible for claim 2; although the prhasing of that comment about the open problem seems to suggest that ""open"" does make a differnece, which would contrast with the tubular neighborhood retraction argument. Edit In case comments to that answer get trimmed (they are a lot), here are screenshots 1 and 2 .","As a follow-up to this question, I was wondering what dimension provides the minimal counterexample to the claims: If $U\subseteq\mathbb{R}^n$ is an open connected set with trivial $H^1(U)$, then $\pi_1(U)$ is trivial; Same as above, but with a more general $U$. Let $m$ be the minimal counterexample's ambient space's dimension. Qiaochu's answer to the above linked question shows $m\leq 4$, since for claim 2, we have $\mathbb{RP}^2$ smoothly imbedded into $\mathbb{R}^4$ providing the example directly, whereas for claim 1 we take a tubular neighborhood of the embedded image of $\mathbb{RP}^2$, which is then open and connected, and deformation retracts (I guess, correct me if I'm wrong) onto $\mathbb{RP}^2$, thus having the same fundamental group and cohomology. Qiaochu also stated in a comment that the fundamental group of an open subset of $\mathbb{R}^2$ is free, which I found proof-sketched here . He also stated that the Universal Coefficient Theorem (which I will sooner or later be studying for an exam) can be used to prove $H^1(U)=1\iff\mathrm{Hom}(\pi_1(U),\mathbb{R})=1$. These two facts put together imply $m_1\in\{1,3,4\}$, where $m_1$ is the $m$ for claim 1. In dimension 1, connected subsets are intervals, hence have trivial $\pi_1$. So $m_1\in\{2,3,4\}$ and $m_2\in\{3,4\}$. The 3-dimensional case seems to have claim 1 as an open problem , so I was wondering if I could get: An answer about 2 dimensions and claim 2; I'm guessing we can once more take a non open connected set in the plane and say a tubular neighborhoods of it would retract onto it, having the same fundamental group, thus concluding by Qiaochu's comment's ""nonobvious fact"" that we have no counterexamples in the plane because all fundamental groups are free; is that right? Something about the 3-dimensional case, if it is possible for claim 2; although the prhasing of that comment about the open problem seems to suggest that ""open"" does make a differnece, which would contrast with the tubular neighborhood retraction argument. Edit In case comments to that answer get trimmed (they are a lot), here are screenshots 1 and 2 .",,"['differential-geometry', 'algebraic-topology', 'homology-cohomology', 'geometric-topology', 'fundamental-groups']"
10,If and only if criterion for something to be a differential ideal,If and only if criterion for something to be a differential ideal,,"Let $I \subset \Omega^*(M)$ be a ($2$-sided) ideal (i.e. $I$ is a vector subspace, and for any $\alpha \in I$ and $\omega \in \Omega^*(M)$ we have $\omega \wedge \alpha \in I$). We say $I$ is a differential ideal if $d\omega \in I$ whenever $\omega \in I$. Suppose $I$ is generated as an ideal by $\omega_1, \omega_2, \ldots, \omega_r$. Is $I$ is a differential ideal if and only if$$d\omega_i = \sum_j \omega_{ij} \wedge \omega_j$$for suitable $1$-forms $\omega_{ij}$?","Let $I \subset \Omega^*(M)$ be a ($2$-sided) ideal (i.e. $I$ is a vector subspace, and for any $\alpha \in I$ and $\omega \in \Omega^*(M)$ we have $\omega \wedge \alpha \in I$). We say $I$ is a differential ideal if $d\omega \in I$ whenever $\omega \in I$. Suppose $I$ is generated as an ideal by $\omega_1, \omega_2, \ldots, \omega_r$. Is $I$ is a differential ideal if and only if$$d\omega_i = \sum_j \omega_{ij} \wedge \omega_j$$for suitable $1$-forms $\omega_{ij}$?",,"['differential-geometry', 'manifolds', 'differential-topology', 'multilinear-algebra', 'exterior-algebra']"
11,Hints for an exercise on Morse theory,Hints for an exercise on Morse theory,,"Exercise : Let $M$ be a $3$-dimensional smooth manifold with boundary $\partial M$ which is a surface of genus $g$. Moreover let $f:M\longrightarrow [0,1]$ be a Morse function with the following properties: $f(\partial M)$ is a regular value. Lets denote with $\mu_i(f)$ the number of critical points of $f$ of index $i$, then $\mu_0(f)=1$ and $\mu_2(f)=\mu_3(f)=0$ Prove that $M$ is connected and determine $\mu_1(f)$. I tried different approaches to solve it; here you can see my wrong reasonings: $1)$  Lets reconstruct partially the Morse-Smale complex (over $\mathbb Z/2\mathbb Z$). We have one critical point of index $0$, therefore $C_0(M)\cong\mathbb Z/2\mathbb Z$ and in the same way we can conclude that $C_2(M)=C_3(M)=0$. For compact manifolds we have the following theorem: Let $M$ be a compact manifold of dimension $n$, then the dimension as vector space of the Morse-Smile homology group $H_n(C^\bullet)$ (or $H_0(C^\bullet)$) is the number of connected components of $M$. In my case $H_3(C^\bullet)=0$ since $C_3(M)=C_4(M)$ so maybe I'm on the wrong way. Probably I can't use the theorem for two reasons: $M$ has boundary and it is not compact. $2)$ I tried to use the Morse inequalities but I have two main obstacles, $M$ ha boundary and I don't know the number of critical points of index $1$ (I have to find them). $3)$ I don't know if I can use the fact that $\chi(M)=0$ if $\text{dim}(M)$ is odd because I've seen this theorem only for compact manifolds without boundary. $4)$ If $M$ where without boundary I could conclude that it has the homotopy type of a CW-complex with only one $0$-cell. At this point I should prove that this type of $CW$-complexes are connected (it is easy). I don't know how to use the fact that the homology of $\partial M$ is known, because I don't understand how to relate it with the homology of $M$. Could you help me please?","Exercise : Let $M$ be a $3$-dimensional smooth manifold with boundary $\partial M$ which is a surface of genus $g$. Moreover let $f:M\longrightarrow [0,1]$ be a Morse function with the following properties: $f(\partial M)$ is a regular value. Lets denote with $\mu_i(f)$ the number of critical points of $f$ of index $i$, then $\mu_0(f)=1$ and $\mu_2(f)=\mu_3(f)=0$ Prove that $M$ is connected and determine $\mu_1(f)$. I tried different approaches to solve it; here you can see my wrong reasonings: $1)$  Lets reconstruct partially the Morse-Smale complex (over $\mathbb Z/2\mathbb Z$). We have one critical point of index $0$, therefore $C_0(M)\cong\mathbb Z/2\mathbb Z$ and in the same way we can conclude that $C_2(M)=C_3(M)=0$. For compact manifolds we have the following theorem: Let $M$ be a compact manifold of dimension $n$, then the dimension as vector space of the Morse-Smile homology group $H_n(C^\bullet)$ (or $H_0(C^\bullet)$) is the number of connected components of $M$. In my case $H_3(C^\bullet)=0$ since $C_3(M)=C_4(M)$ so maybe I'm on the wrong way. Probably I can't use the theorem for two reasons: $M$ has boundary and it is not compact. $2)$ I tried to use the Morse inequalities but I have two main obstacles, $M$ ha boundary and I don't know the number of critical points of index $1$ (I have to find them). $3)$ I don't know if I can use the fact that $\chi(M)=0$ if $\text{dim}(M)$ is odd because I've seen this theorem only for compact manifolds without boundary. $4)$ If $M$ where without boundary I could conclude that it has the homotopy type of a CW-complex with only one $0$-cell. At this point I should prove that this type of $CW$-complexes are connected (it is easy). I don't know how to use the fact that the homology of $\partial M$ is known, because I don't understand how to relate it with the homology of $M$. Could you help me please?",,"['differential-geometry', 'differential-topology', 'homology-cohomology', 'morse-theory']"
12,Are all instances of torsion special cases of the same concept?,Are all instances of torsion special cases of the same concept?,,"The concept of 'torsion' pervades mathematics. As far as I know the origin of the word is in algebraic topology where it was used to describe chains $\gamma$ which are not boundaries but such that $2\gamma$ are boundaries. Then there's torsion in general abelian groups, rings, and modules. There's torsion in differential geometry , and analytic torsion . Lastly, there's $\mathrm{Tor}$, the left derived functor of the tensor product which is defined at least in the case of modules. The lower dimensional $\mathrm{Tor}$ functors tell us about torsion. I don't understand what the higher ones do, but this bridge does exist. So the tensor product over of modules does poop out torsion from high above. In differential geometry, the torsion form is often identified with a section of $TM\otimes \Lambda ^2T^\ast M$, called the torsion tensor. So formally, the tensor product pops up here too. Unfortunately The definition of analytic torsion is beyond me entirely. To what extent can these concepts be unified, seen as special cases of each other, or obtained from abstract nonsense?","The concept of 'torsion' pervades mathematics. As far as I know the origin of the word is in algebraic topology where it was used to describe chains $\gamma$ which are not boundaries but such that $2\gamma$ are boundaries. Then there's torsion in general abelian groups, rings, and modules. There's torsion in differential geometry , and analytic torsion . Lastly, there's $\mathrm{Tor}$, the left derived functor of the tensor product which is defined at least in the case of modules. The lower dimensional $\mathrm{Tor}$ functors tell us about torsion. I don't understand what the higher ones do, but this bridge does exist. So the tensor product over of modules does poop out torsion from high above. In differential geometry, the torsion form is often identified with a section of $TM\otimes \Lambda ^2T^\ast M$, called the torsion tensor. So formally, the tensor product pops up here too. Unfortunately The definition of analytic torsion is beyond me entirely. To what extent can these concepts be unified, seen as special cases of each other, or obtained from abstract nonsense?",,"['differential-geometry', 'algebraic-topology', 'intuition', 'derived-functors', 'big-picture']"
13,Curvature of given metric space,Curvature of given metric space,,"As my question 1 and 2 , I still have many problems. First, the hyperbolic manifold is the manifold $(\mathbb R^n , g)$ given by one chart $\mathbb R^n$, where in spherical coordinates $(\theta^0= s, \theta^1, \cdots, \theta^{n-1})$, the metric is given by  $$\tag{1} g = ds^2 + \frac1M \sinh^2(\sqrt M s) d\Omega^2.$$ I want to compute the curvature of $(\mathbb R^n,g)$.I try to compute $\Gamma_{ij}^k$, but in different dimension,$d\Omega^2$ has different form , I can't get $g_{ij} $ for $i,j\ne0$.Then ,I don't know how to do it .","As my question 1 and 2 , I still have many problems. First, the hyperbolic manifold is the manifold $(\mathbb R^n , g)$ given by one chart $\mathbb R^n$, where in spherical coordinates $(\theta^0= s, \theta^1, \cdots, \theta^{n-1})$, the metric is given by  $$\tag{1} g = ds^2 + \frac1M \sinh^2(\sqrt M s) d\Omega^2.$$ I want to compute the curvature of $(\mathbb R^n,g)$.I try to compute $\Gamma_{ij}^k$, but in different dimension,$d\Omega^2$ has different form , I can't get $g_{ij} $ for $i,j\ne0$.Then ,I don't know how to do it .",,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
14,Why the combinatorial second Stiefel-Whitney class is a cocycle?,Why the combinatorial second Stiefel-Whitney class is a cocycle?,,"From the book ""Spin geometry"" by Lawson&Michaelson Appendix A or this literature we know that there is a nice combinatorial way to interpret the second SW class by the transition functions of a principal bundle. The basic idea is, we firstly take a good covering, where the principal bundle is trivial on each open sets. Then on each two-fold intersection we have the transition functions $$g_{\alpha\beta}: U_\alpha\bigcap U_\beta\rightarrow \mathrm{SO}(n)$$ Lifting each map to $\overline{g}_{\alpha\beta}:U_\alpha\bigcap U_{\beta}\rightarrow \mathrm{Spin}(n)$ gives a cochain on each three-fold intersection $$w_{\alpha\beta\gamma}=\overline{g}_{\alpha\beta}\overline{g}_{\beta\gamma}\overline{g}_{\gamma\alpha}:U_{\alpha}\bigcap U_{\beta} \bigcap U_{\gamma}\rightarrow \mathbb{Z}_2$$ On both references above they just claim that $w$ is a cocycle. But I just wonder is the argument really so trivial?","From the book ""Spin geometry"" by Lawson&Michaelson Appendix A or this literature we know that there is a nice combinatorial way to interpret the second SW class by the transition functions of a principal bundle. The basic idea is, we firstly take a good covering, where the principal bundle is trivial on each open sets. Then on each two-fold intersection we have the transition functions $$g_{\alpha\beta}: U_\alpha\bigcap U_\beta\rightarrow \mathrm{SO}(n)$$ Lifting each map to $\overline{g}_{\alpha\beta}:U_\alpha\bigcap U_{\beta}\rightarrow \mathrm{Spin}(n)$ gives a cochain on each three-fold intersection $$w_{\alpha\beta\gamma}=\overline{g}_{\alpha\beta}\overline{g}_{\beta\gamma}\overline{g}_{\gamma\alpha}:U_{\alpha}\bigcap U_{\beta} \bigcap U_{\gamma}\rightarrow \mathbb{Z}_2$$ On both references above they just claim that $w$ is a cocycle. But I just wonder is the argument really so trivial?",,"['differential-geometry', 'algebraic-topology', 'characteristic-classes', 'spin-geometry']"
15,different definition of connection on bundle,different definition of connection on bundle,,"I have encountered two definitions of connection in two different setting namely in vector bundle and principal bundle and I don't see the equivalence in these two setting. In vector bundle setting: Let $M$ be a smooth manifold, $E$ be a vector bundle on it, and $TM$ be the tangent bundle of $M$. Define a connection $\triangledown $ be a function from $\Gamma(TM,M) \times \Gamma(E,M) \rightarrow \Gamma(E,M)$. Here $\Gamma(-,M)$ is a functor from Vector bundle to its set of global section. So we can think of $\triangledown$ as a function from $\Gamma(E,M)$ to $\Omega^1(M)\otimes \Gamma(E,M)$. Here $\Omega^1(M)$ is the set of differential 1-from on $M$. Let $\pi:P\rightarrow M$ be our principal $G$-bundle. In principal $G$- bundle setting,  we can think of connection as a set of subspace $H_p\subset T_pP$ which has dim equals to $\dim M$ or equivalently a connection form $\omega\in \Omega^1(M)\otimes \frak{g}$, where $\frak{g}$ is the lie algebra of the $G$. I guess the definition of connection of principal $G$- bundle is more general since every vector bundle is equivalent to a principal $GL_n(\mathbb{F})$ (Here $\mathbb{F}$ can be $\mathbb{R}$ or $\mathbb{C}$). Can someone explain to me that why these two definition are equivalent when $G=GL(n)$? Thank you!","I have encountered two definitions of connection in two different setting namely in vector bundle and principal bundle and I don't see the equivalence in these two setting. In vector bundle setting: Let $M$ be a smooth manifold, $E$ be a vector bundle on it, and $TM$ be the tangent bundle of $M$. Define a connection $\triangledown $ be a function from $\Gamma(TM,M) \times \Gamma(E,M) \rightarrow \Gamma(E,M)$. Here $\Gamma(-,M)$ is a functor from Vector bundle to its set of global section. So we can think of $\triangledown$ as a function from $\Gamma(E,M)$ to $\Omega^1(M)\otimes \Gamma(E,M)$. Here $\Omega^1(M)$ is the set of differential 1-from on $M$. Let $\pi:P\rightarrow M$ be our principal $G$-bundle. In principal $G$- bundle setting,  we can think of connection as a set of subspace $H_p\subset T_pP$ which has dim equals to $\dim M$ or equivalently a connection form $\omega\in \Omega^1(M)\otimes \frak{g}$, where $\frak{g}$ is the lie algebra of the $G$. I guess the definition of connection of principal $G$- bundle is more general since every vector bundle is equivalent to a principal $GL_n(\mathbb{F})$ (Here $\mathbb{F}$ can be $\mathbb{R}$ or $\mathbb{C}$). Can someone explain to me that why these two definition are equivalent when $G=GL(n)$? Thank you!",,"['differential-geometry', 'algebraic-topology', 'riemannian-geometry']"
16,Prove that the unit circle centred at the origin is a submanifold of $R^2$.,Prove that the unit circle centred at the origin is a submanifold of .,R^2,"I am having trouble applying the definition of submanifold. In this question, how do I select an atlas for $R^2$ and then how do I choose an atlas for $S^1$? This is the definition I am using:","I am having trouble applying the definition of submanifold. In this question, how do I select an atlas for $R^2$ and then how do I choose an atlas for $S^1$? This is the definition I am using:",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
17,Why the $\partial_t(\Gamma_{ip}^k \Gamma_{jl}^p -\Gamma_{jp}^k\Gamma_{il}^p)$ vanish?,Why the  vanish?,\partial_t(\Gamma_{ip}^k \Gamma_{jl}^p -\Gamma_{jp}^k\Gamma_{il}^p),"In the red line part of below picture  ,why the $\partial_t(\Gamma_{ip}^k  \Gamma_{jl}^p  -\Gamma_{jp}^k\Gamma_{il}^p)$ vanish ?I know $\Gamma$ will vanish under normal coordinate. But if so, the RHS of red line will equal to $0$. And there is similar question in $\frac{\partial}{\partial t}\Gamma_{jl}^h$ of the third  line above red line . Thanks for any useful hint or answer. And the below picture is from 183th page of the paper","In the red line part of below picture  ,why the $\partial_t(\Gamma_{ip}^k  \Gamma_{jl}^p  -\Gamma_{jp}^k\Gamma_{il}^p)$ vanish ?I know $\Gamma$ will vanish under normal coordinate. But if so, the RHS of red line will equal to $0$. And there is similar question in $\frac{\partial}{\partial t}\Gamma_{jl}^h$ of the third  line above red line . Thanks for any useful hint or answer. And the below picture is from 183th page of the paper",,"['differential-geometry', 'riemannian-geometry', 'ricci-flow']"
18,Proving that the curvature is given by $\kappa = \frac{\|\gamma ' \times \gamma ''\|}{\|\gamma '\|^3}$,Proving that the curvature is given by,\kappa = \frac{\|\gamma ' \times \gamma ''\|}{\|\gamma '\|^3},"Given a space curve $\alpha(s)$, parametrised by arc length (this is $|\alpha'(s)|\equiv 1$), we define its curvature to be: $$\kappa (s)=|\alpha''(s)|$$ Now, I've read that given a curve $\gamma(t)$ not necessarily parametrised by arc length, its curvature is given by the formula: $$\kappa (t)=\frac{|\gamma'(t) \times \gamma''(t)|}{|\gamma(t)|^3}$$ When trying to prove this, I can't get the variables $s$ and $t$ to match up on both sides of the equation, so if someone could pin point and explain my mistake, that would be great. My reasoning is the following: If we think of $\gamma(s)$ as $\gamma(t(s))$, then deriving with respect to $s$ gives, by the chain rule: $$\frac{d}{ds}\gamma(s)=\gamma'(t(s))t'(s)$$ $$\frac{d^2}{ds^2}\gamma(s)=\gamma''(t(s))(t'(s))^2 + \gamma'(t(s))t''(s)$$ It follows that: $$\left (\frac{d}{ds}\gamma(s) \right )\times \left (\frac{d^2}{ds^2}\gamma(s) \right )=[\gamma'(t(s))\times \gamma''(t(s))](t'(s))^3$$ But we also have: $$\left \|  \left (\frac{d}{ds}\gamma(s) \right )\times \left (\frac{d^2}{ds^2}\gamma(s) \right ) \right \|=\left \|  \left (\frac{d}{ds}\gamma(s) \right ) \right \| \left \|\left (\frac{d^2}{ds^2}\gamma(s) \right ) \right \|\sin \left (   \left (\frac{d}{ds}\gamma(s) \right ),\left (\frac{d^2}{ds^2}\gamma(s) \right ) \right )$$ $$=\left \|\frac{d^2}{ds^2}\gamma(s) \right \|=\kappa (s)$$ Putting this all together, and using that $t'(s)=\frac{1}{|\gamma'(t(s))|}$ we get: $$\kappa(s)=\frac{\left \| \gamma'(t(s)) \times \gamma''(t(s))\right \|}{\left \| \gamma '(t(s))\right \|^3}$$ Not $t=t(s) \iff s=s(t)$, hence: $$\kappa(s(t))=\frac{\left \| \gamma'(t) \times \gamma''(t)\right \|}{\left \| \gamma '(t)\right \|^3}$$ The right side of this last equation matches what I wanted to prove, but it should be just $t$ instead of $s(t)$ on the left side. Where did I go wrong? Thanks in advance!","Given a space curve $\alpha(s)$, parametrised by arc length (this is $|\alpha'(s)|\equiv 1$), we define its curvature to be: $$\kappa (s)=|\alpha''(s)|$$ Now, I've read that given a curve $\gamma(t)$ not necessarily parametrised by arc length, its curvature is given by the formula: $$\kappa (t)=\frac{|\gamma'(t) \times \gamma''(t)|}{|\gamma(t)|^3}$$ When trying to prove this, I can't get the variables $s$ and $t$ to match up on both sides of the equation, so if someone could pin point and explain my mistake, that would be great. My reasoning is the following: If we think of $\gamma(s)$ as $\gamma(t(s))$, then deriving with respect to $s$ gives, by the chain rule: $$\frac{d}{ds}\gamma(s)=\gamma'(t(s))t'(s)$$ $$\frac{d^2}{ds^2}\gamma(s)=\gamma''(t(s))(t'(s))^2 + \gamma'(t(s))t''(s)$$ It follows that: $$\left (\frac{d}{ds}\gamma(s) \right )\times \left (\frac{d^2}{ds^2}\gamma(s) \right )=[\gamma'(t(s))\times \gamma''(t(s))](t'(s))^3$$ But we also have: $$\left \|  \left (\frac{d}{ds}\gamma(s) \right )\times \left (\frac{d^2}{ds^2}\gamma(s) \right ) \right \|=\left \|  \left (\frac{d}{ds}\gamma(s) \right ) \right \| \left \|\left (\frac{d^2}{ds^2}\gamma(s) \right ) \right \|\sin \left (   \left (\frac{d}{ds}\gamma(s) \right ),\left (\frac{d^2}{ds^2}\gamma(s) \right ) \right )$$ $$=\left \|\frac{d^2}{ds^2}\gamma(s) \right \|=\kappa (s)$$ Putting this all together, and using that $t'(s)=\frac{1}{|\gamma'(t(s))|}$ we get: $$\kappa(s)=\frac{\left \| \gamma'(t(s)) \times \gamma''(t(s))\right \|}{\left \| \gamma '(t(s))\right \|^3}$$ Not $t=t(s) \iff s=s(t)$, hence: $$\kappa(s(t))=\frac{\left \| \gamma'(t) \times \gamma''(t)\right \|}{\left \| \gamma '(t)\right \|^3}$$ The right side of this last equation matches what I wanted to prove, but it should be just $t$ instead of $s(t)$ on the left side. Where did I go wrong? Thanks in advance!",,"['differential-geometry', 'curves']"
19,"Angle of tangent line and line $y=0,z=x$ is constant",Angle of tangent line and line  is constant,"y=0,z=x","Show that the tangent lines to the regular parameterized curve $\alpha(t)=(3t,2t^2,2t^3)$ make a constant angle with the line $y=0,z=x$. 1) The tangent line at each point is given, I believe, by $\alpha'(t)=(3,4t,6t^2)$ 2) So the angle this makes with $(x,0,x)$ is given I believe by $\frac{\arccos(u\cdot v)}{|u||v|}$? $$\frac{\arccos(3tx+6t^2x)}{\sqrt{(2x^2)(9+16t^2+36t^4)}}$$ Two concerns, should $x$ in my line $y=0,z=x$ be parameterized by $t$? Clearly my dot product is wrong, since it won't give a constant angle?","Show that the tangent lines to the regular parameterized curve $\alpha(t)=(3t,2t^2,2t^3)$ make a constant angle with the line $y=0,z=x$. 1) The tangent line at each point is given, I believe, by $\alpha'(t)=(3,4t,6t^2)$ 2) So the angle this makes with $(x,0,x)$ is given I believe by $\frac{\arccos(u\cdot v)}{|u||v|}$? $$\frac{\arccos(3tx+6t^2x)}{\sqrt{(2x^2)(9+16t^2+36t^4)}}$$ Two concerns, should $x$ in my line $y=0,z=x$ be parameterized by $t$? Clearly my dot product is wrong, since it won't give a constant angle?",,"['differential-geometry', 'angle']"
20,Group Action and Smooth Manifolds,Group Action and Smooth Manifolds,,"I was wondering if it is sufficient for a compact (i.e. Hausdorff) smooth manifold  $M$ to have a free group action of a finite group $G$ in order to conclude that $M/G$ is a compact smooth manifold? This is definitely wrong if $M$ is not compact, but I suspect that it might be true for such manifolds.","I was wondering if it is sufficient for a compact (i.e. Hausdorff) smooth manifold  $M$ to have a free group action of a finite group $G$ in order to conclude that $M/G$ is a compact smooth manifold? This is definitely wrong if $M$ is not compact, but I suspect that it might be true for such manifolds.",,"['real-analysis', 'differential-geometry', 'algebraic-topology', 'manifolds', 'differential-topology']"
21,What is the geometric interpretation of the Koszul formula?,What is the geometric interpretation of the Koszul formula?,,"I saw this simple form of Koszul formula on a book: $$2\ g(\nabla_XY,Z) = \mathcal{L}_Yg(X,Z) + (d\theta_Y)(X,Z)$$ where $\theta_Y$ is the one-form $g(Y,\cdot)$ . It is equivalent to the more commonly seen version since: $$\mathcal{L}_Yg(X,Z) = Yg(X,Z) - g([Y,Z],X)-g(Z, [Y, X])$$ and $$d\theta_Y(X,Z) = Xg(Y,Z) - Zg(X,Y)-g([X,Z],Y)$$ I can follow the proof that Christoffel symbols and this formula are equivalent. But I still don't know how to interpret this. I googled and found that Lie derivative of Riemannian metric is related to strain tensor, is there a geometrical or physical interpretation of this formula?","I saw this simple form of Koszul formula on a book: where is the one-form . It is equivalent to the more commonly seen version since: and I can follow the proof that Christoffel symbols and this formula are equivalent. But I still don't know how to interpret this. I googled and found that Lie derivative of Riemannian metric is related to strain tensor, is there a geometrical or physical interpretation of this formula?","2\ g(\nabla_XY,Z) = \mathcal{L}_Yg(X,Z) + (d\theta_Y)(X,Z) \theta_Y g(Y,\cdot) \mathcal{L}_Yg(X,Z) = Yg(X,Z) - g([Y,Z],X)-g(Z, [Y, X]) d\theta_Y(X,Z) = Xg(Y,Z) - Zg(X,Y)-g([X,Z],Y)","['differential-geometry', 'riemannian-geometry']"
22,Intuitive explanation of the term manifold,Intuitive explanation of the term manifold,,"I am reading Christopher Bishop's ""Pattern Recognition and Machine Learning"" and in the first chapter, where he talks about the curse of dimensionality, he gives the following example: Consider, for example, an application   in manufacturing in which images are captured of identical planar objects on a conveyor   belt, in which the goal is to determine their orientation. Each image is a point in a high-dimensional space whose dimensionality is determined by the number of   pixels. Because the objects can occur at different positions within the image and   in different orientations, there are three degrees of freedom of variability between   images, and a set of images will live on a three dimensional manifold embedded   within the high-dimensional space. Due to the complex relationships between the   object position or orientation and the pixel intensities, this manifold will be highly   nonlinear. If the goal is to learn a model that can take an input image and output the   orientation of the object irrespective of its position, then there is only one degree of   freedom of variability within the manifold that is significant. I haven't took a course on differential geometry before; but I have some informal ideas on what manifolds are. I thought them as low dimensional continuous (not in a rigorous way) subsets of high dimensional Euclidean Spaces. For example, a curved surface of a blanket can be considered as a manifold in the space of a room. Well, that explanation does not work when it comes to a more rigorous text like in the above. How should I understand the term ""manifold"" in the context of the above paragraph? I see that there is a high dimensional space, with the dimension equal to the number of pixels in the given images. But the definition of the three dimensional manifold is not exactly a three dimensional (""three pixel"" sized images) subset of the image pixels exactly. It sounds like that a transformation function is applied to each point (image) in this high dimensional space and each high dimensional point is mapped to a three dimensional point in some three dimensional space. (Consisting of x,y coordinates and an orientation angle). But I don't see how this is related with a manifold. So, how should I understand the term ""manifold"" in such a context, in an informal and intuitive way? Is this something completely different from my sloppy understanding of the term?","I am reading Christopher Bishop's ""Pattern Recognition and Machine Learning"" and in the first chapter, where he talks about the curse of dimensionality, he gives the following example: Consider, for example, an application   in manufacturing in which images are captured of identical planar objects on a conveyor   belt, in which the goal is to determine their orientation. Each image is a point in a high-dimensional space whose dimensionality is determined by the number of   pixels. Because the objects can occur at different positions within the image and   in different orientations, there are three degrees of freedom of variability between   images, and a set of images will live on a three dimensional manifold embedded   within the high-dimensional space. Due to the complex relationships between the   object position or orientation and the pixel intensities, this manifold will be highly   nonlinear. If the goal is to learn a model that can take an input image and output the   orientation of the object irrespective of its position, then there is only one degree of   freedom of variability within the manifold that is significant. I haven't took a course on differential geometry before; but I have some informal ideas on what manifolds are. I thought them as low dimensional continuous (not in a rigorous way) subsets of high dimensional Euclidean Spaces. For example, a curved surface of a blanket can be considered as a manifold in the space of a room. Well, that explanation does not work when it comes to a more rigorous text like in the above. How should I understand the term ""manifold"" in the context of the above paragraph? I see that there is a high dimensional space, with the dimension equal to the number of pixels in the given images. But the definition of the three dimensional manifold is not exactly a three dimensional (""three pixel"" sized images) subset of the image pixels exactly. It sounds like that a transformation function is applied to each point (image) in this high dimensional space and each high dimensional point is mapped to a three dimensional point in some three dimensional space. (Consisting of x,y coordinates and an orientation angle). But I don't see how this is related with a manifold. So, how should I understand the term ""manifold"" in such a context, in an informal and intuitive way? Is this something completely different from my sloppy understanding of the term?",,"['calculus', 'differential-geometry', 'machine-learning']"
23,"Principal bundles, connection forms and fundamental vector fields","Principal bundles, connection forms and fundamental vector fields",,"Suppose $\pi:P\rightarrow M$ is a principal bundle, $\omega\in \Omega^1(P;\mathfrak{g})$ is the connection one form and $\sigma(\cdot)$ is the fundamental vector field associated to some vector field in $\mathfrak{g}$. That is, for $X\in \mathfrak{g}$, the value of $\sigma(X)$ at $p\in P$ is given by $ \begin{align*} \sigma(X)_p=\frac{d}{dt}\bigg|_{t=0}p\exp(tX). \end{align*}$ I am reading through some lecture notes at the moment and the author decomposes a vector field $u\in \mathfrak{X}(P)$ in to its horizontal and vertical components. So $u=u_v + u_h$. The author then takes the derivative $u_v f$ of some function $f$ defined on $P$. They make the argument that since this derivative at a point $p\in P$ depends only on the vector $u_v$ at $p$, they may assume $u_v = \sigma(\omega(u))$. I understand the idea of the derivative only depending on the vector at $p$. However, I am stuck on how they can assume that $u_v=\sigma(\omega(u))$. I don't understand how $u_v$ at $p$ is equal to $\sigma(\omega(u))$ at $p$. If anyone could help that would be greatly appreciated. Thanks! EDIT: Thanks very much for your detailed response. I have a few questions 1) Why have you written that map as $\rho_p$ instead of $L_p$? Isn't it just left multiplication? On that note, is it kosher to define left multiplication on $P$? 2)Is the reason $\sigma(X)_p=(\rho_p)_{*,e}X$ because $X=\frac{d}{dt}\big|_{t=0}\exp(tX)$, so $(\rho_p)_{*,e}X=(\rho_p)_{*,e}\frac{d}{dt}\big|_{t=0}\exp(tX)=\frac{d}{dt}\big|_{t=0}p\exp(tX)=\sigma(X)_p$?? 3) Why does $R_g$ and $\delta_g$ being diffeomorphisms imply  $\rho_p$ has constant rank? Why did you go to the effort of adding $g$ and $g^{-1}$? 4) Why does dim$V_p$=dim$\mathfrak{g}$ imply the map is surjective? I'm thinking that's just something from linear algebra I'm forgetting? Thank you again!","Suppose $\pi:P\rightarrow M$ is a principal bundle, $\omega\in \Omega^1(P;\mathfrak{g})$ is the connection one form and $\sigma(\cdot)$ is the fundamental vector field associated to some vector field in $\mathfrak{g}$. That is, for $X\in \mathfrak{g}$, the value of $\sigma(X)$ at $p\in P$ is given by $ \begin{align*} \sigma(X)_p=\frac{d}{dt}\bigg|_{t=0}p\exp(tX). \end{align*}$ I am reading through some lecture notes at the moment and the author decomposes a vector field $u\in \mathfrak{X}(P)$ in to its horizontal and vertical components. So $u=u_v + u_h$. The author then takes the derivative $u_v f$ of some function $f$ defined on $P$. They make the argument that since this derivative at a point $p\in P$ depends only on the vector $u_v$ at $p$, they may assume $u_v = \sigma(\omega(u))$. I understand the idea of the derivative only depending on the vector at $p$. However, I am stuck on how they can assume that $u_v=\sigma(\omega(u))$. I don't understand how $u_v$ at $p$ is equal to $\sigma(\omega(u))$ at $p$. If anyone could help that would be greatly appreciated. Thanks! EDIT: Thanks very much for your detailed response. I have a few questions 1) Why have you written that map as $\rho_p$ instead of $L_p$? Isn't it just left multiplication? On that note, is it kosher to define left multiplication on $P$? 2)Is the reason $\sigma(X)_p=(\rho_p)_{*,e}X$ because $X=\frac{d}{dt}\big|_{t=0}\exp(tX)$, so $(\rho_p)_{*,e}X=(\rho_p)_{*,e}\frac{d}{dt}\big|_{t=0}\exp(tX)=\frac{d}{dt}\big|_{t=0}p\exp(tX)=\sigma(X)_p$?? 3) Why does $R_g$ and $\delta_g$ being diffeomorphisms imply  $\rho_p$ has constant rank? Why did you go to the effort of adding $g$ and $g^{-1}$? 4) Why does dim$V_p$=dim$\mathfrak{g}$ imply the map is surjective? I'm thinking that's just something from linear algebra I'm forgetting? Thank you again!",,"['differential-geometry', 'manifolds', 'lie-groups', 'lie-algebras', 'principal-bundles']"
24,$F$-related vector fields [duplicate],-related vector fields [duplicate],F,"This question already has an answer here : Find $F$-related vector fields on $M\times N$, where $F(x)=(x, f(x))$ (1 answer) Closed 3 years ago . I'm having a bit of difficulty understanding $F$-related vector fields. I think I understand conceptually what's going on (taking a vector field on a manifold $M$ and getting a smooth vector field on $N$ by applying the differential of a map), but I'm having trouble applying the concept. For example, here's a problem (8.14 in Lee's Smooth Manifolds textbook)  Let $M,N$ be smooth manifolds with or without boundary and let $f:M\to N$ be a smooth map. Define $F:M\to M\times N$ by $F(x)=(x,f(x))$. Show that for each vector field $X$ on $M$, there is a smooth vector field $Y$ on $M\times N$ which is $F$ related to $X$. Now, I see that $F$ is the graph of $f$, and so $F(M)$ is closed in $M\times N$, and there's a proposition in Lee which says that if we have a smooth vector field on a closed subset, we can extend it to a smooth vector field on the whole manifold. However, I'm really not sure where to go. I see that $F(M)\subset M\times N$ is an embedded manifold, so we have slice charts, but I'm struggling to see how to construct this $Y$.","This question already has an answer here : Find $F$-related vector fields on $M\times N$, where $F(x)=(x, f(x))$ (1 answer) Closed 3 years ago . I'm having a bit of difficulty understanding $F$-related vector fields. I think I understand conceptually what's going on (taking a vector field on a manifold $M$ and getting a smooth vector field on $N$ by applying the differential of a map), but I'm having trouble applying the concept. For example, here's a problem (8.14 in Lee's Smooth Manifolds textbook)  Let $M,N$ be smooth manifolds with or without boundary and let $f:M\to N$ be a smooth map. Define $F:M\to M\times N$ by $F(x)=(x,f(x))$. Show that for each vector field $X$ on $M$, there is a smooth vector field $Y$ on $M\times N$ which is $F$ related to $X$. Now, I see that $F$ is the graph of $f$, and so $F(M)$ is closed in $M\times N$, and there's a proposition in Lee which says that if we have a smooth vector field on a closed subset, we can extend it to a smooth vector field on the whole manifold. However, I'm really not sure where to go. I see that $F(M)\subset M\times N$ is an embedded manifold, so we have slice charts, but I'm struggling to see how to construct this $Y$.",,"['differential-geometry', 'manifolds', 'vector-bundles']"
25,chern class of complex line bundle,chern class of complex line bundle,,"Let $\xi:=(\mathbb{C},E,p,B)$ be a complex line bundle, where $B$ is a manifold or CW-complex. How to determine whether the first Chern class $c_1(\xi)=0$ or non-vanishing?","Let $\xi:=(\mathbb{C},E,p,B)$ be a complex line bundle, where $B$ is a manifold or CW-complex. How to determine whether the first Chern class $c_1(\xi)=0$ or non-vanishing?",,"['algebraic-geometry', 'differential-geometry', 'algebraic-topology', 'differential-topology', 'characteristic-classes']"
26,Help finding a good book on Finsler geometry,Help finding a good book on Finsler geometry,,"I want to learn more about Finsler geometry. I have just studying the book ""An Introduction to Riemann-Finsler Geometry"" by Bao, Chern and Shen, but i would like to study Finsler Geometry approach to fiber bundles, specifically sphere bundle. I have been reading the book ""initiation to global finslerian geometry"" by Akbar-Zadeh, But I find that it is hard for me to underestand it. Is there any references with the same topics which can help me in better underestanding? Thank you much for your time.","I want to learn more about Finsler geometry. I have just studying the book ""An Introduction to Riemann-Finsler Geometry"" by Bao, Chern and Shen, but i would like to study Finsler Geometry approach to fiber bundles, specifically sphere bundle. I have been reading the book ""initiation to global finslerian geometry"" by Akbar-Zadeh, But I find that it is hard for me to underestand it. Is there any references with the same topics which can help me in better underestanding? Thank you much for your time.",,"['reference-request', 'differential-geometry']"
27,Is it possible to build a tensor with the following properties?,Is it possible to build a tensor with the following properties?,,"I am searching for a tensor in 4-dimensional space-time with two indices that satisfy: \begin{eqnarray} M_{;\mu }^{\mu \nu } &=&0, \\ M^{\mu \nu } + M^{\nu\mu}&=&0,  \nonumber \\ M_{;\varepsilon }^{\mu \nu }+M_{;\nu }^{\varepsilon \mu }+M_{;\mu }^{\nu \varepsilon } &=&0.  \nonumber \end{eqnarray} An obvious choice would be the electromagnetic field strength, but I am investigating if it is possible to build a tensor with such properties that only depends on geometrical properties of the space-time manifold (metric tensor, connection). For instance, the Riemann tensor satisfies two of these properties for fixed α, β: \begin{eqnarray} R_{;\varepsilon }^{\alpha \beta \mu \nu }+R_{;\nu }^{\alpha \beta \varepsilon \mu }+R_{;\mu }^{\alpha \beta \nu \varepsilon } &=&0\text{ } \\ R^{\alpha \beta \mu \nu } &=&-R^{\alpha \beta \mu \nu }  \nonumber \end{eqnarray} But I found its divergence is zero only in very special cases, such as for maximally symmetric spaces. Is there anyway to build a tensor with these properties always, or at least in not so special cases?","I am searching for a tensor in 4-dimensional space-time with two indices that satisfy: An obvious choice would be the electromagnetic field strength, but I am investigating if it is possible to build a tensor with such properties that only depends on geometrical properties of the space-time manifold (metric tensor, connection). For instance, the Riemann tensor satisfies two of these properties for fixed α, β: But I found its divergence is zero only in very special cases, such as for maximally symmetric spaces. Is there anyway to build a tensor with these properties always, or at least in not so special cases?","\begin{eqnarray}
M_{;\mu }^{\mu \nu } &=&0, \\
M^{\mu \nu } + M^{\nu\mu}&=&0,  \nonumber \\
M_{;\varepsilon }^{\mu \nu }+M_{;\nu }^{\varepsilon \mu }+M_{;\mu }^{\nu
\varepsilon } &=&0.  \nonumber
\end{eqnarray} \begin{eqnarray}
R_{;\varepsilon }^{\alpha \beta \mu \nu }+R_{;\nu }^{\alpha \beta
\varepsilon \mu }+R_{;\mu }^{\alpha \beta \nu \varepsilon } &=&0\text{ } \\
R^{\alpha \beta \mu \nu } &=&-R^{\alpha \beta \mu \nu }  \nonumber
\end{eqnarray}","['differential-geometry', 'tensors', 'general-relativity']"
28,Find the area of parallel surface,Find the area of parallel surface,,"Q: Consider a surface $M$ with regular parametrization $X:U_{open}\subset \mathbb{R}^2 \rightarrow \mathbb{R}^3$ and define the parallel surface $M_t$ by $$Y(u,v)=X(u,v) + tN(u,v)$$ where $N(u,v)$ is the unit normal on $X$ at point $(u,v)$ and $t$ is a constant. And Show that $$\text{Area}(M_t)=\text{Area}(M)-2t \int_ M H \text{ d}A+t^2\int_M K\text{ d}A$$ where $H$ and $K$ are the mean curvature and Gaussian curvature, respectively. First, I want to find out what $Y_u \times Y_v$ equals to so that I can apply $$\text{Area}(M_t)=\int_{M_t}\| Y_u \times Y_v\| \text{ d}u\text{d}v$$ $Y_u=X_u+tN_u=X_u(1-tk_1)$ $Y_v=X_v+tN_v=X_v(1-tk_2)$ where $k_1$ and $k_2$ are the principal curvature of $X$ Therefore, $$Y_u \times Y_v=(1-2tH+t^2K)X_u \times X_v$$ And, \begin{equation} \begin{split} \text{Area}(M_t) & =\int_{M}\| (1-2tH+t^2K)X_u \times X_v\| \text{ d}u\text{d}v \\  & = \int_{M} (1-2tH+t^2K)\|X_u \times X_v\| \text{ d}u\text{d}v \\  & = \text{Area}(M) -2t \int_{M}H \| X_u \times X_v \|\text{ d}u\text{d}v + t^2\int_{M}K \|X_u \times X_v \| \text{ d}u\text{d}v \end{split} \end{equation} I don't know how to simplify this to $$ \text{Area}(M_t)  =  \text{Area}(M) -2t \int_{M}H \text{ d}A + t^2\int_{M}K \text{ d}A$$","Q: Consider a surface $M$ with regular parametrization $X:U_{open}\subset \mathbb{R}^2 \rightarrow \mathbb{R}^3$ and define the parallel surface $M_t$ by $$Y(u,v)=X(u,v) + tN(u,v)$$ where $N(u,v)$ is the unit normal on $X$ at point $(u,v)$ and $t$ is a constant. And Show that $$\text{Area}(M_t)=\text{Area}(M)-2t \int_ M H \text{ d}A+t^2\int_M K\text{ d}A$$ where $H$ and $K$ are the mean curvature and Gaussian curvature, respectively. First, I want to find out what $Y_u \times Y_v$ equals to so that I can apply $$\text{Area}(M_t)=\int_{M_t}\| Y_u \times Y_v\| \text{ d}u\text{d}v$$ $Y_u=X_u+tN_u=X_u(1-tk_1)$ $Y_v=X_v+tN_v=X_v(1-tk_2)$ where $k_1$ and $k_2$ are the principal curvature of $X$ Therefore, $$Y_u \times Y_v=(1-2tH+t^2K)X_u \times X_v$$ And, \begin{equation} \begin{split} \text{Area}(M_t) & =\int_{M}\| (1-2tH+t^2K)X_u \times X_v\| \text{ d}u\text{d}v \\  & = \int_{M} (1-2tH+t^2K)\|X_u \times X_v\| \text{ d}u\text{d}v \\  & = \text{Area}(M) -2t \int_{M}H \| X_u \times X_v \|\text{ d}u\text{d}v + t^2\int_{M}K \|X_u \times X_v \| \text{ d}u\text{d}v \end{split} \end{equation} I don't know how to simplify this to $$ \text{Area}(M_t)  =  \text{Area}(M) -2t \int_{M}H \text{ d}A + t^2\int_{M}K \text{ d}A$$",,['differential-geometry']
29,Exercise about tangent space,Exercise about tangent space,,"I have just started of learning about Manifolds from Milnor's book.I am stuck on following exercise,give me some idea. Let $U$ be an open subset of a manifold $X$. Show that for any $x \in U$ the tangent space at $x$ to $U$, i.e., $T_x(U)$ is same as $T_xX$.","I have just started of learning about Manifolds from Milnor's book.I am stuck on following exercise,give me some idea. Let $U$ be an open subset of a manifold $X$. Show that for any $x \in U$ the tangent space at $x$ to $U$, i.e., $T_x(U)$ is same as $T_xX$.",,['differential-geometry']
30,Prove that the tangent space of a Lie group at the identity is isomorphic to the space of left-invariant vector fields,Prove that the tangent space of a Lie group at the identity is isomorphic to the space of left-invariant vector fields,,"I want to prove that the tangent space of a Lie group at its identity $e$ is isomorphic to the vector space of left-invariant vector fields. Given an element $D \in T_e G$ (a derivation), the corresponding left-invariant vector field is $$X : G \rightarrow TG, \; X(g) := L_g^*(D),$$ where $L_g$ is left-multiplication by $D$ . To verify that this is smooth, I take an open subset $U \subseteq G$ and a smooth function $f : U \rightarrow \mathbb{R};$ then I need to see that $Xf$ is smooth, where $$Xf : U \rightarrow \mathbb{R}, \; \; Xf(g) := X_g(f) = (L_g^*)(D)(f) = D(f \circ L_g).$$ I do not know how to show that $Xf$ is smooth.","I want to prove that the tangent space of a Lie group at its identity is isomorphic to the vector space of left-invariant vector fields. Given an element (a derivation), the corresponding left-invariant vector field is where is left-multiplication by . To verify that this is smooth, I take an open subset and a smooth function then I need to see that is smooth, where I do not know how to show that is smooth.","e D \in T_e G X : G \rightarrow TG, \; X(g) := L_g^*(D), L_g D U \subseteq G f : U \rightarrow \mathbb{R}; Xf Xf : U \rightarrow \mathbb{R}, \; \; Xf(g) := X_g(f) = (L_g^*)(D)(f) = D(f \circ L_g). Xf","['differential-geometry', 'lie-groups', 'lie-algebras', 'vector-fields']"
31,Is $\mathbb R^n$ added by one point diffeomorphic to $S^n$?,Is  added by one point diffeomorphic to ?,\mathbb R^n S^n,"Let $M$ be a closed smooth manifold. If for some point $p$ on $M$ we can find a diffeomorphism between $M-\{p\}$ and $\mathbb R^n$, then is $M$ diffeomorphic to $S^n$(with the standard differential structure)?","Let $M$ be a closed smooth manifold. If for some point $p$ on $M$ we can find a diffeomorphism between $M-\{p\}$ and $\mathbb R^n$, then is $M$ diffeomorphic to $S^n$(with the standard differential structure)?",,['differential-geometry']
32,Identities for differential forms and vectorfields (reference request),Identities for differential forms and vectorfields (reference request),,"Recently I found the slides of a talk of J. E. Marsden, ( Differential Forms and Stokes' Theorem ). These slides introduce the required objects and summarize the basics of the corresponding theory. In the last part some very useful formulas (identities) are given, which establish the relation between objects (vector fields and differential forms) and operators (Lie derivatives, Lie brackets, exterior derivative, wedge product, innterior product (= contraction)). E.g. two of them are: $$\iota_{[X,Y]} \alpha = \mathcal{L}_X \iota_Y \alpha - \iota_Y \mathcal{L}_X \alpha \qquad (1)$$ $$\mathcal{L}_{[X,Y]} \alpha = \mathcal{L}_X \mathcal{L}_Y \alpha - \mathcal{L}_Y \mathcal{L}_X \alpha \qquad (2)$$ for vector fields $X,Y$, a $k$-form $\alpha$ and $\mathcal{L}, \iota$ denoting the Lie-derivative and the interior product, respectively. Probably, such formulas can be derived self-sufficiently from basic properties of the related objects. Q1: Must this be done by choosing coordinates or is it always possible to argument without coordinates (like in the proof of Cartans ""magic formula"")? On the other hand it would be nice to know a reference where these (and other) identities are published (including their proofs). Q2: Where to look for the derivation of such identities?","Recently I found the slides of a talk of J. E. Marsden, ( Differential Forms and Stokes' Theorem ). These slides introduce the required objects and summarize the basics of the corresponding theory. In the last part some very useful formulas (identities) are given, which establish the relation between objects (vector fields and differential forms) and operators (Lie derivatives, Lie brackets, exterior derivative, wedge product, innterior product (= contraction)). E.g. two of them are: $$\iota_{[X,Y]} \alpha = \mathcal{L}_X \iota_Y \alpha - \iota_Y \mathcal{L}_X \alpha \qquad (1)$$ $$\mathcal{L}_{[X,Y]} \alpha = \mathcal{L}_X \mathcal{L}_Y \alpha - \mathcal{L}_Y \mathcal{L}_X \alpha \qquad (2)$$ for vector fields $X,Y$, a $k$-form $\alpha$ and $\mathcal{L}, \iota$ denoting the Lie-derivative and the interior product, respectively. Probably, such formulas can be derived self-sufficiently from basic properties of the related objects. Q1: Must this be done by choosing coordinates or is it always possible to argument without coordinates (like in the proof of Cartans ""magic formula"")? On the other hand it would be nice to know a reference where these (and other) identities are published (including their proofs). Q2: Where to look for the derivation of such identities?",,"['reference-request', 'differential-geometry', 'differential-forms', 'exterior-algebra']"
33,Metric Tensors and its Taylor Expansion in Normal Coordinates,Metric Tensors and its Taylor Expansion in Normal Coordinates,,"With metric tensors of the unit sphere in normal coordinates, their Taylor series for $p\in S$ near the north pole $N$ can be written as follows. $$g_{rr}(p) \equiv 1; g_{r\theta}(p) = g_{\theta r}(p) \equiv 0; g_{\theta\theta}(p) = r^2.$$ However, the third expansion does not check out with the following general expression $$g_{ij} = \delta_{ij} - \frac{1}{3} \sum_{k, l} R_{ikjl}(0) u^k u^l + O(|u|^3). $$ $$ g_{22} = g_{\theta\theta} = 1 + \frac{1}{3} (\sin^2r)r^2 + O(|u|^3) $$ Where did I make mistake, please? Thank you!","With metric tensors of the unit sphere in normal coordinates, their Taylor series for $p\in S$ near the north pole $N$ can be written as follows. $$g_{rr}(p) \equiv 1; g_{r\theta}(p) = g_{\theta r}(p) \equiv 0; g_{\theta\theta}(p) = r^2.$$ However, the third expansion does not check out with the following general expression $$g_{ij} = \delta_{ij} - \frac{1}{3} \sum_{k, l} R_{ikjl}(0) u^k u^l + O(|u|^3). $$ $$ g_{22} = g_{\theta\theta} = 1 + \frac{1}{3} (\sin^2r)r^2 + O(|u|^3) $$ Where did I make mistake, please? Thank you!",,"['differential-geometry', 'differential-topology', 'riemann-surfaces', 'surfaces']"
34,"surface area of a Torus using differential forms,","surface area of a Torus using differential forms,",,"Im studing integration over manifolds. I want to compute the surface area of the torus. Im given the usual parametrization $f(u,v)= ((a+b\cos(v))\cos(u), (a+b\cos(v))\sin(u), b\sin(v))$ for $0\leq u,v \leq 2\pi$. I know that the area can be computed as $\int_T \omega$ where $T$ denotes the torus and $\omega$ denotes the volume form of the manifold. I was able to compute the volume form of the 3-dimensional manifold ""the solid torus"". But I dont get how to compute the volume form of the boundary of this manifold (which is $T$). I appreciate any idea.","Im studing integration over manifolds. I want to compute the surface area of the torus. Im given the usual parametrization $f(u,v)= ((a+b\cos(v))\cos(u), (a+b\cos(v))\sin(u), b\sin(v))$ for $0\leq u,v \leq 2\pi$. I know that the area can be computed as $\int_T \omega$ where $T$ denotes the torus and $\omega$ denotes the volume form of the manifold. I was able to compute the volume form of the 3-dimensional manifold ""the solid torus"". But I dont get how to compute the volume form of the boundary of this manifold (which is $T$). I appreciate any idea.",,"['differential-geometry', 'manifolds', 'differential-forms']"
35,Singular Vector Fields as Basis Elements in Contact Planes.,Singular Vector Fields as Basis Elements in Contact Planes.,,"I'm trying to generate specific examples of contact structures in $\mathbb R^3$, but I'm running into something strange. It seems like the contact planes associated to the structure (using cylindrical coordinates in $\mathbb R^3$) EDIT/CORRECTION: My apologies to all who read this for wasting your time; the actual contact structure is, in cylindrical coordinates $( r, \theta, z)$: $$Ker[\cos( \pi r)dz+ \sin(\pi r) d \theta], $$ ( the correction: original was: $Ker (cos(\pi r) dr + sin (\pi r) d\theta).$  To be more rigorous this time, will compute $ w \wedge dw$: we have $dw=-\pi sin (\pi r)dzdr+\pi cos(\pi r)d\theta dr$. We see in expanding $w \wedge dw$ that we have two coefficients for $d\theta dz dr$ which do not cancel each other out; we actually get $\pi dzd\theta dr \neq 0$.) Still, the issue remains after the correction: Set $$(\cos( \pi r)dz+ \sin(\pi r) d \theta )(a_z \partial z+a_{\theta} \partial \theta ):=0.$$ (I got rid of the $\pi$ ) Then we get $a_z  cos( \pi r)+ a_{\theta} sin (\pi r)=0$. How do we avoid dividing here when we find a basis? We can choose, e.g., $a_{\theta}=1$ , then we have $a_z cos (\pi r)+sin(\pi r)=0 $ . And, now, solving for $a_z$ , we still have to divide , to get $a_z =-tan (\pi r )$, and a basis {$(\partial r,0,0),(0,\partial \theta, -tan(\pi r) \partial z)$} And we still have singularities whenever $\pi r= \pi/2+k \pi$ ; $k $ in $\mathbb Z$ , i.e., whenever $r=1/2+k$ How do we deal with this?","I'm trying to generate specific examples of contact structures in $\mathbb R^3$, but I'm running into something strange. It seems like the contact planes associated to the structure (using cylindrical coordinates in $\mathbb R^3$) EDIT/CORRECTION: My apologies to all who read this for wasting your time; the actual contact structure is, in cylindrical coordinates $( r, \theta, z)$: $$Ker[\cos( \pi r)dz+ \sin(\pi r) d \theta], $$ ( the correction: original was: $Ker (cos(\pi r) dr + sin (\pi r) d\theta).$  To be more rigorous this time, will compute $ w \wedge dw$: we have $dw=-\pi sin (\pi r)dzdr+\pi cos(\pi r)d\theta dr$. We see in expanding $w \wedge dw$ that we have two coefficients for $d\theta dz dr$ which do not cancel each other out; we actually get $\pi dzd\theta dr \neq 0$.) Still, the issue remains after the correction: Set $$(\cos( \pi r)dz+ \sin(\pi r) d \theta )(a_z \partial z+a_{\theta} \partial \theta ):=0.$$ (I got rid of the $\pi$ ) Then we get $a_z  cos( \pi r)+ a_{\theta} sin (\pi r)=0$. How do we avoid dividing here when we find a basis? We can choose, e.g., $a_{\theta}=1$ , then we have $a_z cos (\pi r)+sin(\pi r)=0 $ . And, now, solving for $a_z$ , we still have to divide , to get $a_z =-tan (\pi r )$, and a basis {$(\partial r,0,0),(0,\partial \theta, -tan(\pi r) \partial z)$} And we still have singularities whenever $\pi r= \pi/2+k \pi$ ; $k $ in $\mathbb Z$ , i.e., whenever $r=1/2+k$ How do we deal with this?",,"['differential-geometry', 'contact-topology']"
36,Literature on Chern-Weil Theory and the Chern-Gauß-Bonnet Theorem,Literature on Chern-Weil Theory and the Chern-Gauß-Bonnet Theorem,,"At my university there are plans for a graduate seminar on Chern-Weil Theory and Chern's generalisation of the Gauß-Bonnet Theorem. Unfortunately I am having a though time in finding adequate and modern literature on this subject. Classically I know of Milnor's Appendix C in Milnor, Stasheff: ""Characteristic Classes"" and the famous text from Spivak's A Comprehensive Introduction to Differential Geometry entitled ""The Generalized Gauß-Bonnet Theorem and What It Means To Mankind"". Is there any more recent recommendable source? During my search I also came along Zhang: Lectures on Chern-Weil Theory and Witten Deformations . Does anyone have practical experience with this book? Thanks in advance!","At my university there are plans for a graduate seminar on Chern-Weil Theory and Chern's generalisation of the Gauß-Bonnet Theorem. Unfortunately I am having a though time in finding adequate and modern literature on this subject. Classically I know of Milnor's Appendix C in Milnor, Stasheff: ""Characteristic Classes"" and the famous text from Spivak's A Comprehensive Introduction to Differential Geometry entitled ""The Generalized Gauß-Bonnet Theorem and What It Means To Mankind"". Is there any more recent recommendable source? During my search I also came along Zhang: Lectures on Chern-Weil Theory and Witten Deformations . Does anyone have practical experience with this book? Thanks in advance!",,"['differential-geometry', 'soft-question', 'advice']"
37,Immersions of the Klein Bottle,Immersions of the Klein Bottle,,"The famous immersion of the Klein bottle lacks symmetry. (I'm talking about this one. http://en.wikipedia.org/wiki/File:Klein_bottle.svg ) One can only see one plane of reflection. However, the ""square with sides identified"" has (well, I think) in my opinion at least two non-trivial symmetries ; one which is reflection along a vertical line passing through the center of the square, and one is rotation of half a turn centered in the center of the square. My question : is there an immersion of the Klein Bottle which makes the symmetry group of the immersion visible as a subgroup of the group of rotations/reflections of Euclidean 3-space? Attempts : I simply tried to look at the known immersions of the Klein bottle in Euclidean 3-space, but looking at the Klein bagel ( http://kleinbagel.com/ ) or the classical bottle wasn't very enlightening. This seems like an interesting question but I don't know much about the bottle itself.","The famous immersion of the Klein bottle lacks symmetry. (I'm talking about this one. http://en.wikipedia.org/wiki/File:Klein_bottle.svg ) One can only see one plane of reflection. However, the ""square with sides identified"" has (well, I think) in my opinion at least two non-trivial symmetries ; one which is reflection along a vertical line passing through the center of the square, and one is rotation of half a turn centered in the center of the square. My question : is there an immersion of the Klein Bottle which makes the symmetry group of the immersion visible as a subgroup of the group of rotations/reflections of Euclidean 3-space? Attempts : I simply tried to look at the known immersions of the Klein bottle in Euclidean 3-space, but looking at the Klein bagel ( http://kleinbagel.com/ ) or the classical bottle wasn't very enlightening. This seems like an interesting question but I don't know much about the bottle itself.",,"['differential-geometry', 'symmetry', 'klein-bottle']"
38,Why is the restricted holonomy the identity component of the holonomy group?,Why is the restricted holonomy the identity component of the holonomy group?,,"Let $M$ be a connected smooth paracompact manifold, $E$ a vector bundle over $M$ with fibre $\mathbb R^k$, and $\nabla$ a connection on $E$. It is known that Hol$^0(\nabla)$ is a connected Lie subgroup of $GL(k,\mathbb R)$. How can we show Hol$^0(\nabla)$ is an identity component of Hol$(\nabla)$? It seems to me that there are two ways to understand this. The first way is to regard Hol$^0(\nabla)$ and Hol$(\nabla)$ as topological subspaces of $GL(k,\mathbb R)$. Another way is to make Hol$(\nabla)$ a Lie subgroup of $GL(k,\mathbb R)$ by left translating the differential structure of Hol$^0(\nabla)$. But to prove Hol$(\nabla)$ is a Lie group, one has to prove for any $a\in$ Hol$(\nabla)$, the mapping from Hol$^0(\nabla)$ to Hol$^0(\nabla)$ defined by $x \rightarrow axa^{-1}$ is differentiable. I am stuck here.","Let $M$ be a connected smooth paracompact manifold, $E$ a vector bundle over $M$ with fibre $\mathbb R^k$, and $\nabla$ a connection on $E$. It is known that Hol$^0(\nabla)$ is a connected Lie subgroup of $GL(k,\mathbb R)$. How can we show Hol$^0(\nabla)$ is an identity component of Hol$(\nabla)$? It seems to me that there are two ways to understand this. The first way is to regard Hol$^0(\nabla)$ and Hol$(\nabla)$ as topological subspaces of $GL(k,\mathbb R)$. Another way is to make Hol$(\nabla)$ a Lie subgroup of $GL(k,\mathbb R)$ by left translating the differential structure of Hol$^0(\nabla)$. But to prove Hol$(\nabla)$ is a Lie group, one has to prove for any $a\in$ Hol$(\nabla)$, the mapping from Hol$^0(\nabla)$ to Hol$^0(\nabla)$ defined by $x \rightarrow axa^{-1}$ is differentiable. I am stuck here.",,"['differential-geometry', 'vector-bundles', 'holonomy']"
39,"Zariski cotangent space, as defined in Arapura's ""Algebraic Geometry over the Complex Numbers""","Zariski cotangent space, as defined in Arapura's ""Algebraic Geometry over the Complex Numbers""",,"In ""Algebraic Geometry over the Complex Numbers"", Arapura gives the following definition: Definition 2.5.8. When $(R, m, k)$ is a local ring satisfying the tangent space conditions, we define its cotangent space as $T_R^* = m/m^2 = m \otimes_R k$, [...] To give an example, he restricts to $\mathbb{R}^n$. Then $R$ is the ring of germs of $C^\infty$ functions at $x=0$ and the maximal ideal $m$ consists of those germs that vanish at $0$; it is generated by the coordinate functions $\{ x_i \}$. $k = R/m = \mathbb{R}$. Given a function $f$ with Taylor expansion $f(x) = f(0) + \sum \frac{\partial f}{\partial x_i}\vert_0 x_i + \mathcal{O}(x^2)$, the second term corresponds to the elements of $m/m^2$. What I do not understand is how that space is supposed to be isomorphic to the tensor product $m \otimes_R k$.Naively, $m$ includes the ""second order behavior"" that was discarded in the quotient, I don't see how tensoring with $k$ improves that.","In ""Algebraic Geometry over the Complex Numbers"", Arapura gives the following definition: Definition 2.5.8. When $(R, m, k)$ is a local ring satisfying the tangent space conditions, we define its cotangent space as $T_R^* = m/m^2 = m \otimes_R k$, [...] To give an example, he restricts to $\mathbb{R}^n$. Then $R$ is the ring of germs of $C^\infty$ functions at $x=0$ and the maximal ideal $m$ consists of those germs that vanish at $0$; it is generated by the coordinate functions $\{ x_i \}$. $k = R/m = \mathbb{R}$. Given a function $f$ with Taylor expansion $f(x) = f(0) + \sum \frac{\partial f}{\partial x_i}\vert_0 x_i + \mathcal{O}(x^2)$, the second term corresponds to the elements of $m/m^2$. What I do not understand is how that space is supposed to be isomorphic to the tensor product $m \otimes_R k$.Naively, $m$ includes the ""second order behavior"" that was discarded in the quotient, I don't see how tensoring with $k$ improves that.",,"['algebraic-geometry', 'differential-geometry', 'definition']"
40,Bianchi identity of linear connection on vector bundle,Bianchi identity of linear connection on vector bundle,,"Consider a connection on $E$ which is a vector bundle over $M$ : $$ \nabla : \Gamma(E) \rightarrow \Omega^1(M)\otimes \Gamma(E),\ s\mapsto \nabla\ s$$ Here $\nabla s =dx^k\otimes \nabla_{\partial_k} s$ where $x^k$ is coordinate function on $M$ Consider $C^\infty(M)$-linear map $d^\nabla$ : $$  d^\nabla (\omega\otimes s)  = d\omega \otimes s +\nabla s\wedge \omega $$ where $d$ is an exterior differentiation on $M$. Then $$ d^\nabla d^\nabla (\omega \otimes s)  =\sum_{m<k} dx^m\wedge dx^k\wedge \omega \otimes [  \nabla_{\partial_m},\nabla_{\partial_k}]s $$ Here how can we prove that $d^\nabla d^\nabla d^\nabla (s)=0$ ? In fact $$ d^\nabla d^\nabla d^\nabla (s)= dx^m\wedge dx^k\wedge dx^t \otimes (\nabla_{\partial_m} \nabla_{\partial_k}(\nabla_{\partial_t}s)).$$ Reference is the book "" Einstein manifold - Besse "". To show this we must have a metric on vector bundle ? Another Calculation : $\xi$ is a $k$-dimesional vector bundle with a connection $\nabla$ Define  $$d^\nabla : \Omega^i(\xi,M) \rightarrow  \Omega^{i+1}(\xi,M),\ \omega\otimes s\mapsto d\omega\otimes s + (-1)^i\omega\wedge \nabla s  $$ where $\Omega^i(\xi,M)$ is $\xi$-valued $i$-form. Here $\nabla e_i = A_{ij}e_j $ where $e_i$ is basis on $\xi$ and $A_{ij}$ is $k\times k$-matrix of 1-forms. Note that $$ d^\nabla \circ \nabla (e_i) = dA_{ij}\otimes e_j - A_{ij}\wedge \nabla e_j =[ dA_{ij} - A_{im}\wedge A_{mj} ]\otimes e_j$$ so that $$ d^\nabla \circ d^\nabla\circ \nabla (e_i) = [ 0 - dA_{im}\wedge A_{mj} +  A_{im}\wedge dA_{mj} ]\otimes e_j  $$ $$+ [ dA_{is} - A_{im}\wedge A_{ms} ]\wedge (- A_{sj})\otimes  e_j$$ $$  = [ -2 dA_{im}\wedge A_{mj} +  A_{im}\wedge dA_{mj}  + A_{im}\wedge A_{ms} \wedge A_{sj} ]\otimes  e_j$$ Why last line is not zero ?","Consider a connection on $E$ which is a vector bundle over $M$ : $$ \nabla : \Gamma(E) \rightarrow \Omega^1(M)\otimes \Gamma(E),\ s\mapsto \nabla\ s$$ Here $\nabla s =dx^k\otimes \nabla_{\partial_k} s$ where $x^k$ is coordinate function on $M$ Consider $C^\infty(M)$-linear map $d^\nabla$ : $$  d^\nabla (\omega\otimes s)  = d\omega \otimes s +\nabla s\wedge \omega $$ where $d$ is an exterior differentiation on $M$. Then $$ d^\nabla d^\nabla (\omega \otimes s)  =\sum_{m<k} dx^m\wedge dx^k\wedge \omega \otimes [  \nabla_{\partial_m},\nabla_{\partial_k}]s $$ Here how can we prove that $d^\nabla d^\nabla d^\nabla (s)=0$ ? In fact $$ d^\nabla d^\nabla d^\nabla (s)= dx^m\wedge dx^k\wedge dx^t \otimes (\nabla_{\partial_m} \nabla_{\partial_k}(\nabla_{\partial_t}s)).$$ Reference is the book "" Einstein manifold - Besse "". To show this we must have a metric on vector bundle ? Another Calculation : $\xi$ is a $k$-dimesional vector bundle with a connection $\nabla$ Define  $$d^\nabla : \Omega^i(\xi,M) \rightarrow  \Omega^{i+1}(\xi,M),\ \omega\otimes s\mapsto d\omega\otimes s + (-1)^i\omega\wedge \nabla s  $$ where $\Omega^i(\xi,M)$ is $\xi$-valued $i$-form. Here $\nabla e_i = A_{ij}e_j $ where $e_i$ is basis on $\xi$ and $A_{ij}$ is $k\times k$-matrix of 1-forms. Note that $$ d^\nabla \circ \nabla (e_i) = dA_{ij}\otimes e_j - A_{ij}\wedge \nabla e_j =[ dA_{ij} - A_{im}\wedge A_{mj} ]\otimes e_j$$ so that $$ d^\nabla \circ d^\nabla\circ \nabla (e_i) = [ 0 - dA_{im}\wedge A_{mj} +  A_{im}\wedge dA_{mj} ]\otimes e_j  $$ $$+ [ dA_{is} - A_{im}\wedge A_{ms} ]\wedge (- A_{sj})\otimes  e_j$$ $$  = [ -2 dA_{im}\wedge A_{mj} +  A_{im}\wedge dA_{mj}  + A_{im}\wedge A_{ms} \wedge A_{sj} ]\otimes  e_j$$ Why last line is not zero ?",,"['differential-geometry', 'riemannian-geometry']"
41,Vector calculus and Frenet-Serret equations,Vector calculus and Frenet-Serret equations,,"I have shown the first two equality and I am working on the showing the 1st equals the 3rd. \begin{alignat*}{4}   \frac{1}{\rho}\hat{\mathbf{{n}}} &= \frac{d\hat{\mathbf{{u}}}}{ds}   &{}= \frac{\dot{\hat{\mathbf{{u}}}}}{\dot{s}}   &{}= \left((\dot{\mathbf{r}}\cdot\dot{\mathbf{r}})\ddot{\mathbf{r}} -   (\dot{\mathbf{r}}\cdot\ddot{\mathbf{r}})\dot{\mathbf{r}}\right)   \frac{1}{\dot{r}^4} \end{alignat*} $$ \frac{1}{\rho}\hat{\mathbf{{n}}} = \frac{\dot{\hat{\mathbf{{u}}}}}{\dot{s}} $$ We know that $\mathbf{v} = \frac{ds}{dt}\frac{dr}{ds}$ where $\dot{s} = v$ and $\hat{\mathbf{u}} = \frac{dr}{ds}$. So $\mathbf{v} = v\hat{\mathbf{u}}\iff \dot{\hat{\mathbf{u}}} = \frac{1}{v}\frac{d\mathbf{v}}{dt}$. Then $\frac{\dot{\hat{\mathbf{{u}}}}}{\dot{s}} = \frac{1}{v^2}\frac{d\mathbf{v}}{dt}$. I know that $$ \frac{d\mathbf{v}}{dt} = \frac{dv}{dt}\hat{\mathbf{u}} + \frac{v^2}{\rho}\hat{\mathbf{n}}. $$ Then $\frac{\dot{\hat{\mathbf{{u}}}}}{\dot{s}} = \frac{1}{v^2}\frac{dv}{dt}\hat{\mathbf{u}} + \frac{1}{\rho}\hat{\mathbf{n}}$. Therefore, $\frac{1}{v^2}\frac{dv}{dt}\hat{\mathbf{u}} = 0$ but how do I show that this is $0$?","I have shown the first two equality and I am working on the showing the 1st equals the 3rd. \begin{alignat*}{4}   \frac{1}{\rho}\hat{\mathbf{{n}}} &= \frac{d\hat{\mathbf{{u}}}}{ds}   &{}= \frac{\dot{\hat{\mathbf{{u}}}}}{\dot{s}}   &{}= \left((\dot{\mathbf{r}}\cdot\dot{\mathbf{r}})\ddot{\mathbf{r}} -   (\dot{\mathbf{r}}\cdot\ddot{\mathbf{r}})\dot{\mathbf{r}}\right)   \frac{1}{\dot{r}^4} \end{alignat*} $$ \frac{1}{\rho}\hat{\mathbf{{n}}} = \frac{\dot{\hat{\mathbf{{u}}}}}{\dot{s}} $$ We know that $\mathbf{v} = \frac{ds}{dt}\frac{dr}{ds}$ where $\dot{s} = v$ and $\hat{\mathbf{u}} = \frac{dr}{ds}$. So $\mathbf{v} = v\hat{\mathbf{u}}\iff \dot{\hat{\mathbf{u}}} = \frac{1}{v}\frac{d\mathbf{v}}{dt}$. Then $\frac{\dot{\hat{\mathbf{{u}}}}}{\dot{s}} = \frac{1}{v^2}\frac{d\mathbf{v}}{dt}$. I know that $$ \frac{d\mathbf{v}}{dt} = \frac{dv}{dt}\hat{\mathbf{u}} + \frac{v^2}{\rho}\hat{\mathbf{n}}. $$ Then $\frac{\dot{\hat{\mathbf{{u}}}}}{\dot{s}} = \frac{1}{v^2}\frac{dv}{dt}\hat{\mathbf{u}} + \frac{1}{\rho}\hat{\mathbf{n}}$. Therefore, $\frac{1}{v^2}\frac{dv}{dt}\hat{\mathbf{u}} = 0$ but how do I show that this is $0$?",,['differential-geometry']
42,"""Coordinate functions"" on the structure-sheaf definition of a smooth manifold","""Coordinate functions"" on the structure-sheaf definition of a smooth manifold",,"I've been reading Bredon's Topology and Geometry recently; what an excellent book! He defines smooth manifolds in two distinct ways and then shows they are in fact equivalent. The ""non-standard"" definition is in terms of some sheaf-like ""functional structure $F_X$ "" on the underlying space $X$, satisfying the following properties: for every open set $U \subset X,$ we have $F_X(U)$ is a subalgebra of the algebra of continuous real-valued functions on $U$; $F_X(U)$ contains all constant functions; $V \subset U, f \in F_X(U) \implies f|_V \in F_X(V)$; $U = \bigcup U_{\alpha}$ and $f|_{U_{\alpha}} \in F_X(U_{\alpha})$ for all $\alpha \implies f \in F_X(U).$ A morphism of functionally structured spaces $(X,F_X) \rightarrow (Y,F_Y)$ is a map $\phi:X \rightarrow Y$ such that $f \mapsto f \circ \phi$ carries $F_Y(U)$ into $F_X(\phi^{-1}(U))$. Then a smooth $n$-manifold is a second countable, functionally structured, Hausdorff space $(M^n,F)$ which is locally isomorphic to $(\mathbb{R}^n,C^{\infty}).$ My question: to familiarize myself with the definition I have attempted the following exercise: Show that a second countable Hausdorff space $X$ with a functional structure $F$ is an $n$-manifold $\iff$ every point in $X$ has a neighborhood $U$ such that there are functions $f_1,\ldots,f_n \in F(U)$ such that a real-valued function $g$ on $U$ is in $F(U) \iff$ there exists a smooth function $h(x_1,\ldots,x_n)$ of $n$ real variables such that $g(p) = h(f_1(p),\ldots,f_n(p))$ for every $p \in U.$ The only part that I haven't been able to complete is the ""$\Longleftarrow$"" direction. That is, given the $n$ ""coordinate functions"" $f_i$, and given a point $x \in X$ and a neighborhood $U \ni x$ I, have constructed a morphism $\phi:(U,F_U) \rightarrow (\phi(U),C^{\infty})$ via $\phi(x) = (f_1(x),\ldots,f_n(x)).$ But for the life of me, I don't see how I could show that this is actually an isomorphism. Any hint toward the answer would be greatly appreciated!","I've been reading Bredon's Topology and Geometry recently; what an excellent book! He defines smooth manifolds in two distinct ways and then shows they are in fact equivalent. The ""non-standard"" definition is in terms of some sheaf-like ""functional structure $F_X$ "" on the underlying space $X$, satisfying the following properties: for every open set $U \subset X,$ we have $F_X(U)$ is a subalgebra of the algebra of continuous real-valued functions on $U$; $F_X(U)$ contains all constant functions; $V \subset U, f \in F_X(U) \implies f|_V \in F_X(V)$; $U = \bigcup U_{\alpha}$ and $f|_{U_{\alpha}} \in F_X(U_{\alpha})$ for all $\alpha \implies f \in F_X(U).$ A morphism of functionally structured spaces $(X,F_X) \rightarrow (Y,F_Y)$ is a map $\phi:X \rightarrow Y$ such that $f \mapsto f \circ \phi$ carries $F_Y(U)$ into $F_X(\phi^{-1}(U))$. Then a smooth $n$-manifold is a second countable, functionally structured, Hausdorff space $(M^n,F)$ which is locally isomorphic to $(\mathbb{R}^n,C^{\infty}).$ My question: to familiarize myself with the definition I have attempted the following exercise: Show that a second countable Hausdorff space $X$ with a functional structure $F$ is an $n$-manifold $\iff$ every point in $X$ has a neighborhood $U$ such that there are functions $f_1,\ldots,f_n \in F(U)$ such that a real-valued function $g$ on $U$ is in $F(U) \iff$ there exists a smooth function $h(x_1,\ldots,x_n)$ of $n$ real variables such that $g(p) = h(f_1(p),\ldots,f_n(p))$ for every $p \in U.$ The only part that I haven't been able to complete is the ""$\Longleftarrow$"" direction. That is, given the $n$ ""coordinate functions"" $f_i$, and given a point $x \in X$ and a neighborhood $U \ni x$ I, have constructed a morphism $\phi:(U,F_U) \rightarrow (\phi(U),C^{\infty})$ via $\phi(x) = (f_1(x),\ldots,f_n(x)).$ But for the life of me, I don't see how I could show that this is actually an isomorphism. Any hint toward the answer would be greatly appreciated!",,"['differential-geometry', 'differential-topology']"
43,The interior product and the isomorphism $\bigwedge^k(V^*)\otimes\bigwedge^n(V)\cong\bigwedge^{n-k}(V)$,The interior product and the isomorphism,\bigwedge^k(V^*)\otimes\bigwedge^n(V)\cong\bigwedge^{n-k}(V),"Let $V$ be an $n$-dimensional vector space. According to Wikipedia , there is an isomorphism $\bigwedge^k(V^*)\otimes\bigwedge^n(V)\cong\bigwedge^{n-k}(V)$. The explanation is that for $\alpha \in \bigwedge^k(V^*)$ and $\sigma \in \bigwedge^n(V)$, the isomorphism is given by $i_{\alpha}\sigma$ where $i_{\alpha}$ denotes the interior product (or multiplication) with $\alpha$. I'm confused by this. I've only ever seen the interior product of a form by a $1$ covector. How does one define $i_{\alpha}\sigma$?","Let $V$ be an $n$-dimensional vector space. According to Wikipedia , there is an isomorphism $\bigwedge^k(V^*)\otimes\bigwedge^n(V)\cong\bigwedge^{n-k}(V)$. The explanation is that for $\alpha \in \bigwedge^k(V^*)$ and $\sigma \in \bigwedge^n(V)$, the isomorphism is given by $i_{\alpha}\sigma$ where $i_{\alpha}$ denotes the interior product (or multiplication) with $\alpha$. I'm confused by this. I've only ever seen the interior product of a form by a $1$ covector. How does one define $i_{\alpha}\sigma$?",,"['differential-geometry', 'multilinear-algebra']"
44,Is $H^1(M) \subset L^2(M) \subset H^{-1}(M)$ a Hilbert triple for $M$ a manifold with boundary?,Is  a Hilbert triple for  a manifold with boundary?,H^1(M) \subset L^2(M) \subset H^{-1}(M) M,Is $H^1(M) \subset L^2(M)  \subset H^{-1}(M)$ a Hilbert triple for $M$ a manifold with boundary? What smoothness is required of the boundary? I would be grateful for some references to this.,Is $H^1(M) \subset L^2(M)  \subset H^{-1}(M)$ a Hilbert triple for $M$ a manifold with boundary? What smoothness is required of the boundary? I would be grateful for some references to this.,,"['differential-geometry', 'partial-differential-equations', 'hilbert-spaces', 'sobolev-spaces']"
45,Diffeomorphisms between factors in diffeomorphic product manifolds,Diffeomorphisms between factors in diffeomorphic product manifolds,,"Let $M$, $N$ and $P$ be three smooth manifolds such that $M \times N$ is diffeomorphic to $M \times P$. I need to know about some conditions under which one can deduce that $N$ is diffeomorphic to $P$. For example is it sufficient that $N$ and $P$ to be homotopy equivalent? Thanks","Let $M$, $N$ and $P$ be three smooth manifolds such that $M \times N$ is diffeomorphic to $M \times P$. I need to know about some conditions under which one can deduce that $N$ is diffeomorphic to $P$. For example is it sufficient that $N$ and $P$ to be homotopy equivalent? Thanks",,['differential-geometry']
46,Elliptic equation on riemannian manifolds,Elliptic equation on riemannian manifolds,,"Let $ M $ be a compact Riemannian manifold with or without boundary) and let $ \Delta $ be the metric laplacian. I want to study the differential operator $ -\Delta +q $ where $ q $ is a smooth function on $ M $. Now the first thing to do is a development of the theory of weak solutions for this differential operator. I think that all existence results in Chapter 6 , paragraph 2 of Evans' book 'Partial differentail equation' can be reformulate without changement for our case if we are able to prove the Poincarè inequality in the setting of a compact Riemannian manifold. Therefore the first question is is the poincare inequality true for a compact riannian manifold with boundary? (i think so) Now the second problem is the proof of the well- known regularity theorem in our setting (chapter 6.3 of Evans book). Can anyone suggest me a good reference for it? I know the Aubin book but it seems not so clear at this point.\ Thanks","Let $ M $ be a compact Riemannian manifold with or without boundary) and let $ \Delta $ be the metric laplacian. I want to study the differential operator $ -\Delta +q $ where $ q $ is a smooth function on $ M $. Now the first thing to do is a development of the theory of weak solutions for this differential operator. I think that all existence results in Chapter 6 , paragraph 2 of Evans' book 'Partial differentail equation' can be reformulate without changement for our case if we are able to prove the Poincarè inequality in the setting of a compact Riemannian manifold. Therefore the first question is is the poincare inequality true for a compact riannian manifold with boundary? (i think so) Now the second problem is the proof of the well- known regularity theorem in our setting (chapter 6.3 of Evans book). Can anyone suggest me a good reference for it? I know the Aubin book but it seems not so clear at this point.\ Thanks",,['differential-geometry']
47,Geodesics on a 2-sphere,Geodesics on a 2-sphere,,"I've been doing some work where I need to find the geodesics in a given Riemannian Manifold. Let's take the example of the two sphere, for simplicity, with unitary radius. The distance between two points, say: $p$ and $q$, is given by the length of the geodesic that connect those two points, such that: $$d=\int_0^1 [\dot{\theta}^2+\sin^2(\theta)\dot{\phi}^2]^{1/2}dt,$$ where $c(t)=(\theta (t),\phi(t))$ is the geodesic that connect the two considered points (i.e.  $c(0)=p$ and $c(1)=q$). To find the expression of the geodesic one uses the Variational Principle, which leads to the Euler-Lagrange equations for $\theta$ and $\phi$. To simplify our work one can, instead of searching for the curve that minimizes the distance, search for the curve that minimizes the Energy functional and it can be proven that if the curve is a geodesic then the curve that minimizes the energy is the same as the curve that minimizes the distance (proof in the previous link). Using what I've stated to search for the geodesics on the 2-sphere we find two differential equations which admit solutions to be the great circles or the meridians. Now to the actual question(s): If instead of parametrizing the geodesic with the parameter $t$ one parametrizes it with the coordinate $\theta$ (knowing that one can no longer describe the geodesics that connect two points with the same $\theta$ coordinate), such that $c(\theta)=(\theta,\phi(\theta))$ and $\dot{c}=(1,\dot{\phi})$, is the curve that minimizes the distance the same that minimizes the energy? If the answer is yes one finds that: $\phi(\theta)=\frac{\phi_2}{\cot(\theta_2)}\cot(\theta)$, assuming the first point's coordinates to be $(\pi/2,0)$ and $(\theta_2,\phi_2)$ for the second point. But that leads to a wierd behaviour for points near the poles and $\phi_2>\pi$... (see picture) What am I doing wrong?It's the answer to the first question, the coordinate system or something deeper...?","I've been doing some work where I need to find the geodesics in a given Riemannian Manifold. Let's take the example of the two sphere, for simplicity, with unitary radius. The distance between two points, say: $p$ and $q$, is given by the length of the geodesic that connect those two points, such that: $$d=\int_0^1 [\dot{\theta}^2+\sin^2(\theta)\dot{\phi}^2]^{1/2}dt,$$ where $c(t)=(\theta (t),\phi(t))$ is the geodesic that connect the two considered points (i.e.  $c(0)=p$ and $c(1)=q$). To find the expression of the geodesic one uses the Variational Principle, which leads to the Euler-Lagrange equations for $\theta$ and $\phi$. To simplify our work one can, instead of searching for the curve that minimizes the distance, search for the curve that minimizes the Energy functional and it can be proven that if the curve is a geodesic then the curve that minimizes the energy is the same as the curve that minimizes the distance (proof in the previous link). Using what I've stated to search for the geodesics on the 2-sphere we find two differential equations which admit solutions to be the great circles or the meridians. Now to the actual question(s): If instead of parametrizing the geodesic with the parameter $t$ one parametrizes it with the coordinate $\theta$ (knowing that one can no longer describe the geodesics that connect two points with the same $\theta$ coordinate), such that $c(\theta)=(\theta,\phi(\theta))$ and $\dot{c}=(1,\dot{\phi})$, is the curve that minimizes the distance the same that minimizes the energy? If the answer is yes one finds that: $\phi(\theta)=\frac{\phi_2}{\cot(\theta_2)}\cot(\theta)$, assuming the first point's coordinates to be $(\pi/2,0)$ and $(\theta_2,\phi_2)$ for the second point. But that leads to a wierd behaviour for points near the poles and $\phi_2>\pi$... (see picture) What am I doing wrong?It's the answer to the first question, the coordinate system or something deeper...?",,"['differential-geometry', 'riemannian-geometry', 'spherical-geometry']"
48,Lie Bracket and flows,Lie Bracket and flows,,"Can anyone show me how do I differentiate this? Suppose I have $\Phi^{X}_{t}$ and $\Phi^{Y}_{t}$ both flows with $X$ and $Y$ respectively starting from point $p$, what is $\frac{d}{dt}|_{t=0}\phi^{Y}_{-\sqrt{t}}\circ \phi^{X}_{-\sqrt{t}}\circ \phi^{Y}_{\sqrt{t}}\circ\phi^{X}_{\sqrt{t}}$? Thanks!","Can anyone show me how do I differentiate this? Suppose I have $\Phi^{X}_{t}$ and $\Phi^{Y}_{t}$ both flows with $X$ and $Y$ respectively starting from point $p$, what is $\frac{d}{dt}|_{t=0}\phi^{Y}_{-\sqrt{t}}\circ \phi^{X}_{-\sqrt{t}}\circ \phi^{Y}_{\sqrt{t}}\circ\phi^{X}_{\sqrt{t}}$? Thanks!",,['differential-geometry']
49,is this set a regular surface?,is this set a regular surface?,,"I'm reading ""Differential Geometry of Curves and Surfaces of Manfredo Docarmo"" I'm doing  the exercises of the chapter 2. Here is the definition of regular surface that we are following: I have problems with this exercise: Is with the first part, I think that it's not true that it's a regular surface (the second it is). I don't know how to prove that something is not a regular surface.","I'm reading ""Differential Geometry of Curves and Surfaces of Manfredo Docarmo"" I'm doing  the exercises of the chapter 2. Here is the definition of regular surface that we are following: I have problems with this exercise: Is with the first part, I think that it's not true that it's a regular surface (the second it is). I don't know how to prove that something is not a regular surface.",,"['differential-geometry', 'surfaces']"
50,Describing the algebra of functions on $S^2$,Describing the algebra of functions on,S^2,"Chapter 2 of the book ""Elements of Noncommutative Geometry"" claims that the $C^*$-algebra of functions on $S^2$ can be described as an algebra with 3 generators a,b,c all with norm 1, where $a,b$ are positive and $c^*c = 4ab.$ However it never explicitly tells you which functions on the sphere these are. What are they?","Chapter 2 of the book ""Elements of Noncommutative Geometry"" claims that the $C^*$-algebra of functions on $S^2$ can be described as an algebra with 3 generators a,b,c all with norm 1, where $a,b$ are positive and $c^*c = 4ab.$ However it never explicitly tells you which functions on the sphere these are. What are they?",,"['differential-geometry', 'noncommutative-algebra', 'noncommutative-geometry']"
51,A tensor calculus problem,A tensor calculus problem,,"If the relation $a_{ij}u^iu^j=0$ holds for all vectors $u^i$ such that $u^i\lambda_i=0$ where $\lambda_i$ is a given covariant vector, show that $$a_{ij}+a_{ji}=\lambda_iv_j+\lambda_j v_i$$ where $v_j$ is some covariant vector. I am completely stuck on this problem. How can I solve this problem?","If the relation $a_{ij}u^iu^j=0$ holds for all vectors $u^i$ such that $u^i\lambda_i=0$ where $\lambda_i$ is a given covariant vector, show that $$a_{ij}+a_{ji}=\lambda_iv_j+\lambda_j v_i$$ where $v_j$ is some covariant vector. I am completely stuck on this problem. How can I solve this problem?",,"['differential-geometry', 'tensors']"
52,Approximations of shortest curves,Approximations of shortest curves,,"Consider a set of functions $f:[0,1]\rightarrow \mathbb{R}$ with $f(0) = f(1) = 0$ that are supposed to approximate the function $\mathbf{0}:[0,1]\rightarrow \mathbb{R}$ with $\mathbf{0}(x) \equiv 0$. The graph of $\mathbf{0}(x)$ is to be seen as the “reference curve”. Since the graph of $\mathbf{0}$ is the shortest curve between its end points, it seems natural to say that $f$ approximates $\mathbf{0}$ better than $g$ when the arc length of (the graph of) $f$ is shorter than that of $g$, i.e. $$\int_0^1\sqrt{1 + f'(x)^2}dx < \int_0^1\sqrt{1 + g'(x)^2}dx\quad\quad\quad  (1_0)$$ But this conflicts with another measure of proximity: one can say $f$ approximates $\mathbf{0}$ better than $g$ when it deviates less from $\mathbf{0}$ than $g$ in the following sense $$\int_0^1 |f(x) - \mathbf{0}(x)| dx < \int_0^1 |g(x) - \mathbf{0}(x)| dx\quad\quad\quad  (2_0)$$ which means $$\int_0^1 |f(x)| dx < \int_0^1 |g(x)| dx\quad\quad\quad  (2_1)$$ which holds – for the sake of comparison with $(1)$ – iff $$\int_0^1\sqrt{1 + f(x)^2}dx < \int_0^1\sqrt{1 + g(x)^2}dx\quad\quad\quad  (2_2)$$ The “conflict” can easily be made visible: The red curve $g$ has the same length as the blue one $f$ while the area under $g$ is obviously greater than the area under $f$. There is another – “intrinsic” – property of the blue curve $f$ that makes it a better approximation than the red curve $g$ – and even without an explicit reference to $\mathbf{0}$: it changes its direction “more often”. In integral notation: $$\int_0^1 |f''(x)| dx > \int_0^1 |g''(x)| dx\quad\quad\quad  (3_0)$$ or equivalently: $$\int_0^1\sqrt{1 + f''(x)^2}dx > \int_0^1\sqrt{1 + g''(x)^2}dx\quad\quad\quad  (3_1)$$ In which “theory” or framework do these findings fit together – and how? And what are, resp., the official names of $$\int |f(x)| dx $$ $$\int |f'(x)| dx $$ $$\int |f''(x)| dx $$","Consider a set of functions $f:[0,1]\rightarrow \mathbb{R}$ with $f(0) = f(1) = 0$ that are supposed to approximate the function $\mathbf{0}:[0,1]\rightarrow \mathbb{R}$ with $\mathbf{0}(x) \equiv 0$. The graph of $\mathbf{0}(x)$ is to be seen as the “reference curve”. Since the graph of $\mathbf{0}$ is the shortest curve between its end points, it seems natural to say that $f$ approximates $\mathbf{0}$ better than $g$ when the arc length of (the graph of) $f$ is shorter than that of $g$, i.e. $$\int_0^1\sqrt{1 + f'(x)^2}dx < \int_0^1\sqrt{1 + g'(x)^2}dx\quad\quad\quad  (1_0)$$ But this conflicts with another measure of proximity: one can say $f$ approximates $\mathbf{0}$ better than $g$ when it deviates less from $\mathbf{0}$ than $g$ in the following sense $$\int_0^1 |f(x) - \mathbf{0}(x)| dx < \int_0^1 |g(x) - \mathbf{0}(x)| dx\quad\quad\quad  (2_0)$$ which means $$\int_0^1 |f(x)| dx < \int_0^1 |g(x)| dx\quad\quad\quad  (2_1)$$ which holds – for the sake of comparison with $(1)$ – iff $$\int_0^1\sqrt{1 + f(x)^2}dx < \int_0^1\sqrt{1 + g(x)^2}dx\quad\quad\quad  (2_2)$$ The “conflict” can easily be made visible: The red curve $g$ has the same length as the blue one $f$ while the area under $g$ is obviously greater than the area under $f$. There is another – “intrinsic” – property of the blue curve $f$ that makes it a better approximation than the red curve $g$ – and even without an explicit reference to $\mathbf{0}$: it changes its direction “more often”. In integral notation: $$\int_0^1 |f''(x)| dx > \int_0^1 |g''(x)| dx\quad\quad\quad  (3_0)$$ or equivalently: $$\int_0^1\sqrt{1 + f''(x)^2}dx > \int_0^1\sqrt{1 + g''(x)^2}dx\quad\quad\quad  (3_1)$$ In which “theory” or framework do these findings fit together – and how? And what are, resp., the official names of $$\int |f(x)| dx $$ $$\int |f'(x)| dx $$ $$\int |f''(x)| dx $$",,['differential-geometry']
53,An exercise in the Riemannian geometry book,An exercise in the Riemannian geometry book,,"If $M$ is a smooth closed $n$-dimensional Riemannian manifold which is Riemannian embedded in $\mathbb R^{n+1}$, then there exists a point $p \in M$ such that the sectional curvatures at $p$ are all positive. Can any one give me a hint for this problem? I was considering the maximum $p$ of function $|x|^2$ on $M$, then near $p$, $M$ is ""wrapped"" by some $S^n$ and has the same tangent space as $S^n$. But I am stuck there. I have made some progress: We consider the functions $L_q(x)=|x-q|^2$. Then we have a maximum $p$ of $L_q$ and we fix the unit vector $v=\frac{p-q}{|p-q|}$ throughout, so $v$ is the normal vector at $p$. Now if we set $q(t)=p+tv$, then when $t\leq-|p-q|$, $p$ is always the maximum of function $L_{q(t)}$ (this is true if we draw a ball at $q(t)$ with radius $|p-q(t)|$, then all $M$ is contained in this ball). Therefore when $t$ sufficiently tends to $-\infty$, the Hessian $L_{q(t)}$ is always semi-positive definite. Now if we fix a coordinate neighborhood aroud $p$, then Hessian matrix $H$ of $L_{q(t)}$ at $p$ is given by $H=2(F-tS)$ where $F,S$ are the first and second fundamental forms of $M$ at $p$. So we conclude that $S$ has to be semi-positive definite. But how can we move further to say $S$ is positive definite?","If $M$ is a smooth closed $n$-dimensional Riemannian manifold which is Riemannian embedded in $\mathbb R^{n+1}$, then there exists a point $p \in M$ such that the sectional curvatures at $p$ are all positive. Can any one give me a hint for this problem? I was considering the maximum $p$ of function $|x|^2$ on $M$, then near $p$, $M$ is ""wrapped"" by some $S^n$ and has the same tangent space as $S^n$. But I am stuck there. I have made some progress: We consider the functions $L_q(x)=|x-q|^2$. Then we have a maximum $p$ of $L_q$ and we fix the unit vector $v=\frac{p-q}{|p-q|}$ throughout, so $v$ is the normal vector at $p$. Now if we set $q(t)=p+tv$, then when $t\leq-|p-q|$, $p$ is always the maximum of function $L_{q(t)}$ (this is true if we draw a ball at $q(t)$ with radius $|p-q(t)|$, then all $M$ is contained in this ball). Therefore when $t$ sufficiently tends to $-\infty$, the Hessian $L_{q(t)}$ is always semi-positive definite. Now if we fix a coordinate neighborhood aroud $p$, then Hessian matrix $H$ of $L_{q(t)}$ at $p$ is given by $H=2(F-tS)$ where $F,S$ are the first and second fundamental forms of $M$ at $p$. So we conclude that $S$ has to be semi-positive definite. But how can we move further to say $S$ is positive definite?",,"['differential-geometry', 'riemannian-geometry']"
54,$U(1)$-connection,-connection,U(1),Let $M$ be a smooth manifold. I would like to understand why the moduli space of flat $U(1)$-connections modulo gauge equivalence is the torus $$ H^1(M;\mathbb{R})/H^1(M;\mathbb{Z}). $$ How should I see this?,Let $M$ be a smooth manifold. I would like to understand why the moduli space of flat $U(1)$-connections modulo gauge equivalence is the torus $$ H^1(M;\mathbb{R})/H^1(M;\mathbb{Z}). $$ How should I see this?,,['differential-geometry']
55,Lie derivative: concrete example for linear Lie group,Lie derivative: concrete example for linear Lie group,,"I am trying to understand the notion (and notation) of the Lie derivative on a general manifold by trying to convert the notation the concrete example of the Lie group O(n). Let $X,Y$ be smooth vector fields on a smooth manifold $M$, $p \in M$ and the local flow $\psi_t: U \rightarrow M$ of X in a neighborhood $U$ of $p$. Then the $\textit{Lie derivative}$ and thus the Lie bracket is defined as: $$ [X,Y]_p := \mathcal{L}_X(Y_p) = \lim_{t\rightarrow 0} \frac{(d\psi)_{-t}\; Y_{\psi_t(p)} - Y_p}{t}$$ In words: one uses the pullback of the vector field $Y$ along the flow of $X$ to define this derivative. Now, for $M=O(n)$, with associated Lie algebra $\mathfrak{o}(n)=\{ X \in M(n,\mathbb{R}) : X = -X^T \}$, the Lie bracket for $A,B \in \mathfrak{o}(n)$ can be written as: $$[A,B] = \lim_{t\rightarrow 0} \frac{\gamma(t) - B}{t}, $$ where the curve $\gamma$ is given by $$ \gamma(t) = \exp(tA)B\exp(-tA). $$ Unfortunately, I got stuck in defining the abstract notation appropriately to arrive at the latter expression. Does someone has an idea how to define $\psi$ and the vector fields in this situation? Or, does someone know a better $\textit{concrete}$ example where one can well understand the Lie derivative?","I am trying to understand the notion (and notation) of the Lie derivative on a general manifold by trying to convert the notation the concrete example of the Lie group O(n). Let $X,Y$ be smooth vector fields on a smooth manifold $M$, $p \in M$ and the local flow $\psi_t: U \rightarrow M$ of X in a neighborhood $U$ of $p$. Then the $\textit{Lie derivative}$ and thus the Lie bracket is defined as: $$ [X,Y]_p := \mathcal{L}_X(Y_p) = \lim_{t\rightarrow 0} \frac{(d\psi)_{-t}\; Y_{\psi_t(p)} - Y_p}{t}$$ In words: one uses the pullback of the vector field $Y$ along the flow of $X$ to define this derivative. Now, for $M=O(n)$, with associated Lie algebra $\mathfrak{o}(n)=\{ X \in M(n,\mathbb{R}) : X = -X^T \}$, the Lie bracket for $A,B \in \mathfrak{o}(n)$ can be written as: $$[A,B] = \lim_{t\rightarrow 0} \frac{\gamma(t) - B}{t}, $$ where the curve $\gamma$ is given by $$ \gamma(t) = \exp(tA)B\exp(-tA). $$ Unfortunately, I got stuck in defining the abstract notation appropriately to arrive at the latter expression. Does someone has an idea how to define $\psi$ and the vector fields in this situation? Or, does someone know a better $\textit{concrete}$ example where one can well understand the Lie derivative?",,"['differential-geometry', 'lie-algebras', 'lie-groups']"
56,Things related to the Preissman Theorem,Things related to the Preissman Theorem,,"I'm reading the proof of the Preissman Theorem, in Do Carmo's book of Riemannian Geometry.  A crucial step in this demonstration is the following lema, Lema : Let $M$ be a compact riemannian manifold, and $\alpha$ a non trivial deck transformation of  the universal covering $\widetilde{M}$, where we are considering $\widetilde{M}$ with  a  covering metric. So the statement is that $\alpha$ leaves invariant a geodesic $\widetilde{\gamma}$  of    $\widetilde{M}$, in this sense $$\alpha(\widetilde{\gamma}(-\infty,\infty))=\widetilde{\gamma}(-\infty,\infty).$$ Sketch of proof : Let $\pi:\widetilde{M}\to M$ be the  covering  transformation. Let $\widetilde{p}\in \widetilde{M}$ and $p=\pi(\widetilde{p}).$ Let $g\in \pi_1(M,p)$ be the element corresponding to $\alpha$  by the known isomorphism $\pi_1(M,p)\simeq Aut(\widetilde{M}).$ By the Cartan Theorem, there is a closed geodesic $\gamma$ in the  class of free homotopy $M$ given by $g.$ The main idea now is to show that, $\alpha$  fixes the extension of a lifting of $\gamma.$ For this, we obtain a deck tranformation that clearly fix the lifting of $\gamma$ (just take a deck  transformation $\beta$ associated to the class of homotopy of $\gamma$ with a base point $q\in \gamma$). And then show that they coincide in one point and therefore must be the same, $\alpha=\beta$. My Question : Is there any reason to believe that the geodesic wich will be fixed by $\alpha$  is precisely the lifting  of a geodesic  given by the Cartan Theorem?  Or was that just an insight wich the person who'd demonstrated the theorem have? For those who do not remember this is the statement of the theorem cartan Cartan Theorem : Let $M$ be a compact riemannian manifold. Let $\pi_1(M)$ be the set of all the classes of free homotopy of $M.$ Then in each non trival class there is a closed geodesic. (i.e a closed curve which is geodesic in all of its points.)","I'm reading the proof of the Preissman Theorem, in Do Carmo's book of Riemannian Geometry.  A crucial step in this demonstration is the following lema, Lema : Let $M$ be a compact riemannian manifold, and $\alpha$ a non trivial deck transformation of  the universal covering $\widetilde{M}$, where we are considering $\widetilde{M}$ with  a  covering metric. So the statement is that $\alpha$ leaves invariant a geodesic $\widetilde{\gamma}$  of    $\widetilde{M}$, in this sense $$\alpha(\widetilde{\gamma}(-\infty,\infty))=\widetilde{\gamma}(-\infty,\infty).$$ Sketch of proof : Let $\pi:\widetilde{M}\to M$ be the  covering  transformation. Let $\widetilde{p}\in \widetilde{M}$ and $p=\pi(\widetilde{p}).$ Let $g\in \pi_1(M,p)$ be the element corresponding to $\alpha$  by the known isomorphism $\pi_1(M,p)\simeq Aut(\widetilde{M}).$ By the Cartan Theorem, there is a closed geodesic $\gamma$ in the  class of free homotopy $M$ given by $g.$ The main idea now is to show that, $\alpha$  fixes the extension of a lifting of $\gamma.$ For this, we obtain a deck tranformation that clearly fix the lifting of $\gamma$ (just take a deck  transformation $\beta$ associated to the class of homotopy of $\gamma$ with a base point $q\in \gamma$). And then show that they coincide in one point and therefore must be the same, $\alpha=\beta$. My Question : Is there any reason to believe that the geodesic wich will be fixed by $\alpha$  is precisely the lifting  of a geodesic  given by the Cartan Theorem?  Or was that just an insight wich the person who'd demonstrated the theorem have? For those who do not remember this is the statement of the theorem cartan Cartan Theorem : Let $M$ be a compact riemannian manifold. Let $\pi_1(M)$ be the set of all the classes of free homotopy of $M.$ Then in each non trival class there is a closed geodesic. (i.e a closed curve which is geodesic in all of its points.)",,['algebraic-topology']
57,Curvature and torsion changes related to Frenet frame choice,Curvature and torsion changes related to Frenet frame choice,,"Let $\gamma(s)$ be a unit-speed curve in $\mathbb{R}^3$. Let $t = \dot{\gamma}(s)$, $n = \frac{\dot{t}}{\left \| \dot{t} \right \|}$ and $b= t \times n$. The vectors $(t,n,b)$ form what is called a Frenet frame in a point $s$. Define the curvature as $k = \dot{t} \cdot n$ and the torsion as $\tau = - \dot{b} \cdot n$. We can change the sign of $t$ and $n$ arbitrarily, obtaining (for example) the new frame $(t^\ast=-t,n^\ast=-n,b^\ast=b)$. My teacher said that curvature's sign depends on the choice of $t$ but torsion's sign remains unchanged after arbitrary sign switching on $t$ and $n$... but that seems not to be true. In fact we have $$\tau= - \dot{b} \cdot n$$ realted to the first frame and $$\tau^\ast = - \dot{b^\ast} \cdot n^\ast = -\dot{b} \cdot (-n) = -\tau \quad$$ for the second I wrote. So, where is my mistake?","Let $\gamma(s)$ be a unit-speed curve in $\mathbb{R}^3$. Let $t = \dot{\gamma}(s)$, $n = \frac{\dot{t}}{\left \| \dot{t} \right \|}$ and $b= t \times n$. The vectors $(t,n,b)$ form what is called a Frenet frame in a point $s$. Define the curvature as $k = \dot{t} \cdot n$ and the torsion as $\tau = - \dot{b} \cdot n$. We can change the sign of $t$ and $n$ arbitrarily, obtaining (for example) the new frame $(t^\ast=-t,n^\ast=-n,b^\ast=b)$. My teacher said that curvature's sign depends on the choice of $t$ but torsion's sign remains unchanged after arbitrary sign switching on $t$ and $n$... but that seems not to be true. In fact we have $$\tau= - \dot{b} \cdot n$$ realted to the first frame and $$\tau^\ast = - \dot{b^\ast} \cdot n^\ast = -\dot{b} \cdot (-n) = -\tau \quad$$ for the second I wrote. So, where is my mistake?",,[]
58,Flow on manifolds and Lie bracket.,Flow on manifolds and Lie bracket.,,"I'm currently reading through some notes on Lie Theory online, and I've stumbled across the following question, which I'm totally stumped by. ""Let X,Y be two commuting complete vector fields on a manifold M, that is $[X,Y]=0$. Show that the vector field X+Y is complete and that the flow of X+Y is given by $\phi_{t,X+Y}(p)=\phi_{X,t}\circ \phi_{Y,t}(p)$, where $\phi_{t,X}$ stands for the flow of the vector field X,and so on."" I have no problems showing that the vector field is complete. However, it's the flow part that bugs me. So far I've tried the following:  Look at $h(s,t,p) = \phi_{X,t}\circ \phi_{Y,s}(p)$, for some point p. Set $c(t,p) = h(t,t,p)$. We then have, after differentiating that $\frac{d}{dt}_{t=0}c(t,p) = D_1h(0,0,p)+D_2h(0,0,p)$.Since $h(t,0,p)=\phi_{t,x}(p)$ and $h(0,t,p) = \phi_{t,Y}(p)$ we get that $D_1h(0,0,p) = X(p)$, and $D_2h(0,0,p) = Y(p)$ and thus, the flow is $X(p)+Y(p)$.","I'm currently reading through some notes on Lie Theory online, and I've stumbled across the following question, which I'm totally stumped by. ""Let X,Y be two commuting complete vector fields on a manifold M, that is $[X,Y]=0$. Show that the vector field X+Y is complete and that the flow of X+Y is given by $\phi_{t,X+Y}(p)=\phi_{X,t}\circ \phi_{Y,t}(p)$, where $\phi_{t,X}$ stands for the flow of the vector field X,and so on."" I have no problems showing that the vector field is complete. However, it's the flow part that bugs me. So far I've tried the following:  Look at $h(s,t,p) = \phi_{X,t}\circ \phi_{Y,s}(p)$, for some point p. Set $c(t,p) = h(t,t,p)$. We then have, after differentiating that $\frac{d}{dt}_{t=0}c(t,p) = D_1h(0,0,p)+D_2h(0,0,p)$.Since $h(t,0,p)=\phi_{t,x}(p)$ and $h(0,t,p) = \phi_{t,Y}(p)$ we get that $D_1h(0,0,p) = X(p)$, and $D_2h(0,0,p) = Y(p)$ and thus, the flow is $X(p)+Y(p)$.",,['differential-geometry']
59,Surjection that increases dimensions,Surjection that increases dimensions,,"This question is somewhat inspired by a question on MathOverflow , but it is not necessary to read that question to understand what I am about to ask. It is well known that one can establish a surjection between sets of different Hausdorff dimensions: in the regime of just set theory the cardinality of the unit interval and the unit square are the same, and in fact we get a bijection. If you add a bit of topology, one can in addition request that this surjection be given by a continuous map , but the map cannot be a bijection, else it'd be a homeomorphism. What if, instead of continuity, we require a different condition? Question Fix $N$ a positive integer. Let $B$ be the open unit ball in $\mathbb{R}^N$. Can we find an embedded smooth (or $C^1$) hypersurface $A\subset \mathbb{R}^N$ and a surjection $\phi:A\to B$ such that the vector $a - \phi(a)$ is orthogonal to $A$? Can it be made continuous? Can it be made a bijection?","This question is somewhat inspired by a question on MathOverflow , but it is not necessary to read that question to understand what I am about to ask. It is well known that one can establish a surjection between sets of different Hausdorff dimensions: in the regime of just set theory the cardinality of the unit interval and the unit square are the same, and in fact we get a bijection. If you add a bit of topology, one can in addition request that this surjection be given by a continuous map , but the map cannot be a bijection, else it'd be a homeomorphism. What if, instead of continuity, we require a different condition? Question Fix $N$ a positive integer. Let $B$ be the open unit ball in $\mathbb{R}^N$. Can we find an embedded smooth (or $C^1$) hypersurface $A\subset \mathbb{R}^N$ and a surjection $\phi:A\to B$ such that the vector $a - \phi(a)$ is orthogonal to $A$? Can it be made continuous? Can it be made a bijection?",,"['real-analysis', 'differential-geometry', 'elementary-set-theory']"
60,How does the boundary property usually work in PDE?,How does the boundary property usually work in PDE?,,"This may be related to the question Is the hypersurface of class $C^k$ a $C^k$-differentiable manifold? . In almost every chapter of a PDE textbook(e.g. Folland's Introduction to Partial Differential Equations ), the boundary of the domain is assumed to have some properties. The most common assumption is about the "" smoothness ""(I call it so, whether appropriate or not). For example, in Chapter 3 in Folland's book, there is a sentence as following: ""In this chapter $\Omega$ will be a fixed bounded domain in ${\mathbb R}^n$ with $C^2$ boundary $S$,..."" It seems that this assumption is always used implicitly . I can never understand how it actually work. I can only know superficially that $C^2$ means the coordinates charts are $C^2$-compatible in the definition of differentiable structure. Nothing more. Is there a rule of thumb that how this assumption is used? It may be too vague to ask such question without a concrete proposition/theorem which has such assumption. Any suggestion for a good modification of the question will be really welcomed.","This may be related to the question Is the hypersurface of class $C^k$ a $C^k$-differentiable manifold? . In almost every chapter of a PDE textbook(e.g. Folland's Introduction to Partial Differential Equations ), the boundary of the domain is assumed to have some properties. The most common assumption is about the "" smoothness ""(I call it so, whether appropriate or not). For example, in Chapter 3 in Folland's book, there is a sentence as following: ""In this chapter $\Omega$ will be a fixed bounded domain in ${\mathbb R}^n$ with $C^2$ boundary $S$,..."" It seems that this assumption is always used implicitly . I can never understand how it actually work. I can only know superficially that $C^2$ means the coordinates charts are $C^2$-compatible in the definition of differentiable structure. Nothing more. Is there a rule of thumb that how this assumption is used? It may be too vague to ask such question without a concrete proposition/theorem which has such assumption. Any suggestion for a good modification of the question will be really welcomed.",,['soft-question']
61,Why can we think of the second fundamental form as a Hessian matrix?,Why can we think of the second fundamental form as a Hessian matrix?,,"Let $f: U \rightarrow \mathbb{R}^3$ be an immersion that parametrizes a piece of a surface, and let $(h_{ij})$ be the matrix for the second fundamental form of that surface. According to pg. 70 of the text Differential Geometry by Wolfgang Kuhnel, we can think of the $(h_{ij})$ as ""the Hessian of matrix of a function $h$, which represents the surface as a graph over its tangent plane"". I have a ""heuristic"" understanding of what's going on, but I'd like to be a bit more careful about this.  What exactly is the function $h$?  Can we write it down explicitly (perhaps in terms of the parametrization $f$, the unit normal $\nu$, and their derivatives), so that we can directly check that its Hessian is indeed the second fundamental form $(h_{ij})$?","Let $f: U \rightarrow \mathbb{R}^3$ be an immersion that parametrizes a piece of a surface, and let $(h_{ij})$ be the matrix for the second fundamental form of that surface. According to pg. 70 of the text Differential Geometry by Wolfgang Kuhnel, we can think of the $(h_{ij})$ as ""the Hessian of matrix of a function $h$, which represents the surface as a graph over its tangent plane"". I have a ""heuristic"" understanding of what's going on, but I'd like to be a bit more careful about this.  What exactly is the function $h$?  Can we write it down explicitly (perhaps in terms of the parametrization $f$, the unit normal $\nu$, and their derivatives), so that we can directly check that its Hessian is indeed the second fundamental form $(h_{ij})$?",,['differential-geometry']
62,"Isomorphism between sections of $\text{Hom}(E,F)$ and bundle maps $E \to F$",Isomorphism between sections of  and bundle maps,"\text{Hom}(E,F) E \to F","Given vector bundles $E$ and $F$ over a smooth manifold $M$ do we have an isomorphism $$\Gamma(\text{Hom}(E,F)) \cong \text{Hom}_{C^\infty(M)}(E,F)?$$ That is, if I have a smooth bundle map $E \to F$ do I obtain a section of the bundle $\text{Hom}(E,F)$ and vice versa? I see this being used in multiple places, but I have not found a proof for this proposition.","Given vector bundles and over a smooth manifold do we have an isomorphism That is, if I have a smooth bundle map do I obtain a section of the bundle and vice versa? I see this being used in multiple places, but I have not found a proof for this proposition.","E F M \Gamma(\text{Hom}(E,F)) \cong \text{Hom}_{C^\infty(M)}(E,F)? E \to F \text{Hom}(E,F)","['differential-geometry', 'vector-bundles']"
63,"Show that contact manifolds are orientable, or why $\lambda\alpha\wedge(\lambda d\alpha+d\lambda\wedge\alpha)^n=\lambda^{n+1}\alpha\wedge(d\alpha)^n$","Show that contact manifolds are orientable, or why",\lambda\alpha\wedge(\lambda d\alpha+d\lambda\wedge\alpha)^n=\lambda^{n+1}\alpha\wedge(d\alpha)^n,"While reading to Geige's An Introduction to Contact Topology, I got stuck after the following statement: Observe that $\alpha$ is a contact form precisely if $\alpha\wedge(d\alpha)^n$ is a volume form on $M$ (i.e. a nowhere vanishing top-dimensional differential form); in particular, $M$ needs to be orientable. The condition $\alpha\wedge(d\alpha)^n\not=0$ is independent of the specific choice of $\alpha$ and thus is indeed a property of $\xi=\ker\alpha$ : any other 1–form defining the same hyperplane field must be of the form $\lambda\alpha$ for some smooth function $\lambda:M\rightarrow\mathbb R\setminus\{0\}$ , and we have $$(\lambda\alpha)\wedge d((\lambda\alpha))^n=\lambda\alpha\wedge(\lambda d\alpha+d\lambda\wedge\alpha)^n=\lambda^{n+1}\alpha\wedge(d\alpha)^n\not=0\text{.}$$ For context, $\alpha$ is a 1-form that doesn't vanish at any point of $M$ , where $M$ is a $(2n+1)$ -differentiable manifold, and $(d\alpha)^n$ denotes the $n$ -fold wedge product $d\alpha\wedge\dots\wedge d\alpha$ . I don't know how to prove the second equality, that is, why do we have that $$\lambda\alpha\wedge(\lambda d\alpha+d\lambda\wedge\alpha)^n=\lambda^{n+1}\alpha\wedge(d\alpha)^n?$$ This would be trivial if we somehow had that $d\lambda\wedge\alpha=0$ , which certainly doesn't have to be the case. Thanks in advance for your answer.","While reading to Geige's An Introduction to Contact Topology, I got stuck after the following statement: Observe that is a contact form precisely if is a volume form on (i.e. a nowhere vanishing top-dimensional differential form); in particular, needs to be orientable. The condition is independent of the specific choice of and thus is indeed a property of : any other 1–form defining the same hyperplane field must be of the form for some smooth function , and we have For context, is a 1-form that doesn't vanish at any point of , where is a -differentiable manifold, and denotes the -fold wedge product . I don't know how to prove the second equality, that is, why do we have that This would be trivial if we somehow had that , which certainly doesn't have to be the case. Thanks in advance for your answer.",\alpha \alpha\wedge(d\alpha)^n M M \alpha\wedge(d\alpha)^n\not=0 \alpha \xi=\ker\alpha \lambda\alpha \lambda:M\rightarrow\mathbb R\setminus\{0\} (\lambda\alpha)\wedge d((\lambda\alpha))^n=\lambda\alpha\wedge(\lambda d\alpha+d\lambda\wedge\alpha)^n=\lambda^{n+1}\alpha\wedge(d\alpha)^n\not=0\text{.} \alpha M M (2n+1) (d\alpha)^n n d\alpha\wedge\dots\wedge d\alpha \lambda\alpha\wedge(\lambda d\alpha+d\lambda\wedge\alpha)^n=\lambda^{n+1}\alpha\wedge(d\alpha)^n? d\lambda\wedge\alpha=0,"['differential-geometry', 'smooth-manifolds', 'differential-forms', 'orientation']"
64,An exercise on the Einstein tensor from Petersen's Riemannian geometry,An exercise on the Einstein tensor from Petersen's Riemannian geometry,,"This comes from Riemannian geometry , Peter Petersen, Exercise 3.4.16. Consider the $(0,2)$ -tensor $ T = \operatorname{Ric} + b \operatorname{scal} g + cg $ where $b, c\in \mathbb R$ . Show that $\nabla^* T=0$ if $b=-\frac{1}{2}$ . The tensor $G = \operatorname{Ric} - \frac{1}{2} \operatorname{scal} g +cg$ is known as the  Einstein tensor, and $c$ as the cosmological constant. Show that if $c=0$ , then $G=0$ in dimension 2. When $n>2$ show that if $G=0$ , then the metric is an Einstein metric. When $n>2$ show that if $G=0$ and $c=0$ , then the metric is Ricci flat, i.e. $\operatorname{Ric} \equiv 0$ . For 2, I've done this so far and I just want to make sure it's right: In dimension 2, $$ \sec \left(e_1, e_2\right)=R_{1221}=\left\langle\operatorname{Ric}\left(e_1\right), e_1\right\rangle=\left\langle\operatorname{Ric}\left(e_2\right), e_2\right\rangle, $$ where $e_1, e_2$ orthonormal at a given point $p$ of $M$ . Thus $$ \begin{gathered} G\left(e_1\right)=\operatorname{Ric}\left(e_1\right)-\frac{\text { scal }}{2} e_1=R_{1221} e_1-R_{1221} e_1=0, \\ G\left(e_2\right)=\cdots=0 . \end{gathered} $$ and for part 4,if $G=0$ , then Ric $=\frac{\text { scal }}{2} \cdot I$ , taking contractions imply that $$ \text {scal }=\frac{n}{2} \text { scal, } $$ thus if $n \geq 3, s c a l=0$ , Ric $=\frac{s c a l}{2} \cdot g=0$ I'd appreciate it if you can lmk if I'm on the right track for 2, and 4 and help me with 1 and 3.","This comes from Riemannian geometry , Peter Petersen, Exercise 3.4.16. Consider the -tensor where . Show that if . The tensor is known as the  Einstein tensor, and as the cosmological constant. Show that if , then in dimension 2. When show that if , then the metric is an Einstein metric. When show that if and , then the metric is Ricci flat, i.e. . For 2, I've done this so far and I just want to make sure it's right: In dimension 2, where orthonormal at a given point of . Thus and for part 4,if , then Ric , taking contractions imply that thus if , Ric I'd appreciate it if you can lmk if I'm on the right track for 2, and 4 and help me with 1 and 3.","(0,2) 
T = \operatorname{Ric} + b \operatorname{scal} g + cg
 b, c\in \mathbb R \nabla^* T=0 b=-\frac{1}{2} G = \operatorname{Ric} - \frac{1}{2} \operatorname{scal} g +cg c c=0 G=0 n>2 G=0 n>2 G=0 c=0 \operatorname{Ric} \equiv 0 
\sec \left(e_1, e_2\right)=R_{1221}=\left\langle\operatorname{Ric}\left(e_1\right), e_1\right\rangle=\left\langle\operatorname{Ric}\left(e_2\right), e_2\right\rangle,
 e_1, e_2 p M 
\begin{gathered}
G\left(e_1\right)=\operatorname{Ric}\left(e_1\right)-\frac{\text { scal }}{2} e_1=R_{1221} e_1-R_{1221} e_1=0, \\
G\left(e_2\right)=\cdots=0 .
\end{gathered}
 G=0 =\frac{\text { scal }}{2} \cdot I 
\text {scal }=\frac{n}{2} \text { scal, }
 n \geq 3, s c a l=0 =\frac{s c a l}{2} \cdot g=0",['differential-geometry']
65,"If metric circles on a surface are genuine circles, must the surface be sphere?","If metric circles on a surface are genuine circles, must the surface be sphere?",,"A moment's thought (or some careful examination of maps) reveals that any circle drawn on a globe is in fact a circle in real life.  The same claim holds for circles drawn on flat surfaces (obviously). Are these the only examples? Formally, let $M$ be any Riemannian surface, (isometrically) embedded in $\mathbb{R}^n$ .  Moreover, suppose that any metric circle $C$ (i.e., a locus of points with constant geodesic distance from some fixed point) is in fact a circle in $\mathbb{R}^n$ .  Then must $M$ have constant nonnegative Gaussian curvature?","A moment's thought (or some careful examination of maps) reveals that any circle drawn on a globe is in fact a circle in real life.  The same claim holds for circles drawn on flat surfaces (obviously). Are these the only examples? Formally, let be any Riemannian surface, (isometrically) embedded in .  Moreover, suppose that any metric circle (i.e., a locus of points with constant geodesic distance from some fixed point) is in fact a circle in .  Then must have constant nonnegative Gaussian curvature?",M \mathbb{R}^n C \mathbb{R}^n M,"['differential-geometry', 'circles', 'spherical-geometry']"
66,"Question on gauge fields ""acting on different representations""","Question on gauge fields ""acting on different representations""",,"- First of all, in the end of this question, unfortunatelly, I'll kind of request the solution of an exercise. But, this isn't for any kind of classroom evaluation. It is just that I kind of grasp the heuristic picture, but I don't know how to perform the technical calculations, due to my poor knowledge on lie algebra and lie group theory. I'm following the text book $[1]$ . The question is written in section VII $)$ , on equation $(8)$ . Now, standard model of particle physics is a (chiral) gauge theory . Therefore, it is a theory which is enconded in the language of Principal fiber bundles and associated fibre bundles. I will write a series of topics that explain better my problem here. I) Connection $1$ - $\mathrm{forms}$ Now, in Salam-Weinberg model, the gauge group of the theory is $G =  SU(2)_{L} \times U(1)_{Y}$ . The connection constructed in the principal bundle, the $(SU(2)_{L} \times U(1)_{Y})$ - $\mathrm{bundle}$ , is the connection $1$ - $\mathrm{form}$ : $$A = W + B.\tag{1}$$ $A$ is not the electromagnetic gauge field, rather, the connection $1$ - $\mathrm{form}$ of the principal bundle. $W$ is the weak gauge field and $B$ the hypercharge gauge field. II) Local Connection $1$ - $\mathrm{forms}$ A local version of $(1)$ (the local gauge field) that ""puts the gauge field on spacetime"" is given by: $$A_{s} = s^{*}A.\tag{2}$$ Where, $s$ is a section on the principal bundle (the local gauge choice), and the $s^{*}$ is the pullback of the section (when we apply this map on $A$ , we bring the information of the gauge field for a region located on the base manifold $\mathcal{M}$ ). Furthermore, since our algebraic landscape deals with groups and lie groups, the action of $A_{s}$ on a vector field $X \in T_{p}\mathcal{M}$ lies on the lie algebra: $A_{s}(X) \in \mathfrak{g}$ . III) Representations, Spinors and Multiplets The map, $\rho: G \to GL(V)$ is the representation of the Lie group (gauge group)  Therefore, using this map we produce matrices that acts on vectors of a vector space $V$ . Furthermore, given a representation $\rho$ , it is possible to define its differential representation: $$\rho_{*}: \mathfrak{g} \to \mathrm{End}(V),$$ where the operation $\cdot_{*}$ is the pushfoward. The necessity of dealing with spinors as multiplets introduces a algebraic structure called: ""Twisted Spinor Bundle"" $[1]$ : $$TS = S \otimes E = S \otimes (P\times_{\rho}V). \tag{3}$$ Where, S is the spinor bundle, and E the associated bundle (the $P$ is the principal bundle and $\rho: G \to GL(V)$ the representation). The tensor structure $(3)$ tells us: ""we have spinor fields in $S$ and the fact that we construct a tensor product with $E$ we construct the well-known multiplets $\psi$ "". Actually, Twisted Spinor Bundles are also called Gauge Multiplet Spinor Bundles . IV) Covariant Derivatives 1 In $(3)$ we can construct the covariant derivative of the theory acting on multiplets (spinors) as: $$D^{A}_{\mu}\psi = \partial_{\mu}\psi + \rho_{*}(A_{s}(X))\psi = \partial_{\mu}\psi - \frac{ig}{2}W^{a}_{\mu}\sigma_{a}\psi - \frac{ig'}{2}B_{\mu}\psi. \tag{4}$$ V) Chirality An important feature of the standard model is its chirality. Following $[1]$ , this means that the whole twisted spinor bundles ""slipts"" in right part $R$ and left part $L$ as: $$ S \otimes E = (S_{L} \otimes E_{L}) \oplus (S_{R} \otimes E_{R}). \tag{5} $$ The spinor field notion is then defined with the one observes that first $S$ splits as $S_R\oplus S_L$ and that we are hence free to define a field $\psi_R$ as a section of some $S_R \otimes E_R$ and a field $\psi_L$ as a section of some $S_L \otimes E_L$ where $E_R$ and $E_L$ have no a priori relation. Then we define $\psi = \psi_R \oplus \psi_L$ The structure $(5)$ is called ""Twisted Chiral Spinor Bundle"". Due to this mathematical structure, and knowing that $E_{L}$ and $E_{R}$ depends on representations. There are two (possibly distinct) representations of $G$ on complex vector spaces $V_{R}$ and $V_{L}$ , i.e., the whole formal bundle that I'm talking about is (with all structures explicitly showed): $$TS_{\mathrm{chiral}} = S \otimes E = (S_{L} \otimes E_{L}) \oplus (S_{R} \otimes E_{R})  = (S_{L} \otimes (P\times_{\rho_{L}}V_{L})) \oplus (S_{R} \otimes (P\times_{\rho_{R}}V_{R})). \tag{6}$$ The map, $\rho_{L}: G \to GL(V_{L})$ is the representation of the Lie group (gauge group), that produce matrices that acts on vectors of a vector space $V_{L}$ . Similarly, the map, $\rho_{R}: G \to GL(V_{R})$ is the representation of the Lie group (gauge group), that produce matrices that acts on vectors of a vector space $V_{R}$ . Therefore, we have two distinct induced representations as well: $\rho_{L*}: \mathfrak{g} \to \mathrm{End}(V_{L})$ and $\rho_{R*}: \mathfrak{g} \to \mathrm{End}(V_{R})$ . VI) Covariant Derivatives 2 In same fashion, we can construct the covariant derivative of the theory acting on chiral multiplets (spinors) as: $$D^{A}_{\mu}\psi= \partial_{\mu}\psi + \rho_{L*}(A_{s}(X))\psi_{L} + \rho_{R*}(A_{s}(X))\psi_{R} \implies$$ $$D^{A}_{\mu}\psi \equiv D^{A}_{\mu}(\psi_{L} + \psi_{R}) =\partial_{\mu}\psi_{L} + \rho_{L*}(A_{s}(X))\psi_{L} + \partial_{\mu}\psi_{R} + \rho_{R*}(A_{s}(X))\psi_{R}\tag{7}$$ VII) My Question Explicitly, I have the following data: $G = SU(2)_{L} \times U(1)_{Y}$ $\mathfrak{g} = \mathfrak{su}(2)_{L} \oplus \mathfrak{u}(1)_{Y}$ $V_{L} = \mathbb{C}_{L}^2 \otimes \mathbb{C}_{Y}$ $V_{R} = \mathbb{C}_{L} \otimes \mathbb{C}_{Y}$ The subscripts are nothing but labels, the $\mathbb{C}$ 's are your standard linear algebra complex vector spaces. Also, for your convenience: $\rho_{L*}:\mathfrak{su}(2)_{L} \oplus \mathfrak{u}(1)_{Y} \to \mathrm{End}(\mathbb{C}_{L}^2 \otimes \mathbb{C}_{Y})$ $\rho_{R*}:\mathfrak{su}(2)_{L} \oplus \mathfrak{u}(1)_{Y} \to \mathrm{End}(\mathbb{C}_{L} \otimes \mathbb{C}_{Y})$ So my question is: how can I show the explicit calculation (i.e. could you please write the calculation) that: $$\rho_{R*}(A_{s}(X)) = \rho_{R*}(W_{s}(X)+B_{s}(X)) = \rho_{R*}(W_{s}(X))+\rho_{R*}(B_{s}(X)) = \rho_{R*}(B_{s}(X))? \tag{8}$$ There are three different, but equivalent, ways to ask question: $1)$ Exercise $8.11.8$ of $[1]$ , page $525$ . $2)$ What happens, explicitly, with $\rho_{R*}(W_{s}(X))$ ? I mean, this term seems to simply ""vanish"". $3)$ In physics (local chart) language: concerning the gauge group of Salam-Weinberg theory, how can I show that: $$\rho_{L*}(A_{s}(X)) = - \frac{ig}{2}W^{a}_{\mu}\sigma_{a} - \frac{ig'}{2}B_{\mu} \tag{9}$$ and $$\rho_{R*}(A_{s}(X))= - \frac{ig'}{2}B_{\mu}?\tag{10}$$ Where $\sigma_{a}$ are the Pauli Matrices . $[1]$ Mark J.D. Hamilton Mathematical Gauge Theory , Springer, 2017.","- First of all, in the end of this question, unfortunatelly, I'll kind of request the solution of an exercise. But, this isn't for any kind of classroom evaluation. It is just that I kind of grasp the heuristic picture, but I don't know how to perform the technical calculations, due to my poor knowledge on lie algebra and lie group theory. I'm following the text book . The question is written in section VII , on equation . Now, standard model of particle physics is a (chiral) gauge theory . Therefore, it is a theory which is enconded in the language of Principal fiber bundles and associated fibre bundles. I will write a series of topics that explain better my problem here. I) Connection - Now, in Salam-Weinberg model, the gauge group of the theory is . The connection constructed in the principal bundle, the - , is the connection - : is not the electromagnetic gauge field, rather, the connection - of the principal bundle. is the weak gauge field and the hypercharge gauge field. II) Local Connection - A local version of (the local gauge field) that ""puts the gauge field on spacetime"" is given by: Where, is a section on the principal bundle (the local gauge choice), and the is the pullback of the section (when we apply this map on , we bring the information of the gauge field for a region located on the base manifold ). Furthermore, since our algebraic landscape deals with groups and lie groups, the action of on a vector field lies on the lie algebra: . III) Representations, Spinors and Multiplets The map, is the representation of the Lie group (gauge group)  Therefore, using this map we produce matrices that acts on vectors of a vector space . Furthermore, given a representation , it is possible to define its differential representation: where the operation is the pushfoward. The necessity of dealing with spinors as multiplets introduces a algebraic structure called: ""Twisted Spinor Bundle"" : Where, S is the spinor bundle, and E the associated bundle (the is the principal bundle and the representation). The tensor structure tells us: ""we have spinor fields in and the fact that we construct a tensor product with we construct the well-known multiplets "". Actually, Twisted Spinor Bundles are also called Gauge Multiplet Spinor Bundles . IV) Covariant Derivatives 1 In we can construct the covariant derivative of the theory acting on multiplets (spinors) as: V) Chirality An important feature of the standard model is its chirality. Following , this means that the whole twisted spinor bundles ""slipts"" in right part and left part as: The spinor field notion is then defined with the one observes that first splits as and that we are hence free to define a field as a section of some and a field as a section of some where and have no a priori relation. Then we define The structure is called ""Twisted Chiral Spinor Bundle"". Due to this mathematical structure, and knowing that and depends on representations. There are two (possibly distinct) representations of on complex vector spaces and , i.e., the whole formal bundle that I'm talking about is (with all structures explicitly showed): The map, is the representation of the Lie group (gauge group), that produce matrices that acts on vectors of a vector space . Similarly, the map, is the representation of the Lie group (gauge group), that produce matrices that acts on vectors of a vector space . Therefore, we have two distinct induced representations as well: and . VI) Covariant Derivatives 2 In same fashion, we can construct the covariant derivative of the theory acting on chiral multiplets (spinors) as: VII) My Question Explicitly, I have the following data: The subscripts are nothing but labels, the 's are your standard linear algebra complex vector spaces. Also, for your convenience: So my question is: how can I show the explicit calculation (i.e. could you please write the calculation) that: There are three different, but equivalent, ways to ask question: Exercise of , page . What happens, explicitly, with ? I mean, this term seems to simply ""vanish"". In physics (local chart) language: concerning the gauge group of Salam-Weinberg theory, how can I show that: and Where are the Pauli Matrices . Mark J.D. Hamilton Mathematical Gauge Theory , Springer, 2017.","[1] ) (8) 1 \mathrm{forms} G =  SU(2)_{L} \times U(1)_{Y} (SU(2)_{L} \times U(1)_{Y}) \mathrm{bundle} 1 \mathrm{form} A = W + B.\tag{1} A 1 \mathrm{form} W B 1 \mathrm{forms} (1) A_{s} = s^{*}A.\tag{2} s s^{*} A \mathcal{M} A_{s} X \in T_{p}\mathcal{M} A_{s}(X) \in \mathfrak{g} \rho: G \to GL(V) V \rho \rho_{*}: \mathfrak{g} \to \mathrm{End}(V), \cdot_{*} [1] TS = S \otimes E = S \otimes (P\times_{\rho}V). \tag{3} P \rho: G \to GL(V) (3) S E \psi (3) D^{A}_{\mu}\psi = \partial_{\mu}\psi + \rho_{*}(A_{s}(X))\psi = \partial_{\mu}\psi - \frac{ig}{2}W^{a}_{\mu}\sigma_{a}\psi - \frac{ig'}{2}B_{\mu}\psi. \tag{4} [1] R L  S \otimes E = (S_{L} \otimes E_{L}) \oplus (S_{R} \otimes E_{R}). \tag{5}  S S_R\oplus S_L \psi_R S_R \otimes E_R \psi_L S_L \otimes E_L E_R E_L \psi = \psi_R \oplus \psi_L (5) E_{L} E_{R} G V_{R} V_{L} TS_{\mathrm{chiral}} = S \otimes E = (S_{L} \otimes E_{L}) \oplus (S_{R} \otimes E_{R})  = (S_{L} \otimes (P\times_{\rho_{L}}V_{L})) \oplus (S_{R} \otimes (P\times_{\rho_{R}}V_{R})). \tag{6} \rho_{L}: G \to GL(V_{L}) V_{L} \rho_{R}: G \to GL(V_{R}) V_{R} \rho_{L*}: \mathfrak{g} \to \mathrm{End}(V_{L}) \rho_{R*}: \mathfrak{g} \to \mathrm{End}(V_{R}) D^{A}_{\mu}\psi= \partial_{\mu}\psi + \rho_{L*}(A_{s}(X))\psi_{L} + \rho_{R*}(A_{s}(X))\psi_{R} \implies D^{A}_{\mu}\psi \equiv D^{A}_{\mu}(\psi_{L} + \psi_{R}) =\partial_{\mu}\psi_{L} + \rho_{L*}(A_{s}(X))\psi_{L} + \partial_{\mu}\psi_{R} + \rho_{R*}(A_{s}(X))\psi_{R}\tag{7} G = SU(2)_{L} \times U(1)_{Y} \mathfrak{g} = \mathfrak{su}(2)_{L} \oplus \mathfrak{u}(1)_{Y} V_{L} = \mathbb{C}_{L}^2 \otimes \mathbb{C}_{Y} V_{R} = \mathbb{C}_{L} \otimes \mathbb{C}_{Y} \mathbb{C} \rho_{L*}:\mathfrak{su}(2)_{L} \oplus \mathfrak{u}(1)_{Y} \to \mathrm{End}(\mathbb{C}_{L}^2 \otimes \mathbb{C}_{Y}) \rho_{R*}:\mathfrak{su}(2)_{L} \oplus \mathfrak{u}(1)_{Y} \to \mathrm{End}(\mathbb{C}_{L} \otimes \mathbb{C}_{Y}) \rho_{R*}(A_{s}(X)) = \rho_{R*}(W_{s}(X)+B_{s}(X)) = \rho_{R*}(W_{s}(X))+\rho_{R*}(B_{s}(X)) = \rho_{R*}(B_{s}(X))? \tag{8} 1) 8.11.8 [1] 525 2) \rho_{R*}(W_{s}(X)) 3) \rho_{L*}(A_{s}(X)) = - \frac{ig}{2}W^{a}_{\mu}\sigma_{a} - \frac{ig'}{2}B_{\mu} \tag{9} \rho_{R*}(A_{s}(X))= - \frac{ig'}{2}B_{\mu}?\tag{10} \sigma_{a} [1]","['differential-geometry', 'lie-algebras', 'physics', 'connections', 'gauge-theory']"
67,Torsion Free Spin Connection,Torsion Free Spin Connection,,"Ok I am not exactly sure how much of this common notation/terminology, and how much is unique to the book I'm reading, so bear with me for a moment here. First we have a vector bundle $E$ associated to the orthonormal frame bundle of some manifold $M$ . There is a soldering form, an isomorphism from $TM\rightarrow E$ , given by a collection of one forms $e^I$ (equivalently a vector valued one form): $$e^I=e^I_\mu dx^\mu$$ where $I$ is an index $I=1,\dots,n$ . This encodes a riemannian metric on $M$ via: $$g(v,u):=\langle e^I(u),e^I(v)\rangle=g_{\mu\nu}=e^I_\mu e^J_\nu \delta_{IJ}$$ A metric connection on $E$ then satisfies the following property: $$d^\omega\delta^{IJ}=\omega^I_K\delta^{KJ}+\omega^J_K\delta^{KI}=0$$ Which is really just the condition that $\omega^i_j=-\omega^j_i$ , or, equivalently, that $\omega$ is a one form with values in $\mathfrak{o}(n)$ . Torsion is then defined as: $$T^I:=d^\omega e^I=de^I+\omega^I_Je^J$$ I am pretty sure I am fine with all of this, but this next jump is a calculation that I haven't been able to follow: given the soldering form, there exists a unique metric and torsion free connection given by: $$ \omega^I_{\mu J}=e^{\rho I}e_J^{\sigma}\left(-C_{\mu\rho\sigma}+C_{\rho\sigma\mu}+C_{\sigma\mu\rho}\right) $$ Where: $$C_{\mu\rho\sigma}=e_{\mu I}\partial_{[\rho}e^I_{\sigma]}$$ The object $e^\mu_I$ is the inverse of the soldering form defined as $e^\mu_Ie^J_\mu=\delta^J_I$ , and $e^\mu_Ie^I_\nu=\delta^\mu_\nu$ . I am a little confused as to what the objects $e^{\rho I}$ and $e_{\mu I}$ are. In principal I know what this calculation is, it's essentially the equivalent of the formula for the Christoffel symbols in the levi-civita connection, however deriving this in this gauge theory esque framework as proved troublesome. I figured I should just set $T^I$ equal to zero and use $\omega^I_J=-\omega^J_I$ at some point to get the components of the connection, but this has not worked. I first wrote everything explicitly, and examined the $i$ th component of $T^I$ : $$ T^i=d(e^i_\mu dx^\mu)+\omega^i_{\nu j}e^j_\mu dx^\nu\wedge dx^\mu $$ Carrying out the exterior derivative of the first term we obtain: $$ T^i=\partial_\nu e^i_\mu dx^\nu\wedge dx^\mu+\omega^i_{\nu j}e^j_\mu dx^\nu\wedge dx^\mu $$ Contracting $T^i$ with the coordinate vector fields $\partial_\mu$ and $\partial_\nu$ we obtain: $$ i_{\partial_\nu}\left(i_{\partial_\mu}T^i\right)=\partial_\nu e^i_\mu-\partial_\mu e^i_\nu+\omega^i_{\mu j}e^j_\nu-\omega^i_{\nu j}e^j_\mu $$ Setting this equal to zero I thought I could do something to solve for $\omega^i_{\mu j}$ , but everything I think of doing doesn't pan out, which suggests to me that I'm attacking this the incorrect way. Any advice or hints would be greatly appreciated. Edit: I am now convinced I need to use the following coordinate invariant koszul formula: $$2g(\nabla_X Y,Z)=Xg(Y,Z)+Yg(Z,X)-Zg(X,Y)-g(X,[Y,Z])+g(Y,[Z,X])+g(Z,[Y,X])$$ But I am not quite sure how to translate it in this frame work. When finding the components of the levi civita connection you just let $X=\partial_i,Y=\partial_j,Z=\partial_k$ but I am not sure what I should let $X,Y,Z$ be since I don't feel like I can use the coordinate vector fields. Could I just let $e_i$ be the standard basis vectors on $\mathbb{R}^m$ and then set $X=e_\mu^ie_i, Y=e_\nu^ie_i, Z=e_\eta^ie_i$ ? Or should I should let $e^I_u$ denote a basis vector and have $\left(\nabla_{e^I_\nu} e^I_\mu\right)^j=\omega^j_{\nu I} e^I_\mu$ ?","Ok I am not exactly sure how much of this common notation/terminology, and how much is unique to the book I'm reading, so bear with me for a moment here. First we have a vector bundle associated to the orthonormal frame bundle of some manifold . There is a soldering form, an isomorphism from , given by a collection of one forms (equivalently a vector valued one form): where is an index . This encodes a riemannian metric on via: A metric connection on then satisfies the following property: Which is really just the condition that , or, equivalently, that is a one form with values in . Torsion is then defined as: I am pretty sure I am fine with all of this, but this next jump is a calculation that I haven't been able to follow: given the soldering form, there exists a unique metric and torsion free connection given by: Where: The object is the inverse of the soldering form defined as , and . I am a little confused as to what the objects and are. In principal I know what this calculation is, it's essentially the equivalent of the formula for the Christoffel symbols in the levi-civita connection, however deriving this in this gauge theory esque framework as proved troublesome. I figured I should just set equal to zero and use at some point to get the components of the connection, but this has not worked. I first wrote everything explicitly, and examined the th component of : Carrying out the exterior derivative of the first term we obtain: Contracting with the coordinate vector fields and we obtain: Setting this equal to zero I thought I could do something to solve for , but everything I think of doing doesn't pan out, which suggests to me that I'm attacking this the incorrect way. Any advice or hints would be greatly appreciated. Edit: I am now convinced I need to use the following coordinate invariant koszul formula: But I am not quite sure how to translate it in this frame work. When finding the components of the levi civita connection you just let but I am not sure what I should let be since I don't feel like I can use the coordinate vector fields. Could I just let be the standard basis vectors on and then set ? Or should I should let denote a basis vector and have ?","E M TM\rightarrow E e^I e^I=e^I_\mu dx^\mu I I=1,\dots,n M g(v,u):=\langle e^I(u),e^I(v)\rangle=g_{\mu\nu}=e^I_\mu e^J_\nu \delta_{IJ} E d^\omega\delta^{IJ}=\omega^I_K\delta^{KJ}+\omega^J_K\delta^{KI}=0 \omega^i_j=-\omega^j_i \omega \mathfrak{o}(n) T^I:=d^\omega e^I=de^I+\omega^I_Je^J 
\omega^I_{\mu J}=e^{\rho I}e_J^{\sigma}\left(-C_{\mu\rho\sigma}+C_{\rho\sigma\mu}+C_{\sigma\mu\rho}\right)
 C_{\mu\rho\sigma}=e_{\mu I}\partial_{[\rho}e^I_{\sigma]} e^\mu_I e^\mu_Ie^J_\mu=\delta^J_I e^\mu_Ie^I_\nu=\delta^\mu_\nu e^{\rho I} e_{\mu I} T^I \omega^I_J=-\omega^J_I i T^I 
T^i=d(e^i_\mu dx^\mu)+\omega^i_{\nu j}e^j_\mu dx^\nu\wedge dx^\mu
 
T^i=\partial_\nu e^i_\mu dx^\nu\wedge dx^\mu+\omega^i_{\nu j}e^j_\mu dx^\nu\wedge dx^\mu
 T^i \partial_\mu \partial_\nu 
i_{\partial_\nu}\left(i_{\partial_\mu}T^i\right)=\partial_\nu e^i_\mu-\partial_\mu e^i_\nu+\omega^i_{\mu j}e^j_\nu-\omega^i_{\nu j}e^j_\mu
 \omega^i_{\mu j} 2g(\nabla_X Y,Z)=Xg(Y,Z)+Yg(Z,X)-Zg(X,Y)-g(X,[Y,Z])+g(Y,[Z,X])+g(Z,[Y,X]) X=\partial_i,Y=\partial_j,Z=\partial_k X,Y,Z e_i \mathbb{R}^m X=e_\mu^ie_i, Y=e_\nu^ie_i, Z=e_\eta^ie_i e^I_u \left(\nabla_{e^I_\nu} e^I_\mu\right)^j=\omega^j_{\nu I} e^I_\mu","['differential-geometry', 'differential-topology', 'connections', 'gauge-theory', 'cartan-geometry']"
68,Is it possible to realize the Moebius strip as a linear group orbit?,Is it possible to realize the Moebius strip as a linear group orbit?,,"Is the Moebius strip a linear group orbit? In other words: Does there exists a Lie group $ G $ , a representation $ \pi: G \to GL(V) $ , and a vector $ v \in V $ such that the orbit $$ \mathcal{O}_v=\{ \pi(g)v: g\in G  \}  $$ is diffeomorphic to the Moebius strip? My thoughts so far: The only two obstructions I know for being a linear group orbit is that the manifold (1) must be smooth homogeneous (shown below for the the group $ SE_2 $ ) and (2) must be a vector bundle over a compact Riemannian homogeneous manifold (here the base is the circle $ S^1 $ ). The Moebius strip is homogeneous for the special Euclidean group of the plane $$ SE_2= \left \{ \ \begin{bmatrix} a & b & x \\ -b & a & y \\ 0 & 0 & 1  \end{bmatrix} : a^2+b^2=1 \right \}  $$ there is a connected group $ V $ of translations up each vertical line $$ V= \left \{ \  \begin{bmatrix} 1 & 0 & 0 \\ 0 & 1 & y \\ 0 & 0 & 1  \end{bmatrix} : y \in \mathbb{R} \right \}  $$ Now if we include the rotation by 180 degrees $$ \tau:=\begin{bmatrix} -1 & 0 & 0 \\ 0 & -1 & 0 \\ 0 & 0 & 1  \end{bmatrix} $$ Then $ \langle V, \tau \rangle$ has two connected components and $$ SE_2 \mathbin{/} \langle V, \tau \rangle $$ is the Moebius strip. Indeed if we consider the model of the Moebius strip as the manifold of affine lines in the plane then the subgroup $ <V,\tau> $ is exactly the stabilizer of the $ y $ -axis.","Is the Moebius strip a linear group orbit? In other words: Does there exists a Lie group , a representation , and a vector such that the orbit is diffeomorphic to the Moebius strip? My thoughts so far: The only two obstructions I know for being a linear group orbit is that the manifold (1) must be smooth homogeneous (shown below for the the group ) and (2) must be a vector bundle over a compact Riemannian homogeneous manifold (here the base is the circle ). The Moebius strip is homogeneous for the special Euclidean group of the plane there is a connected group of translations up each vertical line Now if we include the rotation by 180 degrees Then has two connected components and is the Moebius strip. Indeed if we consider the model of the Moebius strip as the manifold of affine lines in the plane then the subgroup is exactly the stabilizer of the -axis."," G   \pi: G \to GL(V)   v \in V  
\mathcal{O}_v=\{ \pi(g)v: g\in G  \} 
  SE_2   S^1  
SE_2= \left \{ \
\begin{bmatrix}
a & b & x \\
-b & a & y \\
0 & 0 & 1 
\end{bmatrix} : a^2+b^2=1 \right \} 
  V  
V= \left \{ \ 
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & y \\
0 & 0 & 1 
\end{bmatrix} : y \in \mathbb{R} \right \} 
 
\tau:=\begin{bmatrix}
-1 & 0 & 0 \\
0 & -1 & 0 \\
0 & 0 & 1 
\end{bmatrix}
  \langle V, \tau \rangle 
SE_2 \mathbin{/} \langle V, \tau \rangle
  <V,\tau>   y ","['differential-geometry', 'representation-theory', 'lie-groups', 'geometric-topology', 'algebraic-groups']"
69,Counterexample to Kunneth Formula,Counterexample to Kunneth Formula,,"I'm reading Example 9.14 of Bott&Tu's Differential Forms in Algebraic Topology, which gave a counter example to the Kunneth formula when the assumption is not satisfied by constructing manifolds $M$ and $F$ such that $H^0(M\times F)$ is naturally isomorphic to $\mathbb{R}^{\mathbb{Z}\times\mathbb{Z}}$ while $H^0(M)\otimes H^0(F)$ is naturally isomrophic to $\mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}}$ . I can see that these two are not naturally isomorphic via the explicit mapping in Kunneth formula. But if one ommit the explicit mapping in the statement of Kunneth formula, then a counterexample in degree $0$ needs $H^0(M\times F) \not\cong H^0(M)\otimes H^0(F)$ as real vector spaces. So I wish to figure out if $\mathbb{R}^{\mathbb{Z}\times\mathbb{Z}}$ is isomorphic to $\mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}}$ as vector spaces. The counterexample would appear to be more perfect to me if they are not isomorphic. Two vector spaces are isomorphic if and only if their basis have a same cardinality. Since there is a natural embedding $\mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}}\hookrightarrow \mathbb{R}^{\mathbb{Z}\times\mathbb{Z}}$ , the cardinality of basis of $\mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}}$ is no larger than $\mathbb{R}^{\mathbb{Z}\times\mathbb{Z}}$ . On the other hand, we have $\mathbb{R}^\mathbb{Z\times Z}\cong \mathbb{R}^\mathbb{Z}$ by re-indexing $\mathbb{Z}\times \mathbb{Z}\cong\mathbb{Z}$ , and then $\mathbb{R}^\mathbb{Z}\hookrightarrow \mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}}:v\mapsto v\otimes 1$ is an embedding, concluding that $\mathbb{R}^{\mathbb{Z\times Z}}\cong \mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}}$ . Is my above argument correct? If so, is there any other counterexample to Kunneth formula, with $H^*(M\times F)\not\cong H^*(M)\otimes H^*(F)$ as real vector spaces in some degree? Thanks in advance.","I'm reading Example 9.14 of Bott&Tu's Differential Forms in Algebraic Topology, which gave a counter example to the Kunneth formula when the assumption is not satisfied by constructing manifolds and such that is naturally isomorphic to while is naturally isomrophic to . I can see that these two are not naturally isomorphic via the explicit mapping in Kunneth formula. But if one ommit the explicit mapping in the statement of Kunneth formula, then a counterexample in degree needs as real vector spaces. So I wish to figure out if is isomorphic to as vector spaces. The counterexample would appear to be more perfect to me if they are not isomorphic. Two vector spaces are isomorphic if and only if their basis have a same cardinality. Since there is a natural embedding , the cardinality of basis of is no larger than . On the other hand, we have by re-indexing , and then is an embedding, concluding that . Is my above argument correct? If so, is there any other counterexample to Kunneth formula, with as real vector spaces in some degree? Thanks in advance.",M F H^0(M\times F) \mathbb{R}^{\mathbb{Z}\times\mathbb{Z}} H^0(M)\otimes H^0(F) \mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}} 0 H^0(M\times F) \not\cong H^0(M)\otimes H^0(F) \mathbb{R}^{\mathbb{Z}\times\mathbb{Z}} \mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}} \mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}}\hookrightarrow \mathbb{R}^{\mathbb{Z}\times\mathbb{Z}} \mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}} \mathbb{R}^{\mathbb{Z}\times\mathbb{Z}} \mathbb{R}^\mathbb{Z\times Z}\cong \mathbb{R}^\mathbb{Z} \mathbb{Z}\times \mathbb{Z}\cong\mathbb{Z} \mathbb{R}^\mathbb{Z}\hookrightarrow \mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}}:v\mapsto v\otimes 1 \mathbb{R}^{\mathbb{Z\times Z}}\cong \mathbb{R}^{\mathbb{Z}}\otimes \mathbb{R}^{\mathbb{Z}} H^*(M\times F)\not\cong H^*(M)\otimes H^*(F),"['differential-geometry', 'algebraic-topology', 'differential-forms', 'de-rham-cohomology']"
70,"Are there holes in my road map from calculus to malliavin differential geometry, Bayesian hypergraphs, and causal inference?","Are there holes in my road map from calculus to malliavin differential geometry, Bayesian hypergraphs, and causal inference?",,"I've constructed a directed acyclic graph that leads from introductory subjects, such as calculus (single and multivariable) to some of my current interests including causal inference, Bayesian hypergraphs, and Malliavin differential geometry. The arcs indicate that something in one subject is required by another, with some relaxation in noting that there is transitivity across the graph. I've excluded set theory as too obvious and universal, and hypernetworks and simplicial complexes as merely borderline to my interests as of this moment. You can produce the diagram for yourself with the following code which is provided below. from graphviz import Digraph  g = Digraph()  # Calculus g.edge('Calculus', 'Real\nAnalysis') g.edge('Calculus', 'Topology') g.edge('Calculus', 'Differential\nEquations')  # Linear Algebra g.edge('Linear\nAlgebra', 'Differential\nEquations') g.edge('Linear\nAlgebra', 'Multilinear\nAlgebra')  # Abstract Algebra g.edge('Abstract\nAlgebra', 'Multilinear\nAlgebra')  # Real Analysis g.edge('Real\nAnalysis', 'Measure\nTheory')  # Topology g.edge('Topology', 'Measure\nTheory')  # Measure Theory g.edge('Measure\nTheory', 'Probability\nTheory')  # Probability Theory g.edge('Probability\nTheory', 'Bayesian\nProbability') g.edge('Probability\nTheory', 'Stochastic\nProcesses')  # Bayesian Probability g.edge('Bayesian\nProbability', 'Bayesian\nNetworks')  # Graph Theory g.edge('Graph\nTheory', 'Bayesian\nNetworks') g.edge('Graph\nTheory', 'Hypergraph\nTheory') g.edge('Bayesian\nProbability', 'Bayesian\nHypergraphs')  # Hypergraph Theory g.edge('Hypergraph\nTheory', 'Bayesian\nHypergraphs')  # Bayesian Networks g.edge('Bayesian\nNetworks', 'Causal\nInference')  # Stochastic Processes g.edge('Stochastic\nProcesses', 'Stochastic\nCalculus')  # Differential Equations g.edge('Differential\nEquations', 'Partial\nDifferential\nEquations') g.edge('Differential\nEquations', 'Stochastic\nCalculus')  # Partial Differential Equations g.edge('Partial\nDifferential\nEquations', 'Calculus\nof\nVariations') g.edge('Partial\nDifferential\nEquations', 'Differential\nGeometry')  # Stochastic Calculus g.edge('Stochastic\nCalculus', 'Stochastic\nDifferential\nEquations') g.edge('Stochastic\nCalculus', 'Stochastic\nDifferential\nGeometry')  # Stochastic Differential Equations g.edge('Stochastic\nDifferential\nEquations', 'Malliavin\nCalculus')  # Calculus of Variations g.edge('Calculus\nof\nVariations', 'Malliavin\nCalculus')  # Topology g.edge('Topology', 'Differential\nGeometry')  # Multilinear Algebra g.edge('Multilinear\nAlgebra', 'Differential\nGeometry')  # Differential Geometry g.edge('Differential\nGeometry', 'Stochastic\nDifferential\nGeometry')  # Malliavin Calculus g.edge('Malliavin\nCalculus', 'Malliavin\nDifferential\nGeometry')   # Stochastic Differential Geometry g.edge('Stochastic\nDifferential\nGeometry','Malliavin\nDifferential\nGeometry')   g.view() What I would like to know is if there are any subjects that I have left out. You're welcome to comment on other flaws in the DAG, and feel free to use the code to show me how you think it 'should' be structured in your answer, but I am primarily interested in missing subjects.","I've constructed a directed acyclic graph that leads from introductory subjects, such as calculus (single and multivariable) to some of my current interests including causal inference, Bayesian hypergraphs, and Malliavin differential geometry. The arcs indicate that something in one subject is required by another, with some relaxation in noting that there is transitivity across the graph. I've excluded set theory as too obvious and universal, and hypernetworks and simplicial complexes as merely borderline to my interests as of this moment. You can produce the diagram for yourself with the following code which is provided below. from graphviz import Digraph  g = Digraph()  # Calculus g.edge('Calculus', 'Real\nAnalysis') g.edge('Calculus', 'Topology') g.edge('Calculus', 'Differential\nEquations')  # Linear Algebra g.edge('Linear\nAlgebra', 'Differential\nEquations') g.edge('Linear\nAlgebra', 'Multilinear\nAlgebra')  # Abstract Algebra g.edge('Abstract\nAlgebra', 'Multilinear\nAlgebra')  # Real Analysis g.edge('Real\nAnalysis', 'Measure\nTheory')  # Topology g.edge('Topology', 'Measure\nTheory')  # Measure Theory g.edge('Measure\nTheory', 'Probability\nTheory')  # Probability Theory g.edge('Probability\nTheory', 'Bayesian\nProbability') g.edge('Probability\nTheory', 'Stochastic\nProcesses')  # Bayesian Probability g.edge('Bayesian\nProbability', 'Bayesian\nNetworks')  # Graph Theory g.edge('Graph\nTheory', 'Bayesian\nNetworks') g.edge('Graph\nTheory', 'Hypergraph\nTheory') g.edge('Bayesian\nProbability', 'Bayesian\nHypergraphs')  # Hypergraph Theory g.edge('Hypergraph\nTheory', 'Bayesian\nHypergraphs')  # Bayesian Networks g.edge('Bayesian\nNetworks', 'Causal\nInference')  # Stochastic Processes g.edge('Stochastic\nProcesses', 'Stochastic\nCalculus')  # Differential Equations g.edge('Differential\nEquations', 'Partial\nDifferential\nEquations') g.edge('Differential\nEquations', 'Stochastic\nCalculus')  # Partial Differential Equations g.edge('Partial\nDifferential\nEquations', 'Calculus\nof\nVariations') g.edge('Partial\nDifferential\nEquations', 'Differential\nGeometry')  # Stochastic Calculus g.edge('Stochastic\nCalculus', 'Stochastic\nDifferential\nEquations') g.edge('Stochastic\nCalculus', 'Stochastic\nDifferential\nGeometry')  # Stochastic Differential Equations g.edge('Stochastic\nDifferential\nEquations', 'Malliavin\nCalculus')  # Calculus of Variations g.edge('Calculus\nof\nVariations', 'Malliavin\nCalculus')  # Topology g.edge('Topology', 'Differential\nGeometry')  # Multilinear Algebra g.edge('Multilinear\nAlgebra', 'Differential\nGeometry')  # Differential Geometry g.edge('Differential\nGeometry', 'Stochastic\nDifferential\nGeometry')  # Malliavin Calculus g.edge('Malliavin\nCalculus', 'Malliavin\nDifferential\nGeometry')   # Stochastic Differential Geometry g.edge('Stochastic\nDifferential\nGeometry','Malliavin\nDifferential\nGeometry')   g.view() What I would like to know is if there are any subjects that I have left out. You're welcome to comment on other flaws in the DAG, and feel free to use the code to show me how you think it 'should' be structured in your answer, but I am primarily interested in missing subjects.",,"['differential-geometry', 'hypergraphs', 'malliavin-calculus', 'causality', 'causal-diagrams']"
71,Schouten theorem and doubts in the calculation of the tensor derivative,Schouten theorem and doubts in the calculation of the tensor derivative,,"I am working on the following theorem Theorem (J. A. Schouten) For $n\geq 4$ the metric $g$ is conformally flat if and only if $W=0$ . For $n=3$ , the metric $g$ is conformally flat if and only if the relation $$ (\nabla_X C) (Y, Z) = (\nabla_Y C) (X, Z)$$ holds for all $X, Y, Z$ . Here $C$ and $W$ denote the Schouten tensor and the Weyl tensor with $R=C\bullet g+W$ . I am following Theorem 8.31, pg. 352 in Differential Geometry: Curves - Surfaces - Manifolds by Wolfgang Kühnel. For the demonstration he uses the following derivation: $$d^\nabla A(X, Y, Z):= (\nabla_X A)(Y,Z) - (\nabla_Y A)(X, Z)$$ for an arbitrary symmetric (0,2)-tensor. So he concludes, for a scalar function $\varphi$ : \begin{eqnarray*} d^\nabla \nabla^{2} \varphi (X, Y, Z) &=& \left<R(X, Y)\text{grad}\varphi, Z \right>\\ d^\nabla\left( \nabla\varphi\cdot\nabla \varphi \right)(X, Y, Z) &=& (Y\varphi)\nabla^{2}\varphi(X, Z) - (X\varphi)\nabla^{2}\varphi(Y, Z)\\ d^\nabla\left(\frac{1}{2}\vert\vert \text{grad}\varphi\vert\vert\cdot g\right)(X,Y,Z) &=& \nabla^{2}\varphi (X,\text{grad}\varphi)\left<Y,Z\right>-\nabla^{2}\varphi(Y,\text{grad}\varphi)\left<X,Z\right> \end{eqnarray*} where $R$ is the curvature tensor. Similarly, for a one-form $\alpha=d\varphi$ he concludes: \begin{eqnarray*}  d^\nabla\alpha(X, Y, Z) &=& - \alpha(R(X, Y)Z)\\ d^\nabla(\alpha\cdot\alpha)(X,Y,Z) &=& d\alpha(X,Y)\alpha(Z)+\alpha(Y)\nabla\alpha(X,Z)-\alpha(X)\nabla\alpha(Y,Z)\\ d^\nabla\left(\frac{1}{2}\vert\vert \alpha\vert\vert^{2}\cdot g\right)(X,Y,Z) &=& \left<\nabla_X\alpha, \alpha\right>\left<Y,Z\right> - \left<\nabla_Y\alpha, \alpha\right>\left<X,Z\right> \end{eqnarray*} I am having difficulties in obtaining these six equalities above. I tried several times. For each of the identities above, the desired term appears but still contains some other terms that have not been canceled. I looked for other references that may present the proof of this theorem but I haven't found it. For the first equality, using the definition of $d^\nabla$ in $d^\nabla\nabla^{2}\varphi(X,Y,Z)$ , I got $$d^\nabla\nabla^{2}\varphi(X,Y,Z) = \left<R(X,Y)\text{grad}\varphi, Z\right>+\left<\nabla_{[X,Y]}\text{grad}\varphi, Z\right>+\left<\nabla_{Y}\text{grad}\varphi, \nabla_X Z\right>-\left<\nabla_{X}\text{grad}\varphi,\nabla_Y Z\right> $$ And for the second: $$ d^\nabla\left( \nabla\varphi\cdot\nabla \varphi \right)(X, Y, Z) = (Y\varphi)\nabla^{2}\varphi(X, Z) - (X\varphi)\nabla^{2}\varphi(Y, Z)+Z(\varphi)\left<\text{grad}\varphi, [X,Y] \right> +  Y(\varphi)\left<\text{grad}\varphi, \nabla_X Z\right>-X(\varphi)\left<\text{grad}\varphi, \nabla_Y Z \right>$$","I am working on the following theorem Theorem (J. A. Schouten) For the metric is conformally flat if and only if . For , the metric is conformally flat if and only if the relation holds for all . Here and denote the Schouten tensor and the Weyl tensor with . I am following Theorem 8.31, pg. 352 in Differential Geometry: Curves - Surfaces - Manifolds by Wolfgang Kühnel. For the demonstration he uses the following derivation: for an arbitrary symmetric (0,2)-tensor. So he concludes, for a scalar function : where is the curvature tensor. Similarly, for a one-form he concludes: I am having difficulties in obtaining these six equalities above. I tried several times. For each of the identities above, the desired term appears but still contains some other terms that have not been canceled. I looked for other references that may present the proof of this theorem but I haven't found it. For the first equality, using the definition of in , I got And for the second:","n\geq 4 g W=0 n=3 g  (\nabla_X C) (Y, Z) = (\nabla_Y C) (X, Z) X, Y, Z C W R=C\bullet g+W d^\nabla A(X, Y, Z):= (\nabla_X A)(Y,Z) - (\nabla_Y A)(X, Z) \varphi \begin{eqnarray*}
d^\nabla \nabla^{2} \varphi (X, Y, Z) &=& \left<R(X, Y)\text{grad}\varphi, Z \right>\\
d^\nabla\left( \nabla\varphi\cdot\nabla \varphi \right)(X, Y, Z) &=& (Y\varphi)\nabla^{2}\varphi(X, Z) - (X\varphi)\nabla^{2}\varphi(Y, Z)\\
d^\nabla\left(\frac{1}{2}\vert\vert \text{grad}\varphi\vert\vert\cdot g\right)(X,Y,Z) &=& \nabla^{2}\varphi (X,\text{grad}\varphi)\left<Y,Z\right>-\nabla^{2}\varphi(Y,\text{grad}\varphi)\left<X,Z\right>
\end{eqnarray*} R \alpha=d\varphi \begin{eqnarray*}
 d^\nabla\alpha(X, Y, Z) &=& - \alpha(R(X, Y)Z)\\
d^\nabla(\alpha\cdot\alpha)(X,Y,Z) &=& d\alpha(X,Y)\alpha(Z)+\alpha(Y)\nabla\alpha(X,Z)-\alpha(X)\nabla\alpha(Y,Z)\\
d^\nabla\left(\frac{1}{2}\vert\vert \alpha\vert\vert^{2}\cdot g\right)(X,Y,Z) &=& \left<\nabla_X\alpha, \alpha\right>\left<Y,Z\right> - \left<\nabla_Y\alpha, \alpha\right>\left<X,Z\right>
\end{eqnarray*} d^\nabla d^\nabla\nabla^{2}\varphi(X,Y,Z) d^\nabla\nabla^{2}\varphi(X,Y,Z) = \left<R(X,Y)\text{grad}\varphi, Z\right>+\left<\nabla_{[X,Y]}\text{grad}\varphi, Z\right>+\left<\nabla_{Y}\text{grad}\varphi, \nabla_X Z\right>-\left<\nabla_{X}\text{grad}\varphi,\nabla_Y Z\right>   d^\nabla\left( \nabla\varphi\cdot\nabla \varphi \right)(X, Y, Z) = (Y\varphi)\nabla^{2}\varphi(X, Z) - (X\varphi)\nabla^{2}\varphi(Y, Z)+Z(\varphi)\left<\text{grad}\varphi, [X,Y] \right> +  Y(\varphi)\left<\text{grad}\varphi, \nabla_X Z\right>-X(\varphi)\left<\text{grad}\varphi, \nabla_Y Z \right>","['differential-geometry', 'riemannian-geometry', 'tensors', 'curvature', 'tensor-decomposition']"
72,Computing a differential on the loop space of a Symplectic manifold,Computing a differential on the loop space of a Symplectic manifold,,"Suppose we have a symplectic manifold $(M,\omega)$ such that $\omega$ is exact ,i.e, $\omega=d\alpha$ .  Now let $L_0$ and $L_1$ be two lagrangian submanifolds and consider $\Omega(L_0,L_1)$ to be the set of smooth paths $\gamma:[0,1]\rightarrow M$ such that $\gamma(0)\in L_0$ and $\gamma(1)\in L_1$ .  Now the ""tangent space"" at a point of this space is just the space of vector fields $\xi(t)$ along that curve, such that $\xi(i)\in T_{\gamma(i)}L_i$ for $i=0,1$ . Define $A:\Omega(L_0,L_1)\rightarrow \mathbb{R}$ as $A(\gamma)=\int_{0}^{1}\gamma^*\alpha$ , in local coordinate we have $A(\gamma)=\int_{0}^{1}\alpha(\frac{\partial \gamma}{\partial t})dt$ . Now given a family of smooth almost-complex structures $J_t$ we have a canocanil family of riemannian metrics $g_t$ and can define the inner product in $\Omega(L_0,L_1)$ as $\langle v_1, v_2\rangle=\int_{0}^{1}g_t(v_1(t),v_2(t))dt$ . Now with this I would like to compute the gradient of $A$ . My attempt is the following : $dA_{\gamma}(\xi)=\frac{\partial }{\partial s}|_{s=0}A(c(s))$ , where $c(s):(-\epsilon,\epsilon)\rightarrow \Omega(L_0,L_1)$ such that $c(0)=\gamma$ and $\frac{\partial }{\partial s}|_{s=0}c(s,t)=\xi(t)$ , and this will be equal to $\int_{0}^{1} \frac{\partial }{\partial s}|_{s=0} \alpha(\frac{c(s,t)}{\partial t})dt$ , and now from here I don't know what to do. I belive the answer is supposed to be that $grad A(\gamma)=J_t\frac{\partial \gamma}{\partial t}$ , but I don't know how to get there. Any help is appreciated. Thanks in advance.","Suppose we have a symplectic manifold such that is exact ,i.e, .  Now let and be two lagrangian submanifolds and consider to be the set of smooth paths such that and .  Now the ""tangent space"" at a point of this space is just the space of vector fields along that curve, such that for . Define as , in local coordinate we have . Now given a family of smooth almost-complex structures we have a canocanil family of riemannian metrics and can define the inner product in as . Now with this I would like to compute the gradient of . My attempt is the following : , where such that and , and this will be equal to , and now from here I don't know what to do. I belive the answer is supposed to be that , but I don't know how to get there. Any help is appreciated. Thanks in advance.","(M,\omega) \omega \omega=d\alpha L_0 L_1 \Omega(L_0,L_1) \gamma:[0,1]\rightarrow M \gamma(0)\in L_0 \gamma(1)\in L_1 \xi(t) \xi(i)\in T_{\gamma(i)}L_i i=0,1 A:\Omega(L_0,L_1)\rightarrow \mathbb{R} A(\gamma)=\int_{0}^{1}\gamma^*\alpha A(\gamma)=\int_{0}^{1}\alpha(\frac{\partial \gamma}{\partial t})dt J_t g_t \Omega(L_0,L_1) \langle v_1, v_2\rangle=\int_{0}^{1}g_t(v_1(t),v_2(t))dt A dA_{\gamma}(\xi)=\frac{\partial }{\partial s}|_{s=0}A(c(s)) c(s):(-\epsilon,\epsilon)\rightarrow \Omega(L_0,L_1) c(0)=\gamma \frac{\partial }{\partial s}|_{s=0}c(s,t)=\xi(t) \int_{0}^{1} \frac{\partial }{\partial s}|_{s=0} \alpha(\frac{c(s,t)}{\partial t})dt grad A(\gamma)=J_t\frac{\partial \gamma}{\partial t}","['differential-geometry', 'calculus-of-variations', 'symplectic-geometry']"
73,"Milnor, Lectures on the h-cobordism theorem, proof of Theorem 3.4","Milnor, Lectures on the h-cobordism theorem, proof of Theorem 3.4",,"I have a question while reading the proof of Theorem 3.4 in Milnor's book Lectures on the h-cobordism theorem . ( https://www.maths.ed.ac.uk/~v1ranick/surgery/hcobord.pdf ) Theorem 3.4. If the Morse number $\mu$ of the triad $(W;V_0,V_1)$ is zero, then $(W;V_0,V_1)$ is a product cobordism. Proof) $(\cdots)$ We obtain an integral which satisfies $f(\psi(s))=s$ . Each integral curve can be extended uniquely over a maximal interval, which, since $W$ is compact, must be $[0,1]$ . $(\cdots)$ My question is: How did the compactness of $W$ used to show that the maximal domain of an integral curve must be $[0,1]$ ?","I have a question while reading the proof of Theorem 3.4 in Milnor's book Lectures on the h-cobordism theorem . ( https://www.maths.ed.ac.uk/~v1ranick/surgery/hcobord.pdf ) Theorem 3.4. If the Morse number of the triad is zero, then is a product cobordism. Proof) We obtain an integral which satisfies . Each integral curve can be extended uniquely over a maximal interval, which, since is compact, must be . My question is: How did the compactness of used to show that the maximal domain of an integral curve must be ?","\mu (W;V_0,V_1) (W;V_0,V_1) (\cdots) f(\psi(s))=s W [0,1] (\cdots) W [0,1]","['differential-geometry', 'proof-explanation', 'differential-topology', 'smooth-manifolds', 'vector-fields']"
74,An equation for Killing vector fields,An equation for Killing vector fields,,"Let $(M,g)$ be Riemannian manifold with Levi-Civita Connection $\nabla$ . We know that a vector field $X$ is a Killing vector field if and only if it satisfies the Killing equation (written in abstract index notation) \begin{equation}     \nabla_{\mu}X_{\nu} + \nabla_{\nu}X_{\mu} = 0 \end{equation} Now I'd like to show that $X$ also satisfies the equation \begin{equation*} \Delta_{g}X^{\mu} + {R^{\mu}}_{\nu}X^{\nu} = 0 \tag{$\heartsuit$} \end{equation*} where $\Delta_{g} = \nabla^{\mu}\nabla_{\mu}$ is the Laplace-Beltrami operator and $R_{\mu \nu}$ is the Ricci tensor. The derivation should be straightforward. Indeed, if we apply $g^{\lambda \nu} \nabla^{\mu}$ to both sides of the Killing equation, we can commute the order of covariant differentiation and get \begin{align*} g^{\lambda \nu}\nabla^{\mu}\nabla_{\mu}X_{\nu} + g^{\lambda \nu}\nabla^{\mu}\nabla_{\nu}X_{\mu} &= \Delta_{g}X^{\lambda} + \nabla^{\mu}\nabla^{\lambda}X_{\mu}\\ & = \Delta_{g}X^{\lambda} + \nabla^{\lambda}\nabla^{\mu}X_{\mu} + {R^{\mu \lambda}}_{\mu \nu}X^{\nu}\\ & = \Delta_{g}X^{\lambda}+ \nabla^{\lambda}\text{div}X + {R^{\lambda}}_{\nu}X^{\nu}\\ & = \Delta_{g}X^{\lambda}+ {R^{\lambda}}_{\nu}X^{\nu}\\ & = 0 \end{align*} where the second to last equality follows from the fact that a Killing vector field is divergence free. However, I'm not sure about the third equality, that \begin{equation}  \nabla^{\lambda}\nabla^{\mu}X_{\mu} =  \nabla^{\lambda}(\nabla^{\mu}X_{\mu}) = \nabla^{\lambda}\text{div}X \end{equation} The main confusion comes from whether we can evaluate the term $\nabla^{\mu}X_{\mu}$ first, and then apply  the outer convariant differentiation. On the other hand, I'm pretty sure $(\heartsuit)$ holds, since it will serve as a key step to prove the fact that $\Delta_{g}$ commutes with Killing vector fields on Riemannian manifolds.","Let be Riemannian manifold with Levi-Civita Connection . We know that a vector field is a Killing vector field if and only if it satisfies the Killing equation (written in abstract index notation) Now I'd like to show that also satisfies the equation where is the Laplace-Beltrami operator and is the Ricci tensor. The derivation should be straightforward. Indeed, if we apply to both sides of the Killing equation, we can commute the order of covariant differentiation and get where the second to last equality follows from the fact that a Killing vector field is divergence free. However, I'm not sure about the third equality, that The main confusion comes from whether we can evaluate the term first, and then apply  the outer convariant differentiation. On the other hand, I'm pretty sure holds, since it will serve as a key step to prove the fact that commutes with Killing vector fields on Riemannian manifolds.","(M,g) \nabla X \begin{equation}
    \nabla_{\mu}X_{\nu} + \nabla_{\nu}X_{\mu} = 0
\end{equation} X \begin{equation*}
\Delta_{g}X^{\mu} + {R^{\mu}}_{\nu}X^{\nu} = 0 \tag{\heartsuit}
\end{equation*} \Delta_{g} = \nabla^{\mu}\nabla_{\mu} R_{\mu \nu} g^{\lambda \nu} \nabla^{\mu} \begin{align*}
g^{\lambda \nu}\nabla^{\mu}\nabla_{\mu}X_{\nu} + g^{\lambda \nu}\nabla^{\mu}\nabla_{\nu}X_{\mu} &= \Delta_{g}X^{\lambda} + \nabla^{\mu}\nabla^{\lambda}X_{\mu}\\
& = \Delta_{g}X^{\lambda} + \nabla^{\lambda}\nabla^{\mu}X_{\mu} + {R^{\mu \lambda}}_{\mu \nu}X^{\nu}\\
& = \Delta_{g}X^{\lambda}+ \nabla^{\lambda}\text{div}X + {R^{\lambda}}_{\nu}X^{\nu}\\
& = \Delta_{g}X^{\lambda}+ {R^{\lambda}}_{\nu}X^{\nu}\\
& = 0
\end{align*} \begin{equation}
 \nabla^{\lambda}\nabla^{\mu}X_{\mu} =  \nabla^{\lambda}(\nabla^{\mu}X_{\mu}) = \nabla^{\lambda}\text{div}X
\end{equation} \nabla^{\mu}X_{\mu} (\heartsuit) \Delta_{g}","['differential-geometry', 'riemannian-geometry']"
75,"Gaussian curvature of a surface which is equal to the $(x,y)$-plane outside a ball of radius $10$",Gaussian curvature of a surface which is equal to the -plane outside a ball of radius,"(x,y) 10","The problem I'm working on is as follows Let $M \subseteq \mathbb{R}^3$ be a non-compact orientable surface without boundary which coincides with the $(x, y)$ -plane outside of the ball of radius $10$ centered at the origin. Prove that if the Gaussian curvature $K$ of $M$ is everywhere non-negative, then $K$ is everywhere $0$ . A few days ago, I posted here an idea I had for this problem, hoping someone could help me flesh out the missing step(s). The idea I had was to look at the part of the surface contained in the ball of radius $10$ , call it $R$ , a surface w/ boundary, and apply Gauss-Bonnet to it to establish that $\iint_R K \mathrm{d} M \leq 0$ . This would imply that $K$ is identically $0$ . I later realized that this method won't work, since we can't guarantee that $R$ is compact, a necessary assumption to use GB. For example, if $M$ was just the $(x, y)$ -plane minus the origin, it would fit the hypotheses of the problem, but $R$ would be a punctured disc, which is not compact. My second idea had been to look at the point in the surface where the $z$ -coordinate was maximized and see if I could come to some conclusion about the curvature there, but this won't work for similar reasons, since the $z$ -coordinate could be unbounded. I have in mind something where there's a ""singularity"" about the $z$ -axis. So I'm out of ideas for how to solve this problem. I don't really know what's left to try. I would love hints, but I'm studying for an exam in two days, so I'd also appreciate worked-out solutions to this problem. Thanks!","The problem I'm working on is as follows Let be a non-compact orientable surface without boundary which coincides with the -plane outside of the ball of radius centered at the origin. Prove that if the Gaussian curvature of is everywhere non-negative, then is everywhere . A few days ago, I posted here an idea I had for this problem, hoping someone could help me flesh out the missing step(s). The idea I had was to look at the part of the surface contained in the ball of radius , call it , a surface w/ boundary, and apply Gauss-Bonnet to it to establish that . This would imply that is identically . I later realized that this method won't work, since we can't guarantee that is compact, a necessary assumption to use GB. For example, if was just the -plane minus the origin, it would fit the hypotheses of the problem, but would be a punctured disc, which is not compact. My second idea had been to look at the point in the surface where the -coordinate was maximized and see if I could come to some conclusion about the curvature there, but this won't work for similar reasons, since the -coordinate could be unbounded. I have in mind something where there's a ""singularity"" about the -axis. So I'm out of ideas for how to solve this problem. I don't really know what's left to try. I would love hints, but I'm studying for an exam in two days, so I'd also appreciate worked-out solutions to this problem. Thanks!","M \subseteq \mathbb{R}^3 (x, y) 10 K M K 0 10 R \iint_R K \mathrm{d} M \leq 0 K 0 R M (x, y) R z z z","['differential-geometry', 'riemannian-geometry', 'curvature']"
76,Submanifold of $\mathbb{R}^3$ with tangent space spanned by given vector fields,Submanifold of  with tangent space spanned by given vector fields,\mathbb{R}^3,"Question: This is part of a problem from an old qualifying exam that I am having a little trouble with, so any help is greatly appreciated! In the problem, we are given two vector fields on $\mathbb{R}^3$ expressed by $$X = x(2y + \cos(y))\frac{\partial}{\partial x} - \frac{\partial}{\partial z},\qquad Y = \frac{\partial}{\partial y} + \frac{\partial}{\partial z} $$ and we need to write down a submanifold $N$ of $\mathbb{R}^3$ containing the point $p = (0,1,0)$ such that there is an open neightborhood $U_p$ around $p$ such that for every point $q\in U_p$ we have $T_qN = \text{span}\{X\vert_q, Y\vert_q\}$ , but I can't figure out a good way of going about this. My Attempt: My first thought was to check and see if $X$ and $Y$ commute: they are obviously linearly independent at $p = (0,1,0)$ , so if they commute, there is some coordinate representation of $N = (s^1,s^2,s^3)$ such that for a chart $(V_p, (s^i))$ of $N$ centered at $p$ , we have that $X = \frac{\partial}{\partial s^1}$ and $Y = \frac{\partial}{\partial s^2}$ [see Theorem 9.46 of Lee's Intro to Smooth Manifolds]. However, when I compute the Lie bracket $[X, Y]$ , I get $$\begin{align*} [X,Y] &= X(1)\frac{\partial}{\partial y} + X(1)\frac{\partial}{\partial z} - Y(x(2y + \cos(y)))\frac{\partial}{\partial x} + Y(1)\frac{\partial}{\partial z}\\ &=0 + 0 - (2x-x\sin(y))\frac{\partial}{\partial x}+0\\ &=(x\sin(y) - 2x)\frac{\partial}{\partial x}\\ &\not= 0, \end{align*}$$ so the vector fields don't commute. At this point I got stuck. I did compute that the flow $\theta_t$ of $X$ is given by $$\theta_t(x,y,z) = (xe^{2yt + t\cos(y)}, y, z - t),$$ and that the flow $\psi_t$ of $Y$ is given by $$\psi_t(x,y,z) = (x, y + t, z + t),$$ but I don't really know how to use this information to describe $N$ .","Question: This is part of a problem from an old qualifying exam that I am having a little trouble with, so any help is greatly appreciated! In the problem, we are given two vector fields on expressed by and we need to write down a submanifold of containing the point such that there is an open neightborhood around such that for every point we have , but I can't figure out a good way of going about this. My Attempt: My first thought was to check and see if and commute: they are obviously linearly independent at , so if they commute, there is some coordinate representation of such that for a chart of centered at , we have that and [see Theorem 9.46 of Lee's Intro to Smooth Manifolds]. However, when I compute the Lie bracket , I get so the vector fields don't commute. At this point I got stuck. I did compute that the flow of is given by and that the flow of is given by but I don't really know how to use this information to describe .","\mathbb{R}^3 X = x(2y + \cos(y))\frac{\partial}{\partial x} - \frac{\partial}{\partial z},\qquad Y = \frac{\partial}{\partial y} + \frac{\partial}{\partial z}  N \mathbb{R}^3 p = (0,1,0) U_p p q\in U_p T_qN = \text{span}\{X\vert_q, Y\vert_q\} X Y p = (0,1,0) N = (s^1,s^2,s^3) (V_p, (s^i)) N p X = \frac{\partial}{\partial s^1} Y = \frac{\partial}{\partial s^2} [X, Y] \begin{align*}
[X,Y] &= X(1)\frac{\partial}{\partial y} + X(1)\frac{\partial}{\partial z} - Y(x(2y + \cos(y)))\frac{\partial}{\partial x} + Y(1)\frac{\partial}{\partial z}\\
&=0 + 0 - (2x-x\sin(y))\frac{\partial}{\partial x}+0\\
&=(x\sin(y) - 2x)\frac{\partial}{\partial x}\\
&\not= 0,
\end{align*} \theta_t X \theta_t(x,y,z) = (xe^{2yt + t\cos(y)}, y, z - t), \psi_t Y \psi_t(x,y,z) = (x, y + t, z + t), N","['differential-geometry', 'vector-fields', 'submanifold']"
77,"Can we write explicitly the Euler-Lagrange equation of the ""pullback functional"" $E(f)=\int_M f^*\omega$?","Can we write explicitly the Euler-Lagrange equation of the ""pullback functional"" ?",E(f)=\int_M f^*\omega,"$\newcommand{\Cof}{\text{Cof}}$ $\newcommand{\R}{\mathbb{R}}$ Let $M,N$ be smooth oriented manifolds, M compact, $\partial N=\emptyset$ . Let $\omega \in \Omega^m(N)$ be closed . ( $m=\dim M$ ). I don't assume that $\dim M=\dim N$ . Consider the functional $E:C^{\infty}(M,N) \to \mathbb{R}$ , defined by $E(f)=\int_M f^*\omega$ . Can we obtain an ""explicit"" form of its Euler-Lagrange equation? I imagine something of the form $\Phi_{\omega}(f)=0$ , where $\Phi_{\omega}$ is some second order differential operator (which depends on $\omega$ ). One idea I have is to introduce more structure , e.g. endow $M$ and $N$ with Riemannian metrics $g_M,g_N$ . Now we might be able to find a ""metric-dependent"" formulation of the Euler-Lagrange equation. (Even though our functional does not depend on the Riemannian  structures, of course). More specifically, let $V \in \Gamma(f^*TN)$ be compactly supported in the interior $M^o$ , and let $f_t$ be a variation of $f$ satisfying $\left. \frac{\partial}{\partial t} \right|_{t=0} f_t=V$ . My goal is to express $$  \left. \frac{d}{dt} \right|_{t=0} E(f_t)=\int_M \langle V,\Phi_{\omega,g_M,g_N}(f)\rangle Vol_M,$$ where $\Phi_{\omega,g_M,g_N}:C^{\infty}(M,N) \to \Gamma(f^*TN)$ is some (second order) differential operator, which depends on $\omega$ and on the metrics $g_M,g_N$ . Actually, since only the metric on $N$ appears in $\langle V,\Phi_{\omega,g_M,g_N}(f)\rangle$ , $\Phi_{\omega,g_M,g_N}$ depends ""in essence"" only on $g_N$ ; however, $g_M$ may ""get in"" in a way which ""cancels itself"". (See example below). Perhaps something non-trivial can be said at least when $\omega$ is parallel (w.r.t the Levi-Civita connection) or harmonic? Comment: I know that $E$ is a null-Lagrangian, i.e. that every map satisfies its E-L equation. (This follows from the fact that I assumed that $d\omega=0$ and that the variation field is compactly supported in the interior; i.e. the variation do not change the values of the map on boundary $\partial M$ ). However, it does not mean that the E-L equation is ""trivial"" i.e. $0=0$ . See the example below. The first task is to find an expression for $\left. \frac{d}{dt} \right|_{t=0} f_t^*\omega$ where $f_t$ is some variation of $f$ . Here are two attempts: First attempt: Set $f_t=\phi_t \circ f$ , where $\phi_t \in \text{Diff}(N)$ . If $\left. \frac{\partial  \phi_t}{\partial t} \right|_{t=0}=X$ , then $V=X \circ f$ . Then $f_t^* \omega=f^* \phi_t^*  \omega$ , so $$\left. \frac{d}{dt} \right|_{t=0} f_t^*\omega=f^*L_X\omega,$$ and $$ \left. \frac{d}{dt} \right|_{t=0} E(f_t) =\int_M f^*L_X\omega=\int_M f^*d(\iota_X \omega).$$ Note that since $V=X \circ f$ , then $f(p_1)=f(p_2) \Rightarrow V(p_1)=V(p_2)$ , so if $f$ is not injective, not every variation field $V  \in \Gamma(f^*TN)$ can be expressed as $V=X \circ f$ , for some $X \in \Gamma(TN)$ . I don't know how to pass from here to something of the form $\langle X,\Phi(f) \rangle $ . Second attempt: We now take $f_t=f  \circ \psi_t$ , where $\psi_t \in \text{Diff}(M)$ . If $\left. \frac{\partial \psi_t}{\partial t} \right|_{t=0} =X \in \Gamma(TM)$ , then $V=df \circ X$ . (This means that if $df_p$ is not surjective not every $V$ can be realized in this way). Then $f_t^* \omega= \psi_t^*  f^*\omega$ , so $$\left. \frac{d}{dt} \right|_{t=0} f_t^*\omega=L_Xf^*\omega,$$ and $$ \left. \frac{d}{dt} \right|_{t=0} E(f_t) =\int_M L_Xf^*\omega=\int_M d(\iota_X f^*\omega).$$ Again, I don't know how to pass from here to something of the form $\langle X,\Phi(f) \rangle $ . Here is an example for the kind of 'explicit' expression I am looking for: Let $M=\Omega $ be an open subset of $\mathbb{R}^n$ , and $N=\mathbb{R}^n$ , both endowed with the Euclidean metrics, and set $\omega= \text{Vol}_{\mathbb{R}^n}$ . Then $$ E(f)=\int_{\Omega} f^*\text{Vol}_{\R^n}=\int_{\Omega}  \det df \text{Vol}_{\R^n}, $$ and so writing $f_t=f+tV$ for some $V:\Omega \to \R^n$ , we obtain $$\left. \frac{d}{dt} \right|_{t=0} E(f_t)=\int_{\Omega} \left. \frac{d}{dt} \right|_{t=0}  \det df_t=\int_{\Omega} \left. \frac{d}{dt} \right|_{t=0}  \det (df+tdV)=\int_{\Omega} \langle \Cof df,dV \rangle=\int_{\Omega} \langle \text{div} \Cof df,V \rangle,$$ so the Euler-Lagrange equation is given by $$ \text{div} \Cof df=0,$$ where $\Cof df$ is the cofactor matrix of $df$ , and the divergence here is taken row-by-row. This special case can be generalized to the case where $M,N$ are equidimensional Riemannian manifolds, and $\omega=\text{Vol}_N$ is the Riemannian volume form of $N$ . (admittedly, here $\omega$ itself depends upon the target metric $g_N$ , which is not exactly the context I presented in this question so far, where the metrics $g_M,g_N$ and the form $\omega$ are chosen independently). The corresponding Euler-Lagrange equation is $\delta (\Cof df)=0$ , where $\delta$ and $\Cof df$ are natural generalizations of the cofactor matrix and the divergence operator to Riemannian settings. For more details about this see this answer of mine. This in fact gives an infinite family of equations, that any map satisfies-one equation for every two metrics we choose.","Let be smooth oriented manifolds, M compact, . Let be closed . ( ). I don't assume that . Consider the functional , defined by . Can we obtain an ""explicit"" form of its Euler-Lagrange equation? I imagine something of the form , where is some second order differential operator (which depends on ). One idea I have is to introduce more structure , e.g. endow and with Riemannian metrics . Now we might be able to find a ""metric-dependent"" formulation of the Euler-Lagrange equation. (Even though our functional does not depend on the Riemannian  structures, of course). More specifically, let be compactly supported in the interior , and let be a variation of satisfying . My goal is to express where is some (second order) differential operator, which depends on and on the metrics . Actually, since only the metric on appears in , depends ""in essence"" only on ; however, may ""get in"" in a way which ""cancels itself"". (See example below). Perhaps something non-trivial can be said at least when is parallel (w.r.t the Levi-Civita connection) or harmonic? Comment: I know that is a null-Lagrangian, i.e. that every map satisfies its E-L equation. (This follows from the fact that I assumed that and that the variation field is compactly supported in the interior; i.e. the variation do not change the values of the map on boundary ). However, it does not mean that the E-L equation is ""trivial"" i.e. . See the example below. The first task is to find an expression for where is some variation of . Here are two attempts: First attempt: Set , where . If , then . Then , so and Note that since , then , so if is not injective, not every variation field can be expressed as , for some . I don't know how to pass from here to something of the form . Second attempt: We now take , where . If , then . (This means that if is not surjective not every can be realized in this way). Then , so and Again, I don't know how to pass from here to something of the form . Here is an example for the kind of 'explicit' expression I am looking for: Let be an open subset of , and , both endowed with the Euclidean metrics, and set . Then and so writing for some , we obtain so the Euler-Lagrange equation is given by where is the cofactor matrix of , and the divergence here is taken row-by-row. This special case can be generalized to the case where are equidimensional Riemannian manifolds, and is the Riemannian volume form of . (admittedly, here itself depends upon the target metric , which is not exactly the context I presented in this question so far, where the metrics and the form are chosen independently). The corresponding Euler-Lagrange equation is , where and are natural generalizations of the cofactor matrix and the divergence operator to Riemannian settings. For more details about this see this answer of mine. This in fact gives an infinite family of equations, that any map satisfies-one equation for every two metrics we choose.","\newcommand{\Cof}{\text{Cof}} \newcommand{\R}{\mathbb{R}} M,N \partial N=\emptyset \omega \in \Omega^m(N) m=\dim M \dim M=\dim N E:C^{\infty}(M,N) \to \mathbb{R} E(f)=\int_M f^*\omega \Phi_{\omega}(f)=0 \Phi_{\omega} \omega M N g_M,g_N V \in \Gamma(f^*TN) M^o f_t f \left. \frac{\partial}{\partial t} \right|_{t=0} f_t=V   \left. \frac{d}{dt} \right|_{t=0} E(f_t)=\int_M \langle V,\Phi_{\omega,g_M,g_N}(f)\rangle Vol_M, \Phi_{\omega,g_M,g_N}:C^{\infty}(M,N) \to \Gamma(f^*TN) \omega g_M,g_N N \langle V,\Phi_{\omega,g_M,g_N}(f)\rangle \Phi_{\omega,g_M,g_N} g_N g_M \omega E d\omega=0 \partial M 0=0 \left. \frac{d}{dt} \right|_{t=0} f_t^*\omega f_t f f_t=\phi_t \circ f \phi_t \in \text{Diff}(N) \left. \frac{\partial  \phi_t}{\partial t} \right|_{t=0}=X V=X \circ f f_t^* \omega=f^* \phi_t^*  \omega \left. \frac{d}{dt} \right|_{t=0} f_t^*\omega=f^*L_X\omega,  \left. \frac{d}{dt} \right|_{t=0} E(f_t) =\int_M f^*L_X\omega=\int_M f^*d(\iota_X \omega). V=X \circ f f(p_1)=f(p_2) \Rightarrow V(p_1)=V(p_2) f V  \in \Gamma(f^*TN) V=X \circ f X \in \Gamma(TN) \langle X,\Phi(f) \rangle  f_t=f  \circ \psi_t \psi_t \in \text{Diff}(M) \left. \frac{\partial \psi_t}{\partial t} \right|_{t=0} =X \in \Gamma(TM) V=df \circ X df_p V f_t^* \omega= \psi_t^*  f^*\omega \left. \frac{d}{dt} \right|_{t=0} f_t^*\omega=L_Xf^*\omega,  \left. \frac{d}{dt} \right|_{t=0} E(f_t) =\int_M L_Xf^*\omega=\int_M d(\iota_X f^*\omega). \langle X,\Phi(f) \rangle  M=\Omega  \mathbb{R}^n N=\mathbb{R}^n \omega= \text{Vol}_{\mathbb{R}^n}  E(f)=\int_{\Omega} f^*\text{Vol}_{\R^n}=\int_{\Omega}  \det df \text{Vol}_{\R^n},  f_t=f+tV V:\Omega \to \R^n \left. \frac{d}{dt} \right|_{t=0} E(f_t)=\int_{\Omega} \left. \frac{d}{dt} \right|_{t=0}  \det df_t=\int_{\Omega} \left. \frac{d}{dt} \right|_{t=0}  \det (df+tdV)=\int_{\Omega} \langle \Cof df,dV \rangle=\int_{\Omega} \langle \text{div} \Cof df,V \rangle,  \text{div} \Cof df=0, \Cof df df M,N \omega=\text{Vol}_N N \omega g_N g_M,g_N \omega \delta (\Cof df)=0 \delta \Cof df","['differential-geometry', 'riemannian-geometry', 'differential-forms', 'calculus-of-variations', 'euler-lagrange-equation']"
78,"On a pair of pants, complete geodesics do not cover the whole surface","On a pair of pants, complete geodesics do not cover the whole surface",,"I am reading a thesis by Jenya Sapir. In her thesis, she mentions that ""on a pair of pants, complete geodesics no longer cover the whole surface"". I could not figure out how can we come up with this claim but I knew that, when the length of each geodesic at the boundary of the surface is long enough, then this claim is true obviously. Further questions, whether this property holds when we consider any hyperbolic surface with boundary? Thank you in advance!","I am reading a thesis by Jenya Sapir. In her thesis, she mentions that ""on a pair of pants, complete geodesics no longer cover the whole surface"". I could not figure out how can we come up with this claim but I knew that, when the length of each geodesic at the boundary of the surface is long enough, then this claim is true obviously. Further questions, whether this property holds when we consider any hyperbolic surface with boundary? Thank you in advance!",,['differential-geometry']
79,Exterior derivative of 1-form and derivatives of sections of $T^*M$,Exterior derivative of 1-form and derivatives of sections of,T^*M,"Let $M$ be a compact manifold and consider a differential form $\alpha\in\Omega^1(M)$ , which we can think of as a map $\alpha:M\to T^*M$ . Since $T^*M$ is a smooth manifold we can compute the differential of this map $$D\alpha:TM\to T(T^*M)$$ How does this differential differ from the exterior derivative on 1-forms? I have a feeling that $D\alpha(X) = d(\alpha(X))$ , but I'm not sure how to show this.","Let be a compact manifold and consider a differential form , which we can think of as a map . Since is a smooth manifold we can compute the differential of this map How does this differential differ from the exterior derivative on 1-forms? I have a feeling that , but I'm not sure how to show this.",M \alpha\in\Omega^1(M) \alpha:M\to T^*M T^*M D\alpha:TM\to T(T^*M) D\alpha(X) = d(\alpha(X)),"['differential-geometry', 'differential-forms']"
80,A query about Atiyah's proof of the convexity of moment map,A query about Atiyah's proof of the convexity of moment map,,"This is about proving connectedness of level sets of moment map of a $\mathbb T^n$ $\implies$ convexity of image of moment map for $\mathbb T^{n+1}$ action. I am following Ana Cannas's wonderful lecture notes but I got stuck at a point in the proof where it says for any two points $p_0,p_1 \in M$ there is a sequence of points $q_n \rightarrow p_0,l_n\rightarrow p_1$ such that $\mu(p_1) - \mu(p_0)$ is in $ker A^t$ for some integer $(n+1) \times (n)$ matrix $A$ with rank n. I realised that it'd be enough to get a sequence such that $\mu(p_1) - \mu(p_0)$ has all rational coefficients is enough, but I am confused about how to do this. I looked at this part in Dusa Mcduff's book and it doesn't elaborate on this topic either, so I have a feeling it might be really trivial but I guess I am missing some trick/ easy observation.","This is about proving connectedness of level sets of moment map of a convexity of image of moment map for action. I am following Ana Cannas's wonderful lecture notes but I got stuck at a point in the proof where it says for any two points there is a sequence of points such that is in for some integer matrix with rank n. I realised that it'd be enough to get a sequence such that has all rational coefficients is enough, but I am confused about how to do this. I looked at this part in Dusa Mcduff's book and it doesn't elaborate on this topic either, so I have a feeling it might be really trivial but I guess I am missing some trick/ easy observation.","\mathbb T^n \implies \mathbb T^{n+1} p_0,p_1 \in M q_n \rightarrow p_0,l_n\rightarrow p_1 \mu(p_1) - \mu(p_0) ker A^t (n+1) \times (n) A \mu(p_1) - \mu(p_0)","['differential-geometry', 'symplectic-geometry', 'moment-map']"
81,Extension of Du-Bois-Raymond lemma to Vector Fields on a Riemannian Manifold,Extension of Du-Bois-Raymond lemma to Vector Fields on a Riemannian Manifold,,"Edit: Reviving this thread because I still could not prove or find a proof of this. A sketch of a proof attempt can be found in the previous edit of this post. I am trying to show the following extension of the Du Bois Raymond lemma: Let $M$ be a smooth Riemannian Manifold and $\omega: [0,1] \rightarrow M$ be a $W^{1,2}$ curve on M. Consider a tangential $L^2$ vector field along $\omega$ denoted by $v \in L^2(\omega^*TM)$ . If $$\int_{0}^{1} \langle v, \frac{Du}{\partial t} \rangle \text{ dt} = 0 \ \ \ \ \ \text{for all } u \in W ^{1,2}(\omega^*TM) \text{ with } u(0)=u(1)=0$$ Then $$v \in W^{1,2}(\omega^*TM)\ \ \text{ with   }\ \  \frac{Dv}{\partial t} = 0 \ \ a.e.$$ where $\frac{Du}{\partial t}$ denotes the covariant derivative of $u$ along the curve $\omega$ . For my purposes it would be sufficient to show this for the simplified case where $M = S^2$ and the covariant derivative becomes the projection onto the respective tangent space, i.e., $\frac{Du}{\partial t} = u' - \langle u', \omega \rangle \omega$ . Kind regards.","Edit: Reviving this thread because I still could not prove or find a proof of this. A sketch of a proof attempt can be found in the previous edit of this post. I am trying to show the following extension of the Du Bois Raymond lemma: Let be a smooth Riemannian Manifold and be a curve on M. Consider a tangential vector field along denoted by . If Then where denotes the covariant derivative of along the curve . For my purposes it would be sufficient to show this for the simplified case where and the covariant derivative becomes the projection onto the respective tangent space, i.e., . Kind regards.","M \omega: [0,1] \rightarrow M W^{1,2} L^2 \omega v \in L^2(\omega^*TM) \int_{0}^{1} \langle v, \frac{Du}{\partial t} \rangle \text{ dt} = 0 \ \ \ \ \ \text{for all } u \in W ^{1,2}(\omega^*TM) \text{ with } u(0)=u(1)=0 v \in W^{1,2}(\omega^*TM)\ \ \text{ with   }\ \  \frac{Dv}{\partial t} = 0 \ \ a.e. \frac{Du}{\partial t} u \omega M = S^2 \frac{Du}{\partial t} = u' - \langle u', \omega \rangle \omega","['differential-geometry', 'manifolds', 'riemannian-geometry', 'calculus-of-variations']"
82,deformation of Hodge star operator and harmonic forms,deformation of Hodge star operator and harmonic forms,,"Suppose $(M,g)$ is a compact Riemannian manifold, and $*_g$ is the Hodge star operator defined on the de Rham algebra $\Omega^*(M)$ with respect to the metric $g$ . Let $\phi:M\to M$ be a diffeomorphism. Then, can we find another metric $h$ (which should be related to $\phi$ ) so that $$ (\phi^{-1})^* \circ *_g\circ \phi^* $$ agree with the new Hodge star operator $*_h$ ? EDIT: I guess this should be the Hodge star operator for the pullback metric. On the other hand, we know $\phi$ induces a map $$ \phi^*:H^*(M)\to H^*(M)$$ on de Rham cohomology groups, and meanwhile we also know for any metric $h$ there is the so-called Hodge isomorphism $\mathcal H^*_h(M) \to H^*(M)$ where $\mathcal H^*_h(M)$ denotes the $h$ -harmonic forms. Now another interesting question is that can we find a metric $h$ so that we can induce a map $$ \phi^*: \mathcal H_g(M) \to \mathcal H_h(M)$$ ?","Suppose is a compact Riemannian manifold, and is the Hodge star operator defined on the de Rham algebra with respect to the metric . Let be a diffeomorphism. Then, can we find another metric (which should be related to ) so that agree with the new Hodge star operator ? EDIT: I guess this should be the Hodge star operator for the pullback metric. On the other hand, we know induces a map on de Rham cohomology groups, and meanwhile we also know for any metric there is the so-called Hodge isomorphism where denotes the -harmonic forms. Now another interesting question is that can we find a metric so that we can induce a map ?","(M,g) *_g \Omega^*(M) g \phi:M\to M h \phi 
(\phi^{-1})^* \circ *_g\circ \phi^*
 *_h \phi 
\phi^*:H^*(M)\to H^*(M) h \mathcal H^*_h(M) \to H^*(M) \mathcal H^*_h(M) h h  \phi^*: \mathcal H_g(M) \to \mathcal H_h(M)","['differential-geometry', 'differential-topology', 'riemannian-geometry', 'hodge-theory', 'de-rham-cohomology']"
83,Definition of manifolds as submanifolds of $\mathbb{R}^m$,Definition of manifolds as submanifolds of,\mathbb{R}^m,"I'm having trouble understanding the definition of coordinate charts of manifolds given in the book ""Analysis II"" by Herbert Amann and Joachim Escher. They define manifolds as submanifolds of $\mathbb{R}^m$ (which is equivalent to the abstract aproach by the Whitney embedding theorem right?). The definition of a submanifold I learned is: Let $M$ be an $m$ -dimensional manifold. We say that a subset $L \subseteq M$ is a submanifold of $M$ of dimension $n$ , if for every point $p \in L$ there exists an adapted chart $\phi: U \rightarrow V' \times V''$ with $U \subseteq L$ open in $L$ , $V' \subseteq \mathbb{R}^n$ open in $\mathbb{R}^n$ and $V'' \subseteq \mathbb{R}^{m-n}$ open in $\mathbb{R}^{m-n}$ such that $\phi (U \cap L) = V' \times \{0\}$ with $0 \in \mathbb{R}^{m-n}$ Then $L$ becomes an $n$ -dimensional manifold of itself with the smooth atlas induced by the restricted charts $\phi : U \cap L \rightarrow V'$ . The authors of the book define a submanifold of $\mathbb{R}^m$ as follows A subset $L \subseteq \mathbb{R}^m$ is called an $n$ -dimensional submanifold of $\mathbb{R}^m$ if for every point $p \in L$ there exists an open set $U \subseteq \mathbb{R}^m$ containing $p$ and an open subset $V\subseteq \mathbb{R}^m$ together with a diffeomorphism $\phi$ from $U$ to $V$ such that $\phi(M \cap U)=V \cap (\mathbb{R}^n \times \{0\})$ with $0 \in \mathbb{R}^{m-n}$ . ,which directly coincides with the book's definition if one views $\mathbb{R}^m$ as an $m$ -dimensional manifold with the smooth atlas induced by the universal chart $(\mathbb{R}^m, id)$ . Then the authors define coordinate charts of an $n$ -dimensional submanifold $L$ of $\mathbb{R}^m$ around a point $p \in L$ as follows Let $\phi: U \rightarrow V$ be a homeomorphism from an open set $U \subseteq L$ in the subspace topology containing $p$ to an open subset $V$ of $\mathbb{R}^n$ such that $ i_M \ \circ \ \phi ^{-1}$ is a $C^\infty$ -immersion, where $i_M$ is the cannonical injection from $L$ to $\mathbb{R}^m$ . How is this equivalent to the restricted charts given in the first definition? Why does $ i_M \ \circ \ \phi^{-1}$ need to be an immersion? I'm really having trouble connecting the abstract aproach to manifolds to the way of defining manifolds as submanifolds of $\mathbb{R}^m$ . What's a good way to  think about the approach taken by the book?","I'm having trouble understanding the definition of coordinate charts of manifolds given in the book ""Analysis II"" by Herbert Amann and Joachim Escher. They define manifolds as submanifolds of (which is equivalent to the abstract aproach by the Whitney embedding theorem right?). The definition of a submanifold I learned is: Let be an -dimensional manifold. We say that a subset is a submanifold of of dimension , if for every point there exists an adapted chart with open in , open in and open in such that with Then becomes an -dimensional manifold of itself with the smooth atlas induced by the restricted charts . The authors of the book define a submanifold of as follows A subset is called an -dimensional submanifold of if for every point there exists an open set containing and an open subset together with a diffeomorphism from to such that with . ,which directly coincides with the book's definition if one views as an -dimensional manifold with the smooth atlas induced by the universal chart . Then the authors define coordinate charts of an -dimensional submanifold of around a point as follows Let be a homeomorphism from an open set in the subspace topology containing to an open subset of such that is a -immersion, where is the cannonical injection from to . How is this equivalent to the restricted charts given in the first definition? Why does need to be an immersion? I'm really having trouble connecting the abstract aproach to manifolds to the way of defining manifolds as submanifolds of . What's a good way to  think about the approach taken by the book?","\mathbb{R}^m M m L \subseteq M M n p \in L \phi: U \rightarrow V' \times V'' U \subseteq L L V' \subseteq \mathbb{R}^n \mathbb{R}^n V'' \subseteq \mathbb{R}^{m-n} \mathbb{R}^{m-n} \phi (U \cap L) = V' \times \{0\} 0 \in \mathbb{R}^{m-n} L n \phi : U \cap L \rightarrow V' \mathbb{R}^m L \subseteq \mathbb{R}^m n \mathbb{R}^m p \in L U \subseteq \mathbb{R}^m p V\subseteq \mathbb{R}^m \phi U V \phi(M \cap U)=V \cap (\mathbb{R}^n \times \{0\}) 0 \in \mathbb{R}^{m-n} \mathbb{R}^m m (\mathbb{R}^m, id) n L \mathbb{R}^m p \in L \phi: U \rightarrow V U \subseteq L p V \mathbb{R}^n  i_M \ \circ \ \phi ^{-1} C^\infty i_M L \mathbb{R}^m  i_M \ \circ \ \phi^{-1} \mathbb{R}^m","['differential-geometry', 'definition', 'smooth-manifolds']"
84,Showing that the Lie bracket of two Killing fields on a Riemannian manifold is again a Killing field using the Killing equation,Showing that the Lie bracket of two Killing fields on a Riemannian manifold is again a Killing field using the Killing equation,,"I've read that the Lie bracket of two Killing fields $X$ and $Y$ on a Riemannian  manifold $M$ are again a Killing field so I thought it might be a good exercise to try to prove this using the Killing equation. We want to show that $$\langle \nabla_{Z}[X,Y],W \rangle =-\langle \nabla_{W}[X,Y],Z \rangle$$ for any two (smooth) vector fields $Z$ and $W$ on $M$ . Here is my attempt: $\langle \nabla_{Z}[X,Y],W \rangle= \langle \nabla_{Z}(\nabla_{X}Y-\nabla_YX),W\rangle$ (using symmetry) $=\langle \nabla_{Z} \nabla_X Y,W \rangle -\langle \nabla_{Z} \nabla_Y X,W \rangle$ (using linearity of the connection) $=Z\langle \nabla_XY,W \rangle-\langle \nabla_XY,\nabla_ZW\rangle-Z\langle \nabla_YX,W \rangle +\langle \nabla_YX,\nabla_ZW \rangle$ (compatibility of the metric) At this point I thought about using the fact that $X$ and $Y$ satisfy the Killing equation and applying it to the terms being acted on by $Z$ but this doesn't appear to work. Maybe I'm going down the wrong road here but does anyone have a proof of this using the Killing equation?",I've read that the Lie bracket of two Killing fields and on a Riemannian  manifold are again a Killing field so I thought it might be a good exercise to try to prove this using the Killing equation. We want to show that for any two (smooth) vector fields and on . Here is my attempt: (using symmetry) (using linearity of the connection) (compatibility of the metric) At this point I thought about using the fact that and satisfy the Killing equation and applying it to the terms being acted on by but this doesn't appear to work. Maybe I'm going down the wrong road here but does anyone have a proof of this using the Killing equation?,"X Y M \langle \nabla_{Z}[X,Y],W \rangle =-\langle \nabla_{W}[X,Y],Z \rangle Z W M \langle \nabla_{Z}[X,Y],W \rangle= \langle \nabla_{Z}(\nabla_{X}Y-\nabla_YX),W\rangle =\langle \nabla_{Z} \nabla_X Y,W \rangle -\langle \nabla_{Z} \nabla_Y X,W \rangle =Z\langle \nabla_XY,W \rangle-\langle \nabla_XY,\nabla_ZW\rangle-Z\langle \nabla_YX,W \rangle +\langle \nabla_YX,\nabla_ZW \rangle X Y Z","['differential-geometry', 'riemannian-geometry']"
85,Characteristic classes of spinor bundle,Characteristic classes of spinor bundle,,"Given a spin structure on a oriented Riemannian manifold $(M,g)$, a spinor is a section of the spinor bundle $\pi:\mathbf{S}\to M$. I am trying to calculate the characteristic classes of the spinor bundle, in particular when $M$ is a 4-manifold. In this case, the Dold-Whitney theorem says that bundles over $M^4$ are classified topologically by the second Stiefel-Whitney class and the first Pontryagin class. Note that the space of metrics on $M$ is convex (and hence contractible), so all spinor bundles on $M$ are isomorphic. I am particularly interested in the cases of $S^4$ and a K3 surface. $S^4$ has no second cohomology, so the second Stiefel-Whitney class is trivial. The first Pontryagin class $p_1(\mathbf{S})\in H^4(S^4;\mathbb{Z})=\mathbb{Z}$ will correspond to some integer, but I'm not sure which one. Thanks for your help.","Given a spin structure on a oriented Riemannian manifold $(M,g)$, a spinor is a section of the spinor bundle $\pi:\mathbf{S}\to M$. I am trying to calculate the characteristic classes of the spinor bundle, in particular when $M$ is a 4-manifold. In this case, the Dold-Whitney theorem says that bundles over $M^4$ are classified topologically by the second Stiefel-Whitney class and the first Pontryagin class. Note that the space of metrics on $M$ is convex (and hence contractible), so all spinor bundles on $M$ are isomorphic. I am particularly interested in the cases of $S^4$ and a K3 surface. $S^4$ has no second cohomology, so the second Stiefel-Whitney class is trivial. The first Pontryagin class $p_1(\mathbf{S})\in H^4(S^4;\mathbb{Z})=\mathbb{Z}$ will correspond to some integer, but I'm not sure which one. Thanks for your help.",,"['differential-geometry', 'algebraic-topology', 'differential-topology', 'spin-geometry']"
86,A Killing field on a compact Riemannian manifold $M$ of positive sectional curvature has a singularity,A Killing field on a compact Riemannian manifold  of positive sectional curvature has a singularity,M,"This problem comes from do Carmo's book on page 104. I've almost got this thing worked out but am stuck at one point. The problem is long so I'll try to break it down. Assume $M$ is a compact Riemannian manifold of even dimension whose sectional curvature is positive. Show that every killing field $X$ on $M$ has a singularity, i.e. a point $p$ where $X_p = 0$. We have the following maps: $A_{X}: \mathfrak{X}(M) \rightarrow \mathfrak{X}(M)$ defined by $A_{X}(Z)=\nabla_{Z}X$ $f: M \rightarrow \mathbb{R}$ defined by  $f(q)=\| X \|_{q}^{2}=\langle X, X \rangle_{q}$. Let $p \in M$ be a critical point of $f$, i.e. where $df_{p}=0$. I proved the following lemma (exercise 2 from p. 104): Lemma: For any $Z \in \mathfrak{X}(M)$, we have at the critical point $p$ (i) $\langle A_X(Z),X \rangle_p = 0$ (ii) $ \langle A_X(Z),A_X(Z)\rangle_p = \frac{1}{2}Z_p(Z\langle X,X \rangle)+  R(X,Z,X,Z)(p)$ We will look at a point $p \in M$ where $f$ attains its minimum. Assume for contradiction that $X_p \neq 0$. The map $A_X$ defined above induces a map $A:T_pM \rightarrow T_pM$ by $A(y)=A_XY(p)=\nabla_Y X(p)$ where $Y$ is any extension of $y \in T_pM$. Let $E \subset T_pM$ be orthogonal to $X_p$. I want to show that the restriction $A: E \rightarrow E$ is an antisymmetric isomorphism. Note it follows from Lemma (i) that $A$ actually gives a map $E \rightarrow E$. I've already showed antisymmetric so I'm going to only show my work on isomorphism. It suffices to show that $A: E \rightarrow E$ is injective. If $A(y_1)=A(y_2)$ then $A(y_1-y_2)=0$, so let $Z=Y_1 -Y_2$ where $Y_1$, $Y_2$ are extensions of $y_1$ and $y_2$. Then, using Lemma (ii) we have $0=\langle(A(y_1-y_2),A(y_1-y_2) \rangle_p = \langle A_X(Z),A_X(Z) \rangle_p = \frac{1}{2}Z_p(Z\langle X,X\rangle) + R(X,Z,X,Z)(p)$ By the assumption on curvature, $R(X,Z,X,Z)(p)>0$, so if we can show $Z_p(Z\langle X, X \rangle) \geq 0$ then we will have a contradiction. This is where I'm stuck.","This problem comes from do Carmo's book on page 104. I've almost got this thing worked out but am stuck at one point. The problem is long so I'll try to break it down. Assume $M$ is a compact Riemannian manifold of even dimension whose sectional curvature is positive. Show that every killing field $X$ on $M$ has a singularity, i.e. a point $p$ where $X_p = 0$. We have the following maps: $A_{X}: \mathfrak{X}(M) \rightarrow \mathfrak{X}(M)$ defined by $A_{X}(Z)=\nabla_{Z}X$ $f: M \rightarrow \mathbb{R}$ defined by  $f(q)=\| X \|_{q}^{2}=\langle X, X \rangle_{q}$. Let $p \in M$ be a critical point of $f$, i.e. where $df_{p}=0$. I proved the following lemma (exercise 2 from p. 104): Lemma: For any $Z \in \mathfrak{X}(M)$, we have at the critical point $p$ (i) $\langle A_X(Z),X \rangle_p = 0$ (ii) $ \langle A_X(Z),A_X(Z)\rangle_p = \frac{1}{2}Z_p(Z\langle X,X \rangle)+  R(X,Z,X,Z)(p)$ We will look at a point $p \in M$ where $f$ attains its minimum. Assume for contradiction that $X_p \neq 0$. The map $A_X$ defined above induces a map $A:T_pM \rightarrow T_pM$ by $A(y)=A_XY(p)=\nabla_Y X(p)$ where $Y$ is any extension of $y \in T_pM$. Let $E \subset T_pM$ be orthogonal to $X_p$. I want to show that the restriction $A: E \rightarrow E$ is an antisymmetric isomorphism. Note it follows from Lemma (i) that $A$ actually gives a map $E \rightarrow E$. I've already showed antisymmetric so I'm going to only show my work on isomorphism. It suffices to show that $A: E \rightarrow E$ is injective. If $A(y_1)=A(y_2)$ then $A(y_1-y_2)=0$, so let $Z=Y_1 -Y_2$ where $Y_1$, $Y_2$ are extensions of $y_1$ and $y_2$. Then, using Lemma (ii) we have $0=\langle(A(y_1-y_2),A(y_1-y_2) \rangle_p = \langle A_X(Z),A_X(Z) \rangle_p = \frac{1}{2}Z_p(Z\langle X,X\rangle) + R(X,Z,X,Z)(p)$ By the assumption on curvature, $R(X,Z,X,Z)(p)>0$, so if we can show $Z_p(Z\langle X, X \rangle) \geq 0$ then we will have a contradiction. This is where I'm stuck.",,"['differential-geometry', 'riemannian-geometry']"
87,Does this condition on the curvature implies existence of a parallel section?,Does this condition on the curvature implies existence of a parallel section?,,"Let $E$ be a smooth vector bundle over a manifold $M$ ($\dim M>1$), equipped with a metric. Let $\nabla$ be a metric connection on $E$. Suppose there exist locally a non-zero section $\sigma \in \Gamma(E)$ which lies in $\ker R(X,Y)$ for all $X,Y \in \Gamma(TM)$. Does $\nabla$ admit a parallel section (locally)? Note that even if $\| \sigma\|=1$, it is not necessarily true that $\sigma$ parallel. (e.g. if $\nabla$ is flat). (We have to normalize: the point is that if $\sigma \in \ker R(X,Y)$ so is $f\sigma$ for any function $f$. A parallel section has a constant norm though.) Clearly, this is a necessary condition: If $\sigma$ is parallel, then $R(X,Y)\sigma=d_{\nabla}^2\sigma(X,Y)=0$","Let $E$ be a smooth vector bundle over a manifold $M$ ($\dim M>1$), equipped with a metric. Let $\nabla$ be a metric connection on $E$. Suppose there exist locally a non-zero section $\sigma \in \Gamma(E)$ which lies in $\ker R(X,Y)$ for all $X,Y \in \Gamma(TM)$. Does $\nabla$ admit a parallel section (locally)? Note that even if $\| \sigma\|=1$, it is not necessarily true that $\sigma$ parallel. (e.g. if $\nabla$ is flat). (We have to normalize: the point is that if $\sigma \in \ker R(X,Y)$ so is $f\sigma$ for any function $f$. A parallel section has a constant norm though.) Clearly, this is a necessary condition: If $\sigma$ is parallel, then $R(X,Y)\sigma=d_{\nabla}^2\sigma(X,Y)=0$",,"['differential-geometry', 'riemannian-geometry', 'vector-bundles', 'curvature', 'connections']"
88,Metallic Riemannian manifolds,Metallic Riemannian manifolds,,"I have recently heard about the existence of the so called metallic Riemannian manifolds . As far as I understand, those are manifold with a polynomial structure, compatible with the Riemannian metric, induced by a $(1,1)$ tensor $J$ satisfying a metallic equation $$ J^2 = pJ + qI $$ where $p$ and $q$ are positive integers and $I$ is the identity operator. Why are they studied? Is there any geometric application? I mean, does the existence of a metallic structure imply some interesting geometric or topological property of the manifold?","I have recently heard about the existence of the so called metallic Riemannian manifolds . As far as I understand, those are manifold with a polynomial structure, compatible with the Riemannian metric, induced by a $(1,1)$ tensor $J$ satisfying a metallic equation $$ J^2 = pJ + qI $$ where $p$ and $q$ are positive integers and $I$ is the identity operator. Why are they studied? Is there any geometric application? I mean, does the existence of a metallic structure imply some interesting geometric or topological property of the manifold?",,"['differential-geometry', 'differential-topology', 'riemannian-geometry', 'smooth-manifolds']"
89,Is a conformal transformation also a general coordinate transformation?,Is a conformal transformation also a general coordinate transformation?,,"As far as I understand, a general coordinate transformation is induced by a diffeomorphism $f:M\rightarrow M$ where $M$ is a manifold (which can locally be described with coordinates). So if $x:M\rightarrow \mathbb{R}^m$ is a  coordinate map, then $y:=x\circ f$ is a new coordinate map after the coordinate transformation. One could locally express the new coordinates in terms of the old ones, writing $y=y(x)$. Is that right so far? Now if such a diffeomorphism is applied to all points, it should induce an effect on the metric. Let's say $X,Y$ are vector fields (elements of the module of derivatives over the ring of smooth functions $C^\infty(M)$ over $M$) and $g$ is the metric tensor field (an element of the comodule of the module of vector fields which takes two vector fields back to $C^\infty(M)$) and $p$ is a point of $M$. Then, is it right to say that the diffeomorphism induces the change \begin{equation} f^*g(X,Y)|_p = g_p(f_* X_p, f_* Y_p)? \end{equation} I have also seen in another post an action defined on all objects as in \begin{equation} (f^*)^{(-1)}g(f_* X,f_* Y)|_p = g_p(X_p, Y_p), \end{equation} which would mean that any diffeo would leave $g(X,Y)$ invariant? If this is correct, then I am confused here because I don't yet understand why the action should include the inverse of the pull-back? A conformal transformation is defined as a diffeomorphism that leaves the metric invariant up to a an overall factor, meaning that the diffeomorphism induces a pull-back of the metric that is conformally equivalent (equivalent up to an overall factor) to the old one. Does this mean \begin{equation} f^*g(X,Y)|_p=g_p(f_* X_p, f_* Y_p)=\Omega(p) g_p(X_p,Y_p)? \end{equation} In that case, a conformal transformation would be  a coordinate transformation that changes the metric only by an overall factor and is thus also a coordinate transformation? But then a conformal invariance of some theory would not be special anymore in a covariant formulation which confuses me. Thus my understanding of the action of a transformation on the metric and the vector fields is probably wrong at some (or multiple) point(s). Would be great if you could help me to clarify that.","As far as I understand, a general coordinate transformation is induced by a diffeomorphism $f:M\rightarrow M$ where $M$ is a manifold (which can locally be described with coordinates). So if $x:M\rightarrow \mathbb{R}^m$ is a  coordinate map, then $y:=x\circ f$ is a new coordinate map after the coordinate transformation. One could locally express the new coordinates in terms of the old ones, writing $y=y(x)$. Is that right so far? Now if such a diffeomorphism is applied to all points, it should induce an effect on the metric. Let's say $X,Y$ are vector fields (elements of the module of derivatives over the ring of smooth functions $C^\infty(M)$ over $M$) and $g$ is the metric tensor field (an element of the comodule of the module of vector fields which takes two vector fields back to $C^\infty(M)$) and $p$ is a point of $M$. Then, is it right to say that the diffeomorphism induces the change \begin{equation} f^*g(X,Y)|_p = g_p(f_* X_p, f_* Y_p)? \end{equation} I have also seen in another post an action defined on all objects as in \begin{equation} (f^*)^{(-1)}g(f_* X,f_* Y)|_p = g_p(X_p, Y_p), \end{equation} which would mean that any diffeo would leave $g(X,Y)$ invariant? If this is correct, then I am confused here because I don't yet understand why the action should include the inverse of the pull-back? A conformal transformation is defined as a diffeomorphism that leaves the metric invariant up to a an overall factor, meaning that the diffeomorphism induces a pull-back of the metric that is conformally equivalent (equivalent up to an overall factor) to the old one. Does this mean \begin{equation} f^*g(X,Y)|_p=g_p(f_* X_p, f_* Y_p)=\Omega(p) g_p(X_p,Y_p)? \end{equation} In that case, a conformal transformation would be  a coordinate transformation that changes the metric only by an overall factor and is thus also a coordinate transformation? But then a conformal invariance of some theory would not be special anymore in a covariant formulation which confuses me. Thus my understanding of the action of a transformation on the metric and the vector fields is probably wrong at some (or multiple) point(s). Would be great if you could help me to clarify that.",,"['differential-geometry', 'transformation', 'conformal-geometry', 'invariance', 'pullback']"
90,Why does a fiber bundle connection satisfy Leibniz rule?,Why does a fiber bundle connection satisfy Leibniz rule?,,"Let $M$ be a smooth manifold and $\pi:TM\rightarrow M$ be the projection map. Define $V=ker(d\pi)$ and define $H$ to satisfy $TTM=V\oplus H$ and suppose $H$ is invariant under the tangent map induced by the multiplication maps $m_\lambda:TM\rightarrow TM:x\rightarrow \lambda x$. Let $\rho_V:TTM\rightarrow ker(d\pi)$ be the vertical projection map. Define $\bigtriangledown_X Y:=\rho_V\circ dY \circ X$ for smooth vector fields $X,Y:M\rightarrow TM$. I was trying to prove that it satisfies that $\bigtriangledown_X (fY)= X(f) Y + f\bigtriangledown_X Y$ where $f$ is a smooth function, but I don't know how to prove this. How do I prove this?","Let $M$ be a smooth manifold and $\pi:TM\rightarrow M$ be the projection map. Define $V=ker(d\pi)$ and define $H$ to satisfy $TTM=V\oplus H$ and suppose $H$ is invariant under the tangent map induced by the multiplication maps $m_\lambda:TM\rightarrow TM:x\rightarrow \lambda x$. Let $\rho_V:TTM\rightarrow ker(d\pi)$ be the vertical projection map. Define $\bigtriangledown_X Y:=\rho_V\circ dY \circ X$ for smooth vector fields $X,Y:M\rightarrow TM$. I was trying to prove that it satisfies that $\bigtriangledown_X (fY)= X(f) Y + f\bigtriangledown_X Y$ where $f$ is a smooth function, but I don't know how to prove this. How do I prove this?",,"['differential-geometry', 'smooth-manifolds', 'connections']"
91,Do smooth embeddings preserve quotient bundles?,Do smooth embeddings preserve quotient bundles?,,"Let $M$ be a smooth connected oriented $d$ -dimensional manifold. Let $S \subseteq M$ be a $k$ -dimensional embedded submanifold which is also compact, connected and orientable. Suppose we are given a smooth embedding $F:S \to \mathbb{R}^d$ . Question: Suppose that $TM|_S$ is a trivial vector bundle. Is it true that the quotients $TM|_S \big/ TS$ and $S \times \mathbb{R}^d\big/dF(TS)$ are isomorphic as vector bundles? The triviality of $TM|_S$ is an obvious necessary condition, since if $TM|_S \big/ TS \cong S \times \mathbb{R}^d\big/dF(TS)$ , then $$TM|_S \cong TS \oplus TM|_S \big/ TS \cong dF(TS) \oplus S \times \mathbb{R}^d\big/dF(TS) \cong S \times \mathbb{R}^d.$$ Of course, isomorphic bundles and subbundles can induce non-isomorphic quotients, so $TS \cong dF(TS)$ and $TM|_S \cong S \times \mathbb{R}^d$ do not imply the quotients are isomorphic. My guess is that the answer can be negative in general, but I don't know how to find a counterexample. Note that when the codimension $d-k=1$ , the answer is positive: The quotients are isomorphic .","Let be a smooth connected oriented -dimensional manifold. Let be a -dimensional embedded submanifold which is also compact, connected and orientable. Suppose we are given a smooth embedding . Question: Suppose that is a trivial vector bundle. Is it true that the quotients and are isomorphic as vector bundles? The triviality of is an obvious necessary condition, since if , then Of course, isomorphic bundles and subbundles can induce non-isomorphic quotients, so and do not imply the quotients are isomorphic. My guess is that the answer can be negative in general, but I don't know how to find a counterexample. Note that when the codimension , the answer is positive: The quotients are isomorphic .",M d S \subseteq M k F:S \to \mathbb{R}^d TM|_S TM|_S \big/ TS S \times \mathbb{R}^d\big/dF(TS) TM|_S TM|_S \big/ TS \cong S \times \mathbb{R}^d\big/dF(TS) TM|_S \cong TS \oplus TM|_S \big/ TS \cong dF(TS) \oplus S \times \mathbb{R}^d\big/dF(TS) \cong S \times \mathbb{R}^d. TS \cong dF(TS) TM|_S \cong S \times \mathbb{R}^d d-k=1,"['differential-geometry', 'differential-topology', 'riemannian-geometry', 'smooth-manifolds', 'vector-bundles']"
92,Point with connected geodesic circles on closed convex surface,Point with connected geodesic circles on closed convex surface,,"Let $S\subset\mathbb{R}^3$ be a closed convex surface (smooth if necessary) and denote by $d$ the intrinsic distance on $S$. Can we always find a point $p$ such that $S_p(t):=\{q\in S\mid d(p,q)=t\}$ stays connected for all $t\geq 0$?","Let $S\subset\mathbb{R}^3$ be a closed convex surface (smooth if necessary) and denote by $d$ the intrinsic distance on $S$. Can we always find a point $p$ such that $S_p(t):=\{q\in S\mid d(p,q)=t\}$ stays connected for all $t\geq 0$?",,"['differential-geometry', 'riemannian-geometry', 'surfaces']"
93,Some questions on complex determinants and flat connections on a $U(1)$ bundle,Some questions on complex determinants and flat connections on a  bundle,U(1),"Inspired by Geometric interpretation of the determinant of a complex matrix , I ask the following related questions. The complex determinant is determined up to a global scaling factor by the fact that it is multilinear and skew-symmetric. Let us try to understand the phase of the determinant. For that purpose, let us restrict our attention to $G = U(n)$. Let $E = G \times U(1)$ be the trivial $U(1)$ bundle over $G$. Let $T$ denote a maximal torus of $G$; to fix the ideas, let us assume it is the one consisting of all diagonal matrices in $G$. Let $N(T)$ denote the normalizer of $T$ in $G$. $N(T)$ is the semi-direct product of $T$ with the symmetric group $S_n$ ($S_n$ is the full permutation group on $n$ elements). We can now say that the determinant is a global smooth section $s$ of $E$ over $G$ which is further $N(T)$-equivariant. Question 1: do these properties determine $s$ up to a global phase factor? If we let $\nabla$ denote the unique flat connection on $E$ which makes the actual determinant function parallel (i.e. covariantly constant) everywhere, then if we require that the section $s$ be covariantly constant with respect to $\nabla$, then we recover the determinant function uniquely up to a global phase factor, and the symmetry properties under $N(T)$ are automatically satisfied. What remains to be done, is to describe this flat connection $\nabla$ on $E$ in a way that does not involve the determinant function, so as to avoid circularity. What we know about $\nabla$ is that it is a flat connection on the trivial $U(1)$ bundle $E$ over $G = U(n)$, such that there exists a global parallel section $s$, unique up to a global phase factor, which is equivariant under $N(T)$. Question 2: how can $\nabla$ be the defined directly (say using Maurer-Cartan 1-forms and geometric things like that)? Edit: The whole point of my post, is to be able to define the determinant function on $U(n)$, simply as a parallel section (parallel with respect to the connection $\nabla$) which has the value 1 at the identity.","Inspired by Geometric interpretation of the determinant of a complex matrix , I ask the following related questions. The complex determinant is determined up to a global scaling factor by the fact that it is multilinear and skew-symmetric. Let us try to understand the phase of the determinant. For that purpose, let us restrict our attention to $G = U(n)$. Let $E = G \times U(1)$ be the trivial $U(1)$ bundle over $G$. Let $T$ denote a maximal torus of $G$; to fix the ideas, let us assume it is the one consisting of all diagonal matrices in $G$. Let $N(T)$ denote the normalizer of $T$ in $G$. $N(T)$ is the semi-direct product of $T$ with the symmetric group $S_n$ ($S_n$ is the full permutation group on $n$ elements). We can now say that the determinant is a global smooth section $s$ of $E$ over $G$ which is further $N(T)$-equivariant. Question 1: do these properties determine $s$ up to a global phase factor? If we let $\nabla$ denote the unique flat connection on $E$ which makes the actual determinant function parallel (i.e. covariantly constant) everywhere, then if we require that the section $s$ be covariantly constant with respect to $\nabla$, then we recover the determinant function uniquely up to a global phase factor, and the symmetry properties under $N(T)$ are automatically satisfied. What remains to be done, is to describe this flat connection $\nabla$ on $E$ in a way that does not involve the determinant function, so as to avoid circularity. What we know about $\nabla$ is that it is a flat connection on the trivial $U(1)$ bundle $E$ over $G = U(n)$, such that there exists a global parallel section $s$, unique up to a global phase factor, which is equivariant under $N(T)$. Question 2: how can $\nabla$ be the defined directly (say using Maurer-Cartan 1-forms and geometric things like that)? Edit: The whole point of my post, is to be able to define the determinant function on $U(n)$, simply as a parallel section (parallel with respect to the connection $\nabla$) which has the value 1 at the identity.",,"['differential-geometry', 'determinant', 'connections']"
94,Determining isometry group of symmetric spaces,Determining isometry group of symmetric spaces,,"I am learning some symmetric spaces, and I tried to look at some example, including Grassmannian (say, $p$-dimensional subspaces in $\mathbb{C}^{p+q}$) and the projective space $\mathbb{CP}^n$. I follow Helgason, therefore I wish to describe them in terms of Lie groups. My problem is: How to determine the isometry group of a manifold whose geometric description is known? Let me elaborate more. For $\mathbb{CP}^n$, I understand that the special unitary group $SU(n+1)$ acts transitively on it. Also, I know the isotropy group for a certain point is $U(n)$. It is tempting now to claim $\mathbb{CP}^n = SU(n+1)/U(n)$. But I have not checked that $SU(n+1)$ is the isometry group! Similar problems arise when I try Grassmannians, Lagrangian Grassmannians, Orthogonal Grassmannians, etc. I usually can find a group acting well on these spaces but I cannot determine whether that group is the isometry group. Anyone can help? Thanks a lot!","I am learning some symmetric spaces, and I tried to look at some example, including Grassmannian (say, $p$-dimensional subspaces in $\mathbb{C}^{p+q}$) and the projective space $\mathbb{CP}^n$. I follow Helgason, therefore I wish to describe them in terms of Lie groups. My problem is: How to determine the isometry group of a manifold whose geometric description is known? Let me elaborate more. For $\mathbb{CP}^n$, I understand that the special unitary group $SU(n+1)$ acts transitively on it. Also, I know the isotropy group for a certain point is $U(n)$. It is tempting now to claim $\mathbb{CP}^n = SU(n+1)/U(n)$. But I have not checked that $SU(n+1)$ is the isometry group! Similar problems arise when I try Grassmannians, Lagrangian Grassmannians, Orthogonal Grassmannians, etc. I usually can find a group acting well on these spaces but I cannot determine whether that group is the isometry group. Anyone can help? Thanks a lot!",,"['differential-geometry', 'riemannian-geometry', 'symmetry']"
95,Isometry group of quotient of Lie group as symmetric space,Isometry group of quotient of Lie group as symmetric space,,"I have been reading about symmetric spaces and studying the correspondence between pointed symmetric Riemannian manifolds (say, $(M,o)$) and Riemannian symmetric pairs, namely a system $(G,K,\sigma)$ where $G$ is a connected Lie group, $K$ a closed subgroup s,t. $Ad(K) \le GL(\mathfrak{g})$ is compact, and $\sigma$ is an involution such that $(G^\sigma)^{\circ} \subset K \subset G^\sigma $. We can construct a $G$-invariant Riemannian structure on $M:=G/K$ and make it a Riemannian symmetric space. It is clear that $G$ acts as isometries on $M$, but is the converse true? That is, is the identity component of the isometry group of $M$ equal to $G$? Thanks in advance!","I have been reading about symmetric spaces and studying the correspondence between pointed symmetric Riemannian manifolds (say, $(M,o)$) and Riemannian symmetric pairs, namely a system $(G,K,\sigma)$ where $G$ is a connected Lie group, $K$ a closed subgroup s,t. $Ad(K) \le GL(\mathfrak{g})$ is compact, and $\sigma$ is an involution such that $(G^\sigma)^{\circ} \subset K \subset G^\sigma $. We can construct a $G$-invariant Riemannian structure on $M:=G/K$ and make it a Riemannian symmetric space. It is clear that $G$ acts as isometries on $M$, but is the converse true? That is, is the identity component of the isometry group of $M$ equal to $G$? Thanks in advance!",,"['differential-geometry', 'lie-groups', 'riemannian-geometry']"
96,metric on SE(3),metric on SE(3),,"Let $ SO(3) = \{ R  \mid RR^\top = I_3 \text{ and } \det(R) = 1 \} $ and $$ SE(3) = \left\{\begin{bmatrix} R & {\bf t} \\ {\bf 0}^\top & 1 \end{bmatrix}\mid R \in SO(3), {\bf t} \in \mathbb{R}^3\right\}. $$ My question is, given two matrices $H_1, H_2 \in SE(3),$ can anyone provide a formula for the geodesic distance between them? My best guess is to add the magnitude of the rotation and the magnitude of the translation. Then, the the distance between $H_1$ and $H_2$ is given by $$ ||H_1 - H_2||  = ||{\rm Rodrigues}(R_1R_2^\top)||_2 +\frac{1}{2} \left( ||{\bf t}_1 - R_2^\top {\bf t}_2||_2+ ||{\bf t}_2 - R_1^\top {\bf t}_1||_2\right), $$ where I am using Rodrigues' formula to find the angle-axis representation for $SO(3)$ in order to easily find the magnitude of a rotation. This is rather ad-hoc, but it at least it is zero when $H_1=H_2$, strictly positive otherwise, and symmetric.  Whether or not it obeys the triangle inequality I do not know for sure, but I think no. Calin Belta and Vijay Kumar's 2002 paper seems to be relevant, but they are talking about smooth rigid motions parameterized by points in $SE(3)$, and not necessarily just looking at the absolute difference that I am interested in.  Maybe its the same, but I don't know enough differential geometry to tell.","Let $ SO(3) = \{ R  \mid RR^\top = I_3 \text{ and } \det(R) = 1 \} $ and $$ SE(3) = \left\{\begin{bmatrix} R & {\bf t} \\ {\bf 0}^\top & 1 \end{bmatrix}\mid R \in SO(3), {\bf t} \in \mathbb{R}^3\right\}. $$ My question is, given two matrices $H_1, H_2 \in SE(3),$ can anyone provide a formula for the geodesic distance between them? My best guess is to add the magnitude of the rotation and the magnitude of the translation. Then, the the distance between $H_1$ and $H_2$ is given by $$ ||H_1 - H_2||  = ||{\rm Rodrigues}(R_1R_2^\top)||_2 +\frac{1}{2} \left( ||{\bf t}_1 - R_2^\top {\bf t}_2||_2+ ||{\bf t}_2 - R_1^\top {\bf t}_1||_2\right), $$ where I am using Rodrigues' formula to find the angle-axis representation for $SO(3)$ in order to easily find the magnitude of a rotation. This is rather ad-hoc, but it at least it is zero when $H_1=H_2$, strictly positive otherwise, and symmetric.  Whether or not it obeys the triangle inequality I do not know for sure, but I think no. Calin Belta and Vijay Kumar's 2002 paper seems to be relevant, but they are talking about smooth rigid motions parameterized by points in $SE(3)$, and not necessarily just looking at the absolute difference that I am interested in.  Maybe its the same, but I don't know enough differential geometry to tell.",,"['differential-geometry', 'metric-spaces', 'rotations']"
97,Hodge conjecture prerequisites.,Hodge conjecture prerequisites.,,"I am in middle with my grad school, and as you know most of the years as a doctorate student focuses  on a very specific topic and a very single problem. I am coming from the world of moduli spaces of sheaves, and my background in algebraic geometry is what you find in Hartshorne, plus whatever similar topics in moduli spaces of sheaves. Unfortunately, I don't have a complex algebraic geometer in my department who works in Hodge conjuctere  related stuff. After graduation, I will have a small job in a small university where I will not have the pressure of publishing papers, and I want to devote my time to work on Hodge conjecture. Not only I hope to resolve it, but also I find the topic and related math very nice and attractive. my questions: with someone with experience in algebraic geometry as in Hartshorne, and the book Geometry of moduli space of sheaves, How far someone is from handling complex geometry topics? Can you please help me on where to start, i,e. what are the books that cover the basics? what are the books that come after the books of the basics? including anything in deferential geometry, or any other geometry. what are the good starting research Papers to look at? how to keep up with improvments? what are the mathematicians names who are famous for the subjects and can be approached?. Any advise is appreciated. Thank you all .","I am in middle with my grad school, and as you know most of the years as a doctorate student focuses  on a very specific topic and a very single problem. I am coming from the world of moduli spaces of sheaves, and my background in algebraic geometry is what you find in Hartshorne, plus whatever similar topics in moduli spaces of sheaves. Unfortunately, I don't have a complex algebraic geometer in my department who works in Hodge conjuctere  related stuff. After graduation, I will have a small job in a small university where I will not have the pressure of publishing papers, and I want to devote my time to work on Hodge conjecture. Not only I hope to resolve it, but also I find the topic and related math very nice and attractive. my questions: with someone with experience in algebraic geometry as in Hartshorne, and the book Geometry of moduli space of sheaves, How far someone is from handling complex geometry topics? Can you please help me on where to start, i,e. what are the books that cover the basics? what are the books that come after the books of the basics? including anything in deferential geometry, or any other geometry. what are the good starting research Papers to look at? how to keep up with improvments? what are the mathematicians names who are famous for the subjects and can be approached?. Any advise is appreciated. Thank you all .",,"['differential-geometry', 'algebraic-geometry']"
98,A proof that parallel transport preserves orientation,A proof that parallel transport preserves orientation,,"Let $M$ be a riemannian manifold (With the Levi-Civita connection), $c$ a curve in $M$ with $c(t_0)=c_0,c(t)=c_t$ $P_{c,t_0,t}$ denote the function $T_{c_0}M\to T_{c_t}M$ given by parallel transporting each tangent vector $v\in T_{c_0}M$ to $T_{c_t}M$ along the curve $c$. I want to prove that $P=P_{c,t_0,t}$ is an isometry which preserves orientation, given that $M$ is orientable. I've already proven that it's an isometry and its inverse is given by $P_{c,t,t_0}$. I now want to prove, that, with the orientation induced by $\phi_t:\mathbb{R}^n\to T_{c_t}M$ with $\phi_t(e_i)=\partial_{i,c_t}$ the orientation is preserved. In other words, the mapping $P':T_{c_t}M\to T_{c_t}M$ given by $\partial_{i,c_t}\mapsto P_{c,t_0,t}\partial_{i,c_0}$ has positive determinant with respect to those bases. Since it's an isometry, then its determinant is $\pm 1$, so I just have to prove it's $1$. If the function $d:\text{dom} c\to \mathbb{R}$ given by $t\mapsto \det P'$ is continuous, then since $d(t_0)=1$, if $d(t_1)=-1$ there would be some $t\in (t_0,t_1)$ such that $d(t)=0$ and this is impossible. So the only thing left is to prove that $d$ is continuous. How could I do that? An idea would be, that this function can be seen as a composition of continuous functions: $t_0\stackrel{V}{\to} V_{c(t_0)}\stackrel{P}{\to} V_{c(t)}\stackrel{?}{\to}d(t_0)$ but I'm not sure what would go in ?.","Let $M$ be a riemannian manifold (With the Levi-Civita connection), $c$ a curve in $M$ with $c(t_0)=c_0,c(t)=c_t$ $P_{c,t_0,t}$ denote the function $T_{c_0}M\to T_{c_t}M$ given by parallel transporting each tangent vector $v\in T_{c_0}M$ to $T_{c_t}M$ along the curve $c$. I want to prove that $P=P_{c,t_0,t}$ is an isometry which preserves orientation, given that $M$ is orientable. I've already proven that it's an isometry and its inverse is given by $P_{c,t,t_0}$. I now want to prove, that, with the orientation induced by $\phi_t:\mathbb{R}^n\to T_{c_t}M$ with $\phi_t(e_i)=\partial_{i,c_t}$ the orientation is preserved. In other words, the mapping $P':T_{c_t}M\to T_{c_t}M$ given by $\partial_{i,c_t}\mapsto P_{c,t_0,t}\partial_{i,c_0}$ has positive determinant with respect to those bases. Since it's an isometry, then its determinant is $\pm 1$, so I just have to prove it's $1$. If the function $d:\text{dom} c\to \mathbb{R}$ given by $t\mapsto \det P'$ is continuous, then since $d(t_0)=1$, if $d(t_1)=-1$ there would be some $t\in (t_0,t_1)$ such that $d(t)=0$ and this is impossible. So the only thing left is to prove that $d$ is continuous. How could I do that? An idea would be, that this function can be seen as a composition of continuous functions: $t_0\stackrel{V}{\to} V_{c(t_0)}\stackrel{P}{\to} V_{c(t)}\stackrel{?}{\to}d(t_0)$ but I'm not sure what would go in ?.",,"['differential-geometry', 'riemannian-geometry']"
99,Show that $S$ is non-orientable,Show that  is non-orientable,S,"Let $S$ be a regular surface covered by coordinate neighborhoods $V_1$ and $V_2$. Assume that $V_1\cap V_2$ has two connected components, $W_1$, $W_2$, and that the Jacobian of the change of coordinates is positive in $W_1$ and negative in $W_2$. Show that $S$ is non-orientable. I know that, if a regular surface $S$, can be covered by two coordinate neighborhoods, whose intersection is connected, then the surface is orientable. Furthermore, if $f:S\subset\mathbb{R}^3\to\mathbb{R}$ is a continuous function, in a connected surface $S$, then $f$ doesn't change of sign on $S$. Can give any hint! Thanks!","Let $S$ be a regular surface covered by coordinate neighborhoods $V_1$ and $V_2$. Assume that $V_1\cap V_2$ has two connected components, $W_1$, $W_2$, and that the Jacobian of the change of coordinates is positive in $W_1$ and negative in $W_2$. Show that $S$ is non-orientable. I know that, if a regular surface $S$, can be covered by two coordinate neighborhoods, whose intersection is connected, then the surface is orientable. Furthermore, if $f:S\subset\mathbb{R}^3\to\mathbb{R}$ is a continuous function, in a connected surface $S$, then $f$ doesn't change of sign on $S$. Can give any hint! Thanks!",,['differential-geometry']
