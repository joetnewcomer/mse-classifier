,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,A non-zero continuous function such that summing over equally spaced values always gives zero,A non-zero continuous function such that summing over equally spaced values always gives zero,,"A long time ago now, I wondered whether or not there exists some sequence of real numbers $(a_n)_{n \in \mathbb{N}}$ , different from the zero sequence, such that for any $m \in \mathbb{N}$ , $$ \sum_{n=1}^{\infty} \, a_{nm} = 0. $$ To avoid any confusion: I really mean the product $nm$ in the subscript, it does not indicate an array of numbers. A friend of mine found a solution to this problem: $a_n = \mu(n)/n$ , where $\mu$ denotes the Möbius function, should work. Now, this makes it easy to construct a function $f : \mathbb{R} \to \mathbb{R}$ , different from the zero function, with the property that $$ \sum_{n=1}^{\infty} f(\alpha n) = 0, $$ for all $\alpha \in \mathbb{R}$ , but it would of course by no means be continuous. Indeed, we may set $f(n) = a_n$ for all $n \in \mathbb{N}$ and extend by zero everywhere else. Therefore my question is: does such a continuous function exist?","A long time ago now, I wondered whether or not there exists some sequence of real numbers , different from the zero sequence, such that for any , To avoid any confusion: I really mean the product in the subscript, it does not indicate an array of numbers. A friend of mine found a solution to this problem: , where denotes the Möbius function, should work. Now, this makes it easy to construct a function , different from the zero function, with the property that for all , but it would of course by no means be continuous. Indeed, we may set for all and extend by zero everywhere else. Therefore my question is: does such a continuous function exist?","(a_n)_{n \in \mathbb{N}} m \in \mathbb{N} 
\sum_{n=1}^{\infty} \, a_{nm} = 0.
 nm a_n = \mu(n)/n \mu f : \mathbb{R} \to \mathbb{R} 
\sum_{n=1}^{\infty} f(\alpha n) = 0,
 \alpha \in \mathbb{R} f(n) = a_n n \in \mathbb{N}","['limits', 'elementary-number-theory', 'discrete-mathematics', 'continuity']"
1,"What is the limit of zero times x, as x approaches infinity?","What is the limit of zero times x, as x approaches infinity?",,"I am having difficulty determining is the solution for the following problem: $$\displaystyle \lim_{x \rightarrow \infty}\left( x \times 0 \right)$$ To clarify, this question assumes ${0}$ is a constant and is absolutely zero (""true zero""), and not another figure approaching or is approximately zero (""near zero""). Thus, the question is not asking what ""near zero"" times ""near infinity"" is. I know that ${\infty *0}$ is undefined, however my difficulty is that I'm unsure whether the answer to the problem is undefined because ${\infty *0}$ is undefined. From my understanding, a limit does not ever 'reach' infinity - it only approaches infinity, thus there are a rational amount of numbers. As ${x\cdot 0=0}$ , when x is not ${\infty}$ , it seems to me that in all cases of $x$ approaching infinity the answer could also be ${0}$ .","I am having difficulty determining is the solution for the following problem: To clarify, this question assumes is a constant and is absolutely zero (""true zero""), and not another figure approaching or is approximately zero (""near zero""). Thus, the question is not asking what ""near zero"" times ""near infinity"" is. I know that is undefined, however my difficulty is that I'm unsure whether the answer to the problem is undefined because is undefined. From my understanding, a limit does not ever 'reach' infinity - it only approaches infinity, thus there are a rational amount of numbers. As , when x is not , it seems to me that in all cases of approaching infinity the answer could also be .",\displaystyle \lim_{x \rightarrow \infty}\left( x \times 0 \right) {0} {\infty *0} {\infty *0} {x\cdot 0=0} {\infty} x {0},['limits']
2,How much is $\lceil\frac{1}{\infty}\rceil$?,How much is ?,\lceil\frac{1}{\infty}\rceil,"How much is  $\lceil\frac{1}{\infty}\rceil$  ? On one hand, $\frac{1}{\infty}=0$, so its ceiling is also $0$. On the other hand, for all $x\geq 1$, $\lceil\frac{1}{x}\rceil = 1$, so, when $x$ goes to infinity, the function should remain with the same value...","How much is  $\lceil\frac{1}{\infty}\rceil$  ? On one hand, $\frac{1}{\infty}=0$, so its ceiling is also $0$. On the other hand, for all $x\geq 1$, $\lceil\frac{1}{x}\rceil = 1$, so, when $x$ goes to infinity, the function should remain with the same value...",,"['limits', 'ceiling-and-floor-functions']"
3,Limit of $s_n=\frac{1}{\sqrt{n}}\left(1+\frac{1}{\sqrt{2}}+\cdots +\frac{1}{\sqrt{n}}\right)$,Limit of,s_n=\frac{1}{\sqrt{n}}\left(1+\frac{1}{\sqrt{2}}+\cdots +\frac{1}{\sqrt{n}}\right),"\begin{align*}S_n=\frac{1}{\sqrt{n}}\left(1+\frac{1}{\sqrt{2}}+\cdots +\frac{1}{\sqrt{n}}\right)\end{align*} how to calculate the limit $s_n$? \begin{align*}\lim_{n\to \infty } \, S_n\end{align*}","\begin{align*}S_n=\frac{1}{\sqrt{n}}\left(1+\frac{1}{\sqrt{2}}+\cdots +\frac{1}{\sqrt{n}}\right)\end{align*} how to calculate the limit $s_n$? \begin{align*}\lim_{n\to \infty } \, S_n\end{align*}",,"['limits', 'summation', 'radicals']"
4,Why do I get two different answers while doing this simple limit math?,Why do I get two different answers while doing this simple limit math?,,"Problem: $$\lim_{n\to\infty} \frac{1}{n^3}\cdot\frac{n(n+1)(2n+1)}{6}$$ Attempt 1: $$\lim_{n\to\infty} \frac{1}{n^3}\cdot\frac{n(n+1)(2n+1)}{6}$$ $$=\lim_{n\to\infty} \frac{(n+1)(2n+1)}{6n^2}$$ $$=\lim_{n\to\infty} \frac{n+1}{6n}\cdot\frac{2n+1}{n}$$ $$=\lim_{n\to\infty} \left(\frac{1}{6}+\frac{1}{6n}\right)\cdot\left(2+\frac{1}{n}\right)$$ $$=\left(\frac{1}{6}+0\right)\cdot\left(2+0\right)$$ $$=\frac{1}{6}\cdot2$$ $$=\frac{1}{3}$$ Attempt 2: $$\lim_{n\to\infty} \frac{1}{n^3}\cdot\frac{n(n+1)(2n+1)}{6}$$ $$=\lim_{n\to\infty} \frac{1}{n^3}\cdot\lim_{n\to\infty}\frac{n(n+1)(2n+1)}{6}$$ $$=0\cdot\lim_{n\to\infty}\frac{n(n+1)(2n+1)}{6}$$ $$=0$$ I know that attempt 1 is the correct attempt; however, I'm unsure as to why attempt 2 is not working. Why is attempt 2 not working?","Problem: Attempt 1: Attempt 2: I know that attempt 1 is the correct attempt; however, I'm unsure as to why attempt 2 is not working. Why is attempt 2 not working?",\lim_{n\to\infty} \frac{1}{n^3}\cdot\frac{n(n+1)(2n+1)}{6} \lim_{n\to\infty} \frac{1}{n^3}\cdot\frac{n(n+1)(2n+1)}{6} =\lim_{n\to\infty} \frac{(n+1)(2n+1)}{6n^2} =\lim_{n\to\infty} \frac{n+1}{6n}\cdot\frac{2n+1}{n} =\lim_{n\to\infty} \left(\frac{1}{6}+\frac{1}{6n}\right)\cdot\left(2+\frac{1}{n}\right) =\left(\frac{1}{6}+0\right)\cdot\left(2+0\right) =\frac{1}{6}\cdot2 =\frac{1}{3} \lim_{n\to\infty} \frac{1}{n^3}\cdot\frac{n(n+1)(2n+1)}{6} =\lim_{n\to\infty} \frac{1}{n^3}\cdot\lim_{n\to\infty}\frac{n(n+1)(2n+1)}{6} =0\cdot\lim_{n\to\infty}\frac{n(n+1)(2n+1)}{6} =0,"['limits', 'solution-verification', 'limits-without-lhopital']"
5,Find $\lim_{x\to-\infty}{x+e^{-x}}$,Find,\lim_{x\to-\infty}{x+e^{-x}},"I have this exercise in my worksheet: $$\lim_{x\to-\infty}{x+e^{-x}}$$ I am always ending up with $-∞+∞$ or $\frac{∞}{∞}$. It says the answer is $+∞$, but how can I get that?","I have this exercise in my worksheet: $$\lim_{x\to-\infty}{x+e^{-x}}$$ I am always ending up with $-∞+∞$ or $\frac{∞}{∞}$. It says the answer is $+∞$, but how can I get that?",,"['limits', 'exponential-function', 'infinity']"
6,Long limit question,Long limit question,,If $$\lim_{x \to \infty}\frac{a(2x^3-x^2)+b(x^3+5x^2-1)-c(3x^3+x^2)}{a(5x^4-x)-bx^4+c(4x^4+1)+2x^2+5x}=1$$ then find the value of $a+b+c$. I have done such problems with $x$ tending to some finite amount. Infinity is creating some problems.,If $$\lim_{x \to \infty}\frac{a(2x^3-x^2)+b(x^3+5x^2-1)-c(3x^3+x^2)}{a(5x^4-x)-bx^4+c(4x^4+1)+2x^2+5x}=1$$ then find the value of $a+b+c$. I have done such problems with $x$ tending to some finite amount. Infinity is creating some problems.,,['limits']
7,Trigonometry limit's proof: $\lim_{x\to0}\frac{\sin(x)+\sin(2x)+\cdots+\sin(kx)}{x}=\frac{k(k+1)}{2}$,Trigonometry limit's proof:,\lim_{x\to0}\frac{\sin(x)+\sin(2x)+\cdots+\sin(kx)}{x}=\frac{k(k+1)}{2},How to prove that $$\lim_{x\to0}\frac{\sin(x)+\sin(2x)+\cdots+\sin(kx)}{x}=\frac{k(k+1)}{2}$$ I tried to split up the fraction and multiple-divide every new fraction with its $x$ factor but didn't work out. ex: $$\lim_{x\to 0}\frac{\sin(2x)}{x} = \lim_{x\to 0}\frac{\sin(2x)\cdot 2}{2\cdot x}=2$$,How to prove that $$\lim_{x\to0}\frac{\sin(x)+\sin(2x)+\cdots+\sin(kx)}{x}=\frac{k(k+1)}{2}$$ I tried to split up the fraction and multiple-divide every new fraction with its $x$ factor but didn't work out. ex: $$\lim_{x\to 0}\frac{\sin(2x)}{x} = \lim_{x\to 0}\frac{\sin(2x)\cdot 2}{2\cdot x}=2$$,,"['limits', 'trigonometry', 'summation', 'limits-without-lhopital']"
8,How to evaluate $\lim_{x\to 0} (1+2x)^{1/x}$,How to evaluate,\lim_{x\to 0} (1+2x)^{1/x},Good night guys! I'm having some trouble with this: $$\lim_{x\to 0} (1+2x)^{1/x}$$ I know that $\lim_{x\to\infty} (1 + 1/x)^x = e$ but I don't know if i should take $h=1/(2x)$ or $h=1/x$ Can someone please help me? Thanks!,Good night guys! I'm having some trouble with this: $$\lim_{x\to 0} (1+2x)^{1/x}$$ I know that $\lim_{x\to\infty} (1 + 1/x)^x = e$ but I don't know if i should take $h=1/(2x)$ or $h=1/x$ Can someone please help me? Thanks!,,['limits']
9,Help understand Taylor's theorem - “when” does a function becomes linear?,Help understand Taylor's theorem - “when” does a function becomes linear?,,"It is known that for relatively small intervals around some value (say $a$), any (any?) continuous and differentiable function $f$ can be approximated (in the region of the interval) to a linear function via Taylor's theorem with: $f(x) = f(a) + f'(a)*(x-a) + h_k(x)(x-a)$ How is this notion defined more precisely? For example, say that I take the function $x^2$, and I am interested in a region around $x=1$, how can I say how close my function is to linear, as the region around 1 becomes smaller?","It is known that for relatively small intervals around some value (say $a$), any (any?) continuous and differentiable function $f$ can be approximated (in the region of the interval) to a linear function via Taylor's theorem with: $f(x) = f(a) + f'(a)*(x-a) + h_k(x)(x-a)$ How is this notion defined more precisely? For example, say that I take the function $x^2$, and I am interested in a region around $x=1$, how can I say how close my function is to linear, as the region around 1 becomes smaller?",,['limits']
10,Please explain how to solve limit. I know the answer but how to explain it?,Please explain how to solve limit. I know the answer but how to explain it?,,"Problem: $a@b = \frac{a+b}{ab+1}$ . Solve limit: $\lim_{n \to \infty}(2@3@...@n)$ . I've tried to solve this problem by just calculating: $$2 @ 3 = 0.714$$ $$2 @ 3 @ 4 = 1.222$$ $$2 @ 3 @ 4 @ 5 = 0.875$$ $$2 @ 3 @ 4 @ 5 @ 6 = 1.1$$ I found the pattern. The first number is less than 1, then the next is greater than 1, the next is less than 1, and so on. So the limit must be 1. But how to explain it mathematically? I've tried to transform this: $$(n-1)@n = \frac{2n-1}{n^2-n+1}$$ $$n@(n+1) = \frac{2n + 1}{n^2+n+1}$$ But it didn't help me to understand the method how to solve it. I think there should be a simple idea, which I don't see. I appreciate all hints.","Problem: . Solve limit: . I've tried to solve this problem by just calculating: I found the pattern. The first number is less than 1, then the next is greater than 1, the next is less than 1, and so on. So the limit must be 1. But how to explain it mathematically? I've tried to transform this: But it didn't help me to understand the method how to solve it. I think there should be a simple idea, which I don't see. I appreciate all hints.",a@b = \frac{a+b}{ab+1} \lim_{n \to \infty}(2@3@...@n) 2 @ 3 = 0.714 2 @ 3 @ 4 = 1.222 2 @ 3 @ 4 @ 5 = 0.875 2 @ 3 @ 4 @ 5 @ 6 = 1.1 (n-1)@n = \frac{2n-1}{n^2-n+1} n@(n+1) = \frac{2n + 1}{n^2+n+1},['limits']
11,Compute $\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2}$,Compute,\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2},"I have to compute $\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2}$. I tried say that this limit exists and it's l, so we have $\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2} = L$ then I rewrited it as: $\lim_{n\rightarrow\infty}(\frac{\sqrt n}{\sqrt[n]{n!}})^{2n}$ then I used natural log over the whole expresion but didn't got into a nice place. I don't know about Pi function or gamma function so therefore can't really use L'Hospital's rule.","I have to compute $\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2}$. I tried say that this limit exists and it's l, so we have $\lim_{n\rightarrow\infty}\frac{n^n}{(n!)^2} = L$ then I rewrited it as: $\lim_{n\rightarrow\infty}(\frac{\sqrt n}{\sqrt[n]{n!}})^{2n}$ then I used natural log over the whole expresion but didn't got into a nice place. I don't know about Pi function or gamma function so therefore can't really use L'Hospital's rule.",,"['limits', 'limits-without-lhopital']"
12,How find this $f(k)=\sum_{n=1}^{\infty}\frac{n^k}{2^n}$ is positive integers?,How find this  is positive integers?,f(k)=\sum_{n=1}^{\infty}\frac{n^k}{2^n},"Question: let $$f(k)=\sum_{n=1}^{\infty}\dfrac{n^k}{2^n},k\in N^{+}$$ show that:   $f(k)$is always postive integer numbers. this is problem is my creat it,maybe is old problem,because when I deal following $$f(1)=\sum_{n=1}^{\infty}\dfrac{n}{2^n}$$ and this solution: $$\sum_{n=1}^{\infty}nx^n=x\sum_{n=1}^{\infty}nx^{n-1}=\dfrac{x}{(1-x)^2}$$ so $$f(1)=2$$ and use same methods $$f(2)=\sum_{n=1}^{\infty}\dfrac{n^2}{2^n}=6$$ $$f(3)=\sum_{n=1}^{\infty}\dfrac{n^3}{2^n}=26$$ $$f(4)=\sum_{n=1}^{\infty}\dfrac{n^4}{2^n}=150$$ $$\cdots\cdots\cdots$$ and How prove $f(k)$ is postive integers,and maybe find the $f(k)=?$","Question: let $$f(k)=\sum_{n=1}^{\infty}\dfrac{n^k}{2^n},k\in N^{+}$$ show that:   $f(k)$is always postive integer numbers. this is problem is my creat it,maybe is old problem,because when I deal following $$f(1)=\sum_{n=1}^{\infty}\dfrac{n}{2^n}$$ and this solution: $$\sum_{n=1}^{\infty}nx^n=x\sum_{n=1}^{\infty}nx^{n-1}=\dfrac{x}{(1-x)^2}$$ so $$f(1)=2$$ and use same methods $$f(2)=\sum_{n=1}^{\infty}\dfrac{n^2}{2^n}=6$$ $$f(3)=\sum_{n=1}^{\infty}\dfrac{n^3}{2^n}=26$$ $$f(4)=\sum_{n=1}^{\infty}\dfrac{n^4}{2^n}=150$$ $$\cdots\cdots\cdots$$ and How prove $f(k)$ is postive integers,and maybe find the $f(k)=?$",,"['limits', 'summation']"
13,Prove that $\lim\frac{1}{n}\sum_{k=1}^n a_kb_{n+1-k}=(\lim a_n)(\lim b_n)$,Prove that,\lim\frac{1}{n}\sum_{k=1}^n a_kb_{n+1-k}=(\lim a_n)(\lim b_n),"Let $ \displaystyle \lim_{n \to \infty} a_{n} = a $ and $ \displaystyle \lim_{n \to \infty} b_{n} = b $. Prove that: $$ \lim_{n \to \infty} u_{n} := \lim_{n \to \infty} \frac{a_{1} b_{n} + a_{2} b_{n - 1} + \cdots + a_{n} b_{1}}{n} = ab. $$ I tried to put $ x_{n} \leq u_{n} \leq y_{n} $, but I can’t.","Let $ \displaystyle \lim_{n \to \infty} a_{n} = a $ and $ \displaystyle \lim_{n \to \infty} b_{n} = b $. Prove that: $$ \lim_{n \to \infty} u_{n} := \lim_{n \to \infty} \frac{a_{1} b_{n} + a_{2} b_{n - 1} + \cdots + a_{n} b_{1}}{n} = ab. $$ I tried to put $ x_{n} \leq u_{n} \leq y_{n} $, but I can’t.",,['limits']
14,how to find this limit $\lim_{x\rightarrow 0} \frac{\sin x^2}{ \ln ( \cos x^2 \cos x + \sin x^2 \sin x)} = -2$ without using L'Hôpital's rule,how to find this limit  without using L'Hôpital's rule,\lim_{x\rightarrow 0} \frac{\sin x^2}{ \ln ( \cos x^2 \cos x + \sin x^2 \sin x)} = -2,I am looking for simple trigonometric or algebraic manipulation so that this limit can be solved without using L'Hôpital's rule $$ \lim_{x\rightarrow 0} \frac{\sin x^2}{ \ln ( \cos x^2 \cos x + \sin x^2 \sin x)} = -2$$ link on wolframalpha. Thank you for help!!,I am looking for simple trigonometric or algebraic manipulation so that this limit can be solved without using L'Hôpital's rule $$ \lim_{x\rightarrow 0} \frac{\sin x^2}{ \ln ( \cos x^2 \cos x + \sin x^2 \sin x)} = -2$$ link on wolframalpha. Thank you for help!!,,"['trigonometry', 'limits']"
15,If $y=x^{x^{x^{x^{x^{.^{.^{.}}}}}}}$ then how $y=x^y$?,If  then how ?,y=x^{x^{x^{x^{x^{.^{.^{.}}}}}}} y=x^y,"In questions like, find the derivative of $f(x)=x^{x^{x^{x^{x^{.^{.^{.}}}}}}}$, how can we formally show that $y=x^y$? We use this technique for all type of iterations, e.g. $y=\sqrt{6+\sqrt{6+\sqrt{6+\cdots}}}$, we say $y= \sqrt{6+y}$ and solve the quadratic equation. Intuitively they seem to use the fact that $\infty +1=\infty$, that is the expression has an infinite number of terms so adding or deleting one term won't change the expression. But This logic is quite informal or we can say non-rigorous. Can we somehow show this formally, e.g. by using the $\epsilon - \delta$ definition of limit or something like that ?","In questions like, find the derivative of $f(x)=x^{x^{x^{x^{x^{.^{.^{.}}}}}}}$, how can we formally show that $y=x^y$? We use this technique for all type of iterations, e.g. $y=\sqrt{6+\sqrt{6+\sqrt{6+\cdots}}}$, we say $y= \sqrt{6+y}$ and solve the quadratic equation. Intuitively they seem to use the fact that $\infty +1=\infty$, that is the expression has an infinite number of terms so adding or deleting one term won't change the expression. But This logic is quite informal or we can say non-rigorous. Can we somehow show this formally, e.g. by using the $\epsilon - \delta$ definition of limit or something like that ?",,"['limits', 'infinity', 'tetration']"
16,limit of the sum $\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{2n} $ [duplicate],limit of the sum  [duplicate],\frac{1}{n+1}+\frac{1}{n+2}+\cdots+\frac{1}{2n} ,"This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 8 years ago . Prove that : $\displaystyle \lim_{n\to \infty} \frac{1}{n+1}+\frac{1}{n+2}+\frac{1}{n+3}+\cdots+\frac{1}{2n}=\ln 2$ the only thing I could think of is that it can be written like this : $$ \lim_{n\to \infty} \sum_{k=1}^n \frac{1}{k+n} =\lim_{n\to \infty} \frac{1}{n} \sum_{k=1}^n \frac{1}{\frac{k}{n}+1}=\int_0^1 \frac{1}{x+1} \ \mathrm{d}x=\ln 2$$ is my answer right ? and are there any other method ?(I'm sure there are)","This question already has answers here : The limit of truncated sums of harmonic series, $\lim\limits_{k\to\infty}\sum_{n=k+1}^{2k}{\frac{1}{n}}$ (12 answers) Closed 8 years ago . Prove that : $\displaystyle \lim_{n\to \infty} \frac{1}{n+1}+\frac{1}{n+2}+\frac{1}{n+3}+\cdots+\frac{1}{2n}=\ln 2$ the only thing I could think of is that it can be written like this : $$ \lim_{n\to \infty} \sum_{k=1}^n \frac{1}{k+n} =\lim_{n\to \infty} \frac{1}{n} \sum_{k=1}^n \frac{1}{\frac{k}{n}+1}=\int_0^1 \frac{1}{x+1} \ \mathrm{d}x=\ln 2$$ is my answer right ? and are there any other method ?(I'm sure there are)",,"['limits', 'summation']"
17,Limit in number theory,Limit in number theory,,"I was given the following thing to prove: $$\lim_{n \to \infty} {d(n) \over n} = 0$$ where $d(n)$ is the number of divisors of n. I'm so sure how to approach this question. One way I thought of is to use the UFT to turn the expression to: $$\lim_{n \to \infty} {\prod (x_i + 1) \over \prod p_i^{x_i}}$$ And then to use L'Hôpital's rule for each $x_i$, so I get something like this: $$\lim_{n \to \infty} {1 \over \ln (\sum p_i) \prod p_i^{x_i}}$$ That equals zero. Is this a good approach? Is there a different way to solve this?","I was given the following thing to prove: $$\lim_{n \to \infty} {d(n) \over n} = 0$$ where $d(n)$ is the number of divisors of n. I'm so sure how to approach this question. One way I thought of is to use the UFT to turn the expression to: $$\lim_{n \to \infty} {\prod (x_i + 1) \over \prod p_i^{x_i}}$$ And then to use L'Hôpital's rule for each $x_i$, so I get something like this: $$\lim_{n \to \infty} {1 \over \ln (\sum p_i) \prod p_i^{x_i}}$$ That equals zero. Is this a good approach? Is there a different way to solve this?",,"['number-theory', 'limits']"
18,Evaluating the value of first derivative at $x=1$ for a polynomial $f$ satisfying $f(x)+f'(x)+f''(x)=x^5+64$,Evaluating the value of first derivative at  for a polynomial  satisfying,x=1 f f(x)+f'(x)+f''(x)=x^5+64,"Let $f(x)$ be a polynomial function such that $f(x)+f'(x)+f''(x)=x^5+64$ . Then, the value of $\lim_{x \to 1}\frac{f(x)}{x-1}$ is $\boxed{A) \; -15}$ $B) \; -60$ $C) \; 60$ $D) \; 15$ I have solved it by considering a $5$ degree general polynomial of the form $ax^5+bx^4+cx^3+dx^2+ex+f$ and then algebraically solving to obtain the required result. Is there any other method which doesn't include assumption of a function of any kind? Source: JEE Mains 2022 25th June Shift-1","Let be a polynomial function such that . Then, the value of is I have solved it by considering a degree general polynomial of the form and then algebraically solving to obtain the required result. Is there any other method which doesn't include assumption of a function of any kind? Source: JEE Mains 2022 25th June Shift-1",f(x) f(x)+f'(x)+f''(x)=x^5+64 \lim_{x \to 1}\frac{f(x)}{x-1} \boxed{A) \; -15} B) \; -60 C) \; 60 D) \; 15 5 ax^5+bx^4+cx^3+dx^2+ex+f,"['limits', 'functions']"
19,How find this limits $\lim_{n\to\infty}\left(\sin{\frac{\ln{2}}{2}}+\sin{\frac{\ln{3}}{3}}+\cdots+\sin{\frac{\ln{n}}{n}}\right)^{1/n}$,How find this limits,\lim_{n\to\infty}\left(\sin{\frac{\ln{2}}{2}}+\sin{\frac{\ln{3}}{3}}+\cdots+\sin{\frac{\ln{n}}{n}}\right)^{1/n},"Find this limit   $$\lim_{n\to\infty}\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{n}}{n}}\right)^{1/n}$$ My idea:use  $$x=e^{\ln{x}}$$ so we only find $$\lim_{n\to \infty}\dfrac{\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{n}}{n}}\right)}}{n}$$ then $$\lim_{n\to\infty}\dfrac{\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{(n+1)}}{n+1}}\right)}-\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{n}}{n}}\right)}}{(n+1)-n}=\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{(n+1)}}{n+1}}\right)}-\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{n}}{n}}\right)}$$ then I can't works,Thank you","Find this limit   $$\lim_{n\to\infty}\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{n}}{n}}\right)^{1/n}$$ My idea:use  $$x=e^{\ln{x}}$$ so we only find $$\lim_{n\to \infty}\dfrac{\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{n}}{n}}\right)}}{n}$$ then $$\lim_{n\to\infty}\dfrac{\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{(n+1)}}{n+1}}\right)}-\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{n}}{n}}\right)}}{(n+1)-n}=\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{(n+1)}}{n+1}}\right)}-\ln{\left(\sin{\dfrac{\ln{2}}{2}}+\sin{\dfrac{\ln{3}}{3}}+\cdots+\sin{\dfrac{\ln{n}}{n}}\right)}$$ then I can't works,Thank you",,"['analysis', 'limits']"
20,$\sum_{n=1}^x\sin n$ is never greater than 2?,is never greater than 2?,\sum_{n=1}^x\sin n,"I was playing around with Desmos, and I put in the following equation: $$y=\sum_{n=1}^{100x}\sin n$$ I'm not quite sure what I was expecting, but I noticed that the seemingly random dots it produced were never greater than y=2 (and never less than y=-0.25). I'm wondering if there is any proof and/or explanation that that is the case. Also, what branch of math would this problem fall under? It really interests me and I would like to know. Thanks.","I was playing around with Desmos, and I put in the following equation: $$y=\sum_{n=1}^{100x}\sin n$$ I'm not quite sure what I was expecting, but I noticed that the seemingly random dots it produced were never greater than y=2 (and never less than y=-0.25). I'm wondering if there is any proof and/or explanation that that is the case. Also, what branch of math would this problem fall under? It really interests me and I would like to know. Thanks.",,"['limits', 'trigonometry']"
21,Evaluating the factorial-related limit $\lim_{x \to \infty} (x + 1)!^{1 / (x + 1)} - x!^{1/x}$,Evaluating the factorial-related limit,\lim_{x \to \infty} (x + 1)!^{1 / (x + 1)} - x!^{1/x},"I'm looking for the limit $$\lim_{x \to \infty} \left[[(x+1)!]^\frac{1}{1+x} - (x!)^\frac{1}{x}\right].$$ I've put the above in a computer program, and evaluated it at very high values of $x$ (at $x = 100\text{ }000$, it is approximately $0.367881$). The value seems to be caving in to $1/e$, which is $0.3678794412\ldots$ That makes sense, as $e$ has an expansion related to factorial. However I'm stuck trying to figure out a proof if there is any. Thanks for any help.","I'm looking for the limit $$\lim_{x \to \infty} \left[[(x+1)!]^\frac{1}{1+x} - (x!)^\frac{1}{x}\right].$$ I've put the above in a computer program, and evaluated it at very high values of $x$ (at $x = 100\text{ }000$, it is approximately $0.367881$). The value seems to be caving in to $1/e$, which is $0.3678794412\ldots$ That makes sense, as $e$ has an expansion related to factorial. However I'm stuck trying to figure out a proof if there is any. Thanks for any help.",,"['limits', 'factorial']"
22,Formula for $\pi$: what did Doron Zeilberger mean instead of $\pi = \lim_{n} \frac{4^n}{{2n \choose n}n}$?,Formula for : what did Doron Zeilberger mean instead of ?,\pi \pi = \lim_{n} \frac{4^n}{{2n \choose n}n},"I just watched the Vimeo video ""What is Pi and what it is not"" where Doron Zeilberger talks about $\pi$ . At around 16:00, he writes this on the blackboard: $$\pi = \lim_{n} \frac{4^n}{{2n \choose n}n}$$ But that doesn't work. As $n$ increases, this expression seems to tend towards $0$ . Does anyone have a clue as to what he might have meant to write? I'm guessing the expression needs only a little adjustment.","I just watched the Vimeo video ""What is Pi and what it is not"" where Doron Zeilberger talks about . At around 16:00, he writes this on the blackboard: But that doesn't work. As increases, this expression seems to tend towards . Does anyone have a clue as to what he might have meant to write? I'm guessing the expression needs only a little adjustment.",\pi \pi = \lim_{n} \frac{4^n}{{2n \choose n}n} n 0,"['limits', 'pi']"
23,Closed form of $\lim\limits_{n\to\infty}\left(\int_0^{n}\frac{{\rm d}k}{\sqrt{k}}-\sum_{k=1}^n\frac1{\sqrt k}\right)$,Closed form of,\lim\limits_{n\to\infty}\left(\int_0^{n}\frac{{\rm d}k}{\sqrt{k}}-\sum_{k=1}^n\frac1{\sqrt k}\right),"Show that     $$ L=\lim_{s\rightarrow\infty}\left(\int_0^s\frac{ds'}{\sqrt{s'}}-\sum_{s'=1}^s\frac{1}{\sqrt{s'}}\right) = 1.460\ldots $$ My attempts: To begin, rewriting the limit of the form $$ L=\lim_{\epsilon\rightarrow0}\left(\int_0^{\infty}\frac{e^{-\epsilon s'}}{\sqrt{s'}}ds'-\sum_{s'=1}^{\infty}\frac{e^{-\epsilon s'}}{\sqrt{s'}}\right) $$ where $$ \int_0^{\infty}\frac{e^{-\epsilon s'}}{\sqrt{s'}}ds' = \int_0^{\infty}\frac{e^{-\epsilon s^2}}{s}d(s^2) = \sqrt{\frac{\pi}{\epsilon}} $$ and $$ \sum_{s'=1}^{\infty}\frac{e^{-\epsilon s'}}{\sqrt{s'}} = \sum_{s'=1}^{\infty}{e^{-\epsilon s'}}\int_0^{\infty}e^{-\sqrt{s'}t}dt = \int_0^{\infty}\left(\sum_{s'=1}^{\infty}{e^{-\epsilon s'-\sqrt{s'}t}}\right)dt $$ Second, the identity  $$ \sum_{s=1}^{\infty}\frac{(1-\epsilon)^s}{\sqrt{s}}=\sqrt{\frac{\pi}{\epsilon}}(1+O(\epsilon)); $$ may be of some help. Thirdly, the limit is somehow $-\zeta(1/2)=1.46035\cdots$ where $\zeta(s)$ is the Riemann zeta function.","Show that     $$ L=\lim_{s\rightarrow\infty}\left(\int_0^s\frac{ds'}{\sqrt{s'}}-\sum_{s'=1}^s\frac{1}{\sqrt{s'}}\right) = 1.460\ldots $$ My attempts: To begin, rewriting the limit of the form $$ L=\lim_{\epsilon\rightarrow0}\left(\int_0^{\infty}\frac{e^{-\epsilon s'}}{\sqrt{s'}}ds'-\sum_{s'=1}^{\infty}\frac{e^{-\epsilon s'}}{\sqrt{s'}}\right) $$ where $$ \int_0^{\infty}\frac{e^{-\epsilon s'}}{\sqrt{s'}}ds' = \int_0^{\infty}\frac{e^{-\epsilon s^2}}{s}d(s^2) = \sqrt{\frac{\pi}{\epsilon}} $$ and $$ \sum_{s'=1}^{\infty}\frac{e^{-\epsilon s'}}{\sqrt{s'}} = \sum_{s'=1}^{\infty}{e^{-\epsilon s'}}\int_0^{\infty}e^{-\sqrt{s'}t}dt = \int_0^{\infty}\left(\sum_{s'=1}^{\infty}{e^{-\epsilon s'-\sqrt{s'}t}}\right)dt $$ Second, the identity  $$ \sum_{s=1}^{\infty}\frac{(1-\epsilon)^s}{\sqrt{s}}=\sqrt{\frac{\pi}{\epsilon}}(1+O(\epsilon)); $$ may be of some help. Thirdly, the limit is somehow $-\zeta(1/2)=1.46035\cdots$ where $\zeta(s)$ is the Riemann zeta function.",,"['limits', 'improper-integrals', 'special-functions', 'riemann-zeta']"
24,Limit of the sequence $(\sin n)^{n}$,Limit of the sequence,(\sin n)^{n},"How to calculate $$ \lim_{n\to\infty}(\sin n)^{n} \, ? $$ Is it sufficiently that since $|\sin x|\leq 1$ $\forall x\in\mathbb{R}$ and $|\sin n|<1$ $\forall n\in\mathbb{N}$ then $$ \lim_{n\to\infty}(\sin n)^{n}=0 \, ? $$ Is it true that if $|a_{n}|<1$ $\forall n\in\mathbb{N}$ then $$ \lim_{n\to\infty}(a_{n})^{n}=0 \, ? $$","How to calculate $$ \lim_{n\to\infty}(\sin n)^{n} \, ? $$ Is it sufficiently that since $|\sin x|\leq 1$ $\forall x\in\mathbb{R}$ and $|\sin n|<1$ $\forall n\in\mathbb{N}$ then $$ \lim_{n\to\infty}(\sin n)^{n}=0 \, ? $$ Is it true that if $|a_{n}|<1$ $\forall n\in\mathbb{N}$ then $$ \lim_{n\to\infty}(a_{n})^{n}=0 \, ? $$",,['limits']
25,"How to prove that $\lim_{(x,y) \to (0,0)} \frac{x^3y}{x^4+y^2} = 0?$ [duplicate]",How to prove that  [duplicate],"\lim_{(x,y) \to (0,0)} \frac{x^3y}{x^4+y^2} = 0?","This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 3 years ago . How to prove that $\lim_{(x,y) \to (0,0)} \dfrac{x^3y}{x^4+y^2} = 0?$ First I tried to contradict by using $y = mx$ , but I found that the limit exists. Secondly I tried to use polar coordinates, $x =  \cos\theta $ and $y = \sin\theta$, And failed .. How would you prove this limit equals $0$?","This question already has answers here : Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$ (4 answers) Closed 3 years ago . How to prove that $\lim_{(x,y) \to (0,0)} \dfrac{x^3y}{x^4+y^2} = 0?$ First I tried to contradict by using $y = mx$ , but I found that the limit exists. Secondly I tried to use polar coordinates, $x =  \cos\theta $ and $y = \sin\theta$, And failed .. How would you prove this limit equals $0$?",,"['limits', 'multivariable-calculus']"
26,"Showing $\lim_{(x,y) \to (0,0)} xy \log(x^2+y^2) = 0$",Showing,"\lim_{(x,y) \to (0,0)} xy \log(x^2+y^2) = 0","First I let $x=r\cos \theta, y = r\sin \theta$ and so limit $$\lim_{r\to 0} r^2\sin2\theta \log(r)$$ Now, in region $0<x<1$, $\log(x) < 1/x$  $$|r^2\sin 2\theta \log (r) - 0| < |r\sin 2\theta| \le |r| < \delta < \epsilon$$ So limit exist if $\delta < \epsilon$ and limit is 0. Other way, I used L hospital, I don't know if we can apply, but I wrote $r^2 \log r$ as $\log(r) / (r^{-2})$ which again gave 0.","First I let $x=r\cos \theta, y = r\sin \theta$ and so limit $$\lim_{r\to 0} r^2\sin2\theta \log(r)$$ Now, in region $0<x<1$, $\log(x) < 1/x$  $$|r^2\sin 2\theta \log (r) - 0| < |r\sin 2\theta| \le |r| < \delta < \epsilon$$ So limit exist if $\delta < \epsilon$ and limit is 0. Other way, I used L hospital, I don't know if we can apply, but I wrote $r^2 \log r$ as $\log(r) / (r^{-2})$ which again gave 0.",,"['limits', 'multivariable-calculus']"
27,Limit $\lim_{x\rightarrow +\infty}\sqrt{x}e^{-x}\left(\sum_{k=1}^{\infty}\frac{x^{k}}{k!\sqrt{k}}\right)$,Limit,\lim_{x\rightarrow +\infty}\sqrt{x}e^{-x}\left(\sum_{k=1}^{\infty}\frac{x^{k}}{k!\sqrt{k}}\right),$$\lim_{x\rightarrow +\infty}\sqrt{x}e^{-x}\left(\sum_{k=1}^{\infty}\frac{x^{k}}{k!\sqrt{k}}\right)$$ Any hint will be appreciated. Note: There is a related question on MathOverflow: Asymptotic expansion of $\sum\limits_{n=1}^{\infty} \frac{x^{2n+1}}{n!{\sqrt{n}}}$ . The MO question references this question and it also links to some other posts containing similar expressions.,Any hint will be appreciated. Note: There is a related question on MathOverflow: Asymptotic expansion of . The MO question references this question and it also links to some other posts containing similar expressions.,\lim_{x\rightarrow +\infty}\sqrt{x}e^{-x}\left(\sum_{k=1}^{\infty}\frac{x^{k}}{k!\sqrt{k}}\right) \sum\limits_{n=1}^{\infty} \frac{x^{2n+1}}{n!{\sqrt{n}}},['limits']
28,Proving $(2n-1)^n + (2n)^n ≈ (2n+1)^n$,Proving,(2n-1)^n + (2n)^n ≈ (2n+1)^n,"As I do, I was messing around and I thought to myself this simple thing: $3^2 + 4^2 = 5^2$ I just thought that this is only Pythagorean triplet with sequential integers. I know that there are no others and there are no others to higher powers due to Fermat's Last Theorem. However there are many that can be approximated. $5^3 + 6^3 = 341 ≈ 7^3$ $7^4 + 8^4 = 6479 ≈ 9^4$ $9^5 + 10^5 = 159049 ≈ 11^5$ As you can see, there is a pattern occurring in the form of: $(2n-1)^n + (2n)^n ≈ (2n + 1)^n \{n ∈ ℤ+; n > 0\}$ It also seems the that if you rearrange the equation and take the limit at +∞: $\lim_{n\to +\infty} { [(2n-1)^n + (2n)^n]^{1/n} - (2n + 1) } = 2ln(1 + e^{1/2}) - 2 ≈ -0.051846 $ (Calculated using Wolfram|Alpha) Has this been noticed before; if so, is there a proof or is this the proof?","As I do, I was messing around and I thought to myself this simple thing: $3^2 + 4^2 = 5^2$ I just thought that this is only Pythagorean triplet with sequential integers. I know that there are no others and there are no others to higher powers due to Fermat's Last Theorem. However there are many that can be approximated. $5^3 + 6^3 = 341 ≈ 7^3$ $7^4 + 8^4 = 6479 ≈ 9^4$ $9^5 + 10^5 = 159049 ≈ 11^5$ As you can see, there is a pattern occurring in the form of: $(2n-1)^n + (2n)^n ≈ (2n + 1)^n \{n ∈ ℤ+; n > 0\}$ It also seems the that if you rearrange the equation and take the limit at +∞: $\lim_{n\to +\infty} { [(2n-1)^n + (2n)^n]^{1/n} - (2n + 1) } = 2ln(1 + e^{1/2}) - 2 ≈ -0.051846 $ (Calculated using Wolfram|Alpha) Has this been noticed before; if so, is there a proof or is this the proof?",,"['limits', 'proof-verification']"
29,Is there an exact term for $\sqrt{2+\sqrt{4+\sqrt{8+\dots}}}$,Is there an exact term for,\sqrt{2+\sqrt{4+\sqrt{8+\dots}}},"I'm wondering whether it's possible to find an exact term for the infinite nested radical expression from the title. I got a quite good approximation with my calculator but what I'm looking for is an exact term. $$ f(x)=\sqrt{2^x+\sqrt{2^{x+1}+\sqrt{2^{x+2}...}}} $$ It is necessary that f satisfies the condition: $$ f(x)^2=2^x+f(x+1) $$ EDIT: But there should be infinetely many solutions to this equations - furthermore, I wasn't able to find a single one! Does anyone have an idea how to find an exact finite term - or prove that no such term exists?","I'm wondering whether it's possible to find an exact term for the infinite nested radical expression from the title. I got a quite good approximation with my calculator but what I'm looking for is an exact term. $$ f(x)=\sqrt{2^x+\sqrt{2^{x+1}+\sqrt{2^{x+2}...}}} $$ It is necessary that f satisfies the condition: $$ f(x)^2=2^x+f(x+1) $$ EDIT: But there should be infinetely many solutions to this equations - furthermore, I wasn't able to find a single one! Does anyone have an idea how to find an exact finite term - or prove that no such term exists?",,"['limits', 'nested-radicals']"
30,When does the $f^{(n)}$ converge to a limit function as $n\to\infty$?,When does the  converge to a limit function as ?,f^{(n)} n\to\infty,"(This was something someone (almost) asked in a comment in a thread about repeated differentiation of polynomials.) Consider a general smooth (that is $C^\infty$) function $f$. As usual $f^{(n)}$ denotes the $n$th derivative of $f$. Under what circumstance does $\{ f^{(n)} \}_{n=1}^\infty$ converge to a limit function as $n$ goes to infinity? For example when $0<k<1$ is fixed and $f(x)=e^{kx}$, then we have the pointwise convergence $f^{(n)} \to 0$ for $n\to\infty$ where $0$ is the zero function. The case $k=1$ is different. Of course when $f(x)=\cos x$, there is no convergence of the $f^{(n)}$. But $\cos(kx)$ ... Can a criterion be given?","(This was something someone (almost) asked in a comment in a thread about repeated differentiation of polynomials.) Consider a general smooth (that is $C^\infty$) function $f$. As usual $f^{(n)}$ denotes the $n$th derivative of $f$. Under what circumstance does $\{ f^{(n)} \}_{n=1}^\infty$ converge to a limit function as $n$ goes to infinity? For example when $0<k<1$ is fixed and $f(x)=e^{kx}$, then we have the pointwise convergence $f^{(n)} \to 0$ for $n\to\infty$ where $0$ is the zero function. The case $k=1$ is different. Of course when $f(x)=\cos x$, there is no convergence of the $f^{(n)}$. But $\cos(kx)$ ... Can a criterion be given?",,"['limits', 'functions', 'derivatives', 'convergence-divergence']"
31,Interchanging pointwise limit and derivative of a sequence of C1 functions,Interchanging pointwise limit and derivative of a sequence of C1 functions,,"Assume the following: $f_n$ is a sequence of $C^1$ functions on $[0,1]$ $f_n(x) \rightarrow 0$ pointwise. $f'_n(x) \rightarrow g(x)$ pointwise. Is it true that $g(x) = 0$ almost everywhere? I think the answer is no, but I'm having trouble with finding a counter-example.","Assume the following: $f_n$ is a sequence of $C^1$ functions on $[0,1]$ $f_n(x) \rightarrow 0$ pointwise. $f'_n(x) \rightarrow g(x)$ pointwise. Is it true that $g(x) = 0$ almost everywhere? I think the answer is no, but I'm having trouble with finding a counter-example.",,"['limits', 'derivatives', 'convergence-divergence']"
32,"Without superior math, can we evaluate this limit?","Without superior math, can we evaluate this limit?",,"We all knew, with $$\lim_{x\to 0}\frac{\sin x - x}{x(1-\cos x)}$$ we can use L'Hôpital's rule or Taylor series to eliminate undefined form. But without all tools, by only using high school knowledge, how can we evaluate this limit? It seems difficult to transform numerator, any idea? Thank you!","We all knew, with we can use L'Hôpital's rule or Taylor series to eliminate undefined form. But without all tools, by only using high school knowledge, how can we evaluate this limit? It seems difficult to transform numerator, any idea? Thank you!",\lim_{x\to 0}\frac{\sin x - x}{x(1-\cos x)},"['limits', 'limits-without-lhopital']"
33,Find the value of : $\lim_{n\to\infty}(2a)^{\frac{n}{2}}\sqrt{a-\sqrt{a(a-1)+\sqrt{a(a-1)+\cdots}}}$,Find the value of :,\lim_{n\to\infty}(2a)^{\frac{n}{2}}\sqrt{a-\sqrt{a(a-1)+\sqrt{a(a-1)+\cdots}}},find the limit $$\lim_{n\to\infty}(2a)^{\frac{n}{2}}\underbrace{\sqrt{a-\sqrt{a(a-1)+\sqrt{a(a-1)+\cdots}}}}_{n \textrm{ square roots}}$$ My try:    I know this Find $\lim_{n\to\infty}2^n\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}_{n \textrm{ square roots}}$. and this problem just $$\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}_{n \textrm{ square roots}}=4\left|\sin{\frac{\theta}{2^n}}\right|$$   so   follow this limit is easy to find it. But $$\underbrace{\sqrt{a-\sqrt{a(a-1)+\sqrt{a(a-1)+\cdots}}}}_{n \textrm{ square roots}}=?$$,find the limit $$\lim_{n\to\infty}(2a)^{\frac{n}{2}}\underbrace{\sqrt{a-\sqrt{a(a-1)+\sqrt{a(a-1)+\cdots}}}}_{n \textrm{ square roots}}$$ My try:    I know this Find $\lim_{n\to\infty}2^n\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}_{n \textrm{ square roots}}$. and this problem just $$\underbrace{\sqrt{2-\sqrt{2+\sqrt{2+\dots+\sqrt2}}}}_{n \textrm{ square roots}}=4\left|\sin{\frac{\theta}{2^n}}\right|$$   so   follow this limit is easy to find it. But $$\underbrace{\sqrt{a-\sqrt{a(a-1)+\sqrt{a(a-1)+\cdots}}}}_{n \textrm{ square roots}}=?$$,,['limits']
34,The case for L'Hôpital's rule?,The case for L'Hôpital's rule?,,"While this may seem very subjective — and, admittedly, my own dislike of L'Hôpital's rule is not entirely devoid of subjectivity — I am looking here for argumented, factual answers. From what I understand, students in the United States, when learning calculus and limits, are provided with and encouraged to use L'Hôpital's rule very early on. As a result, based on e.g. the activity on Math.SE, the use of L'Hôpital's rule ends up being pervasive and somewhat of a reflex for many students. Assuming for once that the application of L'Hôpital is well-justified, and that the assumptions are checked, etc., this is a valid technique. However, based on my limited experience in research, this is a technique I have never seen used in ""real"" life."" I frequently see people rely on asymptotic equivalents, Taylor approximations, integral comparisons, etc; all of them tools that, AFAIK, are barely taught to high-school or undergrad students. My question, thus, is: why ? What is the rationale in promoting the (almost exclusive) usage of L'Hôpital's rule in secondary education (again, in the USA)? Are my observation wrong, and are other techniques actually emphasized as well? (based on the sample data I have, I sort of doubt it) Is there a clear advantage to teaching L'Hôpital's rule and training students to use it by default, advantage that I am missing? (e.g., either educational, or in terms of further studies/applications)","While this may seem very subjective — and, admittedly, my own dislike of L'Hôpital's rule is not entirely devoid of subjectivity — I am looking here for argumented, factual answers. From what I understand, students in the United States, when learning calculus and limits, are provided with and encouraged to use L'Hôpital's rule very early on. As a result, based on e.g. the activity on Math.SE, the use of L'Hôpital's rule ends up being pervasive and somewhat of a reflex for many students. Assuming for once that the application of L'Hôpital is well-justified, and that the assumptions are checked, etc., this is a valid technique. However, based on my limited experience in research, this is a technique I have never seen used in ""real"" life."" I frequently see people rely on asymptotic equivalents, Taylor approximations, integral comparisons, etc; all of them tools that, AFAIK, are barely taught to high-school or undergrad students. My question, thus, is: why ? What is the rationale in promoting the (almost exclusive) usage of L'Hôpital's rule in secondary education (again, in the USA)? Are my observation wrong, and are other techniques actually emphasized as well? (based on the sample data I have, I sort of doubt it) Is there a clear advantage to teaching L'Hôpital's rule and training students to use it by default, advantage that I am missing? (e.g., either educational, or in terms of further studies/applications)",,"['limits', 'soft-question', 'education']"
35,Calculation of $\lim_{n\rightarrow\infty}\frac{3^{3n}\cdot (n!)^3}{(3n+1)!}=$,Calculation of,\lim_{n\rightarrow\infty}\frac{3^{3n}\cdot (n!)^3}{(3n+1)!}=,"Calculation of $$\lim_{n\rightarrow\infty}\frac{3^{3n}\cdot (n!)^3}{(3n+1)!}=$$ $\bf{My\; Try::}$ Using Stirling Approximation $\displaystyle (n!\approx\left(\frac{n}{e}\right)^n\sqrt{2\pi n})$,We get Limit $$l=\lim_{n\rightarrow\infty}\frac{3^{3n}\cdot \left(\frac{n}{e}\right)^{3n}\left(\sqrt{2\pi n}\right)^3}{\left(\frac{3n+1}{e}\right)^{3n+1}\sqrt{2\pi (3n+1)}} = \frac{2\pi}{3\sqrt{3}}$$ My question is how can we solve it Using Reinman sum (Limit as a sum) or any other method Help me ,Thanks","Calculation of $$\lim_{n\rightarrow\infty}\frac{3^{3n}\cdot (n!)^3}{(3n+1)!}=$$ $\bf{My\; Try::}$ Using Stirling Approximation $\displaystyle (n!\approx\left(\frac{n}{e}\right)^n\sqrt{2\pi n})$,We get Limit $$l=\lim_{n\rightarrow\infty}\frac{3^{3n}\cdot \left(\frac{n}{e}\right)^{3n}\left(\sqrt{2\pi n}\right)^3}{\left(\frac{3n+1}{e}\right)^{3n+1}\sqrt{2\pi (3n+1)}} = \frac{2\pi}{3\sqrt{3}}$$ My question is how can we solve it Using Reinman sum (Limit as a sum) or any other method Help me ,Thanks",,['limits']
36,Proof of $\lim\sup(a_nb_n)\leq \lim\sup(a_n)\limsup(b_n)$,Proof of,\lim\sup(a_nb_n)\leq \lim\sup(a_n)\limsup(b_n),"Let $a_n>0$ and $b_n\geq 0$, then $\lim\sup(a_nb_n)\leq \lim\sup(a_n)\limsup(b_n)$ My attempt at a proof is as follows.  Let $A_n=\sup\{a_n, a_{n+1},...\}$, $B_n=\sup\{b_n, b_{n+1},...\}$, and $C_n=\sup\{a_nb_n, a_{n+1}b_{n+1},...\}$. Note: $a_mb_m \leq A_nB_n$ for all $m \geq n$. Thus $\limsup(a_nb_n)=\lim C_n \leq \lim (A_nB_n) = (\lim A_n)(\lim B_n) = (\limsup a_n)(\limsup b_n).$","Let $a_n>0$ and $b_n\geq 0$, then $\lim\sup(a_nb_n)\leq \lim\sup(a_n)\limsup(b_n)$ My attempt at a proof is as follows.  Let $A_n=\sup\{a_n, a_{n+1},...\}$, $B_n=\sup\{b_n, b_{n+1},...\}$, and $C_n=\sup\{a_nb_n, a_{n+1}b_{n+1},...\}$. Note: $a_mb_m \leq A_nB_n$ for all $m \geq n$. Thus $\limsup(a_nb_n)=\lim C_n \leq \lim (A_nB_n) = (\lim A_n)(\lim B_n) = (\limsup a_n)(\limsup b_n).$",,"['analysis', 'limits', 'inequality', 'limsup-and-liminf']"
37,Trying to show that $\ln(x) = \lim_{n\to\infty} n(x^{1/n} -1)$,Trying to show that,\ln(x) = \lim_{n\to\infty} n(x^{1/n} -1),How do I show that $\ln(x) = \lim_{n\to\infty} n (x^{1/n} - 1)$? I ran into this identity on this stackoverflow question . I haven't been able to find any proof online and my efforts to get from $\ln(x) := \int_1^x \frac{\mathrm dt}t$ to that limit have been a failure.,How do I show that $\ln(x) = \lim_{n\to\infty} n (x^{1/n} - 1)$? I ran into this identity on this stackoverflow question . I haven't been able to find any proof online and my efforts to get from $\ln(x) := \int_1^x \frac{\mathrm dt}t$ to that limit have been a failure.,,"['limits', 'proof-verification', 'logarithms', 'radicals']"
38,Disprove the limit $\lim_{x\to 0}\frac{1}{x}=5$ with epsilon-delta,Disprove the limit  with epsilon-delta,\lim_{x\to 0}\frac{1}{x}=5,"I understand how to prove a limit such as $\lim_{x\to 3}x^2=9$. Now I was wondering, can one also use the epsilon-delta method to dis prove a limit such as: $$\lim_{x\to 0}\frac{1}{x}=5$$ If so, how? Thanks! edit: what would a formal proof look like?","I understand how to prove a limit such as $\lim_{x\to 3}x^2=9$. Now I was wondering, can one also use the epsilon-delta method to dis prove a limit such as: $$\lim_{x\to 0}\frac{1}{x}=5$$ If so, how? Thanks! edit: what would a formal proof look like?",,"['limits', 'epsilon-delta']"
39,Evaluate $ \lim_{x \to 0} \frac{x^2}{x+\sin (\frac 1 x)} $,Evaluate, \lim_{x \to 0} \frac{x^2}{x+\sin (\frac 1 x)} ,How can I find the following limit without the use of any series or expansion? $$ \lim_{x \to 0} \frac{x^2}{x+\sin (\frac 1 x)} $$ Thanks for help.,How can I find the following limit without the use of any series or expansion? $$ \lim_{x \to 0} \frac{x^2}{x+\sin (\frac 1 x)} $$ Thanks for help.,,['limits']
40,limit when zero divided by infinity,limit when zero divided by infinity,,"I have a case where $$\lim_{x\rightarrow\infty}=\frac{f\left(x\right)}{h\left(x\right)}$$ I know that $\lim_{x\rightarrow\infty} f(x)=0$ and $\lim_{x\rightarrow\infty} h(x)=\infty$ So at the and I have $\frac{0}{\infty}$. I know that infinity is not a real number but I am not sure if the limit is indeterminate. (Also, there are people who are saying contradictory things on internet) I know very well that it is not possible to use Hopital's rule. My guess is that : As we know that $\lim_{x\rightarrow\infty}\frac{1}{\infty}=0$, We can just write  $\lim_{x\rightarrow\infty} \frac{1}{\infty}=0$ $$\lim_{x\rightarrow\infty} \frac{1-0}{\infty}=0$$ $$\lim_{x\rightarrow\infty} \frac{1}{\infty}-\frac{0}{\infty}=0$$ So, in this case $\frac{0}{\infty}=0$. What could be the answer and its explanation ?","I have a case where $$\lim_{x\rightarrow\infty}=\frac{f\left(x\right)}{h\left(x\right)}$$ I know that $\lim_{x\rightarrow\infty} f(x)=0$ and $\lim_{x\rightarrow\infty} h(x)=\infty$ So at the and I have $\frac{0}{\infty}$. I know that infinity is not a real number but I am not sure if the limit is indeterminate. (Also, there are people who are saying contradictory things on internet) I know very well that it is not possible to use Hopital's rule. My guess is that : As we know that $\lim_{x\rightarrow\infty}\frac{1}{\infty}=0$, We can just write  $\lim_{x\rightarrow\infty} \frac{1}{\infty}=0$ $$\lim_{x\rightarrow\infty} \frac{1-0}{\infty}=0$$ $$\lim_{x\rightarrow\infty} \frac{1}{\infty}-\frac{0}{\infty}=0$$ So, in this case $\frac{0}{\infty}=0$. What could be the answer and its explanation ?",,['limits']
41,How can a Cauchy sequence converge to an irrational number?,How can a Cauchy sequence converge to an irrational number?,,"I am a physics major and would like to clear a confusion regarding complete metric spaces. I am quoting the definition of a Cauchy sequence from wikipedia below Formally, given a metric space $(X, d)$, a sequence $x_1, x_2, x_3, \ldots$   is Cauchy, if for every positive real number $\epsilon > 0$ there is a positive integer $N$ such that for all positive integers $m, n > N$, the distance $$d(x_m, x_n) < \epsilon$$ Now, if we have sequence like $x_1=3, x_2=3.1, x_3=3.14, \ldots$ converging to $\pi$, I do not understand how all distances $d(x_m, x_n)$ will be less than all positive real numbers. Since irrational numbers do not terminate and continue forever, how can the distance ever be less than the smallest real number or infinitesimal (hyperreal) as the distance can never become $0$. Does this definition of completeness apply where $\epsilon$ is infinitesimal (hypperreal) ? Kindly excuse my ignorance as I am not a mathematics major. Thanks","I am a physics major and would like to clear a confusion regarding complete metric spaces. I am quoting the definition of a Cauchy sequence from wikipedia below Formally, given a metric space $(X, d)$, a sequence $x_1, x_2, x_3, \ldots$   is Cauchy, if for every positive real number $\epsilon > 0$ there is a positive integer $N$ such that for all positive integers $m, n > N$, the distance $$d(x_m, x_n) < \epsilon$$ Now, if we have sequence like $x_1=3, x_2=3.1, x_3=3.14, \ldots$ converging to $\pi$, I do not understand how all distances $d(x_m, x_n)$ will be less than all positive real numbers. Since irrational numbers do not terminate and continue forever, how can the distance ever be less than the smallest real number or infinitesimal (hyperreal) as the distance can never become $0$. Does this definition of completeness apply where $\epsilon$ is infinitesimal (hypperreal) ? Kindly excuse my ignorance as I am not a mathematics major. Thanks",,"['limits', 'infinity', 'irrational-numbers', 'cauchy-sequences', 'complete-spaces']"
42,"If $a_n+b_n\sqrt{3}=(2+\sqrt{3})^n$, then what's $\lim_{n\rightarrow\infty}\frac{a_n}{b_n}$?","If , then what's ?",a_n+b_n\sqrt{3}=(2+\sqrt{3})^n \lim_{n\rightarrow\infty}\frac{a_n}{b_n},"Let $a_n$ and $b_n$ be integers defined in the following way: $$a_n+b_n\sqrt{3}=(2+\sqrt{3})^n.$$ Compute $$\lim_{n\rightarrow\infty}\frac{a_n}{b_n}.$$ I tried expanding using binomial theorem: $$ (2+\sqrt{3})^n=\binom{n}{0}2+\binom{n}{1}2^2\sqrt{3}+\binom{n}{2}2^3\cdot 3+\ldots+\binom{n}{n-1}2\sqrt{3}^{n-1}+\binom{n}{n}\sqrt{3}^{n}$$ and I think we have that: $$ a_n=\binom{n}{0}2+\binom{n}{2}2^3\cdot 3+\ldots+\binom{n}{n}\sqrt{3}^{n}$$ $$ b_n=\binom{n}{1}2^2\sqrt{3}+\ldots+\binom{n}{n-1}2\sqrt{3}^{n-1}$$ But, frankly, I do not know what to do next.","Let $a_n$ and $b_n$ be integers defined in the following way: $$a_n+b_n\sqrt{3}=(2+\sqrt{3})^n.$$ Compute $$\lim_{n\rightarrow\infty}\frac{a_n}{b_n}.$$ I tried expanding using binomial theorem: $$ (2+\sqrt{3})^n=\binom{n}{0}2+\binom{n}{1}2^2\sqrt{3}+\binom{n}{2}2^3\cdot 3+\ldots+\binom{n}{n-1}2\sqrt{3}^{n-1}+\binom{n}{n}\sqrt{3}^{n}$$ and I think we have that: $$ a_n=\binom{n}{0}2+\binom{n}{2}2^3\cdot 3+\ldots+\binom{n}{n}\sqrt{3}^{n}$$ $$ b_n=\binom{n}{1}2^2\sqrt{3}+\ldots+\binom{n}{n-1}2\sqrt{3}^{n-1}$$ But, frankly, I do not know what to do next.",,"['limits', 'binomial-theorem']"
43,Limit of n-th root of $1/n$,Limit of n-th root of,1/n,"I'm struggling to calculate the limit $$\lim_{n\rightarrow\infty}\left(\frac{1}{n}\right)^{\frac{1}{n}}$$ I have tried taking log, $\log(\frac{1}{n})^{\frac{1}{n}}=\frac{1}{n}\log({\frac{1}{n}})$ and setting $t=\frac{1}{n}$ and rewite the desired limit as $e^{\lim_{t\rightarrow 0}t\log(t)}$, and I'm stuck here because $\log$ is not defined at $0$. Did I miss something? Thank you for reading.","I'm struggling to calculate the limit $$\lim_{n\rightarrow\infty}\left(\frac{1}{n}\right)^{\frac{1}{n}}$$ I have tried taking log, $\log(\frac{1}{n})^{\frac{1}{n}}=\frac{1}{n}\log({\frac{1}{n}})$ and setting $t=\frac{1}{n}$ and rewite the desired limit as $e^{\lim_{t\rightarrow 0}t\log(t)}$, and I'm stuck here because $\log$ is not defined at $0$. Did I miss something? Thank you for reading.",,['limits']
44,"Limit of $(1+1/n)^n$ is not equal to one, but why ?","Limit of  is not equal to one, but why ?",(1+1/n)^n,"The fact that :  $$\lim_{n\to\infty} (1+1/n)^n \ne 1$$ is  conterintuitive to me. Why this doesn't work : $\lim_{n\to\infty} 1/n = 0$, then by composition : $\lim_{n\to\infty} (1+1/n)^n = 1$ ? Is there a calculus way and intuitive way to understand why this is false ?","The fact that :  $$\lim_{n\to\infty} (1+1/n)^n \ne 1$$ is  conterintuitive to me. Why this doesn't work : $\lim_{n\to\infty} 1/n = 0$, then by composition : $\lim_{n\to\infty} (1+1/n)^n = 1$ ? Is there a calculus way and intuitive way to understand why this is false ?",,['limits']
45,Difference of asymptotes at infinity,Difference of asymptotes at infinity,,"Let $f(x)$ and $g(x)$ be two functions such that $$\lim_{x\to\infty}\frac{f(x)}{g(x)}=1$$ Does it imply: $\lim_{x\to\infty}\frac{g(x)}{f(x)}=1$ $\lim_{x\to\infty}\left(f(x)-g(x)\right)=0$ To me it seems like both are true, but the second is obviously false: $$\lim_{x\to\infty}\left(\sqrt{x+\sqrt{x}}-\sqrt{x}\right)=1/2$$ but why? If both functions are basically the same far enough in the number line why does the limit not approach $0$. I don't know how to give a rigorous answer (rather than examples) Are the answers different in these two cases? $\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)=\infty$ $f(x)$ and $g(x)$ are bounded Thanks","Let $f(x)$ and $g(x)$ be two functions such that $$\lim_{x\to\infty}\frac{f(x)}{g(x)}=1$$ Does it imply: $\lim_{x\to\infty}\frac{g(x)}{f(x)}=1$ $\lim_{x\to\infty}\left(f(x)-g(x)\right)=0$ To me it seems like both are true, but the second is obviously false: $$\lim_{x\to\infty}\left(\sqrt{x+\sqrt{x}}-\sqrt{x}\right)=1/2$$ but why? If both functions are basically the same far enough in the number line why does the limit not approach $0$. I don't know how to give a rigorous answer (rather than examples) Are the answers different in these two cases? $\lim_{x\to\infty}f(x)=\lim_{x\to\infty}g(x)=\infty$ $f(x)$ and $g(x)$ are bounded Thanks",,"['limits', 'functions', 'asymptotics']"
46,Does $a_{n}/a_{n-1}$ converge to the golden ratio for all Fibonacci-like sequences?,Does  converge to the golden ratio for all Fibonacci-like sequences?,a_{n}/a_{n-1},"Yesterday a friend challenged me to prove that $$\lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}=\varphi\; ,$$ where $\varphi$ is the golden ratio, for the Fibonacci series. I started rewriting the limit as $$\lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}=\lim_{n\rightarrow\infty}\frac{a_{n-1}+a_{n-2}}{a_{n-1}}=\lim_{n\rightarrow\infty}1+\frac{a_{n-2}}{a_{n-1}}\; .$$ If the sequence $b_n=\frac{a_n}{a_{n-1}}$ is convergent , $$\lim_{n\rightarrow\infty}\frac{a_{n-2}}{a_{n-1}}=\left(\lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}\right)^{-1}\; .$$ Renaming the desired limit $x$ , we obtain the quadratic equation $$x=1+\frac{1}{x}$$ $$x^2-x-1=0$$ if $x\neq 0$ . Therefore, if $b_n$ is convergent, it must be equal to $\frac{1+\sqrt{5}}{2}$ or $\frac{1-\sqrt{5}}{2}$ . Since $a_n>0$ , $b_n>0, \forall n$ , so the limit must be equal to $\varphi=\frac{1+\sqrt{5}}{2}$ . This proof made me think that I didn't make use of the initial values of the sequence, so it must hold true for any sequence where $a_{n}=a_{n-1}+a_{n-2}$ . The first question is, is $a_{n}/a_{n-1}$ convergent for all Fibonacci-like sequences? The second and most intriguing for me is, is there any Fibonacci-like sequence where the limit is $\frac{1-\sqrt{5}}{2}$ ? Since this solution is negative, $a_n$ should change its sing with each $n$ , but I couldn't find any values for $a_0$ and $a_1$ , which would lead me to this case. If the answer to this question is no, what mathematical sense does this negative solution have?","Yesterday a friend challenged me to prove that where is the golden ratio, for the Fibonacci series. I started rewriting the limit as If the sequence is convergent , Renaming the desired limit , we obtain the quadratic equation if . Therefore, if is convergent, it must be equal to or . Since , , so the limit must be equal to . This proof made me think that I didn't make use of the initial values of the sequence, so it must hold true for any sequence where . The first question is, is convergent for all Fibonacci-like sequences? The second and most intriguing for me is, is there any Fibonacci-like sequence where the limit is ? Since this solution is negative, should change its sing with each , but I couldn't find any values for and , which would lead me to this case. If the answer to this question is no, what mathematical sense does this negative solution have?","\lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}=\varphi\; , \varphi \lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}=\lim_{n\rightarrow\infty}\frac{a_{n-1}+a_{n-2}}{a_{n-1}}=\lim_{n\rightarrow\infty}1+\frac{a_{n-2}}{a_{n-1}}\; . b_n=\frac{a_n}{a_{n-1}} \lim_{n\rightarrow\infty}\frac{a_{n-2}}{a_{n-1}}=\left(\lim_{n\rightarrow\infty}\frac{a_n}{a_{n-1}}\right)^{-1}\; . x x=1+\frac{1}{x} x^2-x-1=0 x\neq 0 b_n \frac{1+\sqrt{5}}{2} \frac{1-\sqrt{5}}{2} a_n>0 b_n>0, \forall n \varphi=\frac{1+\sqrt{5}}{2} a_{n}=a_{n-1}+a_{n-2} a_{n}/a_{n-1} \frac{1-\sqrt{5}}{2} a_n n a_0 a_1","['limits', 'proof-explanation', 'fibonacci-numbers', 'golden-ratio']"
47,whats the proof for $\lim_{x → 0} [(a_1^x + a_2^x + .....+ a_n^x)/n]^{1/x} = (a_1.a_2....a_n)^{1/n}$,whats the proof for,\lim_{x → 0} [(a_1^x + a_2^x + .....+ a_n^x)/n]^{1/x} = (a_1.a_2....a_n)^{1/n},"This equation is directly given in my book and I am don't know anything about its proof.I tried L'Hospital rule by differentiating the both numerator as well as denominator(division rule), but the result is still coming in indeterminate forms.I am a beginner , and haven't practiced limits that much. This formula is really confusing me.","This equation is directly given in my book and I am don't know anything about its proof.I tried L'Hospital rule by differentiating the both numerator as well as denominator(division rule), but the result is still coming in indeterminate forms.I am a beginner , and haven't practiced limits that much. This formula is really confusing me.",,['limits']
48,Limit of the derivative of a function [duplicate],Limit of the derivative of a function [duplicate],,This question already has answers here : Proving that $\lim\limits_{x\to\infty}f'(x) = 0$ when $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ exist (6 answers) Closed 8 years ago . $f(x)$ is a differentiable function on the real line such that $ \lim_{x\to \infty } f(x) =1 $  and $ \lim_{x\to \infty } f'(x) = s $ .Then $s$ should be $0$ $s$ need not be $0$ but $|s| < 1$ $s > 1$ $s < -1$ Because $f(x)$ is bounded need not mean it can neither be increasing nor decreasing.So the derivative needs not be $0$.,This question already has answers here : Proving that $\lim\limits_{x\to\infty}f'(x) = 0$ when $\lim\limits_{x\to\infty}f(x)$ and $\lim\limits_{x\to\infty}f'(x)$ exist (6 answers) Closed 8 years ago . $f(x)$ is a differentiable function on the real line such that $ \lim_{x\to \infty } f(x) =1 $  and $ \lim_{x\to \infty } f'(x) = s $ .Then $s$ should be $0$ $s$ need not be $0$ but $|s| < 1$ $s > 1$ $s < -1$ Because $f(x)$ is bounded need not mean it can neither be increasing nor decreasing.So the derivative needs not be $0$.,,"['limits', 'derivatives']"
49,"Multivariable limit proof: $\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$",Multivariable limit proof:,"\lim\limits_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0","I have some trouble with this: Show that if $a, b \ge 0$, $c, d > 0$ and $\frac{a}{c} + \frac{b}{d} > 1$ then $$\lim_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$$ we were not really shown how to evaluate multivariable limits other than trying different paths, which wouldn't work when the limit exists, or by applying the squeeze theorem which is my initial plan. Unfortunately I cannot find a proper bound for the denominator and so I am quite lost right now. Any help would be appreciated.","I have some trouble with this: Show that if $a, b \ge 0$, $c, d > 0$ and $\frac{a}{c} + \frac{b}{d} > 1$ then $$\lim_{(x,y)\rightarrow (0,0)}\frac{\left|x\right|^a\left|y\right|^b}{\left|x\right|^c + \left|y\right|^d} = 0$$ we were not really shown how to evaluate multivariable limits other than trying different paths, which wouldn't work when the limit exists, or by applying the squeeze theorem which is my initial plan. Unfortunately I cannot find a proper bound for the denominator and so I am quite lost right now. Any help would be appreciated.",,"['multivariable-calculus', 'limits']"
50,How can I evaluate this limit with or without applying derivatives?,How can I evaluate this limit with or without applying derivatives?,,"$$ \lim_{n \to \infty} \frac{1^{1/3} + 2^{1/3} + \cdots + n^{1/3}}{n \cdot n^{1/3}} $$ High school student here! This was a question from our Mathematics exam (prior to learning derivatives). Now there was some sort of a bounty here in our school, but nobody could solve it even after weeks passed. WolframAlpha gives $3/4$ but no other explanation. I'm curious how one could tackle the expression in the numerator.","$$ \lim_{n \to \infty} \frac{1^{1/3} + 2^{1/3} + \cdots + n^{1/3}}{n \cdot n^{1/3}} $$ High school student here! This was a question from our Mathematics exam (prior to learning derivatives). Now there was some sort of a bounty here in our school, but nobody could solve it even after weeks passed. WolframAlpha gives $3/4$ but no other explanation. I'm curious how one could tackle the expression in the numerator.",,['limits']
51,Why doesn't L'hopitals Rule work for $\lim\limits_{x \to \infty} \frac{x+ \sin x}{x+ 2 \sin x}$? [duplicate],Why doesn't L'hopitals Rule work for ? [duplicate],\lim\limits_{x \to \infty} \frac{x+ \sin x}{x+ 2 \sin x},"This question already has answers here : Why doesn't L'Hôpital's rule work in this case? (4 answers) Closed 5 years ago . This is how I would evaluate $\lim\limits_{x \to \infty} \dfrac{x+ \sin x}{x+ 2 \sin x}$ $=\lim\limits_{x \to \infty} \dfrac{x \left( 1+ \frac{\sin x}{x} \right)}{x \left(1+ 2 \cdot \frac{ \sin x}{x} \right)}$ $= \dfrac{1+0}{1+2 \cdot 0} = 1$ But now applying L'hopitals Rule, I get $\lim\limits_{x \to \infty} \dfrac{1+ \cos x}{1+ 2 \cos x}$ Since $\cos x $ just oscillates between $[-1,1]$ I think we can  conclude the limit doesn't exist. What is going on here?","This question already has answers here : Why doesn't L'Hôpital's rule work in this case? (4 answers) Closed 5 years ago . This is how I would evaluate But now applying L'hopitals Rule, I get Since just oscillates between I think we can  conclude the limit doesn't exist. What is going on here?","\lim\limits_{x \to \infty} \dfrac{x+ \sin x}{x+ 2 \sin x} =\lim\limits_{x \to \infty} \dfrac{x \left( 1+ \frac{\sin x}{x} \right)}{x \left(1+ 2 \cdot \frac{ \sin x}{x} \right)} = \dfrac{1+0}{1+2 \cdot 0} = 1 \lim\limits_{x \to \infty} \dfrac{1+ \cos x}{1+ 2 \cos x} \cos x  [-1,1]",['limits']
52,"What does the phrase ""except possibly at $a$ itself"" mean in the definition of a limit?","What does the phrase ""except possibly at  itself"" mean in the definition of a limit?",a,"The definition of limit says that Let $f(x)$ be a function defined on some open interval that contains the number $a$, except possibly at $a$ itself. Then we say that the limit of $f(x)$ as $x$ approaches $a$ is $L$ If....{the rest of definition is left to make the question easier}. What does the phrase ""except possibly at $a$ itself"" mean? What is the significance of defining the interval, open i.e why not closed?","The definition of limit says that Let $f(x)$ be a function defined on some open interval that contains the number $a$, except possibly at $a$ itself. Then we say that the limit of $f(x)$ as $x$ approaches $a$ is $L$ If....{the rest of definition is left to make the question easier}. What does the phrase ""except possibly at $a$ itself"" mean? What is the significance of defining the interval, open i.e why not closed?",,['limits']
53,Prove that $\lim_{n\to\infty}\sin(nx)/ \pi x$ is a delta function,Prove that  is a delta function,\lim_{n\to\infty}\sin(nx)/ \pi x,"I need to prove that $\delta_n(x)=\sin (nx)/\pi x$ is a delta function. That is, to prove that: $$\underset{n\rightarrow \infty}{\lim}\int^\infty_{-\infty}f(x)\frac{\sin( nx)}{\pi x}dx=f(0).$$ For that I made $y=x/n$ and took the limit under the integral since $f(x)$ is supposed to be analytic in $\mathbb{R}$ . I have a fundamental limit for the $\sin$ leaving me with $$\int^\infty_{-\infty}f(0)\cdot1 \;dy.$$ But this is equal to $f(0)$ $\iff$ $f(x)$ have contribuition only at $x=0$ , but here the only assumption is that $f(x)=0$ when $x\rightarrow \pm \infty$ . What is wrong here?","I need to prove that is a delta function. That is, to prove that: For that I made and took the limit under the integral since is supposed to be analytic in . I have a fundamental limit for the leaving me with But this is equal to have contribuition only at , but here the only assumption is that when . What is wrong here?",\delta_n(x)=\sin (nx)/\pi x \underset{n\rightarrow \infty}{\lim}\int^\infty_{-\infty}f(x)\frac{\sin( nx)}{\pi x}dx=f(0). y=x/n f(x) \mathbb{R} \sin \int^\infty_{-\infty}f(0)\cdot1 \;dy. f(0) \iff f(x) x=0 f(x)=0 x\rightarrow \pm \infty,"['limits', 'distribution-theory', 'dirac-delta']"
54,how to solve $\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+k}}}\right)^{n}}$?,how to solve ?,\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+k}}}\right)^{n}},"$\displaystyle\left(\sum_{k=1}^{n} \frac{1}{\sqrt{n^{2}+1}}\right)^{n}\ge\left(\sum_{k=1}^{n} \frac{1}{\sqrt{n^{2}+k}}\right)^{n}\ge\left(\sum_{k=1}^{n} \frac{1}{\sqrt{n^{2}+n}}\right)^{n}$ left= $\displaystyle\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+1}}}\right)^{n}}=e^{\displaystyle n \ln{\frac{n}{\sqrt{n^2+1}}} }=e^{0}=1$ right= $\displaystyle\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+n}}}\right)^{n}}=e^{\displaystyle n \ln{\frac{n}{\sqrt{n^2+n}}} }=e^{-\frac{1}{2}}$ left $\ne$ right ,what to do next? $\displaystyle\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+k}}}\right)^{n}}=\lim _{n \rightarrow \infty} e^{\displaystyle n \ln \sum_{k=1}^{n} \frac{1}{\sqrt{n^{2}+k}}(1)}$ $(1)=\displaystyle \lim _{n \rightarrow \infty} n\left(\ln \frac{1}{n} \sum_{k=1}^{n} \frac{1}{\sqrt{1+k/n^{2}}}\right)$$=\lim _{n \rightarrow \infty} n\left(\ln \frac{1}{n} \sum_{k=1}^{n} \frac{1}{\sqrt{1+k/n \cdot 1/n}}\right)$$=\lim _{n \rightarrow \infty} n \ln \int_{0}^{1} \frac{1}{\sqrt{1+x/n}} d x$$=\lim _{n \rightarrow \infty} n \ln \int_{0}^{1} \frac{nd(x/n+1)}{\sqrt{1+x/n}}$$= \lim_{n\to\infty}{n\ln{n \cdot2 \left.\sqrt{1+\frac{x}{n} }\right|_{0}^{1}}}$$= \lim_{n\to\infty}{n\ln{n \cdot2 (\sqrt{1+\frac{1}{n}}-1)}}$$=\lim_{n\to\infty}{n\ln{n \cdot2 (\frac{1}{2n} -\frac{1}{2n^2} +o(\frac{1}{n^2}))}}$$=\lim_{n\to\infty}{n\ln{n \cdot2 (\frac{1}{2n} +\left(\frac{1}{2!}\cdot \frac{1}{2} \cdot \left(\frac{1}{2}-1\right) \right)\frac{1}{n^2} +o(\frac{1}{n^2}))}}=\lim_{n\to\infty}{n \ln{\left(1-\frac{1}{4n}\right)}}=-\frac{1}{4} $ so that $\displaystyle\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+k}}}\right)^{n}}=\lim _{n \rightarrow \infty} e^{(1)}=e^{-\frac{1}{4}}$ this solution is right.","left= right= left right ,what to do next? so that this solution is right.",\displaystyle\left(\sum_{k=1}^{n} \frac{1}{\sqrt{n^{2}+1}}\right)^{n}\ge\left(\sum_{k=1}^{n} \frac{1}{\sqrt{n^{2}+k}}\right)^{n}\ge\left(\sum_{k=1}^{n} \frac{1}{\sqrt{n^{2}+n}}\right)^{n} \displaystyle\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+1}}}\right)^{n}}=e^{\displaystyle n \ln{\frac{n}{\sqrt{n^2+1}}} }=e^{0}=1 \displaystyle\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+n}}}\right)^{n}}=e^{\displaystyle n \ln{\frac{n}{\sqrt{n^2+n}}} }=e^{-\frac{1}{2}} \ne \displaystyle\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+k}}}\right)^{n}}=\lim _{n \rightarrow \infty} e^{\displaystyle n \ln \sum_{k=1}^{n} \frac{1}{\sqrt{n^{2}+k}}(1)} (1)=\displaystyle \lim _{n \rightarrow \infty} n\left(\ln \frac{1}{n} \sum_{k=1}^{n} \frac{1}{\sqrt{1+k/n^{2}}}\right)=\lim _{n \rightarrow \infty} n\left(\ln \frac{1}{n} \sum_{k=1}^{n} \frac{1}{\sqrt{1+k/n \cdot 1/n}}\right)=\lim _{n \rightarrow \infty} n \ln \int_{0}^{1} \frac{1}{\sqrt{1+x/n}} d x=\lim _{n \rightarrow \infty} n \ln \int_{0}^{1} \frac{nd(x/n+1)}{\sqrt{1+x/n}}= \lim_{n\to\infty}{n\ln{n \cdot2 \left.\sqrt{1+\frac{x}{n} }\right|_{0}^{1}}}= \lim_{n\to\infty}{n\ln{n \cdot2 (\sqrt{1+\frac{1}{n}}-1)}}=\lim_{n\to\infty}{n\ln{n \cdot2 (\frac{1}{2n} -\frac{1}{2n^2} +o(\frac{1}{n^2}))}}=\lim_{n\to\infty}{n\ln{n \cdot2 (\frac{1}{2n} +\left(\frac{1}{2!}\cdot \frac{1}{2} \cdot \left(\frac{1}{2}-1\right) \right)\frac{1}{n^2} +o(\frac{1}{n^2}))}}=\lim_{n\to\infty}{n \ln{\left(1-\frac{1}{4n}\right)}}=-\frac{1}{4}  \displaystyle\lim_{n\to\infty}{\left(\sum_{k=1}^{n}{\frac{1}{\sqrt{n^2+k}}}\right)^{n}}=\lim _{n \rightarrow \infty} e^{(1)}=e^{-\frac{1}{4}},['limits']
55,Calculate this limit : $\lim_{x\rightarrow +\infty}\left[x\left(4\arctan\left(\frac{x+1}{x}\right)-\pi\right)\right]$ [closed],Calculate this limit :  [closed],\lim_{x\rightarrow +\infty}\left[x\left(4\arctan\left(\frac{x+1}{x}\right)-\pi\right)\right],"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Calculate the limit $$\lim_{x\rightarrow +\infty}\left[x\left(4\arctan\left(\frac{x+1}{x}\right)-\pi\right)\right]$$ Neither L'Hospital's rule nor Taylor expansions are allowed,","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question Calculate the limit $$\lim_{x\rightarrow +\infty}\left[x\left(4\arctan\left(\frac{x+1}{x}\right)-\pi\right)\right]$$ Neither L'Hospital's rule nor Taylor expansions are allowed,",,"['limits', 'limits-without-lhopital']"
56,Practice Preliminary exam - evaluate the limit,Practice Preliminary exam - evaluate the limit,,This is from a practice prelim exam and I know I should be able to get this one. $$ \lim_{n\to\infty} n^{1/2}\int_0^\infty \left( \frac{2x}{1+x^2} \right)^n $$ I have tried many different $u-$substitions but to no avail.  I have tried $$ u = \log(1+x^2) $$ $$ du = \frac{2x}{1+x^2}dx $$  but did not get anywhere,This is from a practice prelim exam and I know I should be able to get this one. $$ \lim_{n\to\infty} n^{1/2}\int_0^\infty \left( \frac{2x}{1+x^2} \right)^n $$ I have tried many different $u-$substitions but to no avail.  I have tried $$ u = \log(1+x^2) $$ $$ du = \frac{2x}{1+x^2}dx $$  but did not get anywhere,,['limits']
57,Infinite sums: adding terms,Infinite sums: adding terms,,"I would like to know where I can find a formal treatment of an idea I had, assuming it makes sense. Consider the infinite sum $$\sum\limits_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$$ and define the partial sum $$S_N=\sum\limits_{n=1}^{N}\frac{1}{n^2}$$ I guess that $$R_N = S_N + \frac{1}{N}$$ should converge faster as $N\rightarrow\infty$. Does it make sense? Any formal theory? Thanks!!!","I would like to know where I can find a formal treatment of an idea I had, assuming it makes sense. Consider the infinite sum $$\sum\limits_{n=1}^{\infty}\frac{1}{n^2}=\frac{\pi^2}{6}$$ and define the partial sum $$S_N=\sum\limits_{n=1}^{N}\frac{1}{n^2}$$ I guess that $$R_N = S_N + \frac{1}{N}$$ should converge faster as $N\rightarrow\infty$. Does it make sense? Any formal theory? Thanks!!!",,"['limits', 'summation']"
58,How can this be proved $\lim_{x\to\infty}(f(x)+f'(x))=l$ [duplicate],How can this be proved  [duplicate],\lim_{x\to\infty}(f(x)+f'(x))=l,"This question already has answers here : If $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty$, does $\lim\limits_{x\rightarrow\infty} f(x) $ exist? (2 answers) Closed 3 months ago . If $$\lim_{x\to\infty}(f(x)+f'(x))=l$$ then prove that $$\lim_{x\to\infty}f(x)=l \text{ and } \lim_{x\to\infty}f'(x)=0 $$ I assume four cases $$\begin{array}{c|c|c|c|}   & f(x) & f'(x) \\ \hline \text{1} & \infty & -\infty \\ \hline \text{2} & -\infty & \infty \\ \hline \text{3} & l & 0 \\ \hline \text{4} & 0 & l \\ \hline \end{array}$$ and elimination(1,2,4) of not possible cases can give the answer(3). My work is not a correct/perfect or flaw proof.What would be a correct one or is this correct.","This question already has answers here : If $\lim\limits_{x\rightarrow\infty} (f'(x)+f(x)) =L<\infty$, does $\lim\limits_{x\rightarrow\infty} f(x) $ exist? (2 answers) Closed 3 months ago . If $$\lim_{x\to\infty}(f(x)+f'(x))=l$$ then prove that $$\lim_{x\to\infty}f(x)=l \text{ and } \lim_{x\to\infty}f'(x)=0 $$ I assume four cases $$\begin{array}{c|c|c|c|}   & f(x) & f'(x) \\ \hline \text{1} & \infty & -\infty \\ \hline \text{2} & -\infty & \infty \\ \hline \text{3} & l & 0 \\ \hline \text{4} & 0 & l \\ \hline \end{array}$$ and elimination(1,2,4) of not possible cases can give the answer(3). My work is not a correct/perfect or flaw proof.What would be a correct one or is this correct.",,['limits']
59,Evaluate the limit $\lim\limits_{n\rightarrow \infty}\int_{0}^{\pi}\left|\sin(x)-\sin(2nx)\right|\text{ d}x$ [closed],Evaluate the limit  [closed],\lim\limits_{n\rightarrow \infty}\int_{0}^{\pi}\left|\sin(x)-\sin(2nx)\right|\text{ d}x,"Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question $$\lim_{n\rightarrow \infty}\int_{0}^{\pi}\left|\sin(x)-\sin(2nx)\right|\mathrm d x$$ Heading I put proper big numbers to $n$ using calculator to estimate the answer. And then I figured out that the answer seems like $\frac{8}{\pi}$ , but unfortunately I dont have any clues. Please help.","Closed. This question does not meet Mathematics Stack Exchange guidelines . It is not currently accepting answers. Please provide additional context , which ideally explains why the question is relevant to you and our  community. Some forms of context include: background and motivation, relevant definitions, source, possible strategies, your current progress, why the question is interesting or important, etc. Closed 1 year ago . Improve this question Heading I put proper big numbers to using calculator to estimate the answer. And then I figured out that the answer seems like , but unfortunately I dont have any clues. Please help.",\lim_{n\rightarrow \infty}\int_{0}^{\pi}\left|\sin(x)-\sin(2nx)\right|\mathrm d x n \frac{8}{\pi},"['limits', 'definite-integrals', 'trigonometric-integrals']"
60,Why can't you take the limit of a 2-D function in every direction and call that the limit if they're equal?,Why can't you take the limit of a 2-D function in every direction and call that the limit if they're equal?,,"In my second-year calculus class this term, one of the thing that the professor insisted was wrong was that the limit of a two-dimensional function as the input approached a certain point could not be calculated simply by taking the limit of the function in every direction and verifying that they were all equal. I've taken her word for it, but why is this not true? Is there a counterexample to this proposition, and if so, what general principle does it violate?","In my second-year calculus class this term, one of the thing that the professor insisted was wrong was that the limit of a two-dimensional function as the input approached a certain point could not be calculated simply by taking the limit of the function in every direction and verifying that they were all equal. I've taken her word for it, but why is this not true? Is there a counterexample to this proposition, and if so, what general principle does it violate?",,"['limits', 'multivariable-calculus']"
61,Prime number curiosity : $ \lim\limits_{n\to\infty}\frac{\exp(1+\sum_{i=1}^n\frac1{p_i-1})}{\prod_{i=1}^n(1+\frac1{p_i-1})}=\frac{79}{25}$ !?,Prime number curiosity :  !?, \lim\limits_{n\to\infty}\frac{\exp(1+\sum_{i=1}^n\frac1{p_i-1})}{\prod_{i=1}^n(1+\frac1{p_i-1})}=\frac{79}{25},"Let $0<n$ be a positive integer. Let $p_n$ be the $n$ -th odd prime. $$p_1 = 3,p_2=5,p_3=7,p_4=11,\ldots$$ Let $$f(n) = \exp \left(1 + \sum_{i=1}^{n}\frac{1}{p_i-1} \right)$$ Let $$g(n) = \prod_{i=1}^{n} \left(1+\frac{1}{p_i-1} \right)$$ Let $$t(n) = \frac{f(n)}{g(n)}$$ Then this limit exists $$ \lim_{n \to +\infty} t(n) = \frac{79}{25}$$ And for sufficiently large $n$ we have : $$ \frac{79}{25} - \frac{\ln(n)+2}{n^2-1} < t(n) < \frac{79}{25} - \frac{1}{n^5}$$ How to formally prove it ?",Let be a positive integer. Let be the -th odd prime. Let Let Let Then this limit exists And for sufficiently large we have : How to formally prove it ?,"0<n p_n n p_1 = 3,p_2=5,p_3=7,p_4=11,\ldots f(n) = \exp \left(1 + \sum_{i=1}^{n}\frac{1}{p_i-1} \right) g(n) = \prod_{i=1}^{n} \left(1+\frac{1}{p_i-1} \right) t(n) = \frac{f(n)}{g(n)}  \lim_{n \to +\infty} t(n) = \frac{79}{25} n  \frac{79}{25} - \frac{\ln(n)+2}{n^2-1} < t(n) < \frac{79}{25} - \frac{1}{n^5}","['limits', 'number-theory', 'prime-numbers', 'asymptotics', 'fractions']"
62,Improper Integral of $f_n$ of a Uniformly Convergent Sequence,Improper Integral of  of a Uniformly Convergent Sequence,f_n,"Let $(f_n)$ be a sequence of functions defined in $[a,\infty)$, which uniformly converges to $f$ in every interval $I_b$ of the form $[a,b]$. Assume every function in the sequence is integrable in $I_b$ for all $b\geq a$. Finally, assume $\int_a^\infty f(x)dx$ and $\int_a^\infty f_n(x)dx$ converge for all n. Does the following equality necessarily hold? $$\lim_{n\rightarrow \infty}\int_a^\infty f_n(x)dx = \int_a^\infty f(x)dx$$ First, since the sequence converges unformly, we have $$\lim_{n\rightarrow \infty}\int_a^b f_n(x)dx = \int_a^b f(x)dx$$ Second, $$\lim_{n\rightarrow \infty}\int_a^\infty f_n(x)dx = \lim_{n\rightarrow \infty}\left[\lim_{b\rightarrow \infty}\int_a^b f_n(x)dx\right]$$ and also $$\int_a^\infty f(x)dx = \lim_{b\rightarrow \infty}\left[\lim_{n\rightarrow \infty}\int_a^b f_n(x)dx\right]$$ So it kind of boils down to this change of limits, and this is what I cannot justify, nor disprove for this case. Any directions? Thanks. Edit: my current intuition is that the statement is false, and to hold there must be added an extra condition such as a dominating function $g$ for $f_n$, as seen elsewhere in similar questions, but I'm still unable to disprove this equality.","Let $(f_n)$ be a sequence of functions defined in $[a,\infty)$, which uniformly converges to $f$ in every interval $I_b$ of the form $[a,b]$. Assume every function in the sequence is integrable in $I_b$ for all $b\geq a$. Finally, assume $\int_a^\infty f(x)dx$ and $\int_a^\infty f_n(x)dx$ converge for all n. Does the following equality necessarily hold? $$\lim_{n\rightarrow \infty}\int_a^\infty f_n(x)dx = \int_a^\infty f(x)dx$$ First, since the sequence converges unformly, we have $$\lim_{n\rightarrow \infty}\int_a^b f_n(x)dx = \int_a^b f(x)dx$$ Second, $$\lim_{n\rightarrow \infty}\int_a^\infty f_n(x)dx = \lim_{n\rightarrow \infty}\left[\lim_{b\rightarrow \infty}\int_a^b f_n(x)dx\right]$$ and also $$\int_a^\infty f(x)dx = \lim_{b\rightarrow \infty}\left[\lim_{n\rightarrow \infty}\int_a^b f_n(x)dx\right]$$ So it kind of boils down to this change of limits, and this is what I cannot justify, nor disprove for this case. Any directions? Thanks. Edit: my current intuition is that the statement is false, and to hold there must be added an extra condition such as a dominating function $g$ for $f_n$, as seen elsewhere in similar questions, but I'm still unable to disprove this equality.",,"['limits', 'improper-integrals', 'uniform-convergence']"
63,Find $\lim_{t\to 1^{-}}(1-t)\sum_{r = 1}^\infty \frac{t^r}{t^r+1}$,Find,\lim_{t\to 1^{-}}(1-t)\sum_{r = 1}^\infty \frac{t^r}{t^r+1},"$$\lim_{t\to 1^{-}}(1-t)\sum_{r = 1}^\infty \frac{t^r}{t^r+1}$$ Note: I am a high school student and this problem appeared in my test. So, please try to use methods to solve this problem at a high school level :) My Attempt: I have honestly no idea how to approach this problem. I first tried to simplify the summation but didn't find any pattern. By looking at the options given to me ( which were all in ln's and e's )I do get a feel that we may have to integrate at some point. Though I am not sure. Any help would be appreciated.","Note: I am a high school student and this problem appeared in my test. So, please try to use methods to solve this problem at a high school level :) My Attempt: I have honestly no idea how to approach this problem. I first tried to simplify the summation but didn't find any pattern. By looking at the options given to me ( which were all in ln's and e's )I do get a feel that we may have to integrate at some point. Though I am not sure. Any help would be appreciated.",\lim_{t\to 1^{-}}(1-t)\sum_{r = 1}^\infty \frac{t^r}{t^r+1},"['limits', 'summation']"
64,Find a value of $\;\lim\limits_{n\rightarrow\infty}n\left ( 1- a_{n} \right )$,Find a value of,\;\lim\limits_{n\rightarrow\infty}n\left ( 1- a_{n} \right ),"I'm going to give you an extremal problem. Given $a_{n}:=\left ( \text{the solution for the equation}\,x^{n}= \cos x,\quad x> 0 \right ),$ find a value of $$\lim_{n\rightarrow\infty}n\left ( 1- a_{n} \right )$$ Source: Fujino_Yusui If you imagine the graph of $x^{n},$ it should intersect at the point where it increases rapidly by $1,$ which is about where $x^{n}= \cos 1\,(y$ is increasing rapidly, so if you look at $y,$ you should be able to approximate $x$ well enough $).\,n\left ( 1- \cos^{\frac{1}{n}}1 \right )$ looks good, and $\frac{1}{n}= h$ is the derivative of $h\rightarrow 0^{+}.$ I guess $-\ln\cos 1$ by definition.","I'm going to give you an extremal problem. Given find a value of Source: Fujino_Yusui If you imagine the graph of it should intersect at the point where it increases rapidly by which is about where is increasing rapidly, so if you look at you should be able to approximate well enough looks good, and is the derivative of I guess by definition.","a_{n}:=\left ( \text{the solution for the equation}\,x^{n}= \cos x,\quad x> 0 \right ), \lim_{n\rightarrow\infty}n\left ( 1- a_{n} \right ) x^{n}, 1, x^{n}= \cos 1\,(y y, x ).\,n\left ( 1- \cos^{\frac{1}{n}}1 \right ) \frac{1}{n}= h h\rightarrow 0^{+}. -\ln\cos 1",['limits']
65,Find $\lim_{n\to\infty}\left(2n\int_{0}^{1}\frac{x^n}{1+x^2}dx\right)^n$,Find,\lim_{n\to\infty}\left(2n\int_{0}^{1}\frac{x^n}{1+x^2}dx\right)^n,Find this limits $$\lim_{n\to\infty}\left(2n\int_{0}^{1}\dfrac{x^n}{1+x^2}dx\right)^n\tag{1}$$ since following links post this question have solve  it.$$\lim_{n\to\infty}2n\int_{0}^{\frac{\pi}{4}}\tan^n{x}dx=\dfrac{1}{2}$$ Solving $\lim_{n\to\infty}(n\int_0^{\pi/4}(\tan x)^ndx)$? Could you suggest a helpful idea with $(1)$ ?,Find this limits $$\lim_{n\to\infty}\left(2n\int_{0}^{1}\dfrac{x^n}{1+x^2}dx\right)^n\tag{1}$$ since following links post this question have solve  it.$$\lim_{n\to\infty}2n\int_{0}^{\frac{\pi}{4}}\tan^n{x}dx=\dfrac{1}{2}$$ Solving $\lim_{n\to\infty}(n\int_0^{\pi/4}(\tan x)^ndx)$? Could you suggest a helpful idea with $(1)$ ?,,[]
66,Limit of $\left(\frac{2\sqrt{a(a+b/(\sqrt{n}+\epsilon))}}{2a+b/(\sqrt{n}+\epsilon)}\right)^{n/2}$,Limit of,\left(\frac{2\sqrt{a(a+b/(\sqrt{n}+\epsilon))}}{2a+b/(\sqrt{n}+\epsilon)}\right)^{n/2},"I'm having a hard time characterising the behavior of the following expression: $$\lim_{n\rightarrow\infty}\left(\frac{2\sqrt{a(a+b/(\sqrt{n}+\epsilon))}}{2a+b/(\sqrt{n}+\epsilon)}\right)^{\frac{n}{2}}$$ with the following constraints on the parameters: $0<b<a<\infty$, and $\epsilon\in\mathbb{R}$.  I am interested in the following: for $\epsilon>0$, does this limit go to zero or does it go to some constant $C$?  If it can both go to zero or to some constant $C>0$, what are the conditions on the value of $\epsilon$ as a function of $a$ and $b$ which leads to these outcomes, if any? for $\epsilon<0$, does it always go to some constant $C<1$, or can it go to 1 for some $\epsilon$, if it's a function of $a$ and $b$? what happens to this limit when $\epsilon=0$?","I'm having a hard time characterising the behavior of the following expression: $$\lim_{n\rightarrow\infty}\left(\frac{2\sqrt{a(a+b/(\sqrt{n}+\epsilon))}}{2a+b/(\sqrt{n}+\epsilon)}\right)^{\frac{n}{2}}$$ with the following constraints on the parameters: $0<b<a<\infty$, and $\epsilon\in\mathbb{R}$.  I am interested in the following: for $\epsilon>0$, does this limit go to zero or does it go to some constant $C$?  If it can both go to zero or to some constant $C>0$, what are the conditions on the value of $\epsilon$ as a function of $a$ and $b$ which leads to these outcomes, if any? for $\epsilon<0$, does it always go to some constant $C<1$, or can it go to 1 for some $\epsilon$, if it's a function of $a$ and $b$? what happens to this limit when $\epsilon=0$?",,['limits']
67,Question about $\lim_{n\to\infty} n|\sin n|$,Question about,\lim_{n\to\infty} n|\sin n|,"I have a question regarding this limit (of a sequence): $$\lim_{n\to \infty} n|\sin(n)|$$ Why isn't it infinite? The way I thought this problem is like this-$|\sin(n)|$ is always positive, and n tends to infinity, so shouldn't the whole limit go to infinity? What is the right way to solve this and why is my idea wrong?","I have a question regarding this limit (of a sequence): $$\lim_{n\to \infty} n|\sin(n)|$$ Why isn't it infinite? The way I thought this problem is like this-$|\sin(n)|$ is always positive, and n tends to infinity, so shouldn't the whole limit go to infinity? What is the right way to solve this and why is my idea wrong?",,"['limits', 'trigonometry', 'complex-numbers', 'infinity']"
68,What is the limit of this divergent infinite product multiplied by an exponential?,What is the limit of this divergent infinite product multiplied by an exponential?,,"What is... $$\lim_{\omega \to \infty}  \left( {1 \over {c^{\omega}}} \cdot  \prod_{N=1}^{\omega} (1+e^{b \cdot c^{-N}}) \right)$$ My attempt: I have absolutely no clue except for the case of $c=2$ and  $b=1$ Create a line integral over the unit line evaluated with a uniform measure... $$\int_L e^x d \mu=\int_{L/2} e^x \ d\mu+\int_{L/2} e^{x+1/2} \ d\mu$$ This identity should be evident by self-similarity. Prepare for recursion... $$\int_L e^x d \mu=\int_{L/2} e^x+e^{x+1/2} \ d\mu=(1+e^{1/2}) \cdot \int_{L/2} e^x \ d\mu$$ $$\Rightarrow \int_L e^x d \mu=(1+e^{1/2}) \cdot \left( \int_{L/4} e^x \ d\mu+\int_{L/4} e^{x+1/4} \ d\mu \right)$$ $$\Rightarrow \int_L e^x d \mu=(1+e^{1/2}) \cdot (1+e^{1/4}) \cdot \left( \int_{L/4} e^x \ d\mu \right)$$ It wouldn't be hard to prove by induction then that... $$\Rightarrow \int_L e^x d \mu=\lim_{\omega \to \infty}  \left(\prod_{N=1}^{\omega} (1+e^{2^{-N}}) \cdot \int_{L/{2^{\omega}}} e^x \ d\mu \right)$$ Yet we know what the left hand side equals, since it can be evaluated as a definite integral, also we know what the integral on the right equals. Since the measure is uniform and the number of values x will be allowed to take on the interval decreases to just the value, namely $0$... $$e-1= \lim_{\omega \to \infty}  \left( {1 \over {2^{\omega}}} \cdot \prod_{N=1}^{\omega} (1+e^{2^{-N}}) \right)$$ Motivation: Getting an answer will allow me to derive methods to integrate a function like $e^x$ over fractals.","What is... $$\lim_{\omega \to \infty}  \left( {1 \over {c^{\omega}}} \cdot  \prod_{N=1}^{\omega} (1+e^{b \cdot c^{-N}}) \right)$$ My attempt: I have absolutely no clue except for the case of $c=2$ and  $b=1$ Create a line integral over the unit line evaluated with a uniform measure... $$\int_L e^x d \mu=\int_{L/2} e^x \ d\mu+\int_{L/2} e^{x+1/2} \ d\mu$$ This identity should be evident by self-similarity. Prepare for recursion... $$\int_L e^x d \mu=\int_{L/2} e^x+e^{x+1/2} \ d\mu=(1+e^{1/2}) \cdot \int_{L/2} e^x \ d\mu$$ $$\Rightarrow \int_L e^x d \mu=(1+e^{1/2}) \cdot \left( \int_{L/4} e^x \ d\mu+\int_{L/4} e^{x+1/4} \ d\mu \right)$$ $$\Rightarrow \int_L e^x d \mu=(1+e^{1/2}) \cdot (1+e^{1/4}) \cdot \left( \int_{L/4} e^x \ d\mu \right)$$ It wouldn't be hard to prove by induction then that... $$\Rightarrow \int_L e^x d \mu=\lim_{\omega \to \infty}  \left(\prod_{N=1}^{\omega} (1+e^{2^{-N}}) \cdot \int_{L/{2^{\omega}}} e^x \ d\mu \right)$$ Yet we know what the left hand side equals, since it can be evaluated as a definite integral, also we know what the integral on the right equals. Since the measure is uniform and the number of values x will be allowed to take on the interval decreases to just the value, namely $0$... $$e-1= \lim_{\omega \to \infty}  \left( {1 \over {2^{\omega}}} \cdot \prod_{N=1}^{\omega} (1+e^{2^{-N}}) \right)$$ Motivation: Getting an answer will allow me to derive methods to integrate a function like $e^x$ over fractals.",,"['limits', 'infinite-product']"
69,How find this limit$\lim_{n\to\infty}\frac{1}{n}\left(\frac{n}{\frac{1}{2}+\frac{2}{3}+\cdots+\frac{n}{n+1}}\right)^n$,How find this limit,\lim_{n\to\infty}\frac{1}{n}\left(\frac{n}{\frac{1}{2}+\frac{2}{3}+\cdots+\frac{n}{n+1}}\right)^n,"How  find this limit $$\lim_{n\to\infty}\dfrac{1}{n}\left(\dfrac{n}{\dfrac{1}{2}+\dfrac{2}{3}+\cdots+\dfrac{n}{n+1}}\right)^n$$ My try: since $$\dfrac{1}{2}+\dfrac{2}{3}+\cdots+\dfrac{n}{n+1}=\left(1-\dfrac{1}{2}\right)+\left(1-\dfrac{1}{3}\right)+\cdots+\left(1-\dfrac{1}{n+1}\right)=(n+1)-H_{n+1}$$ where $$H_{n}=1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}$$ then I can't.Thank you this problem is from a book,and only give this answer $$e^{\gamma-1}$$ where $\gamma$ is denotes the Euler–Mascheroni constant.","How  find this limit $$\lim_{n\to\infty}\dfrac{1}{n}\left(\dfrac{n}{\dfrac{1}{2}+\dfrac{2}{3}+\cdots+\dfrac{n}{n+1}}\right)^n$$ My try: since $$\dfrac{1}{2}+\dfrac{2}{3}+\cdots+\dfrac{n}{n+1}=\left(1-\dfrac{1}{2}\right)+\left(1-\dfrac{1}{3}\right)+\cdots+\left(1-\dfrac{1}{n+1}\right)=(n+1)-H_{n+1}$$ where $$H_{n}=1+\dfrac{1}{2}+\dfrac{1}{3}+\cdots+\dfrac{1}{n}$$ then I can't.Thank you this problem is from a book,and only give this answer $$e^{\gamma-1}$$ where $\gamma$ is denotes the Euler–Mascheroni constant.",,['limits']
70,Why does Python's calculation of $0^0$ include the digits of pi?,Why does Python's calculation of  include the digits of pi?,0^0,"When you run the following Python code, which is equivalent to $\lim_{x \to 0^+} x^x$ , x = 0.0000000001; print(x ** x) The output will correctly approach 1. (The output is 0.9999999976974149 ). But when you change: x = -0.0000000001 Which would be equivalent to $\lim_{x \to 0^-} x^x$ , the following output is produced: (1.000000002302585-3.141592660823578e-10j) This is also correct but why do I see an approximation of $\pi$ ? Surely this can't be a coincidence. Is it the side product of an algorithm that's being used? Or is there a purely mathematical reason for it? Edit: I only tested it in python. I don't know if similar outputs arise in other programming languages.","When you run the following Python code, which is equivalent to , x = 0.0000000001; print(x ** x) The output will correctly approach 1. (The output is 0.9999999976974149 ). But when you change: x = -0.0000000001 Which would be equivalent to , the following output is produced: (1.000000002302585-3.141592660823578e-10j) This is also correct but why do I see an approximation of ? Surely this can't be a coincidence. Is it the side product of an algorithm that's being used? Or is there a purely mathematical reason for it? Edit: I only tested it in python. I don't know if similar outputs arise in other programming languages.",\lim_{x \to 0^+} x^x \lim_{x \to 0^-} x^x \pi,"['limits', 'computer-science']"
71,Solve limit using definite integration,Solve limit using definite integration,,"I have to solve this limit using definite integral $${\lim_{n\to \infty} \frac{1}{n} \cdot \sum_{i=1}^n \frac{1}{1+(\frac{i}{n})^i}}$$ Well, my development was: I tried to give the Riemann integral definition form, using a regular partition such that: $$\int_a^bf(x)dx=\lim_{n\to\infty}\frac{b-a}{n}\cdot\sum_{i=1}f\left(a+i\frac{b-a}{n}\right)$$ So, i set $b=1, a=0$ for simplicity, then we have $f(\frac{i}{n})$ must be equal to ${\frac{1}{1+(\frac{i}{n})^i}}$ . Let ${x=\frac{i}{n}}$ , then $${f(x)=\frac{1}{1+x^{nx}}}$$ The problem is that $n$ is a dummy variable that does not make sense outside the limit, that is, it does not make sense for the function $f$ So, I need to do some kind of algebraic transformation or variable change for $n$ , in such a way that the function $f$ remains only in terms of $x$ and thus I can use it in the definite integral. However, I have not been able to find such a magical algebraic transformation or variable change for $n$ .","I have to solve this limit using definite integral Well, my development was: I tried to give the Riemann integral definition form, using a regular partition such that: So, i set for simplicity, then we have must be equal to . Let , then The problem is that is a dummy variable that does not make sense outside the limit, that is, it does not make sense for the function So, I need to do some kind of algebraic transformation or variable change for , in such a way that the function remains only in terms of and thus I can use it in the definite integral. However, I have not been able to find such a magical algebraic transformation or variable change for .","{\lim_{n\to \infty} \frac{1}{n} \cdot \sum_{i=1}^n \frac{1}{1+(\frac{i}{n})^i}} \int_a^bf(x)dx=\lim_{n\to\infty}\frac{b-a}{n}\cdot\sum_{i=1}f\left(a+i\frac{b-a}{n}\right) b=1, a=0 f(\frac{i}{n}) {\frac{1}{1+(\frac{i}{n})^i}} {x=\frac{i}{n}} {f(x)=\frac{1}{1+x^{nx}}} n f n f x n","['limits', 'definite-integrals']"
72,L’Hopital’s rule for (infinity over minus infinity),L’Hopital’s rule for (infinity over minus infinity),,Can I apply L’Hopital’s rule to this: $$ \lim_{x\to0}\frac{f(x)}{g(x)}  $$ when $ \lim_{x\to0}f(x) = \infty $ and $ \lim_{x\to0}g(x) = -\infty $. Is this an indeterminate form?,Can I apply L’Hopital’s rule to this: $$ \lim_{x\to0}\frac{f(x)}{g(x)}  $$ when $ \lim_{x\to0}f(x) = \infty $ and $ \lim_{x\to0}g(x) = -\infty $. Is this an indeterminate form?,,['limits']
73,Prove that $\lim_{x\to\infty} f'(x) = 0$ [duplicate],Prove that  [duplicate],\lim_{x\to\infty} f'(x) = 0,"This question already has answers here : If $f(x)\to 0$ as $x\to\infty$ and $f''$ is bounded, show that $f'(x)\to0$ as $x\to\infty$ (4 answers) Closed 9 years ago . Let $f(x)$ be twice differentiable on $(0,\infty)$ and let $\lim_{x\to \infty} f(x) = L<\infty$ and $|f''(x)| \le M$ for some $M>0$. Prove that $\lim_{x \to \infty} f'(x) = 0$. I've tried to use taylor with remainder in a lot of different ways and am still unable to crack this one.","This question already has answers here : If $f(x)\to 0$ as $x\to\infty$ and $f''$ is bounded, show that $f'(x)\to0$ as $x\to\infty$ (4 answers) Closed 9 years ago . Let $f(x)$ be twice differentiable on $(0,\infty)$ and let $\lim_{x\to \infty} f(x) = L<\infty$ and $|f''(x)| \le M$ for some $M>0$. Prove that $\lim_{x \to \infty} f'(x) = 0$. I've tried to use taylor with remainder in a lot of different ways and am still unable to crack this one.",,"['limits', 'taylor-expansion']"
74,How find this limit $\lim_{n\to\infty}a_{n}$,How find this limit,\lim_{n\to\infty}a_{n},"let $f(x)=x\ln{x}  (x>0)$,   and $f_{1}(x)=f(x)$,and such $f_{2}(x)=f(f_{1}(x)),f_{3}(x)=f(f_{2}(x)),\cdots,f_{n+1}(x)=f(f_{n}(x))$ Assume that the sequnce $\{a_{n}\}$ such  $f_{n}(a_{n})=1$ Find the $$\lim_{n\to\infty}a_{n}$$ My try: since $$f_{2}(x)=f(f_{1}(x))=f(x\ln{x})=x\ln{x}\ln{(x\ln{x})}=x\ln^2{x}+x\ln{x}\ln{(\ln{x})}$$   $$f_{3}(x)=f(f_{2}(x))=f(x\ln^2{x}+x\ln{x}\ln{(\ln{x})})=[x\ln^2{x}+x\ln{x}\ln{(\ln{x})}]\ln{[x\ln^2{x}+x\ln{x}\ln{(\ln{x})}]}=\cdots\cdots$$   and I can't work,But I fell guess   $$\lim_{n\to\infty}a_{n}=e?$$","let $f(x)=x\ln{x}  (x>0)$,   and $f_{1}(x)=f(x)$,and such $f_{2}(x)=f(f_{1}(x)),f_{3}(x)=f(f_{2}(x)),\cdots,f_{n+1}(x)=f(f_{n}(x))$ Assume that the sequnce $\{a_{n}\}$ such  $f_{n}(a_{n})=1$ Find the $$\lim_{n\to\infty}a_{n}$$ My try: since $$f_{2}(x)=f(f_{1}(x))=f(x\ln{x})=x\ln{x}\ln{(x\ln{x})}=x\ln^2{x}+x\ln{x}\ln{(\ln{x})}$$   $$f_{3}(x)=f(f_{2}(x))=f(x\ln^2{x}+x\ln{x}\ln{(\ln{x})})=[x\ln^2{x}+x\ln{x}\ln{(\ln{x})}]\ln{[x\ln^2{x}+x\ln{x}\ln{(\ln{x})}]}=\cdots\cdots$$   and I can't work,But I fell guess   $$\lim_{n\to\infty}a_{n}=e?$$",,['limits']
75,Prove that $\lim_{x\to 0} \frac{f(x)}{f'(x)} = 0$ for $f\in C^1$ and $f(0)=0=f'(0)$,Prove that  for  and,\lim_{x\to 0} \frac{f(x)}{f'(x)} = 0 f\in C^1 f(0)=0=f'(0),"Let $f\in C^1(\mathbb{R})$ , with $f(0)=0$ and $f'(0)=0$ . Furthermore, assume that in some neighborhood around $0$ , $f$ and $f'$ have no additional zeros, so $f^{-1}(\{0\})=\{0\}=(f')^{-1}(\{0\})$ . I want to show that $\lim_{x\to 0} \frac{f(x)}{f'(x)}=0$ . EDIT: According to a comment, this statement might be false. Would it be possible to prove the following, weaker statement: If $\lim_{x\to 0} \frac{f(x)}{f'(x)}=y$ , then, $y\in\{0,+\infty,-\infty\}$ ? My attempt so far is to write $$ \lim_{x\to 0} \frac{f(x)}{f'(x)} = \lim_{x\to 0} \lim_{h\to 0} \frac{hf(x)}{f(x+h)-f(x)} \stackrel{?}{=} \lim_{h\to 0} \lim_{x\to 0} \frac{hf(x)}{f(x+h)-f(x)} = \lim_{h\to 0} \frac{h\cdot 0}{f(h)-0} = 0. $$ As indicated by the ""?"" above the ""="", I am not sure how to prove that I am allowed to exchange these limits. I tried to apply the Moore-Osgood theorem. If I understand the theorem correctly, it boils down to showing: For all $h\neq 0$ , the limit $\lim_{x\to 0} \frac{hf(x)}{f(x+h)-f(x)}$ exists. This limit is always equal to $0$ , by the same calculation as above. For all $x\neq 0$ , the limit $\lim_{h\to 0} \frac{hf(x)}{f(x+h)-f(x)}$ exists. This limit is equal to $\frac{f(x)}{f'(x)}$ and thus exists. One of the limits converges uniformly, i.e., either the first limit converges uniformly for $h\neq 0$ , or the second limit converges uniformly for $x\neq 0$ . Unfortunately, I am stuck at showing uniform convergence of either of the two limits. I have the following questions: Is the statement I am trying to prove correct, or do I need further assumptions? Is my proof strategy correct so far? Is there a simpler way? Is one of the limits actually uniform? If so, can someone give me a hint on how to show it?","Let , with and . Furthermore, assume that in some neighborhood around , and have no additional zeros, so . I want to show that . EDIT: According to a comment, this statement might be false. Would it be possible to prove the following, weaker statement: If , then, ? My attempt so far is to write As indicated by the ""?"" above the ""="", I am not sure how to prove that I am allowed to exchange these limits. I tried to apply the Moore-Osgood theorem. If I understand the theorem correctly, it boils down to showing: For all , the limit exists. This limit is always equal to , by the same calculation as above. For all , the limit exists. This limit is equal to and thus exists. One of the limits converges uniformly, i.e., either the first limit converges uniformly for , or the second limit converges uniformly for . Unfortunately, I am stuck at showing uniform convergence of either of the two limits. I have the following questions: Is the statement I am trying to prove correct, or do I need further assumptions? Is my proof strategy correct so far? Is there a simpler way? Is one of the limits actually uniform? If so, can someone give me a hint on how to show it?","f\in C^1(\mathbb{R}) f(0)=0 f'(0)=0 0 f f' f^{-1}(\{0\})=\{0\}=(f')^{-1}(\{0\}) \lim_{x\to 0} \frac{f(x)}{f'(x)}=0 \lim_{x\to 0} \frac{f(x)}{f'(x)}=y y\in\{0,+\infty,-\infty\} 
\lim_{x\to 0} \frac{f(x)}{f'(x)} = \lim_{x\to 0} \lim_{h\to 0} \frac{hf(x)}{f(x+h)-f(x)}
\stackrel{?}{=} \lim_{h\to 0} \lim_{x\to 0} \frac{hf(x)}{f(x+h)-f(x)}
= \lim_{h\to 0} \frac{h\cdot 0}{f(h)-0} = 0.
 h\neq 0 \lim_{x\to 0} \frac{hf(x)}{f(x+h)-f(x)} 0 x\neq 0 \lim_{h\to 0} \frac{hf(x)}{f(x+h)-f(x)} \frac{f(x)}{f'(x)} h\neq 0 x\neq 0",['limits']
76,Limit of $\ln(1\cdot\ln(2\cdot\ln(3\cdot\ln(4\cdots))))$,Limit of,\ln(1\cdot\ln(2\cdot\ln(3\cdot\ln(4\cdots)))),"I recently asked for the limit $$\lim_{n \to\infty} \ln(1+\ln(2+\ln(3+\ln(4+\cdots+\ln(n))\ldots)$$. But what about the similar limit $$\lim_{n \to\infty} \ln(1\cdot \ln(2\cdot \ln(3\cdot \ln(4\cdots \ln(n))\ldots)$$ ? This limit also seems to exist ? n=10^5;x=log(n);while(n>1,x=log(x*(n-1));n=n-1);print(x) 0.3132776395465558314822583305 For n=100 the same value appears within this precision. Is there a proof of convergence also for this limit ? Can the limit be expressed by a closed form ?","I recently asked for the limit $$\lim_{n \to\infty} \ln(1+\ln(2+\ln(3+\ln(4+\cdots+\ln(n))\ldots)$$. But what about the similar limit $$\lim_{n \to\infty} \ln(1\cdot \ln(2\cdot \ln(3\cdot \ln(4\cdots \ln(n))\ldots)$$ ? This limit also seems to exist ? n=10^5;x=log(n);while(n>1,x=log(x*(n-1));n=n-1);print(x) 0.3132776395465558314822583305 For n=100 the same value appears within this precision. Is there a proof of convergence also for this limit ? Can the limit be expressed by a closed form ?",,"['analysis', 'limits']"
77,How prove this nice limit $\lim_{n\to+\infty}\frac{1}{n}\sum_{k=1}^{n}f(\{ka\})=\int_{0}^{1}f(x)dx$,How prove this nice limit,\lim_{n\to+\infty}\frac{1}{n}\sum_{k=1}^{n}f(\{ka\})=\int_{0}^{1}f(x)dx,"let $f(x)$ is Continuous on $[0,1]$, and such $f(0)=f(1)$,and if $a$ is irrational number. show that $$\lim_{n\to+\infty}\dfrac{1}{n}\sum_{k=1}^{n}f(\{ka\})=\int_{0}^{1}f(x)dx$$ where $\{ka\}=x-[x]$,and $[x]$ is  is the largest integer not greater than $x$ This problem  is from this ( problem 8) http://wenku.baidu.com/view/a643e6c26137ee06eff91855.html and I find this Prove that $\lim_{N\rightarrow\infty}(1/N)\sum_{n=1}^N f(nx)=\int_{0}^1f(t)dt$ Have without Trigonometric series  methods? because  this problem is Freshman exam questions","let $f(x)$ is Continuous on $[0,1]$, and such $f(0)=f(1)$,and if $a$ is irrational number. show that $$\lim_{n\to+\infty}\dfrac{1}{n}\sum_{k=1}^{n}f(\{ka\})=\int_{0}^{1}f(x)dx$$ where $\{ka\}=x-[x]$,and $[x]$ is  is the largest integer not greater than $x$ This problem  is from this ( problem 8) http://wenku.baidu.com/view/a643e6c26137ee06eff91855.html and I find this Prove that $\lim_{N\rightarrow\infty}(1/N)\sum_{n=1}^N f(nx)=\int_{0}^1f(t)dt$ Have without Trigonometric series  methods? because  this problem is Freshman exam questions",,['analysis']
78,Prove that $\lim\limits_{x\to 0^+}(x^{x^x}-x^x)=-1$,Prove that,\lim\limits_{x\to 0^+}(x^{x^x}-x^x)=-1,Prove that $\lim\limits_{x\to 0^+}(x^{x^x}-x^x)=-1$ Here neither L Hospital rule nor series expansion is working here.By what method should it be proved?Thanks.,Prove that $\lim\limits_{x\to 0^+}(x^{x^x}-x^x)=-1$ Here neither L Hospital rule nor series expansion is working here.By what method should it be proved?Thanks.,,['limits']
79,"General approach to solving problems with extending multivariable functions to be continuous, e.g. $f(x,y,z) = \frac{x^2-y^2+z^2}{x+y}$","General approach to solving problems with extending multivariable functions to be continuous, e.g.","f(x,y,z) = \frac{x^2-y^2+z^2}{x+y}","I'm having issues with the said title. In general, I get some functions,determine the domain $D_f$ and additionally the limit points of your domain, since $f$ is said to be continuous at $x$ if $x$ isn't a limit point of the set $D_f$. The problem is always to find points in which the function can be extended so it is continuous . So I can't say oh it's not continous at one specific point therefore it can't be extended. E.g. if you had a function that can be extended to $(0,0)$ but not points of the form$(0,x)$ you have to prove the statement and that's a valid answer. Some of the tools I've been given to prove the function is continous at a point are Heine, which proved to be not useful whenever you have a function that is a polynomial and more than one variable is in the denominator, and the usual $\epsilon -\delta$ which is pretty complicated to work out most of the time. An additional problem is that I've been taught that at uni just a few days ago, and next week I'm already being tested in solving some functions that are even harder. It's far easier to prove that a function can't be extended at a point, because then all you have to do is find two restrictions of the given function with different limit points, or two specific sequences that converge to the same point, but the limit point of the function value of the said sequences is not the same. So basically, I'm more interested in figuring out a general approach to these problems, rather than specific solutions. It's like I still haven't got the slightest feeling beforehand, whether it will or wil not be extendable to certain points . And considering I'll get about 20 minutes to solve such a problem I really want to figure it out. For example, consider the function: $$f:R^3\rightarrow R,$$defined as $$f(x,y,z) = \frac{x^2-y^2+z^2}{x+y}$$ Now, $D_f = R^3\backslash\{(x,-x,z):x,z\in R\}$ and obviously every point in $R^3$ is a limit point of the set $D_f$. First let's talk about $(0,0,0)$ After testing out some limits of restriction of this function, e.g. $lim_{x\rightarrow0}f(x,0,0) = 0 $ whichever such restriction  I choose, e.g. $y = 0, x = 0, z= 0, x=y=z$ etc. the limit is either $0$ or doesn't exist. So my intuition tells me I either can't extend it or I can extend it to 0, for that point.  But I'm not sure what to do here? $\epsilon - \delta$ for $0$ didn't yield any results and taking a sequence $(x_k,y_k,z_k)$ and plugging it into the function didn't work out well either. Not to mention proving anything for $\{(x,-x,z):x,z\in R\}$. Other examples include functions such as : $f:R^2 \rightarrow R, f(x,y) = \frac{e^{xy-1}}{x(x^2-y)}$","I'm having issues with the said title. In general, I get some functions,determine the domain $D_f$ and additionally the limit points of your domain, since $f$ is said to be continuous at $x$ if $x$ isn't a limit point of the set $D_f$. The problem is always to find points in which the function can be extended so it is continuous . So I can't say oh it's not continous at one specific point therefore it can't be extended. E.g. if you had a function that can be extended to $(0,0)$ but not points of the form$(0,x)$ you have to prove the statement and that's a valid answer. Some of the tools I've been given to prove the function is continous at a point are Heine, which proved to be not useful whenever you have a function that is a polynomial and more than one variable is in the denominator, and the usual $\epsilon -\delta$ which is pretty complicated to work out most of the time. An additional problem is that I've been taught that at uni just a few days ago, and next week I'm already being tested in solving some functions that are even harder. It's far easier to prove that a function can't be extended at a point, because then all you have to do is find two restrictions of the given function with different limit points, or two specific sequences that converge to the same point, but the limit point of the function value of the said sequences is not the same. So basically, I'm more interested in figuring out a general approach to these problems, rather than specific solutions. It's like I still haven't got the slightest feeling beforehand, whether it will or wil not be extendable to certain points . And considering I'll get about 20 minutes to solve such a problem I really want to figure it out. For example, consider the function: $$f:R^3\rightarrow R,$$defined as $$f(x,y,z) = \frac{x^2-y^2+z^2}{x+y}$$ Now, $D_f = R^3\backslash\{(x,-x,z):x,z\in R\}$ and obviously every point in $R^3$ is a limit point of the set $D_f$. First let's talk about $(0,0,0)$ After testing out some limits of restriction of this function, e.g. $lim_{x\rightarrow0}f(x,0,0) = 0 $ whichever such restriction  I choose, e.g. $y = 0, x = 0, z= 0, x=y=z$ etc. the limit is either $0$ or doesn't exist. So my intuition tells me I either can't extend it or I can extend it to 0, for that point.  But I'm not sure what to do here? $\epsilon - \delta$ for $0$ didn't yield any results and taking a sequence $(x_k,y_k,z_k)$ and plugging it into the function didn't work out well either. Not to mention proving anything for $\{(x,-x,z):x,z\in R\}$. Other examples include functions such as : $f:R^2 \rightarrow R, f(x,y) = \frac{e^{xy-1}}{x(x^2-y)}$",,"['limits', 'multivariable-calculus']"
80,Fraction of $1$s in binary representation of $n!$,Fraction of s in binary representation of,1 n!,"I plotted a fraction of $1$s in binary representation of $n!$ (i.e. A079584 / A072831 ) for $n$ from $1$ to $10^4$: It appears it might converge to some limit for $n\to\infty$. Can we (dis-)prove that this limit exists, and find its exact value? Or, at least, find the limit inferior and limit superior of the sequence?","I plotted a fraction of $1$s in binary representation of $n!$ (i.e. A079584 / A072831 ) for $n$ from $1$ to $10^4$: It appears it might converge to some limit for $n\to\infty$. Can we (dis-)prove that this limit exists, and find its exact value? Or, at least, find the limit inferior and limit superior of the sequence?",,"['number-theory', 'limits', 'factorial', 'limsup-and-liminf', 'binary']"
81,Reason for LCM of all numbers from 1 .. n equals roughly $e^n$,Reason for LCM of all numbers from 1 .. n equals roughly,e^n,"I computed the LCM for all natural numbers from 1 up to a limit $n$ and plotted the result over $n$.  Due to the fast-raising numbers, I plotted the logarithm of the result and was surprised to find a (more or less) identity curve ($x=y$). In other words, $LCM(1, 2, 3, ..., n)$ appears to be roughly the value $e^n$. Is a there a simple explanation on why this is so? $LCM(a, b, c, …)$ shall be defined as the least common multiple of all arguments $a, b, c, …$","I computed the LCM for all natural numbers from 1 up to a limit $n$ and plotted the result over $n$.  Due to the fast-raising numbers, I plotted the logarithm of the result and was surprised to find a (more or less) identity curve ($x=y$). In other words, $LCM(1, 2, 3, ..., n)$ appears to be roughly the value $e^n$. Is a there a simple explanation on why this is so? $LCM(a, b, c, …)$ shall be defined as the least common multiple of all arguments $a, b, c, …$",,"['number-theory', 'exponential-function', 'least-common-multiple']"
82,"Is 1/3 included in the sequence 0.3, 0.33, 0.333,...? [closed]","Is 1/3 included in the sequence 0.3, 0.33, 0.333,...? [closed]",,"Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 months ago . Improve this question I assume that $\frac{1}{3}$ is equal to $0.3333...$ . Let's define a sequence as follows: $0.3$ , $0.33$ , $0.333$ , $0.3333$ ,... Question: is $\frac{1}{3}$ included in this sequence? Every item in the sequence clearly has finite number of decimals, and $\frac{1}{3}$ has infinite decimals so it is clearly not included. On the other hand the limit of this sequence is $\frac{1}{3}$ so it seems ok to say that it ""includes"" $\frac{1}{3}$ . What is the correct answer?","Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 2 months ago . Improve this question I assume that is equal to . Let's define a sequence as follows: , , , ,... Question: is included in this sequence? Every item in the sequence clearly has finite number of decimals, and has infinite decimals so it is clearly not included. On the other hand the limit of this sequence is so it seems ok to say that it ""includes"" . What is the correct answer?",\frac{1}{3} 0.3333... 0.3 0.33 0.333 0.3333 \frac{1}{3} \frac{1}{3} \frac{1}{3} \frac{1}{3},"['limits', 'convergence-divergence', 'decimal-expansion']"
83,"Isn't $\lim_{h \to 0} \frac{c-c}{h}$ indeterminate, as $\lim_{h \to 0} \frac{c-c}{h} = \frac{0}{0}$?","Isn't  indeterminate, as ?",\lim_{h \to 0} \frac{c-c}{h} \lim_{h \to 0} \frac{c-c}{h} = \frac{0}{0},I have a question that asks me to differentiate  $f(x) = e^5$. This looks like differentiating a constant. So the answer is 0. But I'm confused about the proof withthe definition of a deriative: Don't we have an indeterminate limit since $\lim_{h \to 0} \frac{c-c}{h} = \frac{0}{0}$? Or is the right way to think about this is that the numerator is 0 but the denominator is never really quite 0 and so the limit as a whole is 0?,I have a question that asks me to differentiate  $f(x) = e^5$. This looks like differentiating a constant. So the answer is 0. But I'm confused about the proof withthe definition of a deriative: Don't we have an indeterminate limit since $\lim_{h \to 0} \frac{c-c}{h} = \frac{0}{0}$? Or is the right way to think about this is that the numerator is 0 but the denominator is never really quite 0 and so the limit as a whole is 0?,,['limits']
84,Calculating limit of definite integral,Calculating limit of definite integral,,"I need to calculate: $$ \lim_{x\to \infty} \int_x^{x+1} \frac{t^2+1}{t^2+20t+8}\, dt $$ The result should be $1$ . Is there a quicker way than calculating the primitive function? I thought about seperating to $\int_0^{x+1} -\int_0^x$ but still can't think of the solution.",I need to calculate: The result should be . Is there a quicker way than calculating the primitive function? I thought about seperating to but still can't think of the solution.,"
\lim_{x\to \infty} \int_x^{x+1} \frac{t^2+1}{t^2+20t+8}\, dt
 1 \int_0^{x+1} -\int_0^x","['limits', 'definite-integrals']"
85,What do Indeterminate Forms mean? [duplicate],What do Indeterminate Forms mean? [duplicate],,"This question already has answers here : What really is an indeterminate form? (6 answers) Closed 4 years ago . I know they can be $\frac{0}{0}$ or $\frac{\pm\infty}{\pm\infty}$, but what do they mean in English? For example, $$\lim_{n\rightarrow \infty}A$$ In the context of limits, when the above example get a limit that is an indeterminate form. I assume it means that $A$ does not give enough information to ""determine"" a limit. Fine. But why is it that when we cancel out some terms out in $A$, *poof* now we have enough information to get a definite limit even though no extra information (i.e. additional expressions) have been added to $A$. Another example: $\lim_{x\rightarrow3}\frac{(x-3)(x+3)}{x-3}=\frac{0}{0}$, not enough information to determine the limit. $\lim_{x\rightarrow3}\frac{(x-3)(x+3)}{x-3}=\lim_{x\rightarrow3}(x+3)=6$, Hey! Now we have enough information to determine the limit! (I thought you said you didn't have enough information)","This question already has answers here : What really is an indeterminate form? (6 answers) Closed 4 years ago . I know they can be $\frac{0}{0}$ or $\frac{\pm\infty}{\pm\infty}$, but what do they mean in English? For example, $$\lim_{n\rightarrow \infty}A$$ In the context of limits, when the above example get a limit that is an indeterminate form. I assume it means that $A$ does not give enough information to ""determine"" a limit. Fine. But why is it that when we cancel out some terms out in $A$, *poof* now we have enough information to get a definite limit even though no extra information (i.e. additional expressions) have been added to $A$. Another example: $\lim_{x\rightarrow3}\frac{(x-3)(x+3)}{x-3}=\frac{0}{0}$, not enough information to determine the limit. $\lim_{x\rightarrow3}\frac{(x-3)(x+3)}{x-3}=\lim_{x\rightarrow3}(x+3)=6$, Hey! Now we have enough information to determine the limit! (I thought you said you didn't have enough information)",,['limits']
86,What is $\lim_{x\to\infty}\left(\sin{\frac 1x}+\cos{\frac 1x}\right)^x$?,What is ?,\lim_{x\to\infty}\left(\sin{\frac 1x}+\cos{\frac 1x}\right)^x,"$$\lim_{x\to\infty}\left(\sin{\frac 1x}+\cos{\frac 1x}\right)^x$$ It is about the $(\to1)^{(\to\infty)}$ situation. Can we find its limit using the formula $\lim_{x\to\infty}(1+\frac 1x)^x=e$? If yes, then how?","$$\lim_{x\to\infty}\left(\sin{\frac 1x}+\cos{\frac 1x}\right)^x$$ It is about the $(\to1)^{(\to\infty)}$ situation. Can we find its limit using the formula $\lim_{x\to\infty}(1+\frac 1x)^x=e$? If yes, then how?",,"['limits', 'trigonometry']"
87,"Determine whether or not the limit exists: $\lim_{(x,y)\to(0,0)}\frac{(x+y)^2}{x^2+y^2}$",Determine whether or not the limit exists:,"\lim_{(x,y)\to(0,0)}\frac{(x+y)^2}{x^2+y^2}","Determine whether or not the limit $$\lim_{(x,y)\to(0,0)}\frac{(x+y)^2}{x^2+y^2}$$   exists. If it does, then calculate its value. My attempt: $$\begin{align}\lim \frac{(x+y)^2}{x^2+y^2} &= \lim \frac{x^2+y^2}{x^2+y^2} + \lim \frac {2xy}{x^2+y^2} =\\&= 1 + \lim \frac 2{xy^{-1}+yx^{-1}} = 1+ 2\cdot\lim \frac 1{xy^{-1}+yx^{-1}}\end{align}$$ But $\lim_{x\to 0^+} x^{-1} = +\infty$ and $\lim_{x\to 0^-} x^{-1} = -\infty$ Likewise, $\lim_{y\to 0^+} y^{-1} = +\infty$ and $\lim_{y\to 0^-} y^{-1} = -\infty$ So the left hand and right hand limits cannot be equal, and therefore the limit does not exist.","Determine whether or not the limit $$\lim_{(x,y)\to(0,0)}\frac{(x+y)^2}{x^2+y^2}$$   exists. If it does, then calculate its value. My attempt: $$\begin{align}\lim \frac{(x+y)^2}{x^2+y^2} &= \lim \frac{x^2+y^2}{x^2+y^2} + \lim \frac {2xy}{x^2+y^2} =\\&= 1 + \lim \frac 2{xy^{-1}+yx^{-1}} = 1+ 2\cdot\lim \frac 1{xy^{-1}+yx^{-1}}\end{align}$$ But $\lim_{x\to 0^+} x^{-1} = +\infty$ and $\lim_{x\to 0^-} x^{-1} = -\infty$ Likewise, $\lim_{y\to 0^+} y^{-1} = +\infty$ and $\lim_{y\to 0^-} y^{-1} = -\infty$ So the left hand and right hand limits cannot be equal, and therefore the limit does not exist.",,"['limits', 'multivariable-calculus']"
88,How do I find the limit of this function?,How do I find the limit of this function?,,This is a question from my calculus text. It says $$\lim\limits_{x\to1}\left(\frac{p}{1-x^p}-\frac{q}{1-x^q}\right)$$ where $p$ and $q$ are natural numbers. I know this is an infinity-infinity indeterminant form which can be converted to a $0/0$ form. I tried substituting $x=1+h$ where $h\to0$. But it is not working. What should I do?,This is a question from my calculus text. It says $$\lim\limits_{x\to1}\left(\frac{p}{1-x^p}-\frac{q}{1-x^q}\right)$$ where $p$ and $q$ are natural numbers. I know this is an infinity-infinity indeterminant form which can be converted to a $0/0$ form. I tried substituting $x=1+h$ where $h\to0$. But it is not working. What should I do?,,['limits']
89,"If a function is continuous everywhere, but undefined at one point, is it still continuous?","If a function is continuous everywhere, but undefined at one point, is it still continuous?",,"This is a question regarding the definition of continuity. My understanding of continuity is that a function is continuous at a point when it holds that $$\lim_{x\to a^-}f(x) = f(a) = \lim_{x\to a^+}f(x) \quad \quad (1)$$ The book I'm currently reading has this image: Note here that $f(x)$ is defined for $x=3$ , but $g(x)$ is not. This is followed by text stating that g(x) is continuous because $D_g = [0, 6]\text{\\}\{3\}$ , thus it is continuous for all values in its domain. My point of contention here is that, how can we say that it is continuous at $x=3$ when $g(3)$ does not exist? Referring to the aforementioned definition $(1)$ that the limits converge to the actual value at this point. I would have immediately declared both cases as jump discontinuities. Am I mistaken here? Does $g(x)$ illustrate an exception to $(1)$ ?","This is a question regarding the definition of continuity. My understanding of continuity is that a function is continuous at a point when it holds that The book I'm currently reading has this image: Note here that is defined for , but is not. This is followed by text stating that g(x) is continuous because , thus it is continuous for all values in its domain. My point of contention here is that, how can we say that it is continuous at when does not exist? Referring to the aforementioned definition that the limits converge to the actual value at this point. I would have immediately declared both cases as jump discontinuities. Am I mistaken here? Does illustrate an exception to ?","\lim_{x\to a^-}f(x) = f(a) = \lim_{x\to a^+}f(x) \quad \quad (1) f(x) x=3 g(x) D_g = [0, 6]\text{\\}\{3\} x=3 g(3) (1) g(x) (1)","['limits', 'continuity', 'piecewise-continuity']"
90,Limit of complex function,Limit of complex function,,Im trying to find the limit of: $$ \frac{\operatorname{Re}(z) \operatorname{Im}(z)}{z^2}$$ as z tends to zero.,Im trying to find the limit of: $$ \frac{\operatorname{Re}(z) \operatorname{Im}(z)}{z^2}$$ as z tends to zero.,,"['limits', 'complex-numbers']"
91,"Justify: if $x\gt 0$, $\;\lim_{n\to\infty} \sqrt{n}\cdot{\overbrace{\sin\sin\cdots\sin}^{n\space\text{sines}}(x)}=\sqrt{3}$","Justify: if ,",x\gt 0 \;\lim_{n\to\infty} \sqrt{n}\cdot{\overbrace{\sin\sin\cdots\sin}^{n\space\text{sines}}(x)}=\sqrt{3},"I believe that I have managed to show that (if $x\gt 0$) $$\lim_{n\to\infty} \sqrt{n}\cdot{\overbrace{\sin\sin\cdots\sin}^{n\space\text{sines}}(x)}=\sqrt{3}$$ I did this by defining a sequence as $a_0=x$ and the recursion $$a_{n+1}=\sin a_n$$ I then approximated the recursion with the first two nonzero terms of the Maclaurin series for sine, giving me $$\Delta a_n=-\frac{x^3}{6}$$ I then approximated this with a differential equation $$y'=-\frac{y^3}{6}$$ Which I then easily solved... the answer follows from here. Question: How can this be made more rigorous? I don't know how to justify that my approximations are good enough for th error to vanish under the limit. What theorems are generally used to justify approximations of discrete recursions with differential equations? I think I know how to justify the approximation of some with its Maclaurin series using the Lagrange error bound.","I believe that I have managed to show that (if $x\gt 0$) $$\lim_{n\to\infty} \sqrt{n}\cdot{\overbrace{\sin\sin\cdots\sin}^{n\space\text{sines}}(x)}=\sqrt{3}$$ I did this by defining a sequence as $a_0=x$ and the recursion $$a_{n+1}=\sin a_n$$ I then approximated the recursion with the first two nonzero terms of the Maclaurin series for sine, giving me $$\Delta a_n=-\frac{x^3}{6}$$ I then approximated this with a differential equation $$y'=-\frac{y^3}{6}$$ Which I then easily solved... the answer follows from here. Question: How can this be made more rigorous? I don't know how to justify that my approximations are good enough for th error to vanish under the limit. What theorems are generally used to justify approximations of discrete recursions with differential equations? I think I know how to justify the approximation of some with its Maclaurin series using the Lagrange error bound.",,"['limits', 'reference-request', 'recurrence-relations', 'approximation']"
92,Euler Limit of $\frac{x^x-x}{1-x+\ln(x)}$ Without L'Hopital,Euler Limit of  Without L'Hopital,\frac{x^x-x}{1-x+\ln(x)},"On slide $10$ here: http://math.cmu.edu/~bwsulliv/basel-problem.pdf , it is stated that Euler may have used L'Hopital's Rule to show that the limit $$\lim_{x\to 1}\dfrac{x^x-x}{1-x+\ln(x)}=-2$$ I was able to reproduce this easily with L'Hopital's Rule Upon two applications of it (shown at the bottom of this post). I've attempted and failed showing this limit using various methods including substitutions, Squeeze Theorem, splitting it up into $\dfrac{x^x}{1-x+\ln(x)}-\dfrac{x}{1-x+\ln(x)}$ (doesn't seem to work because it's just indeterminate), and series expansion representations (sort of). Substitutions tried and problems with them: Let $y=\ln(x)\implies x=e^y$ and $x^x=e^{ye^y}$, but I still get $\frac{0}{0}$ and couldn't find a way to transform it into a known limit. Let $y=x^x\implies \ln(y)=x\ln(x)$, but don't know how to solve for $x$ here in terms of $y$. Let $y=e^x\implies \ln(y)=x\implies x^x=(\ln(y))^{(\ln(y))}$. This limit did not seem to be easier. For Squeeze Theorem, I simply couldn't find suitable comparisons mostly since I could not remove the $\ln(x)$ in those comparisons. Even removing the $x^x$ doesn't seem like it would help since $\dfrac{x^x-x}{1-x+\ln(x)}$ is strictly less than $\dfrac{-x}{1-x+\ln(x)}$. So, even if the new limit went to $-2$, which it doesn't, we wouldn't have strictly shown the original limit to be $-2$. As for series expansions, I have no idea how to get a good series expansion of that (tried Taylor at $x=0,1,2$, but very messy and still gave $\frac{0}{0}$ and didn't give any hints). With L'Hopital $$\lim_{x\to 1}\dfrac{x^x-x}{1-x+\ln(x)}\to\dfrac{0}{0}\implies \lim_{x\to 1}\dfrac{x^x-x}{1-x+\ln(x)}=\lim_{x\to 1}\dfrac{x^x(\ln(x)+1)-1}{-1+\frac{1}{x}}=\dfrac{0}{0}$$ $$\implies \lim_{x\to 1}\dfrac{x^x(\ln(x)+1)-1}{-1+\frac{1}{x}}=\lim_{x\to 1}\dfrac{x^{x-1}+x^x(\ln(x)+1)\ln(x)+x^x(\ln(x)+1)}{-\frac{1}{x^2}}$$ $$=-(1^2)\cdot\left[1^{1-1}+1^1(\ln(1)+1)\ln(1)+1^1(\ln(1)+1)\right]=(-1)\cdot\left[1+0+1\right]=\boxed{-2}$$ I appreciate any helps or hints on changing this does to a bunch of known/simpler limits.","On slide $10$ here: http://math.cmu.edu/~bwsulliv/basel-problem.pdf , it is stated that Euler may have used L'Hopital's Rule to show that the limit $$\lim_{x\to 1}\dfrac{x^x-x}{1-x+\ln(x)}=-2$$ I was able to reproduce this easily with L'Hopital's Rule Upon two applications of it (shown at the bottom of this post). I've attempted and failed showing this limit using various methods including substitutions, Squeeze Theorem, splitting it up into $\dfrac{x^x}{1-x+\ln(x)}-\dfrac{x}{1-x+\ln(x)}$ (doesn't seem to work because it's just indeterminate), and series expansion representations (sort of). Substitutions tried and problems with them: Let $y=\ln(x)\implies x=e^y$ and $x^x=e^{ye^y}$, but I still get $\frac{0}{0}$ and couldn't find a way to transform it into a known limit. Let $y=x^x\implies \ln(y)=x\ln(x)$, but don't know how to solve for $x$ here in terms of $y$. Let $y=e^x\implies \ln(y)=x\implies x^x=(\ln(y))^{(\ln(y))}$. This limit did not seem to be easier. For Squeeze Theorem, I simply couldn't find suitable comparisons mostly since I could not remove the $\ln(x)$ in those comparisons. Even removing the $x^x$ doesn't seem like it would help since $\dfrac{x^x-x}{1-x+\ln(x)}$ is strictly less than $\dfrac{-x}{1-x+\ln(x)}$. So, even if the new limit went to $-2$, which it doesn't, we wouldn't have strictly shown the original limit to be $-2$. As for series expansions, I have no idea how to get a good series expansion of that (tried Taylor at $x=0,1,2$, but very messy and still gave $\frac{0}{0}$ and didn't give any hints). With L'Hopital $$\lim_{x\to 1}\dfrac{x^x-x}{1-x+\ln(x)}\to\dfrac{0}{0}\implies \lim_{x\to 1}\dfrac{x^x-x}{1-x+\ln(x)}=\lim_{x\to 1}\dfrac{x^x(\ln(x)+1)-1}{-1+\frac{1}{x}}=\dfrac{0}{0}$$ $$\implies \lim_{x\to 1}\dfrac{x^x(\ln(x)+1)-1}{-1+\frac{1}{x}}=\lim_{x\to 1}\dfrac{x^{x-1}+x^x(\ln(x)+1)\ln(x)+x^x(\ln(x)+1)}{-\frac{1}{x^2}}$$ $$=-(1^2)\cdot\left[1^{1-1}+1^1(\ln(1)+1)\ln(1)+1^1(\ln(1)+1)\right]=(-1)\cdot\left[1+0+1\right]=\boxed{-2}$$ I appreciate any helps or hints on changing this does to a bunch of known/simpler limits.",,"['limits', 'limits-without-lhopital']"
93,Is there a standard way to compute $\lim\limits_{n\to\infty}(\frac{n!}{n^n})^{1/n}$?,Is there a standard way to compute ?,\lim\limits_{n\to\infty}(\frac{n!}{n^n})^{1/n},"I'm computing the radii of convergence for some complex power series. For one I need to compute $$\lim_{n\to\infty}\left(\frac{n!}{n^n}\right)^{1/n}.$$ I know the answer is $\frac{1}{e}$, so the radius is $e$. But how could you compute this by hand? I tried taking the logarithms and raising $e$ by this logarithm, but it didn't lead me to the correct limit. (This is just practice, not homework.)","I'm computing the radii of convergence for some complex power series. For one I need to compute $$\lim_{n\to\infty}\left(\frac{n!}{n^n}\right)^{1/n}.$$ I know the answer is $\frac{1}{e}$, so the radius is $e$. But how could you compute this by hand? I tried taking the logarithms and raising $e$ by this logarithm, but it didn't lead me to the correct limit. (This is just practice, not homework.)",,['limits']
94,"Can any positive real be approximated as $2^m/3^n$ with $(m,n)$ large enough?",Can any positive real be approximated as  with  large enough?,"2^m/3^n (m,n)","Conjecture. There exist positive integers $(m,n)$ large enough, such that for any positive real number $r$ and a given error $\epsilon$ : $$    \left| r - \frac{2^m}{3^n} \right| < \epsilon $$ There is numerical evidence for this conjecture. I have tried $r = \sqrt{2}$ and $\epsilon = 10^{-3}$ . Below is a little Delphi Pascal program with accompanying output. But .. can somebody prove the conjecture? program apart; procedure test(r : double; eps : double); var   a : double;   m,n : integer; begin   a := 1;   m := 0; n := 0;   while true do   begin     if a < r then     begin       m := m + 1;       a := a * 2;     end else begin       n := n + 1;       a := a / 3;     end;     if abs(r-a) < eps then Break;   end;   Writeln(r,' = 2^',m,'/3^',n,' =',a); end; begin   test(sqrt(2),1.E-3); end. Output: 1.41421356237310E+0000 = 2^243/3^153 = 1.41493657935359E+0000 UPDATE. The answer by lhf does look like a very concise proof. But for me - as an retired physicist by education - it's a bit beyond comprehension. Furthermore, it leaves a few issues untouched. One might ask for example whether there are estimates for $m$ and $n$ when $r$ and $\epsilon$ are given. Note. The question can also be formulated as: Can any positive real be approximated as $3^m/2^n$ with $(m,n)$ large enough? Which is the same as allowing negative integers with the original formulation. In this form, it shows some resemblance to the (in)famous Collatz problem . EDIT. As suggested by the answers, an approach with logarithms could be more effective: program anders; procedure proef(r : double; eps : double); var   a,l2,l3,lr : double;   m,n : integer; begin   l2 := ln(2); l3 := ln(3);   lr := ln(r); a := 0;   m := 0; n := 0;   while true do   begin     a := m*l2 - n*l3 - lr;     if abs(a) < eps then Break;     if a < 0 then m := m + 1 else n := n + 1;   end;   Writeln(r,' = 2^',m,'/3^',n,' =',exp(a)*r); end; begin   proef(sqrt(2),1.E-3);   proef(sqrt(2),1.E-9); end. Output: 1.41421356237310E+0000 = 2^243/3^153 = 1.41493657935356E+0000  1.41421356237310E+0000 = 2^911485507/3^575083326 = 1.41421356125035E+0000 The first line in the output is almost identical to the result obtained previously . The last line in the output shows that the latter approach indeed is more effective. The error plays the same role in both approaches. Oh well, almost. Let's take a look at the places where the 'Break's are. First program: $$ \left| r - \frac{2^m}{3^n} \right| < \epsilon $$ Second program: $$ -\epsilon < m\ln(2) - n\ln(3) - \ln(r) < +\epsilon \\ \ln(1-\epsilon) < \ln\left(\frac{2^m/3^n}{r}\right) < \ln(1+\epsilon) \\ -\epsilon < \frac{2^m/3^n}{r} - 1 < +\epsilon \\ \left| r - \frac{2^m}{3^n} \right| < \epsilon.r $$ So $\epsilon$ in the first program is an absolute error, while $\epsilon$ in the second program is a relative error. Continuing story at: Can the Stern-Brocot tree be employed for better convergence of $2^m/3^n$ ?","Conjecture. There exist positive integers large enough, such that for any positive real number and a given error : There is numerical evidence for this conjecture. I have tried and . Below is a little Delphi Pascal program with accompanying output. But .. can somebody prove the conjecture? program apart; procedure test(r : double; eps : double); var   a : double;   m,n : integer; begin   a := 1;   m := 0; n := 0;   while true do   begin     if a < r then     begin       m := m + 1;       a := a * 2;     end else begin       n := n + 1;       a := a / 3;     end;     if abs(r-a) < eps then Break;   end;   Writeln(r,' = 2^',m,'/3^',n,' =',a); end; begin   test(sqrt(2),1.E-3); end. Output: 1.41421356237310E+0000 = 2^243/3^153 = 1.41493657935359E+0000 UPDATE. The answer by lhf does look like a very concise proof. But for me - as an retired physicist by education - it's a bit beyond comprehension. Furthermore, it leaves a few issues untouched. One might ask for example whether there are estimates for and when and are given. Note. The question can also be formulated as: Can any positive real be approximated as with large enough? Which is the same as allowing negative integers with the original formulation. In this form, it shows some resemblance to the (in)famous Collatz problem . EDIT. As suggested by the answers, an approach with logarithms could be more effective: program anders; procedure proef(r : double; eps : double); var   a,l2,l3,lr : double;   m,n : integer; begin   l2 := ln(2); l3 := ln(3);   lr := ln(r); a := 0;   m := 0; n := 0;   while true do   begin     a := m*l2 - n*l3 - lr;     if abs(a) < eps then Break;     if a < 0 then m := m + 1 else n := n + 1;   end;   Writeln(r,' = 2^',m,'/3^',n,' =',exp(a)*r); end; begin   proef(sqrt(2),1.E-3);   proef(sqrt(2),1.E-9); end. Output: 1.41421356237310E+0000 = 2^243/3^153 = 1.41493657935356E+0000  1.41421356237310E+0000 = 2^911485507/3^575083326 = 1.41421356125035E+0000 The first line in the output is almost identical to the result obtained previously . The last line in the output shows that the latter approach indeed is more effective. The error plays the same role in both approaches. Oh well, almost. Let's take a look at the places where the 'Break's are. First program: Second program: So in the first program is an absolute error, while in the second program is a relative error. Continuing story at: Can the Stern-Brocot tree be employed for better convergence of ?","(m,n) r \epsilon 
   \left| r - \frac{2^m}{3^n} \right| < \epsilon
 r = \sqrt{2} \epsilon = 10^{-3} m n r \epsilon 3^m/2^n (m,n) 
\left| r - \frac{2^m}{3^n} \right| < \epsilon
 
-\epsilon < m\ln(2) - n\ln(3) - \ln(r) < +\epsilon \\
\ln(1-\epsilon) < \ln\left(\frac{2^m/3^n}{r}\right) < \ln(1+\epsilon) \\
-\epsilon < \frac{2^m/3^n}{r} - 1 < +\epsilon \\
\left| r - \frac{2^m}{3^n} \right| < \epsilon.r
 \epsilon \epsilon 2^m/3^n","['limits', 'irrational-numbers', 'rational-numbers']"
95,Doubt on limits evaluation.,Doubt on limits evaluation.,,Can anyone tell me what am I doing wrong here. The limit provided is$$\lim_{x \to 0}\dfrac{xe^x-\ln(1+x)}{x²}$$ Method 1 (using standard limits) $$= \ \ \ \  \dfrac{\displaystyle \lim_{x \to 0}\dfrac{xe^x}{x}-\lim_{x \to 0}\dfrac{\ln(1+x)}{x}}{\displaystyle \lim_{x \to 0}x}$$ $$= \ \ \ \  \dfrac{\displaystyle \lim_{x \to 0}e^x-\lim_{x \to 0} 1}{\displaystyle \lim_{x \to 0}x}$$ $$= \ \ \ \  \lim_{x \to 0} \dfrac{e^x-1}{x}$$ $$= \ \ \ \ 1$$ Method 2 (using  Maclaurin series ) $$\lim_{x \to 0}\dfrac{xe^x-\ln(1+x)}{x²}$$ $$= \ \ \ \ \dfrac{3}{2}$$ Even with L'Hopital rule I get $\dfrac{3}{2}$. Then what's wrong with method 1. Some limit's properties,Can anyone tell me what am I doing wrong here. The limit provided is$$\lim_{x \to 0}\dfrac{xe^x-\ln(1+x)}{x²}$$ Method 1 (using standard limits) $$= \ \ \ \  \dfrac{\displaystyle \lim_{x \to 0}\dfrac{xe^x}{x}-\lim_{x \to 0}\dfrac{\ln(1+x)}{x}}{\displaystyle \lim_{x \to 0}x}$$ $$= \ \ \ \  \dfrac{\displaystyle \lim_{x \to 0}e^x-\lim_{x \to 0} 1}{\displaystyle \lim_{x \to 0}x}$$ $$= \ \ \ \  \lim_{x \to 0} \dfrac{e^x-1}{x}$$ $$= \ \ \ \ 1$$ Method 2 (using  Maclaurin series ) $$\lim_{x \to 0}\dfrac{xe^x-\ln(1+x)}{x²}$$ $$= \ \ \ \ \dfrac{3}{2}$$ Even with L'Hopital rule I get $\dfrac{3}{2}$. Then what's wrong with method 1. Some limit's properties,,[]
96,Solving math captcha involving a limit and $\sin(1/x)$,Solving math captcha involving a limit and,\sin(1/x),"The other day, while I was accessing a Russian math enthusiast web site, I came across this captcha: Can you help me make sense of it, and enter that site?","The other day, while I was accessing a Russian math enthusiast web site, I came across this captcha: Can you help me make sense of it, and enter that site?",,"['limits', 'recreational-mathematics']"
97,Find $\lim_\limits{x\to -\infty}{\frac{\ln\left(1+3^x\right)}{\ln\left(1+2^x\right)}}$,Find,\lim_\limits{x\to -\infty}{\frac{\ln\left(1+3^x\right)}{\ln\left(1+2^x\right)}},Prove the following limit without using approximations and derivatives: $$\lim_\limits{x\to -\infty}{\frac{\ln\left(1+3^{x}\right)}{\ln\left(1+2^{x}\right)}}=0$$ I cannot think of any possible factorization or inequality (so that I could use the Squeeze Theorem) that doesn't use derivatives so as to find this limit. Any hint?,Prove the following limit without using approximations and derivatives: $$\lim_\limits{x\to -\infty}{\frac{\ln\left(1+3^{x}\right)}{\ln\left(1+2^{x}\right)}}=0$$ I cannot think of any possible factorization or inequality (so that I could use the Squeeze Theorem) that doesn't use derivatives so as to find this limit. Any hint?,,['limits']
98,Limit $\lim_{x\to 0} x^{x^x}$,Limit,\lim_{x\to 0} x^{x^x},"What is: $$\lim_{x→0} x^{x^x}$$ I'm getting 0 as an answer, but I also got infinity as an answer. How would one solve this?","What is: $$\lim_{x→0} x^{x^x}$$ I'm getting 0 as an answer, but I also got infinity as an answer. How would one solve this?",,['limits']
99,How to convert into a definite integral,How to convert into a definite integral,,Could you show me how to convert the following into a definite integral: $$\lim\limits_{n \to \infty} \sum_{k=1}^{3n} \frac{1}{n}\cos\left(\frac{k\pi}{n}\right)\sin\left(\frac{2k\pi}{n}\right)$$ Thank you!,Could you show me how to convert the following into a definite integral: $$\lim\limits_{n \to \infty} \sum_{k=1}^{3n} \frac{1}{n}\cos\left(\frac{k\pi}{n}\right)\sin\left(\frac{2k\pi}{n}\right)$$ Thank you!,,"['limits', 'definite-integrals']"
