,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Examples of (infinite dimensional) linear operators,Examples of (infinite dimensional) linear operators,,"I'm trying to familiarize myself with linear operators. In finite dimensions it is clear to me that they are matrices. No problem there. But then in infinite dimensions matters are not so clear to me. Of course the identity map is a linear operator. I also know that if the domain is a space of functions then the integration and differentiation operators are examples of linear operators. Furthermore I found the example of the shift operator (works on sequences and function spaces). But I feel that a few more examples would help me greatly in understanding linear operators better. Now other than the ones I mentioned what are examples of linear operators $T: X \to Y$ where $X,Y$ are infinite dimensional normed linear spaces?","I'm trying to familiarize myself with linear operators. In finite dimensions it is clear to me that they are matrices. No problem there. But then in infinite dimensions matters are not so clear to me. Of course the identity map is a linear operator. I also know that if the domain is a space of functions then the integration and differentiation operators are examples of linear operators. Furthermore I found the example of the shift operator (works on sequences and function spaces). But I feel that a few more examples would help me greatly in understanding linear operators better. Now other than the ones I mentioned what are examples of linear operators $T: X \to Y$ where $X,Y$ are infinite dimensional normed linear spaces?",,['functional-analysis']
1,When weak convergence implies moment convergence?,When weak convergence implies moment convergence?,,"Given a sequence $(\mu_n)_n$ of probability measures on $\mathbb R$ , which converges weakly to a probability measure $\mu$ , when do we have $$ \tag{1} \lim_{n}\int x^kd\mu_n(x)=\int x^k d\mu(x) \qquad \forall k\geq 0\;? $$ Is "" $\mu$ has compact support"" a sufficient condition? Note that $\mu_n$ converges to $\mu$ weakly if $$ \int \varphi d\mu_n \to \int \varphi d\mu$$ for all $\varphi$ which is continuous and has compact support. Note that $x^k$ are continuous but not of compact support, so (1) is not immediately obvious.","Given a sequence of probability measures on , which converges weakly to a probability measure , when do we have Is "" has compact support"" a sufficient condition? Note that converges to weakly if for all which is continuous and has compact support. Note that are continuous but not of compact support, so (1) is not immediately obvious.","(\mu_n)_n \mathbb R \mu 
\tag{1} \lim_{n}\int x^kd\mu_n(x)=\int x^k d\mu(x) \qquad \forall k\geq 0\;?
 \mu \mu_n \mu  \int \varphi d\mu_n \to \int \varphi d\mu \varphi x^k","['functional-analysis', 'probability-theory', 'measure-theory', 'weak-convergence']"
2,Compact operator whose range is not closed,Compact operator whose range is not closed,,"I am asked to find a compact operator (on a Hilbert space) whose range is not closed, but I am having trouble coming up with one. My guess is that you need to have some sequence in the range that converges to something outside the range, but this feels like it contradicts the definition of compactness. [Our definition of an operator being compact is that the closure of the image of the closed unit ball is sequentially compact.] Any pointers/suggestions would be appreciated. Thanks in advance!","I am asked to find a compact operator (on a Hilbert space) whose range is not closed, but I am having trouble coming up with one. My guess is that you need to have some sequence in the range that converges to something outside the range, but this feels like it contradicts the definition of compactness. [Our definition of an operator being compact is that the closure of the image of the closed unit ball is sequentially compact.] Any pointers/suggestions would be appreciated. Thanks in advance!",,"['functional-analysis', 'hilbert-spaces', 'compact-operators']"
3,Can the space of linear operators on a Hilbert space be made into a Hilbert space?,Can the space of linear operators on a Hilbert space be made into a Hilbert space?,,"Let $H$ be a Hilbert space, and $\mathcal L(H)$ be the space of linear operators on $H$ . Can we find an inner product on $\mathcal L(H)$ that induces an equivalent norm on $\mathcal L(H)$ , i.e., a norm that is equivalent to the operator norm? For finite-dimensional spaces, the Frobenius inner product answers the question in the affirmative. So any counter-examples necessarily is infinite-dimensional. I am aware of the negative result , that  there is no inner product that induces the operator norm if $\dim H\ge 2$ .","Let be a Hilbert space, and be the space of linear operators on . Can we find an inner product on that induces an equivalent norm on , i.e., a norm that is equivalent to the operator norm? For finite-dimensional spaces, the Frobenius inner product answers the question in the affirmative. So any counter-examples necessarily is infinite-dimensional. I am aware of the negative result , that  there is no inner product that induces the operator norm if .",H \mathcal L(H) H \mathcal L(H) \mathcal L(H) \dim H\ge 2,"['functional-analysis', 'operator-theory', 'hilbert-spaces']"
4,When $\|T(b)\|\le M\|b\|$ for each vector from a basis implies that $T$ is bounded?,When  for each vector from a basis implies that  is bounded?,\|T(b)\|\le M\|b\| T,"A linear operator $T\colon X\to Y$ between linear normed spaces is bounded if there exists a constant $M$ such that $$\|Tx\| \le M\|x\|\tag{*}$$ holds for every $x\in X$. Are there some situations when it is sufficient to verify that this condition is true for elements from some Hamel basis $B$? Is there characterization of normed spaces here validity of $(*)$ for some Hamel basis implies boundedness? Are there at least some sufficient conditions? Is situation easier in Banach spaces? Can we say something at least for $Y=\mathbb R, \mathbb C$? Or are there perhaps no pairs $(X,B)$ such that boundedness on $B$ implies boundedness on $X$? My feeling about this question is that this might be somehow related to the ""shape"" of the unit ball. But I guess that convexity of unit ball is probably not enough. This basically arose from a rather elementary discussion about a linear operator defined on $X=c_{00}$. (The space of sequences which have only finitely many non-zero terms with the sup norm. In this can write down an explicit basis $e^{(i)}=(0,0,\dots,0,1,0,\dots)$ and in the conversation I got an impression that the other person thinks that it suffices to verify $(*)$ for these vectors. I corrected them and said that we need to check this for each $x\in X$ - or at least for all elements of the unit ball - if we follow the definition they've learned. But I realized that the question whether this work at least sometimes might be quite complicated.) I searched a bit to see whether similar question has been posted here in the past. I only found this question, which deals with orthonormal basis rather than Hamel basis: Linear Operator bounded on a basis .","A linear operator $T\colon X\to Y$ between linear normed spaces is bounded if there exists a constant $M$ such that $$\|Tx\| \le M\|x\|\tag{*}$$ holds for every $x\in X$. Are there some situations when it is sufficient to verify that this condition is true for elements from some Hamel basis $B$? Is there characterization of normed spaces here validity of $(*)$ for some Hamel basis implies boundedness? Are there at least some sufficient conditions? Is situation easier in Banach spaces? Can we say something at least for $Y=\mathbb R, \mathbb C$? Or are there perhaps no pairs $(X,B)$ such that boundedness on $B$ implies boundedness on $X$? My feeling about this question is that this might be somehow related to the ""shape"" of the unit ball. But I guess that convexity of unit ball is probably not enough. This basically arose from a rather elementary discussion about a linear operator defined on $X=c_{00}$. (The space of sequences which have only finitely many non-zero terms with the sup norm. In this can write down an explicit basis $e^{(i)}=(0,0,\dots,0,1,0,\dots)$ and in the conversation I got an impression that the other person thinks that it suffices to verify $(*)$ for these vectors. I corrected them and said that we need to check this for each $x\in X$ - or at least for all elements of the unit ball - if we follow the definition they've learned. But I realized that the question whether this work at least sometimes might be quite complicated.) I searched a bit to see whether similar question has been posted here in the past. I only found this question, which deals with orthonormal basis rather than Hamel basis: Linear Operator bounded on a basis .",,['functional-analysis']
5,"Reason for the term ""smooth""","Reason for the term ""smooth""",,"A normed space $X$ is said to be smooth if for $x \in X$ with $||x||=1$ there exists a unique bounded linear functional $f$ such that $||f||=1$ and $f(x)=||x||$ . Why the term ""smooth"" comes?","A normed space is said to be smooth if for with there exists a unique bounded linear functional such that and . Why the term ""smooth"" comes?",X x \in X ||x||=1 f ||f||=1 f(x)=||x||,"['functional-analysis', 'banach-spaces', 'normed-spaces']"
6,The convex hull of every open set is open,The convex hull of every open set is open,,"Let $X$ be a topological vector space. Prove that the convex hull of every open subset of $X$ is open. I tried using definition of Convex Hull and Open Set, but I couldn't prove the statement.","Let $X$ be a topological vector space. Prove that the convex hull of every open subset of $X$ is open. I tried using definition of Convex Hull and Open Set, but I couldn't prove the statement.",,"['functional-analysis', 'convex-analysis', 'topological-vector-spaces']"
7,Convergent sequence in Lp has a subsequence bounded by another Lp function,Convergent sequence in Lp has a subsequence bounded by another Lp function,,"For $E$ a measurable set and $1\leq p<\infty $, assume $f_n\to f$ in $L^p(E)$. Show that there is a subsequence $\{f_{n_k}\}$ and a function $g\in L^p(E)$ such that $|f_{n_k}|\leq g$ almost everywhere on $E$ for all $k$. By convergence in $L^p(E)$, I mean that $\|f_n-f\|_p\to 0$. I know that a convergent sequence in $L^p$ has a subsequence that converges pointwise a.e. to $f$ on $E$. Since $f\in L^p(E)$, it must be finite almost everywhere. I would like to define $g$ to be the pointwise supremum of the $f_{n_k}$, but there is no guarantee that this supremum is finite almost everywhere. How can I construct $g$ to bound this subsequence above pointwise?","For $E$ a measurable set and $1\leq p<\infty $, assume $f_n\to f$ in $L^p(E)$. Show that there is a subsequence $\{f_{n_k}\}$ and a function $g\in L^p(E)$ such that $|f_{n_k}|\leq g$ almost everywhere on $E$ for all $k$. By convergence in $L^p(E)$, I mean that $\|f_n-f\|_p\to 0$. I know that a convergent sequence in $L^p$ has a subsequence that converges pointwise a.e. to $f$ on $E$. Since $f\in L^p(E)$, it must be finite almost everywhere. I would like to define $g$ to be the pointwise supremum of the $f_{n_k}$, but there is no guarantee that this supremum is finite almost everywhere. How can I construct $g$ to bound this subsequence above pointwise?",,['functional-analysis']
8,Hahn Banach Theorem,Hahn Banach Theorem,,"It is stated often that the Hahn Banach Theorem makes the study of the dual space ""interesting"". What does this exactly mean though? I.e what is exactly meant by ""interesting""? I am puzzled as to why it follows immediately from Hahn-Banach that the dual of a (non-zero) normed vector space is non-trivial. How does it follow DIRECTLY from Hahn Banach that there are non-trivial functions?","It is stated often that the Hahn Banach Theorem makes the study of the dual space ""interesting"". What does this exactly mean though? I.e what is exactly meant by ""interesting""? I am puzzled as to why it follows immediately from Hahn-Banach that the dual of a (non-zero) normed vector space is non-trivial. How does it follow DIRECTLY from Hahn Banach that there are non-trivial functions?",,[]
9,Is $L^2(\mathbb R)$ isometrically isomorphic with $\ell^2(\mathbb Z)?$,Is  isometrically isomorphic with,L^2(\mathbb R) \ell^2(\mathbb Z)?,"Is $L^2(\mathbb R)$ isometrically isomorphic with $\ell^2(\mathbb Z)?$ My thoughts: We can define an operator $\mathcal L:L^2(\mathbb R)\rightarrow \ell^2(\mathbb Z)$ : $\mathcal Lf=\{\hat f(ξ)\}_{ξ\in \mathbb Z}$ (obviously $\mathcal L$ is linear & $1-1$ by uniqueness) and  by the Parseval identity we have that $\lVert f\rVert_{L^2(\mathbb R)}^2=\lVert \hat f\rVert_{\ell^2(\mathbb Z)}^2$ Hence we have an isometry. is that enough? Also, can we claim that $:L^2(\mathbb R)≅ \ell^2(\mathbb Z)?$ Thanks you. EDIT: how about $L^2([a,b])?$","Is isometrically isomorphic with My thoughts: We can define an operator : (obviously is linear & by uniqueness) and  by the Parseval identity we have that Hence we have an isometry. is that enough? Also, can we claim that Thanks you. EDIT: how about","L^2(\mathbb R) \ell^2(\mathbb Z)? \mathcal L:L^2(\mathbb R)\rightarrow \ell^2(\mathbb Z) \mathcal Lf=\{\hat f(ξ)\}_{ξ\in \mathbb Z} \mathcal L 1-1 \lVert f\rVert_{L^2(\mathbb R)}^2=\lVert \hat f\rVert_{\ell^2(\mathbb Z)}^2 :L^2(\mathbb R)≅ \ell^2(\mathbb Z)? L^2([a,b])?","['functional-analysis', 'fourier-analysis', 'operator-theory', 'harmonic-analysis']"
10,Using Functional Analysis for Differential Equations,Using Functional Analysis for Differential Equations,,"In the functional analysis books that I have read, they do not explain how the ideas and theorems of functional analysis (in the sense of operators on Banach spaces) help to deal with differential equations, such as proving existence or uniqueness of solutions. Could someone give me an example of using the ideas and theorems of functional analysis to actually say something about a (partial) differential equation?","In the functional analysis books that I have read, they do not explain how the ideas and theorems of functional analysis (in the sense of operators on Banach spaces) help to deal with differential equations, such as proving existence or uniqueness of solutions. Could someone give me an example of using the ideas and theorems of functional analysis to actually say something about a (partial) differential equation?",,"['functional-analysis', 'analysis', 'partial-differential-equations', 'numerical-methods']"
11,Counterexample around Dini's Theorem,Counterexample around Dini's Theorem,,"""Give an example of an increasing sequence $(f_n)$ of bounded continuous functions from $(0,1]$ to $\mathbb{R}$ which converge pointwise but not uniformly to a bounded continuous function $f$ and explain why Dini's Theorem does not apply in this case"" So clearly Dini's Theorem does not apply, as $(0,1]$ is not a closed interval (or compact metric space), but I can't figure out an example. My first thought is $f_n(x)=\frac{1}{x^n}$ , but this does not converge pointwise to a bounded continuous function, as $x=1$ is in the interval My second thought is $f_n(x)=x^\frac{1}{n}$ . This is clearly an increasing sequence of bounded continuous functions (I think?) I believe this converges pointwise to $f(x)=1$ for all $x\in (0,1]$ , but I'm struggling to then show why this doesn't converge uniformly to $f(x)=1$ How would I do this? Or is then an easier/better example I could use?","""Give an example of an increasing sequence of bounded continuous functions from to which converge pointwise but not uniformly to a bounded continuous function and explain why Dini's Theorem does not apply in this case"" So clearly Dini's Theorem does not apply, as is not a closed interval (or compact metric space), but I can't figure out an example. My first thought is , but this does not converge pointwise to a bounded continuous function, as is in the interval My second thought is . This is clearly an increasing sequence of bounded continuous functions (I think?) I believe this converges pointwise to for all , but I'm struggling to then show why this doesn't converge uniformly to How would I do this? Or is then an easier/better example I could use?","(f_n) (0,1] \mathbb{R} f (0,1] f_n(x)=\frac{1}{x^n} x=1 f_n(x)=x^\frac{1}{n} f(x)=1 x\in (0,1] f(x)=1","['functional-analysis', 'metric-spaces', 'uniform-convergence', 'pointwise-convergence']"
12,"If $T:L^p[0,1] \to L^p[0,1]$ bounded for $1 < p < \infty$ with continuous image, then it's compact","If  bounded for  with continuous image, then it's compact","T:L^p[0,1] \to L^p[0,1] 1 < p < \infty","Is the following statement true? Let $T:L^p[0,1] \to L^p[0,1]$ be a bounded operator for $1 < p < \infty$ and suppose that $\operatorname{Im}(T) \subset C[0,1]$ consists of continuous functions. Then $T$ is compact. I have tried to prove it by using the reflexivity of $X=L^p[0,1]$ : Given $f_n \in X$ a bounded sequence, $Tf_n$ is also bounded, and thus by weak compactness, there exists $g \in L^p[0,1]$ such that $Tf_n \overset{w}{\to}g$ (denoting the subsequence again by $Tf_n$ ). One can show that actually $g = Tf$ for some $f \in X$ (by the fact that $TB_X$ is closed and convex and thus weakly closed) and thus $T(f_n - f) \overset{w}{\to}0$ . I am stuck here and can't seem to understand how by continuity of $T(f_n - f)$ we can conclude strong convergence. Maybe this approach is not fruitful, or the statement is just false. Any leads are appreciated.","Is the following statement true? Let be a bounded operator for and suppose that consists of continuous functions. Then is compact. I have tried to prove it by using the reflexivity of : Given a bounded sequence, is also bounded, and thus by weak compactness, there exists such that (denoting the subsequence again by ). One can show that actually for some (by the fact that is closed and convex and thus weakly closed) and thus . I am stuck here and can't seem to understand how by continuity of we can conclude strong convergence. Maybe this approach is not fruitful, or the statement is just false. Any leads are appreciated.","T:L^p[0,1] \to L^p[0,1] 1 < p < \infty \operatorname{Im}(T) \subset C[0,1] T X=L^p[0,1] f_n \in X Tf_n g \in L^p[0,1] Tf_n \overset{w}{\to}g Tf_n g = Tf f \in X TB_X T(f_n - f) \overset{w}{\to}0 T(f_n - f)","['functional-analysis', 'operator-theory', 'banach-spaces', 'lp-spaces', 'compact-operators']"
13,Graphical explanation of Riesz's lemma,Graphical explanation of Riesz's lemma,,Does there exist an intuitive graphical explanation of Riesz's lemma?,Does there exist an intuitive graphical explanation of Riesz's lemma?,,['functional-analysis']
14,$T$ is surjective if and only if the adjoint $T^*$ is an isomorphism (onto its image),is surjective if and only if the adjoint  is an isomorphism (onto its image),T T^*,"I am trying to prove the following statements:  Let $X$ and $Y$ be normed spaces (not necessarily complete) Let $T\in L(X,Y)$  (meaning $T:X\to Y$ is a bounded linear map). Let $T^*:Y^*\to X^*$ denote the adjoint operator. Then: $T^*$ is sujective if and only if $T$ is an isomorphism; $T$ is surjective if and only of $T^*$ is an isomorphism. Here an ""isomorphism"" $X\to Y$ is an injective linear operator $T:X\to Y$ such that there exists $c_1,c_2>0$ with $$c_1\|x\|\leq \|Tx\|\leq c_2\|x\| \text{ for all } x\in X.$$ In particular we do not require $T$ to be surjective. Discussion I have proved statement 1. and I have also proved that if $T^*$ is an isomorphism then $T$ is surjective, and that if $T$ is surjective then $T^*$ is injective. An ideal next step would be to show that $Image(T^*)$ is closed in $X^*$, at which point I could apply the open mapping theorem to conclude that $T^*$ is an isomorphism (since I already know $T^*$ is a bounded operator). However, I am struggling to show that the image of $T^*$ is closed. Any ideas would be appreciated.","I am trying to prove the following statements:  Let $X$ and $Y$ be normed spaces (not necessarily complete) Let $T\in L(X,Y)$  (meaning $T:X\to Y$ is a bounded linear map). Let $T^*:Y^*\to X^*$ denote the adjoint operator. Then: $T^*$ is sujective if and only if $T$ is an isomorphism; $T$ is surjective if and only of $T^*$ is an isomorphism. Here an ""isomorphism"" $X\to Y$ is an injective linear operator $T:X\to Y$ such that there exists $c_1,c_2>0$ with $$c_1\|x\|\leq \|Tx\|\leq c_2\|x\| \text{ for all } x\in X.$$ In particular we do not require $T$ to be surjective. Discussion I have proved statement 1. and I have also proved that if $T^*$ is an isomorphism then $T$ is surjective, and that if $T$ is surjective then $T^*$ is injective. An ideal next step would be to show that $Image(T^*)$ is closed in $X^*$, at which point I could apply the open mapping theorem to conclude that $T^*$ is an isomorphism (since I already know $T^*$ is a bounded operator). However, I am struggling to show that the image of $T^*$ is closed. Any ideas would be appreciated.",,"['functional-analysis', 'normed-spaces', 'adjoint-operators']"
15,If all $L^p$ norms are bounded then the $L^\infty$ is bounded,If all  norms are bounded then the  is bounded,L^p L^\infty,Suppose that $||f||_p \le K$ for all $1 \le p <\infty$ for some $K>0$. How to show that the essential supremum exists and bounded by $K$ that i s$||f||_\infty \le K$? I know how to prove that if $f \in L^\infty$ then  \begin{align} lim_{p \to \infty} ||f||_p=||f||_\infty \end{align} but this already assume that $f \in L^\infty$ in this question we have to show that $f$ has an essential supremum. To be more precise I don't think I can use a technique when I define \begin{align} A_\epsilon =\{ x | \ |f(x)|>||f||_{\infty}-\epsilon \} \end{align} I feel like here we have to use some converges theorem. Thanks for any help,Suppose that $||f||_p \le K$ for all $1 \le p <\infty$ for some $K>0$. How to show that the essential supremum exists and bounded by $K$ that i s$||f||_\infty \le K$? I know how to prove that if $f \in L^\infty$ then  \begin{align} lim_{p \to \infty} ||f||_p=||f||_\infty \end{align} but this already assume that $f \in L^\infty$ in this question we have to show that $f$ has an essential supremum. To be more precise I don't think I can use a technique when I define \begin{align} A_\epsilon =\{ x | \ |f(x)|>||f||_{\infty}-\epsilon \} \end{align} I feel like here we have to use some converges theorem. Thanks for any help,,"['functional-analysis', 'lp-spaces']"
16,"How are $C^0,C^1$ norms defined",How are  norms defined,"C^0,C^1","How are $C^0,C^1$ norms defined? I know $L_p,L_\infty$ norms but are the former defined.","How are $C^0,C^1$ norms defined? I know $L_p,L_\infty$ norms but are the former defined.",,"['functional-analysis', 'normed-spaces']"
17,Questions about Bochner integral,Questions about Bochner integral,,"I was wondering If there is distinction between existence of Bochner integral and Bochner integrability , or the two always mean the same? If in Bochner integral, the integrand is assumed to be measurable wrt the Borel $\sigma$-algebra of the codomain Banach space? if differentiation under integral sign is still true for Bochner integral ? What is the condition for that to be true? What kinds of derivatives are involved above, Fréchet derivative, the Gâteaux derivative, or something else? For example,  $\frac{d}{dt} \int_a^t     f(t) g(x,t) dt$, where $f: \mathbb{R} \rightarrow \mathbb{R}$, $g: B \times     \mathbb{R} \rightarrow \mathbb{R}$, $B$ is a Banach space, and the Bochner integral exists. Thanks and regards! Also are there some nice references?","I was wondering If there is distinction between existence of Bochner integral and Bochner integrability , or the two always mean the same? If in Bochner integral, the integrand is assumed to be measurable wrt the Borel $\sigma$-algebra of the codomain Banach space? if differentiation under integral sign is still true for Bochner integral ? What is the condition for that to be true? What kinds of derivatives are involved above, Fréchet derivative, the Gâteaux derivative, or something else? For example,  $\frac{d}{dt} \int_a^t     f(t) g(x,t) dt$, where $f: \mathbb{R} \rightarrow \mathbb{R}$, $g: B \times     \mathbb{R} \rightarrow \mathbb{R}$, $B$ is a Banach space, and the Bochner integral exists. Thanks and regards! Also are there some nice references?",,['functional-analysis']
18,"How to prove that $(u-v)^+\in W_0^{1,2}(\Omega)$, if $u\in W_0^{1,2}(\Omega)$, $v\geq 0$.","How to prove that , if , .","(u-v)^+\in W_0^{1,2}(\Omega) u\in W_0^{1,2}(\Omega) v\geq 0","Let $\Omega$ denote a open subset of $\mathbb{R}^n$, and $W^{1,p}(\Omega)$ the Sobolev space of weakly differentiable functions $u\in L^p(\Omega)$ (that is, for which $D_iu$ exists and belongs to $L^p(\Omega)$ as well, for every $i\in\left\{1,\ldots,n\right\}$). I'm studying boundary regularity of a solution of the Dirichlet problem for the circle $D\subseteq\mathbb{R}^2$, and the weak maximum principle is needed. For that, we need to give a proper meaning for $u\leq v$ in $\partial\Omega$ (the boundary of $\Omega$), where $u,v\in W^{1,2}(\Omega)$. The definition is: $u\leq v$ in $\partial\Omega$ iff $(u-v)^+\in W_0^{1,2}(\Omega)$, where: $w^+=\max(w,0)$ denotes the positive part of $w$; and $W_0^{1,2}(\Omega)$ is the closure (in Sobolev norm) of $C_0^\infty(\Omega)=\left\{w\in C^\infty(\Omega):\text{supp}(w)\text{ is compact}\right\}$ Now, a lot of statements relating to that concept need the following lemma (or something similar), which I'm unable to prove: Lemma : Let $u\in W_0^{1,2}(\Omega)$, $v\in W^{1,2}(\Omega)$ such that $v\geq 0$ pointwise. Show that $(u-v)^+\in W_0^{1,2}(\Omega)$. Intuitively, that should be true. If we think of continuous functions $u$ and $v$ such that $u\in C_0(\Omega)$, then $(u-v)^+\in C_0(\Omega)$, since $|(u-v)^+|\leq|u|$ (where $C_0(\Omega)$ denotes the set o compactly supported continuous functions from $\Omega$ to $\mathbb{R}$). Using mollifiers, it's easy to see that $C_0(\Omega)\subseteq W_0^{1,2}(\Omega)$, and the lemma is true in that case. I tried to give the following proof: The case $u\in C_0^\infty(\Omega)$ is easy enough. Now, let $\left\{u_n\right\}_{n\in\mathbb{N}}\subseteq C_0^\infty(\Omega)$ be a sequence converging in $W^{1,2}(\Omega)$ to $u$. Taking subsequences if necessary, I tried making pointwise convergence (almost everywhere in $\Omega$) of $(u_n-v)^+$ and $D_i(u_n-v)^+$ to $(u-v)^+$ and $D_i(u-v)^+$, respectively, so I'd apply Lebesgue's Dominated Convergence Theorem, and conclude convergence in $W^{1,2}(\Omega)$, hence proving the lemma. The problem is exactly with the derivatives: Since $Dw^+(x)=0$ if $w(x)\leq 0$ and $Dw^+(x)=Dw(x)$ if $w(x)>0$ ($\forall w\in W^{1,2}(\Omega)$: this follows from the weak chain rule), we cannot garantee pointwise convergence if $u(x)=v(x)$. Any idea would be of great value. Even if one must assume $\Omega$ bounded and/or $v\in C^\infty(\Omega)\cap C^0(\overline{\Omega})$, it would suffice for what I need. Thank you in advance.","Let $\Omega$ denote a open subset of $\mathbb{R}^n$, and $W^{1,p}(\Omega)$ the Sobolev space of weakly differentiable functions $u\in L^p(\Omega)$ (that is, for which $D_iu$ exists and belongs to $L^p(\Omega)$ as well, for every $i\in\left\{1,\ldots,n\right\}$). I'm studying boundary regularity of a solution of the Dirichlet problem for the circle $D\subseteq\mathbb{R}^2$, and the weak maximum principle is needed. For that, we need to give a proper meaning for $u\leq v$ in $\partial\Omega$ (the boundary of $\Omega$), where $u,v\in W^{1,2}(\Omega)$. The definition is: $u\leq v$ in $\partial\Omega$ iff $(u-v)^+\in W_0^{1,2}(\Omega)$, where: $w^+=\max(w,0)$ denotes the positive part of $w$; and $W_0^{1,2}(\Omega)$ is the closure (in Sobolev norm) of $C_0^\infty(\Omega)=\left\{w\in C^\infty(\Omega):\text{supp}(w)\text{ is compact}\right\}$ Now, a lot of statements relating to that concept need the following lemma (or something similar), which I'm unable to prove: Lemma : Let $u\in W_0^{1,2}(\Omega)$, $v\in W^{1,2}(\Omega)$ such that $v\geq 0$ pointwise. Show that $(u-v)^+\in W_0^{1,2}(\Omega)$. Intuitively, that should be true. If we think of continuous functions $u$ and $v$ such that $u\in C_0(\Omega)$, then $(u-v)^+\in C_0(\Omega)$, since $|(u-v)^+|\leq|u|$ (where $C_0(\Omega)$ denotes the set o compactly supported continuous functions from $\Omega$ to $\mathbb{R}$). Using mollifiers, it's easy to see that $C_0(\Omega)\subseteq W_0^{1,2}(\Omega)$, and the lemma is true in that case. I tried to give the following proof: The case $u\in C_0^\infty(\Omega)$ is easy enough. Now, let $\left\{u_n\right\}_{n\in\mathbb{N}}\subseteq C_0^\infty(\Omega)$ be a sequence converging in $W^{1,2}(\Omega)$ to $u$. Taking subsequences if necessary, I tried making pointwise convergence (almost everywhere in $\Omega$) of $(u_n-v)^+$ and $D_i(u_n-v)^+$ to $(u-v)^+$ and $D_i(u-v)^+$, respectively, so I'd apply Lebesgue's Dominated Convergence Theorem, and conclude convergence in $W^{1,2}(\Omega)$, hence proving the lemma. The problem is exactly with the derivatives: Since $Dw^+(x)=0$ if $w(x)\leq 0$ and $Dw^+(x)=Dw(x)$ if $w(x)>0$ ($\forall w\in W^{1,2}(\Omega)$: this follows from the weak chain rule), we cannot garantee pointwise convergence if $u(x)=v(x)$. Any idea would be of great value. Even if one must assume $\Omega$ bounded and/or $v\in C^\infty(\Omega)\cap C^0(\overline{\Omega})$, it would suffice for what I need. Thank you in advance.",,"['functional-analysis', 'sobolev-spaces']"
19,Banach-Saks property and reflexivity,Banach-Saks property and reflexivity,,"On the German Wikipedia page on the Banach-Saks property , they claim that every Banach space with the Banach-Saks property is reflexive but that the converse is not true. There should be a proof due to T. Nishiura and D. Waterman, but unfortunately, I can't find a proof of this interesting statement. It would be appreciated if someone could give me an online available reference (if possible). Unfortunately, my library at the university doesn't have a copy. Thx for your help math","On the German Wikipedia page on the Banach-Saks property , they claim that every Banach space with the Banach-Saks property is reflexive but that the converse is not true. There should be a proof due to T. Nishiura and D. Waterman, but unfortunately, I can't find a proof of this interesting statement. It would be appreciated if someone could give me an online available reference (if possible). Unfortunately, my library at the university doesn't have a copy. Thx for your help math",,"['reference-request', 'functional-analysis', 'banach-spaces']"
20,Existence and uniqueness of projections on closed convex sets,Existence and uniqueness of projections on closed convex sets,,"Let $X$ be a normed vector space. I'm interested in determining what are the minimal assumptions on $X$ that guarantee the existence and uniqueness of projections on closed convex sets and in counterexamples showing that those assumptions are indeed necessary. In particular let P1 and P2 be the following statements P1: (existence) for every convex closed set $C\subseteq X$ and every $x\in X$ there exist $y\in C$ with $\|x-y\|=d(x,C)$ . P2: (uniqueness) for every convex closed set $C\subseteq X$ and every $x\in X$ there exist a unique $y\in C$ with $\|x-y\|=d(x,C)$ . What I know so far is that P2 holds in all uniformly convex Banach spaces, while to get P1 is enough to assume that $X$ is a reflexive Banach space, but I don't have an example of a reflexive Banach space not satisfying P2 and I don't know if those assumptions can be further weakened.","Let be a normed vector space. I'm interested in determining what are the minimal assumptions on that guarantee the existence and uniqueness of projections on closed convex sets and in counterexamples showing that those assumptions are indeed necessary. In particular let P1 and P2 be the following statements P1: (existence) for every convex closed set and every there exist with . P2: (uniqueness) for every convex closed set and every there exist a unique with . What I know so far is that P2 holds in all uniformly convex Banach spaces, while to get P1 is enough to assume that is a reflexive Banach space, but I don't have an example of a reflexive Banach space not satisfying P2 and I don't know if those assumptions can be further weakened.","X X C\subseteq X x\in X y\in C \|x-y\|=d(x,C) C\subseteq X x\in X y\in C \|x-y\|=d(x,C) X","['functional-analysis', 'convex-analysis', 'normed-spaces']"
21,The intuition of the dual space?,The intuition of the dual space?,,"The dual space of X is defined to be the space of all linear and continuous functionals that map X to R. But, What exactly is a dual space intuitively? In my current self-guided understanding, I think of a space of function as a set of points( or a region) in infinite dimensional space $\mathbb R^\infty$. Let $f(x)$ be a element of a space of functions $X$, can I think of each value $f(x)$ as the magnitude in the dimension $x$? If my assumption above is correct, then what does  it mean  to have a space consists of functionals?  Functionals take a function as input and spit out a scalar, right? There are many functionals that involve differentiation and are not continuous. These functionals in no sense correspond to any functions, right? Since all linear functionals that are bounded are also continuous, can I say that the only class of functionals that is linear and continuous is simple convolution with certain bounded function g(x)?  Namely, $\int f(x)g(x)dx$?  And so, all g(x) that make the integral mapping continuous are the elements of the dual space? This is the best explanation I can come up with so far. If all my assumptions are incorrect, can someone explain to me what it means to have a space which consists of functionals?","The dual space of X is defined to be the space of all linear and continuous functionals that map X to R. But, What exactly is a dual space intuitively? In my current self-guided understanding, I think of a space of function as a set of points( or a region) in infinite dimensional space $\mathbb R^\infty$. Let $f(x)$ be a element of a space of functions $X$, can I think of each value $f(x)$ as the magnitude in the dimension $x$? If my assumption above is correct, then what does  it mean  to have a space consists of functionals?  Functionals take a function as input and spit out a scalar, right? There are many functionals that involve differentiation and are not continuous. These functionals in no sense correspond to any functions, right? Since all linear functionals that are bounded are also continuous, can I say that the only class of functionals that is linear and continuous is simple convolution with certain bounded function g(x)?  Namely, $\int f(x)g(x)dx$?  And so, all g(x) that make the integral mapping continuous are the elements of the dual space? This is the best explanation I can come up with so far. If all my assumptions are incorrect, can someone explain to me what it means to have a space which consists of functionals?",,['functional-analysis']
22,"Do we adopt the term ""normed space"" which is over any ordered-field?","Do we adopt the term ""normed space"" which is over any ordered-field?",,"The definition of normed vector spaces , as far as I know, is only defined for vector space over $\Bbb R$ or $\Bbb C$, like this one: However, it seems no harm to talk about whether a vector space over a general ordered field forms a normed space. So do we adopt such situation? If not, why?","The definition of normed vector spaces , as far as I know, is only defined for vector space over $\Bbb R$ or $\Bbb C$, like this one: However, it seems no harm to talk about whether a vector space over a general ordered field forms a normed space. So do we adopt such situation? If not, why?",,"['functional-analysis', 'normed-spaces']"
23,"If $x, y \in X$ with $x \neq y$, then there exists $f \in X^*$ such that $f(x) \neq f(y)$.","If  with , then there exists  such that .","x, y \in X x \neq y f \in X^* f(x) \neq f(y)","Let $X$ be a normed linear space. Prove that if $x, y \in X$ with $x \neq y$, then there exists $f \in X^*$ such that $f(x) \neq f(y)$. Here $X^*$ denotes the dual space of $X$. I am getting some smell of using Hahn Banach theorem but not able to prove it. Need some hints.","Let $X$ be a normed linear space. Prove that if $x, y \in X$ with $x \neq y$, then there exists $f \in X^*$ such that $f(x) \neq f(y)$. Here $X^*$ denotes the dual space of $X$. I am getting some smell of using Hahn Banach theorem but not able to prove it. Need some hints.",,"['functional-analysis', 'normed-spaces']"
24,Spectrum of left shift operator: take two,Spectrum of left shift operator: take two,,"This is my second attempt at calculating the spectrum of the left shift operator on a Hilbert space. I got stuck again and I would be grateful if someone could help. (You can find my previous (failed) attempt here ). Let $H$ be a Hilbert space with orthonormal base $e_i$ and let $L\in B(H)$ be the left shift operator, that is, $L(e_i) = e_{i-1}$. In the following I will assume that if there exists a sequence $x_n\in H$ with $\|x_n\|=1$ and $Tx_n \to 0$ then $T$ is not invertible. First note that $L$ is not invertible hence $0 \in \sigma (L)$. Let $\lambda \in \mathbb C$ be non-zero. I am stuck trying to find $x_n$ with $\|x_n\|=1$ and $(T-\lambda I)x_n \to 0$. Edit After doing some calculations I think that $L - \lambda I$ is never invertible for any $\lambda \in \mathbb C$ but I can't find $x \neq 0$ such that $(L-\lambda I)x = 0$. Could someone help me find such $x$ please? I'm sure that $\sigma(L) = \mathbb C$.","This is my second attempt at calculating the spectrum of the left shift operator on a Hilbert space. I got stuck again and I would be grateful if someone could help. (You can find my previous (failed) attempt here ). Let $H$ be a Hilbert space with orthonormal base $e_i$ and let $L\in B(H)$ be the left shift operator, that is, $L(e_i) = e_{i-1}$. In the following I will assume that if there exists a sequence $x_n\in H$ with $\|x_n\|=1$ and $Tx_n \to 0$ then $T$ is not invertible. First note that $L$ is not invertible hence $0 \in \sigma (L)$. Let $\lambda \in \mathbb C$ be non-zero. I am stuck trying to find $x_n$ with $\|x_n\|=1$ and $(T-\lambda I)x_n \to 0$. Edit After doing some calculations I think that $L - \lambda I$ is never invertible for any $\lambda \in \mathbb C$ but I can't find $x \neq 0$ such that $(L-\lambda I)x = 0$. Could someone help me find such $x$ please? I'm sure that $\sigma(L) = \mathbb C$.",,['functional-analysis']
25,Is it sufficient to check weak convergence on a (weak* or strongly) dense subset of the dual?,Is it sufficient to check weak convergence on a (weak* or strongly) dense subset of the dual?,,"Let X be a Banach space. If $D \subset X^*$ is (weak*ly or strongly?) dense, then does $f(x_n) \to f(x)$ $\forall f \in D$ imply that $x_n \to x$ weakly? My thoughts: If $g_m \to g$ in the dual, then we can write: $|g(x) - g(x_n)| \leq |g(x) - g_m(x)| + |g_m(x) - g_m(x_n)| + |g_m(x_n) - g(x_n)|$, where the middle term always vanishes for a fixed $m$ as $n \to \infty$ by assumption, though this is a moving target. The first term will vanish as $m \to \infty$ in either the weak* topology or the strong topology on the dual, and the latter term vanishes if the dual topology was the strong topology and the sequence $x_n$ was bounded in norm.","Let X be a Banach space. If $D \subset X^*$ is (weak*ly or strongly?) dense, then does $f(x_n) \to f(x)$ $\forall f \in D$ imply that $x_n \to x$ weakly? My thoughts: If $g_m \to g$ in the dual, then we can write: $|g(x) - g(x_n)| \leq |g(x) - g_m(x)| + |g_m(x) - g_m(x_n)| + |g_m(x_n) - g(x_n)|$, where the middle term always vanishes for a fixed $m$ as $n \to \infty$ by assumption, though this is a moving target. The first term will vanish as $m \to \infty$ in either the weak* topology or the strong topology on the dual, and the latter term vanishes if the dual topology was the strong topology and the sequence $x_n$ was bounded in norm.",,"['functional-analysis', 'banach-spaces']"
26,Showing that the norm of the canonical projection $X\to X/M$ is $1$,Showing that the norm of the canonical projection  is,X\to X/M 1,"How do I show that given $M$ a closed subspace of a normed space $X$, and let $\pi$ be the canonical projection of X onto $X/M$. Prove that $\|\pi\| = 1$. I figure I could use Riesz' lemma and set $\|\pi\| = 1$, that's as far as I got. I could also use the fact that the canonical map is a contraction so I would have $\|\pi(x)\| \leq \|x\| \Rightarrow \frac{\|\pi(x)\|}{\|x\|} \leq 1$ and taking a supremum then we get the desired result. This doesn't seem as rigorous.","How do I show that given $M$ a closed subspace of a normed space $X$, and let $\pi$ be the canonical projection of X onto $X/M$. Prove that $\|\pi\| = 1$. I figure I could use Riesz' lemma and set $\|\pi\| = 1$, that's as far as I got. I could also use the fact that the canonical map is a contraction so I would have $\|\pi(x)\| \leq \|x\| \Rightarrow \frac{\|\pi(x)\|}{\|x\|} \leq 1$ and taking a supremum then we get the desired result. This doesn't seem as rigorous.",,"['analysis', 'functional-analysis', 'normed-spaces']"
27,Question about sum of l'p spaces [duplicate],Question about sum of l'p spaces [duplicate],,"This question already has answers here : About the $p$ summable sequences (4 answers) Closed 10 years ago . Is this true or false: $$\bigcup_{1 \leq p < q} \ell^p = \ell^q?$$ I've tried to give an counter example, but I did not get any one.","This question already has answers here : About the $p$ summable sequences (4 answers) Closed 10 years ago . Is this true or false: I've tried to give an counter example, but I did not get any one.",\bigcup_{1 \leq p < q} \ell^p = \ell^q?,"['functional-analysis', 'lp-spaces']"
28,How to endow topology on a finite dimensional topological vector space?,How to endow topology on a finite dimensional topological vector space?,,"This post may be coincide with some of the contents here . From Conway, A course in functional analysis , page 104. If $H$ is a finite dimensional vector space and $F_{1},F_{2}$ are two topologies on $H$, that makes $H$ into a TVS. Then $F_{1}=F_{2}$. I do not really know how to prove this because $H$ may not be normable if all its non-empty open sets are unbounded. If $H$ is normable, then a subtle argument showed any norm on a finite dimensional space is equivalent to each other, hence $F_{1}=F_{2}$. (See Conway page 69). But I do not really know what to do when $H$ is just a finite dimensional TVS with no additional structure given. Even in the one dimensional case, it seems to me that $H$ may have different topologies. However, I also do not know how to construct one which is continuous with respect to addition and multiplication but not coincide withthe usual topology (in one dimensional case).","This post may be coincide with some of the contents here . From Conway, A course in functional analysis , page 104. If $H$ is a finite dimensional vector space and $F_{1},F_{2}$ are two topologies on $H$, that makes $H$ into a TVS. Then $F_{1}=F_{2}$. I do not really know how to prove this because $H$ may not be normable if all its non-empty open sets are unbounded. If $H$ is normable, then a subtle argument showed any norm on a finite dimensional space is equivalent to each other, hence $F_{1}=F_{2}$. (See Conway page 69). But I do not really know what to do when $H$ is just a finite dimensional TVS with no additional structure given. Even in the one dimensional case, it seems to me that $H$ may have different topologies. However, I also do not know how to construct one which is continuous with respect to addition and multiplication but not coincide withthe usual topology (in one dimensional case).",,"['functional-analysis', 'topological-vector-spaces']"
29,Boundedness of a continuous linear functional on a topological vector space,Boundedness of a continuous linear functional on a topological vector space,,"Suppose: $X$ is topological vector space whose topology is defined by a countable family of separating semi-norms $\|\cdot\|_N$, $N\geq 0$. Suppose $\Lambda:X\to \mathbb{R}$ is a continuous linear functional. Question: Does it follow that there exists $N \geq 0$ and a constant $C <\infty$ such that  $$|\Lambda \phi| \leq C\|\phi\|_N \text{, for all } \phi \in X \text{ ?}$$ I find it a bit strange if the answer is yes, but if $X=C^\infty(K)$ is the space of smooth functions of compact support $K$, and $\Lambda$ is a distribution, then the answer is yes. I would like to understand why. I'd appreciate any help. Edit1: The answers suggest the statement is true, but I would like to get some intuition for why it should be so. Edit2:I am still looking for some more clarification or intuition on this problem. Maybe one of the experts here could have a look at it? The answer below gives the correct statement, but I don't see why it is true. I would really like to know why, and I think it should be an easy statement to prove for folks in functional analysis. Thank you.","Suppose: $X$ is topological vector space whose topology is defined by a countable family of separating semi-norms $\|\cdot\|_N$, $N\geq 0$. Suppose $\Lambda:X\to \mathbb{R}$ is a continuous linear functional. Question: Does it follow that there exists $N \geq 0$ and a constant $C <\infty$ such that  $$|\Lambda \phi| \leq C\|\phi\|_N \text{, for all } \phi \in X \text{ ?}$$ I find it a bit strange if the answer is yes, but if $X=C^\infty(K)$ is the space of smooth functions of compact support $K$, and $\Lambda$ is a distribution, then the answer is yes. I would like to understand why. I'd appreciate any help. Edit1: The answers suggest the statement is true, but I would like to get some intuition for why it should be so. Edit2:I am still looking for some more clarification or intuition on this problem. Maybe one of the experts here could have a look at it? The answer below gives the correct statement, but I don't see why it is true. I would really like to know why, and I think it should be an easy statement to prove for folks in functional analysis. Thank you.",,['functional-analysis']
30,Convergence of test-functions is not induced by any metric.,Convergence of test-functions is not induced by any metric.,,"By $\mathcal{D}(\mathbb{R})$ we denote linear space of smooth compactly supported functions. We say that $\{\varphi_n:n\in\mathbb{N}\}\subset\mathcal{D}(\mathbb{R})$ converges to $\varphi\in\mathcal{D}(\mathbb{R})$ if for all $k\in\mathbb{Z}_+$ the sequence $\{\varphi_n^{(k)}:n\in\mathbb{N}\}$ uniformly converges to $\varphi^{(k)}$. there exist a compact $K\subset \mathbb{R}$ such that $\mathrm{supp}(\varphi_n)\subset K$ for all $n\in\mathbb{N}$. Could you give me a hint to prove the following well known fact. There is no metric $d$ on $\mathcal{D}(\mathbb{R})$ such that convergence described above is equivalent to convergence in metric space $(\mathcal{D}(\mathbb{R}), d)$.","By $\mathcal{D}(\mathbb{R})$ we denote linear space of smooth compactly supported functions. We say that $\{\varphi_n:n\in\mathbb{N}\}\subset\mathcal{D}(\mathbb{R})$ converges to $\varphi\in\mathcal{D}(\mathbb{R})$ if for all $k\in\mathbb{Z}_+$ the sequence $\{\varphi_n^{(k)}:n\in\mathbb{N}\}$ uniformly converges to $\varphi^{(k)}$. there exist a compact $K\subset \mathbb{R}$ such that $\mathrm{supp}(\varphi_n)\subset K$ for all $n\in\mathbb{N}$. Could you give me a hint to prove the following well known fact. There is no metric $d$ on $\mathcal{D}(\mathbb{R})$ such that convergence described above is equivalent to convergence in metric space $(\mathcal{D}(\mathbb{R}), d)$.",,"['functional-analysis', 'distribution-theory']"
31,Strong convergence does not imply operator norm convergence,Strong convergence does not imply operator norm convergence,,"How do I construct a sequence of bounded linear transformations that converge strongly to the zero operator, but do not converge to the zero operator in the operator norm? Something strange must happen for certain elements of the Hilbert space, but what sort of thing should I be looking for? An example would be most helpful, thanks in advance!","How do I construct a sequence of bounded linear transformations that converge strongly to the zero operator, but do not converge to the zero operator in the operator norm? Something strange must happen for certain elements of the Hilbert space, but what sort of thing should I be looking for? An example would be most helpful, thanks in advance!",,['functional-analysis']
32,Please suggest a functional analysis book to refresh my knowledge,Please suggest a functional analysis book to refresh my knowledge,,"I would like to ask you to recommend me a good modern textbook on functional analysis to refresh what I already know. I am a computer science student and for the last two semesters we've been having a functional analysis course, but, big surprise, some months after I passed the exam I discovered my knowledge of the topic has considerably waned. My requirements for the book would be: Easy to read (the lecturer never dared to explain any of the topics to us, and we've been forced to do everything by ourselves. One thing I discovered about the lectures was that the material was presented in a very diverse way, topics sometimes were not connected to the neighbouring topics. Some theorems were brief definitions, some had EXTREMELY long proofs, while the idea of the proof was rather simple - i.e., the theorem about the completion of normed vector spaces. And he never gave us any intuitive examples of what these constructs could be like. So the material was unbalanced. I would especially like that the book has  intuitive explanations). Rather new (it is always bothersome to read books so old they are unaware of the existence of personal home computers. Most of the books we have here were published in the 1970s-80s, if not earlier, and they sometimes mention that some of the described problems could be solved on ЭВМ - an archaic Russian term for a computer. I think that the area of functional analysis is not one to be filled with computational examples, but nevertheless, maybe in the book they could illustrate some points with Mathematica or similar things). It may be for a complete beginner, or a bit higher level, but not a level such that the ordinary student would feel completely defeated on the second page :) The topics we learned are (by topics I mostly mean main definitions, some properties, some lemmas/theorems. We never went deeply into them): Measure and Lebesgue integral Introduction to set theory Measure, countable measure Outer measure, Lebesgue measure, measurable sets Measurable functions Stieltjes-Lebesgue measure (very very brief) Lebesgue integral Egorov theorem, Lebesgue theorem, Beppo Levi's lemma Normed spaces Vector spaces, definitions Norm Topology of normed spaces Banach spaces The application of contraction mappings to the solution of the Fredholm and Volterra integral equations Pre-Hilbert spaces Hilbert spaces Compact sets and Arzela-Ascoli theorem Linear operators Linear operators, definitions Bounded and continuous operators Invertible operators Closed operators Hahn-Banach theorem Compact operators The application of the theory of compact operators to the solution of second-order equations (Riesz-Schauder theory) Spectral analysis of linear operators Introduction to the spectral theory of linear operators. Hilbert-Schmidt theorem (both are brief) I tried to be specific and detailed in my request. Thank you in advance! Added later: I would like to thank you all for useful answers, thank you, guys, you are very helpful!","I would like to ask you to recommend me a good modern textbook on functional analysis to refresh what I already know. I am a computer science student and for the last two semesters we've been having a functional analysis course, but, big surprise, some months after I passed the exam I discovered my knowledge of the topic has considerably waned. My requirements for the book would be: Easy to read (the lecturer never dared to explain any of the topics to us, and we've been forced to do everything by ourselves. One thing I discovered about the lectures was that the material was presented in a very diverse way, topics sometimes were not connected to the neighbouring topics. Some theorems were brief definitions, some had EXTREMELY long proofs, while the idea of the proof was rather simple - i.e., the theorem about the completion of normed vector spaces. And he never gave us any intuitive examples of what these constructs could be like. So the material was unbalanced. I would especially like that the book has  intuitive explanations). Rather new (it is always bothersome to read books so old they are unaware of the existence of personal home computers. Most of the books we have here were published in the 1970s-80s, if not earlier, and they sometimes mention that some of the described problems could be solved on ЭВМ - an archaic Russian term for a computer. I think that the area of functional analysis is not one to be filled with computational examples, but nevertheless, maybe in the book they could illustrate some points with Mathematica or similar things). It may be for a complete beginner, or a bit higher level, but not a level such that the ordinary student would feel completely defeated on the second page :) The topics we learned are (by topics I mostly mean main definitions, some properties, some lemmas/theorems. We never went deeply into them): Measure and Lebesgue integral Introduction to set theory Measure, countable measure Outer measure, Lebesgue measure, measurable sets Measurable functions Stieltjes-Lebesgue measure (very very brief) Lebesgue integral Egorov theorem, Lebesgue theorem, Beppo Levi's lemma Normed spaces Vector spaces, definitions Norm Topology of normed spaces Banach spaces The application of contraction mappings to the solution of the Fredholm and Volterra integral equations Pre-Hilbert spaces Hilbert spaces Compact sets and Arzela-Ascoli theorem Linear operators Linear operators, definitions Bounded and continuous operators Invertible operators Closed operators Hahn-Banach theorem Compact operators The application of the theory of compact operators to the solution of second-order equations (Riesz-Schauder theory) Spectral analysis of linear operators Introduction to the spectral theory of linear operators. Hilbert-Schmidt theorem (both are brief) I tried to be specific and detailed in my request. Thank you in advance! Added later: I would like to thank you all for useful answers, thank you, guys, you are very helpful!",,"['functional-analysis', 'reference-request', 'book-recommendation']"
33,How to prove this inequality in Banach space?,How to prove this inequality in Banach space?,,"In a normed space $(E,\lVert \cdot\rVert)$ space we have the following inequality: $$\forall\, x,y\in E,\quad\|x\|^{2}-\|y\|^{2}\leq \lVert x-y\rVert\cdot \|x+y\|.$$ How can we prove it?","In a normed space $(E,\lVert \cdot\rVert)$ space we have the following inequality: $$\forall\, x,y\in E,\quad\|x\|^{2}-\|y\|^{2}\leq \lVert x-y\rVert\cdot \|x+y\|.$$ How can we prove it?",,"['functional-analysis', 'banach-spaces']"
34,Is a contraction idempotent operator self-adjoint?,Is a contraction idempotent operator self-adjoint?,,"Is a contraction idempotent operator self-adjoint? In the other words, if $T:H\to H$ is a bounded linear operator such that $||T||\leq1$ and $T^{2}=T$, can we conclude $T=T^*$?","Is a contraction idempotent operator self-adjoint? In the other words, if $T:H\to H$ is a bounded linear operator such that $||T||\leq1$ and $T^{2}=T$, can we conclude $T=T^*$?",,['functional-analysis']
35,Polynomial and spectrum of a Operator .,Polynomial and spectrum of a Operator .,,I need help with the following question :  Let us consider $X$ to be a $\mathbb C  $ Banach space . Let $T \in B(X)$ ie. $T$ is a continuous linear map from $X$ to $X$ . define $$P(T)=\sum_{k=o}^{n}a_kT^k$$ with $T^0=id_X$ (identity) . The claim is that the spectrum of $T : \sigma(T) \subset\{\lambda \in \mathbb C : P(\lambda)= 0\}$  Here $P$ is a polynomial such that $P(T) =0$  . Thanks.,I need help with the following question :  Let us consider $X$ to be a $\mathbb C  $ Banach space . Let $T \in B(X)$ ie. $T$ is a continuous linear map from $X$ to $X$ . define $$P(T)=\sum_{k=o}^{n}a_kT^k$$ with $T^0=id_X$ (identity) . The claim is that the spectrum of $T : \sigma(T) \subset\{\lambda \in \mathbb C : P(\lambda)= 0\}$  Here $P$ is a polynomial such that $P(T) =0$  . Thanks.,,['functional-analysis']
36,The dual of the direct sum,The dual of the direct sum,,"Let $X$, $Y$, $Z$ normed spaces If X$\cong Y\oplus Z$ why is $X^*\cong Y^*\oplus Z^*$? where $X^*$ is the dual of $X$. For example ${\ell^\infty}^*\cong\ell^1\oplus\mathrm{Null}\;C_0$ so if we take the double dual we find the ${\ell^\infty}^{**}\cong{\ell^1}^*\oplus (\mathrm{Null}\; C_0)^*$. I am not sure I understand why these equalities should hold?","Let $X$, $Y$, $Z$ normed spaces If X$\cong Y\oplus Z$ why is $X^*\cong Y^*\oplus Z^*$? where $X^*$ is the dual of $X$. For example ${\ell^\infty}^*\cong\ell^1\oplus\mathrm{Null}\;C_0$ so if we take the double dual we find the ${\ell^\infty}^{**}\cong{\ell^1}^*\oplus (\mathrm{Null}\; C_0)^*$. I am not sure I understand why these equalities should hold?",,['functional-analysis']
37,Example of application of the Uniform Boundedness Principle,Example of application of the Uniform Boundedness Principle,,"I've been trying to come up with an easy example of an application of the uniform boundedness principle (or Banach-Steinhaus theorem). I was thinking of something like the following, which is unfortunately a non-example: Non-example: Consider the Banach space $(B(X), \|\cdot\|_\infty)$, i.e. the space of bounded functions with the sup norm. Let's choose $X=\mathbb R$ and let $\mu$ be a measure that is finite on compact sets, like for example the Lebesgue measure. Define  $$ T_t : (B(X), \|\cdot\|_\infty) \to \mathbb R$$ as $$ f \mapsto \int_{[-t,t]} f d \mu$$ Then $T_t$ is linear and bounded: If $\|f\|_\infty = 1$ then $\|T_t f\| = |T_t f| = \int_{[-t,t]} f d \mu \leq 2t$ so that the operator norm $\|T_t\| \leq 2t  < \infty$. The condition that fails that prevents me from applying Banach-Steinhaus is that the family $\{T_t\}_{t \in \mathbb R}$ is not pointwise bounded: For $f$ with $\|f\|_\infty$ we have $\sup_{t \in \mathbb R} \|T_t\| \geq \sup_{t \in \mathbb R} 2 t = \infty$. My non-example was supposed to conclude that the integral operator is continuous on the whole space. Of course it's not on $\mathbb R$ for bounded functions but you see what I'm trying to do. Although one might consider showing that the integral is a continuous operator by applying Banach-Steinhaus ""cracking nuts with a sledge hammer"", this one is for educational purposes so it's acceptable. Can someone either modify my example so that it works or show me an equally easy example? Thanks a lot for your help.","I've been trying to come up with an easy example of an application of the uniform boundedness principle (or Banach-Steinhaus theorem). I was thinking of something like the following, which is unfortunately a non-example: Non-example: Consider the Banach space $(B(X), \|\cdot\|_\infty)$, i.e. the space of bounded functions with the sup norm. Let's choose $X=\mathbb R$ and let $\mu$ be a measure that is finite on compact sets, like for example the Lebesgue measure. Define  $$ T_t : (B(X), \|\cdot\|_\infty) \to \mathbb R$$ as $$ f \mapsto \int_{[-t,t]} f d \mu$$ Then $T_t$ is linear and bounded: If $\|f\|_\infty = 1$ then $\|T_t f\| = |T_t f| = \int_{[-t,t]} f d \mu \leq 2t$ so that the operator norm $\|T_t\| \leq 2t  < \infty$. The condition that fails that prevents me from applying Banach-Steinhaus is that the family $\{T_t\}_{t \in \mathbb R}$ is not pointwise bounded: For $f$ with $\|f\|_\infty$ we have $\sup_{t \in \mathbb R} \|T_t\| \geq \sup_{t \in \mathbb R} 2 t = \infty$. My non-example was supposed to conclude that the integral operator is continuous on the whole space. Of course it's not on $\mathbb R$ for bounded functions but you see what I'm trying to do. Although one might consider showing that the integral is a continuous operator by applying Banach-Steinhaus ""cracking nuts with a sledge hammer"", this one is for educational purposes so it's acceptable. Can someone either modify my example so that it works or show me an equally easy example? Thanks a lot for your help.",,"['functional-analysis', 'examples-counterexamples']"
38,Proof of Eberlein–Smulian Theorem for a reflexive Banach spaces,Proof of Eberlein–Smulian Theorem for a reflexive Banach spaces,,"Looking for the proof of Eberlein-Smulian Theorem. Searching for the proof is what I break with this morning. Some of my friends recommend Haim Brezis ( Functional Analysis, Sobolev Spaces and Partial Differential Equations ). After I search the book, I only found the statement of the theorem, is the proof very difficult to grasp? Why is Haim Brezis skip it in his book? Please I need a reference where I can find the proof in detail. Theorem :(Eberlein-Smul'yan Theorem) A Banach space $E$ is reflexive if and   only if every (norm) bounded sequence in $E$ has a subsequence which converges   weakly to an element of $E$.","Looking for the proof of Eberlein-Smulian Theorem. Searching for the proof is what I break with this morning. Some of my friends recommend Haim Brezis ( Functional Analysis, Sobolev Spaces and Partial Differential Equations ). After I search the book, I only found the statement of the theorem, is the proof very difficult to grasp? Why is Haim Brezis skip it in his book? Please I need a reference where I can find the proof in detail. Theorem :(Eberlein-Smul'yan Theorem) A Banach space $E$ is reflexive if and   only if every (norm) bounded sequence in $E$ has a subsequence which converges   weakly to an element of $E$.",,"['functional-analysis', 'reference-request', 'banach-spaces']"
39,Isomorphism of Banach spaces implies isomorphism of duals?,Isomorphism of Banach spaces implies isomorphism of duals?,,"I can't make up my mind whether this question is trivial, or simply wrong, so i decided to ask, just in case someone sees a fallacy in my reasoning: Question: Suppose $V,W$ are two banach spaces, and $T:V\to W$ is an isomorphism. Is $T^*:W^*\to V^*$ an isomorphism? On the one hand this seems trivial- it requires a little work, but one can show that $T^*$ is injective, given that $T$ is surjective without working too hard, so if $T^*$ is also surjective, the open mapping theorem should finish the work for us: To show this, let $f\in V^*$ be arbitrary. Then $f\circ T^{-1}:W\to \mathbb{C}$ is bounded and linear (since $T^{-1}$ and $f$ both are), and $$T^*(f\circ T^{-1})(w)=f\circ T^{-1}(Tw)=f(w)$$ again, this apears (to me, at least) to be correct, but my little experience with Banach spaces has taught me to fear such immediate results, when discussing duals :-P... anyhow, I would be very happy if someone could tell me if I'm correct, or otherwise, give a counter-example, or point to a mistake. Additionally, assuming this isn't as immediate as I thought- does the assertion hold when $T$ is an isometric isomorphism? Thank you very much :-) (p.s i added the homework tag, as this question arose as part of a h.w assignment, but this isn't a h.w question per-se)","I can't make up my mind whether this question is trivial, or simply wrong, so i decided to ask, just in case someone sees a fallacy in my reasoning: Question: Suppose $V,W$ are two banach spaces, and $T:V\to W$ is an isomorphism. Is $T^*:W^*\to V^*$ an isomorphism? On the one hand this seems trivial- it requires a little work, but one can show that $T^*$ is injective, given that $T$ is surjective without working too hard, so if $T^*$ is also surjective, the open mapping theorem should finish the work for us: To show this, let $f\in V^*$ be arbitrary. Then $f\circ T^{-1}:W\to \mathbb{C}$ is bounded and linear (since $T^{-1}$ and $f$ both are), and $$T^*(f\circ T^{-1})(w)=f\circ T^{-1}(Tw)=f(w)$$ again, this apears (to me, at least) to be correct, but my little experience with Banach spaces has taught me to fear such immediate results, when discussing duals :-P... anyhow, I would be very happy if someone could tell me if I'm correct, or otherwise, give a counter-example, or point to a mistake. Additionally, assuming this isn't as immediate as I thought- does the assertion hold when $T$ is an isometric isomorphism? Thank you very much :-) (p.s i added the homework tag, as this question arose as part of a h.w assignment, but this isn't a h.w question per-se)",,"['analysis', 'functional-analysis', 'banach-spaces']"
40,How can one relate inverse of a differential operator to an integral operator?,How can one relate inverse of a differential operator to an integral operator?,,"Informally speaking, the integral operator can be regarded as the inverse of some differential operator. In some very special case, finding the inverse of the differential operator is equivalent to finding the Green's function. For example if the differential operator $A$ is defined as $$Au:=au''+bu'+cu,$$ then in some BVP, one may have  $$A^{-1}f(x)=\int_{0}^1g(x,y)f(y)dy$$ If one knows that   $A^{-1}f=(I-\partial_{xx}^2)^{-1}\partial_xf$,   how can one turn it into the form   above, i.e, write it as an integral? By solving an ODE, one may find $(I-\partial_{xx}^2)^{-1}$. However, when it comes to $(I-\partial_{xx}^2)^{-1}\partial_x$, things become complicated. Is there any rule of thumb for dealing   with this kind of problems?","Informally speaking, the integral operator can be regarded as the inverse of some differential operator. In some very special case, finding the inverse of the differential operator is equivalent to finding the Green's function. For example if the differential operator $A$ is defined as $$Au:=au''+bu'+cu,$$ then in some BVP, one may have  $$A^{-1}f(x)=\int_{0}^1g(x,y)f(y)dy$$ If one knows that   $A^{-1}f=(I-\partial_{xx}^2)^{-1}\partial_xf$,   how can one turn it into the form   above, i.e, write it as an integral? By solving an ODE, one may find $(I-\partial_{xx}^2)^{-1}$. However, when it comes to $(I-\partial_{xx}^2)^{-1}\partial_x$, things become complicated. Is there any rule of thumb for dealing   with this kind of problems?",,['functional-analysis']
41,Not all norms are equivalent in an infinite-dimensional space,Not all norms are equivalent in an infinite-dimensional space,,"How to prove that not all norms are equivalent in an infinite-dimensional vector space? In particular, I would like to prove that for a space $X$ of continuous real-valued functions defined on interval $[0,1]$, every two norms $\|\ .\|_p$ ($p \in [1, \infty]$) are not equivalent.","How to prove that not all norms are equivalent in an infinite-dimensional vector space? In particular, I would like to prove that for a space $X$ of continuous real-valued functions defined on interval $[0,1]$, every two norms $\|\ .\|_p$ ($p \in [1, \infty]$) are not equivalent.",,"['functional-analysis', 'normed-spaces']"
42,Do we need completeness for a weak*-convergent sequence to be bounded?,Do we need completeness for a weak*-convergent sequence to be bounded?,,Let $(\phi_n)_n$ be a weak* convergent sequence in the dual of some normed space $X$ with (weak*-)limit $\phi$. If $X$ is Banach then it follows from the uniform boundedness principle that $\sup_n \lVert \phi_n \rVert < \infty$ since $\sup_n  |\phi_n (x)| < \infty$ for every $x \in X$. But what if $X$ is not Banach? Does this still hold true?,Let $(\phi_n)_n$ be a weak* convergent sequence in the dual of some normed space $X$ with (weak*-)limit $\phi$. If $X$ is Banach then it follows from the uniform boundedness principle that $\sup_n \lVert \phi_n \rVert < \infty$ since $\sup_n  |\phi_n (x)| < \infty$ for every $x \in X$. But what if $X$ is not Banach? Does this still hold true?,,"['functional-analysis', 'banach-spaces', 'weak-convergence']"
43,characterization of the dual space of the Sobolev space $H_0^1$,characterization of the dual space of the Sobolev space,H_0^1,"I am slightly confused about the properties of the dual space of the Sobolev space $H_0^1$ as outlined on page 299 in Evans. In particular, following the notation in the book, item 3 says that $\forall u \in H_{0}^{1}(U), v \subset L^2(U) \subset H^{-1}(U)$, $$(v,u)_{L^2(U)}=\langle v,u \rangle.$$ I am not quite sure how to prove this and it might be due to a confusion with notation. Since $v \in H^{-1}(U)$, item 1 in the book states that $\exists \, v^0,v^1, \dots , v^n$ in $L^2(U)$ such that $$\langle v,u\rangle=\int_Uv^0u+\sum_{i=1}^{n}v^{i}u_{x_i} \,dx.$$ In other words, we can identify $v$ with $(v^0,\dots,v^n)$. Since $v\in L^2$ and since this implies that $v$ is ""associated"" with the above functional $\langle v,u \rangle$ then one of the $v_i$'s have to be $v$ and the rest have to be $0$. Certainly, if $v^0=v$ the above statement follows. But why must this be the case? Why can't $v^1=v$ instead? Or is this what is meant by $L^2(U) \subset H^{-1}(U)$, i.e. that if $v \in L^2$ then the functional associated with $v$ takes on the form $\int vu\,dx$? I am hoping to clarify this part because certainly $\int v_{x_i}u\,dx$ seems legitimate too.","I am slightly confused about the properties of the dual space of the Sobolev space $H_0^1$ as outlined on page 299 in Evans. In particular, following the notation in the book, item 3 says that $\forall u \in H_{0}^{1}(U), v \subset L^2(U) \subset H^{-1}(U)$, $$(v,u)_{L^2(U)}=\langle v,u \rangle.$$ I am not quite sure how to prove this and it might be due to a confusion with notation. Since $v \in H^{-1}(U)$, item 1 in the book states that $\exists \, v^0,v^1, \dots , v^n$ in $L^2(U)$ such that $$\langle v,u\rangle=\int_Uv^0u+\sum_{i=1}^{n}v^{i}u_{x_i} \,dx.$$ In other words, we can identify $v$ with $(v^0,\dots,v^n)$. Since $v\in L^2$ and since this implies that $v$ is ""associated"" with the above functional $\langle v,u \rangle$ then one of the $v_i$'s have to be $v$ and the rest have to be $0$. Certainly, if $v^0=v$ the above statement follows. But why must this be the case? Why can't $v^1=v$ instead? Or is this what is meant by $L^2(U) \subset H^{-1}(U)$, i.e. that if $v \in L^2$ then the functional associated with $v$ takes on the form $\int vu\,dx$? I am hoping to clarify this part because certainly $\int v_{x_i}u\,dx$ seems legitimate too.",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
44,Weak convergence and weak star convergence.,Weak convergence and weak star convergence.,,"If region $\Omega$ is bounded and $u_n$ has weak star convergence in $L^\infty ( \Omega)$ to some $u\in L^\infty(\Omega)$ , does it imply that $u_n$ converges weakly in any $L^p(\Omega) $ ? I think i got it : If $sup$ of a function is finite then integral over a bounded region is finite with any $p$ norm  . is it right ?","If region $\Omega$ is bounded and $u_n$ has weak star convergence in $L^\infty ( \Omega)$ to some $u\in L^\infty(\Omega)$ , does it imply that $u_n$ converges weakly in any $L^p(\Omega) $ ? I think i got it : If $sup$ of a function is finite then integral over a bounded region is finite with any $p$ norm  . is it right ?",,"['functional-analysis', 'measure-theory']"
45,Show differential operator is not bounded using definition of bounded operators,Show differential operator is not bounded using definition of bounded operators,,"Let $T:C^{1}_{[a,b]} \rightarrow C^{0}_{[a,b]}$ with $a<b$ be the differential operator defined as $Tx=x’$ . The practice exercise asks for the kernel and range of such operator and also a demonstration using the definition of bounded operators. An operator on normed spaces is said to be bounded when $\|Tx\| \leq c\|x\|$ where $c$ is a real number. I have already been through examples of continuous functions which show that it is not bounded. However, this one specifically asks to use the definition. Your contribution would be much appreciated. Feel free to shut this down if you indicate a solution that is available out there.","Let with be the differential operator defined as . The practice exercise asks for the kernel and range of such operator and also a demonstration using the definition of bounded operators. An operator on normed spaces is said to be bounded when where is a real number. I have already been through examples of continuous functions which show that it is not bounded. However, this one specifically asks to use the definition. Your contribution would be much appreciated. Feel free to shut this down if you indicate a solution that is available out there.","T:C^{1}_{[a,b]} \rightarrow C^{0}_{[a,b]} a<b Tx=x’ \|Tx\| \leq c\|x\| c","['functional-analysis', 'operator-theory', 'normed-spaces', 'differential-operators']"
46,Extending the spectral theorem for bounded self adjoint operators to bounded normal operators,Extending the spectral theorem for bounded self adjoint operators to bounded normal operators,,"I'm currently preparing for an exam in functional analysis, and I have a question about the extension of the spectral theorem for bounded self adjoint operators to bounded normal operators. Starting point is the spectral theorem for bounded self adjoint operators: Let $T$ be a bounded self adjoint operator in an Hilbert space $X$ , then there exists a unique spectral measure $E : \Sigma_\mathbb{R} \rightarrow B(X)$ , which has compact support in $\mathbb{R}$ (Here $\Sigma_\mathbb{R}$ is the Borel- $\sigma$ -algebra on $\mathbb{R}$ and $B(X)$ is the set of all bounded and linear operators in $X$ ) and $T = \int\limits_{\mathbb{R}}\lambda dE_\lambda$ . Moreover the mapping $f \rightarrow f(T) := \int\limits_{\mathbb{R}} f(\lambda) dE_\lambda$ , for bounded and measurable functions $f$ , satisfies the conditions of the (unique) measurable functional calculus. If a normal operator $T \in B(X)$ is given, one can define the Operators: $S_1 := \frac{1}{2} \left( T+T^{\ast} \right)$ and $S_2 := \frac{1}{2i} \left( T-T^{\ast} \right)$ . Then we get that $T = S_1 + i S_2$ and that $S_1$ and $S_2$ are self adjoint. Then by the spectral theorem for self adjoint operators there exist two spectral measures $E^1$ and $E^2$ . Since $T$ is normal, $S_1$ and $S_2$ commute, and therefore the spectral measures $E^1$ and $E^2$ . Then there exists a unique spectral measure $E : \Sigma_{\mathbb{R}^2} \rightarrow B(X)$ such that for all $A, B \in \Sigma_\mathbb{R}$ we have that $E(A \times B) = E^1(A)E^2(B)$ . (See: Schmüdgen - Thm. 4.10) By identifying $\mathbb{R}^2$ with $\mathbb{C}$ one gets a unique specral measure $E : \Sigma_\mathbb{C} \rightarrow B(X)$ and is able to define integrals with respect to this spectral measure in the natural way: First for step functions and then for bounded measurable functions by approximation. Now I have to show that $E$ has the same properties as the spectral measure for self adjoint operators, i.e.: $T = \int\limits_{\mathbb{C}} z dE_z$ and the mapping $f \rightarrow f(T) := \int\limits_{\mathbb{C}} f(z) dE_z$ , for bounded and measurable functions $f$ , satisfies the conditions of the (unique) measurable functional calculus. My question now is: is there any other way to show that, beside re-do the proof of the spectral theorem for self adjoint operators? It's not that much work, once one has the proof of the self adjoint case. I'm just curious if there's an more elegant way ... Thanks in advance, GordonFreeman","I'm currently preparing for an exam in functional analysis, and I have a question about the extension of the spectral theorem for bounded self adjoint operators to bounded normal operators. Starting point is the spectral theorem for bounded self adjoint operators: Let be a bounded self adjoint operator in an Hilbert space , then there exists a unique spectral measure , which has compact support in (Here is the Borel- -algebra on and is the set of all bounded and linear operators in ) and . Moreover the mapping , for bounded and measurable functions , satisfies the conditions of the (unique) measurable functional calculus. If a normal operator is given, one can define the Operators: and . Then we get that and that and are self adjoint. Then by the spectral theorem for self adjoint operators there exist two spectral measures and . Since is normal, and commute, and therefore the spectral measures and . Then there exists a unique spectral measure such that for all we have that . (See: Schmüdgen - Thm. 4.10) By identifying with one gets a unique specral measure and is able to define integrals with respect to this spectral measure in the natural way: First for step functions and then for bounded measurable functions by approximation. Now I have to show that has the same properties as the spectral measure for self adjoint operators, i.e.: and the mapping , for bounded and measurable functions , satisfies the conditions of the (unique) measurable functional calculus. My question now is: is there any other way to show that, beside re-do the proof of the spectral theorem for self adjoint operators? It's not that much work, once one has the proof of the self adjoint case. I'm just curious if there's an more elegant way ... Thanks in advance, GordonFreeman","T X E : \Sigma_\mathbb{R} \rightarrow B(X) \mathbb{R} \Sigma_\mathbb{R} \sigma \mathbb{R} B(X) X T = \int\limits_{\mathbb{R}}\lambda dE_\lambda f \rightarrow f(T) := \int\limits_{\mathbb{R}} f(\lambda) dE_\lambda f T \in B(X) S_1 := \frac{1}{2} \left( T+T^{\ast} \right) S_2 := \frac{1}{2i} \left( T-T^{\ast} \right) T = S_1 + i S_2 S_1 S_2 E^1 E^2 T S_1 S_2 E^1 E^2 E : \Sigma_{\mathbb{R}^2} \rightarrow B(X) A, B \in \Sigma_\mathbb{R} E(A \times B) = E^1(A)E^2(B) \mathbb{R}^2 \mathbb{C} E : \Sigma_\mathbb{C} \rightarrow B(X) E T = \int\limits_{\mathbb{C}} z dE_z f \rightarrow f(T) := \int\limits_{\mathbb{C}} f(z) dE_z f","['functional-analysis', 'spectral-theory']"
47,Proof of Hardy inequality in $\mathbb{R}^n$,Proof of Hardy inequality in,\mathbb{R}^n,"I've often seen people use the inequality  $$\int_{\mathbb R^3} \frac{|u(x)|^2}{|x|^2}\,dx  \leq 4\int_{\mathbb R^3}|\nabla u(x)|^2\,dx,\qquad u\in C_0^\infty(\mathbb R^3) $$ without proof, refering to it as ""Hardy's inequality"". I struggled to find a direct proof of this in the literature and couldn't prove it myself. Does anyone know a straightforward proof of this or a book in which Hardy's inequality in this form is proved? I would also be interested in the general form of this inequality, i.e. what happens if one replaces $\mathbb R^3$ with $\mathbb R^n$?","I've often seen people use the inequality  $$\int_{\mathbb R^3} \frac{|u(x)|^2}{|x|^2}\,dx  \leq 4\int_{\mathbb R^3}|\nabla u(x)|^2\,dx,\qquad u\in C_0^\infty(\mathbb R^3) $$ without proof, refering to it as ""Hardy's inequality"". I struggled to find a direct proof of this in the literature and couldn't prove it myself. Does anyone know a straightforward proof of this or a book in which Hardy's inequality in this form is proved? I would also be interested in the general form of this inequality, i.e. what happens if one replaces $\mathbb R^3$ with $\mathbb R^n$?",,"['functional-analysis', 'inequality', 'lebesgue-integral', 'sobolev-spaces', 'lp-spaces']"
48,If $T: X \to Y$ is norm-norm continuous then it is weak-weak continuous,If  is norm-norm continuous then it is weak-weak continuous,T: X \to Y,"Let $X,Y$ be normed linear spaces (or Banach spaces if necessary) and let $T: X \to Y$ be linear. We call $T$ norm-norm continuous if $X,Y$ are endowed with the norm topology and similarly, weak-weak continuous if $X,Y$ are endowed with the weak topology. I am trying to show that if $T$ is norm norm continuous then it is weak-weak continuous. My idea was to use the sequential definition of continuity and to show that if $x_n \to x$ weakly then $Tx_n \to Tx$ weakly. That was easy enough but to complete my proof I would now have to show that this implies that $T$ is continuous and I can't seem to prove it. It would be easy if the topologies were the norm topologies but with both spaces carrying the weak topology I don't see how to proceed. My question is: Is it true that if $T$ is linear and $x_n \to x$ weakly implies $Tx_n \to Tx$ weakly then $T$ is continuous? If yes, could someone please show me a proof, I can't seem to work it out.","Let $X,Y$ be normed linear spaces (or Banach spaces if necessary) and let $T: X \to Y$ be linear. We call $T$ norm-norm continuous if $X,Y$ are endowed with the norm topology and similarly, weak-weak continuous if $X,Y$ are endowed with the weak topology. I am trying to show that if $T$ is norm norm continuous then it is weak-weak continuous. My idea was to use the sequential definition of continuity and to show that if $x_n \to x$ weakly then $Tx_n \to Tx$ weakly. That was easy enough but to complete my proof I would now have to show that this implies that $T$ is continuous and I can't seem to prove it. It would be easy if the topologies were the norm topologies but with both spaces carrying the weak topology I don't see how to proceed. My question is: Is it true that if $T$ is linear and $x_n \to x$ weakly implies $Tx_n \to Tx$ weakly then $T$ is continuous? If yes, could someone please show me a proof, I can't seem to work it out.",,[]
49,Show that the semigroup S(t) here described is a contraction semigroup,Show that the semigroup S(t) here described is a contraction semigroup,,"Definition 1 : Let $H$ be a Hilbert space. A strongly continuous semigroup is a family $\{S(t)\}_{t \ge 0}$ of continuous linear operators $S(t): H \rightarrow H$ such that $S(0)=I$, where $I$ is the identity operator. $S(t)S(s)=S(t+s)$ for all $t,s \ge 0$. $t\mapsto S(t)x$ is continuous on $[0,\infty)$ for all $x\in H$. A contraction semigroup on a Hilbert space $H$ is a semigroup whose norm is less or equal than 1; as in $\forall t \in \mathbb{R}^+: \|S(t)\| \le 1.$ Let $S(t)$ be a strongly continuous semigroup defined on a Hilbert space $H$ satisfying: \begin{align*} \left\|\int_0^t S(\tau) x\,d\tau\right\|_H \le t\|x\|_H \end{align*} How can I show that $S(t)$ is a contraction semigroup, i.e $\|S(t)\| \le 1$ for all $t \ge 0$? I tried to prove it by contradiction. I supposed that $\exists t_0 \in \mathbb{R}^+: \|S(t_0)\| \gt 1$ but then I noticed that I couldn't use the inequality because $\left\|\int_0^{t_0} S(\tau) x\,d\tau\right\|_H$ is always $\le t_0\|x\|_H$ and not greater than anything else. Many thanks in advance, -- Cesar","Definition 1 : Let $H$ be a Hilbert space. A strongly continuous semigroup is a family $\{S(t)\}_{t \ge 0}$ of continuous linear operators $S(t): H \rightarrow H$ such that $S(0)=I$, where $I$ is the identity operator. $S(t)S(s)=S(t+s)$ for all $t,s \ge 0$. $t\mapsto S(t)x$ is continuous on $[0,\infty)$ for all $x\in H$. A contraction semigroup on a Hilbert space $H$ is a semigroup whose norm is less or equal than 1; as in $\forall t \in \mathbb{R}^+: \|S(t)\| \le 1.$ Let $S(t)$ be a strongly continuous semigroup defined on a Hilbert space $H$ satisfying: \begin{align*} \left\|\int_0^t S(\tau) x\,d\tau\right\|_H \le t\|x\|_H \end{align*} How can I show that $S(t)$ is a contraction semigroup, i.e $\|S(t)\| \le 1$ for all $t \ge 0$? I tried to prove it by contradiction. I supposed that $\exists t_0 \in \mathbb{R}^+: \|S(t_0)\| \gt 1$ but then I noticed that I couldn't use the inequality because $\left\|\int_0^{t_0} S(\tau) x\,d\tau\right\|_H$ is always $\le t_0\|x\|_H$ and not greater than anything else. Many thanks in advance, -- Cesar",,"['functional-analysis', 'semigroup-of-operators']"
50,Weak convergence of continuous functions,Weak convergence of continuous functions,,"Let $X$ be an LCH space and $C_0(X)$ the set of continuous vanishing functions on $X$. If $C_0(X)$ is given the structure of a Banach space with the sup-norm, then its weak topology is given by the set of Radon measures $M(X)$ of finite total variation. One has $f_\alpha \to f$ if and only if $\int f_\alpha ~d\mu \to \int f~d\mu$ for all $\mu \in M(X)$. My question: Is there a characterization for weak convergence in $C_0(X)$? Weak convergence is at least as strong as pointwise convergence (because of the Dirac measures). I have an example showing that it is not the same as pointwise convergence in general.","Let $X$ be an LCH space and $C_0(X)$ the set of continuous vanishing functions on $X$. If $C_0(X)$ is given the structure of a Banach space with the sup-norm, then its weak topology is given by the set of Radon measures $M(X)$ of finite total variation. One has $f_\alpha \to f$ if and only if $\int f_\alpha ~d\mu \to \int f~d\mu$ for all $\mu \in M(X)$. My question: Is there a characterization for weak convergence in $C_0(X)$? Weak convergence is at least as strong as pointwise convergence (because of the Dirac measures). I have an example showing that it is not the same as pointwise convergence in general.",,"['functional-analysis', 'measure-theory']"
51,Introductory/Intuitive Functional Analysis Book,Introductory/Intuitive Functional Analysis Book,,"Can you recommend a gentle introduction to the abstract thinking and motivation of functional analysis? I'm looking for a book that holds you by the hand and shows the details of exercises, etc. Thanks.","Can you recommend a gentle introduction to the abstract thinking and motivation of functional analysis? I'm looking for a book that holds you by the hand and shows the details of exercises, etc. Thanks.",,"['functional-analysis', 'reference-request', 'book-recommendation']"
52,"Bounded linear operator maps norm-bounded, closed sets to closed sets. Implies closed range?","Bounded linear operator maps norm-bounded, closed sets to closed sets. Implies closed range?",,"Question Suppose $T:X\rightarrow Y$ is a continuous, injective linear operator between Banach spaces. Suppose, in addition, that $T$ maps norm bounded closed sets in $X$ to closed sets in $Y$. Then the range of $T$ is closed in $Y$. This is a problem related to one given An Invitation to Operator Theory by Abramovich and Aliprantis and I'd just like to verify my proof. Attempt We assume that $T$ is as above, and we shall prove that it has closed range. If $y_n = T x_n$ and $y_n\rightarrow y$, we want to show that $y=Tx$ for some $x\in X$. First, suppose $\{x_n\}_{n\geq 1}$ is unbounded. Then $$\lim_n\, T(x_n/\|x_n\|) = \lim_n\, y_n/\|x_n\| = 0.$$ But the set $B=\{ x\in X: \| x\|=1\}$ is closed and norm-bounded, so its image under $T$ is closed. In particular, we must have $Tz=0$ for some $z\in B$. This contradicts the fact that $T$ is injective. So the sequence $\{x_n\}_{n\geq 1}$ is bounded in $X$. Since $\{x_n\}_{n\geq 1}$ is bounded, the set $$ A=\mathrm{cl} \{ x_1, x_2, \ldots, x_n, \ldots \}$$ is closed and norm bounded. Hence $T(A)$ is closed in $Y$. In particular, $y=\lim_n\, Tx_n = Tx$ for some $x\in A \subset X$. So the range of $T$ is closed. Thanks in advance!","Question Suppose $T:X\rightarrow Y$ is a continuous, injective linear operator between Banach spaces. Suppose, in addition, that $T$ maps norm bounded closed sets in $X$ to closed sets in $Y$. Then the range of $T$ is closed in $Y$. This is a problem related to one given An Invitation to Operator Theory by Abramovich and Aliprantis and I'd just like to verify my proof. Attempt We assume that $T$ is as above, and we shall prove that it has closed range. If $y_n = T x_n$ and $y_n\rightarrow y$, we want to show that $y=Tx$ for some $x\in X$. First, suppose $\{x_n\}_{n\geq 1}$ is unbounded. Then $$\lim_n\, T(x_n/\|x_n\|) = \lim_n\, y_n/\|x_n\| = 0.$$ But the set $B=\{ x\in X: \| x\|=1\}$ is closed and norm-bounded, so its image under $T$ is closed. In particular, we must have $Tz=0$ for some $z\in B$. This contradicts the fact that $T$ is injective. So the sequence $\{x_n\}_{n\geq 1}$ is bounded in $X$. Since $\{x_n\}_{n\geq 1}$ is bounded, the set $$ A=\mathrm{cl} \{ x_1, x_2, \ldots, x_n, \ldots \}$$ is closed and norm bounded. Hence $T(A)$ is closed in $Y$. In particular, $y=\lim_n\, Tx_n = Tx$ for some $x\in A \subset X$. So the range of $T$ is closed. Thanks in advance!",,"['functional-analysis', 'banach-spaces']"
53,$L_{p}$ distance between a function and its translation,distance between a function and its translation,L_{p},"I'm working through a proof and one of the comments is that for a function $f\in L_p (\mathbb{T})$: $$\lim_{t\to 0}\;\|f(\cdot + t) - f\|_p = 0.$$ How do I prove it?  I think it is intuitively clear if $f$ is a step function, but what about for an arbitrary $p$ integrable function?","I'm working through a proof and one of the comments is that for a function $f\in L_p (\mathbb{T})$: $$\lim_{t\to 0}\;\|f(\cdot + t) - f\|_p = 0.$$ How do I prove it?  I think it is intuitively clear if $f$ is a step function, but what about for an arbitrary $p$ integrable function?",,"['functional-analysis', 'measure-theory', 'fourier-analysis']"
54,Convex functions and families of affine functions,Convex functions and families of affine functions,,I know that the supremum of a family of affine functions is convex. Just wondering if it is true (and if so how one proves) that the converse -- any $C^1$ convex function is the supremum of some family of affine functions. Thanks.,I know that the supremum of a family of affine functions is convex. Just wondering if it is true (and if so how one proves) that the converse -- any $C^1$ convex function is the supremum of some family of affine functions. Thanks.,,"['functional-analysis', 'convex-analysis', 'topological-vector-spaces']"
55,Unbounded operator such that $P^2=P$,Unbounded operator such that,P^2=P,"Does there exist an Unbounded operator $P$ on some Banach space $X$ such that $Dom(P)=X$ and $P^2=P$ ? If we don’t require $Dom(P)=X$ , we can easily construct a Unbounded operator on $L^2[0,2π]$ by define $P$ which act on bases as $P\exp(in\theta)=|n|+1$ for all integers $n$ . Any help will be appreciated, thanks.","Does there exist an Unbounded operator on some Banach space such that and ? If we don’t require , we can easily construct a Unbounded operator on by define which act on bases as for all integers . Any help will be appreciated, thanks.","P X Dom(P)=X P^2=P Dom(P)=X L^2[0,2π] P P\exp(in\theta)=|n|+1 n","['functional-analysis', 'projection', 'unbounded-operators', 'closed-graph']"
56,Brezis Exercise 3.9,Brezis Exercise 3.9,,"3.9 Let $E$ be a Banach space; let $M\subset E$ be a linear subspace, and let $f_{0} \in E^{\star}$. Prove that there exists some $g_{0} \in M^{\perp}$ such that $$ \inf_{g\in M^{\perp}}\lVert f_{0}-g\rVert=\lVert f_{0}-g_{0}\rVert. $$ Two methods are suggested: Use Theorem 1.12. Use the weak$^{\star}$ topology $\sigma(E^{\star},E)$. I'm trying to solve this problem using method number 2 . I've already shown that $M^\bot$ is closed in the weak* topology, and I'm aware of the fact that $B_{E^*}$ is compact in that same topology. Any ideas on how to proceed on this one? Obs: $$ M^\bot = \left\{ g\in E^*\ ;\ g(v)=0\ ,\ v\in M \right\} $$","3.9 Let $E$ be a Banach space; let $M\subset E$ be a linear subspace, and let $f_{0} \in E^{\star}$. Prove that there exists some $g_{0} \in M^{\perp}$ such that $$ \inf_{g\in M^{\perp}}\lVert f_{0}-g\rVert=\lVert f_{0}-g_{0}\rVert. $$ Two methods are suggested: Use Theorem 1.12. Use the weak$^{\star}$ topology $\sigma(E^{\star},E)$. I'm trying to solve this problem using method number 2 . I've already shown that $M^\bot$ is closed in the weak* topology, and I'm aware of the fact that $B_{E^*}$ is compact in that same topology. Any ideas on how to proceed on this one? Obs: $$ M^\bot = \left\{ g\in E^*\ ;\ g(v)=0\ ,\ v\in M \right\} $$",,"['functional-analysis', 'weak-topology']"
57,"A linear map $S:Y^*\to X^*$ is weak$^*$ continuous if and only if $S=T^*$ for some $T\in B(X,Y)$",A linear map  is weak continuous if and only if  for some,"S:Y^*\to X^* ^* S=T^* T\in B(X,Y)","As the title says, the question is how to prove Let $X,Y$ be normed spaces. A linear map $S:Y^*\to X^*$ is weak $^*$ continuous if and only if $S=T^*$ for some $T\in B(X,Y)$","As the title says, the question is how to prove Let be normed spaces. A linear map is weak continuous if and only if for some","X,Y S:Y^*\to X^* ^* S=T^* T\in B(X,Y)","['functional-analysis', 'operator-theory', 'normed-spaces']"
58,Every separable Banach space is isomorphic to $\ell_1/A$ for some closed $A\subset \ell_1$,Every separable Banach space is isomorphic to  for some closed,\ell_1/A A\subset \ell_1,"How to prove the following mind-blowing fact? Let $X$ be a separable Banach space and let $\ell_1$ be the space of all absolutely summable scalar sequences. Then there exists such closed subspace $A\subset \ell_1$ that factor space $\ell_1/A$ and $X$ are isomorphic as normed spaces. Edit: So what, this is like a classification up to isomorphism of all separable Banach spaces? Each separable Banach space corresponds to some closed subspace of $\ell_1$?","How to prove the following mind-blowing fact? Let $X$ be a separable Banach space and let $\ell_1$ be the space of all absolutely summable scalar sequences. Then there exists such closed subspace $A\subset \ell_1$ that factor space $\ell_1/A$ and $X$ are isomorphic as normed spaces. Edit: So what, this is like a classification up to isomorphism of all separable Banach spaces? Each separable Banach space corresponds to some closed subspace of $\ell_1$?",,"['functional-analysis', 'convergence-divergence', 'banach-spaces', 'normed-spaces']"
59,Are there any differences between distributions (generalized functions) and probability distributions?,Are there any differences between distributions (generalized functions) and probability distributions?,,"A distribution/generalized function is an element of the dual space of $$S=\{f\in  C^{\infty}(\mathbb{R})\colon \|f\|_{\alpha,\beta}<\infty \text{ for all } \alpha ,\beta\}$$ Where $\|f\|_{\alpha,\beta}=\sup_{x\in \mathbb{R}}|x^{\alpha} f^{(\beta)}(x)|$. We know that all probability measures are elements of $S^*$, or more specifically the linear functional $L_{\mu}\colon S\rightarrow \mathbb{R}$ where $L_{\mu} (f)=\int_{-\infty}^{\infty}fd\mu$. In this sense, a probability measure is just a linear functional $L\colon S\cup\{1\}\rightarrow \mathbb{R}$ with $L(1)=1$. Using the Riesz Representation Theorem, any linear functional (with a few technical considerations) has a unique associated measure. So if $L$ is any distribution on $S\cup \{1\}$, where $L(1)=1$, it is a probability distribution. Is this correct? A ""probability distribution"" (in the sense of the Radon-Nikodym derivative of a probability measure with respect to Lebesgue measure) is really just a normalized (or is uniquely associated with a) normalized Schwartz distribution?","A distribution/generalized function is an element of the dual space of $$S=\{f\in  C^{\infty}(\mathbb{R})\colon \|f\|_{\alpha,\beta}<\infty \text{ for all } \alpha ,\beta\}$$ Where $\|f\|_{\alpha,\beta}=\sup_{x\in \mathbb{R}}|x^{\alpha} f^{(\beta)}(x)|$. We know that all probability measures are elements of $S^*$, or more specifically the linear functional $L_{\mu}\colon S\rightarrow \mathbb{R}$ where $L_{\mu} (f)=\int_{-\infty}^{\infty}fd\mu$. In this sense, a probability measure is just a linear functional $L\colon S\cup\{1\}\rightarrow \mathbb{R}$ with $L(1)=1$. Using the Riesz Representation Theorem, any linear functional (with a few technical considerations) has a unique associated measure. So if $L$ is any distribution on $S\cup \{1\}$, where $L(1)=1$, it is a probability distribution. Is this correct? A ""probability distribution"" (in the sense of the Radon-Nikodym derivative of a probability measure with respect to Lebesgue measure) is really just a normalized (or is uniquely associated with a) normalized Schwartz distribution?",,"['functional-analysis', 'measure-theory']"
60,Physical interpretation of $L_1$ and $L_2$ norms,Physical interpretation of  and  norms,L_1 L_2,"In signal analysis, students have no qualms about associating the $L_2$ norm of a square integrable function $f(t)$ as the energy associated with that signal. A good understanding of whether a function $f(t)$ is a square integrable function is to picture whether it has finite amount of energy. I find this to be an extremely useful knowledge. However, when I plot the $L_1$ norm of a given function, all I'm getting is the total positive area lying under the curve. Which leads to two important questions: How did $L_2$ norm get associated with being the energy of a signal? I.e. what is the physics involved? What is the physical interpretation of the $L_1$ norm? I find ""area"" not very convincing not only given the enormous physical intuition behind the $L_2$ norm but an area is still more of a construction from a mathematical perspective.","In signal analysis, students have no qualms about associating the $L_2$ norm of a square integrable function $f(t)$ as the energy associated with that signal. A good understanding of whether a function $f(t)$ is a square integrable function is to picture whether it has finite amount of energy. I find this to be an extremely useful knowledge. However, when I plot the $L_1$ norm of a given function, all I'm getting is the total positive area lying under the curve. Which leads to two important questions: How did $L_2$ norm get associated with being the energy of a signal? I.e. what is the physics involved? What is the physical interpretation of the $L_1$ norm? I find ""area"" not very convincing not only given the enormous physical intuition behind the $L_2$ norm but an area is still more of a construction from a mathematical perspective.",,"['functional-analysis', 'hilbert-spaces', 'normed-spaces', 'mathematical-physics', 'signal-processing']"
61,Weak-star lower semicontinuity in $L^\infty$,Weak-star lower semicontinuity in,L^\infty,Let $u_n \rightharpoonup^* u$ in $L^\infty(\Omega)$. Do we get something like $$\lVert u \rVert_{L^\infty} \leq \liminf_{n \to \infty} \lVert u_n \rVert_{L^\infty}$$ i.e. a weak-star lower semicontinuity? This is because I want to know if $\lVert u_n \rVert_{L^\infty} \leq C$ for all $n$ if the limit $u$ also satisfies this. Is this property true for Banach spaces in general?,Let $u_n \rightharpoonup^* u$ in $L^\infty(\Omega)$. Do we get something like $$\lVert u \rVert_{L^\infty} \leq \liminf_{n \to \infty} \lVert u_n \rVert_{L^\infty}$$ i.e. a weak-star lower semicontinuity? This is because I want to know if $\lVert u_n \rVert_{L^\infty} \leq C$ for all $n$ if the limit $u$ also satisfies this. Is this property true for Banach spaces in general?,,"['functional-analysis', 'lp-spaces', 'weak-convergence']"
62,"Is ""Functional Analysis"" by ""Yosida"" a good book for self study?","Is ""Functional Analysis"" by ""Yosida"" a good book for self study?",,"I was wishing to start studying by myself the book Functional Analysis by Yosida , does anyone have already used it, is it a good reference?","I was wishing to start studying by myself the book Functional Analysis by Yosida , does anyone have already used it, is it a good reference?",,"['functional-analysis', 'reference-request', 'self-learning']"
63,The Principle of Condensation of Singularities,The Principle of Condensation of Singularities,,"Let $X$, $Y$ be Banach spaces and $\{T_{jk} : j,k \in\Bbb N\}$ be bounded linear maps from $X$ to $Y$. Suppose that for each $k$ there exists $x\in X$ such that $\sup\{\lVert T_{jk} x\rVert : j \in\Bbb N\} =+\infty$. Then there is an $x$ (indeed a residual set of $x$'s) such that $\sup\{\lVert T_{jk} x\rVert : j \in\Bbb N\} =+ \infty$ for all $k$.","Let $X$, $Y$ be Banach spaces and $\{T_{jk} : j,k \in\Bbb N\}$ be bounded linear maps from $X$ to $Y$. Suppose that for each $k$ there exists $x\in X$ such that $\sup\{\lVert T_{jk} x\rVert : j \in\Bbb N\} =+\infty$. Then there is an $x$ (indeed a residual set of $x$'s) such that $\sup\{\lVert T_{jk} x\rVert : j \in\Bbb N\} =+ \infty$ for all $k$.",,"['functional-analysis', 'banach-spaces', 'operator-theory', 'normed-spaces', 'baire-category']"
64,Square root of compactly supported C-infinity function,Square root of compactly supported C-infinity function,,"Given $u \in \mathcal{C}^\infty_0(\mathbb{R}^n)$, $u \geq 0$ everywhere, is $v(x) = \sqrt{u(x)}$ also in $\mathcal{C}^\infty_0$? It is clear that the only problematic points are the boundary of the support, where one must show that all the derivatives vanish. I would appreciate any help!","Given $u \in \mathcal{C}^\infty_0(\mathbb{R}^n)$, $u \geq 0$ everywhere, is $v(x) = \sqrt{u(x)}$ also in $\mathcal{C}^\infty_0$? It is clear that the only problematic points are the boundary of the support, where one must show that all the derivatives vanish. I would appreciate any help!",,"['functional-analysis', 'examples-counterexamples', 'distribution-theory']"
65,Must a complete space be locally compact?,Must a complete space be locally compact?,,"There are two versions of second category space: one is complete metric space, the other is locally compact space. As we know, an open interval is locally compact but not complete. But how about the opposite? Must a complete space be locally compact? If not, must a complete topological vector space  be second category?","There are two versions of second category space: one is complete metric space, the other is locally compact space. As we know, an open interval is locally compact but not complete. But how about the opposite? Must a complete space be locally compact? If not, must a complete topological vector space  be second category?",,"['functional-analysis', 'topological-vector-spaces']"
66,What does Trotter Product Formula mean?,What does Trotter Product Formula mean?,,"For some reason, I have to work with Trotter product formula recently, but I do not have a strong background in functional analysis. The following is the statement of the formula from MathWorld When A and B are self-adjoint operators,    $$ e^{t(A+B)} = \lim_{n \to +\infty}(e^{tA/n}e^{tB/n})^n $$ My questions are: What does the exponential of an operator mean precisely? How to interpret the convergence? In terms of some norm?","For some reason, I have to work with Trotter product formula recently, but I do not have a strong background in functional analysis. The following is the statement of the formula from MathWorld When A and B are self-adjoint operators,    $$ e^{t(A+B)} = \lim_{n \to +\infty}(e^{tA/n}e^{tB/n})^n $$ My questions are: What does the exponential of an operator mean precisely? How to interpret the convergence? In terms of some norm?",,"['functional-analysis', 'semigroup-of-operators']"
67,"Spectrum of the ""discrete Laplacian operator""","Spectrum of the ""discrete Laplacian operator""",,"In numerical analysis, the discrete Laplacian operator $\Delta$ on $\ell^2({\bf Z})$ can be written in terms of the shift operator $\Delta=S+S^*-2I$ where $S$ is the right shift operator. Since it is self-adjoint, the spectrum should be in the real line. On the other hand, simple calculation show that one can write the operator $\Delta-\lambda$ as the following $\Delta-\lambda=-\frac{1}{\mu}(S-\mu)(S^*-\mu)$ (*) where $\mu$ is such that $\mu+\frac{1}{\mu}=2+\lambda$. (*) can give the intuition that the spectrum $\sigma(\Delta)=\{\mu+\frac{1}{\mu}:|\mu|=1\}-2$ However, for proving it, (*) seems not work. Here are my questions: Is   $\sigma(\Delta)=\{\mu+\frac{1}{\mu}:|\mu|=1\}-2$   true? Does the fact that $\sigma(S)$ is purely continuous imply that $\sigma(\Delta)$ is also continuous?","In numerical analysis, the discrete Laplacian operator $\Delta$ on $\ell^2({\bf Z})$ can be written in terms of the shift operator $\Delta=S+S^*-2I$ where $S$ is the right shift operator. Since it is self-adjoint, the spectrum should be in the real line. On the other hand, simple calculation show that one can write the operator $\Delta-\lambda$ as the following $\Delta-\lambda=-\frac{1}{\mu}(S-\mu)(S^*-\mu)$ (*) where $\mu$ is such that $\mu+\frac{1}{\mu}=2+\lambda$. (*) can give the intuition that the spectrum $\sigma(\Delta)=\{\mu+\frac{1}{\mu}:|\mu|=1\}-2$ However, for proving it, (*) seems not work. Here are my questions: Is   $\sigma(\Delta)=\{\mu+\frac{1}{\mu}:|\mu|=1\}-2$   true? Does the fact that $\sigma(S)$ is purely continuous imply that $\sigma(\Delta)$ is also continuous?",,['functional-analysis']
68,C$^{*}$-algebra acting irreducibly on the finite-dimensional space $\mathbb{C}^{n}$ must be $M_{n}(\mathbb{C})$,C-algebra acting irreducibly on the finite-dimensional space  must be,^{*} \mathbb{C}^{n} M_{n}(\mathbb{C}),"Suppose $A\subseteq M_{n}(\mathbb{C})$ is a C$^{*}$-algebra acting irreducibly on the finite-dimensional space $\mathbb{C}^{n}$. I.e., there are no non-trivial subspaces of $\mathbb{C}^{n}$ invariant under $A$, or, equivalently, $W_{v}:=\operatorname{span}\{av:a\in A\}=\mathbb{C}^{n}$ for any $v\in\mathbb{C}^{n}$. Is there a straightforward way to see that $A=M_{n}(\mathbb{C})$?","Suppose $A\subseteq M_{n}(\mathbb{C})$ is a C$^{*}$-algebra acting irreducibly on the finite-dimensional space $\mathbb{C}^{n}$. I.e., there are no non-trivial subspaces of $\mathbb{C}^{n}$ invariant under $A$, or, equivalently, $W_{v}:=\operatorname{span}\{av:a\in A\}=\mathbb{C}^{n}$ for any $v\in\mathbb{C}^{n}$. Is there a straightforward way to see that $A=M_{n}(\mathbb{C})$?",,"['functional-analysis', 'operator-theory', 'representation-theory', 'operator-algebras', 'c-star-algebras']"
69,Jensen's inequality for random functions in a Banach space,Jensen's inequality for random functions in a Banach space,,"Suppose I have a Banach space of functions over $\mathbb{R}$ with norm $||\cdot||$. Suppose that $f$ is a random function that takes values in this space such that $||f||\leq 1$. Suppose that for all $x\in\mathbb{R}$ $E[f(x)]$ exists and is finite (where the expectation is over the random function $f$). Can I then apply Jensen's inequality to get $||E[f]||\leq E[||f||] \leq 1$? Where $E[f]$ is the function of $\mathbb{R}$ defined by $E[f](x)=E[f(x)]$. Moreover, suppose that I do not know that $E[f(x)]$ is finite for all $x$. Can I then replace $f$ with some related function $\hat{f}$ so that $E[\hat{f}(x)]$ exists and is finite for all $x$ and $||\hat{f}-f||=0$. In the case where the norm is an $L_p(\mu)$ norm for some measure $\mu$ over $\mathbb{R}$, then $||\hat{f}-f||=0$ means that the two functions differ only on a subset of $\mathbb{R}$ of $\mu$ measure 0. I think I can prove the results above directly for $L_p$ norms (and easily for the supremum norm) but I wondered if they might be known to hold more generally either for all norms or perhaps all monotone norms. Any help greatly appreciated!","Suppose I have a Banach space of functions over $\mathbb{R}$ with norm $||\cdot||$. Suppose that $f$ is a random function that takes values in this space such that $||f||\leq 1$. Suppose that for all $x\in\mathbb{R}$ $E[f(x)]$ exists and is finite (where the expectation is over the random function $f$). Can I then apply Jensen's inequality to get $||E[f]||\leq E[||f||] \leq 1$? Where $E[f]$ is the function of $\mathbb{R}$ defined by $E[f](x)=E[f(x)]$. Moreover, suppose that I do not know that $E[f(x)]$ is finite for all $x$. Can I then replace $f$ with some related function $\hat{f}$ so that $E[\hat{f}(x)]$ exists and is finite for all $x$ and $||\hat{f}-f||=0$. In the case where the norm is an $L_p(\mu)$ norm for some measure $\mu$ over $\mathbb{R}$, then $||\hat{f}-f||=0$ means that the two functions differ only on a subset of $\mathbb{R}$ of $\mu$ measure 0. I think I can prove the results above directly for $L_p$ norms (and easily for the supremum norm) but I wondered if they might be known to hold more generally either for all norms or perhaps all monotone norms. Any help greatly appreciated!",,"['functional-analysis', 'measure-theory', 'random-functions', 'jensen-inequality']"
70,"Show that in a complex Hilbert space, T normal bounded linear operator, $\| T^2 \| =\| T \| ^2$","Show that in a complex Hilbert space, T normal bounded linear operator,",\| T^2 \| =\| T \| ^2,"So,  as a part of a problem, I've been asked to prove that if $H$ is a complex Hilbert space and $T\in L(H)$ is normal,  then $\| T^2 \| =\| T \| ^2$  (Operator norm) Context: This is part (b) in a three part problem obviously designed to build to a final result.  The final result being this is good for any integer $n$, and the first part (already proved) was that  $$T \text { normal } \iff \forall x\in H,\| T(x)\|=\|T^*(x)\|$$ So,  here's my attempt at a proof of part b: Since the operator norm is submultiplicative, we have $\|T^2\|\le \| T\| ^2$. Then from a theorem in Kreyszig's Introductory Functional Analysis with Applications (Thm 3.94(e), page 198) we have  $$\|TT^*\|=\|T\|^2$$, and using submultiplicativity again, combined with them 3.92 (p 196) that states $\|T^*\|=\|T\|$, we have $$\|T\|^2\le \|T\|\cdot \|T^*\|=\|T\|^2$$ hence $\|T^2\|=\|T\|^2$  as desired. Now, the problem is...none of theorems I have used require $T$ to be normal (Or the space to be complex).  Nor did I use part a.   So....either my proof is wrong,  or this statement actually holds for all bounded linear operators on any Hilbert space...which I doubt, so I think I made a mistake somewhere.   Any advice?","So,  as a part of a problem, I've been asked to prove that if $H$ is a complex Hilbert space and $T\in L(H)$ is normal,  then $\| T^2 \| =\| T \| ^2$  (Operator norm) Context: This is part (b) in a three part problem obviously designed to build to a final result.  The final result being this is good for any integer $n$, and the first part (already proved) was that  $$T \text { normal } \iff \forall x\in H,\| T(x)\|=\|T^*(x)\|$$ So,  here's my attempt at a proof of part b: Since the operator norm is submultiplicative, we have $\|T^2\|\le \| T\| ^2$. Then from a theorem in Kreyszig's Introductory Functional Analysis with Applications (Thm 3.94(e), page 198) we have  $$\|TT^*\|=\|T\|^2$$, and using submultiplicativity again, combined with them 3.92 (p 196) that states $\|T^*\|=\|T\|$, we have $$\|T\|^2\le \|T\|\cdot \|T^*\|=\|T\|^2$$ hence $\|T^2\|=\|T\|^2$  as desired. Now, the problem is...none of theorems I have used require $T$ to be normal (Or the space to be complex).  Nor did I use part a.   So....either my proof is wrong,  or this statement actually holds for all bounded linear operators on any Hilbert space...which I doubt, so I think I made a mistake somewhere.   Any advice?",,"['functional-analysis', 'hilbert-spaces', 'normed-spaces', 'normal-operator']"
71,Difference between total orthonormal set and basis,Difference between total orthonormal set and basis,,"I'm learning about Hilbert spaces and related things from the book ""Introductory functional analysis with applications"". Now I just read the following sentence, which I don't quite understand: ""A total orthonormal family in $X$ is sometimes called an orthonormal basis for $X$. However, it is important to note that this is not a basis, in the sense of algebra, for $X$ as a vector space, unless $X$ is finite dimensional."" But I think that a total orthonormal sequence must be a Schauder basis, basically just from the definition. So does the author just mean that the basis is not a Hamel basis? Or is there something more subtle going on here that I'm not seeing?","I'm learning about Hilbert spaces and related things from the book ""Introductory functional analysis with applications"". Now I just read the following sentence, which I don't quite understand: ""A total orthonormal family in $X$ is sometimes called an orthonormal basis for $X$. However, it is important to note that this is not a basis, in the sense of algebra, for $X$ as a vector space, unless $X$ is finite dimensional."" But I think that a total orthonormal sequence must be a Schauder basis, basically just from the definition. So does the author just mean that the basis is not a Hamel basis? Or is there something more subtle going on here that I'm not seeing?",,"['functional-analysis', 'hilbert-spaces']"
72,Difference between an eigenvalue and a spectral value,Difference between an eigenvalue and a spectral value,,"What is the difference in the definition of a spectral value and an eigenvalue. My notes from functional analysis says $\lambda$ is an eigenvalue of an operator $A$ if $\,\exists \, x \in \mathbb{C^n}$ such that $$Ax = \lambda x$$ This implies $(A - \lambda I)x = 0  \Rightarrow \ker(A - \lambda I) \neq {0}$. This is equivalent   of saying that $A$ is not injective. On the other hand, the definition of a spectral value is $\lambda$ is called a spectral value of $A$ if $A - \lambda I$ is not   invertible. What is the difference here? How is it that some operators can have spectral values and not eigenvalues (eigenvalues $\subset$ spectrum(A)) and lastly, how do they conincide when the space is finite dimensional ?","What is the difference in the definition of a spectral value and an eigenvalue. My notes from functional analysis says $\lambda$ is an eigenvalue of an operator $A$ if $\,\exists \, x \in \mathbb{C^n}$ such that $$Ax = \lambda x$$ This implies $(A - \lambda I)x = 0  \Rightarrow \ker(A - \lambda I) \neq {0}$. This is equivalent   of saying that $A$ is not injective. On the other hand, the definition of a spectral value is $\lambda$ is called a spectral value of $A$ if $A - \lambda I$ is not   invertible. What is the difference here? How is it that some operators can have spectral values and not eigenvalues (eigenvalues $\subset$ spectrum(A)) and lastly, how do they conincide when the space is finite dimensional ?",,"['functional-analysis', 'spectral-theory']"
73,Bounded linear operator commuting with every compact operators,Bounded linear operator commuting with every compact operators,,"Let $A$ be a bounded linear operator on the Banach space $X$. Assuming that $AK = KA$ for every compact operator $K$, how do I show that $A$ must be a scalar multiple of the identity, i.e., we have $A = \lambda I$ for some number $\lambda$. So far I attempt to solve this using Schur's lemma but I can't reason that $A$ will have an eigenvalue in the first place for the lemma to applies (the book where I got the problem from doesn't even specify if the field is real or complex). Any hint or help is highly appreciated.","Let $A$ be a bounded linear operator on the Banach space $X$. Assuming that $AK = KA$ for every compact operator $K$, how do I show that $A$ must be a scalar multiple of the identity, i.e., we have $A = \lambda I$ for some number $\lambda$. So far I attempt to solve this using Schur's lemma but I can't reason that $A$ will have an eigenvalue in the first place for the lemma to applies (the book where I got the problem from doesn't even specify if the field is real or complex). Any hint or help is highly appreciated.",,"['functional-analysis', 'operator-theory', 'compact-operators']"
74,When is $V=U\oplus U^{\perp}$?,When is ?,V=U\oplus U^{\perp},"Let $V$ be a (infinite dimensional) vector space with inner product $(,)$ and $V$ may not be complete with the metric induced from the norm. Let $U$ be a subspace of $V$. What is the necessary and sufficient condition that can guarantee $$ U\oplus U^{\perp}=V? $$ Is the hypothesis $U$ has finite codimension enough? Update: As others pointed out, $U$ is closed or $U$ has finite codimension is not enough. I `know' that the following condition is enough: If there exist a finite dimensional subspace $W\subseteq V$ such that $W^{\perp}\subseteq U$, then $V=U\oplus U^{\perp}$. But neither can I prove it, nor do I know a better condition to replace it or show the criterion is wrong. So I ask at here.","Let $V$ be a (infinite dimensional) vector space with inner product $(,)$ and $V$ may not be complete with the metric induced from the norm. Let $U$ be a subspace of $V$. What is the necessary and sufficient condition that can guarantee $$ U\oplus U^{\perp}=V? $$ Is the hypothesis $U$ has finite codimension enough? Update: As others pointed out, $U$ is closed or $U$ has finite codimension is not enough. I `know' that the following condition is enough: If there exist a finite dimensional subspace $W\subseteq V$ such that $W^{\perp}\subseteq U$, then $V=U\oplus U^{\perp}$. But neither can I prove it, nor do I know a better condition to replace it or show the criterion is wrong. So I ask at here.",,"['functional-analysis', 'vector-spaces', 'inner-products']"
75,Orthonormal Sets in Hilbert Spaces,Orthonormal Sets in Hilbert Spaces,,"let $H$ be a Hilbert space and let M be a dense linear subspace of H. Can we find a complete orthonormal set $\{u_{\alpha}: \alpha \in A\}$ for H in M? I think the answer is negative in general, but I cannot find a counterexample. Thank you very much in advance for your help.","let $H$ be a Hilbert space and let M be a dense linear subspace of H. Can we find a complete orthonormal set $\{u_{\alpha}: \alpha \in A\}$ for H in M? I think the answer is negative in general, but I cannot find a counterexample. Thank you very much in advance for your help.",,['functional-analysis']
76,"Why is gradient boundedness sufficient to have $u_n \to u$ in $W^{1,p}$?",Why is gradient boundedness sufficient to have  in ?,"u_n \to u W^{1,p}","This is a remark from Brezis' book, ch. 9 (pag. 264). Let $\Omega \subset \mathbb R^N$ an open set and $(u_n)_n$ a sequence   in $W^{1,p}(\Omega)$ such that $u_n \to u$ in $L^p(\Omega)$. If $\nabla u_n$ converges to some limit in $L^p(\Omega)^N$ then $u_n \to u$ in $W^{1,p}$.    If $p \in [1,+\infty)$ it suffices to know only   that $u_n \to u$ in $L^p(\Omega)$ and that $(\nabla u_n)$ is bounded in   $L^p(\Omega)^N$, i.e. there exists $C>0$ s. t.  $$ \Vert \nabla u_n \Vert_{L^p} \le C $$ in order to conclude that $u_n \to u$ in   $W^{1,p}$. Why is this true? I have thought to Banach Alaoglu theorem: since $p\ne 1$ I can consider on $L^p$ the weak-$\star$ topology; then, due to compactness of the (unit) ball, from the bounded sequence $(\nabla u_n)$ I can extract a convergent subsequence. But I'm not sure of what I am doing and I need your kind help. Thanks in advance.","This is a remark from Brezis' book, ch. 9 (pag. 264). Let $\Omega \subset \mathbb R^N$ an open set and $(u_n)_n$ a sequence   in $W^{1,p}(\Omega)$ such that $u_n \to u$ in $L^p(\Omega)$. If $\nabla u_n$ converges to some limit in $L^p(\Omega)^N$ then $u_n \to u$ in $W^{1,p}$.    If $p \in [1,+\infty)$ it suffices to know only   that $u_n \to u$ in $L^p(\Omega)$ and that $(\nabla u_n)$ is bounded in   $L^p(\Omega)^N$, i.e. there exists $C>0$ s. t.  $$ \Vert \nabla u_n \Vert_{L^p} \le C $$ in order to conclude that $u_n \to u$ in   $W^{1,p}$. Why is this true? I have thought to Banach Alaoglu theorem: since $p\ne 1$ I can consider on $L^p$ the weak-$\star$ topology; then, due to compactness of the (unit) ball, from the bounded sequence $(\nabla u_n)$ I can extract a convergent subsequence. But I'm not sure of what I am doing and I need your kind help. Thanks in advance.",,"['functional-analysis', 'sobolev-spaces']"
77,If $x_n \rightarrow x_0$ weakly then show that lim inf $\|x_n\| \ge \|x_0\|$,If  weakly then show that lim inf,x_n \rightarrow x_0 \|x_n\| \ge \|x_0\|,"How does one show that if $x_n \to x_0$ weakly, then $\liminf ||x_n|| \geq ||x_0||$? I'm just doing additional problems from a book to try and prepare for a final. Unfortunately, I have really gotten nowhere with this one, so I'm afraid I just have to ask for help from the get go. Any suggestions?","How does one show that if $x_n \to x_0$ weakly, then $\liminf ||x_n|| \geq ||x_0||$? I'm just doing additional problems from a book to try and prepare for a final. Unfortunately, I have really gotten nowhere with this one, so I'm afraid I just have to ask for help from the get go. Any suggestions?",,"['functional-analysis', 'weak-convergence']"
78,Dual space of Bochner space,Dual space of Bochner space,,"Let $B$ be a refexive Banach space. I want to show that  $$(L^2(0,T;B))^* = L^2(0,T;B^*)$$ and that  the dual pairing is $$\langle F,f \rangle_{L^2(0,T;B^*), L^2(0,T;B)} = \int_0^T \langle F(t), f(t) \rangle_{B^*,B}.$$ Can anyone help me with either part? Thanks.","Let $B$ be a refexive Banach space. I want to show that  $$(L^2(0,T;B))^* = L^2(0,T;B^*)$$ and that  the dual pairing is $$\langle F,f \rangle_{L^2(0,T;B^*), L^2(0,T;B)} = \int_0^T \langle F(t), f(t) \rangle_{B^*,B}.$$ Can anyone help me with either part? Thanks.",,"['functional-analysis', 'banach-spaces']"
79,Parallelogram law valid in banach spaces?,Parallelogram law valid in banach spaces?,,It is known that the parallelogram law $\|x-y\|^2+\|x+y\|^2 = 2(\|x\|^2 + \|y\|^2)$ holds in any space with an inner product (the norm being induced by this inner product). Is this formula valid in general Banach spaces? Or are there counterexamples? Thank you! :),It is known that the parallelogram law $\|x-y\|^2+\|x+y\|^2 = 2(\|x\|^2 + \|y\|^2)$ holds in any space with an inner product (the norm being induced by this inner product). Is this formula valid in general Banach spaces? Or are there counterexamples? Thank you! :),,"['functional-analysis', 'banach-spaces', 'hilbert-spaces']"
80,How to prove that $\lVert \Delta u \rVert_{L^2} + \lVert u \rVert_{L^2}$ and $\lVert u \rVert_{H^2}$ are equivalent norms?,How to prove that  and  are equivalent norms?,\lVert \Delta u \rVert_{L^2} + \lVert u \rVert_{L^2} \lVert u \rVert_{H^2},How to prove that $\lVert \Delta u \rVert_{L^2} + \lVert u \rVert_{L^2}$ and $\lVert u \rVert_{H^2}$ are equivalent norms on a bounded domain? I hear there is a way to do it by RRT but any other way is fine. Thanks.,How to prove that $\lVert \Delta u \rVert_{L^2} + \lVert u \rVert_{L^2}$ and $\lVert u \rVert_{H^2}$ are equivalent norms on a bounded domain? I hear there is a way to do it by RRT but any other way is fine. Thanks.,,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces']"
81,why do successive eigenfunctions have more oscillation?,why do successive eigenfunctions have more oscillation?,,"I was told the following argument as to why successive eigenfunctions tend to have more oscillations: Suppose (without worrying about why) that the first eigenfunction has the least oscillation. The second eigenfunction is orthogonal to the first, thus it must have both positive and negative parts on the region where the 1st eigenfunction is positive, and similarly for the     region corresponding to the negative part of the 1st eigenfunction (if any). Thus each eigenfunction has more oscillations than the previous. Although I certainly believe the conclusion is true, I do not quite see that this is a solid argument. Suppose the first eigenfunction is $\sin(x)$. Then the second eigenfunction can be $-\sin(x)$, which is orthogonal to the first. So, one can find an orthogonal function without using step 2 in the argument, so (to me) the argument fails.  [Edit: a big error here-- I don't know how I was thinking that sin, -sin are orthogonal, they certainly are not] Is there a better intuitive argument for ``successive eigenfunctions have  more oscillation''? (Or, point out the flaw in my thinking or description)","I was told the following argument as to why successive eigenfunctions tend to have more oscillations: Suppose (without worrying about why) that the first eigenfunction has the least oscillation. The second eigenfunction is orthogonal to the first, thus it must have both positive and negative parts on the region where the 1st eigenfunction is positive, and similarly for the     region corresponding to the negative part of the 1st eigenfunction (if any). Thus each eigenfunction has more oscillations than the previous. Although I certainly believe the conclusion is true, I do not quite see that this is a solid argument. Suppose the first eigenfunction is $\sin(x)$. Then the second eigenfunction can be $-\sin(x)$, which is orthogonal to the first. So, one can find an orthogonal function without using step 2 in the argument, so (to me) the argument fails.  [Edit: a big error here-- I don't know how I was thinking that sin, -sin are orthogonal, they certainly are not] Is there a better intuitive argument for ``successive eigenfunctions have  more oscillation''? (Or, point out the flaw in my thinking or description)",,"['functional-analysis', 'eigenvalues-eigenvectors']"
82,Bochner integral = 0 iff $f = 0$,Bochner integral = 0 iff,f = 0,"This problem is about integrals of functions taking values in a Banach space. Let $f \in L^1(X,S,\mu,B)$ where $X$ is a set with a $\sigma$-algebra $S$ and a measure $\mu$. Function $f$ takes values in a Banach space $B$. If $\int_E f(x)d\mu(x) = 0$ for all $E \in S$, prove that $f = 0$ a.e. Note that since $f$ takes values in $B$, $\int_E f(x)d\mu(x)$ also takes values in $B$, i.e. the ""$0$"" is the zero of the Banach space $B$. In case of reals, there is an ordering and considering $f^{-1}([0, \infty)) \in S$ its easy to see that $f$ must be $0$ a.e. I'm unsure how to proceed for a Banach space.","This problem is about integrals of functions taking values in a Banach space. Let $f \in L^1(X,S,\mu,B)$ where $X$ is a set with a $\sigma$-algebra $S$ and a measure $\mu$. Function $f$ takes values in a Banach space $B$. If $\int_E f(x)d\mu(x) = 0$ for all $E \in S$, prove that $f = 0$ a.e. Note that since $f$ takes values in $B$, $\int_E f(x)d\mu(x)$ also takes values in $B$, i.e. the ""$0$"" is the zero of the Banach space $B$. In case of reals, there is an ordering and considering $f^{-1}([0, \infty)) \in S$ its easy to see that $f$ must be $0$ a.e. I'm unsure how to proceed for a Banach space.",,"['functional-analysis', 'measure-theory', 'banach-spaces']"
83,pythagoras theorem for $L_p$ spaces,pythagoras theorem for  spaces,L_p,"Let's consider $L_2(\mathbb{R}^n)$. Let $Y$ be a non empty closed subspace of $L_2(\mathbb{R}^n)$. Let $x\notin Y$. Let $y^*$ be the best approximation of $x$ on $Y$, i.e., $\|x-y^*\|_2=\inf_{y\in Y}\|x-y\|_2$. We know then that, $x-y^*$ would be orthogonal to $Y$ and hence from parallelogram law, one can deduce the pythagoras theorem: $$\|x-y\|_2^2=\|x-y^*\|_2^2+\|y^*-y\|_2^2 \text{ for } y\in Y$$ I'm wondering whether the same kind of result would be true for $L_p(\mathbb{R}^n)$, $p\ge 1$, $p\neq 2$ also, i.e., whether $$\|x-y\|_p^p=\|x-y^*\|_p^p+\|y^*-y\|_p^p $$ I think its not possible to deduce from the parallelogram law as we have only inequality in parallelogram law in $L_p(\mathbb{R}^n)$ and there's no notion of orthogonality in $L_p(\mathbb{R}^n)$ for $p\neq 2$. But I think there may be some other way to get the result. At least mentioning some reference is appreciated.","Let's consider $L_2(\mathbb{R}^n)$. Let $Y$ be a non empty closed subspace of $L_2(\mathbb{R}^n)$. Let $x\notin Y$. Let $y^*$ be the best approximation of $x$ on $Y$, i.e., $\|x-y^*\|_2=\inf_{y\in Y}\|x-y\|_2$. We know then that, $x-y^*$ would be orthogonal to $Y$ and hence from parallelogram law, one can deduce the pythagoras theorem: $$\|x-y\|_2^2=\|x-y^*\|_2^2+\|y^*-y\|_2^2 \text{ for } y\in Y$$ I'm wondering whether the same kind of result would be true for $L_p(\mathbb{R}^n)$, $p\ge 1$, $p\neq 2$ also, i.e., whether $$\|x-y\|_p^p=\|x-y^*\|_p^p+\|y^*-y\|_p^p $$ I think its not possible to deduce from the parallelogram law as we have only inequality in parallelogram law in $L_p(\mathbb{R}^n)$ and there's no notion of orthogonality in $L_p(\mathbb{R}^n)$ for $p\neq 2$. But I think there may be some other way to get the result. At least mentioning some reference is appreciated.",,"['functional-analysis', 'lp-spaces']"
84,Weak convergences of measurable functions and of measures,Weak convergences of measurable functions and of measures,,"My question is ""how weak convergences of measurable functions is defined?"" There seems to be two different definitions which are both based on weak convergence of measures generated by the measurable functions, but differ in how the measurable functions generate their new measures. In terms of the new measure $\nu(A):=\int_A f \,d\mu$ generated from a measurable function $f$ wrt a measure $\mu$ on its domain: From ""Weak Compactness"" in Section 19 ""The $L^p$ spaces"" of ""Probability and Measure"" by Billingsley: Suppose that $f$ and $f_n$ are elements of $L^p(\Omega,  \mathcal{F},\mu)$. If $\int f \times g \, d\mu= \lim_{n\rightarrow      \infty} \int f \times g \, d\mu$ for each $g$ in $L^q(\Omega,      \mathcal{F},\mu)$ with $1/p + 1/q = 1$, then $f_n$ converges weakly   to   $f$. At the end of Section 4.1 of ""A Course in Probability Theory"" by Kai Lai Chung, weak convergence of random variables in $L^1$ space is also defined similarly to Billingsley's. In terms of the pushforward measure of a measurable function: In Wikipedia , In this case the term weak convergence is preferable (see weak   convergence of measures), and we say that a sequence of random   elements $\{X_n\}$ converges weakly to $X$  if $$          \operatorname{E}^*h(X_n) \to \operatorname{E}\,h(X)  $$ for all continuous bounded functions $h(·)$. Here $E^*$ denotes the   outer   expectation, that is the expectation of a “smallest measurable   function g that dominates $h(X_n)$”. Also from Wikipedia : Let $(\Omega, \mathcal{F}, P)$ be a probability space and   $\textbf{X}$ be a metric space. If $X_n, X: Ω → \textbf{X}$ is a   sequence of random variables then $X_n$ is said to converge weakly (or   in distribution or in law) to $X$ as $n → ∞$ if the sequence of   pushforward measures $(X_n)_∗(P)$ converges weakly to $X_∗(P)$ in the   sense of weak convergence of measures on $\textbf{X}$. I wonder if the two definitions of weak convergence of measurable functions are equivalent? Why are there two different definitions for the same concept? Thanks and regards!","My question is ""how weak convergences of measurable functions is defined?"" There seems to be two different definitions which are both based on weak convergence of measures generated by the measurable functions, but differ in how the measurable functions generate their new measures. In terms of the new measure $\nu(A):=\int_A f \,d\mu$ generated from a measurable function $f$ wrt a measure $\mu$ on its domain: From ""Weak Compactness"" in Section 19 ""The $L^p$ spaces"" of ""Probability and Measure"" by Billingsley: Suppose that $f$ and $f_n$ are elements of $L^p(\Omega,  \mathcal{F},\mu)$. If $\int f \times g \, d\mu= \lim_{n\rightarrow      \infty} \int f \times g \, d\mu$ for each $g$ in $L^q(\Omega,      \mathcal{F},\mu)$ with $1/p + 1/q = 1$, then $f_n$ converges weakly   to   $f$. At the end of Section 4.1 of ""A Course in Probability Theory"" by Kai Lai Chung, weak convergence of random variables in $L^1$ space is also defined similarly to Billingsley's. In terms of the pushforward measure of a measurable function: In Wikipedia , In this case the term weak convergence is preferable (see weak   convergence of measures), and we say that a sequence of random   elements $\{X_n\}$ converges weakly to $X$  if $$          \operatorname{E}^*h(X_n) \to \operatorname{E}\,h(X)  $$ for all continuous bounded functions $h(·)$. Here $E^*$ denotes the   outer   expectation, that is the expectation of a “smallest measurable   function g that dominates $h(X_n)$”. Also from Wikipedia : Let $(\Omega, \mathcal{F}, P)$ be a probability space and   $\textbf{X}$ be a metric space. If $X_n, X: Ω → \textbf{X}$ is a   sequence of random variables then $X_n$ is said to converge weakly (or   in distribution or in law) to $X$ as $n → ∞$ if the sequence of   pushforward measures $(X_n)_∗(P)$ converges weakly to $X_∗(P)$ in the   sense of weak convergence of measures on $\textbf{X}$. I wonder if the two definitions of weak convergence of measurable functions are equivalent? Why are there two different definitions for the same concept? Thanks and regards!",,"['measure-theory', 'functional-analysis', 'probability-theory']"
85,Original proof of Uniform Boundedness Principle (Banach Steinhaus) and related questions,Original proof of Uniform Boundedness Principle (Banach Steinhaus) and related questions,,"Can someone please provide me with any of the things listed below : a list of different proofs of (some version of) the Uniform Boundedness Principle (also known as the Banach Steinhaus theorem), I already know Rudin's proof that seems quite general, a proof in the case of Banach spaces found in Haïm Brezis' book on functional analysis (also based on Baire Category) and a different proof altogether (making no use of Baire Category) found here https://pantherfile.uwm.edu/kevinm/www/qtbook/notes/pub.pdf . if possible the original proof and formulation of the theorem. The reason I ask is that I don't understand how people realised completeness was a necessary condition, also I wonder if using the Baire Category Theorem was standard in Banach's time. Finally, what motivating examples did Banach or Steinhaus consider?","Can someone please provide me with any of the things listed below : a list of different proofs of (some version of) the Uniform Boundedness Principle (also known as the Banach Steinhaus theorem), I already know Rudin's proof that seems quite general, a proof in the case of Banach spaces found in Haïm Brezis' book on functional analysis (also based on Baire Category) and a different proof altogether (making no use of Baire Category) found here https://pantherfile.uwm.edu/kevinm/www/qtbook/notes/pub.pdf . if possible the original proof and formulation of the theorem. The reason I ask is that I don't understand how people realised completeness was a necessary condition, also I wonder if using the Baire Category Theorem was standard in Banach's time. Finally, what motivating examples did Banach or Steinhaus consider?",,"['functional-analysis', 'reference-request', 'banach-spaces', 'math-history', 'topological-vector-spaces']"
86,Mixed Lebesgue spaces: information needed,Mixed Lebesgue spaces: information needed,,"Let $\Omega_t$ and $\Omega_x$ be two $\sigma$-finite measure spaces. If it makes things easier we can assume that $\Omega_t$ is some interval and $\Omega_x$ some Euclidean space. For each measurable $f\colon \Omega_t \times \Omega_x \to \mathbb{C}$ define $$\lVert f(t, x) \rVert_{L^p_t L^q_x}=\left[\int_{\Omega_t}dt \left(\int_{\Omega_x} \lvert f(t, x) \rvert^q\, dx\right)^\frac{p}{q}\right]^{\frac{1}{p}}.$$ I would like to get some information on the resulting space $L^p_t L^q_x(\Omega_t \times \Omega_x)$, especially: Under what name is it known? Is it the product of some canonical construction? Is there some obvious way to show that it is complete (if true)? Is there any relationship between $\lVert f(t, x) \rVert_{L^p_t L^q_x}$ and $\lVert f(t, x) \rVert_{L^q_x L^p_t}$? Under what circumstances do they coincide? I'm especially after some reference, but answers of any other kind (proofs, hints, conjectures) are welcome. Thank you.","Let $\Omega_t$ and $\Omega_x$ be two $\sigma$-finite measure spaces. If it makes things easier we can assume that $\Omega_t$ is some interval and $\Omega_x$ some Euclidean space. For each measurable $f\colon \Omega_t \times \Omega_x \to \mathbb{C}$ define $$\lVert f(t, x) \rVert_{L^p_t L^q_x}=\left[\int_{\Omega_t}dt \left(\int_{\Omega_x} \lvert f(t, x) \rvert^q\, dx\right)^\frac{p}{q}\right]^{\frac{1}{p}}.$$ I would like to get some information on the resulting space $L^p_t L^q_x(\Omega_t \times \Omega_x)$, especially: Under what name is it known? Is it the product of some canonical construction? Is there some obvious way to show that it is complete (if true)? Is there any relationship between $\lVert f(t, x) \rVert_{L^p_t L^q_x}$ and $\lVert f(t, x) \rVert_{L^q_x L^p_t}$? Under what circumstances do they coincide? I'm especially after some reference, but answers of any other kind (proofs, hints, conjectures) are welcome. Thank you.",,"['reference-request', 'measure-theory', 'functional-analysis']"
87,Uniform mean ergodic theorem,Uniform mean ergodic theorem,,"I'm working in Einsiedler and Ward's book on Ergodic Theory and in Exercise 2.5.4 they want to prove the following $$\lim_{N - M \to \infty} \frac{1}{N - M} \sum_{n = M}^{N - 1} U_T^n f \to P_T f.$$ Now I'm wondering what this limit really says, it must be stronger than pointwise convergence since we can pick $M = 0$. It we let $N = 2n$ and $M = n$, then we seem to get more and more terms but adding them up from the ""tail"". To me it seems that this is a very strong convergence condition or am I wrong? What does the limit intuitively say?","I'm working in Einsiedler and Ward's book on Ergodic Theory and in Exercise 2.5.4 they want to prove the following $$\lim_{N - M \to \infty} \frac{1}{N - M} \sum_{n = M}^{N - 1} U_T^n f \to P_T f.$$ Now I'm wondering what this limit really says, it must be stronger than pointwise convergence since we can pick $M = 0$. It we let $N = 2n$ and $M = n$, then we seem to get more and more terms but adding them up from the ""tail"". To me it seems that this is a very strong convergence condition or am I wrong? What does the limit intuitively say?",,"['functional-analysis', 'hilbert-spaces', 'operator-theory', 'ergodic-theory']"
88,Understanding the roles of rapid decay & smoothness in the Fourier transform,Understanding the roles of rapid decay & smoothness in the Fourier transform,,"1) If we define a rapidly decaying function in the usual way, it says nothing about derivatives; rather, just that its decay beats any polynomial growth. 2) A Schwartz class function is then simply a smooth function that is also rapidly decaying. 2) A Schwartz class function is not only smooth, but it and all of its derivatives are also rapidly decaying. 3) The Fourier transform is an isomorphism from the Schwartz class functions to themselves. This all feels very beautiful and deep, like a truth underlying something much bigger. At first glance it seems like rapid decay is such a powerful condition, and that smoothness is something quite common and boring. Because of these assumptions, I wouldn't have been surprised if the rapid decay condition for Schwartz class functions was the ""more important"" of the two conditions (whatever that means... perhaps that there is a loosening of the condition that could still lead to some interesting analysis? ) But as soon as you take away the smoothness condition, things start to unravel: Obviously $e^{-|x|}$ is rapidly decreasing, but it of course fails to be smooth at $x=0$ . And its Fourier transform ends up being $\frac{2}{1+\omega}$ , which is certainly not rapidly decreasing any longer. Strange... But for all $\epsilon > 0$ , the family of functions $f_{\epsilon}(x) = e^{-\sqrt{\epsilon + x^2}}$ is smooth and rapidly decreasing (hence Schwartz class). Therefore $\widehat{f_\epsilon}(\omega)$ is also Schwartz class, even though $f_\epsilon \to f$ uniformly as $\epsilon \to 0$ . Again, quite strange... We could have also created a compactly supported bump function, $\beta(x)$ , that is identically $1$ on some $\epsilon$ -neighborhood of $x=0$ . Then you can use $1-\beta(x/\epsilon)$ as a family of smooth cutoffs to eliminate the point of non-differentiability: $g_{\epsilon}(x) = (1-\beta(x/\epsilon))e^{-|x|}$ . This does the same thing as before, with $\widehat{g_{\epsilon}}(\omega)$ being Schwartz class for all $\epsilon > 0$ , with $g_{\epsilon} \to g$ as $\epsilon \to 0$ . And even if we go one level deeper and consider a function which is $C^1$ , just not smooth, things aren't any better. Consider the function $h(x) = x|x|e^{-x^2}$ . The exponential term, $e^{-x^2}$ , is a Gaussian which is pretty much as nice as it gets when it comes to Fourier transforms; and the other term, $x|x|$ , has a derivative equal to $2|x|$ and hence it is $C^1$ . But sure enough, $\widehat{h}(\omega)$ involves some polynomial terms and the Dawson function , and ends up being $O\left( \omega^{-3} \right)$ . Similar computations can be done for any function of the form $h_k(x) = x^k |x| e^{-x^2}$ , with $k\in \mathbb{N}$ , where each $h_k \in C^{k}(\mathbb{R})$ , and yet none of these have a Fourier transform that has rapidly decay. So clearly being $C^k$ and rapidly decreasing is still not very much better than simply being $C^0$ and rapidly decreasing; and certainly nowhere close to being as good as being smooth and rapidly decreasing. Again, I'm not disputing any of these facts, and these kinds of phenomena where sequences of ""nice"" functions converge to ""not nice"" functions are abundant in analysis. I'm just looking for some deeper understanding or insight (dare I say, intuition ) as to the role smoothness plays when it comes to Fourier transforms. This then would also beg the question of what role rapid decay has as well? How do these two unrelated ideas come together so perfectly for the Fourier transform? And is there analogous concepts when it comes to the more general Fourier transform on locally compact abelian groups ?","1) If we define a rapidly decaying function in the usual way, it says nothing about derivatives; rather, just that its decay beats any polynomial growth. 2) A Schwartz class function is then simply a smooth function that is also rapidly decaying. 2) A Schwartz class function is not only smooth, but it and all of its derivatives are also rapidly decaying. 3) The Fourier transform is an isomorphism from the Schwartz class functions to themselves. This all feels very beautiful and deep, like a truth underlying something much bigger. At first glance it seems like rapid decay is such a powerful condition, and that smoothness is something quite common and boring. Because of these assumptions, I wouldn't have been surprised if the rapid decay condition for Schwartz class functions was the ""more important"" of the two conditions (whatever that means... perhaps that there is a loosening of the condition that could still lead to some interesting analysis? ) But as soon as you take away the smoothness condition, things start to unravel: Obviously is rapidly decreasing, but it of course fails to be smooth at . And its Fourier transform ends up being , which is certainly not rapidly decreasing any longer. Strange... But for all , the family of functions is smooth and rapidly decreasing (hence Schwartz class). Therefore is also Schwartz class, even though uniformly as . Again, quite strange... We could have also created a compactly supported bump function, , that is identically on some -neighborhood of . Then you can use as a family of smooth cutoffs to eliminate the point of non-differentiability: . This does the same thing as before, with being Schwartz class for all , with as . And even if we go one level deeper and consider a function which is , just not smooth, things aren't any better. Consider the function . The exponential term, , is a Gaussian which is pretty much as nice as it gets when it comes to Fourier transforms; and the other term, , has a derivative equal to and hence it is . But sure enough, involves some polynomial terms and the Dawson function , and ends up being . Similar computations can be done for any function of the form , with , where each , and yet none of these have a Fourier transform that has rapidly decay. So clearly being and rapidly decreasing is still not very much better than simply being and rapidly decreasing; and certainly nowhere close to being as good as being smooth and rapidly decreasing. Again, I'm not disputing any of these facts, and these kinds of phenomena where sequences of ""nice"" functions converge to ""not nice"" functions are abundant in analysis. I'm just looking for some deeper understanding or insight (dare I say, intuition ) as to the role smoothness plays when it comes to Fourier transforms. This then would also beg the question of what role rapid decay has as well? How do these two unrelated ideas come together so perfectly for the Fourier transform? And is there analogous concepts when it comes to the more general Fourier transform on locally compact abelian groups ?",e^{-|x|} x=0 \frac{2}{1+\omega} \epsilon > 0 f_{\epsilon}(x) = e^{-\sqrt{\epsilon + x^2}} \widehat{f_\epsilon}(\omega) f_\epsilon \to f \epsilon \to 0 \beta(x) 1 \epsilon x=0 1-\beta(x/\epsilon) g_{\epsilon}(x) = (1-\beta(x/\epsilon))e^{-|x|} \widehat{g_{\epsilon}}(\omega) \epsilon > 0 g_{\epsilon} \to g \epsilon \to 0 C^1 h(x) = x|x|e^{-x^2} e^{-x^2} x|x| 2|x| C^1 \widehat{h}(\omega) O\left( \omega^{-3} \right) h_k(x) = x^k |x| e^{-x^2} k\in \mathbb{N} h_k \in C^{k}(\mathbb{R}) C^k C^0,"['functional-analysis', 'fourier-transform', 'locally-compact-groups']"
89,Why is a distribution called a distribution?,Why is a distribution called a distribution?,,"I learned in class that distribution $f$ is a continuous mapping from the set of smooth test functions $\phi$ to a real number. Why is this mapping called a ""distribution""? Can you explain to me the intuition/motivation for the name? What is $f$ a distribution of?","I learned in class that distribution is a continuous mapping from the set of smooth test functions to a real number. Why is this mapping called a ""distribution""? Can you explain to me the intuition/motivation for the name? What is a distribution of?",f \phi f,"['functional-analysis', 'terminology', 'distribution-theory']"
90,Is there a noncommutative version of von Neumann's ergodic theorem.,Is there a noncommutative version of von Neumann's ergodic theorem.,,"The two most celebrated ergodic theorems are Birkhoff's ergodic theorem and von Neumann's ergodic theorem. E. C. Lance in his remarkable work ( Ergodic Theorems for Convex Sets and Operator Algebras ) formulated that can be considered to be the noncommutative version of Birkhoff's ergodic theorem, for a von Neumann algebra, $T*$ -automorphism and a faithful $T$ -invariant normal state. I would like to know whether someone has done the same for von Neumann's ergodic theorem. In other words, is there a noncommutative version of von Neumann's ergodic theorem ?","The two most celebrated ergodic theorems are Birkhoff's ergodic theorem and von Neumann's ergodic theorem. E. C. Lance in his remarkable work ( Ergodic Theorems for Convex Sets and Operator Algebras ) formulated that can be considered to be the noncommutative version of Birkhoff's ergodic theorem, for a von Neumann algebra, -automorphism and a faithful -invariant normal state. I would like to know whether someone has done the same for von Neumann's ergodic theorem. In other words, is there a noncommutative version of von Neumann's ergodic theorem ?",T* T,"['functional-analysis', 'measure-theory', 'operator-algebras', 'ergodic-theory', 'von-neumann-algebras']"
91,Conditional Expectation on von Neumann algebras,Conditional Expectation on von Neumann algebras,,"A linear map $\phi$ from a von Neumann algebra M to the subalgebra N is called a conditional expectation when $\phi$ has the following properties. 1) $\phi(I)=I$ , 2) $\phi(x_{1}y x_{2})=x_{1}\phi(y)x_{2}$ whenever $x_{1},x_{2}\in N$ and $y\in M.$ Can anyone explain me why this map is called conditional expectation? How it is related to the classical case? Thanks in advance.","A linear map from a von Neumann algebra M to the subalgebra N is called a conditional expectation when has the following properties. 1) , 2) whenever and Can anyone explain me why this map is called conditional expectation? How it is related to the classical case? Thanks in advance.","\phi \phi \phi(I)=I \phi(x_{1}y x_{2})=x_{1}\phi(y)x_{2} x_{1},x_{2}\in N y\in M.","['functional-analysis', 'conditional-expectation', 'von-neumann-algebras']"
92,Explicit Countable Orthonormal Basis for $L^2(\mathbb{R})$,Explicit Countable Orthonormal Basis for,L^2(\mathbb{R}),"I was working with my thesis and I needed to use the existence of a countable orthonormal basis of $L^2(\mathbb{R}).$ It should be true that the Hilbert Space $L^2(\mathbb{R})$ is separable, this because the measure space $(\mathbb{R},\lambda),$ where $\lambda$ is the Lebesgue measure, is $\sigma-$finite. Now, this implies that there exists a countable orthonormal basis, but this comes from an abstract type of reasoning, i.e. the Zorn's Lemma for the existence of an orthonormal basis and the use of separability to say that it is countable. The question that came up to me is: is there an explicit representation of this basis? The answer should be no, otherwise the use of the continuous Fourier transform doesn't make much sense, but who knows, perhaps there are some good reasons to prefer the continuous transform even if there is a countable basis. My idea was to take inspiration from the system $\{sin(\frac{n x}{m})\}_{n,m\in\mathbb{N}},$ but I don't know how to continue.","I was working with my thesis and I needed to use the existence of a countable orthonormal basis of $L^2(\mathbb{R}).$ It should be true that the Hilbert Space $L^2(\mathbb{R})$ is separable, this because the measure space $(\mathbb{R},\lambda),$ where $\lambda$ is the Lebesgue measure, is $\sigma-$finite. Now, this implies that there exists a countable orthonormal basis, but this comes from an abstract type of reasoning, i.e. the Zorn's Lemma for the existence of an orthonormal basis and the use of separability to say that it is countable. The question that came up to me is: is there an explicit representation of this basis? The answer should be no, otherwise the use of the continuous Fourier transform doesn't make much sense, but who knows, perhaps there are some good reasons to prefer the continuous transform even if there is a countable basis. My idea was to take inspiration from the system $\{sin(\frac{n x}{m})\}_{n,m\in\mathbb{N}},$ but I don't know how to continue.",,"['functional-analysis', 'fourier-analysis', 'orthonormal', 'separable-spaces']"
93,Application of Baire theorem for proof of non-existence of a universal function,Application of Baire theorem for proof of non-existence of a universal function,,"I have encountered the following problem: Prove that there is no continuous function $U\colon [\,0;1\,]\times[\,0;1\,]\rightarrow\mathbb{R}$, so that $\forall f\in C[\,0;1\,], \quad|f(x)|\leq1\quad \forall x\in[\,0;1\,]$, exists such $y_f\in[\,0;1\,]$ so that $f(x)\equiv U(x,y_f)$. It ia advised to use Baire theorem, but I have no idea which sets to choose. What sould I try?","I have encountered the following problem: Prove that there is no continuous function $U\colon [\,0;1\,]\times[\,0;1\,]\rightarrow\mathbb{R}$, so that $\forall f\in C[\,0;1\,], \quad|f(x)|\leq1\quad \forall x\in[\,0;1\,]$, exists such $y_f\in[\,0;1\,]$ so that $f(x)\equiv U(x,y_f)$. It ia advised to use Baire theorem, but I have no idea which sets to choose. What sould I try?",,['functional-analysis']
94,Inequivalent Hilbert norms on given vector space,Inequivalent Hilbert norms on given vector space,,"Suppose we have a vector space $X$. Let $\|\cdot\|_1$ and $\|\cdot\|_2$ be two different complete norms on $X$ s.th. $X$ equipped with $\|\cdot\|_j, \ j\in\{1,2\}$ is a Hilbert space. Are there simple examples of such norms, which are inequivalent ? This question arises from this discussion.","Suppose we have a vector space $X$. Let $\|\cdot\|_1$ and $\|\cdot\|_2$ be two different complete norms on $X$ s.th. $X$ equipped with $\|\cdot\|_j, \ j\in\{1,2\}$ is a Hilbert space. Are there simple examples of such norms, which are inequivalent ? This question arises from this discussion.",,"['functional-analysis', 'hilbert-spaces']"
95,Surjectivity of the trace operator in Sobolev spaces,Surjectivity of the trace operator in Sobolev spaces,,"Suppose $U$ is an open bounded set with $C^1$ boundary. It is a well-known result in the theory of Sobolev spaces $W^{1,p}$ that there is a continuous linear operator $T:W^{1,p}(U)\rightarrow L^p(\partial U )$ that equals ordinary restriction on continuous functions. Wikipedia tells me that this operator is in general not surjective. I know that one way to prove this is to show that functions in the image are actually more regular than your general $L^p$-function, and I have somewhat understood the proof for that. However, I feel that there should be some elementary counterexample. In fact, any function that is a trace of some $u\in W^{1,p}(U)$ is a limit of a Cauchy sequence of functions in $C^{\infty}(\bar{U})$ (and vice versa), and that could be exploited to exhibit some example where $T$ is not surjective. Does anyone have a good example?","Suppose $U$ is an open bounded set with $C^1$ boundary. It is a well-known result in the theory of Sobolev spaces $W^{1,p}$ that there is a continuous linear operator $T:W^{1,p}(U)\rightarrow L^p(\partial U )$ that equals ordinary restriction on continuous functions. Wikipedia tells me that this operator is in general not surjective. I know that one way to prove this is to show that functions in the image are actually more regular than your general $L^p$-function, and I have somewhat understood the proof for that. However, I feel that there should be some elementary counterexample. In fact, any function that is a trace of some $u\in W^{1,p}(U)$ is a limit of a Cauchy sequence of functions in $C^{\infty}(\bar{U})$ (and vice versa), and that could be exploited to exhibit some example where $T$ is not surjective. Does anyone have a good example?",,"['functional-analysis', 'partial-differential-equations', 'sobolev-spaces', 'trace']"
96,What makes irreducible representations nice?,What makes irreducible representations nice?,,"Let $\mathcal{A}$ be a C*-algebra and $(H,\pi,\Omega)$ a cyclic representation. What does it intuitively mean if the representation is irreducible? From what I've read, irreducible representations are nice and I can be happy if my algebra can be represented in such a way, but which nice properties does an irreducible representation actually bring about?","Let $\mathcal{A}$ be a C*-algebra and $(H,\pi,\Omega)$ a cyclic representation. What does it intuitively mean if the representation is irreducible? From what I've read, irreducible representations are nice and I can be happy if my algebra can be represented in such a way, but which nice properties does an irreducible representation actually bring about?",,"['functional-analysis', 'representation-theory', 'c-star-algebras']"
97,Two definitions of a bounded set in topological vector spaces,Two definitions of a bounded set in topological vector spaces,,Let $X$ be a topological vector space. A subset $E$ is bounded if to every open set $V$ containing $0$ in $X$ there corresponds a number $s>0$ such that $E\subseteq tV$ for every $t > s$ . Would the content of this definition be altered if it were required merely that to every open set $V$ containing $0$ there corresponds some $t>0$ such that $E\subseteq tV$ ?,Let be a topological vector space. A subset is bounded if to every open set containing in there corresponds a number such that for every . Would the content of this definition be altered if it were required merely that to every open set containing there corresponds some such that ?,X E V 0 X s>0 E\subseteq tV t > s V 0 t>0 E\subseteq tV,"['functional-analysis', 'topological-vector-spaces']"
98,Compatibility of pointwise and distributional convergence,Compatibility of pointwise and distributional convergence,,"Let $\Omega$ be an open subset of $\mathbb{R}^n$ and let $u_k,\, u$ and $v$ be elements of $L^1_{\mathrm{loc}}(\Omega)$ . Assume that \begin{equation} \begin{array}{ccc} u_k(x)\to u(x)\quad x\text{-a.e.} &\text{and}& u_k\to v\quad \text{in }\mathscr{D}'.\end{array} \end{equation} Does it follow that $u=v$ almost everywhere? As it is usual, the convergence $u_k\to v$ in $\mathscr{D}'$ is defined as follows: $$\int_{\Omega}u_k(x) \phi(x)\, dx \to \int_{\Omega}v(x)\phi(x)\, dx,\qquad\text{for all } \phi \in C^{\infty}_c(\Omega).$$ The point of this question is to show that there is a minimum degree of ""compatibility"" between the two notions of convergence, even if neither of the two implies the other. NOTE CAREFULLY . This question has already received an excellent answer by Chris Janjigian, which will be awarded the bounty.","Let be an open subset of and let and be elements of . Assume that Does it follow that almost everywhere? As it is usual, the convergence in is defined as follows: The point of this question is to show that there is a minimum degree of ""compatibility"" between the two notions of convergence, even if neither of the two implies the other. NOTE CAREFULLY . This question has already received an excellent answer by Chris Janjigian, which will be awarded the bounty.","\Omega \mathbb{R}^n u_k,\, u v L^1_{\mathrm{loc}}(\Omega) \begin{equation}
\begin{array}{ccc}
u_k(x)\to u(x)\quad x\text{-a.e.} &\text{and}& u_k\to v\quad \text{in }\mathscr{D}'.\end{array}
\end{equation} u=v u_k\to v \mathscr{D}' \int_{\Omega}u_k(x) \phi(x)\, dx \to \int_{\Omega}v(x)\phi(x)\, dx,\qquad\text{for all } \phi \in C^{\infty}_c(\Omega).","['functional-analysis', 'measure-theory', 'distribution-theory']"
99,About Lusin's condition (N),About Lusin's condition (N),,"We say that $f:[0,1]\to \mathbb{R}$ satisfies Lusin's condition (N) provided $$m(f(B))=0 \quad\mbox{whenever}\quad B\subseteq [0,1] \mbox{ with }m(B)=0$$ where $m$ stands for the Lebesgue measure on $\mathbb{R}$. I found in here the following definition. We say that $f:[0,1]\to X$ satisfies Lusin's condition (N) provided $$\mathcal{H}^1(f(B))=0 \quad\mbox{whenever}\quad B\subseteq [0,1] \mbox{ with }m(B)=0$$ where $X$ is a metric space  and $\mathcal{H}^1$ stands for 1-dimensional Hausdorff measure. What comes to my mind is the possible formulation of condition (N) for the function $f:[0,1]\to X$ but this time our $X$ is a Hausdorff locally convex topological vector space. I don't know if such formulation exists. If such formulation exists, I would be greatful if you can provide me such definition.","We say that $f:[0,1]\to \mathbb{R}$ satisfies Lusin's condition (N) provided $$m(f(B))=0 \quad\mbox{whenever}\quad B\subseteq [0,1] \mbox{ with }m(B)=0$$ where $m$ stands for the Lebesgue measure on $\mathbb{R}$. I found in here the following definition. We say that $f:[0,1]\to X$ satisfies Lusin's condition (N) provided $$\mathcal{H}^1(f(B))=0 \quad\mbox{whenever}\quad B\subseteq [0,1] \mbox{ with }m(B)=0$$ where $X$ is a metric space  and $\mathcal{H}^1$ stands for 1-dimensional Hausdorff measure. What comes to my mind is the possible formulation of condition (N) for the function $f:[0,1]\to X$ but this time our $X$ is a Hausdorff locally convex topological vector space. I don't know if such formulation exists. If such formulation exists, I would be greatful if you can provide me such definition.",,"['analysis', 'functional-analysis', 'topological-vector-spaces']"
