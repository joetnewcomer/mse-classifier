,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Confusion with definition of a manifold.,Confusion with definition of a manifold.,,"I'm reading some notes about integration of differential forms and at the begining the author claims: A $1$-manifold in $n$ dimensions is just a curve parametrized as $X: (a, b) \subseteq \mathbb{R} \rightarrow \mathbb{R}^{n}$ (Me: plus other conditions of smoothness, etc.). In general a $k$-manifold in $n$ dimensions is just the image of a function $X: D \subseteq \mathbb{R}^{k} \rightarrow \mathbb{R}^{n}$ (Me: with the aditional conditions). My questions are: $(1)$ how can you come to such description of a manifold from the definiton of manifolds by charts, atlases and transition maps, and $(2)$ by the definiton I know, a manifold $M$ is of dimension $n$ (and is called a $n$-manifold) if for some chart (and hence for all) $(U \subseteq M, \phi)$, $\phi (U) \subseteq \mathbb{R}^{n}$. So how would I determine the dimension of a manifold with the definition of the notes (i.e. is the dimension $k$ or $n$)?","I'm reading some notes about integration of differential forms and at the begining the author claims: A $1$-manifold in $n$ dimensions is just a curve parametrized as $X: (a, b) \subseteq \mathbb{R} \rightarrow \mathbb{R}^{n}$ (Me: plus other conditions of smoothness, etc.). In general a $k$-manifold in $n$ dimensions is just the image of a function $X: D \subseteq \mathbb{R}^{k} \rightarrow \mathbb{R}^{n}$ (Me: with the aditional conditions). My questions are: $(1)$ how can you come to such description of a manifold from the definiton of manifolds by charts, atlases and transition maps, and $(2)$ by the definiton I know, a manifold $M$ is of dimension $n$ (and is called a $n$-manifold) if for some chart (and hence for all) $(U \subseteq M, \phi)$, $\phi (U) \subseteq \mathbb{R}^{n}$. So how would I determine the dimension of a manifold with the definition of the notes (i.e. is the dimension $k$ or $n$)?",,['differential-geometry']
1,What can we know about the metric if we know the Christoffel symbols (2 dimensions)?,What can we know about the metric if we know the Christoffel symbols (2 dimensions)?,,"Assume $U\subset {\mathbb ℝ}^2$, $g$ and $h$ two metrics on $U$. Assume that the Christoffel symbols $Γ^i_{jk}(g)\equiv Γ^i_{jk}(h)$, as a pointwise identity, for all sets of indices. Does it follow that $g=h$? If not, is there a counter-example? Will then the result hold true if $g$ and $h$ coincide in a point or on the boundary or a region? In general, what can be said about the relationship between g and h under the above hypothesis?","Assume $U\subset {\mathbb ℝ}^2$, $g$ and $h$ two metrics on $U$. Assume that the Christoffel symbols $Γ^i_{jk}(g)\equiv Γ^i_{jk}(h)$, as a pointwise identity, for all sets of indices. Does it follow that $g=h$? If not, is there a counter-example? Will then the result hold true if $g$ and $h$ coincide in a point or on the boundary or a region? In general, what can be said about the relationship between g and h under the above hypothesis?",,['differential-geometry']
2,Real projective $n$ space,Real projective  space,n,"We define $\sim$ on $\mathbf{R}^n - \{0\}$ by $x \sim y$ if $x = \lambda y$ for some $\lambda \in \mathbf{R}$. We define projective $n$ space by $X = (\mathbf{R}^n - \{0\})/{\sim}$. I am having trouble showing that $X$ is an $(n-1)$-dimensional topological manifold. The definition of a topological manifold that I'm working with is the following: $X$ is a topological $n$-manifold if, for all $x \in X$, there is an open nhood $U$ of $x$ such that $U$ is homeomorphic to an open subset of $\mathbf{R}^n$. I understand that one can take $U$ to be homeomorphic to any open ball in $\mathbf{R}^n$, or any open nhood ball in $\mathbf{R}^n$. I am also aware that the open nhoods of $\overline{x} \in X$ will look like a half-sphere (at least I think so; I think my work was OK here).","We define $\sim$ on $\mathbf{R}^n - \{0\}$ by $x \sim y$ if $x = \lambda y$ for some $\lambda \in \mathbf{R}$. We define projective $n$ space by $X = (\mathbf{R}^n - \{0\})/{\sim}$. I am having trouble showing that $X$ is an $(n-1)$-dimensional topological manifold. The definition of a topological manifold that I'm working with is the following: $X$ is a topological $n$-manifold if, for all $x \in X$, there is an open nhood $U$ of $x$ such that $U$ is homeomorphic to an open subset of $\mathbf{R}^n$. I understand that one can take $U$ to be homeomorphic to any open ball in $\mathbf{R}^n$, or any open nhood ball in $\mathbf{R}^n$. I am also aware that the open nhoods of $\overline{x} \in X$ will look like a half-sphere (at least I think so; I think my work was OK here).",,"['differential-geometry', 'manifolds']"
3,"For a closed plane curve, showing some inequalities.","For a closed plane curve, showing some inequalities.",,"I have a problem following : Let $\gamma:[0,T]→\mathbb{R}^2$ be a closed plane curve, i.e., a regular parametrized curve such that $ \gamma$ and all its derivatives agree at 0 and $T$. For convenience of formulation, we assume that $\gamma$ is parametrized by arc-length (1) Show that there exist $t_1, t_2 \in [0,T]$ such that $\gamma'(t_1)=-\gamma'(t_2)$. (2) Let $\kappa(t)$ denote the curvature of $\gamma$ at t. Show that $$\int_0^{T} |\kappa(t)|dt \ge 2\pi$$ I tried to solve this problems. Since $\gamma$ is parametrized by arc-length, it is unit-speed curve.  So, I know the part(1) geometrically, but I don't know the perfect answer. My tutor gave me a hint 'consider the integral $$\int_0^{T} \gamma'(t)dt$$ I know the value of the integral is zero because $\gamma$ is a closed curve. But I don't proceed more.. Also, for part (2), I hope to apply Gauss-Bonnet Theorem. Since it is a plane curve, the Gaussian curvature is 0, and the  curvature $\kappa$ is equal to the geodesic curvature $\kappa_g$. But I don't know why does the inequality in (2) hold. please inform me..","I have a problem following : Let $\gamma:[0,T]→\mathbb{R}^2$ be a closed plane curve, i.e., a regular parametrized curve such that $ \gamma$ and all its derivatives agree at 0 and $T$. For convenience of formulation, we assume that $\gamma$ is parametrized by arc-length (1) Show that there exist $t_1, t_2 \in [0,T]$ such that $\gamma'(t_1)=-\gamma'(t_2)$. (2) Let $\kappa(t)$ denote the curvature of $\gamma$ at t. Show that $$\int_0^{T} |\kappa(t)|dt \ge 2\pi$$ I tried to solve this problems. Since $\gamma$ is parametrized by arc-length, it is unit-speed curve.  So, I know the part(1) geometrically, but I don't know the perfect answer. My tutor gave me a hint 'consider the integral $$\int_0^{T} \gamma'(t)dt$$ I know the value of the integral is zero because $\gamma$ is a closed curve. But I don't proceed more.. Also, for part (2), I hope to apply Gauss-Bonnet Theorem. Since it is a plane curve, the Gaussian curvature is 0, and the  curvature $\kappa$ is equal to the geodesic curvature $\kappa_g$. But I don't know why does the inequality in (2) hold. please inform me..",,['differential-geometry']
4,What do the curvature and torsion measure? [duplicate],What do the curvature and torsion measure? [duplicate],,"This question already has answers here : Geometric interpretation of connection forms, torsion forms, curvature forms, etc (3 answers) Closed 10 years ago . Consider a smooth surface for simplicity. What does its curvature measure? What does its Gaussian/Riemannian curvature measure? What does its torsion measure? What does the Ricci curvature measure?","This question already has answers here : Geometric interpretation of connection forms, torsion forms, curvature forms, etc (3 answers) Closed 10 years ago . Consider a smooth surface for simplicity. What does its curvature measure? What does its Gaussian/Riemannian curvature measure? What does its torsion measure? What does the Ricci curvature measure?",,"['differential-geometry', 'curvature']"
5,How to induce a connection on endomorphism bundle?,How to induce a connection on endomorphism bundle?,,"Assume $\nabla:C^\infty(E) \rightarrow C^\infty(T^*X \otimes E)$ is a covariant derivative  and $u$ is an element in the endomorphism bundle $End E$. I'm confused why is the induced connection of $\nabla$ on $End E$ is $\nabla^{End(E)}u=[\nabla,u]$. Any hints?","Assume $\nabla:C^\infty(E) \rightarrow C^\infty(T^*X \otimes E)$ is a covariant derivative  and $u$ is an element in the endomorphism bundle $End E$. I'm confused why is the induced connection of $\nabla$ on $End E$ is $\nabla^{End(E)}u=[\nabla,u]$. Any hints?",,['differential-geometry']
6,Harmonic maps from the sphere,Harmonic maps from the sphere,,"In Hamilton's 1997 paper on four-manifolds with positive isotropic curvature, he  considers a local diffeomorphism of Riemannian $n$-manifolds $$ P: (N,\bar g) \to (M, g). $$ Such a map is harmonic if $$  \operatorname{tr}_{\bar g} \nabla d P^\alpha = \bar g^{jk} \left(  \frac{\partial P^\alpha}{\partial x^j \partial x^k} +  \Gamma_{\mu\nu}^\alpha \frac{\partial P^\mu}{\partial x^j} \frac{\partial P^\nu}{\partial x^k} -  \bar \Gamma^l_{jk} \frac{\partial P^\alpha}{\partial x^l} \right) = 0 $$ where $\Gamma$ is the Levi-Civita connection of the pullback metric $ P^* g $. He then claims that when $(N, \bar g)$ is the round sphere $S^n$, this is equivalent to  $$ \bar g^{jk} ( \bar\Gamma_{jk}^i - \Gamma_{jk}^i ) =0.$$ There must be some property of the connection on the round sphere that makes this work, but I'm not seeing it - any pointers? Also, in the first formula for the Laplacian I gave above, $\Gamma$ is usually interpreted as the pullback connection on $P^* TM$ (which I have given Greek indices) - this works in more general cases than when $P$ is a local diffeomorphism. Am I correct that in this case both interpretations give the same result?","In Hamilton's 1997 paper on four-manifolds with positive isotropic curvature, he  considers a local diffeomorphism of Riemannian $n$-manifolds $$ P: (N,\bar g) \to (M, g). $$ Such a map is harmonic if $$  \operatorname{tr}_{\bar g} \nabla d P^\alpha = \bar g^{jk} \left(  \frac{\partial P^\alpha}{\partial x^j \partial x^k} +  \Gamma_{\mu\nu}^\alpha \frac{\partial P^\mu}{\partial x^j} \frac{\partial P^\nu}{\partial x^k} -  \bar \Gamma^l_{jk} \frac{\partial P^\alpha}{\partial x^l} \right) = 0 $$ where $\Gamma$ is the Levi-Civita connection of the pullback metric $ P^* g $. He then claims that when $(N, \bar g)$ is the round sphere $S^n$, this is equivalent to  $$ \bar g^{jk} ( \bar\Gamma_{jk}^i - \Gamma_{jk}^i ) =0.$$ There must be some property of the connection on the round sphere that makes this work, but I'm not seeing it - any pointers? Also, in the first formula for the Laplacian I gave above, $\Gamma$ is usually interpreted as the pullback connection on $P^* TM$ (which I have given Greek indices) - this works in more general cases than when $P$ is a local diffeomorphism. Am I correct that in this case both interpretations give the same result?",,"['differential-geometry', 'riemannian-geometry']"
7,Why do all solutions to this equation have the same form?,Why do all solutions to this equation have the same form?,,"In this paper on page 45, the authors state that Let's assume we know that $$ w \times dw = d\varphi + \sum_{j=1}^3\alpha_jdx_j, \tag{1}$$ where $\varphi \in H^1(\mathbb{R}^3, \mathbb{R})$, $\alpha_j$ are real numbers and $\vert w \vert=1$. One then checks that $$ w(x)= \exp i \left(\varphi(x)+\sum_{j=1}^3 \alpha_j x_j + \theta\right). \tag{2}$$ for some $\theta \in \mathbb{R}$. Here $$w \times dw= \sum_{i=1}^3 (w_1 \partial_i w_2 - w_2 \partial_i w_1) dx_i$$ for $$w=w_1 +i w_2 : \mathbb{R}^3 \to \mathbb{C}.$$ I do not understand this statement. In fact, one can easily check that $w$ from (2) satisfies equation (1). But why does every $w$ that satisfies equation (1) have the form (2)? Any hint would be much appreciated!","In this paper on page 45, the authors state that Let's assume we know that $$ w \times dw = d\varphi + \sum_{j=1}^3\alpha_jdx_j, \tag{1}$$ where $\varphi \in H^1(\mathbb{R}^3, \mathbb{R})$, $\alpha_j$ are real numbers and $\vert w \vert=1$. One then checks that $$ w(x)= \exp i \left(\varphi(x)+\sum_{j=1}^3 \alpha_j x_j + \theta\right). \tag{2}$$ for some $\theta \in \mathbb{R}$. Here $$w \times dw= \sum_{i=1}^3 (w_1 \partial_i w_2 - w_2 \partial_i w_1) dx_i$$ for $$w=w_1 +i w_2 : \mathbb{R}^3 \to \mathbb{C}.$$ I do not understand this statement. In fact, one can easily check that $w$ from (2) satisfies equation (1). But why does every $w$ that satisfies equation (1) have the form (2)? Any hint would be much appreciated!",,"['differential-geometry', 'partial-differential-equations', 'differential-forms']"
8,planar points and differential geometry,planar points and differential geometry,,"Prove or disprove ; Let $S  $ be a surface in $ R^3$.  $S  $ is a plane iff every point of $S  $ is planar point. ""All points of plane are planar points"" is trivial. But,...  the converse is also really true? The definition of planar point ;  $p  $ is called a planar point of $S  $ iff the two principal curvatures vanish.","Prove or disprove ; Let $S  $ be a surface in $ R^3$.  $S  $ is a plane iff every point of $S  $ is planar point. ""All points of plane are planar points"" is trivial. But,...  the converse is also really true? The definition of planar point ;  $p  $ is called a planar point of $S  $ iff the two principal curvatures vanish.",,['differential-geometry']
9,scalar curvature,scalar curvature,,"I am studying scalar curvature. It is the trace of the Ricci operator. I read that its geometric meaning follows from this formula $\frac{Vol_M(B(p,t))}{Vol_{\mathbb{R}^n}(B(o,t))}=1-\frac{1}{6(n+2)}k(p)t^2+o(t^2)$ where $k$ is the scalar curvature. From this formula one knows that if the scalar curvature is positive the geodesic balls with small radius have smaller volume than that of the same ball in $\mathbb{R}^n$. Unfortunately, I don't know the meaning of ""volume of the geodesic ball"" (i.e. $Vol_M(B(p,t))$) and I cannot find it. Can someone help? Thanks in advance for the help and I apology for my English.","I am studying scalar curvature. It is the trace of the Ricci operator. I read that its geometric meaning follows from this formula $\frac{Vol_M(B(p,t))}{Vol_{\mathbb{R}^n}(B(o,t))}=1-\frac{1}{6(n+2)}k(p)t^2+o(t^2)$ where $k$ is the scalar curvature. From this formula one knows that if the scalar curvature is positive the geodesic balls with small radius have smaller volume than that of the same ball in $\mathbb{R}^n$. Unfortunately, I don't know the meaning of ""volume of the geodesic ball"" (i.e. $Vol_M(B(p,t))$) and I cannot find it. Can someone help? Thanks in advance for the help and I apology for my English.",,"['differential-geometry', 'riemannian-geometry', 'curvature']"
10,Explicitly writing out a differential 2-form,Explicitly writing out a differential 2-form,,"In Tu's An Introduction to Manifolds , one question asks: At each point $p\in \mathbb{R}^3$, define a bilinear function $\omega_p$ on $T_p(\mathbb{R}^3)$ by:   $$\omega_p(\underline{a},\underline{b})=\omega_p((a^1,a^2,a^3),(b^1,b^2,b^3))=p^3(a^1b^2-a^2b^1)$$   For tangent vetors $\underline{a},\underline{b}\in T_p(\mathbb{R}^3)$, where $p^3$ is the third component of $\underline{p}=(p^1,p^2,p^3)$. Since $\omega_p$ is an alternating bilinear function on $T_p(\mathbb{R}^3)$, $\omega$ is a 2-form on $\mathbb{R}^3$. Write $\omega$ in terms of the standard basis $dx^i\wedge dx^j$ at each point. I understand that we write this as $\omega=a_{ij}dx^i\wedge dx^j$, with $a_{ij}=\omega(e_i,e_j)$ where $e_1,e_2,e_3$ span $T_p(\mathbb{R})$. With this I find that all constants vanish apart from $a_{12}$ and $a_{21}$, which lead to: $\omega=p^3dx\wedge dy-p^3dy\wedge dx=2p^3dx\wedge dy$. In the solutions however, since an alternating function of two arguments is completely determined by its actions on $w(e_{k},e_{l}),k<l$, Tu sums only over $i<j$ leading to $\omega=p^3dx\wedge dy$. My question is, I thought that whether or not a multilinear function is alternating, you should be able to characterise it by feeding it all possible combinations of basis elements. But it seems in this case that leads to a different answer. Why is this?","In Tu's An Introduction to Manifolds , one question asks: At each point $p\in \mathbb{R}^3$, define a bilinear function $\omega_p$ on $T_p(\mathbb{R}^3)$ by:   $$\omega_p(\underline{a},\underline{b})=\omega_p((a^1,a^2,a^3),(b^1,b^2,b^3))=p^3(a^1b^2-a^2b^1)$$   For tangent vetors $\underline{a},\underline{b}\in T_p(\mathbb{R}^3)$, where $p^3$ is the third component of $\underline{p}=(p^1,p^2,p^3)$. Since $\omega_p$ is an alternating bilinear function on $T_p(\mathbb{R}^3)$, $\omega$ is a 2-form on $\mathbb{R}^3$. Write $\omega$ in terms of the standard basis $dx^i\wedge dx^j$ at each point. I understand that we write this as $\omega=a_{ij}dx^i\wedge dx^j$, with $a_{ij}=\omega(e_i,e_j)$ where $e_1,e_2,e_3$ span $T_p(\mathbb{R})$. With this I find that all constants vanish apart from $a_{12}$ and $a_{21}$, which lead to: $\omega=p^3dx\wedge dy-p^3dy\wedge dx=2p^3dx\wedge dy$. In the solutions however, since an alternating function of two arguments is completely determined by its actions on $w(e_{k},e_{l}),k<l$, Tu sums only over $i<j$ leading to $\omega=p^3dx\wedge dy$. My question is, I thought that whether or not a multilinear function is alternating, you should be able to characterise it by feeding it all possible combinations of basis elements. But it seems in this case that leads to a different answer. Why is this?",,['differential-geometry']
11,Computing integral of $2$ - form on a torus,Computing integral of  - form on a torus,2,"I am looking at problem 16-2 of Lee's Smooth Manifolds, second edition. Problem 16 - 2: Let $\Bbb{T}^2 \subseteq \Bbb{R}^4$ be the two torus defined as the set of points $(w,x,y,z)$ such that $w^2 + x^2 = y^2 + z^2 = 1$, with the product orientation determined by the standard orientation on $\Bbb{S}^1$. Compute $\int_{\Bbb{T}^2} \omega$ where $\omega$ is the following two form on $\Bbb{R}^4$:     $$\omega = xyz \hspace{1mm} dw \wedge dy.$$ Now if I want to evaluate such a two form do I need to care about the orientation? I am tempted to set up a map $F : \Bbb{R}^2 \to \Bbb{R}^4$ that sends $\varphi, \theta$ to $(\cos \varphi, \sin \varphi, \cos \theta, \sin \theta)$ and then taking the integral of $\omega$ on the torus to be $$\int_{[0,2\pi]^2} F^\ast \omega  .$$ Is my reasoning correct, or do I need to care about the product orientation?","I am looking at problem 16-2 of Lee's Smooth Manifolds, second edition. Problem 16 - 2: Let $\Bbb{T}^2 \subseteq \Bbb{R}^4$ be the two torus defined as the set of points $(w,x,y,z)$ such that $w^2 + x^2 = y^2 + z^2 = 1$, with the product orientation determined by the standard orientation on $\Bbb{S}^1$. Compute $\int_{\Bbb{T}^2} \omega$ where $\omega$ is the following two form on $\Bbb{R}^4$:     $$\omega = xyz \hspace{1mm} dw \wedge dy.$$ Now if I want to evaluate such a two form do I need to care about the orientation? I am tempted to set up a map $F : \Bbb{R}^2 \to \Bbb{R}^4$ that sends $\varphi, \theta$ to $(\cos \varphi, \sin \varphi, \cos \theta, \sin \theta)$ and then taking the integral of $\omega$ on the torus to be $$\int_{[0,2\pi]^2} F^\ast \omega  .$$ Is my reasoning correct, or do I need to care about the product orientation?",,[]
12,How does the differential $df$ act on an element of $T_pM$?,How does the differential  act on an element of ?,df T_pM,"Let $f$ be a smooth real valued function on a smooth manifold $M$. The differential of $f$ is the covector field $df$ defined by $$df_p(v) = v(f)$$ where $v \in T_pM$ and where we are now thinking of $v$ as an element of $\operatorname{Der}(M)$. Now I am trying to see if I can understand this definition in the following concrete case. Let $f : \Bbb{S}^2 \to \Bbb{R}$ be the smooth real valued function that just picks out the $z$ - coordinate of a point $p  \in S^2$. Now if $p \in S^2 - N$ where $N$ is the north pole then choose the coordinate chart $\{S^2 - N, \sigma_N\}$ on $S^2$ where $\sigma_N$ is stereographic projection from the north pole. With this chart, I have computed $df_p$ in coordinates  to be $$df_p = \left( \frac{4x}{\left(x^2 + y^2 + 1\right)^2} dx + \frac{4y}{\left (x^2 + y^2 + 1\right)^2} dy \right)\Bigg|_{\sigma_N(p)}.$$ My question is: Having computed $df_p(v)$, how can I see what it does to an arbitrary vector $T_pS^2$? For example if $v$ is the vector $(1,1,0)$ based at the point $p = (0,0,-1)$, what is $df_{(0,0,-1)}( v)$? Thanks.","Let $f$ be a smooth real valued function on a smooth manifold $M$. The differential of $f$ is the covector field $df$ defined by $$df_p(v) = v(f)$$ where $v \in T_pM$ and where we are now thinking of $v$ as an element of $\operatorname{Der}(M)$. Now I am trying to see if I can understand this definition in the following concrete case. Let $f : \Bbb{S}^2 \to \Bbb{R}$ be the smooth real valued function that just picks out the $z$ - coordinate of a point $p  \in S^2$. Now if $p \in S^2 - N$ where $N$ is the north pole then choose the coordinate chart $\{S^2 - N, \sigma_N\}$ on $S^2$ where $\sigma_N$ is stereographic projection from the north pole. With this chart, I have computed $df_p$ in coordinates  to be $$df_p = \left( \frac{4x}{\left(x^2 + y^2 + 1\right)^2} dx + \frac{4y}{\left (x^2 + y^2 + 1\right)^2} dy \right)\Bigg|_{\sigma_N(p)}.$$ My question is: Having computed $df_p(v)$, how can I see what it does to an arbitrary vector $T_pS^2$? For example if $v$ is the vector $(1,1,0)$ based at the point $p = (0,0,-1)$, what is $df_{(0,0,-1)}( v)$? Thanks.",,[]
13,How to make a $C^1$ knot into a $C^\infty$ knot,How to make a  knot into a  knot,C^1 C^\infty,"Suppose I have a $C^1$ imbedding $f: S^1 \rightarrow S^3$.  From the point of view of knot theory, what's the ""best"" way to get a $C^\infty$ curve that ""looks like"" or is ""equivalent to"" $f$?  For instance, one of the stronger things I can think to try to prove is that there exists a $C^1$ isotopy, H, of $S^3$ which takes $f$ to a $C^\infty$ imbedding and such that $H_t  (f(S^1))= f(S^1)$ for all times $t$ (so the isotopy doesnt move the image of $f$ off of itself).  But I would be happy with weaker results.  Also at the risk of asking two questions I'll say that I'd be happy to learn of any particular books or notes that deal with very technical and foundational knot-theoretic questions such as this.  Thank you for reading my question,","Suppose I have a $C^1$ imbedding $f: S^1 \rightarrow S^3$.  From the point of view of knot theory, what's the ""best"" way to get a $C^\infty$ curve that ""looks like"" or is ""equivalent to"" $f$?  For instance, one of the stronger things I can think to try to prove is that there exists a $C^1$ isotopy, H, of $S^3$ which takes $f$ to a $C^\infty$ imbedding and such that $H_t  (f(S^1))= f(S^1)$ for all times $t$ (so the isotopy doesnt move the image of $f$ off of itself).  But I would be happy with weaker results.  Also at the risk of asking two questions I'll say that I'd be happy to learn of any particular books or notes that deal with very technical and foundational knot-theoretic questions such as this.  Thank you for reading my question,",,"['differential-geometry', 'differential-topology', 'knot-theory', 'low-dimensional-topology']"
14,Positive curvature on holomorphic vector bundles,Positive curvature on holomorphic vector bundles,,"There must be a mistake in my understanding the definition of positivity for the curvature. Let me summarize: Let $ (L,\nabla,h) \rightarrow M $ be a hermitian hol line bundle with Chern connection. Then one can show (e.g. Huybrechts, complex geometry Prop. 4.3.8) that the curvature $F = \nabla^2 \in \mathcal{A}^{1,1}(M,\mathbb{C})$ is a (1,1)-Form with the property that (i) $h(F_{X,Y}\sigma,\tau)=-h(\sigma,F_{X,Y}\tau) $. Now, writing $F$ in local coordinates $(z_i)$ of $M$, we see $F=\sum_{i,j}F_{Z_i,\bar Z_j}dz_i \wedge d\bar z_j$ where $ a_{ij}:=F_{Z_i,\bar Z_j}$ is a hermitian symmetric matrix. Now my question is: From the first equality (i) we deduce, that $ F_{X,Y} $ is a purely imaginary complex number. Why isn't this a contradiction to $ a_{ij} $ being hermitian symmetric? The matrix entries of $ a_{ij} $ are special $ F_{X,Y} $, so we get a matrix with purely imaginary entries which cannot be positive definite. Where is my mistake?!","There must be a mistake in my understanding the definition of positivity for the curvature. Let me summarize: Let $ (L,\nabla,h) \rightarrow M $ be a hermitian hol line bundle with Chern connection. Then one can show (e.g. Huybrechts, complex geometry Prop. 4.3.8) that the curvature $F = \nabla^2 \in \mathcal{A}^{1,1}(M,\mathbb{C})$ is a (1,1)-Form with the property that (i) $h(F_{X,Y}\sigma,\tau)=-h(\sigma,F_{X,Y}\tau) $. Now, writing $F$ in local coordinates $(z_i)$ of $M$, we see $F=\sum_{i,j}F_{Z_i,\bar Z_j}dz_i \wedge d\bar z_j$ where $ a_{ij}:=F_{Z_i,\bar Z_j}$ is a hermitian symmetric matrix. Now my question is: From the first equality (i) we deduce, that $ F_{X,Y} $ is a purely imaginary complex number. Why isn't this a contradiction to $ a_{ij} $ being hermitian symmetric? The matrix entries of $ a_{ij} $ are special $ F_{X,Y} $, so we get a matrix with purely imaginary entries which cannot be positive definite. Where is my mistake?!",,"['differential-geometry', 'complex-geometry', 'vector-bundles', 'curvature']"
15,Tangent space at the identity element of a lie group,Tangent space at the identity element of a lie group,,"Let G be a lie group . we know a Lie group is a group with a smooth manifold structure s.t both the multiplication map $m$ and group inversion map $i$ are smooth . Now by identifying $T_{(e,e)}(G\times G)\simeq T_eG\oplus T_eG $  , I can show that the tangent map $T_{(e,e)}m:T_eG\oplus T_eG\mapsto T_eG$ is given by $T_{(e,e)}m.(X,Y)=X+Y$. Now , I wanna use this result to show that the tangent map $T_ei:T_e(G)\mapsto T_e(G)$ is given by $T_ei.X=-X$ since it seems hard to directly derive this result. My attempt is to define a map $m':G\times G \mapsto G$  by  $ g.g^{-1}=e$.Then $T_{(e,e)}m'.(X,Y)=X+Y$= 0 . Now the question is I don't know how to relate  $T_{(e,e)}m'.(X,Y)=X+Y$= 0 to $T_ei.X=-X$.I am also not sure about the correct way to define $m'$. Could someone help me with it ? Thanks a lot.","Let G be a lie group . we know a Lie group is a group with a smooth manifold structure s.t both the multiplication map $m$ and group inversion map $i$ are smooth . Now by identifying $T_{(e,e)}(G\times G)\simeq T_eG\oplus T_eG $  , I can show that the tangent map $T_{(e,e)}m:T_eG\oplus T_eG\mapsto T_eG$ is given by $T_{(e,e)}m.(X,Y)=X+Y$. Now , I wanna use this result to show that the tangent map $T_ei:T_e(G)\mapsto T_e(G)$ is given by $T_ei.X=-X$ since it seems hard to directly derive this result. My attempt is to define a map $m':G\times G \mapsto G$  by  $ g.g^{-1}=e$.Then $T_{(e,e)}m'.(X,Y)=X+Y$= 0 . Now the question is I don't know how to relate  $T_{(e,e)}m'.(X,Y)=X+Y$= 0 to $T_ei.X=-X$.I am also not sure about the correct way to define $m'$. Could someone help me with it ? Thanks a lot.",,"['differential-geometry', 'manifolds', 'lie-groups', 'lie-algebras']"
16,"Baby Rudin, Chapter 10, Problem 23 (d) - Differential forms.","Baby Rudin, Chapter 10, Problem 23 (d) - Differential forms.",,"In problems 21 and 22, Rudin defines the differential forms $\eta=\dfrac{xdy-ydx}{x^2+y^2}$ and $\zeta=\dfrac{x dy \wedge dz+ydz \wedge dx+z dx \wedge dy}{r^3}$ and the reader is asked to prove various statements regarding them (for example, that integrating these forms gives the surface area, and that integrating over homotopic surfaces yields the same result). In problem 23, we are asked to try to generalize some of the assertions from problems 21,22 for arbitrary $n$, for the differential n-form $\omega_n=\frac{1}{r^n} \sum_{i=1}^n(-1)^{i-1} x_i dx_1 \wedge \ldots \wedge dx_{i-1} \wedge dx_{i+1} \wedge \ldots \wedge dx_n$. I'd love to hear any well known results about $\omega_n$, and with proofs if possible (I'm new to high-dimensional analysis). I already know it's closed, and not exact. Thank you.","In problems 21 and 22, Rudin defines the differential forms $\eta=\dfrac{xdy-ydx}{x^2+y^2}$ and $\zeta=\dfrac{x dy \wedge dz+ydz \wedge dx+z dx \wedge dy}{r^3}$ and the reader is asked to prove various statements regarding them (for example, that integrating these forms gives the surface area, and that integrating over homotopic surfaces yields the same result). In problem 23, we are asked to try to generalize some of the assertions from problems 21,22 for arbitrary $n$, for the differential n-form $\omega_n=\frac{1}{r^n} \sum_{i=1}^n(-1)^{i-1} x_i dx_1 \wedge \ldots \wedge dx_{i-1} \wedge dx_{i+1} \wedge \ldots \wedge dx_n$. I'd love to hear any well known results about $\omega_n$, and with proofs if possible (I'm new to high-dimensional analysis). I already know it's closed, and not exact. Thank you.",,"['real-analysis', 'differential-geometry', 'differential-forms']"
17,Why does it appear that Willmore energy is always zero?,Why does it appear that Willmore energy is always zero?,,"The answer is ""because I'm being sloppy,"" but the problem is I don't know exactly where I'm being sloppy.  Here's my sloppy argument: Let $M$ be a smooth compact surface without boundary in $\mathbb{R}^3$   and let $H$ be its mean curvature.  If $\langle \cdot, \cdot \rangle$   denotes the $L^2$ inner product, then the Willmore energy can be   expressed as $$W = \langle H, H \rangle.$$ Equivalently, since mean   curvature can be expressed as $H = \nabla \cdot N$ where $N$ is the   unit normal field, we have $$W = \langle \nabla \cdot N, H \rangle.$$   But by Stokes' theorem $$\langle \nabla \cdot N, H \rangle = -\langle N, \nabla H \rangle.$$ And since $\nabla H$ is always tangent to $M$,   this inner product vanishes, i.e., the Willmore energy is always zero! Where did I go wrong?  There are several potential flaws -- I suspect that the basic problem is I'm not thinking correctly about how quantities get extended to the ambient space.  But I'm having trouble putting my finger on the precise problem. Thanks!","The answer is ""because I'm being sloppy,"" but the problem is I don't know exactly where I'm being sloppy.  Here's my sloppy argument: Let $M$ be a smooth compact surface without boundary in $\mathbb{R}^3$   and let $H$ be its mean curvature.  If $\langle \cdot, \cdot \rangle$   denotes the $L^2$ inner product, then the Willmore energy can be   expressed as $$W = \langle H, H \rangle.$$ Equivalently, since mean   curvature can be expressed as $H = \nabla \cdot N$ where $N$ is the   unit normal field, we have $$W = \langle \nabla \cdot N, H \rangle.$$   But by Stokes' theorem $$\langle \nabla \cdot N, H \rangle = -\langle N, \nabla H \rangle.$$ And since $\nabla H$ is always tangent to $M$,   this inner product vanishes, i.e., the Willmore energy is always zero! Where did I go wrong?  There are several potential flaws -- I suspect that the basic problem is I'm not thinking correctly about how quantities get extended to the ambient space.  But I'm having trouble putting my finger on the precise problem. Thanks!",,"['differential-geometry', 'riemannian-geometry', 'surfaces']"
18,Invariant vector field by group action,Invariant vector field by group action,,"in a solved exercise, there is a point in the solution that I can't work out. I would be grateful if somebody could give me the detailed steps. Consider the trivial principal bundle $P = M\times U(1)$ over a $C^\infty$-manifold $M$. Let $\Phi_t$ be the flow of a vector field $\mathfrak{X}(P)$. Apparently, if $R_z$ designates the group action of $z \in U(1)$ on $M$, $X$ is $U(1)$-invariant ($R_z \cdot X=X$) if and only if $R_z$ commutes with $\Phi_t$ ($R_z \circ \Phi_t= \Phi_t \circ R_z$). Can somebody confirm this and help me with the proof ? Thanks, JD","in a solved exercise, there is a point in the solution that I can't work out. I would be grateful if somebody could give me the detailed steps. Consider the trivial principal bundle $P = M\times U(1)$ over a $C^\infty$-manifold $M$. Let $\Phi_t$ be the flow of a vector field $\mathfrak{X}(P)$. Apparently, if $R_z$ designates the group action of $z \in U(1)$ on $M$, $X$ is $U(1)$-invariant ($R_z \cdot X=X$) if and only if $R_z$ commutes with $\Phi_t$ ($R_z \circ \Phi_t= \Phi_t \circ R_z$). Can somebody confirm this and help me with the proof ? Thanks, JD",,['differential-geometry']
19,How show that a surface embedded is non-orientable?,How show that a surface embedded is non-orientable?,,"Let be $M$ a compact $3$-manifold. If $\Sigma$ is a embedded surface in $M$, such that $\Sigma$ is homeomorphic to $\mathbb{RP}^2$. If $i: \pi_1(\Sigma) \longrightarrow \pi_1(M)$ is not injective, then $\Sigma$ is non-orientable? Note that $\pi_1(\Sigma) = \mathbb{Z}/2$. This is utilized in the proof of Proposition 3 in http://arxiv.org/abs/0909.1665 . Thank you!","Let be $M$ a compact $3$-manifold. If $\Sigma$ is a embedded surface in $M$, such that $\Sigma$ is homeomorphic to $\mathbb{RP}^2$. If $i: \pi_1(\Sigma) \longrightarrow \pi_1(M)$ is not injective, then $\Sigma$ is non-orientable? Note that $\pi_1(\Sigma) = \mathbb{Z}/2$. This is utilized in the proof of Proposition 3 in http://arxiv.org/abs/0909.1665 . Thank you!",,"['differential-geometry', 'differential-topology', 'riemannian-geometry']"
20,What is the curvature 2-form on the associated vector bundle?,What is the curvature 2-form on the associated vector bundle?,,"Consider a principal bundle $P\rightarrow M$ and the associated vector bundle $P\times_{\rho}V$ over $M$ such that $(p,v)=(pg^{-1},\rho(g)v)$. The connection on the principal bundle $A$ defines a covariant derivative on $P\times_{\rho}V$ as follows. View a section $s$ on $P\times_{\rho}V$ as a $G$-equivariant map $s^{P}:P\rightarrow V$. This means $S^{P}(pg^{-1})=\rho(g)s^{P}(p)$. This defines a $G$-equivariant homomorphism $s^{P}_{*}$ from $TP$ to $V$. Let $x\in M$ and $v\in TM_{x}$, $H_{A}$ be the horizontal vector bundle in $TP$ defined by $A$. Then for any $p$ be the inverse image of $x$, there is a unique horizontal vector $v_{A}\in H_{A}|_{p}$ being the horizontal lift of $v$ such that $\pi_{*}v_{A}=v$. The covariant derivative $\nabla_{A}$ sends section $v$ to the equivalence of the pair $(p,s^{P}_{*}v_{A})$. A routine exercise showed this is not dependent on the choice of $p$. Taubes claim in his book Differential Geometry that locally we can write the covariderive $\nabla_{A}$ on $P\times_{\rho}V$ as $$x\rightarrow (x,ds_{U}+\rho_{*}(a_{U})s_{U})$$where $\rho_{*}:\mathcal{G}\rightarrow End(V)$ is the differential of $\rho$ at the identity. I do not understand how he derived this identity given the above definition of $\nabla_{A}$. Even if we use the canonical identification $$\phi_{U}^{*}H_{A}=(x,-g^{-1}a_{U}(v)g)\in TU\oplus \mathcal{G}$$ where $\phi_{U}^{*}$ is the local trivialization. I still do not know how to derive the desired identity. Note in particular the connection 1-form on $P$ is given by $$g^{-1}dg+g^{-1}a_{U}g$$ where $a_{U}:U\rightarrow \mathcal{G}\otimes T^{*}M$. However I do not know how to put all these formulas together.","Consider a principal bundle $P\rightarrow M$ and the associated vector bundle $P\times_{\rho}V$ over $M$ such that $(p,v)=(pg^{-1},\rho(g)v)$. The connection on the principal bundle $A$ defines a covariant derivative on $P\times_{\rho}V$ as follows. View a section $s$ on $P\times_{\rho}V$ as a $G$-equivariant map $s^{P}:P\rightarrow V$. This means $S^{P}(pg^{-1})=\rho(g)s^{P}(p)$. This defines a $G$-equivariant homomorphism $s^{P}_{*}$ from $TP$ to $V$. Let $x\in M$ and $v\in TM_{x}$, $H_{A}$ be the horizontal vector bundle in $TP$ defined by $A$. Then for any $p$ be the inverse image of $x$, there is a unique horizontal vector $v_{A}\in H_{A}|_{p}$ being the horizontal lift of $v$ such that $\pi_{*}v_{A}=v$. The covariant derivative $\nabla_{A}$ sends section $v$ to the equivalence of the pair $(p,s^{P}_{*}v_{A})$. A routine exercise showed this is not dependent on the choice of $p$. Taubes claim in his book Differential Geometry that locally we can write the covariderive $\nabla_{A}$ on $P\times_{\rho}V$ as $$x\rightarrow (x,ds_{U}+\rho_{*}(a_{U})s_{U})$$where $\rho_{*}:\mathcal{G}\rightarrow End(V)$ is the differential of $\rho$ at the identity. I do not understand how he derived this identity given the above definition of $\nabla_{A}$. Even if we use the canonical identification $$\phi_{U}^{*}H_{A}=(x,-g^{-1}a_{U}(v)g)\in TU\oplus \mathcal{G}$$ where $\phi_{U}^{*}$ is the local trivialization. I still do not know how to derive the desired identity. Note in particular the connection 1-form on $P$ is given by $$g^{-1}dg+g^{-1}a_{U}g$$ where $a_{U}:U\rightarrow \mathcal{G}\otimes T^{*}M$. However I do not know how to put all these formulas together.",,['differential-geometry']
21,elementary question regarding differential forms,elementary question regarding differential forms,,"Is it possible to give a high level explanation why changing the order of differentials will give rise to a minus sign ? I.e. why do we have $$ dx\,dt = - dt\,dx $$ (I am going to take a course on manifolds next semester which will hopefully shed some more detailed light on this, but for the moment I'd need some explanatnion to help me along whilst I'm still lacking the proper foundations -if such an explanation is possible)","Is it possible to give a high level explanation why changing the order of differentials will give rise to a minus sign ? I.e. why do we have $$ dx\,dt = - dt\,dx $$ (I am going to take a course on manifolds next semester which will hopefully shed some more detailed light on this, but for the moment I'd need some explanatnion to help me along whilst I'm still lacking the proper foundations -if such an explanation is possible)",,"['differential-geometry', 'manifolds', 'differential-forms', 'exterior-algebra']"
22,Quotient of $\mathbb{R}$ by $2\pi \mathbb{Z}$,Quotient of  by,\mathbb{R} 2\pi \mathbb{Z},"I'd like help for the problem: Let the additive group $2\pi \mathbb{Z}$ act on $\mathbb{R}$ on the right by $x · 2\pi n = x+2\pi n$, where $n$ is an integer. Show that the orbit space $\frac{\mathbb{R}}{2\pi n\mathbb{Z}} $  is a smooth manifold. I proved that $\frac{\mathbb{R}}{2\pi n\mathbb{Z}} $ is hausdorff and second countable, but I don't know how to find an atlas, I was thinking about $ \psi([x])=e^{ix}$ but I don't know how to show that this is a homeomorphism.","I'd like help for the problem: Let the additive group $2\pi \mathbb{Z}$ act on $\mathbb{R}$ on the right by $x · 2\pi n = x+2\pi n$, where $n$ is an integer. Show that the orbit space $\frac{\mathbb{R}}{2\pi n\mathbb{Z}} $  is a smooth manifold. I proved that $\frac{\mathbb{R}}{2\pi n\mathbb{Z}} $ is hausdorff and second countable, but I don't know how to find an atlas, I was thinking about $ \psi([x])=e^{ix}$ but I don't know how to show that this is a homeomorphism.",,['differential-geometry']
23,Hopf fibration is a submersion,Hopf fibration is a submersion,,"Hopf Fibration is $F:S^3\to S^2$ given by formula $F\left(z_1,z_2\right)=\left(\left(\phi^+\right)^{-1}\left(\frac{z_1}{z_2}\right)\right)$ for $z_2 \ne0$ and $F\left(z_1,0\right)=\left(1,0,0\right)$ where $\phi^+$ is stereographic projection from $\left(1,0,0\right)$ of $S^2$. Now to prove this I tried to compute the rank of the Jacobian matrix of $\psi\circ F\circ\phi^{-1}$ with $\psi$ being the stereographic projection from North of $S^3$. But is this the easy way?","Hopf Fibration is $F:S^3\to S^2$ given by formula $F\left(z_1,z_2\right)=\left(\left(\phi^+\right)^{-1}\left(\frac{z_1}{z_2}\right)\right)$ for $z_2 \ne0$ and $F\left(z_1,0\right)=\left(1,0,0\right)$ where $\phi^+$ is stereographic projection from $\left(1,0,0\right)$ of $S^2$. Now to prove this I tried to compute the rank of the Jacobian matrix of $\psi\circ F\circ\phi^{-1}$ with $\psi$ being the stereographic projection from North of $S^3$. But is this the easy way?",,['differential-geometry']
24,"Are any two Cantor sets ; ""Fat"" and ""Standard"" Diffeomorphic to each Other?","Are any two Cantor sets ; ""Fat"" and ""Standard"" Diffeomorphic to each Other?",,"All: I know any two Cantor sets; ""fat"" , and ""Standard""(middle-third) are homeomorphic to each other. Still, are they diffeomorphic to each other? I think yes, since they are both $0$-dimensional manifolds (###), and any two $0$-dimensional manifolds are diffeomorphic to each other. Still, I saw an argument somewhere where the claim is that the two are not diffeomorphic. The argument is along the lines that, for $C$ the characteristic function of the standard Cantor set integrates to $0$ , since $C$ has (Lebesgue) measure zero, but , if $g$ where a diffeomorphism into a fat Cantor set $C'$, then: $ f(g(x))$ is the indicator function for $C'$, so its integral is positive. And (my apologies, I don't remember the Tex for integral and I don't have enough points to look at someone else's edit ; if someone could please let me know ) By the chain rule, the change-of-variable $\int_0^1 f(g(x))g'(x)dx$ should equal $\int_a^b f(x)dx$ but $g'(x)>0$ and $f(g(x))>0$ . So the change-of-variable is contradicted by the assumption of the existence of the diffeomorphism $g$ between $C$ and $C'$. Is this right? (###)EDIT: I realized after posting --simultaneously with ""Lost in Math""* , that the Cantor sets {C} are not 0-dimensional manifolds (for one thing, C has no isolated points). The problem then becomes, as someone posted in the comments, one of deciding if there is a differentiable map $f:[0,1]\rightarrow [0,1]$ taking C to C' with a differentiable inverse. I mean, who isn't, right?","All: I know any two Cantor sets; ""fat"" , and ""Standard""(middle-third) are homeomorphic to each other. Still, are they diffeomorphic to each other? I think yes, since they are both $0$-dimensional manifolds (###), and any two $0$-dimensional manifolds are diffeomorphic to each other. Still, I saw an argument somewhere where the claim is that the two are not diffeomorphic. The argument is along the lines that, for $C$ the characteristic function of the standard Cantor set integrates to $0$ , since $C$ has (Lebesgue) measure zero, but , if $g$ where a diffeomorphism into a fat Cantor set $C'$, then: $ f(g(x))$ is the indicator function for $C'$, so its integral is positive. And (my apologies, I don't remember the Tex for integral and I don't have enough points to look at someone else's edit ; if someone could please let me know ) By the chain rule, the change-of-variable $\int_0^1 f(g(x))g'(x)dx$ should equal $\int_a^b f(x)dx$ but $g'(x)>0$ and $f(g(x))>0$ . So the change-of-variable is contradicted by the assumption of the existence of the diffeomorphism $g$ between $C$ and $C'$. Is this right? (###)EDIT: I realized after posting --simultaneously with ""Lost in Math""* , that the Cantor sets {C} are not 0-dimensional manifolds (for one thing, C has no isolated points). The problem then becomes, as someone posted in the comments, one of deciding if there is a differentiable map $f:[0,1]\rightarrow [0,1]$ taking C to C' with a differentiable inverse. I mean, who isn't, right?",,['differential-geometry']
25,Jacobian when representing integral of differential form by Riemann integral?,Jacobian when representing integral of differential form by Riemann integral?,,"In Terence Tao's note : If $Ω$ is any open bounded domain in $R^n$ , we then have the identity   $$\int_Ω f (x)dx_1 ∧ . . . ∧ dx_n = \int_Ω f (x) dx$$ where on the left we have an integral of a differential form (with $Ω$   viewed as a positively oriented n-dimensional manifold), and on the   right we have the Riemann or Lebesgue integral of $f$ on $Ω$. From Wikipedia (basically same as in baby Rudin): Let $$\omega=\sum a_{i_1,\dots,i_k}({\mathbf x})\,dx^{i_1} \wedge \cdots  \wedge dx^{i_k} $$ be a differential form and $S$ a differentiable $k$-manifold over   which we wish to integrate, where $S$ has the parameterization $$S({\mathbf u})=(x^1({\mathbf u}),\dots,x^n({\mathbf u}))$$ for $u$ in the parameter domain $D$. Then (Rudin 1976) defines the   integral of the differential form over $S$ as $$\int_S \omega =\int_D \sum a_{i_1,\dots,i_k}(S({\mathbf u}))  \frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}\,du^1\ldots  du^k$$ where $$\frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}$$ is the determinant of the Jacobian. I wonder if in the case of Wikipedia, the change of variable can be eliminated just as in Terence Tao's, for example, \begin{align} \int_S \omega  &=\int_D \sum a_{i_1,\dots,i_k}(S({\mathbf u}))  \frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}\,du^1\ldots du^k \\ &=\int_S \sum a_{i_1,\dots,i_k}(x) \,dx^{i_1}\ldots dx^{i_k} ? \end{align} If not, when can it be? If the manifold $S$ is not a subset of $R^n$, the Jacobian will not make sense. Can $\int_S \omega $ still be represented by Riemann/Lebesgue integral? How is that like if yes? Thanks and regards!","In Terence Tao's note : If $Ω$ is any open bounded domain in $R^n$ , we then have the identity   $$\int_Ω f (x)dx_1 ∧ . . . ∧ dx_n = \int_Ω f (x) dx$$ where on the left we have an integral of a differential form (with $Ω$   viewed as a positively oriented n-dimensional manifold), and on the   right we have the Riemann or Lebesgue integral of $f$ on $Ω$. From Wikipedia (basically same as in baby Rudin): Let $$\omega=\sum a_{i_1,\dots,i_k}({\mathbf x})\,dx^{i_1} \wedge \cdots  \wedge dx^{i_k} $$ be a differential form and $S$ a differentiable $k$-manifold over   which we wish to integrate, where $S$ has the parameterization $$S({\mathbf u})=(x^1({\mathbf u}),\dots,x^n({\mathbf u}))$$ for $u$ in the parameter domain $D$. Then (Rudin 1976) defines the   integral of the differential form over $S$ as $$\int_S \omega =\int_D \sum a_{i_1,\dots,i_k}(S({\mathbf u}))  \frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}\,du^1\ldots  du^k$$ where $$\frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}$$ is the determinant of the Jacobian. I wonder if in the case of Wikipedia, the change of variable can be eliminated just as in Terence Tao's, for example, \begin{align} \int_S \omega  &=\int_D \sum a_{i_1,\dots,i_k}(S({\mathbf u}))  \frac{\partial(x^{i_1},\dots,x^{i_k})}{\partial(u^{1},\dots,u^{k})}\,du^1\ldots du^k \\ &=\int_S \sum a_{i_1,\dots,i_k}(x) \,dx^{i_1}\ldots dx^{i_k} ? \end{align} If not, when can it be? If the manifold $S$ is not a subset of $R^n$, the Jacobian will not make sense. Can $\int_S \omega $ still be represented by Riemann/Lebesgue integral? How is that like if yes? Thanks and regards!",,"['integration', 'differential-geometry', 'differential-forms']"
26,Compute the degree of map,Compute the degree of map,,"Let $S:SU(2)\rightarrow SU(2)$ be defined as $S(X)=X^{4}$. Compute the degree of $S$. Now, $SU(2)$ is homeomorphic to $S^{3}$, so the degree can be taken as:$$ \int_{S^{3}}S^{*}\omega=(\deg S)\int_{S^{3}}\omega$$ where $\omega$ is a nontrivial 3-form on $H^{3}(S^{3})$. Explicitly, I know that this is: $$ \omega=\sum_{i=0}^{k}(-1)^{i}x^{i}dx^{0}\wedge\dots\wedge dx^{i-1}\wedge dx^{i+1}\wedge\dots\wedge dx^{k}$$ where $k=3$. Now, $\int_{S^{3}}\omega$ is equal to $4$ times the volume of $B^{4}$. I am having some trouble computing $\int_{S^{3}}S^{*}\omega$ which would enable me to find $\deg S$.","Let $S:SU(2)\rightarrow SU(2)$ be defined as $S(X)=X^{4}$. Compute the degree of $S$. Now, $SU(2)$ is homeomorphic to $S^{3}$, so the degree can be taken as:$$ \int_{S^{3}}S^{*}\omega=(\deg S)\int_{S^{3}}\omega$$ where $\omega$ is a nontrivial 3-form on $H^{3}(S^{3})$. Explicitly, I know that this is: $$ \omega=\sum_{i=0}^{k}(-1)^{i}x^{i}dx^{0}\wedge\dots\wedge dx^{i-1}\wedge dx^{i+1}\wedge\dots\wedge dx^{k}$$ where $k=3$. Now, $\int_{S^{3}}\omega$ is equal to $4$ times the volume of $B^{4}$. I am having some trouble computing $\int_{S^{3}}S^{*}\omega$ which would enable me to find $\deg S$.",,"['differential-geometry', 'differential-topology']"
27,Wald's definition of parallel transport,Wald's definition of parallel transport,,"I was unsure whether to ask this here or at a physics SE. Wald's ""General Relativity"" defines parallel transport as follows: $\nabla$ is a derivative operator (is linear, obeys Leibniz rule, commutative with contraction, torsion free and is consistent with the notion of vectors as directional derivatives). A vector $v^b$ given at each point of a curve C is parallel transported is said to be parallelly transported as one moves along the curve if the equation $t^a \nabla _a v^b =0$ is satisfied along the curve, where $t^a$ are vectors tangent to the curve. How does this definition reproduce what we intuitively understand as parallel transport? Also, other references use different terminology, with a $\nabla _v$ meaning the derivative along a vector $v$, (the same role $t^a$ plays in the definition above) which is easier to understand but (1) seems ill defined, unlike wald's definition, and (2) both definitions should be related in some way.","I was unsure whether to ask this here or at a physics SE. Wald's ""General Relativity"" defines parallel transport as follows: $\nabla$ is a derivative operator (is linear, obeys Leibniz rule, commutative with contraction, torsion free and is consistent with the notion of vectors as directional derivatives). A vector $v^b$ given at each point of a curve C is parallel transported is said to be parallelly transported as one moves along the curve if the equation $t^a \nabla _a v^b =0$ is satisfied along the curve, where $t^a$ are vectors tangent to the curve. How does this definition reproduce what we intuitively understand as parallel transport? Also, other references use different terminology, with a $\nabla _v$ meaning the derivative along a vector $v$, (the same role $t^a$ plays in the definition above) which is easier to understand but (1) seems ill defined, unlike wald's definition, and (2) both definitions should be related in some way.",,['differential-geometry']
28,Tangent space to circle,Tangent space to circle,,"I guess I am missing something obvious here. I am reading about vector bundles. (What Karoubi calls 'Quasi Vector-Bundles') An example is the sphere, where for every point $X \in S^n$ we choose $E_X$ (the fiber) to be the vector space orthogonal to $X$, and let $E$ (the total space) be the disjoint union of the $E_X$'s, which is naturally a subspace of $S^n \times R^{n+1}$ Now later it states we can have an (iso)morphism to the space $E'= S^1 \times \mathbb{R}$ given by $$g(x,z) = (x,iz/x)$$ Now I must be missing something here. If $x \in S^1$ and $z \in \mathbb{C} = \mathbb{R}^2$ (identifying $\mathbb{R}^2$ with the complex numbers), then doesn't $g(i,a+i)=(i,a+i)$, and $a+i \notin \mathbb{R}$. What am I missing? $a+i$ is in the vector space orthogonal to $i$ (which is just the tanget line at the point $(0,1)$ of the circle) (Feel free to re-tag, wasn't sure what it should be under)","I guess I am missing something obvious here. I am reading about vector bundles. (What Karoubi calls 'Quasi Vector-Bundles') An example is the sphere, where for every point $X \in S^n$ we choose $E_X$ (the fiber) to be the vector space orthogonal to $X$, and let $E$ (the total space) be the disjoint union of the $E_X$'s, which is naturally a subspace of $S^n \times R^{n+1}$ Now later it states we can have an (iso)morphism to the space $E'= S^1 \times \mathbb{R}$ given by $$g(x,z) = (x,iz/x)$$ Now I must be missing something here. If $x \in S^1$ and $z \in \mathbb{C} = \mathbb{R}^2$ (identifying $\mathbb{R}^2$ with the complex numbers), then doesn't $g(i,a+i)=(i,a+i)$, and $a+i \notin \mathbb{R}$. What am I missing? $a+i$ is in the vector space orthogonal to $i$ (which is just the tanget line at the point $(0,1)$ of the circle) (Feel free to re-tag, wasn't sure what it should be under)",,['differential-geometry']
29,Adjoint of Cartan's magic formula,Adjoint of Cartan's magic formula,,"It is well-known that if $X$ is a vector field and $\omega$ is a form, then we have Cartan's ""magic"" formula $$ L_X \omega = d\iota_X \omega + \iota_X d\omega. $$ Assuming that we are on a (pseudo-)Riemannian manifold, I would like to obtain an ""adjoint"" formula for the codifferential. It is also known that $$ \langle \iota_X \omega, \eta \rangle = \langle \omega, X^\flat \wedge \eta \rangle, $$ so if we apply $\langle\langle \eta, \cdot \rangle\rangle$ (here I am taking the $L^2$ inner product and assuming the forms are compactly supported) to Cartan's formula, we get $$ \langle\langle L_X \omega, \eta \rangle\rangle = \langle\langle \omega, X^\flat \wedge d^*\eta + d^*(X^\flat \wedge \eta) \rangle\rangle. $$ For the left-hand side, we can write \begin{align*} \langle L_X \omega, \eta \rangle &= -\langle \omega, L_X \eta \rangle + d\langle \omega,\eta\rangle(X) - (L_Xg)(\omega,\eta) \\ &= -\langle \omega, L_X \eta + \text{div}(X)\eta \rangle - \text{div}(\langle\omega,\eta\rangle X) - (L_Xg)(\omega,\eta). \end{align*} The divergence in the second term will die after integration, but how do I deal with the last term?","It is well-known that if is a vector field and is a form, then we have Cartan's ""magic"" formula Assuming that we are on a (pseudo-)Riemannian manifold, I would like to obtain an ""adjoint"" formula for the codifferential. It is also known that so if we apply (here I am taking the inner product and assuming the forms are compactly supported) to Cartan's formula, we get For the left-hand side, we can write The divergence in the second term will die after integration, but how do I deal with the last term?","X \omega  L_X \omega = d\iota_X \omega + \iota_X d\omega.   \langle \iota_X \omega, \eta \rangle = \langle \omega, X^\flat \wedge \eta \rangle,  \langle\langle \eta, \cdot \rangle\rangle L^2  \langle\langle L_X \omega, \eta \rangle\rangle = \langle\langle \omega, X^\flat \wedge d^*\eta + d^*(X^\flat \wedge \eta) \rangle\rangle.  \begin{align*}
\langle L_X \omega, \eta \rangle &= -\langle \omega, L_X \eta \rangle + d\langle \omega,\eta\rangle(X) - (L_Xg)(\omega,\eta) \\
&= -\langle \omega, L_X \eta + \text{div}(X)\eta \rangle - \text{div}(\langle\omega,\eta\rangle X) - (L_Xg)(\omega,\eta).
\end{align*}","['differential-geometry', 'riemannian-geometry', 'semi-riemannian-geometry']"
30,Constructing a Diffeomorphism between a Cone like and cylinder surface,Constructing a Diffeomorphism between a Cone like and cylinder surface,,"I am told very specifically that a cone has the following definition: $$C_1 = \{(x,y,z) \in \mathbb{R^3} | z^2 = x^2 + y^2 , z > 0\}$$ Please note the $z>0$ part. I want to map it to a cylinder of the form: $$C_2 = \{(x,y,z) \in \mathbb{R^3} | x^2 + y^2 = 1\}$$ If $f:C_1 \rightarrow C_2$ is smooth, inverse exist and is smooth, then we are in business! I know that in topology we would say that the point in the cone would make these two not topologically equivalent, but the definition here is excluding that point. So would the following map work: $$f(x,y,z) = (\frac{x}{z}, \frac{y}{z}, z)$$ Clearly, $(x/z)^2 + (y/z)^2 = 1$ as required. furthermore, the function is differentiable in $z$ as long as $z > 0$ . The inverse also exists as: $$f^{-1}(u,v,w) = (uw,vw,w)$$ Which is clearly smooth wrt all variables. Hence, am I correct in concluding that these two are diffeomorphic?","I am told very specifically that a cone has the following definition: Please note the part. I want to map it to a cylinder of the form: If is smooth, inverse exist and is smooth, then we are in business! I know that in topology we would say that the point in the cone would make these two not topologically equivalent, but the definition here is excluding that point. So would the following map work: Clearly, as required. furthermore, the function is differentiable in as long as . The inverse also exists as: Which is clearly smooth wrt all variables. Hence, am I correct in concluding that these two are diffeomorphic?","C_1 = \{(x,y,z) \in \mathbb{R^3} | z^2 = x^2 + y^2 , z > 0\} z>0 C_2 = \{(x,y,z) \in \mathbb{R^3} | x^2 + y^2 = 1\} f:C_1 \rightarrow C_2 f(x,y,z) = (\frac{x}{z}, \frac{y}{z}, z) (x/z)^2 + (y/z)^2 = 1 z z > 0 f^{-1}(u,v,w) = (uw,vw,w)","['differential-geometry', 'surfaces', 'diffeomorphism']"
31,Properties of $\Gamma$ regarding $\operatorname{Hom}$ and $\otimes$.,Properties of  regarding  and .,\Gamma \operatorname{Hom} \otimes,"In Tu's book on differential geometry he defines a connection on a smooth vector bundle $E \to M$ as $\nabla : \mathfrak{X}(M) \times \Gamma(E) \to \Gamma(E)$ so that $\nabla$ is $C^\infty$ -linear on $X \in \mathfrak{X}(M)$ and $\Bbb R$ -linear on $s \in \Gamma(E)$ . On the other hand wikipedia defines a connection on a vector bundle as $\nabla : \Gamma(E) \to \Gamma(T^*M \otimes E)$ such that it satisfies the Leibniz rule. This question is more about the properties of $\Gamma$ and $\otimes$ than it is about connections, but I would be interested in understanding how I can go from $\nabla : \Gamma(E) \to \Gamma(T^*M \otimes E)$ to the one given by Tu? Do I need that $T^*M\otimes E \cong \mathrm{Hom}(TM,E)$ and is there some property that says something about the Hom functor or the tensor product under $\Gamma$ ?","In Tu's book on differential geometry he defines a connection on a smooth vector bundle as so that is -linear on and -linear on . On the other hand wikipedia defines a connection on a vector bundle as such that it satisfies the Leibniz rule. This question is more about the properties of and than it is about connections, but I would be interested in understanding how I can go from to the one given by Tu? Do I need that and is there some property that says something about the Hom functor or the tensor product under ?","E \to M \nabla : \mathfrak{X}(M) \times \Gamma(E) \to \Gamma(E) \nabla C^\infty X \in \mathfrak{X}(M) \Bbb R s \in \Gamma(E) \nabla : \Gamma(E) \to \Gamma(T^*M \otimes E) \Gamma \otimes \nabla : \Gamma(E) \to \Gamma(T^*M \otimes E) T^*M\otimes E \cong \mathrm{Hom}(TM,E) \Gamma",['differential-geometry']
32,Locally free circle actions on Euclidean space,Locally free circle actions on Euclidean space,,"I've been wandering whether or not there are locally free smooth circle actions on $\mathbb{R}^n$ , or, more specifically, if an Euclidean space would admit a smooth nonvanishing vector field $X$ whose orbits are all periodic. I know this cannot happen in $\mathbb{R}^2$ , and I suspect it is true in every dimension. I know that, since $S^1$ is compact, we can construct an invariant metric on $\mathbb{R}^n$ using an averaging procedure, and therefore consider the $S^1$ -action to be an action by isometries. If we could somehow show that these isometries must necessarily be some sort of rotation then they would have fixed points, and therefore could not be locally free. This seems to work in $\mathbb{R}^3$ , but I'm not sure how to turn this idea into a rigorous argument, or if it would still hold in higher dimensions. Any tips, better arguments or counterexamples would be welcome. A related but more general question is whether or not $\mathbb{R}^n$ admit regular foliations by circles.","I've been wandering whether or not there are locally free smooth circle actions on , or, more specifically, if an Euclidean space would admit a smooth nonvanishing vector field whose orbits are all periodic. I know this cannot happen in , and I suspect it is true in every dimension. I know that, since is compact, we can construct an invariant metric on using an averaging procedure, and therefore consider the -action to be an action by isometries. If we could somehow show that these isometries must necessarily be some sort of rotation then they would have fixed points, and therefore could not be locally free. This seems to work in , but I'm not sure how to turn this idea into a rigorous argument, or if it would still hold in higher dimensions. Any tips, better arguments or counterexamples would be welcome. A related but more general question is whether or not admit regular foliations by circles.",\mathbb{R}^n X \mathbb{R}^2 S^1 \mathbb{R}^n S^1 \mathbb{R}^3 \mathbb{R}^n,"['differential-geometry', 'differential-topology', 'group-actions', 'vector-fields', 'foliations']"
33,Curvature of streamlines as a Scalar field from a given vector field?,Curvature of streamlines as a Scalar field from a given vector field?,,"Some context I'm looking for an approach to print the stress trajectory of a part via composite 3D printing, however our composite 3D printer only allows for a turn radius of 3mm ( $C_r = 3$ ). I believe if I can find a transform $T_r$ that acts on the stress field to give the radius of curvature at any given point I can constrain the resultant scalar field to be greater than $C_r$ then use inverse transform of the resultant scalar field to plot the composite path. I will write this as: $$T_r(F(x,y)) = R(x,y)$$ A mathematical definition Given a vector field $F(x, y)$ for every point $(x, y)$ there exists a streamline $\gamma(s) = (x(s), y(s))$ such that $$\gamma^\prime(s) = F(\gamma(s))$$ I believe I can obtain the radius of curvature of the streamline to a specic point in space using the equation of curvature of a parametric equation: $$\kappa = \frac{\det(\gamma^\prime, \gamma^{\prime\prime})}{||\gamma^\prime||^3}$$ however I am unsure how to solve this or if my mathematical logic applies.","Some context I'm looking for an approach to print the stress trajectory of a part via composite 3D printing, however our composite 3D printer only allows for a turn radius of 3mm ( ). I believe if I can find a transform that acts on the stress field to give the radius of curvature at any given point I can constrain the resultant scalar field to be greater than then use inverse transform of the resultant scalar field to plot the composite path. I will write this as: A mathematical definition Given a vector field for every point there exists a streamline such that I believe I can obtain the radius of curvature of the streamline to a specic point in space using the equation of curvature of a parametric equation: however I am unsure how to solve this or if my mathematical logic applies.","C_r = 3 T_r C_r T_r(F(x,y)) = R(x,y) F(x, y) (x, y) \gamma(s) = (x(s), y(s)) \gamma^\prime(s) = F(\gamma(s)) \kappa = \frac{\det(\gamma^\prime, \gamma^{\prime\prime})}{||\gamma^\prime||^3}","['calculus', 'differential-geometry', 'partial-differential-equations', 'vector-fields', 'parametric']"
34,Book that Develops the Theory of Tangent Space whilst Defining Tangent Vectors as Equivalence Classes of Curves,Book that Develops the Theory of Tangent Space whilst Defining Tangent Vectors as Equivalence Classes of Curves,,"Currently reading Lee's Introduction to Smooth Manifolds . At the end of chapter $3$ he mentions that tangent vectors may be defined in terms of equivalence classes of curves, but by that time he has developed the theory of the tangent space using Derivations, and thus does not delve further. Is there a book that develops the theory of tangent spaces whilst definiting tangent vectors as equivalence classes of curves?","Currently reading Lee's Introduction to Smooth Manifolds . At the end of chapter he mentions that tangent vectors may be defined in terms of equivalence classes of curves, but by that time he has developed the theory of the tangent space using Derivations, and thus does not delve further. Is there a book that develops the theory of tangent spaces whilst definiting tangent vectors as equivalence classes of curves?",3,"['differential-geometry', 'reference-request', 'definition', 'smooth-manifolds', 'tangent-spaces']"
35,What kind of object is the (second) exterior derivative of a moving point $R$ in $\mathbb R^n$? What does $dR\wedge\omega \mathbf e$ mean?,What kind of object is the (second) exterior derivative of a moving point  in ? What does  mean?,R \mathbb R^n dR\wedge\omega \mathbf e,"TL;DR: Given $f:\mathbb R \to \mathbb R^n$ smooth enough, what are $df$ and $d^2f$ and how are they computed wrt possibly moving bases $\{e_i(t)\}$ ? I (believe that I) understand the answers in the ""reverse"" case where $g:\mathbb R^n \to \mathbb R$ - then $dg$ is the second component of the natural extension of $f$ to a fiber bundle homomorphism $T\mathbb R^n\to T\mathbb R$ , that is, $dg:\mathbb R^n \to (R^n)^*$ , and $d^2g:\mathbb R^n\to(R^n)^*\wedge (R^n)^*$ , or $dg\in A^1(T\mathbb R^n)$ and $d^2g\in A^2(T\mathbb R^n)$ . But with my $f$ , the $df$ and $d^2f$ just don't ""type check"" because the ""star"" gives scalar-valued functions, not vector-valued ones. Long story : I'm reading a physics book and I just can't get my head around what they're doing. Assume every function here to be $C^\infty$ . Using Einstein notation , i.e. every expression $a^i b_i$ is meant to read $\sum_i a^ib_i$ . Setup. In a smooth manifold $M\subseteq \mathbb R^n$ we have a rigid body moving within a time interval $I\subseteq \mathbb R$ . The body movement is described by a point $\mathbf R:I\to M$ and a coordinate system (basis) $e_i : I\to \mathbb R^n,i=1,\ldots,n$ , thought of as ""attached"" to the body for each $t\in I$ at the point $\mathbf R(t)$ . For brevity I'll omit the dependence on time and write $\mathbf R$ even if $\mathbf R(t)$ is meant (and $e_i$ instead of $e_i(t)$ ). Denote the standard basis in $\mathbb R^n$ with $\boldsymbol{\epsilon}_{i}$ . Now $\mathbf R=R^i \boldsymbol\epsilon_i$ for some $R^i(t),i=1,\ldots,n$ . Since (for each $t\in I$ ) $\{e_i(t)\}$ forms a basis in $\mathbb R^n$ , too, we can express $\boldsymbol{e}_{i}=g_{i}^{j}(\mathbf{R})\boldsymbol{\epsilon}_{j}$ and $\boldsymbol{\epsilon}_{i}=\left(g^{-1}(\mathbf{R})\right)_{i}^{j}\boldsymbol{e}_{j}$ for some invertible matrices $g(\textbf R(t))$ . First differential. Next in the book they take the differential of $\mathbf R$ and do some computations: $$ d\mathbf{R} =d\left(R^{i}\boldsymbol{\epsilon}_{i}\right) =\left(dR^{i}\right)\boldsymbol{\epsilon}_{i} =\left(dR^{i}\right)\left(g^{-1}(\mathbf{R})\right)_{i}^{j}\boldsymbol{e}_{j}$$ I'm uneasy about the second equality $d\left(R^{i}\boldsymbol{\epsilon}_{i}\right) =\left(dR^{i}\right)\boldsymbol{\epsilon}_{i}$ transforming the differential of a vector into a vector multiplied by the differential of a scalar function . Though suspicious, at least symbolically it seems legit because $\boldsymbol{\epsilon}_{i}$ does not depend on the time $t\in I$ , so it somehow makes sense to reduce the action of $d$ only to the scalar multiplier $R^i$ . What is the nature of the product between a differential 1-form $dR^i$ and a vector $\boldsymbol \epsilon_i$ ? Second differential. Here's where it gets too wild for me to move forward easily. They take the second differential of $\mathbf{R}$ like this: $$0=dd\mathbf{R}=d(\omega^j \boldsymbol{e}_{j})=d\omega^j \boldsymbol{e}_{j}-\omega^j \wedge d\boldsymbol{e}_{j}$$ where the $\omega^j$ are defined s.t. $d\mathbf{R}=\omega^j \boldsymbol{e}_{j}$ . We have now a product of a two-form $d\omega^j$ with a vector $\boldsymbol{e}_{j}$ , plus a wedge product of a one-form $\omega^j$ with a ""vector-form"" $d\boldsymbol{e}_{j}$ , and both are supposed to be of the same type. $\omega^j \wedge d\boldsymbol{e}_{j}$ looks like complete non-sense to me, because a wedge product can take only same-type objects. There is $V\wedge V$ but never $V\wedge W$ for $V\neq W$ . And yet, here $\omega^j$ is a ""scalar"" one-form while $d\boldsymbol{e}_{j}$ is a ""vector"" one-form, and they're wedged together. And I'm not even sure if I have to write the vector in the second position, it seems if I write $-d\boldsymbol{e}_{j} \wedge \omega^j$ it'd be ok, too. I suspected something like a ""vector-valued form"" should exist, and indeed there's a wikipedia article on it. I read through it a few times, but I got too confused with the abstract construction done in two parts - defining a ""bundle-valued"" form and then taking a tensor product of bundles. Neither could I really understand what are the rules I can use in my more ""practical"" problem. My question s are: what is the ""type signature"" of $\mathbf R$ as a (vector-valued) diffferential (0-)form, allowing us take its exterior derivatives $d\mathbf R$ and $d^2\mathbf R$ ? what does it mean to multiply ""scalar"" and ""vector"" forms? how is such a mixed-type product computed? Why does $d(fg)=df\wedge g-f\wedge dg$ still apply, if $f$ and $g$ are differently typed?","TL;DR: Given smooth enough, what are and and how are they computed wrt possibly moving bases ? I (believe that I) understand the answers in the ""reverse"" case where - then is the second component of the natural extension of to a fiber bundle homomorphism , that is, , and , or and . But with my , the and just don't ""type check"" because the ""star"" gives scalar-valued functions, not vector-valued ones. Long story : I'm reading a physics book and I just can't get my head around what they're doing. Assume every function here to be . Using Einstein notation , i.e. every expression is meant to read . Setup. In a smooth manifold we have a rigid body moving within a time interval . The body movement is described by a point and a coordinate system (basis) , thought of as ""attached"" to the body for each at the point . For brevity I'll omit the dependence on time and write even if is meant (and instead of ). Denote the standard basis in with . Now for some . Since (for each ) forms a basis in , too, we can express and for some invertible matrices . First differential. Next in the book they take the differential of and do some computations: I'm uneasy about the second equality transforming the differential of a vector into a vector multiplied by the differential of a scalar function . Though suspicious, at least symbolically it seems legit because does not depend on the time , so it somehow makes sense to reduce the action of only to the scalar multiplier . What is the nature of the product between a differential 1-form and a vector ? Second differential. Here's where it gets too wild for me to move forward easily. They take the second differential of like this: where the are defined s.t. . We have now a product of a two-form with a vector , plus a wedge product of a one-form with a ""vector-form"" , and both are supposed to be of the same type. looks like complete non-sense to me, because a wedge product can take only same-type objects. There is but never for . And yet, here is a ""scalar"" one-form while is a ""vector"" one-form, and they're wedged together. And I'm not even sure if I have to write the vector in the second position, it seems if I write it'd be ok, too. I suspected something like a ""vector-valued form"" should exist, and indeed there's a wikipedia article on it. I read through it a few times, but I got too confused with the abstract construction done in two parts - defining a ""bundle-valued"" form and then taking a tensor product of bundles. Neither could I really understand what are the rules I can use in my more ""practical"" problem. My question s are: what is the ""type signature"" of as a (vector-valued) diffferential (0-)form, allowing us take its exterior derivatives and ? what does it mean to multiply ""scalar"" and ""vector"" forms? how is such a mixed-type product computed? Why does still apply, if and are differently typed?","f:\mathbb R \to \mathbb R^n df d^2f \{e_i(t)\} g:\mathbb R^n \to \mathbb R dg f T\mathbb R^n\to T\mathbb R dg:\mathbb R^n \to (R^n)^* d^2g:\mathbb R^n\to(R^n)^*\wedge (R^n)^* dg\in A^1(T\mathbb R^n) d^2g\in A^2(T\mathbb R^n) f df d^2f C^\infty a^i b_i \sum_i a^ib_i M\subseteq \mathbb R^n I\subseteq \mathbb R \mathbf R:I\to M e_i : I\to \mathbb R^n,i=1,\ldots,n t\in I \mathbf R(t) \mathbf R \mathbf R(t) e_i e_i(t) \mathbb R^n \boldsymbol{\epsilon}_{i} \mathbf R=R^i \boldsymbol\epsilon_i R^i(t),i=1,\ldots,n t\in I \{e_i(t)\} \mathbb R^n \boldsymbol{e}_{i}=g_{i}^{j}(\mathbf{R})\boldsymbol{\epsilon}_{j} \boldsymbol{\epsilon}_{i}=\left(g^{-1}(\mathbf{R})\right)_{i}^{j}\boldsymbol{e}_{j} g(\textbf R(t)) \mathbf R  d\mathbf{R}
=d\left(R^{i}\boldsymbol{\epsilon}_{i}\right)
=\left(dR^{i}\right)\boldsymbol{\epsilon}_{i}
=\left(dR^{i}\right)\left(g^{-1}(\mathbf{R})\right)_{i}^{j}\boldsymbol{e}_{j} d\left(R^{i}\boldsymbol{\epsilon}_{i}\right) =\left(dR^{i}\right)\boldsymbol{\epsilon}_{i} \boldsymbol{\epsilon}_{i} t\in I d R^i dR^i \boldsymbol \epsilon_i \mathbf{R} 0=dd\mathbf{R}=d(\omega^j \boldsymbol{e}_{j})=d\omega^j \boldsymbol{e}_{j}-\omega^j \wedge d\boldsymbol{e}_{j} \omega^j d\mathbf{R}=\omega^j \boldsymbol{e}_{j} d\omega^j \boldsymbol{e}_{j} \omega^j d\boldsymbol{e}_{j} \omega^j \wedge d\boldsymbol{e}_{j} V\wedge V V\wedge W V\neq W \omega^j d\boldsymbol{e}_{j} -d\boldsymbol{e}_{j} \wedge \omega^j \mathbf R d\mathbf R d^2\mathbf R d(fg)=df\wedge g-f\wedge dg f g","['differential-geometry', 'smooth-manifolds', 'differential', 'exterior-derivative']"
36,Understanding $1$-forms as 'onions',Understanding -forms as 'onions',1,"I stumbled across this paper providing an intuition of differential forms. On page $3$ the paper reads ""Think of a vector as a pin and a one-form as an onion. You evaluate a one-form on a vector by counting how many onion layers it goes through. More generally we represent a one-form on an $n$ -manifold by drawing $(n − 1)$ -dimensional surfaces on it. We call these surfaces leaves . In the general case we can still count how many of these leaves each vector goes through. [...] This picture makes it easy to integrate a one-form."" I understand the definition of a $k$ -form, as well as this (different?) interpretation of them, yet the phrase ""You evaluate a one-form on a vector by counting how many onion layers it goes through"" remains a mystery to me. What does the quoted passage mean?","I stumbled across this paper providing an intuition of differential forms. On page the paper reads ""Think of a vector as a pin and a one-form as an onion. You evaluate a one-form on a vector by counting how many onion layers it goes through. More generally we represent a one-form on an -manifold by drawing -dimensional surfaces on it. We call these surfaces leaves . In the general case we can still count how many of these leaves each vector goes through. [...] This picture makes it easy to integrate a one-form."" I understand the definition of a -form, as well as this (different?) interpretation of them, yet the phrase ""You evaluate a one-form on a vector by counting how many onion layers it goes through"" remains a mystery to me. What does the quoted passage mean?",3 n (n − 1) k,"['differential-geometry', 'definition', 'intuition', 'differential-forms']"
37,Derivation for expression for second covariant derivative,Derivation for expression for second covariant derivative,,"This is a direct follow up to my earlier question: Reconciling different expressions for Riemann curvature tensor . I think it deserves a separate question, plus I don't want to disturb the answerer of the earlier post by repeated queries in comments. The answer in that highlights this identity: $$\nabla_{\partial_a}(\nabla_{\partial_b}Z)=\nabla_{\nabla_{\partial_a}\partial_b}Z+\nabla^2_{\partial_a,\partial_b}Z\tag{1}$$ The derivation of the above identity is through a calculation of $\nabla_X(\nabla_Y(Z))$ . I will avoid using any notational shortcuts that people get used to after experience. Here is my version of the calculation (the only version of chain rule for covariant derivatives I know is $\nabla_X(fY)=X(f)Y+f\nabla_X(Y)$ , which is what I'm using): $$\nabla_X(\nabla_Y(Z))=X^a\nabla_{\partial_a}(Y^b\nabla_{\partial_b}(Z))=X^a(\partial_aY^b)(\nabla_{\partial_b}(Z))+X^aY^b\nabla_{\partial_a}(\nabla_{\partial_b}(Z))$$ $$=X(Y^b)(\nabla_{\partial_b}(Z))+X^aY^b\nabla_{\partial_a}(\nabla_{\partial_b}(Z))$$ $$=\nabla_X(Y^b)(\nabla_{\partial_b}(Z))+X^aY^b\nabla_{\partial_a}(\nabla_{\partial_b}(Z))\tag{2}$$ Now on the RHS, I have a problem with both terms! First term : It seems that the 1st RHS term is supposed to equal $\nabla_{\nabla_X(Y)}(Z)$ . But then $$\nabla_{\nabla_X(Y)}(Z)=\nabla_{(\nabla_X(Y))^b\partial_b}(Z)=(\nabla_X(Y))^b\nabla_{\partial_b}(Z)\tag{3}$$ Let me evaluate $(\nabla_X(Y))^b$ : $$(\nabla_X(Y))^b=(\nabla_X(Y^c\partial_c))^b=\big(X(Y^c)\partial_c+Y^c\nabla_X(\partial_c)\big)^b=X(Y^b)+(Y^c\nabla_X(\partial_c))^b$$ $$=\nabla_X(Y^b)+Y^c(X^d\nabla_{\partial_d}(\partial_c))^b=\nabla_X(Y^b)+Y^c(X^d\Gamma^e_{dc}\partial_e)^b$$ $$=\nabla_X(Y^b)+Y^cX^d\Gamma^b_{dc}\tag{4}$$ This means $$\nabla_{\nabla_X(Y)}(Z)=(\nabla_X(Y))^b\nabla_{\partial_b}(Z)\neq \nabla_X(Y^b)(\nabla_{\partial_b}(Z))\tag{5}$$ How is this inconsistency resolved? Second term : The 2nd RHS term is supposed to be $\nabla_{X,Y}^2(Z)$ . This means that $$\big(\nabla_{X,Y}^2(Z)\big)^c=\big(\ \ X^aY^b\nabla_{\partial_a}(\nabla_{\partial_b}(Z))\ \ \big)^c=X^aY^b\big(\nabla_{\partial_a}(\nabla_{\partial_b}(Z))(\text{d}x^c)\big)$$ where the last term involves the $(1,0)$ -tensor $\nabla_{\partial_a}(\nabla_{\partial_b}(Z))$ acting on $\text{d}x^c$ . But on wikipedia , the following equation is given: $(\nabla^2_{u,v}w)^a=u^cv^b\nabla_c\nabla_bw^a$ (I don't know if this equation is a result , or a definition , or what), which can be re-written as $$\big(\nabla_{X,Y}^2(Z)\big)^c=X^aY^b\nabla_a\nabla_bZ^c=X^aY^b\big(\nabla\nabla Z(\text{d}x^c,\partial_a,\partial_b)\big)$$ It boils down to showing that $\nabla\nabla Z(\text{d}x^c,\partial_a,\partial_b)=\nabla_{\partial_a}(\nabla_{\partial_b}(Z))(\text{d}x^c)$ . Now by definition of total covariant derivative, $$\nabla(\mathcal{A})(\omega^1,\ldots,\omega^r,X_1,\ldots,X_s,X)=\nabla_X(\mathcal{A})(\omega^1,\ldots,\omega^r,X_1,\ldots,X_s)$$ So $$\nabla_{\partial_a}(\nabla_{\partial_b}(Z))(\text{d}x^c)=\nabla(\nabla_{\partial_b}(Z))(\text{d}x^c,\partial_a)\tag{6}$$ and $$\nabla\nabla Z(\text{d}x^c,\partial_a,\partial_b)\equiv\nabla(\nabla(Z))(\text{d}x^c,\partial_a,\partial_b)=\nabla_{\partial_b}(\nabla(Z))(\text{d}x^c,\partial_a)\tag{7}$$ How do I even equate these two (RHS of eq.s 6 and 7) ? Is there some property of total covariant derivative that I'm missing out on?","This is a direct follow up to my earlier question: Reconciling different expressions for Riemann curvature tensor . I think it deserves a separate question, plus I don't want to disturb the answerer of the earlier post by repeated queries in comments. The answer in that highlights this identity: The derivation of the above identity is through a calculation of . I will avoid using any notational shortcuts that people get used to after experience. Here is my version of the calculation (the only version of chain rule for covariant derivatives I know is , which is what I'm using): Now on the RHS, I have a problem with both terms! First term : It seems that the 1st RHS term is supposed to equal . But then Let me evaluate : This means How is this inconsistency resolved? Second term : The 2nd RHS term is supposed to be . This means that where the last term involves the -tensor acting on . But on wikipedia , the following equation is given: (I don't know if this equation is a result , or a definition , or what), which can be re-written as It boils down to showing that . Now by definition of total covariant derivative, So and How do I even equate these two (RHS of eq.s 6 and 7) ? Is there some property of total covariant derivative that I'm missing out on?","\nabla_{\partial_a}(\nabla_{\partial_b}Z)=\nabla_{\nabla_{\partial_a}\partial_b}Z+\nabla^2_{\partial_a,\partial_b}Z\tag{1} \nabla_X(\nabla_Y(Z)) \nabla_X(fY)=X(f)Y+f\nabla_X(Y) \nabla_X(\nabla_Y(Z))=X^a\nabla_{\partial_a}(Y^b\nabla_{\partial_b}(Z))=X^a(\partial_aY^b)(\nabla_{\partial_b}(Z))+X^aY^b\nabla_{\partial_a}(\nabla_{\partial_b}(Z)) =X(Y^b)(\nabla_{\partial_b}(Z))+X^aY^b\nabla_{\partial_a}(\nabla_{\partial_b}(Z)) =\nabla_X(Y^b)(\nabla_{\partial_b}(Z))+X^aY^b\nabla_{\partial_a}(\nabla_{\partial_b}(Z))\tag{2} \nabla_{\nabla_X(Y)}(Z) \nabla_{\nabla_X(Y)}(Z)=\nabla_{(\nabla_X(Y))^b\partial_b}(Z)=(\nabla_X(Y))^b\nabla_{\partial_b}(Z)\tag{3} (\nabla_X(Y))^b (\nabla_X(Y))^b=(\nabla_X(Y^c\partial_c))^b=\big(X(Y^c)\partial_c+Y^c\nabla_X(\partial_c)\big)^b=X(Y^b)+(Y^c\nabla_X(\partial_c))^b =\nabla_X(Y^b)+Y^c(X^d\nabla_{\partial_d}(\partial_c))^b=\nabla_X(Y^b)+Y^c(X^d\Gamma^e_{dc}\partial_e)^b =\nabla_X(Y^b)+Y^cX^d\Gamma^b_{dc}\tag{4} \nabla_{\nabla_X(Y)}(Z)=(\nabla_X(Y))^b\nabla_{\partial_b}(Z)\neq \nabla_X(Y^b)(\nabla_{\partial_b}(Z))\tag{5} \nabla_{X,Y}^2(Z) \big(\nabla_{X,Y}^2(Z)\big)^c=\big(\ \ X^aY^b\nabla_{\partial_a}(\nabla_{\partial_b}(Z))\ \ \big)^c=X^aY^b\big(\nabla_{\partial_a}(\nabla_{\partial_b}(Z))(\text{d}x^c)\big) (1,0) \nabla_{\partial_a}(\nabla_{\partial_b}(Z)) \text{d}x^c (\nabla^2_{u,v}w)^a=u^cv^b\nabla_c\nabla_bw^a \big(\nabla_{X,Y}^2(Z)\big)^c=X^aY^b\nabla_a\nabla_bZ^c=X^aY^b\big(\nabla\nabla Z(\text{d}x^c,\partial_a,\partial_b)\big) \nabla\nabla Z(\text{d}x^c,\partial_a,\partial_b)=\nabla_{\partial_a}(\nabla_{\partial_b}(Z))(\text{d}x^c) \nabla(\mathcal{A})(\omega^1,\ldots,\omega^r,X_1,\ldots,X_s,X)=\nabla_X(\mathcal{A})(\omega^1,\ldots,\omega^r,X_1,\ldots,X_s) \nabla_{\partial_a}(\nabla_{\partial_b}(Z))(\text{d}x^c)=\nabla(\nabla_{\partial_b}(Z))(\text{d}x^c,\partial_a)\tag{6} \nabla\nabla Z(\text{d}x^c,\partial_a,\partial_b)\equiv\nabla(\nabla(Z))(\text{d}x^c,\partial_a,\partial_b)=\nabla_{\partial_b}(\nabla(Z))(\text{d}x^c,\partial_a)\tag{7}","['differential-geometry', 'connections']"
38,Relation between connection on vector bundle and Ehresmann connection on frame bundle,Relation between connection on vector bundle and Ehresmann connection on frame bundle,,"I'll be using the conventions, notation and (numbered) results from Tu's Differential Geometry book. Let $M$ be a smooth manifold, $E\to M$ a (real) vector bundle of rank $r$ with a connection $\nabla:\Gamma(E)\to\Omega^1(M)\otimes\Gamma(E)$ . There is a way to obtain a connection on $E$ via the Consider the frame bundle $\pi:\text{Fr}(E)\to M$ of $E$ , which has an induced Ehresmann-connection $\omega\in\Omega^1(\text{Fr}(E),\text{Fr}(E)\times\mathfrak{gl}_r\mathbb R)$ , and whose corresponding associated vector bundle $\text{Fr}(E)\times_1\mathbb R^k$ with respect to the identity representation $1:\text{GL}(r,\mathbb R)\to\text{GL}(r,\mathbb R)$ is canonically isomorphic to $E$ . Let's denote by $\Omega_1^k(\text{Fr}(E),\text{Fr}(E)\times\mathbb R^r)$ the $\mathbb R^r$ -valued $k$ -forms on the frame bundle which are right-invariant and horizontal, meaning that $r_g^*\omega=\omega$ and that $\omega$ vanishes as soon as an input vector is vertical. There is a covariant derivative $$ D:\Omega_1^k(\text{Fr}(E),\text{Fr}(E)\times\mathbb R^r)\to \Omega_1^{k+1}(\text{Fr}(E),\text{Fr}(E)\times\mathbb R^r),\omega\mapsto (d\omega)^h, $$ where $(d\omega)^h(v_1,\dots,v_{k+1})=dw(hv_1,\dots,hv_{k+1})$ , where by $hv$ we mean the horizontal component of $v$ . By Theorem 31.9 we have an identification $$ \Omega_1^k(\text{Fr}(E),\text{Fr}(E)\times\mathfrak{gl}_r\mathbb R))\cong\Omega^k(M,\text{Fr}(E)\times_1\mathbb R^r), $$ which means that the covariant derivative $D$ can be considered as a map $$ \Omega^k(M)\otimes\Gamma(E)\to\Omega^{k+1}(M)\otimes\Gamma(E). $$ My question is as follows: I want to show that for $k=0$ this map corresponds to $\nabla$ , but I'm not sure how to show this rigourously; due to the identifications made it is difficult for me to imagine how $D$ looks like as a map from $\Gamma(E)$ to $\Omega^1(M)\otimes\Gamma(E)$ . By Theorem 31.19 I know that for $\phi\in\Omega^0_1(\text{Fr}(E),\text{Fr}(E)\times\mathbb R^r)\cong\Gamma(\text{Fr}(E)\times\mathbb R^r)$ we have $$ D\phi=d\phi+\omega\cdot\phi, $$ where the action $\omega\cdot\phi$ is the natural action of $\omega\in\Omega^1(\text{Fr}(E))\otimes\Gamma(\text{Fr}(E)\times\mathfrak{gl}_r\mathbb R))$ on $\phi$ . Note that the formula above looks a lot like the formula $$ \nabla(f^i\sigma_i)=df^i\otimes\sigma_i+f^i\nabla\sigma_i=df^i\otimes\sigma+f^i\omega^j_i\otimes\sigma_j, $$ where $\omega_\sigma=(\omega^i_j)$ is the connection matrix corresponding to the local frame $(\sigma_i)\subset\Gamma(E\vert_U)$ . If we think of the local frame $(\sigma_i)$ as a section $\sigma\in\Gamma(\text{Fr}E\vert_U)$ , then by Theorem 29.10 we have $\omega_\sigma=\sigma^*\omega$ . So I feel like I've got most of the ingredients, but I can't make it into a complete and formal argument. Could someone help me out?","I'll be using the conventions, notation and (numbered) results from Tu's Differential Geometry book. Let be a smooth manifold, a (real) vector bundle of rank with a connection . There is a way to obtain a connection on via the Consider the frame bundle of , which has an induced Ehresmann-connection , and whose corresponding associated vector bundle with respect to the identity representation is canonically isomorphic to . Let's denote by the -valued -forms on the frame bundle which are right-invariant and horizontal, meaning that and that vanishes as soon as an input vector is vertical. There is a covariant derivative where , where by we mean the horizontal component of . By Theorem 31.9 we have an identification which means that the covariant derivative can be considered as a map My question is as follows: I want to show that for this map corresponds to , but I'm not sure how to show this rigourously; due to the identifications made it is difficult for me to imagine how looks like as a map from to . By Theorem 31.19 I know that for we have where the action is the natural action of on . Note that the formula above looks a lot like the formula where is the connection matrix corresponding to the local frame . If we think of the local frame as a section , then by Theorem 29.10 we have . So I feel like I've got most of the ingredients, but I can't make it into a complete and formal argument. Could someone help me out?","M E\to M r \nabla:\Gamma(E)\to\Omega^1(M)\otimes\Gamma(E) E \pi:\text{Fr}(E)\to M E \omega\in\Omega^1(\text{Fr}(E),\text{Fr}(E)\times\mathfrak{gl}_r\mathbb R) \text{Fr}(E)\times_1\mathbb R^k 1:\text{GL}(r,\mathbb R)\to\text{GL}(r,\mathbb R) E \Omega_1^k(\text{Fr}(E),\text{Fr}(E)\times\mathbb R^r) \mathbb R^r k r_g^*\omega=\omega \omega 
D:\Omega_1^k(\text{Fr}(E),\text{Fr}(E)\times\mathbb R^r)\to \Omega_1^{k+1}(\text{Fr}(E),\text{Fr}(E)\times\mathbb R^r),\omega\mapsto (d\omega)^h,
 (d\omega)^h(v_1,\dots,v_{k+1})=dw(hv_1,\dots,hv_{k+1}) hv v 
\Omega_1^k(\text{Fr}(E),\text{Fr}(E)\times\mathfrak{gl}_r\mathbb R))\cong\Omega^k(M,\text{Fr}(E)\times_1\mathbb R^r),
 D 
\Omega^k(M)\otimes\Gamma(E)\to\Omega^{k+1}(M)\otimes\Gamma(E).
 k=0 \nabla D \Gamma(E) \Omega^1(M)\otimes\Gamma(E) \phi\in\Omega^0_1(\text{Fr}(E),\text{Fr}(E)\times\mathbb R^r)\cong\Gamma(\text{Fr}(E)\times\mathbb R^r) 
D\phi=d\phi+\omega\cdot\phi,
 \omega\cdot\phi \omega\in\Omega^1(\text{Fr}(E))\otimes\Gamma(\text{Fr}(E)\times\mathfrak{gl}_r\mathbb R)) \phi 
\nabla(f^i\sigma_i)=df^i\otimes\sigma_i+f^i\nabla\sigma_i=df^i\otimes\sigma+f^i\omega^j_i\otimes\sigma_j,
 \omega_\sigma=(\omega^i_j) (\sigma_i)\subset\Gamma(E\vert_U) (\sigma_i) \sigma\in\Gamma(\text{Fr}E\vert_U) \omega_\sigma=\sigma^*\omega","['differential-geometry', 'connections']"
39,The projective plane as a smooth surface in a 4-dimensional space,The projective plane as a smooth surface in a 4-dimensional space,,"For $(a, b, c)$ pairwise distinct: $$ \begin{align} f: & S^2       & \mapsto & \quad \mathbb{R}^4 \\    & (x, y, z) & \mapsto & \quad (X, Y, Z, W) = (y \cdot z, x \cdot z, x \cdot y, a \cdot x^2 + b \cdot y^2 + c \cdot z^2) \end{align} $$ is a smooth double covering map of the real unit sphere $S^2$ to a surface in the real 4-dimensional space $\mathbb{R}^4$ , and opposite points have the same image, such that it can also be interpreted as an injective embedding of the real projective plane. In particular, the image of $f()$ is a surface, that is, each point has a non-degenerate tangential plane. The image of $f()$ can be defined in the $(X, Y, Z, W)$ coordinates as follows. If $X \cdot Y \cdot Z \neq 0$ : $$     (Y \cdot Z)^2 + (X \cdot Z)^2 + (X \cdot Y)^2 = X \cdot Y \cdot Z \\     a \cdot (Y \cdot Z)^2 + b \cdot (X \cdot Z)^2 + c \cdot (X \cdot Y)^2 = X \cdot Y \cdot Z \cdot W $$ If $X = Y = 0$ and $Z \neq 0$ : $$     (a - b)^2 \cdot (1 - 4 \cdot Z^2) = (2 \cdot W - (a + b))^2 $$ If $X = Z = 0$ and $Y \neq 0$ : $$     (a - c)^2 \cdot (1 - 4 \cdot Z^2) = (2 \cdot W - (a + c))^2 $$ If $Y = Z = 0$ and $X \neq 0$ : $$      (b - c)^2 \cdot (1 - 4 \cdot Z^2) = (2 \cdot W - (b + c))^2 $$ If $X = Y = Z = 0$ : $$      (W - a) \cdot (W - b) \cdot (W - c) = 0 $$ Question 1 : Is the image of $f()$ an algebraic set in the $(X, Y, Z, W)$ coordinates ? Can it be defined by a single ideal, without case analysis ? If yes, what is the ideal in question, explicitly ? If no, how to prove it ? Furthermore, the image of f() consists then of five algebraic pieces fitting together smoothly, without being, as a whole, algebraic; I find it surprising, what happens where the pieces meet ? Question 2 : If $X \cdot Y \cdot Z \neq 0$ , or, equivalently, $x \cdot y \cdot z \neq 0$ , then $$     [x : y : z] = [Y \cdot Z : X \cdot Z : X \cdot Y] $$ Is there a rational formula for each of the other pieces ? If yes, what are the respective formulæ, explicitly ? If no, how to prove it ?","For pairwise distinct: is a smooth double covering map of the real unit sphere to a surface in the real 4-dimensional space , and opposite points have the same image, such that it can also be interpreted as an injective embedding of the real projective plane. In particular, the image of is a surface, that is, each point has a non-degenerate tangential plane. The image of can be defined in the coordinates as follows. If : If and : If and : If and : If : Question 1 : Is the image of an algebraic set in the coordinates ? Can it be defined by a single ideal, without case analysis ? If yes, what is the ideal in question, explicitly ? If no, how to prove it ? Furthermore, the image of f() consists then of five algebraic pieces fitting together smoothly, without being, as a whole, algebraic; I find it surprising, what happens where the pieces meet ? Question 2 : If , or, equivalently, , then Is there a rational formula for each of the other pieces ? If yes, what are the respective formulæ, explicitly ? If no, how to prove it ?","(a, b, c) 
\begin{align}
f: & S^2       & \mapsto & \quad \mathbb{R}^4 \\
   & (x, y, z) & \mapsto & \quad (X, Y, Z, W) = (y \cdot z, x \cdot z, x \cdot y, a \cdot x^2 + b \cdot y^2 + c \cdot z^2)
\end{align}
 S^2 \mathbb{R}^4 f() f() (X, Y, Z, W) X \cdot Y \cdot Z \neq 0 
    (Y \cdot Z)^2 + (X \cdot Z)^2 + (X \cdot Y)^2 = X \cdot Y \cdot Z \\
    a \cdot (Y \cdot Z)^2 + b \cdot (X \cdot Z)^2 + c \cdot (X \cdot Y)^2 = X \cdot Y \cdot Z \cdot W
 X = Y = 0 Z \neq 0 
    (a - b)^2 \cdot (1 - 4 \cdot Z^2) = (2 \cdot W - (a + b))^2
 X = Z = 0 Y \neq 0 
    (a - c)^2 \cdot (1 - 4 \cdot Z^2) = (2 \cdot W - (a + c))^2
 Y = Z = 0 X \neq 0  
    (b - c)^2 \cdot (1 - 4 \cdot Z^2) = (2 \cdot W - (b + c))^2
 X = Y = Z = 0  
    (W - a) \cdot (W - b) \cdot (W - c) = 0
 f() (X, Y, Z, W) X \cdot Y \cdot Z \neq 0 x \cdot y \cdot z \neq 0 
    [x : y : z] = [Y \cdot Z : X \cdot Z : X \cdot Y]
","['differential-geometry', 'algebraic-geometry', 'projective-space', 'birational-geometry']"
40,Why is Lie group unimodularity related to the determinant of the adjoint?,Why is Lie group unimodularity related to the determinant of the adjoint?,,"I'm reading through Michael Taylor's notes from this PDF . The author starts saying that given an $N$ -dimensional Lie group $G$ and some covector $\omega_e \in \bigwedge^N T^*_e G$ , there is a unique differential $N$ -form $\omega_\ell$ that is left-invariant, meaning $\omega_\ell(e)=\omega_e$ and $L_g^*\omega_\ell=\omega_\ell$ with $L_g(h)\equiv gh$ . Similarly, there is a unique right-invariant $\omega_r(e)=\omega_r$ , $R_g^* \omega_r =\omega_r$ . They then observe that these must also satisfy $$R_h^* \omega_\ell = \alpha(h)\omega_\ell, \qquad L_h^* \omega_r = \beta(g) \omega_r,$$ for some pair of homomorphisms $\alpha,\beta:G\to(0,\infty)$ . The group is said to be unimodular iff $\alpha=1$ or $\beta=1$ . Shortly thereafter, the authors discuss the adjoint representation of the group, by defining $$K_g:G\to G, \qquad K_g(h)\equiv ghg^{-1}$$ and defining $\operatorname{Ad}(g)=DK_g(e):T_e G\to T_e G$ , with $D$ denoting the differential. After a few standard observations about the adjoint representation, they say that comparing the two equations above, we find that $$\alpha(g) = \det(\operatorname{Ad}(g)).$$ Is there a more explicit way to see where this relation comes from? I can see some connection: I can write $K_g=L_g \circ R_g^{-1}$ and thus $$\operatorname{Ad}(g)=DK_g(e) = (DL_g(g^{-1}))\circ (D R_g^{-1}(e)).$$ Still, I think I'm missing something, because I don't how to link this with the statements about left- or right-invariant differential forms made previously, as well as whether we should make a choice of $\omega_e$ for this to work, etc.","I'm reading through Michael Taylor's notes from this PDF . The author starts saying that given an -dimensional Lie group and some covector , there is a unique differential -form that is left-invariant, meaning and with . Similarly, there is a unique right-invariant , . They then observe that these must also satisfy for some pair of homomorphisms . The group is said to be unimodular iff or . Shortly thereafter, the authors discuss the adjoint representation of the group, by defining and defining , with denoting the differential. After a few standard observations about the adjoint representation, they say that comparing the two equations above, we find that Is there a more explicit way to see where this relation comes from? I can see some connection: I can write and thus Still, I think I'm missing something, because I don't how to link this with the statements about left- or right-invariant differential forms made previously, as well as whether we should make a choice of for this to work, etc.","N G \omega_e \in \bigwedge^N T^*_e G N \omega_\ell \omega_\ell(e)=\omega_e L_g^*\omega_\ell=\omega_\ell L_g(h)\equiv gh \omega_r(e)=\omega_r R_g^* \omega_r =\omega_r R_h^* \omega_\ell = \alpha(h)\omega_\ell,
\qquad L_h^* \omega_r = \beta(g) \omega_r, \alpha,\beta:G\to(0,\infty) \alpha=1 \beta=1 K_g:G\to G, \qquad K_g(h)\equiv ghg^{-1} \operatorname{Ad}(g)=DK_g(e):T_e G\to T_e G D \alpha(g) = \det(\operatorname{Ad}(g)). K_g=L_g \circ R_g^{-1} \operatorname{Ad}(g)=DK_g(e) = (DL_g(g^{-1}))\circ (D R_g^{-1}(e)). \omega_e","['differential-geometry', 'representation-theory', 'lie-groups']"
41,Extending a principal connection form to an associated principal bundle,Extending a principal connection form to an associated principal bundle,,"Suppose that I have a principal $G$ -bundle $\mathcal{G} \to M$ equipped with a principal connection form $\omega_\mathcal{G}: T\mathcal{G} \to \mathfrak{g}$ and a lie group homorphism $\varphi: G \to H$ . Explicitly, what is the formula for the extended principal connection form on the associated principal $H$ -bundle $\mathcal{G} \times_G H$ ?  I've tried looking in various textbooks but haven't found this discussed. This should be a linear map $T \mathcal{G} \times_{TG} TH \cong T(\mathcal{G} \times_G H)  \to \mathfrak{g}$ . My guess is that it would be obtained from the sum of the principal connection form $\omega_\mathcal{G}$ and the Maurer-Cartan form $\omega_H$ on elements in $T \mathcal{G} \times  TH$ . But I would need to show that this is a $TG$ -balanced map so that it descends to the quotient $T \mathcal{G} \times_{TG} TH$ . I can show that the Maurer-Cartan form transforms with respect to the tangent group structure as $$\omega_H((\varphi_* X) \cdot Y) = \operatorname{Ad}(h)\varphi_*\omega_G(X) + \omega_H(Y),$$ for $X \in T_g G$ and $Y \in T_h H$ But it seems more difficult to figure out how the principal connection form should behave with respect to the action of the tangent group $TG$ since we lack an explicit formula for the connection form.","Suppose that I have a principal -bundle equipped with a principal connection form and a lie group homorphism . Explicitly, what is the formula for the extended principal connection form on the associated principal -bundle ?  I've tried looking in various textbooks but haven't found this discussed. This should be a linear map . My guess is that it would be obtained from the sum of the principal connection form and the Maurer-Cartan form on elements in . But I would need to show that this is a -balanced map so that it descends to the quotient . I can show that the Maurer-Cartan form transforms with respect to the tangent group structure as for and But it seems more difficult to figure out how the principal connection form should behave with respect to the action of the tangent group since we lack an explicit formula for the connection form.","G \mathcal{G} \to M \omega_\mathcal{G}: T\mathcal{G} \to \mathfrak{g} \varphi: G \to H H \mathcal{G} \times_G H T \mathcal{G} \times_{TG} TH \cong T(\mathcal{G} \times_G H)  \to \mathfrak{g} \omega_\mathcal{G} \omega_H T \mathcal{G} \times  TH TG T \mathcal{G} \times_{TG} TH \omega_H((\varphi_* X) \cdot Y) = \operatorname{Ad}(h)\varphi_*\omega_G(X) + \omega_H(Y), X \in T_g G Y \in T_h H TG","['differential-geometry', 'lie-groups', 'principal-bundles']"
42,Integration on Hypersurfaces,Integration on Hypersurfaces,,"Consider a pseudo-Riemannian manifold $(M,g)$ of dimension $d$ . The natural volume form induced by the metric is $$\boldsymbol{\omega} = \sqrt{(-1)^s \mathrm{det}(g_{ij})} dx^1 \wedge ...\wedge dx^d$$ where $s$ is the number of negatives in the signature. Such a $d$ -form enables integration of functions $f : M \to \mathbb{R}$ over a chart domain $\mathcal{U}$ as we define $$\int_{\mathcal{U}} f := \int_{x(\mathcal{U})} d\alpha_1... d\alpha_d \omega(x^{-1}(\alpha))f_{(x)}(\alpha)$$ which is invariant under the choice of chart $x$ (non-boldface $\omega$ being the components of the volume form). Now, given an embedded submanifold of dimension $(d-1)$ , can someone show explicitly how to go from the data above to a similar notion of integration on hypersurfaces? For example, in the sort of flux integrals given by the generalized divergence theorem $$\int_{M} \mathrm{div}(X) = \int_{\partial M} \langle X,\vec{n} \rangle $$ what is the volume form on the rhs? I know both the interior product and hodge star operations can be used to get a $(d-1)$ form from a $d$ -form and and a $(d-1)$ form from a vector field respectively, and that somehow the pullback of $g$ to the hypersuface must show up, but not well enough to implement them myself. i.e. the goal is to understand what really is the volume form in flux-integral resembling expressions like $$E = \int T_{\mu \nu} \xi^\mu n^\nu \sqrt{h} d^3 x$$ and how to derive it from the definition of integration given above. Thank you.","Consider a pseudo-Riemannian manifold of dimension . The natural volume form induced by the metric is where is the number of negatives in the signature. Such a -form enables integration of functions over a chart domain as we define which is invariant under the choice of chart (non-boldface being the components of the volume form). Now, given an embedded submanifold of dimension , can someone show explicitly how to go from the data above to a similar notion of integration on hypersurfaces? For example, in the sort of flux integrals given by the generalized divergence theorem what is the volume form on the rhs? I know both the interior product and hodge star operations can be used to get a form from a -form and and a form from a vector field respectively, and that somehow the pullback of to the hypersuface must show up, but not well enough to implement them myself. i.e. the goal is to understand what really is the volume form in flux-integral resembling expressions like and how to derive it from the definition of integration given above. Thank you.","(M,g) d \boldsymbol{\omega} = \sqrt{(-1)^s \mathrm{det}(g_{ij})} dx^1 \wedge ...\wedge dx^d s d f : M \to \mathbb{R} \mathcal{U} \int_{\mathcal{U}} f := \int_{x(\mathcal{U})} d\alpha_1... d\alpha_d \omega(x^{-1}(\alpha))f_{(x)}(\alpha) x \omega (d-1) \int_{M} \mathrm{div}(X) = \int_{\partial M} \langle X,\vec{n} \rangle  (d-1) d (d-1) g E = \int T_{\mu \nu} \xi^\mu n^\nu \sqrt{h} d^3 x","['integration', 'differential-geometry', 'riemannian-geometry', 'smooth-manifolds', 'general-relativity']"
43,The set of compatible vector fields,The set of compatible vector fields,,"Let us fix some smooth vector field $F(x)$ in some open submanifold $M\subseteq \mathbb R^n$ , $n\ge3$ . A vector field $G(x)$ is said to be compatible with $F(x)$ if the Lie bracket $[F,G]$ is a linear combination of $F(x)$ and $G(x)$ , i.e. $$ \forall x\in M \quad [F(x),G(x)]= \alpha(x) F(x)+\beta(x) G(x), $$ where $\alpha(x)$ and $\beta(x)$ are some smooth scalar functions. Denote by $C_F$ the set of all smooth vector fields compatible with a given vector field $F(x)$ . What is the structure of the set $C_F$ ? Does it always contain any vector fields other than fields of the form $\gamma(x) F(x)$ , where $\gamma(x)$ is a smooth scalar function? And if so, how can one get such vector fields?","Let us fix some smooth vector field in some open submanifold , . A vector field is said to be compatible with if the Lie bracket is a linear combination of and , i.e. where and are some smooth scalar functions. Denote by the set of all smooth vector fields compatible with a given vector field . What is the structure of the set ? Does it always contain any vector fields other than fields of the form , where is a smooth scalar function? And if so, how can one get such vector fields?","F(x) M\subseteq \mathbb R^n n\ge3 G(x) F(x) [F,G] F(x) G(x) 
\forall x\in M \quad [F(x),G(x)]= \alpha(x) F(x)+\beta(x) G(x),
 \alpha(x) \beta(x) C_F F(x) C_F \gamma(x) F(x) \gamma(x)","['differential-geometry', 'smooth-manifolds', 'vector-fields', 'submanifold']"
44,"Using integration by parts to show $\int_{\Sigma} |\nabla^N_{\Sigma} X|^2 = - \int_{\Sigma} \langle X, \Delta^N_{\Sigma} X \rangle$",Using integration by parts to show,"\int_{\Sigma} |\nabla^N_{\Sigma} X|^2 = - \int_{\Sigma} \langle X, \Delta^N_{\Sigma} X \rangle","I'm trying to work through a derivation of the stability operator from minimal surface theory. Suppose $\Sigma^k$ is a minimal submanifold of $\mathbb{R}^n$ , and suppose $X$ is a normal vector field on $\Sigma$ with compact support vanishing on the boundary. Part of the derivation involves the integration by parts $\int_{\Sigma} \langle \nabla_{\Sigma}^N X, \nabla_{\Sigma}^N X \rangle = - \int_{\Sigma} \langle X, \Delta^N_{\Sigma} X \rangle$ , where $\nabla_{\Sigma}^N$ is the normal projection of the covariant derivative on $\Sigma$ , and $\Delta^N_{\Sigma}$ is the normal Laplacian defined by $\Sigma_{i = 1}^k \nabla_{E_i}^N \nabla_{E_i}^N X - \nabla^N_{\left(\nabla_{E^i} E_i\right)^T} X$ , with $E_i$ being an orthonormal frame for $\Sigma$ . Why does this hold? I'm aware of Green's identity holding for the Laplacian and gradient of scalar functions, but the operators involved here are normal projections, and I want to know why the identity still holds in this case. I have tried to compute $\nabla_{\Sigma}^N (\nabla_{\Sigma}^N X)$ in hopes that its inner product with $X$ is the same as that with $\Delta_{\Sigma}^N X$ , up to some terms which vanish under the integral like a divergence, but I haven't gotten anywhere.","I'm trying to work through a derivation of the stability operator from minimal surface theory. Suppose is a minimal submanifold of , and suppose is a normal vector field on with compact support vanishing on the boundary. Part of the derivation involves the integration by parts , where is the normal projection of the covariant derivative on , and is the normal Laplacian defined by , with being an orthonormal frame for . Why does this hold? I'm aware of Green's identity holding for the Laplacian and gradient of scalar functions, but the operators involved here are normal projections, and I want to know why the identity still holds in this case. I have tried to compute in hopes that its inner product with is the same as that with , up to some terms which vanish under the integral like a divergence, but I haven't gotten anywhere.","\Sigma^k \mathbb{R}^n X \Sigma \int_{\Sigma} \langle \nabla_{\Sigma}^N X, \nabla_{\Sigma}^N X \rangle = - \int_{\Sigma} \langle X, \Delta^N_{\Sigma} X \rangle \nabla_{\Sigma}^N \Sigma \Delta^N_{\Sigma} \Sigma_{i = 1}^k \nabla_{E_i}^N \nabla_{E_i}^N X - \nabla^N_{\left(\nabla_{E^i} E_i\right)^T} X E_i \Sigma \nabla_{\Sigma}^N (\nabla_{\Sigma}^N X) X \Delta_{\Sigma}^N X","['differential-geometry', 'riemannian-geometry', 'differential-topology', 'vector-analysis', 'minimal-surfaces']"
45,Book on Riemannian Manifold [closed],Book on Riemannian Manifold [closed],,"Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 2 years ago . Improve this question I am writing my bachelor's thesis which is in part about Riemannian Manifolds but not extensively and I am using the book Introduction to Smooth Manifolds by Lee. However, I find the Riemannian Manifold part requires a lot of information on covectors, tensors, etc. So I want to ask if there is any other book that introduces Riemannian manifold in an intuitive manner and self-contained in a way that does not require tensors, covectors, etc.","Closed . This question is opinion-based . It is not currently accepting answers. Want to improve this question? Update the question so it can be answered with facts and citations by editing this post . Closed 2 years ago . Improve this question I am writing my bachelor's thesis which is in part about Riemannian Manifolds but not extensively and I am using the book Introduction to Smooth Manifolds by Lee. However, I find the Riemannian Manifold part requires a lot of information on covectors, tensors, etc. So I want to ask if there is any other book that introduces Riemannian manifold in an intuitive manner and self-contained in a way that does not require tensors, covectors, etc.",,"['differential-geometry', 'reference-request', 'riemannian-geometry', 'book-recommendation']"
46,Help proving statement in Lee's Introduction to Riemannian Manifolds about smooth curves into manifolds with nonempty boundary.,Help proving statement in Lee's Introduction to Riemannian Manifolds about smooth curves into manifolds with nonempty boundary.,,"The statement appears on page 33 of the second edition of Professor Lee's Introduction to Riemannian Manifolds. It is in the section on Lengths and Distances in Riemannian manifolds, but I think the statement may be generally true even if there is no Riemannian metric given for the manifold. Here is the relevant paragraph: ""Without further qualification, a curve in $M$ always means a parameterized curve , that is, a continuous map $\gamma\colon I\to M$ , where $I\subseteq\mathbb{R}$ is some interval. ... To say that $\gamma$ is a smooth curve is to say that it is smooth as a map from the manifold (with boundary) $I$ to $M$ . If $I$ has one or two endpoints and $M$ has empty boundary, then $\gamma$ is smooth if and only if it extends to a smooth curve defined on some open interval containing $I$ . (If $\partial M\neq\varnothing$ , then smoothness of $\gamma$ has to be interpreted as meaning that each coordinate representation of $\gamma$ has a smooth extension to an open interval.)"" I believe I have a correct proof of the statement for the case when $M$ has empty boundary. It is the parenthetical statement that follows, about the case when the boundary of $M$ is nonempty, that has me stymied. I have sketched a proof of one direction of that statement, namely the ""if"" direction. It is the ""only if"" direction that I can't get a handle on. That is, I assume that $\gamma$ is smooth, $(U,\phi)$ is a smooth chart for $I$ , $(V,\psi)$ is a smooth chart for $M$ , and $\gamma(U)\subseteq V$ . I set $\hat{\gamma}=\psi\circ\gamma\circ\phi^{-1}\colon\phi(U)\to\psi(V)$ . By definition, $\hat{\gamma}$ (which is a coordinate representation of $\gamma$ ) is smooth, and I need to find an open interval $J$ which contains $\phi(U)$ and a smooth map $\Gamma\colon J\to\mathbf{R}^n$ such that $\Gamma|_{\phi(U)}=\hat{\gamma}$ . Here, I have assumed that $\dim M=n$ . I tried to work on a simpler version of this problem, so I assumed first that $\phi(U)$ was open in $\mathbb{R}$ (it could be open in the half-space instead). Then a plausible candidate for $J$ is $(\inf\phi(U),\sup\phi(U))$ . But how would I define $\Gamma$ so as to match $\hat{\gamma}$ ? I know $\phi(U)$ is a countable collection of disjoint open intervals, but I haven't been able to figure out how to use something like a partition of unity to glue the restrictions of $\hat{\gamma}$ to each interval in the collection together to make $\Gamma$ . That is mostly because I haven't come up with a reasonable  open cover for $J$ . Also complicating things is that an interval which appears in $\phi(U)$ might actually have been flipped by $\phi$ compared to the interval it came from in $I$ . For example, if $(-1,1)\subseteq I$ , $\phi$ might multiply it by $-1$ but not do that to other nearby subintervals. Can someone please offer some suggestions on how to go about proving the parenthetical statement.","The statement appears on page 33 of the second edition of Professor Lee's Introduction to Riemannian Manifolds. It is in the section on Lengths and Distances in Riemannian manifolds, but I think the statement may be generally true even if there is no Riemannian metric given for the manifold. Here is the relevant paragraph: ""Without further qualification, a curve in always means a parameterized curve , that is, a continuous map , where is some interval. ... To say that is a smooth curve is to say that it is smooth as a map from the manifold (with boundary) to . If has one or two endpoints and has empty boundary, then is smooth if and only if it extends to a smooth curve defined on some open interval containing . (If , then smoothness of has to be interpreted as meaning that each coordinate representation of has a smooth extension to an open interval.)"" I believe I have a correct proof of the statement for the case when has empty boundary. It is the parenthetical statement that follows, about the case when the boundary of is nonempty, that has me stymied. I have sketched a proof of one direction of that statement, namely the ""if"" direction. It is the ""only if"" direction that I can't get a handle on. That is, I assume that is smooth, is a smooth chart for , is a smooth chart for , and . I set . By definition, (which is a coordinate representation of ) is smooth, and I need to find an open interval which contains and a smooth map such that . Here, I have assumed that . I tried to work on a simpler version of this problem, so I assumed first that was open in (it could be open in the half-space instead). Then a plausible candidate for is . But how would I define so as to match ? I know is a countable collection of disjoint open intervals, but I haven't been able to figure out how to use something like a partition of unity to glue the restrictions of to each interval in the collection together to make . That is mostly because I haven't come up with a reasonable  open cover for . Also complicating things is that an interval which appears in might actually have been flipped by compared to the interval it came from in . For example, if , might multiply it by but not do that to other nearby subintervals. Can someone please offer some suggestions on how to go about proving the parenthetical statement.","M \gamma\colon I\to M I\subseteq\mathbb{R} \gamma I M I M \gamma I \partial M\neq\varnothing \gamma \gamma M M \gamma (U,\phi) I (V,\psi) M \gamma(U)\subseteq V \hat{\gamma}=\psi\circ\gamma\circ\phi^{-1}\colon\phi(U)\to\psi(V) \hat{\gamma} \gamma J \phi(U) \Gamma\colon J\to\mathbf{R}^n \Gamma|_{\phi(U)}=\hat{\gamma} \dim M=n \phi(U) \mathbb{R} J (\inf\phi(U),\sup\phi(U)) \Gamma \hat{\gamma} \phi(U) \hat{\gamma} \Gamma J \phi(U) \phi I (-1,1)\subseteq I \phi -1","['differential-geometry', 'smooth-manifolds', 'manifolds-with-boundary']"
47,Warp product structure on the complex hyperbolic space,Warp product structure on the complex hyperbolic space,,"It is known that the real hyperbolic space $\mathbb{H}^n$ has a warped product structure $g = dr^2 + \sinh^2 r\; ds^2_{n - 1} $ , where $r \in (0, \infty)$ . My question is, does the complex hyperbolic space $\mathbb{CH}^n$ also have a warped metric? Recall that a warped product metric on $(M, g) \times (N, h)$ is defined as $g + \varphi^2(x) h$ , where $\varphi$ is a positive smooth function on $M$ . This is probably well-known, so this is mainly a reference request.","It is known that the real hyperbolic space has a warped product structure , where . My question is, does the complex hyperbolic space also have a warped metric? Recall that a warped product metric on is defined as , where is a positive smooth function on . This is probably well-known, so this is mainly a reference request.","\mathbb{H}^n g = dr^2 + \sinh^2 r\; ds^2_{n - 1}  r \in (0, \infty) \mathbb{CH}^n (M, g) \times (N, h) g + \varphi^2(x) h \varphi M","['differential-geometry', 'reference-request', 'riemannian-geometry', 'hyperbolic-geometry', 'homogeneous-spaces']"
48,Commutativity of $\nabla$ and $\Delta$,Commutativity of  and,\nabla \Delta,"Let $M$ be a (closed if necessary) Riemannian manifold with Levi-Civita connection Let $\nabla^*$ be the formal adjoint of $\nabla$ with respect to the $L^2$ inner product. Let $\Delta=\nabla^*\nabla$ denote the Laplacian. Question 1: In general, do we have $\nabla\circ\Delta$ = $\Delta\circ\nabla$ , as operators $C^\infty(M)\to C^\infty(M)\otimes C^\infty(T^*M)$ ? Question 2: If not, is this relation true if the metric is flat? Comment: I feel that the answer to Q2 at least must be yes, but I am not good with these computations. So I would appreciate it if someone could work through the computation (or perhaps share a reference) for the commutator $[\nabla,\Delta]$ involving the curvature terms.","Let be a (closed if necessary) Riemannian manifold with Levi-Civita connection Let be the formal adjoint of with respect to the inner product. Let denote the Laplacian. Question 1: In general, do we have = , as operators ? Question 2: If not, is this relation true if the metric is flat? Comment: I feel that the answer to Q2 at least must be yes, but I am not good with these computations. So I would appreciate it if someone could work through the computation (or perhaps share a reference) for the commutator involving the curvature terms.","M \nabla^* \nabla L^2 \Delta=\nabla^*\nabla \nabla\circ\Delta \Delta\circ\nabla C^\infty(M)\to C^\infty(M)\otimes C^\infty(T^*M) [\nabla,\Delta]","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
49,Computation of a left-invariant vector field,Computation of a left-invariant vector field,,"Consider $\mathbb{R}^3\times\mathbb{R}^3$ as a Lie group endowed with the group operation $(x,y).(u,v)=(x+u,y+v+x\times u) $ where ( $x\times u $ is the cross product of the $\mathbb{R}^3$ vectors $x$ and $u$ ). I need to explicitly calculate the unique left-invariant vector field $X$ such that $X_{(0,0)}=(u,v)\in T_{(0,0)}(\mathbb{R}^3\times\mathbb{R}^3)$ Now using $X_{(a,b)}=DL_{(a,b)}(X_{(0,0)})$ after some computations I'm getting $X_{(a,b)}=(u,v+a\times u)$ . But the answer seems to be $X_{(a,b)}=(a+u,b+v+a\times u)$ . So can you please give me an explicit computation for $X_{(a,b)}$ so that I know which one of the above is correct.",Consider as a Lie group endowed with the group operation where ( is the cross product of the vectors and ). I need to explicitly calculate the unique left-invariant vector field such that Now using after some computations I'm getting . But the answer seems to be . So can you please give me an explicit computation for so that I know which one of the above is correct.,"\mathbb{R}^3\times\mathbb{R}^3 (x,y).(u,v)=(x+u,y+v+x\times u)  x\times u  \mathbb{R}^3 x u X X_{(0,0)}=(u,v)\in T_{(0,0)}(\mathbb{R}^3\times\mathbb{R}^3) X_{(a,b)}=DL_{(a,b)}(X_{(0,0)}) X_{(a,b)}=(u,v+a\times u) X_{(a,b)}=(a+u,b+v+a\times u) X_{(a,b)}","['differential-geometry', 'lie-groups', 'vector-fields']"
50,Proving the induced derivation of endomorphism equals trace on top exterior power,Proving the induced derivation of endomorphism equals trace on top exterior power,,"Let $V$ be a finite-dimensional vector space over a field $K$ of dimension $r:= \dim_K(V)$ (let's say $K$ equals the real or complex numbers). If $\varphi: V\to V$ is an endomorphism, we know that $\varphi$ can be naturally extended to act as a derivation on $\bigwedge^k V $ for each $1\leq k\leq r$ by $\widetilde\varphi_k\colon \bigwedge^k V \to \bigwedge^k V  $ defined as $$ \widetilde\varphi_k(v_1\wedge\cdots\wedge v_k):=\sum_{j=1}^k v_1\wedge\cdots\wedge \varphi (v_j)\wedge\cdots\wedge v_k. $$ Now, I want a formal explanation/proof of why does this extension acts as just the scalar multiplication by the trace of $\varphi$ on the top exterior power $\bigwedge^r V \cong  K$ . Namely, I want to prove that $$(*)\qquad\qquad\widetilde\varphi_r(v_1\wedge\cdots\wedge v_r)=\mathrm{tr}(\varphi)v_1\wedge\cdots\wedge v_r  .$$ This has appeared in my path in the context of differential geometry. Namely, if $E$ is a vector bundle of rank $r$ with connection $\nabla$ and curvature form $\Omega$ , then it is asserted or implicitely used in several places that the curvature form of the determinant line bundle $\det E:=\bigwedge^r E$ is given by $\widetilde\Omega=\mathrm{tr}(\Omega)$ with respect to the natural connection $\widetilde\nabla$ on $\bigwedge^r E$ , namely, the extension of $\nabla$ as a derivation: $\widetilde\nabla(\xi_1\wedge\cdots\wedge \xi_r):=\sum\limits_{j=1}^r \xi_1\wedge\cdots\wedge \nabla \xi_j\wedge\cdots\wedge \xi_r$ . By what we said above, this just amounts to a multilinear algebra problem, that is, $(*)$ . It is also worth noting that the identity $(*)$ is a sister identity of the more well-known identity $$\bigwedge\nolimits^r \varphi(v_1\wedge\cdots\wedge v_r):= \varphi(v_1)\wedge\cdots\wedge\varphi(v_r)=\det(\varphi)v_1\wedge\cdots\wedge v_r,$$ and that give us a nice overpowered definition of both the determinant and the trace. Any hint or proof is appreciated.","Let be a finite-dimensional vector space over a field of dimension (let's say equals the real or complex numbers). If is an endomorphism, we know that can be naturally extended to act as a derivation on for each by defined as Now, I want a formal explanation/proof of why does this extension acts as just the scalar multiplication by the trace of on the top exterior power . Namely, I want to prove that This has appeared in my path in the context of differential geometry. Namely, if is a vector bundle of rank with connection and curvature form , then it is asserted or implicitely used in several places that the curvature form of the determinant line bundle is given by with respect to the natural connection on , namely, the extension of as a derivation: . By what we said above, this just amounts to a multilinear algebra problem, that is, . It is also worth noting that the identity is a sister identity of the more well-known identity and that give us a nice overpowered definition of both the determinant and the trace. Any hint or proof is appreciated.","V K r:= \dim_K(V) K \varphi: V\to V \varphi \bigwedge^k V  1\leq k\leq r \widetilde\varphi_k\colon \bigwedge^k V \to \bigwedge^k V    \widetilde\varphi_k(v_1\wedge\cdots\wedge v_k):=\sum_{j=1}^k v_1\wedge\cdots\wedge \varphi (v_j)\wedge\cdots\wedge v_k.  \varphi \bigwedge^r V \cong  K (*)\qquad\qquad\widetilde\varphi_r(v_1\wedge\cdots\wedge v_r)=\mathrm{tr}(\varphi)v_1\wedge\cdots\wedge v_r  . E r \nabla \Omega \det E:=\bigwedge^r E \widetilde\Omega=\mathrm{tr}(\Omega) \widetilde\nabla \bigwedge^r E \nabla \widetilde\nabla(\xi_1\wedge\cdots\wedge \xi_r):=\sum\limits_{j=1}^r \xi_1\wedge\cdots\wedge \nabla \xi_j\wedge\cdots\wedge \xi_r (*) (*) \bigwedge\nolimits^r \varphi(v_1\wedge\cdots\wedge v_r):= \varphi(v_1)\wedge\cdots\wedge\varphi(v_r)=\det(\varphi)v_1\wedge\cdots\wedge v_r,","['differential-geometry', 'reference-request', 'trace', 'multilinear-algebra', 'connections']"
51,Where is it possible to have an isometric immersion of $\mathbb{H}^2$?,Where is it possible to have an isometric immersion of ?,\mathbb{H}^2,"I'm researching the Hilbert's Theorem .- There is no isometric immersion of the hyperbolic plane $\mathbb{H}^2$ in $\mathbb{R}^3$ . But on the way I have come across several results, such as: Efimov's theorem .- There is no isometric immersion of a complete surface with Gaussian curvature bounded superiorly by a negative constant, at $\mathbb{R}^3$ . Then the question arose, where is it possible to have an isometric immersion of $\mathbb{H}^2$ ? I read that there is an isometric immersion in $\mathbb{R}^5$ , but I only got this result, Blanusa's theorem .- There is an isometric embedding proper to the hyperbolic plane $\mathbb{H}^2$ in $\mathbb{R}^6$ . From Efimov's theorem I have managed to find references to read, but from Blanusa's Theorem or other similar ones I have not obtained much information. If someone knows the topics and could give me some references or perhaps other theorems that can enrich my research, I would appreciate it very much. Some documents i have found: D. Brander - Isometric Embeddings between Space Forms T. Milnor - Efimov's theorem about complete immersed surface of negative curvature Do Carmo - Differential geometry And others Here","I'm researching the Hilbert's Theorem .- There is no isometric immersion of the hyperbolic plane in . But on the way I have come across several results, such as: Efimov's theorem .- There is no isometric immersion of a complete surface with Gaussian curvature bounded superiorly by a negative constant, at . Then the question arose, where is it possible to have an isometric immersion of ? I read that there is an isometric immersion in , but I only got this result, Blanusa's theorem .- There is an isometric embedding proper to the hyperbolic plane in . From Efimov's theorem I have managed to find references to read, but from Blanusa's Theorem or other similar ones I have not obtained much information. If someone knows the topics and could give me some references or perhaps other theorems that can enrich my research, I would appreciate it very much. Some documents i have found: D. Brander - Isometric Embeddings between Space Forms T. Milnor - Efimov's theorem about complete immersed surface of negative curvature Do Carmo - Differential geometry And others Here",\mathbb{H}^2 \mathbb{R}^3 \mathbb{R}^3 \mathbb{H}^2 \mathbb{R}^5 \mathbb{H}^2 \mathbb{R}^6,"['differential-geometry', 'riemannian-geometry', 'hyperbolic-geometry', 'isometry']"
52,Prove that the Gaussian curvature of such a surface is constant.,Prove that the Gaussian curvature of such a surface is constant.,,"The first fundamental (FF) form of a surface is given by $$ds^2 = \frac{du^2}{(u^2+v^2+c^2)^2} + \frac{dv^2}{(u^2+v^2+c^2)^2}$$ Prove that the Gaussian curvature of such a surface is constant I was trying to find the coefficient of the second fundamental (SF) form first. From the condition we have $$s_u\cdot s_u = s_v\cdot s_v = \frac{1}{(u^2+v^2+c^2)^2}$$ For the (SF), I have to find $s_{uu}, s_{uv}$ and $s_{vv}$ but with the dot products given I'm not sure how to do it. I tried to differentiate w.r.t $u$ the dot product $s_u^2$ which gave $$2\cdot s_u \cdot s_{uu} = -\frac{8(u^2+v^2+c^2)u}{(u^2+v^2+c^2)^3}$$ However, how can I extract $s_{uu}$ out of here? Or is there any other approach?","The first fundamental (FF) form of a surface is given by Prove that the Gaussian curvature of such a surface is constant I was trying to find the coefficient of the second fundamental (SF) form first. From the condition we have For the (SF), I have to find and but with the dot products given I'm not sure how to do it. I tried to differentiate w.r.t the dot product which gave However, how can I extract out of here? Or is there any other approach?","ds^2 = \frac{du^2}{(u^2+v^2+c^2)^2} + \frac{dv^2}{(u^2+v^2+c^2)^2} s_u\cdot s_u = s_v\cdot s_v = \frac{1}{(u^2+v^2+c^2)^2} s_{uu}, s_{uv} s_{vv} u s_u^2 2\cdot s_u \cdot s_{uu} = -\frac{8(u^2+v^2+c^2)u}{(u^2+v^2+c^2)^3} s_{uu}","['differential-geometry', 'surfaces', 'curvature']"
53,Tangent space of 3-sphere,Tangent space of 3-sphere,,"Consider the 3-sphere $S^3$ . If I look it as a embedded in $\mathbb{R}^4$ , then the tangent space in a point $x \in \mathbb{R}^4$ is isomorphic to $\mathbb{R}^3$ . But, if I consider $$S^3 = \{(z,w) \in \mathbb{C}^2| \ |z|^2 + |w|^2 = 1\},$$ given a point $a \in \mathbb{C}^2$ , how the tangent $T_a S^3$ looks like? I don't know if this question makes sense because $S^3$ is a real manifold. I saw questions related, but I didn't find the answer. Appreciate.","Consider the 3-sphere . If I look it as a embedded in , then the tangent space in a point is isomorphic to . But, if I consider given a point , how the tangent looks like? I don't know if this question makes sense because is a real manifold. I saw questions related, but I didn't find the answer. Appreciate.","S^3 \mathbb{R}^4 x \in \mathbb{R}^4 \mathbb{R}^3 S^3 = \{(z,w) \in \mathbb{C}^2| \ |z|^2 + |w|^2 = 1\}, a \in \mathbb{C}^2 T_a S^3 S^3","['differential-geometry', 'complex-numbers', 'complex-geometry', 'spheres', 'tangent-spaces']"
54,"On the proof of the Künneth Formula (Bott, Tu, Proposition 9.12)","On the proof of the Künneth Formula (Bott, Tu, Proposition 9.12)",,"I'm currently going through a proof of the Künneth formula via the Cech-de Rham complex. More precisely, the statement is the following: If $M$ and $F$ are two manifolds and $F$ has finite-dimensional cohomology, then $H^{\bullet}(M\times F)=H^{\bullet}(M)\otimes H^{\bullet}(F)$ . Let $\mathfrak{U}=\{U_{\alpha}\}_{\alpha\in A}$ be a countable good open cover of $M$ (which we suppose to be ordered). Then we know that there is an isomorphism $H^{\bullet}(M)=H^{\bullet}(C^{\bullet}(\mathfrak{U},\Omega^{\bullet}))$ . Choose closed forms $\omega_{1},...,\omega_{r}\in \Omega^{\bullet}(F)$ such that $\{[\omega_{1}],...,[\omega_{r}]\}$ is a basis of $H^{\bullet}(F)$ . The authors then define a map $\pi_{\mathfrak{U}}^{*}\colon H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet})\to C^{\bullet}(\mathfrak{\pi^{-1}\mathfrak{U}},\Omega^{\bullet})$ given by $[\omega_{i}]\otimes \eta \to \rho^{*}\omega_{i}\wedge\pi^{*}\eta$ , where $\rho\colon M\times F\to F$ and $\pi\colon M\times F\to M$ are the projections. Here is the confusing part to me: the authors claim that $H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet})$ can be seen as a (double, I think) complex with cohomology $H^{\bullet}(F)\otimes H^{\bullet}(C^{\bullet}(\mathfrak{U},\Omega^{\bullet}))$ by using the differential of the second factor. That is, if we denote by $d$ and $\delta$ the differentials of $C^{\bullet}(\mathfrak{U},\Omega^{\bullet})$ , then $1\otimes d$ and $1\otimes \delta$ are the differentials of $H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet})$ . At first, this made sense to me, but later it is stated that $\pi^{*}_{\mathfrak{U}}$ induces an isomorphism in cohomology. But if we take some $\eta\in C^{p}(\mathfrak{U},\Omega^{q})$ , then $\rho^{*}\omega_{i}\wedge \pi^{*}\eta\in C^{p}(\pi^{-1}\mathfrak{U},\Omega^{q+\operatorname{deg}\omega_{i}})$ , so $\pi^{*}_{\mathfrak{U}}$ is not a homomorphism of double complexes. What am I missing here? Is it that the structure of complex in $H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet})$ is different than the one I'm thinking of? Thank you in advance! EDIT: I believe the problem here lies on the structure given to $H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet})$ . I thought that maybe we can consider it as a product complex by using the fact that $H^{\bullet}(F)$ is finite-dimensional, but I'm not sure on how to proceed.","I'm currently going through a proof of the Künneth formula via the Cech-de Rham complex. More precisely, the statement is the following: If and are two manifolds and has finite-dimensional cohomology, then . Let be a countable good open cover of (which we suppose to be ordered). Then we know that there is an isomorphism . Choose closed forms such that is a basis of . The authors then define a map given by , where and are the projections. Here is the confusing part to me: the authors claim that can be seen as a (double, I think) complex with cohomology by using the differential of the second factor. That is, if we denote by and the differentials of , then and are the differentials of . At first, this made sense to me, but later it is stated that induces an isomorphism in cohomology. But if we take some , then , so is not a homomorphism of double complexes. What am I missing here? Is it that the structure of complex in is different than the one I'm thinking of? Thank you in advance! EDIT: I believe the problem here lies on the structure given to . I thought that maybe we can consider it as a product complex by using the fact that is finite-dimensional, but I'm not sure on how to proceed.","M F F H^{\bullet}(M\times F)=H^{\bullet}(M)\otimes H^{\bullet}(F) \mathfrak{U}=\{U_{\alpha}\}_{\alpha\in A} M H^{\bullet}(M)=H^{\bullet}(C^{\bullet}(\mathfrak{U},\Omega^{\bullet})) \omega_{1},...,\omega_{r}\in \Omega^{\bullet}(F) \{[\omega_{1}],...,[\omega_{r}]\} H^{\bullet}(F) \pi_{\mathfrak{U}}^{*}\colon H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet})\to C^{\bullet}(\mathfrak{\pi^{-1}\mathfrak{U}},\Omega^{\bullet}) [\omega_{i}]\otimes \eta \to \rho^{*}\omega_{i}\wedge\pi^{*}\eta \rho\colon M\times F\to F \pi\colon M\times F\to M H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet}) H^{\bullet}(F)\otimes H^{\bullet}(C^{\bullet}(\mathfrak{U},\Omega^{\bullet})) d \delta C^{\bullet}(\mathfrak{U},\Omega^{\bullet}) 1\otimes d 1\otimes \delta H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet}) \pi^{*}_{\mathfrak{U}} \eta\in C^{p}(\mathfrak{U},\Omega^{q}) \rho^{*}\omega_{i}\wedge \pi^{*}\eta\in C^{p}(\pi^{-1}\mathfrak{U},\Omega^{q+\operatorname{deg}\omega_{i}}) \pi^{*}_{\mathfrak{U}} H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet}) H^{\bullet}(F)\otimes C^{\bullet}(\mathfrak{U},\Omega^{\bullet}) H^{\bullet}(F)","['differential-geometry', 'homology-cohomology', 'differential-forms']"
55,Holomorphic function on a connected compact Riemann surface is constant,Holomorphic function on a connected compact Riemann surface is constant,,"I was trying to solve the following exercise. I wanted to check if my solution was correct/rigorous enough, and ask a question at the end. (The general direction is given in here: holomorphic map between compact Riemann surfaces , and I seem to have expanded out the steps in a detailed way) Let $h\colon X \rightarrow Y$ be a morphism of Riemann surfaces. Assume that $X$ is connected and $h$ is not constant. Show that the image of $h$ is open in $Y .$ Deduce that $h$ is surjective if we moreover assume that $X$ is non-empty and compact, and $Y$ is connected. This implies that a morphism from a connected compact Riemann surface to a connected non-compact Riemann surface is always constant. In particular, every holomorphic function on a connected compact Riemann surface is constant. Open mapping theorem: If $U$ is a connected open subset of $\mathbb{C}$ , then the image of every non-constant holomorphic function $f: U \rightarrow \mathbb{C}$ is open. Proof: Let $h\colon X \rightarrow Y$ be such a morphism. Let $O \subset X$ be an open subset of $X$ , and we will show $h(O)$ is open. For any $x \in O$ , let $(U,\phi)$ be a chart of $O$ containing $x$ , and $(V,\psi)$ a chart of $Y$ containing $h(x)$ . Then consider the holomorphic map $\psi \circ h \circ \phi^{-1}$ defined on the open set $\phi(U \cap h^{-1}(V))\ni\phi(x)$ . Draw an open neighbourhood around $\phi(x)$ , and apply $\psi \circ h \circ \phi^{-1}$ to it. The result is an open in $\mathbb{C}$ around $\psi \circ h(x)$ , using the open mapping theorem. Composing from the left with $\psi^{-1}$ , we obtain an open neighbourhood around $h(x)$ . Since this holds for any point $x \in O$ , $h(O)$ is open in $Y$ . Now assume that $X$ is connected, non-empty, compact, and $Y$ connected. Let the notation be as above. Then $h(X)$ is compact, non-empty, and connected. As $h$ is an open map, $h(X)$ is open in $Y$ . As $h(X)$ is compact, it is closed in Hausdorff space $Y$ . As $Y$ is connected, we conclude $h(X) = Y$ . Now, if $Y$ is non-compact, a continuous map cannot map a compact space to a non-compact space, so $h$ must be a constant (otherwise we proved it is surjective). Is my solution correct? Also, I do not understand why this implies that every holomorphic function on a connected compact Riemann surface is constant.","I was trying to solve the following exercise. I wanted to check if my solution was correct/rigorous enough, and ask a question at the end. (The general direction is given in here: holomorphic map between compact Riemann surfaces , and I seem to have expanded out the steps in a detailed way) Let be a morphism of Riemann surfaces. Assume that is connected and is not constant. Show that the image of is open in Deduce that is surjective if we moreover assume that is non-empty and compact, and is connected. This implies that a morphism from a connected compact Riemann surface to a connected non-compact Riemann surface is always constant. In particular, every holomorphic function on a connected compact Riemann surface is constant. Open mapping theorem: If is a connected open subset of , then the image of every non-constant holomorphic function is open. Proof: Let be such a morphism. Let be an open subset of , and we will show is open. For any , let be a chart of containing , and a chart of containing . Then consider the holomorphic map defined on the open set . Draw an open neighbourhood around , and apply to it. The result is an open in around , using the open mapping theorem. Composing from the left with , we obtain an open neighbourhood around . Since this holds for any point , is open in . Now assume that is connected, non-empty, compact, and connected. Let the notation be as above. Then is compact, non-empty, and connected. As is an open map, is open in . As is compact, it is closed in Hausdorff space . As is connected, we conclude . Now, if is non-compact, a continuous map cannot map a compact space to a non-compact space, so must be a constant (otherwise we proved it is surjective). Is my solution correct? Also, I do not understand why this implies that every holomorphic function on a connected compact Riemann surface is constant.","h\colon X \rightarrow Y X h h Y . h X Y U \mathbb{C} f: U \rightarrow \mathbb{C} h\colon X \rightarrow Y O \subset X X h(O) x \in O (U,\phi) O x (V,\psi) Y h(x) \psi \circ h \circ \phi^{-1} \phi(U \cap h^{-1}(V))\ni\phi(x) \phi(x) \psi \circ h \circ \phi^{-1} \mathbb{C} \psi \circ h(x) \psi^{-1} h(x) x \in O h(O) Y X Y h(X) h h(X) Y h(X) Y Y h(X) = Y Y h","['differential-geometry', 'solution-verification', 'manifolds', 'complex-manifolds']"
56,About the proof of Proposition 6.45 on Ziller's notes,About the proof of Proposition 6.45 on Ziller's notes,,"I'm currently going through W. Ziller's notes on symmetric spaces, and I've come across one argument he makes which I can't seem to wrap my head around. Suppose $(G,K)$ is a symmetric pair of the noncompact type with Cartan decomposition $\mathfrak{g}=\mathfrak{k}\oplus\mathfrak{p}$ (that is, the Killing form $B$ is negative definite in $\mathfrak{p}$ ). I wish to prove that $K$ is a maximal compact subgroup of $G$ . I'll briefly describe Ziller's proof as follows: given that $f\colon \mathfrak{p}\times K\to G$ , $f(X,g)=\operatorname{Exp}(X)g$ is a diffeomorphism, where $\operatorname{Exp}$ stands for the Lie exponential map, we suppose a compact subgroup $K\subseteq L\subseteq G$ . Since $L$ is compact, we can define an inner product over $\mathfrak{g}$ such that for every $X\in \mathfrak{l}=\operatorname{Lie}(L)$ , $\operatorname{ad}_{X}$ is skew-symmetric. This implies that $B|_{\mathfrak{l}}$ is negative semidefinite, and in reality it is negative definite, since its kernel is $\mathfrak{z}(\mathfrak{g})\cap\mathfrak{l}=0$ . Because of this, we must have $\mathfrak{k}=\mathfrak{l}$ , so that $K=L^{0}$ , the identity component of $L$ (hence, $K$ is normal in $L$ ). Therefore, $L/K$ is a $0$ -dimensional compact Lie group (that is, a finite group). Now the part that I don't understand Take a nontrivial element $gK\in L/K$ , which corresponds to some $g\in L\setminus K$ . Since $f$ is a diffeomorphism, we can write $g=\operatorname{Exp}(X)y$ for some uniquely determined $X\in \mathfrak{p}$ , $y\in K$ . Then, since $L/K$ is finite, we get that for some $n>0$ , $g^{n}=\operatorname{Exp}(nX)y'\in K$ , so that $\operatorname{Exp}(nX)y'=\operatorname{Exp}(0)z$ for $z\in K$ , contradicting that $f$ is injective. Here is my question: how can we be sure that $g^{n}$ admits an expression as above? Since elements of $G$ don't commute, it doesn't seem obvious to me that we can make such a claim. Thank you in advance!","I'm currently going through W. Ziller's notes on symmetric spaces, and I've come across one argument he makes which I can't seem to wrap my head around. Suppose is a symmetric pair of the noncompact type with Cartan decomposition (that is, the Killing form is negative definite in ). I wish to prove that is a maximal compact subgroup of . I'll briefly describe Ziller's proof as follows: given that , is a diffeomorphism, where stands for the Lie exponential map, we suppose a compact subgroup . Since is compact, we can define an inner product over such that for every , is skew-symmetric. This implies that is negative semidefinite, and in reality it is negative definite, since its kernel is . Because of this, we must have , so that , the identity component of (hence, is normal in ). Therefore, is a -dimensional compact Lie group (that is, a finite group). Now the part that I don't understand Take a nontrivial element , which corresponds to some . Since is a diffeomorphism, we can write for some uniquely determined , . Then, since is finite, we get that for some , , so that for , contradicting that is injective. Here is my question: how can we be sure that admits an expression as above? Since elements of don't commute, it doesn't seem obvious to me that we can make such a claim. Thank you in advance!","(G,K) \mathfrak{g}=\mathfrak{k}\oplus\mathfrak{p} B \mathfrak{p} K G f\colon \mathfrak{p}\times K\to G f(X,g)=\operatorname{Exp}(X)g \operatorname{Exp} K\subseteq L\subseteq G L \mathfrak{g} X\in \mathfrak{l}=\operatorname{Lie}(L) \operatorname{ad}_{X} B|_{\mathfrak{l}} \mathfrak{z}(\mathfrak{g})\cap\mathfrak{l}=0 \mathfrak{k}=\mathfrak{l} K=L^{0} L K L L/K 0 gK\in L/K g\in L\setminus K f g=\operatorname{Exp}(X)y X\in \mathfrak{p} y\in K L/K n>0 g^{n}=\operatorname{Exp}(nX)y'\in K \operatorname{Exp}(nX)y'=\operatorname{Exp}(0)z z\in K f g^{n} G","['differential-geometry', 'symmetric-spaces']"
57,Are the following two inner products on differential forms equal?,Are the following two inner products on differential forms equal?,,"There are two inner product on differential forms: $\langle \alpha,\beta\rangle$ induced from Riemannian metric $g$ by defining on 1-forms as dual of vector fields then extending to all differential forms i.e. $\langle e_{i_1}\wedge \dots\wedge e_{i_k}, e_{j_1}\wedge \dots\wedge e_{j_k}\rangle =\det[\langle e_{i_s}, e_{j_s}\rangle]$ . On compact oriented Riemannian manifold $(M,g)$ $$(\alpha,\beta)=\int_M\alpha\wedge\star\beta.$$ Q1: Are these two inner products on differential forms equal? Q2: If the answer to Q1 is ""NO"" then is it important to notice that two operators are adjoint of each other (or an operator is symmetric or self-adjoint)  w.r.t. which metric? e.g. $d$ and $\delta$ that are adjoint w.r.t. second inner product but I don't know it is w.r.t. other one.","There are two inner product on differential forms: induced from Riemannian metric by defining on 1-forms as dual of vector fields then extending to all differential forms i.e. . On compact oriented Riemannian manifold Q1: Are these two inner products on differential forms equal? Q2: If the answer to Q1 is ""NO"" then is it important to notice that two operators are adjoint of each other (or an operator is symmetric or self-adjoint)  w.r.t. which metric? e.g. and that are adjoint w.r.t. second inner product but I don't know it is w.r.t. other one.","\langle \alpha,\beta\rangle g \langle e_{i_1}\wedge \dots\wedge e_{i_k}, e_{j_1}\wedge \dots\wedge e_{j_k}\rangle =\det[\langle e_{i_s}, e_{j_s}\rangle] (M,g) (\alpha,\beta)=\int_M\alpha\wedge\star\beta. d \delta","['differential-geometry', 'riemannian-geometry', 'inner-products', 'adjoint-operators', 'self-adjoint-operators']"
58,sum of covariant derivatives implies constant Ricci curvature,sum of covariant derivatives implies constant Ricci curvature,,"Let $R_{ij}$ denote the Ricci tensor . If $R_{ij,k}+R_{jk,i}+R_{ki,j}=0$ , prove that the scalar curvature $R$ is constant . A straightforward calculation gives $$R_{ij,k}=\frac{\partial R_{ij}}{\partial x^k}-\Gamma^l_{ik}R_{lj}-\Gamma^l_{jk}R_{il} \\ R_{jk,i}=\frac{\partial R_{jk}}{\partial x^i}-\Gamma^l_{ji}R_{lk}-\Gamma^l_{ki}R_{jl} \\ R_{ki,j}=\frac{\partial R_{ki}}{\partial x^j}-\Gamma^l_{kj}R_{li}-\Gamma^l_{ij}R_{kl}$$ Since $R_{ij}$ is symmetric $$R_{ij,k}+R_{jk,i}+R_{ki,j}=0 \\ \implies \frac{\partial R_{ij}}{\partial x^k}+\frac{\partial R_{jk}}{\partial x^i}+\frac{\partial R_{ki}}{\partial x^j}=2\Gamma^l_{ik}R_{lj}+2\Gamma^l_{jk}R_{il}+2\Gamma^l_{ij}R_{kl}$$ I know that $R=g^{ij}R_{ij}$ , but multiplying above expression with any one of $g^{lj},g^{il},g^{kl}$ won't help . How to approach this one ? Any help is appreciated .","Let denote the Ricci tensor . If , prove that the scalar curvature is constant . A straightforward calculation gives Since is symmetric I know that , but multiplying above expression with any one of won't help . How to approach this one ? Any help is appreciated .","R_{ij} R_{ij,k}+R_{jk,i}+R_{ki,j}=0 R R_{ij,k}=\frac{\partial R_{ij}}{\partial x^k}-\Gamma^l_{ik}R_{lj}-\Gamma^l_{jk}R_{il} \\ R_{jk,i}=\frac{\partial R_{jk}}{\partial x^i}-\Gamma^l_{ji}R_{lk}-\Gamma^l_{ki}R_{jl} \\ R_{ki,j}=\frac{\partial R_{ki}}{\partial x^j}-\Gamma^l_{kj}R_{li}-\Gamma^l_{ij}R_{kl} R_{ij} R_{ij,k}+R_{jk,i}+R_{ki,j}=0 \\ \implies \frac{\partial R_{ij}}{\partial x^k}+\frac{\partial R_{jk}}{\partial x^i}+\frac{\partial R_{ki}}{\partial x^j}=2\Gamma^l_{ik}R_{lj}+2\Gamma^l_{jk}R_{il}+2\Gamma^l_{ij}R_{kl} R=g^{ij}R_{ij} g^{lj},g^{il},g^{kl}","['differential-geometry', 'riemannian-geometry', 'tensors', 'curvature']"
59,Computing a Killing vector field from flow,Computing a Killing vector field from flow,,"I am given the following manifold $N=\{(x,y)\in \mathbb{R}^2, y>0\}$ with metric: $$ds^2=\frac{dx^2+dy^2}{y^2}$$ There is a suggestion to take $z=x+iy$ and consider the transformations: $$z\to z+c\,, \quad z\to cz\,,\quad z \to \frac{z}{cz+1}\,,\quad c\in \mathbb{R}$$ I have to find three independent Killing vector fields. I think the idea is to define a flow from those transformations and then compute the Killing vectors associated to that flow. Is there any systematic way to do this?",I am given the following manifold with metric: There is a suggestion to take and consider the transformations: I have to find three independent Killing vector fields. I think the idea is to define a flow from those transformations and then compute the Killing vectors associated to that flow. Is there any systematic way to do this?,"N=\{(x,y)\in \mathbb{R}^2, y>0\} ds^2=\frac{dx^2+dy^2}{y^2} z=x+iy z\to z+c\,, \quad z\to cz\,,\quad z \to \frac{z}{cz+1}\,,\quad c\in \mathbb{R}",['differential-geometry']
60,"Does the norm of a (1,1) tensor depend on the conformal factor?","Does the norm of a (1,1) tensor depend on the conformal factor?",,"If we have a $(1,1)$ tensor $T$ on a (pseudo-)Riemannian manifold $(M,g)$ , its norm is $$ g(T, T) = g_{AB}g^{CD}T^A_C T^B_D. $$ If we let $h = \phi^2 g$ be a conformally equivalent metric, then its inverse is $h^{-1} = \phi^{-2}g^{-1}$ and thus the norm of $T$ as measured by $h$ is identical, as the conformal factors cancel out. This only happens when $T$ is a mixed tensor which is covariant in the same number of indices as it is contravariant. Questions: Is this proof correct? Is there any geometric reason why these types of tensors have their norm preserved by conformal transformations?","If we have a tensor on a (pseudo-)Riemannian manifold , its norm is If we let be a conformally equivalent metric, then its inverse is and thus the norm of as measured by is identical, as the conformal factors cancel out. This only happens when is a mixed tensor which is covariant in the same number of indices as it is contravariant. Questions: Is this proof correct? Is there any geometric reason why these types of tensors have their norm preserved by conformal transformations?","(1,1) T (M,g) 
g(T, T) = g_{AB}g^{CD}T^A_C T^B_D.
 h = \phi^2 g h^{-1} = \phi^{-2}g^{-1} T h T","['differential-geometry', 'solution-verification', 'riemannian-geometry', 'tensors']"
61,Orthogonality between geodesics and normal spheres in a Riemannian manifold,Orthogonality between geodesics and normal spheres in a Riemannian manifold,,"In do Carmo's Riemannian Geometry , right after proving Gauss' Lemma and defining normal neighborhoods and normal balls, the author writes: By Gauss' Lemma, the boundary of a normal ball $B_\varepsilon(p)$ is a hypersurface (a submanifold of codimension $1$ ) in $M$ orthogonal to the geodesics leaving $p$ , which is denoted by $S_\varepsilon (p)$ and called the normal (or geodesic sphere). As I understand, the orthogonality refers to ortogonality between the tangent vector of the geodesic and the tangent plane to the said hypersurface. Is it correct? Anyway, how to prove the claim about the sphere being a submanifold and the claim about orthogonality? Thanks in advance.","In do Carmo's Riemannian Geometry , right after proving Gauss' Lemma and defining normal neighborhoods and normal balls, the author writes: By Gauss' Lemma, the boundary of a normal ball is a hypersurface (a submanifold of codimension ) in orthogonal to the geodesics leaving , which is denoted by and called the normal (or geodesic sphere). As I understand, the orthogonality refers to ortogonality between the tangent vector of the geodesic and the tangent plane to the said hypersurface. Is it correct? Anyway, how to prove the claim about the sphere being a submanifold and the claim about orthogonality? Thanks in advance.",B_\varepsilon(p) 1 M p S_\varepsilon (p),"['differential-geometry', 'riemannian-geometry', 'geodesic']"
62,Connection on pullback bundle.,Connection on pullback bundle.,,"Let $E\to N$ be a vector bundle and $f:M\to N$ be a smooth map. The pullback $f^*:\Omega^k(N,E)\to \Omega^k(M,f^*E)$ is then defined by $$(f^*\omega)_x(v_1,...,v_k)=\omega_{f(x)}((df)_x(v_1),...,(df)_x(v_k))$$ with $x\in M$ and $v_1,...,v_k\in T_xM$ . First question : how can I rewrite this pullback as a map $f^*\omega:\mathfrak{X}(M)\times...\times \mathfrak{X}(M)\to \Gamma(M,f^*E)$ ? My problem is that $df:\mathfrak{X}(M)\to \mathfrak{X}(N)$ is well defined as long as $f$ is a diffeomorphism. However, $df:\mathfrak{X}(M)\to \Gamma(M,f^*TN)$ is actually well defined. Then, I know that the connection $f^*\nabla$ on $f^*E\to M$ is uniquely determined by $$(f^*\nabla)(f^*s):=f^*(\nabla(s))\in \Omega^1(M,f^*E)$$ Second question: In some books, I saw the notation $$(f^*\nabla)_X(f^*s)=f^*(\nabla_{df(X)}(s))=\nabla_{df(X)}(s)\circ f$$ but as long as $f$ is not a diffeomorphism $df(X)$ is not a vector field on $N$ so it doesn't make sense writing $\nabla_{df(X)}$ . How can I solve this problem?","Let be a vector bundle and be a smooth map. The pullback is then defined by with and . First question : how can I rewrite this pullback as a map ? My problem is that is well defined as long as is a diffeomorphism. However, is actually well defined. Then, I know that the connection on is uniquely determined by Second question: In some books, I saw the notation but as long as is not a diffeomorphism is not a vector field on so it doesn't make sense writing . How can I solve this problem?","E\to N f:M\to N f^*:\Omega^k(N,E)\to \Omega^k(M,f^*E) (f^*\omega)_x(v_1,...,v_k)=\omega_{f(x)}((df)_x(v_1),...,(df)_x(v_k)) x\in M v_1,...,v_k\in T_xM f^*\omega:\mathfrak{X}(M)\times...\times \mathfrak{X}(M)\to \Gamma(M,f^*E) df:\mathfrak{X}(M)\to \mathfrak{X}(N) f df:\mathfrak{X}(M)\to \Gamma(M,f^*TN) f^*\nabla f^*E\to M (f^*\nabla)(f^*s):=f^*(\nabla(s))\in \Omega^1(M,f^*E) (f^*\nabla)_X(f^*s)=f^*(\nabla_{df(X)}(s))=\nabla_{df(X)}(s)\circ f f df(X) N \nabla_{df(X)}","['differential-geometry', 'vector-bundles', 'connections']"
63,Variation of metric,Variation of metric,,"I am looking at the derivation of the Einstein field equations as the Euler-Lagrange equations of the Hilbert functional. To do this one starts with a variation $$ g(t) = g+th $$ of the metric, where $h$ is a symmetric 2-covariant tensor. For small $t$ , $g(t)$ will be invertible (if we interpret it as a matrix), so it makes sense to consider the components $g(t)^{ij}$ of the inverse. We have $$ 0 = \frac{d}{dt}\Big|_0 (g(t)_{ij} \, g(t)^{jk}) = h_{ij} g^{jk} + g_{ij}h^{jk} \quad\Rightarrow \quad h^{lk} = - g^{il} g^{jk} h_{ij}. $$ My question: What exactly do the coefficients $h^{lk}$ represent? I always thought that if one has a, say, 1-covariant tensor $A = A_i dx^i$ , then $A^i$ denote the components of the 1-contravariant tensor $A^\#$ (cf. musical isomorphisms ), given by $A^i = g^{ij}A_j$ . But in the formula for $h^{lk}$ above we also have a minus sign in front, so as far as I can see the coefficients $h^{lk}$ are not obtained by raising the indices of $h_{lk}$ . That being said, the metric is not really fixed in this case so the musical isomorphisms aren't either, which may be the source of confusion for me.","I am looking at the derivation of the Einstein field equations as the Euler-Lagrange equations of the Hilbert functional. To do this one starts with a variation of the metric, where is a symmetric 2-covariant tensor. For small , will be invertible (if we interpret it as a matrix), so it makes sense to consider the components of the inverse. We have My question: What exactly do the coefficients represent? I always thought that if one has a, say, 1-covariant tensor , then denote the components of the 1-contravariant tensor (cf. musical isomorphisms ), given by . But in the formula for above we also have a minus sign in front, so as far as I can see the coefficients are not obtained by raising the indices of . That being said, the metric is not really fixed in this case so the musical isomorphisms aren't either, which may be the source of confusion for me."," g(t) = g+th  h t g(t) g(t)^{ij}  0 = \frac{d}{dt}\Big|_0 (g(t)_{ij} \, g(t)^{jk}) = h_{ij} g^{jk} + g_{ij}h^{jk} \quad\Rightarrow \quad h^{lk} = - g^{il} g^{jk} h_{ij}.  h^{lk} A = A_i dx^i A^i A^\# A^i = g^{ij}A_j h^{lk} h^{lk} h_{lk}","['differential-geometry', 'riemannian-geometry', 'tensors', 'euler-lagrange-equation']"
64,Why did I get $J \bar{v} = \sqrt{-1}\bar{v}$ ??,Why did I get  ??,J \bar{v} = \sqrt{-1}\bar{v},"Q. I cannot deduce the equation $J \bar{v}= -\sqrt{-1}\bar{v}$ for $v$ satisfying $Jv= \sqrt{-1}v$ . Details Let $V$ be a vector space on $\mathbb{R}$ equipped with a complex structure $J$ . Using $J$ , the action of $\mathbb{C}$ to $V$ is defined by $(a+b\sqrt{-1})v := av + bJv$ for $v \in V$ and $a,b \in \mathbb{R}$ . Let $V_{\mathbb{C}}:= V \otimes_ \mathbb{R} \mathbb{C}$ . For $v= w\otimes_ \mathbb{R} \alpha \in V_{\mathbb{C}}$ , its complex conjugate is defined by $\bar{v}:= w\otimes_ \mathbb{R} \bar{\alpha} \in V_{\mathbb{C}}$ . I cannot understand the statement that $Jv= \sqrt{-1}v$ implies $J \bar{v}= -\sqrt{-1}\bar{v}$ , where $v \in V_{\mathbb{C}}$ . In my view, $J \bar{v} = J( w\otimes_ \mathbb{R} \bar{\alpha} )= (J w) \otimes_ \mathbb{R} \bar{\alpha} =  (\sqrt{-1} w) \otimes_ \mathbb{R} \bar{\alpha}$ I get stuck, because $\sqrt{-1}$ cannot pass the $\otimes_ \mathbb{R}$ . So,.. but maybe $J \bar{v} = J( w\otimes_ \mathbb{R} \bar{\alpha} )= (J w) \otimes_ \mathbb{R} \bar{\alpha} =  (\sqrt{-1} w) \otimes_ \mathbb{R} \bar{\alpha}:=  \sqrt{-1}( w \otimes_ \mathbb{R} \bar{\alpha})=  \sqrt{-1} \bar{v}$ ?? Where do I misunderstand??","Q. I cannot deduce the equation for satisfying . Details Let be a vector space on equipped with a complex structure . Using , the action of to is defined by for and . Let . For , its complex conjugate is defined by . I cannot understand the statement that implies , where . In my view, I get stuck, because cannot pass the . So,.. but maybe ?? Where do I misunderstand??","J \bar{v}= -\sqrt{-1}\bar{v} v Jv= \sqrt{-1}v V \mathbb{R} J J \mathbb{C} V (a+b\sqrt{-1})v := av + bJv v \in V a,b \in \mathbb{R} V_{\mathbb{C}}:= V \otimes_ \mathbb{R} \mathbb{C} v= w\otimes_ \mathbb{R} \alpha \in V_{\mathbb{C}} \bar{v}:= w\otimes_ \mathbb{R} \bar{\alpha} \in V_{\mathbb{C}} Jv= \sqrt{-1}v J \bar{v}= -\sqrt{-1}\bar{v} v \in V_{\mathbb{C}} J \bar{v} = J( w\otimes_ \mathbb{R} \bar{\alpha} )= (J w) \otimes_ \mathbb{R} \bar{\alpha} =  (\sqrt{-1} w) \otimes_ \mathbb{R} \bar{\alpha} \sqrt{-1} \otimes_ \mathbb{R} J \bar{v} = J( w\otimes_ \mathbb{R} \bar{\alpha} )= (J w) \otimes_ \mathbb{R} \bar{\alpha} =  (\sqrt{-1} w) \otimes_ \mathbb{R} \bar{\alpha}:=  \sqrt{-1}( w \otimes_ \mathbb{R} \bar{\alpha})=  \sqrt{-1} \bar{v}","['differential-geometry', 'complex-geometry', 'almost-complex']"
65,inclusion map in smooth manifold,inclusion map in smooth manifold,,"Given smooth manifold $M$ and it's submanifold $S$ (e.g. open subset of $M$ ) we have inclusion map $i:S\to M$ . And we treat $i$ as $i(x) = x$ typically. For example $i:S^n \to \mathbb{R}^{n+1}$ is valid to define $i(x) = x$ But it seems not for example inclusion $i:\mathbb{R}^n \to \mathbb{R}^{n+1}$ as $(x_1,...,x_n) \to (x_1,...,x_n,0)$ So I was a bit confused what is the definition for inclusion here?Should we treat it as $i(x) = x$ ? Is this ""inclusion"" a topological embedding by default setting or not? I found an explanation here","Given smooth manifold and it's submanifold (e.g. open subset of ) we have inclusion map . And we treat as typically. For example is valid to define But it seems not for example inclusion as So I was a bit confused what is the definition for inclusion here?Should we treat it as ? Is this ""inclusion"" a topological embedding by default setting or not? I found an explanation here","M S M i:S\to M i i(x) = x i:S^n \to \mathbb{R}^{n+1} i(x) = x i:\mathbb{R}^n \to \mathbb{R}^{n+1} (x_1,...,x_n) \to (x_1,...,x_n,0) i(x) = x","['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
66,Literature review of a (possibly) open differential geometry problem,Literature review of a (possibly) open differential geometry problem,,"I recently came across an apparently simple-sounding problem in basic differential geometry, as mentioned below, Problem Let $S \subset \mathbb{R}^3$ be a closed surface of diameter $d$ . Suppose that there exists a constant $h < d$ so that whenever a pair of planes separated by a distance of $h$ intersects $S$ , the area of $S$ contained between these planes is constant. Does it then follow that $S$ is a sphere? I searched for references/reviews regarding progress made for this problem, but could not find anything relevant. It would be helpful if someone could point out any relevant material/concepts regarding this problem.","I recently came across an apparently simple-sounding problem in basic differential geometry, as mentioned below, Problem Let be a closed surface of diameter . Suppose that there exists a constant so that whenever a pair of planes separated by a distance of intersects , the area of contained between these planes is constant. Does it then follow that is a sphere? I searched for references/reviews regarding progress made for this problem, but could not find anything relevant. It would be helpful if someone could point out any relevant material/concepts regarding this problem.",S \subset \mathbb{R}^3 d h < d h S S S,"['differential-geometry', 'reference-request', 'soft-question']"
67,Mistake in Spivak's definition of a consistent orientation on a manifold,Mistake in Spivak's definition of a consistent orientation on a manifold,,"I think Spivak may have made a mistake when defining the notion of a consistent orientation on a manifold. I've included the relevant section of Calculus on Manifolds below. I should mention that when Spivak mentions a manifold, they are referring to an embedded submanifold in $\mathbb{R}^n$ . It is often necessary to choose an orientation $\mu_x$ for each tangent space $M_x$ of a manifold $M$ . Such choices are called consistent provided that for every coordinate system $f\colon W\to\mathbb{R}^n$ and $a,b\in W$ the relation $$[f_*((e_1)_a),\ldots,f_*((e_k)_a)]=\mu_{f(a)}$$ holds if and only if $$[f_*((e_1)_b),\ldots,f_*((e_k)_b)]=\mu_{f(b)}.$$ I think this definition of consistent orientation is problematic when $W$ is not a connected set. For instance, consider $$M=\{(x,y)\in\mathbb{R}^2:y=0\}.$$ Then $M$ is a $1$ -manifold in $\mathbb{R}^2$ . However under Spivak's definitions, $M$ is non-orientable. Indeed, suppose for the sake of contradiction that $\mu$ is a consistent orientation on $M$ . Define $W=(-1,1)\cup (2,4)\subset\mathbb{R}$ and the coordinate systems $f,g\colon W\to\mathbb{R}^2$ by $$f(x)=(x,0)\qquad\text{and}\qquad g(x)=\begin{cases}(-x,0), &\text{if }x\in(-1,1);\\(x,0),&\text{if }x\in(2,4).\end{cases}$$ Finally, set $a=0$ and $b=3$ . Then $f(a)=g(a)=(0,0)$ and $f(b)=g(b)=(3,0)$ . According to Spivak's definition, we must have $[f_*((e_1)_a)]=\mu_{(0,0)}$ if and only if $[f_*((e_1)_b)]=\mu_{(3,0)}$ . Similarly, $[g_*((e_1)_a)]=\mu_{(0,0)}$ if and only if $[g_*((e_1)_b)]=\mu_{(3,0)}$ . This is impossible, since $$[f_*((e_1)_a)]=-[g_*((e_1)_a)]\qquad\text{but}\qquad [f_*((e_1)_b)]=[g_*((e_1)_b)].$$ I think a similar construction shows that every manifold is non-orientable with Spivak's definition. How do we fix this definition? Does it suffice to insist that $W$ be connected?","I think Spivak may have made a mistake when defining the notion of a consistent orientation on a manifold. I've included the relevant section of Calculus on Manifolds below. I should mention that when Spivak mentions a manifold, they are referring to an embedded submanifold in . It is often necessary to choose an orientation for each tangent space of a manifold . Such choices are called consistent provided that for every coordinate system and the relation holds if and only if I think this definition of consistent orientation is problematic when is not a connected set. For instance, consider Then is a -manifold in . However under Spivak's definitions, is non-orientable. Indeed, suppose for the sake of contradiction that is a consistent orientation on . Define and the coordinate systems by Finally, set and . Then and . According to Spivak's definition, we must have if and only if . Similarly, if and only if . This is impossible, since I think a similar construction shows that every manifold is non-orientable with Spivak's definition. How do we fix this definition? Does it suffice to insist that be connected?","\mathbb{R}^n \mu_x M_x M f\colon W\to\mathbb{R}^n a,b\in W [f_*((e_1)_a),\ldots,f_*((e_k)_a)]=\mu_{f(a)} [f_*((e_1)_b),\ldots,f_*((e_k)_b)]=\mu_{f(b)}. W M=\{(x,y)\in\mathbb{R}^2:y=0\}. M 1 \mathbb{R}^2 M \mu M W=(-1,1)\cup (2,4)\subset\mathbb{R} f,g\colon W\to\mathbb{R}^2 f(x)=(x,0)\qquad\text{and}\qquad g(x)=\begin{cases}(-x,0), &\text{if }x\in(-1,1);\\(x,0),&\text{if }x\in(2,4).\end{cases} a=0 b=3 f(a)=g(a)=(0,0) f(b)=g(b)=(3,0) [f_*((e_1)_a)]=\mu_{(0,0)} [f_*((e_1)_b)]=\mu_{(3,0)} [g_*((e_1)_a)]=\mu_{(0,0)} [g_*((e_1)_b)]=\mu_{(3,0)} [f_*((e_1)_a)]=-[g_*((e_1)_a)]\qquad\text{but}\qquad [f_*((e_1)_b)]=[g_*((e_1)_b)]. W","['differential-geometry', 'manifolds', 'orientation']"
68,Counterexample: Uniqueness of fiber metric on alternating $2$-vectors,Counterexample: Uniqueness of fiber metric on alternating -vectors,2,"I'm working on the following problem (Lee's ""Riemannian Manifolds"", Problem 8-33(a)). Suppose $(M,g)$ is a Riemannian manifold. Let $\Lambda^2(TM)$ be the bundle of $2$ -tensors on $M$ . Show that there is a unique fiber metric on $\Lambda^2(TM)$ whose associated norm satisfies $$|w \wedge x|^2 = |w|^2|x|^2-\langle w, x\rangle^2$$ for all tangent vectors $w, x$ at every point $q \in M$ . My question: Are we guaranteed uniqueness? Existence is straightforward by taking a local orthonormal frame $\{E_1,\ldots, E_n\}$ of $M$ and declaring $\{E_i \wedge E_j : i < j\}$ to be an orthonormal frame. One can further show using the algebra of alternating bivectors that given any local orthonormal frame $\{\tilde E_1, \ldots, \tilde E_n\}$ , the corresponding set $\{\tilde E_i \wedge \tilde E_j : i < j\}$ of contravariant $2$ -tensor fields is orthonormal in this inner product, so this fiber bundle is smooth and well-defined on all of $M$ . However, I'm not sure we have uniqueness. Consider $(M,g) = (\mathbb{R}^4, \overline g)$ , where $\overline g$ is the Euclidean metric, and let $\{E_1, E_2, E_3, E_4\}$ be the standard orthonormal coordinate frame. Define the metric $\langle \cdot, \cdot \rangle$ on $\Lambda^2(T\mathbb R^4)$ by declaring $|E_i \wedge E_j| = 1$ for $1 \leq i<j \leq 4$ , along with the relations $$ \langle E_1 \wedge E_2, E_3 \wedge E_4 \rangle = \langle E_1 \wedge E_4, E_2 \wedge E_3 \rangle = -\langle E_1 \wedge E_3, E_2 \wedge E_4 \rangle = 1, $$ and all products of the form $\langle E_i \wedge E_j, E_i \wedge E_k \rangle = 0$ for $j \neq k$ . Noting $w \wedge x = \sum_{i<j}\left(w^i x^j - w^j x^i\right) E_i \wedge E_j$ , one can show by direct computation that in this metric, we have: \begin{align*} |w \wedge x|^2 &= 2\bigg((w^1 x^2 - w^2 x^1)(w^3x^4-w^4x^3) - (w^1x^3-w^3x^1)(w^2x^4-w^4x^2) + (w^1x^4-w^4x^1)(w^2x^3-w^3x^2)\bigg) \\ &\quad+ \sum_{i<j}(w^i x^j - w^j x^i)^2 \\ &= \sum_{i<j}(w^i x^j - w^j x^i)^2 = \sum_{i\neq j} \left((w^i)^2(v^j)^2-w^i v^i w^j v^j\right) \\ &= |w|^2|v|^2-\langle w, v \rangle^2, \end{align*} because the parenthetical term to the right of the $2$ in the first equation above simplifies to $0$ . This is obviously a different metric from the one generally constructed in the proof of existence, so is there a reason this metric fails the conditions of the problem, or is uniqueness indeed too much to ask for?","I'm working on the following problem (Lee's ""Riemannian Manifolds"", Problem 8-33(a)). Suppose is a Riemannian manifold. Let be the bundle of -tensors on . Show that there is a unique fiber metric on whose associated norm satisfies for all tangent vectors at every point . My question: Are we guaranteed uniqueness? Existence is straightforward by taking a local orthonormal frame of and declaring to be an orthonormal frame. One can further show using the algebra of alternating bivectors that given any local orthonormal frame , the corresponding set of contravariant -tensor fields is orthonormal in this inner product, so this fiber bundle is smooth and well-defined on all of . However, I'm not sure we have uniqueness. Consider , where is the Euclidean metric, and let be the standard orthonormal coordinate frame. Define the metric on by declaring for , along with the relations and all products of the form for . Noting , one can show by direct computation that in this metric, we have: because the parenthetical term to the right of the in the first equation above simplifies to . This is obviously a different metric from the one generally constructed in the proof of existence, so is there a reason this metric fails the conditions of the problem, or is uniqueness indeed too much to ask for?","(M,g) \Lambda^2(TM) 2 M \Lambda^2(TM) |w \wedge x|^2 = |w|^2|x|^2-\langle w, x\rangle^2 w, x q \in M \{E_1,\ldots, E_n\} M \{E_i \wedge E_j : i < j\} \{\tilde E_1, \ldots, \tilde E_n\} \{\tilde E_i \wedge \tilde E_j : i < j\} 2 M (M,g) = (\mathbb{R}^4, \overline g) \overline g \{E_1, E_2, E_3, E_4\} \langle \cdot, \cdot \rangle \Lambda^2(T\mathbb R^4) |E_i \wedge E_j| = 1 1 \leq i<j \leq 4 
\langle E_1 \wedge E_2, E_3 \wedge E_4 \rangle = \langle E_1 \wedge E_4, E_2 \wedge E_3 \rangle = -\langle E_1 \wedge E_3, E_2 \wedge E_4 \rangle = 1,
 \langle E_i \wedge E_j, E_i \wedge E_k \rangle = 0 j \neq k w \wedge x = \sum_{i<j}\left(w^i x^j - w^j x^i\right) E_i \wedge E_j \begin{align*}
|w \wedge x|^2 &= 2\bigg((w^1 x^2 - w^2 x^1)(w^3x^4-w^4x^3) - (w^1x^3-w^3x^1)(w^2x^4-w^4x^2) + (w^1x^4-w^4x^1)(w^2x^3-w^3x^2)\bigg) \\ &\quad+ \sum_{i<j}(w^i x^j - w^j x^i)^2 \\
&= \sum_{i<j}(w^i x^j - w^j x^i)^2 = \sum_{i\neq j} \left((w^i)^2(v^j)^2-w^i v^i w^j v^j\right) \\
&= |w|^2|v|^2-\langle w, v \rangle^2,
\end{align*} 2 0","['differential-geometry', 'riemannian-geometry', 'tensors', 'exterior-algebra']"
69,Problem 5-12 John Lee's Smooth Manifolds. A smooth covering map restricted to a component of the boundary is a smooth covering map onto a component,Problem 5-12 John Lee's Smooth Manifolds. A smooth covering map restricted to a component of the boundary is a smooth covering map onto a component,,"This is a problem I got stuck on while studying John Lee's Introduction to Smooth Manifolds. Problem 5-12. Suppose $E$ and $M$ are connected smooth manifolds with boundary, and $\pi : E \to M$ is a smooth covering map, i.e. $\pi$ is smooth surjective and each point in $M$ has a neighborhood $U$ such that each component of $\pi^{-1}(U)$ is mapped diffeomorphically onto $U$ by $\pi$ . Show that the restriction of $\pi $ to each connected component of $\partial E$ is a smooth covering map onto a component of $\partial M$ . My attempt so far: Let $F$ be a connected component of $\partial E$ . Let $x \in \pi(F)$ , and let $U$ be an evenly covered neighborhood of $x$ . Take $e \in F$ such that $\pi(e)=x$ . Let $\tilde U$ be the component of $\pi^{-1}(U)$ containing $e$ . Then $\pi|_{\tilde U} : \tilde{U} \to U$ is a diffeomorphism by assumption. Since $\pi$ is a local diffeomorphism, $\pi$ maps boundary points to boundary points, so we have $\pi(\tilde{U} \cap F) = U \cap \partial M$ . But this is not really getting me further. I need to show that first, the image $\pi(F)$ is a connected component of $\partial M$ . And then for each $x \in \pi(F)$ , there is an evenly covered neighborhood $U$ such that each component of $\pi^{-1}(U) \cap F$ is mapped diffeomorphically onto $U \cap \pi(F)$ by $\pi$ . How could I prove this? This problem is in a chapter on submanifolds, but I cannot see how I could use theorems on embedded submanifolds  here.","This is a problem I got stuck on while studying John Lee's Introduction to Smooth Manifolds. Problem 5-12. Suppose and are connected smooth manifolds with boundary, and is a smooth covering map, i.e. is smooth surjective and each point in has a neighborhood such that each component of is mapped diffeomorphically onto by . Show that the restriction of to each connected component of is a smooth covering map onto a component of . My attempt so far: Let be a connected component of . Let , and let be an evenly covered neighborhood of . Take such that . Let be the component of containing . Then is a diffeomorphism by assumption. Since is a local diffeomorphism, maps boundary points to boundary points, so we have . But this is not really getting me further. I need to show that first, the image is a connected component of . And then for each , there is an evenly covered neighborhood such that each component of is mapped diffeomorphically onto by . How could I prove this? This problem is in a chapter on submanifolds, but I cannot see how I could use theorems on embedded submanifolds  here.",E M \pi : E \to M \pi M U \pi^{-1}(U) U \pi \pi  \partial E \partial M F \partial E x \in \pi(F) U x e \in F \pi(e)=x \tilde U \pi^{-1}(U) e \pi|_{\tilde U} : \tilde{U} \to U \pi \pi \pi(\tilde{U} \cap F) = U \cap \partial M \pi(F) \partial M x \in \pi(F) U \pi^{-1}(U) \cap F U \cap \pi(F) \pi,"['differential-geometry', 'algebraic-topology', 'manifolds', 'smooth-manifolds', 'manifolds-with-boundary']"
70,Does the vanishing of the Lie derivative of the metric at a single point imply that the associated flow is isometric at some point?,Does the vanishing of the Lie derivative of the metric at a single point imply that the associated flow is isometric at some point?,,"Let $(M,g)$ be a smooth Riemannian manifold, and let $X \in \Gamma(TM)$ be a smooth compactly supported vector field on $M$ . Suppose that $(L_X g)(p)=0$ for some specific point $p \in M$ . Let $\phi_t$ be the flow of $X$ . Is it true that for every $t$ , $(d\phi_t)_{q(t)}$ is an isometry for some suitably chosen point $q(t)$ ? Is it true for $q(t)=p$ ? The point is that if we know that $L_Xg=0$ everywhere, i.e. $X$ is Killing, then $\phi_t$ is a global isometry. However, from inspecting the proof, it does not seem ""localizable"" (i.e. I think that the vanishing of $L_Xg$ at a point should not imply that the flow is an isometry, not even at a single point. But I don't know how to construct an example.)","Let be a smooth Riemannian manifold, and let be a smooth compactly supported vector field on . Suppose that for some specific point . Let be the flow of . Is it true that for every , is an isometry for some suitably chosen point ? Is it true for ? The point is that if we know that everywhere, i.e. is Killing, then is a global isometry. However, from inspecting the proof, it does not seem ""localizable"" (i.e. I think that the vanishing of at a point should not imply that the flow is an isometry, not even at a single point. But I don't know how to construct an example.)","(M,g) X \in \Gamma(TM) M (L_X g)(p)=0 p \in M \phi_t X t (d\phi_t)_{q(t)} q(t) q(t)=p L_Xg=0 X \phi_t L_Xg","['differential-geometry', 'differential-topology', 'riemannian-geometry', 'vector-fields', 'symmetry']"
71,Orientation of stereographic projection,Orientation of stereographic projection,,"I was reading Lee and was wondering if the stereographic projection of the north pole and the south pole are in the same oriented smooth atlas. To be more precise, we have $\sigma_N: S^n \to \mathbb{R}^n$ defined by: $$ \sigma_N(x^1, \ldots, x^{n+1}) = \frac{(x^1, \ldots, x^n)}{1-x^{n+1}} $$ and: $$ \sigma_N^{-1}(u^1, \ldots, u^n) = \frac{(2u^1, \ldots, 2u^n, |u|^2 - 1)}{|u|^2+1} $$ Then the projection from the south pole is given by: $\sigma_S(x) = -\sigma_N(x)$ . The composition of these two maps yields: $$ \sigma_S \circ \sigma_N^{-1} (x) = \frac{x}{|x|^2} $$ If the determinant of the total derivative of this map is negative, then these two functions do not belong to the same oriented smooth atlas. I have been able to show this in two and in three dimensions with some laborious computations in Mathematica, but I don't see how I can can compute that in the $n$ -dimensional case. Is there an easier way to show that these two maps do not belong to the same oriented smooth atlas?","I was reading Lee and was wondering if the stereographic projection of the north pole and the south pole are in the same oriented smooth atlas. To be more precise, we have defined by: and: Then the projection from the south pole is given by: . The composition of these two maps yields: If the determinant of the total derivative of this map is negative, then these two functions do not belong to the same oriented smooth atlas. I have been able to show this in two and in three dimensions with some laborious computations in Mathematica, but I don't see how I can can compute that in the -dimensional case. Is there an easier way to show that these two maps do not belong to the same oriented smooth atlas?","\sigma_N: S^n \to \mathbb{R}^n 
\sigma_N(x^1, \ldots, x^{n+1}) = \frac{(x^1, \ldots, x^n)}{1-x^{n+1}}
 
\sigma_N^{-1}(u^1, \ldots, u^n) = \frac{(2u^1, \ldots, 2u^n, |u|^2 - 1)}{|u|^2+1}
 \sigma_S(x) = -\sigma_N(x) 
\sigma_S \circ \sigma_N^{-1} (x) = \frac{x}{|x|^2}
 n","['differential-geometry', 'smooth-manifolds']"
72,Cohomology of $G$-invariant differential forms,Cohomology of -invariant differential forms,G,"Let $G$ be a Lie group with a left action on a manifold $M$ , $\cdot : G \times M \to M$ . Define a $G$ -invariant differential form $\alpha \in \Omega^{k}(M)$ as a form satisfying $g^{*}\alpha = \alpha,$ where $g:M \to M$ is the action by $g \in G$ . Since pullbacks commute with differentials, the set of all $G$ -invariant forms (which I will denote by $\Omega(M)^G$ ) is a subcomplex of $\Omega(M)$ . I found the following theorem in several places: Theorem: If $G$ is compact and connected, then the inclusion $i: \Omega(M)^{G} \to \Omega(M)$ is induces an isomorphism in de Rham cohomology. One of the places where I found this is https://planetmath.org/invariantdifferentialform . However, there is no proof there, and I would like to find a proof. Does anyone know a good reference on this subject matter?","Let be a Lie group with a left action on a manifold , . Define a -invariant differential form as a form satisfying where is the action by . Since pullbacks commute with differentials, the set of all -invariant forms (which I will denote by ) is a subcomplex of . I found the following theorem in several places: Theorem: If is compact and connected, then the inclusion is induces an isomorphism in de Rham cohomology. One of the places where I found this is https://planetmath.org/invariantdifferentialform . However, there is no proof there, and I would like to find a proof. Does anyone know a good reference on this subject matter?","G M \cdot : G \times M \to M G \alpha \in \Omega^{k}(M) g^{*}\alpha = \alpha, g:M \to M g \in G G \Omega(M)^G \Omega(M) G i: \Omega(M)^{G} \to \Omega(M)","['differential-geometry', 'lie-groups', 'smooth-manifolds', 'group-actions', 'de-rham-cohomology']"
73,Stokes’s theorem and compact 2-manifolds in $\mathbb{R}^2$,Stokes’s theorem and compact 2-manifolds in,\mathbb{R}^2,"I am trying to solve the following problem of Andrew Browder: ""Mathematical Analysis; An Introduction"" (Springer Undergraduate Texts in Mathematics): Find THE compact $2$ -manifold $M$ in $\mathbb{R}^2$ with area $\pi$ for which $$ \int_{\partial M} {y^3dx + (3x - x^3)dy} $$ is maximal. The definition of Manifold in the book is: Definition I have tried to use the Stokes’s theorem but I don't know how to find a such manifold $M$ . Thanks in advance.","I am trying to solve the following problem of Andrew Browder: ""Mathematical Analysis; An Introduction"" (Springer Undergraduate Texts in Mathematics): Find THE compact -manifold in with area for which is maximal. The definition of Manifold in the book is: Definition I have tried to use the Stokes’s theorem but I don't know how to find a such manifold . Thanks in advance.","2 M \mathbb{R}^2 \pi 
\int_{\partial M} {y^3dx + (3x - x^3)dy}
 M","['integration', 'differential-geometry', 'stokes-theorem', 'manifolds-with-boundary']"
74,"Associated vector bundles: Given a vector bundle $E$ show that $F(E)\times \mathbb{R}^n/GL(n,\mathbb{R})\cong E$",Associated vector bundles: Given a vector bundle  show that,"E F(E)\times \mathbb{R}^n/GL(n,\mathbb{R})\cong E","I am trying to understand the map between vector bundles and principal fibre bundles and would like to work out the following example explicitly. Moreover in this example I am only currently looking at one direction, I would like to understand this well to attempt the other direction after this. Given a vector bundle $ \pi:E\rightarrow M$ of rank $n$ , we can consider the frame bundle $F(E)$ . Since $F(E)$ is a principle fibre bundle we can consider the vector bundle associated to $F(E)$ which is $F(E)\times \mathbb{R}^n/GL(n,\mathbb{R})$ . Show that $\mathcal{P}=F(E)\times \mathbb{R}^n/GL(n,\mathbb{R})\cong E$ . Intuitively this makes sense but to fully understand this I should be able to produce a rigour argument. As I understand we can think elements of $F(E)$ fibrewise as maps $p: \mathbb{R}^n\rightarrow E_x$ . For $\mathcal{P}$ an element is an equivalence class $[p,v]$ where $p$ is a map as above, $v\in E_x$ and $(p,v)\sim(pg,\rho(g^{-1})v)$ (I'm not entirely sure what $\rho(g^{-1})v$ is, I know $\rho$ is the ""standard representation of $GL(n,\mathbb{R})$ in $\mathbb{R}^n$ but I don't know what this representation is). Taking inspiration from the wikipedia page, I claim that the isomorphism is given by $[p,v]\mapsto p(v)$ . First we show this is well defined. By definition of this map $[pg,\rho(g^{-1})v]\mapsto pg(\rho(g^{-1})v)$ ? If I understood the representation It would probably make sense why the $g$ and $\rho(g^{-1})$ cancel. It seemed like surjectivety should be clear, as for any $v\in E$ we can just take $[id,v]$ but this doesn't make sense. Also should the elements in $E$ be pairs $(v,p)$ with $p$ a point in the base manifold?","I am trying to understand the map between vector bundles and principal fibre bundles and would like to work out the following example explicitly. Moreover in this example I am only currently looking at one direction, I would like to understand this well to attempt the other direction after this. Given a vector bundle of rank , we can consider the frame bundle . Since is a principle fibre bundle we can consider the vector bundle associated to which is . Show that . Intuitively this makes sense but to fully understand this I should be able to produce a rigour argument. As I understand we can think elements of fibrewise as maps . For an element is an equivalence class where is a map as above, and (I'm not entirely sure what is, I know is the ""standard representation of in but I don't know what this representation is). Taking inspiration from the wikipedia page, I claim that the isomorphism is given by . First we show this is well defined. By definition of this map ? If I understood the representation It would probably make sense why the and cancel. It seemed like surjectivety should be clear, as for any we can just take but this doesn't make sense. Also should the elements in be pairs with a point in the base manifold?"," \pi:E\rightarrow M n F(E) F(E) F(E) F(E)\times \mathbb{R}^n/GL(n,\mathbb{R}) \mathcal{P}=F(E)\times \mathbb{R}^n/GL(n,\mathbb{R})\cong E F(E) p: \mathbb{R}^n\rightarrow E_x \mathcal{P} [p,v] p v\in E_x (p,v)\sim(pg,\rho(g^{-1})v) \rho(g^{-1})v \rho GL(n,\mathbb{R}) \mathbb{R}^n [p,v]\mapsto p(v) [pg,\rho(g^{-1})v]\mapsto pg(\rho(g^{-1})v) g \rho(g^{-1}) v\in E [id,v] E (v,p) p","['differential-geometry', 'vector-bundles', 'principal-bundles']"
75,How to prove that the Möbius band has geodesics?,How to prove that the Möbius band has geodesics?,,"In my class of Differential Geometry, the teacher defined geodesics as follows: A regular curve on a regular surface, denoted as $\gamma:I\subset\Bbb{R}\to S$ , ( $S$ is the surface) is a geodesic if, $\forall t\in I$ , the vector $\gamma""(t)$ is a normal vector to $S$ at the point $\gamma(t)$ . With this definition, I must prove for an exposition project that the möbius band can have geodesics. The problem is that saying that a vector is normal to a surface implies orientation, and the möbius band is un-orientable. So this is my question: How can i define geodesics on an un-orientable surface like the möbius band, and with that, how do i calculate them? Can't the möbius band have any geodesics at all, because of its un-orientability? If you can provide me a reference, i would apreciate it.","In my class of Differential Geometry, the teacher defined geodesics as follows: A regular curve on a regular surface, denoted as , ( is the surface) is a geodesic if, , the vector is a normal vector to at the point . With this definition, I must prove for an exposition project that the möbius band can have geodesics. The problem is that saying that a vector is normal to a surface implies orientation, and the möbius band is un-orientable. So this is my question: How can i define geodesics on an un-orientable surface like the möbius band, and with that, how do i calculate them? Can't the möbius band have any geodesics at all, because of its un-orientability? If you can provide me a reference, i would apreciate it.","\gamma:I\subset\Bbb{R}\to S S \forall t\in I \gamma""(t) S \gamma(t)","['differential-geometry', 'mobius-band']"
76,commuting the covariant derivative of a function,commuting the covariant derivative of a function,,"Let $f$ be a smooth function such on a compact kahler manifold $(M, w)$ , and the component of $w$ is denoted by $g_{ij}$ , assume there is a constant $s$ such that $sf = -g^{ij}\sqrt{-1}\partial_{j}\bar\partial_{i}f$ , we have: $s \nabla_j f   = -\nabla_j \nabla_p \nabla_{\bar p} f$ suppresing the mertic. Then how do you prove the following Bochner-Weitzenbock formula: $(\int_{U}-\nabla_j \nabla_p \nabla_{\bar p} f \nabla_\bar j f)w^n = (\int_{U} -\nabla_{\bar p} \nabla_p \nabla_{ j} f \nabla_{\bar j} f + R^{q \bar j} \nabla_{q} f \nabla_{\bar j}f )w^n$ Thoughts: the left hand side is simply $\partial_j sf = \partial_j-g^{ik}\sqrt{-1}\partial_{j}\bar\partial_{k}f = - \partial_j g^{ik} \sqrt{-1}\partial_{j}\bar\partial_{k}f -\partial_j\sqrt{-1}\partial_{j}\bar\partial_{k}f g^{ik}$ How do you proceed? Update: My definition for the Ricci curvature is the following: Lowering the index of the curvature tensor we have $R_{i \bar j k \bar l} = -\partial_{k} \partial_{l} g_{i \bar j} + g^{p \bar q}(\partial_k g_{i \bar q})(\partial_{\bar l} g_{p \bar j})$ , then let $R_{i\bar j} = g^{k \bar l } R_{i \bar j k \bar l}$ . It is not obvious how to go from this definition.","Let be a smooth function such on a compact kahler manifold , and the component of is denoted by , assume there is a constant such that , we have: suppresing the mertic. Then how do you prove the following Bochner-Weitzenbock formula: Thoughts: the left hand side is simply How do you proceed? Update: My definition for the Ricci curvature is the following: Lowering the index of the curvature tensor we have , then let . It is not obvious how to go from this definition.","f (M, w) w g_{ij} s sf = -g^{ij}\sqrt{-1}\partial_{j}\bar\partial_{i}f s \nabla_j f   = -\nabla_j \nabla_p \nabla_{\bar p} f (\int_{U}-\nabla_j \nabla_p \nabla_{\bar p} f \nabla_\bar j f)w^n = (\int_{U} -\nabla_{\bar p} \nabla_p \nabla_{ j} f \nabla_{\bar j} f + R^{q \bar j} \nabla_{q} f \nabla_{\bar j}f )w^n \partial_j sf = \partial_j-g^{ik}\sqrt{-1}\partial_{j}\bar\partial_{k}f = - \partial_j g^{ik} \sqrt{-1}\partial_{j}\bar\partial_{k}f -\partial_j\sqrt{-1}\partial_{j}\bar\partial_{k}f g^{ik} R_{i \bar j k \bar l} = -\partial_{k} \partial_{l} g_{i \bar j} + g^{p \bar q}(\partial_k g_{i \bar q})(\partial_{\bar l} g_{p \bar j}) R_{i\bar j} = g^{k \bar l } R_{i \bar j k \bar l}","['real-analysis', 'differential-geometry', 'partial-differential-equations', 'riemannian-geometry', 'complex-geometry']"
77,About (relatively) recent progress in manifold topology and de Rham cohomology,About (relatively) recent progress in manifold topology and de Rham cohomology,,"Background : I'm at the end of my BsC and in the next semester I'll start my MsC. I'm already familiar with analysis on manifolds (at the level of Tu's ""An Introduction to Manifolds"" and Spivak's ""A Comprehensive Introduction to Differential Geometry, Volume 1"") and classic differential geometry (at the level of Do Carmo's ""Differential geometry of curves and surfaces""). My main goal is to deeply understand how smooth manifolds work in terms of their topology and geometry. unfortunately I can't spend the whole 2 years of the MsC in this endeavor, so I need a more pinpoint focus in the future, so I'd like some help in deciding a sort of pre-project given the following (I'll try to be as specific as possible): Understanding the algebraic and differential topology of manifolds is a big deal for me. Right now I'm studying Milnor's ""Topology from the differentiable viewpoint"" and I'd really like to know what's out there beyond the topics he already covers (like, where does one go after Hopf's theorem?) The interplay of geometry and topology. Like the Bonnet-Myers theorem, (I think) Morse's theory, the sphere theorem and Hamilton's theorem, that kind of stuff. I'm also particularly interested in deeply understanding some of the topics Wellington de Melo covers in his ""Topology of manifolds"", like bundle geometry and the morphism of Chern-Weil. I know most of you will say ""ask your advisor, he's the best one to guide you in this"" but to be honest he's more or less as lost as I am. If it were possible I'd just spend the next 2 years of the MsC just trying to understand the topics I mentioned, but this is not doable and eventually I'm gonna have to focus on something a lot more specific. So I'm looking for advice: is this too much to expect for 2 years? Should I focus on something in particular on the list above? What have people been up to with diffential topology of manifolds now?","Background : I'm at the end of my BsC and in the next semester I'll start my MsC. I'm already familiar with analysis on manifolds (at the level of Tu's ""An Introduction to Manifolds"" and Spivak's ""A Comprehensive Introduction to Differential Geometry, Volume 1"") and classic differential geometry (at the level of Do Carmo's ""Differential geometry of curves and surfaces""). My main goal is to deeply understand how smooth manifolds work in terms of their topology and geometry. unfortunately I can't spend the whole 2 years of the MsC in this endeavor, so I need a more pinpoint focus in the future, so I'd like some help in deciding a sort of pre-project given the following (I'll try to be as specific as possible): Understanding the algebraic and differential topology of manifolds is a big deal for me. Right now I'm studying Milnor's ""Topology from the differentiable viewpoint"" and I'd really like to know what's out there beyond the topics he already covers (like, where does one go after Hopf's theorem?) The interplay of geometry and topology. Like the Bonnet-Myers theorem, (I think) Morse's theory, the sphere theorem and Hamilton's theorem, that kind of stuff. I'm also particularly interested in deeply understanding some of the topics Wellington de Melo covers in his ""Topology of manifolds"", like bundle geometry and the morphism of Chern-Weil. I know most of you will say ""ask your advisor, he's the best one to guide you in this"" but to be honest he's more or less as lost as I am. If it were possible I'd just spend the next 2 years of the MsC just trying to understand the topics I mentioned, but this is not doable and eventually I'm gonna have to focus on something a lot more specific. So I'm looking for advice: is this too much to expect for 2 years? Should I focus on something in particular on the list above? What have people been up to with diffential topology of manifolds now?",,"['differential-geometry', 'algebraic-topology', 'manifolds', 'differential-topology', 'advice']"
78,Questions about a proof of the Gauss-Bonnet theorem,Questions about a proof of the Gauss-Bonnet theorem,,"$\newcommand{\dz}{{\rm d}z}$ $\newcommand{\dbz}{{\rm d}\bar z}$ I am reading this version of the Gauss-Bonnet theorem (in the book Compact Riemann Surfaces by Jurgen Jost), which is regarding compact Riemann surfaces without boundary equipped with a conformal metric: Theorem (Gauss-Bonnet) Let $\Sigma$ be a compact Riemann surface without boundary, of genus $p$ , with a conformal Riemannian metric given in local coordinates by $\rho^2(z)\dz\dbz$ . Let the curvature be $K_\rho$ . Then $$\int_\Sigma K_\rho\rho^2(z)\frac{i}{2}\dz\wedge\dbz=2\pi(2-2p)$$ Before giving the proof I should note that the cases in which the curvature is constant have been proved, so we can make use of them, namely, these cases: The unit sphere $\Sigma=S^2,\ K\equiv 1$ (Induced Eulidean metric) The torus $\Sigma=\mathbb C/M,\ K\equiv 0$ (Induced Eucliean metric, and $M$ is a rank-2 lattice) $\Sigma=H/\Gamma,\ K\equiv -1$ (Hyperbolic metric given by $\frac{1}{y^2}\dz\dbz$ , and $\Gamma$ is a discrete group of isometries, acting without fixed points) The proof in the book goes like this: proof. By the uniformization theorem we first assume $\Sigma$ is diffeomorphic to $S^2$ or $\mathbb C/M$ or $H/\Gamma$ . We put another metric $\lambda^2(z)\dz\dbz$ of constant curvature $K$ . Now the quotient $\rho^2(z)/\lambda^2(z)$ is invariant under coordinate transformations, i.e. behaves like a function. We compute now $$\int K\lambda^2\frac{i}{2}\dz\wedge\dbz-\int K_\rho\rho^2\frac{i}{2}\dz\wedge\dbz\\ =-4\int\frac{\partial^2}{\partial z\partial\bar z}\log\lambda\frac{i}{2}\dz\wedge\dbz+4\int\frac{\partial^2}{\partial z\partial\bar z}\log\rho\frac{i}{2}\dz\wedge\dbz\\ =4\int\frac{\partial^2}{\partial z\partial\bar z}\log\frac{\rho}{\lambda}\frac{i}{2}\dz\wedge\dbz$$ which vanishes by Gauss' Divergence Theorem. The theorem then follows from the cases with constant curvatures. Thoughts and Questions: (1) How can we ensure the existence of a metric with constant curvature? Can I say that the diffeomorphism $f:\Sigma\to S^2$ (or $\mathbb C/M$ or $H/\Gamma$ , by the uniformization theorem) equips $S^2$ with a metric induced by that on $\Sigma$ , and the curvature integrals on them are the same, so as to focus on $S^2$ instead of $\Sigma$ ? (2) I understand why $\rho^2(z)/\lambda^2(z)$ is invariant under a coordinate transformation. But it doesn't seem to be useful in the following proof. What does it do? (3) Why does the last integral vanish? The Gauss divergence theorem turns an integral over a domain to its boundary. However, $\Sigma$ is a surface without a boundary, so I am not sure how the divergence theorem applies here. Does this have something to do with $\rho^2/\lambda^2$ being invariant under coordinate changes?","I am reading this version of the Gauss-Bonnet theorem (in the book Compact Riemann Surfaces by Jurgen Jost), which is regarding compact Riemann surfaces without boundary equipped with a conformal metric: Theorem (Gauss-Bonnet) Let be a compact Riemann surface without boundary, of genus , with a conformal Riemannian metric given in local coordinates by . Let the curvature be . Then Before giving the proof I should note that the cases in which the curvature is constant have been proved, so we can make use of them, namely, these cases: The unit sphere (Induced Eulidean metric) The torus (Induced Eucliean metric, and is a rank-2 lattice) (Hyperbolic metric given by , and is a discrete group of isometries, acting without fixed points) The proof in the book goes like this: proof. By the uniformization theorem we first assume is diffeomorphic to or or . We put another metric of constant curvature . Now the quotient is invariant under coordinate transformations, i.e. behaves like a function. We compute now which vanishes by Gauss' Divergence Theorem. The theorem then follows from the cases with constant curvatures. Thoughts and Questions: (1) How can we ensure the existence of a metric with constant curvature? Can I say that the diffeomorphism (or or , by the uniformization theorem) equips with a metric induced by that on , and the curvature integrals on them are the same, so as to focus on instead of ? (2) I understand why is invariant under a coordinate transformation. But it doesn't seem to be useful in the following proof. What does it do? (3) Why does the last integral vanish? The Gauss divergence theorem turns an integral over a domain to its boundary. However, is a surface without a boundary, so I am not sure how the divergence theorem applies here. Does this have something to do with being invariant under coordinate changes?","\newcommand{\dz}{{\rm d}z} \newcommand{\dbz}{{\rm d}\bar z} \Sigma p \rho^2(z)\dz\dbz K_\rho \int_\Sigma K_\rho\rho^2(z)\frac{i}{2}\dz\wedge\dbz=2\pi(2-2p) \Sigma=S^2,\ K\equiv 1 \Sigma=\mathbb C/M,\ K\equiv 0 M \Sigma=H/\Gamma,\ K\equiv -1 \frac{1}{y^2}\dz\dbz \Gamma \Sigma S^2 \mathbb C/M H/\Gamma \lambda^2(z)\dz\dbz K \rho^2(z)/\lambda^2(z) \int K\lambda^2\frac{i}{2}\dz\wedge\dbz-\int K_\rho\rho^2\frac{i}{2}\dz\wedge\dbz\\
=-4\int\frac{\partial^2}{\partial z\partial\bar z}\log\lambda\frac{i}{2}\dz\wedge\dbz+4\int\frac{\partial^2}{\partial z\partial\bar z}\log\rho\frac{i}{2}\dz\wedge\dbz\\
=4\int\frac{\partial^2}{\partial z\partial\bar z}\log\frac{\rho}{\lambda}\frac{i}{2}\dz\wedge\dbz f:\Sigma\to S^2 \mathbb C/M H/\Gamma S^2 \Sigma S^2 \Sigma \rho^2(z)/\lambda^2(z) \Sigma \rho^2/\lambda^2","['differential-geometry', 'riemannian-geometry', 'riemann-surfaces']"
79,Fixpoints of isometry is a totally geodesic submanifold,Fixpoints of isometry is a totally geodesic submanifold,,"I'm working on the proof for: Let $(M,g)$ be a Riemannian manifold, $F:M \rightarrow M$ isometry, $N:=\{x \in M \vert F(x)=x\}$ . Now I want to show that $N$ is a totally geodesic submanifold. I know that this question has already been asked and I also tried to understand the following proof for this: but as far as I see it, this only proofs that $N$ is a submanifold and not that it is totally geodesic. Is this part of the proof somehow trivial? (If yes, can somebody maybe explain it to me..?)","I'm working on the proof for: Let be a Riemannian manifold, isometry, . Now I want to show that is a totally geodesic submanifold. I know that this question has already been asked and I also tried to understand the following proof for this: but as far as I see it, this only proofs that is a submanifold and not that it is totally geodesic. Is this part of the proof somehow trivial? (If yes, can somebody maybe explain it to me..?)","(M,g) F:M \rightarrow M N:=\{x \in M \vert F(x)=x\} N N","['differential-geometry', 'riemannian-geometry', 'isometry', 'geodesic']"
80,Example of non regular surface,Example of non regular surface,,"I was reading definition of surface in differential geometry book   which defined as follows A subset $S\subset \mathbb  R^3$ is regular surface if $\forall p\in S $ there is open set in S such that $p\in V $ and $\exists \phi :U\to V\in S$ where U is open set in $\mathbb R^2 $ such that map is surjective , smooth and homeomorphism with image and also $\forall q\in U, dX_q:\mathbb R^2\to \mathbb R^3$ is injective TO better understand cocept I wanted to know counterexample of regular surface. Please Help me Any Help will be appreciated","I was reading definition of surface in differential geometry book   which defined as follows A subset is regular surface if there is open set in S such that and where U is open set in such that map is surjective , smooth and homeomorphism with image and also is injective TO better understand cocept I wanted to know counterexample of regular surface. Please Help me Any Help will be appreciated","S\subset \mathbb  R^3 \forall p\in S  p\in V  \exists \phi :U\to V\in S \mathbb R^2  \forall q\in U, dX_q:\mathbb R^2\to \mathbb R^3","['real-analysis', 'differential-geometry', 'examples-counterexamples', 'surfaces']"
81,Does the blow-up induce an isomorphism in top cohomology (real coefficients)?,Does the blow-up induce an isomorphism in top cohomology (real coefficients)?,,"Let $X$ be a (possibly singular) compact complex manifold of complex dimension $n$ and let $Y\subset X$ be a submanifold along we blow-up $X$ . So we get a blow-down map $P:Bl_Y X\to X$ . Is $P^*: H^{2n}(X,\mathbb R)\to H^{2n}(Bl_YX,\mathbb R)$ an   isomorphism? So far I looked at the Mayer Vietoris sequence for $Bl_YX = (Bl_YX\setminus E) \cup E$ , where $E$ is the exceptional divisor. We also call the corresponding intersection $Z$ .  If $X$ is non-singular, then $Z=S^{2n-1}$ . $Bl_YX\setminus E \simeq  X\setminus Y$ and as $\dim Y \le 2n-2$ , it follows that $H^{2n}(X) = H^{2n}(X\setminus Y)$ and $H^{2n-1}(X) = H^{2n-1}(X\setminus Y)$ . Also, $\dim E = 2n-2$ , so $H^{2n}(E)=H^{2n-1}(E) =0$ . Thus $$\to H^3(X) \stackrel j \to H^3 (Z)\to H^4(Bl_YX)\stackrel {i^*}\to H^4(X) \to 0$$ is exact. Thus in order for $H^4(Bl_YX)$ to be isomorphic to $H^4(X)$ , we need $j$ to be surjective. But even so, this would only tell me that $i^*$ is an isomorphism. I am interested in $P^*$ .","Let be a (possibly singular) compact complex manifold of complex dimension and let be a submanifold along we blow-up . So we get a blow-down map . Is an   isomorphism? So far I looked at the Mayer Vietoris sequence for , where is the exceptional divisor. We also call the corresponding intersection .  If is non-singular, then . and as , it follows that and . Also, , so . Thus is exact. Thus in order for to be isomorphic to , we need to be surjective. But even so, this would only tell me that is an isomorphism. I am interested in .","X n Y\subset X X P:Bl_Y X\to X P^*: H^{2n}(X,\mathbb R)\to H^{2n}(Bl_YX,\mathbb R) Bl_YX = (Bl_YX\setminus E) \cup E E Z X Z=S^{2n-1} Bl_YX\setminus E \simeq  X\setminus Y \dim Y \le 2n-2 H^{2n}(X) = H^{2n}(X\setminus Y) H^{2n-1}(X) = H^{2n-1}(X\setminus Y) \dim E = 2n-2 H^{2n}(E)=H^{2n-1}(E) =0 \to H^3(X) \stackrel j \to H^3 (Z)\to H^4(Bl_YX)\stackrel {i^*}\to H^4(X) \to 0 H^4(Bl_YX) H^4(X) j i^* P^*","['differential-geometry', 'algebraic-geometry', 'algebraic-topology', 'complex-geometry', 'blowup']"
82,"$X, Y$ are two complete vector fields with$[X, Y] = 0$, what is the resulting flow of $X+Y$?","are two complete vector fields with, what is the resulting flow of ?","X, Y [X, Y] = 0 X+Y","If $X, Y$ are two complete vector fields with $[X, Y] = 0$ , what is the resulting flow of $X+Y$ ? I'm kind of confused on what the flow is. I know that the respective flows for $\Phi_t^X$ and $\Phi_t^Y$ commute, but what is the flow for the addition of two vector fields? Thank you.","If are two complete vector fields with , what is the resulting flow of ? I'm kind of confused on what the flow is. I know that the respective flows for and commute, but what is the flow for the addition of two vector fields? Thank you.","X, Y [X, Y] = 0 X+Y \Phi_t^X \Phi_t^Y","['differential-geometry', 'vector-fields']"
83,Calculating Pull-Back of a $1$-form.,Calculating Pull-Back of a -form.,1,"I'm studying Differential Forms for the first time. I'm stuck on a problem that seems simple. My book definition. Let $f: \mathbb{R}^{n} \to \mathbb{R}^{m}$ be a differentiable function. Then $f$ induce an aplication $f^{*}$ that map $k$ -forms into $k$ -forms. Let $\omega$ a $k$ -form in $\mathbb{R}^{m}$ . By definition, $f^{\ast}\omega$ is a $k$ -form in $\mathbb{R}^{n}$ given by $$(f^{*}\omega)(p)(v_{1},...,v_{k}) = \omega(f(p))(df_{p}(v_{1}),...,df_{p}(v_{k}))\tag{1}$$ where $p \in \mathbb{R}^{n}$ , $v_{1},...,v_{k} \in T_{p}\mathbb{R}^{n}$ and $df_{p}: T_{p}\mathbb{R}^{n} \to T_{f(p)}\mathbb{R}^{n}$ is the differential aplication of $f$ . Here, $T_{p}$ is the tangent plane at $p$ . After that, the book give an example. Example. Let $\omega$ a $1$ -form in $\mathbb{R}^{2}\setminus\{(0,0)\}$ given by $$\omega = -\frac{y}{x^2+y^2}dx + \frac{x}{x^2+y^2}dy.$$ Let $U = \{(r,\theta) \mid r>0,0<\theta<2\pi\}$ and $f:U \to \mathbb{R}^{2}$ given by $$f(r,\theta) = \begin{cases} x = r\cos\theta\\ y = r\sin\theta \end{cases}.$$ Let's calculate $f^{*}\omega$ . Since $$dx = \cos\theta dr - r\sin\theta d\theta,$$ $$dy = \sin\theta dr + r\cos\theta d\theta,$$ we get $$f^{*}\omega = -\frac{r\sin\theta}{r^{2}}(\cos\theta dr - r\sin\theta d\theta) + \frac{r\cos\theta}{r^{2}}(\sin\theta dr + r\cos\theta d\theta) = d\theta.$$ I think that I don't completely understood the definition. Using (1), $$\omega(f(r,\theta)) = -\frac{r\sin\theta}{r^{2}}(\cos\theta dr - r\sin\theta d\theta) + \frac{r\cos\theta}{r^{2}}(\sin\theta dr + r\cos\theta d\theta)$$ But, what about $df_{(r,\theta)}(v)$ with $v \in T_{(r,\theta)}U$ ?","I'm studying Differential Forms for the first time. I'm stuck on a problem that seems simple. My book definition. Let be a differentiable function. Then induce an aplication that map -forms into -forms. Let a -form in . By definition, is a -form in given by where , and is the differential aplication of . Here, is the tangent plane at . After that, the book give an example. Example. Let a -form in given by Let and given by Let's calculate . Since we get I think that I don't completely understood the definition. Using (1), But, what about with ?","f: \mathbb{R}^{n} \to \mathbb{R}^{m} f f^{*} k k \omega k \mathbb{R}^{m} f^{\ast}\omega k \mathbb{R}^{n} (f^{*}\omega)(p)(v_{1},...,v_{k}) = \omega(f(p))(df_{p}(v_{1}),...,df_{p}(v_{k}))\tag{1} p \in \mathbb{R}^{n} v_{1},...,v_{k} \in T_{p}\mathbb{R}^{n} df_{p}: T_{p}\mathbb{R}^{n} \to T_{f(p)}\mathbb{R}^{n} f T_{p} p \omega 1 \mathbb{R}^{2}\setminus\{(0,0)\} \omega = -\frac{y}{x^2+y^2}dx + \frac{x}{x^2+y^2}dy. U = \{(r,\theta) \mid r>0,0<\theta<2\pi\} f:U \to \mathbb{R}^{2} f(r,\theta) = \begin{cases}
x = r\cos\theta\\
y = r\sin\theta
\end{cases}. f^{*}\omega dx = \cos\theta dr - r\sin\theta d\theta, dy = \sin\theta dr + r\cos\theta d\theta, f^{*}\omega = -\frac{r\sin\theta}{r^{2}}(\cos\theta dr - r\sin\theta d\theta) + \frac{r\cos\theta}{r^{2}}(\sin\theta dr + r\cos\theta d\theta) = d\theta. \omega(f(r,\theta)) = -\frac{r\sin\theta}{r^{2}}(\cos\theta dr - r\sin\theta d\theta) + \frac{r\cos\theta}{r^{2}}(\sin\theta dr + r\cos\theta d\theta) df_{(r,\theta)}(v) v \in T_{(r,\theta)}U","['real-analysis', 'differential-geometry', 'differential-forms']"
84,Why doesn't ds appear in the statement of Green's Theorem?,Why doesn't ds appear in the statement of Green's Theorem?,,"I am trying to compare the line integral stated in Green's Theorem with the definition of a line integral. According to Wikipedia: $$ \oint_C(L dx+Mdy)=\int^b_af(\textbf{r}(t))|\textbf{r}'(t)|dt. $$ My intuition tells me that $\textbf{r}(t)=(x(t),y(t))$ . Let $ds=\sqrt{dx^2+dy^2}$ . Thus, $|\textbf{r}'(t)|dt=ds$ , right? So if $C$ is a simple closed curve, is the expression below equivalent to the expression of the line integral in Green's Theorem? $$ \oint_C(L+M)ds $$ My question really is: what are $f$ and $\textbf{r}$ in the statement of Green's theorem? I was only able to recreate the statement by definition by letting $L$ and $M$ be independent of $y$ and $x$ respectively, as seen below: $$ \oint_CL(x(t))|\frac{dx}{dt}|dt+M(y(t))|\frac{dy}{dt}|dt. $$ The problem that I run into here is that $\partial L/\partial y$ and $\partial M/\partial x$ are then both 0.","I am trying to compare the line integral stated in Green's Theorem with the definition of a line integral. According to Wikipedia: My intuition tells me that . Let . Thus, , right? So if is a simple closed curve, is the expression below equivalent to the expression of the line integral in Green's Theorem? My question really is: what are and in the statement of Green's theorem? I was only able to recreate the statement by definition by letting and be independent of and respectively, as seen below: The problem that I run into here is that and are then both 0.","
\oint_C(L dx+Mdy)=\int^b_af(\textbf{r}(t))|\textbf{r}'(t)|dt.
 \textbf{r}(t)=(x(t),y(t)) ds=\sqrt{dx^2+dy^2} |\textbf{r}'(t)|dt=ds C 
\oint_C(L+M)ds
 f \textbf{r} L M y x 
\oint_CL(x(t))|\frac{dx}{dt}|dt+M(y(t))|\frac{dy}{dt}|dt.
 \partial L/\partial y \partial M/\partial x",['differential-geometry']
85,"For which $P,Q \in \text{SO}$ $T_P\text{SO}$ and $T_Q\text{SO}$ are parallel?",For which   and  are parallel?,"P,Q \in \text{SO} T_P\text{SO} T_Q\text{SO}","I am curious: For which $P,Q \in \text{SO}_n$ does $T_Q\text{SO}_n=T_P\text{SO}_n$ hold? This reduces to the question at the identity,i.e. for which $Q \in  \text{SO}_n$ , $T_Q\text{SO}_n=T_{Id}\text{SO}_n=\text{skew}$ . I will now prove that $Q^2=Id$ is a necessary condition. Is it sufficient? Since $T_Q\text{SO}_n=QT_{Id}\text{SO}_n=Q\text{skew}$ , this happens if and only if $Q\text{skew}=\text{skew}$ , i.e. $-AQ^T=(QA)^T=-QA$ for every $A \in \text{skew}$ , or $AQ^T=QA$ . Taking traces we get $$ \langle Q,A\rangle=\text{tr}(Q^TA)=\text{tr}(AQ^T)=\text{tr}(QA)=\text{tr}(AQ)=-\text{tr}(A^TQ)= \langle A,Q\rangle,$$ so $\langle Q,A\rangle=0$ for every $A \in \text{skew}$ , i.e. $Q \in \text{skew}^{\perp}=\text{sym}$ , so $Q^T=Q$ , or $Q^2=Id$ . Note that at even dimensions $Q=-Id$ is always a solution. For dimension $n=2$ , this is indeed the only non-trivial solution (since $\text{SO}_2$ is the circle). In that case $Q^2=Id$ , and $Q=\pm Id$ are equivalent.","I am curious: For which does hold? This reduces to the question at the identity,i.e. for which , . I will now prove that is a necessary condition. Is it sufficient? Since , this happens if and only if , i.e. for every , or . Taking traces we get so for every , i.e. , so , or . Note that at even dimensions is always a solution. For dimension , this is indeed the only non-trivial solution (since is the circle). In that case , and are equivalent.","P,Q \in \text{SO}_n T_Q\text{SO}_n=T_P\text{SO}_n Q \in  \text{SO}_n T_Q\text{SO}_n=T_{Id}\text{SO}_n=\text{skew} Q^2=Id T_Q\text{SO}_n=QT_{Id}\text{SO}_n=Q\text{skew} Q\text{skew}=\text{skew} -AQ^T=(QA)^T=-QA A \in \text{skew} AQ^T=QA  \langle Q,A\rangle=\text{tr}(Q^TA)=\text{tr}(AQ^T)=\text{tr}(QA)=\text{tr}(AQ)=-\text{tr}(A^TQ)= \langle A,Q\rangle, \langle Q,A\rangle=0 A \in \text{skew} Q \in \text{skew}^{\perp}=\text{sym} Q^T=Q Q^2=Id Q=-Id n=2 \text{SO}_2 Q^2=Id Q=\pm Id","['differential-geometry', 'lie-groups', 'riemannian-geometry', 'orthogonal-matrices', 'tangent-spaces']"
86,Is it trivial that the Levi-Civita connection can be pulled back to a isometric manifold?,Is it trivial that the Levi-Civita connection can be pulled back to a isometric manifold?,,"Let $M, N$ be Riemannian Manifolds and $\phi: M \to N$ a isometric diffeomorphism. We know that we have unique Levi-Civita Connections $\nabla^M, \nabla^N$ on $M, N$ respectively. One can check that $\tilde\nabla^N_V W = \phi^*\nabla^N_{\phi_* V}\phi_* W$ satisfies the properties of a Levi-Civita connection and hence (by uniqueness) $\tilde\nabla^N = \nabla^M$ . However it seems to me that this should be trivial , since $M$ and $N$ are ""the same"" (when identified via $\phi$ ) as far as their differentiable structures and metrics are concerned. Since the properties of a Levi-Civita connection are expressed using only ""the language of Riemannian manifolds"" (i.e. smooth functions, vector fields, the metric, etc.) it seems that it should be obvious that $\tilde\nabla^N$ is a Levi-Civita connection on $M$ . To me this seems analogous to other trivial facts like The tangent bundles of diffeomorphic manifolds are isomorphic (as vector bundles) The centers of isomorphic groups are isomorphic (Number 1 can actually be argued to follow from the functoriality of taking tangent spaces, but AFAIK there is no suitable functor that works for 2). So is it a valid argument to say that the Levi-Civita connection can be pulled back to $M$ because the two manifolds are ""the same in every relevant aspect""? Also is there any way to generalize this kind of argument? EDIT: It feels to me like this question (and the other two facts I stated) are an example of the following principle: Since $\phi$ preserves all structures on $M$ and $N$ (that is a Topological space, a smooth structure and a metric) and The Levi-Civita connections only depends on these structures they are equivalent (using $\phi$ to ""translate"" them). For the center of a group you would argue analogously, saying that it only depends on the group structure, which is preserved by group isomorphisms. Therefore the centers must be isomorphic (with the isomorphism given by the isomorphism on the groups). And so on...","Let be Riemannian Manifolds and a isometric diffeomorphism. We know that we have unique Levi-Civita Connections on respectively. One can check that satisfies the properties of a Levi-Civita connection and hence (by uniqueness) . However it seems to me that this should be trivial , since and are ""the same"" (when identified via ) as far as their differentiable structures and metrics are concerned. Since the properties of a Levi-Civita connection are expressed using only ""the language of Riemannian manifolds"" (i.e. smooth functions, vector fields, the metric, etc.) it seems that it should be obvious that is a Levi-Civita connection on . To me this seems analogous to other trivial facts like The tangent bundles of diffeomorphic manifolds are isomorphic (as vector bundles) The centers of isomorphic groups are isomorphic (Number 1 can actually be argued to follow from the functoriality of taking tangent spaces, but AFAIK there is no suitable functor that works for 2). So is it a valid argument to say that the Levi-Civita connection can be pulled back to because the two manifolds are ""the same in every relevant aspect""? Also is there any way to generalize this kind of argument? EDIT: It feels to me like this question (and the other two facts I stated) are an example of the following principle: Since preserves all structures on and (that is a Topological space, a smooth structure and a metric) and The Levi-Civita connections only depends on these structures they are equivalent (using to ""translate"" them). For the center of a group you would argue analogously, saying that it only depends on the group structure, which is preserved by group isomorphisms. Therefore the centers must be isomorphic (with the isomorphism given by the isomorphism on the groups). And so on...","M, N \phi: M \to N \nabla^M, \nabla^N M, N \tilde\nabla^N_V W = \phi^*\nabla^N_{\phi_* V}\phi_* W \tilde\nabla^N = \nabla^M M N \phi \tilde\nabla^N M M \phi M N \phi","['proof-verification', 'differential-geometry', 'soft-question', 'category-theory']"
87,Hodge-$\star$ operator computation on a smooth two-dimensional manifold,Hodge- operator computation on a smooth two-dimensional manifold,\star,"Let $(x,y)$ be the local coordinates on a Riemannian manifold $M$ with $\dim(M) =2$ . Let $\star$ denote the Hodge- $\star$ operator, and let $g = g_{ij}$ denote the Riemannian metric on $M$ . I am attempting to compute the formula for the Laplace--Beltrami acting on 1-forms of $M$ . I have been stuck on computing that action of the Hodge- $\star$ operator on $dx$ and $dy$ , and this is what I would like help with. We know: $\star(1) = \sqrt{\det(g)} dx \wedge dy$ and $\star(dx \wedge dy) = \dfrac{1}{\sqrt{\det(g)}}$ . If the metric is simply $\delta_{ij}$ , then we know that $\star dx$ and $\star dy = -dx$ , but I am interested in the case when the metric $g_{ij} \neq \delta_{ij}$ . I would appreciate any help with this, and if you need any further details, please let me know. I have been aware of the following, but has been of little or no avail: \begin{eqnarray*} dx \wedge \star dx &=& \sqrt{\det(g_{ij})} g^{11} dx \wedge dy,\\ dy \wedge \star dx &=& \sqrt{\det(g_{ij})} g^{12} dy \wedge dx \end{eqnarray*} From this, it is claimed that we deduce: $$\star dx = \sqrt{\det(g_{ij})}(g^{11} dy - g^{12}dx).$$ This is not clear.","Let be the local coordinates on a Riemannian manifold with . Let denote the Hodge- operator, and let denote the Riemannian metric on . I am attempting to compute the formula for the Laplace--Beltrami acting on 1-forms of . I have been stuck on computing that action of the Hodge- operator on and , and this is what I would like help with. We know: and . If the metric is simply , then we know that and , but I am interested in the case when the metric . I would appreciate any help with this, and if you need any further details, please let me know. I have been aware of the following, but has been of little or no avail: From this, it is claimed that we deduce: This is not clear.","(x,y) M \dim(M) =2 \star \star g = g_{ij} M M \star dx dy \star(1) = \sqrt{\det(g)} dx \wedge dy \star(dx \wedge dy) = \dfrac{1}{\sqrt{\det(g)}} \delta_{ij} \star dx \star dy = -dx g_{ij} \neq \delta_{ij} \begin{eqnarray*}
dx \wedge \star dx &=& \sqrt{\det(g_{ij})} g^{11} dx \wedge dy,\\
dy \wedge \star dx &=& \sqrt{\det(g_{ij})} g^{12} dy \wedge dx
\end{eqnarray*} \star dx = \sqrt{\det(g_{ij})}(g^{11} dy - g^{12}dx).","['differential-geometry', 'riemannian-geometry', 'laplacian', 'hodge-theory']"
88,Show that a specific map is a submersion of $O(3)$ in $S^2$,Show that a specific map is a submersion of  in,O(3) S^2,"Denoting the components of the $3\times3$ matrix $A \in O(3)$ as $a_{ij}$ , show that $$ F: O(3) \rightarrow S^2, a_{ij} \mapsto a_{1j} $$ is a submersion. (The map is well defined since for $A \in O(3)$ it is true that $a_{11}^2 + a_{12}^2 + a_{13}^2 = 1$ .) From what I understand to show that the map is a submersion, I have to show that the differential map $$ dF: T_AO(3) \rightarrow T_{F(A)}S^2 $$ is onto for every $A \in O(3)$ . Now if I were given a tangent vector $X\in T_AO(3)$ then from what I understand the map simply is $dF: x_{ij} \mapsto x_{1j}$ , where $x_{ij}$ denote the components of $X$ . However, I fail to see that this is surjective at every point $A\in O(3)$ . Indeed at the identity $A = I$ I know that a basis of tangent vectors is given by the antisymmetric matrices with one non-zero number in the upper triangular part and that then the map is something like $X \mapsto (0, s, t)$ and arguably two parameters are enough to span the tangent space of $S^2$ . I fail to see how this is true for tangent vectors $X$ at an arbitrary point $A$ with the vector being given by $$ X = \left.\frac{\mathrm{d}}{\mathrm{d}t}\right|_{t=0} \gamma(t)$$ where $\gamma: \mathbb{R} \rightarrow O(3)$ with $\gamma(0) = A$ .","Denoting the components of the matrix as , show that is a submersion. (The map is well defined since for it is true that .) From what I understand to show that the map is a submersion, I have to show that the differential map is onto for every . Now if I were given a tangent vector then from what I understand the map simply is , where denote the components of . However, I fail to see that this is surjective at every point . Indeed at the identity I know that a basis of tangent vectors is given by the antisymmetric matrices with one non-zero number in the upper triangular part and that then the map is something like and arguably two parameters are enough to span the tangent space of . I fail to see how this is true for tangent vectors at an arbitrary point with the vector being given by where with .","3\times3 A \in O(3) a_{ij}  F: O(3) \rightarrow S^2, a_{ij} \mapsto a_{1j}  A \in O(3) a_{11}^2 + a_{12}^2 + a_{13}^2 = 1  dF: T_AO(3) \rightarrow T_{F(A)}S^2  A \in O(3) X\in T_AO(3) dF: x_{ij} \mapsto x_{1j} x_{ij} X A\in O(3) A = I X \mapsto (0, s, t) S^2 X A  X = \left.\frac{\mathrm{d}}{\mathrm{d}t}\right|_{t=0} \gamma(t) \gamma: \mathbb{R} \rightarrow O(3) \gamma(0) = A",['differential-geometry']
89,Smooth extension of a smooth map on an non-empty open subset of a manifold to the whole manifold.,Smooth extension of a smooth map on an non-empty open subset of a manifold to the whole manifold.,,"Proposition : Suppose $M$ is a smooth manifold and $\emptyset\neq U\subset M$ is open and $f:U\rightarrow \mathbb{R}$ is a smooth function. Then $f$ does not necessarily extend smoothly to M. Proof : (Counterexample). Let $M=\mathbb{S}^1$ and $U=\mathbb{S}^1\setminus\{p\}$ where $p$ is the 'north pole' (i.e. if we think of $\mathbb{S}^1$ as embedded in $\mathbb{R}^2$ then $p=(1,0)$ ). Define the map $f:U\rightarrow \mathbb{R}$ by stereographic projection, $f:(x_0,x_1)\in \mathbb{S}^1\setminus \{p\}\mapsto \frac{x_1}{1-x_0}\in \mathbb{R}$ which is well-defined and smooth since $x_0\neq 0$ on $U$ . If we attempt to extend this map to $\mathbb{S}^1$ then $p$ must map to $\infty$ by continuity. However $\infty\not\in \mathbb{R}$ , hence $\nexists$ a smooth extension of $f$ to all of $\mathbb{S}^1$ . Is this a valid counterexample or have I missed something obvious? If my proposition is wrong could you please provide a reference for the proof? Thanks!","Proposition : Suppose is a smooth manifold and is open and is a smooth function. Then does not necessarily extend smoothly to M. Proof : (Counterexample). Let and where is the 'north pole' (i.e. if we think of as embedded in then ). Define the map by stereographic projection, which is well-defined and smooth since on . If we attempt to extend this map to then must map to by continuity. However , hence a smooth extension of to all of . Is this a valid counterexample or have I missed something obvious? If my proposition is wrong could you please provide a reference for the proof? Thanks!","M \emptyset\neq U\subset M f:U\rightarrow \mathbb{R} f M=\mathbb{S}^1 U=\mathbb{S}^1\setminus\{p\} p \mathbb{S}^1 \mathbb{R}^2 p=(1,0) f:U\rightarrow \mathbb{R} f:(x_0,x_1)\in \mathbb{S}^1\setminus \{p\}\mapsto \frac{x_1}{1-x_0}\in \mathbb{R} x_0\neq 0 U \mathbb{S}^1 p \infty \infty\not\in \mathbb{R} \nexists f \mathbb{S}^1","['proof-verification', 'differential-geometry', 'smooth-manifolds']"
90,"Why Hessian is a (0,2) symmetry tensor?","Why Hessian is a (0,2) symmetry tensor?",,"On a Remiannian manifold M, the Hessian of a smooth function $f$ on M is defined to be: $$\operatorname{Hess}f=\frac{1}{2}\mathcal L_{\nabla f}(g)$$ where $\mathcal L$ stands for Lie derivative, $g$ is the metric of the manifold, and $\nabla f$ means the divergence of the function. It is said that Hessian is a symmetry tensor, but I am not sure why it's symmetric.","On a Remiannian manifold M, the Hessian of a smooth function on M is defined to be: where stands for Lie derivative, is the metric of the manifold, and means the divergence of the function. It is said that Hessian is a symmetry tensor, but I am not sure why it's symmetric.",f \operatorname{Hess}f=\frac{1}{2}\mathcal L_{\nabla f}(g) \mathcal L g \nabla f,['differential-geometry']
91,Proof of a linear algebra lemma for Cohn-Vossen's theorem,Proof of a linear algebra lemma for Cohn-Vossen's theorem,,"For the proof of Cohn-Vossen's rigidity theorem I need to prove the next lemma (can be found in Montiel-Ros's Curves and Surfaces page 218): If $\Phi$ and $\Psi$ are two definite self-adjoint endomorphisms of a Euclidean vector   plane and $det \Phi = det \Psi$ . Then, $det (\Phi + \Psi) \leq 0$ and that equality occurs if and only if $\Phi = - \Psi$ . The proof says the following: If $det(\Phi +\Psi) > 0$ , the endomorphism $\Phi+\Psi$ would be definite, say, positive definite. Now, we take $\{ e_1, e_2 \}$ a basis of the plane diagonalizing $\Phi$ , one has $$ \langle \Phi(e_i), e_i \rangle + \langle \Psi(e_i), e_i \rangle > 0, \;\;\;\; i = 1,2.$$ Consequently, $$ det \Phi = \langle \Phi(e_1), e_1 \rangle \langle \Phi(e_2), e_2 \rangle \stackrel{(1)}{>} \langle \Psi(e_1), e_1 \rangle \langle \Psi(e_2), e_2 \rangle \geq \langle \Psi(e_1), e_1 \rangle \langle \Psi(e_2), e_2 \rangle - \langle \Psi(e_1), e_2 \rangle^2 \stackrel{(2)}{=} det \Psi $$ which gives a contradiction to our hypothesis. Therefore, $det( \Phi + \Psi ) \leq 0$ . Here, I don't understand inequality (1) and equality (2). Moreover, the lemma says the following: In the above inequality, equality occurs if and only if $\Phi = -  \Psi$ . The proof says the following: Following the reasoning above, if equality holds, there wouldbe at least a non-null vector in the kernel of $\Phi + \Psi$ . Let $\{u_1, u_2 \}$ be a basis diagonalizing $\Phi + \Psi$ , that is, such that $$ \Phi(u_1) + \Psi(u_1) = 0 \;\;\;\; and \;\;\;\; \Phi(u_2) + \Psi(u_2) = \lambda u_2, \;\;\; \lambda \in \mathbb{R}. $$ From the first equality we deduce that $$ \langle \Phi(u_1), u_1 \rangle = - \langle \Psi(u_1), u_1 \rangle \;\;\;\; and \;\;\;\; \langle \Phi(u_1), u_2 \rangle = - \langle \Psi(u_1), u_2 \rangle, $$ which together with the facts that $det \Phi = det \Psi$ and that $\Phi$ and $\Psi$ are definite, gives the equality $$ \langle \Phi(u_2), u_2 \rangle \stackrel{(3)}{=} - \langle \Psi(u_2), u_2 \rangle, $$ implying $\lambda = 0$ . Thus, in this case, $\Phi = - \Psi$ . Of this latest part I don't understand the equality (3). Could you show me why these equations hold?","For the proof of Cohn-Vossen's rigidity theorem I need to prove the next lemma (can be found in Montiel-Ros's Curves and Surfaces page 218): If and are two definite self-adjoint endomorphisms of a Euclidean vector   plane and . Then, and that equality occurs if and only if . The proof says the following: If , the endomorphism would be definite, say, positive definite. Now, we take a basis of the plane diagonalizing , one has Consequently, which gives a contradiction to our hypothesis. Therefore, . Here, I don't understand inequality (1) and equality (2). Moreover, the lemma says the following: In the above inequality, equality occurs if and only if . The proof says the following: Following the reasoning above, if equality holds, there wouldbe at least a non-null vector in the kernel of . Let be a basis diagonalizing , that is, such that From the first equality we deduce that which together with the facts that and that and are definite, gives the equality implying . Thus, in this case, . Of this latest part I don't understand the equality (3). Could you show me why these equations hold?","\Phi \Psi det \Phi = det \Psi det (\Phi + \Psi) \leq 0 \Phi = - \Psi det(\Phi +\Psi) > 0 \Phi+\Psi \{ e_1, e_2 \} \Phi  \langle \Phi(e_i), e_i \rangle + \langle \Psi(e_i), e_i \rangle > 0, \;\;\;\; i = 1,2.  det \Phi = \langle \Phi(e_1), e_1 \rangle \langle \Phi(e_2), e_2 \rangle \stackrel{(1)}{>} \langle \Psi(e_1), e_1 \rangle \langle \Psi(e_2), e_2 \rangle \geq \langle \Psi(e_1), e_1 \rangle \langle \Psi(e_2), e_2 \rangle - \langle \Psi(e_1), e_2 \rangle^2 \stackrel{(2)}{=} det \Psi  det( \Phi + \Psi ) \leq 0 \Phi = -
 \Psi \Phi + \Psi \{u_1, u_2 \} \Phi + \Psi  \Phi(u_1) + \Psi(u_1) = 0 \;\;\;\; and \;\;\;\; \Phi(u_2) + \Psi(u_2) = \lambda u_2, \;\;\; \lambda \in \mathbb{R}.   \langle \Phi(u_1), u_1 \rangle = - \langle \Psi(u_1), u_1 \rangle \;\;\;\; and \;\;\;\; \langle \Phi(u_1), u_2 \rangle = - \langle \Psi(u_1), u_2 \rangle,  det \Phi = det \Psi \Phi \Psi  \langle \Phi(u_2), u_2 \rangle \stackrel{(3)}{=} - \langle \Psi(u_2), u_2 \rangle,  \lambda = 0 \Phi = - \Psi","['linear-algebra', 'differential-geometry', 'proof-explanation', 'determinant', 'self-adjoint-operators']"
92,Topology and smooth structure on tangent bundle,Topology and smooth structure on tangent bundle,,"My lecture notes on differential geometry read the following (without proof): For $M$ a manifold, let $TM = \bigcup_{p \in M} T_p M$ be the (disjoint) union of all its tangent spaces. Then, there exists a unique topology and smooth structure on $TM$ making it into a smooth manifold such that any section $X:M \rightarrow TM$ of the canonical projection map is smooth if and only if for all smooth functions $f$ on $M$, the function $Xf$ is smooth. I am not quite sure as to how to approach this (I am talking about the uniqueness part, the usual topology and smooth structure evidently imply the desired equivalence). I found a related post without an answer here: Why is the manifold structure on the tangent bundle unique? It seems that in this post, OP also assumes the projection map to be continuous, whereas my lecture notes do not. Any help would be appreciated.","My lecture notes on differential geometry read the following (without proof): For $M$ a manifold, let $TM = \bigcup_{p \in M} T_p M$ be the (disjoint) union of all its tangent spaces. Then, there exists a unique topology and smooth structure on $TM$ making it into a smooth manifold such that any section $X:M \rightarrow TM$ of the canonical projection map is smooth if and only if for all smooth functions $f$ on $M$, the function $Xf$ is smooth. I am not quite sure as to how to approach this (I am talking about the uniqueness part, the usual topology and smooth structure evidently imply the desired equivalence). I found a related post without an answer here: Why is the manifold structure on the tangent bundle unique? It seems that in this post, OP also assumes the projection map to be continuous, whereas my lecture notes do not. Any help would be appreciated.",,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'tangent-bundle']"
93,Characterisation of the Minkowski metric,Characterisation of the Minkowski metric,,"Suppose a manifold is homeomorphic to $\mathbb R^4$, and you've shown that it is equipped with a flat metric of signature $(n-1,1)$. To what extent can I conclude that my space is Minkowski space? My intuition tells me that there exists something like a linear change of coordinates so that my metric is literally diag$(-1,1,1,1)$. If this is indeed the case, how do I formalise this? I cannot conclude that my metric is the Minkowski metric up to a change in basis, since its eigenvalues need not be in $\{-1,1\}$. Essentially I'm after a characterisation of Minkowski space that doesn't require me to say ""the metric is diag$(-1,1,1,1)$"", because I'm working in a more abstract setting and I'd prefer not to compute anything with coordinates.","Suppose a manifold is homeomorphic to $\mathbb R^4$, and you've shown that it is equipped with a flat metric of signature $(n-1,1)$. To what extent can I conclude that my space is Minkowski space? My intuition tells me that there exists something like a linear change of coordinates so that my metric is literally diag$(-1,1,1,1)$. If this is indeed the case, how do I formalise this? I cannot conclude that my metric is the Minkowski metric up to a change in basis, since its eigenvalues need not be in $\{-1,1\}$. Essentially I'm after a characterisation of Minkowski space that doesn't require me to say ""the metric is diag$(-1,1,1,1)$"", because I'm working in a more abstract setting and I'd prefer not to compute anything with coordinates.",,"['differential-geometry', 'riemannian-geometry', 'mathematical-physics', 'curvature', 'general-relativity']"
94,Diffusion maps & preserving the local geometry,Diffusion maps & preserving the local geometry,,"I am reading about diffusion maps . It is stated that here : "" the diffusion map preserves the local geometry of the graph. "" We know that this embedding is based on the Markov matrix . Now, I am curious to know: How much does precise this statement? And what can we say about the global geometry rather than local geometry? Are there other approaches that can preserves the geometry of a graph? I am new in this area and your detailed answers will be appreciated.","I am reading about diffusion maps . It is stated that here : "" the diffusion map preserves the local geometry of the graph. "" We know that this embedding is based on the Markov matrix . Now, I am curious to know: How much does precise this statement? And what can we say about the global geometry rather than local geometry? Are there other approaches that can preserves the geometry of a graph? I am new in this area and your detailed answers will be appreciated.",,"['differential-geometry', 'graph-theory', 'euclidean-geometry', 'riemannian-geometry']"
95,Differential geometry vs Riemannian geometry [closed],Differential geometry vs Riemannian geometry [closed],,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I'd like to know the relation between differential geometry and Riemannian geometry. exactly what makes them different? Is one an special case of another? exactly how?,Closed . This question needs details or clarity . It is not currently accepting answers. Want to improve this question? Add details and clarify the problem by editing this post . Closed 6 years ago . Improve this question I'd like to know the relation between differential geometry and Riemannian geometry. exactly what makes them different? Is one an special case of another? exactly how?,,"['differential-geometry', 'riemannian-geometry']"
96,Lemma 2.3 - Lectures on Mean Curvature Flow,Lemma 2.3 - Lectures on Mean Curvature Flow,,"I'm self-study Mean Curvature Flow and I'm stuck on item $(ii)$ of the lemma below My doubts are referent the equalities marked with a red rectangle Why $|A|^2 = \langle h_{ij}, h_{ij} \rangle$ ? I know that $|A|^2 = g^{ij}g^{kl}h_{ik}h_{jl}$, but I can't see how $|A|^2 = \langle h_{ij}, h_{ij} \rangle$ What is the definition of $\nabla A$? The closer I got to the definition was on the proof of Lemma 2.2 of this article by Huisken . I think the second equality marked is just by definition, but I would like to know what is the definition of $\nabla A$. Why $\text{tr} (A^3) = \langle h_{ij}, h_{ik} h^k_j \rangle$? Thanks in advance! $\textbf{EDIT:}$ I finally understood why $\text{tr} (A^3) = \langle h_{ij}, h_{ik} h^k_j \rangle$. I will post how to develop $\langle h_{ij}, h_{ik} h^k_j \rangle$ to arrive at this. By the definition of inner product of tensors (see this topic as well as the comments that I did in Lee's answer for the definition and for a motivation of it), $\langle h_{ij}, h_{ik} h^k_j \rangle = g^{ii} g^{jj} h_{ij} h_{ik} h^k_j = g^{ii} g^{jj} g^{lk} h_{ij} h_{ik} h_{lj}$ and, as pointed by Anthony on his answer, I can consider an orthonormal frame (it's just assume a local chart with normal coordinates), then $\langle h_{ij}, h_{ik} h^k_j \rangle = g^{ii} g^{jj} g^{lk} h_{ij} h_{ik} h_{lj} = h_{ij} h_{ik} h_{kj} = h_{ij} h_{jk} h_{ki} = \text{tr} (A^3)$.","I'm self-study Mean Curvature Flow and I'm stuck on item $(ii)$ of the lemma below My doubts are referent the equalities marked with a red rectangle Why $|A|^2 = \langle h_{ij}, h_{ij} \rangle$ ? I know that $|A|^2 = g^{ij}g^{kl}h_{ik}h_{jl}$, but I can't see how $|A|^2 = \langle h_{ij}, h_{ij} \rangle$ What is the definition of $\nabla A$? The closer I got to the definition was on the proof of Lemma 2.2 of this article by Huisken . I think the second equality marked is just by definition, but I would like to know what is the definition of $\nabla A$. Why $\text{tr} (A^3) = \langle h_{ij}, h_{ik} h^k_j \rangle$? Thanks in advance! $\textbf{EDIT:}$ I finally understood why $\text{tr} (A^3) = \langle h_{ij}, h_{ik} h^k_j \rangle$. I will post how to develop $\langle h_{ij}, h_{ik} h^k_j \rangle$ to arrive at this. By the definition of inner product of tensors (see this topic as well as the comments that I did in Lee's answer for the definition and for a motivation of it), $\langle h_{ij}, h_{ik} h^k_j \rangle = g^{ii} g^{jj} h_{ij} h_{ik} h^k_j = g^{ii} g^{jj} g^{lk} h_{ij} h_{ik} h_{lj}$ and, as pointed by Anthony on his answer, I can consider an orthonormal frame (it's just assume a local chart with normal coordinates), then $\langle h_{ij}, h_{ik} h^k_j \rangle = g^{ii} g^{jj} g^{lk} h_{ij} h_{ik} h_{lj} = h_{ij} h_{ik} h_{kj} = h_{ij} h_{jk} h_{ki} = \text{tr} (A^3)$.",,"['differential-geometry', 'riemannian-geometry', 'mean-curvature-flows']"
97,"Fourier transform, tangent and cotangent bundles","Fourier transform, tangent and cotangent bundles",,"I'm familiar with the notion of Fourier transform in the context of $\mathbb{R}^n$ and more generally, locally compact abelian groups. However recently I came across the Fourier transform acting as follows: $M$ is a compact manifold, $x \in M$ and $T_xM,T^*_xM$ are tangent and cotangent spaces at $x$. Also $E$ is a given vector bundle over $M$. Then the Fourier transform should act $\mathcal{F}_x:\Gamma^{\infty}(T_xM,T_xM \times E_x) \to \Gamma^{\infty}(T^*_xM,T_xM \times E_x)$ Any idea how such Fourier transform should be defined? Here $T_xM \times E_x$ should be viewed as a trivial vector bundle over $T_xM$ with fiber $E_x$. However I suspect that $\mathcal{F}_x$ should be defined somehow consistently when $x$ varies.","I'm familiar with the notion of Fourier transform in the context of $\mathbb{R}^n$ and more generally, locally compact abelian groups. However recently I came across the Fourier transform acting as follows: $M$ is a compact manifold, $x \in M$ and $T_xM,T^*_xM$ are tangent and cotangent spaces at $x$. Also $E$ is a given vector bundle over $M$. Then the Fourier transform should act $\mathcal{F}_x:\Gamma^{\infty}(T_xM,T_xM \times E_x) \to \Gamma^{\infty}(T^*_xM,T_xM \times E_x)$ Any idea how such Fourier transform should be defined? Here $T_xM \times E_x$ should be viewed as a trivial vector bundle over $T_xM$ with fiber $E_x$. However I suspect that $\mathcal{F}_x$ should be defined somehow consistently when $x$ varies.",,"['differential-geometry', 'fourier-analysis', 'fourier-transform', 'tangent-bundle']"
98,Regular surface and self-intersections,Regular surface and self-intersections,,"So the definition of a regular surface is the following: A topological subspace $S  \subset \mathbb{R^3}$ is a regular surface if $\forall p \in S$ there exist open sets $U \subset \mathbb{R^2}$ , $V \subset S, p \in V$ and a function $\phi:U \rightarrow \mathbb{R^3}$ with $\phi \in C^{\infty}(U, \mathbb{R^3})$ such that: $\phi:U \rightarrow V$ is a homeomorphism. $d\phi_q:\mathbb{R^2} \rightarrow \mathbb{R^3}$ is injective $\forall q \in U$ ( $d\phi_q$ is the differential of $\phi$ in q). Regular surfaces cannot have self-intersections. I guess this has to follow from the definition of regular surface given above, probably the condition of $\phi$ being an homeomorphism, but I can' t see exactly why.","So the definition of a regular surface is the following: A topological subspace is a regular surface if there exist open sets , and a function with such that: is a homeomorphism. is injective ( is the differential of in q). Regular surfaces cannot have self-intersections. I guess this has to follow from the definition of regular surface given above, probably the condition of being an homeomorphism, but I can' t see exactly why.","S  \subset \mathbb{R^3} \forall p \in S U \subset \mathbb{R^2} V \subset S, p \in V \phi:U \rightarrow \mathbb{R^3} \phi \in C^{\infty}(U, \mathbb{R^3}) \phi:U \rightarrow V d\phi_q:\mathbb{R^2} \rightarrow \mathbb{R^3} \forall q \in U d\phi_q \phi \phi","['differential-geometry', 'surfaces']"
99,Equivalence of tangential and normal stably almost complex structure,Equivalence of tangential and normal stably almost complex structure,,"Let $M$ be a smooth manifold. $M$ is said to be tangential stably almost complex if $TM \oplus \underline{\mathbb{R}}^k$ can be given a structure of a complex vector bundle, for some $k$. $M$ is said to be normal stably almost complex if $\nu \oplus \underline{\mathbb{R}}^k$ can be given a structure of a complex vector bundle, where $\nu$ is the normal bundle of some embedding of $M$ into $\mathbb{R}^N$, for some $k$. It is stated in a few places that tangential stably almost complex structures and normal stably almost complex structures are equivalent, see for example: http://www.map.mpim-bonn.mpg.de/Complex_bordism#Stably_complex_structures . However I cannot figure out why. In the above link, it is stated that this follows from $TM \oplus \nu = \underline{\mathbb{R}}^N$. So suppose I have a tangential stably almost complex structure, then $(TM \oplus \underline{\mathbb{R}}^k) \oplus \nu = \underline{\mathbb{R}}^{N+k}$, the first summand on the left has an almost complex structure and I can see that the right hand side can be given an almost complex structure as well. But then how does one proceed next? It seems to me that one needs some method to extend an almost complex structure on $\mathbb{R}^m$ (the first summand) to $\mathbb{R}^{N+k}$ on each fibre, so that we can restrict it back to $\nu$. But since the space of almost complex structures $O(2n)/U(n)$ has nontrivial topology, whether this can be done seems to depend on the topology of $M$. So I guess I might be on the wrong path here. Any help is appreciated!","Let $M$ be a smooth manifold. $M$ is said to be tangential stably almost complex if $TM \oplus \underline{\mathbb{R}}^k$ can be given a structure of a complex vector bundle, for some $k$. $M$ is said to be normal stably almost complex if $\nu \oplus \underline{\mathbb{R}}^k$ can be given a structure of a complex vector bundle, where $\nu$ is the normal bundle of some embedding of $M$ into $\mathbb{R}^N$, for some $k$. It is stated in a few places that tangential stably almost complex structures and normal stably almost complex structures are equivalent, see for example: http://www.map.mpim-bonn.mpg.de/Complex_bordism#Stably_complex_structures . However I cannot figure out why. In the above link, it is stated that this follows from $TM \oplus \nu = \underline{\mathbb{R}}^N$. So suppose I have a tangential stably almost complex structure, then $(TM \oplus \underline{\mathbb{R}}^k) \oplus \nu = \underline{\mathbb{R}}^{N+k}$, the first summand on the left has an almost complex structure and I can see that the right hand side can be given an almost complex structure as well. But then how does one proceed next? It seems to me that one needs some method to extend an almost complex structure on $\mathbb{R}^m$ (the first summand) to $\mathbb{R}^{N+k}$ on each fibre, so that we can restrict it back to $\nu$. But since the space of almost complex structures $O(2n)/U(n)$ has nontrivial topology, whether this can be done seems to depend on the topology of $M$. So I guess I might be on the wrong path here. Any help is appreciated!",,"['differential-geometry', 'differential-topology', 'almost-complex']"
