,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Probability of 3 Heads in 10 Coin Flips,Probability of 3 Heads in 10 Coin Flips,,What’s the probability of getting 3 heads and 7 tails if one flips a fair coin 10 times. I just can’t figure out how to model this correctly.,What’s the probability of getting 3 heads and 7 tails if one flips a fair coin 10 times. I just can’t figure out how to model this correctly.,,['probability']
1,Expected value of maximum of two random variables from uniform distribution,Expected value of maximum of two random variables from uniform distribution,,"If I have two variables $X$ and $Y$ which randomly take on values uniformly from the range $[a,b]$ (all values equally probable), what is the expected value for $\max(X,Y)$?","If I have two variables $X$ and $Y$ which randomly take on values uniformly from the range $[a,b]$ (all values equally probable), what is the expected value for $\max(X,Y)$?",,['probability']
2,100 prisoners and a lightbulb,100 prisoners and a lightbulb,,"100 prisoners are imprisoned in solitary cells. Each cell is windowless and soundproof. There's a central living room with one light bulb; the bulb is initially off. No prisoner can see the light bulb from his or her own cell. Each day, the warden picks a prisoner equally at random, and that prisoner visits the central living room; at the end of the day the prisoner is returned to his cell. While in the living room, the prisoner can toggle the bulb if he or she wishes. Also, the prisoner has the option of asserting the claim that all 100 prisoners have been to the living room. If this assertion is false (that is, some prisoners still haven't been to the living room), all 100 prisoners will be shot for their stupidity. However, if it is indeed true, all prisoners are set free and inducted into MENSA, since the world can always use more smart people. Thus, the assertion should only be made if the prisoner is 100% certain of its validity. Before this whole procedure begins, the prisoners are allowed to get together in the courtyard to discuss a plan. What is the optimal plan they can agree on, so that eventually, someone will make a correct assertion? http://www.ocf.berkeley.edu/~wwu/riddles/hard.shtml I was wondering does anyone know the solution for the 4,000 days solution. Also, anyone got any ideas on how to solve this? Just wanted to know if anyone got any ideas how to solve this. http://www.siam.org/ is offering prize money for a proof of a optimal solution for it. I suppose to make it clear the people want a plan that would mean on average it would take least amount of time to free the prisoner. The point is the average run time is as low as possible.","100 prisoners are imprisoned in solitary cells. Each cell is windowless and soundproof. There's a central living room with one light bulb; the bulb is initially off. No prisoner can see the light bulb from his or her own cell. Each day, the warden picks a prisoner equally at random, and that prisoner visits the central living room; at the end of the day the prisoner is returned to his cell. While in the living room, the prisoner can toggle the bulb if he or she wishes. Also, the prisoner has the option of asserting the claim that all 100 prisoners have been to the living room. If this assertion is false (that is, some prisoners still haven't been to the living room), all 100 prisoners will be shot for their stupidity. However, if it is indeed true, all prisoners are set free and inducted into MENSA, since the world can always use more smart people. Thus, the assertion should only be made if the prisoner is 100% certain of its validity. Before this whole procedure begins, the prisoners are allowed to get together in the courtyard to discuss a plan. What is the optimal plan they can agree on, so that eventually, someone will make a correct assertion? http://www.ocf.berkeley.edu/~wwu/riddles/hard.shtml I was wondering does anyone know the solution for the 4,000 days solution. Also, anyone got any ideas on how to solve this? Just wanted to know if anyone got any ideas how to solve this. http://www.siam.org/ is offering prize money for a proof of a optimal solution for it. I suppose to make it clear the people want a plan that would mean on average it would take least amount of time to free the prisoner. The point is the average run time is as low as possible.",,"['probability', 'expected-value', 'puzzle']"
3,Expected outcome for repeated dice rolls with dice fixing,Expected outcome for repeated dice rolls with dice fixing,,"Here is another dice roll question. The rules You start with $n$ dice, and roll all of them. You select one or more dice and fix them, i.e. their value will not change any more. You re-roll the other dice. Repeat that until all dice are fixed (after at most $n$ rounds). The final score is the sum of the values of all $n$ dice. Assume you want to maximize the expected score. The questions What is the expected score? Can the re-rolling strategy be easily phrased? Are there situations (possibly for slightly larger $n$ ) where you would re-roll a 6? Thoughts It seems to be counter-intuitive to re-roll a 6, but it would give you one extra roll for all other dice, so maybe it is worth it? Or is there an argument disproving this hypothesis, even without answering the first two questions? Further reading I wrote a narrative about this question and the answers on my blog post.","Here is another dice roll question. The rules You start with dice, and roll all of them. You select one or more dice and fix them, i.e. their value will not change any more. You re-roll the other dice. Repeat that until all dice are fixed (after at most rounds). The final score is the sum of the values of all dice. Assume you want to maximize the expected score. The questions What is the expected score? Can the re-rolling strategy be easily phrased? Are there situations (possibly for slightly larger ) where you would re-roll a 6? Thoughts It seems to be counter-intuitive to re-roll a 6, but it would give you one extra roll for all other dice, so maybe it is worth it? Or is there an argument disproving this hypothesis, even without answering the first two questions? Further reading I wrote a narrative about this question and the answers on my blog post.",n n n n,"['probability', 'dice', 'dynamic-programming']"
4,Does a randomly chosen series diverge?,Does a randomly chosen series diverge?,,"Pick a point at random in the interval $[0,1]$, call it $P_1$. Pick another point at random in the interval $[0,P_1]$, call it $P_2$. Pick another point at random in the interval $[0,P2]$, call it $P_3$. Etc... Let $S = P_1+P_2+P_3+\cdots$ What is the probability that $S$ is divergent? Any thoughts? P.S. random, in this particular case, means equidistributed. I.e. $P(a<P_1<b)=b-a$.","Pick a point at random in the interval $[0,1]$, call it $P_1$. Pick another point at random in the interval $[0,P_1]$, call it $P_2$. Pick another point at random in the interval $[0,P2]$, call it $P_3$. Etc... Let $S = P_1+P_2+P_3+\cdots$ What is the probability that $S$ is divergent? Any thoughts? P.S. random, in this particular case, means equidistributed. I.e. $P(a<P_1<b)=b-a$.",,"['probability', 'sequences-and-series', 'divergent-series']"
5,Why does this not seem to be random?,Why does this not seem to be random?,,"I was running a procedure to be like one of those games were people try to guess a number between 1 and 100 where there are 100 people guessing.I then averaged how many different guesses there are. from random import randint  def averager(times):     tests = list()     for _ in range(times):         l = [randint(0,100) for _ in range(100)]         tests.append(len(set(l)))     return sum(tests)/len(tests)  print(averager(100)) For some reason, the number of different guesses averages out to 63.6 Why is this?Is it due to a flaw in the python random library? In a scenario where people were guessing a number between 1 and 10 The first person has a 100% chance to guess a previously unguessed number The second person has a 90% chance to guess a previously unguessed number The third person has a 80% chance to guess a previously unguessed number and so on... The average chance of guessing a new number(by my reasoning) is 55%.  But the data doesn't reflect this.","I was running a procedure to be like one of those games were people try to guess a number between 1 and 100 where there are 100 people guessing.I then averaged how many different guesses there are. from random import randint  def averager(times):     tests = list()     for _ in range(times):         l = [randint(0,100) for _ in range(100)]         tests.append(len(set(l)))     return sum(tests)/len(tests)  print(averager(100)) For some reason, the number of different guesses averages out to 63.6 Why is this?Is it due to a flaw in the python random library? In a scenario where people were guessing a number between 1 and 10 The first person has a 100% chance to guess a previously unguessed number The second person has a 90% chance to guess a previously unguessed number The third person has a 80% chance to guess a previously unguessed number and so on... The average chance of guessing a new number(by my reasoning) is 55%.  But the data doesn't reflect this.",,"['probability', 'statistics', 'random']"
6,Probability brain teaser with infinite loop,Probability brain teaser with infinite loop,,"I found this problem and I've been stuck on how to solve it. A miner is trapped in a mine containing 3 doors. The first door leads to a tunnel that will take him to safety after 3 hours of travel. The second door leads to a tunnel that will return him to the mine after 5 hours of travel. The third door leads to a tunnel that will return him to the mine after 7 hours. If we assume that the miner is at all times equally likely to choose any one of doors, what is the expected length of time until he reaches safety? The fact that the miner could be stuck in an infinite loop has confused me. Any help is greatly appreciated.","I found this problem and I've been stuck on how to solve it. A miner is trapped in a mine containing 3 doors. The first door leads to a tunnel that will take him to safety after 3 hours of travel. The second door leads to a tunnel that will return him to the mine after 5 hours of travel. The third door leads to a tunnel that will return him to the mine after 7 hours. If we assume that the miner is at all times equally likely to choose any one of doors, what is the expected length of time until he reaches safety? The fact that the miner could be stuck in an infinite loop has confused me. Any help is greatly appreciated.",,"['probability', 'markov-chains', 'puzzle']"
7,Expectation of the maximum of i.i.d. geometric random variables,Expectation of the maximum of i.i.d. geometric random variables,,"Given $n$ independent geometric random variables $X_n$, each with probability parameter $p$ (and thus expectation $E\left(X_n\right) = \frac{1}{p}$), what is $$E_n = E\left(\max_{i \in 1 .. n}X_n\right)$$ If we instead look at a continuous-time analogue, e.g. exponential random variables $Y_n$ with rate parameter $\lambda$, this is simple: $$E\left(\max_{i \in 1 .. n}Y_n\right) = \sum_{i=1}^n\frac{1}{i\lambda}$$ (I think this is right... that's the time for the first plus the time for the second plus ... plus the time for the last.) However, I can't find something similarly nice for the discrete-time case. What I have done is to construct a Markov chain modelling the number of the $X_n$ that haven't yet ""hit"". (i.e. at each time interval, perform a binomial trial on the number of $X_n$ remaining to see which ""hit"", and then move to the number that didn't ""hit"".) This gives $$E_n = 1 + \sum_{i=0}^n \left(\begin{matrix}n\\i\end{matrix}\right)p^{n-i}(1-p)^iE_i$$ which gives the correct answer, but is a nightmare of recursion to calculate. I'm hoping for something in a shorter form.","Given $n$ independent geometric random variables $X_n$, each with probability parameter $p$ (and thus expectation $E\left(X_n\right) = \frac{1}{p}$), what is $$E_n = E\left(\max_{i \in 1 .. n}X_n\right)$$ If we instead look at a continuous-time analogue, e.g. exponential random variables $Y_n$ with rate parameter $\lambda$, this is simple: $$E\left(\max_{i \in 1 .. n}Y_n\right) = \sum_{i=1}^n\frac{1}{i\lambda}$$ (I think this is right... that's the time for the first plus the time for the second plus ... plus the time for the last.) However, I can't find something similarly nice for the discrete-time case. What I have done is to construct a Markov chain modelling the number of the $X_n$ that haven't yet ""hit"". (i.e. at each time interval, perform a binomial trial on the number of $X_n$ remaining to see which ""hit"", and then move to the number that didn't ""hit"".) This gives $$E_n = 1 + \sum_{i=0}^n \left(\begin{matrix}n\\i\end{matrix}\right)p^{n-i}(1-p)^iE_i$$ which gives the correct answer, but is a nightmare of recursion to calculate. I'm hoping for something in a shorter form.",,"['probability', 'probability-distributions']"
8,probability density of the maximum of samples from a uniform distribution,probability density of the maximum of samples from a uniform distribution,,"Suppose $$X_1, X_2, \dots, X_n\sim Unif(0, \theta), iid$$ and suppose $$\hat\theta = \max\{X_1, X_2, \dots, X_n\}$$ How would I find the probability density of $\hat\theta$ ?",Suppose and suppose How would I find the probability density of ?,"X_1, X_2, \dots, X_n\sim Unif(0, \theta), iid \hat\theta = \max\{X_1, X_2, \dots, X_n\} \hat\theta","['probability', 'probability-theory', 'probability-distributions', 'maxima-minima']"
9,±1-random walk from 5 until 20 or broke [closed],±1-random walk from 5 until 20 or broke [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question You play a game where a fair coin is flipped. You win 1 if it shows heads and lose 1 if it shows tails. You start with 5 and decide to play until you either have 20 or go broke. What is the probability that you will go broke?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 7 years ago . Improve this question You play a game where a fair coin is flipped. You win 1 if it shows heads and lose 1 if it shows tails. You start with 5 and decide to play until you either have 20 or go broke. What is the probability that you will go broke?",,"['probability', 'random-walk', 'gambling']"
10,"Mean and variance of Squared Gaussian: $Y=X^2$ where: $X\sim\mathcal{N}(0,\sigma^2)$?",Mean and variance of Squared Gaussian:  where: ?,"Y=X^2 X\sim\mathcal{N}(0,\sigma^2)","What is the mean and variance of Squared Gaussian: $Y=X^2$ where: $X\sim\mathcal{N}(0,\sigma^2)$? It is interesting to note that Gaussian R.V here is zero-mean and non-central Chi-square Distribution doesn't work. Thanks.","What is the mean and variance of Squared Gaussian: $Y=X^2$ where: $X\sim\mathcal{N}(0,\sigma^2)$? It is interesting to note that Gaussian R.V here is zero-mean and non-central Chi-square Distribution doesn't work. Thanks.",,"['probability', 'random-variables']"
11,Is there a clever solution to this elementary probability/combinatorics problem?,Is there a clever solution to this elementary probability/combinatorics problem?,,"My friend was asked the following problem in an interview a while back, and it has a nice answer, leading me to believe that there is an equally nice solution. Suppose that there are 42 bags, labeled $0$ though $41$.  Bag $i$ contains $i$ red balls and $42-(i+1)$ blue balls.  Suppose that you pick a bag, then pull out three balls without replacement.  What is the probability that all 3 balls are the same color? The problem can be solved easily by using some basic identities with binomial coefficients, and the answer is $1/2$.  Moreover, if $42$ is replaced by $n$, the answer does not change, assuming $n>3$.  However, this computational approach obscures any hidden structure there might be.  Ideally, I would like a simple and direct proof that the probability of getting RRR is the same as the probability of getting RBB. So, is there a nice solution to the problem, one that could be explained fully to someone without the use of paper?  Or is there no good way to explain this beyond computational coincidence?","My friend was asked the following problem in an interview a while back, and it has a nice answer, leading me to believe that there is an equally nice solution. Suppose that there are 42 bags, labeled $0$ though $41$.  Bag $i$ contains $i$ red balls and $42-(i+1)$ blue balls.  Suppose that you pick a bag, then pull out three balls without replacement.  What is the probability that all 3 balls are the same color? The problem can be solved easily by using some basic identities with binomial coefficients, and the answer is $1/2$.  Moreover, if $42$ is replaced by $n$, the answer does not change, assuming $n>3$.  However, this computational approach obscures any hidden structure there might be.  Ideally, I would like a simple and direct proof that the probability of getting RRR is the same as the probability of getting RBB. So, is there a nice solution to the problem, one that could be explained fully to someone without the use of paper?  Or is there no good way to explain this beyond computational coincidence?",,"['probability', 'combinatorics']"
12,How to compute the sum of random variables of geometric distribution,How to compute the sum of random variables of geometric distribution,,"Let $X_{i}$, $i=1,2,\dots, n$, be independent random variables of geometric distribution, that is, $P(X_{i}=m)=p(1-p)^{m-1}$. How to compute the PDF of their sum $\sum_{i=1}^{n}X_{i}$? I know intuitively it's a negative binomial distribution $$P\left(\sum_{i=1}^{n}X_{i}=m\right)=\binom{m-1}{n-1}p^{n}(1-p)^{m-n}$$ but how to do this deduction?","Let $X_{i}$, $i=1,2,\dots, n$, be independent random variables of geometric distribution, that is, $P(X_{i}=m)=p(1-p)^{m-1}$. How to compute the PDF of their sum $\sum_{i=1}^{n}X_{i}$? I know intuitively it's a negative binomial distribution $$P\left(\sum_{i=1}^{n}X_{i}=m\right)=\binom{m-1}{n-1}p^{n}(1-p)^{m-n}$$ but how to do this deduction?",,"['probability', 'probability-distributions', 'random-variables']"
13,Best strategy to pick a lock which opens if at least two of its three decimal digit wheels are dialed correctly?,Best strategy to pick a lock which opens if at least two of its three decimal digit wheels are dialed correctly?,,"Suppose you want to open a lock with three digits code, the lock is a little special because it can be opened if you have two digits guessed right. To clarify, if the correct three digit is 123 , then guess 124 or 153 can open the box. The lock looks like this: Question is: what is best strategy to open the box? The best strategy is a strategy which requires least attempts at average. You should also find the average. The strategies I came up with are: First strategy: hold first digit, and constantly change second and third while keep them equal when changing them. For example, I will try: 111 , 122 ... 199 , 211 , 222 ,..., 299 ,.... Second strategy: hold second and third equal, and constantly change first one. For example: 111 , 211 ,..., 911 , 122 , 222 ,... I don't know if these two are best, nor do I know if they are equivalent efficient. Edit Here is a program to calculate the average number of trails for a strategy from an ardent comment. To use it, replace the line '// Input your list here' with your test list and press run.","Suppose you want to open a lock with three digits code, the lock is a little special because it can be opened if you have two digits guessed right. To clarify, if the correct three digit is 123 , then guess 124 or 153 can open the box. The lock looks like this: Question is: what is best strategy to open the box? The best strategy is a strategy which requires least attempts at average. You should also find the average. The strategies I came up with are: First strategy: hold first digit, and constantly change second and third while keep them equal when changing them. For example, I will try: 111 , 122 ... 199 , 211 , 222 ,..., 299 ,.... Second strategy: hold second and third equal, and constantly change first one. For example: 111 , 211 ,..., 911 , 122 , 222 ,... I don't know if these two are best, nor do I know if they are equivalent efficient. Edit Here is a program to calculate the average number of trails for a strategy from an ardent comment. To use it, replace the line '// Input your list here' with your test list and press run.",,"['probability', 'combinatorics']"
14,What is the Kolmogorov Extension Theorem good for?,What is the Kolmogorov Extension Theorem good for?,,"The Kolmogorov Extension Theorem says, essentially, that one can get a process on $\mathbb{R}^T$ for $T$ being an arbitrary , non-empty index set, by specifying all finite dimensional distributions in a ""consistent"" way. My favorite formulation of the consistency condition can be found here . Now for the case in which $T$ is countable, this has already be shown by P. J. Daniell (see for example here or here ). So I would like to know what the extension to uncountable index sets brings. Events like ""sample paths are continuous"" are not in the $\sigma$ -algebra. In a rather critical paper on Kolmogrov's work on the foundation of probability, Shafer and Vovk write about the extension to uncountable index sets: ""This greater generality is merely formal, in two senses: it involves no additional mathematical complications and it has no practical use."" My impression is that this sentiment is not universally shared, so I would like to know: How is the Kolmogorov Extension Theorem applied in the construction of stochastic processes in continuous time? Especially, how are the constructed probabilities transferred to richer measurable spaces?","The Kolmogorov Extension Theorem says, essentially, that one can get a process on for being an arbitrary , non-empty index set, by specifying all finite dimensional distributions in a ""consistent"" way. My favorite formulation of the consistency condition can be found here . Now for the case in which is countable, this has already be shown by P. J. Daniell (see for example here or here ). So I would like to know what the extension to uncountable index sets brings. Events like ""sample paths are continuous"" are not in the -algebra. In a rather critical paper on Kolmogrov's work on the foundation of probability, Shafer and Vovk write about the extension to uncountable index sets: ""This greater generality is merely formal, in two senses: it involves no additional mathematical complications and it has no practical use."" My impression is that this sentiment is not universally shared, so I would like to know: How is the Kolmogorov Extension Theorem applied in the construction of stochastic processes in continuous time? Especially, how are the constructed probabilities transferred to richer measurable spaces?",\mathbb{R}^T T T \sigma,"['probability', 'measure-theory', 'stochastic-processes']"
15,What is the probability of a coin landing tails 7 times in a row in a series of 150 coin flips?,What is the probability of a coin landing tails 7 times in a row in a series of 150 coin flips?,,"If you were to flip a coin 150 times, what is the probability that it would land tails 7 times in a row?  How about 6 times in a row?  Is there some forumula that can calculate this probability?","If you were to flip a coin 150 times, what is the probability that it would land tails 7 times in a row?  How about 6 times in a row?  Is there some forumula that can calculate this probability?",,['probability']
16,Sum of independent Gamma distributions is a Gamma distribution,Sum of independent Gamma distributions is a Gamma distribution,,"If $X\sim \Gamma(a_1,b)$ and $Y \sim \Gamma(a_2,b)$ , I need to prove $X+Y\sim\Gamma(a_1+a_2,b)$ if $X$ and $Y$ are independent. I am trying to apply formula for independence integral and just trying to multiply the gamma function but stuck ?","If and , I need to prove if and are independent. I am trying to apply formula for independence integral and just trying to multiply the gamma function but stuck ?","X\sim \Gamma(a_1,b) Y \sim \Gamma(a_2,b) X+Y\sim\Gamma(a_1+a_2,b) X Y","['probability', 'probability-distributions', 'gamma-distribution']"
17,Combination with repetitions.,Combination with repetitions.,,The formula for computing a k-combination with repetitions from n elements is: $$\binom{n + k - 1}{k} = \binom{n + k - 1}{n - 1}$$ I would like if someone can give me a simple basic proof that a beginner can understand easily.,The formula for computing a k-combination with repetitions from n elements is: $$\binom{n + k - 1}{k} = \binom{n + k - 1}{n - 1}$$ I would like if someone can give me a simple basic proof that a beginner can understand easily.,,['probability']
18,Method of generating random numbers that sum to 100 - is this truly random?,Method of generating random numbers that sum to 100 - is this truly random?,,"I am writing a computer program that involves generating 4 random numbers, a, b, c, and d, the sum of which should equal 100. Here is the method I first came up with to achieve that goal, in pseudocode: Generate a random number out of 100. (Let's say it generates 16). Assign this value as the first number, so a = 16. Take away a from 100, which gives 84.  Generate a random number out of 84. (Let's say it generates 21). Assign this value as the second number, so b = 21. Take away b from 84, which gives 63.  Generate a random number out of 63. (Let's say it generates 40). Assign this value as the third number, so c = 40. Take away c from 63, which gives 23.  Assign the remainder as the fourth number, so d = 23. However, for some reason I have a funny feeling about this method. Am I truly generating four random numbers that sum to 100 here? Would this be equivalent to me generating four random numbers out of 100 over and over again, and only accepting when the sum is 100? Or am I creating some sort of bias by picking a random number out of 100, and then a random number out of the remainder, and so on? Thanks.","I am writing a computer program that involves generating 4 random numbers, a, b, c, and d, the sum of which should equal 100. Here is the method I first came up with to achieve that goal, in pseudocode: Generate a random number out of 100. (Let's say it generates 16). Assign this value as the first number, so a = 16. Take away a from 100, which gives 84.  Generate a random number out of 84. (Let's say it generates 21). Assign this value as the second number, so b = 21. Take away b from 84, which gives 63.  Generate a random number out of 63. (Let's say it generates 40). Assign this value as the third number, so c = 40. Take away c from 63, which gives 23.  Assign the remainder as the fourth number, so d = 23. However, for some reason I have a funny feeling about this method. Am I truly generating four random numbers that sum to 100 here? Would this be equivalent to me generating four random numbers out of 100 over and over again, and only accepting when the sum is 100? Or am I creating some sort of bias by picking a random number out of 100, and then a random number out of the remainder, and so on? Thanks.",,"['probability', 'random']"
19,Scaling the normal distribution?,Scaling the normal distribution?,,"I might just be slow (or too drunk), but I'm seeing a conflict in the equations for adding  two normals and scaling a normal. According to page 2 of this , if $X_1 \sim N(\mu_1,\sigma_1^2)$ and $X_2 \sim N(\mu_2,\sigma_2^2)$, then $X_1 + X_2 \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$, and for some $c \in \mathbb{R}$, $cX_1 = N(c\mu_1, c^2\sigma_1^2)$. Then for $X \sim N(\mu,\sigma^2)$, we have $X + X = N(\mu + \mu,\sigma^2 + \sigma^2) = N(2\mu,2\sigma^2)$, but also $X + X = 2X = N(2\mu,2^2\sigma^2) = N(2\mu,4\sigma^2)$ ? Ie, the variances disagree. edit: Oh, am I mistaken in saying that $2X = X + X$? Is the former ""rolling"" $X$ just once and doubling it while the latter ""rolls"" twice and adds them?","I might just be slow (or too drunk), but I'm seeing a conflict in the equations for adding  two normals and scaling a normal. According to page 2 of this , if $X_1 \sim N(\mu_1,\sigma_1^2)$ and $X_2 \sim N(\mu_2,\sigma_2^2)$, then $X_1 + X_2 \sim N(\mu_1 + \mu_2, \sigma_1^2 + \sigma_2^2)$, and for some $c \in \mathbb{R}$, $cX_1 = N(c\mu_1, c^2\sigma_1^2)$. Then for $X \sim N(\mu,\sigma^2)$, we have $X + X = N(\mu + \mu,\sigma^2 + \sigma^2) = N(2\mu,2\sigma^2)$, but also $X + X = 2X = N(2\mu,2^2\sigma^2) = N(2\mu,4\sigma^2)$ ? Ie, the variances disagree. edit: Oh, am I mistaken in saying that $2X = X + X$? Is the former ""rolling"" $X$ just once and doubling it while the latter ""rolls"" twice and adds them?",,"['probability', 'statistics', 'normal-distribution']"
20,What does multiplication mean in probability theory?,What does multiplication mean in probability theory?,,"For independent events, the probability of both occurring is the product of the probabilities of the individual events: $Pr(A\; \text{and}\;B) = Pr(A \cap B)= Pr(A)\times Pr(B)$. Example: if you flip a coin twice, the probability of heads both times is: $1/2 \times 1/2 =1/4.$ I don't understand why we multiply. I mean, I've memorized the operation by now, that we multiply for independent events; but why , I don't get it. If I have $4$ bags with $3$ balls, then I have $3\times 4=12$ balls: This I understand. Multiplication is (the act of) scaling . But what does scaling have to do with independent events? I don't understand why we scale one event by the other to calculate $Pr(A \cap B)$, if A, B are independent. Explain it to me as if I'm really dense, because I am. Thanks.","For independent events, the probability of both occurring is the product of the probabilities of the individual events: $Pr(A\; \text{and}\;B) = Pr(A \cap B)= Pr(A)\times Pr(B)$. Example: if you flip a coin twice, the probability of heads both times is: $1/2 \times 1/2 =1/4.$ I don't understand why we multiply. I mean, I've memorized the operation by now, that we multiply for independent events; but why , I don't get it. If I have $4$ bags with $3$ balls, then I have $3\times 4=12$ balls: This I understand. Multiplication is (the act of) scaling . But what does scaling have to do with independent events? I don't understand why we scale one event by the other to calculate $Pr(A \cap B)$, if A, B are independent. Explain it to me as if I'm really dense, because I am. Thanks.",,"['probability', 'statistics', 'arithmetic']"
21,"If I have a $0.00048\%$ chance of dying every second, how to numerically calculate the chance I have of dying in a day?","If I have a  chance of dying every second, how to numerically calculate the chance I have of dying in a day?",0.00048\%,"Hypothetically, if I have a 0.00048% chance of dying when I blink, and I blink once a second, what chance do I have of dying in a single day? I tried $1-0.0000048^{86400}$ but no calculator I could find would support this.  How would I work this out manually?","Hypothetically, if I have a 0.00048% chance of dying when I blink, and I blink once a second, what chance do I have of dying in a single day? I tried $1-0.0000048^{86400}$ but no calculator I could find would support this.  How would I work this out manually?",,['probability']
22,Prove: $\binom{n}{k}^{-1}=(n+1)\int_{0}^{1}x^{k}(1-x)^{n-k}dx$ for $0 \leq k \leq n$,Prove:  for,\binom{n}{k}^{-1}=(n+1)\int_{0}^{1}x^{k}(1-x)^{n-k}dx 0 \leq k \leq n,"I would like your help with proving that for every  $0 \leq k \leq n$, $$\binom{n}{k}^{-1}=(n+1)\int_{0}^{1}x^{k}(1-x)^{n-k}dx  . $$ I tried to integration by parts and to get a pattern or to use the binomial formula somehow, but it didn't go well. Thanks a lot!","I would like your help with proving that for every  $0 \leq k \leq n$, $$\binom{n}{k}^{-1}=(n+1)\int_{0}^{1}x^{k}(1-x)^{n-k}dx  . $$ I tried to integration by parts and to get a pattern or to use the binomial formula somehow, but it didn't go well. Thanks a lot!",,"['probability', 'special-functions', 'binomial-coefficients', 'definite-integrals']"
23,Reducing download time using prime numbers,Reducing download time using prime numbers,,"An issue has cropped up recently in programming with which I could greatly benefit from the expertise of proper mathematicians. The real-world problem is that apps often need to download huge chunks of data from a server, like videos and images, and users might face the issue of not having great connectivity (say 3G) or they might be on an expensive data plan. Instead of downloading a whole file though, I've been trying to prove that it's possible to instead just download a kind of 'reflection' of it and then using the powerful computing of the smartphone accurately reconstruct the file locally using probability. The way it works is like this: A file is broken into its bits (1,0,0,1 etc) and laid out in a predetermined pattern in the shape of a cube. Like going from front-to-back, left-to-right and then down a row, until complete. The pattern doesn't matter, as long as it can be reversed afterwards. To reduce file size, instead of requesting the whole cube of data (the equivalent of downloading the whole file), we only download 3 x 2D sides instead. These sides I'm calling the reflection for want of a better term. They have the contents of the cube mapped onto them. The reflection is then used to reconstruct the 3D cube of data using probability - kind of like asking a computer to do a huge three-dimensional Sudoku. Creating the reflection and reconstructing the data from it are computationally heavy, and as much as computers love doing math, I'd like to lighten their load a bit. The way I'm picturing is like a 10x10 transparent Rubik's cube. On three of the sides, light is shone through each row. Each cell it travels through has a predetermined value and is either on or off (either binary 1 or 0). If it's on, it magnifies the light by its value. If it is off, it does nothing. All we see is the final amount of light exiting each row, after travelling through the cube from the other side. Using the three sides, the computer needs to determine what values (either 1 or 0) are inside the cube. At the moment I'm using normal prime numbers as the cell values to reduce computing time, but I'm curious to know if there is another type of prime (or another type of number completely) that might be more effective. I'm looking for a series of values that has the lowest possible combination of components from within that series. Here is a rough diagram: It might help to imagine that light shines in at the green arrows, and exits with some value at the red arrows. This happens for each row, in each of the three directions. We're left with only three 2D sides of numbers, which are used to reconstruct what's inside the cube. If you look where the 14 exits on the left, it can have two possible combinations, (3 + 11 and 2 + 5 + 7). If for arguments sake we were to assume it were 3 and 11 (coloured green), then we could say at the coordinate where 3 and 11 exist, there are active cells (magnifying the light by their value). In terms of data, we would say this is on (binary 1). In practice we can rarely say for certain (for 2 and 3 we could) what an inside value has based on its reflection on the surface, so a probability for each is assigned to that coordinate or cell. Some numbers will never be reflected on the surface, like 1, 4 or 6, since they can't be composed of only primes. The same happens in the vertical direction, where the output is 30, which has multiple possibilities of which two correspond to the possibility shown in the horizontal direction with an exit of 14, coloured blue and pink (since they hit the 23, the same as 3 in the horizontal direction). This probability is also added to that coordinate and we repeat in the front-to-back direction, doing the same a final time. After this is done for each cell in the whole cube, we have a set of three probabilities that a cell is either on or off. That is then used as the starting point to see if we can complete the cube. If it doesn't 'unlock' we try a different combination of probabilities and so forth until we have solved the 3D Sudoku. The final step of the method is once the cube is solved, the binary information is pulled out of it and arranged in the reverse pattern to how it was laid out on the server. This can then be cut up (say for multiple images) or used to create a video or something. You could cough in theory cough download something like Avatar 3D (280GB) in around 3 minutes on decent wifi. Solving it (nevermind building the pixel output) would take a while though, and this is where I'm curious about using an alternative to prime numbers. You might have guessed that my maths ability goes off a very steep cliff beyond routine programming stuff. There are three areas of concern / drawbacks to this method: it is rubbish at low levels of data transfer. A 10 x 10 x 10 cube for instance has a larger 'surface area' than volume. That's because while each cell can hold one bit (either 1 or 0), each surface cell needs to be a minimum of 8 bits (one character is one byte, or 8 bits). We can't even have 'nothing', since we need null to behave as a type of placeholder to keep the structure intact. This also accounts for why in the above diagram, a 1000x1000x1000-cell cube has its surface areas multiplied by 4 characters (the thousandth prime is 7919 - 4 characters) and the 10'000(cubed)-cell cube has its surface areas multiplied by 6 characters (10'000th prime is 104729, six characters). The aim is to keep total character length on the 2D side to a minimum. Using letters could work, as we could go from a-Z with 52 symbols, before paying double bubble for the next character (the equivalent to ""10""). There are 256 unique ASCII characters, so that's the upper limit there. the factorials are still too high using prime numbers. Is there a series of numbers that are both short in character length (to avoid the problem above) and have very few possible parents? I'm leaning towards some subset of primes, but lack the maths to know which - some sort of inverted Fibonacci? The fewest possible combinations, the faster the computer will solve the cube. I haven't tested yet if its possible to use a third, fourth or nth side to increase either the capacity of the cube or the accuracy of the reflection. Using a say octahedron (yellow below) instead of a cube might be better, just hurts the brain a little to picture how it might work. I'm guessing it would tend towards a sphere, but that's beyond my ability. EDIT: Thank you for your helpful input. Many answers have referred to the Pigeonhole principle and the issue of too many possible combinations. I should also correct that a 1000 x cube would require 7 digits not 4 as I stated above, since the sum of the first 1000 primes is 3682913. I should also emphasise the idea isn't to compress in the common sense of the word, as in taking pixels out of an image, but more like sending blueprints on how to build something, and relying only on the computation and knowledge at the receiving end to fill in the blanks. There is more than one correct answer, and will mark correct the one with the most votes. Many thanks for the detailed and patient explanations.","An issue has cropped up recently in programming with which I could greatly benefit from the expertise of proper mathematicians. The real-world problem is that apps often need to download huge chunks of data from a server, like videos and images, and users might face the issue of not having great connectivity (say 3G) or they might be on an expensive data plan. Instead of downloading a whole file though, I've been trying to prove that it's possible to instead just download a kind of 'reflection' of it and then using the powerful computing of the smartphone accurately reconstruct the file locally using probability. The way it works is like this: A file is broken into its bits (1,0,0,1 etc) and laid out in a predetermined pattern in the shape of a cube. Like going from front-to-back, left-to-right and then down a row, until complete. The pattern doesn't matter, as long as it can be reversed afterwards. To reduce file size, instead of requesting the whole cube of data (the equivalent of downloading the whole file), we only download 3 x 2D sides instead. These sides I'm calling the reflection for want of a better term. They have the contents of the cube mapped onto them. The reflection is then used to reconstruct the 3D cube of data using probability - kind of like asking a computer to do a huge three-dimensional Sudoku. Creating the reflection and reconstructing the data from it are computationally heavy, and as much as computers love doing math, I'd like to lighten their load a bit. The way I'm picturing is like a 10x10 transparent Rubik's cube. On three of the sides, light is shone through each row. Each cell it travels through has a predetermined value and is either on or off (either binary 1 or 0). If it's on, it magnifies the light by its value. If it is off, it does nothing. All we see is the final amount of light exiting each row, after travelling through the cube from the other side. Using the three sides, the computer needs to determine what values (either 1 or 0) are inside the cube. At the moment I'm using normal prime numbers as the cell values to reduce computing time, but I'm curious to know if there is another type of prime (or another type of number completely) that might be more effective. I'm looking for a series of values that has the lowest possible combination of components from within that series. Here is a rough diagram: It might help to imagine that light shines in at the green arrows, and exits with some value at the red arrows. This happens for each row, in each of the three directions. We're left with only three 2D sides of numbers, which are used to reconstruct what's inside the cube. If you look where the 14 exits on the left, it can have two possible combinations, (3 + 11 and 2 + 5 + 7). If for arguments sake we were to assume it were 3 and 11 (coloured green), then we could say at the coordinate where 3 and 11 exist, there are active cells (magnifying the light by their value). In terms of data, we would say this is on (binary 1). In practice we can rarely say for certain (for 2 and 3 we could) what an inside value has based on its reflection on the surface, so a probability for each is assigned to that coordinate or cell. Some numbers will never be reflected on the surface, like 1, 4 or 6, since they can't be composed of only primes. The same happens in the vertical direction, where the output is 30, which has multiple possibilities of which two correspond to the possibility shown in the horizontal direction with an exit of 14, coloured blue and pink (since they hit the 23, the same as 3 in the horizontal direction). This probability is also added to that coordinate and we repeat in the front-to-back direction, doing the same a final time. After this is done for each cell in the whole cube, we have a set of three probabilities that a cell is either on or off. That is then used as the starting point to see if we can complete the cube. If it doesn't 'unlock' we try a different combination of probabilities and so forth until we have solved the 3D Sudoku. The final step of the method is once the cube is solved, the binary information is pulled out of it and arranged in the reverse pattern to how it was laid out on the server. This can then be cut up (say for multiple images) or used to create a video or something. You could cough in theory cough download something like Avatar 3D (280GB) in around 3 minutes on decent wifi. Solving it (nevermind building the pixel output) would take a while though, and this is where I'm curious about using an alternative to prime numbers. You might have guessed that my maths ability goes off a very steep cliff beyond routine programming stuff. There are three areas of concern / drawbacks to this method: it is rubbish at low levels of data transfer. A 10 x 10 x 10 cube for instance has a larger 'surface area' than volume. That's because while each cell can hold one bit (either 1 or 0), each surface cell needs to be a minimum of 8 bits (one character is one byte, or 8 bits). We can't even have 'nothing', since we need null to behave as a type of placeholder to keep the structure intact. This also accounts for why in the above diagram, a 1000x1000x1000-cell cube has its surface areas multiplied by 4 characters (the thousandth prime is 7919 - 4 characters) and the 10'000(cubed)-cell cube has its surface areas multiplied by 6 characters (10'000th prime is 104729, six characters). The aim is to keep total character length on the 2D side to a minimum. Using letters could work, as we could go from a-Z with 52 symbols, before paying double bubble for the next character (the equivalent to ""10""). There are 256 unique ASCII characters, so that's the upper limit there. the factorials are still too high using prime numbers. Is there a series of numbers that are both short in character length (to avoid the problem above) and have very few possible parents? I'm leaning towards some subset of primes, but lack the maths to know which - some sort of inverted Fibonacci? The fewest possible combinations, the faster the computer will solve the cube. I haven't tested yet if its possible to use a third, fourth or nth side to increase either the capacity of the cube or the accuracy of the reflection. Using a say octahedron (yellow below) instead of a cube might be better, just hurts the brain a little to picture how it might work. I'm guessing it would tend towards a sphere, but that's beyond my ability. EDIT: Thank you for your helpful input. Many answers have referred to the Pigeonhole principle and the issue of too many possible combinations. I should also correct that a 1000 x cube would require 7 digits not 4 as I stated above, since the sum of the first 1000 primes is 3682913. I should also emphasise the idea isn't to compress in the common sense of the word, as in taking pixels out of an image, but more like sending blueprints on how to build something, and relying only on the computation and knowledge at the receiving end to fill in the blanks. There is more than one correct answer, and will mark correct the one with the most votes. Many thanks for the detailed and patient explanations.",,"['probability', 'prime-numbers', 'factorial']"
24,What is the expected number of times a dice has to be rolled to get two consecutive sixes? [closed],What is the expected number of times a dice has to be rolled to get two consecutive sixes? [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Basically, on average, how many times one should roll to expect two consecutive sixes?","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Basically, on average, how many times one should roll to expect two consecutive sixes?",,"['probability', 'statistics', 'dice']"
25,Looking for (overkill) usages of indicator functions,Looking for (overkill) usages of indicator functions,,"I am going to give a presentation about the indicator functions , and I am looking for some interesting examples to include. The examples can be even an overkill solution since I am mainly interested in demonstrating the creative ways of using it. I would be grateful if you share your examples. The diversity of answers is appreciated. To give you an idea, here are my examples. Most of my examples are in probability and combinatorics so examples from other fields would be even better. Calculating the expected value of a random variable using linearity of expectations. Most famously the number of fixed points in a random permutation. Showing how $|A \Delta B| = |A|+|B|-2|A \cap B|$ and $(A-B)^2 = A^2+B^2-2AB$ are related. An overkill proof for $\sum \deg(v) = 2|E|$ .","I am going to give a presentation about the indicator functions , and I am looking for some interesting examples to include. The examples can be even an overkill solution since I am mainly interested in demonstrating the creative ways of using it. I would be grateful if you share your examples. The diversity of answers is appreciated. To give you an idea, here are my examples. Most of my examples are in probability and combinatorics so examples from other fields would be even better. Calculating the expected value of a random variable using linearity of expectations. Most famously the number of fixed points in a random permutation. Showing how and are related. An overkill proof for .",|A \Delta B| = |A|+|B|-2|A \cap B| (A-B)^2 = A^2+B^2-2AB \sum \deg(v) = 2|E|,"['probability', 'combinatorics', 'soft-question', 'big-list', 'characteristic-functions']"
26,Probability that a quadratic polynomial with random coefficients has real roots,Probability that a quadratic polynomial with random coefficients has real roots,,"The following is a homework question for which I am asking guidance. Let $A$, $B$, $C$ be independent random variables uniformly distributed between $(0,1)$. What is the probability that the polynomial $Ax^2 + Bx + C$ has real roots? That means I need $P(B^2 -4AC \geq 0$). I've tried calling $X=B^2 -4AC$ and finding $1-F_X(0)$, where $F$ is the cumulative distribution function. I have two problems with this approach. First, I'm having trouble determining the product of two uniform random variables. We haven't been taught anything like this in class, and couldn't find anything like it on Sheldon Ross' Introduction to Probability Models. Second, this strategy just seems wrong , because it involves so many steps and subjects we haven't seen in class. Even if I calculate the product of $A$ and $C$, I'll still have to square $B$, multiply $AC$ by four and then subtract those results. It's too much for a homework question. I'm hoping there might be an easier way.","The following is a homework question for which I am asking guidance. Let $A$, $B$, $C$ be independent random variables uniformly distributed between $(0,1)$. What is the probability that the polynomial $Ax^2 + Bx + C$ has real roots? That means I need $P(B^2 -4AC \geq 0$). I've tried calling $X=B^2 -4AC$ and finding $1-F_X(0)$, where $F$ is the cumulative distribution function. I have two problems with this approach. First, I'm having trouble determining the product of two uniform random variables. We haven't been taught anything like this in class, and couldn't find anything like it on Sheldon Ross' Introduction to Probability Models. Second, this strategy just seems wrong , because it involves so many steps and subjects we haven't seen in class. Even if I calculate the product of $A$ and $C$, I'll still have to square $B$, multiply $AC$ by four and then subtract those results. It's too much for a homework question. I'm hoping there might be an easier way.",,"['probability', 'polynomials', 'quadratics']"
27,"Making 400k random choices from 400k samples seems to always end up with 63% distinct choices, why?","Making 400k random choices from 400k samples seems to always end up with 63% distinct choices, why?",,"I have a very simple simulation program, the sequence is: Create an array of 400k elements Use a PRNG to pick an index, and mark the element (repeat 400k times) Count number of marked elements. An element may be picked more than once, but counted as only one ""marked element"". The PRNG is properly seeded. No matter how many times I run the simulation, I always end up getting around 63% (252k) marked elements. What is the math behind this? Or was there a fault in my PRNG?","I have a very simple simulation program, the sequence is: Create an array of 400k elements Use a PRNG to pick an index, and mark the element (repeat 400k times) Count number of marked elements. An element may be picked more than once, but counted as only one ""marked element"". The PRNG is properly seeded. No matter how many times I run the simulation, I always end up getting around 63% (252k) marked elements. What is the math behind this? Or was there a fault in my PRNG?",,"['probability', 'random', 'balls-in-bins']"
28,"Calculate the expected value of $Y=e^X$ where $X \sim N(\mu, \sigma^2)$",Calculate the expected value of  where,"Y=e^X X \sim N(\mu, \sigma^2)","I got a problem of calculating $E[e^X]$, where X follows a normal distribution $N(\mu, \sigma^2)$ of mean $\mu$ and standard deviation $\sigma$. I still got no clue how to solve it. Assume $Y=e^X$. Trying to calculate this value directly by substitution $f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\, e^{\frac{-(x-\mu)^2}{2\sigma^2}}$ then find $g(y)$ of $Y$ is a nightmare (and I don't know how to calculate this integral to be honest). Another way is to find the inverse function. Assume $Y=\phi(X)$, if $\phi$ is differentiable, monotonic, and have inverse function $X=\psi(Y)$ then $g(y)$ (PDF of random variable $Y$) is as follows: $g(y)=f[\psi(y)]|\psi'(y)|$. I think we don't need to find PDF of $Y$ explicitly to find $E[Y]$. This seems to be a classic problem. Anyone can help?","I got a problem of calculating $E[e^X]$, where X follows a normal distribution $N(\mu, \sigma^2)$ of mean $\mu$ and standard deviation $\sigma$. I still got no clue how to solve it. Assume $Y=e^X$. Trying to calculate this value directly by substitution $f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\, e^{\frac{-(x-\mu)^2}{2\sigma^2}}$ then find $g(y)$ of $Y$ is a nightmare (and I don't know how to calculate this integral to be honest). Another way is to find the inverse function. Assume $Y=\phi(X)$, if $\phi$ is differentiable, monotonic, and have inverse function $X=\psi(Y)$ then $g(y)$ (PDF of random variable $Y$) is as follows: $g(y)=f[\psi(y)]|\psi'(y)|$. I think we don't need to find PDF of $Y$ explicitly to find $E[Y]$. This seems to be a classic problem. Anyone can help?",,"['probability', 'normal-distribution']"
29,In need of tips/suggestions when to add or multiply probabilities,In need of tips/suggestions when to add or multiply probabilities,,"I am having trouble deciding when to add or when to multiply probabilities as in the following example. I know that by constructing Probability tree diagrams we could multiply along branches and add vertically. However I could definitely use more suggestions/tips that  might help me decide when to multiply and when to add probabilities. A jar contains $4$ black and $3$ White balls. If you reach into the jar and pick two balls simultaneously , what is the probability that one is black and the other is white ? This is how I am solving the above : Pr(Black from the total 7 balls)=$\frac{4}{7}$ Pr(White from the remaining 6 balls after choosing a Black ball) $= \frac{3}{6}$ So Ans = $\frac{4}{7} \times \frac{3}{6} = \frac{2}{7}$","I am having trouble deciding when to add or when to multiply probabilities as in the following example. I know that by constructing Probability tree diagrams we could multiply along branches and add vertically. However I could definitely use more suggestions/tips that  might help me decide when to multiply and when to add probabilities. A jar contains $4$ black and $3$ White balls. If you reach into the jar and pick two balls simultaneously , what is the probability that one is black and the other is white ? This is how I am solving the above : Pr(Black from the total 7 balls)=$\frac{4}{7}$ Pr(White from the remaining 6 balls after choosing a Black ball) $= \frac{3}{6}$ So Ans = $\frac{4}{7} \times \frac{3}{6} = \frac{2}{7}$",,['probability']
30,"If $(a,b,c)$ are the sides of a triangle, what is the probability that $ac>b^2$?","If  are the sides of a triangle, what is the probability that ?","(a,b,c) ac>b^2","Let $a \le b \le c$ be the sides of a triangle inscribed inside a fixed circle such that the vertices of the triangle are distributed uniformly on the circumference. Question 1 : Is it true that the probability that $ac > b^2$ is $\displaystyle \frac{1}{5}$ . I ran a simulation by generating $1.75 \times 10^9$ triangle and counting the number of times $ac > b^2$ . The experimental data seems to suggest that probability converges to about $0.2$ . Note : For any triangle with $a \le b \le c$ , the triangle inequality implies $b < a+c < 3b$ . Now the condition $ac > b^2$ implies that $2b < a+c < 3b$ ; here the lower bound follows from AM-GM inequality. Hence all triangles for which $b < a+c < 2b$ are ruled out. For our problem, the condition $2b < a+c < 3b$ is necessary but not sufficient. Update : Changed the title in light of the comments and answer that relaxing the condition $a\le b \le c$ is easier to handle Related question: If $(a,b,c)$ are the sides of a triangle and $x \ge 1$ , what is the probability that $a+b > cx$ ?","Let be the sides of a triangle inscribed inside a fixed circle such that the vertices of the triangle are distributed uniformly on the circumference. Question 1 : Is it true that the probability that is . I ran a simulation by generating triangle and counting the number of times . The experimental data seems to suggest that probability converges to about . Note : For any triangle with , the triangle inequality implies . Now the condition implies that ; here the lower bound follows from AM-GM inequality. Hence all triangles for which are ruled out. For our problem, the condition is necessary but not sufficient. Update : Changed the title in light of the comments and answer that relaxing the condition is easier to handle Related question: If are the sides of a triangle and , what is the probability that ?","a \le b \le c ac > b^2 \displaystyle \frac{1}{5} 1.75 \times 10^9 ac > b^2 0.2 a \le b \le c b < a+c < 3b ac > b^2 2b < a+c < 3b b < a+c < 2b 2b < a+c < 3b a\le b \le c (a,b,c) x \ge 1 a+b > cx","['probability', 'geometry', 'inequality', 'triangles', 'geometric-probability']"
31,How to mentally flip a coin?,How to mentally flip a coin?,,"If you've ever played rock-paper-scissors, and you are reading this on math.stackexchange, you probably know that always playing $1$ of the $3$ choices at random (more precisely: uniformly at random and independently of previous choices) guarantees even chances of victory against any opponent. But ""playing at random"" is harder than it looks, particularly if you have no tools - from old-fashioned dice to tech accessing thermal noise. In fact, I've seen a little piece of code that marginally, but consistently over time, beats most humans at rock-paper-scissors simply by looking at biases in how they've been playing so far, and predicting future throws accordingly. For example, humans tend to to play long sequences of identical throws with the ""wrong"" frequency. I was wondering if anyone knows good ways to produce reasonably random bits without tools ; say, enough to compete with even or as-even-as possible odds against a computer trying to predict one's choices. I realize ""good"" and ""reasonably"" (and even ""tools"") is a bit fuzzy, but I'm sure folks will understand the spirit of the question... I don't want to simulate a Mersenne Twister in my head (though a pseudorandom generator with a reasonable balance of randomness and simplicity would definitely be a possibility), nor use the painful method a friend of mine suggested: pull a random hair from one's head, and check if it's white (for most people it's a biased toss, but as long as one's hair is salt-and-pepper one can trade hair for fairness in the toss ). Buried in the comments below, there's a link to a web page allowing you to test any such scheme !","If you've ever played rock-paper-scissors, and you are reading this on math.stackexchange, you probably know that always playing $1$ of the $3$ choices at random (more precisely: uniformly at random and independently of previous choices) guarantees even chances of victory against any opponent. But ""playing at random"" is harder than it looks, particularly if you have no tools - from old-fashioned dice to tech accessing thermal noise. In fact, I've seen a little piece of code that marginally, but consistently over time, beats most humans at rock-paper-scissors simply by looking at biases in how they've been playing so far, and predicting future throws accordingly. For example, humans tend to to play long sequences of identical throws with the ""wrong"" frequency. I was wondering if anyone knows good ways to produce reasonably random bits without tools ; say, enough to compete with even or as-even-as possible odds against a computer trying to predict one's choices. I realize ""good"" and ""reasonably"" (and even ""tools"") is a bit fuzzy, but I'm sure folks will understand the spirit of the question... I don't want to simulate a Mersenne Twister in my head (though a pseudorandom generator with a reasonable balance of randomness and simplicity would definitely be a possibility), nor use the painful method a friend of mine suggested: pull a random hair from one's head, and check if it's white (for most people it's a biased toss, but as long as one's hair is salt-and-pepper one can trade hair for fairness in the toss ). Buried in the comments below, there's a link to a web page allowing you to test any such scheme !",,"['probability', 'random', 'card-games']"
32,"Intuitively, why is the Gaussian the Fourier transform of itself?","Intuitively, why is the Gaussian the Fourier transform of itself?",,"It's a standard exercise to find the Fourier transform of the Gaussian $e^{-x^2}$ and show that it is equal to itself. Although it is computationally straightforward, this has always somewhat surprised me. My intuition for the Gaussian is as the integrand of normal distributions, and my intuition for Fourier transforms is as a means to extract frequencies from a function. They seem unrelated, save for their use of the exponential function. How should I understand this property of the Gaussian, or in general, eigenfunctions of the Fourier transform? The Hermite polynomials are eigenfunctions of the Fourier transform and play a central role in probability. Is this an instance of a deeper connection between probability and harmonic analysis?","It's a standard exercise to find the Fourier transform of the Gaussian $e^{-x^2}$ and show that it is equal to itself. Although it is computationally straightforward, this has always somewhat surprised me. My intuition for the Gaussian is as the integrand of normal distributions, and my intuition for Fourier transforms is as a means to extract frequencies from a function. They seem unrelated, save for their use of the exponential function. How should I understand this property of the Gaussian, or in general, eigenfunctions of the Fourier transform? The Hermite polynomials are eigenfunctions of the Fourier transform and play a central role in probability. Is this an instance of a deeper connection between probability and harmonic analysis?",,"['probability', 'fourier-analysis']"
33,How does a disease spread through a triangular network?,How does a disease spread through a triangular network?,,"Consider a population of nodes arranged in a triangular configuration as shown in the figure below, where each level $k$ has $k$ nodes. Each node, except the ones in the last level, is a parent node to two child nodes. Each node in levels $2$ and below has $1$ parent node if it is at the edge, and $2$ parent nodes otherwise. The single node in level $1$ is infected (red). With some probability $p_0$, it does not infect either of its child nodes in level $2$. With some probability $p_1$, it infects exactly one of its child nodes, with equal probability. With the remaining probability $p_2=1-p_0-p_1$, it infects both of its child nodes. Each infected node in level $2$ then acts in a similar manner on its two child nodes in level $3$, and so on down the levels. It makes no difference whether a node is inected by one or two parents nodes - it's still just infected. The figure below shows one possibility of how the disease may spread up to level $6$. The question is: what is the expected number of infected nodes at level $k$? Simulations suggest that this is (at least asymptotically) linear in $k$, i.e., $$ \mathbb{E}(\text{number of infected nodes in level } k) = \alpha k $$ where $\alpha = f(p_0, p_1,p_2)$. This question arises out of a practical scenario in some research I'm doing. Unfortunately, the mathematics involved is beyond my current knowledge, so I'm kindly asking for your help. Pointers to relevant references are also appreciated. I asked a different version of this question some time ago, which did not have the possibility of a node not infecting either of its child nodes. It now turns out that in the system I'm looking at, the probability of this happening is not negligble.","Consider a population of nodes arranged in a triangular configuration as shown in the figure below, where each level $k$ has $k$ nodes. Each node, except the ones in the last level, is a parent node to two child nodes. Each node in levels $2$ and below has $1$ parent node if it is at the edge, and $2$ parent nodes otherwise. The single node in level $1$ is infected (red). With some probability $p_0$, it does not infect either of its child nodes in level $2$. With some probability $p_1$, it infects exactly one of its child nodes, with equal probability. With the remaining probability $p_2=1-p_0-p_1$, it infects both of its child nodes. Each infected node in level $2$ then acts in a similar manner on its two child nodes in level $3$, and so on down the levels. It makes no difference whether a node is inected by one or two parents nodes - it's still just infected. The figure below shows one possibility of how the disease may spread up to level $6$. The question is: what is the expected number of infected nodes at level $k$? Simulations suggest that this is (at least asymptotically) linear in $k$, i.e., $$ \mathbb{E}(\text{number of infected nodes in level } k) = \alpha k $$ where $\alpha = f(p_0, p_1,p_2)$. This question arises out of a practical scenario in some research I'm doing. Unfortunately, the mathematics involved is beyond my current knowledge, so I'm kindly asking for your help. Pointers to relevant references are also appreciated. I asked a different version of this question some time ago, which did not have the possibility of a node not infecting either of its child nodes. It now turns out that in the system I'm looking at, the probability of this happening is not negligble.",,"['probability', 'combinatorics', 'statistics', 'reference-request', 'expectation']"
34,Monty Hall Problem with Five Doors,Monty Hall Problem with Five Doors,,"My math class went over the original Monty Hall problem a few days ago, then looked at a related question where the number of doors was increased to five. There was a struggle to figure out what the answer to the problem is, and after coming back to it a few more times we're still a bit unclear. In this extended problem, let's say you pick door A out of doors A, B, C, D and E. The host then opens one of the other doors to show it's empty and gives you the choice to stay or switch to one of the other remaining doors. a) If you always stay with the door you picked, what is the probability of winning? b) If you always switch to another door, what is the probability of winning? Note that the host will open only one door. All the extended Monty Hall problems I found online had the host open all but one, so they weren't really helpful with this particular problem my class is working on. I calculated that the chances are 1/4 regardless of whether you switch or not since the host opening only one empty door is not enough to truly affect the difference in win rates between staying and switching. Is that right? EDIT: Sorry about the confusion for me not being clear enough. The problem I bring is indeed ising the same basic principles as the original: the host will always open a door after you choose one to show it is empty, and then you are given the choice. The reason why I got to 1/4 is because I was looking at the situation by figuring out how many ways can you win/lose depending on where the prize is after the host opens an empty door as well as which door you switched to, which gave me 3/12 for every switch or 1/4 (or by putting it all together i got 12/48). We didn't get far enough into the lessons to learn more about calculating probability with conditions so I apologize if that was what led to me a false calculation. Thanks for the answers, everyone!","My math class went over the original Monty Hall problem a few days ago, then looked at a related question where the number of doors was increased to five. There was a struggle to figure out what the answer to the problem is, and after coming back to it a few more times we're still a bit unclear. In this extended problem, let's say you pick door A out of doors A, B, C, D and E. The host then opens one of the other doors to show it's empty and gives you the choice to stay or switch to one of the other remaining doors. a) If you always stay with the door you picked, what is the probability of winning? b) If you always switch to another door, what is the probability of winning? Note that the host will open only one door. All the extended Monty Hall problems I found online had the host open all but one, so they weren't really helpful with this particular problem my class is working on. I calculated that the chances are 1/4 regardless of whether you switch or not since the host opening only one empty door is not enough to truly affect the difference in win rates between staying and switching. Is that right? EDIT: Sorry about the confusion for me not being clear enough. The problem I bring is indeed ising the same basic principles as the original: the host will always open a door after you choose one to show it is empty, and then you are given the choice. The reason why I got to 1/4 is because I was looking at the situation by figuring out how many ways can you win/lose depending on where the prize is after the host opens an empty door as well as which door you switched to, which gave me 3/12 for every switch or 1/4 (or by putting it all together i got 12/48). We didn't get far enough into the lessons to learn more about calculating probability with conditions so I apologize if that was what led to me a false calculation. Thanks for the answers, everyone!",,"['probability', 'discrete-mathematics', 'monty-hall']"
35,Probability of being poisoned,Probability of being poisoned,,"You are playing a game in which you have $100$ jellybeans, $10$ of them are poisonous (You eat one, you die). Now you have to pick $10$ at random to eat. Question : What is the probability of dying? How I tried to solve it: Each jellybean has a $\frac{1}{10}$ chance of being poisonous. Since you need to take $10$ of them, I multiply it by $10$ which gave $1$ (Guaranteed death). How other people tried to solve it : Each jellybean is picked out separately. The first jellybean has a $\frac{10}{100}$ chance of being poisonous, the second -- $\frac{10}{99}$, the third -- $\frac{10}{98}$ and so on.. which gives a sum of roughly $\sim 1.04$ (More than guaranteed death!) Both these results make no sense since there are obviously multiple possibilities were you survive since there are $90$ jellybeans to pick out of. Can someone explain this to me?","You are playing a game in which you have $100$ jellybeans, $10$ of them are poisonous (You eat one, you die). Now you have to pick $10$ at random to eat. Question : What is the probability of dying? How I tried to solve it: Each jellybean has a $\frac{1}{10}$ chance of being poisonous. Since you need to take $10$ of them, I multiply it by $10$ which gave $1$ (Guaranteed death). How other people tried to solve it : Each jellybean is picked out separately. The first jellybean has a $\frac{10}{100}$ chance of being poisonous, the second -- $\frac{10}{99}$, the third -- $\frac{10}{98}$ and so on.. which gives a sum of roughly $\sim 1.04$ (More than guaranteed death!) Both these results make no sense since there are obviously multiple possibilities were you survive since there are $90$ jellybeans to pick out of. Can someone explain this to me?",,['probability']
36,Expected Value of Max of Uniform IID Variables,Expected Value of Max of Uniform IID Variables,,What is the expected value of the maximum of 500 IID random variables   with uniform distribution between 0 and 1? I'm not quite sure of the technique to go about solving something like this. Could anyone point me the right direction? Thanks,What is the expected value of the maximum of 500 IID random variables   with uniform distribution between 0 and 1? I'm not quite sure of the technique to go about solving something like this. Could anyone point me the right direction? Thanks,,"['probability', 'probability-distributions', 'uniform-distribution', 'order-statistics']"
37,Is Mega Millions Positive Expected Value?,Is Mega Millions Positive Expected Value?,,"Given the rapid rise of the Mega Millions jackpot in the US (now advertised at \$640 million and equivalent to a ""cash"" prize of about \$448 million), I was wondering if there was ever a point at which the lottery became positive expected value (EV), and, if so, what is that point or range? Also, a friend and I came up with two different ways of looking at the problem, and I'm curious if they are both valid. First, it is simple to calculate the expected value of the ""fixed"" prizes. The first five numbers are selected from a pool of 56, the final ""mega"" ball from a pool of 46. (Let us ignore taxes in all of our calculations... one can adjust later for one's own tax rate which will vary by state). The expected value of all these fixed prizes is \$0.183. So, then you are paying \$0.817 for the jackpot prize. My plan was then to calculate the expected number of winners of the jackpot (multiple winners split the prize) to get an expected jackpot amount and multiply by the probability of selecting the winning numbers (given by $\binom{56}{5} * 46 = 1 \text{ in } 175,711,536$). The number of tickets sold can be easily estimated since \$0.32 of each ticket is added to the prize, so: ( Current Cash Jackpot - Previous Cash Jackpot ) / 0.32 = Tickets Sold $(448 - 252) / 0.32 = 612.5$ million tickets sold (!!). (The cash prizes are lower than the advertised jackpot. Currently, they are about 70% of the advertised jackpot.) Obviously, one expects multiple winners, but I can't figure out how to get a precise estimate, and various web sources seem to be getting different numbers. Alternative methodology: My friend's methodology, which is far simpler, is to say 50% of this drawing's sales will be paid out in prizes (\$0.18 to fixed prizes and \$0.32 to the jackpot). Add to that the carried over jackpot amount (\$250 million cash prize from the unwon previous jackpot) that will also be paid out. So, your expected value is $\$250$ million / 612.5 million tickets sold = \$0.40 from the previous drawing + \$0.50 from this drawing = \$0.90 total expected value for each \$1 ticket purchased (before taxes). Is this a valid approach or is it missing something? It's far simpler than anything I found while searching the web for this. Added: After considering the answer below, this is why I don't think my friend's methodology can be correct: it neglects the probability that no one will win. For instance, if a $1$ ticket was sold, the expected value of that ticket would not be $250 million + 0.50 since one has to consider the probability of the jackpot not being paid out at all. So, additional question: what is this probability and how do we find it? (Obviously it is quite small when $612.5$ million tickets are sold and the odds of each one winning is $1:175.7$ million.) Would this allow us to salvage this methodology? So, is there a point that the lottery will be positive EV? And, what is the EV this week, and the methodology for calculating it?","Given the rapid rise of the Mega Millions jackpot in the US (now advertised at \$640 million and equivalent to a ""cash"" prize of about \$448 million), I was wondering if there was ever a point at which the lottery became positive expected value (EV), and, if so, what is that point or range? Also, a friend and I came up with two different ways of looking at the problem, and I'm curious if they are both valid. First, it is simple to calculate the expected value of the ""fixed"" prizes. The first five numbers are selected from a pool of 56, the final ""mega"" ball from a pool of 46. (Let us ignore taxes in all of our calculations... one can adjust later for one's own tax rate which will vary by state). The expected value of all these fixed prizes is \$0.183. So, then you are paying \$0.817 for the jackpot prize. My plan was then to calculate the expected number of winners of the jackpot (multiple winners split the prize) to get an expected jackpot amount and multiply by the probability of selecting the winning numbers (given by $\binom{56}{5} * 46 = 1 \text{ in } 175,711,536$). The number of tickets sold can be easily estimated since \$0.32 of each ticket is added to the prize, so: ( Current Cash Jackpot - Previous Cash Jackpot ) / 0.32 = Tickets Sold $(448 - 252) / 0.32 = 612.5$ million tickets sold (!!). (The cash prizes are lower than the advertised jackpot. Currently, they are about 70% of the advertised jackpot.) Obviously, one expects multiple winners, but I can't figure out how to get a precise estimate, and various web sources seem to be getting different numbers. Alternative methodology: My friend's methodology, which is far simpler, is to say 50% of this drawing's sales will be paid out in prizes (\$0.18 to fixed prizes and \$0.32 to the jackpot). Add to that the carried over jackpot amount (\$250 million cash prize from the unwon previous jackpot) that will also be paid out. So, your expected value is $\$250$ million / 612.5 million tickets sold = \$0.40 from the previous drawing + \$0.50 from this drawing = \$0.90 total expected value for each \$1 ticket purchased (before taxes). Is this a valid approach or is it missing something? It's far simpler than anything I found while searching the web for this. Added: After considering the answer below, this is why I don't think my friend's methodology can be correct: it neglects the probability that no one will win. For instance, if a $1$ ticket was sold, the expected value of that ticket would not be $250 million + 0.50 since one has to consider the probability of the jackpot not being paid out at all. So, additional question: what is this probability and how do we find it? (Obviously it is quite small when $612.5$ million tickets are sold and the odds of each one winning is $1:175.7$ million.) Would this allow us to salvage this methodology? So, is there a point that the lottery will be positive EV? And, what is the EV this week, and the methodology for calculating it?",,['probability']
38,Are primes randomly distributed?,Are primes randomly distributed?,,"There is a famous citation that says ""It is evident that the primes are randomly distributed but, unfortunately, we don't know what 'random' means."" R. C. Vaughan (February 1990) I have this very clear but rather broad question that might be answered by different opinions and view points. However, my question is really not targeting an intuitive or philosophical answer, and I beg you for view points with a strength of mathematical foundation. are primes randomly distributed? so then what is 'random' in this context? A posterior I A possible hint comes perhaps from the theory of complex dynamical systems. It can be difficult to tell from data whether a physical or other observed process is random or chaotic, because in practice no time series consists of pure 'signal.' There will always be some form of corrupting noise, even if it is present as round-off or truncation error. Thus any real time series, even if mostly deterministic, will contain some randomness. All methods for distinguishing deterministic and stochastic processes rely on the fact that a deterministic system always evolves in the same way from a given starting point. (ref 1 , 2 , 3 , and "" Distinguishing random from chaotic data "") - complying to latter, remind that every prime $p$ can be trivially identified by a sieving that applies prior primes $q<p$ so it is possible to determine that somehow the system evolves in the same way from a given starting point . Of course to take into account that time must be substituted by a walking index as well. A posterior II Thank you for all of many the comprehensive answers and discussions. This is a quite classic question on MSE and meanwhile we moved much forward. You are right that primes are not random as per above question. Indeed we could show that they are in their sequence some type of ""deterministic chaos"". We don't need the Riemann function for this purpose. The primes sequence is a so called ""ordered iterative sequence"". Meanwhile this has been further elaborated by this source: ""The Secret Harmony of Primes"" (ISBN 978-9176370001) http://a.co/iIHQqR8 Some of you correctly referred to sieving. It is crucial however that we regard sieving procedures as a subset of ""interference"" (incl. frequencies and amplitudes). We can iteratively apply interference rules in order to gain from the first prime 2, the next ordered sequence. This can be iterative continued in an ""ordered"" way and within exact boundaries of p-squares (for 100% certainty). Indeed, in order to construct an ordered sequence of primes you just need to begin with 2. The Riemann approach is charming but would raise difficulties since we don't have yet a proof of the hypothesis that connects the order of the non-trivial zeros with the primes. So if you apply Riemann, as some colleagues here suggest, we would need to say at any time in the begin of your argumentation something like ""provided the Riemann hypothesis would be true..."". Having in mind that the very unique rule that primes follow, is that in an interference scheme all odd prime frequencies dance on the base frequency of 2 (ordered iterative sequence), one may even give it a thought to something of a parallel in the Riemann transformed world, that all non-trivial zeros dance on 1/2. But latter remains not more than a tempting trivial speculation yet.","There is a famous citation that says ""It is evident that the primes are randomly distributed but, unfortunately, we don't know what 'random' means."" R. C. Vaughan (February 1990) I have this very clear but rather broad question that might be answered by different opinions and view points. However, my question is really not targeting an intuitive or philosophical answer, and I beg you for view points with a strength of mathematical foundation. are primes randomly distributed? so then what is 'random' in this context? A posterior I A possible hint comes perhaps from the theory of complex dynamical systems. It can be difficult to tell from data whether a physical or other observed process is random or chaotic, because in practice no time series consists of pure 'signal.' There will always be some form of corrupting noise, even if it is present as round-off or truncation error. Thus any real time series, even if mostly deterministic, will contain some randomness. All methods for distinguishing deterministic and stochastic processes rely on the fact that a deterministic system always evolves in the same way from a given starting point. (ref 1 , 2 , 3 , and "" Distinguishing random from chaotic data "") - complying to latter, remind that every prime $p$ can be trivially identified by a sieving that applies prior primes $q<p$ so it is possible to determine that somehow the system evolves in the same way from a given starting point . Of course to take into account that time must be substituted by a walking index as well. A posterior II Thank you for all of many the comprehensive answers and discussions. This is a quite classic question on MSE and meanwhile we moved much forward. You are right that primes are not random as per above question. Indeed we could show that they are in their sequence some type of ""deterministic chaos"". We don't need the Riemann function for this purpose. The primes sequence is a so called ""ordered iterative sequence"". Meanwhile this has been further elaborated by this source: ""The Secret Harmony of Primes"" (ISBN 978-9176370001) http://a.co/iIHQqR8 Some of you correctly referred to sieving. It is crucial however that we regard sieving procedures as a subset of ""interference"" (incl. frequencies and amplitudes). We can iteratively apply interference rules in order to gain from the first prime 2, the next ordered sequence. This can be iterative continued in an ""ordered"" way and within exact boundaries of p-squares (for 100% certainty). Indeed, in order to construct an ordered sequence of primes you just need to begin with 2. The Riemann approach is charming but would raise difficulties since we don't have yet a proof of the hypothesis that connects the order of the non-trivial zeros with the primes. So if you apply Riemann, as some colleagues here suggest, we would need to say at any time in the begin of your argumentation something like ""provided the Riemann hypothesis would be true..."". Having in mind that the very unique rule that primes follow, is that in an interference scheme all odd prime frequencies dance on the base frequency of 2 (ordered iterative sequence), one may even give it a thought to something of a parallel in the Riemann transformed world, that all non-trivial zeros dance on 1/2. But latter remains not more than a tempting trivial speculation yet.",,"['probability', 'number-theory', 'prime-numbers', 'random']"
39,When Jensen's inequality is equality,When Jensen's inequality is equality,,"One form of Jensen's inequality is If $X$ is a random variable and $g$ is a convex function, then   $\mathbb{E}(g(X))\geq g(\mathbb{E}(X))$. Just out of curiosity, when do we have equality? If and only if $g$ is constant?","One form of Jensen's inequality is If $X$ is a random variable and $g$ is a convex function, then   $\mathbb{E}(g(X))\geq g(\mathbb{E}(X))$. Just out of curiosity, when do we have equality? If and only if $g$ is constant?",,"['probability', 'probability-theory', 'jensen-inequality']"
40,Strange Patience Game,Strange Patience Game,,"I read about this game as a kid, but my maths was never up to solving it: The score starts at zero. Take a shuffled pack of cards and keep dealing face up until you reach the first Ace, at which the score becomes 1. Deal on until you reach the next 2, at which the score becomes 2, although you may not reach this if all the 2s came before the first Ace. If you reach 2, deal on until you reach the first 3, at which, if you reach it, the score becomes 3, and so on. What is the most likely final score? And how do you calculate the probability of any particular score? I once wrote a program that performed this routine millions of times on randomised packs with different numbers of suits up to about 10. To my surprise, the most likely score for any pack seemed empirically to always be the same as the number of suits in the pack. I would love to see this proved, though it is beyond my powers.","I read about this game as a kid, but my maths was never up to solving it: The score starts at zero. Take a shuffled pack of cards and keep dealing face up until you reach the first Ace, at which the score becomes 1. Deal on until you reach the next 2, at which the score becomes 2, although you may not reach this if all the 2s came before the first Ace. If you reach 2, deal on until you reach the first 3, at which, if you reach it, the score becomes 3, and so on. What is the most likely final score? And how do you calculate the probability of any particular score? I once wrote a program that performed this routine millions of times on randomised packs with different numbers of suits up to about 10. To my surprise, the most likely score for any pack seemed empirically to always be the same as the number of suits in the pack. I would love to see this proved, though it is beyond my powers.",,"['probability', 'combinatorics']"
41,Cutting out a circle using circles,Cutting out a circle using circles,,"Let $X_0$ be the unit disc, and consider the process of ""cutting out circles"", where to construct $X_n$ you select a uniform random point $x \in X_{n-1}$ , and cut out the largest circle with center $x$ . To illustrate this process, we have the following graphic: where the graphs are respectively showing one sample of $X_1,X_2,X_3,X_{100}$ (the orange parts have been cut out). Can we prove we eventually cut everything out? Formally, is the following true $$\text{lim}_{n \to \infty} \mathbb{E}[\text{Area}(X_n)] = 0$$ where $\mathbb{E}$ denotes we are taking the expectation value. Doing simulations, this seems true, in fact $\mathbb{E}[\text{Area}($ X_n $)]$ seems to decay with some power law, but after 4 years I still don't really know how to prove this :(. The main thing you need to rule out is that $X_n$ doesn't get too skinny too quickly, it seems.","Let be the unit disc, and consider the process of ""cutting out circles"", where to construct you select a uniform random point , and cut out the largest circle with center . To illustrate this process, we have the following graphic: where the graphs are respectively showing one sample of (the orange parts have been cut out). Can we prove we eventually cut everything out? Formally, is the following true where denotes we are taking the expectation value. Doing simulations, this seems true, in fact X_n seems to decay with some power law, but after 4 years I still don't really know how to prove this :(. The main thing you need to rule out is that doesn't get too skinny too quickly, it seems.","X_0 X_n x \in X_{n-1} x X_1,X_2,X_3,X_{100} \text{lim}_{n \to \infty} \mathbb{E}[\text{Area}(X_n)] = 0 \mathbb{E} \mathbb{E}[\text{Area}( )] X_n","['probability', 'geometry', 'measure-theory', 'random-variables', 'recreational-mathematics']"
42,Probability of completing a self-avoiding chessboard tour,Probability of completing a self-avoiding chessboard tour,,"Someone asked a question about self-avoiding random walks, and it made me think of the following: Consider a piece that starts at a corner of an ordinary $8 \times 8$ chessboard.  At each turn, it moves one step, either up, down, left, or right, with equal probability, except that it must stay on the board, of course, and it must not return to a square previously visited. Clarification.  On any given step, if the piece has $n$ available moves (excluding those that would put the piece on a previously   visited square), it chooses randomly and uniformly from those $n$   moves.  Example: Starting from a corner, at first move, $n = 2$, and   either move is chosen with probability $1/2$.  Next move, $n = 2$   also, because it cannot return to the corner, and so either of the two   other moves are chosen with probability $1/2$.  On the third move, if   it is on the edge, $n = 2$, while if it is off the edge, $n = 3$.  And   so on. It is possible for the piece to be deadlocked at some point prior to completing a tour of the chessboard.  For instance, if it starts at lower left, and moves up, right, right, down, left, it is now stuck. What is the probability that it completes the tour?  Is there a method that answers this question besides exhaustive enumeration?  What about $n \times n$ chessboards for $n \geq 3$?  (The problem is trivial for $n = 1$ or $2$.) Analysis for $n = 3$, as another clarification: Let the chessboard be labelled $(1, 1)$ through $(3, 3)$, and the   piece starts at $(1, 1)$.  Without loss of generality, the piece moves   to $(2, 1)$.  Then: With probability $1/2$, the piece moves to the center square $(2, 2)$ on its second move.  From there, only one move permits completion   of the tour—the move to $(1, 2)$—and in that case, the tour is   guaranteed to complete.  This move is chosen with probability $1/3$. With probability $1/2$, the piece moves to $(3, 1)$ on its second move.  It is then forced to move to $(3, 2)$. With probability $1/2$, it then moves to $(3, 3)$ on its fourth   move and is guaranteed to complete the tour. Otherwise, also with probability $1/2$, it moves to the center   square $(2, 2)$ on its fourth move.  From there, it moves to $(1, 2)$   with probability $1/2$ (and is then guaranteed to complete the tour),   or to $(2, 3)$ also with probability $1/2$ (and is then unable to   complete the tour). Thus, the probability of completing the tour on a $3 \times 3$ board   is $$ p_3 = \frac{1}{2} \times \frac{1}{3}      + \frac{1}{2} \times \left( \frac{1}{2} + \frac{1}{2} \times \frac{1}{2} \right)      = \frac{1}{6} + \frac{3}{8} = \frac{13}{24} $$ Update. An exhaustive enumeration in floating point yielded the following: For $n = 8, p_n = 0.000006751027716$","Someone asked a question about self-avoiding random walks, and it made me think of the following: Consider a piece that starts at a corner of an ordinary $8 \times 8$ chessboard.  At each turn, it moves one step, either up, down, left, or right, with equal probability, except that it must stay on the board, of course, and it must not return to a square previously visited. Clarification.  On any given step, if the piece has $n$ available moves (excluding those that would put the piece on a previously   visited square), it chooses randomly and uniformly from those $n$   moves.  Example: Starting from a corner, at first move, $n = 2$, and   either move is chosen with probability $1/2$.  Next move, $n = 2$   also, because it cannot return to the corner, and so either of the two   other moves are chosen with probability $1/2$.  On the third move, if   it is on the edge, $n = 2$, while if it is off the edge, $n = 3$.  And   so on. It is possible for the piece to be deadlocked at some point prior to completing a tour of the chessboard.  For instance, if it starts at lower left, and moves up, right, right, down, left, it is now stuck. What is the probability that it completes the tour?  Is there a method that answers this question besides exhaustive enumeration?  What about $n \times n$ chessboards for $n \geq 3$?  (The problem is trivial for $n = 1$ or $2$.) Analysis for $n = 3$, as another clarification: Let the chessboard be labelled $(1, 1)$ through $(3, 3)$, and the   piece starts at $(1, 1)$.  Without loss of generality, the piece moves   to $(2, 1)$.  Then: With probability $1/2$, the piece moves to the center square $(2, 2)$ on its second move.  From there, only one move permits completion   of the tour—the move to $(1, 2)$—and in that case, the tour is   guaranteed to complete.  This move is chosen with probability $1/3$. With probability $1/2$, the piece moves to $(3, 1)$ on its second move.  It is then forced to move to $(3, 2)$. With probability $1/2$, it then moves to $(3, 3)$ on its fourth   move and is guaranteed to complete the tour. Otherwise, also with probability $1/2$, it moves to the center   square $(2, 2)$ on its fourth move.  From there, it moves to $(1, 2)$   with probability $1/2$ (and is then guaranteed to complete the tour),   or to $(2, 3)$ also with probability $1/2$ (and is then unable to   complete the tour). Thus, the probability of completing the tour on a $3 \times 3$ board   is $$ p_3 = \frac{1}{2} \times \frac{1}{3}      + \frac{1}{2} \times \left( \frac{1}{2} + \frac{1}{2} \times \frac{1}{2} \right)      = \frac{1}{6} + \frac{3}{8} = \frac{13}{24} $$ Update. An exhaustive enumeration in floating point yielded the following: For $n = 8, p_n = 0.000006751027716$",,"['probability', 'combinatorics', 'stochastic-processes', 'random-walk', 'chessboard']"
43,A family has three children. What is the probability that at least one of them is a boy?,A family has three children. What is the probability that at least one of them is a boy?,,"According to me there are $4$ possible outcomes: $$GGG \ \  BBB \ \  BGG \ \ BBG $$ Out of these four outcomes, $3$ are favorable. So the probability should be $\frac{3}{4}$. But should you take into account the order of their birth? Because in that case it would be $\frac{7}{8}$!","According to me there are $4$ possible outcomes: $$GGG \ \  BBB \ \  BGG \ \ BBG $$ Out of these four outcomes, $3$ are favorable. So the probability should be $\frac{3}{4}$. But should you take into account the order of their birth? Because in that case it would be $\frac{7}{8}$!",,['probability']
44,Probability of drawing the Jack of Hearts? [duplicate],Probability of drawing the Jack of Hearts? [duplicate],,"This question already has answers here : Probability of second card being an ace (4 answers) Closed 4 years ago . You have a standard deck of cards and randomly take one card away without looking at it and set it aside. What is the probability that you draw the Jack of Hearts from the pile now containing 51 cards? I'm confused by this question because if the card you removed from the pile was the Jack of Hearts then the probability would be zero so I'm not sure how to calculate it. Edit: I asked this question about a year ago because I was struggling to get an intuitive understanding of an important concept in probability, and the comments and answers were really helpful for me (especially the one about ""no new information being added so the probability doesn't change"").","This question already has answers here : Probability of second card being an ace (4 answers) Closed 4 years ago . You have a standard deck of cards and randomly take one card away without looking at it and set it aside. What is the probability that you draw the Jack of Hearts from the pile now containing 51 cards? I'm confused by this question because if the card you removed from the pile was the Jack of Hearts then the probability would be zero so I'm not sure how to calculate it. Edit: I asked this question about a year ago because I was struggling to get an intuitive understanding of an important concept in probability, and the comments and answers were really helpful for me (especially the one about ""no new information being added so the probability doesn't change"").",,"['probability', 'discrete-mathematics', 'card-games']"
45,When to stop rolling a die in a game where 6 loses everything,When to stop rolling a die in a game where 6 loses everything,,"You play a game using a standard six-sided die. You start with 0 points. Before every roll, you decide whether you want to continue the game or end it and keep your points. After each roll, if you rolled 6, then you lose everything and the game ends. Otherwise, add the score from the die to your total points and continue/stop the game. When should one stop playing this game? Obviously, one wants to maximize total score. As I was asked to show my preliminary results on this one, here they are: If we simplify the game to getting 0 on 6 and 3 otherwise, we get the following: $$\begin{align} EV &= \frac{5}{6}3+\frac{25}{36}6+\frac{125}{216}9+\ldots\\[5pt] &= \sum_{n=1}^{\infty}\left(\frac{5}{6}\right)^n3n \end{align}$$ which is divergent, so it would make sense to play forever, which makes this similar to the St. Petersburg paradox. Yet I can sense that I'm wrong somewhere!","You play a game using a standard six-sided die. You start with 0 points. Before every roll, you decide whether you want to continue the game or end it and keep your points. After each roll, if you rolled 6, then you lose everything and the game ends. Otherwise, add the score from the die to your total points and continue/stop the game. When should one stop playing this game? Obviously, one wants to maximize total score. As I was asked to show my preliminary results on this one, here they are: If we simplify the game to getting 0 on 6 and 3 otherwise, we get the following: $$\begin{align} EV &= \frac{5}{6}3+\frac{25}{36}6+\frac{125}{216}9+\ldots\\[5pt] &= \sum_{n=1}^{\infty}\left(\frac{5}{6}\right)^n3n \end{align}$$ which is divergent, so it would make sense to play forever, which makes this similar to the St. Petersburg paradox. Yet I can sense that I'm wrong somewhere!",,"['probability', 'dice', 'gambling']"
46,An ant walk on the edges of a cube where it can select any of the 3 adjoining vertices with equal probability.,An ant walk on the edges of a cube where it can select any of the 3 adjoining vertices with equal probability.,,There is a cube and an ant is performing a random walk on the edges where it can select any of the 3 adjoining vertices with equal probability. What is the expected number of steps it needs till it reaches the diagonally opposite vertex?,There is a cube and an ant is performing a random walk on the edges where it can select any of the 3 adjoining vertices with equal probability. What is the expected number of steps it needs till it reaches the diagonally opposite vertex?,,"['probability', 'graph-theory', 'expected-value']"
47,"What is the difference between ""expectation"", ""variance"" for statistics versus probability textbooks?","What is the difference between ""expectation"", ""variance"" for statistics versus probability textbooks?",,"It seems that there are two ideas of expectation, variance, etc. going on in our world. In any probability textbook: I have a random variable $X$ , which is a function from the sample space to the real line. Ok, now I define the expectation operator, which is a function that maps this random variable to a real number, and this function looks like, $$\mathbb{E}[X] = \sum\limits_{i = 1}^n x_i p(x_i)$$ where $p$ is the probability mass function, $p: x_i \mapsto [0,1], \sum_{i = 1}^n p(x_i) = 1$ and $x_i \in \text{range}(X)$ . The variance is, $$\mathbb{E}[(X - \mathbb{E}[X])^2]$$ The definition is similar for a continuous RV. However, in statistics, data science, finance, bioinformatics (and I guess everyday language when talking to your mother) I have a multi-set of data $D = \{x_i\}_{i = 1}^n$ (weight of onions, height of school children). The mean of this dataset is $$\dfrac{1}{n}\sum\limits_{i= 1}^n x_i$$ The variance of this dataset (according to "" science buddy "" and "" mathisfun dot com "" and government of Canada ) is, $$\dfrac{1}{n}\sum\limits_{i= 1}^n(x_i - \sum\limits_{j= 1}^n \dfrac{1}{n} x_j)^2$$ I mean, I can already see what's going on here (one is assuming uniform distribution), however, I want an authoritative explanation on the following: Is the distinction real? Meaning, is there a universe where expectation/mean/variance... are defined for functions/random variables and another universe where expectation/mean/variance... are defined for raw data? Or are they essentially the same thing (with hidden/implicit assumption) Why is it no probabilistic assumption is made when talking about mean or variance when it comes to dealing with data in statistics or data science (or other areas of real life)? Is there some consistent language for distinguishing these two seemingly different mean and variance terminologies? For example, if my cashier asks me about the ""mean weight"" of two items, do I ask him/her for the probabilistic distribution of the random variable whose realization are the weights of these two items ( def 1 ), or do I just add up the value and divide  ( def 2 )? How do I know which mean the person is talking about?/","It seems that there are two ideas of expectation, variance, etc. going on in our world. In any probability textbook: I have a random variable , which is a function from the sample space to the real line. Ok, now I define the expectation operator, which is a function that maps this random variable to a real number, and this function looks like, where is the probability mass function, and . The variance is, The definition is similar for a continuous RV. However, in statistics, data science, finance, bioinformatics (and I guess everyday language when talking to your mother) I have a multi-set of data (weight of onions, height of school children). The mean of this dataset is The variance of this dataset (according to "" science buddy "" and "" mathisfun dot com "" and government of Canada ) is, I mean, I can already see what's going on here (one is assuming uniform distribution), however, I want an authoritative explanation on the following: Is the distinction real? Meaning, is there a universe where expectation/mean/variance... are defined for functions/random variables and another universe where expectation/mean/variance... are defined for raw data? Or are they essentially the same thing (with hidden/implicit assumption) Why is it no probabilistic assumption is made when talking about mean or variance when it comes to dealing with data in statistics or data science (or other areas of real life)? Is there some consistent language for distinguishing these two seemingly different mean and variance terminologies? For example, if my cashier asks me about the ""mean weight"" of two items, do I ask him/her for the probabilistic distribution of the random variable whose realization are the weights of these two items ( def 1 ), or do I just add up the value and divide  ( def 2 )? How do I know which mean the person is talking about?/","X \mathbb{E}[X] = \sum\limits_{i = 1}^n x_i p(x_i) p p: x_i \mapsto [0,1], \sum_{i = 1}^n p(x_i) = 1 x_i \in \text{range}(X) \mathbb{E}[(X - \mathbb{E}[X])^2] D = \{x_i\}_{i = 1}^n \dfrac{1}{n}\sum\limits_{i= 1}^n x_i \dfrac{1}{n}\sum\limits_{i= 1}^n(x_i - \sum\limits_{j= 1}^n \dfrac{1}{n} x_j)^2","['probability', 'probability-theory', 'statistics', 'soft-question', 'terminology']"
48,Law of total variance intuition,Law of total variance intuition,,"Intuitively, what's the difference between 2 following terms on the right hand side of the law of total variance? $$\text{Var}(Y) = \Bbb E\left[\text{Var}\left(Y|X\right)\right] + \text{Var}\left(\Bbb E[Y|X]\right)$$","Intuitively, what's the difference between 2 following terms on the right hand side of the law of total variance?",\text{Var}(Y) = \Bbb E\left[\text{Var}\left(Y|X\right)\right] + \text{Var}\left(\Bbb E[Y|X]\right),"['probability', 'probability-theory']"
49,"Calculation of the n-th central moment of the normal distribution $\mathcal{N}(\mu,\sigma^2)$",Calculation of the n-th central moment of the normal distribution,"\mathcal{N}(\mu,\sigma^2)","Since integration is not my strong suit I need some feedback on this, please: Let $Y$ be $\mathcal{N}(\mu,\sigma^2)$, the normal distrubution with parameters $\mu$ and $\sigma^2$. I know $\mu$ is the expectation value and $\sigma$ is the variance of $Y$. I want to calculate the $n$-th central moments of $Y$. The density function of $Y$ is $$f(x)=\frac{1}{\sigma\sqrt {2\pi}}e^{-\frac{1}{2}\left(\frac{y-\mu}{\sigma}\right)^2}$$ The $n$-th central moment of $Y$ is $$E[(Y-E(Y))^n]$$ The $n$-th moment of $Y$ is $$E(Y^n)=\psi^{(n)}(0)$$ where $\psi$ is the Moment-generating function $$\psi(t)=E(e^{tX})$$ So I started calculating: $$\begin{align}  E[(Y-E(Y))^n]&=\int_\mathbb{R}\left(f(x)-\int_\mathbb{R}f(x)dx\right)^n\,dx \\ &=\int_\mathbb{R}\sum_{k=0}^n\left[\binom{n}{k}(f(x))^k\left(-\int_\mathbb{R}f(x)dx\right)^{n-k}\right]\,dx \\ &=\sum_{k=0}^n\binom{n}{k}\left(\int_\mathbb{R}\left[(f(x))^k\left(-\int_\mathbb{R}f(x)dx\right)^{n-k}\right]\,dx\right) \\ &=\sum_{k=0}^n\binom{n}{k}\left(\int_\mathbb{R}\left[(f(x))^k\left(-\mu\right)^{n-k}\right]\,dx\right) \\ &=\sum_{k=0}^n\binom{n}{k}\left((-\mu)^{n-k}\int_\mathbb{R}(f(x))^k\,dx\right) \\ &=\sum_{k=0}^n\binom{n}{k}\left((-\mu)^{n-k}E\left(Y^k\right)\right) \\ \end{align}$$ Am I on the right track or completely misguided? If I have made no mistakes so far, I would be glad to get some inspiration because I am stuck here. Thanks!","Since integration is not my strong suit I need some feedback on this, please: Let $Y$ be $\mathcal{N}(\mu,\sigma^2)$, the normal distrubution with parameters $\mu$ and $\sigma^2$. I know $\mu$ is the expectation value and $\sigma$ is the variance of $Y$. I want to calculate the $n$-th central moments of $Y$. The density function of $Y$ is $$f(x)=\frac{1}{\sigma\sqrt {2\pi}}e^{-\frac{1}{2}\left(\frac{y-\mu}{\sigma}\right)^2}$$ The $n$-th central moment of $Y$ is $$E[(Y-E(Y))^n]$$ The $n$-th moment of $Y$ is $$E(Y^n)=\psi^{(n)}(0)$$ where $\psi$ is the Moment-generating function $$\psi(t)=E(e^{tX})$$ So I started calculating: $$\begin{align}  E[(Y-E(Y))^n]&=\int_\mathbb{R}\left(f(x)-\int_\mathbb{R}f(x)dx\right)^n\,dx \\ &=\int_\mathbb{R}\sum_{k=0}^n\left[\binom{n}{k}(f(x))^k\left(-\int_\mathbb{R}f(x)dx\right)^{n-k}\right]\,dx \\ &=\sum_{k=0}^n\binom{n}{k}\left(\int_\mathbb{R}\left[(f(x))^k\left(-\int_\mathbb{R}f(x)dx\right)^{n-k}\right]\,dx\right) \\ &=\sum_{k=0}^n\binom{n}{k}\left(\int_\mathbb{R}\left[(f(x))^k\left(-\mu\right)^{n-k}\right]\,dx\right) \\ &=\sum_{k=0}^n\binom{n}{k}\left((-\mu)^{n-k}\int_\mathbb{R}(f(x))^k\,dx\right) \\ &=\sum_{k=0}^n\binom{n}{k}\left((-\mu)^{n-k}E\left(Y^k\right)\right) \\ \end{align}$$ Am I on the right track or completely misguided? If I have made no mistakes so far, I would be glad to get some inspiration because I am stuck here. Thanks!",,"['probability', 'normal-distribution']"
50,Expected number of loops,Expected number of loops,,"There are 100 ropes in a bag. In each step, two rope ends are picked at random, tied together and put back into a bag. The process is repeated until there are no free ends. What is the expected number of loops at the end of the process?","There are 100 ropes in a bag. In each step, two rope ends are picked at random, tied together and put back into a bag. The process is repeated until there are no free ends. What is the expected number of loops at the end of the process?",,['probability']
51,"How can I generate ""random"" curves?","How can I generate ""random"" curves?",,"In game programming (my profession) it is often necessary to generate all kinds of random things, including random curves (for example, to make a procedural island or for an agent to follow some path). For one dimensional things, we usually use some random generator that generates say floats (which are really rational numbers) in some range and that is good enough as an approximation for most purposes. (Even though we cannot generate actual real numbers within a range uniformly, we can get a good sense of it with the rationals that we DO generate.) When it comes to 2D things, though, things are very murky. For example, suppose I want to generate curves uniformly between two points (say, all curves bounded in a box, and say, additional requirements such as that the curves are differentiable). The way we usually do it is to generate random parameters for some specific type of curve - say a Bezier curve, but this is not (AFAI can see) uniform in the original requirements - i.e. some curves that fit the bill will be more likely than others. Is this even a sensible question to ask? And if so, is there a way to generate curves (to a decent approximation) so that they are uniform within the parameters? (bounded and smooth)? It ""feels"" like there are too many curves; it is strictly true with real numbers too... but there we have that rationals can be close enough for practical purposes; but with 2D things it seems less clear that any possible real curve is ""close enough"" to a ""rational curve"". So I guess the main question is... if we have a set of ""all curves"", whether we can find a way to generate another set of approximations so that each ""real"" curve is close enough to our approximation. Or: is there a mapping from ""approximations to reals"" to ""approximations of continuous, differentiable, bounded curves between two points"".... (that preserves uniformity, at least intuitively)? Or: is there a notion of distribution of (bounded differential) curves? (And way to pick items from it). Edit: I am more interested in the theoretical possibilities. I know LOTS of ways to generate curves... I am particular interested in generating curves without some kind of bias, and whether this even makes sense to want. Edit: @pjs36 pointed out the curve may be arbitrary long. I don't mind additional restrictions to prevent pathological curves. Restrictions like ""not longer than $x$"", or not self-crossing.","In game programming (my profession) it is often necessary to generate all kinds of random things, including random curves (for example, to make a procedural island or for an agent to follow some path). For one dimensional things, we usually use some random generator that generates say floats (which are really rational numbers) in some range and that is good enough as an approximation for most purposes. (Even though we cannot generate actual real numbers within a range uniformly, we can get a good sense of it with the rationals that we DO generate.) When it comes to 2D things, though, things are very murky. For example, suppose I want to generate curves uniformly between two points (say, all curves bounded in a box, and say, additional requirements such as that the curves are differentiable). The way we usually do it is to generate random parameters for some specific type of curve - say a Bezier curve, but this is not (AFAI can see) uniform in the original requirements - i.e. some curves that fit the bill will be more likely than others. Is this even a sensible question to ask? And if so, is there a way to generate curves (to a decent approximation) so that they are uniform within the parameters? (bounded and smooth)? It ""feels"" like there are too many curves; it is strictly true with real numbers too... but there we have that rationals can be close enough for practical purposes; but with 2D things it seems less clear that any possible real curve is ""close enough"" to a ""rational curve"". So I guess the main question is... if we have a set of ""all curves"", whether we can find a way to generate another set of approximations so that each ""real"" curve is close enough to our approximation. Or: is there a mapping from ""approximations to reals"" to ""approximations of continuous, differentiable, bounded curves between two points"".... (that preserves uniformity, at least intuitively)? Or: is there a notion of distribution of (bounded differential) curves? (And way to pick items from it). Edit: I am more interested in the theoretical possibilities. I know LOTS of ways to generate curves... I am particular interested in generating curves without some kind of bias, and whether this even makes sense to want. Edit: @pjs36 pointed out the curve may be arbitrary long. I don't mind additional restrictions to prevent pathological curves. Restrictions like ""not longer than $x$"", or not self-crossing.",,"['probability', 'approximation']"
52,What is the probability that eventually it will rain forever?,What is the probability that eventually it will rain forever?,,"Probability of raining today is 60%. If it rains today, the probability of raining tomorrow will increase by 10%. If it doesn't rain today, the probability raining tomorrow will decrease by 10%. Rule 2 and 3 can be applied to future days. What is the probability that eventually, it will rain forever? (I tried using binomial option pricing model but couldn't solve it because the probability isn't fixed. I saw this question in Chinese as an interview question for a quant position. I couldn't find an answer online. So please help me smart people!)","Probability of raining today is 60%. If it rains today, the probability of raining tomorrow will increase by 10%. If it doesn't rain today, the probability raining tomorrow will decrease by 10%. Rule 2 and 3 can be applied to future days. What is the probability that eventually, it will rain forever? (I tried using binomial option pricing model but couldn't solve it because the probability isn't fixed. I saw this question in Chinese as an interview question for a quant position. I couldn't find an answer online. So please help me smart people!)",,['probability']
53,Are there arbitrarily large gaps between consecutive primes? [duplicate],Are there arbitrarily large gaps between consecutive primes? [duplicate],,"This question already has answers here : I'm trying to find the longest consecutive set of composite numbers (6 answers) Closed 6 years ago . I made a program to find out the number of primes within a certain range, for example between $1$ and $10000$ I found $1229$ primes, I then increased my range to $20000$ and then I found $2262$ primes, after doing it for $1$ to $30000$, I found $3245$ primes. Now a curious thing to notice is that each time, The probability of finding a prime in between $2$ multiples of $10000$ is decreasing, i.e it was $$\frac{2262-1229}{10000}=0.1033$$ between $10000$ and $20000$, and $$\frac{3245-2262}{10000}=0.0983$$ between $20000$ and $30000$, So from this can we infer that there will exist two numbers separated by a gap of $10000$ such that no number in between them is prime? If so how to determine the first two numbers with which this happens? Also I took $10000$ just as a reference here, what about if the gap between them in general is $x$, can we do something for this in generality? Thanks!","This question already has answers here : I'm trying to find the longest consecutive set of composite numbers (6 answers) Closed 6 years ago . I made a program to find out the number of primes within a certain range, for example between $1$ and $10000$ I found $1229$ primes, I then increased my range to $20000$ and then I found $2262$ primes, after doing it for $1$ to $30000$, I found $3245$ primes. Now a curious thing to notice is that each time, The probability of finding a prime in between $2$ multiples of $10000$ is decreasing, i.e it was $$\frac{2262-1229}{10000}=0.1033$$ between $10000$ and $20000$, and $$\frac{3245-2262}{10000}=0.0983$$ between $20000$ and $30000$, So from this can we infer that there will exist two numbers separated by a gap of $10000$ such that no number in between them is prime? If so how to determine the first two numbers with which this happens? Also I took $10000$ just as a reference here, what about if the gap between them in general is $x$, can we do something for this in generality? Thanks!",,"['probability', 'elementary-number-theory', 'prime-numbers', 'prime-gaps']"
54,Proving Pascal's Rule : ${{n} \choose {r}}={{n-1} \choose {r-1}}+{{n-1} \choose r}$ when $1\leq r\leq n$,Proving Pascal's Rule :  when,{{n} \choose {r}}={{n-1} \choose {r-1}}+{{n-1} \choose r} 1\leq r\leq n,"I'm trying to prove that ${n \choose r}$ is equal to ${{n-1} \choose {r-1}}+{{n-1} \choose r}$ when $1\leq r\leq n$. I suppose I could use the counting rules in probability, perhaps combination= ${{n} \choose {r}}=\frac{n!}{r!(n-r!)}$. I want to see an actual proof behind this equation.  Does anyone have any ideas?","I'm trying to prove that ${n \choose r}$ is equal to ${{n-1} \choose {r-1}}+{{n-1} \choose r}$ when $1\leq r\leq n$. I suppose I could use the counting rules in probability, perhaps combination= ${{n} \choose {r}}=\frac{n!}{r!(n-r!)}$. I want to see an actual proof behind this equation.  Does anyone have any ideas?",,['probability']
55,Probability that a stick randomly broken in two places can form a triangle,Probability that a stick randomly broken in two places can form a triangle,,"Randomly break a stick (or a piece of dry spaghetti, etc.) in two places, forming three pieces.  The probability that these three pieces can form a triangle is $\frac14$ (coordinatize the stick form $0$ to $1$, call the breaking points $x$ and $y$, consider the unit square of the coordinate plane, shade the areas that satisfy the triangle inequality edit : see comments on the question, below, for a better explanation of this). The other day in class * , my professor was demonstrating how to do a Monte Carlo simulation of this problem on a calculator and wrote a program that, for each trial did the following: Pick a random number $x$ between $0$ and $1$.  This is the first side length. Pick a random number $y$ between $0$ and $1 - x$ (the remaning part of the stick).  This is the second side length. The third side length is $1 - x - y$. Test if the three side lengths satisfy the triangle inequality (in all three permutations). He ran around $1000$ trials and was getting $0.19$, which he said was probably just random-chance error off $0.25$, but every time the program was run, no matter who's calculator we used, the result was around $0.19$. What's wrong with the simulation method?  What is the theoretical answer to the problem actually being simulated? ( * the other day was more than $10$ years ago)","Randomly break a stick (or a piece of dry spaghetti, etc.) in two places, forming three pieces.  The probability that these three pieces can form a triangle is $\frac14$ (coordinatize the stick form $0$ to $1$, call the breaking points $x$ and $y$, consider the unit square of the coordinate plane, shade the areas that satisfy the triangle inequality edit : see comments on the question, below, for a better explanation of this). The other day in class * , my professor was demonstrating how to do a Monte Carlo simulation of this problem on a calculator and wrote a program that, for each trial did the following: Pick a random number $x$ between $0$ and $1$.  This is the first side length. Pick a random number $y$ between $0$ and $1 - x$ (the remaning part of the stick).  This is the second side length. The third side length is $1 - x - y$. Test if the three side lengths satisfy the triangle inequality (in all three permutations). He ran around $1000$ trials and was getting $0.19$, which he said was probably just random-chance error off $0.25$, but every time the program was run, no matter who's calculator we used, the result was around $0.19$. What's wrong with the simulation method?  What is the theoretical answer to the problem actually being simulated? ( * the other day was more than $10$ years ago)",,"['probability', 'monte-carlo']"
56,Can we prove the law of total probability for continuous distributions?,Can we prove the law of total probability for continuous distributions?,,"If we have a probability space $(\Omega,\mathcal{F},P)$ and $\Omega$ is partitioned into pairwise disjoint subsets $A_{i}$ , with $i\in\mathbb{N}$ , then the law of total probability says that $P(B)=\sum_{i=1}^{n}P(B|A_{i})P(A_i{})$ . This law can be proved using the following two facts: \begin{align*} P(B|A_{i})&=\frac{P(B\cap A_{i})}{P(A_{i})}\\ P\left(\bigcup_{i\in \mathbb{N}} S_{i}\right)&=\sum_{i\in\mathbb{N}}P(S_{i}) \end{align*} Where the $S_{i}$ 's are a pairwise disjoint and a $\textit{countable}$ family of events in $\mathcal{F}$ . However, if we want to apply the law of total probability on a continuous random variable $X$ with density $f$ , we have ( like here ): $$P(A)=\int_{-\infty}^{\infty}P(A|X=x)f(x)dx$$ which is the law of total probabillity but with the summation replaced with an integral, and $P(A_{i})$ replaced with $f(x)dx$ . The problem is that we are conditioning on an $\textit{uncountable}$ family. Is there any proof of this statement (if true)?","If we have a probability space and is partitioned into pairwise disjoint subsets , with , then the law of total probability says that . This law can be proved using the following two facts: Where the 's are a pairwise disjoint and a family of events in . However, if we want to apply the law of total probability on a continuous random variable with density , we have ( like here ): which is the law of total probabillity but with the summation replaced with an integral, and replaced with . The problem is that we are conditioning on an family. Is there any proof of this statement (if true)?","(\Omega,\mathcal{F},P) \Omega A_{i} i\in\mathbb{N} P(B)=\sum_{i=1}^{n}P(B|A_{i})P(A_i{}) \begin{align*}
P(B|A_{i})&=\frac{P(B\cap A_{i})}{P(A_{i})}\\
P\left(\bigcup_{i\in \mathbb{N}} S_{i}\right)&=\sum_{i\in\mathbb{N}}P(S_{i})
\end{align*} S_{i} \textit{countable} \mathcal{F} X f P(A)=\int_{-\infty}^{\infty}P(A|X=x)f(x)dx P(A_{i}) f(x)dx \textit{uncountable}","['probability', 'probability-distributions']"
57,Exercise 1.6.3 from Alon & Spencer's *The Probabilistic Method*: prove that $Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1]$ for i.i.d. real RVs $X$ and $Y$,Exercise 1.6.3 from Alon & Spencer's *The Probabilistic Method*: prove that  for i.i.d. real RVs  and,Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1] X Y,"Doing a little reading over the break ( The Probabilistic Method by Alon and Spencer); can't come up with the solution for this seemingly simple (and perhaps even a little surprising?) result: (A-S 1.6.3) Prove that for every two independent identically distributed real random variables $X$ and $Y$ , $$Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1].$$","Doing a little reading over the break ( The Probabilistic Method by Alon and Spencer); can't come up with the solution for this seemingly simple (and perhaps even a little surprising?) result: (A-S 1.6.3) Prove that for every two independent identically distributed real random variables and ,",X Y Pr[|X-Y| \leq 2] \leq 3 Pr[|X-Y| \leq 1].,"['probability', 'combinatorics', 'probability-theory', 'measure-theory', 'inequality']"
58,Why is the roll of a die considered random?,Why is the roll of a die considered random?,,"I've been reading articles on pseudo-randomness in computing when generating a random value. They all state that the generated numbers are pseudo-random because we know all the factors that influence the outcome, and that the roll of a die is considered truly random. But I'm wondering why. Don't we know all the physical forces that influence the die when it's being rolled? Or is there too many of them?","I've been reading articles on pseudo-randomness in computing when generating a random value. They all state that the generated numbers are pseudo-random because we know all the factors that influence the outcome, and that the roll of a die is considered truly random. But I'm wondering why. Don't we know all the physical forces that influence the die when it's being rolled? Or is there too many of them?",,"['probability', 'random-variables', 'random']"
59,Help: rules of a game whose details I don't remember!,Help: rules of a game whose details I don't remember!,,"In a probability course, a game was introduced which a logical approach won't yield a strategy for winning, but a probabilistic one will. My problem is that I don't remember the details (the rules of the game)! I would be thankful if anyone can complete the description of the game. I give the outline of the game, below. Some person (A) hides a 100 or 200 dollar bill, and asks another one (B) to guess which one is hidden. If B's guess is correct, something happens and if not, something else (this is what I don't remember). The strange point is, B can think of a strategy so that always ends to a positive amount, but now A can deduce that B will use this strategy, and finds a strategy to overcome B. Now B knows A's strategy, and will uses another strategy, and so on. So, before even playing the game for once, there is an infinite chain of strategies which A and B choose successively! Can you complete the story? I mean, what happens when B's guess correct and incorrect? Thanks.","In a probability course, a game was introduced which a logical approach won't yield a strategy for winning, but a probabilistic one will. My problem is that I don't remember the details (the rules of the game)! I would be thankful if anyone can complete the description of the game. I give the outline of the game, below. Some person (A) hides a 100 or 200 dollar bill, and asks another one (B) to guess which one is hidden. If B's guess is correct, something happens and if not, something else (this is what I don't remember). The strange point is, B can think of a strategy so that always ends to a positive amount, but now A can deduce that B will use this strategy, and finds a strategy to overcome B. Now B knows A's strategy, and will uses another strategy, and so on. So, before even playing the game for once, there is an infinite chain of strategies which A and B choose successively! Can you complete the story? I mean, what happens when B's guess correct and incorrect? Thanks.",,"['probability', 'logic', 'game-theory']"
60,Why is the expected value $E(X^2) \neq E(X)^2$?,Why is the expected value ?,E(X^2) \neq E(X)^2,"I wish to use the Computational formula of the variance to calculate the variance of a normal-distributed function. For this, I need the expected value of $X$ as well as the one of $X^2$. Intuitively, I would have assumed that $E(X^2)$ is always equal to $E(X)^2$. In fact, I cannot imagine how they could be different. Could you explain how this is possible, e.g. with an example?","I wish to use the Computational formula of the variance to calculate the variance of a normal-distributed function. For this, I need the expected value of $X$ as well as the one of $X^2$. Intuitively, I would have assumed that $E(X^2)$ is always equal to $E(X)^2$. In fact, I cannot imagine how they could be different. Could you explain how this is possible, e.g. with an example?",,['probability']
61,How can a probability density function (pdf) be greater than $1$?,How can a probability density function (pdf) be greater than ?,1,"The PDF describes the probability of a random variable to take on a given value: $f(x)=P(X=x)$ My question is whether this value can become greater than $1$? Quote from wikipedia: ""Unlike a probability, a probability density function can take on values greater than one; for example, the uniform distribution on the interval $[0, \frac12]$ has probability density $f(x) = 2$ for $0 \leq x \leq \frac12$ and $f(x) = 0$ elsewhere."" This wasn't clear to me, unfortunately. The question has been asked/answered here before, yet used the same example. Would anyone be able to explain it in a simple manner (using a real-life example, etc)? Original question: ""$X$ is a continuous random variable with probability density function $f$. Answer with either True or False. $f(x)$ can never exceed $1$."" Thank you! EDIT: Resolved.","The PDF describes the probability of a random variable to take on a given value: $f(x)=P(X=x)$ My question is whether this value can become greater than $1$? Quote from wikipedia: ""Unlike a probability, a probability density function can take on values greater than one; for example, the uniform distribution on the interval $[0, \frac12]$ has probability density $f(x) = 2$ for $0 \leq x \leq \frac12$ and $f(x) = 0$ elsewhere."" This wasn't clear to me, unfortunately. The question has been asked/answered here before, yet used the same example. Would anyone be able to explain it in a simple manner (using a real-life example, etc)? Original question: ""$X$ is a continuous random variable with probability density function $f$. Answer with either True or False. $f(x)$ can never exceed $1$."" Thank you! EDIT: Resolved.",,"['probability', 'statistics', 'density-function']"
62,Proofs of $\lim\limits_{n \to \infty} \left(H_n - 2^{-n} \sum\limits_{k=1}^n \binom{n}{k} H_k\right) = \log 2$,Proofs of,\lim\limits_{n \to \infty} \left(H_n - 2^{-n} \sum\limits_{k=1}^n \binom{n}{k} H_k\right) = \log 2,"Let $H_n$ denote the $n$th harmonic number; i.e., $H_n = \sum\limits_{i=1}^n \frac{1}{i}$.  I've got a couple of proofs of the following limiting expression, which I don't think is that well-known: $$\lim_{n \to \infty} \left(H_n - \frac{1}{2^n} \sum_{k=1}^n \binom{n}{k} H_k \right) = \log 2.$$ I'm curious about other ways to prove this expression, and so I thought I would ask here to see if anybody knows any or can think of any.  I would particularly like to see a combinatorial proof, but that might be difficult given that we're taking a limit and we have a transcendental number on one side.  I'd like to see any proofs, though.  I'll hold off from posting my own for a day or two to give others a chance to respond first. (The probability tag is included because the expression whose limit is being taken can also be interpreted probabilistically.) ( Added : I've accepted Srivatsan's first answer, and I've posted my two proofs for those who are interested in seeing them. Also, the sort of inverse question may be of interest.  Suppose we have a function $f(n)$ such that  $$\lim_{n \to \infty} \left(f(n) - \frac{1}{2^n} \sum_{k=0}^n \binom{n}{k} f(k) \right) = L,$$ where $L$ is finite and nonzero.  What can we say about $f(n)$? This question was asked and answered a while back ; it turns out that $f(n)$ must be $\Theta (\log n)$.  More specifically, we must have $\frac{f(n)}{\log_2 n} \to L$ as $n \to \infty$.)","Let $H_n$ denote the $n$th harmonic number; i.e., $H_n = \sum\limits_{i=1}^n \frac{1}{i}$.  I've got a couple of proofs of the following limiting expression, which I don't think is that well-known: $$\lim_{n \to \infty} \left(H_n - \frac{1}{2^n} \sum_{k=1}^n \binom{n}{k} H_k \right) = \log 2.$$ I'm curious about other ways to prove this expression, and so I thought I would ask here to see if anybody knows any or can think of any.  I would particularly like to see a combinatorial proof, but that might be difficult given that we're taking a limit and we have a transcendental number on one side.  I'd like to see any proofs, though.  I'll hold off from posting my own for a day or two to give others a chance to respond first. (The probability tag is included because the expression whose limit is being taken can also be interpreted probabilistically.) ( Added : I've accepted Srivatsan's first answer, and I've posted my two proofs for those who are interested in seeing them. Also, the sort of inverse question may be of interest.  Suppose we have a function $f(n)$ such that  $$\lim_{n \to \infty} \left(f(n) - \frac{1}{2^n} \sum_{k=0}^n \binom{n}{k} f(k) \right) = L,$$ where $L$ is finite and nonzero.  What can we say about $f(n)$? This question was asked and answered a while back ; it turns out that $f(n)$ must be $\Theta (\log n)$.  More specifically, we must have $\frac{f(n)}{\log_2 n} \to L$ as $n \to \infty$.)",,"['probability', 'combinatorics', 'sequences-and-series', 'limits', 'binomial-coefficients']"
63,Basic Probability Help for First Year Teacher,Basic Probability Help for First Year Teacher,,"Need some help. I'm a first year teacher, moving into a probability unit. I was looking through my given materials, and think I've found two errors. It's been a long time since I've done probability and I don't want to ask staff for fear of sounding stupid. I created a Word document  that I took a screen shot of, in order to hopefully get some confirmation. Anything inside the orange boxes are from my course materials, anything outside is work I did myself in Word. The red box on the right is just highlighting where I think the error occurs. Any help would be greatly appreciated. Noticed a small error on my part. The absolute last thing I wrote should say 3/16. As the book defines P(A and B) as such, not as 11/16, as I suggested.","Need some help. I'm a first year teacher, moving into a probability unit. I was looking through my given materials, and think I've found two errors. It's been a long time since I've done probability and I don't want to ask staff for fear of sounding stupid. I created a Word document  that I took a screen shot of, in order to hopefully get some confirmation. Anything inside the orange boxes are from my course materials, anything outside is work I did myself in Word. The red box on the right is just highlighting where I think the error occurs. Any help would be greatly appreciated. Noticed a small error on my part. The absolute last thing I wrote should say 3/16. As the book defines P(A and B) as such, not as 11/16, as I suggested.",,['probability']
64,What is the difference between mutually independent and pairwise independent events in probability theory?,What is the difference between mutually independent and pairwise independent events in probability theory?,,"Let us assume that a number is selected at random from $1, 2, 3$. We define $$A = \{1, 2\},\quad B = \{2, 3\},\quad C = \{1, 3\}$$ Then are $A$, $B$ and $C$ mutually independent or pairwise independent or both? I am confused between mutually vs pairwise independent.","Let us assume that a number is selected at random from $1, 2, 3$. We define $$A = \{1, 2\},\quad B = \{2, 3\},\quad C = \{1, 3\}$$ Then are $A$, $B$ and $C$ mutually independent or pairwise independent or both? I am confused between mutually vs pairwise independent.",,"['probability', 'probability-theory']"
65,What can I do with measure theory that I can't with probability and statistics,What can I do with measure theory that I can't with probability and statistics,,"I've studied mathematics and statistics at undergraduate level and am pretty happy with the main concepts. However, I've come across measure theory several times, and I know it is a basis for probability theory , and, unsurprising, looking at a basic introduction such as this Measure Theory Tutorial (pdf) , I see there are concepts such as events, sample spaces, and ways of getting from them to real numbers, that seem familiar. So measure theory seems like an area of pure mathematics that I probably ought to study (as discussed very well here ) but I have a lot of other areas I'd like to look at. For example, I'm studying and using calculus and Taylor series at a more advanced level and I've never studied real analysis properly -- and I can tell! In the future I'd like to study the theory of differential equations and integral transforms, and to do that I think I will need to study complex analysis. But I don't have the same kind of ""I don't know what I'm doing"" feeling when I do probability and statistics as when I look at calculus, series, or integral transforms, so those seem a lot more urgent to me from a foundational perspective. So my real question is, are there some application relating to probability and statistics  that I can't tackle without measure theory , or for that matter applications in other areas? Or is it more, I'm glad those measure theory guys have got the foundations worked out, I can trust they did a good job and get on with using what's built on top?","I've studied mathematics and statistics at undergraduate level and am pretty happy with the main concepts. However, I've come across measure theory several times, and I know it is a basis for probability theory , and, unsurprising, looking at a basic introduction such as this Measure Theory Tutorial (pdf) , I see there are concepts such as events, sample spaces, and ways of getting from them to real numbers, that seem familiar. So measure theory seems like an area of pure mathematics that I probably ought to study (as discussed very well here ) but I have a lot of other areas I'd like to look at. For example, I'm studying and using calculus and Taylor series at a more advanced level and I've never studied real analysis properly -- and I can tell! In the future I'd like to study the theory of differential equations and integral transforms, and to do that I think I will need to study complex analysis. But I don't have the same kind of ""I don't know what I'm doing"" feeling when I do probability and statistics as when I look at calculus, series, or integral transforms, so those seem a lot more urgent to me from a foundational perspective. So my real question is, are there some application relating to probability and statistics  that I can't tackle without measure theory , or for that matter applications in other areas? Or is it more, I'm glad those measure theory guys have got the foundations worked out, I can trust they did a good job and get on with using what's built on top?",,"['probability', 'measure-theory', 'statistics', 'probability-theory']"
66,Applications of the $\frac{5}{8}$ Theorem,Applications of the  Theorem,\frac{5}{8},"The 5/8 theorem for compact groups says the following: Theorem (5/8 Theorem for Compact Groups) Let $G$ be a compact Hausdorff topological group with Haar measure $\mu$ . If $G$ is not abelian then the probability that two elements of $G$ commute is at most $5/8$ . More precisely, if $G$ is not abelian then $$(\mu \times \mu)(\{(g,g') \in G \times G : [g,g'] = e\}) \leq 5/8.$$ If you don't care or already know how this is proved, skip down the page, past the next horizontal rule. Lemma 1. Let $G$ be a compact Hausdorff topological group with a Borel subgroup $H$ . Let $\mu$ be the Haar measure on $G$ . Then $\mu(H) = 1/[G:H]$ (this is $0$ by convention when $[G:H]$ is infinite). Proof of Lemma 1: The cosets of $H$ partition $G$ , and all have the same measure by translation-invariance of $\mu$ . If there are finitely many cosets, the result follows directly from additivity of $\mu$ . If there are infinitely many cosets, suppose for contradiction that $\mu(H) > 0$ , and pick any sequence $(C_n)_{n \geq 0}$ of distinct cosets of $H$ . Then $$1 = \mu(G) \geq \mu\left(\bigcup_{n \geq 0} C_n\right) = \sum_{n = 0}^\infty \mu(C_n) = \sum_{n=0}^\infty \mu(H) = \infty,$$ a contradiction. Lemma 2. Let $G$ be a group such that $G/Z(G)$ is cyclic. Then $G$ is abelian. Proof of Lemma 2: Let $g \in G$ such that $gZ(G)$ generates $G/Z(G)$ . Let $x,y \in G$ be arbitrary. Then $x \in g^nZ(G)$ , $y \in g^mZ(G)$ for some $n,m \in \mathbb{Z}$ . Write $x = g^n z$ , $y = g^m z'$ for some $z, z' \in Z(G)$ . Since $g$ , $z$ , and $z'$ pairwise commute, $x$ and $y$ commute. Proof of Theorem: Let $$X = \{(g,g') \in G \times G : [g,g'] = e\} = \{(g,g') \in G \times G : g' \in Z(g)\},$$ where $Z(g)$ denotes the centralizer of $g$ in $G$ . By Fubini's Theorem, the measure of $X$ (which we aim to show is at most $5/8$ ) equals $\int_G \mu(Z(g)) \; \mathrm{d}\mu(g)$ . The center of $G$ (which we will denote by $Z$ ) is closed, since it can be written the intersection of closed sets $\bigcap_{g \in G} Z(g)$ ( $Z(g)$ is the inverse image of $\{e\}$ under the continuous map $x \mapsto xgx^{-1} : G \to G$ ). Thus, $$\begin{multline*}\mu(X) = \int_G \mu(Z(g)) \;\mathrm{d}\mu(g) = \int_Z \mu(Z(g)) \;\mathrm{d}\mu(g) + \int_{G \setminus Z} \mu(Z(g)) \;\mathrm{d}\mu(g)\\ = \mu(Z) + \int_{G \setminus Z} \mu(Z(g)) \;\mathrm{d}\mu(g).\end{multline*}$$ If $g \in G\setminus Z$ then $Z(g) \neq G$ , so $[G : Z(g)] \geq 2$ , so $\mu(Z(g)) \leq 1/2$ by Lemma 1. This means that $$\mu(X) \leq \mu(Z) + \frac{1}{2}\mu(G \setminus Z) = \mu(Z) + \frac{1}{2}\left(1 - \mu(Z)\right) = \frac{\mu(Z) + 1}{2}.$$ By Lemma 2, we must have $[G : Z] \geq 4$ (or else $G/Z$ would be cyclic), so by Lemma 1 again, we have $\mu(Z) \leq 1/4$ . Therefore, $\mu(X) \leq 5/8$ , as desired. Corollary (5/8 Theorem for Finite Groups) Let $G$ be a finite group. If the probability that two randomly chosen elements of $G$ commute is greater than $5/8$ , then $G$ is abelian. My question is this: Are there any interesting applications of this result? Interesting examples may include: A finite (or compact) group which is not obviously abelian, but for which it is relatively easy to prove that elements commute with probability >5/8. A non-abelian group which has no compact Hausdorff topology making it into a topological group because ""too many pairs of elements commute"" (i.e. a proof by contradiction that no such topology exists, using the result of the 5/8 Theorem). These are the kinds of applications I was able to imagine, but there are probably many others; I'd be interested to hear if anyone has come across any application of the 5/8 Theorem!","The 5/8 theorem for compact groups says the following: Theorem (5/8 Theorem for Compact Groups) Let be a compact Hausdorff topological group with Haar measure . If is not abelian then the probability that two elements of commute is at most . More precisely, if is not abelian then If you don't care or already know how this is proved, skip down the page, past the next horizontal rule. Lemma 1. Let be a compact Hausdorff topological group with a Borel subgroup . Let be the Haar measure on . Then (this is by convention when is infinite). Proof of Lemma 1: The cosets of partition , and all have the same measure by translation-invariance of . If there are finitely many cosets, the result follows directly from additivity of . If there are infinitely many cosets, suppose for contradiction that , and pick any sequence of distinct cosets of . Then a contradiction. Lemma 2. Let be a group such that is cyclic. Then is abelian. Proof of Lemma 2: Let such that generates . Let be arbitrary. Then , for some . Write , for some . Since , , and pairwise commute, and commute. Proof of Theorem: Let where denotes the centralizer of in . By Fubini's Theorem, the measure of (which we aim to show is at most ) equals . The center of (which we will denote by ) is closed, since it can be written the intersection of closed sets ( is the inverse image of under the continuous map ). Thus, If then , so , so by Lemma 1. This means that By Lemma 2, we must have (or else would be cyclic), so by Lemma 1 again, we have . Therefore, , as desired. Corollary (5/8 Theorem for Finite Groups) Let be a finite group. If the probability that two randomly chosen elements of commute is greater than , then is abelian. My question is this: Are there any interesting applications of this result? Interesting examples may include: A finite (or compact) group which is not obviously abelian, but for which it is relatively easy to prove that elements commute with probability >5/8. A non-abelian group which has no compact Hausdorff topology making it into a topological group because ""too many pairs of elements commute"" (i.e. a proof by contradiction that no such topology exists, using the result of the 5/8 Theorem). These are the kinds of applications I was able to imagine, but there are probably many others; I'd be interested to hear if anyone has come across any application of the 5/8 Theorem!","G \mu G G 5/8 G (\mu \times \mu)(\{(g,g') \in G \times G : [g,g'] = e\}) \leq 5/8. G H \mu G \mu(H) = 1/[G:H] 0 [G:H] H G \mu \mu \mu(H) > 0 (C_n)_{n \geq 0} H 1 = \mu(G) \geq \mu\left(\bigcup_{n \geq 0} C_n\right) = \sum_{n = 0}^\infty \mu(C_n) = \sum_{n=0}^\infty \mu(H) = \infty, G G/Z(G) G g \in G gZ(G) G/Z(G) x,y \in G x \in g^nZ(G) y \in g^mZ(G) n,m \in \mathbb{Z} x = g^n z y = g^m z' z, z' \in Z(G) g z z' x y X = \{(g,g') \in G \times G : [g,g'] = e\} = \{(g,g') \in G \times G : g' \in Z(g)\}, Z(g) g G X 5/8 \int_G \mu(Z(g)) \; \mathrm{d}\mu(g) G Z \bigcap_{g \in G} Z(g) Z(g) \{e\} x \mapsto xgx^{-1} : G \to G \begin{multline*}\mu(X) = \int_G \mu(Z(g)) \;\mathrm{d}\mu(g) = \int_Z \mu(Z(g)) \;\mathrm{d}\mu(g) + \int_{G \setminus Z} \mu(Z(g)) \;\mathrm{d}\mu(g)\\
= \mu(Z) + \int_{G \setminus Z} \mu(Z(g)) \;\mathrm{d}\mu(g).\end{multline*} g \in G\setminus Z Z(g) \neq G [G : Z(g)] \geq 2 \mu(Z(g)) \leq 1/2 \mu(X) \leq \mu(Z) + \frac{1}{2}\mu(G \setminus Z) = \mu(Z) + \frac{1}{2}\left(1 - \mu(Z)\right) = \frac{\mu(Z) + 1}{2}. [G : Z] \geq 4 G/Z \mu(Z) \leq 1/4 \mu(X) \leq 5/8 G G 5/8 G","['probability', 'abstract-algebra', 'group-theory', 'measure-theory', 'big-list']"
67,Simulate repeated rolls of a 7-sided die with a 6-sided die,Simulate repeated rolls of a 7-sided die with a 6-sided die,,"What is the most efficient way to simulate a 7-sided die with a 6-sided die? I've put some thought into it but I'm not sure I get somewhere specifically. To create a 7-sided die we can use a rejection technique. 3-bits give uniform 1-8 and we need uniform 1-7 which means that we have to reject 1/8 i.e. 12.5% rejection probability. To create $n * 7$-sided die rolls we need $\lceil log_2(  7^n ) \rceil$ bits. This means that our rejection probability is $p_r(n)=1-\frac{7^n}{2^{\lceil log_2(  7^n ) \rceil}}$. It turns out that the rejection probability varies wildly but for $n=26$ we get $p_r(26) = 1 - \frac{7^{26}}{2^{\lceil log_2(7^{26}) \rceil}} = 1-\frac{7^{26}}{2^{73}} \approx 0.6\%$ rejection probability which is quite good. This means that we can generate with good odds 26 7-die rolls out of 73 bits. Similarly, if we throw a fair die $n$ times we get number from $0...(6^n-1)$ which gives us $\lfloor log_2(6^{n}) \rfloor$ bits by rejecting everything which is above $2^{\lfloor log_2(6^{n}) \rfloor}$. Consequently the rejection probability is $p_r(n)=1-\frac{2^{\lfloor log_2(  6^{n} ) \rfloor}}{6^n}$. Again this varies wildly but for $n = 53$, we get $p_r(53) = 1-\frac{2^{137}}{6^{53}} \approx 0.2\%$ which is excellent. As a result, we can roll the 6-face die 53 times and get ~137 bits. This means that we get about $\frac{137}{53} * \frac{26}{73} = 0.9207$ 7-face die rolls out of 6-face die rolls which is close to the optimum $\frac{log 7}{log6} = 0.9208$. Is there a way to get the optimum? Is there an way to find those $n$ numbers as above that minimize errors? Is there relevant theory I could have a look at? P.S. Relevant python expressions: min([ (i, round(1000*(1-(  7**i )  /  (2**ceil(log(7**i,2)))) )/10)  for i in xrange(1,100)], key=lambda x: x[1]) min([ (i, round(1000*(1- ((2**floor(log(6**i,2))) / (  6**i ))   )    )/10)  for i in xrange(1,100)], key=lambda x: x[1]) P.S.2 Thanks to @Erick Wong for helping me get the question right with his great comments. Related question: Is there a way to simulate any $n$-sided die using a fixed set of die types for all $n$?","What is the most efficient way to simulate a 7-sided die with a 6-sided die? I've put some thought into it but I'm not sure I get somewhere specifically. To create a 7-sided die we can use a rejection technique. 3-bits give uniform 1-8 and we need uniform 1-7 which means that we have to reject 1/8 i.e. 12.5% rejection probability. To create $n * 7$-sided die rolls we need $\lceil log_2(  7^n ) \rceil$ bits. This means that our rejection probability is $p_r(n)=1-\frac{7^n}{2^{\lceil log_2(  7^n ) \rceil}}$. It turns out that the rejection probability varies wildly but for $n=26$ we get $p_r(26) = 1 - \frac{7^{26}}{2^{\lceil log_2(7^{26}) \rceil}} = 1-\frac{7^{26}}{2^{73}} \approx 0.6\%$ rejection probability which is quite good. This means that we can generate with good odds 26 7-die rolls out of 73 bits. Similarly, if we throw a fair die $n$ times we get number from $0...(6^n-1)$ which gives us $\lfloor log_2(6^{n}) \rfloor$ bits by rejecting everything which is above $2^{\lfloor log_2(6^{n}) \rfloor}$. Consequently the rejection probability is $p_r(n)=1-\frac{2^{\lfloor log_2(  6^{n} ) \rfloor}}{6^n}$. Again this varies wildly but for $n = 53$, we get $p_r(53) = 1-\frac{2^{137}}{6^{53}} \approx 0.2\%$ which is excellent. As a result, we can roll the 6-face die 53 times and get ~137 bits. This means that we get about $\frac{137}{53} * \frac{26}{73} = 0.9207$ 7-face die rolls out of 6-face die rolls which is close to the optimum $\frac{log 7}{log6} = 0.9208$. Is there a way to get the optimum? Is there an way to find those $n$ numbers as above that minimize errors? Is there relevant theory I could have a look at? P.S. Relevant python expressions: min([ (i, round(1000*(1-(  7**i )  /  (2**ceil(log(7**i,2)))) )/10)  for i in xrange(1,100)], key=lambda x: x[1]) min([ (i, round(1000*(1- ((2**floor(log(6**i,2))) / (  6**i ))   )    )/10)  for i in xrange(1,100)], key=lambda x: x[1]) P.S.2 Thanks to @Erick Wong for helping me get the question right with his great comments. Related question: Is there a way to simulate any $n$-sided die using a fixed set of die types for all $n$?",,"['probability', 'dice']"
68,birthday problem - expected number of collisions,birthday problem - expected number of collisions,,"There are many descriptions of the ""birthday problem"" on this site — the problem of finding the probability that in a group of $n$ people there will be any (= at least 2) sharing a birthday. I am wondering how to find instead the expected number of people sharing a birthday in a group of $n$ people. I remember that expectation means the weighted sum of the probabilities of each outcome: $$E[X]=\sum_{i=0}^{n-1}x_ip_i$$ And here $x$ must mean the number of collisions involving $i+1$ people, which is $n\choose i$. All $n$ people born on different days means no collisions, $i=0$; two people born on the same day means $n$ collisions, $i=1$; all $n$ people born on the same day means $n$ collisions, $i=n-1$. Since the probabilities of three or more people with the same birthday are vanishingly small compared to two people with the same birthday, and decreases faster than $x$ increases, is it correct to say that this expectation can be approximated by $$E[X]\approx {n\choose 0}p_{no\ collisions}+{n\choose 1}p_{one\ collision}$$ This doesn't look right to me and I'd appreciate some guidance. Sorry - edited to change ${n\choose 1}$ to ${n\choose 0}$ in second equation. Sloppy of me.","There are many descriptions of the ""birthday problem"" on this site — the problem of finding the probability that in a group of $n$ people there will be any (= at least 2) sharing a birthday. I am wondering how to find instead the expected number of people sharing a birthday in a group of $n$ people. I remember that expectation means the weighted sum of the probabilities of each outcome: $$E[X]=\sum_{i=0}^{n-1}x_ip_i$$ And here $x$ must mean the number of collisions involving $i+1$ people, which is $n\choose i$. All $n$ people born on different days means no collisions, $i=0$; two people born on the same day means $n$ collisions, $i=1$; all $n$ people born on the same day means $n$ collisions, $i=n-1$. Since the probabilities of three or more people with the same birthday are vanishingly small compared to two people with the same birthday, and decreases faster than $x$ increases, is it correct to say that this expectation can be approximated by $$E[X]\approx {n\choose 0}p_{no\ collisions}+{n\choose 1}p_{one\ collision}$$ This doesn't look right to me and I'd appreciate some guidance. Sorry - edited to change ${n\choose 1}$ to ${n\choose 0}$ in second equation. Sloppy of me.",,"['probability', 'calendar-computations', 'birthday']"
69,Difference between logarithm of an expectation value and expectation value of a logarithm,Difference between logarithm of an expectation value and expectation value of a logarithm,,"Assuming I have a always positive random variable $X$, $X \in \mathbb{R}$, $X > 0$. Then  I am now interested in the difference between the following two expectation values: $E \left[ \ln X \right]$ $\ln E \left[ X \right]$ Is one maybe always a lower/upper bound of the other? Many thanks in advance...","Assuming I have a always positive random variable $X$, $X \in \mathbb{R}$, $X > 0$. Then  I am now interested in the difference between the following two expectation values: $E \left[ \ln X \right]$ $\ln E \left[ X \right]$ Is one maybe always a lower/upper bound of the other? Many thanks in advance...",,"['probability', 'random', 'parameter-estimation']"
70,Is there any difference between $P$ and $\Pr$ to represent probabilities?,Is there any difference between  and  to represent probabilities?,P \Pr,"I have come across both $P(\dots)$ and $\Pr(\dots)$ being used to represent probabilities. Is there any difference in the meaning of these notations, or are they just different shorthands? I seem to come by $\Pr(\dots)$ more often in Bayesian probability contexts, though I wouldn't say that's a rule.","I have come across both $P(\dots)$ and $\Pr(\dots)$ being used to represent probabilities. Is there any difference in the meaning of these notations, or are they just different shorthands? I seem to come by $\Pr(\dots)$ more often in Bayesian probability contexts, though I wouldn't say that's a rule.",,"['probability', 'notation']"
71,Criteria for being a true martingale,Criteria for being a true martingale,,Could you kindly list here all the criteria you know which guarantee that a continuous local martingale is in fact a true martingale? Which of these are valid for a general local martingale (non necessarily continuous)? Possible references to the listed results would be appreciated.,Could you kindly list here all the criteria you know which guarantee that a continuous local martingale is in fact a true martingale? Which of these are valid for a general local martingale (non necessarily continuous)? Possible references to the listed results would be appreciated.,,"['probability', 'stochastic-processes', 'martingales']"
72,Probability distribution in the coupon collector's problem,Probability distribution in the coupon collector's problem,,"I'm trying to solve the well known Coupon Collector's Problem by explicitly finding the probability distribution (so far all the methods I read involve using some sort of trick). However, I'm not having much luck getting anywhere as combinatorics is not something I'm particularly good at. The Coupon Collector's Problem is stated as: There are $m$ different kinds of coupons to be collected from boxes. Assuming each type of coupon is equally likely to be found per box, what's the expected amount of boxes one has to buy to collect all types of coupons? What I'm attempting: Let $N$ be the random variable associated with the number of boxes one has to buy to find all coupons. Then $P(N=n)=\frac{|A_n|}{|\Omega _n|}$, where $A_n$ is the set of all outcomes such that all types of coupons are observed in $n$ buys, and $\Omega _n$ is the set of all the possible outcomes in $n$ buys. I think $|\Omega _n| = m^n$, but I'm not even sure about that anymore, as all my attempts so far led to garbage probabilities that either diverged or didn't sum up to 1.","I'm trying to solve the well known Coupon Collector's Problem by explicitly finding the probability distribution (so far all the methods I read involve using some sort of trick). However, I'm not having much luck getting anywhere as combinatorics is not something I'm particularly good at. The Coupon Collector's Problem is stated as: There are $m$ different kinds of coupons to be collected from boxes. Assuming each type of coupon is equally likely to be found per box, what's the expected amount of boxes one has to buy to collect all types of coupons? What I'm attempting: Let $N$ be the random variable associated with the number of boxes one has to buy to find all coupons. Then $P(N=n)=\frac{|A_n|}{|\Omega _n|}$, where $A_n$ is the set of all outcomes such that all types of coupons are observed in $n$ buys, and $\Omega _n$ is the set of all the possible outcomes in $n$ buys. I think $|\Omega _n| = m^n$, but I'm not even sure about that anymore, as all my attempts so far led to garbage probabilities that either diverged or didn't sum up to 1.",,"['probability', 'combinatorics', 'coupon-collector']"
73,Probability of a point taken from a certain normal distribution will be greater than a point taken from another?,Probability of a point taken from a certain normal distribution will be greater than a point taken from another?,,"Let's say I have one point that will be taken randomly from a normal distribution with mean $\mu_1$ and standard deviation $\sigma_1$.  Let's say I have another point that is taken much in the same way from another normal distribution with mean $\mu_2$ and standard deviation $\sigma_2$;. How can I compute the probability, given $\mu_1$, $\mu_2$, $\sigma_1$, and $\sigma_2$, that my first point will be larger than the second? I am sort of interested in the reasoning behind an ""analytic"" answer (or as analytic as you can possibly get with the normal distribution, which isn't that much), but I am more importantly looking for an algorithm of computing this probability, as it will be used in a simulation/model. Does anyone know where I could get started on reasoning through this? Note: For actual computation, having a table of values of the % of the curve within a given multiple of the standard deviation is feasible in my situation.","Let's say I have one point that will be taken randomly from a normal distribution with mean $\mu_1$ and standard deviation $\sigma_1$.  Let's say I have another point that is taken much in the same way from another normal distribution with mean $\mu_2$ and standard deviation $\sigma_2$;. How can I compute the probability, given $\mu_1$, $\mu_2$, $\sigma_1$, and $\sigma_2$, that my first point will be larger than the second? I am sort of interested in the reasoning behind an ""analytic"" answer (or as analytic as you can possibly get with the normal distribution, which isn't that much), but I am more importantly looking for an algorithm of computing this probability, as it will be used in a simulation/model. Does anyone know where I could get started on reasoning through this? Note: For actual computation, having a table of values of the % of the curve within a given multiple of the standard deviation is feasible in my situation.",,"['probability', 'normal-distribution']"
74,Does exceptionalism persist as sample size gets large?,Does exceptionalism persist as sample size gets large?,,"Which of the following is more surprising? In a group of 100 people, the tallest person is one inch taller than the second tallest person. In a group of one billion people, the tallest person is one inch taller than the second tallest person. Put more precisely, suppose we have a normal distribution with given mean $\mu$ and standard deviation $\sigma$. If we sample from this distribution $N$ times, what is the expected difference between the largest and second largest values in our sample? In particular, does this expected difference go to zero as $N$ grows? In another question , it is explained how to compute the distribution $MAX_N$ of the maximum, but I don't see how to extract an estimate for the expected value of the maximum from that answer. Though $E(MAX_N)-E(MAX_{N-1})$ isn't the number I'm looking for, it might be a good enough estimate to determine if the value goes to zero as $N$ gets large.","Which of the following is more surprising? In a group of 100 people, the tallest person is one inch taller than the second tallest person. In a group of one billion people, the tallest person is one inch taller than the second tallest person. Put more precisely, suppose we have a normal distribution with given mean $\mu$ and standard deviation $\sigma$. If we sample from this distribution $N$ times, what is the expected difference between the largest and second largest values in our sample? In particular, does this expected difference go to zero as $N$ grows? In another question , it is explained how to compute the distribution $MAX_N$ of the maximum, but I don't see how to extract an estimate for the expected value of the maximum from that answer. Though $E(MAX_N)-E(MAX_{N-1})$ isn't the number I'm looking for, it might be a good enough estimate to determine if the value goes to zero as $N$ gets large.",,"['probability', 'statistics']"
75,Expectation of the min of two independent random variables?,Expectation of the min of two independent random variables?,,"How do you compute the minimum of two independent random variables in the general case ? In the particular case there would be two uniform variables with a difference support, how should one proceed ? EDIT: specified that they were independent and that the uniform variables do not have obligatory the same support range.","How do you compute the minimum of two independent random variables in the general case ? In the particular case there would be two uniform variables with a difference support, how should one proceed ? EDIT: specified that they were independent and that the uniform variables do not have obligatory the same support range.",,"['probability', 'probability-distributions', 'random-variables', 'uniform-distribution']"
76,Random Walk Without Repetitions,Random Walk Without Repetitions,,"Suppose that we simulated a random walk on $\mathbb Z$ starting at $0$. At each step, we transition from position $x$ to position $x-3,\,x-2,\,x-1,\,x+1,\,x+2,$ or $x+3$ with equal probability. If we ever move to a position we have been at before, we stop. What is the probability that we will eventually reach (and stop at) $0$ again? This is to say, we consider that walks like $0,2,4,3,2$ end at $2$ because they repeated and walks like $0,2,4,3,1,0$ reach $0$ again - and are interested in the probability of the latter case. I'm not sure what methods I can use to dispatch such a problem; if the step size were $1$ rather than $2$, the answer is obviously $\frac{1}2$, as we would need to immediately undo our first step, otherwise we'd never return. If the step size is $1$ or $2$, then we can solve the problem by noting that we can never leap over any pair of positions $(x,x+1)$ - which allows us to classify and count every possible walk (e.g. walks of the form $0,1,3,5,\ldots,2n+1,2n,2n-2,\ldots,0$ form one class). The probability of returning to $0$ is $\frac{7}{18}$ in this case. However, no such approach extends to the case above. By simulating all random walks of length $8$ or less, I have proven that the probability $p$ satisfies $.32<p<.39$. Running many random trials suggests that $p$ is very close to the lower bound.","Suppose that we simulated a random walk on $\mathbb Z$ starting at $0$. At each step, we transition from position $x$ to position $x-3,\,x-2,\,x-1,\,x+1,\,x+2,$ or $x+3$ with equal probability. If we ever move to a position we have been at before, we stop. What is the probability that we will eventually reach (and stop at) $0$ again? This is to say, we consider that walks like $0,2,4,3,2$ end at $2$ because they repeated and walks like $0,2,4,3,1,0$ reach $0$ again - and are interested in the probability of the latter case. I'm not sure what methods I can use to dispatch such a problem; if the step size were $1$ rather than $2$, the answer is obviously $\frac{1}2$, as we would need to immediately undo our first step, otherwise we'd never return. If the step size is $1$ or $2$, then we can solve the problem by noting that we can never leap over any pair of positions $(x,x+1)$ - which allows us to classify and count every possible walk (e.g. walks of the form $0,1,3,5,\ldots,2n+1,2n,2n-2,\ldots,0$ form one class). The probability of returning to $0$ is $\frac{7}{18}$ in this case. However, no such approach extends to the case above. By simulating all random walks of length $8$ or less, I have proven that the probability $p$ satisfies $.32<p<.39$. Running many random trials suggests that $p$ is very close to the lower bound.",,"['probability', 'random-walk']"
77,Expiring coupon collector's problem,Expiring coupon collector's problem,,"The well-studied coupon collector's problem asks, given $N$ different coupons from which coupons are being drawn with equal probability and with replacement: How many coupons do you expect to need to draw before having drawn each coupon at least once? For large $N$, the expected number of draws is known to be $\Theta(N\log N)$.  What is known about the following variation? One coupon is drawn each day, and each coupon expires $M \ge N$ days after being drawn.   How many coupons do you expect to need to draw before having at least one unexpired copy of each coupon? Presumably if $M$ is large enough (say, $M\in\Omega(N\log N)$), it will have no effect on the problem, and the expected number of draws will still be $\Theta(N\log N)$.  On the other hand, if $M=N$, a perfect run of $N$ distinct coupons is required.  For any $N$ consecutive days, the probability of this happening is $$ \frac{N!}{N^N}\sim \frac{\sqrt{2\pi N}}{e^N},$$ and so the expected number of draws must grow exponentially with $N$.  This is a large change in the expected time (from almost linear to exponential) corresponding to a small change in the expiration behavior (from almost linear to linear).  Can anything precise be said about the intermediate cases?","The well-studied coupon collector's problem asks, given $N$ different coupons from which coupons are being drawn with equal probability and with replacement: How many coupons do you expect to need to draw before having drawn each coupon at least once? For large $N$, the expected number of draws is known to be $\Theta(N\log N)$.  What is known about the following variation? One coupon is drawn each day, and each coupon expires $M \ge N$ days after being drawn.   How many coupons do you expect to need to draw before having at least one unexpired copy of each coupon? Presumably if $M$ is large enough (say, $M\in\Omega(N\log N)$), it will have no effect on the problem, and the expected number of draws will still be $\Theta(N\log N)$.  On the other hand, if $M=N$, a perfect run of $N$ distinct coupons is required.  For any $N$ consecutive days, the probability of this happening is $$ \frac{N!}{N^N}\sim \frac{\sqrt{2\pi N}}{e^N},$$ and so the expected number of draws must grow exponentially with $N$.  This is a large change in the expected time (from almost linear to exponential) corresponding to a small change in the expiration behavior (from almost linear to linear).  Can anything precise be said about the intermediate cases?",,"['probability', 'combinatorics', 'coupon-collector']"
78,A disease spreading through a triangular population,A disease spreading through a triangular population,,"I have run into this problem in my research, which I'm presenting under a different guise to avoid going into unnecessary background. Consider a population that is connected in a triangular manner, as shown in the figure below. The root node has a disease, which spreads downwards through the population as follows: With probability $p$ a diseased parent node infects only one of its two child nodes (chosen randomly); and with probability $1-p$ it infects both of them A child node becomes diseased if it is infected by one or two parent nodes I am interested in the asymptotic behavior of the expected number of diseased nodes at level $k$. Simulations show that the expected number of diseased nodes grows asymptotically linearly with the number of levels. Moreover, the slope of this relationship decreases approximately linearly with $p$ (obviously, when $p = 0$ the slope is $1$, as everyone gets diseased; when $p = 1$ the slope is $0$ as the number of diseased nodes remains at $1$ at every level). So the behavior seems to follow: $E(\text{diseased nodes at level n})=(1 - p)n$, at least to a very good approximation.","I have run into this problem in my research, which I'm presenting under a different guise to avoid going into unnecessary background. Consider a population that is connected in a triangular manner, as shown in the figure below. The root node has a disease, which spreads downwards through the population as follows: With probability $p$ a diseased parent node infects only one of its two child nodes (chosen randomly); and with probability $1-p$ it infects both of them A child node becomes diseased if it is infected by one or two parent nodes I am interested in the asymptotic behavior of the expected number of diseased nodes at level $k$. Simulations show that the expected number of diseased nodes grows asymptotically linearly with the number of levels. Moreover, the slope of this relationship decreases approximately linearly with $p$ (obviously, when $p = 0$ the slope is $1$, as everyone gets diseased; when $p = 1$ the slope is $0$ as the number of diseased nodes remains at $1$ at every level). So the behavior seems to follow: $E(\text{diseased nodes at level n})=(1 - p)n$, at least to a very good approximation.",,"['probability', 'combinatorics', 'graph-theory', 'asymptotics', 'expectation']"
79,A coin flipping game,A coin flipping game,,"I've been thinking about the following game for a while and am curious if anyone has any ideas of how to analyze it. Problem description Say I have two biased coins: coin 1 that shows heads with probability $p$ and coin 2 that shows heads with probability $q$ . You and I both know the statistics of the coins. The game proceeds in multiple rounds as follows: In the starting round $n=0$ : I (privately) pick a coin and flip it, we both observe the outcome you decide to make a guess of which coin I just flipped, or continue watching if you guess correctly, I pay you $\$100$ ; if you guess incorrectly, you receive no reward and the game is over At each subsequent round $n\ge 1$ : I decide to stay with my current coin or reach into my pocket and swap out the current coin for the other coin you can see whether I swapped out the coin or not (assume I must switch if I reach into my pocket) I flip the coin and we both observe the outcome you decide to guess which coin was just flipped, or keep watching if you guess correctly, I pay you $\$100\cdot\delta^n$ , where $\delta\in(0,1)$ ; if you guess incorrectly the game ends with you getting nothing Question I want to find the ""best"" switching strategy to minimize the (expected) amount of money I have to pay you. Notes The probabilities $p$ and $q$ can take on any value, but let's assume that they cannot be equal. Since you are trying to maximize your reward, the discount factor $\delta$ incentives you to guess correctly as quickly as possible. Since there are only two coins and you observe when I switch, you are trying to discern between two possible coin sequences, one where the initial coin was coin 1 and the other where the initial coin was coin 2. My first thoughts are that I would want to keep the empirical averages (of the two sequences) as close as possible to each other. Intuitively this will be easy if $p$ and $q$ are close, but hard if they are far apart.","I've been thinking about the following game for a while and am curious if anyone has any ideas of how to analyze it. Problem description Say I have two biased coins: coin 1 that shows heads with probability and coin 2 that shows heads with probability . You and I both know the statistics of the coins. The game proceeds in multiple rounds as follows: In the starting round : I (privately) pick a coin and flip it, we both observe the outcome you decide to make a guess of which coin I just flipped, or continue watching if you guess correctly, I pay you ; if you guess incorrectly, you receive no reward and the game is over At each subsequent round : I decide to stay with my current coin or reach into my pocket and swap out the current coin for the other coin you can see whether I swapped out the coin or not (assume I must switch if I reach into my pocket) I flip the coin and we both observe the outcome you decide to guess which coin was just flipped, or keep watching if you guess correctly, I pay you , where ; if you guess incorrectly the game ends with you getting nothing Question I want to find the ""best"" switching strategy to minimize the (expected) amount of money I have to pay you. Notes The probabilities and can take on any value, but let's assume that they cannot be equal. Since you are trying to maximize your reward, the discount factor incentives you to guess correctly as quickly as possible. Since there are only two coins and you observe when I switch, you are trying to discern between two possible coin sequences, one where the initial coin was coin 1 and the other where the initial coin was coin 2. My first thoughts are that I would want to keep the empirical averages (of the two sequences) as close as possible to each other. Intuitively this will be easy if and are close, but hard if they are far apart.","p q n=0 \100 n\ge 1 \100\cdot\delta^n \delta\in(0,1) p q \delta p q","['probability', 'puzzle', 'game-theory']"
80,Distribution of roots of complex polynomials,Distribution of roots of complex polynomials,,I generated random quadratic and cubic polynomials with coefficients in $\mathbb{C}$ uniformly distributed in the unit disk $|z| \le 1$. The distribution of the roots of 10000 of these polynomials are shown below (left: quadratic; right: cubic). What explains these distributions? In particular: (1) Why the relative paucity of roots near the origin. (2) Why is the density concentrated in $\frac{1}{2} \le |z| \le 1$? (3) Why is the cubic distribution sharper than the quadratic?,I generated random quadratic and cubic polynomials with coefficients in $\mathbb{C}$ uniformly distributed in the unit disk $|z| \le 1$. The distribution of the roots of 10000 of these polynomials are shown below (left: quadratic; right: cubic). What explains these distributions? In particular: (1) Why the relative paucity of roots near the origin. (2) Why is the density concentrated in $\frac{1}{2} \le |z| \le 1$? (3) Why is the cubic distribution sharper than the quadratic?,,"['probability', 'complex-analysis', 'polynomials', 'complex-numbers', 'roots']"
81,"Three coins are tossed. If one of them shows a tails, what is the probability that all three coins show tails? [duplicate]","Three coins are tossed. If one of them shows a tails, what is the probability that all three coins show tails? [duplicate]",,"This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 4 years ago . To solve the following problem Three coins are tossed. If one of them shows a tails, what is the probability that all three coins show tails? I tried $1\cdot\frac12\cdot\frac12$ where $1$ is the probability for the first coin that shows tails, and $\frac12$ is the probability for the other two coins that can be heads or tails. This answer does not match the expected one. Where am I wrong?","This question already has answers here : In a family with two children, what are the chances, if one of the children is a girl, that both children are girls? (21 answers) Closed 4 years ago . To solve the following problem Three coins are tossed. If one of them shows a tails, what is the probability that all three coins show tails? I tried where is the probability for the first coin that shows tails, and is the probability for the other two coins that can be heads or tails. This answer does not match the expected one. Where am I wrong?",1\cdot\frac12\cdot\frac12 1 \frac12,['probability']
82,A dice is rolled until a $6$ occurs. What is the probability that the sum including the $6$ is even?,A dice is rolled until a  occurs. What is the probability that the sum including the  is even?,6 6,"A game is played where a standard six sided dice is rolled until a $6$ is rolled, and the sum of all of the rolls up to and including the $6$ is taken. What is the probability that this sum is even? I know that this is a geometric distribution and the expected number of rolls is $\frac1{1/6} = 6$ rolls until a $6$ occurs, along with the expected value being $21$ ($6$ rolls times expected value of $3.5$ per roll), but I'm not certain how to proceed from there. Would the expected range (if it is even relevant) be from $11 = 1·5+6$ to $31 = 5·5+6$? The answer is supposedly $\frac47$. I'm also curious about how this question would change if the stopping number was anything else, say a $3$ stopping the sequence rather than a $6$. Thank you in advance!","A game is played where a standard six sided dice is rolled until a $6$ is rolled, and the sum of all of the rolls up to and including the $6$ is taken. What is the probability that this sum is even? I know that this is a geometric distribution and the expected number of rolls is $\frac1{1/6} = 6$ rolls until a $6$ occurs, along with the expected value being $21$ ($6$ rolls times expected value of $3.5$ per roll), but I'm not certain how to proceed from there. Would the expected range (if it is even relevant) be from $11 = 1·5+6$ to $31 = 5·5+6$? The answer is supposedly $\frac47$. I'm also curious about how this question would change if the stopping number was anything else, say a $3$ stopping the sequence rather than a $6$. Thank you in advance!",,"['probability', 'dice']"
83,"Prove that if events A and B are independent, then the complement events of A and B are also independent.","Prove that if events A and B are independent, then the complement events of A and B are also independent.",,"I know that: $$\begin{gathered}P\left(A\cap B\right)=P\left(A\right)P\left(B\right)\\ P\left(A^{C}\right)=1-P\left(A\right)\\ P\left(B^{C}\right)=1-P\left(B\right) \end{gathered} $$ My proof so far: $$\begin{gathered}P\left(A^{C}\cap B^{C}\right)=\left(1-P\left(A\right)\right)\left(1-P\left(B\right)\right)=\\ 1-P\left(B\right)-P\left(A\right)+P\left(A\right)P\left(B\right)=1-P\left(B\right)-P\left(A\right)+P\left(A\cap B\right) \end{gathered} $$ After that, I'm stuck.  Any help would be appreciated.","I know that: $$\begin{gathered}P\left(A\cap B\right)=P\left(A\right)P\left(B\right)\\ P\left(A^{C}\right)=1-P\left(A\right)\\ P\left(B^{C}\right)=1-P\left(B\right) \end{gathered} $$ My proof so far: $$\begin{gathered}P\left(A^{C}\cap B^{C}\right)=\left(1-P\left(A\right)\right)\left(1-P\left(B\right)\right)=\\ 1-P\left(B\right)-P\left(A\right)+P\left(A\right)P\left(B\right)=1-P\left(B\right)-P\left(A\right)+P\left(A\cap B\right) \end{gathered} $$ After that, I'm stuck.  Any help would be appreciated.",,['probability']
84,Question about Monty Hall if you already knew a bad door beforehand,Question about Monty Hall if you already knew a bad door beforehand,,"So the setup of the scenario here is exactly the traditional Monty Hall problem. Except, before the game starts, you decide to cheat and open a door and it happens to be a goat. Before you can peek at the two other doors, the game begins, and you pick a door that's not the one you just peeked into (obviously, because you peeked a goat). Here it seems the probability to win a car is $\frac{1}{2}$, because you improved your original $\frac{1}{3}$ chance of winning a car by cheating. Then the game host opens the same door you just peeked at before the game started (knowing it was a goat, like the traditional Monty Hall problem). Is it still a $\frac{2}{3}$ chance of winning the car if you switch, even though you already knew the informatiom beforehand? Or does it still remain $\frac{1}{2}$ because you already knew the information before, so you just screwed yourself out of the better $\frac{2}{3}$ probability by cheating? If you originally picked a door with a goat, then the game host must pick the door you peeked at, because the other door contains the car. In this situation, it doesn't seem like anything changes because you already knew the door the game host opened beforehand by cheating. If you originally picked a door with a car, the game host can open either other door, because they both have goats. If the game host opens the door you did not peek at and reveals a goat, then you know with $100\%$ probability that the door you originally picked contains the winning car. However, if the game host opens the door you peeked at, then it seems like the same situation in the paragraph I described before this one.","So the setup of the scenario here is exactly the traditional Monty Hall problem. Except, before the game starts, you decide to cheat and open a door and it happens to be a goat. Before you can peek at the two other doors, the game begins, and you pick a door that's not the one you just peeked into (obviously, because you peeked a goat). Here it seems the probability to win a car is $\frac{1}{2}$, because you improved your original $\frac{1}{3}$ chance of winning a car by cheating. Then the game host opens the same door you just peeked at before the game started (knowing it was a goat, like the traditional Monty Hall problem). Is it still a $\frac{2}{3}$ chance of winning the car if you switch, even though you already knew the informatiom beforehand? Or does it still remain $\frac{1}{2}$ because you already knew the information before, so you just screwed yourself out of the better $\frac{2}{3}$ probability by cheating? If you originally picked a door with a goat, then the game host must pick the door you peeked at, because the other door contains the car. In this situation, it doesn't seem like anything changes because you already knew the door the game host opened beforehand by cheating. If you originally picked a door with a car, the game host can open either other door, because they both have goats. If the game host opens the door you did not peek at and reveals a goat, then you know with $100\%$ probability that the door you originally picked contains the winning car. However, if the game host opens the door you peeked at, then it seems like the same situation in the paragraph I described before this one.",,"['probability', 'monty-hall']"
85,Correlation between three variables question,Correlation between three variables question,,"I was asked this question regarding correlation recently, and although it seems intuitive, I still haven't worked out the answer satisfactorily. I hope you can help me out with this seemingly simple question. Suppose I have three random variables $A$, $B$, $C$. Is it possible to have these three relationships satisfied? $$ \mathrm{corr}[A,B] = 0.9 $$ $$ \mathrm{corr}[B,C] = 0.8 $$ $$ \mathrm{corr}[A,C] = 0.1 $$ My intuition is that it is not possible, although I can't see right now how I can prove this conclusively.","I was asked this question regarding correlation recently, and although it seems intuitive, I still haven't worked out the answer satisfactorily. I hope you can help me out with this seemingly simple question. Suppose I have three random variables $A$, $B$, $C$. Is it possible to have these three relationships satisfied? $$ \mathrm{corr}[A,B] = 0.9 $$ $$ \mathrm{corr}[B,C] = 0.8 $$ $$ \mathrm{corr}[A,C] = 0.1 $$ My intuition is that it is not possible, although I can't see right now how I can prove this conclusively.",,"['probability', 'statistics', 'random-variables', 'correlation']"
86,Infinite expected value of a random variable,Infinite expected value of a random variable,,"How can a positive random variable $X$ which never takes on the value $+\infty$, have expected value $\mathbb{E}[X] = +\infty$?","How can a positive random variable $X$ which never takes on the value $+\infty$, have expected value $\mathbb{E}[X] = +\infty$?",,"['probability', 'infinity', 'random-variables']"
87,Proof that the hypergeometric distribution with large $N$ approaches the binomial distribution.,Proof that the hypergeometric distribution with large  approaches the binomial distribution.,N,"I have this problem on a textbook that doesn't have a solution. It is: Let $$f(x)=\frac{\binom{r}{x} \binom{N-r}{n-x}}{\binom{N}{n}}\;,$$ and keep $p=\dfrac{r}{N}$ fixed. Prove that $$\lim_{N \rightarrow \infty} f(x)=\binom{n}{x} p^x (1-p)^{n-x}\;.$$ Although I can find lots of examples using the binomial to approximate the hypergeometric for very large values of $N$, I couldn't find a full proof of this online.","I have this problem on a textbook that doesn't have a solution. It is: Let $$f(x)=\frac{\binom{r}{x} \binom{N-r}{n-x}}{\binom{N}{n}}\;,$$ and keep $p=\dfrac{r}{N}$ fixed. Prove that $$\lim_{N \rightarrow \infty} f(x)=\binom{n}{x} p^x (1-p)^{n-x}\;.$$ Although I can find lots of examples using the binomial to approximate the hypergeometric for very large values of $N$, I couldn't find a full proof of this online.",,"['probability', 'statistics']"
88,"Given two basis sets for a finite Hilbert space, does an unbiased vector exist?","Given two basis sets for a finite Hilbert space, does an unbiased vector exist?",,"Let $\{A_n\}$ and $\{B_n\}$ be two bases for an $N$-dimensional Hilbert space . Does there exist a unit vector $V$ such that: $$(V\cdot A_j)\;(A_j\cdot V) = (V\cdot B_j)\;(B_j\cdot V) = 1/N\;\;\; \ \text{for all} \ 1\le j\le N?$$ Notes and application: That the $\{A_n\}$ and $\{B_n\}$ are bases means that $$(A_j\cdot A_k) =\left\{\begin{array}{cl} 1&\;\text{if }j=k,\\ 0&\;\text{otherwise}.\end{array}\right.$$ In the physics notation, one might write $V\cdot A_j = \langle V\,|\,A_j\rangle$. In quantum mechanics, $P_{jk} = |\langle A_j|B_k\rangle|^2$ is the ""transition probability"" between the states $A_j$ and $B_k$. ""Unbiased"" means that there is no preference in the transition probabilities. A subject much studied in quantum information theory is ""mutually unbiased bases"" or MUBs . Two mutually unbiased bases satisfy $|\langle A_j|B_k\rangle|^2 = 1/N\;\;$ for all $j,k$. If it is true that the vector $V$ always exists, then one can multiply the rows and columns of any unitary matrix by complex phases so as to obtain a unitary matrix where each row and column individually sums to one . If true, then $U(n)$ can be written as follows: $$U(n) = \exp(i\alpha) \begin{pmatrix}1&0&0&0...\\0&e^{i\beta_1}&0&0...\\0&0&e^{i\beta_2}&0...\end{pmatrix} M \begin{pmatrix}1&0&0&0...\\0&e^{i\gamma_1}&0&0...\\0&0&e^{i\gamma_2}&0...\end{pmatrix}$$ where the Greek letters give complex phases and where $M$ is a ""magic"" unitary matrix, that is, $M$ has all rows and columns individually sum to 1. And $M$ can be written as $M=\exp(im)$ where $m$ is Hermitian and has all rows and columns sum to 0. What's significant about this is that the $m$ form a Lie algebra. Thus unitary matrices can be thought of as complex phases, plus a Lie algebra. This is a new decomposition of unitary matrices. Since $m$ is Hermitian and has all rows and columns sum to 0, it is equivalent to an $(n-1)\times(n-1)$ Hermitian matrix with no restriction on the row and column sums. And this shows that $U(n)$ is equivalent to complex phases added to an object (the $M$ matrices) that is equivalent to $U(n-1)$. This gives a recursive definition of unitary matrices entirely in terms of complex phases.","Let $\{A_n\}$ and $\{B_n\}$ be two bases for an $N$-dimensional Hilbert space . Does there exist a unit vector $V$ such that: $$(V\cdot A_j)\;(A_j\cdot V) = (V\cdot B_j)\;(B_j\cdot V) = 1/N\;\;\; \ \text{for all} \ 1\le j\le N?$$ Notes and application: That the $\{A_n\}$ and $\{B_n\}$ are bases means that $$(A_j\cdot A_k) =\left\{\begin{array}{cl} 1&\;\text{if }j=k,\\ 0&\;\text{otherwise}.\end{array}\right.$$ In the physics notation, one might write $V\cdot A_j = \langle V\,|\,A_j\rangle$. In quantum mechanics, $P_{jk} = |\langle A_j|B_k\rangle|^2$ is the ""transition probability"" between the states $A_j$ and $B_k$. ""Unbiased"" means that there is no preference in the transition probabilities. A subject much studied in quantum information theory is ""mutually unbiased bases"" or MUBs . Two mutually unbiased bases satisfy $|\langle A_j|B_k\rangle|^2 = 1/N\;\;$ for all $j,k$. If it is true that the vector $V$ always exists, then one can multiply the rows and columns of any unitary matrix by complex phases so as to obtain a unitary matrix where each row and column individually sums to one . If true, then $U(n)$ can be written as follows: $$U(n) = \exp(i\alpha) \begin{pmatrix}1&0&0&0...\\0&e^{i\beta_1}&0&0...\\0&0&e^{i\beta_2}&0...\end{pmatrix} M \begin{pmatrix}1&0&0&0...\\0&e^{i\gamma_1}&0&0...\\0&0&e^{i\gamma_2}&0...\end{pmatrix}$$ where the Greek letters give complex phases and where $M$ is a ""magic"" unitary matrix, that is, $M$ has all rows and columns individually sum to 1. And $M$ can be written as $M=\exp(im)$ where $m$ is Hermitian and has all rows and columns sum to 0. What's significant about this is that the $m$ form a Lie algebra. Thus unitary matrices can be thought of as complex phases, plus a Lie algebra. This is a new decomposition of unitary matrices. Since $m$ is Hermitian and has all rows and columns sum to 0, it is equivalent to an $(n-1)\times(n-1)$ Hermitian matrix with no restriction on the row and column sums. And this shows that $U(n)$ is equivalent to complex phases added to an object (the $M$ matrices) that is equivalent to $U(n-1)$. This gives a recursive definition of unitary matrices entirely in terms of complex phases.",,"['probability', 'vector-spaces', 'hilbert-spaces']"
89,Puzzle of gold coins in the bag,Puzzle of gold coins in the bag,,"At the end of Probability class, our professor gave us the following puzzle: There are 100 bags each with 100 coins, but only one of these bags has gold coins in it. The gold coin has weight of 1.01 grams and the other coins has weight of 1 gram. We are given a digital scale, but we can only use it once. How can we identify the bag of gold coins? After about 5 minutes waiting, our professor gave us the solution (the class had ended and he didn't want to wait any longer): Give the bags numbers from 0 through 99, then take 0 coins from the bag number 0, 1 coin from the bag number 1, 2 coins from the bag number 2, and so on until we take 99 coins from the bag number 99. Gather all the coins we have taken together and put them on the scale. Denote the weight of these coins as $W$ and the number of bag with gold coins in it as $N$, then we can identify the bag of gold coins using formula $$N=100(W-4950)$$   For instance, if the weight of all coins gathered is $4950.25$ grams, then using the formula above the bag number 25 has the gold coins in it. My questions are: How does the formula work? Where does it come from? Do we have other ways to solve this puzzle? If yes, how? If the digital scale is replaced by a traditional scale, the scale like symbol of libra or the scale in Shakespeare's drama: The Merchant of Venice (I don't know what is the name in English), then how do we solve this puzzle?","At the end of Probability class, our professor gave us the following puzzle: There are 100 bags each with 100 coins, but only one of these bags has gold coins in it. The gold coin has weight of 1.01 grams and the other coins has weight of 1 gram. We are given a digital scale, but we can only use it once. How can we identify the bag of gold coins? After about 5 minutes waiting, our professor gave us the solution (the class had ended and he didn't want to wait any longer): Give the bags numbers from 0 through 99, then take 0 coins from the bag number 0, 1 coin from the bag number 1, 2 coins from the bag number 2, and so on until we take 99 coins from the bag number 99. Gather all the coins we have taken together and put them on the scale. Denote the weight of these coins as $W$ and the number of bag with gold coins in it as $N$, then we can identify the bag of gold coins using formula $$N=100(W-4950)$$   For instance, if the weight of all coins gathered is $4950.25$ grams, then using the formula above the bag number 25 has the gold coins in it. My questions are: How does the formula work? Where does it come from? Do we have other ways to solve this puzzle? If yes, how? If the digital scale is replaced by a traditional scale, the scale like symbol of libra or the scale in Shakespeare's drama: The Merchant of Venice (I don't know what is the name in English), then how do we solve this puzzle?",,"['probability', 'combinatorics', 'soft-question', 'recreational-mathematics', 'puzzle']"
90,Expected rank of a random binary matrix?,Expected rank of a random binary matrix?,,"Recently a friend stumbled across this question: Let $M$ be a random $n \times n$ matrix with entries in $\{0,1\}$ (both zero and one has probability $p = q = \frac{1}{2}$). What is its expected rank? My intuition is that it would be something of order $\frac{n}{\log n}$, similarly to coupon collector's problem , but I could not produce anything more specific. Unfortunately my linear algebra skills are, to put it mildly, rusty. Is this a know problem? If the exact calculation is hard, are there any simple arguments regarding the order when $n$ tends to infinity? I would greatly appreciate any hints, proofs, references, or any other help. Edit: The original question was phrased in terms of field $\mathbb{F}_2$, however, the approach for $\mathbb{R}$ would be great as well, that is I would consider it a full answer (especially if simpler).","Recently a friend stumbled across this question: Let $M$ be a random $n \times n$ matrix with entries in $\{0,1\}$ (both zero and one has probability $p = q = \frac{1}{2}$). What is its expected rank? My intuition is that it would be something of order $\frac{n}{\log n}$, similarly to coupon collector's problem , but I could not produce anything more specific. Unfortunately my linear algebra skills are, to put it mildly, rusty. Is this a know problem? If the exact calculation is hard, are there any simple arguments regarding the order when $n$ tends to infinity? I would greatly appreciate any hints, proofs, references, or any other help. Edit: The original question was phrased in terms of field $\mathbb{F}_2$, however, the approach for $\mathbb{R}$ would be great as well, that is I would consider it a full answer (especially if simpler).",,"['probability', 'matrices', 'reference-request', 'matrix-rank', 'random-matrices']"
91,Why do we want probabilities to be *countably* additive?,Why do we want probabilities to be *countably* additive?,,"In probability theory, it is (as far as I am aware) universal to equate ""probability"" with a probabilistic measure in the sense of measure theory (possibly a particularly well behaved measure, but never mind). In particular, we do assume $\sigma$-additivity, but not anything more (say, additivity with respect to families with cardinality $\mathfrak{c}$ [which would of course make things break down]). For me, as a mathematician, this is completely satisfactory, and until recently I hardly realised that it may not be entirely obvious that probability should behave thus. A sufficiently convincing justification  for working with measures would be that integration theory is precious, and we want to be able to make use of integrals to compute expected values, variances, moments and so on. And we can't require any ""stronger"" kind of additivity, since then things fall apart already for a uniform random distribution on $[0,1]$. However, recently I have had some interactions with non-mathematicians, who approach ""higher"" mathematics with some understandable uncertainty, but who still find the notion of probability relevant. One of the things it made me realise is that I am not myself fully aware why, in principle, we define things thus and not otherwise. Hence, after this overlong introduction, here is the question. Is there a fundamental reason why measure theory is the ""only right way"" to deal with probabilities (as opposed to e.g. declaring probabilities to be just finitely additive)? If so, is there a ""spectacular"" example showing why any other approach would not work? If not, then is there an alternative approach (with any research behind it)?","In probability theory, it is (as far as I am aware) universal to equate ""probability"" with a probabilistic measure in the sense of measure theory (possibly a particularly well behaved measure, but never mind). In particular, we do assume $\sigma$-additivity, but not anything more (say, additivity with respect to families with cardinality $\mathfrak{c}$ [which would of course make things break down]). For me, as a mathematician, this is completely satisfactory, and until recently I hardly realised that it may not be entirely obvious that probability should behave thus. A sufficiently convincing justification  for working with measures would be that integration theory is precious, and we want to be able to make use of integrals to compute expected values, variances, moments and so on. And we can't require any ""stronger"" kind of additivity, since then things fall apart already for a uniform random distribution on $[0,1]$. However, recently I have had some interactions with non-mathematicians, who approach ""higher"" mathematics with some understandable uncertainty, but who still find the notion of probability relevant. One of the things it made me realise is that I am not myself fully aware why, in principle, we define things thus and not otherwise. Hence, after this overlong introduction, here is the question. Is there a fundamental reason why measure theory is the ""only right way"" to deal with probabilities (as opposed to e.g. declaring probabilities to be just finitely additive)? If so, is there a ""spectacular"" example showing why any other approach would not work? If not, then is there an alternative approach (with any research behind it)?",,"['probability', 'probability-theory', 'soft-question', 'education', 'motivation']"
92,How to generate points uniformly distributed on the surface of an ellipsoid?,How to generate points uniformly distributed on the surface of an ellipsoid?,,"I am trying to find a way to generate random points uniformly distributed on the surface of an ellipsoid. If it was a sphere there is a neat way of doing it: Generate three $N(0,1)$ variables $\{x_1,x_2,x_3\}$, calculate the distance from the origin $$d=\sqrt{x_1^2+x_2^2+x_3^2}$$ and calculate the point $$\mathbf{y}=(x_1,x_2,x_3)/d.$$ It can then be shown that the points $\mathbf{y}$ lie on the surface of the sphere and are uniformly distributed on the sphere surface, and the argument that proves it is just one word, ""isotropy"". No prefered direction. Suppose now we have an ellipsoid $$\frac{x_1^2}{a^2}+\frac{x_2^2}{b^2}+\frac{x_3^2}{c^2}=1$$ How about generating three $N(0,1)$ variables as above, calculate $$d=\sqrt{\frac{x_1^2}{a^2}+\frac{x_2^2}{b^2}+\frac{x_3^2}{c^2}}$$ and then using $\mathbf{y}=(x_1,x_2,x_3)/d$ as above. That way we get points guaranteed on the surface of the ellipsoid but will they be uniformly distributed? How can we check that? Any help greatly appreciated, thanks. PS I am looking for a solution without accepting/rejecting points, which is kind of trivial. EDIT: Switching to polar coordinates, the surface element is $dS=F(\theta,\phi)\ d\theta\ d\phi$ where $F$ is expressed as $$\frac{1}{4} \sqrt{r^2 \left(16 \sin ^2(\theta ) \left(a^2 \sin ^2(\phi )+b^2 \cos    ^2(\phi )+c^2\right)+16 \cos ^2(\theta ) \left(a^2 \cos ^2(\phi )+b^2 \sin    ^2(\phi )\right)-r^2 \left(a^2-b^2\right)^2 \sin ^2(2 \theta ) \sin ^2(2 \phi    )\right)}$$","I am trying to find a way to generate random points uniformly distributed on the surface of an ellipsoid. If it was a sphere there is a neat way of doing it: Generate three $N(0,1)$ variables $\{x_1,x_2,x_3\}$, calculate the distance from the origin $$d=\sqrt{x_1^2+x_2^2+x_3^2}$$ and calculate the point $$\mathbf{y}=(x_1,x_2,x_3)/d.$$ It can then be shown that the points $\mathbf{y}$ lie on the surface of the sphere and are uniformly distributed on the sphere surface, and the argument that proves it is just one word, ""isotropy"". No prefered direction. Suppose now we have an ellipsoid $$\frac{x_1^2}{a^2}+\frac{x_2^2}{b^2}+\frac{x_3^2}{c^2}=1$$ How about generating three $N(0,1)$ variables as above, calculate $$d=\sqrt{\frac{x_1^2}{a^2}+\frac{x_2^2}{b^2}+\frac{x_3^2}{c^2}}$$ and then using $\mathbf{y}=(x_1,x_2,x_3)/d$ as above. That way we get points guaranteed on the surface of the ellipsoid but will they be uniformly distributed? How can we check that? Any help greatly appreciated, thanks. PS I am looking for a solution without accepting/rejecting points, which is kind of trivial. EDIT: Switching to polar coordinates, the surface element is $dS=F(\theta,\phi)\ d\theta\ d\phi$ where $F$ is expressed as $$\frac{1}{4} \sqrt{r^2 \left(16 \sin ^2(\theta ) \left(a^2 \sin ^2(\phi )+b^2 \cos    ^2(\phi )+c^2\right)+16 \cos ^2(\theta ) \left(a^2 \cos ^2(\phi )+b^2 \sin    ^2(\phi )\right)-r^2 \left(a^2-b^2\right)^2 \sin ^2(2 \theta ) \sin ^2(2 \phi    )\right)}$$",,"['probability', 'stochastic-processes', 'random-variables', 'analytic-geometry', 'ellipsoids']"
93,Zombie outbreak on a $k$-regular graph,Zombie outbreak on a -regular graph,k,"Suppose we have a zombie outbreak on a connected $k$-regular graph of order $n$.  There are $n_0$ initially infected zombie nodes, and each turn, each zombie infects its neighbors with probability $p$.  Let $z(t)$ denote the number of infected nodes on turn $t$. What is the expected number of turns until zombies have taken over the world?  (that is, until $z(t)=n$?) Is it true that $z(t)\approx \dfrac{n}{1+(n-n_0)e^{-rt}}$?  If so, what is $r$?","Suppose we have a zombie outbreak on a connected $k$-regular graph of order $n$.  There are $n_0$ initially infected zombie nodes, and each turn, each zombie infects its neighbors with probability $p$.  Let $z(t)$ denote the number of infected nodes on turn $t$. What is the expected number of turns until zombies have taken over the world?  (that is, until $z(t)=n$?) Is it true that $z(t)\approx \dfrac{n}{1+(n-n_0)e^{-rt}}$?  If so, what is $r$?",,"['probability', 'graph-theory', 'probability-distributions', 'stochastic-processes', 'asymptotics']"
94,A probability question that I failed to answer in a job interview,A probability question that I failed to answer in a job interview,,"There are $N$ different sized targets, numbered $1, 2,\dots, N$.  A blindfolded shooter shoots towards random directions. Because target sizes are different, the hit probabilities of each target are different, say $p_1, p_2,\dots ,p_N$. A bullet hole is left on the target each time a target is hit. The shooter does not know whether a shot hit a target or not. Note that a shoot could be ""void"", i.e., $p_1+p_2+\cdots+p_N\le1$. One shot at most hits one target. The shooter keeps shooting until $X$ out of the $N$, $X<N$, targets have bullet holes. ( each of the $X$ targets is hit at least once). Then the shooter is told to stop. The question is: at the end of the game, what is the probability that target $k$ has NOT been hit, $1\leq k\leq N$.","There are $N$ different sized targets, numbered $1, 2,\dots, N$.  A blindfolded shooter shoots towards random directions. Because target sizes are different, the hit probabilities of each target are different, say $p_1, p_2,\dots ,p_N$. A bullet hole is left on the target each time a target is hit. The shooter does not know whether a shot hit a target or not. Note that a shoot could be ""void"", i.e., $p_1+p_2+\cdots+p_N\le1$. One shot at most hits one target. The shooter keeps shooting until $X$ out of the $N$, $X<N$, targets have bullet holes. ( each of the $X$ targets is hit at least once). Then the shooter is told to stop. The question is: at the end of the game, what is the probability that target $k$ has NOT been hit, $1\leq k\leq N$.",,['probability']
95,% of % - Please Help Me Prove My Friend Wrong,% of % - Please Help Me Prove My Friend Wrong,,"Here is the situation:  My friend and I are at an impasse.  I believe I'm correct, but he's so damn stubborn he won't believe me.  Also, I'm not the most articulate at explaining things.  Hopefully some of you guys can help me explain this to him in a way he'll understand.  Here is the problem: A DVD is either at his parent's house or his own.  The probability that it's at his house is 30%. If the DVD is at his own house, there is a 90% chance it's on the porch, and a 10% chance it's in the living room. What is the % chance the DVD is on the porch? My friend says you take 90% of 30% which is 27 and that is the % chance it's on the porch.  Is this correct?  I don't believe so. I believe that regardless of where the DVD is, the chance of it being anywhere in his house is still 30% overall.  Location inside his house won't change those odd because the porch and the living room are both part of the house.  If there is a 90% chance it's on the porch, it doesn't change the overall odds of it being in that location. Now, if you rephrase the question and ask, ""The DVD Is either at my parents, my porch, or my living room.  What is the % chance it's on my porch?"", the answer is 33%.  If there are three places it could be, then there is 33.333% chance it's on the porch.  Even if it's a 90% chance it's at his house, if there are only three places it can be, it remains the same. I think the correct way of answering the question is:  There is a 30% chance the DVD is at my house.  If it is at my house, there is a 90% chance it's on my porch.  They are two separate odds and you can't take a percentage of the overall odds since the locations are inside the house. Is this correct or am I wrong?  And regardless, please give me your explanation.","Here is the situation:  My friend and I are at an impasse.  I believe I'm correct, but he's so damn stubborn he won't believe me.  Also, I'm not the most articulate at explaining things.  Hopefully some of you guys can help me explain this to him in a way he'll understand.  Here is the problem: A DVD is either at his parent's house or his own.  The probability that it's at his house is 30%. If the DVD is at his own house, there is a 90% chance it's on the porch, and a 10% chance it's in the living room. What is the % chance the DVD is on the porch? My friend says you take 90% of 30% which is 27 and that is the % chance it's on the porch.  Is this correct?  I don't believe so. I believe that regardless of where the DVD is, the chance of it being anywhere in his house is still 30% overall.  Location inside his house won't change those odd because the porch and the living room are both part of the house.  If there is a 90% chance it's on the porch, it doesn't change the overall odds of it being in that location. Now, if you rephrase the question and ask, ""The DVD Is either at my parents, my porch, or my living room.  What is the % chance it's on my porch?"", the answer is 33%.  If there are three places it could be, then there is 33.333% chance it's on the porch.  Even if it's a 90% chance it's at his house, if there are only three places it can be, it remains the same. I think the correct way of answering the question is:  There is a 30% chance the DVD is at my house.  If it is at my house, there is a 90% chance it's on my porch.  They are two separate odds and you can't take a percentage of the overall odds since the locations are inside the house. Is this correct or am I wrong?  And regardless, please give me your explanation.",,['probability']
96,What is the probability that the center of the circle is contained within a triangle formed by choosing three random points on the circumference?,What is the probability that the center of the circle is contained within a triangle formed by choosing three random points on the circumference?,,Consider the triangle formed by randomly distributing three points on a circle. What is the probability of the center of the circle be contained within the triangle?,Consider the triangle formed by randomly distributing three points on a circle. What is the probability of the center of the circle be contained within the triangle?,,"['probability', 'circles', 'geometric-probability']"
97,Expected Value of Flips Until HT Consecutively,Expected Value of Flips Until HT Consecutively,,"Suppose you ﬂip a fair coin repeatedly until you see a Heads followed by a Tails. What is the expected number of coin ﬂips you have to ﬂip? By manipulating an equation based on the result of the first flip, shown at this link: http://www.codechef.com/wiki/tutorial-expectation the answer is 6. This also makes sense intuitively since the expected value of the number flips until HH or TT is 3. But is there a way to tackle this problem by summing a series of probabilities multiplied by the values? Thank you!","Suppose you ﬂip a fair coin repeatedly until you see a Heads followed by a Tails. What is the expected number of coin ﬂips you have to ﬂip? By manipulating an equation based on the result of the first flip, shown at this link: http://www.codechef.com/wiki/tutorial-expectation the answer is 6. This also makes sense intuitively since the expected value of the number flips until HH or TT is 3. But is there a way to tackle this problem by summing a series of probabilities multiplied by the values? Thank you!",,"['probability', 'random-variables']"
98,Expected value of the number of flips until the first head,Expected value of the number of flips until the first head,,"Suppose we flip a coin until we see a head. What is the expected value of the number of flips we will take? I am pretty new to expected value, so I tried to evaluate it by multiplying the probability of each scenario with the number of flips it took to get there (like taking the arithmetic mean). This didn't work though, because of the infinite possibilities. I'm really confused, and if someone were to provide an answer, I would really appreciate it if they could go into detail.","Suppose we flip a coin until we see a head. What is the expected value of the number of flips we will take? I am pretty new to expected value, so I tried to evaluate it by multiplying the probability of each scenario with the number of flips it took to get there (like taking the arithmetic mean). This didn't work though, because of the infinite possibilities. I'm really confused, and if someone were to provide an answer, I would really appreciate it if they could go into detail.",,['probability']
99,What is the difference between multinomial and categorical distribution?,What is the difference between multinomial and categorical distribution?,,"Both seem to result in one of k different separated outcomes, and Wikipedia says these are often conflated. Despite reading the explanation of the difference on the article about multinomial distribution , I still have trouble understanding what the difference really is.","Both seem to result in one of k different separated outcomes, and Wikipedia says these are often conflated. Despite reading the explanation of the difference on the article about multinomial distribution , I still have trouble understanding what the difference really is.",,[]
