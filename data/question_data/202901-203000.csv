,title_raw,title_text,title_latex,body_raw,body_text,body_latex,tags
0,Differential of exponential function,Differential of exponential function,,"I have the following theorem and proof in my lecture, which I don't quite understand: Let $M$ be a smooth manifold, $p \in M$ . Then it holds that $(d \exp _p)_0=: T_0 T_pM \cong T_pM \rightarrow T_pM$ is the identity. On the proof it says:  Since $\exp(tv)= \gamma_v(t)$ for $v \in T_pM$ , it holds $$(d  \exp _p)_0 (v)= \biggl.\dfrac{\partial}{\partial t} \biggr|_0  \exp (tv)=v$$ ( $\gamma_v$ is the unique maximal geodesic with $\gamma^{'}(0)=v$ ). Now what I don't understand: The exponential function is only defined on a neighboorhood of $0$ in $TM$ right, so $(d \exp_p)_0: T_0 D$ where $D \subset T_pM$ , right? I don't understand the proof at all, where does the $\frac{\partial}{\partial t}$ come from? Can somebody explain this?","I have the following theorem and proof in my lecture, which I don't quite understand: Let be a smooth manifold, . Then it holds that is the identity. On the proof it says:  Since for , it holds ( is the unique maximal geodesic with ). Now what I don't understand: The exponential function is only defined on a neighboorhood of in right, so where , right? I don't understand the proof at all, where does the come from? Can somebody explain this?",M p \in M (d \exp _p)_0=: T_0 T_pM \cong T_pM \rightarrow T_pM \exp(tv)= \gamma_v(t) v \in T_pM (d  \exp _p)_0 (v)= \biggl.\dfrac{\partial}{\partial t} \biggr|_0  \exp (tv)=v \gamma_v \gamma^{'}(0)=v 0 TM (d \exp_p)_0: T_0 D D \subset T_pM \frac{\partial}{\partial t},"['differential-geometry', 'riemannian-geometry', 'geodesic', 'semi-riemannian-geometry']"
1,Detailed computations of geodesic equation (using Langrangian or not),Detailed computations of geodesic equation (using Langrangian or not),,"Given a manifold and a path $\gamma$ on this manifold, I want to know if this path is actually a geodesic. From what I read, I should compute the geodesic equation with that path, then check if it equals zero. I should hence compute : ${d^2 x^\mu \over ds^2}+\Gamma^\mu {}_{\alpha \beta}{d x^\alpha \over ds}{d x^\beta \over ds}$ Where, if I understand correctly, $s$ is the variable that parametrises $\gamma$ , and $x^\mu$ are the components of $\gamma$ in some generalised coordinate system. Still understanding Christoffel symbols is really hard to me, and I might not be ready using these yet. I read there is another (probably simpler) formulation using a Lagrangian, which would need me to compute, if I'm right : $\frac{\partial \dot{\gamma}}{\partial x^\mu} - \frac{\mathrm d}{\mathrm ds} \left(\frac{\partial \dot{\gamma}}{\partial \dot{x}^\mu}\right)$ Again, I am failing manipulating such expressions. I would like you to help me with this simple example : in $\mathbb{R}^3$ , let the manifold be the sphere of radius $1$ and center $O$ and we consider : $\gamma : s \mapsto \begin{pmatrix}\cos s \\ \sin s \\ 0\end{pmatrix}$ This obviously parametrises a great circle of the sphere, and hence is a geodesic. So I already know our computations should give us $0$ , yet and I am failing getting it. We suppose we have euclidean metric. Computing $\dot{\gamma} : s \mapsto \begin{pmatrix}-\sin s \\ \cos s \\ 0\end{pmatrix}$ is not what poses a problem. To my understanding, we have $x^1 = \cos s$ , so what does $\frac{\partial (-\sin s)}{\cos s}$ worth ? Does it mean I should express $-{\sin s}$ from $\cos s$ , which would give something like $-{\sin s} = \pm \sqrt{1 - (\cos s)^2}$ ? Some tips about me : I understand Einstein summation convention ; I should be familiar with Leibniz differential notations, though detailing steps does not harm ; I have been initiated to tensors, but can not pretend mastering them ; I know some vector differential operator, but would rather avoid using nabla notation ; I know the Lagrangian is somehow a ""potential"" we want to minimise, but I have no intuition about it. Thanks for your attention.","Given a manifold and a path on this manifold, I want to know if this path is actually a geodesic. From what I read, I should compute the geodesic equation with that path, then check if it equals zero. I should hence compute : Where, if I understand correctly, is the variable that parametrises , and are the components of in some generalised coordinate system. Still understanding Christoffel symbols is really hard to me, and I might not be ready using these yet. I read there is another (probably simpler) formulation using a Lagrangian, which would need me to compute, if I'm right : Again, I am failing manipulating such expressions. I would like you to help me with this simple example : in , let the manifold be the sphere of radius and center and we consider : This obviously parametrises a great circle of the sphere, and hence is a geodesic. So I already know our computations should give us , yet and I am failing getting it. We suppose we have euclidean metric. Computing is not what poses a problem. To my understanding, we have , so what does worth ? Does it mean I should express from , which would give something like ? Some tips about me : I understand Einstein summation convention ; I should be familiar with Leibniz differential notations, though detailing steps does not harm ; I have been initiated to tensors, but can not pretend mastering them ; I know some vector differential operator, but would rather avoid using nabla notation ; I know the Lagrangian is somehow a ""potential"" we want to minimise, but I have no intuition about it. Thanks for your attention.","\gamma {d^2 x^\mu \over ds^2}+\Gamma^\mu {}_{\alpha \beta}{d x^\alpha \over ds}{d x^\beta \over ds} s \gamma x^\mu \gamma \frac{\partial \dot{\gamma}}{\partial x^\mu}
- \frac{\mathrm d}{\mathrm ds} \left(\frac{\partial \dot{\gamma}}{\partial \dot{x}^\mu}\right) \mathbb{R}^3 1 O \gamma : s \mapsto \begin{pmatrix}\cos s \\ \sin s \\ 0\end{pmatrix} 0 \dot{\gamma} : s \mapsto \begin{pmatrix}-\sin s \\ \cos s \\ 0\end{pmatrix} x^1 = \cos s \frac{\partial (-\sin s)}{\cos s} -{\sin s} \cos s -{\sin s} = \pm \sqrt{1 - (\cos s)^2}","['differential-geometry', 'differential', 'geodesic', 'euler-lagrange-equation']"
2,Lie derivative of vector fields on $S^1$,Lie derivative of vector fields on,S^1,"I am trying to do a simple calculation of $L_X(Y)$ and $L_Y(X)$ over the manifold $M = S^1$ where $X = \partial_{\theta} = (-\sin{\theta}, \cos{\theta})$ and $Y = \cos{\theta}\partial_\theta$ using the local coordinates $\phi(\theta) = (\cos{\theta}, \sin{\theta})$ . In particular I am self-studying from Peter Peterson's Riemannian Geometry and want to really understand what the Lie derivative is of $2$ vector fields from the difference quotient definition with local flow. $Y$ has a source and a sink.""> I have the following. In local coordinates, the local flow defined by $X$ is $F^t(\theta) = (\cos{(\theta + t)} , \sin{(\theta + t)})$ and is a curve on $S^1$ . $$L_X(Y) :=  \lim\limits_{t \rightarrow 0} \frac{dF^{-t}(Y(F^t(\theta))) - Y(\theta)}{t} = (\sin^2{\theta}, - \sin{\theta}\cos{\theta}) = -\sin{\theta} \partial_{\theta}$$ Questions $1.~~$ I am having a hard time picturing what it means for $L_X(Y) = 0$ at the rightmost and leftmost points of the circle. Relatedly, how does the vector (1,0) relate to $Y$ ""flowing along $X$ "" at the top point of $S^1$ ? I get that these derivatives are really about curves in $T_pM$ . In particular, the difference quotient is fixing a point $p$ on $S^1$ , flowing along $X$ , taking the vector given by $Y$ , and pulling it back to $T_pM$ , thus tracing a curve in $T_pM$ as $t$ varies. $2.~~$ I am having trouble calculating the local flow of $Y$ to ultimately calculate $L_Y(X)$ . I have tried the following: Let $G^t(\theta) = (\cos(\eta(t, \theta)), \sin(\eta(t, \theta)))$ . Then $\dot{G} = (-\sin(\eta)\dot{\eta}, \cos(\eta)\dot{\eta}) = \cos(\eta) (-\sin(\eta), \cos(\eta)) = Y(G^t(\theta))$ where the dot is differentiation w.r.t. $t$ . This gives $\dot{\eta} = \cos(\eta)$ . I'm not sure how to proceed. I also know that $G^0(\theta) = (\cos\theta,\sin\theta)$ , and $G^t(\pm \frac{\pi}{2}) = (0, \pm 1)$ . A hint on how to proceed would be greatly appreciated. Separation of variables (treating $\theta$ as constant)/an ODE solver seems to give rather unpleasant solutions that I can't easily use to plug into $X$ . Is thinking of these things as literal vectors as opposed to the derivation viewpoint hindering me?","I am trying to do a simple calculation of and over the manifold where and using the local coordinates . In particular I am self-studying from Peter Peterson's Riemannian Geometry and want to really understand what the Lie derivative is of vector fields from the difference quotient definition with local flow. $Y$ has a source and a sink.""> I have the following. In local coordinates, the local flow defined by is and is a curve on . Questions I am having a hard time picturing what it means for at the rightmost and leftmost points of the circle. Relatedly, how does the vector (1,0) relate to ""flowing along "" at the top point of ? I get that these derivatives are really about curves in . In particular, the difference quotient is fixing a point on , flowing along , taking the vector given by , and pulling it back to , thus tracing a curve in as varies. I am having trouble calculating the local flow of to ultimately calculate . I have tried the following: Let . Then where the dot is differentiation w.r.t. . This gives . I'm not sure how to proceed. I also know that , and . A hint on how to proceed would be greatly appreciated. Separation of variables (treating as constant)/an ODE solver seems to give rather unpleasant solutions that I can't easily use to plug into . Is thinking of these things as literal vectors as opposed to the derivation viewpoint hindering me?","L_X(Y) L_Y(X) M = S^1 X = \partial_{\theta} = (-\sin{\theta}, \cos{\theta}) Y = \cos{\theta}\partial_\theta \phi(\theta) = (\cos{\theta}, \sin{\theta}) 2 X F^t(\theta) = (\cos{(\theta + t)} , \sin{(\theta + t)}) S^1 L_X(Y) :=  \lim\limits_{t \rightarrow 0} \frac{dF^{-t}(Y(F^t(\theta))) - Y(\theta)}{t} = (\sin^2{\theta}, - \sin{\theta}\cos{\theta}) = -\sin{\theta} \partial_{\theta} 1.~~ L_X(Y) = 0 Y X S^1 T_pM p S^1 X Y T_pM T_pM t 2.~~ Y L_Y(X) G^t(\theta) = (\cos(\eta(t, \theta)), \sin(\eta(t, \theta))) \dot{G} = (-\sin(\eta)\dot{\eta}, \cos(\eta)\dot{\eta}) = \cos(\eta) (-\sin(\eta), \cos(\eta)) = Y(G^t(\theta)) t \dot{\eta} = \cos(\eta) G^0(\theta) = (\cos\theta,\sin\theta) G^t(\pm \frac{\pi}{2}) = (0, \pm 1) \theta X","['differential-geometry', 'lie-derivative']"
3,Application of Cartan Magic Formula (solving for vector field),Application of Cartan Magic Formula (solving for vector field),,"I have been going through 'Lectures on Symplectic geometry' by AC da Silva and in the proof of the Moser Theorem (notable for the 'Moser Trick'), there is an application of the Cartan Magic Formula that eventually leads to the equation $$i_{v_t}\omega_t + \mu=0$$ where $\mu$ is a 1-form and it says we can 'solve for the vector field $v_t$ ' but I'm not sure how to proceed. Any insight would be much appreciated. It would also be great to know the reason for requiring that the 2-forms $\omega_0$ and $\omega_1$ be in the same cohomology class. I see it being used to say that $\omega_1-\omega_0 = d\mu$ for some 1-form $\mu$ but some intuition would be most welcome.","I have been going through 'Lectures on Symplectic geometry' by AC da Silva and in the proof of the Moser Theorem (notable for the 'Moser Trick'), there is an application of the Cartan Magic Formula that eventually leads to the equation where is a 1-form and it says we can 'solve for the vector field ' but I'm not sure how to proceed. Any insight would be much appreciated. It would also be great to know the reason for requiring that the 2-forms and be in the same cohomology class. I see it being used to say that for some 1-form but some intuition would be most welcome.",i_{v_t}\omega_t + \mu=0 \mu v_t \omega_0 \omega_1 \omega_1-\omega_0 = d\mu \mu,"['differential-geometry', 'symplectic-geometry', 'lie-derivative']"
4,Understanding the definition of a left-invariant connection on a Lie group,Understanding the definition of a left-invariant connection on a Lie group,,"Let $\nabla$ be an affine connection on a Lie group G . Here they define $\nabla$ to be left-invariant if, for arbitrary vector fields $X,Y$ , $$d L_g \nabla_X Y = \nabla_{d L_g X}\hspace{0.5mm} d L_g Y \hspace{1mm},$$ where I assume that $d L_g X$ is the differential of $L_g$ acting on a vector field in the following way; $h \mapsto d(L_g)_h X_h \in T_{gh} G$ . My first question is about understanding that this definition is well-defined. $d L_g X$ is not a vector field, since $h \mapsto d(L_g)_h X_h$ is not in $T_h G$ . Therefore $\nabla_{d L_g X}\hspace{0.5mm} d L_g Y$ is not well-defined... or am I reading the expression in a wrong way? A thought: since $L_g$ is a diffeomorphism, I suppose $d L_g X$ can be identified with the vector field $h \mapsto d({L_g})_{L_g^{-1}(h)}  X_{L_g^{-1}(h)} \in T_h G$ . If this is the way to read it, the LHS should be read in the same way. My second question is about a statement which is supposed to hold, but I don't see why. Let $\nabla$ be left-invariant. Then it is supposed to hold for left-invariant vector fields X and Y , that $\nabla_X Y$ is itself a left-invariant vector field. Any solutions, hints or comments would be greatly appreciated!","Let be an affine connection on a Lie group G . Here they define to be left-invariant if, for arbitrary vector fields , where I assume that is the differential of acting on a vector field in the following way; . My first question is about understanding that this definition is well-defined. is not a vector field, since is not in . Therefore is not well-defined... or am I reading the expression in a wrong way? A thought: since is a diffeomorphism, I suppose can be identified with the vector field . If this is the way to read it, the LHS should be read in the same way. My second question is about a statement which is supposed to hold, but I don't see why. Let be left-invariant. Then it is supposed to hold for left-invariant vector fields X and Y , that is itself a left-invariant vector field. Any solutions, hints or comments would be greatly appreciated!","\nabla \nabla X,Y d L_g \nabla_X Y = \nabla_{d L_g X}\hspace{0.5mm} d L_g Y \hspace{1mm}, d L_g X L_g h \mapsto d(L_g)_h X_h \in T_{gh} G d L_g X h \mapsto d(L_g)_h X_h T_h G \nabla_{d L_g X}\hspace{0.5mm} d L_g Y L_g d L_g X h \mapsto d({L_g})_{L_g^{-1}(h)}  X_{L_g^{-1}(h)} \in T_h G \nabla \nabla_X Y","['differential-geometry', 'lie-groups', 'connections']"
5,Property of pullback connections,Property of pullback connections,,"I'm trying to prove Proposition 4.38 in Lee's Intro to Riemannian Manifolds which is left for the reader: Suppose $M$ and $\tilde M$ are smooth manifolds without boundary, and $\phi: M\to \tilde M$ is a diffeomorphism. Let $\tilde \nabla$ be a connection in $T\tilde M$ and let $\nabla= \phi^*\tilde \nabla$ be the pullback connection in $TM$ . Suppose $\gamma: I\to M$ is a smooth curve. (a) $\phi$ takes covariant derivatives along curves to covariant derivatives along curves: if $V$ is a smooth vector field along $\gamma$ , then $$d\phi \circ D_t V = \tilde D_t(d\phi \circ V),$$ Where $D_t$ is covariant differentiation along $\gamma$ with respect to $\nabla$ , and $\tilde D_t$ is covariant differentiation along $\phi\circ \gamma$ with respect to $\tilde \nabla$ . I've tried expanding both side using the component expression: $$D_t V = \dot V^i(t)\partial_i + V^j\nabla_{\gamma'(t)} \partial_j$$ But the expression grew really fast and seem to be taking me nowhere. How can I prove this result? Any help is appreciated.","I'm trying to prove Proposition 4.38 in Lee's Intro to Riemannian Manifolds which is left for the reader: Suppose and are smooth manifolds without boundary, and is a diffeomorphism. Let be a connection in and let be the pullback connection in . Suppose is a smooth curve. (a) takes covariant derivatives along curves to covariant derivatives along curves: if is a smooth vector field along , then Where is covariant differentiation along with respect to , and is covariant differentiation along with respect to . I've tried expanding both side using the component expression: But the expression grew really fast and seem to be taking me nowhere. How can I prove this result? Any help is appreciated.","M \tilde M \phi: M\to \tilde M \tilde \nabla T\tilde M \nabla= \phi^*\tilde \nabla TM \gamma: I\to M \phi V \gamma d\phi \circ D_t V = \tilde D_t(d\phi \circ V), D_t \gamma \nabla \tilde D_t \phi\circ \gamma \tilde \nabla D_t V = \dot V^i(t)\partial_i + V^j\nabla_{\gamma'(t)} \partial_j","['differential-geometry', 'riemannian-geometry', 'smooth-manifolds']"
6,Is the graph of a smooth function a manifold?,Is the graph of a smooth function a manifold?,,"Let $f:V\rightarrow M$ be a smooth map between smooth manifolds. Why is $Gr(f):=\{\ \left(v,f(v)\right)\ |\ v\in V\} $ a submanifold of $V \times M$ ? This is used in a proof by Kosinski (""Differentiable Manifolds"", chapter 4, Corollary 2.5) but it is not justified.","Let be a smooth map between smooth manifolds. Why is a submanifold of ? This is used in a proof by Kosinski (""Differentiable Manifolds"", chapter 4, Corollary 2.5) but it is not justified.","f:V\rightarrow M Gr(f):=\{\ \left(v,f(v)\right)\ |\ v\in V\}  V \times M","['differential-geometry', 'smooth-manifolds', 'smooth-functions']"
7,Show that the tangent bundle $TM $ of a variety $M$ is Hausdorff.,Show that the tangent bundle  of a variety  is Hausdorff.,TM  M,"I read a Lemma Introduction to smooth manifolds"" which says that given a smooth n -manifold ð‘€, then the tangent bundle ð‘‡ð‘€ is a smooth 2ð‘›-manifold, how can I prove this?","I read a Lemma Introduction to smooth manifolds"" which says that given a smooth n -manifold ð‘€, then the tangent bundle ð‘‡ð‘€ is a smooth 2ð‘›-manifold, how can I prove this?",,"['differential-geometry', 'manifolds', 'tangent-bundle']"
8,Definition of vector fields on submanifolds,Definition of vector fields on submanifolds,,"There is a definition in my lecture which I don't really understand: Let $\overline{M}$ be a manifold and $M$ a submanifold. Now I'm ""quoting"" (+translating) the lecture notes: Each vector field $X \in \mathfrak{X}(\overline{M})$ defines a vector field $X_{|M}$ along the inclusion $M \hookrightarrow \overline{M}$ . Define $\overline{\mathfrak{X}}(M)$ as the $C^{\infty}(M)$ module of vector fields along the inclusion $M \hookrightarrow \overline{M}$ . Also, it holds $\mathfrak{X}(M) \subset \overline{\mathfrak{X}}(M)$ . My interpretation: $X \in \mathfrak{X}(\overline{M})$ means that $X$ is a function $\overline{M} \rightarrow T\overline{M}$ . Now $X_{|M}$ is then a function $M \rightarrow \bigcup\limits_{p \in M} T_p \overline{M}$ right? A vector field $X \in  \mathfrak{X}(M) $ is a function $M \rightarrow TM$ . Thus $TM \subset \bigcup\limits_{p \in M} T_p \overline{M}$ , right? Now that's something I don't understand. Shouldn't it be $TM =\bigcup\limits_{p \in M} T_p \overline{M}$ ? I'm not quite sure, if I understand what $\bigcup\limits_{p \in M} T_p \overline{M}$ means. Sorry for my sometimes confusing explanations but maybe still somebody can explain this to me..","There is a definition in my lecture which I don't really understand: Let be a manifold and a submanifold. Now I'm ""quoting"" (+translating) the lecture notes: Each vector field defines a vector field along the inclusion . Define as the module of vector fields along the inclusion . Also, it holds . My interpretation: means that is a function . Now is then a function right? A vector field is a function . Thus , right? Now that's something I don't understand. Shouldn't it be ? I'm not quite sure, if I understand what means. Sorry for my sometimes confusing explanations but maybe still somebody can explain this to me..",\overline{M} M X \in \mathfrak{X}(\overline{M}) X_{|M} M \hookrightarrow \overline{M} \overline{\mathfrak{X}}(M) C^{\infty}(M) M \hookrightarrow \overline{M} \mathfrak{X}(M) \subset \overline{\mathfrak{X}}(M) X \in \mathfrak{X}(\overline{M}) X \overline{M} \rightarrow T\overline{M} X_{|M} M \rightarrow \bigcup\limits_{p \in M} T_p \overline{M} X \in  \mathfrak{X}(M)  M \rightarrow TM TM \subset \bigcup\limits_{p \in M} T_p \overline{M} TM =\bigcup\limits_{p \in M} T_p \overline{M} \bigcup\limits_{p \in M} T_p \overline{M},"['differential-geometry', 'riemannian-geometry', 'vector-fields', 'submanifold']"
9,"Do all non-orientable have to ""close"" in some direction?","Do all non-orientable have to ""close"" in some direction?",,"I am not a connoisseur in the topic of surfaces, the two non-orientable surfaces I know are the MÃ¶bius strip and the Klein bottle. Intuitively I understand that for a surface to be non-orientable, the basis vectors have to flip at some point (while following a given path without changing their relative direction... probably something like parallel transport), so that a basis that was once positively oriented changes to one that has negative orientation, and consequently it makes no sense to talk about orientation. Whenever I think about it, the following image is what comes to mind. But for this to happen there must be at least one path, tangent to some basis vector, that has to close on itself. In other words, at least one of the directions is bounded. In the particular case of the the MÃ¶bius strip and the Klein bottle we also know that the genus is greater than zero (one and two, respectively). My question is, Are there (finite dimensional) unbounded non-orientable surfaces? Also, Is the genus of these surfaces always greater than zero?","I am not a connoisseur in the topic of surfaces, the two non-orientable surfaces I know are the MÃ¶bius strip and the Klein bottle. Intuitively I understand that for a surface to be non-orientable, the basis vectors have to flip at some point (while following a given path without changing their relative direction... probably something like parallel transport), so that a basis that was once positively oriented changes to one that has negative orientation, and consequently it makes no sense to talk about orientation. Whenever I think about it, the following image is what comes to mind. But for this to happen there must be at least one path, tangent to some basis vector, that has to close on itself. In other words, at least one of the directions is bounded. In the particular case of the the MÃ¶bius strip and the Klein bottle we also know that the genus is greater than zero (one and two, respectively). My question is, Are there (finite dimensional) unbounded non-orientable surfaces? Also, Is the genus of these surfaces always greater than zero?",,"['general-topology', 'geometry']"
10,Showing that the real projective space is Hausdorff using matrices and linear algebra,Showing that the real projective space is Hausdorff using matrices and linear algebra,,"I am trying to follow the proof in Loring Tu's book (An introduction to smooth manifolds, 2nd edition, p.79) to show that the real projective space is Hausdorff. A snippet of the proof is shown below. I am confused about the part where we show that $R$ is a closed subset. I understand that the rank of $x$ and $y$ concatinated being at most 1 is equivalent to the vanishing of all $2\times 2$ minors of $[x \hspace{0.5em} y]$ . My 2 questions are: 1) How is $R$ the zero set of finitely many polynomials? Showing the rank is at most 1 only involves $2 \times 2$ minors, i.e. only 2 rows of $R$ are utilized. 2) If it is the zero set, why is it closed? Does the ""finitely"" (in ""finitely many polynomials) play a role here? Hoping someone can help clarify things. Thanks!","I am trying to follow the proof in Loring Tu's book (An introduction to smooth manifolds, 2nd edition, p.79) to show that the real projective space is Hausdorff. A snippet of the proof is shown below. I am confused about the part where we show that is a closed subset. I understand that the rank of and concatinated being at most 1 is equivalent to the vanishing of all minors of . My 2 questions are: 1) How is the zero set of finitely many polynomials? Showing the rank is at most 1 only involves minors, i.e. only 2 rows of are utilized. 2) If it is the zero set, why is it closed? Does the ""finitely"" (in ""finitely many polynomials) play a role here? Hoping someone can help clarify things. Thanks!",R x y 2\times 2 [x \hspace{0.5em} y] R 2 \times 2 R,"['linear-algebra', 'general-topology', 'differential-geometry', 'manifolds', 'smooth-manifolds']"
11,An example computation with a form that is closed but not exact,An example computation with a form that is closed but not exact,,"I'm working on the following question in munkres: Let $A = \mathbb{R}^2-0$ ; let $$\omega = (-y\,dx + x\, dy)/(x^2+y^2)$$ in $A$ . Show $\omega$ is closed but not exact in $A$ . This is a multi-part question, so I've posted an image of all the parts (I wrote the question so it could be searched). My questions correspond to the parts of problem: b. This clearly ""smells"" like polar coordinates. Indeed, if $\phi(x,y) = \tan^{-1}(y/x)$ the formulas are verified ""almost everywhere"" on B. However, the fact that the formula above doesn't work everywhere (namely $x=0$ ) gives me pause. The way he asks the question makes me think there's a way of showing uniqueness without producing an explicit formula for $\phi$ , but I cannot see the argument. Thoughts? c. My original thought was to consider $f_1(x,y,t) = (x^2+y^2)^{1/2}\cos t - x$ and $f_2(x,y,t) = (x^2+y^2)^{1/2}\cos t - y$ . Then use implicit fxn theorem to conclude there exists $g(x,y) = t$ -- this gets me regularity of $g$ too. But there are some periodic problems. For $f_1$ : $\frac{\partial f_1}{\partial t} = 0$ when $t = k\pi$ so this $g(x,y)$ isn't defined everywhere. How would one proceed showing this then? How is the hint used? d. Do b/c provide an explicit formula then? How is the hint used? e. So in d, we showed $\omega$ is exact. The given formula shows $\omega$ is a one form. Then by this part, we conclude $\phi$ is constant on $B$ ? f. I don't understand what the hint is suggesting I do. Generically: I think the point of the problem is to show that the domain of the form matters -- is this correct?","I'm working on the following question in munkres: Let ; let in . Show is closed but not exact in . This is a multi-part question, so I've posted an image of all the parts (I wrote the question so it could be searched). My questions correspond to the parts of problem: b. This clearly ""smells"" like polar coordinates. Indeed, if the formulas are verified ""almost everywhere"" on B. However, the fact that the formula above doesn't work everywhere (namely ) gives me pause. The way he asks the question makes me think there's a way of showing uniqueness without producing an explicit formula for , but I cannot see the argument. Thoughts? c. My original thought was to consider and . Then use implicit fxn theorem to conclude there exists -- this gets me regularity of too. But there are some periodic problems. For : when so this isn't defined everywhere. How would one proceed showing this then? How is the hint used? d. Do b/c provide an explicit formula then? How is the hint used? e. So in d, we showed is exact. The given formula shows is a one form. Then by this part, we conclude is constant on ? f. I don't understand what the hint is suggesting I do. Generically: I think the point of the problem is to show that the domain of the form matters -- is this correct?","A = \mathbb{R}^2-0 \omega = (-y\,dx + x\, dy)/(x^2+y^2) A \omega A \phi(x,y) = \tan^{-1}(y/x) x=0 \phi f_1(x,y,t) = (x^2+y^2)^{1/2}\cos t - x f_2(x,y,t) = (x^2+y^2)^{1/2}\cos t - y g(x,y) = t g f_1 \frac{\partial f_1}{\partial t} = 0 t = k\pi g(x,y) \omega \omega \phi B","['differential-geometry', 'manifolds', 'differential-topology']"
12,Einstein manifolds with metric locally conformal to that of a manifold of constant sectional curvature have constant sectional curvature as well,Einstein manifolds with metric locally conformal to that of a manifold of constant sectional curvature have constant sectional curvature as well,,"I'm reading an article from $1988$ from Kuhnel, where I found the following: $\textbf{Proposition}$ . Let $(M, g)$ be a space of constant curvature $K$ and dimension $n \geq 3$ and $\psi: M \to \mathbb{R}$ a function, and $\bar{g} = \psi^{-2}g$ . $\textbf{Then the following are equivalent}$ : $(1)$ $(M, \bar{g})$ is a space of constant sectional curvature $\bar{K}$ $(2) $$(M, \bar{g})$ is Einstein $(3)$ $\nabla^2 \psi = \cfrac{\Delta\psi}{n} \cdot g$ where $ \nabla^{2} \varphi=\nabla(\nabla \varphi) $ denotes the hessian of $\varphi$ . Here's the proof for $(3) \iff (1)$ (not verbatim): Define $\varphi$ by $\psi \doteq e^{\varphi} $ . Let $\sigma$ be the $2$ -plane spanned by two vectors $X, Y$ which are orthonormal with respect to $g$ . Let $\overline{K}_{\sigma}$ denote the sectional curvature of $\sigma$ in $(M, \bar{g})$ . Then from $(1.2)$ we have: $$ \begin{aligned} \psi^{-2} \overline{K}_{\sigma} &=\langle \overline{{R}}(X, Y) Y, X \rangle\\ &\color{red}{={K}+\nabla^{2} \varphi(Y, Y)+\nabla^{2} \varphi(X, X)+(Y \varphi)^{2}+(X \varphi)^{2}-\|\nabla \varphi\|^{2} }\\ &\color{red}{=K+\frac{2}{n} \cdot \frac{\Delta \psi}{\psi}-\|\nabla \varphi\|^{2} }\end{aligned} $$ and the  result follows from Schur's theorem. Now, $(1.2)$ is the following: $$ \begin{aligned} \overline{R_{m}}(X, Y) Z &=R_{m}(X, Y) Z-\left[\langle X, Z\rangle H_{\varphi} Y-\langle Y, Z\rangle H_{\varphi} X\right] \\ &+\left[\nabla^{2} \varphi(Y, Z)+(Y \varphi)(Z \varphi)-\langle Y, Z\rangle\|\varphi\|^{2}\right] X \\ &-\left[\nabla^{2} \varphi(X, Z)+(X \varphi)(Z \varphi)-\langle X, Z\rangle\|\varphi\|^{2}\right] Y \\ &+[(X \varphi)\langle Y, Z\rangle-(Y \varphi)\langle X, Z\rangle] \nabla \varphi \end{aligned} $$ where $$ {H}_{\psi}(X) \doteq \nabla_{X}(\nabla \psi) $$ I don't understand how the equalities above outlined in red follow from $(1.2)$ . Using $(1.2)$ , I get: $$ \begin{aligned} \overline{R}(X, Y) Y &=R_{m}(X, Y) Y-\left[\langle X, Y\rangle H_{\varphi} Y-\langle Y, Y\rangle H_{\varphi} X\right] \\ &+\left[\nabla^{2} \varphi(Y, Y)+(Y \varphi)(Y \varphi)-\langle Y, Y\rangle\|\varphi\|^{2}\right] X \\ &-\left[\nabla^{2} \varphi(X, Y)+(X \varphi)(Y \varphi)-\langle X, Y\rangle\|\varphi\|^{2}\right] Y \\ &+[(X \varphi)\langle Y, Y\rangle-(Y \varphi)\langle X, Y\rangle] \nabla \varphi \end{aligned} $$ so that (using the fact $X, Y$ are orthonormal) we have: $$ \begin{aligned} \psi^{-2} \overline{K}_{\sigma} &=\langle \overline{{R}}(X, Y) Y, X \rangle\\ &={K}+ \langle H_{\varphi}X, X \rangle + \nabla^{2} \varphi(Y, Y)+(Y \varphi)^{2} -\|\nabla \varphi\|^{2} + \langle (X\varphi)\nabla \varphi, X \rangle\\ &=K+\nabla^2 \varphi(X, X) +\nabla^2 \varphi(Y, Y) + (Y\varphi)^2  +  \langle (X\varphi)\nabla \varphi, X \rangle-\|\nabla \varphi\|^{2} \end{aligned} $$ so my doubt is really this one: how/why are the following equalities true: $$\langle (X\varphi)\nabla \varphi, X \rangle = (X\varphi)^2$$ $$\nabla^2 \varphi(X, X) +\nabla^2 \varphi(Y, Y) + (Y\varphi)^2  +  (X\varphi)^2 = \frac{2}{n} \cdot \frac{\Delta \psi}{\psi} $$ EDIT: I'm being silly. The first equality is by definition. The second one is still not solved though.","I'm reading an article from from Kuhnel, where I found the following: . Let be a space of constant curvature and dimension and a function, and . : is a space of constant sectional curvature is Einstein where denotes the hessian of . Here's the proof for (not verbatim): Define by . Let be the -plane spanned by two vectors which are orthonormal with respect to . Let denote the sectional curvature of in . Then from we have: and the  result follows from Schur's theorem. Now, is the following: where I don't understand how the equalities above outlined in red follow from . Using , I get: so that (using the fact are orthonormal) we have: so my doubt is really this one: how/why are the following equalities true: EDIT: I'm being silly. The first equality is by definition. The second one is still not solved though.","1988 \textbf{Proposition} (M, g) K n \geq 3 \psi: M \to \mathbb{R} \bar{g} = \psi^{-2}g \textbf{Then the following are equivalent} (1) (M, \bar{g}) \bar{K} (2) (M, \bar{g}) (3) \nabla^2 \psi = \cfrac{\Delta\psi}{n} \cdot g 
\nabla^{2} \varphi=\nabla(\nabla \varphi)
 \varphi (3) \iff (1) \varphi \psi \doteq e^{\varphi}  \sigma 2 X, Y g \overline{K}_{\sigma} \sigma (M, \bar{g}) (1.2) 
\begin{aligned} \psi^{-2} \overline{K}_{\sigma} &=\langle \overline{{R}}(X, Y) Y, X \rangle\\ &\color{red}{={K}+\nabla^{2} \varphi(Y, Y)+\nabla^{2} \varphi(X, X)+(Y \varphi)^{2}+(X \varphi)^{2}-\|\nabla \varphi\|^{2} }\\ &\color{red}{=K+\frac{2}{n} \cdot \frac{\Delta \psi}{\psi}-\|\nabla \varphi\|^{2} }\end{aligned}
 (1.2) 
\begin{aligned} \overline{R_{m}}(X, Y) Z &=R_{m}(X, Y) Z-\left[\langle X, Z\rangle H_{\varphi} Y-\langle Y, Z\rangle H_{\varphi} X\right] \\ &+\left[\nabla^{2} \varphi(Y, Z)+(Y \varphi)(Z \varphi)-\langle Y, Z\rangle\|\varphi\|^{2}\right] X \\ &-\left[\nabla^{2} \varphi(X, Z)+(X \varphi)(Z \varphi)-\langle X, Z\rangle\|\varphi\|^{2}\right] Y \\ &+[(X \varphi)\langle Y, Z\rangle-(Y \varphi)\langle X, Z\rangle] \nabla \varphi \end{aligned}
 
{H}_{\psi}(X) \doteq \nabla_{X}(\nabla \psi)
 (1.2) (1.2) 
\begin{aligned} \overline{R}(X, Y) Y &=R_{m}(X, Y) Y-\left[\langle X, Y\rangle H_{\varphi} Y-\langle Y, Y\rangle H_{\varphi} X\right] \\ &+\left[\nabla^{2} \varphi(Y, Y)+(Y \varphi)(Y \varphi)-\langle Y, Y\rangle\|\varphi\|^{2}\right] X \\ &-\left[\nabla^{2} \varphi(X, Y)+(X \varphi)(Y \varphi)-\langle X, Y\rangle\|\varphi\|^{2}\right] Y \\ &+[(X \varphi)\langle Y, Y\rangle-(Y \varphi)\langle X, Y\rangle] \nabla \varphi \end{aligned}
 X, Y 
\begin{aligned} \psi^{-2} \overline{K}_{\sigma} &=\langle \overline{{R}}(X, Y) Y, X \rangle\\ &={K}+ \langle H_{\varphi}X, X \rangle + \nabla^{2} \varphi(Y, Y)+(Y \varphi)^{2} -\|\nabla \varphi\|^{2} + \langle (X\varphi)\nabla \varphi, X \rangle\\ &=K+\nabla^2 \varphi(X, X) +\nabla^2 \varphi(Y, Y) + (Y\varphi)^2  +  \langle (X\varphi)\nabla \varphi, X \rangle-\|\nabla \varphi\|^{2} \end{aligned}
 \langle (X\varphi)\nabla \varphi, X \rangle = (X\varphi)^2 \nabla^2 \varphi(X, X) +\nabla^2 \varphi(Y, Y) + (Y\varphi)^2  +  (X\varphi)^2 = \frac{2}{n} \cdot \frac{\Delta \psi}{\psi} ","['differential-geometry', 'manifolds', 'riemannian-geometry', 'curvature']"
13,"Do Carmo Riemannian Geometry, definition 2.6","Do Carmo Riemannian Geometry, definition 2.6",,"Bit of trouble understanding the following definition: Let $M$ be a differentiable manifold. A differentiable function $\alpha : (-\epsilon,+\epsilon)\to M$ is called a differentiable curve in $M$ . Suppose $\alpha(0) = p \in  M$ , and let $\mathcal{D}$ be the set of functions on $M$ that are differentiable at $p$ . The tangent vector to the curve $\alpha$ at $t=0$ is a function $\alpha'(0):\mathcal{D}\to \mathbb{R}$ given by $$ \alpha'(0) f = \left( \frac{d(f \circ \alpha)}{dt} \right)_{t=0} $$ The definition continues but it's irrelevant for my question. Because I don't know the image of the function $f$ , but it is assumed to be differentiable shall I assume that $f$ is real valued somehow? Definition 2.5. defines a mapping $\varphi$ from a manifold to another to be differentiable if its expression is differentiable. The expression is a well defined function from $\mathbb{R}^m$ to $\mathbb{R}^n$ . However in the definition above of tangent vector I don't think $f$ is necessarely a function between two manifolds. The question is how is the definition of $\alpha'(0)$ well defined to be a function from $\mathcal{D}$ to $\mathbb{R}$ ?","Bit of trouble understanding the following definition: Let be a differentiable manifold. A differentiable function is called a differentiable curve in . Suppose , and let be the set of functions on that are differentiable at . The tangent vector to the curve at is a function given by The definition continues but it's irrelevant for my question. Because I don't know the image of the function , but it is assumed to be differentiable shall I assume that is real valued somehow? Definition 2.5. defines a mapping from a manifold to another to be differentiable if its expression is differentiable. The expression is a well defined function from to . However in the definition above of tangent vector I don't think is necessarely a function between two manifolds. The question is how is the definition of well defined to be a function from to ?","M \alpha : (-\epsilon,+\epsilon)\to M M \alpha(0) = p \in  M \mathcal{D} M p \alpha t=0 \alpha'(0):\mathcal{D}\to \mathbb{R} 
\alpha'(0) f = \left( \frac{d(f \circ \alpha)}{dt} \right)_{t=0}
 f f \varphi \mathbb{R}^m \mathbb{R}^n f \alpha'(0) \mathcal{D} \mathbb{R}","['differential-geometry', 'manifolds', 'definition']"
14,Understanding the Proof about the Uniqueness of $d$ operator,Understanding the Proof about the Uniqueness of  operator,d,"Munkres defines $d$ -- the generalized differential operator -- by showing it characterized by the following properties: Let $A \subset \mathbb{R}^n$ open and $\Omega^k(A)$ be the linear space of $C^\infty$ k-forms on $A$ . $d$ is the unique linear transformation such that: $$d:\Omega^k(A) \rightarrow \Omega^{k+1}(A)$$ defined for $k \geq 0$ , such that: If $f$ is a 0-form, then $df$ is the 1-form $$df(x)(x;v) = Df(x) \cdot v$$ If $\omega$ nad $\nu$ are forms of orders $k$ and $l$ , resp, then $$d(\omega \wedge \nu) = d\omega \wedge \nu + (-1)^k\omega \wedge d\nu$$ For every form $\omega$ $$d(d\omega)=0$$ Below I outline his proof. My question: why is this work sufficient to show the claim? I'm having trouble following his logic. I provide more detail below. Proof Steps Sketch: Verifies uniqueness in two steps. First he shows that conditions two and three imply that for any forms $\omega_1,...\omega_k$ we have: $$d(d\omega_1\wedge ...\wedge d\omega_k)=0$$ then he shows that any $k$ -form is determined by the value of $d$ on $0$ -forms. To complete this second task he says: ""Since $d$ is linear, it suffices to consider the case $\omega = f dx_I$ "" then does a computation to show $d\omega = df \wedge dx_I$ . Why is he checking all this stuff? The only way I know to check uniqueness is to start with two different elements ""of the same type"" and then show the operator sends them to the same value Also he's checking assuming linearity of $d$ before proving it, below. Isn't that incorrect? Also in the computation in the second part of the step, he starts $$d\omega = d(f dx_I) = d(f \wedge dx_I) = ...$$ -- this appearance of a wedge in the last step is mysterious to me. Check that given k-form $\omega$ , $d\omega$ is $C^{\infty}$ and $d$ is linear on $k$ -forms If $J$ is an abtrirary k-tuple of integers then $$d(f \wedge dx_J) = df \wedge dx_J$$ Didn't he show this in the second part of step one?? Verify property 2 in special case Verify property 2 in general. Verify property 3 in special case. Verify property 3 in general. Where's the verification of property 1, was that accomplished somewhere without being explicitly mentioned?","Munkres defines -- the generalized differential operator -- by showing it characterized by the following properties: Let open and be the linear space of k-forms on . is the unique linear transformation such that: defined for , such that: If is a 0-form, then is the 1-form If nad are forms of orders and , resp, then For every form Below I outline his proof. My question: why is this work sufficient to show the claim? I'm having trouble following his logic. I provide more detail below. Proof Steps Sketch: Verifies uniqueness in two steps. First he shows that conditions two and three imply that for any forms we have: then he shows that any -form is determined by the value of on -forms. To complete this second task he says: ""Since is linear, it suffices to consider the case "" then does a computation to show . Why is he checking all this stuff? The only way I know to check uniqueness is to start with two different elements ""of the same type"" and then show the operator sends them to the same value Also he's checking assuming linearity of before proving it, below. Isn't that incorrect? Also in the computation in the second part of the step, he starts -- this appearance of a wedge in the last step is mysterious to me. Check that given k-form , is and is linear on -forms If is an abtrirary k-tuple of integers then Didn't he show this in the second part of step one?? Verify property 2 in special case Verify property 2 in general. Verify property 3 in special case. Verify property 3 in general. Where's the verification of property 1, was that accomplished somewhere without being explicitly mentioned?","d A \subset \mathbb{R}^n \Omega^k(A) C^\infty A d d:\Omega^k(A) \rightarrow \Omega^{k+1}(A) k \geq 0 f df df(x)(x;v) = Df(x) \cdot v \omega \nu k l d(\omega \wedge \nu) = d\omega \wedge \nu + (-1)^k\omega \wedge d\nu \omega d(d\omega)=0 \omega_1,...\omega_k d(d\omega_1\wedge ...\wedge d\omega_k)=0 k d 0 d \omega = f dx_I d\omega = df \wedge dx_I d d\omega = d(f dx_I) = d(f \wedge dx_I) = ... \omega d\omega C^{\infty} d k J d(f \wedge dx_J) = df \wedge dx_J","['geometry', 'differential-geometry', 'manifolds', 'proof-explanation', 'tensors']"
15,Nonvanishing form in $\Omega^3(O(3))$,Nonvanishing form in,\Omega^3(O(3)),"This is an old exam question which most of it I understand now due to the comments below. I still have two concerns. Define a $p$ -form on $GL(n)$ as follows. $$\Theta_p=tr(X^{-1}dX \wedge X^{-1}dX \wedge \cdots \wedge X^{-1}dX)$$ (i) Restrict $\Theta_3$ to $O(3)$ .  Writing the matrix $X$ with orthonormal column vectors $\mathbf{x_1, x_2,x_3}$ , show that $X^{-1}dX$ is a skew symmetric matrix whose $i,j$ th entry is $\mathbf{x}_i\cdot d\mathbf{x}_j$ . (ii) Show that at $X=I$ , the forms $\mathbf{x_1} \cdot \mathbf{dx_2}, \mathbf{x_2 \cdot dx_3},$ and $\mathbf{x_3, \cdot dx_1}$ are linearly independent and $\Theta_3$ is nonzero. (iii) Deduce that since $(AX)^{-1}d(AX)=X^{-1}dX$ , $\Theta_3$ is non vanishing at all points. (a) why can we just restrict $\Theta_3$ to $O(3)$ ? How do we know this form is still smooth? i.e. the induced map to $O(3) \rightarrow \wedge^*T^*O(3)$ is still smooth? (b) Why does the equality in (iii) show $X^{-1}dX$ is left invariant? I am also unsure what this means, since we are working with $1$ -forms rather than vector fields. I suppose we are to show: $$(L_{A^{-1}}^*) X^{-1}dX_I = X^{-1}dX_A $$","This is an old exam question which most of it I understand now due to the comments below. I still have two concerns. Define a -form on as follows. (i) Restrict to .  Writing the matrix with orthonormal column vectors , show that is a skew symmetric matrix whose th entry is . (ii) Show that at , the forms and are linearly independent and is nonzero. (iii) Deduce that since , is non vanishing at all points. (a) why can we just restrict to ? How do we know this form is still smooth? i.e. the induced map to is still smooth? (b) Why does the equality in (iii) show is left invariant? I am also unsure what this means, since we are working with -forms rather than vector fields. I suppose we are to show:","p GL(n) \Theta_p=tr(X^{-1}dX \wedge X^{-1}dX \wedge \cdots \wedge X^{-1}dX) \Theta_3 O(3) X \mathbf{x_1, x_2,x_3} X^{-1}dX i,j \mathbf{x}_i\cdot d\mathbf{x}_j X=I \mathbf{x_1} \cdot \mathbf{dx_2}, \mathbf{x_2 \cdot dx_3}, \mathbf{x_3, \cdot dx_1} \Theta_3 (AX)^{-1}d(AX)=X^{-1}dX \Theta_3 \Theta_3 O(3) O(3) \rightarrow \wedge^*T^*O(3) X^{-1}dX 1 (L_{A^{-1}}^*) X^{-1}dX_I = X^{-1}dX_A ","['differential-geometry', 'manifolds', 'lie-groups', 'differential-forms', 'de-rham-cohomology']"
16,Formula for Lie derivative along a time-dependent vector field,Formula for Lie derivative along a time-dependent vector field,,"I want to prove the following (if it is true) Let be $M$ a manifold, $\Lambda \in \Omega^k(M)$ a $k$ -form on $M$ , $X_t \in \mathfrak{X}(M)$ a time-dependent vector field on $M$ and $\phi_t \in Diff(M)$ a time-dependent diffeomorphism of $M$ such that $\phi_t' = X_t\phi_t$ .  Then for every $t$ : $\mathcal{L}_{X_t}\Lambda = \frac{\partial}{\partial s}(\phi_{t+s}^{\ }\phi_t^{-1})^*\Lambda|_{s=0}$ My attempt was: Consider the projection $\pi: \mathbb{R} \times M \to M$ . Define $\bar{\Lambda} = \pi^*\Lambda \in \Omega^k(\mathbb{R} \times M)$ . Define $\bar{X} \in \mathfrak{X}(\mathbb{R} \times M)$ such that $\bar{X}(t, p) = \partial_t + X_t(p)$ . Define $\bar{\phi_s} \in Diff(\mathbb{R} \times M)$ such that $\bar{\phi_s}(t, p) = (t + s, \phi^{\ }_{t+s}\phi_t^{-1}(p))$ . Then $\bar{\phi_s}$ is a flow for $\bar{X}$ . So $\frac{\partial}{\partial s}(\phi_{t+s}^{\ }\phi_t^{-1})^*\Lambda|_{s=0} = \frac{\partial}{\partial s}(\pi\bar{\phi_s}\pi_t^{-1})^*\Lambda|_{s=0} = {(\pi_t^{-1})}^*(\frac{\partial}{\partial s}\bar{\phi_s}^*\bar\Lambda)|_{s=0} = {(\pi_t^{-1})}^*\mathcal{L}_{\bar{X}}\bar{\Lambda}$ where $\pi_t = \pi|_{\{t\}\times M}$ . What I can't prove (at least formally, because it seems obvious to me) is that ${(\pi_t^{-1})}^*\mathcal{L}_{\bar{X}}\bar{\Lambda} = \mathcal{L}_{X_t}\Lambda$ for every $t \in \mathbb{R}$ . EDIT One idea is to use Cartan's formula and then discard the $dt$ term, but I hope there is a more elegant way.","I want to prove the following (if it is true) Let be a manifold, a -form on , a time-dependent vector field on and a time-dependent diffeomorphism of such that .  Then for every : My attempt was: Consider the projection . Define . Define such that . Define such that . Then is a flow for . So where . What I can't prove (at least formally, because it seems obvious to me) is that for every . EDIT One idea is to use Cartan's formula and then discard the term, but I hope there is a more elegant way.","M \Lambda \in \Omega^k(M) k M X_t \in \mathfrak{X}(M) M \phi_t \in Diff(M) M \phi_t' = X_t\phi_t t \mathcal{L}_{X_t}\Lambda = \frac{\partial}{\partial s}(\phi_{t+s}^{\ }\phi_t^{-1})^*\Lambda|_{s=0} \pi: \mathbb{R} \times M \to M \bar{\Lambda} = \pi^*\Lambda \in \Omega^k(\mathbb{R} \times M) \bar{X} \in \mathfrak{X}(\mathbb{R} \times M) \bar{X}(t, p) = \partial_t + X_t(p) \bar{\phi_s} \in Diff(\mathbb{R} \times M) \bar{\phi_s}(t, p) = (t + s, \phi^{\ }_{t+s}\phi_t^{-1}(p)) \bar{\phi_s} \bar{X} \frac{\partial}{\partial s}(\phi_{t+s}^{\ }\phi_t^{-1})^*\Lambda|_{s=0} = \frac{\partial}{\partial s}(\pi\bar{\phi_s}\pi_t^{-1})^*\Lambda|_{s=0} = {(\pi_t^{-1})}^*(\frac{\partial}{\partial s}\bar{\phi_s}^*\bar\Lambda)|_{s=0} = {(\pi_t^{-1})}^*\mathcal{L}_{\bar{X}}\bar{\Lambda} \pi_t = \pi|_{\{t\}\times M} {(\pi_t^{-1})}^*\mathcal{L}_{\bar{X}}\bar{\Lambda} = \mathcal{L}_{X_t}\Lambda t \in \mathbb{R} dt","['differential-geometry', 'differential-forms', 'vector-fields', 'lie-derivative']"
17,Frenet- Serret and Darboux frame,Frenet- Serret and Darboux frame,,"I am aware the two frames are different, aside from sharing the same tangent unit vector in their basis. But I was wondering, why or when would one choose to use/work with one other frame and not the other? What information does one of frame have that the other does not?","I am aware the two frames are different, aside from sharing the same tangent unit vector in their basis. But I was wondering, why or when would one choose to use/work with one other frame and not the other? What information does one of frame have that the other does not?",,"['differential-geometry', 'frenet-frame']"
18,"In topology: Is there a special terminology for a map that is ""almost'' a homeomorphism?","In topology: Is there a special terminology for a map that is ""almost'' a homeomorphism?",,"By ""almost"" I mean that it can be slightly perturbed within a given fixed compact domain to obtain a homeomorphism from that domain to its image. To be more precise: Let a compact topological space $U \subset \mathbb{R}^n$ , and let a map $f:U\to M$ such that for any $\epsilon>0$ there exists homeomorphism $f_\epsilon:U\to V$ (continuous function with continuous inverse) between $U$ and $V$ for some $V\subset \mathbb{R}^n$ such that $$ \|f(x)-f_\epsilon(x)\|_2<\epsilon \text{ for all } x \in U. \tag{1} $$ Examples: a constant map from cube $x \in [0,1]^3$ to $\mathbb{R}^3$ , $f(x): x \mapsto (0,0,0)$ is almost homeomorphism on the cube. Indeed, for any $\epsilon$ one can introduce $f_\epsilon(x): x \mapsto  \frac{1}{2\sqrt{3}} \epsilon( x_1, x_2, x_3)$ which is a homeomorphism, and (1) is satisfied. a function from $\mathbb{R}\to \mathbb{R}$ , $f(x):x^2$ is not almost homeomorphism on $[-1, 1]$ , since there is no inverse map for $x=0$ . In one dimension, I presume, a function is almost homeomorphism if and only if it is  monotonic, but I'm not familiar with the notion of monotonic in higher dimensions.","By ""almost"" I mean that it can be slightly perturbed within a given fixed compact domain to obtain a homeomorphism from that domain to its image. To be more precise: Let a compact topological space , and let a map such that for any there exists homeomorphism (continuous function with continuous inverse) between and for some such that Examples: a constant map from cube to , is almost homeomorphism on the cube. Indeed, for any one can introduce which is a homeomorphism, and (1) is satisfied. a function from , is not almost homeomorphism on , since there is no inverse map for . In one dimension, I presume, a function is almost homeomorphism if and only if it is  monotonic, but I'm not familiar with the notion of monotonic in higher dimensions.","U \subset \mathbb{R}^n f:U\to M \epsilon>0 f_\epsilon:U\to V U V V\subset \mathbb{R}^n 
\|f(x)-f_\epsilon(x)\|_2<\epsilon \text{ for all } x \in U. \tag{1}
 x \in [0,1]^3 \mathbb{R}^3 f(x): x \mapsto (0,0,0) \epsilon f_\epsilon(x): x \mapsto  \frac{1}{2\sqrt{3}} \epsilon( x_1, x_2, x_3) \mathbb{R}\to \mathbb{R} f(x):x^2 [-1, 1] x=0","['general-topology', 'differential-geometry', 'terminology']"
19,Jacobi Identity for Poisson Bracket [duplicate],Jacobi Identity for Poisson Bracket [duplicate],,"This question already has an answer here : Showing Jacobi identity for Poisson Bracket (1 answer) Closed 2 years ago . We define the so-called rigid body Poisson bracket as $\{F,G\}(\Pi) = -\Pi \cdot(\nabla{F} \times \nabla{G}) $ . I want to prove Jacobi's identity, which is : $\{F,\{G,H\}\} + \{G,\{H,F\}\}+\{H,\{F,G\}\} =0.$ My (naive) approach is to go ahead and use the definition of the bracket mentioned above and write: $\{F,\{G,H\}\}= -\Pi\cdot(\nabla{F} \times \nabla{\{G,H\}})$ . I can then write that $\nabla{\{G,H\}}= \nabla({-\Pi}\cdot(\nabla{G}\times\nabla{H})).$ I then use the vector identity $\nabla({A \cdot B}) = \nabla{A}\cdot B + \nabla{B}\cdot A$ . This gives me: $\nabla{\{G,H\}}= \nabla({-\Pi}\cdot(\nabla{G}\times\nabla{H})) = -\nabla{\Pi}\cdot(\nabla{G}\times\nabla{H})+ \nabla{(\nabla{G}\times\nabla{H)}}\cdot(-\Pi).$ I am almost tempted to say that the second term vanishes, so $\nabla{(\nabla{G}\times\nabla{H)}}\cdot(-\Pi) =0$ . But I am not so sure we can do that. I lack a good argument for this part. I also know that $\nabla{\Pi} = I$ , since the coordinates are $\Pi = (\Pi_1,\Pi_2,\Pi_3)$ . Can anyone help point me in the right direction? Also, I am trying to avoid using coordinates (I don't want to turn to the dark side of the force...) Update: I am open to using coordinates (yes, I am a Sith lord now). But since I am not so familiar with this approach, can someone please enlighten me? Update 2: The operation above $\nabla{(\nabla{G}\times\nabla{H)}}$ does not make sense unless we think of $\nabla$ as a Jacobian. This makes me even more confused...","This question already has an answer here : Showing Jacobi identity for Poisson Bracket (1 answer) Closed 2 years ago . We define the so-called rigid body Poisson bracket as . I want to prove Jacobi's identity, which is : My (naive) approach is to go ahead and use the definition of the bracket mentioned above and write: . I can then write that I then use the vector identity . This gives me: I am almost tempted to say that the second term vanishes, so . But I am not so sure we can do that. I lack a good argument for this part. I also know that , since the coordinates are . Can anyone help point me in the right direction? Also, I am trying to avoid using coordinates (I don't want to turn to the dark side of the force...) Update: I am open to using coordinates (yes, I am a Sith lord now). But since I am not so familiar with this approach, can someone please enlighten me? Update 2: The operation above does not make sense unless we think of as a Jacobian. This makes me even more confused...","\{F,G\}(\Pi) = -\Pi \cdot(\nabla{F} \times \nabla{G})  \{F,\{G,H\}\} + \{G,\{H,F\}\}+\{H,\{F,G\}\} =0. \{F,\{G,H\}\}= -\Pi\cdot(\nabla{F} \times \nabla{\{G,H\}}) \nabla{\{G,H\}}= \nabla({-\Pi}\cdot(\nabla{G}\times\nabla{H})). \nabla({A \cdot B}) = \nabla{A}\cdot B + \nabla{B}\cdot A \nabla{\{G,H\}}= \nabla({-\Pi}\cdot(\nabla{G}\times\nabla{H})) = -\nabla{\Pi}\cdot(\nabla{G}\times\nabla{H})+ \nabla{(\nabla{G}\times\nabla{H)}}\cdot(-\Pi). \nabla{(\nabla{G}\times\nabla{H)}}\cdot(-\Pi) =0 \nabla{\Pi} = I \Pi = (\Pi_1,\Pi_2,\Pi_3) \nabla{(\nabla{G}\times\nabla{H)}} \nabla","['differential-geometry', 'poisson-geometry']"
20,Energy bounds for pseudoholomorphic curves without symplectic structure,Energy bounds for pseudoholomorphic curves without symplectic structure,,"Let $(M,J)$ be a compact almost complex manifold and $C>0$ a constant. Gromov's compactness theorem states that the space of $J$ -holomorphic curves $u:S^2\to M$ with energy bounded above by $C$ is compact, modulo bubbling. The usual way of employing Gromov's theorem is by using a compatible symplectic form on $(M,J)$ and restricting to the space of $J$ -holomorphic maps to a fixed homology class $A\in H_2(M;\mathbb{Z})$ : all curves in this class have equal energy. Question: Suppose $(M,J)$ has no compatible symplectic structure . How can we obtain energy bounds on $J$ -holomorphic curves in a fixed homology class $A$ ? In particular, suppose $g$ is a $J$ -compatible Riemannian metric. Are there any conditions (e.g. curvature bounds) on $g$ which imply a uniform area bound for $J$ -holomorphic curves $u:S^2\to M$ in $A$ ? The reason I think a condition on $g$ might give uniform energy bounds is that the energy of a $J$ -holomorphic curve is equal to the area of the curve with respect to a $J$ -compatible metric.","Let be a compact almost complex manifold and a constant. Gromov's compactness theorem states that the space of -holomorphic curves with energy bounded above by is compact, modulo bubbling. The usual way of employing Gromov's theorem is by using a compatible symplectic form on and restricting to the space of -holomorphic maps to a fixed homology class : all curves in this class have equal energy. Question: Suppose has no compatible symplectic structure . How can we obtain energy bounds on -holomorphic curves in a fixed homology class ? In particular, suppose is a -compatible Riemannian metric. Are there any conditions (e.g. curvature bounds) on which imply a uniform area bound for -holomorphic curves in ? The reason I think a condition on might give uniform energy bounds is that the energy of a -holomorphic curve is equal to the area of the curve with respect to a -compatible metric.","(M,J) C>0 J u:S^2\to M C (M,J) J A\in H_2(M;\mathbb{Z}) (M,J) J A g J g J u:S^2\to M A g J J","['differential-geometry', 'manifolds', 'symplectic-geometry', 'minimal-surfaces']"
21,Signed curvature of catenary involving turning/tangential angle,Signed curvature of catenary involving turning/tangential angle,,"Suppose we want to find the signed curvature of the catenary $$\gamma(t)=(t,\cosh t)$$ where $\mathcal{k}_n=\frac{d\phi}{ds}$ and $\phi(s)$ is the turning angle of $\gamma$ such that $$\dot\gamma(s)=(\cos\phi(s), \sin\phi(s))$$ We proceed: $$s=\int_{s_0}^{s}|\dot\gamma(t)|dt=\int_{s_0}^s\sqrt{1+\sinh^2t}dt=\sinh t$$ so if $\phi$ is the angle between $\dot\gamma$ and the $x$ -axis, then $$\tan\phi=\sinh t=s\implies\sec^2\phi\frac{d\phi}{ds}=1\implies k_s=\frac{1}{1+s^2}$$ Can someone explain how we proceed in that last line of calculation? Why does $\tan\phi=\sinh t=s? $","Suppose we want to find the signed curvature of the catenary where and is the turning angle of such that We proceed: so if is the angle between and the -axis, then Can someone explain how we proceed in that last line of calculation? Why does","\gamma(t)=(t,\cosh t) \mathcal{k}_n=\frac{d\phi}{ds} \phi(s) \gamma \dot\gamma(s)=(\cos\phi(s), \sin\phi(s)) s=\int_{s_0}^{s}|\dot\gamma(t)|dt=\int_{s_0}^s\sqrt{1+\sinh^2t}dt=\sinh t \phi \dot\gamma x \tan\phi=\sinh t=s\implies\sec^2\phi\frac{d\phi}{ds}=1\implies k_s=\frac{1}{1+s^2} \tan\phi=\sinh t=s?
",[]
22,Laplacian is the trace of Hessian in local coordinates,Laplacian is the trace of Hessian in local coordinates,,"I am working in the riemannian setting with Levi-Civita connection and I would like to prove using local coordinates that the laplacian is the trace of the Hessian i.e. $$ \text{tr}_g(\nabla^2 f)=\sum_{i,j} g^{ij} \bigl ( f_{ij} - \sum_k\Gamma_{ij}^k f_k \bigr ) = \sum_{i,k} \bigl ( \partial_i (g^{ki} f_k) + \sum_{j}g^{kj} \Gamma_{ji}^i f_k \bigr )= \Delta f$$ Expanding summations and using Liebniz I obtain $$ \sum_{i,j} g^{ij} f_{ij} - \sum_{i,j,k}g^{ij}\Gamma_{ij}^k f_k = \sum_{i,k} g^{ki}f_{ik} + \sum_{i,k} \partial_i(g^{ki})f_k+ \sum_{i,j,k} g^{kj}\Gamma_{ji}^if_k$$ and then to prove the equality it is enough to show $$ -\sum_{i,j,k}g^{ij}\Gamma_{ij}^kf_k = \sum_{i,k} \partial_i(g^{ki})f_k+ \sum_{i,j,k}g^{kj}\Gamma_{ji}^if_k$$ i.e. that for every $k$ it holds $$ -\sum_{i,j}g^{ij} \Gamma_{ij}^k = \sum_{i}\partial_i (g^{ki}) + \sum_{i,j}\Gamma_{ji}^ig^{kj}$$ I do not know how to proceed from this point.",I am working in the riemannian setting with Levi-Civita connection and I would like to prove using local coordinates that the laplacian is the trace of the Hessian i.e. Expanding summations and using Liebniz I obtain and then to prove the equality it is enough to show i.e. that for every it holds I do not know how to proceed from this point.," \text{tr}_g(\nabla^2 f)=\sum_{i,j} g^{ij} \bigl ( f_{ij} - \sum_k\Gamma_{ij}^k f_k \bigr ) = \sum_{i,k} \bigl ( \partial_i (g^{ki} f_k) + \sum_{j}g^{kj} \Gamma_{ji}^i f_k \bigr )= \Delta f  \sum_{i,j} g^{ij} f_{ij} - \sum_{i,j,k}g^{ij}\Gamma_{ij}^k f_k = \sum_{i,k} g^{ki}f_{ik} + \sum_{i,k} \partial_i(g^{ki})f_k+ \sum_{i,j,k} g^{kj}\Gamma_{ji}^if_k  -\sum_{i,j,k}g^{ij}\Gamma_{ij}^kf_k = \sum_{i,k} \partial_i(g^{ki})f_k+ \sum_{i,j,k}g^{kj}\Gamma_{ji}^if_k k  -\sum_{i,j}g^{ij} \Gamma_{ij}^k = \sum_{i}\partial_i (g^{ki}) + \sum_{i,j}\Gamma_{ji}^ig^{kj}","['differential-geometry', 'riemannian-geometry']"
23,How to transfer a metric to the orthonormal coordinate?,How to transfer a metric to the orthonormal coordinate?,,"Suppose in Cartesian coordinate system a Minkowski metric for flat spacetime can be written as : $$ ds^2 = -[1 + 2Ïˆ(t,x)]dt^2 + a^2(t) [1 - 2Ïˆ(t,x)]dx^2 $$ This is a diagonal metric. How can I transform this metric to the orthonormal frame? For that case, what will be the components of this metric in the orthonormal frame?","Suppose in Cartesian coordinate system a Minkowski metric for flat spacetime can be written as : This is a diagonal metric. How can I transform this metric to the orthonormal frame? For that case, what will be the components of this metric in the orthonormal frame?"," ds^2 = -[1 + 2Ïˆ(t,x)]dt^2 + a^2(t) [1 - 2Ïˆ(t,x)]dx^2 ","['matrices', 'differential-geometry', 'coordinate-systems', 'tensors', 'general-relativity']"
24,Why is it the metric that allows for the canonical tangent space/ cotangent space identification?,Why is it the metric that allows for the canonical tangent space/ cotangent space identification?,,"I have seen the phrase ""The metric allows for a canonical identification of the tangent space with the cotangent space"" all over diff geo resources and questions. I understand the map and why it serves as an identification, but since it works using an inner product, isn't the inner product what allows for the identification? I understand that inner products can induce metrics, but I don't see how the metric comes into play here.","I have seen the phrase ""The metric allows for a canonical identification of the tangent space with the cotangent space"" all over diff geo resources and questions. I understand the map and why it serves as an identification, but since it works using an inner product, isn't the inner product what allows for the identification? I understand that inner products can induce metrics, but I don't see how the metric comes into play here.",,['differential-geometry']
25,Canonical projectors onto submanifolds in differential geometry,Canonical projectors onto submanifolds in differential geometry,,"Let $\phi :H\rightarrow M$ be a embedded submanifold of $M$ . If I want to construct a smooth projection map $tan:\mathfrak X(M) \rightarrow \mathfrak X(H) $ , one way is to use a Riemannian metric (whose existence is well known) to construct one (see [1] below). I want to understand this in a different way if possible. Pointwise, I see the following happening: At any point $p \in H$ , consider $T_{\phi(p)}M$ . Now, $\phi'(T_pH)$ is a linear subspace of $T_{\phi(p)}M$ . By injectivity of $\phi'$ , it is clear that $T_pH\cong \phi'(T_pH) $ . Further, by standard linear algebra arguments and the definition of normal bundle, and above, one can easily say that: $$T_{\phi(p)}M \cong T_pH\oplus N_pH$$ Use the standard projectors $pr_i$ of the direct sum to  construct the projector of the vector field as $$(tan(X))(p)=(\phi')^{-1}\circ pr_1(X(\phi(p)))$$ Ofcourse, the key caveat here is that we want the map to be smooth [2], and the problematic part is the $pr_1$ above. Now, I do not expect this map to be smooth, but I can't think of a counterexample to show that the above map is not smooth either. [1] I know that given a Riemannian structure $g$ on $M$ , one can induce one on $H$ as $h:=\phi^*g$ . This yields a very natural smooth projection map as $tan:=h^\sharp \circ \phi^* \circ g^\flat$ . But I am not interested in this. [2] By smoothness of tan, I mean for all $X \in \mathfrak X(M)$ , $tan(X) \in \mathfrak X(H)$ is smooth as a vector field of $H$ .","Let be a embedded submanifold of . If I want to construct a smooth projection map , one way is to use a Riemannian metric (whose existence is well known) to construct one (see [1] below). I want to understand this in a different way if possible. Pointwise, I see the following happening: At any point , consider . Now, is a linear subspace of . By injectivity of , it is clear that . Further, by standard linear algebra arguments and the definition of normal bundle, and above, one can easily say that: Use the standard projectors of the direct sum to  construct the projector of the vector field as Ofcourse, the key caveat here is that we want the map to be smooth [2], and the problematic part is the above. Now, I do not expect this map to be smooth, but I can't think of a counterexample to show that the above map is not smooth either. [1] I know that given a Riemannian structure on , one can induce one on as . This yields a very natural smooth projection map as . But I am not interested in this. [2] By smoothness of tan, I mean for all , is smooth as a vector field of .",\phi :H\rightarrow M M tan:\mathfrak X(M) \rightarrow \mathfrak X(H)  p \in H T_{\phi(p)}M \phi'(T_pH) T_{\phi(p)}M \phi' T_pH\cong \phi'(T_pH)  T_{\phi(p)}M \cong T_pH\oplus N_pH pr_i (tan(X))(p)=(\phi')^{-1}\circ pr_1(X(\phi(p))) pr_1 g M H h:=\phi^*g tan:=h^\sharp \circ \phi^* \circ g^\flat X \in \mathfrak X(M) tan(X) \in \mathfrak X(H) H,"['differential-geometry', 'riemannian-geometry']"
26,Worked examples of Lie derivatives,Worked examples of Lie derivatives,,"I'm trying to find the Lie derivative of a 2-form $\sin(\theta)d\theta \wedge d\phi$ with respect to a vector field given in a differential basis $a \partial/ \partial \phi$ and I think the way to go here is to use Cartan's formula but I'm not sure how to do that. I can't find any worked examples in any differential textbook or online, everything seems to focus on proving identities not performing actual calculations. Can somebody point me to a useful resource with some exercises or step-by-step examples?","I'm trying to find the Lie derivative of a 2-form with respect to a vector field given in a differential basis and I think the way to go here is to use Cartan's formula but I'm not sure how to do that. I can't find any worked examples in any differential textbook or online, everything seems to focus on proving identities not performing actual calculations. Can somebody point me to a useful resource with some exercises or step-by-step examples?",\sin(\theta)d\theta \wedge d\phi a \partial/ \partial \phi,"['differential-geometry', 'differential-forms', 'lie-derivative']"
27,Every differential form $\omega$ of degree 1 in the sphere $S^m\subset\mathbb{R}^{m+1}$ that is closed is also exact.,Every differential form  of degree 1 in the sphere  that is closed is also exact.,\omega S^m\subset\mathbb{R}^{m+1},"I am in a series of self-studies on differential forms on $m$ -dimensional surfaces in Euclidean space. I'm two days thinking about the exercise below. The book that proposes this exercise gives no hint of how to solve it. And it seems to me that there is nothing in the text of the book that can help. This exercise is in a chapter preceding the chapter on the Stokes' theorem ( $\int_{\partial M} \omega = \int_{M} d\omega $ ). So I am trying a solution that does not use Stokes' theorem. Exercise. For every differential form of class $C^k$ in  sphere $S^m$ there exists a differential $r$ -form $\Omega$ of class $C^k$ in $\mathbb{R}^{m + 1}-\{0\}$ such that $\Omega|_{S^m} = \omega $ . If $m>1$ , conclude that every closed differential form of degree $1$ in the sphere $S^m$ is the differential of a function $f:S^m \to \mathbb{R}$ . In particular, any closed form of degree $1$ in $S^m$ ( $m>1$ ) must be nullified by at least two points. My job. Let $\omega$ be a differential form of class $C^k$ and degree $r$ in sphere $$S^m = \{(x_1,\ldots, x_{m + 1}) \in \mathbb{R}^{m + 1}: x_1^2 +\ldots + x_{m + 1}^2 = 1\}.$$ Let us obtain a differential form $ \Omega $ of class $ C^k $ and degree $ r $ in $ \mathbb{R}^{m + 1}$ such that $\Omega|_{S^m}=\omega$ . Let $ x \in \mathbb{R}^{m+1}-\{0\}$ be fixed. Given any other vector $ v \in \mathbb{R}^m$ there exists a unique vector $P_x(v)$ perpendicular to $x$ such that $$ v=c_v\cdot x + P_x(v) $$ where $ c_v $ is a constant that depends on $ v $ . Note that $P_x(v)\in T_xS^m$ . Since the projection $ P_x $ is a linear application we can define $$ \Omega(x)(v_1,\ldots,v_r)=\omega({x}/{|x|})(P_x(v_1),\ldots,P_x(v_r)). $$ I believe that this first part of the exercise I did correctly.Now let's go to the second part of the exercise which is proof that $ \omega $ is exact. For every point $ x $ of the sphere $ S^m $ there exists a parametrization $\varphi: \overline{U} \to \tilde{U} $ with $x = \varphi (u)$ from which we can obtain the base $\left\{\frac{\partial\varphi(u)}{\partial u_1},\ldots,\frac{\partial\varphi(u)}{\partial u_m}  \right\}$ of $ T_xS ^ m $ and its dual base $\{du_1,\ldots, du_m\}$ of $ (T_xS^m)^\ast $ . In addition, there are coordinate functions $a_j^{\varphi}:\overline{U}\to \mathbb{R}$ such that $$ \omega(x)(v) = a_1^{\varphi}(u) du_1\cdot v+\ldots+ a_m^{\varphi} du_m\cdot v $$ for all $x=\varphi(u)\in \tilde{U}$ and all $v\in T_xS^m$ . On the assumption that $ \omega $ is closed we have $$ d\omega(x)(v_1,v_2) =\sum_{i<j} \left(\frac{\partial a_j^{\varphi}}{\partial u_i}(u)-\frac{\partial a_i^{\varphi}}{\partial u_j}(u) \right)  du_i\wedge du_j ( v_1,v_2)=0 $$ for all $x=\varphi(u)\in \tilde{U}$ and all $v_1,v_2\in T_xS^m$ . This means that for every point $x\in S^m$ there is a parametrization $\varphi $ , as $\varphi(u)=x$ for some $u \in \overline{U} $ , which provides coordinate functions $a_j^{\varphi}:\overline{U}\to\mathbb{R}$ of $ \omega $ that satisfies for all $i<j$ in $\{1,\ldots,m\}$ $$ \frac{\partial a_j^{\varphi}}{\partial u_i}(u)-\frac{\partial a_i^{\varphi}}{\partial u_j}(u)=0 $$ for all $u\in \overline{U}$ . I think of using the coordinate functions $a_i^{\varphi}$ to define a vector field in $\overline{U}$ or $\tilde{U}$ and achieve some geometric result with line integrals. But I have no idea how to define this field of vectors. Maybe I have not noticed any geometrical property of the sphere that can be used.","I am in a series of self-studies on differential forms on -dimensional surfaces in Euclidean space. I'm two days thinking about the exercise below. The book that proposes this exercise gives no hint of how to solve it. And it seems to me that there is nothing in the text of the book that can help. This exercise is in a chapter preceding the chapter on the Stokes' theorem ( ). So I am trying a solution that does not use Stokes' theorem. Exercise. For every differential form of class in  sphere there exists a differential -form of class in such that . If , conclude that every closed differential form of degree in the sphere is the differential of a function . In particular, any closed form of degree in ( ) must be nullified by at least two points. My job. Let be a differential form of class and degree in sphere Let us obtain a differential form of class and degree in such that . Let be fixed. Given any other vector there exists a unique vector perpendicular to such that where is a constant that depends on . Note that . Since the projection is a linear application we can define I believe that this first part of the exercise I did correctly.Now let's go to the second part of the exercise which is proof that is exact. For every point of the sphere there exists a parametrization with from which we can obtain the base of and its dual base of . In addition, there are coordinate functions such that for all and all . On the assumption that is closed we have for all and all . This means that for every point there is a parametrization , as for some , which provides coordinate functions of that satisfies for all in for all . I think of using the coordinate functions to define a vector field in or and achieve some geometric result with line integrals. But I have no idea how to define this field of vectors. Maybe I have not noticed any geometrical property of the sphere that can be used.","m \int_{\partial M} \omega = \int_{M} d\omega  C^k S^m r \Omega C^k \mathbb{R}^{m + 1}-\{0\} \Omega|_{S^m} = \omega  m>1 1 S^m f:S^m \to \mathbb{R} 1 S^m m>1 \omega C^k r S^m = \{(x_1,\ldots, x_{m + 1}) \in \mathbb{R}^{m + 1}: x_1^2 +\ldots + x_{m + 1}^2 = 1\}.  \Omega   C^k   r   \mathbb{R}^{m + 1} \Omega|_{S^m}=\omega  x \in \mathbb{R}^{m+1}-\{0\}  v \in \mathbb{R}^m P_x(v) x 
v=c_v\cdot x + P_x(v)
  c_v   v  P_x(v)\in T_xS^m  P_x  
\Omega(x)(v_1,\ldots,v_r)=\omega({x}/{|x|})(P_x(v_1),\ldots,P_x(v_r)).
  \omega   x   S^m  \varphi: \overline{U} \to \tilde{U}  x = \varphi (u) \left\{\frac{\partial\varphi(u)}{\partial u_1},\ldots,\frac{\partial\varphi(u)}{\partial u_m}  \right\}  T_xS ^ m  \{du_1,\ldots, du_m\}  (T_xS^m)^\ast  a_j^{\varphi}:\overline{U}\to \mathbb{R} 
\omega(x)(v) = a_1^{\varphi}(u) du_1\cdot v+\ldots+ a_m^{\varphi} du_m\cdot v
 x=\varphi(u)\in \tilde{U} v\in T_xS^m  \omega  
d\omega(x)(v_1,v_2) =\sum_{i<j} \left(\frac{\partial a_j^{\varphi}}{\partial u_i}(u)-\frac{\partial a_i^{\varphi}}{\partial u_j}(u) \right)  du_i\wedge du_j ( v_1,v_2)=0
 x=\varphi(u)\in \tilde{U} v_1,v_2\in T_xS^m x\in S^m \varphi  \varphi(u)=x u \in \overline{U}  a_j^{\varphi}:\overline{U}\to\mathbb{R}  \omega  i<j \{1,\ldots,m\} 
\frac{\partial a_j^{\varphi}}{\partial u_i}(u)-\frac{\partial a_i^{\varphi}}{\partial u_j}(u)=0
 u\in \overline{U} a_i^{\varphi} \overline{U} \tilde{U}","['differential-geometry', 'differential-topology', 'differential-forms']"
28,Surjectivity and Invertibility of the exponential map,Surjectivity and Invertibility of the exponential map,,"Let $(\mathcal{M},g)$ be a geodesically complete Riemannian manifold.  So $\forall x \in \mathcal{M}$ , the exponential map $\exp_x$ is defined on all of $T_x \mathcal{M}$ .  I have two related questions: (1) Is $\exp_x : T_x \mathcal{M} \rightarrow \mathcal{M}$ surjective for all $x \in \mathcal{M}$ ?  If not, under what conditions on $\mathcal{M}$ is $\exp_x$ surjective (e.g., assuming $\mathcal{M}$ is compact)? (2) If $\exp_x : T_x \mathcal{M} \rightarrow \mathcal{M}$ is surjective, is there a subset of $S_x \subset T_x \mathcal{M}$ such that $\exp_x$ is invertible on $S_x$ and the image of $S_x$ is almost all of $\mathcal{M}$ ?  I.e., $\exp_x(S_x) = \mathcal{M} \setminus U_x$ for some small (e.g., 'measure zero') set $U_x$ .  For example, consider the unit 2-sphere: $\mathcal{M} = S^2 \subset \mathbb{R}^3$ .  Then $exp_x : B_{\pi} \rightarrow S^2 \setminus \{-x\}$ is invertible.","Let be a geodesically complete Riemannian manifold.  So , the exponential map is defined on all of .  I have two related questions: (1) Is surjective for all ?  If not, under what conditions on is surjective (e.g., assuming is compact)? (2) If is surjective, is there a subset of such that is invertible on and the image of is almost all of ?  I.e., for some small (e.g., 'measure zero') set .  For example, consider the unit 2-sphere: .  Then is invertible.","(\mathcal{M},g) \forall x \in \mathcal{M} \exp_x T_x \mathcal{M} \exp_x : T_x \mathcal{M} \rightarrow \mathcal{M} x \in \mathcal{M} \mathcal{M} \exp_x \mathcal{M} \exp_x : T_x \mathcal{M} \rightarrow \mathcal{M} S_x \subset T_x \mathcal{M} \exp_x S_x S_x \mathcal{M} \exp_x(S_x) = \mathcal{M} \setminus U_x U_x \mathcal{M} = S^2 \subset \mathbb{R}^3 exp_x : B_{\pi} \rightarrow S^2 \setminus \{-x\}","['differential-geometry', 'riemannian-geometry']"
29,The image of the exterior derivative is closed: Hodge theory,The image of the exterior derivative is closed: Hodge theory,,If we have an operator $T$ in a Hilbert space $H$ then one can decmpose $H$ as an orthogonal sum $ker(T^*) \oplus \overline{ran(T)}$ . This is purely operator theoretic context. On the other hand there is an important theory which is called Hodge theory : one possible application of this theory is to find a special (unique) representative of cohomology class (as a harmonic differential form). My question is the following: Does the Hodge theory imply that the range of the exterior derivative is closed?,If we have an operator in a Hilbert space then one can decmpose as an orthogonal sum . This is purely operator theoretic context. On the other hand there is an important theory which is called Hodge theory : one possible application of this theory is to find a special (unique) representative of cohomology class (as a harmonic differential form). My question is the following: Does the Hodge theory imply that the range of the exterior derivative is closed?,T H H ker(T^*) \oplus \overline{ran(T)},"['differential-geometry', 'operator-theory', 'hodge-theory']"
30,Reference: riemannian metric with operator norm arbitrarily small compact manifolds,Reference: riemannian metric with operator norm arbitrarily small compact manifolds,,"I read this posts: uniform equivalence of norms induced by riemannian-metrics and supremum of operator norm of the differential So, it is natural to ask the following. Let $f: M \to M$ to be a $C^{1}$ local diffeomorphism map in a compact finite dimensional manifold $M$ , fixed $\beta >0$ .   Does  there exist a Riemannian metric on $TM$ such that $\|df_{x}\| \leq \beta$ ? I suspect that the answer is negative, I tried to solve this for only one point of manifold, but I stuck. Does someone know any reference related with this topic? Thanks","I read this posts: uniform equivalence of norms induced by riemannian-metrics and supremum of operator norm of the differential So, it is natural to ask the following. Let to be a local diffeomorphism map in a compact finite dimensional manifold , fixed .   Does  there exist a Riemannian metric on such that ? I suspect that the answer is negative, I tried to solve this for only one point of manifold, but I stuck. Does someone know any reference related with this topic? Thanks",f: M \to M C^{1} M \beta >0 TM \|df_{x}\| \leq \beta,"['differential-geometry', 'riemannian-geometry']"
31,"Let $M$ be a smooth manifold. Can we say that $M - M = \{ n - m : n,m \in M\}$ is also a smooth manifold?",Let  be a smooth manifold. Can we say that  is also a smooth manifold?,"M M - M = \{ n - m : n,m \in M\}","I was thinking about this for a while. The definition I use for the smooth manifold is the same as per Wikipedia . Let $\{(U_k,\phi_k)\}$ is a smooth atlas of $M$ . Then the natural atlas which was coming in my mind for $M-M$ was $\{(U_i - U_j, \phi_i - \phi_j)\}$ where $(\phi_i - \phi_j)(u)=\phi_i(u) - \phi_j(u) \; \forall u \; \in U_i - U_j$ . Is my approach correct? By $M - M$ I just mean formal difference of two sets where an element $x$ of $M-M$ can be written as $n-m$ for some $n,m \in M$ . Note that ""difference"" in $M-M$ has no meaning but I am seeking a suitable atlas for this set so that when I am in some $\Bbb R^n$ , I will do subtraction as per the addition is done in the group $\Bbb R^n$ . As a beginner in learning the subject, I am not confident in writing down the details. Thank you. EDIT: After a recent comment by @MikeMiller, I realized that I was actually working in $M \times M$ . So I thought to change my definition of $M - M$ . I see now $M - M$ as a set of equivalence classes where the equivalence relation is such that any to pairs $(m,n)$ and $(p,q)$ (or $m-n$ and $p-q$ ) are equivalent if we have a suitable atlas for $M-M$ such that in local coordinates, $m-n=p-q \in \Bbb R^n$ . The problem is I want to know whether such an atlas exists.","I was thinking about this for a while. The definition I use for the smooth manifold is the same as per Wikipedia . Let is a smooth atlas of . Then the natural atlas which was coming in my mind for was where . Is my approach correct? By I just mean formal difference of two sets where an element of can be written as for some . Note that ""difference"" in has no meaning but I am seeking a suitable atlas for this set so that when I am in some , I will do subtraction as per the addition is done in the group . As a beginner in learning the subject, I am not confident in writing down the details. Thank you. EDIT: After a recent comment by @MikeMiller, I realized that I was actually working in . So I thought to change my definition of . I see now as a set of equivalence classes where the equivalence relation is such that any to pairs and (or and ) are equivalent if we have a suitable atlas for such that in local coordinates, . The problem is I want to know whether such an atlas exists.","\{(U_k,\phi_k)\} M M-M \{(U_i - U_j, \phi_i - \phi_j)\} (\phi_i - \phi_j)(u)=\phi_i(u) - \phi_j(u) \; \forall u \; \in U_i - U_j M - M x M-M n-m n,m \in M M-M \Bbb R^n \Bbb R^n M \times M M - M M - M (m,n) (p,q) m-n p-q M-M m-n=p-q \in \Bbb R^n","['differential-geometry', 'manifolds', 'differential-topology', 'smooth-manifolds']"
32,Understanding Lie algebra of matrix Lie group,Understanding Lie algebra of matrix Lie group,,"In my lecture, we gave a very sloppy (physics people ...) proof of the fact that the Lie algebra $\mathfrak{g}$ of a matrix Lie group $G$ is a subspace of $\text{Mat}_n(\mathbb{F})$ . I am not satisfied and I would love to understand this fact in the language of differential geometry that I am learning right now. What I know : The Lie algebra $\mathfrak{g}$ of a matrix Lie group $G$ is the set of all left-invariant vector fields on $G$ . This set is isomorphic to the tangent space at the identity of the Lie group $G$ . The elements $v$ of the tangent space at the identity are according to my definition of the tangent space real-valued functions $$v:F(G)\to \mathbb{R}$$ where $F(M)$ is the set of all smooth-real valued functions on the manifold $G$ . The tangent vectors are $\mathbb{R}$ linear and fulfil a Leibniz rule and the tangent space at $p$ , namely $T_pG$ is simply the set of all these tangent vectors. What I want to know Given the above definitions, how can I formally understand that the members of the tangent space at the identity of a matrix Lie group are matrices?","In my lecture, we gave a very sloppy (physics people ...) proof of the fact that the Lie algebra of a matrix Lie group is a subspace of . I am not satisfied and I would love to understand this fact in the language of differential geometry that I am learning right now. What I know : The Lie algebra of a matrix Lie group is the set of all left-invariant vector fields on . This set is isomorphic to the tangent space at the identity of the Lie group . The elements of the tangent space at the identity are according to my definition of the tangent space real-valued functions where is the set of all smooth-real valued functions on the manifold . The tangent vectors are linear and fulfil a Leibniz rule and the tangent space at , namely is simply the set of all these tangent vectors. What I want to know Given the above definitions, how can I formally understand that the members of the tangent space at the identity of a matrix Lie group are matrices?",\mathfrak{g} G \text{Mat}_n(\mathbb{F}) \mathfrak{g} G G G v v:F(G)\to \mathbb{R} F(M) G \mathbb{R} p T_pG,"['differential-geometry', 'lie-groups', 'lie-algebras', 'tangent-spaces']"
33,Why are map projections of the Earth not charts?,Why are map projections of the Earth not charts?,,"The Earth is a classic example of a 2D manifold. Looks Euclidean to us, but is most definitely curved. I am self teaching some differential geometry and I don't quite understand the difference between two things. So I understand that a chart is a mapping between a subset of the manifold and Eulclidean space, but what I don't understand is how this relates to maps of the Earth. I have read that it is impossible to represent the surface of the Earth/sphere with just a single chart. However, there are definitely maps of the earth that encompass every point. I have seen one that is centered around the north pole, for example, that includes the whole surface - except the south pole is definitely misrepresented somewhat, as it is wrapped around the edges. So what is it about map projections that means they are not considered charts? One presumes some level of maths is needed to perform a map projection, are there specific rules for what makes a chart a chart? And presumably these rules are broken for map projections?","The Earth is a classic example of a 2D manifold. Looks Euclidean to us, but is most definitely curved. I am self teaching some differential geometry and I don't quite understand the difference between two things. So I understand that a chart is a mapping between a subset of the manifold and Eulclidean space, but what I don't understand is how this relates to maps of the Earth. I have read that it is impossible to represent the surface of the Earth/sphere with just a single chart. However, there are definitely maps of the earth that encompass every point. I have seen one that is centered around the north pole, for example, that includes the whole surface - except the south pole is definitely misrepresented somewhat, as it is wrapped around the edges. So what is it about map projections that means they are not considered charts? One presumes some level of maths is needed to perform a map projection, are there specific rules for what makes a chart a chart? And presumably these rules are broken for map projections?",,"['differential-geometry', 'manifolds']"
34,Transformation for Integrals over Manifolds,Transformation for Integrals over Manifolds,,"Most of modern books on integration theory, when constructing the Lebesgue integral, do not introduce manifolds prior. The transformation for Lebesgue integrals can then be stated as follows: Let $\Omega \subseteq \mathbb{R}^d$ be open and $\Phi \colon \Omega \rightarrow \Phi(\Omega)\subseteq\mathbb{R}^d$ a diffeomorphism. The function $f$ is integrable on $\Phi(\Omega)$ if and only if $x\mapsto f(\Phi(x))|\det(D\Phi(x))|$ is on $\Omega$ . It then holds that $\displaystyle \int_{\Phi(\Omega)}f(y)\,\mathrm{d}y=\int_{\Omega} f(\Phi(x))|\det(D\Phi(x))|\,\mathrm{d}x$ where $D\Phi(x)$ is the functional matrix. When considering integrals over manifolds one could proceed like this (where some details are omitted for the purpose of transparency and only global charts are considered): Let $\Psi\colon T\rightarrow V\subseteq M, T\subseteq\mathbb{R}^k$ be a global chart. The integral of $f$ over $M$ is then defined as $\displaystyle \int_M f(x)\,\mathrm{d}S(x)=\int_T f(\Psi(t))\sqrt{g(t)}\,\mathrm{d}t$ where $g$ is the gramian determinant of the chart $\Psi$ . I am looking for an analogue of the first integral transformation for manifolds. Has this anything to do with a change of charts? Also, if I remember correctly, in the theory of differentialforms this analogue is the pullback of a form, is this correct? Do you have to invoke parametrisations for a pullback, too?","Most of modern books on integration theory, when constructing the Lebesgue integral, do not introduce manifolds prior. The transformation for Lebesgue integrals can then be stated as follows: Let be open and a diffeomorphism. The function is integrable on if and only if is on . It then holds that where is the functional matrix. When considering integrals over manifolds one could proceed like this (where some details are omitted for the purpose of transparency and only global charts are considered): Let be a global chart. The integral of over is then defined as where is the gramian determinant of the chart . I am looking for an analogue of the first integral transformation for manifolds. Has this anything to do with a change of charts? Also, if I remember correctly, in the theory of differentialforms this analogue is the pullback of a form, is this correct? Do you have to invoke parametrisations for a pullback, too?","\Omega \subseteq \mathbb{R}^d \Phi \colon \Omega \rightarrow \Phi(\Omega)\subseteq\mathbb{R}^d f \Phi(\Omega) x\mapsto f(\Phi(x))|\det(D\Phi(x))| \Omega \displaystyle \int_{\Phi(\Omega)}f(y)\,\mathrm{d}y=\int_{\Omega} f(\Phi(x))|\det(D\Phi(x))|\,\mathrm{d}x D\Phi(x) \Psi\colon T\rightarrow V\subseteq M, T\subseteq\mathbb{R}^k f M \displaystyle \int_M f(x)\,\mathrm{d}S(x)=\int_T f(\Psi(t))\sqrt{g(t)}\,\mathrm{d}t g \Psi","['integration', 'differential-geometry', 'differential-topology']"
35,Non-vanishing volume form on $S^2$,Non-vanishing volume form on,S^2,"I have been given the form $\mu=x\,dy\wedge dz+y\,dz\wedge dx+z\,dx\wedge dy\in\Omega^2(S^2)$ . I am asked to prove that this form is never vanishing. That is, $\nexists p\in S^2$ such that $\mu_p=0$ . Intuitively, I would say that th eonly point where $\mu$ vanishes is $(0,0,0)$ which is not in $S^2$ , so $\mu$ is nowhere 0. However, I know there are expressions of the form $xdx+ydy+zdz$ which are 0 on $S^2$ . How could I prove that $\mu$ is nowhere vanishing?","I have been given the form . I am asked to prove that this form is never vanishing. That is, such that . Intuitively, I would say that th eonly point where vanishes is which is not in , so is nowhere 0. However, I know there are expressions of the form which are 0 on . How could I prove that is nowhere vanishing?","\mu=x\,dy\wedge dz+y\,dz\wedge dx+z\,dx\wedge dy\in\Omega^2(S^2) \nexists p\in S^2 \mu_p=0 \mu (0,0,0) S^2 \mu xdx+ydy+zdz S^2 \mu",['differential-geometry']
36,Example 9.6 Tu text on manifolds,Example 9.6 Tu text on manifolds,,"I am trying to understand example 9.6 from Tu text on manifolds. The problem is trying to expresss $S^2 = \{(x,y,z) \in \mathbb{R}^3 | x^2 + y^2 + z^2 = 1\}$ as a zero set. Thus, we define the equation $f(x,y,z) = x^2 + y^2+z^2-1=0$ and then clearly, $S^2 = f^{-1}(\{0\})$ . This is the part I don't quite get, the text says: since $\frac{\partial f}{\partial x} = 2x$ , $\frac{\partial f}{\partial y} = 2y$ , $\frac{\partial f}{\partial z} = 2z$ , the only critical point of $f$ is $(0,0,0)$ . I know that a critical point $p$ is a point where the differential of a map fails to be surjective. But I really see no connection between this definition and the quick conclusion that TU arrived at. The way I am trying to understand this is as follows: since $f:\mathbb{R}^3 \rightarrow \mathbb{R}$ , then the differential of $f$ , will also be a map from a $3$ dimensional vector space to a 1 dimensional vector space (well the tangent spaces). Thus, the only way this map has rank less than 1 (and so would not be a surjective map because the map doesn't have maximal rank) happens when we consider the point $(0,0,0)$ . Thus, the point $(0,0,0)$ is the only critical point. Is this reasoning correct for this type of problems or how can it be improved/made correct? Thanks for your help!","I am trying to understand example 9.6 from Tu text on manifolds. The problem is trying to expresss as a zero set. Thus, we define the equation and then clearly, . This is the part I don't quite get, the text says: since , , , the only critical point of is . I know that a critical point is a point where the differential of a map fails to be surjective. But I really see no connection between this definition and the quick conclusion that TU arrived at. The way I am trying to understand this is as follows: since , then the differential of , will also be a map from a dimensional vector space to a 1 dimensional vector space (well the tangent spaces). Thus, the only way this map has rank less than 1 (and so would not be a surjective map because the map doesn't have maximal rank) happens when we consider the point . Thus, the point is the only critical point. Is this reasoning correct for this type of problems or how can it be improved/made correct? Thanks for your help!","S^2 = \{(x,y,z) \in \mathbb{R}^3 | x^2 + y^2 + z^2 = 1\} f(x,y,z) = x^2 + y^2+z^2-1=0 S^2 = f^{-1}(\{0\}) \frac{\partial f}{\partial x} = 2x \frac{\partial f}{\partial y} = 2y \frac{\partial f}{\partial z} = 2z f (0,0,0) p f:\mathbb{R}^3 \rightarrow \mathbb{R} f 3 (0,0,0) (0,0,0)","['differential-geometry', 'differential-topology']"
37,"what is the geometry picture of Riemann tensor identity $R(X\wedge Y,V\wedge W) = R(V\wedge W, X\wedge Y)$",what is the geometry picture of Riemann tensor identity,"R(X\wedge Y,V\wedge W) = R(V\wedge W, X\wedge Y)","For symmetries in Riemann tensor of $R(X,Y)V:=\nabla_X\nabla_YV-\nabla_Y\nabla_XV-\nabla_{[X,Y]}V$ , there are excellent explanations on the intuition behind it like this relevant question . If we think $R(X,Y)V$ measures the change of tangent vector $V$ along $X$ and $Y$ direction, it is easily understood that $R(X,Y) = -R(Y,X)$ . But along this line, how can we see through the skew symmetry of the latter pair $ R(.,.,V,W) = -R(.,.,W,V) $ and the symmetry of exchange pair of $X,Y$ and $V,W$ beyond algebraic proof? $$R(X\wedge Y,V\wedge W) = R(V\wedge W, X\wedge Y)$$","For symmetries in Riemann tensor of , there are excellent explanations on the intuition behind it like this relevant question . If we think measures the change of tangent vector along and direction, it is easily understood that . But along this line, how can we see through the skew symmetry of the latter pair and the symmetry of exchange pair of and beyond algebraic proof?","R(X,Y)V:=\nabla_X\nabla_YV-\nabla_Y\nabla_XV-\nabla_{[X,Y]}V R(X,Y)V V X Y R(X,Y) = -R(Y,X)  R(.,.,V,W) = -R(.,.,W,V)  X,Y V,W R(X\wedge Y,V\wedge W) = R(V\wedge W, X\wedge Y)","['differential-geometry', 'riemannian-geometry', 'curvature', 'general-relativity', 'geometric-algebras']"
38,Gaussian curvature of the pseudosphere,Gaussian curvature of the pseudosphere,,"I am asked to show that the pseudosphere has Gaussian Curvature $-1$ at all points. So I parametrized the tractrix as: \begin{equation} \alpha(t) = (\sin{t},\cos{t}+\log{\tan{\frac{t}{2}}}) \end{equation} So the surface of revolution would be: \begin{equation} x(\theta,t)=(\sin{t}\cos{\theta},\sin{t}\sin{\theta},\cos{t}+\log{\tan{\frac{t}{2}}}) \end{equation} By calculating the first and second fundamental forms we have that $F=f=0$ and $E=(\sin{t})^2,G=(\cot{t})^2,e=(\cos{t})^2$ and $g=-(\cot{t})^2$ . So the Gaussian curvature is: \begin{equation} K = \frac{eg}{EG} = -(\cot{t})^2 \end{equation} What am I doing wrong?",I am asked to show that the pseudosphere has Gaussian Curvature at all points. So I parametrized the tractrix as: So the surface of revolution would be: By calculating the first and second fundamental forms we have that and and . So the Gaussian curvature is: What am I doing wrong?,"-1 \begin{equation}
\alpha(t) = (\sin{t},\cos{t}+\log{\tan{\frac{t}{2}}})
\end{equation} \begin{equation}
x(\theta,t)=(\sin{t}\cos{\theta},\sin{t}\sin{\theta},\cos{t}+\log{\tan{\frac{t}{2}}})
\end{equation} F=f=0 E=(\sin{t})^2,G=(\cot{t})^2,e=(\cos{t})^2 g=-(\cot{t})^2 \begin{equation}
K = \frac{eg}{EG} = -(\cot{t})^2
\end{equation}",['differential-geometry']
39,Proof that a curve is a line given a restriction on it's tangent lines,Proof that a curve is a line given a restriction on it's tangent lines,,"I'm having a hard time doing this problem and I'd like some insights: Given a regular curve $\gamma: \rm I\!R \to \rm I\!R^n$ , show that if all it's tangent lines pass through a same point $P$ , then $\gamma$ is a line or a line segment. I tried a proof by contradiction, supposing that it not being a line there exists a point where the curvature $\neq 0$ and proceeding to find a contradiction, but it seems to bring me no where as I can prove that the tangents only intersect at $P$ but nothing else. Thank you very much!","I'm having a hard time doing this problem and I'd like some insights: Given a regular curve , show that if all it's tangent lines pass through a same point , then is a line or a line segment. I tried a proof by contradiction, supposing that it not being a line there exists a point where the curvature and proceeding to find a contradiction, but it seems to bring me no where as I can prove that the tangents only intersect at but nothing else. Thank you very much!",\gamma: \rm I\!R \to \rm I\!R^n P \gamma \neq 0 P,"['geometry', 'proof-verification', 'differential-geometry']"
40,The definition of integral forms,The definition of integral forms,,"A $d$ -closed differential form $\phi$ on $X$ is said to be integral if its cohomology class in the de Rham group, $[\phi]\in H^*(X,\mathbb{C})$ , is in the image of the natural mapping: $H^*(X,\mathbb{Z})\to H^*(X,\mathbb{C})$ . But I also see an alternative definition: a form is called integral if its integral over any cycle is an integer. I can't see how these two definitions agree. And I didn't see the second definition  when I was taking the manifold class. Moreover, I can't find any reference to show these two definitions agree. Can you show me the proof or tell me the reference?","A -closed differential form on is said to be integral if its cohomology class in the de Rham group, , is in the image of the natural mapping: . But I also see an alternative definition: a form is called integral if its integral over any cycle is an integer. I can't see how these two definitions agree. And I didn't see the second definition  when I was taking the manifold class. Moreover, I can't find any reference to show these two definitions agree. Can you show me the proof or tell me the reference?","d \phi X [\phi]\in H^*(X,\mathbb{C}) H^*(X,\mathbb{Z})\to H^*(X,\mathbb{C})","['differential-geometry', 'differential-forms', 'complex-geometry']"
41,"Relation between two different definitions of ""regular surface""","Relation between two different definitions of ""regular surface""",,"I am currently being confused by two different definitions given in the books ""manifolds and differential geometry (by jeffrey lee)"" and ""differential geometry of curves and surfaces (by do carmo)"". First definition, given by Lee: ""A subset $S$ of a smooth n-manifold $M$ is called a ""regular submanifold"" of dimension $k$ if every point $p \in S $ is in the domain of a chart (U,x) that has the following ""regular submanifold property"" with respect to $S$ : $x(U \cap S ) =x (U) \cap (\mathbb{R}^k \times \{c\})$ for some $c \in \mathbb{R}^{n-k}$ . Note: In Lee's book, a smooth manifold is defined to be a Hausdorff paracompact topological space attached with smoothly compatible charts covering the whole space, i.e. a smooth atlas. Another (somewhat related) definition given by do Carmo is: A subset $S \subset \mathbb{R}^3 $ (although I think this can be easily replaced by $\mathbb{R}^n$ ) is a ""regular surface"" if, for each $p \in S$ , there exists an open $V \subset \mathbb{R}^3$ and a map $x:U \rightarrow V \cap S$ of an open set $U \subset \mathbb{R}^2$ onto $V \cap S \subset \mathbb{R}^3 $ such that x is $C^\infty$ x is a homeomorphism onto its image The differential $ dx(q):\mathbb{R}^2 \rightarrow \mathbb{R}^3$ is injective for all $q \in U$ . My question is: How are these definitions related? More precisely, Given a regular surface in sense of do Carmo, is it always a regular submanifold of dimension 2 of $\mathbb{R}^3$ in sense of Lee? (i.e. is there a 'canonical' way to construct charts having the regular submanifold property?) Do every regular sub 2-manifold of $\mathbb{R}^3$ in sense of Lee becomes a regular surface in sense of do Carmo? Thanks.","I am currently being confused by two different definitions given in the books ""manifolds and differential geometry (by jeffrey lee)"" and ""differential geometry of curves and surfaces (by do carmo)"". First definition, given by Lee: ""A subset of a smooth n-manifold is called a ""regular submanifold"" of dimension if every point is in the domain of a chart (U,x) that has the following ""regular submanifold property"" with respect to : for some . Note: In Lee's book, a smooth manifold is defined to be a Hausdorff paracompact topological space attached with smoothly compatible charts covering the whole space, i.e. a smooth atlas. Another (somewhat related) definition given by do Carmo is: A subset (although I think this can be easily replaced by ) is a ""regular surface"" if, for each , there exists an open and a map of an open set onto such that x is x is a homeomorphism onto its image The differential is injective for all . My question is: How are these definitions related? More precisely, Given a regular surface in sense of do Carmo, is it always a regular submanifold of dimension 2 of in sense of Lee? (i.e. is there a 'canonical' way to construct charts having the regular submanifold property?) Do every regular sub 2-manifold of in sense of Lee becomes a regular surface in sense of do Carmo? Thanks.",S M k p \in S  S x(U \cap S ) =x (U) \cap (\mathbb{R}^k \times \{c\}) c \in \mathbb{R}^{n-k} S \subset \mathbb{R}^3  \mathbb{R}^n p \in S V \subset \mathbb{R}^3 x:U \rightarrow V \cap S U \subset \mathbb{R}^2 V \cap S \subset \mathbb{R}^3  C^\infty  dx(q):\mathbb{R}^2 \rightarrow \mathbb{R}^3 q \in U \mathbb{R}^3 \mathbb{R}^3,"['differential-geometry', 'smooth-manifolds']"
42,Intuition of a smooth vector field,Intuition of a smooth vector field,,"I read the following statement in pg180, of John Lee's smooth manifold. I am not having much intuition. Let $M$ be a smooth manifold, $X:M \rightarrow TM$ be a rough vector field (i.e. it does not have to be smooth map). Then the following are equivalent: $X$ is smooth. For every $f \in C^\infty(M)$ the map $Xf$ is also smooth on $M$ . I understand the proof. But what is the geometric meaning/ significance of this statement? Is there an analogue somewhere else?","I read the following statement in pg180, of John Lee's smooth manifold. I am not having much intuition. Let be a smooth manifold, be a rough vector field (i.e. it does not have to be smooth map). Then the following are equivalent: is smooth. For every the map is also smooth on . I understand the proof. But what is the geometric meaning/ significance of this statement? Is there an analogue somewhere else?",M X:M \rightarrow TM X f \in C^\infty(M) Xf M,"['differential-geometry', 'intuition', 'smooth-manifolds', 'vector-bundles', 'vector-fields']"
43,Question on Shortest Path on the Sphere,Question on Shortest Path on the Sphere,,"Consider the following parameterization of the unit sphere: $$X(u,v)=(\sin v \cos u , \sin v \sin u, \cos v)$$ where $u \in (-\pi,\pi),v \in (0,\pi)$ . First of all, I am told to find the length of the curve $u=u_0, t \in [a,b]$ , where $u_0$ is a constant and $0<a<b<\pi$ (I call this curve $\alpha$ ). It is easy to see that it is given by $b-a$ . After that, I am told to show that if $(u(t),v(t)), t \in [a,b]$ is a curve on $(-\pi,\pi) \times (0,\pi)$ , then the curve on the surface $\beta (t)=X(u(t),v(t))$ which satsifies the $\alpha(a)=\beta(a)$ and $\alpha(b)=\beta(b)$ has a length $\geq b-a$ . I know there is something called ""geodesic"", but I would to like to show it explicitly without evoking any large theorem. I tried to compute the length of $X(a(t),b(t))$ , which is given by $$L=\int_a^b \sqrt{\sin ^2 (v(t)) \left(\frac{du}{dt}\right)^2+\left(\frac{dv}{dt}\right)^2}dt$$ I am stuck here. Can anyone give me some hint?","Consider the following parameterization of the unit sphere: where . First of all, I am told to find the length of the curve , where is a constant and (I call this curve ). It is easy to see that it is given by . After that, I am told to show that if is a curve on , then the curve on the surface which satsifies the and has a length . I know there is something called ""geodesic"", but I would to like to show it explicitly without evoking any large theorem. I tried to compute the length of , which is given by I am stuck here. Can anyone give me some hint?","X(u,v)=(\sin v \cos u , \sin v \sin u, \cos v) u \in (-\pi,\pi),v \in (0,\pi) u=u_0, t \in [a,b] u_0 0<a<b<\pi \alpha b-a (u(t),v(t)), t \in [a,b] (-\pi,\pi) \times (0,\pi) \beta (t)=X(u(t),v(t)) \alpha(a)=\beta(a) \alpha(b)=\beta(b) \geq b-a X(a(t),b(t)) L=\int_a^b \sqrt{\sin ^2 (v(t)) \left(\frac{du}{dt}\right)^2+\left(\frac{dv}{dt}\right)^2}dt","['differential-geometry', 'surfaces', 'curves', 'geodesic']"
44,Problem in do Carmo's book Riemannian geometry at space forms.,Problem in do Carmo's book Riemannian geometry at space forms.,,"I'm reading do Carmo's book, riemannian geometry and at page 163 is this lemma. I dont get the fact that $\varphi(q)=q.$ Can someone fill in the details?","I'm reading do Carmo's book, riemannian geometry and at page 163 is this lemma. I dont get the fact that $\varphi(q)=q.$ Can someone fill in the details?",,"['differential-geometry', 'riemannian-geometry', 'geodesic']"
45,Clarification on definition of smooth map between smooth manifolds,Clarification on definition of smooth map between smooth manifolds,,"Let $M$ and $N$ be $n$-dimensional smooth manifolds. A map $F: M \to N$ is smooth if for each $p \in M$ there exists smooth charts $(U, \varphi)$ containing $p$ and $(V, \psi)$ containing $F(p)$ such that $F(U) \subset V$ and the composite map $\psi \circ F \circ \varphi^{-1} : \varphi(U) \to \psi(V)$ is smooth. My confusion is: Does this definition hold for all smooth charts containing $p$? In other words, if $(W, \sigma)$ is any chart for containing $p$, in any smooth atlas for $M$, will there be a corresponding chart $(V_2, \psi_2)$ containing $F(p)$ such that $F(W) \subset V_2$ and $\psi_2 \circ F \circ \sigma^{-1} : \sigma(W) \to \psi_2(V_2)$ is smooth.? Or is the definition saying that if $F$ is smooth then there exists at least one chart containing $p$ satisfying the conditions.","Let $M$ and $N$ be $n$-dimensional smooth manifolds. A map $F: M \to N$ is smooth if for each $p \in M$ there exists smooth charts $(U, \varphi)$ containing $p$ and $(V, \psi)$ containing $F(p)$ such that $F(U) \subset V$ and the composite map $\psi \circ F \circ \varphi^{-1} : \varphi(U) \to \psi(V)$ is smooth. My confusion is: Does this definition hold for all smooth charts containing $p$? In other words, if $(W, \sigma)$ is any chart for containing $p$, in any smooth atlas for $M$, will there be a corresponding chart $(V_2, \psi_2)$ containing $F(p)$ such that $F(W) \subset V_2$ and $\psi_2 \circ F \circ \sigma^{-1} : \sigma(W) \to \psi_2(V_2)$ is smooth.? Or is the definition saying that if $F$ is smooth then there exists at least one chart containing $p$ satisfying the conditions.",,"['differential-geometry', 'definition', 'differential-topology', 'smooth-manifolds', 'smooth-functions']"
46,Model for symplectic geometry,Model for symplectic geometry,,"An almost symplectic structure on a smooth even dimension manifold $M$ can be viewed as a reduction of structure group $Sp(2n,\mathbb{R}) \hookrightarrow GL(2n,\mathbb{R})$ for the principal frame bundle $\mathcal{F}(M)$. If this structure group reduction corresponds to a closed section of $\mathcal{F}(M)/Sp(2n,\mathbb{R})$ then it is a symplectic structure. It is claimed in here that, as an integrable $G$-structure, a symplectic manifold is a Cartan geometry. So, if we want to describe a symplectic manifold as a Cartan geometry of type $(G,H)$ what are the possible choices of Lie groups $G$ and $H$? Different choices of $G$ and $H$ will give rise to homogeneous spaces $G/H $ that are related by model mutation. I am primarily concerned with the groups that give rise to a compact model $G/H$ for symplectic manifolds.","An almost symplectic structure on a smooth even dimension manifold $M$ can be viewed as a reduction of structure group $Sp(2n,\mathbb{R}) \hookrightarrow GL(2n,\mathbb{R})$ for the principal frame bundle $\mathcal{F}(M)$. If this structure group reduction corresponds to a closed section of $\mathcal{F}(M)/Sp(2n,\mathbb{R})$ then it is a symplectic structure. It is claimed in here that, as an integrable $G$-structure, a symplectic manifold is a Cartan geometry. So, if we want to describe a symplectic manifold as a Cartan geometry of type $(G,H)$ what are the possible choices of Lie groups $G$ and $H$? Different choices of $G$ and $H$ will give rise to homogeneous spaces $G/H $ that are related by model mutation. I am primarily concerned with the groups that give rise to a compact model $G/H$ for symplectic manifolds.",,['differential-geometry']
47,Curvature function and rate of change of angle,Curvature function and rate of change of angle,,"Let $\gamma:(a,b)\rightarrow \mathbb{R}^2$ be a smooth curve with $\| \dot{\gamma}(s)\|=1$ for all $s\in (a,b)$. Fix $s_0\in (a,b)$ and let the unit vector $\dot{\gamma}(s_0)$ be represented by $(\cos \phi_0,\sin\phi_0)$.  Then there is smooth function $\phi$ with $\phi(s_0)=\phi_0$  such that    $$\dot{\gamma}(s)=(\cos\phi(s),\sin\phi(s))$$   for all $s\in (a,b)$. The proof goes as follows: let  $$\dot{\gamma}(s)=(f(s),g(s))$$ so that $f(s)^2+g(s)^2=1$ for all $s$. Define  $$\phi(s)=\phi_0 + \int_{s_0}^s (f\dot{g}-g\dot{f})du$$ It is then shown that this is required $\phi$ in the theorem. Q. I didn't get intuition for choice (definition) of $\phi$. How do we justify the choice of $\phi$ above? Reference: Elementary differential geometry by Pressley, Proposition 2.2.1 (New edition) Using the explicitly defined angular function $\phi$, the curvature function is given by  $$\kappa_s =\frac{d\phi}{ds}.$$","Let $\gamma:(a,b)\rightarrow \mathbb{R}^2$ be a smooth curve with $\| \dot{\gamma}(s)\|=1$ for all $s\in (a,b)$. Fix $s_0\in (a,b)$ and let the unit vector $\dot{\gamma}(s_0)$ be represented by $(\cos \phi_0,\sin\phi_0)$.  Then there is smooth function $\phi$ with $\phi(s_0)=\phi_0$  such that    $$\dot{\gamma}(s)=(\cos\phi(s),\sin\phi(s))$$   for all $s\in (a,b)$. The proof goes as follows: let  $$\dot{\gamma}(s)=(f(s),g(s))$$ so that $f(s)^2+g(s)^2=1$ for all $s$. Define  $$\phi(s)=\phi_0 + \int_{s_0}^s (f\dot{g}-g\dot{f})du$$ It is then shown that this is required $\phi$ in the theorem. Q. I didn't get intuition for choice (definition) of $\phi$. How do we justify the choice of $\phi$ above? Reference: Elementary differential geometry by Pressley, Proposition 2.2.1 (New edition) Using the explicitly defined angular function $\phi$, the curvature function is given by  $$\kappa_s =\frac{d\phi}{ds}.$$",,['differential-geometry']
48,Atlas of a regular surface,Atlas of a regular surface,,"I have the following set of $R^3$: $$ S=\{(x,y,z) \in \mathbb{R}^3: \, x^2+y^2-z^3=1\} $$ It is immediate to see that $S$ is a regular surface. How may I find an atlas? When  $z \neq 0$, as $z=\sqrt[3]{x^2+y^2-1}$, we have the parameterization $x(u,v)=(u,v,\sqrt[3]{u^2+v^2-1})$ but what happens when $z=0$?","I have the following set of $R^3$: $$ S=\{(x,y,z) \in \mathbb{R}^3: \, x^2+y^2-z^3=1\} $$ It is immediate to see that $S$ is a regular surface. How may I find an atlas? When  $z \neq 0$, as $z=\sqrt[3]{x^2+y^2-1}$, we have the parameterization $x(u,v)=(u,v,\sqrt[3]{u^2+v^2-1})$ but what happens when $z=0$?",,['differential-geometry']
49,Equation for great circles of a sphere [closed],Equation for great circles of a sphere [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Background : I have a sphere of some radius R. What I'm trying to do is essentially create a wireframe consisting of great circles that run along the sphere. I want an equation to represent the great circles so that I can find points that run along those trajectories. I don't have enough credit to post links, but there a post in the Mathematica stack exchange titled: How to draw a great circle on a sphere? Which is what I want to achieve. However, I want to implement it in python and require a further breakdown of the equations that are happening behind the scenes. I will be plotting these equations in python.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 5 years ago . Improve this question Background : I have a sphere of some radius R. What I'm trying to do is essentially create a wireframe consisting of great circles that run along the sphere. I want an equation to represent the great circles so that I can find points that run along those trajectories. I don't have enough credit to post links, but there a post in the Mathematica stack exchange titled: How to draw a great circle on a sphere? Which is what I want to achieve. However, I want to implement it in python and require a further breakdown of the equations that are happening behind the scenes. I will be plotting these equations in python.",,"['geometry', 'differential-geometry', 'parametric', 'spheres']"
50,Under what conditions can one glue together local diffeomorphisms?,Under what conditions can one glue together local diffeomorphisms?,,"I know that, given an open cover $\{U_\alpha\}$ of a manifold $M$ and a family of smooth maps $\,f_\alpha: U_\alpha \to N$ that agree on overlaps, it is possible to construct a smooth $f:M \to N$ that restricts to $f_\alpha$ on each $U_\alpha$. My question is, are there conditions under which you can do the same thing with a family of local diffeomorphisms? I have a family of such maps defined on open subsets of some $M$ that agree on overlaps, and I would like to glue them together on some larger open set and have the extended map remain a local diffeomorphism.  Is such a thing possible? Thanks, EDIT: To be more clear, I suppose I mean conditions on which the extended map is a diffeomorphism on the entire larger open set.  It is obviously still a local diffeomorphism after extension.","I know that, given an open cover $\{U_\alpha\}$ of a manifold $M$ and a family of smooth maps $\,f_\alpha: U_\alpha \to N$ that agree on overlaps, it is possible to construct a smooth $f:M \to N$ that restricts to $f_\alpha$ on each $U_\alpha$. My question is, are there conditions under which you can do the same thing with a family of local diffeomorphisms? I have a family of such maps defined on open subsets of some $M$ that agree on overlaps, and I would like to glue them together on some larger open set and have the extended map remain a local diffeomorphism.  Is such a thing possible? Thanks, EDIT: To be more clear, I suppose I mean conditions on which the extended map is a diffeomorphism on the entire larger open set.  It is obviously still a local diffeomorphism after extension.",,"['differential-geometry', 'differential-topology', 'smooth-manifolds']"
51,Trying to prove $\partial^2=0$ on $k$-cells,Trying to prove  on -cells,\partial^2=0 k,"Consider a $k$-cell $ c : [0,1]^k \to U \subset \mathbb{R}^n , (t_1,...,t_k) \mapsto c (t_1,...,t_k) $. Then the boundary of $c$, $\partial c$ is defined as $$ \partial c := \sum_{i=1}^k (-1)^{i-1} \left( c_i^1 - c_i^0 \right) $$ where $$ c_i^1 := c(t_1,...,t_{i-1},1,t_{i+1},...,t_k)  \\ c_i^0 := c(t_1,...,t_{i-1},0,t_{i+1},...,t_k) $$ Then supposing $c = \sum_m a^m c_m$ is a $k$-chain ($a^m \in \mathbb{R}$, $c_m$ $k$-cells), itâ€™s boundary is defined by $$ \partial c = \partial \left( \sum_m a^m c_m \right) := \sum_m a^m \partial c_m $$ Iâ€™m struggling to prove the special property of $\partial$ that $\partial^2 = 0$. Hereâ€™s what I have so far... Since $\partial$ is linear, it is sufficient to prove $\partial^2 c = 0$ for any $k$-cell $c$. Introducing another sigma sign, the definition of $\partial c$ can be made to look nicer, $$  \partial c := \sum_{i=1}^k (-1)^{i-1} \left( c_i^1 - c_i^0 \right)  \\  =  \sum_{i=1}^k (-1)^{i-1} \sum_{\rho=0}^1 (-1)^{\rho+1} c_i^\rho   \\ = \sum_{i=1}^k \sum_{\rho=0}^1 (-1)^{i+\rho} c_i^\rho $$ Then, I tried brute forcing some algebra and definitions... $$ \partial^2 c = \partial \sum_{i=1}^k \sum_{\rho=0}^1 (-1)^{i+\rho} c_i^\rho  = \sum_{i=1}^k \sum_{\rho=0}^1 (-1)^{i+\rho} \partial c_i^\rho \\  = \sum_{i=1}^k \sum_{\rho=0}^1 (-1)^{i+\rho} \sum_{j=1 | j\neq i}^k \sum_{\sigma=0}^1 (-1)^{j+\sigma} c_{ij}^{\rho \sigma}  \\  = \sum_{i,j=1 | i\neq j }^{k} \sum_{\rho,\sigma = 0}^{1} (-1)^{i+j+\rho+\sigma} c_{ij}^{\rho\sigma}  $$ where $$ c_{ij}^{\rho\sigma} = c(t_1, ... , t_{i-1} , \rho , t_{i+1} , ... , t_{j-1} , \sigma, t_{j+1}, ... , t_k)  $$ This is where Iâ€™m stuck.","Consider a $k$-cell $ c : [0,1]^k \to U \subset \mathbb{R}^n , (t_1,...,t_k) \mapsto c (t_1,...,t_k) $. Then the boundary of $c$, $\partial c$ is defined as $$ \partial c := \sum_{i=1}^k (-1)^{i-1} \left( c_i^1 - c_i^0 \right) $$ where $$ c_i^1 := c(t_1,...,t_{i-1},1,t_{i+1},...,t_k)  \\ c_i^0 := c(t_1,...,t_{i-1},0,t_{i+1},...,t_k) $$ Then supposing $c = \sum_m a^m c_m$ is a $k$-chain ($a^m \in \mathbb{R}$, $c_m$ $k$-cells), itâ€™s boundary is defined by $$ \partial c = \partial \left( \sum_m a^m c_m \right) := \sum_m a^m \partial c_m $$ Iâ€™m struggling to prove the special property of $\partial$ that $\partial^2 = 0$. Hereâ€™s what I have so far... Since $\partial$ is linear, it is sufficient to prove $\partial^2 c = 0$ for any $k$-cell $c$. Introducing another sigma sign, the definition of $\partial c$ can be made to look nicer, $$  \partial c := \sum_{i=1}^k (-1)^{i-1} \left( c_i^1 - c_i^0 \right)  \\  =  \sum_{i=1}^k (-1)^{i-1} \sum_{\rho=0}^1 (-1)^{\rho+1} c_i^\rho   \\ = \sum_{i=1}^k \sum_{\rho=0}^1 (-1)^{i+\rho} c_i^\rho $$ Then, I tried brute forcing some algebra and definitions... $$ \partial^2 c = \partial \sum_{i=1}^k \sum_{\rho=0}^1 (-1)^{i+\rho} c_i^\rho  = \sum_{i=1}^k \sum_{\rho=0}^1 (-1)^{i+\rho} \partial c_i^\rho \\  = \sum_{i=1}^k \sum_{\rho=0}^1 (-1)^{i+\rho} \sum_{j=1 | j\neq i}^k \sum_{\sigma=0}^1 (-1)^{j+\sigma} c_{ij}^{\rho \sigma}  \\  = \sum_{i,j=1 | i\neq j }^{k} \sum_{\rho,\sigma = 0}^{1} (-1)^{i+j+\rho+\sigma} c_{ij}^{\rho\sigma}  $$ where $$ c_{ij}^{\rho\sigma} = c(t_1, ... , t_{i-1} , \rho , t_{i+1} , ... , t_{j-1} , \sigma, t_{j+1}, ... , t_k)  $$ This is where Iâ€™m stuck.",,['differential-geometry']
52,"If $F^*\alpha=\alpha$, then $F$ is the cotangent lift of some $\phi$","If , then  is the cotangent lift of some",F^*\alpha=\alpha F \phi,"Let $Q$ be a smooth manifold, $\alpha\in\Omega^1(T^*Q)$ the tautological $1$-form and $\omega:=-d\alpha$. Suppose there is a diffeomorphism $F:T^*Q\to T^*Q$ such that $F^*\alpha=\alpha$. Prove there is a diffeomorphism $\phi:Q\to Q$ such that $F$ is the cotangent lift of $\phi$. Suggested plan: 1) Prove that the Euler field $X$ (defined by $i_X\omega =-\alpha$) is invariant under $F$, i.e., $dF(X)=X\circ F$. 2) If $\phi_t^X$ is the flow of $X$, prove that $\phi_t^X\circ F=F\circ\phi_t^X$ and that $\phi_t^X(x,\xi)=(x,e^t\xi)$ locally. 3) Verify that $F(\lambda m)=\lambda F(m)$ for all $m\in T_q^*Q$, $\lambda\in\mathbb{R}$. Conclude there exists $\phi$ such that $\phi\circ\pi=\pi\circ F$ and that $F$ is the cotangent lift of $\phi$. I've already gone through $1)$ and $2)$ but I'm stuck with $3)$. Here where I'm at: for $\lambda>0$, we have: $$F(\lambda m)=F(x,\lambda\xi)=F(x,e^{ln(\lambda)}\xi)=F\circ\varphi_{ln(\lambda)}^X(x,\xi)=\varphi_{ln(\lambda)}^X\circ F(x,\xi)=\lambda F(m)$$ By continuity, that also covers the case $\lambda=0$, but I don't know what to do when $\lambda<0$. I tried doing $F(\lambda p)=F(-\lambda(-p))=-\lambda F(-p)$, but I can't prove $F(-p)=-F(p)$. I know how to prove that if such a $\phi$ exists it must be a diffeomorphism. My problem is to define $\phi$ and to check $F$ is its cotangent lift. If I could prove $F$ is linear on the fibers, then I could just define $\phi:=\pi\circ F\circ \eta$, where $\eta:Q\to T^*Q$ is any $1$-form in $Q$, but I wasn't able to prove the aditive property (i.e., $F(v+w)=F(v)+F(w))$. Besides, the exercise appararently suggests we only need the scaling property, which is also confusing me. For $F$ being the cotangent lift, I'm also stuck.","Let $Q$ be a smooth manifold, $\alpha\in\Omega^1(T^*Q)$ the tautological $1$-form and $\omega:=-d\alpha$. Suppose there is a diffeomorphism $F:T^*Q\to T^*Q$ such that $F^*\alpha=\alpha$. Prove there is a diffeomorphism $\phi:Q\to Q$ such that $F$ is the cotangent lift of $\phi$. Suggested plan: 1) Prove that the Euler field $X$ (defined by $i_X\omega =-\alpha$) is invariant under $F$, i.e., $dF(X)=X\circ F$. 2) If $\phi_t^X$ is the flow of $X$, prove that $\phi_t^X\circ F=F\circ\phi_t^X$ and that $\phi_t^X(x,\xi)=(x,e^t\xi)$ locally. 3) Verify that $F(\lambda m)=\lambda F(m)$ for all $m\in T_q^*Q$, $\lambda\in\mathbb{R}$. Conclude there exists $\phi$ such that $\phi\circ\pi=\pi\circ F$ and that $F$ is the cotangent lift of $\phi$. I've already gone through $1)$ and $2)$ but I'm stuck with $3)$. Here where I'm at: for $\lambda>0$, we have: $$F(\lambda m)=F(x,\lambda\xi)=F(x,e^{ln(\lambda)}\xi)=F\circ\varphi_{ln(\lambda)}^X(x,\xi)=\varphi_{ln(\lambda)}^X\circ F(x,\xi)=\lambda F(m)$$ By continuity, that also covers the case $\lambda=0$, but I don't know what to do when $\lambda<0$. I tried doing $F(\lambda p)=F(-\lambda(-p))=-\lambda F(-p)$, but I can't prove $F(-p)=-F(p)$. I know how to prove that if such a $\phi$ exists it must be a diffeomorphism. My problem is to define $\phi$ and to check $F$ is its cotangent lift. If I could prove $F$ is linear on the fibers, then I could just define $\phi:=\pi\circ F\circ \eta$, where $\eta:Q\to T^*Q$ is any $1$-form in $Q$, but I wasn't able to prove the aditive property (i.e., $F(v+w)=F(v)+F(w))$. Besides, the exercise appararently suggests we only need the scaling property, which is also confusing me. For $F$ being the cotangent lift, I'm also stuck.",,"['differential-geometry', 'symplectic-geometry']"
53,Relation between lie derivative of a vector field and associated 1-form in a Lorentzian manifold,Relation between lie derivative of a vector field and associated 1-form in a Lorentzian manifold,,"Let $(M,g)$ be a Lorentzian manifold and $X$ and $u$ represent two vector fields in $M$ such that $\mathcal{L}_X u=0$, that is, $u$ is Lie transported along the integral curve of $X$. My question is: given the associated 1-form to $u$, $u^\flat$, is $\mathcal{L}_X u^\flat=0$? I would say yes, but my common sense may be tricking me and I don't really know how to prove such a thing. Edit: Following Jackozee Hakkiuz suggestion I tried using the Leibniz rule such that $$ X<u^\flat,u> ~=~ <\mathcal{L}_X u^\flat,u> + <u^\flat,\mathcal{L}_X u> ~ =~ <\mathcal{L}_X u^\flat,u>~. $$ But I'm stuck. I tried playing around with the expressions of the above quantities in a local coordinate system but I can't seem to find a relation that answers my question...","Let $(M,g)$ be a Lorentzian manifold and $X$ and $u$ represent two vector fields in $M$ such that $\mathcal{L}_X u=0$, that is, $u$ is Lie transported along the integral curve of $X$. My question is: given the associated 1-form to $u$, $u^\flat$, is $\mathcal{L}_X u^\flat=0$? I would say yes, but my common sense may be tricking me and I don't really know how to prove such a thing. Edit: Following Jackozee Hakkiuz suggestion I tried using the Leibniz rule such that $$ X<u^\flat,u> ~=~ <\mathcal{L}_X u^\flat,u> + <u^\flat,\mathcal{L}_X u> ~ =~ <\mathcal{L}_X u^\flat,u>~. $$ But I'm stuck. I tried playing around with the expressions of the above quantities in a local coordinate system but I can't seem to find a relation that answers my question...",,"['differential-geometry', 'smooth-manifolds', 'semi-riemannian-geometry', 'lie-derivative']"
54,smooth projective variety with arbitary large degree irreducible divisors,smooth projective variety with arbitary large degree irreducible divisors,,Does every  projective complex two dimensinal manifold have divisors $D$ of arbitary large degree (integral of chern class of $[D]$  with a fixed Kahler form) which cannot be written as $D= dD_1$ where $D_1$  is  a divisor of lower degree? Example: Take $\mathbb{CP}^{2}$ and divisors which are zero sets of homogenous polynomials  $(x_1)^{d} + (x_2)^{d} + (x_3)^{d}$ where $d$ varies up to infinity. If so a reference,Does every  projective complex two dimensinal manifold have divisors $D$ of arbitary large degree (integral of chern class of $[D]$  with a fixed Kahler form) which cannot be written as $D= dD_1$ where $D_1$  is  a divisor of lower degree? Example: Take $\mathbb{CP}^{2}$ and divisors which are zero sets of homogenous polynomials  $(x_1)^{d} + (x_2)^{d} + (x_3)^{d}$ where $d$ varies up to infinity. If so a reference,,"['differential-geometry', 'algebraic-geometry', 'complex-geometry']"
55,Which specific smooth structure are we using in general relativity?,Which specific smooth structure are we using in general relativity?,,"In this lecture by Fredric Schuller it is said that in the case of a non compact four dimensional manifold there is a non countable infinity of differentiable or smooth manifolds that are NOT diffeomorphic. Differentiable structures definition and classification - Lec 07 - Frederic Schuller My question is that how this fact from math can be related to or affect the study of black holes, say finding the Schwarzschild solution or the study of cosmology, say solving for the FLRW metric. I mean in which part of the calculations we specify which specific smooth structure, i.e. $C^{\infty}$-compatible maximal atlas are we using to take the chart from it and put a coordinate system?","In this lecture by Fredric Schuller it is said that in the case of a non compact four dimensional manifold there is a non countable infinity of differentiable or smooth manifolds that are NOT diffeomorphic. Differentiable structures definition and classification - Lec 07 - Frederic Schuller My question is that how this fact from math can be related to or affect the study of black holes, say finding the Schwarzschild solution or the study of cosmology, say solving for the FLRW metric. I mean in which part of the calculations we specify which specific smooth structure, i.e. $C^{\infty}$-compatible maximal atlas are we using to take the chart from it and put a coordinate system?",,"['differential-geometry', 'manifolds']"
56,The (orbifold) space of symmetric complex matrix,The (orbifold) space of symmetric complex matrix,,"Let $K$ be a rank-2 symmetric complex matrix, such that the transpose $K^T=K$ is itself. Let $V$ be a rank-2 unitary matrix, $V \in U(2)$. Consider the identification between any K and K' of any rank-2 symmetric complex matrix, $$ K\sim K', $$ if it satisfies $$ V^T K V =K', $$ for any $V \in U(2).$ Originally, we can parametrize $K$ as $$ K=\begin{pmatrix}k1 & k\\ k& k2\end{pmatrix}, $$ with $$k1,k, k2 \in \mathbb{C}.$$  There are 6 real degrees of freedom in total. After the identification of the $K\sim K'$, constrained by the $V\in U(2)$ which has 4 real degrees of freedom. So totally there should be at least 2 real degrees of freedom left for the $d \geq 2$-dimensional space of the $K\sim K'$. (But $d \geq 2$ could be more due to the consideration of stabilizer.) question: What is the real dimension of the new space of $K$ (under the   $K\sim K'$ and $V^T K V =K'$, for any $V \in U(2)$ condition)? How do we parametrize this new space of $K$ in terms of a rank-2   matrix (mod out the redundancy under the $K\sim K'$ and $V^T K V =K'$,   for any $V \in U(2)$ condition)? (p.s. This space may be a called an orbifold space(?). i.e. The (orbifold) space of symmetric complex matrix after mod out a relation identifying a unitary matrix.)","Let $K$ be a rank-2 symmetric complex matrix, such that the transpose $K^T=K$ is itself. Let $V$ be a rank-2 unitary matrix, $V \in U(2)$. Consider the identification between any K and K' of any rank-2 symmetric complex matrix, $$ K\sim K', $$ if it satisfies $$ V^T K V =K', $$ for any $V \in U(2).$ Originally, we can parametrize $K$ as $$ K=\begin{pmatrix}k1 & k\\ k& k2\end{pmatrix}, $$ with $$k1,k, k2 \in \mathbb{C}.$$  There are 6 real degrees of freedom in total. After the identification of the $K\sim K'$, constrained by the $V\in U(2)$ which has 4 real degrees of freedom. So totally there should be at least 2 real degrees of freedom left for the $d \geq 2$-dimensional space of the $K\sim K'$. (But $d \geq 2$ could be more due to the consideration of stabilizer.) question: What is the real dimension of the new space of $K$ (under the   $K\sim K'$ and $V^T K V =K'$, for any $V \in U(2)$ condition)? How do we parametrize this new space of $K$ in terms of a rank-2   matrix (mod out the redundancy under the $K\sim K'$ and $V^T K V =K'$,   for any $V \in U(2)$ condition)? (p.s. This space may be a called an orbifold space(?). i.e. The (orbifold) space of symmetric complex matrix after mod out a relation identifying a unitary matrix.)",,"['linear-algebra', 'group-theory', 'differential-geometry', 'algebraic-topology', 'manifolds']"
57,expansion of exterior derivative of interior product,expansion of exterior derivative of interior product,,"Let $\omega$ be an 1-form and $X$ be a vectorfield. As usual $i_X \omega$ denotes the interior product and $\mathrm d$. the exterior derivative. Is there an expansion of the term $$ \mathrm d (i_X \omega) \quad ? $$ I would suspect that this can be expressed in terms of Lie-Derivatives, wedge-products and $i$ and $\mathrm d$ but I could not find anything in the literature.","Let $\omega$ be an 1-form and $X$ be a vectorfield. As usual $i_X \omega$ denotes the interior product and $\mathrm d$. the exterior derivative. Is there an expansion of the term $$ \mathrm d (i_X \omega) \quad ? $$ I would suspect that this can be expressed in terms of Lie-Derivatives, wedge-products and $i$ and $\mathrm d$ but I could not find anything in the literature.",,"['differential-geometry', 'reference-request', 'differential-forms', 'exterior-algebra', 'lie-derivative']"
58,Book indication on Hyperbolic space,Book indication on Hyperbolic space,,"could someone tell me a good introductory book on hyperbolic space? A book that will get me well on the road to understanding CMC surfaces in the hyperbolic. I've looked for books on the internet, but I'm not sure if they are good references.","could someone tell me a good introductory book on hyperbolic space? A book that will get me well on the road to understanding CMC surfaces in the hyperbolic. I've looked for books on the internet, but I'm not sure if they are good references.",,"['differential-geometry', 'reference-request', 'book-recommendation', 'hyperbolic-geometry']"
59,Embedded and immersed submanifold,Embedded and immersed submanifold,,"I try to solve the following problem:For each $a\in \mathbb{R}$, let $M_a$ be the subset of $\mathbb{R}^2$ defined by $$ M_a=\{(x,y):y^2=x(x-1)(x-a)\}.$$ For which values of $a$ is $M_a$ an embedded submanifold of $\mathbb{R}^2$? For which values can $M_a$ be given a topology and smooth structure making it into an immersed submanifold? My attempt: Let $F(x,y)=y^2-x(x-1)(x-a)$ so that $M_a=F^{-1}(0)$.\  Then $DF(x,y)=[-(3x^2-(2a+2)x+a)~~ 2y]$. Therefore, $0$ is a regular value of $F$ unless there is a point $(x,y)$ such that $$y=0,3x^2-(2a+2)x+a=0 ~\text{and}~ F(x,y)=-x(x-1)(x-a)=0.$$ In this case, $-x(x-1)(x-a)=0$ implies that $x=0$ or $x=1$ or $x=a$.\ When $x=0$, $3x^2-(2a+2)x+a=0$ implies that $a=0$. When $x=1$, $3x^2-(2a+2)x+a=0$ implies that $a=1$. The case $x=a$ gives the above values. Thus we have the following cases to consider: Case 1: $a=0, (x,y)=(0,0)$. When $a=0$, the point $(0,0)$ is local minimum of $F$, so $(0,0)$ is an isolated point of $M_0$, and hence $M_0$ can not be an embedded or immersed submanifold. my difficulty is in the following case: Case 2: $a=1, (x,y)=(1,0)$. when $a=1$, the point $(1,0)$ is saddle point of $F$, and thus the curve $M_1$ is self-intersecting at $(1,0)$. In such cases I saw examples saying it can not be an embedded submanifold but by giving an appropriate topology and smooth structure we can make  $M_1$ an immersed submanifold of $\mathbb{R}^2$. My difficulty is to justify how it cannot be embedded submanifold, and how we define the topology and smooth structure to make it immersed submanifold. Clearly for $a\neq 0$ and $a\neq 1$, $M_a$ is an embedded submanifold.","I try to solve the following problem:For each $a\in \mathbb{R}$, let $M_a$ be the subset of $\mathbb{R}^2$ defined by $$ M_a=\{(x,y):y^2=x(x-1)(x-a)\}.$$ For which values of $a$ is $M_a$ an embedded submanifold of $\mathbb{R}^2$? For which values can $M_a$ be given a topology and smooth structure making it into an immersed submanifold? My attempt: Let $F(x,y)=y^2-x(x-1)(x-a)$ so that $M_a=F^{-1}(0)$.\  Then $DF(x,y)=[-(3x^2-(2a+2)x+a)~~ 2y]$. Therefore, $0$ is a regular value of $F$ unless there is a point $(x,y)$ such that $$y=0,3x^2-(2a+2)x+a=0 ~\text{and}~ F(x,y)=-x(x-1)(x-a)=0.$$ In this case, $-x(x-1)(x-a)=0$ implies that $x=0$ or $x=1$ or $x=a$.\ When $x=0$, $3x^2-(2a+2)x+a=0$ implies that $a=0$. When $x=1$, $3x^2-(2a+2)x+a=0$ implies that $a=1$. The case $x=a$ gives the above values. Thus we have the following cases to consider: Case 1: $a=0, (x,y)=(0,0)$. When $a=0$, the point $(0,0)$ is local minimum of $F$, so $(0,0)$ is an isolated point of $M_0$, and hence $M_0$ can not be an embedded or immersed submanifold. my difficulty is in the following case: Case 2: $a=1, (x,y)=(1,0)$. when $a=1$, the point $(1,0)$ is saddle point of $F$, and thus the curve $M_1$ is self-intersecting at $(1,0)$. In such cases I saw examples saying it can not be an embedded submanifold but by giving an appropriate topology and smooth structure we can make  $M_1$ an immersed submanifold of $\mathbb{R}^2$. My difficulty is to justify how it cannot be embedded submanifold, and how we define the topology and smooth structure to make it immersed submanifold. Clearly for $a\neq 0$ and $a\neq 1$, $M_a$ is an embedded submanifold.",,['differential-geometry']
60,Are these two cotangent bundles symplectomorphic?,Are these two cotangent bundles symplectomorphic?,,"Let $T^{*}X$ be the cotangent bundle of $X$ and $\omega$ the tautological $2$-form. If $\sigma$ is a closed $1$-form defined on $X$, by defining $$\omega_{\sigma}=\omega+\pi^{*}\sigma,$$ I have proved that $(T^{*}X,\omega_{\sigma})$ is again a symplectic manifold. I want to know if $(T^{*}X,\omega)$ and $(T^{*}X,\omega_{\sigma})$ are symplectomorphic if $\sigma$ is exact. I have also shown that if $\theta$ is a $1$-form defined on $X$, $\theta(X)=\{(x,\theta_{x})\mid x\in X\}$ is a Lagrangian submanifold of $(T^{*}X,\omega_{\sigma})$ if and only if $\sigma=d\theta$. Then, I do believe that $(T^{*}X,\omega)$ and $(T^{*}X,\omega_{\sigma})$ are not symplectomorphic. If $\sigma$ is exact, $\sigma=d\theta$, then $\theta(X)$ is a Lagrangian submanifold in $(T^{*}X,\omega_{\sigma})$. Then, if $\varphi$ were a symplectomorphism, $\varphi(\theta(X))=\{(\varphi(x),\varphi(\theta_{x}))\mid x\in X\}$ would be a Lagrangian submanifold of $(T^{*}X,\omega)$. I am trying to prove that this in not, in fact, a Lagrangian submanifold, but I do not know how to do it. Can anyone help me, please? Thanks in advance. $\mathbf{EDIT}$: I think that by taking $f\colon (T^{*}X,\omega_{\sigma})\longrightarrow (T^{*}X,\omega)$ to be $f((x,\xi))=(x,\xi+\theta_{x}))$, $f$ is a symplectomorphism. I should prove that $f^{*}\alpha=\alpha+\pi^{*}\theta$ and I would be done. But does this hold? If I check it in the basis, considering $\alpha=\sum_{i=1}^{n}\xi_{i} dx_{i}$, $$f^{*}\alpha\big(\frac{\partial}{\partial x_{i}}\big)=\xi_{i},$$ but why is $$(\alpha+\pi^{*}\theta)\big( \frac{\partial}{\partial x_{i}}\big)=\xi_{i}?$$","Let $T^{*}X$ be the cotangent bundle of $X$ and $\omega$ the tautological $2$-form. If $\sigma$ is a closed $1$-form defined on $X$, by defining $$\omega_{\sigma}=\omega+\pi^{*}\sigma,$$ I have proved that $(T^{*}X,\omega_{\sigma})$ is again a symplectic manifold. I want to know if $(T^{*}X,\omega)$ and $(T^{*}X,\omega_{\sigma})$ are symplectomorphic if $\sigma$ is exact. I have also shown that if $\theta$ is a $1$-form defined on $X$, $\theta(X)=\{(x,\theta_{x})\mid x\in X\}$ is a Lagrangian submanifold of $(T^{*}X,\omega_{\sigma})$ if and only if $\sigma=d\theta$. Then, I do believe that $(T^{*}X,\omega)$ and $(T^{*}X,\omega_{\sigma})$ are not symplectomorphic. If $\sigma$ is exact, $\sigma=d\theta$, then $\theta(X)$ is a Lagrangian submanifold in $(T^{*}X,\omega_{\sigma})$. Then, if $\varphi$ were a symplectomorphism, $\varphi(\theta(X))=\{(\varphi(x),\varphi(\theta_{x}))\mid x\in X\}$ would be a Lagrangian submanifold of $(T^{*}X,\omega)$. I am trying to prove that this in not, in fact, a Lagrangian submanifold, but I do not know how to do it. Can anyone help me, please? Thanks in advance. $\mathbf{EDIT}$: I think that by taking $f\colon (T^{*}X,\omega_{\sigma})\longrightarrow (T^{*}X,\omega)$ to be $f((x,\xi))=(x,\xi+\theta_{x}))$, $f$ is a symplectomorphism. I should prove that $f^{*}\alpha=\alpha+\pi^{*}\theta$ and I would be done. But does this hold? If I check it in the basis, considering $\alpha=\sum_{i=1}^{n}\xi_{i} dx_{i}$, $$f^{*}\alpha\big(\frac{\partial}{\partial x_{i}}\big)=\xi_{i},$$ but why is $$(\alpha+\pi^{*}\theta)\big( \frac{\partial}{\partial x_{i}}\big)=\xi_{i}?$$",,"['differential-geometry', 'symplectic-geometry']"
61,Which data define an $SU(3)$ structure?,Which data define an  structure?,SU(3),"Let $(z_1,\overline{z}_1,\dots, z_n,\overline{z}_n)$ be the coordinates on $\mathbb{R}^{2n}$ given by the identification $\mathbb{R}^{2n} \simeq \mathbb{C}^n$. Define $$ g =\left| dz_1 \right|^2+ \dots + \left| dz_n \right|^2 \\ \omega = \frac{i}{2} (dz_1 \wedge d \overline{z}_1+ \dots + dz_n \wedge d \overline{z}_n) \\ \gamma=dz_1 \wedge \dots \wedge dz_m $$ The subgroup of $GL(2n)$ that stabilizes $g$ and $\omega$ is $U(n)$ (""2-out-of-3-property""). The subgroup of $GL(2n)$ that additionally stabilizes $\gamma$ is $SU(n)$. In one source an $SU(3)$ structure on a manifold $M$ is given by specifying a $2$-form $\omega$ and a $3$-form $\gamma$ so that in any point $p \in M$ there exists an element in the frame bundle $L \in GL(M)_p$ that pulls back $\omega$ and $\gamma$ to the forms above. Question:   A priori, this should not be an $SU(3)$-structure, because the stabilizer of the forms $\omega$ and $\gamma$ from above is bigger than $SU(3)$.   Is this correct? Is it maybe assumed that the manifold is a Riemannian manifold, and that $L \in GL(M)_p$ also pulls back the Riemannian metric to the $g$ defined above? I can see that this would then be an $SU(3)$-structure. Or is this a specialty of (complex) dimension 3, that here the stabilizer of $\omega$ and $\gamma$ is already equal to $SU(3)$?","Let $(z_1,\overline{z}_1,\dots, z_n,\overline{z}_n)$ be the coordinates on $\mathbb{R}^{2n}$ given by the identification $\mathbb{R}^{2n} \simeq \mathbb{C}^n$. Define $$ g =\left| dz_1 \right|^2+ \dots + \left| dz_n \right|^2 \\ \omega = \frac{i}{2} (dz_1 \wedge d \overline{z}_1+ \dots + dz_n \wedge d \overline{z}_n) \\ \gamma=dz_1 \wedge \dots \wedge dz_m $$ The subgroup of $GL(2n)$ that stabilizes $g$ and $\omega$ is $U(n)$ (""2-out-of-3-property""). The subgroup of $GL(2n)$ that additionally stabilizes $\gamma$ is $SU(n)$. In one source an $SU(3)$ structure on a manifold $M$ is given by specifying a $2$-form $\omega$ and a $3$-form $\gamma$ so that in any point $p \in M$ there exists an element in the frame bundle $L \in GL(M)_p$ that pulls back $\omega$ and $\gamma$ to the forms above. Question:   A priori, this should not be an $SU(3)$-structure, because the stabilizer of the forms $\omega$ and $\gamma$ from above is bigger than $SU(3)$.   Is this correct? Is it maybe assumed that the manifold is a Riemannian manifold, and that $L \in GL(M)_p$ also pulls back the Riemannian metric to the $g$ defined above? I can see that this would then be an $SU(3)$-structure. Or is this a specialty of (complex) dimension 3, that here the stabilizer of $\omega$ and $\gamma$ is already equal to $SU(3)$?",,"['linear-algebra', 'differential-geometry']"
62,Tangent Space Coincides with Null Space of Jacobian When Full Rank,Tangent Space Coincides with Null Space of Jacobian When Full Rank,,"This is for an optimization class, but I think what I am trying to prove is erring towards differential geometry, if that tag is inappropriate please remove it. My professor left this claim asserted but not proven, I would like to prove it. I found a lower dimensional case here on page 24 that I am trying to adapt. Here is the background, and the problem. Let $$g: \mathbb{R}^n \to \mathbb{R}^m,$$ $$g(\mathbf{x}) = [ g_1(\mathbf{x}), \dots , g_m(\mathbf{x})]^{T}$$ where $n \geq m$ and each $g_i$ is a $C^{1}$ map $\mathbb{R}^n \to \mathbb{R}$. Set $k$ to be the codim $n-m$. Define $S$ to be the zero locus of $g$ and for $\mathbf{x}_0 \in S$ define the tangent space $T_{\mathbf{x}_0}S$ to be the set of vectors $\mathbf{v}$ such that there exists a curve $\gamma(t) \subset S$ with $\gamma(0) = \mathbf{x}_0$ and $\gamma'(0) = \mathbf{v}$. Let $Dg(\mathbf{x}_0)$ denote the $m$ x $n$ Jacobian of $g$ at $\mathbf{x}_0$ and assume it has full rank. I would like to prove that $$\mathrm{Nul}(Dg(\mathbf{x}_0)) \subseteq T_{\mathbf{x}_0} S.$$ Here is what I have so far (almost entirely adapted from the link provided above). Suppose $\mathbf{v} \in \mathrm{Nul}(Dg(\mathbf{x}_0))$, then in particular $\nabla g_i(\mathbf{x}_0) \cdot \mathbf{v} = \mathbf{0}$ and all of the $\nabla g_i(\mathbf{x}_0)$ are linearly independent. After a suitable reordering of the variables, we can apply the Implicit Function Theorem  (exactly as stated on the wiki page here , reordering the variables so that $m$ x $m$ matrix is invertible, invoking the full rank of the Jacobian). Now denote the point $\mathbf{x}_0 = (x_1,\dots,x_k,y_1,\dots,y_m)$. Let $\mathbf{a} = (x_1,\dots,x_k)$ and $\mathbf{b} = (y_1, \dots, y_k)$. By invoking the IFT we have some open set $U \subset \mathbb{R}^k$, $\mathbf{a} \in U$, and the existence of a $C^{1}$ map $\phi \colon U \to \mathbb{R}^m$ such that $\phi(\mathbf{a}) = \mathbf{b}$ and $g(\mathbf{x},\phi(\mathbf{x}) = 0$ for all $\mathbf{x} \in U$. I am attempting to use all of the above to start building a parameterization $\gamma(t)$, but this is where I am stuck. I would like to define $\gamma_i(t) = x_i + v_i t$ for $1 \leq i \leq k$. Since $U$ is open I should be able to choose $\epsilon$ sufficiently small so that, at least for these first $k$ coordinates $\gamma$ stays in $S$ for $t \in (-\epsilon, \epsilon)$. But I don't know how to finish the next $m$ entries of $\gamma$. My assumption is that when the parameterization works out, the derivative portion of the Implicit Function Theorem combined with my hypothesis will allow me to say $\gamma'(0) = \mathbf{v}$. Thanks!","This is for an optimization class, but I think what I am trying to prove is erring towards differential geometry, if that tag is inappropriate please remove it. My professor left this claim asserted but not proven, I would like to prove it. I found a lower dimensional case here on page 24 that I am trying to adapt. Here is the background, and the problem. Let $$g: \mathbb{R}^n \to \mathbb{R}^m,$$ $$g(\mathbf{x}) = [ g_1(\mathbf{x}), \dots , g_m(\mathbf{x})]^{T}$$ where $n \geq m$ and each $g_i$ is a $C^{1}$ map $\mathbb{R}^n \to \mathbb{R}$. Set $k$ to be the codim $n-m$. Define $S$ to be the zero locus of $g$ and for $\mathbf{x}_0 \in S$ define the tangent space $T_{\mathbf{x}_0}S$ to be the set of vectors $\mathbf{v}$ such that there exists a curve $\gamma(t) \subset S$ with $\gamma(0) = \mathbf{x}_0$ and $\gamma'(0) = \mathbf{v}$. Let $Dg(\mathbf{x}_0)$ denote the $m$ x $n$ Jacobian of $g$ at $\mathbf{x}_0$ and assume it has full rank. I would like to prove that $$\mathrm{Nul}(Dg(\mathbf{x}_0)) \subseteq T_{\mathbf{x}_0} S.$$ Here is what I have so far (almost entirely adapted from the link provided above). Suppose $\mathbf{v} \in \mathrm{Nul}(Dg(\mathbf{x}_0))$, then in particular $\nabla g_i(\mathbf{x}_0) \cdot \mathbf{v} = \mathbf{0}$ and all of the $\nabla g_i(\mathbf{x}_0)$ are linearly independent. After a suitable reordering of the variables, we can apply the Implicit Function Theorem  (exactly as stated on the wiki page here , reordering the variables so that $m$ x $m$ matrix is invertible, invoking the full rank of the Jacobian). Now denote the point $\mathbf{x}_0 = (x_1,\dots,x_k,y_1,\dots,y_m)$. Let $\mathbf{a} = (x_1,\dots,x_k)$ and $\mathbf{b} = (y_1, \dots, y_k)$. By invoking the IFT we have some open set $U \subset \mathbb{R}^k$, $\mathbf{a} \in U$, and the existence of a $C^{1}$ map $\phi \colon U \to \mathbb{R}^m$ such that $\phi(\mathbf{a}) = \mathbf{b}$ and $g(\mathbf{x},\phi(\mathbf{x}) = 0$ for all $\mathbf{x} \in U$. I am attempting to use all of the above to start building a parameterization $\gamma(t)$, but this is where I am stuck. I would like to define $\gamma_i(t) = x_i + v_i t$ for $1 \leq i \leq k$. Since $U$ is open I should be able to choose $\epsilon$ sufficiently small so that, at least for these first $k$ coordinates $\gamma$ stays in $S$ for $t \in (-\epsilon, \epsilon)$. But I don't know how to finish the next $m$ entries of $\gamma$. My assumption is that when the parameterization works out, the derivative portion of the Implicit Function Theorem combined with my hypothesis will allow me to say $\gamma'(0) = \mathbf{v}$. Thanks!",,"['differential-geometry', 'optimization', 'manifolds', 'implicit-function-theorem']"
63,How to prove the real points of affine variety defined over the reals is a differentiable manifold?,How to prove the real points of affine variety defined over the reals is a differentiable manifold?,,"Let $V$ be an affine algebraic set defined as a zero set of real polynomials. Then $V \cap \mathbb{R}^n \backslash V^*$ defines a differentiable manifold according to Wikipedia https://en.wikipedia.org/wiki/Differentiable_manifold . Here $V^*$ is the set of singular points.  I have been taking this fact for granted, but realized not sure how to actually prove it. I would greatly appreciate comments and references. PS I would greatly appreciate a reference for this also!","Let $V$ be an affine algebraic set defined as a zero set of real polynomials. Then $V \cap \mathbb{R}^n \backslash V^*$ defines a differentiable manifold according to Wikipedia https://en.wikipedia.org/wiki/Differentiable_manifold . Here $V^*$ is the set of singular points.  I have been taking this fact for granted, but realized not sure how to actually prove it. I would greatly appreciate comments and references. PS I would greatly appreciate a reference for this also!",,"['differential-geometry', 'algebraic-geometry', 'reference-request']"
64,Dimension as a real manifold vs dimension as a real variety.,Dimension as a real manifold vs dimension as a real variety.,,"Let $X$ be a smooth $\mathbb{R}$ irreducible algebraic set, where the closed sets zero sets in $\mathbb{R}^n$ of real polynomials. I am trying to understand why dimension of $X$ as a manifold equals  the dimension defined topologically (given as the length of a maximal chain of irreducible algebraic sets). Any comments are appreciated. Thank you.","Let $X$ be a smooth $\mathbb{R}$ irreducible algebraic set, where the closed sets zero sets in $\mathbb{R}^n$ of real polynomials. I am trying to understand why dimension of $X$ as a manifold equals  the dimension defined topologically (given as the length of a maximal chain of irreducible algebraic sets). Any comments are appreciated. Thank you.",,"['differential-geometry', 'algebraic-geometry']"
65,Is the space of exact forms modulo exact forms whose anti-derivatives vanish on the boundary finite dimensional?,Is the space of exact forms modulo exact forms whose anti-derivatives vanish on the boundary finite dimensional?,,"Let $M$ be a smooth, connected, compact manifold with boundary (of dimension $d \ge 2$). Let $E$ be the space of exact $k$-forms on $M$. Define $$E_0=\{ \eta \in E \, | \, \eta=d\theta, \theta|_{\partial M}=0\}.$$ Is it true that $ E/E_0$ infinite dimensional? The answer is positive for $k=1$: $$ E/E_0=\{ df   \, | \, f \in C^{\infty}(M) \, \}\, / \, \{ dg \, | \,  g \in C^{\infty}(M) \, \, \text{and} \,g|_{\partial M}=0\}.$$ Let $f_i$ be an infinite set of functions on $\partial M$, such that $\{1,f_1,f_2\dots\}$ are linearly independent in $C^{\infty}(\partial M) $. Let $F_i$ be smooth extensions of $f_i$ to all of $M$. Then $[dF_i]$ are linearly independent in $E/E_0$. Indeed, suppose that $a^i[dF_i]=0$. Then $0=[a^idF_i]=[d(a^iF_i)]$, so $d(a^iF_i)=dg$ for some $g \in C^{\infty}(M)$ vanishing on $\partial M$. Since $M$ is connected, this implies $a^iF_i-g$ is some constant $c$, so in particular $a^if_i=c$, which implies $a_i=0$. What about $k>1$?","Let $M$ be a smooth, connected, compact manifold with boundary (of dimension $d \ge 2$). Let $E$ be the space of exact $k$-forms on $M$. Define $$E_0=\{ \eta \in E \, | \, \eta=d\theta, \theta|_{\partial M}=0\}.$$ Is it true that $ E/E_0$ infinite dimensional? The answer is positive for $k=1$: $$ E/E_0=\{ df   \, | \, f \in C^{\infty}(M) \, \}\, / \, \{ dg \, | \,  g \in C^{\infty}(M) \, \, \text{and} \,g|_{\partial M}=0\}.$$ Let $f_i$ be an infinite set of functions on $\partial M$, such that $\{1,f_1,f_2\dots\}$ are linearly independent in $C^{\infty}(\partial M) $. Let $F_i$ be smooth extensions of $f_i$ to all of $M$. Then $[dF_i]$ are linearly independent in $E/E_0$. Indeed, suppose that $a^i[dF_i]=0$. Then $0=[a^idF_i]=[d(a^iF_i)]$, so $d(a^iF_i)=dg$ for some $g \in C^{\infty}(M)$ vanishing on $\partial M$. Since $M$ is connected, this implies $a^iF_i-g$ is some constant $c$, so in particular $a^if_i=c$, which implies $a_i=0$. What about $k>1$?",,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'differential-forms']"
66,When does a polygon gives the maximum area?,When does a polygon gives the maximum area?,,"I have a polygon with $n$-vertices and of fixed length, I need to find a condition for which the polygon gives the maximum area without using isoperimetric inequality. I tried with the simple polygon ""Triangle"" ($n=3$) and find that it gives maximum area when it's 3 sides are equal. ( See here for proof ) Next, I break one side of the triangle to form a Quadrilateral ($n=4$). And find that it gives maximum area when it is a Square. ( See proof here ) My intuition tells me that if I increase $n$ then the corresponding polygon will give maximum if their sides are all equal, I assumed this is true for $n=k$ but I am unable to show this for $n=k+1$. Or is there is any other way to prove it? Any help will be appreciated. Thanks in advance.","I have a polygon with $n$-vertices and of fixed length, I need to find a condition for which the polygon gives the maximum area without using isoperimetric inequality. I tried with the simple polygon ""Triangle"" ($n=3$) and find that it gives maximum area when it's 3 sides are equal. ( See here for proof ) Next, I break one side of the triangle to form a Quadrilateral ($n=4$). And find that it gives maximum area when it is a Square. ( See proof here ) My intuition tells me that if I increase $n$ then the corresponding polygon will give maximum if their sides are all equal, I assumed this is true for $n=k$ but I am unable to show this for $n=k+1$. Or is there is any other way to prove it? Any help will be appreciated. Thanks in advance.",,"['geometry', 'differential-geometry', 'polygons']"
67,Codimension-1 submanifold as a inverse image of regular value. [closed],Codimension-1 submanifold as a inverse image of regular value. [closed],,"Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $M$ be a manifold and $N\subset M$ be a codimension-1 submanifold. Is it possible to find a function $H: M\rightarrow \mathbb{R}$ such that $N\subset H^{-1}(a)$ for some regular value a of $H$?. If it exists, what is necessary condition for $N=H^{-1}(a)?.$ I have no idea how to proceed it. Thanks, advance.","Closed. This question is off-topic . It is not currently accepting answers. This question is missing context or other details : Please improve the question by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level. Closed 6 years ago . Improve this question Let $M$ be a manifold and $N\subset M$ be a codimension-1 submanifold. Is it possible to find a function $H: M\rightarrow \mathbb{R}$ such that $N\subset H^{-1}(a)$ for some regular value a of $H$?. If it exists, what is necessary condition for $N=H^{-1}(a)?.$ I have no idea how to proceed it. Thanks, advance.",,"['differential-geometry', 'differential-topology', 'smooth-manifolds', 'morse-theory']"
68,"Is there a typo on this remark? Should it be $(\bar u,\bar v)$ instead of $(u,v)$?",Is there a typo on this remark? Should it be  instead of ?,"(\bar u,\bar v) (u,v)","I'm working through a text that provides an introduction to differential geometry, and the author writes the following in one of the demonstrations: (...) Let $X(u,v) = (x(u,v), y(u,v),z(u,v))$ be a regular parameterized surface and let $\overline{X}(\overline{u}, \overline{v}) = X \circ h=X(h(\overline{u}, \overline{v}))$ be a reparametrization of $X$, denoting by $(u,v) = h(\overline{u}, \overline{v})$ (...) I believe there is a typo, and the following would be correct: (...) Let $X(u,v) = (x(u,v), y(u,v),z(u,v))$ be a regular parameterized surface and let  $\overline{X}(\overline{u}, \overline{v}) = X \circ h=X(h(\overline{u}, \overline{v}))$ be a reparametrization of $X$, denoting by $\color{red}{(\overline{u}, \overline{v})} = h(\overline{u}, \overline{v})$ (...) Since taking $(u,v) = h(\overline{u}, \overline{v})$ then $\overline{X}(\overline{u}, \overline{v}) = X \circ h = X(u,v)$, the same parametrization! And this would be rather pointless. I haven't provided further context because I don't think it's necessary (if it is I'll do so, though).","I'm working through a text that provides an introduction to differential geometry, and the author writes the following in one of the demonstrations: (...) Let $X(u,v) = (x(u,v), y(u,v),z(u,v))$ be a regular parameterized surface and let $\overline{X}(\overline{u}, \overline{v}) = X \circ h=X(h(\overline{u}, \overline{v}))$ be a reparametrization of $X$, denoting by $(u,v) = h(\overline{u}, \overline{v})$ (...) I believe there is a typo, and the following would be correct: (...) Let $X(u,v) = (x(u,v), y(u,v),z(u,v))$ be a regular parameterized surface and let  $\overline{X}(\overline{u}, \overline{v}) = X \circ h=X(h(\overline{u}, \overline{v}))$ be a reparametrization of $X$, denoting by $\color{red}{(\overline{u}, \overline{v})} = h(\overline{u}, \overline{v})$ (...) Since taking $(u,v) = h(\overline{u}, \overline{v})$ then $\overline{X}(\overline{u}, \overline{v}) = X \circ h = X(u,v)$, the same parametrization! And this would be rather pointless. I haven't provided further context because I don't think it's necessary (if it is I'll do so, though).",,"['differential-geometry', 'notation', 'surfaces']"
69,Laplace-Beltrami operator in $\mathbb{R}^m$,Laplace-Beltrami operator in,\mathbb{R}^m,"The Laplace-Beltrami operator, $\Delta\colon \Omega^{k}(M)\longrightarrow \Omega^{k}(M)$ is defined as $\Delta=d\delta + \delta d$ where $d$ is the usual exterior derivative and $\delta$ is the codifferential: $$\delta=(-1)^{m(k+1)+1}*d*$$ where $*$ is the Hodge operator, $\alpha \wedge *\beta= \langle\alpha,\beta\rangle \text{Vol}$. I am trying to prove that if $f\in C^{\infty}(M)$, $\Delta f=-\sum_{i=1}^{m}\frac{\partial^2f}{\partial x_{i}^2}$. I have tried to do this: $\Delta f=(\delta d)(f)$ and  $$(\delta d)(f)=\delta\sum_{i=1}^{n}\frac{\partial f}{\partial x_{i}}dx_{i}.$$ Now, $*(\frac{\partial f}{\partial x_{i}}dx_{i})=(-1)^{i-1}\frac{\partial f}{\partial x_{i}}dx_{1}\wedge \cdots dx_{i-1}\wedge dx_{i+1}\wedge \cdots \wedge dx_{m}.$ Again,  $$\begin{split} d \left((-1)^{i-1}\frac{\partial f}{\partial x_{i}}dx_{1}\wedge \cdots dx_{i-1}\wedge \cdots \wedge dx_{m}\right)&=(-1)^{i-1}\frac{\partial ^2 f}{\partial x_{i}^2}dx_{i}\wedge dx_{1}\wedge \cdots \wedge dx_{m}\\ &=\frac{\partial ^2 f}{\partial x_{i}^2}dx_{1}\wedge \cdots \wedge dx_{m} \end{split},$$ and  $$*\left(\frac{\partial ^2 f}{\partial x_{i}^2}dx_{1}\wedge \cdots \wedge dx_{m}\right)=\frac{\partial ^2 f}{\partial x_{i}^2}.$$ In conclusion, I obtain that $\Delta f=(-1)^{m+1}\sum_{i=1}^{m}\frac{\partial ^2 f}{\partial x_{i}^2}$, instead of $-\sum_{i=1}^{m}\frac{\partial ^2 f}{\partial x_{i}^2}$. Can someone help me finding the wrong step? Thanks in advance.","The Laplace-Beltrami operator, $\Delta\colon \Omega^{k}(M)\longrightarrow \Omega^{k}(M)$ is defined as $\Delta=d\delta + \delta d$ where $d$ is the usual exterior derivative and $\delta$ is the codifferential: $$\delta=(-1)^{m(k+1)+1}*d*$$ where $*$ is the Hodge operator, $\alpha \wedge *\beta= \langle\alpha,\beta\rangle \text{Vol}$. I am trying to prove that if $f\in C^{\infty}(M)$, $\Delta f=-\sum_{i=1}^{m}\frac{\partial^2f}{\partial x_{i}^2}$. I have tried to do this: $\Delta f=(\delta d)(f)$ and  $$(\delta d)(f)=\delta\sum_{i=1}^{n}\frac{\partial f}{\partial x_{i}}dx_{i}.$$ Now, $*(\frac{\partial f}{\partial x_{i}}dx_{i})=(-1)^{i-1}\frac{\partial f}{\partial x_{i}}dx_{1}\wedge \cdots dx_{i-1}\wedge dx_{i+1}\wedge \cdots \wedge dx_{m}.$ Again,  $$\begin{split} d \left((-1)^{i-1}\frac{\partial f}{\partial x_{i}}dx_{1}\wedge \cdots dx_{i-1}\wedge \cdots \wedge dx_{m}\right)&=(-1)^{i-1}\frac{\partial ^2 f}{\partial x_{i}^2}dx_{i}\wedge dx_{1}\wedge \cdots \wedge dx_{m}\\ &=\frac{\partial ^2 f}{\partial x_{i}^2}dx_{1}\wedge \cdots \wedge dx_{m} \end{split},$$ and  $$*\left(\frac{\partial ^2 f}{\partial x_{i}^2}dx_{1}\wedge \cdots \wedge dx_{m}\right)=\frac{\partial ^2 f}{\partial x_{i}^2}.$$ In conclusion, I obtain that $\Delta f=(-1)^{m+1}\sum_{i=1}^{m}\frac{\partial ^2 f}{\partial x_{i}^2}$, instead of $-\sum_{i=1}^{m}\frac{\partial ^2 f}{\partial x_{i}^2}$. Can someone help me finding the wrong step? Thanks in advance.",,"['differential-geometry', 'differential-forms', 'laplacian']"
70,Gradient in polar coordinates,Gradient in polar coordinates,,"I was reading the answer from here , which is showing  $$\nabla = \partial_r e_r + \frac{1}{r} \partial_\theta e_\theta.$$ The answer actually made the choice  $$e_r = (\cos\theta, \sin\theta), \quad e_\theta = (-\sin\theta, \cos\theta)$$ I would like to clarify this step more naturally. More generally, let $g(x,y) = (u,v)$ be the change of variable map. Given a real valued function $f(x,y)$, we know in the new variable $\tilde f (u,v)= f(g^{-1}(u,v))$. Now given a vector field  $$v(x,y) = v_1\frac{\partial}{\partial x} +  v_2\frac{\partial}{\partial y}$$  we would like to calculate $\tilde v(u,v)$ in the new variable, I think this is given by $dg(v)$ following the change of variable formula $$dg\left(\frac{\partial}{\partial x}\right) = \frac{\partial u}{\partial x} \frac{\partial}{\partial u}+\frac{\partial v}{\partial x} \frac{\partial}{\partial v}$$ $$dg\left(\frac{\partial}{\partial y}\right) = \frac{\partial u}{\partial y} \frac{\partial}{\partial u}+\frac{\partial v}{\partial y} \frac{\partial}{\partial v}$$ Let us denote the coordinates of $v$ as $[v] = (v_1, v_2)$, we get  $$[\tilde v(u,v)] = (Jg)(g^{-1}(u,v))[v(g^{-1}(u,v))].$$ I tried the following calculation. Given $f(x,y)$, $h(r,\theta) = (x,y)$ the change of variable map, and $\tilde f = f \circ h$. Given the vector field: gradient of $\tilde f$ $$\tilde v(r, \theta) = \frac{\partial \tilde f}{\partial r}\frac{\partial  }{\partial r}+ \frac{1}{r^2}\frac{\partial \tilde f}{\partial \theta}\frac{\partial }{\partial \theta}$$ Then we see that  $$dh(\tilde v(r, \theta)) = \frac{\partial \tilde f}{\partial r}dh\left(\frac{\partial  }{\partial r}\right)+ \frac{1}{r^2}\frac{\partial \tilde f}{\partial \theta}dh\left(\frac{\partial }{\partial \theta}\right)\\ =  \frac{\partial \tilde f}{\partial r}\left(\cos\theta \frac{\partial  }{\partial x}+ \sin\theta \frac{\partial  }{\partial y}\right)+ \frac{1}{r^2}\frac{\partial \tilde f}{\partial \theta}\left(-{r}\sin\theta \frac{\partial  }{\partial x}+ {r}\cos\theta \frac{\partial  }{\partial y}\right)\\ =  \left(\cos\theta\frac{\partial \tilde f}{\partial r} -\frac{1}{r}\sin\theta \frac{\partial \tilde f}{\partial \theta}\right) \frac{\partial  }{\partial x}+  \left(\sin\theta\frac{\partial \tilde f}{\partial r} +\frac{1}{r}\cos\theta \frac{\partial \tilde f}{\partial \theta}\right) \frac{\partial  }{\partial y}\\ =  \frac{\partial  f }{\partial x}\frac{\partial  }{\partial x}+  \frac{\partial  f }{\partial y}\frac{\partial  }{\partial y}. $$ Now $e_r = dh\left(\frac{\partial  }{\partial r}\right)$ and $e_\theta = \frac{1}{r} dh\left(\frac{\partial  }{\partial \theta}\right)$","I was reading the answer from here , which is showing  $$\nabla = \partial_r e_r + \frac{1}{r} \partial_\theta e_\theta.$$ The answer actually made the choice  $$e_r = (\cos\theta, \sin\theta), \quad e_\theta = (-\sin\theta, \cos\theta)$$ I would like to clarify this step more naturally. More generally, let $g(x,y) = (u,v)$ be the change of variable map. Given a real valued function $f(x,y)$, we know in the new variable $\tilde f (u,v)= f(g^{-1}(u,v))$. Now given a vector field  $$v(x,y) = v_1\frac{\partial}{\partial x} +  v_2\frac{\partial}{\partial y}$$  we would like to calculate $\tilde v(u,v)$ in the new variable, I think this is given by $dg(v)$ following the change of variable formula $$dg\left(\frac{\partial}{\partial x}\right) = \frac{\partial u}{\partial x} \frac{\partial}{\partial u}+\frac{\partial v}{\partial x} \frac{\partial}{\partial v}$$ $$dg\left(\frac{\partial}{\partial y}\right) = \frac{\partial u}{\partial y} \frac{\partial}{\partial u}+\frac{\partial v}{\partial y} \frac{\partial}{\partial v}$$ Let us denote the coordinates of $v$ as $[v] = (v_1, v_2)$, we get  $$[\tilde v(u,v)] = (Jg)(g^{-1}(u,v))[v(g^{-1}(u,v))].$$ I tried the following calculation. Given $f(x,y)$, $h(r,\theta) = (x,y)$ the change of variable map, and $\tilde f = f \circ h$. Given the vector field: gradient of $\tilde f$ $$\tilde v(r, \theta) = \frac{\partial \tilde f}{\partial r}\frac{\partial  }{\partial r}+ \frac{1}{r^2}\frac{\partial \tilde f}{\partial \theta}\frac{\partial }{\partial \theta}$$ Then we see that  $$dh(\tilde v(r, \theta)) = \frac{\partial \tilde f}{\partial r}dh\left(\frac{\partial  }{\partial r}\right)+ \frac{1}{r^2}\frac{\partial \tilde f}{\partial \theta}dh\left(\frac{\partial }{\partial \theta}\right)\\ =  \frac{\partial \tilde f}{\partial r}\left(\cos\theta \frac{\partial  }{\partial x}+ \sin\theta \frac{\partial  }{\partial y}\right)+ \frac{1}{r^2}\frac{\partial \tilde f}{\partial \theta}\left(-{r}\sin\theta \frac{\partial  }{\partial x}+ {r}\cos\theta \frac{\partial  }{\partial y}\right)\\ =  \left(\cos\theta\frac{\partial \tilde f}{\partial r} -\frac{1}{r}\sin\theta \frac{\partial \tilde f}{\partial \theta}\right) \frac{\partial  }{\partial x}+  \left(\sin\theta\frac{\partial \tilde f}{\partial r} +\frac{1}{r}\cos\theta \frac{\partial \tilde f}{\partial \theta}\right) \frac{\partial  }{\partial y}\\ =  \frac{\partial  f }{\partial x}\frac{\partial  }{\partial x}+  \frac{\partial  f }{\partial y}\frac{\partial  }{\partial y}. $$ Now $e_r = dh\left(\frac{\partial  }{\partial r}\right)$ and $e_\theta = \frac{1}{r} dh\left(\frac{\partial  }{\partial \theta}\right)$",,"['calculus', 'differential-geometry', 'polar-coordinates']"
71,Is there a coordinate free proof for this result?,Is there a coordinate free proof for this result?,,"Let $(M,g)$ be a smooth manifold with metric tensor $g$. For this problem, the signature of $g$ seems to be of no importance. Consider a vector bundle $\pi : E\to M$ and a smooth embedding $\phi : N\to M$. We can form the pullback bundle $\phi^\ast E$ and introduce on it the induced connexion, characterized by $$(\phi^\ast\nabla)_X (\phi^\ast f)=\phi^\ast(\nabla_{\phi_\ast X}f).$$ First of all it is worth to remark that if $f : N\to \phi^\ast E$ is a section, we know it to be of the form $f(x)=(x,\bar{f}(x))$ where $\bar{f} : N\to E$ with $\pi\circ \bar{f}=\phi$. In other words, we extract $\bar{f}$ from $f$ by composing with the projection on the second factor $\operatorname{pr}_2: N\times E\to E$. If $f : N\to \phi^\ast E$ is a section, we shall denote $$(\phi^\ast \nabla)_{X}\bar{f}=\operatorname{pr}_2\circ (\phi^\ast\nabla)_X f.$$ I have first of all shown the following result: Let $\{e_a\}$ be a local frame of $E$ so that $f = f^a \phi^\ast e_a$. Suppose further that $(y,V)$ is a coordinate system on $N$ and $(x,U)$ a coordinate system on the image of $\phi$ inside $M$. Define $\Gamma_{\kappa a}^b$ by $$\nabla_{\frac{\partial}{\partial x^\kappa}}e_a=\Gamma_{\kappa a}^b e_b$$   then we have $$(\phi^\ast \nabla)_X \bar{f}=\left[X(f^b)+f^a(\phi_\ast \circ X)^\kappa \Gamma_{\kappa a}^b\circ \phi\right]e_b\circ \phi.$$ With this we can prove the following result: let $E=TM$ be the tangent bundle and $\nabla$ some connexion on it (not necessarily the Levi-Civita). Let $N=(-\epsilon,\epsilon)\times [a,b]$ equiped with the natural coordinate functions $(s,u)$ which are just the components of the identity. Let $\gamma : N\to M$ be a one-parameter family of geodesics. Introduce the tangent and deviation vector fields on $\gamma^\ast(TM)$ by $$\bar{T}=\gamma_\ast \circ \dfrac{\partial}{\partial u},\quad \bar{S}=\gamma_\ast \circ \dfrac{\partial}{\partial s}.$$ It is clear that the components of these vector fields over $\gamma$ are just $$\bar{T}^\beta = \dfrac{\partial \gamma^\beta}{\partial u},\quad \bar{S}^\beta=\dfrac{\partial \gamma^\beta}{\partial s}.$$ In that case I have shown in local coordinates on the image of $\gamma$ the following \begin{align}(\gamma^\ast\nabla)_{\frac{\partial}{\partial s}}\bar{T}^\beta&=\dfrac{\partial T^\beta}{\partial s}+T^\alpha S^\kappa \Gamma_{\kappa \alpha}^\beta\circ \gamma\\ &= \dfrac{\partial^2 \gamma^\beta}{\partial u\partial s}+T^\alpha S^\kappa \Gamma_{\kappa \alpha}^\beta\circ \gamma\\&=\dfrac{\partial^2 \gamma^\beta}{\partial s\partial u}+T^\alpha S^\kappa \Gamma_{\kappa \alpha}^\beta\circ \gamma\\&=\dfrac{\partial S^\beta}{\partial u}+T^\alpha S^\kappa \Gamma_{\kappa \alpha}^\beta\circ \gamma\\&=\dfrac{\partial S^\beta}{\partial u}+T^\alpha S^\kappa \Gamma_{\alpha\kappa }^\beta\circ \gamma+2 S^\kappa T^\alpha \Gamma_{[\kappa\alpha]}^\beta\circ\gamma\\&=(\gamma^\ast\nabla)_{\frac{\partial}{\partial u}}S^\beta+2S^\kappa T^\alpha\Gamma_{[\kappa\alpha]}^\beta\circ\gamma.\end{align} In particular if the connexion is torsion-free (the Levi-Civita for example) we get the nice-looking result: \begin{align}(\gamma^\ast\nabla)_{\frac{\partial}{\partial s}}\bar{T}^\beta&=(\gamma^\ast\nabla)_{\frac{\partial}{\partial u}}S^\beta.\end{align} This proof seems fine to me (of course I could have made some mistake and not noticed), but I'm wondering: is there some coordinate free proof of this result? The only way I've found to prove this result was going through the coordinate expression of the pullback connexion, but I believe some quicker and cleaner way without coordinates there should be.","Let $(M,g)$ be a smooth manifold with metric tensor $g$. For this problem, the signature of $g$ seems to be of no importance. Consider a vector bundle $\pi : E\to M$ and a smooth embedding $\phi : N\to M$. We can form the pullback bundle $\phi^\ast E$ and introduce on it the induced connexion, characterized by $$(\phi^\ast\nabla)_X (\phi^\ast f)=\phi^\ast(\nabla_{\phi_\ast X}f).$$ First of all it is worth to remark that if $f : N\to \phi^\ast E$ is a section, we know it to be of the form $f(x)=(x,\bar{f}(x))$ where $\bar{f} : N\to E$ with $\pi\circ \bar{f}=\phi$. In other words, we extract $\bar{f}$ from $f$ by composing with the projection on the second factor $\operatorname{pr}_2: N\times E\to E$. If $f : N\to \phi^\ast E$ is a section, we shall denote $$(\phi^\ast \nabla)_{X}\bar{f}=\operatorname{pr}_2\circ (\phi^\ast\nabla)_X f.$$ I have first of all shown the following result: Let $\{e_a\}$ be a local frame of $E$ so that $f = f^a \phi^\ast e_a$. Suppose further that $(y,V)$ is a coordinate system on $N$ and $(x,U)$ a coordinate system on the image of $\phi$ inside $M$. Define $\Gamma_{\kappa a}^b$ by $$\nabla_{\frac{\partial}{\partial x^\kappa}}e_a=\Gamma_{\kappa a}^b e_b$$   then we have $$(\phi^\ast \nabla)_X \bar{f}=\left[X(f^b)+f^a(\phi_\ast \circ X)^\kappa \Gamma_{\kappa a}^b\circ \phi\right]e_b\circ \phi.$$ With this we can prove the following result: let $E=TM$ be the tangent bundle and $\nabla$ some connexion on it (not necessarily the Levi-Civita). Let $N=(-\epsilon,\epsilon)\times [a,b]$ equiped with the natural coordinate functions $(s,u)$ which are just the components of the identity. Let $\gamma : N\to M$ be a one-parameter family of geodesics. Introduce the tangent and deviation vector fields on $\gamma^\ast(TM)$ by $$\bar{T}=\gamma_\ast \circ \dfrac{\partial}{\partial u},\quad \bar{S}=\gamma_\ast \circ \dfrac{\partial}{\partial s}.$$ It is clear that the components of these vector fields over $\gamma$ are just $$\bar{T}^\beta = \dfrac{\partial \gamma^\beta}{\partial u},\quad \bar{S}^\beta=\dfrac{\partial \gamma^\beta}{\partial s}.$$ In that case I have shown in local coordinates on the image of $\gamma$ the following \begin{align}(\gamma^\ast\nabla)_{\frac{\partial}{\partial s}}\bar{T}^\beta&=\dfrac{\partial T^\beta}{\partial s}+T^\alpha S^\kappa \Gamma_{\kappa \alpha}^\beta\circ \gamma\\ &= \dfrac{\partial^2 \gamma^\beta}{\partial u\partial s}+T^\alpha S^\kappa \Gamma_{\kappa \alpha}^\beta\circ \gamma\\&=\dfrac{\partial^2 \gamma^\beta}{\partial s\partial u}+T^\alpha S^\kappa \Gamma_{\kappa \alpha}^\beta\circ \gamma\\&=\dfrac{\partial S^\beta}{\partial u}+T^\alpha S^\kappa \Gamma_{\kappa \alpha}^\beta\circ \gamma\\&=\dfrac{\partial S^\beta}{\partial u}+T^\alpha S^\kappa \Gamma_{\alpha\kappa }^\beta\circ \gamma+2 S^\kappa T^\alpha \Gamma_{[\kappa\alpha]}^\beta\circ\gamma\\&=(\gamma^\ast\nabla)_{\frac{\partial}{\partial u}}S^\beta+2S^\kappa T^\alpha\Gamma_{[\kappa\alpha]}^\beta\circ\gamma.\end{align} In particular if the connexion is torsion-free (the Levi-Civita for example) we get the nice-looking result: \begin{align}(\gamma^\ast\nabla)_{\frac{\partial}{\partial s}}\bar{T}^\beta&=(\gamma^\ast\nabla)_{\frac{\partial}{\partial u}}S^\beta.\end{align} This proof seems fine to me (of course I could have made some mistake and not noticed), but I'm wondering: is there some coordinate free proof of this result? The only way I've found to prove this result was going through the coordinate expression of the pullback connexion, but I believe some quicker and cleaner way without coordinates there should be.",,"['differential-geometry', 'riemannian-geometry', 'alternative-proof', 'vector-bundles', 'semi-riemannian-geometry']"
72,Symplectic form on the n-torus,Symplectic form on the n-torus,,"I am trying to show that the n-torus, $\mathbb{R}^{2n}/ \mathbb{Z}^{2n}$ always has a symplectic form. By the Quotient Manifold Theorem, we have a smooth structure on the n-torus and a covering map $\pi \colon \mathbb{R}^{2n}\longrightarrow \mathbb{R}^{2n}/ \mathbb{Z}^{2n}$. Then, we have an open covering of the n-torus and in each open we can define a symplectic form by passing the symplectic form of an open of $\mathbb{R}^{2n}$ by a diffeomorphism. However, I am having troubles to understand why the symplectic form is defined globally; i.e, why it varies smoothly. Thanks in advance.","I am trying to show that the n-torus, $\mathbb{R}^{2n}/ \mathbb{Z}^{2n}$ always has a symplectic form. By the Quotient Manifold Theorem, we have a smooth structure on the n-torus and a covering map $\pi \colon \mathbb{R}^{2n}\longrightarrow \mathbb{R}^{2n}/ \mathbb{Z}^{2n}$. Then, we have an open covering of the n-torus and in each open we can define a symplectic form by passing the symplectic form of an open of $\mathbb{R}^{2n}$ by a diffeomorphism. However, I am having troubles to understand why the symplectic form is defined globally; i.e, why it varies smoothly. Thanks in advance.",,"['differential-geometry', 'symplectic-geometry']"
73,A flow of a parallel vector field preserves the connection?,A flow of a parallel vector field preserves the connection?,,"Let $M$ be a closed manifold equipped with an affine connection $\nabla$. Let $X \in \Gamma(TM)$, and suppose $X$ is a parallel vector field, i.e. $\nabla X=0$. Is it true that the flow of $X$ preserves the connection? i.e. let $\phi_t$ be the flow of $X$. Is it true that $\phi_t^* \nabla=\nabla$? Here, for a given diffeomorphism $\phi:M \to M$, I define $\phi^* \nabla$ by requiring $$ \phi_*\big((\phi^* \nabla)_XY\big)= \nabla_{\phi_* X}\phi_* Y,$$ where $\phi_*$ is the pushforward operation. (I think this is the 'right' definition). What about the converse, that is suppose that $\phi_t^* \nabla=\nabla$. Is $X$ parallel? I am not sure how to compute the 'variational derivative' $\frac{d}{dt}|_{t=0}\phi_t^* \nabla$.","Let $M$ be a closed manifold equipped with an affine connection $\nabla$. Let $X \in \Gamma(TM)$, and suppose $X$ is a parallel vector field, i.e. $\nabla X=0$. Is it true that the flow of $X$ preserves the connection? i.e. let $\phi_t$ be the flow of $X$. Is it true that $\phi_t^* \nabla=\nabla$? Here, for a given diffeomorphism $\phi:M \to M$, I define $\phi^* \nabla$ by requiring $$ \phi_*\big((\phi^* \nabla)_XY\big)= \nabla_{\phi_* X}\phi_* Y,$$ where $\phi_*$ is the pushforward operation. (I think this is the 'right' definition). What about the converse, that is suppose that $\phi_t^* \nabla=\nabla$. Is $X$ parallel? I am not sure how to compute the 'variational derivative' $\frac{d}{dt}|_{t=0}\phi_t^* \nabla$.",,"['differential-geometry', 'riemannian-geometry', 'calculus-of-variations', 'vector-bundles', 'connections']"
74,Vector bundle isomorphism from a collection of vector space isomorphisms,Vector bundle isomorphism from a collection of vector space isomorphisms,,"I've recently started studying vector bundles, and I cannot seem to understand this. I feel as though I am missing some simple, crucial fact. Suppose we have two vector bundles $E$ and $F$ over the same manifold $M$. My question is this: If I have a collection of functions $\{ f_x \}_{x\in M}$, where each $f_x : E_x \rightarrow F_x$ is an isomorphism of vector spaces, under what conditions can I define a function $f: E \rightarrow F$ that is a vector-bundle isomorphism? Clearly I can just define $f$ fibrewise based on the family of $f_x$'s, but how can I ensure that it is a smooth map between $E$ and $F$?","I've recently started studying vector bundles, and I cannot seem to understand this. I feel as though I am missing some simple, crucial fact. Suppose we have two vector bundles $E$ and $F$ over the same manifold $M$. My question is this: If I have a collection of functions $\{ f_x \}_{x\in M}$, where each $f_x : E_x \rightarrow F_x$ is an isomorphism of vector spaces, under what conditions can I define a function $f: E \rightarrow F$ that is a vector-bundle isomorphism? Clearly I can just define $f$ fibrewise based on the family of $f_x$'s, but how can I ensure that it is a smooth map between $E$ and $F$?",,"['differential-geometry', 'vector-bundles']"
75,Meaning of this exclamation mark?,Meaning of this exclamation mark?,,"In section 3 of the paper https://www.sciencedirect.com/science/article/pii/S0723086907000151 The author constructs a fiber bundle $(\rho_n)\zeta$ by taking the pullback of the diagram $S^8\xrightarrow{\rho_n} S^8$ with $\zeta$ above the rightmost $S^8$ (sorry dont know who to draw it online).    We're treating the sphere's as the one point compactifications of the octonions.  Here the map $\rho_n$ is just the map sending an octonion to it's $n$th power. In the next paragraph the author starts talking about a vector bundle $(\rho_n)^!\zeta$.  It doesn't seem to be explained what this exclamation notation means, and I haven't seen it before.  Any ideas? EDIT/UPDATE:  I'm tempted to believe that the exclamation is meant to indicate the isomorphism class of $(\rho_n)\zeta$ in $KO(S^8)$, however if that were the case, wouldn't the author also be using the notation $n^!\zeta$ to talk about the class of $n\zeta$ in $KO(S^8)$?  Instead they just use $n\zeta$... EDIT #2:  I'm nearly convinced that there is a typo and the initial definition of $(\rho_n)\zeta$ should have included an exclamation.  I have attempted to contact the author and will update when and if he responds. The professor who passed this paper on to me is currently out of the country, but when he returns I will also ask him if I don't have answer yet, and share his take.","In section 3 of the paper https://www.sciencedirect.com/science/article/pii/S0723086907000151 The author constructs a fiber bundle $(\rho_n)\zeta$ by taking the pullback of the diagram $S^8\xrightarrow{\rho_n} S^8$ with $\zeta$ above the rightmost $S^8$ (sorry dont know who to draw it online).    We're treating the sphere's as the one point compactifications of the octonions.  Here the map $\rho_n$ is just the map sending an octonion to it's $n$th power. In the next paragraph the author starts talking about a vector bundle $(\rho_n)^!\zeta$.  It doesn't seem to be explained what this exclamation notation means, and I haven't seen it before.  Any ideas? EDIT/UPDATE:  I'm tempted to believe that the exclamation is meant to indicate the isomorphism class of $(\rho_n)\zeta$ in $KO(S^8)$, however if that were the case, wouldn't the author also be using the notation $n^!\zeta$ to talk about the class of $n\zeta$ in $KO(S^8)$?  Instead they just use $n\zeta$... EDIT #2:  I'm nearly convinced that there is a typo and the initial definition of $(\rho_n)\zeta$ should have included an exclamation.  I have attempted to contact the author and will update when and if he responds. The professor who passed this paper on to me is currently out of the country, but when he returns I will also ask him if I don't have answer yet, and share his take.",,"['differential-geometry', 'fiber-bundles', 'k-theory', 'octonions']"
76,Example of submanifold without subspace topology,Example of submanifold without subspace topology,,"I am interested in giving an example for a closed, connected submanifold of a connected manifold which does not carry the subspace (or relative) topology. With some help from Boothby (III.4 p.71-72), I believe an example could be the following: Let $F : \mathbb{R} \to \mathbb{R}^2$ be given by $$F(t) = \left( 2 \cos\left( t - \frac{1}{2} \pi \right), \sin 2 \left(t - \frac{1}{2} \pi \right) \right) {;}$$ the image is a figure eight. Now, let $g(t)$ be a monotone increasing smooth function on $- \infty < t < \infty$ such that $g(0) = \pi$, $\lim\limits_{t \to - \infty} g(t) = 0$ and $\lim\limits_{t \to \infty} g(t) = 2 \pi$ (e.g., we may use $g(t) = \pi + 2 \arctan{t}$). Then define $G : \mathbb{R} \to \mathbb{R}^2$ by composition of $g(t)$ with $F(t)$: $$G(t) = F(g(t)) = \left( 2 \cos \left( g(t) - \frac{\pi}{2} \right), \sin 2 \left( g(t) - \frac{\pi}{2} \right) \right) {;}$$ note that $G(t)$ is an injective immersion. By definition, it follows that $G(\mathbb{R}) = \tilde{N}$ is a submanifold (or immersed submanifold) of $\mathbb{R}^2$. From this point, it gets tricky and I am unsure of how to show whether or not $\tilde{N}$ is closed. Boothby notes that $\mathbb{R}$ is not homeomorphic (under $G$) to $\tilde{N}$ considered as a subspace of $\mathbb{R}^2$. It seems reasonable that $\tilde{N}$ is closed, if $\mathbb{R}^2 - \tilde{N}$ is open, though I would like to be able to justify this rigorously. Is this an example of what I am looking for? If not, could someone point me in the right direction? Any hints or suggestions would be greatly appreciated. Edit: The image of a connected space under a continuous map is connected, and thus $\tilde{N}$ is connected.","I am interested in giving an example for a closed, connected submanifold of a connected manifold which does not carry the subspace (or relative) topology. With some help from Boothby (III.4 p.71-72), I believe an example could be the following: Let $F : \mathbb{R} \to \mathbb{R}^2$ be given by $$F(t) = \left( 2 \cos\left( t - \frac{1}{2} \pi \right), \sin 2 \left(t - \frac{1}{2} \pi \right) \right) {;}$$ the image is a figure eight. Now, let $g(t)$ be a monotone increasing smooth function on $- \infty < t < \infty$ such that $g(0) = \pi$, $\lim\limits_{t \to - \infty} g(t) = 0$ and $\lim\limits_{t \to \infty} g(t) = 2 \pi$ (e.g., we may use $g(t) = \pi + 2 \arctan{t}$). Then define $G : \mathbb{R} \to \mathbb{R}^2$ by composition of $g(t)$ with $F(t)$: $$G(t) = F(g(t)) = \left( 2 \cos \left( g(t) - \frac{\pi}{2} \right), \sin 2 \left( g(t) - \frac{\pi}{2} \right) \right) {;}$$ note that $G(t)$ is an injective immersion. By definition, it follows that $G(\mathbb{R}) = \tilde{N}$ is a submanifold (or immersed submanifold) of $\mathbb{R}^2$. From this point, it gets tricky and I am unsure of how to show whether or not $\tilde{N}$ is closed. Boothby notes that $\mathbb{R}$ is not homeomorphic (under $G$) to $\tilde{N}$ considered as a subspace of $\mathbb{R}^2$. It seems reasonable that $\tilde{N}$ is closed, if $\mathbb{R}^2 - \tilde{N}$ is open, though I would like to be able to justify this rigorously. Is this an example of what I am looking for? If not, could someone point me in the right direction? Any hints or suggestions would be greatly appreciated. Edit: The image of a connected space under a continuous map is connected, and thus $\tilde{N}$ is connected.",,"['general-topology', 'differential-geometry', 'examples-counterexamples', 'smooth-manifolds', 'submanifold']"
77,What is the exponential map?,What is the exponential map?,,"I am well versed in Calculus but I have never taken a differential geometry course. I am trying to understand what the exponential map is, with the main purpose to approximate a geodesic line on an elliptical manifold. I have read a couple of sites that try to describe it, but doing depth first search on every single term I encounter that I can't recognize is not very efficient. Can someone give an intuitive explanation of what the exponential map is?","I am well versed in Calculus but I have never taken a differential geometry course. I am trying to understand what the exponential map is, with the main purpose to approximate a geodesic line on an elliptical manifold. I have read a couple of sites that try to describe it, but doing depth first search on every single term I encounter that I can't recognize is not very efficient. Can someone give an intuitive explanation of what the exponential map is?",,"['calculus', 'geometry', 'differential-geometry']"
78,$H_{dR}^k(M/G)\to H_{dR}^k(M)$ is injective,is injective,H_{dR}^k(M/G)\to H_{dR}^k(M),"Let $M$ be a smooth manifold and $G$ a finite group of automorphisms acting properly on it. If $\pi:M\to M/G$ is the projection map, prove that $\pi^*:H_{dR}^k(M/G)\to H_{dR}^k(M)$ is injective. I know how to prove that $\pi^*:\Omega^k (M/G)\to\Omega^k (M) $ is injective using the fact that $\pi$ is a surjective submersion. But how do I prove injectiveness in cohomology?","Let $M$ be a smooth manifold and $G$ a finite group of automorphisms acting properly on it. If $\pi:M\to M/G$ is the projection map, prove that $\pi^*:H_{dR}^k(M/G)\to H_{dR}^k(M)$ is injective. I know how to prove that $\pi^*:\Omega^k (M/G)\to\Omega^k (M) $ is injective using the fact that $\pi$ is a surjective submersion. But how do I prove injectiveness in cohomology?",,"['differential-geometry', 'homology-cohomology', 'smooth-manifolds', 'pullback']"
79,Number of components of Levi Civita Connection $\Gamma^a_{bc}$.,Number of components of Levi Civita Connection .,\Gamma^a_{bc},"How follows on page $1$ of this paper, in the second last paragraph, the three formulas containing $n$ , namely $n^2(n+1)/2$ $n+n(n+1)/2$ and $n(n^2-3)/2$ Maybe it will suffice for me to understand the first number $n^2(n+1)/2$ to get the rest: This is the number of independent components in $\Gamma^a_{bc}=\Gamma^a_{cb} $ , but I do not understand the combinatorics behind it.","How follows on page of this paper, in the second last paragraph, the three formulas containing , namely and Maybe it will suffice for me to understand the first number to get the rest: This is the number of independent components in , but I do not understand the combinatorics behind it.",1 n n^2(n+1)/2 n+n(n+1)/2 n(n^2-3)/2 n^2(n+1)/2 \Gamma^a_{bc}=\Gamma^a_{cb} ,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'projective-geometry', 'connections']"
80,Computing the second Chern character on KÃ¤hler manifold,Computing the second Chern character on KÃ¤hler manifold,,"Let $(X, \omega)$  be a compact KÃ¤hler manifold and $E$ a vector bundle on $X$ with hermitian metric $h$. Let also $F_h$ be the curvature of Chern connection on $(E, h)$. It is a $(1,1)$-form with coefficients in $\operatorname{End}(E)$. In Simpson's paper ""Higgs bundles and local systems"" the following formula plays important role: $$ \int_X \operatorname{Tr}(F_h \wedge F_h) \wedge \omega^{n-2} = C_1||F_h||_{L^2} - C_2||\Lambda F_h||_{L^2} $$ for certain constants $C_1$ and $C_2$ (here $\Lambda$, as usual, is the hermitian-adjoint to the Lefschetz operator $L \colon \eta \mapsto \omega \wedge \eta$) Indeed in Simpson's paper this equation is used not for a curvature of a unitary connection, but for a pseudocurvature of a hermitian metric on vector bundle endowed with flat connection . However, I believe it is not really important and the proves must be similar. It seems that this relation holds in a general situation and follows from some standard Hodge theory. Although I don't understand how to prove it. Simpson claims that this fact follows from ""Riemann bilinear relations"", but I don't understand what he really means.","Let $(X, \omega)$  be a compact KÃ¤hler manifold and $E$ a vector bundle on $X$ with hermitian metric $h$. Let also $F_h$ be the curvature of Chern connection on $(E, h)$. It is a $(1,1)$-form with coefficients in $\operatorname{End}(E)$. In Simpson's paper ""Higgs bundles and local systems"" the following formula plays important role: $$ \int_X \operatorname{Tr}(F_h \wedge F_h) \wedge \omega^{n-2} = C_1||F_h||_{L^2} - C_2||\Lambda F_h||_{L^2} $$ for certain constants $C_1$ and $C_2$ (here $\Lambda$, as usual, is the hermitian-adjoint to the Lefschetz operator $L \colon \eta \mapsto \omega \wedge \eta$) Indeed in Simpson's paper this equation is used not for a curvature of a unitary connection, but for a pseudocurvature of a hermitian metric on vector bundle endowed with flat connection . However, I believe it is not really important and the proves must be similar. It seems that this relation holds in a general situation and follows from some standard Hodge theory. Although I don't understand how to prove it. Simpson claims that this fact follows from ""Riemann bilinear relations"", but I don't understand what he really means.",,"['differential-geometry', 'riemannian-geometry', 'complex-geometry', 'kahler-manifolds', 'hodge-theory']"
81,"What is the ""submersion principle?"" Showing that $SL_n(R)$ is a submanifold of $GL_n(R)$.","What is the ""submersion principle?"" Showing that  is a submanifold of .",SL_n(R) GL_n(R),"I'm watching the following series of video lectures on Lie groups .  In the last couple of minutes of the first lecture, he states his strategy to show that $\textrm{SL}_n(\mathbb{R})$ is a Lie subgroup of $\textrm{GL}_n(\mathbb{R})$ : 1 .  Show that $\textrm{SL}_n(\mathbb{R}) = \textrm{det}^{-1}\{1\}$ is a submanifold of $\textrm{GL}_n(\mathbb{R})$ at $I_n$ , by showing that the map on tangent spaces at $I_n$ is surjective, and then using the ""submersion principle."" 2 .  Use homogeneity to show that $\textrm{SL}_n(\mathbb{R})$ is a submanifold everywhere. The second principle is clear to me, as well as the fact that the tangent space map at the identity is surjective.  But I don't understand what is the ""submersion principle"" or how it is used.  I tried googling submersion principle but nothing useful came up.  This seems to have something to do with a smooth map having constant rank in a neighborhood of a point. Edit: Not a duplicate of the previous question of why SL is a submanifold, because I am asking about a specific approach to showing it is a submanifold.","I'm watching the following series of video lectures on Lie groups .  In the last couple of minutes of the first lecture, he states his strategy to show that is a Lie subgroup of : 1 .  Show that is a submanifold of at , by showing that the map on tangent spaces at is surjective, and then using the ""submersion principle."" 2 .  Use homogeneity to show that is a submanifold everywhere. The second principle is clear to me, as well as the fact that the tangent space map at the identity is surjective.  But I don't understand what is the ""submersion principle"" or how it is used.  I tried googling submersion principle but nothing useful came up.  This seems to have something to do with a smooth map having constant rank in a neighborhood of a point. Edit: Not a duplicate of the previous question of why SL is a submanifold, because I am asking about a specific approach to showing it is a submanifold.",\textrm{SL}_n(\mathbb{R}) \textrm{GL}_n(\mathbb{R}) \textrm{SL}_n(\mathbb{R}) = \textrm{det}^{-1}\{1\} \textrm{GL}_n(\mathbb{R}) I_n I_n \textrm{SL}_n(\mathbb{R}),"['differential-geometry', 'manifolds', 'lie-groups', 'smooth-manifolds', 'submanifold']"
82,Surfaces of revolution perpendicular to the plane xOy,Surfaces of revolution perpendicular to the plane xOy,,"Let $S$ be a surface of revolution parametrized by $(\varphi(v) \cos u, \varphi(v) \sin u, \delta(v))$. Assume $S$ has constant Gaussian curvature equal to 1. Since $K = -\frac{\varphi''}{\varphi}$, $\varphi'' + \varphi = 0$. If we solve this differential equation we obtain that  \begin{equation} \varphi(v) = c_1 \cos(v) + c_2 \sin(v). \end{equation} My question is the following: if we know that $S$ intersects perpendicularly the plane $xOy$, can we say that $\varphi(v) = c_1 \cos(v)$? Apparently, this is true, but I don't know why. I found the Gaussian map and at points $p$, where $p$ is in the intersection of $S$ and the plane $xOy$, $\varphi'(v) = 0$. I try to play with this but nothing came up. Please if you can help me, I will really appreciate it. Thanks!","Let $S$ be a surface of revolution parametrized by $(\varphi(v) \cos u, \varphi(v) \sin u, \delta(v))$. Assume $S$ has constant Gaussian curvature equal to 1. Since $K = -\frac{\varphi''}{\varphi}$, $\varphi'' + \varphi = 0$. If we solve this differential equation we obtain that  \begin{equation} \varphi(v) = c_1 \cos(v) + c_2 \sin(v). \end{equation} My question is the following: if we know that $S$ intersects perpendicularly the plane $xOy$, can we say that $\varphi(v) = c_1 \cos(v)$? Apparently, this is true, but I don't know why. I found the Gaussian map and at points $p$, where $p$ is in the intersection of $S$ and the plane $xOy$, $\varphi'(v) = 0$. I try to play with this but nothing came up. Please if you can help me, I will really appreciate it. Thanks!",,"['differential-geometry', 'surfaces', 'parametrization']"
83,Show that the area of a regular tube of radius $r$ around a curve $\alpha = 2\pi r $(length of $\alpha$),Show that the area of a regular tube of radius  around a curve (length of ),r \alpha = 2\pi r  \alpha,"This is a question from do Carmo exercises, Sec 2-5. I know I just have to compute the area by using First Fundamental form, area $$ = \int\int\sqrt{EG-F^2}du dv$$ for a paramatrisation $x(u, v)$ of the tube surface, but I can't think of a parametrisation in just $2$ variables.","This is a question from do Carmo exercises, Sec 2-5. I know I just have to compute the area by using First Fundamental form, area $$ = \int\int\sqrt{EG-F^2}du dv$$ for a paramatrisation $x(u, v)$ of the tube surface, but I can't think of a parametrisation in just $2$ variables.",,['differential-geometry']
84,"$G$ a Lie group, $V, S$ submanifolds of $G$ containing $e$, $\psi : V \times S \rightarrow G$; $\psi(v,s)=vs$, then $d\psi(X,0)=X$ and $d\psi(0,Y)=Y$","a Lie group,  submanifolds of  containing , ; , then  and","G V, S G e \psi : V \times S \rightarrow G \psi(v,s)=vs d\psi(X,0)=X d\psi(0,Y)=Y","Okay I couldn't fit this all in the title but here is the full setup: $G$ a Lie group with $V,S$ submanifolds of $G$ containing the identity element $e$. We are considering the map $\psi: V \times S \rightarrow G$ obtained by restricting the multiplication map on $G$, i.e. $\psi(v,s)=vs$. I am stuck trying to show that since $\psi(v,e)=v$ for $v \in V$ and $\psi(e,s)=s$ for $s \in S$, then it follows that the differential of $\psi$ at $(e,e)$ satisfies $d\psi(X,0)=X$ and $d\psi(0,Y)=Y$ for $X \in T_{e}V$ and $Y \in T_{e}S$. I am also confused about how we are identifying $T_{(e,e)}(V \times S)$ with $T_{e}V \oplus T_{e}S$. This problem arises in the proof of Theorem 7.21 of John Lee's introduction to smooth manifolds book (second edition).","Okay I couldn't fit this all in the title but here is the full setup: $G$ a Lie group with $V,S$ submanifolds of $G$ containing the identity element $e$. We are considering the map $\psi: V \times S \rightarrow G$ obtained by restricting the multiplication map on $G$, i.e. $\psi(v,s)=vs$. I am stuck trying to show that since $\psi(v,e)=v$ for $v \in V$ and $\psi(e,s)=s$ for $s \in S$, then it follows that the differential of $\psi$ at $(e,e)$ satisfies $d\psi(X,0)=X$ and $d\psi(0,Y)=Y$ for $X \in T_{e}V$ and $Y \in T_{e}S$. I am also confused about how we are identifying $T_{(e,e)}(V \times S)$ with $T_{e}V \oplus T_{e}S$. This problem arises in the proof of Theorem 7.21 of John Lee's introduction to smooth manifolds book (second edition).",,"['differential-geometry', 'differential-topology', 'lie-groups', 'smooth-manifolds']"
85,Is this subset of the product space of $\mathbb R^{n+1}$ and the projective space $\mathbb R P^n$ a submanifold?,Is this subset of the product space of  and the projective space  a submanifold?,\mathbb R^{n+1} \mathbb R P^n,"Consider the projective space $\mathbb R P^n$, constructed as the quotient space of the sphere $S^n \subseteq \mathbb R^{n+1}$ with the equivalence relation where we identify opposite points. I now want to prove or disprove that the set $M := \{(x, [y]) : [y] \in \mathbb R P^n, x \in [y]\}$ is a submanifold of the manifold $N := \mathbb R^{n+1} \times \mathbb R P^n$. Now I rather suspect that it's not a submanifold, but I wasn't able to prove it so far. My thinking was, $M$ is a submanifold of $N$ if and only if there is an injective immersion $\iota: M \to N$. Now the first choice for such an immersion would be the natural map $M \to N, (x, [y]) \mapsto (x, [y])$. To check if that's an immersion, we would need to check that the Jacobean matrix is injective. I have not proven it yet but I suspect it will not be injective, basically because the components of a vector $x$ of the first component of $(x, [y])$ also appear in the $[y]$-component so the Jacobean it shouldn't add up to full rank? But let's assume that's true, then I would have shown that the identity map $M \to N$ isn't an immersion... how would I go about showing that there doesn't exist any other map $M \to N$ that happens to be an injective immersion? Is there an easy way to see on why this is or isn't the case? The most similar question I could find was this one and the set in question is not the same there as far as I can tell.","Consider the projective space $\mathbb R P^n$, constructed as the quotient space of the sphere $S^n \subseteq \mathbb R^{n+1}$ with the equivalence relation where we identify opposite points. I now want to prove or disprove that the set $M := \{(x, [y]) : [y] \in \mathbb R P^n, x \in [y]\}$ is a submanifold of the manifold $N := \mathbb R^{n+1} \times \mathbb R P^n$. Now I rather suspect that it's not a submanifold, but I wasn't able to prove it so far. My thinking was, $M$ is a submanifold of $N$ if and only if there is an injective immersion $\iota: M \to N$. Now the first choice for such an immersion would be the natural map $M \to N, (x, [y]) \mapsto (x, [y])$. To check if that's an immersion, we would need to check that the Jacobean matrix is injective. I have not proven it yet but I suspect it will not be injective, basically because the components of a vector $x$ of the first component of $(x, [y])$ also appear in the $[y]$-component so the Jacobean it shouldn't add up to full rank? But let's assume that's true, then I would have shown that the identity map $M \to N$ isn't an immersion... how would I go about showing that there doesn't exist any other map $M \to N$ that happens to be an injective immersion? Is there an easy way to see on why this is or isn't the case? The most similar question I could find was this one and the set in question is not the same there as far as I can tell.",,"['differential-geometry', 'manifolds', 'projective-geometry', 'projective-space', 'submanifold']"
86,Identity involving pullback in symplectic geometry,Identity involving pullback in symplectic geometry,,"I'm following Ana Cannas' book , trying to prove Proposition 2.5. If you don't want to open the book, here's a sketch of the problem. Let $X_\mu = \{ (x,\mu_x); x \in X, \, \mu_x \in T_x^*X\}$, where $X$ is a manifold. $X_\mu$ defines, thus, a submanifold in the cotangent bundle. The de Rham 1-form $\mu: X \to T^*X$ is said to depend smoothly on $x$. Define $s_\mu: X \to T^*X: x \mapsto (x,\mu_x)$ as ""the 1-form $\mu$ regarded exclusively as a map"", which obviously has $X_\mu$ as its image, and let $\alpha$ be the tautological 1-form on $T^*X$. Proposition 2.5 wants to prove that $s_\mu^* \alpha = \mu$. The proof starts by noticing that one possible definition of the tautological form, $\alpha_p = (d\pi_p)^*\xi$, where $p=(x,\xi)$ and $\pi$ is the projection $\pi:T^*X \to X: (x,\xi) \mapsto x$, says that if $p=(x,\mu_x)$, then $\alpha_p = (d\pi_p)^*\mu_x$ (pretty obvious). She then writes that $(s_\mu^* \alpha)_x = (ds_\mu)_x^* \alpha_p = \dots$. I can't understand how $s_\mu^*$ became $(ds_\mu)^*$. If $s_\mu: X \to T^*X:x \mapsto (x,\mu_x)$, then $s_\mu^*: T^* X \to T^*(T^*X): (x,\gamma) \mapsto (?,?,?)$, and I also can't get what $(ds_\mu)^*$ is/does. I think I'm having problems visualising the actions of all those mappings.","I'm following Ana Cannas' book , trying to prove Proposition 2.5. If you don't want to open the book, here's a sketch of the problem. Let $X_\mu = \{ (x,\mu_x); x \in X, \, \mu_x \in T_x^*X\}$, where $X$ is a manifold. $X_\mu$ defines, thus, a submanifold in the cotangent bundle. The de Rham 1-form $\mu: X \to T^*X$ is said to depend smoothly on $x$. Define $s_\mu: X \to T^*X: x \mapsto (x,\mu_x)$ as ""the 1-form $\mu$ regarded exclusively as a map"", which obviously has $X_\mu$ as its image, and let $\alpha$ be the tautological 1-form on $T^*X$. Proposition 2.5 wants to prove that $s_\mu^* \alpha = \mu$. The proof starts by noticing that one possible definition of the tautological form, $\alpha_p = (d\pi_p)^*\xi$, where $p=(x,\xi)$ and $\pi$ is the projection $\pi:T^*X \to X: (x,\xi) \mapsto x$, says that if $p=(x,\mu_x)$, then $\alpha_p = (d\pi_p)^*\mu_x$ (pretty obvious). She then writes that $(s_\mu^* \alpha)_x = (ds_\mu)_x^* \alpha_p = \dots$. I can't understand how $s_\mu^*$ became $(ds_\mu)^*$. If $s_\mu: X \to T^*X:x \mapsto (x,\mu_x)$, then $s_\mu^*: T^* X \to T^*(T^*X): (x,\gamma) \mapsto (?,?,?)$, and I also can't get what $(ds_\mu)^*$ is/does. I think I'm having problems visualising the actions of all those mappings.",,"['differential-geometry', 'symplectic-geometry']"
87,Geodesics on the 3-Sphere vs Hopf Circles,Geodesics on the 3-Sphere vs Hopf Circles,,"Regarding $\mathbb S^3$, the $3$-sphere: I'm trying to reconcile claims that seem contradictory. On page 2 of this article: "" Sculptures in $\mathbb S^3$ "" by Schleimer and Segerman one finds the quote: ""Any plane, meeting the origin in $\mathbb R^4$, cuts $\mathbb S^3$ in a great circle. The great circles are the geodesics, or locally shortest paths, in the geometry on $\mathbb S^3$. Just as for the usual sphere, $\mathbb S^2$, two distinct great circles meet at two points, [$x$ and the antipode of $x$]"" That makes sense to me. However on page 103 of ""Three-Dimensional Geometry and Topology"" by William Thurston, I find the quote: ""Each complex line (one-dimensional subspace) in $\mathbb C^2$ intersects $\mathbb S^3$ in a great circle, called a Hopf Circle. Since exactly one Hopf circle passes through each point of $\mathbb S^3$ ,..."" A one-dimensional line in $\mathbb C^2$ is analagous to a  plane in $\mathbb R^4$. The first quote says more than one great circle can pass through a single point of $\mathbb S^3$, while the second quote says the opposite. What am I confusing here? Secondly, it sounds like Thurston is saying that the plane does not need to intersect the origin for its intersection with $\mathbb S^3$ to form a geodesic. Is that correct? If so, how does on make a small circle on $\mathbb S^3$?","Regarding $\mathbb S^3$, the $3$-sphere: I'm trying to reconcile claims that seem contradictory. On page 2 of this article: "" Sculptures in $\mathbb S^3$ "" by Schleimer and Segerman one finds the quote: ""Any plane, meeting the origin in $\mathbb R^4$, cuts $\mathbb S^3$ in a great circle. The great circles are the geodesics, or locally shortest paths, in the geometry on $\mathbb S^3$. Just as for the usual sphere, $\mathbb S^2$, two distinct great circles meet at two points, [$x$ and the antipode of $x$]"" That makes sense to me. However on page 103 of ""Three-Dimensional Geometry and Topology"" by William Thurston, I find the quote: ""Each complex line (one-dimensional subspace) in $\mathbb C^2$ intersects $\mathbb S^3$ in a great circle, called a Hopf Circle. Since exactly one Hopf circle passes through each point of $\mathbb S^3$ ,..."" A one-dimensional line in $\mathbb C^2$ is analagous to a  plane in $\mathbb R^4$. The first quote says more than one great circle can pass through a single point of $\mathbb S^3$, while the second quote says the opposite. What am I confusing here? Secondly, it sounds like Thurston is saying that the plane does not need to intersect the origin for its intersection with $\mathbb S^3$ to form a geodesic. Is that correct? If so, how does on make a small circle on $\mathbb S^3$?",,"['differential-geometry', 'spheres', 'spherical-geometry']"
88,"Manifold , smooth curve, differentiation","Manifold , smooth curve, differentiation",,"Suppose $M^n$ is a smooth $n$-dimensional manifold, and $\gamma(t):[0,1]\to M^n$ is a smooth curve on it.How do I find the differentiation (derivation) $d\gamma(t)/dt$ so that in particular if $\gamma(t)=x^\alpha(t)$ is the $\alpha$th-coordinate function then $d\gamma(t)/dt=1$? What I do not understand is the fact that $\gamma$ leads to $M^n$ and not to $\mathbb{R}^n$, and I have problems with the precise,technical applications of charts $(U,\phi_U)$ where $U$ is an open set in the manifold $M^n$ and $\phi:U\to \phi(U)\subseteq\mathbb{R}^n$ is a homeomorphism.","Suppose $M^n$ is a smooth $n$-dimensional manifold, and $\gamma(t):[0,1]\to M^n$ is a smooth curve on it.How do I find the differentiation (derivation) $d\gamma(t)/dt$ so that in particular if $\gamma(t)=x^\alpha(t)$ is the $\alpha$th-coordinate function then $d\gamma(t)/dt=1$? What I do not understand is the fact that $\gamma$ leads to $M^n$ and not to $\mathbb{R}^n$, and I have problems with the precise,technical applications of charts $(U,\phi_U)$ where $U$ is an open set in the manifold $M^n$ and $\phi:U\to \phi(U)\subseteq\mathbb{R}^n$ is a homeomorphism.",,"['differential-geometry', 'manifolds', 'smooth-manifolds', 'coordinate-systems', 'curves']"
89,Volume of a manifold,Volume of a manifold,,"Throughout this post, I am presuming $M$ to be an $2$-dimensional manifold that is parametrized by one chart $\varphi$, and I presume $\omega$ be a $2$-form on $M$. Apparently, there is no natural way to define the volume of a manifold, if it's not a pseudo-Riemannian manifold - i.e., we don't have a metric on it of some kind. Here is a question I have, based on that: 1 My ""argument"" against this a few days ago was this - why does it not make sense to define the volume as $ \int_M 1 dx_1 \wedge .. \wedge dx_n$? To this I got the reply, that I can ""scale"" that form, and it still makes perfect sense to define that as volume - so it's arbitrary to choose $1 dx_1 \wedge .. \wedge dx_n$ as opposed to $2 dx_1 \wedge .. \wedge dx_n$. I didn't undestand this argument, but I think I do now, and I'd like to make sure I undestand it correctly. I think the issue here stems from my previous understanding of $dx_i$ primarily as symbols, as opposed to actual linear maps from the tangent space, that are induced by some map. I thought $1 dx_1 \wedge .. \wedge dx_n$ is the always the same thing as $1 dy_1 \wedge .. \wedge dy_n$, that it's just a different notation of the coordinates - but I see now, that in some sense, that's not the case. - As a linear map from the tangent space, the expression $1 dx_1 \wedge .. \wedge dx_n$ by itself doesn't really make sense on it's own, and it's not something I can integrate on $M$ - first, I need to pick a certain chart, to know what $dx_i$ actually are - and this is arbitrary. More formally: If for a chart $\varphi$ I denote the 'induced' forms $dx_i$ as those forms, for which $dx_i(\frac{\partial }{\partial x_i})=1$, where $(\frac{\partial }{\partial x_i})$ is the tangent vector induced by $\varphi$. I take a ""scaled"" version of $\varphi$ and call this new chart $\varphi'$. If I now consider two differential forms : $\omega = 1 dx_1 \wedge .. \wedge dx_n$ (where $dx_i$ are induced by $\varphi$) $\omega'= 1 dx_1' \wedge .. \wedge dx_n'$ (where $dx_i'$ are induced by $\varphi'$), it's actually true that $\omega' = \alpha dx_1 \wedge .. \wedge dx_n$ , for some $\alpha$. Thus, their integrals will give something different, depending on Î±Î±, and choosing one as opposed to the other is arbitrary, and so it doesn't make sense to prefer one as opposed to the other for defining volume. - Is my answer to 1 correct? 2 Based on all of this, does it then make sense to think of differential forms as some type of ""measure"", that gives me volumes of tangent vectors, parallelograms formed by a choice of two tangent vectors, or generalizations of the previous?","Throughout this post, I am presuming $M$ to be an $2$-dimensional manifold that is parametrized by one chart $\varphi$, and I presume $\omega$ be a $2$-form on $M$. Apparently, there is no natural way to define the volume of a manifold, if it's not a pseudo-Riemannian manifold - i.e., we don't have a metric on it of some kind. Here is a question I have, based on that: 1 My ""argument"" against this a few days ago was this - why does it not make sense to define the volume as $ \int_M 1 dx_1 \wedge .. \wedge dx_n$? To this I got the reply, that I can ""scale"" that form, and it still makes perfect sense to define that as volume - so it's arbitrary to choose $1 dx_1 \wedge .. \wedge dx_n$ as opposed to $2 dx_1 \wedge .. \wedge dx_n$. I didn't undestand this argument, but I think I do now, and I'd like to make sure I undestand it correctly. I think the issue here stems from my previous understanding of $dx_i$ primarily as symbols, as opposed to actual linear maps from the tangent space, that are induced by some map. I thought $1 dx_1 \wedge .. \wedge dx_n$ is the always the same thing as $1 dy_1 \wedge .. \wedge dy_n$, that it's just a different notation of the coordinates - but I see now, that in some sense, that's not the case. - As a linear map from the tangent space, the expression $1 dx_1 \wedge .. \wedge dx_n$ by itself doesn't really make sense on it's own, and it's not something I can integrate on $M$ - first, I need to pick a certain chart, to know what $dx_i$ actually are - and this is arbitrary. More formally: If for a chart $\varphi$ I denote the 'induced' forms $dx_i$ as those forms, for which $dx_i(\frac{\partial }{\partial x_i})=1$, where $(\frac{\partial }{\partial x_i})$ is the tangent vector induced by $\varphi$. I take a ""scaled"" version of $\varphi$ and call this new chart $\varphi'$. If I now consider two differential forms : $\omega = 1 dx_1 \wedge .. \wedge dx_n$ (where $dx_i$ are induced by $\varphi$) $\omega'= 1 dx_1' \wedge .. \wedge dx_n'$ (where $dx_i'$ are induced by $\varphi'$), it's actually true that $\omega' = \alpha dx_1 \wedge .. \wedge dx_n$ , for some $\alpha$. Thus, their integrals will give something different, depending on Î±Î±, and choosing one as opposed to the other is arbitrary, and so it doesn't make sense to prefer one as opposed to the other for defining volume. - Is my answer to 1 correct? 2 Based on all of this, does it then make sense to think of differential forms as some type of ""measure"", that gives me volumes of tangent vectors, parallelograms formed by a choice of two tangent vectors, or generalizations of the previous?",,"['differential-geometry', 'manifolds', 'differential-forms', 'manifolds-with-boundary']"
90,Do carmo's exercise 3.2-11: conjugate directions on a surface,Do carmo's exercise 3.2-11: conjugate directions on a surface,,"I'm trying to find a satisfying answer to this problem, so I would appreciate some help. Let $p\in S$ be an elliptic point and let $r$ and $r'$ be conjugate directions at $p$ . Varying $r$ in $T_pS$ , show that the minimum value of the angle between $r$ and $r'$ is attained by a unique pair of vectors in $T_pS$ , which are symmetric with respect to the principal directions. My idea was to simply consider unit vectors in directions of $r$ and $r'$ respectively, say $w=\cos(\theta)e_1+\sin(\theta)e_2$ and $w'=\cos(\phi)e_1+\sin(\phi)e_2$ so that the angle between these two vectors would be given by $\displaystyle \cos(\theta)\cos(\phi)+\sin(\theta)\sin(\phi)$ . Now, remember that $\theta$ is varying and, since $r$ and $r'$ are conjugate, $\phi=\phi(\theta)$ . Taking the derivative of that last expression with respect to $\theta$ and making it equal to 0, we should be able to find the answer. I'm not very confident of this approach, though. Thank you!","I'm trying to find a satisfying answer to this problem, so I would appreciate some help. Let be an elliptic point and let and be conjugate directions at . Varying in , show that the minimum value of the angle between and is attained by a unique pair of vectors in , which are symmetric with respect to the principal directions. My idea was to simply consider unit vectors in directions of and respectively, say and so that the angle between these two vectors would be given by . Now, remember that is varying and, since and are conjugate, . Taking the derivative of that last expression with respect to and making it equal to 0, we should be able to find the answer. I'm not very confident of this approach, though. Thank you!",p\in S r r' p r T_pS r r' T_pS r r' w=\cos(\theta)e_1+\sin(\theta)e_2 w'=\cos(\phi)e_1+\sin(\phi)e_2 \displaystyle \cos(\theta)\cos(\phi)+\sin(\theta)\sin(\phi) \theta r r' \phi=\phi(\theta) \theta,"['differential-geometry', 'surfaces']"
91,Diffeomorphism between open disk and open square and no diffeomorphism closed disk and closed square,Diffeomorphism between open disk and open square and no diffeomorphism closed disk and closed square,,"This is a very basic question. The diffeomorphism between open disk and open square exists. The closed square cannot be diffeomorphic to closed disk as the boundary is not smooth and the diffeomorphism will map boundary to boundary. So given any diffeomorphism between open disk and open square, I cannot extend it to the boundary, though they are homeo. Q1: What is the obstruction to the extension? Intuitive reason please. Q2: Clearly diffeomorphism open sets as above does not see angles on the boundary though there is. However Q1's extension issue does say those diffeomorphisms have some memory on the boundary information as you cannot further extend it. Is there a way to extract this remnant information as the morphism does carry the information about the boundary? Say $A$ is diffeo to $B$ as open sets and I want to check whether $\bar{A}$ diffeo to $\bar{B}$ where the closure is taken in some ambient space? Q3: Under what kind of condition, do I know there is possible extension?","This is a very basic question. The diffeomorphism between open disk and open square exists. The closed square cannot be diffeomorphic to closed disk as the boundary is not smooth and the diffeomorphism will map boundary to boundary. So given any diffeomorphism between open disk and open square, I cannot extend it to the boundary, though they are homeo. Q1: What is the obstruction to the extension? Intuitive reason please. Q2: Clearly diffeomorphism open sets as above does not see angles on the boundary though there is. However Q1's extension issue does say those diffeomorphisms have some memory on the boundary information as you cannot further extend it. Is there a way to extract this remnant information as the morphism does carry the information about the boundary? Say $A$ is diffeo to $B$ as open sets and I want to check whether $\bar{A}$ diffeo to $\bar{B}$ where the closure is taken in some ambient space? Q3: Under what kind of condition, do I know there is possible extension?",,"['general-topology', 'differential-geometry', 'differential-topology']"
92,Lie bracket of left-invariant vector fields is left-invariant,Lie bracket of left-invariant vector fields is left-invariant,,"Let $G$ be a Lie group and $l_g:G\rightarrow G$ be the left-multiplication map. Let $X$ be a left invariant vector field on $G$ , i.e., $X:G\rightarrow TG$ is such that $(l_g)_*X=X$ on $G$ where $(l_g)_*X$ is  defined as follows: $$((l_g)_*X)_{gh}=(l_g)_{*,h}(X_h)$$ where $(l_g)_{*,h}:T_hG\rightarrow T_{gh}G$ is the differential of $l_g$ at $h$ . So, supposing $X$ is a left-invariant vector field, we have $$(l_g)_{*,e}(X_e)=X_g.$$ I am trying to prove that the Lie bracket $[X,Y]$ is also a left-invariant vector field. $${[X,Y]_g(f)}={X_g(Y(f))-Y_g(X(f))}={(l_g)_{*,e}(X_e)(Y(f))-(l_g)_{*,e}(Y_e)(X(f)) }={X_e(Y(f)\circ l_g)-Y_e(X(f)\circ l_g)}={X_e(Y(f\circ l_g))-Y_e(X(f\circ l_g))}={[X,Y]_e(f\circ l_g)}={(l_g)_{*,e}([X,Y]_e)(f)}$$ This is true for all $f$ . So, we have $$(l_g)_{*,e}([X,Y]_e)=[X,Y]_g.$$ Using same idea, we can prove that $$(l_g)_{*,h}([X,Y]_h)=[X,Y]_{gh}$$ for all $h\in G$ which is same as saying that $[X,Y]$ is a left-invariant vector field. I am sure about all equalities except one, i.e., $Y(f\circ l_g)=Y(f)\circ l_g$ . I am sure this is correct but could not see. Any suggestions about the proof are welcome.","Let be a Lie group and be the left-multiplication map. Let be a left invariant vector field on , i.e., is such that on where is  defined as follows: where is the differential of at . So, supposing is a left-invariant vector field, we have I am trying to prove that the Lie bracket is also a left-invariant vector field. This is true for all . So, we have Using same idea, we can prove that for all which is same as saying that is a left-invariant vector field. I am sure about all equalities except one, i.e., . I am sure this is correct but could not see. Any suggestions about the proof are welcome.","G l_g:G\rightarrow G X G X:G\rightarrow TG (l_g)_*X=X G (l_g)_*X ((l_g)_*X)_{gh}=(l_g)_{*,h}(X_h) (l_g)_{*,h}:T_hG\rightarrow T_{gh}G l_g h X (l_g)_{*,e}(X_e)=X_g. [X,Y] {[X,Y]_g(f)}={X_g(Y(f))-Y_g(X(f))}={(l_g)_{*,e}(X_e)(Y(f))-(l_g)_{*,e}(Y_e)(X(f))
}={X_e(Y(f)\circ l_g)-Y_e(X(f)\circ l_g)}={X_e(Y(f\circ l_g))-Y_e(X(f\circ l_g))}={[X,Y]_e(f\circ l_g)}={(l_g)_{*,e}([X,Y]_e)(f)} f (l_g)_{*,e}([X,Y]_e)=[X,Y]_g. (l_g)_{*,h}([X,Y]_h)=[X,Y]_{gh} h\in G [X,Y] Y(f\circ l_g)=Y(f)\circ l_g",['differential-geometry']
93,Normal bundles and vector bundles,Normal bundles and vector bundles,,"Let $Y$ be a smooth manifold, and let $\pi:E\to Y$ be a smooth vector bundle over $Y$. Suppose that $X$ is an immersed submanifold of $Y$, which lies in $E$ as the zero set of some smooth section $s:Y\to E$. I am trying to show that $E|_X$ is isomorphic to the normal bundle of $X$ in $Y$ (defined as the quotient bundle $TY|_X/TX$). I proceed as follows. Let $x\in X$ and $z:Y\to E$ be the zero section. The map $\phi_x:E_x\to T_{z(x)}E,v\mapsto\dot\gamma_v(0)$ (where $\gamma_v(t)=(x,tv)$ is injective and $im(\phi_x)=\ker(d\pi_{z(x)})$, so $0\to E_x\to T_{z(x)}E\to T_xY$ is an exact sequence, which splits since $d\pi_{z(x)}\circ ds_x=id_{T_xY}$. Now the map \begin{aligned} \psi_x:T_{z(x)}E&\to E_x\oplus T_xY \\ w&\mapsto(\tilde\phi^{-1}_x(w-dz_x(d\pi_{z(x)}(w))),d\pi_{z(x)}(w)) \end{aligned} is an iso, where $\tilde\phi_x$ is the map $\phi_x$ with codomain restricted to $\ker(d\pi_{z(x)}$. Hence we get map $F:=p_1\circ\psi_x\circ ds_x$, where $p_1:E_x\oplus T_xY\to E_x$ is the projection. This map should clearly become my isomorphism, and I have two concrete questions about it. Unraveling the definitions we see that $v\in T_xY$ is in $\ker(p_1\circ\psi_x\circ ds_X)$ if and only if $dz_x(v)=ds_x(v)$, and from here I want to conclude that this implies that $\ker F=T_xX$, but I'm not quite sure how. The inclusion $T_xX\subset\ker F$ is clear since $z|_X=s|_X\implies dz_x|_{T_xX}=ds_X|_{T_xX}$, but I'm not sure how $dz_x(v)=ds_x(v)$ implies that $v\in T_xX$. We do know that $z|_{X\setminus Y}\neq s|_{X\setminus Y}$, but I am not sure that that implies that $dz_x(v)\neq dz_x(v)$ if $v\in T_xY\setminus T_xX$. Secondly, I need this map to be surjective, but I have no idea how this follows. Any help or tips or references are greatly appreciated! Edit I think that the surjectivity question can be rephrased: since $z(x)=s(x)$ it holds that $d\pi_{z(x)}\circ ds_x=id_{T_xY}$, so the surjectivity of $p_1\circ\psi_x\circ ds_x$ is equivalent to the surjectivity of $\tilde\phi^{-1}_x(ds_x-dz_x)$, i.e. if each $v\in E_x$ can be written as $\tilde\phi^{-1}(ds_x(u)-dz_x(u))$ for some $u\in T_xY$.","Let $Y$ be a smooth manifold, and let $\pi:E\to Y$ be a smooth vector bundle over $Y$. Suppose that $X$ is an immersed submanifold of $Y$, which lies in $E$ as the zero set of some smooth section $s:Y\to E$. I am trying to show that $E|_X$ is isomorphic to the normal bundle of $X$ in $Y$ (defined as the quotient bundle $TY|_X/TX$). I proceed as follows. Let $x\in X$ and $z:Y\to E$ be the zero section. The map $\phi_x:E_x\to T_{z(x)}E,v\mapsto\dot\gamma_v(0)$ (where $\gamma_v(t)=(x,tv)$ is injective and $im(\phi_x)=\ker(d\pi_{z(x)})$, so $0\to E_x\to T_{z(x)}E\to T_xY$ is an exact sequence, which splits since $d\pi_{z(x)}\circ ds_x=id_{T_xY}$. Now the map \begin{aligned} \psi_x:T_{z(x)}E&\to E_x\oplus T_xY \\ w&\mapsto(\tilde\phi^{-1}_x(w-dz_x(d\pi_{z(x)}(w))),d\pi_{z(x)}(w)) \end{aligned} is an iso, where $\tilde\phi_x$ is the map $\phi_x$ with codomain restricted to $\ker(d\pi_{z(x)}$. Hence we get map $F:=p_1\circ\psi_x\circ ds_x$, where $p_1:E_x\oplus T_xY\to E_x$ is the projection. This map should clearly become my isomorphism, and I have two concrete questions about it. Unraveling the definitions we see that $v\in T_xY$ is in $\ker(p_1\circ\psi_x\circ ds_X)$ if and only if $dz_x(v)=ds_x(v)$, and from here I want to conclude that this implies that $\ker F=T_xX$, but I'm not quite sure how. The inclusion $T_xX\subset\ker F$ is clear since $z|_X=s|_X\implies dz_x|_{T_xX}=ds_X|_{T_xX}$, but I'm not sure how $dz_x(v)=ds_x(v)$ implies that $v\in T_xX$. We do know that $z|_{X\setminus Y}\neq s|_{X\setminus Y}$, but I am not sure that that implies that $dz_x(v)\neq dz_x(v)$ if $v\in T_xY\setminus T_xX$. Secondly, I need this map to be surjective, but I have no idea how this follows. Any help or tips or references are greatly appreciated! Edit I think that the surjectivity question can be rephrased: since $z(x)=s(x)$ it holds that $d\pi_{z(x)}\circ ds_x=id_{T_xY}$, so the surjectivity of $p_1\circ\psi_x\circ ds_x$ is equivalent to the surjectivity of $\tilde\phi^{-1}_x(ds_x-dz_x)$, i.e. if each $v\in E_x$ can be written as $\tilde\phi^{-1}(ds_x(u)-dz_x(u))$ for some $u\in T_xY$.",,"['differential-geometry', 'vector-bundles', 'tangent-bundle']"
94,Restricting Foliations by Hopf Circles,Restricting Foliations by Hopf Circles,,"Suppose I have $\mathbb{S}^5$, foliated by Hopf circles. I am wondering if this restricts in some way to the foliation by Hopf circles on $\mathbb{S}^3$ in the join $\mathbb{S}^5=\mathbb{S}^3*\mathbb{S}^1$. More generally, given a foliation of $\mathbb{S}^{2n+1}$ by Hopf circles, does this foliation restrict to Hopf circle foliations of $\mathbb{S}^{2k+1}$ in the join $\mathbb{S}^{2n+1}=\mathbb{S}^{2k+1}*\mathbb{S}^{2(n-k)-1}$?","Suppose I have $\mathbb{S}^5$, foliated by Hopf circles. I am wondering if this restricts in some way to the foliation by Hopf circles on $\mathbb{S}^3$ in the join $\mathbb{S}^5=\mathbb{S}^3*\mathbb{S}^1$. More generally, given a foliation of $\mathbb{S}^{2n+1}$ by Hopf circles, does this foliation restrict to Hopf circle foliations of $\mathbb{S}^{2k+1}$ in the join $\mathbb{S}^{2n+1}=\mathbb{S}^{2k+1}*\mathbb{S}^{2(n-k)-1}$?",,"['differential-geometry', 'riemannian-geometry', 'geometric-topology', 'metric-geometry', 'foliations']"
95,Tangent space to a product manifold using curves,Tangent space to a product manifold using curves,,"This is an exercise from An introduction to Manifolds by Loring Tu. If $M,N$ are manifolds, let $\pi_1:M\times N\rightarrow M$ and $\pi_2:M\times N\rightarrow N$ be two projections. Prove that for $(p,q)\in M\times N$, $$(\pi_{1*},\pi_{2*}):T_{(p,q)}(M\times N)\rightarrow T_pM\times T_qN$$   is an isomorphism. Let $X_{(p,q)}\in T_{(p,q)}M\times N$ i.e., there exists $c:(-\epsilon, \epsilon)\rightarrow M\times N$ such that $c(0)=(p,q)$ and $c'(0)=X_{(p,q)}$. We have composition maps $c_1=\pi_1\circ c:(-\epsilon,\epsilon)\rightarrow M$ and $c_2=\pi_2\circ c:(-\epsilon,\epsilon)\rightarrow N$ such that $c_1(0)=p$ and $c_2(0)=q$. So, we have $c_1'(0)\in T_pM$ and $c_2'(0)\in T_qN$. So, we define the map $T_{(p,q)}(M\times N)\rightarrow T_pM\times T_qN$ as $X_{p,q}=c'(0)\mapsto (c_1'(0),c_2'(0))=(X_p,X_q)$. It remains to prove that this map is an isomorphism. Let $(X_p.Y_q)\in T_pM\times T_qN$ i.e., there exists $\tau_1:(-\epsilon,\epsilon)\rightarrow M$ such that  $\tau_1(0)=p,\tau_1'(0)=X_p$ and $\tau_2:(-\epsilon,\epsilon)\rightarrow N$ such that  $\tau_2(0)=p,\tau_2'(0)=Y_q$. This $\tau_1,\tau_2$ gives $c:(-\epsilon,\epsilon)\rightarrow M\times N$ defined as  $t\mapsto(\tau_1(t),\tau_2(t))$ and $c(0)=(\tau_1(0),\tau_2(0))=(p,q)$ and  $$((\pi_1\circ c)'(0),(\pi_2\circ c)'(0))=(\tau_1'(0),\tau_2'(0))=(X_p,Y_q).$$ So, the above map is surjective. Let $c:(-\epsilon,\epsilon)\rightarrow M\times N$ with $c'(0)\in T_{(p,q)}(M\times N)$ be such that  $$((\pi_1\circ c)'(0),(\pi_2\circ c)'(0))=(0,0).$$ We need to prove that $c'(0)=\in T_{(p,q)}(M\times N)$  i.e., to prove  $c'(0)(f)=0$ i.e., $$\frac{d}{dt}\bigg|_0 (f\circ c)=0$$ for all $f\in C_{(p,q)}^{\infty}(M\times N)$. Given $f\in C_{(p,q)}^{\infty}(M\times N)$ we have $f_1:M\rightarrow \mathbb{R}$ defined as $m\mapsto f(m,q)$ and  $f_2:N\rightarrow \mathbb{R}$ defined as $n\mapsto f(p,n)$. Then, $f_1\in C_p^\infty M$ and $f_2\in C_q^\infty N$. As $(\pi_1\circ \eta_1)'(0)=0$, we have $(\pi_1\circ c)'(0)(f_1)=0$ i.e., $$\frac{d}{dt}\bigg|_{t=0}(f_1\circ \pi_1\circ c)=0.$$ Similarly, we have $$\frac{d}{dt}\bigg|_{t=0}(f_2\circ \pi_2\circ c)=0.$$ I am stuck here. Any suggestion for this approach is welcome.","This is an exercise from An introduction to Manifolds by Loring Tu. If $M,N$ are manifolds, let $\pi_1:M\times N\rightarrow M$ and $\pi_2:M\times N\rightarrow N$ be two projections. Prove that for $(p,q)\in M\times N$, $$(\pi_{1*},\pi_{2*}):T_{(p,q)}(M\times N)\rightarrow T_pM\times T_qN$$   is an isomorphism. Let $X_{(p,q)}\in T_{(p,q)}M\times N$ i.e., there exists $c:(-\epsilon, \epsilon)\rightarrow M\times N$ such that $c(0)=(p,q)$ and $c'(0)=X_{(p,q)}$. We have composition maps $c_1=\pi_1\circ c:(-\epsilon,\epsilon)\rightarrow M$ and $c_2=\pi_2\circ c:(-\epsilon,\epsilon)\rightarrow N$ such that $c_1(0)=p$ and $c_2(0)=q$. So, we have $c_1'(0)\in T_pM$ and $c_2'(0)\in T_qN$. So, we define the map $T_{(p,q)}(M\times N)\rightarrow T_pM\times T_qN$ as $X_{p,q}=c'(0)\mapsto (c_1'(0),c_2'(0))=(X_p,X_q)$. It remains to prove that this map is an isomorphism. Let $(X_p.Y_q)\in T_pM\times T_qN$ i.e., there exists $\tau_1:(-\epsilon,\epsilon)\rightarrow M$ such that  $\tau_1(0)=p,\tau_1'(0)=X_p$ and $\tau_2:(-\epsilon,\epsilon)\rightarrow N$ such that  $\tau_2(0)=p,\tau_2'(0)=Y_q$. This $\tau_1,\tau_2$ gives $c:(-\epsilon,\epsilon)\rightarrow M\times N$ defined as  $t\mapsto(\tau_1(t),\tau_2(t))$ and $c(0)=(\tau_1(0),\tau_2(0))=(p,q)$ and  $$((\pi_1\circ c)'(0),(\pi_2\circ c)'(0))=(\tau_1'(0),\tau_2'(0))=(X_p,Y_q).$$ So, the above map is surjective. Let $c:(-\epsilon,\epsilon)\rightarrow M\times N$ with $c'(0)\in T_{(p,q)}(M\times N)$ be such that  $$((\pi_1\circ c)'(0),(\pi_2\circ c)'(0))=(0,0).$$ We need to prove that $c'(0)=\in T_{(p,q)}(M\times N)$  i.e., to prove  $c'(0)(f)=0$ i.e., $$\frac{d}{dt}\bigg|_0 (f\circ c)=0$$ for all $f\in C_{(p,q)}^{\infty}(M\times N)$. Given $f\in C_{(p,q)}^{\infty}(M\times N)$ we have $f_1:M\rightarrow \mathbb{R}$ defined as $m\mapsto f(m,q)$ and  $f_2:N\rightarrow \mathbb{R}$ defined as $n\mapsto f(p,n)$. Then, $f_1\in C_p^\infty M$ and $f_2\in C_q^\infty N$. As $(\pi_1\circ \eta_1)'(0)=0$, we have $(\pi_1\circ c)'(0)(f_1)=0$ i.e., $$\frac{d}{dt}\bigg|_{t=0}(f_1\circ \pi_1\circ c)=0.$$ Similarly, we have $$\frac{d}{dt}\bigg|_{t=0}(f_2\circ \pi_2\circ c)=0.$$ I am stuck here. Any suggestion for this approach is welcome.",,['differential-geometry']
96,"Example of tensor $(0,2)$ acting on two vectors",Example of tensor  acting on two vectors,"(0,2)","After much shifting through notational hurdles, I may have gotten the point. However, I'd like to confirm this unequivocally by working through an example. If $\beta \in V^*$ is $\beta=\begin{bmatrix}1 &2 &3 \end{bmatrix}$ and $\gamma\in V^*$ is $\gamma=\begin{bmatrix}2 &4 &6 \end{bmatrix}$. The $(2,0)$-tensor $\beta\otimes \gamma$ is the outer product: $$\beta\otimes_o \gamma=\begin{bmatrix}2\,e^1\otimes e^1&4\,e^1\otimes e^2&6\,e^1\otimes e^3\\4\,e^2\otimes e^1&8\,e^2\otimes e^2&12\,e^2\otimes e^3\\6\,e^3\otimes e^1&12\,e^3\otimes e^2&18\,e^3\otimes e^3\end{bmatrix}$$ Now if apply this tensor product on the vectors $$v=\begin{bmatrix}1\\-1\\5\end{bmatrix}, \; w = \begin{bmatrix}2\\0\\3\end{bmatrix}$$ $$\begin{align} (\beta \otimes \gamma)[v,w]&=\\[2ex] & 2 \times  1 \times 2   \quad+\quad    4 \times   1  \times  0   \quad +\quad    6  \times  1  \times 3 \\ +\;&4 \times -1 \times 2  \quad + \quad   8 \times  -1  \times  0   \quad + \quad  12  \times -1  \times 3 \\ +\;&6 \times  5 \times 2  \quad + \quad  12 \times   5  \times  0  \quad  + \quad  18  \times  5  \times 3 \\[2ex] &= 308\end{align}$$ Is this correct?","After much shifting through notational hurdles, I may have gotten the point. However, I'd like to confirm this unequivocally by working through an example. If $\beta \in V^*$ is $\beta=\begin{bmatrix}1 &2 &3 \end{bmatrix}$ and $\gamma\in V^*$ is $\gamma=\begin{bmatrix}2 &4 &6 \end{bmatrix}$. The $(2,0)$-tensor $\beta\otimes \gamma$ is the outer product: $$\beta\otimes_o \gamma=\begin{bmatrix}2\,e^1\otimes e^1&4\,e^1\otimes e^2&6\,e^1\otimes e^3\\4\,e^2\otimes e^1&8\,e^2\otimes e^2&12\,e^2\otimes e^3\\6\,e^3\otimes e^1&12\,e^3\otimes e^2&18\,e^3\otimes e^3\end{bmatrix}$$ Now if apply this tensor product on the vectors $$v=\begin{bmatrix}1\\-1\\5\end{bmatrix}, \; w = \begin{bmatrix}2\\0\\3\end{bmatrix}$$ $$\begin{align} (\beta \otimes \gamma)[v,w]&=\\[2ex] & 2 \times  1 \times 2   \quad+\quad    4 \times   1  \times  0   \quad +\quad    6  \times  1  \times 3 \\ +\;&4 \times -1 \times 2  \quad + \quad   8 \times  -1  \times  0   \quad + \quad  12  \times -1  \times 3 \\ +\;&6 \times  5 \times 2  \quad + \quad  12 \times   5  \times  0  \quad  + \quad  18  \times  5  \times 3 \\[2ex] &= 308\end{align}$$ Is this correct?",,"['linear-algebra', 'differential-geometry', 'tensor-products', 'tensors']"
97,Convergence of ADM mass on asymptotically flat manifolds,Convergence of ADM mass on asymptotically flat manifolds,,"Hey dear mathematicians, I just read about Riemannian geometry and didn't understand this: Given a $n$-dimensional Riemannian manifold $(M,g)$ with a specific asymptotic such that the scalar curvature $R$ is given as $R=\sum_{i,j} \left( \partial_{i}\partial_{j}g_{ij} - \partial_{j}\partial_{j}g_{ii} \right) + \mathcal{O}(|x|^{-2p-2})$, where $2p+2>n$. Now the divergence theorem ensures the existence of $\lim\limits_{r \to \infty} \int_{\mathbb{S}_{r}} \sum_{i,j} \left( \partial_{i}g_{ij} - \partial_{j}g_{ii} \right)\nu_{j}\text{d}\xi(r)$, where $\nu=x/r$ is the Euclidean unit normal to $\mathbb{S}_r$ and $\text{d}\xi(r)$ is the Euclidean area element of $\mathbb{S}_r$. I don't understand this implication, can someone clarify this? Thanks in advance! Sincerely, schoeni","Hey dear mathematicians, I just read about Riemannian geometry and didn't understand this: Given a $n$-dimensional Riemannian manifold $(M,g)$ with a specific asymptotic such that the scalar curvature $R$ is given as $R=\sum_{i,j} \left( \partial_{i}\partial_{j}g_{ij} - \partial_{j}\partial_{j}g_{ii} \right) + \mathcal{O}(|x|^{-2p-2})$, where $2p+2>n$. Now the divergence theorem ensures the existence of $\lim\limits_{r \to \infty} \int_{\mathbb{S}_{r}} \sum_{i,j} \left( \partial_{i}g_{ij} - \partial_{j}g_{ii} \right)\nu_{j}\text{d}\xi(r)$, where $\nu=x/r$ is the Euclidean unit normal to $\mathbb{S}_r$ and $\text{d}\xi(r)$ is the Euclidean area element of $\mathbb{S}_r$. I don't understand this implication, can someone clarify this? Thanks in advance! Sincerely, schoeni",,"['differential-geometry', 'manifolds', 'riemannian-geometry', 'divergence-operator', 'general-relativity']"
98,What is the analog of a vector bundle connection for a projective bundle?,What is the analog of a vector bundle connection for a projective bundle?,,"For a vector bundle, a connection is defined as a linear operator $\nabla:\Gamma(E)\rightarrow \Gamma(E\otimes T^*M)$, and the horizontal subspace is locally spanned by solutions of the equation $\nabla s_i=0$.  Is there a similar way of viewing connections on projective bundles?  If a projective bundle descends from a vector bundle, what is the relation between the connections?  Is there a good source to learn this information from (there are many good sources for vector bundles and principal bundles, but I have not seen any good sources on projective bundles).","For a vector bundle, a connection is defined as a linear operator $\nabla:\Gamma(E)\rightarrow \Gamma(E\otimes T^*M)$, and the horizontal subspace is locally spanned by solutions of the equation $\nabla s_i=0$.  Is there a similar way of viewing connections on projective bundles?  If a projective bundle descends from a vector bundle, what is the relation between the connections?  Is there a good source to learn this information from (there are many good sources for vector bundles and principal bundles, but I have not seen any good sources on projective bundles).",,"['differential-geometry', 'algebraic-geometry', 'projective-geometry', 'projective-space', 'fiber-bundles']"
99,Question about the physical intuition behind tensors,Question about the physical intuition behind tensors,,"I would like to check something with you. I am a beginner in differential geometry and in general relativity so I may say wrong things. This is what I understood from tensors. Tensors are object for which coordinates follows a specific transformation when a change of basis is done. If I define a tensor on a basis $A$, I automatically know its components on a basis $B$. The philosophy behind the object is to be able to define quantities that are ""absolute"" and don't depend on coordinates. For example $ds^2=dx^2+dy^2$ is also written in polar coordinates $ds^2=dr^2+r^2 d\theta^2$ but it represents physically the same distance : if I compute the scalar product between two vectors using either the first or the second basis, the result will be the same. So finally : can I say that tensors are mathematical object that are used to describe phenomenon that are absolute and don't depend on a given set of basis . For example if I take a n-contravariant and p-covariant tensor and I apply it on n vectors and p covectors the final result will not depend of any choice of basis. Also : why do we only define tensors as object that transforms as $m'^i_j=m^k_l \frac{\partial x^l}{\partial y^j}\frac{\partial y^i}{\partial x^k}$ and not more general transformations ? Is it because the tensors are constructed around the notion of vectors/covectors and we want that tensors applied on vector and covector give result independant of the coordinates. So all the tensors were constructed to ensure that applied on vector and covectors they give result indepent of coordinates. Indeed, we could imagine to create other objects that ensure basis-independant results with other object than vectors but it is just that we don't need them in practice (in general relativity we would'nt need them for example). My last question is juste to be sure that I understand well... or not.","I would like to check something with you. I am a beginner in differential geometry and in general relativity so I may say wrong things. This is what I understood from tensors. Tensors are object for which coordinates follows a specific transformation when a change of basis is done. If I define a tensor on a basis $A$, I automatically know its components on a basis $B$. The philosophy behind the object is to be able to define quantities that are ""absolute"" and don't depend on coordinates. For example $ds^2=dx^2+dy^2$ is also written in polar coordinates $ds^2=dr^2+r^2 d\theta^2$ but it represents physically the same distance : if I compute the scalar product between two vectors using either the first or the second basis, the result will be the same. So finally : can I say that tensors are mathematical object that are used to describe phenomenon that are absolute and don't depend on a given set of basis . For example if I take a n-contravariant and p-covariant tensor and I apply it on n vectors and p covectors the final result will not depend of any choice of basis. Also : why do we only define tensors as object that transforms as $m'^i_j=m^k_l \frac{\partial x^l}{\partial y^j}\frac{\partial y^i}{\partial x^k}$ and not more general transformations ? Is it because the tensors are constructed around the notion of vectors/covectors and we want that tensors applied on vector and covector give result independant of the coordinates. So all the tensors were constructed to ensure that applied on vector and covectors they give result indepent of coordinates. Indeed, we could imagine to create other objects that ensure basis-independant results with other object than vectors but it is just that we don't need them in practice (in general relativity we would'nt need them for example). My last question is juste to be sure that I understand well... or not.",,"['differential-geometry', 'general-relativity']"
